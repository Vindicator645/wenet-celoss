/home/work_nfs5_ssd/kxhuang/wenet-encoder_decoder_bias/examples/librispeech/s0/data/lang_char/train_960_unigram5000
dictionary: /home/work_nfs5_ssd/kxhuang/wenet-encoder_decoder_bias/examples/librispeech/s0/data/lang_char/train_960_unigram5000_units.txt
run_2_27_rnnt_bias_both_finetune.sh: init method is file:///home/work_nfs6/tyxu/workspace/wenet-bias-celoss/examples/librispeech/s0/exp/2_27_rnnt_bias_loss_2_class_both_finetune/ddp_init
2023-02-28 22:53:22,857 INFO training on multiple gpus, this gpu 5
2023-02-28 22:53:22,858 INFO training on multiple gpus, this gpu 3
2023-02-28 22:53:22,858 INFO training on multiple gpus, this gpu 7
2023-02-28 22:53:22,860 INFO training on multiple gpus, this gpu 1
2023-02-28 22:53:22,861 INFO training on multiple gpus, this gpu 6
2023-02-28 22:53:22,861 INFO training on multiple gpus, this gpu 2
2023-02-28 22:53:22,863 INFO training on multiple gpus, this gpu 4
2023-02-28 22:53:22,909 INFO training on multiple gpus, this gpu 0
2023-02-28 22:53:33,162 INFO Added key: store_based_barrier_key:1 to store for rank: 4
2023-02-28 22:53:33,163 INFO Added key: store_based_barrier_key:1 to store for rank: 1
2023-02-28 22:53:33,171 INFO Added key: store_based_barrier_key:1 to store for rank: 5
2023-02-28 22:53:33,193 INFO Added key: store_based_barrier_key:1 to store for rank: 7
2023-02-28 22:53:34,179 INFO Added key: store_based_barrier_key:1 to store for rank: 2
2023-02-28 22:53:34,211 INFO Added key: store_based_barrier_key:1 to store for rank: 6
2023-02-28 22:53:36,229 INFO Added key: store_based_barrier_key:1 to store for rank: 3
2023-02-28 22:53:40,426 INFO Added key: store_based_barrier_key:1 to store for rank: 0
2023-02-28 22:53:40,452 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-28 22:53:40,613 INFO Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-28 22:53:40,643 INFO Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-28 22:53:40,707 INFO Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-28 22:53:40,803 INFO Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-28 22:53:41,154 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-28 22:53:41,282 INFO Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-28 22:53:41,379 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-28 22:53:51,605 INFO Checkpoint: loading from checkpoint exp/2_27_rnnt_bias_loss_2_class_both_finetune/43.pt for GPU
2023-02-28 22:53:51,631 INFO Checkpoint: loading from checkpoint exp/2_27_rnnt_bias_loss_2_class_both_finetune/43.pt for GPU
2023-02-28 22:53:51,657 INFO Checkpoint: loading from checkpoint exp/2_27_rnnt_bias_loss_2_class_both_finetune/43.pt for GPU
2023-02-28 22:53:51,685 INFO Checkpoint: loading from checkpoint exp/2_27_rnnt_bias_loss_2_class_both_finetune/43.pt for GPU
2023-02-28 22:53:51,718 INFO Checkpoint: loading from checkpoint exp/2_27_rnnt_bias_loss_2_class_both_finetune/43.pt for GPU
2023-02-28 22:53:51,750 INFO Checkpoint: loading from checkpoint exp/2_27_rnnt_bias_loss_2_class_both_finetune/43.pt for GPU
2023-02-28 22:53:51,791 INFO Checkpoint: loading from checkpoint exp/2_27_rnnt_bias_loss_2_class_both_finetune/43.pt for GPU
2023-02-28 22:53:51,842 INFO Checkpoint: loading from checkpoint exp/2_27_rnnt_bias_loss_2_class_both_finetune/43.pt for GPU
2023-02-28 22:54:02,177 INFO Epoch 44 TRAIN info lr 4e-08
2023-02-28 22:54:02,178 INFO using accumulate grad, new batch size is 4 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=100, out_features=100, bias=True)
      (linear_k): Linear(in_features=100, out_features=100, bias=True)
      (linear_v): Linear(in_features=100, out_features=100, bias=True)
      (linear_out): Linear(in_features=100, out_features=100, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=100, out_features=2, bias=True)
    (hw_output_layer_enc): Linear(in_features=256, out_features=100, bias=True)
    (hw_output_layer_dec): Linear(in_features=256, out_features=100, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58195794
2023-02-28 22:54:02,203 INFO Epoch 44 TRAIN info lr 4e-08
2023-02-28 22:54:02,205 INFO using accumulate grad, new batch size is 4 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=100, out_features=100, bias=True)
      (linear_k): Linear(in_features=100, out_features=100, bias=True)
      (linear_v): Linear(in_features=100, out_features=100, bias=True)
      (linear_out): Linear(in_features=100, out_features=100, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=100, out_features=2, bias=True)
    (hw_output_layer_enc): Linear(in_features=256, out_features=100, bias=True)
    (hw_output_layer_dec): Linear(in_features=256, out_features=100, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58195794
2023-02-28 22:54:02,208 INFO Epoch 44 TRAIN info lr 4e-08
2023-02-28 22:54:02,210 INFO using accumulate grad, new batch size is 4 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=100, out_features=100, bias=True)
      (linear_k): Linear(in_features=100, out_features=100, bias=True)
      (linear_v): Linear(in_features=100, out_features=100, bias=True)
      (linear_out): Linear(in_features=100, out_features=100, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=100, out_features=2, bias=True)
    (hw_output_layer_enc): Linear(in_features=256, out_features=100, bias=True)
    (hw_output_layer_dec): Linear(in_features=256, out_features=100, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58195794
2023-02-28 22:54:02,278 INFO Epoch 44 TRAIN info lr 4e-08
2023-02-28 22:54:02,280 INFO using accumulate grad, new batch size is 4 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=100, out_features=100, bias=True)
      (linear_k): Linear(in_features=100, out_features=100, bias=True)
      (linear_v): Linear(in_features=100, out_features=100, bias=True)
      (linear_out): Linear(in_features=100, out_features=100, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=100, out_features=2, bias=True)
    (hw_output_layer_enc): Linear(in_features=256, out_features=100, bias=True)
    (hw_output_layer_dec): Linear(in_features=256, out_features=100, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58195794
2023-02-28 22:54:02,345 INFO Epoch 44 TRAIN info lr 4e-08
2023-02-28 22:54:02,348 INFO using accumulate grad, new batch size is 4 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=100, out_features=100, bias=True)
      (linear_k): Linear(in_features=100, out_features=100, bias=True)
      (linear_v): Linear(in_features=100, out_features=100, bias=True)
      (linear_out): Linear(in_features=100, out_features=100, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=100, out_features=2, bias=True)
    (hw_output_layer_enc): Linear(in_features=256, out_features=100, bias=True)
    (hw_output_layer_dec): Linear(in_features=256, out_features=100, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58195794
2023-02-28 22:54:02,354 INFO Epoch 44 TRAIN info lr 4e-08
2023-02-28 22:54:02,355 INFO using accumulate grad, new batch size is 4 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=100, out_features=100, bias=True)
      (linear_k): Linear(in_features=100, out_features=100, bias=True)
      (linear_v): Linear(in_features=100, out_features=100, bias=True)
      (linear_out): Linear(in_features=100, out_features=100, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=100, out_features=2, bias=True)
    (hw_output_layer_enc): Linear(in_features=256, out_features=100, bias=True)
    (hw_output_layer_dec): Linear(in_features=256, out_features=100, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58195794
2023-02-28 22:54:02,486 INFO Epoch 44 TRAIN info lr 4e-08
2023-02-28 22:54:02,490 INFO using accumulate grad, new batch size is 4 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=100, out_features=100, bias=True)
      (linear_k): Linear(in_features=100, out_features=100, bias=True)
      (linear_v): Linear(in_features=100, out_features=100, bias=True)
      (linear_out): Linear(in_features=100, out_features=100, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=100, out_features=2, bias=True)
    (hw_output_layer_enc): Linear(in_features=256, out_features=100, bias=True)
    (hw_output_layer_dec): Linear(in_features=256, out_features=100, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58195794
2023-02-28 22:54:02,532 INFO Epoch 44 TRAIN info lr 4e-08
2023-02-28 22:54:02,534 INFO using accumulate grad, new batch size is 4 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=100, out_features=100, bias=True)
      (linear_k): Linear(in_features=100, out_features=100, bias=True)
      (linear_v): Linear(in_features=100, out_features=100, bias=True)
      (linear_out): Linear(in_features=100, out_features=100, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=100, out_features=2, bias=True)
    (hw_output_layer_enc): Linear(in_features=256, out_features=100, bias=True)
    (hw_output_layer_dec): Linear(in_features=256, out_features=100, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58195794
2023-02-28 22:55:04,183 DEBUG TRAIN Batch 44/0 loss 5.928945 loss_att 5.774279 loss_ctc 10.164678 loss_rnnt 4.984973 hw_loss 0.769015 lr 0.00029907 rank 0
2023-02-28 22:55:04,199 DEBUG TRAIN Batch 44/0 loss 9.604799 loss_att 9.591997 loss_ctc 13.420361 loss_rnnt 8.661156 hw_loss 0.820241 lr 0.00029907 rank 5
2023-02-28 22:55:04,201 DEBUG TRAIN Batch 44/0 loss 8.576131 loss_att 8.854004 loss_ctc 13.981318 loss_rnnt 7.377331 hw_loss 0.792249 lr 0.00029907 rank 6
2023-02-28 22:55:04,206 DEBUG TRAIN Batch 44/0 loss 5.861270 loss_att 6.098452 loss_ctc 8.495058 loss_rnnt 5.034477 hw_loss 0.802846 lr 0.00029907 rank 2
2023-02-28 22:55:04,207 DEBUG TRAIN Batch 44/0 loss 7.022789 loss_att 6.756894 loss_ctc 9.692987 loss_rnnt 6.289558 hw_loss 0.806969 lr 0.00029907 rank 4
2023-02-28 22:55:04,210 DEBUG TRAIN Batch 44/0 loss 7.795022 loss_att 6.925681 loss_ctc 9.870909 loss_rnnt 7.244522 hw_loss 0.839218 lr 0.00029907 rank 1
2023-02-28 22:55:04,245 DEBUG TRAIN Batch 44/0 loss 6.527721 loss_att 7.143015 loss_ctc 11.919342 loss_rnnt 5.247931 hw_loss 0.820967 lr 0.00029907 rank 3
2023-02-28 22:55:04,288 DEBUG TRAIN Batch 44/0 loss 9.582920 loss_att 9.601488 loss_ctc 14.104548 loss_rnnt 8.556713 hw_loss 0.786768 lr 0.00029907 rank 7
2023-02-28 22:55:44,384 DEBUG TRAIN Batch 44/100 loss 9.621107 loss_att 12.299061 loss_ctc 16.196192 loss_rnnt 8.107773 hw_loss 0.189498 lr 0.00029906 rank 1
2023-02-28 22:55:44,391 DEBUG TRAIN Batch 44/100 loss 4.452008 loss_att 7.349802 loss_ctc 8.128306 loss_rnnt 3.140681 hw_loss 0.452989 lr 0.00029906 rank 3
2023-02-28 22:55:44,391 DEBUG TRAIN Batch 44/100 loss 4.810158 loss_att 7.820691 loss_ctc 9.900178 loss_rnnt 3.367217 hw_loss 0.304059 lr 0.00029906 rank 4
2023-02-28 22:55:44,401 DEBUG TRAIN Batch 44/100 loss 11.331195 loss_att 13.533758 loss_ctc 18.600842 loss_rnnt 9.794868 hw_loss 0.237242 lr 0.00029906 rank 0
2023-02-28 22:55:44,403 DEBUG TRAIN Batch 44/100 loss 8.294857 loss_att 8.691354 loss_ctc 11.238869 loss_rnnt 7.526485 hw_loss 0.556007 lr 0.00029906 rank 7
2023-02-28 22:55:44,403 DEBUG TRAIN Batch 44/100 loss 2.230661 loss_att 7.181001 loss_ctc 5.440784 loss_rnnt 0.748212 hw_loss 0.120684 lr 0.00029906 rank 2
2023-02-28 22:55:44,407 DEBUG TRAIN Batch 44/100 loss 6.618785 loss_att 13.385986 loss_ctc 16.084690 loss_rnnt 3.782933 hw_loss 0.413046 lr 0.00029906 rank 6
2023-02-28 22:55:44,415 DEBUG TRAIN Batch 44/100 loss 9.654606 loss_att 14.340603 loss_ctc 24.241089 loss_rnnt 6.721381 hw_loss 0.095926 lr 0.00029906 rank 5
2023-02-28 22:56:23,877 DEBUG TRAIN Batch 44/200 loss 6.866387 loss_att 11.351225 loss_ctc 10.976813 loss_rnnt 5.336702 hw_loss 0.158736 lr 0.00029905 rank 1
2023-02-28 22:56:23,879 DEBUG TRAIN Batch 44/200 loss 10.843611 loss_att 13.937510 loss_ctc 16.862692 loss_rnnt 9.282013 hw_loss 0.263014 lr 0.00029905 rank 6
2023-02-28 22:56:23,887 DEBUG TRAIN Batch 44/200 loss 4.026466 loss_att 7.129450 loss_ctc 6.719383 loss_rnnt 2.935381 hw_loss 0.208936 lr 0.00029905 rank 2
2023-02-28 22:56:23,888 DEBUG TRAIN Batch 44/200 loss 1.619694 loss_att 3.990955 loss_ctc 2.827590 loss_rnnt 0.827382 hw_loss 0.294388 lr 0.00029905 rank 7
2023-02-28 22:56:23,889 DEBUG TRAIN Batch 44/200 loss 11.316492 loss_att 13.484859 loss_ctc 22.823217 loss_rnnt 9.223023 hw_loss 0.235434 lr 0.00029905 rank 5
2023-02-28 22:56:23,891 DEBUG TRAIN Batch 44/200 loss 3.587525 loss_att 6.874889 loss_ctc 5.067165 loss_rnnt 2.641093 hw_loss 0.171888 lr 0.00029905 rank 0
2023-02-28 22:56:23,892 DEBUG TRAIN Batch 44/200 loss 5.179803 loss_att 7.745202 loss_ctc 11.182882 loss_rnnt 3.797080 hw_loss 0.129812 lr 0.00029905 rank 3
2023-02-28 22:56:23,903 DEBUG TRAIN Batch 44/200 loss 6.170325 loss_att 10.358486 loss_ctc 12.989546 loss_rnnt 4.361269 hw_loss 0.116614 lr 0.00029905 rank 4
2023-02-28 22:57:02,728 DEBUG TRAIN Batch 44/300 loss 8.057211 loss_att 10.663677 loss_ctc 11.893927 loss_rnnt 6.807140 hw_loss 0.407279 lr 0.00029903 rank 6
2023-02-28 22:57:02,729 DEBUG TRAIN Batch 44/300 loss 3.036795 loss_att 7.053655 loss_ctc 6.323201 loss_rnnt 1.597449 hw_loss 0.370850 lr 0.00029903 rank 7
2023-02-28 22:57:02,734 DEBUG TRAIN Batch 44/300 loss 7.648332 loss_att 9.489146 loss_ctc 8.802662 loss_rnnt 6.982059 hw_loss 0.270371 lr 0.00029903 rank 5
2023-02-28 22:57:02,744 DEBUG TRAIN Batch 44/300 loss 8.689679 loss_att 11.433922 loss_ctc 12.409891 loss_rnnt 7.460368 hw_loss 0.345815 lr 0.00029903 rank 0
2023-02-28 22:57:02,753 DEBUG TRAIN Batch 44/300 loss 4.483916 loss_att 6.283948 loss_ctc 5.967325 loss_rnnt 3.717562 hw_loss 0.391048 lr 0.00029903 rank 4
2023-02-28 22:57:02,773 DEBUG TRAIN Batch 44/300 loss 6.201299 loss_att 11.312513 loss_ctc 14.131636 loss_rnnt 3.986621 hw_loss 0.253233 lr 0.00029903 rank 1
2023-02-28 22:57:02,782 DEBUG TRAIN Batch 44/300 loss 9.200729 loss_att 11.093023 loss_ctc 17.955126 loss_rnnt 7.498210 hw_loss 0.294016 lr 0.00029903 rank 3
2023-02-28 22:57:02,794 DEBUG TRAIN Batch 44/300 loss 18.873198 loss_att 21.150400 loss_ctc 28.920033 loss_rnnt 16.910370 hw_loss 0.314639 lr 0.00029903 rank 2
2023-02-28 22:58:05,666 DEBUG TRAIN Batch 44/400 loss 7.774082 loss_att 10.513559 loss_ctc 11.466109 loss_rnnt 6.579373 hw_loss 0.289770 lr 0.00029902 rank 3
2023-02-28 22:58:05,676 DEBUG TRAIN Batch 44/400 loss 5.305959 loss_att 8.596713 loss_ctc 11.451560 loss_rnnt 3.707312 hw_loss 0.227031 lr 0.00029902 rank 5
2023-02-28 22:58:05,677 DEBUG TRAIN Batch 44/400 loss 4.092047 loss_att 7.433843 loss_ctc 8.432777 loss_rnnt 2.645843 hw_loss 0.373277 lr 0.00029902 rank 2
2023-02-28 22:58:05,678 DEBUG TRAIN Batch 44/400 loss 10.553566 loss_att 13.622294 loss_ctc 16.332685 loss_rnnt 9.053237 hw_loss 0.217565 lr 0.00029902 rank 0
2023-02-28 22:58:05,677 DEBUG TRAIN Batch 44/400 loss 8.371078 loss_att 9.877848 loss_ctc 12.001125 loss_rnnt 7.425937 hw_loss 0.299592 lr 0.00029902 rank 7
2023-02-28 22:58:05,679 DEBUG TRAIN Batch 44/400 loss 9.446249 loss_att 9.935001 loss_ctc 10.644598 loss_rnnt 9.050967 hw_loss 0.258284 lr 0.00029902 rank 6
2023-02-28 22:58:05,685 DEBUG TRAIN Batch 44/400 loss 3.700349 loss_att 6.723277 loss_ctc 6.645113 loss_rnnt 2.588010 hw_loss 0.215846 lr 0.00029902 rank 1
2023-02-28 22:58:05,687 DEBUG TRAIN Batch 44/400 loss 7.886132 loss_att 9.928102 loss_ctc 14.791697 loss_rnnt 6.496117 hw_loss 0.114146 lr 0.00029902 rank 4
2023-02-28 22:58:44,180 DEBUG TRAIN Batch 44/500 loss 7.686284 loss_att 10.005486 loss_ctc 12.512933 loss_rnnt 6.472314 hw_loss 0.199831 lr 0.00029901 rank 3
2023-02-28 22:58:44,195 DEBUG TRAIN Batch 44/500 loss 4.776424 loss_att 8.976044 loss_ctc 9.352927 loss_rnnt 3.257208 hw_loss 0.129548 lr 0.00029901 rank 0
2023-02-28 22:58:44,195 DEBUG TRAIN Batch 44/500 loss 3.024367 loss_att 5.489645 loss_ctc 6.448509 loss_rnnt 1.993877 hw_loss 0.151654 lr 0.00029901 rank 2
2023-02-28 22:58:44,201 DEBUG TRAIN Batch 44/500 loss 3.923313 loss_att 5.210094 loss_ctc 6.557468 loss_rnnt 3.178787 hw_loss 0.254905 lr 0.00029901 rank 6
2023-02-28 22:58:44,201 DEBUG TRAIN Batch 44/500 loss 6.865713 loss_att 9.859743 loss_ctc 10.630994 loss_rnnt 5.595012 hw_loss 0.318485 lr 0.00029901 rank 4
2023-02-28 22:58:44,217 DEBUG TRAIN Batch 44/500 loss 10.470611 loss_att 13.368212 loss_ctc 19.839920 loss_rnnt 8.541222 hw_loss 0.188678 lr 0.00029901 rank 1
2023-02-28 22:58:44,232 DEBUG TRAIN Batch 44/500 loss 6.708538 loss_att 10.171276 loss_ctc 10.639170 loss_rnnt 5.296162 hw_loss 0.367020 lr 0.00029901 rank 7
2023-02-28 22:58:44,246 DEBUG TRAIN Batch 44/500 loss 3.065907 loss_att 6.227389 loss_ctc 6.469077 loss_rnnt 1.774498 hw_loss 0.385045 lr 0.00029901 rank 5
2023-02-28 22:59:23,026 DEBUG TRAIN Batch 44/600 loss 6.719479 loss_att 9.132488 loss_ctc 9.784415 loss_rnnt 5.661784 hw_loss 0.312064 lr 0.00029899 rank 0
2023-02-28 22:59:23,030 DEBUG TRAIN Batch 44/600 loss 6.433412 loss_att 8.022312 loss_ctc 10.255803 loss_rnnt 5.424207 hw_loss 0.340823 lr 0.00029899 rank 1
2023-02-28 22:59:23,031 DEBUG TRAIN Batch 44/600 loss 7.588291 loss_att 8.621717 loss_ctc 12.813036 loss_rnnt 6.546599 hw_loss 0.259451 lr 0.00029899 rank 6
2023-02-28 22:59:23,035 DEBUG TRAIN Batch 44/600 loss 14.765518 loss_att 14.632423 loss_ctc 21.587259 loss_rnnt 13.662965 hw_loss 0.411763 lr 0.00029899 rank 5
2023-02-28 22:59:23,035 DEBUG TRAIN Batch 44/600 loss 7.000075 loss_att 7.757088 loss_ctc 10.930568 loss_rnnt 6.060571 hw_loss 0.495068 lr 0.00029899 rank 7
2023-02-28 22:59:23,035 DEBUG TRAIN Batch 44/600 loss 7.369582 loss_att 8.306219 loss_ctc 12.431872 loss_rnnt 6.380238 hw_loss 0.238209 lr 0.00029899 rank 2
2023-02-28 22:59:23,039 DEBUG TRAIN Batch 44/600 loss 7.667938 loss_att 7.750711 loss_ctc 11.620965 loss_rnnt 6.827407 hw_loss 0.556698 lr 0.00029899 rank 3
2023-02-28 22:59:23,042 DEBUG TRAIN Batch 44/600 loss 6.649758 loss_att 9.277506 loss_ctc 12.685542 loss_rnnt 5.194686 hw_loss 0.233909 lr 0.00029899 rank 4
2023-02-28 23:00:02,308 DEBUG TRAIN Batch 44/700 loss 2.825268 loss_att 5.127984 loss_ctc 3.120681 loss_rnnt 2.208045 hw_loss 0.219920 lr 0.00029898 rank 7
2023-02-28 23:00:02,308 DEBUG TRAIN Batch 44/700 loss 2.593510 loss_att 5.814846 loss_ctc 5.922710 loss_rnnt 1.259998 hw_loss 0.460033 lr 0.00029898 rank 4
2023-02-28 23:00:02,310 DEBUG TRAIN Batch 44/700 loss 4.066329 loss_att 6.552600 loss_ctc 5.231910 loss_rnnt 3.266137 hw_loss 0.276614 lr 0.00029898 rank 5
2023-02-28 23:00:02,319 DEBUG TRAIN Batch 44/700 loss 5.276948 loss_att 7.638785 loss_ctc 9.687774 loss_rnnt 3.987408 hw_loss 0.429492 lr 0.00029898 rank 3
2023-02-28 23:00:02,320 DEBUG TRAIN Batch 44/700 loss 12.354213 loss_att 15.821900 loss_ctc 22.191849 loss_rnnt 10.102764 hw_loss 0.461673 lr 0.00029898 rank 1
2023-02-28 23:00:02,323 DEBUG TRAIN Batch 44/700 loss 4.960471 loss_att 11.129408 loss_ctc 11.259453 loss_rnnt 2.786654 hw_loss 0.187810 lr 0.00029898 rank 6
2023-02-28 23:00:02,325 DEBUG TRAIN Batch 44/700 loss 3.117510 loss_att 6.429944 loss_ctc 3.630490 loss_rnnt 2.329486 hw_loss 0.107138 lr 0.00029898 rank 2
2023-02-28 23:00:02,329 DEBUG TRAIN Batch 44/700 loss 3.754718 loss_att 6.322306 loss_ctc 8.153148 loss_rnnt 2.476874 hw_loss 0.333503 lr 0.00029898 rank 0
2023-02-28 23:01:05,199 DEBUG TRAIN Batch 44/800 loss 10.168015 loss_att 13.758320 loss_ctc 15.041408 loss_rnnt 8.644886 hw_loss 0.291152 lr 0.00029897 rank 1
2023-02-28 23:01:05,200 DEBUG TRAIN Batch 44/800 loss 11.916155 loss_att 15.021684 loss_ctc 20.318457 loss_rnnt 10.080743 hw_loss 0.176245 lr 0.00029897 rank 7
2023-02-28 23:01:05,200 DEBUG TRAIN Batch 44/800 loss 12.224314 loss_att 13.152849 loss_ctc 18.111748 loss_rnnt 11.163198 hw_loss 0.169534 lr 0.00029897 rank 6
2023-02-28 23:01:05,200 DEBUG TRAIN Batch 44/800 loss 1.826082 loss_att 4.863895 loss_ctc 3.939848 loss_rnnt 0.846338 hw_loss 0.169398 lr 0.00029897 rank 3
2023-02-28 23:01:05,203 DEBUG TRAIN Batch 44/800 loss 5.397505 loss_att 6.179209 loss_ctc 5.965787 loss_rnnt 5.053506 hw_loss 0.209789 lr 0.00029897 rank 4
2023-02-28 23:01:05,213 DEBUG TRAIN Batch 44/800 loss 3.925946 loss_att 7.009271 loss_ctc 7.263064 loss_rnnt 2.703229 hw_loss 0.302068 lr 0.00029897 rank 2
2023-02-28 23:01:05,216 DEBUG TRAIN Batch 44/800 loss 11.597947 loss_att 14.152088 loss_ctc 23.043949 loss_rnnt 9.444455 hw_loss 0.218494 lr 0.00029897 rank 0
2023-02-28 23:01:05,230 DEBUG TRAIN Batch 44/800 loss 5.992454 loss_att 9.987396 loss_ctc 12.803721 loss_rnnt 4.204325 hw_loss 0.151822 lr 0.00029897 rank 5
2023-02-28 23:01:43,147 DEBUG TRAIN Batch 44/900 loss 8.982473 loss_att 12.236636 loss_ctc 16.926622 loss_rnnt 7.077286 hw_loss 0.365876 lr 0.00029895 rank 3
2023-02-28 23:01:43,160 DEBUG TRAIN Batch 44/900 loss 8.752844 loss_att 11.160601 loss_ctc 11.635420 loss_rnnt 7.689916 hw_loss 0.369436 lr 0.00029895 rank 0
2023-02-28 23:01:43,161 DEBUG TRAIN Batch 44/900 loss 8.592134 loss_att 14.935225 loss_ctc 16.775454 loss_rnnt 6.088711 hw_loss 0.269431 lr 0.00029895 rank 2
2023-02-28 23:01:43,161 DEBUG TRAIN Batch 44/900 loss 11.653346 loss_att 13.583797 loss_ctc 18.945103 loss_rnnt 10.142113 hw_loss 0.286705 lr 0.00029895 rank 7
2023-02-28 23:01:43,161 DEBUG TRAIN Batch 44/900 loss 4.911567 loss_att 8.275749 loss_ctc 10.793440 loss_rnnt 3.348857 hw_loss 0.198044 lr 0.00029895 rank 5
2023-02-28 23:01:43,163 DEBUG TRAIN Batch 44/900 loss 2.709333 loss_att 4.672338 loss_ctc 5.331545 loss_rnnt 1.888081 hw_loss 0.148168 lr 0.00029895 rank 1
2023-02-28 23:01:43,164 DEBUG TRAIN Batch 44/900 loss 7.557673 loss_att 11.652692 loss_ctc 13.618052 loss_rnnt 5.767858 hw_loss 0.305176 lr 0.00029895 rank 6
2023-02-28 23:01:43,166 DEBUG TRAIN Batch 44/900 loss 6.004467 loss_att 9.443753 loss_ctc 11.327991 loss_rnnt 4.544979 hw_loss 0.115927 lr 0.00029895 rank 4
2023-02-28 23:02:21,443 DEBUG TRAIN Batch 44/1000 loss 7.585780 loss_att 9.858575 loss_ctc 12.244322 loss_rnnt 6.349932 hw_loss 0.300281 lr 0.00029894 rank 6
2023-02-28 23:02:21,445 DEBUG TRAIN Batch 44/1000 loss 3.087594 loss_att 7.546541 loss_ctc 5.718006 loss_rnnt 1.781612 hw_loss 0.119007 lr 0.00029894 rank 2
2023-02-28 23:02:21,453 DEBUG TRAIN Batch 44/1000 loss 2.952086 loss_att 5.771862 loss_ctc 5.285436 loss_rnnt 1.966558 hw_loss 0.207111 lr 0.00029894 rank 3
2023-02-28 23:02:21,463 DEBUG TRAIN Batch 44/1000 loss 9.013430 loss_att 13.464374 loss_ctc 15.898947 loss_rnnt 7.063782 hw_loss 0.265107 lr 0.00029894 rank 5
2023-02-28 23:02:21,464 DEBUG TRAIN Batch 44/1000 loss 6.718746 loss_att 8.610928 loss_ctc 8.719507 loss_rnnt 5.917235 hw_loss 0.293075 lr 0.00029894 rank 4
2023-02-28 23:02:21,467 DEBUG TRAIN Batch 44/1000 loss 4.102443 loss_att 6.566536 loss_ctc 8.585797 loss_rnnt 2.841645 hw_loss 0.319121 lr 0.00029894 rank 7
2023-02-28 23:02:21,467 DEBUG TRAIN Batch 44/1000 loss 7.315670 loss_att 10.888948 loss_ctc 14.623753 loss_rnnt 5.472074 hw_loss 0.289744 lr 0.00029894 rank 0
2023-02-28 23:02:21,477 DEBUG TRAIN Batch 44/1000 loss 11.247520 loss_att 13.310431 loss_ctc 15.582735 loss_rnnt 10.091913 hw_loss 0.309366 lr 0.00029894 rank 1
2023-02-28 23:03:25,450 DEBUG TRAIN Batch 44/1100 loss 5.560225 loss_att 6.021102 loss_ctc 6.291584 loss_rnnt 5.286160 hw_loss 0.158204 lr 0.00029893 rank 1
2023-02-28 23:03:25,453 DEBUG TRAIN Batch 44/1100 loss 3.385811 loss_att 6.901328 loss_ctc 6.841761 loss_rnnt 2.035358 hw_loss 0.349794 lr 0.00029893 rank 3
2023-02-28 23:03:25,454 DEBUG TRAIN Batch 44/1100 loss 7.749860 loss_att 10.407369 loss_ctc 9.946152 loss_rnnt 6.750763 hw_loss 0.327668 lr 0.00029893 rank 0
2023-02-28 23:03:25,456 DEBUG TRAIN Batch 44/1100 loss 11.223888 loss_att 14.986802 loss_ctc 21.454044 loss_rnnt 8.963313 hw_loss 0.269946 lr 0.00029893 rank 2
2023-02-28 23:03:25,461 DEBUG TRAIN Batch 44/1100 loss 4.327017 loss_att 8.210436 loss_ctc 10.039881 loss_rnnt 2.552501 hw_loss 0.442718 lr 0.00029893 rank 5
2023-02-28 23:03:25,463 DEBUG TRAIN Batch 44/1100 loss 13.952230 loss_att 17.202524 loss_ctc 20.840967 loss_rnnt 12.304166 hw_loss 0.149076 lr 0.00029893 rank 4
2023-02-28 23:03:25,471 DEBUG TRAIN Batch 44/1100 loss 9.388602 loss_att 12.769669 loss_ctc 16.446613 loss_rnnt 7.624404 hw_loss 0.275468 lr 0.00029893 rank 6
2023-02-28 23:03:25,506 DEBUG TRAIN Batch 44/1100 loss 3.089097 loss_att 5.644852 loss_ctc 5.154469 loss_rnnt 2.104181 hw_loss 0.371966 lr 0.00029893 rank 7
2023-02-28 23:04:03,790 DEBUG TRAIN Batch 44/1200 loss 7.803995 loss_att 9.446523 loss_ctc 13.863304 loss_rnnt 6.507600 hw_loss 0.299965 lr 0.00029891 rank 7
2023-02-28 23:04:03,802 DEBUG TRAIN Batch 44/1200 loss 6.081498 loss_att 8.409497 loss_ctc 10.195574 loss_rnnt 4.869434 hw_loss 0.371102 lr 0.00029891 rank 2
2023-02-28 23:04:03,803 DEBUG TRAIN Batch 44/1200 loss 5.022842 loss_att 7.457400 loss_ctc 8.618453 loss_rnnt 3.910650 hw_loss 0.273499 lr 0.00029891 rank 0
2023-02-28 23:04:03,803 DEBUG TRAIN Batch 44/1200 loss 4.912453 loss_att 6.630060 loss_ctc 7.776918 loss_rnnt 4.032785 hw_loss 0.289159 lr 0.00029891 rank 5
2023-02-28 23:04:03,805 DEBUG TRAIN Batch 44/1200 loss 5.699450 loss_att 9.276157 loss_ctc 10.385735 loss_rnnt 4.159560 hw_loss 0.374457 lr 0.00029891 rank 1
2023-02-28 23:04:03,811 DEBUG TRAIN Batch 44/1200 loss 10.193769 loss_att 11.633248 loss_ctc 15.303899 loss_rnnt 9.003446 hw_loss 0.414518 lr 0.00029891 rank 6
2023-02-28 23:04:03,812 DEBUG TRAIN Batch 44/1200 loss 4.606302 loss_att 5.259210 loss_ctc 6.037925 loss_rnnt 4.045619 hw_loss 0.448534 lr 0.00029891 rank 3
2023-02-28 23:04:03,852 DEBUG TRAIN Batch 44/1200 loss 5.638962 loss_att 8.236067 loss_ctc 9.838523 loss_rnnt 4.382463 hw_loss 0.332131 lr 0.00029891 rank 4
2023-02-28 23:04:42,332 DEBUG TRAIN Batch 44/1300 loss 7.101266 loss_att 13.093328 loss_ctc 13.250758 loss_rnnt 4.881877 hw_loss 0.376958 lr 0.00029890 rank 1
2023-02-28 23:04:42,341 DEBUG TRAIN Batch 44/1300 loss 4.639590 loss_att 8.700157 loss_ctc 9.844171 loss_rnnt 3.003218 hw_loss 0.244341 lr 0.00029890 rank 6
2023-02-28 23:04:42,342 DEBUG TRAIN Batch 44/1300 loss 2.227434 loss_att 5.126680 loss_ctc 3.497933 loss_rnnt 1.307764 hw_loss 0.319538 lr 0.00029890 rank 3
2023-02-28 23:04:42,346 DEBUG TRAIN Batch 44/1300 loss 9.008018 loss_att 8.247340 loss_ctc 12.227717 loss_rnnt 8.528128 hw_loss 0.380123 lr 0.00029890 rank 0
2023-02-28 23:04:42,350 DEBUG TRAIN Batch 44/1300 loss 12.222827 loss_att 14.806664 loss_ctc 19.535288 loss_rnnt 10.627956 hw_loss 0.193329 lr 0.00029890 rank 2
2023-02-28 23:04:42,354 DEBUG TRAIN Batch 44/1300 loss 1.448822 loss_att 5.191459 loss_ctc 3.744995 loss_rnnt 0.316884 hw_loss 0.144853 lr 0.00029890 rank 7
2023-02-28 23:04:42,356 DEBUG TRAIN Batch 44/1300 loss 6.234701 loss_att 10.788691 loss_ctc 11.441978 loss_rnnt 4.391333 hw_loss 0.446749 lr 0.00029890 rank 5
2023-02-28 23:04:42,359 DEBUG TRAIN Batch 44/1300 loss 5.920287 loss_att 8.725309 loss_ctc 10.039188 loss_rnnt 4.691113 hw_loss 0.223091 lr 0.00029890 rank 4
2023-02-28 23:05:21,504 DEBUG TRAIN Batch 44/1400 loss 6.278624 loss_att 14.414347 loss_ctc 13.046661 loss_rnnt 3.623592 hw_loss 0.235278 lr 0.00029889 rank 7
2023-02-28 23:05:21,506 DEBUG TRAIN Batch 44/1400 loss 10.288863 loss_att 12.430352 loss_ctc 15.141673 loss_rnnt 9.147112 hw_loss 0.124524 lr 0.00029889 rank 5
2023-02-28 23:05:21,509 DEBUG TRAIN Batch 44/1400 loss 8.634340 loss_att 12.285385 loss_ctc 13.917566 loss_rnnt 7.180154 hw_loss 0.036650 lr 0.00029889 rank 1
2023-02-28 23:05:21,518 DEBUG TRAIN Batch 44/1400 loss 3.349807 loss_att 7.428015 loss_ctc 8.661375 loss_rnnt 1.806409 hw_loss 0.036652 lr 0.00029889 rank 4
2023-02-28 23:05:21,519 DEBUG TRAIN Batch 44/1400 loss 5.680456 loss_att 9.369033 loss_ctc 11.283028 loss_rnnt 4.146314 hw_loss 0.092656 lr 0.00029889 rank 3
2023-02-28 23:05:21,521 DEBUG TRAIN Batch 44/1400 loss 7.540912 loss_att 7.455081 loss_ctc 5.717818 loss_rnnt 7.606597 hw_loss 0.364801 lr 0.00029889 rank 0
2023-02-28 23:05:21,524 DEBUG TRAIN Batch 44/1400 loss 11.289523 loss_att 13.995781 loss_ctc 17.077948 loss_rnnt 9.856920 hw_loss 0.224178 lr 0.00029889 rank 2
2023-02-28 23:05:21,529 DEBUG TRAIN Batch 44/1400 loss 4.101195 loss_att 6.179134 loss_ctc 4.335989 loss_rnnt 3.472841 hw_loss 0.340237 lr 0.00029889 rank 6
2023-02-28 23:06:23,926 DEBUG TRAIN Batch 44/1500 loss 2.037838 loss_att 4.673100 loss_ctc 4.981144 loss_rnnt 0.911833 hw_loss 0.387210 lr 0.00029887 rank 5
2023-02-28 23:06:23,927 DEBUG TRAIN Batch 44/1500 loss 4.258261 loss_att 6.697252 loss_ctc 4.116356 loss_rnnt 3.688823 hw_loss 0.188548 lr 0.00029887 rank 7
2023-02-28 23:06:23,930 DEBUG TRAIN Batch 44/1500 loss 4.237197 loss_att 6.920981 loss_ctc 5.605452 loss_rnnt 3.423890 hw_loss 0.176470 lr 0.00029887 rank 6
2023-02-28 23:06:23,932 DEBUG TRAIN Batch 44/1500 loss 2.369450 loss_att 3.957377 loss_ctc 3.612194 loss_rnnt 1.652929 hw_loss 0.437319 lr 0.00029887 rank 3
2023-02-28 23:06:23,944 DEBUG TRAIN Batch 44/1500 loss 4.748301 loss_att 7.333558 loss_ctc 7.986415 loss_rnnt 3.745795 hw_loss 0.100699 lr 0.00029887 rank 0
2023-02-28 23:06:23,946 DEBUG TRAIN Batch 44/1500 loss 2.614165 loss_att 4.648611 loss_ctc 5.354906 loss_rnnt 1.682025 hw_loss 0.299662 lr 0.00029887 rank 2
2023-02-28 23:06:23,955 DEBUG TRAIN Batch 44/1500 loss 7.443759 loss_att 10.191037 loss_ctc 10.853267 loss_rnnt 6.347154 hw_loss 0.173529 lr 0.00029887 rank 4
2023-02-28 23:06:23,970 DEBUG TRAIN Batch 44/1500 loss 3.895139 loss_att 6.721342 loss_ctc 7.593946 loss_rnnt 2.697239 hw_loss 0.261534 lr 0.00029887 rank 1
2023-02-28 23:07:01,841 DEBUG TRAIN Batch 44/1600 loss 5.766884 loss_att 7.839111 loss_ctc 7.787326 loss_rnnt 4.966512 hw_loss 0.218501 lr 0.00029886 rank 6
2023-02-28 23:07:01,845 DEBUG TRAIN Batch 44/1600 loss 4.545285 loss_att 7.188845 loss_ctc 7.230857 loss_rnnt 3.559013 hw_loss 0.186534 lr 0.00029886 rank 5
2023-02-28 23:07:01,854 DEBUG TRAIN Batch 44/1600 loss 5.717513 loss_att 8.339366 loss_ctc 9.538155 loss_rnnt 4.567528 hw_loss 0.217867 lr 0.00029886 rank 0
2023-02-28 23:07:01,855 DEBUG TRAIN Batch 44/1600 loss 3.225279 loss_att 5.881493 loss_ctc 5.304032 loss_rnnt 2.327697 hw_loss 0.167197 lr 0.00029886 rank 7
2023-02-28 23:07:01,856 DEBUG TRAIN Batch 44/1600 loss 6.922673 loss_att 10.300005 loss_ctc 10.619615 loss_rnnt 5.622150 hw_loss 0.247745 lr 0.00029886 rank 2
2023-02-28 23:07:01,857 DEBUG TRAIN Batch 44/1600 loss 6.580130 loss_att 9.190205 loss_ctc 12.907049 loss_rnnt 5.121749 hw_loss 0.173956 lr 0.00029886 rank 1
2023-02-28 23:07:01,865 DEBUG TRAIN Batch 44/1600 loss 15.790752 loss_att 23.730768 loss_ctc 32.043987 loss_rnnt 11.983963 hw_loss 0.096915 lr 0.00029886 rank 3
2023-02-28 23:07:01,865 DEBUG TRAIN Batch 44/1600 loss 3.106584 loss_att 6.444250 loss_ctc 6.129271 loss_rnnt 1.910103 hw_loss 0.236105 lr 0.00029886 rank 4
2023-02-28 23:07:40,367 DEBUG TRAIN Batch 44/1700 loss 6.479269 loss_att 9.456910 loss_ctc 10.375706 loss_rnnt 5.307624 hw_loss 0.106109 lr 0.00029885 rank 4
2023-02-28 23:07:40,377 DEBUG TRAIN Batch 44/1700 loss 7.267669 loss_att 9.780697 loss_ctc 10.832429 loss_rnnt 6.136275 hw_loss 0.287787 lr 0.00029885 rank 3
2023-02-28 23:07:40,385 DEBUG TRAIN Batch 44/1700 loss 2.071420 loss_att 4.972172 loss_ctc 4.281545 loss_rnnt 1.019982 hw_loss 0.331132 lr 0.00029885 rank 0
2023-02-28 23:07:40,387 DEBUG TRAIN Batch 44/1700 loss 7.315986 loss_att 10.311735 loss_ctc 14.407635 loss_rnnt 5.603024 hw_loss 0.315483 lr 0.00029885 rank 2
2023-02-28 23:07:40,387 DEBUG TRAIN Batch 44/1700 loss 3.545563 loss_att 6.878673 loss_ctc 6.310496 loss_rnnt 2.400796 hw_loss 0.205287 lr 0.00029885 rank 1
2023-02-28 23:07:40,407 DEBUG TRAIN Batch 44/1700 loss 5.437258 loss_att 8.071072 loss_ctc 7.492617 loss_rnnt 4.419137 hw_loss 0.407457 lr 0.00029885 rank 6
2023-02-28 23:07:40,417 DEBUG TRAIN Batch 44/1700 loss 6.418077 loss_att 11.831450 loss_ctc 13.239915 loss_rnnt 4.296074 hw_loss 0.243280 lr 0.00029885 rank 7
2023-02-28 23:07:40,420 DEBUG TRAIN Batch 44/1700 loss 8.164668 loss_att 12.013558 loss_ctc 14.979919 loss_rnnt 6.309929 hw_loss 0.330490 lr 0.00029885 rank 5
2023-02-28 23:08:45,733 DEBUG TRAIN Batch 44/1800 loss 5.706733 loss_att 7.223049 loss_ctc 11.780104 loss_rnnt 4.352891 hw_loss 0.451494 lr 0.00029883 rank 6
2023-02-28 23:08:45,735 DEBUG TRAIN Batch 44/1800 loss 11.710662 loss_att 13.156749 loss_ctc 19.093723 loss_rnnt 10.197868 hw_loss 0.448438 lr 0.00029883 rank 7
2023-02-28 23:08:45,736 DEBUG TRAIN Batch 44/1800 loss 3.481359 loss_att 6.540472 loss_ctc 4.100291 loss_rnnt 2.720293 hw_loss 0.125100 lr 0.00029883 rank 2
2023-02-28 23:08:45,737 DEBUG TRAIN Batch 44/1800 loss 6.075222 loss_att 7.599513 loss_ctc 9.175152 loss_rnnt 5.261383 hw_loss 0.179355 lr 0.00029883 rank 0
2023-02-28 23:08:45,737 DEBUG TRAIN Batch 44/1800 loss 9.487419 loss_att 12.420912 loss_ctc 20.049044 loss_rnnt 7.321443 hw_loss 0.320737 lr 0.00029883 rank 1
2023-02-28 23:08:45,739 DEBUG TRAIN Batch 44/1800 loss 8.920938 loss_att 9.770036 loss_ctc 11.880617 loss_rnnt 8.200251 hw_loss 0.292957 lr 0.00029883 rank 3
2023-02-28 23:08:45,742 DEBUG TRAIN Batch 44/1800 loss 3.116608 loss_att 4.802280 loss_ctc 6.366204 loss_rnnt 2.201165 hw_loss 0.271930 lr 0.00029883 rank 5
2023-02-28 23:08:45,742 DEBUG TRAIN Batch 44/1800 loss 4.289654 loss_att 6.929015 loss_ctc 5.818302 loss_rnnt 3.438289 hw_loss 0.224386 lr 0.00029883 rank 4
2023-02-28 23:09:24,229 DEBUG TRAIN Batch 44/1900 loss 8.743198 loss_att 10.874023 loss_ctc 14.565485 loss_rnnt 7.386211 hw_loss 0.289720 lr 0.00029882 rank 5
2023-02-28 23:09:24,232 DEBUG TRAIN Batch 44/1900 loss 9.401692 loss_att 13.121134 loss_ctc 15.025274 loss_rnnt 7.722032 hw_loss 0.348678 lr 0.00029882 rank 6
2023-02-28 23:09:24,244 DEBUG TRAIN Batch 44/1900 loss 7.269195 loss_att 8.024780 loss_ctc 9.878200 loss_rnnt 6.549552 hw_loss 0.413734 lr 0.00029882 rank 2
2023-02-28 23:09:24,245 DEBUG TRAIN Batch 44/1900 loss 3.524311 loss_att 4.479696 loss_ctc 6.756634 loss_rnnt 2.635711 hw_loss 0.499776 lr 0.00029882 rank 0
2023-02-28 23:09:24,246 DEBUG TRAIN Batch 44/1900 loss 9.741522 loss_att 12.785936 loss_ctc 15.929294 loss_rnnt 8.116905 hw_loss 0.357555 lr 0.00029882 rank 4
2023-02-28 23:09:24,247 DEBUG TRAIN Batch 44/1900 loss 10.199284 loss_att 11.173977 loss_ctc 16.590279 loss_rnnt 8.992357 hw_loss 0.299727 lr 0.00029882 rank 1
2023-02-28 23:09:24,254 DEBUG TRAIN Batch 44/1900 loss 8.389198 loss_att 10.647737 loss_ctc 15.403641 loss_rnnt 6.915046 hw_loss 0.163473 lr 0.00029882 rank 7
2023-02-28 23:09:24,294 DEBUG TRAIN Batch 44/1900 loss 3.930360 loss_att 6.906925 loss_ctc 5.795444 loss_rnnt 2.914737 hw_loss 0.321810 lr 0.00029882 rank 3
2023-02-28 23:10:01,929 DEBUG TRAIN Batch 44/2000 loss 5.625010 loss_att 7.514139 loss_ctc 6.821503 loss_rnnt 5.024274 hw_loss 0.118835 lr 0.00029881 rank 7
2023-02-28 23:10:01,931 DEBUG TRAIN Batch 44/2000 loss 11.242574 loss_att 12.464684 loss_ctc 20.391348 loss_rnnt 9.643231 hw_loss 0.253282 lr 0.00029881 rank 2
2023-02-28 23:10:01,932 DEBUG TRAIN Batch 44/2000 loss 2.472558 loss_att 5.036363 loss_ctc 5.427183 loss_rnnt 1.471537 hw_loss 0.176831 lr 0.00029881 rank 0
2023-02-28 23:10:01,933 DEBUG TRAIN Batch 44/2000 loss 5.488223 loss_att 9.337078 loss_ctc 8.586471 loss_rnnt 4.286228 hw_loss 0.035858 lr 0.00029881 rank 6
2023-02-28 23:10:01,935 DEBUG TRAIN Batch 44/2000 loss 6.709718 loss_att 8.020929 loss_ctc 7.659711 loss_rnnt 6.206020 hw_loss 0.215230 lr 0.00029881 rank 1
2023-02-28 23:10:01,935 DEBUG TRAIN Batch 44/2000 loss 2.905174 loss_att 5.706649 loss_ctc 10.229805 loss_rnnt 1.214829 hw_loss 0.287686 lr 0.00029881 rank 4
2023-02-28 23:10:01,938 DEBUG TRAIN Batch 44/2000 loss 2.686295 loss_att 5.871735 loss_ctc 6.306110 loss_rnnt 1.503529 hw_loss 0.118193 lr 0.00029881 rank 5
2023-02-28 23:10:01,939 DEBUG TRAIN Batch 44/2000 loss 6.678394 loss_att 12.280445 loss_ctc 10.088589 loss_rnnt 5.013412 hw_loss 0.168523 lr 0.00029881 rank 3
2023-02-28 23:10:41,663 DEBUG TRAIN Batch 44/2100 loss 7.891155 loss_att 10.980078 loss_ctc 12.104881 loss_rnnt 6.649414 hw_loss 0.116486 lr 0.00029879 rank 1
2023-02-28 23:10:41,670 DEBUG TRAIN Batch 44/2100 loss 3.607039 loss_att 5.839649 loss_ctc 6.573704 loss_rnnt 2.707531 hw_loss 0.107684 lr 0.00029879 rank 6
2023-02-28 23:10:41,677 DEBUG TRAIN Batch 44/2100 loss 4.904675 loss_att 8.167425 loss_ctc 9.387691 loss_rnnt 3.523764 hw_loss 0.244923 lr 0.00029879 rank 7
2023-02-28 23:10:41,678 DEBUG TRAIN Batch 44/2100 loss 9.423048 loss_att 12.635842 loss_ctc 13.636772 loss_rnnt 8.072082 hw_loss 0.274835 lr 0.00029879 rank 4
2023-02-28 23:10:41,680 DEBUG TRAIN Batch 44/2100 loss 4.293742 loss_att 7.551048 loss_ctc 8.382957 loss_rnnt 2.940158 hw_loss 0.294176 lr 0.00029879 rank 0
2023-02-28 23:10:41,681 DEBUG TRAIN Batch 44/2100 loss 2.697259 loss_att 5.398631 loss_ctc 7.577711 loss_rnnt 1.389714 hw_loss 0.218520 lr 0.00029879 rank 5
2023-02-28 23:10:41,682 DEBUG TRAIN Batch 44/2100 loss 4.615574 loss_att 6.293845 loss_ctc 5.486843 loss_rnnt 3.978595 hw_loss 0.347168 lr 0.00029879 rank 3
2023-02-28 23:10:41,682 DEBUG TRAIN Batch 44/2100 loss 1.325371 loss_att 3.330876 loss_ctc 1.306088 loss_rnnt 0.775413 hw_loss 0.283929 lr 0.00029879 rank 2
2023-02-28 23:11:45,375 DEBUG TRAIN Batch 44/2200 loss 6.952619 loss_att 7.668281 loss_ctc 9.309631 loss_rnnt 6.391519 hw_loss 0.194437 lr 0.00029878 rank 5
2023-02-28 23:11:45,376 DEBUG TRAIN Batch 44/2200 loss 10.882026 loss_att 16.258205 loss_ctc 19.282940 loss_rnnt 8.590694 hw_loss 0.179949 lr 0.00029878 rank 6
2023-02-28 23:11:45,391 DEBUG TRAIN Batch 44/2200 loss 4.198378 loss_att 6.120162 loss_ctc 7.679115 loss_rnnt 3.116516 hw_loss 0.437638 lr 0.00029878 rank 2
2023-02-28 23:11:45,393 DEBUG TRAIN Batch 44/2200 loss 2.048840 loss_att 4.381628 loss_ctc 3.128000 loss_rnnt 1.285971 hw_loss 0.285794 lr 0.00029878 rank 0
2023-02-28 23:11:45,395 DEBUG TRAIN Batch 44/2200 loss 4.360908 loss_att 7.367647 loss_ctc 8.096444 loss_rnnt 3.171940 hw_loss 0.167902 lr 0.00029878 rank 1
2023-02-28 23:11:45,394 DEBUG TRAIN Batch 44/2200 loss 9.965133 loss_att 13.770414 loss_ctc 13.058825 loss_rnnt 8.668113 hw_loss 0.231508 lr 0.00029878 rank 3
2023-02-28 23:11:45,401 DEBUG TRAIN Batch 44/2200 loss 5.121946 loss_att 7.136770 loss_ctc 11.699772 loss_rnnt 3.696484 hw_loss 0.272725 lr 0.00029878 rank 4
2023-02-28 23:11:45,413 DEBUG TRAIN Batch 44/2200 loss 11.890173 loss_att 17.575668 loss_ctc 19.380686 loss_rnnt 9.609701 hw_loss 0.271194 lr 0.00029878 rank 7
2023-02-28 23:12:23,752 DEBUG TRAIN Batch 44/2300 loss 5.660093 loss_att 10.393922 loss_ctc 8.736409 loss_rnnt 4.126417 hw_loss 0.331377 lr 0.00029877 rank 4
2023-02-28 23:12:23,764 DEBUG TRAIN Batch 44/2300 loss 15.439462 loss_att 17.133621 loss_ctc 31.209576 loss_rnnt 12.825982 hw_loss 0.322434 lr 0.00029877 rank 7
2023-02-28 23:12:23,765 DEBUG TRAIN Batch 44/2300 loss 8.689495 loss_att 11.664897 loss_ctc 12.820501 loss_rnnt 7.381330 hw_loss 0.304281 lr 0.00029877 rank 0
2023-02-28 23:12:23,771 DEBUG TRAIN Batch 44/2300 loss 8.378263 loss_att 12.393875 loss_ctc 14.775963 loss_rnnt 6.529826 hw_loss 0.360540 lr 0.00029877 rank 2
2023-02-28 23:12:23,772 DEBUG TRAIN Batch 44/2300 loss 2.417207 loss_att 4.921951 loss_ctc 4.729555 loss_rnnt 1.418491 hw_loss 0.355226 lr 0.00029877 rank 6
2023-02-28 23:12:23,774 DEBUG TRAIN Batch 44/2300 loss 8.670807 loss_att 14.079034 loss_ctc 13.777577 loss_rnnt 6.748116 hw_loss 0.300266 lr 0.00029877 rank 5
2023-02-28 23:12:23,776 DEBUG TRAIN Batch 44/2300 loss 6.083788 loss_att 9.207598 loss_ctc 15.102053 loss_rnnt 4.117269 hw_loss 0.261230 lr 0.00029877 rank 3
2023-02-28 23:12:23,778 DEBUG TRAIN Batch 44/2300 loss 4.572441 loss_att 6.712771 loss_ctc 5.613306 loss_rnnt 3.851627 hw_loss 0.288685 lr 0.00029877 rank 1
2023-02-28 23:13:02,074 DEBUG TRAIN Batch 44/2400 loss 9.446780 loss_att 9.878775 loss_ctc 12.777685 loss_rnnt 8.784241 hw_loss 0.247538 lr 0.00029875 rank 1
2023-02-28 23:13:02,075 DEBUG TRAIN Batch 44/2400 loss 3.500705 loss_att 6.432650 loss_ctc 5.762366 loss_rnnt 2.454940 hw_loss 0.295914 lr 0.00029875 rank 5
2023-02-28 23:13:02,089 DEBUG TRAIN Batch 44/2400 loss 8.351899 loss_att 14.407606 loss_ctc 18.411200 loss_rnnt 5.679029 hw_loss 0.225914 lr 0.00029875 rank 0
2023-02-28 23:13:02,089 DEBUG TRAIN Batch 44/2400 loss 6.278856 loss_att 9.084340 loss_ctc 10.525793 loss_rnnt 5.045916 hw_loss 0.197973 lr 0.00029875 rank 7
2023-02-28 23:13:02,089 DEBUG TRAIN Batch 44/2400 loss 5.387337 loss_att 6.942214 loss_ctc 7.480165 loss_rnnt 4.584001 hw_loss 0.399969 lr 0.00029875 rank 4
2023-02-28 23:13:02,089 DEBUG TRAIN Batch 44/2400 loss 4.145705 loss_att 5.458660 loss_ctc 8.587972 loss_rnnt 3.093365 hw_loss 0.370213 lr 0.00029875 rank 6
2023-02-28 23:13:02,089 DEBUG TRAIN Batch 44/2400 loss 7.287057 loss_att 9.054955 loss_ctc 10.255917 loss_rnnt 6.408864 hw_loss 0.241435 lr 0.00029875 rank 3
2023-02-28 23:13:02,098 DEBUG TRAIN Batch 44/2400 loss 7.576837 loss_att 9.287849 loss_ctc 16.271091 loss_rnnt 5.932419 hw_loss 0.268090 lr 0.00029875 rank 2
2023-02-28 23:14:08,385 DEBUG TRAIN Batch 44/2500 loss 5.803282 loss_att 9.061327 loss_ctc 10.835441 loss_rnnt 4.259075 hw_loss 0.415580 lr 0.00029874 rank 6
2023-02-28 23:14:08,395 DEBUG TRAIN Batch 44/2500 loss 3.127501 loss_att 5.458926 loss_ctc 5.204146 loss_rnnt 2.225657 hw_loss 0.297511 lr 0.00029874 rank 1
2023-02-28 23:14:08,398 DEBUG TRAIN Batch 44/2500 loss 2.875015 loss_att 3.756935 loss_ctc 3.251831 loss_rnnt 2.366735 hw_loss 0.528100 lr 0.00029874 rank 2
2023-02-28 23:14:08,399 DEBUG TRAIN Batch 44/2500 loss 4.960830 loss_att 6.631906 loss_ctc 8.130920 loss_rnnt 3.988147 hw_loss 0.404604 lr 0.00029874 rank 5
2023-02-28 23:14:08,400 DEBUG TRAIN Batch 44/2500 loss 8.391005 loss_att 10.755466 loss_ctc 12.957718 loss_rnnt 7.180614 hw_loss 0.241128 lr 0.00029874 rank 0
2023-02-28 23:14:08,402 DEBUG TRAIN Batch 44/2500 loss 7.887827 loss_att 10.388020 loss_ctc 14.070718 loss_rnnt 6.378873 hw_loss 0.345995 lr 0.00029874 rank 3
2023-02-28 23:14:08,406 DEBUG TRAIN Batch 44/2500 loss 3.867739 loss_att 7.102365 loss_ctc 8.298601 loss_rnnt 2.484394 hw_loss 0.273072 lr 0.00029874 rank 7
2023-02-28 23:14:08,409 DEBUG TRAIN Batch 44/2500 loss 6.042551 loss_att 6.355724 loss_ctc 9.748287 loss_rnnt 5.277895 hw_loss 0.389855 lr 0.00029874 rank 4
2023-02-28 23:14:46,589 DEBUG TRAIN Batch 44/2600 loss 2.856908 loss_att 5.317071 loss_ctc 3.691908 loss_rnnt 2.097218 hw_loss 0.293109 lr 0.00029873 rank 4
2023-02-28 23:14:46,608 DEBUG TRAIN Batch 44/2600 loss 5.512741 loss_att 8.994868 loss_ctc 9.913227 loss_rnnt 4.080687 hw_loss 0.279182 lr 0.00029873 rank 7
2023-02-28 23:14:46,610 DEBUG TRAIN Batch 44/2600 loss 2.451652 loss_att 6.467102 loss_ctc 3.659103 loss_rnnt 1.283821 hw_loss 0.382027 lr 0.00029873 rank 6
2023-02-28 23:14:46,611 DEBUG TRAIN Batch 44/2600 loss 3.584282 loss_att 8.044138 loss_ctc 5.949195 loss_rnnt 2.236207 hw_loss 0.263966 lr 0.00029873 rank 3
2023-02-28 23:14:46,613 DEBUG TRAIN Batch 44/2600 loss 9.702074 loss_att 13.062083 loss_ctc 14.157587 loss_rnnt 8.352459 hw_loss 0.156646 lr 0.00029873 rank 1
2023-02-28 23:14:46,614 DEBUG TRAIN Batch 44/2600 loss 4.795942 loss_att 8.861163 loss_ctc 13.339705 loss_rnnt 2.709380 hw_loss 0.251907 lr 0.00029873 rank 0
2023-02-28 23:14:46,615 DEBUG TRAIN Batch 44/2600 loss 11.134440 loss_att 12.590843 loss_ctc 17.168243 loss_rnnt 9.894527 hw_loss 0.270235 lr 0.00029873 rank 2
2023-02-28 23:14:46,624 DEBUG TRAIN Batch 44/2600 loss 6.079066 loss_att 11.036140 loss_ctc 9.420033 loss_rnnt 4.488204 hw_loss 0.288722 lr 0.00029873 rank 5
2023-02-28 23:15:24,840 DEBUG TRAIN Batch 44/2700 loss 5.743353 loss_att 8.158379 loss_ctc 9.598768 loss_rnnt 4.687293 hw_loss 0.110623 lr 0.00029871 rank 0
2023-02-28 23:15:24,852 DEBUG TRAIN Batch 44/2700 loss 4.864825 loss_att 6.987164 loss_ctc 8.509293 loss_rnnt 3.724228 hw_loss 0.431624 lr 0.00029871 rank 2
2023-02-28 23:15:24,866 DEBUG TRAIN Batch 44/2700 loss 7.216850 loss_att 12.320208 loss_ctc 14.272499 loss_rnnt 5.091239 hw_loss 0.307849 lr 0.00029871 rank 7
2023-02-28 23:15:24,867 DEBUG TRAIN Batch 44/2700 loss 5.203872 loss_att 7.093055 loss_ctc 5.521710 loss_rnnt 4.634176 hw_loss 0.280276 lr 0.00029871 rank 1
2023-02-28 23:15:24,873 DEBUG TRAIN Batch 44/2700 loss 9.084410 loss_att 10.793248 loss_ctc 12.093356 loss_rnnt 8.297336 hw_loss 0.082711 lr 0.00029871 rank 4
2023-02-28 23:15:24,875 DEBUG TRAIN Batch 44/2700 loss 2.895222 loss_att 5.429679 loss_ctc 7.572002 loss_rnnt 1.489225 hw_loss 0.516627 lr 0.00029871 rank 3
2023-02-28 23:15:24,877 DEBUG TRAIN Batch 44/2700 loss 5.293417 loss_att 11.180797 loss_ctc 9.533564 loss_rnnt 3.366379 hw_loss 0.345390 lr 0.00029871 rank 5
2023-02-28 23:15:24,922 DEBUG TRAIN Batch 44/2700 loss 4.826206 loss_att 6.821589 loss_ctc 7.890063 loss_rnnt 3.842826 hw_loss 0.329605 lr 0.00029871 rank 6
2023-02-28 23:16:04,371 DEBUG TRAIN Batch 44/2800 loss 9.768709 loss_att 11.122047 loss_ctc 15.612979 loss_rnnt 8.547209 hw_loss 0.321745 lr 0.00029870 rank 1
2023-02-28 23:16:04,392 DEBUG TRAIN Batch 44/2800 loss 7.632347 loss_att 11.792219 loss_ctc 9.434218 loss_rnnt 6.544708 hw_loss 0.028904 lr 0.00029870 rank 0
2023-02-28 23:16:04,394 DEBUG TRAIN Batch 44/2800 loss 4.190709 loss_att 7.053939 loss_ctc 12.065172 loss_rnnt 2.445204 hw_loss 0.230494 lr 0.00029870 rank 3
2023-02-28 23:16:04,394 DEBUG TRAIN Batch 44/2800 loss 3.234939 loss_att 6.010811 loss_ctc 5.885281 loss_rnnt 2.239165 hw_loss 0.163538 lr 0.00029870 rank 2
2023-02-28 23:16:04,397 DEBUG TRAIN Batch 44/2800 loss 2.782416 loss_att 6.010830 loss_ctc 4.018589 loss_rnnt 1.807289 hw_loss 0.308664 lr 0.00029870 rank 7
2023-02-28 23:16:04,398 DEBUG TRAIN Batch 44/2800 loss 8.928264 loss_att 11.736927 loss_ctc 14.091085 loss_rnnt 7.544526 hw_loss 0.250552 lr 0.00029870 rank 6
2023-02-28 23:16:04,405 DEBUG TRAIN Batch 44/2800 loss 5.946911 loss_att 8.045517 loss_ctc 10.128948 loss_rnnt 4.888035 hw_loss 0.152908 lr 0.00029870 rank 5
2023-02-28 23:16:04,412 DEBUG TRAIN Batch 44/2800 loss 4.991148 loss_att 9.302952 loss_ctc 9.999333 loss_rnnt 3.305316 hw_loss 0.291962 lr 0.00029870 rank 4
2023-02-28 23:17:09,170 DEBUG TRAIN Batch 44/2900 loss 7.445633 loss_att 10.843815 loss_ctc 15.213956 loss_rnnt 5.488985 hw_loss 0.452317 lr 0.00029869 rank 7
2023-02-28 23:17:09,172 DEBUG TRAIN Batch 44/2900 loss 9.591294 loss_att 14.156707 loss_ctc 16.990990 loss_rnnt 7.557986 hw_loss 0.250498 lr 0.00029869 rank 2
2023-02-28 23:17:09,181 DEBUG TRAIN Batch 44/2900 loss 9.053753 loss_att 15.152449 loss_ctc 19.129587 loss_rnnt 6.345110 hw_loss 0.272734 lr 0.00029869 rank 0
2023-02-28 23:17:09,194 DEBUG TRAIN Batch 44/2900 loss 5.996517 loss_att 7.419756 loss_ctc 9.788906 loss_rnnt 5.041134 hw_loss 0.309532 lr 0.00029869 rank 1
2023-02-28 23:17:09,194 DEBUG TRAIN Batch 44/2900 loss 7.669856 loss_att 11.631747 loss_ctc 13.873208 loss_rnnt 5.943652 hw_loss 0.200084 lr 0.00029869 rank 3
2023-02-28 23:17:09,196 DEBUG TRAIN Batch 44/2900 loss 9.401920 loss_att 11.456038 loss_ctc 16.030199 loss_rnnt 7.884144 hw_loss 0.418467 lr 0.00029869 rank 5
2023-02-28 23:17:09,200 DEBUG TRAIN Batch 44/2900 loss 5.959599 loss_att 10.087982 loss_ctc 11.288988 loss_rnnt 4.363747 hw_loss 0.111732 lr 0.00029869 rank 4
2023-02-28 23:17:09,211 DEBUG TRAIN Batch 44/2900 loss 1.639815 loss_att 4.304273 loss_ctc 3.908723 loss_rnnt 0.758018 hw_loss 0.086971 lr 0.00029869 rank 6
2023-02-28 23:17:48,164 DEBUG TRAIN Batch 44/3000 loss 8.559125 loss_att 9.601002 loss_ctc 13.475397 loss_rnnt 7.631824 hw_loss 0.118916 lr 0.00029867 rank 7
2023-02-28 23:17:48,169 DEBUG TRAIN Batch 44/3000 loss 7.125546 loss_att 8.716895 loss_ctc 13.115822 loss_rnnt 5.766458 hw_loss 0.453966 lr 0.00029867 rank 5
2023-02-28 23:17:48,172 DEBUG TRAIN Batch 44/3000 loss 9.418168 loss_att 12.654152 loss_ctc 14.202422 loss_rnnt 7.976849 hw_loss 0.292917 lr 0.00029867 rank 4
2023-02-28 23:17:48,183 DEBUG TRAIN Batch 44/3000 loss 3.878888 loss_att 6.365108 loss_ctc 6.842415 loss_rnnt 2.917578 hw_loss 0.129244 lr 0.00029867 rank 2
2023-02-28 23:17:48,183 DEBUG TRAIN Batch 44/3000 loss 5.790227 loss_att 11.575735 loss_ctc 11.227331 loss_rnnt 3.728259 hw_loss 0.337348 lr 0.00029867 rank 1
2023-02-28 23:17:48,188 DEBUG TRAIN Batch 44/3000 loss 4.674576 loss_att 7.133786 loss_ctc 8.987604 loss_rnnt 3.473804 hw_loss 0.250987 lr 0.00029867 rank 0
2023-02-28 23:17:48,194 DEBUG TRAIN Batch 44/3000 loss 6.707891 loss_att 8.804899 loss_ctc 10.619186 loss_rnnt 5.692535 hw_loss 0.139588 lr 0.00029867 rank 3
2023-02-28 23:17:48,239 DEBUG TRAIN Batch 44/3000 loss 10.861754 loss_att 14.154315 loss_ctc 18.612284 loss_rnnt 8.967151 hw_loss 0.380042 lr 0.00029867 rank 6
2023-02-28 23:18:27,186 DEBUG TRAIN Batch 44/3100 loss 6.699738 loss_att 6.855978 loss_ctc 10.489964 loss_rnnt 5.919414 hw_loss 0.456960 lr 0.00029866 rank 6
2023-02-28 23:18:27,199 DEBUG TRAIN Batch 44/3100 loss 8.276978 loss_att 12.533455 loss_ctc 17.361465 loss_rnnt 6.128625 hw_loss 0.160859 lr 0.00029866 rank 0
2023-02-28 23:18:27,200 DEBUG TRAIN Batch 44/3100 loss 6.306169 loss_att 9.554614 loss_ctc 10.421817 loss_rnnt 4.966840 hw_loss 0.264161 lr 0.00029866 rank 1
2023-02-28 23:18:27,203 DEBUG TRAIN Batch 44/3100 loss 6.139629 loss_att 7.044568 loss_ctc 10.509916 loss_rnnt 5.293295 hw_loss 0.154952 lr 0.00029866 rank 5
2023-02-28 23:18:27,204 DEBUG TRAIN Batch 44/3100 loss 8.213204 loss_att 10.544667 loss_ctc 15.023632 loss_rnnt 6.667357 hw_loss 0.321558 lr 0.00029866 rank 4
2023-02-28 23:18:27,206 DEBUG TRAIN Batch 44/3100 loss 5.623321 loss_att 8.215301 loss_ctc 8.661758 loss_rnnt 4.543908 hw_loss 0.292298 lr 0.00029866 rank 2
2023-02-28 23:18:27,206 DEBUG TRAIN Batch 44/3100 loss 3.659209 loss_att 6.909282 loss_ctc 7.011391 loss_rnnt 2.335891 hw_loss 0.424397 lr 0.00029866 rank 3
2023-02-28 23:18:27,240 DEBUG TRAIN Batch 44/3100 loss 11.137813 loss_att 13.091724 loss_ctc 17.045940 loss_rnnt 9.810611 hw_loss 0.278757 lr 0.00029866 rank 7
2023-02-28 23:19:29,061 DEBUG TRAIN Batch 44/3200 loss 6.050059 loss_att 9.962601 loss_ctc 14.973174 loss_rnnt 3.992776 hw_loss 0.159424 lr 0.00029865 rank 6
2023-02-28 23:19:29,070 DEBUG TRAIN Batch 44/3200 loss 8.670142 loss_att 11.738923 loss_ctc 16.988625 loss_rnnt 6.792362 hw_loss 0.290425 lr 0.00029865 rank 0
2023-02-28 23:19:29,071 DEBUG TRAIN Batch 44/3200 loss 5.683291 loss_att 9.336514 loss_ctc 9.273462 loss_rnnt 4.459205 hw_loss 0.027663 lr 0.00029865 rank 2
2023-02-28 23:19:29,072 DEBUG TRAIN Batch 44/3200 loss 9.495361 loss_att 13.614092 loss_ctc 14.243515 loss_rnnt 7.925855 hw_loss 0.211263 lr 0.00029865 rank 4
2023-02-28 23:19:29,073 DEBUG TRAIN Batch 44/3200 loss 8.513905 loss_att 9.952799 loss_ctc 13.250084 loss_rnnt 7.468068 hw_loss 0.237312 lr 0.00029865 rank 3
2023-02-28 23:19:29,083 DEBUG TRAIN Batch 44/3200 loss 13.301699 loss_att 16.030420 loss_ctc 19.190001 loss_rnnt 11.803513 hw_loss 0.313755 lr 0.00029865 rank 1
2023-02-28 23:19:29,100 DEBUG TRAIN Batch 44/3200 loss 5.947064 loss_att 8.380961 loss_ctc 7.387971 loss_rnnt 5.121676 hw_loss 0.274665 lr 0.00029865 rank 5
2023-02-28 23:19:29,127 DEBUG TRAIN Batch 44/3200 loss 5.541296 loss_att 11.176316 loss_ctc 12.794459 loss_rnnt 3.318911 hw_loss 0.240550 lr 0.00029865 rank 7
2023-02-28 23:20:11,478 DEBUG TRAIN Batch 44/3300 loss 6.181224 loss_att 9.540514 loss_ctc 8.370730 loss_rnnt 5.019429 hw_loss 0.371256 lr 0.00029863 rank 5
2023-02-28 23:20:11,492 DEBUG TRAIN Batch 44/3300 loss 4.615359 loss_att 8.599315 loss_ctc 7.213064 loss_rnnt 3.364493 hw_loss 0.201964 lr 0.00029863 rank 0
2023-02-28 23:20:11,493 DEBUG TRAIN Batch 44/3300 loss 5.874172 loss_att 8.836145 loss_ctc 8.931383 loss_rnnt 4.640309 hw_loss 0.438450 lr 0.00029863 rank 6
2023-02-28 23:20:11,493 DEBUG TRAIN Batch 44/3300 loss 2.442397 loss_att 5.694060 loss_ctc 5.382423 loss_rnnt 1.232432 hw_loss 0.314303 lr 0.00029863 rank 1
2023-02-28 23:20:11,495 DEBUG TRAIN Batch 44/3300 loss 8.270866 loss_att 11.439871 loss_ctc 12.454844 loss_rnnt 7.004097 hw_loss 0.140822 lr 0.00029863 rank 3
2023-02-28 23:20:11,494 DEBUG TRAIN Batch 44/3300 loss 5.767096 loss_att 8.071294 loss_ctc 9.715443 loss_rnnt 4.597338 hw_loss 0.342135 lr 0.00029863 rank 4
2023-02-28 23:20:11,495 DEBUG TRAIN Batch 44/3300 loss 10.164850 loss_att 12.695891 loss_ctc 20.297199 loss_rnnt 8.203602 hw_loss 0.195113 lr 0.00029863 rank 7
2023-02-28 23:20:11,496 DEBUG TRAIN Batch 44/3300 loss 6.188543 loss_att 7.902566 loss_ctc 9.842792 loss_rnnt 5.267334 hw_loss 0.170949 lr 0.00029863 rank 2
2023-02-28 23:20:50,105 DEBUG TRAIN Batch 44/3400 loss 2.876127 loss_att 7.240278 loss_ctc 4.053263 loss_rnnt 1.692231 hw_loss 0.288964 lr 0.00029862 rank 7
2023-02-28 23:20:50,107 DEBUG TRAIN Batch 44/3400 loss 1.954079 loss_att 4.261278 loss_ctc 3.171774 loss_rnnt 1.217451 hw_loss 0.211553 lr 0.00029862 rank 2
2023-02-28 23:20:50,107 DEBUG TRAIN Batch 44/3400 loss 5.337548 loss_att 7.959526 loss_ctc 9.594954 loss_rnnt 4.135137 hw_loss 0.206927 lr 0.00029862 rank 6
2023-02-28 23:20:50,109 DEBUG TRAIN Batch 44/3400 loss 6.490450 loss_att 8.648817 loss_ctc 9.389114 loss_rnnt 5.493745 hw_loss 0.334767 lr 0.00029862 rank 0
2023-02-28 23:20:50,111 DEBUG TRAIN Batch 44/3400 loss 9.295226 loss_att 11.765882 loss_ctc 15.195288 loss_rnnt 7.836888 hw_loss 0.332869 lr 0.00029862 rank 4
2023-02-28 23:20:50,114 DEBUG TRAIN Batch 44/3400 loss 6.030371 loss_att 8.807203 loss_ctc 12.552699 loss_rnnt 4.465510 hw_loss 0.262220 lr 0.00029862 rank 3
2023-02-28 23:20:50,137 DEBUG TRAIN Batch 44/3400 loss 6.741103 loss_att 9.599743 loss_ctc 12.303886 loss_rnnt 5.359603 hw_loss 0.127627 lr 0.00029862 rank 1
2023-02-28 23:20:50,145 DEBUG TRAIN Batch 44/3400 loss 7.831903 loss_att 10.537566 loss_ctc 18.859697 loss_rnnt 5.616088 hw_loss 0.383081 lr 0.00029862 rank 5
2023-02-28 23:21:29,089 DEBUG TRAIN Batch 44/3500 loss 17.457052 loss_att 20.644274 loss_ctc 34.779968 loss_rnnt 14.380178 hw_loss 0.243201 lr 0.00029861 rank 7
2023-02-28 23:21:29,092 DEBUG TRAIN Batch 44/3500 loss 7.906341 loss_att 12.498631 loss_ctc 16.300251 loss_rnnt 5.766548 hw_loss 0.191526 lr 0.00029861 rank 6
2023-02-28 23:21:29,098 DEBUG TRAIN Batch 44/3500 loss 5.850860 loss_att 9.796709 loss_ctc 7.930057 loss_rnnt 4.630525 hw_loss 0.288635 lr 0.00029861 rank 2
2023-02-28 23:21:29,105 DEBUG TRAIN Batch 44/3500 loss 8.273954 loss_att 10.758696 loss_ctc 12.686580 loss_rnnt 7.012340 hw_loss 0.330593 lr 0.00029861 rank 1
2023-02-28 23:21:29,107 DEBUG TRAIN Batch 44/3500 loss 6.931992 loss_att 8.874159 loss_ctc 10.028341 loss_rnnt 6.023876 hw_loss 0.200317 lr 0.00029861 rank 0
2023-02-28 23:21:29,122 DEBUG TRAIN Batch 44/3500 loss 7.521621 loss_att 8.502308 loss_ctc 8.974489 loss_rnnt 6.984266 hw_loss 0.276566 lr 0.00029861 rank 3
2023-02-28 23:21:29,129 DEBUG TRAIN Batch 44/3500 loss 8.288910 loss_att 11.697724 loss_ctc 13.568970 loss_rnnt 6.769021 hw_loss 0.251471 lr 0.00029861 rank 5
2023-02-28 23:21:29,135 DEBUG TRAIN Batch 44/3500 loss 8.632591 loss_att 10.996758 loss_ctc 13.609219 loss_rnnt 7.409266 hw_loss 0.163014 lr 0.00029861 rank 4
2023-02-28 23:22:33,589 DEBUG TRAIN Batch 44/3600 loss 4.626295 loss_att 8.920981 loss_ctc 8.580223 loss_rnnt 3.151408 hw_loss 0.166422 lr 0.00029859 rank 5
2023-02-28 23:22:33,590 DEBUG TRAIN Batch 44/3600 loss 6.230642 loss_att 8.782733 loss_ctc 13.299854 loss_rnnt 4.711596 hw_loss 0.123874 lr 0.00029859 rank 3
2023-02-28 23:22:33,595 DEBUG TRAIN Batch 44/3600 loss 6.848536 loss_att 10.826692 loss_ctc 11.252544 loss_rnnt 5.306590 hw_loss 0.298338 lr 0.00029859 rank 1
2023-02-28 23:22:33,597 DEBUG TRAIN Batch 44/3600 loss 11.862701 loss_att 13.623868 loss_ctc 15.561327 loss_rnnt 10.902357 hw_loss 0.215554 lr 0.00029859 rank 2
2023-02-28 23:22:33,600 DEBUG TRAIN Batch 44/3600 loss 4.366105 loss_att 6.903641 loss_ctc 5.602879 loss_rnnt 3.517376 hw_loss 0.330596 lr 0.00029859 rank 4
2023-02-28 23:22:33,600 DEBUG TRAIN Batch 44/3600 loss 11.764931 loss_att 16.537041 loss_ctc 17.630993 loss_rnnt 9.992776 hw_loss 0.066730 lr 0.00029859 rank 0
2023-02-28 23:22:33,601 DEBUG TRAIN Batch 44/3600 loss 5.420339 loss_att 8.144133 loss_ctc 7.442974 loss_rnnt 4.540449 hw_loss 0.122711 lr 0.00029859 rank 6
2023-02-28 23:22:33,643 DEBUG TRAIN Batch 44/3600 loss 4.384221 loss_att 5.349084 loss_ctc 4.522119 loss_rnnt 4.027341 hw_loss 0.272851 lr 0.00029859 rank 7
2023-02-28 23:23:12,703 DEBUG TRAIN Batch 44/3700 loss 0.951337 loss_att 2.764024 loss_ctc 1.664143 loss_rnnt 0.364286 hw_loss 0.242761 lr 0.00029858 rank 7
2023-02-28 23:23:12,704 DEBUG TRAIN Batch 44/3700 loss 8.081815 loss_att 11.134174 loss_ctc 13.646947 loss_rnnt 6.510958 hw_loss 0.409438 lr 0.00029858 rank 5
2023-02-28 23:23:12,706 DEBUG TRAIN Batch 44/3700 loss 7.465251 loss_att 8.237145 loss_ctc 9.354686 loss_rnnt 6.893454 hw_loss 0.310302 lr 0.00029858 rank 0
2023-02-28 23:23:12,707 DEBUG TRAIN Batch 44/3700 loss 6.033618 loss_att 8.004503 loss_ctc 9.314748 loss_rnnt 5.058806 hw_loss 0.268407 lr 0.00029858 rank 2
2023-02-28 23:23:12,707 DEBUG TRAIN Batch 44/3700 loss 15.413608 loss_att 19.989571 loss_ctc 25.600904 loss_rnnt 13.027809 hw_loss 0.210558 lr 0.00029858 rank 4
2023-02-28 23:23:12,709 DEBUG TRAIN Batch 44/3700 loss 2.668330 loss_att 7.070079 loss_ctc 3.069398 loss_rnnt 1.593030 hw_loss 0.265264 lr 0.00029858 rank 6
2023-02-28 23:23:12,715 DEBUG TRAIN Batch 44/3700 loss 4.096559 loss_att 6.293430 loss_ctc 8.397720 loss_rnnt 2.937091 hw_loss 0.274885 lr 0.00029858 rank 3
2023-02-28 23:23:12,717 DEBUG TRAIN Batch 44/3700 loss 9.174905 loss_att 12.464849 loss_ctc 16.537165 loss_rnnt 7.440224 hw_loss 0.178233 lr 0.00029858 rank 1
2023-02-28 23:23:52,147 DEBUG TRAIN Batch 44/3800 loss 7.221281 loss_att 8.309586 loss_ctc 10.380539 loss_rnnt 6.410333 hw_loss 0.322598 lr 0.00029857 rank 4
2023-02-28 23:23:52,149 DEBUG TRAIN Batch 44/3800 loss 8.205398 loss_att 9.517534 loss_ctc 13.017423 loss_rnnt 7.063147 hw_loss 0.446663 lr 0.00029857 rank 0
2023-02-28 23:23:52,149 DEBUG TRAIN Batch 44/3800 loss 11.621711 loss_att 13.138182 loss_ctc 19.639212 loss_rnnt 10.049576 hw_loss 0.374700 lr 0.00029857 rank 7
2023-02-28 23:23:52,151 DEBUG TRAIN Batch 44/3800 loss 6.427034 loss_att 8.548632 loss_ctc 10.966599 loss_rnnt 5.232280 hw_loss 0.309674 lr 0.00029857 rank 2
2023-02-28 23:23:52,164 DEBUG TRAIN Batch 44/3800 loss 3.407119 loss_att 5.159089 loss_ctc 7.127080 loss_rnnt 2.405058 hw_loss 0.291884 lr 0.00029857 rank 3
2023-02-28 23:23:52,179 DEBUG TRAIN Batch 44/3800 loss 7.916899 loss_att 10.958662 loss_ctc 14.968593 loss_rnnt 6.238343 hw_loss 0.243707 lr 0.00029857 rank 1
2023-02-28 23:23:52,185 DEBUG TRAIN Batch 44/3800 loss 3.886443 loss_att 7.108182 loss_ctc 5.990274 loss_rnnt 2.782291 hw_loss 0.336176 lr 0.00029857 rank 6
2023-02-28 23:23:52,194 DEBUG TRAIN Batch 44/3800 loss 7.559488 loss_att 8.289827 loss_ctc 12.770644 loss_rnnt 6.419414 hw_loss 0.560973 lr 0.00029857 rank 5
2023-02-28 23:24:32,791 DEBUG TRAIN Batch 44/3900 loss 2.109190 loss_att 4.709746 loss_ctc 4.984991 loss_rnnt 1.014451 hw_loss 0.358476 lr 0.00029855 rank 1
2023-02-28 23:24:32,795 DEBUG TRAIN Batch 44/3900 loss 9.520101 loss_att 12.074848 loss_ctc 11.205053 loss_rnnt 8.629906 hw_loss 0.289847 lr 0.00029855 rank 7
2023-02-28 23:24:32,796 DEBUG TRAIN Batch 44/3900 loss 9.225005 loss_att 13.368845 loss_ctc 17.310078 loss_rnnt 7.149099 hw_loss 0.317119 lr 0.00029855 rank 5
2023-02-28 23:24:32,804 DEBUG TRAIN Batch 44/3900 loss 4.298252 loss_att 7.512455 loss_ctc 8.221103 loss_rnnt 3.017869 hw_loss 0.214680 lr 0.00029855 rank 6
2023-02-28 23:24:32,807 DEBUG TRAIN Batch 44/3900 loss 3.542308 loss_att 7.092865 loss_ctc 8.716215 loss_rnnt 2.078768 hw_loss 0.119202 lr 0.00029855 rank 0
2023-02-28 23:24:32,809 DEBUG TRAIN Batch 44/3900 loss 4.618188 loss_att 9.364385 loss_ctc 6.296184 loss_rnnt 3.382983 hw_loss 0.116687 lr 0.00029855 rank 3
2023-02-28 23:24:32,810 DEBUG TRAIN Batch 44/3900 loss 7.235907 loss_att 8.705791 loss_ctc 16.043118 loss_rnnt 5.642696 hw_loss 0.234261 lr 0.00029855 rank 2
2023-02-28 23:24:32,813 DEBUG TRAIN Batch 44/3900 loss 2.160430 loss_att 4.531544 loss_ctc 3.826249 loss_rnnt 1.319746 hw_loss 0.270659 lr 0.00029855 rank 4
2023-02-28 23:25:37,288 DEBUG TRAIN Batch 44/4000 loss 9.536548 loss_att 11.378369 loss_ctc 25.266760 loss_rnnt 6.934456 hw_loss 0.255686 lr 0.00029854 rank 5
2023-02-28 23:25:37,288 DEBUG TRAIN Batch 44/4000 loss 3.025763 loss_att 6.077589 loss_ctc 3.911246 loss_rnnt 2.137481 hw_loss 0.299722 lr 0.00029854 rank 7
2023-02-28 23:25:37,291 DEBUG TRAIN Batch 44/4000 loss 3.908331 loss_att 6.248477 loss_ctc 5.149215 loss_rnnt 3.107942 hw_loss 0.312955 lr 0.00029854 rank 1
2023-02-28 23:25:37,297 DEBUG TRAIN Batch 44/4000 loss 11.162253 loss_att 16.967316 loss_ctc 17.071074 loss_rnnt 9.054065 hw_loss 0.298750 lr 0.00029854 rank 4
2023-02-28 23:25:37,297 DEBUG TRAIN Batch 44/4000 loss 4.166341 loss_att 6.756187 loss_ctc 5.591144 loss_rnnt 3.341937 hw_loss 0.218363 lr 0.00029854 rank 6
2023-02-28 23:25:37,299 DEBUG TRAIN Batch 44/4000 loss 7.285940 loss_att 8.642302 loss_ctc 9.497789 loss_rnnt 6.615628 hw_loss 0.195235 lr 0.00029854 rank 3
2023-02-28 23:25:37,318 DEBUG TRAIN Batch 44/4000 loss 1.947951 loss_att 4.944248 loss_ctc 3.939024 loss_rnnt 0.917436 hw_loss 0.310835 lr 0.00029854 rank 0
2023-02-28 23:25:37,329 DEBUG TRAIN Batch 44/4000 loss 2.944042 loss_att 5.704532 loss_ctc 6.926066 loss_rnnt 1.697448 hw_loss 0.306672 lr 0.00029854 rank 2
2023-02-28 23:26:16,642 DEBUG TRAIN Batch 44/4100 loss 7.737593 loss_att 9.028290 loss_ctc 9.223085 loss_rnnt 7.078692 hw_loss 0.380055 lr 0.00029853 rank 0
2023-02-28 23:26:16,643 DEBUG TRAIN Batch 44/4100 loss 12.037271 loss_att 14.159328 loss_ctc 16.923201 loss_rnnt 10.863203 hw_loss 0.184123 lr 0.00029853 rank 4
2023-02-28 23:26:16,644 DEBUG TRAIN Batch 44/4100 loss 7.163399 loss_att 11.678515 loss_ctc 11.126987 loss_rnnt 5.653102 hw_loss 0.147741 lr 0.00029853 rank 2
2023-02-28 23:26:16,644 DEBUG TRAIN Batch 44/4100 loss 4.838082 loss_att 9.609976 loss_ctc 16.000349 loss_rnnt 2.252450 hw_loss 0.268032 lr 0.00029853 rank 1
2023-02-28 23:26:16,646 DEBUG TRAIN Batch 44/4100 loss 4.145158 loss_att 6.842479 loss_ctc 4.824499 loss_rnnt 3.382884 hw_loss 0.247934 lr 0.00029853 rank 6
2023-02-28 23:26:16,648 DEBUG TRAIN Batch 44/4100 loss 3.389250 loss_att 6.235248 loss_ctc 5.471317 loss_rnnt 2.424559 hw_loss 0.221029 lr 0.00029853 rank 3
2023-02-28 23:26:16,660 DEBUG TRAIN Batch 44/4100 loss 5.416687 loss_att 6.883275 loss_ctc 9.361132 loss_rnnt 4.408022 hw_loss 0.355162 lr 0.00029853 rank 5
2023-02-28 23:26:16,667 DEBUG TRAIN Batch 44/4100 loss 6.132765 loss_att 9.335771 loss_ctc 9.747283 loss_rnnt 4.850873 hw_loss 0.298791 lr 0.00029853 rank 7
2023-02-28 23:26:55,923 DEBUG TRAIN Batch 44/4200 loss 12.400432 loss_att 16.105202 loss_ctc 17.678024 loss_rnnt 10.761460 hw_loss 0.364385 lr 0.00029851 rank 6
2023-02-28 23:26:55,930 DEBUG TRAIN Batch 44/4200 loss 8.505960 loss_att 11.928879 loss_ctc 14.625139 loss_rnnt 6.908732 hw_loss 0.181413 lr 0.00029851 rank 5
2023-02-28 23:26:55,935 DEBUG TRAIN Batch 44/4200 loss 2.979661 loss_att 6.419981 loss_ctc 5.166691 loss_rnnt 1.919695 hw_loss 0.150560 lr 0.00029851 rank 3
2023-02-28 23:26:55,937 DEBUG TRAIN Batch 44/4200 loss 6.560153 loss_att 8.937727 loss_ctc 13.241053 loss_rnnt 5.134621 hw_loss 0.111057 lr 0.00029851 rank 7
2023-02-28 23:26:55,939 DEBUG TRAIN Batch 44/4200 loss 15.103404 loss_att 17.026775 loss_ctc 24.931583 loss_rnnt 13.291077 hw_loss 0.219805 lr 0.00029851 rank 0
2023-02-28 23:26:55,940 DEBUG TRAIN Batch 44/4200 loss 6.387890 loss_att 9.900868 loss_ctc 9.729935 loss_rnnt 5.118421 hw_loss 0.227376 lr 0.00029851 rank 4
2023-02-28 23:26:55,943 DEBUG TRAIN Batch 44/4200 loss 4.609857 loss_att 7.398968 loss_ctc 5.573408 loss_rnnt 3.641862 hw_loss 0.528187 lr 0.00029851 rank 2
2023-02-28 23:26:55,952 DEBUG TRAIN Batch 44/4200 loss 6.860984 loss_att 10.113466 loss_ctc 8.463766 loss_rnnt 5.873755 hw_loss 0.230680 lr 0.00029851 rank 1
2023-02-28 23:28:00,795 DEBUG TRAIN Batch 44/4300 loss 3.204075 loss_att 6.368448 loss_ctc 4.265404 loss_rnnt 2.305866 hw_loss 0.232168 lr 0.00029850 rank 7
2023-02-28 23:28:00,803 DEBUG TRAIN Batch 44/4300 loss 6.176972 loss_att 7.423510 loss_ctc 10.155390 loss_rnnt 5.154479 hw_loss 0.455120 lr 0.00029850 rank 6
2023-02-28 23:28:00,805 DEBUG TRAIN Batch 44/4300 loss 4.241927 loss_att 7.622822 loss_ctc 9.475584 loss_rnnt 2.697061 hw_loss 0.320374 lr 0.00029850 rank 0
2023-02-28 23:28:00,807 DEBUG TRAIN Batch 44/4300 loss 4.054523 loss_att 5.378529 loss_ctc 8.455664 loss_rnnt 3.088558 hw_loss 0.214400 lr 0.00029850 rank 4
2023-02-28 23:28:00,810 DEBUG TRAIN Batch 44/4300 loss 6.318300 loss_att 8.512123 loss_ctc 10.131353 loss_rnnt 5.114147 hw_loss 0.481840 lr 0.00029850 rank 5
2023-02-28 23:28:00,810 DEBUG TRAIN Batch 44/4300 loss 8.121788 loss_att 12.487661 loss_ctc 16.896551 loss_rnnt 5.928619 hw_loss 0.281297 lr 0.00029850 rank 2
2023-02-28 23:28:00,838 DEBUG TRAIN Batch 44/4300 loss 4.158726 loss_att 7.319095 loss_ctc 5.465263 loss_rnnt 3.232400 hw_loss 0.225089 lr 0.00029850 rank 1
2023-02-28 23:28:00,846 DEBUG TRAIN Batch 44/4300 loss 4.500607 loss_att 5.669143 loss_ctc 7.691994 loss_rnnt 3.670092 hw_loss 0.321167 lr 0.00029850 rank 3
2023-02-28 23:28:39,326 DEBUG TRAIN Batch 44/4400 loss 7.365757 loss_att 8.732565 loss_ctc 12.222979 loss_rnnt 6.305856 hw_loss 0.260456 lr 0.00029849 rank 0
2023-02-28 23:28:39,330 DEBUG TRAIN Batch 44/4400 loss 6.565934 loss_att 13.591780 loss_ctc 16.636190 loss_rnnt 3.642546 hw_loss 0.329096 lr 0.00029849 rank 1
2023-02-28 23:28:39,332 DEBUG TRAIN Batch 44/4400 loss 8.036051 loss_att 9.531595 loss_ctc 13.468879 loss_rnnt 6.814558 hw_loss 0.371264 lr 0.00029849 rank 2
2023-02-28 23:28:39,337 DEBUG TRAIN Batch 44/4400 loss 6.596367 loss_att 7.537810 loss_ctc 8.280617 loss_rnnt 6.012400 hw_loss 0.320836 lr 0.00029849 rank 5
2023-02-28 23:28:39,337 DEBUG TRAIN Batch 44/4400 loss 2.917908 loss_att 5.514465 loss_ctc 4.803337 loss_rnnt 2.000296 hw_loss 0.275457 lr 0.00029849 rank 4
2023-02-28 23:28:39,337 DEBUG TRAIN Batch 44/4400 loss 9.067706 loss_att 9.733420 loss_ctc 11.783204 loss_rnnt 8.335716 hw_loss 0.443964 lr 0.00029849 rank 7
2023-02-28 23:28:39,344 DEBUG TRAIN Batch 44/4400 loss 2.445051 loss_att 5.872826 loss_ctc 8.146587 loss_rnnt 0.907376 hw_loss 0.172340 lr 0.00029849 rank 3
2023-02-28 23:28:39,344 DEBUG TRAIN Batch 44/4400 loss 5.421594 loss_att 10.143277 loss_ctc 9.840754 loss_rnnt 3.788596 hw_loss 0.186449 lr 0.00029849 rank 6
2023-02-28 23:29:17,890 DEBUG TRAIN Batch 44/4500 loss 6.635297 loss_att 10.459854 loss_ctc 12.177357 loss_rnnt 5.004762 hw_loss 0.237530 lr 0.00029847 rank 0
2023-02-28 23:29:17,895 DEBUG TRAIN Batch 44/4500 loss 12.074994 loss_att 12.100790 loss_ctc 19.189545 loss_rnnt 10.925137 hw_loss 0.367671 lr 0.00029847 rank 7
2023-02-28 23:29:17,897 DEBUG TRAIN Batch 44/4500 loss 6.750675 loss_att 7.426386 loss_ctc 10.478200 loss_rnnt 5.916527 hw_loss 0.378753 lr 0.00029847 rank 1
2023-02-28 23:29:17,898 DEBUG TRAIN Batch 44/4500 loss 7.830965 loss_att 9.613732 loss_ctc 12.954359 loss_rnnt 6.606707 hw_loss 0.346096 lr 0.00029847 rank 5
2023-02-28 23:29:17,900 DEBUG TRAIN Batch 44/4500 loss 7.642550 loss_att 11.667037 loss_ctc 14.985538 loss_rnnt 5.663695 hw_loss 0.365423 lr 0.00029847 rank 4
2023-02-28 23:29:17,902 DEBUG TRAIN Batch 44/4500 loss 4.960986 loss_att 7.561395 loss_ctc 7.361359 loss_rnnt 4.016249 hw_loss 0.196136 lr 0.00029847 rank 3
2023-02-28 23:29:17,906 DEBUG TRAIN Batch 44/4500 loss 2.947256 loss_att 7.177185 loss_ctc 7.739404 loss_rnnt 1.336220 hw_loss 0.236432 lr 0.00029847 rank 2
2023-02-28 23:29:17,946 DEBUG TRAIN Batch 44/4500 loss 6.652236 loss_att 10.188300 loss_ctc 12.133785 loss_rnnt 5.085723 hw_loss 0.240801 lr 0.00029847 rank 6
2023-02-28 23:29:57,913 DEBUG TRAIN Batch 44/4600 loss 12.075969 loss_att 14.314027 loss_ctc 16.449516 loss_rnnt 10.897909 hw_loss 0.276202 lr 0.00029846 rank 7
2023-02-28 23:29:57,914 DEBUG TRAIN Batch 44/4600 loss 3.569635 loss_att 7.029078 loss_ctc 7.634050 loss_rnnt 2.263468 hw_loss 0.135668 lr 0.00029846 rank 6
2023-02-28 23:29:57,915 DEBUG TRAIN Batch 44/4600 loss 3.810004 loss_att 6.812013 loss_ctc 4.711662 loss_rnnt 2.954965 hw_loss 0.252032 lr 0.00029846 rank 1
2023-02-28 23:29:57,916 DEBUG TRAIN Batch 44/4600 loss 1.290547 loss_att 4.148008 loss_ctc 2.074254 loss_rnnt 0.500685 hw_loss 0.213517 lr 0.00029846 rank 4
2023-02-28 23:29:57,928 DEBUG TRAIN Batch 44/4600 loss 6.216398 loss_att 9.474997 loss_ctc 9.969058 loss_rnnt 4.901174 hw_loss 0.305906 lr 0.00029846 rank 2
2023-02-28 23:29:57,931 DEBUG TRAIN Batch 44/4600 loss 4.018264 loss_att 7.218960 loss_ctc 8.006940 loss_rnnt 2.697597 hw_loss 0.278821 lr 0.00029846 rank 0
2023-02-28 23:29:57,967 DEBUG TRAIN Batch 44/4600 loss 4.691874 loss_att 7.845135 loss_ctc 7.107083 loss_rnnt 3.617258 hw_loss 0.228629 lr 0.00029846 rank 3
2023-02-28 23:29:57,979 DEBUG TRAIN Batch 44/4600 loss 10.552844 loss_att 13.311548 loss_ctc 14.489010 loss_rnnt 9.377010 hw_loss 0.186130 lr 0.00029846 rank 5
2023-02-28 23:31:01,885 DEBUG TRAIN Batch 44/4700 loss 5.512428 loss_att 7.660677 loss_ctc 9.882610 loss_rnnt 4.295919 hw_loss 0.382815 lr 0.00029845 rank 5
2023-02-28 23:31:01,897 DEBUG TRAIN Batch 44/4700 loss 3.293578 loss_att 7.411482 loss_ctc 6.774721 loss_rnnt 1.818737 hw_loss 0.350828 lr 0.00029845 rank 1
2023-02-28 23:31:01,902 DEBUG TRAIN Batch 44/4700 loss 3.682895 loss_att 6.652495 loss_ctc 10.226107 loss_rnnt 2.015500 hw_loss 0.376963 lr 0.00029845 rank 2
2023-02-28 23:31:01,906 DEBUG TRAIN Batch 44/4700 loss 7.478029 loss_att 10.761944 loss_ctc 11.641489 loss_rnnt 6.093809 hw_loss 0.323079 lr 0.00029845 rank 0
2023-02-28 23:31:01,907 DEBUG TRAIN Batch 44/4700 loss 8.645863 loss_att 11.892928 loss_ctc 14.355252 loss_rnnt 7.155629 hw_loss 0.149190 lr 0.00029845 rank 6
2023-02-28 23:31:01,910 DEBUG TRAIN Batch 44/4700 loss 1.288610 loss_att 2.673433 loss_ctc 2.110857 loss_rnnt 0.786724 hw_loss 0.216166 lr 0.00029845 rank 4
2023-02-28 23:31:01,930 DEBUG TRAIN Batch 44/4700 loss 6.471402 loss_att 10.910984 loss_ctc 10.837517 loss_rnnt 4.955785 hw_loss 0.085410 lr 0.00029845 rank 7
2023-02-28 23:31:01,959 DEBUG TRAIN Batch 44/4700 loss 11.856961 loss_att 15.042589 loss_ctc 17.428274 loss_rnnt 10.331894 hw_loss 0.272062 lr 0.00029845 rank 3
2023-02-28 23:31:40,045 DEBUG TRAIN Batch 44/4800 loss 7.515504 loss_att 10.294205 loss_ctc 14.193511 loss_rnnt 5.929486 hw_loss 0.262268 lr 0.00029843 rank 2
2023-02-28 23:31:40,048 DEBUG TRAIN Batch 44/4800 loss 1.873005 loss_att 3.896554 loss_ctc 2.925692 loss_rnnt 1.262461 hw_loss 0.122769 lr 0.00029843 rank 1
2023-02-28 23:31:40,056 DEBUG TRAIN Batch 44/4800 loss 7.105572 loss_att 9.065766 loss_ctc 11.373716 loss_rnnt 5.940344 hw_loss 0.382694 lr 0.00029843 rank 7
2023-02-28 23:31:40,060 DEBUG TRAIN Batch 44/4800 loss 5.631081 loss_att 7.430347 loss_ctc 11.468803 loss_rnnt 4.313829 hw_loss 0.335690 lr 0.00029843 rank 3
2023-02-28 23:31:40,062 DEBUG TRAIN Batch 44/4800 loss 2.979664 loss_att 5.648395 loss_ctc 4.228835 loss_rnnt 2.182154 hw_loss 0.182263 lr 0.00029843 rank 0
2023-02-28 23:31:40,063 DEBUG TRAIN Batch 44/4800 loss 12.030293 loss_att 14.039736 loss_ctc 15.376815 loss_rnnt 11.033920 hw_loss 0.278028 lr 0.00029843 rank 4
2023-02-28 23:31:40,065 DEBUG TRAIN Batch 44/4800 loss 8.476821 loss_att 11.935163 loss_ctc 16.818871 loss_rnnt 6.600846 hw_loss 0.135063 lr 0.00029843 rank 6
2023-02-28 23:31:40,075 DEBUG TRAIN Batch 44/4800 loss 10.672931 loss_att 13.392681 loss_ctc 19.505556 loss_rnnt 8.810957 hw_loss 0.263137 lr 0.00029843 rank 5
2023-02-28 23:32:19,738 DEBUG TRAIN Batch 44/4900 loss 7.463043 loss_att 10.409593 loss_ctc 11.710247 loss_rnnt 6.147272 hw_loss 0.300313 lr 0.00029842 rank 4
2023-02-28 23:32:19,744 DEBUG TRAIN Batch 44/4900 loss 4.315058 loss_att 5.913420 loss_ctc 7.045267 loss_rnnt 3.557081 hw_loss 0.139269 lr 0.00029842 rank 5
2023-02-28 23:32:19,745 DEBUG TRAIN Batch 44/4900 loss 7.043643 loss_att 9.791323 loss_ctc 12.676880 loss_rnnt 5.667516 hw_loss 0.141548 lr 0.00029842 rank 2
2023-02-28 23:32:19,750 DEBUG TRAIN Batch 44/4900 loss 10.131025 loss_att 12.947704 loss_ctc 20.664152 loss_rnnt 7.966013 hw_loss 0.369861 lr 0.00029842 rank 1
2023-02-28 23:32:19,753 DEBUG TRAIN Batch 44/4900 loss 6.960183 loss_att 7.468849 loss_ctc 10.820625 loss_rnnt 6.237704 hw_loss 0.198787 lr 0.00029842 rank 6
2023-02-28 23:32:19,756 DEBUG TRAIN Batch 44/4900 loss 2.104789 loss_att 4.675157 loss_ctc 6.810339 loss_rnnt 0.813709 hw_loss 0.280500 lr 0.00029842 rank 0
2023-02-28 23:32:19,774 DEBUG TRAIN Batch 44/4900 loss 3.552750 loss_att 7.089032 loss_ctc 8.914984 loss_rnnt 2.005797 hw_loss 0.233872 lr 0.00029842 rank 7
2023-02-28 23:32:19,780 DEBUG TRAIN Batch 44/4900 loss 3.851447 loss_att 5.743628 loss_ctc 7.715442 loss_rnnt 2.891763 hw_loss 0.123842 lr 0.00029842 rank 3
2023-02-28 23:33:25,133 DEBUG TRAIN Batch 44/5000 loss 6.792987 loss_att 10.741761 loss_ctc 10.492470 loss_rnnt 5.383598 hw_loss 0.236943 lr 0.00029841 rank 4
2023-02-28 23:33:25,134 DEBUG TRAIN Batch 44/5000 loss 5.940830 loss_att 8.047169 loss_ctc 8.907823 loss_rnnt 4.930055 hw_loss 0.363577 lr 0.00029841 rank 0
2023-02-28 23:33:25,134 DEBUG TRAIN Batch 44/5000 loss 5.701964 loss_att 8.236072 loss_ctc 8.620387 loss_rnnt 4.671478 hw_loss 0.252266 lr 0.00029841 rank 5
2023-02-28 23:33:25,135 DEBUG TRAIN Batch 44/5000 loss 7.079518 loss_att 8.525828 loss_ctc 12.692435 loss_rnnt 5.834348 hw_loss 0.389096 lr 0.00029841 rank 3
2023-02-28 23:33:25,135 DEBUG TRAIN Batch 44/5000 loss 7.406377 loss_att 8.109569 loss_ctc 11.411015 loss_rnnt 6.450451 hw_loss 0.527506 lr 0.00029841 rank 6
2023-02-28 23:33:25,136 DEBUG TRAIN Batch 44/5000 loss 4.122200 loss_att 7.751203 loss_ctc 10.110015 loss_rnnt 2.506149 hw_loss 0.172264 lr 0.00029841 rank 1
2023-02-28 23:33:25,139 DEBUG TRAIN Batch 44/5000 loss 5.885941 loss_att 7.925974 loss_ctc 9.591872 loss_rnnt 4.854353 hw_loss 0.242730 lr 0.00029841 rank 2
2023-02-28 23:33:25,146 DEBUG TRAIN Batch 44/5000 loss 5.300577 loss_att 9.127515 loss_ctc 10.093795 loss_rnnt 3.711105 hw_loss 0.346856 lr 0.00029841 rank 7
2023-02-28 23:34:03,836 DEBUG TRAIN Batch 44/5100 loss 10.441423 loss_att 13.245819 loss_ctc 17.920135 loss_rnnt 8.720880 hw_loss 0.304695 lr 0.00029840 rank 1
2023-02-28 23:34:03,843 DEBUG TRAIN Batch 44/5100 loss 7.802876 loss_att 8.550948 loss_ctc 12.188524 loss_rnnt 6.862028 hw_loss 0.387150 lr 0.00029840 rank 4
2023-02-28 23:34:03,843 DEBUG TRAIN Batch 44/5100 loss 7.247175 loss_att 10.729713 loss_ctc 15.981623 loss_rnnt 5.226434 hw_loss 0.299325 lr 0.00029840 rank 2
2023-02-28 23:34:03,844 DEBUG TRAIN Batch 44/5100 loss 7.305130 loss_att 11.037906 loss_ctc 17.377022 loss_rnnt 5.037593 hw_loss 0.333869 lr 0.00029840 rank 6
2023-02-28 23:34:03,846 DEBUG TRAIN Batch 44/5100 loss 4.189751 loss_att 4.920201 loss_ctc 6.380329 loss_rnnt 3.500557 hw_loss 0.470674 lr 0.00029840 rank 0
2023-02-28 23:34:03,848 DEBUG TRAIN Batch 44/5100 loss 6.199560 loss_att 8.747988 loss_ctc 10.132536 loss_rnnt 4.957037 hw_loss 0.390826 lr 0.00029840 rank 5
2023-02-28 23:34:03,869 DEBUG TRAIN Batch 44/5100 loss 9.236793 loss_att 10.471195 loss_ctc 14.106646 loss_rnnt 8.256401 hw_loss 0.157868 lr 0.00029840 rank 7
2023-02-28 23:34:03,880 DEBUG TRAIN Batch 44/5100 loss 3.386519 loss_att 7.872561 loss_ctc 6.547094 loss_rnnt 2.017468 hw_loss 0.094561 lr 0.00029840 rank 3
2023-02-28 23:34:43,084 DEBUG TRAIN Batch 44/5200 loss 3.109413 loss_att 6.263898 loss_ctc 8.547975 loss_rnnt 1.626939 hw_loss 0.237065 lr 0.00029838 rank 3
2023-02-28 23:34:43,094 DEBUG TRAIN Batch 44/5200 loss 1.455884 loss_att 3.757465 loss_ctc 1.940227 loss_rnnt 0.846161 hw_loss 0.159052 lr 0.00029838 rank 7
2023-02-28 23:34:43,104 DEBUG TRAIN Batch 44/5200 loss 6.742596 loss_att 7.865547 loss_ctc 18.883440 loss_rnnt 4.689402 hw_loss 0.393422 lr 0.00029838 rank 4
2023-02-28 23:34:43,105 DEBUG TRAIN Batch 44/5200 loss 9.173254 loss_att 10.905970 loss_ctc 11.380657 loss_rnnt 8.405006 hw_loss 0.238846 lr 0.00029838 rank 0
2023-02-28 23:34:43,106 DEBUG TRAIN Batch 44/5200 loss 6.266614 loss_att 8.247213 loss_ctc 10.839293 loss_rnnt 5.195950 hw_loss 0.121601 lr 0.00029838 rank 2
2023-02-28 23:34:43,110 DEBUG TRAIN Batch 44/5200 loss 7.888144 loss_att 10.386585 loss_ctc 13.998096 loss_rnnt 6.372924 hw_loss 0.376633 lr 0.00029838 rank 5
2023-02-28 23:34:43,111 DEBUG TRAIN Batch 44/5200 loss 9.287774 loss_att 10.954855 loss_ctc 11.424647 loss_rnnt 8.537486 hw_loss 0.247416 lr 0.00029838 rank 6
2023-02-28 23:34:43,115 DEBUG TRAIN Batch 44/5200 loss 4.415716 loss_att 7.383509 loss_ctc 6.979034 loss_rnnt 3.385631 hw_loss 0.177657 lr 0.00029838 rank 1
2023-02-28 23:35:22,656 DEBUG TRAIN Batch 44/5300 loss 12.908724 loss_att 19.608727 loss_ctc 22.231041 loss_rnnt 10.196467 hw_loss 0.242401 lr 0.00029837 rank 3
2023-02-28 23:35:22,661 DEBUG TRAIN Batch 44/5300 loss 6.496140 loss_att 11.508071 loss_ctc 10.349358 loss_rnnt 4.833393 hw_loss 0.274872 lr 0.00029837 rank 7
2023-02-28 23:35:22,662 DEBUG TRAIN Batch 44/5300 loss 5.282615 loss_att 6.862463 loss_ctc 6.428043 loss_rnnt 4.633187 hw_loss 0.338877 lr 0.00029837 rank 4
2023-02-28 23:35:22,669 DEBUG TRAIN Batch 44/5300 loss 6.651093 loss_att 10.632185 loss_ctc 17.499643 loss_rnnt 4.289609 hw_loss 0.222736 lr 0.00029837 rank 6
2023-02-28 23:35:22,670 DEBUG TRAIN Batch 44/5300 loss 5.457132 loss_att 9.570054 loss_ctc 9.170237 loss_rnnt 3.962715 hw_loss 0.331410 lr 0.00029837 rank 2
2023-02-28 23:35:22,672 DEBUG TRAIN Batch 44/5300 loss 4.043963 loss_att 7.665213 loss_ctc 6.435327 loss_rnnt 2.979408 hw_loss 0.040231 lr 0.00029837 rank 0
2023-02-28 23:35:22,679 DEBUG TRAIN Batch 44/5300 loss 3.967437 loss_att 7.241135 loss_ctc 5.057956 loss_rnnt 3.082792 hw_loss 0.158442 lr 0.00029837 rank 1
2023-02-28 23:35:22,693 DEBUG TRAIN Batch 44/5300 loss 11.926047 loss_att 17.474628 loss_ctc 17.727341 loss_rnnt 9.982403 hw_loss 0.113293 lr 0.00029837 rank 5
2023-02-28 23:36:25,434 DEBUG TRAIN Batch 44/5400 loss 6.433889 loss_att 9.069585 loss_ctc 10.034277 loss_rnnt 5.298326 hw_loss 0.240698 lr 0.00029836 rank 5
2023-02-28 23:36:25,448 DEBUG TRAIN Batch 44/5400 loss 7.442721 loss_att 12.092859 loss_ctc 11.435188 loss_rnnt 5.775843 hw_loss 0.383477 lr 0.00029836 rank 0
2023-02-28 23:36:25,452 DEBUG TRAIN Batch 44/5400 loss 5.841260 loss_att 8.798347 loss_ctc 8.259365 loss_rnnt 4.780879 hw_loss 0.274780 lr 0.00029836 rank 7
2023-02-28 23:36:25,452 DEBUG TRAIN Batch 44/5400 loss 8.859194 loss_att 10.968958 loss_ctc 10.707205 loss_rnnt 7.995687 hw_loss 0.365909 lr 0.00029836 rank 1
2023-02-28 23:36:25,455 DEBUG TRAIN Batch 44/5400 loss 10.331300 loss_att 12.840017 loss_ctc 17.964273 loss_rnnt 8.637627 hw_loss 0.326625 lr 0.00029836 rank 2
2023-02-28 23:36:25,455 DEBUG TRAIN Batch 44/5400 loss 6.378089 loss_att 8.592943 loss_ctc 10.245478 loss_rnnt 5.297616 hw_loss 0.228469 lr 0.00029836 rank 3
2023-02-28 23:36:25,457 DEBUG TRAIN Batch 44/5400 loss 10.376958 loss_att 13.607079 loss_ctc 22.115376 loss_rnnt 8.027006 hw_loss 0.260259 lr 0.00029836 rank 6
2023-02-28 23:36:25,457 DEBUG TRAIN Batch 44/5400 loss 4.432444 loss_att 7.369567 loss_ctc 6.231194 loss_rnnt 3.486550 hw_loss 0.222442 lr 0.00029836 rank 4
2023-02-28 23:37:03,760 DEBUG TRAIN Batch 44/5500 loss 4.417306 loss_att 7.380879 loss_ctc 11.238498 loss_rnnt 2.726561 hw_loss 0.353509 lr 0.00029834 rank 5
2023-02-28 23:37:03,761 DEBUG TRAIN Batch 44/5500 loss 8.371346 loss_att 11.838545 loss_ctc 13.468450 loss_rnnt 6.792531 hw_loss 0.385800 lr 0.00029834 rank 3
2023-02-28 23:37:03,770 DEBUG TRAIN Batch 44/5500 loss 8.753871 loss_att 12.268619 loss_ctc 15.549345 loss_rnnt 7.004990 hw_loss 0.262253 lr 0.00029834 rank 2
2023-02-28 23:37:03,771 DEBUG TRAIN Batch 44/5500 loss 6.323864 loss_att 9.052836 loss_ctc 12.097799 loss_rnnt 4.888338 hw_loss 0.224763 lr 0.00029834 rank 6
2023-02-28 23:37:03,774 DEBUG TRAIN Batch 44/5500 loss 3.393720 loss_att 6.426738 loss_ctc 5.667259 loss_rnnt 2.352229 hw_loss 0.247028 lr 0.00029834 rank 7
2023-02-28 23:37:03,775 DEBUG TRAIN Batch 44/5500 loss 4.331923 loss_att 7.471101 loss_ctc 5.154442 loss_rnnt 3.457634 hw_loss 0.256471 lr 0.00029834 rank 0
2023-02-28 23:37:03,776 DEBUG TRAIN Batch 44/5500 loss 10.277869 loss_att 14.882408 loss_ctc 18.191677 loss_rnnt 8.259712 hw_loss 0.078890 lr 0.00029834 rank 1
2023-02-28 23:37:03,835 DEBUG TRAIN Batch 44/5500 loss 7.492815 loss_att 10.770620 loss_ctc 14.152054 loss_rnnt 5.861358 hw_loss 0.164995 lr 0.00029834 rank 4
2023-02-28 23:37:42,933 DEBUG TRAIN Batch 44/5600 loss 9.100925 loss_att 13.455159 loss_ctc 12.820707 loss_rnnt 7.563350 hw_loss 0.320170 lr 0.00029833 rank 7
2023-02-28 23:37:42,934 DEBUG TRAIN Batch 44/5600 loss 5.043337 loss_att 7.725139 loss_ctc 10.598040 loss_rnnt 3.599574 hw_loss 0.312702 lr 0.00029833 rank 4
2023-02-28 23:37:42,947 DEBUG TRAIN Batch 44/5600 loss 8.301463 loss_att 10.160355 loss_ctc 12.372904 loss_rnnt 7.276767 hw_loss 0.206360 lr 0.00029833 rank 1
2023-02-28 23:37:42,954 DEBUG TRAIN Batch 44/5600 loss 14.989434 loss_att 14.372356 loss_ctc 19.959671 loss_rnnt 14.256071 hw_loss 0.363904 lr 0.00029833 rank 3
2023-02-28 23:37:42,954 DEBUG TRAIN Batch 44/5600 loss 3.869496 loss_att 5.678396 loss_ctc 7.209481 loss_rnnt 2.988225 hw_loss 0.139051 lr 0.00029833 rank 2
2023-02-28 23:37:42,956 DEBUG TRAIN Batch 44/5600 loss 10.108935 loss_att 13.087025 loss_ctc 22.897575 loss_rnnt 7.718143 hw_loss 0.168792 lr 0.00029833 rank 0
2023-02-28 23:37:42,987 DEBUG TRAIN Batch 44/5600 loss 8.783942 loss_att 13.734921 loss_ctc 21.115452 loss_rnnt 5.935944 hw_loss 0.400502 lr 0.00029833 rank 6
2023-02-28 23:37:42,996 DEBUG TRAIN Batch 44/5600 loss 3.155480 loss_att 5.434029 loss_ctc 7.840285 loss_rnnt 1.809679 hw_loss 0.497720 lr 0.00029833 rank 5
2023-02-28 23:38:47,365 DEBUG TRAIN Batch 44/5700 loss 4.794292 loss_att 6.287108 loss_ctc 7.254049 loss_rnnt 4.006383 hw_loss 0.302584 lr 0.00029832 rank 0
2023-02-28 23:38:47,366 DEBUG TRAIN Batch 44/5700 loss 9.108088 loss_att 10.936036 loss_ctc 14.166800 loss_rnnt 7.948061 hw_loss 0.224890 lr 0.00029832 rank 1
2023-02-28 23:38:47,366 DEBUG TRAIN Batch 44/5700 loss 7.262315 loss_att 10.655479 loss_ctc 16.567623 loss_rnnt 5.131701 hw_loss 0.396137 lr 0.00029832 rank 2
2023-02-28 23:38:47,367 DEBUG TRAIN Batch 44/5700 loss 4.812728 loss_att 5.989649 loss_ctc 8.285454 loss_rnnt 3.985139 hw_loss 0.242204 lr 0.00029832 rank 7
2023-02-28 23:38:47,368 DEBUG TRAIN Batch 44/5700 loss 10.100835 loss_att 13.773769 loss_ctc 19.255060 loss_rnnt 8.075607 hw_loss 0.131395 lr 0.00029832 rank 6
2023-02-28 23:38:47,373 DEBUG TRAIN Batch 44/5700 loss 7.379735 loss_att 8.004947 loss_ctc 9.772952 loss_rnnt 6.726503 hw_loss 0.392051 lr 0.00029832 rank 5
2023-02-28 23:38:47,373 DEBUG TRAIN Batch 44/5700 loss 5.137265 loss_att 5.761312 loss_ctc 7.582484 loss_rnnt 4.502478 hw_loss 0.344904 lr 0.00029832 rank 4
2023-02-28 23:38:47,420 DEBUG TRAIN Batch 44/5700 loss 6.383447 loss_att 9.377768 loss_ctc 8.582118 loss_rnnt 5.330074 hw_loss 0.302534 lr 0.00029832 rank 3
2023-02-28 23:39:26,123 DEBUG TRAIN Batch 44/5800 loss 6.274999 loss_att 10.217095 loss_ctc 12.579006 loss_rnnt 4.506782 hw_loss 0.261119 lr 0.00029830 rank 7
2023-02-28 23:39:26,125 DEBUG TRAIN Batch 44/5800 loss 7.751449 loss_att 11.574965 loss_ctc 13.195921 loss_rnnt 6.059185 hw_loss 0.378058 lr 0.00029830 rank 3
2023-02-28 23:39:26,126 DEBUG TRAIN Batch 44/5800 loss 6.359780 loss_att 9.064878 loss_ctc 10.889427 loss_rnnt 5.083200 hw_loss 0.246763 lr 0.00029830 rank 5
2023-02-28 23:39:26,137 DEBUG TRAIN Batch 44/5800 loss 6.575272 loss_att 8.264072 loss_ctc 9.283360 loss_rnnt 5.762280 hw_loss 0.214038 lr 0.00029830 rank 2
2023-02-28 23:39:26,140 DEBUG TRAIN Batch 44/5800 loss 3.805665 loss_att 5.623191 loss_ctc 4.700134 loss_rnnt 3.140447 hw_loss 0.342095 lr 0.00029830 rank 0
2023-02-28 23:39:26,142 DEBUG TRAIN Batch 44/5800 loss 5.474407 loss_att 7.821825 loss_ctc 7.506571 loss_rnnt 4.584837 hw_loss 0.279620 lr 0.00029830 rank 6
2023-02-28 23:39:26,145 DEBUG TRAIN Batch 44/5800 loss 2.349360 loss_att 4.114073 loss_ctc 2.908584 loss_rnnt 1.818932 hw_loss 0.192980 lr 0.00029830 rank 4
2023-02-28 23:39:26,148 DEBUG TRAIN Batch 44/5800 loss 9.215197 loss_att 9.562778 loss_ctc 16.788984 loss_rnnt 7.930508 hw_loss 0.385000 lr 0.00029830 rank 1
2023-02-28 23:40:04,797 DEBUG TRAIN Batch 44/5900 loss 2.862638 loss_att 5.565572 loss_ctc 5.009994 loss_rnnt 1.879329 hw_loss 0.293263 lr 0.00029829 rank 0
2023-02-28 23:40:04,799 DEBUG TRAIN Batch 44/5900 loss 2.484372 loss_att 6.285593 loss_ctc 3.736329 loss_rnnt 1.413516 hw_loss 0.269409 lr 0.00029829 rank 4
2023-02-28 23:40:04,800 DEBUG TRAIN Batch 44/5900 loss 1.711767 loss_att 3.482588 loss_ctc 2.578825 loss_rnnt 1.214778 hw_loss 0.051032 lr 0.00029829 rank 2
2023-02-28 23:40:04,801 DEBUG TRAIN Batch 44/5900 loss 4.571727 loss_att 8.502066 loss_ctc 9.504967 loss_rnnt 2.905044 hw_loss 0.417845 lr 0.00029829 rank 3
2023-02-28 23:40:04,802 DEBUG TRAIN Batch 44/5900 loss 7.044313 loss_att 9.054749 loss_ctc 16.313696 loss_rnnt 5.185773 hw_loss 0.413502 lr 0.00029829 rank 6
2023-02-28 23:40:04,804 DEBUG TRAIN Batch 44/5900 loss 4.699894 loss_att 8.967780 loss_ctc 12.360103 loss_rnnt 2.615538 hw_loss 0.392658 lr 0.00029829 rank 7
2023-02-28 23:40:04,821 DEBUG TRAIN Batch 44/5900 loss 4.939821 loss_att 6.846048 loss_ctc 9.365244 loss_rnnt 3.852973 hw_loss 0.216650 lr 0.00029829 rank 1
2023-02-28 23:40:04,832 DEBUG TRAIN Batch 44/5900 loss 3.447556 loss_att 6.673032 loss_ctc 7.483584 loss_rnnt 2.114827 hw_loss 0.280307 lr 0.00029829 rank 5
2023-02-28 23:40:44,153 DEBUG TRAIN Batch 44/6000 loss 5.438264 loss_att 8.921210 loss_ctc 7.354349 loss_rnnt 4.326435 hw_loss 0.299554 lr 0.00029828 rank 6
2023-02-28 23:40:44,155 DEBUG TRAIN Batch 44/6000 loss 11.356368 loss_att 14.480525 loss_ctc 23.143269 loss_rnnt 9.114402 hw_loss 0.085402 lr 0.00029828 rank 7
2023-02-28 23:40:44,156 DEBUG TRAIN Batch 44/6000 loss 1.721614 loss_att 3.359593 loss_ctc 1.201882 loss_rnnt 1.299786 hw_loss 0.306618 lr 0.00029828 rank 1
2023-02-28 23:40:44,159 DEBUG TRAIN Batch 44/6000 loss 9.462880 loss_att 15.330706 loss_ctc 17.774254 loss_rnnt 6.967774 hw_loss 0.400044 lr 0.00029828 rank 3
2023-02-28 23:40:44,166 DEBUG TRAIN Batch 44/6000 loss 4.101423 loss_att 7.812613 loss_ctc 7.414213 loss_rnnt 2.814623 hw_loss 0.192856 lr 0.00029828 rank 2
2023-02-28 23:40:44,168 DEBUG TRAIN Batch 44/6000 loss 9.862040 loss_att 10.744927 loss_ctc 16.668556 loss_rnnt 8.581116 hw_loss 0.369018 lr 0.00029828 rank 5
2023-02-28 23:40:44,171 DEBUG TRAIN Batch 44/6000 loss 3.887254 loss_att 6.455862 loss_ctc 4.616953 loss_rnnt 3.171271 hw_loss 0.196815 lr 0.00029828 rank 4
2023-02-28 23:40:44,172 DEBUG TRAIN Batch 44/6000 loss 7.248914 loss_att 11.930096 loss_ctc 15.080334 loss_rnnt 5.057493 hw_loss 0.395617 lr 0.00029828 rank 0
2023-02-28 23:41:48,750 DEBUG TRAIN Batch 44/6100 loss 10.878214 loss_att 15.202600 loss_ctc 21.435955 loss_rnnt 8.425994 hw_loss 0.336833 lr 0.00029826 rank 3
2023-02-28 23:41:48,767 DEBUG TRAIN Batch 44/6100 loss 4.608469 loss_att 7.791689 loss_ctc 13.395384 loss_rnnt 2.625470 hw_loss 0.327685 lr 0.00029826 rank 4
2023-02-28 23:41:48,767 DEBUG TRAIN Batch 44/6100 loss 9.274213 loss_att 13.944536 loss_ctc 16.458881 loss_rnnt 7.297356 hw_loss 0.159065 lr 0.00029826 rank 0
2023-02-28 23:41:48,768 DEBUG TRAIN Batch 44/6100 loss 7.605410 loss_att 9.383333 loss_ctc 13.349314 loss_rnnt 6.342524 hw_loss 0.265216 lr 0.00029826 rank 5
2023-02-28 23:41:48,769 DEBUG TRAIN Batch 44/6100 loss 11.251979 loss_att 13.744319 loss_ctc 15.251922 loss_rnnt 10.097282 hw_loss 0.230444 lr 0.00029826 rank 1
2023-02-28 23:41:48,771 DEBUG TRAIN Batch 44/6100 loss 8.675701 loss_att 11.337980 loss_ctc 11.456972 loss_rnnt 7.687283 hw_loss 0.159612 lr 0.00029826 rank 2
2023-02-28 23:41:48,771 DEBUG TRAIN Batch 44/6100 loss 7.772057 loss_att 9.776949 loss_ctc 15.334442 loss_rnnt 6.184443 hw_loss 0.334345 lr 0.00029826 rank 6
2023-02-28 23:41:48,773 DEBUG TRAIN Batch 44/6100 loss 9.088841 loss_att 12.721043 loss_ctc 19.749773 loss_rnnt 6.842002 hw_loss 0.185516 lr 0.00029826 rank 7
2023-02-28 23:42:27,956 DEBUG TRAIN Batch 44/6200 loss 8.070836 loss_att 10.877999 loss_ctc 13.316663 loss_rnnt 6.733815 hw_loss 0.142770 lr 0.00029825 rank 6
2023-02-28 23:42:27,967 DEBUG TRAIN Batch 44/6200 loss 10.368513 loss_att 13.000077 loss_ctc 18.557026 loss_rnnt 8.686000 hw_loss 0.120750 lr 0.00029825 rank 1
2023-02-28 23:42:27,971 DEBUG TRAIN Batch 44/6200 loss 7.598178 loss_att 11.403177 loss_ctc 17.313236 loss_rnnt 5.395630 hw_loss 0.274138 lr 0.00029825 rank 3
2023-02-28 23:42:27,972 DEBUG TRAIN Batch 44/6200 loss 13.537365 loss_att 16.511801 loss_ctc 18.848732 loss_rnnt 12.020636 hw_loss 0.400613 lr 0.00029825 rank 0
2023-02-28 23:42:27,973 DEBUG TRAIN Batch 44/6200 loss 7.572453 loss_att 9.064796 loss_ctc 11.329808 loss_rnnt 6.654184 hw_loss 0.222787 lr 0.00029825 rank 7
2023-02-28 23:42:27,978 DEBUG TRAIN Batch 44/6200 loss 9.708389 loss_att 11.737429 loss_ctc 15.101039 loss_rnnt 8.478797 hw_loss 0.196433 lr 0.00029825 rank 2
2023-02-28 23:42:28,002 DEBUG TRAIN Batch 44/6200 loss 5.604718 loss_att 8.620621 loss_ctc 12.406981 loss_rnnt 4.004424 hw_loss 0.169021 lr 0.00029825 rank 5
2023-02-28 23:42:28,006 DEBUG TRAIN Batch 44/6200 loss 7.354599 loss_att 10.638513 loss_ctc 13.134905 loss_rnnt 5.805172 hw_loss 0.228632 lr 0.00029825 rank 4
2023-02-28 23:43:06,981 DEBUG TRAIN Batch 44/6300 loss 10.345663 loss_att 14.090631 loss_ctc 16.364958 loss_rnnt 8.663408 hw_loss 0.245040 lr 0.00029824 rank 0
2023-02-28 23:43:06,984 DEBUG TRAIN Batch 44/6300 loss 10.366129 loss_att 13.550766 loss_ctc 15.899274 loss_rnnt 8.847136 hw_loss 0.270587 lr 0.00029824 rank 7
2023-02-28 23:43:06,987 DEBUG TRAIN Batch 44/6300 loss 6.514551 loss_att 8.180740 loss_ctc 7.903327 loss_rnnt 5.807386 hw_loss 0.353921 lr 0.00029824 rank 5
2023-02-28 23:43:06,988 DEBUG TRAIN Batch 44/6300 loss 6.940488 loss_att 9.266491 loss_ctc 10.213945 loss_rnnt 5.891570 hw_loss 0.276107 lr 0.00029824 rank 2
2023-02-28 23:43:06,989 DEBUG TRAIN Batch 44/6300 loss 5.464408 loss_att 10.395869 loss_ctc 10.612078 loss_rnnt 3.704170 hw_loss 0.164232 lr 0.00029824 rank 3
2023-02-28 23:43:06,993 DEBUG TRAIN Batch 44/6300 loss 9.832438 loss_att 9.673160 loss_ctc 14.600546 loss_rnnt 9.030563 hw_loss 0.371219 lr 0.00029824 rank 4
2023-02-28 23:43:06,994 DEBUG TRAIN Batch 44/6300 loss 6.217812 loss_att 9.890127 loss_ctc 9.380598 loss_rnnt 4.911930 hw_loss 0.280713 lr 0.00029824 rank 1
2023-02-28 23:43:06,996 DEBUG TRAIN Batch 44/6300 loss 9.735306 loss_att 10.176991 loss_ctc 13.345586 loss_rnnt 8.992657 hw_loss 0.324265 lr 0.00029824 rank 6
2023-02-28 23:44:07,610 DEBUG TRAIN Batch 44/6400 loss 4.850686 loss_att 6.282052 loss_ctc 7.069538 loss_rnnt 4.041021 hw_loss 0.426647 lr 0.00029822 rank 1
2023-02-28 23:44:07,611 DEBUG TRAIN Batch 44/6400 loss 2.638678 loss_att 7.234706 loss_ctc 5.458997 loss_rnnt 1.325765 hw_loss 0.033122 lr 0.00029822 rank 5
2023-02-28 23:44:07,612 DEBUG TRAIN Batch 44/6400 loss 3.852147 loss_att 5.810585 loss_ctc 5.738420 loss_rnnt 3.097444 hw_loss 0.209086 lr 0.00029822 rank 7
2023-02-28 23:44:07,613 DEBUG TRAIN Batch 44/6400 loss 6.605751 loss_att 13.050594 loss_ctc 12.115153 loss_rnnt 4.486049 hw_loss 0.180274 lr 0.00029822 rank 6
2023-02-28 23:44:07,614 DEBUG TRAIN Batch 44/6400 loss 4.202302 loss_att 7.635674 loss_ctc 8.231041 loss_rnnt 2.862031 hw_loss 0.218309 lr 0.00029822 rank 2
2023-02-28 23:44:07,619 DEBUG TRAIN Batch 44/6400 loss 4.105922 loss_att 7.417066 loss_ctc 6.955303 loss_rnnt 2.899028 hw_loss 0.308902 lr 0.00029822 rank 3
2023-02-28 23:44:07,643 DEBUG TRAIN Batch 44/6400 loss 5.817856 loss_att 8.727722 loss_ctc 8.217010 loss_rnnt 4.773535 hw_loss 0.267115 lr 0.00029822 rank 4
2023-02-28 23:44:07,645 DEBUG TRAIN Batch 44/6400 loss 5.740788 loss_att 11.351486 loss_ctc 11.453135 loss_rnnt 3.828779 hw_loss 0.052916 lr 0.00029822 rank 0
2023-02-28 23:44:50,853 DEBUG TRAIN Batch 44/6500 loss 6.429700 loss_att 13.130324 loss_ctc 16.701923 loss_rnnt 3.602568 hw_loss 0.220083 lr 0.00029821 rank 4
2023-02-28 23:44:50,855 DEBUG TRAIN Batch 44/6500 loss 5.974024 loss_att 9.638123 loss_ctc 7.130901 loss_rnnt 4.898941 hw_loss 0.352525 lr 0.00029821 rank 7
2023-02-28 23:44:50,855 DEBUG TRAIN Batch 44/6500 loss 4.111417 loss_att 5.604579 loss_ctc 7.520537 loss_rnnt 3.192367 hw_loss 0.311002 lr 0.00029821 rank 5
2023-02-28 23:44:50,856 DEBUG TRAIN Batch 44/6500 loss 3.219385 loss_att 6.523065 loss_ctc 3.753253 loss_rnnt 2.352022 hw_loss 0.253959 lr 0.00029821 rank 0
2023-02-28 23:44:50,857 DEBUG TRAIN Batch 44/6500 loss 5.319694 loss_att 10.073561 loss_ctc 9.153702 loss_rnnt 3.739488 hw_loss 0.221684 lr 0.00029821 rank 3
2023-02-28 23:44:50,859 DEBUG TRAIN Batch 44/6500 loss 2.038577 loss_att 3.642442 loss_ctc 2.256762 loss_rnnt 1.606384 hw_loss 0.154366 lr 0.00029821 rank 2
2023-02-28 23:44:50,859 DEBUG TRAIN Batch 44/6500 loss 4.561148 loss_att 8.322184 loss_ctc 5.970908 loss_rnnt 3.530356 hw_loss 0.169906 lr 0.00029821 rank 6
2023-02-28 23:44:50,863 DEBUG TRAIN Batch 44/6500 loss 5.418691 loss_att 9.695816 loss_ctc 8.726404 loss_rnnt 4.020718 hw_loss 0.190348 lr 0.00029821 rank 1
2023-02-28 23:45:29,784 DEBUG TRAIN Batch 44/6600 loss 3.245636 loss_att 6.480001 loss_ctc 5.899761 loss_rnnt 2.015977 hw_loss 0.429193 lr 0.00029820 rank 6
2023-02-28 23:45:29,795 DEBUG TRAIN Batch 44/6600 loss 4.042920 loss_att 5.670985 loss_ctc 4.526962 loss_rnnt 3.577806 hw_loss 0.140553 lr 0.00029820 rank 7
2023-02-28 23:45:29,797 DEBUG TRAIN Batch 44/6600 loss 7.234623 loss_att 9.582423 loss_ctc 11.736387 loss_rnnt 6.004379 hw_loss 0.300840 lr 0.00029820 rank 5
2023-02-28 23:45:29,797 DEBUG TRAIN Batch 44/6600 loss 2.694345 loss_att 5.593550 loss_ctc 5.719265 loss_rnnt 1.633694 hw_loss 0.145287 lr 0.00029820 rank 4
2023-02-28 23:45:29,797 DEBUG TRAIN Batch 44/6600 loss 5.367039 loss_att 8.424534 loss_ctc 7.355678 loss_rnnt 4.393874 hw_loss 0.180964 lr 0.00029820 rank 0
2023-02-28 23:45:29,803 DEBUG TRAIN Batch 44/6600 loss 5.290726 loss_att 9.384204 loss_ctc 10.482529 loss_rnnt 3.684836 hw_loss 0.178038 lr 0.00029820 rank 1
2023-02-28 23:45:29,804 DEBUG TRAIN Batch 44/6600 loss 5.811719 loss_att 7.271922 loss_ctc 8.354472 loss_rnnt 5.078257 hw_loss 0.191977 lr 0.00029820 rank 2
2023-02-28 23:45:29,814 DEBUG TRAIN Batch 44/6600 loss 6.020305 loss_att 8.563900 loss_ctc 7.746553 loss_rnnt 5.109966 hw_loss 0.321474 lr 0.00029820 rank 3
2023-02-28 23:46:09,053 DEBUG TRAIN Batch 44/6700 loss 6.369324 loss_att 10.805485 loss_ctc 12.695301 loss_rnnt 4.469329 hw_loss 0.317436 lr 0.00029818 rank 3
2023-02-28 23:46:09,054 DEBUG TRAIN Batch 44/6700 loss 7.959983 loss_att 12.415039 loss_ctc 17.391375 loss_rnnt 5.670994 hw_loss 0.263359 lr 0.00029818 rank 1
2023-02-28 23:46:09,056 DEBUG TRAIN Batch 44/6700 loss 10.678919 loss_att 12.798038 loss_ctc 18.477194 loss_rnnt 9.106194 hw_loss 0.204621 lr 0.00029818 rank 7
2023-02-28 23:46:09,064 DEBUG TRAIN Batch 44/6700 loss 3.937820 loss_att 6.235506 loss_ctc 7.428807 loss_rnnt 2.873149 hw_loss 0.261879 lr 0.00029818 rank 4
2023-02-28 23:46:09,068 DEBUG TRAIN Batch 44/6700 loss 6.541634 loss_att 8.482243 loss_ctc 9.931140 loss_rnnt 5.549443 hw_loss 0.285254 lr 0.00029818 rank 5
2023-02-28 23:46:09,075 DEBUG TRAIN Batch 44/6700 loss 4.131114 loss_att 7.309119 loss_ctc 6.309315 loss_rnnt 3.030273 hw_loss 0.327774 lr 0.00029818 rank 0
2023-02-28 23:46:09,075 DEBUG TRAIN Batch 44/6700 loss 7.586863 loss_att 11.399450 loss_ctc 11.797011 loss_rnnt 6.180494 hw_loss 0.154684 lr 0.00029818 rank 6
2023-02-28 23:46:09,089 DEBUG TRAIN Batch 44/6700 loss 6.082966 loss_att 7.582717 loss_ctc 10.402963 loss_rnnt 5.114124 hw_loss 0.174174 lr 0.00029818 rank 2
2023-02-28 23:47:13,391 DEBUG TRAIN Batch 44/6800 loss 10.125433 loss_att 13.409431 loss_ctc 13.637602 loss_rnnt 8.882649 hw_loss 0.220679 lr 0.00029817 rank 0
2023-02-28 23:47:13,403 DEBUG TRAIN Batch 44/6800 loss 5.693353 loss_att 8.506349 loss_ctc 11.133957 loss_rnnt 4.317625 hw_loss 0.164467 lr 0.00029817 rank 7
2023-02-28 23:47:13,407 DEBUG TRAIN Batch 44/6800 loss 7.156044 loss_att 9.532142 loss_ctc 12.589743 loss_rnnt 5.814259 hw_loss 0.266385 lr 0.00029817 rank 2
2023-02-28 23:47:13,408 DEBUG TRAIN Batch 44/6800 loss 11.919030 loss_att 15.617266 loss_ctc 18.826603 loss_rnnt 10.169231 hw_loss 0.167143 lr 0.00029817 rank 6
2023-02-28 23:47:13,410 DEBUG TRAIN Batch 44/6800 loss 8.121743 loss_att 9.518913 loss_ctc 10.048632 loss_rnnt 7.436684 hw_loss 0.278825 lr 0.00029817 rank 5
2023-02-28 23:47:13,410 DEBUG TRAIN Batch 44/6800 loss 7.110263 loss_att 9.125898 loss_ctc 9.628689 loss_rnnt 6.109746 hw_loss 0.490501 lr 0.00029817 rank 4
2023-02-28 23:47:13,416 DEBUG TRAIN Batch 44/6800 loss 4.003187 loss_att 7.565150 loss_ctc 7.209707 loss_rnnt 2.668802 hw_loss 0.364606 lr 0.00029817 rank 1
2023-02-28 23:47:13,416 DEBUG TRAIN Batch 44/6800 loss 3.998715 loss_att 6.877181 loss_ctc 11.056694 loss_rnnt 2.372516 hw_loss 0.205204 lr 0.00029817 rank 3
2023-02-28 23:47:52,819 DEBUG TRAIN Batch 44/6900 loss 9.310133 loss_att 9.937527 loss_ctc 13.054079 loss_rnnt 8.574883 hw_loss 0.207336 lr 0.00029816 rank 2
2023-02-28 23:47:52,823 DEBUG TRAIN Batch 44/6900 loss 10.922731 loss_att 12.809867 loss_ctc 17.113773 loss_rnnt 9.561061 hw_loss 0.297697 lr 0.00029816 rank 5
2023-02-28 23:47:52,823 DEBUG TRAIN Batch 44/6900 loss 2.405493 loss_att 3.432593 loss_ctc 4.028625 loss_rnnt 1.798547 hw_loss 0.347080 lr 0.00029816 rank 6
2023-02-28 23:47:52,823 DEBUG TRAIN Batch 44/6900 loss 8.899116 loss_att 10.933140 loss_ctc 15.160617 loss_rnnt 7.462799 hw_loss 0.364959 lr 0.00029816 rank 1
2023-02-28 23:47:52,823 DEBUG TRAIN Batch 44/6900 loss 4.703773 loss_att 7.304293 loss_ctc 7.443971 loss_rnnt 3.600005 hw_loss 0.409319 lr 0.00029816 rank 4
2023-02-28 23:47:52,829 DEBUG TRAIN Batch 44/6900 loss 7.626093 loss_att 9.801022 loss_ctc 10.114066 loss_rnnt 6.566600 hw_loss 0.548958 lr 0.00029816 rank 0
2023-02-28 23:47:52,833 DEBUG TRAIN Batch 44/6900 loss 5.903744 loss_att 7.730008 loss_ctc 7.561563 loss_rnnt 5.209649 hw_loss 0.202125 lr 0.00029816 rank 7
2023-02-28 23:47:52,873 DEBUG TRAIN Batch 44/6900 loss 7.487563 loss_att 8.883486 loss_ctc 12.951016 loss_rnnt 6.305796 hw_loss 0.326478 lr 0.00029816 rank 3
2023-02-28 23:48:31,916 DEBUG TRAIN Batch 44/7000 loss 10.067351 loss_att 12.901909 loss_ctc 16.810812 loss_rnnt 8.459425 hw_loss 0.266036 lr 0.00029814 rank 1
2023-02-28 23:48:31,933 DEBUG TRAIN Batch 44/7000 loss 4.872192 loss_att 9.451721 loss_ctc 10.307042 loss_rnnt 3.025066 hw_loss 0.387325 lr 0.00029814 rank 0
2023-02-28 23:48:31,935 DEBUG TRAIN Batch 44/7000 loss 3.845732 loss_att 9.720661 loss_ctc 7.447431 loss_rnnt 2.076973 hw_loss 0.212900 lr 0.00029814 rank 7
2023-02-28 23:48:31,936 DEBUG TRAIN Batch 44/7000 loss 6.630960 loss_att 7.139740 loss_ctc 9.502598 loss_rnnt 5.903106 hw_loss 0.456024 lr 0.00029814 rank 6
2023-02-28 23:48:31,941 DEBUG TRAIN Batch 44/7000 loss 4.471967 loss_att 6.999533 loss_ctc 8.381687 loss_rnnt 3.415484 hw_loss 0.055637 lr 0.00029814 rank 3
2023-02-28 23:48:31,942 DEBUG TRAIN Batch 44/7000 loss 4.761123 loss_att 6.793195 loss_ctc 7.579855 loss_rnnt 3.846185 hw_loss 0.248797 lr 0.00029814 rank 2
2023-02-28 23:48:31,943 DEBUG TRAIN Batch 44/7000 loss 14.266968 loss_att 15.381613 loss_ctc 19.736336 loss_rnnt 13.242061 hw_loss 0.136365 lr 0.00029814 rank 5
2023-02-28 23:48:31,950 DEBUG TRAIN Batch 44/7000 loss 5.329414 loss_att 6.484301 loss_ctc 8.278478 loss_rnnt 4.587290 hw_loss 0.221135 lr 0.00029814 rank 4
2023-02-28 23:49:32,835 DEBUG TRAIN Batch 44/7100 loss 5.719267 loss_att 9.905634 loss_ctc 7.181139 loss_rnnt 4.523159 hw_loss 0.307349 lr 0.00029813 rank 7
2023-02-28 23:49:32,850 DEBUG TRAIN Batch 44/7100 loss 3.672929 loss_att 7.442130 loss_ctc 7.308897 loss_rnnt 2.297385 hw_loss 0.256701 lr 0.00029813 rank 3
2023-02-28 23:49:32,854 DEBUG TRAIN Batch 44/7100 loss 6.682555 loss_att 12.059208 loss_ctc 11.156290 loss_rnnt 5.008827 hw_loss 0.003561 lr 0.00029813 rank 6
2023-02-28 23:49:32,856 DEBUG TRAIN Batch 44/7100 loss 6.001928 loss_att 7.121500 loss_ctc 10.985604 loss_rnnt 4.843786 hw_loss 0.505757 lr 0.00029813 rank 1
2023-02-28 23:49:32,857 DEBUG TRAIN Batch 44/7100 loss 7.788234 loss_att 9.127449 loss_ctc 7.399572 loss_rnnt 7.466030 hw_loss 0.199093 lr 0.00029813 rank 2
2023-02-28 23:49:32,864 DEBUG TRAIN Batch 44/7100 loss 2.317845 loss_att 4.909894 loss_ctc 6.031677 loss_rnnt 1.234947 hw_loss 0.129958 lr 0.00029813 rank 5
2023-02-28 23:49:32,870 DEBUG TRAIN Batch 44/7100 loss 7.607055 loss_att 10.912745 loss_ctc 11.679576 loss_rnnt 6.292869 hw_loss 0.206334 lr 0.00029813 rank 4
2023-02-28 23:49:32,891 DEBUG TRAIN Batch 44/7100 loss 8.374487 loss_att 12.095037 loss_ctc 11.466543 loss_rnnt 7.152619 hw_loss 0.122781 lr 0.00029813 rank 0
2023-02-28 23:50:14,788 DEBUG TRAIN Batch 44/7200 loss 4.952908 loss_att 6.881531 loss_ctc 6.271698 loss_rnnt 4.249462 hw_loss 0.266029 lr 0.00029812 rank 1
2023-02-28 23:50:14,789 DEBUG TRAIN Batch 44/7200 loss 9.310405 loss_att 14.800663 loss_ctc 14.809652 loss_rnnt 7.378807 hw_loss 0.188085 lr 0.00029812 rank 0
2023-02-28 23:50:14,790 DEBUG TRAIN Batch 44/7200 loss 10.106102 loss_att 16.542919 loss_ctc 18.238165 loss_rnnt 7.660520 hw_loss 0.138644 lr 0.00029812 rank 2
2023-02-28 23:50:14,790 DEBUG TRAIN Batch 44/7200 loss 5.558293 loss_att 9.043388 loss_ctc 8.259004 loss_rnnt 4.374391 hw_loss 0.237729 lr 0.00029812 rank 5
2023-02-28 23:50:14,791 DEBUG TRAIN Batch 44/7200 loss 3.329017 loss_att 5.838181 loss_ctc 4.557820 loss_rnnt 2.562272 hw_loss 0.189510 lr 0.00029812 rank 7
2023-02-28 23:50:14,791 DEBUG TRAIN Batch 44/7200 loss 12.293794 loss_att 16.362669 loss_ctc 17.677803 loss_rnnt 10.600134 hw_loss 0.303782 lr 0.00029812 rank 6
2023-02-28 23:50:14,796 DEBUG TRAIN Batch 44/7200 loss 3.604958 loss_att 6.827698 loss_ctc 3.357655 loss_rnnt 2.833878 hw_loss 0.299073 lr 0.00029812 rank 4
2023-02-28 23:50:14,809 DEBUG TRAIN Batch 44/7200 loss 7.462249 loss_att 10.436296 loss_ctc 13.130698 loss_rnnt 5.991415 hw_loss 0.225434 lr 0.00029812 rank 3
2023-02-28 23:50:54,200 DEBUG TRAIN Batch 44/7300 loss 10.932213 loss_att 13.943542 loss_ctc 14.391624 loss_rnnt 9.713041 hw_loss 0.291843 lr 0.00029810 rank 4
2023-02-28 23:50:54,213 DEBUG TRAIN Batch 44/7300 loss 5.421073 loss_att 8.217115 loss_ctc 8.942148 loss_rnnt 4.266552 hw_loss 0.235943 lr 0.00029810 rank 7
2023-02-28 23:50:54,216 DEBUG TRAIN Batch 44/7300 loss 6.330699 loss_att 8.873065 loss_ctc 11.348463 loss_rnnt 4.957288 hw_loss 0.367318 lr 0.00029810 rank 0
2023-02-28 23:50:54,217 DEBUG TRAIN Batch 44/7300 loss 2.174966 loss_att 4.662985 loss_ctc 2.530435 loss_rnnt 1.526841 hw_loss 0.193361 lr 0.00029810 rank 2
2023-02-28 23:50:54,221 DEBUG TRAIN Batch 44/7300 loss 2.074379 loss_att 4.061220 loss_ctc 2.758859 loss_rnnt 1.467178 hw_loss 0.222315 lr 0.00029810 rank 6
2023-02-28 23:50:54,221 DEBUG TRAIN Batch 44/7300 loss 6.433823 loss_att 11.511038 loss_ctc 13.550324 loss_rnnt 4.439703 hw_loss 0.055893 lr 0.00029810 rank 5
2023-02-28 23:50:54,222 DEBUG TRAIN Batch 44/7300 loss 4.171794 loss_att 8.939659 loss_ctc 7.604634 loss_rnnt 2.621787 hw_loss 0.260103 lr 0.00029810 rank 3
2023-02-28 23:50:54,224 DEBUG TRAIN Batch 44/7300 loss 6.820594 loss_att 9.382217 loss_ctc 11.454933 loss_rnnt 5.671329 hw_loss 0.035678 lr 0.00029810 rank 1
2023-02-28 23:51:33,715 DEBUG TRAIN Batch 44/7400 loss 4.509031 loss_att 8.450798 loss_ctc 9.003229 loss_rnnt 2.926553 hw_loss 0.365435 lr 0.00029809 rank 5
2023-02-28 23:51:33,716 DEBUG TRAIN Batch 44/7400 loss 2.170539 loss_att 5.237101 loss_ctc 3.217907 loss_rnnt 1.265857 hw_loss 0.284475 lr 0.00029809 rank 0
2023-02-28 23:51:33,717 DEBUG TRAIN Batch 44/7400 loss 6.567143 loss_att 7.911376 loss_ctc 9.042069 loss_rnnt 5.838316 hw_loss 0.243732 lr 0.00029809 rank 3
2023-02-28 23:51:33,721 DEBUG TRAIN Batch 44/7400 loss 0.902346 loss_att 3.002829 loss_ctc 1.316410 loss_rnnt 0.292823 hw_loss 0.251660 lr 0.00029809 rank 1
2023-02-28 23:51:33,722 DEBUG TRAIN Batch 44/7400 loss 12.261531 loss_att 15.540911 loss_ctc 24.727055 loss_rnnt 9.866514 hw_loss 0.144508 lr 0.00029809 rank 4
2023-02-28 23:51:33,732 DEBUG TRAIN Batch 44/7400 loss 10.817105 loss_att 11.362279 loss_ctc 14.925028 loss_rnnt 9.964438 hw_loss 0.367329 lr 0.00029809 rank 6
2023-02-28 23:51:33,736 DEBUG TRAIN Batch 44/7400 loss 9.937057 loss_att 14.133123 loss_ctc 16.934826 loss_rnnt 7.992740 hw_loss 0.322628 lr 0.00029809 rank 2
2023-02-28 23:51:33,738 DEBUG TRAIN Batch 44/7400 loss 6.092057 loss_att 8.713174 loss_ctc 13.055779 loss_rnnt 4.467057 hw_loss 0.323025 lr 0.00029809 rank 7
2023-02-28 23:52:37,259 DEBUG TRAIN Batch 44/7500 loss 7.610627 loss_att 10.023153 loss_ctc 10.159779 loss_rnnt 6.708904 hw_loss 0.148746 lr 0.00029808 rank 0
2023-02-28 23:52:37,265 DEBUG TRAIN Batch 44/7500 loss 6.553740 loss_att 6.888412 loss_ctc 8.740829 loss_rnnt 6.025285 hw_loss 0.318578 lr 0.00029808 rank 3
2023-02-28 23:52:37,266 DEBUG TRAIN Batch 44/7500 loss 4.258399 loss_att 6.920643 loss_ctc 8.360392 loss_rnnt 2.994129 hw_loss 0.346668 lr 0.00029808 rank 4
2023-02-28 23:52:37,268 DEBUG TRAIN Batch 44/7500 loss 7.000412 loss_att 9.962609 loss_ctc 12.707008 loss_rnnt 5.491050 hw_loss 0.292580 lr 0.00029808 rank 5
2023-02-28 23:52:37,268 DEBUG TRAIN Batch 44/7500 loss 11.767591 loss_att 12.010674 loss_ctc 18.293392 loss_rnnt 10.739416 hw_loss 0.205224 lr 0.00029808 rank 1
2023-02-28 23:52:37,269 DEBUG TRAIN Batch 44/7500 loss 5.750183 loss_att 6.668803 loss_ctc 8.126697 loss_rnnt 5.177317 hw_loss 0.135514 lr 0.00029808 rank 2
2023-02-28 23:52:37,269 DEBUG TRAIN Batch 44/7500 loss 7.669655 loss_att 11.110138 loss_ctc 16.513805 loss_rnnt 5.647754 hw_loss 0.289846 lr 0.00029808 rank 6
2023-02-28 23:52:37,308 DEBUG TRAIN Batch 44/7500 loss 5.901474 loss_att 8.701023 loss_ctc 9.528197 loss_rnnt 4.684079 hw_loss 0.326104 lr 0.00029808 rank 7
2023-02-28 23:53:16,109 DEBUG TRAIN Batch 44/7600 loss 8.382606 loss_att 12.553848 loss_ctc 13.123835 loss_rnnt 6.766680 hw_loss 0.280338 lr 0.00029806 rank 7
2023-02-28 23:53:16,110 DEBUG TRAIN Batch 44/7600 loss 2.203089 loss_att 6.181265 loss_ctc 3.822643 loss_rnnt 1.105195 hw_loss 0.161847 lr 0.00029806 rank 3
2023-02-28 23:53:16,131 DEBUG TRAIN Batch 44/7600 loss 7.735056 loss_att 8.902451 loss_ctc 12.482711 loss_rnnt 6.780920 hw_loss 0.164319 lr 0.00029806 rank 1
2023-02-28 23:53:16,133 DEBUG TRAIN Batch 44/7600 loss 5.144405 loss_att 6.332394 loss_ctc 9.384625 loss_rnnt 4.195027 hw_loss 0.274531 lr 0.00029806 rank 4
2023-02-28 23:53:16,135 DEBUG TRAIN Batch 44/7600 loss 5.456679 loss_att 5.821473 loss_ctc 7.916160 loss_rnnt 4.846292 hw_loss 0.392808 lr 0.00029806 rank 5
2023-02-28 23:53:16,137 DEBUG TRAIN Batch 44/7600 loss 10.027170 loss_att 11.939230 loss_ctc 13.854876 loss_rnnt 8.907226 hw_loss 0.425948 lr 0.00029806 rank 2
2023-02-28 23:53:16,143 DEBUG TRAIN Batch 44/7600 loss 2.406348 loss_att 4.482632 loss_ctc 3.199182 loss_rnnt 1.730518 hw_loss 0.290368 lr 0.00029806 rank 0
2023-02-28 23:53:16,179 DEBUG TRAIN Batch 44/7600 loss 8.179005 loss_att 10.122501 loss_ctc 12.923057 loss_rnnt 6.970891 hw_loss 0.350388 lr 0.00029806 rank 6
2023-02-28 23:53:55,367 DEBUG TRAIN Batch 44/7700 loss 16.091743 loss_att 22.470764 loss_ctc 28.411062 loss_rnnt 13.110077 hw_loss 0.118661 lr 0.00029805 rank 7
2023-02-28 23:53:55,370 DEBUG TRAIN Batch 44/7700 loss 7.186625 loss_att 7.292008 loss_ctc 10.768190 loss_rnnt 6.509462 hw_loss 0.334773 lr 0.00029805 rank 6
2023-02-28 23:53:55,373 DEBUG TRAIN Batch 44/7700 loss 3.640962 loss_att 6.287316 loss_ctc 5.321936 loss_rnnt 2.806139 hw_loss 0.152664 lr 0.00029805 rank 5
2023-02-28 23:53:55,374 DEBUG TRAIN Batch 44/7700 loss 4.635401 loss_att 5.540779 loss_ctc 6.930667 loss_rnnt 3.983246 hw_loss 0.309459 lr 0.00029805 rank 0
2023-02-28 23:53:55,375 DEBUG TRAIN Batch 44/7700 loss 10.947551 loss_att 14.543996 loss_ctc 17.957493 loss_rnnt 9.119349 hw_loss 0.326725 lr 0.00029805 rank 4
2023-02-28 23:53:55,380 DEBUG TRAIN Batch 44/7700 loss 5.094292 loss_att 8.993259 loss_ctc 9.870665 loss_rnnt 3.471513 hw_loss 0.386503 lr 0.00029805 rank 3
2023-02-28 23:53:55,381 DEBUG TRAIN Batch 44/7700 loss 2.872683 loss_att 5.742180 loss_ctc 8.988537 loss_rnnt 1.331285 hw_loss 0.285096 lr 0.00029805 rank 2
2023-02-28 23:53:55,412 DEBUG TRAIN Batch 44/7700 loss 5.597598 loss_att 9.311741 loss_ctc 10.399607 loss_rnnt 4.060397 hw_loss 0.288946 lr 0.00029805 rank 1
2023-02-28 23:54:35,819 DEBUG TRAIN Batch 44/7800 loss 7.133679 loss_att 9.708244 loss_ctc 12.851942 loss_rnnt 5.824938 hw_loss 0.058861 lr 0.00029804 rank 7
2023-02-28 23:54:35,819 DEBUG TRAIN Batch 44/7800 loss 7.849713 loss_att 12.931978 loss_ctc 15.104477 loss_rnnt 5.753303 hw_loss 0.211230 lr 0.00029804 rank 0
2023-02-28 23:54:35,823 DEBUG TRAIN Batch 44/7800 loss 3.473459 loss_att 6.556505 loss_ctc 5.019917 loss_rnnt 2.573126 hw_loss 0.145366 lr 0.00029804 rank 4
2023-02-28 23:54:35,831 DEBUG TRAIN Batch 44/7800 loss 3.556385 loss_att 6.174295 loss_ctc 6.243120 loss_rnnt 2.489964 hw_loss 0.346139 lr 0.00029804 rank 3
2023-02-28 23:54:35,832 DEBUG TRAIN Batch 44/7800 loss 2.111822 loss_att 4.672902 loss_ctc 5.020506 loss_rnnt 1.090812 hw_loss 0.226817 lr 0.00029804 rank 1
2023-02-28 23:54:35,837 DEBUG TRAIN Batch 44/7800 loss 4.874383 loss_att 7.839730 loss_ctc 7.144122 loss_rnnt 3.878263 hw_loss 0.188286 lr 0.00029804 rank 2
2023-02-28 23:54:35,838 DEBUG TRAIN Batch 44/7800 loss 4.054335 loss_att 6.802540 loss_ctc 4.418138 loss_rnnt 3.181796 hw_loss 0.514484 lr 0.00029804 rank 6
2023-02-28 23:54:35,851 DEBUG TRAIN Batch 44/7800 loss 5.176870 loss_att 8.130017 loss_ctc 6.988982 loss_rnnt 4.271689 hw_loss 0.136754 lr 0.00029804 rank 5
2023-02-28 23:55:40,052 DEBUG TRAIN Batch 44/7900 loss 10.555451 loss_att 13.507361 loss_ctc 16.854942 loss_rnnt 9.027388 hw_loss 0.183282 lr 0.00029802 rank 6
2023-02-28 23:55:40,056 DEBUG TRAIN Batch 44/7900 loss 8.808759 loss_att 12.257525 loss_ctc 15.273108 loss_rnnt 7.166435 hw_loss 0.169981 lr 0.00029802 rank 4
2023-02-28 23:55:40,069 DEBUG TRAIN Batch 44/7900 loss 3.976304 loss_att 7.602807 loss_ctc 6.176361 loss_rnnt 2.897367 hw_loss 0.113055 lr 0.00029802 rank 1
2023-02-28 23:55:40,069 DEBUG TRAIN Batch 44/7900 loss 8.414227 loss_att 9.600204 loss_ctc 14.949337 loss_rnnt 7.165468 hw_loss 0.262905 lr 0.00029802 rank 3
2023-02-28 23:55:40,069 DEBUG TRAIN Batch 44/7900 loss 15.461059 loss_att 16.026258 loss_ctc 19.775681 loss_rnnt 14.681396 hw_loss 0.171264 lr 0.00029802 rank 7
2023-02-28 23:55:40,071 DEBUG TRAIN Batch 44/7900 loss 5.015323 loss_att 10.203465 loss_ctc 7.773650 loss_rnnt 3.500616 hw_loss 0.204940 lr 0.00029802 rank 0
2023-02-28 23:55:40,072 DEBUG TRAIN Batch 44/7900 loss 3.379847 loss_att 6.153772 loss_ctc 4.843541 loss_rnnt 2.565611 hw_loss 0.120548 lr 0.00029802 rank 2
2023-02-28 23:55:40,082 DEBUG TRAIN Batch 44/7900 loss 6.786133 loss_att 7.270602 loss_ctc 11.282752 loss_rnnt 5.982146 hw_loss 0.201645 lr 0.00029802 rank 5
2023-02-28 23:56:19,100 DEBUG TRAIN Batch 44/8000 loss 5.831819 loss_att 9.762364 loss_ctc 13.328036 loss_rnnt 3.884690 hw_loss 0.302858 lr 0.00029801 rank 7
2023-02-28 23:56:19,101 DEBUG TRAIN Batch 44/8000 loss 4.169891 loss_att 5.855561 loss_ctc 6.619872 loss_rnnt 3.314460 hw_loss 0.359312 lr 0.00029801 rank 0
2023-02-28 23:56:19,114 DEBUG TRAIN Batch 44/8000 loss 9.189876 loss_att 11.415605 loss_ctc 13.210621 loss_rnnt 8.125721 hw_loss 0.155457 lr 0.00029801 rank 2
2023-02-28 23:56:19,116 DEBUG TRAIN Batch 44/8000 loss 6.301455 loss_att 7.495850 loss_ctc 14.497005 loss_rnnt 4.895164 hw_loss 0.140011 lr 0.00029801 rank 3
2023-02-28 23:56:19,117 DEBUG TRAIN Batch 44/8000 loss 1.709295 loss_att 3.521184 loss_ctc 1.957232 loss_rnnt 1.195771 hw_loss 0.221414 lr 0.00029801 rank 1
2023-02-28 23:56:19,118 DEBUG TRAIN Batch 44/8000 loss 12.137460 loss_att 12.341857 loss_ctc 16.916988 loss_rnnt 11.293216 hw_loss 0.311427 lr 0.00029801 rank 6
2023-02-28 23:56:19,123 DEBUG TRAIN Batch 44/8000 loss 2.815597 loss_att 5.660249 loss_ctc 3.777847 loss_rnnt 2.085626 hw_loss 0.061390 lr 0.00029801 rank 5
2023-02-28 23:56:19,166 DEBUG TRAIN Batch 44/8000 loss 6.323018 loss_att 8.723618 loss_ctc 13.464283 loss_rnnt 4.806102 hw_loss 0.158675 lr 0.00029801 rank 4
2023-02-28 23:56:58,399 DEBUG TRAIN Batch 44/8100 loss 4.265745 loss_att 7.696545 loss_ctc 10.407547 loss_rnnt 2.599655 hw_loss 0.301919 lr 0.00029800 rank 1
2023-02-28 23:56:58,403 DEBUG TRAIN Batch 44/8100 loss 3.523022 loss_att 6.592652 loss_ctc 7.461168 loss_rnnt 2.261564 hw_loss 0.229586 lr 0.00029800 rank 4
2023-02-28 23:56:58,405 DEBUG TRAIN Batch 44/8100 loss 4.633893 loss_att 9.658960 loss_ctc 11.212294 loss_rnnt 2.548720 hw_loss 0.380699 lr 0.00029800 rank 0
2023-02-28 23:56:58,408 DEBUG TRAIN Batch 44/8100 loss 11.233216 loss_att 11.573521 loss_ctc 15.259242 loss_rnnt 10.425697 hw_loss 0.379976 lr 0.00029800 rank 3
2023-02-28 23:56:58,408 DEBUG TRAIN Batch 44/8100 loss 7.549738 loss_att 9.985136 loss_ctc 10.937788 loss_rnnt 6.456833 hw_loss 0.288909 lr 0.00029800 rank 6
2023-02-28 23:56:58,410 DEBUG TRAIN Batch 44/8100 loss 3.028891 loss_att 5.291030 loss_ctc 4.583344 loss_rnnt 2.250052 hw_loss 0.223406 lr 0.00029800 rank 2
2023-02-28 23:56:58,424 DEBUG TRAIN Batch 44/8100 loss 8.945606 loss_att 14.906166 loss_ctc 16.727200 loss_rnnt 6.646439 hw_loss 0.130328 lr 0.00029800 rank 5
2023-02-28 23:56:58,429 DEBUG TRAIN Batch 44/8100 loss 5.540906 loss_att 7.982560 loss_ctc 8.872714 loss_rnnt 4.360045 hw_loss 0.465541 lr 0.00029800 rank 7
2023-02-28 23:57:38,963 DEBUG TRAIN Batch 44/8200 loss 2.606763 loss_att 5.317730 loss_ctc 5.616342 loss_rnnt 1.526318 hw_loss 0.256825 lr 0.00029798 rank 5
2023-02-28 23:57:38,966 DEBUG TRAIN Batch 44/8200 loss 2.892503 loss_att 4.706769 loss_ctc 7.207072 loss_rnnt 1.789266 hw_loss 0.309578 lr 0.00029798 rank 6
2023-02-28 23:57:38,977 DEBUG TRAIN Batch 44/8200 loss 7.672074 loss_att 8.735254 loss_ctc 10.465165 loss_rnnt 6.831696 hw_loss 0.478743 lr 0.00029798 rank 7
2023-02-28 23:57:38,979 DEBUG TRAIN Batch 44/8200 loss 7.359602 loss_att 11.460522 loss_ctc 9.116091 loss_rnnt 6.127165 hw_loss 0.333851 lr 0.00029798 rank 0
2023-02-28 23:57:38,982 DEBUG TRAIN Batch 44/8200 loss 8.705916 loss_att 11.984967 loss_ctc 21.867271 loss_rnnt 6.204173 hw_loss 0.170786 lr 0.00029798 rank 1
2023-02-28 23:57:38,982 DEBUG TRAIN Batch 44/8200 loss 2.340198 loss_att 4.957001 loss_ctc 3.719092 loss_rnnt 1.405502 hw_loss 0.426530 lr 0.00029798 rank 3
2023-02-28 23:57:38,984 DEBUG TRAIN Batch 44/8200 loss 6.575109 loss_att 8.613500 loss_ctc 11.796148 loss_rnnt 5.258539 hw_loss 0.398913 lr 0.00029798 rank 2
2023-02-28 23:57:38,989 DEBUG TRAIN Batch 44/8200 loss 8.881207 loss_att 11.611115 loss_ctc 13.325648 loss_rnnt 7.608965 hw_loss 0.250626 lr 0.00029798 rank 4
2023-02-28 23:58:17,690 DEBUG TRAIN Batch 44/8300 loss 6.471165 loss_att 11.019111 loss_ctc 14.875555 loss_rnnt 4.301607 hw_loss 0.261345 lr 0.00029797 rank 5
2023-02-28 23:58:17,696 DEBUG TRAIN Batch 44/8300 loss 2.903653 loss_att 7.678929 loss_ctc 7.542681 loss_rnnt 1.261349 hw_loss 0.128835 lr 0.00029797 rank 3
2023-02-28 23:58:17,700 DEBUG TRAIN Batch 44/8300 loss 5.160832 loss_att 9.162962 loss_ctc 12.097672 loss_rnnt 3.287420 hw_loss 0.277639 lr 0.00029797 rank 1
2023-02-28 23:58:17,711 DEBUG TRAIN Batch 44/8300 loss 8.963306 loss_att 9.908654 loss_ctc 16.551819 loss_rnnt 7.710650 hw_loss 0.097096 lr 0.00029797 rank 2
2023-02-28 23:58:17,710 DEBUG TRAIN Batch 44/8300 loss 5.717370 loss_att 9.692435 loss_ctc 12.301141 loss_rnnt 3.896768 hw_loss 0.277036 lr 0.00029797 rank 0
2023-02-28 23:58:17,711 DEBUG TRAIN Batch 44/8300 loss 5.546041 loss_att 8.386473 loss_ctc 8.906770 loss_rnnt 4.464118 hw_loss 0.123262 lr 0.00029797 rank 7
2023-02-28 23:58:17,712 DEBUG TRAIN Batch 44/8300 loss 11.370413 loss_att 12.634018 loss_ctc 16.984901 loss_rnnt 10.207685 hw_loss 0.302642 lr 0.00029797 rank 6
2023-02-28 23:58:17,715 DEBUG TRAIN Batch 44/8300 loss 6.504720 loss_att 7.049082 loss_ctc 13.440665 loss_rnnt 5.400052 hw_loss 0.133130 lr 0.00029797 rank 4
2023-02-28 23:58:48,952 DEBUG CV Batch 44/0 loss 0.816867 loss_att 0.760248 loss_ctc 1.064309 loss_rnnt 0.530945 hw_loss 0.495476 history loss 0.786613 rank 2
2023-02-28 23:58:48,959 DEBUG CV Batch 44/0 loss 0.816867 loss_att 0.760248 loss_ctc 1.064309 loss_rnnt 0.530945 hw_loss 0.495476 history loss 0.786613 rank 6
2023-02-28 23:58:48,963 DEBUG CV Batch 44/0 loss 0.816867 loss_att 0.760248 loss_ctc 1.064309 loss_rnnt 0.530945 hw_loss 0.495476 history loss 0.786613 rank 0
2023-02-28 23:58:48,965 DEBUG CV Batch 44/0 loss 0.816867 loss_att 0.760248 loss_ctc 1.064309 loss_rnnt 0.530945 hw_loss 0.495476 history loss 0.786613 rank 1
2023-02-28 23:58:48,972 DEBUG CV Batch 44/0 loss 0.816867 loss_att 0.760248 loss_ctc 1.064309 loss_rnnt 0.530945 hw_loss 0.495476 history loss 0.786613 rank 5
2023-02-28 23:58:48,977 DEBUG CV Batch 44/0 loss 0.816867 loss_att 0.760248 loss_ctc 1.064309 loss_rnnt 0.530945 hw_loss 0.495476 history loss 0.786613 rank 7
2023-02-28 23:58:48,979 DEBUG CV Batch 44/0 loss 0.816867 loss_att 0.760248 loss_ctc 1.064309 loss_rnnt 0.530945 hw_loss 0.495476 history loss 0.786613 rank 4
2023-02-28 23:58:48,981 DEBUG CV Batch 44/0 loss 0.816867 loss_att 0.760248 loss_ctc 1.064309 loss_rnnt 0.530945 hw_loss 0.495476 history loss 0.786613 rank 3
2023-02-28 23:59:00,375 DEBUG CV Batch 44/100 loss 3.424833 loss_att 4.730754 loss_ctc 9.044364 loss_rnnt 2.280236 hw_loss 0.251515 history loss 2.916846 rank 4
2023-02-28 23:59:00,520 DEBUG CV Batch 44/100 loss 3.424833 loss_att 4.730754 loss_ctc 9.044364 loss_rnnt 2.280236 hw_loss 0.251515 history loss 2.916846 rank 7
2023-02-28 23:59:00,566 DEBUG CV Batch 44/100 loss 3.424833 loss_att 4.730754 loss_ctc 9.044364 loss_rnnt 2.280236 hw_loss 0.251515 history loss 2.916846 rank 6
2023-02-28 23:59:00,593 DEBUG CV Batch 44/100 loss 3.424833 loss_att 4.730754 loss_ctc 9.044364 loss_rnnt 2.280236 hw_loss 0.251515 history loss 2.916846 rank 0
2023-02-28 23:59:00,744 DEBUG CV Batch 44/100 loss 3.424833 loss_att 4.730754 loss_ctc 9.044364 loss_rnnt 2.280236 hw_loss 0.251515 history loss 2.916846 rank 5
2023-02-28 23:59:00,819 DEBUG CV Batch 44/100 loss 3.424833 loss_att 4.730754 loss_ctc 9.044364 loss_rnnt 2.280236 hw_loss 0.251515 history loss 2.916846 rank 3
2023-02-28 23:59:00,900 DEBUG CV Batch 44/100 loss 3.424833 loss_att 4.730754 loss_ctc 9.044364 loss_rnnt 2.280236 hw_loss 0.251515 history loss 2.916846 rank 1
2023-02-28 23:59:00,977 DEBUG CV Batch 44/100 loss 3.424833 loss_att 4.730754 loss_ctc 9.044364 loss_rnnt 2.280236 hw_loss 0.251515 history loss 2.916846 rank 2
2023-02-28 23:59:14,005 DEBUG CV Batch 44/200 loss 7.759438 loss_att 10.343194 loss_ctc 13.423185 loss_rnnt 6.441919 hw_loss 0.085500 history loss 3.503386 rank 4
2023-02-28 23:59:14,134 DEBUG CV Batch 44/200 loss 7.759438 loss_att 10.343194 loss_ctc 13.423185 loss_rnnt 6.441919 hw_loss 0.085500 history loss 3.503386 rank 7
2023-02-28 23:59:14,185 DEBUG CV Batch 44/200 loss 7.759438 loss_att 10.343194 loss_ctc 13.423185 loss_rnnt 6.441919 hw_loss 0.085500 history loss 3.503386 rank 6
2023-02-28 23:59:14,451 DEBUG CV Batch 44/200 loss 7.759438 loss_att 10.343194 loss_ctc 13.423185 loss_rnnt 6.441919 hw_loss 0.085500 history loss 3.503386 rank 0
2023-02-28 23:59:14,583 DEBUG CV Batch 44/200 loss 7.759438 loss_att 10.343194 loss_ctc 13.423185 loss_rnnt 6.441919 hw_loss 0.085500 history loss 3.503386 rank 5
2023-02-28 23:59:14,652 DEBUG CV Batch 44/200 loss 7.759438 loss_att 10.343194 loss_ctc 13.423185 loss_rnnt 6.441919 hw_loss 0.085500 history loss 3.503386 rank 1
2023-02-28 23:59:14,728 DEBUG CV Batch 44/200 loss 7.759438 loss_att 10.343194 loss_ctc 13.423185 loss_rnnt 6.441919 hw_loss 0.085500 history loss 3.503386 rank 2
2023-02-28 23:59:15,225 DEBUG CV Batch 44/200 loss 7.759438 loss_att 10.343194 loss_ctc 13.423185 loss_rnnt 6.441919 hw_loss 0.085500 history loss 3.503386 rank 3
2023-02-28 23:59:27,062 DEBUG CV Batch 44/300 loss 2.487842 loss_att 3.167789 loss_ctc 3.968698 loss_rnnt 1.985939 hw_loss 0.315876 history loss 3.637914 rank 4
2023-02-28 23:59:27,196 DEBUG CV Batch 44/300 loss 2.487842 loss_att 3.167789 loss_ctc 3.968698 loss_rnnt 1.985939 hw_loss 0.315876 history loss 3.637914 rank 2
2023-02-28 23:59:27,201 DEBUG CV Batch 44/300 loss 2.487842 loss_att 3.167789 loss_ctc 3.968698 loss_rnnt 1.985939 hw_loss 0.315876 history loss 3.637914 rank 1
2023-02-28 23:59:27,217 DEBUG CV Batch 44/300 loss 2.487842 loss_att 3.167789 loss_ctc 3.968698 loss_rnnt 1.985939 hw_loss 0.315876 history loss 3.637914 rank 7
2023-02-28 23:59:27,220 DEBUG CV Batch 44/300 loss 2.487842 loss_att 3.167789 loss_ctc 3.968698 loss_rnnt 1.985939 hw_loss 0.315876 history loss 3.637914 rank 6
2023-02-28 23:59:27,553 DEBUG CV Batch 44/300 loss 2.487842 loss_att 3.167789 loss_ctc 3.968698 loss_rnnt 1.985939 hw_loss 0.315876 history loss 3.637914 rank 0
2023-02-28 23:59:27,641 DEBUG CV Batch 44/300 loss 2.487842 loss_att 3.167789 loss_ctc 3.968698 loss_rnnt 1.985939 hw_loss 0.315876 history loss 3.637914 rank 5
2023-02-28 23:59:28,354 DEBUG CV Batch 44/300 loss 2.487842 loss_att 3.167789 loss_ctc 3.968698 loss_rnnt 1.985939 hw_loss 0.315876 history loss 3.637914 rank 3
2023-02-28 23:59:39,316 DEBUG CV Batch 44/400 loss 15.817381 loss_att 66.097794 loss_ctc 7.597589 loss_rnnt 6.804780 hw_loss 0.098418 history loss 4.456197 rank 1
2023-02-28 23:59:39,500 DEBUG CV Batch 44/400 loss 15.817381 loss_att 66.097794 loss_ctc 7.597589 loss_rnnt 6.804780 hw_loss 0.098418 history loss 4.456197 rank 4
2023-02-28 23:59:39,613 DEBUG CV Batch 44/400 loss 15.817381 loss_att 66.097794 loss_ctc 7.597589 loss_rnnt 6.804780 hw_loss 0.098418 history loss 4.456197 rank 7
2023-02-28 23:59:39,657 DEBUG CV Batch 44/400 loss 15.817381 loss_att 66.097794 loss_ctc 7.597589 loss_rnnt 6.804780 hw_loss 0.098418 history loss 4.456197 rank 2
2023-02-28 23:59:39,915 DEBUG CV Batch 44/400 loss 15.817381 loss_att 66.097794 loss_ctc 7.597589 loss_rnnt 6.804780 hw_loss 0.098418 history loss 4.456197 rank 0
2023-02-28 23:59:40,015 DEBUG CV Batch 44/400 loss 15.817381 loss_att 66.097794 loss_ctc 7.597589 loss_rnnt 6.804780 hw_loss 0.098418 history loss 4.456197 rank 5
2023-02-28 23:59:40,028 DEBUG CV Batch 44/400 loss 15.817381 loss_att 66.097794 loss_ctc 7.597589 loss_rnnt 6.804780 hw_loss 0.098418 history loss 4.456197 rank 6
2023-02-28 23:59:41,303 DEBUG CV Batch 44/400 loss 15.817381 loss_att 66.097794 loss_ctc 7.597589 loss_rnnt 6.804780 hw_loss 0.098418 history loss 4.456197 rank 3
2023-02-28 23:59:50,222 DEBUG CV Batch 44/500 loss 4.362704 loss_att 4.134479 loss_ctc 5.425667 loss_rnnt 4.113853 hw_loss 0.286441 history loss 5.029523 rank 1
2023-02-28 23:59:50,599 DEBUG CV Batch 44/500 loss 4.362704 loss_att 4.134479 loss_ctc 5.425667 loss_rnnt 4.113853 hw_loss 0.286441 history loss 5.029523 rank 4
2023-02-28 23:59:50,692 DEBUG CV Batch 44/500 loss 4.362704 loss_att 4.134479 loss_ctc 5.425667 loss_rnnt 4.113853 hw_loss 0.286441 history loss 5.029523 rank 2
2023-02-28 23:59:50,995 DEBUG CV Batch 44/500 loss 4.362704 loss_att 4.134479 loss_ctc 5.425667 loss_rnnt 4.113853 hw_loss 0.286441 history loss 5.029523 rank 7
2023-02-28 23:59:51,093 DEBUG CV Batch 44/500 loss 4.362704 loss_att 4.134479 loss_ctc 5.425667 loss_rnnt 4.113853 hw_loss 0.286441 history loss 5.029523 rank 0
2023-02-28 23:59:51,140 DEBUG CV Batch 44/500 loss 4.362704 loss_att 4.134479 loss_ctc 5.425667 loss_rnnt 4.113853 hw_loss 0.286441 history loss 5.029523 rank 5
2023-02-28 23:59:51,192 DEBUG CV Batch 44/500 loss 4.362704 loss_att 4.134479 loss_ctc 5.425667 loss_rnnt 4.113853 hw_loss 0.286441 history loss 5.029523 rank 6
2023-02-28 23:59:53,034 DEBUG CV Batch 44/500 loss 4.362704 loss_att 4.134479 loss_ctc 5.425667 loss_rnnt 4.113853 hw_loss 0.286441 history loss 5.029523 rank 3
2023-03-01 00:00:02,630 DEBUG CV Batch 44/600 loss 6.366653 loss_att 6.164717 loss_ctc 8.997063 loss_rnnt 5.808663 hw_loss 0.464353 history loss 5.878033 rank 1
2023-03-01 00:00:03,034 DEBUG CV Batch 44/600 loss 6.366653 loss_att 6.164717 loss_ctc 8.997063 loss_rnnt 5.808663 hw_loss 0.464353 history loss 5.878033 rank 4
2023-03-01 00:00:03,269 DEBUG CV Batch 44/600 loss 6.366653 loss_att 6.164717 loss_ctc 8.997063 loss_rnnt 5.808663 hw_loss 0.464353 history loss 5.878033 rank 2
2023-03-01 00:00:03,517 DEBUG CV Batch 44/600 loss 6.366653 loss_att 6.164717 loss_ctc 8.997063 loss_rnnt 5.808663 hw_loss 0.464353 history loss 5.878033 rank 5
2023-03-01 00:00:03,574 DEBUG CV Batch 44/600 loss 6.366653 loss_att 6.164717 loss_ctc 8.997063 loss_rnnt 5.808663 hw_loss 0.464353 history loss 5.878033 rank 0
2023-03-01 00:00:03,761 DEBUG CV Batch 44/600 loss 6.366653 loss_att 6.164717 loss_ctc 8.997063 loss_rnnt 5.808663 hw_loss 0.464353 history loss 5.878033 rank 6
2023-03-01 00:00:04,073 DEBUG CV Batch 44/600 loss 6.366653 loss_att 6.164717 loss_ctc 8.997063 loss_rnnt 5.808663 hw_loss 0.464353 history loss 5.878033 rank 7
2023-03-01 00:00:06,276 DEBUG CV Batch 44/600 loss 6.366653 loss_att 6.164717 loss_ctc 8.997063 loss_rnnt 5.808663 hw_loss 0.464353 history loss 5.878033 rank 3
2023-03-01 00:00:14,314 DEBUG CV Batch 44/700 loss 10.658589 loss_att 22.645021 loss_ctc 14.698635 loss_rnnt 7.719703 hw_loss 0.005490 history loss 6.385585 rank 1
2023-03-01 00:00:14,692 DEBUG CV Batch 44/700 loss 10.658589 loss_att 22.645021 loss_ctc 14.698635 loss_rnnt 7.719703 hw_loss 0.005490 history loss 6.385585 rank 4
2023-03-01 00:00:14,901 DEBUG CV Batch 44/700 loss 10.658589 loss_att 22.645021 loss_ctc 14.698635 loss_rnnt 7.719703 hw_loss 0.005490 history loss 6.385585 rank 2
2023-03-01 00:00:15,171 DEBUG CV Batch 44/700 loss 10.658589 loss_att 22.645021 loss_ctc 14.698635 loss_rnnt 7.719703 hw_loss 0.005490 history loss 6.385585 rank 5
2023-03-01 00:00:15,410 DEBUG CV Batch 44/700 loss 10.658589 loss_att 22.645021 loss_ctc 14.698635 loss_rnnt 7.719703 hw_loss 0.005490 history loss 6.385585 rank 0
2023-03-01 00:00:15,746 DEBUG CV Batch 44/700 loss 10.658589 loss_att 22.645021 loss_ctc 14.698635 loss_rnnt 7.719703 hw_loss 0.005490 history loss 6.385585 rank 6
2023-03-01 00:00:15,947 DEBUG CV Batch 44/700 loss 10.658589 loss_att 22.645021 loss_ctc 14.698635 loss_rnnt 7.719703 hw_loss 0.005490 history loss 6.385585 rank 7
2023-03-01 00:00:18,555 DEBUG CV Batch 44/700 loss 10.658589 loss_att 22.645021 loss_ctc 14.698635 loss_rnnt 7.719703 hw_loss 0.005490 history loss 6.385585 rank 3
2023-03-01 00:00:25,644 DEBUG CV Batch 44/800 loss 5.754228 loss_att 6.888598 loss_ctc 13.111487 loss_rnnt 4.384281 hw_loss 0.303945 history loss 5.923661 rank 1
2023-03-01 00:00:26,444 DEBUG CV Batch 44/800 loss 5.754228 loss_att 6.888598 loss_ctc 13.111487 loss_rnnt 4.384281 hw_loss 0.303945 history loss 5.923661 rank 4
2023-03-01 00:00:26,647 DEBUG CV Batch 44/800 loss 5.754228 loss_att 6.888598 loss_ctc 13.111487 loss_rnnt 4.384281 hw_loss 0.303945 history loss 5.923661 rank 2
2023-03-01 00:00:26,812 DEBUG CV Batch 44/800 loss 5.754228 loss_att 6.888598 loss_ctc 13.111487 loss_rnnt 4.384281 hw_loss 0.303945 history loss 5.923661 rank 5
2023-03-01 00:00:27,144 DEBUG CV Batch 44/800 loss 5.754228 loss_att 6.888598 loss_ctc 13.111487 loss_rnnt 4.384281 hw_loss 0.303945 history loss 5.923661 rank 0
2023-03-01 00:00:27,565 DEBUG CV Batch 44/800 loss 5.754228 loss_att 6.888598 loss_ctc 13.111487 loss_rnnt 4.384281 hw_loss 0.303945 history loss 5.923661 rank 6
2023-03-01 00:00:27,624 DEBUG CV Batch 44/800 loss 5.754228 loss_att 6.888598 loss_ctc 13.111487 loss_rnnt 4.384281 hw_loss 0.303945 history loss 5.923661 rank 7
2023-03-01 00:00:30,906 DEBUG CV Batch 44/800 loss 5.754228 loss_att 6.888598 loss_ctc 13.111487 loss_rnnt 4.384281 hw_loss 0.303945 history loss 5.923661 rank 3
2023-03-01 00:00:38,914 DEBUG CV Batch 44/900 loss 7.615982 loss_att 10.657763 loss_ctc 18.050667 loss_rnnt 5.487375 hw_loss 0.241799 history loss 5.767863 rank 1
2023-03-01 00:00:40,003 DEBUG CV Batch 44/900 loss 7.615982 loss_att 10.657763 loss_ctc 18.050667 loss_rnnt 5.487375 hw_loss 0.241799 history loss 5.767863 rank 4
2023-03-01 00:00:40,325 DEBUG CV Batch 44/900 loss 7.615982 loss_att 10.657763 loss_ctc 18.050667 loss_rnnt 5.487375 hw_loss 0.241799 history loss 5.767863 rank 2
2023-03-01 00:00:40,388 DEBUG CV Batch 44/900 loss 7.615982 loss_att 10.657763 loss_ctc 18.050667 loss_rnnt 5.487375 hw_loss 0.241799 history loss 5.767863 rank 5
2023-03-01 00:00:40,842 DEBUG CV Batch 44/900 loss 7.615982 loss_att 10.657763 loss_ctc 18.050667 loss_rnnt 5.487375 hw_loss 0.241799 history loss 5.767863 rank 0
2023-03-01 00:00:41,213 DEBUG CV Batch 44/900 loss 7.615982 loss_att 10.657763 loss_ctc 18.050667 loss_rnnt 5.487375 hw_loss 0.241799 history loss 5.767863 rank 6
2023-03-01 00:00:41,214 DEBUG CV Batch 44/900 loss 7.615982 loss_att 10.657763 loss_ctc 18.050667 loss_rnnt 5.487375 hw_loss 0.241799 history loss 5.767863 rank 7
2023-03-01 00:00:44,733 DEBUG CV Batch 44/900 loss 7.615982 loss_att 10.657763 loss_ctc 18.050667 loss_rnnt 5.487375 hw_loss 0.241799 history loss 5.767863 rank 3
2023-03-01 00:00:51,262 DEBUG CV Batch 44/1000 loss 4.156247 loss_att 4.296131 loss_ctc 4.504931 loss_rnnt 3.893664 hw_loss 0.352715 history loss 5.584442 rank 1
2023-03-01 00:00:52,473 DEBUG CV Batch 44/1000 loss 4.156247 loss_att 4.296131 loss_ctc 4.504931 loss_rnnt 3.893664 hw_loss 0.352715 history loss 5.584442 rank 4
2023-03-01 00:00:52,953 DEBUG CV Batch 44/1000 loss 4.156247 loss_att 4.296131 loss_ctc 4.504931 loss_rnnt 3.893664 hw_loss 0.352715 history loss 5.584442 rank 2
2023-03-01 00:00:53,482 DEBUG CV Batch 44/1000 loss 4.156247 loss_att 4.296131 loss_ctc 4.504931 loss_rnnt 3.893664 hw_loss 0.352715 history loss 5.584442 rank 0
2023-03-01 00:00:53,571 DEBUG CV Batch 44/1000 loss 4.156247 loss_att 4.296131 loss_ctc 4.504931 loss_rnnt 3.893664 hw_loss 0.352715 history loss 5.584442 rank 5
2023-03-01 00:00:53,805 DEBUG CV Batch 44/1000 loss 4.156247 loss_att 4.296131 loss_ctc 4.504931 loss_rnnt 3.893664 hw_loss 0.352715 history loss 5.584442 rank 7
2023-03-01 00:00:53,878 DEBUG CV Batch 44/1000 loss 4.156247 loss_att 4.296131 loss_ctc 4.504931 loss_rnnt 3.893664 hw_loss 0.352715 history loss 5.584442 rank 6
2023-03-01 00:00:57,518 DEBUG CV Batch 44/1000 loss 4.156247 loss_att 4.296131 loss_ctc 4.504931 loss_rnnt 3.893664 hw_loss 0.352715 history loss 5.584442 rank 3
2023-03-01 00:01:03,155 DEBUG CV Batch 44/1100 loss 4.487097 loss_att 4.719261 loss_ctc 7.347748 loss_rnnt 3.828116 hw_loss 0.433366 history loss 5.554838 rank 1
2023-03-01 00:01:04,789 DEBUG CV Batch 44/1100 loss 4.487097 loss_att 4.719261 loss_ctc 7.347748 loss_rnnt 3.828116 hw_loss 0.433366 history loss 5.554838 rank 4
2023-03-01 00:01:05,269 DEBUG CV Batch 44/1100 loss 4.487097 loss_att 4.719261 loss_ctc 7.347748 loss_rnnt 3.828116 hw_loss 0.433366 history loss 5.554838 rank 2
2023-03-01 00:01:05,775 DEBUG CV Batch 44/1100 loss 4.487097 loss_att 4.719261 loss_ctc 7.347748 loss_rnnt 3.828116 hw_loss 0.433366 history loss 5.554838 rank 5
2023-03-01 00:01:05,845 DEBUG CV Batch 44/1100 loss 4.487097 loss_att 4.719261 loss_ctc 7.347748 loss_rnnt 3.828116 hw_loss 0.433366 history loss 5.554838 rank 0
2023-03-01 00:01:06,124 DEBUG CV Batch 44/1100 loss 4.487097 loss_att 4.719261 loss_ctc 7.347748 loss_rnnt 3.828116 hw_loss 0.433366 history loss 5.554838 rank 7
2023-03-01 00:01:06,298 DEBUG CV Batch 44/1100 loss 4.487097 loss_att 4.719261 loss_ctc 7.347748 loss_rnnt 3.828116 hw_loss 0.433366 history loss 5.554838 rank 6
2023-03-01 00:01:10,319 DEBUG CV Batch 44/1100 loss 4.487097 loss_att 4.719261 loss_ctc 7.347748 loss_rnnt 3.828116 hw_loss 0.433366 history loss 5.554838 rank 3
2023-03-01 00:01:13,958 DEBUG CV Batch 44/1200 loss 6.515087 loss_att 6.602330 loss_ctc 8.383235 loss_rnnt 6.132327 hw_loss 0.217921 history loss 5.823006 rank 1
2023-03-01 00:01:15,900 DEBUG CV Batch 44/1200 loss 6.515087 loss_att 6.602330 loss_ctc 8.383235 loss_rnnt 6.132327 hw_loss 0.217921 history loss 5.823006 rank 4
2023-03-01 00:01:16,250 DEBUG CV Batch 44/1200 loss 6.515087 loss_att 6.602330 loss_ctc 8.383235 loss_rnnt 6.132327 hw_loss 0.217921 history loss 5.823006 rank 2
2023-03-01 00:01:16,739 DEBUG CV Batch 44/1200 loss 6.515087 loss_att 6.602330 loss_ctc 8.383235 loss_rnnt 6.132327 hw_loss 0.217921 history loss 5.823006 rank 5
2023-03-01 00:01:17,006 DEBUG CV Batch 44/1200 loss 6.515087 loss_att 6.602330 loss_ctc 8.383235 loss_rnnt 6.132327 hw_loss 0.217921 history loss 5.823006 rank 0
2023-03-01 00:01:17,233 DEBUG CV Batch 44/1200 loss 6.515087 loss_att 6.602330 loss_ctc 8.383235 loss_rnnt 6.132327 hw_loss 0.217921 history loss 5.823006 rank 7
2023-03-01 00:01:17,771 DEBUG CV Batch 44/1200 loss 6.515087 loss_att 6.602330 loss_ctc 8.383235 loss_rnnt 6.132327 hw_loss 0.217921 history loss 5.823006 rank 6
2023-03-01 00:01:21,910 DEBUG CV Batch 44/1200 loss 6.515087 loss_att 6.602330 loss_ctc 8.383235 loss_rnnt 6.132327 hw_loss 0.217921 history loss 5.823006 rank 3
2023-03-01 00:01:26,035 DEBUG CV Batch 44/1300 loss 4.355408 loss_att 3.812817 loss_ctc 6.108914 loss_rnnt 4.030614 hw_loss 0.374083 history loss 6.111941 rank 1
2023-03-01 00:01:28,268 DEBUG CV Batch 44/1300 loss 4.355408 loss_att 3.812817 loss_ctc 6.108914 loss_rnnt 4.030614 hw_loss 0.374083 history loss 6.111941 rank 4
2023-03-01 00:01:28,663 DEBUG CV Batch 44/1300 loss 4.355408 loss_att 3.812817 loss_ctc 6.108914 loss_rnnt 4.030614 hw_loss 0.374083 history loss 6.111941 rank 2
2023-03-01 00:01:29,240 DEBUG CV Batch 44/1300 loss 4.355408 loss_att 3.812817 loss_ctc 6.108914 loss_rnnt 4.030614 hw_loss 0.374083 history loss 6.111941 rank 5
2023-03-01 00:01:29,488 DEBUG CV Batch 44/1300 loss 4.355408 loss_att 3.812817 loss_ctc 6.108914 loss_rnnt 4.030614 hw_loss 0.374083 history loss 6.111941 rank 0
2023-03-01 00:01:29,591 DEBUG CV Batch 44/1300 loss 4.355408 loss_att 3.812817 loss_ctc 6.108914 loss_rnnt 4.030614 hw_loss 0.374083 history loss 6.111941 rank 7
2023-03-01 00:01:30,355 DEBUG CV Batch 44/1300 loss 4.355408 loss_att 3.812817 loss_ctc 6.108914 loss_rnnt 4.030614 hw_loss 0.374083 history loss 6.111941 rank 6
2023-03-01 00:01:34,771 DEBUG CV Batch 44/1300 loss 4.355408 loss_att 3.812817 loss_ctc 6.108914 loss_rnnt 4.030614 hw_loss 0.374083 history loss 6.111941 rank 3
2023-03-01 00:01:37,391 DEBUG CV Batch 44/1400 loss 4.197245 loss_att 17.676083 loss_ctc 4.813616 loss_rnnt 1.416366 hw_loss 0.005490 history loss 6.365318 rank 1
2023-03-01 00:01:39,977 DEBUG CV Batch 44/1400 loss 4.197245 loss_att 17.676083 loss_ctc 4.813616 loss_rnnt 1.416366 hw_loss 0.005490 history loss 6.365318 rank 4
2023-03-01 00:01:40,322 DEBUG CV Batch 44/1400 loss 4.197245 loss_att 17.676083 loss_ctc 4.813616 loss_rnnt 1.416366 hw_loss 0.005490 history loss 6.365318 rank 2
2023-03-01 00:01:40,893 DEBUG CV Batch 44/1400 loss 4.197245 loss_att 17.676083 loss_ctc 4.813616 loss_rnnt 1.416366 hw_loss 0.005490 history loss 6.365318 rank 5
2023-03-01 00:01:41,215 DEBUG CV Batch 44/1400 loss 4.197245 loss_att 17.676083 loss_ctc 4.813616 loss_rnnt 1.416366 hw_loss 0.005490 history loss 6.365318 rank 0
2023-03-01 00:01:41,383 DEBUG CV Batch 44/1400 loss 4.197245 loss_att 17.676083 loss_ctc 4.813616 loss_rnnt 1.416366 hw_loss 0.005490 history loss 6.365318 rank 7
2023-03-01 00:01:42,229 DEBUG CV Batch 44/1400 loss 4.197245 loss_att 17.676083 loss_ctc 4.813616 loss_rnnt 1.416366 hw_loss 0.005490 history loss 6.365318 rank 6
2023-03-01 00:01:46,609 DEBUG CV Batch 44/1400 loss 4.197245 loss_att 17.676083 loss_ctc 4.813616 loss_rnnt 1.416366 hw_loss 0.005490 history loss 6.365318 rank 3
2023-03-01 00:01:49,313 DEBUG CV Batch 44/1500 loss 5.932261 loss_att 6.496447 loss_ctc 6.069189 loss_rnnt 5.623466 hw_loss 0.333192 history loss 6.233898 rank 1
2023-03-01 00:01:52,038 DEBUG CV Batch 44/1500 loss 5.932261 loss_att 6.496447 loss_ctc 6.069189 loss_rnnt 5.623466 hw_loss 0.333192 history loss 6.233898 rank 4
2023-03-01 00:01:52,204 DEBUG CV Batch 44/1500 loss 5.932261 loss_att 6.496447 loss_ctc 6.069189 loss_rnnt 5.623466 hw_loss 0.333192 history loss 6.233898 rank 2
2023-03-01 00:01:53,002 DEBUG CV Batch 44/1500 loss 5.932261 loss_att 6.496447 loss_ctc 6.069189 loss_rnnt 5.623466 hw_loss 0.333192 history loss 6.233898 rank 5
2023-03-01 00:01:53,233 DEBUG CV Batch 44/1500 loss 5.932261 loss_att 6.496447 loss_ctc 6.069189 loss_rnnt 5.623466 hw_loss 0.333192 history loss 6.233898 rank 0
2023-03-01 00:01:53,363 DEBUG CV Batch 44/1500 loss 5.932261 loss_att 6.496447 loss_ctc 6.069189 loss_rnnt 5.623466 hw_loss 0.333192 history loss 6.233898 rank 7
2023-03-01 00:01:54,299 DEBUG CV Batch 44/1500 loss 5.932261 loss_att 6.496447 loss_ctc 6.069189 loss_rnnt 5.623466 hw_loss 0.333192 history loss 6.233898 rank 6
2023-03-01 00:01:59,192 DEBUG CV Batch 44/1500 loss 5.932261 loss_att 6.496447 loss_ctc 6.069189 loss_rnnt 5.623466 hw_loss 0.333192 history loss 6.233898 rank 3
2023-03-01 00:02:02,564 DEBUG CV Batch 44/1600 loss 9.838768 loss_att 14.904762 loss_ctc 11.344247 loss_rnnt 8.459468 hw_loss 0.310070 history loss 6.199748 rank 1
2023-03-01 00:02:05,241 DEBUG CV Batch 44/1600 loss 9.838768 loss_att 14.904762 loss_ctc 11.344247 loss_rnnt 8.459468 hw_loss 0.310070 history loss 6.199748 rank 4
2023-03-01 00:02:05,661 DEBUG CV Batch 44/1600 loss 9.838768 loss_att 14.904762 loss_ctc 11.344247 loss_rnnt 8.459468 hw_loss 0.310070 history loss 6.199748 rank 2
2023-03-01 00:02:06,646 DEBUG CV Batch 44/1600 loss 9.838768 loss_att 14.904762 loss_ctc 11.344247 loss_rnnt 8.459468 hw_loss 0.310070 history loss 6.199748 rank 5
2023-03-01 00:02:06,749 DEBUG CV Batch 44/1600 loss 9.838768 loss_att 14.904762 loss_ctc 11.344247 loss_rnnt 8.459468 hw_loss 0.310070 history loss 6.199748 rank 7
2023-03-01 00:02:06,838 DEBUG CV Batch 44/1600 loss 9.838768 loss_att 14.904762 loss_ctc 11.344247 loss_rnnt 8.459468 hw_loss 0.310070 history loss 6.199748 rank 0
2023-03-01 00:02:07,854 DEBUG CV Batch 44/1600 loss 9.838768 loss_att 14.904762 loss_ctc 11.344247 loss_rnnt 8.459468 hw_loss 0.310070 history loss 6.199748 rank 6
2023-03-01 00:02:12,821 DEBUG CV Batch 44/1600 loss 9.838768 loss_att 14.904762 loss_ctc 11.344247 loss_rnnt 8.459468 hw_loss 0.310070 history loss 6.199748 rank 3
2023-03-01 00:02:15,238 DEBUG CV Batch 44/1700 loss 6.501842 loss_att 6.001699 loss_ctc 11.981672 loss_rnnt 5.644994 hw_loss 0.424187 history loss 6.133691 rank 1
2023-03-01 00:02:17,946 DEBUG CV Batch 44/1700 loss 6.501842 loss_att 6.001699 loss_ctc 11.981672 loss_rnnt 5.644994 hw_loss 0.424187 history loss 6.133691 rank 4
2023-03-01 00:02:18,392 DEBUG CV Batch 44/1700 loss 6.501842 loss_att 6.001699 loss_ctc 11.981672 loss_rnnt 5.644994 hw_loss 0.424187 history loss 6.133691 rank 2
2023-03-01 00:02:19,432 DEBUG CV Batch 44/1700 loss 6.501842 loss_att 6.001699 loss_ctc 11.981672 loss_rnnt 5.644994 hw_loss 0.424187 history loss 6.133691 rank 5
2023-03-01 00:02:19,456 DEBUG CV Batch 44/1700 loss 6.501842 loss_att 6.001699 loss_ctc 11.981672 loss_rnnt 5.644994 hw_loss 0.424187 history loss 6.133691 rank 7
2023-03-01 00:02:19,736 DEBUG CV Batch 44/1700 loss 6.501842 loss_att 6.001699 loss_ctc 11.981672 loss_rnnt 5.644994 hw_loss 0.424187 history loss 6.133691 rank 0
2023-03-01 00:02:20,616 DEBUG CV Batch 44/1700 loss 6.501842 loss_att 6.001699 loss_ctc 11.981672 loss_rnnt 5.644994 hw_loss 0.424187 history loss 6.133691 rank 6
2023-03-01 00:02:24,309 INFO Epoch 44 CV info cv_loss 6.111435537398387
2023-03-01 00:02:24,310 INFO Epoch 45 TRAIN info lr 0.00029796869876888424
2023-03-01 00:02:24,315 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 00:02:25,510 DEBUG CV Batch 44/1700 loss 6.501842 loss_att 6.001699 loss_ctc 11.981672 loss_rnnt 5.644994 hw_loss 0.424187 history loss 6.133691 rank 3
2023-03-01 00:02:27,016 INFO Epoch 44 CV info cv_loss 6.1114355374996086
2023-03-01 00:02:27,017 INFO Epoch 45 TRAIN info lr 0.0002979665823711246
2023-03-01 00:02:27,022 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 00:02:27,770 INFO Epoch 44 CV info cv_loss 6.111435535610851
2023-03-01 00:02:27,771 INFO Epoch 45 TRAIN info lr 0.0002979660532787311
2023-03-01 00:02:27,776 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 00:02:28,654 INFO Epoch 44 CV info cv_loss 6.1114355358111405
2023-03-01 00:02:28,654 INFO Epoch 45 TRAIN info lr 0.000297965524189156
2023-03-01 00:02:28,656 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 00:02:28,822 INFO Epoch 44 CV info cv_loss 6.1114355364184725
2023-03-01 00:02:28,822 INFO Epoch 45 TRAIN info lr 0.00029796393693734134
2023-03-01 00:02:28,827 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 00:02:29,087 INFO Epoch 44 CV info cv_loss 6.111435536414165
2023-03-01 00:02:29,087 INFO Checkpoint: save to checkpoint exp/2_27_rnnt_bias_loss_2_class_both_finetune/44.pt
2023-03-01 00:02:29,621 INFO Epoch 45 TRAIN info lr 0.00029796816966521646
2023-03-01 00:02:29,625 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 00:02:29,865 INFO Epoch 44 CV info cv_loss 6.111435535068129
2023-03-01 00:02:29,866 INFO Epoch 45 TRAIN info lr 0.0002979665823711246
2023-03-01 00:02:29,870 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 00:02:34,885 INFO Epoch 44 CV info cv_loss 6.111435537956185
2023-03-01 00:02:34,886 INFO Epoch 45 TRAIN info lr 0.00029796234971089217
2023-03-01 00:02:34,891 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 00:03:37,041 DEBUG TRAIN Batch 45/0 loss 7.410492 loss_att 8.081226 loss_ctc 10.914419 loss_rnnt 6.536896 hw_loss 0.510485 lr 0.00029796 rank 7
2023-03-01 00:03:37,046 DEBUG TRAIN Batch 45/0 loss 5.080452 loss_att 5.252616 loss_ctc 7.706025 loss_rnnt 4.460290 hw_loss 0.441850 lr 0.00029796 rank 5
2023-03-01 00:03:37,048 DEBUG TRAIN Batch 45/0 loss 6.187943 loss_att 6.245099 loss_ctc 8.980763 loss_rnnt 5.595630 hw_loss 0.390948 lr 0.00029797 rank 6
2023-03-01 00:03:37,049 DEBUG TRAIN Batch 45/0 loss 8.518873 loss_att 8.344407 loss_ctc 14.335367 loss_rnnt 7.563534 hw_loss 0.402559 lr 0.00029797 rank 2
2023-03-01 00:03:37,050 DEBUG TRAIN Batch 45/0 loss 9.100875 loss_att 9.027519 loss_ctc 13.324286 loss_rnnt 8.347334 hw_loss 0.384545 lr 0.00029797 rank 0
2023-03-01 00:03:37,051 DEBUG TRAIN Batch 45/0 loss 6.172365 loss_att 5.843657 loss_ctc 8.614615 loss_rnnt 5.645944 hw_loss 0.499742 lr 0.00029797 rank 1
2023-03-01 00:03:37,051 DEBUG TRAIN Batch 45/0 loss 8.422702 loss_att 9.027260 loss_ctc 11.174527 loss_rnnt 7.688690 hw_loss 0.461607 lr 0.00029797 rank 4
2023-03-01 00:03:37,108 DEBUG TRAIN Batch 45/0 loss 8.436417 loss_att 8.597849 loss_ctc 13.586296 loss_rnnt 7.523144 hw_loss 0.364376 lr 0.00029796 rank 3
2023-03-01 00:04:14,887 DEBUG TRAIN Batch 45/100 loss 16.922297 loss_att 20.502127 loss_ctc 30.202269 loss_rnnt 14.315128 hw_loss 0.226010 lr 0.00029795 rank 2
2023-03-01 00:04:14,899 DEBUG TRAIN Batch 45/100 loss 4.746571 loss_att 8.534091 loss_ctc 7.419167 loss_rnnt 3.503234 hw_loss 0.242789 lr 0.00029795 rank 0
2023-03-01 00:04:14,900 DEBUG TRAIN Batch 45/100 loss 3.808702 loss_att 6.037508 loss_ctc 5.162131 loss_rnnt 3.073643 hw_loss 0.204075 lr 0.00029795 rank 6
2023-03-01 00:04:14,905 DEBUG TRAIN Batch 45/100 loss 6.608484 loss_att 10.913262 loss_ctc 9.375622 loss_rnnt 5.222696 hw_loss 0.292276 lr 0.00029795 rank 7
2023-03-01 00:04:14,905 DEBUG TRAIN Batch 45/100 loss 5.549895 loss_att 8.730157 loss_ctc 7.256537 loss_rnnt 4.614287 hw_loss 0.135006 lr 0.00029795 rank 5
2023-03-01 00:04:14,905 DEBUG TRAIN Batch 45/100 loss 3.108526 loss_att 7.001767 loss_ctc 6.008511 loss_rnnt 1.861171 hw_loss 0.153829 lr 0.00029795 rank 1
2023-03-01 00:04:14,907 DEBUG TRAIN Batch 45/100 loss 12.556292 loss_att 13.714317 loss_ctc 17.636288 loss_rnnt 11.522440 hw_loss 0.234211 lr 0.00029795 rank 3
2023-03-01 00:04:14,947 DEBUG TRAIN Batch 45/100 loss 3.787056 loss_att 8.408293 loss_ctc 6.799370 loss_rnnt 2.358156 hw_loss 0.193146 lr 0.00029795 rank 4
2023-03-01 00:04:53,072 DEBUG TRAIN Batch 45/200 loss 5.084961 loss_att 7.701114 loss_ctc 10.005350 loss_rnnt 3.809188 hw_loss 0.180920 lr 0.00029794 rank 2
2023-03-01 00:04:53,084 DEBUG TRAIN Batch 45/200 loss 5.394614 loss_att 8.119394 loss_ctc 7.630024 loss_rnnt 4.421944 hw_loss 0.243111 lr 0.00029794 rank 5
2023-03-01 00:04:53,087 DEBUG TRAIN Batch 45/200 loss 3.464893 loss_att 9.045424 loss_ctc 10.715620 loss_rnnt 1.264598 hw_loss 0.220173 lr 0.00029794 rank 7
2023-03-01 00:04:53,088 DEBUG TRAIN Batch 45/200 loss 9.456800 loss_att 14.238108 loss_ctc 18.116438 loss_rnnt 7.292291 hw_loss 0.100552 lr 0.00029794 rank 3
2023-03-01 00:04:53,090 DEBUG TRAIN Batch 45/200 loss 2.084035 loss_att 5.027455 loss_ctc 2.966106 loss_rnnt 1.313883 hw_loss 0.119733 lr 0.00029794 rank 6
2023-03-01 00:04:53,092 DEBUG TRAIN Batch 45/200 loss 2.302564 loss_att 4.959703 loss_ctc 3.026707 loss_rnnt 1.535179 hw_loss 0.261384 lr 0.00029794 rank 0
2023-03-01 00:04:53,093 DEBUG TRAIN Batch 45/200 loss 8.350021 loss_att 11.534374 loss_ctc 15.380481 loss_rnnt 6.605369 hw_loss 0.319476 lr 0.00029794 rank 1
2023-03-01 00:04:53,141 DEBUG TRAIN Batch 45/200 loss 10.049039 loss_att 11.361186 loss_ctc 18.259018 loss_rnnt 8.456610 hw_loss 0.441255 lr 0.00029794 rank 4
2023-03-01 00:05:31,624 DEBUG TRAIN Batch 45/300 loss 3.247158 loss_att 6.865478 loss_ctc 5.855791 loss_rnnt 2.046082 hw_loss 0.242988 lr 0.00029793 rank 4
2023-03-01 00:05:31,634 DEBUG TRAIN Batch 45/300 loss 4.091316 loss_att 7.108098 loss_ctc 6.781335 loss_rnnt 2.963974 hw_loss 0.309970 lr 0.00029793 rank 1
2023-03-01 00:05:31,635 DEBUG TRAIN Batch 45/300 loss 5.599804 loss_att 8.268207 loss_ctc 8.017573 loss_rnnt 4.637001 hw_loss 0.200162 lr 0.00029793 rank 0
2023-03-01 00:05:31,636 DEBUG TRAIN Batch 45/300 loss 8.518187 loss_att 13.395098 loss_ctc 13.117044 loss_rnnt 6.765358 hw_loss 0.307996 lr 0.00029793 rank 5
2023-03-01 00:05:31,638 DEBUG TRAIN Batch 45/300 loss 5.330258 loss_att 9.691559 loss_ctc 10.325182 loss_rnnt 3.761173 hw_loss 0.057815 lr 0.00029793 rank 2
2023-03-01 00:05:31,639 DEBUG TRAIN Batch 45/300 loss 2.749564 loss_att 7.038267 loss_ctc 8.089104 loss_rnnt 0.987565 hw_loss 0.360599 lr 0.00029793 rank 6
2023-03-01 00:05:31,640 DEBUG TRAIN Batch 45/300 loss 8.476663 loss_att 11.255184 loss_ctc 11.157173 loss_rnnt 7.445578 hw_loss 0.221210 lr 0.00029792 rank 7
2023-03-01 00:05:31,658 DEBUG TRAIN Batch 45/300 loss 11.451683 loss_att 15.050028 loss_ctc 17.880535 loss_rnnt 9.821334 hw_loss 0.100313 lr 0.00029792 rank 3
2023-03-01 00:06:36,387 DEBUG TRAIN Batch 45/400 loss 7.078473 loss_att 10.986259 loss_ctc 16.659113 loss_rnnt 4.887601 hw_loss 0.247304 lr 0.00029791 rank 7
2023-03-01 00:06:36,390 DEBUG TRAIN Batch 45/400 loss 7.993438 loss_att 10.591255 loss_ctc 10.761923 loss_rnnt 6.893715 hw_loss 0.395678 lr 0.00029791 rank 0
2023-03-01 00:06:36,395 DEBUG TRAIN Batch 45/400 loss 8.354287 loss_att 12.339365 loss_ctc 9.645022 loss_rnnt 7.264630 hw_loss 0.226019 lr 0.00029791 rank 3
2023-03-01 00:06:36,396 DEBUG TRAIN Batch 45/400 loss 11.012096 loss_att 16.285379 loss_ctc 21.442242 loss_rnnt 8.434779 hw_loss 0.247452 lr 0.00029791 rank 2
2023-03-01 00:06:36,422 DEBUG TRAIN Batch 45/400 loss 1.619260 loss_att 4.350199 loss_ctc 2.727171 loss_rnnt 0.832011 hw_loss 0.175011 lr 0.00029792 rank 1
2023-03-01 00:06:36,425 DEBUG TRAIN Batch 45/400 loss 3.732713 loss_att 6.462317 loss_ctc 6.413629 loss_rnnt 2.650457 hw_loss 0.335399 lr 0.00029791 rank 4
2023-03-01 00:06:36,430 DEBUG TRAIN Batch 45/400 loss 4.954575 loss_att 7.019832 loss_ctc 5.261951 loss_rnnt 4.307086 hw_loss 0.362726 lr 0.00029791 rank 6
2023-03-01 00:06:36,457 DEBUG TRAIN Batch 45/400 loss 8.127947 loss_att 10.969977 loss_ctc 11.698441 loss_rnnt 6.888615 hw_loss 0.365362 lr 0.00029791 rank 5
2023-03-01 00:07:14,858 DEBUG TRAIN Batch 45/500 loss 13.912882 loss_att 15.499952 loss_ctc 23.800705 loss_rnnt 12.175509 hw_loss 0.190465 lr 0.00029790 rank 2
2023-03-01 00:07:14,862 DEBUG TRAIN Batch 45/500 loss 8.230760 loss_att 10.333167 loss_ctc 12.251260 loss_rnnt 7.135160 hw_loss 0.260721 lr 0.00029790 rank 4
2023-03-01 00:07:14,865 DEBUG TRAIN Batch 45/500 loss 5.067984 loss_att 7.183604 loss_ctc 7.652719 loss_rnnt 4.220079 hw_loss 0.150280 lr 0.00029790 rank 7
2023-03-01 00:07:14,865 DEBUG TRAIN Batch 45/500 loss 6.273173 loss_att 8.668221 loss_ctc 11.841028 loss_rnnt 4.957941 hw_loss 0.175951 lr 0.00029790 rank 3
2023-03-01 00:07:14,866 DEBUG TRAIN Batch 45/500 loss 8.662754 loss_att 10.648787 loss_ctc 12.412947 loss_rnnt 7.672143 hw_loss 0.175085 lr 0.00029790 rank 1
2023-03-01 00:07:14,870 DEBUG TRAIN Batch 45/500 loss 3.718731 loss_att 6.923696 loss_ctc 6.666736 loss_rnnt 2.581996 hw_loss 0.192517 lr 0.00029790 rank 6
2023-03-01 00:07:14,871 DEBUG TRAIN Batch 45/500 loss 6.341771 loss_att 7.632071 loss_ctc 9.397507 loss_rnnt 5.512507 hw_loss 0.307073 lr 0.00029790 rank 0
2023-03-01 00:07:14,914 DEBUG TRAIN Batch 45/500 loss 3.616762 loss_att 6.161480 loss_ctc 4.234368 loss_rnnt 2.886824 hw_loss 0.259963 lr 0.00029790 rank 5
2023-03-01 00:07:53,497 DEBUG TRAIN Batch 45/600 loss 8.342031 loss_att 9.847746 loss_ctc 13.492449 loss_rnnt 7.199902 hw_loss 0.289245 lr 0.00029789 rank 2
2023-03-01 00:07:53,507 DEBUG TRAIN Batch 45/600 loss 11.459404 loss_att 14.097332 loss_ctc 18.158514 loss_rnnt 9.927566 hw_loss 0.208196 lr 0.00029789 rank 0
2023-03-01 00:07:53,515 DEBUG TRAIN Batch 45/600 loss 11.222831 loss_att 11.767529 loss_ctc 20.685389 loss_rnnt 9.734114 hw_loss 0.221444 lr 0.00029788 rank 7
2023-03-01 00:07:53,524 DEBUG TRAIN Batch 45/600 loss 7.908114 loss_att 8.443250 loss_ctc 12.587629 loss_rnnt 6.998000 hw_loss 0.335911 lr 0.00029789 rank 4
2023-03-01 00:07:53,524 DEBUG TRAIN Batch 45/600 loss 5.571950 loss_att 7.517025 loss_ctc 9.331382 loss_rnnt 4.440936 hw_loss 0.451391 lr 0.00029789 rank 6
2023-03-01 00:07:53,526 DEBUG TRAIN Batch 45/600 loss 14.830612 loss_att 20.458593 loss_ctc 23.284311 loss_rnnt 12.425843 hw_loss 0.285023 lr 0.00029788 rank 3
2023-03-01 00:07:53,527 DEBUG TRAIN Batch 45/600 loss 8.097158 loss_att 8.863175 loss_ctc 14.408386 loss_rnnt 6.886508 hw_loss 0.404906 lr 0.00029789 rank 5
2023-03-01 00:07:53,534 DEBUG TRAIN Batch 45/600 loss 10.567154 loss_att 11.271863 loss_ctc 17.501741 loss_rnnt 9.431315 hw_loss 0.131783 lr 0.00029789 rank 1
2023-03-01 00:08:32,974 DEBUG TRAIN Batch 45/700 loss 4.290915 loss_att 7.270599 loss_ctc 8.397891 loss_rnnt 3.017565 hw_loss 0.243406 lr 0.00029788 rank 0
2023-03-01 00:08:32,991 DEBUG TRAIN Batch 45/700 loss 6.216277 loss_att 9.085783 loss_ctc 11.222609 loss_rnnt 4.841986 hw_loss 0.249148 lr 0.00029787 rank 7
2023-03-01 00:08:32,992 DEBUG TRAIN Batch 45/700 loss 6.495543 loss_att 9.073464 loss_ctc 14.356991 loss_rnnt 4.854035 hw_loss 0.145744 lr 0.00029788 rank 1
2023-03-01 00:08:32,994 DEBUG TRAIN Batch 45/700 loss 3.292432 loss_att 6.326697 loss_ctc 9.236841 loss_rnnt 1.695869 hw_loss 0.369604 lr 0.00029787 rank 6
2023-03-01 00:08:32,994 DEBUG TRAIN Batch 45/700 loss 5.924735 loss_att 7.234346 loss_ctc 8.313392 loss_rnnt 5.160199 hw_loss 0.345236 lr 0.00029787 rank 2
2023-03-01 00:08:32,996 DEBUG TRAIN Batch 45/700 loss 2.701032 loss_att 5.900417 loss_ctc 5.094354 loss_rnnt 1.564183 hw_loss 0.333492 lr 0.00029787 rank 3
2023-03-01 00:08:32,999 DEBUG TRAIN Batch 45/700 loss 2.256766 loss_att 4.591738 loss_ctc 4.693025 loss_rnnt 1.304030 hw_loss 0.301700 lr 0.00029787 rank 5
2023-03-01 00:08:33,001 DEBUG TRAIN Batch 45/700 loss 3.559970 loss_att 8.811153 loss_ctc 5.477170 loss_rnnt 2.074191 hw_loss 0.337342 lr 0.00029787 rank 4
2023-03-01 00:09:36,857 DEBUG TRAIN Batch 45/800 loss 1.673385 loss_att 4.666852 loss_ctc 3.476122 loss_rnnt 0.743875 hw_loss 0.169596 lr 0.00029786 rank 0
2023-03-01 00:09:36,861 DEBUG TRAIN Batch 45/800 loss 4.083697 loss_att 7.740025 loss_ctc 7.945112 loss_rnnt 2.678645 hw_loss 0.297996 lr 0.00029786 rank 1
2023-03-01 00:09:36,864 DEBUG TRAIN Batch 45/800 loss 7.187323 loss_att 9.058115 loss_ctc 10.427330 loss_rnnt 6.378907 hw_loss 0.004228 lr 0.00029786 rank 2
2023-03-01 00:09:36,865 DEBUG TRAIN Batch 45/800 loss 7.773655 loss_att 10.716750 loss_ctc 11.493770 loss_rnnt 6.551685 hw_loss 0.257504 lr 0.00029786 rank 7
2023-03-01 00:09:36,866 DEBUG TRAIN Batch 45/800 loss 6.631064 loss_att 10.062525 loss_ctc 11.069595 loss_rnnt 5.246452 hw_loss 0.199717 lr 0.00029786 rank 6
2023-03-01 00:09:36,871 DEBUG TRAIN Batch 45/800 loss 5.353708 loss_att 8.279557 loss_ctc 8.819742 loss_rnnt 4.187838 hw_loss 0.222303 lr 0.00029786 rank 4
2023-03-01 00:09:36,907 DEBUG TRAIN Batch 45/800 loss 1.413447 loss_att 4.234735 loss_ctc 3.151935 loss_rnnt 0.504274 hw_loss 0.212095 lr 0.00029786 rank 3
2023-03-01 00:09:36,916 DEBUG TRAIN Batch 45/800 loss 8.081998 loss_att 15.496930 loss_ctc 15.703807 loss_rnnt 5.492579 hw_loss 0.169108 lr 0.00029786 rank 5
2023-03-01 00:10:15,409 DEBUG TRAIN Batch 45/900 loss 6.990721 loss_att 9.562022 loss_ctc 9.972561 loss_rnnt 6.015805 hw_loss 0.118268 lr 0.00029785 rank 1
2023-03-01 00:10:15,410 DEBUG TRAIN Batch 45/900 loss 6.159543 loss_att 10.371781 loss_ctc 11.190260 loss_rnnt 4.587455 hw_loss 0.110396 lr 0.00029785 rank 5
2023-03-01 00:10:15,411 DEBUG TRAIN Batch 45/900 loss 3.585440 loss_att 5.586045 loss_ctc 4.447623 loss_rnnt 2.986485 hw_loss 0.157266 lr 0.00029785 rank 6
2023-03-01 00:10:15,420 DEBUG TRAIN Batch 45/900 loss 4.888524 loss_att 7.097732 loss_ctc 7.035395 loss_rnnt 4.105512 hw_loss 0.102978 lr 0.00029785 rank 4
2023-03-01 00:10:15,431 DEBUG TRAIN Batch 45/900 loss 3.493660 loss_att 9.226248 loss_ctc 5.734947 loss_rnnt 1.960815 hw_loss 0.164043 lr 0.00029785 rank 0
2023-03-01 00:10:15,432 DEBUG TRAIN Batch 45/900 loss 2.244301 loss_att 5.435744 loss_ctc 3.651601 loss_rnnt 1.350588 hw_loss 0.127095 lr 0.00029785 rank 2
2023-03-01 00:10:15,452 DEBUG TRAIN Batch 45/900 loss 9.174279 loss_att 12.946587 loss_ctc 17.513075 loss_rnnt 7.181145 hw_loss 0.237813 lr 0.00029784 rank 3
2023-03-01 00:10:15,481 DEBUG TRAIN Batch 45/900 loss 1.595299 loss_att 4.112945 loss_ctc 2.469900 loss_rnnt 0.824598 hw_loss 0.282299 lr 0.00029784 rank 7
2023-03-01 00:10:54,082 DEBUG TRAIN Batch 45/1000 loss 10.998083 loss_att 15.387156 loss_ctc 18.562244 loss_rnnt 9.009357 hw_loss 0.191918 lr 0.00029784 rank 1
2023-03-01 00:10:54,082 DEBUG TRAIN Batch 45/1000 loss 3.996429 loss_att 6.352459 loss_ctc 6.162077 loss_rnnt 3.106611 hw_loss 0.243485 lr 0.00029784 rank 0
2023-03-01 00:10:54,091 DEBUG TRAIN Batch 45/1000 loss 4.788219 loss_att 6.721110 loss_ctc 6.035924 loss_rnnt 4.168445 hw_loss 0.125317 lr 0.00029783 rank 3
2023-03-01 00:10:54,097 DEBUG TRAIN Batch 45/1000 loss 9.534215 loss_att 13.036779 loss_ctc 13.907377 loss_rnnt 8.158918 hw_loss 0.171929 lr 0.00029783 rank 5
2023-03-01 00:10:54,100 DEBUG TRAIN Batch 45/1000 loss 3.246780 loss_att 5.232456 loss_ctc 4.404412 loss_rnnt 2.626557 hw_loss 0.128881 lr 0.00029783 rank 2
2023-03-01 00:10:54,105 DEBUG TRAIN Batch 45/1000 loss 10.220350 loss_att 12.986262 loss_ctc 16.766188 loss_rnnt 8.697452 hw_loss 0.181760 lr 0.00029783 rank 7
2023-03-01 00:10:54,108 DEBUG TRAIN Batch 45/1000 loss 2.374930 loss_att 5.397844 loss_ctc 5.564344 loss_rnnt 1.143226 hw_loss 0.378499 lr 0.00029783 rank 4
2023-03-01 00:10:54,123 DEBUG TRAIN Batch 45/1000 loss 4.206333 loss_att 7.317123 loss_ctc 7.837992 loss_rnnt 2.980523 hw_loss 0.223932 lr 0.00029783 rank 6
2023-03-01 00:11:57,398 DEBUG TRAIN Batch 45/1100 loss 4.808216 loss_att 8.117071 loss_ctc 9.142196 loss_rnnt 3.412697 hw_loss 0.292281 lr 0.00029782 rank 2
2023-03-01 00:11:57,407 DEBUG TRAIN Batch 45/1100 loss 13.341342 loss_att 17.153532 loss_ctc 20.163916 loss_rnnt 11.443641 hw_loss 0.422975 lr 0.00029782 rank 1
2023-03-01 00:11:57,410 DEBUG TRAIN Batch 45/1100 loss 5.102213 loss_att 8.786850 loss_ctc 8.356741 loss_rnnt 3.872797 hw_loss 0.109785 lr 0.00029782 rank 7
2023-03-01 00:11:57,410 DEBUG TRAIN Batch 45/1100 loss 3.777789 loss_att 6.959622 loss_ctc 8.472232 loss_rnnt 2.411092 hw_loss 0.195758 lr 0.00029782 rank 5
2023-03-01 00:11:57,412 DEBUG TRAIN Batch 45/1100 loss 2.168404 loss_att 4.574475 loss_ctc 3.956061 loss_rnnt 1.190397 hw_loss 0.484573 lr 0.00029782 rank 0
2023-03-01 00:11:57,411 DEBUG TRAIN Batch 45/1100 loss 4.095076 loss_att 5.302248 loss_ctc 9.336333 loss_rnnt 3.092264 hw_loss 0.117266 lr 0.00029782 rank 3
2023-03-01 00:11:57,414 DEBUG TRAIN Batch 45/1100 loss 3.811266 loss_att 6.689653 loss_ctc 9.381744 loss_rnnt 2.338766 hw_loss 0.288924 lr 0.00029782 rank 6
2023-03-01 00:11:57,422 DEBUG TRAIN Batch 45/1100 loss 5.467852 loss_att 8.595510 loss_ctc 10.231513 loss_rnnt 4.049853 hw_loss 0.294961 lr 0.00029782 rank 4
2023-03-01 00:12:36,291 DEBUG TRAIN Batch 45/1200 loss 4.980149 loss_att 6.682954 loss_ctc 9.245180 loss_rnnt 3.966205 hw_loss 0.196335 lr 0.00029781 rank 5
2023-03-01 00:12:36,293 DEBUG TRAIN Batch 45/1200 loss 9.585513 loss_att 10.523196 loss_ctc 14.521099 loss_rnnt 8.552979 hw_loss 0.350474 lr 0.00029780 rank 3
2023-03-01 00:12:36,299 DEBUG TRAIN Batch 45/1200 loss 3.580286 loss_att 5.870462 loss_ctc 7.847965 loss_rnnt 2.480846 hw_loss 0.135713 lr 0.00029781 rank 6
2023-03-01 00:12:36,300 DEBUG TRAIN Batch 45/1200 loss 4.604421 loss_att 5.417932 loss_ctc 8.641464 loss_rnnt 3.663562 hw_loss 0.449784 lr 0.00029781 rank 1
2023-03-01 00:12:36,303 DEBUG TRAIN Batch 45/1200 loss 4.992256 loss_att 7.572563 loss_ctc 10.034310 loss_rnnt 3.647027 hw_loss 0.294176 lr 0.00029781 rank 0
2023-03-01 00:12:36,305 DEBUG TRAIN Batch 45/1200 loss 8.108108 loss_att 10.199190 loss_ctc 12.499653 loss_rnnt 6.996866 hw_loss 0.201535 lr 0.00029780 rank 7
2023-03-01 00:12:36,306 DEBUG TRAIN Batch 45/1200 loss 7.866252 loss_att 9.398684 loss_ctc 12.852138 loss_rnnt 6.751660 hw_loss 0.268725 lr 0.00029781 rank 2
2023-03-01 00:12:36,309 DEBUG TRAIN Batch 45/1200 loss 4.934044 loss_att 5.769134 loss_ctc 8.569409 loss_rnnt 4.087451 hw_loss 0.365364 lr 0.00029781 rank 4
2023-03-01 00:13:14,559 DEBUG TRAIN Batch 45/1300 loss 4.139104 loss_att 7.396988 loss_ctc 9.424833 loss_rnnt 2.663284 hw_loss 0.224023 lr 0.00029779 rank 2
2023-03-01 00:13:14,572 DEBUG TRAIN Batch 45/1300 loss 1.607284 loss_att 4.949998 loss_ctc 3.863687 loss_rnnt 0.497706 hw_loss 0.262839 lr 0.00029779 rank 3
2023-03-01 00:13:14,574 DEBUG TRAIN Batch 45/1300 loss 2.241920 loss_att 5.803519 loss_ctc 3.097814 loss_rnnt 1.206539 hw_loss 0.391766 lr 0.00029779 rank 4
2023-03-01 00:13:14,574 DEBUG TRAIN Batch 45/1300 loss 5.328695 loss_att 10.879194 loss_ctc 14.356494 loss_rnnt 2.882846 hw_loss 0.247580 lr 0.00029779 rank 6
2023-03-01 00:13:14,575 DEBUG TRAIN Batch 45/1300 loss 5.338433 loss_att 5.496120 loss_ctc 8.651719 loss_rnnt 4.599150 hw_loss 0.498701 lr 0.00029779 rank 7
2023-03-01 00:13:14,575 DEBUG TRAIN Batch 45/1300 loss 2.168288 loss_att 7.199645 loss_ctc 3.590097 loss_rnnt 0.856340 hw_loss 0.217691 lr 0.00029779 rank 5
2023-03-01 00:13:14,581 DEBUG TRAIN Batch 45/1300 loss 4.811947 loss_att 4.949152 loss_ctc 7.070621 loss_rnnt 4.287289 hw_loss 0.367613 lr 0.00029780 rank 0
2023-03-01 00:13:14,622 DEBUG TRAIN Batch 45/1300 loss 4.482929 loss_att 7.964553 loss_ctc 10.946864 loss_rnnt 2.850463 hw_loss 0.139281 lr 0.00029780 rank 1
2023-03-01 00:13:53,855 DEBUG TRAIN Batch 45/1400 loss 5.537437 loss_att 9.280030 loss_ctc 11.657874 loss_rnnt 3.970872 hw_loss 0.003727 lr 0.00029778 rank 0
2023-03-01 00:13:53,857 DEBUG TRAIN Batch 45/1400 loss 4.492268 loss_att 10.385084 loss_ctc 8.952488 loss_rnnt 2.542206 hw_loss 0.331505 lr 0.00029778 rank 3
2023-03-01 00:13:53,861 DEBUG TRAIN Batch 45/1400 loss 6.932808 loss_att 10.666214 loss_ctc 13.256740 loss_rnnt 5.235752 hw_loss 0.200970 lr 0.00029778 rank 4
2023-03-01 00:13:53,867 DEBUG TRAIN Batch 45/1400 loss 8.480234 loss_att 12.875567 loss_ctc 13.256244 loss_rnnt 6.885665 hw_loss 0.147565 lr 0.00029778 rank 2
2023-03-01 00:13:53,869 DEBUG TRAIN Batch 45/1400 loss 2.971876 loss_att 6.449955 loss_ctc 3.861399 loss_rnnt 2.058012 hw_loss 0.186833 lr 0.00029778 rank 6
2023-03-01 00:13:53,871 DEBUG TRAIN Batch 45/1400 loss 9.241945 loss_att 11.149170 loss_ctc 12.401833 loss_rnnt 8.437010 hw_loss 0.004071 lr 0.00029778 rank 1
2023-03-01 00:13:53,872 DEBUG TRAIN Batch 45/1400 loss 3.679055 loss_att 7.589998 loss_ctc 4.393940 loss_rnnt 2.769764 hw_loss 0.059597 lr 0.00029778 rank 7
2023-03-01 00:13:53,915 DEBUG TRAIN Batch 45/1400 loss 5.019023 loss_att 9.150045 loss_ctc 10.598384 loss_rnnt 3.354000 hw_loss 0.177947 lr 0.00029778 rank 5
2023-03-01 00:14:58,536 DEBUG TRAIN Batch 45/1500 loss 2.121748 loss_att 5.170551 loss_ctc 2.471367 loss_rnnt 1.242056 hw_loss 0.418715 lr 0.00029777 rank 4
2023-03-01 00:14:58,541 DEBUG TRAIN Batch 45/1500 loss 5.672196 loss_att 8.388636 loss_ctc 7.666578 loss_rnnt 4.749597 hw_loss 0.212612 lr 0.00029777 rank 6
2023-03-01 00:14:58,544 DEBUG TRAIN Batch 45/1500 loss 13.448499 loss_att 17.082392 loss_ctc 20.371677 loss_rnnt 11.663220 hw_loss 0.253892 lr 0.00029777 rank 1
2023-03-01 00:14:58,562 DEBUG TRAIN Batch 45/1500 loss 8.684512 loss_att 9.887685 loss_ctc 9.043955 loss_rnnt 8.356483 hw_loss 0.074002 lr 0.00029777 rank 2
2023-03-01 00:14:58,567 DEBUG TRAIN Batch 45/1500 loss 3.051615 loss_att 5.281474 loss_ctc 5.545780 loss_rnnt 2.141818 hw_loss 0.246131 lr 0.00029777 rank 0
2023-03-01 00:14:58,567 DEBUG TRAIN Batch 45/1500 loss 13.452082 loss_att 15.896992 loss_ctc 19.370501 loss_rnnt 12.063579 hw_loss 0.206998 lr 0.00029776 rank 3
2023-03-01 00:14:58,568 DEBUG TRAIN Batch 45/1500 loss 11.156514 loss_att 13.848671 loss_ctc 18.170288 loss_rnnt 9.552059 hw_loss 0.245350 lr 0.00029777 rank 5
2023-03-01 00:14:58,611 DEBUG TRAIN Batch 45/1500 loss 3.155417 loss_att 6.908747 loss_ctc 4.756736 loss_rnnt 2.079673 hw_loss 0.209191 lr 0.00029777 rank 7
2023-03-01 00:15:38,204 DEBUG TRAIN Batch 45/1600 loss 7.837986 loss_att 12.295450 loss_ctc 14.093560 loss_rnnt 5.963652 hw_loss 0.278933 lr 0.00029775 rank 6
2023-03-01 00:15:38,222 DEBUG TRAIN Batch 45/1600 loss 9.503816 loss_att 11.197161 loss_ctc 14.394432 loss_rnnt 8.340700 hw_loss 0.323183 lr 0.00029775 rank 3
2023-03-01 00:15:38,225 DEBUG TRAIN Batch 45/1600 loss 5.167888 loss_att 9.174386 loss_ctc 10.726086 loss_rnnt 3.474542 hw_loss 0.283037 lr 0.00029776 rank 0
2023-03-01 00:15:38,225 DEBUG TRAIN Batch 45/1600 loss 4.072564 loss_att 6.297031 loss_ctc 6.917957 loss_rnnt 3.087754 hw_loss 0.300994 lr 0.00029775 rank 5
2023-03-01 00:15:38,229 DEBUG TRAIN Batch 45/1600 loss 5.069064 loss_att 6.195702 loss_ctc 7.107872 loss_rnnt 4.426224 hw_loss 0.273133 lr 0.00029775 rank 4
2023-03-01 00:15:38,229 DEBUG TRAIN Batch 45/1600 loss 6.142202 loss_att 10.496517 loss_ctc 12.990653 loss_rnnt 4.207622 hw_loss 0.282358 lr 0.00029776 rank 1
2023-03-01 00:15:38,278 DEBUG TRAIN Batch 45/1600 loss 4.111505 loss_att 6.227705 loss_ctc 8.309055 loss_rnnt 2.989533 hw_loss 0.260734 lr 0.00029775 rank 2
2023-03-01 00:15:38,577 DEBUG TRAIN Batch 45/1600 loss 10.525236 loss_att 13.695433 loss_ctc 19.721191 loss_rnnt 8.579467 hw_loss 0.160503 lr 0.00029775 rank 7
2023-03-01 00:16:18,656 DEBUG TRAIN Batch 45/1700 loss 4.926210 loss_att 7.180398 loss_ctc 7.952837 loss_rnnt 3.925679 hw_loss 0.274020 lr 0.00029774 rank 5
2023-03-01 00:16:18,674 DEBUG TRAIN Batch 45/1700 loss 9.019179 loss_att 12.210310 loss_ctc 18.023449 loss_rnnt 7.060291 hw_loss 0.225173 lr 0.00029774 rank 0
2023-03-01 00:16:18,674 DEBUG TRAIN Batch 45/1700 loss 4.492249 loss_att 6.840567 loss_ctc 7.570526 loss_rnnt 3.542990 hw_loss 0.129670 lr 0.00029774 rank 1
2023-03-01 00:16:18,676 DEBUG TRAIN Batch 45/1700 loss 6.251790 loss_att 8.888272 loss_ctc 11.388560 loss_rnnt 4.899572 hw_loss 0.262535 lr 0.00029774 rank 3
2023-03-01 00:16:18,676 DEBUG TRAIN Batch 45/1700 loss 4.854976 loss_att 9.472535 loss_ctc 9.269477 loss_rnnt 3.178345 hw_loss 0.308473 lr 0.00029774 rank 2
2023-03-01 00:16:18,699 DEBUG TRAIN Batch 45/1700 loss 2.070063 loss_att 5.088945 loss_ctc 4.811810 loss_rnnt 0.970126 hw_loss 0.244865 lr 0.00029774 rank 7
2023-03-01 00:16:18,710 DEBUG TRAIN Batch 45/1700 loss 3.801753 loss_att 5.661056 loss_ctc 5.680503 loss_rnnt 3.002335 hw_loss 0.331981 lr 0.00029774 rank 4
2023-03-01 00:16:18,718 DEBUG TRAIN Batch 45/1700 loss 1.706467 loss_att 5.128375 loss_ctc 3.768728 loss_rnnt 0.554759 hw_loss 0.360673 lr 0.00029774 rank 6
2023-03-01 00:17:23,375 DEBUG TRAIN Batch 45/1800 loss 4.946277 loss_att 8.116677 loss_ctc 8.147086 loss_rnnt 3.725186 hw_loss 0.300443 lr 0.00029773 rank 4
2023-03-01 00:17:23,377 DEBUG TRAIN Batch 45/1800 loss 7.364297 loss_att 8.899315 loss_ctc 10.645031 loss_rnnt 6.407488 hw_loss 0.398200 lr 0.00029772 rank 3
2023-03-01 00:17:23,379 DEBUG TRAIN Batch 45/1800 loss 8.570922 loss_att 11.655416 loss_ctc 13.708536 loss_rnnt 7.121476 hw_loss 0.276621 lr 0.00029773 rank 5
2023-03-01 00:17:23,382 DEBUG TRAIN Batch 45/1800 loss 2.912252 loss_att 5.139701 loss_ctc 7.808179 loss_rnnt 1.669623 hw_loss 0.270653 lr 0.00029773 rank 6
2023-03-01 00:17:23,383 DEBUG TRAIN Batch 45/1800 loss 8.377625 loss_att 10.801599 loss_ctc 11.542656 loss_rnnt 7.338429 hw_loss 0.248241 lr 0.00029773 rank 0
2023-03-01 00:17:23,385 DEBUG TRAIN Batch 45/1800 loss 6.143830 loss_att 7.421352 loss_ctc 12.242960 loss_rnnt 4.865977 hw_loss 0.392121 lr 0.00029773 rank 1
2023-03-01 00:17:23,385 DEBUG TRAIN Batch 45/1800 loss 8.760916 loss_att 11.334255 loss_ctc 16.591846 loss_rnnt 7.030783 hw_loss 0.321263 lr 0.00029773 rank 2
2023-03-01 00:17:23,421 DEBUG TRAIN Batch 45/1800 loss 4.722868 loss_att 7.236923 loss_ctc 7.926103 loss_rnnt 3.599497 hw_loss 0.362739 lr 0.00029773 rank 7
2023-03-01 00:18:02,287 DEBUG TRAIN Batch 45/1900 loss 4.505365 loss_att 7.978788 loss_ctc 12.823069 loss_rnnt 2.665524 hw_loss 0.067741 lr 0.00029772 rank 1
2023-03-01 00:18:02,290 DEBUG TRAIN Batch 45/1900 loss 6.025832 loss_att 8.590542 loss_ctc 8.076418 loss_rnnt 5.138153 hw_loss 0.189984 lr 0.00029771 rank 3
2023-03-01 00:18:02,296 DEBUG TRAIN Batch 45/1900 loss 7.600973 loss_att 8.449483 loss_ctc 12.512350 loss_rnnt 6.634967 hw_loss 0.265225 lr 0.00029771 rank 7
2023-03-01 00:18:02,299 DEBUG TRAIN Batch 45/1900 loss 4.449656 loss_att 4.843935 loss_ctc 6.584127 loss_rnnt 3.873931 hw_loss 0.398009 lr 0.00029771 rank 2
2023-03-01 00:18:02,304 DEBUG TRAIN Batch 45/1900 loss 6.494149 loss_att 6.177505 loss_ctc 8.309120 loss_rnnt 6.114723 hw_loss 0.376422 lr 0.00029772 rank 6
2023-03-01 00:18:02,305 DEBUG TRAIN Batch 45/1900 loss 2.363255 loss_att 4.842946 loss_ctc 4.793729 loss_rnnt 1.406660 hw_loss 0.256112 lr 0.00029772 rank 0
2023-03-01 00:18:02,343 DEBUG TRAIN Batch 45/1900 loss 8.625003 loss_att 13.597120 loss_ctc 13.066933 loss_rnnt 6.967165 hw_loss 0.133418 lr 0.00029772 rank 4
2023-03-01 00:18:02,349 DEBUG TRAIN Batch 45/1900 loss 4.126917 loss_att 5.156875 loss_ctc 6.075211 loss_rnnt 3.547517 hw_loss 0.213068 lr 0.00029771 rank 5
2023-03-01 00:18:41,294 DEBUG TRAIN Batch 45/2000 loss 4.433752 loss_att 6.880911 loss_ctc 8.465251 loss_rnnt 3.331641 hw_loss 0.140898 lr 0.00029770 rank 5
2023-03-01 00:18:41,297 DEBUG TRAIN Batch 45/2000 loss 3.627189 loss_att 6.751045 loss_ctc 5.550365 loss_rnnt 2.550338 hw_loss 0.366857 lr 0.00029770 rank 0
2023-03-01 00:18:41,301 DEBUG TRAIN Batch 45/2000 loss 6.694597 loss_att 11.035234 loss_ctc 9.544467 loss_rnnt 5.296116 hw_loss 0.281945 lr 0.00029770 rank 1
2023-03-01 00:18:41,302 DEBUG TRAIN Batch 45/2000 loss 7.970033 loss_att 10.481519 loss_ctc 10.649697 loss_rnnt 6.960687 hw_loss 0.280799 lr 0.00029770 rank 7
2023-03-01 00:18:41,303 DEBUG TRAIN Batch 45/2000 loss 1.629610 loss_att 4.141194 loss_ctc 1.605800 loss_rnnt 0.974351 hw_loss 0.292721 lr 0.00029770 rank 6
2023-03-01 00:18:41,303 DEBUG TRAIN Batch 45/2000 loss 2.531734 loss_att 6.537892 loss_ctc 6.257844 loss_rnnt 1.164764 hw_loss 0.129232 lr 0.00029770 rank 4
2023-03-01 00:18:41,303 DEBUG TRAIN Batch 45/2000 loss 1.858859 loss_att 4.531087 loss_ctc 2.651025 loss_rnnt 1.100887 hw_loss 0.221070 lr 0.00029770 rank 3
2023-03-01 00:18:41,311 DEBUG TRAIN Batch 45/2000 loss 5.400371 loss_att 5.959816 loss_ctc 7.488331 loss_rnnt 4.816002 hw_loss 0.363908 lr 0.00029770 rank 2
2023-03-01 00:19:21,330 DEBUG TRAIN Batch 45/2100 loss 1.107305 loss_att 3.228945 loss_ctc 1.362151 loss_rnnt 0.454935 hw_loss 0.363868 lr 0.00029769 rank 7
2023-03-01 00:19:21,331 DEBUG TRAIN Batch 45/2100 loss 8.005300 loss_att 14.166567 loss_ctc 15.729910 loss_rnnt 5.556754 hw_loss 0.349395 lr 0.00029769 rank 1
2023-03-01 00:19:21,341 DEBUG TRAIN Batch 45/2100 loss 4.567261 loss_att 11.103317 loss_ctc 6.337766 loss_rnnt 2.908478 hw_loss 0.216573 lr 0.00029769 rank 0
2023-03-01 00:19:21,344 DEBUG TRAIN Batch 45/2100 loss 6.327835 loss_att 10.959213 loss_ctc 7.970201 loss_rnnt 5.147213 hw_loss 0.066309 lr 0.00029769 rank 2
2023-03-01 00:19:21,348 DEBUG TRAIN Batch 45/2100 loss 5.789753 loss_att 8.111943 loss_ctc 10.583419 loss_rnnt 4.573472 hw_loss 0.211289 lr 0.00029769 rank 4
2023-03-01 00:19:21,351 DEBUG TRAIN Batch 45/2100 loss 13.629993 loss_att 15.184082 loss_ctc 21.915878 loss_rnnt 12.165810 hw_loss 0.091091 lr 0.00029768 rank 3
2023-03-01 00:19:21,352 DEBUG TRAIN Batch 45/2100 loss 9.779230 loss_att 14.264712 loss_ctc 18.536665 loss_rnnt 7.674284 hw_loss 0.075360 lr 0.00029769 rank 5
2023-03-01 00:19:21,386 DEBUG TRAIN Batch 45/2100 loss 3.424396 loss_att 5.085746 loss_ctc 3.452168 loss_rnnt 2.952280 hw_loss 0.255268 lr 0.00029769 rank 6
2023-03-01 00:20:25,165 DEBUG TRAIN Batch 45/2200 loss 6.103641 loss_att 10.138522 loss_ctc 11.898592 loss_rnnt 4.416432 hw_loss 0.201698 lr 0.00029767 rank 7
2023-03-01 00:20:25,169 DEBUG TRAIN Batch 45/2200 loss 12.908656 loss_att 19.752243 loss_ctc 22.511681 loss_rnnt 10.170745 hw_loss 0.166484 lr 0.00029768 rank 6
2023-03-01 00:20:25,182 DEBUG TRAIN Batch 45/2200 loss 13.877256 loss_att 14.740950 loss_ctc 19.372919 loss_rnnt 12.817795 hw_loss 0.288690 lr 0.00029768 rank 1
2023-03-01 00:20:25,183 DEBUG TRAIN Batch 45/2200 loss 3.710688 loss_att 5.596744 loss_ctc 2.506216 loss_rnnt 3.411119 hw_loss 0.155538 lr 0.00029768 rank 0
2023-03-01 00:20:25,185 DEBUG TRAIN Batch 45/2200 loss 2.113347 loss_att 4.993834 loss_ctc 4.524122 loss_rnnt 1.008618 hw_loss 0.388491 lr 0.00029767 rank 5
2023-03-01 00:20:25,186 DEBUG TRAIN Batch 45/2200 loss 3.237762 loss_att 6.004440 loss_ctc 7.458270 loss_rnnt 1.983778 hw_loss 0.258590 lr 0.00029767 rank 2
2023-03-01 00:20:25,189 DEBUG TRAIN Batch 45/2200 loss 6.397350 loss_att 9.103593 loss_ctc 9.885644 loss_rnnt 5.212359 hw_loss 0.334943 lr 0.00029767 rank 3
2023-03-01 00:20:25,241 DEBUG TRAIN Batch 45/2200 loss 6.165303 loss_att 8.981539 loss_ctc 6.243308 loss_rnnt 5.430460 hw_loss 0.302240 lr 0.00029768 rank 4
2023-03-01 00:21:04,136 DEBUG TRAIN Batch 45/2300 loss 5.562974 loss_att 8.186382 loss_ctc 11.024257 loss_rnnt 4.174675 hw_loss 0.253964 lr 0.00029766 rank 1
2023-03-01 00:21:04,146 DEBUG TRAIN Batch 45/2300 loss 4.174949 loss_att 6.552388 loss_ctc 5.437937 loss_rnnt 3.422740 hw_loss 0.203104 lr 0.00029766 rank 2
2023-03-01 00:21:04,149 DEBUG TRAIN Batch 45/2300 loss 4.114163 loss_att 5.722294 loss_ctc 6.666787 loss_rnnt 3.418397 hw_loss 0.063355 lr 0.00029766 rank 0
2023-03-01 00:21:04,150 DEBUG TRAIN Batch 45/2300 loss 8.656296 loss_att 11.931842 loss_ctc 12.486255 loss_rnnt 7.343395 hw_loss 0.275870 lr 0.00029766 rank 4
2023-03-01 00:21:04,153 DEBUG TRAIN Batch 45/2300 loss 5.300898 loss_att 7.899155 loss_ctc 9.825298 loss_rnnt 4.018831 hw_loss 0.298429 lr 0.00029766 rank 3
2023-03-01 00:21:04,156 DEBUG TRAIN Batch 45/2300 loss 8.037036 loss_att 11.691831 loss_ctc 12.353225 loss_rnnt 6.618723 hw_loss 0.209741 lr 0.00029766 rank 7
2023-03-01 00:21:04,157 DEBUG TRAIN Batch 45/2300 loss 4.842968 loss_att 7.057416 loss_ctc 6.077619 loss_rnnt 4.110857 hw_loss 0.233628 lr 0.00029766 rank 6
2023-03-01 00:21:04,160 DEBUG TRAIN Batch 45/2300 loss 8.997708 loss_att 12.656941 loss_ctc 15.066580 loss_rnnt 7.344971 hw_loss 0.209450 lr 0.00029766 rank 5
2023-03-01 00:21:43,346 DEBUG TRAIN Batch 45/2400 loss 3.399972 loss_att 5.611980 loss_ctc 4.289239 loss_rnnt 2.686306 hw_loss 0.286305 lr 0.00029765 rank 4
2023-03-01 00:21:43,351 DEBUG TRAIN Batch 45/2400 loss 12.856908 loss_att 12.561382 loss_ctc 16.750900 loss_rnnt 12.196547 hw_loss 0.375502 lr 0.00029765 rank 6
2023-03-01 00:21:43,356 DEBUG TRAIN Batch 45/2400 loss 6.893452 loss_att 9.923621 loss_ctc 12.239470 loss_rnnt 5.361704 hw_loss 0.399208 lr 0.00029765 rank 7
2023-03-01 00:21:43,356 DEBUG TRAIN Batch 45/2400 loss 3.068419 loss_att 6.767694 loss_ctc 7.178639 loss_rnnt 1.717342 hw_loss 0.118485 lr 0.00029765 rank 0
2023-03-01 00:21:43,358 DEBUG TRAIN Batch 45/2400 loss 5.280504 loss_att 7.238287 loss_ctc 4.933594 loss_rnnt 4.844851 hw_loss 0.169407 lr 0.00029765 rank 2
2023-03-01 00:21:43,359 DEBUG TRAIN Batch 45/2400 loss 8.490686 loss_att 10.074862 loss_ctc 16.314503 loss_rnnt 7.006143 hw_loss 0.233499 lr 0.00029765 rank 1
2023-03-01 00:21:43,370 DEBUG TRAIN Batch 45/2400 loss 6.289764 loss_att 7.517964 loss_ctc 7.332658 loss_rnnt 5.762643 hw_loss 0.267054 lr 0.00029764 rank 3
2023-03-01 00:21:43,378 DEBUG TRAIN Batch 45/2400 loss 3.229904 loss_att 6.739158 loss_ctc 5.415574 loss_rnnt 2.136872 hw_loss 0.187047 lr 0.00029765 rank 5
2023-03-01 00:22:48,446 DEBUG TRAIN Batch 45/2500 loss 2.248724 loss_att 4.423296 loss_ctc 5.032224 loss_rnnt 1.307814 hw_loss 0.252866 lr 0.00029764 rank 2
2023-03-01 00:22:48,445 DEBUG TRAIN Batch 45/2500 loss 10.907412 loss_att 13.147046 loss_ctc 16.898546 loss_rnnt 9.453658 hw_loss 0.388142 lr 0.00029764 rank 6
2023-03-01 00:22:48,449 DEBUG TRAIN Batch 45/2500 loss 7.719545 loss_att 12.073505 loss_ctc 15.217494 loss_rnnt 5.703194 hw_loss 0.273434 lr 0.00029764 rank 0
2023-03-01 00:22:48,450 DEBUG TRAIN Batch 45/2500 loss 8.542602 loss_att 10.587443 loss_ctc 11.392505 loss_rnnt 7.645700 hw_loss 0.202397 lr 0.00029763 rank 7
2023-03-01 00:22:48,451 DEBUG TRAIN Batch 45/2500 loss 4.743251 loss_att 9.063305 loss_ctc 9.683735 loss_rnnt 3.120430 hw_loss 0.187650 lr 0.00029764 rank 4
2023-03-01 00:22:48,454 DEBUG TRAIN Batch 45/2500 loss 6.042618 loss_att 9.641763 loss_ctc 15.378581 loss_rnnt 3.870335 hw_loss 0.389360 lr 0.00029763 rank 5
2023-03-01 00:22:48,467 DEBUG TRAIN Batch 45/2500 loss 6.476907 loss_att 11.027575 loss_ctc 8.433338 loss_rnnt 5.182859 hw_loss 0.230733 lr 0.00029764 rank 1
2023-03-01 00:22:48,493 DEBUG TRAIN Batch 45/2500 loss 3.357985 loss_att 6.494235 loss_ctc 6.752192 loss_rnnt 2.146416 hw_loss 0.247047 lr 0.00029763 rank 3
2023-03-01 00:23:27,370 DEBUG TRAIN Batch 45/2600 loss 1.953432 loss_att 6.257703 loss_ctc 4.887595 loss_rnnt 0.549039 hw_loss 0.285594 lr 0.00029762 rank 2
2023-03-01 00:23:27,385 DEBUG TRAIN Batch 45/2600 loss 2.524326 loss_att 3.929483 loss_ctc 2.122154 loss_rnnt 2.096834 hw_loss 0.375156 lr 0.00029762 rank 0
2023-03-01 00:23:27,389 DEBUG TRAIN Batch 45/2600 loss 6.468210 loss_att 9.579597 loss_ctc 10.193451 loss_rnnt 5.157996 hw_loss 0.358570 lr 0.00029762 rank 1
2023-03-01 00:23:27,391 DEBUG TRAIN Batch 45/2600 loss 8.339874 loss_att 12.742261 loss_ctc 17.304768 loss_rnnt 6.143550 hw_loss 0.225990 lr 0.00029762 rank 6
2023-03-01 00:23:27,392 DEBUG TRAIN Batch 45/2600 loss 4.355331 loss_att 7.746889 loss_ctc 5.438441 loss_rnnt 3.448719 hw_loss 0.157285 lr 0.00029762 rank 4
2023-03-01 00:23:27,393 DEBUG TRAIN Batch 45/2600 loss 4.674709 loss_att 5.336962 loss_ctc 8.679550 loss_rnnt 3.774544 hw_loss 0.438252 lr 0.00029762 rank 5
2023-03-01 00:23:27,394 DEBUG TRAIN Batch 45/2600 loss 12.186870 loss_att 14.024451 loss_ctc 18.969162 loss_rnnt 10.777717 hw_loss 0.257494 lr 0.00029762 rank 3
2023-03-01 00:23:27,395 DEBUG TRAIN Batch 45/2600 loss 4.174976 loss_att 6.653142 loss_ctc 6.314791 loss_rnnt 3.235188 hw_loss 0.297837 lr 0.00029762 rank 7
2023-03-01 00:24:06,203 DEBUG TRAIN Batch 45/2700 loss 2.012275 loss_att 5.788199 loss_ctc 3.869943 loss_rnnt 0.887028 hw_loss 0.229448 lr 0.00029761 rank 0
2023-03-01 00:24:06,208 DEBUG TRAIN Batch 45/2700 loss 6.190567 loss_att 9.949792 loss_ctc 7.023945 loss_rnnt 5.176454 hw_loss 0.283408 lr 0.00029761 rank 4
2023-03-01 00:24:06,209 DEBUG TRAIN Batch 45/2700 loss 4.000263 loss_att 8.587151 loss_ctc 10.079445 loss_rnnt 2.159606 hw_loss 0.211353 lr 0.00029761 rank 3
2023-03-01 00:24:06,215 DEBUG TRAIN Batch 45/2700 loss 1.707279 loss_att 4.198247 loss_ctc 2.138130 loss_rnnt 1.052472 hw_loss 0.185937 lr 0.00029761 rank 5
2023-03-01 00:24:06,217 DEBUG TRAIN Batch 45/2700 loss 4.339832 loss_att 9.414446 loss_ctc 12.243522 loss_rnnt 2.203588 hw_loss 0.126553 lr 0.00029761 rank 6
2023-03-01 00:24:06,225 DEBUG TRAIN Batch 45/2700 loss 3.245497 loss_att 5.697099 loss_ctc 6.916250 loss_rnnt 2.150813 hw_loss 0.215491 lr 0.00029761 rank 2
2023-03-01 00:24:06,225 DEBUG TRAIN Batch 45/2700 loss 10.969567 loss_att 13.605534 loss_ctc 16.123747 loss_rnnt 9.644682 hw_loss 0.207126 lr 0.00029761 rank 1
2023-03-01 00:24:06,264 DEBUG TRAIN Batch 45/2700 loss 4.474535 loss_att 9.253418 loss_ctc 7.435495 loss_rnnt 3.073785 hw_loss 0.094085 lr 0.00029761 rank 7
2023-03-01 00:24:46,034 DEBUG TRAIN Batch 45/2800 loss 2.606055 loss_att 5.889872 loss_ctc 4.947017 loss_rnnt 1.511462 hw_loss 0.235690 lr 0.00029760 rank 6
2023-03-01 00:24:46,035 DEBUG TRAIN Batch 45/2800 loss 2.625742 loss_att 4.820880 loss_ctc 5.620570 loss_rnnt 1.601702 hw_loss 0.348192 lr 0.00029760 rank 5
2023-03-01 00:24:46,048 DEBUG TRAIN Batch 45/2800 loss 2.117789 loss_att 5.044481 loss_ctc 3.306240 loss_rnnt 1.236840 hw_loss 0.257156 lr 0.00029760 rank 0
2023-03-01 00:24:46,052 DEBUG TRAIN Batch 45/2800 loss 3.754642 loss_att 6.232019 loss_ctc 7.000526 loss_rnnt 2.664730 hw_loss 0.303096 lr 0.00029760 rank 4
2023-03-01 00:24:46,056 DEBUG TRAIN Batch 45/2800 loss 6.914760 loss_att 9.650381 loss_ctc 11.311579 loss_rnnt 5.670580 hw_loss 0.207774 lr 0.00029759 rank 7
2023-03-01 00:24:46,057 DEBUG TRAIN Batch 45/2800 loss 4.136184 loss_att 6.843291 loss_ctc 8.454247 loss_rnnt 2.862796 hw_loss 0.292922 lr 0.00029759 rank 3
2023-03-01 00:24:46,057 DEBUG TRAIN Batch 45/2800 loss 7.003299 loss_att 10.045713 loss_ctc 13.382956 loss_rnnt 5.467064 hw_loss 0.144622 lr 0.00029760 rank 2
2023-03-01 00:24:46,089 DEBUG TRAIN Batch 45/2800 loss 11.106123 loss_att 14.694067 loss_ctc 26.799458 loss_rnnt 8.135482 hw_loss 0.301140 lr 0.00029760 rank 1
2023-03-01 00:25:48,698 DEBUG TRAIN Batch 45/2900 loss 6.050752 loss_att 8.202658 loss_ctc 12.981695 loss_rnnt 4.628875 hw_loss 0.126319 lr 0.00029759 rank 1
2023-03-01 00:25:48,704 DEBUG TRAIN Batch 45/2900 loss 4.352419 loss_att 6.560896 loss_ctc 5.535429 loss_rnnt 3.650942 hw_loss 0.191338 lr 0.00029758 rank 4
2023-03-01 00:25:48,715 DEBUG TRAIN Batch 45/2900 loss 2.107536 loss_att 3.183319 loss_ctc 2.842774 loss_rnnt 1.611737 hw_loss 0.342397 lr 0.00029758 rank 6
2023-03-01 00:25:48,717 DEBUG TRAIN Batch 45/2900 loss 6.878147 loss_att 9.968437 loss_ctc 15.233688 loss_rnnt 5.030583 hw_loss 0.216437 lr 0.00029758 rank 0
2023-03-01 00:25:48,718 DEBUG TRAIN Batch 45/2900 loss 10.910757 loss_att 15.943697 loss_ctc 23.895199 loss_rnnt 8.032947 hw_loss 0.262432 lr 0.00029758 rank 5
2023-03-01 00:25:48,718 DEBUG TRAIN Batch 45/2900 loss 5.978182 loss_att 7.959369 loss_ctc 8.918467 loss_rnnt 5.009534 hw_loss 0.338199 lr 0.00029758 rank 7
2023-03-01 00:25:48,719 DEBUG TRAIN Batch 45/2900 loss 5.197024 loss_att 7.324055 loss_ctc 7.222633 loss_rnnt 4.426434 hw_loss 0.140818 lr 0.00029758 rank 2
2023-03-01 00:25:48,724 DEBUG TRAIN Batch 45/2900 loss 8.801354 loss_att 12.228495 loss_ctc 13.757586 loss_rnnt 7.374283 hw_loss 0.151522 lr 0.00029758 rank 3
2023-03-01 00:26:27,341 DEBUG TRAIN Batch 45/3000 loss 5.917045 loss_att 7.154379 loss_ctc 10.113380 loss_rnnt 5.037468 hw_loss 0.136122 lr 0.00029757 rank 4
2023-03-01 00:26:27,340 DEBUG TRAIN Batch 45/3000 loss 5.539547 loss_att 8.944124 loss_ctc 7.459558 loss_rnnt 4.501974 hw_loss 0.188731 lr 0.00029757 rank 6
2023-03-01 00:26:27,354 DEBUG TRAIN Batch 45/3000 loss 7.920615 loss_att 10.117457 loss_ctc 11.881068 loss_rnnt 6.847273 hw_loss 0.198586 lr 0.00029757 rank 0
2023-03-01 00:26:27,355 DEBUG TRAIN Batch 45/3000 loss 10.081598 loss_att 17.275345 loss_ctc 14.916622 loss_rnnt 7.827239 hw_loss 0.320513 lr 0.00029757 rank 7
2023-03-01 00:26:27,355 DEBUG TRAIN Batch 45/3000 loss 3.705785 loss_att 5.949017 loss_ctc 8.454247 loss_rnnt 2.489403 hw_loss 0.252387 lr 0.00029757 rank 1
2023-03-01 00:26:27,355 DEBUG TRAIN Batch 45/3000 loss 6.252623 loss_att 10.045235 loss_ctc 7.707096 loss_rnnt 5.180357 hw_loss 0.224650 lr 0.00029757 rank 2
2023-03-01 00:26:27,392 DEBUG TRAIN Batch 45/3000 loss 6.226624 loss_att 8.025562 loss_ctc 7.238791 loss_rnnt 5.653981 hw_loss 0.146061 lr 0.00029757 rank 3
2023-03-01 00:26:27,403 DEBUG TRAIN Batch 45/3000 loss 7.978331 loss_att 13.866667 loss_ctc 14.042301 loss_rnnt 5.867464 hw_loss 0.233758 lr 0.00029757 rank 5
2023-03-01 00:27:06,685 DEBUG TRAIN Batch 45/3100 loss 4.754252 loss_att 6.451744 loss_ctc 5.151004 loss_rnnt 4.210677 hw_loss 0.283456 lr 0.00029756 rank 0
2023-03-01 00:27:06,691 DEBUG TRAIN Batch 45/3100 loss 11.019938 loss_att 14.453810 loss_ctc 18.644545 loss_rnnt 9.118590 hw_loss 0.371173 lr 0.00029756 rank 2
2023-03-01 00:27:06,697 DEBUG TRAIN Batch 45/3100 loss 9.552595 loss_att 10.751999 loss_ctc 13.781259 loss_rnnt 8.578046 hw_loss 0.320338 lr 0.00029756 rank 1
2023-03-01 00:27:06,700 DEBUG TRAIN Batch 45/3100 loss 9.075890 loss_att 9.216412 loss_ctc 12.555323 loss_rnnt 8.386494 hw_loss 0.370065 lr 0.00029756 rank 6
2023-03-01 00:27:06,704 DEBUG TRAIN Batch 45/3100 loss 7.001056 loss_att 8.716571 loss_ctc 12.035144 loss_rnnt 5.836912 hw_loss 0.280932 lr 0.00029755 rank 3
2023-03-01 00:27:06,713 DEBUG TRAIN Batch 45/3100 loss 11.032957 loss_att 11.565815 loss_ctc 13.057277 loss_rnnt 10.463007 hw_loss 0.362753 lr 0.00029756 rank 4
2023-03-01 00:27:06,719 DEBUG TRAIN Batch 45/3100 loss 6.383193 loss_att 8.388564 loss_ctc 11.966270 loss_rnnt 5.151094 hw_loss 0.162404 lr 0.00029756 rank 5
2023-03-01 00:27:06,752 DEBUG TRAIN Batch 45/3100 loss 7.400818 loss_att 8.393946 loss_ctc 10.552564 loss_rnnt 6.659442 hw_loss 0.229722 lr 0.00029755 rank 7
2023-03-01 00:28:08,091 DEBUG TRAIN Batch 45/3200 loss 5.542234 loss_att 8.497612 loss_ctc 10.406729 loss_rnnt 4.136199 hw_loss 0.311926 lr 0.00029754 rank 7
2023-03-01 00:28:08,091 DEBUG TRAIN Batch 45/3200 loss 10.935838 loss_att 14.995597 loss_ctc 17.896374 loss_rnnt 9.097972 hw_loss 0.183455 lr 0.00029754 rank 3
2023-03-01 00:28:08,093 DEBUG TRAIN Batch 45/3200 loss 13.831495 loss_att 17.203753 loss_ctc 29.105423 loss_rnnt 11.072604 hw_loss 0.089842 lr 0.00029754 rank 6
2023-03-01 00:28:08,101 DEBUG TRAIN Batch 45/3200 loss 6.875865 loss_att 8.999059 loss_ctc 12.040698 loss_rnnt 5.583974 hw_loss 0.334889 lr 0.00029754 rank 5
2023-03-01 00:28:08,104 DEBUG TRAIN Batch 45/3200 loss 8.097147 loss_att 12.371250 loss_ctc 13.739814 loss_rnnt 6.356144 hw_loss 0.250924 lr 0.00029754 rank 2
2023-03-01 00:28:08,108 DEBUG TRAIN Batch 45/3200 loss 7.571668 loss_att 12.217810 loss_ctc 13.977318 loss_rnnt 5.719942 hw_loss 0.128271 lr 0.00029755 rank 1
2023-03-01 00:28:08,127 DEBUG TRAIN Batch 45/3200 loss 4.116923 loss_att 5.620902 loss_ctc 6.212926 loss_rnnt 3.379394 hw_loss 0.294874 lr 0.00029754 rank 4
2023-03-01 00:28:08,150 DEBUG TRAIN Batch 45/3200 loss 8.821596 loss_att 9.314756 loss_ctc 15.252500 loss_rnnt 7.639861 hw_loss 0.423092 lr 0.00029755 rank 0
2023-03-01 00:28:50,990 DEBUG TRAIN Batch 45/3300 loss 10.590573 loss_att 12.531385 loss_ctc 14.350905 loss_rnnt 9.567195 hw_loss 0.250946 lr 0.00029753 rank 7
2023-03-01 00:28:51,005 DEBUG TRAIN Batch 45/3300 loss 2.420454 loss_att 5.736207 loss_ctc 2.334580 loss_rnnt 1.669648 hw_loss 0.185823 lr 0.00029753 rank 0
2023-03-01 00:28:51,006 DEBUG TRAIN Batch 45/3300 loss 3.908708 loss_att 8.339853 loss_ctc 11.806030 loss_rnnt 1.849153 hw_loss 0.225654 lr 0.00029753 rank 5
2023-03-01 00:28:51,008 DEBUG TRAIN Batch 45/3300 loss 4.644570 loss_att 8.192194 loss_ctc 9.389591 loss_rnnt 3.155858 hw_loss 0.274721 lr 0.00029753 rank 4
2023-03-01 00:28:51,011 DEBUG TRAIN Batch 45/3300 loss 4.418933 loss_att 7.175904 loss_ctc 6.860540 loss_rnnt 3.376713 hw_loss 0.309896 lr 0.00029753 rank 2
2023-03-01 00:28:51,015 DEBUG TRAIN Batch 45/3300 loss 2.146593 loss_att 4.669065 loss_ctc 4.752638 loss_rnnt 1.161329 hw_loss 0.249933 lr 0.00029753 rank 3
2023-03-01 00:28:51,017 DEBUG TRAIN Batch 45/3300 loss 8.626124 loss_att 11.898220 loss_ctc 10.613617 loss_rnnt 7.581493 hw_loss 0.234776 lr 0.00029753 rank 1
2023-03-01 00:28:51,041 DEBUG TRAIN Batch 45/3300 loss 5.056980 loss_att 9.473385 loss_ctc 14.153902 loss_rnnt 2.867771 hw_loss 0.174386 lr 0.00029753 rank 6
2023-03-01 00:29:29,827 DEBUG TRAIN Batch 45/3400 loss 4.147619 loss_att 6.995626 loss_ctc 7.913209 loss_rnnt 2.898401 hw_loss 0.332883 lr 0.00029752 rank 0
2023-03-01 00:29:29,829 DEBUG TRAIN Batch 45/3400 loss 2.199647 loss_att 4.724945 loss_ctc 5.094723 loss_rnnt 1.122641 hw_loss 0.348632 lr 0.00029751 rank 7
2023-03-01 00:29:29,829 DEBUG TRAIN Batch 45/3400 loss 4.516521 loss_att 7.344685 loss_ctc 7.049287 loss_rnnt 3.441506 hw_loss 0.321900 lr 0.00029752 rank 2
2023-03-01 00:29:29,830 DEBUG TRAIN Batch 45/3400 loss 9.272080 loss_att 12.985723 loss_ctc 13.199633 loss_rnnt 7.932644 hw_loss 0.136937 lr 0.00029752 rank 1
2023-03-01 00:29:29,835 DEBUG TRAIN Batch 45/3400 loss 4.112385 loss_att 6.393266 loss_ctc 5.386732 loss_rnnt 3.273852 hw_loss 0.398334 lr 0.00029752 rank 4
2023-03-01 00:29:29,837 DEBUG TRAIN Batch 45/3400 loss 4.589479 loss_att 8.235094 loss_ctc 7.051834 loss_rnnt 3.400327 hw_loss 0.246966 lr 0.00029751 rank 3
2023-03-01 00:29:29,837 DEBUG TRAIN Batch 45/3400 loss 6.230942 loss_att 9.039752 loss_ctc 8.391045 loss_rnnt 5.253685 hw_loss 0.239029 lr 0.00029752 rank 5
2023-03-01 00:29:29,876 DEBUG TRAIN Batch 45/3400 loss 5.258428 loss_att 7.415711 loss_ctc 7.983222 loss_rnnt 4.297507 hw_loss 0.311546 lr 0.00029752 rank 6
2023-03-01 00:30:08,992 DEBUG TRAIN Batch 45/3500 loss 4.751608 loss_att 6.049084 loss_ctc 7.966104 loss_rnnt 3.964523 hw_loss 0.185607 lr 0.00029751 rank 1
2023-03-01 00:30:08,999 DEBUG TRAIN Batch 45/3500 loss 7.692079 loss_att 10.621139 loss_ctc 15.536263 loss_rnnt 5.909456 hw_loss 0.282973 lr 0.00029750 rank 5
2023-03-01 00:30:09,010 DEBUG TRAIN Batch 45/3500 loss 3.958005 loss_att 6.014246 loss_ctc 6.600283 loss_rnnt 3.076967 hw_loss 0.220286 lr 0.00029750 rank 7
2023-03-01 00:30:09,012 DEBUG TRAIN Batch 45/3500 loss 4.608651 loss_att 7.870263 loss_ctc 9.125329 loss_rnnt 3.253664 hw_loss 0.188326 lr 0.00029751 rank 0
2023-03-01 00:30:09,015 DEBUG TRAIN Batch 45/3500 loss 8.151183 loss_att 12.739238 loss_ctc 14.671023 loss_rnnt 6.202300 hw_loss 0.303675 lr 0.00029750 rank 2
2023-03-01 00:30:09,017 DEBUG TRAIN Batch 45/3500 loss 6.303750 loss_att 9.937410 loss_ctc 10.082821 loss_rnnt 4.876838 hw_loss 0.368070 lr 0.00029750 rank 3
2023-03-01 00:30:09,019 DEBUG TRAIN Batch 45/3500 loss 7.020227 loss_att 8.620757 loss_ctc 9.499350 loss_rnnt 6.329723 hw_loss 0.074714 lr 0.00029750 rank 4
2023-03-01 00:30:09,038 DEBUG TRAIN Batch 45/3500 loss 2.790819 loss_att 6.021102 loss_ctc 5.125897 loss_rnnt 1.731335 hw_loss 0.191407 lr 0.00029750 rank 6
2023-03-01 00:31:13,452 DEBUG TRAIN Batch 45/3600 loss 16.929644 loss_att 22.259497 loss_ctc 29.970247 loss_rnnt 13.960985 hw_loss 0.307387 lr 0.00029749 rank 0
2023-03-01 00:31:13,466 DEBUG TRAIN Batch 45/3600 loss 7.561659 loss_att 9.594110 loss_ctc 10.988726 loss_rnnt 6.565453 hw_loss 0.248951 lr 0.00029749 rank 7
2023-03-01 00:31:13,469 DEBUG TRAIN Batch 45/3600 loss 7.485128 loss_att 10.242014 loss_ctc 14.047898 loss_rnnt 5.913071 hw_loss 0.273082 lr 0.00029749 rank 3
2023-03-01 00:31:13,470 DEBUG TRAIN Batch 45/3600 loss 4.238612 loss_att 7.337404 loss_ctc 5.149608 loss_rnnt 3.401089 hw_loss 0.180560 lr 0.00029749 rank 5
2023-03-01 00:31:13,471 DEBUG TRAIN Batch 45/3600 loss 3.024127 loss_att 6.492016 loss_ctc 5.106885 loss_rnnt 1.939723 hw_loss 0.212108 lr 0.00029749 rank 4
2023-03-01 00:31:13,474 DEBUG TRAIN Batch 45/3600 loss 6.051989 loss_att 10.088758 loss_ctc 12.255067 loss_rnnt 4.286206 hw_loss 0.246285 lr 0.00029749 rank 6
2023-03-01 00:31:13,476 DEBUG TRAIN Batch 45/3600 loss 1.193457 loss_att 3.061685 loss_ctc 1.454188 loss_rnnt 0.684088 hw_loss 0.189298 lr 0.00029749 rank 1
2023-03-01 00:31:13,483 DEBUG TRAIN Batch 45/3600 loss 7.793355 loss_att 9.669514 loss_ctc 12.283617 loss_rnnt 6.626854 hw_loss 0.361066 lr 0.00029749 rank 2
2023-03-01 00:31:52,420 DEBUG TRAIN Batch 45/3700 loss 10.383299 loss_att 12.734550 loss_ctc 14.548083 loss_rnnt 9.247916 hw_loss 0.205926 lr 0.00029748 rank 2
2023-03-01 00:31:52,427 DEBUG TRAIN Batch 45/3700 loss 7.403272 loss_att 8.288022 loss_ctc 15.295194 loss_rnnt 5.964719 hw_loss 0.392524 lr 0.00029748 rank 7
2023-03-01 00:31:52,430 DEBUG TRAIN Batch 45/3700 loss 8.966105 loss_att 10.635065 loss_ctc 12.465705 loss_rnnt 8.021708 hw_loss 0.269985 lr 0.00029748 rank 4
2023-03-01 00:31:52,432 DEBUG TRAIN Batch 45/3700 loss 9.616113 loss_att 11.259115 loss_ctc 14.684932 loss_rnnt 8.510764 hw_loss 0.189197 lr 0.00029748 rank 6
2023-03-01 00:31:52,441 DEBUG TRAIN Batch 45/3700 loss 6.812516 loss_att 8.712703 loss_ctc 8.884062 loss_rnnt 6.025104 hw_loss 0.245941 lr 0.00029748 rank 0
2023-03-01 00:31:52,447 DEBUG TRAIN Batch 45/3700 loss 5.636895 loss_att 6.624604 loss_ctc 7.114292 loss_rnnt 5.105041 hw_loss 0.257487 lr 0.00029748 rank 1
2023-03-01 00:31:52,448 DEBUG TRAIN Batch 45/3700 loss 4.288635 loss_att 7.281644 loss_ctc 7.945165 loss_rnnt 3.128348 hw_loss 0.139026 lr 0.00029748 rank 5
2023-03-01 00:31:52,450 DEBUG TRAIN Batch 45/3700 loss 5.767035 loss_att 7.795697 loss_ctc 7.766156 loss_rnnt 5.020903 hw_loss 0.138470 lr 0.00029747 rank 3
2023-03-01 00:32:31,911 DEBUG TRAIN Batch 45/3800 loss 2.945447 loss_att 7.689720 loss_ctc 6.345367 loss_rnnt 1.460281 hw_loss 0.155605 lr 0.00029746 rank 4
2023-03-01 00:32:31,915 DEBUG TRAIN Batch 45/3800 loss 4.300643 loss_att 5.944262 loss_ctc 7.398331 loss_rnnt 3.405130 hw_loss 0.288306 lr 0.00029746 rank 5
2023-03-01 00:32:31,927 DEBUG TRAIN Batch 45/3800 loss 8.234735 loss_att 8.798777 loss_ctc 13.668400 loss_rnnt 7.184279 hw_loss 0.399674 lr 0.00029746 rank 6
2023-03-01 00:32:31,932 DEBUG TRAIN Batch 45/3800 loss 6.879226 loss_att 7.619243 loss_ctc 10.085048 loss_rnnt 6.034580 hw_loss 0.504750 lr 0.00029746 rank 2
2023-03-01 00:32:31,932 DEBUG TRAIN Batch 45/3800 loss 8.388852 loss_att 9.709947 loss_ctc 13.226800 loss_rnnt 7.310905 hw_loss 0.316255 lr 0.00029747 rank 0
2023-03-01 00:32:31,934 DEBUG TRAIN Batch 45/3800 loss 5.662197 loss_att 7.661872 loss_ctc 8.523029 loss_rnnt 4.795936 hw_loss 0.159153 lr 0.00029746 rank 7
2023-03-01 00:32:31,934 DEBUG TRAIN Batch 45/3800 loss 6.779112 loss_att 7.149299 loss_ctc 11.110141 loss_rnnt 5.997178 hw_loss 0.244550 lr 0.00029746 rank 3
2023-03-01 00:32:31,952 DEBUG TRAIN Batch 45/3800 loss 6.819777 loss_att 10.971642 loss_ctc 12.640876 loss_rnnt 5.083035 hw_loss 0.244167 lr 0.00029747 rank 1
2023-03-01 00:33:33,044 DEBUG TRAIN Batch 45/3900 loss 11.903923 loss_att 13.513914 loss_ctc 17.080948 loss_rnnt 10.721012 hw_loss 0.319955 lr 0.00029745 rank 0
2023-03-01 00:33:33,049 DEBUG TRAIN Batch 45/3900 loss 11.626311 loss_att 12.892529 loss_ctc 18.169556 loss_rnnt 10.359466 hw_loss 0.264692 lr 0.00029745 rank 1
2023-03-01 00:33:33,054 DEBUG TRAIN Batch 45/3900 loss 9.015329 loss_att 11.847903 loss_ctc 18.121508 loss_rnnt 7.038528 hw_loss 0.367742 lr 0.00029745 rank 4
2023-03-01 00:33:33,054 DEBUG TRAIN Batch 45/3900 loss 6.335553 loss_att 8.695740 loss_ctc 7.500046 loss_rnnt 5.644018 hw_loss 0.120434 lr 0.00029745 rank 3
2023-03-01 00:33:33,057 DEBUG TRAIN Batch 45/3900 loss 4.432337 loss_att 6.530633 loss_ctc 4.830713 loss_rnnt 3.836145 hw_loss 0.231404 lr 0.00029745 rank 7
2023-03-01 00:33:33,061 DEBUG TRAIN Batch 45/3900 loss 10.248130 loss_att 14.538777 loss_ctc 24.218664 loss_rnnt 7.360902 hw_loss 0.311925 lr 0.00029745 rank 2
2023-03-01 00:33:33,070 DEBUG TRAIN Batch 45/3900 loss 3.729354 loss_att 6.704143 loss_ctc 5.260481 loss_rnnt 2.929397 hw_loss 0.001592 lr 0.00029745 rank 6
2023-03-01 00:33:33,084 DEBUG TRAIN Batch 45/3900 loss 9.886244 loss_att 10.371716 loss_ctc 15.995052 loss_rnnt 8.710308 hw_loss 0.495625 lr 0.00029745 rank 5
2023-03-01 00:34:15,616 DEBUG TRAIN Batch 45/4000 loss 8.249255 loss_att 12.326834 loss_ctc 12.028797 loss_rnnt 6.773072 hw_loss 0.293864 lr 0.00029744 rank 4
2023-03-01 00:34:15,619 DEBUG TRAIN Batch 45/4000 loss 16.316519 loss_att 19.435417 loss_ctc 25.503143 loss_rnnt 14.343257 hw_loss 0.233627 lr 0.00029744 rank 0
2023-03-01 00:34:15,621 DEBUG TRAIN Batch 45/4000 loss 5.309584 loss_att 10.741975 loss_ctc 12.935266 loss_rnnt 3.031998 hw_loss 0.326907 lr 0.00029744 rank 1
2023-03-01 00:34:15,622 DEBUG TRAIN Batch 45/4000 loss 5.454330 loss_att 9.420397 loss_ctc 13.785891 loss_rnnt 3.438313 hw_loss 0.209868 lr 0.00029744 rank 5
2023-03-01 00:34:15,624 DEBUG TRAIN Batch 45/4000 loss 7.918242 loss_att 11.170503 loss_ctc 12.566546 loss_rnnt 6.572852 hw_loss 0.140932 lr 0.00029744 rank 7
2023-03-01 00:34:15,627 DEBUG TRAIN Batch 45/4000 loss 8.649604 loss_att 11.190322 loss_ctc 11.708224 loss_rnnt 7.627687 hw_loss 0.198670 lr 0.00029743 rank 3
2023-03-01 00:34:15,630 DEBUG TRAIN Batch 45/4000 loss 4.107831 loss_att 7.415411 loss_ctc 4.597075 loss_rnnt 3.253176 hw_loss 0.239824 lr 0.00029744 rank 6
2023-03-01 00:34:15,668 DEBUG TRAIN Batch 45/4000 loss 8.475541 loss_att 9.824715 loss_ctc 14.716784 loss_rnnt 7.303212 hw_loss 0.131868 lr 0.00029744 rank 2
2023-03-01 00:34:54,512 DEBUG TRAIN Batch 45/4100 loss 2.694440 loss_att 7.419786 loss_ctc 4.980047 loss_rnnt 1.321828 hw_loss 0.230240 lr 0.00029742 rank 7
2023-03-01 00:34:54,521 DEBUG TRAIN Batch 45/4100 loss 5.527250 loss_att 7.989075 loss_ctc 7.437395 loss_rnnt 4.606535 hw_loss 0.325618 lr 0.00029742 rank 2
2023-03-01 00:34:54,522 DEBUG TRAIN Batch 45/4100 loss 8.035142 loss_att 10.973698 loss_ctc 10.735151 loss_rnnt 7.026666 hw_loss 0.113932 lr 0.00029743 rank 0
2023-03-01 00:34:54,524 DEBUG TRAIN Batch 45/4100 loss 1.521049 loss_att 4.183785 loss_ctc 4.018997 loss_rnnt 0.605365 hw_loss 0.093894 lr 0.00029743 rank 1
2023-03-01 00:34:54,526 DEBUG TRAIN Batch 45/4100 loss 5.645396 loss_att 10.939397 loss_ctc 9.612260 loss_rnnt 3.910944 hw_loss 0.275130 lr 0.00029742 rank 5
2023-03-01 00:34:54,527 DEBUG TRAIN Batch 45/4100 loss 8.422885 loss_att 11.695831 loss_ctc 11.719695 loss_rnnt 7.208323 hw_loss 0.225746 lr 0.00029743 rank 6
2023-03-01 00:34:54,532 DEBUG TRAIN Batch 45/4100 loss 11.583341 loss_att 14.633788 loss_ctc 21.898331 loss_rnnt 9.482533 hw_loss 0.216348 lr 0.00029743 rank 4
2023-03-01 00:34:54,576 DEBUG TRAIN Batch 45/4100 loss 6.324766 loss_att 9.600398 loss_ctc 8.704865 loss_rnnt 5.246467 hw_loss 0.198424 lr 0.00029742 rank 3
2023-03-01 00:35:33,555 DEBUG TRAIN Batch 45/4200 loss 4.351816 loss_att 7.527768 loss_ctc 7.237317 loss_rnnt 3.099321 hw_loss 0.436070 lr 0.00029741 rank 1
2023-03-01 00:35:33,557 DEBUG TRAIN Batch 45/4200 loss 11.758620 loss_att 14.438367 loss_ctc 23.733490 loss_rnnt 9.499569 hw_loss 0.237099 lr 0.00029741 rank 2
2023-03-01 00:35:33,559 DEBUG TRAIN Batch 45/4200 loss 8.457929 loss_att 13.513975 loss_ctc 14.049508 loss_rnnt 6.608037 hw_loss 0.174635 lr 0.00029741 rank 6
2023-03-01 00:35:33,560 DEBUG TRAIN Batch 45/4200 loss 5.790198 loss_att 9.489667 loss_ctc 8.918644 loss_rnnt 4.525280 hw_loss 0.202312 lr 0.00029741 rank 0
2023-03-01 00:35:33,561 DEBUG TRAIN Batch 45/4200 loss 21.642899 loss_att 22.463821 loss_ctc 31.829359 loss_rnnt 20.087450 hw_loss 0.062001 lr 0.00029741 rank 3
2023-03-01 00:35:33,564 DEBUG TRAIN Batch 45/4200 loss 6.288405 loss_att 11.263069 loss_ctc 9.285324 loss_rnnt 4.751459 hw_loss 0.267046 lr 0.00029741 rank 4
2023-03-01 00:35:33,571 DEBUG TRAIN Batch 45/4200 loss 2.437239 loss_att 5.942019 loss_ctc 5.114655 loss_rnnt 1.209222 hw_loss 0.318885 lr 0.00029741 rank 5
2023-03-01 00:35:33,584 DEBUG TRAIN Batch 45/4200 loss 3.515944 loss_att 5.963944 loss_ctc 5.856051 loss_rnnt 2.579006 hw_loss 0.253733 lr 0.00029741 rank 7
2023-03-01 00:36:39,307 DEBUG TRAIN Batch 45/4300 loss 4.725863 loss_att 8.287713 loss_ctc 13.965170 loss_rnnt 2.615668 hw_loss 0.311095 lr 0.00029739 rank 3
2023-03-01 00:36:39,315 DEBUG TRAIN Batch 45/4300 loss 5.723900 loss_att 7.334296 loss_ctc 9.452683 loss_rnnt 4.774811 hw_loss 0.243447 lr 0.00029740 rank 0
2023-03-01 00:36:39,320 DEBUG TRAIN Batch 45/4300 loss 8.652532 loss_att 11.670909 loss_ctc 12.567736 loss_rnnt 7.337791 hw_loss 0.354447 lr 0.00029740 rank 5
2023-03-01 00:36:39,320 DEBUG TRAIN Batch 45/4300 loss 7.268756 loss_att 8.367543 loss_ctc 10.978152 loss_rnnt 6.417865 hw_loss 0.256027 lr 0.00029740 rank 4
2023-03-01 00:36:39,320 DEBUG TRAIN Batch 45/4300 loss 2.101542 loss_att 3.976883 loss_ctc 4.282883 loss_rnnt 1.290976 hw_loss 0.271223 lr 0.00029740 rank 7
2023-03-01 00:36:39,321 DEBUG TRAIN Batch 45/4300 loss 2.349833 loss_att 3.911764 loss_ctc 4.530515 loss_rnnt 1.534411 hw_loss 0.398023 lr 0.00029740 rank 2
2023-03-01 00:36:39,325 DEBUG TRAIN Batch 45/4300 loss 15.424910 loss_att 17.810623 loss_ctc 22.088806 loss_rnnt 13.920869 hw_loss 0.259458 lr 0.00029740 rank 6
2023-03-01 00:36:39,331 DEBUG TRAIN Batch 45/4300 loss 2.818720 loss_att 5.432493 loss_ctc 5.929143 loss_rnnt 1.720779 hw_loss 0.300869 lr 0.00029740 rank 1
2023-03-01 00:37:18,867 DEBUG TRAIN Batch 45/4400 loss 6.715757 loss_att 7.262043 loss_ctc 10.149443 loss_rnnt 5.929727 hw_loss 0.410529 lr 0.00029739 rank 4
2023-03-01 00:37:18,870 DEBUG TRAIN Batch 45/4400 loss 5.774255 loss_att 9.964640 loss_ctc 10.962311 loss_rnnt 4.105867 hw_loss 0.259818 lr 0.00029739 rank 1
2023-03-01 00:37:18,876 DEBUG TRAIN Batch 45/4400 loss 4.908145 loss_att 7.909549 loss_ctc 9.476133 loss_rnnt 3.557328 hw_loss 0.265260 lr 0.00029738 rank 3
2023-03-01 00:37:18,878 DEBUG TRAIN Batch 45/4400 loss 8.181020 loss_att 8.008120 loss_ctc 12.304352 loss_rnnt 7.467235 hw_loss 0.372350 lr 0.00029738 rank 7
2023-03-01 00:37:18,880 DEBUG TRAIN Batch 45/4400 loss 7.213364 loss_att 7.465902 loss_ctc 10.201823 loss_rnnt 6.590440 hw_loss 0.326164 lr 0.00029739 rank 6
2023-03-01 00:37:18,881 DEBUG TRAIN Batch 45/4400 loss 4.407547 loss_att 6.307221 loss_ctc 6.175931 loss_rnnt 3.654885 hw_loss 0.256768 lr 0.00029739 rank 0
2023-03-01 00:37:18,890 DEBUG TRAIN Batch 45/4400 loss 8.340648 loss_att 11.273841 loss_ctc 12.869791 loss_rnnt 7.018064 hw_loss 0.247612 lr 0.00029739 rank 2
2023-03-01 00:37:18,893 DEBUG TRAIN Batch 45/4400 loss 4.941265 loss_att 6.870720 loss_ctc 9.074343 loss_rnnt 3.850299 hw_loss 0.288745 lr 0.00029738 rank 5
2023-03-01 00:37:57,493 DEBUG TRAIN Batch 45/4500 loss 6.830710 loss_att 10.712210 loss_ctc 15.008117 loss_rnnt 4.820238 hw_loss 0.269722 lr 0.00029737 rank 1
2023-03-01 00:37:57,513 DEBUG TRAIN Batch 45/4500 loss 5.163053 loss_att 9.104820 loss_ctc 5.266273 loss_rnnt 4.226826 hw_loss 0.251455 lr 0.00029737 rank 0
2023-03-01 00:37:57,518 DEBUG TRAIN Batch 45/4500 loss 11.928963 loss_att 15.908759 loss_ctc 17.688751 loss_rnnt 10.316963 hw_loss 0.090128 lr 0.00029737 rank 3
2023-03-01 00:37:57,519 DEBUG TRAIN Batch 45/4500 loss 4.591081 loss_att 6.386127 loss_ctc 8.908795 loss_rnnt 3.504530 hw_loss 0.284711 lr 0.00029737 rank 5
2023-03-01 00:37:57,519 DEBUG TRAIN Batch 45/4500 loss 3.135938 loss_att 5.070561 loss_ctc 4.281686 loss_rnnt 2.455220 hw_loss 0.264425 lr 0.00029737 rank 4
2023-03-01 00:37:57,519 DEBUG TRAIN Batch 45/4500 loss 3.236479 loss_att 5.102247 loss_ctc 3.186735 loss_rnnt 2.713997 hw_loss 0.292427 lr 0.00029737 rank 7
2023-03-01 00:37:57,519 DEBUG TRAIN Batch 45/4500 loss 4.770370 loss_att 5.229692 loss_ctc 7.740035 loss_rnnt 4.137507 hw_loss 0.271957 lr 0.00029737 rank 2
2023-03-01 00:37:57,570 DEBUG TRAIN Batch 45/4500 loss 11.912684 loss_att 14.527775 loss_ctc 23.762661 loss_rnnt 9.808879 hw_loss 0.001481 lr 0.00029737 rank 6
2023-03-01 00:38:37,960 DEBUG TRAIN Batch 45/4600 loss 3.450080 loss_att 6.927763 loss_ctc 5.603645 loss_rnnt 2.339072 hw_loss 0.240618 lr 0.00029736 rank 5
2023-03-01 00:38:37,962 DEBUG TRAIN Batch 45/4600 loss 6.673723 loss_att 9.402039 loss_ctc 11.591764 loss_rnnt 5.334775 hw_loss 0.257898 lr 0.00029736 rank 0
2023-03-01 00:38:37,969 DEBUG TRAIN Batch 45/4600 loss 9.081828 loss_att 16.921982 loss_ctc 12.939545 loss_rnnt 6.896695 hw_loss 0.192636 lr 0.00029736 rank 6
2023-03-01 00:38:37,972 DEBUG TRAIN Batch 45/4600 loss 4.054071 loss_att 7.141772 loss_ctc 5.543228 loss_rnnt 3.237004 hw_loss 0.001826 lr 0.00029736 rank 2
2023-03-01 00:38:37,973 DEBUG TRAIN Batch 45/4600 loss 11.403718 loss_att 13.994860 loss_ctc 24.123558 loss_rnnt 9.013307 hw_loss 0.330382 lr 0.00029736 rank 1
2023-03-01 00:38:37,977 DEBUG TRAIN Batch 45/4600 loss 4.355636 loss_att 6.631926 loss_ctc 6.194481 loss_rnnt 3.594227 hw_loss 0.114321 lr 0.00029736 rank 3
2023-03-01 00:38:37,983 DEBUG TRAIN Batch 45/4600 loss 10.662876 loss_att 12.324918 loss_ctc 10.746210 loss_rnnt 10.232038 hw_loss 0.163721 lr 0.00029736 rank 7
2023-03-01 00:38:37,982 DEBUG TRAIN Batch 45/4600 loss 4.103340 loss_att 6.607519 loss_ctc 5.104936 loss_rnnt 3.361532 hw_loss 0.201423 lr 0.00029736 rank 4
2023-03-01 00:39:43,613 DEBUG TRAIN Batch 45/4700 loss 9.691502 loss_att 11.632510 loss_ctc 12.895522 loss_rnnt 8.818029 hw_loss 0.108876 lr 0.00029735 rank 2
2023-03-01 00:39:43,631 DEBUG TRAIN Batch 45/4700 loss 3.483079 loss_att 7.723487 loss_ctc 4.977229 loss_rnnt 2.292688 hw_loss 0.268293 lr 0.00029735 rank 5
2023-03-01 00:39:43,635 DEBUG TRAIN Batch 45/4700 loss 5.834510 loss_att 9.574757 loss_ctc 10.472719 loss_rnnt 4.359900 hw_loss 0.202750 lr 0.00029735 rank 1
2023-03-01 00:39:43,637 DEBUG TRAIN Batch 45/4700 loss 9.149686 loss_att 11.088451 loss_ctc 12.534147 loss_rnnt 8.087302 hw_loss 0.418817 lr 0.00029735 rank 0
2023-03-01 00:39:43,636 DEBUG TRAIN Batch 45/4700 loss 2.758473 loss_att 5.666038 loss_ctc 3.827374 loss_rnnt 1.933266 hw_loss 0.189699 lr 0.00029735 rank 4
2023-03-01 00:39:43,639 DEBUG TRAIN Batch 45/4700 loss 6.143515 loss_att 7.672537 loss_ctc 7.322736 loss_rnnt 5.500796 hw_loss 0.336910 lr 0.00029734 rank 3
2023-03-01 00:39:43,652 DEBUG TRAIN Batch 45/4700 loss 7.729405 loss_att 9.243609 loss_ctc 10.607292 loss_rnnt 6.856352 hw_loss 0.349676 lr 0.00029735 rank 6
2023-03-01 00:39:43,693 DEBUG TRAIN Batch 45/4700 loss 6.029136 loss_att 7.202093 loss_ctc 8.985043 loss_rnnt 5.240698 hw_loss 0.299484 lr 0.00029734 rank 7
2023-03-01 00:40:22,512 DEBUG TRAIN Batch 45/4800 loss 6.917853 loss_att 10.160626 loss_ctc 8.263871 loss_rnnt 6.052185 hw_loss 0.070583 lr 0.00029733 rank 7
2023-03-01 00:40:22,522 DEBUG TRAIN Batch 45/4800 loss 7.698840 loss_att 11.681103 loss_ctc 16.908348 loss_rnnt 5.604314 hw_loss 0.131509 lr 0.00029733 rank 5
2023-03-01 00:40:22,523 DEBUG TRAIN Batch 45/4800 loss 1.496890 loss_att 3.877683 loss_ctc 3.383718 loss_rnnt 0.577180 hw_loss 0.359952 lr 0.00029733 rank 0
2023-03-01 00:40:22,526 DEBUG TRAIN Batch 45/4800 loss 6.935454 loss_att 8.945246 loss_ctc 11.694999 loss_rnnt 5.802979 hw_loss 0.179832 lr 0.00029734 rank 1
2023-03-01 00:40:22,527 DEBUG TRAIN Batch 45/4800 loss 4.987789 loss_att 7.210546 loss_ctc 8.403223 loss_rnnt 3.940042 hw_loss 0.277133 lr 0.00029733 rank 4
2023-03-01 00:40:22,531 DEBUG TRAIN Batch 45/4800 loss 8.959571 loss_att 12.126854 loss_ctc 12.318256 loss_rnnt 7.747659 hw_loss 0.244931 lr 0.00029733 rank 2
2023-03-01 00:40:22,530 DEBUG TRAIN Batch 45/4800 loss 10.335992 loss_att 12.308438 loss_ctc 17.068924 loss_rnnt 8.882147 hw_loss 0.303058 lr 0.00029733 rank 6
2023-03-01 00:40:22,532 DEBUG TRAIN Batch 45/4800 loss 7.095864 loss_att 11.155796 loss_ctc 16.132914 loss_rnnt 5.021441 hw_loss 0.107808 lr 0.00029733 rank 3
2023-03-01 00:41:02,012 DEBUG TRAIN Batch 45/4900 loss 8.918763 loss_att 13.200331 loss_ctc 20.050339 loss_rnnt 6.504526 hw_loss 0.138211 lr 0.00029732 rank 7
2023-03-01 00:41:02,013 DEBUG TRAIN Batch 45/4900 loss 4.045697 loss_att 6.907445 loss_ctc 7.279256 loss_rnnt 2.924665 hw_loss 0.220388 lr 0.00029732 rank 1
2023-03-01 00:41:02,014 DEBUG TRAIN Batch 45/4900 loss 6.059043 loss_att 10.224780 loss_ctc 8.600021 loss_rnnt 4.723991 hw_loss 0.305827 lr 0.00029732 rank 5
2023-03-01 00:41:02,016 DEBUG TRAIN Batch 45/4900 loss 10.226233 loss_att 15.840574 loss_ctc 22.356791 loss_rnnt 7.374640 hw_loss 0.208719 lr 0.00029732 rank 3
2023-03-01 00:41:02,024 DEBUG TRAIN Batch 45/4900 loss 11.849596 loss_att 15.286161 loss_ctc 24.623306 loss_rnnt 9.346303 hw_loss 0.211535 lr 0.00029732 rank 4
2023-03-01 00:41:02,025 DEBUG TRAIN Batch 45/4900 loss 4.232285 loss_att 8.336357 loss_ctc 7.269399 loss_rnnt 2.821451 hw_loss 0.347008 lr 0.00029732 rank 2
2023-03-01 00:41:02,026 DEBUG TRAIN Batch 45/4900 loss 5.137020 loss_att 6.072948 loss_ctc 8.638172 loss_rnnt 4.348603 hw_loss 0.252019 lr 0.00029732 rank 0
2023-03-01 00:41:02,039 DEBUG TRAIN Batch 45/4900 loss 6.670485 loss_att 9.362687 loss_ctc 13.137456 loss_rnnt 5.046201 hw_loss 0.419213 lr 0.00029732 rank 6
2023-03-01 00:42:06,747 DEBUG TRAIN Batch 45/5000 loss 4.532296 loss_att 7.334997 loss_ctc 9.864634 loss_rnnt 3.161936 hw_loss 0.185327 lr 0.00029731 rank 0
2023-03-01 00:42:06,754 DEBUG TRAIN Batch 45/5000 loss 14.835820 loss_att 19.716614 loss_ctc 27.018463 loss_rnnt 12.126661 hw_loss 0.203716 lr 0.00029731 rank 5
2023-03-01 00:42:06,756 DEBUG TRAIN Batch 45/5000 loss 19.530245 loss_att 26.277882 loss_ctc 25.872967 loss_rnnt 17.254751 hw_loss 0.150510 lr 0.00029731 rank 6
2023-03-01 00:42:06,757 DEBUG TRAIN Batch 45/5000 loss 9.617498 loss_att 10.327570 loss_ctc 11.506136 loss_rnnt 9.013070 hw_loss 0.394865 lr 0.00029730 rank 3
2023-03-01 00:42:06,758 DEBUG TRAIN Batch 45/5000 loss 9.234762 loss_att 11.704661 loss_ctc 15.568862 loss_rnnt 7.747816 hw_loss 0.278288 lr 0.00029731 rank 4
2023-03-01 00:42:06,785 DEBUG TRAIN Batch 45/5000 loss 8.612880 loss_att 8.466598 loss_ctc 11.623688 loss_rnnt 8.062407 hw_loss 0.334292 lr 0.00029730 rank 7
2023-03-01 00:42:06,790 DEBUG TRAIN Batch 45/5000 loss 6.239524 loss_att 8.517990 loss_ctc 10.878859 loss_rnnt 5.050731 hw_loss 0.214730 lr 0.00029731 rank 2
2023-03-01 00:42:06,810 DEBUG TRAIN Batch 45/5000 loss 4.112577 loss_att 8.054664 loss_ctc 6.284217 loss_rnnt 2.962917 hw_loss 0.134421 lr 0.00029731 rank 1
2023-03-01 00:42:45,692 DEBUG TRAIN Batch 45/5100 loss 1.353715 loss_att 3.640598 loss_ctc 4.701276 loss_rnnt 0.332195 hw_loss 0.220878 lr 0.00029730 rank 1
2023-03-01 00:42:45,707 DEBUG TRAIN Batch 45/5100 loss 9.513996 loss_att 11.325655 loss_ctc 16.277714 loss_rnnt 8.091953 hw_loss 0.296028 lr 0.00029729 rank 4
2023-03-01 00:42:45,709 DEBUG TRAIN Batch 45/5100 loss 11.872947 loss_att 19.809517 loss_ctc 27.681274 loss_rnnt 8.103600 hw_loss 0.139230 lr 0.00029729 rank 7
2023-03-01 00:42:45,709 DEBUG TRAIN Batch 45/5100 loss 5.695753 loss_att 6.585358 loss_ctc 9.858077 loss_rnnt 4.756310 hw_loss 0.387272 lr 0.00029729 rank 5
2023-03-01 00:42:45,709 DEBUG TRAIN Batch 45/5100 loss 7.135155 loss_att 10.325857 loss_ctc 13.044480 loss_rnnt 5.547941 hw_loss 0.302181 lr 0.00029729 rank 2
2023-03-01 00:42:45,710 DEBUG TRAIN Batch 45/5100 loss 5.684953 loss_att 7.305031 loss_ctc 11.486194 loss_rnnt 4.482822 hw_loss 0.196155 lr 0.00029730 rank 0
2023-03-01 00:42:45,713 DEBUG TRAIN Batch 45/5100 loss 3.441262 loss_att 5.833748 loss_ctc 4.664523 loss_rnnt 2.681091 hw_loss 0.222324 lr 0.00029729 rank 6
2023-03-01 00:42:45,759 DEBUG TRAIN Batch 45/5100 loss 4.160984 loss_att 6.975101 loss_ctc 8.673163 loss_rnnt 2.830159 hw_loss 0.311959 lr 0.00029729 rank 3
2023-03-01 00:43:24,645 DEBUG TRAIN Batch 45/5200 loss 5.028490 loss_att 6.655350 loss_ctc 6.935243 loss_rnnt 4.368173 hw_loss 0.151333 lr 0.00029728 rank 0
2023-03-01 00:43:24,646 DEBUG TRAIN Batch 45/5200 loss 10.464739 loss_att 11.763241 loss_ctc 16.915640 loss_rnnt 9.253433 hw_loss 0.171536 lr 0.00029728 rank 4
2023-03-01 00:43:24,647 DEBUG TRAIN Batch 45/5200 loss 8.054365 loss_att 10.118518 loss_ctc 15.744591 loss_rnnt 6.451844 hw_loss 0.308112 lr 0.00029728 rank 7
2023-03-01 00:43:24,650 DEBUG TRAIN Batch 45/5200 loss 2.994421 loss_att 5.958295 loss_ctc 5.232752 loss_rnnt 1.979338 hw_loss 0.232246 lr 0.00029728 rank 2
2023-03-01 00:43:24,650 DEBUG TRAIN Batch 45/5200 loss 4.899362 loss_att 8.397919 loss_ctc 7.662059 loss_rnnt 3.774957 hw_loss 0.105626 lr 0.00029728 rank 6
2023-03-01 00:43:24,652 DEBUG TRAIN Batch 45/5200 loss 8.107628 loss_att 11.100704 loss_ctc 11.749699 loss_rnnt 6.912697 hw_loss 0.207574 lr 0.00029728 rank 3
2023-03-01 00:43:24,653 DEBUG TRAIN Batch 45/5200 loss 3.210194 loss_att 6.217099 loss_ctc 6.378027 loss_rnnt 2.110330 hw_loss 0.142698 lr 0.00029728 rank 1
2023-03-01 00:43:24,658 DEBUG TRAIN Batch 45/5200 loss 1.142282 loss_att 2.934637 loss_ctc 2.342474 loss_rnnt 0.445689 hw_loss 0.333931 lr 0.00029728 rank 5
2023-03-01 00:44:04,925 DEBUG TRAIN Batch 45/5300 loss 7.170925 loss_att 8.847511 loss_ctc 10.387386 loss_rnnt 6.213413 hw_loss 0.362500 lr 0.00029727 rank 4
2023-03-01 00:44:04,931 DEBUG TRAIN Batch 45/5300 loss 5.612464 loss_att 7.832120 loss_ctc 8.635550 loss_rnnt 4.676248 hw_loss 0.167263 lr 0.00029727 rank 6
2023-03-01 00:44:04,941 DEBUG TRAIN Batch 45/5300 loss 11.557055 loss_att 13.972372 loss_ctc 15.981132 loss_rnnt 10.434919 hw_loss 0.092240 lr 0.00029727 rank 0
2023-03-01 00:44:04,942 DEBUG TRAIN Batch 45/5300 loss 5.025588 loss_att 7.998657 loss_ctc 12.495193 loss_rnnt 3.329658 hw_loss 0.197565 lr 0.00029727 rank 2
2023-03-01 00:44:04,943 DEBUG TRAIN Batch 45/5300 loss 6.171852 loss_att 8.789910 loss_ctc 7.864705 loss_rnnt 5.297670 hw_loss 0.234106 lr 0.00029726 rank 3
2023-03-01 00:44:04,947 DEBUG TRAIN Batch 45/5300 loss 1.257925 loss_att 3.739664 loss_ctc 1.605973 loss_rnnt 0.613221 hw_loss 0.191156 lr 0.00029726 rank 7
2023-03-01 00:44:04,964 DEBUG TRAIN Batch 45/5300 loss 6.594732 loss_att 9.332537 loss_ctc 13.045012 loss_rnnt 5.086551 hw_loss 0.188592 lr 0.00029727 rank 5
2023-03-01 00:44:04,985 DEBUG TRAIN Batch 45/5300 loss 5.179418 loss_att 6.978964 loss_ctc 7.586665 loss_rnnt 4.330262 hw_loss 0.315527 lr 0.00029727 rank 1
2023-03-01 00:45:09,241 DEBUG TRAIN Batch 45/5400 loss 3.349361 loss_att 6.147748 loss_ctc 6.241184 loss_rnnt 2.273165 hw_loss 0.245516 lr 0.00029725 rank 6
2023-03-01 00:45:09,245 DEBUG TRAIN Batch 45/5400 loss 3.509933 loss_att 7.360515 loss_ctc 10.225321 loss_rnnt 1.760829 hw_loss 0.156756 lr 0.00029725 rank 5
2023-03-01 00:45:09,248 DEBUG TRAIN Batch 45/5400 loss 8.514341 loss_att 13.018207 loss_ctc 12.719808 loss_rnnt 6.928196 hw_loss 0.233705 lr 0.00029726 rank 1
2023-03-01 00:45:09,259 DEBUG TRAIN Batch 45/5400 loss 2.411165 loss_att 4.454591 loss_ctc 3.132199 loss_rnnt 1.770592 hw_loss 0.254530 lr 0.00029725 rank 4
2023-03-01 00:45:09,263 DEBUG TRAIN Batch 45/5400 loss 5.592894 loss_att 10.031082 loss_ctc 15.348610 loss_rnnt 3.322149 hw_loss 0.154397 lr 0.00029725 rank 7
2023-03-01 00:45:09,269 DEBUG TRAIN Batch 45/5400 loss 4.264399 loss_att 8.478243 loss_ctc 8.370603 loss_rnnt 2.856235 hw_loss 0.033564 lr 0.00029725 rank 2
2023-03-01 00:45:09,270 DEBUG TRAIN Batch 45/5400 loss 5.630991 loss_att 8.174133 loss_ctc 7.459727 loss_rnnt 4.714972 hw_loss 0.306675 lr 0.00029726 rank 0
2023-03-01 00:45:09,270 DEBUG TRAIN Batch 45/5400 loss 2.813242 loss_att 6.158720 loss_ctc 6.766230 loss_rnnt 1.515874 hw_loss 0.189766 lr 0.00029725 rank 3
2023-03-01 00:45:48,486 DEBUG TRAIN Batch 45/5500 loss 4.394904 loss_att 6.529406 loss_ctc 7.494956 loss_rnnt 3.531398 hw_loss 0.043622 lr 0.00029724 rank 7
2023-03-01 00:45:48,490 DEBUG TRAIN Batch 45/5500 loss 3.927072 loss_att 8.091850 loss_ctc 7.220206 loss_rnnt 2.507283 hw_loss 0.277028 lr 0.00029724 rank 5
2023-03-01 00:45:48,491 DEBUG TRAIN Batch 45/5500 loss 7.550244 loss_att 8.496710 loss_ctc 10.243307 loss_rnnt 6.878760 hw_loss 0.230843 lr 0.00029724 rank 2
2023-03-01 00:45:48,500 DEBUG TRAIN Batch 45/5500 loss 3.437888 loss_att 7.013384 loss_ctc 5.721148 loss_rnnt 2.221936 hw_loss 0.368283 lr 0.00029724 rank 4
2023-03-01 00:45:48,501 DEBUG TRAIN Batch 45/5500 loss 7.402864 loss_att 10.798886 loss_ctc 10.009979 loss_rnnt 6.258545 hw_loss 0.220312 lr 0.00029724 rank 0
2023-03-01 00:45:48,501 DEBUG TRAIN Batch 45/5500 loss 5.165096 loss_att 7.584172 loss_ctc 15.420389 loss_rnnt 3.178493 hw_loss 0.253903 lr 0.00029724 rank 3
2023-03-01 00:45:48,502 DEBUG TRAIN Batch 45/5500 loss 4.987665 loss_att 6.804095 loss_ctc 8.131988 loss_rnnt 4.116921 hw_loss 0.165403 lr 0.00029724 rank 6
2023-03-01 00:45:48,503 DEBUG TRAIN Batch 45/5500 loss 8.220386 loss_att 11.428915 loss_ctc 15.318462 loss_rnnt 6.408206 hw_loss 0.420120 lr 0.00029724 rank 1
2023-03-01 00:46:28,401 DEBUG TRAIN Batch 45/5600 loss 4.792128 loss_att 7.736702 loss_ctc 7.263040 loss_rnnt 3.718332 hw_loss 0.291425 lr 0.00029723 rank 7
2023-03-01 00:46:28,404 DEBUG TRAIN Batch 45/5600 loss 9.494335 loss_att 11.402298 loss_ctc 15.142060 loss_rnnt 8.189818 hw_loss 0.318550 lr 0.00029723 rank 1
2023-03-01 00:46:28,405 DEBUG TRAIN Batch 45/5600 loss 4.792336 loss_att 5.273753 loss_ctc 6.059009 loss_rnnt 4.322581 hw_loss 0.383590 lr 0.00029723 rank 6
2023-03-01 00:46:28,409 DEBUG TRAIN Batch 45/5600 loss 8.498849 loss_att 10.974037 loss_ctc 13.189081 loss_rnnt 7.211957 hw_loss 0.312169 lr 0.00029722 rank 3
2023-03-01 00:46:28,408 DEBUG TRAIN Batch 45/5600 loss 6.451238 loss_att 8.218531 loss_ctc 9.798122 loss_rnnt 5.456814 hw_loss 0.365090 lr 0.00029723 rank 0
2023-03-01 00:46:28,412 DEBUG TRAIN Batch 45/5600 loss 4.591611 loss_att 8.049702 loss_ctc 9.294465 loss_rnnt 3.146432 hw_loss 0.237215 lr 0.00029723 rank 2
2023-03-01 00:46:28,412 DEBUG TRAIN Batch 45/5600 loss 7.212048 loss_att 8.975884 loss_ctc 12.074012 loss_rnnt 6.033102 hw_loss 0.333593 lr 0.00029723 rank 4
2023-03-01 00:46:28,429 DEBUG TRAIN Batch 45/5600 loss 4.319197 loss_att 6.625209 loss_ctc 6.615017 loss_rnnt 3.402627 hw_loss 0.279857 lr 0.00029723 rank 5
2023-03-01 00:47:33,123 DEBUG TRAIN Batch 45/5700 loss 10.589241 loss_att 13.527831 loss_ctc 18.701118 loss_rnnt 8.841066 hw_loss 0.147886 lr 0.00029721 rank 5
2023-03-01 00:47:33,127 DEBUG TRAIN Batch 45/5700 loss 9.168278 loss_att 11.645418 loss_ctc 17.320408 loss_rnnt 7.378849 hw_loss 0.388217 lr 0.00029721 rank 2
2023-03-01 00:47:33,129 DEBUG TRAIN Batch 45/5700 loss 2.340174 loss_att 4.573453 loss_ctc 3.405454 loss_rnnt 1.652758 hw_loss 0.185105 lr 0.00029722 rank 1
2023-03-01 00:47:33,130 DEBUG TRAIN Batch 45/5700 loss 7.779854 loss_att 8.543842 loss_ctc 8.337343 loss_rnnt 7.429113 hw_loss 0.231772 lr 0.00029722 rank 0
2023-03-01 00:47:33,135 DEBUG TRAIN Batch 45/5700 loss 4.348045 loss_att 5.849176 loss_ctc 7.690532 loss_rnnt 3.535794 hw_loss 0.124425 lr 0.00029721 rank 6
2023-03-01 00:47:33,144 DEBUG TRAIN Batch 45/5700 loss 7.163724 loss_att 7.543028 loss_ctc 11.741791 loss_rnnt 6.298139 hw_loss 0.336215 lr 0.00029721 rank 4
2023-03-01 00:47:33,145 DEBUG TRAIN Batch 45/5700 loss 8.864627 loss_att 12.606510 loss_ctc 24.391254 loss_rnnt 5.883798 hw_loss 0.304190 lr 0.00029721 rank 3
2023-03-01 00:47:33,145 DEBUG TRAIN Batch 45/5700 loss 4.215724 loss_att 6.603756 loss_ctc 5.017310 loss_rnnt 3.506389 hw_loss 0.234095 lr 0.00029721 rank 7
2023-03-01 00:48:13,254 DEBUG TRAIN Batch 45/5800 loss 10.125549 loss_att 13.309555 loss_ctc 19.959377 loss_rnnt 8.028830 hw_loss 0.278889 lr 0.00029720 rank 7
2023-03-01 00:48:13,270 DEBUG TRAIN Batch 45/5800 loss 5.327929 loss_att 9.921766 loss_ctc 9.481913 loss_rnnt 3.702171 hw_loss 0.287111 lr 0.00029720 rank 5
2023-03-01 00:48:13,273 DEBUG TRAIN Batch 45/5800 loss 7.036570 loss_att 8.177424 loss_ctc 21.339384 loss_rnnt 4.835147 hw_loss 0.124144 lr 0.00029720 rank 1
2023-03-01 00:48:13,274 DEBUG TRAIN Batch 45/5800 loss 7.010925 loss_att 9.970226 loss_ctc 9.392932 loss_rnnt 6.030519 hw_loss 0.133021 lr 0.00029720 rank 0
2023-03-01 00:48:13,275 DEBUG TRAIN Batch 45/5800 loss 7.010540 loss_att 7.902218 loss_ctc 13.835911 loss_rnnt 5.736101 hw_loss 0.348851 lr 0.00029720 rank 2
2023-03-01 00:48:13,276 DEBUG TRAIN Batch 45/5800 loss 11.424777 loss_att 13.803549 loss_ctc 13.740400 loss_rnnt 10.430490 hw_loss 0.393341 lr 0.00029720 rank 6
2023-03-01 00:48:13,279 DEBUG TRAIN Batch 45/5800 loss 5.082095 loss_att 6.091850 loss_ctc 7.168083 loss_rnnt 4.463952 hw_loss 0.258863 lr 0.00029720 rank 3
2023-03-01 00:48:13,290 DEBUG TRAIN Batch 45/5800 loss 10.660099 loss_att 13.750975 loss_ctc 15.757068 loss_rnnt 9.202936 hw_loss 0.298857 lr 0.00029720 rank 4
2023-03-01 00:48:52,647 DEBUG TRAIN Batch 45/5900 loss 10.832324 loss_att 15.162981 loss_ctc 18.318695 loss_rnnt 8.870688 hw_loss 0.182478 lr 0.00029718 rank 3
2023-03-01 00:48:52,660 DEBUG TRAIN Batch 45/5900 loss 7.469639 loss_att 12.195475 loss_ctc 12.337973 loss_rnnt 5.816053 hw_loss 0.111204 lr 0.00029719 rank 0
2023-03-01 00:48:52,663 DEBUG TRAIN Batch 45/5900 loss 3.225510 loss_att 5.317043 loss_ctc 4.456354 loss_rnnt 2.548062 hw_loss 0.178178 lr 0.00029719 rank 5
2023-03-01 00:48:52,663 DEBUG TRAIN Batch 45/5900 loss 3.681654 loss_att 6.052795 loss_ctc 6.003362 loss_rnnt 2.775799 hw_loss 0.228874 lr 0.00029719 rank 1
2023-03-01 00:48:52,665 DEBUG TRAIN Batch 45/5900 loss 5.835020 loss_att 9.099928 loss_ctc 8.224867 loss_rnnt 4.801872 hw_loss 0.115350 lr 0.00029719 rank 4
2023-03-01 00:48:52,664 DEBUG TRAIN Batch 45/5900 loss 3.969480 loss_att 7.186011 loss_ctc 5.912490 loss_rnnt 3.006029 hw_loss 0.114520 lr 0.00029719 rank 7
2023-03-01 00:48:52,669 DEBUG TRAIN Batch 45/5900 loss 5.321711 loss_att 8.438190 loss_ctc 8.176796 loss_rnnt 4.145092 hw_loss 0.323709 lr 0.00029719 rank 6
2023-03-01 00:48:52,715 DEBUG TRAIN Batch 45/5900 loss 4.211228 loss_att 6.919663 loss_ctc 3.782075 loss_rnnt 3.570915 hw_loss 0.292212 lr 0.00029719 rank 2
2023-03-01 00:49:32,685 DEBUG TRAIN Batch 45/6000 loss 3.375994 loss_att 6.442370 loss_ctc 5.028235 loss_rnnt 2.400177 hw_loss 0.266707 lr 0.00029718 rank 2
2023-03-01 00:49:32,691 DEBUG TRAIN Batch 45/6000 loss 3.378147 loss_att 6.903004 loss_ctc 6.525933 loss_rnnt 2.087370 hw_loss 0.311438 lr 0.00029717 rank 7
2023-03-01 00:49:32,701 DEBUG TRAIN Batch 45/6000 loss 13.472284 loss_att 19.386789 loss_ctc 18.483753 loss_rnnt 11.528334 hw_loss 0.174102 lr 0.00029718 rank 4
2023-03-01 00:49:32,704 DEBUG TRAIN Batch 45/6000 loss 8.528923 loss_att 11.835625 loss_ctc 14.934073 loss_rnnt 6.875836 hw_loss 0.258236 lr 0.00029718 rank 0
2023-03-01 00:49:32,719 DEBUG TRAIN Batch 45/6000 loss 10.464462 loss_att 16.097639 loss_ctc 23.259001 loss_rnnt 7.499563 hw_loss 0.248110 lr 0.00029717 rank 5
2023-03-01 00:49:32,719 DEBUG TRAIN Batch 45/6000 loss 11.871344 loss_att 15.777298 loss_ctc 18.301117 loss_rnnt 10.107075 hw_loss 0.235829 lr 0.00029718 rank 6
2023-03-01 00:49:32,722 DEBUG TRAIN Batch 45/6000 loss 10.300312 loss_att 14.082619 loss_ctc 18.873999 loss_rnnt 8.288850 hw_loss 0.209705 lr 0.00029717 rank 3
2023-03-01 00:49:32,723 DEBUG TRAIN Batch 45/6000 loss 7.613709 loss_att 10.291301 loss_ctc 11.837063 loss_rnnt 6.373552 hw_loss 0.265359 lr 0.00029718 rank 1
2023-03-01 00:50:37,874 DEBUG TRAIN Batch 45/6100 loss 5.401024 loss_att 7.529911 loss_ctc 7.004761 loss_rnnt 4.653329 hw_loss 0.202661 lr 0.00029716 rank 7
2023-03-01 00:50:37,878 DEBUG TRAIN Batch 45/6100 loss 8.371040 loss_att 11.455475 loss_ctc 14.019238 loss_rnnt 6.895577 hw_loss 0.197781 lr 0.00029716 rank 3
2023-03-01 00:50:37,880 DEBUG TRAIN Batch 45/6100 loss 6.718249 loss_att 10.248851 loss_ctc 11.399464 loss_rnnt 5.318322 hw_loss 0.130584 lr 0.00029716 rank 5
2023-03-01 00:50:37,880 DEBUG TRAIN Batch 45/6100 loss 4.059717 loss_att 5.837826 loss_ctc 4.930528 loss_rnnt 3.428658 hw_loss 0.298742 lr 0.00029716 rank 6
2023-03-01 00:50:37,880 DEBUG TRAIN Batch 45/6100 loss 4.809134 loss_att 6.962012 loss_ctc 7.190014 loss_rnnt 3.909321 hw_loss 0.284599 lr 0.00029716 rank 1
2023-03-01 00:50:37,882 DEBUG TRAIN Batch 45/6100 loss 2.780601 loss_att 7.295240 loss_ctc 6.986377 loss_rnnt 1.213035 hw_loss 0.194753 lr 0.00029716 rank 2
2023-03-01 00:50:37,883 DEBUG TRAIN Batch 45/6100 loss 5.629683 loss_att 8.240904 loss_ctc 9.792630 loss_rnnt 4.424948 hw_loss 0.238935 lr 0.00029716 rank 0
2023-03-01 00:50:37,887 DEBUG TRAIN Batch 45/6100 loss 3.916582 loss_att 6.372200 loss_ctc 8.619839 loss_rnnt 2.611367 hw_loss 0.350608 lr 0.00029716 rank 4
2023-03-01 00:51:17,296 DEBUG TRAIN Batch 45/6200 loss 3.036364 loss_att 6.209030 loss_ctc 7.237501 loss_rnnt 1.711128 hw_loss 0.244784 lr 0.00029715 rank 0
2023-03-01 00:51:17,304 DEBUG TRAIN Batch 45/6200 loss 5.619286 loss_att 7.382371 loss_ctc 8.473868 loss_rnnt 4.731311 hw_loss 0.290150 lr 0.00029715 rank 7
2023-03-01 00:51:17,303 DEBUG TRAIN Batch 45/6200 loss 8.935131 loss_att 9.254550 loss_ctc 11.578300 loss_rnnt 8.340199 hw_loss 0.334920 lr 0.00029715 rank 6
2023-03-01 00:51:17,304 DEBUG TRAIN Batch 45/6200 loss 7.235104 loss_att 9.218529 loss_ctc 10.780204 loss_rnnt 6.165601 hw_loss 0.375257 lr 0.00029715 rank 1
2023-03-01 00:51:17,305 DEBUG TRAIN Batch 45/6200 loss 5.651749 loss_att 8.583635 loss_ctc 7.937646 loss_rnnt 4.646073 hw_loss 0.214710 lr 0.00029715 rank 3
2023-03-01 00:51:17,307 DEBUG TRAIN Batch 45/6200 loss 6.330805 loss_att 10.093189 loss_ctc 12.603023 loss_rnnt 4.577507 hw_loss 0.308485 lr 0.00029715 rank 2
2023-03-01 00:51:17,309 DEBUG TRAIN Batch 45/6200 loss 16.394737 loss_att 18.428299 loss_ctc 23.707031 loss_rnnt 14.871719 hw_loss 0.264997 lr 0.00029715 rank 4
2023-03-01 00:51:17,309 DEBUG TRAIN Batch 45/6200 loss 6.061371 loss_att 10.841476 loss_ctc 11.352056 loss_rnnt 4.229602 hw_loss 0.319356 lr 0.00029715 rank 5
2023-03-01 00:51:56,946 DEBUG TRAIN Batch 45/6300 loss 13.215397 loss_att 13.804726 loss_ctc 20.814499 loss_rnnt 11.907482 hw_loss 0.331564 lr 0.00029714 rank 2
2023-03-01 00:51:56,948 DEBUG TRAIN Batch 45/6300 loss 3.042813 loss_att 5.188066 loss_ctc 4.143600 loss_rnnt 2.270852 hw_loss 0.367760 lr 0.00029713 rank 7
2023-03-01 00:51:56,963 DEBUG TRAIN Batch 45/6300 loss 9.427711 loss_att 15.005691 loss_ctc 19.243048 loss_rnnt 6.865001 hw_loss 0.259505 lr 0.00029714 rank 0
2023-03-01 00:51:56,964 DEBUG TRAIN Batch 45/6300 loss 9.990052 loss_att 10.831066 loss_ctc 15.689746 loss_rnnt 8.910080 hw_loss 0.284646 lr 0.00029714 rank 5
2023-03-01 00:51:56,966 DEBUG TRAIN Batch 45/6300 loss 5.576728 loss_att 8.060794 loss_ctc 7.014539 loss_rnnt 4.775537 hw_loss 0.211256 lr 0.00029714 rank 6
2023-03-01 00:51:56,967 DEBUG TRAIN Batch 45/6300 loss 4.885355 loss_att 8.233521 loss_ctc 7.582061 loss_rnnt 3.809301 hw_loss 0.087860 lr 0.00029714 rank 1
2023-03-01 00:51:56,972 DEBUG TRAIN Batch 45/6300 loss 4.984611 loss_att 7.572844 loss_ctc 8.263488 loss_rnnt 3.911926 hw_loss 0.220976 lr 0.00029714 rank 4
2023-03-01 00:51:57,010 DEBUG TRAIN Batch 45/6300 loss 8.425576 loss_att 10.186718 loss_ctc 13.142426 loss_rnnt 7.265563 hw_loss 0.335382 lr 0.00029713 rank 3
2023-03-01 00:53:02,234 DEBUG TRAIN Batch 45/6400 loss 11.258458 loss_att 12.152075 loss_ctc 11.789741 loss_rnnt 10.865470 hw_loss 0.268926 lr 0.00029712 rank 3
2023-03-01 00:53:02,235 DEBUG TRAIN Batch 45/6400 loss 6.681860 loss_att 8.761139 loss_ctc 12.502543 loss_rnnt 5.354976 hw_loss 0.253009 lr 0.00029712 rank 6
2023-03-01 00:53:02,241 DEBUG TRAIN Batch 45/6400 loss 9.959407 loss_att 16.310650 loss_ctc 14.867358 loss_rnnt 7.860348 hw_loss 0.327031 lr 0.00029712 rank 0
2023-03-01 00:53:02,241 DEBUG TRAIN Batch 45/6400 loss 2.166509 loss_att 6.258716 loss_ctc 5.262365 loss_rnnt 0.806600 hw_loss 0.241289 lr 0.00029712 rank 7
2023-03-01 00:53:02,243 DEBUG TRAIN Batch 45/6400 loss 6.904515 loss_att 9.220197 loss_ctc 11.564680 loss_rnnt 5.606993 hw_loss 0.399433 lr 0.00029713 rank 1
2023-03-01 00:53:02,248 DEBUG TRAIN Batch 45/6400 loss 4.772121 loss_att 8.603291 loss_ctc 8.484777 loss_rnnt 3.464872 hw_loss 0.086238 lr 0.00029712 rank 5
2023-03-01 00:53:02,285 DEBUG TRAIN Batch 45/6400 loss 5.792956 loss_att 7.397698 loss_ctc 8.963948 loss_rnnt 4.872386 hw_loss 0.331542 lr 0.00029712 rank 2
2023-03-01 00:53:02,286 DEBUG TRAIN Batch 45/6400 loss 4.003798 loss_att 8.476258 loss_ctc 8.085817 loss_rnnt 2.377554 hw_loss 0.351528 lr 0.00029712 rank 4
2023-03-01 00:53:42,249 DEBUG TRAIN Batch 45/6500 loss 7.473382 loss_att 10.337522 loss_ctc 10.145729 loss_rnnt 6.428773 hw_loss 0.216503 lr 0.00029711 rank 2
2023-03-01 00:53:42,250 DEBUG TRAIN Batch 45/6500 loss 5.065032 loss_att 7.854679 loss_ctc 9.278007 loss_rnnt 3.782901 hw_loss 0.304635 lr 0.00029711 rank 6
2023-03-01 00:53:42,261 DEBUG TRAIN Batch 45/6500 loss 2.646507 loss_att 5.123153 loss_ctc 3.679526 loss_rnnt 1.767105 hw_loss 0.461881 lr 0.00029711 rank 7
2023-03-01 00:53:42,262 DEBUG TRAIN Batch 45/6500 loss 5.034064 loss_att 7.471653 loss_ctc 6.651420 loss_rnnt 4.251464 hw_loss 0.148941 lr 0.00029711 rank 1
2023-03-01 00:53:42,263 DEBUG TRAIN Batch 45/6500 loss 3.288457 loss_att 6.714665 loss_ctc 10.339057 loss_rnnt 1.502087 hw_loss 0.301967 lr 0.00029711 rank 0
2023-03-01 00:53:42,264 DEBUG TRAIN Batch 45/6500 loss 3.638234 loss_att 6.545371 loss_ctc 5.126685 loss_rnnt 2.698068 hw_loss 0.300523 lr 0.00029711 rank 5
2023-03-01 00:53:42,268 DEBUG TRAIN Batch 45/6500 loss 2.125628 loss_att 4.069843 loss_ctc 2.545038 loss_rnnt 1.554335 hw_loss 0.237241 lr 0.00029711 rank 3
2023-03-01 00:53:42,272 DEBUG TRAIN Batch 45/6500 loss 2.522513 loss_att 6.729550 loss_ctc 5.445873 loss_rnnt 1.195180 hw_loss 0.180272 lr 0.00029711 rank 4
2023-03-01 00:54:21,590 DEBUG TRAIN Batch 45/6600 loss 7.471177 loss_att 9.388321 loss_ctc 9.133040 loss_rnnt 6.724081 hw_loss 0.266411 lr 0.00029710 rank 0
2023-03-01 00:54:21,592 DEBUG TRAIN Batch 45/6600 loss 5.532003 loss_att 8.923066 loss_ctc 13.064931 loss_rnnt 3.730764 hw_loss 0.222443 lr 0.00029709 rank 7
2023-03-01 00:54:21,594 DEBUG TRAIN Batch 45/6600 loss 5.300219 loss_att 7.669477 loss_ctc 8.491888 loss_rnnt 4.264700 hw_loss 0.255210 lr 0.00029710 rank 4
2023-03-01 00:54:21,596 DEBUG TRAIN Batch 45/6600 loss 10.436514 loss_att 13.652984 loss_ctc 19.614368 loss_rnnt 8.476931 hw_loss 0.173579 lr 0.00029710 rank 6
2023-03-01 00:54:21,598 DEBUG TRAIN Batch 45/6600 loss 7.690777 loss_att 11.593208 loss_ctc 10.483271 loss_rnnt 6.389167 hw_loss 0.278984 lr 0.00029710 rank 2
2023-03-01 00:54:21,601 DEBUG TRAIN Batch 45/6600 loss 6.437966 loss_att 7.820642 loss_ctc 9.422122 loss_rnnt 5.677019 hw_loss 0.162235 lr 0.00029710 rank 5
2023-03-01 00:54:21,605 DEBUG TRAIN Batch 45/6600 loss 5.460993 loss_att 7.657443 loss_ctc 5.865386 loss_rnnt 4.856459 hw_loss 0.208733 lr 0.00029709 rank 3
2023-03-01 00:54:21,640 DEBUG TRAIN Batch 45/6600 loss 9.980617 loss_att 12.663269 loss_ctc 22.227686 loss_rnnt 7.660464 hw_loss 0.282524 lr 0.00029710 rank 1
2023-03-01 00:55:00,751 DEBUG TRAIN Batch 45/6700 loss 15.973902 loss_att 19.592754 loss_ctc 23.107277 loss_rnnt 14.219772 hw_loss 0.148578 lr 0.00029709 rank 0
2023-03-01 00:55:00,756 DEBUG TRAIN Batch 45/6700 loss 8.468406 loss_att 10.290684 loss_ctc 12.740986 loss_rnnt 7.401071 hw_loss 0.249752 lr 0.00029708 rank 4
2023-03-01 00:55:00,757 DEBUG TRAIN Batch 45/6700 loss 2.533794 loss_att 5.728580 loss_ctc 4.253907 loss_rnnt 1.653620 hw_loss 0.022253 lr 0.00029708 rank 5
2023-03-01 00:55:00,768 DEBUG TRAIN Batch 45/6700 loss 8.098294 loss_att 11.963191 loss_ctc 18.443493 loss_rnnt 5.788788 hw_loss 0.294688 lr 0.00029709 rank 1
2023-03-01 00:55:00,770 DEBUG TRAIN Batch 45/6700 loss 5.292897 loss_att 9.309034 loss_ctc 12.308565 loss_rnnt 3.418148 hw_loss 0.255186 lr 0.00029708 rank 6
2023-03-01 00:55:00,772 DEBUG TRAIN Batch 45/6700 loss 6.519032 loss_att 8.299900 loss_ctc 9.190877 loss_rnnt 5.702334 hw_loss 0.195523 lr 0.00029708 rank 7
2023-03-01 00:55:00,776 DEBUG TRAIN Batch 45/6700 loss 6.041077 loss_att 8.794670 loss_ctc 12.786222 loss_rnnt 4.519367 hw_loss 0.134322 lr 0.00029708 rank 2
2023-03-01 00:55:00,790 DEBUG TRAIN Batch 45/6700 loss 10.846404 loss_att 10.509933 loss_ctc 10.484251 loss_rnnt 10.889586 hw_loss 0.135748 lr 0.00029708 rank 3
2023-03-01 00:56:05,939 DEBUG TRAIN Batch 45/6800 loss 4.271512 loss_att 6.306660 loss_ctc 7.894492 loss_rnnt 3.264898 hw_loss 0.218474 lr 0.00029707 rank 1
2023-03-01 00:56:05,944 DEBUG TRAIN Batch 45/6800 loss 3.925497 loss_att 6.243272 loss_ctc 5.774472 loss_rnnt 3.028754 hw_loss 0.349983 lr 0.00029707 rank 3
2023-03-01 00:56:05,955 DEBUG TRAIN Batch 45/6800 loss 6.488433 loss_att 9.780255 loss_ctc 10.567102 loss_rnnt 5.155832 hw_loss 0.244527 lr 0.00029707 rank 0
2023-03-01 00:56:05,955 DEBUG TRAIN Batch 45/6800 loss 6.978583 loss_att 10.670813 loss_ctc 13.178798 loss_rnnt 5.319873 hw_loss 0.175442 lr 0.00029707 rank 6
2023-03-01 00:56:05,955 DEBUG TRAIN Batch 45/6800 loss 7.411006 loss_att 10.735946 loss_ctc 10.269644 loss_rnnt 6.315408 hw_loss 0.092734 lr 0.00029707 rank 4
2023-03-01 00:56:05,959 DEBUG TRAIN Batch 45/6800 loss 9.925095 loss_att 10.833920 loss_ctc 13.271013 loss_rnnt 9.212045 hw_loss 0.159678 lr 0.00029707 rank 7
2023-03-01 00:56:05,961 DEBUG TRAIN Batch 45/6800 loss 9.379698 loss_att 11.635860 loss_ctc 12.741570 loss_rnnt 8.410275 hw_loss 0.131140 lr 0.00029707 rank 5
2023-03-01 00:56:05,969 DEBUG TRAIN Batch 45/6800 loss 3.269047 loss_att 6.904781 loss_ctc 7.089706 loss_rnnt 1.932842 hw_loss 0.186822 lr 0.00029707 rank 2
2023-03-01 00:56:45,218 DEBUG TRAIN Batch 45/6900 loss 10.126981 loss_att 10.477975 loss_ctc 15.628779 loss_rnnt 9.102636 hw_loss 0.413572 lr 0.00029705 rank 7
2023-03-01 00:56:45,218 DEBUG TRAIN Batch 45/6900 loss 6.422565 loss_att 7.692368 loss_ctc 9.623566 loss_rnnt 5.566024 hw_loss 0.329587 lr 0.00029706 rank 1
2023-03-01 00:56:45,221 DEBUG TRAIN Batch 45/6900 loss 7.404225 loss_att 7.595968 loss_ctc 10.834412 loss_rnnt 6.704096 hw_loss 0.383292 lr 0.00029706 rank 6
2023-03-01 00:56:45,226 DEBUG TRAIN Batch 45/6900 loss 5.633614 loss_att 7.157025 loss_ctc 10.260318 loss_rnnt 4.659706 hw_loss 0.098122 lr 0.00029706 rank 2
2023-03-01 00:56:45,237 DEBUG TRAIN Batch 45/6900 loss 9.059588 loss_att 11.620858 loss_ctc 15.500962 loss_rnnt 7.641960 hw_loss 0.087232 lr 0.00029706 rank 0
2023-03-01 00:56:45,240 DEBUG TRAIN Batch 45/6900 loss 3.799139 loss_att 6.861701 loss_ctc 8.429887 loss_rnnt 2.369311 hw_loss 0.374781 lr 0.00029705 rank 3
2023-03-01 00:56:45,245 DEBUG TRAIN Batch 45/6900 loss 7.952054 loss_att 10.899233 loss_ctc 11.918336 loss_rnnt 6.668343 hw_loss 0.310196 lr 0.00029706 rank 5
2023-03-01 00:56:45,267 DEBUG TRAIN Batch 45/6900 loss 5.131614 loss_att 7.542234 loss_ctc 8.486986 loss_rnnt 4.115656 hw_loss 0.162094 lr 0.00029706 rank 4
2023-03-01 00:57:24,347 DEBUG TRAIN Batch 45/7000 loss 7.900317 loss_att 10.250023 loss_ctc 16.407576 loss_rnnt 6.116081 hw_loss 0.337488 lr 0.00029704 rank 5
2023-03-01 00:57:24,348 DEBUG TRAIN Batch 45/7000 loss 6.367183 loss_att 7.029012 loss_ctc 9.794059 loss_rnnt 5.563456 hw_loss 0.402083 lr 0.00029704 rank 4
2023-03-01 00:57:24,361 DEBUG TRAIN Batch 45/7000 loss 6.330066 loss_att 11.773567 loss_ctc 14.223425 loss_rnnt 4.023623 hw_loss 0.309926 lr 0.00029704 rank 7
2023-03-01 00:57:24,364 DEBUG TRAIN Batch 45/7000 loss 6.586396 loss_att 14.582174 loss_ctc 14.297964 loss_rnnt 3.865878 hw_loss 0.174663 lr 0.00029705 rank 1
2023-03-01 00:57:24,365 DEBUG TRAIN Batch 45/7000 loss 6.707195 loss_att 9.553160 loss_ctc 14.266218 loss_rnnt 4.979492 hw_loss 0.282450 lr 0.00029704 rank 2
2023-03-01 00:57:24,366 DEBUG TRAIN Batch 45/7000 loss 3.338850 loss_att 6.457190 loss_ctc 4.558559 loss_rnnt 2.551848 hw_loss 0.001323 lr 0.00029704 rank 6
2023-03-01 00:57:24,367 DEBUG TRAIN Batch 45/7000 loss 5.226625 loss_att 6.065177 loss_ctc 7.224716 loss_rnnt 4.610811 hw_loss 0.340670 lr 0.00029705 rank 0
2023-03-01 00:57:24,369 DEBUG TRAIN Batch 45/7000 loss 7.771659 loss_att 10.154015 loss_ctc 8.762897 loss_rnnt 7.131570 hw_loss 0.058974 lr 0.00029704 rank 3
2023-03-01 00:58:04,785 DEBUG TRAIN Batch 45/7100 loss 6.923100 loss_att 11.101212 loss_ctc 13.471151 loss_rnnt 5.110218 hw_loss 0.195352 lr 0.00029703 rank 2
2023-03-01 00:58:04,786 DEBUG TRAIN Batch 45/7100 loss 6.309772 loss_att 11.295282 loss_ctc 12.223132 loss_rnnt 4.376811 hw_loss 0.276396 lr 0.00029703 rank 5
2023-03-01 00:58:04,793 DEBUG TRAIN Batch 45/7100 loss 2.639162 loss_att 4.554198 loss_ctc 5.641086 loss_rnnt 1.821739 hw_loss 0.064048 lr 0.00029703 rank 3
2023-03-01 00:58:04,796 DEBUG TRAIN Batch 45/7100 loss 7.428217 loss_att 10.629128 loss_ctc 10.267605 loss_rnnt 6.384641 hw_loss 0.046516 lr 0.00029703 rank 0
2023-03-01 00:58:04,801 DEBUG TRAIN Batch 45/7100 loss 3.857855 loss_att 6.227883 loss_ctc 8.419742 loss_rnnt 2.688148 hw_loss 0.163967 lr 0.00029703 rank 7
2023-03-01 00:58:04,801 DEBUG TRAIN Batch 45/7100 loss 2.478893 loss_att 4.906400 loss_ctc 3.122611 loss_rnnt 1.810805 hw_loss 0.181420 lr 0.00029703 rank 1
2023-03-01 00:58:04,805 DEBUG TRAIN Batch 45/7100 loss 8.110473 loss_att 11.311102 loss_ctc 17.247280 loss_rnnt 6.155225 hw_loss 0.181651 lr 0.00029703 rank 6
2023-03-01 00:58:04,843 DEBUG TRAIN Batch 45/7100 loss 13.411104 loss_att 16.142363 loss_ctc 21.210951 loss_rnnt 11.782272 hw_loss 0.079876 lr 0.00029703 rank 4
2023-03-01 00:59:08,466 DEBUG TRAIN Batch 45/7200 loss 3.059318 loss_att 6.757660 loss_ctc 7.125689 loss_rnnt 1.616621 hw_loss 0.301586 lr 0.00029702 rank 5
2023-03-01 00:59:08,467 DEBUG TRAIN Batch 45/7200 loss 4.883368 loss_att 9.489551 loss_ctc 8.929684 loss_rnnt 3.319046 hw_loss 0.194209 lr 0.00029701 rank 3
2023-03-01 00:59:08,469 DEBUG TRAIN Batch 45/7200 loss 2.152759 loss_att 7.996860 loss_ctc 3.669447 loss_rnnt 0.630055 hw_loss 0.284361 lr 0.00029702 rank 2
2023-03-01 00:59:08,482 DEBUG TRAIN Batch 45/7200 loss 8.025768 loss_att 11.864440 loss_ctc 16.704159 loss_rnnt 5.966782 hw_loss 0.251500 lr 0.00029702 rank 1
2023-03-01 00:59:08,486 DEBUG TRAIN Batch 45/7200 loss 7.727595 loss_att 10.217467 loss_ctc 12.099358 loss_rnnt 6.513291 hw_loss 0.250177 lr 0.00029702 rank 0
2023-03-01 00:59:08,489 DEBUG TRAIN Batch 45/7200 loss 6.551850 loss_att 10.396764 loss_ctc 13.389753 loss_rnnt 4.785334 hw_loss 0.160900 lr 0.00029702 rank 4
2023-03-01 00:59:08,490 DEBUG TRAIN Batch 45/7200 loss 4.140303 loss_att 7.991126 loss_ctc 6.059922 loss_rnnt 2.952746 hw_loss 0.302704 lr 0.00029702 rank 6
2023-03-01 00:59:08,495 DEBUG TRAIN Batch 45/7200 loss 2.049253 loss_att 4.573497 loss_ctc 4.549792 loss_rnnt 1.040672 hw_loss 0.319362 lr 0.00029702 rank 7
2023-03-01 00:59:47,383 DEBUG TRAIN Batch 45/7300 loss 14.640860 loss_att 21.140282 loss_ctc 22.130028 loss_rnnt 12.180325 hw_loss 0.303927 lr 0.00029701 rank 6
2023-03-01 00:59:47,399 DEBUG TRAIN Batch 45/7300 loss 4.325623 loss_att 6.482738 loss_ctc 7.644308 loss_rnnt 3.337216 hw_loss 0.214674 lr 0.00029701 rank 1
2023-03-01 00:59:47,400 DEBUG TRAIN Batch 45/7300 loss 9.797050 loss_att 14.582109 loss_ctc 16.957405 loss_rnnt 7.757335 hw_loss 0.239978 lr 0.00029701 rank 4
2023-03-01 00:59:47,401 DEBUG TRAIN Batch 45/7300 loss 5.484168 loss_att 8.864290 loss_ctc 7.830886 loss_rnnt 4.399166 hw_loss 0.180154 lr 0.00029700 rank 5
2023-03-01 00:59:47,401 DEBUG TRAIN Batch 45/7300 loss 5.171481 loss_att 7.641973 loss_ctc 10.272875 loss_rnnt 3.836051 hw_loss 0.302146 lr 0.00029701 rank 0
2023-03-01 00:59:47,405 DEBUG TRAIN Batch 45/7300 loss 9.167437 loss_att 13.675314 loss_ctc 15.181086 loss_rnnt 7.345792 hw_loss 0.221717 lr 0.00029700 rank 3
2023-03-01 00:59:47,408 DEBUG TRAIN Batch 45/7300 loss 4.652719 loss_att 6.892600 loss_ctc 7.368062 loss_rnnt 3.801340 hw_loss 0.077544 lr 0.00029700 rank 7
2023-03-01 00:59:47,412 DEBUG TRAIN Batch 45/7300 loss 1.859300 loss_att 5.295062 loss_ctc 4.580784 loss_rnnt 0.791282 hw_loss 0.033751 lr 0.00029700 rank 2
2023-03-01 01:00:27,130 DEBUG TRAIN Batch 45/7400 loss 10.576567 loss_att 14.151270 loss_ctc 20.502131 loss_rnnt 8.404443 hw_loss 0.250826 lr 0.00029699 rank 6
2023-03-01 01:00:27,142 DEBUG TRAIN Batch 45/7400 loss 12.786821 loss_att 14.206197 loss_ctc 20.225634 loss_rnnt 11.372065 hw_loss 0.260696 lr 0.00029699 rank 5
2023-03-01 01:00:27,143 DEBUG TRAIN Batch 45/7400 loss 6.696553 loss_att 10.135326 loss_ctc 10.433139 loss_rnnt 5.387754 hw_loss 0.230311 lr 0.00029699 rank 0
2023-03-01 01:00:27,145 DEBUG TRAIN Batch 45/7400 loss 3.505886 loss_att 5.179461 loss_ctc 6.267352 loss_rnnt 2.694880 hw_loss 0.202679 lr 0.00029699 rank 3
2023-03-01 01:00:27,147 DEBUG TRAIN Batch 45/7400 loss 14.507172 loss_att 20.632378 loss_ctc 26.601702 loss_rnnt 11.603600 hw_loss 0.123610 lr 0.00029699 rank 4
2023-03-01 01:00:27,151 DEBUG TRAIN Batch 45/7400 loss 7.674600 loss_att 9.260301 loss_ctc 10.298355 loss_rnnt 6.859682 hw_loss 0.277394 lr 0.00029699 rank 1
2023-03-01 01:00:27,164 DEBUG TRAIN Batch 45/7400 loss 6.123351 loss_att 9.836121 loss_ctc 13.967484 loss_rnnt 4.214299 hw_loss 0.226150 lr 0.00029699 rank 2
2023-03-01 01:00:27,168 DEBUG TRAIN Batch 45/7400 loss 5.438181 loss_att 7.693097 loss_ctc 11.038443 loss_rnnt 4.089783 hw_loss 0.282588 lr 0.00029699 rank 7
2023-03-01 01:01:31,493 DEBUG TRAIN Batch 45/7500 loss 7.844485 loss_att 8.828012 loss_ctc 13.416390 loss_rnnt 6.705041 hw_loss 0.374658 lr 0.00029698 rank 7
2023-03-01 01:01:31,493 DEBUG TRAIN Batch 45/7500 loss 10.999228 loss_att 15.945614 loss_ctc 17.411591 loss_rnnt 9.112946 hw_loss 0.078795 lr 0.00029698 rank 0
2023-03-01 01:01:31,495 DEBUG TRAIN Batch 45/7500 loss 4.729911 loss_att 6.903605 loss_ctc 6.889717 loss_rnnt 3.929578 hw_loss 0.145537 lr 0.00029698 rank 5
2023-03-01 01:01:31,496 DEBUG TRAIN Batch 45/7500 loss 3.352463 loss_att 4.988826 loss_ctc 3.674166 loss_rnnt 2.873303 hw_loss 0.204362 lr 0.00029698 rank 4
2023-03-01 01:01:31,498 DEBUG TRAIN Batch 45/7500 loss 0.986434 loss_att 2.706528 loss_ctc 1.747386 loss_rnnt 0.395386 hw_loss 0.272942 lr 0.00029697 rank 3
2023-03-01 01:01:31,497 DEBUG TRAIN Batch 45/7500 loss 7.237315 loss_att 10.362818 loss_ctc 12.548775 loss_rnnt 5.807812 hw_loss 0.180389 lr 0.00029698 rank 2
2023-03-01 01:01:31,542 DEBUG TRAIN Batch 45/7500 loss 9.008602 loss_att 12.999527 loss_ctc 14.659835 loss_rnnt 7.293220 hw_loss 0.306938 lr 0.00029698 rank 1
2023-03-01 01:01:31,547 DEBUG TRAIN Batch 45/7500 loss 5.596333 loss_att 7.048098 loss_ctc 9.311900 loss_rnnt 4.604006 hw_loss 0.387309 lr 0.00029698 rank 6
2023-03-01 01:02:10,673 DEBUG TRAIN Batch 45/7600 loss 9.410456 loss_att 12.014162 loss_ctc 16.415775 loss_rnnt 7.744163 hw_loss 0.396579 lr 0.00029697 rank 4
2023-03-01 01:02:10,673 DEBUG TRAIN Batch 45/7600 loss 9.882311 loss_att 10.519919 loss_ctc 13.544123 loss_rnnt 9.107333 hw_loss 0.298529 lr 0.00029697 rank 0
2023-03-01 01:02:10,678 DEBUG TRAIN Batch 45/7600 loss 8.242825 loss_att 10.942278 loss_ctc 7.741518 loss_rnnt 7.656639 hw_loss 0.212131 lr 0.00029696 rank 7
2023-03-01 01:02:10,678 DEBUG TRAIN Batch 45/7600 loss 9.266290 loss_att 12.322496 loss_ctc 15.030437 loss_rnnt 7.679431 hw_loss 0.388245 lr 0.00029696 rank 3
2023-03-01 01:02:10,679 DEBUG TRAIN Batch 45/7600 loss 8.833640 loss_att 11.884809 loss_ctc 13.522575 loss_rnnt 7.430031 hw_loss 0.315344 lr 0.00029697 rank 1
2023-03-01 01:02:10,681 DEBUG TRAIN Batch 45/7600 loss 7.029998 loss_att 11.211481 loss_ctc 12.908681 loss_rnnt 5.255849 hw_loss 0.288803 lr 0.00029697 rank 2
2023-03-01 01:02:10,682 DEBUG TRAIN Batch 45/7600 loss 8.065583 loss_att 11.212195 loss_ctc 13.372691 loss_rnnt 6.607072 hw_loss 0.227950 lr 0.00029696 rank 5
2023-03-01 01:02:10,691 DEBUG TRAIN Batch 45/7600 loss 2.342571 loss_att 5.038468 loss_ctc 4.278996 loss_rnnt 1.408200 hw_loss 0.256878 lr 0.00029697 rank 6
2023-03-01 01:02:49,941 DEBUG TRAIN Batch 45/7700 loss 8.836196 loss_att 11.989079 loss_ctc 13.935763 loss_rnnt 7.398366 hw_loss 0.238706 lr 0.00029695 rank 1
2023-03-01 01:02:49,954 DEBUG TRAIN Batch 45/7700 loss 5.732962 loss_att 7.900914 loss_ctc 9.871920 loss_rnnt 4.584651 hw_loss 0.305360 lr 0.00029695 rank 2
2023-03-01 01:02:49,955 DEBUG TRAIN Batch 45/7700 loss 2.841638 loss_att 4.118834 loss_ctc 4.967590 loss_rnnt 2.120120 hw_loss 0.342411 lr 0.00029695 rank 7
2023-03-01 01:02:49,956 DEBUG TRAIN Batch 45/7700 loss 7.385923 loss_att 7.291691 loss_ctc 9.734277 loss_rnnt 6.878532 hw_loss 0.399607 lr 0.00029695 rank 0
2023-03-01 01:02:49,962 DEBUG TRAIN Batch 45/7700 loss 2.921061 loss_att 5.457199 loss_ctc 5.128546 loss_rnnt 1.943084 hw_loss 0.330784 lr 0.00029695 rank 4
2023-03-01 01:02:49,962 DEBUG TRAIN Batch 45/7700 loss 4.912774 loss_att 10.613820 loss_ctc 9.541107 loss_rnnt 2.992693 hw_loss 0.305175 lr 0.00029695 rank 3
2023-03-01 01:02:49,964 DEBUG TRAIN Batch 45/7700 loss 4.244278 loss_att 7.638590 loss_ctc 8.432695 loss_rnnt 2.788402 hw_loss 0.409794 lr 0.00029695 rank 6
2023-03-01 01:02:50,008 DEBUG TRAIN Batch 45/7700 loss 7.311055 loss_att 7.701800 loss_ctc 9.796573 loss_rnnt 6.759347 hw_loss 0.266544 lr 0.00029695 rank 5
2023-03-01 01:03:30,294 DEBUG TRAIN Batch 45/7800 loss 11.148030 loss_att 14.038530 loss_ctc 18.180157 loss_rnnt 9.460089 hw_loss 0.322920 lr 0.00029694 rank 5
2023-03-01 01:03:30,294 DEBUG TRAIN Batch 45/7800 loss 6.820077 loss_att 8.148630 loss_ctc 7.376735 loss_rnnt 6.327983 hw_loss 0.285304 lr 0.00029694 rank 2
2023-03-01 01:03:30,296 DEBUG TRAIN Batch 45/7800 loss 4.897965 loss_att 6.837086 loss_ctc 7.347869 loss_rnnt 4.102348 hw_loss 0.152136 lr 0.00029694 rank 1
2023-03-01 01:03:30,307 DEBUG TRAIN Batch 45/7800 loss 3.145767 loss_att 6.492392 loss_ctc 5.577192 loss_rnnt 1.970329 hw_loss 0.341105 lr 0.00029694 rank 6
2023-03-01 01:03:30,312 DEBUG TRAIN Batch 45/7800 loss 5.114518 loss_att 7.083968 loss_ctc 9.805140 loss_rnnt 3.952574 hw_loss 0.267446 lr 0.00029694 rank 0
2023-03-01 01:03:30,315 DEBUG TRAIN Batch 45/7800 loss 10.835170 loss_att 14.241690 loss_ctc 22.229086 loss_rnnt 8.533466 hw_loss 0.189769 lr 0.00029694 rank 7
2023-03-01 01:03:30,323 DEBUG TRAIN Batch 45/7800 loss 5.471042 loss_att 7.629707 loss_ctc 8.632965 loss_rnnt 4.562331 hw_loss 0.103853 lr 0.00029694 rank 3
2023-03-01 01:03:30,322 DEBUG TRAIN Batch 45/7800 loss 4.956562 loss_att 7.881672 loss_ctc 12.986743 loss_rnnt 3.236541 hw_loss 0.120577 lr 0.00029694 rank 4
2023-03-01 01:04:34,831 DEBUG TRAIN Batch 45/7900 loss 6.518984 loss_att 8.151066 loss_ctc 7.787946 loss_rnnt 5.873528 hw_loss 0.280959 lr 0.00029693 rank 6
2023-03-01 01:04:34,845 DEBUG TRAIN Batch 45/7900 loss 11.806786 loss_att 12.132907 loss_ctc 11.514482 loss_rnnt 11.673866 hw_loss 0.200005 lr 0.00029693 rank 5
2023-03-01 01:04:34,844 DEBUG TRAIN Batch 45/7900 loss 7.587680 loss_att 9.144218 loss_ctc 11.030205 loss_rnnt 6.653028 hw_loss 0.308137 lr 0.00029693 rank 4
2023-03-01 01:04:34,845 DEBUG TRAIN Batch 45/7900 loss 5.089053 loss_att 6.911824 loss_ctc 7.356119 loss_rnnt 4.277030 hw_loss 0.272239 lr 0.00029693 rank 0
2023-03-01 01:04:34,848 DEBUG TRAIN Batch 45/7900 loss 6.233663 loss_att 7.733092 loss_ctc 7.914690 loss_rnnt 5.625435 hw_loss 0.157883 lr 0.00029693 rank 2
2023-03-01 01:04:34,848 DEBUG TRAIN Batch 45/7900 loss 5.481576 loss_att 8.392994 loss_ctc 9.658154 loss_rnnt 4.158119 hw_loss 0.345555 lr 0.00029692 rank 7
2023-03-01 01:04:34,856 DEBUG TRAIN Batch 45/7900 loss 6.034852 loss_att 10.337488 loss_ctc 10.690222 loss_rnnt 4.407216 hw_loss 0.274484 lr 0.00029692 rank 3
2023-03-01 01:04:34,892 DEBUG TRAIN Batch 45/7900 loss 5.149713 loss_att 8.636409 loss_ctc 8.321697 loss_rnnt 3.989084 hw_loss 0.075673 lr 0.00029693 rank 1
2023-03-01 01:05:13,879 DEBUG TRAIN Batch 45/8000 loss 6.783050 loss_att 9.683744 loss_ctc 9.943754 loss_rnnt 5.598695 hw_loss 0.342728 lr 0.00029691 rank 3
2023-03-01 01:05:13,886 DEBUG TRAIN Batch 45/8000 loss 9.257552 loss_att 12.387695 loss_ctc 17.665102 loss_rnnt 7.329759 hw_loss 0.338921 lr 0.00029691 rank 5
2023-03-01 01:05:13,893 DEBUG TRAIN Batch 45/8000 loss 12.895375 loss_att 15.902037 loss_ctc 19.369633 loss_rnnt 11.298931 hw_loss 0.247272 lr 0.00029691 rank 7
2023-03-01 01:05:13,895 DEBUG TRAIN Batch 45/8000 loss 9.898072 loss_att 13.491093 loss_ctc 18.469988 loss_rnnt 7.872047 hw_loss 0.308434 lr 0.00029692 rank 0
2023-03-01 01:05:13,895 DEBUG TRAIN Batch 45/8000 loss 9.665069 loss_att 12.003027 loss_ctc 11.889557 loss_rnnt 8.762220 hw_loss 0.259983 lr 0.00029692 rank 1
2023-03-01 01:05:13,897 DEBUG TRAIN Batch 45/8000 loss 8.953530 loss_att 13.555300 loss_ctc 17.282661 loss_rnnt 6.791697 hw_loss 0.245492 lr 0.00029691 rank 4
2023-03-01 01:05:13,903 DEBUG TRAIN Batch 45/8000 loss 1.703492 loss_att 4.343040 loss_ctc 5.015539 loss_rnnt 0.591139 hw_loss 0.267819 lr 0.00029691 rank 2
2023-03-01 01:05:13,946 DEBUG TRAIN Batch 45/8000 loss 7.573848 loss_att 11.290592 loss_ctc 13.295420 loss_rnnt 5.937908 hw_loss 0.243217 lr 0.00029691 rank 6
2023-03-01 01:05:53,291 DEBUG TRAIN Batch 45/8100 loss 5.930724 loss_att 7.359075 loss_ctc 12.428308 loss_rnnt 4.706720 hw_loss 0.134979 lr 0.00029690 rank 6
2023-03-01 01:05:53,303 DEBUG TRAIN Batch 45/8100 loss 12.111956 loss_att 13.266218 loss_ctc 17.277328 loss_rnnt 11.069886 hw_loss 0.229689 lr 0.00029690 rank 4
2023-03-01 01:05:53,303 DEBUG TRAIN Batch 45/8100 loss 3.776320 loss_att 4.751261 loss_ctc 7.737232 loss_rnnt 2.910711 hw_loss 0.267186 lr 0.00029690 rank 7
2023-03-01 01:05:53,306 DEBUG TRAIN Batch 45/8100 loss 5.866639 loss_att 8.407287 loss_ctc 12.088257 loss_rnnt 4.401111 hw_loss 0.239717 lr 0.00029690 rank 0
2023-03-01 01:05:53,307 DEBUG TRAIN Batch 45/8100 loss 10.679353 loss_att 14.964384 loss_ctc 19.830685 loss_rnnt 8.527078 hw_loss 0.140797 lr 0.00029690 rank 3
2023-03-01 01:05:53,310 DEBUG TRAIN Batch 45/8100 loss 5.438295 loss_att 8.476545 loss_ctc 10.505017 loss_rnnt 4.003939 hw_loss 0.283392 lr 0.00029690 rank 2
2023-03-01 01:05:53,319 DEBUG TRAIN Batch 45/8100 loss 4.418389 loss_att 8.224153 loss_ctc 10.363008 loss_rnnt 2.758570 hw_loss 0.198844 lr 0.00029690 rank 5
2023-03-01 01:05:53,323 DEBUG TRAIN Batch 45/8100 loss 3.809953 loss_att 6.597136 loss_ctc 7.287843 loss_rnnt 2.661605 hw_loss 0.238487 lr 0.00029690 rank 1
2023-03-01 01:06:33,831 DEBUG TRAIN Batch 45/8200 loss 5.996006 loss_att 8.771237 loss_ctc 10.578994 loss_rnnt 4.687155 hw_loss 0.267638 lr 0.00029689 rank 1
2023-03-01 01:06:33,831 DEBUG TRAIN Batch 45/8200 loss 6.849079 loss_att 9.390615 loss_ctc 12.413101 loss_rnnt 5.471467 hw_loss 0.238940 lr 0.00029689 rank 6
2023-03-01 01:06:33,833 DEBUG TRAIN Batch 45/8200 loss 2.822597 loss_att 6.343072 loss_ctc 5.864630 loss_rnnt 1.594703 hw_loss 0.221614 lr 0.00029689 rank 2
2023-03-01 01:06:33,834 DEBUG TRAIN Batch 45/8200 loss 10.354517 loss_att 9.923666 loss_ctc 15.611053 loss_rnnt 9.598526 hw_loss 0.264915 lr 0.00029688 rank 3
2023-03-01 01:06:33,836 DEBUG TRAIN Batch 45/8200 loss 5.740355 loss_att 7.238937 loss_ctc 10.115395 loss_rnnt 4.662059 hw_loss 0.366078 lr 0.00029689 rank 0
2023-03-01 01:06:33,836 DEBUG TRAIN Batch 45/8200 loss 7.067177 loss_att 10.312785 loss_ctc 10.359306 loss_rnnt 5.886253 hw_loss 0.174096 lr 0.00029688 rank 7
2023-03-01 01:06:33,840 DEBUG TRAIN Batch 45/8200 loss 9.018101 loss_att 11.087345 loss_ctc 14.979301 loss_rnnt 7.684881 hw_loss 0.233520 lr 0.00029689 rank 5
2023-03-01 01:06:33,838 DEBUG TRAIN Batch 45/8200 loss 3.423889 loss_att 6.234013 loss_ctc 4.155624 loss_rnnt 2.649321 hw_loss 0.215586 lr 0.00029689 rank 4
2023-03-01 01:07:12,550 DEBUG TRAIN Batch 45/8300 loss 6.673800 loss_att 10.811199 loss_ctc 15.237316 loss_rnnt 4.601475 hw_loss 0.193207 lr 0.00029688 rank 0
2023-03-01 01:07:12,557 DEBUG TRAIN Batch 45/8300 loss 9.476106 loss_att 14.662624 loss_ctc 19.429243 loss_rnnt 6.948852 hw_loss 0.305370 lr 0.00029687 rank 3
2023-03-01 01:07:12,561 DEBUG TRAIN Batch 45/8300 loss 4.667111 loss_att 5.613252 loss_ctc 10.554968 loss_rnnt 3.542936 hw_loss 0.281062 lr 0.00029687 rank 4
2023-03-01 01:07:12,563 DEBUG TRAIN Batch 45/8300 loss 3.407295 loss_att 6.949296 loss_ctc 5.878970 loss_rnnt 2.141867 hw_loss 0.426509 lr 0.00029687 rank 7
2023-03-01 01:07:12,567 DEBUG TRAIN Batch 45/8300 loss 5.029016 loss_att 6.871453 loss_ctc 7.253931 loss_rnnt 4.228713 hw_loss 0.253426 lr 0.00029687 rank 6
2023-03-01 01:07:12,572 DEBUG TRAIN Batch 45/8300 loss 8.177695 loss_att 11.691568 loss_ctc 14.431112 loss_rnnt 6.489836 hw_loss 0.283681 lr 0.00029687 rank 2
2023-03-01 01:07:12,575 DEBUG TRAIN Batch 45/8300 loss 5.166918 loss_att 6.453725 loss_ctc 6.189527 loss_rnnt 4.661433 hw_loss 0.209580 lr 0.00029688 rank 1
2023-03-01 01:07:12,575 DEBUG TRAIN Batch 45/8300 loss 8.266420 loss_att 10.679871 loss_ctc 12.577683 loss_rnnt 7.112893 hw_loss 0.180001 lr 0.00029687 rank 5
2023-03-01 01:07:43,911 DEBUG CV Batch 45/0 loss 0.966213 loss_att 1.068156 loss_ctc 1.628005 loss_rnnt 0.623906 hw_loss 0.438149 history loss 0.930427 rank 7
2023-03-01 01:07:43,912 DEBUG CV Batch 45/0 loss 0.966213 loss_att 1.068156 loss_ctc 1.628005 loss_rnnt 0.623906 hw_loss 0.438149 history loss 0.930427 rank 5
2023-03-01 01:07:43,915 DEBUG CV Batch 45/0 loss 0.966213 loss_att 1.068156 loss_ctc 1.628005 loss_rnnt 0.623906 hw_loss 0.438149 history loss 0.930427 rank 6
2023-03-01 01:07:43,920 DEBUG CV Batch 45/0 loss 0.966213 loss_att 1.068156 loss_ctc 1.628005 loss_rnnt 0.623906 hw_loss 0.438149 history loss 0.930427 rank 4
2023-03-01 01:07:43,929 DEBUG CV Batch 45/0 loss 0.966213 loss_att 1.068156 loss_ctc 1.628005 loss_rnnt 0.623906 hw_loss 0.438149 history loss 0.930427 rank 0
2023-03-01 01:07:43,930 DEBUG CV Batch 45/0 loss 0.966213 loss_att 1.068156 loss_ctc 1.628005 loss_rnnt 0.623906 hw_loss 0.438149 history loss 0.930427 rank 3
2023-03-01 01:07:43,938 DEBUG CV Batch 45/0 loss 0.966213 loss_att 1.068156 loss_ctc 1.628005 loss_rnnt 0.623906 hw_loss 0.438149 history loss 0.930427 rank 1
2023-03-01 01:07:43,949 DEBUG CV Batch 45/0 loss 0.966213 loss_att 1.068156 loss_ctc 1.628005 loss_rnnt 0.623906 hw_loss 0.438149 history loss 0.930427 rank 2
2023-03-01 01:07:55,195 DEBUG CV Batch 45/100 loss 3.145887 loss_att 4.456497 loss_ctc 8.035399 loss_rnnt 2.194357 hw_loss 0.070263 history loss 2.918313 rank 1
2023-03-01 01:07:55,350 DEBUG CV Batch 45/100 loss 3.145887 loss_att 4.456497 loss_ctc 8.035399 loss_rnnt 2.194357 hw_loss 0.070263 history loss 2.918313 rank 5
2023-03-01 01:07:55,361 DEBUG CV Batch 45/100 loss 3.145887 loss_att 4.456497 loss_ctc 8.035399 loss_rnnt 2.194357 hw_loss 0.070263 history loss 2.918313 rank 6
2023-03-01 01:07:55,456 DEBUG CV Batch 45/100 loss 3.145887 loss_att 4.456497 loss_ctc 8.035399 loss_rnnt 2.194357 hw_loss 0.070263 history loss 2.918313 rank 4
2023-03-01 01:07:55,528 DEBUG CV Batch 45/100 loss 3.145887 loss_att 4.456497 loss_ctc 8.035399 loss_rnnt 2.194357 hw_loss 0.070263 history loss 2.918313 rank 3
2023-03-01 01:07:55,529 DEBUG CV Batch 45/100 loss 3.145887 loss_att 4.456497 loss_ctc 8.035399 loss_rnnt 2.194357 hw_loss 0.070263 history loss 2.918313 rank 2
2023-03-01 01:07:55,783 DEBUG CV Batch 45/100 loss 3.145887 loss_att 4.456497 loss_ctc 8.035399 loss_rnnt 2.194357 hw_loss 0.070263 history loss 2.918313 rank 7
2023-03-01 01:07:55,862 DEBUG CV Batch 45/100 loss 3.145887 loss_att 4.456497 loss_ctc 8.035399 loss_rnnt 2.194357 hw_loss 0.070263 history loss 2.918313 rank 0
2023-03-01 01:08:08,775 DEBUG CV Batch 45/200 loss 6.767519 loss_att 10.142868 loss_ctc 11.593191 loss_rnnt 5.293175 hw_loss 0.292222 history loss 3.469926 rank 1
2023-03-01 01:08:08,837 DEBUG CV Batch 45/200 loss 6.767519 loss_att 10.142868 loss_ctc 11.593191 loss_rnnt 5.293175 hw_loss 0.292222 history loss 3.469926 rank 5
2023-03-01 01:08:08,965 DEBUG CV Batch 45/200 loss 6.767519 loss_att 10.142868 loss_ctc 11.593191 loss_rnnt 5.293175 hw_loss 0.292222 history loss 3.469926 rank 6
2023-03-01 01:08:09,350 DEBUG CV Batch 45/200 loss 6.767519 loss_att 10.142868 loss_ctc 11.593191 loss_rnnt 5.293175 hw_loss 0.292222 history loss 3.469926 rank 3
2023-03-01 01:08:09,351 DEBUG CV Batch 45/200 loss 6.767519 loss_att 10.142868 loss_ctc 11.593191 loss_rnnt 5.293175 hw_loss 0.292222 history loss 3.469926 rank 2
2023-03-01 01:08:09,445 DEBUG CV Batch 45/200 loss 6.767519 loss_att 10.142868 loss_ctc 11.593191 loss_rnnt 5.293175 hw_loss 0.292222 history loss 3.469926 rank 4
2023-03-01 01:08:09,664 DEBUG CV Batch 45/200 loss 6.767519 loss_att 10.142868 loss_ctc 11.593191 loss_rnnt 5.293175 hw_loss 0.292222 history loss 3.469926 rank 7
2023-03-01 01:08:09,866 DEBUG CV Batch 45/200 loss 6.767519 loss_att 10.142868 loss_ctc 11.593191 loss_rnnt 5.293175 hw_loss 0.292222 history loss 3.469926 rank 0
2023-03-01 01:08:21,209 DEBUG CV Batch 45/300 loss 2.292650 loss_att 3.246854 loss_ctc 3.770202 loss_rnnt 1.799586 hw_loss 0.197281 history loss 3.639925 rank 5
2023-03-01 01:08:21,250 DEBUG CV Batch 45/300 loss 2.292650 loss_att 3.246854 loss_ctc 3.770202 loss_rnnt 1.799586 hw_loss 0.197281 history loss 3.639925 rank 1
2023-03-01 01:08:21,290 DEBUG CV Batch 45/300 loss 2.292650 loss_att 3.246854 loss_ctc 3.770202 loss_rnnt 1.799586 hw_loss 0.197281 history loss 3.639925 rank 6
2023-03-01 01:08:22,109 DEBUG CV Batch 45/300 loss 2.292650 loss_att 3.246854 loss_ctc 3.770202 loss_rnnt 1.799586 hw_loss 0.197281 history loss 3.639925 rank 2
2023-03-01 01:08:22,209 DEBUG CV Batch 45/300 loss 2.292650 loss_att 3.246854 loss_ctc 3.770202 loss_rnnt 1.799586 hw_loss 0.197281 history loss 3.639925 rank 4
2023-03-01 01:08:22,321 DEBUG CV Batch 45/300 loss 2.292650 loss_att 3.246854 loss_ctc 3.770202 loss_rnnt 1.799586 hw_loss 0.197281 history loss 3.639925 rank 7
2023-03-01 01:08:22,336 DEBUG CV Batch 45/300 loss 2.292650 loss_att 3.246854 loss_ctc 3.770202 loss_rnnt 1.799586 hw_loss 0.197281 history loss 3.639925 rank 3
2023-03-01 01:08:22,782 DEBUG CV Batch 45/300 loss 2.292650 loss_att 3.246854 loss_ctc 3.770202 loss_rnnt 1.799586 hw_loss 0.197281 history loss 3.639925 rank 0
2023-03-01 01:08:33,340 DEBUG CV Batch 45/400 loss 14.750051 loss_att 59.983646 loss_ctc 7.146142 loss_rnnt 6.716130 hw_loss 0.001978 history loss 4.422872 rank 1
2023-03-01 01:08:33,412 DEBUG CV Batch 45/400 loss 14.750051 loss_att 59.983646 loss_ctc 7.146142 loss_rnnt 6.716130 hw_loss 0.001978 history loss 4.422872 rank 5
2023-03-01 01:08:33,592 DEBUG CV Batch 45/400 loss 14.750051 loss_att 59.983646 loss_ctc 7.146142 loss_rnnt 6.716130 hw_loss 0.001978 history loss 4.422872 rank 6
2023-03-01 01:08:34,708 DEBUG CV Batch 45/400 loss 14.750051 loss_att 59.983646 loss_ctc 7.146142 loss_rnnt 6.716130 hw_loss 0.001978 history loss 4.422872 rank 2
2023-03-01 01:08:34,813 DEBUG CV Batch 45/400 loss 14.750051 loss_att 59.983646 loss_ctc 7.146142 loss_rnnt 6.716130 hw_loss 0.001978 history loss 4.422872 rank 7
2023-03-01 01:08:34,951 DEBUG CV Batch 45/400 loss 14.750051 loss_att 59.983646 loss_ctc 7.146142 loss_rnnt 6.716130 hw_loss 0.001978 history loss 4.422872 rank 4
2023-03-01 01:08:35,084 DEBUG CV Batch 45/400 loss 14.750051 loss_att 59.983646 loss_ctc 7.146142 loss_rnnt 6.716130 hw_loss 0.001978 history loss 4.422872 rank 3
2023-03-01 01:08:35,565 DEBUG CV Batch 45/400 loss 14.750051 loss_att 59.983646 loss_ctc 7.146142 loss_rnnt 6.716130 hw_loss 0.001978 history loss 4.422872 rank 0
2023-03-01 01:08:44,352 DEBUG CV Batch 45/500 loss 4.411606 loss_att 4.271521 loss_ctc 6.276433 loss_rnnt 4.046942 hw_loss 0.270069 history loss 5.013489 rank 1
2023-03-01 01:08:44,406 DEBUG CV Batch 45/500 loss 4.411606 loss_att 4.271521 loss_ctc 6.276433 loss_rnnt 4.046942 hw_loss 0.270069 history loss 5.013489 rank 6
2023-03-01 01:08:44,487 DEBUG CV Batch 45/500 loss 4.411606 loss_att 4.271521 loss_ctc 6.276433 loss_rnnt 4.046942 hw_loss 0.270069 history loss 5.013489 rank 5
2023-03-01 01:08:45,857 DEBUG CV Batch 45/500 loss 4.411606 loss_att 4.271521 loss_ctc 6.276433 loss_rnnt 4.046942 hw_loss 0.270069 history loss 5.013489 rank 2
2023-03-01 01:08:45,980 DEBUG CV Batch 45/500 loss 4.411606 loss_att 4.271521 loss_ctc 6.276433 loss_rnnt 4.046942 hw_loss 0.270069 history loss 5.013489 rank 7
2023-03-01 01:08:46,117 DEBUG CV Batch 45/500 loss 4.411606 loss_att 4.271521 loss_ctc 6.276433 loss_rnnt 4.046942 hw_loss 0.270069 history loss 5.013489 rank 4
2023-03-01 01:08:46,212 DEBUG CV Batch 45/500 loss 4.411606 loss_att 4.271521 loss_ctc 6.276433 loss_rnnt 4.046942 hw_loss 0.270069 history loss 5.013489 rank 3
2023-03-01 01:08:46,875 DEBUG CV Batch 45/500 loss 4.411606 loss_att 4.271521 loss_ctc 6.276433 loss_rnnt 4.046942 hw_loss 0.270069 history loss 5.013489 rank 0
2023-03-01 01:08:56,787 DEBUG CV Batch 45/600 loss 6.770339 loss_att 5.754716 loss_ctc 8.766598 loss_rnnt 6.453328 hw_loss 0.476191 history loss 5.894834 rank 6
2023-03-01 01:08:56,842 DEBUG CV Batch 45/600 loss 6.770339 loss_att 5.754716 loss_ctc 8.766598 loss_rnnt 6.453328 hw_loss 0.476191 history loss 5.894834 rank 1
2023-03-01 01:08:56,977 DEBUG CV Batch 45/600 loss 6.770339 loss_att 5.754716 loss_ctc 8.766598 loss_rnnt 6.453328 hw_loss 0.476191 history loss 5.894834 rank 5
2023-03-01 01:08:58,278 DEBUG CV Batch 45/600 loss 6.770339 loss_att 5.754716 loss_ctc 8.766598 loss_rnnt 6.453328 hw_loss 0.476191 history loss 5.894834 rank 2
2023-03-01 01:08:58,539 DEBUG CV Batch 45/600 loss 6.770339 loss_att 5.754716 loss_ctc 8.766598 loss_rnnt 6.453328 hw_loss 0.476191 history loss 5.894834 rank 4
2023-03-01 01:08:58,597 DEBUG CV Batch 45/600 loss 6.770339 loss_att 5.754716 loss_ctc 8.766598 loss_rnnt 6.453328 hw_loss 0.476191 history loss 5.894834 rank 7
2023-03-01 01:08:58,810 DEBUG CV Batch 45/600 loss 6.770339 loss_att 5.754716 loss_ctc 8.766598 loss_rnnt 6.453328 hw_loss 0.476191 history loss 5.894834 rank 3
2023-03-01 01:08:59,626 DEBUG CV Batch 45/600 loss 6.770339 loss_att 5.754716 loss_ctc 8.766598 loss_rnnt 6.453328 hw_loss 0.476191 history loss 5.894834 rank 0
2023-03-01 01:09:08,235 DEBUG CV Batch 45/700 loss 12.108512 loss_att 28.835205 loss_ctc 14.263463 loss_rnnt 8.401166 hw_loss 0.140026 history loss 6.423577 rank 1
2023-03-01 01:09:08,432 DEBUG CV Batch 45/700 loss 12.108512 loss_att 28.835205 loss_ctc 14.263463 loss_rnnt 8.401166 hw_loss 0.140026 history loss 6.423577 rank 6
2023-03-01 01:09:08,747 DEBUG CV Batch 45/700 loss 12.108512 loss_att 28.835205 loss_ctc 14.263463 loss_rnnt 8.401166 hw_loss 0.140026 history loss 6.423577 rank 5
2023-03-01 01:09:09,822 DEBUG CV Batch 45/700 loss 12.108512 loss_att 28.835205 loss_ctc 14.263463 loss_rnnt 8.401166 hw_loss 0.140026 history loss 6.423577 rank 2
2023-03-01 01:09:10,311 DEBUG CV Batch 45/700 loss 12.108512 loss_att 28.835205 loss_ctc 14.263463 loss_rnnt 8.401166 hw_loss 0.140026 history loss 6.423577 rank 4
2023-03-01 01:09:10,478 DEBUG CV Batch 45/700 loss 12.108512 loss_att 28.835205 loss_ctc 14.263463 loss_rnnt 8.401166 hw_loss 0.140026 history loss 6.423577 rank 7
2023-03-01 01:09:10,483 DEBUG CV Batch 45/700 loss 12.108512 loss_att 28.835205 loss_ctc 14.263463 loss_rnnt 8.401166 hw_loss 0.140026 history loss 6.423577 rank 3
2023-03-01 01:09:11,647 DEBUG CV Batch 45/700 loss 12.108512 loss_att 28.835205 loss_ctc 14.263463 loss_rnnt 8.401166 hw_loss 0.140026 history loss 6.423577 rank 0
2023-03-01 01:09:19,777 DEBUG CV Batch 45/800 loss 5.572815 loss_att 6.668807 loss_ctc 12.077441 loss_rnnt 4.371654 hw_loss 0.215025 history loss 5.959773 rank 1
2023-03-01 01:09:20,266 DEBUG CV Batch 45/800 loss 5.572815 loss_att 6.668807 loss_ctc 12.077441 loss_rnnt 4.371654 hw_loss 0.215025 history loss 5.959773 rank 6
2023-03-01 01:09:20,541 DEBUG CV Batch 45/800 loss 5.572815 loss_att 6.668807 loss_ctc 12.077441 loss_rnnt 4.371654 hw_loss 0.215025 history loss 5.959773 rank 5
2023-03-01 01:09:21,424 DEBUG CV Batch 45/800 loss 5.572815 loss_att 6.668807 loss_ctc 12.077441 loss_rnnt 4.371654 hw_loss 0.215025 history loss 5.959773 rank 2
2023-03-01 01:09:21,872 DEBUG CV Batch 45/800 loss 5.572815 loss_att 6.668807 loss_ctc 12.077441 loss_rnnt 4.371654 hw_loss 0.215025 history loss 5.959773 rank 4
2023-03-01 01:09:22,318 DEBUG CV Batch 45/800 loss 5.572815 loss_att 6.668807 loss_ctc 12.077441 loss_rnnt 4.371654 hw_loss 0.215025 history loss 5.959773 rank 7
2023-03-01 01:09:22,627 DEBUG CV Batch 45/800 loss 5.572815 loss_att 6.668807 loss_ctc 12.077441 loss_rnnt 4.371654 hw_loss 0.215025 history loss 5.959773 rank 3
2023-03-01 01:09:23,643 DEBUG CV Batch 45/800 loss 5.572815 loss_att 6.668807 loss_ctc 12.077441 loss_rnnt 4.371654 hw_loss 0.215025 history loss 5.959773 rank 0
2023-03-01 01:09:33,130 DEBUG CV Batch 45/900 loss 6.556929 loss_att 9.309753 loss_ctc 16.015551 loss_rnnt 4.619805 hw_loss 0.235142 history loss 5.793492 rank 1
2023-03-01 01:09:33,916 DEBUG CV Batch 45/900 loss 6.556929 loss_att 9.309753 loss_ctc 16.015551 loss_rnnt 4.619805 hw_loss 0.235142 history loss 5.793492 rank 6
2023-03-01 01:09:34,125 DEBUG CV Batch 45/900 loss 6.556929 loss_att 9.309753 loss_ctc 16.015551 loss_rnnt 4.619805 hw_loss 0.235142 history loss 5.793492 rank 5
2023-03-01 01:09:34,988 DEBUG CV Batch 45/900 loss 6.556929 loss_att 9.309753 loss_ctc 16.015551 loss_rnnt 4.619805 hw_loss 0.235142 history loss 5.793492 rank 2
2023-03-01 01:09:35,633 DEBUG CV Batch 45/900 loss 6.556929 loss_att 9.309753 loss_ctc 16.015551 loss_rnnt 4.619805 hw_loss 0.235142 history loss 5.793492 rank 4
2023-03-01 01:09:36,087 DEBUG CV Batch 45/900 loss 6.556929 loss_att 9.309753 loss_ctc 16.015551 loss_rnnt 4.619805 hw_loss 0.235142 history loss 5.793492 rank 7
2023-03-01 01:09:36,790 DEBUG CV Batch 45/900 loss 6.556929 loss_att 9.309753 loss_ctc 16.015551 loss_rnnt 4.619805 hw_loss 0.235142 history loss 5.793492 rank 3
2023-03-01 01:09:37,556 DEBUG CV Batch 45/900 loss 6.556929 loss_att 9.309753 loss_ctc 16.015551 loss_rnnt 4.619805 hw_loss 0.235142 history loss 5.793492 rank 0
2023-03-01 01:09:45,573 DEBUG CV Batch 45/1000 loss 4.196389 loss_att 4.557491 loss_ctc 5.729798 loss_rnnt 3.740024 hw_loss 0.336919 history loss 5.607362 rank 1
2023-03-01 01:09:46,427 DEBUG CV Batch 45/1000 loss 4.196389 loss_att 4.557491 loss_ctc 5.729798 loss_rnnt 3.740024 hw_loss 0.336919 history loss 5.607362 rank 6
2023-03-01 01:09:46,835 DEBUG CV Batch 45/1000 loss 4.196389 loss_att 4.557491 loss_ctc 5.729798 loss_rnnt 3.740024 hw_loss 0.336919 history loss 5.607362 rank 5
2023-03-01 01:09:47,679 DEBUG CV Batch 45/1000 loss 4.196389 loss_att 4.557491 loss_ctc 5.729798 loss_rnnt 3.740024 hw_loss 0.336919 history loss 5.607362 rank 2
2023-03-01 01:09:48,472 DEBUG CV Batch 45/1000 loss 4.196389 loss_att 4.557491 loss_ctc 5.729798 loss_rnnt 3.740024 hw_loss 0.336919 history loss 5.607362 rank 4
2023-03-01 01:09:48,817 DEBUG CV Batch 45/1000 loss 4.196389 loss_att 4.557491 loss_ctc 5.729798 loss_rnnt 3.740024 hw_loss 0.336919 history loss 5.607362 rank 7
2023-03-01 01:09:49,628 DEBUG CV Batch 45/1000 loss 4.196389 loss_att 4.557491 loss_ctc 5.729798 loss_rnnt 3.740024 hw_loss 0.336919 history loss 5.607362 rank 3
2023-03-01 01:09:50,641 DEBUG CV Batch 45/1000 loss 4.196389 loss_att 4.557491 loss_ctc 5.729798 loss_rnnt 3.740024 hw_loss 0.336919 history loss 5.607362 rank 0
2023-03-01 01:09:57,593 DEBUG CV Batch 45/1100 loss 4.500968 loss_att 4.395005 loss_ctc 7.388938 loss_rnnt 3.903561 hw_loss 0.437881 history loss 5.571913 rank 1
2023-03-01 01:09:58,679 DEBUG CV Batch 45/1100 loss 4.500968 loss_att 4.395005 loss_ctc 7.388938 loss_rnnt 3.903561 hw_loss 0.437881 history loss 5.571913 rank 6
2023-03-01 01:09:59,157 DEBUG CV Batch 45/1100 loss 4.500968 loss_att 4.395005 loss_ctc 7.388938 loss_rnnt 3.903561 hw_loss 0.437880 history loss 5.571913 rank 5
2023-03-01 01:09:59,976 DEBUG CV Batch 45/1100 loss 4.500968 loss_att 4.395005 loss_ctc 7.388938 loss_rnnt 3.903561 hw_loss 0.437881 history loss 5.571913 rank 2
2023-03-01 01:10:01,113 DEBUG CV Batch 45/1100 loss 4.500968 loss_att 4.395005 loss_ctc 7.388938 loss_rnnt 3.903561 hw_loss 0.437881 history loss 5.571913 rank 4
2023-03-01 01:10:01,188 DEBUG CV Batch 45/1100 loss 4.500968 loss_att 4.395005 loss_ctc 7.388938 loss_rnnt 3.903561 hw_loss 0.437880 history loss 5.571913 rank 7
2023-03-01 01:10:02,111 DEBUG CV Batch 45/1100 loss 4.500968 loss_att 4.395005 loss_ctc 7.388938 loss_rnnt 3.903561 hw_loss 0.437880 history loss 5.571913 rank 3
2023-03-01 01:10:03,251 DEBUG CV Batch 45/1100 loss 4.500968 loss_att 4.395005 loss_ctc 7.388938 loss_rnnt 3.903561 hw_loss 0.437880 history loss 5.571913 rank 0
2023-03-01 01:10:08,392 DEBUG CV Batch 45/1200 loss 6.952796 loss_att 6.768957 loss_ctc 8.467360 loss_rnnt 6.640724 hw_loss 0.275433 history loss 5.827261 rank 1
2023-03-01 01:10:09,615 DEBUG CV Batch 45/1200 loss 6.952796 loss_att 6.768957 loss_ctc 8.467360 loss_rnnt 6.640724 hw_loss 0.275433 history loss 5.827261 rank 6
2023-03-01 01:10:10,165 DEBUG CV Batch 45/1200 loss 6.952796 loss_att 6.768957 loss_ctc 8.467360 loss_rnnt 6.640724 hw_loss 0.275433 history loss 5.827261 rank 5
2023-03-01 01:10:11,270 DEBUG CV Batch 45/1200 loss 6.952796 loss_att 6.768957 loss_ctc 8.467360 loss_rnnt 6.640724 hw_loss 0.275433 history loss 5.827261 rank 2
2023-03-01 01:10:12,201 DEBUG CV Batch 45/1200 loss 6.952796 loss_att 6.768957 loss_ctc 8.467360 loss_rnnt 6.640724 hw_loss 0.275433 history loss 5.827261 rank 4
2023-03-01 01:10:12,435 DEBUG CV Batch 45/1200 loss 6.952796 loss_att 6.768957 loss_ctc 8.467360 loss_rnnt 6.640724 hw_loss 0.275433 history loss 5.827261 rank 7
2023-03-01 01:10:13,377 DEBUG CV Batch 45/1200 loss 6.952796 loss_att 6.768957 loss_ctc 8.467360 loss_rnnt 6.640724 hw_loss 0.275433 history loss 5.827261 rank 3
2023-03-01 01:10:14,569 DEBUG CV Batch 45/1200 loss 6.952796 loss_att 6.768957 loss_ctc 8.467360 loss_rnnt 6.640724 hw_loss 0.275433 history loss 5.827261 rank 0
2023-03-01 01:10:20,515 DEBUG CV Batch 45/1300 loss 4.038504 loss_att 3.929384 loss_ctc 5.578595 loss_rnnt 3.656019 hw_loss 0.373057 history loss 6.124617 rank 1
2023-03-01 01:10:21,906 DEBUG CV Batch 45/1300 loss 4.038504 loss_att 3.929384 loss_ctc 5.578595 loss_rnnt 3.656019 hw_loss 0.373057 history loss 6.124617 rank 6
2023-03-01 01:10:22,648 DEBUG CV Batch 45/1300 loss 4.038504 loss_att 3.929384 loss_ctc 5.578595 loss_rnnt 3.656019 hw_loss 0.373057 history loss 6.124617 rank 5
2023-03-01 01:10:24,050 DEBUG CV Batch 45/1300 loss 4.038504 loss_att 3.929384 loss_ctc 5.578595 loss_rnnt 3.656019 hw_loss 0.373057 history loss 6.124617 rank 2
2023-03-01 01:10:24,530 DEBUG CV Batch 45/1300 loss 4.038504 loss_att 3.929384 loss_ctc 5.578595 loss_rnnt 3.656019 hw_loss 0.373057 history loss 6.124617 rank 4
2023-03-01 01:10:24,965 DEBUG CV Batch 45/1300 loss 4.038504 loss_att 3.929384 loss_ctc 5.578595 loss_rnnt 3.656019 hw_loss 0.373057 history loss 6.124617 rank 7
2023-03-01 01:10:26,114 DEBUG CV Batch 45/1300 loss 4.038504 loss_att 3.929384 loss_ctc 5.578595 loss_rnnt 3.656019 hw_loss 0.373057 history loss 6.124617 rank 3
2023-03-01 01:10:27,370 DEBUG CV Batch 45/1300 loss 4.038504 loss_att 3.929384 loss_ctc 5.578595 loss_rnnt 3.656019 hw_loss 0.373057 history loss 6.124617 rank 0
2023-03-01 01:10:31,708 DEBUG CV Batch 45/1400 loss 3.820959 loss_att 13.308809 loss_ctc 3.273213 loss_rnnt 1.859745 hw_loss 0.256270 history loss 6.389691 rank 1
2023-03-01 01:10:33,789 DEBUG CV Batch 45/1400 loss 3.820959 loss_att 13.308809 loss_ctc 3.273213 loss_rnnt 1.859745 hw_loss 0.256270 history loss 6.389691 rank 6
2023-03-01 01:10:34,237 DEBUG CV Batch 45/1400 loss 3.820959 loss_att 13.308809 loss_ctc 3.273213 loss_rnnt 1.859745 hw_loss 0.256270 history loss 6.389691 rank 5
2023-03-01 01:10:35,578 DEBUG CV Batch 45/1400 loss 3.820959 loss_att 13.308809 loss_ctc 3.273213 loss_rnnt 1.859745 hw_loss 0.256270 history loss 6.389691 rank 2
2023-03-01 01:10:36,180 DEBUG CV Batch 45/1400 loss 3.820959 loss_att 13.308809 loss_ctc 3.273213 loss_rnnt 1.859745 hw_loss 0.256270 history loss 6.389691 rank 4
2023-03-01 01:10:36,692 DEBUG CV Batch 45/1400 loss 3.820959 loss_att 13.308809 loss_ctc 3.273213 loss_rnnt 1.859745 hw_loss 0.256270 history loss 6.389691 rank 7
2023-03-01 01:10:37,924 DEBUG CV Batch 45/1400 loss 3.820959 loss_att 13.308809 loss_ctc 3.273213 loss_rnnt 1.859745 hw_loss 0.256270 history loss 6.389691 rank 3
2023-03-01 01:10:39,340 DEBUG CV Batch 45/1400 loss 3.820959 loss_att 13.308809 loss_ctc 3.273213 loss_rnnt 1.859745 hw_loss 0.256270 history loss 6.389691 rank 0
2023-03-01 01:10:43,483 DEBUG CV Batch 45/1500 loss 6.924166 loss_att 7.535554 loss_ctc 7.469531 loss_rnnt 6.610956 hw_loss 0.221658 history loss 6.256396 rank 1
2023-03-01 01:10:45,803 DEBUG CV Batch 45/1500 loss 6.924166 loss_att 7.535554 loss_ctc 7.469531 loss_rnnt 6.610956 hw_loss 0.221658 history loss 6.256396 rank 6
2023-03-01 01:10:46,331 DEBUG CV Batch 45/1500 loss 6.924166 loss_att 7.535554 loss_ctc 7.469531 loss_rnnt 6.610956 hw_loss 0.221658 history loss 6.256396 rank 5
2023-03-01 01:10:47,420 DEBUG CV Batch 45/1500 loss 6.924166 loss_att 7.535554 loss_ctc 7.469531 loss_rnnt 6.610956 hw_loss 0.221658 history loss 6.256396 rank 2
2023-03-01 01:10:47,925 DEBUG CV Batch 45/1500 loss 6.924166 loss_att 7.535554 loss_ctc 7.469531 loss_rnnt 6.610956 hw_loss 0.221658 history loss 6.256396 rank 4
2023-03-01 01:10:48,760 DEBUG CV Batch 45/1500 loss 6.924166 loss_att 7.535554 loss_ctc 7.469531 loss_rnnt 6.610956 hw_loss 0.221658 history loss 6.256396 rank 7
2023-03-01 01:10:50,125 DEBUG CV Batch 45/1500 loss 6.924166 loss_att 7.535554 loss_ctc 7.469531 loss_rnnt 6.610956 hw_loss 0.221658 history loss 6.256396 rank 3
2023-03-01 01:10:51,549 DEBUG CV Batch 45/1500 loss 6.924166 loss_att 7.535554 loss_ctc 7.469531 loss_rnnt 6.610956 hw_loss 0.221658 history loss 6.256396 rank 0
2023-03-01 01:10:56,629 DEBUG CV Batch 45/1600 loss 9.592669 loss_att 13.433945 loss_ctc 11.903596 loss_rnnt 8.379514 hw_loss 0.256454 history loss 6.213525 rank 1
2023-03-01 01:10:59,042 DEBUG CV Batch 45/1600 loss 9.592669 loss_att 13.433945 loss_ctc 11.903596 loss_rnnt 8.379514 hw_loss 0.256454 history loss 6.213525 rank 6
2023-03-01 01:10:59,613 DEBUG CV Batch 45/1600 loss 9.592669 loss_att 13.433945 loss_ctc 11.903596 loss_rnnt 8.379514 hw_loss 0.256454 history loss 6.213525 rank 5
2023-03-01 01:11:00,791 DEBUG CV Batch 45/1600 loss 9.592669 loss_att 13.433945 loss_ctc 11.903596 loss_rnnt 8.379514 hw_loss 0.256454 history loss 6.213525 rank 2
2023-03-01 01:11:01,101 DEBUG CV Batch 45/1600 loss 9.592669 loss_att 13.433945 loss_ctc 11.903596 loss_rnnt 8.379514 hw_loss 0.256454 history loss 6.213525 rank 4
2023-03-01 01:11:02,373 DEBUG CV Batch 45/1600 loss 9.592669 loss_att 13.433945 loss_ctc 11.903596 loss_rnnt 8.379514 hw_loss 0.256454 history loss 6.213525 rank 7
2023-03-01 01:11:04,237 DEBUG CV Batch 45/1600 loss 9.592669 loss_att 13.433945 loss_ctc 11.903596 loss_rnnt 8.379514 hw_loss 0.256454 history loss 6.213525 rank 3
2023-03-01 01:11:05,226 DEBUG CV Batch 45/1600 loss 9.592669 loss_att 13.433945 loss_ctc 11.903596 loss_rnnt 8.379514 hw_loss 0.256454 history loss 6.213525 rank 0
2023-03-01 01:11:09,189 DEBUG CV Batch 45/1700 loss 8.406705 loss_att 6.708230 loss_ctc 14.453154 loss_rnnt 7.785120 hw_loss 0.290788 history loss 6.151451 rank 1
2023-03-01 01:11:11,865 DEBUG CV Batch 45/1700 loss 8.406705 loss_att 6.708230 loss_ctc 14.453154 loss_rnnt 7.785120 hw_loss 0.290788 history loss 6.151451 rank 6
2023-03-01 01:11:12,378 DEBUG CV Batch 45/1700 loss 8.406705 loss_att 6.708230 loss_ctc 14.453154 loss_rnnt 7.785120 hw_loss 0.290788 history loss 6.151451 rank 5
2023-03-01 01:11:13,343 DEBUG CV Batch 45/1700 loss 8.406705 loss_att 6.708230 loss_ctc 14.453154 loss_rnnt 7.785120 hw_loss 0.290788 history loss 6.151451 rank 2
2023-03-01 01:11:13,551 DEBUG CV Batch 45/1700 loss 8.406705 loss_att 6.708230 loss_ctc 14.453154 loss_rnnt 7.785120 hw_loss 0.290788 history loss 6.151451 rank 4
2023-03-01 01:11:15,042 DEBUG CV Batch 45/1700 loss 8.406705 loss_att 6.708230 loss_ctc 14.453154 loss_rnnt 7.785120 hw_loss 0.290788 history loss 6.151451 rank 7
2023-03-01 01:11:16,934 DEBUG CV Batch 45/1700 loss 8.406705 loss_att 6.708230 loss_ctc 14.453154 loss_rnnt 7.785120 hw_loss 0.290788 history loss 6.151451 rank 3
2023-03-01 01:11:17,910 DEBUG CV Batch 45/1700 loss 8.406705 loss_att 6.708230 loss_ctc 14.453154 loss_rnnt 7.785120 hw_loss 0.290788 history loss 6.151451 rank 0
2023-03-01 01:11:18,322 INFO Epoch 45 CV info cv_loss 6.129365719330416
2023-03-01 01:11:18,322 INFO Epoch 46 TRAIN info lr 0.00029687055712183144
2023-03-01 01:11:18,328 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 01:11:21,399 INFO Epoch 45 CV info cv_loss 6.129365720178957
2023-03-01 01:11:21,399 INFO Epoch 46 TRAIN info lr 0.0002968663709969595
2023-03-01 01:11:21,402 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 01:11:21,611 INFO Epoch 45 CV info cv_loss 6.1293657180726795
2023-03-01 01:11:21,611 INFO Epoch 46 TRAIN info lr 0.00029687003384653806
2023-03-01 01:11:21,616 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 01:11:22,633 INFO Epoch 45 CV info cv_loss 6.129365717827162
2023-03-01 01:11:22,633 INFO Epoch 46 TRAIN info lr 0.00029687003384653806
2023-03-01 01:11:22,635 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 01:11:22,687 INFO Epoch 45 CV info cv_loss 6.129365719963592
2023-03-01 01:11:22,687 INFO Epoch 46 TRAIN info lr 0.00029687055712183144
2023-03-01 01:11:22,691 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 01:11:24,353 INFO Epoch 45 CV info cv_loss 6.1293657175988745
2023-03-01 01:11:24,354 INFO Epoch 46 TRAIN info lr 0.00029686270828295687
2023-03-01 01:11:24,356 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 01:11:26,307 INFO Epoch 45 CV info cv_loss 6.129365718051143
2023-03-01 01:11:26,308 INFO Epoch 46 TRAIN info lr 0.00029686532449341055
2023-03-01 01:11:26,314 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 01:11:27,453 INFO Epoch 45 CV info cv_loss 6.129365718163133
2023-03-01 01:11:27,453 INFO Checkpoint: save to checkpoint exp/2_27_rnnt_bias_loss_2_class_both_finetune/45.pt
2023-03-01 01:11:28,009 INFO Epoch 46 TRAIN info lr 0.00029687265025067584
2023-03-01 01:11:28,013 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 01:12:29,488 DEBUG TRAIN Batch 46/0 loss 9.175502 loss_att 9.437382 loss_ctc 13.282501 loss_rnnt 8.325519 hw_loss 0.468764 lr 0.00029686 rank 7
2023-03-01 01:12:29,492 DEBUG TRAIN Batch 46/0 loss 7.177521 loss_att 7.294822 loss_ctc 9.116524 loss_rnnt 6.684255 hw_loss 0.396136 lr 0.00029687 rank 2
2023-03-01 01:12:29,492 DEBUG TRAIN Batch 46/0 loss 7.423771 loss_att 7.819187 loss_ctc 10.697636 loss_rnnt 6.701172 hw_loss 0.388126 lr 0.00029687 rank 4
2023-03-01 01:12:29,494 DEBUG TRAIN Batch 46/0 loss 6.549973 loss_att 6.350195 loss_ctc 9.016879 loss_rnnt 6.021826 hw_loss 0.448466 lr 0.00029687 rank 1
2023-03-01 01:12:29,497 DEBUG TRAIN Batch 46/0 loss 10.707259 loss_att 11.942971 loss_ctc 14.160391 loss_rnnt 9.751603 hw_loss 0.465179 lr 0.00029687 rank 0
2023-03-01 01:12:29,499 DEBUG TRAIN Batch 46/0 loss 8.910225 loss_att 8.320972 loss_ctc 12.249109 loss_rnnt 8.399582 hw_loss 0.343705 lr 0.00029687 rank 5
2023-03-01 01:12:29,523 DEBUG TRAIN Batch 46/0 loss 5.547967 loss_att 6.087649 loss_ctc 8.792780 loss_rnnt 4.826068 hw_loss 0.339978 lr 0.00029687 rank 6
2023-03-01 01:12:29,571 DEBUG TRAIN Batch 46/0 loss 5.625776 loss_att 6.047439 loss_ctc 7.755549 loss_rnnt 5.036251 hw_loss 0.414791 lr 0.00029686 rank 3
2023-03-01 01:13:07,534 DEBUG TRAIN Batch 46/100 loss 4.649880 loss_att 6.596500 loss_ctc 6.982292 loss_rnnt 3.790493 hw_loss 0.298266 lr 0.00029686 rank 5
2023-03-01 01:13:07,546 DEBUG TRAIN Batch 46/100 loss 5.315008 loss_att 10.878815 loss_ctc 6.612454 loss_rnnt 3.918328 hw_loss 0.207985 lr 0.00029685 rank 3
2023-03-01 01:13:07,546 DEBUG TRAIN Batch 46/100 loss 6.173676 loss_att 8.446783 loss_ctc 10.532255 loss_rnnt 5.001551 hw_loss 0.255677 lr 0.00029686 rank 0
2023-03-01 01:13:07,546 DEBUG TRAIN Batch 46/100 loss 5.340145 loss_att 9.269400 loss_ctc 12.886261 loss_rnnt 3.398474 hw_loss 0.280633 lr 0.00029686 rank 1
2023-03-01 01:13:07,548 DEBUG TRAIN Batch 46/100 loss 6.875164 loss_att 9.776421 loss_ctc 10.216798 loss_rnnt 5.660686 hw_loss 0.353764 lr 0.00029685 rank 7
2023-03-01 01:13:07,557 DEBUG TRAIN Batch 46/100 loss 6.727996 loss_att 10.114880 loss_ctc 11.649089 loss_rnnt 5.235501 hw_loss 0.298074 lr 0.00029686 rank 2
2023-03-01 01:13:07,565 DEBUG TRAIN Batch 46/100 loss 7.200949 loss_att 12.141966 loss_ctc 12.269164 loss_rnnt 5.438539 hw_loss 0.184584 lr 0.00029686 rank 4
2023-03-01 01:13:07,571 DEBUG TRAIN Batch 46/100 loss 4.519738 loss_att 10.233939 loss_ctc 5.932889 loss_rnnt 3.063630 hw_loss 0.234089 lr 0.00029685 rank 6
2023-03-01 01:13:45,906 DEBUG TRAIN Batch 46/200 loss 6.141310 loss_att 11.018929 loss_ctc 15.439021 loss_rnnt 3.743150 hw_loss 0.343016 lr 0.00029685 rank 0
2023-03-01 01:13:45,923 DEBUG TRAIN Batch 46/200 loss 5.964471 loss_att 8.210262 loss_ctc 7.866255 loss_rnnt 5.143523 hw_loss 0.221659 lr 0.00029684 rank 7
2023-03-01 01:13:45,926 DEBUG TRAIN Batch 46/200 loss 6.047823 loss_att 8.234571 loss_ctc 6.972042 loss_rnnt 5.410579 hw_loss 0.143750 lr 0.00029684 rank 2
2023-03-01 01:13:45,927 DEBUG TRAIN Batch 46/200 loss 12.972920 loss_att 18.047924 loss_ctc 24.920630 loss_rnnt 10.267460 hw_loss 0.182685 lr 0.00029684 rank 3
2023-03-01 01:13:45,928 DEBUG TRAIN Batch 46/200 loss 11.272652 loss_att 16.094761 loss_ctc 16.644852 loss_rnnt 9.499887 hw_loss 0.172590 lr 0.00029684 rank 5
2023-03-01 01:13:45,929 DEBUG TRAIN Batch 46/200 loss 2.577404 loss_att 5.877276 loss_ctc 4.152827 loss_rnnt 1.640446 hw_loss 0.125486 lr 0.00029684 rank 6
2023-03-01 01:13:45,931 DEBUG TRAIN Batch 46/200 loss 14.246743 loss_att 17.840231 loss_ctc 21.506500 loss_rnnt 12.507414 hw_loss 0.098745 lr 0.00029684 rank 4
2023-03-01 01:13:45,936 DEBUG TRAIN Batch 46/200 loss 4.306206 loss_att 8.648160 loss_ctc 10.480708 loss_rnnt 2.513433 hw_loss 0.189589 lr 0.00029684 rank 1
2023-03-01 01:14:23,951 DEBUG TRAIN Batch 46/300 loss 5.168081 loss_att 7.090304 loss_ctc 7.039511 loss_rnnt 4.399898 hw_loss 0.251653 lr 0.00029683 rank 0
2023-03-01 01:14:23,956 DEBUG TRAIN Batch 46/300 loss 2.424982 loss_att 3.412410 loss_ctc 4.036007 loss_rnnt 1.820961 hw_loss 0.359497 lr 0.00029683 rank 3
2023-03-01 01:14:23,957 DEBUG TRAIN Batch 46/300 loss 8.090735 loss_att 12.196283 loss_ctc 16.159904 loss_rnnt 6.085447 hw_loss 0.203041 lr 0.00029683 rank 1
2023-03-01 01:14:23,960 DEBUG TRAIN Batch 46/300 loss 6.935927 loss_att 10.460869 loss_ctc 9.933725 loss_rnnt 5.769104 hw_loss 0.116489 lr 0.00029683 rank 2
2023-03-01 01:14:23,960 DEBUG TRAIN Batch 46/300 loss 7.318055 loss_att 8.519829 loss_ctc 11.754496 loss_rnnt 6.396564 hw_loss 0.168020 lr 0.00029683 rank 5
2023-03-01 01:14:23,960 DEBUG TRAIN Batch 46/300 loss 5.096121 loss_att 9.318335 loss_ctc 9.951277 loss_rnnt 3.471265 hw_loss 0.249485 lr 0.00029682 rank 7
2023-03-01 01:14:23,976 DEBUG TRAIN Batch 46/300 loss 7.221757 loss_att 9.655367 loss_ctc 11.786615 loss_rnnt 5.962598 hw_loss 0.307106 lr 0.00029683 rank 4
2023-03-01 01:14:23,995 DEBUG TRAIN Batch 46/300 loss 4.983790 loss_att 7.091219 loss_ctc 10.087334 loss_rnnt 3.768826 hw_loss 0.211886 lr 0.00029683 rank 6
2023-03-01 01:15:30,399 DEBUG TRAIN Batch 46/400 loss 5.828891 loss_att 7.210749 loss_ctc 8.046975 loss_rnnt 5.092318 hw_loss 0.308355 lr 0.00029682 rank 0
2023-03-01 01:15:30,415 DEBUG TRAIN Batch 46/400 loss 5.676284 loss_att 8.172321 loss_ctc 7.898904 loss_rnnt 4.776021 hw_loss 0.196324 lr 0.00029682 rank 4
2023-03-01 01:15:30,418 DEBUG TRAIN Batch 46/400 loss 5.148917 loss_att 7.779591 loss_ctc 8.002442 loss_rnnt 4.134545 hw_loss 0.202062 lr 0.00029681 rank 7
2023-03-01 01:15:30,418 DEBUG TRAIN Batch 46/400 loss 12.393508 loss_att 14.439497 loss_ctc 24.797106 loss_rnnt 10.171673 hw_loss 0.297796 lr 0.00029682 rank 2
2023-03-01 01:15:30,419 DEBUG TRAIN Batch 46/400 loss 7.796070 loss_att 13.422531 loss_ctc 12.781126 loss_rnnt 5.847713 hw_loss 0.296983 lr 0.00029681 rank 3
2023-03-01 01:15:30,420 DEBUG TRAIN Batch 46/400 loss 3.204736 loss_att 6.144576 loss_ctc 6.618128 loss_rnnt 2.017076 hw_loss 0.271074 lr 0.00029682 rank 5
2023-03-01 01:15:30,428 DEBUG TRAIN Batch 46/400 loss 4.343819 loss_att 5.575624 loss_ctc 6.336054 loss_rnnt 3.744646 hw_loss 0.163463 lr 0.00029682 rank 1
2023-03-01 01:15:30,463 DEBUG TRAIN Batch 46/400 loss 10.558663 loss_att 17.085602 loss_ctc 20.733658 loss_rnnt 7.757819 hw_loss 0.260231 lr 0.00029681 rank 6
2023-03-01 01:16:08,788 DEBUG TRAIN Batch 46/500 loss 5.581697 loss_att 8.600410 loss_ctc 7.091577 loss_rnnt 4.720504 hw_loss 0.105251 lr 0.00029680 rank 6
2023-03-01 01:16:08,810 DEBUG TRAIN Batch 46/500 loss 7.303780 loss_att 8.648117 loss_ctc 11.223954 loss_rnnt 6.444129 hw_loss 0.127677 lr 0.00029680 rank 3
2023-03-01 01:16:08,809 DEBUG TRAIN Batch 46/500 loss 10.055102 loss_att 12.249792 loss_ctc 14.659998 loss_rnnt 8.912041 hw_loss 0.169008 lr 0.00029680 rank 1
2023-03-01 01:16:08,810 DEBUG TRAIN Batch 46/500 loss 2.746356 loss_att 4.829428 loss_ctc 4.912055 loss_rnnt 1.982473 hw_loss 0.109702 lr 0.00029680 rank 7
2023-03-01 01:16:08,813 DEBUG TRAIN Batch 46/500 loss 6.167509 loss_att 9.316602 loss_ctc 8.223872 loss_rnnt 5.153997 hw_loss 0.205332 lr 0.00029680 rank 5
2023-03-01 01:16:08,818 DEBUG TRAIN Batch 46/500 loss 4.669812 loss_att 6.802406 loss_ctc 7.791326 loss_rnnt 3.685070 hw_loss 0.266288 lr 0.00029681 rank 0
2023-03-01 01:16:08,824 DEBUG TRAIN Batch 46/500 loss 8.988301 loss_att 11.280554 loss_ctc 16.478233 loss_rnnt 7.374838 hw_loss 0.293163 lr 0.00029680 rank 2
2023-03-01 01:16:08,836 DEBUG TRAIN Batch 46/500 loss 7.023160 loss_att 8.957278 loss_ctc 11.766563 loss_rnnt 5.868398 hw_loss 0.254035 lr 0.00029680 rank 4
2023-03-01 01:16:48,107 DEBUG TRAIN Batch 46/600 loss 8.405296 loss_att 8.973732 loss_ctc 13.104313 loss_rnnt 7.507124 hw_loss 0.296154 lr 0.00029679 rank 3
2023-03-01 01:16:48,108 DEBUG TRAIN Batch 46/600 loss 9.990492 loss_att 14.211628 loss_ctc 17.538933 loss_rnnt 7.948370 hw_loss 0.358944 lr 0.00029678 rank 7
2023-03-01 01:16:48,109 DEBUG TRAIN Batch 46/600 loss 1.285863 loss_att 4.088304 loss_ctc 1.842821 loss_rnnt 0.557203 hw_loss 0.176082 lr 0.00029679 rank 0
2023-03-01 01:16:48,113 DEBUG TRAIN Batch 46/600 loss 6.359401 loss_att 6.902238 loss_ctc 8.978424 loss_rnnt 5.714083 hw_loss 0.351652 lr 0.00029679 rank 1
2023-03-01 01:16:48,112 DEBUG TRAIN Batch 46/600 loss 6.598618 loss_att 7.494590 loss_ctc 10.152212 loss_rnnt 5.769596 hw_loss 0.330029 lr 0.00029679 rank 5
2023-03-01 01:16:48,113 DEBUG TRAIN Batch 46/600 loss 7.626797 loss_att 9.419491 loss_ctc 11.950182 loss_rnnt 6.481187 hw_loss 0.394911 lr 0.00029679 rank 6
2023-03-01 01:16:48,113 DEBUG TRAIN Batch 46/600 loss 2.326616 loss_att 5.353159 loss_ctc 4.253041 loss_rnnt 1.333540 hw_loss 0.245458 lr 0.00029679 rank 2
2023-03-01 01:16:48,155 DEBUG TRAIN Batch 46/600 loss 7.940791 loss_att 8.408418 loss_ctc 12.496070 loss_rnnt 7.010602 hw_loss 0.429923 lr 0.00029679 rank 4
2023-03-01 01:17:27,516 DEBUG TRAIN Batch 46/700 loss 9.518086 loss_att 14.075438 loss_ctc 21.734808 loss_rnnt 6.778891 hw_loss 0.372805 lr 0.00029677 rank 6
2023-03-01 01:17:27,521 DEBUG TRAIN Batch 46/700 loss 2.067936 loss_att 5.332744 loss_ctc 3.430930 loss_rnnt 1.072126 hw_loss 0.302093 lr 0.00029677 rank 7
2023-03-01 01:17:27,528 DEBUG TRAIN Batch 46/700 loss 6.516222 loss_att 9.297436 loss_ctc 12.232162 loss_rnnt 4.980178 hw_loss 0.408141 lr 0.00029678 rank 0
2023-03-01 01:17:27,529 DEBUG TRAIN Batch 46/700 loss 5.540118 loss_att 7.434977 loss_ctc 8.340509 loss_rnnt 4.597408 hw_loss 0.356910 lr 0.00029678 rank 1
2023-03-01 01:17:27,530 DEBUG TRAIN Batch 46/700 loss 9.435725 loss_att 11.842551 loss_ctc 12.609074 loss_rnnt 8.374070 hw_loss 0.294707 lr 0.00029678 rank 2
2023-03-01 01:17:27,530 DEBUG TRAIN Batch 46/700 loss 6.310662 loss_att 8.152716 loss_ctc 10.248313 loss_rnnt 5.358757 hw_loss 0.109640 lr 0.00029677 rank 3
2023-03-01 01:17:27,533 DEBUG TRAIN Batch 46/700 loss 5.720605 loss_att 8.683448 loss_ctc 9.783293 loss_rnnt 4.585541 hw_loss 0.001507 lr 0.00029678 rank 5
2023-03-01 01:17:27,543 DEBUG TRAIN Batch 46/700 loss 7.741588 loss_att 10.713535 loss_ctc 11.072897 loss_rnnt 6.585775 hw_loss 0.219841 lr 0.00029678 rank 4
2023-03-01 01:18:32,157 DEBUG TRAIN Batch 46/800 loss 2.732711 loss_att 4.553400 loss_ctc 6.820383 loss_rnnt 1.712767 hw_loss 0.207719 lr 0.00029676 rank 7
2023-03-01 01:18:32,158 DEBUG TRAIN Batch 46/800 loss 10.560614 loss_att 15.060224 loss_ctc 15.392940 loss_rnnt 8.970641 hw_loss 0.085763 lr 0.00029677 rank 0
2023-03-01 01:18:32,161 DEBUG TRAIN Batch 46/800 loss 6.522509 loss_att 7.680916 loss_ctc 8.335994 loss_rnnt 5.847929 hw_loss 0.377064 lr 0.00029676 rank 3
2023-03-01 01:18:32,161 DEBUG TRAIN Batch 46/800 loss 4.698991 loss_att 8.234665 loss_ctc 6.013947 loss_rnnt 3.711156 hw_loss 0.197574 lr 0.00029676 rank 6
2023-03-01 01:18:32,162 DEBUG TRAIN Batch 46/800 loss 9.666792 loss_att 10.477806 loss_ctc 14.092751 loss_rnnt 8.746298 hw_loss 0.315306 lr 0.00029677 rank 4
2023-03-01 01:18:32,163 DEBUG TRAIN Batch 46/800 loss 7.858696 loss_att 11.427713 loss_ctc 13.724650 loss_rnnt 6.277111 hw_loss 0.160600 lr 0.00029677 rank 1
2023-03-01 01:18:32,174 DEBUG TRAIN Batch 46/800 loss 4.240432 loss_att 7.332548 loss_ctc 8.158758 loss_rnnt 2.972175 hw_loss 0.238857 lr 0.00029676 rank 2
2023-03-01 01:18:32,210 DEBUG TRAIN Batch 46/800 loss 6.999919 loss_att 10.512972 loss_ctc 11.937823 loss_rnnt 5.472685 hw_loss 0.311693 lr 0.00029676 rank 5
2023-03-01 01:19:10,480 DEBUG TRAIN Batch 46/900 loss 5.871127 loss_att 9.769336 loss_ctc 12.445751 loss_rnnt 4.090062 hw_loss 0.234011 lr 0.00029675 rank 3
2023-03-01 01:19:10,494 DEBUG TRAIN Batch 46/900 loss 2.767391 loss_att 5.652833 loss_ctc 4.636460 loss_rnnt 1.810947 hw_loss 0.244026 lr 0.00029675 rank 4
2023-03-01 01:19:10,495 DEBUG TRAIN Batch 46/900 loss 3.806556 loss_att 7.043486 loss_ctc 6.666795 loss_rnnt 2.617288 hw_loss 0.300968 lr 0.00029675 rank 2
2023-03-01 01:19:10,494 DEBUG TRAIN Batch 46/900 loss 12.722057 loss_att 14.039092 loss_ctc 23.122570 loss_rnnt 10.997225 hw_loss 0.140044 lr 0.00029675 rank 0
2023-03-01 01:19:10,495 DEBUG TRAIN Batch 46/900 loss 9.655435 loss_att 11.187229 loss_ctc 16.712673 loss_rnnt 8.217097 hw_loss 0.358150 lr 0.00029675 rank 1
2023-03-01 01:19:10,496 DEBUG TRAIN Batch 46/900 loss 8.337317 loss_att 12.932840 loss_ctc 17.200882 loss_rnnt 6.186593 hw_loss 0.093396 lr 0.00029674 rank 7
2023-03-01 01:19:10,500 DEBUG TRAIN Batch 46/900 loss 3.588434 loss_att 6.098984 loss_ctc 6.554133 loss_rnnt 2.632366 hw_loss 0.109747 lr 0.00029675 rank 5
2023-03-01 01:19:10,541 DEBUG TRAIN Batch 46/900 loss 2.562137 loss_att 5.399146 loss_ctc 5.030647 loss_rnnt 1.610444 hw_loss 0.103418 lr 0.00029675 rank 6
2023-03-01 01:19:49,225 DEBUG TRAIN Batch 46/1000 loss 6.178541 loss_att 9.826692 loss_ctc 17.436707 loss_rnnt 3.803184 hw_loss 0.271197 lr 0.00029674 rank 0
2023-03-01 01:19:49,229 DEBUG TRAIN Batch 46/1000 loss 9.708136 loss_att 13.824198 loss_ctc 18.824158 loss_rnnt 7.533416 hw_loss 0.255070 lr 0.00029674 rank 2
2023-03-01 01:19:49,242 DEBUG TRAIN Batch 46/1000 loss 6.770732 loss_att 14.392964 loss_ctc 9.501036 loss_rnnt 4.757134 hw_loss 0.234584 lr 0.00029673 rank 3
2023-03-01 01:19:49,247 DEBUG TRAIN Batch 46/1000 loss 4.896735 loss_att 7.383399 loss_ctc 7.502231 loss_rnnt 3.824919 hw_loss 0.425781 lr 0.00029673 rank 7
2023-03-01 01:19:49,249 DEBUG TRAIN Batch 46/1000 loss 7.359497 loss_att 9.427794 loss_ctc 9.783322 loss_rnnt 6.545672 hw_loss 0.144355 lr 0.00029674 rank 5
2023-03-01 01:19:49,251 DEBUG TRAIN Batch 46/1000 loss 7.892349 loss_att 8.991872 loss_ctc 9.981556 loss_rnnt 7.275301 hw_loss 0.222345 lr 0.00029674 rank 6
2023-03-01 01:19:49,276 DEBUG TRAIN Batch 46/1000 loss 4.878702 loss_att 7.956551 loss_ctc 9.356156 loss_rnnt 3.521116 hw_loss 0.271915 lr 0.00029674 rank 1
2023-03-01 01:19:49,278 DEBUG TRAIN Batch 46/1000 loss 3.701899 loss_att 8.381191 loss_ctc 9.842842 loss_rnnt 1.817805 hw_loss 0.242705 lr 0.00029674 rank 4
2023-03-01 01:20:54,973 DEBUG TRAIN Batch 46/1100 loss 4.449131 loss_att 6.278201 loss_ctc 5.750227 loss_rnnt 3.765405 hw_loss 0.270812 lr 0.00029673 rank 2
2023-03-01 01:20:54,975 DEBUG TRAIN Batch 46/1100 loss 8.286116 loss_att 10.929915 loss_ctc 12.640786 loss_rnnt 7.056232 hw_loss 0.225940 lr 0.00029673 rank 0
2023-03-01 01:20:54,976 DEBUG TRAIN Batch 46/1100 loss 3.250219 loss_att 6.372587 loss_ctc 7.354081 loss_rnnt 1.990185 hw_loss 0.165710 lr 0.00029673 rank 4
2023-03-01 01:20:54,976 DEBUG TRAIN Batch 46/1100 loss 6.203013 loss_att 10.130365 loss_ctc 11.686393 loss_rnnt 4.621177 hw_loss 0.122341 lr 0.00029672 rank 6
2023-03-01 01:20:54,977 DEBUG TRAIN Batch 46/1100 loss 9.703238 loss_att 13.333071 loss_ctc 16.412046 loss_rnnt 7.942403 hw_loss 0.263176 lr 0.00029672 rank 7
2023-03-01 01:20:54,978 DEBUG TRAIN Batch 46/1100 loss 4.807841 loss_att 8.058218 loss_ctc 7.772604 loss_rnnt 3.685510 hw_loss 0.144290 lr 0.00029672 rank 3
2023-03-01 01:20:54,978 DEBUG TRAIN Batch 46/1100 loss 7.115103 loss_att 7.767185 loss_ctc 12.832716 loss_rnnt 6.068714 hw_loss 0.288046 lr 0.00029673 rank 5
2023-03-01 01:20:54,984 DEBUG TRAIN Batch 46/1100 loss 7.873974 loss_att 11.011974 loss_ctc 17.714903 loss_rnnt 5.798800 hw_loss 0.253969 lr 0.00029673 rank 1
2023-03-01 01:21:33,803 DEBUG TRAIN Batch 46/1200 loss 4.295098 loss_att 6.491688 loss_ctc 6.925154 loss_rnnt 3.441366 hw_loss 0.119514 lr 0.00029671 rank 1
2023-03-01 01:21:33,807 DEBUG TRAIN Batch 46/1200 loss 8.333930 loss_att 10.133949 loss_ctc 11.162579 loss_rnnt 7.434498 hw_loss 0.304264 lr 0.00029671 rank 3
2023-03-01 01:21:33,808 DEBUG TRAIN Batch 46/1200 loss 3.293107 loss_att 4.457206 loss_ctc 5.127319 loss_rnnt 2.661807 hw_loss 0.288597 lr 0.00029671 rank 2
2023-03-01 01:21:33,808 DEBUG TRAIN Batch 46/1200 loss 3.818647 loss_att 5.756905 loss_ctc 6.780008 loss_rnnt 2.874821 hw_loss 0.302488 lr 0.00029671 rank 7
2023-03-01 01:21:33,809 DEBUG TRAIN Batch 46/1200 loss 5.472292 loss_att 5.795304 loss_ctc 9.527262 loss_rnnt 4.714703 hw_loss 0.285609 lr 0.00029672 rank 0
2023-03-01 01:21:33,809 DEBUG TRAIN Batch 46/1200 loss 6.046316 loss_att 7.829004 loss_ctc 10.184291 loss_rnnt 5.017862 hw_loss 0.225349 lr 0.00029671 rank 6
2023-03-01 01:21:33,810 DEBUG TRAIN Batch 46/1200 loss 4.447808 loss_att 6.225141 loss_ctc 6.449158 loss_rnnt 3.625451 hw_loss 0.375082 lr 0.00029671 rank 4
2023-03-01 01:21:33,852 DEBUG TRAIN Batch 46/1200 loss 8.670725 loss_att 9.516325 loss_ctc 12.388997 loss_rnnt 7.864557 hw_loss 0.264897 lr 0.00029671 rank 5
2023-03-01 01:22:12,269 DEBUG TRAIN Batch 46/1300 loss 2.670583 loss_att 5.095714 loss_ctc 3.886127 loss_rnnt 1.913441 hw_loss 0.206333 lr 0.00029670 rank 6
2023-03-01 01:22:12,274 DEBUG TRAIN Batch 46/1300 loss 7.083068 loss_att 10.894588 loss_ctc 17.270523 loss_rnnt 4.853946 hw_loss 0.203420 lr 0.00029670 rank 4
2023-03-01 01:22:12,280 DEBUG TRAIN Batch 46/1300 loss 4.990909 loss_att 7.446351 loss_ctc 8.358263 loss_rnnt 3.965759 hw_loss 0.159526 lr 0.00029669 rank 3
2023-03-01 01:22:12,287 DEBUG TRAIN Batch 46/1300 loss 5.760482 loss_att 10.689558 loss_ctc 21.432480 loss_rnnt 2.567661 hw_loss 0.220137 lr 0.00029670 rank 0
2023-03-01 01:22:12,291 DEBUG TRAIN Batch 46/1300 loss 4.713944 loss_att 9.706268 loss_ctc 10.020647 loss_rnnt 2.850696 hw_loss 0.294794 lr 0.00029669 rank 7
2023-03-01 01:22:12,294 DEBUG TRAIN Batch 46/1300 loss 9.342027 loss_att 9.229280 loss_ctc 12.573444 loss_rnnt 8.785011 hw_loss 0.278829 lr 0.00029670 rank 1
2023-03-01 01:22:12,318 DEBUG TRAIN Batch 46/1300 loss 6.921474 loss_att 7.553562 loss_ctc 12.451075 loss_rnnt 5.876130 hw_loss 0.340587 lr 0.00029670 rank 2
2023-03-01 01:22:12,322 DEBUG TRAIN Batch 46/1300 loss 7.407931 loss_att 9.992902 loss_ctc 10.603355 loss_rnnt 6.409825 hw_loss 0.103227 lr 0.00029670 rank 5
2023-03-01 01:22:52,118 DEBUG TRAIN Batch 46/1400 loss 4.083106 loss_att 9.069496 loss_ctc 8.492807 loss_rnnt 2.423270 hw_loss 0.139871 lr 0.00029669 rank 5
2023-03-01 01:22:52,120 DEBUG TRAIN Batch 46/1400 loss 6.594547 loss_att 9.952517 loss_ctc 12.568697 loss_rnnt 5.042930 hw_loss 0.156506 lr 0.00029669 rank 2
2023-03-01 01:22:52,124 DEBUG TRAIN Batch 46/1400 loss 6.019605 loss_att 8.925570 loss_ctc 12.295989 loss_rnnt 4.454039 hw_loss 0.276602 lr 0.00029669 rank 4
2023-03-01 01:22:52,126 DEBUG TRAIN Batch 46/1400 loss 5.294218 loss_att 7.418999 loss_ctc 6.759631 loss_rnnt 4.543774 hw_loss 0.243936 lr 0.00029668 rank 3
2023-03-01 01:22:52,132 DEBUG TRAIN Batch 46/1400 loss 2.214164 loss_att 4.990976 loss_ctc 2.079677 loss_rnnt 1.585393 hw_loss 0.171264 lr 0.00029668 rank 6
2023-03-01 01:22:52,132 DEBUG TRAIN Batch 46/1400 loss 6.315073 loss_att 9.149927 loss_ctc 7.621967 loss_rnnt 5.392425 hw_loss 0.340172 lr 0.00029669 rank 0
2023-03-01 01:22:52,134 DEBUG TRAIN Batch 46/1400 loss 1.495255 loss_att 3.383875 loss_ctc 2.321621 loss_rnnt 0.793464 hw_loss 0.401033 lr 0.00029668 rank 7
2023-03-01 01:22:52,145 DEBUG TRAIN Batch 46/1400 loss 3.101707 loss_att 5.638398 loss_ctc 3.747678 loss_rnnt 2.444706 hw_loss 0.119125 lr 0.00029669 rank 1
2023-03-01 01:23:56,625 DEBUG TRAIN Batch 46/1500 loss 3.155051 loss_att 6.794409 loss_ctc 7.347184 loss_rnnt 1.729708 hw_loss 0.259727 lr 0.00029668 rank 0
2023-03-01 01:23:56,635 DEBUG TRAIN Batch 46/1500 loss 8.390273 loss_att 10.087088 loss_ctc 9.824677 loss_rnnt 7.814854 hw_loss 0.084004 lr 0.00029667 rank 1
2023-03-01 01:23:56,638 DEBUG TRAIN Batch 46/1500 loss 6.584285 loss_att 12.110798 loss_ctc 11.998213 loss_rnnt 4.609940 hw_loss 0.275972 lr 0.00029667 rank 4
2023-03-01 01:23:56,649 DEBUG TRAIN Batch 46/1500 loss 3.736504 loss_att 8.443851 loss_ctc 7.238234 loss_rnnt 2.172292 hw_loss 0.292208 lr 0.00029667 rank 7
2023-03-01 01:23:56,653 DEBUG TRAIN Batch 46/1500 loss 12.947278 loss_att 20.083698 loss_ctc 22.261745 loss_rnnt 10.085695 hw_loss 0.360692 lr 0.00029667 rank 2
2023-03-01 01:23:56,653 DEBUG TRAIN Batch 46/1500 loss 6.642862 loss_att 10.344578 loss_ctc 10.977274 loss_rnnt 5.214586 hw_loss 0.206273 lr 0.00029667 rank 6
2023-03-01 01:23:56,654 DEBUG TRAIN Batch 46/1500 loss 5.666094 loss_att 7.659359 loss_ctc 7.798470 loss_rnnt 4.819031 hw_loss 0.307675 lr 0.00029667 rank 5
2023-03-01 01:23:56,655 DEBUG TRAIN Batch 46/1500 loss 12.853003 loss_att 14.056857 loss_ctc 17.080891 loss_rnnt 11.885893 hw_loss 0.304914 lr 0.00029667 rank 3
2023-03-01 01:24:35,069 DEBUG TRAIN Batch 46/1600 loss 8.250108 loss_att 10.862757 loss_ctc 13.476202 loss_rnnt 6.863463 hw_loss 0.313692 lr 0.00029665 rank 7
2023-03-01 01:24:35,076 DEBUG TRAIN Batch 46/1600 loss 6.736509 loss_att 9.515283 loss_ctc 11.961270 loss_rnnt 5.345411 hw_loss 0.260079 lr 0.00029666 rank 1
2023-03-01 01:24:35,084 DEBUG TRAIN Batch 46/1600 loss 5.777832 loss_att 8.272392 loss_ctc 7.897604 loss_rnnt 4.934748 hw_loss 0.115378 lr 0.00029666 rank 0
2023-03-01 01:24:35,085 DEBUG TRAIN Batch 46/1600 loss 2.916217 loss_att 5.194493 loss_ctc 5.010053 loss_rnnt 2.072999 hw_loss 0.203221 lr 0.00029666 rank 6
2023-03-01 01:24:35,087 DEBUG TRAIN Batch 46/1600 loss 6.086832 loss_att 7.972281 loss_ctc 7.253170 loss_rnnt 5.417332 hw_loss 0.256685 lr 0.00029666 rank 5
2023-03-01 01:24:35,089 DEBUG TRAIN Batch 46/1600 loss 2.770630 loss_att 4.224978 loss_ctc 5.535043 loss_rnnt 1.957389 hw_loss 0.288343 lr 0.00029666 rank 4
2023-03-01 01:24:35,090 DEBUG TRAIN Batch 46/1600 loss 4.609915 loss_att 5.354939 loss_ctc 6.062860 loss_rnnt 4.127090 hw_loss 0.262675 lr 0.00029666 rank 3
2023-03-01 01:24:35,093 DEBUG TRAIN Batch 46/1600 loss 5.404081 loss_att 8.813375 loss_ctc 9.690995 loss_rnnt 4.074355 hw_loss 0.143022 lr 0.00029666 rank 2
2023-03-01 01:25:13,954 DEBUG TRAIN Batch 46/1700 loss 6.190936 loss_att 8.247939 loss_ctc 9.980925 loss_rnnt 5.167703 hw_loss 0.199689 lr 0.00029664 rank 6
2023-03-01 01:25:13,969 DEBUG TRAIN Batch 46/1700 loss 2.386882 loss_att 5.089246 loss_ctc 4.121058 loss_rnnt 1.478878 hw_loss 0.255578 lr 0.00029665 rank 1
2023-03-01 01:25:13,969 DEBUG TRAIN Batch 46/1700 loss 2.623541 loss_att 4.919508 loss_ctc 4.097666 loss_rnnt 1.872981 hw_loss 0.177781 lr 0.00029665 rank 4
2023-03-01 01:25:13,972 DEBUG TRAIN Batch 46/1700 loss 7.129595 loss_att 10.246414 loss_ctc 11.487181 loss_rnnt 5.759088 hw_loss 0.311498 lr 0.00029665 rank 0
2023-03-01 01:25:13,977 DEBUG TRAIN Batch 46/1700 loss 5.395670 loss_att 8.000690 loss_ctc 12.292580 loss_rnnt 3.760023 hw_loss 0.365727 lr 0.00029664 rank 7
2023-03-01 01:25:13,997 DEBUG TRAIN Batch 46/1700 loss 2.787469 loss_att 7.152822 loss_ctc 7.540583 loss_rnnt 1.057215 hw_loss 0.418939 lr 0.00029665 rank 2
2023-03-01 01:25:13,998 DEBUG TRAIN Batch 46/1700 loss 8.491895 loss_att 11.569403 loss_ctc 11.586670 loss_rnnt 7.401279 hw_loss 0.117146 lr 0.00029665 rank 5
2023-03-01 01:25:14,005 DEBUG TRAIN Batch 46/1700 loss 6.213185 loss_att 12.123285 loss_ctc 12.827185 loss_rnnt 3.947411 hw_loss 0.378538 lr 0.00029664 rank 3
2023-03-01 01:26:19,746 DEBUG TRAIN Batch 46/1800 loss 9.051131 loss_att 10.341051 loss_ctc 11.118505 loss_rnnt 8.366642 hw_loss 0.282852 lr 0.00029663 rank 1
2023-03-01 01:26:19,756 DEBUG TRAIN Batch 46/1800 loss 5.207925 loss_att 8.584777 loss_ctc 9.315520 loss_rnnt 3.851197 hw_loss 0.250648 lr 0.00029664 rank 0
2023-03-01 01:26:19,765 DEBUG TRAIN Batch 46/1800 loss 8.393474 loss_att 11.097866 loss_ctc 13.042106 loss_rnnt 7.089139 hw_loss 0.269321 lr 0.00029663 rank 7
2023-03-01 01:26:19,765 DEBUG TRAIN Batch 46/1800 loss 4.979419 loss_att 7.118868 loss_ctc 8.441305 loss_rnnt 3.944230 hw_loss 0.273215 lr 0.00029663 rank 2
2023-03-01 01:26:19,767 DEBUG TRAIN Batch 46/1800 loss 10.468669 loss_att 11.909579 loss_ctc 16.322706 loss_rnnt 9.272292 hw_loss 0.239355 lr 0.00029663 rank 5
2023-03-01 01:26:19,767 DEBUG TRAIN Batch 46/1800 loss 5.979217 loss_att 9.014626 loss_ctc 12.279510 loss_rnnt 4.351693 hw_loss 0.338255 lr 0.00029663 rank 6
2023-03-01 01:26:19,769 DEBUG TRAIN Batch 46/1800 loss 9.802170 loss_att 13.112780 loss_ctc 15.520881 loss_rnnt 8.193812 hw_loss 0.344515 lr 0.00029663 rank 4
2023-03-01 01:26:19,771 DEBUG TRAIN Batch 46/1800 loss 3.737492 loss_att 6.922916 loss_ctc 7.628803 loss_rnnt 2.344977 hw_loss 0.443604 lr 0.00029663 rank 3
2023-03-01 01:26:58,511 DEBUG TRAIN Batch 46/1900 loss 1.881873 loss_att 4.883681 loss_ctc 5.226316 loss_rnnt 0.620809 hw_loss 0.402704 lr 0.00029662 rank 6
2023-03-01 01:26:58,512 DEBUG TRAIN Batch 46/1900 loss 2.017561 loss_att 4.841492 loss_ctc 2.722109 loss_rnnt 1.212562 hw_loss 0.274262 lr 0.00029662 rank 3
2023-03-01 01:26:58,514 DEBUG TRAIN Batch 46/1900 loss 10.953113 loss_att 15.316864 loss_ctc 22.910217 loss_rnnt 8.433642 hw_loss 0.098327 lr 0.00029662 rank 0
2023-03-01 01:26:58,516 DEBUG TRAIN Batch 46/1900 loss 4.529442 loss_att 7.267658 loss_ctc 6.484374 loss_rnnt 3.573963 hw_loss 0.275961 lr 0.00029662 rank 2
2023-03-01 01:26:58,530 DEBUG TRAIN Batch 46/1900 loss 3.168790 loss_att 5.812282 loss_ctc 5.490331 loss_rnnt 2.121887 hw_loss 0.391248 lr 0.00029661 rank 7
2023-03-01 01:26:58,537 DEBUG TRAIN Batch 46/1900 loss 7.257276 loss_att 9.403832 loss_ctc 14.848773 loss_rnnt 5.711169 hw_loss 0.196117 lr 0.00029662 rank 5
2023-03-01 01:26:58,539 DEBUG TRAIN Batch 46/1900 loss 6.714408 loss_att 13.679655 loss_ctc 15.114471 loss_rnnt 4.023071 hw_loss 0.334273 lr 0.00029662 rank 4
2023-03-01 01:26:58,577 DEBUG TRAIN Batch 46/1900 loss 4.118751 loss_att 4.412107 loss_ctc 7.368483 loss_rnnt 3.401828 hw_loss 0.421789 lr 0.00029662 rank 1
2023-03-01 01:27:36,950 DEBUG TRAIN Batch 46/2000 loss 6.069269 loss_att 9.755325 loss_ctc 11.193319 loss_rnnt 4.548007 hw_loss 0.189081 lr 0.00029661 rank 0
2023-03-01 01:27:36,956 DEBUG TRAIN Batch 46/2000 loss 3.983428 loss_att 6.132756 loss_ctc 5.881492 loss_rnnt 3.179604 hw_loss 0.226655 lr 0.00029661 rank 4
2023-03-01 01:27:36,967 DEBUG TRAIN Batch 46/2000 loss 3.528970 loss_att 8.612541 loss_ctc 8.223640 loss_rnnt 1.780170 hw_loss 0.198993 lr 0.00029660 rank 7
2023-03-01 01:27:36,969 DEBUG TRAIN Batch 46/2000 loss 4.672736 loss_att 7.964889 loss_ctc 9.419137 loss_rnnt 3.225995 hw_loss 0.291483 lr 0.00029661 rank 1
2023-03-01 01:27:36,970 DEBUG TRAIN Batch 46/2000 loss 3.131406 loss_att 5.765464 loss_ctc 3.586665 loss_rnnt 2.413487 hw_loss 0.244511 lr 0.00029660 rank 6
2023-03-01 01:27:36,970 DEBUG TRAIN Batch 46/2000 loss 9.950151 loss_att 11.868413 loss_ctc 12.827679 loss_rnnt 9.068087 hw_loss 0.215141 lr 0.00029660 rank 3
2023-03-01 01:27:36,971 DEBUG TRAIN Batch 46/2000 loss 6.767259 loss_att 9.687164 loss_ctc 12.599162 loss_rnnt 5.275616 hw_loss 0.243891 lr 0.00029661 rank 5
2023-03-01 01:27:36,972 DEBUG TRAIN Batch 46/2000 loss 1.864904 loss_att 3.818938 loss_ctc 3.102712 loss_rnnt 1.260006 hw_loss 0.091968 lr 0.00029661 rank 2
2023-03-01 01:28:16,442 DEBUG TRAIN Batch 46/2100 loss 10.734365 loss_att 10.929781 loss_ctc 14.977858 loss_rnnt 9.999743 hw_loss 0.243263 lr 0.00029659 rank 6
2023-03-01 01:28:16,453 DEBUG TRAIN Batch 46/2100 loss 7.201931 loss_att 13.075596 loss_ctc 15.791400 loss_rnnt 4.824152 hw_loss 0.108342 lr 0.00029660 rank 4
2023-03-01 01:28:16,460 DEBUG TRAIN Batch 46/2100 loss 11.571523 loss_att 14.346326 loss_ctc 17.952442 loss_rnnt 10.046062 hw_loss 0.224459 lr 0.00029659 rank 7
2023-03-01 01:28:16,460 DEBUG TRAIN Batch 46/2100 loss 7.877992 loss_att 10.087196 loss_ctc 13.164457 loss_rnnt 6.620256 hw_loss 0.208185 lr 0.00029660 rank 1
2023-03-01 01:28:16,463 DEBUG TRAIN Batch 46/2100 loss 3.083353 loss_att 6.740585 loss_ctc 6.174326 loss_rnnt 1.795182 hw_loss 0.271114 lr 0.00029660 rank 0
2023-03-01 01:28:16,464 DEBUG TRAIN Batch 46/2100 loss 6.082242 loss_att 9.023436 loss_ctc 11.913356 loss_rnnt 4.571418 hw_loss 0.272070 lr 0.00029660 rank 5
2023-03-01 01:28:16,516 DEBUG TRAIN Batch 46/2100 loss 1.676783 loss_att 4.660367 loss_ctc 3.848578 loss_rnnt 0.692988 hw_loss 0.182822 lr 0.00029659 rank 3
2023-03-01 01:28:16,517 DEBUG TRAIN Batch 46/2100 loss 5.696512 loss_att 9.210798 loss_ctc 7.800300 loss_rnnt 4.528913 hw_loss 0.345445 lr 0.00029660 rank 2
2023-03-01 01:29:19,348 DEBUG TRAIN Batch 46/2200 loss 4.574665 loss_att 5.804105 loss_ctc 5.030447 loss_rnnt 4.174615 hw_loss 0.175108 lr 0.00029657 rank 7
2023-03-01 01:29:19,358 DEBUG TRAIN Batch 46/2200 loss 6.352581 loss_att 9.365698 loss_ctc 10.234569 loss_rnnt 5.113620 hw_loss 0.222634 lr 0.00029658 rank 1
2023-03-01 01:29:19,361 DEBUG TRAIN Batch 46/2200 loss 7.025703 loss_att 9.489717 loss_ctc 13.953815 loss_rnnt 5.478862 hw_loss 0.244295 lr 0.00029658 rank 6
2023-03-01 01:29:19,362 DEBUG TRAIN Batch 46/2200 loss 3.334925 loss_att 5.830341 loss_ctc 7.108771 loss_rnnt 2.226725 hw_loss 0.198633 lr 0.00029658 rank 2
2023-03-01 01:29:19,364 DEBUG TRAIN Batch 46/2200 loss 3.848109 loss_att 7.149027 loss_ctc 6.835794 loss_rnnt 2.692792 hw_loss 0.181453 lr 0.00029658 rank 0
2023-03-01 01:29:19,366 DEBUG TRAIN Batch 46/2200 loss 5.477404 loss_att 7.831351 loss_ctc 7.727974 loss_rnnt 4.587956 hw_loss 0.222340 lr 0.00029658 rank 5
2023-03-01 01:29:19,366 DEBUG TRAIN Batch 46/2200 loss 4.401381 loss_att 7.983266 loss_ctc 7.739202 loss_rnnt 3.132104 hw_loss 0.202233 lr 0.00029658 rank 4
2023-03-01 01:29:19,369 DEBUG TRAIN Batch 46/2200 loss 7.384434 loss_att 9.353340 loss_ctc 8.395239 loss_rnnt 6.727098 hw_loss 0.241463 lr 0.00029658 rank 3
2023-03-01 01:29:57,722 DEBUG TRAIN Batch 46/2300 loss 8.005071 loss_att 12.065063 loss_ctc 11.338650 loss_rnnt 6.694541 hw_loss 0.101351 lr 0.00029657 rank 4
2023-03-01 01:29:57,725 DEBUG TRAIN Batch 46/2300 loss 8.295815 loss_att 10.459102 loss_ctc 10.947075 loss_rnnt 7.386540 hw_loss 0.230843 lr 0.00029656 rank 7
2023-03-01 01:29:57,727 DEBUG TRAIN Batch 46/2300 loss 4.910735 loss_att 7.652767 loss_ctc 10.040668 loss_rnnt 3.505562 hw_loss 0.323953 lr 0.00029657 rank 0
2023-03-01 01:29:57,729 DEBUG TRAIN Batch 46/2300 loss 6.743467 loss_att 12.311743 loss_ctc 9.253099 loss_rnnt 5.180681 hw_loss 0.214711 lr 0.00029657 rank 6
2023-03-01 01:29:57,729 DEBUG TRAIN Batch 46/2300 loss 6.108227 loss_att 10.463291 loss_ctc 14.030807 loss_rnnt 4.089680 hw_loss 0.170981 lr 0.00029656 rank 3
2023-03-01 01:29:57,733 DEBUG TRAIN Batch 46/2300 loss 5.072771 loss_att 8.243372 loss_ctc 8.876760 loss_rnnt 3.838271 hw_loss 0.174716 lr 0.00029657 rank 1
2023-03-01 01:29:57,734 DEBUG TRAIN Batch 46/2300 loss 1.525536 loss_att 3.781185 loss_ctc 2.217793 loss_rnnt 0.857028 hw_loss 0.234518 lr 0.00029657 rank 5
2023-03-01 01:29:57,735 DEBUG TRAIN Batch 46/2300 loss 5.636984 loss_att 9.375324 loss_ctc 9.023502 loss_rnnt 4.360878 hw_loss 0.144192 lr 0.00029657 rank 2
2023-03-01 01:30:36,872 DEBUG TRAIN Batch 46/2400 loss 10.090538 loss_att 12.564857 loss_ctc 16.175619 loss_rnnt 8.670363 hw_loss 0.213688 lr 0.00029656 rank 1
2023-03-01 01:30:36,873 DEBUG TRAIN Batch 46/2400 loss 5.230386 loss_att 7.699251 loss_ctc 9.729647 loss_rnnt 3.950963 hw_loss 0.348278 lr 0.00029656 rank 4
2023-03-01 01:30:36,874 DEBUG TRAIN Batch 46/2400 loss 10.870858 loss_att 14.570087 loss_ctc 15.910532 loss_rnnt 9.351599 hw_loss 0.201479 lr 0.00029656 rank 5
2023-03-01 01:30:36,880 DEBUG TRAIN Batch 46/2400 loss 9.329050 loss_att 12.930575 loss_ctc 20.535080 loss_rnnt 6.959257 hw_loss 0.291282 lr 0.00029656 rank 0
2023-03-01 01:30:36,882 DEBUG TRAIN Batch 46/2400 loss 9.228498 loss_att 12.769191 loss_ctc 19.529995 loss_rnnt 7.041710 hw_loss 0.197094 lr 0.00029655 rank 6
2023-03-01 01:30:36,890 DEBUG TRAIN Batch 46/2400 loss 5.435642 loss_att 7.829505 loss_ctc 11.338124 loss_rnnt 4.000532 hw_loss 0.317512 lr 0.00029656 rank 2
2023-03-01 01:30:36,891 DEBUG TRAIN Batch 46/2400 loss 5.632007 loss_att 9.649730 loss_ctc 10.333467 loss_rnnt 4.127259 hw_loss 0.139390 lr 0.00029655 rank 3
2023-03-01 01:30:36,894 DEBUG TRAIN Batch 46/2400 loss 3.181856 loss_att 4.779702 loss_ctc 5.544809 loss_rnnt 2.446824 hw_loss 0.188254 lr 0.00029655 rank 7
2023-03-01 01:31:42,241 DEBUG TRAIN Batch 46/2500 loss 6.462817 loss_att 6.468097 loss_ctc 9.946414 loss_rnnt 5.766172 hw_loss 0.433332 lr 0.00029654 rank 7
2023-03-01 01:31:42,248 DEBUG TRAIN Batch 46/2500 loss 10.015198 loss_att 10.594463 loss_ctc 13.789732 loss_rnnt 9.197657 hw_loss 0.372031 lr 0.00029655 rank 0
2023-03-01 01:31:42,248 DEBUG TRAIN Batch 46/2500 loss 5.548402 loss_att 9.081816 loss_ctc 9.453699 loss_rnnt 4.209711 hw_loss 0.208694 lr 0.00029654 rank 4
2023-03-01 01:31:42,251 DEBUG TRAIN Batch 46/2500 loss 5.411540 loss_att 6.847769 loss_ctc 6.153833 loss_rnnt 4.858022 hw_loss 0.313687 lr 0.00029654 rank 1
2023-03-01 01:31:42,251 DEBUG TRAIN Batch 46/2500 loss 7.654766 loss_att 8.228420 loss_ctc 14.615191 loss_rnnt 6.397649 hw_loss 0.401868 lr 0.00029654 rank 3
2023-03-01 01:31:42,254 DEBUG TRAIN Batch 46/2500 loss 7.154510 loss_att 8.588822 loss_ctc 11.303582 loss_rnnt 6.102208 hw_loss 0.397930 lr 0.00029654 rank 6
2023-03-01 01:31:42,252 DEBUG TRAIN Batch 46/2500 loss 5.885142 loss_att 6.096649 loss_ctc 9.729769 loss_rnnt 5.172133 hw_loss 0.296419 lr 0.00029654 rank 5
2023-03-01 01:31:42,300 DEBUG TRAIN Batch 46/2500 loss 3.916836 loss_att 8.452154 loss_ctc 5.314219 loss_rnnt 2.724030 hw_loss 0.186419 lr 0.00029654 rank 2
2023-03-01 01:32:21,111 DEBUG TRAIN Batch 46/2600 loss 3.026152 loss_att 7.054201 loss_ctc 5.595159 loss_rnnt 1.737093 hw_loss 0.264215 lr 0.00029653 rank 1
2023-03-01 01:32:21,115 DEBUG TRAIN Batch 46/2600 loss 3.897799 loss_att 5.582536 loss_ctc 6.127921 loss_rnnt 3.226821 hw_loss 0.068777 lr 0.00029653 rank 3
2023-03-01 01:32:21,117 DEBUG TRAIN Batch 46/2600 loss 5.623725 loss_att 10.649193 loss_ctc 9.932310 loss_rnnt 3.926993 hw_loss 0.219677 lr 0.00029653 rank 4
2023-03-01 01:32:21,125 DEBUG TRAIN Batch 46/2600 loss 3.494287 loss_att 5.755205 loss_ctc 3.584352 loss_rnnt 2.917020 hw_loss 0.212014 lr 0.00029653 rank 5
2023-03-01 01:32:21,132 DEBUG TRAIN Batch 46/2600 loss 6.268236 loss_att 10.197042 loss_ctc 9.211566 loss_rnnt 4.978193 hw_loss 0.209696 lr 0.00029653 rank 0
2023-03-01 01:32:21,133 DEBUG TRAIN Batch 46/2600 loss 2.705264 loss_att 6.290967 loss_ctc 8.167081 loss_rnnt 1.155023 hw_loss 0.196609 lr 0.00029652 rank 7
2023-03-01 01:32:21,173 DEBUG TRAIN Batch 46/2600 loss 8.827787 loss_att 10.767573 loss_ctc 15.077198 loss_rnnt 7.418086 hw_loss 0.353418 lr 0.00029653 rank 2
2023-03-01 01:32:21,175 DEBUG TRAIN Batch 46/2600 loss 3.664668 loss_att 6.511460 loss_ctc 4.512440 loss_rnnt 2.827783 hw_loss 0.289671 lr 0.00029653 rank 6
2023-03-01 01:32:59,852 DEBUG TRAIN Batch 46/2700 loss 11.393697 loss_att 15.179195 loss_ctc 16.939602 loss_rnnt 9.796663 hw_loss 0.188399 lr 0.00029651 rank 6
2023-03-01 01:32:59,859 DEBUG TRAIN Batch 46/2700 loss 2.166430 loss_att 3.952984 loss_ctc 4.419324 loss_rnnt 1.432742 hw_loss 0.142481 lr 0.00029652 rank 2
2023-03-01 01:32:59,864 DEBUG TRAIN Batch 46/2700 loss 7.727625 loss_att 10.917038 loss_ctc 14.735737 loss_rnnt 5.993526 hw_loss 0.303377 lr 0.00029652 rank 5
2023-03-01 01:32:59,866 DEBUG TRAIN Batch 46/2700 loss 8.015422 loss_att 10.898826 loss_ctc 16.362076 loss_rnnt 6.181039 hw_loss 0.271529 lr 0.00029652 rank 0
2023-03-01 01:32:59,870 DEBUG TRAIN Batch 46/2700 loss 3.751342 loss_att 6.415255 loss_ctc 7.379526 loss_rnnt 2.658661 hw_loss 0.142763 lr 0.00029651 rank 7
2023-03-01 01:32:59,876 DEBUG TRAIN Batch 46/2700 loss 2.830769 loss_att 5.341503 loss_ctc 7.848003 loss_rnnt 1.496144 hw_loss 0.306587 lr 0.00029652 rank 1
2023-03-01 01:32:59,880 DEBUG TRAIN Batch 46/2700 loss 3.434726 loss_att 5.765318 loss_ctc 5.622311 loss_rnnt 2.578389 hw_loss 0.184764 lr 0.00029651 rank 3
2023-03-01 01:32:59,882 DEBUG TRAIN Batch 46/2700 loss 1.646764 loss_att 5.142556 loss_ctc 3.708255 loss_rnnt 0.467966 hw_loss 0.383952 lr 0.00029652 rank 4
2023-03-01 01:33:39,385 DEBUG TRAIN Batch 46/2800 loss 5.595940 loss_att 8.068520 loss_ctc 9.273251 loss_rnnt 4.444798 hw_loss 0.311844 lr 0.00029650 rank 1
2023-03-01 01:33:39,401 DEBUG TRAIN Batch 46/2800 loss 4.095246 loss_att 6.905245 loss_ctc 6.149296 loss_rnnt 3.086806 hw_loss 0.323562 lr 0.00029650 rank 4
2023-03-01 01:33:39,403 DEBUG TRAIN Batch 46/2800 loss 6.290613 loss_att 9.640732 loss_ctc 7.052246 loss_rnnt 5.355527 hw_loss 0.306583 lr 0.00029651 rank 0
2023-03-01 01:33:39,405 DEBUG TRAIN Batch 46/2800 loss 7.887254 loss_att 10.297604 loss_ctc 14.205971 loss_rnnt 6.404479 hw_loss 0.296644 lr 0.00029650 rank 5
2023-03-01 01:33:39,405 DEBUG TRAIN Batch 46/2800 loss 3.460684 loss_att 5.242903 loss_ctc 6.416484 loss_rnnt 2.559945 hw_loss 0.281604 lr 0.00029650 rank 7
2023-03-01 01:33:39,411 DEBUG TRAIN Batch 46/2800 loss 5.618288 loss_att 7.736039 loss_ctc 7.997179 loss_rnnt 4.761189 hw_loss 0.218181 lr 0.00029650 rank 2
2023-03-01 01:33:39,412 DEBUG TRAIN Batch 46/2800 loss 8.471712 loss_att 12.624070 loss_ctc 19.240913 loss_rnnt 6.126303 hw_loss 0.148207 lr 0.00029650 rank 3
2023-03-01 01:33:39,414 DEBUG TRAIN Batch 46/2800 loss 6.408692 loss_att 9.359062 loss_ctc 12.870009 loss_rnnt 4.812374 hw_loss 0.271380 lr 0.00029650 rank 6
2023-03-01 01:34:43,102 DEBUG TRAIN Batch 46/2900 loss 12.043318 loss_att 14.332819 loss_ctc 19.286606 loss_rnnt 10.470778 hw_loss 0.279126 lr 0.00029649 rank 6
2023-03-01 01:34:43,116 DEBUG TRAIN Batch 46/2900 loss 10.481832 loss_att 12.409330 loss_ctc 15.275681 loss_rnnt 9.292212 hw_loss 0.309262 lr 0.00029649 rank 1
2023-03-01 01:34:43,116 DEBUG TRAIN Batch 46/2900 loss 6.883914 loss_att 8.911098 loss_ctc 8.526461 loss_rnnt 6.150851 hw_loss 0.203663 lr 0.00029649 rank 0
2023-03-01 01:34:43,122 DEBUG TRAIN Batch 46/2900 loss 10.460292 loss_att 12.485022 loss_ctc 16.019371 loss_rnnt 9.203961 hw_loss 0.206577 lr 0.00029648 rank 7
2023-03-01 01:34:43,122 DEBUG TRAIN Batch 46/2900 loss 4.574526 loss_att 6.715554 loss_ctc 6.865451 loss_rnnt 3.699508 hw_loss 0.265043 lr 0.00029649 rank 2
2023-03-01 01:34:43,140 DEBUG TRAIN Batch 46/2900 loss 9.164032 loss_att 12.608740 loss_ctc 16.512150 loss_rnnt 7.406603 hw_loss 0.166382 lr 0.00029649 rank 3
2023-03-01 01:34:43,141 DEBUG TRAIN Batch 46/2900 loss 6.017662 loss_att 8.810904 loss_ctc 9.944328 loss_rnnt 4.916378 hw_loss 0.035773 lr 0.00029649 rank 4
2023-03-01 01:34:43,148 DEBUG TRAIN Batch 46/2900 loss 4.633873 loss_att 6.020001 loss_ctc 7.800442 loss_rnnt 3.824033 hw_loss 0.207007 lr 0.00029649 rank 5
2023-03-01 01:35:21,683 DEBUG TRAIN Batch 46/3000 loss 5.886049 loss_att 7.107833 loss_ctc 12.874001 loss_rnnt 4.541505 hw_loss 0.315862 lr 0.00029647 rank 7
2023-03-01 01:35:21,687 DEBUG TRAIN Batch 46/3000 loss 2.179668 loss_att 5.508145 loss_ctc 4.883078 loss_rnnt 1.059144 hw_loss 0.176951 lr 0.00029648 rank 5
2023-03-01 01:35:21,700 DEBUG TRAIN Batch 46/3000 loss 9.898531 loss_att 12.574793 loss_ctc 13.428207 loss_rnnt 8.730533 hw_loss 0.303978 lr 0.00029648 rank 4
2023-03-01 01:35:21,706 DEBUG TRAIN Batch 46/3000 loss 9.219385 loss_att 13.116028 loss_ctc 16.999306 loss_rnnt 7.238861 hw_loss 0.307263 lr 0.00029648 rank 2
2023-03-01 01:35:21,706 DEBUG TRAIN Batch 46/3000 loss 4.512895 loss_att 9.133688 loss_ctc 13.321236 loss_rnnt 2.269261 hw_loss 0.271930 lr 0.00029648 rank 1
2023-03-01 01:35:21,706 DEBUG TRAIN Batch 46/3000 loss 7.311599 loss_att 12.384838 loss_ctc 17.565044 loss_rnnt 4.871849 hw_loss 0.108706 lr 0.00029647 rank 6
2023-03-01 01:35:21,708 DEBUG TRAIN Batch 46/3000 loss 3.370476 loss_att 6.148870 loss_ctc 5.156947 loss_rnnt 2.449412 hw_loss 0.238480 lr 0.00029647 rank 3
2023-03-01 01:35:21,709 DEBUG TRAIN Batch 46/3000 loss 2.967434 loss_att 6.358147 loss_ctc 7.577466 loss_rnnt 1.541734 hw_loss 0.249163 lr 0.00029648 rank 0
2023-03-01 01:36:01,066 DEBUG TRAIN Batch 46/3100 loss 7.566919 loss_att 9.461919 loss_ctc 11.905550 loss_rnnt 6.444578 hw_loss 0.309106 lr 0.00029646 rank 6
2023-03-01 01:36:01,067 DEBUG TRAIN Batch 46/3100 loss 1.515146 loss_att 3.458390 loss_ctc 2.325574 loss_rnnt 0.889270 hw_loss 0.242194 lr 0.00029647 rank 1
2023-03-01 01:36:01,068 DEBUG TRAIN Batch 46/3100 loss 3.394342 loss_att 4.853377 loss_ctc 6.208837 loss_rnnt 2.618243 hw_loss 0.204423 lr 0.00029646 rank 2
2023-03-01 01:36:01,068 DEBUG TRAIN Batch 46/3100 loss 6.708700 loss_att 7.203953 loss_ctc 11.356920 loss_rnnt 5.752295 hw_loss 0.445484 lr 0.00029647 rank 4
2023-03-01 01:36:01,068 DEBUG TRAIN Batch 46/3100 loss 5.565213 loss_att 7.510123 loss_ctc 8.074185 loss_rnnt 4.675338 hw_loss 0.311932 lr 0.00029647 rank 0
2023-03-01 01:36:01,069 DEBUG TRAIN Batch 46/3100 loss 4.525230 loss_att 5.951324 loss_ctc 8.561011 loss_rnnt 3.510245 hw_loss 0.359366 lr 0.00029646 rank 7
2023-03-01 01:36:01,078 DEBUG TRAIN Batch 46/3100 loss 3.722593 loss_att 5.577045 loss_ctc 6.748826 loss_rnnt 2.789158 hw_loss 0.298212 lr 0.00029646 rank 3
2023-03-01 01:36:01,107 DEBUG TRAIN Batch 46/3100 loss 3.124747 loss_att 4.922077 loss_ctc 6.886427 loss_rnnt 2.083951 hw_loss 0.337072 lr 0.00029646 rank 5
2023-03-01 01:37:05,835 DEBUG TRAIN Batch 46/3200 loss 7.856040 loss_att 10.346236 loss_ctc 11.204532 loss_rnnt 6.804769 hw_loss 0.200185 lr 0.00029644 rank 7
2023-03-01 01:37:05,836 DEBUG TRAIN Batch 46/3200 loss 7.237714 loss_att 11.443738 loss_ctc 13.129501 loss_rnnt 5.502390 hw_loss 0.203526 lr 0.00029645 rank 0
2023-03-01 01:37:05,840 DEBUG TRAIN Batch 46/3200 loss 7.829402 loss_att 8.418274 loss_ctc 9.934813 loss_rnnt 7.278872 hw_loss 0.285066 lr 0.00029645 rank 2
2023-03-01 01:37:05,841 DEBUG TRAIN Batch 46/3200 loss 5.743464 loss_att 6.455128 loss_ctc 11.988839 loss_rnnt 4.557435 hw_loss 0.395585 lr 0.00029645 rank 1
2023-03-01 01:37:05,852 DEBUG TRAIN Batch 46/3200 loss 6.497124 loss_att 9.576931 loss_ctc 14.837048 loss_rnnt 4.655413 hw_loss 0.213299 lr 0.00029645 rank 4
2023-03-01 01:37:05,867 DEBUG TRAIN Batch 46/3200 loss 7.786121 loss_att 8.113016 loss_ctc 12.694846 loss_rnnt 6.850632 hw_loss 0.404275 lr 0.00029645 rank 5
2023-03-01 01:37:05,869 DEBUG TRAIN Batch 46/3200 loss 3.421920 loss_att 5.772648 loss_ctc 3.591692 loss_rnnt 2.782064 hw_loss 0.275765 lr 0.00029645 rank 3
2023-03-01 01:37:05,883 DEBUG TRAIN Batch 46/3200 loss 9.931297 loss_att 13.140177 loss_ctc 18.085018 loss_rnnt 8.055288 hw_loss 0.275757 lr 0.00029645 rank 6
2023-03-01 01:37:45,568 DEBUG TRAIN Batch 46/3300 loss 2.576128 loss_att 4.433473 loss_ctc 3.916717 loss_rnnt 1.962398 hw_loss 0.119094 lr 0.00029644 rank 2
2023-03-01 01:37:45,580 DEBUG TRAIN Batch 46/3300 loss 11.106292 loss_att 15.046556 loss_ctc 15.939349 loss_rnnt 9.597477 hw_loss 0.143163 lr 0.00029643 rank 7
2023-03-01 01:37:45,582 DEBUG TRAIN Batch 46/3300 loss 9.642521 loss_att 15.638495 loss_ctc 24.897247 loss_rnnt 6.299729 hw_loss 0.205560 lr 0.00029644 rank 0
2023-03-01 01:37:45,585 DEBUG TRAIN Batch 46/3300 loss 2.239102 loss_att 5.134856 loss_ctc 3.926373 loss_rnnt 1.323237 hw_loss 0.209521 lr 0.00029644 rank 6
2023-03-01 01:37:45,585 DEBUG TRAIN Batch 46/3300 loss 3.961561 loss_att 7.208757 loss_ctc 8.960305 loss_rnnt 2.497054 hw_loss 0.278565 lr 0.00029643 rank 3
2023-03-01 01:37:45,591 DEBUG TRAIN Batch 46/3300 loss 3.955936 loss_att 6.302579 loss_ctc 5.273993 loss_rnnt 3.178846 hw_loss 0.247540 lr 0.00029644 rank 4
2023-03-01 01:37:45,591 DEBUG TRAIN Batch 46/3300 loss 3.608281 loss_att 7.977952 loss_ctc 5.867204 loss_rnnt 2.280837 hw_loss 0.285600 lr 0.00029644 rank 5
2023-03-01 01:37:45,633 DEBUG TRAIN Batch 46/3300 loss 11.770245 loss_att 19.799173 loss_ctc 22.156652 loss_rnnt 8.645306 hw_loss 0.251812 lr 0.00029644 rank 1
2023-03-01 01:38:24,325 DEBUG TRAIN Batch 46/3400 loss 4.379787 loss_att 5.612312 loss_ctc 6.855392 loss_rnnt 3.714069 hw_loss 0.167123 lr 0.00029643 rank 0
2023-03-01 01:38:24,330 DEBUG TRAIN Batch 46/3400 loss 7.281528 loss_att 9.931595 loss_ctc 10.914734 loss_rnnt 6.177660 hw_loss 0.167674 lr 0.00029642 rank 7
2023-03-01 01:38:24,331 DEBUG TRAIN Batch 46/3400 loss 3.239612 loss_att 5.988832 loss_ctc 4.803203 loss_rnnt 2.319090 hw_loss 0.304121 lr 0.00029642 rank 3
2023-03-01 01:38:24,332 DEBUG TRAIN Batch 46/3400 loss 4.331241 loss_att 6.386783 loss_ctc 6.776414 loss_rnnt 3.464467 hw_loss 0.243080 lr 0.00029643 rank 4
2023-03-01 01:38:24,333 DEBUG TRAIN Batch 46/3400 loss 3.203660 loss_att 5.785628 loss_ctc 8.085792 loss_rnnt 1.874447 hw_loss 0.303504 lr 0.00029642 rank 6
2023-03-01 01:38:24,333 DEBUG TRAIN Batch 46/3400 loss 14.455582 loss_att 16.094395 loss_ctc 20.778709 loss_rnnt 13.147346 hw_loss 0.257602 lr 0.00029643 rank 1
2023-03-01 01:38:24,335 DEBUG TRAIN Batch 46/3400 loss 7.511648 loss_att 11.460244 loss_ctc 13.384577 loss_rnnt 5.855299 hw_loss 0.156700 lr 0.00029643 rank 5
2023-03-01 01:38:24,335 DEBUG TRAIN Batch 46/3400 loss 3.986665 loss_att 8.125396 loss_ctc 11.392123 loss_rnnt 1.957928 hw_loss 0.400493 lr 0.00029643 rank 2
2023-03-01 01:39:03,798 DEBUG TRAIN Batch 46/3500 loss 7.470555 loss_att 12.296839 loss_ctc 13.169633 loss_rnnt 5.642647 hw_loss 0.192702 lr 0.00029641 rank 3
2023-03-01 01:39:03,800 DEBUG TRAIN Batch 46/3500 loss 2.762552 loss_att 5.717173 loss_ctc 4.536542 loss_rnnt 1.751950 hw_loss 0.343399 lr 0.00029641 rank 1
2023-03-01 01:39:03,806 DEBUG TRAIN Batch 46/3500 loss 5.577139 loss_att 8.320003 loss_ctc 10.199973 loss_rnnt 4.239216 hw_loss 0.324323 lr 0.00029642 rank 0
2023-03-01 01:39:03,810 DEBUG TRAIN Batch 46/3500 loss 9.023512 loss_att 12.410784 loss_ctc 13.155096 loss_rnnt 7.733188 hw_loss 0.116233 lr 0.00029641 rank 2
2023-03-01 01:39:03,812 DEBUG TRAIN Batch 46/3500 loss 6.073425 loss_att 9.508743 loss_ctc 9.990054 loss_rnnt 4.799713 hw_loss 0.120809 lr 0.00029641 rank 7
2023-03-01 01:39:03,815 DEBUG TRAIN Batch 46/3500 loss 7.321592 loss_att 9.362580 loss_ctc 11.541189 loss_rnnt 6.268895 hw_loss 0.153538 lr 0.00029641 rank 5
2023-03-01 01:39:03,823 DEBUG TRAIN Batch 46/3500 loss 12.588858 loss_att 13.132465 loss_ctc 13.796059 loss_rnnt 12.163465 hw_loss 0.291958 lr 0.00029641 rank 6
2023-03-01 01:39:03,825 DEBUG TRAIN Batch 46/3500 loss 8.093828 loss_att 11.229001 loss_ctc 15.050504 loss_rnnt 6.432471 hw_loss 0.200185 lr 0.00029641 rank 4
2023-03-01 01:40:08,754 DEBUG TRAIN Batch 46/3600 loss 3.648856 loss_att 7.566326 loss_ctc 8.296382 loss_rnnt 2.133436 hw_loss 0.210481 lr 0.00029640 rank 0
2023-03-01 01:40:08,755 DEBUG TRAIN Batch 46/3600 loss 4.808511 loss_att 7.217250 loss_ctc 7.577158 loss_rnnt 3.777724 hw_loss 0.337286 lr 0.00029640 rank 1
2023-03-01 01:40:08,756 DEBUG TRAIN Batch 46/3600 loss 4.417486 loss_att 7.232003 loss_ctc 8.492953 loss_rnnt 3.207318 hw_loss 0.194755 lr 0.00029639 rank 3
2023-03-01 01:40:08,757 DEBUG TRAIN Batch 46/3600 loss 9.535535 loss_att 14.503941 loss_ctc 16.986153 loss_rnnt 7.364682 hw_loss 0.344540 lr 0.00029640 rank 5
2023-03-01 01:40:08,759 DEBUG TRAIN Batch 46/3600 loss 8.067439 loss_att 12.947854 loss_ctc 19.664654 loss_rnnt 5.437291 hw_loss 0.202069 lr 0.00029640 rank 4
2023-03-01 01:40:08,758 DEBUG TRAIN Batch 46/3600 loss 5.335807 loss_att 7.419188 loss_ctc 8.435529 loss_rnnt 4.353518 hw_loss 0.285594 lr 0.00029639 rank 7
2023-03-01 01:40:08,760 DEBUG TRAIN Batch 46/3600 loss 4.334933 loss_att 8.579762 loss_ctc 8.847614 loss_rnnt 2.773552 hw_loss 0.207609 lr 0.00029640 rank 6
2023-03-01 01:40:08,764 DEBUG TRAIN Batch 46/3600 loss 9.511927 loss_att 13.524883 loss_ctc 16.861507 loss_rnnt 7.564012 hw_loss 0.310086 lr 0.00029640 rank 2
2023-03-01 01:40:49,933 DEBUG TRAIN Batch 46/3700 loss 2.789804 loss_att 5.703113 loss_ctc 4.765737 loss_rnnt 1.840028 hw_loss 0.194354 lr 0.00029638 rank 6
2023-03-01 01:40:49,936 DEBUG TRAIN Batch 46/3700 loss 6.804037 loss_att 9.406182 loss_ctc 11.923184 loss_rnnt 5.453996 hw_loss 0.275735 lr 0.00029639 rank 5
2023-03-01 01:40:49,945 DEBUG TRAIN Batch 46/3700 loss 10.512451 loss_att 10.948190 loss_ctc 14.930297 loss_rnnt 9.770876 hw_loss 0.122590 lr 0.00029638 rank 7
2023-03-01 01:40:49,948 DEBUG TRAIN Batch 46/3700 loss 12.575348 loss_att 15.710718 loss_ctc 16.162302 loss_rnnt 11.330799 hw_loss 0.261025 lr 0.00029639 rank 1
2023-03-01 01:40:49,949 DEBUG TRAIN Batch 46/3700 loss 9.975252 loss_att 11.790453 loss_ctc 13.705627 loss_rnnt 8.956683 hw_loss 0.296524 lr 0.00029639 rank 2
2023-03-01 01:40:49,951 DEBUG TRAIN Batch 46/3700 loss 4.476552 loss_att 7.976320 loss_ctc 8.844859 loss_rnnt 3.063890 hw_loss 0.244254 lr 0.00029639 rank 0
2023-03-01 01:40:49,951 DEBUG TRAIN Batch 46/3700 loss 4.535437 loss_att 6.242023 loss_ctc 6.316402 loss_rnnt 3.799536 hw_loss 0.294601 lr 0.00029639 rank 4
2023-03-01 01:40:49,959 DEBUG TRAIN Batch 46/3700 loss 3.122427 loss_att 5.778448 loss_ctc 5.083333 loss_rnnt 2.193125 hw_loss 0.256206 lr 0.00029638 rank 3
2023-03-01 01:41:29,796 DEBUG TRAIN Batch 46/3800 loss 2.134995 loss_att 6.051255 loss_ctc 4.728813 loss_rnnt 0.863705 hw_loss 0.266617 lr 0.00029637 rank 4
2023-03-01 01:41:29,796 DEBUG TRAIN Batch 46/3800 loss 6.957229 loss_att 10.668461 loss_ctc 13.720308 loss_rnnt 5.238138 hw_loss 0.140813 lr 0.00029637 rank 3
2023-03-01 01:41:29,805 DEBUG TRAIN Batch 46/3800 loss 4.177272 loss_att 5.079062 loss_ctc 6.900700 loss_rnnt 3.420984 hw_loss 0.399014 lr 0.00029638 rank 0
2023-03-01 01:41:29,806 DEBUG TRAIN Batch 46/3800 loss 3.094607 loss_att 4.594210 loss_ctc 5.631253 loss_rnnt 2.294871 hw_loss 0.302994 lr 0.00029637 rank 2
2023-03-01 01:41:29,807 DEBUG TRAIN Batch 46/3800 loss 10.099984 loss_att 11.082014 loss_ctc 14.563926 loss_rnnt 9.177110 hw_loss 0.246144 lr 0.00029637 rank 1
2023-03-01 01:41:29,807 DEBUG TRAIN Batch 46/3800 loss 5.255724 loss_att 7.163546 loss_ctc 7.101858 loss_rnnt 4.477247 hw_loss 0.282678 lr 0.00029637 rank 6
2023-03-01 01:41:29,809 DEBUG TRAIN Batch 46/3800 loss 6.444559 loss_att 10.159340 loss_ctc 8.931818 loss_rnnt 5.205635 hw_loss 0.308124 lr 0.00029637 rank 7
2023-03-01 01:41:29,815 DEBUG TRAIN Batch 46/3800 loss 8.836038 loss_att 10.635303 loss_ctc 12.421865 loss_rnnt 7.788217 hw_loss 0.393483 lr 0.00029637 rank 5
2023-03-01 01:42:09,999 DEBUG TRAIN Batch 46/3900 loss 3.109707 loss_att 6.960403 loss_ctc 7.189850 loss_rnnt 1.636117 hw_loss 0.298934 lr 0.00029636 rank 1
2023-03-01 01:42:10,002 DEBUG TRAIN Batch 46/3900 loss 6.967252 loss_att 10.706543 loss_ctc 14.116522 loss_rnnt 5.201115 hw_loss 0.121956 lr 0.00029636 rank 3
2023-03-01 01:42:10,002 DEBUG TRAIN Batch 46/3900 loss 2.121889 loss_att 5.139563 loss_ctc 4.687283 loss_rnnt 1.083905 hw_loss 0.173244 lr 0.00029636 rank 6
2023-03-01 01:42:10,004 DEBUG TRAIN Batch 46/3900 loss 5.266345 loss_att 9.725101 loss_ctc 8.974762 loss_rnnt 3.745130 hw_loss 0.253139 lr 0.00029636 rank 5
2023-03-01 01:42:10,021 DEBUG TRAIN Batch 46/3900 loss 3.989165 loss_att 6.169996 loss_ctc 6.343960 loss_rnnt 3.155848 hw_loss 0.155959 lr 0.00029636 rank 0
2023-03-01 01:42:10,025 DEBUG TRAIN Batch 46/3900 loss 8.384503 loss_att 9.753207 loss_ctc 12.383909 loss_rnnt 7.521792 hw_loss 0.104467 lr 0.00029636 rank 2
2023-03-01 01:42:10,025 DEBUG TRAIN Batch 46/3900 loss 5.766848 loss_att 8.996951 loss_ctc 12.105918 loss_rnnt 4.114093 hw_loss 0.302859 lr 0.00029635 rank 7
2023-03-01 01:42:10,030 DEBUG TRAIN Batch 46/3900 loss 8.161578 loss_att 10.074246 loss_ctc 15.805387 loss_rnnt 6.635782 hw_loss 0.232666 lr 0.00029636 rank 4
2023-03-01 01:43:12,754 DEBUG TRAIN Batch 46/4000 loss 7.820299 loss_att 12.827075 loss_ctc 16.492111 loss_rnnt 5.578857 hw_loss 0.157209 lr 0.00029634 rank 7
2023-03-01 01:43:12,772 DEBUG TRAIN Batch 46/4000 loss 4.903698 loss_att 6.965357 loss_ctc 7.858838 loss_rnnt 3.964026 hw_loss 0.249977 lr 0.00029635 rank 0
2023-03-01 01:43:12,776 DEBUG TRAIN Batch 46/4000 loss 9.223171 loss_att 12.886677 loss_ctc 16.611158 loss_rnnt 7.363862 hw_loss 0.265393 lr 0.00029635 rank 4
2023-03-01 01:43:12,779 DEBUG TRAIN Batch 46/4000 loss 1.801746 loss_att 6.353352 loss_ctc 3.975393 loss_rnnt 0.466547 hw_loss 0.253235 lr 0.00029634 rank 6
2023-03-01 01:43:12,780 DEBUG TRAIN Batch 46/4000 loss 3.779091 loss_att 6.719038 loss_ctc 6.785390 loss_rnnt 2.670915 hw_loss 0.223774 lr 0.00029635 rank 1
2023-03-01 01:43:12,782 DEBUG TRAIN Batch 46/4000 loss 2.843657 loss_att 7.479152 loss_ctc 6.034819 loss_rnnt 1.400167 hw_loss 0.170444 lr 0.00029635 rank 2
2023-03-01 01:43:12,784 DEBUG TRAIN Batch 46/4000 loss 11.439116 loss_att 21.162703 loss_ctc 26.500973 loss_rnnt 7.375846 hw_loss 0.206818 lr 0.00029634 rank 3
2023-03-01 01:43:12,833 DEBUG TRAIN Batch 46/4000 loss 2.462020 loss_att 3.638747 loss_ctc 3.515034 loss_rnnt 2.070379 hw_loss 0.029799 lr 0.00029635 rank 5
2023-03-01 01:43:51,405 DEBUG TRAIN Batch 46/4100 loss 4.625499 loss_att 8.305557 loss_ctc 8.322361 loss_rnnt 3.259392 hw_loss 0.257213 lr 0.00029633 rank 7
2023-03-01 01:43:51,411 DEBUG TRAIN Batch 46/4100 loss 5.808350 loss_att 9.326859 loss_ctc 9.576727 loss_rnnt 4.406695 hw_loss 0.366567 lr 0.00029634 rank 0
2023-03-01 01:43:51,411 DEBUG TRAIN Batch 46/4100 loss 4.572553 loss_att 7.480723 loss_ctc 6.607822 loss_rnnt 3.608341 hw_loss 0.208516 lr 0.00029633 rank 2
2023-03-01 01:43:51,411 DEBUG TRAIN Batch 46/4100 loss 8.170662 loss_att 11.424810 loss_ctc 14.031924 loss_rnnt 6.587657 hw_loss 0.282513 lr 0.00029633 rank 5
2023-03-01 01:43:51,414 DEBUG TRAIN Batch 46/4100 loss 1.231135 loss_att 3.421738 loss_ctc 1.367413 loss_rnnt 0.614245 hw_loss 0.301124 lr 0.00029633 rank 3
2023-03-01 01:43:51,440 DEBUG TRAIN Batch 46/4100 loss 3.047373 loss_att 5.047319 loss_ctc 5.952712 loss_rnnt 2.143855 hw_loss 0.217780 lr 0.00029634 rank 4
2023-03-01 01:43:51,443 DEBUG TRAIN Batch 46/4100 loss 3.579149 loss_att 6.453494 loss_ctc 7.306025 loss_rnnt 2.387067 hw_loss 0.225556 lr 0.00029634 rank 1
2023-03-01 01:43:51,455 DEBUG TRAIN Batch 46/4100 loss 7.318863 loss_att 11.188461 loss_ctc 13.596912 loss_rnnt 5.638673 hw_loss 0.129745 lr 0.00029633 rank 6
2023-03-01 01:44:30,680 DEBUG TRAIN Batch 46/4200 loss 3.682837 loss_att 7.756281 loss_ctc 8.452416 loss_rnnt 2.189477 hw_loss 0.080114 lr 0.00029632 rank 1
2023-03-01 01:44:30,680 DEBUG TRAIN Batch 46/4200 loss 5.943261 loss_att 9.978619 loss_ctc 13.366714 loss_rnnt 3.977576 hw_loss 0.316535 lr 0.00029632 rank 5
2023-03-01 01:44:30,691 DEBUG TRAIN Batch 46/4200 loss 5.149886 loss_att 8.968742 loss_ctc 11.445911 loss_rnnt 3.412948 hw_loss 0.250681 lr 0.00029632 rank 0
2023-03-01 01:44:30,696 DEBUG TRAIN Batch 46/4200 loss 6.741097 loss_att 8.585430 loss_ctc 14.696293 loss_rnnt 5.111035 hw_loss 0.375940 lr 0.00029632 rank 4
2023-03-01 01:44:30,697 DEBUG TRAIN Batch 46/4200 loss 2.495628 loss_att 4.452450 loss_ctc 6.035779 loss_rnnt 1.460516 hw_loss 0.321990 lr 0.00029631 rank 7
2023-03-01 01:44:30,697 DEBUG TRAIN Batch 46/4200 loss 10.845853 loss_att 11.747557 loss_ctc 13.188084 loss_rnnt 10.208494 hw_loss 0.271352 lr 0.00029632 rank 6
2023-03-01 01:44:30,700 DEBUG TRAIN Batch 46/4200 loss 8.889053 loss_att 12.363808 loss_ctc 13.018016 loss_rnnt 7.524794 hw_loss 0.222715 lr 0.00029632 rank 2
2023-03-01 01:44:30,707 DEBUG TRAIN Batch 46/4200 loss 14.920443 loss_att 20.391628 loss_ctc 26.839727 loss_rnnt 12.072697 hw_loss 0.308009 lr 0.00029632 rank 3
2023-03-01 01:45:35,209 DEBUG TRAIN Batch 46/4300 loss 2.692497 loss_att 4.784024 loss_ctc 6.100946 loss_rnnt 1.783126 hw_loss 0.068635 lr 0.00029631 rank 4
2023-03-01 01:45:35,213 DEBUG TRAIN Batch 46/4300 loss 9.064423 loss_att 10.494038 loss_ctc 12.298407 loss_rnnt 8.262309 hw_loss 0.159360 lr 0.00029631 rank 2
2023-03-01 01:45:35,213 DEBUG TRAIN Batch 46/4300 loss 7.067585 loss_att 8.620402 loss_ctc 11.181647 loss_rnnt 6.134383 hw_loss 0.138932 lr 0.00029631 rank 0
2023-03-01 01:45:35,213 DEBUG TRAIN Batch 46/4300 loss 3.700339 loss_att 7.560138 loss_ctc 4.071798 loss_rnnt 2.740033 hw_loss 0.260283 lr 0.00029630 rank 6
2023-03-01 01:45:35,213 DEBUG TRAIN Batch 46/4300 loss 5.367218 loss_att 7.021365 loss_ctc 8.726213 loss_rnnt 4.474827 hw_loss 0.213181 lr 0.00029630 rank 7
2023-03-01 01:45:35,214 DEBUG TRAIN Batch 46/4300 loss 7.548709 loss_att 11.254789 loss_ctc 12.057530 loss_rnnt 6.072149 hw_loss 0.251563 lr 0.00029631 rank 5
2023-03-01 01:45:35,216 DEBUG TRAIN Batch 46/4300 loss 11.278043 loss_att 17.596878 loss_ctc 20.636665 loss_rnnt 8.631556 hw_loss 0.252943 lr 0.00029631 rank 1
2023-03-01 01:45:35,218 DEBUG TRAIN Batch 46/4300 loss 5.132318 loss_att 9.015642 loss_ctc 7.063164 loss_rnnt 3.995553 hw_loss 0.192477 lr 0.00029630 rank 3
2023-03-01 01:46:14,383 DEBUG TRAIN Batch 46/4400 loss 2.568751 loss_att 5.591165 loss_ctc 3.675870 loss_rnnt 1.646691 hw_loss 0.318677 lr 0.00029630 rank 1
2023-03-01 01:46:14,387 DEBUG TRAIN Batch 46/4400 loss 3.954109 loss_att 6.780903 loss_ctc 8.377959 loss_rnnt 2.648499 hw_loss 0.282007 lr 0.00029630 rank 2
2023-03-01 01:46:14,396 DEBUG TRAIN Batch 46/4400 loss 5.631115 loss_att 9.904410 loss_ctc 11.307083 loss_rnnt 3.845145 hw_loss 0.327215 lr 0.00029630 rank 5
2023-03-01 01:46:14,405 DEBUG TRAIN Batch 46/4400 loss 11.673820 loss_att 13.301512 loss_ctc 15.623370 loss_rnnt 10.681472 hw_loss 0.262883 lr 0.00029629 rank 7
2023-03-01 01:46:14,409 DEBUG TRAIN Batch 46/4400 loss 7.441809 loss_att 8.707201 loss_ctc 12.379896 loss_rnnt 6.357248 hw_loss 0.324507 lr 0.00029629 rank 3
2023-03-01 01:46:14,410 DEBUG TRAIN Batch 46/4400 loss 8.765866 loss_att 9.736584 loss_ctc 12.750560 loss_rnnt 7.927597 hw_loss 0.211564 lr 0.00029630 rank 0
2023-03-01 01:46:14,435 DEBUG TRAIN Batch 46/4400 loss 6.815618 loss_att 7.032588 loss_ctc 9.531842 loss_rnnt 6.212455 hw_loss 0.370511 lr 0.00029630 rank 4
2023-03-01 01:46:14,446 DEBUG TRAIN Batch 46/4400 loss 5.625158 loss_att 9.132108 loss_ctc 10.511984 loss_rnnt 4.126347 hw_loss 0.273457 lr 0.00029629 rank 6
2023-03-01 01:46:53,182 DEBUG TRAIN Batch 46/4500 loss 9.430762 loss_att 10.813353 loss_ctc 14.180995 loss_rnnt 8.297752 hw_loss 0.418364 lr 0.00029628 rank 2
2023-03-01 01:46:53,190 DEBUG TRAIN Batch 46/4500 loss 6.393659 loss_att 9.553732 loss_ctc 7.218751 loss_rnnt 5.564596 hw_loss 0.163193 lr 0.00029629 rank 0
2023-03-01 01:46:53,190 DEBUG TRAIN Batch 46/4500 loss 11.456397 loss_att 14.357076 loss_ctc 13.948337 loss_rnnt 10.434464 hw_loss 0.205385 lr 0.00029628 rank 7
2023-03-01 01:46:53,192 DEBUG TRAIN Batch 46/4500 loss 11.435723 loss_att 12.313169 loss_ctc 17.446362 loss_rnnt 10.279538 hw_loss 0.336143 lr 0.00029628 rank 1
2023-03-01 01:46:53,192 DEBUG TRAIN Batch 46/4500 loss 4.302470 loss_att 4.895944 loss_ctc 5.578380 loss_rnnt 3.825109 hw_loss 0.353522 lr 0.00029628 rank 5
2023-03-01 01:46:53,197 DEBUG TRAIN Batch 46/4500 loss 9.937542 loss_att 14.461792 loss_ctc 15.016406 loss_rnnt 8.320697 hw_loss 0.065275 lr 0.00029628 rank 3
2023-03-01 01:46:53,200 DEBUG TRAIN Batch 46/4500 loss 4.680088 loss_att 7.533926 loss_ctc 8.968813 loss_rnnt 3.334413 hw_loss 0.380771 lr 0.00029628 rank 4
2023-03-01 01:46:53,238 DEBUG TRAIN Batch 46/4500 loss 10.242027 loss_att 10.401756 loss_ctc 15.773175 loss_rnnt 9.313255 hw_loss 0.298763 lr 0.00029628 rank 6
2023-03-01 01:47:33,535 DEBUG TRAIN Batch 46/4600 loss 5.628552 loss_att 8.537733 loss_ctc 8.295282 loss_rnnt 4.598516 hw_loss 0.173694 lr 0.00029627 rank 4
2023-03-01 01:47:33,537 DEBUG TRAIN Batch 46/4600 loss 5.100295 loss_att 8.583546 loss_ctc 9.835772 loss_rnnt 3.650776 hw_loss 0.227760 lr 0.00029627 rank 2
2023-03-01 01:47:33,549 DEBUG TRAIN Batch 46/4600 loss 9.089881 loss_att 12.445421 loss_ctc 20.494074 loss_rnnt 6.834390 hw_loss 0.119670 lr 0.00029627 rank 6
2023-03-01 01:47:33,552 DEBUG TRAIN Batch 46/4600 loss 6.849831 loss_att 9.137430 loss_ctc 9.650757 loss_rnnt 5.833095 hw_loss 0.348299 lr 0.00029627 rank 1
2023-03-01 01:47:33,550 DEBUG TRAIN Batch 46/4600 loss 3.350158 loss_att 6.883909 loss_ctc 6.312266 loss_rnnt 2.143212 hw_loss 0.197338 lr 0.00029627 rank 0
2023-03-01 01:47:33,552 DEBUG TRAIN Batch 46/4600 loss 3.255166 loss_att 5.493890 loss_ctc 6.307886 loss_rnnt 2.307019 hw_loss 0.175074 lr 0.00029626 rank 7
2023-03-01 01:47:33,552 DEBUG TRAIN Batch 46/4600 loss 2.745981 loss_att 5.550359 loss_ctc 5.251998 loss_rnnt 1.728314 hw_loss 0.229980 lr 0.00029626 rank 3
2023-03-01 01:47:33,562 DEBUG TRAIN Batch 46/4600 loss 4.704037 loss_att 6.693624 loss_ctc 6.224507 loss_rnnt 3.908439 hw_loss 0.365532 lr 0.00029627 rank 5
2023-03-01 01:48:36,989 DEBUG TRAIN Batch 46/4700 loss 4.566048 loss_att 7.223534 loss_ctc 8.347984 loss_rnnt 3.421675 hw_loss 0.203658 lr 0.00029626 rank 4
2023-03-01 01:48:36,997 DEBUG TRAIN Batch 46/4700 loss 5.084610 loss_att 8.455311 loss_ctc 9.956886 loss_rnnt 3.666848 hw_loss 0.176220 lr 0.00029626 rank 5
2023-03-01 01:48:37,002 DEBUG TRAIN Batch 46/4700 loss 8.384866 loss_att 11.340605 loss_ctc 16.472748 loss_rnnt 6.633754 hw_loss 0.152963 lr 0.00029626 rank 0
2023-03-01 01:48:37,011 DEBUG TRAIN Batch 46/4700 loss 2.646905 loss_att 5.622015 loss_ctc 5.595419 loss_rnnt 1.475128 hw_loss 0.344287 lr 0.00029626 rank 1
2023-03-01 01:48:37,012 DEBUG TRAIN Batch 46/4700 loss 5.807331 loss_att 8.354269 loss_ctc 8.563295 loss_rnnt 4.837560 hw_loss 0.174227 lr 0.00029626 rank 2
2023-03-01 01:48:37,014 DEBUG TRAIN Batch 46/4700 loss 4.621494 loss_att 6.362853 loss_ctc 7.700634 loss_rnnt 3.685888 hw_loss 0.331464 lr 0.00029625 rank 7
2023-03-01 01:48:37,028 DEBUG TRAIN Batch 46/4700 loss 6.500245 loss_att 9.144930 loss_ctc 8.274796 loss_rnnt 5.618437 hw_loss 0.217995 lr 0.00029625 rank 3
2023-03-01 01:48:37,039 DEBUG TRAIN Batch 46/4700 loss 3.956444 loss_att 6.233965 loss_ctc 6.553461 loss_rnnt 2.953938 hw_loss 0.376373 lr 0.00029625 rank 6
2023-03-01 01:49:15,852 DEBUG TRAIN Batch 46/4800 loss 10.867389 loss_att 12.469851 loss_ctc 15.210514 loss_rnnt 9.820679 hw_loss 0.275877 lr 0.00029624 rank 6
2023-03-01 01:49:15,868 DEBUG TRAIN Batch 46/4800 loss 2.251890 loss_att 5.292070 loss_ctc 3.050576 loss_rnnt 1.343811 hw_loss 0.362910 lr 0.00029624 rank 4
2023-03-01 01:49:15,868 DEBUG TRAIN Batch 46/4800 loss 5.275196 loss_att 8.842125 loss_ctc 12.033301 loss_rnnt 3.498791 hw_loss 0.303634 lr 0.00029624 rank 5
2023-03-01 01:49:15,872 DEBUG TRAIN Batch 46/4800 loss 3.825390 loss_att 6.610154 loss_ctc 9.285667 loss_rnnt 2.427865 hw_loss 0.211004 lr 0.00029625 rank 0
2023-03-01 01:49:15,872 DEBUG TRAIN Batch 46/4800 loss 5.493466 loss_att 8.063546 loss_ctc 7.062066 loss_rnnt 4.562130 hw_loss 0.390323 lr 0.00029624 rank 2
2023-03-01 01:49:15,873 DEBUG TRAIN Batch 46/4800 loss 5.333134 loss_att 8.025423 loss_ctc 7.483032 loss_rnnt 4.347998 hw_loss 0.300046 lr 0.00029624 rank 7
2023-03-01 01:49:15,875 DEBUG TRAIN Batch 46/4800 loss 8.578380 loss_att 11.555741 loss_ctc 16.840458 loss_rnnt 6.793305 hw_loss 0.164983 lr 0.00029624 rank 3
2023-03-01 01:49:15,920 DEBUG TRAIN Batch 46/4800 loss 5.578559 loss_att 10.020075 loss_ctc 9.218252 loss_rnnt 4.107567 hw_loss 0.182618 lr 0.00029624 rank 1
2023-03-01 01:49:54,918 DEBUG TRAIN Batch 46/4900 loss 2.833325 loss_att 5.519587 loss_ctc 5.408861 loss_rnnt 1.811700 hw_loss 0.264314 lr 0.00029623 rank 2
2023-03-01 01:49:54,923 DEBUG TRAIN Batch 46/4900 loss 3.396434 loss_att 5.790219 loss_ctc 8.998418 loss_rnnt 2.049233 hw_loss 0.227837 lr 0.00029623 rank 5
2023-03-01 01:49:54,927 DEBUG TRAIN Batch 46/4900 loss 5.187972 loss_att 8.903687 loss_ctc 12.001303 loss_rnnt 3.385499 hw_loss 0.282909 lr 0.00029623 rank 0
2023-03-01 01:49:54,929 DEBUG TRAIN Batch 46/4900 loss 2.772128 loss_att 4.216664 loss_ctc 6.024047 loss_rnnt 1.945156 hw_loss 0.195890 lr 0.00029622 rank 7
2023-03-01 01:49:54,937 DEBUG TRAIN Batch 46/4900 loss 5.981244 loss_att 8.142076 loss_ctc 10.424093 loss_rnnt 4.778676 hw_loss 0.333790 lr 0.00029623 rank 4
2023-03-01 01:49:54,970 DEBUG TRAIN Batch 46/4900 loss 5.612293 loss_att 10.324886 loss_ctc 14.491529 loss_rnnt 3.380366 hw_loss 0.197830 lr 0.00029623 rank 6
2023-03-01 01:49:54,979 DEBUG TRAIN Batch 46/4900 loss 2.885256 loss_att 5.780470 loss_ctc 4.509833 loss_rnnt 1.889791 hw_loss 0.374647 lr 0.00029623 rank 1
2023-03-01 01:49:54,983 DEBUG TRAIN Batch 46/4900 loss 6.187644 loss_att 8.470190 loss_ctc 8.240419 loss_rnnt 5.396115 hw_loss 0.114967 lr 0.00029623 rank 3
2023-03-01 01:50:59,967 DEBUG TRAIN Batch 46/5000 loss 9.364511 loss_att 12.281683 loss_ctc 13.272845 loss_rnnt 8.106159 hw_loss 0.288386 lr 0.00029621 rank 7
2023-03-01 01:50:59,978 DEBUG TRAIN Batch 46/5000 loss 10.629025 loss_att 13.920138 loss_ctc 24.660589 loss_rnnt 7.921226 hw_loss 0.335064 lr 0.00029622 rank 5
2023-03-01 01:50:59,980 DEBUG TRAIN Batch 46/5000 loss 10.486072 loss_att 11.873444 loss_ctc 14.703519 loss_rnnt 9.491899 hw_loss 0.289448 lr 0.00029621 rank 3
2023-03-01 01:50:59,981 DEBUG TRAIN Batch 46/5000 loss 3.341727 loss_att 5.735202 loss_ctc 6.108560 loss_rnnt 2.336724 hw_loss 0.295119 lr 0.00029622 rank 4
2023-03-01 01:50:59,982 DEBUG TRAIN Batch 46/5000 loss 6.634243 loss_att 7.334639 loss_ctc 7.966899 loss_rnnt 6.246664 hw_loss 0.130897 lr 0.00029622 rank 2
2023-03-01 01:50:59,984 DEBUG TRAIN Batch 46/5000 loss 10.689685 loss_att 13.735638 loss_ctc 13.794166 loss_rnnt 9.514552 hw_loss 0.285022 lr 0.00029622 rank 0
2023-03-01 01:51:00,004 DEBUG TRAIN Batch 46/5000 loss 11.571107 loss_att 16.673050 loss_ctc 18.619356 loss_rnnt 9.458745 hw_loss 0.285386 lr 0.00029621 rank 6
2023-03-01 01:51:00,006 DEBUG TRAIN Batch 46/5000 loss 11.709972 loss_att 14.511335 loss_ctc 19.637585 loss_rnnt 10.046144 hw_loss 0.087261 lr 0.00029622 rank 1
2023-03-01 01:51:40,330 DEBUG TRAIN Batch 46/5100 loss 3.099537 loss_att 6.939685 loss_ctc 5.211450 loss_rnnt 1.919757 hw_loss 0.244053 lr 0.00029621 rank 4
2023-03-01 01:51:40,332 DEBUG TRAIN Batch 46/5100 loss 9.589956 loss_att 13.700487 loss_ctc 14.135989 loss_rnnt 8.037938 hw_loss 0.232076 lr 0.00029620 rank 2
2023-03-01 01:51:40,348 DEBUG TRAIN Batch 46/5100 loss 6.319845 loss_att 8.857658 loss_ctc 10.299937 loss_rnnt 5.136232 hw_loss 0.272572 lr 0.00029621 rank 1
2023-03-01 01:51:40,352 DEBUG TRAIN Batch 46/5100 loss 14.356597 loss_att 23.424168 loss_ctc 32.688877 loss_rnnt 10.028506 hw_loss 0.131763 lr 0.00029621 rank 0
2023-03-01 01:51:40,352 DEBUG TRAIN Batch 46/5100 loss 4.818490 loss_att 7.739016 loss_ctc 5.153954 loss_rnnt 4.088021 hw_loss 0.190565 lr 0.00029620 rank 7
2023-03-01 01:51:40,355 DEBUG TRAIN Batch 46/5100 loss 2.804828 loss_att 5.603085 loss_ctc 4.563375 loss_rnnt 1.830730 hw_loss 0.337450 lr 0.00029620 rank 3
2023-03-01 01:51:40,357 DEBUG TRAIN Batch 46/5100 loss 5.304563 loss_att 7.447948 loss_ctc 9.224780 loss_rnnt 4.247536 hw_loss 0.198101 lr 0.00029620 rank 5
2023-03-01 01:51:40,363 DEBUG TRAIN Batch 46/5100 loss 9.849041 loss_att 12.186521 loss_ctc 13.974921 loss_rnnt 8.749340 hw_loss 0.153914 lr 0.00029620 rank 6
2023-03-01 01:52:19,337 DEBUG TRAIN Batch 46/5200 loss 9.288943 loss_att 13.232153 loss_ctc 11.981153 loss_rnnt 8.024418 hw_loss 0.219229 lr 0.00029619 rank 1
2023-03-01 01:52:19,342 DEBUG TRAIN Batch 46/5200 loss 3.854822 loss_att 7.047692 loss_ctc 5.050259 loss_rnnt 2.965204 hw_loss 0.171847 lr 0.00029619 rank 4
2023-03-01 01:52:19,344 DEBUG TRAIN Batch 46/5200 loss 8.562334 loss_att 14.800967 loss_ctc 16.477020 loss_rnnt 6.120818 hw_loss 0.259682 lr 0.00029619 rank 2
2023-03-01 01:52:19,354 DEBUG TRAIN Batch 46/5200 loss 6.201318 loss_att 9.742472 loss_ctc 16.814957 loss_rnnt 3.977439 hw_loss 0.188430 lr 0.00029618 rank 7
2023-03-01 01:52:19,354 DEBUG TRAIN Batch 46/5200 loss 3.487844 loss_att 5.826826 loss_ctc 4.587973 loss_rnnt 2.847530 hw_loss 0.048439 lr 0.00029619 rank 5
2023-03-01 01:52:19,355 DEBUG TRAIN Batch 46/5200 loss 2.215310 loss_att 4.546221 loss_ctc 2.421606 loss_rnnt 1.588692 hw_loss 0.249245 lr 0.00029619 rank 3
2023-03-01 01:52:19,358 DEBUG TRAIN Batch 46/5200 loss 5.889303 loss_att 9.269304 loss_ctc 7.826484 loss_rnnt 4.840233 hw_loss 0.215211 lr 0.00029619 rank 6
2023-03-01 01:52:19,358 DEBUG TRAIN Batch 46/5200 loss 4.250196 loss_att 5.780918 loss_ctc 7.435715 loss_rnnt 3.378791 hw_loss 0.263483 lr 0.00029619 rank 0
2023-03-01 01:52:59,126 DEBUG TRAIN Batch 46/5300 loss 6.646185 loss_att 8.936768 loss_ctc 11.355282 loss_rnnt 5.427211 hw_loss 0.249334 lr 0.00029618 rank 4
2023-03-01 01:52:59,129 DEBUG TRAIN Batch 46/5300 loss 3.259734 loss_att 5.035925 loss_ctc 4.768284 loss_rnnt 2.562235 hw_loss 0.264603 lr 0.00029617 rank 3
2023-03-01 01:52:59,131 DEBUG TRAIN Batch 46/5300 loss 4.139714 loss_att 6.943692 loss_ctc 6.540874 loss_rnnt 3.083422 hw_loss 0.328764 lr 0.00029618 rank 1
2023-03-01 01:52:59,144 DEBUG TRAIN Batch 46/5300 loss 11.555211 loss_att 17.779560 loss_ctc 20.410480 loss_rnnt 8.980515 hw_loss 0.279608 lr 0.00029617 rank 6
2023-03-01 01:52:59,144 DEBUG TRAIN Batch 46/5300 loss 12.522394 loss_att 14.762994 loss_ctc 19.582670 loss_rnnt 10.999557 hw_loss 0.250027 lr 0.00029618 rank 0
2023-03-01 01:52:59,147 DEBUG TRAIN Batch 46/5300 loss 2.834328 loss_att 4.236447 loss_ctc 4.353660 loss_rnnt 2.169655 hw_loss 0.340634 lr 0.00029617 rank 7
2023-03-01 01:52:59,147 DEBUG TRAIN Batch 46/5300 loss 7.093867 loss_att 8.171217 loss_ctc 9.777663 loss_rnnt 6.487072 hw_loss 0.062786 lr 0.00029618 rank 2
2023-03-01 01:52:59,170 DEBUG TRAIN Batch 46/5300 loss 2.854180 loss_att 7.210169 loss_ctc 4.445243 loss_rnnt 1.563755 hw_loss 0.388285 lr 0.00029618 rank 5
2023-03-01 01:54:04,660 DEBUG TRAIN Batch 46/5400 loss 5.292474 loss_att 8.375095 loss_ctc 9.804766 loss_rnnt 3.962214 hw_loss 0.210180 lr 0.00029617 rank 1
2023-03-01 01:54:04,664 DEBUG TRAIN Batch 46/5400 loss 8.820303 loss_att 11.450578 loss_ctc 16.274164 loss_rnnt 7.184572 hw_loss 0.217176 lr 0.00029616 rank 7
2023-03-01 01:54:04,681 DEBUG TRAIN Batch 46/5400 loss 8.171890 loss_att 10.364661 loss_ctc 9.457365 loss_rnnt 7.450031 hw_loss 0.209827 lr 0.00029617 rank 4
2023-03-01 01:54:04,682 DEBUG TRAIN Batch 46/5400 loss 14.893020 loss_att 22.361265 loss_ctc 27.347391 loss_rnnt 11.685894 hw_loss 0.099174 lr 0.00029616 rank 3
2023-03-01 01:54:04,684 DEBUG TRAIN Batch 46/5400 loss 5.347474 loss_att 10.108459 loss_ctc 11.779975 loss_rnnt 3.395787 hw_loss 0.265919 lr 0.00029617 rank 5
2023-03-01 01:54:04,687 DEBUG TRAIN Batch 46/5400 loss 5.958148 loss_att 7.924429 loss_ctc 9.729958 loss_rnnt 4.894951 hw_loss 0.313186 lr 0.00029617 rank 0
2023-03-01 01:54:04,689 DEBUG TRAIN Batch 46/5400 loss 9.385033 loss_att 10.923965 loss_ctc 13.879891 loss_rnnt 8.306952 hw_loss 0.320587 lr 0.00029617 rank 2
2023-03-01 01:54:04,731 DEBUG TRAIN Batch 46/5400 loss 3.374203 loss_att 6.897173 loss_ctc 3.863621 loss_rnnt 2.439707 hw_loss 0.308713 lr 0.00029616 rank 6
2023-03-01 01:54:43,812 DEBUG TRAIN Batch 46/5500 loss 16.036491 loss_att 20.172550 loss_ctc 27.149948 loss_rnnt 13.562162 hw_loss 0.309984 lr 0.00029615 rank 6
2023-03-01 01:54:43,820 DEBUG TRAIN Batch 46/5500 loss 5.781001 loss_att 8.798315 loss_ctc 10.124750 loss_rnnt 4.492432 hw_loss 0.198637 lr 0.00029615 rank 4
2023-03-01 01:54:43,823 DEBUG TRAIN Batch 46/5500 loss 5.354222 loss_att 8.459604 loss_ctc 8.004020 loss_rnnt 4.229645 hw_loss 0.281616 lr 0.00029616 rank 0
2023-03-01 01:54:43,826 DEBUG TRAIN Batch 46/5500 loss 7.557566 loss_att 9.569748 loss_ctc 13.870053 loss_rnnt 6.167368 hw_loss 0.273931 lr 0.00029615 rank 7
2023-03-01 01:54:43,826 DEBUG TRAIN Batch 46/5500 loss 7.608858 loss_att 11.900660 loss_ctc 13.916906 loss_rnnt 5.755373 hw_loss 0.288845 lr 0.00029615 rank 3
2023-03-01 01:54:43,828 DEBUG TRAIN Batch 46/5500 loss 5.992703 loss_att 9.427548 loss_ctc 12.229525 loss_rnnt 4.379123 hw_loss 0.178191 lr 0.00029615 rank 1
2023-03-01 01:54:43,835 DEBUG TRAIN Batch 46/5500 loss 10.665753 loss_att 17.085041 loss_ctc 15.600982 loss_rnnt 8.633064 hw_loss 0.170251 lr 0.00029615 rank 2
2023-03-01 01:54:43,878 DEBUG TRAIN Batch 46/5500 loss 5.397263 loss_att 7.678731 loss_ctc 10.278719 loss_rnnt 4.150626 hw_loss 0.261529 lr 0.00029615 rank 5
2023-03-01 01:55:23,401 DEBUG TRAIN Batch 46/5600 loss 5.338064 loss_att 8.103788 loss_ctc 10.127916 loss_rnnt 3.962521 hw_loss 0.344534 lr 0.00029614 rank 2
2023-03-01 01:55:23,406 DEBUG TRAIN Batch 46/5600 loss 3.569030 loss_att 5.427732 loss_ctc 6.184632 loss_rnnt 2.622734 hw_loss 0.423390 lr 0.00029614 rank 6
2023-03-01 01:55:23,406 DEBUG TRAIN Batch 46/5600 loss 13.735375 loss_att 14.948177 loss_ctc 19.602335 loss_rnnt 12.570221 hw_loss 0.263125 lr 0.00029614 rank 0
2023-03-01 01:55:23,410 DEBUG TRAIN Batch 46/5600 loss 6.167463 loss_att 7.808649 loss_ctc 10.217511 loss_rnnt 5.147949 hw_loss 0.283632 lr 0.00029614 rank 4
2023-03-01 01:55:23,411 DEBUG TRAIN Batch 46/5600 loss 4.878726 loss_att 6.454745 loss_ctc 8.783029 loss_rnnt 3.888515 hw_loss 0.289563 lr 0.00029613 rank 3
2023-03-01 01:55:23,414 DEBUG TRAIN Batch 46/5600 loss 7.765973 loss_att 14.144854 loss_ctc 18.322367 loss_rnnt 5.007801 hw_loss 0.140394 lr 0.00029613 rank 7
2023-03-01 01:55:23,420 DEBUG TRAIN Batch 46/5600 loss 5.782538 loss_att 11.008524 loss_ctc 9.310549 loss_rnnt 4.141002 hw_loss 0.236132 lr 0.00029614 rank 5
2023-03-01 01:55:23,452 DEBUG TRAIN Batch 46/5600 loss 5.158585 loss_att 10.102192 loss_ctc 9.892252 loss_rnnt 3.404787 hw_loss 0.251102 lr 0.00029614 rank 1
2023-03-01 01:56:27,600 DEBUG TRAIN Batch 46/5700 loss 3.562449 loss_att 4.077464 loss_ctc 4.763540 loss_rnnt 3.130595 hw_loss 0.316324 lr 0.00029613 rank 0
2023-03-01 01:56:27,602 DEBUG TRAIN Batch 46/5700 loss 4.679284 loss_att 6.350446 loss_ctc 5.357738 loss_rnnt 4.104800 hw_loss 0.280858 lr 0.00029613 rank 4
2023-03-01 01:56:27,605 DEBUG TRAIN Batch 46/5700 loss 5.743458 loss_att 7.774812 loss_ctc 8.897514 loss_rnnt 4.808060 hw_loss 0.203600 lr 0.00029613 rank 2
2023-03-01 01:56:27,605 DEBUG TRAIN Batch 46/5700 loss 4.686070 loss_att 7.429327 loss_ctc 9.044881 loss_rnnt 3.349928 hw_loss 0.386843 lr 0.00029613 rank 1
2023-03-01 01:56:27,606 DEBUG TRAIN Batch 46/5700 loss 10.123221 loss_att 13.156290 loss_ctc 13.932970 loss_rnnt 8.923055 hw_loss 0.160472 lr 0.00029612 rank 7
2023-03-01 01:56:27,608 DEBUG TRAIN Batch 46/5700 loss 3.663701 loss_att 4.814115 loss_ctc 5.447526 loss_rnnt 3.104596 hw_loss 0.170960 lr 0.00029613 rank 5
2023-03-01 01:56:27,611 DEBUG TRAIN Batch 46/5700 loss 3.354597 loss_att 6.634582 loss_ctc 7.186787 loss_rnnt 2.112224 hw_loss 0.141408 lr 0.00029612 rank 3
2023-03-01 01:56:27,665 DEBUG TRAIN Batch 46/5700 loss 6.005961 loss_att 8.586031 loss_ctc 9.590586 loss_rnnt 4.932825 hw_loss 0.148447 lr 0.00029612 rank 6
2023-03-01 01:57:09,180 DEBUG TRAIN Batch 46/5800 loss 6.306380 loss_att 8.531862 loss_ctc 8.885962 loss_rnnt 5.432149 hw_loss 0.159732 lr 0.00029611 rank 1
2023-03-01 01:57:09,182 DEBUG TRAIN Batch 46/5800 loss 6.972769 loss_att 8.210522 loss_ctc 10.813982 loss_rnnt 6.021122 hw_loss 0.359878 lr 0.00029611 rank 2
2023-03-01 01:57:09,183 DEBUG TRAIN Batch 46/5800 loss 8.109169 loss_att 10.776616 loss_ctc 9.144330 loss_rnnt 7.352760 hw_loss 0.159182 lr 0.00029611 rank 4
2023-03-01 01:57:09,182 DEBUG TRAIN Batch 46/5800 loss 3.865409 loss_att 5.893394 loss_ctc 5.931594 loss_rnnt 2.980000 hw_loss 0.383099 lr 0.00029611 rank 5
2023-03-01 01:57:09,182 DEBUG TRAIN Batch 46/5800 loss 8.779831 loss_att 12.584023 loss_ctc 15.341515 loss_rnnt 7.081047 hw_loss 0.118226 lr 0.00029612 rank 0
2023-03-01 01:57:09,184 DEBUG TRAIN Batch 46/5800 loss 3.590729 loss_att 5.794906 loss_ctc 6.273643 loss_rnnt 2.697981 hw_loss 0.176608 lr 0.00029611 rank 7
2023-03-01 01:57:09,190 DEBUG TRAIN Batch 46/5800 loss 6.485335 loss_att 10.323170 loss_ctc 13.283485 loss_rnnt 4.727985 hw_loss 0.156303 lr 0.00029611 rank 6
2023-03-01 01:57:09,235 DEBUG TRAIN Batch 46/5800 loss 9.171292 loss_att 10.802409 loss_ctc 17.149298 loss_rnnt 7.650830 hw_loss 0.244696 lr 0.00029611 rank 3
2023-03-01 01:57:47,896 DEBUG TRAIN Batch 46/5900 loss 5.678538 loss_att 7.667555 loss_ctc 6.681476 loss_rnnt 4.968965 hw_loss 0.333832 lr 0.00029609 rank 7
2023-03-01 01:57:47,900 DEBUG TRAIN Batch 46/5900 loss 3.435389 loss_att 6.435106 loss_ctc 6.975602 loss_rnnt 2.280356 hw_loss 0.155739 lr 0.00029610 rank 1
2023-03-01 01:57:47,900 DEBUG TRAIN Batch 46/5900 loss 7.282505 loss_att 11.029461 loss_ctc 9.022909 loss_rnnt 6.170563 hw_loss 0.244681 lr 0.00029610 rank 0
2023-03-01 01:57:47,902 DEBUG TRAIN Batch 46/5900 loss 4.248365 loss_att 6.656101 loss_ctc 6.910990 loss_rnnt 3.334024 hw_loss 0.145832 lr 0.00029610 rank 5
2023-03-01 01:57:47,903 DEBUG TRAIN Batch 46/5900 loss 6.368066 loss_att 10.255325 loss_ctc 9.058218 loss_rnnt 5.124854 hw_loss 0.200764 lr 0.00029610 rank 2
2023-03-01 01:57:47,907 DEBUG TRAIN Batch 46/5900 loss 6.687231 loss_att 10.116206 loss_ctc 10.077057 loss_rnnt 5.459480 hw_loss 0.168710 lr 0.00029610 rank 6
2023-03-01 01:57:47,911 DEBUG TRAIN Batch 46/5900 loss 3.844673 loss_att 6.835638 loss_ctc 10.265301 loss_rnnt 2.265241 hw_loss 0.234664 lr 0.00029610 rank 4
2023-03-01 01:57:47,955 DEBUG TRAIN Batch 46/5900 loss 2.137550 loss_att 4.920206 loss_ctc 3.158613 loss_rnnt 1.331845 hw_loss 0.211935 lr 0.00029610 rank 3
2023-03-01 01:58:27,394 DEBUG TRAIN Batch 46/6000 loss 10.677700 loss_att 14.987492 loss_ctc 13.977665 loss_rnnt 9.268167 hw_loss 0.201712 lr 0.00029609 rank 0
2023-03-01 01:58:27,396 DEBUG TRAIN Batch 46/6000 loss 7.240145 loss_att 10.842083 loss_ctc 12.105286 loss_rnnt 5.793987 hw_loss 0.144535 lr 0.00029608 rank 6
2023-03-01 01:58:27,396 DEBUG TRAIN Batch 46/6000 loss 4.045052 loss_att 9.088625 loss_ctc 8.383716 loss_rnnt 2.343174 hw_loss 0.215013 lr 0.00029609 rank 2
2023-03-01 01:58:27,407 DEBUG TRAIN Batch 46/6000 loss 6.614356 loss_att 9.008968 loss_ctc 10.841110 loss_rnnt 5.470370 hw_loss 0.190305 lr 0.00029609 rank 1
2023-03-01 01:58:27,408 DEBUG TRAIN Batch 46/6000 loss 10.084892 loss_att 12.335236 loss_ctc 14.201572 loss_rnnt 8.985273 hw_loss 0.188738 lr 0.00029609 rank 4
2023-03-01 01:58:27,410 DEBUG TRAIN Batch 46/6000 loss 8.187873 loss_att 11.817368 loss_ctc 14.405242 loss_rnnt 6.435597 hw_loss 0.370113 lr 0.00029608 rank 7
2023-03-01 01:58:27,424 DEBUG TRAIN Batch 46/6000 loss 8.529379 loss_att 11.294352 loss_ctc 16.250160 loss_rnnt 6.824008 hw_loss 0.230510 lr 0.00029608 rank 3
2023-03-01 01:58:27,432 DEBUG TRAIN Batch 46/6000 loss 8.593940 loss_att 12.756686 loss_ctc 15.733780 loss_rnnt 6.701870 hw_loss 0.201639 lr 0.00029609 rank 5
2023-03-01 01:59:31,705 DEBUG TRAIN Batch 46/6100 loss 4.995575 loss_att 7.775112 loss_ctc 11.640920 loss_rnnt 3.397483 hw_loss 0.292759 lr 0.00029608 rank 4
2023-03-01 01:59:31,710 DEBUG TRAIN Batch 46/6100 loss 7.250968 loss_att 12.661483 loss_ctc 14.880287 loss_rnnt 5.121337 hw_loss 0.056784 lr 0.00029608 rank 0
2023-03-01 01:59:31,712 DEBUG TRAIN Batch 46/6100 loss 2.661161 loss_att 5.178188 loss_ctc 5.911459 loss_rnnt 1.672437 hw_loss 0.097399 lr 0.00029607 rank 6
2023-03-01 01:59:31,723 DEBUG TRAIN Batch 46/6100 loss 8.028072 loss_att 11.994761 loss_ctc 14.189208 loss_rnnt 6.357309 hw_loss 0.104889 lr 0.00029608 rank 1
2023-03-01 01:59:31,723 DEBUG TRAIN Batch 46/6100 loss 5.586986 loss_att 9.121682 loss_ctc 8.990599 loss_rnnt 4.299177 hw_loss 0.238228 lr 0.00029607 rank 2
2023-03-01 01:59:31,725 DEBUG TRAIN Batch 46/6100 loss 9.963279 loss_att 10.845096 loss_ctc 13.813733 loss_rnnt 9.173714 hw_loss 0.187139 lr 0.00029607 rank 7
2023-03-01 01:59:31,724 DEBUG TRAIN Batch 46/6100 loss 3.393328 loss_att 7.677894 loss_ctc 6.313145 loss_rnnt 2.036444 hw_loss 0.207491 lr 0.00029607 rank 5
2023-03-01 01:59:31,726 DEBUG TRAIN Batch 46/6100 loss 9.107774 loss_att 10.093730 loss_ctc 14.895802 loss_rnnt 7.965734 hw_loss 0.324584 lr 0.00029607 rank 3
2023-03-01 02:00:10,466 DEBUG TRAIN Batch 46/6200 loss 8.186464 loss_att 12.612077 loss_ctc 15.754864 loss_rnnt 6.166542 hw_loss 0.235651 lr 0.00029606 rank 4
2023-03-01 02:00:10,475 DEBUG TRAIN Batch 46/6200 loss 6.587265 loss_att 8.183066 loss_ctc 12.634484 loss_rnnt 5.343900 hw_loss 0.221077 lr 0.00029606 rank 0
2023-03-01 02:00:10,476 DEBUG TRAIN Batch 46/6200 loss 2.710597 loss_att 5.461839 loss_ctc 4.655838 loss_rnnt 1.809984 hw_loss 0.170622 lr 0.00029606 rank 6
2023-03-01 02:00:10,476 DEBUG TRAIN Batch 46/6200 loss 6.738832 loss_att 6.929337 loss_ctc 10.644386 loss_rnnt 6.006021 hw_loss 0.326191 lr 0.00029605 rank 7
2023-03-01 02:00:10,476 DEBUG TRAIN Batch 46/6200 loss 6.443788 loss_att 10.958142 loss_ctc 11.125561 loss_rnnt 4.856990 hw_loss 0.111919 lr 0.00029606 rank 1
2023-03-01 02:00:10,479 DEBUG TRAIN Batch 46/6200 loss 4.964097 loss_att 8.217051 loss_ctc 9.616215 loss_rnnt 3.529052 hw_loss 0.307822 lr 0.00029606 rank 3
2023-03-01 02:00:10,485 DEBUG TRAIN Batch 46/6200 loss 15.285790 loss_att 16.141321 loss_ctc 21.511187 loss_rnnt 14.150738 hw_loss 0.251052 lr 0.00029606 rank 2
2023-03-01 02:00:10,538 DEBUG TRAIN Batch 46/6200 loss 8.943737 loss_att 10.503044 loss_ctc 13.927051 loss_rnnt 7.783270 hw_loss 0.345306 lr 0.00029606 rank 5
2023-03-01 02:00:49,697 DEBUG TRAIN Batch 46/6300 loss 9.876062 loss_att 11.137720 loss_ctc 13.276169 loss_rnnt 9.094641 hw_loss 0.142017 lr 0.00029604 rank 7
2023-03-01 02:00:49,699 DEBUG TRAIN Batch 46/6300 loss 4.443937 loss_att 8.686377 loss_ctc 10.699128 loss_rnnt 2.703847 hw_loss 0.107956 lr 0.00029605 rank 6
2023-03-01 02:00:49,711 DEBUG TRAIN Batch 46/6300 loss 10.399885 loss_att 12.075781 loss_ctc 17.351820 loss_rnnt 9.040593 hw_loss 0.182227 lr 0.00029605 rank 4
2023-03-01 02:00:49,711 DEBUG TRAIN Batch 46/6300 loss 10.921292 loss_att 11.415535 loss_ctc 14.553192 loss_rnnt 10.113247 hw_loss 0.421770 lr 0.00029605 rank 0
2023-03-01 02:00:49,713 DEBUG TRAIN Batch 46/6300 loss 5.284359 loss_att 5.996712 loss_ctc 8.944574 loss_rnnt 4.486783 hw_loss 0.313267 lr 0.00029604 rank 3
2023-03-01 02:00:49,717 DEBUG TRAIN Batch 46/6300 loss 1.965115 loss_att 4.263551 loss_ctc 3.641354 loss_rnnt 1.172155 hw_loss 0.205827 lr 0.00029605 rank 1
2023-03-01 02:00:49,731 DEBUG TRAIN Batch 46/6300 loss 6.352235 loss_att 10.265958 loss_ctc 11.983793 loss_rnnt 4.718694 hw_loss 0.187353 lr 0.00029605 rank 2
2023-03-01 02:00:49,764 DEBUG TRAIN Batch 46/6300 loss 5.416514 loss_att 9.386146 loss_ctc 11.502184 loss_rnnt 3.670954 hw_loss 0.262894 lr 0.00029605 rank 5
2023-03-01 02:01:54,539 DEBUG TRAIN Batch 46/6400 loss 7.696260 loss_att 10.165474 loss_ctc 15.365335 loss_rnnt 6.033907 hw_loss 0.273687 lr 0.00029603 rank 7
2023-03-01 02:01:54,542 DEBUG TRAIN Batch 46/6400 loss 8.876650 loss_att 10.879128 loss_ctc 15.233391 loss_rnnt 7.414451 hw_loss 0.401509 lr 0.00029604 rank 1
2023-03-01 02:01:54,542 DEBUG TRAIN Batch 46/6400 loss 2.296441 loss_att 5.159500 loss_ctc 3.991759 loss_rnnt 1.345618 hw_loss 0.285315 lr 0.00029604 rank 0
2023-03-01 02:01:54,544 DEBUG TRAIN Batch 46/6400 loss 5.528440 loss_att 7.831626 loss_ctc 9.824980 loss_rnnt 4.304014 hw_loss 0.357969 lr 0.00029603 rank 6
2023-03-01 02:01:54,547 DEBUG TRAIN Batch 46/6400 loss 3.783077 loss_att 9.756857 loss_ctc 10.352572 loss_rnnt 1.517376 hw_loss 0.365648 lr 0.00029603 rank 3
2023-03-01 02:01:54,558 DEBUG TRAIN Batch 46/6400 loss 6.247245 loss_att 7.458871 loss_ctc 10.276169 loss_rnnt 5.235413 hw_loss 0.435594 lr 0.00029604 rank 5
2023-03-01 02:01:54,566 DEBUG TRAIN Batch 46/6400 loss 4.781061 loss_att 9.986053 loss_ctc 5.299161 loss_rnnt 3.500321 hw_loss 0.319991 lr 0.00029604 rank 4
2023-03-01 02:01:54,593 DEBUG TRAIN Batch 46/6400 loss 4.916332 loss_att 7.368809 loss_ctc 9.175777 loss_rnnt 3.699415 hw_loss 0.297178 lr 0.00029604 rank 2
2023-03-01 02:02:33,962 DEBUG TRAIN Batch 46/6500 loss 5.386663 loss_att 6.913210 loss_ctc 9.589452 loss_rnnt 4.304826 hw_loss 0.405293 lr 0.00029602 rank 1
2023-03-01 02:02:33,961 DEBUG TRAIN Batch 46/6500 loss 6.331788 loss_att 8.467543 loss_ctc 9.748912 loss_rnnt 5.273046 hw_loss 0.329952 lr 0.00029602 rank 4
2023-03-01 02:02:33,962 DEBUG TRAIN Batch 46/6500 loss 2.829268 loss_att 6.261877 loss_ctc 4.080827 loss_rnnt 1.903351 hw_loss 0.135975 lr 0.00029602 rank 2
2023-03-01 02:02:33,964 DEBUG TRAIN Batch 46/6500 loss 6.587804 loss_att 10.534254 loss_ctc 13.665421 loss_rnnt 4.766341 hw_loss 0.165919 lr 0.00029602 rank 6
2023-03-01 02:02:33,984 DEBUG TRAIN Batch 46/6500 loss 7.913382 loss_att 11.213719 loss_ctc 16.419432 loss_rnnt 5.969200 hw_loss 0.281202 lr 0.00029602 rank 7
2023-03-01 02:02:33,985 DEBUG TRAIN Batch 46/6500 loss 8.031075 loss_att 11.983568 loss_ctc 15.718224 loss_rnnt 6.099470 hw_loss 0.217786 lr 0.00029603 rank 0
2023-03-01 02:02:33,991 DEBUG TRAIN Batch 46/6500 loss 3.114569 loss_att 5.973299 loss_ctc 7.206285 loss_rnnt 1.885550 hw_loss 0.209457 lr 0.00029602 rank 5
2023-03-01 02:02:34,036 DEBUG TRAIN Batch 46/6500 loss 4.514032 loss_att 6.739009 loss_ctc 8.814545 loss_rnnt 3.386081 hw_loss 0.205414 lr 0.00029602 rank 3
2023-03-01 02:03:13,126 DEBUG TRAIN Batch 46/6600 loss 6.946912 loss_att 9.436472 loss_ctc 11.403973 loss_rnnt 5.796477 hw_loss 0.109216 lr 0.00029601 rank 0
2023-03-01 02:03:13,126 DEBUG TRAIN Batch 46/6600 loss 9.000764 loss_att 11.820377 loss_ctc 17.786024 loss_rnnt 7.140755 hw_loss 0.233846 lr 0.00029600 rank 7
2023-03-01 02:03:13,130 DEBUG TRAIN Batch 46/6600 loss 4.866447 loss_att 6.059461 loss_ctc 8.153513 loss_rnnt 4.067551 hw_loss 0.228786 lr 0.00029601 rank 1
2023-03-01 02:03:13,130 DEBUG TRAIN Batch 46/6600 loss 20.575998 loss_att 21.039679 loss_ctc 27.543442 loss_rnnt 19.339680 hw_loss 0.402355 lr 0.00029601 rank 6
2023-03-01 02:03:13,136 DEBUG TRAIN Batch 46/6600 loss 3.908745 loss_att 7.457857 loss_ctc 6.950656 loss_rnnt 2.656353 hw_loss 0.256840 lr 0.00029601 rank 2
2023-03-01 02:03:13,137 DEBUG TRAIN Batch 46/6600 loss 5.181935 loss_att 7.611378 loss_ctc 6.158161 loss_rnnt 4.442084 hw_loss 0.232123 lr 0.00029601 rank 4
2023-03-01 02:03:13,140 DEBUG TRAIN Batch 46/6600 loss 6.910280 loss_att 9.753796 loss_ctc 10.496920 loss_rnnt 5.706923 hw_loss 0.293316 lr 0.00029601 rank 3
2023-03-01 02:03:13,141 DEBUG TRAIN Batch 46/6600 loss 8.654523 loss_att 11.928883 loss_ctc 12.619929 loss_rnnt 7.341099 hw_loss 0.243431 lr 0.00029601 rank 5
2023-03-01 02:03:52,936 DEBUG TRAIN Batch 46/6700 loss 6.189228 loss_att 9.521835 loss_ctc 11.409189 loss_rnnt 4.713366 hw_loss 0.212523 lr 0.00029600 rank 4
2023-03-01 02:03:52,936 DEBUG TRAIN Batch 46/6700 loss 5.121145 loss_att 6.466771 loss_ctc 7.272517 loss_rnnt 4.428900 hw_loss 0.255507 lr 0.00029600 rank 1
2023-03-01 02:03:52,943 DEBUG TRAIN Batch 46/6700 loss 10.241839 loss_att 13.045477 loss_ctc 19.181217 loss_rnnt 8.298168 hw_loss 0.358177 lr 0.00029600 rank 0
2023-03-01 02:03:52,946 DEBUG TRAIN Batch 46/6700 loss 5.872282 loss_att 9.282020 loss_ctc 9.737183 loss_rnnt 4.568114 hw_loss 0.200439 lr 0.00029599 rank 3
2023-03-01 02:03:52,946 DEBUG TRAIN Batch 46/6700 loss 5.193625 loss_att 8.719826 loss_ctc 10.903872 loss_rnnt 3.640083 hw_loss 0.163003 lr 0.00029599 rank 7
2023-03-01 02:03:52,949 DEBUG TRAIN Batch 46/6700 loss 7.938394 loss_att 10.556038 loss_ctc 11.796022 loss_rnnt 6.776255 hw_loss 0.232989 lr 0.00029600 rank 2
2023-03-01 02:03:52,994 DEBUG TRAIN Batch 46/6700 loss 3.085528 loss_att 4.621233 loss_ctc 4.887973 loss_rnnt 2.416745 hw_loss 0.227467 lr 0.00029599 rank 6
2023-03-01 02:03:53,000 DEBUG TRAIN Batch 46/6700 loss 8.682412 loss_att 10.526410 loss_ctc 12.360846 loss_rnnt 7.747710 hw_loss 0.141459 lr 0.00029600 rank 5
2023-03-01 02:04:57,489 DEBUG TRAIN Batch 46/6800 loss 6.439824 loss_att 8.907290 loss_ctc 12.151154 loss_rnnt 4.989891 hw_loss 0.365492 lr 0.00029598 rank 1
2023-03-01 02:04:57,496 DEBUG TRAIN Batch 46/6800 loss 7.889201 loss_att 10.962626 loss_ctc 12.772887 loss_rnnt 6.468313 hw_loss 0.290709 lr 0.00029598 rank 7
2023-03-01 02:04:57,497 DEBUG TRAIN Batch 46/6800 loss 3.183429 loss_att 5.676546 loss_ctc 5.222103 loss_rnnt 2.236035 hw_loss 0.331777 lr 0.00029598 rank 6
2023-03-01 02:04:57,497 DEBUG TRAIN Batch 46/6800 loss 6.914391 loss_att 10.665792 loss_ctc 8.994910 loss_rnnt 5.774720 hw_loss 0.209978 lr 0.00029598 rank 2
2023-03-01 02:04:57,498 DEBUG TRAIN Batch 46/6800 loss 3.766268 loss_att 6.154050 loss_ctc 6.409408 loss_rnnt 2.809906 hw_loss 0.236975 lr 0.00029598 rank 4
2023-03-01 02:04:57,501 DEBUG TRAIN Batch 46/6800 loss 7.795491 loss_att 10.117846 loss_ctc 11.370308 loss_rnnt 6.726177 hw_loss 0.240377 lr 0.00029599 rank 0
2023-03-01 02:04:57,500 DEBUG TRAIN Batch 46/6800 loss 2.432605 loss_att 5.168721 loss_ctc 6.200886 loss_rnnt 1.233696 hw_loss 0.279840 lr 0.00029598 rank 5
2023-03-01 02:04:57,505 DEBUG TRAIN Batch 46/6800 loss 7.593314 loss_att 10.954717 loss_ctc 14.439098 loss_rnnt 5.839050 hw_loss 0.317272 lr 0.00029598 rank 3
2023-03-01 02:05:37,127 DEBUG TRAIN Batch 46/6900 loss 6.525242 loss_att 7.775510 loss_ctc 9.450718 loss_rnnt 5.782215 hw_loss 0.192959 lr 0.00029597 rank 0
2023-03-01 02:05:37,134 DEBUG TRAIN Batch 46/6900 loss 10.293591 loss_att 10.803896 loss_ctc 14.872100 loss_rnnt 9.447761 hw_loss 0.249939 lr 0.00029597 rank 4
2023-03-01 02:05:37,134 DEBUG TRAIN Batch 46/6900 loss 6.050770 loss_att 7.481547 loss_ctc 8.111316 loss_rnnt 5.378967 hw_loss 0.207953 lr 0.00029597 rank 6
2023-03-01 02:05:37,137 DEBUG TRAIN Batch 46/6900 loss 6.890611 loss_att 8.841131 loss_ctc 10.085033 loss_rnnt 6.062839 hw_loss 0.022021 lr 0.00029597 rank 2
2023-03-01 02:05:37,139 DEBUG TRAIN Batch 46/6900 loss 1.509119 loss_att 5.006351 loss_ctc 4.271477 loss_rnnt 0.312323 hw_loss 0.241942 lr 0.00029596 rank 7
2023-03-01 02:05:37,140 DEBUG TRAIN Batch 46/6900 loss 6.491707 loss_att 6.786593 loss_ctc 11.068118 loss_rnnt 5.678178 hw_loss 0.270680 lr 0.00029597 rank 3
2023-03-01 02:05:37,165 DEBUG TRAIN Batch 46/6900 loss 3.006523 loss_att 6.478685 loss_ctc 5.278673 loss_rnnt 1.873401 hw_loss 0.254505 lr 0.00029597 rank 1
2023-03-01 02:05:37,178 DEBUG TRAIN Batch 46/6900 loss 5.149828 loss_att 9.805626 loss_ctc 9.772476 loss_rnnt 3.470094 hw_loss 0.247914 lr 0.00029597 rank 5
2023-03-01 02:06:16,321 DEBUG TRAIN Batch 46/7000 loss 10.931802 loss_att 11.732941 loss_ctc 15.280217 loss_rnnt 9.997905 hw_loss 0.363526 lr 0.00029596 rank 1
2023-03-01 02:06:16,322 DEBUG TRAIN Batch 46/7000 loss 9.437170 loss_att 10.369226 loss_ctc 10.074173 loss_rnnt 9.051204 hw_loss 0.214916 lr 0.00029596 rank 2
2023-03-01 02:06:16,332 DEBUG TRAIN Batch 46/7000 loss 3.820853 loss_att 4.957237 loss_ctc 6.934348 loss_rnnt 2.987724 hw_loss 0.357599 lr 0.00029596 rank 5
2023-03-01 02:06:16,333 DEBUG TRAIN Batch 46/7000 loss 4.140688 loss_att 7.838744 loss_ctc 6.338399 loss_rnnt 2.937768 hw_loss 0.319277 lr 0.00029595 rank 7
2023-03-01 02:06:16,334 DEBUG TRAIN Batch 46/7000 loss 7.238413 loss_att 10.255343 loss_ctc 9.653393 loss_rnnt 6.203953 hw_loss 0.204521 lr 0.00029595 rank 6
2023-03-01 02:06:16,338 DEBUG TRAIN Batch 46/7000 loss 1.083495 loss_att 3.948046 loss_ctc 1.982705 loss_rnnt 0.362957 hw_loss 0.051999 lr 0.00029596 rank 0
2023-03-01 02:06:16,340 DEBUG TRAIN Batch 46/7000 loss 5.786522 loss_att 11.457159 loss_ctc 14.180071 loss_rnnt 3.410539 hw_loss 0.230092 lr 0.00029595 rank 3
2023-03-01 02:06:16,343 DEBUG TRAIN Batch 46/7000 loss 5.872999 loss_att 7.070684 loss_ctc 8.926715 loss_rnnt 5.023852 hw_loss 0.379590 lr 0.00029596 rank 4
2023-03-01 02:07:21,057 DEBUG TRAIN Batch 46/7100 loss 8.949861 loss_att 11.349483 loss_ctc 11.995173 loss_rnnt 7.979809 hw_loss 0.157659 lr 0.00029594 rank 3
2023-03-01 02:07:21,059 DEBUG TRAIN Batch 46/7100 loss 2.666093 loss_att 5.016100 loss_ctc 5.369611 loss_rnnt 1.696626 hw_loss 0.260619 lr 0.00029595 rank 2
2023-03-01 02:07:21,062 DEBUG TRAIN Batch 46/7100 loss 5.871911 loss_att 8.368721 loss_ctc 10.620590 loss_rnnt 4.641120 hw_loss 0.184259 lr 0.00029594 rank 7
2023-03-01 02:07:21,062 DEBUG TRAIN Batch 46/7100 loss 3.390146 loss_att 6.818187 loss_ctc 6.044531 loss_rnnt 2.151470 hw_loss 0.373406 lr 0.00029595 rank 0
2023-03-01 02:07:21,063 DEBUG TRAIN Batch 46/7100 loss 2.301743 loss_att 5.985945 loss_ctc 5.943738 loss_rnnt 0.956232 hw_loss 0.230759 lr 0.00029595 rank 1
2023-03-01 02:07:21,067 DEBUG TRAIN Batch 46/7100 loss 3.911568 loss_att 4.969002 loss_ctc 4.956190 loss_rnnt 3.428695 hw_loss 0.247695 lr 0.00029595 rank 5
2023-03-01 02:07:21,072 DEBUG TRAIN Batch 46/7100 loss 6.279218 loss_att 10.696212 loss_ctc 12.660365 loss_rnnt 4.434505 hw_loss 0.207176 lr 0.00029595 rank 4
2023-03-01 02:07:21,115 DEBUG TRAIN Batch 46/7100 loss 10.650579 loss_att 14.943466 loss_ctc 14.017002 loss_rnnt 9.281155 hw_loss 0.116233 lr 0.00029594 rank 6
2023-03-01 02:08:03,248 DEBUG TRAIN Batch 46/7200 loss 6.782198 loss_att 12.716420 loss_ctc 14.237724 loss_rnnt 4.529317 hw_loss 0.134936 lr 0.00029593 rank 5
2023-03-01 02:08:03,260 DEBUG TRAIN Batch 46/7200 loss 3.760282 loss_att 6.357969 loss_ctc 4.976883 loss_rnnt 2.925354 hw_loss 0.287207 lr 0.00029592 rank 7
2023-03-01 02:08:03,260 DEBUG TRAIN Batch 46/7200 loss 7.045945 loss_att 9.381822 loss_ctc 15.970509 loss_rnnt 5.214524 hw_loss 0.326820 lr 0.00029593 rank 2
2023-03-01 02:08:03,264 DEBUG TRAIN Batch 46/7200 loss 3.790105 loss_att 6.398634 loss_ctc 5.743301 loss_rnnt 2.892995 hw_loss 0.215582 lr 0.00029593 rank 1
2023-03-01 02:08:03,272 DEBUG TRAIN Batch 46/7200 loss 9.085823 loss_att 10.398761 loss_ctc 10.266160 loss_rnnt 8.506478 hw_loss 0.298834 lr 0.00029593 rank 0
2023-03-01 02:08:03,285 DEBUG TRAIN Batch 46/7200 loss 4.163655 loss_att 7.166214 loss_ctc 6.285644 loss_rnnt 3.007144 hw_loss 0.512001 lr 0.00029593 rank 4
2023-03-01 02:08:03,296 DEBUG TRAIN Batch 46/7200 loss 7.732525 loss_att 11.810518 loss_ctc 15.713786 loss_rnnt 5.749918 hw_loss 0.192826 lr 0.00029593 rank 3
2023-03-01 02:08:03,305 DEBUG TRAIN Batch 46/7200 loss 6.195807 loss_att 7.652018 loss_ctc 9.454503 loss_rnnt 5.413742 hw_loss 0.105618 lr 0.00029593 rank 6
2023-03-01 02:08:42,576 DEBUG TRAIN Batch 46/7300 loss 10.555017 loss_att 11.292828 loss_ctc 15.264911 loss_rnnt 9.617831 hw_loss 0.303074 lr 0.00029592 rank 0
2023-03-01 02:08:42,577 DEBUG TRAIN Batch 46/7300 loss 5.313391 loss_att 6.259712 loss_ctc 7.900019 loss_rnnt 4.623182 hw_loss 0.292614 lr 0.00029591 rank 7
2023-03-01 02:08:42,584 DEBUG TRAIN Batch 46/7300 loss 5.098982 loss_att 6.694963 loss_ctc 8.519761 loss_rnnt 4.323209 hw_loss 0.000887 lr 0.00029592 rank 5
2023-03-01 02:08:42,583 DEBUG TRAIN Batch 46/7300 loss 4.429365 loss_att 8.315134 loss_ctc 6.619934 loss_rnnt 3.223349 hw_loss 0.256475 lr 0.00029592 rank 1
2023-03-01 02:08:42,585 DEBUG TRAIN Batch 46/7300 loss 7.721560 loss_att 10.574511 loss_ctc 16.085098 loss_rnnt 5.912801 hw_loss 0.230680 lr 0.00029592 rank 6
2023-03-01 02:08:42,602 DEBUG TRAIN Batch 46/7300 loss 3.656225 loss_att 6.199560 loss_ctc 6.781130 loss_rnnt 2.597651 hw_loss 0.249851 lr 0.00029592 rank 4
2023-03-01 02:08:42,606 DEBUG TRAIN Batch 46/7300 loss 12.026395 loss_att 17.403454 loss_ctc 19.033718 loss_rnnt 9.830727 hw_loss 0.348648 lr 0.00029592 rank 2
2023-03-01 02:08:42,636 DEBUG TRAIN Batch 46/7300 loss 7.891564 loss_att 11.338377 loss_ctc 13.024531 loss_rnnt 6.350607 hw_loss 0.313497 lr 0.00029591 rank 3
2023-03-01 02:09:21,792 DEBUG TRAIN Batch 46/7400 loss 11.606256 loss_att 12.308838 loss_ctc 16.503616 loss_rnnt 10.660206 hw_loss 0.286033 lr 0.00029591 rank 5
2023-03-01 02:09:21,809 DEBUG TRAIN Batch 46/7400 loss 5.248937 loss_att 8.299143 loss_ctc 10.238446 loss_rnnt 3.829489 hw_loss 0.270260 lr 0.00029591 rank 0
2023-03-01 02:09:21,810 DEBUG TRAIN Batch 46/7400 loss 10.389825 loss_att 13.929876 loss_ctc 17.316191 loss_rnnt 8.615752 hw_loss 0.267278 lr 0.00029591 rank 4
2023-03-01 02:09:21,810 DEBUG TRAIN Batch 46/7400 loss 4.254767 loss_att 7.094687 loss_ctc 7.285917 loss_rnnt 3.185140 hw_loss 0.182793 lr 0.00029591 rank 2
2023-03-01 02:09:21,813 DEBUG TRAIN Batch 46/7400 loss 5.330684 loss_att 7.482383 loss_ctc 10.696125 loss_rnnt 4.042986 hw_loss 0.266186 lr 0.00029590 rank 7
2023-03-01 02:09:21,846 DEBUG TRAIN Batch 46/7400 loss 12.006455 loss_att 14.215714 loss_ctc 16.871204 loss_rnnt 10.834149 hw_loss 0.153415 lr 0.00029591 rank 1
2023-03-01 02:09:21,860 DEBUG TRAIN Batch 46/7400 loss 6.530471 loss_att 10.645826 loss_ctc 11.201465 loss_rnnt 4.961164 hw_loss 0.231444 lr 0.00029590 rank 3
2023-03-01 02:09:21,861 DEBUG TRAIN Batch 46/7400 loss 10.983008 loss_att 15.404907 loss_ctc 21.470219 loss_rnnt 8.583147 hw_loss 0.219725 lr 0.00029590 rank 6
2023-03-01 02:10:26,056 DEBUG TRAIN Batch 46/7500 loss 5.323068 loss_att 7.881853 loss_ctc 9.178793 loss_rnnt 4.243096 hw_loss 0.101471 lr 0.00029589 rank 6
2023-03-01 02:10:26,067 DEBUG TRAIN Batch 46/7500 loss 5.677999 loss_att 11.059610 loss_ctc 11.376781 loss_rnnt 3.732968 hw_loss 0.204131 lr 0.00029589 rank 7
2023-03-01 02:10:26,070 DEBUG TRAIN Batch 46/7500 loss 5.322184 loss_att 6.732746 loss_ctc 8.198702 loss_rnnt 4.542280 hw_loss 0.214229 lr 0.00029590 rank 0
2023-03-01 02:10:26,073 DEBUG TRAIN Batch 46/7500 loss 3.383255 loss_att 6.798895 loss_ctc 6.337758 loss_rnnt 2.190458 hw_loss 0.217004 lr 0.00029589 rank 4
2023-03-01 02:10:26,073 DEBUG TRAIN Batch 46/7500 loss 2.673640 loss_att 4.469882 loss_ctc 3.336072 loss_rnnt 2.081680 hw_loss 0.270727 lr 0.00029589 rank 5
2023-03-01 02:10:26,073 DEBUG TRAIN Batch 46/7500 loss 8.591399 loss_att 13.046667 loss_ctc 12.583886 loss_rnnt 7.116759 hw_loss 0.096105 lr 0.00029589 rank 1
2023-03-01 02:10:26,079 DEBUG TRAIN Batch 46/7500 loss 5.195835 loss_att 6.018647 loss_ctc 8.330510 loss_rnnt 4.446833 hw_loss 0.312153 lr 0.00029589 rank 3
2023-03-01 02:10:26,080 DEBUG TRAIN Batch 46/7500 loss 1.562647 loss_att 3.155547 loss_ctc 2.500604 loss_rnnt 1.020511 hw_loss 0.184677 lr 0.00029589 rank 2
2023-03-01 02:11:05,243 DEBUG TRAIN Batch 46/7600 loss 1.867496 loss_att 5.141383 loss_ctc 5.104636 loss_rnnt 0.668525 hw_loss 0.211078 lr 0.00029588 rank 0
2023-03-01 02:11:05,261 DEBUG TRAIN Batch 46/7600 loss 7.982881 loss_att 9.939984 loss_ctc 13.481066 loss_rnnt 6.728975 hw_loss 0.242611 lr 0.00029588 rank 6
2023-03-01 02:11:05,270 DEBUG TRAIN Batch 46/7600 loss 8.694724 loss_att 12.238263 loss_ctc 15.887127 loss_rnnt 6.857387 hw_loss 0.318082 lr 0.00029587 rank 7
2023-03-01 02:11:05,273 DEBUG TRAIN Batch 46/7600 loss 6.101884 loss_att 6.873833 loss_ctc 9.163024 loss_rnnt 5.381976 hw_loss 0.295064 lr 0.00029588 rank 2
2023-03-01 02:11:05,277 DEBUG TRAIN Batch 46/7600 loss 12.833344 loss_att 14.168175 loss_ctc 18.292358 loss_rnnt 11.673734 hw_loss 0.308954 lr 0.00029588 rank 5
2023-03-01 02:11:05,279 DEBUG TRAIN Batch 46/7600 loss 7.612144 loss_att 8.713884 loss_ctc 10.447316 loss_rnnt 6.862605 hw_loss 0.283440 lr 0.00029588 rank 1
2023-03-01 02:11:05,281 DEBUG TRAIN Batch 46/7600 loss 5.900614 loss_att 8.241691 loss_ctc 11.529879 loss_rnnt 4.618187 hw_loss 0.119330 lr 0.00029588 rank 4
2023-03-01 02:11:05,301 DEBUG TRAIN Batch 46/7600 loss 4.470966 loss_att 8.671225 loss_ctc 5.372837 loss_rnnt 3.373950 hw_loss 0.256339 lr 0.00029588 rank 3
2023-03-01 02:11:44,627 DEBUG TRAIN Batch 46/7700 loss 5.629146 loss_att 7.303163 loss_ctc 10.338749 loss_rnnt 4.477887 hw_loss 0.353455 lr 0.00029586 rank 7
2023-03-01 02:11:44,644 DEBUG TRAIN Batch 46/7700 loss 4.091524 loss_att 7.497700 loss_ctc 7.145998 loss_rnnt 2.853394 hw_loss 0.280559 lr 0.00029587 rank 0
2023-03-01 02:11:44,645 DEBUG TRAIN Batch 46/7700 loss 9.617381 loss_att 15.385849 loss_ctc 16.222219 loss_rnnt 7.478149 hw_loss 0.196674 lr 0.00029587 rank 4
2023-03-01 02:11:44,647 DEBUG TRAIN Batch 46/7700 loss 9.465402 loss_att 10.607317 loss_ctc 14.374972 loss_rnnt 8.452595 hw_loss 0.243402 lr 0.00029586 rank 6
2023-03-01 02:11:44,647 DEBUG TRAIN Batch 46/7700 loss 6.333889 loss_att 10.409220 loss_ctc 10.658255 loss_rnnt 4.844691 hw_loss 0.182906 lr 0.00029586 rank 3
2023-03-01 02:11:44,652 DEBUG TRAIN Batch 46/7700 loss 6.061757 loss_att 6.476856 loss_ctc 9.030214 loss_rnnt 5.416337 hw_loss 0.312385 lr 0.00029587 rank 1
2023-03-01 02:11:44,666 DEBUG TRAIN Batch 46/7700 loss 5.360468 loss_att 6.214124 loss_ctc 8.330872 loss_rnnt 4.592327 hw_loss 0.377545 lr 0.00029587 rank 2
2023-03-01 02:11:44,709 DEBUG TRAIN Batch 46/7700 loss 7.457238 loss_att 10.504346 loss_ctc 14.936804 loss_rnnt 5.715008 hw_loss 0.254124 lr 0.00029587 rank 5
2023-03-01 02:12:24,340 DEBUG TRAIN Batch 46/7800 loss 3.089904 loss_att 5.610440 loss_ctc 5.304491 loss_rnnt 2.231129 hw_loss 0.111355 lr 0.00029586 rank 0
2023-03-01 02:12:24,356 DEBUG TRAIN Batch 46/7800 loss 2.010200 loss_att 5.012783 loss_ctc 5.085869 loss_rnnt 0.775840 hw_loss 0.419540 lr 0.00029585 rank 3
2023-03-01 02:12:24,357 DEBUG TRAIN Batch 46/7800 loss 13.812054 loss_att 16.336771 loss_ctc 26.581352 loss_rnnt 11.490878 hw_loss 0.213110 lr 0.00029585 rank 6
2023-03-01 02:12:24,358 DEBUG TRAIN Batch 46/7800 loss 10.465463 loss_att 16.299166 loss_ctc 20.813232 loss_rnnt 7.816843 hw_loss 0.191582 lr 0.00029585 rank 2
2023-03-01 02:12:24,359 DEBUG TRAIN Batch 46/7800 loss 5.269463 loss_att 7.225021 loss_ctc 6.220680 loss_rnnt 4.699363 hw_loss 0.097798 lr 0.00029585 rank 5
2023-03-01 02:12:24,362 DEBUG TRAIN Batch 46/7800 loss 10.034528 loss_att 13.790242 loss_ctc 18.742331 loss_rnnt 8.024726 hw_loss 0.183034 lr 0.00029585 rank 1
2023-03-01 02:12:24,371 DEBUG TRAIN Batch 46/7800 loss 7.420309 loss_att 8.880473 loss_ctc 11.036158 loss_rnnt 6.544575 hw_loss 0.190478 lr 0.00029585 rank 7
2023-03-01 02:12:24,374 DEBUG TRAIN Batch 46/7800 loss 3.509820 loss_att 5.850704 loss_ctc 4.786375 loss_rnnt 2.798798 hw_loss 0.136196 lr 0.00029585 rank 4
2023-03-01 02:13:30,934 DEBUG TRAIN Batch 46/7900 loss 5.054465 loss_att 6.898938 loss_ctc 9.768652 loss_rnnt 3.988129 hw_loss 0.129156 lr 0.00029584 rank 4
2023-03-01 02:13:30,934 DEBUG TRAIN Batch 46/7900 loss 2.078941 loss_att 6.057277 loss_ctc 2.584960 loss_rnnt 1.099161 hw_loss 0.218706 lr 0.00029584 rank 6
2023-03-01 02:13:30,936 DEBUG TRAIN Batch 46/7900 loss 9.242747 loss_att 11.013990 loss_ctc 13.520107 loss_rnnt 8.107112 hw_loss 0.395760 lr 0.00029584 rank 0
2023-03-01 02:13:30,936 DEBUG TRAIN Batch 46/7900 loss 7.445569 loss_att 10.007986 loss_ctc 9.531965 loss_rnnt 6.527783 hw_loss 0.238341 lr 0.00029584 rank 2
2023-03-01 02:13:30,936 DEBUG TRAIN Batch 46/7900 loss 13.499761 loss_att 17.495674 loss_ctc 21.030928 loss_rnnt 11.517181 hw_loss 0.336076 lr 0.00029583 rank 7
2023-03-01 02:13:30,944 DEBUG TRAIN Batch 46/7900 loss 13.644449 loss_att 12.582419 loss_ctc 11.631256 loss_rnnt 14.056732 hw_loss 0.128526 lr 0.00029584 rank 1
2023-03-01 02:13:30,972 DEBUG TRAIN Batch 46/7900 loss 11.985845 loss_att 13.910243 loss_ctc 17.792881 loss_rnnt 10.729071 hw_loss 0.183043 lr 0.00029584 rank 3
2023-03-01 02:13:30,998 DEBUG TRAIN Batch 46/7900 loss 2.017174 loss_att 5.256599 loss_ctc 3.209939 loss_rnnt 1.078960 hw_loss 0.246176 lr 0.00029584 rank 5
2023-03-01 02:14:09,602 DEBUG TRAIN Batch 46/8000 loss 9.449654 loss_att 12.852695 loss_ctc 14.697104 loss_rnnt 8.007892 hw_loss 0.115303 lr 0.00029583 rank 4
2023-03-01 02:14:09,612 DEBUG TRAIN Batch 46/8000 loss 3.469334 loss_att 5.704441 loss_ctc 4.109587 loss_rnnt 2.855122 hw_loss 0.153420 lr 0.00029582 rank 7
2023-03-01 02:14:09,617 DEBUG TRAIN Batch 46/8000 loss 5.659080 loss_att 9.719954 loss_ctc 9.609550 loss_rnnt 4.252934 hw_loss 0.126077 lr 0.00029583 rank 5
2023-03-01 02:14:09,619 DEBUG TRAIN Batch 46/8000 loss 9.767059 loss_att 12.202430 loss_ctc 13.360529 loss_rnnt 8.697014 hw_loss 0.194705 lr 0.00029583 rank 0
2023-03-01 02:14:09,619 DEBUG TRAIN Batch 46/8000 loss 6.581456 loss_att 8.656729 loss_ctc 9.223963 loss_rnnt 5.718964 hw_loss 0.178317 lr 0.00029582 rank 6
2023-03-01 02:14:09,619 DEBUG TRAIN Batch 46/8000 loss 4.008255 loss_att 8.197948 loss_ctc 7.933621 loss_rnnt 2.465275 hw_loss 0.340609 lr 0.00029583 rank 1
2023-03-01 02:14:09,623 DEBUG TRAIN Batch 46/8000 loss 5.161295 loss_att 7.899324 loss_ctc 9.659521 loss_rnnt 3.946944 hw_loss 0.125592 lr 0.00029583 rank 2
2023-03-01 02:14:09,623 DEBUG TRAIN Batch 46/8000 loss 9.540339 loss_att 10.923215 loss_ctc 15.633000 loss_rnnt 8.336718 hw_loss 0.215046 lr 0.00029582 rank 3
2023-03-01 02:14:48,691 DEBUG TRAIN Batch 46/8100 loss 9.188830 loss_att 11.733685 loss_ctc 14.179985 loss_rnnt 7.925927 hw_loss 0.165835 lr 0.00029582 rank 5
2023-03-01 02:14:48,695 DEBUG TRAIN Batch 46/8100 loss 11.084832 loss_att 14.221279 loss_ctc 17.975750 loss_rnnt 9.446293 hw_loss 0.173365 lr 0.00029581 rank 6
2023-03-01 02:14:48,705 DEBUG TRAIN Batch 46/8100 loss 9.626067 loss_att 11.231478 loss_ctc 19.092445 loss_rnnt 7.983100 hw_loss 0.111939 lr 0.00029582 rank 2
2023-03-01 02:14:48,706 DEBUG TRAIN Batch 46/8100 loss 7.697434 loss_att 10.608911 loss_ctc 12.290585 loss_rnnt 6.381239 hw_loss 0.227774 lr 0.00029582 rank 1
2023-03-01 02:14:48,707 DEBUG TRAIN Batch 46/8100 loss 6.115901 loss_att 9.461909 loss_ctc 11.088515 loss_rnnt 4.623016 hw_loss 0.301254 lr 0.00029581 rank 3
2023-03-01 02:14:48,708 DEBUG TRAIN Batch 46/8100 loss 6.893541 loss_att 9.500437 loss_ctc 14.058130 loss_rnnt 5.206619 hw_loss 0.394245 lr 0.00029582 rank 0
2023-03-01 02:14:48,724 DEBUG TRAIN Batch 46/8100 loss 8.972400 loss_att 9.272678 loss_ctc 15.105189 loss_rnnt 7.927042 hw_loss 0.314243 lr 0.00029581 rank 7
2023-03-01 02:14:48,733 DEBUG TRAIN Batch 46/8100 loss 9.630721 loss_att 13.801032 loss_ctc 15.457476 loss_rnnt 7.862514 hw_loss 0.294834 lr 0.00029582 rank 4
2023-03-01 02:15:29,272 DEBUG TRAIN Batch 46/8200 loss 10.150352 loss_att 10.690376 loss_ctc 15.030027 loss_rnnt 9.227200 hw_loss 0.308482 lr 0.00029580 rank 4
2023-03-01 02:15:29,282 DEBUG TRAIN Batch 46/8200 loss 8.421031 loss_att 11.570048 loss_ctc 12.915790 loss_rnnt 7.056586 hw_loss 0.253764 lr 0.00029580 rank 2
2023-03-01 02:15:29,284 DEBUG TRAIN Batch 46/8200 loss 7.573228 loss_att 13.155260 loss_ctc 13.526204 loss_rnnt 5.546160 hw_loss 0.219247 lr 0.00029580 rank 1
2023-03-01 02:15:29,296 DEBUG TRAIN Batch 46/8200 loss 5.753755 loss_att 9.502515 loss_ctc 14.180606 loss_rnnt 3.802202 hw_loss 0.146664 lr 0.00029581 rank 0
2023-03-01 02:15:29,295 DEBUG TRAIN Batch 46/8200 loss 1.877556 loss_att 4.887492 loss_ctc 2.348444 loss_rnnt 1.129952 hw_loss 0.155310 lr 0.00029580 rank 7
2023-03-01 02:15:29,302 DEBUG TRAIN Batch 46/8200 loss 11.021893 loss_att 11.455408 loss_ctc 16.922607 loss_rnnt 10.030329 hw_loss 0.221433 lr 0.00029580 rank 5
2023-03-01 02:15:29,312 DEBUG TRAIN Batch 46/8200 loss 7.731793 loss_att 11.595995 loss_ctc 14.886948 loss_rnnt 5.893598 hw_loss 0.208751 lr 0.00029580 rank 3
2023-03-01 02:15:29,327 DEBUG TRAIN Batch 46/8200 loss 5.095901 loss_att 7.067766 loss_ctc 7.648771 loss_rnnt 4.165978 hw_loss 0.365936 lr 0.00029580 rank 6
2023-03-01 02:16:07,667 DEBUG TRAIN Batch 46/8300 loss 10.268076 loss_att 11.556417 loss_ctc 13.163269 loss_rnnt 9.467895 hw_loss 0.293415 lr 0.00029579 rank 2
2023-03-01 02:16:07,671 DEBUG TRAIN Batch 46/8300 loss 4.496987 loss_att 8.179996 loss_ctc 9.194484 loss_rnnt 2.992504 hw_loss 0.265402 lr 0.00029579 rank 0
2023-03-01 02:16:07,671 DEBUG TRAIN Batch 46/8300 loss 14.088671 loss_att 17.120285 loss_ctc 22.309002 loss_rnnt 12.261948 hw_loss 0.233168 lr 0.00029579 rank 6
2023-03-01 02:16:07,672 DEBUG TRAIN Batch 46/8300 loss 2.098948 loss_att 5.167150 loss_ctc 3.154122 loss_rnnt 1.311799 hw_loss 0.061534 lr 0.00029578 rank 3
2023-03-01 02:16:07,672 DEBUG TRAIN Batch 46/8300 loss 9.269073 loss_att 11.036579 loss_ctc 13.277526 loss_rnnt 8.203230 hw_loss 0.333527 lr 0.00029579 rank 5
2023-03-01 02:16:07,687 DEBUG TRAIN Batch 46/8300 loss 9.653341 loss_att 13.309198 loss_ctc 15.144384 loss_rnnt 8.099894 hw_loss 0.169006 lr 0.00029579 rank 1
2023-03-01 02:16:07,690 DEBUG TRAIN Batch 46/8300 loss 3.118659 loss_att 6.696415 loss_ctc 4.805596 loss_rnnt 2.111675 hw_loss 0.124704 lr 0.00029578 rank 7
2023-03-01 02:16:07,712 DEBUG TRAIN Batch 46/8300 loss 4.967147 loss_att 7.468537 loss_ctc 8.249615 loss_rnnt 3.953351 hw_loss 0.142228 lr 0.00029579 rank 4
2023-03-01 02:16:39,906 DEBUG CV Batch 46/0 loss 0.952033 loss_att 0.968979 loss_ctc 1.457217 loss_rnnt 0.648147 hw_loss 0.437136 history loss 0.916773 rank 5
2023-03-01 02:16:39,928 DEBUG CV Batch 46/0 loss 0.952033 loss_att 0.968979 loss_ctc 1.457217 loss_rnnt 0.648147 hw_loss 0.437136 history loss 0.916773 rank 3
2023-03-01 02:16:39,937 DEBUG CV Batch 46/0 loss 0.952033 loss_att 0.968979 loss_ctc 1.457217 loss_rnnt 0.648147 hw_loss 0.437136 history loss 0.916773 rank 1
2023-03-01 02:16:40,144 DEBUG CV Batch 46/0 loss 0.952033 loss_att 0.968979 loss_ctc 1.457217 loss_rnnt 0.648147 hw_loss 0.437136 history loss 0.916773 rank 6
2023-03-01 02:16:40,353 DEBUG CV Batch 46/0 loss 0.952033 loss_att 0.968979 loss_ctc 1.457217 loss_rnnt 0.648147 hw_loss 0.437136 history loss 0.916773 rank 4
2023-03-01 02:16:40,413 DEBUG CV Batch 46/0 loss 0.952033 loss_att 0.968979 loss_ctc 1.457217 loss_rnnt 0.648147 hw_loss 0.437136 history loss 0.916773 rank 0
2023-03-01 02:16:40,448 DEBUG CV Batch 46/0 loss 0.952033 loss_att 0.968979 loss_ctc 1.457217 loss_rnnt 0.648147 hw_loss 0.437136 history loss 0.916773 rank 7
2023-03-01 02:16:40,563 DEBUG CV Batch 46/0 loss 0.952033 loss_att 0.968979 loss_ctc 1.457217 loss_rnnt 0.648147 hw_loss 0.437136 history loss 0.916773 rank 2
2023-03-01 02:16:51,281 DEBUG CV Batch 46/100 loss 3.785077 loss_att 5.068046 loss_ctc 10.076024 loss_rnnt 2.502074 hw_loss 0.351778 history loss 2.917663 rank 5
2023-03-01 02:16:51,638 DEBUG CV Batch 46/100 loss 3.785077 loss_att 5.068046 loss_ctc 10.076024 loss_rnnt 2.502074 hw_loss 0.351778 history loss 2.917663 rank 1
2023-03-01 02:16:51,727 DEBUG CV Batch 46/100 loss 3.785077 loss_att 5.068046 loss_ctc 10.076024 loss_rnnt 2.502074 hw_loss 0.351778 history loss 2.917663 rank 6
2023-03-01 02:16:51,865 DEBUG CV Batch 46/100 loss 3.785077 loss_att 5.068046 loss_ctc 10.076024 loss_rnnt 2.502074 hw_loss 0.351778 history loss 2.917663 rank 4
2023-03-01 02:16:52,022 DEBUG CV Batch 46/100 loss 3.785077 loss_att 5.068046 loss_ctc 10.076024 loss_rnnt 2.502074 hw_loss 0.351778 history loss 2.917663 rank 3
2023-03-01 02:16:52,234 DEBUG CV Batch 46/100 loss 3.785077 loss_att 5.068046 loss_ctc 10.076024 loss_rnnt 2.502074 hw_loss 0.351778 history loss 2.917663 rank 7
2023-03-01 02:16:52,240 DEBUG CV Batch 46/100 loss 3.785077 loss_att 5.068046 loss_ctc 10.076024 loss_rnnt 2.502074 hw_loss 0.351778 history loss 2.917663 rank 0
2023-03-01 02:16:52,355 DEBUG CV Batch 46/100 loss 3.785077 loss_att 5.068046 loss_ctc 10.076024 loss_rnnt 2.502074 hw_loss 0.351778 history loss 2.917663 rank 2
2023-03-01 02:17:04,839 DEBUG CV Batch 46/200 loss 6.700406 loss_att 10.600326 loss_ctc 11.261419 loss_rnnt 5.311177 hw_loss 0.002081 history loss 3.508944 rank 5
2023-03-01 02:17:05,153 DEBUG CV Batch 46/200 loss 6.700406 loss_att 10.600326 loss_ctc 11.261419 loss_rnnt 5.311177 hw_loss 0.002081 history loss 3.508944 rank 1
2023-03-01 02:17:05,448 DEBUG CV Batch 46/200 loss 6.700406 loss_att 10.600326 loss_ctc 11.261419 loss_rnnt 5.311177 hw_loss 0.002081 history loss 3.508944 rank 6
2023-03-01 02:17:05,916 DEBUG CV Batch 46/200 loss 6.700406 loss_att 10.600326 loss_ctc 11.261419 loss_rnnt 5.311177 hw_loss 0.002081 history loss 3.508944 rank 3
2023-03-01 02:17:05,970 DEBUG CV Batch 46/200 loss 6.700406 loss_att 10.600326 loss_ctc 11.261419 loss_rnnt 5.311177 hw_loss 0.002081 history loss 3.508944 rank 4
2023-03-01 02:17:06,173 DEBUG CV Batch 46/200 loss 6.700406 loss_att 10.600326 loss_ctc 11.261419 loss_rnnt 5.311177 hw_loss 0.002081 history loss 3.508944 rank 2
2023-03-01 02:17:06,178 DEBUG CV Batch 46/200 loss 6.700406 loss_att 10.600326 loss_ctc 11.261419 loss_rnnt 5.311177 hw_loss 0.002081 history loss 3.508944 rank 7
2023-03-01 02:17:06,203 DEBUG CV Batch 46/200 loss 6.700406 loss_att 10.600326 loss_ctc 11.261419 loss_rnnt 5.311177 hw_loss 0.002081 history loss 3.508944 rank 0
2023-03-01 02:17:17,656 DEBUG CV Batch 46/300 loss 3.509815 loss_att 3.851011 loss_ctc 6.087036 loss_rnnt 2.995530 hw_loss 0.192030 history loss 3.662159 rank 5
2023-03-01 02:17:17,675 DEBUG CV Batch 46/300 loss 3.509815 loss_att 3.851011 loss_ctc 6.087036 loss_rnnt 2.995530 hw_loss 0.192030 history loss 3.662159 rank 1
2023-03-01 02:17:18,259 DEBUG CV Batch 46/300 loss 3.509815 loss_att 3.851011 loss_ctc 6.087036 loss_rnnt 2.995530 hw_loss 0.192030 history loss 3.662159 rank 6
2023-03-01 02:17:18,330 DEBUG CV Batch 46/300 loss 3.509815 loss_att 3.851011 loss_ctc 6.087036 loss_rnnt 2.995530 hw_loss 0.192030 history loss 3.662159 rank 4
2023-03-01 02:17:18,437 DEBUG CV Batch 46/300 loss 3.509815 loss_att 3.851011 loss_ctc 6.087036 loss_rnnt 2.995530 hw_loss 0.192030 history loss 3.662159 rank 7
2023-03-01 02:17:18,778 DEBUG CV Batch 46/300 loss 3.509815 loss_att 3.851011 loss_ctc 6.087036 loss_rnnt 2.995530 hw_loss 0.192030 history loss 3.662159 rank 2
2023-03-01 02:17:18,839 DEBUG CV Batch 46/300 loss 3.509815 loss_att 3.851011 loss_ctc 6.087036 loss_rnnt 2.995530 hw_loss 0.192030 history loss 3.662159 rank 0
2023-03-01 02:17:19,159 DEBUG CV Batch 46/300 loss 3.509815 loss_att 3.851011 loss_ctc 6.087036 loss_rnnt 2.995530 hw_loss 0.192030 history loss 3.662159 rank 3
2023-03-01 02:17:29,860 DEBUG CV Batch 46/400 loss 23.464865 loss_att 97.240036 loss_ctc 11.403000 loss_rnnt 10.171117 hw_loss 0.275550 history loss 4.478633 rank 1
2023-03-01 02:17:29,910 DEBUG CV Batch 46/400 loss 23.464865 loss_att 97.240036 loss_ctc 11.403000 loss_rnnt 10.171117 hw_loss 0.275550 history loss 4.478633 rank 5
2023-03-01 02:17:30,799 DEBUG CV Batch 46/400 loss 23.464865 loss_att 97.240036 loss_ctc 11.403000 loss_rnnt 10.171117 hw_loss 0.275550 history loss 4.478633 rank 4
2023-03-01 02:17:30,872 DEBUG CV Batch 46/400 loss 23.464865 loss_att 97.240036 loss_ctc 11.403000 loss_rnnt 10.171117 hw_loss 0.275550 history loss 4.478633 rank 6
2023-03-01 02:17:30,958 DEBUG CV Batch 46/400 loss 23.464865 loss_att 97.240036 loss_ctc 11.403000 loss_rnnt 10.171117 hw_loss 0.275550 history loss 4.478633 rank 7
2023-03-01 02:17:31,438 DEBUG CV Batch 46/400 loss 23.464865 loss_att 97.240036 loss_ctc 11.403000 loss_rnnt 10.171117 hw_loss 0.275550 history loss 4.478633 rank 0
2023-03-01 02:17:31,644 DEBUG CV Batch 46/400 loss 23.464865 loss_att 97.240036 loss_ctc 11.403000 loss_rnnt 10.171117 hw_loss 0.275550 history loss 4.478633 rank 2
2023-03-01 02:17:32,300 DEBUG CV Batch 46/400 loss 23.464865 loss_att 97.240036 loss_ctc 11.403000 loss_rnnt 10.171117 hw_loss 0.275550 history loss 4.478633 rank 3
2023-03-01 02:17:40,804 DEBUG CV Batch 46/500 loss 4.249168 loss_att 4.456618 loss_ctc 6.762844 loss_rnnt 3.748856 hw_loss 0.231874 history loss 5.097247 rank 1
2023-03-01 02:17:40,814 DEBUG CV Batch 46/500 loss 4.249168 loss_att 4.456618 loss_ctc 6.762844 loss_rnnt 3.748856 hw_loss 0.231874 history loss 5.097247 rank 5
2023-03-01 02:17:41,699 DEBUG CV Batch 46/500 loss 4.249168 loss_att 4.456618 loss_ctc 6.762844 loss_rnnt 3.748856 hw_loss 0.231874 history loss 5.097247 rank 4
2023-03-01 02:17:41,846 DEBUG CV Batch 46/500 loss 4.249168 loss_att 4.456618 loss_ctc 6.762844 loss_rnnt 3.748856 hw_loss 0.231874 history loss 5.097247 rank 7
2023-03-01 02:17:42,111 DEBUG CV Batch 46/500 loss 4.249168 loss_att 4.456618 loss_ctc 6.762844 loss_rnnt 3.748856 hw_loss 0.231874 history loss 5.097247 rank 6
2023-03-01 02:17:42,873 DEBUG CV Batch 46/500 loss 4.249168 loss_att 4.456618 loss_ctc 6.762844 loss_rnnt 3.748856 hw_loss 0.231874 history loss 5.097247 rank 0
2023-03-01 02:17:43,259 DEBUG CV Batch 46/500 loss 4.249168 loss_att 4.456618 loss_ctc 6.762844 loss_rnnt 3.748856 hw_loss 0.231874 history loss 5.097247 rank 2
2023-03-01 02:17:43,584 DEBUG CV Batch 46/500 loss 4.249168 loss_att 4.456618 loss_ctc 6.762844 loss_rnnt 3.748856 hw_loss 0.231874 history loss 5.097247 rank 3
2023-03-01 02:17:53,081 DEBUG CV Batch 46/600 loss 7.048013 loss_att 5.937928 loss_ctc 9.875790 loss_rnnt 6.760132 hw_loss 0.249115 history loss 5.948043 rank 1
2023-03-01 02:17:53,359 DEBUG CV Batch 46/600 loss 7.048013 loss_att 5.937928 loss_ctc 9.875790 loss_rnnt 6.760132 hw_loss 0.249115 history loss 5.948043 rank 5
2023-03-01 02:17:53,764 DEBUG CV Batch 46/600 loss 7.048013 loss_att 5.937928 loss_ctc 9.875790 loss_rnnt 6.760132 hw_loss 0.249115 history loss 5.948043 rank 4
2023-03-01 02:17:54,266 DEBUG CV Batch 46/600 loss 7.048013 loss_att 5.937928 loss_ctc 9.875790 loss_rnnt 6.760132 hw_loss 0.249115 history loss 5.948043 rank 7
2023-03-01 02:17:54,570 DEBUG CV Batch 46/600 loss 7.048013 loss_att 5.937928 loss_ctc 9.875790 loss_rnnt 6.760132 hw_loss 0.249115 history loss 5.948043 rank 6
2023-03-01 02:17:55,618 DEBUG CV Batch 46/600 loss 7.048013 loss_att 5.937928 loss_ctc 9.875790 loss_rnnt 6.760132 hw_loss 0.249115 history loss 5.948043 rank 0
2023-03-01 02:17:55,846 DEBUG CV Batch 46/600 loss 7.048013 loss_att 5.937928 loss_ctc 9.875790 loss_rnnt 6.760132 hw_loss 0.249115 history loss 5.948043 rank 2
2023-03-01 02:17:56,838 DEBUG CV Batch 46/600 loss 7.048013 loss_att 5.937928 loss_ctc 9.875790 loss_rnnt 6.760132 hw_loss 0.249115 history loss 5.948043 rank 3
2023-03-01 02:18:05,076 DEBUG CV Batch 46/700 loss 12.075178 loss_att 34.892586 loss_ctc 11.815126 loss_rnnt 7.474214 hw_loss 0.135293 history loss 6.456286 rank 1
2023-03-01 02:18:05,099 DEBUG CV Batch 46/700 loss 12.075178 loss_att 34.892586 loss_ctc 11.815126 loss_rnnt 7.474214 hw_loss 0.135293 history loss 6.456286 rank 5
2023-03-01 02:18:05,433 DEBUG CV Batch 46/700 loss 12.075178 loss_att 34.892586 loss_ctc 11.815126 loss_rnnt 7.474214 hw_loss 0.135293 history loss 6.456286 rank 4
2023-03-01 02:18:06,051 DEBUG CV Batch 46/700 loss 12.075178 loss_att 34.892586 loss_ctc 11.815126 loss_rnnt 7.474214 hw_loss 0.135293 history loss 6.456286 rank 7
2023-03-01 02:18:06,389 DEBUG CV Batch 46/700 loss 12.075178 loss_att 34.892586 loss_ctc 11.815126 loss_rnnt 7.474214 hw_loss 0.135293 history loss 6.456286 rank 6
2023-03-01 02:18:07,446 DEBUG CV Batch 46/700 loss 12.075178 loss_att 34.892586 loss_ctc 11.815126 loss_rnnt 7.474214 hw_loss 0.135293 history loss 6.456286 rank 0
2023-03-01 02:18:07,670 DEBUG CV Batch 46/700 loss 12.075178 loss_att 34.892586 loss_ctc 11.815126 loss_rnnt 7.474214 hw_loss 0.135293 history loss 6.456286 rank 2
2023-03-01 02:18:09,055 DEBUG CV Batch 46/700 loss 12.075178 loss_att 34.892586 loss_ctc 11.815126 loss_rnnt 7.474214 hw_loss 0.135293 history loss 6.456286 rank 3
2023-03-01 02:18:16,837 DEBUG CV Batch 46/800 loss 6.959642 loss_att 7.370373 loss_ctc 13.898054 loss_rnnt 5.793779 hw_loss 0.297366 history loss 5.985084 rank 1
2023-03-01 02:18:16,854 DEBUG CV Batch 46/800 loss 6.959642 loss_att 7.370373 loss_ctc 13.898054 loss_rnnt 5.793779 hw_loss 0.297366 history loss 5.985084 rank 4
2023-03-01 02:18:16,946 DEBUG CV Batch 46/800 loss 6.959642 loss_att 7.370373 loss_ctc 13.898054 loss_rnnt 5.793779 hw_loss 0.297366 history loss 5.985084 rank 5
2023-03-01 02:18:17,546 DEBUG CV Batch 46/800 loss 6.959642 loss_att 7.370373 loss_ctc 13.898054 loss_rnnt 5.793779 hw_loss 0.297366 history loss 5.985084 rank 7
2023-03-01 02:18:18,469 DEBUG CV Batch 46/800 loss 6.959642 loss_att 7.370373 loss_ctc 13.898054 loss_rnnt 5.793779 hw_loss 0.297366 history loss 5.985084 rank 6
2023-03-01 02:18:19,494 DEBUG CV Batch 46/800 loss 6.959642 loss_att 7.370373 loss_ctc 13.898054 loss_rnnt 5.793779 hw_loss 0.297366 history loss 5.985084 rank 2
2023-03-01 02:18:19,537 DEBUG CV Batch 46/800 loss 6.959642 loss_att 7.370373 loss_ctc 13.898054 loss_rnnt 5.793779 hw_loss 0.297366 history loss 5.985084 rank 0
2023-03-01 02:18:21,485 DEBUG CV Batch 46/800 loss 6.959642 loss_att 7.370373 loss_ctc 13.898054 loss_rnnt 5.793779 hw_loss 0.297366 history loss 5.985084 rank 3
2023-03-01 02:18:30,245 DEBUG CV Batch 46/900 loss 7.482845 loss_att 11.439143 loss_ctc 14.588294 loss_rnnt 5.630715 hw_loss 0.212768 history loss 5.817795 rank 1
2023-03-01 02:18:30,543 DEBUG CV Batch 46/900 loss 7.482845 loss_att 11.439143 loss_ctc 14.588294 loss_rnnt 5.630715 hw_loss 0.212768 history loss 5.817795 rank 4
2023-03-01 02:18:30,633 DEBUG CV Batch 46/900 loss 7.482845 loss_att 11.439143 loss_ctc 14.588294 loss_rnnt 5.630715 hw_loss 0.212768 history loss 5.817795 rank 5
2023-03-01 02:18:31,159 DEBUG CV Batch 46/900 loss 7.482845 loss_att 11.439143 loss_ctc 14.588294 loss_rnnt 5.630715 hw_loss 0.212768 history loss 5.817795 rank 7
2023-03-01 02:18:32,616 DEBUG CV Batch 46/900 loss 7.482845 loss_att 11.439143 loss_ctc 14.588294 loss_rnnt 5.630715 hw_loss 0.212768 history loss 5.817795 rank 6
2023-03-01 02:18:33,205 DEBUG CV Batch 46/900 loss 7.482845 loss_att 11.439143 loss_ctc 14.588294 loss_rnnt 5.630715 hw_loss 0.212768 history loss 5.817795 rank 2
2023-03-01 02:18:33,496 DEBUG CV Batch 46/900 loss 7.482845 loss_att 11.439143 loss_ctc 14.588294 loss_rnnt 5.630715 hw_loss 0.212768 history loss 5.817795 rank 0
2023-03-01 02:18:35,668 DEBUG CV Batch 46/900 loss 7.482845 loss_att 11.439143 loss_ctc 14.588294 loss_rnnt 5.630715 hw_loss 0.212768 history loss 5.817795 rank 3
2023-03-01 02:18:42,966 DEBUG CV Batch 46/1000 loss 3.460050 loss_att 3.964802 loss_ctc 3.844259 loss_rnnt 3.119952 hw_loss 0.352350 history loss 5.635624 rank 4
2023-03-01 02:18:43,084 DEBUG CV Batch 46/1000 loss 3.460050 loss_att 3.964802 loss_ctc 3.844259 loss_rnnt 3.119952 hw_loss 0.352350 history loss 5.635624 rank 1
2023-03-01 02:18:43,377 DEBUG CV Batch 46/1000 loss 3.460050 loss_att 3.964802 loss_ctc 3.844259 loss_rnnt 3.119952 hw_loss 0.352350 history loss 5.635624 rank 5
2023-03-01 02:18:43,793 DEBUG CV Batch 46/1000 loss 3.460050 loss_att 3.964802 loss_ctc 3.844259 loss_rnnt 3.119952 hw_loss 0.352350 history loss 5.635624 rank 7
2023-03-01 02:18:45,396 DEBUG CV Batch 46/1000 loss 3.460050 loss_att 3.964802 loss_ctc 3.844259 loss_rnnt 3.119952 hw_loss 0.352350 history loss 5.635624 rank 6
2023-03-01 02:18:45,851 DEBUG CV Batch 46/1000 loss 3.460050 loss_att 3.964802 loss_ctc 3.844259 loss_rnnt 3.119952 hw_loss 0.352350 history loss 5.635624 rank 2
2023-03-01 02:18:46,332 DEBUG CV Batch 46/1000 loss 3.460050 loss_att 3.964802 loss_ctc 3.844259 loss_rnnt 3.119952 hw_loss 0.352350 history loss 5.635624 rank 0
2023-03-01 02:18:48,727 DEBUG CV Batch 46/1000 loss 3.460050 loss_att 3.964802 loss_ctc 3.844259 loss_rnnt 3.119952 hw_loss 0.352350 history loss 5.635624 rank 3
2023-03-01 02:18:55,000 DEBUG CV Batch 46/1100 loss 4.568136 loss_att 4.556715 loss_ctc 7.799409 loss_rnnt 3.931018 hw_loss 0.391063 history loss 5.602918 rank 4
2023-03-01 02:18:55,402 DEBUG CV Batch 46/1100 loss 4.568136 loss_att 4.556715 loss_ctc 7.799409 loss_rnnt 3.931018 hw_loss 0.391063 history loss 5.602918 rank 1
2023-03-01 02:18:56,012 DEBUG CV Batch 46/1100 loss 4.568136 loss_att 4.556715 loss_ctc 7.799409 loss_rnnt 3.931018 hw_loss 0.391063 history loss 5.602918 rank 5
2023-03-01 02:18:56,088 DEBUG CV Batch 46/1100 loss 4.568136 loss_att 4.556715 loss_ctc 7.799409 loss_rnnt 3.931018 hw_loss 0.391063 history loss 5.602918 rank 7
2023-03-01 02:18:58,121 DEBUG CV Batch 46/1100 loss 4.568136 loss_att 4.556715 loss_ctc 7.799409 loss_rnnt 3.931018 hw_loss 0.391063 history loss 5.602918 rank 6
2023-03-01 02:18:58,218 DEBUG CV Batch 46/1100 loss 4.568136 loss_att 4.556715 loss_ctc 7.799409 loss_rnnt 3.931018 hw_loss 0.391063 history loss 5.602918 rank 2
2023-03-01 02:18:58,726 DEBUG CV Batch 46/1100 loss 4.568136 loss_att 4.556715 loss_ctc 7.799409 loss_rnnt 3.931018 hw_loss 0.391063 history loss 5.602918 rank 0
2023-03-01 02:19:01,161 DEBUG CV Batch 46/1100 loss 4.568136 loss_att 4.556715 loss_ctc 7.799409 loss_rnnt 3.931018 hw_loss 0.391063 history loss 5.602918 rank 3
2023-03-01 02:19:06,083 DEBUG CV Batch 46/1200 loss 5.728719 loss_att 6.478681 loss_ctc 7.260814 loss_rnnt 5.193519 hw_loss 0.339239 history loss 5.886209 rank 4
2023-03-01 02:19:06,458 DEBUG CV Batch 46/1200 loss 5.728719 loss_att 6.478681 loss_ctc 7.260814 loss_rnnt 5.193519 hw_loss 0.339239 history loss 5.886209 rank 1
2023-03-01 02:19:07,117 DEBUG CV Batch 46/1200 loss 5.728719 loss_att 6.478681 loss_ctc 7.260814 loss_rnnt 5.193519 hw_loss 0.339239 history loss 5.886209 rank 7
2023-03-01 02:19:07,201 DEBUG CV Batch 46/1200 loss 5.728719 loss_att 6.478681 loss_ctc 7.260814 loss_rnnt 5.193519 hw_loss 0.339239 history loss 5.886209 rank 5
2023-03-01 02:19:09,368 DEBUG CV Batch 46/1200 loss 5.728719 loss_att 6.478681 loss_ctc 7.260814 loss_rnnt 5.193519 hw_loss 0.339239 history loss 5.886209 rank 2
2023-03-01 02:19:09,398 DEBUG CV Batch 46/1200 loss 5.728719 loss_att 6.478681 loss_ctc 7.260814 loss_rnnt 5.193519 hw_loss 0.339239 history loss 5.886209 rank 6
2023-03-01 02:19:09,958 DEBUG CV Batch 46/1200 loss 5.728719 loss_att 6.478681 loss_ctc 7.260814 loss_rnnt 5.193519 hw_loss 0.339239 history loss 5.886209 rank 0
2023-03-01 02:19:12,836 DEBUG CV Batch 46/1200 loss 5.728719 loss_att 6.478681 loss_ctc 7.260814 loss_rnnt 5.193519 hw_loss 0.339239 history loss 5.886209 rank 3
2023-03-01 02:19:18,303 DEBUG CV Batch 46/1300 loss 4.458071 loss_att 4.409019 loss_ctc 6.556890 loss_rnnt 3.975622 hw_loss 0.398281 history loss 6.173036 rank 4
2023-03-01 02:19:18,749 DEBUG CV Batch 46/1300 loss 4.458071 loss_att 4.409019 loss_ctc 6.556890 loss_rnnt 3.975622 hw_loss 0.398281 history loss 6.173036 rank 1
2023-03-01 02:19:19,491 DEBUG CV Batch 46/1300 loss 4.458071 loss_att 4.409019 loss_ctc 6.556890 loss_rnnt 3.975622 hw_loss 0.398281 history loss 6.173036 rank 7
2023-03-01 02:19:19,724 DEBUG CV Batch 46/1300 loss 4.458071 loss_att 4.409019 loss_ctc 6.556890 loss_rnnt 3.975622 hw_loss 0.398281 history loss 6.173036 rank 5
2023-03-01 02:19:21,810 DEBUG CV Batch 46/1300 loss 4.458071 loss_att 4.409019 loss_ctc 6.556890 loss_rnnt 3.975622 hw_loss 0.398281 history loss 6.173036 rank 2
2023-03-01 02:19:22,128 DEBUG CV Batch 46/1300 loss 4.458071 loss_att 4.409019 loss_ctc 6.556890 loss_rnnt 3.975622 hw_loss 0.398281 history loss 6.173036 rank 6
2023-03-01 02:19:22,573 DEBUG CV Batch 46/1300 loss 4.458071 loss_att 4.409019 loss_ctc 6.556890 loss_rnnt 3.975622 hw_loss 0.398281 history loss 6.173036 rank 0
2023-03-01 02:19:25,647 DEBUG CV Batch 46/1300 loss 4.458071 loss_att 4.409019 loss_ctc 6.556890 loss_rnnt 3.975622 hw_loss 0.398281 history loss 6.173036 rank 3
2023-03-01 02:19:29,825 DEBUG CV Batch 46/1400 loss 3.492861 loss_att 15.315836 loss_ctc 3.452771 loss_rnnt 0.938488 hw_loss 0.365856 history loss 6.432737 rank 4
2023-03-01 02:19:30,465 DEBUG CV Batch 46/1400 loss 3.492861 loss_att 15.315836 loss_ctc 3.452771 loss_rnnt 0.938488 hw_loss 0.365856 history loss 6.432737 rank 1
2023-03-01 02:19:31,173 DEBUG CV Batch 46/1400 loss 3.492861 loss_att 15.315836 loss_ctc 3.452771 loss_rnnt 0.938488 hw_loss 0.365856 history loss 6.432737 rank 7
2023-03-01 02:19:31,310 DEBUG CV Batch 46/1400 loss 3.492861 loss_att 15.315836 loss_ctc 3.452771 loss_rnnt 0.938488 hw_loss 0.365856 history loss 6.432737 rank 5
2023-03-01 02:19:33,366 DEBUG CV Batch 46/1400 loss 3.492861 loss_att 15.315836 loss_ctc 3.452771 loss_rnnt 0.938488 hw_loss 0.365856 history loss 6.432737 rank 2
2023-03-01 02:19:33,880 DEBUG CV Batch 46/1400 loss 3.492861 loss_att 15.315836 loss_ctc 3.452771 loss_rnnt 0.938488 hw_loss 0.365856 history loss 6.432737 rank 6
2023-03-01 02:19:34,285 DEBUG CV Batch 46/1400 loss 3.492861 loss_att 15.315836 loss_ctc 3.452771 loss_rnnt 0.938488 hw_loss 0.365856 history loss 6.432737 rank 0
2023-03-01 02:19:37,841 DEBUG CV Batch 46/1400 loss 3.492861 loss_att 15.315836 loss_ctc 3.452771 loss_rnnt 0.938488 hw_loss 0.365856 history loss 6.432737 rank 3
2023-03-01 02:19:41,644 DEBUG CV Batch 46/1500 loss 7.117637 loss_att 7.306013 loss_ctc 6.800584 loss_rnnt 7.032621 hw_loss 0.168027 history loss 6.293232 rank 4
2023-03-01 02:19:42,758 DEBUG CV Batch 46/1500 loss 7.117637 loss_att 7.306013 loss_ctc 6.800584 loss_rnnt 7.032621 hw_loss 0.168027 history loss 6.293232 rank 1
2023-03-01 02:19:43,056 DEBUG CV Batch 46/1500 loss 7.117637 loss_att 7.306013 loss_ctc 6.800584 loss_rnnt 7.032621 hw_loss 0.168027 history loss 6.293232 rank 7
2023-03-01 02:19:43,545 DEBUG CV Batch 46/1500 loss 7.117637 loss_att 7.306013 loss_ctc 6.800584 loss_rnnt 7.032621 hw_loss 0.168027 history loss 6.293232 rank 5
2023-03-01 02:19:45,515 DEBUG CV Batch 46/1500 loss 7.117637 loss_att 7.306013 loss_ctc 6.800584 loss_rnnt 7.032621 hw_loss 0.168027 history loss 6.293232 rank 2
2023-03-01 02:19:46,386 DEBUG CV Batch 46/1500 loss 7.117637 loss_att 7.306013 loss_ctc 6.800584 loss_rnnt 7.032621 hw_loss 0.168027 history loss 6.293232 rank 6
2023-03-01 02:19:46,639 DEBUG CV Batch 46/1500 loss 7.117637 loss_att 7.306013 loss_ctc 6.800584 loss_rnnt 7.032621 hw_loss 0.168027 history loss 6.293232 rank 0
2023-03-01 02:19:50,048 DEBUG CV Batch 46/1500 loss 7.117637 loss_att 7.306013 loss_ctc 6.800584 loss_rnnt 7.032621 hw_loss 0.168027 history loss 6.293232 rank 3
2023-03-01 02:19:54,838 DEBUG CV Batch 46/1600 loss 10.556209 loss_att 14.084376 loss_ctc 12.737954 loss_rnnt 9.525552 hw_loss 0.063981 history loss 6.253732 rank 4
2023-03-01 02:19:56,018 DEBUG CV Batch 46/1600 loss 10.556209 loss_att 14.084376 loss_ctc 12.737954 loss_rnnt 9.525552 hw_loss 0.063981 history loss 6.253732 rank 1
2023-03-01 02:19:56,382 DEBUG CV Batch 46/1600 loss 10.556209 loss_att 14.084376 loss_ctc 12.737954 loss_rnnt 9.525552 hw_loss 0.063981 history loss 6.253732 rank 7
2023-03-01 02:19:56,935 DEBUG CV Batch 46/1600 loss 10.556209 loss_att 14.084376 loss_ctc 12.737954 loss_rnnt 9.525552 hw_loss 0.063981 history loss 6.253732 rank 5
2023-03-01 02:19:59,249 DEBUG CV Batch 46/1600 loss 10.556209 loss_att 14.084376 loss_ctc 12.737954 loss_rnnt 9.525552 hw_loss 0.063981 history loss 6.253732 rank 2
2023-03-01 02:20:00,020 DEBUG CV Batch 46/1600 loss 10.556209 loss_att 14.084376 loss_ctc 12.737954 loss_rnnt 9.525552 hw_loss 0.063981 history loss 6.253732 rank 6
2023-03-01 02:20:00,124 DEBUG CV Batch 46/1600 loss 10.556209 loss_att 14.084376 loss_ctc 12.737954 loss_rnnt 9.525552 hw_loss 0.063981 history loss 6.253732 rank 0
2023-03-01 02:20:03,745 DEBUG CV Batch 46/1600 loss 10.556209 loss_att 14.084376 loss_ctc 12.737954 loss_rnnt 9.525552 hw_loss 0.063981 history loss 6.253732 rank 3
2023-03-01 02:20:07,402 DEBUG CV Batch 46/1700 loss 8.085132 loss_att 6.401370 loss_ctc 14.057641 loss_rnnt 7.439530 hw_loss 0.348784 history loss 6.193448 rank 4
2023-03-01 02:20:08,596 DEBUG CV Batch 46/1700 loss 8.085132 loss_att 6.401370 loss_ctc 14.057641 loss_rnnt 7.439530 hw_loss 0.348784 history loss 6.193448 rank 1
2023-03-01 02:20:09,108 DEBUG CV Batch 46/1700 loss 8.085132 loss_att 6.401370 loss_ctc 14.057641 loss_rnnt 7.439530 hw_loss 0.348784 history loss 6.193448 rank 7
2023-03-01 02:20:10,037 DEBUG CV Batch 46/1700 loss 8.085132 loss_att 6.401370 loss_ctc 14.057641 loss_rnnt 7.439530 hw_loss 0.348784 history loss 6.193448 rank 5
2023-03-01 02:20:11,982 DEBUG CV Batch 46/1700 loss 8.085132 loss_att 6.401370 loss_ctc 14.057641 loss_rnnt 7.439530 hw_loss 0.348784 history loss 6.193448 rank 2
2023-03-01 02:20:12,774 DEBUG CV Batch 46/1700 loss 8.085132 loss_att 6.401370 loss_ctc 14.057641 loss_rnnt 7.439530 hw_loss 0.348784 history loss 6.193448 rank 6
2023-03-01 02:20:12,932 DEBUG CV Batch 46/1700 loss 8.085132 loss_att 6.401370 loss_ctc 14.057641 loss_rnnt 7.439530 hw_loss 0.348784 history loss 6.193448 rank 0
2023-03-01 02:20:16,529 INFO Epoch 46 CV info cv_loss 6.174623475456483
2023-03-01 02:20:16,529 INFO Epoch 47 TRAIN info lr 0.00029578446802426724
2023-03-01 02:20:16,534 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 02:20:16,609 DEBUG CV Batch 46/1700 loss 8.085132 loss_att 6.401370 loss_ctc 14.057641 loss_rnnt 7.439530 hw_loss 0.348784 history loss 6.193448 rank 3
2023-03-01 02:20:17,735 INFO Epoch 46 CV info cv_loss 6.174623476712065
2023-03-01 02:20:17,736 INFO Epoch 47 TRAIN info lr 0.00029578653826400935
2023-03-01 02:20:17,742 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 02:20:18,194 INFO Epoch 46 CV info cv_loss 6.174623474614402
2023-03-01 02:20:18,194 INFO Epoch 47 TRAIN info lr 0.00029577359997874674
2023-03-01 02:20:18,196 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 02:20:19,682 INFO Epoch 46 CV info cv_loss 6.174623474971909
2023-03-01 02:20:19,683 INFO Epoch 47 TRAIN info lr 0.00029578446802426724
2023-03-01 02:20:19,688 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 02:20:21,291 INFO Epoch 46 CV info cv_loss 6.174623477002809
2023-03-01 02:20:21,291 INFO Epoch 47 TRAIN info lr 0.00029578653826400935
2023-03-01 02:20:21,293 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 02:20:21,994 INFO Epoch 46 CV info cv_loss 6.174623476417014
2023-03-01 02:20:21,995 INFO Epoch 47 TRAIN info lr 0.00029578291537298723
2023-03-01 02:20:22,000 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 02:20:22,468 INFO Epoch 46 CV info cv_loss 6.174623476864975
2023-03-01 02:20:22,468 INFO Checkpoint: save to checkpoint exp/2_27_rnnt_bias_loss_2_class_both_finetune/46.pt
2023-03-01 02:20:23,033 INFO Epoch 47 TRAIN info lr 0.0002957849855801275
2023-03-01 02:20:23,037 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 02:20:26,409 INFO Epoch 46 CV info cv_loss 6.17462347608535
2023-03-01 02:20:26,409 INFO Epoch 47 TRAIN info lr 0.0002957777400453044
2023-03-01 02:20:26,414 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 02:21:28,179 DEBUG TRAIN Batch 47/0 loss 6.442699 loss_att 6.174265 loss_ctc 8.485677 loss_rnnt 6.015574 hw_loss 0.390778 lr 0.00029577 rank 7
2023-03-01 02:21:28,180 DEBUG TRAIN Batch 47/0 loss 5.587990 loss_att 5.603117 loss_ctc 7.128274 loss_rnnt 5.137206 hw_loss 0.454478 lr 0.00029578 rank 5
2023-03-01 02:21:28,184 DEBUG TRAIN Batch 47/0 loss 6.809569 loss_att 6.480246 loss_ctc 9.219113 loss_rnnt 6.391337 hw_loss 0.305296 lr 0.00029579 rank 2
2023-03-01 02:21:28,187 DEBUG TRAIN Batch 47/0 loss 7.969341 loss_att 8.030256 loss_ctc 11.803183 loss_rnnt 7.233799 hw_loss 0.397836 lr 0.00029578 rank 0
2023-03-01 02:21:28,200 DEBUG TRAIN Batch 47/0 loss 3.507195 loss_att 3.502887 loss_ctc 4.933006 loss_rnnt 3.073368 hw_loss 0.458587 lr 0.00029578 rank 3
2023-03-01 02:21:28,208 DEBUG TRAIN Batch 47/0 loss 8.410527 loss_att 8.241814 loss_ctc 12.306055 loss_rnnt 7.741437 hw_loss 0.343928 lr 0.00029578 rank 6
2023-03-01 02:21:28,212 DEBUG TRAIN Batch 47/0 loss 8.353326 loss_att 7.881076 loss_ctc 9.713083 loss_rnnt 8.043723 hw_loss 0.417660 lr 0.00029578 rank 4
2023-03-01 02:21:28,231 DEBUG TRAIN Batch 47/0 loss 4.441516 loss_att 4.995180 loss_ctc 6.855299 loss_rnnt 3.811766 hw_loss 0.369713 lr 0.00029579 rank 1
2023-03-01 02:22:06,051 DEBUG TRAIN Batch 47/100 loss 5.242649 loss_att 7.106393 loss_ctc 7.949073 loss_rnnt 4.372314 hw_loss 0.256365 lr 0.00029576 rank 7
2023-03-01 02:22:06,053 DEBUG TRAIN Batch 47/100 loss 8.427766 loss_att 13.421526 loss_ctc 12.506609 loss_rnnt 6.718267 hw_loss 0.312941 lr 0.00029577 rank 1
2023-03-01 02:22:06,054 DEBUG TRAIN Batch 47/100 loss 2.366209 loss_att 5.046832 loss_ctc 4.613879 loss_rnnt 1.400157 hw_loss 0.244198 lr 0.00029577 rank 0
2023-03-01 02:22:06,055 DEBUG TRAIN Batch 47/100 loss 8.076069 loss_att 9.754886 loss_ctc 9.432722 loss_rnnt 7.486009 hw_loss 0.137644 lr 0.00029577 rank 6
2023-03-01 02:22:06,058 DEBUG TRAIN Batch 47/100 loss 5.588849 loss_att 9.917021 loss_ctc 8.956096 loss_rnnt 4.184677 hw_loss 0.167946 lr 0.00029577 rank 5
2023-03-01 02:22:06,058 DEBUG TRAIN Batch 47/100 loss 9.030467 loss_att 10.308434 loss_ctc 10.808703 loss_rnnt 8.400955 hw_loss 0.256537 lr 0.00029577 rank 2
2023-03-01 02:22:06,060 DEBUG TRAIN Batch 47/100 loss 2.694235 loss_att 8.054239 loss_ctc 7.460262 loss_rnnt 0.875021 hw_loss 0.209516 lr 0.00029577 rank 4
2023-03-01 02:22:06,062 DEBUG TRAIN Batch 47/100 loss 2.303558 loss_att 4.337031 loss_ctc 5.231094 loss_rnnt 1.438341 hw_loss 0.127845 lr 0.00029576 rank 3
2023-03-01 02:22:43,774 DEBUG TRAIN Batch 47/200 loss 4.263487 loss_att 7.083821 loss_ctc 7.139337 loss_rnnt 3.157286 hw_loss 0.297540 lr 0.00029576 rank 5
2023-03-01 02:22:43,775 DEBUG TRAIN Batch 47/200 loss 5.291703 loss_att 6.395957 loss_ctc 6.933823 loss_rnnt 4.676916 hw_loss 0.328100 lr 0.00029576 rank 0
2023-03-01 02:22:43,776 DEBUG TRAIN Batch 47/200 loss 3.781076 loss_att 8.910764 loss_ctc 10.679998 loss_rnnt 1.761059 hw_loss 0.139170 lr 0.00029576 rank 4
2023-03-01 02:22:43,777 DEBUG TRAIN Batch 47/200 loss 3.803082 loss_att 7.050530 loss_ctc 7.745425 loss_rnnt 2.494296 hw_loss 0.250596 lr 0.00029575 rank 7
2023-03-01 02:22:43,778 DEBUG TRAIN Batch 47/200 loss 6.575733 loss_att 8.526031 loss_ctc 9.033966 loss_rnnt 5.791028 hw_loss 0.125401 lr 0.00029576 rank 1
2023-03-01 02:22:43,784 DEBUG TRAIN Batch 47/200 loss 14.220459 loss_att 17.404799 loss_ctc 25.719467 loss_rnnt 11.964705 hw_loss 0.160661 lr 0.00029575 rank 3
2023-03-01 02:22:43,784 DEBUG TRAIN Batch 47/200 loss 6.485771 loss_att 8.544411 loss_ctc 14.520674 loss_rnnt 4.880515 hw_loss 0.229139 lr 0.00029576 rank 2
2023-03-01 02:22:43,796 DEBUG TRAIN Batch 47/200 loss 1.981949 loss_att 5.040231 loss_ctc 4.045751 loss_rnnt 0.978389 hw_loss 0.218867 lr 0.00029576 rank 6
2023-03-01 02:23:22,291 DEBUG TRAIN Batch 47/300 loss 6.209278 loss_att 9.664551 loss_ctc 10.857071 loss_rnnt 4.755423 hw_loss 0.268303 lr 0.00029575 rank 4
2023-03-01 02:23:22,295 DEBUG TRAIN Batch 47/300 loss 5.511178 loss_att 7.829918 loss_ctc 12.211779 loss_rnnt 4.038464 hw_loss 0.216660 lr 0.00029574 rank 3
2023-03-01 02:23:22,296 DEBUG TRAIN Batch 47/300 loss 2.860307 loss_att 5.181730 loss_ctc 3.425977 loss_rnnt 2.215327 hw_loss 0.197386 lr 0.00029575 rank 5
2023-03-01 02:23:22,305 DEBUG TRAIN Batch 47/300 loss 7.058325 loss_att 10.657757 loss_ctc 11.422466 loss_rnnt 5.658468 hw_loss 0.183909 lr 0.00029575 rank 1
2023-03-01 02:23:22,307 DEBUG TRAIN Batch 47/300 loss 5.107870 loss_att 6.774599 loss_ctc 7.331078 loss_rnnt 4.351294 hw_loss 0.237754 lr 0.00029573 rank 7
2023-03-01 02:23:22,312 DEBUG TRAIN Batch 47/300 loss 5.566259 loss_att 7.642301 loss_ctc 9.328812 loss_rnnt 4.523015 hw_loss 0.236927 lr 0.00029575 rank 2
2023-03-01 02:23:22,313 DEBUG TRAIN Batch 47/300 loss 9.971249 loss_att 11.648890 loss_ctc 16.166428 loss_rnnt 8.752382 hw_loss 0.107464 lr 0.00029575 rank 0
2023-03-01 02:23:22,357 DEBUG TRAIN Batch 47/300 loss 7.370200 loss_att 9.213240 loss_ctc 10.807749 loss_rnnt 6.450522 hw_loss 0.173867 lr 0.00029574 rank 6
2023-03-01 02:24:27,072 DEBUG TRAIN Batch 47/400 loss 1.917028 loss_att 4.902893 loss_ctc 5.951814 loss_rnnt 0.632646 hw_loss 0.279820 lr 0.00029572 rank 7
2023-03-01 02:24:27,080 DEBUG TRAIN Batch 47/400 loss 6.868437 loss_att 8.568487 loss_ctc 10.666246 loss_rnnt 5.969769 hw_loss 0.098030 lr 0.00029573 rank 6
2023-03-01 02:24:27,081 DEBUG TRAIN Batch 47/400 loss 2.495437 loss_att 6.409620 loss_ctc 5.523021 loss_rnnt 1.235312 hw_loss 0.138019 lr 0.00029573 rank 0
2023-03-01 02:24:27,081 DEBUG TRAIN Batch 47/400 loss 6.348563 loss_att 10.143944 loss_ctc 9.818238 loss_rnnt 4.981098 hw_loss 0.273309 lr 0.00029573 rank 5
2023-03-01 02:24:27,083 DEBUG TRAIN Batch 47/400 loss 15.375668 loss_att 17.523163 loss_ctc 23.705927 loss_rnnt 13.746090 hw_loss 0.167581 lr 0.00029573 rank 1
2023-03-01 02:24:27,084 DEBUG TRAIN Batch 47/400 loss 8.284850 loss_att 11.614380 loss_ctc 18.661421 loss_rnnt 6.135819 hw_loss 0.186715 lr 0.00029573 rank 3
2023-03-01 02:24:27,084 DEBUG TRAIN Batch 47/400 loss 7.710423 loss_att 11.394749 loss_ctc 11.940391 loss_rnnt 6.298568 hw_loss 0.208114 lr 0.00029573 rank 2
2023-03-01 02:24:27,103 DEBUG TRAIN Batch 47/400 loss 7.840578 loss_att 9.763756 loss_ctc 11.053452 loss_rnnt 6.856395 hw_loss 0.320932 lr 0.00029573 rank 4
2023-03-01 02:25:05,381 DEBUG TRAIN Batch 47/500 loss 4.672483 loss_att 7.225792 loss_ctc 7.845136 loss_rnnt 3.588474 hw_loss 0.281865 lr 0.00029572 rank 5
2023-03-01 02:25:05,394 DEBUG TRAIN Batch 47/500 loss 2.390463 loss_att 4.583824 loss_ctc 4.451440 loss_rnnt 1.526383 hw_loss 0.282395 lr 0.00029572 rank 1
2023-03-01 02:25:05,395 DEBUG TRAIN Batch 47/500 loss 12.017269 loss_att 16.499987 loss_ctc 21.508171 loss_rnnt 9.702566 hw_loss 0.286323 lr 0.00029571 rank 7
2023-03-01 02:25:05,397 DEBUG TRAIN Batch 47/500 loss 4.180507 loss_att 6.665952 loss_ctc 9.202156 loss_rnnt 2.863719 hw_loss 0.281524 lr 0.00029572 rank 0
2023-03-01 02:25:05,400 DEBUG TRAIN Batch 47/500 loss 6.786898 loss_att 8.344469 loss_ctc 9.588060 loss_rnnt 5.906202 hw_loss 0.366927 lr 0.00029572 rank 6
2023-03-01 02:25:05,400 DEBUG TRAIN Batch 47/500 loss 2.221321 loss_att 5.196608 loss_ctc 3.070476 loss_rnnt 1.402130 hw_loss 0.207960 lr 0.00029571 rank 3
2023-03-01 02:25:05,402 DEBUG TRAIN Batch 47/500 loss 6.803976 loss_att 9.410657 loss_ctc 13.866645 loss_rnnt 5.271623 hw_loss 0.129990 lr 0.00029572 rank 2
2023-03-01 02:25:05,407 DEBUG TRAIN Batch 47/500 loss 3.740813 loss_att 6.283340 loss_ctc 5.825692 loss_rnnt 2.889772 hw_loss 0.121034 lr 0.00029572 rank 4
2023-03-01 02:25:43,991 DEBUG TRAIN Batch 47/600 loss 8.144172 loss_att 9.314397 loss_ctc 16.098413 loss_rnnt 6.695333 hw_loss 0.289177 lr 0.00029571 rank 5
2023-03-01 02:25:43,992 DEBUG TRAIN Batch 47/600 loss 8.136150 loss_att 8.987711 loss_ctc 14.303891 loss_rnnt 6.972694 hw_loss 0.320207 lr 0.00029571 rank 1
2023-03-01 02:25:43,994 DEBUG TRAIN Batch 47/600 loss 6.372365 loss_att 8.594781 loss_ctc 11.614038 loss_rnnt 5.063898 hw_loss 0.309555 lr 0.00029570 rank 3
2023-03-01 02:25:43,994 DEBUG TRAIN Batch 47/600 loss 4.396919 loss_att 5.951752 loss_ctc 9.435205 loss_rnnt 3.263373 hw_loss 0.282763 lr 0.00029571 rank 4
2023-03-01 02:25:43,995 DEBUG TRAIN Batch 47/600 loss 9.421547 loss_att 12.110845 loss_ctc 15.689517 loss_rnnt 7.832870 hw_loss 0.403289 lr 0.00029570 rank 6
2023-03-01 02:25:43,995 DEBUG TRAIN Batch 47/600 loss 5.011809 loss_att 7.735035 loss_ctc 9.647315 loss_rnnt 3.671871 hw_loss 0.332297 lr 0.00029571 rank 0
2023-03-01 02:25:43,996 DEBUG TRAIN Batch 47/600 loss 7.844509 loss_att 8.050611 loss_ctc 10.290101 loss_rnnt 7.276680 hw_loss 0.375992 lr 0.00029571 rank 2
2023-03-01 02:25:43,999 DEBUG TRAIN Batch 47/600 loss 5.258041 loss_att 6.906039 loss_ctc 11.300239 loss_rnnt 3.896366 hw_loss 0.424592 lr 0.00029570 rank 7
2023-03-01 02:26:23,402 DEBUG TRAIN Batch 47/700 loss 3.589785 loss_att 7.979890 loss_ctc 7.896399 loss_rnnt 2.043356 hw_loss 0.176612 lr 0.00029570 rank 2
2023-03-01 02:26:23,403 DEBUG TRAIN Batch 47/700 loss 3.946217 loss_att 5.661778 loss_ctc 8.225113 loss_rnnt 2.882325 hw_loss 0.281739 lr 0.00029569 rank 4
2023-03-01 02:26:23,404 DEBUG TRAIN Batch 47/700 loss 5.145412 loss_att 8.087729 loss_ctc 8.166447 loss_rnnt 3.957188 hw_loss 0.369294 lr 0.00029569 rank 6
2023-03-01 02:26:23,405 DEBUG TRAIN Batch 47/700 loss 6.455116 loss_att 8.096793 loss_ctc 10.926394 loss_rnnt 5.410140 hw_loss 0.225883 lr 0.00029569 rank 5
2023-03-01 02:26:23,420 DEBUG TRAIN Batch 47/700 loss 7.497388 loss_att 11.174768 loss_ctc 9.608773 loss_rnnt 6.365116 hw_loss 0.216146 lr 0.00029569 rank 3
2023-03-01 02:26:23,420 DEBUG TRAIN Batch 47/700 loss 3.600603 loss_att 9.604401 loss_ctc 7.104146 loss_rnnt 1.707242 hw_loss 0.422742 lr 0.00029570 rank 1
2023-03-01 02:26:23,425 DEBUG TRAIN Batch 47/700 loss 3.370558 loss_att 6.806901 loss_ctc 6.273145 loss_rnnt 2.215771 hw_loss 0.150949 lr 0.00029568 rank 7
2023-03-01 02:26:23,425 DEBUG TRAIN Batch 47/700 loss 3.592001 loss_att 6.904820 loss_ctc 6.101252 loss_rnnt 2.420325 hw_loss 0.327270 lr 0.00029569 rank 0
2023-03-01 02:27:27,112 DEBUG TRAIN Batch 47/800 loss 3.022698 loss_att 5.927946 loss_ctc 5.888600 loss_rnnt 1.973639 hw_loss 0.161042 lr 0.00029568 rank 4
2023-03-01 02:27:27,115 DEBUG TRAIN Batch 47/800 loss 3.828050 loss_att 6.075127 loss_ctc 8.657957 loss_rnnt 2.562144 hw_loss 0.323443 lr 0.00029567 rank 3
2023-03-01 02:27:27,136 DEBUG TRAIN Batch 47/800 loss 11.677933 loss_att 12.539847 loss_ctc 16.821394 loss_rnnt 10.678297 hw_loss 0.265236 lr 0.00029568 rank 0
2023-03-01 02:27:27,137 DEBUG TRAIN Batch 47/800 loss 9.100788 loss_att 9.242046 loss_ctc 17.184069 loss_rnnt 7.928348 hw_loss 0.124535 lr 0.00029567 rank 7
2023-03-01 02:27:27,138 DEBUG TRAIN Batch 47/800 loss 12.566398 loss_att 16.220963 loss_ctc 23.756123 loss_rnnt 10.218636 hw_loss 0.234161 lr 0.00029568 rank 1
2023-03-01 02:27:27,140 DEBUG TRAIN Batch 47/800 loss 3.042613 loss_att 6.401043 loss_ctc 5.467306 loss_rnnt 1.962298 hw_loss 0.160006 lr 0.00029568 rank 6
2023-03-01 02:27:27,140 DEBUG TRAIN Batch 47/800 loss 5.661704 loss_att 7.568528 loss_ctc 9.202337 loss_rnnt 4.608006 hw_loss 0.375463 lr 0.00029568 rank 2
2023-03-01 02:27:27,143 DEBUG TRAIN Batch 47/800 loss 14.941406 loss_att 17.776724 loss_ctc 24.565426 loss_rnnt 12.962034 hw_loss 0.242075 lr 0.00029568 rank 5
2023-03-01 02:28:05,359 DEBUG TRAIN Batch 47/900 loss 7.509852 loss_att 9.006707 loss_ctc 12.032645 loss_rnnt 6.457215 hw_loss 0.281675 lr 0.00029566 rank 3
2023-03-01 02:28:05,364 DEBUG TRAIN Batch 47/900 loss 4.750934 loss_att 6.085692 loss_ctc 7.956423 loss_rnnt 3.860268 hw_loss 0.368091 lr 0.00029567 rank 2
2023-03-01 02:28:05,369 DEBUG TRAIN Batch 47/900 loss 8.153216 loss_att 11.332450 loss_ctc 17.097652 loss_rnnt 6.225687 hw_loss 0.185797 lr 0.00029567 rank 0
2023-03-01 02:28:05,371 DEBUG TRAIN Batch 47/900 loss 2.619019 loss_att 5.616506 loss_ctc 3.858739 loss_rnnt 1.701325 hw_loss 0.286689 lr 0.00029566 rank 7
2023-03-01 02:28:05,376 DEBUG TRAIN Batch 47/900 loss 9.343225 loss_att 18.343229 loss_ctc 23.921684 loss_rnnt 5.390535 hw_loss 0.391677 lr 0.00029567 rank 5
2023-03-01 02:28:05,376 DEBUG TRAIN Batch 47/900 loss 10.614188 loss_att 12.053011 loss_ctc 15.716335 loss_rnnt 9.645549 hw_loss 0.001105 lr 0.00029567 rank 1
2023-03-01 02:28:05,377 DEBUG TRAIN Batch 47/900 loss 8.382270 loss_att 9.615330 loss_ctc 10.910963 loss_rnnt 7.661148 hw_loss 0.257533 lr 0.00029567 rank 4
2023-03-01 02:28:05,378 DEBUG TRAIN Batch 47/900 loss 10.126057 loss_att 11.619848 loss_ctc 14.180656 loss_rnnt 9.096792 hw_loss 0.356050 lr 0.00029567 rank 6
2023-03-01 02:28:43,736 DEBUG TRAIN Batch 47/1000 loss 5.728909 loss_att 6.607936 loss_ctc 7.167754 loss_rnnt 5.273399 hw_loss 0.164734 lr 0.00029566 rank 1
2023-03-01 02:28:43,737 DEBUG TRAIN Batch 47/1000 loss 2.236331 loss_att 5.544461 loss_ctc 5.329494 loss_rnnt 1.081981 hw_loss 0.150567 lr 0.00029564 rank 7
2023-03-01 02:28:43,742 DEBUG TRAIN Batch 47/1000 loss 8.359930 loss_att 13.468576 loss_ctc 12.718533 loss_rnnt 6.657315 hw_loss 0.187008 lr 0.00029565 rank 4
2023-03-01 02:28:43,742 DEBUG TRAIN Batch 47/1000 loss 5.668698 loss_att 9.121082 loss_ctc 11.402722 loss_rnnt 4.123556 hw_loss 0.168993 lr 0.00029566 rank 2
2023-03-01 02:28:43,748 DEBUG TRAIN Batch 47/1000 loss 4.077865 loss_att 7.634065 loss_ctc 7.737891 loss_rnnt 2.789469 hw_loss 0.167160 lr 0.00029565 rank 3
2023-03-01 02:28:43,751 DEBUG TRAIN Batch 47/1000 loss 8.584338 loss_att 10.619927 loss_ctc 14.533951 loss_rnnt 7.341649 hw_loss 0.079293 lr 0.00029566 rank 0
2023-03-01 02:28:43,766 DEBUG TRAIN Batch 47/1000 loss 8.185534 loss_att 11.786453 loss_ctc 12.196418 loss_rnnt 6.773629 hw_loss 0.294257 lr 0.00029565 rank 5
2023-03-01 02:28:43,771 DEBUG TRAIN Batch 47/1000 loss 4.682591 loss_att 8.555368 loss_ctc 10.492769 loss_rnnt 3.110387 hw_loss 0.043048 lr 0.00029565 rank 6
2023-03-01 02:29:49,433 DEBUG TRAIN Batch 47/1100 loss 6.921773 loss_att 10.214512 loss_ctc 12.050954 loss_rnnt 5.558383 hw_loss 0.039286 lr 0.00029564 rank 1
2023-03-01 02:29:49,436 DEBUG TRAIN Batch 47/1100 loss 3.581385 loss_att 5.493400 loss_ctc 7.045324 loss_rnnt 2.580443 hw_loss 0.293777 lr 0.00029564 rank 2
2023-03-01 02:29:49,452 DEBUG TRAIN Batch 47/1100 loss 5.044400 loss_att 9.287680 loss_ctc 10.801826 loss_rnnt 3.278150 hw_loss 0.281134 lr 0.00029564 rank 6
2023-03-01 02:29:49,453 DEBUG TRAIN Batch 47/1100 loss 2.758238 loss_att 5.562023 loss_ctc 6.072986 loss_rnnt 1.643695 hw_loss 0.209661 lr 0.00029563 rank 7
2023-03-01 02:29:49,453 DEBUG TRAIN Batch 47/1100 loss 4.565541 loss_att 7.664601 loss_ctc 7.753441 loss_rnnt 3.440135 hw_loss 0.151013 lr 0.00029564 rank 0
2023-03-01 02:29:49,457 DEBUG TRAIN Batch 47/1100 loss 6.018289 loss_att 8.613115 loss_ctc 8.464497 loss_rnnt 5.031055 hw_loss 0.266451 lr 0.00029564 rank 5
2023-03-01 02:29:49,460 DEBUG TRAIN Batch 47/1100 loss 2.809615 loss_att 5.028670 loss_ctc 4.835972 loss_rnnt 2.045503 hw_loss 0.093975 lr 0.00029564 rank 3
2023-03-01 02:29:49,502 DEBUG TRAIN Batch 47/1100 loss 11.213591 loss_att 15.556602 loss_ctc 20.133093 loss_rnnt 8.968586 hw_loss 0.350878 lr 0.00029564 rank 4
2023-03-01 02:30:27,762 DEBUG TRAIN Batch 47/1200 loss 7.135841 loss_att 10.414688 loss_ctc 12.260754 loss_rnnt 5.628135 hw_loss 0.316155 lr 0.00029562 rank 3
2023-03-01 02:30:27,775 DEBUG TRAIN Batch 47/1200 loss 6.830714 loss_att 8.058022 loss_ctc 8.681781 loss_rnnt 6.221460 hw_loss 0.219346 lr 0.00029563 rank 0
2023-03-01 02:30:27,777 DEBUG TRAIN Batch 47/1200 loss 10.916273 loss_att 12.390060 loss_ctc 16.859005 loss_rnnt 9.739202 hw_loss 0.168655 lr 0.00029562 rank 7
2023-03-01 02:30:27,781 DEBUG TRAIN Batch 47/1200 loss 4.383308 loss_att 5.867617 loss_ctc 11.083066 loss_rnnt 3.131690 hw_loss 0.115228 lr 0.00029563 rank 4
2023-03-01 02:30:27,781 DEBUG TRAIN Batch 47/1200 loss 5.039330 loss_att 7.329191 loss_ctc 8.489637 loss_rnnt 3.999908 hw_loss 0.227642 lr 0.00029563 rank 1
2023-03-01 02:30:27,781 DEBUG TRAIN Batch 47/1200 loss 5.378794 loss_att 8.518896 loss_ctc 8.328879 loss_rnnt 4.253546 hw_loss 0.194779 lr 0.00029563 rank 2
2023-03-01 02:30:27,783 DEBUG TRAIN Batch 47/1200 loss 2.760219 loss_att 5.854401 loss_ctc 6.143977 loss_rnnt 1.609150 hw_loss 0.151996 lr 0.00029563 rank 5
2023-03-01 02:30:27,785 DEBUG TRAIN Batch 47/1200 loss 6.151444 loss_att 7.642902 loss_ctc 8.742662 loss_rnnt 5.400926 hw_loss 0.200120 lr 0.00029563 rank 6
2023-03-01 02:31:06,280 DEBUG TRAIN Batch 47/1300 loss 7.766779 loss_att 11.444014 loss_ctc 19.413908 loss_rnnt 5.319807 hw_loss 0.297329 lr 0.00029562 rank 0
2023-03-01 02:31:06,281 DEBUG TRAIN Batch 47/1300 loss 1.077792 loss_att 4.071122 loss_ctc 2.038628 loss_rnnt 0.295935 hw_loss 0.103274 lr 0.00029562 rank 4
2023-03-01 02:31:06,297 DEBUG TRAIN Batch 47/1300 loss 5.085599 loss_att 8.873644 loss_ctc 7.533903 loss_rnnt 3.875865 hw_loss 0.235659 lr 0.00029562 rank 1
2023-03-01 02:31:06,299 DEBUG TRAIN Batch 47/1300 loss 6.968091 loss_att 7.614321 loss_ctc 9.229736 loss_rnnt 6.429904 hw_loss 0.201353 lr 0.00029561 rank 7
2023-03-01 02:31:06,300 DEBUG TRAIN Batch 47/1300 loss 3.285080 loss_att 7.355324 loss_ctc 7.177162 loss_rnnt 1.810327 hw_loss 0.265799 lr 0.00029561 rank 6
2023-03-01 02:31:06,301 DEBUG TRAIN Batch 47/1300 loss 7.784448 loss_att 11.282543 loss_ctc 15.526354 loss_rnnt 5.924870 hw_loss 0.239448 lr 0.00029561 rank 3
2023-03-01 02:31:06,302 DEBUG TRAIN Batch 47/1300 loss 7.567646 loss_att 16.335232 loss_ctc 19.222073 loss_rnnt 4.065380 hw_loss 0.365297 lr 0.00029562 rank 5
2023-03-01 02:31:06,341 DEBUG TRAIN Batch 47/1300 loss 6.465240 loss_att 6.387017 loss_ctc 8.951165 loss_rnnt 5.939440 hw_loss 0.393725 lr 0.00029562 rank 2
2023-03-01 02:31:45,241 DEBUG TRAIN Batch 47/1400 loss 0.702069 loss_att 2.928276 loss_ctc 0.932171 loss_rnnt 0.174622 hw_loss 0.096608 lr 0.00029560 rank 3
2023-03-01 02:31:45,241 DEBUG TRAIN Batch 47/1400 loss 7.624012 loss_att 10.285357 loss_ctc 13.590107 loss_rnnt 6.182576 hw_loss 0.213164 lr 0.00029561 rank 2
2023-03-01 02:31:45,246 DEBUG TRAIN Batch 47/1400 loss 2.785758 loss_att 5.612177 loss_ctc 3.587506 loss_rnnt 1.991283 hw_loss 0.229298 lr 0.00029561 rank 1
2023-03-01 02:31:45,248 DEBUG TRAIN Batch 47/1400 loss 9.780805 loss_att 16.735905 loss_ctc 20.741905 loss_rnnt 6.823645 hw_loss 0.196237 lr 0.00029560 rank 5
2023-03-01 02:31:45,250 DEBUG TRAIN Batch 47/1400 loss 3.024722 loss_att 5.830489 loss_ctc 3.577493 loss_rnnt 2.319284 hw_loss 0.132341 lr 0.00029559 rank 7
2023-03-01 02:31:45,251 DEBUG TRAIN Batch 47/1400 loss 9.060295 loss_att 9.531317 loss_ctc 10.256201 loss_rnnt 8.640518 hw_loss 0.311471 lr 0.00029560 rank 0
2023-03-01 02:31:45,255 DEBUG TRAIN Batch 47/1400 loss 7.657080 loss_att 12.194494 loss_ctc 12.821200 loss_rnnt 5.943991 hw_loss 0.219482 lr 0.00029560 rank 4
2023-03-01 02:31:45,259 DEBUG TRAIN Batch 47/1400 loss 7.285891 loss_att 11.799025 loss_ctc 19.126202 loss_rnnt 4.681279 hw_loss 0.231144 lr 0.00029560 rank 6
2023-03-01 02:32:49,757 DEBUG TRAIN Batch 47/1500 loss 3.966117 loss_att 5.714755 loss_ctc 7.569016 loss_rnnt 3.107074 hw_loss 0.054243 lr 0.00029559 rank 6
2023-03-01 02:32:49,758 DEBUG TRAIN Batch 47/1500 loss 7.551907 loss_att 8.497779 loss_ctc 12.396421 loss_rnnt 6.555603 hw_loss 0.302240 lr 0.00029559 rank 1
2023-03-01 02:32:49,759 DEBUG TRAIN Batch 47/1500 loss 4.492646 loss_att 7.205394 loss_ctc 9.531315 loss_rnnt 3.188314 hw_loss 0.168673 lr 0.00029558 rank 7
2023-03-01 02:32:49,763 DEBUG TRAIN Batch 47/1500 loss 8.940692 loss_att 11.922925 loss_ctc 13.349878 loss_rnnt 7.723334 hw_loss 0.061913 lr 0.00029559 rank 0
2023-03-01 02:32:49,765 DEBUG TRAIN Batch 47/1500 loss 2.223615 loss_att 5.622026 loss_ctc 2.593556 loss_rnnt 1.399897 hw_loss 0.177583 lr 0.00029559 rank 5
2023-03-01 02:32:49,766 DEBUG TRAIN Batch 47/1500 loss 6.971486 loss_att 9.250248 loss_ctc 16.134483 loss_rnnt 5.258293 hw_loss 0.066953 lr 0.00029559 rank 4
2023-03-01 02:32:49,771 DEBUG TRAIN Batch 47/1500 loss 7.338060 loss_att 9.888840 loss_ctc 11.623655 loss_rnnt 6.253980 hw_loss 0.004710 lr 0.00029559 rank 2
2023-03-01 02:32:49,782 DEBUG TRAIN Batch 47/1500 loss 5.955090 loss_att 9.477920 loss_ctc 10.135754 loss_rnnt 4.585959 hw_loss 0.200892 lr 0.00029558 rank 3
2023-03-01 02:33:27,477 DEBUG TRAIN Batch 47/1600 loss 5.536119 loss_att 8.268768 loss_ctc 9.111467 loss_rnnt 4.460032 hw_loss 0.099084 lr 0.00029558 rank 1
2023-03-01 02:33:27,480 DEBUG TRAIN Batch 47/1600 loss 3.788011 loss_att 7.508666 loss_ctc 5.232291 loss_rnnt 2.729239 hw_loss 0.228882 lr 0.00029558 rank 6
2023-03-01 02:33:27,495 DEBUG TRAIN Batch 47/1600 loss 8.820682 loss_att 12.237429 loss_ctc 11.025431 loss_rnnt 7.708549 hw_loss 0.252782 lr 0.00029557 rank 7
2023-03-01 02:33:27,497 DEBUG TRAIN Batch 47/1600 loss 2.912971 loss_att 5.605238 loss_ctc 7.462721 loss_rnnt 1.674691 hw_loss 0.174737 lr 0.00029558 rank 0
2023-03-01 02:33:27,504 DEBUG TRAIN Batch 47/1600 loss 5.592664 loss_att 9.300379 loss_ctc 10.600319 loss_rnnt 4.093490 hw_loss 0.168645 lr 0.00029558 rank 4
2023-03-01 02:33:27,509 DEBUG TRAIN Batch 47/1600 loss 5.804112 loss_att 9.008032 loss_ctc 11.249573 loss_rnnt 4.294046 hw_loss 0.268536 lr 0.00029558 rank 5
2023-03-01 02:33:27,516 DEBUG TRAIN Batch 47/1600 loss 8.738087 loss_att 10.493188 loss_ctc 11.251251 loss_rnnt 7.988235 hw_loss 0.119517 lr 0.00029558 rank 2
2023-03-01 02:33:27,533 DEBUG TRAIN Batch 47/1600 loss 4.770415 loss_att 9.256799 loss_ctc 8.927683 loss_rnnt 3.190437 hw_loss 0.240748 lr 0.00029557 rank 3
2023-03-01 02:34:06,282 DEBUG TRAIN Batch 47/1700 loss 9.174447 loss_att 11.895464 loss_ctc 14.795158 loss_rnnt 7.748440 hw_loss 0.248204 lr 0.00029555 rank 7
2023-03-01 02:34:06,282 DEBUG TRAIN Batch 47/1700 loss 4.246564 loss_att 6.493903 loss_ctc 7.572578 loss_rnnt 3.285929 hw_loss 0.126937 lr 0.00029556 rank 5
2023-03-01 02:34:06,291 DEBUG TRAIN Batch 47/1700 loss 6.070824 loss_att 8.013758 loss_ctc 7.436261 loss_rnnt 5.342320 hw_loss 0.295985 lr 0.00029556 rank 4
2023-03-01 02:34:06,298 DEBUG TRAIN Batch 47/1700 loss 5.198273 loss_att 8.882331 loss_ctc 10.988305 loss_rnnt 3.505994 hw_loss 0.343993 lr 0.00029556 rank 3
2023-03-01 02:34:06,300 DEBUG TRAIN Batch 47/1700 loss 5.212267 loss_att 8.669839 loss_ctc 10.077224 loss_rnnt 3.780221 hw_loss 0.172258 lr 0.00029557 rank 1
2023-03-01 02:34:06,303 DEBUG TRAIN Batch 47/1700 loss 3.065305 loss_att 5.286146 loss_ctc 4.411010 loss_rnnt 2.258076 hw_loss 0.344313 lr 0.00029556 rank 0
2023-03-01 02:34:06,304 DEBUG TRAIN Batch 47/1700 loss 6.300033 loss_att 9.159910 loss_ctc 10.824018 loss_rnnt 4.951151 hw_loss 0.325702 lr 0.00029557 rank 2
2023-03-01 02:34:06,311 DEBUG TRAIN Batch 47/1700 loss 3.330897 loss_att 6.492098 loss_ctc 5.364170 loss_rnnt 2.249522 hw_loss 0.333810 lr 0.00029556 rank 6
2023-03-01 02:35:10,018 DEBUG TRAIN Batch 47/1800 loss 7.450079 loss_att 10.324935 loss_ctc 13.168427 loss_rnnt 6.010118 hw_loss 0.192269 lr 0.00029554 rank 7
2023-03-01 02:35:10,018 DEBUG TRAIN Batch 47/1800 loss 5.806303 loss_att 6.610714 loss_ctc 7.963329 loss_rnnt 5.165254 hw_loss 0.361055 lr 0.00029555 rank 0
2023-03-01 02:35:10,018 DEBUG TRAIN Batch 47/1800 loss 7.307291 loss_att 12.505819 loss_ctc 12.773733 loss_rnnt 5.384078 hw_loss 0.289966 lr 0.00029555 rank 4
2023-03-01 02:35:10,020 DEBUG TRAIN Batch 47/1800 loss 7.652887 loss_att 9.195352 loss_ctc 12.259793 loss_rnnt 6.595057 hw_loss 0.253281 lr 0.00029555 rank 1
2023-03-01 02:35:10,022 DEBUG TRAIN Batch 47/1800 loss 9.029019 loss_att 12.209911 loss_ctc 15.159970 loss_rnnt 7.415742 hw_loss 0.299323 lr 0.00029554 rank 3
2023-03-01 02:35:10,026 DEBUG TRAIN Batch 47/1800 loss 5.761469 loss_att 8.299148 loss_ctc 10.273715 loss_rnnt 4.542965 hw_loss 0.205005 lr 0.00029555 rank 6
2023-03-01 02:35:10,027 DEBUG TRAIN Batch 47/1800 loss 7.814998 loss_att 13.847506 loss_ctc 18.437311 loss_rnnt 5.008868 hw_loss 0.343726 lr 0.00029555 rank 2
2023-03-01 02:35:10,072 DEBUG TRAIN Batch 47/1800 loss 9.639805 loss_att 11.503597 loss_ctc 15.731246 loss_rnnt 8.304191 hw_loss 0.282493 lr 0.00029555 rank 5
2023-03-01 02:35:48,620 DEBUG TRAIN Batch 47/1900 loss 5.624197 loss_att 6.008881 loss_ctc 9.516425 loss_rnnt 4.836638 hw_loss 0.359360 lr 0.00029554 rank 4
2023-03-01 02:35:48,639 DEBUG TRAIN Batch 47/1900 loss 4.215713 loss_att 6.820220 loss_ctc 6.802513 loss_rnnt 3.189330 hw_loss 0.301077 lr 0.00029554 rank 0
2023-03-01 02:35:48,643 DEBUG TRAIN Batch 47/1900 loss 3.699706 loss_att 7.253543 loss_ctc 9.302054 loss_rnnt 2.115530 hw_loss 0.237053 lr 0.00029554 rank 5
2023-03-01 02:35:48,644 DEBUG TRAIN Batch 47/1900 loss 8.343946 loss_att 9.008367 loss_ctc 11.282771 loss_rnnt 7.652860 hw_loss 0.311922 lr 0.00029553 rank 7
2023-03-01 02:35:48,645 DEBUG TRAIN Batch 47/1900 loss 6.625560 loss_att 8.177478 loss_ctc 12.221655 loss_rnnt 5.402385 hw_loss 0.312462 lr 0.00029553 rank 3
2023-03-01 02:35:48,647 DEBUG TRAIN Batch 47/1900 loss 4.657155 loss_att 6.808928 loss_ctc 8.036069 loss_rnnt 3.607630 hw_loss 0.316215 lr 0.00029554 rank 2
2023-03-01 02:35:48,647 DEBUG TRAIN Batch 47/1900 loss 10.583917 loss_att 10.132499 loss_ctc 14.018223 loss_rnnt 10.011475 hw_loss 0.384035 lr 0.00029554 rank 6
2023-03-01 02:35:48,693 DEBUG TRAIN Batch 47/1900 loss 4.827794 loss_att 7.587411 loss_ctc 11.520756 loss_rnnt 3.247617 hw_loss 0.254734 lr 0.00029554 rank 1
2023-03-01 02:36:26,786 DEBUG TRAIN Batch 47/2000 loss 4.217261 loss_att 6.517269 loss_ctc 9.284124 loss_rnnt 2.954515 hw_loss 0.238431 lr 0.00029551 rank 7
2023-03-01 02:36:26,800 DEBUG TRAIN Batch 47/2000 loss 6.026222 loss_att 13.283291 loss_ctc 11.726511 loss_rnnt 3.716651 hw_loss 0.183972 lr 0.00029553 rank 4
2023-03-01 02:36:26,806 DEBUG TRAIN Batch 47/2000 loss 4.148802 loss_att 6.659777 loss_ctc 8.230902 loss_rnnt 2.995080 hw_loss 0.201087 lr 0.00029553 rank 2
2023-03-01 02:36:26,806 DEBUG TRAIN Batch 47/2000 loss 1.721512 loss_att 4.693630 loss_ctc 5.520900 loss_rnnt 0.495167 hw_loss 0.235006 lr 0.00029553 rank 0
2023-03-01 02:36:26,810 DEBUG TRAIN Batch 47/2000 loss 4.561978 loss_att 8.338957 loss_ctc 11.859985 loss_rnnt 2.729678 hw_loss 0.194694 lr 0.00029553 rank 1
2023-03-01 02:36:26,815 DEBUG TRAIN Batch 47/2000 loss 4.307391 loss_att 7.577982 loss_ctc 5.498837 loss_rnnt 3.339839 hw_loss 0.289825 lr 0.00029552 rank 6
2023-03-01 02:36:26,816 DEBUG TRAIN Batch 47/2000 loss 13.408442 loss_att 15.864435 loss_ctc 25.322186 loss_rnnt 11.201651 hw_loss 0.238300 lr 0.00029552 rank 3
2023-03-01 02:36:26,855 DEBUG TRAIN Batch 47/2000 loss 2.253652 loss_att 4.316791 loss_ctc 3.085084 loss_rnnt 1.618384 hw_loss 0.209591 lr 0.00029553 rank 5
2023-03-01 02:37:06,617 DEBUG TRAIN Batch 47/2100 loss 5.461140 loss_att 7.914064 loss_ctc 6.696817 loss_rnnt 4.664133 hw_loss 0.265622 lr 0.00029551 rank 2
2023-03-01 02:37:06,618 DEBUG TRAIN Batch 47/2100 loss 7.711632 loss_att 12.635975 loss_ctc 12.408237 loss_rnnt 6.006135 hw_loss 0.177026 lr 0.00029551 rank 1
2023-03-01 02:37:06,623 DEBUG TRAIN Batch 47/2100 loss 10.271139 loss_att 14.348486 loss_ctc 18.768553 loss_rnnt 8.208067 hw_loss 0.214900 lr 0.00029551 rank 6
2023-03-01 02:37:06,631 DEBUG TRAIN Batch 47/2100 loss 7.980761 loss_att 11.318895 loss_ctc 14.785490 loss_rnnt 6.256084 hw_loss 0.280786 lr 0.00029551 rank 4
2023-03-01 02:37:06,634 DEBUG TRAIN Batch 47/2100 loss 5.725455 loss_att 12.196142 loss_ctc 17.295002 loss_rnnt 2.759256 hw_loss 0.242728 lr 0.00029551 rank 0
2023-03-01 02:37:06,635 DEBUG TRAIN Batch 47/2100 loss 5.622275 loss_att 8.854114 loss_ctc 9.524476 loss_rnnt 4.427756 hw_loss 0.052236 lr 0.00029550 rank 7
2023-03-01 02:37:06,645 DEBUG TRAIN Batch 47/2100 loss 5.509723 loss_att 8.440939 loss_ctc 8.493004 loss_rnnt 4.384426 hw_loss 0.264906 lr 0.00029551 rank 3
2023-03-01 02:37:06,690 DEBUG TRAIN Batch 47/2100 loss 5.079120 loss_att 7.174150 loss_ctc 8.571815 loss_rnnt 4.062051 hw_loss 0.248194 lr 0.00029551 rank 5
2023-03-01 02:38:08,440 DEBUG TRAIN Batch 47/2200 loss 8.104409 loss_att 11.430050 loss_ctc 13.951685 loss_rnnt 6.567723 hw_loss 0.172349 lr 0.00029550 rank 1
2023-03-01 02:38:08,444 DEBUG TRAIN Batch 47/2200 loss 6.990096 loss_att 10.468859 loss_ctc 11.901482 loss_rnnt 5.525816 hw_loss 0.213141 lr 0.00029549 rank 3
2023-03-01 02:38:08,450 DEBUG TRAIN Batch 47/2200 loss 5.982496 loss_att 8.372893 loss_ctc 9.943873 loss_rnnt 4.921457 hw_loss 0.102704 lr 0.00029549 rank 7
2023-03-01 02:38:08,451 DEBUG TRAIN Batch 47/2200 loss 3.971060 loss_att 6.019790 loss_ctc 7.015863 loss_rnnt 2.990838 hw_loss 0.308442 lr 0.00029550 rank 0
2023-03-01 02:38:08,456 DEBUG TRAIN Batch 47/2200 loss 5.029522 loss_att 8.801405 loss_ctc 8.593695 loss_rnnt 3.747592 hw_loss 0.098119 lr 0.00029550 rank 4
2023-03-01 02:38:08,459 DEBUG TRAIN Batch 47/2200 loss 3.994881 loss_att 7.211267 loss_ctc 7.677469 loss_rnnt 2.722339 hw_loss 0.259226 lr 0.00029550 rank 2
2023-03-01 02:38:08,460 DEBUG TRAIN Batch 47/2200 loss 3.505147 loss_att 7.954638 loss_ctc 6.828064 loss_rnnt 2.078691 hw_loss 0.175317 lr 0.00029550 rank 5
2023-03-01 02:38:08,504 DEBUG TRAIN Batch 47/2200 loss 2.645889 loss_att 6.135369 loss_ctc 4.007520 loss_rnnt 1.589699 hw_loss 0.331394 lr 0.00029550 rank 6
2023-03-01 02:38:46,354 DEBUG TRAIN Batch 47/2300 loss 5.418353 loss_att 11.635370 loss_ctc 9.245975 loss_rnnt 3.472265 hw_loss 0.360628 lr 0.00029548 rank 7
2023-03-01 02:38:46,359 DEBUG TRAIN Batch 47/2300 loss 5.516654 loss_att 8.288956 loss_ctc 10.841518 loss_rnnt 4.120434 hw_loss 0.247081 lr 0.00029549 rank 1
2023-03-01 02:38:46,358 DEBUG TRAIN Batch 47/2300 loss 10.494075 loss_att 14.087470 loss_ctc 20.750645 loss_rnnt 8.274024 hw_loss 0.250928 lr 0.00029549 rank 6
2023-03-01 02:38:46,359 DEBUG TRAIN Batch 47/2300 loss 5.202573 loss_att 9.182865 loss_ctc 12.529235 loss_rnnt 3.350229 hw_loss 0.148870 lr 0.00029549 rank 4
2023-03-01 02:38:46,372 DEBUG TRAIN Batch 47/2300 loss 9.719317 loss_att 13.535456 loss_ctc 17.518454 loss_rnnt 7.769190 hw_loss 0.275651 lr 0.00029548 rank 3
2023-03-01 02:38:46,376 DEBUG TRAIN Batch 47/2300 loss 2.534995 loss_att 4.795424 loss_ctc 5.174921 loss_rnnt 1.580593 hw_loss 0.281860 lr 0.00029549 rank 5
2023-03-01 02:38:46,376 DEBUG TRAIN Batch 47/2300 loss 6.938384 loss_att 12.764734 loss_ctc 15.100512 loss_rnnt 4.546206 hw_loss 0.259920 lr 0.00029549 rank 2
2023-03-01 02:38:46,380 DEBUG TRAIN Batch 47/2300 loss 6.290657 loss_att 7.811356 loss_ctc 12.169635 loss_rnnt 5.024951 hw_loss 0.333192 lr 0.00029549 rank 0
2023-03-01 02:39:24,646 DEBUG TRAIN Batch 47/2400 loss 7.661793 loss_att 10.043255 loss_ctc 11.700383 loss_rnnt 6.480665 hw_loss 0.311919 lr 0.00029548 rank 2
2023-03-01 02:39:24,650 DEBUG TRAIN Batch 47/2400 loss 2.288150 loss_att 5.499816 loss_ctc 4.980163 loss_rnnt 1.198421 hw_loss 0.165866 lr 0.00029547 rank 0
2023-03-01 02:39:24,654 DEBUG TRAIN Batch 47/2400 loss 4.343329 loss_att 7.812314 loss_ctc 5.647473 loss_rnnt 3.352197 hw_loss 0.231469 lr 0.00029546 rank 7
2023-03-01 02:39:24,662 DEBUG TRAIN Batch 47/2400 loss 3.226921 loss_att 5.057836 loss_ctc 4.533611 loss_rnnt 2.597925 hw_loss 0.166101 lr 0.00029547 rank 3
2023-03-01 02:39:24,663 DEBUG TRAIN Batch 47/2400 loss 10.020888 loss_att 11.668522 loss_ctc 15.183523 loss_rnnt 8.915563 hw_loss 0.163962 lr 0.00029547 rank 4
2023-03-01 02:39:24,688 DEBUG TRAIN Batch 47/2400 loss 2.516883 loss_att 4.681570 loss_ctc 5.207322 loss_rnnt 1.523662 hw_loss 0.377922 lr 0.00029547 rank 6
2023-03-01 02:39:24,695 DEBUG TRAIN Batch 47/2400 loss 8.870347 loss_att 9.763491 loss_ctc 13.466396 loss_rnnt 7.929126 hw_loss 0.280849 lr 0.00029547 rank 5
2023-03-01 02:39:24,699 DEBUG TRAIN Batch 47/2400 loss 1.681152 loss_att 3.138326 loss_ctc 2.559669 loss_rnnt 1.109710 hw_loss 0.305384 lr 0.00029548 rank 1
2023-03-01 02:40:30,738 DEBUG TRAIN Batch 47/2500 loss 7.046728 loss_att 8.660433 loss_ctc 12.061749 loss_rnnt 5.932767 hw_loss 0.229780 lr 0.00029546 rank 4
2023-03-01 02:40:30,743 DEBUG TRAIN Batch 47/2500 loss 7.030539 loss_att 7.059211 loss_ctc 9.493591 loss_rnnt 6.498100 hw_loss 0.371809 lr 0.00029546 rank 0
2023-03-01 02:40:30,745 DEBUG TRAIN Batch 47/2500 loss 4.640696 loss_att 6.412467 loss_ctc 6.859300 loss_rnnt 3.858130 hw_loss 0.248245 lr 0.00029545 rank 7
2023-03-01 02:40:30,748 DEBUG TRAIN Batch 47/2500 loss 8.818929 loss_att 9.875385 loss_ctc 12.968253 loss_rnnt 7.946181 hw_loss 0.202899 lr 0.00029546 rank 6
2023-03-01 02:40:30,750 DEBUG TRAIN Batch 47/2500 loss 6.302250 loss_att 8.649483 loss_ctc 11.838611 loss_rnnt 4.998808 hw_loss 0.179651 lr 0.00029545 rank 3
2023-03-01 02:40:30,756 DEBUG TRAIN Batch 47/2500 loss 10.892992 loss_att 11.530577 loss_ctc 17.032568 loss_rnnt 9.833629 hw_loss 0.212318 lr 0.00029546 rank 1
2023-03-01 02:40:30,778 DEBUG TRAIN Batch 47/2500 loss 3.598685 loss_att 5.468294 loss_ctc 6.651225 loss_rnnt 2.684032 hw_loss 0.250735 lr 0.00029546 rank 5
2023-03-01 02:40:30,806 DEBUG TRAIN Batch 47/2500 loss 4.161983 loss_att 5.729491 loss_ctc 6.387201 loss_rnnt 3.464913 hw_loss 0.162886 lr 0.00029546 rank 2
2023-03-01 02:41:09,200 DEBUG TRAIN Batch 47/2600 loss 7.949760 loss_att 10.135053 loss_ctc 17.384304 loss_rnnt 6.125103 hw_loss 0.243112 lr 0.00029545 rank 5
2023-03-01 02:41:09,210 DEBUG TRAIN Batch 47/2600 loss 6.768869 loss_att 8.572533 loss_ctc 11.740501 loss_rnnt 5.583290 hw_loss 0.303678 lr 0.00029544 rank 3
2023-03-01 02:41:09,220 DEBUG TRAIN Batch 47/2600 loss 4.252487 loss_att 8.755589 loss_ctc 7.913991 loss_rnnt 2.810361 hw_loss 0.099947 lr 0.00029544 rank 7
2023-03-01 02:41:09,221 DEBUG TRAIN Batch 47/2600 loss 1.971149 loss_att 4.596984 loss_ctc 2.884081 loss_rnnt 1.207294 hw_loss 0.219305 lr 0.00029545 rank 6
2023-03-01 02:41:09,222 DEBUG TRAIN Batch 47/2600 loss 17.175169 loss_att 20.164967 loss_ctc 32.761818 loss_rnnt 14.447954 hw_loss 0.095687 lr 0.00029545 rank 1
2023-03-01 02:41:09,225 DEBUG TRAIN Batch 47/2600 loss 5.587491 loss_att 10.628924 loss_ctc 12.962851 loss_rnnt 3.461874 hw_loss 0.251154 lr 0.00029545 rank 0
2023-03-01 02:41:09,225 DEBUG TRAIN Batch 47/2600 loss 7.479342 loss_att 12.014835 loss_ctc 10.068019 loss_rnnt 6.143781 hw_loss 0.156197 lr 0.00029545 rank 4
2023-03-01 02:41:09,227 DEBUG TRAIN Batch 47/2600 loss 8.147297 loss_att 9.437599 loss_ctc 11.722502 loss_rnnt 7.324736 hw_loss 0.164637 lr 0.00029545 rank 2
2023-03-01 02:41:47,652 DEBUG TRAIN Batch 47/2700 loss 5.330438 loss_att 7.100794 loss_ctc 7.153896 loss_rnnt 4.523730 hw_loss 0.392829 lr 0.00029544 rank 0
2023-03-01 02:41:47,654 DEBUG TRAIN Batch 47/2700 loss 5.490115 loss_att 8.049481 loss_ctc 13.534870 loss_rnnt 3.715650 hw_loss 0.356170 lr 0.00029542 rank 7
2023-03-01 02:41:47,656 DEBUG TRAIN Batch 47/2700 loss 3.846097 loss_att 6.917816 loss_ctc 6.750576 loss_rnnt 2.711490 hw_loss 0.249374 lr 0.00029543 rank 6
2023-03-01 02:41:47,656 DEBUG TRAIN Batch 47/2700 loss 4.724336 loss_att 8.462446 loss_ctc 13.424576 loss_rnnt 2.716834 hw_loss 0.187214 lr 0.00029544 rank 5
2023-03-01 02:41:47,660 DEBUG TRAIN Batch 47/2700 loss 8.451038 loss_att 11.156295 loss_ctc 12.967377 loss_rnnt 7.146617 hw_loss 0.302235 lr 0.00029544 rank 1
2023-03-01 02:41:47,661 DEBUG TRAIN Batch 47/2700 loss 10.211418 loss_att 14.784401 loss_ctc 14.024693 loss_rnnt 8.687139 hw_loss 0.189836 lr 0.00029544 rank 2
2023-03-01 02:41:47,664 DEBUG TRAIN Batch 47/2700 loss 5.788481 loss_att 8.681699 loss_ctc 9.789289 loss_rnnt 4.632691 hw_loss 0.081948 lr 0.00029544 rank 4
2023-03-01 02:41:47,664 DEBUG TRAIN Batch 47/2700 loss 5.762189 loss_att 7.882017 loss_ctc 8.389694 loss_rnnt 4.888768 hw_loss 0.185852 lr 0.00029543 rank 3
2023-03-01 02:42:26,995 DEBUG TRAIN Batch 47/2800 loss 6.815150 loss_att 10.444771 loss_ctc 10.101814 loss_rnnt 5.501588 hw_loss 0.280154 lr 0.00029542 rank 0
2023-03-01 02:42:26,998 DEBUG TRAIN Batch 47/2800 loss 7.827990 loss_att 8.975243 loss_ctc 10.903884 loss_rnnt 7.101114 hw_loss 0.163699 lr 0.00029542 rank 2
2023-03-01 02:42:27,000 DEBUG TRAIN Batch 47/2800 loss 2.071334 loss_att 4.221910 loss_ctc 4.260609 loss_rnnt 1.193818 hw_loss 0.291558 lr 0.00029542 rank 4
2023-03-01 02:42:26,999 DEBUG TRAIN Batch 47/2800 loss 5.795084 loss_att 8.661667 loss_ctc 9.265659 loss_rnnt 4.648416 hw_loss 0.207391 lr 0.00029541 rank 7
2023-03-01 02:42:27,002 DEBUG TRAIN Batch 47/2800 loss 6.097225 loss_att 10.568643 loss_ctc 13.665415 loss_rnnt 4.133874 hw_loss 0.112453 lr 0.00029542 rank 1
2023-03-01 02:42:27,002 DEBUG TRAIN Batch 47/2800 loss 2.888558 loss_att 5.932092 loss_ctc 5.224959 loss_rnnt 1.903328 hw_loss 0.121882 lr 0.00029542 rank 6
2023-03-01 02:42:27,016 DEBUG TRAIN Batch 47/2800 loss 7.195214 loss_att 9.718789 loss_ctc 11.906072 loss_rnnt 5.940289 hw_loss 0.228931 lr 0.00029542 rank 5
2023-03-01 02:42:27,027 DEBUG TRAIN Batch 47/2800 loss 7.604712 loss_att 8.539808 loss_ctc 11.131216 loss_rnnt 6.783684 hw_loss 0.307140 lr 0.00029542 rank 3
2023-03-01 02:43:32,109 DEBUG TRAIN Batch 47/2900 loss 3.870792 loss_att 6.859151 loss_ctc 8.357590 loss_rnnt 2.607383 hw_loss 0.126558 lr 0.00029541 rank 0
2023-03-01 02:43:32,124 DEBUG TRAIN Batch 47/2900 loss 7.951708 loss_att 10.291308 loss_ctc 11.455985 loss_rnnt 6.955446 hw_loss 0.114571 lr 0.00029541 rank 1
2023-03-01 02:43:32,127 DEBUG TRAIN Batch 47/2900 loss 6.628822 loss_att 10.263063 loss_ctc 15.403288 loss_rnnt 4.593099 hw_loss 0.260525 lr 0.00029540 rank 7
2023-03-01 02:43:32,132 DEBUG TRAIN Batch 47/2900 loss 3.502686 loss_att 7.421121 loss_ctc 7.661451 loss_rnnt 2.075593 hw_loss 0.166696 lr 0.00029541 rank 5
2023-03-01 02:43:32,132 DEBUG TRAIN Batch 47/2900 loss 3.684194 loss_att 6.542216 loss_ctc 6.349583 loss_rnnt 2.684347 hw_loss 0.136608 lr 0.00029541 rank 4
2023-03-01 02:43:32,133 DEBUG TRAIN Batch 47/2900 loss 5.483183 loss_att 9.984016 loss_ctc 6.625575 loss_rnnt 4.326651 hw_loss 0.195086 lr 0.00029540 rank 3
2023-03-01 02:43:32,132 DEBUG TRAIN Batch 47/2900 loss 4.063937 loss_att 7.805690 loss_ctc 5.840826 loss_rnnt 2.988464 hw_loss 0.169132 lr 0.00029541 rank 6
2023-03-01 02:43:32,173 DEBUG TRAIN Batch 47/2900 loss 6.412617 loss_att 7.357913 loss_ctc 10.801360 loss_rnnt 5.529835 hw_loss 0.203543 lr 0.00029541 rank 2
2023-03-01 02:44:11,071 DEBUG TRAIN Batch 47/3000 loss 8.155176 loss_att 9.392267 loss_ctc 12.072452 loss_rnnt 7.306531 hw_loss 0.147981 lr 0.00029540 rank 2
2023-03-01 02:44:11,074 DEBUG TRAIN Batch 47/3000 loss 5.851362 loss_att 10.881948 loss_ctc 12.217344 loss_rnnt 3.813548 hw_loss 0.342937 lr 0.00029540 rank 5
2023-03-01 02:44:11,075 DEBUG TRAIN Batch 47/3000 loss 13.676023 loss_att 14.560959 loss_ctc 18.410854 loss_rnnt 12.687391 hw_loss 0.338125 lr 0.00029540 rank 4
2023-03-01 02:44:11,086 DEBUG TRAIN Batch 47/3000 loss 6.564841 loss_att 9.331923 loss_ctc 9.183952 loss_rnnt 5.516296 hw_loss 0.273591 lr 0.00029540 rank 0
2023-03-01 02:44:11,086 DEBUG TRAIN Batch 47/3000 loss 10.967235 loss_att 13.011342 loss_ctc 17.154514 loss_rnnt 9.527419 hw_loss 0.386295 lr 0.00029540 rank 1
2023-03-01 02:44:11,092 DEBUG TRAIN Batch 47/3000 loss 8.579399 loss_att 11.347344 loss_ctc 21.220589 loss_rnnt 6.190965 hw_loss 0.280037 lr 0.00029539 rank 3
2023-03-01 02:44:11,091 DEBUG TRAIN Batch 47/3000 loss 5.908854 loss_att 8.756062 loss_ctc 10.435372 loss_rnnt 4.644934 hw_loss 0.170517 lr 0.00029539 rank 7
2023-03-01 02:44:11,149 DEBUG TRAIN Batch 47/3000 loss 6.222928 loss_att 12.426006 loss_ctc 11.010458 loss_rnnt 4.259576 hw_loss 0.158247 lr 0.00029540 rank 6
2023-03-01 02:44:50,300 DEBUG TRAIN Batch 47/3100 loss 9.326850 loss_att 11.189578 loss_ctc 14.454814 loss_rnnt 8.089156 hw_loss 0.340164 lr 0.00029538 rank 6
2023-03-01 02:44:50,307 DEBUG TRAIN Batch 47/3100 loss 9.157669 loss_att 8.852819 loss_ctc 11.574882 loss_rnnt 8.726406 hw_loss 0.318632 lr 0.00029538 rank 0
2023-03-01 02:44:50,312 DEBUG TRAIN Batch 47/3100 loss 7.640005 loss_att 10.898373 loss_ctc 16.318432 loss_rnnt 5.688306 hw_loss 0.267940 lr 0.00029538 rank 4
2023-03-01 02:44:50,311 DEBUG TRAIN Batch 47/3100 loss 5.025504 loss_att 8.068404 loss_ctc 7.582179 loss_rnnt 3.994480 hw_loss 0.152913 lr 0.00029538 rank 5
2023-03-01 02:44:50,314 DEBUG TRAIN Batch 47/3100 loss 6.554059 loss_att 10.151011 loss_ctc 11.640751 loss_rnnt 4.976968 hw_loss 0.336515 lr 0.00029537 rank 7
2023-03-01 02:44:50,316 DEBUG TRAIN Batch 47/3100 loss 5.077947 loss_att 8.022434 loss_ctc 9.041111 loss_rnnt 3.872303 hw_loss 0.165608 lr 0.00029539 rank 1
2023-03-01 02:44:50,316 DEBUG TRAIN Batch 47/3100 loss 5.276169 loss_att 7.895076 loss_ctc 10.686596 loss_rnnt 3.835124 hw_loss 0.367262 lr 0.00029539 rank 2
2023-03-01 02:44:50,366 DEBUG TRAIN Batch 47/3100 loss 10.865905 loss_att 13.343575 loss_ctc 14.594400 loss_rnnt 9.792669 hw_loss 0.151067 lr 0.00029538 rank 3
2023-03-01 02:45:55,288 DEBUG TRAIN Batch 47/3200 loss 7.669832 loss_att 11.674293 loss_ctc 13.403275 loss_rnnt 6.000134 hw_loss 0.195653 lr 0.00029537 rank 4
2023-03-01 02:45:55,293 DEBUG TRAIN Batch 47/3200 loss 7.825027 loss_att 7.963405 loss_ctc 10.158181 loss_rnnt 7.286108 hw_loss 0.375293 lr 0.00029536 rank 7
2023-03-01 02:45:55,302 DEBUG TRAIN Batch 47/3200 loss 5.220215 loss_att 9.484487 loss_ctc 10.567973 loss_rnnt 3.528444 hw_loss 0.236028 lr 0.00029537 rank 5
2023-03-01 02:45:55,303 DEBUG TRAIN Batch 47/3200 loss 2.934386 loss_att 7.922057 loss_ctc 7.805073 loss_rnnt 1.105990 hw_loss 0.340195 lr 0.00029537 rank 1
2023-03-01 02:45:55,307 DEBUG TRAIN Batch 47/3200 loss 1.419307 loss_att 3.179407 loss_ctc 1.615930 loss_rnnt 0.924302 hw_loss 0.218940 lr 0.00029536 rank 3
2023-03-01 02:45:55,316 DEBUG TRAIN Batch 47/3200 loss 1.614028 loss_att 4.841963 loss_ctc 2.804515 loss_rnnt 0.712505 hw_loss 0.182257 lr 0.00029537 rank 2
2023-03-01 02:45:55,325 DEBUG TRAIN Batch 47/3200 loss 11.845337 loss_att 21.142588 loss_ctc 17.521627 loss_rnnt 9.228697 hw_loss 0.000657 lr 0.00029537 rank 0
2023-03-01 02:45:55,358 DEBUG TRAIN Batch 47/3200 loss 10.913633 loss_att 12.247386 loss_ctc 14.510178 loss_rnnt 10.053171 hw_loss 0.214074 lr 0.00029537 rank 6
2023-03-01 02:46:34,729 DEBUG TRAIN Batch 47/3300 loss 7.983887 loss_att 11.111776 loss_ctc 17.724524 loss_rnnt 5.853707 hw_loss 0.385969 lr 0.00029535 rank 7
2023-03-01 02:46:34,730 DEBUG TRAIN Batch 47/3300 loss 8.827079 loss_att 10.080860 loss_ctc 10.779875 loss_rnnt 8.239590 hw_loss 0.143176 lr 0.00029536 rank 5
2023-03-01 02:46:34,732 DEBUG TRAIN Batch 47/3300 loss 3.457053 loss_att 5.573987 loss_ctc 5.533796 loss_rnnt 2.601860 hw_loss 0.290451 lr 0.00029536 rank 1
2023-03-01 02:46:34,733 DEBUG TRAIN Batch 47/3300 loss 4.144368 loss_att 8.967402 loss_ctc 10.376857 loss_rnnt 2.212378 hw_loss 0.255721 lr 0.00029536 rank 0
2023-03-01 02:46:34,737 DEBUG TRAIN Batch 47/3300 loss 8.288542 loss_att 10.860909 loss_ctc 11.815661 loss_rnnt 7.148150 hw_loss 0.291816 lr 0.00029535 rank 3
2023-03-01 02:46:34,739 DEBUG TRAIN Batch 47/3300 loss 3.161030 loss_att 7.079523 loss_ctc 8.836178 loss_rnnt 1.421042 hw_loss 0.374254 lr 0.00029536 rank 2
2023-03-01 02:46:34,749 DEBUG TRAIN Batch 47/3300 loss 2.947587 loss_att 6.505198 loss_ctc 4.578425 loss_rnnt 1.970607 hw_loss 0.090026 lr 0.00029536 rank 6
2023-03-01 02:46:34,770 DEBUG TRAIN Batch 47/3300 loss 7.420791 loss_att 8.467413 loss_ctc 9.284005 loss_rnnt 6.833797 hw_loss 0.242327 lr 0.00029536 rank 4
2023-03-01 02:47:13,484 DEBUG TRAIN Batch 47/3400 loss 5.471340 loss_att 10.156775 loss_ctc 9.751492 loss_rnnt 3.822660 hw_loss 0.264198 lr 0.00029535 rank 4
2023-03-01 02:47:13,502 DEBUG TRAIN Batch 47/3400 loss 3.982332 loss_att 6.535275 loss_ctc 4.946738 loss_rnnt 3.303389 hw_loss 0.074563 lr 0.00029535 rank 0
2023-03-01 02:47:13,502 DEBUG TRAIN Batch 47/3400 loss 4.007048 loss_att 7.701595 loss_ctc 7.710323 loss_rnnt 2.619514 hw_loss 0.290351 lr 0.00029533 rank 7
2023-03-01 02:47:13,503 DEBUG TRAIN Batch 47/3400 loss 11.458014 loss_att 13.406275 loss_ctc 20.429382 loss_rnnt 9.812441 hw_loss 0.112008 lr 0.00029534 rank 6
2023-03-01 02:47:13,508 DEBUG TRAIN Batch 47/3400 loss 6.204890 loss_att 9.265473 loss_ctc 9.122204 loss_rnnt 5.057891 hw_loss 0.273576 lr 0.00029535 rank 1
2023-03-01 02:47:13,510 DEBUG TRAIN Batch 47/3400 loss 2.115931 loss_att 5.124205 loss_ctc 4.172431 loss_rnnt 1.081783 hw_loss 0.296801 lr 0.00029535 rank 5
2023-03-01 02:47:13,515 DEBUG TRAIN Batch 47/3400 loss 12.632109 loss_att 14.360222 loss_ctc 17.390808 loss_rnnt 11.452490 hw_loss 0.374069 lr 0.00029534 rank 3
2023-03-01 02:47:13,548 DEBUG TRAIN Batch 47/3400 loss 4.139628 loss_att 8.240176 loss_ctc 6.051610 loss_rnnt 2.943066 hw_loss 0.227850 lr 0.00029535 rank 2
2023-03-01 02:47:52,681 DEBUG TRAIN Batch 47/3500 loss 5.101411 loss_att 9.348220 loss_ctc 8.017557 loss_rnnt 3.742491 hw_loss 0.226385 lr 0.00029533 rank 3
2023-03-01 02:47:52,683 DEBUG TRAIN Batch 47/3500 loss 4.290959 loss_att 7.852876 loss_ctc 6.911835 loss_rnnt 3.090836 hw_loss 0.259293 lr 0.00029532 rank 7
2023-03-01 02:47:52,691 DEBUG TRAIN Batch 47/3500 loss 7.547977 loss_att 10.434888 loss_ctc 11.499039 loss_rnnt 6.280970 hw_loss 0.305283 lr 0.00029533 rank 2
2023-03-01 02:47:52,699 DEBUG TRAIN Batch 47/3500 loss 5.742643 loss_att 7.001428 loss_ctc 8.665985 loss_rnnt 4.940694 hw_loss 0.300775 lr 0.00029533 rank 5
2023-03-01 02:47:52,700 DEBUG TRAIN Batch 47/3500 loss 3.710883 loss_att 6.959525 loss_ctc 7.909811 loss_rnnt 2.404987 hw_loss 0.180583 lr 0.00029533 rank 0
2023-03-01 02:47:52,704 DEBUG TRAIN Batch 47/3500 loss 4.479904 loss_att 6.988843 loss_ctc 8.738081 loss_rnnt 3.327443 hw_loss 0.155467 lr 0.00029533 rank 4
2023-03-01 02:47:52,706 DEBUG TRAIN Batch 47/3500 loss 4.831382 loss_att 6.195194 loss_ctc 8.351507 loss_rnnt 3.989656 hw_loss 0.186775 lr 0.00029533 rank 1
2023-03-01 02:47:52,721 DEBUG TRAIN Batch 47/3500 loss 7.131773 loss_att 11.615027 loss_ctc 13.860198 loss_rnnt 5.337001 hw_loss 0.001870 lr 0.00029533 rank 6
2023-03-01 02:48:55,873 DEBUG TRAIN Batch 47/3600 loss 4.379101 loss_att 6.854669 loss_ctc 7.277254 loss_rnnt 3.407808 hw_loss 0.168298 lr 0.00029532 rank 1
2023-03-01 02:48:55,878 DEBUG TRAIN Batch 47/3600 loss 8.793200 loss_att 13.182044 loss_ctc 15.208817 loss_rnnt 6.933463 hw_loss 0.237286 lr 0.00029531 rank 3
2023-03-01 02:48:55,891 DEBUG TRAIN Batch 47/3600 loss 5.579839 loss_att 9.916523 loss_ctc 10.256966 loss_rnnt 3.985149 hw_loss 0.194505 lr 0.00029531 rank 7
2023-03-01 02:48:55,894 DEBUG TRAIN Batch 47/3600 loss 4.529031 loss_att 6.889630 loss_ctc 6.830601 loss_rnnt 3.572310 hw_loss 0.333235 lr 0.00029532 rank 5
2023-03-01 02:48:55,895 DEBUG TRAIN Batch 47/3600 loss 4.453802 loss_att 8.305799 loss_ctc 9.710782 loss_rnnt 2.799152 hw_loss 0.343725 lr 0.00029532 rank 2
2023-03-01 02:48:55,896 DEBUG TRAIN Batch 47/3600 loss 7.761405 loss_att 9.958934 loss_ctc 13.572016 loss_rnnt 6.360990 hw_loss 0.349051 lr 0.00029532 rank 0
2023-03-01 02:48:55,900 DEBUG TRAIN Batch 47/3600 loss 7.325617 loss_att 7.360694 loss_ctc 10.776125 loss_rnnt 6.729754 hw_loss 0.241462 lr 0.00029532 rank 6
2023-03-01 02:48:55,915 DEBUG TRAIN Batch 47/3600 loss 10.968361 loss_att 14.235164 loss_ctc 18.428272 loss_rnnt 9.185993 hw_loss 0.251911 lr 0.00029532 rank 4
2023-03-01 02:49:34,690 DEBUG TRAIN Batch 47/3700 loss 8.239326 loss_att 10.497635 loss_ctc 14.159751 loss_rnnt 6.837042 hw_loss 0.302311 lr 0.00029531 rank 5
2023-03-01 02:49:34,692 DEBUG TRAIN Batch 47/3700 loss 1.808090 loss_att 5.085840 loss_ctc 4.682888 loss_rnnt 0.699259 hw_loss 0.131204 lr 0.00029531 rank 2
2023-03-01 02:49:34,697 DEBUG TRAIN Batch 47/3700 loss 5.825807 loss_att 6.994610 loss_ctc 8.433602 loss_rnnt 5.120831 hw_loss 0.231578 lr 0.00029531 rank 4
2023-03-01 02:49:34,699 DEBUG TRAIN Batch 47/3700 loss 6.658040 loss_att 8.443911 loss_ctc 8.175488 loss_rnnt 5.926869 hw_loss 0.321880 lr 0.00029530 rank 3
2023-03-01 02:49:34,699 DEBUG TRAIN Batch 47/3700 loss 1.961383 loss_att 4.568273 loss_ctc 6.151744 loss_rnnt 0.775934 hw_loss 0.197542 lr 0.00029530 rank 6
2023-03-01 02:49:34,712 DEBUG TRAIN Batch 47/3700 loss 5.849796 loss_att 8.964523 loss_ctc 10.027913 loss_rnnt 4.518002 hw_loss 0.284562 lr 0.00029531 rank 0
2023-03-01 02:49:34,713 DEBUG TRAIN Batch 47/3700 loss 3.704298 loss_att 7.187344 loss_ctc 5.686590 loss_rnnt 2.546127 hw_loss 0.369857 lr 0.00029530 rank 7
2023-03-01 02:49:34,718 DEBUG TRAIN Batch 47/3700 loss 1.960568 loss_att 4.230723 loss_ctc 2.729831 loss_rnnt 1.250867 hw_loss 0.287064 lr 0.00029531 rank 1
2023-03-01 02:50:13,956 DEBUG TRAIN Batch 47/3800 loss 4.363256 loss_att 6.657836 loss_ctc 8.417627 loss_rnnt 3.258573 hw_loss 0.197221 lr 0.00029529 rank 6
2023-03-01 02:50:13,961 DEBUG TRAIN Batch 47/3800 loss 4.785233 loss_att 7.855130 loss_ctc 7.371772 loss_rnnt 3.693493 hw_loss 0.249164 lr 0.00029529 rank 3
2023-03-01 02:50:13,972 DEBUG TRAIN Batch 47/3800 loss 5.237164 loss_att 6.484397 loss_ctc 7.329972 loss_rnnt 4.574242 hw_loss 0.252066 lr 0.00029528 rank 7
2023-03-01 02:50:13,974 DEBUG TRAIN Batch 47/3800 loss 8.444059 loss_att 9.097527 loss_ctc 13.633904 loss_rnnt 7.424778 hw_loss 0.368640 lr 0.00029529 rank 0
2023-03-01 02:50:13,975 DEBUG TRAIN Batch 47/3800 loss 6.646576 loss_att 8.778749 loss_ctc 11.992697 loss_rnnt 5.332504 hw_loss 0.327790 lr 0.00029530 rank 2
2023-03-01 02:50:13,976 DEBUG TRAIN Batch 47/3800 loss 4.707533 loss_att 5.408621 loss_ctc 8.136244 loss_rnnt 3.980419 hw_loss 0.243252 lr 0.00029530 rank 1
2023-03-01 02:50:13,976 DEBUG TRAIN Batch 47/3800 loss 2.836089 loss_att 5.563475 loss_ctc 3.398132 loss_rnnt 2.087324 hw_loss 0.240654 lr 0.00029529 rank 4
2023-03-01 02:50:13,977 DEBUG TRAIN Batch 47/3800 loss 1.177639 loss_att 3.767310 loss_ctc 2.612187 loss_rnnt 0.370896 hw_loss 0.182878 lr 0.00029529 rank 5
2023-03-01 02:51:18,590 DEBUG TRAIN Batch 47/3900 loss 6.023757 loss_att 8.564386 loss_ctc 11.489134 loss_rnnt 4.692050 hw_loss 0.177873 lr 0.00029528 rank 0
2023-03-01 02:51:18,601 DEBUG TRAIN Batch 47/3900 loss 4.790483 loss_att 10.138389 loss_ctc 8.457648 loss_rnnt 3.026478 hw_loss 0.385255 lr 0.00029528 rank 2
2023-03-01 02:51:18,603 DEBUG TRAIN Batch 47/3900 loss 4.358822 loss_att 7.392491 loss_ctc 7.875052 loss_rnnt 3.163686 hw_loss 0.224198 lr 0.00029528 rank 1
2023-03-01 02:51:18,621 DEBUG TRAIN Batch 47/3900 loss 4.466602 loss_att 6.441258 loss_ctc 5.743152 loss_rnnt 3.795263 hw_loss 0.199127 lr 0.00029528 rank 4
2023-03-01 02:51:18,629 DEBUG TRAIN Batch 47/3900 loss 5.339479 loss_att 7.288373 loss_ctc 6.763173 loss_rnnt 4.583480 hw_loss 0.330740 lr 0.00029528 rank 6
2023-03-01 02:51:18,637 DEBUG TRAIN Batch 47/3900 loss 7.560377 loss_att 11.298188 loss_ctc 12.724075 loss_rnnt 6.057043 hw_loss 0.126147 lr 0.00029527 rank 7
2023-03-01 02:51:18,647 DEBUG TRAIN Batch 47/3900 loss 9.971518 loss_att 15.695194 loss_ctc 21.777517 loss_rnnt 7.186625 hw_loss 0.123794 lr 0.00029528 rank 5
2023-03-01 02:51:18,664 DEBUG TRAIN Batch 47/3900 loss 6.988071 loss_att 7.237269 loss_ctc 9.827950 loss_rnnt 6.350658 hw_loss 0.391730 lr 0.00029527 rank 3
2023-03-01 02:51:57,591 DEBUG TRAIN Batch 47/4000 loss 0.752841 loss_att 2.551456 loss_ctc 0.648612 loss_rnnt 0.314351 hw_loss 0.173744 lr 0.00029527 rank 6
2023-03-01 02:51:57,596 DEBUG TRAIN Batch 47/4000 loss 5.009828 loss_att 7.788733 loss_ctc 9.066159 loss_rnnt 3.834227 hw_loss 0.148079 lr 0.00029526 rank 3
2023-03-01 02:51:57,597 DEBUG TRAIN Batch 47/4000 loss 3.016021 loss_att 5.424211 loss_ctc 4.510903 loss_rnnt 2.260245 hw_loss 0.140287 lr 0.00029527 rank 4
2023-03-01 02:51:57,610 DEBUG TRAIN Batch 47/4000 loss 2.324153 loss_att 4.763895 loss_ctc 3.556371 loss_rnnt 1.559012 hw_loss 0.211682 lr 0.00029527 rank 1
2023-03-01 02:51:57,616 DEBUG TRAIN Batch 47/4000 loss 1.385572 loss_att 3.323629 loss_ctc 3.603806 loss_rnnt 0.503422 hw_loss 0.372702 lr 0.00029526 rank 7
2023-03-01 02:51:57,617 DEBUG TRAIN Batch 47/4000 loss 10.776152 loss_att 14.177514 loss_ctc 17.658924 loss_rnnt 9.106185 hw_loss 0.134987 lr 0.00029527 rank 0
2023-03-01 02:51:57,617 DEBUG TRAIN Batch 47/4000 loss 3.684060 loss_att 5.619637 loss_ctc 6.082461 loss_rnnt 2.907102 hw_loss 0.131354 lr 0.00029527 rank 2
2023-03-01 02:51:57,657 DEBUG TRAIN Batch 47/4000 loss 1.061568 loss_att 3.003421 loss_ctc 1.259441 loss_rnnt 0.581324 hw_loss 0.122793 lr 0.00029527 rank 5
2023-03-01 02:52:35,694 DEBUG TRAIN Batch 47/4100 loss 3.646178 loss_att 7.223020 loss_ctc 7.156148 loss_rnnt 2.273698 hw_loss 0.354593 lr 0.00029525 rank 3
2023-03-01 02:52:35,709 DEBUG TRAIN Batch 47/4100 loss 6.506415 loss_att 8.982229 loss_ctc 12.961416 loss_rnnt 4.994450 hw_loss 0.292755 lr 0.00029526 rank 2
2023-03-01 02:52:35,710 DEBUG TRAIN Batch 47/4100 loss 5.903715 loss_att 10.489456 loss_ctc 9.434249 loss_rnnt 4.396295 hw_loss 0.224125 lr 0.00029525 rank 5
2023-03-01 02:52:35,711 DEBUG TRAIN Batch 47/4100 loss 4.559745 loss_att 8.615853 loss_ctc 10.574554 loss_rnnt 2.803233 hw_loss 0.268715 lr 0.00029524 rank 7
2023-03-01 02:52:35,711 DEBUG TRAIN Batch 47/4100 loss 4.903101 loss_att 9.338729 loss_ctc 10.141045 loss_rnnt 3.242463 hw_loss 0.140852 lr 0.00029525 rank 4
2023-03-01 02:52:35,713 DEBUG TRAIN Batch 47/4100 loss 9.033481 loss_att 10.711141 loss_ctc 12.888470 loss_rnnt 8.085327 hw_loss 0.184917 lr 0.00029526 rank 0
2023-03-01 02:52:35,713 DEBUG TRAIN Batch 47/4100 loss 16.751425 loss_att 18.625317 loss_ctc 22.085930 loss_rnnt 15.486563 hw_loss 0.335277 lr 0.00029525 rank 6
2023-03-01 02:52:35,719 DEBUG TRAIN Batch 47/4100 loss 10.196572 loss_att 11.699869 loss_ctc 14.464194 loss_rnnt 9.168497 hw_loss 0.297000 lr 0.00029526 rank 1
2023-03-01 02:53:14,928 DEBUG TRAIN Batch 47/4200 loss 8.264841 loss_att 12.218401 loss_ctc 17.104229 loss_rnnt 6.194343 hw_loss 0.189752 lr 0.00029524 rank 0
2023-03-01 02:53:14,930 DEBUG TRAIN Batch 47/4200 loss 10.831289 loss_att 15.323186 loss_ctc 21.885023 loss_rnnt 8.397211 hw_loss 0.116003 lr 0.00029524 rank 2
2023-03-01 02:53:14,934 DEBUG TRAIN Batch 47/4200 loss 5.175711 loss_att 8.662485 loss_ctc 10.765936 loss_rnnt 3.579018 hw_loss 0.288702 lr 0.00029524 rank 3
2023-03-01 02:53:14,941 DEBUG TRAIN Batch 47/4200 loss 2.314350 loss_att 4.305119 loss_ctc 3.397513 loss_rnnt 1.556032 hw_loss 0.404518 lr 0.00029524 rank 6
2023-03-01 02:53:14,944 DEBUG TRAIN Batch 47/4200 loss 8.923124 loss_att 13.566903 loss_ctc 16.621548 loss_rnnt 6.853560 hw_loss 0.214410 lr 0.00029524 rank 4
2023-03-01 02:53:14,944 DEBUG TRAIN Batch 47/4200 loss 5.709424 loss_att 9.871982 loss_ctc 10.895227 loss_rnnt 3.986678 hw_loss 0.372739 lr 0.00029523 rank 7
2023-03-01 02:53:14,947 DEBUG TRAIN Batch 47/4200 loss 2.582764 loss_att 5.694816 loss_ctc 3.889765 loss_rnnt 1.635657 hw_loss 0.282056 lr 0.00029524 rank 1
2023-03-01 02:53:14,992 DEBUG TRAIN Batch 47/4200 loss 2.826724 loss_att 5.196871 loss_ctc 6.948328 loss_rnnt 1.675355 hw_loss 0.239612 lr 0.00029524 rank 5
2023-03-01 02:54:19,212 DEBUG TRAIN Batch 47/4300 loss 4.846549 loss_att 9.370642 loss_ctc 8.767658 loss_rnnt 3.333256 hw_loss 0.160611 lr 0.00029523 rank 6
2023-03-01 02:54:19,228 DEBUG TRAIN Batch 47/4300 loss 7.328746 loss_att 8.405776 loss_ctc 13.201458 loss_rnnt 6.167150 hw_loss 0.305929 lr 0.00029522 rank 7
2023-03-01 02:54:19,229 DEBUG TRAIN Batch 47/4300 loss 6.794498 loss_att 11.451273 loss_ctc 10.089802 loss_rnnt 5.302817 hw_loss 0.226787 lr 0.00029523 rank 0
2023-03-01 02:54:19,229 DEBUG TRAIN Batch 47/4300 loss 7.728174 loss_att 13.884268 loss_ctc 18.739820 loss_rnnt 4.856750 hw_loss 0.322472 lr 0.00029523 rank 1
2023-03-01 02:54:19,229 DEBUG TRAIN Batch 47/4300 loss 6.003842 loss_att 7.691724 loss_ctc 7.498349 loss_rnnt 5.311790 hw_loss 0.291014 lr 0.00029523 rank 5
2023-03-01 02:54:19,230 DEBUG TRAIN Batch 47/4300 loss 10.630306 loss_att 12.283229 loss_ctc 16.736872 loss_rnnt 9.362073 hw_loss 0.231450 lr 0.00029523 rank 4
2023-03-01 02:54:19,231 DEBUG TRAIN Batch 47/4300 loss 6.655935 loss_att 8.095943 loss_ctc 10.781370 loss_rnnt 5.746955 hw_loss 0.132975 lr 0.00029522 rank 3
2023-03-01 02:54:19,265 DEBUG TRAIN Batch 47/4300 loss 4.212403 loss_att 6.895358 loss_ctc 7.972368 loss_rnnt 3.016817 hw_loss 0.295625 lr 0.00029523 rank 2
2023-03-01 02:54:58,303 DEBUG TRAIN Batch 47/4400 loss 7.916332 loss_att 9.082506 loss_ctc 13.132561 loss_rnnt 6.840328 hw_loss 0.276134 lr 0.00029521 rank 6
2023-03-01 02:54:58,310 DEBUG TRAIN Batch 47/4400 loss 4.639102 loss_att 6.841394 loss_ctc 9.095517 loss_rnnt 3.473679 hw_loss 0.245205 lr 0.00029522 rank 5
2023-03-01 02:54:58,311 DEBUG TRAIN Batch 47/4400 loss 3.246141 loss_att 4.986545 loss_ctc 5.180079 loss_rnnt 2.471412 hw_loss 0.316480 lr 0.00029522 rank 2
2023-03-01 02:54:58,314 DEBUG TRAIN Batch 47/4400 loss 4.654612 loss_att 6.086029 loss_ctc 8.280257 loss_rnnt 3.752808 hw_loss 0.247689 lr 0.00029521 rank 7
2023-03-01 02:54:58,316 DEBUG TRAIN Batch 47/4400 loss 8.042815 loss_att 9.680496 loss_ctc 14.388190 loss_rnnt 6.678775 hw_loss 0.357102 lr 0.00029522 rank 0
2023-03-01 02:54:58,347 DEBUG TRAIN Batch 47/4400 loss 5.801358 loss_att 7.058444 loss_ctc 10.001326 loss_rnnt 4.814054 hw_loss 0.329795 lr 0.00029522 rank 1
2023-03-01 02:54:58,352 DEBUG TRAIN Batch 47/4400 loss 6.339034 loss_att 8.630945 loss_ctc 10.422560 loss_rnnt 5.185991 hw_loss 0.281608 lr 0.00029522 rank 4
2023-03-01 02:54:58,358 DEBUG TRAIN Batch 47/4400 loss 4.244806 loss_att 9.297038 loss_ctc 7.978172 loss_rnnt 2.636621 hw_loss 0.187418 lr 0.00029521 rank 3
2023-03-01 02:55:37,743 DEBUG TRAIN Batch 47/4500 loss 2.881432 loss_att 5.096966 loss_ctc 4.201070 loss_rnnt 2.158696 hw_loss 0.194395 lr 0.00029519 rank 7
2023-03-01 02:55:37,744 DEBUG TRAIN Batch 47/4500 loss 3.727889 loss_att 6.729272 loss_ctc 4.169971 loss_rnnt 3.041520 hw_loss 0.050902 lr 0.00029521 rank 2
2023-03-01 02:55:37,751 DEBUG TRAIN Batch 47/4500 loss 2.225046 loss_att 5.992840 loss_ctc 4.030976 loss_rnnt 1.129834 hw_loss 0.189117 lr 0.00029520 rank 4
2023-03-01 02:55:37,751 DEBUG TRAIN Batch 47/4500 loss 1.179649 loss_att 3.439933 loss_ctc 1.934107 loss_rnnt 0.481026 hw_loss 0.273697 lr 0.00029520 rank 5
2023-03-01 02:55:37,766 DEBUG TRAIN Batch 47/4500 loss 2.519626 loss_att 7.087384 loss_ctc 5.117498 loss_rnnt 1.094429 hw_loss 0.309867 lr 0.00029520 rank 0
2023-03-01 02:55:37,772 DEBUG TRAIN Batch 47/4500 loss 9.139747 loss_att 12.064859 loss_ctc 17.245808 loss_rnnt 7.370895 hw_loss 0.193165 lr 0.00029521 rank 1
2023-03-01 02:55:37,777 DEBUG TRAIN Batch 47/4500 loss 9.586544 loss_att 13.210729 loss_ctc 15.305559 loss_rnnt 7.985913 hw_loss 0.212360 lr 0.00029520 rank 3
2023-03-01 02:55:37,812 DEBUG TRAIN Batch 47/4500 loss 5.928990 loss_att 8.173912 loss_ctc 8.475365 loss_rnnt 5.016457 hw_loss 0.232561 lr 0.00029520 rank 6
2023-03-01 02:56:18,093 DEBUG TRAIN Batch 47/4600 loss 6.920725 loss_att 8.070532 loss_ctc 9.318516 loss_rnnt 6.249584 hw_loss 0.227765 lr 0.00029519 rank 4
2023-03-01 02:56:18,095 DEBUG TRAIN Batch 47/4600 loss 6.922508 loss_att 9.639955 loss_ctc 9.768554 loss_rnnt 5.858649 hw_loss 0.264181 lr 0.00029519 rank 2
2023-03-01 02:56:18,105 DEBUG TRAIN Batch 47/4600 loss 3.877307 loss_att 6.456880 loss_ctc 7.042451 loss_rnnt 2.852385 hw_loss 0.163101 lr 0.00029518 rank 7
2023-03-01 02:56:18,107 DEBUG TRAIN Batch 47/4600 loss 5.596515 loss_att 6.269188 loss_ctc 7.544959 loss_rnnt 5.042637 hw_loss 0.299156 lr 0.00029519 rank 0
2023-03-01 02:56:18,112 DEBUG TRAIN Batch 47/4600 loss 3.433188 loss_att 6.503723 loss_ctc 3.777791 loss_rnnt 2.682729 hw_loss 0.169509 lr 0.00029519 rank 6
2023-03-01 02:56:18,114 DEBUG TRAIN Batch 47/4600 loss 3.826897 loss_att 6.180433 loss_ctc 8.281258 loss_rnnt 2.686026 hw_loss 0.142967 lr 0.00029519 rank 5
2023-03-01 02:56:18,113 DEBUG TRAIN Batch 47/4600 loss 7.824654 loss_att 9.863327 loss_ctc 8.784910 loss_rnnt 7.157056 hw_loss 0.247179 lr 0.00029518 rank 3
2023-03-01 02:56:18,133 DEBUG TRAIN Batch 47/4600 loss 6.222694 loss_att 7.571217 loss_ctc 7.932009 loss_rnnt 5.543788 hw_loss 0.339923 lr 0.00029519 rank 1
2023-03-01 02:57:21,697 DEBUG TRAIN Batch 47/4700 loss 5.045086 loss_att 7.236738 loss_ctc 6.861031 loss_rnnt 4.272859 hw_loss 0.172071 lr 0.00029517 rank 3
2023-03-01 02:57:21,709 DEBUG TRAIN Batch 47/4700 loss 3.739388 loss_att 7.278034 loss_ctc 9.031645 loss_rnnt 2.261905 hw_loss 0.120223 lr 0.00029518 rank 2
2023-03-01 02:57:21,711 DEBUG TRAIN Batch 47/4700 loss 8.852186 loss_att 10.971639 loss_ctc 15.432570 loss_rnnt 7.441904 hw_loss 0.204390 lr 0.00029518 rank 4
2023-03-01 02:57:21,713 DEBUG TRAIN Batch 47/4700 loss 3.102276 loss_att 5.049453 loss_ctc 4.224943 loss_rnnt 2.415085 hw_loss 0.277624 lr 0.00029517 rank 7
2023-03-01 02:57:21,715 DEBUG TRAIN Batch 47/4700 loss 3.689490 loss_att 5.232060 loss_ctc 6.973633 loss_rnnt 2.804048 hw_loss 0.260703 lr 0.00029518 rank 5
2023-03-01 02:57:21,714 DEBUG TRAIN Batch 47/4700 loss 6.506657 loss_att 7.912011 loss_ctc 10.108322 loss_rnnt 5.584208 hw_loss 0.302168 lr 0.00029518 rank 1
2023-03-01 02:57:21,718 DEBUG TRAIN Batch 47/4700 loss 5.030059 loss_att 6.695799 loss_ctc 7.651988 loss_rnnt 4.256055 hw_loss 0.171123 lr 0.00029518 rank 6
2023-03-01 02:57:21,723 DEBUG TRAIN Batch 47/4700 loss 3.966738 loss_att 6.575655 loss_ctc 6.529363 loss_rnnt 2.906680 hw_loss 0.368609 lr 0.00029518 rank 0
2023-03-01 02:58:00,432 DEBUG TRAIN Batch 47/4800 loss 4.371875 loss_att 7.884667 loss_ctc 5.245131 loss_rnnt 3.412142 hw_loss 0.263889 lr 0.00029517 rank 2
2023-03-01 02:58:00,438 DEBUG TRAIN Batch 47/4800 loss 5.306039 loss_att 7.788553 loss_ctc 10.762856 loss_rnnt 3.983361 hw_loss 0.184874 lr 0.00029516 rank 5
2023-03-01 02:58:00,445 DEBUG TRAIN Batch 47/4800 loss 6.335540 loss_att 8.801892 loss_ctc 10.067511 loss_rnnt 5.198390 hw_loss 0.274281 lr 0.00029515 rank 7
2023-03-01 02:58:00,448 DEBUG TRAIN Batch 47/4800 loss 5.448907 loss_att 10.598203 loss_ctc 15.408869 loss_rnnt 2.989308 hw_loss 0.190770 lr 0.00029517 rank 0
2023-03-01 02:58:00,452 DEBUG TRAIN Batch 47/4800 loss 7.193701 loss_att 10.345139 loss_ctc 11.358448 loss_rnnt 5.908602 hw_loss 0.186585 lr 0.00029517 rank 1
2023-03-01 02:58:00,453 DEBUG TRAIN Batch 47/4800 loss 7.345072 loss_att 11.164658 loss_ctc 9.969521 loss_rnnt 6.093537 hw_loss 0.258170 lr 0.00029516 rank 3
2023-03-01 02:58:00,455 DEBUG TRAIN Batch 47/4800 loss 7.003840 loss_att 7.940987 loss_ctc 11.770487 loss_rnnt 6.112607 hw_loss 0.127969 lr 0.00029516 rank 4
2023-03-01 02:58:00,470 DEBUG TRAIN Batch 47/4800 loss 6.343520 loss_att 8.912170 loss_ctc 7.665195 loss_rnnt 5.533404 hw_loss 0.225306 lr 0.00029516 rank 6
2023-03-01 02:58:39,877 DEBUG TRAIN Batch 47/4900 loss 10.342760 loss_att 13.439650 loss_ctc 21.497625 loss_rnnt 8.102673 hw_loss 0.250116 lr 0.00029515 rank 2
2023-03-01 02:58:39,879 DEBUG TRAIN Batch 47/4900 loss 7.167667 loss_att 10.540300 loss_ctc 13.401482 loss_rnnt 5.641755 hw_loss 0.037894 lr 0.00029515 rank 0
2023-03-01 02:58:39,880 DEBUG TRAIN Batch 47/4900 loss 8.428727 loss_att 10.705433 loss_ctc 11.103992 loss_rnnt 7.448266 hw_loss 0.315784 lr 0.00029515 rank 1
2023-03-01 02:58:39,890 DEBUG TRAIN Batch 47/4900 loss 8.351734 loss_att 11.810863 loss_ctc 11.341445 loss_rnnt 7.115216 hw_loss 0.273870 lr 0.00029515 rank 6
2023-03-01 02:58:39,890 DEBUG TRAIN Batch 47/4900 loss 4.818048 loss_att 7.663236 loss_ctc 7.728494 loss_rnnt 3.755120 hw_loss 0.198432 lr 0.00029514 rank 7
2023-03-01 02:58:39,890 DEBUG TRAIN Batch 47/4900 loss 2.062774 loss_att 5.541930 loss_ctc 5.072141 loss_rnnt 0.890376 hw_loss 0.141221 lr 0.00029515 rank 4
2023-03-01 02:58:39,905 DEBUG TRAIN Batch 47/4900 loss 12.865711 loss_att 17.273621 loss_ctc 22.514448 loss_rnnt 10.545626 hw_loss 0.285009 lr 0.00029515 rank 5
2023-03-01 02:58:39,917 DEBUG TRAIN Batch 47/4900 loss 5.951776 loss_att 7.886123 loss_ctc 6.505950 loss_rnnt 5.449617 hw_loss 0.077624 lr 0.00029515 rank 3
2023-03-01 02:59:44,301 DEBUG TRAIN Batch 47/5000 loss 5.293476 loss_att 6.273423 loss_ctc 7.234676 loss_rnnt 4.795995 hw_loss 0.079996 lr 0.00029513 rank 7
2023-03-01 02:59:44,308 DEBUG TRAIN Batch 47/5000 loss 3.907981 loss_att 6.038898 loss_ctc 9.765640 loss_rnnt 2.564394 hw_loss 0.255717 lr 0.00029514 rank 5
2023-03-01 02:59:44,309 DEBUG TRAIN Batch 47/5000 loss 6.155466 loss_att 9.514198 loss_ctc 12.920420 loss_rnnt 4.424794 hw_loss 0.294246 lr 0.00029514 rank 0
2023-03-01 02:59:44,319 DEBUG TRAIN Batch 47/5000 loss 5.489805 loss_att 7.658407 loss_ctc 7.453465 loss_rnnt 4.638521 hw_loss 0.292016 lr 0.00029513 rank 3
2023-03-01 02:59:44,324 DEBUG TRAIN Batch 47/5000 loss 8.447487 loss_att 10.881145 loss_ctc 8.136127 loss_rnnt 7.889629 hw_loss 0.211204 lr 0.00029514 rank 6
2023-03-01 02:59:44,344 DEBUG TRAIN Batch 47/5000 loss 11.643202 loss_att 15.789036 loss_ctc 22.522949 loss_rnnt 9.196560 hw_loss 0.312826 lr 0.00029514 rank 1
2023-03-01 02:59:44,351 DEBUG TRAIN Batch 47/5000 loss 4.125490 loss_att 7.520028 loss_ctc 12.616144 loss_rnnt 2.209162 hw_loss 0.197500 lr 0.00029514 rank 4
2023-03-01 02:59:44,375 DEBUG TRAIN Batch 47/5000 loss 5.527325 loss_att 6.785866 loss_ctc 7.758811 loss_rnnt 4.836229 hw_loss 0.265982 lr 0.00029514 rank 2
2023-03-01 03:00:23,293 DEBUG TRAIN Batch 47/5100 loss 7.778624 loss_att 9.065020 loss_ctc 10.410289 loss_rnnt 6.948599 hw_loss 0.415981 lr 0.00029513 rank 0
2023-03-01 03:00:23,298 DEBUG TRAIN Batch 47/5100 loss 4.694765 loss_att 5.622142 loss_ctc 7.823606 loss_rnnt 3.871266 hw_loss 0.414083 lr 0.00029512 rank 7
2023-03-01 03:00:23,298 DEBUG TRAIN Batch 47/5100 loss 2.035518 loss_att 5.962766 loss_ctc 3.517951 loss_rnnt 0.879109 hw_loss 0.324939 lr 0.00029513 rank 2
2023-03-01 03:00:23,299 DEBUG TRAIN Batch 47/5100 loss 4.561585 loss_att 7.387429 loss_ctc 9.157418 loss_rnnt 3.305326 hw_loss 0.146837 lr 0.00029512 rank 3
2023-03-01 03:00:23,300 DEBUG TRAIN Batch 47/5100 loss 5.430918 loss_att 9.946501 loss_ctc 12.479674 loss_rnnt 3.471532 hw_loss 0.218316 lr 0.00029513 rank 4
2023-03-01 03:00:23,302 DEBUG TRAIN Batch 47/5100 loss 6.555678 loss_att 8.048450 loss_ctc 7.989980 loss_rnnt 5.778106 hw_loss 0.539583 lr 0.00029513 rank 5
2023-03-01 03:00:23,303 DEBUG TRAIN Batch 47/5100 loss 8.450974 loss_att 10.342934 loss_ctc 12.517040 loss_rnnt 7.447395 hw_loss 0.155705 lr 0.00029512 rank 6
2023-03-01 03:00:23,344 DEBUG TRAIN Batch 47/5100 loss 3.700242 loss_att 5.059174 loss_ctc 7.524250 loss_rnnt 2.794115 hw_loss 0.233388 lr 0.00029513 rank 1
2023-03-01 03:01:02,077 DEBUG TRAIN Batch 47/5200 loss 6.119854 loss_att 8.051373 loss_ctc 9.959477 loss_rnnt 5.043120 hw_loss 0.334652 lr 0.00029511 rank 4
2023-03-01 03:01:02,077 DEBUG TRAIN Batch 47/5200 loss 4.401496 loss_att 7.917017 loss_ctc 6.394128 loss_rnnt 3.273438 hw_loss 0.298629 lr 0.00029512 rank 1
2023-03-01 03:01:02,081 DEBUG TRAIN Batch 47/5200 loss 3.370936 loss_att 5.499177 loss_ctc 4.863698 loss_rnnt 2.673706 hw_loss 0.136027 lr 0.00029510 rank 7
2023-03-01 03:01:02,082 DEBUG TRAIN Batch 47/5200 loss 7.459548 loss_att 10.118600 loss_ctc 12.930067 loss_rnnt 6.041228 hw_loss 0.294575 lr 0.00029511 rank 0
2023-03-01 03:01:02,083 DEBUG TRAIN Batch 47/5200 loss 4.882709 loss_att 5.955801 loss_ctc 8.092674 loss_rnnt 4.119170 hw_loss 0.226733 lr 0.00029511 rank 6
2023-03-01 03:01:02,084 DEBUG TRAIN Batch 47/5200 loss 7.011714 loss_att 11.344851 loss_ctc 13.258719 loss_rnnt 5.196601 hw_loss 0.216657 lr 0.00029511 rank 5
2023-03-01 03:01:02,088 DEBUG TRAIN Batch 47/5200 loss 8.052967 loss_att 7.952027 loss_ctc 9.816054 loss_rnnt 7.564770 hw_loss 0.512450 lr 0.00029511 rank 3
2023-03-01 03:01:02,089 DEBUG TRAIN Batch 47/5200 loss 7.610438 loss_att 12.001877 loss_ctc 15.239044 loss_rnnt 5.600859 hw_loss 0.214021 lr 0.00029512 rank 2
2023-03-01 03:01:41,921 DEBUG TRAIN Batch 47/5300 loss 9.746647 loss_att 14.217068 loss_ctc 20.721722 loss_rnnt 7.299079 hw_loss 0.169014 lr 0.00029509 rank 3
2023-03-01 03:01:41,925 DEBUG TRAIN Batch 47/5300 loss 7.054581 loss_att 14.226666 loss_ctc 17.725910 loss_rnnt 4.061761 hw_loss 0.254174 lr 0.00029510 rank 1
2023-03-01 03:01:41,928 DEBUG TRAIN Batch 47/5300 loss 10.615330 loss_att 12.192045 loss_ctc 13.728812 loss_rnnt 9.773855 hw_loss 0.208126 lr 0.00029510 rank 4
2023-03-01 03:01:41,931 DEBUG TRAIN Batch 47/5300 loss 7.445994 loss_att 12.973343 loss_ctc 13.678444 loss_rnnt 5.400245 hw_loss 0.204912 lr 0.00029509 rank 7
2023-03-01 03:01:41,932 DEBUG TRAIN Batch 47/5300 loss 2.135026 loss_att 5.638007 loss_ctc 6.224883 loss_rnnt 0.671428 hw_loss 0.408162 lr 0.00029510 rank 0
2023-03-01 03:01:41,932 DEBUG TRAIN Batch 47/5300 loss 4.688184 loss_att 9.494401 loss_ctc 8.137978 loss_rnnt 3.238844 hw_loss 0.052733 lr 0.00029510 rank 5
2023-03-01 03:01:41,952 DEBUG TRAIN Batch 47/5300 loss 7.441752 loss_att 11.279093 loss_ctc 13.641761 loss_rnnt 5.731391 hw_loss 0.217922 lr 0.00029510 rank 6
2023-03-01 03:01:41,960 DEBUG TRAIN Batch 47/5300 loss 2.915505 loss_att 5.703516 loss_ctc 4.489024 loss_rnnt 1.971954 hw_loss 0.330275 lr 0.00029510 rank 2
2023-03-01 03:02:45,934 DEBUG TRAIN Batch 47/5400 loss 12.942274 loss_att 15.441709 loss_ctc 17.946812 loss_rnnt 11.613596 hw_loss 0.302847 lr 0.00029509 rank 0
2023-03-01 03:02:45,934 DEBUG TRAIN Batch 47/5400 loss 4.110171 loss_att 7.016414 loss_ctc 5.944861 loss_rnnt 3.088912 hw_loss 0.366347 lr 0.00029509 rank 2
2023-03-01 03:02:45,936 DEBUG TRAIN Batch 47/5400 loss 7.854727 loss_att 12.292128 loss_ctc 12.269325 loss_rnnt 6.341210 hw_loss 0.070169 lr 0.00029508 rank 7
2023-03-01 03:02:45,936 DEBUG TRAIN Batch 47/5400 loss 4.043448 loss_att 7.569463 loss_ctc 6.491896 loss_rnnt 2.958228 hw_loss 0.100422 lr 0.00029508 rank 3
2023-03-01 03:02:45,939 DEBUG TRAIN Batch 47/5400 loss 4.425301 loss_att 6.639808 loss_ctc 7.053210 loss_rnnt 3.534379 hw_loss 0.183061 lr 0.00029509 rank 1
2023-03-01 03:02:45,939 DEBUG TRAIN Batch 47/5400 loss 4.642491 loss_att 7.064568 loss_ctc 7.234771 loss_rnnt 3.634578 hw_loss 0.333488 lr 0.00029509 rank 6
2023-03-01 03:02:45,939 DEBUG TRAIN Batch 47/5400 loss 6.290123 loss_att 10.237604 loss_ctc 11.608693 loss_rnnt 4.652096 hw_loss 0.261352 lr 0.00029509 rank 4
2023-03-01 03:02:45,990 DEBUG TRAIN Batch 47/5400 loss 2.133688 loss_att 4.675056 loss_ctc 5.235406 loss_rnnt 1.122477 hw_loss 0.167578 lr 0.00029509 rank 5
2023-03-01 03:03:25,454 DEBUG TRAIN Batch 47/5500 loss 14.995595 loss_att 18.041904 loss_ctc 21.006796 loss_rnnt 13.475820 hw_loss 0.204413 lr 0.00029508 rank 1
2023-03-01 03:03:25,459 DEBUG TRAIN Batch 47/5500 loss 3.965566 loss_att 6.523961 loss_ctc 7.333154 loss_rnnt 2.848186 hw_loss 0.293791 lr 0.00029508 rank 0
2023-03-01 03:03:25,460 DEBUG TRAIN Batch 47/5500 loss 5.845780 loss_att 7.887201 loss_ctc 7.606748 loss_rnnt 5.070482 hw_loss 0.247909 lr 0.00029507 rank 4
2023-03-01 03:03:25,462 DEBUG TRAIN Batch 47/5500 loss 8.390410 loss_att 10.639156 loss_ctc 14.875633 loss_rnnt 6.973418 hw_loss 0.192274 lr 0.00029507 rank 6
2023-03-01 03:03:25,462 DEBUG TRAIN Batch 47/5500 loss 9.683043 loss_att 13.092610 loss_ctc 13.892394 loss_rnnt 8.379715 hw_loss 0.112813 lr 0.00029506 rank 7
2023-03-01 03:03:25,464 DEBUG TRAIN Batch 47/5500 loss 11.916104 loss_att 11.764894 loss_ctc 13.621264 loss_rnnt 11.582675 hw_loss 0.255594 lr 0.00029507 rank 5
2023-03-01 03:03:25,496 DEBUG TRAIN Batch 47/5500 loss 3.719905 loss_att 5.818288 loss_ctc 5.429557 loss_rnnt 3.031769 hw_loss 0.075950 lr 0.00029507 rank 3
2023-03-01 03:03:25,496 DEBUG TRAIN Batch 47/5500 loss 8.340854 loss_att 12.118231 loss_ctc 9.947992 loss_rnnt 7.200531 hw_loss 0.319803 lr 0.00029508 rank 2
2023-03-01 03:04:04,365 DEBUG TRAIN Batch 47/5600 loss 5.337616 loss_att 7.678298 loss_ctc 10.245846 loss_rnnt 4.156360 hw_loss 0.110043 lr 0.00029506 rank 6
2023-03-01 03:04:04,373 DEBUG TRAIN Batch 47/5600 loss 5.213396 loss_att 6.701890 loss_ctc 5.503377 loss_rnnt 4.699450 hw_loss 0.332968 lr 0.00029505 rank 7
2023-03-01 03:04:04,375 DEBUG TRAIN Batch 47/5600 loss 9.359776 loss_att 12.082903 loss_ctc 17.737455 loss_rnnt 7.579421 hw_loss 0.222573 lr 0.00029506 rank 5
2023-03-01 03:04:04,375 DEBUG TRAIN Batch 47/5600 loss 6.812363 loss_att 9.955145 loss_ctc 14.209449 loss_rnnt 5.085615 hw_loss 0.209839 lr 0.00029506 rank 3
2023-03-01 03:04:04,376 DEBUG TRAIN Batch 47/5600 loss 11.729166 loss_att 15.878573 loss_ctc 20.307871 loss_rnnt 9.607252 hw_loss 0.277884 lr 0.00029506 rank 0
2023-03-01 03:04:04,404 DEBUG TRAIN Batch 47/5600 loss 5.951651 loss_att 9.271002 loss_ctc 16.058491 loss_rnnt 3.843821 hw_loss 0.180715 lr 0.00029506 rank 2
2023-03-01 03:04:04,408 DEBUG TRAIN Batch 47/5600 loss 9.180614 loss_att 12.132593 loss_ctc 15.463490 loss_rnnt 7.605443 hw_loss 0.275736 lr 0.00029506 rank 1
2023-03-01 03:04:04,415 DEBUG TRAIN Batch 47/5600 loss 10.447913 loss_att 11.439602 loss_ctc 17.819408 loss_rnnt 9.116679 hw_loss 0.281307 lr 0.00029506 rank 4
2023-03-01 03:05:10,920 DEBUG TRAIN Batch 47/5700 loss 2.064935 loss_att 3.406044 loss_ctc 4.130219 loss_rnnt 1.372522 hw_loss 0.279038 lr 0.00029505 rank 5
2023-03-01 03:05:10,920 DEBUG TRAIN Batch 47/5700 loss 6.507162 loss_att 10.224035 loss_ctc 14.181413 loss_rnnt 4.612989 hw_loss 0.239183 lr 0.00029504 rank 3
2023-03-01 03:05:10,923 DEBUG TRAIN Batch 47/5700 loss 5.031693 loss_att 8.241928 loss_ctc 9.496789 loss_rnnt 3.624126 hw_loss 0.319076 lr 0.00029505 rank 0
2023-03-01 03:05:10,922 DEBUG TRAIN Batch 47/5700 loss 5.652192 loss_att 8.175777 loss_ctc 11.506628 loss_rnnt 4.259830 hw_loss 0.200725 lr 0.00029504 rank 7
2023-03-01 03:05:10,937 DEBUG TRAIN Batch 47/5700 loss 3.202265 loss_att 5.041275 loss_ctc 6.266584 loss_rnnt 2.313672 hw_loss 0.210403 lr 0.00029505 rank 1
2023-03-01 03:05:10,948 DEBUG TRAIN Batch 47/5700 loss 4.913692 loss_att 7.037697 loss_ctc 10.565159 loss_rnnt 3.583998 hw_loss 0.283808 lr 0.00029505 rank 4
2023-03-01 03:05:10,962 DEBUG TRAIN Batch 47/5700 loss 3.198338 loss_att 5.513488 loss_ctc 2.986095 loss_rnnt 2.657753 hw_loss 0.198475 lr 0.00029505 rank 2
2023-03-01 03:05:10,988 DEBUG TRAIN Batch 47/5700 loss 5.796258 loss_att 8.959316 loss_ctc 11.490556 loss_rnnt 4.269817 hw_loss 0.252355 lr 0.00029505 rank 6
2023-03-01 03:05:50,385 DEBUG TRAIN Batch 47/5800 loss 4.511400 loss_att 9.513398 loss_ctc 11.612632 loss_rnnt 2.442649 hw_loss 0.227852 lr 0.00029504 rank 0
2023-03-01 03:05:50,401 DEBUG TRAIN Batch 47/5800 loss 1.039837 loss_att 2.754765 loss_ctc 1.433229 loss_rnnt 0.565766 hw_loss 0.147436 lr 0.00029504 rank 4
2023-03-01 03:05:50,401 DEBUG TRAIN Batch 47/5800 loss 6.452605 loss_att 8.836749 loss_ctc 10.576044 loss_rnnt 5.316241 hw_loss 0.205768 lr 0.00029504 rank 1
2023-03-01 03:05:50,402 DEBUG TRAIN Batch 47/5800 loss 12.348536 loss_att 13.976623 loss_ctc 17.225620 loss_rnnt 11.237067 hw_loss 0.254203 lr 0.00029504 rank 2
2023-03-01 03:05:50,402 DEBUG TRAIN Batch 47/5800 loss 8.020431 loss_att 10.328654 loss_ctc 13.208687 loss_rnnt 6.770029 hw_loss 0.181854 lr 0.00029504 rank 5
2023-03-01 03:05:50,403 DEBUG TRAIN Batch 47/5800 loss 6.076515 loss_att 9.296250 loss_ctc 11.915871 loss_rnnt 4.517944 hw_loss 0.255082 lr 0.00029503 rank 6
2023-03-01 03:05:50,407 DEBUG TRAIN Batch 47/5800 loss 7.761158 loss_att 9.567303 loss_ctc 12.221222 loss_rnnt 6.703108 hw_loss 0.191522 lr 0.00029503 rank 3
2023-03-01 03:05:50,408 DEBUG TRAIN Batch 47/5800 loss 5.226735 loss_att 8.913704 loss_ctc 9.540560 loss_rnnt 3.791105 hw_loss 0.230736 lr 0.00029503 rank 7
2023-03-01 03:06:30,670 DEBUG TRAIN Batch 47/5900 loss 4.795985 loss_att 6.197296 loss_ctc 6.511007 loss_rnnt 4.125553 hw_loss 0.302815 lr 0.00029502 rank 4
2023-03-01 03:06:30,671 DEBUG TRAIN Batch 47/5900 loss 2.277991 loss_att 4.429987 loss_ctc 2.807674 loss_rnnt 1.688271 hw_loss 0.166305 lr 0.00029502 rank 3
2023-03-01 03:06:30,682 DEBUG TRAIN Batch 47/5900 loss 8.262352 loss_att 9.758219 loss_ctc 11.478643 loss_rnnt 7.463819 hw_loss 0.132226 lr 0.00029501 rank 7
2023-03-01 03:06:30,682 DEBUG TRAIN Batch 47/5900 loss 3.144440 loss_att 6.867376 loss_ctc 4.046657 loss_rnnt 2.103140 hw_loss 0.330782 lr 0.00029503 rank 1
2023-03-01 03:06:30,683 DEBUG TRAIN Batch 47/5900 loss 5.907473 loss_att 9.172150 loss_ctc 13.778738 loss_rnnt 4.092456 hw_loss 0.211087 lr 0.00029502 rank 0
2023-03-01 03:06:30,688 DEBUG TRAIN Batch 47/5900 loss 12.567785 loss_att 16.247128 loss_ctc 18.325745 loss_rnnt 10.927272 hw_loss 0.256720 lr 0.00029503 rank 2
2023-03-01 03:06:30,735 DEBUG TRAIN Batch 47/5900 loss 3.738605 loss_att 5.063673 loss_ctc 4.624065 loss_rnnt 3.218291 hw_loss 0.257324 lr 0.00029502 rank 5
2023-03-01 03:06:31,024 DEBUG TRAIN Batch 47/5900 loss 7.261993 loss_att 9.256071 loss_ctc 9.334660 loss_rnnt 6.519369 hw_loss 0.126477 lr 0.00029502 rank 6
2023-03-01 03:07:11,328 DEBUG TRAIN Batch 47/6000 loss 4.427171 loss_att 6.147342 loss_ctc 8.340416 loss_rnnt 3.439914 hw_loss 0.227732 lr 0.00029501 rank 1
2023-03-01 03:07:11,332 DEBUG TRAIN Batch 47/6000 loss 10.194476 loss_att 13.402935 loss_ctc 14.211200 loss_rnnt 8.910751 hw_loss 0.199630 lr 0.00029501 rank 4
2023-03-01 03:07:11,338 DEBUG TRAIN Batch 47/6000 loss 6.791261 loss_att 8.289642 loss_ctc 12.300995 loss_rnnt 5.586317 hw_loss 0.319943 lr 0.00029501 rank 0
2023-03-01 03:07:11,338 DEBUG TRAIN Batch 47/6000 loss 12.951477 loss_att 13.892338 loss_ctc 16.103683 loss_rnnt 12.182434 hw_loss 0.301080 lr 0.00029501 rank 2
2023-03-01 03:07:11,339 DEBUG TRAIN Batch 47/6000 loss 10.068010 loss_att 14.348516 loss_ctc 16.487608 loss_rnnt 8.281826 hw_loss 0.139008 lr 0.00029500 rank 3
2023-03-01 03:07:11,339 DEBUG TRAIN Batch 47/6000 loss 3.179976 loss_att 6.111482 loss_ctc 6.712602 loss_rnnt 2.093345 hw_loss 0.054961 lr 0.00029501 rank 6
2023-03-01 03:07:11,339 DEBUG TRAIN Batch 47/6000 loss 13.809860 loss_att 16.460711 loss_ctc 21.328608 loss_rnnt 12.112095 hw_loss 0.309553 lr 0.00029500 rank 7
2023-03-01 03:07:11,387 DEBUG TRAIN Batch 47/6000 loss 4.566294 loss_att 6.445489 loss_ctc 7.973774 loss_rnnt 3.650561 hw_loss 0.160432 lr 0.00029501 rank 5
2023-03-01 03:08:17,753 DEBUG TRAIN Batch 47/6100 loss 3.654416 loss_att 5.838600 loss_ctc 3.338365 loss_rnnt 3.091594 hw_loss 0.315234 lr 0.00029500 rank 6
2023-03-01 03:08:17,758 DEBUG TRAIN Batch 47/6100 loss 4.830204 loss_att 6.241409 loss_ctc 6.423135 loss_rnnt 4.198288 hw_loss 0.257408 lr 0.00029500 rank 0
2023-03-01 03:08:17,758 DEBUG TRAIN Batch 47/6100 loss 13.854727 loss_att 16.047684 loss_ctc 21.186213 loss_rnnt 12.356419 hw_loss 0.154099 lr 0.00029500 rank 4
2023-03-01 03:08:17,760 DEBUG TRAIN Batch 47/6100 loss 6.516714 loss_att 13.195281 loss_ctc 9.481726 loss_rnnt 4.710388 hw_loss 0.141145 lr 0.00029499 rank 7
2023-03-01 03:08:17,762 DEBUG TRAIN Batch 47/6100 loss 9.036892 loss_att 11.541209 loss_ctc 12.875925 loss_rnnt 7.914532 hw_loss 0.205549 lr 0.00029499 rank 3
2023-03-01 03:08:17,761 DEBUG TRAIN Batch 47/6100 loss 4.385960 loss_att 9.865219 loss_ctc 9.865632 loss_rnnt 2.428197 hw_loss 0.246164 lr 0.00029500 rank 1
2023-03-01 03:08:17,764 DEBUG TRAIN Batch 47/6100 loss 6.979080 loss_att 8.207284 loss_ctc 8.978524 loss_rnnt 6.350121 hw_loss 0.218858 lr 0.00029500 rank 5
2023-03-01 03:08:17,784 DEBUG TRAIN Batch 47/6100 loss 11.737337 loss_att 13.525327 loss_ctc 21.653538 loss_rnnt 9.944670 hw_loss 0.211706 lr 0.00029500 rank 2
2023-03-01 03:08:56,628 DEBUG TRAIN Batch 47/6200 loss 1.288742 loss_att 3.839968 loss_ctc 2.372773 loss_rnnt 0.466161 hw_loss 0.314623 lr 0.00029497 rank 7
2023-03-01 03:08:56,646 DEBUG TRAIN Batch 47/6200 loss 5.796406 loss_att 7.796008 loss_ctc 8.218621 loss_rnnt 4.954077 hw_loss 0.223962 lr 0.00029498 rank 5
2023-03-01 03:08:56,648 DEBUG TRAIN Batch 47/6200 loss 9.178400 loss_att 11.920590 loss_ctc 17.513020 loss_rnnt 7.352367 hw_loss 0.311834 lr 0.00029499 rank 1
2023-03-01 03:08:56,649 DEBUG TRAIN Batch 47/6200 loss 6.110463 loss_att 7.207684 loss_ctc 10.591539 loss_rnnt 5.097555 hw_loss 0.367474 lr 0.00029499 rank 2
2023-03-01 03:08:56,653 DEBUG TRAIN Batch 47/6200 loss 3.683809 loss_att 8.004654 loss_ctc 7.294466 loss_rnnt 2.243491 hw_loss 0.177615 lr 0.00029499 rank 0
2023-03-01 03:08:56,652 DEBUG TRAIN Batch 47/6200 loss 9.206057 loss_att 12.207638 loss_ctc 15.191240 loss_rnnt 7.698616 hw_loss 0.204563 lr 0.00029498 rank 4
2023-03-01 03:08:56,658 DEBUG TRAIN Batch 47/6200 loss 9.588484 loss_att 11.164944 loss_ctc 14.913881 loss_rnnt 8.487154 hw_loss 0.142471 lr 0.00029498 rank 3
2023-03-01 03:08:56,693 DEBUG TRAIN Batch 47/6200 loss 7.989793 loss_att 7.815769 loss_ctc 7.930087 loss_rnnt 7.877650 hw_loss 0.290454 lr 0.00029498 rank 6
2023-03-01 03:09:36,125 DEBUG TRAIN Batch 47/6300 loss 2.987485 loss_att 7.813427 loss_ctc 9.030621 loss_rnnt 1.137485 hw_loss 0.148238 lr 0.00029497 rank 2
2023-03-01 03:09:36,125 DEBUG TRAIN Batch 47/6300 loss 12.264518 loss_att 15.988603 loss_ctc 18.553385 loss_rnnt 10.562432 hw_loss 0.222662 lr 0.00029497 rank 1
2023-03-01 03:09:36,126 DEBUG TRAIN Batch 47/6300 loss 3.910693 loss_att 6.668683 loss_ctc 7.236925 loss_rnnt 2.849567 hw_loss 0.123805 lr 0.00029497 rank 0
2023-03-01 03:09:36,129 DEBUG TRAIN Batch 47/6300 loss 1.948293 loss_att 4.739711 loss_ctc 5.409347 loss_rnnt 0.810502 hw_loss 0.221312 lr 0.00029497 rank 6
2023-03-01 03:09:36,130 DEBUG TRAIN Batch 47/6300 loss 9.100060 loss_att 10.222073 loss_ctc 15.647784 loss_rnnt 7.839140 hw_loss 0.306540 lr 0.00029496 rank 7
2023-03-01 03:09:36,130 DEBUG TRAIN Batch 47/6300 loss 5.102531 loss_att 6.090932 loss_ctc 7.525810 loss_rnnt 4.448497 hw_loss 0.249845 lr 0.00029497 rank 4
2023-03-01 03:09:36,130 DEBUG TRAIN Batch 47/6300 loss 9.588346 loss_att 11.511459 loss_ctc 15.336752 loss_rnnt 8.333609 hw_loss 0.194365 lr 0.00029497 rank 3
2023-03-01 03:09:36,131 DEBUG TRAIN Batch 47/6300 loss 9.332159 loss_att 10.115044 loss_ctc 13.457377 loss_rnnt 8.487226 hw_loss 0.259361 lr 0.00029497 rank 5
2023-03-01 03:10:42,337 DEBUG TRAIN Batch 47/6400 loss 12.176933 loss_att 12.997865 loss_ctc 16.962769 loss_rnnt 11.289668 hw_loss 0.159317 lr 0.00029495 rank 7
2023-03-01 03:10:42,337 DEBUG TRAIN Batch 47/6400 loss 5.310245 loss_att 7.432891 loss_ctc 7.146297 loss_rnnt 4.523977 hw_loss 0.219245 lr 0.00029496 rank 6
2023-03-01 03:10:42,339 DEBUG TRAIN Batch 47/6400 loss 8.699154 loss_att 10.740495 loss_ctc 13.545879 loss_rnnt 7.584304 hw_loss 0.113158 lr 0.00029496 rank 2
2023-03-01 03:10:42,340 DEBUG TRAIN Batch 47/6400 loss 3.462446 loss_att 7.310742 loss_ctc 5.126987 loss_rnnt 2.342829 hw_loss 0.240036 lr 0.00029496 rank 5
2023-03-01 03:10:42,342 DEBUG TRAIN Batch 47/6400 loss 2.852843 loss_att 4.554939 loss_ctc 5.629791 loss_rnnt 2.020724 hw_loss 0.227701 lr 0.00029496 rank 0
2023-03-01 03:10:42,344 DEBUG TRAIN Batch 47/6400 loss 7.074196 loss_att 8.859780 loss_ctc 11.497041 loss_rnnt 5.953655 hw_loss 0.325708 lr 0.00029495 rank 3
2023-03-01 03:10:42,359 DEBUG TRAIN Batch 47/6400 loss 2.583128 loss_att 6.045662 loss_ctc 2.792515 loss_rnnt 1.776618 hw_loss 0.161410 lr 0.00029496 rank 4
2023-03-01 03:10:42,367 DEBUG TRAIN Batch 47/6400 loss 8.765279 loss_att 10.182148 loss_ctc 14.004672 loss_rnnt 7.634339 hw_loss 0.279339 lr 0.00029496 rank 1
2023-03-01 03:11:21,779 DEBUG TRAIN Batch 47/6500 loss 3.476476 loss_att 6.764692 loss_ctc 4.251147 loss_rnnt 2.519074 hw_loss 0.368380 lr 0.00029495 rank 5
2023-03-01 03:11:21,792 DEBUG TRAIN Batch 47/6500 loss 8.231365 loss_att 12.455321 loss_ctc 15.548010 loss_rnnt 6.243018 hw_loss 0.315005 lr 0.00029495 rank 0
2023-03-01 03:11:21,792 DEBUG TRAIN Batch 47/6500 loss 3.805284 loss_att 4.865601 loss_ctc 5.520972 loss_rnnt 3.170528 hw_loss 0.363627 lr 0.00029494 rank 6
2023-03-01 03:11:21,792 DEBUG TRAIN Batch 47/6500 loss 6.142126 loss_att 7.697854 loss_ctc 7.332364 loss_rnnt 5.602151 hw_loss 0.131493 lr 0.00029495 rank 2
2023-03-01 03:11:21,794 DEBUG TRAIN Batch 47/6500 loss 5.673949 loss_att 9.910728 loss_ctc 10.506840 loss_rnnt 4.030226 hw_loss 0.284966 lr 0.00029495 rank 4
2023-03-01 03:11:21,796 DEBUG TRAIN Batch 47/6500 loss 2.485145 loss_att 6.215626 loss_ctc 5.452861 loss_rnnt 1.203836 hw_loss 0.261593 lr 0.00029494 rank 3
2023-03-01 03:11:21,796 DEBUG TRAIN Batch 47/6500 loss 4.502344 loss_att 7.777946 loss_ctc 9.594538 loss_rnnt 2.981527 hw_loss 0.350134 lr 0.00029494 rank 7
2023-03-01 03:11:21,801 DEBUG TRAIN Batch 47/6500 loss 4.153611 loss_att 6.415213 loss_ctc 6.627593 loss_rnnt 3.190502 hw_loss 0.339233 lr 0.00029495 rank 1
2023-03-01 03:12:00,831 DEBUG TRAIN Batch 47/6600 loss 3.342851 loss_att 7.383029 loss_ctc 7.066699 loss_rnnt 1.957465 hw_loss 0.151569 lr 0.00029493 rank 5
2023-03-01 03:12:00,844 DEBUG TRAIN Batch 47/6600 loss 5.312517 loss_att 8.314223 loss_ctc 6.811707 loss_rnnt 4.333676 hw_loss 0.334889 lr 0.00029492 rank 7
2023-03-01 03:12:00,844 DEBUG TRAIN Batch 47/6600 loss 8.265035 loss_att 10.331334 loss_ctc 12.671300 loss_rnnt 7.191458 hw_loss 0.136528 lr 0.00029494 rank 2
2023-03-01 03:12:00,851 DEBUG TRAIN Batch 47/6600 loss 4.379083 loss_att 8.665276 loss_ctc 8.575683 loss_rnnt 2.842873 hw_loss 0.223923 lr 0.00029494 rank 1
2023-03-01 03:12:00,853 DEBUG TRAIN Batch 47/6600 loss 6.927115 loss_att 10.330417 loss_ctc 11.451000 loss_rnnt 5.510508 hw_loss 0.248930 lr 0.00029493 rank 4
2023-03-01 03:12:00,854 DEBUG TRAIN Batch 47/6600 loss 1.332123 loss_att 3.231318 loss_ctc 1.495436 loss_rnnt 0.798918 hw_loss 0.246733 lr 0.00029493 rank 6
2023-03-01 03:12:00,858 DEBUG TRAIN Batch 47/6600 loss 3.178977 loss_att 7.567273 loss_ctc 5.143653 loss_rnnt 1.880626 hw_loss 0.297628 lr 0.00029493 rank 0
2023-03-01 03:12:00,875 DEBUG TRAIN Batch 47/6600 loss 3.307674 loss_att 5.518230 loss_ctc 3.352673 loss_rnnt 2.702527 hw_loss 0.294444 lr 0.00029493 rank 3
2023-03-01 03:12:40,583 DEBUG TRAIN Batch 47/6700 loss 9.245242 loss_att 12.369234 loss_ctc 13.947229 loss_rnnt 7.889302 hw_loss 0.195394 lr 0.00029492 rank 4
2023-03-01 03:12:40,585 DEBUG TRAIN Batch 47/6700 loss 2.271409 loss_att 4.636462 loss_ctc 2.407889 loss_rnnt 1.600518 hw_loss 0.336904 lr 0.00029492 rank 1
2023-03-01 03:12:40,588 DEBUG TRAIN Batch 47/6700 loss 3.458528 loss_att 6.211020 loss_ctc 4.309315 loss_rnnt 2.659000 hw_loss 0.254235 lr 0.00029491 rank 3
2023-03-01 03:12:40,592 DEBUG TRAIN Batch 47/6700 loss 5.727365 loss_att 8.634874 loss_ctc 8.947897 loss_rnnt 4.538473 hw_loss 0.333723 lr 0.00029492 rank 5
2023-03-01 03:12:40,600 DEBUG TRAIN Batch 47/6700 loss 7.817561 loss_att 11.859353 loss_ctc 14.440655 loss_rnnt 5.937813 hw_loss 0.353081 lr 0.00029492 rank 2
2023-03-01 03:12:40,600 DEBUG TRAIN Batch 47/6700 loss 3.909621 loss_att 6.841760 loss_ctc 7.683796 loss_rnnt 2.751953 hw_loss 0.127531 lr 0.00029491 rank 7
2023-03-01 03:12:40,604 DEBUG TRAIN Batch 47/6700 loss 4.886166 loss_att 8.421593 loss_ctc 7.713651 loss_rnnt 3.610434 hw_loss 0.359340 lr 0.00029492 rank 6
2023-03-01 03:12:40,608 DEBUG TRAIN Batch 47/6700 loss 13.587845 loss_att 17.810343 loss_ctc 22.426735 loss_rnnt 11.403967 hw_loss 0.301612 lr 0.00029492 rank 0
2023-03-01 03:13:46,704 DEBUG TRAIN Batch 47/6800 loss 6.690644 loss_att 9.294581 loss_ctc 12.488883 loss_rnnt 5.292811 hw_loss 0.194899 lr 0.00029490 rank 3
2023-03-01 03:13:46,711 DEBUG TRAIN Batch 47/6800 loss 6.731936 loss_att 8.938014 loss_ctc 10.643135 loss_rnnt 5.653514 hw_loss 0.216963 lr 0.00029491 rank 5
2023-03-01 03:13:46,712 DEBUG TRAIN Batch 47/6800 loss 5.976540 loss_att 9.014602 loss_ctc 9.029196 loss_rnnt 4.880266 hw_loss 0.153076 lr 0.00029491 rank 0
2023-03-01 03:13:46,713 DEBUG TRAIN Batch 47/6800 loss 3.930921 loss_att 7.534818 loss_ctc 8.239880 loss_rnnt 2.458049 hw_loss 0.332934 lr 0.00029490 rank 7
2023-03-01 03:13:46,714 DEBUG TRAIN Batch 47/6800 loss 7.891021 loss_att 9.812051 loss_ctc 13.364262 loss_rnnt 6.692709 hw_loss 0.158139 lr 0.00029491 rank 4
2023-03-01 03:13:46,714 DEBUG TRAIN Batch 47/6800 loss 3.438433 loss_att 3.832182 loss_ctc 6.163936 loss_rnnt 2.880324 hw_loss 0.217422 lr 0.00029491 rank 2
2023-03-01 03:13:46,716 DEBUG TRAIN Batch 47/6800 loss 5.736037 loss_att 9.055331 loss_ctc 8.207656 loss_rnnt 4.646905 hw_loss 0.179482 lr 0.00029491 rank 1
2023-03-01 03:13:46,722 DEBUG TRAIN Batch 47/6800 loss 8.116684 loss_att 10.797323 loss_ctc 13.666887 loss_rnnt 6.772628 hw_loss 0.127315 lr 0.00029491 rank 6
2023-03-01 03:14:25,557 DEBUG TRAIN Batch 47/6900 loss 14.977496 loss_att 16.154652 loss_ctc 23.585243 loss_rnnt 13.444283 hw_loss 0.281406 lr 0.00029489 rank 6
2023-03-01 03:14:25,562 DEBUG TRAIN Batch 47/6900 loss 4.656150 loss_att 6.585175 loss_ctc 7.694362 loss_rnnt 3.739723 hw_loss 0.235363 lr 0.00029490 rank 0
2023-03-01 03:14:25,563 DEBUG TRAIN Batch 47/6900 loss 6.776472 loss_att 7.089661 loss_ctc 11.140528 loss_rnnt 5.942236 hw_loss 0.355732 lr 0.00029490 rank 2
2023-03-01 03:14:25,564 DEBUG TRAIN Batch 47/6900 loss 15.612201 loss_att 17.760567 loss_ctc 23.855722 loss_rnnt 13.951765 hw_loss 0.246799 lr 0.00029490 rank 4
2023-03-01 03:14:25,566 DEBUG TRAIN Batch 47/6900 loss 7.991738 loss_att 10.868725 loss_ctc 12.829332 loss_rnnt 6.627125 hw_loss 0.270381 lr 0.00029488 rank 7
2023-03-01 03:14:25,566 DEBUG TRAIN Batch 47/6900 loss 3.291814 loss_att 4.816975 loss_ctc 4.798298 loss_rnnt 2.651599 hw_loss 0.251848 lr 0.00029490 rank 1
2023-03-01 03:14:25,571 DEBUG TRAIN Batch 47/6900 loss 8.883745 loss_att 9.924980 loss_ctc 10.790316 loss_rnnt 8.303266 hw_loss 0.221293 lr 0.00029489 rank 3
2023-03-01 03:14:25,613 DEBUG TRAIN Batch 47/6900 loss 4.951239 loss_att 8.583996 loss_ctc 8.506546 loss_rnnt 3.595110 hw_loss 0.291630 lr 0.00029490 rank 5
2023-03-01 03:15:04,408 DEBUG TRAIN Batch 47/7000 loss 2.037511 loss_att 4.395664 loss_ctc 6.880856 loss_rnnt 0.705771 hw_loss 0.401869 lr 0.00029488 rank 2
2023-03-01 03:15:04,409 DEBUG TRAIN Batch 47/7000 loss 3.670551 loss_att 5.339811 loss_ctc 4.341403 loss_rnnt 3.073051 hw_loss 0.326627 lr 0.00029487 rank 7
2023-03-01 03:15:04,410 DEBUG TRAIN Batch 47/7000 loss 4.985075 loss_att 6.889348 loss_ctc 8.539731 loss_rnnt 3.985802 hw_loss 0.270871 lr 0.00029488 rank 0
2023-03-01 03:15:04,411 DEBUG TRAIN Batch 47/7000 loss 7.825526 loss_att 8.006066 loss_ctc 10.226357 loss_rnnt 7.231902 hw_loss 0.445134 lr 0.00029488 rank 5
2023-03-01 03:15:04,411 DEBUG TRAIN Batch 47/7000 loss 9.144354 loss_att 9.434192 loss_ctc 12.632370 loss_rnnt 8.511797 hw_loss 0.205349 lr 0.00029488 rank 3
2023-03-01 03:15:04,413 DEBUG TRAIN Batch 47/7000 loss 4.966825 loss_att 7.475170 loss_ctc 12.875806 loss_rnnt 3.247669 hw_loss 0.305543 lr 0.00029488 rank 1
2023-03-01 03:15:04,449 DEBUG TRAIN Batch 47/7000 loss 6.893933 loss_att 9.578325 loss_ctc 9.823515 loss_rnnt 5.848255 hw_loss 0.221603 lr 0.00029488 rank 4
2023-03-01 03:15:04,479 DEBUG TRAIN Batch 47/7000 loss 9.098797 loss_att 10.260018 loss_ctc 15.790881 loss_rnnt 7.759831 hw_loss 0.402081 lr 0.00029488 rank 6
2023-03-01 03:16:07,061 DEBUG TRAIN Batch 47/7100 loss 5.715672 loss_att 9.884179 loss_ctc 9.274019 loss_rnnt 4.313780 hw_loss 0.175769 lr 0.00029487 rank 5
2023-03-01 03:16:07,063 DEBUG TRAIN Batch 47/7100 loss 8.025084 loss_att 11.539631 loss_ctc 11.029984 loss_rnnt 6.833070 hw_loss 0.165845 lr 0.00029487 rank 1
2023-03-01 03:16:07,077 DEBUG TRAIN Batch 47/7100 loss 9.618388 loss_att 10.542207 loss_ctc 14.973147 loss_rnnt 8.517272 hw_loss 0.379471 lr 0.00029487 rank 6
2023-03-01 03:16:07,084 DEBUG TRAIN Batch 47/7100 loss 3.142916 loss_att 6.978130 loss_ctc 4.261862 loss_rnnt 2.201999 hw_loss 0.046278 lr 0.00029486 rank 3
2023-03-01 03:16:07,088 DEBUG TRAIN Batch 47/7100 loss 2.558059 loss_att 4.592080 loss_ctc 4.031296 loss_rnnt 1.928698 hw_loss 0.048984 lr 0.00029486 rank 7
2023-03-01 03:16:07,090 DEBUG TRAIN Batch 47/7100 loss 7.866672 loss_att 10.932793 loss_ctc 9.279255 loss_rnnt 6.973114 hw_loss 0.172479 lr 0.00029487 rank 4
2023-03-01 03:16:07,095 DEBUG TRAIN Batch 47/7100 loss 5.497730 loss_att 8.238784 loss_ctc 10.093516 loss_rnnt 4.243714 hw_loss 0.174438 lr 0.00029487 rank 0
2023-03-01 03:16:07,123 DEBUG TRAIN Batch 47/7100 loss 6.506207 loss_att 8.602028 loss_ctc 8.083023 loss_rnnt 5.731967 hw_loss 0.271564 lr 0.00029487 rank 2
2023-03-01 03:16:48,804 DEBUG TRAIN Batch 47/7200 loss 9.379983 loss_att 12.998729 loss_ctc 16.574768 loss_rnnt 7.548991 hw_loss 0.277383 lr 0.00029486 rank 5
2023-03-01 03:16:48,805 DEBUG TRAIN Batch 47/7200 loss 5.218415 loss_att 7.012545 loss_ctc 8.988416 loss_rnnt 4.323987 hw_loss 0.061753 lr 0.00029486 rank 4
2023-03-01 03:16:48,806 DEBUG TRAIN Batch 47/7200 loss 5.645926 loss_att 9.911270 loss_ctc 11.631329 loss_rnnt 3.866783 hw_loss 0.240037 lr 0.00029485 rank 7
2023-03-01 03:16:48,805 DEBUG TRAIN Batch 47/7200 loss 2.781033 loss_att 7.689517 loss_ctc 7.527027 loss_rnnt 1.037167 hw_loss 0.242568 lr 0.00029486 rank 1
2023-03-01 03:16:48,806 DEBUG TRAIN Batch 47/7200 loss 14.456273 loss_att 13.479053 loss_ctc 15.126407 loss_rnnt 14.410875 hw_loss 0.284042 lr 0.00029486 rank 0
2023-03-01 03:16:48,809 DEBUG TRAIN Batch 47/7200 loss 7.579191 loss_att 9.651920 loss_ctc 12.062155 loss_rnnt 6.451244 hw_loss 0.216886 lr 0.00029486 rank 2
2023-03-01 03:16:48,808 DEBUG TRAIN Batch 47/7200 loss 1.425466 loss_att 4.190488 loss_ctc 2.913835 loss_rnnt 0.544244 hw_loss 0.243317 lr 0.00029486 rank 6
2023-03-01 03:16:48,811 DEBUG TRAIN Batch 47/7200 loss 5.289425 loss_att 9.569136 loss_ctc 9.525028 loss_rnnt 3.763948 hw_loss 0.196477 lr 0.00029485 rank 3
2023-03-01 03:17:27,812 DEBUG TRAIN Batch 47/7300 loss 9.193824 loss_att 9.955768 loss_ctc 12.983643 loss_rnnt 8.482502 hw_loss 0.100545 lr 0.00029485 rank 2
2023-03-01 03:17:27,812 DEBUG TRAIN Batch 47/7300 loss 10.528018 loss_att 11.220884 loss_ctc 15.433870 loss_rnnt 9.600915 hw_loss 0.252027 lr 0.00029484 rank 4
2023-03-01 03:17:27,812 DEBUG TRAIN Batch 47/7300 loss 7.511891 loss_att 10.691017 loss_ctc 12.624691 loss_rnnt 6.114412 hw_loss 0.149901 lr 0.00029484 rank 5
2023-03-01 03:17:27,813 DEBUG TRAIN Batch 47/7300 loss 3.469602 loss_att 6.448237 loss_ctc 7.515897 loss_rnnt 2.304065 hw_loss 0.056819 lr 0.00029485 rank 1
2023-03-01 03:17:27,823 DEBUG TRAIN Batch 47/7300 loss 3.374896 loss_att 5.360187 loss_ctc 7.504544 loss_rnnt 2.318306 hw_loss 0.204208 lr 0.00029484 rank 6
2023-03-01 03:17:27,828 DEBUG TRAIN Batch 47/7300 loss 5.978758 loss_att 11.110626 loss_ctc 12.785673 loss_rnnt 3.909640 hw_loss 0.253417 lr 0.00029483 rank 7
2023-03-01 03:17:27,832 DEBUG TRAIN Batch 47/7300 loss 5.641415 loss_att 11.642070 loss_ctc 8.278144 loss_rnnt 4.024966 hw_loss 0.121413 lr 0.00029484 rank 0
2023-03-01 03:17:27,838 DEBUG TRAIN Batch 47/7300 loss 3.617917 loss_att 7.484683 loss_ctc 5.315200 loss_rnnt 2.458871 hw_loss 0.298853 lr 0.00029484 rank 3
2023-03-01 03:18:07,695 DEBUG TRAIN Batch 47/7400 loss 10.644295 loss_att 13.599005 loss_ctc 15.869352 loss_rnnt 9.235868 hw_loss 0.226522 lr 0.00029483 rank 0
2023-03-01 03:18:07,698 DEBUG TRAIN Batch 47/7400 loss 7.495615 loss_att 9.340693 loss_ctc 13.880520 loss_rnnt 6.069375 hw_loss 0.386069 lr 0.00029483 rank 1
2023-03-01 03:18:07,704 DEBUG TRAIN Batch 47/7400 loss 5.249087 loss_att 7.502905 loss_ctc 11.041116 loss_rnnt 3.927808 hw_loss 0.184210 lr 0.00029483 rank 5
2023-03-01 03:18:07,711 DEBUG TRAIN Batch 47/7400 loss 8.951731 loss_att 12.082836 loss_ctc 18.875547 loss_rnnt 6.863623 hw_loss 0.260084 lr 0.00029483 rank 2
2023-03-01 03:18:07,720 DEBUG TRAIN Batch 47/7400 loss 9.195693 loss_att 9.796694 loss_ctc 14.752486 loss_rnnt 8.210837 hw_loss 0.232030 lr 0.00029483 rank 4
2023-03-01 03:18:07,721 DEBUG TRAIN Batch 47/7400 loss 10.368606 loss_att 10.237152 loss_ctc 13.105816 loss_rnnt 9.942822 hw_loss 0.163337 lr 0.00029482 rank 3
2023-03-01 03:18:07,729 DEBUG TRAIN Batch 47/7400 loss 5.810376 loss_att 8.353561 loss_ctc 8.656420 loss_rnnt 4.840065 hw_loss 0.154128 lr 0.00029482 rank 7
2023-03-01 03:18:07,759 DEBUG TRAIN Batch 47/7400 loss 6.303566 loss_att 10.228865 loss_ctc 15.334859 loss_rnnt 4.187837 hw_loss 0.237181 lr 0.00029483 rank 6
2023-03-01 03:19:14,067 DEBUG TRAIN Batch 47/7500 loss 4.772455 loss_att 7.164013 loss_ctc 8.801262 loss_rnnt 3.611384 hw_loss 0.272970 lr 0.00029481 rank 7
2023-03-01 03:19:14,067 DEBUG TRAIN Batch 47/7500 loss 5.404454 loss_att 6.931013 loss_ctc 9.017176 loss_rnnt 4.467971 hw_loss 0.280266 lr 0.00029482 rank 6
2023-03-01 03:19:14,067 DEBUG TRAIN Batch 47/7500 loss 6.644508 loss_att 8.247586 loss_ctc 9.735912 loss_rnnt 5.720283 hw_loss 0.358917 lr 0.00029482 rank 0
2023-03-01 03:19:14,073 DEBUG TRAIN Batch 47/7500 loss 9.872382 loss_att 11.334260 loss_ctc 16.643921 loss_rnnt 8.548129 hw_loss 0.241886 lr 0.00029482 rank 1
2023-03-01 03:19:14,074 DEBUG TRAIN Batch 47/7500 loss 9.304959 loss_att 11.212047 loss_ctc 13.412266 loss_rnnt 8.251987 hw_loss 0.232336 lr 0.00029482 rank 4
2023-03-01 03:19:14,080 DEBUG TRAIN Batch 47/7500 loss 10.651501 loss_att 13.842915 loss_ctc 23.587921 loss_rnnt 8.143451 hw_loss 0.271710 lr 0.00029482 rank 5
2023-03-01 03:19:14,103 DEBUG TRAIN Batch 47/7500 loss 7.797787 loss_att 10.506698 loss_ctc 13.892626 loss_rnnt 6.257380 hw_loss 0.348711 lr 0.00029482 rank 2
2023-03-01 03:19:14,109 DEBUG TRAIN Batch 47/7500 loss 8.975927 loss_att 11.656516 loss_ctc 10.751997 loss_rnnt 8.089899 hw_loss 0.212063 lr 0.00029481 rank 3
2023-03-01 03:19:53,509 DEBUG TRAIN Batch 47/7600 loss 2.169256 loss_att 6.617981 loss_ctc 2.733151 loss_rnnt 1.058555 hw_loss 0.273318 lr 0.00029481 rank 4
2023-03-01 03:19:53,509 DEBUG TRAIN Batch 47/7600 loss 7.757371 loss_att 8.198771 loss_ctc 8.213550 loss_rnnt 7.466084 hw_loss 0.266594 lr 0.00029481 rank 2
2023-03-01 03:19:53,513 DEBUG TRAIN Batch 47/7600 loss 5.837892 loss_att 8.250900 loss_ctc 8.158348 loss_rnnt 4.953924 hw_loss 0.172447 lr 0.00029479 rank 7
2023-03-01 03:19:53,512 DEBUG TRAIN Batch 47/7600 loss 4.506785 loss_att 5.925595 loss_ctc 7.650926 loss_rnnt 3.611856 hw_loss 0.359902 lr 0.00029481 rank 5
2023-03-01 03:19:53,513 DEBUG TRAIN Batch 47/7600 loss 7.003773 loss_att 9.869339 loss_ctc 16.067318 loss_rnnt 5.028902 hw_loss 0.362409 lr 0.00029481 rank 0
2023-03-01 03:19:53,513 DEBUG TRAIN Batch 47/7600 loss 9.292573 loss_att 15.264956 loss_ctc 13.574791 loss_rnnt 7.424289 hw_loss 0.192835 lr 0.00029481 rank 1
2023-03-01 03:19:53,514 DEBUG TRAIN Batch 47/7600 loss 5.696590 loss_att 10.877758 loss_ctc 10.529675 loss_rnnt 3.928232 hw_loss 0.164463 lr 0.00029480 rank 6
2023-03-01 03:19:53,531 DEBUG TRAIN Batch 47/7600 loss 6.191844 loss_att 10.333658 loss_ctc 12.536943 loss_rnnt 4.388693 hw_loss 0.241451 lr 0.00029480 rank 3
2023-03-01 03:20:32,862 DEBUG TRAIN Batch 47/7700 loss 6.213214 loss_att 7.367545 loss_ctc 10.402742 loss_rnnt 5.323245 hw_loss 0.188438 lr 0.00029479 rank 1
2023-03-01 03:20:32,877 DEBUG TRAIN Batch 47/7700 loss 2.699514 loss_att 5.103918 loss_ctc 6.514112 loss_rnnt 1.616807 hw_loss 0.174773 lr 0.00029479 rank 6
2023-03-01 03:20:32,877 DEBUG TRAIN Batch 47/7700 loss 4.869619 loss_att 6.188655 loss_ctc 7.153950 loss_rnnt 4.143175 hw_loss 0.296361 lr 0.00029479 rank 0
2023-03-01 03:20:32,878 DEBUG TRAIN Batch 47/7700 loss 8.544117 loss_att 11.031717 loss_ctc 13.905989 loss_rnnt 7.218204 hw_loss 0.212770 lr 0.00029479 rank 4
2023-03-01 03:20:32,881 DEBUG TRAIN Batch 47/7700 loss 5.397933 loss_att 8.135497 loss_ctc 9.263885 loss_rnnt 4.296956 hw_loss 0.071258 lr 0.00029478 rank 7
2023-03-01 03:20:32,882 DEBUG TRAIN Batch 47/7700 loss 2.844014 loss_att 7.899288 loss_ctc 8.090370 loss_rnnt 1.051088 hw_loss 0.154421 lr 0.00029479 rank 2
2023-03-01 03:20:32,890 DEBUG TRAIN Batch 47/7700 loss 1.969507 loss_att 4.723835 loss_ctc 3.522352 loss_rnnt 1.107084 hw_loss 0.195957 lr 0.00029479 rank 5
2023-03-01 03:20:32,932 DEBUG TRAIN Batch 47/7700 loss 11.460342 loss_att 12.580846 loss_ctc 17.817381 loss_rnnt 10.257235 hw_loss 0.246380 lr 0.00029479 rank 3
2023-03-01 03:21:38,786 DEBUG TRAIN Batch 47/7800 loss 5.142476 loss_att 8.057476 loss_ctc 8.589703 loss_rnnt 3.998531 hw_loss 0.189965 lr 0.00029477 rank 3
2023-03-01 03:21:38,790 DEBUG TRAIN Batch 47/7800 loss 9.809478 loss_att 11.477392 loss_ctc 13.441050 loss_rnnt 8.910783 hw_loss 0.151690 lr 0.00029478 rank 1
2023-03-01 03:21:38,790 DEBUG TRAIN Batch 47/7800 loss 3.258424 loss_att 4.690735 loss_ctc 4.000908 loss_rnnt 2.834635 hw_loss 0.071868 lr 0.00029478 rank 0
2023-03-01 03:21:38,792 DEBUG TRAIN Batch 47/7800 loss 4.944427 loss_att 7.216265 loss_ctc 6.972277 loss_rnnt 4.077122 hw_loss 0.267293 lr 0.00029478 rank 5
2023-03-01 03:21:38,794 DEBUG TRAIN Batch 47/7800 loss 5.904335 loss_att 7.338414 loss_ctc 8.053076 loss_rnnt 5.251223 hw_loss 0.149620 lr 0.00029478 rank 4
2023-03-01 03:21:38,794 DEBUG TRAIN Batch 47/7800 loss 9.826737 loss_att 10.213558 loss_ctc 19.232964 loss_rnnt 8.426100 hw_loss 0.129581 lr 0.00029477 rank 7
2023-03-01 03:21:38,794 DEBUG TRAIN Batch 47/7800 loss 4.366307 loss_att 6.771340 loss_ctc 8.048357 loss_rnnt 3.187990 hw_loss 0.386946 lr 0.00029478 rank 2
2023-03-01 03:21:38,853 DEBUG TRAIN Batch 47/7800 loss 6.606285 loss_att 8.626861 loss_ctc 12.269938 loss_rnnt 5.245139 hw_loss 0.378518 lr 0.00029478 rank 6
2023-03-01 03:22:22,988 DEBUG TRAIN Batch 47/7900 loss 3.857333 loss_att 6.804053 loss_ctc 6.822101 loss_rnnt 2.708187 hw_loss 0.308439 lr 0.00029476 rank 3
2023-03-01 03:22:22,998 DEBUG TRAIN Batch 47/7900 loss 3.039622 loss_att 4.259749 loss_ctc 3.801354 loss_rnnt 2.556349 hw_loss 0.258156 lr 0.00029476 rank 7
2023-03-01 03:22:22,998 DEBUG TRAIN Batch 47/7900 loss 2.573706 loss_att 5.647023 loss_ctc 4.601885 loss_rnnt 1.688287 hw_loss 0.000621 lr 0.00029477 rank 1
2023-03-01 03:22:23,001 DEBUG TRAIN Batch 47/7900 loss 3.275189 loss_att 5.564452 loss_ctc 4.424847 loss_rnnt 2.594806 hw_loss 0.129830 lr 0.00029477 rank 6
2023-03-01 03:22:23,002 DEBUG TRAIN Batch 47/7900 loss 3.465459 loss_att 6.055548 loss_ctc 8.463757 loss_rnnt 2.120762 hw_loss 0.300450 lr 0.00029477 rank 0
2023-03-01 03:22:23,004 DEBUG TRAIN Batch 47/7900 loss 5.007665 loss_att 6.991224 loss_ctc 7.023911 loss_rnnt 4.233101 hw_loss 0.204411 lr 0.00029477 rank 5
2023-03-01 03:22:23,004 DEBUG TRAIN Batch 47/7900 loss 9.271260 loss_att 9.799363 loss_ctc 14.100149 loss_rnnt 8.417813 hw_loss 0.194951 lr 0.00029477 rank 2
2023-03-01 03:22:23,012 DEBUG TRAIN Batch 47/7900 loss 5.118738 loss_att 6.372031 loss_ctc 6.633526 loss_rnnt 4.539954 hw_loss 0.236538 lr 0.00029477 rank 4
2023-03-01 03:23:01,932 DEBUG TRAIN Batch 47/8000 loss 2.796381 loss_att 5.303721 loss_ctc 5.060675 loss_rnnt 1.913511 hw_loss 0.149055 lr 0.00029474 rank 7
2023-03-01 03:23:01,948 DEBUG TRAIN Batch 47/8000 loss 5.273339 loss_att 8.355672 loss_ctc 8.302923 loss_rnnt 4.131172 hw_loss 0.228292 lr 0.00029475 rank 6
2023-03-01 03:23:01,949 DEBUG TRAIN Batch 47/8000 loss 12.164845 loss_att 14.896198 loss_ctc 20.393147 loss_rnnt 10.416336 hw_loss 0.197119 lr 0.00029476 rank 1
2023-03-01 03:23:01,949 DEBUG TRAIN Batch 47/8000 loss 13.067319 loss_att 18.253807 loss_ctc 23.914207 loss_rnnt 10.477319 hw_loss 0.199592 lr 0.00029476 rank 2
2023-03-01 03:23:01,950 DEBUG TRAIN Batch 47/8000 loss 10.963641 loss_att 12.815886 loss_ctc 15.433618 loss_rnnt 9.846650 hw_loss 0.282271 lr 0.00029475 rank 5
2023-03-01 03:23:01,951 DEBUG TRAIN Batch 47/8000 loss 5.655928 loss_att 8.970658 loss_ctc 8.901578 loss_rnnt 4.375374 hw_loss 0.346600 lr 0.00029475 rank 0
2023-03-01 03:23:01,954 DEBUG TRAIN Batch 47/8000 loss 6.448871 loss_att 10.191104 loss_ctc 8.350106 loss_rnnt 5.343630 hw_loss 0.193680 lr 0.00029475 rank 4
2023-03-01 03:23:01,958 DEBUG TRAIN Batch 47/8000 loss 8.751544 loss_att 13.077928 loss_ctc 14.445801 loss_rnnt 6.989241 hw_loss 0.258359 lr 0.00029475 rank 3
2023-03-01 03:23:41,170 DEBUG TRAIN Batch 47/8100 loss 5.536367 loss_att 10.022423 loss_ctc 12.085459 loss_rnnt 3.612219 hw_loss 0.288232 lr 0.00029474 rank 1
2023-03-01 03:23:41,173 DEBUG TRAIN Batch 47/8100 loss 8.004640 loss_att 10.385717 loss_ctc 12.134456 loss_rnnt 6.840468 hw_loss 0.257464 lr 0.00029474 rank 2
2023-03-01 03:23:41,174 DEBUG TRAIN Batch 47/8100 loss 7.534203 loss_att 10.904583 loss_ctc 15.454336 loss_rnnt 5.617476 hw_loss 0.349937 lr 0.00029473 rank 3
2023-03-01 03:23:41,174 DEBUG TRAIN Batch 47/8100 loss 7.633033 loss_att 9.410944 loss_ctc 10.804634 loss_rnnt 6.737678 hw_loss 0.219174 lr 0.00029473 rank 7
2023-03-01 03:23:41,176 DEBUG TRAIN Batch 47/8100 loss 9.858203 loss_att 12.947230 loss_ctc 19.959553 loss_rnnt 7.740285 hw_loss 0.287374 lr 0.00029474 rank 0
2023-03-01 03:23:41,178 DEBUG TRAIN Batch 47/8100 loss 8.357404 loss_att 10.154428 loss_ctc 10.000216 loss_rnnt 7.701966 hw_loss 0.144359 lr 0.00029474 rank 6
2023-03-01 03:23:41,178 DEBUG TRAIN Batch 47/8100 loss 5.944226 loss_att 9.059582 loss_ctc 8.872685 loss_rnnt 4.831294 hw_loss 0.186375 lr 0.00029474 rank 5
2023-03-01 03:23:41,186 DEBUG TRAIN Batch 47/8100 loss 7.112218 loss_att 9.309887 loss_ctc 11.907368 loss_rnnt 5.879906 hw_loss 0.287674 lr 0.00029474 rank 4
2023-03-01 03:24:21,541 DEBUG TRAIN Batch 47/8200 loss 4.315170 loss_att 6.367466 loss_ctc 8.817947 loss_rnnt 3.082937 hw_loss 0.415132 lr 0.00029473 rank 0
2023-03-01 03:24:21,562 DEBUG TRAIN Batch 47/8200 loss 8.805687 loss_att 9.413630 loss_ctc 16.131466 loss_rnnt 7.530561 hw_loss 0.331438 lr 0.00029473 rank 6
2023-03-01 03:24:21,563 DEBUG TRAIN Batch 47/8200 loss 4.829896 loss_att 6.791708 loss_ctc 5.949348 loss_rnnt 4.120700 hw_loss 0.314201 lr 0.00029472 rank 7
2023-03-01 03:24:21,564 DEBUG TRAIN Batch 47/8200 loss 8.049535 loss_att 10.670129 loss_ctc 17.839945 loss_rnnt 6.148170 hw_loss 0.134732 lr 0.00029473 rank 2
2023-03-01 03:24:21,565 DEBUG TRAIN Batch 47/8200 loss 8.818481 loss_att 10.655089 loss_ctc 13.850159 loss_rnnt 7.626822 hw_loss 0.287713 lr 0.00029473 rank 1
2023-03-01 03:24:21,566 DEBUG TRAIN Batch 47/8200 loss 5.440755 loss_att 6.583044 loss_ctc 10.689220 loss_rnnt 4.363820 hw_loss 0.278778 lr 0.00029473 rank 4
2023-03-01 03:24:21,569 DEBUG TRAIN Batch 47/8200 loss 16.492163 loss_att 22.422607 loss_ctc 29.900188 loss_rnnt 13.375839 hw_loss 0.267180 lr 0.00029472 rank 3
2023-03-01 03:24:21,608 DEBUG TRAIN Batch 47/8200 loss 8.803443 loss_att 10.703068 loss_ctc 15.917728 loss_rnnt 7.325050 hw_loss 0.281055 lr 0.00029473 rank 5
2023-03-01 03:25:00,269 DEBUG TRAIN Batch 47/8300 loss 9.577046 loss_att 12.149323 loss_ctc 16.470676 loss_rnnt 8.038595 hw_loss 0.196587 lr 0.00029471 rank 3
2023-03-01 03:25:00,272 DEBUG TRAIN Batch 47/8300 loss 9.149230 loss_att 12.754518 loss_ctc 14.751350 loss_rnnt 7.577886 hw_loss 0.193757 lr 0.00029471 rank 7
2023-03-01 03:25:00,277 DEBUG TRAIN Batch 47/8300 loss 6.539623 loss_att 11.088517 loss_ctc 10.860118 loss_rnnt 5.053033 hw_loss 0.001398 lr 0.00029472 rank 2
2023-03-01 03:25:00,289 DEBUG TRAIN Batch 47/8300 loss 1.457049 loss_att 4.008254 loss_ctc 3.199128 loss_rnnt 0.602393 hw_loss 0.210258 lr 0.00029472 rank 4
2023-03-01 03:25:00,290 DEBUG TRAIN Batch 47/8300 loss 5.189419 loss_att 8.734595 loss_ctc 8.233192 loss_rnnt 3.938621 hw_loss 0.254864 lr 0.00029472 rank 0
2023-03-01 03:25:00,292 DEBUG TRAIN Batch 47/8300 loss 9.584682 loss_att 11.356287 loss_ctc 15.549051 loss_rnnt 8.253942 hw_loss 0.339691 lr 0.00029472 rank 1
2023-03-01 03:25:00,297 DEBUG TRAIN Batch 47/8300 loss 8.209353 loss_att 10.949928 loss_ctc 10.686731 loss_rnnt 7.218616 hw_loss 0.210571 lr 0.00029471 rank 6
2023-03-01 03:25:00,297 DEBUG TRAIN Batch 47/8300 loss 8.251573 loss_att 10.660625 loss_ctc 13.158285 loss_rnnt 6.956342 hw_loss 0.298483 lr 0.00029472 rank 5
2023-03-01 03:25:28,418 DEBUG CV Batch 47/0 loss 0.721268 loss_att 0.804335 loss_ctc 1.121401 loss_rnnt 0.421669 hw_loss 0.430565 history loss 0.694554 rank 2
2023-03-01 03:25:28,489 DEBUG CV Batch 47/0 loss 0.721268 loss_att 0.804335 loss_ctc 1.121401 loss_rnnt 0.421669 hw_loss 0.430565 history loss 0.694554 rank 0
2023-03-01 03:25:28,611 DEBUG CV Batch 47/0 loss 0.721268 loss_att 0.804335 loss_ctc 1.121401 loss_rnnt 0.421669 hw_loss 0.430565 history loss 0.694554 rank 1
2023-03-01 03:25:28,626 DEBUG CV Batch 47/0 loss 0.721268 loss_att 0.804335 loss_ctc 1.121401 loss_rnnt 0.421669 hw_loss 0.430565 history loss 0.694554 rank 5
2023-03-01 03:25:28,634 DEBUG CV Batch 47/0 loss 0.721268 loss_att 0.804335 loss_ctc 1.121401 loss_rnnt 0.421669 hw_loss 0.430565 history loss 0.694554 rank 6
2023-03-01 03:25:28,643 DEBUG CV Batch 47/0 loss 0.721268 loss_att 0.804335 loss_ctc 1.121401 loss_rnnt 0.421669 hw_loss 0.430565 history loss 0.694554 rank 4
2023-03-01 03:25:28,735 DEBUG CV Batch 47/0 loss 0.721268 loss_att 0.804335 loss_ctc 1.121401 loss_rnnt 0.421669 hw_loss 0.430565 history loss 0.694554 rank 3
2023-03-01 03:25:28,833 DEBUG CV Batch 47/0 loss 0.721268 loss_att 0.804335 loss_ctc 1.121401 loss_rnnt 0.421669 hw_loss 0.430565 history loss 0.694554 rank 7
2023-03-01 03:25:39,973 DEBUG CV Batch 47/100 loss 3.866214 loss_att 4.928626 loss_ctc 10.182410 loss_rnnt 2.711302 hw_loss 0.188008 history loss 2.890325 rank 4
2023-03-01 03:25:39,979 DEBUG CV Batch 47/100 loss 3.866214 loss_att 4.928626 loss_ctc 10.182410 loss_rnnt 2.711302 hw_loss 0.188008 history loss 2.890325 rank 2
2023-03-01 03:25:40,027 DEBUG CV Batch 47/100 loss 3.866214 loss_att 4.928626 loss_ctc 10.182410 loss_rnnt 2.711302 hw_loss 0.188008 history loss 2.890325 rank 5
2023-03-01 03:25:40,060 DEBUG CV Batch 47/100 loss 3.866214 loss_att 4.928626 loss_ctc 10.182410 loss_rnnt 2.711302 hw_loss 0.188008 history loss 2.890325 rank 1
2023-03-01 03:25:40,063 DEBUG CV Batch 47/100 loss 3.866214 loss_att 4.928626 loss_ctc 10.182410 loss_rnnt 2.711302 hw_loss 0.188008 history loss 2.890325 rank 6
2023-03-01 03:25:40,234 DEBUG CV Batch 47/100 loss 3.866214 loss_att 4.928626 loss_ctc 10.182410 loss_rnnt 2.711302 hw_loss 0.188008 history loss 2.890325 rank 3
2023-03-01 03:25:40,503 DEBUG CV Batch 47/100 loss 3.866214 loss_att 4.928626 loss_ctc 10.182410 loss_rnnt 2.711302 hw_loss 0.188008 history loss 2.890325 rank 0
2023-03-01 03:25:40,703 DEBUG CV Batch 47/100 loss 3.866214 loss_att 4.928626 loss_ctc 10.182410 loss_rnnt 2.711302 hw_loss 0.188008 history loss 2.890325 rank 7
2023-03-01 03:25:53,373 DEBUG CV Batch 47/200 loss 4.166214 loss_att 9.501328 loss_ctc 6.737568 loss_rnnt 2.638036 hw_loss 0.221829 history loss 3.472243 rank 1
2023-03-01 03:25:53,422 DEBUG CV Batch 47/200 loss 4.166214 loss_att 9.501328 loss_ctc 6.737568 loss_rnnt 2.638036 hw_loss 0.221829 history loss 3.472243 rank 4
2023-03-01 03:25:53,451 DEBUG CV Batch 47/200 loss 4.166214 loss_att 9.501328 loss_ctc 6.737568 loss_rnnt 2.638036 hw_loss 0.221829 history loss 3.472243 rank 5
2023-03-01 03:25:53,591 DEBUG CV Batch 47/200 loss 4.166214 loss_att 9.501328 loss_ctc 6.737568 loss_rnnt 2.638036 hw_loss 0.221829 history loss 3.472243 rank 2
2023-03-01 03:25:53,889 DEBUG CV Batch 47/200 loss 4.166214 loss_att 9.501328 loss_ctc 6.737568 loss_rnnt 2.638036 hw_loss 0.221829 history loss 3.472243 rank 3
2023-03-01 03:25:53,947 DEBUG CV Batch 47/200 loss 4.166214 loss_att 9.501328 loss_ctc 6.737568 loss_rnnt 2.638036 hw_loss 0.221829 history loss 3.472243 rank 6
2023-03-01 03:25:54,585 DEBUG CV Batch 47/200 loss 4.166214 loss_att 9.501328 loss_ctc 6.737568 loss_rnnt 2.638036 hw_loss 0.221829 history loss 3.472243 rank 0
2023-03-01 03:25:54,670 DEBUG CV Batch 47/200 loss 4.166214 loss_att 9.501328 loss_ctc 6.737568 loss_rnnt 2.638036 hw_loss 0.221829 history loss 3.472243 rank 7
2023-03-01 03:26:05,134 DEBUG CV Batch 47/300 loss 3.092056 loss_att 3.815519 loss_ctc 5.710147 loss_rnnt 2.446987 hw_loss 0.283684 history loss 3.601295 rank 1
2023-03-01 03:26:05,457 DEBUG CV Batch 47/300 loss 3.092056 loss_att 3.815519 loss_ctc 5.710147 loss_rnnt 2.446987 hw_loss 0.283684 history loss 3.601295 rank 5
2023-03-01 03:26:05,680 DEBUG CV Batch 47/300 loss 3.092056 loss_att 3.815519 loss_ctc 5.710147 loss_rnnt 2.446987 hw_loss 0.283684 history loss 3.601295 rank 2
2023-03-01 03:26:06,061 DEBUG CV Batch 47/300 loss 3.092056 loss_att 3.815519 loss_ctc 5.710147 loss_rnnt 2.446987 hw_loss 0.283684 history loss 3.601295 rank 3
2023-03-01 03:26:06,075 DEBUG CV Batch 47/300 loss 3.092056 loss_att 3.815519 loss_ctc 5.710147 loss_rnnt 2.446987 hw_loss 0.283684 history loss 3.601295 rank 6
2023-03-01 03:26:06,161 DEBUG CV Batch 47/300 loss 3.092056 loss_att 3.815519 loss_ctc 5.710147 loss_rnnt 2.446987 hw_loss 0.283684 history loss 3.601295 rank 4
2023-03-01 03:26:07,310 DEBUG CV Batch 47/300 loss 3.092056 loss_att 3.815519 loss_ctc 5.710147 loss_rnnt 2.446987 hw_loss 0.283684 history loss 3.601295 rank 7
2023-03-01 03:26:07,403 DEBUG CV Batch 47/300 loss 3.092056 loss_att 3.815519 loss_ctc 5.710147 loss_rnnt 2.446987 hw_loss 0.283684 history loss 3.601295 rank 0
2023-03-01 03:26:17,187 DEBUG CV Batch 47/400 loss 12.290902 loss_att 60.767426 loss_ctc 6.426121 loss_rnnt 3.192696 hw_loss 0.346634 history loss 4.377672 rank 1
2023-03-01 03:26:17,637 DEBUG CV Batch 47/400 loss 12.290902 loss_att 60.767426 loss_ctc 6.426121 loss_rnnt 3.192696 hw_loss 0.346634 history loss 4.377672 rank 5
2023-03-01 03:26:18,131 DEBUG CV Batch 47/400 loss 12.290902 loss_att 60.767426 loss_ctc 6.426121 loss_rnnt 3.192696 hw_loss 0.346634 history loss 4.377672 rank 2
2023-03-01 03:26:18,169 DEBUG CV Batch 47/400 loss 12.290902 loss_att 60.767426 loss_ctc 6.426121 loss_rnnt 3.192696 hw_loss 0.346634 history loss 4.377672 rank 6
2023-03-01 03:26:18,234 DEBUG CV Batch 47/400 loss 12.290902 loss_att 60.767426 loss_ctc 6.426121 loss_rnnt 3.192696 hw_loss 0.346634 history loss 4.377672 rank 4
2023-03-01 03:26:18,505 DEBUG CV Batch 47/400 loss 12.290902 loss_att 60.767426 loss_ctc 6.426121 loss_rnnt 3.192696 hw_loss 0.346634 history loss 4.377672 rank 3
2023-03-01 03:26:20,105 DEBUG CV Batch 47/400 loss 12.290902 loss_att 60.767426 loss_ctc 6.426121 loss_rnnt 3.192696 hw_loss 0.346634 history loss 4.377672 rank 7
2023-03-01 03:26:20,210 DEBUG CV Batch 47/400 loss 12.290902 loss_att 60.767426 loss_ctc 6.426121 loss_rnnt 3.192696 hw_loss 0.346634 history loss 4.377672 rank 0
2023-03-01 03:26:27,947 DEBUG CV Batch 47/500 loss 3.999014 loss_att 4.101800 loss_ctc 5.060257 loss_rnnt 3.691744 hw_loss 0.272277 history loss 4.990834 rank 1
2023-03-01 03:26:27,976 DEBUG CV Batch 47/500 loss 3.999014 loss_att 4.101800 loss_ctc 5.060257 loss_rnnt 3.691744 hw_loss 0.272277 history loss 4.990834 rank 5
2023-03-01 03:26:28,462 DEBUG CV Batch 47/500 loss 3.999014 loss_att 4.101800 loss_ctc 5.060257 loss_rnnt 3.691744 hw_loss 0.272277 history loss 4.990834 rank 4
2023-03-01 03:26:28,562 DEBUG CV Batch 47/500 loss 3.999014 loss_att 4.101800 loss_ctc 5.060257 loss_rnnt 3.691744 hw_loss 0.272277 history loss 4.990834 rank 6
2023-03-01 03:26:28,692 DEBUG CV Batch 47/500 loss 3.999014 loss_att 4.101800 loss_ctc 5.060257 loss_rnnt 3.691744 hw_loss 0.272277 history loss 4.990834 rank 2
2023-03-01 03:26:29,202 DEBUG CV Batch 47/500 loss 3.999014 loss_att 4.101800 loss_ctc 5.060257 loss_rnnt 3.691744 hw_loss 0.272277 history loss 4.990834 rank 3
2023-03-01 03:26:31,354 DEBUG CV Batch 47/500 loss 3.999014 loss_att 4.101800 loss_ctc 5.060257 loss_rnnt 3.691744 hw_loss 0.272277 history loss 4.990834 rank 7
2023-03-01 03:26:31,538 DEBUG CV Batch 47/500 loss 3.999014 loss_att 4.101800 loss_ctc 5.060257 loss_rnnt 3.691744 hw_loss 0.272277 history loss 4.990834 rank 0
2023-03-01 03:26:40,027 DEBUG CV Batch 47/600 loss 6.614971 loss_att 5.792109 loss_ctc 8.803165 loss_rnnt 6.249197 hw_loss 0.447351 history loss 5.864556 rank 1
2023-03-01 03:26:40,147 DEBUG CV Batch 47/600 loss 6.614971 loss_att 5.792109 loss_ctc 8.803165 loss_rnnt 6.249197 hw_loss 0.447351 history loss 5.864556 rank 5
2023-03-01 03:26:40,428 DEBUG CV Batch 47/600 loss 6.614971 loss_att 5.792109 loss_ctc 8.803165 loss_rnnt 6.249197 hw_loss 0.447351 history loss 5.864556 rank 4
2023-03-01 03:26:40,923 DEBUG CV Batch 47/600 loss 6.614971 loss_att 5.792109 loss_ctc 8.803165 loss_rnnt 6.249197 hw_loss 0.447351 history loss 5.864556 rank 2
2023-03-01 03:26:41,041 DEBUG CV Batch 47/600 loss 6.614971 loss_att 5.792109 loss_ctc 8.803165 loss_rnnt 6.249197 hw_loss 0.447351 history loss 5.864556 rank 6
2023-03-01 03:26:41,731 DEBUG CV Batch 47/600 loss 6.614971 loss_att 5.792109 loss_ctc 8.803165 loss_rnnt 6.249197 hw_loss 0.447351 history loss 5.864556 rank 3
2023-03-01 03:26:43,937 DEBUG CV Batch 47/600 loss 6.614971 loss_att 5.792109 loss_ctc 8.803165 loss_rnnt 6.249197 hw_loss 0.447351 history loss 5.864556 rank 7
2023-03-01 03:26:44,467 DEBUG CV Batch 47/600 loss 6.614971 loss_att 5.792109 loss_ctc 8.803165 loss_rnnt 6.249197 hw_loss 0.447351 history loss 5.864556 rank 0
2023-03-01 03:26:51,196 DEBUG CV Batch 47/700 loss 13.157474 loss_att 28.632277 loss_ctc 16.491167 loss_rnnt 9.616910 hw_loss 0.002082 history loss 6.377415 rank 1
2023-03-01 03:26:51,621 DEBUG CV Batch 47/700 loss 13.157474 loss_att 28.632277 loss_ctc 16.491167 loss_rnnt 9.616910 hw_loss 0.002082 history loss 6.377415 rank 5
2023-03-01 03:26:51,967 DEBUG CV Batch 47/700 loss 13.157474 loss_att 28.632277 loss_ctc 16.491167 loss_rnnt 9.616910 hw_loss 0.002082 history loss 6.377415 rank 4
2023-03-01 03:26:52,476 DEBUG CV Batch 47/700 loss 13.157474 loss_att 28.632277 loss_ctc 16.491167 loss_rnnt 9.616910 hw_loss 0.002082 history loss 6.377415 rank 2
2023-03-01 03:26:52,878 DEBUG CV Batch 47/700 loss 13.157474 loss_att 28.632277 loss_ctc 16.491167 loss_rnnt 9.616910 hw_loss 0.002082 history loss 6.377415 rank 6
2023-03-01 03:26:53,605 DEBUG CV Batch 47/700 loss 13.157474 loss_att 28.632277 loss_ctc 16.491167 loss_rnnt 9.616910 hw_loss 0.002082 history loss 6.377415 rank 3
2023-03-01 03:26:55,989 DEBUG CV Batch 47/700 loss 13.157474 loss_att 28.632277 loss_ctc 16.491167 loss_rnnt 9.616910 hw_loss 0.002082 history loss 6.377415 rank 7
2023-03-01 03:26:56,561 DEBUG CV Batch 47/700 loss 13.157474 loss_att 28.632277 loss_ctc 16.491167 loss_rnnt 9.616910 hw_loss 0.002082 history loss 6.377415 rank 0
2023-03-01 03:27:02,217 DEBUG CV Batch 47/800 loss 6.394920 loss_att 7.100596 loss_ctc 11.806143 loss_rnnt 5.397445 hw_loss 0.252831 history loss 5.919452 rank 1
2023-03-01 03:27:02,788 DEBUG CV Batch 47/800 loss 6.394920 loss_att 7.100596 loss_ctc 11.806143 loss_rnnt 5.397445 hw_loss 0.252831 history loss 5.919452 rank 5
2023-03-01 03:27:02,922 DEBUG CV Batch 47/800 loss 6.394920 loss_att 7.100596 loss_ctc 11.806143 loss_rnnt 5.397445 hw_loss 0.252831 history loss 5.919452 rank 4
2023-03-01 03:27:03,993 DEBUG CV Batch 47/800 loss 6.394920 loss_att 7.100596 loss_ctc 11.806143 loss_rnnt 5.397445 hw_loss 0.252831 history loss 5.919452 rank 2
2023-03-01 03:27:04,098 DEBUG CV Batch 47/800 loss 6.394920 loss_att 7.100596 loss_ctc 11.806143 loss_rnnt 5.397445 hw_loss 0.252831 history loss 5.919452 rank 6
2023-03-01 03:27:04,868 DEBUG CV Batch 47/800 loss 6.394920 loss_att 7.100596 loss_ctc 11.806143 loss_rnnt 5.397445 hw_loss 0.252831 history loss 5.919452 rank 3
2023-03-01 03:27:07,869 DEBUG CV Batch 47/800 loss 6.394920 loss_att 7.100596 loss_ctc 11.806143 loss_rnnt 5.397445 hw_loss 0.252831 history loss 5.919452 rank 7
2023-03-01 03:27:08,570 DEBUG CV Batch 47/800 loss 6.394920 loss_att 7.100596 loss_ctc 11.806143 loss_rnnt 5.397445 hw_loss 0.252831 history loss 5.919452 rank 0
2023-03-01 03:27:15,454 DEBUG CV Batch 47/900 loss 10.257335 loss_att 10.933943 loss_ctc 17.560165 loss_rnnt 9.111693 hw_loss 0.068642 history loss 5.764344 rank 1
2023-03-01 03:27:16,110 DEBUG CV Batch 47/900 loss 10.257335 loss_att 10.933943 loss_ctc 17.560165 loss_rnnt 9.111693 hw_loss 0.068642 history loss 5.764344 rank 5
2023-03-01 03:27:16,126 DEBUG CV Batch 47/900 loss 10.257335 loss_att 10.933943 loss_ctc 17.560165 loss_rnnt 9.111693 hw_loss 0.068642 history loss 5.764344 rank 4
2023-03-01 03:27:17,542 DEBUG CV Batch 47/900 loss 10.257335 loss_att 10.933943 loss_ctc 17.560165 loss_rnnt 9.111693 hw_loss 0.068642 history loss 5.764344 rank 2
2023-03-01 03:27:17,690 DEBUG CV Batch 47/900 loss 10.257335 loss_att 10.933943 loss_ctc 17.560165 loss_rnnt 9.111693 hw_loss 0.068642 history loss 5.764344 rank 6
2023-03-01 03:27:18,976 DEBUG CV Batch 47/900 loss 10.257335 loss_att 10.933943 loss_ctc 17.560165 loss_rnnt 9.111693 hw_loss 0.068642 history loss 5.764344 rank 3
2023-03-01 03:27:21,662 DEBUG CV Batch 47/900 loss 10.257335 loss_att 10.933943 loss_ctc 17.560165 loss_rnnt 9.111693 hw_loss 0.068642 history loss 5.764344 rank 7
2023-03-01 03:27:22,614 DEBUG CV Batch 47/900 loss 10.257335 loss_att 10.933943 loss_ctc 17.560165 loss_rnnt 9.111693 hw_loss 0.068642 history loss 5.764344 rank 0
2023-03-01 03:27:27,849 DEBUG CV Batch 47/1000 loss 3.734224 loss_att 4.098759 loss_ctc 3.811496 loss_rnnt 3.449720 hw_loss 0.377426 history loss 5.571788 rank 1
2023-03-01 03:27:28,215 DEBUG CV Batch 47/1000 loss 3.734224 loss_att 4.098759 loss_ctc 3.811496 loss_rnnt 3.449720 hw_loss 0.377426 history loss 5.571788 rank 4
2023-03-01 03:27:28,406 DEBUG CV Batch 47/1000 loss 3.734224 loss_att 4.098759 loss_ctc 3.811496 loss_rnnt 3.449720 hw_loss 0.377426 history loss 5.571788 rank 5
2023-03-01 03:27:30,141 DEBUG CV Batch 47/1000 loss 3.734224 loss_att 4.098759 loss_ctc 3.811496 loss_rnnt 3.449720 hw_loss 0.377426 history loss 5.571788 rank 2
2023-03-01 03:27:30,304 DEBUG CV Batch 47/1000 loss 3.734224 loss_att 4.098759 loss_ctc 3.811496 loss_rnnt 3.449720 hw_loss 0.377426 history loss 5.571788 rank 6
2023-03-01 03:27:31,771 DEBUG CV Batch 47/1000 loss 3.734224 loss_att 4.098759 loss_ctc 3.811496 loss_rnnt 3.449720 hw_loss 0.377426 history loss 5.571788 rank 3
2023-03-01 03:27:34,716 DEBUG CV Batch 47/1000 loss 3.734224 loss_att 4.098759 loss_ctc 3.811496 loss_rnnt 3.449720 hw_loss 0.377426 history loss 5.571788 rank 7
2023-03-01 03:27:35,919 DEBUG CV Batch 47/1000 loss 3.734224 loss_att 4.098759 loss_ctc 3.811496 loss_rnnt 3.449720 hw_loss 0.377426 history loss 5.571788 rank 0
2023-03-01 03:27:39,965 DEBUG CV Batch 47/1100 loss 4.598542 loss_att 4.483032 loss_ctc 7.910261 loss_rnnt 3.955746 hw_loss 0.420629 history loss 5.537200 rank 1
2023-03-01 03:27:40,096 DEBUG CV Batch 47/1100 loss 4.598542 loss_att 4.483032 loss_ctc 7.910261 loss_rnnt 3.955746 hw_loss 0.420629 history loss 5.537200 rank 4
2023-03-01 03:27:40,658 DEBUG CV Batch 47/1100 loss 4.598542 loss_att 4.483032 loss_ctc 7.910261 loss_rnnt 3.955746 hw_loss 0.420629 history loss 5.537200 rank 5
2023-03-01 03:27:42,266 DEBUG CV Batch 47/1100 loss 4.598542 loss_att 4.483032 loss_ctc 7.910261 loss_rnnt 3.955746 hw_loss 0.420629 history loss 5.537200 rank 2
2023-03-01 03:27:42,501 DEBUG CV Batch 47/1100 loss 4.598542 loss_att 4.483032 loss_ctc 7.910261 loss_rnnt 3.955746 hw_loss 0.420629 history loss 5.537200 rank 6
2023-03-01 03:27:43,893 DEBUG CV Batch 47/1100 loss 4.598542 loss_att 4.483032 loss_ctc 7.910261 loss_rnnt 3.955746 hw_loss 0.420629 history loss 5.537200 rank 3
2023-03-01 03:27:47,135 DEBUG CV Batch 47/1100 loss 4.598542 loss_att 4.483032 loss_ctc 7.910261 loss_rnnt 3.955746 hw_loss 0.420629 history loss 5.537200 rank 7
2023-03-01 03:27:48,664 DEBUG CV Batch 47/1100 loss 4.598542 loss_att 4.483032 loss_ctc 7.910261 loss_rnnt 3.955746 hw_loss 0.420629 history loss 5.537200 rank 0
2023-03-01 03:27:50,409 DEBUG CV Batch 47/1200 loss 7.445146 loss_att 7.033825 loss_ctc 9.134604 loss_rnnt 7.173322 hw_loss 0.241550 history loss 5.804696 rank 4
2023-03-01 03:27:51,373 DEBUG CV Batch 47/1200 loss 7.445146 loss_att 7.033825 loss_ctc 9.134604 loss_rnnt 7.173322 hw_loss 0.241550 history loss 5.804696 rank 5
2023-03-01 03:27:51,415 DEBUG CV Batch 47/1200 loss 7.445146 loss_att 7.033825 loss_ctc 9.134604 loss_rnnt 7.173322 hw_loss 0.241550 history loss 5.804696 rank 1
2023-03-01 03:27:53,216 DEBUG CV Batch 47/1200 loss 7.445146 loss_att 7.033825 loss_ctc 9.134604 loss_rnnt 7.173322 hw_loss 0.241550 history loss 5.804696 rank 2
2023-03-01 03:27:53,576 DEBUG CV Batch 47/1200 loss 7.445146 loss_att 7.033825 loss_ctc 9.134604 loss_rnnt 7.173322 hw_loss 0.241550 history loss 5.804696 rank 6
2023-03-01 03:27:54,855 DEBUG CV Batch 47/1200 loss 7.445146 loss_att 7.033825 loss_ctc 9.134604 loss_rnnt 7.173322 hw_loss 0.241550 history loss 5.804696 rank 3
2023-03-01 03:27:58,387 DEBUG CV Batch 47/1200 loss 7.445146 loss_att 7.033825 loss_ctc 9.134604 loss_rnnt 7.173322 hw_loss 0.241550 history loss 5.804696 rank 7
2023-03-01 03:28:00,065 DEBUG CV Batch 47/1200 loss 7.445146 loss_att 7.033825 loss_ctc 9.134604 loss_rnnt 7.173322 hw_loss 0.241550 history loss 5.804696 rank 0
2023-03-01 03:28:02,282 DEBUG CV Batch 47/1300 loss 4.722188 loss_att 4.475154 loss_ctc 6.917802 loss_rnnt 4.344141 hw_loss 0.252572 history loss 6.092801 rank 4
2023-03-01 03:28:03,415 DEBUG CV Batch 47/1300 loss 4.722188 loss_att 4.475154 loss_ctc 6.917802 loss_rnnt 4.344141 hw_loss 0.252572 history loss 6.092801 rank 5
2023-03-01 03:28:03,558 DEBUG CV Batch 47/1300 loss 4.722188 loss_att 4.475154 loss_ctc 6.917802 loss_rnnt 4.344141 hw_loss 0.252572 history loss 6.092801 rank 1
2023-03-01 03:28:05,574 DEBUG CV Batch 47/1300 loss 4.722188 loss_att 4.475154 loss_ctc 6.917802 loss_rnnt 4.344141 hw_loss 0.252572 history loss 6.092801 rank 2
2023-03-01 03:28:05,899 DEBUG CV Batch 47/1300 loss 4.722188 loss_att 4.475154 loss_ctc 6.917802 loss_rnnt 4.344141 hw_loss 0.252572 history loss 6.092801 rank 6
2023-03-01 03:28:07,121 DEBUG CV Batch 47/1300 loss 4.722188 loss_att 4.475154 loss_ctc 6.917802 loss_rnnt 4.344141 hw_loss 0.252572 history loss 6.092801 rank 3
2023-03-01 03:28:11,045 DEBUG CV Batch 47/1300 loss 4.722188 loss_att 4.475154 loss_ctc 6.917802 loss_rnnt 4.344141 hw_loss 0.252572 history loss 6.092801 rank 7
2023-03-01 03:28:12,931 DEBUG CV Batch 47/1300 loss 4.722188 loss_att 4.475154 loss_ctc 6.917802 loss_rnnt 4.344141 hw_loss 0.252572 history loss 6.092801 rank 0
2023-03-01 03:28:13,414 DEBUG CV Batch 47/1400 loss 3.176139 loss_att 9.037535 loss_ctc 3.866333 loss_rnnt 1.857672 hw_loss 0.101553 history loss 6.348734 rank 4
2023-03-01 03:28:14,826 DEBUG CV Batch 47/1400 loss 3.176139 loss_att 9.037535 loss_ctc 3.866333 loss_rnnt 1.857672 hw_loss 0.101553 history loss 6.348734 rank 5
2023-03-01 03:28:14,834 DEBUG CV Batch 47/1400 loss 3.176139 loss_att 9.037535 loss_ctc 3.866333 loss_rnnt 1.857672 hw_loss 0.101553 history loss 6.348734 rank 1
2023-03-01 03:28:17,027 DEBUG CV Batch 47/1400 loss 3.176139 loss_att 9.037535 loss_ctc 3.866333 loss_rnnt 1.857672 hw_loss 0.101553 history loss 6.348734 rank 2
2023-03-01 03:28:17,576 DEBUG CV Batch 47/1400 loss 3.176139 loss_att 9.037535 loss_ctc 3.866333 loss_rnnt 1.857672 hw_loss 0.101553 history loss 6.348734 rank 6
2023-03-01 03:28:19,063 DEBUG CV Batch 47/1400 loss 3.176139 loss_att 9.037535 loss_ctc 3.866333 loss_rnnt 1.857672 hw_loss 0.101553 history loss 6.348734 rank 3
2023-03-01 03:28:22,912 DEBUG CV Batch 47/1400 loss 3.176139 loss_att 9.037535 loss_ctc 3.866333 loss_rnnt 1.857672 hw_loss 0.101553 history loss 6.348734 rank 7
2023-03-01 03:28:24,616 DEBUG CV Batch 47/1500 loss 7.563543 loss_att 7.325362 loss_ctc 7.950109 loss_rnnt 7.386784 hw_loss 0.324101 history loss 6.218067 rank 4
2023-03-01 03:28:24,918 DEBUG CV Batch 47/1400 loss 3.176139 loss_att 9.037535 loss_ctc 3.866333 loss_rnnt 1.857672 hw_loss 0.101553 history loss 6.348734 rank 0
2023-03-01 03:28:25,940 DEBUG CV Batch 47/1500 loss 7.563543 loss_att 7.325362 loss_ctc 7.950109 loss_rnnt 7.386784 hw_loss 0.324101 history loss 6.218067 rank 1
2023-03-01 03:28:26,254 DEBUG CV Batch 47/1500 loss 7.563543 loss_att 7.325362 loss_ctc 7.950109 loss_rnnt 7.386784 hw_loss 0.324101 history loss 6.218067 rank 5
2023-03-01 03:28:29,321 DEBUG CV Batch 47/1500 loss 7.563543 loss_att 7.325362 loss_ctc 7.950109 loss_rnnt 7.386784 hw_loss 0.324101 history loss 6.218067 rank 6
2023-03-01 03:28:29,343 DEBUG CV Batch 47/1500 loss 7.563543 loss_att 7.325362 loss_ctc 7.950109 loss_rnnt 7.386784 hw_loss 0.324101 history loss 6.218067 rank 2
2023-03-01 03:28:30,819 DEBUG CV Batch 47/1500 loss 7.563543 loss_att 7.325362 loss_ctc 7.950109 loss_rnnt 7.386784 hw_loss 0.324101 history loss 6.218067 rank 3
2023-03-01 03:28:35,061 DEBUG CV Batch 47/1500 loss 7.563543 loss_att 7.325362 loss_ctc 7.950109 loss_rnnt 7.386784 hw_loss 0.324101 history loss 6.218067 rank 7
2023-03-01 03:28:37,283 DEBUG CV Batch 47/1500 loss 7.563543 loss_att 7.325362 loss_ctc 7.950109 loss_rnnt 7.386784 hw_loss 0.324101 history loss 6.218067 rank 0
2023-03-01 03:28:38,160 DEBUG CV Batch 47/1600 loss 8.364681 loss_att 13.993714 loss_ctc 10.728840 loss_rnnt 6.892399 hw_loss 0.058604 history loss 6.182600 rank 4
2023-03-01 03:28:39,046 DEBUG CV Batch 47/1600 loss 8.364681 loss_att 13.993714 loss_ctc 10.728840 loss_rnnt 6.892399 hw_loss 0.058604 history loss 6.182600 rank 1
2023-03-01 03:28:39,631 DEBUG CV Batch 47/1600 loss 8.364681 loss_att 13.993714 loss_ctc 10.728840 loss_rnnt 6.892399 hw_loss 0.058604 history loss 6.182600 rank 5
2023-03-01 03:28:42,590 DEBUG CV Batch 47/1600 loss 8.364681 loss_att 13.993714 loss_ctc 10.728840 loss_rnnt 6.892399 hw_loss 0.058604 history loss 6.182600 rank 2
2023-03-01 03:28:42,711 DEBUG CV Batch 47/1600 loss 8.364681 loss_att 13.993714 loss_ctc 10.728840 loss_rnnt 6.892399 hw_loss 0.058604 history loss 6.182600 rank 6
2023-03-01 03:28:44,321 DEBUG CV Batch 47/1600 loss 8.364681 loss_att 13.993714 loss_ctc 10.728840 loss_rnnt 6.892399 hw_loss 0.058604 history loss 6.182600 rank 3
2023-03-01 03:28:48,528 DEBUG CV Batch 47/1600 loss 8.364681 loss_att 13.993714 loss_ctc 10.728840 loss_rnnt 6.892399 hw_loss 0.058604 history loss 6.182600 rank 7
2023-03-01 03:28:50,575 DEBUG CV Batch 47/1700 loss 8.080976 loss_att 6.946948 loss_ctc 13.821037 loss_rnnt 7.390569 hw_loss 0.284758 history loss 6.129268 rank 4
2023-03-01 03:28:50,999 DEBUG CV Batch 47/1600 loss 8.364681 loss_att 13.993714 loss_ctc 10.728840 loss_rnnt 6.892399 hw_loss 0.058604 history loss 6.182600 rank 0
2023-03-01 03:28:51,601 DEBUG CV Batch 47/1700 loss 8.080976 loss_att 6.946948 loss_ctc 13.821037 loss_rnnt 7.390569 hw_loss 0.284758 history loss 6.129268 rank 1
2023-03-01 03:28:52,274 DEBUG CV Batch 47/1700 loss 8.080976 loss_att 6.946948 loss_ctc 13.821037 loss_rnnt 7.390569 hw_loss 0.284758 history loss 6.129268 rank 5
2023-03-01 03:28:55,320 DEBUG CV Batch 47/1700 loss 8.080976 loss_att 6.946948 loss_ctc 13.821037 loss_rnnt 7.390569 hw_loss 0.284758 history loss 6.129268 rank 2
2023-03-01 03:28:55,502 DEBUG CV Batch 47/1700 loss 8.080976 loss_att 6.946948 loss_ctc 13.821037 loss_rnnt 7.390569 hw_loss 0.284758 history loss 6.129268 rank 6
2023-03-01 03:28:57,177 DEBUG CV Batch 47/1700 loss 8.080976 loss_att 6.946948 loss_ctc 13.821037 loss_rnnt 7.390569 hw_loss 0.284758 history loss 6.129268 rank 3
2023-03-01 03:28:59,642 INFO Epoch 47 CV info cv_loss 6.111438530888546
2023-03-01 03:28:59,642 INFO Epoch 48 TRAIN info lr 0.0002947097006732698
2023-03-01 03:28:59,647 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 03:29:00,678 INFO Epoch 47 CV info cv_loss 6.111438532092441
2023-03-01 03:29:00,679 INFO Epoch 48 TRAIN info lr 0.0002947137962241872
2023-03-01 03:29:00,684 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 03:29:01,019 DEBUG CV Batch 47/1700 loss 8.080976 loss_att 6.946948 loss_ctc 13.821037 loss_rnnt 7.390569 hw_loss 0.284758 history loss 6.129268 rank 7
2023-03-01 03:29:01,502 INFO Epoch 47 CV info cv_loss 6.111438531164214
2023-03-01 03:29:01,503 INFO Epoch 48 TRAIN info lr 0.0002947097006732698
2023-03-01 03:29:01,508 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 03:29:03,568 DEBUG CV Batch 47/1700 loss 8.080976 loss_att 6.946948 loss_ctc 13.821037 loss_rnnt 7.390569 hw_loss 0.284758 history loss 6.129268 rank 0
2023-03-01 03:29:04,647 INFO Epoch 47 CV info cv_loss 6.111438531526028
2023-03-01 03:29:04,648 INFO Epoch 48 TRAIN info lr 0.0002947107245449919
2023-03-01 03:29:04,653 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 03:29:05,225 INFO Epoch 47 CV info cv_loss 6.111438531192212
2023-03-01 03:29:05,226 INFO Epoch 48 TRAIN info lr 0.00029471328427098484
2023-03-01 03:29:05,231 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 03:29:06,551 INFO Epoch 47 CV info cv_loss 6.111438531984758
2023-03-01 03:29:06,552 INFO Epoch 48 TRAIN info lr 0.0002947066291221301
2023-03-01 03:29:06,556 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 03:29:10,425 INFO Epoch 47 CV info cv_loss 6.111438532624394
2023-03-01 03:29:10,425 INFO Epoch 48 TRAIN info lr 0.0002947009981944633
2023-03-01 03:29:10,429 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 03:29:13,253 INFO Epoch 47 CV info cv_loss 6.111438531795236
2023-03-01 03:29:13,254 INFO Checkpoint: save to checkpoint exp/2_27_rnnt_bias_loss_2_class_both_finetune/47.pt
2023-03-01 03:29:13,819 INFO Epoch 48 TRAIN info lr 0.00029471430818005755
2023-03-01 03:29:13,823 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 03:30:23,043 DEBUG TRAIN Batch 48/0 loss 5.652512 loss_att 5.958901 loss_ctc 8.883961 loss_rnnt 4.970328 hw_loss 0.356336 lr 0.00029471 rank 4
2023-03-01 03:30:23,043 DEBUG TRAIN Batch 48/0 loss 5.841392 loss_att 6.132292 loss_ctc 8.389071 loss_rnnt 5.275645 hw_loss 0.314768 lr 0.00029471 rank 3
2023-03-01 03:30:23,045 DEBUG TRAIN Batch 48/0 loss 4.381907 loss_att 4.938272 loss_ctc 6.655694 loss_rnnt 3.773513 hw_loss 0.363656 lr 0.00029471 rank 5
2023-03-01 03:30:23,046 DEBUG TRAIN Batch 48/0 loss 6.778767 loss_att 6.669580 loss_ctc 9.070777 loss_rnnt 6.338052 hw_loss 0.294283 lr 0.00029470 rank 7
2023-03-01 03:30:23,049 DEBUG TRAIN Batch 48/0 loss 6.827634 loss_att 6.863204 loss_ctc 11.585876 loss_rnnt 6.035336 hw_loss 0.282659 lr 0.00029471 rank 1
2023-03-01 03:30:23,056 DEBUG TRAIN Batch 48/0 loss 5.916441 loss_att 7.265097 loss_ctc 9.964162 loss_rnnt 4.891216 hw_loss 0.404623 lr 0.00029471 rank 2
2023-03-01 03:30:23,058 DEBUG TRAIN Batch 48/0 loss 3.921027 loss_att 4.244131 loss_ctc 5.793151 loss_rnnt 3.426360 hw_loss 0.338307 lr 0.00029471 rank 6
2023-03-01 03:30:23,068 DEBUG TRAIN Batch 48/0 loss 7.801392 loss_att 7.232046 loss_ctc 11.792734 loss_rnnt 7.146646 hw_loss 0.443316 lr 0.00029471 rank 0
2023-03-01 03:31:00,691 DEBUG TRAIN Batch 48/100 loss 3.695648 loss_att 9.916527 loss_ctc 7.952374 loss_rnnt 1.775896 hw_loss 0.202523 lr 0.00029470 rank 0
2023-03-01 03:31:00,694 DEBUG TRAIN Batch 48/100 loss 11.004305 loss_att 12.641561 loss_ctc 13.731284 loss_rnnt 10.165060 hw_loss 0.277868 lr 0.00029470 rank 1
2023-03-01 03:31:00,709 DEBUG TRAIN Batch 48/100 loss 7.327970 loss_att 10.213085 loss_ctc 12.214755 loss_rnnt 6.051028 hw_loss 0.090650 lr 0.00029470 rank 4
2023-03-01 03:31:00,711 DEBUG TRAIN Batch 48/100 loss 7.460847 loss_att 8.863619 loss_ctc 12.762042 loss_rnnt 6.380413 hw_loss 0.174477 lr 0.00029470 rank 5
2023-03-01 03:31:00,714 DEBUG TRAIN Batch 48/100 loss 1.070345 loss_att 3.307284 loss_ctc 1.740210 loss_rnnt 0.439710 hw_loss 0.176124 lr 0.00029469 rank 3
2023-03-01 03:31:00,715 DEBUG TRAIN Batch 48/100 loss 3.648020 loss_att 6.732405 loss_ctc 8.677248 loss_rnnt 2.219902 hw_loss 0.263769 lr 0.00029469 rank 7
2023-03-01 03:31:00,738 DEBUG TRAIN Batch 48/100 loss 6.471529 loss_att 8.727340 loss_ctc 8.658880 loss_rnnt 5.583671 hw_loss 0.271967 lr 0.00029470 rank 2
2023-03-01 03:31:00,743 DEBUG TRAIN Batch 48/100 loss 4.214087 loss_att 6.850235 loss_ctc 8.621154 loss_rnnt 2.943757 hw_loss 0.291547 lr 0.00029470 rank 6
2023-03-01 03:31:38,437 DEBUG TRAIN Batch 48/200 loss 8.310318 loss_att 12.019226 loss_ctc 12.848674 loss_rnnt 6.892972 hw_loss 0.132093 lr 0.00029469 rank 6
2023-03-01 03:31:38,442 DEBUG TRAIN Batch 48/200 loss 11.727816 loss_att 15.246307 loss_ctc 20.400627 loss_rnnt 9.756467 hw_loss 0.208641 lr 0.00029469 rank 1
2023-03-01 03:31:38,449 DEBUG TRAIN Batch 48/200 loss 7.542978 loss_att 10.687992 loss_ctc 13.804931 loss_rnnt 5.956895 hw_loss 0.229036 lr 0.00029469 rank 0
2023-03-01 03:31:38,449 DEBUG TRAIN Batch 48/200 loss 3.994546 loss_att 5.530426 loss_ctc 6.584770 loss_rnnt 3.254573 hw_loss 0.163940 lr 0.00029468 rank 2
2023-03-01 03:31:38,450 DEBUG TRAIN Batch 48/200 loss 3.484492 loss_att 6.093378 loss_ctc 4.684999 loss_rnnt 2.722553 hw_loss 0.150177 lr 0.00029467 rank 7
2023-03-01 03:31:38,453 DEBUG TRAIN Batch 48/200 loss 3.050502 loss_att 6.407943 loss_ctc 5.492218 loss_rnnt 2.020994 hw_loss 0.060858 lr 0.00029468 rank 5
2023-03-01 03:31:38,453 DEBUG TRAIN Batch 48/200 loss 5.113643 loss_att 5.961814 loss_ctc 8.584656 loss_rnnt 4.378346 hw_loss 0.192863 lr 0.00029468 rank 4
2023-03-01 03:31:38,471 DEBUG TRAIN Batch 48/200 loss 3.521573 loss_att 6.374237 loss_ctc 7.082747 loss_rnnt 2.243863 hw_loss 0.435663 lr 0.00029468 rank 3
2023-03-01 03:32:17,267 DEBUG TRAIN Batch 48/300 loss 4.193405 loss_att 7.796341 loss_ctc 12.169436 loss_rnnt 2.205161 hw_loss 0.382848 lr 0.00029467 rank 4
2023-03-01 03:32:17,277 DEBUG TRAIN Batch 48/300 loss 1.469623 loss_att 3.394901 loss_ctc 2.605042 loss_rnnt 0.833327 hw_loss 0.187222 lr 0.00029467 rank 6
2023-03-01 03:32:17,279 DEBUG TRAIN Batch 48/300 loss 11.393245 loss_att 14.769686 loss_ctc 20.910301 loss_rnnt 9.303493 hw_loss 0.272854 lr 0.00029468 rank 0
2023-03-01 03:32:17,284 DEBUG TRAIN Batch 48/300 loss 4.749605 loss_att 7.473115 loss_ctc 8.979780 loss_rnnt 3.575713 hw_loss 0.122187 lr 0.00029467 rank 2
2023-03-01 03:32:17,285 DEBUG TRAIN Batch 48/300 loss 5.025964 loss_att 7.159614 loss_ctc 8.765261 loss_rnnt 3.992852 hw_loss 0.202142 lr 0.00029466 rank 7
2023-03-01 03:32:17,286 DEBUG TRAIN Batch 48/300 loss 6.867009 loss_att 8.767851 loss_ctc 8.920527 loss_rnnt 6.069012 hw_loss 0.270050 lr 0.00029467 rank 1
2023-03-01 03:32:17,287 DEBUG TRAIN Batch 48/300 loss 13.607567 loss_att 18.825062 loss_ctc 22.488068 loss_rnnt 11.263983 hw_loss 0.217536 lr 0.00029467 rank 3
2023-03-01 03:32:17,302 DEBUG TRAIN Batch 48/300 loss 17.561327 loss_att 17.782459 loss_ctc 24.839851 loss_rnnt 16.532520 hw_loss 0.026460 lr 0.00029467 rank 5
2023-03-01 03:33:25,382 DEBUG TRAIN Batch 48/400 loss 5.060067 loss_att 8.721825 loss_ctc 7.265050 loss_rnnt 3.873729 hw_loss 0.299980 lr 0.00029466 rank 2
2023-03-01 03:33:25,385 DEBUG TRAIN Batch 48/400 loss 5.909865 loss_att 8.496931 loss_ctc 8.659693 loss_rnnt 4.895919 hw_loss 0.243543 lr 0.00029465 rank 3
2023-03-01 03:33:25,396 DEBUG TRAIN Batch 48/400 loss 3.797081 loss_att 5.621831 loss_ctc 5.087185 loss_rnnt 3.181642 hw_loss 0.147140 lr 0.00029466 rank 5
2023-03-01 03:33:25,398 DEBUG TRAIN Batch 48/400 loss 6.258858 loss_att 7.922800 loss_ctc 8.097305 loss_rnnt 5.499286 hw_loss 0.340609 lr 0.00029466 rank 0
2023-03-01 03:33:25,401 DEBUG TRAIN Batch 48/400 loss 6.801490 loss_att 9.018117 loss_ctc 11.493635 loss_rnnt 5.558197 hw_loss 0.326902 lr 0.00029466 rank 6
2023-03-01 03:33:25,401 DEBUG TRAIN Batch 48/400 loss 7.473270 loss_att 9.858594 loss_ctc 16.555513 loss_rnnt 5.618073 hw_loss 0.313439 lr 0.00029465 rank 7
2023-03-01 03:33:25,401 DEBUG TRAIN Batch 48/400 loss 4.525500 loss_att 7.612739 loss_ctc 8.969400 loss_rnnt 3.175109 hw_loss 0.263294 lr 0.00029466 rank 1
2023-03-01 03:33:25,408 DEBUG TRAIN Batch 48/400 loss 5.265642 loss_att 8.432695 loss_ctc 9.219822 loss_rnnt 3.949431 hw_loss 0.291706 lr 0.00029466 rank 4
2023-03-01 03:34:03,520 DEBUG TRAIN Batch 48/500 loss 10.543476 loss_att 10.467010 loss_ctc 16.229256 loss_rnnt 9.662434 hw_loss 0.259184 lr 0.00029464 rank 7
2023-03-01 03:34:03,541 DEBUG TRAIN Batch 48/500 loss 7.396088 loss_att 10.089394 loss_ctc 13.967291 loss_rnnt 5.873453 hw_loss 0.202150 lr 0.00029465 rank 1
2023-03-01 03:34:03,543 DEBUG TRAIN Batch 48/500 loss 3.254075 loss_att 5.606649 loss_ctc 8.484600 loss_rnnt 2.057708 hw_loss 0.053342 lr 0.00029465 rank 5
2023-03-01 03:34:03,543 DEBUG TRAIN Batch 48/500 loss 5.763881 loss_att 7.096808 loss_ctc 8.646385 loss_rnnt 4.956357 hw_loss 0.293634 lr 0.00029465 rank 2
2023-03-01 03:34:03,545 DEBUG TRAIN Batch 48/500 loss 8.257889 loss_att 10.964273 loss_ctc 10.601607 loss_rnnt 7.234637 hw_loss 0.317773 lr 0.00029465 rank 6
2023-03-01 03:34:03,545 DEBUG TRAIN Batch 48/500 loss 8.720265 loss_att 11.830645 loss_ctc 13.687923 loss_rnnt 7.276096 hw_loss 0.299512 lr 0.00029464 rank 3
2023-03-01 03:34:03,546 DEBUG TRAIN Batch 48/500 loss 7.240652 loss_att 9.694875 loss_ctc 14.151402 loss_rnnt 5.651450 hw_loss 0.331733 lr 0.00029465 rank 0
2023-03-01 03:34:03,552 DEBUG TRAIN Batch 48/500 loss 12.651534 loss_att 13.008128 loss_ctc 17.963831 loss_rnnt 11.743090 hw_loss 0.241534 lr 0.00029465 rank 4
2023-03-01 03:34:41,972 DEBUG TRAIN Batch 48/600 loss 7.209843 loss_att 8.399975 loss_ctc 9.766462 loss_rnnt 6.510513 hw_loss 0.225788 lr 0.00029463 rank 3
2023-03-01 03:34:41,978 DEBUG TRAIN Batch 48/600 loss 6.218109 loss_att 7.916125 loss_ctc 8.532936 loss_rnnt 5.420858 hw_loss 0.279383 lr 0.00029464 rank 0
2023-03-01 03:34:41,981 DEBUG TRAIN Batch 48/600 loss 5.539093 loss_att 6.604202 loss_ctc 10.046181 loss_rnnt 4.533866 hw_loss 0.358613 lr 0.00029462 rank 7
2023-03-01 03:34:41,984 DEBUG TRAIN Batch 48/600 loss 3.096013 loss_att 5.525879 loss_ctc 4.414574 loss_rnnt 2.269802 hw_loss 0.308306 lr 0.00029464 rank 1
2023-03-01 03:34:41,985 DEBUG TRAIN Batch 48/600 loss 6.148967 loss_att 7.476823 loss_ctc 10.308397 loss_rnnt 5.107695 hw_loss 0.414581 lr 0.00029463 rank 2
2023-03-01 03:34:41,987 DEBUG TRAIN Batch 48/600 loss 11.438295 loss_att 13.526140 loss_ctc 18.045074 loss_rnnt 10.044077 hw_loss 0.179523 lr 0.00029463 rank 5
2023-03-01 03:34:41,987 DEBUG TRAIN Batch 48/600 loss 5.121726 loss_att 6.561684 loss_ctc 6.679170 loss_rnnt 4.419092 hw_loss 0.388093 lr 0.00029464 rank 6
2023-03-01 03:34:41,987 DEBUG TRAIN Batch 48/600 loss 2.600562 loss_att 4.426792 loss_ctc 5.939519 loss_rnnt 1.605857 hw_loss 0.345496 lr 0.00029463 rank 4
2023-03-01 03:35:21,413 DEBUG TRAIN Batch 48/700 loss 2.465073 loss_att 5.587357 loss_ctc 4.369059 loss_rnnt 1.439184 hw_loss 0.276687 lr 0.00029462 rank 6
2023-03-01 03:35:21,424 DEBUG TRAIN Batch 48/700 loss 3.085694 loss_att 10.306461 loss_ctc 8.165076 loss_rnnt 0.780775 hw_loss 0.344089 lr 0.00029462 rank 4
2023-03-01 03:35:21,430 DEBUG TRAIN Batch 48/700 loss 5.216414 loss_att 10.234583 loss_ctc 11.701834 loss_rnnt 3.262342 hw_loss 0.160717 lr 0.00029462 rank 3
2023-03-01 03:35:21,431 DEBUG TRAIN Batch 48/700 loss 4.822799 loss_att 8.518589 loss_ctc 8.892807 loss_rnnt 3.450938 hw_loss 0.168814 lr 0.00029461 rank 7
2023-03-01 03:35:21,431 DEBUG TRAIN Batch 48/700 loss 0.961060 loss_att 3.496644 loss_ctc 1.874141 loss_rnnt 0.184979 hw_loss 0.276038 lr 0.00029462 rank 5
2023-03-01 03:35:21,431 DEBUG TRAIN Batch 48/700 loss 8.900346 loss_att 11.449191 loss_ctc 15.735026 loss_rnnt 7.441409 hw_loss 0.071020 lr 0.00029462 rank 0
2023-03-01 03:35:21,437 DEBUG TRAIN Batch 48/700 loss 3.672413 loss_att 6.405420 loss_ctc 7.179553 loss_rnnt 2.588588 hw_loss 0.130509 lr 0.00029462 rank 1
2023-03-01 03:35:21,450 DEBUG TRAIN Batch 48/700 loss 5.568467 loss_att 9.737095 loss_ctc 11.314621 loss_rnnt 3.860080 hw_loss 0.203454 lr 0.00029462 rank 2
2023-03-01 03:36:26,834 DEBUG TRAIN Batch 48/800 loss 8.306041 loss_att 12.252318 loss_ctc 15.545593 loss_rnnt 6.475153 hw_loss 0.143172 lr 0.00029461 rank 6
2023-03-01 03:36:26,843 DEBUG TRAIN Batch 48/800 loss 5.448412 loss_att 7.131933 loss_ctc 10.512356 loss_rnnt 4.286535 hw_loss 0.281214 lr 0.00029461 rank 1
2023-03-01 03:36:26,847 DEBUG TRAIN Batch 48/800 loss 8.196897 loss_att 11.473888 loss_ctc 10.495260 loss_rnnt 7.192643 hw_loss 0.079510 lr 0.00029461 rank 0
2023-03-01 03:36:26,851 DEBUG TRAIN Batch 48/800 loss 5.931241 loss_att 10.639601 loss_ctc 8.303119 loss_rnnt 4.456134 hw_loss 0.407220 lr 0.00029460 rank 7
2023-03-01 03:36:26,853 DEBUG TRAIN Batch 48/800 loss 2.923417 loss_att 5.508421 loss_ctc 5.065758 loss_rnnt 1.977647 hw_loss 0.268358 lr 0.00029461 rank 5
2023-03-01 03:36:26,879 DEBUG TRAIN Batch 48/800 loss 7.368078 loss_att 8.799435 loss_ctc 13.182598 loss_rnnt 6.144199 hw_loss 0.304384 lr 0.00029461 rank 2
2023-03-01 03:36:26,879 DEBUG TRAIN Batch 48/800 loss 1.571297 loss_att 4.968246 loss_ctc 3.838296 loss_rnnt 0.432263 hw_loss 0.295082 lr 0.00029461 rank 4
2023-03-01 03:36:26,895 DEBUG TRAIN Batch 48/800 loss 6.904921 loss_att 9.956816 loss_ctc 15.459326 loss_rnnt 5.070948 hw_loss 0.155637 lr 0.00029460 rank 3
2023-03-01 03:37:05,094 DEBUG TRAIN Batch 48/900 loss 7.666009 loss_att 11.023547 loss_ctc 12.549875 loss_rnnt 6.210258 hw_loss 0.249488 lr 0.00029459 rank 5
2023-03-01 03:37:05,105 DEBUG TRAIN Batch 48/900 loss 4.757363 loss_att 7.373790 loss_ctc 5.250724 loss_rnnt 4.099740 hw_loss 0.128543 lr 0.00029459 rank 3
2023-03-01 03:37:05,105 DEBUG TRAIN Batch 48/900 loss 3.025318 loss_att 7.503593 loss_ctc 4.669240 loss_rnnt 1.833705 hw_loss 0.143941 lr 0.00029459 rank 7
2023-03-01 03:37:05,105 DEBUG TRAIN Batch 48/900 loss 3.386124 loss_att 7.393945 loss_ctc 6.150537 loss_rnnt 2.136635 hw_loss 0.148756 lr 0.00029460 rank 1
2023-03-01 03:37:05,105 DEBUG TRAIN Batch 48/900 loss 2.087519 loss_att 4.475764 loss_ctc 3.939537 loss_rnnt 1.271572 hw_loss 0.171305 lr 0.00029459 rank 4
2023-03-01 03:37:05,108 DEBUG TRAIN Batch 48/900 loss 10.027799 loss_att 13.633282 loss_ctc 14.620256 loss_rnnt 8.627653 hw_loss 0.125101 lr 0.00029460 rank 0
2023-03-01 03:37:05,109 DEBUG TRAIN Batch 48/900 loss 6.379495 loss_att 9.615177 loss_ctc 10.965810 loss_rnnt 5.007038 hw_loss 0.213399 lr 0.00029460 rank 6
2023-03-01 03:37:05,109 DEBUG TRAIN Batch 48/900 loss 7.089714 loss_att 11.147170 loss_ctc 11.272213 loss_rnnt 5.638844 hw_loss 0.153209 lr 0.00029460 rank 2
2023-03-01 03:37:43,561 DEBUG TRAIN Batch 48/1000 loss 4.926749 loss_att 7.141685 loss_ctc 9.859112 loss_rnnt 3.669808 hw_loss 0.293073 lr 0.00029459 rank 1
2023-03-01 03:37:43,562 DEBUG TRAIN Batch 48/1000 loss 5.959095 loss_att 9.166342 loss_ctc 9.371369 loss_rnnt 4.748464 hw_loss 0.214146 lr 0.00029458 rank 4
2023-03-01 03:37:43,565 DEBUG TRAIN Batch 48/1000 loss 6.685595 loss_att 10.533853 loss_ctc 10.657908 loss_rnnt 5.292205 hw_loss 0.176429 lr 0.00029458 rank 3
2023-03-01 03:37:43,566 DEBUG TRAIN Batch 48/1000 loss 6.545217 loss_att 8.451911 loss_ctc 11.036551 loss_rnnt 5.429672 hw_loss 0.253801 lr 0.00029458 rank 6
2023-03-01 03:37:43,569 DEBUG TRAIN Batch 48/1000 loss 7.966218 loss_att 11.442427 loss_ctc 13.016047 loss_rnnt 6.545426 hw_loss 0.097951 lr 0.00029459 rank 0
2023-03-01 03:37:43,571 DEBUG TRAIN Batch 48/1000 loss 3.681631 loss_att 7.976039 loss_ctc 9.131962 loss_rnnt 1.924261 hw_loss 0.322083 lr 0.00029458 rank 5
2023-03-01 03:37:43,579 DEBUG TRAIN Batch 48/1000 loss 6.010155 loss_att 8.857893 loss_ctc 9.072909 loss_rnnt 4.886472 hw_loss 0.273316 lr 0.00029457 rank 7
2023-03-01 03:37:43,580 DEBUG TRAIN Batch 48/1000 loss 2.831200 loss_att 5.711023 loss_ctc 4.456062 loss_rnnt 1.894517 hw_loss 0.270131 lr 0.00029458 rank 2
2023-03-01 03:38:49,310 DEBUG TRAIN Batch 48/1100 loss 3.937741 loss_att 6.168799 loss_ctc 7.409809 loss_rnnt 2.889370 hw_loss 0.261032 lr 0.00029457 rank 1
2023-03-01 03:38:49,321 DEBUG TRAIN Batch 48/1100 loss 7.290201 loss_att 14.080956 loss_ctc 15.362692 loss_rnnt 4.726978 hw_loss 0.241386 lr 0.00029457 rank 4
2023-03-01 03:38:49,325 DEBUG TRAIN Batch 48/1100 loss 8.742241 loss_att 11.311729 loss_ctc 16.069191 loss_rnnt 7.163965 hw_loss 0.163970 lr 0.00029457 rank 0
2023-03-01 03:38:49,326 DEBUG TRAIN Batch 48/1100 loss 2.588241 loss_att 7.051661 loss_ctc 5.619618 loss_rnnt 1.133724 hw_loss 0.295592 lr 0.00029456 rank 7
2023-03-01 03:38:49,327 DEBUG TRAIN Batch 48/1100 loss 11.709988 loss_att 13.741493 loss_ctc 23.717308 loss_rnnt 9.596903 hw_loss 0.198387 lr 0.00029457 rank 5
2023-03-01 03:38:49,330 DEBUG TRAIN Batch 48/1100 loss 7.481401 loss_att 10.870921 loss_ctc 11.982668 loss_rnnt 6.093784 hw_loss 0.205393 lr 0.00029457 rank 2
2023-03-01 03:38:49,329 DEBUG TRAIN Batch 48/1100 loss 7.125250 loss_att 9.613000 loss_ctc 13.415094 loss_rnnt 5.643758 hw_loss 0.272430 lr 0.00029457 rank 6
2023-03-01 03:38:49,377 DEBUG TRAIN Batch 48/1100 loss 3.921041 loss_att 7.114355 loss_ctc 8.684525 loss_rnnt 2.498032 hw_loss 0.279779 lr 0.00029457 rank 3
2023-03-01 03:39:27,958 DEBUG TRAIN Batch 48/1200 loss 11.612759 loss_att 15.904074 loss_ctc 22.729506 loss_rnnt 9.121340 hw_loss 0.282979 lr 0.00029456 rank 1
2023-03-01 03:39:27,961 DEBUG TRAIN Batch 48/1200 loss 6.192767 loss_att 8.515509 loss_ctc 13.093855 loss_rnnt 4.710967 hw_loss 0.182075 lr 0.00029456 rank 5
2023-03-01 03:39:27,965 DEBUG TRAIN Batch 48/1200 loss 6.749754 loss_att 9.339275 loss_ctc 12.116478 loss_rnnt 5.455339 hw_loss 0.114277 lr 0.00029456 rank 2
2023-03-01 03:39:27,966 DEBUG TRAIN Batch 48/1200 loss 4.955921 loss_att 7.216558 loss_ctc 7.916723 loss_rnnt 3.975091 hw_loss 0.251118 lr 0.00029456 rank 0
2023-03-01 03:39:27,969 DEBUG TRAIN Batch 48/1200 loss 4.734835 loss_att 6.482037 loss_ctc 9.355197 loss_rnnt 3.673659 hw_loss 0.179413 lr 0.00029456 rank 6
2023-03-01 03:39:27,975 DEBUG TRAIN Batch 48/1200 loss 3.659843 loss_att 5.027392 loss_ctc 6.850523 loss_rnnt 2.822985 hw_loss 0.258608 lr 0.00029455 rank 7
2023-03-01 03:39:27,978 DEBUG TRAIN Batch 48/1200 loss 8.866244 loss_att 10.238786 loss_ctc 11.303248 loss_rnnt 8.138819 hw_loss 0.239968 lr 0.00029455 rank 3
2023-03-01 03:39:28,022 DEBUG TRAIN Batch 48/1200 loss 7.305315 loss_att 8.525525 loss_ctc 10.438751 loss_rnnt 6.555421 hw_loss 0.165114 lr 0.00029456 rank 4
2023-03-01 03:40:06,414 DEBUG TRAIN Batch 48/1300 loss 8.290409 loss_att 11.560016 loss_ctc 18.034492 loss_rnnt 6.251938 hw_loss 0.160010 lr 0.00029453 rank 7
2023-03-01 03:40:06,421 DEBUG TRAIN Batch 48/1300 loss 8.420878 loss_att 12.884857 loss_ctc 9.896162 loss_rnnt 7.222539 hw_loss 0.204072 lr 0.00029455 rank 1
2023-03-01 03:40:06,438 DEBUG TRAIN Batch 48/1300 loss 6.013199 loss_att 8.255619 loss_ctc 10.074570 loss_rnnt 4.898309 hw_loss 0.234170 lr 0.00029454 rank 5
2023-03-01 03:40:06,438 DEBUG TRAIN Batch 48/1300 loss 4.924690 loss_att 9.764679 loss_ctc 13.048797 loss_rnnt 2.755871 hw_loss 0.220515 lr 0.00029454 rank 2
2023-03-01 03:40:06,438 DEBUG TRAIN Batch 48/1300 loss 4.961335 loss_att 8.253611 loss_ctc 5.406734 loss_rnnt 4.142505 hw_loss 0.189354 lr 0.00029454 rank 4
2023-03-01 03:40:06,441 DEBUG TRAIN Batch 48/1300 loss 5.250832 loss_att 9.949499 loss_ctc 11.769771 loss_rnnt 3.405593 hw_loss 0.068088 lr 0.00029455 rank 6
2023-03-01 03:40:06,444 DEBUG TRAIN Batch 48/1300 loss 10.763021 loss_att 10.393539 loss_ctc 15.289253 loss_rnnt 10.090026 hw_loss 0.268864 lr 0.00029455 rank 0
2023-03-01 03:40:06,445 DEBUG TRAIN Batch 48/1300 loss 8.211743 loss_att 8.706578 loss_ctc 11.515602 loss_rnnt 7.491467 hw_loss 0.338989 lr 0.00029454 rank 3
2023-03-01 03:40:45,799 DEBUG TRAIN Batch 48/1400 loss 6.531939 loss_att 8.230106 loss_ctc 8.454619 loss_rnnt 5.868026 hw_loss 0.127354 lr 0.00029453 rank 3
2023-03-01 03:40:45,802 DEBUG TRAIN Batch 48/1400 loss 4.444492 loss_att 7.474223 loss_ctc 9.804407 loss_rnnt 2.973546 hw_loss 0.281895 lr 0.00029453 rank 0
2023-03-01 03:40:45,803 DEBUG TRAIN Batch 48/1400 loss 0.812777 loss_att 2.694877 loss_ctc 1.195491 loss_rnnt 0.239837 hw_loss 0.272797 lr 0.00029452 rank 7
2023-03-01 03:40:45,804 DEBUG TRAIN Batch 48/1400 loss 8.218566 loss_att 10.364120 loss_ctc 11.340378 loss_rnnt 7.187511 hw_loss 0.348192 lr 0.00029453 rank 4
2023-03-01 03:40:45,807 DEBUG TRAIN Batch 48/1400 loss 3.282640 loss_att 7.990475 loss_ctc 6.632778 loss_rnnt 1.861117 hw_loss 0.062381 lr 0.00029453 rank 1
2023-03-01 03:40:45,808 DEBUG TRAIN Batch 48/1400 loss 5.778157 loss_att 8.746269 loss_ctc 10.924261 loss_rnnt 4.362686 hw_loss 0.254441 lr 0.00029453 rank 2
2023-03-01 03:40:45,810 DEBUG TRAIN Batch 48/1400 loss 6.454262 loss_att 8.864213 loss_ctc 12.877510 loss_rnnt 5.052707 hw_loss 0.118371 lr 0.00029453 rank 5
2023-03-01 03:40:45,856 DEBUG TRAIN Batch 48/1400 loss 10.340063 loss_att 13.783803 loss_ctc 14.431754 loss_rnnt 9.018658 hw_loss 0.163309 lr 0.00029453 rank 6
2023-03-01 03:41:50,511 DEBUG TRAIN Batch 48/1500 loss 8.703484 loss_att 11.479804 loss_ctc 15.260081 loss_rnnt 7.151285 hw_loss 0.230103 lr 0.00029452 rank 4
2023-03-01 03:41:50,513 DEBUG TRAIN Batch 48/1500 loss 12.114185 loss_att 14.738285 loss_ctc 17.234953 loss_rnnt 10.783051 hw_loss 0.231647 lr 0.00029452 rank 6
2023-03-01 03:41:50,514 DEBUG TRAIN Batch 48/1500 loss 6.934280 loss_att 9.080602 loss_ctc 11.286410 loss_rnnt 5.872149 hw_loss 0.098593 lr 0.00029452 rank 0
2023-03-01 03:41:50,514 DEBUG TRAIN Batch 48/1500 loss 3.272554 loss_att 5.923935 loss_ctc 5.838365 loss_rnnt 2.288790 hw_loss 0.208837 lr 0.00029451 rank 7
2023-03-01 03:41:50,515 DEBUG TRAIN Batch 48/1500 loss 5.014980 loss_att 7.195705 loss_ctc 9.393558 loss_rnnt 3.843810 hw_loss 0.283529 lr 0.00029452 rank 2
2023-03-01 03:41:50,516 DEBUG TRAIN Batch 48/1500 loss 2.889046 loss_att 5.303886 loss_ctc 7.358914 loss_rnnt 1.714014 hw_loss 0.180153 lr 0.00029452 rank 5
2023-03-01 03:41:50,517 DEBUG TRAIN Batch 48/1500 loss 8.304070 loss_att 10.425251 loss_ctc 15.516074 loss_rnnt 6.741215 hw_loss 0.331907 lr 0.00029451 rank 3
2023-03-01 03:41:50,522 DEBUG TRAIN Batch 48/1500 loss 2.660898 loss_att 5.598610 loss_ctc 5.566047 loss_rnnt 1.594158 hw_loss 0.172207 lr 0.00029452 rank 1
2023-03-01 03:42:28,952 DEBUG TRAIN Batch 48/1600 loss 2.018182 loss_att 5.214636 loss_ctc 5.547912 loss_rnnt 0.720670 hw_loss 0.351732 lr 0.00029451 rank 6
2023-03-01 03:42:28,952 DEBUG TRAIN Batch 48/1600 loss 4.721297 loss_att 7.910615 loss_ctc 8.655070 loss_rnnt 3.496827 hw_loss 0.116443 lr 0.00029451 rank 0
2023-03-01 03:42:28,957 DEBUG TRAIN Batch 48/1600 loss 2.878660 loss_att 5.163240 loss_ctc 3.616204 loss_rnnt 2.216552 hw_loss 0.200349 lr 0.00029450 rank 7
2023-03-01 03:42:28,959 DEBUG TRAIN Batch 48/1600 loss 3.812610 loss_att 6.350594 loss_ctc 8.789314 loss_rnnt 2.513173 hw_loss 0.240523 lr 0.00029451 rank 1
2023-03-01 03:42:28,961 DEBUG TRAIN Batch 48/1600 loss 6.722082 loss_att 8.779325 loss_ctc 8.574076 loss_rnnt 5.916279 hw_loss 0.276416 lr 0.00029450 rank 5
2023-03-01 03:42:28,962 DEBUG TRAIN Batch 48/1600 loss 7.365036 loss_att 12.247797 loss_ctc 15.586069 loss_rnnt 5.147027 hw_loss 0.272472 lr 0.00029451 rank 2
2023-03-01 03:42:28,962 DEBUG TRAIN Batch 48/1600 loss 9.338467 loss_att 14.085183 loss_ctc 11.541698 loss_rnnt 8.038752 hw_loss 0.106140 lr 0.00029450 rank 3
2023-03-01 03:42:28,981 DEBUG TRAIN Batch 48/1600 loss 6.308272 loss_att 7.722757 loss_ctc 8.312041 loss_rnnt 5.560289 hw_loss 0.371095 lr 0.00029450 rank 4
2023-03-01 03:43:08,047 DEBUG TRAIN Batch 48/1700 loss 4.536756 loss_att 7.018148 loss_ctc 8.267994 loss_rnnt 3.429250 hw_loss 0.213242 lr 0.00029449 rank 5
2023-03-01 03:43:08,049 DEBUG TRAIN Batch 48/1700 loss 2.148464 loss_att 6.462004 loss_ctc 5.190170 loss_rnnt 0.821360 hw_loss 0.110317 lr 0.00029449 rank 2
2023-03-01 03:43:08,061 DEBUG TRAIN Batch 48/1700 loss 6.819099 loss_att 9.725616 loss_ctc 10.370861 loss_rnnt 5.703997 hw_loss 0.112933 lr 0.00029450 rank 0
2023-03-01 03:43:08,061 DEBUG TRAIN Batch 48/1700 loss 7.063789 loss_att 10.649770 loss_ctc 8.417245 loss_rnnt 6.081116 hw_loss 0.159407 lr 0.00029448 rank 7
2023-03-01 03:43:08,063 DEBUG TRAIN Batch 48/1700 loss 6.409783 loss_att 8.181076 loss_ctc 9.609627 loss_rnnt 5.567800 hw_loss 0.114524 lr 0.00029450 rank 6
2023-03-01 03:43:08,064 DEBUG TRAIN Batch 48/1700 loss 12.975411 loss_att 13.389989 loss_ctc 19.562870 loss_rnnt 11.944976 hw_loss 0.129736 lr 0.00029449 rank 4
2023-03-01 03:43:08,071 DEBUG TRAIN Batch 48/1700 loss 8.210164 loss_att 10.871737 loss_ctc 17.936419 loss_rnnt 6.245856 hw_loss 0.253422 lr 0.00029450 rank 1
2023-03-01 03:43:08,077 DEBUG TRAIN Batch 48/1700 loss 5.296367 loss_att 8.009068 loss_ctc 7.905309 loss_rnnt 4.380436 hw_loss 0.047872 lr 0.00029449 rank 3
2023-03-01 03:44:14,215 DEBUG TRAIN Batch 48/1800 loss 11.424762 loss_att 14.134116 loss_ctc 21.781097 loss_rnnt 9.405359 hw_loss 0.181289 lr 0.00029448 rank 1
2023-03-01 03:44:14,216 DEBUG TRAIN Batch 48/1800 loss 11.247229 loss_att 11.985464 loss_ctc 14.197903 loss_rnnt 10.534595 hw_loss 0.321682 lr 0.00029448 rank 2
2023-03-01 03:44:14,217 DEBUG TRAIN Batch 48/1800 loss 5.812220 loss_att 7.220617 loss_ctc 9.162442 loss_rnnt 4.961842 hw_loss 0.228754 lr 0.00029448 rank 3
2023-03-01 03:44:14,220 DEBUG TRAIN Batch 48/1800 loss 3.343832 loss_att 5.474701 loss_ctc 5.222375 loss_rnnt 2.522165 hw_loss 0.271914 lr 0.00029448 rank 0
2023-03-01 03:44:14,221 DEBUG TRAIN Batch 48/1800 loss 5.603803 loss_att 9.181124 loss_ctc 11.525929 loss_rnnt 3.980171 hw_loss 0.222283 lr 0.00029447 rank 7
2023-03-01 03:44:14,223 DEBUG TRAIN Batch 48/1800 loss 3.487403 loss_att 5.935081 loss_ctc 5.313841 loss_rnnt 2.614759 hw_loss 0.261719 lr 0.00029448 rank 5
2023-03-01 03:44:14,228 DEBUG TRAIN Batch 48/1800 loss 4.801184 loss_att 7.040206 loss_ctc 7.586843 loss_rnnt 3.904573 hw_loss 0.145098 lr 0.00029448 rank 4
2023-03-01 03:44:14,238 DEBUG TRAIN Batch 48/1800 loss 14.173553 loss_att 19.972458 loss_ctc 25.463369 loss_rnnt 11.410896 hw_loss 0.182938 lr 0.00029448 rank 6
2023-03-01 03:44:52,690 DEBUG TRAIN Batch 48/1900 loss 5.615222 loss_att 11.621200 loss_ctc 10.017242 loss_rnnt 3.709767 hw_loss 0.219980 lr 0.00029447 rank 6
2023-03-01 03:44:52,690 DEBUG TRAIN Batch 48/1900 loss 8.806690 loss_att 9.411451 loss_ctc 13.618308 loss_rnnt 7.934214 hw_loss 0.206202 lr 0.00029446 rank 7
2023-03-01 03:44:52,691 DEBUG TRAIN Batch 48/1900 loss 4.280348 loss_att 5.537424 loss_ctc 6.418812 loss_rnnt 3.542957 hw_loss 0.376590 lr 0.00029447 rank 0
2023-03-01 03:44:52,694 DEBUG TRAIN Batch 48/1900 loss 9.883204 loss_att 11.546961 loss_ctc 13.085922 loss_rnnt 8.917654 hw_loss 0.385818 lr 0.00029447 rank 4
2023-03-01 03:44:52,695 DEBUG TRAIN Batch 48/1900 loss 4.765237 loss_att 6.972854 loss_ctc 7.302917 loss_rnnt 3.839316 hw_loss 0.273826 lr 0.00029447 rank 5
2023-03-01 03:44:52,729 DEBUG TRAIN Batch 48/1900 loss 7.382334 loss_att 7.445996 loss_ctc 10.902270 loss_rnnt 6.672103 hw_loss 0.427826 lr 0.00029447 rank 1
2023-03-01 03:44:52,733 DEBUG TRAIN Batch 48/1900 loss 7.741443 loss_att 9.073713 loss_ctc 12.925414 loss_rnnt 6.587967 hw_loss 0.367173 lr 0.00029447 rank 2
2023-03-01 03:44:52,741 DEBUG TRAIN Batch 48/1900 loss 7.468400 loss_att 7.694638 loss_ctc 8.637679 loss_rnnt 7.108788 hw_loss 0.297112 lr 0.00029446 rank 3
2023-03-01 03:45:30,961 DEBUG TRAIN Batch 48/2000 loss 1.782120 loss_att 3.776833 loss_ctc 3.124097 loss_rnnt 1.106414 hw_loss 0.183438 lr 0.00029445 rank 2
2023-03-01 03:45:30,972 DEBUG TRAIN Batch 48/2000 loss 3.959866 loss_att 9.116732 loss_ctc 9.917891 loss_rnnt 2.067327 hw_loss 0.125180 lr 0.00029446 rank 0
2023-03-01 03:45:30,972 DEBUG TRAIN Batch 48/2000 loss 2.113858 loss_att 4.632667 loss_ctc 4.591047 loss_rnnt 1.163599 hw_loss 0.217884 lr 0.00029444 rank 7
2023-03-01 03:45:30,974 DEBUG TRAIN Batch 48/2000 loss 2.187958 loss_att 4.588042 loss_ctc 3.692459 loss_rnnt 1.412396 hw_loss 0.178021 lr 0.00029445 rank 4
2023-03-01 03:45:30,974 DEBUG TRAIN Batch 48/2000 loss 3.473891 loss_att 6.020982 loss_ctc 10.056838 loss_rnnt 2.004655 hw_loss 0.153919 lr 0.00029446 rank 1
2023-03-01 03:45:30,976 DEBUG TRAIN Batch 48/2000 loss 4.202662 loss_att 7.020688 loss_ctc 7.762174 loss_rnnt 3.032872 hw_loss 0.246719 lr 0.00029445 rank 3
2023-03-01 03:45:30,978 DEBUG TRAIN Batch 48/2000 loss 5.708131 loss_att 8.887016 loss_ctc 6.888950 loss_rnnt 4.776333 hw_loss 0.259834 lr 0.00029445 rank 5
2023-03-01 03:45:30,990 DEBUG TRAIN Batch 48/2000 loss 6.739983 loss_att 11.947254 loss_ctc 11.985495 loss_rnnt 4.972308 hw_loss 0.050286 lr 0.00029446 rank 6
2023-03-01 03:46:10,519 DEBUG TRAIN Batch 48/2100 loss 9.524219 loss_att 12.871484 loss_ctc 13.336146 loss_rnnt 8.199602 hw_loss 0.275451 lr 0.00029444 rank 1
2023-03-01 03:46:10,525 DEBUG TRAIN Batch 48/2100 loss 3.849487 loss_att 8.503654 loss_ctc 9.715975 loss_rnnt 1.965336 hw_loss 0.320847 lr 0.00029444 rank 4
2023-03-01 03:46:10,527 DEBUG TRAIN Batch 48/2100 loss 4.921891 loss_att 7.671412 loss_ctc 8.393205 loss_rnnt 3.742367 hw_loss 0.312708 lr 0.00029444 rank 6
2023-03-01 03:46:10,533 DEBUG TRAIN Batch 48/2100 loss 2.372118 loss_att 6.340087 loss_ctc 5.309348 loss_rnnt 1.081921 hw_loss 0.196824 lr 0.00029445 rank 0
2023-03-01 03:46:10,536 DEBUG TRAIN Batch 48/2100 loss 4.895958 loss_att 9.329214 loss_ctc 7.736799 loss_rnnt 3.489446 hw_loss 0.264529 lr 0.00029444 rank 3
2023-03-01 03:46:10,538 DEBUG TRAIN Batch 48/2100 loss 3.168142 loss_att 6.654492 loss_ctc 4.886336 loss_rnnt 2.106079 hw_loss 0.254437 lr 0.00029443 rank 7
2023-03-01 03:46:10,541 DEBUG TRAIN Batch 48/2100 loss 6.990724 loss_att 8.883444 loss_ctc 8.306344 loss_rnnt 6.318429 hw_loss 0.221877 lr 0.00029444 rank 2
2023-03-01 03:46:10,546 DEBUG TRAIN Batch 48/2100 loss 8.787971 loss_att 13.573032 loss_ctc 17.756424 loss_rnnt 6.497203 hw_loss 0.258679 lr 0.00029444 rank 5
2023-03-01 03:47:17,486 DEBUG TRAIN Batch 48/2200 loss 8.347938 loss_att 9.941918 loss_ctc 11.321283 loss_rnnt 7.567173 hw_loss 0.122855 lr 0.00029443 rank 6
2023-03-01 03:47:17,490 DEBUG TRAIN Batch 48/2200 loss 9.101771 loss_att 11.413292 loss_ctc 14.050385 loss_rnnt 7.872058 hw_loss 0.201737 lr 0.00029443 rank 1
2023-03-01 03:47:17,494 DEBUG TRAIN Batch 48/2200 loss 7.459028 loss_att 9.022732 loss_ctc 12.862091 loss_rnnt 6.265759 hw_loss 0.300225 lr 0.00029443 rank 4
2023-03-01 03:47:17,501 DEBUG TRAIN Batch 48/2200 loss 3.973940 loss_att 8.620325 loss_ctc 7.176267 loss_rnnt 2.512252 hw_loss 0.197689 lr 0.00029442 rank 7
2023-03-01 03:47:17,502 DEBUG TRAIN Batch 48/2200 loss 11.537519 loss_att 13.692277 loss_ctc 19.483032 loss_rnnt 9.929784 hw_loss 0.220089 lr 0.00029443 rank 0
2023-03-01 03:47:17,503 DEBUG TRAIN Batch 48/2200 loss 4.818606 loss_att 6.745560 loss_ctc 6.843498 loss_rnnt 4.067881 hw_loss 0.178778 lr 0.00029442 rank 3
2023-03-01 03:47:17,503 DEBUG TRAIN Batch 48/2200 loss 3.117747 loss_att 6.243623 loss_ctc 6.419474 loss_rnnt 1.912812 hw_loss 0.261619 lr 0.00029443 rank 5
2023-03-01 03:47:17,551 DEBUG TRAIN Batch 48/2200 loss 9.575768 loss_att 11.985408 loss_ctc 13.865749 loss_rnnt 8.367704 hw_loss 0.289007 lr 0.00029443 rank 2
2023-03-01 03:47:55,550 DEBUG TRAIN Batch 48/2300 loss 5.984118 loss_att 8.279321 loss_ctc 8.925362 loss_rnnt 4.991111 hw_loss 0.265878 lr 0.00029441 rank 3
2023-03-01 03:47:55,568 DEBUG TRAIN Batch 48/2300 loss 4.327949 loss_att 7.339207 loss_ctc 7.414382 loss_rnnt 3.137847 hw_loss 0.330611 lr 0.00029442 rank 0
2023-03-01 03:47:55,569 DEBUG TRAIN Batch 48/2300 loss 8.979659 loss_att 12.880444 loss_ctc 16.512512 loss_rnnt 7.063768 hw_loss 0.246285 lr 0.00029442 rank 5
2023-03-01 03:47:55,574 DEBUG TRAIN Batch 48/2300 loss 2.444781 loss_att 5.247661 loss_ctc 6.313958 loss_rnnt 1.253189 hw_loss 0.215859 lr 0.00029441 rank 7
2023-03-01 03:47:55,574 DEBUG TRAIN Batch 48/2300 loss 4.149835 loss_att 7.069860 loss_ctc 8.955135 loss_rnnt 2.853104 hw_loss 0.135036 lr 0.00029442 rank 4
2023-03-01 03:47:55,576 DEBUG TRAIN Batch 48/2300 loss 6.394733 loss_att 8.162233 loss_ctc 7.726101 loss_rnnt 5.774115 hw_loss 0.168004 lr 0.00029442 rank 2
2023-03-01 03:47:55,577 DEBUG TRAIN Batch 48/2300 loss 11.619636 loss_att 13.601843 loss_ctc 16.755621 loss_rnnt 10.428333 hw_loss 0.206369 lr 0.00029442 rank 6
2023-03-01 03:47:55,614 DEBUG TRAIN Batch 48/2300 loss 9.356428 loss_att 11.811609 loss_ctc 15.746866 loss_rnnt 7.909433 hw_loss 0.194812 lr 0.00029442 rank 1
2023-03-01 03:48:33,902 DEBUG TRAIN Batch 48/2400 loss 4.232496 loss_att 9.057658 loss_ctc 7.540963 loss_rnnt 2.705683 hw_loss 0.226219 lr 0.00029441 rank 0
2023-03-01 03:48:33,907 DEBUG TRAIN Batch 48/2400 loss 6.116315 loss_att 7.699728 loss_ctc 7.551875 loss_rnnt 5.467181 hw_loss 0.264458 lr 0.00029441 rank 1
2023-03-01 03:48:33,907 DEBUG TRAIN Batch 48/2400 loss 5.037587 loss_att 8.598314 loss_ctc 9.396864 loss_rnnt 3.578470 hw_loss 0.310753 lr 0.00029440 rank 3
2023-03-01 03:48:33,910 DEBUG TRAIN Batch 48/2400 loss 9.951104 loss_att 13.284050 loss_ctc 14.690251 loss_rnnt 8.526471 hw_loss 0.236544 lr 0.00029441 rank 6
2023-03-01 03:48:33,920 DEBUG TRAIN Batch 48/2400 loss 10.133863 loss_att 14.955725 loss_ctc 18.703232 loss_rnnt 7.955917 hw_loss 0.133110 lr 0.00029440 rank 4
2023-03-01 03:48:33,930 DEBUG TRAIN Batch 48/2400 loss 11.538376 loss_att 13.012188 loss_ctc 19.161469 loss_rnnt 10.042459 hw_loss 0.346392 lr 0.00029440 rank 2
2023-03-01 03:48:33,940 DEBUG TRAIN Batch 48/2400 loss 10.171175 loss_att 15.099444 loss_ctc 16.668789 loss_rnnt 8.248359 hw_loss 0.132778 lr 0.00029439 rank 7
2023-03-01 03:48:33,957 DEBUG TRAIN Batch 48/2400 loss 10.362103 loss_att 11.925833 loss_ctc 15.443527 loss_rnnt 9.232300 hw_loss 0.261627 lr 0.00029440 rank 5
2023-03-01 03:49:40,869 DEBUG TRAIN Batch 48/2500 loss 5.367847 loss_att 5.759936 loss_ctc 7.408346 loss_rnnt 4.851158 hw_loss 0.311636 lr 0.00029439 rank 0
2023-03-01 03:49:40,873 DEBUG TRAIN Batch 48/2500 loss 2.818140 loss_att 5.181582 loss_ctc 4.974123 loss_rnnt 1.844543 hw_loss 0.400208 lr 0.00029439 rank 2
2023-03-01 03:49:40,873 DEBUG TRAIN Batch 48/2500 loss 7.501582 loss_att 8.166689 loss_ctc 10.904281 loss_rnnt 6.742434 hw_loss 0.323312 lr 0.00029439 rank 1
2023-03-01 03:49:40,874 DEBUG TRAIN Batch 48/2500 loss 4.951744 loss_att 6.253799 loss_ctc 8.718407 loss_rnnt 4.041126 hw_loss 0.277471 lr 0.00029438 rank 7
2023-03-01 03:49:40,875 DEBUG TRAIN Batch 48/2500 loss 5.906440 loss_att 9.449275 loss_ctc 11.594504 loss_rnnt 4.250955 hw_loss 0.353456 lr 0.00029439 rank 4
2023-03-01 03:49:40,880 DEBUG TRAIN Batch 48/2500 loss 6.877286 loss_att 8.063212 loss_ctc 8.589032 loss_rnnt 6.233051 hw_loss 0.335282 lr 0.00029439 rank 6
2023-03-01 03:49:40,880 DEBUG TRAIN Batch 48/2500 loss 11.145938 loss_att 11.092871 loss_ctc 16.024612 loss_rnnt 10.346416 hw_loss 0.299338 lr 0.00029439 rank 3
2023-03-01 03:49:40,918 DEBUG TRAIN Batch 48/2500 loss 3.959991 loss_att 4.730789 loss_ctc 6.782837 loss_rnnt 3.217499 hw_loss 0.397414 lr 0.00029439 rank 5
2023-03-01 03:50:19,453 DEBUG TRAIN Batch 48/2600 loss 10.563739 loss_att 14.512526 loss_ctc 21.525505 loss_rnnt 8.134453 hw_loss 0.333673 lr 0.00029438 rank 0
2023-03-01 03:50:19,461 DEBUG TRAIN Batch 48/2600 loss 12.605844 loss_att 19.167757 loss_ctc 18.328030 loss_rnnt 10.402712 hw_loss 0.239607 lr 0.00029438 rank 2
2023-03-01 03:50:19,460 DEBUG TRAIN Batch 48/2600 loss 6.416631 loss_att 10.657330 loss_ctc 13.724922 loss_rnnt 4.484114 hw_loss 0.206134 lr 0.00029438 rank 1
2023-03-01 03:50:19,462 DEBUG TRAIN Batch 48/2600 loss 11.188855 loss_att 12.889513 loss_ctc 13.966593 loss_rnnt 10.410033 hw_loss 0.128111 lr 0.00029437 rank 7
2023-03-01 03:50:19,463 DEBUG TRAIN Batch 48/2600 loss 5.860663 loss_att 9.921787 loss_ctc 12.648704 loss_rnnt 4.085010 hw_loss 0.109419 lr 0.00029438 rank 6
2023-03-01 03:50:19,463 DEBUG TRAIN Batch 48/2600 loss 5.379603 loss_att 6.254194 loss_ctc 8.407326 loss_rnnt 4.589729 hw_loss 0.396111 lr 0.00029438 rank 4
2023-03-01 03:50:19,465 DEBUG TRAIN Batch 48/2600 loss 3.992510 loss_att 7.264707 loss_ctc 7.377956 loss_rnnt 2.782383 hw_loss 0.195552 lr 0.00029437 rank 3
2023-03-01 03:50:19,465 DEBUG TRAIN Batch 48/2600 loss 3.939280 loss_att 7.181299 loss_ctc 7.280747 loss_rnnt 2.796665 hw_loss 0.091277 lr 0.00029438 rank 5
2023-03-01 03:50:57,608 DEBUG TRAIN Batch 48/2700 loss 6.879202 loss_att 9.778528 loss_ctc 15.856967 loss_rnnt 4.954587 hw_loss 0.276965 lr 0.00029436 rank 5
2023-03-01 03:50:57,623 DEBUG TRAIN Batch 48/2700 loss 7.170136 loss_att 9.994766 loss_ctc 9.388628 loss_rnnt 6.144022 hw_loss 0.310103 lr 0.00029436 rank 4
2023-03-01 03:50:57,627 DEBUG TRAIN Batch 48/2700 loss 4.657680 loss_att 7.404556 loss_ctc 7.187288 loss_rnnt 3.668971 hw_loss 0.191349 lr 0.00029436 rank 7
2023-03-01 03:50:57,628 DEBUG TRAIN Batch 48/2700 loss 8.407656 loss_att 13.348220 loss_ctc 16.158625 loss_rnnt 6.215947 hw_loss 0.319000 lr 0.00029437 rank 0
2023-03-01 03:50:57,629 DEBUG TRAIN Batch 48/2700 loss 4.373034 loss_att 7.282396 loss_ctc 8.546112 loss_rnnt 3.108870 hw_loss 0.236028 lr 0.00029437 rank 1
2023-03-01 03:50:57,630 DEBUG TRAIN Batch 48/2700 loss 6.141989 loss_att 10.214190 loss_ctc 10.473186 loss_rnnt 4.606601 hw_loss 0.268978 lr 0.00029437 rank 6
2023-03-01 03:50:57,632 DEBUG TRAIN Batch 48/2700 loss 0.877578 loss_att 2.490436 loss_ctc 1.357059 loss_rnnt 0.387461 hw_loss 0.194278 lr 0.00029436 rank 3
2023-03-01 03:50:57,632 DEBUG TRAIN Batch 48/2700 loss 7.070934 loss_att 9.689495 loss_ctc 8.300117 loss_rnnt 6.238361 hw_loss 0.271817 lr 0.00029437 rank 2
2023-03-01 03:51:36,726 DEBUG TRAIN Batch 48/2800 loss 5.708466 loss_att 9.341709 loss_ctc 9.278667 loss_rnnt 4.437989 hw_loss 0.127127 lr 0.00029435 rank 4
2023-03-01 03:51:36,727 DEBUG TRAIN Batch 48/2800 loss 12.506608 loss_att 14.835621 loss_ctc 16.738966 loss_rnnt 11.395975 hw_loss 0.150963 lr 0.00029435 rank 3
2023-03-01 03:51:36,731 DEBUG TRAIN Batch 48/2800 loss 6.296340 loss_att 8.981017 loss_ctc 15.411736 loss_rnnt 4.410546 hw_loss 0.250259 lr 0.00029435 rank 2
2023-03-01 03:51:36,736 DEBUG TRAIN Batch 48/2800 loss 12.745089 loss_att 17.199520 loss_ctc 20.495588 loss_rnnt 10.762612 hw_loss 0.109105 lr 0.00029435 rank 5
2023-03-01 03:51:36,737 DEBUG TRAIN Batch 48/2800 loss 2.512267 loss_att 5.119703 loss_ctc 3.766755 loss_rnnt 1.779435 hw_loss 0.082649 lr 0.00029436 rank 1
2023-03-01 03:51:36,737 DEBUG TRAIN Batch 48/2800 loss 4.133657 loss_att 6.394882 loss_ctc 9.788674 loss_rnnt 2.745272 hw_loss 0.341506 lr 0.00029436 rank 6
2023-03-01 03:51:36,739 DEBUG TRAIN Batch 48/2800 loss 6.350077 loss_att 9.059116 loss_ctc 10.078163 loss_rnnt 5.218622 hw_loss 0.173566 lr 0.00029436 rank 0
2023-03-01 03:51:36,742 DEBUG TRAIN Batch 48/2800 loss 3.959464 loss_att 7.056361 loss_ctc 6.990413 loss_rnnt 2.848119 hw_loss 0.164697 lr 0.00029434 rank 7
2023-03-01 03:52:43,053 DEBUG TRAIN Batch 48/2900 loss 6.002419 loss_att 9.827591 loss_ctc 12.195350 loss_rnnt 4.287122 hw_loss 0.233511 lr 0.00029433 rank 7
2023-03-01 03:52:43,061 DEBUG TRAIN Batch 48/2900 loss 4.971778 loss_att 7.970206 loss_ctc 9.461387 loss_rnnt 3.684206 hw_loss 0.167385 lr 0.00029434 rank 4
2023-03-01 03:52:43,073 DEBUG TRAIN Batch 48/2900 loss 4.583419 loss_att 7.127541 loss_ctc 6.322968 loss_rnnt 3.677839 hw_loss 0.309029 lr 0.00029434 rank 5
2023-03-01 03:52:43,074 DEBUG TRAIN Batch 48/2900 loss 5.044859 loss_att 9.783954 loss_ctc 10.692616 loss_rnnt 3.256180 hw_loss 0.164672 lr 0.00029434 rank 0
2023-03-01 03:52:43,080 DEBUG TRAIN Batch 48/2900 loss 8.367385 loss_att 10.642443 loss_ctc 13.367870 loss_rnnt 7.108396 hw_loss 0.257334 lr 0.00029434 rank 2
2023-03-01 03:52:43,083 DEBUG TRAIN Batch 48/2900 loss 2.348739 loss_att 6.102048 loss_ctc 4.322291 loss_rnnt 1.193092 hw_loss 0.265959 lr 0.00029434 rank 6
2023-03-01 03:52:43,087 DEBUG TRAIN Batch 48/2900 loss 6.719612 loss_att 9.194426 loss_ctc 10.813806 loss_rnnt 5.573710 hw_loss 0.196963 lr 0.00029434 rank 1
2023-03-01 03:52:43,123 DEBUG TRAIN Batch 48/2900 loss 4.828651 loss_att 8.655550 loss_ctc 9.174342 loss_rnnt 3.359109 hw_loss 0.233883 lr 0.00029434 rank 3
2023-03-01 03:53:21,954 DEBUG TRAIN Batch 48/3000 loss 9.019175 loss_att 12.584774 loss_ctc 16.345604 loss_rnnt 7.228158 hw_loss 0.189449 lr 0.00029433 rank 0
2023-03-01 03:53:21,954 DEBUG TRAIN Batch 48/3000 loss 5.286796 loss_att 7.380414 loss_ctc 7.995288 loss_rnnt 4.367954 hw_loss 0.260596 lr 0.00029432 rank 7
2023-03-01 03:53:21,972 DEBUG TRAIN Batch 48/3000 loss 6.079870 loss_att 7.291162 loss_ctc 9.516699 loss_rnnt 5.253168 hw_loss 0.236626 lr 0.00029433 rank 5
2023-03-01 03:53:21,972 DEBUG TRAIN Batch 48/3000 loss 5.343071 loss_att 8.926844 loss_ctc 10.731033 loss_rnnt 3.810843 hw_loss 0.182021 lr 0.00029433 rank 6
2023-03-01 03:53:21,973 DEBUG TRAIN Batch 48/3000 loss 10.781926 loss_att 13.046900 loss_ctc 17.893894 loss_rnnt 9.228214 hw_loss 0.285853 lr 0.00029433 rank 2
2023-03-01 03:53:21,974 DEBUG TRAIN Batch 48/3000 loss 6.990537 loss_att 13.638334 loss_ctc 15.889887 loss_rnnt 4.321364 hw_loss 0.286938 lr 0.00029433 rank 1
2023-03-01 03:53:21,979 DEBUG TRAIN Batch 48/3000 loss 3.274371 loss_att 6.204488 loss_ctc 6.292810 loss_rnnt 2.233984 hw_loss 0.097323 lr 0.00029433 rank 4
2023-03-01 03:53:21,980 DEBUG TRAIN Batch 48/3000 loss 4.316999 loss_att 7.547094 loss_ctc 8.768916 loss_rnnt 3.014669 hw_loss 0.117604 lr 0.00029432 rank 3
2023-03-01 03:54:00,620 DEBUG TRAIN Batch 48/3100 loss 8.211443 loss_att 12.631212 loss_ctc 16.755461 loss_rnnt 6.043064 hw_loss 0.272293 lr 0.00029431 rank 3
2023-03-01 03:54:00,630 DEBUG TRAIN Batch 48/3100 loss 3.777326 loss_att 5.358935 loss_ctc 8.352679 loss_rnnt 2.708570 hw_loss 0.266975 lr 0.00029431 rank 4
2023-03-01 03:54:00,631 DEBUG TRAIN Batch 48/3100 loss 2.164330 loss_att 5.074389 loss_ctc 5.496962 loss_rnnt 0.986634 hw_loss 0.283749 lr 0.00029432 rank 1
2023-03-01 03:54:00,634 DEBUG TRAIN Batch 48/3100 loss 5.880038 loss_att 8.177303 loss_ctc 10.826991 loss_rnnt 4.630837 hw_loss 0.244038 lr 0.00029430 rank 7
2023-03-01 03:54:00,636 DEBUG TRAIN Batch 48/3100 loss 2.470988 loss_att 4.067786 loss_ctc 4.146942 loss_rnnt 1.733723 hw_loss 0.364584 lr 0.00029432 rank 6
2023-03-01 03:54:00,641 DEBUG TRAIN Batch 48/3100 loss 7.622962 loss_att 8.621741 loss_ctc 11.130852 loss_rnnt 6.795300 hw_loss 0.300349 lr 0.00029432 rank 0
2023-03-01 03:54:00,642 DEBUG TRAIN Batch 48/3100 loss 7.675689 loss_att 10.047706 loss_ctc 9.160953 loss_rnnt 6.835990 hw_loss 0.313613 lr 0.00029431 rank 2
2023-03-01 03:54:00,684 DEBUG TRAIN Batch 48/3100 loss 6.398305 loss_att 6.893363 loss_ctc 8.982407 loss_rnnt 5.824390 hw_loss 0.244419 lr 0.00029431 rank 5
2023-03-01 03:55:07,049 DEBUG TRAIN Batch 48/3200 loss 12.013533 loss_att 17.551815 loss_ctc 25.868757 loss_rnnt 8.979236 hw_loss 0.148645 lr 0.00029431 rank 0
2023-03-01 03:55:07,050 DEBUG TRAIN Batch 48/3200 loss 7.834667 loss_att 8.547325 loss_ctc 9.034304 loss_rnnt 7.459295 hw_loss 0.136668 lr 0.00029430 rank 2
2023-03-01 03:55:07,052 DEBUG TRAIN Batch 48/3200 loss 4.765662 loss_att 7.911825 loss_ctc 6.570024 loss_rnnt 3.770159 hw_loss 0.235666 lr 0.00029430 rank 3
2023-03-01 03:55:07,052 DEBUG TRAIN Batch 48/3200 loss 8.299953 loss_att 9.908052 loss_ctc 15.868103 loss_rnnt 6.882301 hw_loss 0.163024 lr 0.00029430 rank 1
2023-03-01 03:55:07,062 DEBUG TRAIN Batch 48/3200 loss 5.083166 loss_att 9.839502 loss_ctc 7.393424 loss_rnnt 3.759784 hw_loss 0.120149 lr 0.00029430 rank 6
2023-03-01 03:55:07,089 DEBUG TRAIN Batch 48/3200 loss 6.102575 loss_att 8.593935 loss_ctc 11.259585 loss_rnnt 4.801571 hw_loss 0.215871 lr 0.00029429 rank 7
2023-03-01 03:55:07,100 DEBUG TRAIN Batch 48/3200 loss 6.588529 loss_att 14.052613 loss_ctc 9.030777 loss_rnnt 4.625561 hw_loss 0.270970 lr 0.00029430 rank 5
2023-03-01 03:55:07,103 DEBUG TRAIN Batch 48/3200 loss 2.728239 loss_att 4.204781 loss_ctc 6.066763 loss_rnnt 1.879895 hw_loss 0.202310 lr 0.00029430 rank 4
2023-03-01 03:55:46,508 DEBUG TRAIN Batch 48/3300 loss 6.051644 loss_att 9.501753 loss_ctc 11.865287 loss_rnnt 4.504519 hw_loss 0.153660 lr 0.00029428 rank 7
2023-03-01 03:55:46,513 DEBUG TRAIN Batch 48/3300 loss 3.490080 loss_att 6.894008 loss_ctc 7.680728 loss_rnnt 2.213210 hw_loss 0.069994 lr 0.00029429 rank 0
2023-03-01 03:55:46,513 DEBUG TRAIN Batch 48/3300 loss 1.733191 loss_att 3.920693 loss_ctc 2.150475 loss_rnnt 1.105115 hw_loss 0.253008 lr 0.00029429 rank 4
2023-03-01 03:55:46,516 DEBUG TRAIN Batch 48/3300 loss 6.037265 loss_att 8.583946 loss_ctc 8.548560 loss_rnnt 5.118350 hw_loss 0.140136 lr 0.00029429 rank 2
2023-03-01 03:55:46,518 DEBUG TRAIN Batch 48/3300 loss 7.764325 loss_att 10.870536 loss_ctc 14.492905 loss_rnnt 6.121198 hw_loss 0.233889 lr 0.00029429 rank 1
2023-03-01 03:55:46,519 DEBUG TRAIN Batch 48/3300 loss 8.215331 loss_att 11.184909 loss_ctc 14.480491 loss_rnnt 6.754865 hw_loss 0.058491 lr 0.00029429 rank 5
2023-03-01 03:55:46,522 DEBUG TRAIN Batch 48/3300 loss 3.429582 loss_att 5.084106 loss_ctc 6.667215 loss_rnnt 2.608198 hw_loss 0.110241 lr 0.00029429 rank 6
2023-03-01 03:55:46,567 DEBUG TRAIN Batch 48/3300 loss 9.476009 loss_att 11.981159 loss_ctc 16.323101 loss_rnnt 7.934219 hw_loss 0.239655 lr 0.00029428 rank 3
2023-03-01 03:56:25,114 DEBUG TRAIN Batch 48/3400 loss 10.860461 loss_att 9.802576 loss_ctc 15.091865 loss_rnnt 10.355577 hw_loss 0.285514 lr 0.00029427 rank 3
2023-03-01 03:56:25,119 DEBUG TRAIN Batch 48/3400 loss 3.907989 loss_att 6.111610 loss_ctc 8.132441 loss_rnnt 2.788636 hw_loss 0.216316 lr 0.00029428 rank 6
2023-03-01 03:56:25,119 DEBUG TRAIN Batch 48/3400 loss 5.923149 loss_att 8.103537 loss_ctc 7.419102 loss_rnnt 5.121960 hw_loss 0.310596 lr 0.00029428 rank 4
2023-03-01 03:56:25,120 DEBUG TRAIN Batch 48/3400 loss 6.257885 loss_att 8.774799 loss_ctc 10.814498 loss_rnnt 5.046728 hw_loss 0.187923 lr 0.00029428 rank 0
2023-03-01 03:56:25,121 DEBUG TRAIN Batch 48/3400 loss 2.830432 loss_att 5.696548 loss_ctc 7.120234 loss_rnnt 1.480773 hw_loss 0.383365 lr 0.00029427 rank 7
2023-03-01 03:56:25,122 DEBUG TRAIN Batch 48/3400 loss 6.272234 loss_att 8.653440 loss_ctc 11.442472 loss_rnnt 4.975735 hw_loss 0.245426 lr 0.00029428 rank 1
2023-03-01 03:56:25,125 DEBUG TRAIN Batch 48/3400 loss 2.501481 loss_att 4.705680 loss_ctc 3.771714 loss_rnnt 1.696253 hw_loss 0.365670 lr 0.00029428 rank 2
2023-03-01 03:56:25,125 DEBUG TRAIN Batch 48/3400 loss 1.953108 loss_att 5.021948 loss_ctc 3.649436 loss_rnnt 1.021101 hw_loss 0.172616 lr 0.00029428 rank 5
2023-03-01 03:57:03,971 DEBUG TRAIN Batch 48/3500 loss 10.696389 loss_att 15.047492 loss_ctc 24.387299 loss_rnnt 8.000547 hw_loss 0.000312 lr 0.00029426 rank 4
2023-03-01 03:57:03,981 DEBUG TRAIN Batch 48/3500 loss 10.489044 loss_att 12.932650 loss_ctc 14.390201 loss_rnnt 9.383915 hw_loss 0.180476 lr 0.00029426 rank 5
2023-03-01 03:57:03,982 DEBUG TRAIN Batch 48/3500 loss 4.248489 loss_att 7.371406 loss_ctc 6.334663 loss_rnnt 3.237409 hw_loss 0.203139 lr 0.00029426 rank 2
2023-03-01 03:57:03,984 DEBUG TRAIN Batch 48/3500 loss 7.306698 loss_att 11.378498 loss_ctc 13.160015 loss_rnnt 5.568329 hw_loss 0.269187 lr 0.00029426 rank 3
2023-03-01 03:57:03,984 DEBUG TRAIN Batch 48/3500 loss 5.733352 loss_att 8.427372 loss_ctc 7.901185 loss_rnnt 4.796957 hw_loss 0.203523 lr 0.00029425 rank 7
2023-03-01 03:57:03,984 DEBUG TRAIN Batch 48/3500 loss 8.227153 loss_att 13.137817 loss_ctc 13.798565 loss_rnnt 6.409129 hw_loss 0.174442 lr 0.00029427 rank 0
2023-03-01 03:57:03,985 DEBUG TRAIN Batch 48/3500 loss 8.021975 loss_att 10.805367 loss_ctc 13.938042 loss_rnnt 6.521149 hw_loss 0.291258 lr 0.00029427 rank 1
2023-03-01 03:57:03,987 DEBUG TRAIN Batch 48/3500 loss 5.984695 loss_att 10.014248 loss_ctc 11.496128 loss_rnnt 4.395160 hw_loss 0.091439 lr 0.00029427 rank 6
2023-03-01 03:58:14,699 DEBUG TRAIN Batch 48/3600 loss 5.417775 loss_att 7.118397 loss_ctc 9.072286 loss_rnnt 4.494920 hw_loss 0.178991 lr 0.00029425 rank 0
2023-03-01 03:58:14,699 DEBUG TRAIN Batch 48/3600 loss 10.734964 loss_att 14.267133 loss_ctc 15.397221 loss_rnnt 9.215576 hw_loss 0.358724 lr 0.00029424 rank 7
2023-03-01 03:58:14,705 DEBUG TRAIN Batch 48/3600 loss 4.579340 loss_att 9.080230 loss_ctc 11.960740 loss_rnnt 2.650007 hw_loss 0.084315 lr 0.00029425 rank 5
2023-03-01 03:58:14,706 DEBUG TRAIN Batch 48/3600 loss 9.038592 loss_att 12.283915 loss_ctc 18.359783 loss_rnnt 7.006549 hw_loss 0.262789 lr 0.00029425 rank 2
2023-03-01 03:58:14,730 DEBUG TRAIN Batch 48/3600 loss 9.605451 loss_att 11.525358 loss_ctc 18.790764 loss_rnnt 7.874512 hw_loss 0.229216 lr 0.00029425 rank 6
2023-03-01 03:58:14,735 DEBUG TRAIN Batch 48/3600 loss 4.433086 loss_att 6.161860 loss_ctc 6.551867 loss_rnnt 3.632861 hw_loss 0.322437 lr 0.00029425 rank 3
2023-03-01 03:58:14,746 DEBUG TRAIN Batch 48/3600 loss 6.443316 loss_att 9.004747 loss_ctc 12.503780 loss_rnnt 5.062404 hw_loss 0.113556 lr 0.00029425 rank 1
2023-03-01 03:58:14,775 DEBUG TRAIN Batch 48/3600 loss 4.831971 loss_att 7.523458 loss_ctc 5.179406 loss_rnnt 4.141712 hw_loss 0.198071 lr 0.00029425 rank 4
2023-03-01 03:58:53,609 DEBUG TRAIN Batch 48/3700 loss 3.685724 loss_att 5.103058 loss_ctc 4.385257 loss_rnnt 3.200333 hw_loss 0.203725 lr 0.00029424 rank 4
2023-03-01 03:58:53,617 DEBUG TRAIN Batch 48/3700 loss 3.467080 loss_att 5.308189 loss_ctc 6.694617 loss_rnnt 2.512569 hw_loss 0.292407 lr 0.00029423 rank 7
2023-03-01 03:58:53,620 DEBUG TRAIN Batch 48/3700 loss 10.593105 loss_att 11.779161 loss_ctc 17.564985 loss_rnnt 9.331944 hw_loss 0.176934 lr 0.00029424 rank 0
2023-03-01 03:58:53,621 DEBUG TRAIN Batch 48/3700 loss 17.516932 loss_att 19.694736 loss_ctc 28.674696 loss_rnnt 15.461108 hw_loss 0.248553 lr 0.00029424 rank 1
2023-03-01 03:58:53,622 DEBUG TRAIN Batch 48/3700 loss 5.975351 loss_att 9.719233 loss_ctc 11.095760 loss_rnnt 4.446073 hw_loss 0.183338 lr 0.00029424 rank 2
2023-03-01 03:58:53,624 DEBUG TRAIN Batch 48/3700 loss 7.550774 loss_att 8.501422 loss_ctc 9.434262 loss_rnnt 6.963474 hw_loss 0.273821 lr 0.00029423 rank 3
2023-03-01 03:58:53,627 DEBUG TRAIN Batch 48/3700 loss 6.200414 loss_att 8.211132 loss_ctc 9.743339 loss_rnnt 5.109939 hw_loss 0.404890 lr 0.00029424 rank 5
2023-03-01 03:58:53,633 DEBUG TRAIN Batch 48/3700 loss 7.490524 loss_att 9.015132 loss_ctc 11.682395 loss_rnnt 6.435851 hw_loss 0.357815 lr 0.00029424 rank 6
2023-03-01 03:59:32,110 DEBUG TRAIN Batch 48/3800 loss 3.876979 loss_att 6.747565 loss_ctc 7.889958 loss_rnnt 2.673489 hw_loss 0.176829 lr 0.00029422 rank 3
2023-03-01 03:59:32,117 DEBUG TRAIN Batch 48/3800 loss 4.781064 loss_att 10.288936 loss_ctc 5.126771 loss_rnnt 3.597951 hw_loss 0.066459 lr 0.00029422 rank 7
2023-03-01 03:59:32,119 DEBUG TRAIN Batch 48/3800 loss 3.694067 loss_att 7.847219 loss_ctc 8.665756 loss_rnnt 2.081614 hw_loss 0.222994 lr 0.00029422 rank 5
2023-03-01 03:59:32,118 DEBUG TRAIN Batch 48/3800 loss 1.428409 loss_att 5.081234 loss_ctc 4.158924 loss_rnnt 0.194950 hw_loss 0.260296 lr 0.00029423 rank 0
2023-03-01 03:59:32,121 DEBUG TRAIN Batch 48/3800 loss 3.018213 loss_att 8.631556 loss_ctc 5.603313 loss_rnnt 1.340176 hw_loss 0.395040 lr 0.00029423 rank 1
2023-03-01 03:59:32,123 DEBUG TRAIN Batch 48/3800 loss 7.895956 loss_att 8.438110 loss_ctc 11.392802 loss_rnnt 7.165460 hw_loss 0.292160 lr 0.00029422 rank 4
2023-03-01 03:59:32,135 DEBUG TRAIN Batch 48/3800 loss 10.945962 loss_att 12.462120 loss_ctc 17.577917 loss_rnnt 9.602008 hw_loss 0.293368 lr 0.00029423 rank 2
2023-03-01 03:59:32,164 DEBUG TRAIN Batch 48/3800 loss 3.403575 loss_att 4.628445 loss_ctc 5.149164 loss_rnnt 2.735115 hw_loss 0.357638 lr 0.00029423 rank 6
2023-03-01 04:00:11,375 DEBUG TRAIN Batch 48/3900 loss 5.462020 loss_att 9.474524 loss_ctc 9.118635 loss_rnnt 4.125406 hw_loss 0.087310 lr 0.00029421 rank 3
2023-03-01 04:00:11,384 DEBUG TRAIN Batch 48/3900 loss 7.929729 loss_att 11.125786 loss_ctc 15.571665 loss_rnnt 6.156098 hw_loss 0.216550 lr 0.00029422 rank 1
2023-03-01 04:00:11,386 DEBUG TRAIN Batch 48/3900 loss 4.869276 loss_att 6.803049 loss_ctc 12.437903 loss_rnnt 3.344224 hw_loss 0.242150 lr 0.00029421 rank 5
2023-03-01 04:00:11,386 DEBUG TRAIN Batch 48/3900 loss 6.280567 loss_att 9.893782 loss_ctc 11.523489 loss_rnnt 4.762216 hw_loss 0.181221 lr 0.00029420 rank 7
2023-03-01 04:00:11,387 DEBUG TRAIN Batch 48/3900 loss 4.958402 loss_att 9.607557 loss_ctc 11.476910 loss_rnnt 2.992849 hw_loss 0.312351 lr 0.00029421 rank 2
2023-03-01 04:00:11,388 DEBUG TRAIN Batch 48/3900 loss 3.961498 loss_att 5.455156 loss_ctc 4.305716 loss_rnnt 3.456445 hw_loss 0.300799 lr 0.00029421 rank 6
2023-03-01 04:00:11,389 DEBUG TRAIN Batch 48/3900 loss 3.184504 loss_att 5.440221 loss_ctc 7.054851 loss_rnnt 2.046441 hw_loss 0.320388 lr 0.00029422 rank 0
2023-03-01 04:00:11,406 DEBUG TRAIN Batch 48/3900 loss 5.108961 loss_att 8.825825 loss_ctc 10.764140 loss_rnnt 3.487887 hw_loss 0.231894 lr 0.00029421 rank 4
2023-03-01 04:01:18,191 DEBUG TRAIN Batch 48/4000 loss 3.886031 loss_att 6.716720 loss_ctc 7.719001 loss_rnnt 2.749831 hw_loss 0.110625 lr 0.00029420 rank 3
2023-03-01 04:01:18,203 DEBUG TRAIN Batch 48/4000 loss 4.649531 loss_att 6.586935 loss_ctc 6.406334 loss_rnnt 3.793107 hw_loss 0.440068 lr 0.00029419 rank 7
2023-03-01 04:01:18,205 DEBUG TRAIN Batch 48/4000 loss 15.116263 loss_att 16.478550 loss_ctc 25.306141 loss_rnnt 13.484771 hw_loss 0.000722 lr 0.00029420 rank 6
2023-03-01 04:01:18,206 DEBUG TRAIN Batch 48/4000 loss 2.516175 loss_att 5.696436 loss_ctc 4.318620 loss_rnnt 1.519678 hw_loss 0.225223 lr 0.00029420 rank 0
2023-03-01 04:01:18,208 DEBUG TRAIN Batch 48/4000 loss 2.396851 loss_att 3.508801 loss_ctc 4.167466 loss_rnnt 1.793105 hw_loss 0.272388 lr 0.00029420 rank 5
2023-03-01 04:01:18,209 DEBUG TRAIN Batch 48/4000 loss 6.178383 loss_att 9.890734 loss_ctc 8.137691 loss_rnnt 5.091809 hw_loss 0.155367 lr 0.00029420 rank 4
2023-03-01 04:01:18,210 DEBUG TRAIN Batch 48/4000 loss 6.384997 loss_att 8.246573 loss_ctc 10.365986 loss_rnnt 5.365034 hw_loss 0.219093 lr 0.00029420 rank 2
2023-03-01 04:01:18,256 DEBUG TRAIN Batch 48/4000 loss 3.700835 loss_att 9.842577 loss_ctc 6.199726 loss_rnnt 1.984407 hw_loss 0.290426 lr 0.00029420 rank 1
2023-03-01 04:01:56,707 DEBUG TRAIN Batch 48/4100 loss 6.971057 loss_att 8.940363 loss_ctc 10.460572 loss_rnnt 6.011822 hw_loss 0.187698 lr 0.00029419 rank 0
2023-03-01 04:01:56,715 DEBUG TRAIN Batch 48/4100 loss 2.149006 loss_att 5.209813 loss_ctc 4.235791 loss_rnnt 1.201965 hw_loss 0.106204 lr 0.00029419 rank 1
2023-03-01 04:01:56,722 DEBUG TRAIN Batch 48/4100 loss 8.514302 loss_att 10.112700 loss_ctc 12.807794 loss_rnnt 7.472136 hw_loss 0.281291 lr 0.00029418 rank 7
2023-03-01 04:01:56,729 DEBUG TRAIN Batch 48/4100 loss 6.985721 loss_att 10.187932 loss_ctc 13.040953 loss_rnnt 5.391577 hw_loss 0.274382 lr 0.00029419 rank 2
2023-03-01 04:01:56,729 DEBUG TRAIN Batch 48/4100 loss 5.028570 loss_att 7.566076 loss_ctc 9.754038 loss_rnnt 3.751780 hw_loss 0.261048 lr 0.00029418 rank 3
2023-03-01 04:01:56,731 DEBUG TRAIN Batch 48/4100 loss 4.742754 loss_att 7.979634 loss_ctc 8.530153 loss_rnnt 3.461587 hw_loss 0.241508 lr 0.00029419 rank 5
2023-03-01 04:01:56,733 DEBUG TRAIN Batch 48/4100 loss 4.190793 loss_att 8.188436 loss_ctc 6.168677 loss_rnnt 3.105347 hw_loss 0.041623 lr 0.00029419 rank 4
2023-03-01 04:01:56,736 DEBUG TRAIN Batch 48/4100 loss 5.632532 loss_att 7.688231 loss_ctc 7.198370 loss_rnnt 4.890193 hw_loss 0.229540 lr 0.00029419 rank 6
2023-03-01 04:02:35,501 DEBUG TRAIN Batch 48/4200 loss 10.231175 loss_att 15.478396 loss_ctc 17.653446 loss_rnnt 8.068245 hw_loss 0.232221 lr 0.00029417 rank 2
2023-03-01 04:02:35,512 DEBUG TRAIN Batch 48/4200 loss 3.782857 loss_att 7.935689 loss_ctc 5.672646 loss_rnnt 2.595055 hw_loss 0.197370 lr 0.00029418 rank 0
2023-03-01 04:02:35,514 DEBUG TRAIN Batch 48/4200 loss 4.330322 loss_att 5.739713 loss_ctc 6.983009 loss_rnnt 3.531243 hw_loss 0.306580 lr 0.00029417 rank 5
2023-03-01 04:02:35,514 DEBUG TRAIN Batch 48/4200 loss 7.939302 loss_att 10.771710 loss_ctc 12.611174 loss_rnnt 6.558392 hw_loss 0.359086 lr 0.00029416 rank 7
2023-03-01 04:02:35,514 DEBUG TRAIN Batch 48/4200 loss 6.350090 loss_att 7.152652 loss_ctc 12.068983 loss_rnnt 5.349283 hw_loss 0.145830 lr 0.00029417 rank 4
2023-03-01 04:02:35,517 DEBUG TRAIN Batch 48/4200 loss 7.989481 loss_att 10.711479 loss_ctc 16.820539 loss_rnnt 6.076466 hw_loss 0.358390 lr 0.00029417 rank 3
2023-03-01 04:02:35,518 DEBUG TRAIN Batch 48/4200 loss 1.721110 loss_att 5.103591 loss_ctc 5.224350 loss_rnnt 0.505260 hw_loss 0.135479 lr 0.00029418 rank 1
2023-03-01 04:02:35,522 DEBUG TRAIN Batch 48/4200 loss 8.626756 loss_att 12.678983 loss_ctc 17.788952 loss_rnnt 6.445760 hw_loss 0.279230 lr 0.00029418 rank 6
2023-03-01 04:03:45,596 DEBUG TRAIN Batch 48/4300 loss 4.513594 loss_att 7.106174 loss_ctc 10.220758 loss_rnnt 3.034259 hw_loss 0.374744 lr 0.00029416 rank 3
2023-03-01 04:03:45,611 DEBUG TRAIN Batch 48/4300 loss 4.974130 loss_att 7.547410 loss_ctc 10.277431 loss_rnnt 3.627875 hw_loss 0.233422 lr 0.00029415 rank 7
2023-03-01 04:03:45,611 DEBUG TRAIN Batch 48/4300 loss 6.250304 loss_att 7.872212 loss_ctc 7.553211 loss_rnnt 5.681159 hw_loss 0.133205 lr 0.00029416 rank 5
2023-03-01 04:03:45,616 DEBUG TRAIN Batch 48/4300 loss 10.133565 loss_att 13.276087 loss_ctc 18.759153 loss_rnnt 8.245821 hw_loss 0.204678 lr 0.00029416 rank 0
2023-03-01 04:03:45,621 DEBUG TRAIN Batch 48/4300 loss 10.848904 loss_att 14.722413 loss_ctc 17.635506 loss_rnnt 9.072580 hw_loss 0.181390 lr 0.00029416 rank 4
2023-03-01 04:03:45,622 DEBUG TRAIN Batch 48/4300 loss 3.758993 loss_att 6.519541 loss_ctc 5.724611 loss_rnnt 2.888398 hw_loss 0.105756 lr 0.00029416 rank 6
2023-03-01 04:03:45,630 DEBUG TRAIN Batch 48/4300 loss 4.860570 loss_att 6.182598 loss_ctc 6.749417 loss_rnnt 4.188282 hw_loss 0.292568 lr 0.00029416 rank 2
2023-03-01 04:03:45,664 DEBUG TRAIN Batch 48/4300 loss 6.979446 loss_att 9.609826 loss_ctc 16.898468 loss_rnnt 5.012909 hw_loss 0.221109 lr 0.00029416 rank 1
2023-03-01 04:04:24,634 DEBUG TRAIN Batch 48/4400 loss 4.252945 loss_att 5.424158 loss_ctc 8.005041 loss_rnnt 3.374143 hw_loss 0.270524 lr 0.00029415 rank 0
2023-03-01 04:04:24,634 DEBUG TRAIN Batch 48/4400 loss 4.922953 loss_att 5.364310 loss_ctc 6.287675 loss_rnnt 4.501453 hw_loss 0.283624 lr 0.00029415 rank 2
2023-03-01 04:04:24,636 DEBUG TRAIN Batch 48/4400 loss 3.362376 loss_att 6.591883 loss_ctc 6.288238 loss_rnnt 2.233299 hw_loss 0.174490 lr 0.00029415 rank 5
2023-03-01 04:04:24,638 DEBUG TRAIN Batch 48/4400 loss 6.985056 loss_att 10.574255 loss_ctc 14.787462 loss_rnnt 5.134012 hw_loss 0.174156 lr 0.00029414 rank 3
2023-03-01 04:04:24,639 DEBUG TRAIN Batch 48/4400 loss 8.176444 loss_att 8.047058 loss_ctc 11.795712 loss_rnnt 7.525416 hw_loss 0.364379 lr 0.00029414 rank 7
2023-03-01 04:04:24,640 DEBUG TRAIN Batch 48/4400 loss 4.881296 loss_att 5.904136 loss_ctc 5.508209 loss_rnnt 4.436744 hw_loss 0.293242 lr 0.00029415 rank 4
2023-03-01 04:04:24,640 DEBUG TRAIN Batch 48/4400 loss 1.624600 loss_att 4.558525 loss_ctc 4.010175 loss_rnnt 0.616103 hw_loss 0.194315 lr 0.00029415 rank 1
2023-03-01 04:04:24,642 DEBUG TRAIN Batch 48/4400 loss 8.181527 loss_att 8.812584 loss_ctc 14.152718 loss_rnnt 7.082912 hw_loss 0.330459 lr 0.00029415 rank 6
2023-03-01 04:05:03,234 DEBUG TRAIN Batch 48/4500 loss 3.358323 loss_att 7.647785 loss_ctc 9.259333 loss_rnnt 1.532182 hw_loss 0.340213 lr 0.00029414 rank 1
2023-03-01 04:05:03,236 DEBUG TRAIN Batch 48/4500 loss 4.464226 loss_att 7.195195 loss_ctc 9.642488 loss_rnnt 3.126431 hw_loss 0.189687 lr 0.00029413 rank 4
2023-03-01 04:05:03,239 DEBUG TRAIN Batch 48/4500 loss 5.403225 loss_att 9.016537 loss_ctc 9.949467 loss_rnnt 3.953861 hw_loss 0.226006 lr 0.00029413 rank 5
2023-03-01 04:05:03,240 DEBUG TRAIN Batch 48/4500 loss 2.601883 loss_att 5.344646 loss_ctc 3.634748 loss_rnnt 1.813513 hw_loss 0.191441 lr 0.00029413 rank 3
2023-03-01 04:05:03,245 DEBUG TRAIN Batch 48/4500 loss 6.581978 loss_att 9.742300 loss_ctc 13.353842 loss_rnnt 4.977781 hw_loss 0.129782 lr 0.00029413 rank 7
2023-03-01 04:05:03,245 DEBUG TRAIN Batch 48/4500 loss 3.886011 loss_att 5.396147 loss_ctc 7.859566 loss_rnnt 2.960356 hw_loss 0.175913 lr 0.00029414 rank 0
2023-03-01 04:05:03,258 DEBUG TRAIN Batch 48/4500 loss 10.794026 loss_att 13.389177 loss_ctc 15.995241 loss_rnnt 9.493989 hw_loss 0.164081 lr 0.00029414 rank 6
2023-03-01 04:05:03,297 DEBUG TRAIN Batch 48/4500 loss 6.022592 loss_att 7.583358 loss_ctc 8.190316 loss_rnnt 5.281332 hw_loss 0.262643 lr 0.00029414 rank 2
2023-03-01 04:05:42,538 DEBUG TRAIN Batch 48/4600 loss 7.857319 loss_att 8.829279 loss_ctc 11.759997 loss_rnnt 7.077221 hw_loss 0.122531 lr 0.00029412 rank 4
2023-03-01 04:05:42,547 DEBUG TRAIN Batch 48/4600 loss 1.742203 loss_att 4.370396 loss_ctc 2.546904 loss_rnnt 1.001858 hw_loss 0.201400 lr 0.00029413 rank 1
2023-03-01 04:05:42,549 DEBUG TRAIN Batch 48/4600 loss 6.750271 loss_att 7.803480 loss_ctc 9.808270 loss_rnnt 6.088516 hw_loss 0.081338 lr 0.00029412 rank 5
2023-03-01 04:05:42,552 DEBUG TRAIN Batch 48/4600 loss 8.730594 loss_att 11.575777 loss_ctc 16.334440 loss_rnnt 7.002653 hw_loss 0.271982 lr 0.00029412 rank 2
2023-03-01 04:05:42,555 DEBUG TRAIN Batch 48/4600 loss 4.231024 loss_att 5.542399 loss_ctc 8.754737 loss_rnnt 3.215468 hw_loss 0.281473 lr 0.00029412 rank 3
2023-03-01 04:05:42,557 DEBUG TRAIN Batch 48/4600 loss 5.880460 loss_att 7.978604 loss_ctc 7.626899 loss_rnnt 5.127075 hw_loss 0.189181 lr 0.00029411 rank 7
2023-03-01 04:05:42,559 DEBUG TRAIN Batch 48/4600 loss 9.326632 loss_att 11.143165 loss_ctc 14.121844 loss_rnnt 8.233425 hw_loss 0.169761 lr 0.00029413 rank 0
2023-03-01 04:05:42,569 DEBUG TRAIN Batch 48/4600 loss 2.408242 loss_att 5.321884 loss_ctc 6.043693 loss_rnnt 1.212752 hw_loss 0.240065 lr 0.00029413 rank 6
2023-03-01 04:06:48,685 DEBUG TRAIN Batch 48/4700 loss 3.542758 loss_att 6.147770 loss_ctc 10.357871 loss_rnnt 1.962307 hw_loss 0.282687 lr 0.00029411 rank 4
2023-03-01 04:06:48,696 DEBUG TRAIN Batch 48/4700 loss 5.338812 loss_att 7.498624 loss_ctc 8.091051 loss_rnnt 4.435999 hw_loss 0.194786 lr 0.00029410 rank 7
2023-03-01 04:06:48,696 DEBUG TRAIN Batch 48/4700 loss 6.822421 loss_att 8.480221 loss_ctc 9.086955 loss_rnnt 6.083213 hw_loss 0.198207 lr 0.00029411 rank 0
2023-03-01 04:06:48,699 DEBUG TRAIN Batch 48/4700 loss 2.641616 loss_att 5.207376 loss_ctc 4.286933 loss_rnnt 1.838481 hw_loss 0.132389 lr 0.00029411 rank 5
2023-03-01 04:06:48,700 DEBUG TRAIN Batch 48/4700 loss 8.060843 loss_att 11.383976 loss_ctc 16.472448 loss_rnnt 6.079064 hw_loss 0.366758 lr 0.00029411 rank 1
2023-03-01 04:06:48,706 DEBUG TRAIN Batch 48/4700 loss 3.562323 loss_att 7.096454 loss_ctc 6.273136 loss_rnnt 2.346555 hw_loss 0.276561 lr 0.00029411 rank 6
2023-03-01 04:06:48,706 DEBUG TRAIN Batch 48/4700 loss 9.646235 loss_att 12.998003 loss_ctc 16.222252 loss_rnnt 7.980759 hw_loss 0.221852 lr 0.00029411 rank 3
2023-03-01 04:06:48,708 DEBUG TRAIN Batch 48/4700 loss 5.101956 loss_att 9.050775 loss_ctc 8.005850 loss_rnnt 3.773571 hw_loss 0.283941 lr 0.00029411 rank 2
2023-03-01 04:07:27,057 DEBUG TRAIN Batch 48/4800 loss 6.821180 loss_att 11.189782 loss_ctc 10.852147 loss_rnnt 5.320439 hw_loss 0.167922 lr 0.00029410 rank 6
2023-03-01 04:07:27,065 DEBUG TRAIN Batch 48/4800 loss 11.851891 loss_att 15.006982 loss_ctc 14.783348 loss_rnnt 10.700282 hw_loss 0.243244 lr 0.00029410 rank 1
2023-03-01 04:07:27,073 DEBUG TRAIN Batch 48/4800 loss 7.796734 loss_att 10.484962 loss_ctc 15.075134 loss_rnnt 6.183352 hw_loss 0.197405 lr 0.00029409 rank 7
2023-03-01 04:07:27,073 DEBUG TRAIN Batch 48/4800 loss 6.203227 loss_att 9.490376 loss_ctc 11.512094 loss_rnnt 4.739505 hw_loss 0.184580 lr 0.00029410 rank 0
2023-03-01 04:07:27,075 DEBUG TRAIN Batch 48/4800 loss 20.122887 loss_att 25.590981 loss_ctc 36.607338 loss_rnnt 16.712051 hw_loss 0.223664 lr 0.00029409 rank 3
2023-03-01 04:07:27,076 DEBUG TRAIN Batch 48/4800 loss 2.863957 loss_att 6.105559 loss_ctc 3.574925 loss_rnnt 1.970128 hw_loss 0.282587 lr 0.00029410 rank 2
2023-03-01 04:07:27,083 DEBUG TRAIN Batch 48/4800 loss 10.261079 loss_att 13.534320 loss_ctc 17.194530 loss_rnnt 8.506397 hw_loss 0.329200 lr 0.00029410 rank 5
2023-03-01 04:07:27,094 DEBUG TRAIN Batch 48/4800 loss 2.744731 loss_att 5.999659 loss_ctc 5.841471 loss_rnnt 1.581486 hw_loss 0.186301 lr 0.00029410 rank 4
2023-03-01 04:08:05,828 DEBUG TRAIN Batch 48/4900 loss 3.572415 loss_att 7.086622 loss_ctc 6.945683 loss_rnnt 2.309881 hw_loss 0.206108 lr 0.00029409 rank 1
2023-03-01 04:08:05,832 DEBUG TRAIN Batch 48/4900 loss 2.033621 loss_att 5.620404 loss_ctc 4.803072 loss_rnnt 0.795041 hw_loss 0.284930 lr 0.00029408 rank 4
2023-03-01 04:08:05,833 DEBUG TRAIN Batch 48/4900 loss 4.381752 loss_att 7.008259 loss_ctc 7.181719 loss_rnnt 3.359083 hw_loss 0.232573 lr 0.00029409 rank 6
2023-03-01 04:08:05,846 DEBUG TRAIN Batch 48/4900 loss 5.573479 loss_att 9.138235 loss_ctc 9.134160 loss_rnnt 4.200928 hw_loss 0.346580 lr 0.00029409 rank 0
2023-03-01 04:08:05,847 DEBUG TRAIN Batch 48/4900 loss 1.927389 loss_att 4.108748 loss_ctc 2.779508 loss_rnnt 1.187281 hw_loss 0.356663 lr 0.00029409 rank 2
2023-03-01 04:08:05,852 DEBUG TRAIN Batch 48/4900 loss 6.802193 loss_att 9.933524 loss_ctc 11.174773 loss_rnnt 5.523715 hw_loss 0.129753 lr 0.00029408 rank 7
2023-03-01 04:08:05,880 DEBUG TRAIN Batch 48/4900 loss 9.905100 loss_att 12.235214 loss_ctc 13.549191 loss_rnnt 8.767286 hw_loss 0.348585 lr 0.00029408 rank 5
2023-03-01 04:08:05,880 DEBUG TRAIN Batch 48/4900 loss 12.297297 loss_att 11.415512 loss_ctc 21.178732 loss_rnnt 11.125351 hw_loss 0.307707 lr 0.00029408 rank 3
2023-03-01 04:09:14,594 DEBUG TRAIN Batch 48/5000 loss 5.096690 loss_att 7.358304 loss_ctc 10.114587 loss_rnnt 3.827679 hw_loss 0.276815 lr 0.00029408 rank 1
2023-03-01 04:09:14,599 DEBUG TRAIN Batch 48/5000 loss 4.298595 loss_att 6.275238 loss_ctc 9.121029 loss_rnnt 3.081443 hw_loss 0.335309 lr 0.00029407 rank 3
2023-03-01 04:09:14,603 DEBUG TRAIN Batch 48/5000 loss 6.990010 loss_att 9.939321 loss_ctc 11.821445 loss_rnnt 5.631441 hw_loss 0.233467 lr 0.00029408 rank 0
2023-03-01 04:09:14,604 DEBUG TRAIN Batch 48/5000 loss 3.564376 loss_att 6.336805 loss_ctc 6.049195 loss_rnnt 2.554201 hw_loss 0.233212 lr 0.00029406 rank 7
2023-03-01 04:09:14,606 DEBUG TRAIN Batch 48/5000 loss 11.605856 loss_att 13.577505 loss_ctc 24.351887 loss_rnnt 9.319876 hw_loss 0.360337 lr 0.00029407 rank 6
2023-03-01 04:09:14,610 DEBUG TRAIN Batch 48/5000 loss 3.171723 loss_att 4.500495 loss_ctc 6.011869 loss_rnnt 2.426652 hw_loss 0.188682 lr 0.00029407 rank 5
2023-03-01 04:09:14,611 DEBUG TRAIN Batch 48/5000 loss 7.084279 loss_att 10.206021 loss_ctc 12.446977 loss_rnnt 5.559504 hw_loss 0.347624 lr 0.00029407 rank 2
2023-03-01 04:09:14,613 DEBUG TRAIN Batch 48/5000 loss 8.108829 loss_att 11.369291 loss_ctc 16.587252 loss_rnnt 6.165247 hw_loss 0.301938 lr 0.00029407 rank 4
2023-03-01 04:09:53,206 DEBUG TRAIN Batch 48/5100 loss 4.337568 loss_att 9.043488 loss_ctc 9.163495 loss_rnnt 2.687353 hw_loss 0.122953 lr 0.00029406 rank 3
2023-03-01 04:09:53,218 DEBUG TRAIN Batch 48/5100 loss 13.473128 loss_att 16.869091 loss_ctc 21.725628 loss_rnnt 11.543587 hw_loss 0.281279 lr 0.00029406 rank 5
2023-03-01 04:09:53,221 DEBUG TRAIN Batch 48/5100 loss 3.559918 loss_att 6.794307 loss_ctc 8.150642 loss_rnnt 2.202321 hw_loss 0.184917 lr 0.00029406 rank 0
2023-03-01 04:09:53,226 DEBUG TRAIN Batch 48/5100 loss 10.378807 loss_att 10.971449 loss_ctc 15.508296 loss_rnnt 9.521320 hw_loss 0.103173 lr 0.00029406 rank 6
2023-03-01 04:09:53,227 DEBUG TRAIN Batch 48/5100 loss 4.042804 loss_att 7.279851 loss_ctc 6.111716 loss_rnnt 2.999663 hw_loss 0.224768 lr 0.00029405 rank 7
2023-03-01 04:09:53,229 DEBUG TRAIN Batch 48/5100 loss 14.901180 loss_att 15.356335 loss_ctc 23.827225 loss_rnnt 13.480180 hw_loss 0.262178 lr 0.00029406 rank 4
2023-03-01 04:09:53,229 DEBUG TRAIN Batch 48/5100 loss 5.307477 loss_att 8.274482 loss_ctc 9.949800 loss_rnnt 4.037859 hw_loss 0.107325 lr 0.00029406 rank 1
2023-03-01 04:09:53,231 DEBUG TRAIN Batch 48/5100 loss 6.574760 loss_att 6.713690 loss_ctc 10.701730 loss_rnnt 5.852468 hw_loss 0.270456 lr 0.00029406 rank 2
2023-03-01 04:10:31,461 DEBUG TRAIN Batch 48/5200 loss 3.274231 loss_att 5.755964 loss_ctc 8.875282 loss_rnnt 1.979453 hw_loss 0.096795 lr 0.00029405 rank 6
2023-03-01 04:10:31,474 DEBUG TRAIN Batch 48/5200 loss 10.947940 loss_att 16.215008 loss_ctc 24.760160 loss_rnnt 8.001122 hw_loss 0.097080 lr 0.00029405 rank 0
2023-03-01 04:10:31,475 DEBUG TRAIN Batch 48/5200 loss 10.297483 loss_att 11.901071 loss_ctc 14.670077 loss_rnnt 9.191051 hw_loss 0.380066 lr 0.00029405 rank 5
2023-03-01 04:10:31,478 DEBUG TRAIN Batch 48/5200 loss 8.668897 loss_att 10.138669 loss_ctc 12.136363 loss_rnnt 7.832627 hw_loss 0.149972 lr 0.00029404 rank 3
2023-03-01 04:10:31,480 DEBUG TRAIN Batch 48/5200 loss 8.862482 loss_att 11.143718 loss_ctc 13.871840 loss_rnnt 7.562057 hw_loss 0.330493 lr 0.00029404 rank 7
2023-03-01 04:10:31,480 DEBUG TRAIN Batch 48/5200 loss 6.797743 loss_att 8.604457 loss_ctc 8.315648 loss_rnnt 6.089190 hw_loss 0.271543 lr 0.00029405 rank 2
2023-03-01 04:10:31,484 DEBUG TRAIN Batch 48/5200 loss 2.001539 loss_att 4.592080 loss_ctc 3.389901 loss_rnnt 1.242668 hw_loss 0.104340 lr 0.00029405 rank 1
2023-03-01 04:10:31,489 DEBUG TRAIN Batch 48/5200 loss 5.134350 loss_att 10.890960 loss_ctc 9.658031 loss_rnnt 3.227577 hw_loss 0.285550 lr 0.00029405 rank 4
2023-03-01 04:11:10,943 DEBUG TRAIN Batch 48/5300 loss 2.575660 loss_att 6.355719 loss_ctc 5.175540 loss_rnnt 1.313407 hw_loss 0.299232 lr 0.00029404 rank 6
2023-03-01 04:11:10,946 DEBUG TRAIN Batch 48/5300 loss 10.848001 loss_att 15.592146 loss_ctc 18.062744 loss_rnnt 8.852760 hw_loss 0.158339 lr 0.00029403 rank 5
2023-03-01 04:11:10,952 DEBUG TRAIN Batch 48/5300 loss 2.787281 loss_att 7.328959 loss_ctc 6.725513 loss_rnnt 1.256468 hw_loss 0.182587 lr 0.00029404 rank 0
2023-03-01 04:11:10,953 DEBUG TRAIN Batch 48/5300 loss 8.321789 loss_att 11.708713 loss_ctc 15.561595 loss_rnnt 6.616628 hw_loss 0.117129 lr 0.00029402 rank 7
2023-03-01 04:11:10,962 DEBUG TRAIN Batch 48/5300 loss 2.499632 loss_att 4.724835 loss_ctc 3.631364 loss_rnnt 1.742956 hw_loss 0.301382 lr 0.00029403 rank 2
2023-03-01 04:11:10,965 DEBUG TRAIN Batch 48/5300 loss 22.929968 loss_att 21.351524 loss_ctc 37.916000 loss_rnnt 21.176939 hw_loss 0.132343 lr 0.00029403 rank 4
2023-03-01 04:11:10,976 DEBUG TRAIN Batch 48/5300 loss 7.614599 loss_att 11.343041 loss_ctc 15.980093 loss_rnnt 5.685921 hw_loss 0.126734 lr 0.00029403 rank 3
2023-03-01 04:11:10,996 DEBUG TRAIN Batch 48/5300 loss 3.446683 loss_att 7.050709 loss_ctc 7.590248 loss_rnnt 2.099448 hw_loss 0.138665 lr 0.00029404 rank 1
2023-03-01 04:12:17,585 DEBUG TRAIN Batch 48/5400 loss 6.925052 loss_att 9.480703 loss_ctc 11.641480 loss_rnnt 5.674669 hw_loss 0.206990 lr 0.00029403 rank 0
2023-03-01 04:12:17,588 DEBUG TRAIN Batch 48/5400 loss 2.207428 loss_att 7.237278 loss_ctc 6.555462 loss_rnnt 0.552989 hw_loss 0.128871 lr 0.00029402 rank 1
2023-03-01 04:12:17,589 DEBUG TRAIN Batch 48/5400 loss 12.967125 loss_att 12.943143 loss_ctc 18.624516 loss_rnnt 12.116104 hw_loss 0.190311 lr 0.00029402 rank 5
2023-03-01 04:12:17,592 DEBUG TRAIN Batch 48/5400 loss 5.312631 loss_att 9.055882 loss_ctc 9.746124 loss_rnnt 3.869530 hw_loss 0.193721 lr 0.00029402 rank 4
2023-03-01 04:12:17,592 DEBUG TRAIN Batch 48/5400 loss 9.029317 loss_att 9.013795 loss_ctc 11.717870 loss_rnnt 8.568306 hw_loss 0.198078 lr 0.00029401 rank 7
2023-03-01 04:12:17,597 DEBUG TRAIN Batch 48/5400 loss 3.831891 loss_att 6.097409 loss_ctc 5.259554 loss_rnnt 3.089266 hw_loss 0.185936 lr 0.00029402 rank 6
2023-03-01 04:12:17,597 DEBUG TRAIN Batch 48/5400 loss 4.999528 loss_att 7.420507 loss_ctc 6.174737 loss_rnnt 4.209430 hw_loss 0.279765 lr 0.00029402 rank 2
2023-03-01 04:12:17,599 DEBUG TRAIN Batch 48/5400 loss 6.262300 loss_att 9.178536 loss_ctc 13.322908 loss_rnnt 4.632220 hw_loss 0.197659 lr 0.00029402 rank 3
2023-03-01 04:12:56,338 DEBUG TRAIN Batch 48/5500 loss 8.835077 loss_att 11.745592 loss_ctc 20.584059 loss_rnnt 6.516864 hw_loss 0.317963 lr 0.00029401 rank 1
2023-03-01 04:12:56,348 DEBUG TRAIN Batch 48/5500 loss 12.570602 loss_att 13.423048 loss_ctc 19.554909 loss_rnnt 11.423531 hw_loss 0.085016 lr 0.00029400 rank 7
2023-03-01 04:12:56,349 DEBUG TRAIN Batch 48/5500 loss 13.702690 loss_att 16.973181 loss_ctc 20.758364 loss_rnnt 12.045760 hw_loss 0.116390 lr 0.00029401 rank 4
2023-03-01 04:12:56,349 DEBUG TRAIN Batch 48/5500 loss 4.695381 loss_att 7.361981 loss_ctc 9.396358 loss_rnnt 3.418879 hw_loss 0.218223 lr 0.00029401 rank 0
2023-03-01 04:12:56,349 DEBUG TRAIN Batch 48/5500 loss 7.819108 loss_att 12.444717 loss_ctc 12.540394 loss_rnnt 6.164502 hw_loss 0.187462 lr 0.00029400 rank 3
2023-03-01 04:12:56,353 DEBUG TRAIN Batch 48/5500 loss 5.331422 loss_att 7.564030 loss_ctc 7.976893 loss_rnnt 4.421991 hw_loss 0.206587 lr 0.00029401 rank 2
2023-03-01 04:12:56,353 DEBUG TRAIN Batch 48/5500 loss 3.998314 loss_att 6.695962 loss_ctc 6.060121 loss_rnnt 3.015155 hw_loss 0.316353 lr 0.00029401 rank 5
2023-03-01 04:12:56,361 DEBUG TRAIN Batch 48/5500 loss 3.277292 loss_att 6.123446 loss_ctc 5.998240 loss_rnnt 2.258268 hw_loss 0.163125 lr 0.00029401 rank 6
2023-03-01 04:13:35,192 DEBUG TRAIN Batch 48/5600 loss 2.255666 loss_att 4.213397 loss_ctc 4.992463 loss_rnnt 1.335906 hw_loss 0.306203 lr 0.00029400 rank 5
2023-03-01 04:13:35,202 DEBUG TRAIN Batch 48/5600 loss 8.961535 loss_att 10.961983 loss_ctc 18.989342 loss_rnnt 7.047458 hw_loss 0.331775 lr 0.00029399 rank 3
2023-03-01 04:13:35,204 DEBUG TRAIN Batch 48/5600 loss 10.853691 loss_att 14.633963 loss_ctc 22.147562 loss_rnnt 8.508406 hw_loss 0.156340 lr 0.00029400 rank 4
2023-03-01 04:13:35,204 DEBUG TRAIN Batch 48/5600 loss 11.533648 loss_att 16.615578 loss_ctc 21.353806 loss_rnnt 9.027320 hw_loss 0.338602 lr 0.00029400 rank 1
2023-03-01 04:13:35,206 DEBUG TRAIN Batch 48/5600 loss 7.718749 loss_att 10.393228 loss_ctc 13.241543 loss_rnnt 6.292531 hw_loss 0.290531 lr 0.00029400 rank 2
2023-03-01 04:13:35,208 DEBUG TRAIN Batch 48/5600 loss 6.444660 loss_att 8.859338 loss_ctc 12.728995 loss_rnnt 5.014228 hw_loss 0.205471 lr 0.00029400 rank 6
2023-03-01 04:13:35,209 DEBUG TRAIN Batch 48/5600 loss 4.379222 loss_att 7.355176 loss_ctc 8.343620 loss_rnnt 3.085598 hw_loss 0.318464 lr 0.00029400 rank 0
2023-03-01 04:13:35,209 DEBUG TRAIN Batch 48/5600 loss 12.898991 loss_att 16.349499 loss_ctc 21.981375 loss_rnnt 10.870583 hw_loss 0.238729 lr 0.00029399 rank 7
2023-03-01 04:14:41,332 DEBUG TRAIN Batch 48/5700 loss 4.593414 loss_att 8.334287 loss_ctc 5.799410 loss_rnnt 3.480083 hw_loss 0.383169 lr 0.00029399 rank 1
2023-03-01 04:14:41,333 DEBUG TRAIN Batch 48/5700 loss 9.470460 loss_att 12.152693 loss_ctc 15.403046 loss_rnnt 8.004098 hw_loss 0.260444 lr 0.00029397 rank 7
2023-03-01 04:14:41,336 DEBUG TRAIN Batch 48/5700 loss 6.209605 loss_att 10.382269 loss_ctc 6.951339 loss_rnnt 5.129685 hw_loss 0.274668 lr 0.00029399 rank 0
2023-03-01 04:14:41,337 DEBUG TRAIN Batch 48/5700 loss 5.527811 loss_att 5.589839 loss_ctc 7.937253 loss_rnnt 4.998893 hw_loss 0.366100 lr 0.00029398 rank 5
2023-03-01 04:14:41,337 DEBUG TRAIN Batch 48/5700 loss 4.793638 loss_att 4.892661 loss_ctc 6.822085 loss_rnnt 4.345170 hw_loss 0.296631 lr 0.00029399 rank 6
2023-03-01 04:14:41,338 DEBUG TRAIN Batch 48/5700 loss 4.206052 loss_att 5.561017 loss_ctc 7.060737 loss_rnnt 3.424957 hw_loss 0.242770 lr 0.00029398 rank 2
2023-03-01 04:14:41,341 DEBUG TRAIN Batch 48/5700 loss 2.491112 loss_att 4.611173 loss_ctc 5.828431 loss_rnnt 1.486615 hw_loss 0.254079 lr 0.00029398 rank 4
2023-03-01 04:14:41,385 DEBUG TRAIN Batch 48/5700 loss 2.663850 loss_att 5.626065 loss_ctc 8.012871 loss_rnnt 1.230234 hw_loss 0.239945 lr 0.00029398 rank 3
2023-03-01 04:15:19,608 DEBUG TRAIN Batch 48/5800 loss 10.334908 loss_att 10.823083 loss_ctc 11.579092 loss_rnnt 9.899981 hw_loss 0.321378 lr 0.00029397 rank 5
2023-03-01 04:15:19,624 DEBUG TRAIN Batch 48/5800 loss 2.442379 loss_att 5.419608 loss_ctc 4.496699 loss_rnnt 1.439649 hw_loss 0.250078 lr 0.00029397 rank 3
2023-03-01 04:15:19,625 DEBUG TRAIN Batch 48/5800 loss 3.363745 loss_att 7.526145 loss_ctc 5.333169 loss_rnnt 2.121581 hw_loss 0.275802 lr 0.00029396 rank 7
2023-03-01 04:15:19,625 DEBUG TRAIN Batch 48/5800 loss 9.474234 loss_att 12.216497 loss_ctc 14.115271 loss_rnnt 8.254070 hw_loss 0.099197 lr 0.00029397 rank 0
2023-03-01 04:15:19,627 DEBUG TRAIN Batch 48/5800 loss 7.727253 loss_att 7.118209 loss_ctc 8.662457 loss_rnnt 7.560603 hw_loss 0.307059 lr 0.00029397 rank 4
2023-03-01 04:15:19,629 DEBUG TRAIN Batch 48/5800 loss 1.757896 loss_att 4.810035 loss_ctc 2.815559 loss_rnnt 0.880245 hw_loss 0.236626 lr 0.00029397 rank 1
2023-03-01 04:15:19,635 DEBUG TRAIN Batch 48/5800 loss 11.735178 loss_att 17.678610 loss_ctc 20.946880 loss_rnnt 9.182896 hw_loss 0.253815 lr 0.00029397 rank 2
2023-03-01 04:15:19,652 DEBUG TRAIN Batch 48/5800 loss 4.599478 loss_att 8.512564 loss_ctc 8.663280 loss_rnnt 3.190452 hw_loss 0.158566 lr 0.00029397 rank 6
2023-03-01 04:15:58,121 DEBUG TRAIN Batch 48/5900 loss 3.783775 loss_att 6.860582 loss_ctc 6.992645 loss_rnnt 2.621225 hw_loss 0.223760 lr 0.00029395 rank 7
2023-03-01 04:15:58,122 DEBUG TRAIN Batch 48/5900 loss 6.159904 loss_att 10.791832 loss_ctc 14.028645 loss_rnnt 4.122147 hw_loss 0.116637 lr 0.00029396 rank 0
2023-03-01 04:15:58,125 DEBUG TRAIN Batch 48/5900 loss 7.575626 loss_att 8.658888 loss_ctc 7.011722 loss_rnnt 7.286980 hw_loss 0.275964 lr 0.00029396 rank 4
2023-03-01 04:15:58,126 DEBUG TRAIN Batch 48/5900 loss 8.826672 loss_att 10.780918 loss_ctc 15.062651 loss_rnnt 7.478456 hw_loss 0.236069 lr 0.00029396 rank 1
2023-03-01 04:15:58,132 DEBUG TRAIN Batch 48/5900 loss 6.923003 loss_att 8.948588 loss_ctc 9.110497 loss_rnnt 6.112173 hw_loss 0.213837 lr 0.00029395 rank 3
2023-03-01 04:15:58,135 DEBUG TRAIN Batch 48/5900 loss 1.608776 loss_att 3.907962 loss_ctc 3.074630 loss_rnnt 0.852818 hw_loss 0.188764 lr 0.00029396 rank 6
2023-03-01 04:15:58,136 DEBUG TRAIN Batch 48/5900 loss 1.260789 loss_att 3.057748 loss_ctc 1.979839 loss_rnnt 0.680448 hw_loss 0.234518 lr 0.00029396 rank 5
2023-03-01 04:15:58,136 DEBUG TRAIN Batch 48/5900 loss 2.171327 loss_att 4.890180 loss_ctc 3.343890 loss_rnnt 1.389703 hw_loss 0.152836 lr 0.00029396 rank 2
2023-03-01 04:16:37,227 DEBUG TRAIN Batch 48/6000 loss 8.026287 loss_att 9.315306 loss_ctc 13.149254 loss_rnnt 6.915412 hw_loss 0.318769 lr 0.00029395 rank 2
2023-03-01 04:16:37,231 DEBUG TRAIN Batch 48/6000 loss 3.218075 loss_att 5.223271 loss_ctc 4.642636 loss_rnnt 2.528361 hw_loss 0.185124 lr 0.00029395 rank 1
2023-03-01 04:16:37,233 DEBUG TRAIN Batch 48/6000 loss 5.170125 loss_att 7.642712 loss_ctc 7.786613 loss_rnnt 4.235873 hw_loss 0.170382 lr 0.00029394 rank 4
2023-03-01 04:16:37,238 DEBUG TRAIN Batch 48/6000 loss 10.043510 loss_att 11.072014 loss_ctc 17.893351 loss_rnnt 8.708041 hw_loss 0.155857 lr 0.00029394 rank 3
2023-03-01 04:16:37,242 DEBUG TRAIN Batch 48/6000 loss 3.925805 loss_att 7.637157 loss_ctc 8.517703 loss_rnnt 2.513608 hw_loss 0.108138 lr 0.00029395 rank 0
2023-03-01 04:16:37,258 DEBUG TRAIN Batch 48/6000 loss 1.825247 loss_att 4.524949 loss_ctc 4.161211 loss_rnnt 0.845351 hw_loss 0.240925 lr 0.00029394 rank 7
2023-03-01 04:16:37,287 DEBUG TRAIN Batch 48/6000 loss 7.771332 loss_att 12.399834 loss_ctc 19.778561 loss_rnnt 5.120266 hw_loss 0.233252 lr 0.00029395 rank 6
2023-03-01 04:16:37,299 DEBUG TRAIN Batch 48/6000 loss 4.405991 loss_att 8.920410 loss_ctc 10.812531 loss_rnnt 2.508530 hw_loss 0.263197 lr 0.00029394 rank 5
2023-03-01 04:17:43,576 DEBUG TRAIN Batch 48/6100 loss 2.491413 loss_att 5.831858 loss_ctc 4.522024 loss_rnnt 1.422846 hw_loss 0.243245 lr 0.00029392 rank 7
2023-03-01 04:17:43,589 DEBUG TRAIN Batch 48/6100 loss 6.093756 loss_att 7.742367 loss_ctc 12.799238 loss_rnnt 4.799375 hw_loss 0.132366 lr 0.00029393 rank 5
2023-03-01 04:17:43,591 DEBUG TRAIN Batch 48/6100 loss 3.464861 loss_att 6.731710 loss_ctc 6.731307 loss_rnnt 2.219264 hw_loss 0.293815 lr 0.00029394 rank 0
2023-03-01 04:17:43,594 DEBUG TRAIN Batch 48/6100 loss 2.396784 loss_att 5.456244 loss_ctc 5.402520 loss_rnnt 1.329485 hw_loss 0.102452 lr 0.00029393 rank 4
2023-03-01 04:17:43,594 DEBUG TRAIN Batch 48/6100 loss 10.655116 loss_att 12.494719 loss_ctc 14.259651 loss_rnnt 9.652919 hw_loss 0.288136 lr 0.00029394 rank 1
2023-03-01 04:17:43,596 DEBUG TRAIN Batch 48/6100 loss 9.007052 loss_att 10.802025 loss_ctc 15.845638 loss_rnnt 7.614619 hw_loss 0.228051 lr 0.00029393 rank 2
2023-03-01 04:17:43,598 DEBUG TRAIN Batch 48/6100 loss 3.086199 loss_att 5.254545 loss_ctc 6.479822 loss_rnnt 2.015688 hw_loss 0.345671 lr 0.00029394 rank 6
2023-03-01 04:17:43,601 DEBUG TRAIN Batch 48/6100 loss 3.050830 loss_att 5.161530 loss_ctc 5.061356 loss_rnnt 2.283247 hw_loss 0.145072 lr 0.00029393 rank 3
2023-03-01 04:18:22,166 DEBUG TRAIN Batch 48/6200 loss 3.603592 loss_att 5.302121 loss_ctc 8.164087 loss_rnnt 2.557349 hw_loss 0.184633 lr 0.00029391 rank 7
2023-03-01 04:18:22,167 DEBUG TRAIN Batch 48/6200 loss 8.229731 loss_att 11.637354 loss_ctc 12.795380 loss_rnnt 6.874090 hw_loss 0.122555 lr 0.00029392 rank 5
2023-03-01 04:18:22,167 DEBUG TRAIN Batch 48/6200 loss 1.699665 loss_att 4.297005 loss_ctc 2.991459 loss_rnnt 0.871953 hw_loss 0.255010 lr 0.00029392 rank 4
2023-03-01 04:18:22,170 DEBUG TRAIN Batch 48/6200 loss 4.832499 loss_att 5.928133 loss_ctc 10.919954 loss_rnnt 3.741994 hw_loss 0.111969 lr 0.00029392 rank 0
2023-03-01 04:18:22,174 DEBUG TRAIN Batch 48/6200 loss 15.146419 loss_att 15.871284 loss_ctc 28.030750 loss_rnnt 13.124061 hw_loss 0.299015 lr 0.00029392 rank 1
2023-03-01 04:18:22,175 DEBUG TRAIN Batch 48/6200 loss 4.946372 loss_att 6.823680 loss_ctc 13.603731 loss_rnnt 3.326009 hw_loss 0.169850 lr 0.00029392 rank 3
2023-03-01 04:18:22,203 DEBUG TRAIN Batch 48/6200 loss 5.277666 loss_att 6.968356 loss_ctc 6.108372 loss_rnnt 4.688725 hw_loss 0.262577 lr 0.00029392 rank 6
2023-03-01 04:18:22,215 DEBUG TRAIN Batch 48/6200 loss 8.527007 loss_att 9.673573 loss_ctc 13.497173 loss_rnnt 7.563169 hw_loss 0.134692 lr 0.00029392 rank 2
2023-03-01 04:19:01,049 DEBUG TRAIN Batch 48/6300 loss 10.229008 loss_att 12.471061 loss_ctc 15.242983 loss_rnnt 8.946222 hw_loss 0.310959 lr 0.00029390 rank 3
2023-03-01 04:19:01,056 DEBUG TRAIN Batch 48/6300 loss 7.014390 loss_att 9.790337 loss_ctc 14.005198 loss_rnnt 5.458608 hw_loss 0.128410 lr 0.00029390 rank 7
2023-03-01 04:19:01,058 DEBUG TRAIN Batch 48/6300 loss 9.855950 loss_att 10.187569 loss_ctc 13.738321 loss_rnnt 9.096603 hw_loss 0.328828 lr 0.00029391 rank 0
2023-03-01 04:19:01,064 DEBUG TRAIN Batch 48/6300 loss 5.530207 loss_att 5.295530 loss_ctc 8.789683 loss_rnnt 5.017651 hw_loss 0.234176 lr 0.00029391 rank 6
2023-03-01 04:19:01,066 DEBUG TRAIN Batch 48/6300 loss 6.086030 loss_att 9.876574 loss_ctc 13.443811 loss_rnnt 4.211494 hw_loss 0.253855 lr 0.00029391 rank 5
2023-03-01 04:19:01,073 DEBUG TRAIN Batch 48/6300 loss 10.519988 loss_att 14.262844 loss_ctc 17.061922 loss_rnnt 8.846544 hw_loss 0.098651 lr 0.00029391 rank 4
2023-03-01 04:19:01,072 DEBUG TRAIN Batch 48/6300 loss 4.132320 loss_att 6.443988 loss_ctc 5.934915 loss_rnnt 3.363148 hw_loss 0.124674 lr 0.00029391 rank 1
2023-03-01 04:19:01,110 DEBUG TRAIN Batch 48/6300 loss 1.214019 loss_att 2.881329 loss_ctc 1.908742 loss_rnnt 0.632070 hw_loss 0.292232 lr 0.00029391 rank 2
2023-03-01 04:20:07,745 DEBUG TRAIN Batch 48/6400 loss 4.840658 loss_att 7.688408 loss_ctc 9.983809 loss_rnnt 3.484788 hw_loss 0.188562 lr 0.00029390 rank 0
2023-03-01 04:20:07,755 DEBUG TRAIN Batch 48/6400 loss 1.888254 loss_att 4.859883 loss_ctc 4.865951 loss_rnnt 0.798388 hw_loss 0.184714 lr 0.00029390 rank 1
2023-03-01 04:20:07,763 DEBUG TRAIN Batch 48/6400 loss 6.254959 loss_att 9.387071 loss_ctc 9.222975 loss_rnnt 5.059746 hw_loss 0.324479 lr 0.00029389 rank 3
2023-03-01 04:20:07,764 DEBUG TRAIN Batch 48/6400 loss 3.644485 loss_att 7.001199 loss_ctc 5.901468 loss_rnnt 2.487043 hw_loss 0.347190 lr 0.00029389 rank 2
2023-03-01 04:20:07,765 DEBUG TRAIN Batch 48/6400 loss 6.045966 loss_att 7.322371 loss_ctc 9.411357 loss_rnnt 5.248165 hw_loss 0.175877 lr 0.00029388 rank 7
2023-03-01 04:20:07,766 DEBUG TRAIN Batch 48/6400 loss 1.714653 loss_att 3.832836 loss_ctc 3.632580 loss_rnnt 0.875139 hw_loss 0.300288 lr 0.00029389 rank 5
2023-03-01 04:20:07,770 DEBUG TRAIN Batch 48/6400 loss 6.795956 loss_att 9.181244 loss_ctc 11.082051 loss_rnnt 5.631622 hw_loss 0.217120 lr 0.00029389 rank 4
2023-03-01 04:20:07,769 DEBUG TRAIN Batch 48/6400 loss 4.982731 loss_att 7.702524 loss_ctc 10.561224 loss_rnnt 3.636305 hw_loss 0.110003 lr 0.00029390 rank 6
2023-03-01 04:20:47,358 DEBUG TRAIN Batch 48/6500 loss 7.484728 loss_att 10.403619 loss_ctc 12.284652 loss_rnnt 6.108964 hw_loss 0.284992 lr 0.00029388 rank 4
2023-03-01 04:20:47,375 DEBUG TRAIN Batch 48/6500 loss 4.470856 loss_att 6.875136 loss_ctc 8.046639 loss_rnnt 3.430750 hw_loss 0.154647 lr 0.00029388 rank 1
2023-03-01 04:20:47,376 DEBUG TRAIN Batch 48/6500 loss 5.110188 loss_att 7.739428 loss_ctc 8.217767 loss_rnnt 4.123478 hw_loss 0.087224 lr 0.00029389 rank 0
2023-03-01 04:20:47,376 DEBUG TRAIN Batch 48/6500 loss 7.977007 loss_att 10.747477 loss_ctc 18.114897 loss_rnnt 6.040757 hw_loss 0.057070 lr 0.00029388 rank 5
2023-03-01 04:20:47,379 DEBUG TRAIN Batch 48/6500 loss 7.848321 loss_att 13.731420 loss_ctc 16.339012 loss_rnnt 5.443069 hw_loss 0.181012 lr 0.00029388 rank 6
2023-03-01 04:20:47,380 DEBUG TRAIN Batch 48/6500 loss 2.809984 loss_att 5.938507 loss_ctc 7.272301 loss_rnnt 1.500086 hw_loss 0.167284 lr 0.00029387 rank 7
2023-03-01 04:20:47,380 DEBUG TRAIN Batch 48/6500 loss 4.577984 loss_att 8.587563 loss_ctc 13.242750 loss_rnnt 2.567105 hw_loss 0.100614 lr 0.00029388 rank 3
2023-03-01 04:20:47,385 DEBUG TRAIN Batch 48/6500 loss 6.433461 loss_att 8.714724 loss_ctc 12.439390 loss_rnnt 5.090379 hw_loss 0.161323 lr 0.00029388 rank 2
2023-03-01 04:21:26,100 DEBUG TRAIN Batch 48/6600 loss 7.843356 loss_att 10.196934 loss_ctc 9.525900 loss_rnnt 7.014495 hw_loss 0.250888 lr 0.00029387 rank 1
2023-03-01 04:21:26,101 DEBUG TRAIN Batch 48/6600 loss 7.499218 loss_att 13.752727 loss_ctc 16.462088 loss_rnnt 5.012687 hw_loss 0.076461 lr 0.00029387 rank 3
2023-03-01 04:21:26,103 DEBUG TRAIN Batch 48/6600 loss 6.959177 loss_att 9.002826 loss_ctc 7.565313 loss_rnnt 6.336487 hw_loss 0.249644 lr 0.00029387 rank 6
2023-03-01 04:21:26,104 DEBUG TRAIN Batch 48/6600 loss 11.295991 loss_att 12.302480 loss_ctc 16.802542 loss_rnnt 10.337048 hw_loss 0.043949 lr 0.00029387 rank 2
2023-03-01 04:21:26,106 DEBUG TRAIN Batch 48/6600 loss 11.232917 loss_att 14.003682 loss_ctc 18.510471 loss_rnnt 9.539936 hw_loss 0.315912 lr 0.00029387 rank 0
2023-03-01 04:21:26,107 DEBUG TRAIN Batch 48/6600 loss 8.399384 loss_att 12.698564 loss_ctc 13.725235 loss_rnnt 6.779777 hw_loss 0.093110 lr 0.00029387 rank 4
2023-03-01 04:21:26,107 DEBUG TRAIN Batch 48/6600 loss 6.195547 loss_att 10.592796 loss_ctc 13.350522 loss_rnnt 4.259359 hw_loss 0.192640 lr 0.00029387 rank 5
2023-03-01 04:21:26,114 DEBUG TRAIN Batch 48/6600 loss 2.791229 loss_att 6.013061 loss_ctc 4.741521 loss_rnnt 1.720273 hw_loss 0.312283 lr 0.00029386 rank 7
2023-03-01 04:22:05,156 DEBUG TRAIN Batch 48/6700 loss 3.917362 loss_att 7.011866 loss_ctc 6.486205 loss_rnnt 2.811908 hw_loss 0.270077 lr 0.00029386 rank 2
2023-03-01 04:22:05,157 DEBUG TRAIN Batch 48/6700 loss 10.770747 loss_att 11.952088 loss_ctc 14.520592 loss_rnnt 9.903508 hw_loss 0.245609 lr 0.00029386 rank 1
2023-03-01 04:22:05,163 DEBUG TRAIN Batch 48/6700 loss 5.136539 loss_att 8.485961 loss_ctc 10.167262 loss_rnnt 3.678036 hw_loss 0.220977 lr 0.00029386 rank 5
2023-03-01 04:22:05,170 DEBUG TRAIN Batch 48/6700 loss 6.491181 loss_att 9.326401 loss_ctc 18.519306 loss_rnnt 4.162543 hw_loss 0.295958 lr 0.00029386 rank 0
2023-03-01 04:22:05,174 DEBUG TRAIN Batch 48/6700 loss 4.148412 loss_att 6.815034 loss_ctc 6.417372 loss_rnnt 3.182862 hw_loss 0.243182 lr 0.00029385 rank 7
2023-03-01 04:22:05,174 DEBUG TRAIN Batch 48/6700 loss 4.636312 loss_att 9.213313 loss_ctc 8.483933 loss_rnnt 3.086646 hw_loss 0.227344 lr 0.00029386 rank 4
2023-03-01 04:22:05,181 DEBUG TRAIN Batch 48/6700 loss 11.715342 loss_att 16.204697 loss_ctc 16.428799 loss_rnnt 10.121374 hw_loss 0.126815 lr 0.00029385 rank 3
2023-03-01 04:22:05,195 DEBUG TRAIN Batch 48/6700 loss 5.240236 loss_att 9.839906 loss_ctc 11.013971 loss_rnnt 3.490808 hw_loss 0.111867 lr 0.00029386 rank 6
2023-03-01 04:23:11,066 DEBUG TRAIN Batch 48/6800 loss 3.709510 loss_att 7.469510 loss_ctc 7.445234 loss_rnnt 2.356833 hw_loss 0.192339 lr 0.00029384 rank 2
2023-03-01 04:23:11,075 DEBUG TRAIN Batch 48/6800 loss 5.863814 loss_att 8.849686 loss_ctc 11.166107 loss_rnnt 4.439254 hw_loss 0.225775 lr 0.00029384 rank 4
2023-03-01 04:23:11,077 DEBUG TRAIN Batch 48/6800 loss 12.780333 loss_att 16.364954 loss_ctc 22.584305 loss_rnnt 10.693318 hw_loss 0.117924 lr 0.00029384 rank 3
2023-03-01 04:23:11,079 DEBUG TRAIN Batch 48/6800 loss 5.250179 loss_att 11.112354 loss_ctc 11.923180 loss_rnnt 3.067080 hw_loss 0.226745 lr 0.00029385 rank 6
2023-03-01 04:23:11,079 DEBUG TRAIN Batch 48/6800 loss 11.009973 loss_att 11.417753 loss_ctc 19.405449 loss_rnnt 9.620800 hw_loss 0.352913 lr 0.00029385 rank 1
2023-03-01 04:23:11,080 DEBUG TRAIN Batch 48/6800 loss 4.449134 loss_att 7.118376 loss_ctc 7.656497 loss_rnnt 3.319433 hw_loss 0.315382 lr 0.00029383 rank 7
2023-03-01 04:23:11,081 DEBUG TRAIN Batch 48/6800 loss 6.840953 loss_att 8.807514 loss_ctc 10.459161 loss_rnnt 5.794811 hw_loss 0.319502 lr 0.00029385 rank 0
2023-03-01 04:23:11,083 DEBUG TRAIN Batch 48/6800 loss 3.501263 loss_att 5.787904 loss_ctc 6.872789 loss_rnnt 2.428134 hw_loss 0.311743 lr 0.00029384 rank 5
2023-03-01 04:23:50,189 DEBUG TRAIN Batch 48/6900 loss 13.035470 loss_att 16.277225 loss_ctc 19.581562 loss_rnnt 11.378215 hw_loss 0.255173 lr 0.00029382 rank 7
2023-03-01 04:23:50,193 DEBUG TRAIN Batch 48/6900 loss 4.941011 loss_att 6.216506 loss_ctc 7.816026 loss_rnnt 4.142022 hw_loss 0.301041 lr 0.00029383 rank 0
2023-03-01 04:23:50,198 DEBUG TRAIN Batch 48/6900 loss 6.238623 loss_att 9.209094 loss_ctc 8.357147 loss_rnnt 5.169396 hw_loss 0.361244 lr 0.00029383 rank 2
2023-03-01 04:23:50,200 DEBUG TRAIN Batch 48/6900 loss 3.919463 loss_att 7.711624 loss_ctc 9.726031 loss_rnnt 2.251627 hw_loss 0.253489 lr 0.00029383 rank 5
2023-03-01 04:23:50,211 DEBUG TRAIN Batch 48/6900 loss 5.586363 loss_att 9.249569 loss_ctc 9.875355 loss_rnnt 4.164726 hw_loss 0.219619 lr 0.00029383 rank 1
2023-03-01 04:23:50,224 DEBUG TRAIN Batch 48/6900 loss 7.511389 loss_att 11.566255 loss_ctc 13.333755 loss_rnnt 5.808743 hw_loss 0.216294 lr 0.00029383 rank 3
2023-03-01 04:23:50,229 DEBUG TRAIN Batch 48/6900 loss 10.780054 loss_att 13.099315 loss_ctc 18.263243 loss_rnnt 9.217113 hw_loss 0.189997 lr 0.00029383 rank 6
2023-03-01 04:23:50,249 DEBUG TRAIN Batch 48/6900 loss 8.477627 loss_att 9.980808 loss_ctc 11.355619 loss_rnnt 7.748686 hw_loss 0.083572 lr 0.00029383 rank 4
2023-03-01 04:24:28,899 DEBUG TRAIN Batch 48/7000 loss 3.023660 loss_att 4.687964 loss_ctc 4.070888 loss_rnnt 2.504640 hw_loss 0.087242 lr 0.00029381 rank 3
2023-03-01 04:24:28,904 DEBUG TRAIN Batch 48/7000 loss 7.214985 loss_att 8.194443 loss_ctc 12.541377 loss_rnnt 6.133486 hw_loss 0.328915 lr 0.00029382 rank 4
2023-03-01 04:24:28,909 DEBUG TRAIN Batch 48/7000 loss 9.576249 loss_att 10.090224 loss_ctc 14.448874 loss_rnnt 8.673854 hw_loss 0.281094 lr 0.00029381 rank 7
2023-03-01 04:24:28,909 DEBUG TRAIN Batch 48/7000 loss 4.337450 loss_att 7.726401 loss_ctc 6.580913 loss_rnnt 3.229568 hw_loss 0.245555 lr 0.00029382 rank 0
2023-03-01 04:24:28,913 DEBUG TRAIN Batch 48/7000 loss 6.340668 loss_att 6.439925 loss_ctc 8.744913 loss_rnnt 5.831621 hw_loss 0.316182 lr 0.00029382 rank 6
2023-03-01 04:24:28,934 DEBUG TRAIN Batch 48/7000 loss 5.805413 loss_att 6.314989 loss_ctc 7.948783 loss_rnnt 5.262472 hw_loss 0.291081 lr 0.00029382 rank 5
2023-03-01 04:24:28,935 DEBUG TRAIN Batch 48/7000 loss 6.282312 loss_att 9.540848 loss_ctc 12.221506 loss_rnnt 4.795569 hw_loss 0.080894 lr 0.00029382 rank 1
2023-03-01 04:24:28,947 DEBUG TRAIN Batch 48/7000 loss 11.210755 loss_att 13.404280 loss_ctc 18.912466 loss_rnnt 9.633245 hw_loss 0.209831 lr 0.00029382 rank 2
2023-03-01 04:25:08,482 DEBUG TRAIN Batch 48/7100 loss 4.690177 loss_att 7.845745 loss_ctc 7.889822 loss_rnnt 3.556941 hw_loss 0.141570 lr 0.00029381 rank 2
2023-03-01 04:25:08,481 DEBUG TRAIN Batch 48/7100 loss 5.631728 loss_att 11.189777 loss_ctc 9.559006 loss_rnnt 3.889138 hw_loss 0.201267 lr 0.00029380 rank 3
2023-03-01 04:25:08,483 DEBUG TRAIN Batch 48/7100 loss 13.511837 loss_att 17.294762 loss_ctc 22.925955 loss_rnnt 11.444288 hw_loss 0.104528 lr 0.00029381 rank 1
2023-03-01 04:25:08,485 DEBUG TRAIN Batch 48/7100 loss 7.835776 loss_att 8.153672 loss_ctc 10.445189 loss_rnnt 7.281653 hw_loss 0.267417 lr 0.00029381 rank 6
2023-03-01 04:25:08,497 DEBUG TRAIN Batch 48/7100 loss 4.854922 loss_att 10.349442 loss_ctc 9.977596 loss_rnnt 2.922938 hw_loss 0.281355 lr 0.00029381 rank 0
2023-03-01 04:25:08,502 DEBUG TRAIN Batch 48/7100 loss 9.592452 loss_att 13.144380 loss_ctc 16.813393 loss_rnnt 7.803468 hw_loss 0.217138 lr 0.00029380 rank 7
2023-03-01 04:25:08,536 DEBUG TRAIN Batch 48/7100 loss 9.477399 loss_att 10.734768 loss_ctc 12.090419 loss_rnnt 8.764101 hw_loss 0.212665 lr 0.00029380 rank 4
2023-03-01 04:25:08,554 DEBUG TRAIN Batch 48/7100 loss 3.728700 loss_att 5.293046 loss_ctc 8.023570 loss_rnnt 2.724471 hw_loss 0.222582 lr 0.00029380 rank 5
2023-03-01 04:26:14,161 DEBUG TRAIN Batch 48/7200 loss 9.872673 loss_att 12.497412 loss_ctc 16.805969 loss_rnnt 8.291537 hw_loss 0.247030 lr 0.00029380 rank 0
2023-03-01 04:26:14,161 DEBUG TRAIN Batch 48/7200 loss 4.311864 loss_att 6.139003 loss_ctc 6.295991 loss_rnnt 3.625257 hw_loss 0.106178 lr 0.00029380 rank 6
2023-03-01 04:26:14,161 DEBUG TRAIN Batch 48/7200 loss 4.687771 loss_att 8.182130 loss_ctc 8.278187 loss_rnnt 3.400984 hw_loss 0.204739 lr 0.00029380 rank 1
2023-03-01 04:26:14,165 DEBUG TRAIN Batch 48/7200 loss 1.502594 loss_att 3.855047 loss_ctc 1.838145 loss_rnnt 0.788678 hw_loss 0.372536 lr 0.00029378 rank 7
2023-03-01 04:26:14,167 DEBUG TRAIN Batch 48/7200 loss 5.229264 loss_att 8.317049 loss_ctc 8.716093 loss_rnnt 4.145994 hw_loss 0.001503 lr 0.00029379 rank 2
2023-03-01 04:26:14,169 DEBUG TRAIN Batch 48/7200 loss 4.169394 loss_att 7.157289 loss_ctc 6.633054 loss_rnnt 3.150116 hw_loss 0.174769 lr 0.00029379 rank 4
2023-03-01 04:26:14,170 DEBUG TRAIN Batch 48/7200 loss 4.322530 loss_att 6.753049 loss_ctc 6.169924 loss_rnnt 3.471967 hw_loss 0.221513 lr 0.00029379 rank 3
2023-03-01 04:26:14,214 DEBUG TRAIN Batch 48/7200 loss 5.638593 loss_att 7.886980 loss_ctc 11.125046 loss_rnnt 4.378971 hw_loss 0.147034 lr 0.00029379 rank 5
2023-03-01 04:26:52,516 DEBUG TRAIN Batch 48/7300 loss 8.912582 loss_att 13.063580 loss_ctc 14.792668 loss_rnnt 7.112165 hw_loss 0.349135 lr 0.00029378 rank 4
2023-03-01 04:26:52,522 DEBUG TRAIN Batch 48/7300 loss 4.135048 loss_att 6.167940 loss_ctc 6.287130 loss_rnnt 3.333942 hw_loss 0.201719 lr 0.00029378 rank 6
2023-03-01 04:26:52,524 DEBUG TRAIN Batch 48/7300 loss 8.854816 loss_att 10.956436 loss_ctc 15.728719 loss_rnnt 7.431803 hw_loss 0.161566 lr 0.00029378 rank 2
2023-03-01 04:26:52,534 DEBUG TRAIN Batch 48/7300 loss 10.462493 loss_att 15.840048 loss_ctc 22.161242 loss_rnnt 7.742360 hw_loss 0.158979 lr 0.00029378 rank 0
2023-03-01 04:26:52,536 DEBUG TRAIN Batch 48/7300 loss 12.465815 loss_att 14.520060 loss_ctc 17.487373 loss_rnnt 11.229746 hw_loss 0.291895 lr 0.00029378 rank 5
2023-03-01 04:26:52,536 DEBUG TRAIN Batch 48/7300 loss 8.750718 loss_att 11.544008 loss_ctc 13.622660 loss_rnnt 7.451036 hw_loss 0.171433 lr 0.00029377 rank 7
2023-03-01 04:26:52,537 DEBUG TRAIN Batch 48/7300 loss 11.388495 loss_att 15.944526 loss_ctc 27.128700 loss_rnnt 8.246862 hw_loss 0.247000 lr 0.00029378 rank 3
2023-03-01 04:26:52,537 DEBUG TRAIN Batch 48/7300 loss 10.241868 loss_att 11.810021 loss_ctc 16.346220 loss_rnnt 9.066572 hw_loss 0.089534 lr 0.00029378 rank 1
2023-03-01 04:27:31,139 DEBUG TRAIN Batch 48/7400 loss 7.582298 loss_att 9.148615 loss_ctc 12.504813 loss_rnnt 6.418558 hw_loss 0.364015 lr 0.00029377 rank 2
2023-03-01 04:27:31,144 DEBUG TRAIN Batch 48/7400 loss 3.574093 loss_att 6.033803 loss_ctc 5.108140 loss_rnnt 2.750519 hw_loss 0.238298 lr 0.00029376 rank 3
2023-03-01 04:27:31,153 DEBUG TRAIN Batch 48/7400 loss 6.046754 loss_att 8.760478 loss_ctc 10.655624 loss_rnnt 4.746690 hw_loss 0.267756 lr 0.00029377 rank 1
2023-03-01 04:27:31,155 DEBUG TRAIN Batch 48/7400 loss 2.989532 loss_att 7.165279 loss_ctc 7.014825 loss_rnnt 1.491196 hw_loss 0.237150 lr 0.00029377 rank 5
2023-03-01 04:27:31,155 DEBUG TRAIN Batch 48/7400 loss 4.933141 loss_att 6.507478 loss_ctc 6.275674 loss_rnnt 4.304256 hw_loss 0.253150 lr 0.00029376 rank 7
2023-03-01 04:27:31,155 DEBUG TRAIN Batch 48/7400 loss 6.978986 loss_att 9.153427 loss_ctc 12.719851 loss_rnnt 5.714218 hw_loss 0.120807 lr 0.00029377 rank 0
2023-03-01 04:27:31,164 DEBUG TRAIN Batch 48/7400 loss 5.313859 loss_att 8.219615 loss_ctc 7.296993 loss_rnnt 4.338849 hw_loss 0.242703 lr 0.00029377 rank 6
2023-03-01 04:27:31,179 DEBUG TRAIN Batch 48/7400 loss 10.234008 loss_att 12.113011 loss_ctc 15.198921 loss_rnnt 9.105166 hw_loss 0.170725 lr 0.00029377 rank 4
2023-03-01 04:28:37,978 DEBUG TRAIN Batch 48/7500 loss 5.679442 loss_att 8.562361 loss_ctc 12.944899 loss_rnnt 4.056534 hw_loss 0.145493 lr 0.00029375 rank 5
2023-03-01 04:28:37,992 DEBUG TRAIN Batch 48/7500 loss 4.521696 loss_att 6.939711 loss_ctc 7.696167 loss_rnnt 3.389885 hw_loss 0.421773 lr 0.00029375 rank 7
2023-03-01 04:28:37,991 DEBUG TRAIN Batch 48/7500 loss 10.380349 loss_att 14.419637 loss_ctc 18.705799 loss_rnnt 8.320267 hw_loss 0.266559 lr 0.00029375 rank 2
2023-03-01 04:28:37,992 DEBUG TRAIN Batch 48/7500 loss 11.743481 loss_att 14.714855 loss_ctc 14.906105 loss_rnnt 10.623945 hw_loss 0.194206 lr 0.00029375 rank 3
2023-03-01 04:28:37,992 DEBUG TRAIN Batch 48/7500 loss 2.575659 loss_att 4.426539 loss_ctc 3.785684 loss_rnnt 1.896112 hw_loss 0.277565 lr 0.00029376 rank 0
2023-03-01 04:28:37,992 DEBUG TRAIN Batch 48/7500 loss 4.542166 loss_att 8.699937 loss_ctc 11.609716 loss_rnnt 2.685395 hw_loss 0.155394 lr 0.00029375 rank 4
2023-03-01 04:28:37,996 DEBUG TRAIN Batch 48/7500 loss 2.339820 loss_att 4.493029 loss_ctc 5.089298 loss_rnnt 1.451159 hw_loss 0.171416 lr 0.00029376 rank 6
2023-03-01 04:28:38,024 DEBUG TRAIN Batch 48/7500 loss 5.924416 loss_att 7.333802 loss_ctc 10.198334 loss_rnnt 4.889463 hw_loss 0.343537 lr 0.00029376 rank 1
2023-03-01 04:29:16,938 DEBUG TRAIN Batch 48/7600 loss 8.334023 loss_att 10.041978 loss_ctc 11.452229 loss_rnnt 7.424685 hw_loss 0.284973 lr 0.00029374 rank 6
2023-03-01 04:29:16,940 DEBUG TRAIN Batch 48/7600 loss 8.087305 loss_att 10.562970 loss_ctc 15.068235 loss_rnnt 6.642826 hw_loss 0.034793 lr 0.00029375 rank 1
2023-03-01 04:29:16,943 DEBUG TRAIN Batch 48/7600 loss 6.623103 loss_att 6.377468 loss_ctc 11.617760 loss_rnnt 5.891304 hw_loss 0.215574 lr 0.00029375 rank 0
2023-03-01 04:29:16,943 DEBUG TRAIN Batch 48/7600 loss 7.888363 loss_att 8.912659 loss_ctc 10.147474 loss_rnnt 7.226291 hw_loss 0.292498 lr 0.00029374 rank 2
2023-03-01 04:29:16,943 DEBUG TRAIN Batch 48/7600 loss 9.021171 loss_att 12.995783 loss_ctc 14.459236 loss_rnnt 7.323601 hw_loss 0.332946 lr 0.00029374 rank 5
2023-03-01 04:29:16,944 DEBUG TRAIN Batch 48/7600 loss 5.224432 loss_att 6.522816 loss_ctc 9.052656 loss_rnnt 4.280279 hw_loss 0.326334 lr 0.00029374 rank 4
2023-03-01 04:29:16,948 DEBUG TRAIN Batch 48/7600 loss 7.423284 loss_att 10.366779 loss_ctc 11.810656 loss_rnnt 6.036783 hw_loss 0.399036 lr 0.00029373 rank 7
2023-03-01 04:29:16,953 DEBUG TRAIN Batch 48/7600 loss 6.205040 loss_att 6.724589 loss_ctc 9.723100 loss_rnnt 5.474800 hw_loss 0.294855 lr 0.00029374 rank 3
2023-03-01 04:29:55,719 DEBUG TRAIN Batch 48/7700 loss 4.530358 loss_att 5.250885 loss_ctc 5.750823 loss_rnnt 4.091976 hw_loss 0.246652 lr 0.00029373 rank 2
2023-03-01 04:29:55,734 DEBUG TRAIN Batch 48/7700 loss 7.112047 loss_att 9.944688 loss_ctc 14.043686 loss_rnnt 5.484520 hw_loss 0.256465 lr 0.00029373 rank 0
2023-03-01 04:29:55,736 DEBUG TRAIN Batch 48/7700 loss 7.335625 loss_att 13.171262 loss_ctc 13.617971 loss_rnnt 5.238432 hw_loss 0.173285 lr 0.00029373 rank 6
2023-03-01 04:29:55,736 DEBUG TRAIN Batch 48/7700 loss 7.151434 loss_att 9.302155 loss_ctc 11.751281 loss_rnnt 5.991544 hw_loss 0.218311 lr 0.00029372 rank 7
2023-03-01 04:29:55,741 DEBUG TRAIN Batch 48/7700 loss 8.870408 loss_att 10.896945 loss_ctc 16.570847 loss_rnnt 7.314716 hw_loss 0.231862 lr 0.00029373 rank 3
2023-03-01 04:29:55,769 DEBUG TRAIN Batch 48/7700 loss 5.125965 loss_att 9.165324 loss_ctc 7.134687 loss_rnnt 3.908624 hw_loss 0.265574 lr 0.00029373 rank 1
2023-03-01 04:29:55,777 DEBUG TRAIN Batch 48/7700 loss 11.733298 loss_att 12.310258 loss_ctc 18.084532 loss_rnnt 10.613252 hw_loss 0.295919 lr 0.00029373 rank 4
2023-03-01 04:29:55,788 DEBUG TRAIN Batch 48/7700 loss 5.091741 loss_att 7.996006 loss_ctc 14.127340 loss_rnnt 3.255720 hw_loss 0.094540 lr 0.00029373 rank 5
2023-03-01 04:30:36,527 DEBUG TRAIN Batch 48/7800 loss 9.776004 loss_att 12.658186 loss_ctc 17.558111 loss_rnnt 8.075824 hw_loss 0.161493 lr 0.00029372 rank 0
2023-03-01 04:30:36,537 DEBUG TRAIN Batch 48/7800 loss 4.875467 loss_att 8.793252 loss_ctc 8.012645 loss_rnnt 3.500854 hw_loss 0.323936 lr 0.00029372 rank 5
2023-03-01 04:30:36,539 DEBUG TRAIN Batch 48/7800 loss 9.643997 loss_att 12.003482 loss_ctc 14.134250 loss_rnnt 8.509207 hw_loss 0.120363 lr 0.00029372 rank 6
2023-03-01 04:30:36,540 DEBUG TRAIN Batch 48/7800 loss 4.358384 loss_att 7.437620 loss_ctc 6.858166 loss_rnnt 3.310583 hw_loss 0.184967 lr 0.00029372 rank 1
2023-03-01 04:30:36,543 DEBUG TRAIN Batch 48/7800 loss 7.425467 loss_att 11.022469 loss_ctc 14.194853 loss_rnnt 5.682633 hw_loss 0.226590 lr 0.00029372 rank 4
2023-03-01 04:30:36,544 DEBUG TRAIN Batch 48/7800 loss 6.398434 loss_att 10.282583 loss_ctc 14.631052 loss_rnnt 4.431654 hw_loss 0.173002 lr 0.00029371 rank 7
2023-03-01 04:30:36,550 DEBUG TRAIN Batch 48/7800 loss 2.571043 loss_att 4.171982 loss_ctc 4.829780 loss_rnnt 1.849828 hw_loss 0.187242 lr 0.00029372 rank 2
2023-03-01 04:30:36,553 DEBUG TRAIN Batch 48/7800 loss 1.978378 loss_att 3.740801 loss_ctc 2.182137 loss_rnnt 1.361165 hw_loss 0.445426 lr 0.00029371 rank 3
2023-03-01 04:31:41,688 DEBUG TRAIN Batch 48/7900 loss 10.924154 loss_att 13.966270 loss_ctc 15.314350 loss_rnnt 9.550595 hw_loss 0.337081 lr 0.00029370 rank 2
2023-03-01 04:31:41,703 DEBUG TRAIN Batch 48/7900 loss 6.294814 loss_att 9.083917 loss_ctc 10.208913 loss_rnnt 5.053825 hw_loss 0.302414 lr 0.00029371 rank 6
2023-03-01 04:31:41,703 DEBUG TRAIN Batch 48/7900 loss 11.589808 loss_att 15.398825 loss_ctc 16.353924 loss_rnnt 10.099867 hw_loss 0.174228 lr 0.00029371 rank 1
2023-03-01 04:31:41,704 DEBUG TRAIN Batch 48/7900 loss 9.071098 loss_att 12.080628 loss_ctc 15.797144 loss_rnnt 7.487245 hw_loss 0.159641 lr 0.00029371 rank 0
2023-03-01 04:31:41,705 DEBUG TRAIN Batch 48/7900 loss 8.338668 loss_att 10.970266 loss_ctc 13.027840 loss_rnnt 7.056799 hw_loss 0.244361 lr 0.00029369 rank 7
2023-03-01 04:31:41,706 DEBUG TRAIN Batch 48/7900 loss 5.699176 loss_att 9.506444 loss_ctc 7.718511 loss_rnnt 4.509319 hw_loss 0.298422 lr 0.00029370 rank 4
2023-03-01 04:31:41,711 DEBUG TRAIN Batch 48/7900 loss 5.151676 loss_att 8.277889 loss_ctc 7.856790 loss_rnnt 4.071589 hw_loss 0.176556 lr 0.00029370 rank 5
2023-03-01 04:31:41,713 DEBUG TRAIN Batch 48/7900 loss 4.412004 loss_att 8.472949 loss_ctc 7.524899 loss_rnnt 2.995096 hw_loss 0.355624 lr 0.00029370 rank 3
2023-03-01 04:32:21,068 DEBUG TRAIN Batch 48/8000 loss 5.241621 loss_att 10.195868 loss_ctc 10.079918 loss_rnnt 3.552302 hw_loss 0.100057 lr 0.00029368 rank 7
2023-03-01 04:32:21,069 DEBUG TRAIN Batch 48/8000 loss 3.291850 loss_att 5.391123 loss_ctc 3.679569 loss_rnnt 2.752460 hw_loss 0.127200 lr 0.00029369 rank 5
2023-03-01 04:32:21,071 DEBUG TRAIN Batch 48/8000 loss 11.326566 loss_att 12.417097 loss_ctc 15.170520 loss_rnnt 10.492621 hw_loss 0.193707 lr 0.00029369 rank 3
2023-03-01 04:32:21,073 DEBUG TRAIN Batch 48/8000 loss 10.118689 loss_att 11.186520 loss_ctc 16.059250 loss_rnnt 9.011782 hw_loss 0.189871 lr 0.00029369 rank 1
2023-03-01 04:32:21,074 DEBUG TRAIN Batch 48/8000 loss 11.357080 loss_att 16.413853 loss_ctc 16.991993 loss_rnnt 9.444450 hw_loss 0.281163 lr 0.00029369 rank 6
2023-03-01 04:32:21,075 DEBUG TRAIN Batch 48/8000 loss 5.737825 loss_att 7.522622 loss_ctc 10.150591 loss_rnnt 4.756362 hw_loss 0.067752 lr 0.00029370 rank 0
2023-03-01 04:32:21,076 DEBUG TRAIN Batch 48/8000 loss 8.176282 loss_att 12.264243 loss_ctc 11.601546 loss_rnnt 6.839653 hw_loss 0.116874 lr 0.00029369 rank 2
2023-03-01 04:32:21,078 DEBUG TRAIN Batch 48/8000 loss 3.911829 loss_att 6.517004 loss_ctc 4.803619 loss_rnnt 3.176300 hw_loss 0.179227 lr 0.00029369 rank 4
2023-03-01 04:33:00,822 DEBUG TRAIN Batch 48/8100 loss 6.645188 loss_att 9.913933 loss_ctc 8.393352 loss_rnnt 5.672319 hw_loss 0.161308 lr 0.00029368 rank 4
2023-03-01 04:33:00,822 DEBUG TRAIN Batch 48/8100 loss 7.171142 loss_att 10.126114 loss_ctc 11.297892 loss_rnnt 5.956679 hw_loss 0.137315 lr 0.00029368 rank 2
2023-03-01 04:33:00,832 DEBUG TRAIN Batch 48/8100 loss 5.661825 loss_att 7.371760 loss_ctc 7.118171 loss_rnnt 5.063725 hw_loss 0.116125 lr 0.00029368 rank 6
2023-03-01 04:33:00,838 DEBUG TRAIN Batch 48/8100 loss 12.617059 loss_att 15.901876 loss_ctc 20.215004 loss_rnnt 10.819789 hw_loss 0.238588 lr 0.00029368 rank 0
2023-03-01 04:33:00,839 DEBUG TRAIN Batch 48/8100 loss 6.968524 loss_att 10.344783 loss_ctc 9.292220 loss_rnnt 5.879486 hw_loss 0.194924 lr 0.00029367 rank 7
2023-03-01 04:33:00,839 DEBUG TRAIN Batch 48/8100 loss 4.678041 loss_att 7.345394 loss_ctc 7.736060 loss_rnnt 3.689728 hw_loss 0.088326 lr 0.00029368 rank 5
2023-03-01 04:33:00,843 DEBUG TRAIN Batch 48/8100 loss 6.559450 loss_att 8.825916 loss_ctc 13.795601 loss_rnnt 4.987031 hw_loss 0.289323 lr 0.00029368 rank 1
2023-03-01 04:33:00,890 DEBUG TRAIN Batch 48/8100 loss 3.508263 loss_att 5.819052 loss_ctc 6.823510 loss_rnnt 2.554182 hw_loss 0.093545 lr 0.00029367 rank 3
2023-03-01 04:33:41,505 DEBUG TRAIN Batch 48/8200 loss 3.396375 loss_att 6.343942 loss_ctc 8.736220 loss_rnnt 1.995268 hw_loss 0.186775 lr 0.00029367 rank 2
2023-03-01 04:33:41,514 DEBUG TRAIN Batch 48/8200 loss 9.909774 loss_att 13.936858 loss_ctc 19.759418 loss_rnnt 7.741106 hw_loss 0.093686 lr 0.00029367 rank 5
2023-03-01 04:33:41,526 DEBUG TRAIN Batch 48/8200 loss 9.161819 loss_att 10.610200 loss_ctc 14.723849 loss_rnnt 7.979840 hw_loss 0.282556 lr 0.00029366 rank 7
2023-03-01 04:33:41,527 DEBUG TRAIN Batch 48/8200 loss 7.940104 loss_att 11.633451 loss_ctc 12.722716 loss_rnnt 6.491449 hw_loss 0.135568 lr 0.00029367 rank 1
2023-03-01 04:33:41,529 DEBUG TRAIN Batch 48/8200 loss 6.108901 loss_att 7.844288 loss_ctc 10.447884 loss_rnnt 5.088668 hw_loss 0.177422 lr 0.00029366 rank 3
2023-03-01 04:33:41,532 DEBUG TRAIN Batch 48/8200 loss 3.775757 loss_att 5.029822 loss_ctc 5.622082 loss_rnnt 3.158731 hw_loss 0.225068 lr 0.00029367 rank 0
2023-03-01 04:33:41,532 DEBUG TRAIN Batch 48/8200 loss 16.166136 loss_att 16.498196 loss_ctc 22.067152 loss_rnnt 15.230568 hw_loss 0.154412 lr 0.00029367 rank 6
2023-03-01 04:33:41,538 DEBUG TRAIN Batch 48/8200 loss 2.761850 loss_att 5.045154 loss_ctc 6.239605 loss_rnnt 1.712212 hw_loss 0.242394 lr 0.00029367 rank 4
2023-03-01 04:34:19,887 DEBUG TRAIN Batch 48/8300 loss 4.892422 loss_att 7.380749 loss_ctc 9.308201 loss_rnnt 3.693855 hw_loss 0.210244 lr 0.00029366 rank 6
2023-03-01 04:34:19,893 DEBUG TRAIN Batch 48/8300 loss 2.066728 loss_att 5.270627 loss_ctc 6.340194 loss_rnnt 0.705776 hw_loss 0.281954 lr 0.00029365 rank 5
2023-03-01 04:34:19,895 DEBUG TRAIN Batch 48/8300 loss 4.810255 loss_att 5.596664 loss_ctc 7.006472 loss_rnnt 4.177155 hw_loss 0.343104 lr 0.00029364 rank 7
2023-03-01 04:34:19,907 DEBUG TRAIN Batch 48/8300 loss 2.629980 loss_att 4.386834 loss_ctc 2.681064 loss_rnnt 2.084874 hw_loss 0.350482 lr 0.00029366 rank 0
2023-03-01 04:34:19,907 DEBUG TRAIN Batch 48/8300 loss 4.258267 loss_att 9.365736 loss_ctc 10.477551 loss_rnnt 2.294673 hw_loss 0.211617 lr 0.00029365 rank 2
2023-03-01 04:34:19,912 DEBUG TRAIN Batch 48/8300 loss 3.202734 loss_att 5.277332 loss_ctc 3.999596 loss_rnnt 2.573539 hw_loss 0.202551 lr 0.00029365 rank 4
2023-03-01 04:34:19,913 DEBUG TRAIN Batch 48/8300 loss 8.769834 loss_att 12.208795 loss_ctc 12.398073 loss_rnnt 7.451224 hw_loss 0.275723 lr 0.00029365 rank 3
2023-03-01 04:34:19,917 DEBUG TRAIN Batch 48/8300 loss 3.834280 loss_att 7.559213 loss_ctc 5.968583 loss_rnnt 2.733232 hw_loss 0.134039 lr 0.00029366 rank 1
2023-03-01 04:34:52,362 DEBUG CV Batch 48/0 loss 1.007150 loss_att 1.090767 loss_ctc 1.927282 loss_rnnt 0.667563 hw_loss 0.375335 history loss 0.969848 rank 6
2023-03-01 04:34:52,363 DEBUG CV Batch 48/0 loss 1.007150 loss_att 1.090767 loss_ctc 1.927282 loss_rnnt 0.667563 hw_loss 0.375335 history loss 0.969848 rank 3
2023-03-01 04:34:52,368 DEBUG CV Batch 48/0 loss 1.007150 loss_att 1.090767 loss_ctc 1.927282 loss_rnnt 0.667563 hw_loss 0.375335 history loss 0.969848 rank 4
2023-03-01 04:34:52,369 DEBUG CV Batch 48/0 loss 1.007150 loss_att 1.090767 loss_ctc 1.927282 loss_rnnt 0.667563 hw_loss 0.375335 history loss 0.969848 rank 5
2023-03-01 04:34:52,374 DEBUG CV Batch 48/0 loss 1.007150 loss_att 1.090767 loss_ctc 1.927282 loss_rnnt 0.667563 hw_loss 0.375335 history loss 0.969848 rank 0
2023-03-01 04:34:52,377 DEBUG CV Batch 48/0 loss 1.007150 loss_att 1.090767 loss_ctc 1.927282 loss_rnnt 0.667563 hw_loss 0.375335 history loss 0.969848 rank 2
2023-03-01 04:34:52,378 DEBUG CV Batch 48/0 loss 1.007150 loss_att 1.090767 loss_ctc 1.927282 loss_rnnt 0.667563 hw_loss 0.375335 history loss 0.969848 rank 7
2023-03-01 04:34:52,398 DEBUG CV Batch 48/0 loss 1.007150 loss_att 1.090767 loss_ctc 1.927282 loss_rnnt 0.667563 hw_loss 0.375335 history loss 0.969848 rank 1
2023-03-01 04:35:03,805 DEBUG CV Batch 48/100 loss 3.635332 loss_att 4.472508 loss_ctc 9.525845 loss_rnnt 2.548795 hw_loss 0.250686 history loss 2.908061 rank 4
2023-03-01 04:35:03,811 DEBUG CV Batch 48/100 loss 3.635332 loss_att 4.472508 loss_ctc 9.525845 loss_rnnt 2.548795 hw_loss 0.250686 history loss 2.908061 rank 1
2023-03-01 04:35:03,865 DEBUG CV Batch 48/100 loss 3.635332 loss_att 4.472508 loss_ctc 9.525845 loss_rnnt 2.548795 hw_loss 0.250686 history loss 2.908061 rank 3
2023-03-01 04:35:03,942 DEBUG CV Batch 48/100 loss 3.635332 loss_att 4.472508 loss_ctc 9.525845 loss_rnnt 2.548795 hw_loss 0.250686 history loss 2.908061 rank 7
2023-03-01 04:35:03,948 DEBUG CV Batch 48/100 loss 3.635332 loss_att 4.472508 loss_ctc 9.525845 loss_rnnt 2.548795 hw_loss 0.250686 history loss 2.908061 rank 2
2023-03-01 04:35:03,967 DEBUG CV Batch 48/100 loss 3.635332 loss_att 4.472508 loss_ctc 9.525845 loss_rnnt 2.548795 hw_loss 0.250686 history loss 2.908061 rank 5
2023-03-01 04:35:04,140 DEBUG CV Batch 48/100 loss 3.635332 loss_att 4.472508 loss_ctc 9.525845 loss_rnnt 2.548795 hw_loss 0.250686 history loss 2.908061 rank 0
2023-03-01 04:35:04,520 DEBUG CV Batch 48/100 loss 3.635332 loss_att 4.472508 loss_ctc 9.525845 loss_rnnt 2.548795 hw_loss 0.250686 history loss 2.908061 rank 6
2023-03-01 04:35:17,290 DEBUG CV Batch 48/200 loss 7.480317 loss_att 11.233117 loss_ctc 10.012457 loss_rnnt 6.345209 hw_loss 0.087991 history loss 3.517321 rank 4
2023-03-01 04:35:17,299 DEBUG CV Batch 48/200 loss 7.480317 loss_att 11.233117 loss_ctc 10.012457 loss_rnnt 6.345209 hw_loss 0.087991 history loss 3.517321 rank 1
2023-03-01 04:35:17,466 DEBUG CV Batch 48/200 loss 7.480317 loss_att 11.233117 loss_ctc 10.012457 loss_rnnt 6.345209 hw_loss 0.087991 history loss 3.517321 rank 2
2023-03-01 04:35:17,636 DEBUG CV Batch 48/200 loss 7.480317 loss_att 11.233117 loss_ctc 10.012457 loss_rnnt 6.345209 hw_loss 0.087991 history loss 3.517321 rank 3
2023-03-01 04:35:17,656 DEBUG CV Batch 48/200 loss 7.480317 loss_att 11.233117 loss_ctc 10.012457 loss_rnnt 6.345209 hw_loss 0.087991 history loss 3.517321 rank 7
2023-03-01 04:35:17,741 DEBUG CV Batch 48/200 loss 7.480317 loss_att 11.233117 loss_ctc 10.012457 loss_rnnt 6.345209 hw_loss 0.087991 history loss 3.517321 rank 5
2023-03-01 04:35:17,982 DEBUG CV Batch 48/200 loss 7.480317 loss_att 11.233117 loss_ctc 10.012457 loss_rnnt 6.345209 hw_loss 0.087991 history loss 3.517321 rank 0
2023-03-01 04:35:18,432 DEBUG CV Batch 48/200 loss 7.480317 loss_att 11.233117 loss_ctc 10.012457 loss_rnnt 6.345209 hw_loss 0.087991 history loss 3.517321 rank 6
2023-03-01 04:35:29,467 DEBUG CV Batch 48/300 loss 4.069237 loss_att 4.271842 loss_ctc 7.573978 loss_rnnt 3.352347 hw_loss 0.392005 history loss 3.654822 rank 4
2023-03-01 04:35:29,572 DEBUG CV Batch 48/300 loss 4.069237 loss_att 4.271842 loss_ctc 7.573978 loss_rnnt 3.352347 hw_loss 0.392005 history loss 3.654822 rank 1
2023-03-01 04:35:29,972 DEBUG CV Batch 48/300 loss 4.069237 loss_att 4.271842 loss_ctc 7.573978 loss_rnnt 3.352347 hw_loss 0.392005 history loss 3.654822 rank 2
2023-03-01 04:35:30,107 DEBUG CV Batch 48/300 loss 4.069237 loss_att 4.271842 loss_ctc 7.573978 loss_rnnt 3.352347 hw_loss 0.392005 history loss 3.654822 rank 5
2023-03-01 04:35:30,199 DEBUG CV Batch 48/300 loss 4.069237 loss_att 4.271842 loss_ctc 7.573978 loss_rnnt 3.352347 hw_loss 0.392005 history loss 3.654822 rank 7
2023-03-01 04:35:30,233 DEBUG CV Batch 48/300 loss 4.069237 loss_att 4.271842 loss_ctc 7.573978 loss_rnnt 3.352347 hw_loss 0.392005 history loss 3.654822 rank 3
2023-03-01 04:35:30,728 DEBUG CV Batch 48/300 loss 4.069237 loss_att 4.271842 loss_ctc 7.573978 loss_rnnt 3.352347 hw_loss 0.392005 history loss 3.654822 rank 0
2023-03-01 04:35:31,000 DEBUG CV Batch 48/300 loss 4.069237 loss_att 4.271842 loss_ctc 7.573978 loss_rnnt 3.352347 hw_loss 0.392005 history loss 3.654822 rank 6
2023-03-01 04:35:41,811 DEBUG CV Batch 48/400 loss 12.787457 loss_att 63.884716 loss_ctc 10.154478 loss_rnnt 2.918883 hw_loss 0.000349 history loss 4.462098 rank 4
2023-03-01 04:35:41,858 DEBUG CV Batch 48/400 loss 12.787457 loss_att 63.884716 loss_ctc 10.154478 loss_rnnt 2.918883 hw_loss 0.000349 history loss 4.462098 rank 1
2023-03-01 04:35:42,332 DEBUG CV Batch 48/400 loss 12.787457 loss_att 63.884716 loss_ctc 10.154478 loss_rnnt 2.918883 hw_loss 0.000349 history loss 4.462098 rank 2
2023-03-01 04:35:42,630 DEBUG CV Batch 48/400 loss 12.787457 loss_att 63.884716 loss_ctc 10.154478 loss_rnnt 2.918883 hw_loss 0.000349 history loss 4.462098 rank 7
2023-03-01 04:35:42,631 DEBUG CV Batch 48/400 loss 12.787457 loss_att 63.884716 loss_ctc 10.154478 loss_rnnt 2.918883 hw_loss 0.000349 history loss 4.462098 rank 5
2023-03-01 04:35:42,726 DEBUG CV Batch 48/400 loss 12.787457 loss_att 63.884716 loss_ctc 10.154478 loss_rnnt 2.918883 hw_loss 0.000349 history loss 4.462098 rank 3
2023-03-01 04:35:43,327 DEBUG CV Batch 48/400 loss 12.787457 loss_att 63.884716 loss_ctc 10.154478 loss_rnnt 2.918883 hw_loss 0.000349 history loss 4.462098 rank 0
2023-03-01 04:35:43,373 DEBUG CV Batch 48/400 loss 12.787457 loss_att 63.884716 loss_ctc 10.154478 loss_rnnt 2.918883 hw_loss 0.000349 history loss 4.462098 rank 6
2023-03-01 04:35:52,275 DEBUG CV Batch 48/500 loss 3.954480 loss_att 4.147716 loss_ctc 5.032341 loss_rnnt 3.640003 hw_loss 0.247715 history loss 5.098215 rank 4
2023-03-01 04:35:52,392 DEBUG CV Batch 48/500 loss 3.954480 loss_att 4.147716 loss_ctc 5.032341 loss_rnnt 3.640003 hw_loss 0.247715 history loss 5.098215 rank 1
2023-03-01 04:35:53,584 DEBUG CV Batch 48/500 loss 3.954480 loss_att 4.147716 loss_ctc 5.032341 loss_rnnt 3.640003 hw_loss 0.247715 history loss 5.098215 rank 7
2023-03-01 04:35:53,746 DEBUG CV Batch 48/500 loss 3.954480 loss_att 4.147716 loss_ctc 5.032341 loss_rnnt 3.640003 hw_loss 0.247715 history loss 5.098215 rank 5
2023-03-01 04:35:53,823 DEBUG CV Batch 48/500 loss 3.954480 loss_att 4.147716 loss_ctc 5.032341 loss_rnnt 3.640003 hw_loss 0.247715 history loss 5.098215 rank 2
2023-03-01 04:35:53,934 DEBUG CV Batch 48/500 loss 3.954480 loss_att 4.147716 loss_ctc 5.032341 loss_rnnt 3.640003 hw_loss 0.247715 history loss 5.098215 rank 3
2023-03-01 04:35:54,355 DEBUG CV Batch 48/500 loss 3.954480 loss_att 4.147716 loss_ctc 5.032341 loss_rnnt 3.640003 hw_loss 0.247715 history loss 5.098215 rank 6
2023-03-01 04:35:54,440 DEBUG CV Batch 48/500 loss 3.954480 loss_att 4.147716 loss_ctc 5.032341 loss_rnnt 3.640003 hw_loss 0.247715 history loss 5.098215 rank 0
2023-03-01 04:36:04,452 DEBUG CV Batch 48/600 loss 7.929521 loss_att 6.873281 loss_ctc 10.386027 loss_rnnt 7.629502 hw_loss 0.344499 history loss 5.912292 rank 4
2023-03-01 04:36:04,533 DEBUG CV Batch 48/600 loss 7.929521 loss_att 6.873281 loss_ctc 10.386027 loss_rnnt 7.629502 hw_loss 0.344499 history loss 5.912292 rank 1
2023-03-01 04:36:06,102 DEBUG CV Batch 48/600 loss 7.929521 loss_att 6.873281 loss_ctc 10.386027 loss_rnnt 7.629502 hw_loss 0.344499 history loss 5.912292 rank 7
2023-03-01 04:36:06,407 DEBUG CV Batch 48/600 loss 7.929521 loss_att 6.873281 loss_ctc 10.386027 loss_rnnt 7.629502 hw_loss 0.344499 history loss 5.912292 rank 3
2023-03-01 04:36:06,433 DEBUG CV Batch 48/600 loss 7.929521 loss_att 6.873281 loss_ctc 10.386027 loss_rnnt 7.629502 hw_loss 0.344499 history loss 5.912292 rank 5
2023-03-01 04:36:06,506 DEBUG CV Batch 48/600 loss 7.929521 loss_att 6.873281 loss_ctc 10.386027 loss_rnnt 7.629502 hw_loss 0.344499 history loss 5.912292 rank 2
2023-03-01 04:36:07,004 DEBUG CV Batch 48/600 loss 7.929521 loss_att 6.873281 loss_ctc 10.386027 loss_rnnt 7.629502 hw_loss 0.344499 history loss 5.912292 rank 0
2023-03-01 04:36:07,210 DEBUG CV Batch 48/600 loss 7.929521 loss_att 6.873281 loss_ctc 10.386027 loss_rnnt 7.629502 hw_loss 0.344499 history loss 5.912292 rank 6
2023-03-01 04:36:15,905 DEBUG CV Batch 48/700 loss 15.345109 loss_att 35.409039 loss_ctc 14.659618 loss_rnnt 11.314063 hw_loss 0.205611 history loss 6.436563 rank 1
2023-03-01 04:36:15,934 DEBUG CV Batch 48/700 loss 15.345109 loss_att 35.409039 loss_ctc 14.659618 loss_rnnt 11.314063 hw_loss 0.205611 history loss 6.436563 rank 4
2023-03-01 04:36:17,809 DEBUG CV Batch 48/700 loss 15.345109 loss_att 35.409039 loss_ctc 14.659618 loss_rnnt 11.314063 hw_loss 0.205611 history loss 6.436563 rank 7
2023-03-01 04:36:18,149 DEBUG CV Batch 48/700 loss 15.345109 loss_att 35.409039 loss_ctc 14.659618 loss_rnnt 11.314063 hw_loss 0.205611 history loss 6.436563 rank 3
2023-03-01 04:36:18,154 DEBUG CV Batch 48/700 loss 15.345109 loss_att 35.409039 loss_ctc 14.659618 loss_rnnt 11.314063 hw_loss 0.205611 history loss 6.436563 rank 2
2023-03-01 04:36:18,527 DEBUG CV Batch 48/700 loss 15.345109 loss_att 35.409039 loss_ctc 14.659618 loss_rnnt 11.314063 hw_loss 0.205611 history loss 6.436563 rank 5
2023-03-01 04:36:18,811 DEBUG CV Batch 48/700 loss 15.345109 loss_att 35.409039 loss_ctc 14.659618 loss_rnnt 11.314063 hw_loss 0.205611 history loss 6.436563 rank 0
2023-03-01 04:36:18,923 DEBUG CV Batch 48/700 loss 15.345109 loss_att 35.409039 loss_ctc 14.659618 loss_rnnt 11.314063 hw_loss 0.205611 history loss 6.436563 rank 6
2023-03-01 04:36:26,855 DEBUG CV Batch 48/800 loss 6.487818 loss_att 7.004476 loss_ctc 13.659931 loss_rnnt 5.256948 hw_loss 0.321104 history loss 5.966678 rank 1
2023-03-01 04:36:27,535 DEBUG CV Batch 48/800 loss 6.487818 loss_att 7.004476 loss_ctc 13.659931 loss_rnnt 5.256948 hw_loss 0.321104 history loss 5.966678 rank 4
2023-03-01 04:36:29,524 DEBUG CV Batch 48/800 loss 6.487818 loss_att 7.004476 loss_ctc 13.659931 loss_rnnt 5.256948 hw_loss 0.321104 history loss 5.966678 rank 7
2023-03-01 04:36:29,833 DEBUG CV Batch 48/800 loss 6.487818 loss_att 7.004476 loss_ctc 13.659931 loss_rnnt 5.256948 hw_loss 0.321104 history loss 5.966678 rank 2
2023-03-01 04:36:30,200 DEBUG CV Batch 48/800 loss 6.487818 loss_att 7.004476 loss_ctc 13.659931 loss_rnnt 5.256948 hw_loss 0.321104 history loss 5.966678 rank 3
2023-03-01 04:36:30,399 DEBUG CV Batch 48/800 loss 6.487818 loss_att 7.004476 loss_ctc 13.659931 loss_rnnt 5.256948 hw_loss 0.321104 history loss 5.966678 rank 6
2023-03-01 04:36:30,565 DEBUG CV Batch 48/800 loss 6.487818 loss_att 7.004476 loss_ctc 13.659931 loss_rnnt 5.256948 hw_loss 0.321104 history loss 5.966678 rank 5
2023-03-01 04:36:30,602 DEBUG CV Batch 48/800 loss 6.487818 loss_att 7.004476 loss_ctc 13.659931 loss_rnnt 5.256948 hw_loss 0.321104 history loss 5.966678 rank 0
2023-03-01 04:36:40,118 DEBUG CV Batch 48/900 loss 8.892136 loss_att 11.904415 loss_ctc 17.549885 loss_rnnt 7.104229 hw_loss 0.058281 history loss 5.808110 rank 1
2023-03-01 04:36:40,919 DEBUG CV Batch 48/900 loss 8.892136 loss_att 11.904415 loss_ctc 17.549885 loss_rnnt 7.104229 hw_loss 0.058281 history loss 5.808110 rank 4
2023-03-01 04:36:43,083 DEBUG CV Batch 48/900 loss 8.892136 loss_att 11.904415 loss_ctc 17.549885 loss_rnnt 7.104229 hw_loss 0.058281 history loss 5.808110 rank 7
2023-03-01 04:36:43,416 DEBUG CV Batch 48/900 loss 8.892136 loss_att 11.904415 loss_ctc 17.549885 loss_rnnt 7.104229 hw_loss 0.058281 history loss 5.808110 rank 2
2023-03-01 04:36:43,880 DEBUG CV Batch 48/900 loss 8.892136 loss_att 11.904415 loss_ctc 17.549885 loss_rnnt 7.104229 hw_loss 0.058281 history loss 5.808110 rank 3
2023-03-01 04:36:44,370 DEBUG CV Batch 48/900 loss 8.892136 loss_att 11.904415 loss_ctc 17.549885 loss_rnnt 7.104229 hw_loss 0.058281 history loss 5.808110 rank 0
2023-03-01 04:36:44,430 DEBUG CV Batch 48/900 loss 8.892136 loss_att 11.904415 loss_ctc 17.549885 loss_rnnt 7.104229 hw_loss 0.058281 history loss 5.808110 rank 6
2023-03-01 04:36:44,667 DEBUG CV Batch 48/900 loss 8.892136 loss_att 11.904415 loss_ctc 17.549885 loss_rnnt 7.104229 hw_loss 0.058281 history loss 5.808110 rank 5
2023-03-01 04:36:52,422 DEBUG CV Batch 48/1000 loss 3.178877 loss_att 3.263822 loss_ctc 3.331342 loss_rnnt 2.949067 hw_loss 0.360924 history loss 5.615824 rank 1
2023-03-01 04:36:53,369 DEBUG CV Batch 48/1000 loss 3.178877 loss_att 3.263822 loss_ctc 3.331342 loss_rnnt 2.949067 hw_loss 0.360924 history loss 5.615824 rank 4
2023-03-01 04:36:55,670 DEBUG CV Batch 48/1000 loss 3.178877 loss_att 3.263822 loss_ctc 3.331342 loss_rnnt 2.949067 hw_loss 0.360924 history loss 5.615824 rank 7
2023-03-01 04:36:56,226 DEBUG CV Batch 48/1000 loss 3.178877 loss_att 3.263822 loss_ctc 3.331342 loss_rnnt 2.949067 hw_loss 0.360924 history loss 5.615824 rank 2
2023-03-01 04:36:56,697 DEBUG CV Batch 48/1000 loss 3.178877 loss_att 3.263822 loss_ctc 3.331342 loss_rnnt 2.949067 hw_loss 0.360924 history loss 5.615824 rank 3
2023-03-01 04:36:57,080 DEBUG CV Batch 48/1000 loss 3.178877 loss_att 3.263822 loss_ctc 3.331342 loss_rnnt 2.949067 hw_loss 0.360924 history loss 5.615824 rank 0
2023-03-01 04:36:57,343 DEBUG CV Batch 48/1000 loss 3.178877 loss_att 3.263822 loss_ctc 3.331342 loss_rnnt 2.949067 hw_loss 0.360924 history loss 5.615824 rank 6
2023-03-01 04:36:57,706 DEBUG CV Batch 48/1000 loss 3.178877 loss_att 3.263822 loss_ctc 3.331342 loss_rnnt 2.949067 hw_loss 0.360924 history loss 5.615824 rank 5
2023-03-01 04:37:04,430 DEBUG CV Batch 48/1100 loss 4.751672 loss_att 4.663595 loss_ctc 8.083403 loss_rnnt 4.095902 hw_loss 0.429665 history loss 5.583180 rank 1
2023-03-01 04:37:05,381 DEBUG CV Batch 48/1100 loss 4.751672 loss_att 4.663595 loss_ctc 8.083403 loss_rnnt 4.095902 hw_loss 0.429665 history loss 5.583180 rank 4
2023-03-01 04:37:07,898 DEBUG CV Batch 48/1100 loss 4.751672 loss_att 4.663595 loss_ctc 8.083403 loss_rnnt 4.095902 hw_loss 0.429665 history loss 5.583180 rank 7
2023-03-01 04:37:08,420 DEBUG CV Batch 48/1100 loss 4.751672 loss_att 4.663595 loss_ctc 8.083403 loss_rnnt 4.095902 hw_loss 0.429665 history loss 5.583180 rank 2
2023-03-01 04:37:09,046 DEBUG CV Batch 48/1100 loss 4.751672 loss_att 4.663595 loss_ctc 8.083403 loss_rnnt 4.095902 hw_loss 0.429665 history loss 5.583180 rank 3
2023-03-01 04:37:09,511 DEBUG CV Batch 48/1100 loss 4.751672 loss_att 4.663595 loss_ctc 8.083403 loss_rnnt 4.095902 hw_loss 0.429665 history loss 5.583180 rank 6
2023-03-01 04:37:09,604 DEBUG CV Batch 48/1100 loss 4.751672 loss_att 4.663595 loss_ctc 8.083403 loss_rnnt 4.095902 hw_loss 0.429665 history loss 5.583180 rank 0
2023-03-01 04:37:10,263 DEBUG CV Batch 48/1100 loss 4.751672 loss_att 4.663595 loss_ctc 8.083403 loss_rnnt 4.095902 hw_loss 0.429665 history loss 5.583180 rank 5
2023-03-01 04:37:15,100 DEBUG CV Batch 48/1200 loss 6.028232 loss_att 6.329423 loss_ctc 6.585195 loss_rnnt 5.697292 hw_loss 0.368326 history loss 5.873583 rank 1
2023-03-01 04:37:16,162 DEBUG CV Batch 48/1200 loss 6.028232 loss_att 6.329423 loss_ctc 6.585195 loss_rnnt 5.697292 hw_loss 0.368326 history loss 5.873583 rank 4
2023-03-01 04:37:19,047 DEBUG CV Batch 48/1200 loss 6.028232 loss_att 6.329423 loss_ctc 6.585195 loss_rnnt 5.697292 hw_loss 0.368326 history loss 5.873583 rank 7
2023-03-01 04:37:19,575 DEBUG CV Batch 48/1200 loss 6.028232 loss_att 6.329423 loss_ctc 6.585195 loss_rnnt 5.697292 hw_loss 0.368326 history loss 5.873583 rank 2
2023-03-01 04:37:20,144 DEBUG CV Batch 48/1200 loss 6.028232 loss_att 6.329423 loss_ctc 6.585195 loss_rnnt 5.697292 hw_loss 0.368326 history loss 5.873583 rank 3
2023-03-01 04:37:20,487 DEBUG CV Batch 48/1200 loss 6.028232 loss_att 6.329423 loss_ctc 6.585195 loss_rnnt 5.697292 hw_loss 0.368326 history loss 5.873583 rank 6
2023-03-01 04:37:20,758 DEBUG CV Batch 48/1200 loss 6.028232 loss_att 6.329423 loss_ctc 6.585195 loss_rnnt 5.697292 hw_loss 0.368326 history loss 5.873583 rank 0
2023-03-01 04:37:21,417 DEBUG CV Batch 48/1200 loss 6.028232 loss_att 6.329423 loss_ctc 6.585195 loss_rnnt 5.697292 hw_loss 0.368326 history loss 5.873583 rank 5
2023-03-01 04:37:27,514 DEBUG CV Batch 48/1300 loss 4.987330 loss_att 4.373055 loss_ctc 7.338301 loss_rnnt 4.581249 hw_loss 0.404013 history loss 6.148309 rank 1
2023-03-01 04:37:28,066 DEBUG CV Batch 48/1300 loss 4.987330 loss_att 4.373055 loss_ctc 7.338301 loss_rnnt 4.581249 hw_loss 0.404013 history loss 6.148309 rank 4
2023-03-01 04:37:31,521 DEBUG CV Batch 48/1300 loss 4.987330 loss_att 4.373055 loss_ctc 7.338301 loss_rnnt 4.581249 hw_loss 0.404013 history loss 6.148309 rank 7
2023-03-01 04:37:31,988 DEBUG CV Batch 48/1300 loss 4.987330 loss_att 4.373055 loss_ctc 7.338301 loss_rnnt 4.581249 hw_loss 0.404013 history loss 6.148309 rank 2
2023-03-01 04:37:32,699 DEBUG CV Batch 48/1300 loss 4.987330 loss_att 4.373055 loss_ctc 7.338301 loss_rnnt 4.581249 hw_loss 0.404013 history loss 6.148309 rank 3
2023-03-01 04:37:33,105 DEBUG CV Batch 48/1300 loss 4.987330 loss_att 4.373055 loss_ctc 7.338301 loss_rnnt 4.581249 hw_loss 0.404013 history loss 6.148309 rank 6
2023-03-01 04:37:33,355 DEBUG CV Batch 48/1300 loss 4.987330 loss_att 4.373055 loss_ctc 7.338301 loss_rnnt 4.581249 hw_loss 0.404013 history loss 6.148309 rank 0
2023-03-01 04:37:34,038 DEBUG CV Batch 48/1300 loss 4.987330 loss_att 4.373055 loss_ctc 7.338301 loss_rnnt 4.581249 hw_loss 0.404013 history loss 6.148309 rank 5
2023-03-01 04:37:38,845 DEBUG CV Batch 48/1400 loss 4.216343 loss_att 10.549978 loss_ctc 5.233813 loss_rnnt 2.768706 hw_loss 0.084839 history loss 6.414715 rank 1
2023-03-01 04:37:39,544 DEBUG CV Batch 48/1400 loss 4.216343 loss_att 10.549978 loss_ctc 5.233813 loss_rnnt 2.768706 hw_loss 0.084839 history loss 6.414715 rank 4
2023-03-01 04:37:43,089 DEBUG CV Batch 48/1400 loss 4.216343 loss_att 10.549978 loss_ctc 5.233813 loss_rnnt 2.768706 hw_loss 0.084839 history loss 6.414715 rank 7
2023-03-01 04:37:43,813 DEBUG CV Batch 48/1400 loss 4.216343 loss_att 10.549978 loss_ctc 5.233813 loss_rnnt 2.768706 hw_loss 0.084839 history loss 6.414715 rank 2
2023-03-01 04:37:44,351 DEBUG CV Batch 48/1400 loss 4.216343 loss_att 10.549978 loss_ctc 5.233813 loss_rnnt 2.768706 hw_loss 0.084839 history loss 6.414715 rank 3
2023-03-01 04:37:44,586 DEBUG CV Batch 48/1400 loss 4.216343 loss_att 10.549978 loss_ctc 5.233813 loss_rnnt 2.768706 hw_loss 0.084839 history loss 6.414715 rank 6
2023-03-01 04:37:45,139 DEBUG CV Batch 48/1400 loss 4.216343 loss_att 10.549978 loss_ctc 5.233813 loss_rnnt 2.768706 hw_loss 0.084839 history loss 6.414715 rank 0
2023-03-01 04:37:45,807 DEBUG CV Batch 48/1400 loss 4.216343 loss_att 10.549978 loss_ctc 5.233813 loss_rnnt 2.768706 hw_loss 0.084839 history loss 6.414715 rank 5
2023-03-01 04:37:50,076 DEBUG CV Batch 48/1500 loss 7.090326 loss_att 7.484305 loss_ctc 6.933184 loss_rnnt 6.899506 hw_loss 0.249333 history loss 6.285266 rank 1
2023-03-01 04:37:51,383 DEBUG CV Batch 48/1500 loss 7.090326 loss_att 7.484305 loss_ctc 6.933184 loss_rnnt 6.899506 hw_loss 0.249333 history loss 6.285266 rank 4
2023-03-01 04:37:55,062 DEBUG CV Batch 48/1500 loss 7.090326 loss_att 7.484305 loss_ctc 6.933184 loss_rnnt 6.899506 hw_loss 0.249333 history loss 6.285266 rank 7
2023-03-01 04:37:55,766 DEBUG CV Batch 48/1500 loss 7.090326 loss_att 7.484305 loss_ctc 6.933184 loss_rnnt 6.899506 hw_loss 0.249333 history loss 6.285266 rank 2
2023-03-01 04:37:56,264 DEBUG CV Batch 48/1500 loss 7.090326 loss_att 7.484305 loss_ctc 6.933184 loss_rnnt 6.899506 hw_loss 0.249333 history loss 6.285266 rank 6
2023-03-01 04:37:56,355 DEBUG CV Batch 48/1500 loss 7.090326 loss_att 7.484305 loss_ctc 6.933184 loss_rnnt 6.899506 hw_loss 0.249333 history loss 6.285266 rank 3
2023-03-01 04:37:57,139 DEBUG CV Batch 48/1500 loss 7.090326 loss_att 7.484305 loss_ctc 6.933184 loss_rnnt 6.899506 hw_loss 0.249333 history loss 6.285266 rank 0
2023-03-01 04:37:57,984 DEBUG CV Batch 48/1500 loss 7.090326 loss_att 7.484305 loss_ctc 6.933184 loss_rnnt 6.899506 hw_loss 0.249333 history loss 6.285266 rank 5
2023-03-01 04:38:03,384 DEBUG CV Batch 48/1600 loss 9.122736 loss_att 13.163239 loss_ctc 13.470062 loss_rnnt 7.680081 hw_loss 0.102960 history loss 6.251949 rank 1
2023-03-01 04:38:04,782 DEBUG CV Batch 48/1600 loss 9.122736 loss_att 13.163239 loss_ctc 13.470062 loss_rnnt 7.680081 hw_loss 0.102960 history loss 6.251949 rank 4
2023-03-01 04:38:08,447 DEBUG CV Batch 48/1600 loss 9.122736 loss_att 13.163239 loss_ctc 13.470062 loss_rnnt 7.680081 hw_loss 0.102960 history loss 6.251949 rank 7
2023-03-01 04:38:09,078 DEBUG CV Batch 48/1600 loss 9.122736 loss_att 13.163239 loss_ctc 13.470062 loss_rnnt 7.680081 hw_loss 0.102960 history loss 6.251949 rank 2
2023-03-01 04:38:09,644 DEBUG CV Batch 48/1600 loss 9.122736 loss_att 13.163239 loss_ctc 13.470062 loss_rnnt 7.680081 hw_loss 0.102960 history loss 6.251949 rank 6
2023-03-01 04:38:10,206 DEBUG CV Batch 48/1600 loss 9.122736 loss_att 13.163239 loss_ctc 13.470062 loss_rnnt 7.680081 hw_loss 0.102960 history loss 6.251949 rank 3
2023-03-01 04:38:10,645 DEBUG CV Batch 48/1600 loss 9.122736 loss_att 13.163239 loss_ctc 13.470062 loss_rnnt 7.680081 hw_loss 0.102960 history loss 6.251949 rank 0
2023-03-01 04:38:11,695 DEBUG CV Batch 48/1600 loss 9.122736 loss_att 13.163239 loss_ctc 13.470062 loss_rnnt 7.680081 hw_loss 0.102960 history loss 6.251949 rank 5
2023-03-01 04:38:15,974 DEBUG CV Batch 48/1700 loss 8.490737 loss_att 6.251445 loss_ctc 13.634749 loss_rnnt 8.059166 hw_loss 0.362927 history loss 6.190368 rank 1
2023-03-01 04:38:17,429 DEBUG CV Batch 48/1700 loss 8.490737 loss_att 6.251445 loss_ctc 13.634749 loss_rnnt 8.059166 hw_loss 0.362927 history loss 6.190368 rank 4
2023-03-01 04:38:21,143 DEBUG CV Batch 48/1700 loss 8.490737 loss_att 6.251445 loss_ctc 13.634749 loss_rnnt 8.059166 hw_loss 0.362927 history loss 6.190368 rank 7
2023-03-01 04:38:21,760 DEBUG CV Batch 48/1700 loss 8.490737 loss_att 6.251445 loss_ctc 13.634749 loss_rnnt 8.059166 hw_loss 0.362927 history loss 6.190368 rank 2
2023-03-01 04:38:22,221 DEBUG CV Batch 48/1700 loss 8.490737 loss_att 6.251445 loss_ctc 13.634749 loss_rnnt 8.059166 hw_loss 0.362927 history loss 6.190368 rank 6
2023-03-01 04:38:22,735 DEBUG CV Batch 48/1700 loss 8.490737 loss_att 6.251445 loss_ctc 13.634749 loss_rnnt 8.059166 hw_loss 0.362927 history loss 6.190368 rank 3
2023-03-01 04:38:23,337 DEBUG CV Batch 48/1700 loss 8.490737 loss_att 6.251445 loss_ctc 13.634749 loss_rnnt 8.059166 hw_loss 0.362927 history loss 6.190368 rank 0
2023-03-01 04:38:24,523 DEBUG CV Batch 48/1700 loss 8.490737 loss_att 6.251445 loss_ctc 13.634749 loss_rnnt 8.059166 hw_loss 0.362927 history loss 6.190368 rank 5
2023-03-01 04:38:25,102 INFO Epoch 48 CV info cv_loss 6.170308105581877
2023-03-01 04:38:25,103 INFO Epoch 49 TRAIN info lr 0.00029364808394773156
2023-03-01 04:38:25,108 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 04:38:26,481 INFO Epoch 48 CV info cv_loss 6.170308104899168
2023-03-01 04:38:26,482 INFO Epoch 49 TRAIN info lr 0.0002936485903698124
2023-03-01 04:38:26,486 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 04:38:30,324 INFO Epoch 48 CV info cv_loss 6.170308106180594
2023-03-01 04:38:30,324 INFO Epoch 49 TRAIN info lr 0.0002936399815507556
2023-03-01 04:38:30,326 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 04:38:31,088 INFO Epoch 48 CV info cv_loss 6.170308104726875
2023-03-01 04:38:31,088 INFO Epoch 49 TRAIN info lr 0.0002936501096517758
2023-03-01 04:38:31,094 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 04:38:31,502 INFO Epoch 48 CV info cv_loss 6.170308104369368
2023-03-01 04:38:31,503 INFO Epoch 49 TRAIN info lr 0.0002936501096517758
2023-03-01 04:38:31,507 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 04:38:32,055 INFO Epoch 48 CV info cv_loss 6.170308105372973
2023-03-01 04:38:32,056 INFO Epoch 49 TRAIN info lr 0.0002936440326654063
2023-03-01 04:38:32,061 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 04:38:32,578 INFO Epoch 48 CV info cv_loss 6.170308104597655
2023-03-01 04:38:32,578 INFO Checkpoint: save to checkpoint exp/2_27_rnnt_bias_loss_2_class_both_finetune/48.pt
2023-03-01 04:38:33,148 INFO Epoch 49 TRAIN info lr 0.00029365264184078537
2023-03-01 04:38:33,152 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 04:38:34,138 INFO Epoch 48 CV info cv_loss 6.1703081062538185
2023-03-01 04:38:34,139 INFO Epoch 49 TRAIN info lr 0.00029364808394773156
2023-03-01 04:38:34,144 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 04:39:39,421 DEBUG TRAIN Batch 49/0 loss 7.392778 loss_att 8.096775 loss_ctc 10.305411 loss_rnnt 6.682392 hw_loss 0.339817 lr 0.00029364 rank 7
2023-03-01 04:39:39,426 DEBUG TRAIN Batch 49/0 loss 6.602546 loss_att 6.835063 loss_ctc 9.968150 loss_rnnt 5.860352 hw_loss 0.463019 lr 0.00029365 rank 4
2023-03-01 04:39:39,426 DEBUG TRAIN Batch 49/0 loss 6.344398 loss_att 6.585308 loss_ctc 8.603503 loss_rnnt 5.823543 hw_loss 0.321487 lr 0.00029365 rank 2
2023-03-01 04:39:39,427 DEBUG TRAIN Batch 49/0 loss 7.254793 loss_att 7.206745 loss_ctc 10.092291 loss_rnnt 6.743398 hw_loss 0.267510 lr 0.00029365 rank 5
2023-03-01 04:39:39,429 DEBUG TRAIN Batch 49/0 loss 5.064801 loss_att 5.120146 loss_ctc 7.782964 loss_rnnt 4.515133 hw_loss 0.330330 lr 0.00029365 rank 0
2023-03-01 04:39:39,442 DEBUG TRAIN Batch 49/0 loss 5.501088 loss_att 5.454849 loss_ctc 8.576070 loss_rnnt 4.917514 hw_loss 0.342794 lr 0.00029364 rank 3
2023-03-01 04:39:39,447 DEBUG TRAIN Batch 49/0 loss 7.295066 loss_att 7.269942 loss_ctc 11.761685 loss_rnnt 6.548947 hw_loss 0.291740 lr 0.00029365 rank 1
2023-03-01 04:39:39,487 DEBUG TRAIN Batch 49/0 loss 5.872044 loss_att 5.502756 loss_ctc 8.473425 loss_rnnt 5.417480 hw_loss 0.340445 lr 0.00029365 rank 6
2023-03-01 04:40:17,007 DEBUG TRAIN Batch 49/100 loss 4.400883 loss_att 6.814282 loss_ctc 7.847144 loss_rnnt 3.278597 hw_loss 0.337695 lr 0.00029364 rank 0
2023-03-01 04:40:17,020 DEBUG TRAIN Batch 49/100 loss 5.380870 loss_att 8.161472 loss_ctc 8.712128 loss_rnnt 4.321136 hw_loss 0.111463 lr 0.00029363 rank 1
2023-03-01 04:40:17,021 DEBUG TRAIN Batch 49/100 loss 11.440714 loss_att 12.672886 loss_ctc 20.108418 loss_rnnt 9.898985 hw_loss 0.261749 lr 0.00029364 rank 2
2023-03-01 04:40:17,023 DEBUG TRAIN Batch 49/100 loss 3.804402 loss_att 5.724790 loss_ctc 5.060107 loss_rnnt 3.085745 hw_loss 0.313410 lr 0.00029363 rank 3
2023-03-01 04:40:17,026 DEBUG TRAIN Batch 49/100 loss 3.567450 loss_att 6.487803 loss_ctc 6.562219 loss_rnnt 2.437224 hw_loss 0.275349 lr 0.00029364 rank 6
2023-03-01 04:40:17,026 DEBUG TRAIN Batch 49/100 loss 6.484750 loss_att 8.045951 loss_ctc 7.362226 loss_rnnt 5.963254 hw_loss 0.172985 lr 0.00029363 rank 5
2023-03-01 04:40:17,033 DEBUG TRAIN Batch 49/100 loss 3.659663 loss_att 9.425393 loss_ctc 5.703007 loss_rnnt 2.130718 hw_loss 0.193787 lr 0.00029363 rank 7
2023-03-01 04:40:17,035 DEBUG TRAIN Batch 49/100 loss 4.211918 loss_att 5.808462 loss_ctc 8.590361 loss_rnnt 3.154841 hw_loss 0.288706 lr 0.00029364 rank 4
2023-03-01 04:40:55,107 DEBUG TRAIN Batch 49/200 loss 3.307103 loss_att 6.720563 loss_ctc 3.823856 loss_rnnt 2.420278 hw_loss 0.253561 lr 0.00029363 rank 0
2023-03-01 04:40:55,111 DEBUG TRAIN Batch 49/200 loss 2.112378 loss_att 5.390735 loss_ctc 4.541752 loss_rnnt 1.094641 hw_loss 0.071529 lr 0.00029361 rank 7
2023-03-01 04:40:55,125 DEBUG TRAIN Batch 49/200 loss 4.555835 loss_att 9.006110 loss_ctc 6.211568 loss_rnnt 3.296183 hw_loss 0.279061 lr 0.00029362 rank 3
2023-03-01 04:40:55,125 DEBUG TRAIN Batch 49/200 loss 3.669687 loss_att 6.698452 loss_ctc 5.976748 loss_rnnt 2.552857 hw_loss 0.381504 lr 0.00029362 rank 5
2023-03-01 04:40:55,129 DEBUG TRAIN Batch 49/200 loss 2.951315 loss_att 6.639070 loss_ctc 4.337240 loss_rnnt 1.976246 hw_loss 0.098866 lr 0.00029362 rank 1
2023-03-01 04:40:55,131 DEBUG TRAIN Batch 49/200 loss 10.834792 loss_att 12.048184 loss_ctc 16.199091 loss_rnnt 9.783381 hw_loss 0.175300 lr 0.00029362 rank 6
2023-03-01 04:40:55,134 DEBUG TRAIN Batch 49/200 loss 3.673436 loss_att 6.878558 loss_ctc 5.339923 loss_rnnt 2.639935 hw_loss 0.319272 lr 0.00029362 rank 2
2023-03-01 04:40:55,134 DEBUG TRAIN Batch 49/200 loss 9.967589 loss_att 12.537410 loss_ctc 11.605085 loss_rnnt 9.088243 hw_loss 0.275717 lr 0.00029362 rank 4
2023-03-01 04:41:33,496 DEBUG TRAIN Batch 49/300 loss 2.068038 loss_att 5.654510 loss_ctc 4.945848 loss_rnnt 0.870389 hw_loss 0.181212 lr 0.00029361 rank 2
2023-03-01 04:41:33,500 DEBUG TRAIN Batch 49/300 loss 5.348937 loss_att 8.726210 loss_ctc 7.151145 loss_rnnt 4.334138 hw_loss 0.185719 lr 0.00029361 rank 3
2023-03-01 04:41:33,508 DEBUG TRAIN Batch 49/300 loss 6.529470 loss_att 9.762500 loss_ctc 12.468397 loss_rnnt 4.980522 hw_loss 0.207160 lr 0.00029361 rank 6
2023-03-01 04:41:33,515 DEBUG TRAIN Batch 49/300 loss 3.683570 loss_att 6.194185 loss_ctc 4.331960 loss_rnnt 2.958896 hw_loss 0.255185 lr 0.00029361 rank 1
2023-03-01 04:41:33,515 DEBUG TRAIN Batch 49/300 loss 6.713520 loss_att 11.792421 loss_ctc 10.716676 loss_rnnt 5.096249 hw_loss 0.127007 lr 0.00029360 rank 7
2023-03-01 04:41:33,518 DEBUG TRAIN Batch 49/300 loss 8.011089 loss_att 13.864459 loss_ctc 18.836721 loss_rnnt 5.290330 hw_loss 0.200003 lr 0.00029361 rank 0
2023-03-01 04:41:33,521 DEBUG TRAIN Batch 49/300 loss 3.553772 loss_att 6.866246 loss_ctc 4.657121 loss_rnnt 2.615762 hw_loss 0.240754 lr 0.00029361 rank 4
2023-03-01 04:41:33,528 DEBUG TRAIN Batch 49/300 loss 7.226679 loss_att 10.595240 loss_ctc 11.307684 loss_rnnt 5.868292 hw_loss 0.263515 lr 0.00029361 rank 5
2023-03-01 04:42:38,978 DEBUG TRAIN Batch 49/400 loss 8.455001 loss_att 12.607731 loss_ctc 18.755821 loss_rnnt 6.097638 hw_loss 0.287576 lr 0.00029360 rank 0
2023-03-01 04:42:38,984 DEBUG TRAIN Batch 49/400 loss 4.265893 loss_att 7.145811 loss_ctc 6.391352 loss_rnnt 3.284101 hw_loss 0.229527 lr 0.00029360 rank 1
2023-03-01 04:42:38,984 DEBUG TRAIN Batch 49/400 loss 7.183177 loss_att 9.384139 loss_ctc 14.005825 loss_rnnt 5.713720 hw_loss 0.224209 lr 0.00029359 rank 7
2023-03-01 04:42:38,987 DEBUG TRAIN Batch 49/400 loss 5.427156 loss_att 10.243691 loss_ctc 11.166991 loss_rnnt 3.573153 hw_loss 0.235096 lr 0.00029360 rank 4
2023-03-01 04:42:38,988 DEBUG TRAIN Batch 49/400 loss 4.165820 loss_att 6.084610 loss_ctc 6.346542 loss_rnnt 3.340510 hw_loss 0.282727 lr 0.00029360 rank 2
2023-03-01 04:42:38,993 DEBUG TRAIN Batch 49/400 loss 8.193752 loss_att 9.836113 loss_ctc 18.034176 loss_rnnt 6.410972 hw_loss 0.266724 lr 0.00029359 rank 3
2023-03-01 04:42:39,018 DEBUG TRAIN Batch 49/400 loss 5.234720 loss_att 5.940179 loss_ctc 7.927057 loss_rnnt 4.541412 hw_loss 0.362322 lr 0.00029360 rank 6
2023-03-01 04:42:39,057 DEBUG TRAIN Batch 49/400 loss 4.068336 loss_att 6.057727 loss_ctc 7.138216 loss_rnnt 3.147952 hw_loss 0.212228 lr 0.00029360 rank 5
2023-03-01 04:43:17,251 DEBUG TRAIN Batch 49/500 loss 2.054958 loss_att 4.328043 loss_ctc 4.217281 loss_rnnt 1.157930 hw_loss 0.288938 lr 0.00029359 rank 2
2023-03-01 04:43:17,257 DEBUG TRAIN Batch 49/500 loss 8.589732 loss_att 11.397913 loss_ctc 15.555630 loss_rnnt 6.999538 hw_loss 0.187071 lr 0.00029358 rank 4
2023-03-01 04:43:17,271 DEBUG TRAIN Batch 49/500 loss 3.001921 loss_att 5.509820 loss_ctc 7.757451 loss_rnnt 1.678795 hw_loss 0.351516 lr 0.00029358 rank 7
2023-03-01 04:43:17,274 DEBUG TRAIN Batch 49/500 loss 10.696664 loss_att 13.588909 loss_ctc 17.257727 loss_rnnt 9.083572 hw_loss 0.299687 lr 0.00029358 rank 1
2023-03-01 04:43:17,276 DEBUG TRAIN Batch 49/500 loss 3.074109 loss_att 5.320005 loss_ctc 3.959370 loss_rnnt 2.355972 hw_loss 0.282979 lr 0.00029359 rank 6
2023-03-01 04:43:17,276 DEBUG TRAIN Batch 49/500 loss 2.614316 loss_att 5.051495 loss_ctc 5.759342 loss_rnnt 1.569936 hw_loss 0.258016 lr 0.00029359 rank 0
2023-03-01 04:43:17,289 DEBUG TRAIN Batch 49/500 loss 8.119185 loss_att 11.722049 loss_ctc 13.030497 loss_rnnt 6.622061 hw_loss 0.228206 lr 0.00029358 rank 3
2023-03-01 04:43:17,302 DEBUG TRAIN Batch 49/500 loss 5.817216 loss_att 8.266239 loss_ctc 11.972231 loss_rnnt 4.449073 hw_loss 0.108131 lr 0.00029358 rank 5
2023-03-01 04:43:56,078 DEBUG TRAIN Batch 49/600 loss 5.130587 loss_att 7.482574 loss_ctc 9.014320 loss_rnnt 4.064393 hw_loss 0.146185 lr 0.00029357 rank 6
2023-03-01 04:43:56,078 DEBUG TRAIN Batch 49/600 loss 5.188130 loss_att 6.139735 loss_ctc 6.962007 loss_rnnt 4.592988 hw_loss 0.315569 lr 0.00029357 rank 2
2023-03-01 04:43:56,077 DEBUG TRAIN Batch 49/600 loss 6.051466 loss_att 7.424861 loss_ctc 10.403217 loss_rnnt 5.069599 hw_loss 0.238038 lr 0.00029357 rank 1
2023-03-01 04:43:56,078 DEBUG TRAIN Batch 49/600 loss 6.024350 loss_att 8.288621 loss_ctc 9.660854 loss_rnnt 4.918139 hw_loss 0.315918 lr 0.00029357 rank 3
2023-03-01 04:43:56,082 DEBUG TRAIN Batch 49/600 loss 5.520158 loss_att 7.391960 loss_ctc 9.964827 loss_rnnt 4.384549 hw_loss 0.316174 lr 0.00029356 rank 7
2023-03-01 04:43:56,083 DEBUG TRAIN Batch 49/600 loss 5.348604 loss_att 6.092523 loss_ctc 8.123451 loss_rnnt 4.685800 hw_loss 0.270077 lr 0.00029358 rank 0
2023-03-01 04:43:56,086 DEBUG TRAIN Batch 49/600 loss 3.055022 loss_att 4.326743 loss_ctc 5.586555 loss_rnnt 2.400182 hw_loss 0.118044 lr 0.00029357 rank 4
2023-03-01 04:43:56,087 DEBUG TRAIN Batch 49/600 loss 10.235833 loss_att 10.647902 loss_ctc 13.176668 loss_rnnt 9.647143 hw_loss 0.214060 lr 0.00029357 rank 5
2023-03-01 04:45:01,595 DEBUG TRAIN Batch 49/700 loss 4.319523 loss_att 10.289930 loss_ctc 4.740094 loss_rnnt 2.915476 hw_loss 0.288543 lr 0.00029356 rank 4
2023-03-01 04:45:01,601 DEBUG TRAIN Batch 49/700 loss 2.641985 loss_att 6.698011 loss_ctc 3.130666 loss_rnnt 1.622843 hw_loss 0.267712 lr 0.00029356 rank 0
2023-03-01 04:45:01,611 DEBUG TRAIN Batch 49/700 loss 6.484125 loss_att 8.962605 loss_ctc 11.432330 loss_rnnt 5.170898 hw_loss 0.295820 lr 0.00029356 rank 5
2023-03-01 04:45:01,615 DEBUG TRAIN Batch 49/700 loss 1.495692 loss_att 5.225099 loss_ctc 3.878382 loss_rnnt 0.352799 hw_loss 0.148725 lr 0.00029356 rank 1
2023-03-01 04:45:01,661 DEBUG TRAIN Batch 49/700 loss 5.234854 loss_att 8.750769 loss_ctc 13.098469 loss_rnnt 3.386289 hw_loss 0.181686 lr 0.00029355 rank 3
2023-03-01 04:45:01,669 DEBUG TRAIN Batch 49/700 loss 6.823767 loss_att 10.469675 loss_ctc 15.285093 loss_rnnt 4.796652 hw_loss 0.318292 lr 0.00029356 rank 6
2023-03-01 04:45:01,673 DEBUG TRAIN Batch 49/700 loss 2.329474 loss_att 4.850373 loss_ctc 7.945501 loss_rnnt 0.976797 hw_loss 0.186925 lr 0.00029355 rank 7
2023-03-01 04:45:01,674 DEBUG TRAIN Batch 49/700 loss 7.470773 loss_att 13.698570 loss_ctc 13.811198 loss_rnnt 5.293467 hw_loss 0.161920 lr 0.00029356 rank 2
2023-03-01 04:45:39,616 DEBUG TRAIN Batch 49/800 loss 7.811240 loss_att 9.880107 loss_ctc 13.892241 loss_rnnt 6.586234 hw_loss 0.000811 lr 0.00029355 rank 0
2023-03-01 04:45:39,620 DEBUG TRAIN Batch 49/800 loss 9.730084 loss_att 14.397526 loss_ctc 19.381941 loss_rnnt 7.397708 hw_loss 0.209950 lr 0.00029355 rank 4
2023-03-01 04:45:39,625 DEBUG TRAIN Batch 49/800 loss 2.902168 loss_att 6.316707 loss_ctc 4.845778 loss_rnnt 1.943127 hw_loss 0.031846 lr 0.00029354 rank 7
2023-03-01 04:45:39,633 DEBUG TRAIN Batch 49/800 loss 3.948467 loss_att 7.239131 loss_ctc 6.689363 loss_rnnt 2.793343 hw_loss 0.246635 lr 0.00029355 rank 5
2023-03-01 04:45:39,639 DEBUG TRAIN Batch 49/800 loss 4.032804 loss_att 5.893512 loss_ctc 4.855807 loss_rnnt 3.290702 hw_loss 0.487924 lr 0.00029355 rank 2
2023-03-01 04:45:39,640 DEBUG TRAIN Batch 49/800 loss 4.574602 loss_att 9.520323 loss_ctc 7.608627 loss_rnnt 3.075221 hw_loss 0.198187 lr 0.00029354 rank 3
2023-03-01 04:45:39,643 DEBUG TRAIN Batch 49/800 loss 3.118968 loss_att 6.274278 loss_ctc 7.281948 loss_rnnt 1.817968 hw_loss 0.215390 lr 0.00029355 rank 6
2023-03-01 04:45:39,685 DEBUG TRAIN Batch 49/800 loss 6.992485 loss_att 11.333831 loss_ctc 10.552239 loss_rnnt 5.599854 hw_loss 0.093241 lr 0.00029355 rank 1
2023-03-01 04:46:18,284 DEBUG TRAIN Batch 49/900 loss 11.660944 loss_att 16.157061 loss_ctc 18.820038 loss_rnnt 9.735157 hw_loss 0.135033 lr 0.00029353 rank 7
2023-03-01 04:46:18,299 DEBUG TRAIN Batch 49/900 loss 5.976539 loss_att 8.009244 loss_ctc 9.813543 loss_rnnt 4.955005 hw_loss 0.193862 lr 0.00029353 rank 4
2023-03-01 04:46:18,302 DEBUG TRAIN Batch 49/900 loss 4.230810 loss_att 6.488189 loss_ctc 5.715721 loss_rnnt 3.448488 hw_loss 0.249110 lr 0.00029354 rank 2
2023-03-01 04:46:18,303 DEBUG TRAIN Batch 49/900 loss 3.052927 loss_att 5.776298 loss_ctc 5.624607 loss_rnnt 2.097502 hw_loss 0.127235 lr 0.00029353 rank 5
2023-03-01 04:46:18,303 DEBUG TRAIN Batch 49/900 loss 8.063319 loss_att 9.079004 loss_ctc 8.295942 loss_rnnt 7.637341 hw_loss 0.359673 lr 0.00029354 rank 0
2023-03-01 04:46:18,308 DEBUG TRAIN Batch 49/900 loss 7.842663 loss_att 9.215899 loss_ctc 9.586346 loss_rnnt 7.223006 hw_loss 0.210974 lr 0.00029353 rank 1
2023-03-01 04:46:18,309 DEBUG TRAIN Batch 49/900 loss 11.205969 loss_att 13.260469 loss_ctc 16.984797 loss_rnnt 9.867606 hw_loss 0.294285 lr 0.00029353 rank 3
2023-03-01 04:46:18,354 DEBUG TRAIN Batch 49/900 loss 6.297173 loss_att 8.858672 loss_ctc 11.035599 loss_rnnt 5.001588 hw_loss 0.284052 lr 0.00029354 rank 6
2023-03-01 04:46:56,697 DEBUG TRAIN Batch 49/1000 loss 6.788396 loss_att 10.726347 loss_ctc 11.446131 loss_rnnt 5.305545 hw_loss 0.139180 lr 0.00029352 rank 1
2023-03-01 04:46:56,703 DEBUG TRAIN Batch 49/1000 loss 6.128984 loss_att 12.019229 loss_ctc 16.672577 loss_rnnt 3.448741 hw_loss 0.180716 lr 0.00029352 rank 3
2023-03-01 04:46:56,704 DEBUG TRAIN Batch 49/1000 loss 1.713138 loss_att 5.209959 loss_ctc 3.602673 loss_rnnt 0.625780 hw_loss 0.255104 lr 0.00029353 rank 0
2023-03-01 04:46:56,705 DEBUG TRAIN Batch 49/1000 loss 5.095016 loss_att 7.146894 loss_ctc 7.509691 loss_rnnt 4.251493 hw_loss 0.208482 lr 0.00029351 rank 7
2023-03-01 04:46:56,710 DEBUG TRAIN Batch 49/1000 loss 2.635067 loss_att 5.239293 loss_ctc 5.304480 loss_rnnt 1.619155 hw_loss 0.260898 lr 0.00029352 rank 2
2023-03-01 04:46:56,714 DEBUG TRAIN Batch 49/1000 loss 15.212423 loss_att 18.458149 loss_ctc 26.261017 loss_rnnt 13.024956 hw_loss 0.122207 lr 0.00029352 rank 5
2023-03-01 04:46:56,716 DEBUG TRAIN Batch 49/1000 loss 16.232491 loss_att 18.365164 loss_ctc 20.035769 loss_rnnt 15.132456 hw_loss 0.311992 lr 0.00029352 rank 6
2023-03-01 04:46:56,718 DEBUG TRAIN Batch 49/1000 loss 3.058197 loss_att 6.307055 loss_ctc 4.228102 loss_rnnt 2.131758 hw_loss 0.226277 lr 0.00029352 rank 4
2023-03-01 04:48:01,114 DEBUG TRAIN Batch 49/1100 loss 4.369599 loss_att 7.412538 loss_ctc 10.091635 loss_rnnt 2.878513 hw_loss 0.224174 lr 0.00029350 rank 3
2023-03-01 04:48:01,123 DEBUG TRAIN Batch 49/1100 loss 7.486962 loss_att 10.509949 loss_ctc 13.298496 loss_rnnt 6.005900 hw_loss 0.190486 lr 0.00029350 rank 7
2023-03-01 04:48:01,125 DEBUG TRAIN Batch 49/1100 loss 5.725753 loss_att 7.600998 loss_ctc 8.147747 loss_rnnt 4.937401 hw_loss 0.169446 lr 0.00029351 rank 6
2023-03-01 04:48:01,125 DEBUG TRAIN Batch 49/1100 loss 3.630743 loss_att 8.655987 loss_ctc 7.603211 loss_rnnt 1.957168 hw_loss 0.260368 lr 0.00029351 rank 2
2023-03-01 04:48:01,127 DEBUG TRAIN Batch 49/1100 loss 4.068770 loss_att 5.969457 loss_ctc 7.868352 loss_rnnt 3.100098 hw_loss 0.153607 lr 0.00029351 rank 0
2023-03-01 04:48:01,128 DEBUG TRAIN Batch 49/1100 loss 9.992128 loss_att 12.846225 loss_ctc 16.415699 loss_rnnt 8.439667 hw_loss 0.234686 lr 0.00029351 rank 1
2023-03-01 04:48:01,130 DEBUG TRAIN Batch 49/1100 loss 5.872262 loss_att 8.350129 loss_ctc 9.486008 loss_rnnt 4.823909 hw_loss 0.133024 lr 0.00029351 rank 5
2023-03-01 04:48:01,131 DEBUG TRAIN Batch 49/1100 loss 2.654789 loss_att 6.024426 loss_ctc 5.791862 loss_rnnt 1.458036 hw_loss 0.196032 lr 0.00029351 rank 4
2023-03-01 04:48:39,473 DEBUG TRAIN Batch 49/1200 loss 8.590871 loss_att 11.865314 loss_ctc 16.864483 loss_rnnt 6.650050 hw_loss 0.342720 lr 0.00029350 rank 1
2023-03-01 04:48:39,493 DEBUG TRAIN Batch 49/1200 loss 4.186757 loss_att 6.055904 loss_ctc 7.605096 loss_rnnt 3.215885 hw_loss 0.264869 lr 0.00029350 rank 0
2023-03-01 04:48:39,496 DEBUG TRAIN Batch 49/1200 loss 9.833666 loss_att 11.526344 loss_ctc 12.642928 loss_rnnt 8.990615 hw_loss 0.243652 lr 0.00029350 rank 5
2023-03-01 04:48:39,496 DEBUG TRAIN Batch 49/1200 loss 4.641982 loss_att 7.624312 loss_ctc 11.634233 loss_rnnt 2.954927 hw_loss 0.296792 lr 0.00029349 rank 7
2023-03-01 04:48:39,496 DEBUG TRAIN Batch 49/1200 loss 2.594695 loss_att 4.387876 loss_ctc 4.262479 loss_rnnt 1.891087 hw_loss 0.229876 lr 0.00029350 rank 2
2023-03-01 04:48:39,498 DEBUG TRAIN Batch 49/1200 loss 8.081127 loss_att 10.220657 loss_ctc 14.582761 loss_rnnt 6.705069 hw_loss 0.152378 lr 0.00029350 rank 4
2023-03-01 04:48:39,500 DEBUG TRAIN Batch 49/1200 loss 4.770410 loss_att 9.889682 loss_ctc 10.174393 loss_rnnt 2.911316 hw_loss 0.215078 lr 0.00029350 rank 6
2023-03-01 04:48:39,502 DEBUG TRAIN Batch 49/1200 loss 3.635660 loss_att 4.618814 loss_ctc 6.791156 loss_rnnt 2.860426 hw_loss 0.296007 lr 0.00029349 rank 3
2023-03-01 04:49:18,102 DEBUG TRAIN Batch 49/1300 loss 2.280410 loss_att 4.494257 loss_ctc 3.685888 loss_rnnt 1.568757 hw_loss 0.152786 lr 0.00029349 rank 0
2023-03-01 04:49:18,102 DEBUG TRAIN Batch 49/1300 loss 7.210785 loss_att 9.483575 loss_ctc 12.772113 loss_rnnt 5.829851 hw_loss 0.346624 lr 0.00029348 rank 4
2023-03-01 04:49:18,102 DEBUG TRAIN Batch 49/1300 loss 6.026698 loss_att 8.134384 loss_ctc 9.144827 loss_rnnt 5.050765 hw_loss 0.259958 lr 0.00029348 rank 1
2023-03-01 04:49:18,106 DEBUG TRAIN Batch 49/1300 loss 3.510020 loss_att 7.214960 loss_ctc 8.048859 loss_rnnt 2.082723 hw_loss 0.152120 lr 0.00029348 rank 7
2023-03-01 04:49:18,108 DEBUG TRAIN Batch 49/1300 loss 6.346843 loss_att 7.371373 loss_ctc 11.198946 loss_rnnt 5.307887 hw_loss 0.350820 lr 0.00029349 rank 6
2023-03-01 04:49:18,108 DEBUG TRAIN Batch 49/1300 loss 2.709684 loss_att 6.696649 loss_ctc 4.149711 loss_rnnt 1.599066 hw_loss 0.227292 lr 0.00029348 rank 5
2023-03-01 04:49:18,138 DEBUG TRAIN Batch 49/1300 loss 5.218128 loss_att 9.379351 loss_ctc 10.410101 loss_rnnt 3.545967 hw_loss 0.276849 lr 0.00029348 rank 3
2023-03-01 04:49:18,143 DEBUG TRAIN Batch 49/1300 loss 4.301086 loss_att 5.555958 loss_ctc 7.578139 loss_rnnt 3.452657 hw_loss 0.300964 lr 0.00029349 rank 2
2023-03-01 04:49:57,850 DEBUG TRAIN Batch 49/1400 loss 2.213402 loss_att 4.686960 loss_ctc 2.420163 loss_rnnt 1.528020 hw_loss 0.305816 lr 0.00029347 rank 6
2023-03-01 04:49:57,850 DEBUG TRAIN Batch 49/1400 loss 3.618500 loss_att 8.021965 loss_ctc 7.206808 loss_rnnt 2.129794 hw_loss 0.242949 lr 0.00029347 rank 4
2023-03-01 04:49:57,854 DEBUG TRAIN Batch 49/1400 loss 8.388796 loss_att 11.846304 loss_ctc 16.374538 loss_rnnt 6.561209 hw_loss 0.133723 lr 0.00029346 rank 7
2023-03-01 04:49:57,855 DEBUG TRAIN Batch 49/1400 loss 10.884501 loss_att 12.757530 loss_ctc 16.116001 loss_rnnt 9.692525 hw_loss 0.224692 lr 0.00029347 rank 2
2023-03-01 04:49:57,864 DEBUG TRAIN Batch 49/1400 loss 7.967587 loss_att 13.896201 loss_ctc 13.825229 loss_rnnt 5.895060 hw_loss 0.198347 lr 0.00029348 rank 0
2023-03-01 04:49:57,865 DEBUG TRAIN Batch 49/1400 loss 6.991382 loss_att 7.076805 loss_ctc 11.151501 loss_rnnt 6.278581 hw_loss 0.264437 lr 0.00029347 rank 3
2023-03-01 04:49:57,879 DEBUG TRAIN Batch 49/1400 loss 4.683933 loss_att 7.753341 loss_ctc 7.103845 loss_rnnt 3.598209 hw_loss 0.279727 lr 0.00029347 rank 1
2023-03-01 04:49:57,893 DEBUG TRAIN Batch 49/1400 loss 10.468742 loss_att 12.607088 loss_ctc 22.216034 loss_rnnt 8.317219 hw_loss 0.295402 lr 0.00029347 rank 5
2023-03-01 04:51:02,270 DEBUG TRAIN Batch 49/1500 loss 4.623587 loss_att 8.284696 loss_ctc 7.304048 loss_rnnt 3.487553 hw_loss 0.087032 lr 0.00029346 rank 5
2023-03-01 04:51:02,282 DEBUG TRAIN Batch 49/1500 loss 11.150303 loss_att 14.663977 loss_ctc 16.377014 loss_rnnt 9.698365 hw_loss 0.098077 lr 0.00029346 rank 1
2023-03-01 04:51:02,282 DEBUG TRAIN Batch 49/1500 loss 3.710641 loss_att 6.705984 loss_ctc 5.295251 loss_rnnt 2.781340 hw_loss 0.223032 lr 0.00029346 rank 4
2023-03-01 04:51:02,282 DEBUG TRAIN Batch 49/1500 loss 5.083121 loss_att 7.962962 loss_ctc 10.805102 loss_rnnt 3.613580 hw_loss 0.244955 lr 0.00029345 rank 7
2023-03-01 04:51:02,282 DEBUG TRAIN Batch 49/1500 loss 5.784668 loss_att 9.021514 loss_ctc 7.237451 loss_rnnt 4.786461 hw_loss 0.294627 lr 0.00029346 rank 0
2023-03-01 04:51:02,283 DEBUG TRAIN Batch 49/1500 loss 4.770998 loss_att 10.112591 loss_ctc 10.420810 loss_rnnt 2.870200 hw_loss 0.148445 lr 0.00029346 rank 2
2023-03-01 04:51:02,283 DEBUG TRAIN Batch 49/1500 loss 5.581432 loss_att 9.160160 loss_ctc 13.041553 loss_rnnt 3.778654 hw_loss 0.173158 lr 0.00029345 rank 3
2023-03-01 04:51:02,287 DEBUG TRAIN Batch 49/1500 loss 4.146809 loss_att 7.352931 loss_ctc 7.109991 loss_rnnt 2.985389 hw_loss 0.234572 lr 0.00029346 rank 6
2023-03-01 04:51:40,149 DEBUG TRAIN Batch 49/1600 loss 7.035591 loss_att 10.910821 loss_ctc 12.223579 loss_rnnt 5.421621 hw_loss 0.275984 lr 0.00029345 rank 0
2023-03-01 04:51:40,151 DEBUG TRAIN Batch 49/1600 loss 7.553901 loss_att 10.472273 loss_ctc 15.988977 loss_rnnt 5.682495 hw_loss 0.305728 lr 0.00029345 rank 6
2023-03-01 04:51:40,152 DEBUG TRAIN Batch 49/1600 loss 7.858366 loss_att 9.284190 loss_ctc 12.456980 loss_rnnt 6.861564 hw_loss 0.184667 lr 0.00029345 rank 5
2023-03-01 04:51:40,155 DEBUG TRAIN Batch 49/1600 loss 3.649330 loss_att 6.543625 loss_ctc 5.896389 loss_rnnt 2.645101 hw_loss 0.235803 lr 0.00029345 rank 2
2023-03-01 04:51:40,157 DEBUG TRAIN Batch 49/1600 loss 5.508188 loss_att 8.506716 loss_ctc 9.910352 loss_rnnt 4.267593 hw_loss 0.101127 lr 0.00029344 rank 7
2023-03-01 04:51:40,174 DEBUG TRAIN Batch 49/1600 loss 11.740273 loss_att 11.850568 loss_ctc 13.315653 loss_rnnt 11.376896 hw_loss 0.246126 lr 0.00029345 rank 1
2023-03-01 04:51:40,185 DEBUG TRAIN Batch 49/1600 loss 5.703502 loss_att 8.093900 loss_ctc 9.549767 loss_rnnt 4.573761 hw_loss 0.260296 lr 0.00029344 rank 3
2023-03-01 04:51:40,186 DEBUG TRAIN Batch 49/1600 loss 9.578263 loss_att 13.150927 loss_ctc 19.682434 loss_rnnt 7.358412 hw_loss 0.296428 lr 0.00029345 rank 4
2023-03-01 04:52:19,060 DEBUG TRAIN Batch 49/1700 loss 3.922973 loss_att 7.727978 loss_ctc 4.746787 loss_rnnt 2.974291 hw_loss 0.145950 lr 0.00029344 rank 0
2023-03-01 04:52:19,065 DEBUG TRAIN Batch 49/1700 loss 6.676540 loss_att 9.578259 loss_ctc 9.687478 loss_rnnt 5.650581 hw_loss 0.082793 lr 0.00029343 rank 6
2023-03-01 04:52:19,068 DEBUG TRAIN Batch 49/1700 loss 4.957081 loss_att 7.453835 loss_ctc 9.988178 loss_rnnt 3.720023 hw_loss 0.125427 lr 0.00029343 rank 3
2023-03-01 04:52:19,075 DEBUG TRAIN Batch 49/1700 loss 3.502810 loss_att 7.249466 loss_ctc 7.847713 loss_rnnt 2.073431 hw_loss 0.188865 lr 0.00029343 rank 1
2023-03-01 04:52:19,076 DEBUG TRAIN Batch 49/1700 loss 8.532036 loss_att 10.675117 loss_ctc 13.954515 loss_rnnt 7.288800 hw_loss 0.171793 lr 0.00029343 rank 2
2023-03-01 04:52:19,076 DEBUG TRAIN Batch 49/1700 loss 6.162359 loss_att 9.992990 loss_ctc 9.880852 loss_rnnt 4.766553 hw_loss 0.251025 lr 0.00029342 rank 7
2023-03-01 04:52:19,085 DEBUG TRAIN Batch 49/1700 loss 4.463204 loss_att 7.947457 loss_ctc 13.792618 loss_rnnt 2.456031 hw_loss 0.124501 lr 0.00029343 rank 5
2023-03-01 04:52:19,126 DEBUG TRAIN Batch 49/1700 loss 7.505259 loss_att 9.840782 loss_ctc 14.870908 loss_rnnt 5.861985 hw_loss 0.363903 lr 0.00029343 rank 4
2023-03-01 04:53:24,949 DEBUG TRAIN Batch 49/1800 loss 3.388081 loss_att 6.501263 loss_ctc 5.631465 loss_rnnt 2.353921 hw_loss 0.210762 lr 0.00029342 rank 0
2023-03-01 04:53:24,951 DEBUG TRAIN Batch 49/1800 loss 7.248448 loss_att 9.854217 loss_ctc 15.072005 loss_rnnt 5.537932 hw_loss 0.274164 lr 0.00029342 rank 5
2023-03-01 04:53:24,951 DEBUG TRAIN Batch 49/1800 loss 8.109550 loss_att 9.369622 loss_ctc 10.803786 loss_rnnt 7.438962 hw_loss 0.111266 lr 0.00029342 rank 1
2023-03-01 04:53:24,951 DEBUG TRAIN Batch 49/1800 loss 4.510839 loss_att 6.891324 loss_ctc 8.605994 loss_rnnt 3.353810 hw_loss 0.252958 lr 0.00029341 rank 7
2023-03-01 04:53:24,952 DEBUG TRAIN Batch 49/1800 loss 4.719846 loss_att 8.882945 loss_ctc 10.632896 loss_rnnt 2.979650 hw_loss 0.223441 lr 0.00029342 rank 6
2023-03-01 04:53:24,955 DEBUG TRAIN Batch 49/1800 loss 10.606030 loss_att 12.827473 loss_ctc 18.523560 loss_rnnt 8.911965 hw_loss 0.363946 lr 0.00029342 rank 4
2023-03-01 04:53:24,957 DEBUG TRAIN Batch 49/1800 loss 2.213084 loss_att 5.770846 loss_ctc 5.899703 loss_rnnt 0.899298 hw_loss 0.207533 lr 0.00029342 rank 3
2023-03-01 04:53:24,959 DEBUG TRAIN Batch 49/1800 loss 7.897935 loss_att 10.130627 loss_ctc 9.282084 loss_rnnt 7.094459 hw_loss 0.323221 lr 0.00029342 rank 2
2023-03-01 04:54:03,995 DEBUG TRAIN Batch 49/1900 loss 8.647058 loss_att 11.257963 loss_ctc 14.207405 loss_rnnt 7.252926 hw_loss 0.244821 lr 0.00029340 rank 3
2023-03-01 04:54:04,005 DEBUG TRAIN Batch 49/1900 loss 5.668861 loss_att 7.367973 loss_ctc 8.702292 loss_rnnt 4.743465 hw_loss 0.339594 lr 0.00029341 rank 0
2023-03-01 04:54:04,006 DEBUG TRAIN Batch 49/1900 loss 9.369749 loss_att 9.754821 loss_ctc 13.233355 loss_rnnt 8.531475 hw_loss 0.461459 lr 0.00029341 rank 5
2023-03-01 04:54:04,007 DEBUG TRAIN Batch 49/1900 loss 6.300905 loss_att 7.828344 loss_ctc 9.628818 loss_rnnt 5.358564 hw_loss 0.362123 lr 0.00029340 rank 7
2023-03-01 04:54:04,013 DEBUG TRAIN Batch 49/1900 loss 5.062922 loss_att 5.666800 loss_ctc 7.392349 loss_rnnt 4.459251 hw_loss 0.323072 lr 0.00029341 rank 6
2023-03-01 04:54:04,015 DEBUG TRAIN Batch 49/1900 loss 3.840911 loss_att 5.794817 loss_ctc 7.397011 loss_rnnt 2.848596 hw_loss 0.238850 lr 0.00029341 rank 4
2023-03-01 04:54:04,035 DEBUG TRAIN Batch 49/1900 loss 6.703646 loss_att 7.504735 loss_ctc 11.349672 loss_rnnt 5.688649 hw_loss 0.441205 lr 0.00029341 rank 1
2023-03-01 04:54:04,042 DEBUG TRAIN Batch 49/1900 loss 4.643198 loss_att 7.513741 loss_ctc 8.073683 loss_rnnt 3.449376 hw_loss 0.304341 lr 0.00029341 rank 2
2023-03-01 04:54:41,943 DEBUG TRAIN Batch 49/2000 loss 5.863349 loss_att 9.378284 loss_ctc 11.376338 loss_rnnt 4.408527 hw_loss 0.031445 lr 0.00029339 rank 5
2023-03-01 04:54:41,944 DEBUG TRAIN Batch 49/2000 loss 8.756653 loss_att 10.467319 loss_ctc 13.086535 loss_rnnt 7.752271 hw_loss 0.159244 lr 0.00029340 rank 0
2023-03-01 04:54:41,945 DEBUG TRAIN Batch 49/2000 loss 2.930012 loss_att 5.290805 loss_ctc 4.388074 loss_rnnt 2.124445 hw_loss 0.260623 lr 0.00029339 rank 7
2023-03-01 04:54:41,946 DEBUG TRAIN Batch 49/2000 loss 4.473005 loss_att 7.029248 loss_ctc 12.636717 loss_rnnt 2.796958 hw_loss 0.143066 lr 0.00029340 rank 6
2023-03-01 04:54:41,947 DEBUG TRAIN Batch 49/2000 loss 4.131962 loss_att 7.565805 loss_ctc 12.852908 loss_rnnt 2.189636 hw_loss 0.173932 lr 0.00029339 rank 1
2023-03-01 04:54:41,955 DEBUG TRAIN Batch 49/2000 loss 4.814279 loss_att 5.567278 loss_ctc 6.960747 loss_rnnt 4.261856 hw_loss 0.216801 lr 0.00029340 rank 2
2023-03-01 04:54:41,955 DEBUG TRAIN Batch 49/2000 loss 1.431475 loss_att 3.838490 loss_ctc 2.226153 loss_rnnt 0.745516 hw_loss 0.184872 lr 0.00029339 rank 3
2023-03-01 04:54:41,999 DEBUG TRAIN Batch 49/2000 loss 7.173818 loss_att 6.792312 loss_ctc 10.671025 loss_rnnt 6.606190 hw_loss 0.333066 lr 0.00029340 rank 4
2023-03-01 04:55:21,475 DEBUG TRAIN Batch 49/2100 loss 6.942167 loss_att 7.031446 loss_ctc 7.712034 loss_rnnt 6.744189 hw_loss 0.145261 lr 0.00029338 rank 6
2023-03-01 04:55:21,476 DEBUG TRAIN Batch 49/2100 loss 1.340075 loss_att 4.150161 loss_ctc 2.063900 loss_rnnt 0.589834 hw_loss 0.171962 lr 0.00029338 rank 2
2023-03-01 04:55:21,479 DEBUG TRAIN Batch 49/2100 loss 14.280559 loss_att 17.198347 loss_ctc 22.484371 loss_rnnt 12.501304 hw_loss 0.190981 lr 0.00029338 rank 3
2023-03-01 04:55:21,486 DEBUG TRAIN Batch 49/2100 loss 4.430630 loss_att 7.382566 loss_ctc 10.105884 loss_rnnt 2.877342 hw_loss 0.386625 lr 0.00029338 rank 1
2023-03-01 04:55:21,487 DEBUG TRAIN Batch 49/2100 loss 6.216043 loss_att 7.135255 loss_ctc 10.237657 loss_rnnt 5.388147 hw_loss 0.202200 lr 0.00029337 rank 7
2023-03-01 04:55:21,489 DEBUG TRAIN Batch 49/2100 loss 6.775660 loss_att 10.862751 loss_ctc 12.573181 loss_rnnt 5.115226 hw_loss 0.131274 lr 0.00029339 rank 0
2023-03-01 04:55:21,502 DEBUG TRAIN Batch 49/2100 loss 4.065806 loss_att 6.240351 loss_ctc 7.758211 loss_rnnt 3.056342 hw_loss 0.154189 lr 0.00029338 rank 5
2023-03-01 04:55:21,516 DEBUG TRAIN Batch 49/2100 loss 3.123989 loss_att 5.986861 loss_ctc 3.310261 loss_rnnt 2.421630 hw_loss 0.196778 lr 0.00029338 rank 4
2023-03-01 04:56:26,387 DEBUG TRAIN Batch 49/2200 loss 5.210680 loss_att 8.678073 loss_ctc 8.790133 loss_rnnt 3.865706 hw_loss 0.326689 lr 0.00029337 rank 0
2023-03-01 04:56:26,405 DEBUG TRAIN Batch 49/2200 loss 3.238018 loss_att 7.232557 loss_ctc 7.372992 loss_rnnt 1.722359 hw_loss 0.310165 lr 0.00029337 rank 6
2023-03-01 04:56:26,408 DEBUG TRAIN Batch 49/2200 loss 8.222299 loss_att 10.672743 loss_ctc 18.413990 loss_rnnt 6.271524 hw_loss 0.190862 lr 0.00029336 rank 7
2023-03-01 04:56:26,408 DEBUG TRAIN Batch 49/2200 loss 1.884486 loss_att 4.233039 loss_ctc 2.472061 loss_rnnt 1.197712 hw_loss 0.260100 lr 0.00029337 rank 4
2023-03-01 04:56:26,410 DEBUG TRAIN Batch 49/2200 loss 2.828372 loss_att 4.624688 loss_ctc 7.715369 loss_rnnt 1.679060 hw_loss 0.259591 lr 0.00029337 rank 2
2023-03-01 04:56:26,426 DEBUG TRAIN Batch 49/2200 loss 6.762271 loss_att 11.146420 loss_ctc 14.254839 loss_rnnt 4.732299 hw_loss 0.289000 lr 0.00029337 rank 1
2023-03-01 04:56:26,433 DEBUG TRAIN Batch 49/2200 loss 3.901504 loss_att 7.311368 loss_ctc 5.967978 loss_rnnt 2.882181 hw_loss 0.115913 lr 0.00029337 rank 5
2023-03-01 04:56:26,441 DEBUG TRAIN Batch 49/2200 loss 4.566813 loss_att 6.970854 loss_ctc 9.044748 loss_rnnt 3.444446 hw_loss 0.083439 lr 0.00029337 rank 3
2023-03-01 04:57:04,756 DEBUG TRAIN Batch 49/2300 loss 5.243794 loss_att 8.989233 loss_ctc 8.746309 loss_rnnt 3.933409 hw_loss 0.176803 lr 0.00029336 rank 6
2023-03-01 04:57:04,769 DEBUG TRAIN Batch 49/2300 loss 7.733478 loss_att 9.730698 loss_ctc 17.540943 loss_rnnt 5.897057 hw_loss 0.242467 lr 0.00029336 rank 5
2023-03-01 04:57:04,771 DEBUG TRAIN Batch 49/2300 loss 3.029706 loss_att 5.856386 loss_ctc 5.696270 loss_rnnt 1.973582 hw_loss 0.253586 lr 0.00029336 rank 2
2023-03-01 04:57:04,771 DEBUG TRAIN Batch 49/2300 loss 5.316260 loss_att 8.390363 loss_ctc 8.507067 loss_rnnt 4.205654 hw_loss 0.131896 lr 0.00029335 rank 3
2023-03-01 04:57:04,771 DEBUG TRAIN Batch 49/2300 loss 8.560390 loss_att 11.101907 loss_ctc 17.163858 loss_rnnt 6.794038 hw_loss 0.207975 lr 0.00029335 rank 7
2023-03-01 04:57:04,773 DEBUG TRAIN Batch 49/2300 loss 8.495703 loss_att 10.984103 loss_ctc 15.323544 loss_rnnt 7.000012 hw_loss 0.164307 lr 0.00029336 rank 0
2023-03-01 04:57:04,782 DEBUG TRAIN Batch 49/2300 loss 12.040442 loss_att 17.040588 loss_ctc 24.898621 loss_rnnt 9.192513 hw_loss 0.250268 lr 0.00029336 rank 1
2023-03-01 04:57:04,817 DEBUG TRAIN Batch 49/2300 loss 6.362391 loss_att 7.717047 loss_ctc 8.401884 loss_rnnt 5.702209 hw_loss 0.219974 lr 0.00029336 rank 4
2023-03-01 04:57:43,639 DEBUG TRAIN Batch 49/2400 loss 7.537852 loss_att 10.841938 loss_ctc 15.374176 loss_rnnt 5.714215 hw_loss 0.221204 lr 0.00029335 rank 2
2023-03-01 04:57:43,641 DEBUG TRAIN Batch 49/2400 loss 6.849922 loss_att 9.614998 loss_ctc 7.897652 loss_rnnt 5.978079 hw_loss 0.335867 lr 0.00029334 rank 1
2023-03-01 04:57:43,649 DEBUG TRAIN Batch 49/2400 loss 7.370660 loss_att 9.737380 loss_ctc 11.598372 loss_rnnt 6.212551 hw_loss 0.227007 lr 0.00029334 rank 7
2023-03-01 04:57:43,654 DEBUG TRAIN Batch 49/2400 loss 7.675078 loss_att 9.048080 loss_ctc 10.113611 loss_rnnt 6.989753 hw_loss 0.160477 lr 0.00029335 rank 0
2023-03-01 04:57:43,655 DEBUG TRAIN Batch 49/2400 loss 7.220576 loss_att 10.513046 loss_ctc 11.541925 loss_rnnt 5.902120 hw_loss 0.157092 lr 0.00029334 rank 4
2023-03-01 04:57:43,671 DEBUG TRAIN Batch 49/2400 loss 9.165814 loss_att 11.901936 loss_ctc 15.769382 loss_rnnt 7.645727 hw_loss 0.173224 lr 0.00029334 rank 3
2023-03-01 04:57:43,686 DEBUG TRAIN Batch 49/2400 loss 5.148986 loss_att 8.394152 loss_ctc 8.365661 loss_rnnt 3.843077 hw_loss 0.427475 lr 0.00029334 rank 5
2023-03-01 04:57:43,730 DEBUG TRAIN Batch 49/2400 loss 7.956282 loss_att 10.092524 loss_ctc 7.990571 loss_rnnt 7.407552 hw_loss 0.219204 lr 0.00029335 rank 6
2023-03-01 04:58:49,600 DEBUG TRAIN Batch 49/2500 loss 5.401668 loss_att 8.003178 loss_ctc 9.342444 loss_rnnt 4.161833 hw_loss 0.363929 lr 0.00029334 rank 0
2023-03-01 04:58:49,603 DEBUG TRAIN Batch 49/2500 loss 6.874554 loss_att 8.701054 loss_ctc 11.637075 loss_rnnt 5.736838 hw_loss 0.257648 lr 0.00029333 rank 2
2023-03-01 04:58:49,608 DEBUG TRAIN Batch 49/2500 loss 2.523019 loss_att 3.830374 loss_ctc 4.566719 loss_rnnt 1.804817 hw_loss 0.345446 lr 0.00029332 rank 7
2023-03-01 04:58:49,609 DEBUG TRAIN Batch 49/2500 loss 3.037128 loss_att 4.218717 loss_ctc 4.382425 loss_rnnt 2.460431 hw_loss 0.301889 lr 0.00029333 rank 6
2023-03-01 04:58:49,610 DEBUG TRAIN Batch 49/2500 loss 10.130468 loss_att 12.339851 loss_ctc 16.422657 loss_rnnt 8.759455 hw_loss 0.169084 lr 0.00029333 rank 1
2023-03-01 04:58:49,610 DEBUG TRAIN Batch 49/2500 loss 2.668981 loss_att 5.606775 loss_ctc 8.323932 loss_rnnt 1.164696 hw_loss 0.305124 lr 0.00029333 rank 4
2023-03-01 04:58:49,611 DEBUG TRAIN Batch 49/2500 loss 4.340359 loss_att 6.046056 loss_ctc 6.616735 loss_rnnt 3.552819 hw_loss 0.267907 lr 0.00029333 rank 3
2023-03-01 04:58:49,616 DEBUG TRAIN Batch 49/2500 loss 6.686622 loss_att 7.171710 loss_ctc 11.089194 loss_rnnt 5.831362 hw_loss 0.321059 lr 0.00029333 rank 5
2023-03-01 04:59:28,043 DEBUG TRAIN Batch 49/2600 loss 5.185867 loss_att 6.588928 loss_ctc 5.760936 loss_rnnt 4.727604 hw_loss 0.189327 lr 0.00029332 rank 1
2023-03-01 04:59:28,060 DEBUG TRAIN Batch 49/2600 loss 2.533134 loss_att 5.865381 loss_ctc 3.006896 loss_rnnt 1.575742 hw_loss 0.427078 lr 0.00029331 rank 7
2023-03-01 04:59:28,061 DEBUG TRAIN Batch 49/2600 loss 7.356327 loss_att 7.951812 loss_ctc 11.458794 loss_rnnt 6.513070 hw_loss 0.332183 lr 0.00029332 rank 2
2023-03-01 04:59:28,061 DEBUG TRAIN Batch 49/2600 loss 12.851747 loss_att 15.064277 loss_ctc 17.640244 loss_rnnt 11.626259 hw_loss 0.270964 lr 0.00029331 rank 3
2023-03-01 04:59:28,063 DEBUG TRAIN Batch 49/2600 loss 7.413673 loss_att 9.275246 loss_ctc 10.862019 loss_rnnt 6.440444 hw_loss 0.264630 lr 0.00029332 rank 4
2023-03-01 04:59:28,063 DEBUG TRAIN Batch 49/2600 loss 1.519423 loss_att 3.877161 loss_ctc 3.465504 loss_rnnt 0.679773 hw_loss 0.203673 lr 0.00029332 rank 6
2023-03-01 04:59:28,063 DEBUG TRAIN Batch 49/2600 loss 9.979422 loss_att 11.018878 loss_ctc 16.874683 loss_rnnt 8.724524 hw_loss 0.239319 lr 0.00029332 rank 5
2023-03-01 04:59:28,069 DEBUG TRAIN Batch 49/2600 loss 5.857928 loss_att 10.644586 loss_ctc 10.077983 loss_rnnt 4.244911 hw_loss 0.174398 lr 0.00029332 rank 0
2023-03-01 05:00:06,137 DEBUG TRAIN Batch 49/2700 loss 2.876586 loss_att 7.226795 loss_ctc 4.420845 loss_rnnt 1.657509 hw_loss 0.268378 lr 0.00029331 rank 4
2023-03-01 05:00:06,151 DEBUG TRAIN Batch 49/2700 loss 4.787923 loss_att 7.879512 loss_ctc 10.452082 loss_rnnt 3.343710 hw_loss 0.132514 lr 0.00029331 rank 0
2023-03-01 05:00:06,152 DEBUG TRAIN Batch 49/2700 loss 3.843654 loss_att 6.765376 loss_ctc 4.642998 loss_rnnt 2.910587 hw_loss 0.454019 lr 0.00029331 rank 5
2023-03-01 05:00:06,154 DEBUG TRAIN Batch 49/2700 loss 9.857805 loss_att 18.426216 loss_ctc 19.490084 loss_rnnt 6.683580 hw_loss 0.330447 lr 0.00029330 rank 7
2023-03-01 05:00:06,156 DEBUG TRAIN Batch 49/2700 loss 2.614881 loss_att 6.539645 loss_ctc 5.840889 loss_rnnt 1.190012 hw_loss 0.393341 lr 0.00029330 rank 3
2023-03-01 05:00:06,158 DEBUG TRAIN Batch 49/2700 loss 5.834520 loss_att 6.920737 loss_ctc 8.830360 loss_rnnt 5.079708 hw_loss 0.258982 lr 0.00029331 rank 2
2023-03-01 05:00:06,159 DEBUG TRAIN Batch 49/2700 loss 8.707584 loss_att 12.230412 loss_ctc 13.598480 loss_rnnt 7.240096 hw_loss 0.207755 lr 0.00029331 rank 6
2023-03-01 05:00:06,159 DEBUG TRAIN Batch 49/2700 loss 1.360328 loss_att 3.717243 loss_ctc 2.357966 loss_rnnt 0.613019 hw_loss 0.267953 lr 0.00029331 rank 1
2023-03-01 05:00:46,269 DEBUG TRAIN Batch 49/2800 loss 5.975094 loss_att 10.506552 loss_ctc 9.699665 loss_rnnt 4.505150 hw_loss 0.125706 lr 0.00029329 rank 1
2023-03-01 05:00:46,270 DEBUG TRAIN Batch 49/2800 loss 2.053378 loss_att 4.978749 loss_ctc 3.433166 loss_rnnt 1.173868 hw_loss 0.207122 lr 0.00029329 rank 3
2023-03-01 05:00:46,279 DEBUG TRAIN Batch 49/2800 loss 6.225349 loss_att 9.012895 loss_ctc 8.808582 loss_rnnt 5.232591 hw_loss 0.170282 lr 0.00029330 rank 0
2023-03-01 05:00:46,280 DEBUG TRAIN Batch 49/2800 loss 12.915568 loss_att 19.049038 loss_ctc 25.301205 loss_rnnt 9.956739 hw_loss 0.151344 lr 0.00029329 rank 4
2023-03-01 05:00:46,283 DEBUG TRAIN Batch 49/2800 loss 2.671241 loss_att 6.396983 loss_ctc 3.058312 loss_rnnt 1.755054 hw_loss 0.223929 lr 0.00029329 rank 7
2023-03-01 05:00:46,286 DEBUG TRAIN Batch 49/2800 loss 6.083180 loss_att 11.488811 loss_ctc 13.905105 loss_rnnt 3.796735 hw_loss 0.304494 lr 0.00029329 rank 5
2023-03-01 05:00:46,289 DEBUG TRAIN Batch 49/2800 loss 3.291390 loss_att 6.179604 loss_ctc 4.746293 loss_rnnt 2.384437 hw_loss 0.253730 lr 0.00029330 rank 6
2023-03-01 05:00:46,327 DEBUG TRAIN Batch 49/2800 loss 11.415923 loss_att 11.805210 loss_ctc 15.049164 loss_rnnt 10.792555 hw_loss 0.114525 lr 0.00029330 rank 2
2023-03-01 05:01:51,157 DEBUG TRAIN Batch 49/2900 loss 7.338370 loss_att 9.375597 loss_ctc 12.687080 loss_rnnt 6.133787 hw_loss 0.157455 lr 0.00029328 rank 1
2023-03-01 05:01:51,161 DEBUG TRAIN Batch 49/2900 loss 5.437016 loss_att 7.531769 loss_ctc 11.665139 loss_rnnt 4.105454 hw_loss 0.154116 lr 0.00029328 rank 3
2023-03-01 05:01:51,161 DEBUG TRAIN Batch 49/2900 loss 11.608713 loss_att 14.407743 loss_ctc 15.939411 loss_rnnt 10.340099 hw_loss 0.246341 lr 0.00029328 rank 2
2023-03-01 05:01:51,174 DEBUG TRAIN Batch 49/2900 loss 6.175181 loss_att 8.890635 loss_ctc 10.074115 loss_rnnt 5.025616 hw_loss 0.162405 lr 0.00029328 rank 6
2023-03-01 05:01:51,177 DEBUG TRAIN Batch 49/2900 loss 5.460602 loss_att 7.599377 loss_ctc 10.262571 loss_rnnt 4.210115 hw_loss 0.342131 lr 0.00029328 rank 5
2023-03-01 05:01:51,176 DEBUG TRAIN Batch 49/2900 loss 4.906662 loss_att 7.386595 loss_ctc 8.090402 loss_rnnt 3.930788 hw_loss 0.103855 lr 0.00029329 rank 0
2023-03-01 05:01:51,177 DEBUG TRAIN Batch 49/2900 loss 4.511592 loss_att 6.031572 loss_ctc 5.263865 loss_rnnt 4.032459 hw_loss 0.140314 lr 0.00029327 rank 7
2023-03-01 05:01:51,187 DEBUG TRAIN Batch 49/2900 loss 10.117014 loss_att 14.546034 loss_ctc 17.106071 loss_rnnt 8.214050 hw_loss 0.159910 lr 0.00029328 rank 4
2023-03-01 05:02:29,558 DEBUG TRAIN Batch 49/3000 loss 12.336770 loss_att 14.465604 loss_ctc 15.137625 loss_rnnt 11.454489 hw_loss 0.155752 lr 0.00029327 rank 4
2023-03-01 05:02:29,563 DEBUG TRAIN Batch 49/3000 loss 4.810399 loss_att 7.467038 loss_ctc 6.756618 loss_rnnt 3.959596 hw_loss 0.112462 lr 0.00029326 rank 3
2023-03-01 05:02:29,564 DEBUG TRAIN Batch 49/3000 loss 6.836264 loss_att 8.786926 loss_ctc 11.028279 loss_rnnt 5.761069 hw_loss 0.236488 lr 0.00029327 rank 2
2023-03-01 05:02:29,575 DEBUG TRAIN Batch 49/3000 loss 8.622485 loss_att 9.877088 loss_ctc 12.700763 loss_rnnt 7.640532 hw_loss 0.351118 lr 0.00029326 rank 7
2023-03-01 05:02:29,576 DEBUG TRAIN Batch 49/3000 loss 1.950505 loss_att 4.240665 loss_ctc 3.290895 loss_rnnt 1.232883 hw_loss 0.151633 lr 0.00029327 rank 0
2023-03-01 05:02:29,578 DEBUG TRAIN Batch 49/3000 loss 8.944248 loss_att 11.691439 loss_ctc 13.342948 loss_rnnt 7.652832 hw_loss 0.291537 lr 0.00029327 rank 6
2023-03-01 05:02:29,580 DEBUG TRAIN Batch 49/3000 loss 6.485461 loss_att 9.065489 loss_ctc 10.581478 loss_rnnt 5.265684 hw_loss 0.295567 lr 0.00029327 rank 5
2023-03-01 05:02:29,583 DEBUG TRAIN Batch 49/3000 loss 4.163955 loss_att 6.667665 loss_ctc 5.326281 loss_rnnt 3.465842 hw_loss 0.079488 lr 0.00029327 rank 1
2023-03-01 05:03:08,318 DEBUG TRAIN Batch 49/3100 loss 13.771477 loss_att 17.261559 loss_ctc 22.588175 loss_rnnt 11.862186 hw_loss 0.066962 lr 0.00029325 rank 3
2023-03-01 05:03:08,325 DEBUG TRAIN Batch 49/3100 loss 9.764972 loss_att 11.919950 loss_ctc 15.607773 loss_rnnt 8.376506 hw_loss 0.334555 lr 0.00029325 rank 7
2023-03-01 05:03:08,325 DEBUG TRAIN Batch 49/3100 loss 6.368903 loss_att 9.818259 loss_ctc 13.692312 loss_rnnt 4.558416 hw_loss 0.270302 lr 0.00029326 rank 2
2023-03-01 05:03:08,327 DEBUG TRAIN Batch 49/3100 loss 8.392967 loss_att 9.819093 loss_ctc 12.793737 loss_rnnt 7.354830 hw_loss 0.311517 lr 0.00029326 rank 6
2023-03-01 05:03:08,328 DEBUG TRAIN Batch 49/3100 loss 3.919797 loss_att 8.051768 loss_ctc 8.433152 loss_rnnt 2.332036 hw_loss 0.299222 lr 0.00029326 rank 5
2023-03-01 05:03:08,329 DEBUG TRAIN Batch 49/3100 loss 8.635441 loss_att 11.568588 loss_ctc 18.492765 loss_rnnt 6.639266 hw_loss 0.178567 lr 0.00029326 rank 0
2023-03-01 05:03:08,331 DEBUG TRAIN Batch 49/3100 loss 3.945081 loss_att 7.285326 loss_ctc 8.255363 loss_rnnt 2.535438 hw_loss 0.312919 lr 0.00029326 rank 4
2023-03-01 05:03:08,333 DEBUG TRAIN Batch 49/3100 loss 3.861512 loss_att 5.648568 loss_ctc 6.815622 loss_rnnt 3.046523 hw_loss 0.119430 lr 0.00029326 rank 1
2023-03-01 05:04:13,878 DEBUG TRAIN Batch 49/3200 loss 13.220555 loss_att 14.752148 loss_ctc 20.578808 loss_rnnt 11.850088 hw_loss 0.155718 lr 0.00029325 rank 0
2023-03-01 05:04:13,878 DEBUG TRAIN Batch 49/3200 loss 11.215439 loss_att 12.108871 loss_ctc 17.902189 loss_rnnt 9.956253 hw_loss 0.354247 lr 0.00029324 rank 3
2023-03-01 05:04:13,882 DEBUG TRAIN Batch 49/3200 loss 10.053107 loss_att 12.571718 loss_ctc 20.009623 loss_rnnt 8.087474 hw_loss 0.251955 lr 0.00029324 rank 7
2023-03-01 05:04:13,883 DEBUG TRAIN Batch 49/3200 loss 7.339376 loss_att 8.706408 loss_ctc 11.870605 loss_rnnt 6.354621 hw_loss 0.200972 lr 0.00029324 rank 1
2023-03-01 05:04:13,883 DEBUG TRAIN Batch 49/3200 loss 6.623501 loss_att 7.963695 loss_ctc 10.725128 loss_rnnt 5.697475 hw_loss 0.208320 lr 0.00029325 rank 2
2023-03-01 05:04:13,885 DEBUG TRAIN Batch 49/3200 loss 2.574948 loss_att 6.362262 loss_ctc 6.231841 loss_rnnt 1.161028 hw_loss 0.316634 lr 0.00029325 rank 6
2023-03-01 05:04:13,897 DEBUG TRAIN Batch 49/3200 loss 9.369814 loss_att 15.811195 loss_ctc 15.698486 loss_rnnt 7.058565 hw_loss 0.335905 lr 0.00029324 rank 5
2023-03-01 05:04:13,931 DEBUG TRAIN Batch 49/3200 loss 4.248252 loss_att 5.837313 loss_ctc 7.744426 loss_rnnt 3.390401 hw_loss 0.138529 lr 0.00029324 rank 4
2023-03-01 05:04:52,369 DEBUG TRAIN Batch 49/3300 loss 4.455822 loss_att 6.992319 loss_ctc 7.539011 loss_rnnt 3.455708 hw_loss 0.153230 lr 0.00029323 rank 2
2023-03-01 05:04:52,370 DEBUG TRAIN Batch 49/3300 loss 7.457541 loss_att 12.519229 loss_ctc 8.014820 loss_rnnt 6.186193 hw_loss 0.346326 lr 0.00029323 rank 4
2023-03-01 05:04:52,380 DEBUG TRAIN Batch 49/3300 loss 2.354227 loss_att 7.626709 loss_ctc 6.381393 loss_rnnt 0.715319 hw_loss 0.088979 lr 0.00029324 rank 0
2023-03-01 05:04:52,381 DEBUG TRAIN Batch 49/3300 loss 3.560765 loss_att 6.151073 loss_ctc 4.817831 loss_rnnt 2.766776 hw_loss 0.203096 lr 0.00029322 rank 7
2023-03-01 05:04:52,383 DEBUG TRAIN Batch 49/3300 loss 3.732673 loss_att 6.343976 loss_ctc 4.412032 loss_rnnt 3.067582 hw_loss 0.097968 lr 0.00029323 rank 5
2023-03-01 05:04:52,385 DEBUG TRAIN Batch 49/3300 loss 3.342538 loss_att 6.527921 loss_ctc 7.231187 loss_rnnt 2.096115 hw_loss 0.170362 lr 0.00029323 rank 6
2023-03-01 05:04:52,394 DEBUG TRAIN Batch 49/3300 loss 1.867746 loss_att 4.043228 loss_ctc 2.647532 loss_rnnt 1.196894 hw_loss 0.247096 lr 0.00029323 rank 1
2023-03-01 05:04:52,432 DEBUG TRAIN Batch 49/3300 loss 5.919656 loss_att 8.477362 loss_ctc 14.788788 loss_rnnt 4.126783 hw_loss 0.185214 lr 0.00029323 rank 3
2023-03-01 05:05:30,926 DEBUG TRAIN Batch 49/3400 loss 1.861574 loss_att 3.726046 loss_ctc 1.781100 loss_rnnt 1.422897 hw_loss 0.143461 lr 0.00029322 rank 5
2023-03-01 05:05:30,933 DEBUG TRAIN Batch 49/3400 loss 9.133750 loss_att 10.351122 loss_ctc 13.225489 loss_rnnt 8.299433 hw_loss 0.084897 lr 0.00029322 rank 2
2023-03-01 05:05:30,935 DEBUG TRAIN Batch 49/3400 loss 3.976328 loss_att 7.672649 loss_ctc 8.798880 loss_rnnt 2.402966 hw_loss 0.358296 lr 0.00029322 rank 4
2023-03-01 05:05:30,946 DEBUG TRAIN Batch 49/3400 loss 3.243861 loss_att 7.381276 loss_ctc 4.720934 loss_rnnt 2.079232 hw_loss 0.262882 lr 0.00029322 rank 1
2023-03-01 05:05:30,945 DEBUG TRAIN Batch 49/3400 loss 1.541251 loss_att 3.952370 loss_ctc 2.695567 loss_rnnt 0.767797 hw_loss 0.257479 lr 0.00029321 rank 7
2023-03-01 05:05:30,947 DEBUG TRAIN Batch 49/3400 loss 6.273650 loss_att 9.525046 loss_ctc 13.377955 loss_rnnt 4.611420 hw_loss 0.121331 lr 0.00029322 rank 0
2023-03-01 05:05:30,961 DEBUG TRAIN Batch 49/3400 loss 3.949022 loss_att 6.958864 loss_ctc 7.610788 loss_rnnt 2.716541 hw_loss 0.266769 lr 0.00029321 rank 3
2023-03-01 05:05:30,963 DEBUG TRAIN Batch 49/3400 loss 3.084141 loss_att 7.325029 loss_ctc 5.471477 loss_rnnt 1.774991 hw_loss 0.267488 lr 0.00029322 rank 6
2023-03-01 05:06:10,088 DEBUG TRAIN Batch 49/3500 loss 10.653650 loss_att 14.620747 loss_ctc 20.412483 loss_rnnt 8.449793 hw_loss 0.204862 lr 0.00029320 rank 7
2023-03-01 05:06:10,094 DEBUG TRAIN Batch 49/3500 loss 2.301215 loss_att 3.808569 loss_ctc 2.263392 loss_rnnt 1.906170 hw_loss 0.184907 lr 0.00029321 rank 2
2023-03-01 05:06:10,104 DEBUG TRAIN Batch 49/3500 loss 3.235624 loss_att 7.955717 loss_ctc 6.553165 loss_rnnt 1.683601 hw_loss 0.310623 lr 0.00029321 rank 4
2023-03-01 05:06:10,108 DEBUG TRAIN Batch 49/3500 loss 7.041496 loss_att 10.654643 loss_ctc 14.008070 loss_rnnt 5.312439 hw_loss 0.145408 lr 0.00029321 rank 0
2023-03-01 05:06:10,110 DEBUG TRAIN Batch 49/3500 loss 1.848234 loss_att 4.163569 loss_ctc 2.682078 loss_rnnt 1.144120 hw_loss 0.243501 lr 0.00029321 rank 1
2023-03-01 05:06:10,112 DEBUG TRAIN Batch 49/3500 loss 6.691173 loss_att 10.895611 loss_ctc 10.506366 loss_rnnt 5.294022 hw_loss 0.089195 lr 0.00029321 rank 5
2023-03-01 05:06:10,113 DEBUG TRAIN Batch 49/3500 loss 11.469513 loss_att 16.259272 loss_ctc 17.887520 loss_rnnt 9.489992 hw_loss 0.310940 lr 0.00029321 rank 6
2023-03-01 05:06:10,134 DEBUG TRAIN Batch 49/3500 loss 5.550111 loss_att 9.496170 loss_ctc 9.071004 loss_rnnt 4.201849 hw_loss 0.167997 lr 0.00029320 rank 3
2023-03-01 05:07:15,679 DEBUG TRAIN Batch 49/3600 loss 6.084107 loss_att 8.424309 loss_ctc 10.032549 loss_rnnt 5.003473 hw_loss 0.161503 lr 0.00029319 rank 6
2023-03-01 05:07:15,680 DEBUG TRAIN Batch 49/3600 loss 6.005702 loss_att 7.878729 loss_ctc 10.414105 loss_rnnt 4.896644 hw_loss 0.274998 lr 0.00029320 rank 0
2023-03-01 05:07:15,689 DEBUG TRAIN Batch 49/3600 loss 5.871543 loss_att 9.147115 loss_ctc 8.757580 loss_rnnt 4.787150 hw_loss 0.083388 lr 0.00029319 rank 4
2023-03-01 05:07:15,689 DEBUG TRAIN Batch 49/3600 loss 6.848473 loss_att 10.208822 loss_ctc 10.819963 loss_rnnt 5.587023 hw_loss 0.112213 lr 0.00029319 rank 3
2023-03-01 05:07:15,690 DEBUG TRAIN Batch 49/3600 loss 4.782155 loss_att 6.371013 loss_ctc 6.492832 loss_rnnt 4.091296 hw_loss 0.271869 lr 0.00029318 rank 7
2023-03-01 05:07:15,692 DEBUG TRAIN Batch 49/3600 loss 12.844589 loss_att 15.078035 loss_ctc 16.605408 loss_rnnt 11.742128 hw_loss 0.289367 lr 0.00029319 rank 5
2023-03-01 05:07:15,697 DEBUG TRAIN Batch 49/3600 loss 10.152032 loss_att 15.715473 loss_ctc 18.288548 loss_rnnt 7.824121 hw_loss 0.244415 lr 0.00029319 rank 2
2023-03-01 05:07:15,705 DEBUG TRAIN Batch 49/3600 loss 1.891721 loss_att 3.885261 loss_ctc 3.884696 loss_rnnt 1.158531 hw_loss 0.128910 lr 0.00029319 rank 1
2023-03-01 05:07:54,687 DEBUG TRAIN Batch 49/3700 loss 6.981732 loss_att 7.184716 loss_ctc 7.032882 loss_rnnt 6.815024 hw_loss 0.223672 lr 0.00029317 rank 7
2023-03-01 05:07:54,689 DEBUG TRAIN Batch 49/3700 loss 7.696146 loss_att 10.249763 loss_ctc 15.272768 loss_rnnt 6.022500 hw_loss 0.286323 lr 0.00029318 rank 6
2023-03-01 05:07:54,690 DEBUG TRAIN Batch 49/3700 loss 5.604891 loss_att 7.844165 loss_ctc 8.596760 loss_rnnt 4.615716 hw_loss 0.267008 lr 0.00029318 rank 0
2023-03-01 05:07:54,691 DEBUG TRAIN Batch 49/3700 loss 8.851323 loss_att 13.199898 loss_ctc 12.279856 loss_rnnt 7.354721 hw_loss 0.318281 lr 0.00029318 rank 2
2023-03-01 05:07:54,690 DEBUG TRAIN Batch 49/3700 loss 8.576843 loss_att 12.379221 loss_ctc 17.873516 loss_rnnt 6.391213 hw_loss 0.347996 lr 0.00029318 rank 3
2023-03-01 05:07:54,711 DEBUG TRAIN Batch 49/3700 loss 6.083353 loss_att 10.091846 loss_ctc 9.546338 loss_rnnt 4.747698 hw_loss 0.135421 lr 0.00029318 rank 4
2023-03-01 05:07:54,725 DEBUG TRAIN Batch 49/3700 loss 10.948256 loss_att 14.113445 loss_ctc 18.947983 loss_rnnt 9.208433 hw_loss 0.075290 lr 0.00029318 rank 1
2023-03-01 05:07:54,733 DEBUG TRAIN Batch 49/3700 loss 2.124191 loss_att 4.474361 loss_ctc 3.784518 loss_rnnt 1.341425 hw_loss 0.171290 lr 0.00029318 rank 5
2023-03-01 05:08:34,125 DEBUG TRAIN Batch 49/3800 loss 5.132040 loss_att 7.573911 loss_ctc 9.042446 loss_rnnt 4.005669 hw_loss 0.218643 lr 0.00029317 rank 5
2023-03-01 05:08:34,125 DEBUG TRAIN Batch 49/3800 loss 5.142931 loss_att 7.869971 loss_ctc 9.407351 loss_rnnt 3.860285 hw_loss 0.316216 lr 0.00029317 rank 2
2023-03-01 05:08:34,132 DEBUG TRAIN Batch 49/3800 loss 6.584589 loss_att 10.071648 loss_ctc 12.549411 loss_rnnt 5.037160 hw_loss 0.102577 lr 0.00029316 rank 7
2023-03-01 05:08:34,135 DEBUG TRAIN Batch 49/3800 loss 4.032451 loss_att 6.803670 loss_ctc 7.653232 loss_rnnt 2.866220 hw_loss 0.242280 lr 0.00029317 rank 4
2023-03-01 05:08:34,136 DEBUG TRAIN Batch 49/3800 loss 7.040524 loss_att 8.546761 loss_ctc 9.932885 loss_rnnt 6.189264 hw_loss 0.308182 lr 0.00029317 rank 1
2023-03-01 05:08:34,136 DEBUG TRAIN Batch 49/3800 loss 12.295544 loss_att 13.726934 loss_ctc 20.006756 loss_rnnt 10.749337 hw_loss 0.434561 lr 0.00029317 rank 0
2023-03-01 05:08:34,145 DEBUG TRAIN Batch 49/3800 loss 5.307085 loss_att 9.610651 loss_ctc 8.078623 loss_rnnt 3.960438 hw_loss 0.218240 lr 0.00029317 rank 6
2023-03-01 05:08:34,147 DEBUG TRAIN Batch 49/3800 loss 7.658892 loss_att 8.314645 loss_ctc 12.503647 loss_rnnt 6.645296 hw_loss 0.443397 lr 0.00029316 rank 3
2023-03-01 05:09:38,183 DEBUG TRAIN Batch 49/3900 loss 7.185013 loss_att 9.934989 loss_ctc 8.219332 loss_rnnt 6.442173 hw_loss 0.103005 lr 0.00029316 rank 2
2023-03-01 05:09:38,192 DEBUG TRAIN Batch 49/3900 loss 7.206127 loss_att 11.349525 loss_ctc 12.420333 loss_rnnt 5.681470 hw_loss 0.001404 lr 0.00029315 rank 7
2023-03-01 05:09:38,195 DEBUG TRAIN Batch 49/3900 loss 1.748500 loss_att 4.927987 loss_ctc 2.228071 loss_rnnt 1.021198 hw_loss 0.051490 lr 0.00029316 rank 6
2023-03-01 05:09:38,198 DEBUG TRAIN Batch 49/3900 loss 4.311750 loss_att 7.298062 loss_ctc 6.649249 loss_rnnt 3.251817 hw_loss 0.283135 lr 0.00029315 rank 3
2023-03-01 05:09:38,212 DEBUG TRAIN Batch 49/3900 loss 4.477685 loss_att 5.629596 loss_ctc 7.555508 loss_rnnt 3.769751 hw_loss 0.125954 lr 0.00029316 rank 4
2023-03-01 05:09:38,218 DEBUG TRAIN Batch 49/3900 loss 7.243289 loss_att 9.371099 loss_ctc 11.525919 loss_rnnt 6.161829 hw_loss 0.159152 lr 0.00029316 rank 5
2023-03-01 05:09:38,221 DEBUG TRAIN Batch 49/3900 loss 7.996180 loss_att 12.393314 loss_ctc 13.528648 loss_rnnt 6.264118 hw_loss 0.215574 lr 0.00029316 rank 1
2023-03-01 05:09:38,226 DEBUG TRAIN Batch 49/3900 loss 4.165646 loss_att 11.045239 loss_ctc 10.129440 loss_rnnt 1.868973 hw_loss 0.235466 lr 0.00029316 rank 0
2023-03-01 05:10:17,522 DEBUG TRAIN Batch 49/4000 loss 3.542701 loss_att 7.549982 loss_ctc 9.954916 loss_rnnt 1.735720 hw_loss 0.282304 lr 0.00029314 rank 2
2023-03-01 05:10:17,536 DEBUG TRAIN Batch 49/4000 loss 9.185218 loss_att 8.771298 loss_ctc 7.440826 loss_rnnt 9.312204 hw_loss 0.353218 lr 0.00029314 rank 4
2023-03-01 05:10:17,537 DEBUG TRAIN Batch 49/4000 loss 5.177411 loss_att 6.509584 loss_ctc 6.689284 loss_rnnt 4.579689 hw_loss 0.243194 lr 0.00029315 rank 0
2023-03-01 05:10:17,541 DEBUG TRAIN Batch 49/4000 loss 4.479259 loss_att 7.444395 loss_ctc 6.618913 loss_rnnt 3.423662 hw_loss 0.332404 lr 0.00029313 rank 7
2023-03-01 05:10:17,540 DEBUG TRAIN Batch 49/4000 loss 5.678151 loss_att 11.169679 loss_ctc 11.427792 loss_rnnt 3.701651 hw_loss 0.209203 lr 0.00029314 rank 3
2023-03-01 05:10:17,541 DEBUG TRAIN Batch 49/4000 loss 6.092195 loss_att 8.868000 loss_ctc 18.097713 loss_rnnt 3.860715 hw_loss 0.141718 lr 0.00029314 rank 6
2023-03-01 05:10:17,541 DEBUG TRAIN Batch 49/4000 loss 2.285409 loss_att 4.483330 loss_ctc 6.626858 loss_rnnt 1.096270 hw_loss 0.320053 lr 0.00029314 rank 1
2023-03-01 05:10:17,543 DEBUG TRAIN Batch 49/4000 loss 2.958874 loss_att 6.512319 loss_ctc 4.893622 loss_rnnt 1.943278 hw_loss 0.088013 lr 0.00029314 rank 5
2023-03-01 05:10:56,551 DEBUG TRAIN Batch 49/4100 loss 6.875705 loss_att 9.850300 loss_ctc 9.323277 loss_rnnt 5.815800 hw_loss 0.259955 lr 0.00029312 rank 7
2023-03-01 05:10:56,576 DEBUG TRAIN Batch 49/4100 loss 4.164752 loss_att 7.133379 loss_ctc 5.885963 loss_rnnt 3.240019 hw_loss 0.190338 lr 0.00029313 rank 0
2023-03-01 05:10:56,580 DEBUG TRAIN Batch 49/4100 loss 6.426017 loss_att 8.496101 loss_ctc 7.731604 loss_rnnt 5.663354 hw_loss 0.327314 lr 0.00029313 rank 1
2023-03-01 05:10:56,576 DEBUG TRAIN Batch 49/4100 loss 13.872787 loss_att 16.104692 loss_ctc 26.412689 loss_rnnt 11.617541 hw_loss 0.256646 lr 0.00029313 rank 5
2023-03-01 05:10:56,581 DEBUG TRAIN Batch 49/4100 loss 5.013114 loss_att 8.772703 loss_ctc 10.835979 loss_rnnt 3.239009 hw_loss 0.460885 lr 0.00029313 rank 4
2023-03-01 05:10:56,581 DEBUG TRAIN Batch 49/4100 loss 3.055518 loss_att 5.427028 loss_ctc 4.079615 loss_rnnt 2.343819 hw_loss 0.189097 lr 0.00029313 rank 2
2023-03-01 05:10:56,582 DEBUG TRAIN Batch 49/4100 loss 9.903049 loss_att 11.033850 loss_ctc 16.154448 loss_rnnt 8.642764 hw_loss 0.376134 lr 0.00029313 rank 6
2023-03-01 05:10:56,584 DEBUG TRAIN Batch 49/4100 loss 9.775089 loss_att 12.956513 loss_ctc 18.311916 loss_rnnt 7.821959 hw_loss 0.334880 lr 0.00029313 rank 3
2023-03-01 05:11:35,889 DEBUG TRAIN Batch 49/4200 loss 7.025981 loss_att 9.924932 loss_ctc 12.631701 loss_rnnt 5.552053 hw_loss 0.275078 lr 0.00029312 rank 0
2023-03-01 05:11:35,891 DEBUG TRAIN Batch 49/4200 loss 2.138724 loss_att 3.819529 loss_ctc 1.814379 loss_rnnt 1.698565 hw_loss 0.276084 lr 0.00029311 rank 7
2023-03-01 05:11:35,893 DEBUG TRAIN Batch 49/4200 loss 5.347484 loss_att 8.192592 loss_ctc 8.538641 loss_rnnt 4.320142 hw_loss 0.061561 lr 0.00029311 rank 3
2023-03-01 05:11:35,895 DEBUG TRAIN Batch 49/4200 loss 8.221339 loss_att 10.853061 loss_ctc 14.367622 loss_rnnt 6.782285 hw_loss 0.174761 lr 0.00029312 rank 2
2023-03-01 05:11:35,898 DEBUG TRAIN Batch 49/4200 loss 7.902269 loss_att 11.557839 loss_ctc 14.401953 loss_rnnt 6.147775 hw_loss 0.293918 lr 0.00029312 rank 4
2023-03-01 05:11:35,903 DEBUG TRAIN Batch 49/4200 loss 4.677141 loss_att 8.622219 loss_ctc 10.310658 loss_rnnt 3.034361 hw_loss 0.192429 lr 0.00029312 rank 5
2023-03-01 05:11:35,906 DEBUG TRAIN Batch 49/4200 loss 9.809395 loss_att 14.369921 loss_ctc 12.621715 loss_rnnt 8.365437 hw_loss 0.294145 lr 0.00029312 rank 1
2023-03-01 05:11:35,907 DEBUG TRAIN Batch 49/4200 loss 5.423462 loss_att 8.111662 loss_ctc 10.390029 loss_rnnt 4.072590 hw_loss 0.283169 lr 0.00029312 rank 6
2023-03-01 05:12:41,463 DEBUG TRAIN Batch 49/4300 loss 8.409317 loss_att 11.169932 loss_ctc 13.789186 loss_rnnt 6.999142 hw_loss 0.263880 lr 0.00029310 rank 1
2023-03-01 05:12:41,464 DEBUG TRAIN Batch 49/4300 loss 8.364923 loss_att 10.465875 loss_ctc 14.696680 loss_rnnt 6.913504 hw_loss 0.350616 lr 0.00029310 rank 5
2023-03-01 05:12:41,476 DEBUG TRAIN Batch 49/4300 loss 5.922145 loss_att 9.310323 loss_ctc 9.600020 loss_rnnt 4.645272 hw_loss 0.204100 lr 0.00029310 rank 7
2023-03-01 05:12:41,481 DEBUG TRAIN Batch 49/4300 loss 6.454104 loss_att 7.625523 loss_ctc 8.073759 loss_rnnt 5.808147 hw_loss 0.366975 lr 0.00029311 rank 6
2023-03-01 05:12:41,482 DEBUG TRAIN Batch 49/4300 loss 6.742624 loss_att 11.180706 loss_ctc 7.747789 loss_rnnt 5.507487 hw_loss 0.400309 lr 0.00029311 rank 4
2023-03-01 05:12:41,483 DEBUG TRAIN Batch 49/4300 loss 2.993634 loss_att 6.303885 loss_ctc 6.809989 loss_rnnt 1.688686 hw_loss 0.251345 lr 0.00029311 rank 0
2023-03-01 05:12:41,485 DEBUG TRAIN Batch 49/4300 loss 10.481969 loss_att 13.447162 loss_ctc 17.186018 loss_rnnt 8.893161 hw_loss 0.191055 lr 0.00029311 rank 2
2023-03-01 05:12:41,487 DEBUG TRAIN Batch 49/4300 loss 4.747906 loss_att 6.952658 loss_ctc 7.642348 loss_rnnt 3.754466 hw_loss 0.312308 lr 0.00029310 rank 3
2023-03-01 05:13:20,651 DEBUG TRAIN Batch 49/4400 loss 7.313621 loss_att 9.307021 loss_ctc 11.932885 loss_rnnt 6.227196 hw_loss 0.134706 lr 0.00029309 rank 2
2023-03-01 05:13:20,652 DEBUG TRAIN Batch 49/4400 loss 4.734736 loss_att 8.028960 loss_ctc 9.680789 loss_rnnt 3.252714 hw_loss 0.306945 lr 0.00029309 rank 4
2023-03-01 05:13:20,652 DEBUG TRAIN Batch 49/4400 loss 5.659779 loss_att 8.086914 loss_ctc 10.158790 loss_rnnt 4.460904 hw_loss 0.212962 lr 0.00029309 rank 3
2023-03-01 05:13:20,653 DEBUG TRAIN Batch 49/4400 loss 6.378716 loss_att 8.417840 loss_ctc 13.470319 loss_rnnt 4.853573 hw_loss 0.322070 lr 0.00029308 rank 7
2023-03-01 05:13:20,654 DEBUG TRAIN Batch 49/4400 loss 5.507303 loss_att 7.906112 loss_ctc 11.767019 loss_rnnt 4.054158 hw_loss 0.260164 lr 0.00029310 rank 0
2023-03-01 05:13:20,658 DEBUG TRAIN Batch 49/4400 loss 5.792258 loss_att 8.425638 loss_ctc 11.829050 loss_rnnt 4.356827 hw_loss 0.194715 lr 0.00029309 rank 6
2023-03-01 05:13:20,658 DEBUG TRAIN Batch 49/4400 loss 5.166310 loss_att 7.794748 loss_ctc 8.212387 loss_rnnt 4.070988 hw_loss 0.306546 lr 0.00029309 rank 1
2023-03-01 05:13:20,691 DEBUG TRAIN Batch 49/4400 loss 5.226965 loss_att 7.551834 loss_ctc 8.810005 loss_rnnt 4.161007 hw_loss 0.231084 lr 0.00029309 rank 5
2023-03-01 05:13:59,473 DEBUG TRAIN Batch 49/4500 loss 10.106828 loss_att 14.960562 loss_ctc 14.766978 loss_rnnt 8.388721 hw_loss 0.236264 lr 0.00029308 rank 6
2023-03-01 05:13:59,475 DEBUG TRAIN Batch 49/4500 loss 6.408797 loss_att 6.638847 loss_ctc 9.511209 loss_rnnt 5.771381 hw_loss 0.333281 lr 0.00029308 rank 4
2023-03-01 05:13:59,496 DEBUG TRAIN Batch 49/4500 loss 4.883999 loss_att 8.425692 loss_ctc 6.406530 loss_rnnt 3.889050 hw_loss 0.156762 lr 0.00029307 rank 7
2023-03-01 05:13:59,498 DEBUG TRAIN Batch 49/4500 loss 8.186108 loss_att 11.559774 loss_ctc 14.390921 loss_rnnt 6.558299 hw_loss 0.235814 lr 0.00029308 rank 0
2023-03-01 05:13:59,501 DEBUG TRAIN Batch 49/4500 loss 6.363093 loss_att 10.164441 loss_ctc 11.165882 loss_rnnt 4.783913 hw_loss 0.334760 lr 0.00029308 rank 2
2023-03-01 05:13:59,513 DEBUG TRAIN Batch 49/4500 loss 2.698222 loss_att 7.158218 loss_ctc 6.465715 loss_rnnt 1.242341 hw_loss 0.115405 lr 0.00029308 rank 3
2023-03-01 05:13:59,527 DEBUG TRAIN Batch 49/4500 loss 6.169656 loss_att 7.529806 loss_ctc 9.324135 loss_rnnt 5.286533 hw_loss 0.357181 lr 0.00029308 rank 1
2023-03-01 05:13:59,550 DEBUG TRAIN Batch 49/4500 loss 5.222208 loss_att 10.962543 loss_ctc 15.018082 loss_rnnt 2.593012 hw_loss 0.328146 lr 0.00029308 rank 5
2023-03-01 05:14:39,619 DEBUG TRAIN Batch 49/4600 loss 13.343173 loss_att 16.189106 loss_ctc 16.866388 loss_rnnt 12.185034 hw_loss 0.223485 lr 0.00029307 rank 1
2023-03-01 05:14:39,622 DEBUG TRAIN Batch 49/4600 loss 4.161242 loss_att 6.558944 loss_ctc 7.356001 loss_rnnt 3.085754 hw_loss 0.318711 lr 0.00029307 rank 4
2023-03-01 05:14:39,626 DEBUG TRAIN Batch 49/4600 loss 5.798274 loss_att 11.006812 loss_ctc 10.371244 loss_rnnt 4.008805 hw_loss 0.258808 lr 0.00029307 rank 6
2023-03-01 05:14:39,629 DEBUG TRAIN Batch 49/4600 loss 2.287864 loss_att 5.117836 loss_ctc 4.792307 loss_rnnt 1.301663 hw_loss 0.161775 lr 0.00029306 rank 3
2023-03-01 05:14:39,637 DEBUG TRAIN Batch 49/4600 loss 2.608650 loss_att 5.016338 loss_ctc 3.587576 loss_rnnt 1.931960 hw_loss 0.121179 lr 0.00029306 rank 7
2023-03-01 05:14:39,645 DEBUG TRAIN Batch 49/4600 loss 2.177517 loss_att 5.675597 loss_ctc 4.433555 loss_rnnt 1.064738 hw_loss 0.210673 lr 0.00029307 rank 0
2023-03-01 05:14:39,650 DEBUG TRAIN Batch 49/4600 loss 3.609444 loss_att 5.983721 loss_ctc 9.242868 loss_rnnt 2.313582 hw_loss 0.131031 lr 0.00029307 rank 2
2023-03-01 05:14:39,662 DEBUG TRAIN Batch 49/4600 loss 3.940335 loss_att 7.524851 loss_ctc 5.638574 loss_rnnt 2.836440 hw_loss 0.301050 lr 0.00029307 rank 5
2023-03-01 05:15:46,287 DEBUG TRAIN Batch 49/4700 loss 7.712503 loss_att 10.377029 loss_ctc 12.116140 loss_rnnt 6.475914 hw_loss 0.218497 lr 0.00029306 rank 6
2023-03-01 05:15:46,291 DEBUG TRAIN Batch 49/4700 loss 4.485927 loss_att 6.342835 loss_ctc 4.879662 loss_rnnt 4.032190 hw_loss 0.055981 lr 0.00029306 rank 0
2023-03-01 05:15:46,291 DEBUG TRAIN Batch 49/4700 loss 10.216829 loss_att 12.253435 loss_ctc 19.260374 loss_rnnt 8.498970 hw_loss 0.196370 lr 0.00029305 rank 4
2023-03-01 05:15:46,292 DEBUG TRAIN Batch 49/4700 loss 3.771056 loss_att 6.256333 loss_ctc 5.792181 loss_rnnt 2.876277 hw_loss 0.240451 lr 0.00029305 rank 7
2023-03-01 05:15:46,292 DEBUG TRAIN Batch 49/4700 loss 4.510871 loss_att 9.623560 loss_ctc 8.080549 loss_rnnt 2.806842 hw_loss 0.385376 lr 0.00029305 rank 3
2023-03-01 05:15:46,293 DEBUG TRAIN Batch 49/4700 loss 1.097742 loss_att 3.733510 loss_ctc 1.772334 loss_rnnt 0.340958 hw_loss 0.261910 lr 0.00029305 rank 1
2023-03-01 05:15:46,296 DEBUG TRAIN Batch 49/4700 loss 1.432000 loss_att 3.719770 loss_ctc 3.154048 loss_rnnt 0.593234 hw_loss 0.284261 lr 0.00029306 rank 2
2023-03-01 05:15:46,341 DEBUG TRAIN Batch 49/4700 loss 5.752166 loss_att 8.712161 loss_ctc 11.984921 loss_rnnt 4.229585 hw_loss 0.186652 lr 0.00029305 rank 5
2023-03-01 05:16:24,980 DEBUG TRAIN Batch 49/4800 loss 7.963928 loss_att 11.958067 loss_ctc 12.817175 loss_rnnt 6.432986 hw_loss 0.159403 lr 0.00029305 rank 0
2023-03-01 05:16:24,985 DEBUG TRAIN Batch 49/4800 loss 9.930850 loss_att 12.338510 loss_ctc 12.054853 loss_rnnt 9.152718 hw_loss 0.025124 lr 0.00029304 rank 2
2023-03-01 05:16:24,996 DEBUG TRAIN Batch 49/4800 loss 5.471059 loss_att 7.952430 loss_ctc 7.645504 loss_rnnt 4.592319 hw_loss 0.173513 lr 0.00029303 rank 7
2023-03-01 05:16:25,002 DEBUG TRAIN Batch 49/4800 loss 2.873298 loss_att 5.216688 loss_ctc 5.011791 loss_rnnt 2.002786 hw_loss 0.218815 lr 0.00029304 rank 5
2023-03-01 05:16:25,002 DEBUG TRAIN Batch 49/4800 loss 3.405231 loss_att 7.892597 loss_ctc 10.147089 loss_rnnt 1.509397 hw_loss 0.186464 lr 0.00029304 rank 4
2023-03-01 05:16:25,003 DEBUG TRAIN Batch 49/4800 loss 10.905519 loss_att 12.808311 loss_ctc 15.278042 loss_rnnt 9.828431 hw_loss 0.212861 lr 0.00029304 rank 6
2023-03-01 05:16:25,005 DEBUG TRAIN Batch 49/4800 loss 6.647192 loss_att 8.595886 loss_ctc 8.703315 loss_rnnt 5.910904 hw_loss 0.135749 lr 0.00029304 rank 1
2023-03-01 05:16:25,009 DEBUG TRAIN Batch 49/4800 loss 6.588935 loss_att 7.817420 loss_ctc 8.900352 loss_rnnt 5.932695 hw_loss 0.191914 lr 0.00029304 rank 3
2023-03-01 05:17:04,096 DEBUG TRAIN Batch 49/4900 loss 5.520238 loss_att 10.013579 loss_ctc 9.480117 loss_rnnt 3.989964 hw_loss 0.194293 lr 0.00029303 rank 1
2023-03-01 05:17:04,097 DEBUG TRAIN Batch 49/4900 loss 5.778214 loss_att 8.076070 loss_ctc 8.400965 loss_rnnt 4.791735 hw_loss 0.332264 lr 0.00029303 rank 5
2023-03-01 05:17:04,097 DEBUG TRAIN Batch 49/4900 loss 5.436413 loss_att 10.966770 loss_ctc 11.639440 loss_rnnt 3.391611 hw_loss 0.209361 lr 0.00029303 rank 6
2023-03-01 05:17:04,099 DEBUG TRAIN Batch 49/4900 loss 4.263247 loss_att 7.629276 loss_ctc 9.953756 loss_rnnt 2.776459 hw_loss 0.102839 lr 0.00029303 rank 2
2023-03-01 05:17:04,112 DEBUG TRAIN Batch 49/4900 loss 7.523366 loss_att 9.965424 loss_ctc 10.116303 loss_rnnt 6.595104 hw_loss 0.176487 lr 0.00029303 rank 0
2023-03-01 05:17:04,114 DEBUG TRAIN Batch 49/4900 loss 3.642071 loss_att 8.098281 loss_ctc 6.794423 loss_rnnt 2.173844 hw_loss 0.293760 lr 0.00029302 rank 7
2023-03-01 05:17:04,115 DEBUG TRAIN Batch 49/4900 loss 3.928189 loss_att 7.031471 loss_ctc 7.559853 loss_rnnt 2.730770 hw_loss 0.173514 lr 0.00029303 rank 4
2023-03-01 05:17:04,127 DEBUG TRAIN Batch 49/4900 loss 2.671218 loss_att 5.802192 loss_ctc 4.940981 loss_rnnt 1.594072 hw_loss 0.278093 lr 0.00029303 rank 3
2023-03-01 05:18:08,907 DEBUG TRAIN Batch 49/5000 loss 6.763732 loss_att 6.934508 loss_ctc 9.432473 loss_rnnt 6.276403 hw_loss 0.182514 lr 0.00029302 rank 1
2023-03-01 05:18:08,909 DEBUG TRAIN Batch 49/5000 loss 13.544436 loss_att 15.307579 loss_ctc 21.597450 loss_rnnt 12.015083 hw_loss 0.193103 lr 0.00029302 rank 0
2023-03-01 05:18:08,910 DEBUG TRAIN Batch 49/5000 loss 4.283738 loss_att 5.423291 loss_ctc 7.457610 loss_rnnt 3.507913 hw_loss 0.233871 lr 0.00029302 rank 5
2023-03-01 05:18:08,911 DEBUG TRAIN Batch 49/5000 loss 5.346642 loss_att 7.717375 loss_ctc 9.563251 loss_rnnt 4.171442 hw_loss 0.260326 lr 0.00029301 rank 7
2023-03-01 05:18:08,913 DEBUG TRAIN Batch 49/5000 loss 8.161980 loss_att 8.548512 loss_ctc 13.157340 loss_rnnt 7.262336 hw_loss 0.293041 lr 0.00029302 rank 6
2023-03-01 05:18:08,914 DEBUG TRAIN Batch 49/5000 loss 4.702853 loss_att 6.249217 loss_ctc 8.095115 loss_rnnt 3.849257 hw_loss 0.172542 lr 0.00029301 rank 3
2023-03-01 05:18:08,918 DEBUG TRAIN Batch 49/5000 loss 2.291914 loss_att 4.451528 loss_ctc 4.962438 loss_rnnt 1.414382 hw_loss 0.167889 lr 0.00029302 rank 2
2023-03-01 05:18:08,962 DEBUG TRAIN Batch 49/5000 loss 6.210638 loss_att 8.626765 loss_ctc 9.345243 loss_rnnt 5.212632 hw_loss 0.181561 lr 0.00029302 rank 4
2023-03-01 05:18:47,854 DEBUG TRAIN Batch 49/5100 loss 6.213265 loss_att 8.100029 loss_ctc 11.314823 loss_rnnt 5.001545 hw_loss 0.289048 lr 0.00029300 rank 3
2023-03-01 05:18:47,858 DEBUG TRAIN Batch 49/5100 loss 6.398511 loss_att 8.427487 loss_ctc 9.486794 loss_rnnt 5.390064 hw_loss 0.357903 lr 0.00029300 rank 1
2023-03-01 05:18:47,862 DEBUG TRAIN Batch 49/5100 loss 4.621396 loss_att 5.963479 loss_ctc 7.985247 loss_rnnt 3.794314 hw_loss 0.206534 lr 0.00029300 rank 4
2023-03-01 05:18:47,862 DEBUG TRAIN Batch 49/5100 loss 2.473992 loss_att 4.164522 loss_ctc 2.990798 loss_rnnt 2.051582 hw_loss 0.028868 lr 0.00029300 rank 7
2023-03-01 05:18:47,863 DEBUG TRAIN Batch 49/5100 loss 8.132409 loss_att 10.061063 loss_ctc 11.636556 loss_rnnt 7.177223 hw_loss 0.191691 lr 0.00029301 rank 2
2023-03-01 05:18:47,864 DEBUG TRAIN Batch 49/5100 loss 11.543826 loss_att 11.585527 loss_ctc 15.009990 loss_rnnt 11.004080 hw_loss 0.129845 lr 0.00029301 rank 0
2023-03-01 05:18:47,866 DEBUG TRAIN Batch 49/5100 loss 6.570227 loss_att 8.140815 loss_ctc 10.607390 loss_rnnt 5.570137 hw_loss 0.276909 lr 0.00029300 rank 5
2023-03-01 05:18:47,868 DEBUG TRAIN Batch 49/5100 loss 5.178195 loss_att 8.876500 loss_ctc 9.624006 loss_rnnt 3.711560 hw_loss 0.251622 lr 0.00029301 rank 6
2023-03-01 05:19:26,630 DEBUG TRAIN Batch 49/5200 loss 2.601521 loss_att 4.949836 loss_ctc 4.288117 loss_rnnt 1.782376 hw_loss 0.233631 lr 0.00029299 rank 4
2023-03-01 05:19:26,631 DEBUG TRAIN Batch 49/5200 loss 3.203778 loss_att 6.525225 loss_ctc 6.188543 loss_rnnt 1.979392 hw_loss 0.303990 lr 0.00029299 rank 3
2023-03-01 05:19:26,641 DEBUG TRAIN Batch 49/5200 loss 7.298961 loss_att 7.194688 loss_ctc 10.203329 loss_rnnt 6.706991 hw_loss 0.422956 lr 0.00029299 rank 2
2023-03-01 05:19:26,648 DEBUG TRAIN Batch 49/5200 loss 9.410007 loss_att 12.870150 loss_ctc 14.795333 loss_rnnt 7.879355 hw_loss 0.226085 lr 0.00029300 rank 0
2023-03-01 05:19:26,651 DEBUG TRAIN Batch 49/5200 loss 4.259227 loss_att 10.479684 loss_ctc 13.271167 loss_rnnt 1.708449 hw_loss 0.197052 lr 0.00029298 rank 7
2023-03-01 05:19:26,655 DEBUG TRAIN Batch 49/5200 loss 6.390563 loss_att 8.476275 loss_ctc 10.876568 loss_rnnt 5.263165 hw_loss 0.210227 lr 0.00029299 rank 6
2023-03-01 05:19:26,655 DEBUG TRAIN Batch 49/5200 loss 9.642275 loss_att 10.930850 loss_ctc 15.521428 loss_rnnt 8.391570 hw_loss 0.392068 lr 0.00029299 rank 1
2023-03-01 05:19:26,657 DEBUG TRAIN Batch 49/5200 loss 5.949574 loss_att 7.959661 loss_ctc 9.822882 loss_rnnt 4.916046 hw_loss 0.215754 lr 0.00029299 rank 5
2023-03-01 05:20:06,574 DEBUG TRAIN Batch 49/5300 loss 4.137923 loss_att 6.727689 loss_ctc 7.984220 loss_rnnt 2.988595 hw_loss 0.222254 lr 0.00029298 rank 2
2023-03-01 05:20:06,591 DEBUG TRAIN Batch 49/5300 loss 7.068932 loss_att 11.936373 loss_ctc 15.213257 loss_rnnt 4.898248 hw_loss 0.208661 lr 0.00029298 rank 6
2023-03-01 05:20:06,596 DEBUG TRAIN Batch 49/5300 loss 8.999825 loss_att 10.569124 loss_ctc 13.948225 loss_rnnt 7.903725 hw_loss 0.229600 lr 0.00029297 rank 7
2023-03-01 05:20:06,599 DEBUG TRAIN Batch 49/5300 loss 6.782857 loss_att 9.175028 loss_ctc 9.425468 loss_rnnt 5.833508 hw_loss 0.222314 lr 0.00029297 rank 3
2023-03-01 05:20:06,614 DEBUG TRAIN Batch 49/5300 loss 5.668752 loss_att 7.046952 loss_ctc 11.614511 loss_rnnt 4.392076 hw_loss 0.390501 lr 0.00029298 rank 0
2023-03-01 05:20:06,617 DEBUG TRAIN Batch 49/5300 loss 7.470413 loss_att 12.105898 loss_ctc 11.910708 loss_rnnt 5.899913 hw_loss 0.096305 lr 0.00029298 rank 5
2023-03-01 05:20:06,623 DEBUG TRAIN Batch 49/5300 loss 3.243834 loss_att 6.678886 loss_ctc 2.883245 loss_rnnt 2.506697 hw_loss 0.184134 lr 0.00029298 rank 4
2023-03-01 05:20:06,630 DEBUG TRAIN Batch 49/5300 loss 4.137896 loss_att 8.398972 loss_ctc 9.521830 loss_rnnt 2.436459 hw_loss 0.246307 lr 0.00029298 rank 1
2023-03-01 05:21:11,114 DEBUG TRAIN Batch 49/5400 loss 11.427835 loss_att 15.423873 loss_ctc 14.007335 loss_rnnt 10.183996 hw_loss 0.188809 lr 0.00029297 rank 1
2023-03-01 05:21:11,118 DEBUG TRAIN Batch 49/5400 loss 6.182120 loss_att 7.224258 loss_ctc 8.710534 loss_rnnt 5.451939 hw_loss 0.346185 lr 0.00029296 rank 3
2023-03-01 05:21:11,130 DEBUG TRAIN Batch 49/5400 loss 7.886809 loss_att 9.997459 loss_ctc 10.133030 loss_rnnt 7.077426 hw_loss 0.164543 lr 0.00029296 rank 7
2023-03-01 05:21:11,133 DEBUG TRAIN Batch 49/5400 loss 5.835701 loss_att 8.941877 loss_ctc 11.911679 loss_rnnt 4.266560 hw_loss 0.258328 lr 0.00029297 rank 6
2023-03-01 05:21:11,133 DEBUG TRAIN Batch 49/5400 loss 4.431209 loss_att 10.391531 loss_ctc 13.365917 loss_rnnt 2.025272 hw_loss 0.042333 lr 0.00029297 rank 2
2023-03-01 05:21:11,133 DEBUG TRAIN Batch 49/5400 loss 7.465004 loss_att 10.523266 loss_ctc 13.103111 loss_rnnt 5.969199 hw_loss 0.248260 lr 0.00029297 rank 0
2023-03-01 05:21:11,135 DEBUG TRAIN Batch 49/5400 loss 5.826934 loss_att 11.401493 loss_ctc 5.993448 loss_rnnt 4.534915 hw_loss 0.290448 lr 0.00029297 rank 4
2023-03-01 05:21:11,148 DEBUG TRAIN Batch 49/5400 loss 6.124709 loss_att 7.671921 loss_ctc 9.553923 loss_rnnt 5.357924 hw_loss 0.000214 lr 0.00029297 rank 5
2023-03-01 05:21:50,092 DEBUG TRAIN Batch 49/5500 loss 3.018102 loss_att 5.947051 loss_ctc 5.009487 loss_rnnt 2.048562 hw_loss 0.221685 lr 0.00029295 rank 1
2023-03-01 05:21:50,094 DEBUG TRAIN Batch 49/5500 loss 7.853874 loss_att 9.827927 loss_ctc 12.689561 loss_rnnt 6.671575 hw_loss 0.267619 lr 0.00029295 rank 7
2023-03-01 05:21:50,094 DEBUG TRAIN Batch 49/5500 loss 5.045799 loss_att 11.712869 loss_ctc 14.268590 loss_rnnt 2.383233 hw_loss 0.186461 lr 0.00029296 rank 0
2023-03-01 05:21:50,095 DEBUG TRAIN Batch 49/5500 loss 4.884305 loss_att 7.368248 loss_ctc 7.439291 loss_rnnt 3.871626 hw_loss 0.328549 lr 0.00029296 rank 2
2023-03-01 05:21:50,100 DEBUG TRAIN Batch 49/5500 loss 6.794744 loss_att 11.108941 loss_ctc 17.261330 loss_rnnt 4.462806 hw_loss 0.137912 lr 0.00029296 rank 6
2023-03-01 05:21:50,103 DEBUG TRAIN Batch 49/5500 loss 7.997403 loss_att 10.459045 loss_ctc 11.196512 loss_rnnt 6.929155 hw_loss 0.280073 lr 0.00029295 rank 5
2023-03-01 05:21:50,104 DEBUG TRAIN Batch 49/5500 loss 5.186949 loss_att 6.932619 loss_ctc 7.636669 loss_rnnt 4.416614 hw_loss 0.177322 lr 0.00029295 rank 3
2023-03-01 05:21:50,117 DEBUG TRAIN Batch 49/5500 loss 3.570748 loss_att 6.570612 loss_ctc 5.242531 loss_rnnt 2.672157 hw_loss 0.141964 lr 0.00029295 rank 4
2023-03-01 05:22:29,200 DEBUG TRAIN Batch 49/5600 loss 8.097013 loss_att 11.760560 loss_ctc 12.972180 loss_rnnt 6.565292 hw_loss 0.279355 lr 0.00029293 rank 7
2023-03-01 05:22:29,210 DEBUG TRAIN Batch 49/5600 loss 9.279685 loss_att 11.645640 loss_ctc 9.759598 loss_rnnt 8.638729 hw_loss 0.194580 lr 0.00029294 rank 1
2023-03-01 05:22:29,213 DEBUG TRAIN Batch 49/5600 loss 7.390582 loss_att 10.253876 loss_ctc 11.488420 loss_rnnt 6.210310 hw_loss 0.114814 lr 0.00029295 rank 0
2023-03-01 05:22:29,213 DEBUG TRAIN Batch 49/5600 loss 5.012462 loss_att 8.139286 loss_ctc 8.890969 loss_rnnt 3.771357 hw_loss 0.184885 lr 0.00029294 rank 3
2023-03-01 05:22:29,214 DEBUG TRAIN Batch 49/5600 loss 5.554343 loss_att 7.982821 loss_ctc 8.010736 loss_rnnt 4.590143 hw_loss 0.283096 lr 0.00029294 rank 6
2023-03-01 05:22:29,217 DEBUG TRAIN Batch 49/5600 loss 4.802238 loss_att 5.646998 loss_ctc 7.445709 loss_rnnt 4.080934 hw_loss 0.374794 lr 0.00029294 rank 5
2023-03-01 05:22:29,236 DEBUG TRAIN Batch 49/5600 loss 2.901645 loss_att 4.757035 loss_ctc 4.421894 loss_rnnt 2.232110 hw_loss 0.179545 lr 0.00029294 rank 2
2023-03-01 05:22:29,258 DEBUG TRAIN Batch 49/5600 loss 6.737399 loss_att 8.340400 loss_ctc 12.026445 loss_rnnt 5.593357 hw_loss 0.221691 lr 0.00029294 rank 4
2023-03-01 05:23:34,377 DEBUG TRAIN Batch 49/5700 loss 10.278561 loss_att 14.304399 loss_ctc 16.485516 loss_rnnt 8.543651 hw_loss 0.191527 lr 0.00029293 rank 4
2023-03-01 05:23:34,386 DEBUG TRAIN Batch 49/5700 loss 4.794732 loss_att 6.933304 loss_ctc 7.307207 loss_rnnt 3.878751 hw_loss 0.287380 lr 0.00029292 rank 7
2023-03-01 05:23:34,393 DEBUG TRAIN Batch 49/5700 loss 10.254731 loss_att 12.365902 loss_ctc 16.653873 loss_rnnt 8.837806 hw_loss 0.265263 lr 0.00029293 rank 0
2023-03-01 05:23:34,394 DEBUG TRAIN Batch 49/5700 loss 5.469461 loss_att 8.097849 loss_ctc 10.353642 loss_rnnt 4.292326 hw_loss 0.000437 lr 0.00029293 rank 6
2023-03-01 05:23:34,395 DEBUG TRAIN Batch 49/5700 loss 4.383041 loss_att 9.837648 loss_ctc 8.161386 loss_rnnt 2.667030 hw_loss 0.227457 lr 0.00029292 rank 3
2023-03-01 05:23:34,397 DEBUG TRAIN Batch 49/5700 loss 1.615105 loss_att 3.776163 loss_ctc 2.755472 loss_rnnt 0.889245 hw_loss 0.265498 lr 0.00029293 rank 1
2023-03-01 05:23:34,397 DEBUG TRAIN Batch 49/5700 loss 7.939884 loss_att 11.501312 loss_ctc 12.900951 loss_rnnt 6.418458 hw_loss 0.276871 lr 0.00029293 rank 2
2023-03-01 05:23:34,445 DEBUG TRAIN Batch 49/5700 loss 2.802593 loss_att 6.132567 loss_ctc 4.747393 loss_rnnt 1.769620 hw_loss 0.201885 lr 0.00029293 rank 5
2023-03-01 05:24:13,639 DEBUG TRAIN Batch 49/5800 loss 4.362214 loss_att 7.370131 loss_ctc 5.750134 loss_rnnt 3.384933 hw_loss 0.357452 lr 0.00029292 rank 6
2023-03-01 05:24:13,639 DEBUG TRAIN Batch 49/5800 loss 2.067985 loss_att 6.192329 loss_ctc 5.382516 loss_rnnt 0.646706 hw_loss 0.289637 lr 0.00029292 rank 0
2023-03-01 05:24:13,640 DEBUG TRAIN Batch 49/5800 loss 7.305555 loss_att 11.444237 loss_ctc 16.196718 loss_rnnt 5.153704 hw_loss 0.259925 lr 0.00029291 rank 7
2023-03-01 05:24:13,647 DEBUG TRAIN Batch 49/5800 loss 9.084798 loss_att 13.424014 loss_ctc 16.491657 loss_rnnt 7.120234 hw_loss 0.204636 lr 0.00029292 rank 5
2023-03-01 05:24:13,646 DEBUG TRAIN Batch 49/5800 loss 6.218017 loss_att 12.575186 loss_ctc 13.424864 loss_rnnt 3.984616 hw_loss 0.001977 lr 0.00029292 rank 4
2023-03-01 05:24:13,646 DEBUG TRAIN Batch 49/5800 loss 6.814520 loss_att 8.677263 loss_ctc 11.560699 loss_rnnt 5.730669 hw_loss 0.147149 lr 0.00029292 rank 1
2023-03-01 05:24:13,649 DEBUG TRAIN Batch 49/5800 loss 2.288902 loss_att 4.791588 loss_ctc 4.939758 loss_rnnt 1.325844 hw_loss 0.204512 lr 0.00029291 rank 3
2023-03-01 05:24:13,696 DEBUG TRAIN Batch 49/5800 loss 9.999911 loss_att 11.109055 loss_ctc 15.756182 loss_rnnt 8.848530 hw_loss 0.303845 lr 0.00029292 rank 2
2023-03-01 05:24:53,094 DEBUG TRAIN Batch 49/5900 loss 6.909642 loss_att 10.338772 loss_ctc 10.790911 loss_rnnt 5.607197 hw_loss 0.185844 lr 0.00029290 rank 1
2023-03-01 05:24:53,095 DEBUG TRAIN Batch 49/5900 loss 3.652537 loss_att 6.666541 loss_ctc 7.572039 loss_rnnt 2.379186 hw_loss 0.277406 lr 0.00029290 rank 7
2023-03-01 05:24:53,097 DEBUG TRAIN Batch 49/5900 loss 2.496667 loss_att 5.871513 loss_ctc 4.794532 loss_rnnt 1.325697 hw_loss 0.355535 lr 0.00029290 rank 3
2023-03-01 05:24:53,098 DEBUG TRAIN Batch 49/5900 loss 2.643792 loss_att 6.127966 loss_ctc 4.438869 loss_rnnt 1.612557 hw_loss 0.178231 lr 0.00029291 rank 2
2023-03-01 05:24:53,098 DEBUG TRAIN Batch 49/5900 loss 9.888882 loss_att 11.928936 loss_ctc 13.901123 loss_rnnt 8.781227 hw_loss 0.308771 lr 0.00029291 rank 0
2023-03-01 05:24:53,098 DEBUG TRAIN Batch 49/5900 loss 7.770185 loss_att 8.144012 loss_ctc 10.985458 loss_rnnt 7.182401 hw_loss 0.158089 lr 0.00029290 rank 4
2023-03-01 05:24:53,100 DEBUG TRAIN Batch 49/5900 loss 12.746957 loss_att 13.782803 loss_ctc 19.105072 loss_rnnt 11.568677 hw_loss 0.231302 lr 0.00029291 rank 6
2023-03-01 05:24:53,149 DEBUG TRAIN Batch 49/5900 loss 1.830218 loss_att 3.832766 loss_ctc 4.073124 loss_rnnt 1.002365 hw_loss 0.240541 lr 0.00029290 rank 5
2023-03-01 05:25:33,321 DEBUG TRAIN Batch 49/6000 loss 5.388374 loss_att 8.099334 loss_ctc 9.228434 loss_rnnt 4.234222 hw_loss 0.187411 lr 0.00029289 rank 5
2023-03-01 05:25:33,324 DEBUG TRAIN Batch 49/6000 loss 8.563662 loss_att 10.945358 loss_ctc 11.596763 loss_rnnt 7.615458 hw_loss 0.126469 lr 0.00029289 rank 6
2023-03-01 05:25:33,324 DEBUG TRAIN Batch 49/6000 loss 3.512880 loss_att 6.271315 loss_ctc 6.504376 loss_rnnt 2.396602 hw_loss 0.310733 lr 0.00029290 rank 0
2023-03-01 05:25:33,326 DEBUG TRAIN Batch 49/6000 loss 12.155063 loss_att 15.866776 loss_ctc 17.348711 loss_rnnt 10.628782 hw_loss 0.171470 lr 0.00029288 rank 7
2023-03-01 05:25:33,326 DEBUG TRAIN Batch 49/6000 loss 1.627523 loss_att 3.304231 loss_ctc 2.041258 loss_rnnt 1.063482 hw_loss 0.325378 lr 0.00029289 rank 4
2023-03-01 05:25:33,330 DEBUG TRAIN Batch 49/6000 loss 8.694913 loss_att 11.649264 loss_ctc 13.153110 loss_rnnt 7.367673 hw_loss 0.266145 lr 0.00029289 rank 1
2023-03-01 05:25:33,372 DEBUG TRAIN Batch 49/6000 loss 6.573020 loss_att 9.289817 loss_ctc 11.679199 loss_rnnt 5.211205 hw_loss 0.258059 lr 0.00029289 rank 2
2023-03-01 05:25:33,401 DEBUG TRAIN Batch 49/6000 loss 4.624620 loss_att 9.313612 loss_ctc 7.340480 loss_rnnt 3.261489 hw_loss 0.118535 lr 0.00029289 rank 3
2023-03-01 05:26:38,048 DEBUG TRAIN Batch 49/6100 loss 4.888461 loss_att 7.947131 loss_ctc 11.226951 loss_rnnt 3.349003 hw_loss 0.154859 lr 0.00029287 rank 3
2023-03-01 05:26:38,060 DEBUG TRAIN Batch 49/6100 loss 3.922367 loss_att 6.930825 loss_ctc 9.174437 loss_rnnt 2.508703 hw_loss 0.209430 lr 0.00029288 rank 1
2023-03-01 05:26:38,061 DEBUG TRAIN Batch 49/6100 loss 4.808112 loss_att 7.297930 loss_ctc 6.624621 loss_rnnt 3.966871 hw_loss 0.189516 lr 0.00029288 rank 4
2023-03-01 05:26:38,061 DEBUG TRAIN Batch 49/6100 loss 6.252666 loss_att 9.939789 loss_ctc 14.672098 loss_rnnt 4.283506 hw_loss 0.204646 lr 0.00029288 rank 6
2023-03-01 05:26:38,064 DEBUG TRAIN Batch 49/6100 loss 7.532095 loss_att 9.776763 loss_ctc 10.974509 loss_rnnt 6.481937 hw_loss 0.266692 lr 0.00029288 rank 0
2023-03-01 05:26:38,066 DEBUG TRAIN Batch 49/6100 loss 6.018798 loss_att 7.956730 loss_ctc 12.221077 loss_rnnt 4.617968 hw_loss 0.349261 lr 0.00029287 rank 7
2023-03-01 05:26:38,068 DEBUG TRAIN Batch 49/6100 loss 7.026633 loss_att 9.843223 loss_ctc 15.233713 loss_rnnt 5.257936 hw_loss 0.208316 lr 0.00029288 rank 2
2023-03-01 05:26:38,074 DEBUG TRAIN Batch 49/6100 loss 6.520109 loss_att 8.456586 loss_ctc 10.677138 loss_rnnt 5.538663 hw_loss 0.074775 lr 0.00029288 rank 5
2023-03-01 05:27:16,828 DEBUG TRAIN Batch 49/6200 loss 9.161555 loss_att 12.282004 loss_ctc 20.470375 loss_rnnt 6.961775 hw_loss 0.127215 lr 0.00029287 rank 1
2023-03-01 05:27:16,837 DEBUG TRAIN Batch 49/6200 loss 3.503812 loss_att 4.919671 loss_ctc 6.032719 loss_rnnt 2.804014 hw_loss 0.148947 lr 0.00029287 rank 4
2023-03-01 05:27:16,845 DEBUG TRAIN Batch 49/6200 loss 5.873260 loss_att 9.138096 loss_ctc 9.604133 loss_rnnt 4.603398 hw_loss 0.223958 lr 0.00029287 rank 6
2023-03-01 05:27:16,847 DEBUG TRAIN Batch 49/6200 loss 8.412002 loss_att 9.933334 loss_ctc 15.844893 loss_rnnt 6.966117 hw_loss 0.282312 lr 0.00029287 rank 2
2023-03-01 05:27:16,848 DEBUG TRAIN Batch 49/6200 loss 5.848805 loss_att 7.668291 loss_ctc 11.192209 loss_rnnt 4.676265 hw_loss 0.180353 lr 0.00029287 rank 5
2023-03-01 05:27:16,849 DEBUG TRAIN Batch 49/6200 loss 9.151892 loss_att 12.120012 loss_ctc 17.153519 loss_rnnt 7.334130 hw_loss 0.294851 lr 0.00029286 rank 7
2023-03-01 05:27:16,851 DEBUG TRAIN Batch 49/6200 loss 4.896240 loss_att 7.114965 loss_ctc 7.796222 loss_rnnt 3.988368 hw_loss 0.145242 lr 0.00029287 rank 0
2023-03-01 05:27:16,909 DEBUG TRAIN Batch 49/6200 loss 7.810771 loss_att 9.970779 loss_ctc 11.042955 loss_rnnt 6.867218 hw_loss 0.151111 lr 0.00029286 rank 3
2023-03-01 05:27:56,642 DEBUG TRAIN Batch 49/6300 loss 5.860093 loss_att 8.014320 loss_ctc 10.059770 loss_rnnt 4.800653 hw_loss 0.128697 lr 0.00029286 rank 0
2023-03-01 05:27:56,645 DEBUG TRAIN Batch 49/6300 loss 7.621235 loss_att 11.057645 loss_ctc 14.796157 loss_rnnt 5.865011 hw_loss 0.210536 lr 0.00029285 rank 1
2023-03-01 05:27:56,649 DEBUG TRAIN Batch 49/6300 loss 7.290082 loss_att 8.880848 loss_ctc 11.581602 loss_rnnt 6.206844 hw_loss 0.361654 lr 0.00029285 rank 7
2023-03-01 05:27:56,649 DEBUG TRAIN Batch 49/6300 loss 4.684341 loss_att 7.197222 loss_ctc 8.326014 loss_rnnt 3.550891 hw_loss 0.272471 lr 0.00029286 rank 6
2023-03-01 05:27:56,651 DEBUG TRAIN Batch 49/6300 loss 8.383250 loss_att 10.623529 loss_ctc 11.909540 loss_rnnt 7.300161 hw_loss 0.309115 lr 0.00029285 rank 4
2023-03-01 05:27:56,653 DEBUG TRAIN Batch 49/6300 loss 3.914194 loss_att 6.703554 loss_ctc 9.097141 loss_rnnt 2.518664 hw_loss 0.274871 lr 0.00029285 rank 5
2023-03-01 05:27:56,654 DEBUG TRAIN Batch 49/6300 loss 10.274580 loss_att 11.430131 loss_ctc 15.271711 loss_rnnt 9.264084 hw_loss 0.212066 lr 0.00029285 rank 3
2023-03-01 05:27:56,659 DEBUG TRAIN Batch 49/6300 loss 7.319166 loss_att 9.942112 loss_ctc 10.872832 loss_rnnt 6.206714 hw_loss 0.213826 lr 0.00029286 rank 2
2023-03-01 05:29:01,504 DEBUG TRAIN Batch 49/6400 loss 3.808732 loss_att 8.254309 loss_ctc 7.254214 loss_rnnt 2.368535 hw_loss 0.171907 lr 0.00029284 rank 6
2023-03-01 05:29:01,511 DEBUG TRAIN Batch 49/6400 loss 4.213403 loss_att 5.844028 loss_ctc 6.165789 loss_rnnt 3.497486 hw_loss 0.242763 lr 0.00029284 rank 1
2023-03-01 05:29:01,515 DEBUG TRAIN Batch 49/6400 loss 4.649311 loss_att 5.567835 loss_ctc 8.406252 loss_rnnt 3.899603 hw_loss 0.122020 lr 0.00029285 rank 0
2023-03-01 05:29:01,518 DEBUG TRAIN Batch 49/6400 loss 3.592536 loss_att 8.770647 loss_ctc 6.600416 loss_rnnt 2.108363 hw_loss 0.089063 lr 0.00029283 rank 7
2023-03-01 05:29:01,518 DEBUG TRAIN Batch 49/6400 loss 5.975185 loss_att 6.684201 loss_ctc 8.041129 loss_rnnt 5.400051 hw_loss 0.296009 lr 0.00029284 rank 2
2023-03-01 05:29:01,523 DEBUG TRAIN Batch 49/6400 loss 3.919180 loss_att 5.799583 loss_ctc 4.259211 loss_rnnt 3.409713 hw_loss 0.165092 lr 0.00029284 rank 5
2023-03-01 05:29:01,549 DEBUG TRAIN Batch 49/6400 loss 3.551825 loss_att 11.407572 loss_ctc 4.795774 loss_rnnt 1.671206 hw_loss 0.269268 lr 0.00029284 rank 4
2023-03-01 05:29:01,554 DEBUG TRAIN Batch 49/6400 loss 5.642920 loss_att 7.975940 loss_ctc 9.490773 loss_rnnt 4.583767 hw_loss 0.149065 lr 0.00029284 rank 3
2023-03-01 05:29:41,036 DEBUG TRAIN Batch 49/6500 loss 8.558841 loss_att 14.060316 loss_ctc 19.598677 loss_rnnt 5.884296 hw_loss 0.191757 lr 0.00029282 rank 3
2023-03-01 05:29:41,047 DEBUG TRAIN Batch 49/6500 loss 5.018110 loss_att 6.943177 loss_ctc 6.108600 loss_rnnt 4.426644 hw_loss 0.114474 lr 0.00029283 rank 4
2023-03-01 05:29:41,049 DEBUG TRAIN Batch 49/6500 loss 1.587850 loss_att 5.115234 loss_ctc 4.299984 loss_rnnt 0.376664 hw_loss 0.270170 lr 0.00029283 rank 1
2023-03-01 05:29:41,050 DEBUG TRAIN Batch 49/6500 loss 11.263377 loss_att 12.751244 loss_ctc 19.505741 loss_rnnt 9.746515 hw_loss 0.225574 lr 0.00029282 rank 7
2023-03-01 05:29:41,053 DEBUG TRAIN Batch 49/6500 loss 5.731633 loss_att 7.447210 loss_ctc 16.459095 loss_rnnt 3.829411 hw_loss 0.241461 lr 0.00029283 rank 6
2023-03-01 05:29:41,054 DEBUG TRAIN Batch 49/6500 loss 6.652864 loss_att 11.073839 loss_ctc 10.950102 loss_rnnt 5.112278 hw_loss 0.156423 lr 0.00029283 rank 5
2023-03-01 05:29:41,053 DEBUG TRAIN Batch 49/6500 loss 3.012792 loss_att 5.317623 loss_ctc 3.843744 loss_rnnt 2.392832 hw_loss 0.090374 lr 0.00029283 rank 0
2023-03-01 05:29:41,059 DEBUG TRAIN Batch 49/6500 loss 3.622907 loss_att 8.543380 loss_ctc 6.948909 loss_rnnt 2.117781 hw_loss 0.145433 lr 0.00029283 rank 2
2023-03-01 05:30:19,988 DEBUG TRAIN Batch 49/6600 loss 4.178542 loss_att 6.933825 loss_ctc 7.931570 loss_rnnt 3.048704 hw_loss 0.146958 lr 0.00029282 rank 0
2023-03-01 05:30:19,992 DEBUG TRAIN Batch 49/6600 loss 3.419050 loss_att 6.604707 loss_ctc 6.411024 loss_rnnt 2.195814 hw_loss 0.350952 lr 0.00029282 rank 1
2023-03-01 05:30:19,995 DEBUG TRAIN Batch 49/6600 loss 6.121295 loss_att 11.471401 loss_ctc 13.717886 loss_rnnt 3.972031 hw_loss 0.124432 lr 0.00029281 rank 3
2023-03-01 05:30:19,996 DEBUG TRAIN Batch 49/6600 loss 5.530318 loss_att 7.486847 loss_ctc 9.784126 loss_rnnt 4.436790 hw_loss 0.253216 lr 0.00029281 rank 7
2023-03-01 05:30:19,996 DEBUG TRAIN Batch 49/6600 loss 10.794945 loss_att 15.484594 loss_ctc 18.324968 loss_rnnt 8.726978 hw_loss 0.236313 lr 0.00029282 rank 4
2023-03-01 05:30:20,001 DEBUG TRAIN Batch 49/6600 loss 9.325749 loss_att 11.356075 loss_ctc 13.536276 loss_rnnt 8.314698 hw_loss 0.081716 lr 0.00029282 rank 5
2023-03-01 05:30:20,002 DEBUG TRAIN Batch 49/6600 loss 1.548731 loss_att 4.880381 loss_ctc 2.077135 loss_rnnt 0.660463 hw_loss 0.284033 lr 0.00029282 rank 2
2023-03-01 05:30:20,004 DEBUG TRAIN Batch 49/6600 loss 4.265184 loss_att 7.142718 loss_ctc 8.203182 loss_rnnt 3.032277 hw_loss 0.248125 lr 0.00029282 rank 6
2023-03-01 05:30:59,436 DEBUG TRAIN Batch 49/6700 loss 4.424745 loss_att 6.814589 loss_ctc 7.521600 loss_rnnt 3.449385 hw_loss 0.158393 lr 0.00029280 rank 1
2023-03-01 05:30:59,438 DEBUG TRAIN Batch 49/6700 loss 6.034744 loss_att 7.650928 loss_ctc 5.835126 loss_rnnt 5.636140 hw_loss 0.191218 lr 0.00029280 rank 2
2023-03-01 05:30:59,441 DEBUG TRAIN Batch 49/6700 loss 7.790899 loss_att 12.859629 loss_ctc 11.282682 loss_rnnt 6.203559 hw_loss 0.202542 lr 0.00029280 rank 6
2023-03-01 05:30:59,448 DEBUG TRAIN Batch 49/6700 loss 9.502238 loss_att 11.587158 loss_ctc 20.052423 loss_rnnt 7.570324 hw_loss 0.202950 lr 0.00029279 rank 7
2023-03-01 05:30:59,449 DEBUG TRAIN Batch 49/6700 loss 4.573594 loss_att 7.386743 loss_ctc 9.732380 loss_rnnt 3.258881 hw_loss 0.120458 lr 0.00029281 rank 0
2023-03-01 05:30:59,453 DEBUG TRAIN Batch 49/6700 loss 6.119953 loss_att 7.964658 loss_ctc 11.840605 loss_rnnt 4.843274 hw_loss 0.271846 lr 0.00029280 rank 5
2023-03-01 05:30:59,470 DEBUG TRAIN Batch 49/6700 loss 6.083670 loss_att 9.043799 loss_ctc 9.541302 loss_rnnt 4.894580 hw_loss 0.255088 lr 0.00029280 rank 3
2023-03-01 05:30:59,471 DEBUG TRAIN Batch 49/6700 loss 9.723589 loss_att 13.060967 loss_ctc 13.086521 loss_rnnt 8.479364 hw_loss 0.240669 lr 0.00029280 rank 4
2023-03-01 05:32:06,148 DEBUG TRAIN Batch 49/6800 loss 7.142934 loss_att 10.702622 loss_ctc 13.033005 loss_rnnt 5.524285 hw_loss 0.227565 lr 0.00029279 rank 0
2023-03-01 05:32:06,149 DEBUG TRAIN Batch 49/6800 loss 2.754889 loss_att 5.496307 loss_ctc 3.281921 loss_rnnt 1.905165 hw_loss 0.433443 lr 0.00029279 rank 2
2023-03-01 05:32:06,152 DEBUG TRAIN Batch 49/6800 loss 5.290585 loss_att 7.632286 loss_ctc 10.574240 loss_rnnt 3.886597 hw_loss 0.433426 lr 0.00029279 rank 6
2023-03-01 05:32:06,152 DEBUG TRAIN Batch 49/6800 loss 5.085073 loss_att 5.985729 loss_ctc 8.393938 loss_rnnt 4.386262 hw_loss 0.145306 lr 0.00029279 rank 5
2023-03-01 05:32:06,156 DEBUG TRAIN Batch 49/6800 loss 5.670133 loss_att 9.257225 loss_ctc 9.741784 loss_rnnt 4.196725 hw_loss 0.399568 lr 0.00029278 rank 7
2023-03-01 05:32:06,156 DEBUG TRAIN Batch 49/6800 loss 4.045777 loss_att 6.866097 loss_ctc 8.318285 loss_rnnt 2.784439 hw_loss 0.239262 lr 0.00029279 rank 3
2023-03-01 05:32:06,181 DEBUG TRAIN Batch 49/6800 loss 5.503478 loss_att 7.245013 loss_ctc 8.596775 loss_rnnt 4.624506 hw_loss 0.221674 lr 0.00029279 rank 1
2023-03-01 05:32:06,191 DEBUG TRAIN Batch 49/6800 loss 2.673426 loss_att 6.666643 loss_ctc 4.112770 loss_rnnt 1.583094 hw_loss 0.187081 lr 0.00029279 rank 4
2023-03-01 05:32:45,120 DEBUG TRAIN Batch 49/6900 loss 8.109133 loss_att 9.096058 loss_ctc 11.733124 loss_rnnt 7.252929 hw_loss 0.329290 lr 0.00029278 rank 6
2023-03-01 05:32:45,121 DEBUG TRAIN Batch 49/6900 loss 5.361015 loss_att 7.076407 loss_ctc 7.037659 loss_rnnt 4.658340 hw_loss 0.255080 lr 0.00029278 rank 1
2023-03-01 05:32:45,136 DEBUG TRAIN Batch 49/6900 loss 4.962882 loss_att 5.927896 loss_ctc 7.134992 loss_rnnt 4.314658 hw_loss 0.310513 lr 0.00029278 rank 5
2023-03-01 05:32:45,136 DEBUG TRAIN Batch 49/6900 loss 3.177624 loss_att 6.437141 loss_ctc 7.591572 loss_rnnt 1.768218 hw_loss 0.316831 lr 0.00029278 rank 0
2023-03-01 05:32:45,137 DEBUG TRAIN Batch 49/6900 loss 8.520245 loss_att 12.962687 loss_ctc 14.804760 loss_rnnt 6.667557 hw_loss 0.236746 lr 0.00029277 rank 7
2023-03-01 05:32:45,137 DEBUG TRAIN Batch 49/6900 loss 4.164152 loss_att 7.387497 loss_ctc 8.862985 loss_rnnt 2.772039 hw_loss 0.226751 lr 0.00029278 rank 4
2023-03-01 05:32:45,142 DEBUG TRAIN Batch 49/6900 loss 3.158132 loss_att 3.489600 loss_ctc 3.838638 loss_rnnt 2.846110 hw_loss 0.290614 lr 0.00029277 rank 3
2023-03-01 05:32:45,145 DEBUG TRAIN Batch 49/6900 loss 3.584020 loss_att 6.693865 loss_ctc 6.270794 loss_rnnt 2.434375 hw_loss 0.317699 lr 0.00029278 rank 2
2023-03-01 05:33:24,163 DEBUG TRAIN Batch 49/7000 loss 2.815651 loss_att 5.536320 loss_ctc 4.368387 loss_rnnt 1.972714 hw_loss 0.172072 lr 0.00029277 rank 6
2023-03-01 05:33:24,168 DEBUG TRAIN Batch 49/7000 loss 8.292074 loss_att 12.763000 loss_ctc 20.809185 loss_rnnt 5.653062 hw_loss 0.142275 lr 0.00029277 rank 4
2023-03-01 05:33:24,176 DEBUG TRAIN Batch 49/7000 loss 4.903595 loss_att 6.855846 loss_ctc 11.216410 loss_rnnt 3.551514 hw_loss 0.224854 lr 0.00029277 rank 2
2023-03-01 05:33:24,181 DEBUG TRAIN Batch 49/7000 loss 3.633847 loss_att 5.569394 loss_ctc 6.147277 loss_rnnt 2.711694 hw_loss 0.374849 lr 0.00029277 rank 0
2023-03-01 05:33:24,185 DEBUG TRAIN Batch 49/7000 loss 1.451596 loss_att 3.061897 loss_ctc 1.793083 loss_rnnt 0.987136 hw_loss 0.181629 lr 0.00029276 rank 7
2023-03-01 05:33:24,190 DEBUG TRAIN Batch 49/7000 loss 7.289639 loss_att 10.550082 loss_ctc 12.142828 loss_rnnt 5.850678 hw_loss 0.262085 lr 0.00029277 rank 1
2023-03-01 05:33:24,191 DEBUG TRAIN Batch 49/7000 loss 13.492828 loss_att 16.399879 loss_ctc 24.791494 loss_rnnt 11.387524 hw_loss 0.032635 lr 0.00029276 rank 3
2023-03-01 05:33:24,201 DEBUG TRAIN Batch 49/7000 loss 14.673368 loss_att 16.452579 loss_ctc 24.823505 loss_rnnt 12.937986 hw_loss 0.049103 lr 0.00029277 rank 5
2023-03-01 05:34:40,059 DEBUG TRAIN Batch 49/7100 loss 5.161304 loss_att 9.413344 loss_ctc 9.440104 loss_rnnt 3.627224 hw_loss 0.212184 lr 0.00029275 rank 6
2023-03-01 05:34:40,070 DEBUG TRAIN Batch 49/7100 loss 4.494740 loss_att 9.130794 loss_ctc 11.782043 loss_rnnt 2.422608 hw_loss 0.324903 lr 0.00029276 rank 0
2023-03-01 05:34:40,075 DEBUG TRAIN Batch 49/7100 loss 8.159655 loss_att 8.566181 loss_ctc 12.086616 loss_rnnt 7.395051 hw_loss 0.299444 lr 0.00029275 rank 1
2023-03-01 05:34:40,086 DEBUG TRAIN Batch 49/7100 loss 7.973313 loss_att 8.395423 loss_ctc 13.060854 loss_rnnt 7.059400 hw_loss 0.283410 lr 0.00029275 rank 2
2023-03-01 05:34:40,092 DEBUG TRAIN Batch 49/7100 loss 10.711088 loss_att 12.772188 loss_ctc 19.818396 loss_rnnt 8.909073 hw_loss 0.329039 lr 0.00029274 rank 7
2023-03-01 05:34:40,092 DEBUG TRAIN Batch 49/7100 loss 3.403570 loss_att 4.597219 loss_ctc 4.272960 loss_rnnt 2.903611 hw_loss 0.272458 lr 0.00029275 rank 3
2023-03-01 05:34:40,103 DEBUG TRAIN Batch 49/7100 loss 10.447412 loss_att 12.714069 loss_ctc 21.452976 loss_rnnt 8.455030 hw_loss 0.134327 lr 0.00029275 rank 5
2023-03-01 05:34:40,103 DEBUG TRAIN Batch 49/7100 loss 3.763893 loss_att 7.257463 loss_ctc 5.746326 loss_rnnt 2.655755 hw_loss 0.272062 lr 0.00029275 rank 4
2023-03-01 05:35:19,224 DEBUG TRAIN Batch 49/7200 loss 1.281928 loss_att 3.603005 loss_ctc 2.933126 loss_rnnt 0.444846 hw_loss 0.286325 lr 0.00029274 rank 6
2023-03-01 05:35:19,234 DEBUG TRAIN Batch 49/7200 loss 9.159964 loss_att 13.893885 loss_ctc 16.848919 loss_rnnt 7.088749 hw_loss 0.186068 lr 0.00029274 rank 5
2023-03-01 05:35:19,235 DEBUG TRAIN Batch 49/7200 loss 5.009575 loss_att 8.096019 loss_ctc 8.429145 loss_rnnt 3.889864 hw_loss 0.087147 lr 0.00029274 rank 4
2023-03-01 05:35:19,235 DEBUG TRAIN Batch 49/7200 loss 10.969762 loss_att 13.335348 loss_ctc 15.423569 loss_rnnt 9.862261 hw_loss 0.076017 lr 0.00029274 rank 0
2023-03-01 05:35:19,235 DEBUG TRAIN Batch 49/7200 loss 7.141870 loss_att 10.097434 loss_ctc 15.255204 loss_rnnt 5.336155 hw_loss 0.249045 lr 0.00029273 rank 7
2023-03-01 05:35:19,238 DEBUG TRAIN Batch 49/7200 loss 9.329624 loss_att 11.888712 loss_ctc 16.114199 loss_rnnt 7.912000 hw_loss 0.002244 lr 0.00029274 rank 2
2023-03-01 05:35:19,241 DEBUG TRAIN Batch 49/7200 loss 4.290009 loss_att 6.856316 loss_ctc 11.959242 loss_rnnt 2.622358 hw_loss 0.247173 lr 0.00029274 rank 1
2023-03-01 05:35:19,241 DEBUG TRAIN Batch 49/7200 loss 9.635209 loss_att 12.345832 loss_ctc 16.618567 loss_rnnt 8.091646 hw_loss 0.131858 lr 0.00029274 rank 3
2023-03-01 05:35:58,306 DEBUG TRAIN Batch 49/7300 loss 8.201294 loss_att 13.446012 loss_ctc 20.198652 loss_rnnt 5.551893 hw_loss 0.001517 lr 0.00029273 rank 2
2023-03-01 05:35:58,311 DEBUG TRAIN Batch 49/7300 loss 8.547919 loss_att 13.078068 loss_ctc 17.801563 loss_rnnt 6.281509 hw_loss 0.237303 lr 0.00029273 rank 1
2023-03-01 05:35:58,312 DEBUG TRAIN Batch 49/7300 loss 6.025955 loss_att 10.550181 loss_ctc 9.924839 loss_rnnt 4.488464 hw_loss 0.211488 lr 0.00029273 rank 0
2023-03-01 05:35:58,312 DEBUG TRAIN Batch 49/7300 loss 4.277987 loss_att 6.540874 loss_ctc 4.983284 loss_rnnt 3.604817 hw_loss 0.237284 lr 0.00029272 rank 7
2023-03-01 05:35:58,314 DEBUG TRAIN Batch 49/7300 loss 5.893320 loss_att 11.019428 loss_ctc 12.942513 loss_rnnt 3.753897 hw_loss 0.326829 lr 0.00029273 rank 5
2023-03-01 05:35:58,317 DEBUG TRAIN Batch 49/7300 loss 13.650080 loss_att 18.271629 loss_ctc 24.083017 loss_rnnt 11.234084 hw_loss 0.188676 lr 0.00029272 rank 3
2023-03-01 05:35:58,318 DEBUG TRAIN Batch 49/7300 loss 9.113819 loss_att 10.123569 loss_ctc 15.011415 loss_rnnt 8.029503 hw_loss 0.180036 lr 0.00029273 rank 6
2023-03-01 05:35:58,333 DEBUG TRAIN Batch 49/7300 loss 9.418414 loss_att 13.323240 loss_ctc 14.670008 loss_rnnt 7.910197 hw_loss 0.050698 lr 0.00029273 rank 4
2023-03-01 05:36:37,611 DEBUG TRAIN Batch 49/7400 loss 4.072075 loss_att 7.503534 loss_ctc 4.275512 loss_rnnt 3.304524 hw_loss 0.101502 lr 0.00029272 rank 2
2023-03-01 05:36:37,613 DEBUG TRAIN Batch 49/7400 loss 2.480643 loss_att 5.385081 loss_ctc 6.958098 loss_rnnt 1.148987 hw_loss 0.288327 lr 0.00029272 rank 4
2023-03-01 05:36:37,626 DEBUG TRAIN Batch 49/7400 loss 2.573085 loss_att 4.415222 loss_ctc 3.577245 loss_rnnt 1.896579 hw_loss 0.326608 lr 0.00029272 rank 1
2023-03-01 05:36:37,628 DEBUG TRAIN Batch 49/7400 loss 10.242171 loss_att 10.853111 loss_ctc 13.124565 loss_rnnt 9.703382 hw_loss 0.060530 lr 0.00029272 rank 0
2023-03-01 05:36:37,629 DEBUG TRAIN Batch 49/7400 loss 8.219613 loss_att 10.256601 loss_ctc 13.326897 loss_rnnt 7.077828 hw_loss 0.100153 lr 0.00029271 rank 3
2023-03-01 05:36:37,629 DEBUG TRAIN Batch 49/7400 loss 2.048459 loss_att 3.959793 loss_ctc 3.833802 loss_rnnt 1.357565 hw_loss 0.132340 lr 0.00029271 rank 7
2023-03-01 05:36:37,636 DEBUG TRAIN Batch 49/7400 loss 8.493054 loss_att 11.359974 loss_ctc 15.417575 loss_rnnt 6.866920 hw_loss 0.242779 lr 0.00029272 rank 5
2023-03-01 05:36:37,653 DEBUG TRAIN Batch 49/7400 loss 5.769874 loss_att 8.223452 loss_ctc 9.364871 loss_rnnt 4.660677 hw_loss 0.260903 lr 0.00029272 rank 6
2023-03-01 05:37:45,025 DEBUG TRAIN Batch 49/7500 loss 6.320218 loss_att 8.134302 loss_ctc 9.860197 loss_rnnt 5.418183 hw_loss 0.126038 lr 0.00029270 rank 1
2023-03-01 05:37:45,025 DEBUG TRAIN Batch 49/7500 loss 7.065003 loss_att 8.412392 loss_ctc 11.988101 loss_rnnt 6.014745 hw_loss 0.233187 lr 0.00029269 rank 7
2023-03-01 05:37:45,025 DEBUG TRAIN Batch 49/7500 loss 4.744033 loss_att 7.356571 loss_ctc 7.547032 loss_rnnt 3.745764 hw_loss 0.191303 lr 0.00029270 rank 4
2023-03-01 05:37:45,029 DEBUG TRAIN Batch 49/7500 loss 5.272623 loss_att 7.201703 loss_ctc 7.022923 loss_rnnt 4.592945 hw_loss 0.113415 lr 0.00029271 rank 0
2023-03-01 05:37:45,031 DEBUG TRAIN Batch 49/7500 loss 5.438457 loss_att 9.258813 loss_ctc 10.012239 loss_rnnt 4.041306 hw_loss 0.043579 lr 0.00029270 rank 2
2023-03-01 05:37:45,036 DEBUG TRAIN Batch 49/7500 loss 5.309604 loss_att 6.666779 loss_ctc 7.914624 loss_rnnt 4.533189 hw_loss 0.295582 lr 0.00029270 rank 3
2023-03-01 05:37:45,041 DEBUG TRAIN Batch 49/7500 loss 10.098046 loss_att 13.145453 loss_ctc 16.515867 loss_rnnt 8.558248 hw_loss 0.139889 lr 0.00029270 rank 5
2023-03-01 05:37:45,079 DEBUG TRAIN Batch 49/7500 loss 8.359546 loss_att 10.282269 loss_ctc 14.016310 loss_rnnt 7.090397 hw_loss 0.244440 lr 0.00029270 rank 6
2023-03-01 05:38:23,996 DEBUG TRAIN Batch 49/7600 loss 3.094765 loss_att 5.434817 loss_ctc 5.951931 loss_rnnt 2.128764 hw_loss 0.219441 lr 0.00029269 rank 2
2023-03-01 05:38:24,003 DEBUG TRAIN Batch 49/7600 loss 7.156444 loss_att 12.005067 loss_ctc 9.674518 loss_rnnt 5.743679 hw_loss 0.201183 lr 0.00029269 rank 5
2023-03-01 05:38:24,006 DEBUG TRAIN Batch 49/7600 loss 2.828932 loss_att 6.660906 loss_ctc 10.013372 loss_rnnt 0.936822 hw_loss 0.314604 lr 0.00029269 rank 6
2023-03-01 05:38:24,011 DEBUG TRAIN Batch 49/7600 loss 5.233196 loss_att 7.065147 loss_ctc 9.131426 loss_rnnt 4.316305 hw_loss 0.057633 lr 0.00029269 rank 3
2023-03-01 05:38:24,013 DEBUG TRAIN Batch 49/7600 loss 5.361570 loss_att 7.267506 loss_ctc 10.348770 loss_rnnt 4.254477 hw_loss 0.114274 lr 0.00029268 rank 7
2023-03-01 05:38:24,014 DEBUG TRAIN Batch 49/7600 loss 8.749673 loss_att 11.089355 loss_ctc 14.491612 loss_rnnt 7.435819 hw_loss 0.150609 lr 0.00029269 rank 0
2023-03-01 05:38:24,018 DEBUG TRAIN Batch 49/7600 loss 6.360461 loss_att 7.601263 loss_ctc 11.050999 loss_rnnt 5.436674 hw_loss 0.094166 lr 0.00029269 rank 4
2023-03-01 05:38:24,032 DEBUG TRAIN Batch 49/7600 loss 4.056359 loss_att 7.201578 loss_ctc 8.558874 loss_rnnt 2.743083 hw_loss 0.157307 lr 0.00029269 rank 1
2023-03-01 05:39:02,703 DEBUG TRAIN Batch 49/7700 loss 2.219401 loss_att 5.139482 loss_ctc 4.751827 loss_rnnt 1.160194 hw_loss 0.257877 lr 0.00029267 rank 7
2023-03-01 05:39:02,706 DEBUG TRAIN Batch 49/7700 loss 3.841216 loss_att 5.567798 loss_ctc 6.468191 loss_rnnt 3.033707 hw_loss 0.209866 lr 0.00029268 rank 4
2023-03-01 05:39:02,708 DEBUG TRAIN Batch 49/7700 loss 4.063591 loss_att 6.241936 loss_ctc 7.903470 loss_rnnt 2.951470 hw_loss 0.308378 lr 0.00029268 rank 2
2023-03-01 05:39:02,709 DEBUG TRAIN Batch 49/7700 loss 4.140445 loss_att 7.178732 loss_ctc 8.834891 loss_rnnt 2.835230 hw_loss 0.134307 lr 0.00029268 rank 6
2023-03-01 05:39:02,711 DEBUG TRAIN Batch 49/7700 loss 6.854889 loss_att 7.998397 loss_ctc 12.713313 loss_rnnt 5.774942 hw_loss 0.131479 lr 0.00029268 rank 0
2023-03-01 05:39:02,711 DEBUG TRAIN Batch 49/7700 loss 3.741256 loss_att 6.718743 loss_ctc 8.059983 loss_rnnt 2.500508 hw_loss 0.130164 lr 0.00029267 rank 3
2023-03-01 05:39:02,714 DEBUG TRAIN Batch 49/7700 loss 5.799794 loss_att 7.636249 loss_ctc 7.800510 loss_rnnt 5.089418 hw_loss 0.143105 lr 0.00029268 rank 1
2023-03-01 05:39:02,759 DEBUG TRAIN Batch 49/7700 loss 7.118364 loss_att 10.563570 loss_ctc 13.347975 loss_rnnt 5.467377 hw_loss 0.246246 lr 0.00029268 rank 5
2023-03-01 05:39:43,389 DEBUG TRAIN Batch 49/7800 loss 5.022788 loss_att 8.283262 loss_ctc 9.212217 loss_rnnt 3.672270 hw_loss 0.262186 lr 0.00029267 rank 6
2023-03-01 05:39:43,391 DEBUG TRAIN Batch 49/7800 loss 5.270193 loss_att 7.859632 loss_ctc 6.888092 loss_rnnt 4.455213 hw_loss 0.152572 lr 0.00029266 rank 7
2023-03-01 05:39:43,396 DEBUG TRAIN Batch 49/7800 loss 3.854483 loss_att 7.482363 loss_ctc 9.069870 loss_rnnt 2.253335 hw_loss 0.337850 lr 0.00029267 rank 0
2023-03-01 05:39:43,399 DEBUG TRAIN Batch 49/7800 loss 4.023752 loss_att 7.667932 loss_ctc 5.223306 loss_rnnt 3.013757 hw_loss 0.227285 lr 0.00029267 rank 1
2023-03-01 05:39:43,399 DEBUG TRAIN Batch 49/7800 loss 4.636542 loss_att 10.714814 loss_ctc 11.010314 loss_rnnt 2.433073 hw_loss 0.258709 lr 0.00029267 rank 2
2023-03-01 05:39:43,402 DEBUG TRAIN Batch 49/7800 loss 7.416839 loss_att 14.320614 loss_ctc 20.333538 loss_rnnt 4.165447 hw_loss 0.278268 lr 0.00029266 rank 3
2023-03-01 05:39:43,402 DEBUG TRAIN Batch 49/7800 loss 6.950215 loss_att 9.890215 loss_ctc 15.246547 loss_rnnt 5.198318 hw_loss 0.108222 lr 0.00029267 rank 4
2023-03-01 05:39:43,444 DEBUG TRAIN Batch 49/7800 loss 3.343187 loss_att 7.014585 loss_ctc 5.956306 loss_rnnt 2.111967 hw_loss 0.278485 lr 0.00029267 rank 5
2023-03-01 05:40:49,730 DEBUG TRAIN Batch 49/7900 loss 10.597463 loss_att 16.040844 loss_ctc 18.270321 loss_rnnt 8.313243 hw_loss 0.323430 lr 0.00029265 rank 6
2023-03-01 05:40:49,732 DEBUG TRAIN Batch 49/7900 loss 5.336838 loss_att 14.324001 loss_ctc 11.160433 loss_rnnt 2.654088 hw_loss 0.204073 lr 0.00029265 rank 5
2023-03-01 05:40:49,733 DEBUG TRAIN Batch 49/7900 loss 3.428854 loss_att 6.380733 loss_ctc 5.152290 loss_rnnt 2.490472 hw_loss 0.221653 lr 0.00029265 rank 4
2023-03-01 05:40:49,735 DEBUG TRAIN Batch 49/7900 loss 1.556209 loss_att 4.045345 loss_ctc 2.080180 loss_rnnt 0.851997 hw_loss 0.255979 lr 0.00029266 rank 0
2023-03-01 05:40:49,737 DEBUG TRAIN Batch 49/7900 loss 2.161419 loss_att 5.210209 loss_ctc 3.738335 loss_rnnt 1.206335 hw_loss 0.253258 lr 0.00029264 rank 7
2023-03-01 05:40:49,737 DEBUG TRAIN Batch 49/7900 loss 7.748726 loss_att 10.851204 loss_ctc 14.738900 loss_rnnt 6.072837 hw_loss 0.231319 lr 0.00029265 rank 3
2023-03-01 05:40:49,738 DEBUG TRAIN Batch 49/7900 loss 2.555249 loss_att 4.817694 loss_ctc 5.852117 loss_rnnt 1.594200 hw_loss 0.129333 lr 0.00029265 rank 1
2023-03-01 05:40:49,781 DEBUG TRAIN Batch 49/7900 loss 6.530891 loss_att 9.311361 loss_ctc 13.817686 loss_rnnt 4.860723 hw_loss 0.267190 lr 0.00029265 rank 2
2023-03-01 05:41:28,676 DEBUG TRAIN Batch 49/8000 loss 6.705369 loss_att 10.610140 loss_ctc 11.937346 loss_rnnt 5.191409 hw_loss 0.066393 lr 0.00029264 rank 1
2023-03-01 05:41:28,678 DEBUG TRAIN Batch 49/8000 loss 2.760606 loss_att 5.375482 loss_ctc 5.123468 loss_rnnt 1.779968 hw_loss 0.267402 lr 0.00029264 rank 5
2023-03-01 05:41:28,677 DEBUG TRAIN Batch 49/8000 loss 8.990140 loss_att 10.545668 loss_ctc 13.522541 loss_rnnt 8.032945 hw_loss 0.078318 lr 0.00029263 rank 7
2023-03-01 05:41:28,682 DEBUG TRAIN Batch 49/8000 loss 2.967350 loss_att 7.913071 loss_ctc 6.469920 loss_rnnt 1.355592 hw_loss 0.291758 lr 0.00029264 rank 0
2023-03-01 05:41:28,683 DEBUG TRAIN Batch 49/8000 loss 3.990240 loss_att 5.623336 loss_ctc 5.446399 loss_rnnt 3.308639 hw_loss 0.301551 lr 0.00029264 rank 2
2023-03-01 05:41:28,686 DEBUG TRAIN Batch 49/8000 loss 6.979065 loss_att 11.165576 loss_ctc 12.645218 loss_rnnt 5.306917 hw_loss 0.148796 lr 0.00029264 rank 6
2023-03-01 05:41:28,686 DEBUG TRAIN Batch 49/8000 loss 6.541468 loss_att 9.025417 loss_ctc 8.332323 loss_rnnt 5.737144 hw_loss 0.128913 lr 0.00029264 rank 4
2023-03-01 05:41:28,686 DEBUG TRAIN Batch 49/8000 loss 3.847553 loss_att 7.634033 loss_ctc 4.328317 loss_rnnt 2.923421 hw_loss 0.192625 lr 0.00029264 rank 3
2023-03-01 05:42:08,359 DEBUG TRAIN Batch 49/8100 loss 6.481809 loss_att 8.572099 loss_ctc 17.318745 loss_rnnt 4.474324 hw_loss 0.270942 lr 0.00029263 rank 5
2023-03-01 05:42:08,371 DEBUG TRAIN Batch 49/8100 loss 6.845412 loss_att 11.321678 loss_ctc 11.302892 loss_rnnt 5.189942 hw_loss 0.311035 lr 0.00029263 rank 2
2023-03-01 05:42:08,372 DEBUG TRAIN Batch 49/8100 loss 11.930635 loss_att 13.754751 loss_ctc 16.806499 loss_rnnt 10.782291 hw_loss 0.250134 lr 0.00029263 rank 0
2023-03-01 05:42:08,373 DEBUG TRAIN Batch 49/8100 loss 5.287785 loss_att 8.937579 loss_ctc 10.434539 loss_rnnt 3.693743 hw_loss 0.333466 lr 0.00029262 rank 7
2023-03-01 05:42:08,374 DEBUG TRAIN Batch 49/8100 loss 5.969696 loss_att 9.619504 loss_ctc 11.459966 loss_rnnt 4.452068 hw_loss 0.104306 lr 0.00029263 rank 1
2023-03-01 05:42:08,375 DEBUG TRAIN Batch 49/8100 loss 3.179410 loss_att 4.541272 loss_ctc 5.302081 loss_rnnt 2.546114 hw_loss 0.146064 lr 0.00029262 rank 3
2023-03-01 05:42:08,380 DEBUG TRAIN Batch 49/8100 loss 3.766084 loss_att 5.095103 loss_ctc 6.733825 loss_rnnt 2.988952 hw_loss 0.216806 lr 0.00029263 rank 6
2023-03-01 05:42:08,379 DEBUG TRAIN Batch 49/8100 loss 15.267482 loss_att 16.442528 loss_ctc 18.913042 loss_rnnt 14.525003 hw_loss 0.040115 lr 0.00029263 rank 4
2023-03-01 05:42:48,568 DEBUG TRAIN Batch 49/8200 loss 1.643958 loss_att 4.237073 loss_ctc 2.957358 loss_rnnt 0.782898 hw_loss 0.313719 lr 0.00029261 rank 7
2023-03-01 05:42:48,582 DEBUG TRAIN Batch 49/8200 loss 12.541934 loss_att 15.337296 loss_ctc 17.635527 loss_rnnt 11.153638 hw_loss 0.281397 lr 0.00029262 rank 0
2023-03-01 05:42:48,586 DEBUG TRAIN Batch 49/8200 loss 6.139616 loss_att 6.955944 loss_ctc 10.604283 loss_rnnt 5.232065 hw_loss 0.279367 lr 0.00029261 rank 3
2023-03-01 05:42:48,586 DEBUG TRAIN Batch 49/8200 loss 5.857015 loss_att 8.014924 loss_ctc 10.795375 loss_rnnt 4.626077 hw_loss 0.264203 lr 0.00029262 rank 4
2023-03-01 05:42:48,588 DEBUG TRAIN Batch 49/8200 loss 2.507254 loss_att 5.200068 loss_ctc 4.654877 loss_rnnt 1.626274 hw_loss 0.105126 lr 0.00029262 rank 6
2023-03-01 05:42:48,589 DEBUG TRAIN Batch 49/8200 loss 6.494667 loss_att 9.785223 loss_ctc 11.834295 loss_rnnt 5.028300 hw_loss 0.180571 lr 0.00029261 rank 5
2023-03-01 05:42:48,610 DEBUG TRAIN Batch 49/8200 loss 8.101860 loss_att 10.955650 loss_ctc 13.503070 loss_rnnt 6.697363 hw_loss 0.212957 lr 0.00029261 rank 1
2023-03-01 05:42:48,622 DEBUG TRAIN Batch 49/8200 loss 2.793855 loss_att 5.489184 loss_ctc 6.740717 loss_rnnt 1.588532 hw_loss 0.262517 lr 0.00029262 rank 2
2023-03-01 05:43:27,110 DEBUG TRAIN Batch 49/8300 loss 6.808827 loss_att 12.246100 loss_ctc 18.253735 loss_rnnt 4.098682 hw_loss 0.181319 lr 0.00029259 rank 7
2023-03-01 05:43:27,115 DEBUG TRAIN Batch 49/8300 loss 1.277005 loss_att 4.492562 loss_ctc 3.810566 loss_rnnt 0.205229 hw_loss 0.170354 lr 0.00029260 rank 5
2023-03-01 05:43:27,116 DEBUG TRAIN Batch 49/8300 loss 6.872922 loss_att 9.944119 loss_ctc 17.246960 loss_rnnt 4.755430 hw_loss 0.225089 lr 0.00029260 rank 1
2023-03-01 05:43:27,127 DEBUG TRAIN Batch 49/8300 loss 6.212703 loss_att 6.205117 loss_ctc 9.240738 loss_rnnt 5.602075 hw_loss 0.390763 lr 0.00029261 rank 0
2023-03-01 05:43:27,134 DEBUG TRAIN Batch 49/8300 loss 4.528815 loss_att 6.304917 loss_ctc 7.043920 loss_rnnt 3.699015 hw_loss 0.261061 lr 0.00029260 rank 6
2023-03-01 05:43:27,134 DEBUG TRAIN Batch 49/8300 loss 7.312122 loss_att 10.177878 loss_ctc 12.526186 loss_rnnt 5.876955 hw_loss 0.312765 lr 0.00029260 rank 4
2023-03-01 05:43:27,137 DEBUG TRAIN Batch 49/8300 loss 10.175068 loss_att 14.063438 loss_ctc 14.358734 loss_rnnt 8.701920 hw_loss 0.258098 lr 0.00029260 rank 3
2023-03-01 05:43:27,152 DEBUG TRAIN Batch 49/8300 loss 5.421230 loss_att 7.922110 loss_ctc 8.529341 loss_rnnt 4.415648 hw_loss 0.170610 lr 0.00029260 rank 2
2023-03-01 05:43:59,883 DEBUG CV Batch 49/0 loss 0.987538 loss_att 1.005060 loss_ctc 1.619313 loss_rnnt 0.722463 hw_loss 0.332501 history loss 0.950962 rank 5
2023-03-01 05:43:59,890 DEBUG CV Batch 49/0 loss 0.987538 loss_att 1.005060 loss_ctc 1.619313 loss_rnnt 0.722463 hw_loss 0.332501 history loss 0.950962 rank 0
2023-03-01 05:43:59,904 DEBUG CV Batch 49/0 loss 0.987538 loss_att 1.005060 loss_ctc 1.619313 loss_rnnt 0.722463 hw_loss 0.332501 history loss 0.950962 rank 6
2023-03-01 05:43:59,932 DEBUG CV Batch 49/0 loss 0.987538 loss_att 1.005060 loss_ctc 1.619313 loss_rnnt 0.722463 hw_loss 0.332501 history loss 0.950962 rank 7
2023-03-01 05:43:59,940 DEBUG CV Batch 49/0 loss 0.987538 loss_att 1.005060 loss_ctc 1.619313 loss_rnnt 0.722463 hw_loss 0.332501 history loss 0.950962 rank 1
2023-03-01 05:43:59,945 DEBUG CV Batch 49/0 loss 0.987538 loss_att 1.005060 loss_ctc 1.619313 loss_rnnt 0.722463 hw_loss 0.332501 history loss 0.950962 rank 3
2023-03-01 05:43:59,958 DEBUG CV Batch 49/0 loss 0.987538 loss_att 1.005060 loss_ctc 1.619313 loss_rnnt 0.722463 hw_loss 0.332501 history loss 0.950962 rank 4
2023-03-01 05:43:59,962 DEBUG CV Batch 49/0 loss 0.987538 loss_att 1.005060 loss_ctc 1.619313 loss_rnnt 0.722463 hw_loss 0.332501 history loss 0.950962 rank 2
2023-03-01 05:44:12,020 DEBUG CV Batch 49/100 loss 4.192776 loss_att 4.879061 loss_ctc 9.510160 loss_rnnt 3.243633 hw_loss 0.192940 history loss 2.977794 rank 1
2023-03-01 05:44:12,021 DEBUG CV Batch 49/100 loss 4.192776 loss_att 4.879061 loss_ctc 9.510160 loss_rnnt 3.243633 hw_loss 0.192940 history loss 2.977794 rank 7
2023-03-01 05:44:12,128 DEBUG CV Batch 49/100 loss 4.192776 loss_att 4.879061 loss_ctc 9.510160 loss_rnnt 3.243633 hw_loss 0.192940 history loss 2.977794 rank 0
2023-03-01 05:44:12,221 DEBUG CV Batch 49/100 loss 4.192776 loss_att 4.879061 loss_ctc 9.510160 loss_rnnt 3.243633 hw_loss 0.192940 history loss 2.977794 rank 2
2023-03-01 05:44:12,242 DEBUG CV Batch 49/100 loss 4.192776 loss_att 4.879061 loss_ctc 9.510160 loss_rnnt 3.243633 hw_loss 0.192940 history loss 2.977794 rank 5
2023-03-01 05:44:12,244 DEBUG CV Batch 49/100 loss 4.192776 loss_att 4.879061 loss_ctc 9.510160 loss_rnnt 3.243633 hw_loss 0.192940 history loss 2.977794 rank 6
2023-03-01 05:44:12,259 DEBUG CV Batch 49/100 loss 4.192776 loss_att 4.879061 loss_ctc 9.510160 loss_rnnt 3.243633 hw_loss 0.192940 history loss 2.977794 rank 3
2023-03-01 05:44:12,311 DEBUG CV Batch 49/100 loss 4.192776 loss_att 4.879061 loss_ctc 9.510160 loss_rnnt 3.243633 hw_loss 0.192940 history loss 2.977794 rank 4
2023-03-01 05:44:26,814 DEBUG CV Batch 49/200 loss 3.815113 loss_att 7.375580 loss_ctc 6.936968 loss_rnnt 2.514637 hw_loss 0.322754 history loss 3.529195 rank 7
2023-03-01 05:44:26,843 DEBUG CV Batch 49/200 loss 3.815113 loss_att 7.375580 loss_ctc 6.936968 loss_rnnt 2.514637 hw_loss 0.322754 history loss 3.529195 rank 0
2023-03-01 05:44:26,900 DEBUG CV Batch 49/200 loss 3.815113 loss_att 7.375580 loss_ctc 6.936968 loss_rnnt 2.514637 hw_loss 0.322754 history loss 3.529195 rank 1
2023-03-01 05:44:26,925 DEBUG CV Batch 49/200 loss 3.815113 loss_att 7.375580 loss_ctc 6.936968 loss_rnnt 2.514637 hw_loss 0.322754 history loss 3.529195 rank 5
2023-03-01 05:44:26,954 DEBUG CV Batch 49/200 loss 3.815113 loss_att 7.375580 loss_ctc 6.936968 loss_rnnt 2.514637 hw_loss 0.322754 history loss 3.529195 rank 2
2023-03-01 05:44:27,001 DEBUG CV Batch 49/200 loss 3.815113 loss_att 7.375580 loss_ctc 6.936968 loss_rnnt 2.514637 hw_loss 0.322754 history loss 3.529195 rank 4
2023-03-01 05:44:27,166 DEBUG CV Batch 49/200 loss 3.815113 loss_att 7.375580 loss_ctc 6.936968 loss_rnnt 2.514637 hw_loss 0.322754 history loss 3.529195 rank 3
2023-03-01 05:44:27,171 DEBUG CV Batch 49/200 loss 3.815113 loss_att 7.375580 loss_ctc 6.936968 loss_rnnt 2.514637 hw_loss 0.322754 history loss 3.529195 rank 6
2023-03-01 05:44:39,001 DEBUG CV Batch 49/300 loss 3.917645 loss_att 4.753562 loss_ctc 7.517654 loss_rnnt 3.052093 hw_loss 0.409439 history loss 3.682257 rank 7
2023-03-01 05:44:39,228 DEBUG CV Batch 49/300 loss 3.917645 loss_att 4.753562 loss_ctc 7.517654 loss_rnnt 3.052093 hw_loss 0.409439 history loss 3.682257 rank 0
2023-03-01 05:44:39,237 DEBUG CV Batch 49/300 loss 3.917645 loss_att 4.753562 loss_ctc 7.517654 loss_rnnt 3.052093 hw_loss 0.409439 history loss 3.682257 rank 4
2023-03-01 05:44:39,266 DEBUG CV Batch 49/300 loss 3.917645 loss_att 4.753562 loss_ctc 7.517654 loss_rnnt 3.052093 hw_loss 0.409439 history loss 3.682257 rank 2
2023-03-01 05:44:39,322 DEBUG CV Batch 49/300 loss 3.917645 loss_att 4.753562 loss_ctc 7.517654 loss_rnnt 3.052093 hw_loss 0.409439 history loss 3.682257 rank 1
2023-03-01 05:44:39,327 DEBUG CV Batch 49/300 loss 3.917645 loss_att 4.753562 loss_ctc 7.517654 loss_rnnt 3.052093 hw_loss 0.409439 history loss 3.682257 rank 5
2023-03-01 05:44:39,599 DEBUG CV Batch 49/300 loss 3.917645 loss_att 4.753562 loss_ctc 7.517654 loss_rnnt 3.052093 hw_loss 0.409439 history loss 3.682257 rank 3
2023-03-01 05:44:39,972 DEBUG CV Batch 49/300 loss 3.917645 loss_att 4.753562 loss_ctc 7.517654 loss_rnnt 3.052093 hw_loss 0.409439 history loss 3.682257 rank 6
2023-03-01 05:44:51,159 DEBUG CV Batch 49/400 loss 13.571375 loss_att 63.443825 loss_ctc 5.136629 loss_rnnt 4.633420 hw_loss 0.165184 history loss 4.457224 rank 7
2023-03-01 05:44:51,477 DEBUG CV Batch 49/400 loss 13.571375 loss_att 63.443825 loss_ctc 5.136629 loss_rnnt 4.633420 hw_loss 0.165184 history loss 4.457224 rank 2
2023-03-01 05:44:51,518 DEBUG CV Batch 49/400 loss 13.571375 loss_att 63.443825 loss_ctc 5.136629 loss_rnnt 4.633420 hw_loss 0.165184 history loss 4.457224 rank 0
2023-03-01 05:44:51,522 DEBUG CV Batch 49/400 loss 13.571375 loss_att 63.443825 loss_ctc 5.136629 loss_rnnt 4.633420 hw_loss 0.165184 history loss 4.457224 rank 1
2023-03-01 05:44:51,554 DEBUG CV Batch 49/400 loss 13.571375 loss_att 63.443825 loss_ctc 5.136629 loss_rnnt 4.633420 hw_loss 0.165184 history loss 4.457224 rank 4
2023-03-01 05:44:51,714 DEBUG CV Batch 49/400 loss 13.571375 loss_att 63.443825 loss_ctc 5.136629 loss_rnnt 4.633420 hw_loss 0.165184 history loss 4.457224 rank 5
2023-03-01 05:44:52,064 DEBUG CV Batch 49/400 loss 13.571375 loss_att 63.443825 loss_ctc 5.136629 loss_rnnt 4.633420 hw_loss 0.165184 history loss 4.457224 rank 3
2023-03-01 05:44:52,717 DEBUG CV Batch 49/400 loss 13.571375 loss_att 63.443825 loss_ctc 5.136629 loss_rnnt 4.633420 hw_loss 0.165184 history loss 4.457224 rank 6
2023-03-01 05:45:02,520 DEBUG CV Batch 49/500 loss 4.648044 loss_att 4.231723 loss_ctc 5.626947 loss_rnnt 4.507862 hw_loss 0.174235 history loss 5.038685 rank 7
2023-03-01 05:45:02,573 DEBUG CV Batch 49/500 loss 4.648044 loss_att 4.231723 loss_ctc 5.626947 loss_rnnt 4.507862 hw_loss 0.174235 history loss 5.038685 rank 0
2023-03-01 05:45:02,583 DEBUG CV Batch 49/500 loss 4.648044 loss_att 4.231723 loss_ctc 5.626947 loss_rnnt 4.507862 hw_loss 0.174235 history loss 5.038685 rank 1
2023-03-01 05:45:02,598 DEBUG CV Batch 49/500 loss 4.648044 loss_att 4.231723 loss_ctc 5.626947 loss_rnnt 4.507862 hw_loss 0.174235 history loss 5.038685 rank 2
2023-03-01 05:45:02,718 DEBUG CV Batch 49/500 loss 4.648044 loss_att 4.231723 loss_ctc 5.626947 loss_rnnt 4.507862 hw_loss 0.174235 history loss 5.038685 rank 4
2023-03-01 05:45:02,874 DEBUG CV Batch 49/500 loss 4.648044 loss_att 4.231723 loss_ctc 5.626947 loss_rnnt 4.507862 hw_loss 0.174235 history loss 5.038685 rank 5
2023-03-01 05:45:03,568 DEBUG CV Batch 49/500 loss 4.648044 loss_att 4.231723 loss_ctc 5.626947 loss_rnnt 4.507862 hw_loss 0.174235 history loss 5.038685 rank 6
2023-03-01 05:45:03,805 DEBUG CV Batch 49/500 loss 4.648044 loss_att 4.231723 loss_ctc 5.626947 loss_rnnt 4.507862 hw_loss 0.174235 history loss 5.038685 rank 3
2023-03-01 05:45:16,441 DEBUG CV Batch 49/600 loss 7.069227 loss_att 6.310866 loss_ctc 10.250817 loss_rnnt 6.583519 hw_loss 0.399689 history loss 5.902591 rank 7
2023-03-01 05:45:16,537 DEBUG CV Batch 49/600 loss 7.069227 loss_att 6.310866 loss_ctc 10.250817 loss_rnnt 6.583519 hw_loss 0.399689 history loss 5.902591 rank 1
2023-03-01 05:45:16,574 DEBUG CV Batch 49/600 loss 7.069227 loss_att 6.310866 loss_ctc 10.250817 loss_rnnt 6.583519 hw_loss 0.399689 history loss 5.902591 rank 4
2023-03-01 05:45:16,595 DEBUG CV Batch 49/600 loss 7.069227 loss_att 6.310866 loss_ctc 10.250817 loss_rnnt 6.583519 hw_loss 0.399689 history loss 5.902591 rank 2
2023-03-01 05:45:16,619 DEBUG CV Batch 49/600 loss 7.069227 loss_att 6.310866 loss_ctc 10.250817 loss_rnnt 6.583519 hw_loss 0.399689 history loss 5.902591 rank 0
2023-03-01 05:45:16,696 DEBUG CV Batch 49/600 loss 7.069227 loss_att 6.310866 loss_ctc 10.250817 loss_rnnt 6.583519 hw_loss 0.399689 history loss 5.902591 rank 5
2023-03-01 05:45:16,767 DEBUG CV Batch 49/600 loss 7.069227 loss_att 6.310866 loss_ctc 10.250817 loss_rnnt 6.583519 hw_loss 0.399689 history loss 5.902591 rank 6
2023-03-01 05:45:16,923 DEBUG CV Batch 49/600 loss 7.069227 loss_att 6.310866 loss_ctc 10.250817 loss_rnnt 6.583519 hw_loss 0.399689 history loss 5.902591 rank 3
2023-03-01 05:45:29,184 DEBUG CV Batch 49/700 loss 11.983791 loss_att 29.803833 loss_ctc 15.401275 loss_rnnt 7.963957 hw_loss 0.000303 history loss 6.450718 rank 7
2023-03-01 05:45:29,255 DEBUG CV Batch 49/700 loss 11.983791 loss_att 29.803833 loss_ctc 15.401275 loss_rnnt 7.963957 hw_loss 0.000303 history loss 6.450718 rank 4
2023-03-01 05:45:29,270 DEBUG CV Batch 49/700 loss 11.983791 loss_att 29.803833 loss_ctc 15.401275 loss_rnnt 7.963957 hw_loss 0.000303 history loss 6.450718 rank 0
2023-03-01 05:45:29,292 DEBUG CV Batch 49/700 loss 11.983791 loss_att 29.803833 loss_ctc 15.401275 loss_rnnt 7.963957 hw_loss 0.000303 history loss 6.450718 rank 2
2023-03-01 05:45:29,328 DEBUG CV Batch 49/700 loss 11.983791 loss_att 29.803833 loss_ctc 15.401275 loss_rnnt 7.963957 hw_loss 0.000303 history loss 6.450718 rank 1
2023-03-01 05:45:29,404 DEBUG CV Batch 49/700 loss 11.983791 loss_att 29.803833 loss_ctc 15.401275 loss_rnnt 7.963957 hw_loss 0.000303 history loss 6.450718 rank 5
2023-03-01 05:45:29,457 DEBUG CV Batch 49/700 loss 11.983791 loss_att 29.803833 loss_ctc 15.401275 loss_rnnt 7.963957 hw_loss 0.000303 history loss 6.450718 rank 3
2023-03-01 05:45:29,517 DEBUG CV Batch 49/700 loss 11.983791 loss_att 29.803833 loss_ctc 15.401275 loss_rnnt 7.963957 hw_loss 0.000303 history loss 6.450718 rank 6
2023-03-01 05:45:41,350 DEBUG CV Batch 49/800 loss 6.760545 loss_att 6.961553 loss_ctc 13.658960 loss_rnnt 5.644670 hw_loss 0.292285 history loss 5.989784 rank 7
2023-03-01 05:45:41,582 DEBUG CV Batch 49/800 loss 6.760545 loss_att 6.961553 loss_ctc 13.658960 loss_rnnt 5.644670 hw_loss 0.292285 history loss 5.989784 rank 0
2023-03-01 05:45:41,700 DEBUG CV Batch 49/800 loss 6.760545 loss_att 6.961553 loss_ctc 13.658960 loss_rnnt 5.644670 hw_loss 0.292285 history loss 5.989784 rank 4
2023-03-01 05:45:41,704 DEBUG CV Batch 49/800 loss 6.760545 loss_att 6.961553 loss_ctc 13.658960 loss_rnnt 5.644670 hw_loss 0.292285 history loss 5.989784 rank 5
2023-03-01 05:45:41,710 DEBUG CV Batch 49/800 loss 6.760545 loss_att 6.961553 loss_ctc 13.658960 loss_rnnt 5.644670 hw_loss 0.292285 history loss 5.989784 rank 2
2023-03-01 05:45:41,747 DEBUG CV Batch 49/800 loss 6.760545 loss_att 6.961553 loss_ctc 13.658960 loss_rnnt 5.644670 hw_loss 0.292285 history loss 5.989784 rank 1
2023-03-01 05:45:41,996 DEBUG CV Batch 49/800 loss 6.760545 loss_att 6.961553 loss_ctc 13.658960 loss_rnnt 5.644670 hw_loss 0.292285 history loss 5.989784 rank 6
2023-03-01 05:45:42,085 DEBUG CV Batch 49/800 loss 6.760545 loss_att 6.961553 loss_ctc 13.658960 loss_rnnt 5.644670 hw_loss 0.292285 history loss 5.989784 rank 3
2023-03-01 05:45:55,076 DEBUG CV Batch 49/900 loss 9.171903 loss_att 11.189579 loss_ctc 17.685305 loss_rnnt 7.574469 hw_loss 0.110208 history loss 5.828800 rank 7
2023-03-01 05:45:55,363 DEBUG CV Batch 49/900 loss 9.171903 loss_att 11.189579 loss_ctc 17.685305 loss_rnnt 7.574469 hw_loss 0.110208 history loss 5.828800 rank 0
2023-03-01 05:45:55,565 DEBUG CV Batch 49/900 loss 9.171903 loss_att 11.189579 loss_ctc 17.685305 loss_rnnt 7.574469 hw_loss 0.110208 history loss 5.828800 rank 4
2023-03-01 05:45:55,591 DEBUG CV Batch 49/900 loss 9.171903 loss_att 11.189579 loss_ctc 17.685305 loss_rnnt 7.574469 hw_loss 0.110208 history loss 5.828800 rank 5
2023-03-01 05:45:55,807 DEBUG CV Batch 49/900 loss 9.171903 loss_att 11.189579 loss_ctc 17.685305 loss_rnnt 7.574469 hw_loss 0.110208 history loss 5.828800 rank 2
2023-03-01 05:45:55,905 DEBUG CV Batch 49/900 loss 9.171903 loss_att 11.189579 loss_ctc 17.685305 loss_rnnt 7.574469 hw_loss 0.110208 history loss 5.828800 rank 6
2023-03-01 05:45:56,103 DEBUG CV Batch 49/900 loss 9.171903 loss_att 11.189579 loss_ctc 17.685305 loss_rnnt 7.574469 hw_loss 0.110208 history loss 5.828800 rank 3
2023-03-01 05:45:56,165 DEBUG CV Batch 49/900 loss 9.171903 loss_att 11.189579 loss_ctc 17.685305 loss_rnnt 7.574469 hw_loss 0.110208 history loss 5.828800 rank 1
2023-03-01 05:46:07,535 DEBUG CV Batch 49/1000 loss 3.259130 loss_att 3.156930 loss_ctc 3.532297 loss_rnnt 3.122059 hw_loss 0.227040 history loss 5.644421 rank 7
2023-03-01 05:46:07,881 DEBUG CV Batch 49/1000 loss 3.259130 loss_att 3.156930 loss_ctc 3.532297 loss_rnnt 3.122059 hw_loss 0.227040 history loss 5.644421 rank 0
2023-03-01 05:46:08,223 DEBUG CV Batch 49/1000 loss 3.259130 loss_att 3.156930 loss_ctc 3.532297 loss_rnnt 3.122059 hw_loss 0.227040 history loss 5.644421 rank 4
2023-03-01 05:46:08,359 DEBUG CV Batch 49/1000 loss 3.259130 loss_att 3.156930 loss_ctc 3.532297 loss_rnnt 3.122059 hw_loss 0.227040 history loss 5.644421 rank 5
2023-03-01 05:46:08,522 DEBUG CV Batch 49/1000 loss 3.259130 loss_att 3.156930 loss_ctc 3.532297 loss_rnnt 3.122059 hw_loss 0.227040 history loss 5.644421 rank 1
2023-03-01 05:46:08,599 DEBUG CV Batch 49/1000 loss 3.259130 loss_att 3.156930 loss_ctc 3.532297 loss_rnnt 3.122059 hw_loss 0.227040 history loss 5.644421 rank 2
2023-03-01 05:46:08,792 DEBUG CV Batch 49/1000 loss 3.259130 loss_att 3.156930 loss_ctc 3.532297 loss_rnnt 3.122059 hw_loss 0.227040 history loss 5.644421 rank 6
2023-03-01 05:46:08,850 DEBUG CV Batch 49/1000 loss 3.259130 loss_att 3.156930 loss_ctc 3.532297 loss_rnnt 3.122059 hw_loss 0.227040 history loss 5.644421 rank 3
2023-03-01 05:46:19,789 DEBUG CV Batch 49/1100 loss 4.800079 loss_att 4.723124 loss_ctc 8.629189 loss_rnnt 4.082139 hw_loss 0.417717 history loss 5.601591 rank 7
2023-03-01 05:46:20,285 DEBUG CV Batch 49/1100 loss 4.800079 loss_att 4.723124 loss_ctc 8.629189 loss_rnnt 4.082139 hw_loss 0.417717 history loss 5.601591 rank 0
2023-03-01 05:46:20,498 DEBUG CV Batch 49/1100 loss 4.800079 loss_att 4.723124 loss_ctc 8.629189 loss_rnnt 4.082139 hw_loss 0.417717 history loss 5.601591 rank 4
2023-03-01 05:46:20,588 DEBUG CV Batch 49/1100 loss 4.800079 loss_att 4.723124 loss_ctc 8.629189 loss_rnnt 4.082139 hw_loss 0.417717 history loss 5.601591 rank 1
2023-03-01 05:46:20,928 DEBUG CV Batch 49/1100 loss 4.800079 loss_att 4.723124 loss_ctc 8.629189 loss_rnnt 4.082139 hw_loss 0.417717 history loss 5.601591 rank 2
2023-03-01 05:46:21,000 DEBUG CV Batch 49/1100 loss 4.800079 loss_att 4.723124 loss_ctc 8.629189 loss_rnnt 4.082139 hw_loss 0.417717 history loss 5.601591 rank 5
2023-03-01 05:46:21,138 DEBUG CV Batch 49/1100 loss 4.800079 loss_att 4.723124 loss_ctc 8.629189 loss_rnnt 4.082139 hw_loss 0.417717 history loss 5.601591 rank 3
2023-03-01 05:46:21,316 DEBUG CV Batch 49/1100 loss 4.800079 loss_att 4.723124 loss_ctc 8.629189 loss_rnnt 4.082139 hw_loss 0.417717 history loss 5.601591 rank 6
2023-03-01 05:46:30,462 DEBUG CV Batch 49/1200 loss 6.194217 loss_att 6.222898 loss_ctc 7.343369 loss_rnnt 5.862803 hw_loss 0.323357 history loss 5.865322 rank 7
2023-03-01 05:46:31,086 DEBUG CV Batch 49/1200 loss 6.194217 loss_att 6.222898 loss_ctc 7.343369 loss_rnnt 5.862803 hw_loss 0.323357 history loss 5.865322 rank 4
2023-03-01 05:46:31,091 DEBUG CV Batch 49/1200 loss 6.194217 loss_att 6.222898 loss_ctc 7.343369 loss_rnnt 5.862803 hw_loss 0.323357 history loss 5.865322 rank 0
2023-03-01 05:46:31,317 DEBUG CV Batch 49/1200 loss 6.194217 loss_att 6.222898 loss_ctc 7.343369 loss_rnnt 5.862803 hw_loss 0.323357 history loss 5.865322 rank 1
2023-03-01 05:46:31,950 DEBUG CV Batch 49/1200 loss 6.194217 loss_att 6.222898 loss_ctc 7.343369 loss_rnnt 5.862803 hw_loss 0.323357 history loss 5.865322 rank 3
2023-03-01 05:46:32,041 DEBUG CV Batch 49/1200 loss 6.194217 loss_att 6.222898 loss_ctc 7.343369 loss_rnnt 5.862803 hw_loss 0.323357 history loss 5.865322 rank 2
2023-03-01 05:46:32,100 DEBUG CV Batch 49/1200 loss 6.194217 loss_att 6.222898 loss_ctc 7.343369 loss_rnnt 5.862803 hw_loss 0.323357 history loss 5.865322 rank 5
2023-03-01 05:46:32,448 DEBUG CV Batch 49/1200 loss 6.194217 loss_att 6.222898 loss_ctc 7.343369 loss_rnnt 5.862803 hw_loss 0.323357 history loss 5.865322 rank 6
2023-03-01 05:46:42,649 DEBUG CV Batch 49/1300 loss 4.992605 loss_att 4.816691 loss_ctc 7.527953 loss_rnnt 4.504422 hw_loss 0.347472 history loss 6.162613 rank 7
2023-03-01 05:46:43,395 DEBUG CV Batch 49/1300 loss 4.992605 loss_att 4.816691 loss_ctc 7.527953 loss_rnnt 4.504422 hw_loss 0.347472 history loss 6.162613 rank 1
2023-03-01 05:46:43,404 DEBUG CV Batch 49/1300 loss 4.992605 loss_att 4.816691 loss_ctc 7.527953 loss_rnnt 4.504422 hw_loss 0.347472 history loss 6.162613 rank 0
2023-03-01 05:46:43,521 DEBUG CV Batch 49/1300 loss 4.992605 loss_att 4.816691 loss_ctc 7.527953 loss_rnnt 4.504422 hw_loss 0.347472 history loss 6.162613 rank 4
2023-03-01 05:46:44,203 DEBUG CV Batch 49/1300 loss 4.992605 loss_att 4.816691 loss_ctc 7.527953 loss_rnnt 4.504422 hw_loss 0.347472 history loss 6.162613 rank 2
2023-03-01 05:46:44,360 DEBUG CV Batch 49/1300 loss 4.992605 loss_att 4.816691 loss_ctc 7.527953 loss_rnnt 4.504422 hw_loss 0.347472 history loss 6.162613 rank 3
2023-03-01 05:46:44,514 DEBUG CV Batch 49/1300 loss 4.992605 loss_att 4.816691 loss_ctc 7.527953 loss_rnnt 4.504422 hw_loss 0.347472 history loss 6.162613 rank 5
2023-03-01 05:46:45,112 DEBUG CV Batch 49/1300 loss 4.992605 loss_att 4.816691 loss_ctc 7.527953 loss_rnnt 4.504422 hw_loss 0.347472 history loss 6.162613 rank 6
2023-03-01 05:46:54,074 DEBUG CV Batch 49/1400 loss 2.734295 loss_att 10.894883 loss_ctc 2.860093 loss_rnnt 0.958633 hw_loss 0.237698 history loss 6.437543 rank 7
2023-03-01 05:46:54,852 DEBUG CV Batch 49/1400 loss 2.734295 loss_att 10.894883 loss_ctc 2.860093 loss_rnnt 0.958633 hw_loss 0.237698 history loss 6.437543 rank 1
2023-03-01 05:46:54,902 DEBUG CV Batch 49/1400 loss 2.734295 loss_att 10.894883 loss_ctc 2.860093 loss_rnnt 0.958633 hw_loss 0.237698 history loss 6.437543 rank 4
2023-03-01 05:46:54,939 DEBUG CV Batch 49/1400 loss 2.734295 loss_att 10.894883 loss_ctc 2.860093 loss_rnnt 0.958633 hw_loss 0.237698 history loss 6.437543 rank 0
2023-03-01 05:46:55,910 DEBUG CV Batch 49/1400 loss 2.734295 loss_att 10.894883 loss_ctc 2.860093 loss_rnnt 0.958633 hw_loss 0.237698 history loss 6.437543 rank 2
2023-03-01 05:46:56,013 DEBUG CV Batch 49/1400 loss 2.734295 loss_att 10.894883 loss_ctc 2.860093 loss_rnnt 0.958633 hw_loss 0.237698 history loss 6.437543 rank 3
2023-03-01 05:46:56,595 DEBUG CV Batch 49/1400 loss 2.734295 loss_att 10.894883 loss_ctc 2.860093 loss_rnnt 0.958633 hw_loss 0.237698 history loss 6.437543 rank 5
2023-03-01 05:46:57,322 DEBUG CV Batch 49/1400 loss 2.734295 loss_att 10.894883 loss_ctc 2.860093 loss_rnnt 0.958633 hw_loss 0.237698 history loss 6.437543 rank 6
2023-03-01 05:47:05,665 DEBUG CV Batch 49/1500 loss 7.313889 loss_att 7.093928 loss_ctc 6.926131 loss_rnnt 7.304256 hw_loss 0.197487 history loss 6.305088 rank 7
2023-03-01 05:47:06,610 DEBUG CV Batch 49/1500 loss 7.313889 loss_att 7.093928 loss_ctc 6.926131 loss_rnnt 7.304256 hw_loss 0.197487 history loss 6.305088 rank 0
2023-03-01 05:47:07,167 DEBUG CV Batch 49/1500 loss 7.313889 loss_att 7.093928 loss_ctc 6.926131 loss_rnnt 7.304256 hw_loss 0.197487 history loss 6.305088 rank 4
2023-03-01 05:47:07,528 DEBUG CV Batch 49/1500 loss 7.313889 loss_att 7.093928 loss_ctc 6.926131 loss_rnnt 7.304256 hw_loss 0.197487 history loss 6.305088 rank 1
2023-03-01 05:47:07,672 DEBUG CV Batch 49/1500 loss 7.313889 loss_att 7.093928 loss_ctc 6.926131 loss_rnnt 7.304256 hw_loss 0.197487 history loss 6.305088 rank 2
2023-03-01 05:47:08,005 DEBUG CV Batch 49/1500 loss 7.313889 loss_att 7.093928 loss_ctc 6.926131 loss_rnnt 7.304256 hw_loss 0.197487 history loss 6.305088 rank 3
2023-03-01 05:47:08,477 DEBUG CV Batch 49/1500 loss 7.313889 loss_att 7.093928 loss_ctc 6.926131 loss_rnnt 7.304256 hw_loss 0.197487 history loss 6.305088 rank 5
2023-03-01 05:47:09,951 DEBUG CV Batch 49/1500 loss 7.313889 loss_att 7.093928 loss_ctc 6.926131 loss_rnnt 7.304256 hw_loss 0.197487 history loss 6.305088 rank 6
2023-03-01 05:47:19,011 DEBUG CV Batch 49/1600 loss 10.763390 loss_att 13.846120 loss_ctc 12.138736 loss_rnnt 9.794662 hw_loss 0.316501 history loss 6.266991 rank 7
2023-03-01 05:47:20,118 DEBUG CV Batch 49/1600 loss 10.763390 loss_att 13.846120 loss_ctc 12.138736 loss_rnnt 9.794662 hw_loss 0.316501 history loss 6.266991 rank 0
2023-03-01 05:47:21,108 DEBUG CV Batch 49/1600 loss 10.763390 loss_att 13.846120 loss_ctc 12.138736 loss_rnnt 9.794662 hw_loss 0.316501 history loss 6.266991 rank 4
2023-03-01 05:47:21,597 DEBUG CV Batch 49/1600 loss 10.763390 loss_att 13.846120 loss_ctc 12.138736 loss_rnnt 9.794662 hw_loss 0.316501 history loss 6.266991 rank 2
2023-03-01 05:47:21,790 DEBUG CV Batch 49/1600 loss 10.763390 loss_att 13.846120 loss_ctc 12.138736 loss_rnnt 9.794662 hw_loss 0.316501 history loss 6.266991 rank 1
2023-03-01 05:47:21,994 DEBUG CV Batch 49/1600 loss 10.763390 loss_att 13.846120 loss_ctc 12.138736 loss_rnnt 9.794662 hw_loss 0.316501 history loss 6.266991 rank 3
2023-03-01 05:47:22,250 DEBUG CV Batch 49/1600 loss 10.763390 loss_att 13.846120 loss_ctc 12.138736 loss_rnnt 9.794662 hw_loss 0.316501 history loss 6.266991 rank 5
2023-03-01 05:47:23,859 DEBUG CV Batch 49/1600 loss 10.763390 loss_att 13.846120 loss_ctc 12.138736 loss_rnnt 9.794662 hw_loss 0.316501 history loss 6.266991 rank 6
2023-03-01 05:47:31,760 DEBUG CV Batch 49/1700 loss 8.355664 loss_att 5.968464 loss_ctc 14.435626 loss_rnnt 7.869515 hw_loss 0.286739 history loss 6.202872 rank 7
2023-03-01 05:47:33,011 DEBUG CV Batch 49/1700 loss 8.355664 loss_att 5.968464 loss_ctc 14.435626 loss_rnnt 7.869515 hw_loss 0.286739 history loss 6.202872 rank 0
2023-03-01 05:47:33,859 DEBUG CV Batch 49/1700 loss 8.355664 loss_att 5.968464 loss_ctc 14.435626 loss_rnnt 7.869515 hw_loss 0.286739 history loss 6.202872 rank 4
2023-03-01 05:47:34,355 DEBUG CV Batch 49/1700 loss 8.355664 loss_att 5.968464 loss_ctc 14.435626 loss_rnnt 7.869515 hw_loss 0.286739 history loss 6.202872 rank 1
2023-03-01 05:47:34,417 DEBUG CV Batch 49/1700 loss 8.355664 loss_att 5.968464 loss_ctc 14.435626 loss_rnnt 7.869515 hw_loss 0.286739 history loss 6.202872 rank 2
2023-03-01 05:47:34,925 DEBUG CV Batch 49/1700 loss 8.355664 loss_att 5.968464 loss_ctc 14.435626 loss_rnnt 7.869515 hw_loss 0.286739 history loss 6.202872 rank 3
2023-03-01 05:47:35,219 DEBUG CV Batch 49/1700 loss 8.355664 loss_att 5.968464 loss_ctc 14.435626 loss_rnnt 7.869515 hw_loss 0.286739 history loss 6.202872 rank 5
2023-03-01 05:47:36,929 DEBUG CV Batch 49/1700 loss 8.355664 loss_att 5.968464 loss_ctc 14.435626 loss_rnnt 7.869515 hw_loss 0.286739 history loss 6.202872 rank 6
2023-03-01 05:47:40,918 INFO Epoch 49 CV info cv_loss 6.181851023090146
2023-03-01 05:47:40,918 INFO Epoch 50 TRAIN info lr 0.00029258733722537173
2023-03-01 05:47:40,923 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 05:47:42,169 INFO Epoch 49 CV info cv_loss 6.181851024151899
2023-03-01 05:47:42,170 INFO Checkpoint: save to checkpoint exp/2_27_rnnt_bias_loss_2_class_both_finetune/49.pt
2023-03-01 05:47:42,728 INFO Epoch 50 TRAIN info lr 0.0002926023669593051
2023-03-01 05:47:42,733 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 05:47:43,101 INFO Epoch 49 CV info cv_loss 6.1818510244426434
2023-03-01 05:47:43,102 INFO Epoch 50 TRAIN info lr 0.000292597356790646
2023-03-01 05:47:43,107 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 05:47:43,541 INFO Epoch 49 CV info cv_loss 6.181851024098058
2023-03-01 05:47:43,541 INFO Epoch 50 TRAIN info lr 0.0002926013649049838
2023-03-01 05:47:43,543 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 05:47:44,009 INFO Epoch 49 CV info cv_loss 6.18185102287478
2023-03-01 05:47:44,010 INFO Epoch 50 TRAIN info lr 0.0002926028679903264
2023-03-01 05:47:44,012 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 05:47:44,405 INFO Epoch 49 CV info cv_loss 6.181851023090146
2023-03-01 05:47:44,406 INFO Epoch 50 TRAIN info lr 0.0002925923468793422
2023-03-01 05:47:44,411 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 05:47:44,472 INFO Epoch 49 CV info cv_loss 6.181851024382341
2023-03-01 05:47:44,473 INFO Epoch 50 TRAIN info lr 0.00029259685578793493
2023-03-01 05:47:44,478 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 05:47:46,502 INFO Epoch 49 CV info cv_loss 6.181851025235189
2023-03-01 05:47:46,502 INFO Epoch 50 TRAIN info lr 0.00029259635478779745
2023-03-01 05:47:46,504 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 05:48:48,819 DEBUG TRAIN Batch 50/0 loss 6.500494 loss_att 6.882508 loss_ctc 10.007867 loss_rnnt 5.737563 hw_loss 0.410398 lr 0.00029259 rank 7
2023-03-01 05:48:48,819 DEBUG TRAIN Batch 50/0 loss 7.583007 loss_att 7.522021 loss_ctc 10.991463 loss_rnnt 6.937196 hw_loss 0.381652 lr 0.00029260 rank 5
2023-03-01 05:48:48,823 DEBUG TRAIN Batch 50/0 loss 3.804936 loss_att 4.265917 loss_ctc 6.482080 loss_rnnt 3.186546 hw_loss 0.317325 lr 0.00029260 rank 0
2023-03-01 05:48:48,824 DEBUG TRAIN Batch 50/0 loss 5.331379 loss_att 5.374002 loss_ctc 8.323778 loss_rnnt 4.732836 hw_loss 0.358184 lr 0.00029260 rank 4
2023-03-01 05:48:48,827 DEBUG TRAIN Batch 50/0 loss 6.824057 loss_att 7.663417 loss_ctc 10.681702 loss_rnnt 5.971019 hw_loss 0.320275 lr 0.00029260 rank 1
2023-03-01 05:48:48,861 DEBUG TRAIN Batch 50/0 loss 6.699876 loss_att 6.783927 loss_ctc 11.492870 loss_rnnt 5.855566 hw_loss 0.353313 lr 0.00029260 rank 2
2023-03-01 05:48:48,873 DEBUG TRAIN Batch 50/0 loss 5.912368 loss_att 6.148245 loss_ctc 8.587726 loss_rnnt 5.368598 hw_loss 0.262275 lr 0.00029260 rank 6
2023-03-01 05:48:48,879 DEBUG TRAIN Batch 50/0 loss 6.225214 loss_att 5.839515 loss_ctc 9.522275 loss_rnnt 5.741667 hw_loss 0.227021 lr 0.00029259 rank 3
2023-03-01 05:49:26,619 DEBUG TRAIN Batch 50/100 loss 5.806644 loss_att 8.149353 loss_ctc 8.556017 loss_rnnt 4.849387 hw_loss 0.228997 lr 0.00029258 rank 4
2023-03-01 05:49:26,640 DEBUG TRAIN Batch 50/100 loss 6.264132 loss_att 6.987895 loss_ctc 7.471096 loss_rnnt 5.754977 hw_loss 0.381515 lr 0.00029259 rank 2
2023-03-01 05:49:26,641 DEBUG TRAIN Batch 50/100 loss 18.094790 loss_att 20.681507 loss_ctc 28.744965 loss_rnnt 16.110580 hw_loss 0.087826 lr 0.00029259 rank 0
2023-03-01 05:49:26,641 DEBUG TRAIN Batch 50/100 loss 3.479328 loss_att 6.384409 loss_ctc 8.322973 loss_rnnt 2.150571 hw_loss 0.191102 lr 0.00029259 rank 1
2023-03-01 05:49:26,641 DEBUG TRAIN Batch 50/100 loss 1.487385 loss_att 4.074705 loss_ctc 2.897005 loss_rnnt 0.694281 hw_loss 0.164421 lr 0.00029258 rank 5
2023-03-01 05:49:26,641 DEBUG TRAIN Batch 50/100 loss 1.318206 loss_att 3.606623 loss_ctc 1.878178 loss_rnnt 0.719182 hw_loss 0.125020 lr 0.00029258 rank 3
2023-03-01 05:49:26,642 DEBUG TRAIN Batch 50/100 loss 10.752079 loss_att 12.920383 loss_ctc 17.659611 loss_rnnt 9.317310 hw_loss 0.150195 lr 0.00029257 rank 7
2023-03-01 05:49:26,689 DEBUG TRAIN Batch 50/100 loss 7.947085 loss_att 11.377425 loss_ctc 15.770267 loss_rnnt 6.105262 hw_loss 0.211246 lr 0.00029258 rank 6
2023-03-01 05:50:04,930 DEBUG TRAIN Batch 50/200 loss 5.259119 loss_att 8.024922 loss_ctc 10.238848 loss_rnnt 3.892311 hw_loss 0.280657 lr 0.00029256 rank 7
2023-03-01 05:50:04,954 DEBUG TRAIN Batch 50/200 loss 5.180498 loss_att 8.752795 loss_ctc 7.311513 loss_rnnt 4.099680 hw_loss 0.154166 lr 0.00029258 rank 0
2023-03-01 05:50:04,955 DEBUG TRAIN Batch 50/200 loss 1.755905 loss_att 6.437378 loss_ctc 3.777918 loss_rnnt 0.455760 hw_loss 0.176716 lr 0.00029257 rank 6
2023-03-01 05:50:04,956 DEBUG TRAIN Batch 50/200 loss 8.931912 loss_att 11.170597 loss_ctc 13.723392 loss_rnnt 7.773853 hw_loss 0.133983 lr 0.00029257 rank 5
2023-03-01 05:50:04,959 DEBUG TRAIN Batch 50/200 loss 8.922813 loss_att 9.452000 loss_ctc 11.727093 loss_rnnt 8.305152 hw_loss 0.258600 lr 0.00029258 rank 1
2023-03-01 05:50:04,961 DEBUG TRAIN Batch 50/200 loss 1.950556 loss_att 5.857182 loss_ctc 5.621578 loss_rnnt 0.544042 hw_loss 0.254473 lr 0.00029258 rank 2
2023-03-01 05:50:04,970 DEBUG TRAIN Batch 50/200 loss 1.515805 loss_att 3.692567 loss_ctc 2.563315 loss_rnnt 0.803659 hw_loss 0.257110 lr 0.00029257 rank 3
2023-03-01 05:50:05,002 DEBUG TRAIN Batch 50/200 loss 6.988684 loss_att 11.390036 loss_ctc 13.154521 loss_rnnt 5.286079 hw_loss 0.000417 lr 0.00029257 rank 4
2023-03-01 05:50:43,717 DEBUG TRAIN Batch 50/300 loss 9.094278 loss_att 12.149329 loss_ctc 16.421261 loss_rnnt 7.409306 hw_loss 0.181936 lr 0.00029256 rank 6
2023-03-01 05:50:43,722 DEBUG TRAIN Batch 50/300 loss 8.531619 loss_att 9.170200 loss_ctc 13.206683 loss_rnnt 7.644147 hw_loss 0.255775 lr 0.00029256 rank 2
2023-03-01 05:50:43,728 DEBUG TRAIN Batch 50/300 loss 6.358964 loss_att 10.329113 loss_ctc 8.962246 loss_rnnt 5.113388 hw_loss 0.195831 lr 0.00029256 rank 5
2023-03-01 05:50:43,735 DEBUG TRAIN Batch 50/300 loss 9.483743 loss_att 13.795963 loss_ctc 14.407011 loss_rnnt 7.894785 hw_loss 0.131395 lr 0.00029255 rank 7
2023-03-01 05:50:43,736 DEBUG TRAIN Batch 50/300 loss 3.445878 loss_att 7.600585 loss_ctc 8.070354 loss_rnnt 1.872513 hw_loss 0.235927 lr 0.00029255 rank 3
2023-03-01 05:50:43,737 DEBUG TRAIN Batch 50/300 loss 10.174064 loss_att 13.257267 loss_ctc 20.094173 loss_rnnt 8.099203 hw_loss 0.254136 lr 0.00029256 rank 0
2023-03-01 05:50:43,760 DEBUG TRAIN Batch 50/300 loss 2.061599 loss_att 4.549518 loss_ctc 3.785118 loss_rnnt 1.203893 hw_loss 0.244348 lr 0.00029256 rank 1
2023-03-01 05:50:43,761 DEBUG TRAIN Batch 50/300 loss 11.069547 loss_att 14.269062 loss_ctc 16.192747 loss_rnnt 9.633924 hw_loss 0.211175 lr 0.00029256 rank 4
2023-03-01 05:51:49,588 DEBUG TRAIN Batch 50/400 loss 5.792027 loss_att 8.539846 loss_ctc 11.839205 loss_rnnt 4.310580 hw_loss 0.235486 lr 0.00029255 rank 0
2023-03-01 05:51:49,594 DEBUG TRAIN Batch 50/400 loss 8.215395 loss_att 11.130278 loss_ctc 15.038062 loss_rnnt 6.613349 hw_loss 0.205089 lr 0.00029254 rank 7
2023-03-01 05:51:49,609 DEBUG TRAIN Batch 50/400 loss 3.025003 loss_att 4.969062 loss_ctc 6.037216 loss_rnnt 2.132918 hw_loss 0.190583 lr 0.00029255 rank 4
2023-03-01 05:51:49,610 DEBUG TRAIN Batch 50/400 loss 7.331593 loss_att 7.515314 loss_ctc 8.327622 loss_rnnt 7.014075 hw_loss 0.277444 lr 0.00029255 rank 2
2023-03-01 05:51:49,611 DEBUG TRAIN Batch 50/400 loss 3.983897 loss_att 6.460352 loss_ctc 7.023030 loss_rnnt 2.968294 hw_loss 0.215802 lr 0.00029255 rank 1
2023-03-01 05:51:49,612 DEBUG TRAIN Batch 50/400 loss 7.355118 loss_att 9.405928 loss_ctc 11.388005 loss_rnnt 6.228697 hw_loss 0.334764 lr 0.00029254 rank 3
2023-03-01 05:51:49,617 DEBUG TRAIN Batch 50/400 loss 5.773988 loss_att 8.440617 loss_ctc 8.174633 loss_rnnt 4.779804 hw_loss 0.263946 lr 0.00029255 rank 6
2023-03-01 05:51:49,662 DEBUG TRAIN Batch 50/400 loss 8.277849 loss_att 11.088367 loss_ctc 12.751778 loss_rnnt 7.033162 hw_loss 0.161361 lr 0.00029255 rank 5
2023-03-01 05:52:28,152 DEBUG TRAIN Batch 50/500 loss 5.900083 loss_att 9.173510 loss_ctc 14.976949 loss_rnnt 3.974277 hw_loss 0.114136 lr 0.00029254 rank 0
2023-03-01 05:52:28,168 DEBUG TRAIN Batch 50/500 loss 3.914959 loss_att 5.641449 loss_ctc 5.919498 loss_rnnt 3.221260 hw_loss 0.152116 lr 0.00029254 rank 1
2023-03-01 05:52:28,168 DEBUG TRAIN Batch 50/500 loss 6.158144 loss_att 8.049412 loss_ctc 9.748159 loss_rnnt 5.139244 hw_loss 0.303709 lr 0.00029254 rank 2
2023-03-01 05:52:28,168 DEBUG TRAIN Batch 50/500 loss 6.180399 loss_att 6.315279 loss_ctc 7.930151 loss_rnnt 5.786345 hw_loss 0.250833 lr 0.00029252 rank 7
2023-03-01 05:52:28,169 DEBUG TRAIN Batch 50/500 loss 4.026101 loss_att 6.606686 loss_ctc 5.297557 loss_rnnt 3.252742 hw_loss 0.164463 lr 0.00029253 rank 4
2023-03-01 05:52:28,171 DEBUG TRAIN Batch 50/500 loss 6.603475 loss_att 8.010028 loss_ctc 9.828918 loss_rnnt 5.790367 hw_loss 0.190760 lr 0.00029253 rank 3
2023-03-01 05:52:28,174 DEBUG TRAIN Batch 50/500 loss 4.892385 loss_att 7.545259 loss_ctc 10.681417 loss_rnnt 3.479410 hw_loss 0.207240 lr 0.00029253 rank 5
2023-03-01 05:52:28,176 DEBUG TRAIN Batch 50/500 loss 7.353491 loss_att 9.892540 loss_ctc 12.636065 loss_rnnt 5.988042 hw_loss 0.287430 lr 0.00029253 rank 6
2023-03-01 05:53:07,504 DEBUG TRAIN Batch 50/600 loss 7.426970 loss_att 9.074088 loss_ctc 13.392916 loss_rnnt 6.138820 hw_loss 0.306125 lr 0.00029252 rank 6
2023-03-01 05:53:07,504 DEBUG TRAIN Batch 50/600 loss 6.778243 loss_att 8.878132 loss_ctc 12.324970 loss_rnnt 5.555912 hw_loss 0.117730 lr 0.00029253 rank 0
2023-03-01 05:53:07,504 DEBUG TRAIN Batch 50/600 loss 11.572770 loss_att 12.919365 loss_ctc 16.558172 loss_rnnt 10.479061 hw_loss 0.299379 lr 0.00029252 rank 4
2023-03-01 05:53:07,509 DEBUG TRAIN Batch 50/600 loss 8.385904 loss_att 11.181602 loss_ctc 15.270080 loss_rnnt 6.822863 hw_loss 0.161270 lr 0.00029252 rank 5
2023-03-01 05:53:07,509 DEBUG TRAIN Batch 50/600 loss 6.412869 loss_att 8.273300 loss_ctc 10.147788 loss_rnnt 5.404877 hw_loss 0.258594 lr 0.00029253 rank 2
2023-03-01 05:53:07,508 DEBUG TRAIN Batch 50/600 loss 6.060789 loss_att 6.838446 loss_ctc 7.307452 loss_rnnt 5.585921 hw_loss 0.287089 lr 0.00029252 rank 3
2023-03-01 05:53:07,509 DEBUG TRAIN Batch 50/600 loss 3.375594 loss_att 4.550275 loss_ctc 5.507861 loss_rnnt 2.719550 hw_loss 0.256511 lr 0.00029251 rank 7
2023-03-01 05:53:07,552 DEBUG TRAIN Batch 50/600 loss 4.911629 loss_att 8.239379 loss_ctc 11.207699 loss_rnnt 3.362602 hw_loss 0.082504 lr 0.00029253 rank 1
2023-03-01 05:53:47,179 DEBUG TRAIN Batch 50/700 loss 2.445127 loss_att 5.328039 loss_ctc 3.423679 loss_rnnt 1.656487 hw_loss 0.152969 lr 0.00029251 rank 1
2023-03-01 05:53:47,180 DEBUG TRAIN Batch 50/700 loss 3.272945 loss_att 6.983295 loss_ctc 6.885257 loss_rnnt 1.969732 hw_loss 0.149065 lr 0.00029250 rank 7
2023-03-01 05:53:47,182 DEBUG TRAIN Batch 50/700 loss 4.274438 loss_att 5.878242 loss_ctc 8.419468 loss_rnnt 3.327787 hw_loss 0.137288 lr 0.00029251 rank 4
2023-03-01 05:53:47,188 DEBUG TRAIN Batch 50/700 loss 2.051714 loss_att 6.327833 loss_ctc 3.625555 loss_rnnt 0.847087 hw_loss 0.261671 lr 0.00029250 rank 3
2023-03-01 05:53:47,188 DEBUG TRAIN Batch 50/700 loss 2.018642 loss_att 4.231590 loss_ctc 2.678519 loss_rnnt 1.397408 hw_loss 0.169990 lr 0.00029251 rank 0
2023-03-01 05:53:47,191 DEBUG TRAIN Batch 50/700 loss 3.759966 loss_att 6.480342 loss_ctc 5.645742 loss_rnnt 2.858408 hw_loss 0.198838 lr 0.00029251 rank 5
2023-03-01 05:53:47,236 DEBUG TRAIN Batch 50/700 loss 9.901502 loss_att 12.188812 loss_ctc 14.883743 loss_rnnt 8.565878 hw_loss 0.400993 lr 0.00029251 rank 2
2023-03-01 05:53:47,261 DEBUG TRAIN Batch 50/700 loss 1.475221 loss_att 4.923407 loss_ctc 2.745646 loss_rnnt 0.525930 hw_loss 0.169245 lr 0.00029251 rank 6
2023-03-01 05:54:54,143 DEBUG TRAIN Batch 50/800 loss 6.616205 loss_att 7.991584 loss_ctc 12.723041 loss_rnnt 5.377120 hw_loss 0.280809 lr 0.00029250 rank 6
2023-03-01 05:54:54,154 DEBUG TRAIN Batch 50/800 loss 3.492617 loss_att 8.022607 loss_ctc 8.080730 loss_rnnt 1.841646 hw_loss 0.249798 lr 0.00029250 rank 4
2023-03-01 05:54:54,154 DEBUG TRAIN Batch 50/800 loss 3.868288 loss_att 7.194411 loss_ctc 7.219892 loss_rnnt 2.698813 hw_loss 0.107568 lr 0.00029250 rank 0
2023-03-01 05:54:54,158 DEBUG TRAIN Batch 50/800 loss 4.916441 loss_att 8.472349 loss_ctc 9.248083 loss_rnnt 3.627519 hw_loss 0.000351 lr 0.00029250 rank 5
2023-03-01 05:54:54,159 DEBUG TRAIN Batch 50/800 loss 5.719392 loss_att 8.856735 loss_ctc 10.542572 loss_rnnt 4.327603 hw_loss 0.227305 lr 0.00029249 rank 7
2023-03-01 05:54:54,163 DEBUG TRAIN Batch 50/800 loss 5.967944 loss_att 8.978872 loss_ctc 9.318691 loss_rnnt 4.792773 hw_loss 0.236659 lr 0.00029250 rank 1
2023-03-01 05:54:54,164 DEBUG TRAIN Batch 50/800 loss 1.212678 loss_att 3.226753 loss_ctc 1.100623 loss_rnnt 0.655864 hw_loss 0.316762 lr 0.00029249 rank 3
2023-03-01 05:54:54,205 DEBUG TRAIN Batch 50/800 loss 2.578446 loss_att 5.829972 loss_ctc 4.529110 loss_rnnt 1.584158 hw_loss 0.157302 lr 0.00029250 rank 2
2023-03-01 05:55:32,733 DEBUG TRAIN Batch 50/900 loss 10.980172 loss_att 14.387861 loss_ctc 13.551331 loss_rnnt 9.909266 hw_loss 0.087276 lr 0.00029247 rank 7
2023-03-01 05:55:32,747 DEBUG TRAIN Batch 50/900 loss 3.577561 loss_att 7.495466 loss_ctc 7.490291 loss_rnnt 2.199329 hw_loss 0.136788 lr 0.00029249 rank 0
2023-03-01 05:55:32,749 DEBUG TRAIN Batch 50/900 loss 4.961866 loss_att 8.188794 loss_ctc 6.293300 loss_rnnt 4.010793 hw_loss 0.240307 lr 0.00029248 rank 5
2023-03-01 05:55:32,749 DEBUG TRAIN Batch 50/900 loss 5.241738 loss_att 7.255949 loss_ctc 11.450294 loss_rnnt 3.916864 hw_loss 0.176669 lr 0.00029248 rank 3
2023-03-01 05:55:32,750 DEBUG TRAIN Batch 50/900 loss 6.673284 loss_att 10.201109 loss_ctc 11.191168 loss_rnnt 5.234190 hw_loss 0.245895 lr 0.00029249 rank 2
2023-03-01 05:55:32,750 DEBUG TRAIN Batch 50/900 loss 6.507231 loss_att 9.505588 loss_ctc 11.830750 loss_rnnt 5.072206 hw_loss 0.235408 lr 0.00029249 rank 1
2023-03-01 05:55:32,752 DEBUG TRAIN Batch 50/900 loss 5.385680 loss_att 10.420192 loss_ctc 9.779431 loss_rnnt 3.650686 hw_loss 0.266734 lr 0.00029248 rank 6
2023-03-01 05:55:32,754 DEBUG TRAIN Batch 50/900 loss 8.602719 loss_att 12.275327 loss_ctc 12.997333 loss_rnnt 7.184370 hw_loss 0.183524 lr 0.00029248 rank 4
2023-03-01 05:56:11,591 DEBUG TRAIN Batch 50/1000 loss 9.166061 loss_att 13.797226 loss_ctc 15.496672 loss_rnnt 7.311488 hw_loss 0.157985 lr 0.00029247 rank 6
2023-03-01 05:56:11,598 DEBUG TRAIN Batch 50/1000 loss 5.363150 loss_att 7.972569 loss_ctc 11.737184 loss_rnnt 3.826427 hw_loss 0.309315 lr 0.00029248 rank 2
2023-03-01 05:56:11,600 DEBUG TRAIN Batch 50/1000 loss 6.369426 loss_att 8.661839 loss_ctc 11.119959 loss_rnnt 5.157790 hw_loss 0.224528 lr 0.00029247 rank 5
2023-03-01 05:56:11,610 DEBUG TRAIN Batch 50/1000 loss 12.820082 loss_att 14.335506 loss_ctc 22.365124 loss_rnnt 11.171034 hw_loss 0.137423 lr 0.00029248 rank 1
2023-03-01 05:56:11,611 DEBUG TRAIN Batch 50/1000 loss 8.129594 loss_att 11.471543 loss_ctc 14.910776 loss_rnnt 6.430804 hw_loss 0.236704 lr 0.00029247 rank 4
2023-03-01 05:56:11,612 DEBUG TRAIN Batch 50/1000 loss 8.099488 loss_att 9.629293 loss_ctc 15.948543 loss_rnnt 6.673362 hw_loss 0.138047 lr 0.00029248 rank 0
2023-03-01 05:56:11,613 DEBUG TRAIN Batch 50/1000 loss 3.883553 loss_att 6.929351 loss_ctc 6.267735 loss_rnnt 2.878975 hw_loss 0.145364 lr 0.00029246 rank 7
2023-03-01 05:56:11,617 DEBUG TRAIN Batch 50/1000 loss 7.157864 loss_att 11.490453 loss_ctc 11.551415 loss_rnnt 5.612659 hw_loss 0.174151 lr 0.00029247 rank 3
2023-03-01 05:57:18,336 DEBUG TRAIN Batch 50/1100 loss 8.789910 loss_att 14.554338 loss_ctc 18.849640 loss_rnnt 6.163712 hw_loss 0.247528 lr 0.00029245 rank 7
2023-03-01 05:57:18,336 DEBUG TRAIN Batch 50/1100 loss 10.522362 loss_att 15.972253 loss_ctc 21.504017 loss_rnnt 7.854363 hw_loss 0.213372 lr 0.00029246 rank 0
2023-03-01 05:57:18,339 DEBUG TRAIN Batch 50/1100 loss 12.411420 loss_att 12.393745 loss_ctc 24.182823 loss_rnnt 10.754018 hw_loss 0.171404 lr 0.00029246 rank 6
2023-03-01 05:57:18,342 DEBUG TRAIN Batch 50/1100 loss 8.399047 loss_att 11.888375 loss_ctc 14.279026 loss_rnnt 6.866245 hw_loss 0.095511 lr 0.00029246 rank 5
2023-03-01 05:57:18,343 DEBUG TRAIN Batch 50/1100 loss 4.116744 loss_att 6.633952 loss_ctc 7.987566 loss_rnnt 2.974355 hw_loss 0.230321 lr 0.00029245 rank 3
2023-03-01 05:57:18,347 DEBUG TRAIN Batch 50/1100 loss 4.538958 loss_att 8.330466 loss_ctc 7.257765 loss_rnnt 3.329556 hw_loss 0.166112 lr 0.00029246 rank 1
2023-03-01 05:57:18,348 DEBUG TRAIN Batch 50/1100 loss 9.221203 loss_att 13.294407 loss_ctc 16.981636 loss_rnnt 7.238009 hw_loss 0.250927 lr 0.00029246 rank 4
2023-03-01 05:57:18,396 DEBUG TRAIN Batch 50/1100 loss 3.960334 loss_att 6.925882 loss_ctc 6.729257 loss_rnnt 2.812160 hw_loss 0.348514 lr 0.00029246 rank 2
2023-03-01 05:57:56,754 DEBUG TRAIN Batch 50/1200 loss 7.330177 loss_att 7.807914 loss_ctc 10.835217 loss_rnnt 6.682909 hw_loss 0.158213 lr 0.00029245 rank 6
2023-03-01 05:57:56,763 DEBUG TRAIN Batch 50/1200 loss 7.686096 loss_att 9.338145 loss_ctc 10.592320 loss_rnnt 6.811910 hw_loss 0.293022 lr 0.00029244 rank 3
2023-03-01 05:57:56,766 DEBUG TRAIN Batch 50/1200 loss 2.585117 loss_att 5.625623 loss_ctc 6.586457 loss_rnnt 1.353438 hw_loss 0.168873 lr 0.00029244 rank 7
2023-03-01 05:57:56,768 DEBUG TRAIN Batch 50/1200 loss 3.848680 loss_att 5.517856 loss_ctc 6.311285 loss_rnnt 3.003199 hw_loss 0.343687 lr 0.00029245 rank 0
2023-03-01 05:57:56,771 DEBUG TRAIN Batch 50/1200 loss 3.424970 loss_att 6.220315 loss_ctc 6.153067 loss_rnnt 2.333522 hw_loss 0.316187 lr 0.00029245 rank 1
2023-03-01 05:57:56,771 DEBUG TRAIN Batch 50/1200 loss 3.018389 loss_att 5.248720 loss_ctc 5.471929 loss_rnnt 2.106848 hw_loss 0.259380 lr 0.00029245 rank 2
2023-03-01 05:57:56,772 DEBUG TRAIN Batch 50/1200 loss 5.885834 loss_att 7.450049 loss_ctc 11.142638 loss_rnnt 4.760252 hw_loss 0.209683 lr 0.00029245 rank 4
2023-03-01 05:57:56,796 DEBUG TRAIN Batch 50/1200 loss 7.986721 loss_att 10.302195 loss_ctc 13.383868 loss_rnnt 6.670457 hw_loss 0.250405 lr 0.00029245 rank 5
2023-03-01 05:58:35,574 DEBUG TRAIN Batch 50/1300 loss 3.188534 loss_att 6.639348 loss_ctc 5.161669 loss_rnnt 2.097847 hw_loss 0.257700 lr 0.00029243 rank 5
2023-03-01 05:58:35,577 DEBUG TRAIN Batch 50/1300 loss 8.166758 loss_att 14.202339 loss_ctc 14.818596 loss_rnnt 6.003690 hw_loss 0.129448 lr 0.00029243 rank 3
2023-03-01 05:58:35,585 DEBUG TRAIN Batch 50/1300 loss 6.599029 loss_att 8.493120 loss_ctc 9.564486 loss_rnnt 5.758413 hw_loss 0.124505 lr 0.00029243 rank 6
2023-03-01 05:58:35,586 DEBUG TRAIN Batch 50/1300 loss 7.521662 loss_att 7.917571 loss_ctc 12.040553 loss_rnnt 6.672516 hw_loss 0.313959 lr 0.00029242 rank 7
2023-03-01 05:58:35,589 DEBUG TRAIN Batch 50/1300 loss 6.951975 loss_att 7.068132 loss_ctc 10.451029 loss_rnnt 6.310970 hw_loss 0.283563 lr 0.00029244 rank 0
2023-03-01 05:58:35,590 DEBUG TRAIN Batch 50/1300 loss 7.430669 loss_att 10.705904 loss_ctc 15.227610 loss_rnnt 5.619870 hw_loss 0.217800 lr 0.00029243 rank 4
2023-03-01 05:58:35,595 DEBUG TRAIN Batch 50/1300 loss 6.070057 loss_att 8.038362 loss_ctc 9.269442 loss_rnnt 5.201747 hw_loss 0.090120 lr 0.00029244 rank 1
2023-03-01 05:58:35,596 DEBUG TRAIN Batch 50/1300 loss 4.722245 loss_att 7.588840 loss_ctc 6.252364 loss_rnnt 3.812469 hw_loss 0.248327 lr 0.00029244 rank 2
2023-03-01 05:59:14,903 DEBUG TRAIN Batch 50/1400 loss 4.905192 loss_att 9.662390 loss_ctc 12.373649 loss_rnnt 2.876671 hw_loss 0.152413 lr 0.00029243 rank 2
2023-03-01 05:59:14,907 DEBUG TRAIN Batch 50/1400 loss 1.903417 loss_att 3.896032 loss_ctc 2.944325 loss_rnnt 1.288297 hw_loss 0.145894 lr 0.00029243 rank 1
2023-03-01 05:59:14,909 DEBUG TRAIN Batch 50/1400 loss 3.712813 loss_att 7.351304 loss_ctc 5.773197 loss_rnnt 2.584529 hw_loss 0.236001 lr 0.00029243 rank 0
2023-03-01 05:59:14,909 DEBUG TRAIN Batch 50/1400 loss 5.042572 loss_att 6.630867 loss_ctc 8.103559 loss_rnnt 4.175585 hw_loss 0.264745 lr 0.00029242 rank 3
2023-03-01 05:59:14,913 DEBUG TRAIN Batch 50/1400 loss 4.009713 loss_att 8.396606 loss_ctc 4.848208 loss_rnnt 2.937578 hw_loss 0.155543 lr 0.00029241 rank 7
2023-03-01 05:59:14,914 DEBUG TRAIN Batch 50/1400 loss 2.722731 loss_att 8.865284 loss_ctc 6.829438 loss_rnnt 0.850406 hw_loss 0.180473 lr 0.00029242 rank 4
2023-03-01 05:59:14,916 DEBUG TRAIN Batch 50/1400 loss 7.432535 loss_att 9.878282 loss_ctc 14.039364 loss_rnnt 5.848942 hw_loss 0.400375 lr 0.00029242 rank 5
2023-03-01 05:59:14,922 DEBUG TRAIN Batch 50/1400 loss 5.461597 loss_att 7.934933 loss_ctc 8.842109 loss_rnnt 4.377925 hw_loss 0.259255 lr 0.00029242 rank 6
2023-03-01 06:00:20,806 DEBUG TRAIN Batch 50/1500 loss 3.149718 loss_att 6.270105 loss_ctc 6.718839 loss_rnnt 1.978332 hw_loss 0.133924 lr 0.00029240 rank 3
2023-03-01 06:00:20,820 DEBUG TRAIN Batch 50/1500 loss 7.413985 loss_att 9.359686 loss_ctc 11.333041 loss_rnnt 6.408468 hw_loss 0.175941 lr 0.00029241 rank 6
2023-03-01 06:00:20,822 DEBUG TRAIN Batch 50/1500 loss 4.071217 loss_att 6.105860 loss_ctc 8.296832 loss_rnnt 3.074904 hw_loss 0.048690 lr 0.00029241 rank 4
2023-03-01 06:00:20,823 DEBUG TRAIN Batch 50/1500 loss 5.873187 loss_att 9.395606 loss_ctc 8.037074 loss_rnnt 4.796230 hw_loss 0.157416 lr 0.00029241 rank 0
2023-03-01 06:00:20,824 DEBUG TRAIN Batch 50/1500 loss 5.108105 loss_att 9.534030 loss_ctc 8.278240 loss_rnnt 3.744776 hw_loss 0.103988 lr 0.00029241 rank 5
2023-03-01 06:00:20,825 DEBUG TRAIN Batch 50/1500 loss 1.799799 loss_att 4.167591 loss_ctc 3.332090 loss_rnnt 1.079065 hw_loss 0.080382 lr 0.00029241 rank 1
2023-03-01 06:00:20,826 DEBUG TRAIN Batch 50/1500 loss 14.746543 loss_att 17.019066 loss_ctc 20.802807 loss_rnnt 13.431509 hw_loss 0.099429 lr 0.00029240 rank 7
2023-03-01 06:00:20,875 DEBUG TRAIN Batch 50/1500 loss 5.737861 loss_att 8.706245 loss_ctc 10.001470 loss_rnnt 4.458726 hw_loss 0.219332 lr 0.00029241 rank 2
2023-03-01 06:00:59,607 DEBUG TRAIN Batch 50/1600 loss 8.055771 loss_att 11.505741 loss_ctc 15.105612 loss_rnnt 6.331502 hw_loss 0.176805 lr 0.00029240 rank 2
2023-03-01 06:00:59,613 DEBUG TRAIN Batch 50/1600 loss 7.174725 loss_att 10.249329 loss_ctc 12.307532 loss_rnnt 5.772336 hw_loss 0.193300 lr 0.00029240 rank 1
2023-03-01 06:00:59,615 DEBUG TRAIN Batch 50/1600 loss 5.863992 loss_att 9.141128 loss_ctc 12.114569 loss_rnnt 4.284395 hw_loss 0.170175 lr 0.00029239 rank 3
2023-03-01 06:00:59,628 DEBUG TRAIN Batch 50/1600 loss 3.054519 loss_att 6.194536 loss_ctc 8.594276 loss_rnnt 1.651108 hw_loss 0.068952 lr 0.00029240 rank 6
2023-03-01 06:00:59,628 DEBUG TRAIN Batch 50/1600 loss 4.438656 loss_att 8.328561 loss_ctc 5.299709 loss_rnnt 3.467803 hw_loss 0.146373 lr 0.00029240 rank 4
2023-03-01 06:00:59,629 DEBUG TRAIN Batch 50/1600 loss 2.491482 loss_att 4.844361 loss_ctc 4.404265 loss_rnnt 1.626687 hw_loss 0.260966 lr 0.00029240 rank 5
2023-03-01 06:00:59,633 DEBUG TRAIN Batch 50/1600 loss 11.649137 loss_att 12.584463 loss_ctc 15.907599 loss_rnnt 10.705341 hw_loss 0.354254 lr 0.00029239 rank 7
2023-03-01 06:00:59,638 DEBUG TRAIN Batch 50/1600 loss 4.447737 loss_att 8.186806 loss_ctc 5.944249 loss_rnnt 3.427745 hw_loss 0.136206 lr 0.00029240 rank 0
2023-03-01 06:01:38,352 DEBUG TRAIN Batch 50/1700 loss 4.976649 loss_att 10.381861 loss_ctc 10.712979 loss_rnnt 2.991162 hw_loss 0.261750 lr 0.00029239 rank 2
2023-03-01 06:01:38,354 DEBUG TRAIN Batch 50/1700 loss 4.561505 loss_att 7.168820 loss_ctc 7.160010 loss_rnnt 3.634321 hw_loss 0.111100 lr 0.00029238 rank 5
2023-03-01 06:01:38,358 DEBUG TRAIN Batch 50/1700 loss 2.790868 loss_att 5.512168 loss_ctc 6.084395 loss_rnnt 1.588523 hw_loss 0.410527 lr 0.00029239 rank 1
2023-03-01 06:01:38,360 DEBUG TRAIN Batch 50/1700 loss 5.607319 loss_att 8.314518 loss_ctc 12.749471 loss_rnnt 3.988396 hw_loss 0.234744 lr 0.00029239 rank 0
2023-03-01 06:01:38,360 DEBUG TRAIN Batch 50/1700 loss 8.286163 loss_att 11.166718 loss_ctc 12.767637 loss_rnnt 6.909973 hw_loss 0.379782 lr 0.00029238 rank 3
2023-03-01 06:01:38,361 DEBUG TRAIN Batch 50/1700 loss 5.638437 loss_att 8.128035 loss_ctc 11.659483 loss_rnnt 4.216811 hw_loss 0.226687 lr 0.00029237 rank 7
2023-03-01 06:01:38,364 DEBUG TRAIN Batch 50/1700 loss 5.646504 loss_att 8.640536 loss_ctc 9.967642 loss_rnnt 4.320898 hw_loss 0.282465 lr 0.00029238 rank 6
2023-03-01 06:01:38,779 DEBUG TRAIN Batch 50/1700 loss 5.271812 loss_att 6.649988 loss_ctc 6.368959 loss_rnnt 4.709622 hw_loss 0.263004 lr 0.00029238 rank 4
2023-03-01 06:02:45,597 DEBUG TRAIN Batch 50/1800 loss 3.749631 loss_att 7.168061 loss_ctc 8.664824 loss_rnnt 2.287086 hw_loss 0.231562 lr 0.00029237 rank 3
2023-03-01 06:02:45,600 DEBUG TRAIN Batch 50/1800 loss 8.855128 loss_att 10.072197 loss_ctc 11.344795 loss_rnnt 8.140970 hw_loss 0.260229 lr 0.00029238 rank 2
2023-03-01 06:02:45,608 DEBUG TRAIN Batch 50/1800 loss 1.985886 loss_att 4.503351 loss_ctc 3.993528 loss_rnnt 1.124672 hw_loss 0.168817 lr 0.00029236 rank 7
2023-03-01 06:02:45,609 DEBUG TRAIN Batch 50/1800 loss 6.841356 loss_att 8.244183 loss_ctc 12.643571 loss_rnnt 5.634858 hw_loss 0.285568 lr 0.00029238 rank 0
2023-03-01 06:02:45,610 DEBUG TRAIN Batch 50/1800 loss 5.429484 loss_att 6.873027 loss_ctc 9.688632 loss_rnnt 4.357224 hw_loss 0.404371 lr 0.00029237 rank 5
2023-03-01 06:02:45,610 DEBUG TRAIN Batch 50/1800 loss 4.524775 loss_att 7.622907 loss_ctc 8.520311 loss_rnnt 3.204155 hw_loss 0.315476 lr 0.00029237 rank 4
2023-03-01 06:02:45,611 DEBUG TRAIN Batch 50/1800 loss 4.075846 loss_att 4.183139 loss_ctc 5.088935 loss_rnnt 3.825553 hw_loss 0.175793 lr 0.00029238 rank 1
2023-03-01 06:02:46,032 DEBUG TRAIN Batch 50/1800 loss 6.545232 loss_att 9.786516 loss_ctc 12.984598 loss_rnnt 4.894260 hw_loss 0.270248 lr 0.00029237 rank 6
2023-03-01 06:03:25,165 DEBUG TRAIN Batch 50/1900 loss 2.902170 loss_att 6.374456 loss_ctc 4.470549 loss_rnnt 1.897275 hw_loss 0.189975 lr 0.00029236 rank 5
2023-03-01 06:03:25,165 DEBUG TRAIN Batch 50/1900 loss 3.487962 loss_att 5.717824 loss_ctc 5.356114 loss_rnnt 2.676306 hw_loss 0.218618 lr 0.00029236 rank 4
2023-03-01 06:03:25,168 DEBUG TRAIN Batch 50/1900 loss 3.742876 loss_att 9.252388 loss_ctc 5.978366 loss_rnnt 2.233164 hw_loss 0.205770 lr 0.00029236 rank 2
2023-03-01 06:03:25,179 DEBUG TRAIN Batch 50/1900 loss 7.556878 loss_att 8.181381 loss_ctc 10.427509 loss_rnnt 6.885566 hw_loss 0.306862 lr 0.00029235 rank 7
2023-03-01 06:03:25,185 DEBUG TRAIN Batch 50/1900 loss 11.257252 loss_att 13.866936 loss_ctc 19.149254 loss_rnnt 9.486328 hw_loss 0.368847 lr 0.00029236 rank 6
2023-03-01 06:03:25,187 DEBUG TRAIN Batch 50/1900 loss 3.371839 loss_att 4.641128 loss_ctc 4.665043 loss_rnnt 2.805526 hw_loss 0.262552 lr 0.00029236 rank 0
2023-03-01 06:03:25,187 DEBUG TRAIN Batch 50/1900 loss 5.259681 loss_att 6.426133 loss_ctc 7.439331 loss_rnnt 4.562476 hw_loss 0.324926 lr 0.00029235 rank 3
2023-03-01 06:03:25,199 DEBUG TRAIN Batch 50/1900 loss 3.512140 loss_att 5.586583 loss_ctc 4.584873 loss_rnnt 2.849684 hw_loss 0.196006 lr 0.00029236 rank 1
2023-03-01 06:04:03,888 DEBUG TRAIN Batch 50/2000 loss 10.385838 loss_att 9.780852 loss_ctc 14.271253 loss_rnnt 9.855115 hw_loss 0.250621 lr 0.00029235 rank 4
2023-03-01 06:04:03,892 DEBUG TRAIN Batch 50/2000 loss 6.777204 loss_att 11.043012 loss_ctc 13.400902 loss_rnnt 4.979677 hw_loss 0.114759 lr 0.00029234 rank 3
2023-03-01 06:04:03,894 DEBUG TRAIN Batch 50/2000 loss 8.110140 loss_att 11.365374 loss_ctc 10.679835 loss_rnnt 6.978805 hw_loss 0.258116 lr 0.00029235 rank 6
2023-03-01 06:04:03,903 DEBUG TRAIN Batch 50/2000 loss 3.439523 loss_att 8.268913 loss_ctc 8.973048 loss_rnnt 1.690382 hw_loss 0.085236 lr 0.00029234 rank 7
2023-03-01 06:04:03,904 DEBUG TRAIN Batch 50/2000 loss 7.299899 loss_att 13.108406 loss_ctc 12.477980 loss_rnnt 5.348709 hw_loss 0.185771 lr 0.00029235 rank 0
2023-03-01 06:04:03,905 DEBUG TRAIN Batch 50/2000 loss 3.752182 loss_att 5.621998 loss_ctc 4.478106 loss_rnnt 3.124377 hw_loss 0.294473 lr 0.00029235 rank 2
2023-03-01 06:04:03,908 DEBUG TRAIN Batch 50/2000 loss 3.360722 loss_att 7.045193 loss_ctc 7.084174 loss_rnnt 2.030413 hw_loss 0.181790 lr 0.00029235 rank 5
2023-03-01 06:04:03,913 DEBUG TRAIN Batch 50/2000 loss 3.936821 loss_att 7.295983 loss_ctc 8.889053 loss_rnnt 2.467486 hw_loss 0.257259 lr 0.00029235 rank 1
2023-03-01 06:04:43,947 DEBUG TRAIN Batch 50/2100 loss 2.861898 loss_att 6.055834 loss_ctc 4.982000 loss_rnnt 1.776002 hw_loss 0.308304 lr 0.00029234 rank 1
2023-03-01 06:04:43,951 DEBUG TRAIN Batch 50/2100 loss 9.702138 loss_att 11.313546 loss_ctc 15.722441 loss_rnnt 8.379592 hw_loss 0.370420 lr 0.00029233 rank 3
2023-03-01 06:04:43,964 DEBUG TRAIN Batch 50/2100 loss 9.438641 loss_att 11.903151 loss_ctc 13.654245 loss_rnnt 8.215353 hw_loss 0.315570 lr 0.00029233 rank 5
2023-03-01 06:04:43,965 DEBUG TRAIN Batch 50/2100 loss 5.861333 loss_att 8.897212 loss_ctc 7.900157 loss_rnnt 4.798473 hw_loss 0.344702 lr 0.00029232 rank 7
2023-03-01 06:04:43,965 DEBUG TRAIN Batch 50/2100 loss 7.199084 loss_att 9.858762 loss_ctc 12.965183 loss_rnnt 5.735494 hw_loss 0.305328 lr 0.00029234 rank 0
2023-03-01 06:04:43,969 DEBUG TRAIN Batch 50/2100 loss 12.664557 loss_att 13.340572 loss_ctc 25.318615 loss_rnnt 10.690157 hw_loss 0.284977 lr 0.00029234 rank 2
2023-03-01 06:04:43,974 DEBUG TRAIN Batch 50/2100 loss 7.105288 loss_att 8.913616 loss_ctc 12.133648 loss_rnnt 5.899411 hw_loss 0.325805 lr 0.00029233 rank 6
2023-03-01 06:04:43,973 DEBUG TRAIN Batch 50/2100 loss 6.183162 loss_att 9.275697 loss_ctc 10.755161 loss_rnnt 4.846045 hw_loss 0.204394 lr 0.00029233 rank 4
2023-03-01 06:05:48,657 DEBUG TRAIN Batch 50/2200 loss 2.510719 loss_att 4.816580 loss_ctc 3.905841 loss_rnnt 1.746976 hw_loss 0.218538 lr 0.00029231 rank 7
2023-03-01 06:05:48,664 DEBUG TRAIN Batch 50/2200 loss 7.005778 loss_att 10.428190 loss_ctc 9.282594 loss_rnnt 5.893920 hw_loss 0.232127 lr 0.00029233 rank 2
2023-03-01 06:05:48,680 DEBUG TRAIN Batch 50/2200 loss 5.190629 loss_att 7.510176 loss_ctc 8.183108 loss_rnnt 4.210345 hw_loss 0.220083 lr 0.00029232 rank 6
2023-03-01 06:05:48,681 DEBUG TRAIN Batch 50/2200 loss 5.599542 loss_att 8.549048 loss_ctc 11.651396 loss_rnnt 4.136703 hw_loss 0.123795 lr 0.00029233 rank 0
2023-03-01 06:05:48,682 DEBUG TRAIN Batch 50/2200 loss 2.482417 loss_att 3.510081 loss_ctc 3.939376 loss_rnnt 1.942073 hw_loss 0.263531 lr 0.00029232 rank 3
2023-03-01 06:05:48,684 DEBUG TRAIN Batch 50/2200 loss 3.207436 loss_att 7.980657 loss_ctc 6.063388 loss_rnnt 1.833815 hw_loss 0.071592 lr 0.00029233 rank 1
2023-03-01 06:05:48,689 DEBUG TRAIN Batch 50/2200 loss 9.613344 loss_att 10.452930 loss_ctc 12.514802 loss_rnnt 8.985983 hw_loss 0.136094 lr 0.00029232 rank 5
2023-03-01 06:05:48,728 DEBUG TRAIN Batch 50/2200 loss 8.654542 loss_att 11.484171 loss_ctc 18.296059 loss_rnnt 6.625384 hw_loss 0.333180 lr 0.00029232 rank 4
2023-03-01 06:06:27,024 DEBUG TRAIN Batch 50/2300 loss 7.908534 loss_att 9.617882 loss_ctc 11.731465 loss_rnnt 6.902175 hw_loss 0.290185 lr 0.00029231 rank 4
2023-03-01 06:06:27,042 DEBUG TRAIN Batch 50/2300 loss 1.957248 loss_att 4.420413 loss_ctc 3.119822 loss_rnnt 1.188257 hw_loss 0.227527 lr 0.00029231 rank 2
2023-03-01 06:06:27,044 DEBUG TRAIN Batch 50/2300 loss 9.573842 loss_att 11.055426 loss_ctc 18.071974 loss_rnnt 7.990936 hw_loss 0.287820 lr 0.00029231 rank 6
2023-03-01 06:06:27,045 DEBUG TRAIN Batch 50/2300 loss 4.605328 loss_att 5.892944 loss_ctc 6.024682 loss_rnnt 4.089572 hw_loss 0.129347 lr 0.00029230 rank 7
2023-03-01 06:06:27,045 DEBUG TRAIN Batch 50/2300 loss 7.286352 loss_att 9.877527 loss_ctc 12.073921 loss_rnnt 5.962430 hw_loss 0.313771 lr 0.00029231 rank 0
2023-03-01 06:06:27,049 DEBUG TRAIN Batch 50/2300 loss 5.604338 loss_att 9.202377 loss_ctc 11.271369 loss_rnnt 3.975288 hw_loss 0.288446 lr 0.00029231 rank 1
2023-03-01 06:06:27,056 DEBUG TRAIN Batch 50/2300 loss 5.930047 loss_att 7.457611 loss_ctc 11.535915 loss_rnnt 4.837295 hw_loss 0.074607 lr 0.00029231 rank 5
2023-03-01 06:06:27,059 DEBUG TRAIN Batch 50/2300 loss 6.435442 loss_att 9.766443 loss_ctc 12.060295 loss_rnnt 4.904387 hw_loss 0.215391 lr 0.00029230 rank 3
2023-03-01 06:07:06,062 DEBUG TRAIN Batch 50/2400 loss 3.152502 loss_att 7.051771 loss_ctc 5.669950 loss_rnnt 1.844508 hw_loss 0.360899 lr 0.00029229 rank 7
2023-03-01 06:07:06,066 DEBUG TRAIN Batch 50/2400 loss 3.471877 loss_att 6.200317 loss_ctc 5.590155 loss_rnnt 2.548414 hw_loss 0.178759 lr 0.00029229 rank 3
2023-03-01 06:07:06,075 DEBUG TRAIN Batch 50/2400 loss 6.480289 loss_att 8.358868 loss_ctc 11.428319 loss_rnnt 5.291537 hw_loss 0.287434 lr 0.00029230 rank 0
2023-03-01 06:07:06,076 DEBUG TRAIN Batch 50/2400 loss 4.928332 loss_att 8.280752 loss_ctc 8.157435 loss_rnnt 3.709849 hw_loss 0.220221 lr 0.00029230 rank 4
2023-03-01 06:07:06,080 DEBUG TRAIN Batch 50/2400 loss 3.657045 loss_att 5.707604 loss_ctc 7.142290 loss_rnnt 2.639931 hw_loss 0.266817 lr 0.00029230 rank 1
2023-03-01 06:07:06,081 DEBUG TRAIN Batch 50/2400 loss 8.110638 loss_att 10.532139 loss_ctc 12.439466 loss_rnnt 6.895278 hw_loss 0.288529 lr 0.00029230 rank 2
2023-03-01 06:07:06,083 DEBUG TRAIN Batch 50/2400 loss 13.716683 loss_att 12.807055 loss_ctc 18.732929 loss_rnnt 13.099094 hw_loss 0.245028 lr 0.00029230 rank 6
2023-03-01 06:07:06,088 DEBUG TRAIN Batch 50/2400 loss 9.223533 loss_att 10.644609 loss_ctc 13.774475 loss_rnnt 8.170921 hw_loss 0.303005 lr 0.00029230 rank 5
2023-03-01 06:08:13,405 DEBUG TRAIN Batch 50/2500 loss 4.756223 loss_att 7.141081 loss_ctc 6.752759 loss_rnnt 3.892900 hw_loss 0.225272 lr 0.00029229 rank 0
2023-03-01 06:08:13,411 DEBUG TRAIN Batch 50/2500 loss 9.598309 loss_att 10.990447 loss_ctc 16.029108 loss_rnnt 8.310493 hw_loss 0.284900 lr 0.00029227 rank 7
2023-03-01 06:08:13,413 DEBUG TRAIN Batch 50/2500 loss 5.765183 loss_att 8.616559 loss_ctc 11.413863 loss_rnnt 4.355096 hw_loss 0.162479 lr 0.00029228 rank 6
2023-03-01 06:08:13,413 DEBUG TRAIN Batch 50/2500 loss 6.378416 loss_att 8.040291 loss_ctc 10.861392 loss_rnnt 5.290864 hw_loss 0.295212 lr 0.00029228 rank 3
2023-03-01 06:08:13,416 DEBUG TRAIN Batch 50/2500 loss 6.738950 loss_att 10.530656 loss_ctc 12.908257 loss_rnnt 5.059994 hw_loss 0.183825 lr 0.00029228 rank 5
2023-03-01 06:08:13,417 DEBUG TRAIN Batch 50/2500 loss 8.686873 loss_att 8.489871 loss_ctc 12.697135 loss_rnnt 8.042723 hw_loss 0.279092 lr 0.00029229 rank 2
2023-03-01 06:08:13,419 DEBUG TRAIN Batch 50/2500 loss 2.561074 loss_att 5.681360 loss_ctc 5.193564 loss_rnnt 1.559072 hw_loss 0.050524 lr 0.00029228 rank 4
2023-03-01 06:08:13,453 DEBUG TRAIN Batch 50/2500 loss 5.537692 loss_att 7.404027 loss_ctc 9.932823 loss_rnnt 4.430412 hw_loss 0.277492 lr 0.00029229 rank 1
2023-03-01 06:08:51,996 DEBUG TRAIN Batch 50/2600 loss 9.378572 loss_att 13.669910 loss_ctc 17.776251 loss_rnnt 7.400396 hw_loss 0.000409 lr 0.00029228 rank 2
2023-03-01 06:08:51,996 DEBUG TRAIN Batch 50/2600 loss 4.362711 loss_att 6.285314 loss_ctc 4.217809 loss_rnnt 3.916926 hw_loss 0.151097 lr 0.00029227 rank 6
2023-03-01 06:08:51,997 DEBUG TRAIN Batch 50/2600 loss 2.945512 loss_att 5.000317 loss_ctc 4.172683 loss_rnnt 2.269512 hw_loss 0.190157 lr 0.00029227 rank 3
2023-03-01 06:08:52,002 DEBUG TRAIN Batch 50/2600 loss 8.103217 loss_att 11.088115 loss_ctc 10.588988 loss_rnnt 7.100364 hw_loss 0.139570 lr 0.00029227 rank 5
2023-03-01 06:08:52,015 DEBUG TRAIN Batch 50/2600 loss 6.485920 loss_att 10.306819 loss_ctc 11.712385 loss_rnnt 4.925228 hw_loss 0.186844 lr 0.00029226 rank 7
2023-03-01 06:08:52,017 DEBUG TRAIN Batch 50/2600 loss 6.163526 loss_att 10.782463 loss_ctc 16.833391 loss_rnnt 3.703861 hw_loss 0.212302 lr 0.00029228 rank 0
2023-03-01 06:08:52,018 DEBUG TRAIN Batch 50/2600 loss 7.344834 loss_att 9.265776 loss_ctc 11.306193 loss_rnnt 6.232472 hw_loss 0.374984 lr 0.00029227 rank 4
2023-03-01 06:08:52,034 DEBUG TRAIN Batch 50/2600 loss 3.982795 loss_att 7.963219 loss_ctc 8.586760 loss_rnnt 2.518961 hw_loss 0.101037 lr 0.00029228 rank 1
2023-03-01 06:09:30,229 DEBUG TRAIN Batch 50/2700 loss 7.654493 loss_att 9.522133 loss_ctc 9.022409 loss_rnnt 6.998533 hw_loss 0.187581 lr 0.00029226 rank 4
2023-03-01 06:09:30,233 DEBUG TRAIN Batch 50/2700 loss 5.598955 loss_att 9.086248 loss_ctc 9.587292 loss_rnnt 4.309986 hw_loss 0.111998 lr 0.00029226 rank 0
2023-03-01 06:09:30,235 DEBUG TRAIN Batch 50/2700 loss 1.184540 loss_att 3.882734 loss_ctc 1.941553 loss_rnnt 0.339177 hw_loss 0.383980 lr 0.00029226 rank 5
2023-03-01 06:09:30,238 DEBUG TRAIN Batch 50/2700 loss 9.030185 loss_att 10.729618 loss_ctc 13.774054 loss_rnnt 7.980741 hw_loss 0.144454 lr 0.00029226 rank 1
2023-03-01 06:09:30,239 DEBUG TRAIN Batch 50/2700 loss 4.997470 loss_att 7.900221 loss_ctc 5.394525 loss_rnnt 4.183033 hw_loss 0.339274 lr 0.00029226 rank 6
2023-03-01 06:09:30,240 DEBUG TRAIN Batch 50/2700 loss 1.224365 loss_att 4.420348 loss_ctc 3.039691 loss_rnnt 0.289475 hw_loss 0.100593 lr 0.00029225 rank 7
2023-03-01 06:09:30,241 DEBUG TRAIN Batch 50/2700 loss 3.214284 loss_att 6.554976 loss_ctc 5.666369 loss_rnnt 2.162174 hw_loss 0.106925 lr 0.00029226 rank 2
2023-03-01 06:09:30,241 DEBUG TRAIN Batch 50/2700 loss 7.693321 loss_att 14.306972 loss_ctc 13.333443 loss_rnnt 5.516348 hw_loss 0.191675 lr 0.00029225 rank 3
2023-03-01 06:10:09,985 DEBUG TRAIN Batch 50/2800 loss 5.957678 loss_att 8.781888 loss_ctc 8.480816 loss_rnnt 4.955897 hw_loss 0.188476 lr 0.00029225 rank 1
2023-03-01 06:10:09,993 DEBUG TRAIN Batch 50/2800 loss 8.624779 loss_att 11.933237 loss_ctc 14.581883 loss_rnnt 7.107759 hw_loss 0.114464 lr 0.00029225 rank 6
2023-03-01 06:10:09,995 DEBUG TRAIN Batch 50/2800 loss 8.514232 loss_att 10.520598 loss_ctc 9.099499 loss_rnnt 7.906163 hw_loss 0.241423 lr 0.00029225 rank 2
2023-03-01 06:10:10,000 DEBUG TRAIN Batch 50/2800 loss 0.943182 loss_att 3.420937 loss_ctc 1.976662 loss_rnnt 0.260888 hw_loss 0.091774 lr 0.00029225 rank 0
2023-03-01 06:10:10,005 DEBUG TRAIN Batch 50/2800 loss 3.642456 loss_att 6.943992 loss_ctc 6.168256 loss_rnnt 2.494912 hw_loss 0.282120 lr 0.00029224 rank 7
2023-03-01 06:10:10,014 DEBUG TRAIN Batch 50/2800 loss 1.853952 loss_att 5.074429 loss_ctc 3.780368 loss_rnnt 0.895933 hw_loss 0.107003 lr 0.00029225 rank 4
2023-03-01 06:10:10,048 DEBUG TRAIN Batch 50/2800 loss 7.819211 loss_att 9.584171 loss_ctc 12.601187 loss_rnnt 6.669640 hw_loss 0.298092 lr 0.00029225 rank 5
2023-03-01 06:10:10,075 DEBUG TRAIN Batch 50/2800 loss 3.968879 loss_att 7.333529 loss_ctc 4.943506 loss_rnnt 3.103709 hw_loss 0.116795 lr 0.00029224 rank 3
2023-03-01 06:11:16,266 DEBUG TRAIN Batch 50/2900 loss 12.001588 loss_att 14.869194 loss_ctc 23.336464 loss_rnnt 9.745340 hw_loss 0.321393 lr 0.00029224 rank 2
2023-03-01 06:11:16,273 DEBUG TRAIN Batch 50/2900 loss 2.910597 loss_att 6.056864 loss_ctc 8.175772 loss_rnnt 1.455042 hw_loss 0.233023 lr 0.00029223 rank 5
2023-03-01 06:11:16,274 DEBUG TRAIN Batch 50/2900 loss 4.386458 loss_att 6.952676 loss_ctc 9.494036 loss_rnnt 3.039956 hw_loss 0.285465 lr 0.00029223 rank 4
2023-03-01 06:11:16,275 DEBUG TRAIN Batch 50/2900 loss 2.830013 loss_att 4.886351 loss_ctc 4.798119 loss_rnnt 2.005885 hw_loss 0.282087 lr 0.00029222 rank 7
2023-03-01 06:11:16,276 DEBUG TRAIN Batch 50/2900 loss 8.693555 loss_att 14.583965 loss_ctc 17.003347 loss_rnnt 6.307374 hw_loss 0.187739 lr 0.00029224 rank 0
2023-03-01 06:11:16,276 DEBUG TRAIN Batch 50/2900 loss 5.738977 loss_att 8.062742 loss_ctc 10.226898 loss_rnnt 4.591749 hw_loss 0.157661 lr 0.00029224 rank 1
2023-03-01 06:11:16,282 DEBUG TRAIN Batch 50/2900 loss 8.560112 loss_att 12.753458 loss_ctc 19.719604 loss_rnnt 6.129948 hw_loss 0.194180 lr 0.00029223 rank 3
2023-03-01 06:11:16,325 DEBUG TRAIN Batch 50/2900 loss 5.550846 loss_att 9.831440 loss_ctc 11.243130 loss_rnnt 3.837900 hw_loss 0.183480 lr 0.00029223 rank 6
2023-03-01 06:11:55,103 DEBUG TRAIN Batch 50/3000 loss 10.391746 loss_att 12.479144 loss_ctc 21.682480 loss_rnnt 8.322089 hw_loss 0.275147 lr 0.00029223 rank 1
2023-03-01 06:11:55,120 DEBUG TRAIN Batch 50/3000 loss 6.402110 loss_att 11.002920 loss_ctc 13.996794 loss_rnnt 4.369214 hw_loss 0.187703 lr 0.00029221 rank 7
2023-03-01 06:11:55,125 DEBUG TRAIN Batch 50/3000 loss 5.651988 loss_att 9.432554 loss_ctc 9.722173 loss_rnnt 4.217858 hw_loss 0.253734 lr 0.00029223 rank 2
2023-03-01 06:11:55,124 DEBUG TRAIN Batch 50/3000 loss 7.707798 loss_att 9.451110 loss_ctc 9.541001 loss_rnnt 7.043104 hw_loss 0.134258 lr 0.00029223 rank 0
2023-03-01 06:11:55,125 DEBUG TRAIN Batch 50/3000 loss 4.839995 loss_att 7.690813 loss_ctc 6.377580 loss_rnnt 4.018666 hw_loss 0.086539 lr 0.00029222 rank 5
2023-03-01 06:11:55,125 DEBUG TRAIN Batch 50/3000 loss 8.773276 loss_att 9.664877 loss_ctc 15.529158 loss_rnnt 7.616831 hw_loss 0.145013 lr 0.00029222 rank 3
2023-03-01 06:11:55,127 DEBUG TRAIN Batch 50/3000 loss 11.405765 loss_att 12.574158 loss_ctc 22.137928 loss_rnnt 9.621119 hw_loss 0.225021 lr 0.00029222 rank 4
2023-03-01 06:11:55,128 DEBUG TRAIN Batch 50/3000 loss 13.725143 loss_att 16.624634 loss_ctc 20.243914 loss_rnnt 12.180983 hw_loss 0.178302 lr 0.00029222 rank 6
2023-03-01 06:12:34,325 DEBUG TRAIN Batch 50/3100 loss 6.102460 loss_att 8.962179 loss_ctc 10.242882 loss_rnnt 4.796701 hw_loss 0.340798 lr 0.00029220 rank 7
2023-03-01 06:12:34,326 DEBUG TRAIN Batch 50/3100 loss 7.410515 loss_att 7.902970 loss_ctc 11.382668 loss_rnnt 6.622560 hw_loss 0.299706 lr 0.00029221 rank 2
2023-03-01 06:12:34,328 DEBUG TRAIN Batch 50/3100 loss 5.352333 loss_att 8.137968 loss_ctc 11.908690 loss_rnnt 3.858509 hw_loss 0.117215 lr 0.00029220 rank 3
2023-03-01 06:12:34,331 DEBUG TRAIN Batch 50/3100 loss 12.286966 loss_att 15.518099 loss_ctc 23.771976 loss_rnnt 10.018271 hw_loss 0.170873 lr 0.00029221 rank 0
2023-03-01 06:12:34,331 DEBUG TRAIN Batch 50/3100 loss 5.293445 loss_att 7.805368 loss_ctc 8.927110 loss_rnnt 4.133198 hw_loss 0.325075 lr 0.00029221 rank 6
2023-03-01 06:12:34,333 DEBUG TRAIN Batch 50/3100 loss 6.063607 loss_att 6.968229 loss_ctc 9.855690 loss_rnnt 5.155905 hw_loss 0.414685 lr 0.00029221 rank 1
2023-03-01 06:12:34,346 DEBUG TRAIN Batch 50/3100 loss 11.411891 loss_att 12.911201 loss_ctc 15.223838 loss_rnnt 10.500290 hw_loss 0.194025 lr 0.00029221 rank 5
2023-03-01 06:12:34,362 DEBUG TRAIN Batch 50/3100 loss 3.623927 loss_att 5.814919 loss_ctc 10.088313 loss_rnnt 2.184684 hw_loss 0.260863 lr 0.00029221 rank 4
2023-03-01 06:13:40,084 DEBUG TRAIN Batch 50/3200 loss 5.432728 loss_att 7.569152 loss_ctc 8.991729 loss_rnnt 4.407317 hw_loss 0.231737 lr 0.00029220 rank 2
2023-03-01 06:13:40,097 DEBUG TRAIN Batch 50/3200 loss 6.578124 loss_att 8.310292 loss_ctc 12.071072 loss_rnnt 5.400264 hw_loss 0.185689 lr 0.00029220 rank 0
2023-03-01 06:13:40,099 DEBUG TRAIN Batch 50/3200 loss 3.014801 loss_att 7.024031 loss_ctc 5.540417 loss_rnnt 1.744466 hw_loss 0.247013 lr 0.00029220 rank 1
2023-03-01 06:13:40,100 DEBUG TRAIN Batch 50/3200 loss 8.486521 loss_att 8.786308 loss_ctc 14.145289 loss_rnnt 7.487210 hw_loss 0.346594 lr 0.00029219 rank 3
2023-03-01 06:13:40,103 DEBUG TRAIN Batch 50/3200 loss 11.915384 loss_att 14.930668 loss_ctc 16.880098 loss_rnnt 10.541313 hw_loss 0.204472 lr 0.00029220 rank 6
2023-03-01 06:13:40,107 DEBUG TRAIN Batch 50/3200 loss 4.088869 loss_att 5.860815 loss_ctc 6.234095 loss_rnnt 3.232889 hw_loss 0.404174 lr 0.00029220 rank 4
2023-03-01 06:13:40,123 DEBUG TRAIN Batch 50/3200 loss 10.992386 loss_att 11.151555 loss_ctc 10.936938 loss_rnnt 10.882803 hw_loss 0.159642 lr 0.00029219 rank 7
2023-03-01 06:13:40,123 DEBUG TRAIN Batch 50/3200 loss 5.838737 loss_att 9.301811 loss_ctc 7.943019 loss_rnnt 4.782733 hw_loss 0.155285 lr 0.00029220 rank 5
2023-03-01 06:14:19,462 DEBUG TRAIN Batch 50/3300 loss 4.984414 loss_att 7.207760 loss_ctc 9.606741 loss_rnnt 3.837009 hw_loss 0.162047 lr 0.00029218 rank 3
2023-03-01 06:14:19,472 DEBUG TRAIN Batch 50/3300 loss 7.233413 loss_att 10.888193 loss_ctc 8.847570 loss_rnnt 6.161181 hw_loss 0.236352 lr 0.00029217 rank 7
2023-03-01 06:14:19,476 DEBUG TRAIN Batch 50/3300 loss 4.309726 loss_att 8.197522 loss_ctc 6.876853 loss_rnnt 3.117870 hw_loss 0.135023 lr 0.00029219 rank 0
2023-03-01 06:14:19,476 DEBUG TRAIN Batch 50/3300 loss 3.721503 loss_att 7.390040 loss_ctc 14.755992 loss_rnnt 1.495158 hw_loss 0.040073 lr 0.00029218 rank 6
2023-03-01 06:14:19,476 DEBUG TRAIN Batch 50/3300 loss 1.917300 loss_att 5.338472 loss_ctc 2.996958 loss_rnnt 0.947199 hw_loss 0.266087 lr 0.00029219 rank 1
2023-03-01 06:14:19,495 DEBUG TRAIN Batch 50/3300 loss 7.758320 loss_att 10.501112 loss_ctc 16.419380 loss_rnnt 5.854834 hw_loss 0.375226 lr 0.00029218 rank 5
2023-03-01 06:14:19,497 DEBUG TRAIN Batch 50/3300 loss 1.452196 loss_att 5.254672 loss_ctc 3.355605 loss_rnnt 0.346948 hw_loss 0.170559 lr 0.00029218 rank 4
2023-03-01 06:14:19,524 DEBUG TRAIN Batch 50/3300 loss 7.995085 loss_att 12.452703 loss_ctc 12.751125 loss_rnnt 6.430943 hw_loss 0.072149 lr 0.00029219 rank 2
2023-03-01 06:14:58,263 DEBUG TRAIN Batch 50/3400 loss 4.997469 loss_att 10.749719 loss_ctc 11.718197 loss_rnnt 2.755601 hw_loss 0.366229 lr 0.00029216 rank 7
2023-03-01 06:14:58,275 DEBUG TRAIN Batch 50/3400 loss 4.184959 loss_att 6.873903 loss_ctc 6.591334 loss_rnnt 3.270304 hw_loss 0.105029 lr 0.00029218 rank 0
2023-03-01 06:14:58,278 DEBUG TRAIN Batch 50/3400 loss 8.844312 loss_att 12.152203 loss_ctc 10.500960 loss_rnnt 7.818491 hw_loss 0.268794 lr 0.00029218 rank 1
2023-03-01 06:14:58,284 DEBUG TRAIN Batch 50/3400 loss 11.406739 loss_att 12.846654 loss_ctc 15.140226 loss_rnnt 10.604471 hw_loss 0.030914 lr 0.00029217 rank 5
2023-03-01 06:14:58,283 DEBUG TRAIN Batch 50/3400 loss 7.803492 loss_att 11.353242 loss_ctc 20.230047 loss_rnnt 5.335840 hw_loss 0.189054 lr 0.00029217 rank 4
2023-03-01 06:14:58,285 DEBUG TRAIN Batch 50/3400 loss 3.979235 loss_att 5.919490 loss_ctc 4.875234 loss_rnnt 3.313522 hw_loss 0.296616 lr 0.00029217 rank 3
2023-03-01 06:14:58,286 DEBUG TRAIN Batch 50/3400 loss 8.761668 loss_att 10.833090 loss_ctc 12.394794 loss_rnnt 7.747238 hw_loss 0.216992 lr 0.00029218 rank 2
2023-03-01 06:14:58,292 DEBUG TRAIN Batch 50/3400 loss 4.788904 loss_att 7.496290 loss_ctc 9.640141 loss_rnnt 3.469346 hw_loss 0.246093 lr 0.00029217 rank 6
2023-03-01 06:15:37,632 DEBUG TRAIN Batch 50/3500 loss 4.870628 loss_att 8.065985 loss_ctc 7.727561 loss_rnnt 3.759415 hw_loss 0.171034 lr 0.00029216 rank 1
2023-03-01 06:15:37,632 DEBUG TRAIN Batch 50/3500 loss 10.007019 loss_att 11.723853 loss_ctc 19.878973 loss_rnnt 8.274699 hw_loss 0.136299 lr 0.00029216 rank 4
2023-03-01 06:15:37,650 DEBUG TRAIN Batch 50/3500 loss 6.431098 loss_att 10.359394 loss_ctc 9.630596 loss_rnnt 5.084436 hw_loss 0.252005 lr 0.00029216 rank 2
2023-03-01 06:15:37,657 DEBUG TRAIN Batch 50/3500 loss 5.698312 loss_att 11.149317 loss_ctc 11.416491 loss_rnnt 3.717486 hw_loss 0.240378 lr 0.00029215 rank 7
2023-03-01 06:15:37,658 DEBUG TRAIN Batch 50/3500 loss 5.829982 loss_att 9.700943 loss_ctc 10.237171 loss_rnnt 4.272796 hw_loss 0.366317 lr 0.00029216 rank 0
2023-03-01 06:15:37,675 DEBUG TRAIN Batch 50/3500 loss 13.145089 loss_att 17.194660 loss_ctc 21.146902 loss_rnnt 11.203056 hw_loss 0.122268 lr 0.00029216 rank 6
2023-03-01 06:15:37,678 DEBUG TRAIN Batch 50/3500 loss 4.771760 loss_att 6.231252 loss_ctc 4.871904 loss_rnnt 4.296394 hw_loss 0.318965 lr 0.00029215 rank 3
2023-03-01 06:15:37,685 DEBUG TRAIN Batch 50/3500 loss 7.104918 loss_att 8.717987 loss_ctc 8.677648 loss_rnnt 6.492599 hw_loss 0.150013 lr 0.00029216 rank 5
2023-03-01 06:16:44,180 DEBUG TRAIN Batch 50/3600 loss 3.191026 loss_att 5.486870 loss_ctc 8.576326 loss_rnnt 1.927498 hw_loss 0.161849 lr 0.00029214 rank 7
2023-03-01 06:16:44,193 DEBUG TRAIN Batch 50/3600 loss 3.823523 loss_att 6.454695 loss_ctc 8.017839 loss_rnnt 2.652618 hw_loss 0.160179 lr 0.00029215 rank 6
2023-03-01 06:16:44,195 DEBUG TRAIN Batch 50/3600 loss 5.592737 loss_att 8.269236 loss_ctc 10.234558 loss_rnnt 4.339611 hw_loss 0.185468 lr 0.00029215 rank 0
2023-03-01 06:16:44,198 DEBUG TRAIN Batch 50/3600 loss 6.019135 loss_att 7.838768 loss_ctc 10.009701 loss_rnnt 5.044006 hw_loss 0.148362 lr 0.00029215 rank 4
2023-03-01 06:16:44,200 DEBUG TRAIN Batch 50/3600 loss 2.345283 loss_att 5.115655 loss_ctc 5.104420 loss_rnnt 1.293974 hw_loss 0.242529 lr 0.00029215 rank 2
2023-03-01 06:16:44,205 DEBUG TRAIN Batch 50/3600 loss 10.688372 loss_att 14.395879 loss_ctc 17.879902 loss_rnnt 8.884918 hw_loss 0.193276 lr 0.00029214 rank 3
2023-03-01 06:16:44,206 DEBUG TRAIN Batch 50/3600 loss 8.191232 loss_att 11.630629 loss_ctc 12.888902 loss_rnnt 6.702961 hw_loss 0.326316 lr 0.00029215 rank 1
2023-03-01 06:16:44,250 DEBUG TRAIN Batch 50/3600 loss 4.779491 loss_att 8.009520 loss_ctc 8.899774 loss_rnnt 3.433060 hw_loss 0.283227 lr 0.00029215 rank 5
2023-03-01 06:17:23,254 DEBUG TRAIN Batch 50/3700 loss 9.765782 loss_att 11.832600 loss_ctc 15.122623 loss_rnnt 8.534411 hw_loss 0.194556 lr 0.00029213 rank 4
2023-03-01 06:17:23,263 DEBUG TRAIN Batch 50/3700 loss 5.571212 loss_att 8.286724 loss_ctc 8.238992 loss_rnnt 4.554140 hw_loss 0.221749 lr 0.00029214 rank 2
2023-03-01 06:17:23,265 DEBUG TRAIN Batch 50/3700 loss 9.103252 loss_att 12.742638 loss_ctc 18.359343 loss_rnnt 7.029071 hw_loss 0.210298 lr 0.00029213 rank 3
2023-03-01 06:17:23,267 DEBUG TRAIN Batch 50/3700 loss 2.925830 loss_att 4.472086 loss_ctc 4.873787 loss_rnnt 2.211603 hw_loss 0.272341 lr 0.00029213 rank 5
2023-03-01 06:17:23,268 DEBUG TRAIN Batch 50/3700 loss 9.910966 loss_att 11.197252 loss_ctc 15.202797 loss_rnnt 8.855771 hw_loss 0.173173 lr 0.00029214 rank 1
2023-03-01 06:17:23,269 DEBUG TRAIN Batch 50/3700 loss 9.411266 loss_att 10.467993 loss_ctc 15.685430 loss_rnnt 8.201471 hw_loss 0.303552 lr 0.00029212 rank 7
2023-03-01 06:17:23,273 DEBUG TRAIN Batch 50/3700 loss 13.147178 loss_att 16.165195 loss_ctc 24.849913 loss_rnnt 10.869383 hw_loss 0.213426 lr 0.00029214 rank 0
2023-03-01 06:17:23,322 DEBUG TRAIN Batch 50/3700 loss 8.272891 loss_att 11.939853 loss_ctc 16.069365 loss_rnnt 6.408749 hw_loss 0.171039 lr 0.00029213 rank 6
2023-03-01 06:18:02,137 DEBUG TRAIN Batch 50/3800 loss 6.645202 loss_att 11.233223 loss_ctc 13.138212 loss_rnnt 4.681047 hw_loss 0.339030 lr 0.00029212 rank 5
2023-03-01 06:18:02,148 DEBUG TRAIN Batch 50/3800 loss 5.597755 loss_att 6.832134 loss_ctc 6.931406 loss_rnnt 5.060872 hw_loss 0.210351 lr 0.00029211 rank 7
2023-03-01 06:18:02,149 DEBUG TRAIN Batch 50/3800 loss 7.271452 loss_att 9.762659 loss_ctc 13.027214 loss_rnnt 5.846900 hw_loss 0.297892 lr 0.00029212 rank 6
2023-03-01 06:18:02,149 DEBUG TRAIN Batch 50/3800 loss 3.578887 loss_att 5.233872 loss_ctc 7.973748 loss_rnnt 2.475107 hw_loss 0.350251 lr 0.00029213 rank 0
2023-03-01 06:18:02,153 DEBUG TRAIN Batch 50/3800 loss 4.214558 loss_att 6.282778 loss_ctc 6.303042 loss_rnnt 3.366183 hw_loss 0.292999 lr 0.00029212 rank 4
2023-03-01 06:18:02,155 DEBUG TRAIN Batch 50/3800 loss 6.611254 loss_att 7.875815 loss_ctc 8.874075 loss_rnnt 5.849003 hw_loss 0.389306 lr 0.00029213 rank 2
2023-03-01 06:18:02,155 DEBUG TRAIN Batch 50/3800 loss 11.611033 loss_att 11.524502 loss_ctc 17.231058 loss_rnnt 10.731324 hw_loss 0.276897 lr 0.00029212 rank 3
2023-03-01 06:18:02,156 DEBUG TRAIN Batch 50/3800 loss 1.410199 loss_att 3.978631 loss_ctc 2.601343 loss_rnnt 0.636784 hw_loss 0.189206 lr 0.00029213 rank 1
2023-03-01 06:19:07,399 DEBUG TRAIN Batch 50/3900 loss 4.115093 loss_att 7.023858 loss_ctc 6.458185 loss_rnnt 3.152936 hw_loss 0.127485 lr 0.00029210 rank 3
2023-03-01 06:19:07,409 DEBUG TRAIN Batch 50/3900 loss 5.524070 loss_att 6.689982 loss_ctc 10.058000 loss_rnnt 4.575529 hw_loss 0.207816 lr 0.00029211 rank 0
2023-03-01 06:19:07,410 DEBUG TRAIN Batch 50/3900 loss 6.174581 loss_att 7.448328 loss_ctc 6.640121 loss_rnnt 5.757195 hw_loss 0.188559 lr 0.00029210 rank 7
2023-03-01 06:19:07,411 DEBUG TRAIN Batch 50/3900 loss 5.107789 loss_att 7.676858 loss_ctc 9.545531 loss_rnnt 3.901186 hw_loss 0.189544 lr 0.00029211 rank 1
2023-03-01 06:19:07,422 DEBUG TRAIN Batch 50/3900 loss 5.386046 loss_att 10.228451 loss_ctc 8.335686 loss_rnnt 3.923656 hw_loss 0.188670 lr 0.00029211 rank 5
2023-03-01 06:19:07,424 DEBUG TRAIN Batch 50/3900 loss 10.893068 loss_att 11.881733 loss_ctc 14.340374 loss_rnnt 10.079079 hw_loss 0.293655 lr 0.00029212 rank 2
2023-03-01 06:19:07,454 DEBUG TRAIN Batch 50/3900 loss 10.402066 loss_att 11.110038 loss_ctc 16.216869 loss_rnnt 9.289770 hw_loss 0.366366 lr 0.00029211 rank 4
2023-03-01 06:19:07,505 DEBUG TRAIN Batch 50/3900 loss 7.864603 loss_att 10.900810 loss_ctc 15.523661 loss_rnnt 6.182861 hw_loss 0.099924 lr 0.00029211 rank 6
2023-03-01 06:19:48,295 DEBUG TRAIN Batch 50/4000 loss 3.159651 loss_att 6.851313 loss_ctc 5.060954 loss_rnnt 2.039519 hw_loss 0.240548 lr 0.00029209 rank 7
2023-03-01 06:19:48,296 DEBUG TRAIN Batch 50/4000 loss 4.309255 loss_att 8.613227 loss_ctc 9.429540 loss_rnnt 2.634084 hw_loss 0.246886 lr 0.00029210 rank 0
2023-03-01 06:19:48,306 DEBUG TRAIN Batch 50/4000 loss 12.747207 loss_att 13.029047 loss_ctc 14.090670 loss_rnnt 12.430923 hw_loss 0.151475 lr 0.00029210 rank 1
2023-03-01 06:19:48,311 DEBUG TRAIN Batch 50/4000 loss 11.297502 loss_att 12.228166 loss_ctc 27.346510 loss_rnnt 8.790781 hw_loss 0.338849 lr 0.00029209 rank 3
2023-03-01 06:19:48,312 DEBUG TRAIN Batch 50/4000 loss 5.035503 loss_att 6.547692 loss_ctc 7.908733 loss_rnnt 4.237844 hw_loss 0.210232 lr 0.00029210 rank 4
2023-03-01 06:19:48,314 DEBUG TRAIN Batch 50/4000 loss 5.089068 loss_att 6.987103 loss_ctc 7.659357 loss_rnnt 4.192230 hw_loss 0.327235 lr 0.00029210 rank 6
2023-03-01 06:19:48,315 DEBUG TRAIN Batch 50/4000 loss 2.843425 loss_att 5.847466 loss_ctc 5.786630 loss_rnnt 1.676208 hw_loss 0.326216 lr 0.00029210 rank 5
2023-03-01 06:19:48,322 DEBUG TRAIN Batch 50/4000 loss 6.734681 loss_att 9.388340 loss_ctc 16.014700 loss_rnnt 4.789592 hw_loss 0.331915 lr 0.00029210 rank 2
2023-03-01 06:20:26,442 DEBUG TRAIN Batch 50/4100 loss 4.997526 loss_att 7.707954 loss_ctc 5.981426 loss_rnnt 4.145128 hw_loss 0.335860 lr 0.00029209 rank 0
2023-03-01 06:20:26,446 DEBUG TRAIN Batch 50/4100 loss 1.790634 loss_att 4.473949 loss_ctc 3.292309 loss_rnnt 0.872592 hw_loss 0.339666 lr 0.00029208 rank 5
2023-03-01 06:20:26,446 DEBUG TRAIN Batch 50/4100 loss 4.468153 loss_att 6.996327 loss_ctc 9.247730 loss_rnnt 3.190746 hw_loss 0.252178 lr 0.00029207 rank 7
2023-03-01 06:20:26,446 DEBUG TRAIN Batch 50/4100 loss 5.896218 loss_att 10.881804 loss_ctc 12.648569 loss_rnnt 3.881134 hw_loss 0.220602 lr 0.00029208 rank 3
2023-03-01 06:20:26,449 DEBUG TRAIN Batch 50/4100 loss 6.239692 loss_att 9.013584 loss_ctc 12.622916 loss_rnnt 4.641959 hw_loss 0.359733 lr 0.00029208 rank 4
2023-03-01 06:20:26,449 DEBUG TRAIN Batch 50/4100 loss 7.350941 loss_att 8.966921 loss_ctc 11.660949 loss_rnnt 6.335315 hw_loss 0.220805 lr 0.00029209 rank 1
2023-03-01 06:20:26,453 DEBUG TRAIN Batch 50/4100 loss 5.807623 loss_att 9.286682 loss_ctc 10.034272 loss_rnnt 4.412609 hw_loss 0.254340 lr 0.00029208 rank 6
2023-03-01 06:20:26,454 DEBUG TRAIN Batch 50/4100 loss 5.301110 loss_att 7.324945 loss_ctc 6.008704 loss_rnnt 4.667811 hw_loss 0.251597 lr 0.00029209 rank 2
2023-03-01 06:21:05,790 DEBUG TRAIN Batch 50/4200 loss 5.600187 loss_att 7.885380 loss_ctc 9.261868 loss_rnnt 4.510486 hw_loss 0.270824 lr 0.00029208 rank 2
2023-03-01 06:21:05,802 DEBUG TRAIN Batch 50/4200 loss 11.601943 loss_att 13.926529 loss_ctc 20.261930 loss_rnnt 9.888746 hw_loss 0.175526 lr 0.00029207 rank 4
2023-03-01 06:21:05,804 DEBUG TRAIN Batch 50/4200 loss 19.108627 loss_att 22.711330 loss_ctc 30.791552 loss_rnnt 16.759296 hw_loss 0.133253 lr 0.00029207 rank 6
2023-03-01 06:21:05,805 DEBUG TRAIN Batch 50/4200 loss 4.555090 loss_att 6.841137 loss_ctc 8.266920 loss_rnnt 3.451945 hw_loss 0.283172 lr 0.00029208 rank 0
2023-03-01 06:21:05,808 DEBUG TRAIN Batch 50/4200 loss 19.225651 loss_att 22.503719 loss_ctc 30.451899 loss_rnnt 16.959455 hw_loss 0.213278 lr 0.00029207 rank 3
2023-03-01 06:21:05,808 DEBUG TRAIN Batch 50/4200 loss 8.192643 loss_att 9.410522 loss_ctc 11.784572 loss_rnnt 7.336482 hw_loss 0.250616 lr 0.00029208 rank 1
2023-03-01 06:21:05,809 DEBUG TRAIN Batch 50/4200 loss 8.597642 loss_att 12.113271 loss_ctc 16.308815 loss_rnnt 6.772232 hw_loss 0.176490 lr 0.00029206 rank 7
2023-03-01 06:21:05,811 DEBUG TRAIN Batch 50/4200 loss 6.626064 loss_att 9.560070 loss_ctc 15.194143 loss_rnnt 4.806504 hw_loss 0.169404 lr 0.00029207 rank 5
2023-03-01 06:22:11,155 DEBUG TRAIN Batch 50/4300 loss 6.854621 loss_att 8.719709 loss_ctc 11.108232 loss_rnnt 5.788661 hw_loss 0.235865 lr 0.00029205 rank 7
2023-03-01 06:22:11,156 DEBUG TRAIN Batch 50/4300 loss 9.316666 loss_att 11.315701 loss_ctc 14.567277 loss_rnnt 8.157209 hw_loss 0.111689 lr 0.00029206 rank 0
2023-03-01 06:22:11,156 DEBUG TRAIN Batch 50/4300 loss 10.822759 loss_att 13.869344 loss_ctc 19.165480 loss_rnnt 8.981009 hw_loss 0.225132 lr 0.00029206 rank 1
2023-03-01 06:22:11,157 DEBUG TRAIN Batch 50/4300 loss 7.178559 loss_att 10.070646 loss_ctc 13.789728 loss_rnnt 5.589626 hw_loss 0.241924 lr 0.00029206 rank 5
2023-03-01 06:22:11,158 DEBUG TRAIN Batch 50/4300 loss 2.151020 loss_att 3.727990 loss_ctc 2.619836 loss_rnnt 1.655592 hw_loss 0.220360 lr 0.00029206 rank 4
2023-03-01 06:22:11,159 DEBUG TRAIN Batch 50/4300 loss 3.632296 loss_att 6.265580 loss_ctc 7.702440 loss_rnnt 2.400814 hw_loss 0.304013 lr 0.00029206 rank 6
2023-03-01 06:22:11,161 DEBUG TRAIN Batch 50/4300 loss 13.038497 loss_att 14.848234 loss_ctc 18.521942 loss_rnnt 11.909435 hw_loss 0.067479 lr 0.00029207 rank 2
2023-03-01 06:22:11,163 DEBUG TRAIN Batch 50/4300 loss 8.219571 loss_att 8.522127 loss_ctc 12.065823 loss_rnnt 7.441578 hw_loss 0.383715 lr 0.00029205 rank 3
2023-03-01 06:22:49,931 DEBUG TRAIN Batch 50/4400 loss 8.128557 loss_att 11.556746 loss_ctc 13.656900 loss_rnnt 6.559650 hw_loss 0.274042 lr 0.00029205 rank 6
2023-03-01 06:22:49,935 DEBUG TRAIN Batch 50/4400 loss 3.777271 loss_att 5.629376 loss_ctc 6.845392 loss_rnnt 2.901731 hw_loss 0.180067 lr 0.00029204 rank 7
2023-03-01 06:22:49,937 DEBUG TRAIN Batch 50/4400 loss 4.912904 loss_att 7.184455 loss_ctc 11.779501 loss_rnnt 3.349612 hw_loss 0.362692 lr 0.00029205 rank 0
2023-03-01 06:22:49,938 DEBUG TRAIN Batch 50/4400 loss 9.930285 loss_att 12.119643 loss_ctc 14.197891 loss_rnnt 8.760356 hw_loss 0.305705 lr 0.00029205 rank 4
2023-03-01 06:22:49,941 DEBUG TRAIN Batch 50/4400 loss 6.571186 loss_att 8.512029 loss_ctc 11.089204 loss_rnnt 5.494495 hw_loss 0.161473 lr 0.00029204 rank 3
2023-03-01 06:22:49,949 DEBUG TRAIN Batch 50/4400 loss 11.853014 loss_att 15.497736 loss_ctc 18.028708 loss_rnnt 10.190023 hw_loss 0.207413 lr 0.00029205 rank 2
2023-03-01 06:22:49,957 DEBUG TRAIN Batch 50/4400 loss 6.805734 loss_att 10.132045 loss_ctc 8.569549 loss_rnnt 5.811208 hw_loss 0.176415 lr 0.00029205 rank 1
2023-03-01 06:22:49,960 DEBUG TRAIN Batch 50/4400 loss 6.395515 loss_att 7.091647 loss_ctc 11.082418 loss_rnnt 5.492296 hw_loss 0.260762 lr 0.00029205 rank 5
2023-03-01 06:23:28,891 DEBUG TRAIN Batch 50/4500 loss 9.258462 loss_att 9.279406 loss_ctc 12.970588 loss_rnnt 8.544261 hw_loss 0.403242 lr 0.00029203 rank 6
2023-03-01 06:23:28,896 DEBUG TRAIN Batch 50/4500 loss 3.141858 loss_att 6.432413 loss_ctc 4.508988 loss_rnnt 2.057395 hw_loss 0.457628 lr 0.00029203 rank 3
2023-03-01 06:23:28,911 DEBUG TRAIN Batch 50/4500 loss 6.611916 loss_att 9.325052 loss_ctc 11.827719 loss_rnnt 5.240387 hw_loss 0.250237 lr 0.00029204 rank 0
2023-03-01 06:23:28,911 DEBUG TRAIN Batch 50/4500 loss 2.671432 loss_att 5.780397 loss_ctc 5.224636 loss_rnnt 1.571719 hw_loss 0.257799 lr 0.00029202 rank 7
2023-03-01 06:23:28,912 DEBUG TRAIN Batch 50/4500 loss 5.110262 loss_att 7.663023 loss_ctc 6.165558 loss_rnnt 4.296011 hw_loss 0.305612 lr 0.00029204 rank 2
2023-03-01 06:23:28,912 DEBUG TRAIN Batch 50/4500 loss 5.376142 loss_att 11.964499 loss_ctc 9.292870 loss_rnnt 3.480078 hw_loss 0.105303 lr 0.00029204 rank 1
2023-03-01 06:23:28,915 DEBUG TRAIN Batch 50/4500 loss 6.518303 loss_att 8.191716 loss_ctc 11.430326 loss_rnnt 5.426562 hw_loss 0.191480 lr 0.00029203 rank 5
2023-03-01 06:23:28,957 DEBUG TRAIN Batch 50/4500 loss 4.878861 loss_att 8.256919 loss_ctc 10.127112 loss_rnnt 3.349249 hw_loss 0.289187 lr 0.00029203 rank 4
2023-03-01 06:24:08,979 DEBUG TRAIN Batch 50/4600 loss 4.924211 loss_att 7.214688 loss_ctc 6.051141 loss_rnnt 4.258050 hw_loss 0.108390 lr 0.00029202 rank 6
2023-03-01 06:24:08,989 DEBUG TRAIN Batch 50/4600 loss 4.322926 loss_att 8.693009 loss_ctc 6.514442 loss_rnnt 2.936988 hw_loss 0.411973 lr 0.00029203 rank 0
2023-03-01 06:24:08,993 DEBUG TRAIN Batch 50/4600 loss 7.861971 loss_att 11.204942 loss_ctc 9.944296 loss_rnnt 6.843625 hw_loss 0.135203 lr 0.00029201 rank 7
2023-03-01 06:24:08,992 DEBUG TRAIN Batch 50/4600 loss 11.368455 loss_att 11.314329 loss_ctc 19.477707 loss_rnnt 10.135014 hw_loss 0.305686 lr 0.00029203 rank 2
2023-03-01 06:24:08,993 DEBUG TRAIN Batch 50/4600 loss 5.787431 loss_att 11.285544 loss_ctc 11.143789 loss_rnnt 3.838184 hw_loss 0.253958 lr 0.00029203 rank 1
2023-03-01 06:24:08,993 DEBUG TRAIN Batch 50/4600 loss 3.996113 loss_att 8.865888 loss_ctc 6.906763 loss_rnnt 2.546369 hw_loss 0.164441 lr 0.00029202 rank 4
2023-03-01 06:24:08,995 DEBUG TRAIN Batch 50/4600 loss 3.132796 loss_att 5.066776 loss_ctc 4.000774 loss_rnnt 2.520899 hw_loss 0.205070 lr 0.00029202 rank 5
2023-03-01 06:24:09,020 DEBUG TRAIN Batch 50/4600 loss 6.137970 loss_att 9.693432 loss_ctc 13.572927 loss_rnnt 4.310988 hw_loss 0.233554 lr 0.00029202 rank 3
2023-03-01 06:25:15,777 DEBUG TRAIN Batch 50/4700 loss 7.688421 loss_att 11.135652 loss_ctc 13.730476 loss_rnnt 6.103935 hw_loss 0.167687 lr 0.00029200 rank 7
2023-03-01 06:25:15,778 DEBUG TRAIN Batch 50/4700 loss 2.643389 loss_att 5.708201 loss_ctc 4.082978 loss_rnnt 1.692077 hw_loss 0.274508 lr 0.00029201 rank 4
2023-03-01 06:25:15,778 DEBUG TRAIN Batch 50/4700 loss 3.836875 loss_att 6.352040 loss_ctc 5.196717 loss_rnnt 3.056569 hw_loss 0.179928 lr 0.00029201 rank 0
2023-03-01 06:25:15,779 DEBUG TRAIN Batch 50/4700 loss 5.509094 loss_att 8.350895 loss_ctc 8.746216 loss_rnnt 4.464140 hw_loss 0.084333 lr 0.00029201 rank 6
2023-03-01 06:25:15,783 DEBUG TRAIN Batch 50/4700 loss 10.581639 loss_att 12.540150 loss_ctc 15.429468 loss_rnnt 9.395977 hw_loss 0.276717 lr 0.00029200 rank 3
2023-03-01 06:25:15,787 DEBUG TRAIN Batch 50/4700 loss 7.933007 loss_att 10.467809 loss_ctc 13.480131 loss_rnnt 6.525617 hw_loss 0.301525 lr 0.00029202 rank 2
2023-03-01 06:25:15,803 DEBUG TRAIN Batch 50/4700 loss 6.465932 loss_att 8.295676 loss_ctc 7.386387 loss_rnnt 5.808931 hw_loss 0.315610 lr 0.00029201 rank 1
2023-03-01 06:25:15,804 DEBUG TRAIN Batch 50/4700 loss 3.214055 loss_att 6.845119 loss_ctc 5.614153 loss_rnnt 2.075901 hw_loss 0.172364 lr 0.00029201 rank 5
2023-03-01 06:25:54,607 DEBUG TRAIN Batch 50/4800 loss 5.908836 loss_att 9.881940 loss_ctc 13.524212 loss_rnnt 4.000397 hw_loss 0.184565 lr 0.00029200 rank 2
2023-03-01 06:25:54,616 DEBUG TRAIN Batch 50/4800 loss 8.429689 loss_att 10.735579 loss_ctc 15.853856 loss_rnnt 6.815391 hw_loss 0.306061 lr 0.00029200 rank 5
2023-03-01 06:25:54,616 DEBUG TRAIN Batch 50/4800 loss 10.252308 loss_att 13.054108 loss_ctc 14.056314 loss_rnnt 9.111653 hw_loss 0.137051 lr 0.00029199 rank 7
2023-03-01 06:25:54,620 DEBUG TRAIN Batch 50/4800 loss 3.826543 loss_att 6.844840 loss_ctc 7.874143 loss_rnnt 2.603525 hw_loss 0.149397 lr 0.00029200 rank 4
2023-03-01 06:25:54,621 DEBUG TRAIN Batch 50/4800 loss 2.989490 loss_att 6.318179 loss_ctc 7.643312 loss_rnnt 1.599532 hw_loss 0.194457 lr 0.00029200 rank 0
2023-03-01 06:25:54,627 DEBUG TRAIN Batch 50/4800 loss 6.817981 loss_att 7.993543 loss_ctc 13.325190 loss_rnnt 5.612396 hw_loss 0.192834 lr 0.00029199 rank 3
2023-03-01 06:25:54,666 DEBUG TRAIN Batch 50/4800 loss 6.025331 loss_att 10.109955 loss_ctc 12.239000 loss_rnnt 4.332717 hw_loss 0.088500 lr 0.00029200 rank 1
2023-03-01 06:25:54,694 DEBUG TRAIN Batch 50/4800 loss 3.042813 loss_att 5.785027 loss_ctc 4.825502 loss_rnnt 2.115609 hw_loss 0.264505 lr 0.00029200 rank 6
2023-03-01 06:26:33,505 DEBUG TRAIN Batch 50/4900 loss 5.476693 loss_att 8.085384 loss_ctc 10.013863 loss_rnnt 4.248289 hw_loss 0.190705 lr 0.00029199 rank 1
2023-03-01 06:26:33,509 DEBUG TRAIN Batch 50/4900 loss 4.845726 loss_att 6.429319 loss_ctc 9.401419 loss_rnnt 3.769426 hw_loss 0.285290 lr 0.00029198 rank 3
2023-03-01 06:26:33,516 DEBUG TRAIN Batch 50/4900 loss 4.217721 loss_att 5.883432 loss_ctc 9.588638 loss_rnnt 3.015405 hw_loss 0.286973 lr 0.00029199 rank 0
2023-03-01 06:26:33,517 DEBUG TRAIN Batch 50/4900 loss 5.743989 loss_att 8.022973 loss_ctc 9.546091 loss_rnnt 4.673383 hw_loss 0.202243 lr 0.00029199 rank 4
2023-03-01 06:26:33,519 DEBUG TRAIN Batch 50/4900 loss 5.998732 loss_att 11.817108 loss_ctc 11.588289 loss_rnnt 3.959682 hw_loss 0.243938 lr 0.00029198 rank 6
2023-03-01 06:26:33,523 DEBUG TRAIN Batch 50/4900 loss 8.396980 loss_att 11.989691 loss_ctc 10.836421 loss_rnnt 7.213916 hw_loss 0.261121 lr 0.00029198 rank 7
2023-03-01 06:26:33,525 DEBUG TRAIN Batch 50/4900 loss 5.012079 loss_att 7.427291 loss_ctc 6.489342 loss_rnnt 4.153219 hw_loss 0.335343 lr 0.00029198 rank 5
2023-03-01 06:26:33,541 DEBUG TRAIN Batch 50/4900 loss 6.334540 loss_att 10.374508 loss_ctc 11.363567 loss_rnnt 4.698596 hw_loss 0.295150 lr 0.00029199 rank 2
2023-03-01 06:27:41,817 DEBUG TRAIN Batch 50/5000 loss 10.890098 loss_att 13.173273 loss_ctc 18.732098 loss_rnnt 9.301197 hw_loss 0.162497 lr 0.00029197 rank 6
2023-03-01 06:27:41,831 DEBUG TRAIN Batch 50/5000 loss 1.761578 loss_att 4.316948 loss_ctc 3.748439 loss_rnnt 0.863154 hw_loss 0.229567 lr 0.00029197 rank 3
2023-03-01 06:27:41,832 DEBUG TRAIN Batch 50/5000 loss 15.262731 loss_att 17.160843 loss_ctc 21.854177 loss_rnnt 13.953577 hw_loss 0.095007 lr 0.00029196 rank 7
2023-03-01 06:27:41,834 DEBUG TRAIN Batch 50/5000 loss 4.449053 loss_att 5.785248 loss_ctc 5.557827 loss_rnnt 3.914283 hw_loss 0.224427 lr 0.00029198 rank 0
2023-03-01 06:27:41,835 DEBUG TRAIN Batch 50/5000 loss 6.300055 loss_att 6.940854 loss_ctc 10.267192 loss_rnnt 5.524876 hw_loss 0.221376 lr 0.00029198 rank 1
2023-03-01 06:27:41,839 DEBUG TRAIN Batch 50/5000 loss 4.434317 loss_att 5.137505 loss_ctc 7.385542 loss_rnnt 3.743022 hw_loss 0.294677 lr 0.00029197 rank 5
2023-03-01 06:27:41,839 DEBUG TRAIN Batch 50/5000 loss 6.957605 loss_att 9.561360 loss_ctc 13.666867 loss_rnnt 5.334903 hw_loss 0.388842 lr 0.00029198 rank 2
2023-03-01 06:27:41,842 DEBUG TRAIN Batch 50/5000 loss 4.281085 loss_att 7.764454 loss_ctc 5.466975 loss_rnnt 3.318666 hw_loss 0.201799 lr 0.00029197 rank 4
2023-03-01 06:28:20,223 DEBUG TRAIN Batch 50/5100 loss 4.930364 loss_att 6.751370 loss_ctc 7.579346 loss_rnnt 4.104385 hw_loss 0.203586 lr 0.00029197 rank 0
2023-03-01 06:28:20,225 DEBUG TRAIN Batch 50/5100 loss 14.035983 loss_att 16.120838 loss_ctc 26.282171 loss_rnnt 11.854983 hw_loss 0.246005 lr 0.00029197 rank 2
2023-03-01 06:28:20,226 DEBUG TRAIN Batch 50/5100 loss 2.594083 loss_att 5.721519 loss_ctc 6.560036 loss_rnnt 1.334895 hw_loss 0.196701 lr 0.00029195 rank 7
2023-03-01 06:28:20,227 DEBUG TRAIN Batch 50/5100 loss 1.941052 loss_att 4.904208 loss_ctc 5.609955 loss_rnnt 0.715869 hw_loss 0.268810 lr 0.00029196 rank 1
2023-03-01 06:28:20,228 DEBUG TRAIN Batch 50/5100 loss 5.881701 loss_att 7.268939 loss_ctc 8.073770 loss_rnnt 5.258220 hw_loss 0.100796 lr 0.00029196 rank 5
2023-03-01 06:28:20,230 DEBUG TRAIN Batch 50/5100 loss 8.047274 loss_att 9.582391 loss_ctc 11.026140 loss_rnnt 7.233715 hw_loss 0.205038 lr 0.00029196 rank 6
2023-03-01 06:28:20,230 DEBUG TRAIN Batch 50/5100 loss 8.155202 loss_att 10.192688 loss_ctc 13.489437 loss_rnnt 6.873090 hw_loss 0.306344 lr 0.00029196 rank 4
2023-03-01 06:28:20,232 DEBUG TRAIN Batch 50/5100 loss 8.710214 loss_att 8.368674 loss_ctc 13.431249 loss_rnnt 7.984703 hw_loss 0.308152 lr 0.00029196 rank 3
2023-03-01 06:28:59,230 DEBUG TRAIN Batch 50/5200 loss 6.607626 loss_att 11.247326 loss_ctc 12.063520 loss_rnnt 4.769683 hw_loss 0.342282 lr 0.00029195 rank 6
2023-03-01 06:28:59,233 DEBUG TRAIN Batch 50/5200 loss 3.944974 loss_att 5.560618 loss_ctc 8.170782 loss_rnnt 2.895195 hw_loss 0.306018 lr 0.00029195 rank 4
2023-03-01 06:28:59,234 DEBUG TRAIN Batch 50/5200 loss 5.354843 loss_att 7.292578 loss_ctc 7.567684 loss_rnnt 4.602375 hw_loss 0.131018 lr 0.00029194 rank 7
2023-03-01 06:28:59,235 DEBUG TRAIN Batch 50/5200 loss 13.366966 loss_att 15.511253 loss_ctc 18.490055 loss_rnnt 12.092117 hw_loss 0.305463 lr 0.00029195 rank 1
2023-03-01 06:28:59,237 DEBUG TRAIN Batch 50/5200 loss 5.491178 loss_att 9.148104 loss_ctc 10.394278 loss_rnnt 4.055176 hw_loss 0.095380 lr 0.00029195 rank 0
2023-03-01 06:28:59,238 DEBUG TRAIN Batch 50/5200 loss 3.385250 loss_att 5.852314 loss_ctc 6.227748 loss_rnnt 2.420595 hw_loss 0.172955 lr 0.00029194 rank 3
2023-03-01 06:28:59,242 DEBUG TRAIN Batch 50/5200 loss 5.231468 loss_att 5.585489 loss_ctc 4.050990 loss_rnnt 5.196061 hw_loss 0.228750 lr 0.00029195 rank 5
2023-03-01 06:28:59,243 DEBUG TRAIN Batch 50/5200 loss 4.746464 loss_att 10.589088 loss_ctc 9.531997 loss_rnnt 2.802237 hw_loss 0.258059 lr 0.00029195 rank 2
2023-03-01 06:29:39,281 DEBUG TRAIN Batch 50/5300 loss 5.317779 loss_att 6.755008 loss_ctc 10.424528 loss_rnnt 4.232335 hw_loss 0.219558 lr 0.00029193 rank 7
2023-03-01 06:29:39,282 DEBUG TRAIN Batch 50/5300 loss 8.023678 loss_att 11.336151 loss_ctc 22.848812 loss_rnnt 5.368089 hw_loss 0.030766 lr 0.00029194 rank 0
2023-03-01 06:29:39,283 DEBUG TRAIN Batch 50/5300 loss 4.553505 loss_att 8.314266 loss_ctc 6.294336 loss_rnnt 3.379286 hw_loss 0.356168 lr 0.00029194 rank 2
2023-03-01 06:29:39,284 DEBUG TRAIN Batch 50/5300 loss 1.175867 loss_att 4.472341 loss_ctc 2.248948 loss_rnnt 0.296853 hw_loss 0.143704 lr 0.00029193 rank 3
2023-03-01 06:29:39,286 DEBUG TRAIN Batch 50/5300 loss 4.135846 loss_att 8.849409 loss_ctc 8.239780 loss_rnnt 2.511503 hw_loss 0.252073 lr 0.00029194 rank 4
2023-03-01 06:29:39,287 DEBUG TRAIN Batch 50/5300 loss 9.001196 loss_att 12.646997 loss_ctc 16.443657 loss_rnnt 7.169300 hw_loss 0.207015 lr 0.00029194 rank 1
2023-03-01 06:29:39,289 DEBUG TRAIN Batch 50/5300 loss 2.395775 loss_att 5.234918 loss_ctc 6.246261 loss_rnnt 1.253862 hw_loss 0.113787 lr 0.00029193 rank 6
2023-03-01 06:29:39,311 DEBUG TRAIN Batch 50/5300 loss 11.204576 loss_att 15.169924 loss_ctc 22.989925 loss_rnnt 8.702883 hw_loss 0.257331 lr 0.00029193 rank 5
2023-03-01 06:30:44,795 DEBUG TRAIN Batch 50/5400 loss 4.945315 loss_att 10.387914 loss_ctc 8.274439 loss_rnnt 3.354112 hw_loss 0.110250 lr 0.00029192 rank 4
2023-03-01 06:30:44,806 DEBUG TRAIN Batch 50/5400 loss 6.327975 loss_att 8.275951 loss_ctc 7.481922 loss_rnnt 5.679258 hw_loss 0.197367 lr 0.00029192 rank 6
2023-03-01 06:30:44,806 DEBUG TRAIN Batch 50/5400 loss 2.007773 loss_att 4.485646 loss_ctc 3.946951 loss_rnnt 1.110196 hw_loss 0.268960 lr 0.00029193 rank 1
2023-03-01 06:30:44,807 DEBUG TRAIN Batch 50/5400 loss 7.878564 loss_att 10.909472 loss_ctc 14.602421 loss_rnnt 6.302463 hw_loss 0.137637 lr 0.00029191 rank 7
2023-03-01 06:30:44,808 DEBUG TRAIN Batch 50/5400 loss 7.732468 loss_att 10.265404 loss_ctc 15.431175 loss_rnnt 5.998764 hw_loss 0.376167 lr 0.00029193 rank 0
2023-03-01 06:30:44,810 DEBUG TRAIN Batch 50/5400 loss 10.847094 loss_att 12.908546 loss_ctc 17.765045 loss_rnnt 9.460152 hw_loss 0.097983 lr 0.00029192 rank 3
2023-03-01 06:30:44,814 DEBUG TRAIN Batch 50/5400 loss 4.862729 loss_att 7.110776 loss_ctc 9.196667 loss_rnnt 3.687343 hw_loss 0.277347 lr 0.00029192 rank 5
2023-03-01 06:30:44,861 DEBUG TRAIN Batch 50/5400 loss 8.732418 loss_att 12.505299 loss_ctc 16.510134 loss_rnnt 6.809722 hw_loss 0.245796 lr 0.00029193 rank 2
2023-03-01 06:31:23,764 DEBUG TRAIN Batch 50/5500 loss 2.732114 loss_att 4.446191 loss_ctc 4.435464 loss_rnnt 2.129846 hw_loss 0.060635 lr 0.00029191 rank 6
2023-03-01 06:31:23,764 DEBUG TRAIN Batch 50/5500 loss 9.925265 loss_att 11.344828 loss_ctc 18.321560 loss_rnnt 8.371887 hw_loss 0.281175 lr 0.00029191 rank 1
2023-03-01 06:31:23,770 DEBUG TRAIN Batch 50/5500 loss 6.442364 loss_att 8.116475 loss_ctc 7.871114 loss_rnnt 5.833059 hw_loss 0.157467 lr 0.00029192 rank 2
2023-03-01 06:31:23,780 DEBUG TRAIN Batch 50/5500 loss 1.146343 loss_att 3.390572 loss_ctc 3.218063 loss_rnnt 0.299004 hw_loss 0.229244 lr 0.00029192 rank 0
2023-03-01 06:31:23,781 DEBUG TRAIN Batch 50/5500 loss 7.472320 loss_att 11.414656 loss_ctc 14.466896 loss_rnnt 5.696836 hw_loss 0.102014 lr 0.00029190 rank 7
2023-03-01 06:31:23,784 DEBUG TRAIN Batch 50/5500 loss 10.291713 loss_att 12.817491 loss_ctc 15.242507 loss_rnnt 9.020994 hw_loss 0.197732 lr 0.00029191 rank 5
2023-03-01 06:31:23,787 DEBUG TRAIN Batch 50/5500 loss 7.061768 loss_att 9.568661 loss_ctc 12.067917 loss_rnnt 5.765546 hw_loss 0.238794 lr 0.00029191 rank 4
2023-03-01 06:31:23,788 DEBUG TRAIN Batch 50/5500 loss 3.107900 loss_att 4.347191 loss_ctc 6.278081 loss_rnnt 2.311691 hw_loss 0.235611 lr 0.00029191 rank 3
2023-03-01 06:32:02,915 DEBUG TRAIN Batch 50/5600 loss 2.954070 loss_att 4.990351 loss_ctc 3.400447 loss_rnnt 2.388014 hw_loss 0.186155 lr 0.00029190 rank 6
2023-03-01 06:32:02,920 DEBUG TRAIN Batch 50/5600 loss 10.413416 loss_att 14.138702 loss_ctc 18.140533 loss_rnnt 8.529439 hw_loss 0.203693 lr 0.00029190 rank 0
2023-03-01 06:32:02,927 DEBUG TRAIN Batch 50/5600 loss 5.035644 loss_att 6.746801 loss_ctc 7.819047 loss_rnnt 4.193006 hw_loss 0.242412 lr 0.00029190 rank 1
2023-03-01 06:32:02,933 DEBUG TRAIN Batch 50/5600 loss 1.512418 loss_att 4.601670 loss_ctc 2.747204 loss_rnnt 0.584602 hw_loss 0.272488 lr 0.00029190 rank 2
2023-03-01 06:32:02,934 DEBUG TRAIN Batch 50/5600 loss 3.877495 loss_att 5.937790 loss_ctc 6.456094 loss_rnnt 3.010305 hw_loss 0.208720 lr 0.00029189 rank 7
2023-03-01 06:32:02,935 DEBUG TRAIN Batch 50/5600 loss 4.203848 loss_att 6.472152 loss_ctc 7.441629 loss_rnnt 3.209404 hw_loss 0.204523 lr 0.00029190 rank 5
2023-03-01 06:32:02,942 DEBUG TRAIN Batch 50/5600 loss 5.090978 loss_att 7.379491 loss_ctc 8.602262 loss_rnnt 4.036750 hw_loss 0.240664 lr 0.00029190 rank 4
2023-03-01 06:32:02,959 DEBUG TRAIN Batch 50/5600 loss 8.119076 loss_att 8.696353 loss_ctc 12.063016 loss_rnnt 7.410125 hw_loss 0.126817 lr 0.00029189 rank 3
2023-03-01 06:33:10,616 DEBUG TRAIN Batch 50/5700 loss 7.733857 loss_att 8.101086 loss_ctc 11.452438 loss_rnnt 6.990538 hw_loss 0.326367 lr 0.00029189 rank 0
2023-03-01 06:33:10,616 DEBUG TRAIN Batch 50/5700 loss 6.779408 loss_att 7.176989 loss_ctc 11.273833 loss_rnnt 5.931367 hw_loss 0.317376 lr 0.00029188 rank 7
2023-03-01 06:33:10,624 DEBUG TRAIN Batch 50/5700 loss 4.380519 loss_att 7.161350 loss_ctc 7.680419 loss_rnnt 3.266211 hw_loss 0.221540 lr 0.00029189 rank 2
2023-03-01 06:33:10,625 DEBUG TRAIN Batch 50/5700 loss 4.011741 loss_att 6.426257 loss_ctc 4.358014 loss_rnnt 3.348648 hw_loss 0.251290 lr 0.00029189 rank 5
2023-03-01 06:33:10,626 DEBUG TRAIN Batch 50/5700 loss 8.060246 loss_att 10.519144 loss_ctc 10.469112 loss_rnnt 7.183187 hw_loss 0.120183 lr 0.00029189 rank 4
2023-03-01 06:33:10,629 DEBUG TRAIN Batch 50/5700 loss 7.523179 loss_att 8.816364 loss_ctc 13.438974 loss_rnnt 6.351038 hw_loss 0.233872 lr 0.00029188 rank 6
2023-03-01 06:33:10,648 DEBUG TRAIN Batch 50/5700 loss 4.307371 loss_att 6.553447 loss_ctc 8.106474 loss_rnnt 3.329271 hw_loss 0.041883 lr 0.00029188 rank 3
2023-03-01 06:33:10,654 DEBUG TRAIN Batch 50/5700 loss 3.181684 loss_att 5.037902 loss_ctc 3.773682 loss_rnnt 2.629537 hw_loss 0.191196 lr 0.00029189 rank 1
2023-03-01 06:33:49,482 DEBUG TRAIN Batch 50/5800 loss 5.891940 loss_att 8.950794 loss_ctc 9.986681 loss_rnnt 4.628073 hw_loss 0.198995 lr 0.00029187 rank 3
2023-03-01 06:33:49,482 DEBUG TRAIN Batch 50/5800 loss 7.088830 loss_att 9.464777 loss_ctc 13.586439 loss_rnnt 5.613095 hw_loss 0.251619 lr 0.00029186 rank 7
2023-03-01 06:33:49,484 DEBUG TRAIN Batch 50/5800 loss 2.005779 loss_att 4.528803 loss_ctc 4.619328 loss_rnnt 1.008291 hw_loss 0.270768 lr 0.00029187 rank 5
2023-03-01 06:33:49,485 DEBUG TRAIN Batch 50/5800 loss 5.026444 loss_att 9.995670 loss_ctc 14.532607 loss_rnnt 2.706855 hw_loss 0.109230 lr 0.00029188 rank 0
2023-03-01 06:33:49,485 DEBUG TRAIN Batch 50/5800 loss 4.245346 loss_att 5.480003 loss_ctc 7.941226 loss_rnnt 3.410271 hw_loss 0.178799 lr 0.00029187 rank 4
2023-03-01 06:33:49,486 DEBUG TRAIN Batch 50/5800 loss 5.091858 loss_att 9.473955 loss_ctc 10.103848 loss_rnnt 3.443681 hw_loss 0.194048 lr 0.00029188 rank 2
2023-03-01 06:33:49,487 DEBUG TRAIN Batch 50/5800 loss 6.253749 loss_att 6.945178 loss_ctc 11.137580 loss_rnnt 5.267362 hw_loss 0.369234 lr 0.00029187 rank 6
2023-03-01 06:33:49,531 DEBUG TRAIN Batch 50/5800 loss 2.489353 loss_att 6.225239 loss_ctc 5.364343 loss_rnnt 1.182553 hw_loss 0.330545 lr 0.00029188 rank 1
2023-03-01 06:34:28,516 DEBUG TRAIN Batch 50/5900 loss 5.051064 loss_att 6.978948 loss_ctc 11.094280 loss_rnnt 3.780655 hw_loss 0.148256 lr 0.00029187 rank 2
2023-03-01 06:34:28,519 DEBUG TRAIN Batch 50/5900 loss 2.920228 loss_att 5.622595 loss_ctc 8.767154 loss_rnnt 1.460643 hw_loss 0.261603 lr 0.00029186 rank 1
2023-03-01 06:34:28,522 DEBUG TRAIN Batch 50/5900 loss 5.203437 loss_att 8.404350 loss_ctc 8.905093 loss_rnnt 3.922842 hw_loss 0.275360 lr 0.00029187 rank 0
2023-03-01 06:34:28,523 DEBUG TRAIN Batch 50/5900 loss 5.678706 loss_att 9.024226 loss_ctc 9.038157 loss_rnnt 4.439219 hw_loss 0.229607 lr 0.00029186 rank 5
2023-03-01 06:34:28,524 DEBUG TRAIN Batch 50/5900 loss 4.446764 loss_att 6.723098 loss_ctc 9.478312 loss_rnnt 3.161473 hw_loss 0.298409 lr 0.00029186 rank 4
2023-03-01 06:34:28,525 DEBUG TRAIN Batch 50/5900 loss 12.852679 loss_att 16.216295 loss_ctc 19.607651 loss_rnnt 11.153814 hw_loss 0.235275 lr 0.00029185 rank 7
2023-03-01 06:34:28,526 DEBUG TRAIN Batch 50/5900 loss 3.265342 loss_att 7.578056 loss_ctc 6.899619 loss_rnnt 1.752805 hw_loss 0.310169 lr 0.00029186 rank 3
2023-03-01 06:34:28,527 DEBUG TRAIN Batch 50/5900 loss 7.842023 loss_att 10.704273 loss_ctc 13.215996 loss_rnnt 6.397378 hw_loss 0.291874 lr 0.00029186 rank 6
2023-03-01 06:35:07,749 DEBUG TRAIN Batch 50/6000 loss 4.280509 loss_att 6.906944 loss_ctc 7.318709 loss_rnnt 3.211799 hw_loss 0.259367 lr 0.00029185 rank 2
2023-03-01 06:35:07,750 DEBUG TRAIN Batch 50/6000 loss 5.589243 loss_att 8.222627 loss_ctc 7.309443 loss_rnnt 4.686165 hw_loss 0.275704 lr 0.00029185 rank 0
2023-03-01 06:35:07,751 DEBUG TRAIN Batch 50/6000 loss 6.432026 loss_att 9.878322 loss_ctc 12.393080 loss_rnnt 4.809931 hw_loss 0.258804 lr 0.00029184 rank 3
2023-03-01 06:35:07,752 DEBUG TRAIN Batch 50/6000 loss 5.755397 loss_att 8.238805 loss_ctc 9.879807 loss_rnnt 4.621401 hw_loss 0.163861 lr 0.00029184 rank 7
2023-03-01 06:35:07,754 DEBUG TRAIN Batch 50/6000 loss 15.491440 loss_att 18.840219 loss_ctc 22.051987 loss_rnnt 13.895756 hw_loss 0.095977 lr 0.00029185 rank 1
2023-03-01 06:35:07,756 DEBUG TRAIN Batch 50/6000 loss 5.924112 loss_att 8.120853 loss_ctc 11.810882 loss_rnnt 4.451800 hw_loss 0.465114 lr 0.00029185 rank 6
2023-03-01 06:35:07,757 DEBUG TRAIN Batch 50/6000 loss 6.731115 loss_att 9.996137 loss_ctc 11.039627 loss_rnnt 5.417303 hw_loss 0.161885 lr 0.00029185 rank 4
2023-03-01 06:35:07,762 DEBUG TRAIN Batch 50/6000 loss 3.857066 loss_att 6.379527 loss_ctc 5.394381 loss_rnnt 2.992885 hw_loss 0.290089 lr 0.00029185 rank 5
2023-03-01 06:36:14,255 DEBUG TRAIN Batch 50/6100 loss 6.954865 loss_att 7.322713 loss_ctc 9.394801 loss_rnnt 6.408384 hw_loss 0.276724 lr 0.00029183 rank 6
2023-03-01 06:36:14,265 DEBUG TRAIN Batch 50/6100 loss 2.417196 loss_att 5.247415 loss_ctc 3.474256 loss_rnnt 1.543799 hw_loss 0.312023 lr 0.00029183 rank 7
2023-03-01 06:36:14,270 DEBUG TRAIN Batch 50/6100 loss 5.469921 loss_att 9.796428 loss_ctc 14.544906 loss_rnnt 3.238041 hw_loss 0.293589 lr 0.00029184 rank 4
2023-03-01 06:36:14,271 DEBUG TRAIN Batch 50/6100 loss 9.473093 loss_att 12.353481 loss_ctc 16.200806 loss_rnnt 7.936163 hw_loss 0.119668 lr 0.00029184 rank 0
2023-03-01 06:36:14,274 DEBUG TRAIN Batch 50/6100 loss 5.457587 loss_att 9.791849 loss_ctc 9.642393 loss_rnnt 3.898684 hw_loss 0.251394 lr 0.00029184 rank 1
2023-03-01 06:36:14,275 DEBUG TRAIN Batch 50/6100 loss 6.480170 loss_att 9.376307 loss_ctc 13.471415 loss_rnnt 4.896571 hw_loss 0.135386 lr 0.00029184 rank 2
2023-03-01 06:36:14,275 DEBUG TRAIN Batch 50/6100 loss 4.975017 loss_att 7.131302 loss_ctc 7.612532 loss_rnnt 4.120054 hw_loss 0.135069 lr 0.00029183 rank 3
2023-03-01 06:36:14,294 DEBUG TRAIN Batch 50/6100 loss 3.786540 loss_att 5.858861 loss_ctc 9.850952 loss_rnnt 2.426313 hw_loss 0.257203 lr 0.00029184 rank 5
2023-03-01 06:36:53,430 DEBUG TRAIN Batch 50/6200 loss 6.863581 loss_att 9.041065 loss_ctc 11.039465 loss_rnnt 5.746616 hw_loss 0.233782 lr 0.00029182 rank 6
2023-03-01 06:36:53,441 DEBUG TRAIN Batch 50/6200 loss 5.031850 loss_att 7.343106 loss_ctc 7.273150 loss_rnnt 4.049242 hw_loss 0.415344 lr 0.00029183 rank 0
2023-03-01 06:36:53,440 DEBUG TRAIN Batch 50/6200 loss 7.956924 loss_att 9.818729 loss_ctc 12.977855 loss_rnnt 6.828238 hw_loss 0.162876 lr 0.00029182 rank 4
2023-03-01 06:36:53,441 DEBUG TRAIN Batch 50/6200 loss 9.418803 loss_att 9.027219 loss_ctc 12.478624 loss_rnnt 9.003928 hw_loss 0.159778 lr 0.00029183 rank 1
2023-03-01 06:36:53,442 DEBUG TRAIN Batch 50/6200 loss 6.327163 loss_att 7.752700 loss_ctc 9.779820 loss_rnnt 5.393705 hw_loss 0.352492 lr 0.00029181 rank 7
2023-03-01 06:36:53,443 DEBUG TRAIN Batch 50/6200 loss 9.814290 loss_att 10.142282 loss_ctc 14.259243 loss_rnnt 9.077509 hw_loss 0.147229 lr 0.00029182 rank 3
2023-03-01 06:36:53,447 DEBUG TRAIN Batch 50/6200 loss 13.241093 loss_att 16.440472 loss_ctc 29.072645 loss_rnnt 10.389750 hw_loss 0.188611 lr 0.00029183 rank 2
2023-03-01 06:36:53,451 DEBUG TRAIN Batch 50/6200 loss 4.595666 loss_att 6.384470 loss_ctc 7.933105 loss_rnnt 3.665105 hw_loss 0.239642 lr 0.00029182 rank 5
2023-03-01 06:37:32,524 DEBUG TRAIN Batch 50/6300 loss 8.152524 loss_att 10.803310 loss_ctc 13.295871 loss_rnnt 6.844049 hw_loss 0.173509 lr 0.00029181 rank 3
2023-03-01 06:37:32,533 DEBUG TRAIN Batch 50/6300 loss 6.334374 loss_att 6.691269 loss_ctc 10.346846 loss_rnnt 5.586863 hw_loss 0.264631 lr 0.00029181 rank 1
2023-03-01 06:37:32,535 DEBUG TRAIN Batch 50/6300 loss 5.032228 loss_att 8.706458 loss_ctc 11.188141 loss_rnnt 3.373003 hw_loss 0.194234 lr 0.00029182 rank 0
2023-03-01 06:37:32,534 DEBUG TRAIN Batch 50/6300 loss 4.468977 loss_att 5.766425 loss_ctc 6.517599 loss_rnnt 3.779565 hw_loss 0.293950 lr 0.00029181 rank 5
2023-03-01 06:37:32,535 DEBUG TRAIN Batch 50/6300 loss 9.371039 loss_att 11.957417 loss_ctc 14.218739 loss_rnnt 8.069056 hw_loss 0.259402 lr 0.00029181 rank 4
2023-03-01 06:37:32,536 DEBUG TRAIN Batch 50/6300 loss 7.426673 loss_att 8.213625 loss_ctc 12.594994 loss_rnnt 6.397565 hw_loss 0.342391 lr 0.00029180 rank 7
2023-03-01 06:37:32,547 DEBUG TRAIN Batch 50/6300 loss 3.019436 loss_att 4.832299 loss_ctc 4.707321 loss_rnnt 2.263644 hw_loss 0.315317 lr 0.00029181 rank 6
2023-03-01 06:37:32,586 DEBUG TRAIN Batch 50/6300 loss 3.530986 loss_att 4.967964 loss_ctc 5.530851 loss_rnnt 2.788844 hw_loss 0.352683 lr 0.00029182 rank 2
2023-03-01 06:38:39,112 DEBUG TRAIN Batch 50/6400 loss 2.084072 loss_att 4.166957 loss_ctc 4.223310 loss_rnnt 1.308986 hw_loss 0.137394 lr 0.00029180 rank 2
2023-03-01 06:38:39,113 DEBUG TRAIN Batch 50/6400 loss 5.695222 loss_att 12.880737 loss_ctc 11.625903 loss_rnnt 3.286834 hw_loss 0.338489 lr 0.00029180 rank 1
2023-03-01 06:38:39,116 DEBUG TRAIN Batch 50/6400 loss 8.479777 loss_att 10.935690 loss_ctc 14.652905 loss_rnnt 6.974092 hw_loss 0.358910 lr 0.00029180 rank 4
2023-03-01 06:38:39,120 DEBUG TRAIN Batch 50/6400 loss 6.623259 loss_att 9.167104 loss_ctc 9.521936 loss_rnnt 5.618178 hw_loss 0.205915 lr 0.00029180 rank 0
2023-03-01 06:38:39,123 DEBUG TRAIN Batch 50/6400 loss 9.806784 loss_att 11.172775 loss_ctc 21.801098 loss_rnnt 7.838137 hw_loss 0.180388 lr 0.00029179 rank 7
2023-03-01 06:38:39,129 DEBUG TRAIN Batch 50/6400 loss 4.782341 loss_att 7.293386 loss_ctc 6.027491 loss_rnnt 3.978189 hw_loss 0.254856 lr 0.00029180 rank 5
2023-03-01 06:38:39,131 DEBUG TRAIN Batch 50/6400 loss 11.143749 loss_att 11.815873 loss_ctc 18.611080 loss_rnnt 9.854188 hw_loss 0.299049 lr 0.00029180 rank 6
2023-03-01 06:38:39,177 DEBUG TRAIN Batch 50/6400 loss 13.217582 loss_att 18.380657 loss_ctc 31.159344 loss_rnnt 9.603952 hw_loss 0.353958 lr 0.00029179 rank 3
2023-03-01 06:39:18,111 DEBUG TRAIN Batch 50/6500 loss 1.271886 loss_att 4.304250 loss_ctc 1.730326 loss_rnnt 0.432384 hw_loss 0.322320 lr 0.00029179 rank 5
2023-03-01 06:39:18,119 DEBUG TRAIN Batch 50/6500 loss 3.776947 loss_att 6.427549 loss_ctc 10.463524 loss_rnnt 2.235711 hw_loss 0.224199 lr 0.00029178 rank 7
2023-03-01 06:39:18,120 DEBUG TRAIN Batch 50/6500 loss 8.949448 loss_att 12.469617 loss_ctc 15.480963 loss_rnnt 7.213674 hw_loss 0.301633 lr 0.00029179 rank 1
2023-03-01 06:39:18,121 DEBUG TRAIN Batch 50/6500 loss 5.107295 loss_att 7.526647 loss_ctc 8.421232 loss_rnnt 4.011856 hw_loss 0.318206 lr 0.00029179 rank 4
2023-03-01 06:39:18,124 DEBUG TRAIN Batch 50/6500 loss 2.623610 loss_att 4.704377 loss_ctc 4.672073 loss_rnnt 1.851364 hw_loss 0.155558 lr 0.00029179 rank 0
2023-03-01 06:39:18,125 DEBUG TRAIN Batch 50/6500 loss 7.018775 loss_att 13.028665 loss_ctc 11.185719 loss_rnnt 5.084974 hw_loss 0.330431 lr 0.00029179 rank 2
2023-03-01 06:39:18,130 DEBUG TRAIN Batch 50/6500 loss 3.573971 loss_att 5.912983 loss_ctc 7.050844 loss_rnnt 2.513917 hw_loss 0.241253 lr 0.00029178 rank 3
2023-03-01 06:39:18,177 DEBUG TRAIN Batch 50/6500 loss 7.520661 loss_att 10.026967 loss_ctc 11.556551 loss_rnnt 6.370370 hw_loss 0.207958 lr 0.00029179 rank 6
2023-03-01 06:39:56,918 DEBUG TRAIN Batch 50/6600 loss 6.645868 loss_att 9.808169 loss_ctc 10.670650 loss_rnnt 5.334339 hw_loss 0.267057 lr 0.00029177 rank 3
2023-03-01 06:39:56,925 DEBUG TRAIN Batch 50/6600 loss 6.568696 loss_att 8.543903 loss_ctc 11.641002 loss_rnnt 5.446275 hw_loss 0.095758 lr 0.00029177 rank 5
2023-03-01 06:39:56,935 DEBUG TRAIN Batch 50/6600 loss 7.284434 loss_att 11.782991 loss_ctc 16.270515 loss_rnnt 5.121457 hw_loss 0.122101 lr 0.00029178 rank 2
2023-03-01 06:39:56,935 DEBUG TRAIN Batch 50/6600 loss 4.615768 loss_att 8.272057 loss_ctc 9.973227 loss_rnnt 3.087698 hw_loss 0.154658 lr 0.00029178 rank 0
2023-03-01 06:39:56,938 DEBUG TRAIN Batch 50/6600 loss 5.899128 loss_att 7.662414 loss_ctc 8.834273 loss_rnnt 5.058393 hw_loss 0.181361 lr 0.00029177 rank 4
2023-03-01 06:39:56,938 DEBUG TRAIN Batch 50/6600 loss 7.566330 loss_att 11.278567 loss_ctc 11.661585 loss_rnnt 6.215374 hw_loss 0.117140 lr 0.00029176 rank 7
2023-03-01 06:39:56,941 DEBUG TRAIN Batch 50/6600 loss 1.985415 loss_att 3.659299 loss_ctc 3.398207 loss_rnnt 1.400275 hw_loss 0.116233 lr 0.00029177 rank 6
2023-03-01 06:39:56,943 DEBUG TRAIN Batch 50/6600 loss 11.381662 loss_att 16.320858 loss_ctc 18.029753 loss_rnnt 9.366611 hw_loss 0.263998 lr 0.00029178 rank 1
2023-03-01 06:40:35,651 DEBUG TRAIN Batch 50/6700 loss 12.678734 loss_att 15.231237 loss_ctc 17.916595 loss_rnnt 11.362038 hw_loss 0.202151 lr 0.00029176 rank 3
2023-03-01 06:40:35,655 DEBUG TRAIN Batch 50/6700 loss 10.135968 loss_att 13.444483 loss_ctc 17.125422 loss_rnnt 8.479500 hw_loss 0.117819 lr 0.00029176 rank 6
2023-03-01 06:40:35,658 DEBUG TRAIN Batch 50/6700 loss 5.436885 loss_att 8.868677 loss_ctc 12.048328 loss_rnnt 3.712286 hw_loss 0.293842 lr 0.00029176 rank 4
2023-03-01 06:40:35,670 DEBUG TRAIN Batch 50/6700 loss 5.914575 loss_att 8.698427 loss_ctc 11.065598 loss_rnnt 4.597032 hw_loss 0.138692 lr 0.00029177 rank 0
2023-03-01 06:40:35,671 DEBUG TRAIN Batch 50/6700 loss 9.025519 loss_att 11.106322 loss_ctc 12.425419 loss_rnnt 8.042263 hw_loss 0.213329 lr 0.00029175 rank 7
2023-03-01 06:40:35,673 DEBUG TRAIN Batch 50/6700 loss 3.394696 loss_att 5.715498 loss_ctc 6.577416 loss_rnnt 2.347646 hw_loss 0.297238 lr 0.00029177 rank 2
2023-03-01 06:40:35,681 DEBUG TRAIN Batch 50/6700 loss 4.876422 loss_att 7.704538 loss_ctc 5.997489 loss_rnnt 4.041316 hw_loss 0.225014 lr 0.00029177 rank 1
2023-03-01 06:40:35,687 DEBUG TRAIN Batch 50/6700 loss 9.198715 loss_att 12.757383 loss_ctc 16.144377 loss_rnnt 7.495101 hw_loss 0.123362 lr 0.00029176 rank 5
2023-03-01 06:41:41,834 DEBUG TRAIN Batch 50/6800 loss 3.530959 loss_att 6.743465 loss_ctc 7.639495 loss_rnnt 2.232023 hw_loss 0.203681 lr 0.00029175 rank 5
2023-03-01 06:41:41,839 DEBUG TRAIN Batch 50/6800 loss 8.973487 loss_att 10.712507 loss_ctc 13.383320 loss_rnnt 7.928099 hw_loss 0.205512 lr 0.00029175 rank 1
2023-03-01 06:41:41,839 DEBUG TRAIN Batch 50/6800 loss 8.991529 loss_att 12.059317 loss_ctc 12.990220 loss_rnnt 7.712622 hw_loss 0.247854 lr 0.00029174 rank 7
2023-03-01 06:41:41,840 DEBUG TRAIN Batch 50/6800 loss 9.121078 loss_att 11.921035 loss_ctc 15.746754 loss_rnnt 7.558812 hw_loss 0.222845 lr 0.00029175 rank 6
2023-03-01 06:41:41,840 DEBUG TRAIN Batch 50/6800 loss 10.302252 loss_att 12.649469 loss_ctc 13.897462 loss_rnnt 9.238745 hw_loss 0.215066 lr 0.00029175 rank 0
2023-03-01 06:41:41,849 DEBUG TRAIN Batch 50/6800 loss 4.136771 loss_att 7.553647 loss_ctc 7.227156 loss_rnnt 2.978641 hw_loss 0.117567 lr 0.00029174 rank 3
2023-03-01 06:41:41,853 DEBUG TRAIN Batch 50/6800 loss 2.622157 loss_att 5.126136 loss_ctc 4.084421 loss_rnnt 1.780108 hw_loss 0.274283 lr 0.00029175 rank 4
2023-03-01 06:41:41,869 DEBUG TRAIN Batch 50/6800 loss 8.825536 loss_att 12.882868 loss_ctc 13.516462 loss_rnnt 7.239336 hw_loss 0.279893 lr 0.00029175 rank 2
2023-03-01 06:42:20,726 DEBUG TRAIN Batch 50/6900 loss 4.556876 loss_att 5.442326 loss_ctc 8.589611 loss_rnnt 3.670102 hw_loss 0.322474 lr 0.00029173 rank 7
2023-03-01 06:42:20,728 DEBUG TRAIN Batch 50/6900 loss 9.317512 loss_att 12.860288 loss_ctc 14.859739 loss_rnnt 7.746479 hw_loss 0.231589 lr 0.00029174 rank 4
2023-03-01 06:42:20,730 DEBUG TRAIN Batch 50/6900 loss 1.435201 loss_att 4.029311 loss_ctc 3.595074 loss_rnnt 0.525034 hw_loss 0.193803 lr 0.00029174 rank 0
2023-03-01 06:42:20,731 DEBUG TRAIN Batch 50/6900 loss 9.682903 loss_att 12.021478 loss_ctc 14.006960 loss_rnnt 8.519605 hw_loss 0.223206 lr 0.00029174 rank 5
2023-03-01 06:42:20,734 DEBUG TRAIN Batch 50/6900 loss 4.762517 loss_att 6.521149 loss_ctc 8.388453 loss_rnnt 3.798853 hw_loss 0.240900 lr 0.00029174 rank 2
2023-03-01 06:42:20,737 DEBUG TRAIN Batch 50/6900 loss 10.968742 loss_att 12.423094 loss_ctc 15.240417 loss_rnnt 10.004977 hw_loss 0.193759 lr 0.00029174 rank 1
2023-03-01 06:42:20,749 DEBUG TRAIN Batch 50/6900 loss 5.784228 loss_att 6.821301 loss_ctc 8.694350 loss_rnnt 5.083860 hw_loss 0.196759 lr 0.00029173 rank 3
2023-03-01 06:42:20,764 DEBUG TRAIN Batch 50/6900 loss 1.127741 loss_att 3.083939 loss_ctc 2.115606 loss_rnnt 0.433279 hw_loss 0.321577 lr 0.00029174 rank 6
2023-03-01 06:42:59,779 DEBUG TRAIN Batch 50/7000 loss 4.003190 loss_att 6.149217 loss_ctc 6.312036 loss_rnnt 3.109715 hw_loss 0.293294 lr 0.00029172 rank 6
2023-03-01 06:42:59,788 DEBUG TRAIN Batch 50/7000 loss 3.503678 loss_att 4.542636 loss_ctc 5.019720 loss_rnnt 3.012880 hw_loss 0.151626 lr 0.00029173 rank 2
2023-03-01 06:42:59,789 DEBUG TRAIN Batch 50/7000 loss 7.126912 loss_att 6.970937 loss_ctc 11.451880 loss_rnnt 6.430633 hw_loss 0.282771 lr 0.00029173 rank 0
2023-03-01 06:42:59,792 DEBUG TRAIN Batch 50/7000 loss 6.997753 loss_att 9.975286 loss_ctc 6.865619 loss_rnnt 6.336430 hw_loss 0.156441 lr 0.00029171 rank 7
2023-03-01 06:42:59,794 DEBUG TRAIN Batch 50/7000 loss 5.691733 loss_att 8.988202 loss_ctc 10.339052 loss_rnnt 4.279474 hw_loss 0.249978 lr 0.00029172 rank 5
2023-03-01 06:42:59,797 DEBUG TRAIN Batch 50/7000 loss 6.481848 loss_att 8.052067 loss_ctc 11.400129 loss_rnnt 5.511584 hw_loss 0.000843 lr 0.00029173 rank 1
2023-03-01 06:42:59,802 DEBUG TRAIN Batch 50/7000 loss 11.989744 loss_att 15.936127 loss_ctc 14.706619 loss_rnnt 10.766994 hw_loss 0.133545 lr 0.00029172 rank 4
2023-03-01 06:42:59,819 DEBUG TRAIN Batch 50/7000 loss 2.687809 loss_att 6.427151 loss_ctc 5.599599 loss_rnnt 1.467913 hw_loss 0.157102 lr 0.00029172 rank 3
2023-03-01 06:44:05,983 DEBUG TRAIN Batch 50/7100 loss 8.059029 loss_att 7.851156 loss_ctc 11.471331 loss_rnnt 7.510458 hw_loss 0.253446 lr 0.00029171 rank 4
2023-03-01 06:44:05,984 DEBUG TRAIN Batch 50/7100 loss 3.513954 loss_att 7.090350 loss_ctc 5.651434 loss_rnnt 2.470603 hw_loss 0.080763 lr 0.00029172 rank 1
2023-03-01 06:44:05,984 DEBUG TRAIN Batch 50/7100 loss 8.945774 loss_att 10.721998 loss_ctc 14.289778 loss_rnnt 7.816657 hw_loss 0.115009 lr 0.00029171 rank 5
2023-03-01 06:44:05,985 DEBUG TRAIN Batch 50/7100 loss 1.961641 loss_att 4.147886 loss_ctc 3.443248 loss_rnnt 1.129911 hw_loss 0.369249 lr 0.00029172 rank 2
2023-03-01 06:44:05,985 DEBUG TRAIN Batch 50/7100 loss 7.866282 loss_att 10.154746 loss_ctc 13.667880 loss_rnnt 6.578976 hw_loss 0.105126 lr 0.00029170 rank 7
2023-03-01 06:44:05,986 DEBUG TRAIN Batch 50/7100 loss 2.515216 loss_att 5.126182 loss_ctc 2.872440 loss_rnnt 1.759517 hw_loss 0.348518 lr 0.00029172 rank 0
2023-03-01 06:44:05,990 DEBUG TRAIN Batch 50/7100 loss 12.577208 loss_att 15.109302 loss_ctc 19.362843 loss_rnnt 11.091825 hw_loss 0.139148 lr 0.00029171 rank 3
2023-03-01 06:44:06,028 DEBUG TRAIN Batch 50/7100 loss 4.174824 loss_att 7.934903 loss_ctc 8.876305 loss_rnnt 2.711602 hw_loss 0.158141 lr 0.00029171 rank 6
2023-03-01 06:44:45,076 DEBUG TRAIN Batch 50/7200 loss 2.491525 loss_att 5.150506 loss_ctc 6.868222 loss_rnnt 1.194277 hw_loss 0.341046 lr 0.00029170 rank 5
2023-03-01 06:44:45,080 DEBUG TRAIN Batch 50/7200 loss 2.090429 loss_att 5.306413 loss_ctc 4.815223 loss_rnnt 1.014634 hw_loss 0.129925 lr 0.00029169 rank 3
2023-03-01 06:44:45,082 DEBUG TRAIN Batch 50/7200 loss 4.870541 loss_att 7.526888 loss_ctc 11.432188 loss_rnnt 3.348514 hw_loss 0.217258 lr 0.00029170 rank 4
2023-03-01 06:44:45,088 DEBUG TRAIN Batch 50/7200 loss 4.929671 loss_att 6.393825 loss_ctc 4.802065 loss_rnnt 4.570778 hw_loss 0.155769 lr 0.00029169 rank 7
2023-03-01 06:44:45,090 DEBUG TRAIN Batch 50/7200 loss 2.276325 loss_att 4.916496 loss_ctc 5.520009 loss_rnnt 1.262753 hw_loss 0.099461 lr 0.00029170 rank 0
2023-03-01 06:44:45,093 DEBUG TRAIN Batch 50/7200 loss 8.920062 loss_att 10.495380 loss_ctc 11.687830 loss_rnnt 8.126629 hw_loss 0.205000 lr 0.00029170 rank 1
2023-03-01 06:44:45,093 DEBUG TRAIN Batch 50/7200 loss 11.960668 loss_att 12.913721 loss_ctc 15.076391 loss_rnnt 11.226134 hw_loss 0.240925 lr 0.00029170 rank 2
2023-03-01 06:44:45,099 DEBUG TRAIN Batch 50/7200 loss 6.767030 loss_att 10.316820 loss_ctc 11.504362 loss_rnnt 5.362653 hw_loss 0.117703 lr 0.00029170 rank 6
2023-03-01 06:45:23,393 DEBUG TRAIN Batch 50/7300 loss 5.351401 loss_att 8.881187 loss_ctc 10.651368 loss_rnnt 3.774110 hw_loss 0.308758 lr 0.00029168 rank 7
2023-03-01 06:45:23,400 DEBUG TRAIN Batch 50/7300 loss 4.885582 loss_att 7.691912 loss_ctc 8.954120 loss_rnnt 3.600417 hw_loss 0.340178 lr 0.00029169 rank 4
2023-03-01 06:45:23,404 DEBUG TRAIN Batch 50/7300 loss 7.518476 loss_att 10.659210 loss_ctc 11.722601 loss_rnnt 6.194008 hw_loss 0.254570 lr 0.00029169 rank 1
2023-03-01 06:45:23,403 DEBUG TRAIN Batch 50/7300 loss 11.523661 loss_att 12.510746 loss_ctc 16.381075 loss_rnnt 10.578798 hw_loss 0.187107 lr 0.00029168 rank 3
2023-03-01 06:45:23,404 DEBUG TRAIN Batch 50/7300 loss 5.645829 loss_att 9.287280 loss_ctc 12.564052 loss_rnnt 3.883450 hw_loss 0.209360 lr 0.00029169 rank 5
2023-03-01 06:45:23,407 DEBUG TRAIN Batch 50/7300 loss 10.810674 loss_att 13.635436 loss_ctc 14.926584 loss_rnnt 9.517620 hw_loss 0.336212 lr 0.00029169 rank 0
2023-03-01 06:45:23,418 DEBUG TRAIN Batch 50/7300 loss 5.068100 loss_att 7.388460 loss_ctc 9.272053 loss_rnnt 3.919611 hw_loss 0.232294 lr 0.00029169 rank 2
2023-03-01 06:45:23,456 DEBUG TRAIN Batch 50/7300 loss 4.269845 loss_att 7.887917 loss_ctc 9.655924 loss_rnnt 2.724743 hw_loss 0.193770 lr 0.00029169 rank 6
2023-03-01 06:46:01,913 DEBUG TRAIN Batch 50/7400 loss 5.449074 loss_att 9.387074 loss_ctc 12.054960 loss_rnnt 3.653479 hw_loss 0.238520 lr 0.00029167 rank 6
2023-03-01 06:46:01,922 DEBUG TRAIN Batch 50/7400 loss 2.048322 loss_att 4.519317 loss_ctc 3.174084 loss_rnnt 1.290741 hw_loss 0.212402 lr 0.00029168 rank 0
2023-03-01 06:46:01,927 DEBUG TRAIN Batch 50/7400 loss 8.285805 loss_att 10.525766 loss_ctc 12.280468 loss_rnnt 7.187485 hw_loss 0.220699 lr 0.00029167 rank 3
2023-03-01 06:46:01,926 DEBUG TRAIN Batch 50/7400 loss 5.441294 loss_att 7.292601 loss_ctc 6.576560 loss_rnnt 4.748884 hw_loss 0.320212 lr 0.00029166 rank 7
2023-03-01 06:46:01,929 DEBUG TRAIN Batch 50/7400 loss 4.729646 loss_att 8.085405 loss_ctc 8.263510 loss_rnnt 3.432503 hw_loss 0.290266 lr 0.00029167 rank 5
2023-03-01 06:46:01,933 DEBUG TRAIN Batch 50/7400 loss 11.161955 loss_att 16.060635 loss_ctc 20.892799 loss_rnnt 8.884118 hw_loss 0.001225 lr 0.00029168 rank 2
2023-03-01 06:46:01,938 DEBUG TRAIN Batch 50/7400 loss 5.430665 loss_att 7.607260 loss_ctc 10.764912 loss_rnnt 4.222218 hw_loss 0.116053 lr 0.00029168 rank 1
2023-03-01 06:46:01,953 DEBUG TRAIN Batch 50/7400 loss 11.479147 loss_att 15.287304 loss_ctc 23.877125 loss_rnnt 8.924740 hw_loss 0.261959 lr 0.00029167 rank 4
2023-03-01 06:47:08,092 DEBUG TRAIN Batch 50/7500 loss 4.405050 loss_att 5.907201 loss_ctc 5.522480 loss_rnnt 3.802086 hw_loss 0.287894 lr 0.00029166 rank 5
2023-03-01 06:47:08,100 DEBUG TRAIN Batch 50/7500 loss 9.726414 loss_att 14.195446 loss_ctc 18.609962 loss_rnnt 7.495206 hw_loss 0.286739 lr 0.00029167 rank 1
2023-03-01 06:47:08,103 DEBUG TRAIN Batch 50/7500 loss 2.290591 loss_att 3.837399 loss_ctc 3.683573 loss_rnnt 1.676487 hw_loss 0.223145 lr 0.00029167 rank 2
2023-03-01 06:47:08,103 DEBUG TRAIN Batch 50/7500 loss 11.354817 loss_att 13.938555 loss_ctc 17.004194 loss_rnnt 9.954086 hw_loss 0.245125 lr 0.00029167 rank 0
2023-03-01 06:47:08,106 DEBUG TRAIN Batch 50/7500 loss 11.643453 loss_att 14.409366 loss_ctc 18.713440 loss_rnnt 10.060264 hw_loss 0.163768 lr 0.00029166 rank 3
2023-03-01 06:47:08,108 DEBUG TRAIN Batch 50/7500 loss 7.337174 loss_att 11.693821 loss_ctc 19.125549 loss_rnnt 4.768132 hw_loss 0.236118 lr 0.00029165 rank 7
2023-03-01 06:47:08,115 DEBUG TRAIN Batch 50/7500 loss 6.916281 loss_att 10.109199 loss_ctc 10.367732 loss_rnnt 5.770237 hw_loss 0.088624 lr 0.00029166 rank 6
2023-03-01 06:47:08,156 DEBUG TRAIN Batch 50/7500 loss 5.917905 loss_att 9.070839 loss_ctc 9.964823 loss_rnnt 4.648346 hw_loss 0.186343 lr 0.00029166 rank 4
2023-03-01 06:47:47,358 DEBUG TRAIN Batch 50/7600 loss 4.542360 loss_att 6.579655 loss_ctc 4.745401 loss_rnnt 3.944468 hw_loss 0.306301 lr 0.00029165 rank 1
2023-03-01 06:47:47,370 DEBUG TRAIN Batch 50/7600 loss 9.166334 loss_att 9.562281 loss_ctc 16.101917 loss_rnnt 7.992527 hw_loss 0.318511 lr 0.00029164 rank 3
2023-03-01 06:47:47,376 DEBUG TRAIN Batch 50/7600 loss 3.937193 loss_att 6.696904 loss_ctc 5.946859 loss_rnnt 2.979669 hw_loss 0.258049 lr 0.00029165 rank 4
2023-03-01 06:47:47,376 DEBUG TRAIN Batch 50/7600 loss 7.475496 loss_att 8.322004 loss_ctc 11.064792 loss_rnnt 6.638107 hw_loss 0.355340 lr 0.00029165 rank 0
2023-03-01 06:47:47,376 DEBUG TRAIN Batch 50/7600 loss 4.051153 loss_att 10.699089 loss_ctc 7.782001 loss_rnnt 2.041552 hw_loss 0.342315 lr 0.00029164 rank 7
2023-03-01 06:47:47,378 DEBUG TRAIN Batch 50/7600 loss 7.127643 loss_att 7.595021 loss_ctc 11.630447 loss_rnnt 6.323649 hw_loss 0.206519 lr 0.00029165 rank 5
2023-03-01 06:47:47,381 DEBUG TRAIN Batch 50/7600 loss 5.914703 loss_att 7.368030 loss_ctc 11.278967 loss_rnnt 4.754160 hw_loss 0.289954 lr 0.00029166 rank 2
2023-03-01 06:47:47,389 DEBUG TRAIN Batch 50/7600 loss 11.534470 loss_att 13.666769 loss_ctc 18.532492 loss_rnnt 10.123273 hw_loss 0.096873 lr 0.00029165 rank 6
2023-03-01 06:48:26,003 DEBUG TRAIN Batch 50/7700 loss 7.664823 loss_att 8.908188 loss_ctc 13.526034 loss_rnnt 6.460899 hw_loss 0.325792 lr 0.00029164 rank 4
2023-03-01 06:48:26,015 DEBUG TRAIN Batch 50/7700 loss 3.236960 loss_att 8.723988 loss_ctc 6.871614 loss_rnnt 1.567108 hw_loss 0.164674 lr 0.00029163 rank 7
2023-03-01 06:48:26,016 DEBUG TRAIN Batch 50/7700 loss 8.798199 loss_att 12.306355 loss_ctc 17.993452 loss_rnnt 6.753020 hw_loss 0.220340 lr 0.00029164 rank 5
2023-03-01 06:48:26,018 DEBUG TRAIN Batch 50/7700 loss 8.415121 loss_att 11.174225 loss_ctc 11.566135 loss_rnnt 7.329015 hw_loss 0.214030 lr 0.00029164 rank 0
2023-03-01 06:48:26,018 DEBUG TRAIN Batch 50/7700 loss 3.088928 loss_att 6.795572 loss_ctc 5.508419 loss_rnnt 1.890872 hw_loss 0.251493 lr 0.00029164 rank 2
2023-03-01 06:48:26,023 DEBUG TRAIN Batch 50/7700 loss 5.643229 loss_att 8.602289 loss_ctc 9.354719 loss_rnnt 4.353953 hw_loss 0.379873 lr 0.00029164 rank 1
2023-03-01 06:48:26,024 DEBUG TRAIN Batch 50/7700 loss 8.047030 loss_att 7.898298 loss_ctc 11.406730 loss_rnnt 7.438375 hw_loss 0.357078 lr 0.00029164 rank 6
2023-03-01 06:48:26,023 DEBUG TRAIN Batch 50/7700 loss 12.037929 loss_att 15.631695 loss_ctc 17.012693 loss_rnnt 10.463368 hw_loss 0.360946 lr 0.00029163 rank 3
2023-03-01 06:49:06,241 DEBUG TRAIN Batch 50/7800 loss 15.491642 loss_att 18.142059 loss_ctc 22.249115 loss_rnnt 13.922237 hw_loss 0.259358 lr 0.00029163 rank 2
2023-03-01 06:49:06,246 DEBUG TRAIN Batch 50/7800 loss 10.555094 loss_att 13.387888 loss_ctc 15.957576 loss_rnnt 9.146506 hw_loss 0.228184 lr 0.00029162 rank 6
2023-03-01 06:49:06,247 DEBUG TRAIN Batch 50/7800 loss 4.814660 loss_att 7.042012 loss_ctc 5.401491 loss_rnnt 4.133457 hw_loss 0.295290 lr 0.00029162 rank 5
2023-03-01 06:49:06,256 DEBUG TRAIN Batch 50/7800 loss 9.035623 loss_att 11.252118 loss_ctc 10.453468 loss_rnnt 8.364658 hw_loss 0.072411 lr 0.00029163 rank 1
2023-03-01 06:49:06,258 DEBUG TRAIN Batch 50/7800 loss 9.214093 loss_att 15.169870 loss_ctc 21.810253 loss_rnnt 6.280357 hw_loss 0.118295 lr 0.00029161 rank 7
2023-03-01 06:49:06,261 DEBUG TRAIN Batch 50/7800 loss 5.588959 loss_att 9.765307 loss_ctc 11.973379 loss_rnnt 3.875674 hw_loss 0.050173 lr 0.00029162 rank 3
2023-03-01 06:49:06,268 DEBUG TRAIN Batch 50/7800 loss 6.756296 loss_att 10.718630 loss_ctc 11.928886 loss_rnnt 5.200391 hw_loss 0.138299 lr 0.00029163 rank 0
2023-03-01 06:49:06,312 DEBUG TRAIN Batch 50/7800 loss 3.284279 loss_att 7.737553 loss_ctc 9.010513 loss_rnnt 1.594635 hw_loss 0.066547 lr 0.00029162 rank 4
2023-03-01 06:50:11,530 DEBUG TRAIN Batch 50/7900 loss 1.834985 loss_att 5.227373 loss_ctc 3.495174 loss_rnnt 0.819515 hw_loss 0.216815 lr 0.00029162 rank 0
2023-03-01 06:50:11,530 DEBUG TRAIN Batch 50/7900 loss 5.357668 loss_att 10.659473 loss_ctc 11.362588 loss_rnnt 3.414099 hw_loss 0.154785 lr 0.00029161 rank 5
2023-03-01 06:50:11,544 DEBUG TRAIN Batch 50/7900 loss 9.649170 loss_att 13.564274 loss_ctc 14.543219 loss_rnnt 8.137151 hw_loss 0.143359 lr 0.00029160 rank 7
2023-03-01 06:50:11,546 DEBUG TRAIN Batch 50/7900 loss 8.759460 loss_att 11.149908 loss_ctc 16.542004 loss_rnnt 7.073979 hw_loss 0.318223 lr 0.00029162 rank 1
2023-03-01 06:50:11,547 DEBUG TRAIN Batch 50/7900 loss 10.499120 loss_att 16.936516 loss_ctc 23.400793 loss_rnnt 7.418059 hw_loss 0.137546 lr 0.00029161 rank 3
2023-03-01 06:50:11,547 DEBUG TRAIN Batch 50/7900 loss 7.972532 loss_att 9.423710 loss_ctc 9.916466 loss_rnnt 7.340851 hw_loss 0.154228 lr 0.00029162 rank 2
2023-03-01 06:50:11,551 DEBUG TRAIN Batch 50/7900 loss 3.996094 loss_att 6.428120 loss_ctc 7.029315 loss_rnnt 2.986141 hw_loss 0.223347 lr 0.00029161 rank 6
2023-03-01 06:50:11,594 DEBUG TRAIN Batch 50/7900 loss 2.504911 loss_att 5.691528 loss_ctc 4.264420 loss_rnnt 1.607443 hw_loss 0.047894 lr 0.00029161 rank 4
2023-03-01 06:50:50,108 DEBUG TRAIN Batch 50/8000 loss 4.781294 loss_att 8.079459 loss_ctc 10.599773 loss_rnnt 3.130510 hw_loss 0.403788 lr 0.00029160 rank 4
2023-03-01 06:50:50,118 DEBUG TRAIN Batch 50/8000 loss 6.330736 loss_att 7.875316 loss_ctc 10.628939 loss_rnnt 5.289642 hw_loss 0.298282 lr 0.00029160 rank 0
2023-03-01 06:50:50,119 DEBUG TRAIN Batch 50/8000 loss 9.331246 loss_att 11.155064 loss_ctc 11.761963 loss_rnnt 8.489887 hw_loss 0.285938 lr 0.00029160 rank 5
2023-03-01 06:50:50,120 DEBUG TRAIN Batch 50/8000 loss 4.271203 loss_att 7.155083 loss_ctc 5.835464 loss_rnnt 3.291996 hw_loss 0.363492 lr 0.00029159 rank 7
2023-03-01 06:50:50,120 DEBUG TRAIN Batch 50/8000 loss 5.911588 loss_att 8.053125 loss_ctc 8.976933 loss_rnnt 5.008874 hw_loss 0.123175 lr 0.00029160 rank 1
2023-03-01 06:50:50,123 DEBUG TRAIN Batch 50/8000 loss 5.287821 loss_att 6.989164 loss_ctc 6.627777 loss_rnnt 4.646618 hw_loss 0.229263 lr 0.00029160 rank 3
2023-03-01 06:50:50,135 DEBUG TRAIN Batch 50/8000 loss 6.294802 loss_att 9.851794 loss_ctc 11.699454 loss_rnnt 4.851846 hw_loss 0.020507 lr 0.00029160 rank 6
2023-03-01 06:50:50,147 DEBUG TRAIN Batch 50/8000 loss 2.752218 loss_att 5.827019 loss_ctc 5.450025 loss_rnnt 1.603876 hw_loss 0.325639 lr 0.00029161 rank 2
2023-03-01 06:51:28,933 DEBUG TRAIN Batch 50/8100 loss 3.994676 loss_att 7.046057 loss_ctc 5.891210 loss_rnnt 3.020557 hw_loss 0.208071 lr 0.00029158 rank 3
2023-03-01 06:51:28,938 DEBUG TRAIN Batch 50/8100 loss 6.847554 loss_att 9.936180 loss_ctc 9.925833 loss_rnnt 5.693461 hw_loss 0.236121 lr 0.00029159 rank 1
2023-03-01 06:51:28,941 DEBUG TRAIN Batch 50/8100 loss 4.690416 loss_att 7.934927 loss_ctc 6.906817 loss_rnnt 3.646656 hw_loss 0.186259 lr 0.00029159 rank 5
2023-03-01 06:51:28,941 DEBUG TRAIN Batch 50/8100 loss 6.641427 loss_att 9.960828 loss_ctc 12.055470 loss_rnnt 5.090801 hw_loss 0.309137 lr 0.00029159 rank 4
2023-03-01 06:51:28,946 DEBUG TRAIN Batch 50/8100 loss 7.634811 loss_att 9.323716 loss_ctc 11.378512 loss_rnnt 6.662872 hw_loss 0.253121 lr 0.00029158 rank 7
2023-03-01 06:51:28,950 DEBUG TRAIN Batch 50/8100 loss 3.486572 loss_att 7.362666 loss_ctc 6.696228 loss_rnnt 2.131695 hw_loss 0.284446 lr 0.00029159 rank 0
2023-03-01 06:51:28,954 DEBUG TRAIN Batch 50/8100 loss 6.481399 loss_att 8.453862 loss_ctc 9.317389 loss_rnnt 5.604439 hw_loss 0.195629 lr 0.00029159 rank 6
2023-03-01 06:51:28,998 DEBUG TRAIN Batch 50/8100 loss 3.017778 loss_att 6.708634 loss_ctc 7.009744 loss_rnnt 1.580646 hw_loss 0.312561 lr 0.00029159 rank 2
2023-03-01 06:52:09,170 DEBUG TRAIN Batch 50/8200 loss 6.319958 loss_att 9.800577 loss_ctc 13.163902 loss_rnnt 4.630571 hw_loss 0.151384 lr 0.00029158 rank 0
2023-03-01 06:52:09,172 DEBUG TRAIN Batch 50/8200 loss 8.209637 loss_att 9.733297 loss_ctc 13.835288 loss_rnnt 7.007039 hw_loss 0.277085 lr 0.00029157 rank 7
2023-03-01 06:52:09,175 DEBUG TRAIN Batch 50/8200 loss 11.358019 loss_att 12.412125 loss_ctc 17.748695 loss_rnnt 10.215672 hw_loss 0.148941 lr 0.00029158 rank 4
2023-03-01 06:52:09,180 DEBUG TRAIN Batch 50/8200 loss 4.971529 loss_att 7.844431 loss_ctc 9.611116 loss_rnnt 3.656638 hw_loss 0.228186 lr 0.00029158 rank 2
2023-03-01 06:52:09,180 DEBUG TRAIN Batch 50/8200 loss 7.607059 loss_att 11.438619 loss_ctc 13.254841 loss_rnnt 5.982786 hw_loss 0.196730 lr 0.00029157 rank 6
2023-03-01 06:52:09,181 DEBUG TRAIN Batch 50/8200 loss 8.005327 loss_att 10.834656 loss_ctc 11.801191 loss_rnnt 6.794618 hw_loss 0.260116 lr 0.00029157 rank 5
2023-03-01 06:52:09,182 DEBUG TRAIN Batch 50/8200 loss 3.857656 loss_att 5.363785 loss_ctc 4.752651 loss_rnnt 3.351305 hw_loss 0.160859 lr 0.00029157 rank 3
2023-03-01 06:52:09,188 DEBUG TRAIN Batch 50/8200 loss 9.337496 loss_att 9.712336 loss_ctc 12.607881 loss_rnnt 8.660810 hw_loss 0.310625 lr 0.00029158 rank 1
2023-03-01 06:52:47,548 DEBUG TRAIN Batch 50/8300 loss 7.198413 loss_att 9.431526 loss_ctc 10.559355 loss_rnnt 6.245387 hw_loss 0.109271 lr 0.00029157 rank 0
2023-03-01 06:52:47,550 DEBUG TRAIN Batch 50/8300 loss 9.085603 loss_att 12.108961 loss_ctc 13.162451 loss_rnnt 7.852898 hw_loss 0.158350 lr 0.00029156 rank 5
2023-03-01 06:52:47,568 DEBUG TRAIN Batch 50/8300 loss 5.063110 loss_att 7.764934 loss_ctc 6.475357 loss_rnnt 4.198447 hw_loss 0.254997 lr 0.00029155 rank 7
2023-03-01 06:52:47,569 DEBUG TRAIN Batch 50/8300 loss 4.050239 loss_att 6.561720 loss_ctc 7.197120 loss_rnnt 3.011911 hw_loss 0.218340 lr 0.00029157 rank 1
2023-03-01 06:52:47,570 DEBUG TRAIN Batch 50/8300 loss 12.569939 loss_att 17.874514 loss_ctc 25.508528 loss_rnnt 9.705198 hw_loss 0.147523 lr 0.00029156 rank 6
2023-03-01 06:52:47,573 DEBUG TRAIN Batch 50/8300 loss 1.870466 loss_att 3.827234 loss_ctc 3.646189 loss_rnnt 1.024804 hw_loss 0.407898 lr 0.00029156 rank 3
2023-03-01 06:52:47,575 DEBUG TRAIN Batch 50/8300 loss 1.380701 loss_att 2.790461 loss_ctc 1.699582 loss_rnnt 0.947568 hw_loss 0.203743 lr 0.00029156 rank 4
2023-03-01 06:52:47,575 DEBUG TRAIN Batch 50/8300 loss 3.420025 loss_att 5.803018 loss_ctc 4.252130 loss_rnnt 2.733485 hw_loss 0.185615 lr 0.00029157 rank 2
2023-03-01 06:53:12,619 DEBUG CV Batch 50/0 loss 1.119071 loss_att 1.022664 loss_ctc 1.980656 loss_rnnt 0.826086 hw_loss 0.370104 history loss 1.077624 rank 3
2023-03-01 06:53:12,632 DEBUG CV Batch 50/0 loss 1.119071 loss_att 1.022664 loss_ctc 1.980656 loss_rnnt 0.826086 hw_loss 0.370104 history loss 1.077624 rank 1
2023-03-01 06:53:12,680 DEBUG CV Batch 50/0 loss 1.119071 loss_att 1.022664 loss_ctc 1.980656 loss_rnnt 0.826086 hw_loss 0.370104 history loss 1.077624 rank 6
2023-03-01 06:53:12,687 DEBUG CV Batch 50/0 loss 1.119071 loss_att 1.022664 loss_ctc 1.980656 loss_rnnt 0.826086 hw_loss 0.370104 history loss 1.077624 rank 7
2023-03-01 06:53:12,700 DEBUG CV Batch 50/0 loss 1.119071 loss_att 1.022664 loss_ctc 1.980656 loss_rnnt 0.826086 hw_loss 0.370104 history loss 1.077624 rank 0
2023-03-01 06:53:12,765 DEBUG CV Batch 50/0 loss 1.119071 loss_att 1.022664 loss_ctc 1.980656 loss_rnnt 0.826086 hw_loss 0.370104 history loss 1.077624 rank 5
2023-03-01 06:53:12,851 DEBUG CV Batch 50/0 loss 1.119071 loss_att 1.022664 loss_ctc 1.980656 loss_rnnt 0.826086 hw_loss 0.370104 history loss 1.077624 rank 2
2023-03-01 06:53:12,934 DEBUG CV Batch 50/0 loss 1.119071 loss_att 1.022664 loss_ctc 1.980656 loss_rnnt 0.826086 hw_loss 0.370104 history loss 1.077624 rank 4
2023-03-01 06:53:23,895 DEBUG CV Batch 50/100 loss 3.728662 loss_att 4.796847 loss_ctc 8.555114 loss_rnnt 2.758557 hw_loss 0.211765 history loss 2.921133 rank 6
2023-03-01 06:53:23,973 DEBUG CV Batch 50/100 loss 3.728662 loss_att 4.796847 loss_ctc 8.555114 loss_rnnt 2.758557 hw_loss 0.211765 history loss 2.921133 rank 3
2023-03-01 06:53:24,041 DEBUG CV Batch 50/100 loss 3.728662 loss_att 4.796847 loss_ctc 8.555114 loss_rnnt 2.758557 hw_loss 0.211765 history loss 2.921133 rank 1
2023-03-01 06:53:24,123 DEBUG CV Batch 50/100 loss 3.728662 loss_att 4.796847 loss_ctc 8.555114 loss_rnnt 2.758557 hw_loss 0.211765 history loss 2.921133 rank 2
2023-03-01 06:53:24,246 DEBUG CV Batch 50/100 loss 3.728662 loss_att 4.796847 loss_ctc 8.555114 loss_rnnt 2.758557 hw_loss 0.211765 history loss 2.921133 rank 4
2023-03-01 06:53:24,478 DEBUG CV Batch 50/100 loss 3.728662 loss_att 4.796847 loss_ctc 8.555114 loss_rnnt 2.758557 hw_loss 0.211765 history loss 2.921133 rank 5
2023-03-01 06:53:24,655 DEBUG CV Batch 50/100 loss 3.728662 loss_att 4.796847 loss_ctc 8.555114 loss_rnnt 2.758557 hw_loss 0.211765 history loss 2.921133 rank 7
2023-03-01 06:53:24,746 DEBUG CV Batch 50/100 loss 3.728662 loss_att 4.796847 loss_ctc 8.555114 loss_rnnt 2.758557 hw_loss 0.211765 history loss 2.921133 rank 0
2023-03-01 06:53:37,385 DEBUG CV Batch 50/200 loss 7.522687 loss_att 8.931486 loss_ctc 8.438048 loss_rnnt 6.990318 hw_loss 0.241052 history loss 3.509249 rank 3
2023-03-01 06:53:37,608 DEBUG CV Batch 50/200 loss 7.522687 loss_att 8.931486 loss_ctc 8.438048 loss_rnnt 6.990318 hw_loss 0.241052 history loss 3.509249 rank 4
2023-03-01 06:53:37,607 DEBUG CV Batch 50/200 loss 7.522687 loss_att 8.931486 loss_ctc 8.438048 loss_rnnt 6.990318 hw_loss 0.241052 history loss 3.509249 rank 2
2023-03-01 06:53:37,628 DEBUG CV Batch 50/200 loss 7.522687 loss_att 8.931486 loss_ctc 8.438048 loss_rnnt 6.990318 hw_loss 0.241052 history loss 3.509249 rank 1
2023-03-01 06:53:37,674 DEBUG CV Batch 50/200 loss 7.522687 loss_att 8.931486 loss_ctc 8.438048 loss_rnnt 6.990318 hw_loss 0.241052 history loss 3.509249 rank 6
2023-03-01 06:53:37,707 DEBUG CV Batch 50/200 loss 7.522687 loss_att 8.931486 loss_ctc 8.438048 loss_rnnt 6.990318 hw_loss 0.241052 history loss 3.509249 rank 5
2023-03-01 06:53:38,657 DEBUG CV Batch 50/200 loss 7.522687 loss_att 8.931486 loss_ctc 8.438048 loss_rnnt 6.990318 hw_loss 0.241052 history loss 3.509249 rank 7
2023-03-01 06:53:38,948 DEBUG CV Batch 50/200 loss 7.522687 loss_att 8.931486 loss_ctc 8.438048 loss_rnnt 6.990318 hw_loss 0.241052 history loss 3.509249 rank 0
2023-03-01 06:53:49,279 DEBUG CV Batch 50/300 loss 3.714025 loss_att 4.373392 loss_ctc 7.391008 loss_rnnt 2.928807 hw_loss 0.305777 history loss 3.685518 rank 4
2023-03-01 06:53:49,288 DEBUG CV Batch 50/300 loss 3.714025 loss_att 4.373392 loss_ctc 7.391008 loss_rnnt 2.928807 hw_loss 0.305777 history loss 3.685518 rank 1
2023-03-01 06:53:49,350 DEBUG CV Batch 50/300 loss 3.714025 loss_att 4.373392 loss_ctc 7.391008 loss_rnnt 2.928807 hw_loss 0.305777 history loss 3.685518 rank 3
2023-03-01 06:53:49,602 DEBUG CV Batch 50/300 loss 3.714025 loss_att 4.373392 loss_ctc 7.391008 loss_rnnt 2.928807 hw_loss 0.305777 history loss 3.685518 rank 2
2023-03-01 06:53:49,606 DEBUG CV Batch 50/300 loss 3.714025 loss_att 4.373392 loss_ctc 7.391008 loss_rnnt 2.928807 hw_loss 0.305777 history loss 3.685518 rank 5
2023-03-01 06:53:49,844 DEBUG CV Batch 50/300 loss 3.714025 loss_att 4.373392 loss_ctc 7.391008 loss_rnnt 2.928807 hw_loss 0.305777 history loss 3.685518 rank 6
2023-03-01 06:53:51,377 DEBUG CV Batch 50/300 loss 3.714025 loss_att 4.373392 loss_ctc 7.391008 loss_rnnt 2.928807 hw_loss 0.305777 history loss 3.685518 rank 7
2023-03-01 06:53:52,066 DEBUG CV Batch 50/300 loss 3.714025 loss_att 4.373392 loss_ctc 7.391008 loss_rnnt 2.928807 hw_loss 0.305777 history loss 3.685518 rank 0
2023-03-01 06:54:00,979 DEBUG CV Batch 50/400 loss 13.588583 loss_att 71.696304 loss_ctc 4.767364 loss_rnnt 3.034477 hw_loss 0.203857 history loss 4.498325 rank 1
2023-03-01 06:54:01,111 DEBUG CV Batch 50/400 loss 13.588583 loss_att 71.696304 loss_ctc 4.767364 loss_rnnt 3.034477 hw_loss 0.203857 history loss 4.498325 rank 4
2023-03-01 06:54:01,615 DEBUG CV Batch 50/400 loss 13.588583 loss_att 71.696304 loss_ctc 4.767364 loss_rnnt 3.034477 hw_loss 0.203857 history loss 4.498325 rank 3
2023-03-01 06:54:01,659 DEBUG CV Batch 50/400 loss 13.588583 loss_att 71.696304 loss_ctc 4.767364 loss_rnnt 3.034477 hw_loss 0.203857 history loss 4.498325 rank 5
2023-03-01 06:54:01,694 DEBUG CV Batch 50/400 loss 13.588583 loss_att 71.696304 loss_ctc 4.767364 loss_rnnt 3.034477 hw_loss 0.203857 history loss 4.498325 rank 2
2023-03-01 06:54:01,765 DEBUG CV Batch 50/400 loss 13.588583 loss_att 71.696304 loss_ctc 4.767364 loss_rnnt 3.034477 hw_loss 0.203857 history loss 4.498325 rank 6
2023-03-01 06:54:04,146 DEBUG CV Batch 50/400 loss 13.588583 loss_att 71.696304 loss_ctc 4.767364 loss_rnnt 3.034477 hw_loss 0.203857 history loss 4.498325 rank 7
2023-03-01 06:54:05,044 DEBUG CV Batch 50/400 loss 13.588583 loss_att 71.696304 loss_ctc 4.767364 loss_rnnt 3.034477 hw_loss 0.203857 history loss 4.498325 rank 0
2023-03-01 06:54:10,951 DEBUG CV Batch 50/500 loss 4.019673 loss_att 4.142929 loss_ctc 5.198909 loss_rnnt 3.665305 hw_loss 0.323408 history loss 5.114039 rank 1
2023-03-01 06:54:11,552 DEBUG CV Batch 50/500 loss 4.019672 loss_att 4.142929 loss_ctc 5.198909 loss_rnnt 3.665305 hw_loss 0.323408 history loss 5.114039 rank 4
2023-03-01 06:54:11,728 DEBUG CV Batch 50/500 loss 4.019673 loss_att 4.142929 loss_ctc 5.198909 loss_rnnt 3.665305 hw_loss 0.323408 history loss 5.114039 rank 5
2023-03-01 06:54:11,968 DEBUG CV Batch 50/500 loss 4.019673 loss_att 4.142929 loss_ctc 5.198909 loss_rnnt 3.665305 hw_loss 0.323408 history loss 5.114039 rank 6
2023-03-01 06:54:12,022 DEBUG CV Batch 50/500 loss 4.019673 loss_att 4.142929 loss_ctc 5.198909 loss_rnnt 3.665305 hw_loss 0.323408 history loss 5.114039 rank 3
2023-03-01 06:54:12,215 DEBUG CV Batch 50/500 loss 4.019673 loss_att 4.142929 loss_ctc 5.198909 loss_rnnt 3.665305 hw_loss 0.323408 history loss 5.114039 rank 2
2023-03-01 06:54:15,425 DEBUG CV Batch 50/500 loss 4.019672 loss_att 4.142929 loss_ctc 5.198909 loss_rnnt 3.665305 hw_loss 0.323408 history loss 5.114039 rank 7
2023-03-01 06:54:16,626 DEBUG CV Batch 50/500 loss 4.019673 loss_att 4.142929 loss_ctc 5.198909 loss_rnnt 3.665305 hw_loss 0.323408 history loss 5.114039 rank 0
2023-03-01 06:54:22,777 DEBUG CV Batch 50/600 loss 7.035967 loss_att 6.317161 loss_ctc 9.753424 loss_rnnt 6.615123 hw_loss 0.379272 history loss 5.981796 rank 1
2023-03-01 06:54:23,406 DEBUG CV Batch 50/600 loss 7.035967 loss_att 6.317161 loss_ctc 9.753424 loss_rnnt 6.615123 hw_loss 0.379272 history loss 5.981796 rank 4
2023-03-01 06:54:23,551 DEBUG CV Batch 50/600 loss 7.035967 loss_att 6.317161 loss_ctc 9.753424 loss_rnnt 6.615123 hw_loss 0.379272 history loss 5.981796 rank 5
2023-03-01 06:54:24,072 DEBUG CV Batch 50/600 loss 7.035967 loss_att 6.317161 loss_ctc 9.753424 loss_rnnt 6.615123 hw_loss 0.379272 history loss 5.981796 rank 6
2023-03-01 06:54:24,158 DEBUG CV Batch 50/600 loss 7.035967 loss_att 6.317161 loss_ctc 9.753424 loss_rnnt 6.615123 hw_loss 0.379272 history loss 5.981796 rank 3
2023-03-01 06:54:24,274 DEBUG CV Batch 50/600 loss 7.035967 loss_att 6.317161 loss_ctc 9.753424 loss_rnnt 6.615123 hw_loss 0.379272 history loss 5.981796 rank 2
2023-03-01 06:54:28,165 DEBUG CV Batch 50/600 loss 7.035967 loss_att 6.317161 loss_ctc 9.753424 loss_rnnt 6.615123 hw_loss 0.379272 history loss 5.981796 rank 7
2023-03-01 06:54:29,740 DEBUG CV Batch 50/600 loss 7.035967 loss_att 6.317161 loss_ctc 9.753424 loss_rnnt 6.615123 hw_loss 0.379272 history loss 5.981796 rank 0
2023-03-01 06:54:33,715 DEBUG CV Batch 50/700 loss 11.028021 loss_att 21.765272 loss_ctc 16.013079 loss_rnnt 8.020838 hw_loss 0.365734 history loss 6.507692 rank 1
2023-03-01 06:54:34,361 DEBUG CV Batch 50/700 loss 11.028021 loss_att 21.765272 loss_ctc 16.013079 loss_rnnt 8.020838 hw_loss 0.365734 history loss 6.507692 rank 4
2023-03-01 06:54:34,687 DEBUG CV Batch 50/700 loss 11.028021 loss_att 21.765272 loss_ctc 16.013079 loss_rnnt 8.020838 hw_loss 0.365734 history loss 6.507692 rank 5
2023-03-01 06:54:35,462 DEBUG CV Batch 50/700 loss 11.028021 loss_att 21.765272 loss_ctc 16.013079 loss_rnnt 8.020838 hw_loss 0.365734 history loss 6.507692 rank 2
2023-03-01 06:54:35,549 DEBUG CV Batch 50/700 loss 11.028021 loss_att 21.765272 loss_ctc 16.013079 loss_rnnt 8.020838 hw_loss 0.365734 history loss 6.507692 rank 3
2023-03-01 06:54:35,628 DEBUG CV Batch 50/700 loss 11.028021 loss_att 21.765272 loss_ctc 16.013079 loss_rnnt 8.020838 hw_loss 0.365734 history loss 6.507692 rank 6
2023-03-01 06:54:40,151 DEBUG CV Batch 50/700 loss 11.028021 loss_att 21.765272 loss_ctc 16.013079 loss_rnnt 8.020838 hw_loss 0.365734 history loss 6.507692 rank 7
2023-03-01 06:54:42,027 DEBUG CV Batch 50/700 loss 11.028021 loss_att 21.765272 loss_ctc 16.013079 loss_rnnt 8.020838 hw_loss 0.365734 history loss 6.507692 rank 0
2023-03-01 06:54:45,163 DEBUG CV Batch 50/800 loss 6.939031 loss_att 7.435502 loss_ctc 14.048950 loss_rnnt 5.755926 hw_loss 0.254667 history loss 6.038574 rank 4
2023-03-01 06:54:45,321 DEBUG CV Batch 50/800 loss 6.939031 loss_att 7.435502 loss_ctc 14.048950 loss_rnnt 5.755926 hw_loss 0.254667 history loss 6.038574 rank 1
2023-03-01 06:54:46,233 DEBUG CV Batch 50/800 loss 6.939031 loss_att 7.435502 loss_ctc 14.048950 loss_rnnt 5.755926 hw_loss 0.254667 history loss 6.038574 rank 5
2023-03-01 06:54:46,557 DEBUG CV Batch 50/800 loss 6.939031 loss_att 7.435502 loss_ctc 14.048950 loss_rnnt 5.755926 hw_loss 0.254667 history loss 6.038574 rank 2
2023-03-01 06:54:46,614 DEBUG CV Batch 50/800 loss 6.939031 loss_att 7.435502 loss_ctc 14.048950 loss_rnnt 5.755926 hw_loss 0.254667 history loss 6.038574 rank 3
2023-03-01 06:54:46,626 DEBUG CV Batch 50/800 loss 6.939031 loss_att 7.435502 loss_ctc 14.048950 loss_rnnt 5.755926 hw_loss 0.254667 history loss 6.038574 rank 6
2023-03-01 06:54:52,065 DEBUG CV Batch 50/800 loss 6.939031 loss_att 7.435502 loss_ctc 14.048950 loss_rnnt 5.755926 hw_loss 0.254667 history loss 6.038574 rank 7
2023-03-01 06:54:54,379 DEBUG CV Batch 50/800 loss 6.939031 loss_att 7.435502 loss_ctc 14.048950 loss_rnnt 5.755926 hw_loss 0.254667 history loss 6.038574 rank 0
2023-03-01 06:54:58,147 DEBUG CV Batch 50/900 loss 9.190277 loss_att 9.511795 loss_ctc 17.346201 loss_rnnt 7.960271 hw_loss 0.146710 history loss 5.870444 rank 4
2023-03-01 06:54:58,653 DEBUG CV Batch 50/900 loss 9.190277 loss_att 9.511795 loss_ctc 17.346201 loss_rnnt 7.960271 hw_loss 0.146710 history loss 5.870444 rank 1
2023-03-01 06:54:59,659 DEBUG CV Batch 50/900 loss 9.190277 loss_att 9.511795 loss_ctc 17.346201 loss_rnnt 7.960271 hw_loss 0.146710 history loss 5.870444 rank 5
2023-03-01 06:54:59,988 DEBUG CV Batch 50/900 loss 9.190277 loss_att 9.511795 loss_ctc 17.346201 loss_rnnt 7.960271 hw_loss 0.146710 history loss 5.870444 rank 6
2023-03-01 06:54:59,990 DEBUG CV Batch 50/900 loss 9.190277 loss_att 9.511795 loss_ctc 17.346201 loss_rnnt 7.960271 hw_loss 0.146710 history loss 5.870444 rank 2
2023-03-01 06:55:00,022 DEBUG CV Batch 50/900 loss 9.190277 loss_att 9.511795 loss_ctc 17.346201 loss_rnnt 7.960271 hw_loss 0.146710 history loss 5.870444 rank 3
2023-03-01 06:55:05,996 DEBUG CV Batch 50/900 loss 9.190277 loss_att 9.511795 loss_ctc 17.346201 loss_rnnt 7.960271 hw_loss 0.146710 history loss 5.870444 rank 7
2023-03-01 06:55:08,532 DEBUG CV Batch 50/900 loss 9.190277 loss_att 9.511795 loss_ctc 17.346201 loss_rnnt 7.960271 hw_loss 0.146710 history loss 5.870444 rank 0
2023-03-01 06:55:10,157 DEBUG CV Batch 50/1000 loss 4.855933 loss_att 5.268731 loss_ctc 5.686241 loss_rnnt 4.529021 hw_loss 0.250584 history loss 5.681011 rank 4
2023-03-01 06:55:10,497 DEBUG CV Batch 50/1000 loss 4.855933 loss_att 5.268731 loss_ctc 5.686241 loss_rnnt 4.529021 hw_loss 0.250584 history loss 5.681011 rank 1
2023-03-01 06:55:11,638 DEBUG CV Batch 50/1000 loss 4.855933 loss_att 5.268731 loss_ctc 5.686241 loss_rnnt 4.529021 hw_loss 0.250584 history loss 5.681011 rank 5
2023-03-01 06:55:12,437 DEBUG CV Batch 50/1000 loss 4.855933 loss_att 5.268731 loss_ctc 5.686241 loss_rnnt 4.529021 hw_loss 0.250584 history loss 5.681011 rank 2
2023-03-01 06:55:12,459 DEBUG CV Batch 50/1000 loss 4.855933 loss_att 5.268731 loss_ctc 5.686241 loss_rnnt 4.529021 hw_loss 0.250584 history loss 5.681011 rank 3
2023-03-01 06:55:12,772 DEBUG CV Batch 50/1000 loss 4.855933 loss_att 5.268731 loss_ctc 5.686241 loss_rnnt 4.529021 hw_loss 0.250584 history loss 5.681011 rank 6
2023-03-01 06:55:18,990 DEBUG CV Batch 50/1000 loss 4.855933 loss_att 5.268731 loss_ctc 5.686241 loss_rnnt 4.529021 hw_loss 0.250584 history loss 5.681011 rank 7
2023-03-01 06:55:21,745 DEBUG CV Batch 50/1000 loss 4.855933 loss_att 5.268731 loss_ctc 5.686241 loss_rnnt 4.529021 hw_loss 0.250584 history loss 5.681011 rank 0
2023-03-01 06:55:21,825 DEBUG CV Batch 50/1100 loss 4.629567 loss_att 4.514709 loss_ctc 8.652884 loss_rnnt 3.947037 hw_loss 0.316987 history loss 5.641310 rank 4
2023-03-01 06:55:22,191 DEBUG CV Batch 50/1100 loss 4.629567 loss_att 4.514709 loss_ctc 8.652884 loss_rnnt 3.947037 hw_loss 0.316987 history loss 5.641310 rank 1
2023-03-01 06:55:23,593 DEBUG CV Batch 50/1100 loss 4.629567 loss_att 4.514709 loss_ctc 8.652884 loss_rnnt 3.947037 hw_loss 0.316987 history loss 5.641310 rank 5
2023-03-01 06:55:24,648 DEBUG CV Batch 50/1100 loss 4.629567 loss_att 4.514709 loss_ctc 8.652884 loss_rnnt 3.947037 hw_loss 0.316987 history loss 5.641310 rank 3
2023-03-01 06:55:24,724 DEBUG CV Batch 50/1100 loss 4.629567 loss_att 4.514709 loss_ctc 8.652884 loss_rnnt 3.947037 hw_loss 0.316987 history loss 5.641310 rank 6
2023-03-01 06:55:24,941 DEBUG CV Batch 50/1100 loss 4.629567 loss_att 4.514709 loss_ctc 8.652884 loss_rnnt 3.947037 hw_loss 0.316987 history loss 5.641310 rank 2
2023-03-01 06:55:31,552 DEBUG CV Batch 50/1100 loss 4.629567 loss_att 4.514709 loss_ctc 8.652884 loss_rnnt 3.947037 hw_loss 0.316987 history loss 5.641310 rank 7
2023-03-01 06:55:32,167 DEBUG CV Batch 50/1200 loss 6.337216 loss_att 6.489902 loss_ctc 7.869752 loss_rnnt 5.954038 hw_loss 0.278067 history loss 5.930808 rank 4
2023-03-01 06:55:32,264 DEBUG CV Batch 50/1200 loss 6.337216 loss_att 6.489902 loss_ctc 7.869752 loss_rnnt 5.954038 hw_loss 0.278067 history loss 5.930808 rank 1
2023-03-01 06:55:33,973 DEBUG CV Batch 50/1200 loss 6.337216 loss_att 6.489902 loss_ctc 7.869752 loss_rnnt 5.954038 hw_loss 0.278067 history loss 5.930808 rank 5
2023-03-01 06:55:34,669 DEBUG CV Batch 50/1100 loss 4.629567 loss_att 4.514709 loss_ctc 8.652884 loss_rnnt 3.947037 hw_loss 0.316987 history loss 5.641310 rank 0
2023-03-01 06:55:35,380 DEBUG CV Batch 50/1200 loss 6.337216 loss_att 6.489902 loss_ctc 7.869752 loss_rnnt 5.954038 hw_loss 0.278067 history loss 5.930808 rank 6
2023-03-01 06:55:35,525 DEBUG CV Batch 50/1200 loss 6.337216 loss_att 6.489902 loss_ctc 7.869752 loss_rnnt 5.954038 hw_loss 0.278067 history loss 5.930808 rank 3
2023-03-01 06:55:35,857 DEBUG CV Batch 50/1200 loss 6.337216 loss_att 6.489902 loss_ctc 7.869752 loss_rnnt 5.954038 hw_loss 0.278067 history loss 5.930808 rank 2
2023-03-01 06:55:42,946 DEBUG CV Batch 50/1200 loss 6.337216 loss_att 6.489902 loss_ctc 7.869752 loss_rnnt 5.954038 hw_loss 0.278067 history loss 5.930808 rank 7
2023-03-01 06:55:43,782 DEBUG CV Batch 50/1300 loss 3.834444 loss_att 3.591359 loss_ctc 5.543611 loss_rnnt 3.509150 hw_loss 0.273791 history loss 6.220096 rank 4
2023-03-01 06:55:44,047 DEBUG CV Batch 50/1300 loss 3.834444 loss_att 3.591359 loss_ctc 5.543611 loss_rnnt 3.509150 hw_loss 0.273791 history loss 6.220096 rank 1
2023-03-01 06:55:46,308 DEBUG CV Batch 50/1300 loss 3.834444 loss_att 3.591359 loss_ctc 5.543611 loss_rnnt 3.509150 hw_loss 0.273791 history loss 6.220096 rank 5
2023-03-01 06:55:46,447 DEBUG CV Batch 50/1200 loss 6.337216 loss_att 6.489902 loss_ctc 7.869752 loss_rnnt 5.954038 hw_loss 0.278067 history loss 5.930808 rank 0
2023-03-01 06:55:47,339 DEBUG CV Batch 50/1300 loss 3.834444 loss_att 3.591359 loss_ctc 5.543611 loss_rnnt 3.509150 hw_loss 0.273791 history loss 6.220096 rank 6
2023-03-01 06:55:47,834 DEBUG CV Batch 50/1300 loss 3.834444 loss_att 3.591359 loss_ctc 5.543611 loss_rnnt 3.509150 hw_loss 0.273791 history loss 6.220096 rank 3
2023-03-01 06:55:47,971 DEBUG CV Batch 50/1300 loss 3.834444 loss_att 3.591359 loss_ctc 5.543611 loss_rnnt 3.509150 hw_loss 0.273791 history loss 6.220096 rank 2
2023-03-01 06:55:54,786 DEBUG CV Batch 50/1400 loss 4.067006 loss_att 13.322701 loss_ctc 3.494874 loss_rnnt 2.206460 hw_loss 0.160671 history loss 6.493882 rank 4
2023-03-01 06:55:54,881 DEBUG CV Batch 50/1400 loss 4.067006 loss_att 13.322701 loss_ctc 3.494874 loss_rnnt 2.206460 hw_loss 0.160671 history loss 6.493882 rank 1
2023-03-01 06:55:55,731 DEBUG CV Batch 50/1300 loss 3.834444 loss_att 3.591359 loss_ctc 5.543611 loss_rnnt 3.509150 hw_loss 0.273791 history loss 6.220096 rank 7
2023-03-01 06:55:57,702 DEBUG CV Batch 50/1400 loss 4.067006 loss_att 13.322701 loss_ctc 3.494874 loss_rnnt 2.206460 hw_loss 0.160671 history loss 6.493882 rank 5
2023-03-01 06:55:58,706 DEBUG CV Batch 50/1400 loss 4.067006 loss_att 13.322701 loss_ctc 3.494874 loss_rnnt 2.206460 hw_loss 0.160671 history loss 6.493882 rank 6
2023-03-01 06:55:59,222 DEBUG CV Batch 50/1400 loss 4.067006 loss_att 13.322701 loss_ctc 3.494874 loss_rnnt 2.206460 hw_loss 0.160671 history loss 6.493882 rank 2
2023-03-01 06:55:59,231 DEBUG CV Batch 50/1400 loss 4.067006 loss_att 13.322701 loss_ctc 3.494874 loss_rnnt 2.206460 hw_loss 0.160671 history loss 6.493882 rank 3
2023-03-01 06:55:59,466 DEBUG CV Batch 50/1300 loss 3.834444 loss_att 3.591359 loss_ctc 5.543611 loss_rnnt 3.509150 hw_loss 0.273791 history loss 6.220096 rank 0
2023-03-01 06:56:05,776 DEBUG CV Batch 50/1500 loss 6.461818 loss_att 7.018443 loss_ctc 7.171262 loss_rnnt 6.121419 hw_loss 0.252152 history loss 6.364535 rank 1
2023-03-01 06:56:05,956 DEBUG CV Batch 50/1500 loss 6.461818 loss_att 7.018443 loss_ctc 7.171262 loss_rnnt 6.121419 hw_loss 0.252152 history loss 6.364535 rank 4
2023-03-01 06:56:07,627 DEBUG CV Batch 50/1400 loss 4.067006 loss_att 13.322701 loss_ctc 3.494874 loss_rnnt 2.206460 hw_loss 0.160671 history loss 6.493882 rank 7
2023-03-01 06:56:08,803 DEBUG CV Batch 50/1500 loss 6.461818 loss_att 7.018443 loss_ctc 7.171262 loss_rnnt 6.121419 hw_loss 0.252152 history loss 6.364535 rank 5
2023-03-01 06:56:10,152 DEBUG CV Batch 50/1500 loss 6.461818 loss_att 7.018443 loss_ctc 7.171262 loss_rnnt 6.121419 hw_loss 0.252152 history loss 6.364535 rank 6
2023-03-01 06:56:10,802 DEBUG CV Batch 50/1500 loss 6.461818 loss_att 7.018443 loss_ctc 7.171262 loss_rnnt 6.121419 hw_loss 0.252152 history loss 6.364535 rank 3
2023-03-01 06:56:10,924 DEBUG CV Batch 50/1500 loss 6.461818 loss_att 7.018443 loss_ctc 7.171262 loss_rnnt 6.121419 hw_loss 0.252152 history loss 6.364535 rank 2
2023-03-01 06:56:11,553 DEBUG CV Batch 50/1400 loss 4.067006 loss_att 13.322701 loss_ctc 3.494874 loss_rnnt 2.206460 hw_loss 0.160671 history loss 6.493882 rank 0
2023-03-01 06:56:18,564 DEBUG CV Batch 50/1600 loss 9.939087 loss_att 12.995397 loss_ctc 11.086798 loss_rnnt 9.106841 hw_loss 0.127419 history loss 6.322783 rank 1
2023-03-01 06:56:18,836 DEBUG CV Batch 50/1600 loss 9.939087 loss_att 12.995397 loss_ctc 11.086798 loss_rnnt 9.106841 hw_loss 0.127419 history loss 6.322783 rank 4
2023-03-01 06:56:19,819 DEBUG CV Batch 50/1500 loss 6.461818 loss_att 7.018443 loss_ctc 7.171262 loss_rnnt 6.121419 hw_loss 0.252152 history loss 6.364535 rank 7
2023-03-01 06:56:21,857 DEBUG CV Batch 50/1600 loss 9.939087 loss_att 12.995397 loss_ctc 11.086798 loss_rnnt 9.106841 hw_loss 0.127419 history loss 6.322783 rank 5
2023-03-01 06:56:23,273 DEBUG CV Batch 50/1600 loss 9.939087 loss_att 12.995397 loss_ctc 11.086798 loss_rnnt 9.106841 hw_loss 0.127419 history loss 6.322783 rank 6
2023-03-01 06:56:23,978 DEBUG CV Batch 50/1500 loss 6.461818 loss_att 7.018443 loss_ctc 7.171262 loss_rnnt 6.121419 hw_loss 0.252152 history loss 6.364535 rank 0
2023-03-01 06:56:24,288 DEBUG CV Batch 50/1600 loss 9.939087 loss_att 12.995397 loss_ctc 11.086798 loss_rnnt 9.106841 hw_loss 0.127419 history loss 6.322783 rank 3
2023-03-01 06:56:24,419 DEBUG CV Batch 50/1600 loss 9.939087 loss_att 12.995397 loss_ctc 11.086798 loss_rnnt 9.106841 hw_loss 0.127419 history loss 6.322783 rank 2
2023-03-01 06:56:30,796 DEBUG CV Batch 50/1700 loss 9.060695 loss_att 7.656794 loss_ctc 15.063576 loss_rnnt 8.434496 hw_loss 0.199863 history loss 6.267772 rank 1
2023-03-01 06:56:31,091 DEBUG CV Batch 50/1700 loss 9.060695 loss_att 7.656794 loss_ctc 15.063576 loss_rnnt 8.434496 hw_loss 0.199863 history loss 6.267772 rank 4
2023-03-01 06:56:33,413 DEBUG CV Batch 50/1600 loss 9.939087 loss_att 12.995397 loss_ctc 11.086798 loss_rnnt 9.106841 hw_loss 0.127419 history loss 6.322783 rank 7
2023-03-01 06:56:34,753 DEBUG CV Batch 50/1700 loss 9.060695 loss_att 7.656794 loss_ctc 15.063576 loss_rnnt 8.434496 hw_loss 0.199863 history loss 6.267772 rank 5
2023-03-01 06:56:35,814 DEBUG CV Batch 50/1700 loss 9.060695 loss_att 7.656794 loss_ctc 15.063576 loss_rnnt 8.434496 hw_loss 0.199863 history loss 6.267772 rank 6
2023-03-01 06:56:36,840 DEBUG CV Batch 50/1700 loss 9.060695 loss_att 7.656794 loss_ctc 15.063576 loss_rnnt 8.434496 hw_loss 0.199863 history loss 6.267772 rank 3
2023-03-01 06:56:36,957 DEBUG CV Batch 50/1700 loss 9.060695 loss_att 7.656794 loss_ctc 15.063576 loss_rnnt 8.434496 hw_loss 0.199863 history loss 6.267772 rank 2
2023-03-01 06:56:37,538 DEBUG CV Batch 50/1600 loss 9.939087 loss_att 12.995397 loss_ctc 11.086798 loss_rnnt 9.106841 hw_loss 0.127419 history loss 6.322783 rank 0
2023-03-01 06:56:39,796 INFO Epoch 50 CV info cv_loss 6.244636637254126
2023-03-01 06:56:39,797 INFO Epoch 51 TRAIN info lr 0.00029156080274579747
2023-03-01 06:56:39,802 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 06:56:40,194 INFO Epoch 50 CV info cv_loss 6.244636639196726
2023-03-01 06:56:40,195 INFO Epoch 51 TRAIN info lr 0.00029155981135430415
2023-03-01 06:56:40,196 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 06:56:43,875 INFO Epoch 50 CV info cv_loss 6.24463663606746
2023-03-01 06:56:43,876 INFO Epoch 51 TRAIN info lr 0.0002915568372405015
2023-03-01 06:56:43,881 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 06:56:45,060 INFO Epoch 50 CV info cv_loss 6.244636638231887
2023-03-01 06:56:45,064 INFO Epoch 51 TRAIN info lr 0.00029155881997292385
2023-03-01 06:56:45,068 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 06:56:45,884 DEBUG CV Batch 50/1700 loss 9.060695 loss_att 7.656794 loss_ctc 15.063576 loss_rnnt 8.434496 hw_loss 0.199863 history loss 6.267772 rank 7
2023-03-01 06:56:46,175 INFO Epoch 50 CV info cv_loss 6.24463663785392
2023-03-01 06:56:46,176 INFO Epoch 51 TRAIN info lr 0.0002915533675560941
2023-03-01 06:56:46,181 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 06:56:46,242 INFO Epoch 50 CV info cv_loss 6.244636636853546
2023-03-01 06:56:46,242 INFO Epoch 51 TRAIN info lr 0.000291564768412904
2023-03-01 06:56:46,246 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 06:56:50,179 DEBUG CV Batch 50/1700 loss 9.060695 loss_att 7.656794 loss_ctc 15.063576 loss_rnnt 8.434496 hw_loss 0.199863 history loss 6.267772 rank 0
2023-03-01 06:56:55,279 INFO Epoch 50 CV info cv_loss 6.244636637962679
2023-03-01 06:56:55,280 INFO Epoch 51 TRAIN info lr 0.0002915479154451484
2023-03-01 06:56:55,285 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 06:56:59,669 INFO Epoch 50 CV info cv_loss 6.244636638022982
2023-03-01 06:56:59,669 INFO Checkpoint: save to checkpoint exp/2_27_rnnt_bias_loss_2_class_both_finetune/50.pt
2023-03-01 06:57:00,237 INFO Epoch 51 TRAIN info lr 0.00029156278555912376
2023-03-01 06:57:00,240 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 06:57:59,010 DEBUG TRAIN Batch 51/0 loss 5.902600 loss_att 6.913486 loss_ctc 9.411594 loss_rnnt 5.023894 hw_loss 0.391245 lr 0.00029155 rank 7
2023-03-01 06:57:59,011 DEBUG TRAIN Batch 51/0 loss 4.992792 loss_att 5.073451 loss_ctc 7.872671 loss_rnnt 4.380664 hw_loss 0.397523 lr 0.00029156 rank 4
2023-03-01 06:57:59,014 DEBUG TRAIN Batch 51/0 loss 5.070253 loss_att 5.857625 loss_ctc 8.072214 loss_rnnt 4.300198 hw_loss 0.398098 lr 0.00029156 rank 2
2023-03-01 06:57:59,015 DEBUG TRAIN Batch 51/0 loss 5.580581 loss_att 5.414889 loss_ctc 9.271734 loss_rnnt 4.973012 hw_loss 0.278537 lr 0.00029156 rank 6
2023-03-01 06:57:59,017 DEBUG TRAIN Batch 51/0 loss 5.648047 loss_att 5.777669 loss_ctc 8.555394 loss_rnnt 5.040878 hw_loss 0.362997 lr 0.00029156 rank 1
2023-03-01 06:57:59,020 DEBUG TRAIN Batch 51/0 loss 8.489186 loss_att 8.416171 loss_ctc 12.283200 loss_rnnt 7.838993 hw_loss 0.297990 lr 0.00029156 rank 5
2023-03-01 06:57:59,024 DEBUG TRAIN Batch 51/0 loss 6.184747 loss_att 5.741336 loss_ctc 9.792047 loss_rnnt 5.610544 hw_loss 0.341085 lr 0.00029155 rank 3
2023-03-01 06:57:59,045 DEBUG TRAIN Batch 51/0 loss 5.759490 loss_att 5.724219 loss_ctc 8.141785 loss_rnnt 5.254746 hw_loss 0.364048 lr 0.00029156 rank 0
2023-03-01 06:58:36,807 DEBUG TRAIN Batch 51/100 loss 9.246588 loss_att 12.261909 loss_ctc 15.004336 loss_rnnt 7.750509 hw_loss 0.234965 lr 0.00029155 rank 0
2023-03-01 06:58:36,808 DEBUG TRAIN Batch 51/100 loss 6.564722 loss_att 7.675120 loss_ctc 8.469181 loss_rnnt 5.938280 hw_loss 0.282064 lr 0.00029154 rank 7
2023-03-01 06:58:36,808 DEBUG TRAIN Batch 51/100 loss 6.753875 loss_att 11.402614 loss_ctc 13.550754 loss_rnnt 4.859567 hw_loss 0.109333 lr 0.00029155 rank 1
2023-03-01 06:58:36,813 DEBUG TRAIN Batch 51/100 loss 4.070732 loss_att 8.766052 loss_ctc 7.705747 loss_rnnt 2.580824 hw_loss 0.124077 lr 0.00029154 rank 5
2023-03-01 06:58:36,814 DEBUG TRAIN Batch 51/100 loss 2.927757 loss_att 5.217449 loss_ctc 4.024085 loss_rnnt 2.192889 hw_loss 0.245161 lr 0.00029155 rank 4
2023-03-01 06:58:36,814 DEBUG TRAIN Batch 51/100 loss 8.922010 loss_att 13.313591 loss_ctc 15.121356 loss_rnnt 7.125926 hw_loss 0.170980 lr 0.00029155 rank 2
2023-03-01 06:58:36,816 DEBUG TRAIN Batch 51/100 loss 11.902052 loss_att 16.128559 loss_ctc 17.773857 loss_rnnt 10.073137 hw_loss 0.376323 lr 0.00029154 rank 3
2023-03-01 06:58:36,821 DEBUG TRAIN Batch 51/100 loss 3.260064 loss_att 8.440706 loss_ctc 5.561307 loss_rnnt 1.812312 hw_loss 0.196485 lr 0.00029155 rank 6
2023-03-01 06:59:14,992 DEBUG TRAIN Batch 51/200 loss 4.304338 loss_att 6.906116 loss_ctc 7.519319 loss_rnnt 3.262010 hw_loss 0.174951 lr 0.00029154 rank 0
2023-03-01 06:59:14,994 DEBUG TRAIN Batch 51/200 loss 9.164455 loss_att 10.176908 loss_ctc 11.027629 loss_rnnt 8.596668 hw_loss 0.219138 lr 0.00029154 rank 2
2023-03-01 06:59:14,995 DEBUG TRAIN Batch 51/200 loss 6.169003 loss_att 9.333737 loss_ctc 8.565401 loss_rnnt 5.097715 hw_loss 0.222790 lr 0.00029153 rank 5
2023-03-01 06:59:14,996 DEBUG TRAIN Batch 51/200 loss 4.847469 loss_att 8.989999 loss_ctc 9.142382 loss_rnnt 3.370211 hw_loss 0.142683 lr 0.00029153 rank 3
2023-03-01 06:59:14,996 DEBUG TRAIN Batch 51/200 loss 4.167779 loss_att 6.479252 loss_ctc 5.524833 loss_rnnt 3.368001 hw_loss 0.293518 lr 0.00029152 rank 7
2023-03-01 06:59:14,997 DEBUG TRAIN Batch 51/200 loss 2.913742 loss_att 5.598014 loss_ctc 4.438684 loss_rnnt 2.141190 hw_loss 0.060697 lr 0.00029153 rank 6
2023-03-01 06:59:14,999 DEBUG TRAIN Batch 51/200 loss 2.287633 loss_att 4.801474 loss_ctc 4.217364 loss_rnnt 1.436467 hw_loss 0.170814 lr 0.00029153 rank 4
2023-03-01 06:59:15,054 DEBUG TRAIN Batch 51/200 loss 5.600256 loss_att 10.612020 loss_ctc 12.858161 loss_rnnt 3.533812 hw_loss 0.180693 lr 0.00029154 rank 1
2023-03-01 06:59:53,694 DEBUG TRAIN Batch 51/300 loss 3.031441 loss_att 6.828175 loss_ctc 4.998244 loss_rnnt 1.966308 hw_loss 0.081650 lr 0.00029153 rank 0
2023-03-01 06:59:53,695 DEBUG TRAIN Batch 51/300 loss 5.753394 loss_att 8.221075 loss_ctc 9.164293 loss_rnnt 4.700011 hw_loss 0.196987 lr 0.00029152 rank 6
2023-03-01 06:59:53,714 DEBUG TRAIN Batch 51/300 loss 7.662378 loss_att 8.822585 loss_ctc 12.437748 loss_rnnt 6.737590 hw_loss 0.105057 lr 0.00029151 rank 7
2023-03-01 06:59:53,715 DEBUG TRAIN Batch 51/300 loss 4.423809 loss_att 7.651237 loss_ctc 6.611030 loss_rnnt 3.319356 hw_loss 0.313758 lr 0.00029152 rank 3
2023-03-01 06:59:53,715 DEBUG TRAIN Batch 51/300 loss 8.305082 loss_att 9.707401 loss_ctc 9.918972 loss_rnnt 7.702933 hw_loss 0.199687 lr 0.00029153 rank 2
2023-03-01 06:59:53,716 DEBUG TRAIN Batch 51/300 loss 6.368840 loss_att 10.211663 loss_ctc 7.890275 loss_rnnt 5.335104 hw_loss 0.116837 lr 0.00029152 rank 4
2023-03-01 06:59:53,721 DEBUG TRAIN Batch 51/300 loss 3.658521 loss_att 7.316266 loss_ctc 7.018973 loss_rnnt 2.338999 hw_loss 0.262336 lr 0.00029152 rank 5
2023-03-01 06:59:53,757 DEBUG TRAIN Batch 51/300 loss 3.706452 loss_att 7.449409 loss_ctc 6.149323 loss_rnnt 2.502730 hw_loss 0.242652 lr 0.00029152 rank 1
2023-03-01 07:01:00,001 DEBUG TRAIN Batch 51/400 loss 9.950015 loss_att 11.473435 loss_ctc 11.860855 loss_rnnt 9.335836 hw_loss 0.102594 lr 0.00029150 rank 7
2023-03-01 07:01:00,017 DEBUG TRAIN Batch 51/400 loss 4.634437 loss_att 6.361115 loss_ctc 5.251038 loss_rnnt 4.041542 hw_loss 0.310022 lr 0.00029151 rank 0
2023-03-01 07:01:00,018 DEBUG TRAIN Batch 51/400 loss 2.751480 loss_att 7.237291 loss_ctc 5.204219 loss_rnnt 1.389226 hw_loss 0.258863 lr 0.00029151 rank 2
2023-03-01 07:01:00,018 DEBUG TRAIN Batch 51/400 loss 9.224133 loss_att 13.089249 loss_ctc 14.412842 loss_rnnt 7.687984 hw_loss 0.133685 lr 0.00029151 rank 1
2023-03-01 07:01:00,020 DEBUG TRAIN Batch 51/400 loss 5.161333 loss_att 6.531887 loss_ctc 6.007052 loss_rnnt 4.610072 hw_loss 0.308228 lr 0.00029150 rank 3
2023-03-01 07:01:00,022 DEBUG TRAIN Batch 51/400 loss 7.287047 loss_att 10.414244 loss_ctc 13.832520 loss_rnnt 5.651238 hw_loss 0.258074 lr 0.00029151 rank 4
2023-03-01 07:01:00,025 DEBUG TRAIN Batch 51/400 loss 8.404366 loss_att 9.822047 loss_ctc 16.870535 loss_rnnt 6.834968 hw_loss 0.294450 lr 0.00029151 rank 6
2023-03-01 07:01:00,026 DEBUG TRAIN Batch 51/400 loss 5.762291 loss_att 9.399889 loss_ctc 9.513668 loss_rnnt 4.424674 hw_loss 0.206088 lr 0.00029151 rank 5
2023-03-01 07:01:38,072 DEBUG TRAIN Batch 51/500 loss 8.598656 loss_att 11.108757 loss_ctc 13.879261 loss_rnnt 7.241318 hw_loss 0.283571 lr 0.00029150 rank 6
2023-03-01 07:01:38,076 DEBUG TRAIN Batch 51/500 loss 5.575385 loss_att 8.218634 loss_ctc 6.520989 loss_rnnt 4.735134 hw_loss 0.347850 lr 0.00029150 rank 4
2023-03-01 07:01:38,087 DEBUG TRAIN Batch 51/500 loss 3.513478 loss_att 6.757510 loss_ctc 6.468487 loss_rnnt 2.337002 hw_loss 0.250627 lr 0.00029149 rank 7
2023-03-01 07:01:38,091 DEBUG TRAIN Batch 51/500 loss 4.852707 loss_att 7.109971 loss_ctc 8.305042 loss_rnnt 3.842003 hw_loss 0.185513 lr 0.00029150 rank 0
2023-03-01 07:01:38,098 DEBUG TRAIN Batch 51/500 loss 7.952683 loss_att 9.388474 loss_ctc 13.319962 loss_rnnt 6.805123 hw_loss 0.271433 lr 0.00029150 rank 2
2023-03-01 07:01:38,098 DEBUG TRAIN Batch 51/500 loss 6.732467 loss_att 8.322663 loss_ctc 8.968550 loss_rnnt 5.965427 hw_loss 0.282855 lr 0.00029149 rank 3
2023-03-01 07:01:38,116 DEBUG TRAIN Batch 51/500 loss 9.750393 loss_att 12.359080 loss_ctc 18.369997 loss_rnnt 7.949573 hw_loss 0.243381 lr 0.00029150 rank 1
2023-03-01 07:01:38,144 DEBUG TRAIN Batch 51/500 loss 3.313666 loss_att 5.103261 loss_ctc 6.035912 loss_rnnt 2.431052 hw_loss 0.303240 lr 0.00029149 rank 5
2023-03-01 07:02:16,693 DEBUG TRAIN Batch 51/600 loss 6.653704 loss_att 8.665175 loss_ctc 10.144313 loss_rnnt 5.626122 hw_loss 0.299760 lr 0.00029149 rank 0
2023-03-01 07:02:16,697 DEBUG TRAIN Batch 51/600 loss 4.801176 loss_att 5.576916 loss_ctc 7.190330 loss_rnnt 4.235822 hw_loss 0.171846 lr 0.00029147 rank 7
2023-03-01 07:02:16,699 DEBUG TRAIN Batch 51/600 loss 5.450642 loss_att 7.857203 loss_ctc 9.781676 loss_rnnt 4.275629 hw_loss 0.217930 lr 0.00029149 rank 2
2023-03-01 07:02:16,699 DEBUG TRAIN Batch 51/600 loss 6.830173 loss_att 7.322837 loss_ctc 10.849395 loss_rnnt 6.049275 hw_loss 0.274630 lr 0.00029148 rank 5
2023-03-01 07:02:16,702 DEBUG TRAIN Batch 51/600 loss 11.510456 loss_att 14.175857 loss_ctc 20.918322 loss_rnnt 9.570866 hw_loss 0.285239 lr 0.00029148 rank 4
2023-03-01 07:02:16,704 DEBUG TRAIN Batch 51/600 loss 5.317620 loss_att 8.060925 loss_ctc 10.775718 loss_rnnt 3.852496 hw_loss 0.353843 lr 0.00029149 rank 1
2023-03-01 07:02:16,728 DEBUG TRAIN Batch 51/600 loss 9.563872 loss_att 11.135909 loss_ctc 13.662380 loss_rnnt 8.556663 hw_loss 0.274377 lr 0.00029148 rank 3
2023-03-01 07:02:16,771 DEBUG TRAIN Batch 51/600 loss 9.514992 loss_att 12.653362 loss_ctc 14.843979 loss_rnnt 8.124102 hw_loss 0.098783 lr 0.00029148 rank 6
2023-03-01 07:02:56,561 DEBUG TRAIN Batch 51/700 loss 8.983622 loss_att 11.154764 loss_ctc 12.574968 loss_rnnt 7.881360 hw_loss 0.354723 lr 0.00029147 rank 6
2023-03-01 07:02:56,563 DEBUG TRAIN Batch 51/700 loss 11.111455 loss_att 12.147444 loss_ctc 17.817917 loss_rnnt 9.912537 hw_loss 0.182859 lr 0.00029147 rank 5
2023-03-01 07:02:56,568 DEBUG TRAIN Batch 51/700 loss 5.611801 loss_att 11.843194 loss_ctc 11.097382 loss_rnnt 3.569295 hw_loss 0.121530 lr 0.00029146 rank 7
2023-03-01 07:02:56,568 DEBUG TRAIN Batch 51/700 loss 4.682525 loss_att 7.959866 loss_ctc 9.133257 loss_rnnt 3.313099 hw_loss 0.225988 lr 0.00029148 rank 0
2023-03-01 07:02:56,583 DEBUG TRAIN Batch 51/700 loss 2.260660 loss_att 4.337155 loss_ctc 2.584117 loss_rnnt 1.726786 hw_loss 0.141463 lr 0.00029147 rank 3
2023-03-01 07:02:56,597 DEBUG TRAIN Batch 51/700 loss 4.558046 loss_att 6.391446 loss_ctc 6.212498 loss_rnnt 3.907857 hw_loss 0.117967 lr 0.00029147 rank 1
2023-03-01 07:02:56,603 DEBUG TRAIN Batch 51/700 loss 8.080694 loss_att 8.440886 loss_ctc 16.554647 loss_rnnt 6.685224 hw_loss 0.362948 lr 0.00029148 rank 2
2023-03-01 07:02:56,603 DEBUG TRAIN Batch 51/700 loss 3.127719 loss_att 7.783857 loss_ctc 5.907467 loss_rnnt 1.777193 hw_loss 0.091247 lr 0.00029147 rank 4
2023-03-01 07:04:00,939 DEBUG TRAIN Batch 51/800 loss 8.585039 loss_att 10.438836 loss_ctc 13.356555 loss_rnnt 7.436268 hw_loss 0.265894 lr 0.00029145 rank 3
2023-03-01 07:04:00,951 DEBUG TRAIN Batch 51/800 loss 5.343559 loss_att 8.572396 loss_ctc 9.006196 loss_rnnt 4.083241 hw_loss 0.236621 lr 0.00029146 rank 1
2023-03-01 07:04:00,954 DEBUG TRAIN Batch 51/800 loss 9.447297 loss_att 15.771605 loss_ctc 17.460739 loss_rnnt 7.084586 hw_loss 0.055108 lr 0.00029146 rank 0
2023-03-01 07:04:00,954 DEBUG TRAIN Batch 51/800 loss 2.192077 loss_att 5.161052 loss_ctc 5.169759 loss_rnnt 1.098650 hw_loss 0.192390 lr 0.00029145 rank 7
2023-03-01 07:04:00,956 DEBUG TRAIN Batch 51/800 loss 8.978923 loss_att 10.726995 loss_ctc 12.479063 loss_rnnt 8.162306 hw_loss 0.000597 lr 0.00029146 rank 6
2023-03-01 07:04:00,958 DEBUG TRAIN Batch 51/800 loss 2.068286 loss_att 4.264346 loss_ctc 2.185667 loss_rnnt 1.375677 hw_loss 0.445773 lr 0.00029146 rank 5
2023-03-01 07:04:00,957 DEBUG TRAIN Batch 51/800 loss 4.803356 loss_att 7.405252 loss_ctc 7.761306 loss_rnnt 3.748367 hw_loss 0.262905 lr 0.00029146 rank 4
2023-03-01 07:04:00,966 DEBUG TRAIN Batch 51/800 loss 4.649403 loss_att 6.629721 loss_ctc 11.353786 loss_rnnt 3.311502 hw_loss 0.089848 lr 0.00029147 rank 2
2023-03-01 07:04:39,026 DEBUG TRAIN Batch 51/900 loss 3.230856 loss_att 7.572907 loss_ctc 8.014597 loss_rnnt 1.646183 hw_loss 0.147058 lr 0.00029145 rank 6
2023-03-01 07:04:39,029 DEBUG TRAIN Batch 51/900 loss 11.148753 loss_att 12.792914 loss_ctc 20.495106 loss_rnnt 9.462288 hw_loss 0.208972 lr 0.00029144 rank 3
2023-03-01 07:04:39,039 DEBUG TRAIN Batch 51/900 loss 3.190898 loss_att 6.548958 loss_ctc 4.937350 loss_rnnt 2.153403 hw_loss 0.249417 lr 0.00029144 rank 7
2023-03-01 07:04:39,041 DEBUG TRAIN Batch 51/900 loss 10.589090 loss_att 13.876781 loss_ctc 16.071409 loss_rnnt 9.012585 hw_loss 0.352484 lr 0.00029145 rank 4
2023-03-01 07:04:39,046 DEBUG TRAIN Batch 51/900 loss 4.986828 loss_att 9.848291 loss_ctc 9.773416 loss_rnnt 3.276435 hw_loss 0.187290 lr 0.00029145 rank 0
2023-03-01 07:04:39,049 DEBUG TRAIN Batch 51/900 loss 7.510694 loss_att 9.469914 loss_ctc 17.836716 loss_rnnt 5.627273 hw_loss 0.215200 lr 0.00029145 rank 2
2023-03-01 07:04:39,053 DEBUG TRAIN Batch 51/900 loss 3.382418 loss_att 6.119685 loss_ctc 8.790856 loss_rnnt 1.985925 hw_loss 0.239840 lr 0.00029145 rank 1
2023-03-01 07:04:39,065 DEBUG TRAIN Batch 51/900 loss 6.498014 loss_att 10.364086 loss_ctc 9.541229 loss_rnnt 5.268747 hw_loss 0.094293 lr 0.00029144 rank 5
2023-03-01 07:05:17,066 DEBUG TRAIN Batch 51/1000 loss 7.124320 loss_att 8.652464 loss_ctc 12.645667 loss_rnnt 5.972107 hw_loss 0.207009 lr 0.00029144 rank 1
2023-03-01 07:05:17,074 DEBUG TRAIN Batch 51/1000 loss 8.765779 loss_att 11.749846 loss_ctc 12.218200 loss_rnnt 7.563643 hw_loss 0.271877 lr 0.00029144 rank 4
2023-03-01 07:05:17,078 DEBUG TRAIN Batch 51/1000 loss 2.857563 loss_att 5.772758 loss_ctc 7.770437 loss_rnnt 1.484307 hw_loss 0.253437 lr 0.00029142 rank 7
2023-03-01 07:05:17,081 DEBUG TRAIN Batch 51/1000 loss 5.018497 loss_att 7.217623 loss_ctc 9.570895 loss_rnnt 3.844391 hw_loss 0.238677 lr 0.00029144 rank 0
2023-03-01 07:05:17,087 DEBUG TRAIN Batch 51/1000 loss 4.693009 loss_att 7.892536 loss_ctc 14.700669 loss_rnnt 2.635350 hw_loss 0.156374 lr 0.00029143 rank 6
2023-03-01 07:05:17,094 DEBUG TRAIN Batch 51/1000 loss 7.700921 loss_att 9.147739 loss_ctc 12.801423 loss_rnnt 6.633368 hw_loss 0.183979 lr 0.00029144 rank 2
2023-03-01 07:05:17,103 DEBUG TRAIN Batch 51/1000 loss 8.021892 loss_att 12.942560 loss_ctc 15.941417 loss_rnnt 5.909025 hw_loss 0.136491 lr 0.00029143 rank 5
2023-03-01 07:05:17,117 DEBUG TRAIN Batch 51/1000 loss 5.294139 loss_att 7.056574 loss_ctc 7.326713 loss_rnnt 4.566253 hw_loss 0.195731 lr 0.00029143 rank 3
2023-03-01 07:06:22,430 DEBUG TRAIN Batch 51/1100 loss 17.183317 loss_att 22.318604 loss_ctc 28.015598 loss_rnnt 14.589728 hw_loss 0.229171 lr 0.00029142 rank 5
2023-03-01 07:06:22,437 DEBUG TRAIN Batch 51/1100 loss 4.935000 loss_att 7.477111 loss_ctc 6.214268 loss_rnnt 4.112700 hw_loss 0.268705 lr 0.00029143 rank 0
2023-03-01 07:06:22,442 DEBUG TRAIN Batch 51/1100 loss 6.642859 loss_att 12.193461 loss_ctc 9.495003 loss_rnnt 5.019835 hw_loss 0.248659 lr 0.00029142 rank 1
2023-03-01 07:06:22,442 DEBUG TRAIN Batch 51/1100 loss 5.481896 loss_att 7.415902 loss_ctc 7.250017 loss_rnnt 4.811262 hw_loss 0.090156 lr 0.00029141 rank 7
2023-03-01 07:06:22,447 DEBUG TRAIN Batch 51/1100 loss 8.389397 loss_att 12.449575 loss_ctc 11.521912 loss_rnnt 7.090901 hw_loss 0.128981 lr 0.00029142 rank 3
2023-03-01 07:06:22,479 DEBUG TRAIN Batch 51/1100 loss 6.192652 loss_att 8.284825 loss_ctc 8.889824 loss_rnnt 5.245935 hw_loss 0.316234 lr 0.00029142 rank 4
2023-03-01 07:06:22,480 DEBUG TRAIN Batch 51/1100 loss 3.798395 loss_att 5.697814 loss_ctc 8.417413 loss_rnnt 2.735403 hw_loss 0.126074 lr 0.00029143 rank 2
2023-03-01 07:06:22,490 DEBUG TRAIN Batch 51/1100 loss 11.491062 loss_att 13.937588 loss_ctc 16.596825 loss_rnnt 10.230426 hw_loss 0.169806 lr 0.00029142 rank 6
2023-03-01 07:07:00,816 DEBUG TRAIN Batch 51/1200 loss 4.393318 loss_att 6.631512 loss_ctc 6.131528 loss_rnnt 3.557262 hw_loss 0.293729 lr 0.00029142 rank 2
2023-03-01 07:07:00,826 DEBUG TRAIN Batch 51/1200 loss 10.672297 loss_att 14.026493 loss_ctc 17.955950 loss_rnnt 8.899542 hw_loss 0.245178 lr 0.00029140 rank 7
2023-03-01 07:07:00,828 DEBUG TRAIN Batch 51/1200 loss 2.963017 loss_att 4.318014 loss_ctc 4.761387 loss_rnnt 2.247759 hw_loss 0.383392 lr 0.00029141 rank 0
2023-03-01 07:07:00,832 DEBUG TRAIN Batch 51/1200 loss 5.436680 loss_att 8.241074 loss_ctc 11.023207 loss_rnnt 3.917484 hw_loss 0.400212 lr 0.00029141 rank 5
2023-03-01 07:07:00,833 DEBUG TRAIN Batch 51/1200 loss 7.892451 loss_att 10.540527 loss_ctc 10.253988 loss_rnnt 6.942402 hw_loss 0.197929 lr 0.00029140 rank 3
2023-03-01 07:07:00,864 DEBUG TRAIN Batch 51/1200 loss 2.821621 loss_att 4.930406 loss_ctc 5.982675 loss_rnnt 1.815652 hw_loss 0.305135 lr 0.00029141 rank 6
2023-03-01 07:07:00,872 DEBUG TRAIN Batch 51/1200 loss 11.384096 loss_att 12.654764 loss_ctc 15.916848 loss_rnnt 10.382698 hw_loss 0.267934 lr 0.00029141 rank 4
2023-03-01 07:07:00,876 DEBUG TRAIN Batch 51/1200 loss 7.941388 loss_att 11.928612 loss_ctc 15.145370 loss_rnnt 6.116830 hw_loss 0.124841 lr 0.00029141 rank 1
2023-03-01 07:07:39,369 DEBUG TRAIN Batch 51/1300 loss 4.474190 loss_att 8.129364 loss_ctc 8.345022 loss_rnnt 3.075727 hw_loss 0.283719 lr 0.00029140 rank 5
2023-03-01 07:07:39,372 DEBUG TRAIN Batch 51/1300 loss 1.261911 loss_att 3.518138 loss_ctc 2.271910 loss_rnnt 0.596320 hw_loss 0.149399 lr 0.00029139 rank 3
2023-03-01 07:07:39,376 DEBUG TRAIN Batch 51/1300 loss 6.435708 loss_att 9.057421 loss_ctc 14.604054 loss_rnnt 4.691228 hw_loss 0.245670 lr 0.00029139 rank 7
2023-03-01 07:07:39,378 DEBUG TRAIN Batch 51/1300 loss 13.607471 loss_att 16.290840 loss_ctc 17.389368 loss_rnnt 12.419165 hw_loss 0.276338 lr 0.00029140 rank 4
2023-03-01 07:07:39,381 DEBUG TRAIN Batch 51/1300 loss 6.691115 loss_att 7.430711 loss_ctc 9.068117 loss_rnnt 6.082317 hw_loss 0.269896 lr 0.00029140 rank 0
2023-03-01 07:07:39,384 DEBUG TRAIN Batch 51/1300 loss 6.164002 loss_att 7.283946 loss_ctc 11.813269 loss_rnnt 4.995457 hw_loss 0.358727 lr 0.00029140 rank 1
2023-03-01 07:07:39,391 DEBUG TRAIN Batch 51/1300 loss 5.826008 loss_att 8.919549 loss_ctc 9.307859 loss_rnnt 4.613910 hw_loss 0.242144 lr 0.00029140 rank 6
2023-03-01 07:07:39,397 DEBUG TRAIN Batch 51/1300 loss 2.776064 loss_att 7.122239 loss_ctc 5.899358 loss_rnnt 1.366122 hw_loss 0.233002 lr 0.00029140 rank 2
2023-03-01 07:08:18,355 DEBUG TRAIN Batch 51/1400 loss 5.684295 loss_att 7.392052 loss_ctc 9.374104 loss_rnnt 4.680334 hw_loss 0.319564 lr 0.00029137 rank 7
2023-03-01 07:08:18,364 DEBUG TRAIN Batch 51/1400 loss 13.390203 loss_att 15.161748 loss_ctc 18.820436 loss_rnnt 12.196513 hw_loss 0.216278 lr 0.00029139 rank 0
2023-03-01 07:08:18,371 DEBUG TRAIN Batch 51/1400 loss 1.771490 loss_att 3.993850 loss_ctc 2.060957 loss_rnnt 1.130661 hw_loss 0.295803 lr 0.00029138 rank 5
2023-03-01 07:08:18,372 DEBUG TRAIN Batch 51/1400 loss 8.397432 loss_att 12.166874 loss_ctc 12.734207 loss_rnnt 7.048180 hw_loss 0.032114 lr 0.00029138 rank 3
2023-03-01 07:08:18,373 DEBUG TRAIN Batch 51/1400 loss 4.089353 loss_att 8.282039 loss_ctc 6.623420 loss_rnnt 2.842520 hw_loss 0.132038 lr 0.00029138 rank 6
2023-03-01 07:08:18,376 DEBUG TRAIN Batch 51/1400 loss 1.545444 loss_att 3.345158 loss_ctc 3.942636 loss_rnnt 0.751895 hw_loss 0.213712 lr 0.00029139 rank 4
2023-03-01 07:08:18,379 DEBUG TRAIN Batch 51/1400 loss 3.506010 loss_att 5.711174 loss_ctc 7.178881 loss_rnnt 2.427033 hw_loss 0.277926 lr 0.00029139 rank 1
2023-03-01 07:08:18,417 DEBUG TRAIN Batch 51/1400 loss 1.911298 loss_att 5.133015 loss_ctc 3.992742 loss_rnnt 0.807783 hw_loss 0.340584 lr 0.00029139 rank 2
2023-03-01 07:09:22,063 DEBUG TRAIN Batch 51/1500 loss 10.685541 loss_att 12.704047 loss_ctc 18.717875 loss_rnnt 9.066725 hw_loss 0.270258 lr 0.00029137 rank 4
2023-03-01 07:09:22,076 DEBUG TRAIN Batch 51/1500 loss 2.666304 loss_att 5.813249 loss_ctc 3.845057 loss_rnnt 1.782750 hw_loss 0.181871 lr 0.00029137 rank 1
2023-03-01 07:09:22,076 DEBUG TRAIN Batch 51/1500 loss 4.404148 loss_att 7.126535 loss_ctc 10.583332 loss_rnnt 2.973962 hw_loss 0.115907 lr 0.00029138 rank 2
2023-03-01 07:09:22,078 DEBUG TRAIN Batch 51/1500 loss 2.604850 loss_att 5.388642 loss_ctc 5.217508 loss_rnnt 1.467219 hw_loss 0.435972 lr 0.00029137 rank 6
2023-03-01 07:09:22,080 DEBUG TRAIN Batch 51/1500 loss 8.090016 loss_att 13.121017 loss_ctc 14.320049 loss_rnnt 6.124858 hw_loss 0.240539 lr 0.00029138 rank 0
2023-03-01 07:09:22,080 DEBUG TRAIN Batch 51/1500 loss 6.729155 loss_att 11.824006 loss_ctc 11.180519 loss_rnnt 4.997403 hw_loss 0.223624 lr 0.00029136 rank 7
2023-03-01 07:09:22,086 DEBUG TRAIN Batch 51/1500 loss 7.737391 loss_att 9.051300 loss_ctc 8.516700 loss_rnnt 7.263939 hw_loss 0.200181 lr 0.00029137 rank 5
2023-03-01 07:09:22,095 DEBUG TRAIN Batch 51/1500 loss 6.325375 loss_att 11.652887 loss_ctc 13.505388 loss_rnnt 4.226766 hw_loss 0.142071 lr 0.00029137 rank 3
2023-03-01 07:10:00,185 DEBUG TRAIN Batch 51/1600 loss 3.868138 loss_att 7.583628 loss_ctc 8.860428 loss_rnnt 2.311713 hw_loss 0.276917 lr 0.00029137 rank 2
2023-03-01 07:10:00,189 DEBUG TRAIN Batch 51/1600 loss 4.640700 loss_att 7.304108 loss_ctc 12.354347 loss_rnnt 2.995298 hw_loss 0.157940 lr 0.00029136 rank 0
2023-03-01 07:10:00,191 DEBUG TRAIN Batch 51/1600 loss 14.590478 loss_att 16.257420 loss_ctc 21.679615 loss_rnnt 13.197848 hw_loss 0.213796 lr 0.00029135 rank 7
2023-03-01 07:10:00,203 DEBUG TRAIN Batch 51/1600 loss 5.863684 loss_att 11.419498 loss_ctc 12.889620 loss_rnnt 3.709222 hw_loss 0.199700 lr 0.00029135 rank 3
2023-03-01 07:10:00,204 DEBUG TRAIN Batch 51/1600 loss 1.884668 loss_att 4.118117 loss_ctc 4.021533 loss_rnnt 1.058990 hw_loss 0.176387 lr 0.00029136 rank 1
2023-03-01 07:10:00,205 DEBUG TRAIN Batch 51/1600 loss 4.258640 loss_att 6.354774 loss_ctc 5.378448 loss_rnnt 3.557113 hw_loss 0.249361 lr 0.00029136 rank 5
2023-03-01 07:10:00,206 DEBUG TRAIN Batch 51/1600 loss 7.518797 loss_att 8.702870 loss_ctc 12.072840 loss_rnnt 6.528381 hw_loss 0.274492 lr 0.00029136 rank 4
2023-03-01 07:10:00,257 DEBUG TRAIN Batch 51/1600 loss 6.509456 loss_att 12.112585 loss_ctc 15.546478 loss_rnnt 4.084379 hw_loss 0.186588 lr 0.00029136 rank 6
2023-03-01 07:10:38,677 DEBUG TRAIN Batch 51/1700 loss 6.664503 loss_att 10.344485 loss_ctc 11.397665 loss_rnnt 5.163515 hw_loss 0.251068 lr 0.00029135 rank 1
2023-03-01 07:10:38,693 DEBUG TRAIN Batch 51/1700 loss 4.389255 loss_att 6.645131 loss_ctc 8.832472 loss_rnnt 3.279161 hw_loss 0.124668 lr 0.00029135 rank 5
2023-03-01 07:10:38,696 DEBUG TRAIN Batch 51/1700 loss 9.493486 loss_att 11.904471 loss_ctc 12.605753 loss_rnnt 8.380929 hw_loss 0.403857 lr 0.00029135 rank 0
2023-03-01 07:10:38,696 DEBUG TRAIN Batch 51/1700 loss 4.328202 loss_att 6.255197 loss_ctc 4.641941 loss_rnnt 3.692389 hw_loss 0.391090 lr 0.00029134 rank 3
2023-03-01 07:10:38,698 DEBUG TRAIN Batch 51/1700 loss 6.132565 loss_att 8.043953 loss_ctc 8.084582 loss_rnnt 5.411765 hw_loss 0.146723 lr 0.00029135 rank 4
2023-03-01 07:10:38,699 DEBUG TRAIN Batch 51/1700 loss 6.307605 loss_att 7.126082 loss_ctc 7.298352 loss_rnnt 5.819994 hw_loss 0.359656 lr 0.00029135 rank 6
2023-03-01 07:10:38,700 DEBUG TRAIN Batch 51/1700 loss 3.240268 loss_att 5.560797 loss_ctc 3.552191 loss_rnnt 2.695191 hw_loss 0.073840 lr 0.00029135 rank 2
2023-03-01 07:10:38,708 DEBUG TRAIN Batch 51/1700 loss 4.187406 loss_att 7.966079 loss_ctc 6.829271 loss_rnnt 3.006101 hw_loss 0.137478 lr 0.00029134 rank 7
2023-03-01 07:11:44,569 DEBUG TRAIN Batch 51/1800 loss 2.766311 loss_att 5.202268 loss_ctc 5.629964 loss_rnnt 1.746744 hw_loss 0.282293 lr 0.00029134 rank 6
2023-03-01 07:11:44,579 DEBUG TRAIN Batch 51/1800 loss 5.936658 loss_att 8.095351 loss_ctc 8.911011 loss_rnnt 5.022589 hw_loss 0.160781 lr 0.00029134 rank 2
2023-03-01 07:11:44,584 DEBUG TRAIN Batch 51/1800 loss 5.484022 loss_att 7.254920 loss_ctc 9.761162 loss_rnnt 4.508624 hw_loss 0.095500 lr 0.00029132 rank 7
2023-03-01 07:11:44,585 DEBUG TRAIN Batch 51/1800 loss 4.992332 loss_att 7.269632 loss_ctc 4.886047 loss_rnnt 4.458038 hw_loss 0.174384 lr 0.00029134 rank 0
2023-03-01 07:11:44,592 DEBUG TRAIN Batch 51/1800 loss 9.975283 loss_att 12.151525 loss_ctc 18.084249 loss_rnnt 8.329269 hw_loss 0.242942 lr 0.00029134 rank 4
2023-03-01 07:11:44,620 DEBUG TRAIN Batch 51/1800 loss 13.573430 loss_att 16.429855 loss_ctc 22.936853 loss_rnnt 11.589941 hw_loss 0.307027 lr 0.00029133 rank 3
2023-03-01 07:11:44,626 DEBUG TRAIN Batch 51/1800 loss 6.193592 loss_att 8.707193 loss_ctc 9.953348 loss_rnnt 5.074356 hw_loss 0.216029 lr 0.00029134 rank 1
2023-03-01 07:11:44,633 DEBUG TRAIN Batch 51/1800 loss 2.801429 loss_att 4.940585 loss_ctc 3.248914 loss_rnnt 2.201327 hw_loss 0.211135 lr 0.00029133 rank 5
2023-03-01 07:12:23,126 DEBUG TRAIN Batch 51/1900 loss 5.164797 loss_att 8.190194 loss_ctc 13.218042 loss_rnnt 3.459677 hw_loss 0.049263 lr 0.00029133 rank 2
2023-03-01 07:12:23,129 DEBUG TRAIN Batch 51/1900 loss 2.911657 loss_att 4.676638 loss_ctc 4.413503 loss_rnnt 2.162488 hw_loss 0.367363 lr 0.00029132 rank 6
2023-03-01 07:12:23,141 DEBUG TRAIN Batch 51/1900 loss 6.332605 loss_att 7.492711 loss_ctc 11.044106 loss_rnnt 5.316770 hw_loss 0.291776 lr 0.00029132 rank 4
2023-03-01 07:12:23,143 DEBUG TRAIN Batch 51/1900 loss 7.297786 loss_att 8.563922 loss_ctc 10.890277 loss_rnnt 6.376538 hw_loss 0.354414 lr 0.00029133 rank 1
2023-03-01 07:12:23,145 DEBUG TRAIN Batch 51/1900 loss 9.087422 loss_att 10.109555 loss_ctc 12.222663 loss_rnnt 8.337166 hw_loss 0.239620 lr 0.00029133 rank 0
2023-03-01 07:12:23,145 DEBUG TRAIN Batch 51/1900 loss 11.046370 loss_att 10.667995 loss_ctc 14.461324 loss_rnnt 10.529648 hw_loss 0.257003 lr 0.00029132 rank 5
2023-03-01 07:12:23,147 DEBUG TRAIN Batch 51/1900 loss 4.295092 loss_att 6.770005 loss_ctc 6.790068 loss_rnnt 3.319224 hw_loss 0.277915 lr 0.00029131 rank 7
2023-03-01 07:12:23,148 DEBUG TRAIN Batch 51/1900 loss 3.609591 loss_att 5.880521 loss_ctc 5.846663 loss_rnnt 2.753780 hw_loss 0.193780 lr 0.00029132 rank 3
2023-03-01 07:13:01,428 DEBUG TRAIN Batch 51/2000 loss 4.484082 loss_att 8.734219 loss_ctc 8.936651 loss_rnnt 2.876525 hw_loss 0.307226 lr 0.00029130 rank 7
2023-03-01 07:13:01,432 DEBUG TRAIN Batch 51/2000 loss 3.334294 loss_att 5.632945 loss_ctc 6.787879 loss_rnnt 2.292622 hw_loss 0.227745 lr 0.00029131 rank 0
2023-03-01 07:13:01,448 DEBUG TRAIN Batch 51/2000 loss 5.746988 loss_att 10.166252 loss_ctc 10.981743 loss_rnnt 4.086116 hw_loss 0.148223 lr 0.00029132 rank 2
2023-03-01 07:13:01,449 DEBUG TRAIN Batch 51/2000 loss 6.338263 loss_att 8.967776 loss_ctc 10.562901 loss_rnnt 5.105440 hw_loss 0.269315 lr 0.00029131 rank 6
2023-03-01 07:13:01,451 DEBUG TRAIN Batch 51/2000 loss 3.850733 loss_att 5.539630 loss_ctc 5.932288 loss_rnnt 3.148505 hw_loss 0.162952 lr 0.00029131 rank 3
2023-03-01 07:13:01,451 DEBUG TRAIN Batch 51/2000 loss 10.004127 loss_att 13.771112 loss_ctc 15.023700 loss_rnnt 8.541283 hw_loss 0.075319 lr 0.00029131 rank 5
2023-03-01 07:13:01,452 DEBUG TRAIN Batch 51/2000 loss 5.183556 loss_att 8.749500 loss_ctc 8.650008 loss_rnnt 3.841145 hw_loss 0.313178 lr 0.00029131 rank 1
2023-03-01 07:13:01,452 DEBUG TRAIN Batch 51/2000 loss 7.822392 loss_att 10.972382 loss_ctc 15.701265 loss_rnnt 5.984783 hw_loss 0.294553 lr 0.00029131 rank 4
2023-03-01 07:13:40,659 DEBUG TRAIN Batch 51/2100 loss 4.951104 loss_att 7.411340 loss_ctc 5.416528 loss_rnnt 4.234431 hw_loss 0.304816 lr 0.00029130 rank 0
2023-03-01 07:13:40,661 DEBUG TRAIN Batch 51/2100 loss 4.451072 loss_att 9.346704 loss_ctc 8.254796 loss_rnnt 2.830616 hw_loss 0.251562 lr 0.00029130 rank 1
2023-03-01 07:13:40,669 DEBUG TRAIN Batch 51/2100 loss 4.898757 loss_att 7.253593 loss_ctc 17.175594 loss_rnnt 2.689459 hw_loss 0.190160 lr 0.00029130 rank 2
2023-03-01 07:13:40,671 DEBUG TRAIN Batch 51/2100 loss 9.807774 loss_att 12.491593 loss_ctc 18.814407 loss_rnnt 7.853668 hw_loss 0.405858 lr 0.00029129 rank 7
2023-03-01 07:13:40,677 DEBUG TRAIN Batch 51/2100 loss 6.726944 loss_att 9.621206 loss_ctc 11.845134 loss_rnnt 5.335399 hw_loss 0.244252 lr 0.00029130 rank 6
2023-03-01 07:13:40,679 DEBUG TRAIN Batch 51/2100 loss 5.067331 loss_att 7.705279 loss_ctc 6.629954 loss_rnnt 4.226124 hw_loss 0.197378 lr 0.00029129 rank 3
2023-03-01 07:13:40,693 DEBUG TRAIN Batch 51/2100 loss 1.637604 loss_att 3.991388 loss_ctc 4.199039 loss_rnnt 0.654049 hw_loss 0.321137 lr 0.00029130 rank 5
2023-03-01 07:13:40,704 DEBUG TRAIN Batch 51/2100 loss 4.408108 loss_att 6.288360 loss_ctc 7.970923 loss_rnnt 3.473305 hw_loss 0.156958 lr 0.00029130 rank 4
2023-03-01 07:14:47,013 DEBUG TRAIN Batch 51/2200 loss 7.396169 loss_att 10.236340 loss_ctc 9.448763 loss_rnnt 6.416819 hw_loss 0.258071 lr 0.00029129 rank 2
2023-03-01 07:14:47,023 DEBUG TRAIN Batch 51/2200 loss 5.998310 loss_att 10.066652 loss_ctc 9.058257 loss_rnnt 4.677678 hw_loss 0.185569 lr 0.00029129 rank 0
2023-03-01 07:14:47,026 DEBUG TRAIN Batch 51/2200 loss 3.392854 loss_att 6.419104 loss_ctc 7.171550 loss_rnnt 2.215219 hw_loss 0.128548 lr 0.00029128 rank 5
2023-03-01 07:14:47,028 DEBUG TRAIN Batch 51/2200 loss 3.874516 loss_att 6.963899 loss_ctc 7.050761 loss_rnnt 2.744625 hw_loss 0.165967 lr 0.00029128 rank 7
2023-03-01 07:14:47,029 DEBUG TRAIN Batch 51/2200 loss 3.792798 loss_att 6.981918 loss_ctc 8.081854 loss_rnnt 2.563808 hw_loss 0.036172 lr 0.00029129 rank 4
2023-03-01 07:14:47,029 DEBUG TRAIN Batch 51/2200 loss 3.263402 loss_att 5.478497 loss_ctc 5.156069 loss_rnnt 2.450292 hw_loss 0.220753 lr 0.00029129 rank 6
2023-03-01 07:14:47,029 DEBUG TRAIN Batch 51/2200 loss 7.378845 loss_att 10.284809 loss_ctc 10.695509 loss_rnnt 6.283439 hw_loss 0.134984 lr 0.00029128 rank 3
2023-03-01 07:14:47,075 DEBUG TRAIN Batch 51/2200 loss 5.416365 loss_att 7.388377 loss_ctc 5.336233 loss_rnnt 4.938501 hw_loss 0.176522 lr 0.00029129 rank 1
2023-03-01 07:15:24,911 DEBUG TRAIN Batch 51/2300 loss 9.244995 loss_att 12.948927 loss_ctc 13.755109 loss_rnnt 7.804957 hw_loss 0.183567 lr 0.00029128 rank 0
2023-03-01 07:15:24,911 DEBUG TRAIN Batch 51/2300 loss 9.463523 loss_att 10.345140 loss_ctc 13.542859 loss_rnnt 8.621339 hw_loss 0.228654 lr 0.00029128 rank 1
2023-03-01 07:15:24,913 DEBUG TRAIN Batch 51/2300 loss 8.666372 loss_att 11.607302 loss_ctc 14.762497 loss_rnnt 7.170355 hw_loss 0.178153 lr 0.00029127 rank 5
2023-03-01 07:15:24,915 DEBUG TRAIN Batch 51/2300 loss 2.732852 loss_att 5.520584 loss_ctc 5.408383 loss_rnnt 1.668010 hw_loss 0.282298 lr 0.00029126 rank 7
2023-03-01 07:15:24,915 DEBUG TRAIN Batch 51/2300 loss 8.182329 loss_att 10.715982 loss_ctc 12.380587 loss_rnnt 6.982020 hw_loss 0.250894 lr 0.00029128 rank 2
2023-03-01 07:15:24,918 DEBUG TRAIN Batch 51/2300 loss 7.725454 loss_att 15.961210 loss_ctc 21.848337 loss_rnnt 4.018824 hw_loss 0.330803 lr 0.00029127 rank 4
2023-03-01 07:15:24,921 DEBUG TRAIN Batch 51/2300 loss 10.895624 loss_att 12.403471 loss_ctc 18.443630 loss_rnnt 9.406376 hw_loss 0.339897 lr 0.00029127 rank 6
2023-03-01 07:15:24,944 DEBUG TRAIN Batch 51/2300 loss 9.764709 loss_att 14.906818 loss_ctc 16.465088 loss_rnnt 7.665251 hw_loss 0.333098 lr 0.00029127 rank 3
2023-03-01 07:16:03,460 DEBUG TRAIN Batch 51/2400 loss 5.984617 loss_att 11.056441 loss_ctc 10.713568 loss_rnnt 4.221355 hw_loss 0.221942 lr 0.00029126 rank 1
2023-03-01 07:16:03,470 DEBUG TRAIN Batch 51/2400 loss 3.931936 loss_att 8.053617 loss_ctc 10.338834 loss_rnnt 2.178938 hw_loss 0.139515 lr 0.00029126 rank 3
2023-03-01 07:16:03,480 DEBUG TRAIN Batch 51/2400 loss 4.353805 loss_att 6.092099 loss_ctc 5.838684 loss_rnnt 3.656715 hw_loss 0.283963 lr 0.00029127 rank 2
2023-03-01 07:16:03,483 DEBUG TRAIN Batch 51/2400 loss 3.443160 loss_att 6.773518 loss_ctc 6.039439 loss_rnnt 2.353910 hw_loss 0.144390 lr 0.00029125 rank 7
2023-03-01 07:16:03,484 DEBUG TRAIN Batch 51/2400 loss 4.247685 loss_att 6.670088 loss_ctc 9.348999 loss_rnnt 3.015265 hw_loss 0.127058 lr 0.00029126 rank 4
2023-03-01 07:16:03,484 DEBUG TRAIN Batch 51/2400 loss 3.589879 loss_att 5.316603 loss_ctc 4.814774 loss_rnnt 2.928887 hw_loss 0.285615 lr 0.00029126 rank 6
2023-03-01 07:16:03,486 DEBUG TRAIN Batch 51/2400 loss 5.427901 loss_att 6.470393 loss_ctc 8.627466 loss_rnnt 4.646986 hw_loss 0.273389 lr 0.00029127 rank 0
2023-03-01 07:16:03,537 DEBUG TRAIN Batch 51/2400 loss 6.405958 loss_att 10.963290 loss_ctc 15.778095 loss_rnnt 4.135875 hw_loss 0.204371 lr 0.00029126 rank 5
2023-03-01 07:17:10,798 DEBUG TRAIN Batch 51/2500 loss 4.730252 loss_att 6.822343 loss_ctc 6.483697 loss_rnnt 3.931185 hw_loss 0.275355 lr 0.00029125 rank 0
2023-03-01 07:17:10,801 DEBUG TRAIN Batch 51/2500 loss 6.304151 loss_att 7.869222 loss_ctc 8.748965 loss_rnnt 5.551183 hw_loss 0.213710 lr 0.00029125 rank 1
2023-03-01 07:17:10,803 DEBUG TRAIN Batch 51/2500 loss 6.426381 loss_att 9.443105 loss_ctc 12.645960 loss_rnnt 4.859854 hw_loss 0.251070 lr 0.00029124 rank 7
2023-03-01 07:17:10,803 DEBUG TRAIN Batch 51/2500 loss 5.211316 loss_att 6.788912 loss_ctc 6.891505 loss_rnnt 4.538954 hw_loss 0.249033 lr 0.00029125 rank 5
2023-03-01 07:17:10,804 DEBUG TRAIN Batch 51/2500 loss 6.075993 loss_att 7.680806 loss_ctc 11.136106 loss_rnnt 4.878663 hw_loss 0.378160 lr 0.00029125 rank 2
2023-03-01 07:17:10,807 DEBUG TRAIN Batch 51/2500 loss 9.822429 loss_att 11.160737 loss_ctc 17.838928 loss_rnnt 8.304249 hw_loss 0.340598 lr 0.00029125 rank 6
2023-03-01 07:17:10,810 DEBUG TRAIN Batch 51/2500 loss 6.544360 loss_att 11.094605 loss_ctc 12.551681 loss_rnnt 4.732700 hw_loss 0.188692 lr 0.00029125 rank 4
2023-03-01 07:17:10,857 DEBUG TRAIN Batch 51/2500 loss 4.335020 loss_att 4.516830 loss_ctc 6.940977 loss_rnnt 3.768193 hw_loss 0.343132 lr 0.00029124 rank 3
2023-03-01 07:17:49,159 DEBUG TRAIN Batch 51/2600 loss 2.476309 loss_att 6.744491 loss_ctc 4.465427 loss_rnnt 1.242071 hw_loss 0.216349 lr 0.00029123 rank 7
2023-03-01 07:17:49,160 DEBUG TRAIN Batch 51/2600 loss 2.905612 loss_att 6.492389 loss_ctc 6.166086 loss_rnnt 1.708935 hw_loss 0.083607 lr 0.00029124 rank 0
2023-03-01 07:17:49,180 DEBUG TRAIN Batch 51/2600 loss 13.806069 loss_att 15.447393 loss_ctc 28.013182 loss_rnnt 11.419510 hw_loss 0.307523 lr 0.00029124 rank 2
2023-03-01 07:17:49,181 DEBUG TRAIN Batch 51/2600 loss 7.768481 loss_att 7.070889 loss_ctc 10.308286 loss_rnnt 7.396045 hw_loss 0.324965 lr 0.00029124 rank 4
2023-03-01 07:17:49,182 DEBUG TRAIN Batch 51/2600 loss 3.956787 loss_att 6.074580 loss_ctc 5.000475 loss_rnnt 3.307546 hw_loss 0.162233 lr 0.00029124 rank 6
2023-03-01 07:17:49,187 DEBUG TRAIN Batch 51/2600 loss 9.197536 loss_att 12.965967 loss_ctc 14.628120 loss_rnnt 7.629669 hw_loss 0.168942 lr 0.00029123 rank 3
2023-03-01 07:17:49,189 DEBUG TRAIN Batch 51/2600 loss 3.306868 loss_att 5.655017 loss_ctc 4.594183 loss_rnnt 2.518264 hw_loss 0.276247 lr 0.00029123 rank 5
2023-03-01 07:17:49,232 DEBUG TRAIN Batch 51/2600 loss 4.918620 loss_att 8.656757 loss_ctc 10.871031 loss_rnnt 3.271262 hw_loss 0.198892 lr 0.00029124 rank 1
2023-03-01 07:18:27,863 DEBUG TRAIN Batch 51/2700 loss 1.100735 loss_att 3.297394 loss_ctc 1.229261 loss_rnnt 0.489432 hw_loss 0.290314 lr 0.00029123 rank 1
2023-03-01 07:18:27,863 DEBUG TRAIN Batch 51/2700 loss 10.414645 loss_att 14.044355 loss_ctc 12.448818 loss_rnnt 9.287943 hw_loss 0.242881 lr 0.00029122 rank 5
2023-03-01 07:18:27,875 DEBUG TRAIN Batch 51/2700 loss 11.837841 loss_att 15.759769 loss_ctc 17.311014 loss_rnnt 10.294574 hw_loss 0.054613 lr 0.00029122 rank 6
2023-03-01 07:18:27,876 DEBUG TRAIN Batch 51/2700 loss 7.323578 loss_att 12.188566 loss_ctc 13.052440 loss_rnnt 5.446161 hw_loss 0.263573 lr 0.00029121 rank 7
2023-03-01 07:18:27,879 DEBUG TRAIN Batch 51/2700 loss 8.562003 loss_att 10.027813 loss_ctc 14.118915 loss_rnnt 7.452384 hw_loss 0.141631 lr 0.00029123 rank 0
2023-03-01 07:18:27,879 DEBUG TRAIN Batch 51/2700 loss 5.878144 loss_att 9.885984 loss_ctc 10.111465 loss_rnnt 4.463325 hw_loss 0.091516 lr 0.00029122 rank 3
2023-03-01 07:18:27,887 DEBUG TRAIN Batch 51/2700 loss 7.400268 loss_att 9.458755 loss_ctc 10.055864 loss_rnnt 6.529750 hw_loss 0.196389 lr 0.00029123 rank 2
2023-03-01 07:18:27,898 DEBUG TRAIN Batch 51/2700 loss 3.647688 loss_att 6.065289 loss_ctc 7.786278 loss_rnnt 2.478368 hw_loss 0.251226 lr 0.00029123 rank 4
2023-03-01 07:19:07,096 DEBUG TRAIN Batch 51/2800 loss 5.197114 loss_att 8.939683 loss_ctc 9.846169 loss_rnnt 3.709622 hw_loss 0.223318 lr 0.00029121 rank 4
2023-03-01 07:19:07,102 DEBUG TRAIN Batch 51/2800 loss 2.545830 loss_att 5.947265 loss_ctc 4.024016 loss_rnnt 1.595174 hw_loss 0.137394 lr 0.00029121 rank 1
2023-03-01 07:19:07,110 DEBUG TRAIN Batch 51/2800 loss 11.391389 loss_att 18.140495 loss_ctc 21.219839 loss_rnnt 8.625796 hw_loss 0.197459 lr 0.00029121 rank 5
2023-03-01 07:19:07,111 DEBUG TRAIN Batch 51/2800 loss 3.177144 loss_att 5.809703 loss_ctc 4.304254 loss_rnnt 2.435695 hw_loss 0.121230 lr 0.00029121 rank 6
2023-03-01 07:19:07,114 DEBUG TRAIN Batch 51/2800 loss 7.854225 loss_att 10.933247 loss_ctc 11.169181 loss_rnnt 6.668051 hw_loss 0.240705 lr 0.00029122 rank 0
2023-03-01 07:19:07,114 DEBUG TRAIN Batch 51/2800 loss 5.256638 loss_att 10.994217 loss_ctc 5.134667 loss_rnnt 3.935800 hw_loss 0.355470 lr 0.00029122 rank 2
2023-03-01 07:19:07,116 DEBUG TRAIN Batch 51/2800 loss 7.277012 loss_att 11.277636 loss_ctc 12.190067 loss_rnnt 5.729742 hw_loss 0.172631 lr 0.00029121 rank 3
2023-03-01 07:19:07,119 DEBUG TRAIN Batch 51/2800 loss 4.845433 loss_att 7.150223 loss_ctc 7.942169 loss_rnnt 3.873408 hw_loss 0.184067 lr 0.00029120 rank 7
2023-03-01 07:20:12,590 DEBUG TRAIN Batch 51/2900 loss 10.319081 loss_att 16.733528 loss_ctc 23.237072 loss_rnnt 7.247138 hw_loss 0.124975 lr 0.00029120 rank 5
2023-03-01 07:20:12,600 DEBUG TRAIN Batch 51/2900 loss 6.000367 loss_att 8.749852 loss_ctc 8.472507 loss_rnnt 4.950907 hw_loss 0.318645 lr 0.00029119 rank 3
2023-03-01 07:20:12,605 DEBUG TRAIN Batch 51/2900 loss 8.015490 loss_att 9.710218 loss_ctc 12.873905 loss_rnnt 6.958033 hw_loss 0.132604 lr 0.00029120 rank 1
2023-03-01 07:20:12,611 DEBUG TRAIN Batch 51/2900 loss 4.271793 loss_att 7.201783 loss_ctc 7.217048 loss_rnnt 3.211505 hw_loss 0.152980 lr 0.00029120 rank 0
2023-03-01 07:20:12,613 DEBUG TRAIN Batch 51/2900 loss 13.531666 loss_att 16.242573 loss_ctc 15.531353 loss_rnnt 12.650809 hw_loss 0.135095 lr 0.00029119 rank 7
2023-03-01 07:20:12,617 DEBUG TRAIN Batch 51/2900 loss 8.085119 loss_att 12.129950 loss_ctc 10.196142 loss_rnnt 6.883877 hw_loss 0.207760 lr 0.00029121 rank 2
2023-03-01 07:20:12,620 DEBUG TRAIN Batch 51/2900 loss 5.614613 loss_att 9.453997 loss_ctc 9.487477 loss_rnnt 4.226382 hw_loss 0.194948 lr 0.00029120 rank 4
2023-03-01 07:20:12,665 DEBUG TRAIN Batch 51/2900 loss 4.972559 loss_att 8.194748 loss_ctc 8.999038 loss_rnnt 3.706882 hw_loss 0.158205 lr 0.00029120 rank 6
2023-03-01 07:20:50,957 DEBUG TRAIN Batch 51/3000 loss 6.310095 loss_att 8.591290 loss_ctc 12.620810 loss_rnnt 4.866809 hw_loss 0.273035 lr 0.00029119 rank 5
2023-03-01 07:20:50,966 DEBUG TRAIN Batch 51/3000 loss 7.822046 loss_att 8.700576 loss_ctc 9.841605 loss_rnnt 7.257431 hw_loss 0.224316 lr 0.00029119 rank 2
2023-03-01 07:20:50,970 DEBUG TRAIN Batch 51/3000 loss 7.250216 loss_att 10.305095 loss_ctc 10.213795 loss_rnnt 6.118883 hw_loss 0.234775 lr 0.00029118 rank 7
2023-03-01 07:20:50,970 DEBUG TRAIN Batch 51/3000 loss 11.235153 loss_att 13.920963 loss_ctc 22.435150 loss_rnnt 9.090210 hw_loss 0.214590 lr 0.00029119 rank 0
2023-03-01 07:20:50,973 DEBUG TRAIN Batch 51/3000 loss 8.766362 loss_att 12.014177 loss_ctc 13.505975 loss_rnnt 7.328537 hw_loss 0.293089 lr 0.00029119 rank 4
2023-03-01 07:20:50,974 DEBUG TRAIN Batch 51/3000 loss 11.557076 loss_att 15.559629 loss_ctc 15.901515 loss_rnnt 10.081228 hw_loss 0.180149 lr 0.00029119 rank 1
2023-03-01 07:20:50,974 DEBUG TRAIN Batch 51/3000 loss 7.124099 loss_att 10.834655 loss_ctc 12.119839 loss_rnnt 5.555400 hw_loss 0.300917 lr 0.00029119 rank 6
2023-03-01 07:20:51,017 DEBUG TRAIN Batch 51/3000 loss 1.679908 loss_att 4.341141 loss_ctc 2.476649 loss_rnnt 0.968422 hw_loss 0.136888 lr 0.00029118 rank 3
2023-03-01 07:21:30,121 DEBUG TRAIN Batch 51/3100 loss 9.698491 loss_att 11.421988 loss_ctc 15.512648 loss_rnnt 8.482699 hw_loss 0.179759 lr 0.00029118 rank 0
2023-03-01 07:21:30,121 DEBUG TRAIN Batch 51/3100 loss 6.873527 loss_att 11.453098 loss_ctc 14.031924 loss_rnnt 4.787534 hw_loss 0.404298 lr 0.00029118 rank 4
2023-03-01 07:21:30,121 DEBUG TRAIN Batch 51/3100 loss 6.636780 loss_att 7.798474 loss_ctc 13.792197 loss_rnnt 5.362693 hw_loss 0.164424 lr 0.00029117 rank 5
2023-03-01 07:21:30,121 DEBUG TRAIN Batch 51/3100 loss 4.616025 loss_att 7.421415 loss_ctc 10.941226 loss_rnnt 3.093353 hw_loss 0.221688 lr 0.00029118 rank 1
2023-03-01 07:21:30,121 DEBUG TRAIN Batch 51/3100 loss 9.123687 loss_att 10.059652 loss_ctc 12.378590 loss_rnnt 8.375786 hw_loss 0.237600 lr 0.00029116 rank 7
2023-03-01 07:21:30,122 DEBUG TRAIN Batch 51/3100 loss 8.661729 loss_att 10.267216 loss_ctc 12.261174 loss_rnnt 7.699536 hw_loss 0.302191 lr 0.00029118 rank 2
2023-03-01 07:21:30,123 DEBUG TRAIN Batch 51/3100 loss 5.920353 loss_att 7.199138 loss_ctc 8.747564 loss_rnnt 5.187586 hw_loss 0.187591 lr 0.00029117 rank 6
2023-03-01 07:21:30,168 DEBUG TRAIN Batch 51/3100 loss 3.534332 loss_att 5.074316 loss_ctc 5.826055 loss_rnnt 2.771553 hw_loss 0.279787 lr 0.00029117 rank 3
2023-03-01 07:22:36,381 DEBUG TRAIN Batch 51/3200 loss 3.212776 loss_att 6.267388 loss_ctc 6.969193 loss_rnnt 1.924655 hw_loss 0.330641 lr 0.00029116 rank 6
2023-03-01 07:22:36,387 DEBUG TRAIN Batch 51/3200 loss 2.015783 loss_att 4.644142 loss_ctc 5.826339 loss_rnnt 0.867150 hw_loss 0.215412 lr 0.00029116 rank 3
2023-03-01 07:22:36,389 DEBUG TRAIN Batch 51/3200 loss 4.530927 loss_att 5.067475 loss_ctc 7.119721 loss_rnnt 3.900243 hw_loss 0.334127 lr 0.00029117 rank 0
2023-03-01 07:22:36,393 DEBUG TRAIN Batch 51/3200 loss 11.136605 loss_att 11.407522 loss_ctc 14.050747 loss_rnnt 10.584095 hw_loss 0.205827 lr 0.00029116 rank 1
2023-03-01 07:22:36,393 DEBUG TRAIN Batch 51/3200 loss 8.371357 loss_att 10.292869 loss_ctc 12.151484 loss_rnnt 7.334761 hw_loss 0.278020 lr 0.00029115 rank 7
2023-03-01 07:22:36,400 DEBUG TRAIN Batch 51/3200 loss 9.866007 loss_att 12.048162 loss_ctc 16.459494 loss_rnnt 8.510393 hw_loss 0.075098 lr 0.00029116 rank 4
2023-03-01 07:22:36,421 DEBUG TRAIN Batch 51/3200 loss 8.935496 loss_att 12.032079 loss_ctc 14.876753 loss_rnnt 7.434829 hw_loss 0.167220 lr 0.00029117 rank 2
2023-03-01 07:22:36,450 DEBUG TRAIN Batch 51/3200 loss 4.972378 loss_att 9.001770 loss_ctc 8.055926 loss_rnnt 3.667032 hw_loss 0.165615 lr 0.00029116 rank 5
2023-03-01 07:23:15,140 DEBUG TRAIN Batch 51/3300 loss 9.755100 loss_att 13.481820 loss_ctc 17.451508 loss_rnnt 7.828706 hw_loss 0.290368 lr 0.00029114 rank 7
2023-03-01 07:23:15,143 DEBUG TRAIN Batch 51/3300 loss 3.555968 loss_att 8.694809 loss_ctc 7.139358 loss_rnnt 1.900297 hw_loss 0.281469 lr 0.00029115 rank 4
2023-03-01 07:23:15,156 DEBUG TRAIN Batch 51/3300 loss 6.609086 loss_att 9.675495 loss_ctc 9.917417 loss_rnnt 5.445657 hw_loss 0.204442 lr 0.00029115 rank 0
2023-03-01 07:23:15,162 DEBUG TRAIN Batch 51/3300 loss 2.440336 loss_att 5.942292 loss_ctc 6.668040 loss_rnnt 1.087491 hw_loss 0.166425 lr 0.00029115 rank 5
2023-03-01 07:23:15,163 DEBUG TRAIN Batch 51/3300 loss 8.448557 loss_att 13.025291 loss_ctc 14.149841 loss_rnnt 6.771916 hw_loss 0.002102 lr 0.00029116 rank 2
2023-03-01 07:23:15,163 DEBUG TRAIN Batch 51/3300 loss 9.054603 loss_att 13.098927 loss_ctc 14.718482 loss_rnnt 7.398246 hw_loss 0.173077 lr 0.00029114 rank 3
2023-03-01 07:23:15,167 DEBUG TRAIN Batch 51/3300 loss 6.079171 loss_att 7.701621 loss_ctc 12.483028 loss_rnnt 4.797526 hw_loss 0.193699 lr 0.00029115 rank 1
2023-03-01 07:23:15,181 DEBUG TRAIN Batch 51/3300 loss 4.799372 loss_att 6.621180 loss_ctc 7.035023 loss_rnnt 4.005418 hw_loss 0.246574 lr 0.00029115 rank 6
2023-03-01 07:23:53,332 DEBUG TRAIN Batch 51/3400 loss 6.908146 loss_att 10.955626 loss_ctc 8.815565 loss_rnnt 5.761909 hw_loss 0.154535 lr 0.00029114 rank 6
2023-03-01 07:23:53,333 DEBUG TRAIN Batch 51/3400 loss 9.340797 loss_att 11.502342 loss_ctc 10.262556 loss_rnnt 8.645315 hw_loss 0.263010 lr 0.00029114 rank 5
2023-03-01 07:23:53,338 DEBUG TRAIN Batch 51/3400 loss 5.708972 loss_att 9.589980 loss_ctc 10.441910 loss_rnnt 4.245864 hw_loss 0.104715 lr 0.00029114 rank 1
2023-03-01 07:23:53,338 DEBUG TRAIN Batch 51/3400 loss 1.289782 loss_att 2.824944 loss_ctc 3.054959 loss_rnnt 0.668912 hw_loss 0.147151 lr 0.00029113 rank 7
2023-03-01 07:23:53,344 DEBUG TRAIN Batch 51/3400 loss 4.680335 loss_att 6.290697 loss_ctc 7.841488 loss_rnnt 3.806347 hw_loss 0.244555 lr 0.00029114 rank 0
2023-03-01 07:23:53,347 DEBUG TRAIN Batch 51/3400 loss 6.652750 loss_att 9.647505 loss_ctc 13.697020 loss_rnnt 5.030641 hw_loss 0.157354 lr 0.00029114 rank 2
2023-03-01 07:23:53,371 DEBUG TRAIN Batch 51/3400 loss 4.980847 loss_att 8.965640 loss_ctc 12.203223 loss_rnnt 3.070307 hw_loss 0.282372 lr 0.00029113 rank 3
2023-03-01 07:23:53,381 DEBUG TRAIN Batch 51/3400 loss 1.968030 loss_att 4.463054 loss_ctc 2.467693 loss_rnnt 1.359897 hw_loss 0.079699 lr 0.00029114 rank 4
2023-03-01 07:24:32,953 DEBUG TRAIN Batch 51/3500 loss 4.848308 loss_att 7.501722 loss_ctc 8.575768 loss_rnnt 3.642110 hw_loss 0.334725 lr 0.00029112 rank 3
2023-03-01 07:24:32,962 DEBUG TRAIN Batch 51/3500 loss 3.486986 loss_att 6.498425 loss_ctc 9.850384 loss_rnnt 1.864448 hw_loss 0.322120 lr 0.00029113 rank 2
2023-03-01 07:24:32,964 DEBUG TRAIN Batch 51/3500 loss 2.499621 loss_att 6.653496 loss_ctc 6.219063 loss_rnnt 1.073132 hw_loss 0.187103 lr 0.00029113 rank 1
2023-03-01 07:24:32,966 DEBUG TRAIN Batch 51/3500 loss 6.035401 loss_att 7.699724 loss_ctc 11.512390 loss_rnnt 4.833025 hw_loss 0.261089 lr 0.00029112 rank 5
2023-03-01 07:24:32,966 DEBUG TRAIN Batch 51/3500 loss 3.809114 loss_att 6.327514 loss_ctc 6.754058 loss_rnnt 2.787431 hw_loss 0.235019 lr 0.00029111 rank 7
2023-03-01 07:24:32,966 DEBUG TRAIN Batch 51/3500 loss 3.730056 loss_att 6.588582 loss_ctc 3.997670 loss_rnnt 3.040052 hw_loss 0.154906 lr 0.00029113 rank 4
2023-03-01 07:24:32,972 DEBUG TRAIN Batch 51/3500 loss 7.079849 loss_att 11.638359 loss_ctc 11.787458 loss_rnnt 5.443743 hw_loss 0.181356 lr 0.00029113 rank 0
2023-03-01 07:24:32,973 DEBUG TRAIN Batch 51/3500 loss 7.116754 loss_att 9.259138 loss_ctc 12.499555 loss_rnnt 5.820769 hw_loss 0.280877 lr 0.00029113 rank 6
2023-03-01 07:25:38,553 DEBUG TRAIN Batch 51/3600 loss 6.091347 loss_att 8.240043 loss_ctc 9.904627 loss_rnnt 5.024614 hw_loss 0.241041 lr 0.00029111 rank 3
2023-03-01 07:25:38,565 DEBUG TRAIN Batch 51/3600 loss 3.242829 loss_att 5.287923 loss_ctc 5.259698 loss_rnnt 2.470169 hw_loss 0.177610 lr 0.00029112 rank 0
2023-03-01 07:25:38,571 DEBUG TRAIN Batch 51/3600 loss 5.615958 loss_att 11.229624 loss_ctc 12.987471 loss_rnnt 3.395226 hw_loss 0.215871 lr 0.00029111 rank 4
2023-03-01 07:25:38,572 DEBUG TRAIN Batch 51/3600 loss 11.056767 loss_att 13.377584 loss_ctc 14.534441 loss_rnnt 10.001123 hw_loss 0.239608 lr 0.00029112 rank 1
2023-03-01 07:25:38,573 DEBUG TRAIN Batch 51/3600 loss 5.307007 loss_att 7.996785 loss_ctc 8.403515 loss_rnnt 4.255243 hw_loss 0.189263 lr 0.00029110 rank 7
2023-03-01 07:25:38,574 DEBUG TRAIN Batch 51/3600 loss 9.373066 loss_att 13.641027 loss_ctc 16.247353 loss_rnnt 7.462185 hw_loss 0.263844 lr 0.00029111 rank 6
2023-03-01 07:25:38,577 DEBUG TRAIN Batch 51/3600 loss 6.339296 loss_att 7.702460 loss_ctc 9.379227 loss_rnnt 5.590006 hw_loss 0.133749 lr 0.00029111 rank 5
2023-03-01 07:25:38,584 DEBUG TRAIN Batch 51/3600 loss 5.541695 loss_att 7.671403 loss_ctc 8.798244 loss_rnnt 4.599463 hw_loss 0.153909 lr 0.00029112 rank 2
2023-03-01 07:26:18,041 DEBUG TRAIN Batch 51/3700 loss 4.810950 loss_att 6.733845 loss_ctc 8.420389 loss_rnnt 3.816892 hw_loss 0.240414 lr 0.00029109 rank 7
2023-03-01 07:26:18,065 DEBUG TRAIN Batch 51/3700 loss 4.160676 loss_att 6.374469 loss_ctc 8.412622 loss_rnnt 3.001676 hw_loss 0.279967 lr 0.00029110 rank 5
2023-03-01 07:26:18,069 DEBUG TRAIN Batch 51/3700 loss 3.301176 loss_att 5.317316 loss_ctc 5.528558 loss_rnnt 2.479985 hw_loss 0.226837 lr 0.00029110 rank 0
2023-03-01 07:26:18,070 DEBUG TRAIN Batch 51/3700 loss 3.093063 loss_att 6.466377 loss_ctc 5.155735 loss_rnnt 2.087868 hw_loss 0.104079 lr 0.00029110 rank 4
2023-03-01 07:26:18,070 DEBUG TRAIN Batch 51/3700 loss 8.100801 loss_att 10.893795 loss_ctc 12.468094 loss_rnnt 6.860972 hw_loss 0.185483 lr 0.00029110 rank 1
2023-03-01 07:26:18,071 DEBUG TRAIN Batch 51/3700 loss 7.457790 loss_att 9.160316 loss_ctc 10.386588 loss_rnnt 6.604653 hw_loss 0.228983 lr 0.00029111 rank 2
2023-03-01 07:26:18,097 DEBUG TRAIN Batch 51/3700 loss 6.171583 loss_att 7.648877 loss_ctc 11.894092 loss_rnnt 5.006633 hw_loss 0.199667 lr 0.00029110 rank 3
2023-03-01 07:26:18,136 DEBUG TRAIN Batch 51/3700 loss 2.983334 loss_att 4.994214 loss_ctc 3.518342 loss_rnnt 2.309371 hw_loss 0.375850 lr 0.00029110 rank 6
2023-03-01 07:26:57,276 DEBUG TRAIN Batch 51/3800 loss 5.031305 loss_att 7.336698 loss_ctc 6.059602 loss_rnnt 4.396976 hw_loss 0.067772 lr 0.00029109 rank 2
2023-03-01 07:26:57,279 DEBUG TRAIN Batch 51/3800 loss 8.102416 loss_att 11.980783 loss_ctc 11.951994 loss_rnnt 6.637108 hw_loss 0.330670 lr 0.00029109 rank 4
2023-03-01 07:26:57,281 DEBUG TRAIN Batch 51/3800 loss 5.214378 loss_att 7.969741 loss_ctc 9.037521 loss_rnnt 4.138151 hw_loss 0.028877 lr 0.00029109 rank 5
2023-03-01 07:26:57,292 DEBUG TRAIN Batch 51/3800 loss 7.669816 loss_att 7.217353 loss_ctc 10.699034 loss_rnnt 7.164920 hw_loss 0.359050 lr 0.00029109 rank 0
2023-03-01 07:26:57,293 DEBUG TRAIN Batch 51/3800 loss 7.383932 loss_att 9.403393 loss_ctc 9.736846 loss_rnnt 6.571809 hw_loss 0.177203 lr 0.00029108 rank 7
2023-03-01 07:26:57,293 DEBUG TRAIN Batch 51/3800 loss 2.020820 loss_att 3.891353 loss_ctc 3.645893 loss_rnnt 1.365014 hw_loss 0.121919 lr 0.00029108 rank 3
2023-03-01 07:26:57,298 DEBUG TRAIN Batch 51/3800 loss 6.492085 loss_att 8.422850 loss_ctc 10.310107 loss_rnnt 5.422321 hw_loss 0.327266 lr 0.00029109 rank 1
2023-03-01 07:26:57,344 DEBUG TRAIN Batch 51/3800 loss 7.681521 loss_att 9.628499 loss_ctc 12.634102 loss_rnnt 6.464484 hw_loss 0.313684 lr 0.00029109 rank 6
2023-03-01 07:28:02,780 DEBUG TRAIN Batch 51/3900 loss 3.263904 loss_att 6.994751 loss_ctc 5.573362 loss_rnnt 2.056735 hw_loss 0.287009 lr 0.00029107 rank 5
2023-03-01 07:28:02,786 DEBUG TRAIN Batch 51/3900 loss 2.177818 loss_att 4.366024 loss_ctc 3.799243 loss_rnnt 1.347927 hw_loss 0.330112 lr 0.00029108 rank 0
2023-03-01 07:28:02,794 DEBUG TRAIN Batch 51/3900 loss 8.466517 loss_att 14.916916 loss_ctc 23.763144 loss_rnnt 5.121512 hw_loss 0.028828 lr 0.00029107 rank 3
2023-03-01 07:28:02,801 DEBUG TRAIN Batch 51/3900 loss 1.871753 loss_att 4.927985 loss_ctc 3.161900 loss_rnnt 1.012980 hw_loss 0.141575 lr 0.00029107 rank 7
2023-03-01 07:28:02,803 DEBUG TRAIN Batch 51/3900 loss 10.841917 loss_att 15.220803 loss_ctc 19.332756 loss_rnnt 8.737028 hw_loss 0.181875 lr 0.00029108 rank 2
2023-03-01 07:28:02,807 DEBUG TRAIN Batch 51/3900 loss 2.865109 loss_att 4.915879 loss_ctc 5.924579 loss_rnnt 1.997581 hw_loss 0.092708 lr 0.00029108 rank 1
2023-03-01 07:28:02,834 DEBUG TRAIN Batch 51/3900 loss 5.014990 loss_att 7.574688 loss_ctc 6.861610 loss_rnnt 4.212912 hw_loss 0.082355 lr 0.00029108 rank 6
2023-03-01 07:28:03,304 DEBUG TRAIN Batch 51/3900 loss 3.827650 loss_att 5.026855 loss_ctc 9.182499 loss_rnnt 2.781012 hw_loss 0.174031 lr 0.00029108 rank 4
2023-03-01 07:28:43,157 DEBUG TRAIN Batch 51/4000 loss 8.516314 loss_att 12.949325 loss_ctc 17.356878 loss_rnnt 6.355696 hw_loss 0.178637 lr 0.00029106 rank 4
2023-03-01 07:28:43,163 DEBUG TRAIN Batch 51/4000 loss 5.552092 loss_att 7.669534 loss_ctc 7.990199 loss_rnnt 4.761724 hw_loss 0.078372 lr 0.00029107 rank 1
2023-03-01 07:28:43,171 DEBUG TRAIN Batch 51/4000 loss 7.658196 loss_att 8.633821 loss_ctc 12.581397 loss_rnnt 6.722686 hw_loss 0.157423 lr 0.00029105 rank 7
2023-03-01 07:28:43,173 DEBUG TRAIN Batch 51/4000 loss 4.486712 loss_att 7.672242 loss_ctc 4.615264 loss_rnnt 3.832189 hw_loss 0.000518 lr 0.00029106 rank 5
2023-03-01 07:28:43,176 DEBUG TRAIN Batch 51/4000 loss 4.653332 loss_att 6.807432 loss_ctc 4.973270 loss_rnnt 4.054104 hw_loss 0.235779 lr 0.00029107 rank 2
2023-03-01 07:28:43,186 DEBUG TRAIN Batch 51/4000 loss 6.078129 loss_att 9.924380 loss_ctc 12.274044 loss_rnnt 4.316787 hw_loss 0.311194 lr 0.00029107 rank 0
2023-03-01 07:28:43,189 DEBUG TRAIN Batch 51/4000 loss 3.654356 loss_att 7.382229 loss_ctc 11.769343 loss_rnnt 1.631397 hw_loss 0.366350 lr 0.00029106 rank 3
2023-03-01 07:28:43,191 DEBUG TRAIN Batch 51/4000 loss 4.194271 loss_att 9.044422 loss_ctc 8.593970 loss_rnnt 2.447803 hw_loss 0.355894 lr 0.00029106 rank 6
2023-03-01 07:29:22,361 DEBUG TRAIN Batch 51/4100 loss 6.440197 loss_att 10.209843 loss_ctc 8.265846 loss_rnnt 5.272877 hw_loss 0.318697 lr 0.00029106 rank 0
2023-03-01 07:29:22,364 DEBUG TRAIN Batch 51/4100 loss 5.249072 loss_att 7.598625 loss_ctc 8.190031 loss_rnnt 4.258327 hw_loss 0.241324 lr 0.00029104 rank 7
2023-03-01 07:29:22,367 DEBUG TRAIN Batch 51/4100 loss 2.756394 loss_att 5.164867 loss_ctc 5.888814 loss_rnnt 1.654671 hw_loss 0.379447 lr 0.00029105 rank 1
2023-03-01 07:29:22,369 DEBUG TRAIN Batch 51/4100 loss 6.979884 loss_att 8.034891 loss_ctc 11.454245 loss_rnnt 6.056354 hw_loss 0.217402 lr 0.00029105 rank 6
2023-03-01 07:29:22,371 DEBUG TRAIN Batch 51/4100 loss 3.590629 loss_att 7.263620 loss_ctc 9.748301 loss_rnnt 1.923686 hw_loss 0.208727 lr 0.00029105 rank 3
2023-03-01 07:29:22,379 DEBUG TRAIN Batch 51/4100 loss 10.052171 loss_att 11.916547 loss_ctc 12.010005 loss_rnnt 9.354277 hw_loss 0.119950 lr 0.00029105 rank 4
2023-03-01 07:29:22,386 DEBUG TRAIN Batch 51/4100 loss 5.793615 loss_att 11.218116 loss_ctc 12.309423 loss_rnnt 3.635149 hw_loss 0.383986 lr 0.00029106 rank 2
2023-03-01 07:29:22,389 DEBUG TRAIN Batch 51/4100 loss 4.293507 loss_att 8.439523 loss_ctc 7.742883 loss_rnnt 2.841563 hw_loss 0.305295 lr 0.00029105 rank 5
2023-03-01 07:30:01,762 DEBUG TRAIN Batch 51/4200 loss 5.814031 loss_att 10.140438 loss_ctc 8.513073 loss_rnnt 4.528285 hw_loss 0.113612 lr 0.00029104 rank 6
2023-03-01 07:30:01,762 DEBUG TRAIN Batch 51/4200 loss 7.558868 loss_att 8.771637 loss_ctc 11.610101 loss_rnnt 6.681956 hw_loss 0.176614 lr 0.00029104 rank 1
2023-03-01 07:30:01,766 DEBUG TRAIN Batch 51/4200 loss 8.715701 loss_att 12.308880 loss_ctc 16.448391 loss_rnnt 6.843623 hw_loss 0.229532 lr 0.00029104 rank 5
2023-03-01 07:30:01,772 DEBUG TRAIN Batch 51/4200 loss 4.245754 loss_att 6.767744 loss_ctc 6.002935 loss_rnnt 3.368499 hw_loss 0.259814 lr 0.00029104 rank 0
2023-03-01 07:30:01,778 DEBUG TRAIN Batch 51/4200 loss 8.349174 loss_att 12.089468 loss_ctc 11.356722 loss_rnnt 7.072168 hw_loss 0.239890 lr 0.00029103 rank 7
2023-03-01 07:30:01,786 DEBUG TRAIN Batch 51/4200 loss 13.331707 loss_att 15.908644 loss_ctc 17.897221 loss_rnnt 12.108457 hw_loss 0.185861 lr 0.00029103 rank 3
2023-03-01 07:30:01,797 DEBUG TRAIN Batch 51/4200 loss 9.980578 loss_att 13.278194 loss_ctc 18.186647 loss_rnnt 8.070690 hw_loss 0.292919 lr 0.00029105 rank 2
2023-03-01 07:30:01,797 DEBUG TRAIN Batch 51/4200 loss 6.270194 loss_att 9.161553 loss_ctc 11.552676 loss_rnnt 4.864090 hw_loss 0.231563 lr 0.00029104 rank 4
2023-03-01 07:31:07,027 DEBUG TRAIN Batch 51/4300 loss 3.868247 loss_att 6.742607 loss_ctc 9.289728 loss_rnnt 2.388865 hw_loss 0.340586 lr 0.00029102 rank 7
2023-03-01 07:31:07,027 DEBUG TRAIN Batch 51/4300 loss 6.346012 loss_att 8.168480 loss_ctc 8.695359 loss_rnnt 5.538767 hw_loss 0.242819 lr 0.00029103 rank 0
2023-03-01 07:31:07,028 DEBUG TRAIN Batch 51/4300 loss 7.400662 loss_att 8.971126 loss_ctc 13.482562 loss_rnnt 6.076942 hw_loss 0.372576 lr 0.00029102 rank 5
2023-03-01 07:31:07,031 DEBUG TRAIN Batch 51/4300 loss 13.065917 loss_att 14.427903 loss_ctc 18.326260 loss_rnnt 12.028305 hw_loss 0.119690 lr 0.00029102 rank 3
2023-03-01 07:31:07,031 DEBUG TRAIN Batch 51/4300 loss 6.912521 loss_att 8.066702 loss_ctc 13.214779 loss_rnnt 5.754065 hw_loss 0.163723 lr 0.00029103 rank 6
2023-03-01 07:31:07,035 DEBUG TRAIN Batch 51/4300 loss 5.474103 loss_att 6.555584 loss_ctc 6.931826 loss_rnnt 4.941538 hw_loss 0.228573 lr 0.00029103 rank 4
2023-03-01 07:31:07,035 DEBUG TRAIN Batch 51/4300 loss 8.345254 loss_att 12.406277 loss_ctc 14.549929 loss_rnnt 6.580747 hw_loss 0.234399 lr 0.00029103 rank 1
2023-03-01 07:31:07,036 DEBUG TRAIN Batch 51/4300 loss 4.557481 loss_att 6.737699 loss_ctc 6.184337 loss_rnnt 3.739214 hw_loss 0.309955 lr 0.00029103 rank 2
2023-03-01 07:31:46,324 DEBUG TRAIN Batch 51/4400 loss 3.413279 loss_att 6.742330 loss_ctc 7.388538 loss_rnnt 2.069149 hw_loss 0.278035 lr 0.00029100 rank 7
2023-03-01 07:31:46,330 DEBUG TRAIN Batch 51/4400 loss 3.976288 loss_att 5.879990 loss_ctc 6.583673 loss_rnnt 3.171110 hw_loss 0.143974 lr 0.00029102 rank 1
2023-03-01 07:31:46,332 DEBUG TRAIN Batch 51/4400 loss 3.117606 loss_att 4.259691 loss_ctc 5.485699 loss_rnnt 2.404838 hw_loss 0.316133 lr 0.00029102 rank 0
2023-03-01 07:31:46,333 DEBUG TRAIN Batch 51/4400 loss 5.263487 loss_att 5.546457 loss_ctc 9.033045 loss_rnnt 4.560310 hw_loss 0.269951 lr 0.00029102 rank 2
2023-03-01 07:31:46,334 DEBUG TRAIN Batch 51/4400 loss 2.925783 loss_att 4.256621 loss_ctc 4.719450 loss_rnnt 2.307337 hw_loss 0.212105 lr 0.00029101 rank 6
2023-03-01 07:31:46,335 DEBUG TRAIN Batch 51/4400 loss 5.511535 loss_att 9.432655 loss_ctc 9.728654 loss_rnnt 3.989995 hw_loss 0.328188 lr 0.00029101 rank 5
2023-03-01 07:31:46,336 DEBUG TRAIN Batch 51/4400 loss 6.150186 loss_att 8.455030 loss_ctc 12.010772 loss_rnnt 4.805588 hw_loss 0.191656 lr 0.00029102 rank 4
2023-03-01 07:31:46,378 DEBUG TRAIN Batch 51/4400 loss 5.888922 loss_att 7.565283 loss_ctc 10.650046 loss_rnnt 4.753787 hw_loss 0.309461 lr 0.00029101 rank 3
2023-03-01 07:32:24,993 DEBUG TRAIN Batch 51/4500 loss 8.309952 loss_att 14.578766 loss_ctc 14.596228 loss_rnnt 6.033264 hw_loss 0.346414 lr 0.00029100 rank 5
2023-03-01 07:32:24,998 DEBUG TRAIN Batch 51/4500 loss 6.569218 loss_att 8.235733 loss_ctc 13.311279 loss_rnnt 5.220245 hw_loss 0.218866 lr 0.00029100 rank 4
2023-03-01 07:32:25,007 DEBUG TRAIN Batch 51/4500 loss 1.308559 loss_att 3.997795 loss_ctc 4.431297 loss_rnnt 0.245394 hw_loss 0.204287 lr 0.00029101 rank 0
2023-03-01 07:32:25,008 DEBUG TRAIN Batch 51/4500 loss 8.927802 loss_att 10.844725 loss_ctc 16.923046 loss_rnnt 7.332847 hw_loss 0.272885 lr 0.00029099 rank 7
2023-03-01 07:32:25,009 DEBUG TRAIN Batch 51/4500 loss 11.838429 loss_att 14.124106 loss_ctc 19.479345 loss_rnnt 10.271139 hw_loss 0.171312 lr 0.00029101 rank 2
2023-03-01 07:32:25,013 DEBUG TRAIN Batch 51/4500 loss 10.288973 loss_att 14.109332 loss_ctc 15.950309 loss_rnnt 8.594856 hw_loss 0.328501 lr 0.00029100 rank 6
2023-03-01 07:32:25,015 DEBUG TRAIN Batch 51/4500 loss 2.735182 loss_att 4.249806 loss_ctc 2.431837 loss_rnnt 2.407745 hw_loss 0.121797 lr 0.00029100 rank 3
2023-03-01 07:32:25,019 DEBUG TRAIN Batch 51/4500 loss 5.588240 loss_att 9.464321 loss_ctc 11.466524 loss_rnnt 3.951746 hw_loss 0.145325 lr 0.00029100 rank 1
2023-03-01 07:33:05,218 DEBUG TRAIN Batch 51/4600 loss 5.293273 loss_att 10.275331 loss_ctc 12.202936 loss_rnnt 3.341476 hw_loss 0.063932 lr 0.00029099 rank 4
2023-03-01 07:33:05,220 DEBUG TRAIN Batch 51/4600 loss 7.562240 loss_att 11.511211 loss_ctc 14.019615 loss_rnnt 5.834595 hw_loss 0.144127 lr 0.00029100 rank 2
2023-03-01 07:33:05,222 DEBUG TRAIN Batch 51/4600 loss 6.270997 loss_att 9.705129 loss_ctc 12.087195 loss_rnnt 4.714739 hw_loss 0.176135 lr 0.00029099 rank 1
2023-03-01 07:33:05,228 DEBUG TRAIN Batch 51/4600 loss 11.493194 loss_att 15.682211 loss_ctc 17.276291 loss_rnnt 9.799630 hw_loss 0.158775 lr 0.00029099 rank 6
2023-03-01 07:33:05,235 DEBUG TRAIN Batch 51/4600 loss 4.810624 loss_att 7.615074 loss_ctc 7.429086 loss_rnnt 3.858893 hw_loss 0.078212 lr 0.00029099 rank 0
2023-03-01 07:33:05,237 DEBUG TRAIN Batch 51/4600 loss 3.408654 loss_att 5.815304 loss_ctc 6.332142 loss_rnnt 2.412215 hw_loss 0.234958 lr 0.00029098 rank 3
2023-03-01 07:33:05,241 DEBUG TRAIN Batch 51/4600 loss 7.724025 loss_att 11.639472 loss_ctc 21.975134 loss_rnnt 4.957338 hw_loss 0.156469 lr 0.00029099 rank 5
2023-03-01 07:33:05,243 DEBUG TRAIN Batch 51/4600 loss 9.575224 loss_att 11.955326 loss_ctc 15.983813 loss_rnnt 8.182878 hw_loss 0.115962 lr 0.00029098 rank 7
2023-03-01 07:34:10,734 DEBUG TRAIN Batch 51/4700 loss 5.475581 loss_att 7.641545 loss_ctc 9.590267 loss_rnnt 4.377653 hw_loss 0.217708 lr 0.00029098 rank 1
2023-03-01 07:34:10,743 DEBUG TRAIN Batch 51/4700 loss 6.100344 loss_att 9.065265 loss_ctc 9.575585 loss_rnnt 4.907925 hw_loss 0.255131 lr 0.00029098 rank 0
2023-03-01 07:34:10,744 DEBUG TRAIN Batch 51/4700 loss 2.823043 loss_att 5.360708 loss_ctc 3.481011 loss_rnnt 2.161950 hw_loss 0.123431 lr 0.00029098 rank 4
2023-03-01 07:34:10,745 DEBUG TRAIN Batch 51/4700 loss 1.271156 loss_att 4.199629 loss_ctc 3.947156 loss_rnnt 0.299854 hw_loss 0.054015 lr 0.00029097 rank 7
2023-03-01 07:34:10,746 DEBUG TRAIN Batch 51/4700 loss 5.755730 loss_att 9.868017 loss_ctc 11.587587 loss_rnnt 4.030282 hw_loss 0.235143 lr 0.00029097 rank 3
2023-03-01 07:34:10,749 DEBUG TRAIN Batch 51/4700 loss 8.069688 loss_att 10.275577 loss_ctc 10.764485 loss_rnnt 7.195981 hw_loss 0.137294 lr 0.00029098 rank 5
2023-03-01 07:34:10,750 DEBUG TRAIN Batch 51/4700 loss 13.628347 loss_att 16.571127 loss_ctc 19.026224 loss_rnnt 12.227427 hw_loss 0.173714 lr 0.00029098 rank 2
2023-03-01 07:34:10,757 DEBUG TRAIN Batch 51/4700 loss 10.686992 loss_att 12.060905 loss_ctc 14.024939 loss_rnnt 9.902885 hw_loss 0.120495 lr 0.00029098 rank 6
2023-03-01 07:34:49,047 DEBUG TRAIN Batch 51/4800 loss 4.404482 loss_att 6.172359 loss_ctc 7.364279 loss_rnnt 3.500174 hw_loss 0.292675 lr 0.00029097 rank 0
2023-03-01 07:34:49,049 DEBUG TRAIN Batch 51/4800 loss 5.821899 loss_att 8.509327 loss_ctc 6.766766 loss_rnnt 5.110966 hw_loss 0.088996 lr 0.00029097 rank 4
2023-03-01 07:34:49,050 DEBUG TRAIN Batch 51/4800 loss 7.227527 loss_att 10.825552 loss_ctc 16.508078 loss_rnnt 5.216549 hw_loss 0.101187 lr 0.00029096 rank 5
2023-03-01 07:34:49,053 DEBUG TRAIN Batch 51/4800 loss 4.050930 loss_att 6.257106 loss_ctc 6.427543 loss_rnnt 3.247700 hw_loss 0.084585 lr 0.00029096 rank 3
2023-03-01 07:34:49,054 DEBUG TRAIN Batch 51/4800 loss 9.023035 loss_att 12.776920 loss_ctc 16.969547 loss_rnnt 7.063716 hw_loss 0.279388 lr 0.00029095 rank 7
2023-03-01 07:34:49,055 DEBUG TRAIN Batch 51/4800 loss 5.142871 loss_att 7.278478 loss_ctc 7.783903 loss_rnnt 4.270981 hw_loss 0.173683 lr 0.00029097 rank 6
2023-03-01 07:34:49,056 DEBUG TRAIN Batch 51/4800 loss 5.462201 loss_att 7.049389 loss_ctc 5.304085 loss_rnnt 5.032545 hw_loss 0.249937 lr 0.00029097 rank 1
2023-03-01 07:34:49,103 DEBUG TRAIN Batch 51/4800 loss 6.779681 loss_att 10.167364 loss_ctc 15.823822 loss_rnnt 4.873789 hw_loss 0.042132 lr 0.00029097 rank 2
2023-03-01 07:35:28,332 DEBUG TRAIN Batch 51/4900 loss 3.942506 loss_att 4.837806 loss_ctc 5.845557 loss_rnnt 3.389972 hw_loss 0.224501 lr 0.00029095 rank 5
2023-03-01 07:35:28,334 DEBUG TRAIN Batch 51/4900 loss 4.491676 loss_att 6.468107 loss_ctc 9.017221 loss_rnnt 3.419803 hw_loss 0.137214 lr 0.00029096 rank 0
2023-03-01 07:35:28,335 DEBUG TRAIN Batch 51/4900 loss 5.827391 loss_att 9.540347 loss_ctc 12.060585 loss_rnnt 4.197881 hw_loss 0.104674 lr 0.00029095 rank 3
2023-03-01 07:35:28,342 DEBUG TRAIN Batch 51/4900 loss 8.275214 loss_att 13.652248 loss_ctc 15.549174 loss_rnnt 6.080124 hw_loss 0.280918 lr 0.00029095 rank 4
2023-03-01 07:35:28,345 DEBUG TRAIN Batch 51/4900 loss 6.189349 loss_att 8.510294 loss_ctc 8.814607 loss_rnnt 5.245825 hw_loss 0.242438 lr 0.00029094 rank 7
2023-03-01 07:35:28,347 DEBUG TRAIN Batch 51/4900 loss 2.348604 loss_att 4.486324 loss_ctc 2.365635 loss_rnnt 1.861515 hw_loss 0.107389 lr 0.00029096 rank 2
2023-03-01 07:35:28,367 DEBUG TRAIN Batch 51/4900 loss 2.644128 loss_att 4.469948 loss_ctc 3.907218 loss_rnnt 1.983143 hw_loss 0.238892 lr 0.00029095 rank 6
2023-03-01 07:35:28,369 DEBUG TRAIN Batch 51/4900 loss 6.542378 loss_att 8.775414 loss_ctc 10.516235 loss_rnnt 5.466586 hw_loss 0.186259 lr 0.00029095 rank 1
2023-03-01 07:36:37,872 DEBUG TRAIN Batch 51/5000 loss 3.829677 loss_att 7.246940 loss_ctc 4.914480 loss_rnnt 2.938883 hw_loss 0.117564 lr 0.00029094 rank 4
2023-03-01 07:36:37,874 DEBUG TRAIN Batch 51/5000 loss 7.062089 loss_att 10.221790 loss_ctc 13.674918 loss_rnnt 5.400593 hw_loss 0.277210 lr 0.00029094 rank 6
2023-03-01 07:36:37,877 DEBUG TRAIN Batch 51/5000 loss 3.139995 loss_att 6.366548 loss_ctc 4.335427 loss_rnnt 2.208785 hw_loss 0.237203 lr 0.00029093 rank 7
2023-03-01 07:36:37,876 DEBUG TRAIN Batch 51/5000 loss 4.691071 loss_att 6.274666 loss_ctc 9.682122 loss_rnnt 3.640325 hw_loss 0.128539 lr 0.00029094 rank 3
2023-03-01 07:36:37,878 DEBUG TRAIN Batch 51/5000 loss 3.615934 loss_att 9.864456 loss_ctc 8.794336 loss_rnnt 1.596705 hw_loss 0.148258 lr 0.00029094 rank 0
2023-03-01 07:36:37,879 DEBUG TRAIN Batch 51/5000 loss 7.102259 loss_att 8.900062 loss_ctc 10.900504 loss_rnnt 6.059321 hw_loss 0.331769 lr 0.00029095 rank 2
2023-03-01 07:36:37,879 DEBUG TRAIN Batch 51/5000 loss 6.172783 loss_att 9.185831 loss_ctc 9.627597 loss_rnnt 4.975730 hw_loss 0.250879 lr 0.00029094 rank 1
2023-03-01 07:36:37,881 DEBUG TRAIN Batch 51/5000 loss 6.812044 loss_att 8.068378 loss_ctc 11.182378 loss_rnnt 5.769598 hw_loss 0.390874 lr 0.00029094 rank 5
2023-03-01 07:37:16,888 DEBUG TRAIN Batch 51/5100 loss 8.320263 loss_att 10.649565 loss_ctc 16.657009 loss_rnnt 6.639027 hw_loss 0.194643 lr 0.00029093 rank 4
2023-03-01 07:37:16,889 DEBUG TRAIN Batch 51/5100 loss 3.924525 loss_att 5.967071 loss_ctc 4.873918 loss_rnnt 3.344506 hw_loss 0.084233 lr 0.00029092 rank 3
2023-03-01 07:37:16,895 DEBUG TRAIN Batch 51/5100 loss 5.702912 loss_att 10.246990 loss_ctc 8.014820 loss_rnnt 4.408887 hw_loss 0.144291 lr 0.00029093 rank 1
2023-03-01 07:37:16,904 DEBUG TRAIN Batch 51/5100 loss 2.592427 loss_att 4.505408 loss_ctc 5.690711 loss_rnnt 1.699080 hw_loss 0.183086 lr 0.00029093 rank 0
2023-03-01 07:37:16,906 DEBUG TRAIN Batch 51/5100 loss 10.648091 loss_att 14.111553 loss_ctc 18.920862 loss_rnnt 8.742255 hw_loss 0.206454 lr 0.00029092 rank 7
2023-03-01 07:37:16,916 DEBUG TRAIN Batch 51/5100 loss 8.595896 loss_att 10.957941 loss_ctc 16.653229 loss_rnnt 6.920638 hw_loss 0.241007 lr 0.00029093 rank 2
2023-03-01 07:37:16,917 DEBUG TRAIN Batch 51/5100 loss 4.451896 loss_att 7.208017 loss_ctc 5.996471 loss_rnnt 3.605982 hw_loss 0.166401 lr 0.00029093 rank 6
2023-03-01 07:37:16,928 DEBUG TRAIN Batch 51/5100 loss 4.939754 loss_att 7.229285 loss_ctc 5.275292 loss_rnnt 4.296001 hw_loss 0.264578 lr 0.00029093 rank 5
2023-03-01 07:37:55,131 DEBUG TRAIN Batch 51/5200 loss 1.333477 loss_att 3.419950 loss_ctc 2.976610 loss_rnnt 0.602372 hw_loss 0.177610 lr 0.00029091 rank 3
2023-03-01 07:37:55,139 DEBUG TRAIN Batch 51/5200 loss 5.098079 loss_att 5.807747 loss_ctc 8.531905 loss_rnnt 4.327756 hw_loss 0.319773 lr 0.00029091 rank 7
2023-03-01 07:37:55,140 DEBUG TRAIN Batch 51/5200 loss 7.241574 loss_att 11.635568 loss_ctc 13.687485 loss_rnnt 5.288936 hw_loss 0.401971 lr 0.00029092 rank 0
2023-03-01 07:37:55,142 DEBUG TRAIN Batch 51/5200 loss 6.202831 loss_att 9.094320 loss_ctc 9.036271 loss_rnnt 5.207346 hw_loss 0.073866 lr 0.00029092 rank 2
2023-03-01 07:37:55,142 DEBUG TRAIN Batch 51/5200 loss 10.931635 loss_att 13.267521 loss_ctc 17.331625 loss_rnnt 9.467226 hw_loss 0.269810 lr 0.00029092 rank 4
2023-03-01 07:37:55,144 DEBUG TRAIN Batch 51/5200 loss 8.088243 loss_att 9.968065 loss_ctc 12.484200 loss_rnnt 7.028047 hw_loss 0.183944 lr 0.00029091 rank 5
2023-03-01 07:37:55,144 DEBUG TRAIN Batch 51/5200 loss 9.676273 loss_att 13.027754 loss_ctc 13.703666 loss_rnnt 8.336155 hw_loss 0.249069 lr 0.00029092 rank 1
2023-03-01 07:37:55,146 DEBUG TRAIN Batch 51/5200 loss 9.381295 loss_att 14.470411 loss_ctc 15.924753 loss_rnnt 7.388656 hw_loss 0.191914 lr 0.00029092 rank 6
2023-03-01 07:38:34,942 DEBUG TRAIN Batch 51/5300 loss 4.476061 loss_att 8.288118 loss_ctc 11.010790 loss_rnnt 2.748342 hw_loss 0.176269 lr 0.00029091 rank 1
2023-03-01 07:38:34,943 DEBUG TRAIN Batch 51/5300 loss 3.479288 loss_att 5.504863 loss_ctc 4.954256 loss_rnnt 2.768097 hw_loss 0.205150 lr 0.00029091 rank 0
2023-03-01 07:38:34,947 DEBUG TRAIN Batch 51/5300 loss 4.439720 loss_att 6.345008 loss_ctc 6.814776 loss_rnnt 3.627274 hw_loss 0.215088 lr 0.00029090 rank 4
2023-03-01 07:38:34,947 DEBUG TRAIN Batch 51/5300 loss 5.602836 loss_att 8.489502 loss_ctc 7.703279 loss_rnnt 4.708018 hw_loss 0.070173 lr 0.00029091 rank 2
2023-03-01 07:38:34,956 DEBUG TRAIN Batch 51/5300 loss 9.818369 loss_att 10.135830 loss_ctc 13.315712 loss_rnnt 9.130534 hw_loss 0.296306 lr 0.00029090 rank 6
2023-03-01 07:38:34,956 DEBUG TRAIN Batch 51/5300 loss 1.528557 loss_att 4.061704 loss_ctc 3.735605 loss_rnnt 0.557377 hw_loss 0.319272 lr 0.00029089 rank 7
2023-03-01 07:38:34,961 DEBUG TRAIN Batch 51/5300 loss 7.610352 loss_att 12.260890 loss_ctc 12.450269 loss_rnnt 5.888102 hw_loss 0.275286 lr 0.00029090 rank 5
2023-03-01 07:38:34,977 DEBUG TRAIN Batch 51/5300 loss 7.563929 loss_att 11.331691 loss_ctc 14.501173 loss_rnnt 5.709961 hw_loss 0.328969 lr 0.00029090 rank 3
2023-03-01 07:39:39,809 DEBUG TRAIN Batch 51/5400 loss 5.421761 loss_att 11.071102 loss_ctc 8.655784 loss_rnnt 3.756440 hw_loss 0.195468 lr 0.00029089 rank 1
2023-03-01 07:39:39,814 DEBUG TRAIN Batch 51/5400 loss 8.612473 loss_att 10.300577 loss_ctc 14.574834 loss_rnnt 7.364325 hw_loss 0.216652 lr 0.00029089 rank 3
2023-03-01 07:39:39,817 DEBUG TRAIN Batch 51/5400 loss 6.673428 loss_att 11.150082 loss_ctc 12.888914 loss_rnnt 4.820632 hw_loss 0.241375 lr 0.00029090 rank 2
2023-03-01 07:39:39,819 DEBUG TRAIN Batch 51/5400 loss 9.937642 loss_att 13.665215 loss_ctc 19.945286 loss_rnnt 7.707491 hw_loss 0.281782 lr 0.00029089 rank 6
2023-03-01 07:39:39,828 DEBUG TRAIN Batch 51/5400 loss 7.022639 loss_att 9.990445 loss_ctc 9.419890 loss_rnnt 5.933747 hw_loss 0.329433 lr 0.00029088 rank 7
2023-03-01 07:39:39,829 DEBUG TRAIN Batch 51/5400 loss 7.451049 loss_att 9.659253 loss_ctc 12.491165 loss_rnnt 6.177289 hw_loss 0.300193 lr 0.00029090 rank 0
2023-03-01 07:39:39,833 DEBUG TRAIN Batch 51/5400 loss 2.664764 loss_att 5.619261 loss_ctc 4.157509 loss_rnnt 1.750323 hw_loss 0.233454 lr 0.00029089 rank 5
2023-03-01 07:39:39,883 DEBUG TRAIN Batch 51/5400 loss 4.520580 loss_att 9.156823 loss_ctc 9.220480 loss_rnnt 2.915077 hw_loss 0.096752 lr 0.00029089 rank 4
2023-03-01 07:40:18,588 DEBUG TRAIN Batch 51/5500 loss 4.613514 loss_att 7.149390 loss_ctc 7.196464 loss_rnnt 3.611950 hw_loss 0.281242 lr 0.00029088 rank 0
2023-03-01 07:40:18,594 DEBUG TRAIN Batch 51/5500 loss 4.663992 loss_att 9.033188 loss_ctc 7.159871 loss_rnnt 3.362176 hw_loss 0.178486 lr 0.00029088 rank 1
2023-03-01 07:40:18,596 DEBUG TRAIN Batch 51/5500 loss 3.550232 loss_att 5.608470 loss_ctc 4.579056 loss_rnnt 2.878952 hw_loss 0.229606 lr 0.00029088 rank 6
2023-03-01 07:40:18,597 DEBUG TRAIN Batch 51/5500 loss 6.097485 loss_att 9.652946 loss_ctc 11.221228 loss_rnnt 4.621313 hw_loss 0.153589 lr 0.00029087 rank 7
2023-03-01 07:40:18,599 DEBUG TRAIN Batch 51/5500 loss 6.935386 loss_att 7.765079 loss_ctc 8.230623 loss_rnnt 6.486737 hw_loss 0.206271 lr 0.00029088 rank 4
2023-03-01 07:40:18,600 DEBUG TRAIN Batch 51/5500 loss 3.369839 loss_att 6.517613 loss_ctc 6.056560 loss_rnnt 2.253075 hw_loss 0.241836 lr 0.00029089 rank 2
2023-03-01 07:40:18,633 DEBUG TRAIN Batch 51/5500 loss 5.317407 loss_att 7.275295 loss_ctc 8.118869 loss_rnnt 4.389846 hw_loss 0.304603 lr 0.00029088 rank 5
2023-03-01 07:40:18,644 DEBUG TRAIN Batch 51/5500 loss 10.381727 loss_att 11.699883 loss_ctc 20.391346 loss_rnnt 8.656898 hw_loss 0.237340 lr 0.00029087 rank 3
2023-03-01 07:40:57,634 DEBUG TRAIN Batch 51/5600 loss 4.715092 loss_att 6.334018 loss_ctc 9.441555 loss_rnnt 3.666203 hw_loss 0.177954 lr 0.00029087 rank 6
2023-03-01 07:40:57,637 DEBUG TRAIN Batch 51/5600 loss 6.926011 loss_att 9.998188 loss_ctc 9.274304 loss_rnnt 5.904182 hw_loss 0.176787 lr 0.00029087 rank 1
2023-03-01 07:40:57,638 DEBUG TRAIN Batch 51/5600 loss 3.877258 loss_att 5.932362 loss_ctc 5.876464 loss_rnnt 3.058222 hw_loss 0.265225 lr 0.00029086 rank 5
2023-03-01 07:40:57,649 DEBUG TRAIN Batch 51/5600 loss 5.323606 loss_att 8.369082 loss_ctc 8.538167 loss_rnnt 4.163754 hw_loss 0.229030 lr 0.00029086 rank 7
2023-03-01 07:40:57,649 DEBUG TRAIN Batch 51/5600 loss 4.192697 loss_att 7.119243 loss_ctc 4.702509 loss_rnnt 3.398082 hw_loss 0.264995 lr 0.00029087 rank 0
2023-03-01 07:40:57,653 DEBUG TRAIN Batch 51/5600 loss 6.607079 loss_att 8.674234 loss_ctc 10.364380 loss_rnnt 5.577953 hw_loss 0.215102 lr 0.00029087 rank 2
2023-03-01 07:40:57,659 DEBUG TRAIN Batch 51/5600 loss 17.208090 loss_att 21.068207 loss_ctc 28.858913 loss_rnnt 14.836869 hw_loss 0.085786 lr 0.00029086 rank 3
2023-03-01 07:40:57,685 DEBUG TRAIN Batch 51/5600 loss 13.377022 loss_att 16.274410 loss_ctc 21.024254 loss_rnnt 11.686094 hw_loss 0.172162 lr 0.00029087 rank 4
2023-03-01 07:42:04,677 DEBUG TRAIN Batch 51/5700 loss 4.464797 loss_att 5.122156 loss_ctc 7.971089 loss_rnnt 3.734394 hw_loss 0.246421 lr 0.00029086 rank 2
2023-03-01 07:42:04,680 DEBUG TRAIN Batch 51/5700 loss 3.407847 loss_att 6.432334 loss_ctc 7.407932 loss_rnnt 2.127531 hw_loss 0.266388 lr 0.00029086 rank 0
2023-03-01 07:42:04,679 DEBUG TRAIN Batch 51/5700 loss 11.676485 loss_att 14.201785 loss_ctc 18.835463 loss_rnnt 10.091697 hw_loss 0.234747 lr 0.00029086 rank 4
2023-03-01 07:42:04,680 DEBUG TRAIN Batch 51/5700 loss 5.480725 loss_att 7.017212 loss_ctc 8.976791 loss_rnnt 4.550394 hw_loss 0.294170 lr 0.00029085 rank 3
2023-03-01 07:42:04,680 DEBUG TRAIN Batch 51/5700 loss 4.720195 loss_att 7.139219 loss_ctc 10.419739 loss_rnnt 3.366396 hw_loss 0.206354 lr 0.00029084 rank 7
2023-03-01 07:42:04,686 DEBUG TRAIN Batch 51/5700 loss 6.201495 loss_att 7.776110 loss_ctc 8.133289 loss_rnnt 5.477514 hw_loss 0.284036 lr 0.00029086 rank 1
2023-03-01 07:42:04,692 DEBUG TRAIN Batch 51/5700 loss 5.017000 loss_att 6.550621 loss_ctc 7.609900 loss_rnnt 4.159520 hw_loss 0.384442 lr 0.00029085 rank 6
2023-03-01 07:42:04,742 DEBUG TRAIN Batch 51/5700 loss 4.916717 loss_att 5.226580 loss_ctc 7.027525 loss_rnnt 4.379264 hw_loss 0.363825 lr 0.00029085 rank 5
2023-03-01 07:42:43,260 DEBUG TRAIN Batch 51/5800 loss 4.098930 loss_att 6.382073 loss_ctc 7.603380 loss_rnnt 3.040115 hw_loss 0.252987 lr 0.00029084 rank 4
2023-03-01 07:42:43,262 DEBUG TRAIN Batch 51/5800 loss 3.745909 loss_att 8.823338 loss_ctc 8.640074 loss_rnnt 1.883393 hw_loss 0.364641 lr 0.00029084 rank 1
2023-03-01 07:42:43,268 DEBUG TRAIN Batch 51/5800 loss 5.503374 loss_att 7.825555 loss_ctc 10.722156 loss_rnnt 4.212186 hw_loss 0.245463 lr 0.00029083 rank 7
2023-03-01 07:42:43,268 DEBUG TRAIN Batch 51/5800 loss 11.479781 loss_att 16.486214 loss_ctc 27.415512 loss_rnnt 8.207670 hw_loss 0.273864 lr 0.00029084 rank 6
2023-03-01 07:42:43,268 DEBUG TRAIN Batch 51/5800 loss 7.679508 loss_att 10.650873 loss_ctc 15.057816 loss_rnnt 5.939497 hw_loss 0.303683 lr 0.00029085 rank 0
2023-03-01 07:42:43,273 DEBUG TRAIN Batch 51/5800 loss 4.719111 loss_att 6.040544 loss_ctc 5.461802 loss_rnnt 4.256511 hw_loss 0.186166 lr 0.00029085 rank 2
2023-03-01 07:42:43,276 DEBUG TRAIN Batch 51/5800 loss 5.835527 loss_att 9.088593 loss_ctc 10.838561 loss_rnnt 4.443468 hw_loss 0.139455 lr 0.00029084 rank 3
2023-03-01 07:42:43,296 DEBUG TRAIN Batch 51/5800 loss 3.612652 loss_att 7.147041 loss_ctc 8.044600 loss_rnnt 2.211795 hw_loss 0.193225 lr 0.00029084 rank 5
2023-03-01 07:43:22,131 DEBUG TRAIN Batch 51/5900 loss 6.194567 loss_att 9.901845 loss_ctc 12.629538 loss_rnnt 4.465789 hw_loss 0.242487 lr 0.00029083 rank 5
2023-03-01 07:43:22,132 DEBUG TRAIN Batch 51/5900 loss 2.279924 loss_att 7.271097 loss_ctc 3.302420 loss_rnnt 0.956157 hw_loss 0.354750 lr 0.00029083 rank 6
2023-03-01 07:43:22,137 DEBUG TRAIN Batch 51/5900 loss 8.554830 loss_att 11.631709 loss_ctc 14.724201 loss_rnnt 7.032656 hw_loss 0.157902 lr 0.00029083 rank 0
2023-03-01 07:43:22,141 DEBUG TRAIN Batch 51/5900 loss 4.527756 loss_att 5.255394 loss_ctc 6.172577 loss_rnnt 3.969681 hw_loss 0.362323 lr 0.00029082 rank 7
2023-03-01 07:43:22,143 DEBUG TRAIN Batch 51/5900 loss 5.109148 loss_att 9.914211 loss_ctc 8.810828 loss_rnnt 3.581112 hw_loss 0.137746 lr 0.00029083 rank 1
2023-03-01 07:43:22,144 DEBUG TRAIN Batch 51/5900 loss 1.362670 loss_att 3.817310 loss_ctc 2.032701 loss_rnnt 0.650191 hw_loss 0.247900 lr 0.00029083 rank 4
2023-03-01 07:43:22,145 DEBUG TRAIN Batch 51/5900 loss 4.477605 loss_att 6.708546 loss_ctc 5.776885 loss_rnnt 3.760484 hw_loss 0.183180 lr 0.00029082 rank 3
2023-03-01 07:43:22,148 DEBUG TRAIN Batch 51/5900 loss 8.680480 loss_att 13.816277 loss_ctc 14.700390 loss_rnnt 6.804852 hw_loss 0.085899 lr 0.00029084 rank 2
2023-03-01 07:44:01,716 DEBUG TRAIN Batch 51/6000 loss 4.347412 loss_att 5.805224 loss_ctc 10.144720 loss_rnnt 3.205450 hw_loss 0.145173 lr 0.00029082 rank 4
2023-03-01 07:44:01,720 DEBUG TRAIN Batch 51/6000 loss 5.188975 loss_att 7.563252 loss_ctc 6.970620 loss_rnnt 4.448475 hw_loss 0.052672 lr 0.00029081 rank 3
2023-03-01 07:44:01,728 DEBUG TRAIN Batch 51/6000 loss 2.369458 loss_att 5.804774 loss_ctc 3.741229 loss_rnnt 1.413667 hw_loss 0.160921 lr 0.00029082 rank 1
2023-03-01 07:44:01,733 DEBUG TRAIN Batch 51/6000 loss 6.406752 loss_att 9.348433 loss_ctc 7.806847 loss_rnnt 5.556014 hw_loss 0.141981 lr 0.00029082 rank 0
2023-03-01 07:44:01,735 DEBUG TRAIN Batch 51/6000 loss 2.339246 loss_att 5.692541 loss_ctc 4.190645 loss_rnnt 1.289210 hw_loss 0.248482 lr 0.00029081 rank 7
2023-03-01 07:44:01,737 DEBUG TRAIN Batch 51/6000 loss 5.402259 loss_att 8.241507 loss_ctc 8.230574 loss_rnnt 4.324411 hw_loss 0.249169 lr 0.00029082 rank 2
2023-03-01 07:44:01,750 DEBUG TRAIN Batch 51/6000 loss 11.140330 loss_att 12.335495 loss_ctc 20.184074 loss_rnnt 9.581766 hw_loss 0.213185 lr 0.00029082 rank 6
2023-03-01 07:44:01,781 DEBUG TRAIN Batch 51/6000 loss 10.492793 loss_att 13.378441 loss_ctc 15.323427 loss_rnnt 9.123453 hw_loss 0.277736 lr 0.00029082 rank 5
2023-03-01 07:45:06,896 DEBUG TRAIN Batch 51/6100 loss 6.884685 loss_att 10.042994 loss_ctc 14.032068 loss_rnnt 5.175325 hw_loss 0.233838 lr 0.00029080 rank 3
2023-03-01 07:45:06,902 DEBUG TRAIN Batch 51/6100 loss 11.110679 loss_att 13.904831 loss_ctc 17.015865 loss_rnnt 9.675127 hw_loss 0.167557 lr 0.00029081 rank 1
2023-03-01 07:45:06,903 DEBUG TRAIN Batch 51/6100 loss 7.252316 loss_att 11.502592 loss_ctc 9.908960 loss_rnnt 5.945329 hw_loss 0.192584 lr 0.00029081 rank 2
2023-03-01 07:45:06,903 DEBUG TRAIN Batch 51/6100 loss 2.664453 loss_att 4.555556 loss_ctc 6.120299 loss_rnnt 1.761274 hw_loss 0.120334 lr 0.00029081 rank 0
2023-03-01 07:45:06,908 DEBUG TRAIN Batch 51/6100 loss 9.063991 loss_att 12.878428 loss_ctc 15.514971 loss_rnnt 7.309267 hw_loss 0.246946 lr 0.00029079 rank 7
2023-03-01 07:45:06,909 DEBUG TRAIN Batch 51/6100 loss 3.757389 loss_att 6.455548 loss_ctc 6.106574 loss_rnnt 2.728771 hw_loss 0.329552 lr 0.00029080 rank 5
2023-03-01 07:45:06,910 DEBUG TRAIN Batch 51/6100 loss 7.321845 loss_att 10.323715 loss_ctc 10.986460 loss_rnnt 6.071871 hw_loss 0.301845 lr 0.00029081 rank 6
2023-03-01 07:45:06,954 DEBUG TRAIN Batch 51/6100 loss 6.462790 loss_att 11.565401 loss_ctc 17.423786 loss_rnnt 3.955470 hw_loss 0.047495 lr 0.00029081 rank 4
2023-03-01 07:45:45,885 DEBUG TRAIN Batch 51/6200 loss 3.452116 loss_att 6.591498 loss_ctc 5.939934 loss_rnnt 2.342159 hw_loss 0.281947 lr 0.00029079 rank 5
2023-03-01 07:45:45,898 DEBUG TRAIN Batch 51/6200 loss 4.795103 loss_att 7.443076 loss_ctc 7.168455 loss_rnnt 3.806351 hw_loss 0.267584 lr 0.00029080 rank 1
2023-03-01 07:45:45,900 DEBUG TRAIN Batch 51/6200 loss 3.002628 loss_att 5.337009 loss_ctc 6.395813 loss_rnnt 1.953630 hw_loss 0.243183 lr 0.00029079 rank 3
2023-03-01 07:45:45,902 DEBUG TRAIN Batch 51/6200 loss 12.005495 loss_att 14.332673 loss_ctc 16.164137 loss_rnnt 10.814438 hw_loss 0.320878 lr 0.00029078 rank 7
2023-03-01 07:45:45,904 DEBUG TRAIN Batch 51/6200 loss 6.335259 loss_att 9.252484 loss_ctc 10.655199 loss_rnnt 5.073934 hw_loss 0.191040 lr 0.00029080 rank 2
2023-03-01 07:45:45,909 DEBUG TRAIN Batch 51/6200 loss 3.427463 loss_att 5.589913 loss_ctc 6.465544 loss_rnnt 2.506250 hw_loss 0.156836 lr 0.00029080 rank 0
2023-03-01 07:45:45,920 DEBUG TRAIN Batch 51/6200 loss 8.313878 loss_att 9.740486 loss_ctc 15.238864 loss_rnnt 7.020156 hw_loss 0.159503 lr 0.00029079 rank 6
2023-03-01 07:45:45,963 DEBUG TRAIN Batch 51/6200 loss 9.637428 loss_att 13.231747 loss_ctc 14.387308 loss_rnnt 8.195232 hw_loss 0.168778 lr 0.00029079 rank 4
2023-03-01 07:46:25,409 DEBUG TRAIN Batch 51/6300 loss 7.462561 loss_att 9.831724 loss_ctc 16.496231 loss_rnnt 5.687380 hw_loss 0.181610 lr 0.00029078 rank 3
2023-03-01 07:46:25,411 DEBUG TRAIN Batch 51/6300 loss 8.878267 loss_att 9.931214 loss_ctc 15.030123 loss_rnnt 7.687425 hw_loss 0.300011 lr 0.00029078 rank 6
2023-03-01 07:46:25,412 DEBUG TRAIN Batch 51/6300 loss 4.683190 loss_att 6.950414 loss_ctc 6.764012 loss_rnnt 3.798746 hw_loss 0.287918 lr 0.00029078 rank 4
2023-03-01 07:46:25,414 DEBUG TRAIN Batch 51/6300 loss 5.719965 loss_att 9.534436 loss_ctc 15.339280 loss_rnnt 3.495230 hw_loss 0.336122 lr 0.00029077 rank 7
2023-03-01 07:46:25,414 DEBUG TRAIN Batch 51/6300 loss 4.636865 loss_att 6.356361 loss_ctc 7.619411 loss_rnnt 3.816050 hw_loss 0.148579 lr 0.00029079 rank 2
2023-03-01 07:46:25,414 DEBUG TRAIN Batch 51/6300 loss 1.026515 loss_att 3.138601 loss_ctc 1.873737 loss_rnnt 0.400454 hw_loss 0.170027 lr 0.00029078 rank 0
2023-03-01 07:46:25,415 DEBUG TRAIN Batch 51/6300 loss 7.183710 loss_att 9.356254 loss_ctc 9.930954 loss_rnnt 6.249186 hw_loss 0.250716 lr 0.00029078 rank 1
2023-03-01 07:46:25,431 DEBUG TRAIN Batch 51/6300 loss 7.133717 loss_att 7.401835 loss_ctc 10.749789 loss_rnnt 6.379760 hw_loss 0.409109 lr 0.00029078 rank 5
2023-03-01 07:47:32,842 DEBUG TRAIN Batch 51/6400 loss 7.332355 loss_att 8.546339 loss_ctc 10.720626 loss_rnnt 6.466386 hw_loss 0.321379 lr 0.00029076 rank 7
2023-03-01 07:47:32,844 DEBUG TRAIN Batch 51/6400 loss 8.918917 loss_att 8.769302 loss_ctc 14.735166 loss_rnnt 8.071507 hw_loss 0.190936 lr 0.00029077 rank 0
2023-03-01 07:47:32,847 DEBUG TRAIN Batch 51/6400 loss 6.146299 loss_att 8.257423 loss_ctc 8.525616 loss_rnnt 5.238173 hw_loss 0.316235 lr 0.00029077 rank 4
2023-03-01 07:47:32,849 DEBUG TRAIN Batch 51/6400 loss 7.507399 loss_att 12.632023 loss_ctc 10.436159 loss_rnnt 5.952545 hw_loss 0.261427 lr 0.00029076 rank 3
2023-03-01 07:47:32,853 DEBUG TRAIN Batch 51/6400 loss 3.155499 loss_att 6.177213 loss_ctc 4.658988 loss_rnnt 2.246162 hw_loss 0.195993 lr 0.00029077 rank 2
2023-03-01 07:47:32,854 DEBUG TRAIN Batch 51/6400 loss 5.411765 loss_att 8.513889 loss_ctc 10.773706 loss_rnnt 3.924837 hw_loss 0.284208 lr 0.00029077 rank 6
2023-03-01 07:47:32,857 DEBUG TRAIN Batch 51/6400 loss 2.276615 loss_att 4.195477 loss_ctc 2.846261 loss_rnnt 1.709917 hw_loss 0.200575 lr 0.00029077 rank 5
2023-03-01 07:47:32,877 DEBUG TRAIN Batch 51/6400 loss 6.469592 loss_att 7.440098 loss_ctc 9.058034 loss_rnnt 5.807153 hw_loss 0.231022 lr 0.00029077 rank 1
2023-03-01 07:48:12,182 DEBUG TRAIN Batch 51/6500 loss 2.656255 loss_att 7.090860 loss_ctc 7.088873 loss_rnnt 1.058805 hw_loss 0.224088 lr 0.00029076 rank 2
2023-03-01 07:48:12,185 DEBUG TRAIN Batch 51/6500 loss 1.651009 loss_att 4.628611 loss_ctc 3.146396 loss_rnnt 0.790468 hw_loss 0.123067 lr 0.00029075 rank 7
2023-03-01 07:48:12,205 DEBUG TRAIN Batch 51/6500 loss 4.023296 loss_att 9.055327 loss_ctc 11.650111 loss_rnnt 1.861378 hw_loss 0.259882 lr 0.00029076 rank 4
2023-03-01 07:48:12,204 DEBUG TRAIN Batch 51/6500 loss 5.872333 loss_att 10.030217 loss_ctc 13.464491 loss_rnnt 3.894645 hw_loss 0.250918 lr 0.00029076 rank 0
2023-03-01 07:48:12,205 DEBUG TRAIN Batch 51/6500 loss 4.426587 loss_att 7.709029 loss_ctc 6.477344 loss_rnnt 3.392762 hw_loss 0.194816 lr 0.00029076 rank 6
2023-03-01 07:48:12,205 DEBUG TRAIN Batch 51/6500 loss 4.098927 loss_att 6.316175 loss_ctc 6.249760 loss_rnnt 3.258121 hw_loss 0.207334 lr 0.00029075 rank 5
2023-03-01 07:48:12,205 DEBUG TRAIN Batch 51/6500 loss 6.638509 loss_att 8.913784 loss_ctc 16.264429 loss_rnnt 4.701238 hw_loss 0.372674 lr 0.00029076 rank 1
2023-03-01 07:48:12,207 DEBUG TRAIN Batch 51/6500 loss 6.340800 loss_att 9.214634 loss_ctc 14.120207 loss_rnnt 4.678826 hw_loss 0.093661 lr 0.00029075 rank 3
2023-03-01 07:48:50,990 DEBUG TRAIN Batch 51/6600 loss 6.996323 loss_att 8.199522 loss_ctc 13.458380 loss_rnnt 5.795609 hw_loss 0.184625 lr 0.00029073 rank 7
2023-03-01 07:48:51,005 DEBUG TRAIN Batch 51/6600 loss 3.368657 loss_att 5.574183 loss_ctc 3.479529 loss_rnnt 2.836873 hw_loss 0.142304 lr 0.00029074 rank 5
2023-03-01 07:48:51,009 DEBUG TRAIN Batch 51/6600 loss 7.189244 loss_att 12.097549 loss_ctc 12.360079 loss_rnnt 5.361312 hw_loss 0.294049 lr 0.00029074 rank 6
2023-03-01 07:48:51,009 DEBUG TRAIN Batch 51/6600 loss 2.013625 loss_att 3.648507 loss_ctc 4.362526 loss_rnnt 1.244754 hw_loss 0.241329 lr 0.00029075 rank 0
2023-03-01 07:48:51,011 DEBUG TRAIN Batch 51/6600 loss 0.748121 loss_att 2.661266 loss_ctc 1.349739 loss_rnnt 0.219289 hw_loss 0.123725 lr 0.00029074 rank 3
2023-03-01 07:48:51,015 DEBUG TRAIN Batch 51/6600 loss 5.307496 loss_att 9.147494 loss_ctc 7.807866 loss_rnnt 4.055370 hw_loss 0.282645 lr 0.00029075 rank 2
2023-03-01 07:48:51,016 DEBUG TRAIN Batch 51/6600 loss 6.126807 loss_att 9.292375 loss_ctc 9.159315 loss_rnnt 5.041534 hw_loss 0.089670 lr 0.00029075 rank 1
2023-03-01 07:48:51,033 DEBUG TRAIN Batch 51/6600 loss 6.244954 loss_att 9.176525 loss_ctc 9.104113 loss_rnnt 5.256060 hw_loss 0.040048 lr 0.00029074 rank 4
2023-03-01 07:49:30,423 DEBUG TRAIN Batch 51/6700 loss 6.560993 loss_att 9.736584 loss_ctc 12.730329 loss_rnnt 5.003474 hw_loss 0.187168 lr 0.00029073 rank 4
2023-03-01 07:49:30,424 DEBUG TRAIN Batch 51/6700 loss 4.276619 loss_att 7.030199 loss_ctc 9.132444 loss_rnnt 3.000665 hw_loss 0.145865 lr 0.00029074 rank 2
2023-03-01 07:49:30,438 DEBUG TRAIN Batch 51/6700 loss 10.505414 loss_att 13.223247 loss_ctc 16.255177 loss_rnnt 9.125039 hw_loss 0.131574 lr 0.00029072 rank 7
2023-03-01 07:49:30,438 DEBUG TRAIN Batch 51/6700 loss 1.870170 loss_att 4.453066 loss_ctc 4.567302 loss_rnnt 0.899083 hw_loss 0.177920 lr 0.00029074 rank 0
2023-03-01 07:49:30,441 DEBUG TRAIN Batch 51/6700 loss 12.252387 loss_att 13.322999 loss_ctc 20.062374 loss_rnnt 10.885172 hw_loss 0.209550 lr 0.00029073 rank 1
2023-03-01 07:49:30,441 DEBUG TRAIN Batch 51/6700 loss 5.952786 loss_att 9.469591 loss_ctc 10.768425 loss_rnnt 4.509845 hw_loss 0.182801 lr 0.00029073 rank 3
2023-03-01 07:49:30,456 DEBUG TRAIN Batch 51/6700 loss 3.532757 loss_att 5.512038 loss_ctc 8.049901 loss_rnnt 2.403704 hw_loss 0.245457 lr 0.00029073 rank 6
2023-03-01 07:49:30,487 DEBUG TRAIN Batch 51/6700 loss 6.581334 loss_att 11.599580 loss_ctc 12.809058 loss_rnnt 4.625953 hw_loss 0.227565 lr 0.00029073 rank 5
2023-03-01 07:50:36,243 DEBUG TRAIN Batch 51/6800 loss 6.989403 loss_att 10.575708 loss_ctc 10.773383 loss_rnnt 5.635719 hw_loss 0.247298 lr 0.00029073 rank 2
2023-03-01 07:50:36,244 DEBUG TRAIN Batch 51/6800 loss 7.613050 loss_att 10.442702 loss_ctc 11.995218 loss_rnnt 6.358562 hw_loss 0.195503 lr 0.00029072 rank 4
2023-03-01 07:50:36,244 DEBUG TRAIN Batch 51/6800 loss 6.294480 loss_att 9.555861 loss_ctc 14.426726 loss_rnnt 4.413260 hw_loss 0.271208 lr 0.00029072 rank 1
2023-03-01 07:50:36,259 DEBUG TRAIN Batch 51/6800 loss 4.707556 loss_att 8.238897 loss_ctc 8.659729 loss_rnnt 3.343326 hw_loss 0.245635 lr 0.00029072 rank 0
2023-03-01 07:50:36,260 DEBUG TRAIN Batch 51/6800 loss 5.014051 loss_att 10.629299 loss_ctc 14.517696 loss_rnnt 2.499148 hw_loss 0.233815 lr 0.00029071 rank 7
2023-03-01 07:50:36,260 DEBUG TRAIN Batch 51/6800 loss 6.922584 loss_att 8.572023 loss_ctc 11.250552 loss_rnnt 5.908385 hw_loss 0.201090 lr 0.00029072 rank 5
2023-03-01 07:50:36,263 DEBUG TRAIN Batch 51/6800 loss 3.650306 loss_att 6.615830 loss_ctc 6.985834 loss_rnnt 2.483584 hw_loss 0.241649 lr 0.00029072 rank 6
2023-03-01 07:50:36,270 DEBUG TRAIN Batch 51/6800 loss 3.310551 loss_att 7.006222 loss_ctc 8.152066 loss_rnnt 1.826423 hw_loss 0.186484 lr 0.00029071 rank 3
2023-03-01 07:51:15,154 DEBUG TRAIN Batch 51/6900 loss 4.487166 loss_att 8.345545 loss_ctc 7.301157 loss_rnnt 3.279671 hw_loss 0.113662 lr 0.00029071 rank 6
2023-03-01 07:51:15,171 DEBUG TRAIN Batch 51/6900 loss 5.236144 loss_att 7.325855 loss_ctc 6.255662 loss_rnnt 4.532956 hw_loss 0.279958 lr 0.00029070 rank 7
2023-03-01 07:51:15,174 DEBUG TRAIN Batch 51/6900 loss 11.793649 loss_att 16.848227 loss_ctc 22.018410 loss_rnnt 9.359631 hw_loss 0.112126 lr 0.00029071 rank 0
2023-03-01 07:51:15,174 DEBUG TRAIN Batch 51/6900 loss 8.316732 loss_att 9.578568 loss_ctc 13.781608 loss_rnnt 7.211906 hw_loss 0.232142 lr 0.00029071 rank 1
2023-03-01 07:51:15,177 DEBUG TRAIN Batch 51/6900 loss 8.370866 loss_att 10.300114 loss_ctc 10.263132 loss_rnnt 7.575968 hw_loss 0.293898 lr 0.00029071 rank 4
2023-03-01 07:51:15,178 DEBUG TRAIN Batch 51/6900 loss 7.292878 loss_att 8.690647 loss_ctc 7.341471 loss_rnnt 6.847742 hw_loss 0.298320 lr 0.00029071 rank 5
2023-03-01 07:51:15,180 DEBUG TRAIN Batch 51/6900 loss 7.020798 loss_att 9.706066 loss_ctc 12.462081 loss_rnnt 5.628860 hw_loss 0.242587 lr 0.00029071 rank 2
2023-03-01 07:51:15,185 DEBUG TRAIN Batch 51/6900 loss 6.589364 loss_att 7.282310 loss_ctc 10.773990 loss_rnnt 5.792415 hw_loss 0.188268 lr 0.00029070 rank 3
2023-03-01 07:51:54,075 DEBUG TRAIN Batch 51/7000 loss 2.260585 loss_att 5.227232 loss_ctc 3.661602 loss_rnnt 1.387551 hw_loss 0.174191 lr 0.00029070 rank 2
2023-03-01 07:51:54,087 DEBUG TRAIN Batch 51/7000 loss 6.087817 loss_att 9.184412 loss_ctc 6.400826 loss_rnnt 5.318956 hw_loss 0.202140 lr 0.00029069 rank 5
2023-03-01 07:51:54,088 DEBUG TRAIN Batch 51/7000 loss 7.439132 loss_att 9.824755 loss_ctc 13.825464 loss_rnnt 5.938720 hw_loss 0.322081 lr 0.00029070 rank 0
2023-03-01 07:51:54,088 DEBUG TRAIN Batch 51/7000 loss 7.107361 loss_att 7.003109 loss_ctc 10.658596 loss_rnnt 6.404603 hw_loss 0.468956 lr 0.00029070 rank 1
2023-03-01 07:51:54,090 DEBUG TRAIN Batch 51/7000 loss 6.929140 loss_att 9.085175 loss_ctc 9.255527 loss_rnnt 6.065054 hw_loss 0.230051 lr 0.00029069 rank 3
2023-03-01 07:51:54,090 DEBUG TRAIN Batch 51/7000 loss 5.641560 loss_att 8.915833 loss_ctc 12.338594 loss_rnnt 4.069417 hw_loss 0.045656 lr 0.00029068 rank 7
2023-03-01 07:51:54,091 DEBUG TRAIN Batch 51/7000 loss 11.819749 loss_att 14.298922 loss_ctc 16.842474 loss_rnnt 10.591029 hw_loss 0.118479 lr 0.00029070 rank 4
2023-03-01 07:51:54,099 DEBUG TRAIN Batch 51/7000 loss 3.256301 loss_att 6.037447 loss_ctc 9.078859 loss_rnnt 1.784286 hw_loss 0.261459 lr 0.00029069 rank 6
2023-03-01 07:52:56,494 DEBUG TRAIN Batch 51/7100 loss 9.213560 loss_att 9.394411 loss_ctc 13.256343 loss_rnnt 8.496758 hw_loss 0.265489 lr 0.00029067 rank 7
2023-03-01 07:52:56,496 DEBUG TRAIN Batch 51/7100 loss 2.852132 loss_att 5.275164 loss_ctc 3.526518 loss_rnnt 2.098319 hw_loss 0.336167 lr 0.00029069 rank 0
2023-03-01 07:52:56,498 DEBUG TRAIN Batch 51/7100 loss 2.020202 loss_att 4.786924 loss_ctc 3.542570 loss_rnnt 1.196966 hw_loss 0.125454 lr 0.00029068 rank 1
2023-03-01 07:52:56,500 DEBUG TRAIN Batch 51/7100 loss 3.689013 loss_att 5.640374 loss_ctc 6.192647 loss_rnnt 2.864361 hw_loss 0.188555 lr 0.00029068 rank 3
2023-03-01 07:52:56,505 DEBUG TRAIN Batch 51/7100 loss 4.384856 loss_att 7.401103 loss_ctc 9.395353 loss_rnnt 3.010898 hw_loss 0.192456 lr 0.00029069 rank 2
2023-03-01 07:52:56,516 DEBUG TRAIN Batch 51/7100 loss 7.981448 loss_att 12.182540 loss_ctc 10.958252 loss_rnnt 6.673220 hw_loss 0.133317 lr 0.00029068 rank 4
2023-03-01 07:52:56,525 DEBUG TRAIN Batch 51/7100 loss 5.430892 loss_att 9.093300 loss_ctc 6.617179 loss_rnnt 4.476323 hw_loss 0.119840 lr 0.00029068 rank 6
2023-03-01 07:52:56,550 DEBUG TRAIN Batch 51/7100 loss 3.044537 loss_att 5.418610 loss_ctc 2.949968 loss_rnnt 2.468193 hw_loss 0.214010 lr 0.00029068 rank 5
2023-03-01 07:53:39,754 DEBUG TRAIN Batch 51/7200 loss 8.447660 loss_att 11.459723 loss_ctc 15.549628 loss_rnnt 6.750526 hw_loss 0.277111 lr 0.00029066 rank 7
2023-03-01 07:53:39,773 DEBUG TRAIN Batch 51/7200 loss 8.472719 loss_att 12.588921 loss_ctc 14.000350 loss_rnnt 6.855534 hw_loss 0.106741 lr 0.00029067 rank 4
2023-03-01 07:53:39,774 DEBUG TRAIN Batch 51/7200 loss 2.638443 loss_att 4.588015 loss_ctc 3.138209 loss_rnnt 2.089450 hw_loss 0.173330 lr 0.00029067 rank 0
2023-03-01 07:53:39,775 DEBUG TRAIN Batch 51/7200 loss 2.855924 loss_att 4.732704 loss_ctc 3.708891 loss_rnnt 2.217567 hw_loss 0.279885 lr 0.00029068 rank 2
2023-03-01 07:53:39,774 DEBUG TRAIN Batch 51/7200 loss 8.395979 loss_att 10.640789 loss_ctc 10.330729 loss_rnnt 7.634675 hw_loss 0.101952 lr 0.00029067 rank 6
2023-03-01 07:53:39,776 DEBUG TRAIN Batch 51/7200 loss 8.294589 loss_att 10.772549 loss_ctc 12.220085 loss_rnnt 7.140935 hw_loss 0.252493 lr 0.00029067 rank 1
2023-03-01 07:53:39,778 DEBUG TRAIN Batch 51/7200 loss 1.231236 loss_att 3.036984 loss_ctc 1.250326 loss_rnnt 0.669244 hw_loss 0.371807 lr 0.00029066 rank 3
2023-03-01 07:53:39,789 DEBUG TRAIN Batch 51/7200 loss 6.324164 loss_att 10.495474 loss_ctc 18.174055 loss_rnnt 3.816634 hw_loss 0.174904 lr 0.00029067 rank 5
2023-03-01 07:54:18,772 DEBUG TRAIN Batch 51/7300 loss 6.627385 loss_att 8.751279 loss_ctc 10.148610 loss_rnnt 5.664966 hw_loss 0.127770 lr 0.00029066 rank 2
2023-03-01 07:54:18,773 DEBUG TRAIN Batch 51/7300 loss 0.935207 loss_att 3.363024 loss_ctc 0.726273 loss_rnnt 0.362833 hw_loss 0.215004 lr 0.00029066 rank 0
2023-03-01 07:54:18,776 DEBUG TRAIN Batch 51/7300 loss 4.297570 loss_att 7.966802 loss_ctc 7.828695 loss_rnnt 2.995339 hw_loss 0.182940 lr 0.00029066 rank 4
2023-03-01 07:54:18,777 DEBUG TRAIN Batch 51/7300 loss 10.844041 loss_att 13.602562 loss_ctc 18.539749 loss_rnnt 9.142267 hw_loss 0.232452 lr 0.00029066 rank 1
2023-03-01 07:54:18,779 DEBUG TRAIN Batch 51/7300 loss 4.816887 loss_att 7.900582 loss_ctc 6.991691 loss_rnnt 3.771733 hw_loss 0.259577 lr 0.00029066 rank 5
2023-03-01 07:54:18,780 DEBUG TRAIN Batch 51/7300 loss 4.038933 loss_att 6.556007 loss_ctc 5.817958 loss_rnnt 3.233514 hw_loss 0.121504 lr 0.00029065 rank 7
2023-03-01 07:54:18,783 DEBUG TRAIN Batch 51/7300 loss 6.209935 loss_att 9.228950 loss_ctc 12.525103 loss_rnnt 4.614213 hw_loss 0.281057 lr 0.00029066 rank 6
2023-03-01 07:54:18,784 DEBUG TRAIN Batch 51/7300 loss 1.884500 loss_att 6.164883 loss_ctc 2.774582 loss_rnnt 0.792312 hw_loss 0.220189 lr 0.00029065 rank 3
2023-03-01 07:54:58,188 DEBUG TRAIN Batch 51/7400 loss 6.178266 loss_att 9.508734 loss_ctc 11.553482 loss_rnnt 4.726293 hw_loss 0.129720 lr 0.00029064 rank 3
2023-03-01 07:54:58,195 DEBUG TRAIN Batch 51/7400 loss 3.277793 loss_att 5.173195 loss_ctc 4.934805 loss_rnnt 2.540690 hw_loss 0.257039 lr 0.00029064 rank 5
2023-03-01 07:54:58,204 DEBUG TRAIN Batch 51/7400 loss 11.401035 loss_att 14.005083 loss_ctc 13.726036 loss_rnnt 10.531436 hw_loss 0.072732 lr 0.00029065 rank 1
2023-03-01 07:54:58,207 DEBUG TRAIN Batch 51/7400 loss 4.209422 loss_att 6.445846 loss_ctc 7.615643 loss_rnnt 3.133846 hw_loss 0.326492 lr 0.00029065 rank 2
2023-03-01 07:54:58,208 DEBUG TRAIN Batch 51/7400 loss 4.353502 loss_att 7.490918 loss_ctc 8.432663 loss_rnnt 3.091652 hw_loss 0.169647 lr 0.00029065 rank 0
2023-03-01 07:54:58,210 DEBUG TRAIN Batch 51/7400 loss 7.497549 loss_att 10.335489 loss_ctc 12.210202 loss_rnnt 6.179451 hw_loss 0.229042 lr 0.00029063 rank 7
2023-03-01 07:54:58,210 DEBUG TRAIN Batch 51/7400 loss 4.606343 loss_att 7.799229 loss_ctc 8.924387 loss_rnnt 3.275110 hw_loss 0.219218 lr 0.00029065 rank 6
2023-03-01 07:54:58,212 DEBUG TRAIN Batch 51/7400 loss 4.112702 loss_att 6.186628 loss_ctc 6.691689 loss_rnnt 3.300576 hw_loss 0.100267 lr 0.00029065 rank 4
2023-03-01 07:56:04,343 DEBUG TRAIN Batch 51/7500 loss 6.119357 loss_att 7.007761 loss_ctc 9.395618 loss_rnnt 5.337327 hw_loss 0.314091 lr 0.00029063 rank 5
2023-03-01 07:56:04,346 DEBUG TRAIN Batch 51/7500 loss 3.727298 loss_att 6.485448 loss_ctc 6.708832 loss_rnnt 2.722817 hw_loss 0.103711 lr 0.00029064 rank 2
2023-03-01 07:56:04,360 DEBUG TRAIN Batch 51/7500 loss 7.603706 loss_att 9.549977 loss_ctc 12.985027 loss_rnnt 6.352555 hw_loss 0.270725 lr 0.00029062 rank 7
2023-03-01 07:56:04,365 DEBUG TRAIN Batch 51/7500 loss 9.980330 loss_att 14.201025 loss_ctc 18.665424 loss_rnnt 7.869499 hw_loss 0.203777 lr 0.00029064 rank 1
2023-03-01 07:56:04,366 DEBUG TRAIN Batch 51/7500 loss 7.596916 loss_att 10.889292 loss_ctc 11.130855 loss_rnnt 6.376047 hw_loss 0.171004 lr 0.00029064 rank 0
2023-03-01 07:56:04,370 DEBUG TRAIN Batch 51/7500 loss 6.575239 loss_att 9.740715 loss_ctc 10.756124 loss_rnnt 5.282825 hw_loss 0.191004 lr 0.00029063 rank 6
2023-03-01 07:56:04,371 DEBUG TRAIN Batch 51/7500 loss 9.899745 loss_att 10.135596 loss_ctc 14.892319 loss_rnnt 9.096686 hw_loss 0.169146 lr 0.00029063 rank 3
2023-03-01 07:56:04,372 DEBUG TRAIN Batch 51/7500 loss 4.640022 loss_att 8.228298 loss_ctc 7.537563 loss_rnnt 3.512860 hw_loss 0.043439 lr 0.00029063 rank 4
2023-03-01 07:56:43,674 DEBUG TRAIN Batch 51/7600 loss 4.530902 loss_att 6.542234 loss_ctc 6.490728 loss_rnnt 3.756234 hw_loss 0.208295 lr 0.00029063 rank 2
2023-03-01 07:56:43,682 DEBUG TRAIN Batch 51/7600 loss 5.332299 loss_att 6.902031 loss_ctc 6.512234 loss_rnnt 4.736265 hw_loss 0.233931 lr 0.00029062 rank 6
2023-03-01 07:56:43,692 DEBUG TRAIN Batch 51/7600 loss 8.929469 loss_att 11.401599 loss_ctc 12.755209 loss_rnnt 7.796967 hw_loss 0.239958 lr 0.00029061 rank 7
2023-03-01 07:56:43,693 DEBUG TRAIN Batch 51/7600 loss 8.685559 loss_att 11.785297 loss_ctc 16.775784 loss_rnnt 6.889032 hw_loss 0.183529 lr 0.00029062 rank 0
2023-03-01 07:56:43,697 DEBUG TRAIN Batch 51/7600 loss 9.172097 loss_att 13.297029 loss_ctc 15.217151 loss_rnnt 7.401800 hw_loss 0.261194 lr 0.00029062 rank 1
2023-03-01 07:56:43,697 DEBUG TRAIN Batch 51/7600 loss 5.169486 loss_att 8.726453 loss_ctc 8.320273 loss_rnnt 3.958150 hw_loss 0.149695 lr 0.00029062 rank 4
2023-03-01 07:56:43,699 DEBUG TRAIN Batch 51/7600 loss 2.052186 loss_att 4.612195 loss_ctc 5.533590 loss_rnnt 0.966899 hw_loss 0.204559 lr 0.00029062 rank 5
2023-03-01 07:56:43,701 DEBUG TRAIN Batch 51/7600 loss 7.091410 loss_att 8.043854 loss_ctc 10.092656 loss_rnnt 6.318873 hw_loss 0.341028 lr 0.00029062 rank 3
2023-03-01 07:57:22,308 DEBUG TRAIN Batch 51/7700 loss 4.737056 loss_att 6.055719 loss_ctc 10.148345 loss_rnnt 3.573338 hw_loss 0.334652 lr 0.00029061 rank 0
2023-03-01 07:57:22,311 DEBUG TRAIN Batch 51/7700 loss 9.673185 loss_att 11.666031 loss_ctc 10.391640 loss_rnnt 9.115019 hw_loss 0.119630 lr 0.00029060 rank 3
2023-03-01 07:57:22,312 DEBUG TRAIN Batch 51/7700 loss 5.959447 loss_att 7.184929 loss_ctc 9.770212 loss_rnnt 5.122013 hw_loss 0.157942 lr 0.00029060 rank 7
2023-03-01 07:57:22,314 DEBUG TRAIN Batch 51/7700 loss 3.318312 loss_att 4.980076 loss_ctc 5.808116 loss_rnnt 2.527797 hw_loss 0.236602 lr 0.00029061 rank 4
2023-03-01 07:57:22,315 DEBUG TRAIN Batch 51/7700 loss 9.181964 loss_att 11.810335 loss_ctc 14.441845 loss_rnnt 7.861724 hw_loss 0.174842 lr 0.00029061 rank 5
2023-03-01 07:57:22,319 DEBUG TRAIN Batch 51/7700 loss 3.266900 loss_att 5.954250 loss_ctc 6.895432 loss_rnnt 2.176466 hw_loss 0.129674 lr 0.00029061 rank 6
2023-03-01 07:57:22,334 DEBUG TRAIN Batch 51/7700 loss 7.404127 loss_att 11.386114 loss_ctc 14.772049 loss_rnnt 5.589460 hw_loss 0.067276 lr 0.00029061 rank 2
2023-03-01 07:57:22,371 DEBUG TRAIN Batch 51/7700 loss 4.022258 loss_att 6.893290 loss_ctc 8.528210 loss_rnnt 2.687044 hw_loss 0.300403 lr 0.00029061 rank 1
2023-03-01 07:58:02,237 DEBUG TRAIN Batch 51/7800 loss 3.302409 loss_att 6.380949 loss_ctc 6.312551 loss_rnnt 2.148241 hw_loss 0.257077 lr 0.00029060 rank 1
2023-03-01 07:58:02,237 DEBUG TRAIN Batch 51/7800 loss 4.081892 loss_att 6.349440 loss_ctc 4.248947 loss_rnnt 3.498492 hw_loss 0.201780 lr 0.00029059 rank 3
2023-03-01 07:58:02,244 DEBUG TRAIN Batch 51/7800 loss 3.516956 loss_att 6.590228 loss_ctc 5.317745 loss_rnnt 2.553817 hw_loss 0.203212 lr 0.00029059 rank 5
2023-03-01 07:58:02,248 DEBUG TRAIN Batch 51/7800 loss 2.315806 loss_att 5.525567 loss_ctc 6.717204 loss_rnnt 1.023167 hw_loss 0.119688 lr 0.00029060 rank 0
2023-03-01 07:58:02,251 DEBUG TRAIN Batch 51/7800 loss 8.169966 loss_att 12.237610 loss_ctc 9.917234 loss_rnnt 6.975051 hw_loss 0.278281 lr 0.00029060 rank 2
2023-03-01 07:58:02,251 DEBUG TRAIN Batch 51/7800 loss 2.970598 loss_att 6.096848 loss_ctc 4.475609 loss_rnnt 2.007204 hw_loss 0.257767 lr 0.00029059 rank 7
2023-03-01 07:58:02,255 DEBUG TRAIN Batch 51/7800 loss 4.425619 loss_att 7.229068 loss_ctc 6.440197 loss_rnnt 3.508146 hw_loss 0.165323 lr 0.00029060 rank 6
2023-03-01 07:58:02,286 DEBUG TRAIN Batch 51/7800 loss 8.178323 loss_att 14.438293 loss_ctc 15.131598 loss_rnnt 5.829997 hw_loss 0.317304 lr 0.00029060 rank 4
2023-03-01 07:59:07,773 DEBUG TRAIN Batch 51/7900 loss 11.681958 loss_att 15.946820 loss_ctc 23.023458 loss_rnnt 9.237730 hw_loss 0.148229 lr 0.00029059 rank 0
2023-03-01 07:59:07,775 DEBUG TRAIN Batch 51/7900 loss 6.061956 loss_att 8.470698 loss_ctc 10.413454 loss_rnnt 4.811925 hw_loss 0.352653 lr 0.00029059 rank 1
2023-03-01 07:59:07,776 DEBUG TRAIN Batch 51/7900 loss 10.340236 loss_att 16.839375 loss_ctc 20.723263 loss_rnnt 7.606645 hw_loss 0.092547 lr 0.00029057 rank 7
2023-03-01 07:59:07,778 DEBUG TRAIN Batch 51/7900 loss 8.768149 loss_att 10.558658 loss_ctc 13.706636 loss_rnnt 7.661015 hw_loss 0.169813 lr 0.00029059 rank 2
2023-03-01 07:59:07,781 DEBUG TRAIN Batch 51/7900 loss 3.026727 loss_att 6.457484 loss_ctc 3.712572 loss_rnnt 2.086621 hw_loss 0.304705 lr 0.00029058 rank 5
2023-03-01 07:59:07,783 DEBUG TRAIN Batch 51/7900 loss 4.739726 loss_att 7.192058 loss_ctc 6.135752 loss_rnnt 3.891220 hw_loss 0.322317 lr 0.00029058 rank 3
2023-03-01 07:59:07,785 DEBUG TRAIN Batch 51/7900 loss 3.973440 loss_att 6.336170 loss_ctc 6.838878 loss_rnnt 3.045985 hw_loss 0.136593 lr 0.00029058 rank 6
2023-03-01 07:59:07,818 DEBUG TRAIN Batch 51/7900 loss 1.384185 loss_att 3.563526 loss_ctc 2.309144 loss_rnnt 0.616403 hw_loss 0.391099 lr 0.00029059 rank 4
2023-03-01 07:59:45,969 DEBUG TRAIN Batch 51/8000 loss 6.782660 loss_att 8.473774 loss_ctc 9.760101 loss_rnnt 5.958599 hw_loss 0.166586 lr 0.00029057 rank 4
2023-03-01 07:59:45,974 DEBUG TRAIN Batch 51/8000 loss 12.012912 loss_att 16.363708 loss_ctc 18.844229 loss_rnnt 10.158155 hw_loss 0.138289 lr 0.00029056 rank 7
2023-03-01 07:59:45,974 DEBUG TRAIN Batch 51/8000 loss 11.858525 loss_att 13.597866 loss_ctc 19.328691 loss_rnnt 10.415715 hw_loss 0.185473 lr 0.00029058 rank 0
2023-03-01 07:59:45,975 DEBUG TRAIN Batch 51/8000 loss 9.538935 loss_att 11.695556 loss_ctc 10.855610 loss_rnnt 8.815827 hw_loss 0.217924 lr 0.00029057 rank 5
2023-03-01 07:59:45,976 DEBUG TRAIN Batch 51/8000 loss 7.079992 loss_att 9.150315 loss_ctc 10.542686 loss_rnnt 6.088088 hw_loss 0.217777 lr 0.00029057 rank 6
2023-03-01 07:59:45,977 DEBUG TRAIN Batch 51/8000 loss 8.571565 loss_att 9.453662 loss_ctc 14.122061 loss_rnnt 7.531793 hw_loss 0.231162 lr 0.00029058 rank 2
2023-03-01 07:59:45,977 DEBUG TRAIN Batch 51/8000 loss 6.425460 loss_att 10.561420 loss_ctc 12.495131 loss_rnnt 4.650456 hw_loss 0.259728 lr 0.00029057 rank 3
2023-03-01 07:59:45,979 DEBUG TRAIN Batch 51/8000 loss 3.919990 loss_att 5.323834 loss_ctc 4.841265 loss_rnnt 3.358778 hw_loss 0.295511 lr 0.00029057 rank 1
2023-03-01 08:00:25,072 DEBUG TRAIN Batch 51/8100 loss 7.087315 loss_att 9.946856 loss_ctc 12.870909 loss_rnnt 5.678579 hw_loss 0.123153 lr 0.00029055 rank 7
2023-03-01 08:00:25,073 DEBUG TRAIN Batch 51/8100 loss 5.904141 loss_att 7.327648 loss_ctc 13.484316 loss_rnnt 4.559894 hw_loss 0.091604 lr 0.00029056 rank 0
2023-03-01 08:00:25,075 DEBUG TRAIN Batch 51/8100 loss 5.692624 loss_att 7.174873 loss_ctc 6.940411 loss_rnnt 5.087384 hw_loss 0.267035 lr 0.00029056 rank 1
2023-03-01 08:00:25,076 DEBUG TRAIN Batch 51/8100 loss 7.216398 loss_att 9.316534 loss_ctc 10.595613 loss_rnnt 6.259087 hw_loss 0.162603 lr 0.00029057 rank 2
2023-03-01 08:00:25,077 DEBUG TRAIN Batch 51/8100 loss 4.765147 loss_att 6.880630 loss_ctc 10.670734 loss_rnnt 3.523020 hw_loss 0.059286 lr 0.00029056 rank 4
2023-03-01 08:00:25,082 DEBUG TRAIN Batch 51/8100 loss 5.749966 loss_att 7.949717 loss_ctc 10.463454 loss_rnnt 4.550792 hw_loss 0.245173 lr 0.00029056 rank 6
2023-03-01 08:00:25,108 DEBUG TRAIN Batch 51/8100 loss 10.034424 loss_att 12.298580 loss_ctc 15.324443 loss_rnnt 8.678160 hw_loss 0.371433 lr 0.00029055 rank 3
2023-03-01 08:00:25,108 DEBUG TRAIN Batch 51/8100 loss 4.295598 loss_att 6.680842 loss_ctc 7.312818 loss_rnnt 3.270918 hw_loss 0.272502 lr 0.00029056 rank 5
2023-03-01 08:01:05,141 DEBUG TRAIN Batch 51/8200 loss 2.169692 loss_att 5.702658 loss_ctc 7.091640 loss_rnnt 0.702337 hw_loss 0.195941 lr 0.00029055 rank 0
2023-03-01 08:01:05,153 DEBUG TRAIN Batch 51/8200 loss 7.732029 loss_att 10.230221 loss_ctc 13.185302 loss_rnnt 6.361012 hw_loss 0.270517 lr 0.00029055 rank 1
2023-03-01 08:01:05,156 DEBUG TRAIN Batch 51/8200 loss 5.646578 loss_att 8.045346 loss_ctc 10.074212 loss_rnnt 4.467763 hw_loss 0.203830 lr 0.00029054 rank 7
2023-03-01 08:01:05,159 DEBUG TRAIN Batch 51/8200 loss 2.748729 loss_att 6.434659 loss_ctc 5.168937 loss_rnnt 1.589717 hw_loss 0.185871 lr 0.00029055 rank 4
2023-03-01 08:01:05,161 DEBUG TRAIN Batch 51/8200 loss 6.610467 loss_att 7.965581 loss_ctc 8.360607 loss_rnnt 5.853579 hw_loss 0.473464 lr 0.00029054 rank 3
2023-03-01 08:01:05,162 DEBUG TRAIN Batch 51/8200 loss 9.848152 loss_att 12.007032 loss_ctc 16.662857 loss_rnnt 8.226346 hw_loss 0.527630 lr 0.00029055 rank 2
2023-03-01 08:01:05,164 DEBUG TRAIN Batch 51/8200 loss 7.415818 loss_att 8.411946 loss_ctc 9.823370 loss_rnnt 6.724121 hw_loss 0.321494 lr 0.00029055 rank 6
2023-03-01 08:01:05,178 DEBUG TRAIN Batch 51/8200 loss 4.336362 loss_att 6.357436 loss_ctc 4.730892 loss_rnnt 3.774632 hw_loss 0.196709 lr 0.00029055 rank 5
2023-03-01 08:01:43,482 DEBUG TRAIN Batch 51/8300 loss 9.301291 loss_att 9.958171 loss_ctc 10.416952 loss_rnnt 8.910432 hw_loss 0.207618 lr 0.00029054 rank 6
2023-03-01 08:01:43,483 DEBUG TRAIN Batch 51/8300 loss 3.369005 loss_att 6.417381 loss_ctc 6.826062 loss_rnnt 2.261079 hw_loss 0.069956 lr 0.00029054 rank 4
2023-03-01 08:01:43,487 DEBUG TRAIN Batch 51/8300 loss 3.093364 loss_att 7.384260 loss_ctc 6.941717 loss_rnnt 1.535189 hw_loss 0.350403 lr 0.00029054 rank 1
2023-03-01 08:01:43,487 DEBUG TRAIN Batch 51/8300 loss 3.917037 loss_att 7.667854 loss_ctc 6.150469 loss_rnnt 2.708224 hw_loss 0.301611 lr 0.00029054 rank 2
2023-03-01 08:01:43,490 DEBUG TRAIN Batch 51/8300 loss 4.024957 loss_att 6.838316 loss_ctc 5.976956 loss_rnnt 3.084611 hw_loss 0.220139 lr 0.00029053 rank 3
2023-03-01 08:01:43,501 DEBUG TRAIN Batch 51/8300 loss 5.781943 loss_att 9.187526 loss_ctc 12.544352 loss_rnnt 4.143498 hw_loss 0.104388 lr 0.00029052 rank 7
2023-03-01 08:01:43,503 DEBUG TRAIN Batch 51/8300 loss 5.285932 loss_att 8.035717 loss_ctc 9.157539 loss_rnnt 4.089938 hw_loss 0.243415 lr 0.00029054 rank 0
2023-03-01 08:01:43,508 DEBUG TRAIN Batch 51/8300 loss 8.723158 loss_att 11.970425 loss_ctc 13.266653 loss_rnnt 7.294210 hw_loss 0.325678 lr 0.00029053 rank 5
2023-03-01 08:02:11,100 DEBUG CV Batch 51/0 loss 0.962035 loss_att 0.895855 loss_ctc 1.686422 loss_rnnt 0.682037 hw_loss 0.368717 history loss 0.926404 rank 3
2023-03-01 08:02:11,210 DEBUG CV Batch 51/0 loss 0.962035 loss_att 0.895855 loss_ctc 1.686422 loss_rnnt 0.682037 hw_loss 0.368717 history loss 0.926404 rank 1
2023-03-01 08:02:11,264 DEBUG CV Batch 51/0 loss 0.962035 loss_att 0.895855 loss_ctc 1.686422 loss_rnnt 0.682037 hw_loss 0.368717 history loss 0.926404 rank 7
2023-03-01 08:02:11,545 DEBUG CV Batch 51/0 loss 0.962035 loss_att 0.895855 loss_ctc 1.686422 loss_rnnt 0.682037 hw_loss 0.368717 history loss 0.926404 rank 4
2023-03-01 08:02:11,699 DEBUG CV Batch 51/0 loss 0.962035 loss_att 0.895855 loss_ctc 1.686422 loss_rnnt 0.682037 hw_loss 0.368717 history loss 0.926404 rank 5
2023-03-01 08:02:11,725 DEBUG CV Batch 51/0 loss 0.962035 loss_att 0.895855 loss_ctc 1.686422 loss_rnnt 0.682037 hw_loss 0.368717 history loss 0.926404 rank 6
2023-03-01 08:02:11,881 DEBUG CV Batch 51/0 loss 0.962035 loss_att 0.895855 loss_ctc 1.686422 loss_rnnt 0.682037 hw_loss 0.368717 history loss 0.926404 rank 0
2023-03-01 08:02:12,021 DEBUG CV Batch 51/0 loss 0.962035 loss_att 0.895855 loss_ctc 1.686422 loss_rnnt 0.682037 hw_loss 0.368717 history loss 0.926404 rank 2
2023-03-01 08:02:22,684 DEBUG CV Batch 51/100 loss 3.807839 loss_att 4.298841 loss_ctc 7.512225 loss_rnnt 3.057148 hw_loss 0.297322 history loss 3.017364 rank 7
2023-03-01 08:02:22,870 DEBUG CV Batch 51/100 loss 3.807839 loss_att 4.298841 loss_ctc 7.512225 loss_rnnt 3.057148 hw_loss 0.297322 history loss 3.017364 rank 1
2023-03-01 08:02:22,923 DEBUG CV Batch 51/100 loss 3.807839 loss_att 4.298841 loss_ctc 7.512225 loss_rnnt 3.057148 hw_loss 0.297322 history loss 3.017364 rank 3
2023-03-01 08:02:23,082 DEBUG CV Batch 51/100 loss 3.807839 loss_att 4.298841 loss_ctc 7.512225 loss_rnnt 3.057148 hw_loss 0.297322 history loss 3.017364 rank 4
2023-03-01 08:02:23,496 DEBUG CV Batch 51/100 loss 3.807839 loss_att 4.298841 loss_ctc 7.512225 loss_rnnt 3.057148 hw_loss 0.297322 history loss 3.017364 rank 5
2023-03-01 08:02:23,548 DEBUG CV Batch 51/100 loss 3.807839 loss_att 4.298841 loss_ctc 7.512225 loss_rnnt 3.057148 hw_loss 0.297322 history loss 3.017364 rank 6
2023-03-01 08:02:23,663 DEBUG CV Batch 51/100 loss 3.807839 loss_att 4.298841 loss_ctc 7.512225 loss_rnnt 3.057148 hw_loss 0.297322 history loss 3.017364 rank 0
2023-03-01 08:02:23,717 DEBUG CV Batch 51/100 loss 3.807839 loss_att 4.298841 loss_ctc 7.512225 loss_rnnt 3.057148 hw_loss 0.297322 history loss 3.017364 rank 2
2023-03-01 08:02:36,284 DEBUG CV Batch 51/200 loss 5.132855 loss_att 8.484774 loss_ctc 7.701488 loss_rnnt 4.040297 hw_loss 0.149421 history loss 3.582964 rank 7
2023-03-01 08:02:36,559 DEBUG CV Batch 51/200 loss 5.132855 loss_att 8.484774 loss_ctc 7.701488 loss_rnnt 4.040297 hw_loss 0.149421 history loss 3.582964 rank 1
2023-03-01 08:02:36,675 DEBUG CV Batch 51/200 loss 5.132855 loss_att 8.484774 loss_ctc 7.701488 loss_rnnt 4.040297 hw_loss 0.149421 history loss 3.582964 rank 4
2023-03-01 08:02:36,843 DEBUG CV Batch 51/200 loss 5.132855 loss_att 8.484774 loss_ctc 7.701488 loss_rnnt 4.040297 hw_loss 0.149421 history loss 3.582964 rank 3
2023-03-01 08:02:37,389 DEBUG CV Batch 51/200 loss 5.132855 loss_att 8.484774 loss_ctc 7.701488 loss_rnnt 4.040297 hw_loss 0.149421 history loss 3.582964 rank 5
2023-03-01 08:02:37,415 DEBUG CV Batch 51/200 loss 5.132855 loss_att 8.484774 loss_ctc 7.701488 loss_rnnt 4.040297 hw_loss 0.149421 history loss 3.582964 rank 6
2023-03-01 08:02:37,541 DEBUG CV Batch 51/200 loss 5.132855 loss_att 8.484774 loss_ctc 7.701488 loss_rnnt 4.040297 hw_loss 0.149421 history loss 3.582964 rank 0
2023-03-01 08:02:37,656 DEBUG CV Batch 51/200 loss 5.132855 loss_att 8.484774 loss_ctc 7.701488 loss_rnnt 4.040297 hw_loss 0.149421 history loss 3.582964 rank 2
2023-03-01 08:02:48,487 DEBUG CV Batch 51/300 loss 2.980730 loss_att 3.674265 loss_ctc 5.835296 loss_rnnt 2.351264 hw_loss 0.206533 history loss 3.731893 rank 7
2023-03-01 08:02:48,940 DEBUG CV Batch 51/300 loss 2.980730 loss_att 3.674265 loss_ctc 5.835296 loss_rnnt 2.351264 hw_loss 0.206533 history loss 3.731893 rank 1
2023-03-01 08:02:49,440 DEBUG CV Batch 51/300 loss 2.980730 loss_att 3.674265 loss_ctc 5.835296 loss_rnnt 2.351264 hw_loss 0.206533 history loss 3.731893 rank 4
2023-03-01 08:02:49,564 DEBUG CV Batch 51/300 loss 2.980730 loss_att 3.674265 loss_ctc 5.835296 loss_rnnt 2.351264 hw_loss 0.206533 history loss 3.731893 rank 3
2023-03-01 08:02:49,738 DEBUG CV Batch 51/300 loss 2.980730 loss_att 3.674265 loss_ctc 5.835296 loss_rnnt 2.351264 hw_loss 0.206533 history loss 3.731893 rank 6
2023-03-01 08:02:49,887 DEBUG CV Batch 51/300 loss 2.980730 loss_att 3.674265 loss_ctc 5.835296 loss_rnnt 2.351264 hw_loss 0.206533 history loss 3.731893 rank 0
2023-03-01 08:02:49,929 DEBUG CV Batch 51/300 loss 2.980730 loss_att 3.674265 loss_ctc 5.835296 loss_rnnt 2.351264 hw_loss 0.206533 history loss 3.731893 rank 5
2023-03-01 08:02:50,059 DEBUG CV Batch 51/300 loss 2.980730 loss_att 3.674265 loss_ctc 5.835296 loss_rnnt 2.351264 hw_loss 0.206533 history loss 3.731893 rank 2
2023-03-01 08:03:00,770 DEBUG CV Batch 51/400 loss 13.902102 loss_att 68.132935 loss_ctc 5.039372 loss_rnnt 4.113036 hw_loss 0.233618 history loss 4.563468 rank 7
2023-03-01 08:03:01,343 DEBUG CV Batch 51/400 loss 13.902102 loss_att 68.132935 loss_ctc 5.039372 loss_rnnt 4.113036 hw_loss 0.233618 history loss 4.563468 rank 1
2023-03-01 08:03:01,710 DEBUG CV Batch 51/400 loss 13.902102 loss_att 68.132935 loss_ctc 5.039372 loss_rnnt 4.113036 hw_loss 0.233618 history loss 4.563468 rank 4
2023-03-01 08:03:02,193 DEBUG CV Batch 51/400 loss 13.902102 loss_att 68.132935 loss_ctc 5.039372 loss_rnnt 4.113036 hw_loss 0.233618 history loss 4.563468 rank 3
2023-03-01 08:03:02,258 DEBUG CV Batch 51/400 loss 13.902102 loss_att 68.132935 loss_ctc 5.039372 loss_rnnt 4.113036 hw_loss 0.233618 history loss 4.563468 rank 6
2023-03-01 08:03:02,397 DEBUG CV Batch 51/400 loss 13.902102 loss_att 68.132935 loss_ctc 5.039372 loss_rnnt 4.113036 hw_loss 0.233618 history loss 4.563468 rank 5
2023-03-01 08:03:02,431 DEBUG CV Batch 51/400 loss 13.902102 loss_att 68.132935 loss_ctc 5.039372 loss_rnnt 4.113036 hw_loss 0.233618 history loss 4.563468 rank 0
2023-03-01 08:03:02,722 DEBUG CV Batch 51/400 loss 13.902102 loss_att 68.132935 loss_ctc 5.039372 loss_rnnt 4.113036 hw_loss 0.233618 history loss 4.563468 rank 2
2023-03-01 08:03:11,653 DEBUG CV Batch 51/500 loss 4.674479 loss_att 4.479712 loss_ctc 6.691003 loss_rnnt 4.291964 hw_loss 0.286122 history loss 5.187158 rank 7
2023-03-01 08:03:12,753 DEBUG CV Batch 51/500 loss 4.674479 loss_att 4.479712 loss_ctc 6.691003 loss_rnnt 4.291964 hw_loss 0.286122 history loss 5.187158 rank 1
2023-03-01 08:03:12,975 DEBUG CV Batch 51/500 loss 4.674479 loss_att 4.479712 loss_ctc 6.691003 loss_rnnt 4.291964 hw_loss 0.286122 history loss 5.187158 rank 5
2023-03-01 08:03:13,004 DEBUG CV Batch 51/500 loss 4.674479 loss_att 4.479712 loss_ctc 6.691003 loss_rnnt 4.291964 hw_loss 0.286122 history loss 5.187158 rank 6
2023-03-01 08:03:13,131 DEBUG CV Batch 51/500 loss 4.674479 loss_att 4.479712 loss_ctc 6.691003 loss_rnnt 4.291964 hw_loss 0.286122 history loss 5.187158 rank 0
2023-03-01 08:03:13,329 DEBUG CV Batch 51/500 loss 4.674479 loss_att 4.479712 loss_ctc 6.691003 loss_rnnt 4.291964 hw_loss 0.286122 history loss 5.187158 rank 4
2023-03-01 08:03:13,615 DEBUG CV Batch 51/500 loss 4.674479 loss_att 4.479712 loss_ctc 6.691003 loss_rnnt 4.291964 hw_loss 0.286122 history loss 5.187158 rank 2
2023-03-01 08:03:13,695 DEBUG CV Batch 51/500 loss 4.674479 loss_att 4.479712 loss_ctc 6.691003 loss_rnnt 4.291964 hw_loss 0.286122 history loss 5.187158 rank 3
2023-03-01 08:03:24,077 DEBUG CV Batch 51/600 loss 7.313755 loss_att 6.474039 loss_ctc 10.341355 loss_rnnt 6.877363 hw_loss 0.376229 history loss 6.033313 rank 7
2023-03-01 08:03:25,182 DEBUG CV Batch 51/600 loss 7.313755 loss_att 6.474039 loss_ctc 10.341355 loss_rnnt 6.877363 hw_loss 0.376229 history loss 6.033313 rank 5
2023-03-01 08:03:25,241 DEBUG CV Batch 51/600 loss 7.313755 loss_att 6.474039 loss_ctc 10.341355 loss_rnnt 6.877363 hw_loss 0.376229 history loss 6.033313 rank 1
2023-03-01 08:03:25,473 DEBUG CV Batch 51/600 loss 7.313755 loss_att 6.474039 loss_ctc 10.341355 loss_rnnt 6.877363 hw_loss 0.376229 history loss 6.033313 rank 6
2023-03-01 08:03:25,710 DEBUG CV Batch 51/600 loss 7.313755 loss_att 6.474039 loss_ctc 10.341355 loss_rnnt 6.877363 hw_loss 0.376229 history loss 6.033313 rank 0
2023-03-01 08:03:25,840 DEBUG CV Batch 51/600 loss 7.313755 loss_att 6.474039 loss_ctc 10.341355 loss_rnnt 6.877363 hw_loss 0.376229 history loss 6.033313 rank 4
2023-03-01 08:03:26,102 DEBUG CV Batch 51/600 loss 7.313755 loss_att 6.474039 loss_ctc 10.341355 loss_rnnt 6.877363 hw_loss 0.376229 history loss 6.033313 rank 2
2023-03-01 08:03:26,469 DEBUG CV Batch 51/600 loss 7.313755 loss_att 6.474039 loss_ctc 10.341355 loss_rnnt 6.877363 hw_loss 0.376229 history loss 6.033313 rank 3
2023-03-01 08:03:35,605 DEBUG CV Batch 51/700 loss 8.860002 loss_att 13.861282 loss_ctc 13.022110 loss_rnnt 7.234889 hw_loss 0.131081 history loss 6.562292 rank 7
2023-03-01 08:03:36,859 DEBUG CV Batch 51/700 loss 8.860002 loss_att 13.861282 loss_ctc 13.022110 loss_rnnt 7.234889 hw_loss 0.131081 history loss 6.562292 rank 5
2023-03-01 08:03:37,018 DEBUG CV Batch 51/700 loss 8.860002 loss_att 13.861282 loss_ctc 13.022110 loss_rnnt 7.234889 hw_loss 0.131081 history loss 6.562292 rank 1
2023-03-01 08:03:37,404 DEBUG CV Batch 51/700 loss 8.860002 loss_att 13.861282 loss_ctc 13.022110 loss_rnnt 7.234889 hw_loss 0.131081 history loss 6.562292 rank 6
2023-03-01 08:03:37,540 DEBUG CV Batch 51/700 loss 8.860002 loss_att 13.861282 loss_ctc 13.022110 loss_rnnt 7.234889 hw_loss 0.131081 history loss 6.562292 rank 0
2023-03-01 08:03:37,805 DEBUG CV Batch 51/700 loss 8.860002 loss_att 13.861282 loss_ctc 13.022110 loss_rnnt 7.234889 hw_loss 0.131081 history loss 6.562292 rank 2
2023-03-01 08:03:37,809 DEBUG CV Batch 51/700 loss 8.860002 loss_att 13.861282 loss_ctc 13.022110 loss_rnnt 7.234889 hw_loss 0.131081 history loss 6.562292 rank 4
2023-03-01 08:03:38,560 DEBUG CV Batch 51/700 loss 8.860002 loss_att 13.861282 loss_ctc 13.022110 loss_rnnt 7.234889 hw_loss 0.131081 history loss 6.562292 rank 3
2023-03-01 08:03:47,244 DEBUG CV Batch 51/800 loss 7.599500 loss_att 7.268100 loss_ctc 14.553596 loss_rnnt 6.621131 hw_loss 0.220193 history loss 6.086515 rank 7
2023-03-01 08:03:48,195 DEBUG CV Batch 51/800 loss 7.599500 loss_att 7.268100 loss_ctc 14.553596 loss_rnnt 6.621131 hw_loss 0.220193 history loss 6.086515 rank 5
2023-03-01 08:03:48,747 DEBUG CV Batch 51/800 loss 7.599500 loss_att 7.268100 loss_ctc 14.553596 loss_rnnt 6.621131 hw_loss 0.220193 history loss 6.086515 rank 1
2023-03-01 08:03:48,847 DEBUG CV Batch 51/800 loss 7.599500 loss_att 7.268100 loss_ctc 14.553596 loss_rnnt 6.621131 hw_loss 0.220193 history loss 6.086515 rank 0
2023-03-01 08:03:48,935 DEBUG CV Batch 51/800 loss 7.599500 loss_att 7.268100 loss_ctc 14.553596 loss_rnnt 6.621131 hw_loss 0.220193 history loss 6.086515 rank 6
2023-03-01 08:03:49,771 DEBUG CV Batch 51/800 loss 7.599500 loss_att 7.268100 loss_ctc 14.553596 loss_rnnt 6.621131 hw_loss 0.220193 history loss 6.086515 rank 4
2023-03-01 08:03:49,814 DEBUG CV Batch 51/800 loss 7.599500 loss_att 7.268100 loss_ctc 14.553596 loss_rnnt 6.621131 hw_loss 0.220193 history loss 6.086515 rank 2
2023-03-01 08:03:50,682 DEBUG CV Batch 51/800 loss 7.599500 loss_att 7.268100 loss_ctc 14.553596 loss_rnnt 6.621131 hw_loss 0.220193 history loss 6.086515 rank 3
2023-03-01 08:04:00,863 DEBUG CV Batch 51/900 loss 9.845428 loss_att 11.464052 loss_ctc 19.063589 loss_rnnt 8.174975 hw_loss 0.220575 history loss 5.922970 rank 7
2023-03-01 08:04:01,791 DEBUG CV Batch 51/900 loss 9.845428 loss_att 11.464052 loss_ctc 19.063589 loss_rnnt 8.174975 hw_loss 0.220575 history loss 5.922970 rank 5
2023-03-01 08:04:02,341 DEBUG CV Batch 51/900 loss 9.845428 loss_att 11.464052 loss_ctc 19.063589 loss_rnnt 8.174975 hw_loss 0.220575 history loss 5.922970 rank 1
2023-03-01 08:04:02,533 DEBUG CV Batch 51/900 loss 9.845428 loss_att 11.464052 loss_ctc 19.063589 loss_rnnt 8.174975 hw_loss 0.220575 history loss 5.922970 rank 0
2023-03-01 08:04:02,557 DEBUG CV Batch 51/900 loss 9.845428 loss_att 11.464052 loss_ctc 19.063589 loss_rnnt 8.174975 hw_loss 0.220575 history loss 5.922970 rank 6
2023-03-01 08:04:03,355 DEBUG CV Batch 51/900 loss 9.845428 loss_att 11.464052 loss_ctc 19.063589 loss_rnnt 8.174975 hw_loss 0.220575 history loss 5.922970 rank 4
2023-03-01 08:04:03,636 DEBUG CV Batch 51/900 loss 9.845428 loss_att 11.464052 loss_ctc 19.063589 loss_rnnt 8.174975 hw_loss 0.220575 history loss 5.922970 rank 2
2023-03-01 08:04:04,812 DEBUG CV Batch 51/900 loss 9.845428 loss_att 11.464052 loss_ctc 19.063589 loss_rnnt 8.174975 hw_loss 0.220575 history loss 5.922970 rank 3
2023-03-01 08:04:13,419 DEBUG CV Batch 51/1000 loss 4.518277 loss_att 4.439346 loss_ctc 5.305748 loss_rnnt 4.275552 hw_loss 0.287841 history loss 5.734060 rank 7
2023-03-01 08:04:14,494 DEBUG CV Batch 51/1000 loss 4.518277 loss_att 4.439346 loss_ctc 5.305748 loss_rnnt 4.275552 hw_loss 0.287841 history loss 5.734060 rank 5
2023-03-01 08:04:14,939 DEBUG CV Batch 51/1000 loss 4.518277 loss_att 4.439346 loss_ctc 5.305748 loss_rnnt 4.275552 hw_loss 0.287841 history loss 5.734060 rank 1
2023-03-01 08:04:15,239 DEBUG CV Batch 51/1000 loss 4.518277 loss_att 4.439346 loss_ctc 5.305748 loss_rnnt 4.275552 hw_loss 0.287841 history loss 5.734060 rank 0
2023-03-01 08:04:15,270 DEBUG CV Batch 51/1000 loss 4.518277 loss_att 4.439346 loss_ctc 5.305748 loss_rnnt 4.275552 hw_loss 0.287841 history loss 5.734060 rank 6
2023-03-01 08:04:16,219 DEBUG CV Batch 51/1000 loss 4.518277 loss_att 4.439346 loss_ctc 5.305748 loss_rnnt 4.275552 hw_loss 0.287841 history loss 5.734060 rank 4
2023-03-01 08:04:16,531 DEBUG CV Batch 51/1000 loss 4.518277 loss_att 4.439346 loss_ctc 5.305748 loss_rnnt 4.275552 hw_loss 0.287841 history loss 5.734060 rank 2
2023-03-01 08:04:18,083 DEBUG CV Batch 51/1000 loss 4.518277 loss_att 4.439346 loss_ctc 5.305748 loss_rnnt 4.275552 hw_loss 0.287841 history loss 5.734060 rank 3
2023-03-01 08:04:25,576 DEBUG CV Batch 51/1100 loss 4.386355 loss_att 4.529473 loss_ctc 8.116961 loss_rnnt 3.643967 hw_loss 0.405658 history loss 5.690971 rank 7
2023-03-01 08:04:26,852 DEBUG CV Batch 51/1100 loss 4.386355 loss_att 4.529473 loss_ctc 8.116961 loss_rnnt 3.643967 hw_loss 0.405658 history loss 5.690971 rank 5
2023-03-01 08:04:26,993 DEBUG CV Batch 51/1100 loss 4.386355 loss_att 4.529473 loss_ctc 8.116961 loss_rnnt 3.643967 hw_loss 0.405658 history loss 5.690971 rank 1
2023-03-01 08:04:27,504 DEBUG CV Batch 51/1100 loss 4.386355 loss_att 4.529473 loss_ctc 8.116961 loss_rnnt 3.643967 hw_loss 0.405658 history loss 5.690971 rank 0
2023-03-01 08:04:27,742 DEBUG CV Batch 51/1100 loss 4.386355 loss_att 4.529473 loss_ctc 8.116961 loss_rnnt 3.643967 hw_loss 0.405658 history loss 5.690971 rank 6
2023-03-01 08:04:28,497 DEBUG CV Batch 51/1100 loss 4.386355 loss_att 4.529473 loss_ctc 8.116961 loss_rnnt 3.643967 hw_loss 0.405658 history loss 5.690971 rank 4
2023-03-01 08:04:28,975 DEBUG CV Batch 51/1100 loss 4.386355 loss_att 4.529473 loss_ctc 8.116961 loss_rnnt 3.643967 hw_loss 0.405658 history loss 5.690971 rank 2
2023-03-01 08:04:30,921 DEBUG CV Batch 51/1100 loss 4.386355 loss_att 4.529473 loss_ctc 8.116961 loss_rnnt 3.643967 hw_loss 0.405658 history loss 5.690971 rank 3
2023-03-01 08:04:36,531 DEBUG CV Batch 51/1200 loss 6.032345 loss_att 6.486171 loss_ctc 7.403285 loss_rnnt 5.624143 hw_loss 0.252461 history loss 5.979341 rank 7
2023-03-01 08:04:37,993 DEBUG CV Batch 51/1200 loss 6.032345 loss_att 6.486171 loss_ctc 7.403285 loss_rnnt 5.624143 hw_loss 0.252461 history loss 5.979341 rank 5
2023-03-01 08:04:38,118 DEBUG CV Batch 51/1200 loss 6.032345 loss_att 6.486171 loss_ctc 7.403285 loss_rnnt 5.624143 hw_loss 0.252461 history loss 5.979341 rank 1
2023-03-01 08:04:38,570 DEBUG CV Batch 51/1200 loss 6.032345 loss_att 6.486171 loss_ctc 7.403285 loss_rnnt 5.624143 hw_loss 0.252461 history loss 5.979341 rank 0
2023-03-01 08:04:38,772 DEBUG CV Batch 51/1200 loss 6.032345 loss_att 6.486171 loss_ctc 7.403285 loss_rnnt 5.624143 hw_loss 0.252461 history loss 5.979341 rank 6
2023-03-01 08:04:39,564 DEBUG CV Batch 51/1200 loss 6.032345 loss_att 6.486171 loss_ctc 7.403285 loss_rnnt 5.624143 hw_loss 0.252461 history loss 5.979341 rank 4
2023-03-01 08:04:40,134 DEBUG CV Batch 51/1200 loss 6.032345 loss_att 6.486171 loss_ctc 7.403285 loss_rnnt 5.624143 hw_loss 0.252461 history loss 5.979341 rank 2
2023-03-01 08:04:42,535 DEBUG CV Batch 51/1200 loss 6.032345 loss_att 6.486171 loss_ctc 7.403285 loss_rnnt 5.624143 hw_loss 0.252461 history loss 5.979341 rank 3
2023-03-01 08:04:48,843 DEBUG CV Batch 51/1300 loss 4.861594 loss_att 4.500222 loss_ctc 7.324507 loss_rnnt 4.423311 hw_loss 0.341566 history loss 6.267599 rank 7
2023-03-01 08:04:50,151 DEBUG CV Batch 51/1300 loss 4.861594 loss_att 4.500222 loss_ctc 7.324507 loss_rnnt 4.423311 hw_loss 0.341566 history loss 6.267599 rank 5
2023-03-01 08:04:50,543 DEBUG CV Batch 51/1300 loss 4.861594 loss_att 4.500222 loss_ctc 7.324507 loss_rnnt 4.423311 hw_loss 0.341566 history loss 6.267599 rank 1
2023-03-01 08:04:50,934 DEBUG CV Batch 51/1300 loss 4.861594 loss_att 4.500222 loss_ctc 7.324507 loss_rnnt 4.423311 hw_loss 0.341566 history loss 6.267599 rank 0
2023-03-01 08:04:51,047 DEBUG CV Batch 51/1300 loss 4.861594 loss_att 4.500222 loss_ctc 7.324507 loss_rnnt 4.423311 hw_loss 0.341566 history loss 6.267599 rank 6
2023-03-01 08:04:51,956 DEBUG CV Batch 51/1300 loss 4.861594 loss_att 4.500222 loss_ctc 7.324507 loss_rnnt 4.423311 hw_loss 0.341566 history loss 6.267599 rank 4
2023-03-01 08:04:52,562 DEBUG CV Batch 51/1300 loss 4.861594 loss_att 4.500222 loss_ctc 7.324507 loss_rnnt 4.423311 hw_loss 0.341566 history loss 6.267599 rank 2
2023-03-01 08:04:55,188 DEBUG CV Batch 51/1300 loss 4.861594 loss_att 4.500222 loss_ctc 7.324507 loss_rnnt 4.423311 hw_loss 0.341566 history loss 6.267599 rank 3
2023-03-01 08:05:00,298 DEBUG CV Batch 51/1400 loss 4.459291 loss_att 13.992502 loss_ctc 6.493521 loss_rnnt 2.263302 hw_loss 0.033967 history loss 6.540467 rank 7
2023-03-01 08:05:02,200 DEBUG CV Batch 51/1400 loss 4.459291 loss_att 13.992502 loss_ctc 6.493521 loss_rnnt 2.263302 hw_loss 0.033967 history loss 6.540467 rank 5
2023-03-01 08:05:02,353 DEBUG CV Batch 51/1400 loss 4.459291 loss_att 13.992502 loss_ctc 6.493521 loss_rnnt 2.263302 hw_loss 0.033967 history loss 6.540467 rank 1
2023-03-01 08:05:02,649 DEBUG CV Batch 51/1400 loss 4.459291 loss_att 13.992502 loss_ctc 6.493521 loss_rnnt 2.263302 hw_loss 0.033967 history loss 6.540467 rank 0
2023-03-01 08:05:02,814 DEBUG CV Batch 51/1400 loss 4.459291 loss_att 13.992502 loss_ctc 6.493521 loss_rnnt 2.263302 hw_loss 0.033967 history loss 6.540467 rank 6
2023-03-01 08:05:03,548 DEBUG CV Batch 51/1400 loss 4.459291 loss_att 13.992502 loss_ctc 6.493521 loss_rnnt 2.263302 hw_loss 0.033967 history loss 6.540467 rank 4
2023-03-01 08:05:04,268 DEBUG CV Batch 51/1400 loss 4.459291 loss_att 13.992502 loss_ctc 6.493521 loss_rnnt 2.263302 hw_loss 0.033967 history loss 6.540467 rank 2
2023-03-01 08:05:07,180 DEBUG CV Batch 51/1400 loss 4.459291 loss_att 13.992502 loss_ctc 6.493521 loss_rnnt 2.263302 hw_loss 0.033967 history loss 6.540467 rank 3
2023-03-01 08:05:12,164 DEBUG CV Batch 51/1500 loss 7.032448 loss_att 6.839238 loss_ctc 7.433722 loss_rnnt 6.854743 hw_loss 0.305334 history loss 6.400228 rank 7
2023-03-01 08:05:13,936 DEBUG CV Batch 51/1500 loss 7.032448 loss_att 6.839238 loss_ctc 7.433722 loss_rnnt 6.854743 hw_loss 0.305334 history loss 6.400228 rank 5
2023-03-01 08:05:14,370 DEBUG CV Batch 51/1500 loss 7.032448 loss_att 6.839238 loss_ctc 7.433722 loss_rnnt 6.854743 hw_loss 0.305334 history loss 6.400228 rank 1
2023-03-01 08:05:14,520 DEBUG CV Batch 51/1500 loss 7.032448 loss_att 6.839238 loss_ctc 7.433722 loss_rnnt 6.854743 hw_loss 0.305334 history loss 6.400228 rank 0
2023-03-01 08:05:14,726 DEBUG CV Batch 51/1500 loss 7.032448 loss_att 6.839238 loss_ctc 7.433722 loss_rnnt 6.854743 hw_loss 0.305334 history loss 6.400228 rank 6
2023-03-01 08:05:15,593 DEBUG CV Batch 51/1500 loss 7.032448 loss_att 6.839238 loss_ctc 7.433722 loss_rnnt 6.854743 hw_loss 0.305334 history loss 6.400228 rank 4
2023-03-01 08:05:15,949 DEBUG CV Batch 51/1500 loss 7.032448 loss_att 6.839238 loss_ctc 7.433722 loss_rnnt 6.854743 hw_loss 0.305334 history loss 6.400228 rank 2
2023-03-01 08:05:19,697 DEBUG CV Batch 51/1500 loss 7.032448 loss_att 6.839238 loss_ctc 7.433722 loss_rnnt 6.854743 hw_loss 0.305334 history loss 6.400228 rank 3
2023-03-01 08:05:25,536 DEBUG CV Batch 51/1600 loss 9.295997 loss_att 11.211425 loss_ctc 10.857712 loss_rnnt 8.568197 hw_loss 0.255909 history loss 6.360961 rank 7
2023-03-01 08:05:27,313 DEBUG CV Batch 51/1600 loss 9.295997 loss_att 11.211425 loss_ctc 10.857712 loss_rnnt 8.568197 hw_loss 0.255909 history loss 6.360961 rank 5
2023-03-01 08:05:27,693 DEBUG CV Batch 51/1600 loss 9.295997 loss_att 11.211425 loss_ctc 10.857712 loss_rnnt 8.568197 hw_loss 0.255909 history loss 6.360961 rank 1
2023-03-01 08:05:27,934 DEBUG CV Batch 51/1600 loss 9.295997 loss_att 11.211425 loss_ctc 10.857712 loss_rnnt 8.568197 hw_loss 0.255909 history loss 6.360961 rank 0
2023-03-01 08:05:28,164 DEBUG CV Batch 51/1600 loss 9.295997 loss_att 11.211425 loss_ctc 10.857712 loss_rnnt 8.568197 hw_loss 0.255909 history loss 6.360961 rank 6
2023-03-01 08:05:29,103 DEBUG CV Batch 51/1600 loss 9.295997 loss_att 11.211425 loss_ctc 10.857712 loss_rnnt 8.568197 hw_loss 0.255909 history loss 6.360961 rank 4
2023-03-01 08:05:29,483 DEBUG CV Batch 51/1600 loss 9.295997 loss_att 11.211425 loss_ctc 10.857712 loss_rnnt 8.568197 hw_loss 0.255909 history loss 6.360961 rank 2
2023-03-01 08:05:33,623 DEBUG CV Batch 51/1600 loss 9.295997 loss_att 11.211425 loss_ctc 10.857712 loss_rnnt 8.568197 hw_loss 0.255909 history loss 6.360961 rank 3
2023-03-01 08:05:38,103 DEBUG CV Batch 51/1700 loss 7.542244 loss_att 5.461208 loss_ctc 12.671432 loss_rnnt 7.058042 hw_loss 0.405969 history loss 6.293259 rank 7
2023-03-01 08:05:40,056 DEBUG CV Batch 51/1700 loss 7.542244 loss_att 5.461208 loss_ctc 12.671432 loss_rnnt 7.058042 hw_loss 0.405969 history loss 6.293259 rank 5
2023-03-01 08:05:40,273 DEBUG CV Batch 51/1700 loss 7.542244 loss_att 5.461208 loss_ctc 12.671432 loss_rnnt 7.058042 hw_loss 0.405969 history loss 6.293259 rank 1
2023-03-01 08:05:40,728 DEBUG CV Batch 51/1700 loss 7.542244 loss_att 5.461208 loss_ctc 12.671432 loss_rnnt 7.058042 hw_loss 0.405969 history loss 6.293259 rank 0
2023-03-01 08:05:40,928 DEBUG CV Batch 51/1700 loss 7.542244 loss_att 5.461208 loss_ctc 12.671432 loss_rnnt 7.058042 hw_loss 0.405969 history loss 6.293259 rank 6
2023-03-01 08:05:41,900 DEBUG CV Batch 51/1700 loss 7.542244 loss_att 5.461208 loss_ctc 12.671432 loss_rnnt 7.058042 hw_loss 0.405969 history loss 6.293259 rank 4
2023-03-01 08:05:42,113 DEBUG CV Batch 51/1700 loss 7.542244 loss_att 5.461208 loss_ctc 12.671432 loss_rnnt 7.058042 hw_loss 0.405969 history loss 6.293259 rank 2
2023-03-01 08:05:46,192 DEBUG CV Batch 51/1700 loss 7.542244 loss_att 5.461208 loss_ctc 12.671432 loss_rnnt 7.058042 hw_loss 0.405969 history loss 6.293259 rank 3
2023-03-01 08:05:47,299 INFO Epoch 51 CV info cv_loss 6.266980517509701
2023-03-01 08:05:47,300 INFO Epoch 52 TRAIN info lr 0.00029052194529067974
2023-03-01 08:05:47,304 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 08:05:49,347 INFO Epoch 51 CV info cv_loss 6.266980518877274
2023-03-01 08:05:49,348 INFO Epoch 52 TRAIN info lr 0.0002905317541570014
2023-03-01 08:05:49,353 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 08:05:49,532 INFO Epoch 51 CV info cv_loss 6.266980517793984
2023-03-01 08:05:49,533 INFO Epoch 52 TRAIN info lr 0.00029052635915757785
2023-03-01 08:05:49,537 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 08:05:50,087 INFO Epoch 51 CV info cv_loss 6.266980518151491
2023-03-01 08:05:50,088 INFO Checkpoint: save to checkpoint exp/2_27_rnnt_bias_loss_2_class_both_finetune/51.pt
2023-03-01 08:05:50,159 INFO Epoch 51 CV info cv_loss 6.266980519284315
2023-03-01 08:05:50,159 INFO Epoch 52 TRAIN info lr 0.00029053028276371554
2023-03-01 08:05:50,161 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 08:05:50,674 INFO Epoch 52 TRAIN info lr 0.00029053567798172715
2023-03-01 08:05:50,678 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 08:05:51,000 INFO Epoch 51 CV info cv_loss 6.266980518993571
2023-03-01 08:05:51,001 INFO Epoch 52 TRAIN info lr 0.00029053420652882443
2023-03-01 08:05:51,006 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 08:05:51,534 INFO Epoch 51 CV info cv_loss 6.2669805185563785
2023-03-01 08:05:51,535 INFO Epoch 52 TRAIN info lr 0.0002905351874949421
2023-03-01 08:05:51,540 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 08:05:55,604 INFO Epoch 51 CV info cv_loss 6.266980518931115
2023-03-01 08:05:55,605 INFO Epoch 52 TRAIN info lr 0.00029052439741411985
2023-03-01 08:05:55,610 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 08:06:55,426 DEBUG TRAIN Batch 52/0 loss 4.477203 loss_att 5.247154 loss_ctc 7.690833 loss_rnnt 3.733876 hw_loss 0.301599 lr 0.00029053 rank 2
2023-03-01 08:06:55,428 DEBUG TRAIN Batch 52/0 loss 4.854987 loss_att 5.425623 loss_ctc 6.842324 loss_rnnt 4.312640 hw_loss 0.306076 lr 0.00029053 rank 6
2023-03-01 08:06:55,432 DEBUG TRAIN Batch 52/0 loss 5.369172 loss_att 5.452024 loss_ctc 8.581900 loss_rnnt 4.786801 hw_loss 0.257694 lr 0.00029053 rank 4
2023-03-01 08:06:55,434 DEBUG TRAIN Batch 52/0 loss 5.797939 loss_att 6.612073 loss_ctc 8.295584 loss_rnnt 5.096278 hw_loss 0.385903 lr 0.00029054 rank 0
2023-03-01 08:06:55,437 DEBUG TRAIN Batch 52/0 loss 5.724705 loss_att 5.490585 loss_ctc 8.525518 loss_rnnt 5.203183 hw_loss 0.365445 lr 0.00029052 rank 7
2023-03-01 08:06:55,438 DEBUG TRAIN Batch 52/0 loss 4.696394 loss_att 5.069873 loss_ctc 7.276027 loss_rnnt 4.017488 hw_loss 0.487985 lr 0.00029053 rank 5
2023-03-01 08:06:55,456 DEBUG TRAIN Batch 52/0 loss 8.354039 loss_att 8.407699 loss_ctc 10.559410 loss_rnnt 7.896965 hw_loss 0.285549 lr 0.00029052 rank 3
2023-03-01 08:06:55,479 DEBUG TRAIN Batch 52/0 loss 7.997450 loss_att 7.735459 loss_ctc 12.029170 loss_rnnt 7.310155 hw_loss 0.378994 lr 0.00029053 rank 1
2023-03-01 08:07:33,040 DEBUG TRAIN Batch 52/100 loss 1.428177 loss_att 4.130551 loss_ctc 2.986692 loss_rnnt 0.585471 hw_loss 0.177055 lr 0.00029051 rank 7
2023-03-01 08:07:33,040 DEBUG TRAIN Batch 52/100 loss 6.388264 loss_att 9.641441 loss_ctc 12.312458 loss_rnnt 4.822590 hw_loss 0.234648 lr 0.00029051 rank 3
2023-03-01 08:07:33,043 DEBUG TRAIN Batch 52/100 loss 2.012775 loss_att 4.839864 loss_ctc 4.024610 loss_rnnt 1.039597 hw_loss 0.261593 lr 0.00029052 rank 2
2023-03-01 08:07:33,043 DEBUG TRAIN Batch 52/100 loss 9.757951 loss_att 14.828388 loss_ctc 15.279211 loss_rnnt 7.921638 hw_loss 0.161354 lr 0.00029052 rank 0
2023-03-01 08:07:33,045 DEBUG TRAIN Batch 52/100 loss 3.205555 loss_att 6.192116 loss_ctc 5.703738 loss_rnnt 2.162653 hw_loss 0.210938 lr 0.00029052 rank 4
2023-03-01 08:07:33,045 DEBUG TRAIN Batch 52/100 loss 5.694225 loss_att 6.570237 loss_ctc 7.243979 loss_rnnt 5.115452 hw_loss 0.369255 lr 0.00029052 rank 1
2023-03-01 08:07:33,045 DEBUG TRAIN Batch 52/100 loss 6.917283 loss_att 7.890316 loss_ctc 11.525991 loss_rnnt 6.066519 hw_loss 0.078118 lr 0.00029052 rank 6
2023-03-01 08:07:33,046 DEBUG TRAIN Batch 52/100 loss 3.869804 loss_att 7.294496 loss_ctc 5.956192 loss_rnnt 2.739097 hw_loss 0.314220 lr 0.00029051 rank 5
2023-03-01 08:08:10,995 DEBUG TRAIN Batch 52/200 loss 4.838542 loss_att 6.630967 loss_ctc 4.895654 loss_rnnt 4.347338 hw_loss 0.234571 lr 0.00029051 rank 4
2023-03-01 08:08:10,997 DEBUG TRAIN Batch 52/200 loss 2.308711 loss_att 6.335860 loss_ctc 3.005831 loss_rnnt 1.243003 hw_loss 0.313741 lr 0.00029051 rank 0
2023-03-01 08:08:10,998 DEBUG TRAIN Batch 52/200 loss 5.223556 loss_att 8.864506 loss_ctc 10.252741 loss_rnnt 3.695487 hw_loss 0.242477 lr 0.00029050 rank 7
2023-03-01 08:08:10,999 DEBUG TRAIN Batch 52/200 loss 5.503842 loss_att 8.621851 loss_ctc 8.077883 loss_rnnt 4.389889 hw_loss 0.275898 lr 0.00029050 rank 5
2023-03-01 08:08:11,000 DEBUG TRAIN Batch 52/200 loss 2.196802 loss_att 5.591156 loss_ctc 4.631949 loss_rnnt 1.093814 hw_loss 0.186432 lr 0.00029051 rank 6
2023-03-01 08:08:11,003 DEBUG TRAIN Batch 52/200 loss 4.726651 loss_att 4.901766 loss_ctc 4.828651 loss_rnnt 4.507571 hw_loss 0.319606 lr 0.00029050 rank 3
2023-03-01 08:08:11,005 DEBUG TRAIN Batch 52/200 loss 1.117127 loss_att 3.277234 loss_ctc 1.800536 loss_rnnt 0.463828 hw_loss 0.244042 lr 0.00029051 rank 2
2023-03-01 08:08:11,019 DEBUG TRAIN Batch 52/200 loss 7.399980 loss_att 10.624963 loss_ctc 8.951458 loss_rnnt 6.428114 hw_loss 0.225011 lr 0.00029051 rank 1
2023-03-01 08:08:49,030 DEBUG TRAIN Batch 52/300 loss 3.880012 loss_att 7.660950 loss_ctc 7.628000 loss_rnnt 2.559730 hw_loss 0.120679 lr 0.00029049 rank 1
2023-03-01 08:08:49,032 DEBUG TRAIN Batch 52/300 loss 9.399119 loss_att 12.808004 loss_ctc 19.787468 loss_rnnt 7.188035 hw_loss 0.270365 lr 0.00029049 rank 3
2023-03-01 08:08:49,036 DEBUG TRAIN Batch 52/300 loss 5.980364 loss_att 7.628851 loss_ctc 8.914560 loss_rnnt 5.163812 hw_loss 0.179306 lr 0.00029049 rank 5
2023-03-01 08:08:49,040 DEBUG TRAIN Batch 52/300 loss 9.362883 loss_att 14.636316 loss_ctc 19.073086 loss_rnnt 6.911149 hw_loss 0.191914 lr 0.00029050 rank 0
2023-03-01 08:08:49,047 DEBUG TRAIN Batch 52/300 loss 10.408099 loss_att 12.770141 loss_ctc 16.183270 loss_rnnt 8.998550 hw_loss 0.313346 lr 0.00029048 rank 7
2023-03-01 08:08:49,048 DEBUG TRAIN Batch 52/300 loss 4.404561 loss_att 8.279643 loss_ctc 6.264288 loss_rnnt 3.302578 hw_loss 0.148130 lr 0.00029049 rank 6
2023-03-01 08:08:49,060 DEBUG TRAIN Batch 52/300 loss 5.713207 loss_att 7.949164 loss_ctc 9.118019 loss_rnnt 4.717062 hw_loss 0.178085 lr 0.00029050 rank 4
2023-03-01 08:08:49,088 DEBUG TRAIN Batch 52/300 loss 7.127805 loss_att 11.287862 loss_ctc 13.465181 loss_rnnt 5.347772 hw_loss 0.193196 lr 0.00029050 rank 2
2023-03-01 08:09:52,889 DEBUG TRAIN Batch 52/400 loss 4.508150 loss_att 6.818743 loss_ctc 6.933551 loss_rnnt 3.638392 hw_loss 0.157973 lr 0.00029049 rank 0
2023-03-01 08:09:52,890 DEBUG TRAIN Batch 52/400 loss 9.291919 loss_att 10.532851 loss_ctc 13.590371 loss_rnnt 8.280243 hw_loss 0.356929 lr 0.00029048 rank 5
2023-03-01 08:09:52,893 DEBUG TRAIN Batch 52/400 loss 2.368774 loss_att 5.029223 loss_ctc 6.700971 loss_rnnt 1.142505 hw_loss 0.218537 lr 0.00029049 rank 2
2023-03-01 08:09:52,894 DEBUG TRAIN Batch 52/400 loss 4.157896 loss_att 7.550453 loss_ctc 9.305753 loss_rnnt 2.684346 hw_loss 0.203733 lr 0.00029048 rank 4
2023-03-01 08:09:52,895 DEBUG TRAIN Batch 52/400 loss 6.321498 loss_att 11.080284 loss_ctc 9.374722 loss_rnnt 4.835131 hw_loss 0.239088 lr 0.00029047 rank 7
2023-03-01 08:09:52,896 DEBUG TRAIN Batch 52/400 loss 6.120099 loss_att 10.225424 loss_ctc 12.669882 loss_rnnt 4.356468 hw_loss 0.129864 lr 0.00029048 rank 6
2023-03-01 08:09:52,899 DEBUG TRAIN Batch 52/400 loss 5.590626 loss_att 8.951836 loss_ctc 9.439337 loss_rnnt 4.281133 hw_loss 0.232668 lr 0.00029048 rank 1
2023-03-01 08:09:52,917 DEBUG TRAIN Batch 52/400 loss 1.504228 loss_att 5.179530 loss_ctc 3.605651 loss_rnnt 0.388145 hw_loss 0.189061 lr 0.00029047 rank 3
2023-03-01 08:10:31,434 DEBUG TRAIN Batch 52/500 loss 5.118720 loss_att 7.284975 loss_ctc 9.214866 loss_rnnt 3.988946 hw_loss 0.281943 lr 0.00029047 rank 2
2023-03-01 08:10:31,447 DEBUG TRAIN Batch 52/500 loss 5.090196 loss_att 5.950023 loss_ctc 6.376919 loss_rnnt 4.547610 hw_loss 0.373233 lr 0.00029046 rank 7
2023-03-01 08:10:31,451 DEBUG TRAIN Batch 52/500 loss 5.636272 loss_att 7.901229 loss_ctc 7.356370 loss_rnnt 4.827159 hw_loss 0.237704 lr 0.00029046 rank 3
2023-03-01 08:10:31,452 DEBUG TRAIN Batch 52/500 loss 6.157040 loss_att 10.607250 loss_ctc 10.249924 loss_rnnt 4.631887 hw_loss 0.167611 lr 0.00029047 rank 0
2023-03-01 08:10:31,454 DEBUG TRAIN Batch 52/500 loss 3.956921 loss_att 6.060600 loss_ctc 5.310924 loss_rnnt 3.198036 hw_loss 0.295531 lr 0.00029047 rank 6
2023-03-01 08:10:31,453 DEBUG TRAIN Batch 52/500 loss 2.828825 loss_att 5.837003 loss_ctc 6.451933 loss_rnnt 1.683747 hw_loss 0.113177 lr 0.00029047 rank 1
2023-03-01 08:10:31,459 DEBUG TRAIN Batch 52/500 loss 5.031030 loss_att 8.680746 loss_ctc 11.583479 loss_rnnt 3.333258 hw_loss 0.176566 lr 0.00029046 rank 5
2023-03-01 08:10:31,502 DEBUG TRAIN Batch 52/500 loss 3.806261 loss_att 5.136787 loss_ctc 6.251829 loss_rnnt 3.035465 hw_loss 0.334905 lr 0.00029047 rank 4
2023-03-01 08:11:10,261 DEBUG TRAIN Batch 52/600 loss 4.518761 loss_att 5.785646 loss_ctc 6.371080 loss_rnnt 3.879269 hw_loss 0.260885 lr 0.00029046 rank 0
2023-03-01 08:11:10,262 DEBUG TRAIN Batch 52/600 loss 4.954586 loss_att 7.569841 loss_ctc 11.058591 loss_rnnt 3.443357 hw_loss 0.326832 lr 0.00029046 rank 4
2023-03-01 08:11:10,263 DEBUG TRAIN Batch 52/600 loss 6.455907 loss_att 7.387872 loss_ctc 9.441202 loss_rnnt 5.672272 hw_loss 0.373504 lr 0.00029045 rank 7
2023-03-01 08:11:10,264 DEBUG TRAIN Batch 52/600 loss 8.046765 loss_att 15.612710 loss_ctc 13.333340 loss_rnnt 5.752627 hw_loss 0.142636 lr 0.00029046 rank 6
2023-03-01 08:11:10,265 DEBUG TRAIN Batch 52/600 loss 3.889162 loss_att 5.618461 loss_ctc 6.802550 loss_rnnt 2.971717 hw_loss 0.343374 lr 0.00029046 rank 1
2023-03-01 08:11:10,266 DEBUG TRAIN Batch 52/600 loss 2.789463 loss_att 5.035951 loss_ctc 5.938452 loss_rnnt 1.822351 hw_loss 0.183655 lr 0.00029046 rank 2
2023-03-01 08:11:10,271 DEBUG TRAIN Batch 52/600 loss 7.074639 loss_att 7.767959 loss_ctc 11.148293 loss_rnnt 6.218950 hw_loss 0.326007 lr 0.00029045 rank 5
2023-03-01 08:11:10,272 DEBUG TRAIN Batch 52/600 loss 4.842506 loss_att 5.613059 loss_ctc 7.107426 loss_rnnt 4.253609 hw_loss 0.248995 lr 0.00029045 rank 3
2023-03-01 08:11:49,745 DEBUG TRAIN Batch 52/700 loss 1.087295 loss_att 3.448194 loss_ctc 3.567884 loss_rnnt 0.208170 hw_loss 0.142874 lr 0.00029044 rank 5
2023-03-01 08:11:49,748 DEBUG TRAIN Batch 52/700 loss 11.773390 loss_att 12.315857 loss_ctc 17.413298 loss_rnnt 10.886669 hw_loss 0.049197 lr 0.00029044 rank 7
2023-03-01 08:11:49,752 DEBUG TRAIN Batch 52/700 loss 2.432139 loss_att 6.307957 loss_ctc 5.303186 loss_rnnt 1.171960 hw_loss 0.191643 lr 0.00029044 rank 3
2023-03-01 08:11:49,759 DEBUG TRAIN Batch 52/700 loss 5.715213 loss_att 8.235489 loss_ctc 13.874614 loss_rnnt 4.034202 hw_loss 0.166943 lr 0.00029045 rank 2
2023-03-01 08:11:49,760 DEBUG TRAIN Batch 52/700 loss 6.061368 loss_att 8.897197 loss_ctc 8.440880 loss_rnnt 5.056286 hw_loss 0.226214 lr 0.00029044 rank 6
2023-03-01 08:11:49,763 DEBUG TRAIN Batch 52/700 loss 6.317732 loss_att 9.348251 loss_ctc 11.568274 loss_rnnt 5.010872 hw_loss 0.001280 lr 0.00029045 rank 0
2023-03-01 08:11:49,765 DEBUG TRAIN Batch 52/700 loss 3.798521 loss_att 6.175856 loss_ctc 7.592645 loss_rnnt 2.717042 hw_loss 0.187743 lr 0.00029045 rank 1
2023-03-01 08:11:49,785 DEBUG TRAIN Batch 52/700 loss 3.764546 loss_att 6.948375 loss_ctc 10.460081 loss_rnnt 2.065846 hw_loss 0.317243 lr 0.00029045 rank 4
2023-03-01 08:12:55,661 DEBUG TRAIN Batch 52/800 loss 3.905827 loss_att 6.492697 loss_ctc 3.905485 loss_rnnt 3.286133 hw_loss 0.191934 lr 0.00029044 rank 0
2023-03-01 08:12:55,664 DEBUG TRAIN Batch 52/800 loss 3.566615 loss_att 6.900804 loss_ctc 5.453842 loss_rnnt 2.498117 hw_loss 0.281307 lr 0.00029043 rank 1
2023-03-01 08:12:55,669 DEBUG TRAIN Batch 52/800 loss 5.497724 loss_att 6.934933 loss_ctc 6.406491 loss_rnnt 4.983782 hw_loss 0.197495 lr 0.00029043 rank 6
2023-03-01 08:12:55,672 DEBUG TRAIN Batch 52/800 loss 4.406290 loss_att 6.200920 loss_ctc 6.288049 loss_rnnt 3.707743 hw_loss 0.166350 lr 0.00029044 rank 4
2023-03-01 08:12:55,675 DEBUG TRAIN Batch 52/800 loss 11.771471 loss_att 15.203268 loss_ctc 16.645163 loss_rnnt 10.409054 hw_loss 0.049187 lr 0.00029043 rank 3
2023-03-01 08:12:55,677 DEBUG TRAIN Batch 52/800 loss 6.573996 loss_att 8.998477 loss_ctc 10.596258 loss_rnnt 5.455408 hw_loss 0.182607 lr 0.00029043 rank 5
2023-03-01 08:12:55,679 DEBUG TRAIN Batch 52/800 loss 7.047785 loss_att 10.294525 loss_ctc 11.060928 loss_rnnt 5.806209 hw_loss 0.107142 lr 0.00029042 rank 7
2023-03-01 08:12:55,718 DEBUG TRAIN Batch 52/800 loss 1.598274 loss_att 3.998693 loss_ctc 2.043488 loss_rnnt 0.951914 hw_loss 0.200463 lr 0.00029044 rank 2
2023-03-01 08:13:34,045 DEBUG TRAIN Batch 52/900 loss 2.853221 loss_att 5.379203 loss_ctc 6.450705 loss_rnnt 1.708676 hw_loss 0.299407 lr 0.00029042 rank 6
2023-03-01 08:13:34,060 DEBUG TRAIN Batch 52/900 loss 6.902405 loss_att 9.419989 loss_ctc 12.408904 loss_rnnt 5.545028 hw_loss 0.224365 lr 0.00029041 rank 7
2023-03-01 08:13:34,065 DEBUG TRAIN Batch 52/900 loss 7.599988 loss_att 13.460339 loss_ctc 14.902798 loss_rnnt 5.319107 hw_loss 0.253319 lr 0.00029042 rank 2
2023-03-01 08:13:34,065 DEBUG TRAIN Batch 52/900 loss 6.171784 loss_att 10.170606 loss_ctc 11.404201 loss_rnnt 4.536917 hw_loss 0.257714 lr 0.00029042 rank 0
2023-03-01 08:13:34,068 DEBUG TRAIN Batch 52/900 loss 1.898933 loss_att 4.189734 loss_ctc 3.592714 loss_rnnt 1.101741 hw_loss 0.212240 lr 0.00029042 rank 5
2023-03-01 08:13:34,069 DEBUG TRAIN Batch 52/900 loss 2.507541 loss_att 4.325986 loss_ctc 3.759111 loss_rnnt 1.877845 hw_loss 0.185870 lr 0.00029042 rank 4
2023-03-01 08:13:34,071 DEBUG TRAIN Batch 52/900 loss 6.853888 loss_att 9.410275 loss_ctc 12.859348 loss_rnnt 5.447946 hw_loss 0.176131 lr 0.00029041 rank 3
2023-03-01 08:13:34,070 DEBUG TRAIN Batch 52/900 loss 3.543091 loss_att 8.409247 loss_ctc 9.322838 loss_rnnt 1.662522 hw_loss 0.256321 lr 0.00029042 rank 1
2023-03-01 08:14:12,556 DEBUG TRAIN Batch 52/1000 loss 9.190005 loss_att 11.262443 loss_ctc 17.571634 loss_rnnt 7.591012 hw_loss 0.125538 lr 0.00029041 rank 6
2023-03-01 08:14:12,557 DEBUG TRAIN Batch 52/1000 loss 7.296780 loss_att 11.538057 loss_ctc 11.086377 loss_rnnt 5.857452 hw_loss 0.160861 lr 0.00029040 rank 3
2023-03-01 08:14:12,559 DEBUG TRAIN Batch 52/1000 loss 3.874717 loss_att 7.401216 loss_ctc 5.370833 loss_rnnt 2.927264 hw_loss 0.080007 lr 0.00029040 rank 5
2023-03-01 08:14:12,559 DEBUG TRAIN Batch 52/1000 loss 10.740355 loss_att 12.255413 loss_ctc 16.327589 loss_rnnt 9.595448 hw_loss 0.181745 lr 0.00029041 rank 4
2023-03-01 08:14:12,564 DEBUG TRAIN Batch 52/1000 loss 4.400473 loss_att 6.595130 loss_ctc 6.609769 loss_rnnt 3.552031 hw_loss 0.215507 lr 0.00029041 rank 2
2023-03-01 08:14:12,565 DEBUG TRAIN Batch 52/1000 loss 4.831988 loss_att 8.884424 loss_ctc 7.274614 loss_rnnt 3.559670 hw_loss 0.255276 lr 0.00029040 rank 7
2023-03-01 08:14:12,567 DEBUG TRAIN Batch 52/1000 loss 1.891973 loss_att 4.517583 loss_ctc 4.358338 loss_rnnt 0.915695 hw_loss 0.229325 lr 0.00029041 rank 0
2023-03-01 08:14:12,588 DEBUG TRAIN Batch 52/1000 loss 9.132674 loss_att 13.912663 loss_ctc 14.102282 loss_rnnt 7.385730 hw_loss 0.240624 lr 0.00029041 rank 1
2023-03-01 08:15:18,827 DEBUG TRAIN Batch 52/1100 loss 9.071762 loss_att 11.821338 loss_ctc 10.777878 loss_rnnt 8.143039 hw_loss 0.283738 lr 0.00029040 rank 2
2023-03-01 08:15:18,838 DEBUG TRAIN Batch 52/1100 loss 3.378734 loss_att 6.908498 loss_ctc 4.600082 loss_rnnt 2.369079 hw_loss 0.264105 lr 0.00029040 rank 1
2023-03-01 08:15:18,840 DEBUG TRAIN Batch 52/1100 loss 3.739420 loss_att 7.960326 loss_ctc 11.379845 loss_rnnt 1.723065 hw_loss 0.287718 lr 0.00029039 rank 3
2023-03-01 08:15:18,841 DEBUG TRAIN Batch 52/1100 loss 13.341694 loss_att 14.838406 loss_ctc 21.335499 loss_rnnt 11.917232 hw_loss 0.111150 lr 0.00029039 rank 7
2023-03-01 08:15:18,842 DEBUG TRAIN Batch 52/1100 loss 2.315710 loss_att 4.953684 loss_ctc 4.009194 loss_rnnt 1.422727 hw_loss 0.261731 lr 0.00029040 rank 4
2023-03-01 08:15:18,842 DEBUG TRAIN Batch 52/1100 loss 8.087964 loss_att 9.464134 loss_ctc 13.488778 loss_rnnt 7.005574 hw_loss 0.163215 lr 0.00029040 rank 6
2023-03-01 08:15:18,844 DEBUG TRAIN Batch 52/1100 loss 11.371056 loss_att 15.351349 loss_ctc 21.035164 loss_rnnt 9.181735 hw_loss 0.196337 lr 0.00029040 rank 0
2023-03-01 08:15:18,845 DEBUG TRAIN Batch 52/1100 loss 4.920259 loss_att 8.981681 loss_ctc 7.856736 loss_rnnt 3.601030 hw_loss 0.216404 lr 0.00029039 rank 5
2023-03-01 08:15:57,496 DEBUG TRAIN Batch 52/1200 loss 4.786016 loss_att 5.455499 loss_ctc 6.365423 loss_rnnt 4.205434 hw_loss 0.442682 lr 0.00029039 rank 4
2023-03-01 08:15:57,506 DEBUG TRAIN Batch 52/1200 loss 4.724592 loss_att 7.853642 loss_ctc 10.630318 loss_rnnt 3.203782 hw_loss 0.201692 lr 0.00029039 rank 0
2023-03-01 08:15:57,506 DEBUG TRAIN Batch 52/1200 loss 6.122694 loss_att 8.036295 loss_ctc 10.873769 loss_rnnt 4.929468 hw_loss 0.331929 lr 0.00029038 rank 5
2023-03-01 08:15:57,508 DEBUG TRAIN Batch 52/1200 loss 7.854193 loss_att 11.331828 loss_ctc 10.797210 loss_rnnt 6.681607 hw_loss 0.158729 lr 0.00029037 rank 7
2023-03-01 08:15:57,510 DEBUG TRAIN Batch 52/1200 loss 5.446782 loss_att 9.223514 loss_ctc 9.654166 loss_rnnt 3.968556 hw_loss 0.303554 lr 0.00029038 rank 3
2023-03-01 08:15:57,513 DEBUG TRAIN Batch 52/1200 loss 3.214201 loss_att 4.647240 loss_ctc 5.060803 loss_rnnt 2.501105 hw_loss 0.338014 lr 0.00029038 rank 6
2023-03-01 08:15:57,517 DEBUG TRAIN Batch 52/1200 loss 4.496875 loss_att 5.579480 loss_ctc 9.499486 loss_rnnt 3.458857 hw_loss 0.289655 lr 0.00029039 rank 2
2023-03-01 08:15:57,557 DEBUG TRAIN Batch 52/1200 loss 6.098090 loss_att 8.449278 loss_ctc 10.488108 loss_rnnt 4.968734 hw_loss 0.138341 lr 0.00029038 rank 1
2023-03-01 08:16:35,897 DEBUG TRAIN Batch 52/1300 loss 4.777561 loss_att 6.748722 loss_ctc 6.207178 loss_rnnt 4.068788 hw_loss 0.232359 lr 0.00029038 rank 0
2023-03-01 08:16:35,914 DEBUG TRAIN Batch 52/1300 loss 4.986684 loss_att 6.430278 loss_ctc 7.811110 loss_rnnt 4.147818 hw_loss 0.325419 lr 0.00029038 rank 2
2023-03-01 08:16:35,914 DEBUG TRAIN Batch 52/1300 loss 2.895088 loss_att 5.019709 loss_ctc 3.088511 loss_rnnt 2.288156 hw_loss 0.292908 lr 0.00029037 rank 1
2023-03-01 08:16:35,915 DEBUG TRAIN Batch 52/1300 loss 2.060741 loss_att 3.975038 loss_ctc 2.675756 loss_rnnt 1.497776 hw_loss 0.183944 lr 0.00029037 rank 4
2023-03-01 08:16:35,917 DEBUG TRAIN Batch 52/1300 loss 8.007830 loss_att 10.333569 loss_ctc 14.924330 loss_rnnt 6.464465 hw_loss 0.292532 lr 0.00029036 rank 3
2023-03-01 08:16:35,919 DEBUG TRAIN Batch 52/1300 loss 3.290920 loss_att 6.644372 loss_ctc 4.997575 loss_rnnt 2.250087 hw_loss 0.267354 lr 0.00029036 rank 7
2023-03-01 08:16:35,920 DEBUG TRAIN Batch 52/1300 loss 4.890041 loss_att 8.204221 loss_ctc 9.574211 loss_rnnt 3.555773 hw_loss 0.087893 lr 0.00029037 rank 5
2023-03-01 08:16:35,923 DEBUG TRAIN Batch 52/1300 loss 4.787498 loss_att 6.558963 loss_ctc 4.472937 loss_rnnt 4.385147 hw_loss 0.168750 lr 0.00029037 rank 6
2023-03-01 08:17:15,420 DEBUG TRAIN Batch 52/1400 loss 9.256396 loss_att 13.793614 loss_ctc 14.225086 loss_rnnt 7.601736 hw_loss 0.158862 lr 0.00029036 rank 0
2023-03-01 08:17:15,422 DEBUG TRAIN Batch 52/1400 loss 2.978759 loss_att 5.894032 loss_ctc 4.546507 loss_rnnt 2.059312 hw_loss 0.238800 lr 0.00029036 rank 4
2023-03-01 08:17:15,424 DEBUG TRAIN Batch 52/1400 loss 6.223739 loss_att 9.926047 loss_ctc 14.732828 loss_rnnt 4.187146 hw_loss 0.302973 lr 0.00029035 rank 5
2023-03-01 08:17:15,434 DEBUG TRAIN Batch 52/1400 loss 11.606009 loss_att 14.932720 loss_ctc 16.285364 loss_rnnt 10.239776 hw_loss 0.144333 lr 0.00029036 rank 6
2023-03-01 08:17:15,436 DEBUG TRAIN Batch 52/1400 loss 3.486389 loss_att 6.442078 loss_ctc 4.567484 loss_rnnt 2.750479 hw_loss 0.001175 lr 0.00029035 rank 7
2023-03-01 08:17:15,437 DEBUG TRAIN Batch 52/1400 loss 7.045825 loss_att 9.736194 loss_ctc 13.625521 loss_rnnt 5.599805 hw_loss 0.057475 lr 0.00029036 rank 1
2023-03-01 08:17:15,451 DEBUG TRAIN Batch 52/1400 loss 3.585070 loss_att 5.902853 loss_ctc 4.266860 loss_rnnt 2.990935 hw_loss 0.074386 lr 0.00029035 rank 3
2023-03-01 08:17:15,484 DEBUG TRAIN Batch 52/1400 loss 4.628712 loss_att 6.915005 loss_ctc 5.174038 loss_rnnt 3.968687 hw_loss 0.243855 lr 0.00029036 rank 2
2023-03-01 08:18:21,295 DEBUG TRAIN Batch 52/1500 loss 7.348152 loss_att 12.357577 loss_ctc 9.428600 loss_rnnt 5.914095 hw_loss 0.290209 lr 0.00029035 rank 1
2023-03-01 08:18:21,306 DEBUG TRAIN Batch 52/1500 loss 10.482049 loss_att 13.287167 loss_ctc 18.184769 loss_rnnt 8.738775 hw_loss 0.291038 lr 0.00029034 rank 5
2023-03-01 08:18:21,306 DEBUG TRAIN Batch 52/1500 loss 3.415592 loss_att 4.861385 loss_ctc 4.677172 loss_rnnt 2.827819 hw_loss 0.244508 lr 0.00029034 rank 3
2023-03-01 08:18:21,308 DEBUG TRAIN Batch 52/1500 loss 1.885925 loss_att 4.205153 loss_ctc 3.147194 loss_rnnt 1.151618 hw_loss 0.191798 lr 0.00029035 rank 0
2023-03-01 08:18:21,309 DEBUG TRAIN Batch 52/1500 loss 3.808342 loss_att 7.818713 loss_ctc 9.172398 loss_rnnt 2.199305 hw_loss 0.172042 lr 0.00029034 rank 7
2023-03-01 08:18:21,310 DEBUG TRAIN Batch 52/1500 loss 4.484464 loss_att 7.920565 loss_ctc 10.061310 loss_rnnt 2.930885 hw_loss 0.230211 lr 0.00029035 rank 4
2023-03-01 08:18:21,313 DEBUG TRAIN Batch 52/1500 loss 5.598606 loss_att 9.527111 loss_ctc 11.339838 loss_rnnt 3.990651 hw_loss 0.106418 lr 0.00029035 rank 6
2023-03-01 08:18:21,358 DEBUG TRAIN Batch 52/1500 loss 6.349488 loss_att 9.587620 loss_ctc 13.026977 loss_rnnt 4.707128 hw_loss 0.195755 lr 0.00029035 rank 2
2023-03-01 08:18:59,900 DEBUG TRAIN Batch 52/1600 loss 4.205693 loss_att 6.158768 loss_ctc 7.030319 loss_rnnt 3.347402 hw_loss 0.170737 lr 0.00029034 rank 1
2023-03-01 08:18:59,907 DEBUG TRAIN Batch 52/1600 loss 6.156079 loss_att 6.538154 loss_ctc 7.398482 loss_rnnt 5.769901 hw_loss 0.270206 lr 0.00029034 rank 0
2023-03-01 08:18:59,909 DEBUG TRAIN Batch 52/1600 loss 3.659651 loss_att 6.400959 loss_ctc 6.994361 loss_rnnt 2.554158 hw_loss 0.211132 lr 0.00029033 rank 6
2023-03-01 08:18:59,911 DEBUG TRAIN Batch 52/1600 loss 7.640025 loss_att 11.553925 loss_ctc 12.167448 loss_rnnt 6.205070 hw_loss 0.090970 lr 0.00029033 rank 7
2023-03-01 08:18:59,911 DEBUG TRAIN Batch 52/1600 loss 7.649598 loss_att 9.650497 loss_ctc 11.408825 loss_rnnt 6.662828 hw_loss 0.160049 lr 0.00029033 rank 5
2023-03-01 08:18:59,914 DEBUG TRAIN Batch 52/1600 loss 13.913526 loss_att 13.981832 loss_ctc 20.342230 loss_rnnt 12.934871 hw_loss 0.202187 lr 0.00029034 rank 4
2023-03-01 08:18:59,920 DEBUG TRAIN Batch 52/1600 loss 2.180655 loss_att 6.300995 loss_ctc 5.494288 loss_rnnt 0.757396 hw_loss 0.295077 lr 0.00029033 rank 3
2023-03-01 08:18:59,958 DEBUG TRAIN Batch 52/1600 loss 7.553511 loss_att 9.791913 loss_ctc 15.206116 loss_rnnt 5.931736 hw_loss 0.288274 lr 0.00029034 rank 2
2023-03-01 08:19:39,055 DEBUG TRAIN Batch 52/1700 loss 3.694435 loss_att 5.597375 loss_ctc 7.275276 loss_rnnt 2.701866 hw_loss 0.252253 lr 0.00029032 rank 5
2023-03-01 08:19:39,058 DEBUG TRAIN Batch 52/1700 loss 9.034582 loss_att 11.300917 loss_ctc 16.790434 loss_rnnt 7.451694 hw_loss 0.179076 lr 0.00029032 rank 1
2023-03-01 08:19:39,060 DEBUG TRAIN Batch 52/1700 loss 6.386714 loss_att 7.158637 loss_ctc 7.131025 loss_rnnt 6.021875 hw_loss 0.208525 lr 0.00029031 rank 7
2023-03-01 08:19:39,068 DEBUG TRAIN Batch 52/1700 loss 4.430346 loss_att 6.748330 loss_ctc 7.768745 loss_rnnt 3.425196 hw_loss 0.180814 lr 0.00029032 rank 6
2023-03-01 08:19:39,071 DEBUG TRAIN Batch 52/1700 loss 6.447851 loss_att 9.933224 loss_ctc 10.562530 loss_rnnt 5.075618 hw_loss 0.237253 lr 0.00029032 rank 3
2023-03-01 08:19:39,073 DEBUG TRAIN Batch 52/1700 loss 3.600169 loss_att 8.026349 loss_ctc 9.398878 loss_rnnt 1.859595 hw_loss 0.154082 lr 0.00029033 rank 2
2023-03-01 08:19:39,076 DEBUG TRAIN Batch 52/1700 loss 4.863258 loss_att 8.201907 loss_ctc 10.793122 loss_rnnt 3.276543 hw_loss 0.240629 lr 0.00029033 rank 0
2023-03-01 08:19:39,087 DEBUG TRAIN Batch 52/1700 loss 5.638106 loss_att 8.613577 loss_ctc 8.606176 loss_rnnt 4.556117 hw_loss 0.170911 lr 0.00029033 rank 4
2023-03-01 08:20:44,707 DEBUG TRAIN Batch 52/1800 loss 5.687465 loss_att 8.938369 loss_ctc 11.760457 loss_rnnt 4.101851 hw_loss 0.235688 lr 0.00029031 rank 2
2023-03-01 08:20:44,716 DEBUG TRAIN Batch 52/1800 loss 7.699097 loss_att 7.988686 loss_ctc 8.780741 loss_rnnt 7.353529 hw_loss 0.268932 lr 0.00029031 rank 4
2023-03-01 08:20:44,717 DEBUG TRAIN Batch 52/1800 loss 5.115251 loss_att 6.088430 loss_ctc 6.670264 loss_rnnt 4.513951 hw_loss 0.373741 lr 0.00029030 rank 7
2023-03-01 08:20:44,722 DEBUG TRAIN Batch 52/1800 loss 9.640432 loss_att 10.327173 loss_ctc 13.523401 loss_rnnt 8.839023 hw_loss 0.274373 lr 0.00029031 rank 1
2023-03-01 08:20:44,723 DEBUG TRAIN Batch 52/1800 loss 7.904438 loss_att 12.131634 loss_ctc 20.201082 loss_rnnt 5.370243 hw_loss 0.092257 lr 0.00029031 rank 0
2023-03-01 08:20:44,725 DEBUG TRAIN Batch 52/1800 loss 7.985563 loss_att 10.320263 loss_ctc 14.345232 loss_rnnt 6.552001 hw_loss 0.222500 lr 0.00029031 rank 6
2023-03-01 08:20:44,728 DEBUG TRAIN Batch 52/1800 loss 7.730117 loss_att 9.612301 loss_ctc 14.396375 loss_rnnt 6.302239 hw_loss 0.304885 lr 0.00029031 rank 5
2023-03-01 08:20:44,746 DEBUG TRAIN Batch 52/1800 loss 6.536775 loss_att 7.262985 loss_ctc 8.304262 loss_rnnt 5.995519 hw_loss 0.300654 lr 0.00029030 rank 3
2023-03-01 08:21:23,670 DEBUG TRAIN Batch 52/1900 loss 6.338144 loss_att 7.363589 loss_ctc 9.728495 loss_rnnt 5.512314 hw_loss 0.316301 lr 0.00029029 rank 3
2023-03-01 08:21:23,672 DEBUG TRAIN Batch 52/1900 loss 6.510257 loss_att 9.834348 loss_ctc 11.442794 loss_rnnt 5.106353 hw_loss 0.152653 lr 0.00029030 rank 1
2023-03-01 08:21:23,672 DEBUG TRAIN Batch 52/1900 loss 1.959455 loss_att 4.858777 loss_ctc 5.449662 loss_rnnt 0.825696 hw_loss 0.166001 lr 0.00029030 rank 6
2023-03-01 08:21:23,676 DEBUG TRAIN Batch 52/1900 loss 2.639897 loss_att 6.078057 loss_ctc 2.949632 loss_rnnt 1.826665 hw_loss 0.158066 lr 0.00029029 rank 5
2023-03-01 08:21:23,686 DEBUG TRAIN Batch 52/1900 loss 2.532791 loss_att 3.818447 loss_ctc 2.868965 loss_rnnt 2.082850 hw_loss 0.277475 lr 0.00029030 rank 0
2023-03-01 08:21:23,692 DEBUG TRAIN Batch 52/1900 loss 15.065260 loss_att 15.317714 loss_ctc 23.006449 loss_rnnt 13.809530 hw_loss 0.274528 lr 0.00029029 rank 7
2023-03-01 08:21:23,696 DEBUG TRAIN Batch 52/1900 loss 8.956054 loss_att 10.540236 loss_ctc 13.462491 loss_rnnt 7.835127 hw_loss 0.381059 lr 0.00029030 rank 2
2023-03-01 08:21:23,701 DEBUG TRAIN Batch 52/1900 loss 2.889899 loss_att 5.391317 loss_ctc 5.061260 loss_rnnt 2.060628 hw_loss 0.074011 lr 0.00029030 rank 4
2023-03-01 08:22:02,437 DEBUG TRAIN Batch 52/2000 loss 3.794153 loss_att 9.483986 loss_ctc 5.198758 loss_rnnt 2.351348 hw_loss 0.220422 lr 0.00029029 rank 2
2023-03-01 08:22:02,451 DEBUG TRAIN Batch 52/2000 loss 2.304228 loss_att 7.068714 loss_ctc 4.483913 loss_rnnt 0.986802 hw_loss 0.138570 lr 0.00029029 rank 0
2023-03-01 08:22:02,451 DEBUG TRAIN Batch 52/2000 loss 2.156318 loss_att 6.045883 loss_ctc 3.871251 loss_rnnt 0.997662 hw_loss 0.285159 lr 0.00029028 rank 5
2023-03-01 08:22:02,452 DEBUG TRAIN Batch 52/2000 loss 2.920877 loss_att 5.430991 loss_ctc 3.889240 loss_rnnt 2.192604 hw_loss 0.182130 lr 0.00029028 rank 7
2023-03-01 08:22:02,453 DEBUG TRAIN Batch 52/2000 loss 9.967111 loss_att 17.337490 loss_ctc 22.134792 loss_rnnt 6.711594 hw_loss 0.298284 lr 0.00029028 rank 6
2023-03-01 08:22:02,453 DEBUG TRAIN Batch 52/2000 loss 4.167042 loss_att 9.690630 loss_ctc 9.834853 loss_rnnt 2.239367 hw_loss 0.126091 lr 0.00029029 rank 1
2023-03-01 08:22:02,453 DEBUG TRAIN Batch 52/2000 loss 1.810693 loss_att 4.478012 loss_ctc 3.212718 loss_rnnt 0.883622 hw_loss 0.387507 lr 0.00029029 rank 4
2023-03-01 08:22:02,456 DEBUG TRAIN Batch 52/2000 loss 3.971818 loss_att 6.849827 loss_ctc 5.905559 loss_rnnt 3.022578 hw_loss 0.217137 lr 0.00029028 rank 3
2023-03-01 08:22:42,146 DEBUG TRAIN Batch 52/2100 loss 12.625916 loss_att 15.179627 loss_ctc 15.173244 loss_rnnt 11.660220 hw_loss 0.216207 lr 0.00029028 rank 2
2023-03-01 08:22:42,147 DEBUG TRAIN Batch 52/2100 loss 8.950772 loss_att 13.628342 loss_ctc 13.591965 loss_rnnt 7.292458 hw_loss 0.194952 lr 0.00029028 rank 0
2023-03-01 08:22:42,149 DEBUG TRAIN Batch 52/2100 loss 7.471528 loss_att 10.532183 loss_ctc 14.228290 loss_rnnt 5.829895 hw_loss 0.241125 lr 0.00029027 rank 5
2023-03-01 08:22:42,152 DEBUG TRAIN Batch 52/2100 loss 1.126505 loss_att 2.766899 loss_ctc 2.613491 loss_rnnt 0.451960 hw_loss 0.277877 lr 0.00029027 rank 3
2023-03-01 08:22:42,153 DEBUG TRAIN Batch 52/2100 loss 4.168814 loss_att 6.910879 loss_ctc 9.084461 loss_rnnt 2.796966 hw_loss 0.315029 lr 0.00029027 rank 6
2023-03-01 08:22:42,161 DEBUG TRAIN Batch 52/2100 loss 6.782303 loss_att 9.602139 loss_ctc 12.587412 loss_rnnt 5.329360 hw_loss 0.215550 lr 0.00029026 rank 7
2023-03-01 08:22:42,170 DEBUG TRAIN Batch 52/2100 loss 1.734284 loss_att 3.908366 loss_ctc 3.041810 loss_rnnt 1.081867 hw_loss 0.081121 lr 0.00029027 rank 1
2023-03-01 08:22:42,193 DEBUG TRAIN Batch 52/2100 loss 1.696691 loss_att 4.490442 loss_ctc 3.201539 loss_rnnt 0.802193 hw_loss 0.253315 lr 0.00029028 rank 4
2023-03-01 08:23:46,728 DEBUG TRAIN Batch 52/2200 loss 2.450889 loss_att 5.563153 loss_ctc 3.110148 loss_rnnt 1.620489 hw_loss 0.225084 lr 0.00029027 rank 2
2023-03-01 08:23:46,738 DEBUG TRAIN Batch 52/2200 loss 1.484972 loss_att 4.320558 loss_ctc 2.924269 loss_rnnt 0.611207 hw_loss 0.215140 lr 0.00029026 rank 1
2023-03-01 08:23:46,742 DEBUG TRAIN Batch 52/2200 loss 2.289675 loss_att 5.434481 loss_ctc 5.646885 loss_rnnt 1.158430 hw_loss 0.102480 lr 0.00029027 rank 0
2023-03-01 08:23:46,742 DEBUG TRAIN Batch 52/2200 loss 3.239384 loss_att 5.343334 loss_ctc 4.810894 loss_rnnt 2.515821 hw_loss 0.174823 lr 0.00029026 rank 4
2023-03-01 08:23:46,744 DEBUG TRAIN Batch 52/2200 loss 5.101552 loss_att 7.783230 loss_ctc 9.156606 loss_rnnt 4.001455 hw_loss 0.043290 lr 0.00029025 rank 7
2023-03-01 08:23:46,752 DEBUG TRAIN Batch 52/2200 loss 3.458082 loss_att 6.388557 loss_ctc 7.845222 loss_rnnt 2.262876 hw_loss 0.045298 lr 0.00029026 rank 6
2023-03-01 08:23:46,751 DEBUG TRAIN Batch 52/2200 loss 3.764792 loss_att 5.802312 loss_ctc 6.898817 loss_rnnt 2.858407 hw_loss 0.151895 lr 0.00029025 rank 3
2023-03-01 08:23:46,752 DEBUG TRAIN Batch 52/2200 loss 3.262893 loss_att 6.729852 loss_ctc 5.660064 loss_rnnt 2.153572 hw_loss 0.180574 lr 0.00029026 rank 5
2023-03-01 08:24:24,906 DEBUG TRAIN Batch 52/2300 loss 6.164913 loss_att 11.379666 loss_ctc 13.332365 loss_rnnt 4.009190 hw_loss 0.294585 lr 0.00029025 rank 1
2023-03-01 08:24:24,912 DEBUG TRAIN Batch 52/2300 loss 5.564249 loss_att 7.965103 loss_ctc 6.827490 loss_rnnt 4.822078 hw_loss 0.175439 lr 0.00029025 rank 2
2023-03-01 08:24:24,915 DEBUG TRAIN Batch 52/2300 loss 3.765416 loss_att 5.521058 loss_ctc 4.952873 loss_rnnt 3.111143 hw_loss 0.271533 lr 0.00029024 rank 3
2023-03-01 08:24:24,919 DEBUG TRAIN Batch 52/2300 loss 4.683870 loss_att 8.161331 loss_ctc 8.275240 loss_rnnt 3.337322 hw_loss 0.322887 lr 0.00029025 rank 0
2023-03-01 08:24:24,922 DEBUG TRAIN Batch 52/2300 loss 4.469123 loss_att 7.005708 loss_ctc 10.679063 loss_rnnt 2.957603 hw_loss 0.330396 lr 0.00029024 rank 7
2023-03-01 08:24:24,928 DEBUG TRAIN Batch 52/2300 loss 9.110058 loss_att 11.249620 loss_ctc 10.109526 loss_rnnt 8.435036 hw_loss 0.213462 lr 0.00029025 rank 6
2023-03-01 08:24:24,929 DEBUG TRAIN Batch 52/2300 loss 4.047265 loss_att 7.774888 loss_ctc 9.307196 loss_rnnt 2.466474 hw_loss 0.251143 lr 0.00029025 rank 4
2023-03-01 08:24:24,952 DEBUG TRAIN Batch 52/2300 loss 7.207183 loss_att 10.274042 loss_ctc 8.976226 loss_rnnt 6.271767 hw_loss 0.161574 lr 0.00029024 rank 5
2023-03-01 08:25:03,851 DEBUG TRAIN Batch 52/2400 loss 4.083565 loss_att 7.722755 loss_ctc 6.337756 loss_rnnt 2.944201 hw_loss 0.208062 lr 0.00029024 rank 2
2023-03-01 08:25:03,855 DEBUG TRAIN Batch 52/2400 loss 7.163641 loss_att 10.297996 loss_ctc 12.499250 loss_rnnt 5.689474 hw_loss 0.254778 lr 0.00029023 rank 3
2023-03-01 08:25:03,864 DEBUG TRAIN Batch 52/2400 loss 2.848716 loss_att 4.499164 loss_ctc 5.335899 loss_rnnt 2.051593 hw_loss 0.253893 lr 0.00029024 rank 4
2023-03-01 08:25:03,864 DEBUG TRAIN Batch 52/2400 loss 6.529574 loss_att 9.375919 loss_ctc 9.992902 loss_rnnt 5.498372 hw_loss 0.000294 lr 0.00029024 rank 0
2023-03-01 08:25:03,865 DEBUG TRAIN Batch 52/2400 loss 4.107759 loss_att 5.833337 loss_ctc 6.356724 loss_rnnt 3.297928 hw_loss 0.309099 lr 0.00029023 rank 5
2023-03-01 08:25:03,867 DEBUG TRAIN Batch 52/2400 loss 8.661752 loss_att 11.609051 loss_ctc 14.402667 loss_rnnt 7.198443 hw_loss 0.203238 lr 0.00029024 rank 1
2023-03-01 08:25:03,874 DEBUG TRAIN Batch 52/2400 loss 7.465139 loss_att 12.372400 loss_ctc 10.571324 loss_rnnt 5.998887 hw_loss 0.132455 lr 0.00029023 rank 7
2023-03-01 08:25:03,884 DEBUG TRAIN Batch 52/2400 loss 10.156570 loss_att 11.943926 loss_ctc 16.745913 loss_rnnt 8.847797 hw_loss 0.136356 lr 0.00029024 rank 6
2023-03-01 08:26:10,718 DEBUG TRAIN Batch 52/2500 loss 3.079174 loss_att 4.913693 loss_ctc 3.318778 loss_rnnt 2.595782 hw_loss 0.158514 lr 0.00029023 rank 0
2023-03-01 08:26:10,723 DEBUG TRAIN Batch 52/2500 loss 6.637536 loss_att 10.844781 loss_ctc 15.461278 loss_rnnt 4.500561 hw_loss 0.223174 lr 0.00029022 rank 7
2023-03-01 08:26:10,723 DEBUG TRAIN Batch 52/2500 loss 6.980988 loss_att 10.125778 loss_ctc 12.499094 loss_rnnt 5.506148 hw_loss 0.206502 lr 0.00029022 rank 5
2023-03-01 08:26:10,723 DEBUG TRAIN Batch 52/2500 loss 6.382322 loss_att 8.809209 loss_ctc 10.559471 loss_rnnt 5.225705 hw_loss 0.214287 lr 0.00029023 rank 2
2023-03-01 08:26:10,729 DEBUG TRAIN Batch 52/2500 loss 3.492445 loss_att 6.371037 loss_ctc 8.704045 loss_rnnt 1.999710 hw_loss 0.416506 lr 0.00029022 rank 3
2023-03-01 08:26:10,744 DEBUG TRAIN Batch 52/2500 loss 7.800191 loss_att 9.023322 loss_ctc 11.723805 loss_rnnt 6.914116 hw_loss 0.221812 lr 0.00029022 rank 6
2023-03-01 08:26:10,760 DEBUG TRAIN Batch 52/2500 loss 6.976387 loss_att 7.486273 loss_ctc 12.012799 loss_rnnt 6.036273 hw_loss 0.312401 lr 0.00029023 rank 1
2023-03-01 08:26:10,761 DEBUG TRAIN Batch 52/2500 loss 2.813666 loss_att 6.399746 loss_ctc 5.496507 loss_rnnt 1.651840 hw_loss 0.162932 lr 0.00029023 rank 4
2023-03-01 08:26:48,860 DEBUG TRAIN Batch 52/2600 loss 9.172231 loss_att 12.444004 loss_ctc 18.705730 loss_rnnt 7.128111 hw_loss 0.222435 lr 0.00029022 rank 0
2023-03-01 08:26:48,870 DEBUG TRAIN Batch 52/2600 loss 10.601124 loss_att 15.939218 loss_ctc 19.706062 loss_rnnt 8.248402 hw_loss 0.133336 lr 0.00029021 rank 3
2023-03-01 08:26:48,883 DEBUG TRAIN Batch 52/2600 loss 7.551501 loss_att 14.225304 loss_ctc 12.649273 loss_rnnt 5.464366 hw_loss 0.136257 lr 0.00029020 rank 7
2023-03-01 08:26:48,889 DEBUG TRAIN Batch 52/2600 loss 8.810086 loss_att 10.750512 loss_ctc 14.593042 loss_rnnt 7.544360 hw_loss 0.199837 lr 0.00029021 rank 5
2023-03-01 08:26:48,890 DEBUG TRAIN Batch 52/2600 loss 5.448718 loss_att 7.918645 loss_ctc 6.097695 loss_rnnt 4.743293 hw_loss 0.234206 lr 0.00029022 rank 4
2023-03-01 08:26:48,892 DEBUG TRAIN Batch 52/2600 loss 3.957037 loss_att 7.404258 loss_ctc 12.091875 loss_rnnt 2.022196 hw_loss 0.301408 lr 0.00029021 rank 6
2023-03-01 08:26:48,891 DEBUG TRAIN Batch 52/2600 loss 8.515544 loss_att 10.177170 loss_ctc 11.400943 loss_rnnt 7.680066 hw_loss 0.222060 lr 0.00029022 rank 2
2023-03-01 08:26:48,892 DEBUG TRAIN Batch 52/2600 loss 5.930073 loss_att 9.504037 loss_ctc 11.410135 loss_rnnt 4.378606 hw_loss 0.198748 lr 0.00029021 rank 1
2023-03-01 08:27:27,453 DEBUG TRAIN Batch 52/2700 loss 1.840177 loss_att 5.465852 loss_ctc 3.603790 loss_rnnt 0.693534 hw_loss 0.349425 lr 0.00029020 rank 1
2023-03-01 08:27:27,465 DEBUG TRAIN Batch 52/2700 loss 2.437339 loss_att 6.538191 loss_ctc 4.404769 loss_rnnt 1.267737 hw_loss 0.163326 lr 0.00029020 rank 6
2023-03-01 08:27:27,464 DEBUG TRAIN Batch 52/2700 loss 4.464500 loss_att 8.142183 loss_ctc 5.911618 loss_rnnt 3.480632 hw_loss 0.103844 lr 0.00029020 rank 4
2023-03-01 08:27:27,467 DEBUG TRAIN Batch 52/2700 loss 3.528697 loss_att 9.098396 loss_ctc 8.952948 loss_rnnt 1.623261 hw_loss 0.127992 lr 0.00029020 rank 2
2023-03-01 08:27:27,468 DEBUG TRAIN Batch 52/2700 loss 3.298927 loss_att 4.496298 loss_ctc 4.907568 loss_rnnt 2.658869 hw_loss 0.348934 lr 0.00029020 rank 0
2023-03-01 08:27:27,469 DEBUG TRAIN Batch 52/2700 loss 8.509647 loss_att 10.749553 loss_ctc 10.618731 loss_rnnt 7.679218 hw_loss 0.189819 lr 0.00029019 rank 7
2023-03-01 08:27:27,469 DEBUG TRAIN Batch 52/2700 loss 7.396114 loss_att 10.876715 loss_ctc 14.078753 loss_rnnt 5.709466 hw_loss 0.186579 lr 0.00029019 rank 3
2023-03-01 08:27:27,517 DEBUG TRAIN Batch 52/2700 loss 3.063763 loss_att 5.533463 loss_ctc 8.737172 loss_rnnt 1.643139 hw_loss 0.319180 lr 0.00029020 rank 5
2023-03-01 08:28:07,072 DEBUG TRAIN Batch 52/2800 loss 7.437226 loss_att 11.383762 loss_ctc 11.549922 loss_rnnt 5.955005 hw_loss 0.271039 lr 0.00029019 rank 2
2023-03-01 08:28:07,080 DEBUG TRAIN Batch 52/2800 loss 4.044891 loss_att 6.709097 loss_ctc 9.970745 loss_rnnt 2.624644 hw_loss 0.182421 lr 0.00029019 rank 1
2023-03-01 08:28:07,082 DEBUG TRAIN Batch 52/2800 loss 1.429279 loss_att 4.574530 loss_ctc 3.187774 loss_rnnt 0.452097 hw_loss 0.213123 lr 0.00029019 rank 6
2023-03-01 08:28:07,082 DEBUG TRAIN Batch 52/2800 loss 8.934509 loss_att 11.833126 loss_ctc 13.984474 loss_rnnt 7.586329 hw_loss 0.178366 lr 0.00029019 rank 0
2023-03-01 08:28:07,083 DEBUG TRAIN Batch 52/2800 loss 5.074353 loss_att 7.678006 loss_ctc 9.916635 loss_rnnt 3.810168 hw_loss 0.183408 lr 0.00029018 rank 3
2023-03-01 08:28:07,085 DEBUG TRAIN Batch 52/2800 loss 8.163934 loss_att 10.071206 loss_ctc 12.074918 loss_rnnt 7.208068 hw_loss 0.099276 lr 0.00029019 rank 4
2023-03-01 08:28:07,085 DEBUG TRAIN Batch 52/2800 loss 3.094794 loss_att 7.066512 loss_ctc 5.884315 loss_rnnt 1.878385 hw_loss 0.093993 lr 0.00029018 rank 7
2023-03-01 08:28:07,129 DEBUG TRAIN Batch 52/2800 loss 4.982449 loss_att 6.312066 loss_ctc 11.500319 loss_rnnt 3.760246 hw_loss 0.163556 lr 0.00029018 rank 5
2023-03-01 08:29:13,164 DEBUG TRAIN Batch 52/2900 loss 4.440886 loss_att 10.236021 loss_ctc 9.089685 loss_rnnt 2.517905 hw_loss 0.270214 lr 0.00029017 rank 7
2023-03-01 08:29:13,164 DEBUG TRAIN Batch 52/2900 loss 13.202982 loss_att 16.298824 loss_ctc 23.718235 loss_rnnt 11.030354 hw_loss 0.283924 lr 0.00029018 rank 1
2023-03-01 08:29:13,166 DEBUG TRAIN Batch 52/2900 loss 3.420427 loss_att 6.130910 loss_ctc 7.774917 loss_rnnt 2.202120 hw_loss 0.179272 lr 0.00029017 rank 5
2023-03-01 08:29:13,168 DEBUG TRAIN Batch 52/2900 loss 8.427370 loss_att 10.328426 loss_ctc 12.847799 loss_rnnt 7.328854 hw_loss 0.241714 lr 0.00029018 rank 2
2023-03-01 08:29:13,168 DEBUG TRAIN Batch 52/2900 loss 3.407133 loss_att 6.507552 loss_ctc 5.044445 loss_rnnt 2.440587 hw_loss 0.240287 lr 0.00029018 rank 0
2023-03-01 08:29:13,171 DEBUG TRAIN Batch 52/2900 loss 4.991905 loss_att 7.843662 loss_ctc 9.460512 loss_rnnt 3.708683 hw_loss 0.219478 lr 0.00029017 rank 3
2023-03-01 08:29:13,174 DEBUG TRAIN Batch 52/2900 loss 4.900402 loss_att 8.109276 loss_ctc 6.976627 loss_rnnt 3.832246 hw_loss 0.280407 lr 0.00029018 rank 4
2023-03-01 08:29:13,180 DEBUG TRAIN Batch 52/2900 loss 9.871585 loss_att 12.926819 loss_ctc 12.344427 loss_rnnt 8.798012 hw_loss 0.249026 lr 0.00029017 rank 6
2023-03-01 08:29:52,191 DEBUG TRAIN Batch 52/3000 loss 9.508960 loss_att 11.528357 loss_ctc 16.987495 loss_rnnt 8.022570 hw_loss 0.160075 lr 0.00029015 rank 7
2023-03-01 08:29:52,202 DEBUG TRAIN Batch 52/3000 loss 4.421252 loss_att 7.906171 loss_ctc 7.281952 loss_rnnt 3.210544 hw_loss 0.248058 lr 0.00029017 rank 2
2023-03-01 08:29:52,207 DEBUG TRAIN Batch 52/3000 loss 7.598389 loss_att 9.159678 loss_ctc 9.711287 loss_rnnt 6.829013 hw_loss 0.328872 lr 0.00029017 rank 0
2023-03-01 08:29:52,211 DEBUG TRAIN Batch 52/3000 loss 4.373780 loss_att 7.486963 loss_ctc 8.579973 loss_rnnt 3.055607 hw_loss 0.252581 lr 0.00029016 rank 1
2023-03-01 08:29:52,219 DEBUG TRAIN Batch 52/3000 loss 6.262913 loss_att 9.026392 loss_ctc 13.927252 loss_rnnt 4.596374 hw_loss 0.172372 lr 0.00029016 rank 5
2023-03-01 08:29:52,219 DEBUG TRAIN Batch 52/3000 loss 6.262704 loss_att 7.405464 loss_ctc 12.756724 loss_rnnt 5.058454 hw_loss 0.205930 lr 0.00029016 rank 3
2023-03-01 08:29:52,221 DEBUG TRAIN Batch 52/3000 loss 5.382946 loss_att 7.592527 loss_ctc 12.606511 loss_rnnt 3.851316 hw_loss 0.237323 lr 0.00029017 rank 4
2023-03-01 08:29:52,245 DEBUG TRAIN Batch 52/3000 loss 6.650782 loss_att 9.924032 loss_ctc 13.345194 loss_rnnt 4.926048 hw_loss 0.332805 lr 0.00029016 rank 6
2023-03-01 08:30:31,146 DEBUG TRAIN Batch 52/3100 loss 7.668890 loss_att 7.520817 loss_ctc 6.970716 loss_rnnt 7.649713 hw_loss 0.266027 lr 0.00029015 rank 5
2023-03-01 08:30:31,146 DEBUG TRAIN Batch 52/3100 loss 4.625106 loss_att 7.824272 loss_ctc 8.048706 loss_rnnt 3.395558 hw_loss 0.249815 lr 0.00029014 rank 7
2023-03-01 08:30:31,147 DEBUG TRAIN Batch 52/3100 loss 8.945351 loss_att 9.520409 loss_ctc 13.464695 loss_rnnt 8.053343 hw_loss 0.327032 lr 0.00029015 rank 4
2023-03-01 08:30:31,148 DEBUG TRAIN Batch 52/3100 loss 8.518409 loss_att 11.277856 loss_ctc 13.482767 loss_rnnt 7.169194 hw_loss 0.253896 lr 0.00029016 rank 2
2023-03-01 08:30:31,149 DEBUG TRAIN Batch 52/3100 loss 6.173917 loss_att 7.726960 loss_ctc 10.269985 loss_rnnt 5.183712 hw_loss 0.250227 lr 0.00029016 rank 0
2023-03-01 08:30:31,151 DEBUG TRAIN Batch 52/3100 loss 6.543576 loss_att 9.453842 loss_ctc 10.623154 loss_rnnt 5.309056 hw_loss 0.203480 lr 0.00029015 rank 6
2023-03-01 08:30:31,175 DEBUG TRAIN Batch 52/3100 loss 6.475725 loss_att 8.649617 loss_ctc 10.729972 loss_rnnt 5.343694 hw_loss 0.243787 lr 0.00029014 rank 3
2023-03-01 08:30:31,212 DEBUG TRAIN Batch 52/3100 loss 9.931289 loss_att 10.978896 loss_ctc 13.227660 loss_rnnt 9.145438 hw_loss 0.256524 lr 0.00029015 rank 1
2023-03-01 08:31:36,908 DEBUG TRAIN Batch 52/3200 loss 3.273455 loss_att 6.405183 loss_ctc 4.340489 loss_rnnt 2.401349 hw_loss 0.194042 lr 0.00029014 rank 2
2023-03-01 08:31:36,914 DEBUG TRAIN Batch 52/3200 loss 6.132474 loss_att 7.669550 loss_ctc 11.388890 loss_rnnt 4.998411 hw_loss 0.235862 lr 0.00029013 rank 7
2023-03-01 08:31:36,916 DEBUG TRAIN Batch 52/3200 loss 6.967640 loss_att 11.230522 loss_ctc 10.887404 loss_rnnt 5.489957 hw_loss 0.192135 lr 0.00029014 rank 1
2023-03-01 08:31:36,916 DEBUG TRAIN Batch 52/3200 loss 4.688582 loss_att 6.573190 loss_ctc 6.847828 loss_rnnt 3.919291 hw_loss 0.195881 lr 0.00029013 rank 5
2023-03-01 08:31:36,925 DEBUG TRAIN Batch 52/3200 loss 3.240608 loss_att 6.051057 loss_ctc 8.384653 loss_rnnt 1.842046 hw_loss 0.282374 lr 0.00029014 rank 6
2023-03-01 08:31:36,926 DEBUG TRAIN Batch 52/3200 loss 5.252679 loss_att 7.751555 loss_ctc 9.126097 loss_rnnt 4.170718 hw_loss 0.123243 lr 0.00029014 rank 0
2023-03-01 08:31:36,965 DEBUG TRAIN Batch 52/3200 loss 1.841919 loss_att 4.812000 loss_ctc 4.043401 loss_rnnt 0.782185 hw_loss 0.322850 lr 0.00029014 rank 4
2023-03-01 08:31:36,969 DEBUG TRAIN Batch 52/3200 loss 5.517967 loss_att 8.850398 loss_ctc 9.038713 loss_rnnt 4.209197 hw_loss 0.324097 lr 0.00029013 rank 3
2023-03-01 08:32:15,994 DEBUG TRAIN Batch 52/3300 loss 4.062118 loss_att 8.252116 loss_ctc 12.188910 loss_rnnt 1.974456 hw_loss 0.311420 lr 0.00029012 rank 5
2023-03-01 08:32:16,007 DEBUG TRAIN Batch 52/3300 loss 5.264218 loss_att 8.258123 loss_ctc 8.647552 loss_rnnt 4.123377 hw_loss 0.170529 lr 0.00029013 rank 0
2023-03-01 08:32:16,010 DEBUG TRAIN Batch 52/3300 loss 5.138561 loss_att 8.022358 loss_ctc 10.488995 loss_rnnt 3.767295 hw_loss 0.152091 lr 0.00029013 rank 6
2023-03-01 08:32:16,009 DEBUG TRAIN Batch 52/3300 loss 7.875350 loss_att 9.460604 loss_ctc 12.669762 loss_rnnt 6.760610 hw_loss 0.297065 lr 0.00029013 rank 4
2023-03-01 08:32:16,010 DEBUG TRAIN Batch 52/3300 loss 4.912705 loss_att 10.282525 loss_ctc 5.040784 loss_rnnt 3.709492 hw_loss 0.210321 lr 0.00029012 rank 3
2023-03-01 08:32:16,011 DEBUG TRAIN Batch 52/3300 loss 4.894016 loss_att 7.883668 loss_ctc 9.135605 loss_rnnt 3.642289 hw_loss 0.165472 lr 0.00029012 rank 7
2023-03-01 08:32:16,011 DEBUG TRAIN Batch 52/3300 loss 2.040557 loss_att 5.647570 loss_ctc 4.245321 loss_rnnt 0.888677 hw_loss 0.255955 lr 0.00029013 rank 2
2023-03-01 08:32:16,012 DEBUG TRAIN Batch 52/3300 loss 6.619892 loss_att 11.081433 loss_ctc 14.991980 loss_rnnt 4.529140 hw_loss 0.154060 lr 0.00029013 rank 1
2023-03-01 08:32:54,767 DEBUG TRAIN Batch 52/3400 loss 5.421897 loss_att 8.430363 loss_ctc 9.196642 loss_rnnt 4.207509 hw_loss 0.205116 lr 0.00029012 rank 2
2023-03-01 08:32:54,767 DEBUG TRAIN Batch 52/3400 loss 8.021270 loss_att 10.361514 loss_ctc 10.264462 loss_rnnt 7.137126 hw_loss 0.219380 lr 0.00029011 rank 5
2023-03-01 08:32:54,785 DEBUG TRAIN Batch 52/3400 loss 2.150090 loss_att 4.619241 loss_ctc 2.780200 loss_rnnt 1.539463 hw_loss 0.061468 lr 0.00029012 rank 0
2023-03-01 08:32:54,785 DEBUG TRAIN Batch 52/3400 loss 12.802055 loss_att 16.924995 loss_ctc 12.146776 loss_rnnt 11.968070 hw_loss 0.181440 lr 0.00029011 rank 6
2023-03-01 08:32:54,785 DEBUG TRAIN Batch 52/3400 loss 6.971691 loss_att 10.162243 loss_ctc 7.855231 loss_rnnt 6.101753 hw_loss 0.213791 lr 0.00029011 rank 7
2023-03-01 08:32:54,786 DEBUG TRAIN Batch 52/3400 loss 1.204824 loss_att 4.061763 loss_ctc 1.925613 loss_rnnt 0.454099 hw_loss 0.156060 lr 0.00029011 rank 3
2023-03-01 08:32:54,825 DEBUG TRAIN Batch 52/3400 loss 4.586186 loss_att 7.010277 loss_ctc 8.157127 loss_rnnt 3.573466 hw_loss 0.097080 lr 0.00029012 rank 4
2023-03-01 08:32:54,830 DEBUG TRAIN Batch 52/3400 loss 6.290874 loss_att 9.406740 loss_ctc 11.208216 loss_rnnt 4.892416 hw_loss 0.224322 lr 0.00029012 rank 1
2023-03-01 08:33:33,119 DEBUG TRAIN Batch 52/3500 loss 2.325332 loss_att 4.423187 loss_ctc 3.221014 loss_rnnt 1.693410 hw_loss 0.174237 lr 0.00029011 rank 4
2023-03-01 08:33:33,121 DEBUG TRAIN Batch 52/3500 loss 5.362414 loss_att 8.033514 loss_ctc 8.972858 loss_rnnt 4.210717 hw_loss 0.255158 lr 0.00029011 rank 2
2023-03-01 08:33:33,130 DEBUG TRAIN Batch 52/3500 loss 4.984174 loss_att 8.838690 loss_ctc 9.158596 loss_rnnt 3.590318 hw_loss 0.124432 lr 0.00029010 rank 5
2023-03-01 08:33:33,131 DEBUG TRAIN Batch 52/3500 loss 4.037912 loss_att 6.902468 loss_ctc 7.374219 loss_rnnt 2.878377 hw_loss 0.265844 lr 0.00029010 rank 6
2023-03-01 08:33:33,134 DEBUG TRAIN Batch 52/3500 loss 11.447606 loss_att 14.878103 loss_ctc 16.172081 loss_rnnt 10.035925 hw_loss 0.179347 lr 0.00029009 rank 7
2023-03-01 08:33:33,135 DEBUG TRAIN Batch 52/3500 loss 8.449937 loss_att 10.421442 loss_ctc 11.469627 loss_rnnt 7.537119 hw_loss 0.217295 lr 0.00029010 rank 3
2023-03-01 08:33:33,135 DEBUG TRAIN Batch 52/3500 loss 2.109162 loss_att 5.453801 loss_ctc 1.858745 loss_rnnt 1.385181 hw_loss 0.165830 lr 0.00029011 rank 0
2023-03-01 08:33:33,151 DEBUG TRAIN Batch 52/3500 loss 10.518940 loss_att 11.077727 loss_ctc 11.600559 loss_rnnt 10.095449 hw_loss 0.314095 lr 0.00029010 rank 1
2023-03-01 08:34:38,779 DEBUG TRAIN Batch 52/3600 loss 7.610768 loss_att 13.160149 loss_ctc 11.280985 loss_rnnt 5.960361 hw_loss 0.095942 lr 0.00029009 rank 0
2023-03-01 08:34:38,780 DEBUG TRAIN Batch 52/3600 loss 9.046000 loss_att 14.924931 loss_ctc 14.176528 loss_rnnt 7.142927 hw_loss 0.081028 lr 0.00029009 rank 1
2023-03-01 08:34:38,782 DEBUG TRAIN Batch 52/3600 loss 4.829510 loss_att 6.977202 loss_ctc 6.540193 loss_rnnt 4.063231 hw_loss 0.203716 lr 0.00029008 rank 7
2023-03-01 08:34:38,781 DEBUG TRAIN Batch 52/3600 loss 7.170328 loss_att 11.502468 loss_ctc 9.447427 loss_rnnt 5.907852 hw_loss 0.173314 lr 0.00029009 rank 5
2023-03-01 08:34:38,783 DEBUG TRAIN Batch 52/3600 loss 6.969871 loss_att 8.709492 loss_ctc 13.638414 loss_rnnt 5.575420 hw_loss 0.295102 lr 0.00029008 rank 3
2023-03-01 08:34:38,783 DEBUG TRAIN Batch 52/3600 loss 6.316822 loss_att 8.763210 loss_ctc 10.082530 loss_rnnt 5.179476 hw_loss 0.273699 lr 0.00029009 rank 6
2023-03-01 08:34:38,785 DEBUG TRAIN Batch 52/3600 loss 4.119520 loss_att 6.625351 loss_ctc 5.245073 loss_rnnt 3.402012 hw_loss 0.124253 lr 0.00029009 rank 4
2023-03-01 08:34:38,823 DEBUG TRAIN Batch 52/3600 loss 4.642938 loss_att 6.473236 loss_ctc 9.261591 loss_rnnt 3.540065 hw_loss 0.226862 lr 0.00029009 rank 2
2023-03-01 08:35:17,492 DEBUG TRAIN Batch 52/3700 loss 4.516404 loss_att 7.011733 loss_ctc 7.922905 loss_rnnt 3.465000 hw_loss 0.184009 lr 0.00029008 rank 0
2023-03-01 08:35:17,496 DEBUG TRAIN Batch 52/3700 loss 4.122274 loss_att 7.131828 loss_ctc 8.071370 loss_rnnt 2.877418 hw_loss 0.218248 lr 0.00029008 rank 2
2023-03-01 08:35:17,495 DEBUG TRAIN Batch 52/3700 loss 3.210353 loss_att 5.590107 loss_ctc 8.816130 loss_rnnt 1.889099 hw_loss 0.183500 lr 0.00029007 rank 5
2023-03-01 08:35:17,498 DEBUG TRAIN Batch 52/3700 loss 7.357379 loss_att 10.578150 loss_ctc 13.866713 loss_rnnt 5.711997 hw_loss 0.249971 lr 0.00029007 rank 7
2023-03-01 08:35:17,500 DEBUG TRAIN Batch 52/3700 loss 9.065165 loss_att 9.936770 loss_ctc 13.569704 loss_rnnt 8.192044 hw_loss 0.184114 lr 0.00029008 rank 6
2023-03-01 08:35:17,500 DEBUG TRAIN Batch 52/3700 loss 8.739198 loss_att 8.944718 loss_ctc 15.891489 loss_rnnt 7.595799 hw_loss 0.278729 lr 0.00029007 rank 3
2023-03-01 08:35:17,506 DEBUG TRAIN Batch 52/3700 loss 5.510699 loss_att 7.903964 loss_ctc 10.088939 loss_rnnt 4.252079 hw_loss 0.317877 lr 0.00029008 rank 1
2023-03-01 08:35:17,545 DEBUG TRAIN Batch 52/3700 loss 6.669548 loss_att 8.396618 loss_ctc 9.826999 loss_rnnt 5.805534 hw_loss 0.183012 lr 0.00029008 rank 4
2023-03-01 08:35:56,233 DEBUG TRAIN Batch 52/3800 loss 3.893997 loss_att 6.585714 loss_ctc 7.349988 loss_rnnt 2.813820 hw_loss 0.151940 lr 0.00029007 rank 2
2023-03-01 08:35:56,245 DEBUG TRAIN Batch 52/3800 loss 7.064076 loss_att 10.633705 loss_ctc 12.880424 loss_rnnt 5.335083 hw_loss 0.449163 lr 0.00029006 rank 7
2023-03-01 08:35:56,249 DEBUG TRAIN Batch 52/3800 loss 7.327532 loss_att 7.606117 loss_ctc 11.151026 loss_rnnt 6.591811 hw_loss 0.319133 lr 0.00029007 rank 0
2023-03-01 08:35:56,253 DEBUG TRAIN Batch 52/3800 loss 9.205674 loss_att 12.256631 loss_ctc 13.829773 loss_rnnt 7.867734 hw_loss 0.208503 lr 0.00029007 rank 4
2023-03-01 08:35:56,255 DEBUG TRAIN Batch 52/3800 loss 3.927522 loss_att 8.777118 loss_ctc 6.651435 loss_rnnt 2.507268 hw_loss 0.163402 lr 0.00029006 rank 6
2023-03-01 08:35:56,255 DEBUG TRAIN Batch 52/3800 loss 4.054022 loss_att 5.628259 loss_ctc 8.723492 loss_rnnt 2.980793 hw_loss 0.254598 lr 0.00029006 rank 3
2023-03-01 08:35:56,257 DEBUG TRAIN Batch 52/3800 loss 6.258519 loss_att 6.911461 loss_ctc 10.688502 loss_rnnt 5.346187 hw_loss 0.358274 lr 0.00029006 rank 5
2023-03-01 08:35:56,261 DEBUG TRAIN Batch 52/3800 loss 1.888510 loss_att 4.231353 loss_ctc 1.905009 loss_rnnt 1.349626 hw_loss 0.127718 lr 0.00029007 rank 1
2023-03-01 08:37:02,275 DEBUG TRAIN Batch 52/3900 loss 4.235794 loss_att 8.488491 loss_ctc 12.595340 loss_rnnt 2.169882 hw_loss 0.188938 lr 0.00029005 rank 1
2023-03-01 08:37:02,289 DEBUG TRAIN Batch 52/3900 loss 3.559585 loss_att 6.982083 loss_ctc 4.336723 loss_rnnt 2.695179 hw_loss 0.143042 lr 0.00029004 rank 7
2023-03-01 08:37:02,289 DEBUG TRAIN Batch 52/3900 loss 6.477305 loss_att 9.048619 loss_ctc 12.333757 loss_rnnt 5.016084 hw_loss 0.311433 lr 0.00029006 rank 2
2023-03-01 08:37:02,290 DEBUG TRAIN Batch 52/3900 loss 1.579654 loss_att 4.345903 loss_ctc 1.733812 loss_rnnt 0.869430 hw_loss 0.255787 lr 0.00029006 rank 0
2023-03-01 08:37:02,290 DEBUG TRAIN Batch 52/3900 loss 8.786687 loss_att 13.576612 loss_ctc 15.374488 loss_rnnt 6.860118 hw_loss 0.169143 lr 0.00029005 rank 5
2023-03-01 08:37:02,292 DEBUG TRAIN Batch 52/3900 loss 7.165787 loss_att 10.836098 loss_ctc 12.787005 loss_rnnt 5.626740 hw_loss 0.104042 lr 0.00029006 rank 4
2023-03-01 08:37:02,314 DEBUG TRAIN Batch 52/3900 loss 9.008892 loss_att 15.484140 loss_ctc 27.968832 loss_rnnt 5.139991 hw_loss 0.085985 lr 0.00029005 rank 6
2023-03-01 08:37:02,320 DEBUG TRAIN Batch 52/3900 loss 9.701528 loss_att 13.047983 loss_ctc 17.675379 loss_rnnt 7.914299 hw_loss 0.102671 lr 0.00029005 rank 3
2023-03-01 08:37:41,102 DEBUG TRAIN Batch 52/4000 loss 2.240070 loss_att 4.884364 loss_ctc 3.786416 loss_rnnt 1.436175 hw_loss 0.129107 lr 0.00029003 rank 7
2023-03-01 08:37:41,103 DEBUG TRAIN Batch 52/4000 loss 3.530130 loss_att 4.299159 loss_ctc 6.188679 loss_rnnt 2.882593 hw_loss 0.261110 lr 0.00029004 rank 4
2023-03-01 08:37:41,106 DEBUG TRAIN Batch 52/4000 loss 5.420394 loss_att 8.837443 loss_ctc 11.541021 loss_rnnt 3.814269 hw_loss 0.199934 lr 0.00029005 rank 0
2023-03-01 08:37:41,109 DEBUG TRAIN Batch 52/4000 loss 11.179433 loss_att 16.410847 loss_ctc 20.024616 loss_rnnt 8.887740 hw_loss 0.123849 lr 0.00029003 rank 3
2023-03-01 08:37:41,109 DEBUG TRAIN Batch 52/4000 loss 0.946867 loss_att 3.199040 loss_ctc 2.291647 loss_rnnt 0.233592 hw_loss 0.156631 lr 0.00029004 rank 6
2023-03-01 08:37:41,119 DEBUG TRAIN Batch 52/4000 loss 1.015603 loss_att 2.811915 loss_ctc 2.148892 loss_rnnt 0.315653 hw_loss 0.355467 lr 0.00029004 rank 1
2023-03-01 08:37:41,141 DEBUG TRAIN Batch 52/4000 loss 6.215239 loss_att 10.900723 loss_ctc 14.364593 loss_rnnt 4.066098 hw_loss 0.235244 lr 0.00029005 rank 2
2023-03-01 08:37:41,152 DEBUG TRAIN Batch 52/4000 loss 11.907038 loss_att 14.498428 loss_ctc 21.052139 loss_rnnt 10.016031 hw_loss 0.287590 lr 0.00029004 rank 5
2023-03-01 08:38:19,822 DEBUG TRAIN Batch 52/4100 loss 3.816838 loss_att 6.064849 loss_ctc 4.914974 loss_rnnt 3.102587 hw_loss 0.221682 lr 0.00029003 rank 4
2023-03-01 08:38:19,826 DEBUG TRAIN Batch 52/4100 loss 3.270280 loss_att 4.885385 loss_ctc 6.882792 loss_rnnt 2.324657 hw_loss 0.264250 lr 0.00029002 rank 7
2023-03-01 08:38:19,826 DEBUG TRAIN Batch 52/4100 loss 5.505975 loss_att 8.190826 loss_ctc 7.449302 loss_rnnt 4.569548 hw_loss 0.263149 lr 0.00029002 rank 5
2023-03-01 08:38:19,827 DEBUG TRAIN Batch 52/4100 loss 5.145762 loss_att 8.491643 loss_ctc 7.536451 loss_rnnt 4.091966 hw_loss 0.123491 lr 0.00029002 rank 3
2023-03-01 08:38:19,831 DEBUG TRAIN Batch 52/4100 loss 2.028601 loss_att 5.017368 loss_ctc 2.531199 loss_rnnt 1.172523 hw_loss 0.358708 lr 0.00029003 rank 0
2023-03-01 08:38:19,833 DEBUG TRAIN Batch 52/4100 loss 4.899852 loss_att 7.108909 loss_ctc 10.389877 loss_rnnt 3.554462 hw_loss 0.321704 lr 0.00029003 rank 6
2023-03-01 08:38:19,856 DEBUG TRAIN Batch 52/4100 loss 1.943548 loss_att 4.374315 loss_ctc 2.109604 loss_rnnt 1.323327 hw_loss 0.209862 lr 0.00029003 rank 2
2023-03-01 08:38:19,871 DEBUG TRAIN Batch 52/4100 loss 4.316139 loss_att 7.321867 loss_ctc 9.113181 loss_rnnt 2.994119 hw_loss 0.152378 lr 0.00029003 rank 1
2023-03-01 08:38:58,693 DEBUG TRAIN Batch 52/4200 loss 14.682708 loss_att 18.847301 loss_ctc 24.835905 loss_rnnt 12.344669 hw_loss 0.283803 lr 0.00029002 rank 1
2023-03-01 08:38:58,706 DEBUG TRAIN Batch 52/4200 loss 2.725363 loss_att 6.619068 loss_ctc 7.060622 loss_rnnt 1.257839 hw_loss 0.207652 lr 0.00029002 rank 0
2023-03-01 08:38:58,709 DEBUG TRAIN Batch 52/4200 loss 6.111957 loss_att 8.455995 loss_ctc 8.224698 loss_rnnt 5.267146 hw_loss 0.176821 lr 0.00029001 rank 7
2023-03-01 08:38:58,715 DEBUG TRAIN Batch 52/4200 loss 7.647771 loss_att 11.758362 loss_ctc 15.150908 loss_rnnt 5.786424 hw_loss 0.072769 lr 0.00029002 rank 2
2023-03-01 08:38:58,721 DEBUG TRAIN Batch 52/4200 loss 10.292436 loss_att 14.552439 loss_ctc 20.093498 loss_rnnt 8.040707 hw_loss 0.174225 lr 0.00029001 rank 3
2023-03-01 08:38:58,721 DEBUG TRAIN Batch 52/4200 loss 7.074427 loss_att 9.305877 loss_ctc 11.569131 loss_rnnt 5.898247 hw_loss 0.244867 lr 0.00029002 rank 4
2023-03-01 08:38:58,725 DEBUG TRAIN Batch 52/4200 loss 6.341153 loss_att 10.437267 loss_ctc 11.412249 loss_rnnt 4.704111 hw_loss 0.265637 lr 0.00029001 rank 5
2023-03-01 08:38:58,739 DEBUG TRAIN Batch 52/4200 loss 12.850850 loss_att 15.664730 loss_ctc 19.015415 loss_rnnt 11.406874 hw_loss 0.111109 lr 0.00029002 rank 6
2023-03-01 08:40:03,444 DEBUG TRAIN Batch 52/4300 loss 4.947435 loss_att 6.624144 loss_ctc 7.582693 loss_rnnt 4.142676 hw_loss 0.221342 lr 0.00029000 rank 5
2023-03-01 08:40:03,452 DEBUG TRAIN Batch 52/4300 loss 3.482920 loss_att 5.389282 loss_ctc 5.935419 loss_rnnt 2.661452 hw_loss 0.212241 lr 0.00029000 rank 3
2023-03-01 08:40:03,452 DEBUG TRAIN Batch 52/4300 loss 5.045903 loss_att 7.547003 loss_ctc 9.438382 loss_rnnt 3.824090 hw_loss 0.254866 lr 0.00029001 rank 4
2023-03-01 08:40:03,455 DEBUG TRAIN Batch 52/4300 loss 6.272041 loss_att 8.771304 loss_ctc 15.293447 loss_rnnt 4.486400 hw_loss 0.155501 lr 0.00029001 rank 2
2023-03-01 08:40:03,455 DEBUG TRAIN Batch 52/4300 loss 7.589259 loss_att 12.585663 loss_ctc 13.192646 loss_rnnt 5.729406 hw_loss 0.212725 lr 0.00029001 rank 0
2023-03-01 08:40:03,457 DEBUG TRAIN Batch 52/4300 loss 13.150788 loss_att 17.466759 loss_ctc 18.445391 loss_rnnt 11.531455 hw_loss 0.094111 lr 0.00029000 rank 7
2023-03-01 08:40:03,460 DEBUG TRAIN Batch 52/4300 loss 4.347965 loss_att 8.175588 loss_ctc 6.310064 loss_rnnt 3.275181 hw_loss 0.085587 lr 0.00029000 rank 6
2023-03-01 08:40:03,501 DEBUG TRAIN Batch 52/4300 loss 4.892816 loss_att 7.674181 loss_ctc 7.582540 loss_rnnt 3.821326 hw_loss 0.293601 lr 0.00029001 rank 1
2023-03-01 08:40:42,229 DEBUG TRAIN Batch 52/4400 loss 6.073369 loss_att 7.221196 loss_ctc 9.762158 loss_rnnt 5.230151 hw_loss 0.228400 lr 0.00029000 rank 4
2023-03-01 08:40:42,230 DEBUG TRAIN Batch 52/4400 loss 6.573739 loss_att 8.764580 loss_ctc 10.462196 loss_rnnt 5.486277 hw_loss 0.245311 lr 0.00029000 rank 0
2023-03-01 08:40:42,233 DEBUG TRAIN Batch 52/4400 loss 8.782332 loss_att 11.407032 loss_ctc 15.829021 loss_rnnt 7.230955 hw_loss 0.162896 lr 0.00028999 rank 3
2023-03-01 08:40:42,234 DEBUG TRAIN Batch 52/4400 loss 7.337814 loss_att 10.486652 loss_ctc 11.796595 loss_rnnt 5.980016 hw_loss 0.250361 lr 0.00028998 rank 7
2023-03-01 08:40:42,235 DEBUG TRAIN Batch 52/4400 loss 9.590936 loss_att 9.760931 loss_ctc 12.429891 loss_rnnt 9.095387 hw_loss 0.155666 lr 0.00028999 rank 6
2023-03-01 08:40:42,234 DEBUG TRAIN Batch 52/4400 loss 8.773317 loss_att 9.484243 loss_ctc 13.150464 loss_rnnt 7.847792 hw_loss 0.374474 lr 0.00028999 rank 1
2023-03-01 08:40:42,236 DEBUG TRAIN Batch 52/4400 loss 10.606844 loss_att 13.190548 loss_ctc 18.263447 loss_rnnt 8.951227 hw_loss 0.221240 lr 0.00028999 rank 5
2023-03-01 08:40:42,239 DEBUG TRAIN Batch 52/4400 loss 6.849365 loss_att 11.166409 loss_ctc 12.738142 loss_rnnt 5.059325 hw_loss 0.265238 lr 0.00029000 rank 2
2023-03-01 08:41:20,991 DEBUG TRAIN Batch 52/4500 loss 4.233823 loss_att 5.642681 loss_ctc 6.604480 loss_rnnt 3.473274 hw_loss 0.305042 lr 0.00028997 rank 7
2023-03-01 08:41:20,994 DEBUG TRAIN Batch 52/4500 loss 5.369880 loss_att 8.190999 loss_ctc 11.904459 loss_rnnt 3.887974 hw_loss 0.087008 lr 0.00028998 rank 0
2023-03-01 08:41:20,995 DEBUG TRAIN Batch 52/4500 loss 1.865836 loss_att 4.448213 loss_ctc 3.073256 loss_rnnt 1.059305 hw_loss 0.241998 lr 0.00028998 rank 2
2023-03-01 08:41:20,996 DEBUG TRAIN Batch 52/4500 loss 2.327790 loss_att 5.041405 loss_ctc 5.701883 loss_rnnt 1.217664 hw_loss 0.220359 lr 0.00028998 rank 5
2023-03-01 08:41:20,997 DEBUG TRAIN Batch 52/4500 loss 6.654765 loss_att 8.619083 loss_ctc 10.758063 loss_rnnt 5.570944 hw_loss 0.269721 lr 0.00028998 rank 4
2023-03-01 08:41:20,997 DEBUG TRAIN Batch 52/4500 loss 4.110020 loss_att 9.115546 loss_ctc 10.236012 loss_rnnt 2.219606 hw_loss 0.135956 lr 0.00028997 rank 3
2023-03-01 08:41:21,025 DEBUG TRAIN Batch 52/4500 loss 12.754190 loss_att 15.822830 loss_ctc 20.737125 loss_rnnt 11.024109 hw_loss 0.097430 lr 0.00028998 rank 1
2023-03-01 08:41:21,064 DEBUG TRAIN Batch 52/4500 loss 4.013601 loss_att 7.887291 loss_ctc 4.975820 loss_rnnt 3.033975 hw_loss 0.143611 lr 0.00028998 rank 6
2023-03-01 08:42:01,004 DEBUG TRAIN Batch 52/4600 loss 2.751447 loss_att 6.574950 loss_ctc 3.695925 loss_rnnt 1.774960 hw_loss 0.160980 lr 0.00028997 rank 0
2023-03-01 08:42:01,004 DEBUG TRAIN Batch 52/4600 loss 1.001236 loss_att 3.393668 loss_ctc 1.980142 loss_rnnt 0.294689 hw_loss 0.182888 lr 0.00028996 rank 3
2023-03-01 08:42:01,007 DEBUG TRAIN Batch 52/4600 loss 12.234164 loss_att 15.214409 loss_ctc 14.051974 loss_rnnt 11.254930 hw_loss 0.264017 lr 0.00028996 rank 5
2023-03-01 08:42:01,010 DEBUG TRAIN Batch 52/4600 loss 1.932919 loss_att 5.109838 loss_ctc 6.251155 loss_rnnt 0.588500 hw_loss 0.249881 lr 0.00028997 rank 2
2023-03-01 08:42:01,021 DEBUG TRAIN Batch 52/4600 loss 8.244511 loss_att 11.118731 loss_ctc 10.086969 loss_rnnt 7.383819 hw_loss 0.075351 lr 0.00028997 rank 4
2023-03-01 08:42:01,021 DEBUG TRAIN Batch 52/4600 loss 8.818976 loss_att 14.165409 loss_ctc 14.708868 loss_rnnt 6.811249 hw_loss 0.287103 lr 0.00028996 rank 7
2023-03-01 08:42:01,026 DEBUG TRAIN Batch 52/4600 loss 4.740920 loss_att 6.519534 loss_ctc 7.277168 loss_rnnt 3.873198 hw_loss 0.325936 lr 0.00028997 rank 6
2023-03-01 08:42:01,046 DEBUG TRAIN Batch 52/4600 loss 2.811934 loss_att 6.181129 loss_ctc 6.065304 loss_rnnt 1.613034 hw_loss 0.171147 lr 0.00028997 rank 1
2023-03-01 08:43:06,422 DEBUG TRAIN Batch 52/4700 loss 5.322327 loss_att 9.103031 loss_ctc 11.752649 loss_rnnt 3.635341 hw_loss 0.137754 lr 0.00028995 rank 3
2023-03-01 08:43:06,423 DEBUG TRAIN Batch 52/4700 loss 6.589885 loss_att 7.548430 loss_ctc 6.910293 loss_rnnt 6.240581 hw_loss 0.215390 lr 0.00028996 rank 0
2023-03-01 08:43:06,423 DEBUG TRAIN Batch 52/4700 loss 3.058127 loss_att 5.283603 loss_ctc 7.578023 loss_rnnt 1.914554 hw_loss 0.179671 lr 0.00028995 rank 5
2023-03-01 08:43:06,427 DEBUG TRAIN Batch 52/4700 loss 6.291014 loss_att 9.569624 loss_ctc 10.465997 loss_rnnt 4.993173 hw_loss 0.160227 lr 0.00028995 rank 7
2023-03-01 08:43:06,431 DEBUG TRAIN Batch 52/4700 loss 5.359877 loss_att 7.044918 loss_ctc 5.815265 loss_rnnt 4.813995 hw_loss 0.277793 lr 0.00028996 rank 6
2023-03-01 08:43:06,432 DEBUG TRAIN Batch 52/4700 loss 5.158711 loss_att 8.849722 loss_ctc 8.668487 loss_rnnt 3.847950 hw_loss 0.196106 lr 0.00028996 rank 4
2023-03-01 08:43:06,433 DEBUG TRAIN Batch 52/4700 loss 9.340085 loss_att 11.782656 loss_ctc 13.902102 loss_rnnt 8.153617 hw_loss 0.168160 lr 0.00028996 rank 1
2023-03-01 08:43:06,476 DEBUG TRAIN Batch 52/4700 loss 2.142190 loss_att 3.537934 loss_ctc 3.590612 loss_rnnt 1.568998 hw_loss 0.189226 lr 0.00028996 rank 2
2023-03-01 08:43:44,777 DEBUG TRAIN Batch 52/4800 loss 4.608544 loss_att 7.965570 loss_ctc 9.886559 loss_rnnt 3.082456 hw_loss 0.283027 lr 0.00028994 rank 3
2023-03-01 08:43:44,777 DEBUG TRAIN Batch 52/4800 loss 7.146169 loss_att 10.721562 loss_ctc 13.599729 loss_rnnt 5.483137 hw_loss 0.164022 lr 0.00028994 rank 1
2023-03-01 08:43:44,786 DEBUG TRAIN Batch 52/4800 loss 5.669166 loss_att 8.939823 loss_ctc 10.627310 loss_rnnt 4.196192 hw_loss 0.295794 lr 0.00028995 rank 4
2023-03-01 08:43:44,790 DEBUG TRAIN Batch 52/4800 loss 8.514403 loss_att 9.576003 loss_ctc 19.300213 loss_rnnt 6.695295 hw_loss 0.316274 lr 0.00028995 rank 0
2023-03-01 08:43:44,793 DEBUG TRAIN Batch 52/4800 loss 1.645823 loss_att 5.901433 loss_ctc 1.222938 loss_rnnt 0.749569 hw_loss 0.190342 lr 0.00028993 rank 7
2023-03-01 08:43:44,793 DEBUG TRAIN Batch 52/4800 loss 6.331649 loss_att 8.511583 loss_ctc 9.724876 loss_rnnt 5.261323 hw_loss 0.341078 lr 0.00028994 rank 5
2023-03-01 08:43:44,794 DEBUG TRAIN Batch 52/4800 loss 3.216096 loss_att 5.599335 loss_ctc 5.982081 loss_rnnt 2.199570 hw_loss 0.320776 lr 0.00028995 rank 2
2023-03-01 08:43:44,800 DEBUG TRAIN Batch 52/4800 loss 2.948586 loss_att 7.268355 loss_ctc 6.623415 loss_rnnt 1.476072 hw_loss 0.222342 lr 0.00028994 rank 6
2023-03-01 08:44:23,531 DEBUG TRAIN Batch 52/4900 loss 7.823830 loss_att 10.577638 loss_ctc 14.249641 loss_rnnt 6.295167 hw_loss 0.227111 lr 0.00028994 rank 0
2023-03-01 08:44:23,536 DEBUG TRAIN Batch 52/4900 loss 6.217824 loss_att 10.829862 loss_ctc 14.833221 loss_rnnt 4.061217 hw_loss 0.160275 lr 0.00028993 rank 1
2023-03-01 08:44:23,537 DEBUG TRAIN Batch 52/4900 loss 7.701505 loss_att 11.963009 loss_ctc 10.793967 loss_rnnt 6.327118 hw_loss 0.205797 lr 0.00028992 rank 7
2023-03-01 08:44:23,551 DEBUG TRAIN Batch 52/4900 loss 7.393466 loss_att 9.407900 loss_ctc 7.269040 loss_rnnt 6.918384 hw_loss 0.166473 lr 0.00028994 rank 2
2023-03-01 08:44:23,553 DEBUG TRAIN Batch 52/4900 loss 8.230658 loss_att 10.298763 loss_ctc 10.435012 loss_rnnt 7.444941 hw_loss 0.146590 lr 0.00028993 rank 4
2023-03-01 08:44:23,554 DEBUG TRAIN Batch 52/4900 loss 9.680623 loss_att 13.402548 loss_ctc 20.619404 loss_rnnt 7.389390 hw_loss 0.165647 lr 0.00028993 rank 5
2023-03-01 08:44:23,568 DEBUG TRAIN Batch 52/4900 loss 1.880296 loss_att 3.490812 loss_ctc 2.775235 loss_rnnt 1.327832 hw_loss 0.208193 lr 0.00028992 rank 3
2023-03-01 08:44:23,571 DEBUG TRAIN Batch 52/4900 loss 2.204191 loss_att 4.164518 loss_ctc 4.285585 loss_rnnt 1.386216 hw_loss 0.278233 lr 0.00028993 rank 6
2023-03-01 08:45:30,029 DEBUG TRAIN Batch 52/5000 loss 1.811612 loss_att 4.855375 loss_ctc 4.739150 loss_rnnt 0.726493 hw_loss 0.161303 lr 0.00028992 rank 0
2023-03-01 08:45:30,030 DEBUG TRAIN Batch 52/5000 loss 5.089778 loss_att 11.738668 loss_ctc 11.213060 loss_rnnt 2.811822 hw_loss 0.247012 lr 0.00028991 rank 7
2023-03-01 08:45:30,034 DEBUG TRAIN Batch 52/5000 loss 7.161157 loss_att 8.676708 loss_ctc 14.239682 loss_rnnt 5.791512 hw_loss 0.230120 lr 0.00028992 rank 1
2023-03-01 08:45:30,035 DEBUG TRAIN Batch 52/5000 loss 7.851650 loss_att 13.641539 loss_ctc 16.581787 loss_rnnt 5.428099 hw_loss 0.190414 lr 0.00028991 rank 5
2023-03-01 08:45:30,037 DEBUG TRAIN Batch 52/5000 loss 3.710036 loss_att 5.084267 loss_ctc 5.410439 loss_rnnt 3.062266 hw_loss 0.274130 lr 0.00028992 rank 4
2023-03-01 08:45:30,040 DEBUG TRAIN Batch 52/5000 loss 9.884625 loss_att 13.644948 loss_ctc 17.905586 loss_rnnt 7.954835 hw_loss 0.202994 lr 0.00028992 rank 2
2023-03-01 08:45:30,046 DEBUG TRAIN Batch 52/5000 loss 5.481081 loss_att 7.436604 loss_ctc 7.051601 loss_rnnt 4.741026 hw_loss 0.261653 lr 0.00028991 rank 3
2023-03-01 08:45:30,078 DEBUG TRAIN Batch 52/5000 loss 7.852208 loss_att 10.983588 loss_ctc 12.417701 loss_rnnt 6.446982 hw_loss 0.319156 lr 0.00028992 rank 6
2023-03-01 08:46:09,316 DEBUG TRAIN Batch 52/5100 loss 9.107081 loss_att 11.891847 loss_ctc 12.107073 loss_rnnt 8.074971 hw_loss 0.140923 lr 0.00028991 rank 2
2023-03-01 08:46:09,321 DEBUG TRAIN Batch 52/5100 loss 3.138288 loss_att 7.635451 loss_ctc 6.468097 loss_rnnt 1.714131 hw_loss 0.151407 lr 0.00028991 rank 4
2023-03-01 08:46:09,334 DEBUG TRAIN Batch 52/5100 loss 7.510473 loss_att 8.545263 loss_ctc 9.441154 loss_rnnt 6.947737 hw_loss 0.184412 lr 0.00028990 rank 7
2023-03-01 08:46:09,338 DEBUG TRAIN Batch 52/5100 loss 4.645180 loss_att 8.131742 loss_ctc 7.581020 loss_rnnt 3.477676 hw_loss 0.147650 lr 0.00028991 rank 1
2023-03-01 08:46:09,344 DEBUG TRAIN Batch 52/5100 loss 5.309037 loss_att 8.762888 loss_ctc 9.604114 loss_rnnt 3.956645 hw_loss 0.166771 lr 0.00028991 rank 0
2023-03-01 08:46:09,345 DEBUG TRAIN Batch 52/5100 loss 3.529466 loss_att 6.610549 loss_ctc 6.929460 loss_rnnt 2.405752 hw_loss 0.101560 lr 0.00028990 rank 5
2023-03-01 08:46:09,359 DEBUG TRAIN Batch 52/5100 loss 8.349269 loss_att 8.649246 loss_ctc 12.193649 loss_rnnt 7.567242 hw_loss 0.392714 lr 0.00028990 rank 3
2023-03-01 08:46:09,376 DEBUG TRAIN Batch 52/5100 loss 8.860845 loss_att 10.785832 loss_ctc 8.604916 loss_rnnt 8.466072 hw_loss 0.082309 lr 0.00028991 rank 6
2023-03-01 08:46:48,113 DEBUG TRAIN Batch 52/5200 loss 2.932301 loss_att 6.216140 loss_ctc 3.928276 loss_rnnt 2.033420 hw_loss 0.204969 lr 0.00028989 rank 6
2023-03-01 08:46:48,113 DEBUG TRAIN Batch 52/5200 loss 9.311921 loss_att 13.039991 loss_ctc 20.019314 loss_rnnt 7.056756 hw_loss 0.153560 lr 0.00028989 rank 7
2023-03-01 08:46:48,115 DEBUG TRAIN Batch 52/5200 loss 4.913751 loss_att 6.699462 loss_ctc 8.378651 loss_rnnt 3.902701 hw_loss 0.359851 lr 0.00028990 rank 1
2023-03-01 08:46:48,117 DEBUG TRAIN Batch 52/5200 loss 4.719629 loss_att 7.502595 loss_ctc 7.362249 loss_rnnt 3.761219 hw_loss 0.092750 lr 0.00028990 rank 0
2023-03-01 08:46:48,120 DEBUG TRAIN Batch 52/5200 loss 4.473971 loss_att 7.372392 loss_ctc 9.091437 loss_rnnt 3.190246 hw_loss 0.165710 lr 0.00028990 rank 4
2023-03-01 08:46:48,121 DEBUG TRAIN Batch 52/5200 loss 7.694728 loss_att 11.777376 loss_ctc 14.492240 loss_rnnt 5.880493 hw_loss 0.171321 lr 0.00028990 rank 2
2023-03-01 08:46:48,122 DEBUG TRAIN Batch 52/5200 loss 1.777631 loss_att 4.665776 loss_ctc 4.549530 loss_rnnt 0.725527 hw_loss 0.196666 lr 0.00028989 rank 5
2023-03-01 08:46:48,172 DEBUG TRAIN Batch 52/5200 loss 2.737106 loss_att 5.708316 loss_ctc 4.959178 loss_rnnt 1.715048 hw_loss 0.246636 lr 0.00028989 rank 3
2023-03-01 08:47:27,790 DEBUG TRAIN Batch 52/5300 loss 4.179790 loss_att 5.382804 loss_ctc 5.769039 loss_rnnt 3.651035 hw_loss 0.142971 lr 0.00028988 rank 1
2023-03-01 08:47:27,793 DEBUG TRAIN Batch 52/5300 loss 6.155419 loss_att 9.292802 loss_ctc 12.208247 loss_rnnt 4.553131 hw_loss 0.314566 lr 0.00028988 rank 5
2023-03-01 08:47:27,793 DEBUG TRAIN Batch 52/5300 loss 6.568316 loss_att 10.144252 loss_ctc 11.654694 loss_rnnt 5.054780 hw_loss 0.225308 lr 0.00028989 rank 4
2023-03-01 08:47:27,794 DEBUG TRAIN Batch 52/5300 loss 4.888991 loss_att 7.470425 loss_ctc 6.147285 loss_rnnt 4.157149 hw_loss 0.089592 lr 0.00028988 rank 3
2023-03-01 08:47:27,801 DEBUG TRAIN Batch 52/5300 loss 5.552280 loss_att 8.551935 loss_ctc 10.911764 loss_rnnt 4.060420 hw_loss 0.332496 lr 0.00028987 rank 7
2023-03-01 08:47:27,806 DEBUG TRAIN Batch 52/5300 loss 3.156676 loss_att 5.091100 loss_ctc 5.164522 loss_rnnt 2.427174 hw_loss 0.140445 lr 0.00028989 rank 0
2023-03-01 08:47:27,808 DEBUG TRAIN Batch 52/5300 loss 5.712039 loss_att 8.582986 loss_ctc 10.089680 loss_rnnt 4.431583 hw_loss 0.229839 lr 0.00028988 rank 6
2023-03-01 08:47:27,810 DEBUG TRAIN Batch 52/5300 loss 12.204911 loss_att 13.356441 loss_ctc 22.485149 loss_rnnt 10.458067 hw_loss 0.273450 lr 0.00028989 rank 2
2023-03-01 08:48:32,273 DEBUG TRAIN Batch 52/5400 loss 9.368488 loss_att 14.125919 loss_ctc 16.534561 loss_rnnt 7.355112 hw_loss 0.199526 lr 0.00028987 rank 5
2023-03-01 08:48:32,282 DEBUG TRAIN Batch 52/5400 loss 13.168546 loss_att 15.214055 loss_ctc 17.841085 loss_rnnt 12.037256 hw_loss 0.185966 lr 0.00028987 rank 6
2023-03-01 08:48:32,288 DEBUG TRAIN Batch 52/5400 loss 4.335674 loss_att 7.091073 loss_ctc 8.619951 loss_rnnt 3.164523 hw_loss 0.091564 lr 0.00028988 rank 0
2023-03-01 08:48:32,290 DEBUG TRAIN Batch 52/5400 loss 3.160657 loss_att 5.618865 loss_ctc 3.518525 loss_rnnt 2.505580 hw_loss 0.216975 lr 0.00028987 rank 2
2023-03-01 08:48:32,292 DEBUG TRAIN Batch 52/5400 loss 4.897467 loss_att 8.263205 loss_ctc 11.888807 loss_rnnt 3.203351 hw_loss 0.166480 lr 0.00028986 rank 7
2023-03-01 08:48:32,296 DEBUG TRAIN Batch 52/5400 loss 4.849850 loss_att 6.914008 loss_ctc 6.447261 loss_rnnt 4.116476 hw_loss 0.201664 lr 0.00028987 rank 1
2023-03-01 08:48:32,298 DEBUG TRAIN Batch 52/5400 loss 3.941688 loss_att 6.512023 loss_ctc 6.886542 loss_rnnt 2.964924 hw_loss 0.131343 lr 0.00028987 rank 4
2023-03-01 08:48:32,299 DEBUG TRAIN Batch 52/5400 loss 6.137935 loss_att 10.459515 loss_ctc 8.522131 loss_rnnt 4.789675 hw_loss 0.311346 lr 0.00028986 rank 3
2023-03-01 08:49:10,716 DEBUG TRAIN Batch 52/5500 loss 6.219917 loss_att 9.535398 loss_ctc 9.704136 loss_rnnt 4.982955 hw_loss 0.204943 lr 0.00028985 rank 7
2023-03-01 08:49:10,719 DEBUG TRAIN Batch 52/5500 loss 4.535462 loss_att 9.153876 loss_ctc 11.684604 loss_rnnt 2.624518 hw_loss 0.063829 lr 0.00028986 rank 1
2023-03-01 08:49:10,719 DEBUG TRAIN Batch 52/5500 loss 3.461399 loss_att 7.020765 loss_ctc 8.668163 loss_rnnt 1.997343 hw_loss 0.108653 lr 0.00028986 rank 2
2023-03-01 08:49:10,720 DEBUG TRAIN Batch 52/5500 loss 0.903967 loss_att 2.980259 loss_ctc 2.208091 loss_rnnt 0.232204 hw_loss 0.154916 lr 0.00028985 rank 5
2023-03-01 08:49:10,720 DEBUG TRAIN Batch 52/5500 loss 2.035873 loss_att 5.909452 loss_ctc 3.049354 loss_rnnt 1.028422 hw_loss 0.183009 lr 0.00028986 rank 0
2023-03-01 08:49:10,725 DEBUG TRAIN Batch 52/5500 loss 9.169980 loss_att 12.798208 loss_ctc 15.684856 loss_rnnt 7.506966 hw_loss 0.128846 lr 0.00028985 rank 3
2023-03-01 08:49:10,726 DEBUG TRAIN Batch 52/5500 loss 4.560375 loss_att 7.531411 loss_ctc 7.955185 loss_rnnt 3.399474 hw_loss 0.213848 lr 0.00028986 rank 4
2023-03-01 08:49:10,738 DEBUG TRAIN Batch 52/5500 loss 5.600285 loss_att 6.771259 loss_ctc 7.501605 loss_rnnt 4.942340 hw_loss 0.319202 lr 0.00028986 rank 6
2023-03-01 08:49:50,920 DEBUG TRAIN Batch 52/5600 loss 10.542334 loss_att 12.494819 loss_ctc 19.888124 loss_rnnt 8.759915 hw_loss 0.273403 lr 0.00028985 rank 6
2023-03-01 08:49:50,921 DEBUG TRAIN Batch 52/5600 loss 5.141222 loss_att 8.219334 loss_ctc 8.564674 loss_rnnt 3.894335 hw_loss 0.327757 lr 0.00028985 rank 0
2023-03-01 08:49:50,921 DEBUG TRAIN Batch 52/5600 loss 4.619454 loss_att 7.032792 loss_ctc 10.310158 loss_rnnt 3.281640 hw_loss 0.180724 lr 0.00028985 rank 2
2023-03-01 08:49:50,926 DEBUG TRAIN Batch 52/5600 loss 3.621844 loss_att 5.657636 loss_ctc 5.746657 loss_rnnt 2.842046 hw_loss 0.167496 lr 0.00028985 rank 1
2023-03-01 08:49:50,929 DEBUG TRAIN Batch 52/5600 loss 6.111927 loss_att 10.726378 loss_ctc 10.617683 loss_rnnt 4.425849 hw_loss 0.304537 lr 0.00028984 rank 7
2023-03-01 08:49:50,938 DEBUG TRAIN Batch 52/5600 loss 5.303723 loss_att 8.379412 loss_ctc 11.183279 loss_rnnt 3.769423 hw_loss 0.253541 lr 0.00028984 rank 3
2023-03-01 08:49:50,941 DEBUG TRAIN Batch 52/5600 loss 9.645878 loss_att 11.938009 loss_ctc 20.994606 loss_rnnt 7.499450 hw_loss 0.327821 lr 0.00028984 rank 5
2023-03-01 08:49:50,945 DEBUG TRAIN Batch 52/5600 loss 5.348251 loss_att 6.915751 loss_ctc 9.240534 loss_rnnt 4.359107 hw_loss 0.293763 lr 0.00028985 rank 4
2023-03-01 08:50:57,772 DEBUG TRAIN Batch 52/5700 loss 12.682794 loss_att 13.374147 loss_ctc 18.881065 loss_rnnt 11.597050 hw_loss 0.226943 lr 0.00028983 rank 3
2023-03-01 08:50:57,772 DEBUG TRAIN Batch 52/5700 loss 6.224737 loss_att 8.947190 loss_ctc 10.857025 loss_rnnt 4.909328 hw_loss 0.287400 lr 0.00028984 rank 4
2023-03-01 08:50:57,779 DEBUG TRAIN Batch 52/5700 loss 3.872859 loss_att 7.058230 loss_ctc 6.270454 loss_rnnt 2.850055 hw_loss 0.123844 lr 0.00028983 rank 7
2023-03-01 08:50:57,783 DEBUG TRAIN Batch 52/5700 loss 9.466604 loss_att 12.155824 loss_ctc 18.545696 loss_rnnt 7.635529 hw_loss 0.155037 lr 0.00028984 rank 0
2023-03-01 08:50:57,787 DEBUG TRAIN Batch 52/5700 loss 4.676768 loss_att 6.611069 loss_ctc 6.870861 loss_rnnt 3.914792 hw_loss 0.154819 lr 0.00028983 rank 1
2023-03-01 08:50:57,787 DEBUG TRAIN Batch 52/5700 loss 10.308583 loss_att 13.109617 loss_ctc 19.002338 loss_rnnt 8.466576 hw_loss 0.229935 lr 0.00028984 rank 2
2023-03-01 08:50:57,790 DEBUG TRAIN Batch 52/5700 loss 7.768977 loss_att 11.223148 loss_ctc 14.182448 loss_rnnt 6.138050 hw_loss 0.159306 lr 0.00028983 rank 5
2023-03-01 08:50:57,821 DEBUG TRAIN Batch 52/5700 loss 4.421976 loss_att 8.757528 loss_ctc 6.067087 loss_rnnt 3.263451 hw_loss 0.135123 lr 0.00028983 rank 6
2023-03-01 08:51:37,158 DEBUG TRAIN Batch 52/5800 loss 3.280604 loss_att 5.552448 loss_ctc 4.947109 loss_rnnt 2.513649 hw_loss 0.169472 lr 0.00028982 rank 1
2023-03-01 08:51:37,170 DEBUG TRAIN Batch 52/5800 loss 6.700193 loss_att 8.060391 loss_ctc 12.485150 loss_rnnt 5.516559 hw_loss 0.263001 lr 0.00028981 rank 7
2023-03-01 08:51:37,170 DEBUG TRAIN Batch 52/5800 loss 9.379216 loss_att 14.037168 loss_ctc 15.063480 loss_rnnt 7.675512 hw_loss 0.026649 lr 0.00028982 rank 6
2023-03-01 08:51:37,172 DEBUG TRAIN Batch 52/5800 loss 5.677962 loss_att 5.822642 loss_ctc 9.366882 loss_rnnt 4.970218 hw_loss 0.350535 lr 0.00028983 rank 2
2023-03-01 08:51:37,174 DEBUG TRAIN Batch 52/5800 loss 6.617829 loss_att 22.479244 loss_ctc 9.417322 loss_rnnt 2.998090 hw_loss 0.139107 lr 0.00028983 rank 4
2023-03-01 08:51:37,175 DEBUG TRAIN Batch 52/5800 loss 2.775802 loss_att 8.484348 loss_ctc 4.795543 loss_rnnt 1.298787 hw_loss 0.123763 lr 0.00028982 rank 5
2023-03-01 08:51:37,176 DEBUG TRAIN Batch 52/5800 loss 3.031014 loss_att 5.606455 loss_ctc 9.790173 loss_rnnt 1.521437 hw_loss 0.174876 lr 0.00028983 rank 0
2023-03-01 08:51:37,183 DEBUG TRAIN Batch 52/5800 loss 3.826306 loss_att 7.894842 loss_ctc 6.983984 loss_rnnt 2.453992 hw_loss 0.257966 lr 0.00028982 rank 3
2023-03-01 08:52:15,963 DEBUG TRAIN Batch 52/5900 loss 4.244370 loss_att 7.364296 loss_ctc 5.128523 loss_rnnt 3.384976 hw_loss 0.220354 lr 0.00028981 rank 4
2023-03-01 08:52:15,969 DEBUG TRAIN Batch 52/5900 loss 4.889411 loss_att 6.596044 loss_ctc 6.513219 loss_rnnt 4.144609 hw_loss 0.350563 lr 0.00028980 rank 7
2023-03-01 08:52:15,970 DEBUG TRAIN Batch 52/5900 loss 2.264627 loss_att 4.929505 loss_ctc 4.027564 loss_rnnt 1.291884 hw_loss 0.383828 lr 0.00028981 rank 0
2023-03-01 08:52:15,972 DEBUG TRAIN Batch 52/5900 loss 4.984508 loss_att 7.838894 loss_ctc 9.548909 loss_rnnt 3.768130 hw_loss 0.069214 lr 0.00028981 rank 1
2023-03-01 08:52:15,973 DEBUG TRAIN Batch 52/5900 loss 3.085161 loss_att 4.541788 loss_ctc 4.058753 loss_rnnt 2.557797 hw_loss 0.199174 lr 0.00028980 rank 3
2023-03-01 08:52:15,975 DEBUG TRAIN Batch 52/5900 loss 3.584261 loss_att 6.697390 loss_ctc 6.548631 loss_rnnt 2.510175 hw_loss 0.105395 lr 0.00028981 rank 2
2023-03-01 08:52:15,975 DEBUG TRAIN Batch 52/5900 loss 8.041209 loss_att 13.336183 loss_ctc 21.757469 loss_rnnt 5.084741 hw_loss 0.128697 lr 0.00028981 rank 5
2023-03-01 08:52:15,994 DEBUG TRAIN Batch 52/5900 loss 6.045503 loss_att 8.181164 loss_ctc 9.517303 loss_rnnt 4.997619 hw_loss 0.295958 lr 0.00028981 rank 6
2023-03-01 08:52:56,296 DEBUG TRAIN Batch 52/6000 loss 3.348150 loss_att 5.700994 loss_ctc 5.749597 loss_rnnt 2.500970 hw_loss 0.105785 lr 0.00028979 rank 5
2023-03-01 08:52:56,296 DEBUG TRAIN Batch 52/6000 loss 5.179925 loss_att 8.628992 loss_ctc 11.026938 loss_rnnt 3.651359 hw_loss 0.110908 lr 0.00028979 rank 7
2023-03-01 08:52:56,299 DEBUG TRAIN Batch 52/6000 loss 11.435019 loss_att 15.878214 loss_ctc 20.881430 loss_rnnt 9.212523 hw_loss 0.139376 lr 0.00028980 rank 1
2023-03-01 08:52:56,309 DEBUG TRAIN Batch 52/6000 loss 1.973012 loss_att 3.935612 loss_ctc 3.291230 loss_rnnt 1.233855 hw_loss 0.320390 lr 0.00028980 rank 4
2023-03-01 08:52:56,313 DEBUG TRAIN Batch 52/6000 loss 9.081752 loss_att 12.383224 loss_ctc 14.868015 loss_rnnt 7.576220 hw_loss 0.138254 lr 0.00028980 rank 0
2023-03-01 08:52:56,318 DEBUG TRAIN Batch 52/6000 loss 6.808652 loss_att 10.362129 loss_ctc 11.231104 loss_rnnt 5.412307 hw_loss 0.179981 lr 0.00028980 rank 6
2023-03-01 08:52:56,319 DEBUG TRAIN Batch 52/6000 loss 4.610175 loss_att 6.356006 loss_ctc 8.935004 loss_rnnt 3.556191 hw_loss 0.240325 lr 0.00028980 rank 2
2023-03-01 08:52:56,353 DEBUG TRAIN Batch 52/6000 loss 3.404562 loss_att 5.913925 loss_ctc 6.761522 loss_rnnt 2.357548 hw_loss 0.182901 lr 0.00028979 rank 3
2023-03-01 08:54:01,821 DEBUG TRAIN Batch 52/6100 loss 1.681674 loss_att 4.008409 loss_ctc 5.835279 loss_rnnt 0.597860 hw_loss 0.121226 lr 0.00028978 rank 3
2023-03-01 08:54:01,826 DEBUG TRAIN Batch 52/6100 loss 11.537628 loss_att 14.467594 loss_ctc 17.132622 loss_rnnt 10.145329 hw_loss 0.113075 lr 0.00028979 rank 1
2023-03-01 08:54:01,828 DEBUG TRAIN Batch 52/6100 loss 3.589282 loss_att 6.760766 loss_ctc 8.373997 loss_rnnt 2.157107 hw_loss 0.299844 lr 0.00028979 rank 2
2023-03-01 08:54:01,838 DEBUG TRAIN Batch 52/6100 loss 8.298499 loss_att 10.403955 loss_ctc 14.236244 loss_rnnt 7.034256 hw_loss 0.096474 lr 0.00028978 rank 5
2023-03-01 08:54:01,840 DEBUG TRAIN Batch 52/6100 loss 8.852168 loss_att 11.667212 loss_ctc 13.753741 loss_rnnt 7.573620 hw_loss 0.116243 lr 0.00028978 rank 6
2023-03-01 08:54:01,840 DEBUG TRAIN Batch 52/6100 loss 6.285314 loss_att 8.938309 loss_ctc 8.696890 loss_rnnt 5.352339 hw_loss 0.151561 lr 0.00028978 rank 7
2023-03-01 08:54:01,842 DEBUG TRAIN Batch 52/6100 loss 6.239484 loss_att 11.127582 loss_ctc 13.177691 loss_rnnt 4.185265 hw_loss 0.284073 lr 0.00028979 rank 0
2023-03-01 08:54:01,858 DEBUG TRAIN Batch 52/6100 loss 11.701426 loss_att 16.481239 loss_ctc 21.173052 loss_rnnt 9.473452 hw_loss 0.017115 lr 0.00028979 rank 4
2023-03-01 08:54:41,173 DEBUG TRAIN Batch 52/6200 loss 5.585749 loss_att 7.129527 loss_ctc 8.735330 loss_rnnt 4.717062 hw_loss 0.262475 lr 0.00028977 rank 5
2023-03-01 08:54:41,182 DEBUG TRAIN Batch 52/6200 loss 6.457980 loss_att 9.418602 loss_ctc 12.336889 loss_rnnt 5.019011 hw_loss 0.118106 lr 0.00028977 rank 1
2023-03-01 08:54:41,184 DEBUG TRAIN Batch 52/6200 loss 2.638909 loss_att 4.901334 loss_ctc 6.238500 loss_rnnt 1.550534 hw_loss 0.292396 lr 0.00028978 rank 2
2023-03-01 08:54:41,198 DEBUG TRAIN Batch 52/6200 loss 9.402324 loss_att 10.409782 loss_ctc 14.958728 loss_rnnt 8.362597 hw_loss 0.182588 lr 0.00028977 rank 6
2023-03-01 08:54:41,199 DEBUG TRAIN Batch 52/6200 loss 14.497299 loss_att 15.647486 loss_ctc 21.919464 loss_rnnt 13.195571 hw_loss 0.153878 lr 0.00028978 rank 0
2023-03-01 08:54:41,200 DEBUG TRAIN Batch 52/6200 loss 5.799744 loss_att 7.342715 loss_ctc 8.142703 loss_rnnt 5.139378 hw_loss 0.073832 lr 0.00028976 rank 7
2023-03-01 08:54:41,205 DEBUG TRAIN Batch 52/6200 loss 7.550327 loss_att 10.700731 loss_ctc 13.507266 loss_rnnt 5.951245 hw_loss 0.327640 lr 0.00028978 rank 4
2023-03-01 08:54:41,204 DEBUG TRAIN Batch 52/6200 loss 9.649899 loss_att 11.743319 loss_ctc 17.642811 loss_rnnt 8.050728 hw_loss 0.215184 lr 0.00028977 rank 3
2023-03-01 08:55:20,601 DEBUG TRAIN Batch 52/6300 loss 5.243785 loss_att 7.801140 loss_ctc 6.356311 loss_rnnt 4.506198 hw_loss 0.145835 lr 0.00028975 rank 7
2023-03-01 08:55:20,604 DEBUG TRAIN Batch 52/6300 loss 7.296012 loss_att 9.674695 loss_ctc 12.273143 loss_rnnt 6.054255 hw_loss 0.192007 lr 0.00028976 rank 5
2023-03-01 08:55:20,607 DEBUG TRAIN Batch 52/6300 loss 2.363954 loss_att 5.046891 loss_ctc 3.898205 loss_rnnt 1.519754 hw_loss 0.193211 lr 0.00028976 rank 4
2023-03-01 08:55:20,616 DEBUG TRAIN Batch 52/6300 loss 5.779920 loss_att 7.221510 loss_ctc 8.592812 loss_rnnt 5.031407 hw_loss 0.159641 lr 0.00028977 rank 2
2023-03-01 08:55:20,625 DEBUG TRAIN Batch 52/6300 loss 5.824278 loss_att 9.864694 loss_ctc 9.336707 loss_rnnt 4.423721 hw_loss 0.232784 lr 0.00028977 rank 0
2023-03-01 08:55:20,625 DEBUG TRAIN Batch 52/6300 loss 4.807664 loss_att 7.731641 loss_ctc 9.328486 loss_rnnt 3.531334 hw_loss 0.166423 lr 0.00028975 rank 3
2023-03-01 08:55:20,628 DEBUG TRAIN Batch 52/6300 loss 7.253020 loss_att 7.871950 loss_ctc 10.334909 loss_rnnt 6.541185 hw_loss 0.332118 lr 0.00028976 rank 6
2023-03-01 08:55:20,663 DEBUG TRAIN Batch 52/6300 loss 3.600770 loss_att 7.383069 loss_ctc 4.302895 loss_rnnt 2.627001 hw_loss 0.231924 lr 0.00028976 rank 1
2023-03-01 08:56:25,129 DEBUG TRAIN Batch 52/6400 loss 2.810193 loss_att 3.805630 loss_ctc 5.282161 loss_rnnt 2.121112 hw_loss 0.300746 lr 0.00028975 rank 0
2023-03-01 08:56:25,133 DEBUG TRAIN Batch 52/6400 loss 10.795148 loss_att 12.620979 loss_ctc 23.420746 loss_rnnt 8.644638 hw_loss 0.191118 lr 0.00028974 rank 3
2023-03-01 08:56:25,133 DEBUG TRAIN Batch 52/6400 loss 1.839906 loss_att 5.162795 loss_ctc 3.981011 loss_rnnt 0.858811 hw_loss 0.058195 lr 0.00028975 rank 1
2023-03-01 08:56:25,133 DEBUG TRAIN Batch 52/6400 loss 9.664136 loss_att 11.851093 loss_ctc 15.265475 loss_rnnt 8.367973 hw_loss 0.209862 lr 0.00028975 rank 2
2023-03-01 08:56:25,134 DEBUG TRAIN Batch 52/6400 loss 7.691976 loss_att 11.772067 loss_ctc 10.886212 loss_rnnt 6.333849 hw_loss 0.217894 lr 0.00028974 rank 7
2023-03-01 08:56:25,136 DEBUG TRAIN Batch 52/6400 loss 5.745345 loss_att 7.608823 loss_ctc 6.623443 loss_rnnt 5.196385 hw_loss 0.110969 lr 0.00028974 rank 5
2023-03-01 08:56:25,139 DEBUG TRAIN Batch 52/6400 loss 4.051583 loss_att 6.403399 loss_ctc 5.873889 loss_rnnt 3.249171 hw_loss 0.167015 lr 0.00028975 rank 4
2023-03-01 08:56:25,165 DEBUG TRAIN Batch 52/6400 loss 4.611279 loss_att 7.239697 loss_ctc 7.275382 loss_rnnt 3.604772 hw_loss 0.235518 lr 0.00028975 rank 6
2023-03-01 08:57:04,207 DEBUG TRAIN Batch 52/6500 loss 4.778621 loss_att 8.530854 loss_ctc 6.255310 loss_rnnt 3.684458 hw_loss 0.275297 lr 0.00028973 rank 3
2023-03-01 08:57:04,209 DEBUG TRAIN Batch 52/6500 loss 2.242443 loss_att 4.492105 loss_ctc 3.379079 loss_rnnt 1.502509 hw_loss 0.259593 lr 0.00028974 rank 4
2023-03-01 08:57:04,209 DEBUG TRAIN Batch 52/6500 loss 4.379316 loss_att 6.719207 loss_ctc 6.787936 loss_rnnt 3.526770 hw_loss 0.118908 lr 0.00028974 rank 0
2023-03-01 08:57:04,209 DEBUG TRAIN Batch 52/6500 loss 2.502024 loss_att 5.352106 loss_ctc 4.486152 loss_rnnt 1.547084 hw_loss 0.225698 lr 0.00028974 rank 2
2023-03-01 08:57:04,211 DEBUG TRAIN Batch 52/6500 loss 3.091533 loss_att 7.708087 loss_ctc 7.894086 loss_rnnt 1.409351 hw_loss 0.222244 lr 0.00028974 rank 6
2023-03-01 08:57:04,211 DEBUG TRAIN Batch 52/6500 loss 3.274118 loss_att 5.779468 loss_ctc 4.287717 loss_rnnt 2.474452 hw_loss 0.306468 lr 0.00028974 rank 1
2023-03-01 08:57:04,213 DEBUG TRAIN Batch 52/6500 loss 7.426674 loss_att 7.858363 loss_ctc 10.729643 loss_rnnt 6.676534 hw_loss 0.418887 lr 0.00028973 rank 7
2023-03-01 08:57:04,221 DEBUG TRAIN Batch 52/6500 loss 5.581171 loss_att 11.411708 loss_ctc 7.442630 loss_rnnt 4.128678 hw_loss 0.071606 lr 0.00028973 rank 5
2023-03-01 08:57:43,071 DEBUG TRAIN Batch 52/6600 loss 3.413979 loss_att 8.402905 loss_ctc 6.448282 loss_rnnt 1.911393 hw_loss 0.187926 lr 0.00028972 rank 6
2023-03-01 08:57:43,080 DEBUG TRAIN Batch 52/6600 loss 2.915095 loss_att 5.450478 loss_ctc 5.113824 loss_rnnt 2.034448 hw_loss 0.150762 lr 0.00028973 rank 0
2023-03-01 08:57:43,080 DEBUG TRAIN Batch 52/6600 loss 8.344080 loss_att 10.452680 loss_ctc 12.943110 loss_rnnt 7.308868 hw_loss 0.000541 lr 0.00028972 rank 7
2023-03-01 08:57:43,081 DEBUG TRAIN Batch 52/6600 loss 5.526671 loss_att 8.614758 loss_ctc 7.736946 loss_rnnt 4.441550 hw_loss 0.324001 lr 0.00028973 rank 1
2023-03-01 08:57:43,082 DEBUG TRAIN Batch 52/6600 loss 5.309742 loss_att 7.900320 loss_ctc 8.935841 loss_rnnt 4.240963 hw_loss 0.125968 lr 0.00028973 rank 2
2023-03-01 08:57:43,085 DEBUG TRAIN Batch 52/6600 loss 3.869784 loss_att 7.389542 loss_ctc 6.466302 loss_rnnt 2.657772 hw_loss 0.303484 lr 0.00028972 rank 3
2023-03-01 08:57:43,087 DEBUG TRAIN Batch 52/6600 loss 7.283681 loss_att 9.969271 loss_ctc 11.999537 loss_rnnt 6.043337 hw_loss 0.139585 lr 0.00028972 rank 5
2023-03-01 08:57:43,089 DEBUG TRAIN Batch 52/6600 loss 9.271162 loss_att 10.118572 loss_ctc 10.402367 loss_rnnt 8.887938 hw_loss 0.117965 lr 0.00028973 rank 4
2023-03-01 08:58:22,539 DEBUG TRAIN Batch 52/6700 loss 7.738495 loss_att 8.932339 loss_ctc 9.352024 loss_rnnt 7.139941 hw_loss 0.271214 lr 0.00028972 rank 4
2023-03-01 08:58:22,549 DEBUG TRAIN Batch 52/6700 loss 4.620884 loss_att 7.597613 loss_ctc 7.051908 loss_rnnt 3.591388 hw_loss 0.206275 lr 0.00028971 rank 6
2023-03-01 08:58:22,554 DEBUG TRAIN Batch 52/6700 loss 6.585863 loss_att 8.985031 loss_ctc 9.371939 loss_rnnt 5.571646 hw_loss 0.305449 lr 0.00028972 rank 0
2023-03-01 08:58:22,554 DEBUG TRAIN Batch 52/6700 loss 6.536755 loss_att 12.115944 loss_ctc 13.540362 loss_rnnt 4.288346 hw_loss 0.372668 lr 0.00028970 rank 7
2023-03-01 08:58:22,555 DEBUG TRAIN Batch 52/6700 loss 5.839889 loss_att 8.350750 loss_ctc 7.871368 loss_rnnt 4.948941 hw_loss 0.221083 lr 0.00028972 rank 2
2023-03-01 08:58:22,557 DEBUG TRAIN Batch 52/6700 loss 3.080640 loss_att 5.850873 loss_ctc 6.800151 loss_rnnt 1.956696 hw_loss 0.138680 lr 0.00028971 rank 1
2023-03-01 08:58:22,560 DEBUG TRAIN Batch 52/6700 loss 4.769196 loss_att 9.739473 loss_ctc 7.156859 loss_rnnt 3.409120 hw_loss 0.089372 lr 0.00028971 rank 3
2023-03-01 08:58:22,562 DEBUG TRAIN Batch 52/6700 loss 3.624040 loss_att 6.950360 loss_ctc 6.210110 loss_rnnt 2.477829 hw_loss 0.255258 lr 0.00028971 rank 5
2023-03-01 08:59:29,018 DEBUG TRAIN Batch 52/6800 loss 2.885387 loss_att 4.648283 loss_ctc 4.555644 loss_rnnt 2.184978 hw_loss 0.234618 lr 0.00028970 rank 5
2023-03-01 08:59:29,029 DEBUG TRAIN Batch 52/6800 loss 6.679656 loss_att 9.329385 loss_ctc 9.790533 loss_rnnt 5.597550 hw_loss 0.257579 lr 0.00028969 rank 7
2023-03-01 08:59:29,032 DEBUG TRAIN Batch 52/6800 loss 7.065705 loss_att 10.882320 loss_ctc 15.864435 loss_rnnt 4.988766 hw_loss 0.263349 lr 0.00028970 rank 0
2023-03-01 08:59:29,033 DEBUG TRAIN Batch 52/6800 loss 5.880439 loss_att 8.224837 loss_ctc 7.910523 loss_rnnt 5.092533 hw_loss 0.090652 lr 0.00028970 rank 2
2023-03-01 08:59:29,036 DEBUG TRAIN Batch 52/6800 loss 6.406974 loss_att 8.668059 loss_ctc 9.566124 loss_rnnt 5.384468 hw_loss 0.279502 lr 0.00028970 rank 1
2023-03-01 08:59:29,036 DEBUG TRAIN Batch 52/6800 loss 10.005639 loss_att 12.434510 loss_ctc 21.436031 loss_rnnt 7.901736 hw_loss 0.176393 lr 0.00028970 rank 6
2023-03-01 08:59:29,041 DEBUG TRAIN Batch 52/6800 loss 13.689638 loss_att 18.303614 loss_ctc 21.285755 loss_rnnt 11.593866 hw_loss 0.300302 lr 0.00028970 rank 4
2023-03-01 08:59:29,041 DEBUG TRAIN Batch 52/6800 loss 4.239038 loss_att 7.085300 loss_ctc 7.594746 loss_rnnt 3.042770 hw_loss 0.336726 lr 0.00028969 rank 3
2023-03-01 09:00:08,085 DEBUG TRAIN Batch 52/6900 loss 6.493488 loss_att 7.880718 loss_ctc 7.721259 loss_rnnt 5.998847 hw_loss 0.100299 lr 0.00028968 rank 7
2023-03-01 09:00:08,089 DEBUG TRAIN Batch 52/6900 loss 9.352886 loss_att 10.916024 loss_ctc 12.015280 loss_rnnt 8.606264 hw_loss 0.148141 lr 0.00028968 rank 3
2023-03-01 09:00:08,089 DEBUG TRAIN Batch 52/6900 loss 9.966027 loss_att 10.857128 loss_ctc 13.732939 loss_rnnt 9.194868 hw_loss 0.170030 lr 0.00028969 rank 2
2023-03-01 09:00:08,091 DEBUG TRAIN Batch 52/6900 loss 4.893060 loss_att 8.388975 loss_ctc 9.686385 loss_rnnt 3.481841 hw_loss 0.136737 lr 0.00028969 rank 0
2023-03-01 09:00:08,095 DEBUG TRAIN Batch 52/6900 loss 5.107248 loss_att 5.779479 loss_ctc 7.135060 loss_rnnt 4.568952 hw_loss 0.250267 lr 0.00028969 rank 1
2023-03-01 09:00:08,094 DEBUG TRAIN Batch 52/6900 loss 5.354937 loss_att 7.319951 loss_ctc 8.377851 loss_rnnt 4.420803 hw_loss 0.258891 lr 0.00028969 rank 6
2023-03-01 09:00:08,097 DEBUG TRAIN Batch 52/6900 loss 9.717032 loss_att 10.464531 loss_ctc 15.594835 loss_rnnt 8.597568 hw_loss 0.349233 lr 0.00028969 rank 4
2023-03-01 09:00:08,102 DEBUG TRAIN Batch 52/6900 loss 6.813375 loss_att 8.748672 loss_ctc 10.485970 loss_rnnt 5.775848 hw_loss 0.301480 lr 0.00028968 rank 5
2023-03-01 09:00:47,354 DEBUG TRAIN Batch 52/7000 loss 2.449957 loss_att 5.847790 loss_ctc 3.171725 loss_rnnt 1.483491 hw_loss 0.357494 lr 0.00028968 rank 1
2023-03-01 09:00:47,356 DEBUG TRAIN Batch 52/7000 loss 4.422285 loss_att 6.672858 loss_ctc 7.976911 loss_rnnt 3.365835 hw_loss 0.248222 lr 0.00028968 rank 6
2023-03-01 09:00:47,370 DEBUG TRAIN Batch 52/7000 loss 3.454737 loss_att 4.743782 loss_ctc 4.448931 loss_rnnt 2.945280 hw_loss 0.223290 lr 0.00028968 rank 2
2023-03-01 09:00:47,372 DEBUG TRAIN Batch 52/7000 loss 13.925455 loss_att 15.712490 loss_ctc 27.913904 loss_rnnt 11.544029 hw_loss 0.297924 lr 0.00028967 rank 7
2023-03-01 09:00:47,372 DEBUG TRAIN Batch 52/7000 loss 3.694406 loss_att 3.967041 loss_ctc 4.668808 loss_rnnt 3.360603 hw_loss 0.280043 lr 0.00028968 rank 0
2023-03-01 09:00:47,378 DEBUG TRAIN Batch 52/7000 loss 6.389500 loss_att 7.697257 loss_ctc 10.621472 loss_rnnt 5.389579 hw_loss 0.326448 lr 0.00028967 rank 3
2023-03-01 09:00:47,391 DEBUG TRAIN Batch 52/7000 loss 4.204264 loss_att 6.798111 loss_ctc 8.021107 loss_rnnt 3.024322 hw_loss 0.285489 lr 0.00028967 rank 5
2023-03-01 09:00:47,397 DEBUG TRAIN Batch 52/7000 loss 4.757147 loss_att 8.722175 loss_ctc 8.055960 loss_rnnt 3.394896 hw_loss 0.242633 lr 0.00028968 rank 4
2023-03-01 09:01:49,061 DEBUG TRAIN Batch 52/7100 loss 3.726295 loss_att 6.584128 loss_ctc 9.235443 loss_rnnt 2.264143 hw_loss 0.292561 lr 0.00028967 rank 2
2023-03-01 09:01:49,064 DEBUG TRAIN Batch 52/7100 loss 2.869056 loss_att 4.461719 loss_ctc 5.996625 loss_rnnt 2.001087 hw_loss 0.248302 lr 0.00028965 rank 7
2023-03-01 09:01:49,075 DEBUG TRAIN Batch 52/7100 loss 1.414071 loss_att 3.217247 loss_ctc 3.095435 loss_rnnt 0.802632 hw_loss 0.049915 lr 0.00028967 rank 0
2023-03-01 09:01:49,075 DEBUG TRAIN Batch 52/7100 loss 6.269480 loss_att 9.641335 loss_ctc 6.971720 loss_rnnt 5.390905 hw_loss 0.207322 lr 0.00028966 rank 3
2023-03-01 09:01:49,076 DEBUG TRAIN Batch 52/7100 loss 7.213932 loss_att 11.399561 loss_ctc 13.715792 loss_rnnt 5.407767 hw_loss 0.191482 lr 0.00028966 rank 6
2023-03-01 09:01:49,082 DEBUG TRAIN Batch 52/7100 loss 2.828194 loss_att 5.301741 loss_ctc 5.082668 loss_rnnt 1.924622 hw_loss 0.202998 lr 0.00028966 rank 1
2023-03-01 09:01:49,091 DEBUG TRAIN Batch 52/7100 loss 11.711788 loss_att 16.049900 loss_ctc 24.670444 loss_rnnt 9.033793 hw_loss 0.154783 lr 0.00028967 rank 4
2023-03-01 09:01:49,096 DEBUG TRAIN Batch 52/7100 loss 14.548157 loss_att 18.474834 loss_ctc 28.927847 loss_rnnt 11.740339 hw_loss 0.197232 lr 0.00028966 rank 5
2023-03-01 09:02:32,973 DEBUG TRAIN Batch 52/7200 loss 6.155843 loss_att 10.572192 loss_ctc 12.633429 loss_rnnt 4.313295 hw_loss 0.179250 lr 0.00028964 rank 7
2023-03-01 09:02:32,974 DEBUG TRAIN Batch 52/7200 loss 2.845406 loss_att 6.888934 loss_ctc 3.551926 loss_rnnt 1.803582 hw_loss 0.260467 lr 0.00028966 rank 0
2023-03-01 09:02:32,990 DEBUG TRAIN Batch 52/7200 loss 5.209442 loss_att 8.555852 loss_ctc 11.508522 loss_rnnt 3.632063 hw_loss 0.127912 lr 0.00028965 rank 4
2023-03-01 09:02:32,993 DEBUG TRAIN Batch 52/7200 loss 5.407701 loss_att 7.455723 loss_ctc 11.668068 loss_rnnt 4.063165 hw_loss 0.187905 lr 0.00028965 rank 5
2023-03-01 09:02:32,995 DEBUG TRAIN Batch 52/7200 loss 10.669557 loss_att 11.745047 loss_ctc 13.849883 loss_rnnt 9.918296 hw_loss 0.210226 lr 0.00028965 rank 6
2023-03-01 09:02:32,995 DEBUG TRAIN Batch 52/7200 loss 7.459632 loss_att 8.977949 loss_ctc 10.422264 loss_rnnt 6.693794 hw_loss 0.125919 lr 0.00028966 rank 2
2023-03-01 09:02:32,996 DEBUG TRAIN Batch 52/7200 loss 2.569585 loss_att 4.818139 loss_ctc 3.454642 loss_rnnt 1.851935 hw_loss 0.281123 lr 0.00028965 rank 3
2023-03-01 09:02:32,999 DEBUG TRAIN Batch 52/7200 loss 5.794901 loss_att 10.644203 loss_ctc 11.450068 loss_rnnt 3.942104 hw_loss 0.241714 lr 0.00028965 rank 1
2023-03-01 09:03:11,638 DEBUG TRAIN Batch 52/7300 loss 5.691482 loss_att 8.520552 loss_ctc 10.845959 loss_rnnt 4.339092 hw_loss 0.186211 lr 0.00028964 rank 1
2023-03-01 09:03:11,639 DEBUG TRAIN Batch 52/7300 loss 1.420440 loss_att 4.163336 loss_ctc 2.772320 loss_rnnt 0.599787 hw_loss 0.172168 lr 0.00028963 rank 7
2023-03-01 09:03:11,640 DEBUG TRAIN Batch 52/7300 loss 4.157657 loss_att 6.947633 loss_ctc 6.242241 loss_rnnt 3.180452 hw_loss 0.264872 lr 0.00028964 rank 2
2023-03-01 09:03:11,640 DEBUG TRAIN Batch 52/7300 loss 10.155285 loss_att 13.233114 loss_ctc 18.316671 loss_rnnt 8.284615 hw_loss 0.312975 lr 0.00028963 rank 3
2023-03-01 09:03:11,641 DEBUG TRAIN Batch 52/7300 loss 6.688494 loss_att 10.039429 loss_ctc 11.515523 loss_rnnt 5.226310 hw_loss 0.278236 lr 0.00028964 rank 6
2023-03-01 09:03:11,645 DEBUG TRAIN Batch 52/7300 loss 2.167239 loss_att 4.336986 loss_ctc 2.728736 loss_rnnt 1.504190 hw_loss 0.289187 lr 0.00028964 rank 4
2023-03-01 09:03:11,655 DEBUG TRAIN Batch 52/7300 loss 8.464535 loss_att 13.216978 loss_ctc 15.768870 loss_rnnt 6.450833 hw_loss 0.167442 lr 0.00028964 rank 0
2023-03-01 09:03:11,679 DEBUG TRAIN Batch 52/7300 loss 3.192308 loss_att 6.516870 loss_ctc 5.276876 loss_rnnt 2.187823 hw_loss 0.115557 lr 0.00028963 rank 5
2023-03-01 09:03:50,298 DEBUG TRAIN Batch 52/7400 loss 4.634608 loss_att 6.554226 loss_ctc 6.459778 loss_rnnt 3.841698 hw_loss 0.310557 lr 0.00028963 rank 6
2023-03-01 09:03:50,299 DEBUG TRAIN Batch 52/7400 loss 6.782021 loss_att 11.665843 loss_ctc 14.111351 loss_rnnt 4.673401 hw_loss 0.289896 lr 0.00028962 rank 3
2023-03-01 09:03:50,300 DEBUG TRAIN Batch 52/7400 loss 4.299520 loss_att 7.217011 loss_ctc 6.791936 loss_rnnt 3.247487 hw_loss 0.255396 lr 0.00028963 rank 1
2023-03-01 09:03:50,308 DEBUG TRAIN Batch 52/7400 loss 5.448572 loss_att 7.349992 loss_ctc 8.621691 loss_rnnt 4.565770 hw_loss 0.148941 lr 0.00028963 rank 0
2023-03-01 09:03:50,317 DEBUG TRAIN Batch 52/7400 loss 1.983680 loss_att 5.985359 loss_ctc 5.660597 loss_rnnt 0.660148 hw_loss 0.061763 lr 0.00028962 rank 7
2023-03-01 09:03:50,324 DEBUG TRAIN Batch 52/7400 loss 9.837661 loss_att 13.481981 loss_ctc 15.970204 loss_rnnt 8.235305 hw_loss 0.104660 lr 0.00028963 rank 2
2023-03-01 09:03:50,352 DEBUG TRAIN Batch 52/7400 loss 6.484684 loss_att 9.747619 loss_ctc 13.435044 loss_rnnt 4.818737 hw_loss 0.162461 lr 0.00028963 rank 4
2023-03-01 09:03:50,361 DEBUG TRAIN Batch 52/7400 loss 9.030823 loss_att 9.567105 loss_ctc 13.633761 loss_rnnt 8.253813 hw_loss 0.105051 lr 0.00028962 rank 5
2023-03-01 09:04:56,898 DEBUG TRAIN Batch 52/7500 loss 10.446935 loss_att 14.047260 loss_ctc 17.850435 loss_rnnt 8.658424 hw_loss 0.152459 lr 0.00028961 rank 7
2023-03-01 09:04:56,899 DEBUG TRAIN Batch 52/7500 loss 5.662017 loss_att 10.132931 loss_ctc 9.457418 loss_rnnt 4.120967 hw_loss 0.264026 lr 0.00028962 rank 0
2023-03-01 09:04:56,905 DEBUG TRAIN Batch 52/7500 loss 10.440369 loss_att 12.479858 loss_ctc 16.451727 loss_rnnt 9.080130 hw_loss 0.282800 lr 0.00028962 rank 4
2023-03-01 09:04:56,908 DEBUG TRAIN Batch 52/7500 loss 3.499658 loss_att 5.565970 loss_ctc 5.014121 loss_rnnt 2.777477 hw_loss 0.200606 lr 0.00028962 rank 2
2023-03-01 09:04:56,910 DEBUG TRAIN Batch 52/7500 loss 7.743863 loss_att 8.200853 loss_ctc 9.506787 loss_rnnt 7.300978 hw_loss 0.218304 lr 0.00028961 rank 3
2023-03-01 09:04:56,911 DEBUG TRAIN Batch 52/7500 loss 7.694018 loss_att 9.107535 loss_ctc 11.385597 loss_rnnt 6.801214 hw_loss 0.221044 lr 0.00028961 rank 6
2023-03-01 09:04:56,914 DEBUG TRAIN Batch 52/7500 loss 10.907853 loss_att 12.807341 loss_ctc 15.343149 loss_rnnt 9.846690 hw_loss 0.168548 lr 0.00028961 rank 5
2023-03-01 09:04:56,957 DEBUG TRAIN Batch 52/7500 loss 6.597687 loss_att 7.291171 loss_ctc 7.526214 loss_rnnt 6.222696 hw_loss 0.210921 lr 0.00028962 rank 1
2023-03-01 09:05:36,207 DEBUG TRAIN Batch 52/7600 loss 3.832843 loss_att 4.028569 loss_ctc 6.488168 loss_rnnt 3.239872 hw_loss 0.374592 lr 0.00028960 rank 6
2023-03-01 09:05:36,218 DEBUG TRAIN Batch 52/7600 loss 5.789763 loss_att 7.691941 loss_ctc 10.213267 loss_rnnt 4.714597 hw_loss 0.196746 lr 0.00028960 rank 3
2023-03-01 09:05:36,223 DEBUG TRAIN Batch 52/7600 loss 3.885970 loss_att 5.519264 loss_ctc 6.700456 loss_rnnt 3.055406 hw_loss 0.241200 lr 0.00028960 rank 5
2023-03-01 09:05:36,225 DEBUG TRAIN Batch 52/7600 loss 5.824385 loss_att 7.067063 loss_ctc 8.956957 loss_rnnt 5.023544 hw_loss 0.252430 lr 0.00028961 rank 0
2023-03-01 09:05:36,226 DEBUG TRAIN Batch 52/7600 loss 3.226171 loss_att 5.793082 loss_ctc 7.393562 loss_rnnt 2.031243 hw_loss 0.236051 lr 0.00028959 rank 7
2023-03-01 09:05:36,230 DEBUG TRAIN Batch 52/7600 loss 7.025272 loss_att 12.628252 loss_ctc 16.496342 loss_rnnt 4.549202 hw_loss 0.173745 lr 0.00028961 rank 4
2023-03-01 09:05:36,231 DEBUG TRAIN Batch 52/7600 loss 11.202877 loss_att 14.841483 loss_ctc 19.514172 loss_rnnt 9.217230 hw_loss 0.280787 lr 0.00028960 rank 1
2023-03-01 09:05:36,232 DEBUG TRAIN Batch 52/7600 loss 8.729821 loss_att 10.553435 loss_ctc 15.710260 loss_rnnt 7.246540 hw_loss 0.352188 lr 0.00028961 rank 2
2023-03-01 09:06:14,760 DEBUG TRAIN Batch 52/7700 loss 7.202135 loss_att 10.515283 loss_ctc 15.092235 loss_rnnt 5.344997 hw_loss 0.267177 lr 0.00028959 rank 5
2023-03-01 09:06:14,760 DEBUG TRAIN Batch 52/7700 loss 10.881978 loss_att 15.844449 loss_ctc 13.095714 loss_rnnt 9.489027 hw_loss 0.197422 lr 0.00028960 rank 2
2023-03-01 09:06:14,768 DEBUG TRAIN Batch 52/7700 loss 6.383079 loss_att 9.057936 loss_ctc 12.154887 loss_rnnt 4.971065 hw_loss 0.201502 lr 0.00028958 rank 7
2023-03-01 09:06:14,771 DEBUG TRAIN Batch 52/7700 loss 6.983372 loss_att 9.863344 loss_ctc 11.830951 loss_rnnt 5.612587 hw_loss 0.278337 lr 0.00028960 rank 0
2023-03-01 09:06:14,775 DEBUG TRAIN Batch 52/7700 loss 4.529708 loss_att 6.582231 loss_ctc 7.329084 loss_rnnt 3.648332 hw_loss 0.183040 lr 0.00028958 rank 3
2023-03-01 09:06:14,777 DEBUG TRAIN Batch 52/7700 loss 3.674188 loss_att 5.950810 loss_ctc 5.748786 loss_rnnt 2.774066 hw_loss 0.315346 lr 0.00028959 rank 6
2023-03-01 09:06:14,801 DEBUG TRAIN Batch 52/7700 loss 1.763778 loss_att 3.998182 loss_ctc 3.227128 loss_rnnt 0.975907 hw_loss 0.273519 lr 0.00028959 rank 1
2023-03-01 09:06:14,809 DEBUG TRAIN Batch 52/7700 loss 3.135980 loss_att 5.799285 loss_ctc 5.492274 loss_rnnt 2.089447 hw_loss 0.374437 lr 0.00028959 rank 4
2023-03-01 09:07:15,914 DEBUG TRAIN Batch 52/7800 loss 5.611047 loss_att 6.567565 loss_ctc 8.540616 loss_rnnt 4.976245 hw_loss 0.099166 lr 0.00028958 rank 2
2023-03-01 09:07:15,926 DEBUG TRAIN Batch 52/7800 loss 11.158031 loss_att 13.685778 loss_ctc 17.996557 loss_rnnt 9.599220 hw_loss 0.265234 lr 0.00028958 rank 4
2023-03-01 09:07:15,928 DEBUG TRAIN Batch 52/7800 loss 9.981309 loss_att 12.961263 loss_ctc 16.764038 loss_rnnt 8.382904 hw_loss 0.183844 lr 0.00028958 rank 1
2023-03-01 09:07:15,932 DEBUG TRAIN Batch 52/7800 loss 12.159526 loss_att 13.509090 loss_ctc 17.269041 loss_rnnt 11.170759 hw_loss 0.070473 lr 0.00028957 rank 5
2023-03-01 09:07:15,934 DEBUG TRAIN Batch 52/7800 loss 1.659408 loss_att 3.500963 loss_ctc 2.358738 loss_rnnt 1.045756 hw_loss 0.285181 lr 0.00028958 rank 0
2023-03-01 09:07:15,937 DEBUG TRAIN Batch 52/7800 loss 2.364882 loss_att 5.432733 loss_ctc 6.070621 loss_rnnt 1.199080 hw_loss 0.109001 lr 0.00028958 rank 6
2023-03-01 09:07:15,976 DEBUG TRAIN Batch 52/7800 loss 2.737399 loss_att 5.667892 loss_ctc 6.493597 loss_rnnt 1.546237 hw_loss 0.195445 lr 0.00028957 rank 3
2023-03-01 09:07:16,014 DEBUG TRAIN Batch 52/7800 loss 7.456339 loss_att 7.995542 loss_ctc 9.755490 loss_rnnt 6.879146 hw_loss 0.305248 lr 0.00028957 rank 7
2023-03-01 09:08:00,211 DEBUG TRAIN Batch 52/7900 loss 5.797626 loss_att 9.780929 loss_ctc 10.136532 loss_rnnt 4.321054 hw_loss 0.190106 lr 0.00028956 rank 7
2023-03-01 09:08:00,226 DEBUG TRAIN Batch 52/7900 loss 1.854563 loss_att 4.135479 loss_ctc 3.066797 loss_rnnt 1.110362 hw_loss 0.236975 lr 0.00028957 rank 6
2023-03-01 09:08:00,228 DEBUG TRAIN Batch 52/7900 loss 2.343351 loss_att 4.574505 loss_ctc 2.762710 loss_rnnt 1.701444 hw_loss 0.262054 lr 0.00028956 rank 5
2023-03-01 09:08:00,228 DEBUG TRAIN Batch 52/7900 loss 1.175920 loss_att 2.995087 loss_ctc 1.961528 loss_rnnt 0.580969 hw_loss 0.236943 lr 0.00028957 rank 2
2023-03-01 09:08:00,232 DEBUG TRAIN Batch 52/7900 loss 3.007590 loss_att 4.415551 loss_ctc 5.779913 loss_rnnt 2.183302 hw_loss 0.324474 lr 0.00028957 rank 1
2023-03-01 09:08:00,232 DEBUG TRAIN Batch 52/7900 loss 10.492554 loss_att 12.463209 loss_ctc 16.688221 loss_rnnt 9.141383 hw_loss 0.245533 lr 0.00028957 rank 0
2023-03-01 09:08:00,232 DEBUG TRAIN Batch 52/7900 loss 8.356780 loss_att 10.305484 loss_ctc 15.703038 loss_rnnt 6.987442 hw_loss 0.000182 lr 0.00028956 rank 3
2023-03-01 09:08:00,279 DEBUG TRAIN Batch 52/7900 loss 8.560043 loss_att 13.213058 loss_ctc 13.619823 loss_rnnt 6.878509 hw_loss 0.143050 lr 0.00028957 rank 4
2023-03-01 09:08:38,778 DEBUG TRAIN Batch 52/8000 loss 4.999542 loss_att 7.361381 loss_ctc 10.128616 loss_rnnt 3.770578 hw_loss 0.136349 lr 0.00028955 rank 6
2023-03-01 09:08:38,784 DEBUG TRAIN Batch 52/8000 loss 8.213448 loss_att 10.407795 loss_ctc 12.896482 loss_rnnt 7.037522 hw_loss 0.211221 lr 0.00028955 rank 3
2023-03-01 09:08:38,788 DEBUG TRAIN Batch 52/8000 loss 7.802440 loss_att 10.488986 loss_ctc 16.048105 loss_rnnt 6.051014 hw_loss 0.215053 lr 0.00028956 rank 4
2023-03-01 09:08:38,791 DEBUG TRAIN Batch 52/8000 loss 3.154676 loss_att 6.897447 loss_ctc 6.969406 loss_rnnt 1.805557 hw_loss 0.172375 lr 0.00028956 rank 0
2023-03-01 09:08:38,793 DEBUG TRAIN Batch 52/8000 loss 4.520639 loss_att 8.422107 loss_ctc 6.670244 loss_rnnt 3.360861 hw_loss 0.174132 lr 0.00028956 rank 1
2023-03-01 09:08:38,794 DEBUG TRAIN Batch 52/8000 loss 7.375999 loss_att 9.357445 loss_ctc 12.938810 loss_rnnt 6.115908 hw_loss 0.228925 lr 0.00028955 rank 5
2023-03-01 09:08:38,795 DEBUG TRAIN Batch 52/8000 loss 16.034271 loss_att 18.467581 loss_ctc 25.375206 loss_rnnt 14.157270 hw_loss 0.271655 lr 0.00028955 rank 7
2023-03-01 09:08:38,800 DEBUG TRAIN Batch 52/8000 loss 5.464614 loss_att 8.053366 loss_ctc 12.057524 loss_rnnt 4.007609 hw_loss 0.112874 lr 0.00028956 rank 2
2023-03-01 09:09:17,914 DEBUG TRAIN Batch 52/8100 loss 4.671522 loss_att 6.785382 loss_ctc 6.793659 loss_rnnt 3.807462 hw_loss 0.296879 lr 0.00028954 rank 1
2023-03-01 09:09:17,917 DEBUG TRAIN Batch 52/8100 loss 7.485948 loss_att 10.380378 loss_ctc 8.660604 loss_rnnt 6.714593 hw_loss 0.067215 lr 0.00028954 rank 5
2023-03-01 09:09:17,917 DEBUG TRAIN Batch 52/8100 loss 8.423916 loss_att 9.131773 loss_ctc 13.114629 loss_rnnt 7.609303 hw_loss 0.089274 lr 0.00028954 rank 6
2023-03-01 09:09:17,919 DEBUG TRAIN Batch 52/8100 loss 5.738190 loss_att 8.223590 loss_ctc 8.162536 loss_rnnt 4.796186 hw_loss 0.228144 lr 0.00028953 rank 7
2023-03-01 09:09:17,928 DEBUG TRAIN Batch 52/8100 loss 7.780855 loss_att 9.703207 loss_ctc 9.636144 loss_rnnt 7.027964 hw_loss 0.226964 lr 0.00028954 rank 3
2023-03-01 09:09:17,930 DEBUG TRAIN Batch 52/8100 loss 9.529859 loss_att 10.065403 loss_ctc 13.361028 loss_rnnt 8.812602 hw_loss 0.186233 lr 0.00028955 rank 0
2023-03-01 09:09:17,933 DEBUG TRAIN Batch 52/8100 loss 7.129306 loss_att 11.514580 loss_ctc 11.393741 loss_rnnt 5.541168 hw_loss 0.267172 lr 0.00028955 rank 4
2023-03-01 09:09:17,934 DEBUG TRAIN Batch 52/8100 loss 4.951195 loss_att 6.441055 loss_ctc 7.409678 loss_rnnt 4.264085 hw_loss 0.115013 lr 0.00028955 rank 2
2023-03-01 09:09:58,352 DEBUG TRAIN Batch 52/8200 loss 9.777461 loss_att 13.081253 loss_ctc 22.812458 loss_rnnt 7.300415 hw_loss 0.146790 lr 0.00028952 rank 7
2023-03-01 09:09:58,353 DEBUG TRAIN Batch 52/8200 loss 4.694543 loss_att 8.043311 loss_ctc 7.928871 loss_rnnt 3.546299 hw_loss 0.088588 lr 0.00028953 rank 0
2023-03-01 09:09:58,355 DEBUG TRAIN Batch 52/8200 loss 8.391744 loss_att 9.669320 loss_ctc 14.574261 loss_rnnt 7.155294 hw_loss 0.293622 lr 0.00028953 rank 2
2023-03-01 09:09:58,357 DEBUG TRAIN Batch 52/8200 loss 7.130814 loss_att 8.773952 loss_ctc 12.696942 loss_rnnt 5.968005 hw_loss 0.172557 lr 0.00028953 rank 6
2023-03-01 09:09:58,357 DEBUG TRAIN Batch 52/8200 loss 6.436321 loss_att 9.829306 loss_ctc 10.692069 loss_rnnt 5.078215 hw_loss 0.210144 lr 0.00028953 rank 5
2023-03-01 09:09:58,358 DEBUG TRAIN Batch 52/8200 loss 8.773931 loss_att 10.945093 loss_ctc 14.519974 loss_rnnt 7.390206 hw_loss 0.343784 lr 0.00028953 rank 4
2023-03-01 09:09:58,369 DEBUG TRAIN Batch 52/8200 loss 5.641937 loss_att 8.826118 loss_ctc 9.614314 loss_rnnt 4.377282 hw_loss 0.184066 lr 0.00028952 rank 3
2023-03-01 09:09:58,405 DEBUG TRAIN Batch 52/8200 loss 16.732615 loss_att 17.203392 loss_ctc 21.961134 loss_rnnt 15.941227 hw_loss 0.000181 lr 0.00028953 rank 1
2023-03-01 09:10:36,484 DEBUG TRAIN Batch 52/8300 loss 4.190316 loss_att 6.280654 loss_ctc 6.806904 loss_rnnt 3.338737 hw_loss 0.158686 lr 0.00028952 rank 1
2023-03-01 09:10:36,486 DEBUG TRAIN Batch 52/8300 loss 5.408056 loss_att 7.329797 loss_ctc 8.912506 loss_rnnt 4.540504 hw_loss 0.029895 lr 0.00028952 rank 4
2023-03-01 09:10:36,493 DEBUG TRAIN Batch 52/8300 loss 7.985012 loss_att 10.202883 loss_ctc 15.047351 loss_rnnt 6.523864 hw_loss 0.142367 lr 0.00028952 rank 0
2023-03-01 09:10:36,496 DEBUG TRAIN Batch 52/8300 loss 4.419520 loss_att 7.890850 loss_ctc 8.347826 loss_rnnt 3.133785 hw_loss 0.126930 lr 0.00028951 rank 7
2023-03-01 09:10:36,496 DEBUG TRAIN Batch 52/8300 loss 3.048081 loss_att 6.593865 loss_ctc 8.648791 loss_rnnt 1.478164 hw_loss 0.213748 lr 0.00028952 rank 6
2023-03-01 09:10:36,497 DEBUG TRAIN Batch 52/8300 loss 4.851716 loss_att 7.676163 loss_ctc 8.121104 loss_rnnt 3.724687 hw_loss 0.236665 lr 0.00028951 rank 3
2023-03-01 09:10:36,498 DEBUG TRAIN Batch 52/8300 loss 5.764835 loss_att 6.272519 loss_ctc 8.658797 loss_rnnt 5.080367 hw_loss 0.369505 lr 0.00028951 rank 5
2023-03-01 09:10:36,502 DEBUG TRAIN Batch 52/8300 loss 9.850845 loss_att 10.791467 loss_ctc 16.061064 loss_rnnt 8.727729 hw_loss 0.200556 lr 0.00028952 rank 2
2023-03-01 09:11:04,671 DEBUG CV Batch 52/0 loss 1.007422 loss_att 1.060044 loss_ctc 2.084640 loss_rnnt 0.642688 hw_loss 0.394839 history loss 0.970110 rank 4
2023-03-01 09:11:04,676 DEBUG CV Batch 52/0 loss 1.007422 loss_att 1.060044 loss_ctc 2.084640 loss_rnnt 0.642688 hw_loss 0.394839 history loss 0.970110 rank 2
2023-03-01 09:11:04,679 DEBUG CV Batch 52/0 loss 1.007422 loss_att 1.060044 loss_ctc 2.084640 loss_rnnt 0.642688 hw_loss 0.394839 history loss 0.970110 rank 5
2023-03-01 09:11:04,682 DEBUG CV Batch 52/0 loss 1.007422 loss_att 1.060044 loss_ctc 2.084640 loss_rnnt 0.642688 hw_loss 0.394839 history loss 0.970110 rank 0
2023-03-01 09:11:04,686 DEBUG CV Batch 52/0 loss 1.007422 loss_att 1.060044 loss_ctc 2.084640 loss_rnnt 0.642688 hw_loss 0.394839 history loss 0.970110 rank 6
2023-03-01 09:11:04,695 DEBUG CV Batch 52/0 loss 1.007422 loss_att 1.060044 loss_ctc 2.084640 loss_rnnt 0.642688 hw_loss 0.394839 history loss 0.970110 rank 7
2023-03-01 09:11:04,713 DEBUG CV Batch 52/0 loss 1.007422 loss_att 1.060044 loss_ctc 2.084640 loss_rnnt 0.642688 hw_loss 0.394839 history loss 0.970110 rank 3
2023-03-01 09:11:04,719 DEBUG CV Batch 52/0 loss 1.007422 loss_att 1.060044 loss_ctc 2.084640 loss_rnnt 0.642688 hw_loss 0.394839 history loss 0.970110 rank 1
2023-03-01 09:11:16,086 DEBUG CV Batch 52/100 loss 3.621822 loss_att 4.735383 loss_ctc 9.049454 loss_rnnt 2.564137 hw_loss 0.208666 history loss 2.983707 rank 6
2023-03-01 09:11:16,104 DEBUG CV Batch 52/100 loss 3.621822 loss_att 4.735383 loss_ctc 9.049454 loss_rnnt 2.564137 hw_loss 0.208666 history loss 2.983707 rank 4
2023-03-01 09:11:16,152 DEBUG CV Batch 52/100 loss 3.621822 loss_att 4.735383 loss_ctc 9.049454 loss_rnnt 2.564137 hw_loss 0.208666 history loss 2.983707 rank 1
2023-03-01 09:11:16,346 DEBUG CV Batch 52/100 loss 3.621822 loss_att 4.735383 loss_ctc 9.049454 loss_rnnt 2.564137 hw_loss 0.208666 history loss 2.983707 rank 3
2023-03-01 09:11:16,404 DEBUG CV Batch 52/100 loss 3.621822 loss_att 4.735383 loss_ctc 9.049454 loss_rnnt 2.564137 hw_loss 0.208666 history loss 2.983707 rank 2
2023-03-01 09:11:16,416 DEBUG CV Batch 52/100 loss 3.621822 loss_att 4.735383 loss_ctc 9.049454 loss_rnnt 2.564137 hw_loss 0.208666 history loss 2.983707 rank 0
2023-03-01 09:11:16,450 DEBUG CV Batch 52/100 loss 3.621822 loss_att 4.735383 loss_ctc 9.049454 loss_rnnt 2.564137 hw_loss 0.208666 history loss 2.983707 rank 7
2023-03-01 09:11:16,481 DEBUG CV Batch 52/100 loss 3.621822 loss_att 4.735383 loss_ctc 9.049454 loss_rnnt 2.564137 hw_loss 0.208666 history loss 2.983707 rank 5
2023-03-01 09:11:29,576 DEBUG CV Batch 52/200 loss 4.608339 loss_att 7.950890 loss_ctc 6.431698 loss_rnnt 3.634086 hw_loss 0.117429 history loss 3.593454 rank 1
2023-03-01 09:11:29,644 DEBUG CV Batch 52/200 loss 4.608339 loss_att 7.950890 loss_ctc 6.431698 loss_rnnt 3.634086 hw_loss 0.117429 history loss 3.593454 rank 4
2023-03-01 09:11:29,799 DEBUG CV Batch 52/200 loss 4.608339 loss_att 7.950890 loss_ctc 6.431698 loss_rnnt 3.634086 hw_loss 0.117429 history loss 3.593454 rank 6
2023-03-01 09:11:29,935 DEBUG CV Batch 52/200 loss 4.608339 loss_att 7.950890 loss_ctc 6.431698 loss_rnnt 3.634086 hw_loss 0.117429 history loss 3.593454 rank 5
2023-03-01 09:11:29,942 DEBUG CV Batch 52/200 loss 4.608339 loss_att 7.950890 loss_ctc 6.431698 loss_rnnt 3.634086 hw_loss 0.117429 history loss 3.593454 rank 3
2023-03-01 09:11:30,185 DEBUG CV Batch 52/200 loss 4.608339 loss_att 7.950890 loss_ctc 6.431698 loss_rnnt 3.634086 hw_loss 0.117429 history loss 3.593454 rank 7
2023-03-01 09:11:30,273 DEBUG CV Batch 52/200 loss 4.608339 loss_att 7.950890 loss_ctc 6.431698 loss_rnnt 3.634086 hw_loss 0.117429 history loss 3.593454 rank 2
2023-03-01 09:11:30,376 DEBUG CV Batch 52/200 loss 4.608339 loss_att 7.950890 loss_ctc 6.431698 loss_rnnt 3.634086 hw_loss 0.117429 history loss 3.593454 rank 0
2023-03-01 09:11:41,673 DEBUG CV Batch 52/300 loss 3.888795 loss_att 4.423656 loss_ctc 7.253770 loss_rnnt 3.135091 hw_loss 0.371377 history loss 3.735560 rank 1
2023-03-01 09:11:41,746 DEBUG CV Batch 52/300 loss 3.888795 loss_att 4.423656 loss_ctc 7.253770 loss_rnnt 3.135091 hw_loss 0.371377 history loss 3.735560 rank 4
2023-03-01 09:11:42,204 DEBUG CV Batch 52/300 loss 3.888795 loss_att 4.423656 loss_ctc 7.253770 loss_rnnt 3.135091 hw_loss 0.371377 history loss 3.735560 rank 5
2023-03-01 09:11:42,380 DEBUG CV Batch 52/300 loss 3.888795 loss_att 4.423656 loss_ctc 7.253770 loss_rnnt 3.135091 hw_loss 0.371377 history loss 3.735560 rank 2
2023-03-01 09:11:42,669 DEBUG CV Batch 52/300 loss 3.888795 loss_att 4.423656 loss_ctc 7.253770 loss_rnnt 3.135091 hw_loss 0.371377 history loss 3.735560 rank 3
2023-03-01 09:11:42,674 DEBUG CV Batch 52/300 loss 3.888795 loss_att 4.423656 loss_ctc 7.253770 loss_rnnt 3.135091 hw_loss 0.371377 history loss 3.735560 rank 7
2023-03-01 09:11:42,890 DEBUG CV Batch 52/300 loss 3.888795 loss_att 4.423656 loss_ctc 7.253770 loss_rnnt 3.135091 hw_loss 0.371377 history loss 3.735560 rank 6
2023-03-01 09:11:43,060 DEBUG CV Batch 52/300 loss 3.888795 loss_att 4.423656 loss_ctc 7.253770 loss_rnnt 3.135091 hw_loss 0.371377 history loss 3.735560 rank 0
2023-03-01 09:11:53,855 DEBUG CV Batch 52/400 loss 12.381781 loss_att 55.431416 loss_ctc 5.223701 loss_rnnt 4.725933 hw_loss 0.000620 history loss 4.510083 rank 1
2023-03-01 09:11:53,866 DEBUG CV Batch 52/400 loss 12.381781 loss_att 55.431416 loss_ctc 5.223701 loss_rnnt 4.725933 hw_loss 0.000620 history loss 4.510083 rank 4
2023-03-01 09:11:54,683 DEBUG CV Batch 52/400 loss 12.381781 loss_att 55.431416 loss_ctc 5.223701 loss_rnnt 4.725933 hw_loss 0.000620 history loss 4.510083 rank 2
2023-03-01 09:11:54,784 DEBUG CV Batch 52/400 loss 12.381781 loss_att 55.431416 loss_ctc 5.223701 loss_rnnt 4.725933 hw_loss 0.000620 history loss 4.510083 rank 5
2023-03-01 09:11:54,995 DEBUG CV Batch 52/400 loss 12.381781 loss_att 55.431416 loss_ctc 5.223701 loss_rnnt 4.725933 hw_loss 0.000620 history loss 4.510083 rank 7
2023-03-01 09:11:55,019 DEBUG CV Batch 52/400 loss 12.381781 loss_att 55.431416 loss_ctc 5.223701 loss_rnnt 4.725933 hw_loss 0.000620 history loss 4.510083 rank 3
2023-03-01 09:11:55,575 DEBUG CV Batch 52/400 loss 12.381781 loss_att 55.431416 loss_ctc 5.223701 loss_rnnt 4.725933 hw_loss 0.000620 history loss 4.510083 rank 6
2023-03-01 09:11:55,691 DEBUG CV Batch 52/400 loss 12.381781 loss_att 55.431416 loss_ctc 5.223701 loss_rnnt 4.725933 hw_loss 0.000620 history loss 4.510083 rank 0
2023-03-01 09:12:04,326 DEBUG CV Batch 52/500 loss 4.252957 loss_att 4.251470 loss_ctc 6.266128 loss_rnnt 3.851046 hw_loss 0.250848 history loss 5.118838 rank 4
2023-03-01 09:12:04,516 DEBUG CV Batch 52/500 loss 4.252957 loss_att 4.251470 loss_ctc 6.266128 loss_rnnt 3.851046 hw_loss 0.250848 history loss 5.118838 rank 1
2023-03-01 09:12:05,243 DEBUG CV Batch 52/500 loss 4.252957 loss_att 4.251470 loss_ctc 6.266128 loss_rnnt 3.851046 hw_loss 0.250848 history loss 5.118838 rank 5
2023-03-01 09:12:05,650 DEBUG CV Batch 52/500 loss 4.252957 loss_att 4.251470 loss_ctc 6.266128 loss_rnnt 3.851046 hw_loss 0.250848 history loss 5.118838 rank 2
2023-03-01 09:12:05,918 DEBUG CV Batch 52/500 loss 4.252957 loss_att 4.251470 loss_ctc 6.266128 loss_rnnt 3.851046 hw_loss 0.250848 history loss 5.118838 rank 7
2023-03-01 09:12:06,194 DEBUG CV Batch 52/500 loss 4.252957 loss_att 4.251470 loss_ctc 6.266128 loss_rnnt 3.851046 hw_loss 0.250848 history loss 5.118838 rank 3
2023-03-01 09:12:06,901 DEBUG CV Batch 52/500 loss 4.252957 loss_att 4.251470 loss_ctc 6.266128 loss_rnnt 3.851046 hw_loss 0.250848 history loss 5.118838 rank 0
2023-03-01 09:12:07,003 DEBUG CV Batch 52/500 loss 4.252957 loss_att 4.251470 loss_ctc 6.266128 loss_rnnt 3.851046 hw_loss 0.250848 history loss 5.118838 rank 6
2023-03-01 09:12:16,415 DEBUG CV Batch 52/600 loss 7.059933 loss_att 6.228775 loss_ctc 10.189755 loss_rnnt 6.678396 hw_loss 0.244609 history loss 5.991502 rank 4
2023-03-01 09:12:16,793 DEBUG CV Batch 52/600 loss 7.059933 loss_att 6.228775 loss_ctc 10.189755 loss_rnnt 6.678396 hw_loss 0.244609 history loss 5.991502 rank 1
2023-03-01 09:12:17,344 DEBUG CV Batch 52/600 loss 7.059933 loss_att 6.228775 loss_ctc 10.189755 loss_rnnt 6.678396 hw_loss 0.244609 history loss 5.991502 rank 5
2023-03-01 09:12:17,967 DEBUG CV Batch 52/600 loss 7.059933 loss_att 6.228775 loss_ctc 10.189755 loss_rnnt 6.678396 hw_loss 0.244609 history loss 5.991502 rank 2
2023-03-01 09:12:18,307 DEBUG CV Batch 52/600 loss 7.059933 loss_att 6.228775 loss_ctc 10.189755 loss_rnnt 6.678396 hw_loss 0.244609 history loss 5.991502 rank 7
2023-03-01 09:12:18,999 DEBUG CV Batch 52/600 loss 7.059933 loss_att 6.228775 loss_ctc 10.189755 loss_rnnt 6.678396 hw_loss 0.244609 history loss 5.991502 rank 3
2023-03-01 09:12:19,571 DEBUG CV Batch 52/600 loss 7.059933 loss_att 6.228775 loss_ctc 10.189755 loss_rnnt 6.678396 hw_loss 0.244609 history loss 5.991502 rank 0
2023-03-01 09:12:19,819 DEBUG CV Batch 52/600 loss 7.059933 loss_att 6.228775 loss_ctc 10.189755 loss_rnnt 6.678396 hw_loss 0.244609 history loss 5.991502 rank 6
2023-03-01 09:12:28,222 DEBUG CV Batch 52/700 loss 12.536172 loss_att 21.812025 loss_ctc 14.546017 loss_rnnt 10.194457 hw_loss 0.409811 history loss 6.532683 rank 4
2023-03-01 09:12:28,294 DEBUG CV Batch 52/700 loss 12.536172 loss_att 21.812025 loss_ctc 14.546017 loss_rnnt 10.194457 hw_loss 0.409811 history loss 6.532683 rank 1
2023-03-01 09:12:28,787 DEBUG CV Batch 52/700 loss 12.536172 loss_att 21.812025 loss_ctc 14.546017 loss_rnnt 10.194457 hw_loss 0.409811 history loss 6.532683 rank 5
2023-03-01 09:12:29,633 DEBUG CV Batch 52/700 loss 12.536172 loss_att 21.812025 loss_ctc 14.546017 loss_rnnt 10.194457 hw_loss 0.409811 history loss 6.532683 rank 2
2023-03-01 09:12:29,957 DEBUG CV Batch 52/700 loss 12.536172 loss_att 21.812025 loss_ctc 14.546017 loss_rnnt 10.194457 hw_loss 0.409811 history loss 6.532683 rank 7
2023-03-01 09:12:30,672 DEBUG CV Batch 52/700 loss 12.536172 loss_att 21.812025 loss_ctc 14.546017 loss_rnnt 10.194457 hw_loss 0.409811 history loss 6.532683 rank 3
2023-03-01 09:12:31,463 DEBUG CV Batch 52/700 loss 12.536172 loss_att 21.812025 loss_ctc 14.546017 loss_rnnt 10.194457 hw_loss 0.409811 history loss 6.532683 rank 0
2023-03-01 09:12:31,805 DEBUG CV Batch 52/700 loss 12.536172 loss_att 21.812025 loss_ctc 14.546017 loss_rnnt 10.194457 hw_loss 0.409811 history loss 6.532683 rank 6
2023-03-01 09:12:39,470 DEBUG CV Batch 52/800 loss 6.671780 loss_att 7.250920 loss_ctc 14.772306 loss_rnnt 5.375442 hw_loss 0.188325 history loss 6.062251 rank 1
2023-03-01 09:12:40,004 DEBUG CV Batch 52/800 loss 6.671780 loss_att 7.250920 loss_ctc 14.772306 loss_rnnt 5.375442 hw_loss 0.188325 history loss 6.062251 rank 5
2023-03-01 09:12:40,060 DEBUG CV Batch 52/800 loss 6.671780 loss_att 7.250920 loss_ctc 14.772306 loss_rnnt 5.375442 hw_loss 0.188325 history loss 6.062251 rank 4
2023-03-01 09:12:40,901 DEBUG CV Batch 52/800 loss 6.671780 loss_att 7.250920 loss_ctc 14.772306 loss_rnnt 5.375442 hw_loss 0.188325 history loss 6.062251 rank 2
2023-03-01 09:12:41,635 DEBUG CV Batch 52/800 loss 6.671780 loss_att 7.250920 loss_ctc 14.772306 loss_rnnt 5.375442 hw_loss 0.188325 history loss 6.062251 rank 7
2023-03-01 09:12:42,608 DEBUG CV Batch 52/800 loss 6.671780 loss_att 7.250920 loss_ctc 14.772306 loss_rnnt 5.375442 hw_loss 0.188325 history loss 6.062251 rank 3
2023-03-01 09:12:43,286 DEBUG CV Batch 52/800 loss 6.671780 loss_att 7.250920 loss_ctc 14.772306 loss_rnnt 5.375442 hw_loss 0.188325 history loss 6.062251 rank 0
2023-03-01 09:12:43,705 DEBUG CV Batch 52/800 loss 6.671780 loss_att 7.250920 loss_ctc 14.772306 loss_rnnt 5.375442 hw_loss 0.188325 history loss 6.062251 rank 6
2023-03-01 09:12:52,996 DEBUG CV Batch 52/900 loss 11.147083 loss_att 11.212626 loss_ctc 20.366013 loss_rnnt 9.887403 hw_loss 0.032589 history loss 5.896939 rank 1
2023-03-01 09:12:53,560 DEBUG CV Batch 52/900 loss 11.147083 loss_att 11.212626 loss_ctc 20.366013 loss_rnnt 9.887403 hw_loss 0.032589 history loss 5.896939 rank 4
2023-03-01 09:12:53,657 DEBUG CV Batch 52/900 loss 11.147083 loss_att 11.212626 loss_ctc 20.366013 loss_rnnt 9.887403 hw_loss 0.032589 history loss 5.896939 rank 5
2023-03-01 09:12:54,621 DEBUG CV Batch 52/900 loss 11.147083 loss_att 11.212626 loss_ctc 20.366013 loss_rnnt 9.887403 hw_loss 0.032589 history loss 5.896939 rank 2
2023-03-01 09:12:55,216 DEBUG CV Batch 52/900 loss 11.147083 loss_att 11.212626 loss_ctc 20.366013 loss_rnnt 9.887403 hw_loss 0.032589 history loss 5.896939 rank 7
2023-03-01 09:12:56,599 DEBUG CV Batch 52/900 loss 11.147083 loss_att 11.212626 loss_ctc 20.366013 loss_rnnt 9.887403 hw_loss 0.032589 history loss 5.896939 rank 3
2023-03-01 09:12:57,108 DEBUG CV Batch 52/900 loss 11.147083 loss_att 11.212626 loss_ctc 20.366013 loss_rnnt 9.887403 hw_loss 0.032589 history loss 5.896939 rank 0
2023-03-01 09:12:57,667 DEBUG CV Batch 52/900 loss 11.147083 loss_att 11.212626 loss_ctc 20.366013 loss_rnnt 9.887403 hw_loss 0.032589 history loss 5.896939 rank 6
2023-03-01 09:13:05,563 DEBUG CV Batch 52/1000 loss 3.136138 loss_att 3.782651 loss_ctc 3.387968 loss_rnnt 2.783010 hw_loss 0.356717 history loss 5.707229 rank 1
2023-03-01 09:13:06,128 DEBUG CV Batch 52/1000 loss 3.136138 loss_att 3.782651 loss_ctc 3.387968 loss_rnnt 2.783010 hw_loss 0.356717 history loss 5.707229 rank 5
2023-03-01 09:13:06,283 DEBUG CV Batch 52/1000 loss 3.136138 loss_att 3.782651 loss_ctc 3.387968 loss_rnnt 2.783010 hw_loss 0.356717 history loss 5.707229 rank 4
2023-03-01 09:13:07,267 DEBUG CV Batch 52/1000 loss 3.136138 loss_att 3.782651 loss_ctc 3.387968 loss_rnnt 2.783010 hw_loss 0.356717 history loss 5.707229 rank 2
2023-03-01 09:13:07,916 DEBUG CV Batch 52/1000 loss 3.136138 loss_att 3.782651 loss_ctc 3.387968 loss_rnnt 2.783010 hw_loss 0.356717 history loss 5.707229 rank 7
2023-03-01 09:13:09,501 DEBUG CV Batch 52/1000 loss 3.136138 loss_att 3.782651 loss_ctc 3.387968 loss_rnnt 2.783010 hw_loss 0.356717 history loss 5.707229 rank 3
2023-03-01 09:13:09,912 DEBUG CV Batch 52/1000 loss 3.136138 loss_att 3.782651 loss_ctc 3.387968 loss_rnnt 2.783010 hw_loss 0.356717 history loss 5.707229 rank 0
2023-03-01 09:13:10,891 DEBUG CV Batch 52/1000 loss 3.136138 loss_att 3.782651 loss_ctc 3.387968 loss_rnnt 2.783010 hw_loss 0.356717 history loss 5.707229 rank 6
2023-03-01 09:13:17,500 DEBUG CV Batch 52/1100 loss 4.856399 loss_att 4.646693 loss_ctc 8.196574 loss_rnnt 4.259726 hw_loss 0.362358 history loss 5.664153 rank 1
2023-03-01 09:13:18,453 DEBUG CV Batch 52/1100 loss 4.856399 loss_att 4.646693 loss_ctc 8.196574 loss_rnnt 4.259726 hw_loss 0.362358 history loss 5.664153 rank 5
2023-03-01 09:13:18,511 DEBUG CV Batch 52/1100 loss 4.856399 loss_att 4.646693 loss_ctc 8.196574 loss_rnnt 4.259726 hw_loss 0.362358 history loss 5.664153 rank 4
2023-03-01 09:13:19,389 DEBUG CV Batch 52/1100 loss 4.856399 loss_att 4.646693 loss_ctc 8.196574 loss_rnnt 4.259726 hw_loss 0.362358 history loss 5.664153 rank 2
2023-03-01 09:13:20,143 DEBUG CV Batch 52/1100 loss 4.856399 loss_att 4.646693 loss_ctc 8.196574 loss_rnnt 4.259726 hw_loss 0.362358 history loss 5.664153 rank 7
2023-03-01 09:13:21,851 DEBUG CV Batch 52/1100 loss 4.856399 loss_att 4.646693 loss_ctc 8.196574 loss_rnnt 4.259726 hw_loss 0.362358 history loss 5.664153 rank 3
2023-03-01 09:13:22,453 DEBUG CV Batch 52/1100 loss 4.856399 loss_att 4.646693 loss_ctc 8.196574 loss_rnnt 4.259726 hw_loss 0.362358 history loss 5.664153 rank 0
2023-03-01 09:13:23,443 DEBUG CV Batch 52/1100 loss 4.856399 loss_att 4.646693 loss_ctc 8.196574 loss_rnnt 4.259726 hw_loss 0.362358 history loss 5.664153 rank 6
2023-03-01 09:13:28,316 DEBUG CV Batch 52/1200 loss 3.889061 loss_att 4.816372 loss_ctc 5.172129 loss_rnnt 3.385412 hw_loss 0.275833 history loss 5.932985 rank 1
2023-03-01 09:13:29,157 DEBUG CV Batch 52/1200 loss 3.889061 loss_att 4.816372 loss_ctc 5.172129 loss_rnnt 3.385412 hw_loss 0.275833 history loss 5.932985 rank 5
2023-03-01 09:13:29,532 DEBUG CV Batch 52/1200 loss 3.889061 loss_att 4.816372 loss_ctc 5.172129 loss_rnnt 3.385412 hw_loss 0.275833 history loss 5.932985 rank 4
2023-03-01 09:13:30,175 DEBUG CV Batch 52/1200 loss 3.889061 loss_att 4.816372 loss_ctc 5.172129 loss_rnnt 3.385412 hw_loss 0.275833 history loss 5.932985 rank 2
2023-03-01 09:13:31,289 DEBUG CV Batch 52/1200 loss 3.889061 loss_att 4.816372 loss_ctc 5.172129 loss_rnnt 3.385412 hw_loss 0.275833 history loss 5.932985 rank 7
2023-03-01 09:13:33,534 DEBUG CV Batch 52/1200 loss 3.889061 loss_att 4.816372 loss_ctc 5.172129 loss_rnnt 3.385412 hw_loss 0.275833 history loss 5.932985 rank 3
2023-03-01 09:13:33,692 DEBUG CV Batch 52/1200 loss 3.889061 loss_att 4.816372 loss_ctc 5.172129 loss_rnnt 3.385412 hw_loss 0.275833 history loss 5.932985 rank 0
2023-03-01 09:13:34,596 DEBUG CV Batch 52/1200 loss 3.889061 loss_att 4.816372 loss_ctc 5.172129 loss_rnnt 3.385412 hw_loss 0.275833 history loss 5.932985 rank 6
2023-03-01 09:13:40,373 DEBUG CV Batch 52/1300 loss 5.014071 loss_att 4.854523 loss_ctc 8.092123 loss_rnnt 4.466415 hw_loss 0.317171 history loss 6.228550 rank 1
2023-03-01 09:13:41,224 DEBUG CV Batch 52/1300 loss 5.014071 loss_att 4.854523 loss_ctc 8.092123 loss_rnnt 4.466415 hw_loss 0.317171 history loss 6.228550 rank 5
2023-03-01 09:13:41,569 DEBUG CV Batch 52/1300 loss 5.014071 loss_att 4.854523 loss_ctc 8.092123 loss_rnnt 4.466415 hw_loss 0.317171 history loss 6.228550 rank 4
2023-03-01 09:13:42,275 DEBUG CV Batch 52/1300 loss 5.014071 loss_att 4.854523 loss_ctc 8.092123 loss_rnnt 4.466415 hw_loss 0.317171 history loss 6.228550 rank 2
2023-03-01 09:13:43,718 DEBUG CV Batch 52/1300 loss 5.014071 loss_att 4.854523 loss_ctc 8.092123 loss_rnnt 4.466415 hw_loss 0.317171 history loss 6.228550 rank 7
2023-03-01 09:13:46,152 DEBUG CV Batch 52/1300 loss 5.014071 loss_att 4.854523 loss_ctc 8.092123 loss_rnnt 4.466415 hw_loss 0.317171 history loss 6.228550 rank 3
2023-03-01 09:13:46,307 DEBUG CV Batch 52/1300 loss 5.014071 loss_att 4.854523 loss_ctc 8.092123 loss_rnnt 4.466415 hw_loss 0.317171 history loss 6.228550 rank 0
2023-03-01 09:13:47,168 DEBUG CV Batch 52/1300 loss 5.014071 loss_att 4.854523 loss_ctc 8.092123 loss_rnnt 4.466415 hw_loss 0.317171 history loss 6.228550 rank 6
2023-03-01 09:13:51,564 DEBUG CV Batch 52/1400 loss 4.501398 loss_att 14.152601 loss_ctc 5.433754 loss_rnnt 2.358061 hw_loss 0.166466 history loss 6.497393 rank 1
2023-03-01 09:13:52,984 DEBUG CV Batch 52/1400 loss 4.501398 loss_att 14.152601 loss_ctc 5.433754 loss_rnnt 2.358061 hw_loss 0.166466 history loss 6.497393 rank 4
2023-03-01 09:13:53,035 DEBUG CV Batch 52/1400 loss 4.501398 loss_att 14.152601 loss_ctc 5.433754 loss_rnnt 2.358061 hw_loss 0.166466 history loss 6.497393 rank 5
2023-03-01 09:13:53,811 DEBUG CV Batch 52/1400 loss 4.501398 loss_att 14.152601 loss_ctc 5.433754 loss_rnnt 2.358061 hw_loss 0.166466 history loss 6.497393 rank 2
2023-03-01 09:13:55,284 DEBUG CV Batch 52/1400 loss 4.501398 loss_att 14.152601 loss_ctc 5.433754 loss_rnnt 2.358061 hw_loss 0.166466 history loss 6.497393 rank 7
2023-03-01 09:13:58,128 DEBUG CV Batch 52/1400 loss 4.501398 loss_att 14.152601 loss_ctc 5.433754 loss_rnnt 2.358061 hw_loss 0.166466 history loss 6.497393 rank 3
2023-03-01 09:13:58,146 DEBUG CV Batch 52/1400 loss 4.501398 loss_att 14.152601 loss_ctc 5.433754 loss_rnnt 2.358061 hw_loss 0.166466 history loss 6.497393 rank 0
2023-03-01 09:13:58,772 DEBUG CV Batch 52/1400 loss 4.501398 loss_att 14.152601 loss_ctc 5.433754 loss_rnnt 2.358061 hw_loss 0.166466 history loss 6.497393 rank 6
2023-03-01 09:14:03,200 DEBUG CV Batch 52/1500 loss 7.920344 loss_att 7.511874 loss_ctc 8.558140 loss_rnnt 7.764670 hw_loss 0.285614 history loss 6.368382 rank 1
2023-03-01 09:14:04,309 DEBUG CV Batch 52/1500 loss 7.920344 loss_att 7.511874 loss_ctc 8.558140 loss_rnnt 7.764670 hw_loss 0.285614 history loss 6.368382 rank 4
2023-03-01 09:14:04,662 DEBUG CV Batch 52/1500 loss 7.920344 loss_att 7.511874 loss_ctc 8.558140 loss_rnnt 7.764670 hw_loss 0.285614 history loss 6.368382 rank 5
2023-03-01 09:14:05,369 DEBUG CV Batch 52/1500 loss 7.920344 loss_att 7.511874 loss_ctc 8.558140 loss_rnnt 7.764670 hw_loss 0.285614 history loss 6.368382 rank 2
2023-03-01 09:14:07,210 DEBUG CV Batch 52/1500 loss 7.920344 loss_att 7.511874 loss_ctc 8.558140 loss_rnnt 7.764670 hw_loss 0.285614 history loss 6.368382 rank 7
2023-03-01 09:14:10,226 DEBUG CV Batch 52/1500 loss 7.920344 loss_att 7.511874 loss_ctc 8.558140 loss_rnnt 7.764670 hw_loss 0.285614 history loss 6.368382 rank 0
2023-03-01 09:14:10,494 DEBUG CV Batch 52/1500 loss 7.920344 loss_att 7.511874 loss_ctc 8.558140 loss_rnnt 7.764670 hw_loss 0.285614 history loss 6.368382 rank 3
2023-03-01 09:14:10,752 DEBUG CV Batch 52/1500 loss 7.920344 loss_att 7.511874 loss_ctc 8.558140 loss_rnnt 7.764670 hw_loss 0.285614 history loss 6.368382 rank 6
2023-03-01 09:14:16,291 DEBUG CV Batch 52/1600 loss 8.041616 loss_att 11.890543 loss_ctc 12.493130 loss_rnnt 6.559937 hw_loss 0.221922 history loss 6.330210 rank 1
2023-03-01 09:14:17,503 DEBUG CV Batch 52/1600 loss 8.041616 loss_att 11.890543 loss_ctc 12.493130 loss_rnnt 6.559937 hw_loss 0.221922 history loss 6.330210 rank 4
2023-03-01 09:14:18,241 DEBUG CV Batch 52/1600 loss 8.041616 loss_att 11.890543 loss_ctc 12.493130 loss_rnnt 6.559937 hw_loss 0.221922 history loss 6.330210 rank 5
2023-03-01 09:14:18,717 DEBUG CV Batch 52/1600 loss 8.041616 loss_att 11.890543 loss_ctc 12.493130 loss_rnnt 6.559937 hw_loss 0.221922 history loss 6.330210 rank 2
2023-03-01 09:14:20,622 DEBUG CV Batch 52/1600 loss 8.041616 loss_att 11.890543 loss_ctc 12.493130 loss_rnnt 6.559937 hw_loss 0.221922 history loss 6.330210 rank 7
2023-03-01 09:14:23,786 DEBUG CV Batch 52/1600 loss 8.041616 loss_att 11.890543 loss_ctc 12.493130 loss_rnnt 6.559937 hw_loss 0.221922 history loss 6.330210 rank 0
2023-03-01 09:14:23,962 DEBUG CV Batch 52/1600 loss 8.041616 loss_att 11.890543 loss_ctc 12.493130 loss_rnnt 6.559937 hw_loss 0.221922 history loss 6.330210 rank 6
2023-03-01 09:14:24,097 DEBUG CV Batch 52/1600 loss 8.041616 loss_att 11.890543 loss_ctc 12.493130 loss_rnnt 6.559937 hw_loss 0.221922 history loss 6.330210 rank 3
2023-03-01 09:14:28,965 DEBUG CV Batch 52/1700 loss 6.396027 loss_att 5.497160 loss_ctc 12.694916 loss_rnnt 5.651862 hw_loss 0.157663 history loss 6.266275 rank 1
2023-03-01 09:14:30,076 DEBUG CV Batch 52/1700 loss 6.396027 loss_att 5.497160 loss_ctc 12.694916 loss_rnnt 5.651862 hw_loss 0.157663 history loss 6.266275 rank 4
2023-03-01 09:14:30,741 DEBUG CV Batch 52/1700 loss 6.396027 loss_att 5.497160 loss_ctc 12.694916 loss_rnnt 5.651862 hw_loss 0.157663 history loss 6.266275 rank 5
2023-03-01 09:14:31,421 DEBUG CV Batch 52/1700 loss 6.396027 loss_att 5.497160 loss_ctc 12.694916 loss_rnnt 5.651862 hw_loss 0.157663 history loss 6.266275 rank 2
2023-03-01 09:14:33,377 DEBUG CV Batch 52/1700 loss 6.396027 loss_att 5.497160 loss_ctc 12.694916 loss_rnnt 5.651862 hw_loss 0.157663 history loss 6.266275 rank 7
2023-03-01 09:14:36,590 DEBUG CV Batch 52/1700 loss 6.396027 loss_att 5.497160 loss_ctc 12.694916 loss_rnnt 5.651862 hw_loss 0.157663 history loss 6.266275 rank 6
2023-03-01 09:14:36,648 DEBUG CV Batch 52/1700 loss 6.396027 loss_att 5.497160 loss_ctc 12.694916 loss_rnnt 5.651862 hw_loss 0.157663 history loss 6.266275 rank 0
2023-03-01 09:14:36,810 DEBUG CV Batch 52/1700 loss 6.396027 loss_att 5.497160 loss_ctc 12.694916 loss_rnnt 5.651862 hw_loss 0.157663 history loss 6.266275 rank 3
2023-03-01 09:14:38,016 INFO Epoch 52 CV info cv_loss 6.245590794633916
2023-03-01 09:14:38,017 INFO Epoch 53 TRAIN info lr 0.00028951206915856686
2023-03-01 09:14:38,022 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 09:14:39,171 INFO Epoch 52 CV info cv_loss 6.24559079514864
2023-03-01 09:14:39,172 INFO Epoch 53 TRAIN info lr 0.0002895159518130005
2023-03-01 09:14:39,174 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 09:14:40,507 INFO Epoch 52 CV info cv_loss 6.245590794028738
2023-03-01 09:14:40,508 INFO Epoch 53 TRAIN info lr 0.00028950915727025164
2023-03-01 09:14:40,512 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 09:14:40,607 INFO Epoch 52 CV info cv_loss 6.245590796414992
2023-03-01 09:14:40,607 INFO Epoch 53 TRAIN info lr 0.00028951837855134896
2023-03-01 09:14:40,609 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 09:14:42,542 INFO Epoch 52 CV info cv_loss 6.2455907930854355
2023-03-01 09:14:42,542 INFO Epoch 53 TRAIN info lr 0.0002895077013590421
2023-03-01 09:14:42,544 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 09:14:45,867 INFO Epoch 52 CV info cv_loss 6.245590796053177
2023-03-01 09:14:45,868 INFO Epoch 53 TRAIN info lr 0.00028951109851936584
2023-03-01 09:14:45,873 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 09:14:46,119 INFO Epoch 52 CV info cv_loss 6.245590794545616
2023-03-01 09:14:46,120 INFO Checkpoint: save to checkpoint exp/2_27_rnnt_bias_loss_2_class_both_finetune/52.pt
2023-03-01 09:14:46,493 INFO Epoch 52 CV info cv_loss 6.245590795643982
2023-03-01 09:14:46,494 INFO Epoch 53 TRAIN info lr 0.00028950673076377174
2023-03-01 09:14:46,496 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 09:14:46,689 INFO Epoch 53 TRAIN info lr 0.00028951837855134896
2023-03-01 09:14:46,692 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 09:15:48,696 DEBUG TRAIN Batch 53/0 loss 5.159898 loss_att 6.300374 loss_ctc 8.201479 loss_rnnt 4.427035 hw_loss 0.186044 lr 0.00028952 rank 4
2023-03-01 09:15:48,698 DEBUG TRAIN Batch 53/0 loss 5.810826 loss_att 6.741000 loss_ctc 8.294680 loss_rnnt 5.132979 hw_loss 0.301185 lr 0.00028951 rank 7
2023-03-01 09:15:48,700 DEBUG TRAIN Batch 53/0 loss 9.029033 loss_att 9.421155 loss_ctc 12.865397 loss_rnnt 8.211570 hw_loss 0.426606 lr 0.00028951 rank 3
2023-03-01 09:15:48,700 DEBUG TRAIN Batch 53/0 loss 4.754580 loss_att 5.028512 loss_ctc 8.210721 loss_rnnt 4.063425 hw_loss 0.329156 lr 0.00028951 rank 1
2023-03-01 09:15:48,701 DEBUG TRAIN Batch 53/0 loss 8.380277 loss_att 7.465656 loss_ctc 11.781346 loss_rnnt 7.939654 hw_loss 0.318882 lr 0.00028952 rank 0
2023-03-01 09:15:48,704 DEBUG TRAIN Batch 53/0 loss 7.305009 loss_att 6.604408 loss_ctc 10.482368 loss_rnnt 6.844810 hw_loss 0.331261 lr 0.00028952 rank 2
2023-03-01 09:15:48,705 DEBUG TRAIN Batch 53/0 loss 10.696558 loss_att 10.729744 loss_ctc 15.060110 loss_rnnt 9.933810 hw_loss 0.326820 lr 0.00028951 rank 5
2023-03-01 09:15:48,722 DEBUG TRAIN Batch 53/0 loss 7.705795 loss_att 7.759038 loss_ctc 11.672460 loss_rnnt 7.020791 hw_loss 0.272750 lr 0.00028951 rank 6
2023-03-01 09:16:25,722 DEBUG TRAIN Batch 53/100 loss 4.494551 loss_att 7.059253 loss_ctc 8.853054 loss_rnnt 3.253804 hw_loss 0.275013 lr 0.00028951 rank 0
2023-03-01 09:16:25,738 DEBUG TRAIN Batch 53/100 loss 5.961696 loss_att 8.486125 loss_ctc 10.108772 loss_rnnt 4.870048 hw_loss 0.063411 lr 0.00028950 rank 7
2023-03-01 09:16:25,740 DEBUG TRAIN Batch 53/100 loss 4.264359 loss_att 6.580600 loss_ctc 8.436755 loss_rnnt 3.134612 hw_loss 0.206587 lr 0.00028951 rank 2
2023-03-01 09:16:25,741 DEBUG TRAIN Batch 53/100 loss 14.081437 loss_att 16.548651 loss_ctc 18.370598 loss_rnnt 12.968418 hw_loss 0.089415 lr 0.00028950 rank 6
2023-03-01 09:16:25,742 DEBUG TRAIN Batch 53/100 loss 5.685901 loss_att 8.021976 loss_ctc 12.039068 loss_rnnt 4.278235 hw_loss 0.175052 lr 0.00028950 rank 1
2023-03-01 09:16:25,743 DEBUG TRAIN Batch 53/100 loss 7.409712 loss_att 10.807356 loss_ctc 10.199732 loss_rnnt 6.258413 hw_loss 0.187064 lr 0.00028949 rank 3
2023-03-01 09:16:25,745 DEBUG TRAIN Batch 53/100 loss 6.033386 loss_att 9.561524 loss_ctc 8.631905 loss_rnnt 4.862706 hw_loss 0.222345 lr 0.00028950 rank 5
2023-03-01 09:16:25,750 DEBUG TRAIN Batch 53/100 loss 6.486588 loss_att 9.556534 loss_ctc 12.522154 loss_rnnt 4.903388 hw_loss 0.308378 lr 0.00028950 rank 4
2023-03-01 09:17:03,661 DEBUG TRAIN Batch 53/200 loss 3.931168 loss_att 5.599675 loss_ctc 8.219681 loss_rnnt 2.968398 hw_loss 0.107374 lr 0.00028948 rank 7
2023-03-01 09:17:03,663 DEBUG TRAIN Batch 53/200 loss 7.231882 loss_att 9.478690 loss_ctc 12.663574 loss_rnnt 5.874715 hw_loss 0.344212 lr 0.00028949 rank 2
2023-03-01 09:17:03,663 DEBUG TRAIN Batch 53/200 loss 4.852691 loss_att 6.311804 loss_ctc 7.376081 loss_rnnt 4.011650 hw_loss 0.398936 lr 0.00028948 rank 5
2023-03-01 09:17:03,664 DEBUG TRAIN Batch 53/200 loss 5.576167 loss_att 8.430112 loss_ctc 6.247996 loss_rnnt 4.826383 hw_loss 0.167657 lr 0.00028949 rank 0
2023-03-01 09:17:03,664 DEBUG TRAIN Batch 53/200 loss 1.350811 loss_att 3.329676 loss_ctc 2.658907 loss_rnnt 0.688147 hw_loss 0.173395 lr 0.00028949 rank 1
2023-03-01 09:17:03,665 DEBUG TRAIN Batch 53/200 loss 2.081502 loss_att 5.227932 loss_ctc 3.966091 loss_rnnt 1.083240 hw_loss 0.220683 lr 0.00028949 rank 4
2023-03-01 09:17:03,666 DEBUG TRAIN Batch 53/200 loss 10.168085 loss_att 11.266451 loss_ctc 11.583181 loss_rnnt 9.668350 hw_loss 0.171340 lr 0.00028949 rank 6
2023-03-01 09:17:03,668 DEBUG TRAIN Batch 53/200 loss 6.775897 loss_att 8.577788 loss_ctc 14.739695 loss_rnnt 5.193060 hw_loss 0.301161 lr 0.00028948 rank 3
2023-03-01 09:17:42,063 DEBUG TRAIN Batch 53/300 loss 7.090361 loss_att 9.696081 loss_ctc 10.968184 loss_rnnt 5.911377 hw_loss 0.263994 lr 0.00028948 rank 0
2023-03-01 09:17:42,069 DEBUG TRAIN Batch 53/300 loss 7.822476 loss_att 8.562812 loss_ctc 8.362744 loss_rnnt 7.476187 hw_loss 0.236600 lr 0.00028948 rank 2
2023-03-01 09:17:42,070 DEBUG TRAIN Batch 53/300 loss 3.705793 loss_att 6.350196 loss_ctc 7.966685 loss_rnnt 2.542746 hw_loss 0.123839 lr 0.00028947 rank 3
2023-03-01 09:17:42,083 DEBUG TRAIN Batch 53/300 loss 7.579051 loss_att 9.045393 loss_ctc 12.693884 loss_rnnt 6.538408 hw_loss 0.122619 lr 0.00028947 rank 5
2023-03-01 09:17:42,083 DEBUG TRAIN Batch 53/300 loss 6.140007 loss_att 8.415224 loss_ctc 10.570860 loss_rnnt 5.020463 hw_loss 0.138224 lr 0.00028948 rank 1
2023-03-01 09:17:42,086 DEBUG TRAIN Batch 53/300 loss 6.862895 loss_att 9.744959 loss_ctc 14.274717 loss_rnnt 5.257715 hw_loss 0.075984 lr 0.00028947 rank 7
2023-03-01 09:17:42,088 DEBUG TRAIN Batch 53/300 loss 1.909015 loss_att 4.686312 loss_ctc 3.781575 loss_rnnt 0.971487 hw_loss 0.248238 lr 0.00028947 rank 6
2023-03-01 09:17:42,093 DEBUG TRAIN Batch 53/300 loss 13.060222 loss_att 21.031336 loss_ctc 26.102821 loss_rnnt 9.553194 hw_loss 0.325859 lr 0.00028948 rank 4
2023-03-01 09:18:49,297 DEBUG TRAIN Batch 53/400 loss 4.299067 loss_att 6.169439 loss_ctc 8.237579 loss_rnnt 3.261005 hw_loss 0.260349 lr 0.00028947 rank 4
2023-03-01 09:18:49,302 DEBUG TRAIN Batch 53/400 loss 3.760998 loss_att 6.747991 loss_ctc 6.624311 loss_rnnt 2.728008 hw_loss 0.100905 lr 0.00028947 rank 2
2023-03-01 09:18:49,302 DEBUG TRAIN Batch 53/400 loss 4.192132 loss_att 6.658666 loss_ctc 7.671694 loss_rnnt 3.167907 hw_loss 0.125580 lr 0.00028946 rank 5
2023-03-01 09:18:49,302 DEBUG TRAIN Batch 53/400 loss 8.609939 loss_att 10.605398 loss_ctc 13.321836 loss_rnnt 7.423767 hw_loss 0.297800 lr 0.00028947 rank 0
2023-03-01 09:18:49,302 DEBUG TRAIN Batch 53/400 loss 4.555699 loss_att 6.605410 loss_ctc 5.273705 loss_rnnt 3.893768 hw_loss 0.292977 lr 0.00028946 rank 1
2023-03-01 09:18:49,303 DEBUG TRAIN Batch 53/400 loss 5.313340 loss_att 7.435160 loss_ctc 8.915451 loss_rnnt 4.271045 hw_loss 0.258092 lr 0.00028946 rank 7
2023-03-01 09:18:49,327 DEBUG TRAIN Batch 53/400 loss 4.937682 loss_att 7.877999 loss_ctc 7.825161 loss_rnnt 3.910529 hw_loss 0.101422 lr 0.00028946 rank 3
2023-03-01 09:18:49,357 DEBUG TRAIN Batch 53/400 loss 2.786494 loss_att 5.072885 loss_ctc 6.489043 loss_rnnt 1.753679 hw_loss 0.153493 lr 0.00028946 rank 6
2023-03-01 09:19:27,683 DEBUG TRAIN Batch 53/500 loss 7.797711 loss_att 12.159227 loss_ctc 18.915638 loss_rnnt 5.318755 hw_loss 0.232992 lr 0.00028945 rank 1
2023-03-01 09:19:27,683 DEBUG TRAIN Batch 53/500 loss 11.211690 loss_att 11.156247 loss_ctc 12.679098 loss_rnnt 10.895333 hw_loss 0.247105 lr 0.00028945 rank 4
2023-03-01 09:19:27,684 DEBUG TRAIN Batch 53/500 loss 8.579427 loss_att 11.115786 loss_ctc 14.950261 loss_rnnt 7.198600 hw_loss 0.045207 lr 0.00028945 rank 6
2023-03-01 09:19:27,687 DEBUG TRAIN Batch 53/500 loss 5.884058 loss_att 9.704660 loss_ctc 12.910399 loss_rnnt 4.048013 hw_loss 0.253274 lr 0.00028945 rank 7
2023-03-01 09:19:27,688 DEBUG TRAIN Batch 53/500 loss 3.719697 loss_att 6.528135 loss_ctc 4.515614 loss_rnnt 2.887764 hw_loss 0.307731 lr 0.00028946 rank 0
2023-03-01 09:19:27,689 DEBUG TRAIN Batch 53/500 loss 5.325541 loss_att 8.884426 loss_ctc 7.752088 loss_rnnt 4.187171 hw_loss 0.193226 lr 0.00028945 rank 3
2023-03-01 09:19:27,695 DEBUG TRAIN Batch 53/500 loss 8.237918 loss_att 10.032433 loss_ctc 12.134155 loss_rnnt 7.224165 hw_loss 0.253782 lr 0.00028945 rank 5
2023-03-01 09:19:27,730 DEBUG TRAIN Batch 53/500 loss 6.043083 loss_att 8.113918 loss_ctc 10.444111 loss_rnnt 4.976106 hw_loss 0.123762 lr 0.00028946 rank 2
2023-03-01 09:20:06,783 DEBUG TRAIN Batch 53/600 loss 4.339458 loss_att 5.458055 loss_ctc 6.348543 loss_rnnt 3.703076 hw_loss 0.271470 lr 0.00028944 rank 5
2023-03-01 09:20:06,788 DEBUG TRAIN Batch 53/600 loss 3.804497 loss_att 5.068154 loss_ctc 5.507473 loss_rnnt 3.173121 hw_loss 0.284215 lr 0.00028945 rank 0
2023-03-01 09:20:06,790 DEBUG TRAIN Batch 53/600 loss 8.995962 loss_att 9.762491 loss_ctc 11.827398 loss_rnnt 8.325243 hw_loss 0.262290 lr 0.00028943 rank 7
2023-03-01 09:20:06,794 DEBUG TRAIN Batch 53/600 loss 5.443680 loss_att 8.053674 loss_ctc 11.551563 loss_rnnt 3.971340 hw_loss 0.254919 lr 0.00028944 rank 6
2023-03-01 09:20:06,794 DEBUG TRAIN Batch 53/600 loss 4.384144 loss_att 5.488110 loss_ctc 6.872069 loss_rnnt 3.717197 hw_loss 0.214556 lr 0.00028943 rank 3
2023-03-01 09:20:06,795 DEBUG TRAIN Batch 53/600 loss 8.225816 loss_att 8.266096 loss_ctc 12.029129 loss_rnnt 7.578447 hw_loss 0.247885 lr 0.00028944 rank 4
2023-03-01 09:20:06,796 DEBUG TRAIN Batch 53/600 loss 5.297329 loss_att 6.254496 loss_ctc 8.568416 loss_rnnt 4.546042 hw_loss 0.231955 lr 0.00028944 rank 1
2023-03-01 09:20:06,798 DEBUG TRAIN Batch 53/600 loss 7.400454 loss_att 7.463940 loss_ctc 10.925828 loss_rnnt 6.749696 hw_loss 0.315021 lr 0.00028945 rank 2
2023-03-01 09:21:08,614 DEBUG TRAIN Batch 53/700 loss 4.460806 loss_att 7.168165 loss_ctc 5.689227 loss_rnnt 3.671316 hw_loss 0.157930 lr 0.00028942 rank 5
2023-03-01 09:21:08,623 DEBUG TRAIN Batch 53/700 loss 4.285302 loss_att 5.807191 loss_ctc 8.132967 loss_rnnt 3.355315 hw_loss 0.211100 lr 0.00028943 rank 0
2023-03-01 09:21:08,626 DEBUG TRAIN Batch 53/700 loss 4.063025 loss_att 7.596047 loss_ctc 8.680262 loss_rnnt 2.656844 hw_loss 0.157396 lr 0.00028943 rank 2
2023-03-01 09:21:08,629 DEBUG TRAIN Batch 53/700 loss 9.375332 loss_att 11.410840 loss_ctc 11.922066 loss_rnnt 8.556223 hw_loss 0.135829 lr 0.00028942 rank 3
2023-03-01 09:21:08,640 DEBUG TRAIN Batch 53/700 loss 3.738495 loss_att 8.267117 loss_ctc 6.649962 loss_rnnt 2.314185 hw_loss 0.244482 lr 0.00028943 rank 6
2023-03-01 09:21:08,650 DEBUG TRAIN Batch 53/700 loss 2.007316 loss_att 4.236008 loss_ctc 3.249230 loss_rnnt 1.270091 hw_loss 0.236059 lr 0.00028943 rank 4
2023-03-01 09:21:08,662 DEBUG TRAIN Batch 53/700 loss 5.744884 loss_att 6.267863 loss_ctc 8.802216 loss_rnnt 5.066924 hw_loss 0.310726 lr 0.00028942 rank 7
2023-03-01 09:21:08,682 DEBUG TRAIN Batch 53/700 loss 2.614198 loss_att 4.852227 loss_ctc 4.528194 loss_rnnt 1.842452 hw_loss 0.129265 lr 0.00028943 rank 1
2023-03-01 09:21:50,910 DEBUG TRAIN Batch 53/800 loss 3.947614 loss_att 7.426555 loss_ctc 6.213226 loss_rnnt 2.805373 hw_loss 0.270695 lr 0.00028941 rank 6
2023-03-01 09:21:50,912 DEBUG TRAIN Batch 53/800 loss 3.333833 loss_att 6.005311 loss_ctc 4.905668 loss_rnnt 2.525686 hw_loss 0.120512 lr 0.00028941 rank 7
2023-03-01 09:21:50,912 DEBUG TRAIN Batch 53/800 loss 11.388921 loss_att 17.036442 loss_ctc 27.188726 loss_rnnt 8.087078 hw_loss 0.123182 lr 0.00028941 rank 5
2023-03-01 09:21:50,912 DEBUG TRAIN Batch 53/800 loss 2.573289 loss_att 6.327744 loss_ctc 3.508728 loss_rnnt 1.572828 hw_loss 0.234084 lr 0.00028942 rank 0
2023-03-01 09:21:50,914 DEBUG TRAIN Batch 53/800 loss 5.148985 loss_att 9.694973 loss_ctc 9.516268 loss_rnnt 3.571805 hw_loss 0.160646 lr 0.00028941 rank 1
2023-03-01 09:21:50,916 DEBUG TRAIN Batch 53/800 loss 10.702662 loss_att 11.329700 loss_ctc 16.527130 loss_rnnt 9.656071 hw_loss 0.271100 lr 0.00028942 rank 4
2023-03-01 09:21:50,916 DEBUG TRAIN Batch 53/800 loss 7.535397 loss_att 10.692636 loss_ctc 12.223391 loss_rnnt 6.134597 hw_loss 0.270536 lr 0.00028942 rank 2
2023-03-01 09:21:50,937 DEBUG TRAIN Batch 53/800 loss 10.416385 loss_att 13.436764 loss_ctc 16.678848 loss_rnnt 8.930588 hw_loss 0.087613 lr 0.00028941 rank 3
2023-03-01 09:22:29,236 DEBUG TRAIN Batch 53/900 loss 7.992848 loss_att 10.484863 loss_ctc 13.890810 loss_rnnt 6.648798 hw_loss 0.111098 lr 0.00028940 rank 5
2023-03-01 09:22:29,245 DEBUG TRAIN Batch 53/900 loss 6.773447 loss_att 10.041636 loss_ctc 10.370818 loss_rnnt 5.514180 hw_loss 0.236213 lr 0.00028941 rank 0
2023-03-01 09:22:29,247 DEBUG TRAIN Batch 53/900 loss 6.761622 loss_att 9.459128 loss_ctc 13.713087 loss_rnnt 5.118849 hw_loss 0.330769 lr 0.00028940 rank 1
2023-03-01 09:22:29,248 DEBUG TRAIN Batch 53/900 loss 3.594680 loss_att 5.763066 loss_ctc 7.095951 loss_rnnt 2.605162 hw_loss 0.166882 lr 0.00028941 rank 4
2023-03-01 09:22:29,249 DEBUG TRAIN Batch 53/900 loss 4.022732 loss_att 8.293091 loss_ctc 8.510216 loss_rnnt 2.461994 hw_loss 0.203129 lr 0.00028940 rank 7
2023-03-01 09:22:29,251 DEBUG TRAIN Batch 53/900 loss 5.507449 loss_att 8.134689 loss_ctc 6.412828 loss_rnnt 4.759998 hw_loss 0.189910 lr 0.00028941 rank 2
2023-03-01 09:22:29,253 DEBUG TRAIN Batch 53/900 loss 8.665231 loss_att 12.360416 loss_ctc 14.086151 loss_rnnt 7.148160 hw_loss 0.103581 lr 0.00028940 rank 3
2023-03-01 09:22:29,254 DEBUG TRAIN Batch 53/900 loss 3.134296 loss_att 5.964279 loss_ctc 6.409170 loss_rnnt 2.073016 hw_loss 0.109937 lr 0.00028940 rank 6
2023-03-01 09:23:08,291 DEBUG TRAIN Batch 53/1000 loss 9.667576 loss_att 12.273746 loss_ctc 12.891658 loss_rnnt 8.610418 hw_loss 0.198837 lr 0.00028939 rank 6
2023-03-01 09:23:08,296 DEBUG TRAIN Batch 53/1000 loss 2.950005 loss_att 6.270042 loss_ctc 4.362969 loss_rnnt 2.028471 hw_loss 0.129620 lr 0.00028939 rank 1
2023-03-01 09:23:08,297 DEBUG TRAIN Batch 53/1000 loss 4.666629 loss_att 6.891394 loss_ctc 7.108110 loss_rnnt 3.771017 hw_loss 0.234617 lr 0.00028938 rank 3
2023-03-01 09:23:08,299 DEBUG TRAIN Batch 53/1000 loss 2.618894 loss_att 6.129827 loss_ctc 6.553944 loss_rnnt 1.249490 hw_loss 0.267270 lr 0.00028940 rank 2
2023-03-01 09:23:08,309 DEBUG TRAIN Batch 53/1000 loss 6.241300 loss_att 9.850048 loss_ctc 10.055626 loss_rnnt 4.913332 hw_loss 0.183078 lr 0.00028939 rank 4
2023-03-01 09:23:08,313 DEBUG TRAIN Batch 53/1000 loss 8.548073 loss_att 11.996531 loss_ctc 14.602025 loss_rnnt 6.951049 hw_loss 0.187759 lr 0.00028939 rank 7
2023-03-01 09:23:08,314 DEBUG TRAIN Batch 53/1000 loss 4.216046 loss_att 7.181509 loss_ctc 6.393770 loss_rnnt 3.161408 hw_loss 0.320966 lr 0.00028940 rank 0
2023-03-01 09:23:08,348 DEBUG TRAIN Batch 53/1000 loss 6.542968 loss_att 7.932036 loss_ctc 8.701296 loss_rnnt 5.875644 hw_loss 0.190750 lr 0.00028939 rank 5
2023-03-01 09:24:13,717 DEBUG TRAIN Batch 53/1100 loss 12.569786 loss_att 11.389063 loss_ctc 17.104670 loss_rnnt 12.136314 hw_loss 0.121808 lr 0.00028938 rank 0
2023-03-01 09:24:13,738 DEBUG TRAIN Batch 53/1100 loss 7.100605 loss_att 8.621944 loss_ctc 8.862093 loss_rnnt 6.465109 hw_loss 0.180679 lr 0.00028938 rank 4
2023-03-01 09:24:13,738 DEBUG TRAIN Batch 53/1100 loss 12.691524 loss_att 13.355357 loss_ctc 18.937449 loss_rnnt 11.658580 hw_loss 0.126353 lr 0.00028938 rank 5
2023-03-01 09:24:13,739 DEBUG TRAIN Batch 53/1100 loss 7.444953 loss_att 12.065722 loss_ctc 12.306820 loss_rnnt 5.708652 hw_loss 0.307312 lr 0.00028937 rank 7
2023-03-01 09:24:13,740 DEBUG TRAIN Batch 53/1100 loss 10.104967 loss_att 13.345473 loss_ctc 13.757772 loss_rnnt 8.913273 hw_loss 0.106034 lr 0.00028938 rank 1
2023-03-01 09:24:13,741 DEBUG TRAIN Batch 53/1100 loss 9.682947 loss_att 12.835644 loss_ctc 18.495573 loss_rnnt 7.794853 hw_loss 0.154757 lr 0.00028938 rank 2
2023-03-01 09:24:13,750 DEBUG TRAIN Batch 53/1100 loss 3.552823 loss_att 6.994287 loss_ctc 6.215940 loss_rnnt 2.389539 hw_loss 0.224828 lr 0.00028937 rank 3
2023-03-01 09:24:13,793 DEBUG TRAIN Batch 53/1100 loss 7.914745 loss_att 9.657375 loss_ctc 8.599326 loss_rnnt 7.403194 hw_loss 0.134527 lr 0.00028938 rank 6
2023-03-01 09:24:52,599 DEBUG TRAIN Batch 53/1200 loss 4.456692 loss_att 8.366514 loss_ctc 10.989742 loss_rnnt 2.698656 hw_loss 0.196871 lr 0.00028936 rank 7
2023-03-01 09:24:52,602 DEBUG TRAIN Batch 53/1200 loss 3.372100 loss_att 5.492649 loss_ctc 8.303849 loss_rnnt 2.198705 hw_loss 0.171971 lr 0.00028937 rank 1
2023-03-01 09:24:52,605 DEBUG TRAIN Batch 53/1200 loss 6.382371 loss_att 8.054243 loss_ctc 9.116348 loss_rnnt 5.554914 hw_loss 0.241035 lr 0.00028937 rank 6
2023-03-01 09:24:52,604 DEBUG TRAIN Batch 53/1200 loss 3.684906 loss_att 7.104239 loss_ctc 8.923251 loss_rnnt 2.222825 hw_loss 0.149567 lr 0.00028936 rank 5
2023-03-01 09:24:52,606 DEBUG TRAIN Batch 53/1200 loss 6.256949 loss_att 7.320541 loss_ctc 11.220004 loss_rnnt 5.189916 hw_loss 0.361078 lr 0.00028937 rank 2
2023-03-01 09:24:52,608 DEBUG TRAIN Batch 53/1200 loss 3.069442 loss_att 5.662084 loss_ctc 6.768247 loss_rnnt 1.938441 hw_loss 0.223686 lr 0.00028937 rank 0
2023-03-01 09:24:52,610 DEBUG TRAIN Batch 53/1200 loss 5.819830 loss_att 8.200653 loss_ctc 12.599181 loss_rnnt 4.317776 hw_loss 0.228704 lr 0.00028937 rank 4
2023-03-01 09:24:52,657 DEBUG TRAIN Batch 53/1200 loss 2.946471 loss_att 4.785356 loss_ctc 5.194313 loss_rnnt 2.191676 hw_loss 0.163700 lr 0.00028936 rank 3
2023-03-01 09:25:31,383 DEBUG TRAIN Batch 53/1300 loss 8.216090 loss_att 8.624245 loss_ctc 12.297168 loss_rnnt 7.377989 hw_loss 0.398114 lr 0.00028935 rank 3
2023-03-01 09:25:31,387 DEBUG TRAIN Batch 53/1300 loss 2.892040 loss_att 6.560633 loss_ctc 3.923454 loss_rnnt 1.859346 hw_loss 0.302727 lr 0.00028936 rank 4
2023-03-01 09:25:31,395 DEBUG TRAIN Batch 53/1300 loss 4.610119 loss_att 5.710849 loss_ctc 9.509917 loss_rnnt 3.577390 hw_loss 0.298644 lr 0.00028935 rank 7
2023-03-01 09:25:31,395 DEBUG TRAIN Batch 53/1300 loss 5.683649 loss_att 7.049527 loss_ctc 5.994821 loss_rnnt 5.263675 hw_loss 0.197454 lr 0.00028935 rank 6
2023-03-01 09:25:31,397 DEBUG TRAIN Batch 53/1300 loss 4.656571 loss_att 7.664605 loss_ctc 6.319281 loss_rnnt 3.806233 hw_loss 0.050695 lr 0.00028935 rank 5
2023-03-01 09:25:31,397 DEBUG TRAIN Batch 53/1300 loss 5.605900 loss_att 11.278741 loss_ctc 6.062687 loss_rnnt 4.294327 hw_loss 0.217687 lr 0.00028936 rank 0
2023-03-01 09:25:31,407 DEBUG TRAIN Batch 53/1300 loss 7.757246 loss_att 8.748727 loss_ctc 11.377155 loss_rnnt 6.967358 hw_loss 0.204254 lr 0.00028935 rank 1
2023-03-01 09:25:31,409 DEBUG TRAIN Batch 53/1300 loss 6.098751 loss_att 8.804276 loss_ctc 12.510099 loss_rnnt 4.621884 hw_loss 0.151714 lr 0.00028936 rank 2
2023-03-01 09:26:11,142 DEBUG TRAIN Batch 53/1400 loss 1.093398 loss_att 4.181391 loss_ctc 1.804608 loss_rnnt 0.348873 hw_loss 0.060183 lr 0.00028934 rank 1
2023-03-01 09:26:11,145 DEBUG TRAIN Batch 53/1400 loss 3.855973 loss_att 9.611176 loss_ctc 6.718801 loss_rnnt 2.154028 hw_loss 0.317239 lr 0.00028934 rank 3
2023-03-01 09:26:11,146 DEBUG TRAIN Batch 53/1400 loss 5.404322 loss_att 8.438624 loss_ctc 9.449963 loss_rnnt 4.171108 hw_loss 0.163003 lr 0.00028935 rank 2
2023-03-01 09:26:11,146 DEBUG TRAIN Batch 53/1400 loss 3.768089 loss_att 7.441648 loss_ctc 5.798358 loss_rnnt 2.644523 hw_loss 0.221534 lr 0.00028934 rank 5
2023-03-01 09:26:11,146 DEBUG TRAIN Batch 53/1400 loss 6.985159 loss_att 10.072239 loss_ctc 11.200137 loss_rnnt 5.685075 hw_loss 0.226258 lr 0.00028935 rank 4
2023-03-01 09:26:11,148 DEBUG TRAIN Batch 53/1400 loss 8.074848 loss_att 12.721283 loss_ctc 17.154068 loss_rnnt 5.894506 hw_loss 0.075925 lr 0.00028934 rank 6
2023-03-01 09:26:11,155 DEBUG TRAIN Batch 53/1400 loss 2.704131 loss_att 4.572173 loss_ctc 6.074453 loss_rnnt 1.786615 hw_loss 0.177246 lr 0.00028935 rank 0
2023-03-01 09:26:11,155 DEBUG TRAIN Batch 53/1400 loss 3.868879 loss_att 6.743979 loss_ctc 6.888427 loss_rnnt 2.853392 hw_loss 0.070989 lr 0.00028934 rank 7
2023-03-01 09:27:16,439 DEBUG TRAIN Batch 53/1500 loss 9.056973 loss_att 10.253668 loss_ctc 12.839190 loss_rnnt 8.230812 hw_loss 0.154736 lr 0.00028934 rank 0
2023-03-01 09:27:16,442 DEBUG TRAIN Batch 53/1500 loss 6.717638 loss_att 10.736249 loss_ctc 10.804093 loss_rnnt 5.263635 hw_loss 0.197662 lr 0.00028934 rank 2
2023-03-01 09:27:16,444 DEBUG TRAIN Batch 53/1500 loss 9.382691 loss_att 11.706649 loss_ctc 14.223227 loss_rnnt 8.253504 hw_loss 0.035608 lr 0.00028933 rank 7
2023-03-01 09:27:16,446 DEBUG TRAIN Batch 53/1500 loss 6.765803 loss_att 7.797160 loss_ctc 7.697475 loss_rnnt 6.379525 hw_loss 0.104594 lr 0.00028933 rank 1
2023-03-01 09:27:16,447 DEBUG TRAIN Batch 53/1500 loss 7.707932 loss_att 11.754772 loss_ctc 12.664713 loss_rnnt 6.138741 hw_loss 0.185473 lr 0.00028933 rank 5
2023-03-01 09:27:16,449 DEBUG TRAIN Batch 53/1500 loss 8.265937 loss_att 10.583733 loss_ctc 11.888029 loss_rnnt 7.117402 hw_loss 0.378807 lr 0.00028933 rank 4
2023-03-01 09:27:16,451 DEBUG TRAIN Batch 53/1500 loss 2.790076 loss_att 5.074997 loss_ctc 4.368752 loss_rnnt 2.040087 hw_loss 0.154713 lr 0.00028932 rank 3
2023-03-01 09:27:16,493 DEBUG TRAIN Batch 53/1500 loss 3.540224 loss_att 6.349084 loss_ctc 5.049710 loss_rnnt 2.663366 hw_loss 0.213415 lr 0.00028933 rank 6
2023-03-01 09:27:54,488 DEBUG TRAIN Batch 53/1600 loss 3.549181 loss_att 7.089638 loss_ctc 7.371057 loss_rnnt 2.277030 hw_loss 0.102144 lr 0.00028931 rank 7
2023-03-01 09:27:54,488 DEBUG TRAIN Batch 53/1600 loss 3.688807 loss_att 6.578500 loss_ctc 8.037589 loss_rnnt 2.404562 hw_loss 0.237130 lr 0.00028932 rank 0
2023-03-01 09:27:54,489 DEBUG TRAIN Batch 53/1600 loss 3.090632 loss_att 6.508095 loss_ctc 7.395396 loss_rnnt 1.793742 hw_loss 0.073930 lr 0.00028932 rank 2
2023-03-01 09:27:54,490 DEBUG TRAIN Batch 53/1600 loss 6.697521 loss_att 8.109498 loss_ctc 8.853004 loss_rnnt 6.027222 hw_loss 0.188449 lr 0.00028931 rank 5
2023-03-01 09:27:54,491 DEBUG TRAIN Batch 53/1600 loss 7.561750 loss_att 10.466498 loss_ctc 11.384625 loss_rnnt 6.343573 hw_loss 0.239084 lr 0.00028932 rank 6
2023-03-01 09:27:54,492 DEBUG TRAIN Batch 53/1600 loss 6.289547 loss_att 8.497261 loss_ctc 9.387097 loss_rnnt 5.286354 hw_loss 0.278707 lr 0.00028932 rank 4
2023-03-01 09:27:54,495 DEBUG TRAIN Batch 53/1600 loss 8.782389 loss_att 12.970776 loss_ctc 13.865622 loss_rnnt 7.177616 hw_loss 0.167493 lr 0.00028932 rank 1
2023-03-01 09:27:54,495 DEBUG TRAIN Batch 53/1600 loss 8.994469 loss_att 13.627007 loss_ctc 19.693295 loss_rnnt 6.618438 hw_loss 0.043148 lr 0.00028931 rank 3
2023-03-01 09:28:33,096 DEBUG TRAIN Batch 53/1700 loss 8.368822 loss_att 10.892606 loss_ctc 12.962722 loss_rnnt 7.085437 hw_loss 0.311453 lr 0.00028931 rank 2
2023-03-01 09:28:33,097 DEBUG TRAIN Batch 53/1700 loss 8.177105 loss_att 10.680849 loss_ctc 14.390421 loss_rnnt 6.710260 hw_loss 0.258102 lr 0.00028931 rank 1
2023-03-01 09:28:33,112 DEBUG TRAIN Batch 53/1700 loss 8.891997 loss_att 12.853033 loss_ctc 16.157299 loss_rnnt 7.032962 hw_loss 0.183979 lr 0.00028931 rank 0
2023-03-01 09:28:33,112 DEBUG TRAIN Batch 53/1700 loss 14.134187 loss_att 20.095224 loss_ctc 22.222330 loss_rnnt 11.779049 hw_loss 0.158457 lr 0.00028930 rank 7
2023-03-01 09:28:33,117 DEBUG TRAIN Batch 53/1700 loss 2.585882 loss_att 4.324404 loss_ctc 4.744882 loss_rnnt 1.840772 hw_loss 0.205386 lr 0.00028931 rank 4
2023-03-01 09:28:33,122 DEBUG TRAIN Batch 53/1700 loss 3.525181 loss_att 4.973054 loss_ctc 4.779987 loss_rnnt 2.972587 hw_loss 0.179459 lr 0.00028930 rank 3
2023-03-01 09:28:33,127 DEBUG TRAIN Batch 53/1700 loss 1.458730 loss_att 3.430573 loss_ctc 4.224166 loss_rnnt 0.586643 hw_loss 0.204362 lr 0.00028930 rank 6
2023-03-01 09:28:33,151 DEBUG TRAIN Batch 53/1700 loss 6.121717 loss_att 7.653380 loss_ctc 9.182208 loss_rnnt 5.317317 hw_loss 0.168754 lr 0.00028930 rank 5
2023-03-01 09:29:39,162 DEBUG TRAIN Batch 53/1800 loss 6.883223 loss_att 8.572135 loss_ctc 10.688590 loss_rnnt 5.948844 hw_loss 0.167275 lr 0.00028929 rank 5
2023-03-01 09:29:39,165 DEBUG TRAIN Batch 53/1800 loss 8.160624 loss_att 11.686325 loss_ctc 13.706782 loss_rnnt 6.542749 hw_loss 0.324835 lr 0.00028930 rank 0
2023-03-01 09:29:39,172 DEBUG TRAIN Batch 53/1800 loss 4.186373 loss_att 6.059193 loss_ctc 5.856596 loss_rnnt 3.521045 hw_loss 0.127627 lr 0.00028929 rank 6
2023-03-01 09:29:39,173 DEBUG TRAIN Batch 53/1800 loss 7.119146 loss_att 9.998909 loss_ctc 12.608863 loss_rnnt 5.657810 hw_loss 0.287665 lr 0.00028930 rank 2
2023-03-01 09:29:39,175 DEBUG TRAIN Batch 53/1800 loss 6.380595 loss_att 8.089784 loss_ctc 11.244596 loss_rnnt 5.292122 hw_loss 0.183940 lr 0.00028929 rank 7
2023-03-01 09:29:39,176 DEBUG TRAIN Batch 53/1800 loss 10.138279 loss_att 12.250401 loss_ctc 14.860533 loss_rnnt 8.898180 hw_loss 0.352577 lr 0.00028929 rank 1
2023-03-01 09:29:39,178 DEBUG TRAIN Batch 53/1800 loss 10.309132 loss_att 11.734499 loss_ctc 13.240661 loss_rnnt 9.548461 hw_loss 0.158864 lr 0.00028930 rank 4
2023-03-01 09:29:39,191 DEBUG TRAIN Batch 53/1800 loss 6.918378 loss_att 8.575503 loss_ctc 8.139972 loss_rnnt 6.300401 hw_loss 0.231887 lr 0.00028929 rank 3
2023-03-01 09:30:18,421 DEBUG TRAIN Batch 53/1900 loss 7.347960 loss_att 9.839040 loss_ctc 15.298106 loss_rnnt 5.669347 hw_loss 0.225708 lr 0.00028929 rank 4
2023-03-01 09:30:18,422 DEBUG TRAIN Batch 53/1900 loss 8.246531 loss_att 13.013992 loss_ctc 20.318047 loss_rnnt 5.666143 hw_loss 0.032549 lr 0.00028929 rank 2
2023-03-01 09:30:18,438 DEBUG TRAIN Batch 53/1900 loss 4.898098 loss_att 6.579914 loss_ctc 8.246743 loss_rnnt 3.978376 hw_loss 0.256634 lr 0.00028928 rank 6
2023-03-01 09:30:18,438 DEBUG TRAIN Batch 53/1900 loss 7.064643 loss_att 9.148647 loss_ctc 8.954460 loss_rnnt 6.227736 hw_loss 0.315247 lr 0.00028928 rank 5
2023-03-01 09:30:18,441 DEBUG TRAIN Batch 53/1900 loss 8.850424 loss_att 13.041954 loss_ctc 18.465111 loss_rnnt 6.629067 hw_loss 0.189548 lr 0.00028928 rank 3
2023-03-01 09:30:18,443 DEBUG TRAIN Batch 53/1900 loss 8.155378 loss_att 8.809613 loss_ctc 14.860102 loss_rnnt 7.005873 hw_loss 0.233805 lr 0.00028928 rank 7
2023-03-01 09:30:18,446 DEBUG TRAIN Batch 53/1900 loss 3.346776 loss_att 5.478275 loss_ctc 8.004307 loss_rnnt 2.214224 hw_loss 0.159840 lr 0.00028929 rank 0
2023-03-01 09:30:18,463 DEBUG TRAIN Batch 53/1900 loss 9.547784 loss_att 10.890599 loss_ctc 12.237010 loss_rnnt 8.845761 hw_loss 0.140429 lr 0.00028928 rank 1
2023-03-01 09:30:56,654 DEBUG TRAIN Batch 53/2000 loss 4.282660 loss_att 8.584238 loss_ctc 8.873178 loss_rnnt 2.721889 hw_loss 0.165723 lr 0.00028927 rank 4
2023-03-01 09:30:56,655 DEBUG TRAIN Batch 53/2000 loss 4.384400 loss_att 8.108077 loss_ctc 8.010867 loss_rnnt 3.017902 hw_loss 0.259190 lr 0.00028927 rank 6
2023-03-01 09:30:56,660 DEBUG TRAIN Batch 53/2000 loss 6.423205 loss_att 12.734541 loss_ctc 23.289898 loss_rnnt 2.851366 hw_loss 0.113776 lr 0.00028928 rank 2
2023-03-01 09:30:56,676 DEBUG TRAIN Batch 53/2000 loss 5.633849 loss_att 9.834166 loss_ctc 9.161932 loss_rnnt 4.153858 hw_loss 0.317844 lr 0.00028926 rank 7
2023-03-01 09:30:56,678 DEBUG TRAIN Batch 53/2000 loss 5.064393 loss_att 9.998447 loss_ctc 12.517141 loss_rnnt 3.004186 hw_loss 0.149430 lr 0.00028928 rank 0
2023-03-01 09:30:56,680 DEBUG TRAIN Batch 53/2000 loss 1.896598 loss_att 5.205536 loss_ctc 3.530169 loss_rnnt 0.901280 hw_loss 0.216977 lr 0.00028926 rank 3
2023-03-01 09:30:56,683 DEBUG TRAIN Batch 53/2000 loss 4.127450 loss_att 8.527710 loss_ctc 8.721372 loss_rnnt 2.496261 hw_loss 0.259901 lr 0.00028927 rank 1
2023-03-01 09:30:56,726 DEBUG TRAIN Batch 53/2000 loss 4.329945 loss_att 8.851249 loss_ctc 5.260056 loss_rnnt 3.176947 hw_loss 0.233854 lr 0.00028927 rank 5
2023-03-01 09:31:36,143 DEBUG TRAIN Batch 53/2100 loss 5.463638 loss_att 8.526181 loss_ctc 9.621517 loss_rnnt 4.246797 hw_loss 0.093653 lr 0.00028926 rank 1
2023-03-01 09:31:36,161 DEBUG TRAIN Batch 53/2100 loss 2.599633 loss_att 5.029570 loss_ctc 5.359472 loss_rnnt 1.649888 hw_loss 0.179586 lr 0.00028926 rank 6
2023-03-01 09:31:36,161 DEBUG TRAIN Batch 53/2100 loss 7.837659 loss_att 10.337961 loss_ctc 8.090381 loss_rnnt 7.252840 hw_loss 0.095743 lr 0.00028925 rank 3
2023-03-01 09:31:36,163 DEBUG TRAIN Batch 53/2100 loss 2.412769 loss_att 4.394052 loss_ctc 3.457592 loss_rnnt 1.784833 hw_loss 0.173192 lr 0.00028925 rank 7
2023-03-01 09:31:36,165 DEBUG TRAIN Batch 53/2100 loss 2.111707 loss_att 5.398797 loss_ctc 5.998975 loss_rnnt 0.819143 hw_loss 0.219083 lr 0.00028926 rank 0
2023-03-01 09:31:36,167 DEBUG TRAIN Batch 53/2100 loss 3.480023 loss_att 6.969872 loss_ctc 6.142905 loss_rnnt 2.375219 hw_loss 0.097094 lr 0.00028926 rank 2
2023-03-01 09:31:36,173 DEBUG TRAIN Batch 53/2100 loss 7.307672 loss_att 9.079352 loss_ctc 6.817091 loss_rnnt 6.880623 hw_loss 0.258980 lr 0.00028925 rank 5
2023-03-01 09:31:36,188 DEBUG TRAIN Batch 53/2100 loss 6.698598 loss_att 7.462381 loss_ctc 13.888244 loss_rnnt 5.522617 hw_loss 0.121134 lr 0.00028926 rank 4
2023-03-01 09:32:41,025 DEBUG TRAIN Batch 53/2200 loss 6.999641 loss_att 7.386097 loss_ctc 10.638309 loss_rnnt 6.322874 hw_loss 0.214352 lr 0.00028925 rank 0
2023-03-01 09:32:41,029 DEBUG TRAIN Batch 53/2200 loss 8.365743 loss_att 11.450677 loss_ctc 19.217091 loss_rnnt 6.226723 hw_loss 0.140976 lr 0.00028925 rank 2
2023-03-01 09:32:41,029 DEBUG TRAIN Batch 53/2200 loss 3.265398 loss_att 6.390146 loss_ctc 4.509790 loss_rnnt 2.298908 hw_loss 0.329289 lr 0.00028925 rank 1
2023-03-01 09:32:41,030 DEBUG TRAIN Batch 53/2200 loss 4.864940 loss_att 7.744754 loss_ctc 7.510499 loss_rnnt 3.804883 hw_loss 0.246287 lr 0.00028925 rank 4
2023-03-01 09:32:41,035 DEBUG TRAIN Batch 53/2200 loss 2.302994 loss_att 4.597532 loss_ctc 3.995031 loss_rnnt 1.542432 hw_loss 0.142592 lr 0.00028924 rank 3
2023-03-01 09:32:41,036 DEBUG TRAIN Batch 53/2200 loss 7.282144 loss_att 10.821913 loss_ctc 9.671798 loss_rnnt 6.153586 hw_loss 0.191218 lr 0.00028924 rank 5
2023-03-01 09:32:41,037 DEBUG TRAIN Batch 53/2200 loss 2.881990 loss_att 5.784683 loss_ctc 4.870294 loss_rnnt 1.898497 hw_loss 0.258464 lr 0.00028924 rank 7
2023-03-01 09:32:41,088 DEBUG TRAIN Batch 53/2200 loss 3.723749 loss_att 6.619773 loss_ctc 9.133018 loss_rnnt 2.377671 hw_loss 0.085570 lr 0.00028924 rank 6
2023-03-01 09:33:19,618 DEBUG TRAIN Batch 53/2300 loss 7.678976 loss_att 10.865965 loss_ctc 13.207748 loss_rnnt 6.199153 hw_loss 0.197353 lr 0.00028923 rank 3
2023-03-01 09:33:19,626 DEBUG TRAIN Batch 53/2300 loss 10.034157 loss_att 15.488342 loss_ctc 13.893351 loss_rnnt 8.337747 hw_loss 0.170651 lr 0.00028924 rank 2
2023-03-01 09:33:19,628 DEBUG TRAIN Batch 53/2300 loss 9.033428 loss_att 10.547739 loss_ctc 17.828981 loss_rnnt 7.521075 hw_loss 0.068908 lr 0.00028924 rank 0
2023-03-01 09:33:19,628 DEBUG TRAIN Batch 53/2300 loss 7.937427 loss_att 10.849880 loss_ctc 15.916315 loss_rnnt 6.186274 hw_loss 0.196521 lr 0.00028924 rank 4
2023-03-01 09:33:19,630 DEBUG TRAIN Batch 53/2300 loss 12.369848 loss_att 17.984917 loss_ctc 19.037556 loss_rnnt 10.256461 hw_loss 0.190023 lr 0.00028923 rank 5
2023-03-01 09:33:19,632 DEBUG TRAIN Batch 53/2300 loss 7.145895 loss_att 9.941947 loss_ctc 10.356279 loss_rnnt 6.048774 hw_loss 0.205989 lr 0.00028923 rank 6
2023-03-01 09:33:19,632 DEBUG TRAIN Batch 53/2300 loss 8.888384 loss_att 10.304790 loss_ctc 16.597790 loss_rnnt 7.429592 hw_loss 0.276731 lr 0.00028923 rank 7
2023-03-01 09:33:19,675 DEBUG TRAIN Batch 53/2300 loss 2.746042 loss_att 4.000347 loss_ctc 4.395066 loss_rnnt 2.160091 hw_loss 0.216039 lr 0.00028923 rank 1
2023-03-01 09:33:58,708 DEBUG TRAIN Batch 53/2400 loss 8.414305 loss_att 10.535619 loss_ctc 11.804870 loss_rnnt 7.366110 hw_loss 0.322230 lr 0.00028923 rank 0
2023-03-01 09:33:58,708 DEBUG TRAIN Batch 53/2400 loss 1.927079 loss_att 5.023948 loss_ctc 3.685760 loss_rnnt 0.994156 hw_loss 0.148234 lr 0.00028922 rank 6
2023-03-01 09:33:58,709 DEBUG TRAIN Batch 53/2400 loss 5.778869 loss_att 7.525675 loss_ctc 8.567214 loss_rnnt 4.958999 hw_loss 0.185116 lr 0.00028922 rank 5
2023-03-01 09:33:58,719 DEBUG TRAIN Batch 53/2400 loss 4.161022 loss_att 6.193293 loss_ctc 7.893070 loss_rnnt 3.164478 hw_loss 0.173406 lr 0.00028922 rank 3
2023-03-01 09:33:58,722 DEBUG TRAIN Batch 53/2400 loss 10.861375 loss_att 13.668465 loss_ctc 15.786342 loss_rnnt 9.555865 hw_loss 0.163930 lr 0.00028923 rank 2
2023-03-01 09:33:58,722 DEBUG TRAIN Batch 53/2400 loss 3.986690 loss_att 7.758825 loss_ctc 9.151684 loss_rnnt 2.482071 hw_loss 0.115361 lr 0.00028922 rank 1
2023-03-01 09:33:58,723 DEBUG TRAIN Batch 53/2400 loss 4.791663 loss_att 7.709708 loss_ctc 10.075979 loss_rnnt 3.360342 hw_loss 0.268382 lr 0.00028922 rank 7
2023-03-01 09:33:58,742 DEBUG TRAIN Batch 53/2400 loss 6.506916 loss_att 7.900986 loss_ctc 10.989666 loss_rnnt 5.580945 hw_loss 0.092731 lr 0.00028922 rank 4
2023-03-01 09:35:04,579 DEBUG TRAIN Batch 53/2500 loss 7.298416 loss_att 11.692141 loss_ctc 12.894104 loss_rnnt 5.571434 hw_loss 0.191521 lr 0.00028922 rank 2
2023-03-01 09:35:04,594 DEBUG TRAIN Batch 53/2500 loss 4.332237 loss_att 7.280826 loss_ctc 9.880782 loss_rnnt 2.906943 hw_loss 0.179569 lr 0.00028920 rank 7
2023-03-01 09:35:04,598 DEBUG TRAIN Batch 53/2500 loss 3.380946 loss_att 4.632168 loss_ctc 5.872728 loss_rnnt 2.687888 hw_loss 0.207330 lr 0.00028921 rank 4
2023-03-01 09:35:04,598 DEBUG TRAIN Batch 53/2500 loss 3.812663 loss_att 6.017348 loss_ctc 4.345770 loss_rnnt 3.212184 hw_loss 0.165863 lr 0.00028921 rank 1
2023-03-01 09:35:04,601 DEBUG TRAIN Batch 53/2500 loss 4.114127 loss_att 6.057959 loss_ctc 11.363536 loss_rnnt 2.608805 hw_loss 0.281190 lr 0.00028922 rank 0
2023-03-01 09:35:04,603 DEBUG TRAIN Batch 53/2500 loss 6.495192 loss_att 9.763533 loss_ctc 10.912142 loss_rnnt 5.161086 hw_loss 0.171583 lr 0.00028921 rank 5
2023-03-01 09:35:04,603 DEBUG TRAIN Batch 53/2500 loss 6.170049 loss_att 7.089613 loss_ctc 10.738872 loss_rnnt 5.249562 hw_loss 0.238869 lr 0.00028920 rank 3
2023-03-01 09:35:04,653 DEBUG TRAIN Batch 53/2500 loss 7.247352 loss_att 9.179438 loss_ctc 12.372492 loss_rnnt 6.025095 hw_loss 0.285915 lr 0.00028921 rank 6
2023-03-01 09:35:43,143 DEBUG TRAIN Batch 53/2600 loss 3.940943 loss_att 5.892365 loss_ctc 7.845756 loss_rnnt 2.860641 hw_loss 0.317582 lr 0.00028919 rank 7
2023-03-01 09:35:43,158 DEBUG TRAIN Batch 53/2600 loss 3.824026 loss_att 7.613415 loss_ctc 6.972173 loss_rnnt 2.614586 hw_loss 0.059641 lr 0.00028920 rank 1
2023-03-01 09:35:43,161 DEBUG TRAIN Batch 53/2600 loss 4.420389 loss_att 6.877218 loss_ctc 10.163717 loss_rnnt 3.069190 hw_loss 0.176355 lr 0.00028919 rank 5
2023-03-01 09:35:43,161 DEBUG TRAIN Batch 53/2600 loss 5.050182 loss_att 7.723146 loss_ctc 8.407810 loss_rnnt 3.977165 hw_loss 0.170139 lr 0.00028920 rank 4
2023-03-01 09:35:43,161 DEBUG TRAIN Batch 53/2600 loss 8.543639 loss_att 11.501629 loss_ctc 9.913587 loss_rnnt 7.591217 hw_loss 0.334060 lr 0.00028920 rank 6
2023-03-01 09:35:43,163 DEBUG TRAIN Batch 53/2600 loss 2.449569 loss_att 5.230246 loss_ctc 3.413867 loss_rnnt 1.652101 hw_loss 0.211423 lr 0.00028920 rank 0
2023-03-01 09:35:43,164 DEBUG TRAIN Batch 53/2600 loss 10.567523 loss_att 16.790579 loss_ctc 17.194599 loss_rnnt 8.388855 hw_loss 0.094588 lr 0.00028919 rank 3
2023-03-01 09:35:43,205 DEBUG TRAIN Batch 53/2600 loss 2.442338 loss_att 5.859290 loss_ctc 7.030494 loss_rnnt 1.058566 hw_loss 0.166176 lr 0.00028920 rank 2
2023-03-01 09:36:21,862 DEBUG TRAIN Batch 53/2700 loss 5.348209 loss_att 8.079924 loss_ctc 6.828395 loss_rnnt 4.421906 hw_loss 0.342379 lr 0.00028918 rank 1
2023-03-01 09:36:21,863 DEBUG TRAIN Batch 53/2700 loss 1.399876 loss_att 4.255761 loss_ctc 3.906449 loss_rnnt 0.493422 hw_loss 0.002000 lr 0.00028918 rank 7
2023-03-01 09:36:21,864 DEBUG TRAIN Batch 53/2700 loss 2.581311 loss_att 5.206254 loss_ctc 5.482374 loss_rnnt 1.510944 hw_loss 0.297319 lr 0.00028918 rank 5
2023-03-01 09:36:21,883 DEBUG TRAIN Batch 53/2700 loss 1.478400 loss_att 3.335471 loss_ctc 1.919356 loss_rnnt 0.992010 hw_loss 0.105339 lr 0.00028918 rank 3
2023-03-01 09:36:21,885 DEBUG TRAIN Batch 53/2700 loss 7.177129 loss_att 8.408352 loss_ctc 12.013026 loss_rnnt 6.111604 hw_loss 0.327177 lr 0.00028919 rank 2
2023-03-01 09:36:21,886 DEBUG TRAIN Batch 53/2700 loss 5.045846 loss_att 8.220427 loss_ctc 7.503608 loss_rnnt 4.013634 hw_loss 0.130492 lr 0.00028919 rank 4
2023-03-01 09:36:21,889 DEBUG TRAIN Batch 53/2700 loss 4.448253 loss_att 8.425879 loss_ctc 7.471498 loss_rnnt 3.120762 hw_loss 0.241625 lr 0.00028918 rank 6
2023-03-01 09:36:21,889 DEBUG TRAIN Batch 53/2700 loss 9.283853 loss_att 13.344166 loss_ctc 15.506950 loss_rnnt 7.556717 hw_loss 0.159987 lr 0.00028919 rank 0
2023-03-01 09:37:01,709 DEBUG TRAIN Batch 53/2800 loss 6.010170 loss_att 9.945147 loss_ctc 10.701185 loss_rnnt 4.518816 hw_loss 0.147918 lr 0.00028918 rank 4
2023-03-01 09:37:01,710 DEBUG TRAIN Batch 53/2800 loss 4.308093 loss_att 7.634008 loss_ctc 6.944939 loss_rnnt 3.211718 hw_loss 0.149272 lr 0.00028917 rank 5
2023-03-01 09:37:01,719 DEBUG TRAIN Batch 53/2800 loss 5.457407 loss_att 6.722911 loss_ctc 6.300540 loss_rnnt 4.993477 hw_loss 0.184523 lr 0.00028917 rank 7
2023-03-01 09:37:01,720 DEBUG TRAIN Batch 53/2800 loss 7.146992 loss_att 9.602300 loss_ctc 12.636561 loss_rnnt 5.795176 hw_loss 0.241523 lr 0.00028917 rank 1
2023-03-01 09:37:01,728 DEBUG TRAIN Batch 53/2800 loss 3.626167 loss_att 8.342294 loss_ctc 8.546404 loss_rnnt 1.978948 hw_loss 0.089929 lr 0.00028918 rank 0
2023-03-01 09:37:01,729 DEBUG TRAIN Batch 53/2800 loss 4.626159 loss_att 7.545456 loss_ctc 8.246760 loss_rnnt 3.394494 hw_loss 0.309486 lr 0.00028918 rank 2
2023-03-01 09:37:01,731 DEBUG TRAIN Batch 53/2800 loss 13.099550 loss_att 18.214012 loss_ctc 14.221000 loss_rnnt 11.786711 hw_loss 0.263290 lr 0.00028917 rank 3
2023-03-01 09:37:01,736 DEBUG TRAIN Batch 53/2800 loss 1.587558 loss_att 3.427057 loss_ctc 2.054892 loss_rnnt 0.956912 hw_loss 0.375816 lr 0.00028917 rank 6
2023-03-01 09:38:07,143 DEBUG TRAIN Batch 53/2900 loss 3.705297 loss_att 6.398830 loss_ctc 8.852080 loss_rnnt 2.409531 hw_loss 0.132792 lr 0.00028916 rank 6
2023-03-01 09:38:07,146 DEBUG TRAIN Batch 53/2900 loss 7.458385 loss_att 10.629650 loss_ctc 11.832949 loss_rnnt 6.173396 hw_loss 0.126491 lr 0.00028916 rank 1
2023-03-01 09:38:07,151 DEBUG TRAIN Batch 53/2900 loss 6.406422 loss_att 8.848892 loss_ctc 11.754527 loss_rnnt 5.124690 hw_loss 0.150295 lr 0.00028916 rank 7
2023-03-01 09:38:07,152 DEBUG TRAIN Batch 53/2900 loss 8.570251 loss_att 12.788903 loss_ctc 13.675331 loss_rnnt 6.868052 hw_loss 0.333359 lr 0.00028917 rank 2
2023-03-01 09:38:07,152 DEBUG TRAIN Batch 53/2900 loss 3.319934 loss_att 4.959009 loss_ctc 4.337679 loss_rnnt 2.808065 hw_loss 0.090664 lr 0.00028916 rank 5
2023-03-01 09:38:07,152 DEBUG TRAIN Batch 53/2900 loss 4.713355 loss_att 7.147182 loss_ctc 8.130177 loss_rnnt 3.609644 hw_loss 0.302566 lr 0.00028916 rank 4
2023-03-01 09:38:07,154 DEBUG TRAIN Batch 53/2900 loss 7.980639 loss_att 11.347961 loss_ctc 15.185848 loss_rnnt 6.248556 hw_loss 0.183607 lr 0.00028916 rank 3
2023-03-01 09:38:07,155 DEBUG TRAIN Batch 53/2900 loss 3.795716 loss_att 5.288927 loss_ctc 5.235103 loss_rnnt 3.252070 hw_loss 0.099536 lr 0.00028917 rank 0
2023-03-01 09:38:45,577 DEBUG TRAIN Batch 53/3000 loss 8.869411 loss_att 12.001421 loss_ctc 17.531898 loss_rnnt 6.990247 hw_loss 0.183308 lr 0.00028915 rank 5
2023-03-01 09:38:45,586 DEBUG TRAIN Batch 53/3000 loss 4.198694 loss_att 7.739372 loss_ctc 8.871853 loss_rnnt 2.710684 hw_loss 0.293976 lr 0.00028915 rank 0
2023-03-01 09:38:45,589 DEBUG TRAIN Batch 53/3000 loss 6.413247 loss_att 9.896154 loss_ctc 7.928370 loss_rnnt 5.493199 hw_loss 0.040217 lr 0.00028915 rank 1
2023-03-01 09:38:45,591 DEBUG TRAIN Batch 53/3000 loss 7.971708 loss_att 9.495479 loss_ctc 11.130630 loss_rnnt 7.144374 hw_loss 0.190104 lr 0.00028915 rank 6
2023-03-01 09:38:45,593 DEBUG TRAIN Batch 53/3000 loss 2.729386 loss_att 4.642362 loss_ctc 3.519827 loss_rnnt 2.198915 hw_loss 0.079657 lr 0.00028915 rank 2
2023-03-01 09:38:45,596 DEBUG TRAIN Batch 53/3000 loss 9.036096 loss_att 13.296262 loss_ctc 18.743885 loss_rnnt 6.825875 hw_loss 0.119652 lr 0.00028914 rank 7
2023-03-01 09:38:45,600 DEBUG TRAIN Batch 53/3000 loss 5.413696 loss_att 6.560468 loss_ctc 6.801759 loss_rnnt 4.882893 hw_loss 0.218199 lr 0.00028915 rank 4
2023-03-01 09:38:45,602 DEBUG TRAIN Batch 53/3000 loss 5.097654 loss_att 6.981974 loss_ctc 10.041721 loss_rnnt 3.982946 hw_loss 0.147441 lr 0.00028914 rank 3
2023-03-01 09:39:24,908 DEBUG TRAIN Batch 53/3100 loss 8.055693 loss_att 10.333647 loss_ctc 14.180392 loss_rnnt 6.648273 hw_loss 0.253504 lr 0.00028914 rank 6
2023-03-01 09:39:24,913 DEBUG TRAIN Batch 53/3100 loss 5.373888 loss_att 7.221373 loss_ctc 8.247352 loss_rnnt 4.490833 hw_loss 0.244554 lr 0.00028914 rank 1
2023-03-01 09:39:24,924 DEBUG TRAIN Batch 53/3100 loss 6.281721 loss_att 7.035364 loss_ctc 9.592072 loss_rnnt 5.524098 hw_loss 0.310338 lr 0.00028914 rank 2
2023-03-01 09:39:24,925 DEBUG TRAIN Batch 53/3100 loss 5.681011 loss_att 8.689764 loss_ctc 13.184020 loss_rnnt 3.960431 hw_loss 0.222053 lr 0.00028913 rank 7
2023-03-01 09:39:24,926 DEBUG TRAIN Batch 53/3100 loss 5.823961 loss_att 6.844868 loss_ctc 9.437077 loss_rnnt 4.988655 hw_loss 0.280081 lr 0.00028914 rank 4
2023-03-01 09:39:24,927 DEBUG TRAIN Batch 53/3100 loss 9.282783 loss_att 10.724658 loss_ctc 13.674120 loss_rnnt 8.329128 hw_loss 0.149564 lr 0.00028913 rank 5
2023-03-01 09:39:24,934 DEBUG TRAIN Batch 53/3100 loss 8.234376 loss_att 12.211161 loss_ctc 15.573639 loss_rnnt 6.330835 hw_loss 0.243028 lr 0.00028914 rank 0
2023-03-01 09:39:24,969 DEBUG TRAIN Batch 53/3100 loss 2.728396 loss_att 6.939001 loss_ctc 4.735581 loss_rnnt 1.525825 hw_loss 0.174049 lr 0.00028913 rank 3
2023-03-01 09:40:31,624 DEBUG TRAIN Batch 53/3200 loss 4.275951 loss_att 7.655744 loss_ctc 7.796352 loss_rnnt 3.030756 hw_loss 0.187219 lr 0.00028912 rank 7
2023-03-01 09:40:31,631 DEBUG TRAIN Batch 53/3200 loss 6.579088 loss_att 7.677008 loss_ctc 12.167069 loss_rnnt 5.448166 hw_loss 0.311762 lr 0.00028913 rank 0
2023-03-01 09:40:31,631 DEBUG TRAIN Batch 53/3200 loss 7.551682 loss_att 8.205750 loss_ctc 10.361788 loss_rnnt 6.888795 hw_loss 0.295110 lr 0.00028912 rank 6
2023-03-01 09:40:31,632 DEBUG TRAIN Batch 53/3200 loss 8.765368 loss_att 10.598505 loss_ctc 14.256154 loss_rnnt 7.530824 hw_loss 0.254648 lr 0.00028912 rank 3
2023-03-01 09:40:31,635 DEBUG TRAIN Batch 53/3200 loss 7.768817 loss_att 8.522450 loss_ctc 11.578214 loss_rnnt 6.978471 hw_loss 0.246937 lr 0.00028912 rank 1
2023-03-01 09:40:31,636 DEBUG TRAIN Batch 53/3200 loss 7.704317 loss_att 10.831525 loss_ctc 12.304080 loss_rnnt 6.379127 hw_loss 0.162086 lr 0.00028912 rank 5
2023-03-01 09:40:31,654 DEBUG TRAIN Batch 53/3200 loss 2.098765 loss_att 5.532377 loss_ctc 3.599271 loss_rnnt 1.106430 hw_loss 0.197896 lr 0.00028913 rank 2
2023-03-01 09:40:31,680 DEBUG TRAIN Batch 53/3200 loss 1.893133 loss_att 5.120748 loss_ctc 3.606884 loss_rnnt 0.881417 hw_loss 0.258175 lr 0.00028913 rank 4
2023-03-01 09:41:09,984 DEBUG TRAIN Batch 53/3300 loss 5.227154 loss_att 10.022095 loss_ctc 12.132762 loss_rnnt 3.347170 hw_loss 0.000465 lr 0.00028911 rank 7
2023-03-01 09:41:09,988 DEBUG TRAIN Batch 53/3300 loss 1.412539 loss_att 3.120957 loss_ctc 3.320219 loss_rnnt 0.786195 hw_loss 0.056819 lr 0.00028912 rank 0
2023-03-01 09:41:09,989 DEBUG TRAIN Batch 53/3300 loss 4.039310 loss_att 8.340899 loss_ctc 7.516937 loss_rnnt 2.588309 hw_loss 0.238124 lr 0.00028911 rank 5
2023-03-01 09:41:09,989 DEBUG TRAIN Batch 53/3300 loss 8.419724 loss_att 13.229305 loss_ctc 16.123379 loss_rnnt 6.401302 hw_loss 0.055036 lr 0.00028911 rank 1
2023-03-01 09:41:09,992 DEBUG TRAIN Batch 53/3300 loss 5.749009 loss_att 10.800983 loss_ctc 10.092239 loss_rnnt 3.997511 hw_loss 0.303761 lr 0.00028911 rank 3
2023-03-01 09:41:09,996 DEBUG TRAIN Batch 53/3300 loss 6.473634 loss_att 10.621774 loss_ctc 13.129664 loss_rnnt 4.700534 hw_loss 0.105003 lr 0.00028911 rank 6
2023-03-01 09:41:10,004 DEBUG TRAIN Batch 53/3300 loss 1.097200 loss_att 3.833921 loss_ctc 2.963339 loss_rnnt 0.286066 hw_loss 0.028070 lr 0.00028912 rank 4
2023-03-01 09:41:10,031 DEBUG TRAIN Batch 53/3300 loss 2.609644 loss_att 4.831139 loss_ctc 3.949488 loss_rnnt 1.878831 hw_loss 0.202251 lr 0.00028912 rank 2
2023-03-01 09:41:48,596 DEBUG TRAIN Batch 53/3400 loss 10.375776 loss_att 12.197337 loss_ctc 24.201313 loss_rnnt 8.020183 hw_loss 0.277270 lr 0.00028911 rank 2
2023-03-01 09:41:48,598 DEBUG TRAIN Batch 53/3400 loss 1.092475 loss_att 3.187318 loss_ctc 2.097681 loss_rnnt 0.491872 hw_loss 0.089263 lr 0.00028910 rank 4
2023-03-01 09:41:48,599 DEBUG TRAIN Batch 53/3400 loss 5.843013 loss_att 7.972784 loss_ctc 11.927978 loss_rnnt 4.489470 hw_loss 0.217988 lr 0.00028910 rank 6
2023-03-01 09:41:48,599 DEBUG TRAIN Batch 53/3400 loss 3.191931 loss_att 5.504543 loss_ctc 6.758633 loss_rnnt 2.190029 hw_loss 0.119662 lr 0.00028910 rank 1
2023-03-01 09:41:48,604 DEBUG TRAIN Batch 53/3400 loss 4.306775 loss_att 8.164598 loss_ctc 9.166346 loss_rnnt 2.704837 hw_loss 0.342056 lr 0.00028911 rank 0
2023-03-01 09:41:48,603 DEBUG TRAIN Batch 53/3400 loss 6.950875 loss_att 12.135153 loss_ctc 11.651173 loss_rnnt 5.112225 hw_loss 0.328291 lr 0.00028910 rank 5
2023-03-01 09:41:48,606 DEBUG TRAIN Batch 53/3400 loss 2.574937 loss_att 5.811555 loss_ctc 5.424774 loss_rnnt 1.452605 hw_loss 0.178182 lr 0.00028910 rank 7
2023-03-01 09:41:48,605 DEBUG TRAIN Batch 53/3400 loss 4.253538 loss_att 7.835528 loss_ctc 6.213941 loss_rnnt 3.131041 hw_loss 0.271334 lr 0.00028909 rank 3
2023-03-01 09:42:28,334 DEBUG TRAIN Batch 53/3500 loss 11.701191 loss_att 15.410822 loss_ctc 21.182350 loss_rnnt 9.565342 hw_loss 0.243314 lr 0.00028909 rank 2
2023-03-01 09:42:28,335 DEBUG TRAIN Batch 53/3500 loss 3.979178 loss_att 8.676495 loss_ctc 7.259480 loss_rnnt 2.512960 hw_loss 0.167589 lr 0.00028909 rank 0
2023-03-01 09:42:28,335 DEBUG TRAIN Batch 53/3500 loss 5.999472 loss_att 11.262852 loss_ctc 13.101059 loss_rnnt 3.854846 hw_loss 0.272010 lr 0.00028908 rank 5
2023-03-01 09:42:28,345 DEBUG TRAIN Batch 53/3500 loss 5.988778 loss_att 9.215095 loss_ctc 9.940920 loss_rnnt 4.686385 hw_loss 0.244082 lr 0.00028909 rank 4
2023-03-01 09:42:28,354 DEBUG TRAIN Batch 53/3500 loss 13.932427 loss_att 15.846251 loss_ctc 18.804010 loss_rnnt 12.787434 hw_loss 0.211284 lr 0.00028908 rank 7
2023-03-01 09:42:28,354 DEBUG TRAIN Batch 53/3500 loss 3.859166 loss_att 7.006172 loss_ctc 8.098617 loss_rnnt 2.625906 hw_loss 0.072373 lr 0.00028909 rank 1
2023-03-01 09:42:28,355 DEBUG TRAIN Batch 53/3500 loss 5.597023 loss_att 8.219570 loss_ctc 10.580388 loss_rnnt 4.265472 hw_loss 0.267361 lr 0.00028908 rank 3
2023-03-01 09:42:28,374 DEBUG TRAIN Batch 53/3500 loss 9.040791 loss_att 10.355712 loss_ctc 15.712835 loss_rnnt 7.821802 hw_loss 0.124496 lr 0.00028909 rank 6
2023-03-01 09:43:35,265 DEBUG TRAIN Batch 53/3600 loss 5.748965 loss_att 8.095441 loss_ctc 8.909067 loss_rnnt 4.674657 hw_loss 0.344373 lr 0.00028908 rank 4
2023-03-01 09:43:35,283 DEBUG TRAIN Batch 53/3600 loss 5.453835 loss_att 12.071451 loss_ctc 13.381508 loss_rnnt 2.978507 hw_loss 0.177716 lr 0.00028907 rank 3
2023-03-01 09:43:35,283 DEBUG TRAIN Batch 53/3600 loss 4.186259 loss_att 6.746087 loss_ctc 7.782331 loss_rnnt 3.087511 hw_loss 0.201200 lr 0.00028907 rank 5
2023-03-01 09:43:35,283 DEBUG TRAIN Batch 53/3600 loss 8.783792 loss_att 12.969886 loss_ctc 11.745882 loss_rnnt 7.391968 hw_loss 0.299363 lr 0.00028908 rank 1
2023-03-01 09:43:35,284 DEBUG TRAIN Batch 53/3600 loss 2.760396 loss_att 3.438937 loss_ctc 2.893131 loss_rnnt 2.500563 hw_loss 0.199550 lr 0.00028907 rank 7
2023-03-01 09:43:35,285 DEBUG TRAIN Batch 53/3600 loss 6.877914 loss_att 9.398319 loss_ctc 8.477175 loss_rnnt 6.002962 hw_loss 0.295568 lr 0.00028908 rank 0
2023-03-01 09:43:35,292 DEBUG TRAIN Batch 53/3600 loss 4.922455 loss_att 7.000822 loss_ctc 12.015026 loss_rnnt 3.406177 hw_loss 0.290491 lr 0.00028907 rank 6
2023-03-01 09:43:35,306 DEBUG TRAIN Batch 53/3600 loss 7.041996 loss_att 9.451701 loss_ctc 11.144001 loss_rnnt 5.958530 hw_loss 0.102359 lr 0.00028908 rank 2
2023-03-01 09:44:14,042 DEBUG TRAIN Batch 53/3700 loss 5.934374 loss_att 7.300068 loss_ctc 8.354111 loss_rnnt 5.190048 hw_loss 0.278542 lr 0.00028906 rank 1
2023-03-01 09:44:14,042 DEBUG TRAIN Batch 53/3700 loss 2.511782 loss_att 4.883695 loss_ctc 3.640589 loss_rnnt 1.789515 hw_loss 0.182580 lr 0.00028906 rank 7
2023-03-01 09:44:14,043 DEBUG TRAIN Batch 53/3700 loss 7.745022 loss_att 12.047460 loss_ctc 14.703884 loss_rnnt 5.866753 hw_loss 0.168626 lr 0.00028906 rank 3
2023-03-01 09:44:14,046 DEBUG TRAIN Batch 53/3700 loss 4.523786 loss_att 7.595536 loss_ctc 10.877419 loss_rnnt 2.937791 hw_loss 0.233425 lr 0.00028907 rank 0
2023-03-01 09:44:14,052 DEBUG TRAIN Batch 53/3700 loss 3.950795 loss_att 8.572507 loss_ctc 7.725111 loss_rnnt 2.343216 hw_loss 0.337489 lr 0.00028906 rank 5
2023-03-01 09:44:14,052 DEBUG TRAIN Batch 53/3700 loss 7.147068 loss_att 9.857598 loss_ctc 14.316724 loss_rnnt 5.555618 hw_loss 0.175106 lr 0.00028907 rank 4
2023-03-01 09:44:14,079 DEBUG TRAIN Batch 53/3700 loss 4.252874 loss_att 5.962087 loss_ctc 5.870930 loss_rnnt 3.555985 hw_loss 0.261198 lr 0.00028907 rank 2
2023-03-01 09:44:14,082 DEBUG TRAIN Batch 53/3700 loss 4.569061 loss_att 7.984237 loss_ctc 9.597034 loss_rnnt 3.098326 hw_loss 0.219943 lr 0.00028906 rank 6
2023-03-01 09:44:53,188 DEBUG TRAIN Batch 53/3800 loss 8.079917 loss_att 9.978775 loss_ctc 13.001399 loss_rnnt 6.939835 hw_loss 0.195211 lr 0.00028906 rank 0
2023-03-01 09:44:53,193 DEBUG TRAIN Batch 53/3800 loss 6.646862 loss_att 7.277319 loss_ctc 9.010811 loss_rnnt 6.020309 hw_loss 0.347377 lr 0.00028905 rank 7
2023-03-01 09:44:53,196 DEBUG TRAIN Batch 53/3800 loss 7.235562 loss_att 10.764457 loss_ctc 12.817050 loss_rnnt 5.605549 hw_loss 0.337567 lr 0.00028906 rank 2
2023-03-01 09:44:53,197 DEBUG TRAIN Batch 53/3800 loss 5.815130 loss_att 7.635977 loss_ctc 10.135742 loss_rnnt 4.719847 hw_loss 0.290685 lr 0.00028905 rank 1
2023-03-01 09:44:53,198 DEBUG TRAIN Batch 53/3800 loss 4.820761 loss_att 6.248616 loss_ctc 8.713080 loss_rnnt 3.910908 hw_loss 0.197447 lr 0.00028905 rank 5
2023-03-01 09:44:53,198 DEBUG TRAIN Batch 53/3800 loss 6.754003 loss_att 11.976400 loss_ctc 9.249676 loss_rnnt 5.233497 hw_loss 0.268630 lr 0.00028906 rank 4
2023-03-01 09:44:53,202 DEBUG TRAIN Batch 53/3800 loss 3.147362 loss_att 4.966572 loss_ctc 5.544267 loss_rnnt 2.321292 hw_loss 0.267450 lr 0.00028905 rank 3
2023-03-01 09:44:53,205 DEBUG TRAIN Batch 53/3800 loss 10.291396 loss_att 12.342405 loss_ctc 15.982699 loss_rnnt 9.017694 hw_loss 0.196236 lr 0.00028905 rank 6
2023-03-01 09:45:33,221 DEBUG TRAIN Batch 53/3900 loss 5.236835 loss_att 10.487022 loss_ctc 13.675673 loss_rnnt 2.989763 hw_loss 0.134730 lr 0.00028904 rank 4
2023-03-01 09:45:33,227 DEBUG TRAIN Batch 53/3900 loss 9.359514 loss_att 10.841758 loss_ctc 15.473980 loss_rnnt 8.174419 hw_loss 0.137593 lr 0.00028903 rank 3
2023-03-01 09:45:33,230 DEBUG TRAIN Batch 53/3900 loss 6.685206 loss_att 9.697668 loss_ctc 8.064204 loss_rnnt 5.801421 hw_loss 0.182674 lr 0.00028904 rank 5
2023-03-01 09:45:33,228 DEBUG TRAIN Batch 53/3900 loss 5.843192 loss_att 7.180121 loss_ctc 9.547925 loss_rnnt 4.987414 hw_loss 0.177051 lr 0.00028904 rank 1
2023-03-01 09:45:33,235 DEBUG TRAIN Batch 53/3900 loss 2.287301 loss_att 4.884541 loss_ctc 4.859282 loss_rnnt 1.424485 hw_loss 0.000820 lr 0.00028905 rank 2
2023-03-01 09:45:33,236 DEBUG TRAIN Batch 53/3900 loss 7.914388 loss_att 12.453870 loss_ctc 12.542682 loss_rnnt 6.265488 hw_loss 0.232309 lr 0.00028905 rank 0
2023-03-01 09:45:33,237 DEBUG TRAIN Batch 53/3900 loss 4.751666 loss_att 9.233050 loss_ctc 5.709069 loss_rnnt 3.726874 hw_loss 0.001616 lr 0.00028904 rank 7
2023-03-01 09:45:33,244 DEBUG TRAIN Batch 53/3900 loss 3.631380 loss_att 7.244160 loss_ctc 6.948736 loss_rnnt 2.285060 hw_loss 0.340216 lr 0.00028904 rank 6
2023-03-01 09:46:37,204 DEBUG TRAIN Batch 53/4000 loss 3.203544 loss_att 8.199776 loss_ctc 4.911797 loss_rnnt 1.902326 hw_loss 0.139133 lr 0.00028903 rank 2
2023-03-01 09:46:37,208 DEBUG TRAIN Batch 53/4000 loss 2.591642 loss_att 5.684011 loss_ctc 6.956496 loss_rnnt 1.339795 hw_loss 0.096361 lr 0.00028903 rank 6
2023-03-01 09:46:37,211 DEBUG TRAIN Batch 53/4000 loss 4.401695 loss_att 7.146776 loss_ctc 6.987255 loss_rnnt 3.441419 hw_loss 0.124721 lr 0.00028902 rank 5
2023-03-01 09:46:37,214 DEBUG TRAIN Batch 53/4000 loss 10.539721 loss_att 15.364304 loss_ctc 20.796833 loss_rnnt 8.118519 hw_loss 0.166256 lr 0.00028903 rank 1
2023-03-01 09:46:37,219 DEBUG TRAIN Batch 53/4000 loss 7.660662 loss_att 8.628734 loss_ctc 13.997412 loss_rnnt 6.504666 hw_loss 0.220276 lr 0.00028903 rank 0
2023-03-01 09:46:37,222 DEBUG TRAIN Batch 53/4000 loss 8.361044 loss_att 11.424093 loss_ctc 18.408068 loss_rnnt 6.279935 hw_loss 0.241677 lr 0.00028902 rank 3
2023-03-01 09:46:37,226 DEBUG TRAIN Batch 53/4000 loss 11.069448 loss_att 14.263859 loss_ctc 20.582218 loss_rnnt 9.091429 hw_loss 0.132692 lr 0.00028902 rank 7
2023-03-01 09:46:37,246 DEBUG TRAIN Batch 53/4000 loss 6.119724 loss_att 10.424446 loss_ctc 11.667416 loss_rnnt 4.353544 hw_loss 0.310396 lr 0.00028903 rank 4
2023-03-01 09:47:15,846 DEBUG TRAIN Batch 53/4100 loss 4.964074 loss_att 8.645230 loss_ctc 10.601127 loss_rnnt 3.265876 hw_loss 0.394425 lr 0.00028902 rank 1
2023-03-01 09:47:15,850 DEBUG TRAIN Batch 53/4100 loss 7.519359 loss_att 9.252547 loss_ctc 14.545197 loss_rnnt 6.075253 hw_loss 0.301292 lr 0.00028902 rank 4
2023-03-01 09:47:15,850 DEBUG TRAIN Batch 53/4100 loss 3.191941 loss_att 6.334476 loss_ctc 6.012429 loss_rnnt 2.093277 hw_loss 0.176421 lr 0.00028902 rank 0
2023-03-01 09:47:15,853 DEBUG TRAIN Batch 53/4100 loss 5.425918 loss_att 8.288597 loss_ctc 11.145441 loss_rnnt 3.959384 hw_loss 0.246364 lr 0.00028901 rank 3
2023-03-01 09:47:15,853 DEBUG TRAIN Batch 53/4100 loss 4.040932 loss_att 8.146233 loss_ctc 8.356487 loss_rnnt 2.497292 hw_loss 0.275948 lr 0.00028901 rank 7
2023-03-01 09:47:15,854 DEBUG TRAIN Batch 53/4100 loss 8.182344 loss_att 10.351571 loss_ctc 12.810064 loss_rnnt 7.076368 hw_loss 0.103317 lr 0.00028901 rank 6
2023-03-01 09:47:15,854 DEBUG TRAIN Batch 53/4100 loss 10.136736 loss_att 13.539846 loss_ctc 16.837168 loss_rnnt 8.367909 hw_loss 0.365275 lr 0.00028902 rank 2
2023-03-01 09:47:15,874 DEBUG TRAIN Batch 53/4100 loss 5.442470 loss_att 10.714633 loss_ctc 12.868294 loss_rnnt 3.232255 hw_loss 0.310636 lr 0.00028901 rank 5
2023-03-01 09:47:55,010 DEBUG TRAIN Batch 53/4200 loss 1.378453 loss_att 3.857392 loss_ctc 1.247898 loss_rnnt 0.764840 hw_loss 0.253561 lr 0.00028900 rank 7
2023-03-01 09:47:55,024 DEBUG TRAIN Batch 53/4200 loss 5.181494 loss_att 7.999419 loss_ctc 7.090614 loss_rnnt 4.281826 hw_loss 0.152876 lr 0.00028900 rank 1
2023-03-01 09:47:55,026 DEBUG TRAIN Batch 53/4200 loss 5.837867 loss_att 8.809368 loss_ctc 8.551205 loss_rnnt 4.824113 hw_loss 0.108139 lr 0.00028900 rank 6
2023-03-01 09:47:55,029 DEBUG TRAIN Batch 53/4200 loss 10.428426 loss_att 14.522124 loss_ctc 15.004308 loss_rnnt 8.816759 hw_loss 0.342766 lr 0.00028900 rank 3
2023-03-01 09:47:55,030 DEBUG TRAIN Batch 53/4200 loss 3.243148 loss_att 5.020474 loss_ctc 4.222844 loss_rnnt 2.608417 hw_loss 0.278699 lr 0.00028901 rank 2
2023-03-01 09:47:55,030 DEBUG TRAIN Batch 53/4200 loss 5.872699 loss_att 9.938900 loss_ctc 11.729154 loss_rnnt 4.221198 hw_loss 0.107625 lr 0.00028901 rank 0
2023-03-01 09:47:55,052 DEBUG TRAIN Batch 53/4200 loss 7.932293 loss_att 10.439168 loss_ctc 12.640474 loss_rnnt 6.665087 hw_loss 0.258888 lr 0.00028900 rank 5
2023-03-01 09:47:55,058 DEBUG TRAIN Batch 53/4200 loss 3.412325 loss_att 6.935725 loss_ctc 7.794053 loss_rnnt 2.010695 hw_loss 0.211349 lr 0.00028901 rank 4
2023-03-01 09:49:00,638 DEBUG TRAIN Batch 53/4300 loss 4.327859 loss_att 5.560769 loss_ctc 7.316008 loss_rnnt 3.554358 hw_loss 0.240936 lr 0.00028899 rank 1
2023-03-01 09:49:00,639 DEBUG TRAIN Batch 53/4300 loss 5.952619 loss_att 10.088268 loss_ctc 11.634846 loss_rnnt 4.214785 hw_loss 0.287012 lr 0.00028899 rank 6
2023-03-01 09:49:00,654 DEBUG TRAIN Batch 53/4300 loss 11.684012 loss_att 15.878334 loss_ctc 21.315550 loss_rnnt 9.460199 hw_loss 0.188894 lr 0.00028900 rank 4
2023-03-01 09:49:00,658 DEBUG TRAIN Batch 53/4300 loss 9.377593 loss_att 10.378115 loss_ctc 14.854311 loss_rnnt 8.314900 hw_loss 0.248172 lr 0.00028899 rank 3
2023-03-01 09:49:00,660 DEBUG TRAIN Batch 53/4300 loss 3.956647 loss_att 5.785163 loss_ctc 8.432592 loss_rnnt 2.903612 hw_loss 0.169762 lr 0.00028900 rank 2
2023-03-01 09:49:00,671 DEBUG TRAIN Batch 53/4300 loss 4.532900 loss_att 6.938645 loss_ctc 7.229232 loss_rnnt 3.536289 hw_loss 0.292409 lr 0.00028899 rank 5
2023-03-01 09:49:00,674 DEBUG TRAIN Batch 53/4300 loss 4.729847 loss_att 10.688139 loss_ctc 8.911672 loss_rnnt 2.859433 hw_loss 0.227211 lr 0.00028899 rank 7
2023-03-01 09:49:00,688 DEBUG TRAIN Batch 53/4300 loss 5.177635 loss_att 9.664660 loss_ctc 12.189601 loss_rnnt 3.282157 hw_loss 0.118396 lr 0.00028900 rank 0
2023-03-01 09:49:39,689 DEBUG TRAIN Batch 53/4400 loss 5.381013 loss_att 7.135062 loss_ctc 8.026035 loss_rnnt 4.551516 hw_loss 0.236283 lr 0.00028897 rank 7
2023-03-01 09:49:39,691 DEBUG TRAIN Batch 53/4400 loss 8.303566 loss_att 10.168505 loss_ctc 10.060549 loss_rnnt 7.596691 hw_loss 0.186794 lr 0.00028898 rank 1
2023-03-01 09:49:39,692 DEBUG TRAIN Batch 53/4400 loss 7.231789 loss_att 11.917399 loss_ctc 11.025511 loss_rnnt 5.716889 hw_loss 0.134903 lr 0.00028898 rank 5
2023-03-01 09:49:39,693 DEBUG TRAIN Batch 53/4400 loss 3.513420 loss_att 7.350945 loss_ctc 6.899331 loss_rnnt 2.148942 hw_loss 0.272846 lr 0.00028897 rank 3
2023-03-01 09:49:39,694 DEBUG TRAIN Batch 53/4400 loss 4.930430 loss_att 7.333579 loss_ctc 8.394284 loss_rnnt 3.942151 hw_loss 0.085880 lr 0.00028899 rank 0
2023-03-01 09:49:39,694 DEBUG TRAIN Batch 53/4400 loss 8.281220 loss_att 11.693755 loss_ctc 10.719690 loss_rnnt 7.177167 hw_loss 0.180782 lr 0.00028899 rank 2
2023-03-01 09:49:39,698 DEBUG TRAIN Batch 53/4400 loss 4.339182 loss_att 6.486567 loss_ctc 8.256663 loss_rnnt 3.263901 hw_loss 0.231511 lr 0.00028898 rank 6
2023-03-01 09:49:39,746 DEBUG TRAIN Batch 53/4400 loss 5.789857 loss_att 6.170323 loss_ctc 8.799539 loss_rnnt 5.219967 hw_loss 0.173448 lr 0.00028898 rank 4
2023-03-01 09:50:18,504 DEBUG TRAIN Batch 53/4500 loss 4.625750 loss_att 6.758542 loss_ctc 4.668341 loss_rnnt 4.108330 hw_loss 0.159717 lr 0.00028897 rank 0
2023-03-01 09:50:18,506 DEBUG TRAIN Batch 53/4500 loss 4.697420 loss_att 7.134606 loss_ctc 7.037654 loss_rnnt 3.848376 hw_loss 0.092955 lr 0.00028896 rank 3
2023-03-01 09:50:18,517 DEBUG TRAIN Batch 53/4500 loss 6.091737 loss_att 10.291997 loss_ctc 15.693275 loss_rnnt 3.891135 hw_loss 0.150647 lr 0.00028896 rank 7
2023-03-01 09:50:18,520 DEBUG TRAIN Batch 53/4500 loss 0.572252 loss_att 2.208203 loss_ctc 0.511653 loss_rnnt 0.106829 hw_loss 0.274335 lr 0.00028897 rank 4
2023-03-01 09:50:18,521 DEBUG TRAIN Batch 53/4500 loss 1.840558 loss_att 5.478049 loss_ctc 3.780911 loss_rnnt 0.736686 hw_loss 0.220614 lr 0.00028897 rank 1
2023-03-01 09:50:18,521 DEBUG TRAIN Batch 53/4500 loss 6.242802 loss_att 9.767157 loss_ctc 11.732996 loss_rnnt 4.712183 hw_loss 0.175728 lr 0.00028897 rank 2
2023-03-01 09:50:18,522 DEBUG TRAIN Batch 53/4500 loss 4.705334 loss_att 5.574141 loss_ctc 9.784866 loss_rnnt 3.762869 hw_loss 0.171435 lr 0.00028896 rank 5
2023-03-01 09:50:18,523 DEBUG TRAIN Batch 53/4500 loss 7.303324 loss_att 10.320055 loss_ctc 12.901066 loss_rnnt 5.906981 hw_loss 0.087431 lr 0.00028897 rank 6
2023-03-01 09:50:58,343 DEBUG TRAIN Batch 53/4600 loss 1.520931 loss_att 5.258001 loss_ctc 2.952736 loss_rnnt 0.483161 hw_loss 0.186466 lr 0.00028895 rank 3
2023-03-01 09:50:58,344 DEBUG TRAIN Batch 53/4600 loss 8.165071 loss_att 12.280170 loss_ctc 18.777657 loss_rnnt 5.851337 hw_loss 0.141945 lr 0.00028896 rank 1
2023-03-01 09:50:58,353 DEBUG TRAIN Batch 53/4600 loss 5.722332 loss_att 9.611847 loss_ctc 7.883512 loss_rnnt 4.593265 hw_loss 0.118138 lr 0.00028896 rank 0
2023-03-01 09:50:58,354 DEBUG TRAIN Batch 53/4600 loss 5.532998 loss_att 9.891932 loss_ctc 9.515137 loss_rnnt 4.045790 hw_loss 0.158379 lr 0.00028896 rank 2
2023-03-01 09:50:58,357 DEBUG TRAIN Batch 53/4600 loss 2.550994 loss_att 5.982446 loss_ctc 6.648613 loss_rnnt 1.190315 hw_loss 0.240075 lr 0.00028895 rank 7
2023-03-01 09:50:58,357 DEBUG TRAIN Batch 53/4600 loss 2.812919 loss_att 5.410062 loss_ctc 4.812065 loss_rnnt 1.889408 hw_loss 0.257868 lr 0.00028895 rank 5
2023-03-01 09:50:58,363 DEBUG TRAIN Batch 53/4600 loss 7.385169 loss_att 11.550328 loss_ctc 12.398463 loss_rnnt 5.801552 hw_loss 0.154024 lr 0.00028896 rank 4
2023-03-01 09:50:58,368 DEBUG TRAIN Batch 53/4600 loss 4.144571 loss_att 9.092005 loss_ctc 8.973898 loss_rnnt 2.429903 hw_loss 0.152386 lr 0.00028895 rank 6
2023-03-01 09:52:06,049 DEBUG TRAIN Batch 53/4700 loss 3.405941 loss_att 5.411820 loss_ctc 3.690848 loss_rnnt 2.889116 hw_loss 0.145614 lr 0.00028894 rank 1
2023-03-01 09:52:06,053 DEBUG TRAIN Batch 53/4700 loss 8.025903 loss_att 12.643679 loss_ctc 17.140697 loss_rnnt 5.770473 hw_loss 0.218566 lr 0.00028895 rank 4
2023-03-01 09:52:06,053 DEBUG TRAIN Batch 53/4700 loss 9.048206 loss_att 12.559258 loss_ctc 15.811634 loss_rnnt 7.300380 hw_loss 0.269676 lr 0.00028894 rank 3
2023-03-01 09:52:06,062 DEBUG TRAIN Batch 53/4700 loss 7.388278 loss_att 10.838431 loss_ctc 13.386692 loss_rnnt 5.721973 hw_loss 0.330912 lr 0.00028894 rank 7
2023-03-01 09:52:06,063 DEBUG TRAIN Batch 53/4700 loss 3.721938 loss_att 6.944703 loss_ctc 4.150547 loss_rnnt 2.835626 hw_loss 0.346145 lr 0.00028895 rank 2
2023-03-01 09:52:06,064 DEBUG TRAIN Batch 53/4700 loss 7.686968 loss_att 9.979409 loss_ctc 12.186111 loss_rnnt 6.482415 hw_loss 0.274085 lr 0.00028895 rank 0
2023-03-01 09:52:06,067 DEBUG TRAIN Batch 53/4700 loss 3.314493 loss_att 6.643080 loss_ctc 7.361812 loss_rnnt 2.027458 hw_loss 0.153143 lr 0.00028894 rank 5
2023-03-01 09:52:06,067 DEBUG TRAIN Batch 53/4700 loss 2.771996 loss_att 5.656801 loss_ctc 2.916456 loss_rnnt 2.006209 hw_loss 0.317933 lr 0.00028894 rank 6
2023-03-01 09:52:44,389 DEBUG TRAIN Batch 53/4800 loss 3.937155 loss_att 7.006304 loss_ctc 7.363860 loss_rnnt 2.693297 hw_loss 0.324625 lr 0.00028893 rank 7
2023-03-01 09:52:44,391 DEBUG TRAIN Batch 53/4800 loss 6.678082 loss_att 11.944398 loss_ctc 12.471443 loss_rnnt 4.812198 hw_loss 0.075324 lr 0.00028894 rank 2
2023-03-01 09:52:44,393 DEBUG TRAIN Batch 53/4800 loss 5.486723 loss_att 10.725109 loss_ctc 9.857474 loss_rnnt 3.817564 hw_loss 0.072589 lr 0.00028894 rank 0
2023-03-01 09:52:44,400 DEBUG TRAIN Batch 53/4800 loss 4.548903 loss_att 7.816275 loss_ctc 7.838346 loss_rnnt 3.411806 hw_loss 0.084432 lr 0.00028893 rank 5
2023-03-01 09:52:44,400 DEBUG TRAIN Batch 53/4800 loss 9.108719 loss_att 11.194212 loss_ctc 16.526833 loss_rnnt 7.676068 hw_loss 0.049631 lr 0.00028893 rank 3
2023-03-01 09:52:44,401 DEBUG TRAIN Batch 53/4800 loss 4.679458 loss_att 7.608720 loss_ctc 6.660098 loss_rnnt 3.743230 hw_loss 0.161794 lr 0.00028893 rank 4
2023-03-01 09:52:44,404 DEBUG TRAIN Batch 53/4800 loss 3.168852 loss_att 5.537695 loss_ctc 6.225012 loss_rnnt 2.136833 hw_loss 0.282679 lr 0.00028893 rank 1
2023-03-01 09:52:44,405 DEBUG TRAIN Batch 53/4800 loss 3.495331 loss_att 7.190414 loss_ctc 5.341043 loss_rnnt 2.423721 hw_loss 0.162186 lr 0.00028893 rank 6
2023-03-01 09:53:23,140 DEBUG TRAIN Batch 53/4900 loss 4.400162 loss_att 8.125365 loss_ctc 6.729301 loss_rnnt 3.220924 hw_loss 0.231835 lr 0.00028892 rank 5
2023-03-01 09:53:23,148 DEBUG TRAIN Batch 53/4900 loss 4.365050 loss_att 8.189058 loss_ctc 7.934867 loss_rnnt 2.910591 hw_loss 0.400655 lr 0.00028891 rank 7
2023-03-01 09:53:23,149 DEBUG TRAIN Batch 53/4900 loss 10.906688 loss_att 14.010853 loss_ctc 14.519061 loss_rnnt 9.652038 hw_loss 0.285312 lr 0.00028893 rank 2
2023-03-01 09:53:23,150 DEBUG TRAIN Batch 53/4900 loss 5.399385 loss_att 7.455019 loss_ctc 9.117058 loss_rnnt 4.329932 hw_loss 0.304944 lr 0.00028892 rank 6
2023-03-01 09:53:23,151 DEBUG TRAIN Batch 53/4900 loss 8.796168 loss_att 10.687678 loss_ctc 12.233282 loss_rnnt 7.871584 hw_loss 0.165001 lr 0.00028892 rank 1
2023-03-01 09:53:23,152 DEBUG TRAIN Batch 53/4900 loss 10.839541 loss_att 14.724373 loss_ctc 19.609764 loss_rnnt 8.812300 hw_loss 0.151710 lr 0.00028893 rank 0
2023-03-01 09:53:23,154 DEBUG TRAIN Batch 53/4900 loss 8.163330 loss_att 10.786636 loss_ctc 14.370739 loss_rnnt 6.658257 hw_loss 0.286420 lr 0.00028892 rank 4
2023-03-01 09:53:23,176 DEBUG TRAIN Batch 53/4900 loss 3.415227 loss_att 4.376781 loss_ctc 6.624448 loss_rnnt 2.694448 hw_loss 0.188573 lr 0.00028891 rank 3
2023-03-01 09:54:29,619 DEBUG TRAIN Batch 53/5000 loss 4.316698 loss_att 6.315239 loss_ctc 5.569083 loss_rnnt 3.573707 hw_loss 0.330559 lr 0.00028891 rank 0
2023-03-01 09:54:29,621 DEBUG TRAIN Batch 53/5000 loss 7.773523 loss_att 10.356295 loss_ctc 11.441595 loss_rnnt 6.700728 hw_loss 0.125932 lr 0.00028890 rank 5
2023-03-01 09:54:29,621 DEBUG TRAIN Batch 53/5000 loss 10.135343 loss_att 12.112398 loss_ctc 16.660830 loss_rnnt 8.770044 hw_loss 0.187165 lr 0.00028890 rank 3
2023-03-01 09:54:29,622 DEBUG TRAIN Batch 53/5000 loss 2.877267 loss_att 4.932340 loss_ctc 4.286978 loss_rnnt 2.117487 hw_loss 0.301507 lr 0.00028891 rank 6
2023-03-01 09:54:29,624 DEBUG TRAIN Batch 53/5000 loss 5.078004 loss_att 7.962965 loss_ctc 11.317049 loss_rnnt 3.576263 hw_loss 0.174144 lr 0.00028890 rank 7
2023-03-01 09:54:29,627 DEBUG TRAIN Batch 53/5000 loss 5.056169 loss_att 6.849971 loss_ctc 9.862359 loss_rnnt 3.999020 hw_loss 0.107931 lr 0.00028891 rank 4
2023-03-01 09:54:29,628 DEBUG TRAIN Batch 53/5000 loss 8.117503 loss_att 9.034788 loss_ctc 13.085022 loss_rnnt 7.106115 hw_loss 0.310491 lr 0.00028891 rank 2
2023-03-01 09:54:29,630 DEBUG TRAIN Batch 53/5000 loss 9.545332 loss_att 12.775139 loss_ctc 15.612864 loss_rnnt 7.986782 hw_loss 0.194221 lr 0.00028891 rank 1
2023-03-01 09:55:08,025 DEBUG TRAIN Batch 53/5100 loss 6.854338 loss_att 10.433659 loss_ctc 11.057747 loss_rnnt 5.426128 hw_loss 0.284796 lr 0.00028890 rank 2
2023-03-01 09:55:08,041 DEBUG TRAIN Batch 53/5100 loss 7.954294 loss_att 9.280849 loss_ctc 10.715173 loss_rnnt 7.181481 hw_loss 0.261344 lr 0.00028889 rank 7
2023-03-01 09:55:08,043 DEBUG TRAIN Batch 53/5100 loss 7.213286 loss_att 7.704703 loss_ctc 12.752667 loss_rnnt 6.185123 hw_loss 0.358678 lr 0.00028890 rank 0
2023-03-01 09:55:08,046 DEBUG TRAIN Batch 53/5100 loss 6.358933 loss_att 7.694446 loss_ctc 9.331142 loss_rnnt 5.548506 hw_loss 0.275683 lr 0.00028889 rank 3
2023-03-01 09:55:08,054 DEBUG TRAIN Batch 53/5100 loss 4.172903 loss_att 5.457985 loss_ctc 6.039557 loss_rnnt 3.546847 hw_loss 0.225286 lr 0.00028889 rank 6
2023-03-01 09:55:08,060 DEBUG TRAIN Batch 53/5100 loss 2.174102 loss_att 4.613234 loss_ctc 4.749893 loss_rnnt 1.234649 hw_loss 0.202851 lr 0.00028889 rank 1
2023-03-01 09:55:08,070 DEBUG TRAIN Batch 53/5100 loss 8.633075 loss_att 13.038952 loss_ctc 18.543999 loss_rnnt 6.376352 hw_loss 0.101420 lr 0.00028890 rank 4
2023-03-01 09:55:08,080 DEBUG TRAIN Batch 53/5100 loss 4.357595 loss_att 5.660966 loss_ctc 6.874265 loss_rnnt 3.602651 hw_loss 0.297588 lr 0.00028889 rank 5
2023-03-01 09:55:46,451 DEBUG TRAIN Batch 53/5200 loss 9.124643 loss_att 9.818140 loss_ctc 16.014345 loss_rnnt 7.959074 hw_loss 0.202955 lr 0.00028889 rank 4
2023-03-01 09:55:46,461 DEBUG TRAIN Batch 53/5200 loss 4.246889 loss_att 6.283505 loss_ctc 7.079664 loss_rnnt 3.391553 hw_loss 0.131830 lr 0.00028888 rank 7
2023-03-01 09:55:46,464 DEBUG TRAIN Batch 53/5200 loss 7.491022 loss_att 11.514773 loss_ctc 15.043315 loss_rnnt 5.561476 hw_loss 0.220917 lr 0.00028888 rank 6
2023-03-01 09:55:46,465 DEBUG TRAIN Batch 53/5200 loss 6.493879 loss_att 6.849709 loss_ctc 10.290198 loss_rnnt 5.835296 hw_loss 0.152327 lr 0.00028889 rank 2
2023-03-01 09:55:46,465 DEBUG TRAIN Batch 53/5200 loss 7.852214 loss_att 9.876842 loss_ctc 13.905799 loss_rnnt 6.541091 hw_loss 0.185724 lr 0.00028888 rank 1
2023-03-01 09:55:46,466 DEBUG TRAIN Batch 53/5200 loss 4.272176 loss_att 6.651335 loss_ctc 6.989713 loss_rnnt 3.332352 hw_loss 0.190601 lr 0.00028889 rank 0
2023-03-01 09:55:46,466 DEBUG TRAIN Batch 53/5200 loss 6.357580 loss_att 9.503930 loss_ctc 12.326472 loss_rnnt 4.882021 hw_loss 0.094569 lr 0.00028888 rank 5
2023-03-01 09:55:46,466 DEBUG TRAIN Batch 53/5200 loss 1.717247 loss_att 5.027417 loss_ctc 3.331417 loss_rnnt 0.744443 hw_loss 0.179152 lr 0.00028888 rank 3
2023-03-01 09:56:26,583 DEBUG TRAIN Batch 53/5300 loss 3.375709 loss_att 6.514435 loss_ctc 6.178852 loss_rnnt 2.237876 hw_loss 0.255629 lr 0.00028888 rank 2
2023-03-01 09:56:26,587 DEBUG TRAIN Batch 53/5300 loss 8.461220 loss_att 9.313434 loss_ctc 14.416725 loss_rnnt 7.368774 hw_loss 0.239877 lr 0.00028887 rank 3
2023-03-01 09:56:26,591 DEBUG TRAIN Batch 53/5300 loss 8.180443 loss_att 13.339426 loss_ctc 8.877518 loss_rnnt 6.881093 hw_loss 0.327392 lr 0.00028887 rank 1
2023-03-01 09:56:26,592 DEBUG TRAIN Batch 53/5300 loss 4.972689 loss_att 8.465836 loss_ctc 7.967086 loss_rnnt 3.792196 hw_loss 0.154894 lr 0.00028887 rank 5
2023-03-01 09:56:26,598 DEBUG TRAIN Batch 53/5300 loss 5.639353 loss_att 8.494138 loss_ctc 9.709803 loss_rnnt 4.432138 hw_loss 0.175372 lr 0.00028887 rank 6
2023-03-01 09:56:26,599 DEBUG TRAIN Batch 53/5300 loss 13.932700 loss_att 19.254631 loss_ctc 30.979816 loss_rnnt 10.513474 hw_loss 0.153547 lr 0.00028888 rank 0
2023-03-01 09:56:26,599 DEBUG TRAIN Batch 53/5300 loss 8.668386 loss_att 11.424706 loss_ctc 13.493881 loss_rnnt 7.273800 hw_loss 0.374855 lr 0.00028887 rank 4
2023-03-01 09:56:26,602 DEBUG TRAIN Batch 53/5300 loss 5.659131 loss_att 8.676186 loss_ctc 10.790888 loss_rnnt 4.256618 hw_loss 0.215377 lr 0.00028887 rank 7
2023-03-01 09:57:32,477 DEBUG TRAIN Batch 53/5400 loss 6.486706 loss_att 9.129977 loss_ctc 11.009170 loss_rnnt 5.255047 hw_loss 0.187519 lr 0.00028886 rank 0
2023-03-01 09:57:32,488 DEBUG TRAIN Batch 53/5400 loss 2.168598 loss_att 5.379824 loss_ctc 4.550550 loss_rnnt 1.084834 hw_loss 0.232360 lr 0.00028886 rank 5
2023-03-01 09:57:32,488 DEBUG TRAIN Batch 53/5400 loss 4.096631 loss_att 10.070314 loss_ctc 12.380424 loss_rnnt 1.697863 hw_loss 0.186610 lr 0.00028886 rank 2
2023-03-01 09:57:32,490 DEBUG TRAIN Batch 53/5400 loss 9.946024 loss_att 11.000686 loss_ctc 12.081097 loss_rnnt 9.354009 hw_loss 0.180763 lr 0.00028885 rank 7
2023-03-01 09:57:32,491 DEBUG TRAIN Batch 53/5400 loss 6.492439 loss_att 7.308878 loss_ctc 8.598961 loss_rnnt 6.006696 hw_loss 0.077973 lr 0.00028885 rank 3
2023-03-01 09:57:32,491 DEBUG TRAIN Batch 53/5400 loss 7.857704 loss_att 11.069225 loss_ctc 16.349079 loss_rnnt 5.971052 hw_loss 0.210307 lr 0.00028886 rank 6
2023-03-01 09:57:32,493 DEBUG TRAIN Batch 53/5400 loss 3.668061 loss_att 5.551614 loss_ctc 6.588224 loss_rnnt 2.795269 hw_loss 0.200109 lr 0.00028886 rank 1
2023-03-01 09:57:32,500 DEBUG TRAIN Batch 53/5400 loss 5.849932 loss_att 8.571804 loss_ctc 12.606351 loss_rnnt 4.255267 hw_loss 0.280190 lr 0.00028886 rank 4
2023-03-01 09:58:10,921 DEBUG TRAIN Batch 53/5500 loss 5.132051 loss_att 7.260149 loss_ctc 8.740173 loss_rnnt 4.162911 hw_loss 0.117067 lr 0.00028884 rank 7
2023-03-01 09:58:10,928 DEBUG TRAIN Batch 53/5500 loss 5.612803 loss_att 7.887004 loss_ctc 10.779465 loss_rnnt 4.283097 hw_loss 0.348709 lr 0.00028885 rank 0
2023-03-01 09:58:10,940 DEBUG TRAIN Batch 53/5500 loss 4.209875 loss_att 5.894397 loss_ctc 9.577120 loss_rnnt 3.057611 hw_loss 0.186986 lr 0.00028885 rank 6
2023-03-01 09:58:10,943 DEBUG TRAIN Batch 53/5500 loss 6.863531 loss_att 11.217697 loss_ctc 12.812033 loss_rnnt 5.107905 hw_loss 0.171861 lr 0.00028885 rank 2
2023-03-01 09:58:10,944 DEBUG TRAIN Batch 53/5500 loss 6.868826 loss_att 8.664598 loss_ctc 12.321358 loss_rnnt 5.702415 hw_loss 0.150472 lr 0.00028885 rank 1
2023-03-01 09:58:10,945 DEBUG TRAIN Batch 53/5500 loss 7.260972 loss_att 9.986760 loss_ctc 12.699623 loss_rnnt 5.852484 hw_loss 0.259082 lr 0.00028884 rank 3
2023-03-01 09:58:10,946 DEBUG TRAIN Batch 53/5500 loss 4.536866 loss_att 8.823463 loss_ctc 7.592477 loss_rnnt 3.199034 hw_loss 0.137056 lr 0.00028885 rank 4
2023-03-01 09:58:10,945 DEBUG TRAIN Batch 53/5500 loss 6.655184 loss_att 10.501122 loss_ctc 13.227333 loss_rnnt 4.938891 hw_loss 0.132785 lr 0.00028884 rank 5
2023-03-01 09:58:50,169 DEBUG TRAIN Batch 53/5600 loss 4.084867 loss_att 5.952066 loss_ctc 7.083938 loss_rnnt 3.171373 hw_loss 0.262832 lr 0.00028884 rank 2
2023-03-01 09:58:50,180 DEBUG TRAIN Batch 53/5600 loss 10.105656 loss_att 15.014858 loss_ctc 16.267403 loss_rnnt 8.202239 hw_loss 0.187519 lr 0.00028883 rank 7
2023-03-01 09:58:50,182 DEBUG TRAIN Batch 53/5600 loss 3.061044 loss_att 4.853533 loss_ctc 4.675475 loss_rnnt 2.365458 hw_loss 0.228433 lr 0.00028883 rank 1
2023-03-01 09:58:50,183 DEBUG TRAIN Batch 53/5600 loss 2.596772 loss_att 4.240586 loss_ctc 3.808358 loss_rnnt 1.937352 hw_loss 0.317084 lr 0.00028883 rank 6
2023-03-01 09:58:50,184 DEBUG TRAIN Batch 53/5600 loss 9.605260 loss_att 10.792032 loss_ctc 12.476736 loss_rnnt 8.811639 hw_loss 0.325129 lr 0.00028884 rank 0
2023-03-01 09:58:50,186 DEBUG TRAIN Batch 53/5600 loss 4.072810 loss_att 7.980453 loss_ctc 9.423285 loss_rnnt 2.485710 hw_loss 0.172827 lr 0.00028883 rank 5
2023-03-01 09:58:50,187 DEBUG TRAIN Batch 53/5600 loss 9.375835 loss_att 11.400370 loss_ctc 16.454287 loss_rnnt 7.921701 hw_loss 0.197691 lr 0.00028883 rank 3
2023-03-01 09:58:50,193 DEBUG TRAIN Batch 53/5600 loss 0.996096 loss_att 2.496822 loss_ctc 1.907469 loss_rnnt 0.505608 hw_loss 0.129048 lr 0.00028884 rank 4
2023-03-01 09:59:55,852 DEBUG TRAIN Batch 53/5700 loss 6.710585 loss_att 8.903259 loss_ctc 9.172476 loss_rnnt 5.799542 hw_loss 0.270478 lr 0.00028883 rank 2
2023-03-01 09:59:55,857 DEBUG TRAIN Batch 53/5700 loss 6.379890 loss_att 8.138496 loss_ctc 9.307067 loss_rnnt 5.546524 hw_loss 0.171290 lr 0.00028882 rank 3
2023-03-01 09:59:55,865 DEBUG TRAIN Batch 53/5700 loss 7.680796 loss_att 8.231819 loss_ctc 12.584785 loss_rnnt 6.797360 hw_loss 0.223809 lr 0.00028882 rank 7
2023-03-01 09:59:55,871 DEBUG TRAIN Batch 53/5700 loss 6.384270 loss_att 8.121851 loss_ctc 12.474084 loss_rnnt 5.073605 hw_loss 0.283449 lr 0.00028883 rank 0
2023-03-01 09:59:55,873 DEBUG TRAIN Batch 53/5700 loss 6.594134 loss_att 7.558332 loss_ctc 12.044568 loss_rnnt 5.471616 hw_loss 0.380538 lr 0.00028882 rank 5
2023-03-01 09:59:55,876 DEBUG TRAIN Batch 53/5700 loss 9.211076 loss_att 13.152311 loss_ctc 20.051327 loss_rnnt 6.910604 hw_loss 0.125358 lr 0.00028883 rank 4
2023-03-01 09:59:55,877 DEBUG TRAIN Batch 53/5700 loss 13.109391 loss_att 13.753059 loss_ctc 19.525082 loss_rnnt 11.919630 hw_loss 0.385506 lr 0.00028882 rank 1
2023-03-01 09:59:55,910 DEBUG TRAIN Batch 53/5700 loss 10.161356 loss_att 17.584398 loss_ctc 16.698881 loss_rnnt 7.734529 hw_loss 0.132280 lr 0.00028882 rank 6
2023-03-01 10:00:34,893 DEBUG TRAIN Batch 53/5800 loss 6.833138 loss_att 7.014053 loss_ctc 10.204118 loss_rnnt 6.243613 hw_loss 0.194770 lr 0.00028882 rank 0
2023-03-01 10:00:34,894 DEBUG TRAIN Batch 53/5800 loss 5.753071 loss_att 7.089447 loss_ctc 8.846649 loss_rnnt 4.901142 hw_loss 0.322830 lr 0.00028881 rank 5
2023-03-01 10:00:34,895 DEBUG TRAIN Batch 53/5800 loss 2.717998 loss_att 5.781466 loss_ctc 6.022995 loss_rnnt 1.625268 hw_loss 0.073818 lr 0.00028881 rank 1
2023-03-01 10:00:34,899 DEBUG TRAIN Batch 53/5800 loss 2.638340 loss_att 4.737125 loss_ctc 4.353309 loss_rnnt 1.884692 hw_loss 0.197303 lr 0.00028881 rank 3
2023-03-01 10:00:34,900 DEBUG TRAIN Batch 53/5800 loss 7.414715 loss_att 7.734076 loss_ctc 10.383362 loss_rnnt 6.765561 hw_loss 0.355241 lr 0.00028881 rank 7
2023-03-01 10:00:34,901 DEBUG TRAIN Batch 53/5800 loss 3.279237 loss_att 7.523182 loss_ctc 6.749087 loss_rnnt 1.846202 hw_loss 0.227998 lr 0.00028882 rank 2
2023-03-01 10:00:34,902 DEBUG TRAIN Batch 53/5800 loss 2.825415 loss_att 5.949900 loss_ctc 3.757736 loss_rnnt 1.941977 hw_loss 0.251683 lr 0.00028881 rank 6
2023-03-01 10:00:34,943 DEBUG TRAIN Batch 53/5800 loss 2.637830 loss_att 5.662676 loss_ctc 3.562275 loss_rnnt 1.791984 hw_loss 0.220533 lr 0.00028881 rank 4
2023-03-01 10:01:13,685 DEBUG TRAIN Batch 53/5900 loss 2.091128 loss_att 3.750390 loss_ctc 2.327223 loss_rnnt 1.556851 hw_loss 0.320522 lr 0.00028879 rank 3
2023-03-01 10:01:13,686 DEBUG TRAIN Batch 53/5900 loss 2.736756 loss_att 5.266877 loss_ctc 4.336563 loss_rnnt 1.930830 hw_loss 0.162364 lr 0.00028880 rank 6
2023-03-01 10:01:13,689 DEBUG TRAIN Batch 53/5900 loss 1.964972 loss_att 5.372113 loss_ctc 4.400452 loss_rnnt 0.782761 hw_loss 0.330097 lr 0.00028880 rank 0
2023-03-01 10:01:13,690 DEBUG TRAIN Batch 53/5900 loss 6.297172 loss_att 8.364771 loss_ctc 10.080929 loss_rnnt 5.265277 hw_loss 0.213514 lr 0.00028880 rank 4
2023-03-01 10:01:13,691 DEBUG TRAIN Batch 53/5900 loss 3.870699 loss_att 9.472908 loss_ctc 6.791144 loss_rnnt 2.180800 hw_loss 0.337621 lr 0.00028880 rank 1
2023-03-01 10:01:13,693 DEBUG TRAIN Batch 53/5900 loss 6.595016 loss_att 8.037727 loss_ctc 9.425890 loss_rnnt 5.802108 hw_loss 0.237970 lr 0.00028880 rank 5
2023-03-01 10:01:13,694 DEBUG TRAIN Batch 53/5900 loss 6.263444 loss_att 6.929210 loss_ctc 8.631496 loss_rnnt 5.709145 hw_loss 0.197636 lr 0.00028880 rank 2
2023-03-01 10:01:13,696 DEBUG TRAIN Batch 53/5900 loss 4.797821 loss_att 7.245581 loss_ctc 8.398366 loss_rnnt 3.749851 hw_loss 0.146896 lr 0.00028879 rank 7
2023-03-01 10:01:53,000 DEBUG TRAIN Batch 53/6000 loss 3.128807 loss_att 4.330809 loss_ctc 5.141650 loss_rnnt 2.494910 hw_loss 0.234596 lr 0.00028878 rank 3
2023-03-01 10:01:53,011 DEBUG TRAIN Batch 53/6000 loss 8.729773 loss_att 12.160059 loss_ctc 19.765589 loss_rnnt 6.519073 hw_loss 0.099753 lr 0.00028878 rank 7
2023-03-01 10:01:53,011 DEBUG TRAIN Batch 53/6000 loss 2.245965 loss_att 5.671672 loss_ctc 4.105968 loss_rnnt 1.207619 hw_loss 0.197258 lr 0.00028879 rank 2
2023-03-01 10:01:53,012 DEBUG TRAIN Batch 53/6000 loss 7.398329 loss_att 11.847270 loss_ctc 13.885106 loss_rnnt 5.491684 hw_loss 0.284910 lr 0.00028879 rank 4
2023-03-01 10:01:53,014 DEBUG TRAIN Batch 53/6000 loss 5.298577 loss_att 8.600126 loss_ctc 10.222830 loss_rnnt 3.832314 hw_loss 0.280098 lr 0.00028878 rank 5
2023-03-01 10:01:53,016 DEBUG TRAIN Batch 53/6000 loss 2.341838 loss_att 5.063230 loss_ctc 3.983555 loss_rnnt 1.437900 hw_loss 0.263934 lr 0.00028879 rank 1
2023-03-01 10:01:53,019 DEBUG TRAIN Batch 53/6000 loss 1.887235 loss_att 3.880544 loss_ctc 3.993989 loss_rnnt 1.131379 hw_loss 0.143050 lr 0.00028879 rank 6
2023-03-01 10:01:53,020 DEBUG TRAIN Batch 53/6000 loss 5.563528 loss_att 11.176229 loss_ctc 12.066126 loss_rnnt 3.573750 hw_loss 0.000419 lr 0.00028879 rank 0
2023-03-01 10:03:01,889 DEBUG TRAIN Batch 53/6100 loss 10.436869 loss_att 15.167365 loss_ctc 17.516512 loss_rnnt 8.429800 hw_loss 0.219407 lr 0.00028877 rank 3
2023-03-01 10:03:01,896 DEBUG TRAIN Batch 53/6100 loss 6.372550 loss_att 8.551323 loss_ctc 10.094799 loss_rnnt 5.316432 hw_loss 0.232620 lr 0.00028878 rank 2
2023-03-01 10:03:01,898 DEBUG TRAIN Batch 53/6100 loss 9.662607 loss_att 11.491552 loss_ctc 16.750330 loss_rnnt 8.252294 hw_loss 0.186554 lr 0.00028878 rank 0
2023-03-01 10:03:01,900 DEBUG TRAIN Batch 53/6100 loss 9.317429 loss_att 13.649136 loss_ctc 16.917397 loss_rnnt 7.331587 hw_loss 0.199071 lr 0.00028877 rank 7
2023-03-01 10:03:01,901 DEBUG TRAIN Batch 53/6100 loss 5.463652 loss_att 11.907268 loss_ctc 11.730331 loss_rnnt 3.199759 hw_loss 0.261772 lr 0.00028877 rank 6
2023-03-01 10:03:01,902 DEBUG TRAIN Batch 53/6100 loss 8.835798 loss_att 13.511229 loss_ctc 15.158967 loss_rnnt 6.965557 hw_loss 0.172625 lr 0.00028877 rank 1
2023-03-01 10:03:01,906 DEBUG TRAIN Batch 53/6100 loss 4.870850 loss_att 8.232594 loss_ctc 7.042949 loss_rnnt 3.756360 hw_loss 0.285990 lr 0.00028877 rank 5
2023-03-01 10:03:01,925 DEBUG TRAIN Batch 53/6100 loss 11.598840 loss_att 11.069603 loss_ctc 17.534006 loss_rnnt 10.748871 hw_loss 0.308363 lr 0.00028878 rank 4
2023-03-01 10:03:41,008 DEBUG TRAIN Batch 53/6200 loss 5.190020 loss_att 6.895895 loss_ctc 7.077802 loss_rnnt 4.503059 hw_loss 0.176401 lr 0.00028877 rank 0
2023-03-01 10:03:41,010 DEBUG TRAIN Batch 53/6200 loss 9.803083 loss_att 12.166101 loss_ctc 17.392292 loss_rnnt 8.215546 hw_loss 0.193199 lr 0.00028877 rank 4
2023-03-01 10:03:41,011 DEBUG TRAIN Batch 53/6200 loss 1.288677 loss_att 3.869727 loss_ctc 3.430318 loss_rnnt 0.331972 hw_loss 0.290516 lr 0.00028876 rank 3
2023-03-01 10:03:41,012 DEBUG TRAIN Batch 53/6200 loss 8.741529 loss_att 9.273600 loss_ctc 14.622446 loss_rnnt 7.591888 hw_loss 0.485819 lr 0.00028876 rank 1
2023-03-01 10:03:41,014 DEBUG TRAIN Batch 53/6200 loss 4.934710 loss_att 8.574667 loss_ctc 11.225637 loss_rnnt 3.288287 hw_loss 0.149326 lr 0.00028876 rank 6
2023-03-01 10:03:41,016 DEBUG TRAIN Batch 53/6200 loss 10.064106 loss_att 13.076177 loss_ctc 17.343479 loss_rnnt 8.365343 hw_loss 0.235811 lr 0.00028876 rank 7
2023-03-01 10:03:41,018 DEBUG TRAIN Batch 53/6200 loss 13.342246 loss_att 15.093571 loss_ctc 22.266163 loss_rnnt 11.675703 hw_loss 0.237044 lr 0.00028877 rank 2
2023-03-01 10:03:41,062 DEBUG TRAIN Batch 53/6200 loss 18.542173 loss_att 21.351784 loss_ctc 27.714031 loss_rnnt 16.674351 hw_loss 0.155596 lr 0.00028876 rank 5
2023-03-01 10:04:20,733 DEBUG TRAIN Batch 53/6300 loss 5.949321 loss_att 7.047121 loss_ctc 10.243483 loss_rnnt 5.060245 hw_loss 0.181802 lr 0.00028875 rank 1
2023-03-01 10:04:20,736 DEBUG TRAIN Batch 53/6300 loss 5.624197 loss_att 9.423877 loss_ctc 8.691790 loss_rnnt 4.319561 hw_loss 0.254415 lr 0.00028875 rank 4
2023-03-01 10:04:20,736 DEBUG TRAIN Batch 53/6300 loss 7.011557 loss_att 10.607482 loss_ctc 11.997919 loss_rnnt 5.513003 hw_loss 0.214725 lr 0.00028876 rank 0
2023-03-01 10:04:20,737 DEBUG TRAIN Batch 53/6300 loss 3.709164 loss_att 5.051817 loss_ctc 5.779704 loss_rnnt 3.032062 hw_loss 0.248436 lr 0.00028875 rank 6
2023-03-01 10:04:20,738 DEBUG TRAIN Batch 53/6300 loss 7.580522 loss_att 9.724879 loss_ctc 10.686882 loss_rnnt 6.551322 hw_loss 0.349023 lr 0.00028875 rank 7
2023-03-01 10:04:20,741 DEBUG TRAIN Batch 53/6300 loss 4.657519 loss_att 7.425502 loss_ctc 8.487544 loss_rnnt 3.488757 hw_loss 0.195928 lr 0.00028874 rank 3
2023-03-01 10:04:20,761 DEBUG TRAIN Batch 53/6300 loss 4.668708 loss_att 8.095057 loss_ctc 5.506960 loss_rnnt 3.741132 hw_loss 0.244760 lr 0.00028875 rank 5
2023-03-01 10:04:20,767 DEBUG TRAIN Batch 53/6300 loss 4.903999 loss_att 8.428102 loss_ctc 6.882204 loss_rnnt 3.884655 hw_loss 0.095181 lr 0.00028876 rank 2
2023-03-01 10:05:30,484 DEBUG TRAIN Batch 53/6400 loss 4.157380 loss_att 6.141020 loss_ctc 6.967092 loss_rnnt 3.279456 hw_loss 0.199815 lr 0.00028874 rank 4
2023-03-01 10:05:30,487 DEBUG TRAIN Batch 53/6400 loss 8.973577 loss_att 10.849803 loss_ctc 13.315402 loss_rnnt 7.941772 hw_loss 0.145597 lr 0.00028874 rank 6
2023-03-01 10:05:30,499 DEBUG TRAIN Batch 53/6400 loss 6.963485 loss_att 9.051184 loss_ctc 10.992098 loss_rnnt 5.869039 hw_loss 0.262047 lr 0.00028873 rank 7
2023-03-01 10:05:30,502 DEBUG TRAIN Batch 53/6400 loss 5.683654 loss_att 7.433284 loss_ctc 9.784319 loss_rnnt 4.610794 hw_loss 0.330334 lr 0.00028874 rank 0
2023-03-01 10:05:30,502 DEBUG TRAIN Batch 53/6400 loss 5.825956 loss_att 8.584920 loss_ctc 10.185701 loss_rnnt 4.555635 hw_loss 0.257305 lr 0.00028874 rank 2
2023-03-01 10:05:30,504 DEBUG TRAIN Batch 53/6400 loss 7.135975 loss_att 8.941414 loss_ctc 12.170863 loss_rnnt 5.972289 hw_loss 0.246149 lr 0.00028874 rank 5
2023-03-01 10:05:30,513 DEBUG TRAIN Batch 53/6400 loss 7.957746 loss_att 8.906054 loss_ctc 11.744269 loss_rnnt 7.167923 hw_loss 0.178672 lr 0.00028873 rank 3
2023-03-01 10:05:30,568 DEBUG TRAIN Batch 53/6400 loss 6.233656 loss_att 8.054523 loss_ctc 10.661791 loss_rnnt 5.175001 hw_loss 0.195119 lr 0.00028874 rank 1
2023-03-01 10:06:09,526 DEBUG TRAIN Batch 53/6500 loss 10.422718 loss_att 13.915215 loss_ctc 14.229305 loss_rnnt 9.055259 hw_loss 0.302654 lr 0.00028872 rank 5
2023-03-01 10:06:09,528 DEBUG TRAIN Batch 53/6500 loss 5.735352 loss_att 8.433070 loss_ctc 10.289825 loss_rnnt 4.436391 hw_loss 0.285288 lr 0.00028872 rank 3
2023-03-01 10:06:09,528 DEBUG TRAIN Batch 53/6500 loss 9.408506 loss_att 17.009171 loss_ctc 21.859482 loss_rnnt 6.148996 hw_loss 0.148589 lr 0.00028872 rank 7
2023-03-01 10:06:09,533 DEBUG TRAIN Batch 53/6500 loss 4.455356 loss_att 6.355518 loss_ctc 7.956876 loss_rnnt 3.482170 hw_loss 0.236783 lr 0.00028873 rank 0
2023-03-01 10:06:09,536 DEBUG TRAIN Batch 53/6500 loss 8.727394 loss_att 13.168230 loss_ctc 21.933287 loss_rnnt 5.965444 hw_loss 0.211869 lr 0.00028873 rank 4
2023-03-01 10:06:09,538 DEBUG TRAIN Batch 53/6500 loss 7.135489 loss_att 12.259411 loss_ctc 11.794192 loss_rnnt 5.369908 hw_loss 0.224315 lr 0.00028873 rank 2
2023-03-01 10:06:09,553 DEBUG TRAIN Batch 53/6500 loss 4.467010 loss_att 8.228565 loss_ctc 11.096935 loss_rnnt 2.695734 hw_loss 0.253077 lr 0.00028873 rank 1
2023-03-01 10:06:09,557 DEBUG TRAIN Batch 53/6500 loss 6.009722 loss_att 8.589194 loss_ctc 8.773178 loss_rnnt 5.002852 hw_loss 0.229713 lr 0.00028873 rank 6
2023-03-01 10:06:48,387 DEBUG TRAIN Batch 53/6600 loss 10.537832 loss_att 12.448465 loss_ctc 15.882397 loss_rnnt 9.303574 hw_loss 0.261608 lr 0.00028871 rank 3
2023-03-01 10:06:48,392 DEBUG TRAIN Batch 53/6600 loss 12.977454 loss_att 15.301590 loss_ctc 26.075779 loss_rnnt 10.669514 hw_loss 0.181255 lr 0.00028871 rank 1
2023-03-01 10:06:48,398 DEBUG TRAIN Batch 53/6600 loss 4.417061 loss_att 7.655634 loss_ctc 4.833731 loss_rnnt 3.567842 hw_loss 0.273655 lr 0.00028871 rank 6
2023-03-01 10:06:48,402 DEBUG TRAIN Batch 53/6600 loss 10.138734 loss_att 14.440966 loss_ctc 21.761982 loss_rnnt 7.518350 hw_loss 0.394071 lr 0.00028872 rank 0
2023-03-01 10:06:48,407 DEBUG TRAIN Batch 53/6600 loss 4.383009 loss_att 7.854638 loss_ctc 7.414950 loss_rnnt 3.252150 hw_loss 0.060515 lr 0.00028872 rank 4
2023-03-01 10:06:48,408 DEBUG TRAIN Batch 53/6600 loss 3.318040 loss_att 6.459064 loss_ctc 7.323874 loss_rnnt 2.086715 hw_loss 0.129392 lr 0.00028872 rank 2
2023-03-01 10:06:48,409 DEBUG TRAIN Batch 53/6600 loss 8.642891 loss_att 9.587412 loss_ctc 14.573544 loss_rnnt 7.598453 hw_loss 0.121465 lr 0.00028871 rank 5
2023-03-01 10:06:48,409 DEBUG TRAIN Batch 53/6600 loss 5.645092 loss_att 8.037768 loss_ctc 8.445631 loss_rnnt 4.768200 hw_loss 0.046783 lr 0.00028871 rank 7
2023-03-01 10:07:27,537 DEBUG TRAIN Batch 53/6700 loss 2.996841 loss_att 6.004696 loss_ctc 5.136675 loss_rnnt 1.984158 hw_loss 0.235878 lr 0.00028870 rank 6
2023-03-01 10:07:27,550 DEBUG TRAIN Batch 53/6700 loss 7.787029 loss_att 9.757216 loss_ctc 10.652834 loss_rnnt 6.979350 hw_loss 0.059126 lr 0.00028871 rank 4
2023-03-01 10:07:27,557 DEBUG TRAIN Batch 53/6700 loss 6.618254 loss_att 10.808226 loss_ctc 9.684652 loss_rnnt 5.371243 hw_loss 0.000307 lr 0.00028870 rank 7
2023-03-01 10:07:27,558 DEBUG TRAIN Batch 53/6700 loss 3.344880 loss_att 6.665299 loss_ctc 6.023142 loss_rnnt 2.200081 hw_loss 0.231775 lr 0.00028871 rank 0
2023-03-01 10:07:27,559 DEBUG TRAIN Batch 53/6700 loss 5.992480 loss_att 9.040152 loss_ctc 11.695454 loss_rnnt 4.533932 hw_loss 0.166156 lr 0.00028870 rank 3
2023-03-01 10:07:27,564 DEBUG TRAIN Batch 53/6700 loss 4.042292 loss_att 7.984087 loss_ctc 7.982724 loss_rnnt 2.564418 hw_loss 0.307733 lr 0.00028871 rank 2
2023-03-01 10:07:27,587 DEBUG TRAIN Batch 53/6700 loss 7.364478 loss_att 11.363026 loss_ctc 9.725652 loss_rnnt 6.151871 hw_loss 0.183890 lr 0.00028870 rank 1
2023-03-01 10:07:27,597 DEBUG TRAIN Batch 53/6700 loss 6.426773 loss_att 7.282890 loss_ctc 10.608330 loss_rnnt 5.560525 hw_loss 0.257781 lr 0.00028870 rank 5
2023-03-01 10:08:38,481 DEBUG TRAIN Batch 53/6800 loss 4.937985 loss_att 8.830939 loss_ctc 8.276666 loss_rnnt 3.601113 hw_loss 0.212107 lr 0.00028870 rank 0
2023-03-01 10:08:38,485 DEBUG TRAIN Batch 53/6800 loss 4.657423 loss_att 6.690440 loss_ctc 10.023695 loss_rnnt 3.364346 hw_loss 0.320571 lr 0.00028869 rank 6
2023-03-01 10:08:38,485 DEBUG TRAIN Batch 53/6800 loss 6.651399 loss_att 10.163101 loss_ctc 15.038706 loss_rnnt 4.740917 hw_loss 0.168440 lr 0.00028869 rank 1
2023-03-01 10:08:38,485 DEBUG TRAIN Batch 53/6800 loss 6.693604 loss_att 8.659112 loss_ctc 11.492863 loss_rnnt 5.510684 hw_loss 0.281095 lr 0.00028869 rank 5
2023-03-01 10:08:38,486 DEBUG TRAIN Batch 53/6800 loss 7.618821 loss_att 10.584511 loss_ctc 11.673260 loss_rnnt 6.320320 hw_loss 0.308945 lr 0.00028869 rank 7
2023-03-01 10:08:38,487 DEBUG TRAIN Batch 53/6800 loss 4.987566 loss_att 8.079937 loss_ctc 10.602420 loss_rnnt 3.416277 hw_loss 0.382811 lr 0.00028869 rank 4
2023-03-01 10:08:38,491 DEBUG TRAIN Batch 53/6800 loss 4.164546 loss_att 7.049167 loss_ctc 6.891371 loss_rnnt 3.109315 hw_loss 0.215117 lr 0.00028868 rank 3
2023-03-01 10:08:38,495 DEBUG TRAIN Batch 53/6800 loss 10.032487 loss_att 14.330184 loss_ctc 18.286329 loss_rnnt 7.924567 hw_loss 0.277252 lr 0.00028870 rank 2
2023-03-01 10:09:17,499 DEBUG TRAIN Batch 53/6900 loss 4.458189 loss_att 7.884022 loss_ctc 7.390899 loss_rnnt 3.245095 hw_loss 0.256685 lr 0.00028868 rank 2
2023-03-01 10:09:17,507 DEBUG TRAIN Batch 53/6900 loss 2.909290 loss_att 7.288991 loss_ctc 6.264969 loss_rnnt 1.497305 hw_loss 0.166163 lr 0.00028868 rank 4
2023-03-01 10:09:17,511 DEBUG TRAIN Batch 53/6900 loss 2.074598 loss_att 3.894514 loss_ctc 2.531764 loss_rnnt 1.469437 hw_loss 0.337918 lr 0.00028867 rank 7
2023-03-01 10:09:17,515 DEBUG TRAIN Batch 53/6900 loss 8.015447 loss_att 10.367357 loss_ctc 10.457264 loss_rnnt 7.131273 hw_loss 0.165404 lr 0.00028868 rank 0
2023-03-01 10:09:17,515 DEBUG TRAIN Batch 53/6900 loss 5.481956 loss_att 8.316345 loss_ctc 9.203926 loss_rnnt 4.286320 hw_loss 0.248428 lr 0.00028868 rank 5
2023-03-01 10:09:17,518 DEBUG TRAIN Batch 53/6900 loss 3.114450 loss_att 6.961888 loss_ctc 10.197726 loss_rnnt 1.354518 hw_loss 0.086264 lr 0.00028868 rank 6
2023-03-01 10:09:17,518 DEBUG TRAIN Batch 53/6900 loss 7.043894 loss_att 7.589109 loss_ctc 8.715403 loss_rnnt 6.684077 hw_loss 0.052325 lr 0.00028867 rank 3
2023-03-01 10:09:17,521 DEBUG TRAIN Batch 53/6900 loss 4.538056 loss_att 5.716065 loss_ctc 8.916542 loss_rnnt 3.618270 hw_loss 0.188224 lr 0.00028868 rank 1
2023-03-01 10:09:56,300 DEBUG TRAIN Batch 53/7000 loss 4.113369 loss_att 8.992090 loss_ctc 5.244517 loss_rnnt 2.780476 hw_loss 0.386865 lr 0.00028867 rank 4
2023-03-01 10:09:56,308 DEBUG TRAIN Batch 53/7000 loss 6.285720 loss_att 8.903534 loss_ctc 10.062120 loss_rnnt 5.128892 hw_loss 0.243273 lr 0.00028867 rank 2
2023-03-01 10:09:56,308 DEBUG TRAIN Batch 53/7000 loss 4.135676 loss_att 7.541481 loss_ctc 6.811216 loss_rnnt 3.005963 hw_loss 0.172150 lr 0.00028866 rank 5
2023-03-01 10:09:56,309 DEBUG TRAIN Batch 53/7000 loss 5.796822 loss_att 8.114037 loss_ctc 9.228273 loss_rnnt 4.690514 hw_loss 0.347511 lr 0.00028866 rank 3
2023-03-01 10:09:56,312 DEBUG TRAIN Batch 53/7000 loss 3.121194 loss_att 7.129420 loss_ctc 4.487849 loss_rnnt 2.037790 hw_loss 0.186635 lr 0.00028867 rank 1
2023-03-01 10:09:56,314 DEBUG TRAIN Batch 53/7000 loss 6.406519 loss_att 8.079668 loss_ctc 11.969074 loss_rnnt 5.248586 hw_loss 0.153057 lr 0.00028867 rank 0
2023-03-01 10:09:56,316 DEBUG TRAIN Batch 53/7000 loss 3.489200 loss_att 4.346833 loss_ctc 4.734501 loss_rnnt 3.016169 hw_loss 0.253995 lr 0.00028867 rank 6
2023-03-01 10:09:56,316 DEBUG TRAIN Batch 53/7000 loss 7.041221 loss_att 10.892015 loss_ctc 13.630462 loss_rnnt 5.306383 hw_loss 0.161465 lr 0.00028866 rank 7
2023-03-01 10:11:03,249 DEBUG TRAIN Batch 53/7100 loss 3.940244 loss_att 7.017905 loss_ctc 7.888691 loss_rnnt 2.726590 hw_loss 0.134368 lr 0.00028865 rank 5
2023-03-01 10:11:03,256 DEBUG TRAIN Batch 53/7100 loss 6.008401 loss_att 9.480167 loss_ctc 12.140884 loss_rnnt 4.404805 hw_loss 0.171709 lr 0.00028866 rank 2
2023-03-01 10:11:03,269 DEBUG TRAIN Batch 53/7100 loss 3.363150 loss_att 6.682096 loss_ctc 4.888872 loss_rnnt 2.398022 hw_loss 0.183581 lr 0.00028866 rank 4
2023-03-01 10:11:03,271 DEBUG TRAIN Batch 53/7100 loss 5.662968 loss_att 9.567150 loss_ctc 16.128759 loss_rnnt 3.356698 hw_loss 0.243740 lr 0.00028865 rank 1
2023-03-01 10:11:03,292 DEBUG TRAIN Batch 53/7100 loss 5.459043 loss_att 9.663425 loss_ctc 10.055779 loss_rnnt 3.980953 hw_loss 0.045592 lr 0.00028865 rank 6
2023-03-01 10:11:03,295 DEBUG TRAIN Batch 53/7100 loss 6.993046 loss_att 9.835873 loss_ctc 9.707351 loss_rnnt 5.991369 hw_loss 0.133508 lr 0.00028865 rank 7
2023-03-01 10:11:03,307 DEBUG TRAIN Batch 53/7100 loss 3.775010 loss_att 8.050782 loss_ctc 7.765859 loss_rnnt 2.261903 hw_loss 0.235949 lr 0.00028865 rank 3
2023-03-01 10:11:03,310 DEBUG TRAIN Batch 53/7100 loss 7.725165 loss_att 7.705454 loss_ctc 11.138391 loss_rnnt 7.109097 hw_loss 0.309212 lr 0.00028866 rank 0
2023-03-01 10:11:45,599 DEBUG TRAIN Batch 53/7200 loss 13.503815 loss_att 18.571909 loss_ctc 24.056768 loss_rnnt 11.016360 hw_loss 0.125202 lr 0.00028864 rank 7
2023-03-01 10:11:45,603 DEBUG TRAIN Batch 53/7200 loss 13.962409 loss_att 11.621007 loss_ctc 22.182472 loss_rnnt 13.222671 hw_loss 0.210020 lr 0.00028865 rank 0
2023-03-01 10:11:45,603 DEBUG TRAIN Batch 53/7200 loss 15.258586 loss_att 17.739494 loss_ctc 23.773705 loss_rnnt 13.490281 hw_loss 0.256451 lr 0.00028865 rank 4
2023-03-01 10:11:45,605 DEBUG TRAIN Batch 53/7200 loss 5.309514 loss_att 9.027956 loss_ctc 11.095002 loss_rnnt 3.726041 hw_loss 0.128224 lr 0.00028865 rank 2
2023-03-01 10:11:45,605 DEBUG TRAIN Batch 53/7200 loss 7.566606 loss_att 8.247441 loss_ctc 10.110641 loss_rnnt 6.992383 hw_loss 0.185345 lr 0.00028864 rank 3
2023-03-01 10:11:45,607 DEBUG TRAIN Batch 53/7200 loss 10.194740 loss_att 10.925843 loss_ctc 17.441122 loss_rnnt 9.034611 hw_loss 0.089484 lr 0.00028864 rank 5
2023-03-01 10:11:45,611 DEBUG TRAIN Batch 53/7200 loss 6.362865 loss_att 9.975035 loss_ctc 10.857386 loss_rnnt 4.907402 hw_loss 0.250800 lr 0.00028864 rank 6
2023-03-01 10:11:45,658 DEBUG TRAIN Batch 53/7200 loss 2.189033 loss_att 4.941960 loss_ctc 4.520561 loss_rnnt 1.149254 hw_loss 0.334356 lr 0.00028864 rank 1
2023-03-01 10:12:24,751 DEBUG TRAIN Batch 53/7300 loss 7.047308 loss_att 11.923262 loss_ctc 10.805490 loss_rnnt 5.467004 hw_loss 0.195041 lr 0.00028863 rank 1
2023-03-01 10:12:24,756 DEBUG TRAIN Batch 53/7300 loss 8.989270 loss_att 10.620254 loss_ctc 10.778891 loss_rnnt 8.315392 hw_loss 0.204495 lr 0.00028864 rank 2
2023-03-01 10:12:24,771 DEBUG TRAIN Batch 53/7300 loss 4.839065 loss_att 6.223639 loss_ctc 11.030882 loss_rnnt 3.580483 hw_loss 0.292671 lr 0.00028863 rank 7
2023-03-01 10:12:24,774 DEBUG TRAIN Batch 53/7300 loss 4.136195 loss_att 7.903900 loss_ctc 5.031228 loss_rnnt 3.150647 hw_loss 0.211254 lr 0.00028863 rank 5
2023-03-01 10:12:24,774 DEBUG TRAIN Batch 53/7300 loss 2.886141 loss_att 5.908854 loss_ctc 7.096727 loss_rnnt 1.594351 hw_loss 0.235943 lr 0.00028863 rank 4
2023-03-01 10:12:24,775 DEBUG TRAIN Batch 53/7300 loss 6.992058 loss_att 9.522791 loss_ctc 9.142542 loss_rnnt 6.072642 hw_loss 0.237259 lr 0.00028864 rank 0
2023-03-01 10:12:24,785 DEBUG TRAIN Batch 53/7300 loss 5.840125 loss_att 9.260773 loss_ctc 13.059752 loss_rnnt 4.056612 hw_loss 0.256437 lr 0.00028863 rank 6
2023-03-01 10:12:24,793 DEBUG TRAIN Batch 53/7300 loss 2.587662 loss_att 6.463986 loss_ctc 4.188417 loss_rnnt 1.533136 hw_loss 0.123427 lr 0.00028862 rank 3
2023-03-01 10:13:03,695 DEBUG TRAIN Batch 53/7400 loss 16.113884 loss_att 18.145027 loss_ctc 25.639267 loss_rnnt 14.367427 hw_loss 0.131585 lr 0.00028862 rank 5
2023-03-01 10:13:03,701 DEBUG TRAIN Batch 53/7400 loss 2.693322 loss_att 5.030835 loss_ctc 3.023849 loss_rnnt 2.041272 hw_loss 0.263395 lr 0.00028862 rank 0
2023-03-01 10:13:03,715 DEBUG TRAIN Batch 53/7400 loss 4.575987 loss_att 7.273180 loss_ctc 9.047987 loss_rnnt 3.324661 hw_loss 0.216788 lr 0.00028862 rank 4
2023-03-01 10:13:03,721 DEBUG TRAIN Batch 53/7400 loss 10.311227 loss_att 14.694558 loss_ctc 17.997231 loss_rnnt 8.293483 hw_loss 0.218022 lr 0.00028861 rank 7
2023-03-01 10:13:03,722 DEBUG TRAIN Batch 53/7400 loss 3.176143 loss_att 5.562801 loss_ctc 6.276865 loss_rnnt 2.153271 hw_loss 0.247708 lr 0.00028861 rank 3
2023-03-01 10:13:03,736 DEBUG TRAIN Batch 53/7400 loss 6.563920 loss_att 9.097920 loss_ctc 9.733034 loss_rnnt 5.520712 hw_loss 0.213487 lr 0.00028862 rank 1
2023-03-01 10:13:03,741 DEBUG TRAIN Batch 53/7400 loss 4.497323 loss_att 6.085573 loss_ctc 7.552984 loss_rnnt 3.721490 hw_loss 0.095178 lr 0.00028862 rank 2
2023-03-01 10:13:03,765 DEBUG TRAIN Batch 53/7400 loss 4.932445 loss_att 8.194135 loss_ctc 10.621307 loss_rnnt 3.464719 hw_loss 0.106637 lr 0.00028862 rank 6
2023-03-01 10:14:14,139 DEBUG TRAIN Batch 53/7500 loss 3.362989 loss_att 5.495471 loss_ctc 3.752444 loss_rnnt 2.752747 hw_loss 0.247160 lr 0.00028861 rank 0
2023-03-01 10:14:14,143 DEBUG TRAIN Batch 53/7500 loss 5.945541 loss_att 8.549180 loss_ctc 10.939804 loss_rnnt 4.645192 hw_loss 0.213225 lr 0.00028860 rank 7
2023-03-01 10:14:14,146 DEBUG TRAIN Batch 53/7500 loss 6.171185 loss_att 8.501075 loss_ctc 7.671936 loss_rnnt 5.371872 hw_loss 0.249814 lr 0.00028860 rank 5
2023-03-01 10:14:14,147 DEBUG TRAIN Batch 53/7500 loss 7.761499 loss_att 9.129561 loss_ctc 10.902807 loss_rnnt 6.943736 hw_loss 0.234957 lr 0.00028861 rank 2
2023-03-01 10:14:14,147 DEBUG TRAIN Batch 53/7500 loss 10.481661 loss_att 12.681158 loss_ctc 16.092279 loss_rnnt 9.211290 hw_loss 0.154477 lr 0.00028861 rank 1
2023-03-01 10:14:14,150 DEBUG TRAIN Batch 53/7500 loss 10.767254 loss_att 15.633548 loss_ctc 17.693933 loss_rnnt 8.780682 hw_loss 0.168295 lr 0.00028860 rank 6
2023-03-01 10:14:14,148 DEBUG TRAIN Batch 53/7500 loss 3.993852 loss_att 6.058099 loss_ctc 5.680090 loss_rnnt 3.264083 hw_loss 0.172664 lr 0.00028860 rank 3
2023-03-01 10:14:14,188 DEBUG TRAIN Batch 53/7500 loss 6.855244 loss_att 9.238941 loss_ctc 13.994337 loss_rnnt 5.348988 hw_loss 0.145569 lr 0.00028861 rank 4
2023-03-01 10:14:53,423 DEBUG TRAIN Batch 53/7600 loss 1.752215 loss_att 3.474757 loss_ctc 2.685311 loss_rnnt 1.152795 hw_loss 0.244684 lr 0.00028860 rank 2
2023-03-01 10:14:53,435 DEBUG TRAIN Batch 53/7600 loss 6.061247 loss_att 9.616998 loss_ctc 11.835116 loss_rnnt 4.473872 hw_loss 0.199454 lr 0.00028859 rank 5
2023-03-01 10:14:53,436 DEBUG TRAIN Batch 53/7600 loss 3.470858 loss_att 10.152529 loss_ctc 10.269266 loss_rnnt 1.148577 hw_loss 0.149046 lr 0.00028860 rank 4
2023-03-01 10:14:53,436 DEBUG TRAIN Batch 53/7600 loss 11.136720 loss_att 13.987897 loss_ctc 16.828827 loss_rnnt 9.740646 hw_loss 0.125421 lr 0.00028859 rank 1
2023-03-01 10:14:53,441 DEBUG TRAIN Batch 53/7600 loss 8.153523 loss_att 10.652281 loss_ctc 12.746828 loss_rnnt 6.910862 hw_loss 0.244631 lr 0.00028859 rank 7
2023-03-01 10:14:53,443 DEBUG TRAIN Batch 53/7600 loss 3.035537 loss_att 5.522918 loss_ctc 4.942742 loss_rnnt 2.118113 hw_loss 0.310601 lr 0.00028860 rank 0
2023-03-01 10:14:53,444 DEBUG TRAIN Batch 53/7600 loss 4.306713 loss_att 7.271230 loss_ctc 7.917787 loss_rnnt 3.097036 hw_loss 0.253680 lr 0.00028859 rank 3
2023-03-01 10:14:53,484 DEBUG TRAIN Batch 53/7600 loss 3.257483 loss_att 5.849349 loss_ctc 7.147141 loss_rnnt 2.137706 hw_loss 0.155219 lr 0.00028859 rank 6
2023-03-01 10:15:33,220 DEBUG TRAIN Batch 53/7700 loss 6.540892 loss_att 7.576086 loss_ctc 12.103312 loss_rnnt 5.496413 hw_loss 0.179594 lr 0.00028858 rank 6
2023-03-01 10:15:33,219 DEBUG TRAIN Batch 53/7700 loss 10.246403 loss_att 15.092224 loss_ctc 21.794586 loss_rnnt 7.644360 hw_loss 0.174601 lr 0.00028858 rank 1
2023-03-01 10:15:33,223 DEBUG TRAIN Batch 53/7700 loss 5.757009 loss_att 9.083909 loss_ctc 11.656850 loss_rnnt 4.177125 hw_loss 0.239732 lr 0.00028858 rank 5
2023-03-01 10:15:33,234 DEBUG TRAIN Batch 53/7700 loss 4.577163 loss_att 7.479757 loss_ctc 6.843053 loss_rnnt 3.567487 hw_loss 0.238197 lr 0.00028858 rank 7
2023-03-01 10:15:33,236 DEBUG TRAIN Batch 53/7700 loss 2.048445 loss_att 3.412751 loss_ctc 4.195282 loss_rnnt 1.293854 hw_loss 0.366535 lr 0.00028859 rank 0
2023-03-01 10:15:33,238 DEBUG TRAIN Batch 53/7700 loss 3.263774 loss_att 6.457183 loss_ctc 3.838249 loss_rnnt 2.420320 hw_loss 0.240328 lr 0.00028858 rank 3
2023-03-01 10:15:33,242 DEBUG TRAIN Batch 53/7700 loss 3.645724 loss_att 5.376602 loss_ctc 6.170919 loss_rnnt 2.793139 hw_loss 0.318219 lr 0.00028859 rank 2
2023-03-01 10:15:33,246 DEBUG TRAIN Batch 53/7700 loss 3.626578 loss_att 5.915849 loss_ctc 5.408374 loss_rnnt 2.853816 hw_loss 0.145003 lr 0.00028859 rank 4
2023-03-01 10:16:13,357 DEBUG TRAIN Batch 53/7800 loss 9.148713 loss_att 11.598072 loss_ctc 13.946589 loss_rnnt 7.958900 hw_loss 0.112919 lr 0.00028857 rank 7
2023-03-01 10:16:13,363 DEBUG TRAIN Batch 53/7800 loss 6.003891 loss_att 7.954346 loss_ctc 9.975034 loss_rnnt 4.962672 hw_loss 0.228078 lr 0.00028856 rank 3
2023-03-01 10:16:13,377 DEBUG TRAIN Batch 53/7800 loss 3.066052 loss_att 5.523041 loss_ctc 5.235229 loss_rnnt 2.132917 hw_loss 0.285963 lr 0.00028858 rank 0
2023-03-01 10:16:13,379 DEBUG TRAIN Batch 53/7800 loss 5.590091 loss_att 7.870864 loss_ctc 15.211706 loss_rnnt 3.753128 hw_loss 0.183612 lr 0.00028858 rank 2
2023-03-01 10:16:13,383 DEBUG TRAIN Batch 53/7800 loss 9.400485 loss_att 11.490351 loss_ctc 13.905325 loss_rnnt 8.199070 hw_loss 0.342744 lr 0.00028857 rank 1
2023-03-01 10:16:13,387 DEBUG TRAIN Batch 53/7800 loss 1.087790 loss_att 3.335036 loss_ctc 1.479774 loss_rnnt 0.450971 hw_loss 0.253321 lr 0.00028857 rank 6
2023-03-01 10:16:13,400 DEBUG TRAIN Batch 53/7800 loss 12.846755 loss_att 16.813978 loss_ctc 19.053175 loss_rnnt 11.125134 hw_loss 0.188727 lr 0.00028857 rank 4
2023-03-01 10:16:13,411 DEBUG TRAIN Batch 53/7800 loss 8.196032 loss_att 12.971100 loss_ctc 18.177227 loss_rnnt 5.858087 hw_loss 0.097698 lr 0.00028857 rank 5
2023-03-01 10:17:23,073 DEBUG TRAIN Batch 53/7900 loss 6.927506 loss_att 11.967734 loss_ctc 10.252024 loss_rnnt 5.336782 hw_loss 0.261391 lr 0.00028856 rank 1
2023-03-01 10:17:23,076 DEBUG TRAIN Batch 53/7900 loss 6.179583 loss_att 9.133934 loss_ctc 14.895115 loss_rnnt 4.278329 hw_loss 0.278085 lr 0.00028856 rank 4
2023-03-01 10:17:23,086 DEBUG TRAIN Batch 53/7900 loss 4.894391 loss_att 7.588998 loss_ctc 7.880287 loss_rnnt 3.801869 hw_loss 0.291526 lr 0.00028855 rank 5
2023-03-01 10:17:23,087 DEBUG TRAIN Batch 53/7900 loss 2.731529 loss_att 5.987072 loss_ctc 6.504517 loss_rnnt 1.436498 hw_loss 0.264108 lr 0.00028856 rank 0
2023-03-01 10:17:23,091 DEBUG TRAIN Batch 53/7900 loss 3.006205 loss_att 6.576694 loss_ctc 5.138246 loss_rnnt 1.928251 hw_loss 0.149220 lr 0.00028855 rank 3
2023-03-01 10:17:23,095 DEBUG TRAIN Batch 53/7900 loss 5.564757 loss_att 7.887322 loss_ctc 8.992560 loss_rnnt 4.545902 hw_loss 0.182440 lr 0.00028856 rank 6
2023-03-01 10:17:23,096 DEBUG TRAIN Batch 53/7900 loss 6.324791 loss_att 7.749166 loss_ctc 10.071899 loss_rnnt 5.446609 hw_loss 0.175673 lr 0.00028855 rank 7
2023-03-01 10:17:23,136 DEBUG TRAIN Batch 53/7900 loss 4.228813 loss_att 8.274728 loss_ctc 7.656040 loss_rnnt 2.892658 hw_loss 0.131265 lr 0.00028856 rank 2
2023-03-01 10:18:02,275 DEBUG TRAIN Batch 53/8000 loss 11.204485 loss_att 14.903324 loss_ctc 22.783041 loss_rnnt 8.844204 hw_loss 0.143823 lr 0.00028855 rank 4
2023-03-01 10:18:02,291 DEBUG TRAIN Batch 53/8000 loss 2.548675 loss_att 5.993836 loss_ctc 3.815840 loss_rnnt 1.516232 hw_loss 0.327105 lr 0.00028854 rank 7
2023-03-01 10:18:02,293 DEBUG TRAIN Batch 53/8000 loss 5.884738 loss_att 8.200092 loss_ctc 8.733871 loss_rnnt 4.941774 hw_loss 0.187516 lr 0.00028855 rank 0
2023-03-01 10:18:02,295 DEBUG TRAIN Batch 53/8000 loss 12.843193 loss_att 15.726103 loss_ctc 17.805355 loss_rnnt 11.461572 hw_loss 0.268907 lr 0.00028855 rank 1
2023-03-01 10:18:02,299 DEBUG TRAIN Batch 53/8000 loss 1.825564 loss_att 4.540109 loss_ctc 4.049791 loss_rnnt 0.875479 hw_loss 0.207397 lr 0.00028854 rank 5
2023-03-01 10:18:02,301 DEBUG TRAIN Batch 53/8000 loss 9.783087 loss_att 12.053412 loss_ctc 13.179880 loss_rnnt 8.708530 hw_loss 0.314224 lr 0.00028854 rank 3
2023-03-01 10:18:02,301 DEBUG TRAIN Batch 53/8000 loss 5.431328 loss_att 8.610989 loss_ctc 9.390013 loss_rnnt 4.199136 hw_loss 0.128317 lr 0.00028855 rank 2
2023-03-01 10:18:02,305 DEBUG TRAIN Batch 53/8000 loss 5.718387 loss_att 7.957629 loss_ctc 8.031556 loss_rnnt 4.861571 hw_loss 0.188521 lr 0.00028854 rank 6
2023-03-01 10:18:41,824 DEBUG TRAIN Batch 53/8100 loss 3.899591 loss_att 6.716554 loss_ctc 5.311237 loss_rnnt 3.027516 hw_loss 0.225868 lr 0.00028854 rank 0
2023-03-01 10:18:41,834 DEBUG TRAIN Batch 53/8100 loss 9.342239 loss_att 13.289586 loss_ctc 15.965758 loss_rnnt 7.562218 hw_loss 0.201407 lr 0.00028853 rank 1
2023-03-01 10:18:41,844 DEBUG TRAIN Batch 53/8100 loss 5.686737 loss_att 10.157296 loss_ctc 9.217875 loss_rnnt 4.226908 hw_loss 0.177935 lr 0.00028853 rank 6
2023-03-01 10:18:41,844 DEBUG TRAIN Batch 53/8100 loss 5.896333 loss_att 7.960150 loss_ctc 9.059678 loss_rnnt 4.958795 hw_loss 0.193117 lr 0.00028854 rank 4
2023-03-01 10:18:41,844 DEBUG TRAIN Batch 53/8100 loss 5.549860 loss_att 8.478945 loss_ctc 7.564039 loss_rnnt 4.563033 hw_loss 0.248347 lr 0.00028853 rank 3
2023-03-01 10:18:41,845 DEBUG TRAIN Batch 53/8100 loss 4.467659 loss_att 7.147273 loss_ctc 7.441035 loss_rnnt 3.457730 hw_loss 0.145415 lr 0.00028853 rank 7
2023-03-01 10:18:41,864 DEBUG TRAIN Batch 53/8100 loss 3.506857 loss_att 5.930561 loss_ctc 6.988552 loss_rnnt 2.428286 hw_loss 0.243009 lr 0.00028853 rank 5
2023-03-01 10:18:41,881 DEBUG TRAIN Batch 53/8100 loss 7.993732 loss_att 9.566111 loss_ctc 15.921434 loss_rnnt 6.476285 hw_loss 0.273645 lr 0.00028854 rank 2
2023-03-01 10:19:22,928 DEBUG TRAIN Batch 53/8200 loss 8.809002 loss_att 9.701542 loss_ctc 12.645194 loss_rnnt 8.042573 hw_loss 0.143303 lr 0.00028852 rank 1
2023-03-01 10:19:22,930 DEBUG TRAIN Batch 53/8200 loss 2.951960 loss_att 5.690841 loss_ctc 5.393260 loss_rnnt 1.905302 hw_loss 0.325078 lr 0.00028853 rank 0
2023-03-01 10:19:22,932 DEBUG TRAIN Batch 53/8200 loss 4.664042 loss_att 7.706138 loss_ctc 9.079372 loss_rnnt 3.358869 hw_loss 0.202582 lr 0.00028852 rank 7
2023-03-01 10:19:22,933 DEBUG TRAIN Batch 53/8200 loss 6.959349 loss_att 8.922802 loss_ctc 11.996389 loss_rnnt 5.784214 hw_loss 0.207824 lr 0.00028852 rank 3
2023-03-01 10:19:22,934 DEBUG TRAIN Batch 53/8200 loss 1.988444 loss_att 4.908068 loss_ctc 5.141329 loss_rnnt 0.930144 hw_loss 0.101232 lr 0.00028853 rank 4
2023-03-01 10:19:22,938 DEBUG TRAIN Batch 53/8200 loss 12.947658 loss_att 17.824978 loss_ctc 22.478310 loss_rnnt 10.651774 hw_loss 0.093121 lr 0.00028853 rank 2
2023-03-01 10:19:22,939 DEBUG TRAIN Batch 53/8200 loss 5.801655 loss_att 7.341231 loss_ctc 11.895835 loss_rnnt 4.543108 hw_loss 0.258889 lr 0.00028852 rank 5
2023-03-01 10:19:22,940 DEBUG TRAIN Batch 53/8200 loss 8.119507 loss_att 9.515352 loss_ctc 14.859082 loss_rnnt 6.774774 hw_loss 0.313038 lr 0.00028852 rank 6
2023-03-01 10:20:02,096 DEBUG TRAIN Batch 53/8300 loss 6.218034 loss_att 7.644593 loss_ctc 9.121934 loss_rnnt 5.378652 hw_loss 0.312908 lr 0.00028851 rank 4
2023-03-01 10:20:02,100 DEBUG TRAIN Batch 53/8300 loss 4.070528 loss_att 9.112322 loss_ctc 11.345286 loss_rnnt 1.985426 hw_loss 0.200203 lr 0.00028851 rank 5
2023-03-01 10:20:02,103 DEBUG TRAIN Batch 53/8300 loss 2.408893 loss_att 5.669765 loss_ctc 7.719320 loss_rnnt 0.966132 hw_loss 0.154742 lr 0.00028851 rank 1
2023-03-01 10:20:02,108 DEBUG TRAIN Batch 53/8300 loss 3.467718 loss_att 5.898423 loss_ctc 6.148865 loss_rnnt 2.466482 hw_loss 0.295516 lr 0.00028852 rank 0
2023-03-01 10:20:02,109 DEBUG TRAIN Batch 53/8300 loss 2.576597 loss_att 4.456528 loss_ctc 4.122478 loss_rnnt 1.908001 hw_loss 0.162174 lr 0.00028851 rank 7
2023-03-01 10:20:02,114 DEBUG TRAIN Batch 53/8300 loss 11.751294 loss_att 12.270626 loss_ctc 13.415693 loss_rnnt 11.305160 hw_loss 0.225653 lr 0.00028852 rank 2
2023-03-01 10:20:02,119 DEBUG TRAIN Batch 53/8300 loss 10.401157 loss_att 12.875341 loss_ctc 14.997524 loss_rnnt 9.192403 hw_loss 0.189506 lr 0.00028851 rank 6
2023-03-01 10:20:02,119 DEBUG TRAIN Batch 53/8300 loss 8.376416 loss_att 11.521584 loss_ctc 11.188532 loss_rnnt 7.329121 hw_loss 0.081212 lr 0.00028850 rank 3
2023-03-01 10:20:33,066 DEBUG CV Batch 53/0 loss 1.221059 loss_att 1.113968 loss_ctc 1.819083 loss_rnnt 0.970883 hw_loss 0.359733 history loss 1.175835 rank 5
2023-03-01 10:20:33,068 DEBUG CV Batch 53/0 loss 1.221059 loss_att 1.113968 loss_ctc 1.819083 loss_rnnt 0.970883 hw_loss 0.359733 history loss 1.175835 rank 7
2023-03-01 10:20:33,070 DEBUG CV Batch 53/0 loss 1.221059 loss_att 1.113968 loss_ctc 1.819083 loss_rnnt 0.970883 hw_loss 0.359733 history loss 1.175835 rank 4
2023-03-01 10:20:33,075 DEBUG CV Batch 53/0 loss 1.221059 loss_att 1.113968 loss_ctc 1.819083 loss_rnnt 0.970883 hw_loss 0.359733 history loss 1.175835 rank 6
2023-03-01 10:20:33,079 DEBUG CV Batch 53/0 loss 1.221059 loss_att 1.113968 loss_ctc 1.819083 loss_rnnt 0.970883 hw_loss 0.359733 history loss 1.175835 rank 2
2023-03-01 10:20:33,084 DEBUG CV Batch 53/0 loss 1.221059 loss_att 1.113968 loss_ctc 1.819083 loss_rnnt 0.970883 hw_loss 0.359733 history loss 1.175835 rank 3
2023-03-01 10:20:33,085 DEBUG CV Batch 53/0 loss 1.221059 loss_att 1.113968 loss_ctc 1.819083 loss_rnnt 0.970883 hw_loss 0.359733 history loss 1.175835 rank 0
2023-03-01 10:20:33,098 DEBUG CV Batch 53/0 loss 1.221059 loss_att 1.113968 loss_ctc 1.819083 loss_rnnt 0.970883 hw_loss 0.359733 history loss 1.175835 rank 1
2023-03-01 10:20:44,134 DEBUG CV Batch 53/100 loss 3.810632 loss_att 4.507697 loss_ctc 8.405293 loss_rnnt 2.984552 hw_loss 0.138835 history loss 2.978172 rank 2
2023-03-01 10:20:44,160 DEBUG CV Batch 53/100 loss 3.810632 loss_att 4.507697 loss_ctc 8.405293 loss_rnnt 2.984552 hw_loss 0.138835 history loss 2.978172 rank 4
2023-03-01 10:20:44,220 DEBUG CV Batch 53/100 loss 3.810632 loss_att 4.507697 loss_ctc 8.405293 loss_rnnt 2.984552 hw_loss 0.138835 history loss 2.978172 rank 1
2023-03-01 10:20:44,232 DEBUG CV Batch 53/100 loss 3.810632 loss_att 4.507697 loss_ctc 8.405293 loss_rnnt 2.984552 hw_loss 0.138835 history loss 2.978172 rank 5
2023-03-01 10:20:44,293 DEBUG CV Batch 53/100 loss 3.810632 loss_att 4.507697 loss_ctc 8.405293 loss_rnnt 2.984552 hw_loss 0.138835 history loss 2.978172 rank 3
2023-03-01 10:20:44,852 DEBUG CV Batch 53/100 loss 3.810632 loss_att 4.507697 loss_ctc 8.405293 loss_rnnt 2.984552 hw_loss 0.138835 history loss 2.978172 rank 6
2023-03-01 10:20:45,045 DEBUG CV Batch 53/100 loss 3.810632 loss_att 4.507697 loss_ctc 8.405293 loss_rnnt 2.984552 hw_loss 0.138835 history loss 2.978172 rank 7
2023-03-01 10:20:45,163 DEBUG CV Batch 53/100 loss 3.810632 loss_att 4.507697 loss_ctc 8.405293 loss_rnnt 2.984552 hw_loss 0.138835 history loss 2.978172 rank 0
2023-03-01 10:20:57,621 DEBUG CV Batch 53/200 loss 4.933307 loss_att 8.467216 loss_ctc 8.695425 loss_rnnt 3.724425 hw_loss 0.000909 history loss 3.588115 rank 2
2023-03-01 10:20:58,061 DEBUG CV Batch 53/200 loss 4.933307 loss_att 8.467216 loss_ctc 8.695425 loss_rnnt 3.724425 hw_loss 0.000909 history loss 3.588115 rank 4
2023-03-01 10:20:58,101 DEBUG CV Batch 53/200 loss 4.933307 loss_att 8.467216 loss_ctc 8.695425 loss_rnnt 3.724425 hw_loss 0.000909 history loss 3.588115 rank 5
2023-03-01 10:20:58,221 DEBUG CV Batch 53/200 loss 4.933307 loss_att 8.467216 loss_ctc 8.695425 loss_rnnt 3.724425 hw_loss 0.000909 history loss 3.588115 rank 6
2023-03-01 10:20:58,274 DEBUG CV Batch 53/200 loss 4.933307 loss_att 8.467216 loss_ctc 8.695425 loss_rnnt 3.724425 hw_loss 0.000909 history loss 3.588115 rank 3
2023-03-01 10:20:58,813 DEBUG CV Batch 53/200 loss 4.933307 loss_att 8.467216 loss_ctc 8.695425 loss_rnnt 3.724425 hw_loss 0.000909 history loss 3.588115 rank 1
2023-03-01 10:20:58,973 DEBUG CV Batch 53/200 loss 4.933307 loss_att 8.467216 loss_ctc 8.695425 loss_rnnt 3.724425 hw_loss 0.000909 history loss 3.588115 rank 7
2023-03-01 10:20:59,386 DEBUG CV Batch 53/200 loss 4.933307 loss_att 8.467216 loss_ctc 8.695425 loss_rnnt 3.724425 hw_loss 0.000909 history loss 3.588115 rank 0
2023-03-01 10:21:09,561 DEBUG CV Batch 53/300 loss 3.232057 loss_att 3.884573 loss_ctc 6.190300 loss_rnnt 2.587387 hw_loss 0.224502 history loss 3.749856 rank 2
2023-03-01 10:21:09,900 DEBUG CV Batch 53/300 loss 3.232057 loss_att 3.884573 loss_ctc 6.190300 loss_rnnt 2.587387 hw_loss 0.224502 history loss 3.749856 rank 5
2023-03-01 10:21:09,965 DEBUG CV Batch 53/300 loss 3.232057 loss_att 3.884573 loss_ctc 6.190300 loss_rnnt 2.587387 hw_loss 0.224502 history loss 3.749856 rank 4
2023-03-01 10:21:09,986 DEBUG CV Batch 53/300 loss 3.232057 loss_att 3.884573 loss_ctc 6.190300 loss_rnnt 2.587387 hw_loss 0.224502 history loss 3.749856 rank 6
2023-03-01 10:21:10,272 DEBUG CV Batch 53/300 loss 3.232057 loss_att 3.884573 loss_ctc 6.190300 loss_rnnt 2.587387 hw_loss 0.224502 history loss 3.749856 rank 3
2023-03-01 10:21:10,516 DEBUG CV Batch 53/300 loss 3.232057 loss_att 3.884573 loss_ctc 6.190300 loss_rnnt 2.587387 hw_loss 0.224502 history loss 3.749856 rank 1
2023-03-01 10:21:11,638 DEBUG CV Batch 53/300 loss 3.232057 loss_att 3.884573 loss_ctc 6.190300 loss_rnnt 2.587387 hw_loss 0.224502 history loss 3.749856 rank 7
2023-03-01 10:21:12,342 DEBUG CV Batch 53/300 loss 3.232057 loss_att 3.884573 loss_ctc 6.190300 loss_rnnt 2.587387 hw_loss 0.224502 history loss 3.749856 rank 0
2023-03-01 10:21:21,579 DEBUG CV Batch 53/400 loss 14.684860 loss_att 60.810516 loss_ctc 8.217653 loss_rnnt 6.239741 hw_loss 0.154276 history loss 4.559201 rank 2
2023-03-01 10:21:21,674 DEBUG CV Batch 53/400 loss 14.684860 loss_att 60.810516 loss_ctc 8.217653 loss_rnnt 6.239741 hw_loss 0.154276 history loss 4.559201 rank 4
2023-03-01 10:21:21,753 DEBUG CV Batch 53/400 loss 14.684860 loss_att 60.810516 loss_ctc 8.217653 loss_rnnt 6.239741 hw_loss 0.154276 history loss 4.559201 rank 5
2023-03-01 10:21:21,814 DEBUG CV Batch 53/400 loss 14.684860 loss_att 60.810516 loss_ctc 8.217653 loss_rnnt 6.239741 hw_loss 0.154276 history loss 4.559201 rank 6
2023-03-01 10:21:22,165 DEBUG CV Batch 53/400 loss 14.684860 loss_att 60.810516 loss_ctc 8.217653 loss_rnnt 6.239741 hw_loss 0.154276 history loss 4.559201 rank 1
2023-03-01 10:21:22,455 DEBUG CV Batch 53/400 loss 14.684860 loss_att 60.810516 loss_ctc 8.217653 loss_rnnt 6.239741 hw_loss 0.154276 history loss 4.559201 rank 3
2023-03-01 10:21:24,383 DEBUG CV Batch 53/400 loss 14.684860 loss_att 60.810516 loss_ctc 8.217653 loss_rnnt 6.239741 hw_loss 0.154276 history loss 4.559201 rank 7
2023-03-01 10:21:25,442 DEBUG CV Batch 53/400 loss 14.684860 loss_att 60.810516 loss_ctc 8.217653 loss_rnnt 6.239741 hw_loss 0.154276 history loss 4.559201 rank 0
2023-03-01 10:21:31,870 DEBUG CV Batch 53/500 loss 3.044883 loss_att 3.823375 loss_ctc 4.560869 loss_rnnt 2.641302 hw_loss 0.085784 history loss 5.162204 rank 2
2023-03-01 10:21:31,913 DEBUG CV Batch 53/500 loss 3.044883 loss_att 3.823375 loss_ctc 4.560869 loss_rnnt 2.641302 hw_loss 0.085784 history loss 5.162204 rank 4
2023-03-01 10:21:32,107 DEBUG CV Batch 53/500 loss 3.044883 loss_att 3.823375 loss_ctc 4.560869 loss_rnnt 2.641302 hw_loss 0.085784 history loss 5.162204 rank 6
2023-03-01 10:21:32,136 DEBUG CV Batch 53/500 loss 3.044883 loss_att 3.823375 loss_ctc 4.560869 loss_rnnt 2.641302 hw_loss 0.085784 history loss 5.162204 rank 5
2023-03-01 10:21:32,961 DEBUG CV Batch 53/500 loss 3.044883 loss_att 3.823375 loss_ctc 4.560869 loss_rnnt 2.641302 hw_loss 0.085784 history loss 5.162204 rank 1
2023-03-01 10:21:33,034 DEBUG CV Batch 53/500 loss 3.044883 loss_att 3.823375 loss_ctc 4.560869 loss_rnnt 2.641302 hw_loss 0.085784 history loss 5.162204 rank 3
2023-03-01 10:21:35,460 DEBUG CV Batch 53/500 loss 3.044883 loss_att 3.823375 loss_ctc 4.560869 loss_rnnt 2.641302 hw_loss 0.085784 history loss 5.162204 rank 7
2023-03-01 10:21:36,941 DEBUG CV Batch 53/500 loss 3.044883 loss_att 3.823375 loss_ctc 4.560869 loss_rnnt 2.641302 hw_loss 0.085784 history loss 5.162204 rank 0
2023-03-01 10:21:44,108 DEBUG CV Batch 53/600 loss 7.980324 loss_att 7.068987 loss_ctc 11.316593 loss_rnnt 7.545773 hw_loss 0.322468 history loss 6.029024 rank 4
2023-03-01 10:21:44,406 DEBUG CV Batch 53/600 loss 7.980324 loss_att 7.068987 loss_ctc 11.316593 loss_rnnt 7.545773 hw_loss 0.322468 history loss 6.029024 rank 2
2023-03-01 10:21:44,514 DEBUG CV Batch 53/600 loss 7.980324 loss_att 7.068987 loss_ctc 11.316593 loss_rnnt 7.545773 hw_loss 0.322468 history loss 6.029024 rank 6
2023-03-01 10:21:44,903 DEBUG CV Batch 53/600 loss 7.980324 loss_att 7.068987 loss_ctc 11.316593 loss_rnnt 7.545773 hw_loss 0.322468 history loss 6.029024 rank 5
2023-03-01 10:21:45,007 DEBUG CV Batch 53/600 loss 7.980324 loss_att 7.068987 loss_ctc 11.316593 loss_rnnt 7.545773 hw_loss 0.322468 history loss 6.029024 rank 1
2023-03-01 10:21:45,338 DEBUG CV Batch 53/600 loss 7.980324 loss_att 7.068987 loss_ctc 11.316593 loss_rnnt 7.545773 hw_loss 0.322468 history loss 6.029024 rank 3
2023-03-01 10:21:48,115 DEBUG CV Batch 53/600 loss 7.980324 loss_att 7.068987 loss_ctc 11.316593 loss_rnnt 7.545773 hw_loss 0.322468 history loss 6.029024 rank 7
2023-03-01 10:21:49,696 DEBUG CV Batch 53/600 loss 7.980324 loss_att 7.068987 loss_ctc 11.316593 loss_rnnt 7.545773 hw_loss 0.322468 history loss 6.029024 rank 0
2023-03-01 10:21:55,568 DEBUG CV Batch 53/700 loss 11.731359 loss_att 23.320072 loss_ctc 15.499739 loss_rnnt 8.759011 hw_loss 0.285292 history loss 6.575746 rank 2
2023-03-01 10:21:57,006 DEBUG CV Batch 53/700 loss 11.731359 loss_att 23.320072 loss_ctc 15.499739 loss_rnnt 8.759011 hw_loss 0.285292 history loss 6.575746 rank 4
2023-03-01 10:21:57,381 DEBUG CV Batch 53/700 loss 11.731359 loss_att 23.320072 loss_ctc 15.499739 loss_rnnt 8.759011 hw_loss 0.285292 history loss 6.575746 rank 6
2023-03-01 10:21:57,712 DEBUG CV Batch 53/700 loss 11.731359 loss_att 23.320072 loss_ctc 15.499739 loss_rnnt 8.759011 hw_loss 0.285292 history loss 6.575746 rank 5
2023-03-01 10:21:58,021 DEBUG CV Batch 53/700 loss 11.731359 loss_att 23.320072 loss_ctc 15.499739 loss_rnnt 8.759011 hw_loss 0.285292 history loss 6.575746 rank 1
2023-03-01 10:21:58,256 DEBUG CV Batch 53/700 loss 11.731359 loss_att 23.320072 loss_ctc 15.499739 loss_rnnt 8.759011 hw_loss 0.285292 history loss 6.575746 rank 3
2023-03-01 10:22:00,032 DEBUG CV Batch 53/700 loss 11.731359 loss_att 23.320072 loss_ctc 15.499739 loss_rnnt 8.759011 hw_loss 0.285292 history loss 6.575746 rank 7
2023-03-01 10:22:01,980 DEBUG CV Batch 53/700 loss 11.731359 loss_att 23.320072 loss_ctc 15.499739 loss_rnnt 8.759011 hw_loss 0.285292 history loss 6.575746 rank 0
2023-03-01 10:22:07,204 DEBUG CV Batch 53/800 loss 6.099338 loss_att 6.808889 loss_ctc 12.134104 loss_rnnt 5.074454 hw_loss 0.146882 history loss 6.096055 rank 2
2023-03-01 10:22:09,519 DEBUG CV Batch 53/800 loss 6.099338 loss_att 6.808889 loss_ctc 12.134104 loss_rnnt 5.074454 hw_loss 0.146882 history loss 6.096055 rank 4
2023-03-01 10:22:10,247 DEBUG CV Batch 53/800 loss 6.099338 loss_att 6.808889 loss_ctc 12.134104 loss_rnnt 5.074454 hw_loss 0.146882 history loss 6.096055 rank 1
2023-03-01 10:22:10,254 DEBUG CV Batch 53/800 loss 6.099338 loss_att 6.808889 loss_ctc 12.134104 loss_rnnt 5.074454 hw_loss 0.146882 history loss 6.096055 rank 5
2023-03-01 10:22:10,270 DEBUG CV Batch 53/800 loss 6.099338 loss_att 6.808889 loss_ctc 12.134104 loss_rnnt 5.074454 hw_loss 0.146882 history loss 6.096055 rank 6
2023-03-01 10:22:10,861 DEBUG CV Batch 53/800 loss 6.099338 loss_att 6.808889 loss_ctc 12.134104 loss_rnnt 5.074454 hw_loss 0.146882 history loss 6.096055 rank 3
2023-03-01 10:22:11,705 DEBUG CV Batch 53/800 loss 6.099338 loss_att 6.808889 loss_ctc 12.134104 loss_rnnt 5.074454 hw_loss 0.146882 history loss 6.096055 rank 7
2023-03-01 10:22:13,914 DEBUG CV Batch 53/800 loss 6.099338 loss_att 6.808889 loss_ctc 12.134104 loss_rnnt 5.074454 hw_loss 0.146882 history loss 6.096055 rank 0
2023-03-01 10:22:20,825 DEBUG CV Batch 53/900 loss 12.580250 loss_att 12.283607 loss_ctc 21.545088 loss_rnnt 11.417770 hw_loss 0.049681 history loss 5.932887 rank 2
2023-03-01 10:22:24,067 DEBUG CV Batch 53/900 loss 12.580250 loss_att 12.283607 loss_ctc 21.545088 loss_rnnt 11.417770 hw_loss 0.049681 history loss 5.932887 rank 4
2023-03-01 10:22:24,385 DEBUG CV Batch 53/900 loss 12.580250 loss_att 12.283607 loss_ctc 21.545088 loss_rnnt 11.417770 hw_loss 0.049681 history loss 5.932887 rank 6
2023-03-01 10:22:24,460 DEBUG CV Batch 53/900 loss 12.580250 loss_att 12.283607 loss_ctc 21.545088 loss_rnnt 11.417770 hw_loss 0.049681 history loss 5.932887 rank 5
2023-03-01 10:22:24,624 DEBUG CV Batch 53/900 loss 12.580250 loss_att 12.283607 loss_ctc 21.545088 loss_rnnt 11.417770 hw_loss 0.049681 history loss 5.932887 rank 1
2023-03-01 10:22:25,356 DEBUG CV Batch 53/900 loss 12.580250 loss_att 12.283607 loss_ctc 21.545088 loss_rnnt 11.417770 hw_loss 0.049681 history loss 5.932887 rank 3
2023-03-01 10:22:25,699 DEBUG CV Batch 53/900 loss 12.580250 loss_att 12.283607 loss_ctc 21.545088 loss_rnnt 11.417770 hw_loss 0.049681 history loss 5.932887 rank 7
2023-03-01 10:22:28,241 DEBUG CV Batch 53/900 loss 12.580250 loss_att 12.283607 loss_ctc 21.545088 loss_rnnt 11.417770 hw_loss 0.049681 history loss 5.932887 rank 0
2023-03-01 10:22:33,001 DEBUG CV Batch 53/1000 loss 4.475576 loss_att 4.672163 loss_ctc 6.073064 loss_rnnt 4.076323 hw_loss 0.275508 history loss 5.746148 rank 2
2023-03-01 10:22:35,881 DEBUG CV Batch 53/1000 loss 4.475576 loss_att 4.672163 loss_ctc 6.073064 loss_rnnt 4.076323 hw_loss 0.275508 history loss 5.746148 rank 4
2023-03-01 10:22:36,392 DEBUG CV Batch 53/1000 loss 4.475576 loss_att 4.672163 loss_ctc 6.073064 loss_rnnt 4.076323 hw_loss 0.275508 history loss 5.746148 rank 5
2023-03-01 10:22:36,399 DEBUG CV Batch 53/1000 loss 4.475576 loss_att 4.672163 loss_ctc 6.073064 loss_rnnt 4.076323 hw_loss 0.275508 history loss 5.746148 rank 6
2023-03-01 10:22:36,631 DEBUG CV Batch 53/1000 loss 4.475576 loss_att 4.672163 loss_ctc 6.073064 loss_rnnt 4.076323 hw_loss 0.275508 history loss 5.746148 rank 1
2023-03-01 10:22:37,625 DEBUG CV Batch 53/1000 loss 4.475576 loss_att 4.672163 loss_ctc 6.073064 loss_rnnt 4.076323 hw_loss 0.275508 history loss 5.746148 rank 3
2023-03-01 10:22:38,612 DEBUG CV Batch 53/1000 loss 4.475576 loss_att 4.672163 loss_ctc 6.073064 loss_rnnt 4.076323 hw_loss 0.275508 history loss 5.746148 rank 7
2023-03-01 10:22:41,469 DEBUG CV Batch 53/1000 loss 4.475576 loss_att 4.672163 loss_ctc 6.073064 loss_rnnt 4.076323 hw_loss 0.275508 history loss 5.746148 rank 0
2023-03-01 10:22:44,845 DEBUG CV Batch 53/1100 loss 4.728875 loss_att 4.543048 loss_ctc 8.011924 loss_rnnt 4.108788 hw_loss 0.411583 history loss 5.706297 rank 2
2023-03-01 10:22:47,572 DEBUG CV Batch 53/1100 loss 4.728875 loss_att 4.543048 loss_ctc 8.011924 loss_rnnt 4.108788 hw_loss 0.411583 history loss 5.706297 rank 4
2023-03-01 10:22:48,186 DEBUG CV Batch 53/1100 loss 4.728875 loss_att 4.543048 loss_ctc 8.011924 loss_rnnt 4.108788 hw_loss 0.411583 history loss 5.706297 rank 1
2023-03-01 10:22:48,189 DEBUG CV Batch 53/1100 loss 4.728875 loss_att 4.543048 loss_ctc 8.011924 loss_rnnt 4.108788 hw_loss 0.411583 history loss 5.706297 rank 5
2023-03-01 10:22:48,247 DEBUG CV Batch 53/1100 loss 4.728875 loss_att 4.543048 loss_ctc 8.011924 loss_rnnt 4.108788 hw_loss 0.411583 history loss 5.706297 rank 6
2023-03-01 10:22:49,717 DEBUG CV Batch 53/1100 loss 4.728875 loss_att 4.543048 loss_ctc 8.011924 loss_rnnt 4.108788 hw_loss 0.411583 history loss 5.706297 rank 3
2023-03-01 10:22:51,299 DEBUG CV Batch 53/1100 loss 4.728875 loss_att 4.543048 loss_ctc 8.011924 loss_rnnt 4.108788 hw_loss 0.411583 history loss 5.706297 rank 7
2023-03-01 10:22:54,168 DEBUG CV Batch 53/1100 loss 4.728875 loss_att 4.543048 loss_ctc 8.011924 loss_rnnt 4.108788 hw_loss 0.411583 history loss 5.706297 rank 0
2023-03-01 10:22:55,177 DEBUG CV Batch 53/1200 loss 7.512011 loss_att 7.015139 loss_ctc 7.611217 loss_rnnt 7.453331 hw_loss 0.271552 history loss 5.979754 rank 2
2023-03-01 10:22:57,868 DEBUG CV Batch 53/1200 loss 7.512011 loss_att 7.015139 loss_ctc 7.611217 loss_rnnt 7.453331 hw_loss 0.271552 history loss 5.979754 rank 4
2023-03-01 10:22:58,545 DEBUG CV Batch 53/1200 loss 7.512011 loss_att 7.015139 loss_ctc 7.611217 loss_rnnt 7.453331 hw_loss 0.271552 history loss 5.979754 rank 5
2023-03-01 10:22:58,813 DEBUG CV Batch 53/1200 loss 7.512011 loss_att 7.015139 loss_ctc 7.611217 loss_rnnt 7.453331 hw_loss 0.271552 history loss 5.979754 rank 1
2023-03-01 10:22:58,850 DEBUG CV Batch 53/1200 loss 7.512011 loss_att 7.015139 loss_ctc 7.611217 loss_rnnt 7.453331 hw_loss 0.271552 history loss 5.979754 rank 6
2023-03-01 10:23:00,303 DEBUG CV Batch 53/1200 loss 7.512011 loss_att 7.015139 loss_ctc 7.611217 loss_rnnt 7.453331 hw_loss 0.271552 history loss 5.979754 rank 3
2023-03-01 10:23:02,644 DEBUG CV Batch 53/1200 loss 7.512011 loss_att 7.015139 loss_ctc 7.611217 loss_rnnt 7.453331 hw_loss 0.271552 history loss 5.979754 rank 7
2023-03-01 10:23:05,559 DEBUG CV Batch 53/1200 loss 7.512011 loss_att 7.015139 loss_ctc 7.611217 loss_rnnt 7.453331 hw_loss 0.271552 history loss 5.979754 rank 0
2023-03-01 10:23:07,049 DEBUG CV Batch 53/1300 loss 3.827776 loss_att 3.450417 loss_ctc 6.099771 loss_rnnt 3.461160 hw_loss 0.260916 history loss 6.263391 rank 2
2023-03-01 10:23:10,047 DEBUG CV Batch 53/1300 loss 3.827776 loss_att 3.450417 loss_ctc 6.099771 loss_rnnt 3.461160 hw_loss 0.260916 history loss 6.263391 rank 4
2023-03-01 10:23:10,494 DEBUG CV Batch 53/1300 loss 3.827776 loss_att 3.450417 loss_ctc 6.099771 loss_rnnt 3.461160 hw_loss 0.260916 history loss 6.263391 rank 5
2023-03-01 10:23:10,949 DEBUG CV Batch 53/1300 loss 3.827776 loss_att 3.450417 loss_ctc 6.099771 loss_rnnt 3.461160 hw_loss 0.260916 history loss 6.263391 rank 6
2023-03-01 10:23:11,001 DEBUG CV Batch 53/1300 loss 3.827776 loss_att 3.450417 loss_ctc 6.099771 loss_rnnt 3.461160 hw_loss 0.260916 history loss 6.263391 rank 1
2023-03-01 10:23:12,426 DEBUG CV Batch 53/1300 loss 3.827776 loss_att 3.450417 loss_ctc 6.099771 loss_rnnt 3.461160 hw_loss 0.260916 history loss 6.263391 rank 3
2023-03-01 10:23:15,134 DEBUG CV Batch 53/1300 loss 3.827776 loss_att 3.450417 loss_ctc 6.099771 loss_rnnt 3.461160 hw_loss 0.260916 history loss 6.263391 rank 7
2023-03-01 10:23:18,392 DEBUG CV Batch 53/1300 loss 3.827776 loss_att 3.450417 loss_ctc 6.099771 loss_rnnt 3.461160 hw_loss 0.260916 history loss 6.263391 rank 0
2023-03-01 10:23:18,397 DEBUG CV Batch 53/1400 loss 3.801296 loss_att 14.464752 loss_ctc 4.030107 loss_rnnt 1.483009 hw_loss 0.290788 history loss 6.546437 rank 2
2023-03-01 10:23:22,436 DEBUG CV Batch 53/1400 loss 3.801296 loss_att 14.464752 loss_ctc 4.030107 loss_rnnt 1.483009 hw_loss 0.290788 history loss 6.546437 rank 4
2023-03-01 10:23:23,088 DEBUG CV Batch 53/1400 loss 3.801296 loss_att 14.464752 loss_ctc 4.030107 loss_rnnt 1.483009 hw_loss 0.290788 history loss 6.546437 rank 6
2023-03-01 10:23:23,226 DEBUG CV Batch 53/1400 loss 3.801296 loss_att 14.464752 loss_ctc 4.030107 loss_rnnt 1.483009 hw_loss 0.290788 history loss 6.546437 rank 1
2023-03-01 10:23:23,334 DEBUG CV Batch 53/1400 loss 3.801296 loss_att 14.464752 loss_ctc 4.030107 loss_rnnt 1.483009 hw_loss 0.290788 history loss 6.546437 rank 5
2023-03-01 10:23:24,624 DEBUG CV Batch 53/1400 loss 3.801296 loss_att 14.464752 loss_ctc 4.030107 loss_rnnt 1.483009 hw_loss 0.290788 history loss 6.546437 rank 3
2023-03-01 10:23:27,111 DEBUG CV Batch 53/1400 loss 3.801296 loss_att 14.464752 loss_ctc 4.030107 loss_rnnt 1.483009 hw_loss 0.290788 history loss 6.546437 rank 7
2023-03-01 10:23:29,763 DEBUG CV Batch 53/1500 loss 7.639319 loss_att 7.305519 loss_ctc 8.309982 loss_rnnt 7.502327 hw_loss 0.214369 history loss 6.408081 rank 2
2023-03-01 10:23:30,585 DEBUG CV Batch 53/1400 loss 3.801296 loss_att 14.464752 loss_ctc 4.030107 loss_rnnt 1.483009 hw_loss 0.290788 history loss 6.546437 rank 0
2023-03-01 10:23:35,637 DEBUG CV Batch 53/1500 loss 7.639319 loss_att 7.305519 loss_ctc 8.309982 loss_rnnt 7.502327 hw_loss 0.214369 history loss 6.408081 rank 4
2023-03-01 10:23:35,678 DEBUG CV Batch 53/1500 loss 7.639319 loss_att 7.305519 loss_ctc 8.309982 loss_rnnt 7.502327 hw_loss 0.214369 history loss 6.408081 rank 5
2023-03-01 10:23:35,863 DEBUG CV Batch 53/1500 loss 7.639319 loss_att 7.305519 loss_ctc 8.309982 loss_rnnt 7.502327 hw_loss 0.214369 history loss 6.408081 rank 6
2023-03-01 10:23:36,108 DEBUG CV Batch 53/1500 loss 7.639319 loss_att 7.305519 loss_ctc 8.309982 loss_rnnt 7.502327 hw_loss 0.214369 history loss 6.408081 rank 1
2023-03-01 10:23:37,473 DEBUG CV Batch 53/1500 loss 7.639319 loss_att 7.305519 loss_ctc 8.309982 loss_rnnt 7.502327 hw_loss 0.214369 history loss 6.408081 rank 3
2023-03-01 10:23:39,059 DEBUG CV Batch 53/1500 loss 7.639319 loss_att 7.305519 loss_ctc 8.309982 loss_rnnt 7.502327 hw_loss 0.214369 history loss 6.408081 rank 7
2023-03-01 10:23:42,850 DEBUG CV Batch 53/1600 loss 8.033743 loss_att 10.646484 loss_ctc 10.819332 loss_rnnt 7.057929 hw_loss 0.153477 history loss 6.370538 rank 2
2023-03-01 10:23:42,908 DEBUG CV Batch 53/1500 loss 7.639319 loss_att 7.305519 loss_ctc 8.309982 loss_rnnt 7.502327 hw_loss 0.214369 history loss 6.408081 rank 0
2023-03-01 10:23:48,945 DEBUG CV Batch 53/1600 loss 8.033743 loss_att 10.646484 loss_ctc 10.819332 loss_rnnt 7.057929 hw_loss 0.153477 history loss 6.370538 rank 4
2023-03-01 10:23:49,458 DEBUG CV Batch 53/1600 loss 8.033743 loss_att 10.646484 loss_ctc 10.819332 loss_rnnt 7.057929 hw_loss 0.153477 history loss 6.370538 rank 5
2023-03-01 10:23:49,596 DEBUG CV Batch 53/1600 loss 8.033743 loss_att 10.646484 loss_ctc 10.819332 loss_rnnt 7.057929 hw_loss 0.153477 history loss 6.370538 rank 1
2023-03-01 10:23:49,780 DEBUG CV Batch 53/1600 loss 8.033743 loss_att 10.646484 loss_ctc 10.819332 loss_rnnt 7.057929 hw_loss 0.153477 history loss 6.370538 rank 6
2023-03-01 10:23:51,127 DEBUG CV Batch 53/1600 loss 8.033743 loss_att 10.646484 loss_ctc 10.819332 loss_rnnt 7.057929 hw_loss 0.153477 history loss 6.370538 rank 3
2023-03-01 10:23:52,933 DEBUG CV Batch 53/1600 loss 8.033743 loss_att 10.646484 loss_ctc 10.819332 loss_rnnt 7.057929 hw_loss 0.153477 history loss 6.370538 rank 7
2023-03-01 10:23:55,184 DEBUG CV Batch 53/1700 loss 7.867762 loss_att 6.561065 loss_ctc 14.764906 loss_rnnt 7.105650 hw_loss 0.194684 history loss 6.312844 rank 2
2023-03-01 10:23:56,807 DEBUG CV Batch 53/1600 loss 8.033743 loss_att 10.646484 loss_ctc 10.819332 loss_rnnt 7.057929 hw_loss 0.153477 history loss 6.370538 rank 0
2023-03-01 10:24:01,068 DEBUG CV Batch 53/1700 loss 7.867762 loss_att 6.561065 loss_ctc 14.764906 loss_rnnt 7.105650 hw_loss 0.194684 history loss 6.312844 rank 4
2023-03-01 10:24:01,694 DEBUG CV Batch 53/1700 loss 7.867762 loss_att 6.561065 loss_ctc 14.764906 loss_rnnt 7.105650 hw_loss 0.194684 history loss 6.312844 rank 5
2023-03-01 10:24:01,790 DEBUG CV Batch 53/1700 loss 7.867762 loss_att 6.561065 loss_ctc 14.764906 loss_rnnt 7.105650 hw_loss 0.194684 history loss 6.312844 rank 1
2023-03-01 10:24:02,125 DEBUG CV Batch 53/1700 loss 7.867762 loss_att 6.561065 loss_ctc 14.764906 loss_rnnt 7.105650 hw_loss 0.194684 history loss 6.312844 rank 6
2023-03-01 10:24:03,482 DEBUG CV Batch 53/1700 loss 7.867762 loss_att 6.561065 loss_ctc 14.764906 loss_rnnt 7.105650 hw_loss 0.194684 history loss 6.312844 rank 3
2023-03-01 10:24:04,649 INFO Epoch 53 CV info cv_loss 6.295685838378696
2023-03-01 10:24:04,649 INFO Epoch 54 TRAIN info lr 0.0002885092894201837
2023-03-01 10:24:04,654 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 10:24:06,005 DEBUG CV Batch 53/1700 loss 7.867762 loss_att 6.561065 loss_ctc 14.764906 loss_rnnt 7.105650 hw_loss 0.194684 history loss 6.312844 rank 7
2023-03-01 10:24:09,823 DEBUG CV Batch 53/1700 loss 7.867762 loss_att 6.561065 loss_ctc 14.764906 loss_rnnt 7.105650 hw_loss 0.194684 history loss 6.312844 rank 0
2023-03-01 10:24:10,215 INFO Epoch 53 CV info cv_loss 6.295685838413154
2023-03-01 10:24:10,216 INFO Epoch 54 TRAIN info lr 0.00028850592740362806
2023-03-01 10:24:10,218 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 10:24:10,980 INFO Epoch 53 CV info cv_loss 6.295685839661199
2023-03-01 10:24:10,980 INFO Epoch 54 TRAIN info lr 0.00028850496684905684
2023-03-01 10:24:10,982 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 10:24:11,004 INFO Epoch 53 CV info cv_loss 6.295685839157243
2023-03-01 10:24:11,005 INFO Epoch 54 TRAIN info lr 0.0002885040063040798
2023-03-01 10:24:11,012 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 10:24:11,534 INFO Epoch 53 CV info cv_loss 6.29568583862852
2023-03-01 10:24:11,534 INFO Epoch 54 TRAIN info lr 0.00028850496684905684
2023-03-01 10:24:11,536 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 10:24:12,963 INFO Epoch 53 CV info cv_loss 6.295685838890189
2023-03-01 10:24:12,963 INFO Epoch 54 TRAIN info lr 0.00028850016422011024
2023-03-01 10:24:12,968 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 10:24:15,327 INFO Epoch 53 CV info cv_loss 6.295685837330941
2023-03-01 10:24:15,327 INFO Epoch 54 TRAIN info lr 0.00028850352603518905
2023-03-01 10:24:15,329 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 10:24:19,306 INFO Epoch 53 CV info cv_loss 6.29568583980334
2023-03-01 10:24:19,306 INFO Checkpoint: save to checkpoint exp/2_27_rnnt_bias_loss_2_class_both_finetune/53.pt
2023-03-01 10:24:19,872 INFO Epoch 54 TRAIN info lr 0.00028851217124221
2023-03-01 10:24:19,877 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 10:25:23,524 DEBUG TRAIN Batch 54/0 loss 6.192917 loss_att 6.631746 loss_ctc 7.790324 loss_rnnt 5.719834 hw_loss 0.323116 lr 0.00028850 rank 1
2023-03-01 10:25:23,525 DEBUG TRAIN Batch 54/0 loss 10.403881 loss_att 9.566971 loss_ctc 14.493213 loss_rnnt 9.882227 hw_loss 0.269609 lr 0.00028851 rank 2
2023-03-01 10:25:23,528 DEBUG TRAIN Batch 54/0 loss 4.629131 loss_att 4.479362 loss_ctc 7.047172 loss_rnnt 4.188893 hw_loss 0.277101 lr 0.00028851 rank 4
2023-03-01 10:25:23,529 DEBUG TRAIN Batch 54/0 loss 5.050465 loss_att 5.446393 loss_ctc 7.287642 loss_rnnt 4.488184 hw_loss 0.346509 lr 0.00028850 rank 6
2023-03-01 10:25:23,531 DEBUG TRAIN Batch 54/0 loss 5.105662 loss_att 5.736762 loss_ctc 8.038796 loss_rnnt 4.420508 hw_loss 0.314718 lr 0.00028850 rank 7
2023-03-01 10:25:23,536 DEBUG TRAIN Batch 54/0 loss 3.317594 loss_att 3.593820 loss_ctc 4.649056 loss_rnnt 2.943779 hw_loss 0.264454 lr 0.00028850 rank 5
2023-03-01 10:25:23,539 DEBUG TRAIN Batch 54/0 loss 5.283196 loss_att 5.841209 loss_ctc 8.191970 loss_rnnt 4.587208 hw_loss 0.368528 lr 0.00028850 rank 3
2023-03-01 10:25:23,540 DEBUG TRAIN Batch 54/0 loss 6.541572 loss_att 7.192130 loss_ctc 8.911861 loss_rnnt 5.971267 hw_loss 0.232790 lr 0.00028851 rank 0
2023-03-01 10:26:01,093 DEBUG TRAIN Batch 54/100 loss 2.497893 loss_att 5.069828 loss_ctc 3.447897 loss_rnnt 1.759793 hw_loss 0.181962 lr 0.00028849 rank 3
2023-03-01 10:26:01,095 DEBUG TRAIN Batch 54/100 loss 3.318150 loss_att 6.566232 loss_ctc 6.015298 loss_rnnt 2.222472 hw_loss 0.162077 lr 0.00028849 rank 6
2023-03-01 10:26:01,095 DEBUG TRAIN Batch 54/100 loss 13.516323 loss_att 23.863035 loss_ctc 29.806217 loss_rnnt 9.109520 hw_loss 0.310265 lr 0.00028849 rank 4
2023-03-01 10:26:01,097 DEBUG TRAIN Batch 54/100 loss 6.596331 loss_att 9.043917 loss_ctc 9.152654 loss_rnnt 5.616615 hw_loss 0.280042 lr 0.00028850 rank 2
2023-03-01 10:26:01,098 DEBUG TRAIN Batch 54/100 loss 3.568771 loss_att 8.686201 loss_ctc 6.923005 loss_rnnt 1.946974 hw_loss 0.283273 lr 0.00028849 rank 7
2023-03-01 10:26:01,100 DEBUG TRAIN Batch 54/100 loss 3.446731 loss_att 6.142045 loss_ctc 5.133921 loss_rnnt 2.548050 hw_loss 0.252488 lr 0.00028849 rank 1
2023-03-01 10:26:01,101 DEBUG TRAIN Batch 54/100 loss 6.716651 loss_att 10.209398 loss_ctc 12.549155 loss_rnnt 5.191728 hw_loss 0.091326 lr 0.00028850 rank 0
2023-03-01 10:26:01,102 DEBUG TRAIN Batch 54/100 loss 6.727310 loss_att 7.572933 loss_ctc 8.526861 loss_rnnt 6.159103 hw_loss 0.298390 lr 0.00028849 rank 5
2023-03-01 10:26:39,290 DEBUG TRAIN Batch 54/200 loss 2.085029 loss_att 4.958365 loss_ctc 2.868795 loss_rnnt 1.266237 hw_loss 0.261791 lr 0.00028848 rank 7
2023-03-01 10:26:39,305 DEBUG TRAIN Batch 54/200 loss 2.974672 loss_att 5.957314 loss_ctc 5.331359 loss_rnnt 2.011149 hw_loss 0.098941 lr 0.00028849 rank 0
2023-03-01 10:26:39,307 DEBUG TRAIN Batch 54/200 loss 3.999277 loss_att 10.231697 loss_ctc 8.221065 loss_rnnt 2.078553 hw_loss 0.208754 lr 0.00028848 rank 1
2023-03-01 10:26:39,310 DEBUG TRAIN Batch 54/200 loss 10.574479 loss_att 11.989969 loss_ctc 11.563621 loss_rnnt 10.023893 hw_loss 0.254254 lr 0.00028848 rank 4
2023-03-01 10:26:39,313 DEBUG TRAIN Batch 54/200 loss 2.864627 loss_att 4.444088 loss_ctc 4.767810 loss_rnnt 2.273464 hw_loss 0.040337 lr 0.00028848 rank 2
2023-03-01 10:26:39,314 DEBUG TRAIN Batch 54/200 loss 4.202849 loss_att 5.855700 loss_ctc 6.813464 loss_rnnt 3.386973 hw_loss 0.257295 lr 0.00028848 rank 6
2023-03-01 10:26:39,315 DEBUG TRAIN Batch 54/200 loss 3.211422 loss_att 5.079473 loss_ctc 5.854897 loss_rnnt 2.368738 hw_loss 0.218644 lr 0.00028848 rank 3
2023-03-01 10:26:39,322 DEBUG TRAIN Batch 54/200 loss 2.541204 loss_att 7.553840 loss_ctc 7.232998 loss_rnnt 0.763956 hw_loss 0.279653 lr 0.00028848 rank 5
2023-03-01 10:27:18,126 DEBUG TRAIN Batch 54/300 loss 4.171407 loss_att 6.692672 loss_ctc 6.692315 loss_rnnt 3.204979 hw_loss 0.236351 lr 0.00028847 rank 1
2023-03-01 10:27:18,126 DEBUG TRAIN Batch 54/300 loss 9.199139 loss_att 13.093068 loss_ctc 16.215652 loss_rnnt 7.358011 hw_loss 0.237759 lr 0.00028847 rank 4
2023-03-01 10:27:18,127 DEBUG TRAIN Batch 54/300 loss 6.516304 loss_att 8.946092 loss_ctc 11.854246 loss_rnnt 5.189208 hw_loss 0.242648 lr 0.00028848 rank 0
2023-03-01 10:27:18,128 DEBUG TRAIN Batch 54/300 loss 5.752955 loss_att 9.654255 loss_ctc 8.875320 loss_rnnt 4.442011 hw_loss 0.214442 lr 0.00028847 rank 6
2023-03-01 10:27:18,132 DEBUG TRAIN Batch 54/300 loss 3.334449 loss_att 6.768683 loss_ctc 6.311866 loss_rnnt 2.176550 hw_loss 0.138868 lr 0.00028846 rank 3
2023-03-01 10:27:18,146 DEBUG TRAIN Batch 54/300 loss 6.442498 loss_att 8.210714 loss_ctc 12.370651 loss_rnnt 5.203202 hw_loss 0.178559 lr 0.00028847 rank 7
2023-03-01 10:27:18,153 DEBUG TRAIN Batch 54/300 loss 7.894992 loss_att 10.854398 loss_ctc 13.105499 loss_rnnt 6.501018 hw_loss 0.201301 lr 0.00028847 rank 5
2023-03-01 10:27:18,170 DEBUG TRAIN Batch 54/300 loss 2.336335 loss_att 6.970279 loss_ctc 5.869151 loss_rnnt 0.825137 hw_loss 0.212563 lr 0.00028847 rank 2
2023-03-01 10:28:29,670 DEBUG TRAIN Batch 54/400 loss 5.640966 loss_att 8.210344 loss_ctc 10.098096 loss_rnnt 4.331198 hw_loss 0.378015 lr 0.00028845 rank 3
2023-03-01 10:28:29,673 DEBUG TRAIN Batch 54/400 loss 2.342985 loss_att 6.265513 loss_ctc 3.221365 loss_rnnt 1.336564 hw_loss 0.196496 lr 0.00028846 rank 4
2023-03-01 10:28:29,675 DEBUG TRAIN Batch 54/400 loss 2.709925 loss_att 5.818411 loss_ctc 3.837230 loss_rnnt 1.804013 hw_loss 0.251076 lr 0.00028846 rank 5
2023-03-01 10:28:29,690 DEBUG TRAIN Batch 54/400 loss 10.099776 loss_att 13.403961 loss_ctc 14.619787 loss_rnnt 8.712155 hw_loss 0.232715 lr 0.00028846 rank 2
2023-03-01 10:28:29,691 DEBUG TRAIN Batch 54/400 loss 3.865705 loss_att 6.272299 loss_ctc 7.431749 loss_rnnt 2.831213 hw_loss 0.145688 lr 0.00028846 rank 7
2023-03-01 10:28:29,696 DEBUG TRAIN Batch 54/400 loss 10.226239 loss_att 11.772396 loss_ctc 15.285929 loss_rnnt 9.131660 hw_loss 0.207602 lr 0.00028846 rank 6
2023-03-01 10:28:29,696 DEBUG TRAIN Batch 54/400 loss 7.200809 loss_att 8.930838 loss_ctc 9.092211 loss_rnnt 6.446064 hw_loss 0.293535 lr 0.00028846 rank 0
2023-03-01 10:28:29,699 DEBUG TRAIN Batch 54/400 loss 9.071587 loss_att 11.789721 loss_ctc 14.180664 loss_rnnt 7.718971 hw_loss 0.239584 lr 0.00028846 rank 1
2023-03-01 10:29:08,189 DEBUG TRAIN Batch 54/500 loss 6.492548 loss_att 11.211703 loss_ctc 16.987637 loss_rnnt 4.019457 hw_loss 0.243589 lr 0.00028844 rank 7
2023-03-01 10:29:08,199 DEBUG TRAIN Batch 54/500 loss 2.984926 loss_att 6.327704 loss_ctc 4.753920 loss_rnnt 1.955171 hw_loss 0.234999 lr 0.00028844 rank 1
2023-03-01 10:29:08,199 DEBUG TRAIN Batch 54/500 loss 6.542925 loss_att 8.622669 loss_ctc 9.753553 loss_rnnt 5.577127 hw_loss 0.228312 lr 0.00028845 rank 4
2023-03-01 10:29:08,201 DEBUG TRAIN Batch 54/500 loss 5.547184 loss_att 9.153576 loss_ctc 8.874462 loss_rnnt 4.348311 hw_loss 0.063669 lr 0.00028844 rank 5
2023-03-01 10:29:08,203 DEBUG TRAIN Batch 54/500 loss 4.211391 loss_att 6.875710 loss_ctc 7.492346 loss_rnnt 3.096943 hw_loss 0.270233 lr 0.00028844 rank 3
2023-03-01 10:29:08,205 DEBUG TRAIN Batch 54/500 loss 3.891969 loss_att 8.059307 loss_ctc 8.064948 loss_rnnt 2.374546 hw_loss 0.239171 lr 0.00028845 rank 0
2023-03-01 10:29:08,206 DEBUG TRAIN Batch 54/500 loss 9.576220 loss_att 12.619463 loss_ctc 17.418926 loss_rnnt 7.803726 hw_loss 0.221533 lr 0.00028844 rank 6
2023-03-01 10:29:08,212 DEBUG TRAIN Batch 54/500 loss 3.712838 loss_att 8.723680 loss_ctc 6.855145 loss_rnnt 2.206957 hw_loss 0.158884 lr 0.00028845 rank 2
2023-03-01 10:29:46,892 DEBUG TRAIN Batch 54/600 loss 5.787564 loss_att 7.713029 loss_ctc 8.203122 loss_rnnt 4.938367 hw_loss 0.266305 lr 0.00028843 rank 3
2023-03-01 10:29:46,898 DEBUG TRAIN Batch 54/600 loss 8.349924 loss_att 9.718058 loss_ctc 13.020065 loss_rnnt 7.308317 hw_loss 0.272429 lr 0.00028843 rank 7
2023-03-01 10:29:46,904 DEBUG TRAIN Batch 54/600 loss 9.636638 loss_att 11.358012 loss_ctc 14.904648 loss_rnnt 8.528076 hw_loss 0.116035 lr 0.00028844 rank 0
2023-03-01 10:29:46,905 DEBUG TRAIN Batch 54/600 loss 1.863552 loss_att 2.814461 loss_ctc 3.354865 loss_rnnt 1.351872 hw_loss 0.229980 lr 0.00028844 rank 2
2023-03-01 10:29:46,907 DEBUG TRAIN Batch 54/600 loss 7.753891 loss_att 9.817369 loss_ctc 15.239807 loss_rnnt 6.260274 hw_loss 0.155249 lr 0.00028843 rank 6
2023-03-01 10:29:46,910 DEBUG TRAIN Batch 54/600 loss 8.060216 loss_att 9.167955 loss_ctc 10.425515 loss_rnnt 7.353850 hw_loss 0.317710 lr 0.00028843 rank 4
2023-03-01 10:29:46,911 DEBUG TRAIN Batch 54/600 loss 11.381399 loss_att 11.091236 loss_ctc 15.023823 loss_rnnt 10.810078 hw_loss 0.269432 lr 0.00028843 rank 5
2023-03-01 10:29:46,953 DEBUG TRAIN Batch 54/600 loss 8.252365 loss_att 11.253269 loss_ctc 11.851951 loss_rnnt 7.017548 hw_loss 0.290045 lr 0.00028843 rank 1
2023-03-01 10:30:26,164 DEBUG TRAIN Batch 54/700 loss 2.879736 loss_att 5.604434 loss_ctc 8.818645 loss_rnnt 1.468852 hw_loss 0.138917 lr 0.00028842 rank 7
2023-03-01 10:30:26,166 DEBUG TRAIN Batch 54/700 loss 7.417996 loss_att 10.616546 loss_ctc 13.678127 loss_rnnt 5.805958 hw_loss 0.258083 lr 0.00028842 rank 6
2023-03-01 10:30:26,174 DEBUG TRAIN Batch 54/700 loss 2.962119 loss_att 5.453926 loss_ctc 3.507157 loss_rnnt 2.226635 hw_loss 0.308344 lr 0.00028842 rank 2
2023-03-01 10:30:26,177 DEBUG TRAIN Batch 54/700 loss 7.925651 loss_att 9.921071 loss_ctc 13.188126 loss_rnnt 6.739402 hw_loss 0.160315 lr 0.00028843 rank 0
2023-03-01 10:30:26,180 DEBUG TRAIN Batch 54/700 loss 3.527431 loss_att 6.104816 loss_ctc 6.958152 loss_rnnt 2.455464 hw_loss 0.185738 lr 0.00028842 rank 3
2023-03-01 10:30:26,188 DEBUG TRAIN Batch 54/700 loss 5.452872 loss_att 9.636549 loss_ctc 10.769142 loss_rnnt 3.765242 hw_loss 0.266360 lr 0.00028842 rank 5
2023-03-01 10:30:26,205 DEBUG TRAIN Batch 54/700 loss 5.560432 loss_att 7.539088 loss_ctc 8.344152 loss_rnnt 4.683774 hw_loss 0.205807 lr 0.00028842 rank 1
2023-03-01 10:30:26,211 DEBUG TRAIN Batch 54/700 loss 2.267228 loss_att 7.478824 loss_ctc 5.874977 loss_rnnt 0.658195 hw_loss 0.160652 lr 0.00028842 rank 4
2023-03-01 10:31:34,630 DEBUG TRAIN Batch 54/800 loss 1.418924 loss_att 3.116483 loss_ctc 2.178928 loss_rnnt 0.961583 hw_loss 0.030928 lr 0.00028840 rank 3
2023-03-01 10:31:34,642 DEBUG TRAIN Batch 54/800 loss 3.769449 loss_att 6.524895 loss_ctc 5.923650 loss_rnnt 2.886234 hw_loss 0.084187 lr 0.00028841 rank 6
2023-03-01 10:31:34,643 DEBUG TRAIN Batch 54/800 loss 3.566195 loss_att 5.533324 loss_ctc 4.956093 loss_rnnt 2.872090 hw_loss 0.216299 lr 0.00028841 rank 2
2023-03-01 10:31:34,644 DEBUG TRAIN Batch 54/800 loss 1.094251 loss_att 3.373351 loss_ctc 1.926393 loss_rnnt 0.483951 hw_loss 0.081615 lr 0.00028841 rank 1
2023-03-01 10:31:34,646 DEBUG TRAIN Batch 54/800 loss 1.657904 loss_att 4.647583 loss_ctc 2.832980 loss_rnnt 0.740341 hw_loss 0.305534 lr 0.00028841 rank 7
2023-03-01 10:31:34,647 DEBUG TRAIN Batch 54/800 loss 6.161486 loss_att 10.215000 loss_ctc 15.650457 loss_rnnt 3.890333 hw_loss 0.366101 lr 0.00028842 rank 0
2023-03-01 10:31:34,648 DEBUG TRAIN Batch 54/800 loss 3.395908 loss_att 6.260225 loss_ctc 5.401589 loss_rnnt 2.443986 hw_loss 0.209313 lr 0.00028841 rank 5
2023-03-01 10:31:34,653 DEBUG TRAIN Batch 54/800 loss 5.346964 loss_att 7.019270 loss_ctc 7.229748 loss_rnnt 4.587360 hw_loss 0.326447 lr 0.00028841 rank 4
2023-03-01 10:32:12,873 DEBUG TRAIN Batch 54/900 loss 3.498519 loss_att 5.951744 loss_ctc 5.879864 loss_rnnt 2.614985 hw_loss 0.141331 lr 0.00028840 rank 1
2023-03-01 10:32:12,873 DEBUG TRAIN Batch 54/900 loss 3.743740 loss_att 6.442183 loss_ctc 6.399893 loss_rnnt 2.688890 hw_loss 0.301887 lr 0.00028840 rank 4
2023-03-01 10:32:12,876 DEBUG TRAIN Batch 54/900 loss 5.978300 loss_att 8.657652 loss_ctc 8.577024 loss_rnnt 5.044946 hw_loss 0.095600 lr 0.00028840 rank 5
2023-03-01 10:32:12,886 DEBUG TRAIN Batch 54/900 loss 2.120485 loss_att 4.819333 loss_ctc 6.325355 loss_rnnt 0.938078 hw_loss 0.153727 lr 0.00028840 rank 7
2023-03-01 10:32:12,887 DEBUG TRAIN Batch 54/900 loss 3.547823 loss_att 7.242971 loss_ctc 6.678861 loss_rnnt 2.217319 hw_loss 0.326254 lr 0.00028840 rank 6
2023-03-01 10:32:12,893 DEBUG TRAIN Batch 54/900 loss 3.456197 loss_att 6.131395 loss_ctc 6.996752 loss_rnnt 2.343900 hw_loss 0.197219 lr 0.00028840 rank 0
2023-03-01 10:32:12,901 DEBUG TRAIN Batch 54/900 loss 2.454303 loss_att 4.287069 loss_ctc 3.562554 loss_rnnt 1.813993 hw_loss 0.236230 lr 0.00028839 rank 3
2023-03-01 10:32:12,909 DEBUG TRAIN Batch 54/900 loss 10.226294 loss_att 13.983389 loss_ctc 13.793311 loss_rnnt 8.934112 hw_loss 0.122177 lr 0.00028840 rank 2
2023-03-01 10:32:51,854 DEBUG TRAIN Batch 54/1000 loss 6.385461 loss_att 11.185423 loss_ctc 8.971107 loss_rnnt 5.013748 hw_loss 0.125566 lr 0.00028839 rank 4
2023-03-01 10:32:51,858 DEBUG TRAIN Batch 54/1000 loss 8.938222 loss_att 11.220570 loss_ctc 12.101797 loss_rnnt 7.947868 hw_loss 0.210140 lr 0.00028838 rank 1
2023-03-01 10:32:51,858 DEBUG TRAIN Batch 54/1000 loss 9.987854 loss_att 12.640844 loss_ctc 18.993973 loss_rnnt 8.179604 hw_loss 0.144068 lr 0.00028839 rank 2
2023-03-01 10:32:51,859 DEBUG TRAIN Batch 54/1000 loss 3.839424 loss_att 5.846970 loss_ctc 7.506382 loss_rnnt 2.905634 hw_loss 0.081288 lr 0.00028838 rank 3
2023-03-01 10:32:51,861 DEBUG TRAIN Batch 54/1000 loss 1.365928 loss_att 3.365146 loss_ctc 3.139154 loss_rnnt 0.692700 hw_loss 0.069290 lr 0.00028839 rank 0
2023-03-01 10:32:51,863 DEBUG TRAIN Batch 54/1000 loss 4.452816 loss_att 7.233988 loss_ctc 5.440248 loss_rnnt 3.719599 hw_loss 0.084986 lr 0.00028838 rank 7
2023-03-01 10:32:51,867 DEBUG TRAIN Batch 54/1000 loss 6.260043 loss_att 9.392294 loss_ctc 8.798275 loss_rnnt 5.162401 hw_loss 0.248927 lr 0.00028838 rank 5
2023-03-01 10:32:51,868 DEBUG TRAIN Batch 54/1000 loss 4.057561 loss_att 6.860027 loss_ctc 7.344793 loss_rnnt 2.969171 hw_loss 0.167999 lr 0.00028838 rank 6
2023-03-01 10:34:00,776 DEBUG TRAIN Batch 54/1100 loss 4.999461 loss_att 7.233701 loss_ctc 8.457500 loss_rnnt 3.952833 hw_loss 0.260078 lr 0.00028837 rank 1
2023-03-01 10:34:00,777 DEBUG TRAIN Batch 54/1100 loss 4.459942 loss_att 6.991824 loss_ctc 6.733799 loss_rnnt 3.569242 hw_loss 0.152143 lr 0.00028837 rank 4
2023-03-01 10:34:00,778 DEBUG TRAIN Batch 54/1100 loss 3.977422 loss_att 6.984169 loss_ctc 8.383527 loss_rnnt 2.561672 hw_loss 0.425476 lr 0.00028838 rank 0
2023-03-01 10:34:00,777 DEBUG TRAIN Batch 54/1100 loss 6.382140 loss_att 8.465537 loss_ctc 9.142550 loss_rnnt 5.471707 hw_loss 0.235683 lr 0.00028837 rank 3
2023-03-01 10:34:00,779 DEBUG TRAIN Batch 54/1100 loss 9.395181 loss_att 11.671298 loss_ctc 17.515219 loss_rnnt 7.724653 hw_loss 0.248687 lr 0.00028837 rank 7
2023-03-01 10:34:00,783 DEBUG TRAIN Batch 54/1100 loss 6.964508 loss_att 11.119966 loss_ctc 11.109493 loss_rnnt 5.528580 hw_loss 0.097821 lr 0.00028838 rank 2
2023-03-01 10:34:00,787 DEBUG TRAIN Batch 54/1100 loss 1.639347 loss_att 4.817982 loss_ctc 3.626876 loss_rnnt 0.602069 hw_loss 0.256025 lr 0.00028837 rank 5
2023-03-01 10:34:00,795 DEBUG TRAIN Batch 54/1100 loss 11.831811 loss_att 13.413061 loss_ctc 15.780503 loss_rnnt 10.869044 hw_loss 0.225046 lr 0.00028837 rank 6
2023-03-01 10:34:39,168 DEBUG TRAIN Batch 54/1200 loss 5.487378 loss_att 8.862930 loss_ctc 10.132729 loss_rnnt 4.077294 hw_loss 0.216736 lr 0.00028836 rank 2
2023-03-01 10:34:39,178 DEBUG TRAIN Batch 54/1200 loss 6.101948 loss_att 7.905700 loss_ctc 9.105641 loss_rnnt 5.242458 hw_loss 0.184213 lr 0.00028836 rank 7
2023-03-01 10:34:39,183 DEBUG TRAIN Batch 54/1200 loss 5.354839 loss_att 8.543697 loss_ctc 8.637397 loss_rnnt 4.087359 hw_loss 0.360063 lr 0.00028836 rank 3
2023-03-01 10:34:39,184 DEBUG TRAIN Batch 54/1200 loss 16.375797 loss_att 21.077005 loss_ctc 24.870617 loss_rnnt 14.151138 hw_loss 0.284575 lr 0.00028836 rank 6
2023-03-01 10:34:39,186 DEBUG TRAIN Batch 54/1200 loss 7.314476 loss_att 8.520239 loss_ctc 13.027690 loss_rnnt 6.111890 hw_loss 0.374384 lr 0.00028837 rank 0
2023-03-01 10:34:39,186 DEBUG TRAIN Batch 54/1200 loss 6.817891 loss_att 9.042950 loss_ctc 11.659982 loss_rnnt 5.644887 hw_loss 0.154462 lr 0.00028836 rank 4
2023-03-01 10:34:39,189 DEBUG TRAIN Batch 54/1200 loss 6.404917 loss_att 8.039327 loss_ctc 13.704000 loss_rnnt 4.978100 hw_loss 0.237608 lr 0.00028836 rank 5
2023-03-01 10:34:39,190 DEBUG TRAIN Batch 54/1200 loss 6.772387 loss_att 8.672441 loss_ctc 9.628158 loss_rnnt 5.849082 hw_loss 0.304732 lr 0.00028836 rank 1
2023-03-01 10:35:17,634 DEBUG TRAIN Batch 54/1300 loss 3.015779 loss_att 5.112997 loss_ctc 7.324378 loss_rnnt 1.904476 hw_loss 0.220086 lr 0.00028836 rank 0
2023-03-01 10:35:17,648 DEBUG TRAIN Batch 54/1300 loss 5.786582 loss_att 9.225878 loss_ctc 8.667574 loss_rnnt 4.593392 hw_loss 0.227247 lr 0.00028835 rank 7
2023-03-01 10:35:17,651 DEBUG TRAIN Batch 54/1300 loss 8.561306 loss_att 10.260515 loss_ctc 11.903943 loss_rnnt 7.582709 hw_loss 0.362006 lr 0.00028835 rank 6
2023-03-01 10:35:17,652 DEBUG TRAIN Batch 54/1300 loss 12.229483 loss_att 11.961386 loss_ctc 17.829702 loss_rnnt 11.393715 hw_loss 0.267547 lr 0.00028835 rank 1
2023-03-01 10:35:17,653 DEBUG TRAIN Batch 54/1300 loss 2.721241 loss_att 6.907493 loss_ctc 5.471178 loss_rnnt 1.414250 hw_loss 0.193278 lr 0.00028835 rank 5
2023-03-01 10:35:17,654 DEBUG TRAIN Batch 54/1300 loss 2.681920 loss_att 7.702150 loss_ctc 5.276592 loss_rnnt 1.298070 hw_loss 0.063466 lr 0.00028835 rank 4
2023-03-01 10:35:17,654 DEBUG TRAIN Batch 54/1300 loss 7.178850 loss_att 7.633036 loss_ctc 8.533808 loss_rnnt 6.679883 hw_loss 0.426503 lr 0.00028834 rank 3
2023-03-01 10:35:17,656 DEBUG TRAIN Batch 54/1300 loss 4.357922 loss_att 5.410622 loss_ctc 6.612541 loss_rnnt 3.675087 hw_loss 0.321898 lr 0.00028835 rank 2
2023-03-01 10:35:56,984 DEBUG TRAIN Batch 54/1400 loss 6.433647 loss_att 7.722396 loss_ctc 9.762389 loss_rnnt 5.584649 hw_loss 0.276405 lr 0.00028833 rank 3
2023-03-01 10:35:56,988 DEBUG TRAIN Batch 54/1400 loss 1.771202 loss_att 3.590755 loss_ctc 2.933172 loss_rnnt 1.198227 hw_loss 0.101504 lr 0.00028834 rank 6
2023-03-01 10:35:57,004 DEBUG TRAIN Batch 54/1400 loss 11.982453 loss_att 12.677103 loss_ctc 15.505005 loss_rnnt 11.227861 hw_loss 0.273726 lr 0.00028834 rank 4
2023-03-01 10:35:57,005 DEBUG TRAIN Batch 54/1400 loss 10.778698 loss_att 12.733060 loss_ctc 19.691725 loss_rnnt 9.129652 hw_loss 0.130817 lr 0.00028834 rank 0
2023-03-01 10:35:57,005 DEBUG TRAIN Batch 54/1400 loss 3.579463 loss_att 7.190504 loss_ctc 4.008059 loss_rnnt 2.696177 hw_loss 0.194872 lr 0.00028834 rank 5
2023-03-01 10:35:57,006 DEBUG TRAIN Batch 54/1400 loss 2.869548 loss_att 5.876637 loss_ctc 6.436624 loss_rnnt 1.727413 hw_loss 0.122076 lr 0.00028834 rank 7
2023-03-01 10:35:57,022 DEBUG TRAIN Batch 54/1400 loss 5.446367 loss_att 10.058622 loss_ctc 13.021261 loss_rnnt 3.392538 hw_loss 0.227610 lr 0.00028834 rank 2
2023-03-01 10:35:57,035 DEBUG TRAIN Batch 54/1400 loss 6.984637 loss_att 9.962475 loss_ctc 11.158423 loss_rnnt 5.748283 hw_loss 0.158027 lr 0.00028834 rank 1
2023-03-01 10:37:06,563 DEBUG TRAIN Batch 54/1500 loss 1.961363 loss_att 5.319296 loss_ctc 4.488583 loss_rnnt 0.885930 hw_loss 0.125408 lr 0.00028833 rank 2
2023-03-01 10:37:06,576 DEBUG TRAIN Batch 54/1500 loss 7.514968 loss_att 11.925331 loss_ctc 17.442167 loss_rnnt 5.251708 hw_loss 0.107927 lr 0.00028832 rank 5
2023-03-01 10:37:06,579 DEBUG TRAIN Batch 54/1500 loss 6.849566 loss_att 8.507170 loss_ctc 10.562669 loss_rnnt 5.965752 hw_loss 0.107276 lr 0.00028832 rank 7
2023-03-01 10:37:06,582 DEBUG TRAIN Batch 54/1500 loss 6.115744 loss_att 7.680867 loss_ctc 10.241742 loss_rnnt 5.105097 hw_loss 0.276543 lr 0.00028833 rank 0
2023-03-01 10:37:06,584 DEBUG TRAIN Batch 54/1500 loss 3.584602 loss_att 6.398458 loss_ctc 6.515647 loss_rnnt 2.517221 hw_loss 0.213382 lr 0.00028833 rank 4
2023-03-01 10:37:06,586 DEBUG TRAIN Batch 54/1500 loss 4.620766 loss_att 7.972026 loss_ctc 10.034792 loss_rnnt 3.069908 hw_loss 0.297630 lr 0.00028832 rank 1
2023-03-01 10:37:06,589 DEBUG TRAIN Batch 54/1500 loss 4.793130 loss_att 8.369596 loss_ctc 8.601087 loss_rnnt 3.492452 hw_loss 0.145609 lr 0.00028832 rank 3
2023-03-01 10:37:06,623 DEBUG TRAIN Batch 54/1500 loss 5.550082 loss_att 9.056929 loss_ctc 15.388556 loss_rnnt 3.468973 hw_loss 0.127393 lr 0.00028832 rank 6
2023-03-01 10:37:44,835 DEBUG TRAIN Batch 54/1600 loss 8.291403 loss_att 10.133998 loss_ctc 12.453892 loss_rnnt 7.333393 hw_loss 0.064673 lr 0.00028831 rank 5
2023-03-01 10:37:44,835 DEBUG TRAIN Batch 54/1600 loss 3.784365 loss_att 8.900730 loss_ctc 7.938735 loss_rnnt 2.117124 hw_loss 0.168847 lr 0.00028831 rank 4
2023-03-01 10:37:44,841 DEBUG TRAIN Batch 54/1600 loss 4.093124 loss_att 8.172832 loss_ctc 10.225594 loss_rnnt 2.384392 hw_loss 0.140866 lr 0.00028831 rank 3
2023-03-01 10:37:44,856 DEBUG TRAIN Batch 54/1600 loss 4.388202 loss_att 6.162341 loss_ctc 10.361263 loss_rnnt 3.163816 hw_loss 0.137157 lr 0.00028832 rank 0
2023-03-01 10:37:44,857 DEBUG TRAIN Batch 54/1600 loss 4.333794 loss_att 7.389680 loss_ctc 9.715258 loss_rnnt 2.850004 hw_loss 0.290784 lr 0.00028831 rank 7
2023-03-01 10:37:44,861 DEBUG TRAIN Batch 54/1600 loss 4.316519 loss_att 7.687784 loss_ctc 8.912545 loss_rnnt 2.888731 hw_loss 0.263871 lr 0.00028831 rank 6
2023-03-01 10:37:44,862 DEBUG TRAIN Batch 54/1600 loss 9.807394 loss_att 14.971853 loss_ctc 17.423565 loss_rnnt 7.701643 hw_loss 0.107570 lr 0.00028831 rank 1
2023-03-01 10:37:44,865 DEBUG TRAIN Batch 54/1600 loss 6.933753 loss_att 9.053807 loss_ctc 12.734127 loss_rnnt 5.657298 hw_loss 0.148238 lr 0.00028832 rank 2
2023-03-01 10:38:23,548 DEBUG TRAIN Batch 54/1700 loss 6.110086 loss_att 9.767609 loss_ctc 8.070992 loss_rnnt 5.007363 hw_loss 0.205809 lr 0.00028830 rank 1
2023-03-01 10:38:23,548 DEBUG TRAIN Batch 54/1700 loss 12.140241 loss_att 15.104262 loss_ctc 19.772585 loss_rnnt 10.374393 hw_loss 0.291371 lr 0.00028830 rank 6
2023-03-01 10:38:23,553 DEBUG TRAIN Batch 54/1700 loss 4.434834 loss_att 6.198360 loss_ctc 7.481588 loss_rnnt 3.559555 hw_loss 0.218135 lr 0.00028830 rank 5
2023-03-01 10:38:23,560 DEBUG TRAIN Batch 54/1700 loss 4.602608 loss_att 7.620537 loss_ctc 11.135382 loss_rnnt 3.024197 hw_loss 0.194603 lr 0.00028831 rank 0
2023-03-01 10:38:23,565 DEBUG TRAIN Batch 54/1700 loss 4.944207 loss_att 8.845583 loss_ctc 10.019813 loss_rnnt 3.385484 hw_loss 0.190687 lr 0.00028830 rank 7
2023-03-01 10:38:23,569 DEBUG TRAIN Batch 54/1700 loss 3.326039 loss_att 7.522967 loss_ctc 9.182997 loss_rnnt 1.575379 hw_loss 0.244401 lr 0.00028830 rank 2
2023-03-01 10:38:23,577 DEBUG TRAIN Batch 54/1700 loss 8.653055 loss_att 10.891218 loss_ctc 14.911114 loss_rnnt 7.304896 hw_loss 0.123972 lr 0.00028830 rank 3
2023-03-01 10:38:23,610 DEBUG TRAIN Batch 54/1700 loss 3.032633 loss_att 6.161983 loss_ctc 5.284304 loss_rnnt 2.004686 hw_loss 0.190976 lr 0.00028830 rank 4
2023-03-01 10:39:32,711 DEBUG TRAIN Batch 54/1800 loss 5.367917 loss_att 6.672308 loss_ctc 9.410934 loss_rnnt 4.525569 hw_loss 0.079500 lr 0.00028829 rank 6
2023-03-01 10:39:32,712 DEBUG TRAIN Batch 54/1800 loss 7.366273 loss_att 11.924501 loss_ctc 10.538950 loss_rnnt 5.895750 hw_loss 0.254727 lr 0.00028830 rank 0
2023-03-01 10:39:32,713 DEBUG TRAIN Batch 54/1800 loss 6.221599 loss_att 8.058317 loss_ctc 11.505050 loss_rnnt 5.038488 hw_loss 0.208700 lr 0.00028829 rank 7
2023-03-01 10:39:32,714 DEBUG TRAIN Batch 54/1800 loss 6.687144 loss_att 10.157450 loss_ctc 12.583272 loss_rnnt 5.106305 hw_loss 0.188677 lr 0.00028828 rank 3
2023-03-01 10:39:32,714 DEBUG TRAIN Batch 54/1800 loss 4.338932 loss_att 6.617046 loss_ctc 6.582961 loss_rnnt 3.419760 hw_loss 0.308148 lr 0.00028829 rank 1
2023-03-01 10:39:32,718 DEBUG TRAIN Batch 54/1800 loss 6.126652 loss_att 7.211452 loss_ctc 8.376884 loss_rnnt 5.571554 hw_loss 0.071450 lr 0.00028829 rank 2
2023-03-01 10:39:32,734 DEBUG TRAIN Batch 54/1800 loss 6.549010 loss_att 8.303432 loss_ctc 10.598948 loss_rnnt 5.610377 hw_loss 0.089544 lr 0.00028829 rank 5
2023-03-01 10:39:32,742 DEBUG TRAIN Batch 54/1800 loss 9.577310 loss_att 11.782674 loss_ctc 16.541092 loss_rnnt 8.160729 hw_loss 0.088132 lr 0.00028829 rank 4
2023-03-01 10:40:11,674 DEBUG TRAIN Batch 54/1900 loss 8.834930 loss_att 12.572044 loss_ctc 17.603844 loss_rnnt 6.812696 hw_loss 0.198042 lr 0.00028827 rank 3
2023-03-01 10:40:11,681 DEBUG TRAIN Batch 54/1900 loss 3.514116 loss_att 6.525958 loss_ctc 6.632126 loss_rnnt 2.458173 hw_loss 0.070949 lr 0.00028828 rank 7
2023-03-01 10:40:11,683 DEBUG TRAIN Batch 54/1900 loss 7.007172 loss_att 7.528761 loss_ctc 11.537321 loss_rnnt 6.210688 hw_loss 0.165272 lr 0.00028828 rank 6
2023-03-01 10:40:11,688 DEBUG TRAIN Batch 54/1900 loss 7.253566 loss_att 10.068252 loss_ctc 12.418310 loss_rnnt 5.816152 hw_loss 0.348458 lr 0.00028828 rank 0
2023-03-01 10:40:11,688 DEBUG TRAIN Batch 54/1900 loss 3.732623 loss_att 5.656699 loss_ctc 5.171050 loss_rnnt 3.004869 hw_loss 0.283402 lr 0.00028828 rank 2
2023-03-01 10:40:11,690 DEBUG TRAIN Batch 54/1900 loss 4.285041 loss_att 6.350651 loss_ctc 6.676651 loss_rnnt 3.430529 hw_loss 0.229704 lr 0.00028828 rank 1
2023-03-01 10:40:11,692 DEBUG TRAIN Batch 54/1900 loss 11.291100 loss_att 15.654822 loss_ctc 14.971231 loss_rnnt 9.749653 hw_loss 0.333784 lr 0.00028828 rank 5
2023-03-01 10:40:11,692 DEBUG TRAIN Batch 54/1900 loss 8.439569 loss_att 10.201484 loss_ctc 14.267177 loss_rnnt 7.175431 hw_loss 0.252637 lr 0.00028828 rank 4
2023-03-01 10:40:50,111 DEBUG TRAIN Batch 54/2000 loss 1.712819 loss_att 4.289243 loss_ctc 2.584851 loss_rnnt 0.965366 hw_loss 0.217308 lr 0.00028826 rank 1
2023-03-01 10:40:50,115 DEBUG TRAIN Batch 54/2000 loss 3.685149 loss_att 6.484112 loss_ctc 7.004458 loss_rnnt 2.489685 hw_loss 0.362057 lr 0.00028827 rank 2
2023-03-01 10:40:50,132 DEBUG TRAIN Batch 54/2000 loss 1.383660 loss_att 4.767767 loss_ctc 3.437505 loss_rnnt 0.339457 hw_loss 0.175380 lr 0.00028827 rank 0
2023-03-01 10:40:50,132 DEBUG TRAIN Batch 54/2000 loss 4.131815 loss_att 5.865485 loss_ctc 5.776577 loss_rnnt 3.461880 hw_loss 0.194811 lr 0.00028826 rank 5
2023-03-01 10:40:50,133 DEBUG TRAIN Batch 54/2000 loss 5.569869 loss_att 8.805893 loss_ctc 8.679766 loss_rnnt 4.396099 hw_loss 0.209833 lr 0.00028827 rank 4
2023-03-01 10:40:50,134 DEBUG TRAIN Batch 54/2000 loss 1.414131 loss_att 3.220835 loss_ctc 1.210759 loss_rnnt 0.931626 hw_loss 0.278024 lr 0.00028826 rank 6
2023-03-01 10:40:50,141 DEBUG TRAIN Batch 54/2000 loss 3.494550 loss_att 6.705567 loss_ctc 8.290701 loss_rnnt 2.079508 hw_loss 0.250034 lr 0.00028826 rank 7
2023-03-01 10:40:50,179 DEBUG TRAIN Batch 54/2000 loss 7.584647 loss_att 9.341700 loss_ctc 10.775825 loss_rnnt 6.706676 hw_loss 0.189506 lr 0.00028826 rank 3
2023-03-01 10:41:30,247 DEBUG TRAIN Batch 54/2100 loss 7.766849 loss_att 10.678083 loss_ctc 15.390671 loss_rnnt 5.995820 hw_loss 0.323008 lr 0.00028826 rank 2
2023-03-01 10:41:30,250 DEBUG TRAIN Batch 54/2100 loss 8.842790 loss_att 11.748428 loss_ctc 14.558029 loss_rnnt 7.422708 hw_loss 0.144229 lr 0.00028825 rank 7
2023-03-01 10:41:30,264 DEBUG TRAIN Batch 54/2100 loss 4.139075 loss_att 7.900234 loss_ctc 6.578641 loss_rnnt 2.999991 hw_loss 0.115455 lr 0.00028826 rank 0
2023-03-01 10:41:30,265 DEBUG TRAIN Batch 54/2100 loss 5.776273 loss_att 10.463390 loss_ctc 10.158978 loss_rnnt 4.218587 hw_loss 0.067315 lr 0.00028825 rank 1
2023-03-01 10:41:30,266 DEBUG TRAIN Batch 54/2100 loss 2.590568 loss_att 6.793383 loss_ctc 4.281007 loss_rnnt 1.365435 hw_loss 0.298461 lr 0.00028825 rank 4
2023-03-01 10:41:30,267 DEBUG TRAIN Batch 54/2100 loss 14.348965 loss_att 15.167800 loss_ctc 19.424362 loss_rnnt 13.460303 hw_loss 0.090327 lr 0.00028825 rank 6
2023-03-01 10:41:30,281 DEBUG TRAIN Batch 54/2100 loss 3.217397 loss_att 5.456665 loss_ctc 5.093425 loss_rnnt 2.388767 hw_loss 0.244949 lr 0.00028825 rank 5
2023-03-01 10:41:30,292 DEBUG TRAIN Batch 54/2100 loss 7.904777 loss_att 12.011856 loss_ctc 16.822884 loss_rnnt 5.792884 hw_loss 0.190118 lr 0.00028825 rank 3
2023-03-01 10:42:38,559 DEBUG TRAIN Batch 54/2200 loss 1.108919 loss_att 4.100685 loss_ctc 1.299648 loss_rnnt 0.348517 hw_loss 0.256159 lr 0.00028825 rank 2
2023-03-01 10:42:38,560 DEBUG TRAIN Batch 54/2200 loss 6.663194 loss_att 10.999368 loss_ctc 12.424036 loss_rnnt 4.872193 hw_loss 0.291850 lr 0.00028824 rank 5
2023-03-01 10:42:38,571 DEBUG TRAIN Batch 54/2200 loss 10.199493 loss_att 12.293783 loss_ctc 14.504264 loss_rnnt 9.047215 hw_loss 0.298971 lr 0.00028824 rank 4
2023-03-01 10:42:38,574 DEBUG TRAIN Batch 54/2200 loss 4.414556 loss_att 6.970891 loss_ctc 7.541584 loss_rnnt 3.388887 hw_loss 0.182745 lr 0.00028824 rank 3
2023-03-01 10:42:38,575 DEBUG TRAIN Batch 54/2200 loss 6.513428 loss_att 9.109358 loss_ctc 11.002113 loss_rnnt 5.324821 hw_loss 0.132993 lr 0.00028824 rank 7
2023-03-01 10:42:38,575 DEBUG TRAIN Batch 54/2200 loss 8.249067 loss_att 10.439610 loss_ctc 9.823495 loss_rnnt 7.522591 hw_loss 0.147082 lr 0.00028825 rank 0
2023-03-01 10:42:38,577 DEBUG TRAIN Batch 54/2200 loss 2.894989 loss_att 6.566373 loss_ctc 6.402725 loss_rnnt 1.578728 hw_loss 0.214286 lr 0.00028824 rank 6
2023-03-01 10:42:38,579 DEBUG TRAIN Batch 54/2200 loss 2.016401 loss_att 4.568833 loss_ctc 3.364073 loss_rnnt 1.122621 hw_loss 0.381757 lr 0.00028824 rank 1
2023-03-01 10:43:16,603 DEBUG TRAIN Batch 54/2300 loss 5.691206 loss_att 7.226927 loss_ctc 9.538162 loss_rnnt 4.807880 hw_loss 0.118599 lr 0.00028823 rank 7
2023-03-01 10:43:16,604 DEBUG TRAIN Batch 54/2300 loss 5.814610 loss_att 7.881577 loss_ctc 10.260359 loss_rnnt 4.750008 hw_loss 0.109579 lr 0.00028823 rank 6
2023-03-01 10:43:16,604 DEBUG TRAIN Batch 54/2300 loss 4.704388 loss_att 8.230505 loss_ctc 7.698437 loss_rnnt 3.502871 hw_loss 0.182039 lr 0.00028823 rank 2
2023-03-01 10:43:16,604 DEBUG TRAIN Batch 54/2300 loss 3.337378 loss_att 5.807371 loss_ctc 7.428516 loss_rnnt 2.169511 hw_loss 0.240718 lr 0.00028822 rank 3
2023-03-01 10:43:16,606 DEBUG TRAIN Batch 54/2300 loss 7.099419 loss_att 8.975757 loss_ctc 11.150841 loss_rnnt 6.014369 hw_loss 0.317987 lr 0.00028824 rank 0
2023-03-01 10:43:16,606 DEBUG TRAIN Batch 54/2300 loss 1.704395 loss_att 3.485719 loss_ctc 2.039096 loss_rnnt 1.202567 hw_loss 0.189256 lr 0.00028823 rank 1
2023-03-01 10:43:16,610 DEBUG TRAIN Batch 54/2300 loss 4.890492 loss_att 8.334859 loss_ctc 7.926661 loss_rnnt 3.708754 hw_loss 0.165080 lr 0.00028823 rank 4
2023-03-01 10:43:16,610 DEBUG TRAIN Batch 54/2300 loss 5.448205 loss_att 7.755577 loss_ctc 9.359566 loss_rnnt 4.299963 hw_loss 0.309846 lr 0.00028823 rank 5
2023-03-01 10:43:55,444 DEBUG TRAIN Batch 54/2400 loss 4.471859 loss_att 8.350352 loss_ctc 7.562781 loss_rnnt 3.246192 hw_loss 0.070960 lr 0.00028822 rank 0
2023-03-01 10:43:55,457 DEBUG TRAIN Batch 54/2400 loss 3.238045 loss_att 6.232543 loss_ctc 8.159872 loss_rnnt 1.897584 hw_loss 0.159972 lr 0.00028822 rank 7
2023-03-01 10:43:55,457 DEBUG TRAIN Batch 54/2400 loss 3.035085 loss_att 4.293112 loss_ctc 5.478055 loss_rnnt 2.277539 hw_loss 0.337895 lr 0.00028822 rank 5
2023-03-01 10:43:55,457 DEBUG TRAIN Batch 54/2400 loss 4.084399 loss_att 7.428204 loss_ctc 6.971333 loss_rnnt 2.941939 hw_loss 0.166451 lr 0.00028822 rank 6
2023-03-01 10:43:55,459 DEBUG TRAIN Batch 54/2400 loss 6.301812 loss_att 7.686176 loss_ctc 9.335054 loss_rnnt 5.567062 hw_loss 0.100208 lr 0.00028822 rank 2
2023-03-01 10:43:55,460 DEBUG TRAIN Batch 54/2400 loss 1.886756 loss_att 5.169466 loss_ctc 4.877190 loss_rnnt 0.757598 hw_loss 0.138547 lr 0.00028822 rank 1
2023-03-01 10:43:55,459 DEBUG TRAIN Batch 54/2400 loss 2.031599 loss_att 4.443302 loss_ctc 6.966805 loss_rnnt 0.764779 hw_loss 0.237096 lr 0.00028821 rank 3
2023-03-01 10:43:55,506 DEBUG TRAIN Batch 54/2400 loss 1.679012 loss_att 3.251792 loss_ctc 4.054728 loss_rnnt 0.981047 hw_loss 0.124962 lr 0.00028822 rank 4
2023-03-01 10:45:05,748 DEBUG TRAIN Batch 54/2500 loss 6.174176 loss_att 7.748618 loss_ctc 10.446150 loss_rnnt 5.183028 hw_loss 0.199993 lr 0.00028820 rank 1
2023-03-01 10:45:05,750 DEBUG TRAIN Batch 54/2500 loss 10.469501 loss_att 11.403131 loss_ctc 14.844644 loss_rnnt 9.586975 hw_loss 0.210836 lr 0.00028821 rank 2
2023-03-01 10:45:05,751 DEBUG TRAIN Batch 54/2500 loss 6.100084 loss_att 6.898912 loss_ctc 8.507227 loss_rnnt 5.443664 hw_loss 0.329440 lr 0.00028820 rank 7
2023-03-01 10:45:05,751 DEBUG TRAIN Batch 54/2500 loss 5.102369 loss_att 6.798904 loss_ctc 7.355266 loss_rnnt 4.359775 hw_loss 0.192941 lr 0.00028820 rank 6
2023-03-01 10:45:05,752 DEBUG TRAIN Batch 54/2500 loss 7.770499 loss_att 10.000372 loss_ctc 14.874083 loss_rnnt 6.265749 hw_loss 0.209308 lr 0.00028821 rank 0
2023-03-01 10:45:05,751 DEBUG TRAIN Batch 54/2500 loss 6.079749 loss_att 7.445830 loss_ctc 9.668647 loss_rnnt 5.185380 hw_loss 0.267435 lr 0.00028821 rank 4
2023-03-01 10:45:05,754 DEBUG TRAIN Batch 54/2500 loss 7.568599 loss_att 10.481783 loss_ctc 10.595352 loss_rnnt 6.411957 hw_loss 0.319573 lr 0.00028820 rank 3
2023-03-01 10:45:05,754 DEBUG TRAIN Batch 54/2500 loss 5.528415 loss_att 8.206432 loss_ctc 11.173368 loss_rnnt 4.122246 hw_loss 0.221071 lr 0.00028820 rank 5
2023-03-01 10:45:44,509 DEBUG TRAIN Batch 54/2600 loss 3.205293 loss_att 5.334057 loss_ctc 3.448714 loss_rnnt 2.597975 hw_loss 0.279579 lr 0.00028820 rank 0
2023-03-01 10:45:44,516 DEBUG TRAIN Batch 54/2600 loss 6.239006 loss_att 6.851442 loss_ctc 11.112313 loss_rnnt 5.287906 hw_loss 0.335322 lr 0.00028820 rank 2
2023-03-01 10:45:44,518 DEBUG TRAIN Batch 54/2600 loss 3.375895 loss_att 6.276502 loss_ctc 5.838178 loss_rnnt 2.359543 hw_loss 0.202360 lr 0.00028819 rank 7
2023-03-01 10:45:44,518 DEBUG TRAIN Batch 54/2600 loss 4.264802 loss_att 6.193556 loss_ctc 7.330741 loss_rnnt 3.379654 hw_loss 0.169886 lr 0.00028819 rank 3
2023-03-01 10:45:44,518 DEBUG TRAIN Batch 54/2600 loss 5.207263 loss_att 8.288788 loss_ctc 7.789096 loss_rnnt 4.142494 hw_loss 0.195413 lr 0.00028819 rank 4
2023-03-01 10:45:44,521 DEBUG TRAIN Batch 54/2600 loss 1.816207 loss_att 4.979184 loss_ctc 4.133428 loss_rnnt 0.716011 hw_loss 0.297446 lr 0.00028819 rank 5
2023-03-01 10:45:44,528 DEBUG TRAIN Batch 54/2600 loss 7.532115 loss_att 11.670523 loss_ctc 14.455679 loss_rnnt 5.708238 hw_loss 0.136975 lr 0.00028819 rank 6
2023-03-01 10:45:44,529 DEBUG TRAIN Batch 54/2600 loss 10.949538 loss_att 12.477228 loss_ctc 16.736122 loss_rnnt 9.704607 hw_loss 0.314717 lr 0.00028819 rank 1
2023-03-01 10:46:23,215 DEBUG TRAIN Batch 54/2700 loss 0.853842 loss_att 2.658725 loss_ctc 1.379817 loss_rnnt 0.319756 hw_loss 0.193085 lr 0.00028818 rank 1
2023-03-01 10:46:23,215 DEBUG TRAIN Batch 54/2700 loss 2.303994 loss_att 4.799326 loss_ctc 2.560311 loss_rnnt 1.696533 hw_loss 0.139161 lr 0.00028818 rank 5
2023-03-01 10:46:23,218 DEBUG TRAIN Batch 54/2700 loss 9.182898 loss_att 11.718462 loss_ctc 15.822369 loss_rnnt 7.718349 hw_loss 0.135324 lr 0.00028818 rank 4
2023-03-01 10:46:23,223 DEBUG TRAIN Batch 54/2700 loss 3.853557 loss_att 6.981313 loss_ctc 7.733491 loss_rnnt 2.710264 hw_loss 0.000783 lr 0.00028819 rank 2
2023-03-01 10:46:23,234 DEBUG TRAIN Batch 54/2700 loss 6.688964 loss_att 12.429722 loss_ctc 11.486002 loss_rnnt 4.804204 hw_loss 0.181879 lr 0.00028818 rank 7
2023-03-01 10:46:23,235 DEBUG TRAIN Batch 54/2700 loss 9.261410 loss_att 16.249615 loss_ctc 19.780333 loss_rnnt 6.391283 hw_loss 0.131177 lr 0.00028819 rank 0
2023-03-01 10:46:23,236 DEBUG TRAIN Batch 54/2700 loss 4.871854 loss_att 7.594996 loss_ctc 8.939850 loss_rnnt 3.652009 hw_loss 0.249033 lr 0.00028818 rank 6
2023-03-01 10:46:23,245 DEBUG TRAIN Batch 54/2700 loss 6.462973 loss_att 7.960863 loss_ctc 9.378691 loss_rnnt 5.643298 hw_loss 0.246252 lr 0.00028818 rank 3
2023-03-01 10:47:03,148 DEBUG TRAIN Batch 54/2800 loss 15.081273 loss_att 17.129091 loss_ctc 22.078613 loss_rnnt 13.692931 hw_loss 0.085874 lr 0.00028817 rank 2
2023-03-01 10:47:03,149 DEBUG TRAIN Batch 54/2800 loss 3.992057 loss_att 7.105506 loss_ctc 4.192366 loss_rnnt 3.253937 hw_loss 0.166356 lr 0.00028817 rank 7
2023-03-01 10:47:03,149 DEBUG TRAIN Batch 54/2800 loss 9.050086 loss_att 14.115897 loss_ctc 13.299229 loss_rnnt 7.374897 hw_loss 0.179013 lr 0.00028817 rank 4
2023-03-01 10:47:03,150 DEBUG TRAIN Batch 54/2800 loss 7.913805 loss_att 9.853382 loss_ctc 12.894076 loss_rnnt 6.748562 hw_loss 0.212422 lr 0.00028817 rank 1
2023-03-01 10:47:03,152 DEBUG TRAIN Batch 54/2800 loss 3.982134 loss_att 7.600245 loss_ctc 10.247332 loss_rnnt 2.369929 hw_loss 0.099792 lr 0.00028817 rank 6
2023-03-01 10:47:03,153 DEBUG TRAIN Batch 54/2800 loss 2.048433 loss_att 4.853103 loss_ctc 3.536072 loss_rnnt 1.193050 hw_loss 0.180183 lr 0.00028818 rank 0
2023-03-01 10:47:03,153 DEBUG TRAIN Batch 54/2800 loss 2.294026 loss_att 6.518497 loss_ctc 5.238006 loss_rnnt 0.876061 hw_loss 0.338512 lr 0.00028816 rank 3
2023-03-01 10:47:03,172 DEBUG TRAIN Batch 54/2800 loss 8.875278 loss_att 12.603666 loss_ctc 11.790897 loss_rnnt 7.669642 hw_loss 0.133517 lr 0.00028817 rank 5
2023-03-01 10:48:11,338 DEBUG TRAIN Batch 54/2900 loss 7.236825 loss_att 10.670764 loss_ctc 11.471835 loss_rnnt 5.884785 hw_loss 0.188595 lr 0.00028815 rank 3
2023-03-01 10:48:11,350 DEBUG TRAIN Batch 54/2900 loss 2.482843 loss_att 5.335006 loss_ctc 5.775863 loss_rnnt 1.423756 hw_loss 0.092972 lr 0.00028816 rank 1
2023-03-01 10:48:11,350 DEBUG TRAIN Batch 54/2900 loss 10.306444 loss_att 10.972832 loss_ctc 16.019093 loss_rnnt 9.361825 hw_loss 0.093101 lr 0.00028816 rank 4
2023-03-01 10:48:11,351 DEBUG TRAIN Batch 54/2900 loss 5.220535 loss_att 7.409286 loss_ctc 10.100861 loss_rnnt 3.972602 hw_loss 0.299012 lr 0.00028816 rank 0
2023-03-01 10:48:11,352 DEBUG TRAIN Batch 54/2900 loss 8.135857 loss_att 9.934344 loss_ctc 12.299792 loss_rnnt 7.059549 hw_loss 0.302661 lr 0.00028816 rank 7
2023-03-01 10:48:11,352 DEBUG TRAIN Batch 54/2900 loss 7.910498 loss_att 11.684986 loss_ctc 14.656479 loss_rnnt 6.182161 hw_loss 0.138702 lr 0.00028816 rank 5
2023-03-01 10:48:11,353 DEBUG TRAIN Batch 54/2900 loss 2.856966 loss_att 4.099636 loss_ctc 4.278196 loss_rnnt 2.311660 hw_loss 0.201141 lr 0.00028816 rank 2
2023-03-01 10:48:11,356 DEBUG TRAIN Batch 54/2900 loss 6.021211 loss_att 7.899300 loss_ctc 13.126822 loss_rnnt 4.621572 hw_loss 0.143638 lr 0.00028816 rank 6
2023-03-01 10:48:49,955 DEBUG TRAIN Batch 54/3000 loss 4.358022 loss_att 8.512845 loss_ctc 7.929316 loss_rnnt 2.966012 hw_loss 0.159136 lr 0.00028815 rank 0
2023-03-01 10:48:49,955 DEBUG TRAIN Batch 54/3000 loss 7.166045 loss_att 10.126545 loss_ctc 13.006876 loss_rnnt 5.729776 hw_loss 0.122606 lr 0.00028814 rank 7
2023-03-01 10:48:49,961 DEBUG TRAIN Batch 54/3000 loss 6.076692 loss_att 9.103823 loss_ctc 7.973973 loss_rnnt 5.073889 hw_loss 0.270762 lr 0.00028815 rank 4
2023-03-01 10:48:49,961 DEBUG TRAIN Batch 54/3000 loss 9.647797 loss_att 12.325584 loss_ctc 13.516027 loss_rnnt 8.442332 hw_loss 0.289017 lr 0.00028814 rank 1
2023-03-01 10:48:49,961 DEBUG TRAIN Batch 54/3000 loss 8.750580 loss_att 9.924240 loss_ctc 14.174286 loss_rnnt 7.675017 hw_loss 0.220633 lr 0.00028814 rank 5
2023-03-01 10:48:49,964 DEBUG TRAIN Batch 54/3000 loss 2.733851 loss_att 5.664385 loss_ctc 5.620024 loss_rnnt 1.651342 hw_loss 0.209211 lr 0.00028814 rank 3
2023-03-01 10:48:49,967 DEBUG TRAIN Batch 54/3000 loss 4.823876 loss_att 7.009572 loss_ctc 9.691834 loss_rnnt 3.606811 hw_loss 0.245373 lr 0.00028815 rank 2
2023-03-01 10:48:49,969 DEBUG TRAIN Batch 54/3000 loss 4.888455 loss_att 7.568181 loss_ctc 10.406194 loss_rnnt 3.567582 hw_loss 0.092307 lr 0.00028814 rank 6
2023-03-01 10:49:29,704 DEBUG TRAIN Batch 54/3100 loss 8.055182 loss_att 11.268875 loss_ctc 12.044605 loss_rnnt 6.707548 hw_loss 0.324325 lr 0.00028813 rank 4
2023-03-01 10:49:29,713 DEBUG TRAIN Batch 54/3100 loss 7.077878 loss_att 8.629846 loss_ctc 10.636149 loss_rnnt 6.116233 hw_loss 0.331531 lr 0.00028814 rank 0
2023-03-01 10:49:29,715 DEBUG TRAIN Batch 54/3100 loss 5.825038 loss_att 7.709385 loss_ctc 8.434006 loss_rnnt 4.983802 hw_loss 0.218446 lr 0.00028813 rank 7
2023-03-01 10:49:29,717 DEBUG TRAIN Batch 54/3100 loss 3.306268 loss_att 5.457356 loss_ctc 5.903266 loss_rnnt 2.313803 hw_loss 0.404965 lr 0.00028814 rank 2
2023-03-01 10:49:29,719 DEBUG TRAIN Batch 54/3100 loss 4.626424 loss_att 8.111669 loss_ctc 9.808424 loss_rnnt 3.145639 hw_loss 0.174005 lr 0.00028813 rank 3
2023-03-01 10:49:29,719 DEBUG TRAIN Batch 54/3100 loss 3.714653 loss_att 5.483009 loss_ctc 6.360536 loss_rnnt 2.901763 hw_loss 0.199566 lr 0.00028813 rank 5
2023-03-01 10:49:29,751 DEBUG TRAIN Batch 54/3100 loss 7.040380 loss_att 8.969570 loss_ctc 7.450348 loss_rnnt 6.417438 hw_loss 0.342080 lr 0.00028813 rank 6
2023-03-01 10:49:29,788 DEBUG TRAIN Batch 54/3100 loss 6.770401 loss_att 9.277863 loss_ctc 10.060975 loss_rnnt 5.724806 hw_loss 0.197551 lr 0.00028813 rank 1
2023-03-01 10:50:38,919 DEBUG TRAIN Batch 54/3200 loss 4.537208 loss_att 4.655009 loss_ctc 6.746223 loss_rnnt 4.044782 hw_loss 0.326868 lr 0.00028812 rank 4
2023-03-01 10:50:38,921 DEBUG TRAIN Batch 54/3200 loss 4.931040 loss_att 5.888443 loss_ctc 7.991870 loss_rnnt 4.257871 hw_loss 0.137959 lr 0.00028813 rank 2
2023-03-01 10:50:38,924 DEBUG TRAIN Batch 54/3200 loss 4.565875 loss_att 7.841941 loss_ctc 8.878267 loss_rnnt 3.264500 hw_loss 0.133456 lr 0.00028813 rank 0
2023-03-01 10:50:38,924 DEBUG TRAIN Batch 54/3200 loss 3.056818 loss_att 5.026152 loss_ctc 5.173551 loss_rnnt 2.273651 hw_loss 0.200755 lr 0.00028812 rank 7
2023-03-01 10:50:38,926 DEBUG TRAIN Batch 54/3200 loss 2.928253 loss_att 6.380280 loss_ctc 4.928422 loss_rnnt 1.872488 hw_loss 0.185009 lr 0.00028812 rank 1
2023-03-01 10:50:38,929 DEBUG TRAIN Batch 54/3200 loss 9.475661 loss_att 10.403625 loss_ctc 15.316795 loss_rnnt 8.357485 hw_loss 0.288311 lr 0.00028812 rank 3
2023-03-01 10:50:38,930 DEBUG TRAIN Batch 54/3200 loss 5.020807 loss_att 5.927842 loss_ctc 8.424769 loss_rnnt 4.213642 hw_loss 0.322307 lr 0.00028812 rank 6
2023-03-01 10:50:38,931 DEBUG TRAIN Batch 54/3200 loss 1.595739 loss_att 4.496830 loss_ctc 3.042365 loss_rnnt 0.772247 hw_loss 0.094482 lr 0.00028812 rank 5
2023-03-01 10:51:18,101 DEBUG TRAIN Batch 54/3300 loss 5.554615 loss_att 8.400990 loss_ctc 11.545544 loss_rnnt 4.073520 hw_loss 0.211931 lr 0.00028811 rank 4
2023-03-01 10:51:18,117 DEBUG TRAIN Batch 54/3300 loss 9.340521 loss_att 9.183262 loss_ctc 12.213449 loss_rnnt 8.840568 hw_loss 0.278154 lr 0.00028811 rank 1
2023-03-01 10:51:18,119 DEBUG TRAIN Batch 54/3300 loss 2.505565 loss_att 4.730882 loss_ctc 6.284529 loss_rnnt 1.452683 hw_loss 0.194918 lr 0.00028811 rank 5
2023-03-01 10:51:18,119 DEBUG TRAIN Batch 54/3300 loss 10.898259 loss_att 15.194161 loss_ctc 19.847740 loss_rnnt 8.772215 hw_loss 0.138000 lr 0.00028812 rank 0
2023-03-01 10:51:18,121 DEBUG TRAIN Batch 54/3300 loss 8.540393 loss_att 10.396267 loss_ctc 12.527115 loss_rnnt 7.612194 hw_loss 0.047739 lr 0.00028811 rank 7
2023-03-01 10:51:18,127 DEBUG TRAIN Batch 54/3300 loss 3.348273 loss_att 8.562595 loss_ctc 9.579597 loss_rnnt 1.339860 hw_loss 0.252572 lr 0.00028811 rank 2
2023-03-01 10:51:18,127 DEBUG TRAIN Batch 54/3300 loss 8.718701 loss_att 13.526051 loss_ctc 8.739903 loss_rnnt 7.688369 hw_loss 0.123817 lr 0.00028810 rank 3
2023-03-01 10:51:18,128 DEBUG TRAIN Batch 54/3300 loss 10.288909 loss_att 13.752319 loss_ctc 14.130417 loss_rnnt 8.879184 hw_loss 0.384079 lr 0.00028811 rank 6
2023-03-01 10:51:57,188 DEBUG TRAIN Batch 54/3400 loss 7.513493 loss_att 8.639316 loss_ctc 10.728072 loss_rnnt 6.702416 hw_loss 0.294938 lr 0.00028810 rank 6
2023-03-01 10:51:57,204 DEBUG TRAIN Batch 54/3400 loss 5.327802 loss_att 7.790665 loss_ctc 7.288239 loss_rnnt 4.487723 hw_loss 0.161466 lr 0.00028810 rank 7
2023-03-01 10:51:57,206 DEBUG TRAIN Batch 54/3400 loss 3.779559 loss_att 5.538589 loss_ctc 5.373434 loss_rnnt 3.139308 hw_loss 0.142364 lr 0.00028810 rank 4
2023-03-01 10:51:57,207 DEBUG TRAIN Batch 54/3400 loss 2.279895 loss_att 4.560173 loss_ctc 5.148572 loss_rnnt 1.270191 hw_loss 0.320922 lr 0.00028810 rank 0
2023-03-01 10:51:57,207 DEBUG TRAIN Batch 54/3400 loss 7.242701 loss_att 8.760242 loss_ctc 10.496717 loss_rnnt 6.339031 hw_loss 0.311799 lr 0.00028810 rank 5
2023-03-01 10:51:57,211 DEBUG TRAIN Batch 54/3400 loss 1.957929 loss_att 4.151883 loss_ctc 3.279151 loss_rnnt 1.283381 hw_loss 0.111737 lr 0.00028810 rank 1
2023-03-01 10:51:57,214 DEBUG TRAIN Batch 54/3400 loss 5.072310 loss_att 8.795337 loss_ctc 7.633343 loss_rnnt 3.856723 hw_loss 0.242835 lr 0.00028809 rank 3
2023-03-01 10:51:57,231 DEBUG TRAIN Batch 54/3400 loss 5.839501 loss_att 8.658206 loss_ctc 8.364046 loss_rnnt 4.808525 hw_loss 0.244930 lr 0.00028810 rank 2
2023-03-01 10:52:36,679 DEBUG TRAIN Batch 54/3500 loss 5.325530 loss_att 9.760980 loss_ctc 7.969239 loss_rnnt 3.915713 hw_loss 0.319185 lr 0.00028809 rank 5
2023-03-01 10:52:36,680 DEBUG TRAIN Batch 54/3500 loss 5.429600 loss_att 9.372600 loss_ctc 8.761839 loss_rnnt 4.094773 hw_loss 0.191116 lr 0.00028808 rank 1
2023-03-01 10:52:36,683 DEBUG TRAIN Batch 54/3500 loss 6.233920 loss_att 11.801555 loss_ctc 9.981544 loss_rnnt 4.530584 hw_loss 0.168985 lr 0.00028809 rank 0
2023-03-01 10:52:36,684 DEBUG TRAIN Batch 54/3500 loss 5.392986 loss_att 9.211382 loss_ctc 9.900098 loss_rnnt 3.954917 hw_loss 0.137702 lr 0.00028809 rank 6
2023-03-01 10:52:36,684 DEBUG TRAIN Batch 54/3500 loss 11.135973 loss_att 12.727058 loss_ctc 14.620787 loss_rnnt 10.261386 hw_loss 0.171990 lr 0.00028808 rank 7
2023-03-01 10:52:36,685 DEBUG TRAIN Batch 54/3500 loss 9.721225 loss_att 12.270043 loss_ctc 14.940760 loss_rnnt 8.409805 hw_loss 0.198221 lr 0.00028809 rank 4
2023-03-01 10:52:36,687 DEBUG TRAIN Batch 54/3500 loss 7.642092 loss_att 10.961875 loss_ctc 12.907194 loss_rnnt 6.179332 hw_loss 0.181481 lr 0.00028808 rank 3
2023-03-01 10:52:36,696 DEBUG TRAIN Batch 54/3500 loss 8.084640 loss_att 10.658257 loss_ctc 14.559388 loss_rnnt 6.620460 hw_loss 0.161546 lr 0.00028809 rank 2
2023-03-01 10:53:48,441 DEBUG TRAIN Batch 54/3600 loss 6.108445 loss_att 9.852111 loss_ctc 8.395168 loss_rnnt 4.935529 hw_loss 0.223663 lr 0.00028807 rank 1
2023-03-01 10:53:48,447 DEBUG TRAIN Batch 54/3600 loss 7.350104 loss_att 8.608439 loss_ctc 12.279918 loss_rnnt 6.322774 hw_loss 0.221912 lr 0.00028807 rank 4
2023-03-01 10:53:48,454 DEBUG TRAIN Batch 54/3600 loss 8.472195 loss_att 10.567692 loss_ctc 12.424443 loss_rnnt 7.446975 hw_loss 0.148413 lr 0.00028807 rank 7
2023-03-01 10:53:48,455 DEBUG TRAIN Batch 54/3600 loss 2.891744 loss_att 6.273160 loss_ctc 3.399975 loss_rnnt 2.083562 hw_loss 0.120252 lr 0.00028807 rank 5
2023-03-01 10:53:48,459 DEBUG TRAIN Batch 54/3600 loss 11.819774 loss_att 16.146866 loss_ctc 21.807667 loss_rnnt 9.494788 hw_loss 0.239712 lr 0.00028808 rank 0
2023-03-01 10:53:48,466 DEBUG TRAIN Batch 54/3600 loss 2.368511 loss_att 6.187009 loss_ctc 6.508756 loss_rnnt 0.956195 hw_loss 0.181095 lr 0.00028807 rank 3
2023-03-01 10:53:48,468 DEBUG TRAIN Batch 54/3600 loss 9.047645 loss_att 10.462614 loss_ctc 15.508753 loss_rnnt 7.874216 hw_loss 0.054291 lr 0.00028807 rank 6
2023-03-01 10:53:48,475 DEBUG TRAIN Batch 54/3600 loss 6.296927 loss_att 10.168890 loss_ctc 11.027171 loss_rnnt 4.874650 hw_loss 0.032223 lr 0.00028808 rank 2
2023-03-01 10:54:27,517 DEBUG TRAIN Batch 54/3700 loss 6.451991 loss_att 10.725458 loss_ctc 16.199682 loss_rnnt 4.212241 hw_loss 0.160058 lr 0.00028806 rank 6
2023-03-01 10:54:27,521 DEBUG TRAIN Batch 54/3700 loss 8.128551 loss_att 9.611284 loss_ctc 14.722612 loss_rnnt 6.822865 hw_loss 0.243620 lr 0.00028806 rank 1
2023-03-01 10:54:27,523 DEBUG TRAIN Batch 54/3700 loss 6.896534 loss_att 7.458388 loss_ctc 9.445018 loss_rnnt 6.272454 hw_loss 0.322332 lr 0.00028806 rank 7
2023-03-01 10:54:27,529 DEBUG TRAIN Batch 54/3700 loss 5.745341 loss_att 6.732269 loss_ctc 10.045524 loss_rnnt 4.877130 hw_loss 0.182751 lr 0.00028806 rank 5
2023-03-01 10:54:27,530 DEBUG TRAIN Batch 54/3700 loss 4.465072 loss_att 6.391039 loss_ctc 7.077621 loss_rnnt 3.568022 hw_loss 0.306593 lr 0.00028807 rank 0
2023-03-01 10:54:27,533 DEBUG TRAIN Batch 54/3700 loss 2.468725 loss_att 5.518860 loss_ctc 7.426851 loss_rnnt 1.130434 hw_loss 0.125963 lr 0.00028807 rank 2
2023-03-01 10:54:27,537 DEBUG TRAIN Batch 54/3700 loss 3.952479 loss_att 6.051250 loss_ctc 5.277417 loss_rnnt 3.256024 hw_loss 0.187579 lr 0.00028806 rank 4
2023-03-01 10:54:27,546 DEBUG TRAIN Batch 54/3700 loss 3.646012 loss_att 6.423751 loss_ctc 4.559055 loss_rnnt 2.863405 hw_loss 0.197475 lr 0.00028806 rank 3
2023-03-01 10:55:06,825 DEBUG TRAIN Batch 54/3800 loss 5.016685 loss_att 8.470775 loss_ctc 7.743598 loss_rnnt 3.798772 hw_loss 0.306575 lr 0.00028805 rank 5
2023-03-01 10:55:06,833 DEBUG TRAIN Batch 54/3800 loss 5.216840 loss_att 7.559943 loss_ctc 9.706600 loss_rnnt 4.039762 hw_loss 0.205915 lr 0.00028805 rank 7
2023-03-01 10:55:06,836 DEBUG TRAIN Batch 54/3800 loss 5.282117 loss_att 7.173571 loss_ctc 6.496995 loss_rnnt 4.710643 hw_loss 0.058498 lr 0.00028806 rank 0
2023-03-01 10:55:06,840 DEBUG TRAIN Batch 54/3800 loss 6.803933 loss_att 9.804555 loss_ctc 12.264582 loss_rnnt 5.367507 hw_loss 0.202904 lr 0.00028805 rank 6
2023-03-01 10:55:06,842 DEBUG TRAIN Batch 54/3800 loss 5.819248 loss_att 6.688585 loss_ctc 9.114658 loss_rnnt 5.108202 hw_loss 0.183357 lr 0.00028805 rank 2
2023-03-01 10:55:06,844 DEBUG TRAIN Batch 54/3800 loss 6.768638 loss_att 7.622897 loss_ctc 9.815754 loss_rnnt 5.979966 hw_loss 0.396632 lr 0.00028805 rank 4
2023-03-01 10:55:06,857 DEBUG TRAIN Batch 54/3800 loss 3.387572 loss_att 6.618615 loss_ctc 8.816235 loss_rnnt 1.873650 hw_loss 0.269797 lr 0.00028805 rank 1
2023-03-01 10:55:06,870 DEBUG TRAIN Batch 54/3800 loss 2.350625 loss_att 5.567218 loss_ctc 4.805890 loss_rnnt 1.292188 hw_loss 0.164531 lr 0.00028804 rank 3
2023-03-01 10:56:13,035 DEBUG TRAIN Batch 54/3900 loss 4.112238 loss_att 7.634392 loss_ctc 6.259676 loss_rnnt 2.994554 hw_loss 0.237990 lr 0.00028804 rank 4
2023-03-01 10:56:13,045 DEBUG TRAIN Batch 54/3900 loss 3.938525 loss_att 5.965676 loss_ctc 5.340423 loss_rnnt 3.192867 hw_loss 0.287454 lr 0.00028804 rank 5
2023-03-01 10:56:13,053 DEBUG TRAIN Batch 54/3900 loss 10.812113 loss_att 15.515919 loss_ctc 19.247387 loss_rnnt 8.688372 hw_loss 0.109269 lr 0.00028804 rank 0
2023-03-01 10:56:13,056 DEBUG TRAIN Batch 54/3900 loss 4.264109 loss_att 7.349524 loss_ctc 6.590787 loss_rnnt 3.163647 hw_loss 0.324666 lr 0.00028804 rank 1
2023-03-01 10:56:13,056 DEBUG TRAIN Batch 54/3900 loss 5.745416 loss_att 8.010537 loss_ctc 8.588818 loss_rnnt 4.798244 hw_loss 0.215679 lr 0.00028804 rank 2
2023-03-01 10:56:13,057 DEBUG TRAIN Batch 54/3900 loss 11.286121 loss_att 12.974901 loss_ctc 17.112513 loss_rnnt 10.025371 hw_loss 0.274017 lr 0.00028803 rank 3
2023-03-01 10:56:13,059 DEBUG TRAIN Batch 54/3900 loss 7.706828 loss_att 8.275508 loss_ctc 11.770588 loss_rnnt 6.937195 hw_loss 0.213866 lr 0.00028804 rank 7
2023-03-01 10:56:13,065 DEBUG TRAIN Batch 54/3900 loss 1.608876 loss_att 3.807032 loss_ctc 1.940744 loss_rnnt 0.991348 hw_loss 0.250590 lr 0.00028804 rank 6
2023-03-01 10:56:56,797 DEBUG TRAIN Batch 54/4000 loss 6.301336 loss_att 9.959641 loss_ctc 8.921538 loss_rnnt 5.116367 hw_loss 0.194903 lr 0.00028803 rank 5
2023-03-01 10:56:56,803 DEBUG TRAIN Batch 54/4000 loss 5.140646 loss_att 9.152013 loss_ctc 10.178974 loss_rnnt 3.550537 hw_loss 0.217611 lr 0.00028803 rank 4
2023-03-01 10:56:56,804 DEBUG TRAIN Batch 54/4000 loss 13.415034 loss_att 19.012051 loss_ctc 18.937298 loss_rnnt 11.433519 hw_loss 0.235891 lr 0.00028803 rank 6
2023-03-01 10:56:56,814 DEBUG TRAIN Batch 54/4000 loss 2.969929 loss_att 5.820330 loss_ctc 7.037691 loss_rnnt 1.689376 hw_loss 0.315197 lr 0.00028803 rank 0
2023-03-01 10:56:56,821 DEBUG TRAIN Batch 54/4000 loss 3.870488 loss_att 7.692136 loss_ctc 6.991333 loss_rnnt 2.611174 hw_loss 0.147885 lr 0.00028803 rank 2
2023-03-01 10:56:56,823 DEBUG TRAIN Batch 54/4000 loss 2.680789 loss_att 7.340539 loss_ctc 4.858267 loss_rnnt 1.364836 hw_loss 0.175637 lr 0.00028802 rank 7
2023-03-01 10:56:56,824 DEBUG TRAIN Batch 54/4000 loss 10.365915 loss_att 13.014523 loss_ctc 16.330870 loss_rnnt 8.906637 hw_loss 0.251680 lr 0.00028802 rank 1
2023-03-01 10:56:56,841 DEBUG TRAIN Batch 54/4000 loss 7.327151 loss_att 10.504232 loss_ctc 12.691906 loss_rnnt 5.910089 hw_loss 0.124397 lr 0.00028802 rank 3
2023-03-01 10:57:35,930 DEBUG TRAIN Batch 54/4100 loss 3.127096 loss_att 5.874581 loss_ctc 7.721036 loss_rnnt 1.909202 hw_loss 0.104759 lr 0.00028802 rank 0
2023-03-01 10:57:35,931 DEBUG TRAIN Batch 54/4100 loss 10.715787 loss_att 15.104951 loss_ctc 16.863382 loss_rnnt 8.956193 hw_loss 0.116404 lr 0.00028801 rank 5
2023-03-01 10:57:35,932 DEBUG TRAIN Batch 54/4100 loss 4.383217 loss_att 8.206876 loss_ctc 7.636936 loss_rnnt 3.120272 hw_loss 0.120721 lr 0.00028801 rank 7
2023-03-01 10:57:35,934 DEBUG TRAIN Batch 54/4100 loss 3.287908 loss_att 6.599451 loss_ctc 6.218375 loss_rnnt 2.190589 hw_loss 0.083027 lr 0.00028801 rank 4
2023-03-01 10:57:35,935 DEBUG TRAIN Batch 54/4100 loss 4.405551 loss_att 6.499977 loss_ctc 7.039110 loss_rnnt 3.509161 hw_loss 0.236931 lr 0.00028801 rank 6
2023-03-01 10:57:35,936 DEBUG TRAIN Batch 54/4100 loss 2.548646 loss_att 5.242168 loss_ctc 3.782779 loss_rnnt 1.760683 hw_loss 0.158827 lr 0.00028801 rank 1
2023-03-01 10:57:35,937 DEBUG TRAIN Batch 54/4100 loss 5.836159 loss_att 9.656640 loss_ctc 19.713181 loss_rnnt 3.108294 hw_loss 0.212811 lr 0.00028801 rank 3
2023-03-01 10:57:35,946 DEBUG TRAIN Batch 54/4100 loss 3.203915 loss_att 6.176798 loss_ctc 4.290533 loss_rnnt 2.324034 hw_loss 0.263291 lr 0.00028802 rank 2
2023-03-01 10:58:15,256 DEBUG TRAIN Batch 54/4200 loss 9.634665 loss_att 12.924702 loss_ctc 16.079355 loss_rnnt 8.051392 hw_loss 0.123701 lr 0.00028800 rank 6
2023-03-01 10:58:15,256 DEBUG TRAIN Batch 54/4200 loss 4.836926 loss_att 8.238417 loss_ctc 9.522016 loss_rnnt 3.432027 hw_loss 0.187354 lr 0.00028800 rank 7
2023-03-01 10:58:15,258 DEBUG TRAIN Batch 54/4200 loss 6.790943 loss_att 9.050686 loss_ctc 11.592539 loss_rnnt 5.590134 hw_loss 0.203713 lr 0.00028801 rank 0
2023-03-01 10:58:15,258 DEBUG TRAIN Batch 54/4200 loss 5.742215 loss_att 9.326448 loss_ctc 11.023932 loss_rnnt 4.251853 hw_loss 0.129910 lr 0.00028800 rank 5
2023-03-01 10:58:15,259 DEBUG TRAIN Batch 54/4200 loss 3.506147 loss_att 5.977106 loss_ctc 4.115396 loss_rnnt 2.833541 hw_loss 0.182216 lr 0.00028800 rank 4
2023-03-01 10:58:15,263 DEBUG TRAIN Batch 54/4200 loss 2.282696 loss_att 5.596648 loss_ctc 4.122977 loss_rnnt 1.283784 hw_loss 0.170157 lr 0.00028800 rank 3
2023-03-01 10:58:15,265 DEBUG TRAIN Batch 54/4200 loss 2.107237 loss_att 4.192934 loss_ctc 3.398863 loss_rnnt 1.447194 hw_loss 0.132538 lr 0.00028801 rank 2
2023-03-01 10:58:15,283 DEBUG TRAIN Batch 54/4200 loss 5.320009 loss_att 8.288444 loss_ctc 8.725121 loss_rnnt 4.123235 hw_loss 0.279509 lr 0.00028800 rank 1
2023-03-01 10:59:23,508 DEBUG TRAIN Batch 54/4300 loss 3.798228 loss_att 6.214363 loss_ctc 6.010516 loss_rnnt 2.941453 hw_loss 0.147330 lr 0.00028799 rank 4
2023-03-01 10:59:23,519 DEBUG TRAIN Batch 54/4300 loss 3.885241 loss_att 5.672557 loss_ctc 4.779328 loss_rnnt 3.282567 hw_loss 0.236248 lr 0.00028800 rank 0
2023-03-01 10:59:23,520 DEBUG TRAIN Batch 54/4300 loss 5.106945 loss_att 7.099456 loss_ctc 8.373018 loss_rnnt 4.124680 hw_loss 0.278036 lr 0.00028799 rank 7
2023-03-01 10:59:23,522 DEBUG TRAIN Batch 54/4300 loss 7.414412 loss_att 9.759016 loss_ctc 15.261862 loss_rnnt 5.769314 hw_loss 0.243471 lr 0.00028798 rank 3
2023-03-01 10:59:23,523 DEBUG TRAIN Batch 54/4300 loss 4.894546 loss_att 7.949989 loss_ctc 9.861385 loss_rnnt 3.472825 hw_loss 0.278226 lr 0.00028799 rank 2
2023-03-01 10:59:23,526 DEBUG TRAIN Batch 54/4300 loss 4.092141 loss_att 7.259202 loss_ctc 8.210755 loss_rnnt 2.731915 hw_loss 0.333121 lr 0.00028799 rank 6
2023-03-01 10:59:23,540 DEBUG TRAIN Batch 54/4300 loss 1.297693 loss_att 3.349541 loss_ctc 3.180586 loss_rnnt 0.545673 hw_loss 0.169871 lr 0.00028799 rank 5
2023-03-01 10:59:23,549 DEBUG TRAIN Batch 54/4300 loss 5.286981 loss_att 6.953773 loss_ctc 10.636438 loss_rnnt 4.141643 hw_loss 0.185097 lr 0.00028799 rank 1
2023-03-01 11:00:02,434 DEBUG TRAIN Batch 54/4400 loss 2.623440 loss_att 4.315047 loss_ctc 3.990533 loss_rnnt 1.860536 hw_loss 0.454320 lr 0.00028798 rank 6
2023-03-01 11:00:02,437 DEBUG TRAIN Batch 54/4400 loss 4.123439 loss_att 8.292147 loss_ctc 7.641361 loss_rnnt 2.708420 hw_loss 0.210413 lr 0.00028797 rank 3
2023-03-01 11:00:02,447 DEBUG TRAIN Batch 54/4400 loss 6.341010 loss_att 10.228951 loss_ctc 11.922932 loss_rnnt 4.694766 hw_loss 0.233249 lr 0.00028798 rank 7
2023-03-01 11:00:02,448 DEBUG TRAIN Batch 54/4400 loss 6.819350 loss_att 9.657766 loss_ctc 9.566546 loss_rnnt 5.765157 hw_loss 0.225406 lr 0.00028798 rank 0
2023-03-01 11:00:02,452 DEBUG TRAIN Batch 54/4400 loss 3.448746 loss_att 6.614943 loss_ctc 7.358463 loss_rnnt 2.164438 hw_loss 0.243325 lr 0.00028798 rank 1
2023-03-01 11:00:02,454 DEBUG TRAIN Batch 54/4400 loss 5.487516 loss_att 7.665136 loss_ctc 10.094672 loss_rnnt 4.300127 hw_loss 0.257958 lr 0.00028798 rank 4
2023-03-01 11:00:02,476 DEBUG TRAIN Batch 54/4400 loss 6.727676 loss_att 7.716002 loss_ctc 8.896087 loss_rnnt 6.113197 hw_loss 0.239423 lr 0.00028798 rank 2
2023-03-01 11:00:02,487 DEBUG TRAIN Batch 54/4400 loss 5.604765 loss_att 8.210794 loss_ctc 7.133329 loss_rnnt 4.791042 hw_loss 0.166328 lr 0.00028798 rank 5
2023-03-01 11:00:41,150 DEBUG TRAIN Batch 54/4500 loss 5.369584 loss_att 8.860970 loss_ctc 11.326387 loss_rnnt 3.692673 hw_loss 0.345736 lr 0.00028796 rank 7
2023-03-01 11:00:41,152 DEBUG TRAIN Batch 54/4500 loss 8.674927 loss_att 13.015123 loss_ctc 18.609959 loss_rnnt 6.366051 hw_loss 0.217810 lr 0.00028797 rank 0
2023-03-01 11:00:41,155 DEBUG TRAIN Batch 54/4500 loss 8.183293 loss_att 8.693194 loss_ctc 11.654737 loss_rnnt 7.507010 hw_loss 0.208957 lr 0.00028797 rank 6
2023-03-01 11:00:41,157 DEBUG TRAIN Batch 54/4500 loss 4.774547 loss_att 8.165323 loss_ctc 7.147214 loss_rnnt 3.639939 hw_loss 0.262682 lr 0.00028797 rank 5
2023-03-01 11:00:41,159 DEBUG TRAIN Batch 54/4500 loss 5.598387 loss_att 5.775675 loss_ctc 8.237664 loss_rnnt 5.020762 hw_loss 0.356744 lr 0.00028797 rank 2
2023-03-01 11:00:41,161 DEBUG TRAIN Batch 54/4500 loss 5.603157 loss_att 5.567306 loss_ctc 9.906318 loss_rnnt 4.850127 hw_loss 0.349584 lr 0.00028796 rank 1
2023-03-01 11:00:41,162 DEBUG TRAIN Batch 54/4500 loss 5.180369 loss_att 8.404917 loss_ctc 6.297336 loss_rnnt 4.345103 hw_loss 0.077677 lr 0.00028797 rank 4
2023-03-01 11:00:41,180 DEBUG TRAIN Batch 54/4500 loss 12.590698 loss_att 12.999381 loss_ctc 20.337402 loss_rnnt 11.400232 hw_loss 0.142192 lr 0.00028796 rank 3
2023-03-01 11:01:21,144 DEBUG TRAIN Batch 54/4600 loss 7.497504 loss_att 10.867919 loss_ctc 13.824275 loss_rnnt 5.814592 hw_loss 0.309862 lr 0.00028795 rank 3
2023-03-01 11:01:21,157 DEBUG TRAIN Batch 54/4600 loss 4.263677 loss_att 7.559110 loss_ctc 6.888042 loss_rnnt 3.165725 hw_loss 0.166781 lr 0.00028796 rank 0
2023-03-01 11:01:21,157 DEBUG TRAIN Batch 54/4600 loss 9.044442 loss_att 12.735907 loss_ctc 17.759207 loss_rnnt 7.025365 hw_loss 0.222779 lr 0.00028795 rank 1
2023-03-01 11:01:21,158 DEBUG TRAIN Batch 54/4600 loss 6.361874 loss_att 9.930915 loss_ctc 11.926636 loss_rnnt 4.754405 hw_loss 0.284423 lr 0.00028795 rank 4
2023-03-01 11:01:21,159 DEBUG TRAIN Batch 54/4600 loss 7.085712 loss_att 11.238876 loss_ctc 9.477974 loss_rnnt 5.837298 hw_loss 0.185274 lr 0.00028795 rank 7
2023-03-01 11:01:21,160 DEBUG TRAIN Batch 54/4600 loss 4.452193 loss_att 8.718180 loss_ctc 8.664456 loss_rnnt 2.937984 hw_loss 0.186331 lr 0.00028796 rank 2
2023-03-01 11:01:21,165 DEBUG TRAIN Batch 54/4600 loss 5.806149 loss_att 9.328249 loss_ctc 11.219938 loss_rnnt 4.340079 hw_loss 0.074646 lr 0.00028795 rank 6
2023-03-01 11:01:21,211 DEBUG TRAIN Batch 54/4600 loss 11.207067 loss_att 15.200165 loss_ctc 20.629408 loss_rnnt 9.017740 hw_loss 0.251989 lr 0.00028795 rank 5
2023-03-01 11:02:28,594 DEBUG TRAIN Batch 54/4700 loss 4.444345 loss_att 7.685834 loss_ctc 10.531612 loss_rnnt 2.856112 hw_loss 0.240563 lr 0.00028794 rank 6
2023-03-01 11:02:28,598 DEBUG TRAIN Batch 54/4700 loss 7.096666 loss_att 13.046114 loss_ctc 14.259192 loss_rnnt 4.887564 hw_loss 0.120392 lr 0.00028795 rank 0
2023-03-01 11:02:28,600 DEBUG TRAIN Batch 54/4700 loss 1.799658 loss_att 4.620405 loss_ctc 3.829076 loss_rnnt 0.873164 hw_loss 0.172042 lr 0.00028794 rank 7
2023-03-01 11:02:28,603 DEBUG TRAIN Batch 54/4700 loss 5.774206 loss_att 8.025982 loss_ctc 11.159002 loss_rnnt 4.430196 hw_loss 0.329404 lr 0.00028794 rank 3
2023-03-01 11:02:28,604 DEBUG TRAIN Batch 54/4700 loss 4.406510 loss_att 8.749783 loss_ctc 6.505495 loss_rnnt 3.099974 hw_loss 0.296282 lr 0.00028794 rank 1
2023-03-01 11:02:28,602 DEBUG TRAIN Batch 54/4700 loss 8.923508 loss_att 11.167031 loss_ctc 14.098826 loss_rnnt 7.675103 hw_loss 0.205608 lr 0.00028795 rank 2
2023-03-01 11:02:28,612 DEBUG TRAIN Batch 54/4700 loss 6.437107 loss_att 9.400114 loss_ctc 10.802439 loss_rnnt 5.138828 hw_loss 0.231814 lr 0.00028794 rank 4
2023-03-01 11:02:28,619 DEBUG TRAIN Batch 54/4700 loss 10.572254 loss_att 13.541060 loss_ctc 19.475025 loss_rnnt 8.683245 hw_loss 0.202897 lr 0.00028794 rank 5
2023-03-01 11:03:07,266 DEBUG TRAIN Batch 54/4800 loss 7.435367 loss_att 11.719027 loss_ctc 16.417778 loss_rnnt 5.280611 hw_loss 0.188191 lr 0.00028793 rank 6
2023-03-01 11:03:07,275 DEBUG TRAIN Batch 54/4800 loss 3.012704 loss_att 6.198120 loss_ctc 6.472681 loss_rnnt 1.865514 hw_loss 0.091457 lr 0.00028793 rank 3
2023-03-01 11:03:07,282 DEBUG TRAIN Batch 54/4800 loss 8.670553 loss_att 12.758729 loss_ctc 17.168596 loss_rnnt 6.673409 hw_loss 0.087068 lr 0.00028794 rank 0
2023-03-01 11:03:07,282 DEBUG TRAIN Batch 54/4800 loss 6.194090 loss_att 7.196774 loss_ctc 7.653157 loss_rnnt 5.679598 hw_loss 0.223901 lr 0.00028793 rank 5
2023-03-01 11:03:07,283 DEBUG TRAIN Batch 54/4800 loss 7.718448 loss_att 9.852911 loss_ctc 9.942234 loss_rnnt 6.888578 hw_loss 0.199636 lr 0.00028793 rank 4
2023-03-01 11:03:07,284 DEBUG TRAIN Batch 54/4800 loss 7.837991 loss_att 8.563221 loss_ctc 7.801959 loss_rnnt 7.559940 hw_loss 0.258390 lr 0.00028793 rank 7
2023-03-01 11:03:07,286 DEBUG TRAIN Batch 54/4800 loss 3.052068 loss_att 6.304415 loss_ctc 8.652775 loss_rnnt 1.532003 hw_loss 0.230314 lr 0.00028793 rank 1
2023-03-01 11:03:07,293 DEBUG TRAIN Batch 54/4800 loss 11.668033 loss_att 16.826008 loss_ctc 19.899719 loss_rnnt 9.448019 hw_loss 0.170365 lr 0.00028793 rank 2
2023-03-01 11:03:46,238 DEBUG TRAIN Batch 54/4900 loss 4.580215 loss_att 6.684386 loss_ctc 10.366940 loss_rnnt 3.272217 hw_loss 0.216751 lr 0.00028792 rank 7
2023-03-01 11:03:46,239 DEBUG TRAIN Batch 54/4900 loss 10.027655 loss_att 11.761410 loss_ctc 14.565069 loss_rnnt 8.957531 hw_loss 0.221970 lr 0.00028793 rank 0
2023-03-01 11:03:46,240 DEBUG TRAIN Batch 54/4900 loss 6.759069 loss_att 7.804953 loss_ctc 9.305511 loss_rnnt 6.073010 hw_loss 0.257542 lr 0.00028792 rank 2
2023-03-01 11:03:46,242 DEBUG TRAIN Batch 54/4900 loss 5.885485 loss_att 10.351680 loss_ctc 11.450767 loss_rnnt 4.086321 hw_loss 0.307289 lr 0.00028792 rank 1
2023-03-01 11:03:46,245 DEBUG TRAIN Batch 54/4900 loss 5.041537 loss_att 7.539886 loss_ctc 9.277417 loss_rnnt 3.920777 hw_loss 0.105574 lr 0.00028792 rank 6
2023-03-01 11:03:46,247 DEBUG TRAIN Batch 54/4900 loss 2.121010 loss_att 5.909876 loss_ctc 6.090816 loss_rnnt 0.750404 hw_loss 0.156611 lr 0.00028792 rank 4
2023-03-01 11:03:46,249 DEBUG TRAIN Batch 54/4900 loss 4.485093 loss_att 7.022301 loss_ctc 7.231331 loss_rnnt 3.568963 hw_loss 0.079730 lr 0.00028792 rank 5
2023-03-01 11:03:46,256 DEBUG TRAIN Batch 54/4900 loss 3.813847 loss_att 7.919910 loss_ctc 9.389753 loss_rnnt 2.055038 hw_loss 0.364015 lr 0.00028791 rank 3
2023-03-01 11:04:54,419 DEBUG TRAIN Batch 54/5000 loss 3.509574 loss_att 6.580239 loss_ctc 5.649656 loss_rnnt 2.486204 hw_loss 0.232299 lr 0.00028791 rank 1
2023-03-01 11:04:54,421 DEBUG TRAIN Batch 54/5000 loss 3.162265 loss_att 5.828354 loss_ctc 4.108068 loss_rnnt 2.369653 hw_loss 0.249914 lr 0.00028791 rank 6
2023-03-01 11:04:54,435 DEBUG TRAIN Batch 54/5000 loss 7.248152 loss_att 8.814483 loss_ctc 9.994414 loss_rnnt 6.405030 hw_loss 0.306911 lr 0.00028791 rank 0
2023-03-01 11:04:54,438 DEBUG TRAIN Batch 54/5000 loss 6.200481 loss_att 8.412980 loss_ctc 12.092552 loss_rnnt 4.811396 hw_loss 0.301829 lr 0.00028791 rank 2
2023-03-01 11:04:54,441 DEBUG TRAIN Batch 54/5000 loss 4.763157 loss_att 6.917038 loss_ctc 8.087714 loss_rnnt 3.776883 hw_loss 0.210420 lr 0.00028790 rank 7
2023-03-01 11:04:54,441 DEBUG TRAIN Batch 54/5000 loss 10.136367 loss_att 11.354485 loss_ctc 17.929430 loss_rnnt 8.738140 hw_loss 0.216614 lr 0.00028791 rank 5
2023-03-01 11:04:54,446 DEBUG TRAIN Batch 54/5000 loss 2.544118 loss_att 5.021554 loss_ctc 5.526030 loss_rnnt 1.525025 hw_loss 0.236284 lr 0.00028791 rank 4
2023-03-01 11:04:54,450 DEBUG TRAIN Batch 54/5000 loss 8.653089 loss_att 8.919676 loss_ctc 12.275982 loss_rnnt 7.979075 hw_loss 0.258081 lr 0.00028790 rank 3
2023-03-01 11:05:33,385 DEBUG TRAIN Batch 54/5100 loss 3.155906 loss_att 6.194907 loss_ctc 7.998157 loss_rnnt 1.766858 hw_loss 0.254277 lr 0.00028789 rank 5
2023-03-01 11:05:33,386 DEBUG TRAIN Batch 54/5100 loss 7.581375 loss_att 8.660374 loss_ctc 12.750664 loss_rnnt 6.449275 hw_loss 0.425742 lr 0.00028790 rank 4
2023-03-01 11:05:33,405 DEBUG TRAIN Batch 54/5100 loss 6.298288 loss_att 10.513602 loss_ctc 12.781814 loss_rnnt 4.423112 hw_loss 0.314332 lr 0.00028789 rank 7
2023-03-01 11:05:33,405 DEBUG TRAIN Batch 54/5100 loss 2.376976 loss_att 3.986852 loss_ctc 5.528482 loss_rnnt 1.545446 hw_loss 0.167539 lr 0.00028789 rank 3
2023-03-01 11:05:33,408 DEBUG TRAIN Batch 54/5100 loss 5.313344 loss_att 6.808572 loss_ctc 8.512012 loss_rnnt 4.428500 hw_loss 0.298705 lr 0.00028790 rank 0
2023-03-01 11:05:33,408 DEBUG TRAIN Batch 54/5100 loss 8.697663 loss_att 10.842195 loss_ctc 14.561321 loss_rnnt 7.283271 hw_loss 0.381873 lr 0.00028789 rank 1
2023-03-01 11:05:33,411 DEBUG TRAIN Batch 54/5100 loss 6.040612 loss_att 7.616779 loss_ctc 9.007252 loss_rnnt 5.197124 hw_loss 0.248817 lr 0.00028789 rank 6
2023-03-01 11:05:33,413 DEBUG TRAIN Batch 54/5100 loss 4.831151 loss_att 6.974644 loss_ctc 6.150366 loss_rnnt 4.010503 hw_loss 0.405101 lr 0.00028790 rank 2
2023-03-01 11:06:12,051 DEBUG TRAIN Batch 54/5200 loss 0.908974 loss_att 3.287930 loss_ctc 1.966024 loss_rnnt 0.212413 hw_loss 0.149680 lr 0.00028789 rank 0
2023-03-01 11:06:12,068 DEBUG TRAIN Batch 54/5200 loss 7.454917 loss_att 10.422053 loss_ctc 12.625262 loss_rnnt 6.052612 hw_loss 0.224059 lr 0.00028788 rank 7
2023-03-01 11:06:12,068 DEBUG TRAIN Batch 54/5200 loss 5.143262 loss_att 6.743571 loss_ctc 8.684847 loss_rnnt 4.266361 hw_loss 0.158677 lr 0.00028788 rank 6
2023-03-01 11:06:12,071 DEBUG TRAIN Batch 54/5200 loss 8.626914 loss_att 13.381671 loss_ctc 30.973640 loss_rnnt 4.579760 hw_loss 0.218699 lr 0.00028788 rank 1
2023-03-01 11:06:12,072 DEBUG TRAIN Batch 54/5200 loss 9.773624 loss_att 10.750660 loss_ctc 17.361500 loss_rnnt 8.534486 hw_loss 0.060026 lr 0.00028788 rank 5
2023-03-01 11:06:12,075 DEBUG TRAIN Batch 54/5200 loss 2.945995 loss_att 6.156772 loss_ctc 4.694566 loss_rnnt 1.918905 hw_loss 0.284610 lr 0.00028789 rank 2
2023-03-01 11:06:12,078 DEBUG TRAIN Batch 54/5200 loss 4.932531 loss_att 8.120544 loss_ctc 9.767824 loss_rnnt 3.619570 hw_loss 0.057472 lr 0.00028788 rank 3
2023-03-01 11:06:12,121 DEBUG TRAIN Batch 54/5200 loss 4.556777 loss_att 7.798361 loss_ctc 8.793558 loss_rnnt 3.216375 hw_loss 0.238464 lr 0.00028788 rank 4
2023-03-01 11:06:52,213 DEBUG TRAIN Batch 54/5300 loss 4.044036 loss_att 6.642040 loss_ctc 6.313607 loss_rnnt 3.089169 hw_loss 0.248733 lr 0.00028787 rank 5
2023-03-01 11:06:52,214 DEBUG TRAIN Batch 54/5300 loss 1.322069 loss_att 3.140313 loss_ctc 3.327061 loss_rnnt 0.550323 hw_loss 0.263933 lr 0.00028787 rank 1
2023-03-01 11:06:52,224 DEBUG TRAIN Batch 54/5300 loss 10.658502 loss_att 12.641105 loss_ctc 11.430052 loss_rnnt 10.030574 hw_loss 0.241002 lr 0.00028787 rank 2
2023-03-01 11:06:52,227 DEBUG TRAIN Batch 54/5300 loss 9.935843 loss_att 11.562881 loss_ctc 21.934523 loss_rnnt 7.913591 hw_loss 0.181910 lr 0.00028787 rank 6
2023-03-01 11:06:52,230 DEBUG TRAIN Batch 54/5300 loss 4.508921 loss_att 7.680117 loss_ctc 10.189403 loss_rnnt 3.040925 hw_loss 0.143172 lr 0.00028788 rank 0
2023-03-01 11:06:52,232 DEBUG TRAIN Batch 54/5300 loss 4.367605 loss_att 7.643397 loss_ctc 5.948228 loss_rnnt 3.376411 hw_loss 0.234909 lr 0.00028787 rank 7
2023-03-01 11:06:52,233 DEBUG TRAIN Batch 54/5300 loss 3.317038 loss_att 7.099038 loss_ctc 5.117594 loss_rnnt 2.237218 hw_loss 0.156272 lr 0.00028787 rank 3
2023-03-01 11:06:52,243 DEBUG TRAIN Batch 54/5300 loss 4.323741 loss_att 5.185804 loss_ctc 10.019547 loss_rnnt 3.319844 hw_loss 0.135083 lr 0.00028787 rank 4
2023-03-01 11:07:56,694 DEBUG TRAIN Batch 54/5400 loss 2.851209 loss_att 6.208203 loss_ctc 5.606163 loss_rnnt 1.713377 hw_loss 0.185822 lr 0.00028786 rank 1
2023-03-01 11:07:56,703 DEBUG TRAIN Batch 54/5400 loss 4.748562 loss_att 8.706556 loss_ctc 7.100652 loss_rnnt 3.536563 hw_loss 0.200227 lr 0.00028786 rank 6
2023-03-01 11:07:56,705 DEBUG TRAIN Batch 54/5400 loss 4.001798 loss_att 8.085929 loss_ctc 8.088234 loss_rnnt 2.571677 hw_loss 0.128319 lr 0.00028786 rank 5
2023-03-01 11:07:56,716 DEBUG TRAIN Batch 54/5400 loss 7.486558 loss_att 8.977194 loss_ctc 13.858786 loss_rnnt 6.241252 hw_loss 0.182904 lr 0.00028787 rank 0
2023-03-01 11:07:56,719 DEBUG TRAIN Batch 54/5400 loss 10.209358 loss_att 11.669745 loss_ctc 16.078325 loss_rnnt 9.030984 hw_loss 0.194565 lr 0.00028786 rank 7
2023-03-01 11:07:56,723 DEBUG TRAIN Batch 54/5400 loss 2.950556 loss_att 5.285123 loss_ctc 4.993591 loss_rnnt 2.075869 hw_loss 0.253817 lr 0.00028786 rank 4
2023-03-01 11:07:56,723 DEBUG TRAIN Batch 54/5400 loss 8.115060 loss_att 12.961395 loss_ctc 16.996685 loss_rnnt 5.870687 hw_loss 0.170416 lr 0.00028786 rank 2
2023-03-01 11:07:56,770 DEBUG TRAIN Batch 54/5400 loss 9.833295 loss_att 15.583326 loss_ctc 16.347418 loss_rnnt 7.636620 hw_loss 0.333974 lr 0.00028785 rank 3
2023-03-01 11:08:35,525 DEBUG TRAIN Batch 54/5500 loss 3.893036 loss_att 5.255282 loss_ctc 4.641443 loss_rnnt 3.397756 hw_loss 0.230706 lr 0.00028784 rank 7
2023-03-01 11:08:35,525 DEBUG TRAIN Batch 54/5500 loss 2.714746 loss_att 4.394111 loss_ctc 4.142417 loss_rnnt 2.143991 hw_loss 0.083484 lr 0.00028785 rank 0
2023-03-01 11:08:35,528 DEBUG TRAIN Batch 54/5500 loss 3.490687 loss_att 6.720644 loss_ctc 7.620217 loss_rnnt 2.127143 hw_loss 0.313029 lr 0.00028785 rank 4
2023-03-01 11:08:35,531 DEBUG TRAIN Batch 54/5500 loss 3.498369 loss_att 6.234256 loss_ctc 11.397943 loss_rnnt 1.760786 hw_loss 0.257118 lr 0.00028784 rank 3
2023-03-01 11:08:35,532 DEBUG TRAIN Batch 54/5500 loss 5.931401 loss_att 9.517746 loss_ctc 10.289264 loss_rnnt 4.513887 hw_loss 0.223495 lr 0.00028785 rank 2
2023-03-01 11:08:35,544 DEBUG TRAIN Batch 54/5500 loss 7.014810 loss_att 10.285416 loss_ctc 11.608354 loss_rnnt 5.697581 hw_loss 0.094941 lr 0.00028785 rank 6
2023-03-01 11:08:35,559 DEBUG TRAIN Batch 54/5500 loss 4.968145 loss_att 6.446040 loss_ctc 6.778384 loss_rnnt 4.277556 hw_loss 0.288085 lr 0.00028785 rank 5
2023-03-01 11:08:35,578 DEBUG TRAIN Batch 54/5500 loss 4.267169 loss_att 6.570329 loss_ctc 6.347198 loss_rnnt 3.361574 hw_loss 0.314300 lr 0.00028785 rank 1
2023-03-01 11:09:15,249 DEBUG TRAIN Batch 54/5600 loss 5.281476 loss_att 7.805688 loss_ctc 10.524256 loss_rnnt 4.014098 hw_loss 0.119059 lr 0.00028783 rank 1
2023-03-01 11:09:15,253 DEBUG TRAIN Batch 54/5600 loss 5.012367 loss_att 8.308268 loss_ctc 8.709452 loss_rnnt 3.770761 hw_loss 0.167777 lr 0.00028784 rank 2
2023-03-01 11:09:15,256 DEBUG TRAIN Batch 54/5600 loss 7.096377 loss_att 8.848806 loss_ctc 10.061585 loss_rnnt 6.258256 hw_loss 0.173012 lr 0.00028784 rank 4
2023-03-01 11:09:15,258 DEBUG TRAIN Batch 54/5600 loss 5.789175 loss_att 7.385445 loss_ctc 7.901183 loss_rnnt 5.012175 hw_loss 0.330271 lr 0.00028783 rank 7
2023-03-01 11:09:15,261 DEBUG TRAIN Batch 54/5600 loss 8.058517 loss_att 10.070402 loss_ctc 13.053605 loss_rnnt 6.857567 hw_loss 0.248551 lr 0.00028784 rank 0
2023-03-01 11:09:15,262 DEBUG TRAIN Batch 54/5600 loss 6.306312 loss_att 9.624420 loss_ctc 13.199880 loss_rnnt 4.613270 hw_loss 0.206770 lr 0.00028783 rank 6
2023-03-01 11:09:15,266 DEBUG TRAIN Batch 54/5600 loss 6.194096 loss_att 8.008917 loss_ctc 10.277018 loss_rnnt 5.176779 hw_loss 0.206181 lr 0.00028783 rank 3
2023-03-01 11:09:15,287 DEBUG TRAIN Batch 54/5600 loss 4.278156 loss_att 6.834761 loss_ctc 11.946632 loss_rnnt 2.660434 hw_loss 0.157384 lr 0.00028783 rank 5
2023-03-01 11:10:20,166 DEBUG TRAIN Batch 54/5700 loss 10.068765 loss_att 12.252628 loss_ctc 15.937227 loss_rnnt 8.742099 hw_loss 0.201434 lr 0.00028782 rank 1
2023-03-01 11:10:20,170 DEBUG TRAIN Batch 54/5700 loss 4.089442 loss_att 5.509732 loss_ctc 8.182501 loss_rnnt 3.205428 hw_loss 0.101653 lr 0.00028783 rank 2
2023-03-01 11:10:20,172 DEBUG TRAIN Batch 54/5700 loss 10.174541 loss_att 12.818963 loss_ctc 14.324045 loss_rnnt 8.994390 hw_loss 0.183749 lr 0.00028783 rank 0
2023-03-01 11:10:20,173 DEBUG TRAIN Batch 54/5700 loss 6.847200 loss_att 9.686723 loss_ctc 12.941129 loss_rnnt 5.338879 hw_loss 0.239798 lr 0.00028782 rank 6
2023-03-01 11:10:20,174 DEBUG TRAIN Batch 54/5700 loss 11.366349 loss_att 10.873193 loss_ctc 14.564625 loss_rnnt 10.972005 hw_loss 0.124759 lr 0.00028782 rank 3
2023-03-01 11:10:20,175 DEBUG TRAIN Batch 54/5700 loss 6.922312 loss_att 7.449593 loss_ctc 9.063644 loss_rnnt 6.361158 hw_loss 0.319101 lr 0.00028782 rank 4
2023-03-01 11:10:20,192 DEBUG TRAIN Batch 54/5700 loss 5.135566 loss_att 9.737183 loss_ctc 8.908155 loss_rnnt 3.625866 hw_loss 0.161935 lr 0.00028782 rank 7
2023-03-01 11:10:20,218 DEBUG TRAIN Batch 54/5700 loss 13.715129 loss_att 16.129368 loss_ctc 20.087017 loss_rnnt 12.231903 hw_loss 0.282739 lr 0.00028782 rank 5
2023-03-01 11:10:59,103 DEBUG TRAIN Batch 54/5800 loss 6.348003 loss_att 13.510443 loss_ctc 14.945292 loss_rnnt 3.629850 hw_loss 0.261301 lr 0.00028781 rank 2
2023-03-01 11:10:59,104 DEBUG TRAIN Batch 54/5800 loss 6.744519 loss_att 8.567350 loss_ctc 10.581302 loss_rnnt 5.752700 hw_loss 0.216902 lr 0.00028781 rank 7
2023-03-01 11:10:59,104 DEBUG TRAIN Batch 54/5800 loss 6.040156 loss_att 6.323075 loss_ctc 8.552180 loss_rnnt 5.456079 hw_loss 0.361043 lr 0.00028782 rank 0
2023-03-01 11:10:59,104 DEBUG TRAIN Batch 54/5800 loss 3.443803 loss_att 4.981393 loss_ctc 4.213838 loss_rnnt 2.920855 hw_loss 0.211421 lr 0.00028781 rank 4
2023-03-01 11:10:59,108 DEBUG TRAIN Batch 54/5800 loss 3.804260 loss_att 6.346220 loss_ctc 6.463064 loss_rnnt 2.813205 hw_loss 0.240292 lr 0.00028781 rank 1
2023-03-01 11:10:59,109 DEBUG TRAIN Batch 54/5800 loss 6.540910 loss_att 8.314958 loss_ctc 10.160730 loss_rnnt 5.557874 hw_loss 0.272968 lr 0.00028781 rank 5
2023-03-01 11:10:59,110 DEBUG TRAIN Batch 54/5800 loss 7.181417 loss_att 9.165358 loss_ctc 14.728091 loss_rnnt 5.613899 hw_loss 0.308450 lr 0.00028781 rank 3
2023-03-01 11:10:59,148 DEBUG TRAIN Batch 54/5800 loss 5.962241 loss_att 8.355373 loss_ctc 10.674038 loss_rnnt 4.728727 hw_loss 0.237464 lr 0.00028781 rank 6
2023-03-01 11:11:37,920 DEBUG TRAIN Batch 54/5900 loss 3.739552 loss_att 4.883799 loss_ctc 7.314171 loss_rnnt 2.906855 hw_loss 0.238559 lr 0.00028780 rank 6
2023-03-01 11:11:37,920 DEBUG TRAIN Batch 54/5900 loss 7.023235 loss_att 8.631407 loss_ctc 9.463336 loss_rnnt 6.178590 hw_loss 0.370621 lr 0.00028780 rank 5
2023-03-01 11:11:37,934 DEBUG TRAIN Batch 54/5900 loss 3.578790 loss_att 5.905931 loss_ctc 5.162349 loss_rnnt 2.817955 hw_loss 0.157997 lr 0.00028781 rank 0
2023-03-01 11:11:37,934 DEBUG TRAIN Batch 54/5900 loss 4.534528 loss_att 6.666719 loss_ctc 8.790325 loss_rnnt 3.459016 hw_loss 0.153063 lr 0.00028780 rank 7
2023-03-01 11:11:37,939 DEBUG TRAIN Batch 54/5900 loss 9.006680 loss_att 12.034681 loss_ctc 12.977882 loss_rnnt 7.754152 hw_loss 0.220188 lr 0.00028780 rank 1
2023-03-01 11:11:37,939 DEBUG TRAIN Batch 54/5900 loss 4.692484 loss_att 8.470405 loss_ctc 5.286510 loss_rnnt 3.725146 hw_loss 0.248533 lr 0.00028779 rank 3
2023-03-01 11:11:37,940 DEBUG TRAIN Batch 54/5900 loss 11.001272 loss_att 14.697610 loss_ctc 23.878035 loss_rnnt 8.460051 hw_loss 0.159474 lr 0.00028780 rank 4
2023-03-01 11:11:37,957 DEBUG TRAIN Batch 54/5900 loss 8.559739 loss_att 11.949030 loss_ctc 13.107389 loss_rnnt 7.141586 hw_loss 0.251137 lr 0.00028780 rank 2
2023-03-01 11:12:17,676 DEBUG TRAIN Batch 54/6000 loss 9.836961 loss_att 13.623626 loss_ctc 14.386389 loss_rnnt 8.348281 hw_loss 0.233921 lr 0.00028779 rank 7
2023-03-01 11:12:17,680 DEBUG TRAIN Batch 54/6000 loss 5.662379 loss_att 7.025744 loss_ctc 9.198271 loss_rnnt 4.822391 hw_loss 0.179743 lr 0.00028779 rank 4
2023-03-01 11:12:17,681 DEBUG TRAIN Batch 54/6000 loss 5.180005 loss_att 8.511662 loss_ctc 8.759118 loss_rnnt 3.938159 hw_loss 0.184312 lr 0.00028779 rank 0
2023-03-01 11:12:17,682 DEBUG TRAIN Batch 54/6000 loss 7.537715 loss_att 12.774666 loss_ctc 10.582075 loss_rnnt 5.991659 hw_loss 0.173910 lr 0.00028779 rank 1
2023-03-01 11:12:17,686 DEBUG TRAIN Batch 54/6000 loss 6.336863 loss_att 8.922916 loss_ctc 11.338913 loss_rnnt 4.972472 hw_loss 0.337950 lr 0.00028779 rank 6
2023-03-01 11:12:17,687 DEBUG TRAIN Batch 54/6000 loss 7.541698 loss_att 10.160110 loss_ctc 10.792988 loss_rnnt 6.468634 hw_loss 0.217269 lr 0.00028779 rank 5
2023-03-01 11:12:17,692 DEBUG TRAIN Batch 54/6000 loss 2.551761 loss_att 5.889863 loss_ctc 7.300830 loss_rnnt 1.139489 hw_loss 0.208953 lr 0.00028778 rank 3
2023-03-01 11:12:17,717 DEBUG TRAIN Batch 54/6000 loss 5.329492 loss_att 10.716586 loss_ctc 15.232973 loss_rnnt 2.772486 hw_loss 0.298353 lr 0.00028779 rank 2
2023-03-01 11:13:21,439 DEBUG TRAIN Batch 54/6100 loss 8.127914 loss_att 12.826034 loss_ctc 12.693541 loss_rnnt 6.526324 hw_loss 0.099782 lr 0.00028777 rank 3
2023-03-01 11:13:21,441 DEBUG TRAIN Batch 54/6100 loss 11.627770 loss_att 13.892673 loss_ctc 17.521461 loss_rnnt 10.311864 hw_loss 0.144564 lr 0.00028778 rank 2
2023-03-01 11:13:21,445 DEBUG TRAIN Batch 54/6100 loss 6.366584 loss_att 11.186810 loss_ctc 13.610362 loss_rnnt 4.338098 hw_loss 0.184882 lr 0.00028777 rank 1
2023-03-01 11:13:21,458 DEBUG TRAIN Batch 54/6100 loss 7.958612 loss_att 10.277538 loss_ctc 11.617132 loss_rnnt 6.965406 hw_loss 0.078036 lr 0.00028778 rank 4
2023-03-01 11:13:21,459 DEBUG TRAIN Batch 54/6100 loss 2.916558 loss_att 6.492717 loss_ctc 5.319274 loss_rnnt 1.659470 hw_loss 0.415301 lr 0.00028778 rank 0
2023-03-01 11:13:21,459 DEBUG TRAIN Batch 54/6100 loss 5.202621 loss_att 6.849871 loss_ctc 7.757984 loss_rnnt 4.401119 hw_loss 0.246258 lr 0.00028777 rank 7
2023-03-01 11:13:21,464 DEBUG TRAIN Batch 54/6100 loss 5.704774 loss_att 8.911741 loss_ctc 11.841135 loss_rnnt 4.212848 hw_loss 0.060659 lr 0.00028777 rank 5
2023-03-01 11:13:21,464 DEBUG TRAIN Batch 54/6100 loss 8.109518 loss_att 11.714987 loss_ctc 16.849520 loss_rnnt 6.136765 hw_loss 0.161863 lr 0.00028777 rank 6
2023-03-01 11:14:00,352 DEBUG TRAIN Batch 54/6200 loss 8.019852 loss_att 11.712532 loss_ctc 16.177052 loss_rnnt 6.102433 hw_loss 0.171103 lr 0.00028776 rank 3
2023-03-01 11:14:00,355 DEBUG TRAIN Batch 54/6200 loss 11.015639 loss_att 14.963854 loss_ctc 15.159159 loss_rnnt 9.620739 hw_loss 0.098977 lr 0.00028776 rank 4
2023-03-01 11:14:00,360 DEBUG TRAIN Batch 54/6200 loss 8.518438 loss_att 11.125963 loss_ctc 15.777220 loss_rnnt 6.942636 hw_loss 0.162114 lr 0.00028777 rank 2
2023-03-01 11:14:00,371 DEBUG TRAIN Batch 54/6200 loss 7.769243 loss_att 13.202332 loss_ctc 14.942513 loss_rnnt 5.614717 hw_loss 0.209012 lr 0.00028776 rank 1
2023-03-01 11:14:00,372 DEBUG TRAIN Batch 54/6200 loss 5.803977 loss_att 8.500368 loss_ctc 10.084734 loss_rnnt 4.562868 hw_loss 0.245742 lr 0.00028776 rank 6
2023-03-01 11:14:00,374 DEBUG TRAIN Batch 54/6200 loss 2.711344 loss_att 5.904317 loss_ctc 8.215261 loss_rnnt 1.195822 hw_loss 0.268260 lr 0.00028777 rank 0
2023-03-01 11:14:00,376 DEBUG TRAIN Batch 54/6200 loss 6.453204 loss_att 8.773860 loss_ctc 12.828726 loss_rnnt 5.048823 hw_loss 0.169087 lr 0.00028776 rank 7
2023-03-01 11:14:00,376 DEBUG TRAIN Batch 54/6200 loss 4.722525 loss_att 6.811154 loss_ctc 10.001667 loss_rnnt 3.436406 hw_loss 0.308451 lr 0.00028776 rank 5
2023-03-01 11:14:39,536 DEBUG TRAIN Batch 54/6300 loss 15.252609 loss_att 16.873358 loss_ctc 28.847931 loss_rnnt 12.987079 hw_loss 0.241258 lr 0.00028775 rank 3
2023-03-01 11:14:39,540 DEBUG TRAIN Batch 54/6300 loss 6.880332 loss_att 9.128237 loss_ctc 12.801027 loss_rnnt 5.525474 hw_loss 0.217223 lr 0.00028775 rank 5
2023-03-01 11:14:39,549 DEBUG TRAIN Batch 54/6300 loss 3.371326 loss_att 6.279708 loss_ctc 6.101043 loss_rnnt 2.326331 hw_loss 0.186293 lr 0.00028775 rank 7
2023-03-01 11:14:39,549 DEBUG TRAIN Batch 54/6300 loss 4.349434 loss_att 7.214803 loss_ctc 8.202632 loss_rnnt 3.158329 hw_loss 0.195509 lr 0.00028775 rank 6
2023-03-01 11:14:39,550 DEBUG TRAIN Batch 54/6300 loss 5.421251 loss_att 7.993416 loss_ctc 9.394811 loss_rnnt 4.239025 hw_loss 0.258722 lr 0.00028775 rank 4
2023-03-01 11:14:39,554 DEBUG TRAIN Batch 54/6300 loss 2.847499 loss_att 6.350429 loss_ctc 6.374798 loss_rnnt 1.543318 hw_loss 0.249916 lr 0.00028776 rank 2
2023-03-01 11:14:39,558 DEBUG TRAIN Batch 54/6300 loss 3.818975 loss_att 5.543920 loss_ctc 4.906866 loss_rnnt 3.237747 hw_loss 0.170976 lr 0.00028776 rank 0
2023-03-01 11:14:39,600 DEBUG TRAIN Batch 54/6300 loss 13.348020 loss_att 14.227327 loss_ctc 17.775400 loss_rnnt 12.416176 hw_loss 0.310621 lr 0.00028775 rank 1
2023-03-01 11:15:44,820 DEBUG TRAIN Batch 54/6400 loss 5.541869 loss_att 10.013450 loss_ctc 11.146105 loss_rnnt 3.761412 hw_loss 0.260455 lr 0.00028774 rank 4
2023-03-01 11:15:44,830 DEBUG TRAIN Batch 54/6400 loss 3.883253 loss_att 7.426768 loss_ctc 6.506660 loss_rnnt 2.735856 hw_loss 0.166699 lr 0.00028775 rank 0
2023-03-01 11:15:44,834 DEBUG TRAIN Batch 54/6400 loss 9.039403 loss_att 9.714530 loss_ctc 14.796025 loss_rnnt 7.981672 hw_loss 0.290916 lr 0.00028774 rank 2
2023-03-01 11:15:44,835 DEBUG TRAIN Batch 54/6400 loss 3.180536 loss_att 5.949168 loss_ctc 6.159126 loss_rnnt 2.099555 hw_loss 0.243957 lr 0.00028774 rank 7
2023-03-01 11:15:44,835 DEBUG TRAIN Batch 54/6400 loss 8.269446 loss_att 8.984739 loss_ctc 12.210736 loss_rnnt 7.415500 hw_loss 0.347593 lr 0.00028773 rank 3
2023-03-01 11:15:44,837 DEBUG TRAIN Batch 54/6400 loss 3.307212 loss_att 5.560254 loss_ctc 7.800083 loss_rnnt 2.165421 hw_loss 0.172749 lr 0.00028774 rank 1
2023-03-01 11:15:44,842 DEBUG TRAIN Batch 54/6400 loss 3.589313 loss_att 7.366429 loss_ctc 8.205750 loss_rnnt 2.161539 hw_loss 0.106549 lr 0.00028774 rank 5
2023-03-01 11:15:44,862 DEBUG TRAIN Batch 54/6400 loss 7.470301 loss_att 7.774758 loss_ctc 10.060272 loss_rnnt 6.870950 hw_loss 0.362117 lr 0.00028774 rank 6
2023-03-01 11:16:23,710 DEBUG TRAIN Batch 54/6500 loss 6.923044 loss_att 11.937656 loss_ctc 13.187716 loss_rnnt 5.031422 hw_loss 0.100144 lr 0.00028772 rank 3
2023-03-01 11:16:23,718 DEBUG TRAIN Batch 54/6500 loss 6.728076 loss_att 8.717019 loss_ctc 11.904071 loss_rnnt 5.487359 hw_loss 0.286491 lr 0.00028773 rank 7
2023-03-01 11:16:23,720 DEBUG TRAIN Batch 54/6500 loss 4.603707 loss_att 6.944199 loss_ctc 8.119110 loss_rnnt 3.536501 hw_loss 0.244476 lr 0.00028773 rank 1
2023-03-01 11:16:23,720 DEBUG TRAIN Batch 54/6500 loss 3.492757 loss_att 6.657213 loss_ctc 8.737556 loss_rnnt 2.160174 hw_loss 0.000724 lr 0.00028773 rank 6
2023-03-01 11:16:23,724 DEBUG TRAIN Batch 54/6500 loss 5.651719 loss_att 7.802207 loss_ctc 10.799361 loss_rnnt 4.339199 hw_loss 0.367631 lr 0.00028773 rank 0
2023-03-01 11:16:23,724 DEBUG TRAIN Batch 54/6500 loss 10.154522 loss_att 15.172955 loss_ctc 17.517334 loss_rnnt 8.068884 hw_loss 0.187956 lr 0.00028773 rank 5
2023-03-01 11:16:23,728 DEBUG TRAIN Batch 54/6500 loss 5.453944 loss_att 8.382977 loss_ctc 9.140054 loss_rnnt 4.237348 hw_loss 0.261202 lr 0.00028773 rank 2
2023-03-01 11:16:23,769 DEBUG TRAIN Batch 54/6500 loss 4.169342 loss_att 7.141145 loss_ctc 8.826809 loss_rnnt 2.846796 hw_loss 0.200980 lr 0.00028773 rank 4
2023-03-01 11:17:01,988 DEBUG TRAIN Batch 54/6600 loss 8.925255 loss_att 14.006505 loss_ctc 15.939086 loss_rnnt 6.852162 hw_loss 0.228122 lr 0.00028772 rank 4
2023-03-01 11:17:01,989 DEBUG TRAIN Batch 54/6600 loss 4.442390 loss_att 5.656902 loss_ctc 5.726512 loss_rnnt 3.994030 hw_loss 0.064202 lr 0.00028771 rank 1
2023-03-01 11:17:02,001 DEBUG TRAIN Batch 54/6600 loss 9.864201 loss_att 14.163729 loss_ctc 19.728691 loss_rnnt 7.592268 hw_loss 0.181429 lr 0.00028771 rank 3
2023-03-01 11:17:02,002 DEBUG TRAIN Batch 54/6600 loss 9.673413 loss_att 11.186975 loss_ctc 15.079447 loss_rnnt 8.505961 hw_loss 0.269879 lr 0.00028772 rank 0
2023-03-01 11:17:02,004 DEBUG TRAIN Batch 54/6600 loss 11.496542 loss_att 14.329786 loss_ctc 17.979910 loss_rnnt 10.014616 hw_loss 0.095300 lr 0.00028771 rank 7
2023-03-01 11:17:02,006 DEBUG TRAIN Batch 54/6600 loss 3.011958 loss_att 5.721735 loss_ctc 3.734908 loss_rnnt 2.287366 hw_loss 0.161705 lr 0.00028772 rank 2
2023-03-01 11:17:02,007 DEBUG TRAIN Batch 54/6600 loss 7.526696 loss_att 11.775591 loss_ctc 11.420539 loss_rnnt 6.019889 hw_loss 0.258468 lr 0.00028772 rank 5
2023-03-01 11:17:02,051 DEBUG TRAIN Batch 54/6600 loss 1.699581 loss_att 4.364403 loss_ctc 2.882336 loss_rnnt 0.924268 hw_loss 0.158714 lr 0.00028772 rank 6
2023-03-01 11:17:41,303 DEBUG TRAIN Batch 54/6700 loss 4.860218 loss_att 7.043197 loss_ctc 8.906176 loss_rnnt 3.835557 hw_loss 0.091131 lr 0.00028770 rank 1
2023-03-01 11:17:41,323 DEBUG TRAIN Batch 54/6700 loss 10.627264 loss_att 12.128889 loss_ctc 12.976883 loss_rnnt 9.917252 hw_loss 0.180760 lr 0.00028770 rank 6
2023-03-01 11:17:41,325 DEBUG TRAIN Batch 54/6700 loss 5.109291 loss_att 7.379686 loss_ctc 10.840345 loss_rnnt 3.806493 hw_loss 0.158584 lr 0.00028771 rank 0
2023-03-01 11:17:41,328 DEBUG TRAIN Batch 54/6700 loss 3.838768 loss_att 6.751663 loss_ctc 5.366322 loss_rnnt 2.917394 hw_loss 0.253352 lr 0.00028770 rank 7
2023-03-01 11:17:41,329 DEBUG TRAIN Batch 54/6700 loss 6.642720 loss_att 9.773086 loss_ctc 12.863539 loss_rnnt 5.121246 hw_loss 0.123670 lr 0.00028770 rank 5
2023-03-01 11:17:41,332 DEBUG TRAIN Batch 54/6700 loss 4.286224 loss_att 7.188678 loss_ctc 5.982899 loss_rnnt 3.376570 hw_loss 0.193012 lr 0.00028770 rank 4
2023-03-01 11:17:41,341 DEBUG TRAIN Batch 54/6700 loss 6.752708 loss_att 8.241788 loss_ctc 9.860737 loss_rnnt 5.937190 hw_loss 0.193686 lr 0.00028770 rank 3
2023-03-01 11:17:41,346 DEBUG TRAIN Batch 54/6700 loss 5.956378 loss_att 9.345970 loss_ctc 11.628969 loss_rnnt 4.465247 hw_loss 0.106624 lr 0.00028771 rank 2
2023-03-01 11:18:46,334 DEBUG TRAIN Batch 54/6800 loss 11.235950 loss_att 14.204515 loss_ctc 19.238449 loss_rnnt 9.439925 hw_loss 0.253711 lr 0.00028769 rank 3
2023-03-01 11:18:46,344 DEBUG TRAIN Batch 54/6800 loss 5.987649 loss_att 9.137373 loss_ctc 14.087958 loss_rnnt 4.159175 hw_loss 0.222166 lr 0.00028769 rank 1
2023-03-01 11:18:46,344 DEBUG TRAIN Batch 54/6800 loss 8.713340 loss_att 10.283009 loss_ctc 16.000038 loss_rnnt 7.346080 hw_loss 0.153313 lr 0.00028770 rank 2
2023-03-01 11:18:46,355 DEBUG TRAIN Batch 54/6800 loss 7.723662 loss_att 12.101144 loss_ctc 20.431009 loss_rnnt 5.006103 hw_loss 0.277031 lr 0.00028769 rank 6
2023-03-01 11:18:46,357 DEBUG TRAIN Batch 54/6800 loss 4.461701 loss_att 8.288179 loss_ctc 6.804690 loss_rnnt 3.309557 hw_loss 0.139593 lr 0.00028770 rank 0
2023-03-01 11:18:46,357 DEBUG TRAIN Batch 54/6800 loss 6.374364 loss_att 10.473335 loss_ctc 12.783393 loss_rnnt 4.623794 hw_loss 0.142947 lr 0.00028769 rank 7
2023-03-01 11:18:46,394 DEBUG TRAIN Batch 54/6800 loss 4.796710 loss_att 6.382916 loss_ctc 6.098465 loss_rnnt 4.208485 hw_loss 0.182654 lr 0.00028769 rank 4
2023-03-01 11:18:46,423 DEBUG TRAIN Batch 54/6800 loss 9.302512 loss_att 12.826652 loss_ctc 15.207953 loss_rnnt 7.740355 hw_loss 0.131132 lr 0.00028769 rank 5
2023-03-01 11:19:25,016 DEBUG TRAIN Batch 54/6900 loss 6.099542 loss_att 8.879186 loss_ctc 12.415746 loss_rnnt 4.610899 hw_loss 0.169789 lr 0.00028768 rank 2
2023-03-01 11:19:25,024 DEBUG TRAIN Batch 54/6900 loss 6.509721 loss_att 7.457119 loss_ctc 11.375957 loss_rnnt 5.529010 hw_loss 0.267001 lr 0.00028768 rank 7
2023-03-01 11:19:25,027 DEBUG TRAIN Batch 54/6900 loss 4.629947 loss_att 7.389732 loss_ctc 6.240922 loss_rnnt 3.701505 hw_loss 0.303165 lr 0.00028768 rank 4
2023-03-01 11:19:25,029 DEBUG TRAIN Batch 54/6900 loss 5.953990 loss_att 9.142782 loss_ctc 8.420350 loss_rnnt 4.915657 hw_loss 0.134487 lr 0.00028768 rank 6
2023-03-01 11:19:25,029 DEBUG TRAIN Batch 54/6900 loss 6.371641 loss_att 10.909968 loss_ctc 15.921677 loss_rnnt 4.079406 hw_loss 0.208558 lr 0.00028769 rank 0
2023-03-01 11:19:25,030 DEBUG TRAIN Batch 54/6900 loss 4.153361 loss_att 6.457736 loss_ctc 5.329620 loss_rnnt 3.401139 hw_loss 0.252210 lr 0.00028768 rank 1
2023-03-01 11:19:25,031 DEBUG TRAIN Batch 54/6900 loss 3.569077 loss_att 6.604909 loss_ctc 9.858858 loss_rnnt 1.968023 hw_loss 0.291095 lr 0.00028768 rank 5
2023-03-01 11:19:25,032 DEBUG TRAIN Batch 54/6900 loss 13.293622 loss_att 14.906121 loss_ctc 24.924294 loss_rnnt 11.298313 hw_loss 0.228850 lr 0.00028767 rank 3
2023-03-01 11:20:04,290 DEBUG TRAIN Batch 54/7000 loss 10.487489 loss_att 12.198951 loss_ctc 16.449169 loss_rnnt 9.222086 hw_loss 0.240411 lr 0.00028767 rank 2
2023-03-01 11:20:04,295 DEBUG TRAIN Batch 54/7000 loss 3.178264 loss_att 5.789046 loss_ctc 3.980148 loss_rnnt 2.407283 hw_loss 0.266075 lr 0.00028767 rank 7
2023-03-01 11:20:04,297 DEBUG TRAIN Batch 54/7000 loss 6.459362 loss_att 8.017795 loss_ctc 12.293920 loss_rnnt 5.229783 hw_loss 0.262408 lr 0.00028767 rank 4
2023-03-01 11:20:04,297 DEBUG TRAIN Batch 54/7000 loss 4.320781 loss_att 5.278050 loss_ctc 6.812024 loss_rnnt 3.616374 hw_loss 0.338977 lr 0.00028767 rank 6
2023-03-01 11:20:04,301 DEBUG TRAIN Batch 54/7000 loss 7.605658 loss_att 9.587956 loss_ctc 12.418351 loss_rnnt 6.424908 hw_loss 0.267370 lr 0.00028767 rank 0
2023-03-01 11:20:04,303 DEBUG TRAIN Batch 54/7000 loss 7.327342 loss_att 8.447751 loss_ctc 11.690231 loss_rnnt 6.319467 hw_loss 0.378889 lr 0.00028766 rank 3
2023-03-01 11:20:04,309 DEBUG TRAIN Batch 54/7000 loss 6.181207 loss_att 7.246466 loss_ctc 9.163135 loss_rnnt 5.400011 hw_loss 0.319789 lr 0.00028767 rank 1
2023-03-01 11:20:04,326 DEBUG TRAIN Batch 54/7000 loss 7.420768 loss_att 7.911217 loss_ctc 14.022810 loss_rnnt 6.404134 hw_loss 0.071761 lr 0.00028767 rank 5
2023-03-01 11:21:08,897 DEBUG TRAIN Batch 54/7100 loss 5.449139 loss_att 8.054721 loss_ctc 8.061995 loss_rnnt 4.485323 hw_loss 0.176847 lr 0.00028766 rank 4
2023-03-01 11:21:08,912 DEBUG TRAIN Batch 54/7100 loss 7.611402 loss_att 10.120090 loss_ctc 11.021953 loss_rnnt 6.545131 hw_loss 0.205861 lr 0.00028765 rank 7
2023-03-01 11:21:08,914 DEBUG TRAIN Batch 54/7100 loss 7.783824 loss_att 12.655704 loss_ctc 16.751257 loss_rnnt 5.534887 hw_loss 0.147944 lr 0.00028765 rank 1
2023-03-01 11:21:08,917 DEBUG TRAIN Batch 54/7100 loss 9.903836 loss_att 9.923605 loss_ctc 13.611980 loss_rnnt 9.210041 hw_loss 0.366415 lr 0.00028766 rank 0
2023-03-01 11:21:08,918 DEBUG TRAIN Batch 54/7100 loss 2.786784 loss_att 6.935949 loss_ctc 7.256992 loss_rnnt 1.359468 hw_loss 0.002729 lr 0.00028765 rank 3
2023-03-01 11:21:08,919 DEBUG TRAIN Batch 54/7100 loss 5.285631 loss_att 8.290566 loss_ctc 7.716812 loss_rnnt 4.335599 hw_loss 0.046664 lr 0.00028766 rank 5
2023-03-01 11:21:08,958 DEBUG TRAIN Batch 54/7100 loss 5.211739 loss_att 7.700614 loss_ctc 6.246049 loss_rnnt 4.480682 hw_loss 0.178827 lr 0.00028766 rank 2
2023-03-01 11:21:09,004 DEBUG TRAIN Batch 54/7100 loss 7.261464 loss_att 7.744376 loss_ctc 11.706965 loss_rnnt 6.407142 hw_loss 0.309386 lr 0.00028766 rank 6
2023-03-01 11:21:48,539 DEBUG TRAIN Batch 54/7200 loss 2.106343 loss_att 4.034915 loss_ctc 2.788401 loss_rnnt 1.533928 hw_loss 0.179550 lr 0.00028764 rank 4
2023-03-01 11:21:48,555 DEBUG TRAIN Batch 54/7200 loss 7.487775 loss_att 10.212524 loss_ctc 14.287762 loss_rnnt 5.924304 hw_loss 0.209730 lr 0.00028765 rank 2
2023-03-01 11:21:48,558 DEBUG TRAIN Batch 54/7200 loss 4.830447 loss_att 7.788757 loss_ctc 12.411497 loss_rnnt 3.067000 hw_loss 0.301833 lr 0.00028765 rank 0
2023-03-01 11:21:48,560 DEBUG TRAIN Batch 54/7200 loss 5.529424 loss_att 7.203054 loss_ctc 8.400911 loss_rnnt 4.719605 hw_loss 0.172926 lr 0.00028764 rank 7
2023-03-01 11:21:48,561 DEBUG TRAIN Batch 54/7200 loss 3.091254 loss_att 5.834983 loss_ctc 4.992125 loss_rnnt 2.229659 hw_loss 0.111375 lr 0.00028764 rank 6
2023-03-01 11:21:48,562 DEBUG TRAIN Batch 54/7200 loss 10.561556 loss_att 13.376309 loss_ctc 15.698741 loss_rnnt 9.262411 hw_loss 0.096066 lr 0.00028764 rank 1
2023-03-01 11:21:48,565 DEBUG TRAIN Batch 54/7200 loss 5.368248 loss_att 7.793419 loss_ctc 6.702380 loss_rnnt 4.534554 hw_loss 0.320203 lr 0.00028764 rank 5
2023-03-01 11:21:48,607 DEBUG TRAIN Batch 54/7200 loss 1.933627 loss_att 3.988729 loss_ctc 2.330762 loss_rnnt 1.374187 hw_loss 0.179004 lr 0.00028764 rank 3
2023-03-01 11:22:26,997 DEBUG TRAIN Batch 54/7300 loss 4.895883 loss_att 8.969975 loss_ctc 11.000290 loss_rnnt 3.155655 hw_loss 0.209042 lr 0.00028763 rank 5
2023-03-01 11:22:27,005 DEBUG TRAIN Batch 54/7300 loss 3.349376 loss_att 5.287146 loss_ctc 6.729983 loss_rnnt 2.349888 hw_loss 0.302226 lr 0.00028764 rank 0
2023-03-01 11:22:27,006 DEBUG TRAIN Batch 54/7300 loss 5.570178 loss_att 9.406057 loss_ctc 8.998682 loss_rnnt 4.250653 hw_loss 0.178529 lr 0.00028763 rank 7
2023-03-01 11:22:27,014 DEBUG TRAIN Batch 54/7300 loss 7.125827 loss_att 9.621208 loss_ctc 9.882733 loss_rnnt 6.201530 hw_loss 0.108063 lr 0.00028764 rank 2
2023-03-01 11:22:27,013 DEBUG TRAIN Batch 54/7300 loss 12.362246 loss_att 15.883432 loss_ctc 19.949617 loss_rnnt 10.491733 hw_loss 0.289924 lr 0.00028763 rank 6
2023-03-01 11:22:27,018 DEBUG TRAIN Batch 54/7300 loss 9.535032 loss_att 12.725381 loss_ctc 16.694225 loss_rnnt 7.847603 hw_loss 0.177751 lr 0.00028763 rank 3
2023-03-01 11:22:27,041 DEBUG TRAIN Batch 54/7300 loss 5.320807 loss_att 8.861691 loss_ctc 8.574198 loss_rnnt 4.067189 hw_loss 0.209355 lr 0.00028763 rank 4
2023-03-01 11:22:27,051 DEBUG TRAIN Batch 54/7300 loss 6.066093 loss_att 10.849152 loss_ctc 12.251066 loss_rnnt 4.143712 hw_loss 0.264574 lr 0.00028763 rank 1
2023-03-01 11:23:06,375 DEBUG TRAIN Batch 54/7400 loss 2.881462 loss_att 5.044736 loss_ctc 6.115657 loss_rnnt 1.887073 hw_loss 0.244702 lr 0.00028762 rank 3
2023-03-01 11:23:06,375 DEBUG TRAIN Batch 54/7400 loss 5.279111 loss_att 9.032148 loss_ctc 6.372061 loss_rnnt 4.302681 hw_loss 0.150180 lr 0.00028762 rank 5
2023-03-01 11:23:06,381 DEBUG TRAIN Batch 54/7400 loss 4.514121 loss_att 8.910882 loss_ctc 7.466816 loss_rnnt 3.107196 hw_loss 0.251024 lr 0.00028762 rank 7
2023-03-01 11:23:06,384 DEBUG TRAIN Batch 54/7400 loss 5.350718 loss_att 7.406962 loss_ctc 6.275607 loss_rnnt 4.668414 hw_loss 0.277004 lr 0.00028763 rank 0
2023-03-01 11:23:06,388 DEBUG TRAIN Batch 54/7400 loss 13.484399 loss_att 18.909727 loss_ctc 27.235918 loss_rnnt 10.519057 hw_loss 0.087637 lr 0.00028762 rank 4
2023-03-01 11:23:06,397 DEBUG TRAIN Batch 54/7400 loss 7.893295 loss_att 10.236826 loss_ctc 11.672967 loss_rnnt 6.803797 hw_loss 0.219066 lr 0.00028762 rank 6
2023-03-01 11:23:06,417 DEBUG TRAIN Batch 54/7400 loss 6.620179 loss_att 9.964385 loss_ctc 12.468777 loss_rnnt 5.041184 hw_loss 0.244387 lr 0.00028762 rank 1
2023-03-01 11:23:06,424 DEBUG TRAIN Batch 54/7400 loss 7.715881 loss_att 8.502923 loss_ctc 8.756487 loss_rnnt 7.346929 hw_loss 0.136494 lr 0.00028762 rank 2
2023-03-01 11:24:11,643 DEBUG TRAIN Batch 54/7500 loss 6.952793 loss_att 11.061425 loss_ctc 11.548586 loss_rnnt 5.356659 hw_loss 0.303064 lr 0.00028761 rank 4
2023-03-01 11:24:11,657 DEBUG TRAIN Batch 54/7500 loss 3.284714 loss_att 6.027760 loss_ctc 5.885201 loss_rnnt 2.288388 hw_loss 0.189346 lr 0.00028762 rank 0
2023-03-01 11:24:11,657 DEBUG TRAIN Batch 54/7500 loss 2.781856 loss_att 4.362013 loss_ctc 5.879843 loss_rnnt 1.947150 hw_loss 0.198020 lr 0.00028761 rank 7
2023-03-01 11:24:11,658 DEBUG TRAIN Batch 54/7500 loss 8.006896 loss_att 13.036495 loss_ctc 15.533499 loss_rnnt 5.857986 hw_loss 0.261456 lr 0.00028760 rank 3
2023-03-01 11:24:11,660 DEBUG TRAIN Batch 54/7500 loss 5.233470 loss_att 6.833645 loss_ctc 9.722553 loss_rnnt 4.160271 hw_loss 0.289912 lr 0.00028761 rank 2
2023-03-01 11:24:11,661 DEBUG TRAIN Batch 54/7500 loss 3.368701 loss_att 6.184038 loss_ctc 7.930130 loss_rnnt 2.181916 hw_loss 0.029113 lr 0.00028761 rank 1
2023-03-01 11:24:11,663 DEBUG TRAIN Batch 54/7500 loss 4.701803 loss_att 7.323214 loss_ctc 7.329677 loss_rnnt 3.674832 hw_loss 0.285573 lr 0.00028761 rank 6
2023-03-01 11:24:11,711 DEBUG TRAIN Batch 54/7500 loss 7.101333 loss_att 8.810458 loss_ctc 10.910185 loss_rnnt 6.100294 hw_loss 0.283812 lr 0.00028761 rank 5
2023-03-01 11:24:50,661 DEBUG TRAIN Batch 54/7600 loss 6.489661 loss_att 8.893021 loss_ctc 11.265745 loss_rnnt 5.251932 hw_loss 0.225459 lr 0.00028760 rank 1
2023-03-01 11:24:50,679 DEBUG TRAIN Batch 54/7600 loss 4.532437 loss_att 6.786737 loss_ctc 7.266704 loss_rnnt 3.583404 hw_loss 0.250507 lr 0.00028760 rank 0
2023-03-01 11:24:50,680 DEBUG TRAIN Batch 54/7600 loss 5.900225 loss_att 7.261571 loss_ctc 7.668691 loss_rnnt 5.265281 hw_loss 0.237897 lr 0.00028760 rank 4
2023-03-01 11:24:50,684 DEBUG TRAIN Batch 54/7600 loss 2.945578 loss_att 5.549976 loss_ctc 6.564467 loss_rnnt 1.846095 hw_loss 0.180159 lr 0.00028760 rank 6
2023-03-01 11:24:50,684 DEBUG TRAIN Batch 54/7600 loss 7.005456 loss_att 10.841892 loss_ctc 7.962006 loss_rnnt 6.033864 hw_loss 0.143935 lr 0.00028759 rank 7
2023-03-01 11:24:50,684 DEBUG TRAIN Batch 54/7600 loss 6.886011 loss_att 7.582625 loss_ctc 9.512337 loss_rnnt 6.262237 hw_loss 0.251765 lr 0.00028760 rank 5
2023-03-01 11:24:50,685 DEBUG TRAIN Batch 54/7600 loss 4.381188 loss_att 4.694364 loss_ctc 5.628172 loss_rnnt 3.958466 hw_loss 0.363418 lr 0.00028759 rank 3
2023-03-01 11:24:50,688 DEBUG TRAIN Batch 54/7600 loss 4.774466 loss_att 6.363345 loss_ctc 7.924079 loss_rnnt 3.925116 hw_loss 0.209298 lr 0.00028760 rank 2
2023-03-01 11:25:29,716 DEBUG TRAIN Batch 54/7700 loss 6.375782 loss_att 13.797243 loss_ctc 10.911898 loss_rnnt 4.183105 hw_loss 0.194192 lr 0.00028758 rank 3
2023-03-01 11:25:29,722 DEBUG TRAIN Batch 54/7700 loss 11.104138 loss_att 15.181705 loss_ctc 18.596016 loss_rnnt 9.217796 hw_loss 0.134833 lr 0.00028758 rank 5
2023-03-01 11:25:29,727 DEBUG TRAIN Batch 54/7700 loss 6.287321 loss_att 8.883036 loss_ctc 8.147549 loss_rnnt 5.414651 hw_loss 0.197806 lr 0.00028758 rank 7
2023-03-01 11:25:29,729 DEBUG TRAIN Batch 54/7700 loss 8.086036 loss_att 10.719544 loss_ctc 15.459002 loss_rnnt 6.448291 hw_loss 0.239963 lr 0.00028759 rank 0
2023-03-01 11:25:29,732 DEBUG TRAIN Batch 54/7700 loss 2.316691 loss_att 5.274212 loss_ctc 6.171041 loss_rnnt 1.022036 hw_loss 0.354821 lr 0.00028758 rank 1
2023-03-01 11:25:29,760 DEBUG TRAIN Batch 54/7700 loss 10.538506 loss_att 12.730700 loss_ctc 16.652855 loss_rnnt 9.183352 hw_loss 0.190253 lr 0.00028758 rank 6
2023-03-01 11:25:29,767 DEBUG TRAIN Batch 54/7700 loss 3.809696 loss_att 5.349276 loss_ctc 6.703123 loss_rnnt 3.090704 hw_loss 0.047411 lr 0.00028759 rank 2
2023-03-01 11:25:29,780 DEBUG TRAIN Batch 54/7700 loss 2.554361 loss_att 6.164941 loss_ctc 4.974421 loss_rnnt 1.413623 hw_loss 0.179902 lr 0.00028759 rank 4
2023-03-01 11:26:09,876 DEBUG TRAIN Batch 54/7800 loss 3.004749 loss_att 5.272694 loss_ctc 4.950405 loss_rnnt 2.137556 hw_loss 0.289093 lr 0.00028757 rank 7
2023-03-01 11:26:09,878 DEBUG TRAIN Batch 54/7800 loss 1.596734 loss_att 5.735819 loss_ctc 2.627107 loss_rnnt 0.530638 hw_loss 0.189178 lr 0.00028758 rank 0
2023-03-01 11:26:09,880 DEBUG TRAIN Batch 54/7800 loss 5.358803 loss_att 8.394368 loss_ctc 8.965961 loss_rnnt 4.202717 hw_loss 0.127535 lr 0.00028757 rank 6
2023-03-01 11:26:09,891 DEBUG TRAIN Batch 54/7800 loss 1.511965 loss_att 3.983796 loss_ctc 1.864068 loss_rnnt 0.878270 hw_loss 0.173215 lr 0.00028757 rank 3
2023-03-01 11:26:09,894 DEBUG TRAIN Batch 54/7800 loss 10.409678 loss_att 14.143907 loss_ctc 17.716270 loss_rnnt 8.615344 hw_loss 0.137392 lr 0.00028758 rank 2
2023-03-01 11:26:09,898 DEBUG TRAIN Batch 54/7800 loss 7.568253 loss_att 11.417007 loss_ctc 15.589043 loss_rnnt 5.602698 hw_loss 0.236934 lr 0.00028757 rank 1
2023-03-01 11:26:09,905 DEBUG TRAIN Batch 54/7800 loss 9.891006 loss_att 11.959204 loss_ctc 14.624338 loss_rnnt 8.740626 hw_loss 0.198055 lr 0.00028757 rank 5
2023-03-01 11:26:09,915 DEBUG TRAIN Batch 54/7800 loss 4.220232 loss_att 6.409814 loss_ctc 5.901293 loss_rnnt 3.474701 hw_loss 0.156513 lr 0.00028757 rank 4
2023-03-01 11:27:14,415 DEBUG TRAIN Batch 54/7900 loss 2.371361 loss_att 5.778415 loss_ctc 4.499692 loss_rnnt 1.329599 hw_loss 0.143578 lr 0.00028756 rank 5
2023-03-01 11:27:14,414 DEBUG TRAIN Batch 54/7900 loss 1.794363 loss_att 4.933023 loss_ctc 3.378447 loss_rnnt 0.843432 hw_loss 0.209976 lr 0.00028757 rank 0
2023-03-01 11:27:14,415 DEBUG TRAIN Batch 54/7900 loss 5.755791 loss_att 9.097928 loss_ctc 8.250473 loss_rnnt 4.664819 hw_loss 0.168600 lr 0.00028756 rank 7
2023-03-01 11:27:14,416 DEBUG TRAIN Batch 54/7900 loss 9.133829 loss_att 11.097072 loss_ctc 14.031569 loss_rnnt 8.013493 hw_loss 0.139981 lr 0.00028756 rank 4
2023-03-01 11:27:14,417 DEBUG TRAIN Batch 54/7900 loss 9.035107 loss_att 12.030134 loss_ctc 15.665474 loss_rnnt 7.352106 hw_loss 0.374899 lr 0.00028756 rank 3
2023-03-01 11:27:14,423 DEBUG TRAIN Batch 54/7900 loss 12.316671 loss_att 14.186598 loss_ctc 15.514697 loss_rnnt 11.378916 hw_loss 0.257561 lr 0.00028756 rank 1
2023-03-01 11:27:14,424 DEBUG TRAIN Batch 54/7900 loss 3.079636 loss_att 5.470971 loss_ctc 2.734756 loss_rnnt 2.582949 hw_loss 0.120757 lr 0.00028756 rank 2
2023-03-01 11:27:14,463 DEBUG TRAIN Batch 54/7900 loss 6.256867 loss_att 10.309093 loss_ctc 11.067569 loss_rnnt 4.727357 hw_loss 0.145570 lr 0.00028756 rank 6
2023-03-01 11:27:53,514 DEBUG TRAIN Batch 54/8000 loss 3.198421 loss_att 7.444149 loss_ctc 7.110638 loss_rnnt 1.693941 hw_loss 0.250698 lr 0.00028755 rank 2
2023-03-01 11:27:53,519 DEBUG TRAIN Batch 54/8000 loss 11.729497 loss_att 13.836582 loss_ctc 19.153316 loss_rnnt 10.227805 hw_loss 0.169562 lr 0.00028755 rank 5
2023-03-01 11:27:53,529 DEBUG TRAIN Batch 54/8000 loss 6.942027 loss_att 12.728765 loss_ctc 13.343947 loss_rnnt 4.771059 hw_loss 0.300060 lr 0.00028756 rank 0
2023-03-01 11:27:53,532 DEBUG TRAIN Batch 54/8000 loss 8.446751 loss_att 9.222177 loss_ctc 11.889430 loss_rnnt 7.701098 hw_loss 0.246645 lr 0.00028755 rank 7
2023-03-01 11:27:53,532 DEBUG TRAIN Batch 54/8000 loss 7.243369 loss_att 8.174915 loss_ctc 8.666613 loss_rnnt 6.747446 hw_loss 0.224715 lr 0.00028754 rank 3
2023-03-01 11:27:53,535 DEBUG TRAIN Batch 54/8000 loss 2.744634 loss_att 6.643562 loss_ctc 4.833359 loss_rnnt 1.665307 hw_loss 0.039460 lr 0.00028755 rank 6
2023-03-01 11:27:53,538 DEBUG TRAIN Batch 54/8000 loss 9.036127 loss_att 10.585109 loss_ctc 13.153340 loss_rnnt 8.035132 hw_loss 0.266693 lr 0.00028755 rank 1
2023-03-01 11:27:53,544 DEBUG TRAIN Batch 54/8000 loss 7.480856 loss_att 10.071033 loss_ctc 18.406687 loss_rnnt 5.318803 hw_loss 0.351075 lr 0.00028755 rank 4
2023-03-01 11:28:33,016 DEBUG TRAIN Batch 54/8100 loss 2.232334 loss_att 5.340786 loss_ctc 5.461776 loss_rnnt 1.114316 hw_loss 0.123254 lr 0.00028754 rank 6
2023-03-01 11:28:33,019 DEBUG TRAIN Batch 54/8100 loss 4.074429 loss_att 9.758504 loss_ctc 13.454536 loss_rnnt 1.558839 hw_loss 0.240174 lr 0.00028754 rank 5
2023-03-01 11:28:33,026 DEBUG TRAIN Batch 54/8100 loss 2.679204 loss_att 6.245130 loss_ctc 5.074850 loss_rnnt 1.545946 hw_loss 0.188725 lr 0.00028754 rank 0
2023-03-01 11:28:33,029 DEBUG TRAIN Batch 54/8100 loss 4.362022 loss_att 8.007004 loss_ctc 7.170827 loss_rnnt 3.121848 hw_loss 0.256256 lr 0.00028754 rank 2
2023-03-01 11:28:33,032 DEBUG TRAIN Batch 54/8100 loss 5.456501 loss_att 10.059341 loss_ctc 11.990318 loss_rnnt 3.543320 hw_loss 0.227695 lr 0.00028754 rank 4
2023-03-01 11:28:33,032 DEBUG TRAIN Batch 54/8100 loss 8.536889 loss_att 12.531421 loss_ctc 13.959924 loss_rnnt 6.839940 hw_loss 0.328070 lr 0.00028754 rank 1
2023-03-01 11:28:33,038 DEBUG TRAIN Batch 54/8100 loss 6.867901 loss_att 13.468933 loss_ctc 9.981299 loss_rnnt 5.085863 hw_loss 0.087586 lr 0.00028753 rank 3
2023-03-01 11:28:33,044 DEBUG TRAIN Batch 54/8100 loss 3.573608 loss_att 4.775732 loss_ctc 5.949695 loss_rnnt 2.872037 hw_loss 0.270628 lr 0.00028754 rank 7
2023-03-01 11:29:13,102 DEBUG TRAIN Batch 54/8200 loss 6.107644 loss_att 11.583157 loss_ctc 13.722240 loss_rnnt 3.861032 hw_loss 0.255433 lr 0.00028752 rank 6
2023-03-01 11:29:13,103 DEBUG TRAIN Batch 54/8200 loss 5.577672 loss_att 8.680193 loss_ctc 6.471794 loss_rnnt 4.711002 hw_loss 0.238030 lr 0.00028752 rank 7
2023-03-01 11:29:13,110 DEBUG TRAIN Batch 54/8200 loss 6.826159 loss_att 8.626366 loss_ctc 15.040610 loss_rnnt 5.254397 hw_loss 0.218364 lr 0.00028752 rank 3
2023-03-01 11:29:13,116 DEBUG TRAIN Batch 54/8200 loss 1.136648 loss_att 2.875097 loss_ctc 1.613411 loss_rnnt 0.601631 hw_loss 0.232046 lr 0.00028753 rank 0
2023-03-01 11:29:13,116 DEBUG TRAIN Batch 54/8200 loss 4.355552 loss_att 6.323805 loss_ctc 7.555190 loss_rnnt 3.435152 hw_loss 0.187746 lr 0.00028752 rank 5
2023-03-01 11:29:13,117 DEBUG TRAIN Batch 54/8200 loss 8.004805 loss_att 10.367743 loss_ctc 15.783046 loss_rnnt 6.372982 hw_loss 0.229005 lr 0.00028753 rank 4
2023-03-01 11:29:13,122 DEBUG TRAIN Batch 54/8200 loss 11.692461 loss_att 14.772507 loss_ctc 23.230057 loss_rnnt 9.430084 hw_loss 0.202541 lr 0.00028752 rank 1
2023-03-01 11:29:13,170 DEBUG TRAIN Batch 54/8200 loss 6.421218 loss_att 9.139242 loss_ctc 11.152753 loss_rnnt 5.130932 hw_loss 0.217144 lr 0.00028753 rank 2
2023-03-01 11:29:51,403 DEBUG TRAIN Batch 54/8300 loss 3.708139 loss_att 7.102655 loss_ctc 6.131254 loss_rnnt 2.561493 hw_loss 0.271237 lr 0.00028751 rank 3
2023-03-01 11:29:51,403 DEBUG TRAIN Batch 54/8300 loss 5.907552 loss_att 9.844532 loss_ctc 10.786469 loss_rnnt 4.342834 hw_loss 0.237748 lr 0.00028751 rank 5
2023-03-01 11:29:51,407 DEBUG TRAIN Batch 54/8300 loss 3.292375 loss_att 5.845197 loss_ctc 4.420246 loss_rnnt 2.558957 hw_loss 0.135883 lr 0.00028751 rank 1
2023-03-01 11:29:51,408 DEBUG TRAIN Batch 54/8300 loss 4.256636 loss_att 8.547668 loss_ctc 8.529279 loss_rnnt 2.672798 hw_loss 0.292398 lr 0.00028751 rank 6
2023-03-01 11:29:51,419 DEBUG TRAIN Batch 54/8300 loss 4.572792 loss_att 10.298248 loss_ctc 14.405838 loss_rnnt 2.055285 hw_loss 0.115018 lr 0.00028751 rank 7
2023-03-01 11:29:51,420 DEBUG TRAIN Batch 54/8300 loss 9.930528 loss_att 12.891843 loss_ctc 18.261749 loss_rnnt 8.169535 hw_loss 0.108561 lr 0.00028752 rank 0
2023-03-01 11:29:51,428 DEBUG TRAIN Batch 54/8300 loss 2.463166 loss_att 5.570992 loss_ctc 2.472720 loss_rnnt 1.748307 hw_loss 0.172539 lr 0.00028752 rank 2
2023-03-01 11:29:51,479 DEBUG TRAIN Batch 54/8300 loss 3.868927 loss_att 7.349964 loss_ctc 6.156186 loss_rnnt 2.720925 hw_loss 0.275298 lr 0.00028751 rank 4
2023-03-01 11:30:18,785 DEBUG CV Batch 54/0 loss 0.971755 loss_att 0.876345 loss_ctc 1.651875 loss_rnnt 0.682093 hw_loss 0.408866 history loss 0.935764 rank 7
2023-03-01 11:30:18,791 DEBUG CV Batch 54/0 loss 0.971755 loss_att 0.876345 loss_ctc 1.651875 loss_rnnt 0.682093 hw_loss 0.408866 history loss 0.935764 rank 2
2023-03-01 11:30:18,793 DEBUG CV Batch 54/0 loss 0.971755 loss_att 0.876345 loss_ctc 1.651875 loss_rnnt 0.682093 hw_loss 0.408866 history loss 0.935764 rank 1
2023-03-01 11:30:18,794 DEBUG CV Batch 54/0 loss 0.971755 loss_att 0.876345 loss_ctc 1.651875 loss_rnnt 0.682093 hw_loss 0.408866 history loss 0.935764 rank 5
2023-03-01 11:30:18,797 DEBUG CV Batch 54/0 loss 0.971755 loss_att 0.876345 loss_ctc 1.651875 loss_rnnt 0.682093 hw_loss 0.408866 history loss 0.935764 rank 4
2023-03-01 11:30:18,804 DEBUG CV Batch 54/0 loss 0.971755 loss_att 0.876345 loss_ctc 1.651875 loss_rnnt 0.682093 hw_loss 0.408866 history loss 0.935764 rank 3
2023-03-01 11:30:18,805 DEBUG CV Batch 54/0 loss 0.971755 loss_att 0.876345 loss_ctc 1.651875 loss_rnnt 0.682093 hw_loss 0.408866 history loss 0.935764 rank 0
2023-03-01 11:30:18,810 DEBUG CV Batch 54/0 loss 0.971755 loss_att 0.876345 loss_ctc 1.651875 loss_rnnt 0.682093 hw_loss 0.408866 history loss 0.935764 rank 6
2023-03-01 11:30:30,061 DEBUG CV Batch 54/100 loss 2.770218 loss_att 4.076150 loss_ctc 7.650514 loss_rnnt 1.745810 hw_loss 0.210966 history loss 2.961008 rank 4
2023-03-01 11:30:30,149 DEBUG CV Batch 54/100 loss 2.770218 loss_att 4.076150 loss_ctc 7.650514 loss_rnnt 1.745810 hw_loss 0.210966 history loss 2.961008 rank 2
2023-03-01 11:30:30,224 DEBUG CV Batch 54/100 loss 2.770218 loss_att 4.076150 loss_ctc 7.650514 loss_rnnt 1.745810 hw_loss 0.210966 history loss 2.961008 rank 6
2023-03-01 11:30:30,432 DEBUG CV Batch 54/100 loss 2.770218 loss_att 4.076150 loss_ctc 7.650514 loss_rnnt 1.745810 hw_loss 0.210966 history loss 2.961008 rank 1
2023-03-01 11:30:30,460 DEBUG CV Batch 54/100 loss 2.770218 loss_att 4.076150 loss_ctc 7.650514 loss_rnnt 1.745810 hw_loss 0.210966 history loss 2.961008 rank 3
2023-03-01 11:30:30,531 DEBUG CV Batch 54/100 loss 2.770218 loss_att 4.076150 loss_ctc 7.650514 loss_rnnt 1.745810 hw_loss 0.210966 history loss 2.961008 rank 5
2023-03-01 11:30:30,575 DEBUG CV Batch 54/100 loss 2.770218 loss_att 4.076150 loss_ctc 7.650514 loss_rnnt 1.745810 hw_loss 0.210966 history loss 2.961008 rank 7
2023-03-01 11:30:30,668 DEBUG CV Batch 54/100 loss 2.770218 loss_att 4.076150 loss_ctc 7.650514 loss_rnnt 1.745810 hw_loss 0.210966 history loss 2.961008 rank 0
2023-03-01 11:30:43,435 DEBUG CV Batch 54/200 loss 3.401097 loss_att 7.506905 loss_ctc 6.016945 loss_rnnt 2.182575 hw_loss 0.091088 history loss 3.541468 rank 4
2023-03-01 11:30:43,709 DEBUG CV Batch 54/200 loss 3.401097 loss_att 7.506905 loss_ctc 6.016945 loss_rnnt 2.182575 hw_loss 0.091088 history loss 3.541468 rank 6
2023-03-01 11:30:43,917 DEBUG CV Batch 54/200 loss 3.401097 loss_att 7.506905 loss_ctc 6.016945 loss_rnnt 2.182575 hw_loss 0.091088 history loss 3.541468 rank 5
2023-03-01 11:30:44,228 DEBUG CV Batch 54/200 loss 3.401097 loss_att 7.506905 loss_ctc 6.016945 loss_rnnt 2.182575 hw_loss 0.091088 history loss 3.541468 rank 3
2023-03-01 11:30:44,233 DEBUG CV Batch 54/200 loss 3.401097 loss_att 7.506905 loss_ctc 6.016945 loss_rnnt 2.182575 hw_loss 0.091088 history loss 3.541468 rank 2
2023-03-01 11:30:44,359 DEBUG CV Batch 54/200 loss 3.401097 loss_att 7.506905 loss_ctc 6.016945 loss_rnnt 2.182575 hw_loss 0.091088 history loss 3.541468 rank 1
2023-03-01 11:30:44,450 DEBUG CV Batch 54/200 loss 3.401097 loss_att 7.506905 loss_ctc 6.016945 loss_rnnt 2.182575 hw_loss 0.091088 history loss 3.541468 rank 7
2023-03-01 11:30:44,648 DEBUG CV Batch 54/200 loss 3.401097 loss_att 7.506905 loss_ctc 6.016945 loss_rnnt 2.182575 hw_loss 0.091088 history loss 3.541468 rank 0
2023-03-01 11:30:55,907 DEBUG CV Batch 54/300 loss 2.780717 loss_att 3.563743 loss_ctc 5.225020 loss_rnnt 2.127978 hw_loss 0.319174 history loss 3.683835 rank 4
2023-03-01 11:30:56,315 DEBUG CV Batch 54/300 loss 2.780717 loss_att 3.563743 loss_ctc 5.225020 loss_rnnt 2.127978 hw_loss 0.319174 history loss 3.683835 rank 6
2023-03-01 11:30:56,370 DEBUG CV Batch 54/300 loss 2.780717 loss_att 3.563743 loss_ctc 5.225020 loss_rnnt 2.127978 hw_loss 0.319174 history loss 3.683835 rank 5
2023-03-01 11:30:56,706 DEBUG CV Batch 54/300 loss 2.780717 loss_att 3.563743 loss_ctc 5.225020 loss_rnnt 2.127978 hw_loss 0.319174 history loss 3.683835 rank 2
2023-03-01 11:30:56,871 DEBUG CV Batch 54/300 loss 2.780717 loss_att 3.563743 loss_ctc 5.225020 loss_rnnt 2.127978 hw_loss 0.319174 history loss 3.683835 rank 7
2023-03-01 11:30:57,021 DEBUG CV Batch 54/300 loss 2.780717 loss_att 3.563743 loss_ctc 5.225020 loss_rnnt 2.127978 hw_loss 0.319174 history loss 3.683835 rank 1
2023-03-01 11:30:57,361 DEBUG CV Batch 54/300 loss 2.780717 loss_att 3.563743 loss_ctc 5.225020 loss_rnnt 2.127978 hw_loss 0.319174 history loss 3.683835 rank 3
2023-03-01 11:30:57,475 DEBUG CV Batch 54/300 loss 2.780717 loss_att 3.563743 loss_ctc 5.225020 loss_rnnt 2.127978 hw_loss 0.319174 history loss 3.683835 rank 0
2023-03-01 11:31:07,978 DEBUG CV Batch 54/400 loss 16.733147 loss_att 60.683571 loss_ctc 10.920500 loss_rnnt 8.602606 hw_loss 0.216515 history loss 4.440551 rank 4
2023-03-01 11:31:08,444 DEBUG CV Batch 54/400 loss 16.733147 loss_att 60.683571 loss_ctc 10.920500 loss_rnnt 8.602606 hw_loss 0.216515 history loss 4.440551 rank 6
2023-03-01 11:31:08,488 DEBUG CV Batch 54/400 loss 16.733147 loss_att 60.683571 loss_ctc 10.920500 loss_rnnt 8.602606 hw_loss 0.216515 history loss 4.440551 rank 5
2023-03-01 11:31:08,953 DEBUG CV Batch 54/400 loss 16.733147 loss_att 60.683571 loss_ctc 10.920500 loss_rnnt 8.602606 hw_loss 0.216515 history loss 4.440551 rank 2
2023-03-01 11:31:09,542 DEBUG CV Batch 54/400 loss 16.733147 loss_att 60.683571 loss_ctc 10.920500 loss_rnnt 8.602606 hw_loss 0.216515 history loss 4.440551 rank 7
2023-03-01 11:31:09,567 DEBUG CV Batch 54/400 loss 16.733147 loss_att 60.683571 loss_ctc 10.920500 loss_rnnt 8.602606 hw_loss 0.216515 history loss 4.440551 rank 1
2023-03-01 11:31:09,727 DEBUG CV Batch 54/400 loss 16.733147 loss_att 60.683571 loss_ctc 10.920500 loss_rnnt 8.602606 hw_loss 0.216515 history loss 4.440551 rank 3
2023-03-01 11:31:10,264 DEBUG CV Batch 54/400 loss 16.733147 loss_att 60.683571 loss_ctc 10.920500 loss_rnnt 8.602606 hw_loss 0.216515 history loss 4.440551 rank 0
2023-03-01 11:31:19,291 DEBUG CV Batch 54/500 loss 3.270610 loss_att 3.865620 loss_ctc 4.640950 loss_rnnt 2.885848 hw_loss 0.155715 history loss 5.047889 rank 4
2023-03-01 11:31:19,494 DEBUG CV Batch 54/500 loss 3.270610 loss_att 3.865620 loss_ctc 4.640950 loss_rnnt 2.885848 hw_loss 0.155715 history loss 5.047889 rank 6
2023-03-01 11:31:19,580 DEBUG CV Batch 54/500 loss 3.270610 loss_att 3.865620 loss_ctc 4.640950 loss_rnnt 2.885848 hw_loss 0.155715 history loss 5.047889 rank 5
2023-03-01 11:31:19,897 DEBUG CV Batch 54/500 loss 3.270610 loss_att 3.865620 loss_ctc 4.640950 loss_rnnt 2.885848 hw_loss 0.155715 history loss 5.047889 rank 2
2023-03-01 11:31:20,658 DEBUG CV Batch 54/500 loss 3.270610 loss_att 3.865620 loss_ctc 4.640950 loss_rnnt 2.885848 hw_loss 0.155715 history loss 5.047889 rank 7
2023-03-01 11:31:20,729 DEBUG CV Batch 54/500 loss 3.270610 loss_att 3.865620 loss_ctc 4.640950 loss_rnnt 2.885848 hw_loss 0.155715 history loss 5.047889 rank 1
2023-03-01 11:31:20,875 DEBUG CV Batch 54/500 loss 3.270610 loss_att 3.865620 loss_ctc 4.640950 loss_rnnt 2.885848 hw_loss 0.155715 history loss 5.047889 rank 3
2023-03-01 11:31:21,630 DEBUG CV Batch 54/500 loss 3.270610 loss_att 3.865620 loss_ctc 4.640950 loss_rnnt 2.885848 hw_loss 0.155715 history loss 5.047889 rank 0
2023-03-01 11:31:31,649 DEBUG CV Batch 54/600 loss 7.237150 loss_att 6.159825 loss_ctc 10.401250 loss_rnnt 6.857728 hw_loss 0.324387 history loss 5.920321 rank 4
2023-03-01 11:31:31,982 DEBUG CV Batch 54/600 loss 7.237150 loss_att 6.159825 loss_ctc 10.401250 loss_rnnt 6.857728 hw_loss 0.324387 history loss 5.920321 rank 5
2023-03-01 11:31:32,132 DEBUG CV Batch 54/600 loss 7.237150 loss_att 6.159825 loss_ctc 10.401250 loss_rnnt 6.857728 hw_loss 0.324387 history loss 5.920321 rank 6
2023-03-01 11:31:32,280 DEBUG CV Batch 54/600 loss 7.237150 loss_att 6.159825 loss_ctc 10.401250 loss_rnnt 6.857728 hw_loss 0.324387 history loss 5.920321 rank 2
2023-03-01 11:31:33,324 DEBUG CV Batch 54/600 loss 7.237150 loss_att 6.159825 loss_ctc 10.401250 loss_rnnt 6.857728 hw_loss 0.324387 history loss 5.920321 rank 7
2023-03-01 11:31:33,409 DEBUG CV Batch 54/600 loss 7.237150 loss_att 6.159825 loss_ctc 10.401250 loss_rnnt 6.857728 hw_loss 0.324387 history loss 5.920321 rank 3
2023-03-01 11:31:33,505 DEBUG CV Batch 54/600 loss 7.237150 loss_att 6.159825 loss_ctc 10.401250 loss_rnnt 6.857728 hw_loss 0.324387 history loss 5.920321 rank 1
2023-03-01 11:31:34,310 DEBUG CV Batch 54/600 loss 7.237150 loss_att 6.159825 loss_ctc 10.401250 loss_rnnt 6.857728 hw_loss 0.324387 history loss 5.920321 rank 0
2023-03-01 11:31:43,119 DEBUG CV Batch 54/700 loss 11.093304 loss_att 18.231445 loss_ctc 14.734694 loss_rnnt 8.995942 hw_loss 0.345401 history loss 6.478872 rank 4
2023-03-01 11:31:43,482 DEBUG CV Batch 54/700 loss 11.093304 loss_att 18.231445 loss_ctc 14.734694 loss_rnnt 8.995942 hw_loss 0.345401 history loss 6.478872 rank 5
2023-03-01 11:31:43,875 DEBUG CV Batch 54/700 loss 11.093304 loss_att 18.231445 loss_ctc 14.734694 loss_rnnt 8.995942 hw_loss 0.345401 history loss 6.478872 rank 2
2023-03-01 11:31:43,925 DEBUG CV Batch 54/700 loss 11.093304 loss_att 18.231445 loss_ctc 14.734694 loss_rnnt 8.995942 hw_loss 0.345401 history loss 6.478872 rank 6
2023-03-01 11:31:45,162 DEBUG CV Batch 54/700 loss 11.093304 loss_att 18.231445 loss_ctc 14.734694 loss_rnnt 8.995942 hw_loss 0.345401 history loss 6.478872 rank 3
2023-03-01 11:31:45,283 DEBUG CV Batch 54/700 loss 11.093304 loss_att 18.231445 loss_ctc 14.734694 loss_rnnt 8.995942 hw_loss 0.345401 history loss 6.478872 rank 7
2023-03-01 11:31:45,516 DEBUG CV Batch 54/700 loss 11.093304 loss_att 18.231445 loss_ctc 14.734694 loss_rnnt 8.995942 hw_loss 0.345401 history loss 6.478872 rank 1
2023-03-01 11:31:46,616 DEBUG CV Batch 54/700 loss 11.093304 loss_att 18.231445 loss_ctc 14.734694 loss_rnnt 8.995942 hw_loss 0.345401 history loss 6.478872 rank 0
2023-03-01 11:31:54,822 DEBUG CV Batch 54/800 loss 5.354355 loss_att 6.615748 loss_ctc 11.615269 loss_rnnt 4.062664 hw_loss 0.383671 history loss 6.004030 rank 4
2023-03-01 11:31:55,170 DEBUG CV Batch 54/800 loss 5.354355 loss_att 6.615748 loss_ctc 11.615269 loss_rnnt 4.062664 hw_loss 0.383671 history loss 6.004030 rank 5
2023-03-01 11:31:55,664 DEBUG CV Batch 54/800 loss 5.354355 loss_att 6.615748 loss_ctc 11.615269 loss_rnnt 4.062664 hw_loss 0.383671 history loss 6.004030 rank 2
2023-03-01 11:31:55,703 DEBUG CV Batch 54/800 loss 5.354355 loss_att 6.615748 loss_ctc 11.615269 loss_rnnt 4.062664 hw_loss 0.383671 history loss 6.004030 rank 6
2023-03-01 11:31:56,826 DEBUG CV Batch 54/800 loss 5.354355 loss_att 6.615748 loss_ctc 11.615269 loss_rnnt 4.062664 hw_loss 0.383671 history loss 6.004030 rank 3
2023-03-01 11:31:57,069 DEBUG CV Batch 54/800 loss 5.354355 loss_att 6.615748 loss_ctc 11.615269 loss_rnnt 4.062664 hw_loss 0.383671 history loss 6.004030 rank 7
2023-03-01 11:31:57,304 DEBUG CV Batch 54/800 loss 5.354355 loss_att 6.615748 loss_ctc 11.615269 loss_rnnt 4.062664 hw_loss 0.383671 history loss 6.004030 rank 1
2023-03-01 11:31:58,652 DEBUG CV Batch 54/800 loss 5.354355 loss_att 6.615748 loss_ctc 11.615269 loss_rnnt 4.062664 hw_loss 0.383671 history loss 6.004030 rank 0
2023-03-01 11:32:08,176 DEBUG CV Batch 54/900 loss 8.050911 loss_att 10.994691 loss_ctc 17.700890 loss_rnnt 6.102901 hw_loss 0.136105 history loss 5.837148 rank 4
2023-03-01 11:32:09,041 DEBUG CV Batch 54/900 loss 8.050911 loss_att 10.994691 loss_ctc 17.700890 loss_rnnt 6.102901 hw_loss 0.136105 history loss 5.837148 rank 5
2023-03-01 11:32:09,318 DEBUG CV Batch 54/900 loss 8.050911 loss_att 10.994691 loss_ctc 17.700890 loss_rnnt 6.102901 hw_loss 0.136105 history loss 5.837148 rank 2
2023-03-01 11:32:09,377 DEBUG CV Batch 54/900 loss 8.050911 loss_att 10.994691 loss_ctc 17.700890 loss_rnnt 6.102901 hw_loss 0.136105 history loss 5.837148 rank 6
2023-03-01 11:32:10,706 DEBUG CV Batch 54/900 loss 8.050911 loss_att 10.994691 loss_ctc 17.700890 loss_rnnt 6.102901 hw_loss 0.136105 history loss 5.837148 rank 3
2023-03-01 11:32:10,828 DEBUG CV Batch 54/900 loss 8.050911 loss_att 10.994691 loss_ctc 17.700890 loss_rnnt 6.102901 hw_loss 0.136105 history loss 5.837148 rank 7
2023-03-01 11:32:11,060 DEBUG CV Batch 54/900 loss 8.050911 loss_att 10.994691 loss_ctc 17.700890 loss_rnnt 6.102901 hw_loss 0.136105 history loss 5.837148 rank 1
2023-03-01 11:32:12,614 DEBUG CV Batch 54/900 loss 8.050911 loss_att 10.994691 loss_ctc 17.700890 loss_rnnt 6.102901 hw_loss 0.136105 history loss 5.837148 rank 0
2023-03-01 11:32:20,529 DEBUG CV Batch 54/1000 loss 3.483722 loss_att 3.716078 loss_ctc 3.615084 loss_rnnt 3.322403 hw_loss 0.182500 history loss 5.642101 rank 4
2023-03-01 11:32:21,661 DEBUG CV Batch 54/1000 loss 3.483722 loss_att 3.716078 loss_ctc 3.615084 loss_rnnt 3.322403 hw_loss 0.182500 history loss 5.642101 rank 5
2023-03-01 11:32:21,848 DEBUG CV Batch 54/1000 loss 3.483722 loss_att 3.716078 loss_ctc 3.615084 loss_rnnt 3.322403 hw_loss 0.182500 history loss 5.642101 rank 2
2023-03-01 11:32:21,934 DEBUG CV Batch 54/1000 loss 3.483722 loss_att 3.716078 loss_ctc 3.615084 loss_rnnt 3.322403 hw_loss 0.182500 history loss 5.642101 rank 6
2023-03-01 11:32:23,219 DEBUG CV Batch 54/1000 loss 3.483722 loss_att 3.716078 loss_ctc 3.615084 loss_rnnt 3.322403 hw_loss 0.182500 history loss 5.642101 rank 3
2023-03-01 11:32:23,663 DEBUG CV Batch 54/1000 loss 3.483722 loss_att 3.716078 loss_ctc 3.615084 loss_rnnt 3.322403 hw_loss 0.182500 history loss 5.642101 rank 1
2023-03-01 11:32:23,671 DEBUG CV Batch 54/1000 loss 3.483722 loss_att 3.716078 loss_ctc 3.615084 loss_rnnt 3.322403 hw_loss 0.182500 history loss 5.642101 rank 7
2023-03-01 11:32:25,646 DEBUG CV Batch 54/1000 loss 3.483722 loss_att 3.716078 loss_ctc 3.615084 loss_rnnt 3.322403 hw_loss 0.182500 history loss 5.642101 rank 0
2023-03-01 11:32:32,398 DEBUG CV Batch 54/1100 loss 4.823809 loss_att 4.691222 loss_ctc 8.492880 loss_rnnt 4.177546 hw_loss 0.344196 history loss 5.595979 rank 4
2023-03-01 11:32:33,805 DEBUG CV Batch 54/1100 loss 4.823809 loss_att 4.691222 loss_ctc 8.492880 loss_rnnt 4.177546 hw_loss 0.344196 history loss 5.595979 rank 5
2023-03-01 11:32:34,234 DEBUG CV Batch 54/1100 loss 4.823809 loss_att 4.691222 loss_ctc 8.492880 loss_rnnt 4.177546 hw_loss 0.344196 history loss 5.595979 rank 2
2023-03-01 11:32:34,441 DEBUG CV Batch 54/1100 loss 4.823809 loss_att 4.691222 loss_ctc 8.492880 loss_rnnt 4.177546 hw_loss 0.344196 history loss 5.595979 rank 6
2023-03-01 11:32:35,607 DEBUG CV Batch 54/1100 loss 4.823809 loss_att 4.691222 loss_ctc 8.492880 loss_rnnt 4.177546 hw_loss 0.344196 history loss 5.595979 rank 3
2023-03-01 11:32:35,772 DEBUG CV Batch 54/1100 loss 4.823809 loss_att 4.691222 loss_ctc 8.492880 loss_rnnt 4.177546 hw_loss 0.344196 history loss 5.595979 rank 1
2023-03-01 11:32:36,089 DEBUG CV Batch 54/1100 loss 4.823809 loss_att 4.691222 loss_ctc 8.492880 loss_rnnt 4.177546 hw_loss 0.344196 history loss 5.595979 rank 7
2023-03-01 11:32:38,419 DEBUG CV Batch 54/1100 loss 4.823809 loss_att 4.691222 loss_ctc 8.492880 loss_rnnt 4.177546 hw_loss 0.344196 history loss 5.595979 rank 0
2023-03-01 11:32:43,398 DEBUG CV Batch 54/1200 loss 6.562814 loss_att 6.656262 loss_ctc 7.538529 loss_rnnt 6.340210 hw_loss 0.138410 history loss 5.870400 rank 4
2023-03-01 11:32:44,844 DEBUG CV Batch 54/1200 loss 6.562814 loss_att 6.656262 loss_ctc 7.538529 loss_rnnt 6.340210 hw_loss 0.138410 history loss 5.870400 rank 5
2023-03-01 11:32:45,332 DEBUG CV Batch 54/1200 loss 6.562814 loss_att 6.656262 loss_ctc 7.538529 loss_rnnt 6.340210 hw_loss 0.138410 history loss 5.870400 rank 2
2023-03-01 11:32:45,423 DEBUG CV Batch 54/1200 loss 6.562814 loss_att 6.656262 loss_ctc 7.538529 loss_rnnt 6.340210 hw_loss 0.138410 history loss 5.870400 rank 6
2023-03-01 11:32:46,831 DEBUG CV Batch 54/1200 loss 6.562814 loss_att 6.656262 loss_ctc 7.538529 loss_rnnt 6.340210 hw_loss 0.138410 history loss 5.870400 rank 1
2023-03-01 11:32:46,850 DEBUG CV Batch 54/1200 loss 6.562814 loss_att 6.656262 loss_ctc 7.538529 loss_rnnt 6.340210 hw_loss 0.138410 history loss 5.870400 rank 3
2023-03-01 11:32:47,319 DEBUG CV Batch 54/1200 loss 6.562814 loss_att 6.656262 loss_ctc 7.538529 loss_rnnt 6.340210 hw_loss 0.138410 history loss 5.870400 rank 7
2023-03-01 11:32:49,835 DEBUG CV Batch 54/1200 loss 6.562814 loss_att 6.656262 loss_ctc 7.538529 loss_rnnt 6.340210 hw_loss 0.138410 history loss 5.870400 rank 0
2023-03-01 11:32:55,641 DEBUG CV Batch 54/1300 loss 4.533506 loss_att 4.236083 loss_ctc 7.029042 loss_rnnt 4.142803 hw_loss 0.220218 history loss 6.159546 rank 4
2023-03-01 11:32:57,258 DEBUG CV Batch 54/1300 loss 4.533506 loss_att 4.236083 loss_ctc 7.029042 loss_rnnt 4.142803 hw_loss 0.220218 history loss 6.159546 rank 5
2023-03-01 11:32:57,779 DEBUG CV Batch 54/1300 loss 4.533506 loss_att 4.236083 loss_ctc 7.029042 loss_rnnt 4.142803 hw_loss 0.220218 history loss 6.159546 rank 6
2023-03-01 11:32:58,248 DEBUG CV Batch 54/1300 loss 4.533506 loss_att 4.236083 loss_ctc 7.029042 loss_rnnt 4.142803 hw_loss 0.220218 history loss 6.159546 rank 2
2023-03-01 11:32:59,184 DEBUG CV Batch 54/1300 loss 4.533506 loss_att 4.236083 loss_ctc 7.029042 loss_rnnt 4.142803 hw_loss 0.220218 history loss 6.159546 rank 1
2023-03-01 11:32:59,317 DEBUG CV Batch 54/1300 loss 4.533506 loss_att 4.236083 loss_ctc 7.029042 loss_rnnt 4.142803 hw_loss 0.220218 history loss 6.159546 rank 3
2023-03-01 11:32:59,864 DEBUG CV Batch 54/1300 loss 4.533506 loss_att 4.236083 loss_ctc 7.029042 loss_rnnt 4.142803 hw_loss 0.220218 history loss 6.159546 rank 7
2023-03-01 11:33:02,551 DEBUG CV Batch 54/1300 loss 4.533506 loss_att 4.236083 loss_ctc 7.029042 loss_rnnt 4.142803 hw_loss 0.220218 history loss 6.159546 rank 0
2023-03-01 11:33:07,026 DEBUG CV Batch 54/1400 loss 5.137641 loss_att 14.456822 loss_ctc 6.656447 loss_rnnt 3.071206 hw_loss 0.000172 history loss 6.430849 rank 4
2023-03-01 11:33:08,743 DEBUG CV Batch 54/1400 loss 5.137641 loss_att 14.456822 loss_ctc 6.656447 loss_rnnt 3.071206 hw_loss 0.000172 history loss 6.430849 rank 5
2023-03-01 11:33:09,232 DEBUG CV Batch 54/1400 loss 5.137641 loss_att 14.456822 loss_ctc 6.656447 loss_rnnt 3.071206 hw_loss 0.000172 history loss 6.430849 rank 6
2023-03-01 11:33:09,628 DEBUG CV Batch 54/1400 loss 5.137641 loss_att 14.456822 loss_ctc 6.656447 loss_rnnt 3.071206 hw_loss 0.000172 history loss 6.430849 rank 2
2023-03-01 11:33:10,761 DEBUG CV Batch 54/1400 loss 5.137641 loss_att 14.456822 loss_ctc 6.656447 loss_rnnt 3.071206 hw_loss 0.000172 history loss 6.430849 rank 1
2023-03-01 11:33:11,178 DEBUG CV Batch 54/1400 loss 5.137641 loss_att 14.456822 loss_ctc 6.656447 loss_rnnt 3.071206 hw_loss 0.000172 history loss 6.430849 rank 3
2023-03-01 11:33:11,575 DEBUG CV Batch 54/1400 loss 5.137641 loss_att 14.456822 loss_ctc 6.656447 loss_rnnt 3.071206 hw_loss 0.000172 history loss 6.430849 rank 7
2023-03-01 11:33:14,541 DEBUG CV Batch 54/1400 loss 5.137641 loss_att 14.456822 loss_ctc 6.656447 loss_rnnt 3.071206 hw_loss 0.000172 history loss 6.430849 rank 0
2023-03-01 11:33:18,813 DEBUG CV Batch 54/1500 loss 7.020821 loss_att 6.840957 loss_ctc 7.681968 loss_rnnt 6.898550 hw_loss 0.131421 history loss 6.297432 rank 4
2023-03-01 11:33:20,673 DEBUG CV Batch 54/1500 loss 7.020821 loss_att 6.840957 loss_ctc 7.681968 loss_rnnt 6.898550 hw_loss 0.131421 history loss 6.297432 rank 5
2023-03-01 11:33:21,237 DEBUG CV Batch 54/1500 loss 7.020821 loss_att 6.840957 loss_ctc 7.681968 loss_rnnt 6.898550 hw_loss 0.131421 history loss 6.297432 rank 6
2023-03-01 11:33:21,418 DEBUG CV Batch 54/1500 loss 7.020821 loss_att 6.840957 loss_ctc 7.681968 loss_rnnt 6.898550 hw_loss 0.131421 history loss 6.297432 rank 2
2023-03-01 11:33:22,762 DEBUG CV Batch 54/1500 loss 7.020821 loss_att 6.840957 loss_ctc 7.681968 loss_rnnt 6.898550 hw_loss 0.131421 history loss 6.297432 rank 1
2023-03-01 11:33:23,237 DEBUG CV Batch 54/1500 loss 7.020821 loss_att 6.840957 loss_ctc 7.681968 loss_rnnt 6.898550 hw_loss 0.131421 history loss 6.297432 rank 3
2023-03-01 11:33:23,627 DEBUG CV Batch 54/1500 loss 7.020821 loss_att 6.840957 loss_ctc 7.681968 loss_rnnt 6.898550 hw_loss 0.131421 history loss 6.297432 rank 7
2023-03-01 11:33:26,926 DEBUG CV Batch 54/1500 loss 7.020821 loss_att 6.840957 loss_ctc 7.681968 loss_rnnt 6.898550 hw_loss 0.131421 history loss 6.297432 rank 0
2023-03-01 11:33:32,309 DEBUG CV Batch 54/1600 loss 10.433259 loss_att 11.992717 loss_ctc 13.168798 loss_rnnt 9.614620 hw_loss 0.266266 history loss 6.260226 rank 4
2023-03-01 11:33:33,999 DEBUG CV Batch 54/1600 loss 10.433259 loss_att 11.992717 loss_ctc 13.168798 loss_rnnt 9.614620 hw_loss 0.266266 history loss 6.260226 rank 5
2023-03-01 11:33:34,567 DEBUG CV Batch 54/1600 loss 10.433259 loss_att 11.992717 loss_ctc 13.168798 loss_rnnt 9.614620 hw_loss 0.266266 history loss 6.260226 rank 6
2023-03-01 11:33:34,714 DEBUG CV Batch 54/1600 loss 10.433259 loss_att 11.992717 loss_ctc 13.168798 loss_rnnt 9.614620 hw_loss 0.266266 history loss 6.260226 rank 2
2023-03-01 11:33:35,887 DEBUG CV Batch 54/1600 loss 10.433259 loss_att 11.992717 loss_ctc 13.168798 loss_rnnt 9.614620 hw_loss 0.266266 history loss 6.260226 rank 1
2023-03-01 11:33:36,679 DEBUG CV Batch 54/1600 loss 10.433259 loss_att 11.992717 loss_ctc 13.168798 loss_rnnt 9.614620 hw_loss 0.266266 history loss 6.260226 rank 3
2023-03-01 11:33:37,062 DEBUG CV Batch 54/1600 loss 10.433259 loss_att 11.992717 loss_ctc 13.168798 loss_rnnt 9.614620 hw_loss 0.266266 history loss 6.260226 rank 7
2023-03-01 11:33:40,632 DEBUG CV Batch 54/1600 loss 10.433259 loss_att 11.992717 loss_ctc 13.168798 loss_rnnt 9.614620 hw_loss 0.266266 history loss 6.260226 rank 0
2023-03-01 11:33:44,940 DEBUG CV Batch 54/1700 loss 7.316936 loss_att 6.301945 loss_ctc 12.813640 loss_rnnt 6.621048 hw_loss 0.311236 history loss 6.198181 rank 4
2023-03-01 11:33:46,568 DEBUG CV Batch 54/1700 loss 7.316936 loss_att 6.301945 loss_ctc 12.813640 loss_rnnt 6.621048 hw_loss 0.311236 history loss 6.198181 rank 5
2023-03-01 11:33:47,280 DEBUG CV Batch 54/1700 loss 7.316936 loss_att 6.301945 loss_ctc 12.813640 loss_rnnt 6.621048 hw_loss 0.311236 history loss 6.198181 rank 6
2023-03-01 11:33:47,375 DEBUG CV Batch 54/1700 loss 7.316936 loss_att 6.301945 loss_ctc 12.813640 loss_rnnt 6.621048 hw_loss 0.311236 history loss 6.198181 rank 2
2023-03-01 11:33:48,314 DEBUG CV Batch 54/1700 loss 7.316936 loss_att 6.301945 loss_ctc 12.813640 loss_rnnt 6.621048 hw_loss 0.311236 history loss 6.198181 rank 1
2023-03-01 11:33:49,549 DEBUG CV Batch 54/1700 loss 7.316936 loss_att 6.301945 loss_ctc 12.813640 loss_rnnt 6.621048 hw_loss 0.311236 history loss 6.198181 rank 3
2023-03-01 11:33:49,709 DEBUG CV Batch 54/1700 loss 7.316936 loss_att 6.301945 loss_ctc 12.813640 loss_rnnt 6.621048 hw_loss 0.311236 history loss 6.198181 rank 7
2023-03-01 11:33:53,154 DEBUG CV Batch 54/1700 loss 7.316936 loss_att 6.301945 loss_ctc 12.813640 loss_rnnt 6.621048 hw_loss 0.311236 history loss 6.198181 rank 0
2023-03-01 11:33:54,039 INFO Epoch 54 CV info cv_loss 6.18198900555777
2023-03-01 11:33:54,040 INFO Epoch 55 TRAIN info lr 0.0002875083019220787
2023-03-01 11:33:54,045 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 11:33:55,785 INFO Epoch 54 CV info cv_loss 6.181989007646818
2023-03-01 11:33:55,786 INFO Epoch 55 TRAIN info lr 0.0002875083019220787
2023-03-01 11:33:55,791 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 11:33:56,533 INFO Epoch 54 CV info cv_loss 6.181989005618072
2023-03-01 11:33:56,533 INFO Epoch 55 TRAIN info lr 0.00028751115385217883
2023-03-01 11:33:56,535 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 11:33:56,602 INFO Epoch 54 CV info cv_loss 6.181989007752347
2023-03-01 11:33:56,602 INFO Epoch 55 TRAIN info lr 0.0002875130551860623
2023-03-01 11:33:56,607 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 11:33:57,592 INFO Epoch 54 CV info cv_loss 6.181989006281399
2023-03-01 11:33:57,592 INFO Epoch 55 TRAIN info lr 0.00028750735129757143
2023-03-01 11:33:57,597 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 11:33:58,864 INFO Epoch 54 CV info cv_loss 6.181989005656837
2023-03-01 11:33:58,864 INFO Epoch 55 TRAIN info lr 0.0002875030736039757
2023-03-01 11:33:58,867 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 11:33:58,936 INFO Epoch 54 CV info cv_loss 6.181989005271333
2023-03-01 11:33:58,936 INFO Epoch 55 TRAIN info lr 0.0002875049747775567
2023-03-01 11:33:58,939 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 11:34:02,683 INFO Epoch 54 CV info cv_loss 6.1819890065290695
2023-03-01 11:34:02,683 INFO Checkpoint: save to checkpoint exp/2_27_rnnt_bias_loss_2_class_both_finetune/54.pt
2023-03-01 11:34:03,237 INFO Epoch 55 TRAIN info lr 0.0002875178086858053
2023-03-01 11:34:03,241 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 11:35:03,970 DEBUG TRAIN Batch 55/0 loss 5.859222 loss_att 6.393075 loss_ctc 8.659260 loss_rnnt 5.169787 hw_loss 0.392485 lr 0.00028751 rank 2
2023-03-01 11:35:03,971 DEBUG TRAIN Batch 55/0 loss 8.667346 loss_att 8.365039 loss_ctc 12.829101 loss_rnnt 7.972872 hw_loss 0.375065 lr 0.00028751 rank 4
2023-03-01 11:35:03,971 DEBUG TRAIN Batch 55/0 loss 6.441603 loss_att 6.716361 loss_ctc 9.190532 loss_rnnt 5.860762 hw_loss 0.298810 lr 0.00028751 rank 5
2023-03-01 11:35:03,975 DEBUG TRAIN Batch 55/0 loss 7.923934 loss_att 7.777637 loss_ctc 10.077204 loss_rnnt 7.513065 hw_loss 0.286924 lr 0.00028750 rank 7
2023-03-01 11:35:03,976 DEBUG TRAIN Batch 55/0 loss 6.583967 loss_att 6.855524 loss_ctc 9.955621 loss_rnnt 5.920268 hw_loss 0.299689 lr 0.00028751 rank 1
2023-03-01 11:35:03,977 DEBUG TRAIN Batch 55/0 loss 6.256727 loss_att 6.845843 loss_ctc 10.387020 loss_rnnt 5.368725 hw_loss 0.411511 lr 0.00028750 rank 3
2023-03-01 11:35:04,020 DEBUG TRAIN Batch 55/0 loss 5.210175 loss_att 5.435180 loss_ctc 8.591043 loss_rnnt 4.492795 hw_loss 0.415493 lr 0.00028751 rank 6
2023-03-01 11:35:04,023 DEBUG TRAIN Batch 55/0 loss 5.032047 loss_att 4.941156 loss_ctc 7.132687 loss_rnnt 4.607452 hw_loss 0.305039 lr 0.00028752 rank 0
2023-03-01 11:35:41,398 DEBUG TRAIN Batch 55/100 loss 5.650856 loss_att 9.945824 loss_ctc 8.706025 loss_rnnt 4.210989 hw_loss 0.325343 lr 0.00028750 rank 4
2023-03-01 11:35:41,400 DEBUG TRAIN Batch 55/100 loss 4.510478 loss_att 8.100207 loss_ctc 10.098165 loss_rnnt 2.937492 hw_loss 0.206276 lr 0.00028750 rank 5
2023-03-01 11:35:41,412 DEBUG TRAIN Batch 55/100 loss 2.423841 loss_att 5.141881 loss_ctc 5.473587 loss_rnnt 1.337748 hw_loss 0.254725 lr 0.00028749 rank 7
2023-03-01 11:35:41,413 DEBUG TRAIN Batch 55/100 loss 4.343464 loss_att 6.857046 loss_ctc 8.774294 loss_rnnt 3.148008 hw_loss 0.191181 lr 0.00028751 rank 0
2023-03-01 11:35:41,419 DEBUG TRAIN Batch 55/100 loss 4.295722 loss_att 8.975971 loss_ctc 11.647404 loss_rnnt 2.231591 hw_loss 0.277233 lr 0.00028749 rank 1
2023-03-01 11:35:41,419 DEBUG TRAIN Batch 55/100 loss 10.125166 loss_att 13.641715 loss_ctc 12.072765 loss_rnnt 8.976245 hw_loss 0.348622 lr 0.00028750 rank 2
2023-03-01 11:35:41,435 DEBUG TRAIN Batch 55/100 loss 5.054868 loss_att 8.464323 loss_ctc 8.333306 loss_rnnt 3.763395 hw_loss 0.323356 lr 0.00028750 rank 6
2023-03-01 11:35:41,475 DEBUG TRAIN Batch 55/100 loss 5.938307 loss_att 8.065687 loss_ctc 6.341400 loss_rnnt 5.351049 hw_loss 0.202568 lr 0.00028749 rank 3
2023-03-01 11:36:18,902 DEBUG TRAIN Batch 55/200 loss 6.671283 loss_att 9.924143 loss_ctc 12.249601 loss_rnnt 5.276438 hw_loss 0.000933 lr 0.00028749 rank 2
2023-03-01 11:36:18,903 DEBUG TRAIN Batch 55/200 loss 3.797814 loss_att 7.017625 loss_ctc 8.303410 loss_rnnt 2.435820 hw_loss 0.219910 lr 0.00028749 rank 6
2023-03-01 11:36:18,907 DEBUG TRAIN Batch 55/200 loss 13.225986 loss_att 16.497833 loss_ctc 19.807919 loss_rnnt 11.596292 hw_loss 0.183249 lr 0.00028748 rank 1
2023-03-01 11:36:18,908 DEBUG TRAIN Batch 55/200 loss 4.155228 loss_att 6.315884 loss_ctc 8.817474 loss_rnnt 2.976911 hw_loss 0.233537 lr 0.00028748 rank 3
2023-03-01 11:36:18,915 DEBUG TRAIN Batch 55/200 loss 3.640003 loss_att 6.553682 loss_ctc 6.799208 loss_rnnt 2.539172 hw_loss 0.181626 lr 0.00028748 rank 7
2023-03-01 11:36:18,916 DEBUG TRAIN Batch 55/200 loss 5.573884 loss_att 9.058476 loss_ctc 10.038838 loss_rnnt 4.171743 hw_loss 0.206055 lr 0.00028749 rank 0
2023-03-01 11:36:18,917 DEBUG TRAIN Batch 55/200 loss 4.504468 loss_att 7.775325 loss_ctc 4.730100 loss_rnnt 3.690312 hw_loss 0.243561 lr 0.00028748 rank 4
2023-03-01 11:36:18,917 DEBUG TRAIN Batch 55/200 loss 4.918019 loss_att 7.734094 loss_ctc 6.135491 loss_rnnt 4.036159 hw_loss 0.293093 lr 0.00028748 rank 5
2023-03-01 11:36:57,477 DEBUG TRAIN Batch 55/300 loss 7.197214 loss_att 10.325231 loss_ctc 12.883771 loss_rnnt 5.683145 hw_loss 0.244234 lr 0.00028747 rank 1
2023-03-01 11:36:57,486 DEBUG TRAIN Batch 55/300 loss 7.247289 loss_att 8.477182 loss_ctc 15.491365 loss_rnnt 5.839915 hw_loss 0.116597 lr 0.00028748 rank 2
2023-03-01 11:36:57,496 DEBUG TRAIN Batch 55/300 loss 2.607447 loss_att 4.821088 loss_ctc 7.137907 loss_rnnt 1.403149 hw_loss 0.295327 lr 0.00028747 rank 5
2023-03-01 11:36:57,497 DEBUG TRAIN Batch 55/300 loss 6.757685 loss_att 10.593336 loss_ctc 9.854205 loss_rnnt 5.498783 hw_loss 0.147942 lr 0.00028748 rank 0
2023-03-01 11:36:57,497 DEBUG TRAIN Batch 55/300 loss 6.415329 loss_att 10.143206 loss_ctc 11.533272 loss_rnnt 4.904273 hw_loss 0.155791 lr 0.00028747 rank 7
2023-03-01 11:36:57,498 DEBUG TRAIN Batch 55/300 loss 8.568320 loss_att 12.987411 loss_ctc 17.087633 loss_rnnt 6.424233 hw_loss 0.233176 lr 0.00028748 rank 6
2023-03-01 11:36:57,529 DEBUG TRAIN Batch 55/300 loss 6.663755 loss_att 8.261026 loss_ctc 7.648139 loss_rnnt 6.097604 hw_loss 0.216460 lr 0.00028747 rank 3
2023-03-01 11:36:57,535 DEBUG TRAIN Batch 55/300 loss 6.307423 loss_att 7.676208 loss_ctc 10.705529 loss_rnnt 5.311183 hw_loss 0.255129 lr 0.00028747 rank 4
2023-03-01 11:38:01,255 DEBUG TRAIN Batch 55/400 loss 7.892719 loss_att 11.238845 loss_ctc 15.194818 loss_rnnt 6.059449 hw_loss 0.357058 lr 0.00028746 rank 7
2023-03-01 11:38:01,269 DEBUG TRAIN Batch 55/400 loss 10.281847 loss_att 13.906260 loss_ctc 15.973572 loss_rnnt 8.723789 hw_loss 0.139274 lr 0.00028746 rank 4
2023-03-01 11:38:01,269 DEBUG TRAIN Batch 55/400 loss 5.860616 loss_att 8.350992 loss_ctc 11.419945 loss_rnnt 4.499296 hw_loss 0.228752 lr 0.00028746 rank 6
2023-03-01 11:38:01,271 DEBUG TRAIN Batch 55/400 loss 5.710600 loss_att 8.616228 loss_ctc 10.648619 loss_rnnt 4.371745 hw_loss 0.186238 lr 0.00028746 rank 3
2023-03-01 11:38:01,272 DEBUG TRAIN Batch 55/400 loss 5.060564 loss_att 7.657656 loss_ctc 11.137345 loss_rnnt 3.676275 hw_loss 0.102437 lr 0.00028746 rank 5
2023-03-01 11:38:01,274 DEBUG TRAIN Batch 55/400 loss 5.484156 loss_att 9.064506 loss_ctc 9.167082 loss_rnnt 4.187736 hw_loss 0.167426 lr 0.00028747 rank 0
2023-03-01 11:38:01,277 DEBUG TRAIN Batch 55/400 loss 9.171411 loss_att 11.165459 loss_ctc 13.625360 loss_rnnt 8.086357 hw_loss 0.173220 lr 0.00028747 rank 2
2023-03-01 11:38:01,323 DEBUG TRAIN Batch 55/400 loss 2.484743 loss_att 5.016804 loss_ctc 2.795135 loss_rnnt 1.798864 hw_loss 0.258901 lr 0.00028746 rank 1
2023-03-01 11:38:40,049 DEBUG TRAIN Batch 55/500 loss 16.573927 loss_att 17.635553 loss_ctc 25.149775 loss_rnnt 15.115171 hw_loss 0.193095 lr 0.00028745 rank 7
2023-03-01 11:38:40,052 DEBUG TRAIN Batch 55/500 loss 4.957910 loss_att 7.333881 loss_ctc 9.502741 loss_rnnt 3.802647 hw_loss 0.138922 lr 0.00028745 rank 1
2023-03-01 11:38:40,052 DEBUG TRAIN Batch 55/500 loss 3.344760 loss_att 5.299953 loss_ctc 5.469811 loss_rnnt 2.583864 hw_loss 0.162219 lr 0.00028745 rank 5
2023-03-01 11:38:40,053 DEBUG TRAIN Batch 55/500 loss 10.138556 loss_att 14.924940 loss_ctc 17.926407 loss_rnnt 8.065643 hw_loss 0.144855 lr 0.00028745 rank 6
2023-03-01 11:38:40,054 DEBUG TRAIN Batch 55/500 loss 9.695208 loss_att 11.435667 loss_ctc 11.363846 loss_rnnt 8.950905 hw_loss 0.325737 lr 0.00028746 rank 0
2023-03-01 11:38:40,056 DEBUG TRAIN Batch 55/500 loss 8.464517 loss_att 9.005144 loss_ctc 13.654465 loss_rnnt 7.540330 hw_loss 0.232626 lr 0.00028745 rank 2
2023-03-01 11:38:40,057 DEBUG TRAIN Batch 55/500 loss 6.983067 loss_att 9.311295 loss_ctc 10.328493 loss_rnnt 5.954941 hw_loss 0.218294 lr 0.00028745 rank 4
2023-03-01 11:38:40,105 DEBUG TRAIN Batch 55/500 loss 6.659202 loss_att 8.171258 loss_ctc 7.980751 loss_rnnt 6.114959 hw_loss 0.123048 lr 0.00028744 rank 3
2023-03-01 11:39:18,778 DEBUG TRAIN Batch 55/600 loss 6.784905 loss_att 7.618974 loss_ctc 9.950086 loss_rnnt 6.010951 hw_loss 0.347094 lr 0.00028744 rank 5
2023-03-01 11:39:18,788 DEBUG TRAIN Batch 55/600 loss 5.131466 loss_att 8.256535 loss_ctc 7.995130 loss_rnnt 3.999862 hw_loss 0.233941 lr 0.00028745 rank 0
2023-03-01 11:39:18,790 DEBUG TRAIN Batch 55/600 loss 6.366950 loss_att 9.185013 loss_ctc 9.221238 loss_rnnt 5.293680 hw_loss 0.242036 lr 0.00028744 rank 1
2023-03-01 11:39:18,793 DEBUG TRAIN Batch 55/600 loss 4.379012 loss_att 5.646300 loss_ctc 7.725076 loss_rnnt 3.530471 hw_loss 0.279264 lr 0.00028744 rank 2
2023-03-01 11:39:18,793 DEBUG TRAIN Batch 55/600 loss 10.053773 loss_att 9.651702 loss_ctc 14.505130 loss_rnnt 9.373366 hw_loss 0.313698 lr 0.00028743 rank 7
2023-03-01 11:39:18,797 DEBUG TRAIN Batch 55/600 loss 7.593991 loss_att 7.642609 loss_ctc 10.474966 loss_rnnt 7.040408 hw_loss 0.299492 lr 0.00028744 rank 6
2023-03-01 11:39:18,801 DEBUG TRAIN Batch 55/600 loss 6.404634 loss_att 8.450073 loss_ctc 9.590079 loss_rnnt 5.417600 hw_loss 0.287289 lr 0.00028744 rank 4
2023-03-01 11:39:18,845 DEBUG TRAIN Batch 55/600 loss 5.249213 loss_att 6.291992 loss_ctc 8.828798 loss_rnnt 4.423598 hw_loss 0.262089 lr 0.00028743 rank 3
2023-03-01 11:39:58,789 DEBUG TRAIN Batch 55/700 loss 2.234076 loss_att 7.354474 loss_ctc 3.384714 loss_rnnt 1.018155 hw_loss 0.072044 lr 0.00028743 rank 2
2023-03-01 11:39:58,792 DEBUG TRAIN Batch 55/700 loss 6.921255 loss_att 10.925474 loss_ctc 10.511622 loss_rnnt 5.596088 hw_loss 0.085514 lr 0.00028743 rank 0
2023-03-01 11:39:58,800 DEBUG TRAIN Batch 55/700 loss 4.214797 loss_att 7.660525 loss_ctc 5.454238 loss_rnnt 3.303780 hw_loss 0.106148 lr 0.00028742 rank 1
2023-03-01 11:39:58,800 DEBUG TRAIN Batch 55/700 loss 10.727422 loss_att 16.402822 loss_ctc 19.501226 loss_rnnt 8.372219 hw_loss 0.094279 lr 0.00028742 rank 5
2023-03-01 11:39:58,802 DEBUG TRAIN Batch 55/700 loss 8.127679 loss_att 12.413191 loss_ctc 17.355726 loss_rnnt 5.954463 hw_loss 0.160699 lr 0.00028742 rank 4
2023-03-01 11:39:58,806 DEBUG TRAIN Batch 55/700 loss 4.389663 loss_att 11.370308 loss_ctc 10.457495 loss_rnnt 2.051839 hw_loss 0.248720 lr 0.00028743 rank 6
2023-03-01 11:39:58,815 DEBUG TRAIN Batch 55/700 loss 4.299958 loss_att 7.250767 loss_ctc 3.827510 loss_rnnt 3.678842 hw_loss 0.176152 lr 0.00028742 rank 3
2023-03-01 11:39:58,821 DEBUG TRAIN Batch 55/700 loss 5.348477 loss_att 9.407484 loss_ctc 13.077983 loss_rnnt 3.374417 hw_loss 0.246857 lr 0.00028742 rank 7
2023-03-01 11:41:01,560 DEBUG TRAIN Batch 55/800 loss 5.177548 loss_att 9.926371 loss_ctc 12.798115 loss_rnnt 3.186461 hw_loss 0.047339 lr 0.00028741 rank 7
2023-03-01 11:41:01,566 DEBUG TRAIN Batch 55/800 loss 4.850488 loss_att 9.073693 loss_ctc 9.586506 loss_rnnt 3.202990 hw_loss 0.321353 lr 0.00028742 rank 6
2023-03-01 11:41:01,576 DEBUG TRAIN Batch 55/800 loss 1.259698 loss_att 3.316183 loss_ctc 1.346863 loss_rnnt 0.734951 hw_loss 0.190926 lr 0.00028742 rank 0
2023-03-01 11:41:01,580 DEBUG TRAIN Batch 55/800 loss 2.343841 loss_att 5.602475 loss_ctc 4.901003 loss_rnnt 1.275017 hw_loss 0.142765 lr 0.00028742 rank 2
2023-03-01 11:41:01,583 DEBUG TRAIN Batch 55/800 loss 4.802791 loss_att 7.770855 loss_ctc 5.762364 loss_rnnt 3.966132 hw_loss 0.215818 lr 0.00028741 rank 3
2023-03-01 11:41:01,584 DEBUG TRAIN Batch 55/800 loss 5.584516 loss_att 9.749780 loss_ctc 10.281383 loss_rnnt 4.007326 hw_loss 0.221041 lr 0.00028741 rank 5
2023-03-01 11:41:01,592 DEBUG TRAIN Batch 55/800 loss 5.217468 loss_att 7.319757 loss_ctc 9.084777 loss_rnnt 4.238345 hw_loss 0.080670 lr 0.00028741 rank 4
2023-03-01 11:41:01,600 DEBUG TRAIN Batch 55/800 loss 3.360269 loss_att 5.937343 loss_ctc 6.108456 loss_rnnt 2.444390 hw_loss 0.063823 lr 0.00028741 rank 1
2023-03-01 11:41:39,923 DEBUG TRAIN Batch 55/900 loss 7.239355 loss_att 9.605755 loss_ctc 11.453873 loss_rnnt 6.149505 hw_loss 0.102442 lr 0.00028740 rank 6
2023-03-01 11:41:39,928 DEBUG TRAIN Batch 55/900 loss 4.706156 loss_att 7.984038 loss_ctc 7.582650 loss_rnnt 3.634339 hw_loss 0.061328 lr 0.00028741 rank 2
2023-03-01 11:41:39,928 DEBUG TRAIN Batch 55/900 loss 2.244526 loss_att 6.114674 loss_ctc 5.130517 loss_rnnt 1.000275 hw_loss 0.160166 lr 0.00028740 rank 5
2023-03-01 11:41:39,941 DEBUG TRAIN Batch 55/900 loss 8.060822 loss_att 9.885187 loss_ctc 7.716449 loss_rnnt 7.690557 hw_loss 0.096202 lr 0.00028741 rank 0
2023-03-01 11:41:39,942 DEBUG TRAIN Batch 55/900 loss 5.373920 loss_att 9.517644 loss_ctc 10.193806 loss_rnnt 3.842775 hw_loss 0.112030 lr 0.00028740 rank 4
2023-03-01 11:41:39,942 DEBUG TRAIN Batch 55/900 loss 4.892591 loss_att 6.612936 loss_ctc 8.425662 loss_rnnt 3.923031 hw_loss 0.289527 lr 0.00028740 rank 7
2023-03-01 11:41:39,948 DEBUG TRAIN Batch 55/900 loss 7.537703 loss_att 9.873723 loss_ctc 15.118492 loss_rnnt 5.944373 hw_loss 0.216287 lr 0.00028740 rank 1
2023-03-01 11:41:39,994 DEBUG TRAIN Batch 55/900 loss 4.607776 loss_att 9.190540 loss_ctc 6.404564 loss_rnnt 3.389469 hw_loss 0.116593 lr 0.00028740 rank 3
2023-03-01 11:42:18,537 DEBUG TRAIN Batch 55/1000 loss 5.308294 loss_att 8.823292 loss_ctc 11.520784 loss_rnnt 3.712533 hw_loss 0.120805 lr 0.00028739 rank 1
2023-03-01 11:42:18,542 DEBUG TRAIN Batch 55/1000 loss 11.533199 loss_att 16.938465 loss_ctc 17.791225 loss_rnnt 9.617496 hw_loss 0.000464 lr 0.00028738 rank 3
2023-03-01 11:42:18,543 DEBUG TRAIN Batch 55/1000 loss 7.784237 loss_att 9.438459 loss_ctc 10.680456 loss_rnnt 6.890863 hw_loss 0.330687 lr 0.00028739 rank 2
2023-03-01 11:42:18,552 DEBUG TRAIN Batch 55/1000 loss 6.377145 loss_att 9.763883 loss_ctc 14.416500 loss_rnnt 4.520409 hw_loss 0.201516 lr 0.00028739 rank 4
2023-03-01 11:42:18,555 DEBUG TRAIN Batch 55/1000 loss 7.088840 loss_att 7.645610 loss_ctc 9.057328 loss_rnnt 6.610364 hw_loss 0.196231 lr 0.00028739 rank 7
2023-03-01 11:42:18,555 DEBUG TRAIN Batch 55/1000 loss 4.197286 loss_att 8.864230 loss_ctc 7.925892 loss_rnnt 2.683186 hw_loss 0.156681 lr 0.00028740 rank 0
2023-03-01 11:42:18,562 DEBUG TRAIN Batch 55/1000 loss 5.367661 loss_att 8.358497 loss_ctc 7.182785 loss_rnnt 4.514368 hw_loss 0.024581 lr 0.00028739 rank 6
2023-03-01 11:42:18,577 DEBUG TRAIN Batch 55/1000 loss 7.796199 loss_att 12.687929 loss_ctc 13.800016 loss_rnnt 5.912363 hw_loss 0.196838 lr 0.00028739 rank 5
2023-03-01 11:43:22,699 DEBUG TRAIN Batch 55/1100 loss 12.425937 loss_att 14.280058 loss_ctc 24.113932 loss_rnnt 10.351619 hw_loss 0.272053 lr 0.00028738 rank 4
2023-03-01 11:43:22,705 DEBUG TRAIN Batch 55/1100 loss 9.148593 loss_att 14.232052 loss_ctc 13.311939 loss_rnnt 7.479441 hw_loss 0.182526 lr 0.00028738 rank 5
2023-03-01 11:43:22,717 DEBUG TRAIN Batch 55/1100 loss 12.978831 loss_att 14.018525 loss_ctc 18.772020 loss_rnnt 11.920072 hw_loss 0.146993 lr 0.00028737 rank 7
2023-03-01 11:43:22,718 DEBUG TRAIN Batch 55/1100 loss 5.144852 loss_att 8.886870 loss_ctc 9.237989 loss_rnnt 3.705581 hw_loss 0.272091 lr 0.00028738 rank 1
2023-03-01 11:43:22,718 DEBUG TRAIN Batch 55/1100 loss 4.549154 loss_att 7.445956 loss_ctc 8.430058 loss_rnnt 3.322342 hw_loss 0.243743 lr 0.00028739 rank 0
2023-03-01 11:43:22,719 DEBUG TRAIN Batch 55/1100 loss 7.164385 loss_att 9.731722 loss_ctc 9.048107 loss_rnnt 6.246096 hw_loss 0.288111 lr 0.00028737 rank 3
2023-03-01 11:43:22,721 DEBUG TRAIN Batch 55/1100 loss 4.961191 loss_att 9.058752 loss_ctc 10.476784 loss_rnnt 3.319398 hw_loss 0.162877 lr 0.00028738 rank 6
2023-03-01 11:43:22,722 DEBUG TRAIN Batch 55/1100 loss 5.022964 loss_att 8.418304 loss_ctc 10.211088 loss_rnnt 3.553871 hw_loss 0.184265 lr 0.00028738 rank 2
2023-03-01 11:44:01,551 DEBUG TRAIN Batch 55/1200 loss 8.883570 loss_att 9.954261 loss_ctc 10.721968 loss_rnnt 8.341552 hw_loss 0.155174 lr 0.00028737 rank 5
2023-03-01 11:44:01,572 DEBUG TRAIN Batch 55/1200 loss 6.488888 loss_att 7.888628 loss_ctc 11.739990 loss_rnnt 5.347497 hw_loss 0.302429 lr 0.00028737 rank 0
2023-03-01 11:44:01,572 DEBUG TRAIN Batch 55/1200 loss 7.100071 loss_att 7.275590 loss_ctc 10.253679 loss_rnnt 6.555587 hw_loss 0.166684 lr 0.00028737 rank 4
2023-03-01 11:44:01,573 DEBUG TRAIN Batch 55/1200 loss 4.988655 loss_att 6.761682 loss_ctc 6.651367 loss_rnnt 4.259537 hw_loss 0.286532 lr 0.00028736 rank 7
2023-03-01 11:44:01,580 DEBUG TRAIN Batch 55/1200 loss 12.139817 loss_att 12.742405 loss_ctc 18.849173 loss_rnnt 11.025463 hw_loss 0.186105 lr 0.00028736 rank 3
2023-03-01 11:44:01,603 DEBUG TRAIN Batch 55/1200 loss 4.661811 loss_att 6.988313 loss_ctc 9.734130 loss_rnnt 3.367083 hw_loss 0.287098 lr 0.00028737 rank 6
2023-03-01 11:44:01,606 DEBUG TRAIN Batch 55/1200 loss 8.316175 loss_att 9.889349 loss_ctc 13.670317 loss_rnnt 7.070693 hw_loss 0.406804 lr 0.00028737 rank 2
2023-03-01 11:44:01,623 DEBUG TRAIN Batch 55/1200 loss 2.805622 loss_att 4.019721 loss_ctc 3.156611 loss_rnnt 2.344297 hw_loss 0.321949 lr 0.00028736 rank 1
2023-03-01 11:44:40,810 DEBUG TRAIN Batch 55/1300 loss 11.404793 loss_att 13.453968 loss_ctc 19.791958 loss_rnnt 9.851555 hw_loss 0.047090 lr 0.00028736 rank 2
2023-03-01 11:44:40,824 DEBUG TRAIN Batch 55/1300 loss 4.134007 loss_att 4.831302 loss_ctc 6.698910 loss_rnnt 3.488888 hw_loss 0.306886 lr 0.00028736 rank 6
2023-03-01 11:44:40,825 DEBUG TRAIN Batch 55/1300 loss 7.334373 loss_att 10.037970 loss_ctc 17.007452 loss_rnnt 5.431221 hw_loss 0.136294 lr 0.00028735 rank 5
2023-03-01 11:44:40,832 DEBUG TRAIN Batch 55/1300 loss 7.946880 loss_att 9.266274 loss_ctc 14.619527 loss_rnnt 6.616776 hw_loss 0.331011 lr 0.00028736 rank 0
2023-03-01 11:44:40,832 DEBUG TRAIN Batch 55/1300 loss 8.056814 loss_att 8.560266 loss_ctc 11.529181 loss_rnnt 7.312896 hw_loss 0.337960 lr 0.00028735 rank 3
2023-03-01 11:44:40,833 DEBUG TRAIN Batch 55/1300 loss 3.565699 loss_att 5.538040 loss_ctc 4.762408 loss_rnnt 2.927478 hw_loss 0.157858 lr 0.00028735 rank 7
2023-03-01 11:44:40,835 DEBUG TRAIN Batch 55/1300 loss 8.479904 loss_att 7.936381 loss_ctc 11.008761 loss_rnnt 8.096370 hw_loss 0.290736 lr 0.00028735 rank 4
2023-03-01 11:44:40,852 DEBUG TRAIN Batch 55/1300 loss 9.930462 loss_att 14.142110 loss_ctc 15.686778 loss_rnnt 8.288620 hw_loss 0.060006 lr 0.00028735 rank 1
2023-03-01 11:45:20,446 DEBUG TRAIN Batch 55/1400 loss 1.921890 loss_att 4.926623 loss_ctc 3.258377 loss_rnnt 1.029476 hw_loss 0.212380 lr 0.00028734 rank 5
2023-03-01 11:45:20,447 DEBUG TRAIN Batch 55/1400 loss 4.008342 loss_att 7.228692 loss_ctc 5.871532 loss_rnnt 3.002009 hw_loss 0.213445 lr 0.00028735 rank 2
2023-03-01 11:45:20,449 DEBUG TRAIN Batch 55/1400 loss 1.511261 loss_att 4.082569 loss_ctc 4.571700 loss_rnnt 0.441265 hw_loss 0.276892 lr 0.00028734 rank 4
2023-03-01 11:45:20,453 DEBUG TRAIN Batch 55/1400 loss 7.539697 loss_att 11.659094 loss_ctc 11.517138 loss_rnnt 5.965316 hw_loss 0.412830 lr 0.00028734 rank 3
2023-03-01 11:45:20,456 DEBUG TRAIN Batch 55/1400 loss 2.888276 loss_att 5.367581 loss_ctc 2.701889 loss_rnnt 2.319090 hw_loss 0.184080 lr 0.00028734 rank 7
2023-03-01 11:45:20,460 DEBUG TRAIN Batch 55/1400 loss 3.310785 loss_att 6.183325 loss_ctc 6.521455 loss_rnnt 2.146599 hw_loss 0.302978 lr 0.00028735 rank 0
2023-03-01 11:45:20,470 DEBUG TRAIN Batch 55/1400 loss 4.747828 loss_att 8.020016 loss_ctc 10.263540 loss_rnnt 3.259703 hw_loss 0.184236 lr 0.00028734 rank 6
2023-03-01 11:45:20,483 DEBUG TRAIN Batch 55/1400 loss 11.041726 loss_att 13.698236 loss_ctc 17.154453 loss_rnnt 9.619095 hw_loss 0.143059 lr 0.00028734 rank 1
2023-03-01 11:46:24,868 DEBUG TRAIN Batch 55/1500 loss 7.008992 loss_att 9.693570 loss_ctc 11.942991 loss_rnnt 5.684924 hw_loss 0.242410 lr 0.00028733 rank 5
2023-03-01 11:46:24,874 DEBUG TRAIN Batch 55/1500 loss 2.231840 loss_att 4.086775 loss_ctc 4.442750 loss_rnnt 1.468729 hw_loss 0.182506 lr 0.00028732 rank 3
2023-03-01 11:46:24,881 DEBUG TRAIN Batch 55/1500 loss 13.289601 loss_att 15.041903 loss_ctc 21.544088 loss_rnnt 11.662622 hw_loss 0.329848 lr 0.00028734 rank 0
2023-03-01 11:46:24,888 DEBUG TRAIN Batch 55/1500 loss 18.495176 loss_att 23.948862 loss_ctc 37.075478 loss_rnnt 14.784014 hw_loss 0.268220 lr 0.00028733 rank 7
2023-03-01 11:46:24,888 DEBUG TRAIN Batch 55/1500 loss 1.153736 loss_att 2.504863 loss_ctc 1.395133 loss_rnnt 0.732052 hw_loss 0.223637 lr 0.00028733 rank 1
2023-03-01 11:46:24,894 DEBUG TRAIN Batch 55/1500 loss 3.832650 loss_att 7.120042 loss_ctc 7.430545 loss_rnnt 2.618031 hw_loss 0.145166 lr 0.00028733 rank 4
2023-03-01 11:46:24,902 DEBUG TRAIN Batch 55/1500 loss 7.714089 loss_att 10.135242 loss_ctc 9.289972 loss_rnnt 6.884962 hw_loss 0.252711 lr 0.00028733 rank 6
2023-03-01 11:46:24,909 DEBUG TRAIN Batch 55/1500 loss 5.775893 loss_att 7.608791 loss_ctc 7.483655 loss_rnnt 5.053729 hw_loss 0.239780 lr 0.00028733 rank 2
2023-03-01 11:47:03,261 DEBUG TRAIN Batch 55/1600 loss 4.090561 loss_att 5.763827 loss_ctc 5.411114 loss_rnnt 3.459650 hw_loss 0.225346 lr 0.00028732 rank 4
2023-03-01 11:47:03,264 DEBUG TRAIN Batch 55/1600 loss 4.109601 loss_att 6.423208 loss_ctc 6.333588 loss_rnnt 3.259841 hw_loss 0.169701 lr 0.00028732 rank 2
2023-03-01 11:47:03,271 DEBUG TRAIN Batch 55/1600 loss 4.593631 loss_att 7.423265 loss_ctc 8.948116 loss_rnnt 3.323726 hw_loss 0.231336 lr 0.00028732 rank 1
2023-03-01 11:47:03,274 DEBUG TRAIN Batch 55/1600 loss 3.719936 loss_att 7.881904 loss_ctc 9.320519 loss_rnnt 2.061837 hw_loss 0.148053 lr 0.00028731 rank 3
2023-03-01 11:47:03,276 DEBUG TRAIN Batch 55/1600 loss 3.577364 loss_att 6.851999 loss_ctc 8.377962 loss_rnnt 2.138489 hw_loss 0.269753 lr 0.00028731 rank 7
2023-03-01 11:47:03,282 DEBUG TRAIN Batch 55/1600 loss 2.941900 loss_att 6.460224 loss_ctc 7.171267 loss_rnnt 1.583339 hw_loss 0.170587 lr 0.00028733 rank 0
2023-03-01 11:47:03,328 DEBUG TRAIN Batch 55/1600 loss 6.126521 loss_att 7.497471 loss_ctc 9.768489 loss_rnnt 5.206332 hw_loss 0.300754 lr 0.00028732 rank 6
2023-03-01 11:47:03,354 DEBUG TRAIN Batch 55/1600 loss 6.657482 loss_att 9.525083 loss_ctc 9.797979 loss_rnnt 5.617600 hw_loss 0.089303 lr 0.00028732 rank 5
2023-03-01 11:47:42,683 DEBUG TRAIN Batch 55/1700 loss 5.939201 loss_att 9.419256 loss_ctc 13.862376 loss_rnnt 4.100549 hw_loss 0.161658 lr 0.00028731 rank 5
2023-03-01 11:47:42,684 DEBUG TRAIN Batch 55/1700 loss 10.110458 loss_att 13.284764 loss_ctc 20.388815 loss_rnnt 8.005060 hw_loss 0.187665 lr 0.00028731 rank 1
2023-03-01 11:47:42,686 DEBUG TRAIN Batch 55/1700 loss 2.589151 loss_att 5.275895 loss_ctc 4.916426 loss_rnnt 1.653847 hw_loss 0.164346 lr 0.00028731 rank 6
2023-03-01 11:47:42,703 DEBUG TRAIN Batch 55/1700 loss 5.950481 loss_att 9.993310 loss_ctc 9.322975 loss_rnnt 4.574664 hw_loss 0.220471 lr 0.00028730 rank 3
2023-03-01 11:47:42,704 DEBUG TRAIN Batch 55/1700 loss 4.809671 loss_att 8.890806 loss_ctc 9.186224 loss_rnnt 3.277663 hw_loss 0.247950 lr 0.00028731 rank 4
2023-03-01 11:47:42,707 DEBUG TRAIN Batch 55/1700 loss 4.731372 loss_att 6.223433 loss_ctc 7.802117 loss_rnnt 3.933281 hw_loss 0.169210 lr 0.00028731 rank 2
2023-03-01 11:47:42,713 DEBUG TRAIN Batch 55/1700 loss 4.043240 loss_att 7.483142 loss_ctc 10.598989 loss_rnnt 2.444080 hw_loss 0.069524 lr 0.00028730 rank 7
2023-03-01 11:47:42,717 DEBUG TRAIN Batch 55/1700 loss 3.391513 loss_att 7.097299 loss_ctc 8.770350 loss_rnnt 1.826387 hw_loss 0.200232 lr 0.00028732 rank 0
2023-03-01 11:48:48,335 DEBUG TRAIN Batch 55/1800 loss 3.217604 loss_att 6.489350 loss_ctc 7.837629 loss_rnnt 1.827440 hw_loss 0.224647 lr 0.00028729 rank 1
2023-03-01 11:48:48,351 DEBUG TRAIN Batch 55/1800 loss 3.564144 loss_att 5.916673 loss_ctc 4.175988 loss_rnnt 2.929050 hw_loss 0.155643 lr 0.00028730 rank 6
2023-03-01 11:48:48,351 DEBUG TRAIN Batch 55/1800 loss 6.587998 loss_att 8.161363 loss_ctc 9.754638 loss_rnnt 5.673111 hw_loss 0.333740 lr 0.00028729 rank 5
2023-03-01 11:48:48,352 DEBUG TRAIN Batch 55/1800 loss 3.565084 loss_att 4.869409 loss_ctc 7.647892 loss_rnnt 2.622477 hw_loss 0.257563 lr 0.00028729 rank 4
2023-03-01 11:48:48,356 DEBUG TRAIN Batch 55/1800 loss 7.396266 loss_att 9.531316 loss_ctc 9.488854 loss_rnnt 6.489255 hw_loss 0.376853 lr 0.00028730 rank 0
2023-03-01 11:48:48,357 DEBUG TRAIN Batch 55/1800 loss 2.863010 loss_att 5.628499 loss_ctc 5.481453 loss_rnnt 1.845547 hw_loss 0.216075 lr 0.00028729 rank 7
2023-03-01 11:48:48,359 DEBUG TRAIN Batch 55/1800 loss 3.339462 loss_att 5.206213 loss_ctc 4.959460 loss_rnnt 2.638238 hw_loss 0.209765 lr 0.00028730 rank 2
2023-03-01 11:48:48,361 DEBUG TRAIN Batch 55/1800 loss 3.346046 loss_att 6.109471 loss_ctc 6.036997 loss_rnnt 2.318360 hw_loss 0.217890 lr 0.00028729 rank 3
2023-03-01 11:49:28,165 DEBUG TRAIN Batch 55/1900 loss 7.611155 loss_att 9.460226 loss_ctc 8.490198 loss_rnnt 7.090602 hw_loss 0.062872 lr 0.00028728 rank 1
2023-03-01 11:49:28,181 DEBUG TRAIN Batch 55/1900 loss 7.653668 loss_att 9.931426 loss_ctc 11.831284 loss_rnnt 6.481052 hw_loss 0.300091 lr 0.00028729 rank 0
2023-03-01 11:49:28,181 DEBUG TRAIN Batch 55/1900 loss 6.549537 loss_att 8.395191 loss_ctc 11.295088 loss_rnnt 5.358230 hw_loss 0.355193 lr 0.00028728 rank 4
2023-03-01 11:49:28,182 DEBUG TRAIN Batch 55/1900 loss 5.903318 loss_att 6.495049 loss_ctc 8.937491 loss_rnnt 5.189597 hw_loss 0.357785 lr 0.00028728 rank 5
2023-03-01 11:49:28,183 DEBUG TRAIN Batch 55/1900 loss 7.742179 loss_att 9.835520 loss_ctc 14.624693 loss_rnnt 6.294051 hw_loss 0.209609 lr 0.00028728 rank 3
2023-03-01 11:49:28,184 DEBUG TRAIN Batch 55/1900 loss 1.538274 loss_att 4.689798 loss_ctc 3.047899 loss_rnnt 0.498092 hw_loss 0.391114 lr 0.00028729 rank 2
2023-03-01 11:49:28,184 DEBUG TRAIN Batch 55/1900 loss 6.519357 loss_att 9.893549 loss_ctc 13.311728 loss_rnnt 4.847817 hw_loss 0.170723 lr 0.00028729 rank 6
2023-03-01 11:49:28,589 DEBUG TRAIN Batch 55/1900 loss 2.913963 loss_att 7.288526 loss_ctc 7.376218 loss_rnnt 1.372606 hw_loss 0.134020 lr 0.00028728 rank 7
2023-03-01 11:50:07,517 DEBUG TRAIN Batch 55/2000 loss 6.107806 loss_att 9.102844 loss_ctc 8.910779 loss_rnnt 5.040562 hw_loss 0.177201 lr 0.00028728 rank 0
2023-03-01 11:50:07,520 DEBUG TRAIN Batch 55/2000 loss 1.938017 loss_att 5.452015 loss_ctc 5.645434 loss_rnnt 0.693777 hw_loss 0.088346 lr 0.00028728 rank 2
2023-03-01 11:50:07,523 DEBUG TRAIN Batch 55/2000 loss 2.101536 loss_att 3.800545 loss_ctc 3.669196 loss_rnnt 1.477327 hw_loss 0.141348 lr 0.00028727 rank 7
2023-03-01 11:50:07,523 DEBUG TRAIN Batch 55/2000 loss 8.714637 loss_att 12.951680 loss_ctc 13.964287 loss_rnnt 7.096274 hw_loss 0.133126 lr 0.00028727 rank 4
2023-03-01 11:50:07,524 DEBUG TRAIN Batch 55/2000 loss 5.777693 loss_att 8.414924 loss_ctc 11.820762 loss_rnnt 4.294859 hw_loss 0.280585 lr 0.00028727 rank 6
2023-03-01 11:50:07,545 DEBUG TRAIN Batch 55/2000 loss 13.150835 loss_att 13.710196 loss_ctc 14.947622 loss_rnnt 12.635543 hw_loss 0.307217 lr 0.00028727 rank 3
2023-03-01 11:50:07,555 DEBUG TRAIN Batch 55/2000 loss 6.540912 loss_att 8.414805 loss_ctc 10.498099 loss_rnnt 5.507596 hw_loss 0.245459 lr 0.00028727 rank 1
2023-03-01 11:50:07,573 DEBUG TRAIN Batch 55/2000 loss 3.691277 loss_att 6.588894 loss_ctc 6.193660 loss_rnnt 2.725375 hw_loss 0.098865 lr 0.00028727 rank 5
2023-03-01 11:50:48,193 DEBUG TRAIN Batch 55/2100 loss 2.970569 loss_att 5.577536 loss_ctc 3.864256 loss_rnnt 2.159913 hw_loss 0.318946 lr 0.00028726 rank 6
2023-03-01 11:50:48,200 DEBUG TRAIN Batch 55/2100 loss 7.575779 loss_att 12.110399 loss_ctc 11.720466 loss_rnnt 6.063437 hw_loss 0.098987 lr 0.00028726 rank 4
2023-03-01 11:50:48,201 DEBUG TRAIN Batch 55/2100 loss 8.457862 loss_att 11.789050 loss_ctc 15.568954 loss_rnnt 6.746669 hw_loss 0.181519 lr 0.00028726 rank 2
2023-03-01 11:50:48,204 DEBUG TRAIN Batch 55/2100 loss 15.703237 loss_att 19.020523 loss_ctc 24.886658 loss_rnnt 13.658942 hw_loss 0.293215 lr 0.00028727 rank 0
2023-03-01 11:50:48,205 DEBUG TRAIN Batch 55/2100 loss 4.436324 loss_att 6.663805 loss_ctc 5.465143 loss_rnnt 3.763856 hw_loss 0.168368 lr 0.00028726 rank 7
2023-03-01 11:50:48,218 DEBUG TRAIN Batch 55/2100 loss 11.964964 loss_att 13.608440 loss_ctc 18.319555 loss_rnnt 10.670767 hw_loss 0.221668 lr 0.00028726 rank 5
2023-03-01 11:50:48,224 DEBUG TRAIN Batch 55/2100 loss 3.021820 loss_att 6.131060 loss_ctc 6.204275 loss_rnnt 1.841754 hw_loss 0.251044 lr 0.00028725 rank 3
2023-03-01 11:50:48,234 DEBUG TRAIN Batch 55/2100 loss 4.012236 loss_att 6.743042 loss_ctc 8.154387 loss_rnnt 2.846539 hw_loss 0.126091 lr 0.00028726 rank 1
2023-03-01 11:51:50,695 DEBUG TRAIN Batch 55/2200 loss 2.855129 loss_att 5.831306 loss_ctc 5.733444 loss_rnnt 1.747932 hw_loss 0.240350 lr 0.00028726 rank 0
2023-03-01 11:51:50,711 DEBUG TRAIN Batch 55/2200 loss 10.232724 loss_att 13.288124 loss_ctc 16.573576 loss_rnnt 8.653883 hw_loss 0.229338 lr 0.00028725 rank 6
2023-03-01 11:51:50,711 DEBUG TRAIN Batch 55/2200 loss 9.214130 loss_att 12.458589 loss_ctc 16.843687 loss_rnnt 7.412218 hw_loss 0.254523 lr 0.00028724 rank 3
2023-03-01 11:51:50,711 DEBUG TRAIN Batch 55/2200 loss 2.260307 loss_att 6.018232 loss_ctc 3.175827 loss_rnnt 1.269857 hw_loss 0.218992 lr 0.00028725 rank 5
2023-03-01 11:51:50,713 DEBUG TRAIN Batch 55/2200 loss 3.814724 loss_att 6.511883 loss_ctc 5.687877 loss_rnnt 2.959219 hw_loss 0.124351 lr 0.00028725 rank 2
2023-03-01 11:51:50,714 DEBUG TRAIN Batch 55/2200 loss 9.744184 loss_att 13.227396 loss_ctc 19.497620 loss_rnnt 7.627203 hw_loss 0.224778 lr 0.00028724 rank 7
2023-03-01 11:51:50,716 DEBUG TRAIN Batch 55/2200 loss 9.370195 loss_att 10.095570 loss_ctc 14.360493 loss_rnnt 8.465159 hw_loss 0.177352 lr 0.00028725 rank 1
2023-03-01 11:51:50,737 DEBUG TRAIN Batch 55/2200 loss 7.461823 loss_att 10.756650 loss_ctc 15.665954 loss_rnnt 5.566006 hw_loss 0.268062 lr 0.00028725 rank 4
2023-03-01 11:52:28,947 DEBUG TRAIN Batch 55/2300 loss 9.449268 loss_att 11.767920 loss_ctc 16.358166 loss_rnnt 7.955134 hw_loss 0.204783 lr 0.00028724 rank 0
2023-03-01 11:52:28,952 DEBUG TRAIN Batch 55/2300 loss 6.347078 loss_att 9.775721 loss_ctc 11.727617 loss_rnnt 4.883886 hw_loss 0.112610 lr 0.00028723 rank 3
2023-03-01 11:52:28,962 DEBUG TRAIN Batch 55/2300 loss 5.657796 loss_att 9.482152 loss_ctc 11.703159 loss_rnnt 3.982631 hw_loss 0.195460 lr 0.00028723 rank 7
2023-03-01 11:52:28,969 DEBUG TRAIN Batch 55/2300 loss 6.905973 loss_att 7.685801 loss_ctc 10.150293 loss_rnnt 6.248882 hw_loss 0.128529 lr 0.00028724 rank 2
2023-03-01 11:52:28,972 DEBUG TRAIN Batch 55/2300 loss 11.076432 loss_att 15.086233 loss_ctc 16.108175 loss_rnnt 9.533017 hw_loss 0.132292 lr 0.00028723 rank 5
2023-03-01 11:52:28,973 DEBUG TRAIN Batch 55/2300 loss 5.768932 loss_att 7.822917 loss_ctc 13.015446 loss_rnnt 4.203078 hw_loss 0.354103 lr 0.00028723 rank 1
2023-03-01 11:52:29,001 DEBUG TRAIN Batch 55/2300 loss 4.916380 loss_att 7.462523 loss_ctc 10.897681 loss_rnnt 3.549726 hw_loss 0.112347 lr 0.00028723 rank 4
2023-03-01 11:52:29,030 DEBUG TRAIN Batch 55/2300 loss 6.000095 loss_att 9.387857 loss_ctc 10.197576 loss_rnnt 4.619364 hw_loss 0.269090 lr 0.00028724 rank 6
2023-03-01 11:53:08,080 DEBUG TRAIN Batch 55/2400 loss 5.021474 loss_att 9.297594 loss_ctc 11.212867 loss_rnnt 3.195978 hw_loss 0.271412 lr 0.00028723 rank 2
2023-03-01 11:53:08,084 DEBUG TRAIN Batch 55/2400 loss 5.228446 loss_att 8.122042 loss_ctc 9.137226 loss_rnnt 4.023226 hw_loss 0.197493 lr 0.00028722 rank 4
2023-03-01 11:53:08,084 DEBUG TRAIN Batch 55/2400 loss 6.486246 loss_att 10.401472 loss_ctc 11.032771 loss_rnnt 5.069023 hw_loss 0.052452 lr 0.00028722 rank 5
2023-03-01 11:53:08,085 DEBUG TRAIN Batch 55/2400 loss 8.088880 loss_att 8.153385 loss_ctc 10.861428 loss_rnnt 7.529315 hw_loss 0.331857 lr 0.00028723 rank 6
2023-03-01 11:53:08,094 DEBUG TRAIN Batch 55/2400 loss 7.701949 loss_att 8.914480 loss_ctc 9.894993 loss_rnnt 7.064301 hw_loss 0.192630 lr 0.00028723 rank 0
2023-03-01 11:53:08,098 DEBUG TRAIN Batch 55/2400 loss 4.164408 loss_att 5.891694 loss_ctc 4.455747 loss_rnnt 3.735629 hw_loss 0.083392 lr 0.00028722 rank 7
2023-03-01 11:53:08,101 DEBUG TRAIN Batch 55/2400 loss 4.444644 loss_att 7.022254 loss_ctc 7.323321 loss_rnnt 3.505274 hw_loss 0.075047 lr 0.00028722 rank 3
2023-03-01 11:53:08,124 DEBUG TRAIN Batch 55/2400 loss 7.764651 loss_att 10.436540 loss_ctc 13.571345 loss_rnnt 6.347543 hw_loss 0.203443 lr 0.00028722 rank 1
2023-03-01 11:54:12,099 DEBUG TRAIN Batch 55/2500 loss 10.831060 loss_att 11.553539 loss_ctc 15.130443 loss_rnnt 10.003852 hw_loss 0.205241 lr 0.00028722 rank 0
2023-03-01 11:54:12,102 DEBUG TRAIN Batch 55/2500 loss 5.216161 loss_att 6.723126 loss_ctc 8.032013 loss_rnnt 4.323097 hw_loss 0.405418 lr 0.00028721 rank 1
2023-03-01 11:54:12,102 DEBUG TRAIN Batch 55/2500 loss 5.579901 loss_att 7.887691 loss_ctc 9.048571 loss_rnnt 4.514303 hw_loss 0.265408 lr 0.00028722 rank 2
2023-03-01 11:54:12,102 DEBUG TRAIN Batch 55/2500 loss 10.456435 loss_att 12.642248 loss_ctc 17.810217 loss_rnnt 8.908417 hw_loss 0.244409 lr 0.00028721 rank 7
2023-03-01 11:54:12,106 DEBUG TRAIN Batch 55/2500 loss 9.128210 loss_att 10.257199 loss_ctc 13.944013 loss_rnnt 8.105011 hw_loss 0.291176 lr 0.00028721 rank 5
2023-03-01 11:54:12,109 DEBUG TRAIN Batch 55/2500 loss 5.494717 loss_att 6.564343 loss_ctc 9.250441 loss_rnnt 4.712252 hw_loss 0.127082 lr 0.00028721 rank 4
2023-03-01 11:54:12,112 DEBUG TRAIN Batch 55/2500 loss 3.404826 loss_att 6.659499 loss_ctc 6.138287 loss_rnnt 2.293731 hw_loss 0.179434 lr 0.00028721 rank 6
2023-03-01 11:54:12,115 DEBUG TRAIN Batch 55/2500 loss 4.336938 loss_att 5.593760 loss_ctc 5.646206 loss_rnnt 3.805016 hw_loss 0.198730 lr 0.00028721 rank 3
2023-03-01 11:54:51,076 DEBUG TRAIN Batch 55/2600 loss 6.302312 loss_att 9.623407 loss_ctc 9.321593 loss_rnnt 5.075391 hw_loss 0.300246 lr 0.00028720 rank 5
2023-03-01 11:54:51,092 DEBUG TRAIN Batch 55/2600 loss 7.946676 loss_att 8.078922 loss_ctc 11.000929 loss_rnnt 7.289319 hw_loss 0.419389 lr 0.00028721 rank 0
2023-03-01 11:54:51,093 DEBUG TRAIN Batch 55/2600 loss 7.515365 loss_att 8.332110 loss_ctc 9.803616 loss_rnnt 6.929119 hw_loss 0.220869 lr 0.00028720 rank 7
2023-03-01 11:54:51,094 DEBUG TRAIN Batch 55/2600 loss 7.225680 loss_att 10.243334 loss_ctc 13.535992 loss_rnnt 5.678104 hw_loss 0.192507 lr 0.00028720 rank 2
2023-03-01 11:54:51,096 DEBUG TRAIN Batch 55/2600 loss 17.268793 loss_att 19.494286 loss_ctc 21.230993 loss_rnnt 16.294479 hw_loss 0.001729 lr 0.00028720 rank 4
2023-03-01 11:54:51,097 DEBUG TRAIN Batch 55/2600 loss 10.651654 loss_att 13.171587 loss_ctc 16.118067 loss_rnnt 9.268770 hw_loss 0.281330 lr 0.00028720 rank 6
2023-03-01 11:54:51,099 DEBUG TRAIN Batch 55/2600 loss 9.497070 loss_att 9.653700 loss_ctc 15.343480 loss_rnnt 8.498909 hw_loss 0.351213 lr 0.00028719 rank 3
2023-03-01 11:54:51,134 DEBUG TRAIN Batch 55/2600 loss 7.528499 loss_att 12.007516 loss_ctc 11.217846 loss_rnnt 6.092371 hw_loss 0.090773 lr 0.00028720 rank 1
2023-03-01 11:55:29,594 DEBUG TRAIN Batch 55/2700 loss 7.730954 loss_att 9.219748 loss_ctc 13.652138 loss_rnnt 6.493049 hw_loss 0.282480 lr 0.00028719 rank 6
2023-03-01 11:55:29,595 DEBUG TRAIN Batch 55/2700 loss 5.859122 loss_att 7.307023 loss_ctc 9.873180 loss_rnnt 4.848861 hw_loss 0.347763 lr 0.00028720 rank 0
2023-03-01 11:55:29,599 DEBUG TRAIN Batch 55/2700 loss 3.349401 loss_att 6.299614 loss_ctc 6.913827 loss_rnnt 2.201617 hw_loss 0.154658 lr 0.00028719 rank 2
2023-03-01 11:55:29,600 DEBUG TRAIN Batch 55/2700 loss 3.707742 loss_att 7.586158 loss_ctc 9.181004 loss_rnnt 2.069166 hw_loss 0.249608 lr 0.00028718 rank 7
2023-03-01 11:55:29,599 DEBUG TRAIN Batch 55/2700 loss 4.138986 loss_att 7.383556 loss_ctc 5.687513 loss_rnnt 3.226796 hw_loss 0.106510 lr 0.00028719 rank 1
2023-03-01 11:55:29,600 DEBUG TRAIN Batch 55/2700 loss 6.840067 loss_att 9.309001 loss_ctc 9.304787 loss_rnnt 5.873114 hw_loss 0.271008 lr 0.00028719 rank 4
2023-03-01 11:55:29,600 DEBUG TRAIN Batch 55/2700 loss 4.972412 loss_att 7.427810 loss_ctc 6.031551 loss_rnnt 4.262256 hw_loss 0.145982 lr 0.00028718 rank 3
2023-03-01 11:55:29,602 DEBUG TRAIN Batch 55/2700 loss 11.216029 loss_att 11.933689 loss_ctc 16.275902 loss_rnnt 10.259753 hw_loss 0.258928 lr 0.00028719 rank 5
2023-03-01 11:56:09,349 DEBUG TRAIN Batch 55/2800 loss 11.933542 loss_att 15.017458 loss_ctc 26.236641 loss_rnnt 9.226826 hw_loss 0.342852 lr 0.00028718 rank 6
2023-03-01 11:56:09,358 DEBUG TRAIN Batch 55/2800 loss 3.453276 loss_att 6.670652 loss_ctc 6.921158 loss_rnnt 2.271258 hw_loss 0.142796 lr 0.00028718 rank 2
2023-03-01 11:56:09,360 DEBUG TRAIN Batch 55/2800 loss 7.884685 loss_att 12.319002 loss_ctc 18.994419 loss_rnnt 5.373244 hw_loss 0.268650 lr 0.00028717 rank 7
2023-03-01 11:56:09,361 DEBUG TRAIN Batch 55/2800 loss 5.748960 loss_att 11.042476 loss_ctc 12.547317 loss_rnnt 3.685119 hw_loss 0.185045 lr 0.00028717 rank 1
2023-03-01 11:56:09,363 DEBUG TRAIN Batch 55/2800 loss 7.672569 loss_att 14.345135 loss_ctc 13.008822 loss_rnnt 5.554676 hw_loss 0.134773 lr 0.00028719 rank 0
2023-03-01 11:56:09,365 DEBUG TRAIN Batch 55/2800 loss 2.130501 loss_att 5.333083 loss_ctc 6.241296 loss_rnnt 0.843812 hw_loss 0.183875 lr 0.00028717 rank 3
2023-03-01 11:56:09,379 DEBUG TRAIN Batch 55/2800 loss 9.774933 loss_att 12.906298 loss_ctc 15.747610 loss_rnnt 8.199446 hw_loss 0.286608 lr 0.00028718 rank 5
2023-03-01 11:56:09,399 DEBUG TRAIN Batch 55/2800 loss 3.588630 loss_att 5.626009 loss_ctc 5.176039 loss_rnnt 2.865040 hw_loss 0.195863 lr 0.00028718 rank 4
2023-03-01 11:57:12,761 DEBUG TRAIN Batch 55/2900 loss 9.040247 loss_att 10.129349 loss_ctc 13.072206 loss_rnnt 8.186569 hw_loss 0.184242 lr 0.00028717 rank 0
2023-03-01 11:57:12,773 DEBUG TRAIN Batch 55/2900 loss 2.165542 loss_att 5.421654 loss_ctc 4.988029 loss_rnnt 1.050347 hw_loss 0.164326 lr 0.00028716 rank 3
2023-03-01 11:57:12,774 DEBUG TRAIN Batch 55/2900 loss 8.373240 loss_att 12.035566 loss_ctc 14.135136 loss_rnnt 6.786685 hw_loss 0.160941 lr 0.00028716 rank 4
2023-03-01 11:57:12,785 DEBUG TRAIN Batch 55/2900 loss 9.124478 loss_att 12.393147 loss_ctc 11.603422 loss_rnnt 8.058779 hw_loss 0.152701 lr 0.00028716 rank 7
2023-03-01 11:57:12,787 DEBUG TRAIN Batch 55/2900 loss 3.823154 loss_att 6.368649 loss_ctc 7.009970 loss_rnnt 2.810158 hw_loss 0.148105 lr 0.00028717 rank 2
2023-03-01 11:57:12,788 DEBUG TRAIN Batch 55/2900 loss 3.862150 loss_att 9.375276 loss_ctc 8.333455 loss_rnnt 2.075087 hw_loss 0.165497 lr 0.00028716 rank 5
2023-03-01 11:57:12,788 DEBUG TRAIN Batch 55/2900 loss 4.509876 loss_att 6.918294 loss_ctc 5.337421 loss_rnnt 3.877267 hw_loss 0.076098 lr 0.00028717 rank 6
2023-03-01 11:57:12,831 DEBUG TRAIN Batch 55/2900 loss 3.334168 loss_att 6.955830 loss_ctc 6.629624 loss_rnnt 2.046199 hw_loss 0.232956 lr 0.00028716 rank 1
2023-03-01 11:57:51,736 DEBUG TRAIN Batch 55/3000 loss 12.511568 loss_att 13.459829 loss_ctc 20.692751 loss_rnnt 11.179628 hw_loss 0.096493 lr 0.00028716 rank 0
2023-03-01 11:57:51,750 DEBUG TRAIN Batch 55/3000 loss 9.420535 loss_att 10.469894 loss_ctc 14.707832 loss_rnnt 8.389895 hw_loss 0.217116 lr 0.00028715 rank 4
2023-03-01 11:57:51,751 DEBUG TRAIN Batch 55/3000 loss 8.069354 loss_att 12.604912 loss_ctc 13.233441 loss_rnnt 6.364133 hw_loss 0.205433 lr 0.00028715 rank 1
2023-03-01 11:57:51,753 DEBUG TRAIN Batch 55/3000 loss 4.256933 loss_att 6.337622 loss_ctc 6.912095 loss_rnnt 3.407887 hw_loss 0.147912 lr 0.00028715 rank 5
2023-03-01 11:57:51,756 DEBUG TRAIN Batch 55/3000 loss 3.162869 loss_att 6.227962 loss_ctc 3.653100 loss_rnnt 2.419757 hw_loss 0.121367 lr 0.00028716 rank 2
2023-03-01 11:57:51,757 DEBUG TRAIN Batch 55/3000 loss 7.169648 loss_att 9.450018 loss_ctc 13.350034 loss_rnnt 5.743837 hw_loss 0.273160 lr 0.00028715 rank 7
2023-03-01 11:57:51,760 DEBUG TRAIN Batch 55/3000 loss 3.731168 loss_att 7.160809 loss_ctc 7.634139 loss_rnnt 2.357793 hw_loss 0.313219 lr 0.00028715 rank 6
2023-03-01 11:57:51,761 DEBUG TRAIN Batch 55/3000 loss 7.761555 loss_att 9.531311 loss_ctc 14.973236 loss_rnnt 6.322629 hw_loss 0.231408 lr 0.00028715 rank 3
2023-03-01 11:58:30,940 DEBUG TRAIN Batch 55/3100 loss 2.907966 loss_att 7.001689 loss_ctc 4.874352 loss_rnnt 1.718683 hw_loss 0.203162 lr 0.00028714 rank 7
2023-03-01 11:58:30,946 DEBUG TRAIN Batch 55/3100 loss 7.097551 loss_att 8.337217 loss_ctc 10.167593 loss_rnnt 6.279991 hw_loss 0.300540 lr 0.00028714 rank 1
2023-03-01 11:58:30,951 DEBUG TRAIN Batch 55/3100 loss 7.873540 loss_att 10.855007 loss_ctc 11.723345 loss_rnnt 6.658214 hw_loss 0.198236 lr 0.00028713 rank 3
2023-03-01 11:58:30,958 DEBUG TRAIN Batch 55/3100 loss 6.461153 loss_att 10.050930 loss_ctc 12.048664 loss_rnnt 4.867397 hw_loss 0.245248 lr 0.00028714 rank 6
2023-03-01 11:58:30,964 DEBUG TRAIN Batch 55/3100 loss 3.335640 loss_att 6.475999 loss_ctc 5.648719 loss_rnnt 2.184811 hw_loss 0.401900 lr 0.00028714 rank 5
2023-03-01 11:58:30,965 DEBUG TRAIN Batch 55/3100 loss 7.278019 loss_att 7.841859 loss_ctc 9.540851 loss_rnnt 6.753665 hw_loss 0.206018 lr 0.00028715 rank 0
2023-03-01 11:58:30,966 DEBUG TRAIN Batch 55/3100 loss 6.490002 loss_att 9.393959 loss_ctc 11.928558 loss_rnnt 5.093708 hw_loss 0.169428 lr 0.00028714 rank 2
2023-03-01 11:58:30,972 DEBUG TRAIN Batch 55/3100 loss 5.225399 loss_att 6.715427 loss_ctc 12.252868 loss_rnnt 3.878094 hw_loss 0.210569 lr 0.00028714 rank 4
2023-03-01 11:59:35,110 DEBUG TRAIN Batch 55/3200 loss 4.055293 loss_att 8.237652 loss_ctc 8.608935 loss_rnnt 2.427207 hw_loss 0.345866 lr 0.00028713 rank 7
2023-03-01 11:59:35,111 DEBUG TRAIN Batch 55/3200 loss 8.292060 loss_att 12.164942 loss_ctc 11.327006 loss_rnnt 6.954731 hw_loss 0.296423 lr 0.00028713 rank 2
2023-03-01 11:59:35,114 DEBUG TRAIN Batch 55/3200 loss 3.549162 loss_att 6.086478 loss_ctc 8.687632 loss_rnnt 2.263364 hw_loss 0.174759 lr 0.00028713 rank 4
2023-03-01 11:59:35,125 DEBUG TRAIN Batch 55/3200 loss 6.598733 loss_att 8.618485 loss_ctc 10.095373 loss_rnnt 5.620903 hw_loss 0.201865 lr 0.00028714 rank 0
2023-03-01 11:59:35,138 DEBUG TRAIN Batch 55/3200 loss 12.175148 loss_att 15.770163 loss_ctc 19.557125 loss_rnnt 10.275618 hw_loss 0.367994 lr 0.00028713 rank 1
2023-03-01 11:59:35,165 DEBUG TRAIN Batch 55/3200 loss 7.147501 loss_att 8.465726 loss_ctc 11.625254 loss_rnnt 6.119298 hw_loss 0.314107 lr 0.00028713 rank 5
2023-03-01 11:59:35,170 DEBUG TRAIN Batch 55/3200 loss 5.700241 loss_att 7.406541 loss_ctc 10.271935 loss_rnnt 4.595961 hw_loss 0.287736 lr 0.00028713 rank 6
2023-03-01 11:59:35,174 DEBUG TRAIN Batch 55/3200 loss 6.961229 loss_att 8.265569 loss_ctc 14.512503 loss_rnnt 5.565558 hw_loss 0.239938 lr 0.00028712 rank 3
2023-03-01 12:00:14,211 DEBUG TRAIN Batch 55/3300 loss 2.840189 loss_att 3.216870 loss_ctc 1.936045 loss_rnnt 2.692350 hw_loss 0.361981 lr 0.00028712 rank 4
2023-03-01 12:00:14,215 DEBUG TRAIN Batch 55/3300 loss 10.446282 loss_att 14.735447 loss_ctc 17.447464 loss_rnnt 8.518240 hw_loss 0.256345 lr 0.00028712 rank 1
2023-03-01 12:00:14,215 DEBUG TRAIN Batch 55/3300 loss 3.554615 loss_att 7.332568 loss_ctc 7.359886 loss_rnnt 2.202973 hw_loss 0.166277 lr 0.00028712 rank 5
2023-03-01 12:00:14,216 DEBUG TRAIN Batch 55/3300 loss 2.518414 loss_att 5.311399 loss_ctc 4.084494 loss_rnnt 1.711125 hw_loss 0.074776 lr 0.00028712 rank 2
2023-03-01 12:00:14,216 DEBUG TRAIN Batch 55/3300 loss 2.013702 loss_att 4.403183 loss_ctc 1.464192 loss_rnnt 1.529776 hw_loss 0.148684 lr 0.00028711 rank 7
2023-03-01 12:00:14,218 DEBUG TRAIN Batch 55/3300 loss 3.617164 loss_att 5.154041 loss_ctc 4.400404 loss_rnnt 3.120584 hw_loss 0.158950 lr 0.00028713 rank 0
2023-03-01 12:00:14,218 DEBUG TRAIN Batch 55/3300 loss 2.405583 loss_att 5.432578 loss_ctc 3.319411 loss_rnnt 1.576275 hw_loss 0.191372 lr 0.00028711 rank 3
2023-03-01 12:00:14,264 DEBUG TRAIN Batch 55/3300 loss 1.763999 loss_att 4.388934 loss_ctc 2.414729 loss_rnnt 0.994052 hw_loss 0.296616 lr 0.00028712 rank 6
2023-03-01 12:00:53,118 DEBUG TRAIN Batch 55/3400 loss 3.049953 loss_att 4.373946 loss_ctc 6.846466 loss_rnnt 2.125135 hw_loss 0.288409 lr 0.00028710 rank 1
2023-03-01 12:00:53,131 DEBUG TRAIN Batch 55/3400 loss 1.979855 loss_att 3.799089 loss_ctc 6.777970 loss_rnnt 0.881949 hw_loss 0.176832 lr 0.00028711 rank 0
2023-03-01 12:00:53,133 DEBUG TRAIN Batch 55/3400 loss 6.033494 loss_att 7.651561 loss_ctc 7.753378 loss_rnnt 5.425308 hw_loss 0.103603 lr 0.00028710 rank 7
2023-03-01 12:00:53,134 DEBUG TRAIN Batch 55/3400 loss 4.918529 loss_att 7.498729 loss_ctc 8.518830 loss_rnnt 3.729093 hw_loss 0.362543 lr 0.00028711 rank 6
2023-03-01 12:00:53,134 DEBUG TRAIN Batch 55/3400 loss 3.182961 loss_att 4.488091 loss_ctc 4.576977 loss_rnnt 2.591544 hw_loss 0.270978 lr 0.00028711 rank 2
2023-03-01 12:00:53,137 DEBUG TRAIN Batch 55/3400 loss 4.343691 loss_att 8.079376 loss_ctc 13.496173 loss_rnnt 2.222888 hw_loss 0.287505 lr 0.00028710 rank 3
2023-03-01 12:00:53,137 DEBUG TRAIN Batch 55/3400 loss 1.879218 loss_att 4.910429 loss_ctc 4.176891 loss_rnnt 0.843310 hw_loss 0.231204 lr 0.00028710 rank 4
2023-03-01 12:00:53,181 DEBUG TRAIN Batch 55/3400 loss 8.120073 loss_att 11.042424 loss_ctc 12.686072 loss_rnnt 6.872759 hw_loss 0.101332 lr 0.00028710 rank 5
2023-03-01 12:01:33,089 DEBUG TRAIN Batch 55/3500 loss 5.423373 loss_att 8.475600 loss_ctc 7.025542 loss_rnnt 4.491656 hw_loss 0.201842 lr 0.00028710 rank 6
2023-03-01 12:01:33,091 DEBUG TRAIN Batch 55/3500 loss 9.567503 loss_att 13.348991 loss_ctc 19.369688 loss_rnnt 7.414969 hw_loss 0.167397 lr 0.00028709 rank 1
2023-03-01 12:01:33,091 DEBUG TRAIN Batch 55/3500 loss 4.736677 loss_att 6.692409 loss_ctc 8.375278 loss_rnnt 3.785965 hw_loss 0.139535 lr 0.00028710 rank 2
2023-03-01 12:01:33,093 DEBUG TRAIN Batch 55/3500 loss 4.389452 loss_att 6.641504 loss_ctc 7.231426 loss_rnnt 3.482094 hw_loss 0.146283 lr 0.00028710 rank 0
2023-03-01 12:01:33,093 DEBUG TRAIN Batch 55/3500 loss 7.552987 loss_att 10.108687 loss_ctc 10.978844 loss_rnnt 6.439477 hw_loss 0.272980 lr 0.00028709 rank 5
2023-03-01 12:01:33,094 DEBUG TRAIN Batch 55/3500 loss 7.430153 loss_att 10.520729 loss_ctc 13.557833 loss_rnnt 5.903497 hw_loss 0.171595 lr 0.00028709 rank 3
2023-03-01 12:01:33,094 DEBUG TRAIN Batch 55/3500 loss 4.239621 loss_att 9.032001 loss_ctc 10.595383 loss_rnnt 2.314831 hw_loss 0.222898 lr 0.00028709 rank 7
2023-03-01 12:01:33,127 DEBUG TRAIN Batch 55/3500 loss 10.662939 loss_att 11.235867 loss_ctc 14.407068 loss_rnnt 9.921436 hw_loss 0.239436 lr 0.00028709 rank 4
2023-03-01 12:02:36,689 DEBUG TRAIN Batch 55/3600 loss 3.904556 loss_att 6.230969 loss_ctc 8.352514 loss_rnnt 2.758678 hw_loss 0.164128 lr 0.00028708 rank 7
2023-03-01 12:02:36,689 DEBUG TRAIN Batch 55/3600 loss 5.591712 loss_att 9.216473 loss_ctc 8.243305 loss_rnnt 4.321689 hw_loss 0.359111 lr 0.00028709 rank 0
2023-03-01 12:02:36,689 DEBUG TRAIN Batch 55/3600 loss 5.117608 loss_att 8.088465 loss_ctc 10.402669 loss_rnnt 3.710453 hw_loss 0.203079 lr 0.00028709 rank 2
2023-03-01 12:02:36,693 DEBUG TRAIN Batch 55/3600 loss 11.562678 loss_att 15.110750 loss_ctc 20.852509 loss_rnnt 9.477242 hw_loss 0.257207 lr 0.00028708 rank 6
2023-03-01 12:02:36,695 DEBUG TRAIN Batch 55/3600 loss 9.231522 loss_att 13.265551 loss_ctc 15.675138 loss_rnnt 7.489085 hw_loss 0.143404 lr 0.00028708 rank 3
2023-03-01 12:02:36,696 DEBUG TRAIN Batch 55/3600 loss 4.204969 loss_att 7.414921 loss_ctc 7.578012 loss_rnnt 3.011265 hw_loss 0.191202 lr 0.00028708 rank 1
2023-03-01 12:02:36,701 DEBUG TRAIN Batch 55/3600 loss 2.810467 loss_att 5.588384 loss_ctc 5.792848 loss_rnnt 1.738649 hw_loss 0.222344 lr 0.00028708 rank 5
2023-03-01 12:02:36,744 DEBUG TRAIN Batch 55/3600 loss 6.126601 loss_att 8.315155 loss_ctc 9.504595 loss_rnnt 5.073771 hw_loss 0.308849 lr 0.00028708 rank 4
2023-03-01 12:03:15,925 DEBUG TRAIN Batch 55/3700 loss 10.497772 loss_att 12.701214 loss_ctc 12.522409 loss_rnnt 9.743261 hw_loss 0.082258 lr 0.00028708 rank 0
2023-03-01 12:03:15,940 DEBUG TRAIN Batch 55/3700 loss 5.434776 loss_att 9.154871 loss_ctc 8.693979 loss_rnnt 4.149546 hw_loss 0.199970 lr 0.00028707 rank 6
2023-03-01 12:03:15,941 DEBUG TRAIN Batch 55/3700 loss 2.164017 loss_att 3.807007 loss_ctc 3.739730 loss_rnnt 1.483548 hw_loss 0.265831 lr 0.00028707 rank 7
2023-03-01 12:03:15,941 DEBUG TRAIN Batch 55/3700 loss 2.328650 loss_att 4.745133 loss_ctc 2.967074 loss_rnnt 1.647860 hw_loss 0.210695 lr 0.00028707 rank 1
2023-03-01 12:03:15,943 DEBUG TRAIN Batch 55/3700 loss 4.201177 loss_att 6.790155 loss_ctc 9.950880 loss_rnnt 2.773415 hw_loss 0.268762 lr 0.00028707 rank 4
2023-03-01 12:03:15,944 DEBUG TRAIN Batch 55/3700 loss 5.334275 loss_att 8.658898 loss_ctc 11.064276 loss_rnnt 3.763916 hw_loss 0.265189 lr 0.00028707 rank 2
2023-03-01 12:03:15,948 DEBUG TRAIN Batch 55/3700 loss 3.848514 loss_att 7.604182 loss_ctc 9.176946 loss_rnnt 2.258765 hw_loss 0.240296 lr 0.00028706 rank 3
2023-03-01 12:03:15,991 DEBUG TRAIN Batch 55/3700 loss 5.679208 loss_att 9.328615 loss_ctc 12.127089 loss_rnnt 3.938784 hw_loss 0.282798 lr 0.00028707 rank 5
2023-03-01 12:03:55,387 DEBUG TRAIN Batch 55/3800 loss 5.244286 loss_att 7.974872 loss_ctc 12.203817 loss_rnnt 3.635691 hw_loss 0.252263 lr 0.00028706 rank 4
2023-03-01 12:03:55,402 DEBUG TRAIN Batch 55/3800 loss 7.890426 loss_att 9.472166 loss_ctc 12.361053 loss_rnnt 6.880766 hw_loss 0.182303 lr 0.00028706 rank 6
2023-03-01 12:03:55,403 DEBUG TRAIN Batch 55/3800 loss 6.402334 loss_att 9.039211 loss_ctc 8.831389 loss_rnnt 5.505842 hw_loss 0.084830 lr 0.00028705 rank 7
2023-03-01 12:03:55,405 DEBUG TRAIN Batch 55/3800 loss 7.353821 loss_att 8.568084 loss_ctc 12.479167 loss_rnnt 6.350890 hw_loss 0.143811 lr 0.00028707 rank 0
2023-03-01 12:03:55,406 DEBUG TRAIN Batch 55/3800 loss 7.365652 loss_att 13.011984 loss_ctc 16.963892 loss_rnnt 4.802118 hw_loss 0.289691 lr 0.00028706 rank 5
2023-03-01 12:03:55,412 DEBUG TRAIN Batch 55/3800 loss 4.818523 loss_att 6.686604 loss_ctc 8.447636 loss_rnnt 3.851891 hw_loss 0.204627 lr 0.00028705 rank 3
2023-03-01 12:03:55,412 DEBUG TRAIN Batch 55/3800 loss 4.946341 loss_att 6.916288 loss_ctc 7.423772 loss_rnnt 4.033602 hw_loss 0.353298 lr 0.00028706 rank 1
2023-03-01 12:03:55,420 DEBUG TRAIN Batch 55/3800 loss 4.984744 loss_att 8.379848 loss_ctc 5.410816 loss_rnnt 4.212802 hw_loss 0.067708 lr 0.00028706 rank 2
2023-03-01 12:05:00,478 DEBUG TRAIN Batch 55/3900 loss 1.167550 loss_att 3.863584 loss_ctc 2.051911 loss_rnnt 0.458985 hw_loss 0.096458 lr 0.00028704 rank 7
2023-03-01 12:05:00,483 DEBUG TRAIN Batch 55/3900 loss 3.299305 loss_att 7.218965 loss_ctc 8.984777 loss_rnnt 1.668744 hw_loss 0.166063 lr 0.00028705 rank 4
2023-03-01 12:05:00,486 DEBUG TRAIN Batch 55/3900 loss 3.387486 loss_att 4.113225 loss_ctc 6.222516 loss_rnnt 2.742706 hw_loss 0.228055 lr 0.00028705 rank 0
2023-03-01 12:05:00,489 DEBUG TRAIN Batch 55/3900 loss 2.244051 loss_att 5.125145 loss_ctc 3.491421 loss_rnnt 1.375037 hw_loss 0.237149 lr 0.00028704 rank 3
2023-03-01 12:05:00,489 DEBUG TRAIN Batch 55/3900 loss 3.203001 loss_att 5.403244 loss_ctc 4.549026 loss_rnnt 2.412671 hw_loss 0.320271 lr 0.00028704 rank 1
2023-03-01 12:05:00,491 DEBUG TRAIN Batch 55/3900 loss 7.715550 loss_att 9.936234 loss_ctc 12.393635 loss_rnnt 6.423120 hw_loss 0.421027 lr 0.00028705 rank 2
2023-03-01 12:05:00,537 DEBUG TRAIN Batch 55/3900 loss 6.191529 loss_att 9.910193 loss_ctc 12.558323 loss_rnnt 4.476151 hw_loss 0.230139 lr 0.00028705 rank 6
2023-03-01 12:05:00,539 DEBUG TRAIN Batch 55/3900 loss 6.525356 loss_att 7.765351 loss_ctc 10.543743 loss_rnnt 5.618488 hw_loss 0.230781 lr 0.00028705 rank 5
2023-03-01 12:05:39,894 DEBUG TRAIN Batch 55/4000 loss 2.702201 loss_att 5.471928 loss_ctc 6.440096 loss_rnnt 1.539497 hw_loss 0.206949 lr 0.00028703 rank 3
2023-03-01 12:05:39,896 DEBUG TRAIN Batch 55/4000 loss 6.368332 loss_att 8.697279 loss_ctc 8.495174 loss_rnnt 5.489242 hw_loss 0.243228 lr 0.00028704 rank 2
2023-03-01 12:05:39,896 DEBUG TRAIN Batch 55/4000 loss 2.754131 loss_att 5.649180 loss_ctc 7.924632 loss_rnnt 1.425219 hw_loss 0.113441 lr 0.00028703 rank 5
2023-03-01 12:05:39,902 DEBUG TRAIN Batch 55/4000 loss 7.945056 loss_att 13.288280 loss_ctc 13.767772 loss_rnnt 6.069453 hw_loss 0.057367 lr 0.00028704 rank 6
2023-03-01 12:05:39,914 DEBUG TRAIN Batch 55/4000 loss 4.437676 loss_att 8.725700 loss_ctc 6.479587 loss_rnnt 3.248775 hw_loss 0.110704 lr 0.00028703 rank 4
2023-03-01 12:05:39,914 DEBUG TRAIN Batch 55/4000 loss 4.523718 loss_att 8.315264 loss_ctc 8.317142 loss_rnnt 3.138086 hw_loss 0.227873 lr 0.00028704 rank 0
2023-03-01 12:05:39,916 DEBUG TRAIN Batch 55/4000 loss 3.910118 loss_att 7.316258 loss_ctc 6.267873 loss_rnnt 2.831418 hw_loss 0.155822 lr 0.00028703 rank 7
2023-03-01 12:05:39,969 DEBUG TRAIN Batch 55/4000 loss 12.725411 loss_att 18.504070 loss_ctc 27.159718 loss_rnnt 9.451137 hw_loss 0.363691 lr 0.00028703 rank 1
2023-03-01 12:06:19,024 DEBUG TRAIN Batch 55/4100 loss 7.055437 loss_att 10.133127 loss_ctc 10.653893 loss_rnnt 5.903666 hw_loss 0.105823 lr 0.00028702 rank 1
2023-03-01 12:06:19,031 DEBUG TRAIN Batch 55/4100 loss 3.815594 loss_att 8.239578 loss_ctc 8.252031 loss_rnnt 2.264375 hw_loss 0.140431 lr 0.00028702 rank 6
2023-03-01 12:06:19,035 DEBUG TRAIN Batch 55/4100 loss 1.321055 loss_att 4.286771 loss_ctc 0.966359 loss_rnnt 0.667501 hw_loss 0.201944 lr 0.00028702 rank 5
2023-03-01 12:06:19,044 DEBUG TRAIN Batch 55/4100 loss 5.495658 loss_att 7.931436 loss_ctc 9.794884 loss_rnnt 4.319025 hw_loss 0.217966 lr 0.00028703 rank 0
2023-03-01 12:06:19,047 DEBUG TRAIN Batch 55/4100 loss 5.750996 loss_att 8.934534 loss_ctc 13.036938 loss_rnnt 4.022786 hw_loss 0.225079 lr 0.00028703 rank 2
2023-03-01 12:06:19,051 DEBUG TRAIN Batch 55/4100 loss 2.294659 loss_att 4.985000 loss_ctc 3.120270 loss_rnnt 1.508868 hw_loss 0.258079 lr 0.00028702 rank 7
2023-03-01 12:06:19,053 DEBUG TRAIN Batch 55/4100 loss 9.241020 loss_att 14.946421 loss_ctc 12.528303 loss_rnnt 7.564972 hw_loss 0.181244 lr 0.00028702 rank 3
2023-03-01 12:06:19,056 DEBUG TRAIN Batch 55/4100 loss 1.536520 loss_att 3.443317 loss_ctc 1.939424 loss_rnnt 1.016773 hw_loss 0.158751 lr 0.00028702 rank 4
2023-03-01 12:06:58,083 DEBUG TRAIN Batch 55/4200 loss 5.261073 loss_att 9.094211 loss_ctc 12.350291 loss_rnnt 3.469363 hw_loss 0.149725 lr 0.00028701 rank 6
2023-03-01 12:06:58,086 DEBUG TRAIN Batch 55/4200 loss 7.786217 loss_att 11.284838 loss_ctc 18.610172 loss_rnnt 5.511780 hw_loss 0.246599 lr 0.00028701 rank 1
2023-03-01 12:06:58,088 DEBUG TRAIN Batch 55/4200 loss 4.580765 loss_att 7.791695 loss_ctc 9.685036 loss_rnnt 3.144487 hw_loss 0.212856 lr 0.00028701 rank 2
2023-03-01 12:06:58,092 DEBUG TRAIN Batch 55/4200 loss 9.546728 loss_att 10.414039 loss_ctc 11.277214 loss_rnnt 8.932087 hw_loss 0.394589 lr 0.00028701 rank 7
2023-03-01 12:06:58,095 DEBUG TRAIN Batch 55/4200 loss 3.754510 loss_att 5.686020 loss_ctc 6.976697 loss_rnnt 2.881612 hw_loss 0.106821 lr 0.00028702 rank 0
2023-03-01 12:06:58,103 DEBUG TRAIN Batch 55/4200 loss 10.258470 loss_att 14.495118 loss_ctc 16.850010 loss_rnnt 8.437799 hw_loss 0.177128 lr 0.00028700 rank 3
2023-03-01 12:06:58,111 DEBUG TRAIN Batch 55/4200 loss 7.628011 loss_att 10.282988 loss_ctc 14.783856 loss_rnnt 6.067511 hw_loss 0.141358 lr 0.00028701 rank 4
2023-03-01 12:06:58,115 DEBUG TRAIN Batch 55/4200 loss 5.874162 loss_att 9.880180 loss_ctc 12.258413 loss_rnnt 4.129847 hw_loss 0.172271 lr 0.00028701 rank 5
2023-03-01 12:08:03,385 DEBUG TRAIN Batch 55/4300 loss 9.238746 loss_att 11.563635 loss_ctc 15.514665 loss_rnnt 7.879160 hw_loss 0.108408 lr 0.00028701 rank 0
2023-03-01 12:08:03,385 DEBUG TRAIN Batch 55/4300 loss 2.996320 loss_att 4.644006 loss_ctc 5.702568 loss_rnnt 2.231483 hw_loss 0.139626 lr 0.00028700 rank 2
2023-03-01 12:08:03,387 DEBUG TRAIN Batch 55/4300 loss 8.198958 loss_att 12.307472 loss_ctc 15.631813 loss_rnnt 6.275215 hw_loss 0.208111 lr 0.00028700 rank 6
2023-03-01 12:08:03,387 DEBUG TRAIN Batch 55/4300 loss 7.573623 loss_att 9.608895 loss_ctc 13.872102 loss_rnnt 6.178927 hw_loss 0.277208 lr 0.00028699 rank 7
2023-03-01 12:08:03,388 DEBUG TRAIN Batch 55/4300 loss 11.184263 loss_att 14.800110 loss_ctc 16.704901 loss_rnnt 9.651447 hw_loss 0.137926 lr 0.00028699 rank 3
2023-03-01 12:08:03,403 DEBUG TRAIN Batch 55/4300 loss 5.902897 loss_att 8.400122 loss_ctc 10.293729 loss_rnnt 4.668871 hw_loss 0.279629 lr 0.00028700 rank 5
2023-03-01 12:08:03,412 DEBUG TRAIN Batch 55/4300 loss 7.467364 loss_att 8.934109 loss_ctc 9.725823 loss_rnnt 6.715375 hw_loss 0.295334 lr 0.00028700 rank 1
2023-03-01 12:08:03,426 DEBUG TRAIN Batch 55/4300 loss 4.669449 loss_att 7.146224 loss_ctc 12.260170 loss_rnnt 3.028006 hw_loss 0.251237 lr 0.00028700 rank 4
2023-03-01 12:08:42,771 DEBUG TRAIN Batch 55/4400 loss 4.960534 loss_att 6.437037 loss_ctc 5.494189 loss_rnnt 4.429111 hw_loss 0.309315 lr 0.00028699 rank 1
2023-03-01 12:08:42,783 DEBUG TRAIN Batch 55/4400 loss 3.854671 loss_att 7.109169 loss_ctc 8.008871 loss_rnnt 2.477376 hw_loss 0.323443 lr 0.00028698 rank 7
2023-03-01 12:08:42,785 DEBUG TRAIN Batch 55/4400 loss 4.869966 loss_att 6.715027 loss_ctc 7.967088 loss_rnnt 4.043733 hw_loss 0.083009 lr 0.00028700 rank 0
2023-03-01 12:08:42,788 DEBUG TRAIN Batch 55/4400 loss 4.717120 loss_att 7.972230 loss_ctc 9.560809 loss_rnnt 3.261767 hw_loss 0.297200 lr 0.00028699 rank 6
2023-03-01 12:08:42,788 DEBUG TRAIN Batch 55/4400 loss 5.882806 loss_att 7.376855 loss_ctc 11.477648 loss_rnnt 4.729393 hw_loss 0.203670 lr 0.00028699 rank 2
2023-03-01 12:08:42,791 DEBUG TRAIN Batch 55/4400 loss 3.303019 loss_att 5.962120 loss_ctc 4.344199 loss_rnnt 2.538624 hw_loss 0.175784 lr 0.00028699 rank 5
2023-03-01 12:08:42,819 DEBUG TRAIN Batch 55/4400 loss 9.618166 loss_att 12.422918 loss_ctc 13.596515 loss_rnnt 8.420535 hw_loss 0.199190 lr 0.00028698 rank 3
2023-03-01 12:08:42,824 DEBUG TRAIN Batch 55/4400 loss 12.098001 loss_att 10.953697 loss_ctc 17.817415 loss_rnnt 11.422124 hw_loss 0.266531 lr 0.00028699 rank 4
2023-03-01 12:09:22,033 DEBUG TRAIN Batch 55/4500 loss 2.979634 loss_att 5.826146 loss_ctc 3.118840 loss_rnnt 2.249230 hw_loss 0.267263 lr 0.00028697 rank 4
2023-03-01 12:09:22,047 DEBUG TRAIN Batch 55/4500 loss 1.048006 loss_att 2.253151 loss_ctc 1.602376 loss_rnnt 0.661351 hw_loss 0.134456 lr 0.00028697 rank 5
2023-03-01 12:09:22,048 DEBUG TRAIN Batch 55/4500 loss 4.384418 loss_att 6.498128 loss_ctc 6.551665 loss_rnnt 3.584530 hw_loss 0.165339 lr 0.00028698 rank 0
2023-03-01 12:09:22,049 DEBUG TRAIN Batch 55/4500 loss 8.465072 loss_att 10.670176 loss_ctc 11.323206 loss_rnnt 7.568538 hw_loss 0.139551 lr 0.00028697 rank 3
2023-03-01 12:09:22,051 DEBUG TRAIN Batch 55/4500 loss 1.614260 loss_att 3.459045 loss_ctc 2.503433 loss_rnnt 1.010134 hw_loss 0.218647 lr 0.00028697 rank 1
2023-03-01 12:09:22,052 DEBUG TRAIN Batch 55/4500 loss 8.024811 loss_att 14.101288 loss_ctc 13.441694 loss_rnnt 5.976926 hw_loss 0.206882 lr 0.00028697 rank 7
2023-03-01 12:09:22,055 DEBUG TRAIN Batch 55/4500 loss 6.084891 loss_att 8.544958 loss_ctc 9.897066 loss_rnnt 4.960864 hw_loss 0.231984 lr 0.00028698 rank 6
2023-03-01 12:09:22,056 DEBUG TRAIN Batch 55/4500 loss 13.567609 loss_att 20.105198 loss_ctc 27.036993 loss_rnnt 10.404057 hw_loss 0.112719 lr 0.00028698 rank 2
2023-03-01 12:10:02,518 DEBUG TRAIN Batch 55/4600 loss 7.095156 loss_att 8.934626 loss_ctc 12.543579 loss_rnnt 5.896242 hw_loss 0.196057 lr 0.00028697 rank 2
2023-03-01 12:10:02,520 DEBUG TRAIN Batch 55/4600 loss 12.578251 loss_att 15.806904 loss_ctc 27.322811 loss_rnnt 9.834085 hw_loss 0.248425 lr 0.00028696 rank 1
2023-03-01 12:10:02,531 DEBUG TRAIN Batch 55/4600 loss 4.631933 loss_att 9.926927 loss_ctc 9.618402 loss_rnnt 2.771133 hw_loss 0.256760 lr 0.00028696 rank 5
2023-03-01 12:10:02,534 DEBUG TRAIN Batch 55/4600 loss 2.962872 loss_att 6.040356 loss_ctc 9.198994 loss_rnnt 1.435318 hw_loss 0.151077 lr 0.00028697 rank 0
2023-03-01 12:10:02,537 DEBUG TRAIN Batch 55/4600 loss 9.179658 loss_att 10.384415 loss_ctc 10.706728 loss_rnnt 8.599401 hw_loss 0.254428 lr 0.00028696 rank 7
2023-03-01 12:10:02,539 DEBUG TRAIN Batch 55/4600 loss 10.722705 loss_att 12.978664 loss_ctc 11.806307 loss_rnnt 10.024239 hw_loss 0.192741 lr 0.00028696 rank 3
2023-03-01 12:10:02,546 DEBUG TRAIN Batch 55/4600 loss 5.842408 loss_att 8.398375 loss_ctc 8.500301 loss_rnnt 4.842098 hw_loss 0.252622 lr 0.00028696 rank 4
2023-03-01 12:10:02,583 DEBUG TRAIN Batch 55/4600 loss 2.595372 loss_att 4.815951 loss_ctc 3.888430 loss_rnnt 1.866536 hw_loss 0.210587 lr 0.00028697 rank 6
2023-03-01 12:11:06,042 DEBUG TRAIN Batch 55/4700 loss 2.081410 loss_att 4.703501 loss_ctc 3.887869 loss_rnnt 1.253929 hw_loss 0.116626 lr 0.00028695 rank 4
2023-03-01 12:11:06,044 DEBUG TRAIN Batch 55/4700 loss 5.085649 loss_att 9.037269 loss_ctc 8.842934 loss_rnnt 3.660379 hw_loss 0.251204 lr 0.00028695 rank 7
2023-03-01 12:11:06,044 DEBUG TRAIN Batch 55/4700 loss 15.269383 loss_att 18.839319 loss_ctc 27.754192 loss_rnnt 12.799963 hw_loss 0.170235 lr 0.00028695 rank 5
2023-03-01 12:11:06,045 DEBUG TRAIN Batch 55/4700 loss 6.386611 loss_att 8.585002 loss_ctc 8.421491 loss_rnnt 5.549501 hw_loss 0.236465 lr 0.00028695 rank 6
2023-03-01 12:11:06,047 DEBUG TRAIN Batch 55/4700 loss 2.734194 loss_att 5.167867 loss_ctc 5.765393 loss_rnnt 1.764371 hw_loss 0.147990 lr 0.00028696 rank 0
2023-03-01 12:11:06,047 DEBUG TRAIN Batch 55/4700 loss 3.195541 loss_att 6.015514 loss_ctc 7.593625 loss_rnnt 2.019454 hw_loss 0.048153 lr 0.00028695 rank 1
2023-03-01 12:11:06,053 DEBUG TRAIN Batch 55/4700 loss 9.496012 loss_att 12.183670 loss_ctc 17.280466 loss_rnnt 7.789012 hw_loss 0.246638 lr 0.00028696 rank 2
2023-03-01 12:11:06,102 DEBUG TRAIN Batch 55/4700 loss 8.106555 loss_att 10.901329 loss_ctc 11.354242 loss_rnnt 7.057916 hw_loss 0.106237 lr 0.00028695 rank 3
2023-03-01 12:11:44,964 DEBUG TRAIN Batch 55/4800 loss 5.914482 loss_att 7.739720 loss_ctc 7.959044 loss_rnnt 5.132886 hw_loss 0.269886 lr 0.00028694 rank 4
2023-03-01 12:11:44,969 DEBUG TRAIN Batch 55/4800 loss 3.108281 loss_att 6.930173 loss_ctc 4.870157 loss_rnnt 1.986829 hw_loss 0.229043 lr 0.00028694 rank 5
2023-03-01 12:11:44,983 DEBUG TRAIN Batch 55/4800 loss 8.648195 loss_att 10.292456 loss_ctc 16.280891 loss_rnnt 7.208336 hw_loss 0.174962 lr 0.00028693 rank 3
2023-03-01 12:11:44,985 DEBUG TRAIN Batch 55/4800 loss 5.169252 loss_att 9.197088 loss_ctc 10.440858 loss_rnnt 3.447301 hw_loss 0.400319 lr 0.00028695 rank 0
2023-03-01 12:11:44,986 DEBUG TRAIN Batch 55/4800 loss 6.766765 loss_att 10.295341 loss_ctc 13.630116 loss_rnnt 5.037217 hw_loss 0.203847 lr 0.00028694 rank 7
2023-03-01 12:11:44,986 DEBUG TRAIN Batch 55/4800 loss 7.514008 loss_att 10.452907 loss_ctc 15.067379 loss_rnnt 5.800351 hw_loss 0.222675 lr 0.00028694 rank 2
2023-03-01 12:11:44,989 DEBUG TRAIN Batch 55/4800 loss 6.986884 loss_att 10.830336 loss_ctc 13.729826 loss_rnnt 5.257119 hw_loss 0.116279 lr 0.00028694 rank 1
2023-03-01 12:11:44,991 DEBUG TRAIN Batch 55/4800 loss 9.387402 loss_att 12.375889 loss_ctc 13.043300 loss_rnnt 8.230026 hw_loss 0.135422 lr 0.00028694 rank 6
2023-03-01 12:12:24,553 DEBUG TRAIN Batch 55/4900 loss 5.800676 loss_att 8.889299 loss_ctc 7.765753 loss_rnnt 4.810628 hw_loss 0.206836 lr 0.00028693 rank 5
2023-03-01 12:12:24,562 DEBUG TRAIN Batch 55/4900 loss 4.546252 loss_att 6.605249 loss_ctc 7.344551 loss_rnnt 3.719792 hw_loss 0.077914 lr 0.00028693 rank 6
2023-03-01 12:12:24,564 DEBUG TRAIN Batch 55/4900 loss 2.365716 loss_att 4.029909 loss_ctc 5.056453 loss_rnnt 1.561591 hw_loss 0.210977 lr 0.00028694 rank 0
2023-03-01 12:12:24,564 DEBUG TRAIN Batch 55/4900 loss 6.770581 loss_att 9.621279 loss_ctc 12.477273 loss_rnnt 5.322444 hw_loss 0.219573 lr 0.00028693 rank 1
2023-03-01 12:12:24,574 DEBUG TRAIN Batch 55/4900 loss 4.595142 loss_att 6.258234 loss_ctc 7.386909 loss_rnnt 3.810074 hw_loss 0.150403 lr 0.00028692 rank 3
2023-03-01 12:12:24,575 DEBUG TRAIN Batch 55/4900 loss 4.930377 loss_att 8.781496 loss_ctc 10.259785 loss_rnnt 3.347208 hw_loss 0.191921 lr 0.00028693 rank 2
2023-03-01 12:12:24,590 DEBUG TRAIN Batch 55/4900 loss 3.164887 loss_att 4.738481 loss_ctc 3.300332 loss_rnnt 2.690541 hw_loss 0.265441 lr 0.00028692 rank 7
2023-03-01 12:12:24,592 DEBUG TRAIN Batch 55/4900 loss 7.689208 loss_att 10.299326 loss_ctc 12.728920 loss_rnnt 6.389307 hw_loss 0.198593 lr 0.00028693 rank 4
2023-03-01 12:13:30,157 DEBUG TRAIN Batch 55/5000 loss 5.639303 loss_att 7.975816 loss_ctc 11.454853 loss_rnnt 4.293954 hw_loss 0.192449 lr 0.00028692 rank 4
2023-03-01 12:13:30,158 DEBUG TRAIN Batch 55/5000 loss 2.108583 loss_att 5.489810 loss_ctc 5.348371 loss_rnnt 0.916737 hw_loss 0.156804 lr 0.00028691 rank 7
2023-03-01 12:13:30,158 DEBUG TRAIN Batch 55/5000 loss 9.935665 loss_att 12.382133 loss_ctc 19.870893 loss_rnnt 8.005157 hw_loss 0.218471 lr 0.00028692 rank 0
2023-03-01 12:13:30,160 DEBUG TRAIN Batch 55/5000 loss 4.007932 loss_att 8.831978 loss_ctc 7.940626 loss_rnnt 2.402612 hw_loss 0.217783 lr 0.00028692 rank 5
2023-03-01 12:13:30,160 DEBUG TRAIN Batch 55/5000 loss 3.099315 loss_att 7.289500 loss_ctc 7.174675 loss_rnnt 1.581211 hw_loss 0.256285 lr 0.00028691 rank 1
2023-03-01 12:13:30,164 DEBUG TRAIN Batch 55/5000 loss 8.213404 loss_att 9.256155 loss_ctc 16.913397 loss_rnnt 6.715860 hw_loss 0.241867 lr 0.00028692 rank 2
2023-03-01 12:13:30,165 DEBUG TRAIN Batch 55/5000 loss 5.404043 loss_att 9.782076 loss_ctc 12.874599 loss_rnnt 3.412659 hw_loss 0.224442 lr 0.00028691 rank 3
2023-03-01 12:13:30,170 DEBUG TRAIN Batch 55/5000 loss 10.177243 loss_att 13.073508 loss_ctc 18.602951 loss_rnnt 8.328636 hw_loss 0.273612 lr 0.00028692 rank 6
2023-03-01 12:14:09,492 DEBUG TRAIN Batch 55/5100 loss 15.285147 loss_att 19.001503 loss_ctc 24.691620 loss_rnnt 13.149798 hw_loss 0.258526 lr 0.00028690 rank 4
2023-03-01 12:14:09,509 DEBUG TRAIN Batch 55/5100 loss 6.835863 loss_att 9.657337 loss_ctc 11.844666 loss_rnnt 5.461201 hw_loss 0.267238 lr 0.00028690 rank 7
2023-03-01 12:14:09,512 DEBUG TRAIN Batch 55/5100 loss 2.798950 loss_att 5.923806 loss_ctc 8.634693 loss_rnnt 1.326455 hw_loss 0.130171 lr 0.00028691 rank 2
2023-03-01 12:14:09,513 DEBUG TRAIN Batch 55/5100 loss 11.118847 loss_att 12.026715 loss_ctc 18.260077 loss_rnnt 9.833334 hw_loss 0.284578 lr 0.00028690 rank 5
2023-03-01 12:14:09,517 DEBUG TRAIN Batch 55/5100 loss 3.446656 loss_att 6.092701 loss_ctc 4.328641 loss_rnnt 2.637148 hw_loss 0.305065 lr 0.00028691 rank 0
2023-03-01 12:14:09,529 DEBUG TRAIN Batch 55/5100 loss 3.711669 loss_att 6.373628 loss_ctc 5.055215 loss_rnnt 2.877165 hw_loss 0.230575 lr 0.00028690 rank 1
2023-03-01 12:14:09,534 DEBUG TRAIN Batch 55/5100 loss 8.555106 loss_att 10.355155 loss_ctc 12.727450 loss_rnnt 7.506673 hw_loss 0.247707 lr 0.00028690 rank 3
2023-03-01 12:14:09,546 DEBUG TRAIN Batch 55/5100 loss 2.425322 loss_att 6.386985 loss_ctc 6.865970 loss_rnnt 0.933596 hw_loss 0.201199 lr 0.00028691 rank 6
2023-03-01 12:14:48,315 DEBUG TRAIN Batch 55/5200 loss 5.723277 loss_att 7.498963 loss_ctc 9.835138 loss_rnnt 4.730939 hw_loss 0.166785 lr 0.00028690 rank 0
2023-03-01 12:14:48,316 DEBUG TRAIN Batch 55/5200 loss 4.853809 loss_att 7.490898 loss_ctc 7.500808 loss_rnnt 3.797404 hw_loss 0.330102 lr 0.00028689 rank 7
2023-03-01 12:14:48,318 DEBUG TRAIN Batch 55/5200 loss 8.033756 loss_att 8.196263 loss_ctc 12.899510 loss_rnnt 7.199715 hw_loss 0.286447 lr 0.00028689 rank 6
2023-03-01 12:14:48,318 DEBUG TRAIN Batch 55/5200 loss 7.555719 loss_att 10.892329 loss_ctc 12.013671 loss_rnnt 6.244728 hw_loss 0.092389 lr 0.00028689 rank 5
2023-03-01 12:14:48,321 DEBUG TRAIN Batch 55/5200 loss 11.172237 loss_att 10.870814 loss_ctc 14.927725 loss_rnnt 10.575837 hw_loss 0.292414 lr 0.00028689 rank 1
2023-03-01 12:14:48,323 DEBUG TRAIN Batch 55/5200 loss 5.616555 loss_att 7.507308 loss_ctc 8.094341 loss_rnnt 4.768617 hw_loss 0.261405 lr 0.00028689 rank 3
2023-03-01 12:14:48,340 DEBUG TRAIN Batch 55/5200 loss 9.985442 loss_att 10.705948 loss_ctc 13.961020 loss_rnnt 9.194962 hw_loss 0.218068 lr 0.00028689 rank 4
2023-03-01 12:14:48,373 DEBUG TRAIN Batch 55/5200 loss 6.028290 loss_att 9.548564 loss_ctc 8.160509 loss_rnnt 4.909090 hw_loss 0.245344 lr 0.00028690 rank 2
2023-03-01 12:15:28,572 DEBUG TRAIN Batch 55/5300 loss 8.754040 loss_att 9.451944 loss_ctc 13.334025 loss_rnnt 7.840781 hw_loss 0.305651 lr 0.00028687 rank 3
2023-03-01 12:15:28,572 DEBUG TRAIN Batch 55/5300 loss 6.366806 loss_att 10.270681 loss_ctc 9.196175 loss_rnnt 5.111985 hw_loss 0.181493 lr 0.00028688 rank 2
2023-03-01 12:15:28,574 DEBUG TRAIN Batch 55/5300 loss 6.057691 loss_att 8.673075 loss_ctc 7.605641 loss_rnnt 5.189103 hw_loss 0.260844 lr 0.00028688 rank 6
2023-03-01 12:15:28,587 DEBUG TRAIN Batch 55/5300 loss 3.948036 loss_att 7.682670 loss_ctc 8.787921 loss_rnnt 2.462525 hw_loss 0.174875 lr 0.00028688 rank 4
2023-03-01 12:15:28,590 DEBUG TRAIN Batch 55/5300 loss 3.908784 loss_att 7.682118 loss_ctc 9.754986 loss_rnnt 2.292448 hw_loss 0.154081 lr 0.00028689 rank 0
2023-03-01 12:15:28,591 DEBUG TRAIN Batch 55/5300 loss 8.208036 loss_att 10.771076 loss_ctc 17.324230 loss_rnnt 6.447082 hw_loss 0.061599 lr 0.00028688 rank 7
2023-03-01 12:15:28,596 DEBUG TRAIN Batch 55/5300 loss 11.256058 loss_att 12.084395 loss_ctc 17.589216 loss_rnnt 10.142140 hw_loss 0.194679 lr 0.00028688 rank 1
2023-03-01 12:15:28,634 DEBUG TRAIN Batch 55/5300 loss 12.991101 loss_att 15.089477 loss_ctc 13.255183 loss_rnnt 12.418266 hw_loss 0.221155 lr 0.00028688 rank 5
2023-03-01 12:16:33,938 DEBUG TRAIN Batch 55/5400 loss 5.855199 loss_att 9.171135 loss_ctc 7.425512 loss_rnnt 4.898522 hw_loss 0.157715 lr 0.00028687 rank 5
2023-03-01 12:16:33,948 DEBUG TRAIN Batch 55/5400 loss 4.052243 loss_att 6.404273 loss_ctc 6.954994 loss_rnnt 3.123331 hw_loss 0.134011 lr 0.00028687 rank 4
2023-03-01 12:16:33,952 DEBUG TRAIN Batch 55/5400 loss 5.211726 loss_att 8.380104 loss_ctc 7.945804 loss_rnnt 4.057868 hw_loss 0.291821 lr 0.00028688 rank 0
2023-03-01 12:16:33,952 DEBUG TRAIN Batch 55/5400 loss 7.648338 loss_att 8.444541 loss_ctc 12.834643 loss_rnnt 6.713811 hw_loss 0.157084 lr 0.00028686 rank 7
2023-03-01 12:16:33,955 DEBUG TRAIN Batch 55/5400 loss 5.981132 loss_att 8.220586 loss_ctc 10.180735 loss_rnnt 4.908049 hw_loss 0.122335 lr 0.00028686 rank 3
2023-03-01 12:16:33,959 DEBUG TRAIN Batch 55/5400 loss 6.550397 loss_att 10.711293 loss_ctc 11.166633 loss_rnnt 4.992149 hw_loss 0.207320 lr 0.00028687 rank 2
2023-03-01 12:16:33,976 DEBUG TRAIN Batch 55/5400 loss 10.581822 loss_att 18.012058 loss_ctc 17.715645 loss_rnnt 8.055375 hw_loss 0.167294 lr 0.00028687 rank 6
2023-03-01 12:16:34,002 DEBUG TRAIN Batch 55/5400 loss 6.440353 loss_att 7.690149 loss_ctc 11.767909 loss_rnnt 5.386382 hw_loss 0.175634 lr 0.00028687 rank 1
2023-03-01 12:17:13,087 DEBUG TRAIN Batch 55/5500 loss 5.512658 loss_att 9.566107 loss_ctc 8.728079 loss_rnnt 4.168281 hw_loss 0.196809 lr 0.00028686 rank 4
2023-03-01 12:17:13,091 DEBUG TRAIN Batch 55/5500 loss 3.492416 loss_att 5.626688 loss_ctc 5.646974 loss_rnnt 2.727127 hw_loss 0.095925 lr 0.00028686 rank 6
2023-03-01 12:17:13,097 DEBUG TRAIN Batch 55/5500 loss 6.863316 loss_att 10.090552 loss_ctc 12.296831 loss_rnnt 5.393024 hw_loss 0.188204 lr 0.00028687 rank 0
2023-03-01 12:17:13,099 DEBUG TRAIN Batch 55/5500 loss 12.873585 loss_att 17.187145 loss_ctc 20.765968 loss_rnnt 10.887634 hw_loss 0.132976 lr 0.00028685 rank 3
2023-03-01 12:17:13,100 DEBUG TRAIN Batch 55/5500 loss 7.035777 loss_att 8.405031 loss_ctc 11.050040 loss_rnnt 6.148014 hw_loss 0.147522 lr 0.00028685 rank 7
2023-03-01 12:17:13,100 DEBUG TRAIN Batch 55/5500 loss 4.538871 loss_att 6.568268 loss_ctc 6.476171 loss_rnnt 3.726752 hw_loss 0.277375 lr 0.00028686 rank 2
2023-03-01 12:17:13,101 DEBUG TRAIN Batch 55/5500 loss 7.670457 loss_att 11.291534 loss_ctc 12.003358 loss_rnnt 6.346973 hw_loss 0.040403 lr 0.00028686 rank 5
2023-03-01 12:17:13,153 DEBUG TRAIN Batch 55/5500 loss 5.266822 loss_att 7.890878 loss_ctc 9.124972 loss_rnnt 4.093623 hw_loss 0.251190 lr 0.00028686 rank 1
2023-03-01 12:17:52,695 DEBUG TRAIN Batch 55/5600 loss 8.293495 loss_att 10.460652 loss_ctc 16.220985 loss_rnnt 6.638011 hw_loss 0.309476 lr 0.00028684 rank 5
2023-03-01 12:17:52,698 DEBUG TRAIN Batch 55/5600 loss 14.853192 loss_att 15.133421 loss_ctc 24.749762 loss_rnnt 13.340162 hw_loss 0.257705 lr 0.00028684 rank 4
2023-03-01 12:17:52,701 DEBUG TRAIN Batch 55/5600 loss 5.813512 loss_att 8.211875 loss_ctc 11.713562 loss_rnnt 4.481555 hw_loss 0.123021 lr 0.00028684 rank 3
2023-03-01 12:17:52,703 DEBUG TRAIN Batch 55/5600 loss 7.577944 loss_att 10.661234 loss_ctc 11.106451 loss_rnnt 6.427580 hw_loss 0.118573 lr 0.00028685 rank 6
2023-03-01 12:17:52,706 DEBUG TRAIN Batch 55/5600 loss 8.272212 loss_att 11.074469 loss_ctc 11.588245 loss_rnnt 7.174104 hw_loss 0.179098 lr 0.00028684 rank 7
2023-03-01 12:17:52,708 DEBUG TRAIN Batch 55/5600 loss 4.947322 loss_att 9.132228 loss_ctc 7.495013 loss_rnnt 3.700390 hw_loss 0.131734 lr 0.00028685 rank 0
2023-03-01 12:17:52,731 DEBUG TRAIN Batch 55/5600 loss 5.163321 loss_att 5.779552 loss_ctc 8.421117 loss_rnnt 4.478804 hw_loss 0.237935 lr 0.00028684 rank 1
2023-03-01 12:17:52,739 DEBUG TRAIN Batch 55/5600 loss 9.403467 loss_att 11.669851 loss_ctc 15.018845 loss_rnnt 8.142051 hw_loss 0.111419 lr 0.00028685 rank 2
2023-03-01 12:18:59,359 DEBUG TRAIN Batch 55/5700 loss 2.026625 loss_att 5.091531 loss_ctc 3.342304 loss_rnnt 1.129121 hw_loss 0.204560 lr 0.00028683 rank 5
2023-03-01 12:18:59,363 DEBUG TRAIN Batch 55/5700 loss 7.965958 loss_att 10.352895 loss_ctc 14.311216 loss_rnnt 6.569100 hw_loss 0.137690 lr 0.00028683 rank 1
2023-03-01 12:18:59,366 DEBUG TRAIN Batch 55/5700 loss 6.836021 loss_att 9.143779 loss_ctc 15.763327 loss_rnnt 5.090329 hw_loss 0.175936 lr 0.00028684 rank 6
2023-03-01 12:18:59,375 DEBUG TRAIN Batch 55/5700 loss 9.184934 loss_att 9.438202 loss_ctc 12.556517 loss_rnnt 8.563962 hw_loss 0.226450 lr 0.00028684 rank 0
2023-03-01 12:18:59,375 DEBUG TRAIN Batch 55/5700 loss 6.791645 loss_att 7.557509 loss_ctc 10.571095 loss_rnnt 6.024352 hw_loss 0.206612 lr 0.00028683 rank 4
2023-03-01 12:18:59,381 DEBUG TRAIN Batch 55/5700 loss 12.901097 loss_att 13.897090 loss_ctc 18.268217 loss_rnnt 11.856268 hw_loss 0.243781 lr 0.00028683 rank 3
2023-03-01 12:18:59,384 DEBUG TRAIN Batch 55/5700 loss 13.884154 loss_att 14.303804 loss_ctc 24.320318 loss_rnnt 12.301808 hw_loss 0.200489 lr 0.00028684 rank 2
2023-03-01 12:18:59,411 DEBUG TRAIN Batch 55/5700 loss 4.711783 loss_att 6.511224 loss_ctc 6.680576 loss_rnnt 4.007513 hw_loss 0.153518 lr 0.00028683 rank 7
2023-03-01 12:19:38,357 DEBUG TRAIN Batch 55/5800 loss 7.390902 loss_att 10.046741 loss_ctc 12.204365 loss_rnnt 6.104179 hw_loss 0.213300 lr 0.00028682 rank 4
2023-03-01 12:19:38,361 DEBUG TRAIN Batch 55/5800 loss 3.202440 loss_att 7.058872 loss_ctc 8.525897 loss_rnnt 1.632659 hw_loss 0.166314 lr 0.00028683 rank 2
2023-03-01 12:19:38,364 DEBUG TRAIN Batch 55/5800 loss 1.470212 loss_att 3.670883 loss_ctc 2.211973 loss_rnnt 0.836454 hw_loss 0.177605 lr 0.00028682 rank 7
2023-03-01 12:19:38,368 DEBUG TRAIN Batch 55/5800 loss 7.009512 loss_att 10.079524 loss_ctc 10.015398 loss_rnnt 5.811407 hw_loss 0.343723 lr 0.00028683 rank 0
2023-03-01 12:19:38,370 DEBUG TRAIN Batch 55/5800 loss 5.792138 loss_att 7.017775 loss_ctc 8.848500 loss_rnnt 4.921123 hw_loss 0.409448 lr 0.00028682 rank 6
2023-03-01 12:19:38,372 DEBUG TRAIN Batch 55/5800 loss 7.767705 loss_att 12.464573 loss_ctc 14.151329 loss_rnnt 5.917128 hw_loss 0.112602 lr 0.00028682 rank 5
2023-03-01 12:19:38,372 DEBUG TRAIN Batch 55/5800 loss 4.402272 loss_att 5.513984 loss_ctc 7.600523 loss_rnnt 3.705540 hw_loss 0.089917 lr 0.00028682 rank 1
2023-03-01 12:19:38,375 DEBUG TRAIN Batch 55/5800 loss 3.583587 loss_att 5.271686 loss_ctc 7.000422 loss_rnnt 2.672003 hw_loss 0.221974 lr 0.00028682 rank 3
2023-03-01 12:20:17,435 DEBUG TRAIN Batch 55/5900 loss 10.316582 loss_att 13.075873 loss_ctc 17.542936 loss_rnnt 8.655682 hw_loss 0.272866 lr 0.00028681 rank 7
2023-03-01 12:20:17,450 DEBUG TRAIN Batch 55/5900 loss 1.668171 loss_att 3.868830 loss_ctc 3.404704 loss_rnnt 0.970418 hw_loss 0.048906 lr 0.00028681 rank 6
2023-03-01 12:20:17,450 DEBUG TRAIN Batch 55/5900 loss 4.584220 loss_att 6.556934 loss_ctc 8.347855 loss_rnnt 3.581879 hw_loss 0.198713 lr 0.00028680 rank 3
2023-03-01 12:20:17,451 DEBUG TRAIN Batch 55/5900 loss 8.630233 loss_att 8.834606 loss_ctc 14.235085 loss_rnnt 7.682579 hw_loss 0.298998 lr 0.00028682 rank 0
2023-03-01 12:20:17,451 DEBUG TRAIN Batch 55/5900 loss 4.417094 loss_att 8.910049 loss_ctc 8.220136 loss_rnnt 2.964588 hw_loss 0.087831 lr 0.00028681 rank 4
2023-03-01 12:20:17,451 DEBUG TRAIN Batch 55/5900 loss 0.709889 loss_att 2.620985 loss_ctc 1.239075 loss_rnnt 0.092256 hw_loss 0.309105 lr 0.00028681 rank 2
2023-03-01 12:20:17,468 DEBUG TRAIN Batch 55/5900 loss 11.787007 loss_att 18.713005 loss_ctc 21.411028 loss_rnnt 9.005932 hw_loss 0.211263 lr 0.00028681 rank 1
2023-03-01 12:20:17,470 DEBUG TRAIN Batch 55/5900 loss 1.944107 loss_att 5.533611 loss_ctc 3.122377 loss_rnnt 0.932334 hw_loss 0.256442 lr 0.00028681 rank 5
2023-03-01 12:20:57,117 DEBUG TRAIN Batch 55/6000 loss 3.632411 loss_att 7.635486 loss_ctc 6.681356 loss_rnnt 2.336099 hw_loss 0.167196 lr 0.00028680 rank 2
2023-03-01 12:20:57,119 DEBUG TRAIN Batch 55/6000 loss 2.867808 loss_att 4.900574 loss_ctc 3.596015 loss_rnnt 2.257662 hw_loss 0.199686 lr 0.00028681 rank 0
2023-03-01 12:20:57,125 DEBUG TRAIN Batch 55/6000 loss 7.313494 loss_att 12.279636 loss_ctc 11.145329 loss_rnnt 5.727561 hw_loss 0.153361 lr 0.00028680 rank 1
2023-03-01 12:20:57,126 DEBUG TRAIN Batch 55/6000 loss 9.557823 loss_att 10.066495 loss_ctc 15.142456 loss_rnnt 8.480688 hw_loss 0.432718 lr 0.00028680 rank 6
2023-03-01 12:20:57,127 DEBUG TRAIN Batch 55/6000 loss 7.138630 loss_att 8.955050 loss_ctc 11.277534 loss_rnnt 6.080462 hw_loss 0.268183 lr 0.00028680 rank 5
2023-03-01 12:20:57,129 DEBUG TRAIN Batch 55/6000 loss 1.288544 loss_att 3.587093 loss_ctc 2.274072 loss_rnnt 0.588149 hw_loss 0.204902 lr 0.00028680 rank 4
2023-03-01 12:20:57,131 DEBUG TRAIN Batch 55/6000 loss 2.829777 loss_att 5.591158 loss_ctc 5.017113 loss_rnnt 1.868290 hw_loss 0.220437 lr 0.00028679 rank 3
2023-03-01 12:20:57,134 DEBUG TRAIN Batch 55/6000 loss 6.507279 loss_att 7.749342 loss_ctc 9.916241 loss_rnnt 5.707255 hw_loss 0.182032 lr 0.00028679 rank 7
2023-03-01 12:22:01,156 DEBUG TRAIN Batch 55/6100 loss 4.633353 loss_att 6.446951 loss_ctc 7.378000 loss_rnnt 3.696992 hw_loss 0.389416 lr 0.00028680 rank 0
2023-03-01 12:22:01,156 DEBUG TRAIN Batch 55/6100 loss 4.196927 loss_att 6.382852 loss_ctc 5.934363 loss_rnnt 3.371697 hw_loss 0.293224 lr 0.00028678 rank 1
2023-03-01 12:22:01,157 DEBUG TRAIN Batch 55/6100 loss 7.841018 loss_att 11.483145 loss_ctc 13.530546 loss_rnnt 6.278193 hw_loss 0.142116 lr 0.00028679 rank 2
2023-03-01 12:22:01,158 DEBUG TRAIN Batch 55/6100 loss 6.012676 loss_att 8.096592 loss_ctc 7.235162 loss_rnnt 5.359663 hw_loss 0.137310 lr 0.00028679 rank 5
2023-03-01 12:22:01,160 DEBUG TRAIN Batch 55/6100 loss 3.729475 loss_att 7.210939 loss_ctc 8.018674 loss_rnnt 2.344229 hw_loss 0.219486 lr 0.00028678 rank 7
2023-03-01 12:22:01,164 DEBUG TRAIN Batch 55/6100 loss 7.666321 loss_att 9.779943 loss_ctc 11.375383 loss_rnnt 6.652005 hw_loss 0.181968 lr 0.00028678 rank 3
2023-03-01 12:22:01,166 DEBUG TRAIN Batch 55/6100 loss 7.114527 loss_att 10.679917 loss_ctc 14.054830 loss_rnnt 5.353868 hw_loss 0.229137 lr 0.00028679 rank 6
2023-03-01 12:22:01,167 DEBUG TRAIN Batch 55/6100 loss 2.741696 loss_att 5.106847 loss_ctc 4.989726 loss_rnnt 1.923856 hw_loss 0.084510 lr 0.00028679 rank 4
2023-03-01 12:22:40,166 DEBUG TRAIN Batch 55/6200 loss 10.520796 loss_att 13.018878 loss_ctc 15.523263 loss_rnnt 9.288416 hw_loss 0.123315 lr 0.00028678 rank 0
2023-03-01 12:22:40,173 DEBUG TRAIN Batch 55/6200 loss 5.623279 loss_att 6.395399 loss_ctc 9.531084 loss_rnnt 4.796484 hw_loss 0.283742 lr 0.00028677 rank 7
2023-03-01 12:22:40,176 DEBUG TRAIN Batch 55/6200 loss 7.641838 loss_att 10.714765 loss_ctc 11.770660 loss_rnnt 6.365531 hw_loss 0.208522 lr 0.00028677 rank 3
2023-03-01 12:22:40,177 DEBUG TRAIN Batch 55/6200 loss 7.093032 loss_att 8.809209 loss_ctc 10.335593 loss_rnnt 6.192984 hw_loss 0.233383 lr 0.00028678 rank 2
2023-03-01 12:22:40,177 DEBUG TRAIN Batch 55/6200 loss 5.591424 loss_att 6.551015 loss_ctc 8.626043 loss_rnnt 4.900621 hw_loss 0.176753 lr 0.00028677 rank 1
2023-03-01 12:22:40,185 DEBUG TRAIN Batch 55/6200 loss 9.867265 loss_att 13.145149 loss_ctc 17.025082 loss_rnnt 8.193453 hw_loss 0.119735 lr 0.00028677 rank 5
2023-03-01 12:22:40,205 DEBUG TRAIN Batch 55/6200 loss 5.631463 loss_att 7.743441 loss_ctc 10.717060 loss_rnnt 4.422421 hw_loss 0.203562 lr 0.00028678 rank 6
2023-03-01 12:22:40,223 DEBUG TRAIN Batch 55/6200 loss 4.337246 loss_att 7.690697 loss_ctc 9.467192 loss_rnnt 2.831493 hw_loss 0.283257 lr 0.00028677 rank 4
2023-03-01 12:23:19,269 DEBUG TRAIN Batch 55/6300 loss 5.186553 loss_att 8.286259 loss_ctc 9.245502 loss_rnnt 3.926598 hw_loss 0.185291 lr 0.00028676 rank 7
2023-03-01 12:23:19,270 DEBUG TRAIN Batch 55/6300 loss 6.944353 loss_att 8.684414 loss_ctc 9.788051 loss_rnnt 6.109942 hw_loss 0.201072 lr 0.00028677 rank 2
2023-03-01 12:23:19,271 DEBUG TRAIN Batch 55/6300 loss 5.260572 loss_att 9.110328 loss_ctc 12.035884 loss_rnnt 3.440031 hw_loss 0.276028 lr 0.00028677 rank 0
2023-03-01 12:23:19,271 DEBUG TRAIN Batch 55/6300 loss 2.188318 loss_att 5.646433 loss_ctc 3.766637 loss_rnnt 1.194647 hw_loss 0.171761 lr 0.00028676 rank 1
2023-03-01 12:23:19,272 DEBUG TRAIN Batch 55/6300 loss 8.027776 loss_att 10.988123 loss_ctc 12.769880 loss_rnnt 6.659377 hw_loss 0.270092 lr 0.00028676 rank 5
2023-03-01 12:23:19,275 DEBUG TRAIN Batch 55/6300 loss 10.365628 loss_att 13.605370 loss_ctc 21.409018 loss_rnnt 8.163713 hw_loss 0.152839 lr 0.00028676 rank 4
2023-03-01 12:23:19,278 DEBUG TRAIN Batch 55/6300 loss 3.722049 loss_att 8.053879 loss_ctc 5.988809 loss_rnnt 2.462245 hw_loss 0.171007 lr 0.00028676 rank 6
2023-03-01 12:23:19,321 DEBUG TRAIN Batch 55/6300 loss 7.584285 loss_att 10.582179 loss_ctc 11.992636 loss_rnnt 6.285356 hw_loss 0.209193 lr 0.00028676 rank 3
2023-03-01 12:24:24,129 DEBUG TRAIN Batch 55/6400 loss 4.669436 loss_att 7.984084 loss_ctc 6.624567 loss_rnnt 3.566420 hw_loss 0.336380 lr 0.00028676 rank 2
2023-03-01 12:24:24,139 DEBUG TRAIN Batch 55/6400 loss 7.222375 loss_att 10.871161 loss_ctc 13.920519 loss_rnnt 5.508544 hw_loss 0.170600 lr 0.00028675 rank 7
2023-03-01 12:24:24,141 DEBUG TRAIN Batch 55/6400 loss 4.466681 loss_att 7.889452 loss_ctc 10.061239 loss_rnnt 2.919122 hw_loss 0.219494 lr 0.00028676 rank 0
2023-03-01 12:24:24,142 DEBUG TRAIN Batch 55/6400 loss 8.019597 loss_att 10.060191 loss_ctc 12.446894 loss_rnnt 6.836564 hw_loss 0.346139 lr 0.00028675 rank 5
2023-03-01 12:24:24,143 DEBUG TRAIN Batch 55/6400 loss 0.979087 loss_att 3.116732 loss_ctc 1.628770 loss_rnnt 0.265030 hw_loss 0.374821 lr 0.00028675 rank 1
2023-03-01 12:24:24,144 DEBUG TRAIN Batch 55/6400 loss 5.270863 loss_att 7.873128 loss_ctc 9.058248 loss_rnnt 4.174486 hw_loss 0.133011 lr 0.00028675 rank 4
2023-03-01 12:24:24,146 DEBUG TRAIN Batch 55/6400 loss 9.272718 loss_att 9.661433 loss_ctc 16.986479 loss_rnnt 8.033401 hw_loss 0.249512 lr 0.00028675 rank 6
2023-03-01 12:24:24,183 DEBUG TRAIN Batch 55/6400 loss 11.218005 loss_att 14.742288 loss_ctc 14.282545 loss_rnnt 9.997999 hw_loss 0.199768 lr 0.00028675 rank 3
2023-03-01 12:25:03,365 DEBUG TRAIN Batch 55/6500 loss 4.141876 loss_att 7.810141 loss_ctc 8.488464 loss_rnnt 2.727599 hw_loss 0.189523 lr 0.00028674 rank 1
2023-03-01 12:25:03,366 DEBUG TRAIN Batch 55/6500 loss 4.685337 loss_att 7.562844 loss_ctc 8.286420 loss_rnnt 3.549507 hw_loss 0.150346 lr 0.00028674 rank 7
2023-03-01 12:25:03,368 DEBUG TRAIN Batch 55/6500 loss 5.543886 loss_att 6.130358 loss_ctc 13.134867 loss_rnnt 4.306759 hw_loss 0.201942 lr 0.00028674 rank 5
2023-03-01 12:25:03,370 DEBUG TRAIN Batch 55/6500 loss 7.174069 loss_att 10.806564 loss_ctc 10.775023 loss_rnnt 5.890355 hw_loss 0.144539 lr 0.00028673 rank 3
2023-03-01 12:25:03,369 DEBUG TRAIN Batch 55/6500 loss 4.024214 loss_att 6.561491 loss_ctc 5.839823 loss_rnnt 3.159296 hw_loss 0.216342 lr 0.00028674 rank 6
2023-03-01 12:25:03,371 DEBUG TRAIN Batch 55/6500 loss 7.061050 loss_att 8.583419 loss_ctc 12.093420 loss_rnnt 5.903178 hw_loss 0.342031 lr 0.00028675 rank 0
2023-03-01 12:25:03,371 DEBUG TRAIN Batch 55/6500 loss 6.362983 loss_att 8.281382 loss_ctc 7.918143 loss_rnnt 5.657071 hw_loss 0.215395 lr 0.00028674 rank 2
2023-03-01 12:25:03,376 DEBUG TRAIN Batch 55/6500 loss 4.601170 loss_att 7.290668 loss_ctc 6.103651 loss_rnnt 3.738127 hw_loss 0.234022 lr 0.00028674 rank 4
2023-03-01 12:25:42,194 DEBUG TRAIN Batch 55/6600 loss 5.188533 loss_att 8.743227 loss_ctc 10.471904 loss_rnnt 3.691247 hw_loss 0.153560 lr 0.00028673 rank 2
2023-03-01 12:25:42,195 DEBUG TRAIN Batch 55/6600 loss 9.198915 loss_att 16.582253 loss_ctc 17.381516 loss_rnnt 6.534677 hw_loss 0.181046 lr 0.00028673 rank 6
2023-03-01 12:25:42,207 DEBUG TRAIN Batch 55/6600 loss 2.462500 loss_att 3.985527 loss_ctc 2.163465 loss_rnnt 2.094948 hw_loss 0.192782 lr 0.00028674 rank 0
2023-03-01 12:25:42,210 DEBUG TRAIN Batch 55/6600 loss 8.028284 loss_att 11.868353 loss_ctc 13.350193 loss_rnnt 6.503076 hw_loss 0.089262 lr 0.00028672 rank 7
2023-03-01 12:25:42,210 DEBUG TRAIN Batch 55/6600 loss 4.923172 loss_att 8.704832 loss_ctc 9.601434 loss_rnnt 3.379532 hw_loss 0.306637 lr 0.00028673 rank 5
2023-03-01 12:25:42,210 DEBUG TRAIN Batch 55/6600 loss 3.986073 loss_att 6.573752 loss_ctc 10.334723 loss_rnnt 2.470469 hw_loss 0.284215 lr 0.00028673 rank 1
2023-03-01 12:25:42,212 DEBUG TRAIN Batch 55/6600 loss 1.612330 loss_att 4.235531 loss_ctc 4.437271 loss_rnnt 0.571145 hw_loss 0.262285 lr 0.00028672 rank 3
2023-03-01 12:25:42,218 DEBUG TRAIN Batch 55/6600 loss 5.798372 loss_att 8.286345 loss_ctc 10.910821 loss_rnnt 4.570872 hw_loss 0.090459 lr 0.00028673 rank 4
2023-03-01 12:26:21,800 DEBUG TRAIN Batch 55/6700 loss 2.758160 loss_att 6.136704 loss_ctc 4.670614 loss_rnnt 1.761272 hw_loss 0.124098 lr 0.00028671 rank 5
2023-03-01 12:26:21,802 DEBUG TRAIN Batch 55/6700 loss 3.617241 loss_att 5.017807 loss_ctc 4.155750 loss_rnnt 3.116555 hw_loss 0.278947 lr 0.00028671 rank 1
2023-03-01 12:26:21,803 DEBUG TRAIN Batch 55/6700 loss 6.771245 loss_att 8.308386 loss_ctc 13.987261 loss_rnnt 5.374467 hw_loss 0.238528 lr 0.00028672 rank 2
2023-03-01 12:26:21,803 DEBUG TRAIN Batch 55/6700 loss 3.826678 loss_att 6.420183 loss_ctc 7.991333 loss_rnnt 2.612425 hw_loss 0.262995 lr 0.00028672 rank 6
2023-03-01 12:26:21,815 DEBUG TRAIN Batch 55/6700 loss 9.233648 loss_att 10.141975 loss_ctc 15.158648 loss_rnnt 8.175953 hw_loss 0.161307 lr 0.00028672 rank 0
2023-03-01 12:26:21,819 DEBUG TRAIN Batch 55/6700 loss 10.989604 loss_att 13.844675 loss_ctc 20.894291 loss_rnnt 8.962379 hw_loss 0.254224 lr 0.00028671 rank 7
2023-03-01 12:26:21,831 DEBUG TRAIN Batch 55/6700 loss 2.294852 loss_att 5.126657 loss_ctc 3.712154 loss_rnnt 1.391647 hw_loss 0.277257 lr 0.00028671 rank 4
2023-03-01 12:26:21,838 DEBUG TRAIN Batch 55/6700 loss 1.142855 loss_att 3.834153 loss_ctc 1.790708 loss_rnnt 0.336779 hw_loss 0.340192 lr 0.00028671 rank 3
2023-03-01 12:27:25,441 DEBUG TRAIN Batch 55/6800 loss 7.793406 loss_att 9.903321 loss_ctc 19.213825 loss_rnnt 5.754309 hw_loss 0.176983 lr 0.00028670 rank 5
2023-03-01 12:27:25,453 DEBUG TRAIN Batch 55/6800 loss 4.907555 loss_att 10.759648 loss_ctc 10.165018 loss_rnnt 2.916477 hw_loss 0.224371 lr 0.00028671 rank 0
2023-03-01 12:27:25,458 DEBUG TRAIN Batch 55/6800 loss 5.672789 loss_att 9.553879 loss_ctc 9.463472 loss_rnnt 4.348636 hw_loss 0.079709 lr 0.00028671 rank 2
2023-03-01 12:27:25,459 DEBUG TRAIN Batch 55/6800 loss 3.993959 loss_att 5.235773 loss_ctc 7.096329 loss_rnnt 3.148973 hw_loss 0.343075 lr 0.00028670 rank 1
2023-03-01 12:27:25,460 DEBUG TRAIN Batch 55/6800 loss 5.351336 loss_att 8.192686 loss_ctc 7.025937 loss_rnnt 4.468879 hw_loss 0.170450 lr 0.00028670 rank 3
2023-03-01 12:27:25,463 DEBUG TRAIN Batch 55/6800 loss 2.723415 loss_att 5.126386 loss_ctc 4.402363 loss_rnnt 1.911459 hw_loss 0.201564 lr 0.00028670 rank 4
2023-03-01 12:27:25,466 DEBUG TRAIN Batch 55/6800 loss 5.365517 loss_att 7.023666 loss_ctc 7.984048 loss_rnnt 4.539093 hw_loss 0.273107 lr 0.00028670 rank 7
2023-03-01 12:27:25,482 DEBUG TRAIN Batch 55/6800 loss 8.966896 loss_att 10.822797 loss_ctc 18.419945 loss_rnnt 7.232217 hw_loss 0.193298 lr 0.00028671 rank 6
2023-03-01 12:28:04,398 DEBUG TRAIN Batch 55/6900 loss 9.612082 loss_att 14.784688 loss_ctc 16.035450 loss_rnnt 7.544389 hw_loss 0.331354 lr 0.00028670 rank 2
2023-03-01 12:28:04,408 DEBUG TRAIN Batch 55/6900 loss 1.997724 loss_att 3.872559 loss_ctc 3.599245 loss_rnnt 1.315233 hw_loss 0.176229 lr 0.00028669 rank 4
2023-03-01 12:28:04,411 DEBUG TRAIN Batch 55/6900 loss 6.903231 loss_att 7.773313 loss_ctc 11.613957 loss_rnnt 5.980547 hw_loss 0.226067 lr 0.00028669 rank 3
2023-03-01 12:28:04,416 DEBUG TRAIN Batch 55/6900 loss 4.780219 loss_att 5.817709 loss_ctc 8.063415 loss_rnnt 3.976233 hw_loss 0.297616 lr 0.00028669 rank 1
2023-03-01 12:28:04,419 DEBUG TRAIN Batch 55/6900 loss 9.171946 loss_att 10.395687 loss_ctc 14.821471 loss_rnnt 8.022667 hw_loss 0.283613 lr 0.00028669 rank 7
2023-03-01 12:28:04,422 DEBUG TRAIN Batch 55/6900 loss 3.397918 loss_att 6.508585 loss_ctc 6.323824 loss_rnnt 2.256583 hw_loss 0.242027 lr 0.00028669 rank 5
2023-03-01 12:28:04,427 DEBUG TRAIN Batch 55/6900 loss 6.292625 loss_att 9.908194 loss_ctc 14.200183 loss_rnnt 4.442291 hw_loss 0.136650 lr 0.00028670 rank 0
2023-03-01 12:28:04,434 DEBUG TRAIN Batch 55/6900 loss 6.851773 loss_att 9.331202 loss_ctc 9.971025 loss_rnnt 5.916653 hw_loss 0.043752 lr 0.00028669 rank 6
2023-03-01 12:28:43,437 DEBUG TRAIN Batch 55/7000 loss 3.917417 loss_att 6.831267 loss_ctc 6.531774 loss_rnnt 2.895138 hw_loss 0.170489 lr 0.00028668 rank 6
2023-03-01 12:28:43,443 DEBUG TRAIN Batch 55/7000 loss 5.570894 loss_att 12.556082 loss_ctc 10.017782 loss_rnnt 3.514235 hw_loss 0.125068 lr 0.00028668 rank 4
2023-03-01 12:28:43,454 DEBUG TRAIN Batch 55/7000 loss 7.153226 loss_att 9.780662 loss_ctc 10.960766 loss_rnnt 5.989252 hw_loss 0.245280 lr 0.00028669 rank 0
2023-03-01 12:28:43,454 DEBUG TRAIN Batch 55/7000 loss 4.633687 loss_att 8.025843 loss_ctc 12.005362 loss_rnnt 2.911958 hw_loss 0.113264 lr 0.00028668 rank 1
2023-03-01 12:28:43,455 DEBUG TRAIN Batch 55/7000 loss 2.692143 loss_att 8.145924 loss_ctc 4.764708 loss_rnnt 1.234639 hw_loss 0.169512 lr 0.00028667 rank 3
2023-03-01 12:28:43,456 DEBUG TRAIN Batch 55/7000 loss 1.967107 loss_att 4.730643 loss_ctc 2.826363 loss_rnnt 1.213578 hw_loss 0.161725 lr 0.00028668 rank 7
2023-03-01 12:28:43,458 DEBUG TRAIN Batch 55/7000 loss 5.734321 loss_att 8.944366 loss_ctc 8.410038 loss_rnnt 4.619580 hw_loss 0.217443 lr 0.00028668 rank 5
2023-03-01 12:28:43,480 DEBUG TRAIN Batch 55/7000 loss 6.436502 loss_att 9.460261 loss_ctc 11.059683 loss_rnnt 5.042876 hw_loss 0.323342 lr 0.00028668 rank 2
2023-03-01 12:29:45,393 DEBUG TRAIN Batch 55/7100 loss 8.649532 loss_att 17.579117 loss_ctc 14.604986 loss_rnnt 5.909500 hw_loss 0.300102 lr 0.00028667 rank 6
2023-03-01 12:29:45,394 DEBUG TRAIN Batch 55/7100 loss 6.725919 loss_att 6.984927 loss_ctc 8.762133 loss_rnnt 6.285315 hw_loss 0.219952 lr 0.00028667 rank 1
2023-03-01 12:29:45,395 DEBUG TRAIN Batch 55/7100 loss 1.203876 loss_att 4.033673 loss_ctc 1.639467 loss_rnnt 0.482161 hw_loss 0.183144 lr 0.00028666 rank 3
2023-03-01 12:29:45,396 DEBUG TRAIN Batch 55/7100 loss 3.654318 loss_att 9.176418 loss_ctc 8.478456 loss_rnnt 1.805011 hw_loss 0.190629 lr 0.00028667 rank 2
2023-03-01 12:29:45,403 DEBUG TRAIN Batch 55/7100 loss 7.362586 loss_att 9.090133 loss_ctc 11.427157 loss_rnnt 6.398929 hw_loss 0.142883 lr 0.00028666 rank 7
2023-03-01 12:29:45,404 DEBUG TRAIN Batch 55/7100 loss 7.979929 loss_att 8.550303 loss_ctc 13.952807 loss_rnnt 6.887544 hw_loss 0.341112 lr 0.00028668 rank 0
2023-03-01 12:29:45,410 DEBUG TRAIN Batch 55/7100 loss 5.500185 loss_att 8.278374 loss_ctc 9.474746 loss_rnnt 4.346165 hw_loss 0.128328 lr 0.00028667 rank 4
2023-03-01 12:29:45,442 DEBUG TRAIN Batch 55/7100 loss 9.426663 loss_att 14.873400 loss_ctc 17.597021 loss_rnnt 7.118479 hw_loss 0.242733 lr 0.00028667 rank 5
2023-03-01 12:30:27,667 DEBUG TRAIN Batch 55/7200 loss 2.277154 loss_att 5.207351 loss_ctc 5.675057 loss_rnnt 1.217559 hw_loss 0.038441 lr 0.00028666 rank 2
2023-03-01 12:30:27,677 DEBUG TRAIN Batch 55/7200 loss 5.638187 loss_att 9.517673 loss_ctc 10.680266 loss_rnnt 4.138467 hw_loss 0.096647 lr 0.00028665 rank 7
2023-03-01 12:30:27,680 DEBUG TRAIN Batch 55/7200 loss 9.236307 loss_att 12.168505 loss_ctc 13.010333 loss_rnnt 8.039566 hw_loss 0.200808 lr 0.00028667 rank 0
2023-03-01 12:30:27,680 DEBUG TRAIN Batch 55/7200 loss 4.702479 loss_att 6.299585 loss_ctc 6.036280 loss_rnnt 3.992541 hw_loss 0.398768 lr 0.00028666 rank 5
2023-03-01 12:30:27,683 DEBUG TRAIN Batch 55/7200 loss 2.646997 loss_att 4.426735 loss_ctc 6.159283 loss_rnnt 1.694337 hw_loss 0.240765 lr 0.00028666 rank 6
2023-03-01 12:30:27,684 DEBUG TRAIN Batch 55/7200 loss 3.869104 loss_att 6.007352 loss_ctc 8.237224 loss_rnnt 2.810913 hw_loss 0.090236 lr 0.00028665 rank 3
2023-03-01 12:30:27,685 DEBUG TRAIN Batch 55/7200 loss 6.267621 loss_att 10.400240 loss_ctc 11.893353 loss_rnnt 4.641513 hw_loss 0.092788 lr 0.00028666 rank 1
2023-03-01 12:30:27,689 DEBUG TRAIN Batch 55/7200 loss 8.571111 loss_att 11.229763 loss_ctc 12.982485 loss_rnnt 7.335783 hw_loss 0.216403 lr 0.00028666 rank 4
2023-03-01 12:31:06,713 DEBUG TRAIN Batch 55/7300 loss 6.962960 loss_att 8.853637 loss_ctc 9.872976 loss_rnnt 6.070592 hw_loss 0.236683 lr 0.00028664 rank 1
2023-03-01 12:31:06,724 DEBUG TRAIN Batch 55/7300 loss 4.044591 loss_att 7.455128 loss_ctc 6.146532 loss_rnnt 2.949323 hw_loss 0.249192 lr 0.00028665 rank 0
2023-03-01 12:31:06,725 DEBUG TRAIN Batch 55/7300 loss 2.070981 loss_att 4.684693 loss_ctc 3.680852 loss_rnnt 1.238646 hw_loss 0.178018 lr 0.00028664 rank 3
2023-03-01 12:31:06,728 DEBUG TRAIN Batch 55/7300 loss 3.403433 loss_att 8.152735 loss_ctc 8.378983 loss_rnnt 1.671298 hw_loss 0.222878 lr 0.00028664 rank 4
2023-03-01 12:31:06,728 DEBUG TRAIN Batch 55/7300 loss 9.525197 loss_att 13.362535 loss_ctc 13.906674 loss_rnnt 8.106576 hw_loss 0.125543 lr 0.00028664 rank 7
2023-03-01 12:31:06,730 DEBUG TRAIN Batch 55/7300 loss 8.351257 loss_att 11.557508 loss_ctc 14.511843 loss_rnnt 6.777617 hw_loss 0.208085 lr 0.00028664 rank 5
2023-03-01 12:31:06,731 DEBUG TRAIN Batch 55/7300 loss 6.297304 loss_att 9.132993 loss_ctc 10.214689 loss_rnnt 5.157874 hw_loss 0.093700 lr 0.00028665 rank 6
2023-03-01 12:31:06,732 DEBUG TRAIN Batch 55/7300 loss 6.012292 loss_att 8.489700 loss_ctc 10.188875 loss_rnnt 4.777578 hw_loss 0.341915 lr 0.00028665 rank 2
2023-03-01 12:31:46,235 DEBUG TRAIN Batch 55/7400 loss 4.145102 loss_att 7.341208 loss_ctc 7.883537 loss_rnnt 2.932383 hw_loss 0.140701 lr 0.00028664 rank 0
2023-03-01 12:31:46,235 DEBUG TRAIN Batch 55/7400 loss 7.211107 loss_att 9.824606 loss_ctc 11.581588 loss_rnnt 5.992435 hw_loss 0.212327 lr 0.00028663 rank 5
2023-03-01 12:31:46,237 DEBUG TRAIN Batch 55/7400 loss 11.839842 loss_att 13.793805 loss_ctc 20.597437 loss_rnnt 10.206989 hw_loss 0.139464 lr 0.00028663 rank 1
2023-03-01 12:31:46,238 DEBUG TRAIN Batch 55/7400 loss 1.194273 loss_att 4.510968 loss_ctc 1.834194 loss_rnnt 0.342889 hw_loss 0.192606 lr 0.00028664 rank 6
2023-03-01 12:31:46,245 DEBUG TRAIN Batch 55/7400 loss 6.207588 loss_att 9.562973 loss_ctc 10.920927 loss_rnnt 4.756013 hw_loss 0.285098 lr 0.00028663 rank 7
2023-03-01 12:31:46,253 DEBUG TRAIN Batch 55/7400 loss 10.881499 loss_att 14.972795 loss_ctc 22.975657 loss_rnnt 8.349774 hw_loss 0.189208 lr 0.00028663 rank 3
2023-03-01 12:31:46,262 DEBUG TRAIN Batch 55/7400 loss 5.998923 loss_att 9.568315 loss_ctc 7.708885 loss_rnnt 4.933817 hw_loss 0.231061 lr 0.00028663 rank 4
2023-03-01 12:31:46,305 DEBUG TRAIN Batch 55/7400 loss 7.293024 loss_att 10.736917 loss_ctc 13.928678 loss_rnnt 5.599593 hw_loss 0.224809 lr 0.00028664 rank 2
2023-03-01 12:32:50,591 DEBUG TRAIN Batch 55/7500 loss 7.245564 loss_att 10.143036 loss_ctc 14.245726 loss_rnnt 5.650201 hw_loss 0.154715 lr 0.00028663 rank 0
2023-03-01 12:32:50,591 DEBUG TRAIN Batch 55/7500 loss 6.609576 loss_att 9.437937 loss_ctc 8.404502 loss_rnnt 5.712276 hw_loss 0.173069 lr 0.00028662 rank 1
2023-03-01 12:32:50,592 DEBUG TRAIN Batch 55/7500 loss 2.472827 loss_att 4.386587 loss_ctc 3.913141 loss_rnnt 1.729343 hw_loss 0.316293 lr 0.00028662 rank 7
2023-03-01 12:32:50,597 DEBUG TRAIN Batch 55/7500 loss 6.521773 loss_att 8.941965 loss_ctc 11.572477 loss_rnnt 5.264352 hw_loss 0.187416 lr 0.00028662 rank 3
2023-03-01 12:32:50,598 DEBUG TRAIN Batch 55/7500 loss 4.285977 loss_att 6.191591 loss_ctc 5.963634 loss_rnnt 3.533766 hw_loss 0.276377 lr 0.00028662 rank 5
2023-03-01 12:32:50,600 DEBUG TRAIN Batch 55/7500 loss 5.440214 loss_att 6.479471 loss_ctc 7.750324 loss_rnnt 4.786789 hw_loss 0.257922 lr 0.00028662 rank 6
2023-03-01 12:32:50,604 DEBUG TRAIN Batch 55/7500 loss 3.098260 loss_att 6.485821 loss_ctc 3.780105 loss_rnnt 2.214966 hw_loss 0.215380 lr 0.00028662 rank 4
2023-03-01 12:32:50,641 DEBUG TRAIN Batch 55/7500 loss 8.515720 loss_att 9.917181 loss_ctc 13.213461 loss_rnnt 7.470468 hw_loss 0.259865 lr 0.00028663 rank 2
2023-03-01 12:33:29,988 DEBUG TRAIN Batch 55/7600 loss 5.506733 loss_att 7.687848 loss_ctc 9.447589 loss_rnnt 4.438745 hw_loss 0.199347 lr 0.00028661 rank 1
2023-03-01 12:33:29,994 DEBUG TRAIN Batch 55/7600 loss 9.224281 loss_att 10.578550 loss_ctc 14.371351 loss_rnnt 8.076072 hw_loss 0.358274 lr 0.00028661 rank 4
2023-03-01 12:33:29,998 DEBUG TRAIN Batch 55/7600 loss 7.254656 loss_att 9.717174 loss_ctc 15.772988 loss_rnnt 5.507208 hw_loss 0.223439 lr 0.00028661 rank 6
2023-03-01 12:33:29,999 DEBUG TRAIN Batch 55/7600 loss 11.470123 loss_att 14.462362 loss_ctc 21.841682 loss_rnnt 9.391710 hw_loss 0.182044 lr 0.00028662 rank 0
2023-03-01 12:33:30,009 DEBUG TRAIN Batch 55/7600 loss 1.385636 loss_att 4.342821 loss_ctc 3.330487 loss_rnnt 0.425626 hw_loss 0.204862 lr 0.00028661 rank 7
2023-03-01 12:33:30,010 DEBUG TRAIN Batch 55/7600 loss 1.556020 loss_att 5.716045 loss_ctc 3.584589 loss_rnnt 0.453359 hw_loss 0.000336 lr 0.00028660 rank 3
2023-03-01 12:33:30,013 DEBUG TRAIN Batch 55/7600 loss 11.422480 loss_att 14.155905 loss_ctc 14.882956 loss_rnnt 10.260335 hw_loss 0.288869 lr 0.00028661 rank 2
2023-03-01 12:33:30,060 DEBUG TRAIN Batch 55/7600 loss 10.702257 loss_att 13.639237 loss_ctc 20.712555 loss_rnnt 8.670720 hw_loss 0.205187 lr 0.00028661 rank 5
2023-03-01 12:34:09,386 DEBUG TRAIN Batch 55/7700 loss 3.040101 loss_att 5.564015 loss_ctc 6.021545 loss_rnnt 2.043192 hw_loss 0.177374 lr 0.00028659 rank 3
2023-03-01 12:34:09,391 DEBUG TRAIN Batch 55/7700 loss 11.021987 loss_att 13.400400 loss_ctc 16.822906 loss_rnnt 9.636383 hw_loss 0.255871 lr 0.00028661 rank 0
2023-03-01 12:34:09,394 DEBUG TRAIN Batch 55/7700 loss 6.609230 loss_att 7.838061 loss_ctc 7.936388 loss_rnnt 6.030460 hw_loss 0.292592 lr 0.00028660 rank 6
2023-03-01 12:34:09,396 DEBUG TRAIN Batch 55/7700 loss 9.628493 loss_att 14.570040 loss_ctc 24.508657 loss_rnnt 6.610612 hw_loss 0.085406 lr 0.00028660 rank 2
2023-03-01 12:34:09,397 DEBUG TRAIN Batch 55/7700 loss 2.674292 loss_att 4.971276 loss_ctc 5.915140 loss_rnnt 1.707679 hw_loss 0.140817 lr 0.00028660 rank 5
2023-03-01 12:34:09,397 DEBUG TRAIN Batch 55/7700 loss 3.434410 loss_att 6.302829 loss_ctc 6.462994 loss_rnnt 2.359585 hw_loss 0.182494 lr 0.00028659 rank 7
2023-03-01 12:34:09,403 DEBUG TRAIN Batch 55/7700 loss 2.674164 loss_att 5.390901 loss_ctc 5.045404 loss_rnnt 1.629340 hw_loss 0.347457 lr 0.00028660 rank 4
2023-03-01 12:34:09,421 DEBUG TRAIN Batch 55/7700 loss 4.593806 loss_att 6.730209 loss_ctc 6.170324 loss_rnnt 3.901302 hw_loss 0.103163 lr 0.00028660 rank 1
2023-03-01 12:35:10,069 DEBUG TRAIN Batch 55/7800 loss 5.713882 loss_att 8.490587 loss_ctc 13.584370 loss_rnnt 4.006709 hw_loss 0.192063 lr 0.00028659 rank 5
2023-03-01 12:35:10,074 DEBUG TRAIN Batch 55/7800 loss 2.732667 loss_att 6.169685 loss_ctc 6.458632 loss_rnnt 1.475489 hw_loss 0.136837 lr 0.00028659 rank 2
2023-03-01 12:35:10,078 DEBUG TRAIN Batch 55/7800 loss 6.780225 loss_att 11.646751 loss_ctc 13.878967 loss_rnnt 4.750385 hw_loss 0.206316 lr 0.00028658 rank 7
2023-03-01 12:35:10,080 DEBUG TRAIN Batch 55/7800 loss 6.034585 loss_att 7.988755 loss_ctc 7.321248 loss_rnnt 5.392878 hw_loss 0.148721 lr 0.00028659 rank 6
2023-03-01 12:35:10,083 DEBUG TRAIN Batch 55/7800 loss 10.076240 loss_att 11.647566 loss_ctc 18.894884 loss_rnnt 8.512413 hw_loss 0.138266 lr 0.00028658 rank 3
2023-03-01 12:35:10,083 DEBUG TRAIN Batch 55/7800 loss 3.985363 loss_att 6.718782 loss_ctc 6.306395 loss_rnnt 3.029007 hw_loss 0.187878 lr 0.00028658 rank 1
2023-03-01 12:35:10,098 DEBUG TRAIN Batch 55/7800 loss 6.552438 loss_att 6.944992 loss_ctc 9.538774 loss_rnnt 5.911906 hw_loss 0.307205 lr 0.00028659 rank 0
2023-03-01 12:35:10,111 DEBUG TRAIN Batch 55/7800 loss 8.890022 loss_att 12.798361 loss_ctc 21.229652 loss_rnnt 6.365000 hw_loss 0.183883 lr 0.00028659 rank 4
2023-03-01 12:35:52,960 DEBUG TRAIN Batch 55/7900 loss 5.346397 loss_att 8.697947 loss_ctc 11.655451 loss_rnnt 3.722272 hw_loss 0.211139 lr 0.00028658 rank 2
2023-03-01 12:35:52,960 DEBUG TRAIN Batch 55/7900 loss 6.015011 loss_att 8.478403 loss_ctc 7.973114 loss_rnnt 5.049003 hw_loss 0.397968 lr 0.00028658 rank 0
2023-03-01 12:35:52,962 DEBUG TRAIN Batch 55/7900 loss 3.700717 loss_att 6.495655 loss_ctc 10.666561 loss_rnnt 2.074003 hw_loss 0.260527 lr 0.00028658 rank 6
2023-03-01 12:35:52,962 DEBUG TRAIN Batch 55/7900 loss 10.361976 loss_att 11.489476 loss_ctc 16.645927 loss_rnnt 9.167042 hw_loss 0.246702 lr 0.00028657 rank 7
2023-03-01 12:35:52,964 DEBUG TRAIN Batch 55/7900 loss 6.499764 loss_att 9.271652 loss_ctc 12.901907 loss_rnnt 5.018752 hw_loss 0.136905 lr 0.00028657 rank 5
2023-03-01 12:35:52,965 DEBUG TRAIN Batch 55/7900 loss 4.010354 loss_att 6.583838 loss_ctc 7.165730 loss_rnnt 3.000102 hw_loss 0.140322 lr 0.00028657 rank 1
2023-03-01 12:35:52,966 DEBUG TRAIN Batch 55/7900 loss 2.264311 loss_att 5.208241 loss_ctc 3.553961 loss_rnnt 1.333298 hw_loss 0.319262 lr 0.00028657 rank 4
2023-03-01 12:35:52,983 DEBUG TRAIN Batch 55/7900 loss 7.105352 loss_att 9.152810 loss_ctc 9.710297 loss_rnnt 6.240141 hw_loss 0.203237 lr 0.00028657 rank 3
2023-03-01 12:36:31,755 DEBUG TRAIN Batch 55/8000 loss 2.447717 loss_att 3.856821 loss_ctc 2.487466 loss_rnnt 2.031719 hw_loss 0.241647 lr 0.00028656 rank 7
2023-03-01 12:36:31,762 DEBUG TRAIN Batch 55/8000 loss 9.518826 loss_att 15.117073 loss_ctc 19.128023 loss_rnnt 7.005541 hw_loss 0.210768 lr 0.00028657 rank 2
2023-03-01 12:36:31,768 DEBUG TRAIN Batch 55/8000 loss 2.471842 loss_att 4.192954 loss_ctc 3.082849 loss_rnnt 1.945163 hw_loss 0.189353 lr 0.00028656 rank 5
2023-03-01 12:36:31,771 DEBUG TRAIN Batch 55/8000 loss 6.427387 loss_att 10.192504 loss_ctc 13.574992 loss_rnnt 4.620682 hw_loss 0.188752 lr 0.00028657 rank 0
2023-03-01 12:36:31,772 DEBUG TRAIN Batch 55/8000 loss 4.184398 loss_att 7.532017 loss_ctc 9.192345 loss_rnnt 2.793908 hw_loss 0.099826 lr 0.00028656 rank 6
2023-03-01 12:36:31,780 DEBUG TRAIN Batch 55/8000 loss 7.218947 loss_att 8.828270 loss_ctc 10.849251 loss_rnnt 6.412772 hw_loss 0.000506 lr 0.00028656 rank 4
2023-03-01 12:36:31,781 DEBUG TRAIN Batch 55/8000 loss 7.089486 loss_att 7.815687 loss_ctc 8.421494 loss_rnnt 6.700283 hw_loss 0.124428 lr 0.00028656 rank 1
2023-03-01 12:36:31,823 DEBUG TRAIN Batch 55/8000 loss 11.970235 loss_att 14.363791 loss_ctc 23.554491 loss_rnnt 9.858988 hw_loss 0.164941 lr 0.00028656 rank 3
2023-03-01 12:37:11,150 DEBUG TRAIN Batch 55/8100 loss 14.061911 loss_att 22.026897 loss_ctc 27.626877 loss_rnnt 10.497635 hw_loss 0.304904 lr 0.00028655 rank 4
2023-03-01 12:37:11,157 DEBUG TRAIN Batch 55/8100 loss 8.398721 loss_att 11.336535 loss_ctc 15.418762 loss_rnnt 6.764756 hw_loss 0.206993 lr 0.00028654 rank 3
2023-03-01 12:37:11,165 DEBUG TRAIN Batch 55/8100 loss 6.273329 loss_att 7.962481 loss_ctc 11.227368 loss_rnnt 5.202223 hw_loss 0.136381 lr 0.00028655 rank 7
2023-03-01 12:37:11,167 DEBUG TRAIN Batch 55/8100 loss 1.943227 loss_att 4.006760 loss_ctc 3.938374 loss_rnnt 1.164756 hw_loss 0.187021 lr 0.00028656 rank 0
2023-03-01 12:37:11,169 DEBUG TRAIN Batch 55/8100 loss 5.171178 loss_att 7.362664 loss_ctc 9.542114 loss_rnnt 4.034980 hw_loss 0.215830 lr 0.00028655 rank 1
2023-03-01 12:37:11,171 DEBUG TRAIN Batch 55/8100 loss 4.866060 loss_att 6.206849 loss_ctc 8.056827 loss_rnnt 4.109472 hw_loss 0.118116 lr 0.00028655 rank 2
2023-03-01 12:37:11,170 DEBUG TRAIN Batch 55/8100 loss 4.671788 loss_att 6.036422 loss_ctc 8.056734 loss_rnnt 3.908281 hw_loss 0.073602 lr 0.00028655 rank 5
2023-03-01 12:37:11,172 DEBUG TRAIN Batch 55/8100 loss 4.897477 loss_att 9.011929 loss_ctc 9.358464 loss_rnnt 3.395899 hw_loss 0.157292 lr 0.00028655 rank 6
2023-03-01 12:37:51,429 DEBUG TRAIN Batch 55/8200 loss 2.713760 loss_att 6.181270 loss_ctc 5.302696 loss_rnnt 1.527683 hw_loss 0.276344 lr 0.00028654 rank 1
2023-03-01 12:37:51,429 DEBUG TRAIN Batch 55/8200 loss 7.041240 loss_att 9.730877 loss_ctc 12.128371 loss_rnnt 5.780581 hw_loss 0.083339 lr 0.00028654 rank 5
2023-03-01 12:37:51,444 DEBUG TRAIN Batch 55/8200 loss 10.996055 loss_att 12.242168 loss_ctc 21.132576 loss_rnnt 9.253849 hw_loss 0.265212 lr 0.00028655 rank 0
2023-03-01 12:37:51,448 DEBUG TRAIN Batch 55/8200 loss 7.610645 loss_att 8.359509 loss_ctc 11.594614 loss_rnnt 6.750135 hw_loss 0.336639 lr 0.00028653 rank 3
2023-03-01 12:37:51,449 DEBUG TRAIN Batch 55/8200 loss 2.137016 loss_att 5.172486 loss_ctc 5.892742 loss_rnnt 0.887948 hw_loss 0.264771 lr 0.00028654 rank 7
2023-03-01 12:37:51,450 DEBUG TRAIN Batch 55/8200 loss 6.452147 loss_att 6.653579 loss_ctc 9.927632 loss_rnnt 5.793880 hw_loss 0.289843 lr 0.00028654 rank 2
2023-03-01 12:37:51,481 DEBUG TRAIN Batch 55/8200 loss 3.848308 loss_att 5.591639 loss_ctc 5.164870 loss_rnnt 3.272677 hw_loss 0.096420 lr 0.00028654 rank 6
2023-03-01 12:37:51,491 DEBUG TRAIN Batch 55/8200 loss 10.575028 loss_att 13.163654 loss_ctc 20.854788 loss_rnnt 8.530993 hw_loss 0.291891 lr 0.00028654 rank 4
2023-03-01 12:38:29,890 DEBUG TRAIN Batch 55/8300 loss 7.955987 loss_att 10.047111 loss_ctc 8.187429 loss_rnnt 7.390118 hw_loss 0.218973 lr 0.00028653 rank 4
2023-03-01 12:38:29,892 DEBUG TRAIN Batch 55/8300 loss 8.218637 loss_att 12.874093 loss_ctc 16.641783 loss_rnnt 6.006046 hw_loss 0.297026 lr 0.00028654 rank 0
2023-03-01 12:38:29,897 DEBUG TRAIN Batch 55/8300 loss 2.707597 loss_att 6.068316 loss_ctc 4.682836 loss_rnnt 1.651123 hw_loss 0.226809 lr 0.00028653 rank 2
2023-03-01 12:38:29,900 DEBUG TRAIN Batch 55/8300 loss 3.833298 loss_att 6.899377 loss_ctc 9.690757 loss_rnnt 2.305715 hw_loss 0.250075 lr 0.00028653 rank 6
2023-03-01 12:38:29,904 DEBUG TRAIN Batch 55/8300 loss 9.475838 loss_att 14.553734 loss_ctc 18.173588 loss_rnnt 7.108167 hw_loss 0.360731 lr 0.00028652 rank 7
2023-03-01 12:38:29,910 DEBUG TRAIN Batch 55/8300 loss 8.630370 loss_att 10.408743 loss_ctc 14.687247 loss_rnnt 7.399473 hw_loss 0.126825 lr 0.00028653 rank 5
2023-03-01 12:38:29,912 DEBUG TRAIN Batch 55/8300 loss 3.048279 loss_att 8.267245 loss_ctc 4.535915 loss_rnnt 1.638435 hw_loss 0.314435 lr 0.00028652 rank 3
2023-03-01 12:38:29,957 DEBUG TRAIN Batch 55/8300 loss 5.315768 loss_att 7.157965 loss_ctc 10.002997 loss_rnnt 4.210274 hw_loss 0.210169 lr 0.00028653 rank 1
2023-03-01 12:39:00,271 DEBUG CV Batch 55/0 loss 0.624989 loss_att 0.799196 loss_ctc 1.041265 loss_rnnt 0.332329 hw_loss 0.379340 history loss 0.601841 rank 0
2023-03-01 12:39:00,317 DEBUG CV Batch 55/0 loss 0.624989 loss_att 0.799196 loss_ctc 1.041265 loss_rnnt 0.332329 hw_loss 0.379340 history loss 0.601841 rank 5
2023-03-01 12:39:00,391 DEBUG CV Batch 55/0 loss 0.624989 loss_att 0.799196 loss_ctc 1.041265 loss_rnnt 0.332329 hw_loss 0.379340 history loss 0.601841 rank 2
2023-03-01 12:39:00,408 DEBUG CV Batch 55/0 loss 0.624989 loss_att 0.799196 loss_ctc 1.041265 loss_rnnt 0.332329 hw_loss 0.379340 history loss 0.601841 rank 1
2023-03-01 12:39:00,423 DEBUG CV Batch 55/0 loss 0.624989 loss_att 0.799196 loss_ctc 1.041265 loss_rnnt 0.332329 hw_loss 0.379340 history loss 0.601841 rank 4
2023-03-01 12:39:00,582 DEBUG CV Batch 55/0 loss 0.624989 loss_att 0.799196 loss_ctc 1.041265 loss_rnnt 0.332329 hw_loss 0.379340 history loss 0.601841 rank 3
2023-03-01 12:39:00,605 DEBUG CV Batch 55/0 loss 0.624989 loss_att 0.799196 loss_ctc 1.041265 loss_rnnt 0.332329 hw_loss 0.379340 history loss 0.601841 rank 6
2023-03-01 12:39:00,681 DEBUG CV Batch 55/0 loss 0.624989 loss_att 0.799196 loss_ctc 1.041265 loss_rnnt 0.332329 hw_loss 0.379340 history loss 0.601841 rank 7
2023-03-01 12:39:11,627 DEBUG CV Batch 55/100 loss 3.302167 loss_att 4.351180 loss_ctc 7.978086 loss_rnnt 2.371728 hw_loss 0.182212 history loss 2.990959 rank 1
2023-03-01 12:39:11,753 DEBUG CV Batch 55/100 loss 3.302167 loss_att 4.351180 loss_ctc 7.978086 loss_rnnt 2.371728 hw_loss 0.182212 history loss 2.990959 rank 5
2023-03-01 12:39:11,790 DEBUG CV Batch 55/100 loss 3.302167 loss_att 4.351180 loss_ctc 7.978086 loss_rnnt 2.371728 hw_loss 0.182212 history loss 2.990959 rank 2
2023-03-01 12:39:11,806 DEBUG CV Batch 55/100 loss 3.302167 loss_att 4.351180 loss_ctc 7.978086 loss_rnnt 2.371728 hw_loss 0.182212 history loss 2.990959 rank 4
2023-03-01 12:39:11,994 DEBUG CV Batch 55/100 loss 3.302167 loss_att 4.351180 loss_ctc 7.978086 loss_rnnt 2.371728 hw_loss 0.182212 history loss 2.990959 rank 6
2023-03-01 12:39:12,072 DEBUG CV Batch 55/100 loss 3.302167 loss_att 4.351180 loss_ctc 7.978086 loss_rnnt 2.371728 hw_loss 0.182212 history loss 2.990959 rank 0
2023-03-01 12:39:12,518 DEBUG CV Batch 55/100 loss 3.302167 loss_att 4.351180 loss_ctc 7.978086 loss_rnnt 2.371728 hw_loss 0.182212 history loss 2.990959 rank 7
2023-03-01 12:39:12,796 DEBUG CV Batch 55/100 loss 3.302167 loss_att 4.351180 loss_ctc 7.978086 loss_rnnt 2.371728 hw_loss 0.182212 history loss 2.990959 rank 3
2023-03-01 12:39:25,110 DEBUG CV Batch 55/200 loss 4.012239 loss_att 7.321059 loss_ctc 5.334106 loss_rnnt 3.031866 hw_loss 0.266926 history loss 3.558465 rank 1
2023-03-01 12:39:25,296 DEBUG CV Batch 55/200 loss 4.012239 loss_att 7.321059 loss_ctc 5.334106 loss_rnnt 3.031866 hw_loss 0.266926 history loss 3.558465 rank 5
2023-03-01 12:39:25,312 DEBUG CV Batch 55/200 loss 4.012239 loss_att 7.321059 loss_ctc 5.334106 loss_rnnt 3.031866 hw_loss 0.266926 history loss 3.558465 rank 4
2023-03-01 12:39:25,588 DEBUG CV Batch 55/200 loss 4.012239 loss_att 7.321059 loss_ctc 5.334106 loss_rnnt 3.031866 hw_loss 0.266926 history loss 3.558465 rank 2
2023-03-01 12:39:25,635 DEBUG CV Batch 55/200 loss 4.012239 loss_att 7.321059 loss_ctc 5.334106 loss_rnnt 3.031866 hw_loss 0.266926 history loss 3.558465 rank 6
2023-03-01 12:39:25,978 DEBUG CV Batch 55/200 loss 4.012239 loss_att 7.321059 loss_ctc 5.334106 loss_rnnt 3.031866 hw_loss 0.266926 history loss 3.558465 rank 0
2023-03-01 12:39:26,379 DEBUG CV Batch 55/200 loss 4.012239 loss_att 7.321059 loss_ctc 5.334106 loss_rnnt 3.031866 hw_loss 0.266926 history loss 3.558465 rank 7
2023-03-01 12:39:26,930 DEBUG CV Batch 55/200 loss 4.012239 loss_att 7.321059 loss_ctc 5.334106 loss_rnnt 3.031866 hw_loss 0.266926 history loss 3.558465 rank 3
2023-03-01 12:39:37,533 DEBUG CV Batch 55/300 loss 3.940855 loss_att 4.408121 loss_ctc 7.335951 loss_rnnt 3.244257 hw_loss 0.282122 history loss 3.678365 rank 5
2023-03-01 12:39:37,539 DEBUG CV Batch 55/300 loss 3.940855 loss_att 4.408121 loss_ctc 7.335951 loss_rnnt 3.244257 hw_loss 0.282122 history loss 3.678365 rank 1
2023-03-01 12:39:37,800 DEBUG CV Batch 55/300 loss 3.940855 loss_att 4.408121 loss_ctc 7.335951 loss_rnnt 3.244257 hw_loss 0.282122 history loss 3.678365 rank 4
2023-03-01 12:39:37,882 DEBUG CV Batch 55/300 loss 3.940855 loss_att 4.408121 loss_ctc 7.335951 loss_rnnt 3.244257 hw_loss 0.282122 history loss 3.678365 rank 2
2023-03-01 12:39:38,305 DEBUG CV Batch 55/300 loss 3.940855 loss_att 4.408121 loss_ctc 7.335951 loss_rnnt 3.244257 hw_loss 0.282122 history loss 3.678365 rank 6
2023-03-01 12:39:38,619 DEBUG CV Batch 55/300 loss 3.940855 loss_att 4.408121 loss_ctc 7.335951 loss_rnnt 3.244257 hw_loss 0.282122 history loss 3.678365 rank 0
2023-03-01 12:39:38,756 DEBUG CV Batch 55/300 loss 3.940855 loss_att 4.408121 loss_ctc 7.335951 loss_rnnt 3.244257 hw_loss 0.282122 history loss 3.678365 rank 7
2023-03-01 12:39:40,095 DEBUG CV Batch 55/300 loss 3.940855 loss_att 4.408121 loss_ctc 7.335951 loss_rnnt 3.244257 hw_loss 0.282122 history loss 3.678365 rank 3
2023-03-01 12:39:49,661 DEBUG CV Batch 55/400 loss 17.930550 loss_att 77.405716 loss_ctc 6.182640 loss_rnnt 7.437725 hw_loss 0.307837 history loss 4.481961 rank 1
2023-03-01 12:39:49,757 DEBUG CV Batch 55/400 loss 17.930550 loss_att 77.405716 loss_ctc 6.182640 loss_rnnt 7.437725 hw_loss 0.307837 history loss 4.481961 rank 5
2023-03-01 12:39:49,895 DEBUG CV Batch 55/400 loss 17.930550 loss_att 77.405716 loss_ctc 6.182640 loss_rnnt 7.437725 hw_loss 0.307837 history loss 4.481961 rank 4
2023-03-01 12:39:50,267 DEBUG CV Batch 55/400 loss 17.930550 loss_att 77.405716 loss_ctc 6.182640 loss_rnnt 7.437725 hw_loss 0.307837 history loss 4.481961 rank 2
2023-03-01 12:39:51,001 DEBUG CV Batch 55/400 loss 17.930550 loss_att 77.405716 loss_ctc 6.182640 loss_rnnt 7.437725 hw_loss 0.307837 history loss 4.481961 rank 6
2023-03-01 12:39:51,297 DEBUG CV Batch 55/400 loss 17.930550 loss_att 77.405716 loss_ctc 6.182640 loss_rnnt 7.437725 hw_loss 0.307837 history loss 4.481961 rank 0
2023-03-01 12:39:51,327 DEBUG CV Batch 55/400 loss 17.930550 loss_att 77.405716 loss_ctc 6.182640 loss_rnnt 7.437725 hw_loss 0.307837 history loss 4.481961 rank 7
2023-03-01 12:39:53,006 DEBUG CV Batch 55/400 loss 17.930550 loss_att 77.405716 loss_ctc 6.182640 loss_rnnt 7.437725 hw_loss 0.307837 history loss 4.481961 rank 3
2023-03-01 12:40:00,627 DEBUG CV Batch 55/500 loss 3.790167 loss_att 4.226593 loss_ctc 5.817739 loss_rnnt 3.324537 hw_loss 0.202502 history loss 5.084004 rank 5
2023-03-01 12:40:00,654 DEBUG CV Batch 55/500 loss 3.790167 loss_att 4.226593 loss_ctc 5.817739 loss_rnnt 3.324537 hw_loss 0.202502 history loss 5.084004 rank 1
2023-03-01 12:40:00,987 DEBUG CV Batch 55/500 loss 3.790167 loss_att 4.226593 loss_ctc 5.817739 loss_rnnt 3.324537 hw_loss 0.202502 history loss 5.084004 rank 4
2023-03-01 12:40:01,177 DEBUG CV Batch 55/500 loss 3.790167 loss_att 4.226593 loss_ctc 5.817739 loss_rnnt 3.324537 hw_loss 0.202502 history loss 5.084004 rank 2
2023-03-01 12:40:02,051 DEBUG CV Batch 55/500 loss 3.790167 loss_att 4.226593 loss_ctc 5.817739 loss_rnnt 3.324537 hw_loss 0.202502 history loss 5.084004 rank 6
2023-03-01 12:40:02,394 DEBUG CV Batch 55/500 loss 3.790167 loss_att 4.226593 loss_ctc 5.817739 loss_rnnt 3.324537 hw_loss 0.202502 history loss 5.084004 rank 7
2023-03-01 12:40:02,467 DEBUG CV Batch 55/500 loss 3.790167 loss_att 4.226593 loss_ctc 5.817739 loss_rnnt 3.324537 hw_loss 0.202502 history loss 5.084004 rank 0
2023-03-01 12:40:04,880 DEBUG CV Batch 55/500 loss 3.790167 loss_att 4.226593 loss_ctc 5.817739 loss_rnnt 3.324537 hw_loss 0.202502 history loss 5.084004 rank 3
2023-03-01 12:40:13,032 DEBUG CV Batch 55/600 loss 7.976627 loss_att 7.380193 loss_ctc 11.089035 loss_rnnt 7.494711 hw_loss 0.349152 history loss 5.943793 rank 5
2023-03-01 12:40:13,044 DEBUG CV Batch 55/600 loss 7.976627 loss_att 7.380193 loss_ctc 11.089035 loss_rnnt 7.494711 hw_loss 0.349152 history loss 5.943793 rank 1
2023-03-01 12:40:13,223 DEBUG CV Batch 55/600 loss 7.976627 loss_att 7.380193 loss_ctc 11.089035 loss_rnnt 7.494711 hw_loss 0.349152 history loss 5.943793 rank 4
2023-03-01 12:40:13,624 DEBUG CV Batch 55/600 loss 7.976627 loss_att 7.380193 loss_ctc 11.089035 loss_rnnt 7.494711 hw_loss 0.349152 history loss 5.943793 rank 2
2023-03-01 12:40:14,701 DEBUG CV Batch 55/600 loss 7.976627 loss_att 7.380193 loss_ctc 11.089035 loss_rnnt 7.494711 hw_loss 0.349152 history loss 5.943793 rank 6
2023-03-01 12:40:14,986 DEBUG CV Batch 55/600 loss 7.976627 loss_att 7.380193 loss_ctc 11.089035 loss_rnnt 7.494711 hw_loss 0.349152 history loss 5.943793 rank 7
2023-03-01 12:40:15,057 DEBUG CV Batch 55/600 loss 7.976627 loss_att 7.380193 loss_ctc 11.089035 loss_rnnt 7.494711 hw_loss 0.349152 history loss 5.943793 rank 0
2023-03-01 12:40:17,731 DEBUG CV Batch 55/600 loss 7.976627 loss_att 7.380193 loss_ctc 11.089035 loss_rnnt 7.494711 hw_loss 0.349152 history loss 5.943793 rank 3
2023-03-01 12:40:24,469 DEBUG CV Batch 55/700 loss 10.652137 loss_att 21.984253 loss_ctc 16.220840 loss_rnnt 7.536182 hw_loss 0.200693 history loss 6.496640 rank 1
2023-03-01 12:40:24,514 DEBUG CV Batch 55/700 loss 10.652137 loss_att 21.984253 loss_ctc 16.220840 loss_rnnt 7.536182 hw_loss 0.200693 history loss 6.496640 rank 5
2023-03-01 12:40:24,667 DEBUG CV Batch 55/700 loss 10.652137 loss_att 21.984253 loss_ctc 16.220840 loss_rnnt 7.536182 hw_loss 0.200693 history loss 6.496640 rank 4
2023-03-01 12:40:25,331 DEBUG CV Batch 55/700 loss 10.652137 loss_att 21.984253 loss_ctc 16.220840 loss_rnnt 7.536182 hw_loss 0.200693 history loss 6.496640 rank 2
2023-03-01 12:40:26,342 DEBUG CV Batch 55/700 loss 10.652137 loss_att 21.984253 loss_ctc 16.220840 loss_rnnt 7.536182 hw_loss 0.200693 history loss 6.496640 rank 6
2023-03-01 12:40:26,875 DEBUG CV Batch 55/700 loss 10.652137 loss_att 21.984253 loss_ctc 16.220840 loss_rnnt 7.536182 hw_loss 0.200693 history loss 6.496640 rank 7
2023-03-01 12:40:26,977 DEBUG CV Batch 55/700 loss 10.652137 loss_att 21.984253 loss_ctc 16.220840 loss_rnnt 7.536182 hw_loss 0.200693 history loss 6.496640 rank 0
2023-03-01 12:40:30,111 DEBUG CV Batch 55/700 loss 10.652137 loss_att 21.984253 loss_ctc 16.220840 loss_rnnt 7.536182 hw_loss 0.200693 history loss 6.496640 rank 3
2023-03-01 12:40:35,998 DEBUG CV Batch 55/800 loss 6.007804 loss_att 7.042134 loss_ctc 13.231327 loss_rnnt 4.734095 hw_loss 0.194449 history loss 6.021957 rank 1
2023-03-01 12:40:36,168 DEBUG CV Batch 55/800 loss 6.007804 loss_att 7.042134 loss_ctc 13.231327 loss_rnnt 4.734095 hw_loss 0.194449 history loss 6.021957 rank 5
2023-03-01 12:40:36,252 DEBUG CV Batch 55/800 loss 6.007804 loss_att 7.042134 loss_ctc 13.231327 loss_rnnt 4.734095 hw_loss 0.194449 history loss 6.021957 rank 4
2023-03-01 12:40:36,888 DEBUG CV Batch 55/800 loss 6.007804 loss_att 7.042134 loss_ctc 13.231327 loss_rnnt 4.734095 hw_loss 0.194449 history loss 6.021957 rank 2
2023-03-01 12:40:38,012 DEBUG CV Batch 55/800 loss 6.007804 loss_att 7.042134 loss_ctc 13.231327 loss_rnnt 4.734095 hw_loss 0.194449 history loss 6.021957 rank 6
2023-03-01 12:40:38,611 DEBUG CV Batch 55/800 loss 6.007804 loss_att 7.042134 loss_ctc 13.231327 loss_rnnt 4.734095 hw_loss 0.194449 history loss 6.021957 rank 7
2023-03-01 12:40:38,907 DEBUG CV Batch 55/800 loss 6.007804 loss_att 7.042134 loss_ctc 13.231327 loss_rnnt 4.734095 hw_loss 0.194449 history loss 6.021957 rank 0
2023-03-01 12:40:42,325 DEBUG CV Batch 55/800 loss 6.007804 loss_att 7.042134 loss_ctc 13.231327 loss_rnnt 4.734095 hw_loss 0.194449 history loss 6.021957 rank 3
2023-03-01 12:40:49,307 DEBUG CV Batch 55/900 loss 8.386544 loss_att 9.596418 loss_ctc 16.892477 loss_rnnt 6.940744 hw_loss 0.130690 history loss 5.858025 rank 1
2023-03-01 12:40:49,863 DEBUG CV Batch 55/900 loss 8.386544 loss_att 9.596418 loss_ctc 16.892477 loss_rnnt 6.940744 hw_loss 0.130690 history loss 5.858025 rank 4
2023-03-01 12:40:50,092 DEBUG CV Batch 55/900 loss 8.386544 loss_att 9.596418 loss_ctc 16.892477 loss_rnnt 6.940744 hw_loss 0.130690 history loss 5.858025 rank 5
2023-03-01 12:40:50,544 DEBUG CV Batch 55/900 loss 8.386544 loss_att 9.596418 loss_ctc 16.892477 loss_rnnt 6.940744 hw_loss 0.130690 history loss 5.858025 rank 2
2023-03-01 12:40:51,786 DEBUG CV Batch 55/900 loss 8.386544 loss_att 9.596418 loss_ctc 16.892477 loss_rnnt 6.940744 hw_loss 0.130690 history loss 5.858025 rank 6
2023-03-01 12:40:52,316 DEBUG CV Batch 55/900 loss 8.386544 loss_att 9.596418 loss_ctc 16.892477 loss_rnnt 6.940744 hw_loss 0.130690 history loss 5.858025 rank 7
2023-03-01 12:40:52,663 DEBUG CV Batch 55/900 loss 8.386544 loss_att 9.596418 loss_ctc 16.892477 loss_rnnt 6.940744 hw_loss 0.130690 history loss 5.858025 rank 0
2023-03-01 12:40:56,102 DEBUG CV Batch 55/900 loss 8.386544 loss_att 9.596418 loss_ctc 16.892477 loss_rnnt 6.940744 hw_loss 0.130690 history loss 5.858025 rank 3
2023-03-01 12:41:01,670 DEBUG CV Batch 55/1000 loss 4.049288 loss_att 4.100132 loss_ctc 4.661929 loss_rnnt 3.806515 hw_loss 0.282972 history loss 5.661584 rank 1
2023-03-01 12:41:02,315 DEBUG CV Batch 55/1000 loss 4.049288 loss_att 4.100132 loss_ctc 4.661929 loss_rnnt 3.806515 hw_loss 0.282972 history loss 5.661584 rank 4
2023-03-01 12:41:02,824 DEBUG CV Batch 55/1000 loss 4.049288 loss_att 4.100132 loss_ctc 4.661929 loss_rnnt 3.806515 hw_loss 0.282972 history loss 5.661584 rank 5
2023-03-01 12:41:03,136 DEBUG CV Batch 55/1000 loss 4.049288 loss_att 4.100132 loss_ctc 4.661929 loss_rnnt 3.806515 hw_loss 0.282972 history loss 5.661584 rank 2
2023-03-01 12:41:04,486 DEBUG CV Batch 55/1000 loss 4.049288 loss_att 4.100132 loss_ctc 4.661929 loss_rnnt 3.806515 hw_loss 0.282972 history loss 5.661584 rank 6
2023-03-01 12:41:05,153 DEBUG CV Batch 55/1000 loss 4.049288 loss_att 4.100132 loss_ctc 4.661929 loss_rnnt 3.806515 hw_loss 0.282972 history loss 5.661584 rank 7
2023-03-01 12:41:05,510 DEBUG CV Batch 55/1000 loss 4.049288 loss_att 4.100132 loss_ctc 4.661929 loss_rnnt 3.806515 hw_loss 0.282972 history loss 5.661584 rank 0
2023-03-01 12:41:08,937 DEBUG CV Batch 55/1000 loss 4.049288 loss_att 4.100132 loss_ctc 4.661929 loss_rnnt 3.806515 hw_loss 0.282972 history loss 5.661584 rank 3
2023-03-01 12:41:13,618 DEBUG CV Batch 55/1100 loss 4.963482 loss_att 4.878298 loss_ctc 8.584531 loss_rnnt 4.282907 hw_loss 0.402761 history loss 5.629343 rank 1
2023-03-01 12:41:14,389 DEBUG CV Batch 55/1100 loss 4.963482 loss_att 4.878298 loss_ctc 8.584531 loss_rnnt 4.282907 hw_loss 0.402761 history loss 5.629343 rank 4
2023-03-01 12:41:15,298 DEBUG CV Batch 55/1100 loss 4.963482 loss_att 4.878298 loss_ctc 8.584531 loss_rnnt 4.282907 hw_loss 0.402761 history loss 5.629343 rank 2
2023-03-01 12:41:15,433 DEBUG CV Batch 55/1100 loss 4.963482 loss_att 4.878298 loss_ctc 8.584531 loss_rnnt 4.282907 hw_loss 0.402761 history loss 5.629343 rank 5
2023-03-01 12:41:16,845 DEBUG CV Batch 55/1100 loss 4.963482 loss_att 4.878298 loss_ctc 8.584531 loss_rnnt 4.282907 hw_loss 0.402761 history loss 5.629343 rank 6
2023-03-01 12:41:17,432 DEBUG CV Batch 55/1100 loss 4.963482 loss_att 4.878298 loss_ctc 8.584531 loss_rnnt 4.282907 hw_loss 0.402761 history loss 5.629343 rank 7
2023-03-01 12:41:17,994 DEBUG CV Batch 55/1100 loss 4.963482 loss_att 4.878298 loss_ctc 8.584531 loss_rnnt 4.282907 hw_loss 0.402761 history loss 5.629343 rank 0
2023-03-01 12:41:21,594 DEBUG CV Batch 55/1100 loss 4.963482 loss_att 4.878298 loss_ctc 8.584531 loss_rnnt 4.282907 hw_loss 0.402761 history loss 5.629343 rank 3
2023-03-01 12:41:24,391 DEBUG CV Batch 55/1200 loss 6.706281 loss_att 6.665165 loss_ctc 7.105447 loss_rnnt 6.546817 hw_loss 0.214621 history loss 5.892236 rank 1
2023-03-01 12:41:25,369 DEBUG CV Batch 55/1200 loss 6.706281 loss_att 6.665165 loss_ctc 7.105447 loss_rnnt 6.546817 hw_loss 0.214621 history loss 5.892236 rank 4
2023-03-01 12:41:26,217 DEBUG CV Batch 55/1200 loss 6.706281 loss_att 6.665165 loss_ctc 7.105447 loss_rnnt 6.546817 hw_loss 0.214621 history loss 5.892236 rank 2
2023-03-01 12:41:26,331 DEBUG CV Batch 55/1200 loss 6.706281 loss_att 6.665165 loss_ctc 7.105447 loss_rnnt 6.546817 hw_loss 0.214621 history loss 5.892236 rank 5
2023-03-01 12:41:27,980 DEBUG CV Batch 55/1200 loss 6.706281 loss_att 6.665165 loss_ctc 7.105447 loss_rnnt 6.546817 hw_loss 0.214621 history loss 5.892236 rank 6
2023-03-01 12:41:28,707 DEBUG CV Batch 55/1200 loss 6.706281 loss_att 6.665165 loss_ctc 7.105447 loss_rnnt 6.546817 hw_loss 0.214621 history loss 5.892236 rank 7
2023-03-01 12:41:29,410 DEBUG CV Batch 55/1200 loss 6.706281 loss_att 6.665165 loss_ctc 7.105447 loss_rnnt 6.546817 hw_loss 0.214621 history loss 5.892236 rank 0
2023-03-01 12:41:33,352 DEBUG CV Batch 55/1200 loss 6.706281 loss_att 6.665165 loss_ctc 7.105447 loss_rnnt 6.546817 hw_loss 0.214621 history loss 5.892236 rank 3
2023-03-01 12:41:36,453 DEBUG CV Batch 55/1300 loss 4.302078 loss_att 4.295886 loss_ctc 7.051581 loss_rnnt 3.743907 hw_loss 0.361516 history loss 6.189284 rank 1
2023-03-01 12:41:37,568 DEBUG CV Batch 55/1300 loss 4.302078 loss_att 4.295886 loss_ctc 7.051581 loss_rnnt 3.743907 hw_loss 0.361516 history loss 6.189284 rank 4
2023-03-01 12:41:38,446 DEBUG CV Batch 55/1300 loss 4.302078 loss_att 4.295886 loss_ctc 7.051581 loss_rnnt 3.743907 hw_loss 0.361516 history loss 6.189284 rank 2
2023-03-01 12:41:38,670 DEBUG CV Batch 55/1300 loss 4.302078 loss_att 4.295886 loss_ctc 7.051581 loss_rnnt 3.743907 hw_loss 0.361516 history loss 6.189284 rank 5
2023-03-01 12:41:40,394 DEBUG CV Batch 55/1300 loss 4.302078 loss_att 4.295886 loss_ctc 7.051581 loss_rnnt 3.743907 hw_loss 0.361516 history loss 6.189284 rank 6
2023-03-01 12:41:41,342 DEBUG CV Batch 55/1300 loss 4.302078 loss_att 4.295886 loss_ctc 7.051581 loss_rnnt 3.743907 hw_loss 0.361516 history loss 6.189284 rank 7
2023-03-01 12:41:42,137 DEBUG CV Batch 55/1300 loss 4.302078 loss_att 4.295886 loss_ctc 7.051581 loss_rnnt 3.743907 hw_loss 0.361516 history loss 6.189284 rank 0
2023-03-01 12:41:46,283 DEBUG CV Batch 55/1300 loss 4.302078 loss_att 4.295886 loss_ctc 7.051581 loss_rnnt 3.743907 hw_loss 0.361516 history loss 6.189284 rank 3
2023-03-01 12:41:47,746 DEBUG CV Batch 55/1400 loss 2.827319 loss_att 11.220089 loss_ctc 3.038108 loss_rnnt 1.037194 hw_loss 0.156500 history loss 6.470714 rank 1
2023-03-01 12:41:48,980 DEBUG CV Batch 55/1400 loss 2.827319 loss_att 11.220089 loss_ctc 3.038108 loss_rnnt 1.037194 hw_loss 0.156500 history loss 6.470714 rank 4
2023-03-01 12:41:50,090 DEBUG CV Batch 55/1400 loss 2.827319 loss_att 11.220089 loss_ctc 3.038108 loss_rnnt 1.037194 hw_loss 0.156500 history loss 6.470714 rank 2
2023-03-01 12:41:50,379 DEBUG CV Batch 55/1400 loss 2.827319 loss_att 11.220089 loss_ctc 3.038108 loss_rnnt 1.037194 hw_loss 0.156500 history loss 6.470714 rank 5
2023-03-01 12:41:51,975 DEBUG CV Batch 55/1400 loss 2.827319 loss_att 11.220089 loss_ctc 3.038108 loss_rnnt 1.037194 hw_loss 0.156500 history loss 6.470714 rank 6
2023-03-01 12:41:53,163 DEBUG CV Batch 55/1400 loss 2.827319 loss_att 11.220089 loss_ctc 3.038108 loss_rnnt 1.037194 hw_loss 0.156500 history loss 6.470714 rank 7
2023-03-01 12:41:53,942 DEBUG CV Batch 55/1400 loss 2.827319 loss_att 11.220089 loss_ctc 3.038108 loss_rnnt 1.037194 hw_loss 0.156500 history loss 6.470714 rank 0
2023-03-01 12:41:58,121 DEBUG CV Batch 55/1400 loss 2.827319 loss_att 11.220089 loss_ctc 3.038108 loss_rnnt 1.037194 hw_loss 0.156500 history loss 6.470714 rank 3
2023-03-01 12:41:59,683 DEBUG CV Batch 55/1500 loss 7.804955 loss_att 7.862070 loss_ctc 8.291893 loss_rnnt 7.626760 hw_loss 0.190966 history loss 6.336871 rank 1
2023-03-01 12:42:00,914 DEBUG CV Batch 55/1500 loss 7.804955 loss_att 7.862070 loss_ctc 8.291893 loss_rnnt 7.626760 hw_loss 0.190965 history loss 6.336871 rank 4
2023-03-01 12:42:01,899 DEBUG CV Batch 55/1500 loss 7.804955 loss_att 7.862070 loss_ctc 8.291893 loss_rnnt 7.626760 hw_loss 0.190965 history loss 6.336871 rank 2
2023-03-01 12:42:02,083 DEBUG CV Batch 55/1500 loss 7.804955 loss_att 7.862070 loss_ctc 8.291893 loss_rnnt 7.626760 hw_loss 0.190966 history loss 6.336871 rank 5
2023-03-01 12:42:04,062 DEBUG CV Batch 55/1500 loss 7.804955 loss_att 7.862070 loss_ctc 8.291893 loss_rnnt 7.626760 hw_loss 0.190965 history loss 6.336871 rank 6
2023-03-01 12:42:05,281 DEBUG CV Batch 55/1500 loss 7.804955 loss_att 7.862070 loss_ctc 8.291893 loss_rnnt 7.626760 hw_loss 0.190966 history loss 6.336871 rank 7
2023-03-01 12:42:06,280 DEBUG CV Batch 55/1500 loss 7.804955 loss_att 7.862070 loss_ctc 8.291893 loss_rnnt 7.626760 hw_loss 0.190965 history loss 6.336871 rank 0
2023-03-01 12:42:10,395 DEBUG CV Batch 55/1500 loss 7.804955 loss_att 7.862070 loss_ctc 8.291893 loss_rnnt 7.626760 hw_loss 0.190965 history loss 6.336871 rank 3
2023-03-01 12:42:12,863 DEBUG CV Batch 55/1600 loss 9.347509 loss_att 11.062958 loss_ctc 13.477728 loss_rnnt 8.346618 hw_loss 0.200825 history loss 6.299338 rank 1
2023-03-01 12:42:14,030 DEBUG CV Batch 55/1600 loss 9.347509 loss_att 11.062958 loss_ctc 13.477728 loss_rnnt 8.346618 hw_loss 0.200825 history loss 6.299338 rank 4
2023-03-01 12:42:15,181 DEBUG CV Batch 55/1600 loss 9.347509 loss_att 11.062958 loss_ctc 13.477728 loss_rnnt 8.346618 hw_loss 0.200825 history loss 6.299338 rank 2
2023-03-01 12:42:15,299 DEBUG CV Batch 55/1600 loss 9.347509 loss_att 11.062958 loss_ctc 13.477728 loss_rnnt 8.346618 hw_loss 0.200825 history loss 6.299338 rank 5
2023-03-01 12:42:17,473 DEBUG CV Batch 55/1600 loss 9.347509 loss_att 11.062958 loss_ctc 13.477728 loss_rnnt 8.346618 hw_loss 0.200825 history loss 6.299338 rank 6
2023-03-01 12:42:18,780 DEBUG CV Batch 55/1600 loss 9.347509 loss_att 11.062958 loss_ctc 13.477728 loss_rnnt 8.346618 hw_loss 0.200825 history loss 6.299338 rank 7
2023-03-01 12:42:19,882 DEBUG CV Batch 55/1600 loss 9.347509 loss_att 11.062958 loss_ctc 13.477728 loss_rnnt 8.346618 hw_loss 0.200825 history loss 6.299338 rank 0
2023-03-01 12:42:23,963 DEBUG CV Batch 55/1600 loss 9.347509 loss_att 11.062958 loss_ctc 13.477728 loss_rnnt 8.346618 hw_loss 0.200825 history loss 6.299338 rank 3
2023-03-01 12:42:25,340 DEBUG CV Batch 55/1700 loss 6.341894 loss_att 5.603717 loss_ctc 12.662444 loss_rnnt 5.513270 hw_loss 0.250349 history loss 6.235758 rank 1
2023-03-01 12:42:26,985 DEBUG CV Batch 55/1700 loss 6.341894 loss_att 5.603717 loss_ctc 12.662444 loss_rnnt 5.513270 hw_loss 0.250349 history loss 6.235758 rank 4
2023-03-01 12:42:28,049 DEBUG CV Batch 55/1700 loss 6.341894 loss_att 5.603717 loss_ctc 12.662444 loss_rnnt 5.513270 hw_loss 0.250349 history loss 6.235758 rank 5
2023-03-01 12:42:28,097 DEBUG CV Batch 55/1700 loss 6.341894 loss_att 5.603717 loss_ctc 12.662444 loss_rnnt 5.513270 hw_loss 0.250349 history loss 6.235758 rank 2
2023-03-01 12:42:30,123 DEBUG CV Batch 55/1700 loss 6.341894 loss_att 5.603717 loss_ctc 12.662444 loss_rnnt 5.513270 hw_loss 0.250349 history loss 6.235758 rank 6
2023-03-01 12:42:31,453 DEBUG CV Batch 55/1700 loss 6.341894 loss_att 5.603717 loss_ctc 12.662444 loss_rnnt 5.513270 hw_loss 0.250349 history loss 6.235758 rank 7
2023-03-01 12:42:32,571 DEBUG CV Batch 55/1700 loss 6.341894 loss_att 5.603717 loss_ctc 12.662444 loss_rnnt 5.513270 hw_loss 0.250349 history loss 6.235758 rank 0
2023-03-01 12:42:34,475 INFO Epoch 55 CV info cv_loss 6.217366580775594
2023-03-01 12:42:34,476 INFO Epoch 56 TRAIN info lr 0.0002865181318909449
2023-03-01 12:42:34,480 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 12:42:36,078 INFO Epoch 55 CV info cv_loss 6.217366580336248
2023-03-01 12:42:36,078 INFO Epoch 56 TRAIN info lr 0.00028652142489189037
2023-03-01 12:42:36,080 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 12:42:36,720 DEBUG CV Batch 55/1700 loss 6.341894 loss_att 5.603717 loss_ctc 12.662444 loss_rnnt 5.513270 hw_loss 0.250349 history loss 6.235758 rank 3
2023-03-01 12:42:37,240 INFO Epoch 55 CV info cv_loss 6.217366578716697
2023-03-01 12:42:37,241 INFO Epoch 56 TRAIN info lr 0.0002865228362127677
2023-03-01 12:42:37,246 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 12:42:37,517 INFO Epoch 55 CV info cv_loss 6.217366577876771
2023-03-01 12:42:37,517 INFO Epoch 56 TRAIN info lr 0.00028652518846057564
2023-03-01 12:42:37,519 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 12:42:39,392 INFO Epoch 55 CV info cv_loss 6.217366580536538
2023-03-01 12:42:39,393 INFO Epoch 56 TRAIN info lr 0.00028652801123441865
2023-03-01 12:42:39,395 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 12:42:40,779 INFO Epoch 55 CV info cv_loss 6.217366578441029
2023-03-01 12:42:40,780 INFO Epoch 56 TRAIN info lr 0.00028651672063958214
2023-03-01 12:42:40,785 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 12:42:42,021 INFO Epoch 55 CV info cv_loss 6.217366581357082
2023-03-01 12:42:42,021 INFO Checkpoint: save to checkpoint exp/2_27_rnnt_bias_loss_2_class_both_finetune/55.pt
2023-03-01 12:42:42,575 INFO Epoch 56 TRAIN info lr 0.00028653506853403867
2023-03-01 12:42:42,578 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 12:42:46,334 INFO Epoch 55 CV info cv_loss 6.217366580405165
2023-03-01 12:42:46,335 INFO Epoch 56 TRAIN info lr 0.0002865162502270953
2023-03-01 12:42:46,337 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 12:43:46,889 DEBUG TRAIN Batch 56/0 loss 5.308438 loss_att 5.653071 loss_ctc 7.882828 loss_rnnt 4.713905 hw_loss 0.341913 lr 0.00028653 rank 0
2023-03-01 12:43:46,893 DEBUG TRAIN Batch 56/0 loss 5.619761 loss_att 7.178627 loss_ctc 9.471540 loss_rnnt 4.636334 hw_loss 0.296403 lr 0.00028652 rank 4
2023-03-01 12:43:46,894 DEBUG TRAIN Batch 56/0 loss 7.157236 loss_att 6.958936 loss_ctc 11.882378 loss_rnnt 6.397623 hw_loss 0.317353 lr 0.00028652 rank 5
2023-03-01 12:43:46,896 DEBUG TRAIN Batch 56/0 loss 5.125237 loss_att 5.324249 loss_ctc 8.489761 loss_rnnt 4.477209 hw_loss 0.299290 lr 0.00028653 rank 6
2023-03-01 12:43:46,897 DEBUG TRAIN Batch 56/0 loss 5.779033 loss_att 6.774013 loss_ctc 9.522953 loss_rnnt 4.921764 hw_loss 0.298283 lr 0.00028652 rank 7
2023-03-01 12:43:46,900 DEBUG TRAIN Batch 56/0 loss 8.448176 loss_att 8.338925 loss_ctc 13.677416 loss_rnnt 7.639274 hw_loss 0.250352 lr 0.00028652 rank 2
2023-03-01 12:43:46,943 DEBUG TRAIN Batch 56/0 loss 5.679655 loss_att 6.651786 loss_ctc 10.669742 loss_rnnt 4.693010 hw_loss 0.237888 lr 0.00028652 rank 1
2023-03-01 12:43:46,951 DEBUG TRAIN Batch 56/0 loss 5.261827 loss_att 5.546649 loss_ctc 8.278586 loss_rnnt 4.628504 hw_loss 0.326484 lr 0.00028652 rank 3
2023-03-01 12:44:24,655 DEBUG TRAIN Batch 56/100 loss 3.376741 loss_att 5.510567 loss_ctc 6.985348 loss_rnnt 2.357123 hw_loss 0.209447 lr 0.00028651 rank 5
2023-03-01 12:44:24,664 DEBUG TRAIN Batch 56/100 loss 2.925153 loss_att 5.453318 loss_ctc 3.298437 loss_rnnt 2.320042 hw_loss 0.093201 lr 0.00028652 rank 0
2023-03-01 12:44:24,667 DEBUG TRAIN Batch 56/100 loss 9.064764 loss_att 10.082311 loss_ctc 14.045975 loss_rnnt 8.090256 hw_loss 0.200322 lr 0.00028651 rank 2
2023-03-01 12:44:24,670 DEBUG TRAIN Batch 56/100 loss 2.091886 loss_att 5.440150 loss_ctc 4.233338 loss_rnnt 0.926982 hw_loss 0.393233 lr 0.00028650 rank 7
2023-03-01 12:44:24,671 DEBUG TRAIN Batch 56/100 loss 5.966819 loss_att 11.210997 loss_ctc 16.588936 loss_rnnt 3.407987 hw_loss 0.175715 lr 0.00028652 rank 6
2023-03-01 12:44:24,672 DEBUG TRAIN Batch 56/100 loss 3.465168 loss_att 6.617357 loss_ctc 7.617967 loss_rnnt 2.142121 hw_loss 0.260442 lr 0.00028650 rank 3
2023-03-01 12:44:24,682 DEBUG TRAIN Batch 56/100 loss 9.742145 loss_att 9.243284 loss_ctc 13.372787 loss_rnnt 9.292406 hw_loss 0.122671 lr 0.00028651 rank 4
2023-03-01 12:44:24,689 DEBUG TRAIN Batch 56/100 loss 2.049293 loss_att 5.242412 loss_ctc 4.347834 loss_rnnt 1.013732 hw_loss 0.169623 lr 0.00028651 rank 1
2023-03-01 12:45:02,789 DEBUG TRAIN Batch 56/200 loss 2.081234 loss_att 4.609464 loss_ctc 3.580466 loss_rnnt 1.269155 hw_loss 0.199755 lr 0.00028649 rank 1
2023-03-01 12:45:02,791 DEBUG TRAIN Batch 56/200 loss 7.090138 loss_att 10.629011 loss_ctc 15.568820 loss_rnnt 5.148961 hw_loss 0.192961 lr 0.00028650 rank 6
2023-03-01 12:45:02,793 DEBUG TRAIN Batch 56/200 loss 10.115089 loss_att 12.576651 loss_ctc 13.522522 loss_rnnt 8.969414 hw_loss 0.373200 lr 0.00028651 rank 0
2023-03-01 12:45:02,793 DEBUG TRAIN Batch 56/200 loss 2.131280 loss_att 4.413501 loss_ctc 4.303596 loss_rnnt 1.360563 hw_loss 0.046183 lr 0.00028649 rank 3
2023-03-01 12:45:02,794 DEBUG TRAIN Batch 56/200 loss 1.013019 loss_att 3.289921 loss_ctc 1.781744 loss_rnnt 0.297398 hw_loss 0.295771 lr 0.00028649 rank 7
2023-03-01 12:45:02,795 DEBUG TRAIN Batch 56/200 loss 2.404958 loss_att 5.182230 loss_ctc 3.590989 loss_rnnt 1.600005 hw_loss 0.171301 lr 0.00028650 rank 4
2023-03-01 12:45:02,796 DEBUG TRAIN Batch 56/200 loss 6.523249 loss_att 9.961348 loss_ctc 17.822239 loss_rnnt 4.177810 hw_loss 0.283664 lr 0.00028650 rank 2
2023-03-01 12:45:02,798 DEBUG TRAIN Batch 56/200 loss 4.007469 loss_att 7.749004 loss_ctc 6.926620 loss_rnnt 2.785495 hw_loss 0.158339 lr 0.00028650 rank 5
2023-03-01 12:45:41,147 DEBUG TRAIN Batch 56/300 loss 6.869607 loss_att 9.691071 loss_ctc 10.194600 loss_rnnt 5.831707 hw_loss 0.056768 lr 0.00028648 rank 1
2023-03-01 12:45:41,151 DEBUG TRAIN Batch 56/300 loss 2.317099 loss_att 4.720618 loss_ctc 5.453337 loss_rnnt 1.314400 hw_loss 0.194683 lr 0.00028649 rank 2
2023-03-01 12:45:41,155 DEBUG TRAIN Batch 56/300 loss 9.666817 loss_att 11.866325 loss_ctc 20.976103 loss_rnnt 7.675009 hw_loss 0.082502 lr 0.00028649 rank 5
2023-03-01 12:45:41,162 DEBUG TRAIN Batch 56/300 loss 7.925357 loss_att 10.411061 loss_ctc 16.120964 loss_rnnt 6.195154 hw_loss 0.263091 lr 0.00028649 rank 4
2023-03-01 12:45:41,169 DEBUG TRAIN Batch 56/300 loss 7.554523 loss_att 8.889654 loss_ctc 13.267452 loss_rnnt 6.433284 hw_loss 0.173418 lr 0.00028650 rank 0
2023-03-01 12:45:41,170 DEBUG TRAIN Batch 56/300 loss 7.189482 loss_att 9.912723 loss_ctc 12.370480 loss_rnnt 5.806304 hw_loss 0.276992 lr 0.00028648 rank 7
2023-03-01 12:45:41,175 DEBUG TRAIN Batch 56/300 loss 8.887111 loss_att 14.197143 loss_ctc 18.789883 loss_rnnt 6.421776 hw_loss 0.155546 lr 0.00028648 rank 3
2023-03-01 12:45:41,194 DEBUG TRAIN Batch 56/300 loss 2.703359 loss_att 6.683261 loss_ctc 6.389372 loss_rnnt 1.362104 hw_loss 0.100884 lr 0.00028649 rank 6
2023-03-01 12:46:46,564 DEBUG TRAIN Batch 56/400 loss 7.792630 loss_att 10.308753 loss_ctc 13.531440 loss_rnnt 6.509727 hw_loss 0.027193 lr 0.00028647 rank 3
2023-03-01 12:46:46,566 DEBUG TRAIN Batch 56/400 loss 9.349088 loss_att 10.032670 loss_ctc 12.858861 loss_rnnt 8.660574 hw_loss 0.157176 lr 0.00028648 rank 2
2023-03-01 12:46:46,566 DEBUG TRAIN Batch 56/400 loss 7.184125 loss_att 10.877019 loss_ctc 12.521986 loss_rnnt 5.565583 hw_loss 0.315465 lr 0.00028648 rank 6
2023-03-01 12:46:46,569 DEBUG TRAIN Batch 56/400 loss 8.332399 loss_att 9.661756 loss_ctc 12.393623 loss_rnnt 7.411172 hw_loss 0.213488 lr 0.00028648 rank 5
2023-03-01 12:46:46,569 DEBUG TRAIN Batch 56/400 loss 5.030899 loss_att 6.074632 loss_ctc 5.483510 loss_rnnt 4.613247 hw_loss 0.278544 lr 0.00028649 rank 0
2023-03-01 12:46:46,570 DEBUG TRAIN Batch 56/400 loss 8.134657 loss_att 11.602217 loss_ctc 13.991253 loss_rnnt 6.574013 hw_loss 0.161725 lr 0.00028647 rank 7
2023-03-01 12:46:46,570 DEBUG TRAIN Batch 56/400 loss 5.146381 loss_att 8.645008 loss_ctc 12.642561 loss_rnnt 3.321926 hw_loss 0.234822 lr 0.00028647 rank 1
2023-03-01 12:46:46,589 DEBUG TRAIN Batch 56/400 loss 11.633036 loss_att 14.659535 loss_ctc 16.429413 loss_rnnt 10.356779 hw_loss 0.058950 lr 0.00028647 rank 4
2023-03-01 12:47:25,244 DEBUG TRAIN Batch 56/500 loss 4.854504 loss_att 6.489179 loss_ctc 6.826406 loss_rnnt 4.124323 hw_loss 0.263110 lr 0.00028646 rank 7
2023-03-01 12:47:25,245 DEBUG TRAIN Batch 56/500 loss 4.604335 loss_att 6.346425 loss_ctc 6.309289 loss_rnnt 3.920161 hw_loss 0.203303 lr 0.00028647 rank 6
2023-03-01 12:47:25,246 DEBUG TRAIN Batch 56/500 loss 4.173606 loss_att 6.995620 loss_ctc 7.688457 loss_rnnt 3.060099 hw_loss 0.150858 lr 0.00028648 rank 0
2023-03-01 12:47:25,248 DEBUG TRAIN Batch 56/500 loss 3.081896 loss_att 5.436662 loss_ctc 5.837745 loss_rnnt 2.123870 hw_loss 0.224301 lr 0.00028647 rank 2
2023-03-01 12:47:25,248 DEBUG TRAIN Batch 56/500 loss 5.006804 loss_att 6.576355 loss_ctc 6.807723 loss_rnnt 4.317283 hw_loss 0.254042 lr 0.00028646 rank 3
2023-03-01 12:47:25,249 DEBUG TRAIN Batch 56/500 loss 9.658962 loss_att 11.150764 loss_ctc 16.949802 loss_rnnt 8.284959 hw_loss 0.194121 lr 0.00028646 rank 5
2023-03-01 12:47:25,250 DEBUG TRAIN Batch 56/500 loss 6.988896 loss_att 8.378697 loss_ctc 10.260805 loss_rnnt 6.173195 hw_loss 0.190286 lr 0.00028646 rank 4
2023-03-01 12:47:25,252 DEBUG TRAIN Batch 56/500 loss 3.470375 loss_att 5.660982 loss_ctc 7.865497 loss_rnnt 2.339761 hw_loss 0.199643 lr 0.00028646 rank 1
2023-03-01 12:48:04,325 DEBUG TRAIN Batch 56/600 loss 8.983268 loss_att 11.187120 loss_ctc 11.605426 loss_rnnt 8.032590 hw_loss 0.300536 lr 0.00028645 rank 1
2023-03-01 12:48:04,333 DEBUG TRAIN Batch 56/600 loss 6.530967 loss_att 6.768507 loss_ctc 8.617188 loss_rnnt 5.979690 hw_loss 0.423012 lr 0.00028646 rank 0
2023-03-01 12:48:04,337 DEBUG TRAIN Batch 56/600 loss 9.384522 loss_att 11.319579 loss_ctc 14.931542 loss_rnnt 8.164690 hw_loss 0.174784 lr 0.00028645 rank 7
2023-03-01 12:48:04,339 DEBUG TRAIN Batch 56/600 loss 8.721671 loss_att 9.989429 loss_ctc 13.772243 loss_rnnt 7.645131 hw_loss 0.280459 lr 0.00028645 rank 2
2023-03-01 12:48:04,341 DEBUG TRAIN Batch 56/600 loss 5.582386 loss_att 7.484495 loss_ctc 12.743737 loss_rnnt 4.083869 hw_loss 0.306092 lr 0.00028646 rank 6
2023-03-01 12:48:04,348 DEBUG TRAIN Batch 56/600 loss 4.271794 loss_att 6.420261 loss_ctc 6.131326 loss_rnnt 3.411160 hw_loss 0.343130 lr 0.00028645 rank 4
2023-03-01 12:48:04,374 DEBUG TRAIN Batch 56/600 loss 7.727821 loss_att 9.948136 loss_ctc 12.516462 loss_rnnt 6.475042 hw_loss 0.319184 lr 0.00028645 rank 5
2023-03-01 12:48:04,407 DEBUG TRAIN Batch 56/600 loss 8.635772 loss_att 9.925832 loss_ctc 11.988874 loss_rnnt 7.819011 hw_loss 0.209380 lr 0.00028645 rank 3
2023-03-01 12:48:44,082 DEBUG TRAIN Batch 56/700 loss 8.154274 loss_att 10.353806 loss_ctc 20.157507 loss_rnnt 6.000337 hw_loss 0.212998 lr 0.00028644 rank 2
2023-03-01 12:48:44,083 DEBUG TRAIN Batch 56/700 loss 2.718203 loss_att 5.760952 loss_ctc 6.997961 loss_rnnt 1.421831 hw_loss 0.219728 lr 0.00028644 rank 1
2023-03-01 12:48:44,087 DEBUG TRAIN Batch 56/700 loss 10.304029 loss_att 13.322774 loss_ctc 23.760517 loss_rnnt 7.773330 hw_loss 0.248910 lr 0.00028643 rank 3
2023-03-01 12:48:44,089 DEBUG TRAIN Batch 56/700 loss 9.079340 loss_att 13.141246 loss_ctc 10.938663 loss_rnnt 7.877285 hw_loss 0.265809 lr 0.00028644 rank 5
2023-03-01 12:48:44,097 DEBUG TRAIN Batch 56/700 loss 8.210722 loss_att 12.169354 loss_ctc 16.754066 loss_rnnt 6.237004 hw_loss 0.080397 lr 0.00028643 rank 7
2023-03-01 12:48:44,099 DEBUG TRAIN Batch 56/700 loss 5.341399 loss_att 7.540134 loss_ctc 11.356129 loss_rnnt 4.026486 hw_loss 0.137253 lr 0.00028645 rank 0
2023-03-01 12:48:44,104 DEBUG TRAIN Batch 56/700 loss 5.114168 loss_att 7.747565 loss_ctc 8.123804 loss_rnnt 4.107818 hw_loss 0.146973 lr 0.00028644 rank 4
2023-03-01 12:48:44,118 DEBUG TRAIN Batch 56/700 loss 8.438519 loss_att 12.898391 loss_ctc 15.539660 loss_rnnt 6.482780 hw_loss 0.219274 lr 0.00028645 rank 6
2023-03-01 12:49:47,854 DEBUG TRAIN Batch 56/800 loss 5.269823 loss_att 9.376719 loss_ctc 8.011625 loss_rnnt 3.896377 hw_loss 0.349675 lr 0.00028642 rank 7
2023-03-01 12:49:47,857 DEBUG TRAIN Batch 56/800 loss 3.627685 loss_att 5.754933 loss_ctc 5.161131 loss_rnnt 2.898502 hw_loss 0.186138 lr 0.00028643 rank 6
2023-03-01 12:49:47,858 DEBUG TRAIN Batch 56/800 loss 6.506890 loss_att 8.310395 loss_ctc 9.805054 loss_rnnt 5.620018 hw_loss 0.162029 lr 0.00028643 rank 5
2023-03-01 12:49:47,859 DEBUG TRAIN Batch 56/800 loss 2.218143 loss_att 5.690572 loss_ctc 5.038590 loss_rnnt 1.069168 hw_loss 0.147057 lr 0.00028644 rank 0
2023-03-01 12:49:47,860 DEBUG TRAIN Batch 56/800 loss 2.424876 loss_att 6.209394 loss_ctc 3.826030 loss_rnnt 1.406239 hw_loss 0.140464 lr 0.00028642 rank 1
2023-03-01 12:49:47,863 DEBUG TRAIN Batch 56/800 loss 7.776699 loss_att 10.954487 loss_ctc 15.020748 loss_rnnt 6.029411 hw_loss 0.273481 lr 0.00028643 rank 4
2023-03-01 12:49:47,864 DEBUG TRAIN Batch 56/800 loss 6.498579 loss_att 9.085535 loss_ctc 10.464019 loss_rnnt 5.362980 hw_loss 0.167779 lr 0.00028643 rank 2
2023-03-01 12:49:47,865 DEBUG TRAIN Batch 56/800 loss 4.381158 loss_att 6.528678 loss_ctc 5.534938 loss_rnnt 3.699852 hw_loss 0.183685 lr 0.00028642 rank 3
2023-03-01 12:50:26,563 DEBUG TRAIN Batch 56/900 loss 4.165792 loss_att 7.464462 loss_ctc 6.356978 loss_rnnt 3.099321 hw_loss 0.214834 lr 0.00028641 rank 1
2023-03-01 12:50:26,568 DEBUG TRAIN Batch 56/900 loss 7.787139 loss_att 9.672827 loss_ctc 14.346484 loss_rnnt 6.409308 hw_loss 0.236464 lr 0.00028643 rank 0
2023-03-01 12:50:26,568 DEBUG TRAIN Batch 56/900 loss 2.041953 loss_att 4.790009 loss_ctc 3.790177 loss_rnnt 1.232291 hw_loss 0.050538 lr 0.00028641 rank 7
2023-03-01 12:50:26,569 DEBUG TRAIN Batch 56/900 loss 1.067071 loss_att 4.064571 loss_ctc 2.922075 loss_rnnt 0.219907 hw_loss 0.000621 lr 0.00028641 rank 3
2023-03-01 12:50:26,569 DEBUG TRAIN Batch 56/900 loss 8.660940 loss_att 9.997559 loss_ctc 12.240520 loss_rnnt 7.843405 hw_loss 0.136751 lr 0.00028642 rank 2
2023-03-01 12:50:26,572 DEBUG TRAIN Batch 56/900 loss 6.394616 loss_att 7.920485 loss_ctc 8.284780 loss_rnnt 5.654795 hw_loss 0.342421 lr 0.00028642 rank 5
2023-03-01 12:50:26,578 DEBUG TRAIN Batch 56/900 loss 7.380979 loss_att 9.155443 loss_ctc 8.028902 loss_rnnt 6.811810 hw_loss 0.239787 lr 0.00028642 rank 6
2023-03-01 12:50:26,621 DEBUG TRAIN Batch 56/900 loss 4.789835 loss_att 7.178200 loss_ctc 5.983720 loss_rnnt 3.998925 hw_loss 0.288848 lr 0.00028642 rank 4
2023-03-01 12:51:05,547 DEBUG TRAIN Batch 56/1000 loss 3.087645 loss_att 6.784668 loss_ctc 6.708170 loss_rnnt 1.738626 hw_loss 0.237894 lr 0.00028641 rank 6
2023-03-01 12:51:05,550 DEBUG TRAIN Batch 56/1000 loss 3.782727 loss_att 8.311820 loss_ctc 8.496348 loss_rnnt 2.176873 hw_loss 0.134161 lr 0.00028640 rank 4
2023-03-01 12:51:05,564 DEBUG TRAIN Batch 56/1000 loss 3.494370 loss_att 5.530391 loss_ctc 8.363488 loss_rnnt 2.261821 hw_loss 0.330243 lr 0.00028641 rank 2
2023-03-01 12:51:05,565 DEBUG TRAIN Batch 56/1000 loss 2.269858 loss_att 4.353707 loss_ctc 4.014798 loss_rnnt 1.513961 hw_loss 0.199630 lr 0.00028640 rank 5
2023-03-01 12:51:05,564 DEBUG TRAIN Batch 56/1000 loss 6.793600 loss_att 8.623432 loss_ctc 8.127936 loss_rnnt 6.156068 hw_loss 0.175600 lr 0.00028640 rank 7
2023-03-01 12:51:05,566 DEBUG TRAIN Batch 56/1000 loss 7.573269 loss_att 10.310717 loss_ctc 9.225088 loss_rnnt 6.617975 hw_loss 0.351679 lr 0.00028642 rank 0
2023-03-01 12:51:05,598 DEBUG TRAIN Batch 56/1000 loss 4.592994 loss_att 8.015817 loss_ctc 6.361917 loss_rnnt 3.566136 hw_loss 0.199569 lr 0.00028640 rank 1
2023-03-01 12:51:05,632 DEBUG TRAIN Batch 56/1000 loss 8.711102 loss_att 11.012218 loss_ctc 11.503418 loss_rnnt 7.723952 hw_loss 0.289910 lr 0.00028640 rank 3
2023-03-01 12:52:10,686 DEBUG TRAIN Batch 56/1100 loss 4.810693 loss_att 6.444198 loss_ctc 6.980819 loss_rnnt 4.097274 hw_loss 0.182564 lr 0.00028639 rank 7
2023-03-01 12:52:10,702 DEBUG TRAIN Batch 56/1100 loss 5.286137 loss_att 8.261484 loss_ctc 8.525761 loss_rnnt 4.158630 hw_loss 0.188415 lr 0.00028639 rank 5
2023-03-01 12:52:10,703 DEBUG TRAIN Batch 56/1100 loss 6.171598 loss_att 8.945775 loss_ctc 11.456972 loss_rnnt 4.817697 hw_loss 0.176906 lr 0.00028641 rank 0
2023-03-01 12:52:10,704 DEBUG TRAIN Batch 56/1100 loss 7.715688 loss_att 11.202015 loss_ctc 12.551521 loss_rnnt 6.236924 hw_loss 0.256350 lr 0.00028639 rank 1
2023-03-01 12:52:10,705 DEBUG TRAIN Batch 56/1100 loss 8.340096 loss_att 11.824808 loss_ctc 13.503724 loss_rnnt 6.868087 hw_loss 0.162343 lr 0.00028639 rank 4
2023-03-01 12:52:10,705 DEBUG TRAIN Batch 56/1100 loss 6.084191 loss_att 8.752935 loss_ctc 8.480175 loss_rnnt 5.159483 hw_loss 0.134051 lr 0.00028639 rank 3
2023-03-01 12:52:10,705 DEBUG TRAIN Batch 56/1100 loss 3.127285 loss_att 5.080740 loss_ctc 6.125683 loss_rnnt 2.174371 hw_loss 0.304569 lr 0.00028640 rank 2
2023-03-01 12:52:10,753 DEBUG TRAIN Batch 56/1100 loss 8.242908 loss_att 11.934086 loss_ctc 12.607820 loss_rnnt 6.819535 hw_loss 0.193405 lr 0.00028640 rank 6
2023-03-01 12:52:49,651 DEBUG TRAIN Batch 56/1200 loss 4.497297 loss_att 6.264551 loss_ctc 8.308745 loss_rnnt 3.502980 hw_loss 0.248761 lr 0.00028639 rank 6
2023-03-01 12:52:49,652 DEBUG TRAIN Batch 56/1200 loss 5.632343 loss_att 7.347156 loss_ctc 8.586139 loss_rnnt 4.767008 hw_loss 0.240998 lr 0.00028638 rank 2
2023-03-01 12:52:49,652 DEBUG TRAIN Batch 56/1200 loss 4.421607 loss_att 9.210350 loss_ctc 8.749327 loss_rnnt 2.828062 hw_loss 0.110186 lr 0.00028638 rank 1
2023-03-01 12:52:49,656 DEBUG TRAIN Batch 56/1200 loss 6.908150 loss_att 8.158701 loss_ctc 10.293475 loss_rnnt 6.020188 hw_loss 0.349641 lr 0.00028639 rank 0
2023-03-01 12:52:49,657 DEBUG TRAIN Batch 56/1200 loss 4.315471 loss_att 6.500180 loss_ctc 7.719131 loss_rnnt 3.319105 hw_loss 0.198006 lr 0.00028638 rank 5
2023-03-01 12:52:49,658 DEBUG TRAIN Batch 56/1200 loss 7.409745 loss_att 10.043854 loss_ctc 11.319624 loss_rnnt 6.303996 hw_loss 0.108020 lr 0.00028638 rank 7
2023-03-01 12:52:49,670 DEBUG TRAIN Batch 56/1200 loss 8.947728 loss_att 11.724562 loss_ctc 17.851307 loss_rnnt 7.065208 hw_loss 0.262518 lr 0.00028637 rank 3
2023-03-01 12:52:49,679 DEBUG TRAIN Batch 56/1200 loss 1.848697 loss_att 3.408149 loss_ctc 3.673367 loss_rnnt 1.112146 hw_loss 0.340072 lr 0.00028638 rank 4
2023-03-01 12:53:28,228 DEBUG TRAIN Batch 56/1300 loss 3.866694 loss_att 3.828370 loss_ctc 6.625976 loss_rnnt 3.350093 hw_loss 0.293180 lr 0.00028636 rank 7
2023-03-01 12:53:28,232 DEBUG TRAIN Batch 56/1300 loss 10.297247 loss_att 10.064947 loss_ctc 14.694945 loss_rnnt 9.603908 hw_loss 0.287699 lr 0.00028636 rank 3
2023-03-01 12:53:28,232 DEBUG TRAIN Batch 56/1300 loss 6.786785 loss_att 8.610264 loss_ctc 11.048590 loss_rnnt 5.704775 hw_loss 0.279512 lr 0.00028637 rank 6
2023-03-01 12:53:28,233 DEBUG TRAIN Batch 56/1300 loss 2.889792 loss_att 4.910260 loss_ctc 4.026889 loss_rnnt 2.300972 hw_loss 0.062088 lr 0.00028637 rank 4
2023-03-01 12:53:28,235 DEBUG TRAIN Batch 56/1300 loss 7.973276 loss_att 8.333210 loss_ctc 11.935955 loss_rnnt 7.137726 hw_loss 0.441011 lr 0.00028637 rank 5
2023-03-01 12:53:28,235 DEBUG TRAIN Batch 56/1300 loss 10.388086 loss_att 15.631607 loss_ctc 26.546331 loss_rnnt 7.154884 hw_loss 0.056373 lr 0.00028638 rank 0
2023-03-01 12:53:28,238 DEBUG TRAIN Batch 56/1300 loss 2.856199 loss_att 5.057135 loss_ctc 3.719395 loss_rnnt 2.141711 hw_loss 0.298513 lr 0.00028637 rank 2
2023-03-01 12:53:28,246 DEBUG TRAIN Batch 56/1300 loss 2.876458 loss_att 5.605242 loss_ctc 8.307758 loss_rnnt 1.506273 hw_loss 0.187978 lr 0.00028636 rank 1
2023-03-01 12:54:08,305 DEBUG TRAIN Batch 56/1400 loss 3.061830 loss_att 5.721324 loss_ctc 6.415412 loss_rnnt 1.917420 hw_loss 0.310062 lr 0.00028636 rank 2
2023-03-01 12:54:08,306 DEBUG TRAIN Batch 56/1400 loss 6.809310 loss_att 9.677649 loss_ctc 11.194796 loss_rnnt 5.495925 hw_loss 0.290598 lr 0.00028635 rank 1
2023-03-01 12:54:08,312 DEBUG TRAIN Batch 56/1400 loss 4.142287 loss_att 7.120705 loss_ctc 6.331060 loss_rnnt 3.116197 hw_loss 0.259820 lr 0.00028635 rank 7
2023-03-01 12:54:08,312 DEBUG TRAIN Batch 56/1400 loss 9.799818 loss_att 12.421183 loss_ctc 13.522815 loss_rnnt 8.614612 hw_loss 0.308503 lr 0.00028637 rank 0
2023-03-01 12:54:08,320 DEBUG TRAIN Batch 56/1400 loss 6.972458 loss_att 10.132942 loss_ctc 12.400802 loss_rnnt 5.615467 hw_loss 0.002090 lr 0.00028635 rank 3
2023-03-01 12:54:08,323 DEBUG TRAIN Batch 56/1400 loss 6.902948 loss_att 11.099360 loss_ctc 9.677017 loss_rnnt 5.579234 hw_loss 0.214791 lr 0.00028636 rank 5
2023-03-01 12:54:08,330 DEBUG TRAIN Batch 56/1400 loss 1.928431 loss_att 5.432372 loss_ctc 4.000706 loss_rnnt 0.842625 hw_loss 0.203841 lr 0.00028636 rank 6
2023-03-01 12:54:08,353 DEBUG TRAIN Batch 56/1400 loss 9.184875 loss_att 11.688980 loss_ctc 11.657843 loss_rnnt 8.288288 hw_loss 0.123821 lr 0.00028636 rank 4
2023-03-01 12:55:12,272 DEBUG TRAIN Batch 56/1500 loss 8.765171 loss_att 14.155792 loss_ctc 14.099186 loss_rnnt 6.925259 hw_loss 0.094847 lr 0.00028634 rank 3
2023-03-01 12:55:12,284 DEBUG TRAIN Batch 56/1500 loss 2.500400 loss_att 5.349955 loss_ctc 6.461969 loss_rnnt 1.314802 hw_loss 0.164021 lr 0.00028636 rank 0
2023-03-01 12:55:12,284 DEBUG TRAIN Batch 56/1500 loss 8.126953 loss_att 9.174667 loss_ctc 14.251335 loss_rnnt 6.959141 hw_loss 0.265660 lr 0.00028634 rank 7
2023-03-01 12:55:12,286 DEBUG TRAIN Batch 56/1500 loss 9.072990 loss_att 10.579624 loss_ctc 14.202385 loss_rnnt 7.981948 hw_loss 0.198370 lr 0.00028634 rank 1
2023-03-01 12:55:12,286 DEBUG TRAIN Batch 56/1500 loss 5.333823 loss_att 9.894394 loss_ctc 9.828541 loss_rnnt 3.693637 hw_loss 0.241455 lr 0.00028635 rank 6
2023-03-01 12:55:12,288 DEBUG TRAIN Batch 56/1500 loss 4.820250 loss_att 7.684505 loss_ctc 9.508658 loss_rnnt 3.507508 hw_loss 0.215193 lr 0.00028635 rank 2
2023-03-01 12:55:12,293 DEBUG TRAIN Batch 56/1500 loss 6.445981 loss_att 9.883515 loss_ctc 10.320086 loss_rnnt 5.151401 hw_loss 0.169735 lr 0.00028634 rank 4
2023-03-01 12:55:12,296 DEBUG TRAIN Batch 56/1500 loss 4.342846 loss_att 6.466352 loss_ctc 8.796603 loss_rnnt 3.243832 hw_loss 0.150898 lr 0.00028635 rank 5
2023-03-01 12:55:50,442 DEBUG TRAIN Batch 56/1600 loss 2.499999 loss_att 5.718130 loss_ctc 5.439705 loss_rnnt 1.310459 hw_loss 0.288661 lr 0.00028633 rank 5
2023-03-01 12:55:50,458 DEBUG TRAIN Batch 56/1600 loss 7.883347 loss_att 10.885164 loss_ctc 15.296141 loss_rnnt 6.187228 hw_loss 0.201343 lr 0.00028633 rank 7
2023-03-01 12:55:50,459 DEBUG TRAIN Batch 56/1600 loss 6.908990 loss_att 11.065299 loss_ctc 16.502844 loss_rnnt 4.757328 hw_loss 0.077289 lr 0.00028633 rank 3
2023-03-01 12:55:50,460 DEBUG TRAIN Batch 56/1600 loss 5.755032 loss_att 8.536610 loss_ctc 10.742496 loss_rnnt 4.386647 hw_loss 0.275763 lr 0.00028635 rank 0
2023-03-01 12:55:50,461 DEBUG TRAIN Batch 56/1600 loss 6.917441 loss_att 8.186906 loss_ctc 10.554775 loss_rnnt 6.093947 hw_loss 0.158667 lr 0.00028633 rank 1
2023-03-01 12:55:50,461 DEBUG TRAIN Batch 56/1600 loss 4.372954 loss_att 5.823741 loss_ctc 9.202124 loss_rnnt 3.320080 hw_loss 0.222801 lr 0.00028634 rank 2
2023-03-01 12:55:50,463 DEBUG TRAIN Batch 56/1600 loss 3.780033 loss_att 5.953638 loss_ctc 9.447954 loss_rnnt 2.413640 hw_loss 0.329905 lr 0.00028634 rank 6
2023-03-01 12:55:50,513 DEBUG TRAIN Batch 56/1600 loss 2.996852 loss_att 6.013211 loss_ctc 4.823319 loss_rnnt 2.066396 hw_loss 0.156853 lr 0.00028633 rank 4
2023-03-01 12:56:29,525 DEBUG TRAIN Batch 56/1700 loss 6.350106 loss_att 8.056987 loss_ctc 11.276615 loss_rnnt 5.300572 hw_loss 0.096168 lr 0.00028632 rank 1
2023-03-01 12:56:29,526 DEBUG TRAIN Batch 56/1700 loss 4.723141 loss_att 7.097164 loss_ctc 7.629200 loss_rnnt 3.745275 hw_loss 0.216725 lr 0.00028632 rank 5
2023-03-01 12:56:29,526 DEBUG TRAIN Batch 56/1700 loss 6.627916 loss_att 9.728148 loss_ctc 13.487265 loss_rnnt 4.969198 hw_loss 0.232674 lr 0.00028632 rank 4
2023-03-01 12:56:29,530 DEBUG TRAIN Batch 56/1700 loss 11.120623 loss_att 14.731842 loss_ctc 22.505981 loss_rnnt 8.761805 hw_loss 0.222234 lr 0.00028633 rank 6
2023-03-01 12:56:29,531 DEBUG TRAIN Batch 56/1700 loss 6.458568 loss_att 7.714986 loss_ctc 12.866345 loss_rnnt 5.187741 hw_loss 0.309699 lr 0.00028633 rank 0
2023-03-01 12:56:29,533 DEBUG TRAIN Batch 56/1700 loss 7.777262 loss_att 9.431369 loss_ctc 10.828354 loss_rnnt 6.980092 hw_loss 0.111631 lr 0.00028632 rank 7
2023-03-01 12:56:29,534 DEBUG TRAIN Batch 56/1700 loss 4.687544 loss_att 7.224429 loss_ctc 7.581732 loss_rnnt 3.675064 hw_loss 0.223522 lr 0.00028632 rank 3
2023-03-01 12:56:29,537 DEBUG TRAIN Batch 56/1700 loss 5.201942 loss_att 7.375689 loss_ctc 7.761575 loss_rnnt 4.360788 hw_loss 0.122103 lr 0.00028632 rank 2
2023-03-01 12:57:34,499 DEBUG TRAIN Batch 56/1800 loss 4.588688 loss_att 8.020609 loss_ctc 9.390024 loss_rnnt 3.115376 hw_loss 0.275154 lr 0.00028630 rank 7
2023-03-01 12:57:34,501 DEBUG TRAIN Batch 56/1800 loss 5.522295 loss_att 6.381998 loss_ctc 9.155869 loss_rnnt 4.683733 hw_loss 0.341523 lr 0.00028632 rank 0
2023-03-01 12:57:34,507 DEBUG TRAIN Batch 56/1800 loss 4.506336 loss_att 5.620088 loss_ctc 6.983631 loss_rnnt 3.777628 hw_loss 0.329348 lr 0.00028631 rank 1
2023-03-01 12:57:34,508 DEBUG TRAIN Batch 56/1800 loss 12.098298 loss_att 13.413631 loss_ctc 24.115608 loss_rnnt 10.022756 hw_loss 0.394064 lr 0.00028631 rank 5
2023-03-01 12:57:34,508 DEBUG TRAIN Batch 56/1800 loss 2.991616 loss_att 5.371570 loss_ctc 4.526824 loss_rnnt 2.152491 hw_loss 0.297073 lr 0.00028631 rank 4
2023-03-01 12:57:34,508 DEBUG TRAIN Batch 56/1800 loss 10.354708 loss_att 14.630517 loss_ctc 22.299732 loss_rnnt 7.741218 hw_loss 0.310606 lr 0.00028630 rank 3
2023-03-01 12:57:34,512 DEBUG TRAIN Batch 56/1800 loss 11.064981 loss_att 14.289267 loss_ctc 17.570072 loss_rnnt 9.375874 hw_loss 0.331698 lr 0.00028631 rank 2
2023-03-01 12:57:34,558 DEBUG TRAIN Batch 56/1800 loss 6.944887 loss_att 9.377496 loss_ctc 8.912873 loss_rnnt 6.103711 hw_loss 0.172979 lr 0.00028632 rank 6
2023-03-01 12:58:13,921 DEBUG TRAIN Batch 56/1900 loss 13.150935 loss_att 20.416937 loss_ctc 24.804220 loss_rnnt 10.069368 hw_loss 0.139867 lr 0.00028631 rank 0
2023-03-01 12:58:13,922 DEBUG TRAIN Batch 56/1900 loss 3.160186 loss_att 8.314932 loss_ctc 7.095221 loss_rnnt 1.465445 hw_loss 0.260852 lr 0.00028630 rank 2
2023-03-01 12:58:13,927 DEBUG TRAIN Batch 56/1900 loss 3.232554 loss_att 5.753350 loss_ctc 5.339592 loss_rnnt 2.391461 hw_loss 0.104990 lr 0.00028629 rank 1
2023-03-01 12:58:13,935 DEBUG TRAIN Batch 56/1900 loss 6.418912 loss_att 6.707070 loss_ctc 10.885649 loss_rnnt 5.588554 hw_loss 0.332177 lr 0.00028629 rank 7
2023-03-01 12:58:13,940 DEBUG TRAIN Batch 56/1900 loss 6.329863 loss_att 7.489492 loss_ctc 10.037186 loss_rnnt 5.454454 hw_loss 0.279697 lr 0.00028630 rank 4
2023-03-01 12:58:13,941 DEBUG TRAIN Batch 56/1900 loss 4.898817 loss_att 8.305645 loss_ctc 11.111335 loss_rnnt 3.312774 hw_loss 0.143139 lr 0.00028630 rank 6
2023-03-01 12:58:13,946 DEBUG TRAIN Batch 56/1900 loss 7.095423 loss_att 10.504406 loss_ctc 9.726704 loss_rnnt 5.923763 hw_loss 0.260672 lr 0.00028630 rank 5
2023-03-01 12:58:13,984 DEBUG TRAIN Batch 56/1900 loss 11.277380 loss_att 11.653139 loss_ctc 13.430876 loss_rnnt 10.718875 hw_loss 0.367915 lr 0.00028629 rank 3
2023-03-01 12:58:52,692 DEBUG TRAIN Batch 56/2000 loss 6.202132 loss_att 8.821525 loss_ctc 9.767765 loss_rnnt 5.109260 hw_loss 0.175455 lr 0.00028629 rank 2
2023-03-01 12:58:52,701 DEBUG TRAIN Batch 56/2000 loss 4.881339 loss_att 6.342085 loss_ctc 7.373654 loss_rnnt 4.150693 hw_loss 0.199102 lr 0.00028630 rank 0
2023-03-01 12:58:52,701 DEBUG TRAIN Batch 56/2000 loss 4.836922 loss_att 7.149013 loss_ctc 8.339207 loss_rnnt 3.781230 hw_loss 0.236816 lr 0.00028628 rank 7
2023-03-01 12:58:52,705 DEBUG TRAIN Batch 56/2000 loss 9.015738 loss_att 10.300459 loss_ctc 13.359687 loss_rnnt 8.084546 hw_loss 0.178225 lr 0.00028629 rank 5
2023-03-01 12:58:52,706 DEBUG TRAIN Batch 56/2000 loss 6.182844 loss_att 9.204917 loss_ctc 14.115245 loss_rnnt 4.431694 hw_loss 0.167030 lr 0.00028629 rank 4
2023-03-01 12:58:52,708 DEBUG TRAIN Batch 56/2000 loss 5.208852 loss_att 7.812077 loss_ctc 8.425520 loss_rnnt 4.188802 hw_loss 0.132219 lr 0.00028628 rank 1
2023-03-01 12:58:52,714 DEBUG TRAIN Batch 56/2000 loss 3.439790 loss_att 5.038273 loss_ctc 4.357064 loss_rnnt 2.866290 hw_loss 0.246564 lr 0.00028628 rank 3
2023-03-01 12:58:52,731 DEBUG TRAIN Batch 56/2000 loss 5.774706 loss_att 9.688034 loss_ctc 8.989096 loss_rnnt 4.480508 hw_loss 0.155527 lr 0.00028629 rank 6
2023-03-01 12:59:32,642 DEBUG TRAIN Batch 56/2100 loss 6.499787 loss_att 10.199761 loss_ctc 10.939749 loss_rnnt 5.034976 hw_loss 0.249040 lr 0.00028627 rank 1
2023-03-01 12:59:32,644 DEBUG TRAIN Batch 56/2100 loss 6.779335 loss_att 10.850117 loss_ctc 13.201176 loss_rnnt 4.909407 hw_loss 0.374110 lr 0.00028628 rank 5
2023-03-01 12:59:32,645 DEBUG TRAIN Batch 56/2100 loss 4.590756 loss_att 7.640397 loss_ctc 7.709189 loss_rnnt 3.409410 hw_loss 0.291800 lr 0.00028629 rank 0
2023-03-01 12:59:32,646 DEBUG TRAIN Batch 56/2100 loss 2.452475 loss_att 4.736329 loss_ctc 5.732595 loss_rnnt 1.416504 hw_loss 0.265970 lr 0.00028628 rank 2
2023-03-01 12:59:32,650 DEBUG TRAIN Batch 56/2100 loss 7.742193 loss_att 10.980074 loss_ctc 10.127493 loss_rnnt 6.675416 hw_loss 0.189676 lr 0.00028627 rank 3
2023-03-01 12:59:32,660 DEBUG TRAIN Batch 56/2100 loss 0.988171 loss_att 3.472353 loss_ctc 1.147310 loss_rnnt 0.343802 hw_loss 0.236837 lr 0.00028627 rank 4
2023-03-01 12:59:32,663 DEBUG TRAIN Batch 56/2100 loss 3.776529 loss_att 6.112055 loss_ctc 4.702822 loss_rnnt 3.101732 hw_loss 0.157850 lr 0.00028628 rank 6
2023-03-01 12:59:32,663 DEBUG TRAIN Batch 56/2100 loss 8.097207 loss_att 11.217412 loss_ctc 14.732754 loss_rnnt 6.483977 hw_loss 0.195843 lr 0.00028627 rank 7
2023-03-01 13:00:35,895 DEBUG TRAIN Batch 56/2200 loss 4.628075 loss_att 7.512718 loss_ctc 6.557446 loss_rnnt 3.698181 hw_loss 0.179466 lr 0.00028626 rank 7
2023-03-01 13:00:35,896 DEBUG TRAIN Batch 56/2200 loss 4.630921 loss_att 8.015529 loss_ctc 10.803436 loss_rnnt 3.003792 hw_loss 0.238510 lr 0.00028626 rank 4
2023-03-01 13:00:35,897 DEBUG TRAIN Batch 56/2200 loss 2.606152 loss_att 5.699636 loss_ctc 5.362216 loss_rnnt 1.540026 hw_loss 0.149915 lr 0.00028627 rank 2
2023-03-01 13:00:35,901 DEBUG TRAIN Batch 56/2200 loss 2.414886 loss_att 4.343208 loss_ctc 3.955323 loss_rnnt 1.663981 hw_loss 0.299718 lr 0.00028628 rank 0
2023-03-01 13:00:35,900 DEBUG TRAIN Batch 56/2200 loss 4.230917 loss_att 6.074145 loss_ctc 6.873060 loss_rnnt 3.419760 hw_loss 0.169171 lr 0.00028626 rank 1
2023-03-01 13:00:35,901 DEBUG TRAIN Batch 56/2200 loss 2.543222 loss_att 6.024545 loss_ctc 4.590250 loss_rnnt 1.443146 hw_loss 0.245390 lr 0.00028626 rank 3
2023-03-01 13:00:35,903 DEBUG TRAIN Batch 56/2200 loss 6.167035 loss_att 10.265374 loss_ctc 10.927788 loss_rnnt 4.614205 hw_loss 0.184491 lr 0.00028627 rank 6
2023-03-01 13:00:35,942 DEBUG TRAIN Batch 56/2200 loss 9.582223 loss_att 11.789771 loss_ctc 11.716431 loss_rnnt 8.743721 hw_loss 0.210808 lr 0.00028626 rank 5
2023-03-01 13:01:14,730 DEBUG TRAIN Batch 56/2300 loss 7.515323 loss_att 10.082987 loss_ctc 11.392016 loss_rnnt 6.351844 hw_loss 0.249474 lr 0.00028625 rank 2
2023-03-01 13:01:14,743 DEBUG TRAIN Batch 56/2300 loss 2.585178 loss_att 5.482275 loss_ctc 4.440147 loss_rnnt 1.625046 hw_loss 0.250092 lr 0.00028625 rank 1
2023-03-01 13:01:14,746 DEBUG TRAIN Batch 56/2300 loss 5.200372 loss_att 7.512649 loss_ctc 6.950731 loss_rnnt 4.403782 hw_loss 0.188911 lr 0.00028626 rank 0
2023-03-01 13:01:14,746 DEBUG TRAIN Batch 56/2300 loss 5.878557 loss_att 10.166564 loss_ctc 12.529519 loss_rnnt 3.991288 hw_loss 0.267884 lr 0.00028625 rank 4
2023-03-01 13:01:14,748 DEBUG TRAIN Batch 56/2300 loss 8.424473 loss_att 10.980225 loss_ctc 15.736147 loss_rnnt 6.841384 hw_loss 0.181966 lr 0.00028625 rank 7
2023-03-01 13:01:14,750 DEBUG TRAIN Batch 56/2300 loss 3.079552 loss_att 7.380063 loss_ctc 7.581868 loss_rnnt 1.503853 hw_loss 0.216166 lr 0.00028625 rank 3
2023-03-01 13:01:14,752 DEBUG TRAIN Batch 56/2300 loss 7.318221 loss_att 9.194066 loss_ctc 13.258339 loss_rnnt 6.045279 hw_loss 0.198293 lr 0.00028625 rank 5
2023-03-01 13:01:14,803 DEBUG TRAIN Batch 56/2300 loss 4.202266 loss_att 6.371678 loss_ctc 10.262374 loss_rnnt 2.808937 hw_loss 0.283936 lr 0.00028626 rank 6
2023-03-01 13:01:54,137 DEBUG TRAIN Batch 56/2400 loss 6.089145 loss_att 8.386842 loss_ctc 12.395962 loss_rnnt 4.653283 hw_loss 0.253899 lr 0.00028624 rank 1
2023-03-01 13:01:54,137 DEBUG TRAIN Batch 56/2400 loss 3.943019 loss_att 7.679965 loss_ctc 6.727138 loss_rnnt 2.724504 hw_loss 0.187331 lr 0.00028625 rank 6
2023-03-01 13:01:54,140 DEBUG TRAIN Batch 56/2400 loss 6.581885 loss_att 8.943846 loss_ctc 8.962015 loss_rnnt 5.636075 hw_loss 0.292625 lr 0.00028625 rank 0
2023-03-01 13:01:54,140 DEBUG TRAIN Batch 56/2400 loss 5.595121 loss_att 8.054332 loss_ctc 10.247919 loss_rnnt 4.424888 hw_loss 0.108784 lr 0.00028624 rank 4
2023-03-01 13:01:54,142 DEBUG TRAIN Batch 56/2400 loss 8.705276 loss_att 11.752854 loss_ctc 14.311972 loss_rnnt 7.201605 hw_loss 0.274868 lr 0.00028624 rank 5
2023-03-01 13:01:54,143 DEBUG TRAIN Batch 56/2400 loss 1.592219 loss_att 4.222100 loss_ctc 3.416664 loss_rnnt 0.698406 hw_loss 0.233582 lr 0.00028623 rank 7
2023-03-01 13:01:54,147 DEBUG TRAIN Batch 56/2400 loss 12.995633 loss_att 14.550476 loss_ctc 14.290020 loss_rnnt 12.389380 hw_loss 0.230065 lr 0.00028623 rank 3
2023-03-01 13:01:54,184 DEBUG TRAIN Batch 56/2400 loss 6.094913 loss_att 7.500643 loss_ctc 9.508719 loss_rnnt 5.209769 hw_loss 0.279044 lr 0.00028624 rank 2
2023-03-01 13:02:58,468 DEBUG TRAIN Batch 56/2500 loss 2.980199 loss_att 5.710128 loss_ctc 3.147399 loss_rnnt 2.362994 hw_loss 0.091735 lr 0.00028624 rank 0
2023-03-01 13:02:58,470 DEBUG TRAIN Batch 56/2500 loss 9.043967 loss_att 11.878922 loss_ctc 12.468863 loss_rnnt 7.896729 hw_loss 0.231740 lr 0.00028622 rank 3
2023-03-01 13:02:58,470 DEBUG TRAIN Batch 56/2500 loss 4.987576 loss_att 6.284751 loss_ctc 9.382037 loss_rnnt 3.956070 hw_loss 0.349016 lr 0.00028623 rank 4
2023-03-01 13:02:58,479 DEBUG TRAIN Batch 56/2500 loss 3.836052 loss_att 5.616119 loss_ctc 7.380415 loss_rnnt 2.892427 hw_loss 0.215679 lr 0.00028623 rank 5
2023-03-01 13:02:58,482 DEBUG TRAIN Batch 56/2500 loss 4.483753 loss_att 7.711466 loss_ctc 4.153655 loss_rnnt 3.791344 hw_loss 0.170398 lr 0.00028622 rank 1
2023-03-01 13:02:58,486 DEBUG TRAIN Batch 56/2500 loss 7.217724 loss_att 8.877323 loss_ctc 7.718610 loss_rnnt 6.673267 hw_loss 0.273284 lr 0.00028622 rank 7
2023-03-01 13:02:58,498 DEBUG TRAIN Batch 56/2500 loss 4.321780 loss_att 9.939533 loss_ctc 7.644825 loss_rnnt 2.667227 hw_loss 0.164867 lr 0.00028623 rank 2
2023-03-01 13:02:58,498 DEBUG TRAIN Batch 56/2500 loss 1.903962 loss_att 3.916226 loss_ctc 3.292300 loss_rnnt 1.187685 hw_loss 0.241337 lr 0.00028623 rank 6
2023-03-01 13:03:37,272 DEBUG TRAIN Batch 56/2600 loss 8.193502 loss_att 12.566670 loss_ctc 17.589071 loss_rnnt 5.914424 hw_loss 0.284440 lr 0.00028622 rank 2
2023-03-01 13:03:37,274 DEBUG TRAIN Batch 56/2600 loss 3.888516 loss_att 5.673895 loss_ctc 5.064275 loss_rnnt 3.287060 hw_loss 0.164272 lr 0.00028622 rank 4
2023-03-01 13:03:37,284 DEBUG TRAIN Batch 56/2600 loss 3.769713 loss_att 5.405379 loss_ctc 4.976719 loss_rnnt 3.198551 hw_loss 0.155803 lr 0.00028623 rank 0
2023-03-01 13:03:37,286 DEBUG TRAIN Batch 56/2600 loss 6.763618 loss_att 10.422807 loss_ctc 13.369278 loss_rnnt 5.150730 hw_loss 0.000553 lr 0.00028621 rank 1
2023-03-01 13:03:37,289 DEBUG TRAIN Batch 56/2600 loss 3.642680 loss_att 6.344165 loss_ctc 7.509751 loss_rnnt 2.451159 hw_loss 0.254276 lr 0.00028621 rank 7
2023-03-01 13:03:37,290 DEBUG TRAIN Batch 56/2600 loss 14.597535 loss_att 15.272897 loss_ctc 19.678066 loss_rnnt 13.687011 hw_loss 0.183841 lr 0.00028622 rank 5
2023-03-01 13:03:37,303 DEBUG TRAIN Batch 56/2600 loss 3.053443 loss_att 7.144997 loss_ctc 8.958624 loss_rnnt 1.259831 hw_loss 0.352393 lr 0.00028621 rank 3
2023-03-01 13:03:37,334 DEBUG TRAIN Batch 56/2600 loss 6.549472 loss_att 8.907400 loss_ctc 10.220583 loss_rnnt 5.384746 hw_loss 0.381862 lr 0.00028622 rank 6
2023-03-01 13:04:16,134 DEBUG TRAIN Batch 56/2700 loss 6.411835 loss_att 9.533117 loss_ctc 9.712013 loss_rnnt 5.297308 hw_loss 0.094212 lr 0.00028621 rank 5
2023-03-01 13:04:16,143 DEBUG TRAIN Batch 56/2700 loss 5.060832 loss_att 9.125417 loss_ctc 9.561907 loss_rnnt 3.494125 hw_loss 0.288086 lr 0.00028620 rank 1
2023-03-01 13:04:16,155 DEBUG TRAIN Batch 56/2700 loss 4.317601 loss_att 6.570554 loss_ctc 9.071198 loss_rnnt 3.128603 hw_loss 0.196113 lr 0.00028620 rank 7
2023-03-01 13:04:16,156 DEBUG TRAIN Batch 56/2700 loss 4.491529 loss_att 5.801992 loss_ctc 6.456770 loss_rnnt 3.918930 hw_loss 0.090890 lr 0.00028622 rank 0
2023-03-01 13:04:16,160 DEBUG TRAIN Batch 56/2700 loss 4.405497 loss_att 6.227643 loss_ctc 8.053246 loss_rnnt 3.436063 hw_loss 0.222445 lr 0.00028621 rank 6
2023-03-01 13:04:16,161 DEBUG TRAIN Batch 56/2700 loss 3.551097 loss_att 8.272768 loss_ctc 9.059305 loss_rnnt 1.823795 hw_loss 0.091013 lr 0.00028620 rank 3
2023-03-01 13:04:16,167 DEBUG TRAIN Batch 56/2700 loss 3.240157 loss_att 7.302766 loss_ctc 10.676673 loss_rnnt 1.392044 hw_loss 0.082605 lr 0.00028620 rank 4
2023-03-01 13:04:16,175 DEBUG TRAIN Batch 56/2700 loss 3.235774 loss_att 6.499827 loss_ctc 7.774520 loss_rnnt 1.900283 hw_loss 0.145339 lr 0.00028621 rank 2
2023-03-01 13:04:56,030 DEBUG TRAIN Batch 56/2800 loss 5.994645 loss_att 8.462855 loss_ctc 11.074916 loss_rnnt 4.796861 hw_loss 0.050198 lr 0.00028619 rank 4
2023-03-01 13:04:56,037 DEBUG TRAIN Batch 56/2800 loss 1.669833 loss_att 4.332696 loss_ctc 5.264341 loss_rnnt 0.572197 hw_loss 0.160866 lr 0.00028619 rank 5
2023-03-01 13:04:56,038 DEBUG TRAIN Batch 56/2800 loss 4.931399 loss_att 11.091951 loss_ctc 8.595630 loss_rnnt 3.105505 hw_loss 0.197286 lr 0.00028619 rank 3
2023-03-01 13:04:56,042 DEBUG TRAIN Batch 56/2800 loss 3.760805 loss_att 6.289032 loss_ctc 3.306633 loss_rnnt 3.231473 hw_loss 0.157953 lr 0.00028619 rank 1
2023-03-01 13:04:56,050 DEBUG TRAIN Batch 56/2800 loss 4.015543 loss_att 5.420911 loss_ctc 4.448334 loss_rnnt 3.564978 hw_loss 0.209597 lr 0.00028619 rank 7
2023-03-01 13:04:56,050 DEBUG TRAIN Batch 56/2800 loss 3.146431 loss_att 7.249382 loss_ctc 7.858906 loss_rnnt 1.602793 hw_loss 0.177595 lr 0.00028621 rank 0
2023-03-01 13:04:56,073 DEBUG TRAIN Batch 56/2800 loss 8.606902 loss_att 13.410607 loss_ctc 16.281843 loss_rnnt 6.496412 hw_loss 0.237042 lr 0.00028620 rank 2
2023-03-01 13:04:56,076 DEBUG TRAIN Batch 56/2800 loss 6.654145 loss_att 8.798101 loss_ctc 10.024203 loss_rnnt 5.639618 hw_loss 0.255738 lr 0.00028620 rank 6
2023-03-01 13:05:59,774 DEBUG TRAIN Batch 56/2900 loss 9.863114 loss_att 13.256442 loss_ctc 10.965391 loss_rnnt 8.937747 hw_loss 0.186998 lr 0.00028619 rank 6
2023-03-01 13:05:59,776 DEBUG TRAIN Batch 56/2900 loss 7.576610 loss_att 14.046047 loss_ctc 17.005150 loss_rnnt 4.921215 hw_loss 0.195691 lr 0.00028618 rank 1
2023-03-01 13:05:59,777 DEBUG TRAIN Batch 56/2900 loss 3.474825 loss_att 6.692634 loss_ctc 6.084292 loss_rnnt 2.371993 hw_loss 0.208765 lr 0.00028618 rank 7
2023-03-01 13:05:59,779 DEBUG TRAIN Batch 56/2900 loss 2.794077 loss_att 4.892141 loss_ctc 4.550001 loss_rnnt 2.029894 hw_loss 0.207087 lr 0.00028618 rank 5
2023-03-01 13:05:59,781 DEBUG TRAIN Batch 56/2900 loss 3.615174 loss_att 6.653481 loss_ctc 4.905688 loss_rnnt 2.775917 hw_loss 0.111613 lr 0.00028619 rank 0
2023-03-01 13:05:59,781 DEBUG TRAIN Batch 56/2900 loss 4.217249 loss_att 6.805575 loss_ctc 8.604079 loss_rnnt 2.995975 hw_loss 0.222559 lr 0.00028618 rank 2
2023-03-01 13:05:59,794 DEBUG TRAIN Batch 56/2900 loss 4.027532 loss_att 7.350673 loss_ctc 5.927170 loss_rnnt 2.998516 hw_loss 0.208317 lr 0.00028618 rank 3
2023-03-01 13:05:59,836 DEBUG TRAIN Batch 56/2900 loss 9.136808 loss_att 10.410213 loss_ctc 12.875216 loss_rnnt 8.242434 hw_loss 0.264825 lr 0.00028618 rank 4
2023-03-01 13:06:39,083 DEBUG TRAIN Batch 56/3000 loss 9.420386 loss_att 14.660514 loss_ctc 16.512844 loss_rnnt 7.354606 hw_loss 0.135177 lr 0.00028617 rank 4
2023-03-01 13:06:39,092 DEBUG TRAIN Batch 56/3000 loss 5.893583 loss_att 8.113567 loss_ctc 8.265830 loss_rnnt 5.062911 hw_loss 0.131954 lr 0.00028617 rank 1
2023-03-01 13:06:39,092 DEBUG TRAIN Batch 56/3000 loss 7.832368 loss_att 10.797440 loss_ctc 12.684532 loss_rnnt 6.537336 hw_loss 0.103242 lr 0.00028616 rank 3
2023-03-01 13:06:39,097 DEBUG TRAIN Batch 56/3000 loss 6.967573 loss_att 9.578051 loss_ctc 9.086445 loss_rnnt 6.050552 hw_loss 0.210767 lr 0.00028618 rank 0
2023-03-01 13:06:39,098 DEBUG TRAIN Batch 56/3000 loss 4.246212 loss_att 8.671228 loss_ctc 6.840345 loss_rnnt 2.891215 hw_loss 0.232704 lr 0.00028616 rank 7
2023-03-01 13:06:39,102 DEBUG TRAIN Batch 56/3000 loss 3.169135 loss_att 6.203758 loss_ctc 5.786233 loss_rnnt 2.101185 hw_loss 0.210148 lr 0.00028618 rank 6
2023-03-01 13:06:39,107 DEBUG TRAIN Batch 56/3000 loss 2.249305 loss_att 4.898085 loss_ctc 7.193181 loss_rnnt 1.000928 hw_loss 0.111444 lr 0.00028617 rank 5
2023-03-01 13:06:39,110 DEBUG TRAIN Batch 56/3000 loss 5.028103 loss_att 6.861307 loss_ctc 8.009522 loss_rnnt 4.181127 hw_loss 0.155275 lr 0.00028617 rank 2
2023-03-01 13:07:18,178 DEBUG TRAIN Batch 56/3100 loss 4.410253 loss_att 7.616821 loss_ctc 7.647468 loss_rnnt 3.241488 hw_loss 0.179667 lr 0.00028616 rank 4
2023-03-01 13:07:18,181 DEBUG TRAIN Batch 56/3100 loss 4.676276 loss_att 6.416090 loss_ctc 8.268227 loss_rnnt 3.778591 hw_loss 0.132741 lr 0.00028617 rank 0
2023-03-01 13:07:18,182 DEBUG TRAIN Batch 56/3100 loss 10.005968 loss_att 14.524866 loss_ctc 13.710617 loss_rnnt 8.466198 hw_loss 0.266318 lr 0.00028615 rank 3
2023-03-01 13:07:18,195 DEBUG TRAIN Batch 56/3100 loss 9.458925 loss_att 10.605387 loss_ctc 14.205192 loss_rnnt 8.498661 hw_loss 0.184003 lr 0.00028616 rank 5
2023-03-01 13:07:18,198 DEBUG TRAIN Batch 56/3100 loss 7.465295 loss_att 7.501578 loss_ctc 10.568210 loss_rnnt 6.836610 hw_loss 0.389450 lr 0.00028615 rank 1
2023-03-01 13:07:18,198 DEBUG TRAIN Batch 56/3100 loss 1.358644 loss_att 3.138563 loss_ctc 3.008093 loss_rnnt 0.659675 hw_loss 0.230736 lr 0.00028615 rank 7
2023-03-01 13:07:18,221 DEBUG TRAIN Batch 56/3100 loss 8.427204 loss_att 13.432847 loss_ctc 15.272243 loss_rnnt 6.456002 hw_loss 0.107628 lr 0.00028616 rank 6
2023-03-01 13:07:18,233 DEBUG TRAIN Batch 56/3100 loss 4.834116 loss_att 4.547684 loss_ctc 7.075755 loss_rnnt 4.444988 hw_loss 0.276618 lr 0.00028616 rank 2
2023-03-01 13:08:21,512 DEBUG TRAIN Batch 56/3200 loss 8.372076 loss_att 11.686945 loss_ctc 23.575081 loss_rnnt 5.524531 hw_loss 0.295320 lr 0.00028615 rank 6
2023-03-01 13:08:21,515 DEBUG TRAIN Batch 56/3200 loss 6.962083 loss_att 8.977195 loss_ctc 13.481518 loss_rnnt 5.600176 hw_loss 0.168050 lr 0.00028614 rank 7
2023-03-01 13:08:21,522 DEBUG TRAIN Batch 56/3200 loss 4.111877 loss_att 7.825983 loss_ctc 6.077938 loss_rnnt 3.051130 hw_loss 0.104597 lr 0.00028616 rank 0
2023-03-01 13:08:21,525 DEBUG TRAIN Batch 56/3200 loss 11.598458 loss_att 15.919996 loss_ctc 15.016466 loss_rnnt 10.192148 hw_loss 0.161752 lr 0.00028615 rank 2
2023-03-01 13:08:21,526 DEBUG TRAIN Batch 56/3200 loss 5.320122 loss_att 5.500086 loss_ctc 9.294698 loss_rnnt 4.579736 hw_loss 0.327093 lr 0.00028615 rank 5
2023-03-01 13:08:21,545 DEBUG TRAIN Batch 56/3200 loss 5.903942 loss_att 6.576079 loss_ctc 8.137115 loss_rnnt 5.323556 hw_loss 0.277876 lr 0.00028615 rank 4
2023-03-01 13:08:21,577 DEBUG TRAIN Batch 56/3200 loss 3.686962 loss_att 6.867893 loss_ctc 7.545462 loss_rnnt 2.405887 hw_loss 0.244542 lr 0.00028614 rank 1
2023-03-01 13:08:21,582 DEBUG TRAIN Batch 56/3200 loss 7.330364 loss_att 7.667377 loss_ctc 13.629223 loss_rnnt 6.259607 hw_loss 0.306575 lr 0.00028614 rank 3
2023-03-01 13:09:00,913 DEBUG TRAIN Batch 56/3300 loss 4.343240 loss_att 8.191343 loss_ctc 7.006168 loss_rnnt 3.097147 hw_loss 0.227654 lr 0.00028613 rank 7
2023-03-01 13:09:00,928 DEBUG TRAIN Batch 56/3300 loss 0.986305 loss_att 3.629105 loss_ctc 1.834934 loss_rnnt 0.279807 hw_loss 0.121477 lr 0.00028613 rank 4
2023-03-01 13:09:00,931 DEBUG TRAIN Batch 56/3300 loss 5.660052 loss_att 6.855962 loss_ctc 6.475852 loss_rnnt 5.199236 hw_loss 0.211613 lr 0.00028615 rank 0
2023-03-01 13:09:00,934 DEBUG TRAIN Batch 56/3300 loss 5.638066 loss_att 7.627078 loss_ctc 5.915170 loss_rnnt 5.116321 hw_loss 0.163118 lr 0.00028614 rank 5
2023-03-01 13:09:00,938 DEBUG TRAIN Batch 56/3300 loss 2.627455 loss_att 4.181380 loss_ctc 3.989243 loss_rnnt 1.951662 hw_loss 0.343943 lr 0.00028613 rank 3
2023-03-01 13:09:00,939 DEBUG TRAIN Batch 56/3300 loss 4.927335 loss_att 7.839423 loss_ctc 11.266978 loss_rnnt 3.421821 hw_loss 0.145895 lr 0.00028614 rank 2
2023-03-01 13:09:00,942 DEBUG TRAIN Batch 56/3300 loss 5.547604 loss_att 7.646388 loss_ctc 9.044724 loss_rnnt 4.593101 hw_loss 0.128369 lr 0.00028613 rank 1
2023-03-01 13:09:00,946 DEBUG TRAIN Batch 56/3300 loss 7.551008 loss_att 12.522379 loss_ctc 9.251822 loss_rnnt 6.228618 hw_loss 0.190014 lr 0.00028614 rank 6
2023-03-01 13:09:39,986 DEBUG TRAIN Batch 56/3400 loss 7.398994 loss_att 9.638735 loss_ctc 10.006250 loss_rnnt 6.569822 hw_loss 0.062981 lr 0.00028614 rank 0
2023-03-01 13:09:40,000 DEBUG TRAIN Batch 56/3400 loss 3.151115 loss_att 5.007620 loss_ctc 4.438172 loss_rnnt 2.480613 hw_loss 0.239238 lr 0.00028612 rank 5
2023-03-01 13:09:40,000 DEBUG TRAIN Batch 56/3400 loss 5.800983 loss_att 7.337171 loss_ctc 9.233835 loss_rnnt 4.929695 hw_loss 0.199381 lr 0.00028612 rank 7
2023-03-01 13:09:40,010 DEBUG TRAIN Batch 56/3400 loss 3.226173 loss_att 4.351690 loss_ctc 4.013156 loss_rnnt 2.744781 hw_loss 0.283795 lr 0.00028612 rank 3
2023-03-01 13:09:40,014 DEBUG TRAIN Batch 56/3400 loss 3.014498 loss_att 5.660697 loss_ctc 4.558683 loss_rnnt 2.213616 hw_loss 0.123281 lr 0.00028613 rank 6
2023-03-01 13:09:40,014 DEBUG TRAIN Batch 56/3400 loss 0.826502 loss_att 2.832455 loss_ctc 1.015776 loss_rnnt 0.276840 hw_loss 0.231066 lr 0.00028612 rank 4
2023-03-01 13:09:40,040 DEBUG TRAIN Batch 56/3400 loss 8.593564 loss_att 11.868752 loss_ctc 14.404757 loss_rnnt 7.003170 hw_loss 0.300995 lr 0.00028612 rank 1
2023-03-01 13:09:40,049 DEBUG TRAIN Batch 56/3400 loss 8.661063 loss_att 10.760255 loss_ctc 12.916487 loss_rnnt 7.596244 hw_loss 0.145484 lr 0.00028613 rank 2
2023-03-01 13:10:19,891 DEBUG TRAIN Batch 56/3500 loss 3.999621 loss_att 8.076928 loss_ctc 8.858381 loss_rnnt 2.373691 hw_loss 0.304939 lr 0.00028611 rank 5
2023-03-01 13:10:19,903 DEBUG TRAIN Batch 56/3500 loss 5.102738 loss_att 7.404630 loss_ctc 9.098053 loss_rnnt 4.034456 hw_loss 0.140991 lr 0.00028612 rank 0
2023-03-01 13:10:19,907 DEBUG TRAIN Batch 56/3500 loss 1.442468 loss_att 4.033496 loss_ctc 3.146775 loss_rnnt 0.541982 hw_loss 0.290700 lr 0.00028611 rank 7
2023-03-01 13:10:19,916 DEBUG TRAIN Batch 56/3500 loss 5.512650 loss_att 9.785745 loss_ctc 10.957431 loss_rnnt 3.827260 hw_loss 0.196501 lr 0.00028612 rank 6
2023-03-01 13:10:19,923 DEBUG TRAIN Batch 56/3500 loss 3.330278 loss_att 6.534777 loss_ctc 7.699302 loss_rnnt 1.972634 hw_loss 0.251640 lr 0.00028611 rank 4
2023-03-01 13:10:19,937 DEBUG TRAIN Batch 56/3500 loss 5.954279 loss_att 8.624263 loss_ctc 10.553787 loss_rnnt 4.651174 hw_loss 0.292201 lr 0.00028611 rank 1
2023-03-01 13:10:19,937 DEBUG TRAIN Batch 56/3500 loss 5.756889 loss_att 8.020119 loss_ctc 9.510336 loss_rnnt 4.673811 hw_loss 0.243697 lr 0.00028611 rank 2
2023-03-01 13:10:19,941 DEBUG TRAIN Batch 56/3500 loss 7.686644 loss_att 10.033973 loss_ctc 12.835964 loss_rnnt 6.484970 hw_loss 0.085560 lr 0.00028611 rank 3
2023-03-01 13:11:23,372 DEBUG TRAIN Batch 56/3600 loss 7.512379 loss_att 9.246307 loss_ctc 12.845455 loss_rnnt 6.301864 hw_loss 0.286224 lr 0.00028609 rank 7
2023-03-01 13:11:23,374 DEBUG TRAIN Batch 56/3600 loss 5.809845 loss_att 8.147444 loss_ctc 10.535920 loss_rnnt 4.546634 hw_loss 0.310405 lr 0.00028611 rank 0
2023-03-01 13:11:23,375 DEBUG TRAIN Batch 56/3600 loss 6.908075 loss_att 9.890751 loss_ctc 10.820621 loss_rnnt 5.672094 hw_loss 0.220826 lr 0.00028609 rank 3
2023-03-01 13:11:23,375 DEBUG TRAIN Batch 56/3600 loss 6.741696 loss_att 9.329227 loss_ctc 10.215435 loss_rnnt 5.593382 hw_loss 0.314329 lr 0.00028610 rank 2
2023-03-01 13:11:23,378 DEBUG TRAIN Batch 56/3600 loss 2.943308 loss_att 5.757032 loss_ctc 4.428068 loss_rnnt 1.984497 hw_loss 0.371434 lr 0.00028610 rank 1
2023-03-01 13:11:23,381 DEBUG TRAIN Batch 56/3600 loss 6.102082 loss_att 9.552711 loss_ctc 9.243315 loss_rnnt 4.910360 hw_loss 0.155184 lr 0.00028610 rank 5
2023-03-01 13:11:23,381 DEBUG TRAIN Batch 56/3600 loss 2.879254 loss_att 6.042006 loss_ctc 5.945196 loss_rnnt 1.731956 hw_loss 0.198667 lr 0.00028610 rank 4
2023-03-01 13:11:23,381 DEBUG TRAIN Batch 56/3600 loss 7.588852 loss_att 10.731136 loss_ctc 11.994986 loss_rnnt 6.242118 hw_loss 0.245237 lr 0.00028611 rank 6
2023-03-01 13:12:02,331 DEBUG TRAIN Batch 56/3700 loss 4.296756 loss_att 6.319656 loss_ctc 8.819620 loss_rnnt 3.103547 hw_loss 0.347962 lr 0.00028610 rank 0
2023-03-01 13:12:02,332 DEBUG TRAIN Batch 56/3700 loss 4.919754 loss_att 6.958096 loss_ctc 8.723063 loss_rnnt 3.871689 hw_loss 0.249914 lr 0.00028609 rank 5
2023-03-01 13:12:02,334 DEBUG TRAIN Batch 56/3700 loss 4.789409 loss_att 7.682280 loss_ctc 7.412718 loss_rnnt 3.738351 hw_loss 0.230080 lr 0.00028608 rank 7
2023-03-01 13:12:02,338 DEBUG TRAIN Batch 56/3700 loss 4.578385 loss_att 5.810475 loss_ctc 7.296565 loss_rnnt 3.805346 hw_loss 0.307871 lr 0.00028608 rank 1
2023-03-01 13:12:02,339 DEBUG TRAIN Batch 56/3700 loss 3.248279 loss_att 4.946910 loss_ctc 4.273405 loss_rnnt 2.578133 hw_loss 0.363255 lr 0.00028608 rank 3
2023-03-01 13:12:02,341 DEBUG TRAIN Batch 56/3700 loss 5.783629 loss_att 10.295399 loss_ctc 17.485033 loss_rnnt 3.180784 hw_loss 0.263071 lr 0.00028609 rank 4
2023-03-01 13:12:02,341 DEBUG TRAIN Batch 56/3700 loss 2.937347 loss_att 5.735703 loss_ctc 4.172301 loss_rnnt 2.108940 hw_loss 0.195140 lr 0.00028609 rank 6
2023-03-01 13:12:02,383 DEBUG TRAIN Batch 56/3700 loss 7.228381 loss_att 9.682678 loss_ctc 13.524595 loss_rnnt 5.748692 hw_loss 0.280003 lr 0.00028609 rank 2
2023-03-01 13:12:41,522 DEBUG TRAIN Batch 56/3800 loss 9.138906 loss_att 13.096742 loss_ctc 17.431280 loss_rnnt 7.132480 hw_loss 0.204771 lr 0.00028609 rank 0
2023-03-01 13:12:41,536 DEBUG TRAIN Batch 56/3800 loss 7.035785 loss_att 8.033491 loss_ctc 9.047335 loss_rnnt 6.440004 hw_loss 0.240061 lr 0.00028608 rank 5
2023-03-01 13:12:41,543 DEBUG TRAIN Batch 56/3800 loss 2.002252 loss_att 5.840839 loss_ctc 4.566166 loss_rnnt 0.795200 hw_loss 0.182774 lr 0.00028608 rank 2
2023-03-01 13:12:41,543 DEBUG TRAIN Batch 56/3800 loss 7.566720 loss_att 10.759737 loss_ctc 13.965969 loss_rnnt 5.942802 hw_loss 0.247651 lr 0.00028608 rank 4
2023-03-01 13:12:41,545 DEBUG TRAIN Batch 56/3800 loss 5.611897 loss_att 6.757196 loss_ctc 8.336146 loss_rnnt 4.902006 hw_loss 0.220497 lr 0.00028607 rank 3
2023-03-01 13:12:41,545 DEBUG TRAIN Batch 56/3800 loss 11.811485 loss_att 13.599045 loss_ctc 20.977207 loss_rnnt 10.086232 hw_loss 0.273082 lr 0.00028607 rank 7
2023-03-01 13:12:41,547 DEBUG TRAIN Batch 56/3800 loss 4.728677 loss_att 7.015256 loss_ctc 9.199298 loss_rnnt 3.578388 hw_loss 0.181670 lr 0.00028608 rank 6
2023-03-01 13:12:41,566 DEBUG TRAIN Batch 56/3800 loss 8.165940 loss_att 11.554919 loss_ctc 20.110998 loss_rnnt 5.769544 hw_loss 0.236111 lr 0.00028607 rank 1
2023-03-01 13:13:22,260 DEBUG TRAIN Batch 56/3900 loss 5.390702 loss_att 10.109887 loss_ctc 8.764741 loss_rnnt 3.883800 hw_loss 0.212237 lr 0.00028607 rank 2
2023-03-01 13:13:22,263 DEBUG TRAIN Batch 56/3900 loss 3.130716 loss_att 6.808727 loss_ctc 5.547668 loss_rnnt 2.024660 hw_loss 0.090363 lr 0.00028606 rank 7
2023-03-01 13:13:22,275 DEBUG TRAIN Batch 56/3900 loss 3.140698 loss_att 6.511299 loss_ctc 5.654678 loss_rnnt 2.031433 hw_loss 0.187403 lr 0.00028608 rank 0
2023-03-01 13:13:22,279 DEBUG TRAIN Batch 56/3900 loss 2.068541 loss_att 5.678619 loss_ctc 3.101161 loss_rnnt 1.031763 hw_loss 0.332024 lr 0.00028606 rank 5
2023-03-01 13:13:22,284 DEBUG TRAIN Batch 56/3900 loss 2.733381 loss_att 6.243013 loss_ctc 5.964651 loss_rnnt 1.507365 hw_loss 0.174851 lr 0.00028606 rank 4
2023-03-01 13:13:22,303 DEBUG TRAIN Batch 56/3900 loss 5.655050 loss_att 8.269730 loss_ctc 8.584627 loss_rnnt 4.653279 hw_loss 0.165420 lr 0.00028606 rank 3
2023-03-01 13:13:22,314 DEBUG TRAIN Batch 56/3900 loss 4.617507 loss_att 7.134082 loss_ctc 6.565269 loss_rnnt 3.785435 hw_loss 0.129479 lr 0.00028607 rank 6
2023-03-01 13:13:22,330 DEBUG TRAIN Batch 56/3900 loss 3.019257 loss_att 4.730008 loss_ctc 5.546263 loss_rnnt 2.168125 hw_loss 0.322589 lr 0.00028606 rank 1
2023-03-01 13:14:26,239 DEBUG TRAIN Batch 56/4000 loss 2.464957 loss_att 3.935091 loss_ctc 3.072330 loss_rnnt 1.981770 hw_loss 0.202833 lr 0.00028607 rank 0
2023-03-01 13:14:26,256 DEBUG TRAIN Batch 56/4000 loss 6.631325 loss_att 9.956952 loss_ctc 11.139397 loss_rnnt 5.291729 hw_loss 0.137613 lr 0.00028605 rank 7
2023-03-01 13:14:26,256 DEBUG TRAIN Batch 56/4000 loss 4.848596 loss_att 7.485105 loss_ctc 11.622541 loss_rnnt 3.303030 hw_loss 0.215757 lr 0.00028606 rank 2
2023-03-01 13:14:26,260 DEBUG TRAIN Batch 56/4000 loss 7.857389 loss_att 9.650663 loss_ctc 10.596205 loss_rnnt 6.990157 hw_loss 0.268879 lr 0.00028605 rank 3
2023-03-01 13:14:26,260 DEBUG TRAIN Batch 56/4000 loss 7.087077 loss_att 9.022130 loss_ctc 10.210273 loss_rnnt 6.190827 hw_loss 0.174022 lr 0.00028605 rank 4
2023-03-01 13:14:26,261 DEBUG TRAIN Batch 56/4000 loss 3.705527 loss_att 5.299735 loss_ctc 6.587016 loss_rnnt 2.817463 hw_loss 0.346920 lr 0.00028605 rank 1
2023-03-01 13:14:26,262 DEBUG TRAIN Batch 56/4000 loss 11.305769 loss_att 16.033604 loss_ctc 17.172588 loss_rnnt 9.507442 hw_loss 0.132219 lr 0.00028606 rank 6
2023-03-01 13:14:26,281 DEBUG TRAIN Batch 56/4000 loss 10.210521 loss_att 12.389241 loss_ctc 12.472937 loss_rnnt 9.371759 hw_loss 0.190052 lr 0.00028605 rank 5
2023-03-01 13:15:05,920 DEBUG TRAIN Batch 56/4100 loss 5.099511 loss_att 8.042986 loss_ctc 9.871719 loss_rnnt 3.753138 hw_loss 0.227595 lr 0.00028604 rank 1
2023-03-01 13:15:05,922 DEBUG TRAIN Batch 56/4100 loss 6.845329 loss_att 11.049317 loss_ctc 11.728279 loss_rnnt 5.218691 hw_loss 0.252712 lr 0.00028605 rank 0
2023-03-01 13:15:05,924 DEBUG TRAIN Batch 56/4100 loss 2.642223 loss_att 4.902280 loss_ctc 4.460299 loss_rnnt 1.899351 hw_loss 0.090845 lr 0.00028604 rank 7
2023-03-01 13:15:05,927 DEBUG TRAIN Batch 56/4100 loss 6.122977 loss_att 8.823816 loss_ctc 10.036761 loss_rnnt 4.968618 hw_loss 0.173162 lr 0.00028605 rank 6
2023-03-01 13:15:05,929 DEBUG TRAIN Batch 56/4100 loss 4.706868 loss_att 9.611682 loss_ctc 9.788965 loss_rnnt 2.819701 hw_loss 0.428609 lr 0.00028604 rank 4
2023-03-01 13:15:05,930 DEBUG TRAIN Batch 56/4100 loss 4.399420 loss_att 8.837704 loss_ctc 8.797010 loss_rnnt 2.760670 hw_loss 0.308902 lr 0.00028604 rank 5
2023-03-01 13:15:05,929 DEBUG TRAIN Batch 56/4100 loss 8.435040 loss_att 10.837308 loss_ctc 10.612778 loss_rnnt 7.595603 hw_loss 0.128659 lr 0.00028603 rank 3
2023-03-01 13:15:05,938 DEBUG TRAIN Batch 56/4100 loss 9.865014 loss_att 12.710499 loss_ctc 12.564310 loss_rnnt 8.850339 hw_loss 0.160634 lr 0.00028604 rank 2
2023-03-01 13:15:45,151 DEBUG TRAIN Batch 56/4200 loss 8.343838 loss_att 12.573365 loss_ctc 11.535262 loss_rnnt 6.980784 hw_loss 0.171797 lr 0.00028603 rank 4
2023-03-01 13:15:45,153 DEBUG TRAIN Batch 56/4200 loss 10.864779 loss_att 13.057911 loss_ctc 16.439188 loss_rnnt 9.552495 hw_loss 0.244505 lr 0.00028602 rank 1
2023-03-01 13:15:45,156 DEBUG TRAIN Batch 56/4200 loss 5.693489 loss_att 9.396498 loss_ctc 10.558683 loss_rnnt 4.218959 hw_loss 0.159814 lr 0.00028603 rank 6
2023-03-01 13:15:45,157 DEBUG TRAIN Batch 56/4200 loss 4.475133 loss_att 7.964192 loss_ctc 6.923795 loss_rnnt 3.323421 hw_loss 0.238897 lr 0.00028602 rank 3
2023-03-01 13:15:45,161 DEBUG TRAIN Batch 56/4200 loss 10.253963 loss_att 12.634460 loss_ctc 15.530716 loss_rnnt 8.969222 hw_loss 0.197014 lr 0.00028603 rank 5
2023-03-01 13:15:45,163 DEBUG TRAIN Batch 56/4200 loss 5.738788 loss_att 8.884323 loss_ctc 9.852977 loss_rnnt 4.511223 hw_loss 0.093562 lr 0.00028602 rank 7
2023-03-01 13:15:45,165 DEBUG TRAIN Batch 56/4200 loss 13.881385 loss_att 17.363068 loss_ctc 20.131157 loss_rnnt 12.245703 hw_loss 0.198830 lr 0.00028604 rank 0
2023-03-01 13:15:45,183 DEBUG TRAIN Batch 56/4200 loss 3.445819 loss_att 6.687966 loss_ctc 6.223613 loss_rnnt 2.401037 hw_loss 0.048712 lr 0.00028603 rank 2
2023-03-01 13:16:49,062 DEBUG TRAIN Batch 56/4300 loss 4.790592 loss_att 6.930667 loss_ctc 6.417101 loss_rnnt 4.034172 hw_loss 0.209130 lr 0.00028603 rank 0
2023-03-01 13:16:49,079 DEBUG TRAIN Batch 56/4300 loss 8.595046 loss_att 11.048392 loss_ctc 10.598711 loss_rnnt 7.725021 hw_loss 0.210376 lr 0.00028602 rank 2
2023-03-01 13:16:49,079 DEBUG TRAIN Batch 56/4300 loss 11.519213 loss_att 13.484799 loss_ctc 21.086258 loss_rnnt 9.772122 hw_loss 0.146937 lr 0.00028601 rank 1
2023-03-01 13:16:49,080 DEBUG TRAIN Batch 56/4300 loss 7.413084 loss_att 9.463166 loss_ctc 18.324310 loss_rnnt 5.479581 hw_loss 0.128731 lr 0.00028602 rank 5
2023-03-01 13:16:49,081 DEBUG TRAIN Batch 56/4300 loss 2.314047 loss_att 4.948349 loss_ctc 3.916153 loss_rnnt 1.461312 hw_loss 0.210488 lr 0.00028601 rank 7
2023-03-01 13:16:49,081 DEBUG TRAIN Batch 56/4300 loss 6.424749 loss_att 8.580056 loss_ctc 12.783877 loss_rnnt 5.064255 hw_loss 0.152905 lr 0.00028602 rank 4
2023-03-01 13:16:49,086 DEBUG TRAIN Batch 56/4300 loss 6.507627 loss_att 8.731778 loss_ctc 10.090840 loss_rnnt 5.470964 hw_loss 0.213884 lr 0.00028601 rank 3
2023-03-01 13:16:49,105 DEBUG TRAIN Batch 56/4300 loss 3.087992 loss_att 5.909990 loss_ctc 4.390044 loss_rnnt 2.262615 hw_loss 0.163821 lr 0.00028602 rank 6
2023-03-01 13:17:28,296 DEBUG TRAIN Batch 56/4400 loss 4.055219 loss_att 5.342488 loss_ctc 6.483337 loss_rnnt 3.355969 hw_loss 0.221337 lr 0.00028601 rank 5
2023-03-01 13:17:28,307 DEBUG TRAIN Batch 56/4400 loss 2.331765 loss_att 5.320263 loss_ctc 5.261776 loss_rnnt 1.186523 hw_loss 0.294140 lr 0.00028600 rank 7
2023-03-01 13:17:28,308 DEBUG TRAIN Batch 56/4400 loss 5.436443 loss_att 5.843969 loss_ctc 7.189023 loss_rnnt 4.974056 hw_loss 0.276009 lr 0.00028602 rank 0
2023-03-01 13:17:28,309 DEBUG TRAIN Batch 56/4400 loss 6.006354 loss_att 12.026328 loss_ctc 13.787154 loss_rnnt 3.645767 hw_loss 0.223411 lr 0.00028601 rank 2
2023-03-01 13:17:28,311 DEBUG TRAIN Batch 56/4400 loss 1.601535 loss_att 4.708977 loss_ctc 4.080565 loss_rnnt 0.490203 hw_loss 0.298700 lr 0.00028600 rank 1
2023-03-01 13:17:28,319 DEBUG TRAIN Batch 56/4400 loss 3.142423 loss_att 6.339890 loss_ctc 3.709107 loss_rnnt 2.331339 hw_loss 0.180062 lr 0.00028600 rank 3
2023-03-01 13:17:28,322 DEBUG TRAIN Batch 56/4400 loss 3.647182 loss_att 6.045739 loss_ctc 7.342204 loss_rnnt 2.638836 hw_loss 0.067433 lr 0.00028601 rank 6
2023-03-01 13:17:28,340 DEBUG TRAIN Batch 56/4400 loss 6.491929 loss_att 8.811797 loss_ctc 7.546562 loss_rnnt 5.738312 hw_loss 0.279423 lr 0.00028600 rank 4
2023-03-01 13:18:07,815 DEBUG TRAIN Batch 56/4500 loss 5.492471 loss_att 10.439282 loss_ctc 9.433883 loss_rnnt 3.929126 hw_loss 0.090865 lr 0.00028600 rank 2
2023-03-01 13:18:07,825 DEBUG TRAIN Batch 56/4500 loss 3.009056 loss_att 7.023677 loss_ctc 3.859953 loss_rnnt 1.921885 hw_loss 0.320237 lr 0.00028601 rank 0
2023-03-01 13:18:07,830 DEBUG TRAIN Batch 56/4500 loss 9.152028 loss_att 11.951583 loss_ctc 16.090057 loss_rnnt 7.515169 hw_loss 0.284769 lr 0.00028599 rank 5
2023-03-01 13:18:07,833 DEBUG TRAIN Batch 56/4500 loss 10.685266 loss_att 16.479813 loss_ctc 15.104986 loss_rnnt 8.848688 hw_loss 0.165700 lr 0.00028599 rank 4
2023-03-01 13:18:07,833 DEBUG TRAIN Batch 56/4500 loss 5.124911 loss_att 7.706675 loss_ctc 9.249852 loss_rnnt 3.924865 hw_loss 0.250690 lr 0.00028599 rank 7
2023-03-01 13:18:07,833 DEBUG TRAIN Batch 56/4500 loss 4.882144 loss_att 7.000210 loss_ctc 7.742712 loss_rnnt 3.941636 hw_loss 0.254036 lr 0.00028599 rank 3
2023-03-01 13:18:07,862 DEBUG TRAIN Batch 56/4500 loss 1.724924 loss_att 6.025356 loss_ctc 4.610844 loss_rnnt 0.340554 hw_loss 0.261551 lr 0.00028599 rank 1
2023-03-01 13:18:07,876 DEBUG TRAIN Batch 56/4500 loss 2.715107 loss_att 3.481523 loss_ctc 4.467412 loss_rnnt 2.185423 hw_loss 0.267677 lr 0.00028600 rank 6
2023-03-01 13:18:47,940 DEBUG TRAIN Batch 56/4600 loss 4.578654 loss_att 8.544910 loss_ctc 8.115633 loss_rnnt 3.258068 hw_loss 0.104508 lr 0.00028598 rank 1
2023-03-01 13:18:47,953 DEBUG TRAIN Batch 56/4600 loss 4.746187 loss_att 8.668774 loss_ctc 6.835992 loss_rnnt 3.653569 hw_loss 0.055238 lr 0.00028598 rank 5
2023-03-01 13:18:47,955 DEBUG TRAIN Batch 56/4600 loss 6.589949 loss_att 11.533708 loss_ctc 12.455647 loss_rnnt 4.705726 hw_loss 0.212584 lr 0.00028599 rank 6
2023-03-01 13:18:47,959 DEBUG TRAIN Batch 56/4600 loss 1.442662 loss_att 3.835335 loss_ctc 4.081491 loss_rnnt 0.484417 hw_loss 0.239749 lr 0.00028598 rank 4
2023-03-01 13:18:47,960 DEBUG TRAIN Batch 56/4600 loss 6.759156 loss_att 9.702044 loss_ctc 10.439565 loss_rnnt 5.596271 hw_loss 0.156725 lr 0.00028598 rank 7
2023-03-01 13:18:47,960 DEBUG TRAIN Batch 56/4600 loss 3.650418 loss_att 7.888088 loss_ctc 6.413343 loss_rnnt 2.291865 hw_loss 0.267430 lr 0.00028598 rank 3
2023-03-01 13:18:47,961 DEBUG TRAIN Batch 56/4600 loss 3.842984 loss_att 8.651299 loss_ctc 6.780456 loss_rnnt 2.431935 hw_loss 0.108231 lr 0.00028599 rank 2
2023-03-01 13:18:47,961 DEBUG TRAIN Batch 56/4600 loss 2.670717 loss_att 5.275165 loss_ctc 5.737605 loss_rnnt 1.706453 hw_loss 0.064606 lr 0.00028600 rank 0
2023-03-01 13:19:51,795 DEBUG TRAIN Batch 56/4700 loss 5.578820 loss_att 8.092347 loss_ctc 8.667258 loss_rnnt 4.604929 hw_loss 0.111363 lr 0.00028597 rank 5
2023-03-01 13:19:51,798 DEBUG TRAIN Batch 56/4700 loss 2.216321 loss_att 4.967769 loss_ctc 3.088520 loss_rnnt 1.431353 hw_loss 0.221973 lr 0.00028597 rank 2
2023-03-01 13:19:51,809 DEBUG TRAIN Batch 56/4700 loss 9.363855 loss_att 11.155200 loss_ctc 19.539238 loss_rnnt 7.493122 hw_loss 0.292024 lr 0.00028597 rank 7
2023-03-01 13:19:51,813 DEBUG TRAIN Batch 56/4700 loss 4.801322 loss_att 6.956833 loss_ctc 7.139193 loss_rnnt 3.979529 hw_loss 0.148077 lr 0.00028598 rank 0
2023-03-01 13:19:51,818 DEBUG TRAIN Batch 56/4700 loss 3.637169 loss_att 5.359974 loss_ctc 8.017746 loss_rnnt 2.530136 hw_loss 0.334492 lr 0.00028596 rank 3
2023-03-01 13:19:51,818 DEBUG TRAIN Batch 56/4700 loss 7.313112 loss_att 9.821474 loss_ctc 15.227461 loss_rnnt 5.618207 hw_loss 0.258723 lr 0.00028598 rank 6
2023-03-01 13:19:51,819 DEBUG TRAIN Batch 56/4700 loss 5.180727 loss_att 9.014641 loss_ctc 10.055703 loss_rnnt 3.656465 hw_loss 0.201531 lr 0.00028597 rank 1
2023-03-01 13:19:51,821 DEBUG TRAIN Batch 56/4700 loss 2.719555 loss_att 6.473045 loss_ctc 9.774446 loss_rnnt 0.930850 hw_loss 0.182541 lr 0.00028597 rank 4
2023-03-01 13:20:30,664 DEBUG TRAIN Batch 56/4800 loss 8.062213 loss_att 11.915558 loss_ctc 12.088141 loss_rnnt 6.635004 hw_loss 0.224531 lr 0.00028597 rank 0
2023-03-01 13:20:30,668 DEBUG TRAIN Batch 56/4800 loss 9.859449 loss_att 14.762637 loss_ctc 16.677092 loss_rnnt 7.927467 hw_loss 0.079361 lr 0.00028595 rank 7
2023-03-01 13:20:30,672 DEBUG TRAIN Batch 56/4800 loss 11.031725 loss_att 14.755682 loss_ctc 19.581776 loss_rnnt 9.078302 hw_loss 0.128670 lr 0.00028596 rank 4
2023-03-01 13:20:30,675 DEBUG TRAIN Batch 56/4800 loss 2.966039 loss_att 4.130503 loss_ctc 3.439743 loss_rnnt 2.441710 hw_loss 0.428017 lr 0.00028595 rank 1
2023-03-01 13:20:30,675 DEBUG TRAIN Batch 56/4800 loss 6.761988 loss_att 8.110321 loss_ctc 8.757889 loss_rnnt 6.194217 hw_loss 0.059970 lr 0.00028596 rank 2
2023-03-01 13:20:30,673 DEBUG TRAIN Batch 56/4800 loss 8.853864 loss_att 12.307908 loss_ctc 18.207756 loss_rnnt 6.790756 hw_loss 0.234588 lr 0.00028596 rank 5
2023-03-01 13:20:30,678 DEBUG TRAIN Batch 56/4800 loss 5.143359 loss_att 7.120713 loss_ctc 10.083307 loss_rnnt 3.998323 hw_loss 0.170447 lr 0.00028595 rank 3
2023-03-01 13:20:30,718 DEBUG TRAIN Batch 56/4800 loss 9.165811 loss_att 11.243864 loss_ctc 13.858028 loss_rnnt 8.044174 hw_loss 0.150744 lr 0.00028596 rank 6
2023-03-01 13:21:09,780 DEBUG TRAIN Batch 56/4900 loss 2.692133 loss_att 4.815872 loss_ctc 4.788831 loss_rnnt 1.796503 hw_loss 0.358729 lr 0.00028594 rank 1
2023-03-01 13:21:09,783 DEBUG TRAIN Batch 56/4900 loss 1.946538 loss_att 5.106364 loss_ctc 2.613273 loss_rnnt 1.072451 hw_loss 0.287296 lr 0.00028594 rank 7
2023-03-01 13:21:09,785 DEBUG TRAIN Batch 56/4900 loss 5.446179 loss_att 7.968348 loss_ctc 7.783760 loss_rnnt 4.512029 hw_loss 0.221323 lr 0.00028595 rank 4
2023-03-01 13:21:09,797 DEBUG TRAIN Batch 56/4900 loss 7.608863 loss_att 10.859865 loss_ctc 16.509195 loss_rnnt 5.641493 hw_loss 0.244611 lr 0.00028596 rank 0
2023-03-01 13:21:09,798 DEBUG TRAIN Batch 56/4900 loss 3.600733 loss_att 7.982705 loss_ctc 10.017551 loss_rnnt 1.745698 hw_loss 0.230746 lr 0.00028595 rank 5
2023-03-01 13:21:09,800 DEBUG TRAIN Batch 56/4900 loss 14.432661 loss_att 17.453205 loss_ctc 22.984196 loss_rnnt 12.563536 hw_loss 0.234023 lr 0.00028594 rank 3
2023-03-01 13:21:09,800 DEBUG TRAIN Batch 56/4900 loss 5.386906 loss_att 8.277539 loss_ctc 8.427348 loss_rnnt 4.288213 hw_loss 0.215951 lr 0.00028595 rank 2
2023-03-01 13:21:09,811 DEBUG TRAIN Batch 56/4900 loss 3.296939 loss_att 5.740744 loss_ctc 9.744580 loss_rnnt 1.801168 hw_loss 0.276234 lr 0.00028595 rank 6
2023-03-01 13:22:15,016 DEBUG TRAIN Batch 56/5000 loss 3.616846 loss_att 5.180981 loss_ctc 5.866590 loss_rnnt 2.854964 hw_loss 0.279541 lr 0.00028593 rank 7
2023-03-01 13:22:15,020 DEBUG TRAIN Batch 56/5000 loss 3.927469 loss_att 5.514888 loss_ctc 5.913470 loss_rnnt 3.236203 hw_loss 0.204342 lr 0.00028593 rank 4
2023-03-01 13:22:15,023 DEBUG TRAIN Batch 56/5000 loss 2.765736 loss_att 4.820079 loss_ctc 4.651765 loss_rnnt 1.965792 hw_loss 0.258009 lr 0.00028595 rank 0
2023-03-01 13:22:15,025 DEBUG TRAIN Batch 56/5000 loss 8.196873 loss_att 8.523087 loss_ctc 10.643994 loss_rnnt 7.638817 hw_loss 0.312243 lr 0.00028593 rank 1
2023-03-01 13:22:15,024 DEBUG TRAIN Batch 56/5000 loss 2.243031 loss_att 6.281209 loss_ctc 4.221263 loss_rnnt 1.046846 hw_loss 0.233972 lr 0.00028594 rank 6
2023-03-01 13:22:15,027 DEBUG TRAIN Batch 56/5000 loss 11.416956 loss_att 13.189341 loss_ctc 14.280664 loss_rnnt 10.519829 hw_loss 0.301542 lr 0.00028594 rank 5
2023-03-01 13:22:15,053 DEBUG TRAIN Batch 56/5000 loss 3.952363 loss_att 9.087528 loss_ctc 5.854413 loss_rnnt 2.617762 hw_loss 0.101177 lr 0.00028593 rank 3
2023-03-01 13:22:15,081 DEBUG TRAIN Batch 56/5000 loss 6.399012 loss_att 11.819570 loss_ctc 15.299419 loss_rnnt 4.053603 hw_loss 0.139830 lr 0.00028594 rank 2
2023-03-01 13:22:53,862 DEBUG TRAIN Batch 56/5100 loss 3.823995 loss_att 5.327287 loss_ctc 4.608669 loss_rnnt 3.237350 hw_loss 0.340055 lr 0.00028594 rank 0
2023-03-01 13:22:53,866 DEBUG TRAIN Batch 56/5100 loss 3.880515 loss_att 6.729027 loss_ctc 6.825862 loss_rnnt 2.767419 hw_loss 0.282527 lr 0.00028592 rank 1
2023-03-01 13:22:53,866 DEBUG TRAIN Batch 56/5100 loss 3.569744 loss_att 6.475124 loss_ctc 6.369406 loss_rnnt 2.468787 hw_loss 0.274860 lr 0.00028593 rank 2
2023-03-01 13:22:53,869 DEBUG TRAIN Batch 56/5100 loss 7.003155 loss_att 9.518045 loss_ctc 9.914804 loss_rnnt 6.013683 hw_loss 0.184264 lr 0.00028592 rank 7
2023-03-01 13:22:53,869 DEBUG TRAIN Batch 56/5100 loss 5.051812 loss_att 7.273088 loss_ctc 10.196097 loss_rnnt 3.810748 hw_loss 0.207945 lr 0.00028593 rank 6
2023-03-01 13:22:53,871 DEBUG TRAIN Batch 56/5100 loss 5.667813 loss_att 8.600301 loss_ctc 11.269212 loss_rnnt 4.198150 hw_loss 0.255586 lr 0.00028592 rank 4
2023-03-01 13:22:53,871 DEBUG TRAIN Batch 56/5100 loss 6.673014 loss_att 10.124254 loss_ctc 12.974031 loss_rnnt 5.042555 hw_loss 0.187641 lr 0.00028592 rank 5
2023-03-01 13:22:53,874 DEBUG TRAIN Batch 56/5100 loss 9.463312 loss_att 12.082774 loss_ctc 15.476549 loss_rnnt 8.034817 hw_loss 0.192822 lr 0.00028592 rank 3
2023-03-01 13:23:32,768 DEBUG TRAIN Batch 56/5200 loss 3.337387 loss_att 3.515317 loss_ctc 5.648624 loss_rnnt 2.892639 hw_loss 0.189369 lr 0.00028591 rank 5
2023-03-01 13:23:32,778 DEBUG TRAIN Batch 56/5200 loss 13.294118 loss_att 13.584027 loss_ctc 20.598976 loss_rnnt 12.093692 hw_loss 0.315869 lr 0.00028591 rank 7
2023-03-01 13:23:32,778 DEBUG TRAIN Batch 56/5200 loss 5.453512 loss_att 8.812799 loss_ctc 9.944996 loss_rnnt 4.043448 hw_loss 0.261266 lr 0.00028591 rank 1
2023-03-01 13:23:32,781 DEBUG TRAIN Batch 56/5200 loss 3.569318 loss_att 4.611266 loss_ctc 4.428923 loss_rnnt 3.048316 hw_loss 0.371248 lr 0.00028592 rank 2
2023-03-01 13:23:32,788 DEBUG TRAIN Batch 56/5200 loss 4.687591 loss_att 7.790432 loss_ctc 9.367470 loss_rnnt 3.351250 hw_loss 0.172104 lr 0.00028591 rank 3
2023-03-01 13:23:32,789 DEBUG TRAIN Batch 56/5200 loss 6.400375 loss_att 10.979268 loss_ctc 11.102644 loss_rnnt 4.701253 hw_loss 0.293202 lr 0.00028592 rank 0
2023-03-01 13:23:32,790 DEBUG TRAIN Batch 56/5200 loss 3.732656 loss_att 6.802246 loss_ctc 7.221879 loss_rnnt 2.599869 hw_loss 0.100573 lr 0.00028591 rank 4
2023-03-01 13:23:32,808 DEBUG TRAIN Batch 56/5200 loss 5.661883 loss_att 6.577077 loss_ctc 10.456868 loss_rnnt 4.701153 hw_loss 0.259424 lr 0.00028592 rank 6
2023-03-01 13:24:13,019 DEBUG TRAIN Batch 56/5300 loss 4.930346 loss_att 6.895509 loss_ctc 7.309553 loss_rnnt 4.117389 hw_loss 0.192559 lr 0.00028589 rank 7
2023-03-01 13:24:13,021 DEBUG TRAIN Batch 56/5300 loss 1.719205 loss_att 5.157185 loss_ctc 5.240002 loss_rnnt 0.443419 hw_loss 0.222659 lr 0.00028590 rank 4
2023-03-01 13:24:13,023 DEBUG TRAIN Batch 56/5300 loss 5.405694 loss_att 8.219488 loss_ctc 7.473843 loss_rnnt 4.473394 hw_loss 0.175854 lr 0.00028591 rank 0
2023-03-01 13:24:13,037 DEBUG TRAIN Batch 56/5300 loss 9.165051 loss_att 13.631517 loss_ctc 10.321810 loss_rnnt 8.004785 hw_loss 0.211385 lr 0.00028589 rank 3
2023-03-01 13:24:13,041 DEBUG TRAIN Batch 56/5300 loss 3.364561 loss_att 5.390557 loss_ctc 5.198647 loss_rnnt 2.580585 hw_loss 0.251684 lr 0.00028590 rank 2
2023-03-01 13:24:13,041 DEBUG TRAIN Batch 56/5300 loss 3.957379 loss_att 7.052702 loss_ctc 6.678654 loss_rnnt 2.868938 hw_loss 0.199763 lr 0.00028590 rank 5
2023-03-01 13:24:13,054 DEBUG TRAIN Batch 56/5300 loss 5.569685 loss_att 9.909809 loss_ctc 7.364490 loss_rnnt 4.329942 hw_loss 0.248270 lr 0.00028591 rank 6
2023-03-01 13:24:13,062 DEBUG TRAIN Batch 56/5300 loss 10.117851 loss_att 13.585520 loss_ctc 15.570564 loss_rnnt 8.557180 hw_loss 0.262705 lr 0.00028590 rank 1
2023-03-01 13:25:18,600 DEBUG TRAIN Batch 56/5400 loss 4.669024 loss_att 9.543592 loss_ctc 9.025332 loss_rnnt 3.030822 hw_loss 0.154589 lr 0.00028589 rank 4
2023-03-01 13:25:18,600 DEBUG TRAIN Batch 56/5400 loss 5.489951 loss_att 8.187494 loss_ctc 10.150702 loss_rnnt 4.178679 hw_loss 0.281868 lr 0.00028589 rank 2
2023-03-01 13:25:18,601 DEBUG TRAIN Batch 56/5400 loss 2.159948 loss_att 4.709525 loss_ctc 3.716994 loss_rnnt 1.426039 hw_loss 0.030727 lr 0.00028588 rank 3
2023-03-01 13:25:18,602 DEBUG TRAIN Batch 56/5400 loss 2.847804 loss_att 4.735887 loss_ctc 3.276380 loss_rnnt 2.296608 hw_loss 0.218315 lr 0.00028588 rank 1
2023-03-01 13:25:18,610 DEBUG TRAIN Batch 56/5400 loss 8.054279 loss_att 9.278801 loss_ctc 16.885986 loss_rnnt 6.565739 hw_loss 0.123889 lr 0.00028590 rank 0
2023-03-01 13:25:18,610 DEBUG TRAIN Batch 56/5400 loss 2.539384 loss_att 4.236635 loss_ctc 4.345144 loss_rnnt 1.852945 hw_loss 0.199164 lr 0.00028588 rank 7
2023-03-01 13:25:18,615 DEBUG TRAIN Batch 56/5400 loss 6.408346 loss_att 7.458857 loss_ctc 12.671073 loss_rnnt 5.201983 hw_loss 0.302307 lr 0.00028589 rank 6
2023-03-01 13:25:18,626 DEBUG TRAIN Batch 56/5400 loss 2.769918 loss_att 5.983459 loss_ctc 5.251160 loss_rnnt 1.698588 hw_loss 0.183356 lr 0.00028589 rank 5
2023-03-01 13:25:57,375 DEBUG TRAIN Batch 56/5500 loss 10.304749 loss_att 12.119029 loss_ctc 15.185623 loss_rnnt 9.214701 hw_loss 0.143267 lr 0.00028588 rank 4
2023-03-01 13:25:57,386 DEBUG TRAIN Batch 56/5500 loss 2.745587 loss_att 4.434759 loss_ctc 3.334177 loss_rnnt 2.154945 hw_loss 0.326866 lr 0.00028587 rank 1
2023-03-01 13:25:57,392 DEBUG TRAIN Batch 56/5500 loss 2.063893 loss_att 5.977878 loss_ctc 5.916853 loss_rnnt 0.702019 hw_loss 0.122529 lr 0.00028587 rank 3
2023-03-01 13:25:57,392 DEBUG TRAIN Batch 56/5500 loss 9.021500 loss_att 10.579606 loss_ctc 17.900599 loss_rnnt 7.427978 hw_loss 0.183790 lr 0.00028588 rank 5
2023-03-01 13:25:57,393 DEBUG TRAIN Batch 56/5500 loss 4.220116 loss_att 6.140277 loss_ctc 6.462387 loss_rnnt 3.387710 hw_loss 0.280131 lr 0.00028588 rank 2
2023-03-01 13:25:57,404 DEBUG TRAIN Batch 56/5500 loss 6.090693 loss_att 8.318663 loss_ctc 9.287149 loss_rnnt 5.120153 hw_loss 0.185162 lr 0.00028589 rank 0
2023-03-01 13:25:57,407 DEBUG TRAIN Batch 56/5500 loss 8.679832 loss_att 10.908783 loss_ctc 13.486333 loss_rnnt 7.448023 hw_loss 0.272159 lr 0.00028587 rank 7
2023-03-01 13:25:57,440 DEBUG TRAIN Batch 56/5500 loss 8.843036 loss_att 10.113284 loss_ctc 14.016180 loss_rnnt 7.777727 hw_loss 0.227824 lr 0.00028588 rank 6
2023-03-01 13:26:37,014 DEBUG TRAIN Batch 56/5600 loss 6.580664 loss_att 8.721513 loss_ctc 12.390207 loss_rnnt 5.269999 hw_loss 0.202293 lr 0.00028586 rank 4
2023-03-01 13:26:37,017 DEBUG TRAIN Batch 56/5600 loss 8.869074 loss_att 11.898258 loss_ctc 11.615108 loss_rnnt 7.802697 hw_loss 0.177005 lr 0.00028586 rank 7
2023-03-01 13:26:37,017 DEBUG TRAIN Batch 56/5600 loss 5.616571 loss_att 8.226468 loss_ctc 8.246288 loss_rnnt 4.641874 hw_loss 0.191418 lr 0.00028588 rank 0
2023-03-01 13:26:37,018 DEBUG TRAIN Batch 56/5600 loss 5.740602 loss_att 8.295448 loss_ctc 13.261133 loss_rnnt 4.107582 hw_loss 0.223714 lr 0.00028586 rank 1
2023-03-01 13:26:37,019 DEBUG TRAIN Batch 56/5600 loss 7.938739 loss_att 11.135849 loss_ctc 14.189499 loss_rnnt 6.355464 hw_loss 0.207034 lr 0.00028586 rank 3
2023-03-01 13:26:37,020 DEBUG TRAIN Batch 56/5600 loss 2.038540 loss_att 4.265538 loss_ctc 5.275496 loss_rnnt 1.075969 hw_loss 0.160457 lr 0.00028587 rank 6
2023-03-01 13:26:37,047 DEBUG TRAIN Batch 56/5600 loss 9.770760 loss_att 10.866686 loss_ctc 14.041328 loss_rnnt 8.808489 hw_loss 0.325642 lr 0.00028587 rank 2
2023-03-01 13:26:37,051 DEBUG TRAIN Batch 56/5600 loss 6.587662 loss_att 8.621442 loss_ctc 9.459879 loss_rnnt 5.688395 hw_loss 0.205404 lr 0.00028587 rank 5
2023-03-01 13:27:40,483 DEBUG TRAIN Batch 56/5700 loss 8.310903 loss_att 10.176619 loss_ctc 13.568209 loss_rnnt 7.111898 hw_loss 0.234163 lr 0.00028585 rank 7
2023-03-01 13:27:40,487 DEBUG TRAIN Batch 56/5700 loss 6.679663 loss_att 9.524104 loss_ctc 11.230986 loss_rnnt 5.375842 hw_loss 0.240168 lr 0.00028585 rank 5
2023-03-01 13:27:40,487 DEBUG TRAIN Batch 56/5700 loss 2.977250 loss_att 6.850050 loss_ctc 8.719206 loss_rnnt 1.303304 hw_loss 0.250861 lr 0.00028585 rank 1
2023-03-01 13:27:40,489 DEBUG TRAIN Batch 56/5700 loss 7.199080 loss_att 7.583317 loss_ctc 9.881507 loss_rnnt 6.637671 hw_loss 0.237946 lr 0.00028585 rank 4
2023-03-01 13:27:40,489 DEBUG TRAIN Batch 56/5700 loss 10.391810 loss_att 14.633456 loss_ctc 16.362310 loss_rnnt 8.712633 hw_loss 0.065215 lr 0.00028586 rank 2
2023-03-01 13:27:40,489 DEBUG TRAIN Batch 56/5700 loss 8.568945 loss_att 12.452394 loss_ctc 17.407417 loss_rnnt 6.493135 hw_loss 0.226232 lr 0.00028587 rank 0
2023-03-01 13:27:40,494 DEBUG TRAIN Batch 56/5700 loss 6.358168 loss_att 6.723284 loss_ctc 11.920218 loss_rnnt 5.381010 hw_loss 0.304742 lr 0.00028585 rank 3
2023-03-01 13:27:40,552 DEBUG TRAIN Batch 56/5700 loss 7.390250 loss_att 9.530770 loss_ctc 14.567693 loss_rnnt 6.004919 hw_loss 0.000441 lr 0.00028586 rank 6
2023-03-01 13:28:19,954 DEBUG TRAIN Batch 56/5800 loss 5.861102 loss_att 6.257198 loss_ctc 13.211374 loss_rnnt 4.746020 hw_loss 0.104675 lr 0.00028584 rank 3
2023-03-01 13:28:19,955 DEBUG TRAIN Batch 56/5800 loss 8.039468 loss_att 10.580190 loss_ctc 12.832573 loss_rnnt 6.813349 hw_loss 0.147926 lr 0.00028584 rank 4
2023-03-01 13:28:19,966 DEBUG TRAIN Batch 56/5800 loss 6.414895 loss_att 8.534234 loss_ctc 10.276251 loss_rnnt 5.371179 hw_loss 0.196875 lr 0.00028584 rank 7
2023-03-01 13:28:19,967 DEBUG TRAIN Batch 56/5800 loss 2.558886 loss_att 5.449995 loss_ctc 3.501662 loss_rnnt 1.736289 hw_loss 0.222511 lr 0.00028584 rank 1
2023-03-01 13:28:19,969 DEBUG TRAIN Batch 56/5800 loss 3.967775 loss_att 7.237099 loss_ctc 5.778889 loss_rnnt 2.975908 hw_loss 0.180976 lr 0.00028585 rank 0
2023-03-01 13:28:19,969 DEBUG TRAIN Batch 56/5800 loss 6.293292 loss_att 8.059644 loss_ctc 9.969034 loss_rnnt 5.319400 hw_loss 0.244731 lr 0.00028584 rank 2
2023-03-01 13:28:19,977 DEBUG TRAIN Batch 56/5800 loss 5.192635 loss_att 7.289084 loss_ctc 10.887633 loss_rnnt 3.849572 hw_loss 0.308324 lr 0.00028585 rank 6
2023-03-01 13:28:19,979 DEBUG TRAIN Batch 56/5800 loss 3.458806 loss_att 5.085264 loss_ctc 5.201189 loss_rnnt 2.780067 hw_loss 0.227117 lr 0.00028584 rank 5
2023-03-01 13:28:59,121 DEBUG TRAIN Batch 56/5900 loss 2.241987 loss_att 4.349689 loss_ctc 4.602858 loss_rnnt 1.413653 hw_loss 0.172522 lr 0.00028583 rank 1
2023-03-01 13:28:59,129 DEBUG TRAIN Batch 56/5900 loss 2.575617 loss_att 5.938716 loss_ctc 6.270864 loss_rnnt 1.314712 hw_loss 0.179223 lr 0.00028582 rank 3
2023-03-01 13:28:59,139 DEBUG TRAIN Batch 56/5900 loss 6.189909 loss_att 9.378428 loss_ctc 11.136045 loss_rnnt 4.691362 hw_loss 0.377547 lr 0.00028584 rank 0
2023-03-01 13:28:59,140 DEBUG TRAIN Batch 56/5900 loss 4.104403 loss_att 9.020765 loss_ctc 7.252286 loss_rnnt 2.552593 hw_loss 0.279037 lr 0.00028582 rank 7
2023-03-01 13:28:59,150 DEBUG TRAIN Batch 56/5900 loss 5.287942 loss_att 7.689478 loss_ctc 10.762104 loss_rnnt 3.931070 hw_loss 0.275018 lr 0.00028583 rank 2
2023-03-01 13:28:59,169 DEBUG TRAIN Batch 56/5900 loss 15.637867 loss_att 16.623549 loss_ctc 21.077103 loss_rnnt 14.605268 hw_loss 0.206684 lr 0.00028583 rank 4
2023-03-01 13:28:59,173 DEBUG TRAIN Batch 56/5900 loss 5.257072 loss_att 6.287714 loss_ctc 6.770690 loss_rnnt 4.758985 hw_loss 0.169017 lr 0.00028584 rank 6
2023-03-01 13:28:59,193 DEBUG TRAIN Batch 56/5900 loss 3.723178 loss_att 6.212336 loss_ctc 5.908662 loss_rnnt 2.843915 hw_loss 0.168812 lr 0.00028583 rank 5
2023-03-01 13:29:38,931 DEBUG TRAIN Batch 56/6000 loss 3.651098 loss_att 6.398669 loss_ctc 7.063964 loss_rnnt 2.585431 hw_loss 0.114571 lr 0.00028582 rank 4
2023-03-01 13:29:38,934 DEBUG TRAIN Batch 56/6000 loss 10.933328 loss_att 15.886298 loss_ctc 13.836910 loss_rnnt 9.475718 hw_loss 0.149759 lr 0.00028581 rank 3
2023-03-01 13:29:38,942 DEBUG TRAIN Batch 56/6000 loss 3.831637 loss_att 4.952009 loss_ctc 6.126404 loss_rnnt 3.200944 hw_loss 0.188718 lr 0.00028582 rank 6
2023-03-01 13:29:38,942 DEBUG TRAIN Batch 56/6000 loss 10.650644 loss_att 13.055220 loss_ctc 13.346769 loss_rnnt 9.712386 hw_loss 0.183486 lr 0.00028581 rank 1
2023-03-01 13:29:38,944 DEBUG TRAIN Batch 56/6000 loss 9.063734 loss_att 10.708736 loss_ctc 13.284509 loss_rnnt 8.014469 hw_loss 0.295301 lr 0.00028582 rank 2
2023-03-01 13:29:38,943 DEBUG TRAIN Batch 56/6000 loss 8.541463 loss_att 13.273539 loss_ctc 11.709337 loss_rnnt 7.049059 hw_loss 0.231759 lr 0.00028583 rank 0
2023-03-01 13:29:38,943 DEBUG TRAIN Batch 56/6000 loss 3.850025 loss_att 8.772690 loss_ctc 5.831330 loss_rnnt 2.508321 hw_loss 0.174370 lr 0.00028581 rank 7
2023-03-01 13:29:38,975 DEBUG TRAIN Batch 56/6000 loss 8.067245 loss_att 9.105913 loss_ctc 11.372635 loss_rnnt 7.307802 hw_loss 0.208105 lr 0.00028582 rank 5
2023-03-01 13:30:43,593 DEBUG TRAIN Batch 56/6100 loss 8.115539 loss_att 10.448276 loss_ctc 14.069686 loss_rnnt 6.757986 hw_loss 0.182099 lr 0.00028580 rank 7
2023-03-01 13:30:43,594 DEBUG TRAIN Batch 56/6100 loss 4.831266 loss_att 8.798508 loss_ctc 10.865623 loss_rnnt 3.149745 hw_loss 0.156547 lr 0.00028582 rank 0
2023-03-01 13:30:43,595 DEBUG TRAIN Batch 56/6100 loss 6.559128 loss_att 8.627632 loss_ctc 11.296642 loss_rnnt 5.372299 hw_loss 0.265236 lr 0.00028581 rank 2
2023-03-01 13:30:43,597 DEBUG TRAIN Batch 56/6100 loss 2.848416 loss_att 7.175146 loss_ctc 6.506987 loss_rnnt 1.418072 hw_loss 0.144729 lr 0.00028580 rank 3
2023-03-01 13:30:43,601 DEBUG TRAIN Batch 56/6100 loss 4.793137 loss_att 8.307646 loss_ctc 5.529556 loss_rnnt 3.854764 hw_loss 0.257404 lr 0.00028581 rank 5
2023-03-01 13:30:43,606 DEBUG TRAIN Batch 56/6100 loss 4.611951 loss_att 6.721661 loss_ctc 6.147383 loss_rnnt 3.877817 hw_loss 0.201502 lr 0.00028580 rank 1
2023-03-01 13:30:43,621 DEBUG TRAIN Batch 56/6100 loss 4.746658 loss_att 8.222128 loss_ctc 8.439245 loss_rnnt 3.452508 hw_loss 0.200083 lr 0.00028581 rank 6
2023-03-01 13:30:43,654 DEBUG TRAIN Batch 56/6100 loss 5.808654 loss_att 7.386212 loss_ctc 10.550440 loss_rnnt 4.775044 hw_loss 0.160989 lr 0.00028581 rank 4
2023-03-01 13:31:22,272 DEBUG TRAIN Batch 56/6200 loss 3.108205 loss_att 5.924124 loss_ctc 4.849531 loss_rnnt 2.130834 hw_loss 0.341270 lr 0.00028581 rank 0
2023-03-01 13:31:22,292 DEBUG TRAIN Batch 56/6200 loss 5.887733 loss_att 7.833190 loss_ctc 11.756332 loss_rnnt 4.596184 hw_loss 0.224956 lr 0.00028579 rank 7
2023-03-01 13:31:22,293 DEBUG TRAIN Batch 56/6200 loss 4.856761 loss_att 6.645894 loss_ctc 5.884319 loss_rnnt 4.245781 hw_loss 0.217770 lr 0.00028580 rank 5
2023-03-01 13:31:22,296 DEBUG TRAIN Batch 56/6200 loss 5.376254 loss_att 6.945716 loss_ctc 6.458581 loss_rnnt 4.847526 hw_loss 0.132233 lr 0.00028579 rank 4
2023-03-01 13:31:22,298 DEBUG TRAIN Batch 56/6200 loss 6.965022 loss_att 10.533548 loss_ctc 14.624563 loss_rnnt 5.129341 hw_loss 0.188817 lr 0.00028579 rank 3
2023-03-01 13:31:22,299 DEBUG TRAIN Batch 56/6200 loss 4.162622 loss_att 5.760847 loss_ctc 9.336800 loss_rnnt 2.996201 hw_loss 0.294160 lr 0.00028580 rank 2
2023-03-01 13:31:22,299 DEBUG TRAIN Batch 56/6200 loss 1.873364 loss_att 4.340035 loss_ctc 3.873561 loss_rnnt 1.019413 hw_loss 0.176106 lr 0.00028580 rank 6
2023-03-01 13:31:22,341 DEBUG TRAIN Batch 56/6200 loss 4.125713 loss_att 6.029762 loss_ctc 7.710620 loss_rnnt 3.047886 hw_loss 0.410681 lr 0.00028579 rank 1
2023-03-01 13:32:01,352 DEBUG TRAIN Batch 56/6300 loss 4.423385 loss_att 7.263581 loss_ctc 10.185388 loss_rnnt 2.967026 hw_loss 0.225100 lr 0.00028578 rank 5
2023-03-01 13:32:01,357 DEBUG TRAIN Batch 56/6300 loss 5.403850 loss_att 8.083586 loss_ctc 8.277436 loss_rnnt 4.386361 hw_loss 0.184494 lr 0.00028579 rank 6
2023-03-01 13:32:01,361 DEBUG TRAIN Batch 56/6300 loss 3.867790 loss_att 6.188772 loss_ctc 6.541719 loss_rnnt 2.944065 hw_loss 0.193135 lr 0.00028578 rank 3
2023-03-01 13:32:01,363 DEBUG TRAIN Batch 56/6300 loss 5.383448 loss_att 7.747746 loss_ctc 9.471487 loss_rnnt 4.210983 hw_loss 0.289747 lr 0.00028578 rank 7
2023-03-01 13:32:01,364 DEBUG TRAIN Batch 56/6300 loss 5.011152 loss_att 5.382872 loss_ctc 9.768826 loss_rnnt 4.134559 hw_loss 0.314798 lr 0.00028580 rank 0
2023-03-01 13:32:01,366 DEBUG TRAIN Batch 56/6300 loss 5.853709 loss_att 8.617628 loss_ctc 7.684669 loss_rnnt 5.031114 hw_loss 0.048156 lr 0.00028578 rank 1
2023-03-01 13:32:01,366 DEBUG TRAIN Batch 56/6300 loss 5.513141 loss_att 8.602874 loss_ctc 10.745882 loss_rnnt 4.160339 hw_loss 0.069668 lr 0.00028579 rank 2
2023-03-01 13:32:01,373 DEBUG TRAIN Batch 56/6300 loss 10.054064 loss_att 10.312597 loss_ctc 12.306922 loss_rnnt 9.524376 hw_loss 0.333001 lr 0.00028578 rank 4
2023-03-01 13:33:04,432 DEBUG TRAIN Batch 56/6400 loss 4.661016 loss_att 7.897478 loss_ctc 10.355534 loss_rnnt 3.085174 hw_loss 0.317401 lr 0.00028577 rank 2
2023-03-01 13:33:04,438 DEBUG TRAIN Batch 56/6400 loss 3.038129 loss_att 6.085268 loss_ctc 5.668346 loss_rnnt 2.019725 hw_loss 0.109275 lr 0.00028578 rank 0
2023-03-01 13:33:04,439 DEBUG TRAIN Batch 56/6400 loss 4.524227 loss_att 7.218146 loss_ctc 7.723783 loss_rnnt 3.394630 hw_loss 0.307885 lr 0.00028577 rank 7
2023-03-01 13:33:04,442 DEBUG TRAIN Batch 56/6400 loss 6.699574 loss_att 9.143425 loss_ctc 8.866777 loss_rnnt 5.797094 hw_loss 0.233907 lr 0.00028577 rank 1
2023-03-01 13:33:04,444 DEBUG TRAIN Batch 56/6400 loss 2.179312 loss_att 4.756888 loss_ctc 3.448740 loss_rnnt 1.357238 hw_loss 0.257439 lr 0.00028577 rank 3
2023-03-01 13:33:04,445 DEBUG TRAIN Batch 56/6400 loss 6.131392 loss_att 8.239773 loss_ctc 8.994236 loss_rnnt 5.188802 hw_loss 0.261002 lr 0.00028577 rank 5
2023-03-01 13:33:04,466 DEBUG TRAIN Batch 56/6400 loss 5.525318 loss_att 7.548722 loss_ctc 9.950281 loss_rnnt 4.393565 hw_loss 0.257018 lr 0.00028578 rank 6
2023-03-01 13:33:04,491 DEBUG TRAIN Batch 56/6400 loss 6.149627 loss_att 11.781032 loss_ctc 12.903511 loss_rnnt 3.961212 hw_loss 0.303032 lr 0.00028577 rank 4
2023-03-01 13:33:44,536 DEBUG TRAIN Batch 56/6500 loss 6.360748 loss_att 10.050070 loss_ctc 12.679726 loss_rnnt 4.679217 hw_loss 0.189629 lr 0.00028576 rank 4
2023-03-01 13:33:44,536 DEBUG TRAIN Batch 56/6500 loss 3.049132 loss_att 5.271557 loss_ctc 4.417381 loss_rnnt 2.335599 hw_loss 0.162403 lr 0.00028576 rank 2
2023-03-01 13:33:44,539 DEBUG TRAIN Batch 56/6500 loss 2.372913 loss_att 6.009073 loss_ctc 4.024130 loss_rnnt 1.291236 hw_loss 0.251779 lr 0.00028577 rank 0
2023-03-01 13:33:44,539 DEBUG TRAIN Batch 56/6500 loss 8.594611 loss_att 9.229308 loss_ctc 13.091535 loss_rnnt 7.698019 hw_loss 0.318868 lr 0.00028575 rank 7
2023-03-01 13:33:44,539 DEBUG TRAIN Batch 56/6500 loss 1.485557 loss_att 4.335097 loss_ctc 4.076124 loss_rnnt 0.502499 hw_loss 0.127015 lr 0.00028576 rank 5
2023-03-01 13:33:44,544 DEBUG TRAIN Batch 56/6500 loss 3.555195 loss_att 5.865797 loss_ctc 4.714881 loss_rnnt 2.798853 hw_loss 0.261746 lr 0.00028576 rank 1
2023-03-01 13:33:44,545 DEBUG TRAIN Batch 56/6500 loss 5.604502 loss_att 9.163883 loss_ctc 8.813108 loss_rnnt 4.411599 hw_loss 0.099773 lr 0.00028577 rank 6
2023-03-01 13:33:44,592 DEBUG TRAIN Batch 56/6500 loss 0.774240 loss_att 2.869857 loss_ctc 1.641437 loss_rnnt 0.178603 hw_loss 0.114163 lr 0.00028575 rank 3
2023-03-01 13:34:23,326 DEBUG TRAIN Batch 56/6600 loss 7.936796 loss_att 10.777708 loss_ctc 17.146965 loss_rnnt 6.078049 hw_loss 0.117268 lr 0.00028574 rank 7
2023-03-01 13:34:23,331 DEBUG TRAIN Batch 56/6600 loss 7.241283 loss_att 9.082266 loss_ctc 10.247889 loss_rnnt 6.353311 hw_loss 0.222928 lr 0.00028574 rank 3
2023-03-01 13:34:23,339 DEBUG TRAIN Batch 56/6600 loss 5.799128 loss_att 9.604515 loss_ctc 11.469589 loss_rnnt 4.212351 hw_loss 0.130570 lr 0.00028576 rank 0
2023-03-01 13:34:23,341 DEBUG TRAIN Batch 56/6600 loss 2.623142 loss_att 5.272589 loss_ctc 5.463305 loss_rnnt 1.620261 hw_loss 0.176819 lr 0.00028575 rank 2
2023-03-01 13:34:23,342 DEBUG TRAIN Batch 56/6600 loss 7.283607 loss_att 13.569973 loss_ctc 12.682457 loss_rnnt 5.094098 hw_loss 0.398230 lr 0.00028575 rank 4
2023-03-01 13:34:23,344 DEBUG TRAIN Batch 56/6600 loss 4.576433 loss_att 6.335754 loss_ctc 7.051034 loss_rnnt 3.802495 hw_loss 0.172737 lr 0.00028574 rank 1
2023-03-01 13:34:23,348 DEBUG TRAIN Batch 56/6600 loss 18.581875 loss_att 22.915392 loss_ctc 26.455368 loss_rnnt 16.612778 hw_loss 0.098613 lr 0.00028575 rank 6
2023-03-01 13:34:23,358 DEBUG TRAIN Batch 56/6600 loss 7.455752 loss_att 8.688964 loss_ctc 10.062669 loss_rnnt 6.766660 hw_loss 0.177864 lr 0.00028575 rank 5
2023-03-01 13:35:03,025 DEBUG TRAIN Batch 56/6700 loss 3.688506 loss_att 5.518357 loss_ctc 7.130139 loss_rnnt 2.750786 hw_loss 0.211624 lr 0.00028574 rank 5
2023-03-01 13:35:03,032 DEBUG TRAIN Batch 56/6700 loss 3.156615 loss_att 6.217029 loss_ctc 5.181655 loss_rnnt 2.113598 hw_loss 0.301740 lr 0.00028574 rank 2
2023-03-01 13:35:03,040 DEBUG TRAIN Batch 56/6700 loss 1.436875 loss_att 3.517483 loss_ctc 2.090590 loss_rnnt 0.757663 hw_loss 0.329865 lr 0.00028573 rank 7
2023-03-01 13:35:03,040 DEBUG TRAIN Batch 56/6700 loss 12.151752 loss_att 16.103487 loss_ctc 26.941597 loss_rnnt 9.234339 hw_loss 0.290789 lr 0.00028575 rank 0
2023-03-01 13:35:03,040 DEBUG TRAIN Batch 56/6700 loss 6.944334 loss_att 10.778934 loss_ctc 11.648737 loss_rnnt 5.494001 hw_loss 0.105300 lr 0.00028573 rank 3
2023-03-01 13:35:03,041 DEBUG TRAIN Batch 56/6700 loss 5.678410 loss_att 10.125672 loss_ctc 11.061018 loss_rnnt 3.898705 hw_loss 0.323571 lr 0.00028574 rank 4
2023-03-01 13:35:03,049 DEBUG TRAIN Batch 56/6700 loss 3.861071 loss_att 5.649959 loss_ctc 9.398438 loss_rnnt 2.608134 hw_loss 0.294082 lr 0.00028573 rank 1
2023-03-01 13:35:03,070 DEBUG TRAIN Batch 56/6700 loss 6.038442 loss_att 11.094477 loss_ctc 13.742790 loss_rnnt 3.918009 hw_loss 0.153710 lr 0.00028574 rank 6
2023-03-01 13:36:06,532 DEBUG TRAIN Batch 56/6800 loss 6.977354 loss_att 11.914666 loss_ctc 13.759689 loss_rnnt 5.032538 hw_loss 0.099453 lr 0.00028573 rank 6
2023-03-01 13:36:06,544 DEBUG TRAIN Batch 56/6800 loss 4.922380 loss_att 6.759904 loss_ctc 6.601945 loss_rnnt 4.252510 hw_loss 0.147045 lr 0.00028574 rank 0
2023-03-01 13:36:06,548 DEBUG TRAIN Batch 56/6800 loss 4.950676 loss_att 7.469764 loss_ctc 8.259527 loss_rnnt 3.931109 hw_loss 0.139817 lr 0.00028572 rank 7
2023-03-01 13:36:06,554 DEBUG TRAIN Batch 56/6800 loss 5.702726 loss_att 9.420683 loss_ctc 11.564460 loss_rnnt 4.106349 hw_loss 0.133540 lr 0.00028573 rank 5
2023-03-01 13:36:06,562 DEBUG TRAIN Batch 56/6800 loss 7.310967 loss_att 9.969000 loss_ctc 11.859715 loss_rnnt 6.105271 hw_loss 0.126730 lr 0.00028572 rank 4
2023-03-01 13:36:06,566 DEBUG TRAIN Batch 56/6800 loss 7.317493 loss_att 10.893660 loss_ctc 13.535848 loss_rnnt 5.617668 hw_loss 0.291522 lr 0.00028572 rank 3
2023-03-01 13:36:06,569 DEBUG TRAIN Batch 56/6800 loss 4.384178 loss_att 6.683185 loss_ctc 6.790160 loss_rnnt 3.501600 hw_loss 0.191212 lr 0.00028572 rank 1
2023-03-01 13:36:06,606 DEBUG TRAIN Batch 56/6800 loss 8.180406 loss_att 9.681347 loss_ctc 10.805812 loss_rnnt 7.415114 hw_loss 0.215717 lr 0.00028573 rank 2
2023-03-01 13:36:46,010 DEBUG TRAIN Batch 56/6900 loss 7.147227 loss_att 11.423158 loss_ctc 11.297191 loss_rnnt 5.706857 hw_loss 0.059728 lr 0.00028572 rank 2
2023-03-01 13:36:46,010 DEBUG TRAIN Batch 56/6900 loss 16.491600 loss_att 18.343117 loss_ctc 23.803020 loss_rnnt 15.022385 hw_loss 0.232602 lr 0.00028571 rank 3
2023-03-01 13:36:46,010 DEBUG TRAIN Batch 56/6900 loss 3.761861 loss_att 7.401179 loss_ctc 8.108793 loss_rnnt 2.255295 hw_loss 0.373334 lr 0.00028571 rank 5
2023-03-01 13:36:46,023 DEBUG TRAIN Batch 56/6900 loss 8.441485 loss_att 9.812219 loss_ctc 13.460541 loss_rnnt 7.327502 hw_loss 0.319928 lr 0.00028573 rank 0
2023-03-01 13:36:46,024 DEBUG TRAIN Batch 56/6900 loss 1.771684 loss_att 3.420811 loss_ctc 2.346087 loss_rnnt 1.241695 hw_loss 0.231705 lr 0.00028571 rank 7
2023-03-01 13:36:46,024 DEBUG TRAIN Batch 56/6900 loss 5.675626 loss_att 7.928847 loss_ctc 7.469959 loss_rnnt 4.783010 hw_loss 0.380114 lr 0.00028572 rank 6
2023-03-01 13:36:46,028 DEBUG TRAIN Batch 56/6900 loss 3.036904 loss_att 5.311203 loss_ctc 5.019418 loss_rnnt 2.182557 hw_loss 0.253408 lr 0.00028571 rank 4
2023-03-01 13:36:46,032 DEBUG TRAIN Batch 56/6900 loss 3.601126 loss_att 9.733986 loss_ctc 10.907381 loss_rnnt 1.400270 hw_loss 0.000220 lr 0.00028571 rank 1
2023-03-01 13:37:24,904 DEBUG TRAIN Batch 56/7000 loss 1.562797 loss_att 6.242318 loss_ctc 3.924821 loss_rnnt 0.265587 hw_loss 0.086943 lr 0.00028570 rank 2
2023-03-01 13:37:24,907 DEBUG TRAIN Batch 56/7000 loss 7.441334 loss_att 9.595360 loss_ctc 9.271164 loss_rnnt 6.703625 hw_loss 0.117988 lr 0.00028570 rank 7
2023-03-01 13:37:24,907 DEBUG TRAIN Batch 56/7000 loss 7.281324 loss_att 9.733817 loss_ctc 11.754203 loss_rnnt 6.020028 hw_loss 0.327026 lr 0.00028571 rank 6
2023-03-01 13:37:24,916 DEBUG TRAIN Batch 56/7000 loss 3.509754 loss_att 5.396090 loss_ctc 4.231899 loss_rnnt 2.895696 hw_loss 0.263446 lr 0.00028570 rank 3
2023-03-01 13:37:24,928 DEBUG TRAIN Batch 56/7000 loss 8.228946 loss_att 14.329367 loss_ctc 20.311089 loss_rnnt 5.341844 hw_loss 0.105122 lr 0.00028570 rank 4
2023-03-01 13:37:24,931 DEBUG TRAIN Batch 56/7000 loss 6.847779 loss_att 10.209970 loss_ctc 13.168811 loss_rnnt 5.237352 hw_loss 0.178470 lr 0.00028570 rank 1
2023-03-01 13:37:24,933 DEBUG TRAIN Batch 56/7000 loss 2.805403 loss_att 8.197849 loss_ctc 6.803848 loss_rnnt 1.147470 hw_loss 0.086846 lr 0.00028571 rank 0
2023-03-01 13:37:24,974 DEBUG TRAIN Batch 56/7000 loss 7.423702 loss_att 10.664996 loss_ctc 13.141541 loss_rnnt 5.958539 hw_loss 0.102236 lr 0.00028570 rank 5
2023-03-01 13:38:28,735 DEBUG TRAIN Batch 56/7100 loss 2.765347 loss_att 5.259212 loss_ctc 6.732418 loss_rnnt 1.567126 hw_loss 0.319698 lr 0.00028569 rank 4
2023-03-01 13:38:28,738 DEBUG TRAIN Batch 56/7100 loss 4.249189 loss_att 6.481979 loss_ctc 4.939714 loss_rnnt 3.660783 hw_loss 0.093335 lr 0.00028569 rank 2
2023-03-01 13:38:28,744 DEBUG TRAIN Batch 56/7100 loss 4.732316 loss_att 8.207876 loss_ctc 6.818488 loss_rnnt 3.622741 hw_loss 0.255575 lr 0.00028570 rank 0
2023-03-01 13:38:28,749 DEBUG TRAIN Batch 56/7100 loss 6.258654 loss_att 7.952931 loss_ctc 13.587253 loss_rnnt 4.841737 hw_loss 0.189216 lr 0.00028569 rank 1
2023-03-01 13:38:28,751 DEBUG TRAIN Batch 56/7100 loss 7.145433 loss_att 10.175423 loss_ctc 7.989330 loss_rnnt 6.248032 hw_loss 0.335408 lr 0.00028568 rank 7
2023-03-01 13:38:28,772 DEBUG TRAIN Batch 56/7100 loss 5.290711 loss_att 5.910856 loss_ctc 8.302927 loss_rnnt 4.585622 hw_loss 0.336435 lr 0.00028568 rank 3
2023-03-01 13:38:28,787 DEBUG TRAIN Batch 56/7100 loss 11.213974 loss_att 10.780767 loss_ctc 16.040562 loss_rnnt 10.513424 hw_loss 0.269337 lr 0.00028569 rank 5
2023-03-01 13:38:28,789 DEBUG TRAIN Batch 56/7100 loss 5.464878 loss_att 7.692904 loss_ctc 7.708934 loss_rnnt 4.538051 hw_loss 0.341277 lr 0.00028570 rank 6
2023-03-01 13:39:10,887 DEBUG TRAIN Batch 56/7200 loss 6.470207 loss_att 11.475641 loss_ctc 16.438610 loss_rnnt 4.043171 hw_loss 0.181553 lr 0.00028568 rank 2
2023-03-01 13:39:10,887 DEBUG TRAIN Batch 56/7200 loss 4.737703 loss_att 6.552003 loss_ctc 5.404285 loss_rnnt 4.118600 hw_loss 0.313811 lr 0.00028568 rank 6
2023-03-01 13:39:10,890 DEBUG TRAIN Batch 56/7200 loss 14.298471 loss_att 17.118946 loss_ctc 24.312628 loss_rnnt 12.337379 hw_loss 0.115828 lr 0.00028568 rank 4
2023-03-01 13:39:10,891 DEBUG TRAIN Batch 56/7200 loss 8.220221 loss_att 11.904061 loss_ctc 11.221621 loss_rnnt 6.988078 hw_loss 0.178477 lr 0.00028567 rank 7
2023-03-01 13:39:10,894 DEBUG TRAIN Batch 56/7200 loss 10.892994 loss_att 12.652067 loss_ctc 19.795029 loss_rnnt 9.248072 hw_loss 0.199068 lr 0.00028567 rank 1
2023-03-01 13:39:10,895 DEBUG TRAIN Batch 56/7200 loss 3.915728 loss_att 6.820925 loss_ctc 6.235338 loss_rnnt 2.968711 hw_loss 0.106306 lr 0.00028569 rank 0
2023-03-01 13:39:10,899 DEBUG TRAIN Batch 56/7200 loss 2.262305 loss_att 5.007772 loss_ctc 7.278342 loss_rnnt 0.908762 hw_loss 0.254335 lr 0.00028567 rank 3
2023-03-01 13:39:10,909 DEBUG TRAIN Batch 56/7200 loss 3.824173 loss_att 5.446970 loss_ctc 6.491241 loss_rnnt 3.063537 hw_loss 0.150876 lr 0.00028568 rank 5
2023-03-01 13:39:50,052 DEBUG TRAIN Batch 56/7300 loss 6.615839 loss_att 8.872790 loss_ctc 9.420404 loss_rnnt 5.653524 hw_loss 0.256843 lr 0.00028568 rank 0
2023-03-01 13:39:50,059 DEBUG TRAIN Batch 56/7300 loss 5.907320 loss_att 9.238055 loss_ctc 9.229785 loss_rnnt 4.714607 hw_loss 0.156694 lr 0.00028566 rank 7
2023-03-01 13:39:50,060 DEBUG TRAIN Batch 56/7300 loss 7.237611 loss_att 10.260787 loss_ctc 11.127930 loss_rnnt 5.986554 hw_loss 0.239461 lr 0.00028567 rank 5
2023-03-01 13:39:50,060 DEBUG TRAIN Batch 56/7300 loss 3.533132 loss_att 6.673822 loss_ctc 6.742290 loss_rnnt 2.379473 hw_loss 0.183061 lr 0.00028567 rank 6
2023-03-01 13:39:50,062 DEBUG TRAIN Batch 56/7300 loss 1.824797 loss_att 4.793919 loss_ctc 5.033505 loss_rnnt 0.741699 hw_loss 0.115211 lr 0.00028567 rank 2
2023-03-01 13:39:50,077 DEBUG TRAIN Batch 56/7300 loss 7.635744 loss_att 11.217667 loss_ctc 16.433367 loss_rnnt 5.596312 hw_loss 0.281307 lr 0.00028566 rank 1
2023-03-01 13:39:50,088 DEBUG TRAIN Batch 56/7300 loss 11.278345 loss_att 14.949378 loss_ctc 18.708824 loss_rnnt 9.468095 hw_loss 0.159961 lr 0.00028567 rank 4
2023-03-01 13:39:50,093 DEBUG TRAIN Batch 56/7300 loss 7.626883 loss_att 8.559088 loss_ctc 13.253944 loss_rnnt 6.550371 hw_loss 0.262117 lr 0.00028566 rank 3
2023-03-01 13:40:29,578 DEBUG TRAIN Batch 56/7400 loss 6.904037 loss_att 8.695201 loss_ctc 11.896477 loss_rnnt 5.811217 hw_loss 0.129239 lr 0.00028567 rank 0
2023-03-01 13:40:29,580 DEBUG TRAIN Batch 56/7400 loss 7.583468 loss_att 10.674128 loss_ctc 12.300510 loss_rnnt 6.249917 hw_loss 0.162150 lr 0.00028565 rank 1
2023-03-01 13:40:29,581 DEBUG TRAIN Batch 56/7400 loss 5.696254 loss_att 9.711402 loss_ctc 11.940579 loss_rnnt 3.959461 hw_loss 0.189724 lr 0.00028565 rank 4
2023-03-01 13:40:29,582 DEBUG TRAIN Batch 56/7400 loss 2.622177 loss_att 4.000634 loss_ctc 2.971793 loss_rnnt 2.184608 hw_loss 0.216116 lr 0.00028565 rank 7
2023-03-01 13:40:29,586 DEBUG TRAIN Batch 56/7400 loss 2.261713 loss_att 4.423739 loss_ctc 4.037561 loss_rnnt 1.481013 hw_loss 0.209091 lr 0.00028566 rank 5
2023-03-01 13:40:29,587 DEBUG TRAIN Batch 56/7400 loss 4.212749 loss_att 7.627883 loss_ctc 7.132043 loss_rnnt 3.059667 hw_loss 0.151531 lr 0.00028565 rank 3
2023-03-01 13:40:29,591 DEBUG TRAIN Batch 56/7400 loss 8.129891 loss_att 10.829983 loss_ctc 14.027745 loss_rnnt 6.716416 hw_loss 0.163269 lr 0.00028566 rank 6
2023-03-01 13:40:29,601 DEBUG TRAIN Batch 56/7400 loss 3.952324 loss_att 6.478114 loss_ctc 6.981619 loss_rnnt 2.998238 hw_loss 0.084416 lr 0.00028566 rank 2
2023-03-01 13:41:34,154 DEBUG TRAIN Batch 56/7500 loss 8.496003 loss_att 11.059315 loss_ctc 13.430275 loss_rnnt 7.241037 hw_loss 0.158251 lr 0.00028564 rank 3
2023-03-01 13:41:34,167 DEBUG TRAIN Batch 56/7500 loss 1.648568 loss_att 4.177498 loss_ctc 3.010827 loss_rnnt 0.832186 hw_loss 0.241803 lr 0.00028564 rank 7
2023-03-01 13:41:34,170 DEBUG TRAIN Batch 56/7500 loss 12.549158 loss_att 13.706802 loss_ctc 19.159599 loss_rnnt 11.324620 hw_loss 0.209278 lr 0.00028565 rank 2
2023-03-01 13:41:34,169 DEBUG TRAIN Batch 56/7500 loss 5.169545 loss_att 8.040541 loss_ctc 8.380556 loss_rnnt 4.038750 hw_loss 0.240863 lr 0.00028565 rank 6
2023-03-01 13:41:34,171 DEBUG TRAIN Batch 56/7500 loss 6.957713 loss_att 8.266420 loss_ctc 10.322680 loss_rnnt 6.118367 hw_loss 0.241766 lr 0.00028566 rank 0
2023-03-01 13:41:34,173 DEBUG TRAIN Batch 56/7500 loss 3.500801 loss_att 3.890469 loss_ctc 4.891510 loss_rnnt 3.085202 hw_loss 0.285444 lr 0.00028564 rank 1
2023-03-01 13:41:34,174 DEBUG TRAIN Batch 56/7500 loss 4.611282 loss_att 7.987647 loss_ctc 8.436351 loss_rnnt 3.298893 hw_loss 0.238325 lr 0.00028564 rank 4
2023-03-01 13:41:34,218 DEBUG TRAIN Batch 56/7500 loss 6.785855 loss_att 9.134218 loss_ctc 11.489464 loss_rnnt 5.593973 hw_loss 0.178242 lr 0.00028564 rank 5
2023-03-01 13:42:13,038 DEBUG TRAIN Batch 56/7600 loss 2.247030 loss_att 4.362645 loss_ctc 3.644829 loss_rnnt 1.548620 hw_loss 0.166713 lr 0.00028563 rank 5
2023-03-01 13:42:13,057 DEBUG TRAIN Batch 56/7600 loss 3.789868 loss_att 7.046733 loss_ctc 8.602024 loss_rnnt 2.316426 hw_loss 0.338339 lr 0.00028564 rank 0
2023-03-01 13:42:13,058 DEBUG TRAIN Batch 56/7600 loss 3.523042 loss_att 5.666033 loss_ctc 6.886373 loss_rnnt 2.567818 hw_loss 0.146591 lr 0.00028563 rank 7
2023-03-01 13:42:13,057 DEBUG TRAIN Batch 56/7600 loss 8.580591 loss_att 13.333347 loss_ctc 14.605018 loss_rnnt 6.682147 hw_loss 0.271194 lr 0.00028563 rank 1
2023-03-01 13:42:13,058 DEBUG TRAIN Batch 56/7600 loss 7.112116 loss_att 9.302589 loss_ctc 15.665615 loss_rnnt 5.427959 hw_loss 0.197990 lr 0.00028563 rank 3
2023-03-01 13:42:13,058 DEBUG TRAIN Batch 56/7600 loss 11.932220 loss_att 16.362539 loss_ctc 21.065241 loss_rnnt 9.711271 hw_loss 0.219655 lr 0.00028564 rank 6
2023-03-01 13:42:13,061 DEBUG TRAIN Batch 56/7600 loss 10.276892 loss_att 15.602713 loss_ctc 19.064661 loss_rnnt 7.901122 hw_loss 0.260444 lr 0.00028563 rank 4
2023-03-01 13:42:13,061 DEBUG TRAIN Batch 56/7600 loss 11.179863 loss_att 15.497051 loss_ctc 16.150082 loss_rnnt 9.564838 hw_loss 0.166668 lr 0.00028564 rank 2
2023-03-01 13:42:52,299 DEBUG TRAIN Batch 56/7700 loss 12.359849 loss_att 13.692460 loss_ctc 19.093145 loss_rnnt 11.052502 hw_loss 0.268222 lr 0.00028563 rank 0
2023-03-01 13:42:52,302 DEBUG TRAIN Batch 56/7700 loss 6.481196 loss_att 9.675560 loss_ctc 8.238909 loss_rnnt 5.509013 hw_loss 0.185531 lr 0.00028562 rank 4
2023-03-01 13:42:52,303 DEBUG TRAIN Batch 56/7700 loss 6.046870 loss_att 7.569746 loss_ctc 10.526690 loss_rnnt 4.989049 hw_loss 0.292381 lr 0.00028563 rank 6
2023-03-01 13:42:52,305 DEBUG TRAIN Batch 56/7700 loss 17.850018 loss_att 20.474398 loss_ctc 24.447861 loss_rnnt 16.323238 hw_loss 0.229105 lr 0.00028562 rank 2
2023-03-01 13:42:52,306 DEBUG TRAIN Batch 56/7700 loss 7.585169 loss_att 10.813778 loss_ctc 11.762607 loss_rnnt 6.221900 hw_loss 0.301043 lr 0.00028562 rank 5
2023-03-01 13:42:52,307 DEBUG TRAIN Batch 56/7700 loss 5.732157 loss_att 6.732844 loss_ctc 7.797459 loss_rnnt 5.185294 hw_loss 0.133785 lr 0.00028561 rank 7
2023-03-01 13:42:52,313 DEBUG TRAIN Batch 56/7700 loss 11.295761 loss_att 15.400371 loss_ctc 19.721636 loss_rnnt 9.250781 hw_loss 0.188641 lr 0.00028561 rank 3
2023-03-01 13:42:52,329 DEBUG TRAIN Batch 56/7700 loss 5.687600 loss_att 8.657771 loss_ctc 10.530525 loss_rnnt 4.371561 hw_loss 0.143027 lr 0.00028562 rank 1
2023-03-01 13:43:53,052 DEBUG TRAIN Batch 56/7800 loss 5.576584 loss_att 8.604795 loss_ctc 7.752138 loss_rnnt 4.559505 hw_loss 0.227553 lr 0.00028561 rank 6
2023-03-01 13:43:53,057 DEBUG TRAIN Batch 56/7800 loss 6.599609 loss_att 12.938913 loss_ctc 12.658328 loss_rnnt 4.433620 hw_loss 0.169311 lr 0.00028561 rank 5
2023-03-01 13:43:53,063 DEBUG TRAIN Batch 56/7800 loss 6.690021 loss_att 9.445725 loss_ctc 11.571737 loss_rnnt 5.407230 hw_loss 0.151416 lr 0.00028561 rank 2
2023-03-01 13:43:53,068 DEBUG TRAIN Batch 56/7800 loss 9.120138 loss_att 9.679962 loss_ctc 11.895576 loss_rnnt 8.555871 hw_loss 0.154206 lr 0.00028562 rank 0
2023-03-01 13:43:53,070 DEBUG TRAIN Batch 56/7800 loss 3.948249 loss_att 7.706243 loss_ctc 5.932793 loss_rnnt 2.833797 hw_loss 0.184214 lr 0.00028561 rank 4
2023-03-01 13:43:53,076 DEBUG TRAIN Batch 56/7800 loss 8.274323 loss_att 12.315058 loss_ctc 14.596785 loss_rnnt 6.558601 hw_loss 0.121089 lr 0.00028560 rank 1
2023-03-01 13:43:53,076 DEBUG TRAIN Batch 56/7800 loss 3.618402 loss_att 7.180657 loss_ctc 5.926137 loss_rnnt 2.510299 hw_loss 0.164913 lr 0.00028560 rank 3
2023-03-01 13:43:53,106 DEBUG TRAIN Batch 56/7800 loss 4.851149 loss_att 5.579086 loss_ctc 8.114276 loss_rnnt 4.091821 hw_loss 0.334982 lr 0.00028560 rank 7
2023-03-01 13:44:37,486 DEBUG TRAIN Batch 56/7900 loss 4.026968 loss_att 6.016267 loss_ctc 5.580293 loss_rnnt 3.328582 hw_loss 0.175157 lr 0.00028560 rank 5
2023-03-01 13:44:37,486 DEBUG TRAIN Batch 56/7900 loss 5.652012 loss_att 7.464185 loss_ctc 9.330108 loss_rnnt 4.734303 hw_loss 0.121619 lr 0.00028559 rank 1
2023-03-01 13:44:37,494 DEBUG TRAIN Batch 56/7900 loss 3.062736 loss_att 5.091338 loss_ctc 8.495686 loss_rnnt 1.820583 hw_loss 0.210075 lr 0.00028561 rank 0
2023-03-01 13:44:37,500 DEBUG TRAIN Batch 56/7900 loss 7.045256 loss_att 9.684162 loss_ctc 10.854181 loss_rnnt 5.971044 hw_loss 0.072327 lr 0.00028560 rank 2
2023-03-01 13:44:37,500 DEBUG TRAIN Batch 56/7900 loss 1.118562 loss_att 3.507478 loss_ctc 1.878635 loss_rnnt 0.492299 hw_loss 0.088380 lr 0.00028559 rank 7
2023-03-01 13:44:37,501 DEBUG TRAIN Batch 56/7900 loss 10.564301 loss_att 11.984449 loss_ctc 15.187202 loss_rnnt 9.590876 hw_loss 0.136892 lr 0.00028560 rank 4
2023-03-01 13:44:37,502 DEBUG TRAIN Batch 56/7900 loss 4.820268 loss_att 8.749055 loss_ctc 8.864202 loss_rnnt 3.336645 hw_loss 0.297515 lr 0.00028560 rank 6
2023-03-01 13:44:37,548 DEBUG TRAIN Batch 56/7900 loss 4.491684 loss_att 9.410315 loss_ctc 8.559673 loss_rnnt 2.889990 hw_loss 0.141693 lr 0.00028559 rank 3
2023-03-01 13:45:16,263 DEBUG TRAIN Batch 56/8000 loss 5.147964 loss_att 7.019033 loss_ctc 9.363497 loss_rnnt 4.096889 hw_loss 0.215230 lr 0.00028559 rank 5
2023-03-01 13:45:16,265 DEBUG TRAIN Batch 56/8000 loss 9.368086 loss_att 11.338051 loss_ctc 17.041639 loss_rnnt 7.881151 hw_loss 0.130876 lr 0.00028559 rank 2
2023-03-01 13:45:16,282 DEBUG TRAIN Batch 56/8000 loss 2.535200 loss_att 4.689832 loss_ctc 3.893731 loss_rnnt 1.789701 hw_loss 0.250192 lr 0.00028558 rank 7
2023-03-01 13:45:16,281 DEBUG TRAIN Batch 56/8000 loss 8.593288 loss_att 11.349835 loss_ctc 16.226568 loss_rnnt 6.882625 hw_loss 0.265470 lr 0.00028560 rank 0
2023-03-01 13:45:16,282 DEBUG TRAIN Batch 56/8000 loss 5.290751 loss_att 8.326550 loss_ctc 10.097906 loss_rnnt 3.978498 hw_loss 0.120264 lr 0.00028559 rank 6
2023-03-01 13:45:16,287 DEBUG TRAIN Batch 56/8000 loss 15.341281 loss_att 15.508001 loss_ctc 20.748945 loss_rnnt 14.477574 hw_loss 0.205012 lr 0.00028558 rank 1
2023-03-01 13:45:16,289 DEBUG TRAIN Batch 56/8000 loss 5.055598 loss_att 7.692882 loss_ctc 7.770278 loss_rnnt 4.110654 hw_loss 0.104118 lr 0.00028558 rank 3
2023-03-01 13:45:16,333 DEBUG TRAIN Batch 56/8000 loss 14.379176 loss_att 17.295610 loss_ctc 21.404854 loss_rnnt 12.735548 hw_loss 0.231721 lr 0.00028558 rank 4
2023-03-01 13:45:55,327 DEBUG TRAIN Batch 56/8100 loss 6.681894 loss_att 8.713928 loss_ctc 11.571815 loss_rnnt 5.503213 hw_loss 0.225533 lr 0.00028557 rank 7
2023-03-01 13:45:55,333 DEBUG TRAIN Batch 56/8100 loss 6.837284 loss_att 11.185514 loss_ctc 14.325250 loss_rnnt 4.798623 hw_loss 0.319911 lr 0.00028557 rank 3
2023-03-01 13:45:55,335 DEBUG TRAIN Batch 56/8100 loss 1.451927 loss_att 3.271128 loss_ctc 1.861261 loss_rnnt 0.909874 hw_loss 0.231815 lr 0.00028558 rank 6
2023-03-01 13:45:55,348 DEBUG TRAIN Batch 56/8100 loss 5.087120 loss_att 7.823079 loss_ctc 7.287108 loss_rnnt 4.146664 hw_loss 0.187373 lr 0.00028557 rank 1
2023-03-01 13:45:55,350 DEBUG TRAIN Batch 56/8100 loss 7.113379 loss_att 9.926870 loss_ctc 14.583473 loss_rnnt 5.387530 hw_loss 0.313382 lr 0.00028557 rank 4
2023-03-01 13:45:55,352 DEBUG TRAIN Batch 56/8100 loss 7.872256 loss_att 10.986361 loss_ctc 21.080921 loss_rnnt 5.399259 hw_loss 0.166915 lr 0.00028557 rank 5
2023-03-01 13:45:55,353 DEBUG TRAIN Batch 56/8100 loss 5.012725 loss_att 6.970285 loss_ctc 9.110496 loss_rnnt 3.941054 hw_loss 0.250856 lr 0.00028559 rank 0
2023-03-01 13:45:55,392 DEBUG TRAIN Batch 56/8100 loss 7.175809 loss_att 7.836757 loss_ctc 12.297699 loss_rnnt 6.186728 hw_loss 0.326200 lr 0.00028558 rank 2
2023-03-01 13:46:35,501 DEBUG TRAIN Batch 56/8200 loss 1.807047 loss_att 3.607646 loss_ctc 1.747340 loss_rnnt 1.397469 hw_loss 0.107661 lr 0.00028557 rank 0
2023-03-01 13:46:35,526 DEBUG TRAIN Batch 56/8200 loss 6.668642 loss_att 10.889044 loss_ctc 14.225098 loss_rnnt 4.725638 hw_loss 0.171366 lr 0.00028556 rank 7
2023-03-01 13:46:35,527 DEBUG TRAIN Batch 56/8200 loss 8.476677 loss_att 10.129418 loss_ctc 15.134097 loss_rnnt 7.155340 hw_loss 0.193374 lr 0.00028556 rank 5
2023-03-01 13:46:35,531 DEBUG TRAIN Batch 56/8200 loss 7.349774 loss_att 7.030045 loss_ctc 11.174801 loss_rnnt 6.774662 hw_loss 0.241977 lr 0.00028556 rank 1
2023-03-01 13:46:35,535 DEBUG TRAIN Batch 56/8200 loss 1.654329 loss_att 4.230833 loss_ctc 3.507907 loss_rnnt 0.786614 hw_loss 0.197382 lr 0.00028556 rank 3
2023-03-01 13:46:35,563 DEBUG TRAIN Batch 56/8200 loss 4.517248 loss_att 7.024843 loss_ctc 8.753219 loss_rnnt 3.339261 hw_loss 0.209384 lr 0.00028557 rank 6
2023-03-01 13:46:35,570 DEBUG TRAIN Batch 56/8200 loss 3.135503 loss_att 7.616432 loss_ctc 5.226040 loss_rnnt 1.844684 hw_loss 0.217302 lr 0.00028556 rank 4
2023-03-01 13:46:35,574 DEBUG TRAIN Batch 56/8200 loss 3.540309 loss_att 6.644784 loss_ctc 6.342250 loss_rnnt 2.390980 hw_loss 0.290329 lr 0.00028557 rank 2
2023-03-01 13:47:14,157 DEBUG TRAIN Batch 56/8300 loss 11.751267 loss_att 15.798525 loss_ctc 19.955067 loss_rnnt 9.796963 hw_loss 0.095652 lr 0.00028555 rank 5
2023-03-01 13:47:14,159 DEBUG TRAIN Batch 56/8300 loss 3.296418 loss_att 7.256879 loss_ctc 5.933640 loss_rnnt 2.075934 hw_loss 0.143930 lr 0.00028555 rank 4
2023-03-01 13:47:14,162 DEBUG TRAIN Batch 56/8300 loss 2.905804 loss_att 6.436825 loss_ctc 3.999761 loss_rnnt 1.986966 hw_loss 0.125199 lr 0.00028554 rank 3
2023-03-01 13:47:14,173 DEBUG TRAIN Batch 56/8300 loss 3.093714 loss_att 6.892282 loss_ctc 5.576164 loss_rnnt 1.888083 hw_loss 0.215481 lr 0.00028555 rank 7
2023-03-01 13:47:14,174 DEBUG TRAIN Batch 56/8300 loss 3.741635 loss_att 7.261155 loss_ctc 10.935417 loss_rnnt 1.979364 hw_loss 0.185992 lr 0.00028555 rank 1
2023-03-01 13:47:14,178 DEBUG TRAIN Batch 56/8300 loss 3.615184 loss_att 7.614540 loss_ctc 7.336124 loss_rnnt 2.193427 hw_loss 0.235801 lr 0.00028555 rank 2
2023-03-01 13:47:14,183 DEBUG TRAIN Batch 56/8300 loss 2.682540 loss_att 5.717058 loss_ctc 5.047736 loss_rnnt 1.598810 hw_loss 0.302752 lr 0.00028556 rank 0
2023-03-01 13:47:14,198 DEBUG TRAIN Batch 56/8300 loss 7.958585 loss_att 9.389585 loss_ctc 12.575808 loss_rnnt 6.926686 hw_loss 0.243879 lr 0.00028556 rank 6
2023-03-01 13:47:47,145 DEBUG CV Batch 56/0 loss 1.045708 loss_att 1.038387 loss_ctc 2.039639 loss_rnnt 0.780927 hw_loss 0.250727 history loss 1.006978 rank 0
2023-03-01 13:47:47,177 DEBUG CV Batch 56/0 loss 1.045708 loss_att 1.038387 loss_ctc 2.039639 loss_rnnt 0.780927 hw_loss 0.250727 history loss 1.006978 rank 4
2023-03-01 13:47:47,189 DEBUG CV Batch 56/0 loss 1.045708 loss_att 1.038387 loss_ctc 2.039639 loss_rnnt 0.780927 hw_loss 0.250727 history loss 1.006978 rank 6
2023-03-01 13:47:47,259 DEBUG CV Batch 56/0 loss 1.045708 loss_att 1.038387 loss_ctc 2.039639 loss_rnnt 0.780927 hw_loss 0.250727 history loss 1.006978 rank 7
2023-03-01 13:47:47,455 DEBUG CV Batch 56/0 loss 1.045708 loss_att 1.038387 loss_ctc 2.039639 loss_rnnt 0.780927 hw_loss 0.250727 history loss 1.006978 rank 5
2023-03-01 13:47:47,533 DEBUG CV Batch 56/0 loss 1.045708 loss_att 1.038387 loss_ctc 2.039639 loss_rnnt 0.780927 hw_loss 0.250727 history loss 1.006978 rank 2
2023-03-01 13:47:47,549 DEBUG CV Batch 56/0 loss 1.045708 loss_att 1.038387 loss_ctc 2.039639 loss_rnnt 0.780927 hw_loss 0.250727 history loss 1.006978 rank 3
2023-03-01 13:47:47,647 DEBUG CV Batch 56/0 loss 1.045708 loss_att 1.038387 loss_ctc 2.039639 loss_rnnt 0.780927 hw_loss 0.250727 history loss 1.006978 rank 1
2023-03-01 13:47:58,521 DEBUG CV Batch 56/100 loss 3.991177 loss_att 4.434650 loss_ctc 7.958295 loss_rnnt 3.221721 hw_loss 0.284647 history loss 3.054265 rank 4
2023-03-01 13:47:58,585 DEBUG CV Batch 56/100 loss 3.991177 loss_att 4.434650 loss_ctc 7.958295 loss_rnnt 3.221721 hw_loss 0.284647 history loss 3.054265 rank 6
2023-03-01 13:47:58,873 DEBUG CV Batch 56/100 loss 3.991177 loss_att 4.434650 loss_ctc 7.958295 loss_rnnt 3.221721 hw_loss 0.284647 history loss 3.054265 rank 5
2023-03-01 13:47:58,912 DEBUG CV Batch 56/100 loss 3.991177 loss_att 4.434650 loss_ctc 7.958295 loss_rnnt 3.221721 hw_loss 0.284647 history loss 3.054265 rank 2
2023-03-01 13:47:59,000 DEBUG CV Batch 56/100 loss 3.991177 loss_att 4.434650 loss_ctc 7.958295 loss_rnnt 3.221721 hw_loss 0.284647 history loss 3.054265 rank 1
2023-03-01 13:47:59,047 DEBUG CV Batch 56/100 loss 3.991177 loss_att 4.434650 loss_ctc 7.958295 loss_rnnt 3.221721 hw_loss 0.284647 history loss 3.054265 rank 7
2023-03-01 13:47:59,097 DEBUG CV Batch 56/100 loss 3.991177 loss_att 4.434650 loss_ctc 7.958295 loss_rnnt 3.221721 hw_loss 0.284647 history loss 3.054265 rank 3
2023-03-01 13:47:59,184 DEBUG CV Batch 56/100 loss 3.991177 loss_att 4.434650 loss_ctc 7.958295 loss_rnnt 3.221721 hw_loss 0.284647 history loss 3.054265 rank 0
2023-03-01 13:48:12,074 DEBUG CV Batch 56/200 loss 4.711584 loss_att 8.508469 loss_ctc 7.447526 loss_rnnt 3.503418 hw_loss 0.157494 history loss 3.640266 rank 4
2023-03-01 13:48:12,169 DEBUG CV Batch 56/200 loss 4.711584 loss_att 8.508469 loss_ctc 7.447526 loss_rnnt 3.503418 hw_loss 0.157494 history loss 3.640266 rank 5
2023-03-01 13:48:12,260 DEBUG CV Batch 56/200 loss 4.711584 loss_att 8.508469 loss_ctc 7.447526 loss_rnnt 3.503418 hw_loss 0.157494 history loss 3.640266 rank 6
2023-03-01 13:48:12,272 DEBUG CV Batch 56/200 loss 4.711584 loss_att 8.508469 loss_ctc 7.447526 loss_rnnt 3.503418 hw_loss 0.157494 history loss 3.640266 rank 1
2023-03-01 13:48:12,368 DEBUG CV Batch 56/200 loss 4.711584 loss_att 8.508469 loss_ctc 7.447526 loss_rnnt 3.503418 hw_loss 0.157494 history loss 3.640266 rank 2
2023-03-01 13:48:12,537 DEBUG CV Batch 56/200 loss 4.711584 loss_att 8.508469 loss_ctc 7.447526 loss_rnnt 3.503418 hw_loss 0.157494 history loss 3.640266 rank 3
2023-03-01 13:48:12,933 DEBUG CV Batch 56/200 loss 4.711584 loss_att 8.508469 loss_ctc 7.447526 loss_rnnt 3.503418 hw_loss 0.157494 history loss 3.640266 rank 7
2023-03-01 13:48:13,354 DEBUG CV Batch 56/200 loss 4.711584 loss_att 8.508469 loss_ctc 7.447526 loss_rnnt 3.503418 hw_loss 0.157494 history loss 3.640266 rank 0
2023-03-01 13:48:24,405 DEBUG CV Batch 56/300 loss 3.568365 loss_att 4.579394 loss_ctc 6.825464 loss_rnnt 2.818885 hw_loss 0.211864 history loss 3.784120 rank 5
2023-03-01 13:48:24,461 DEBUG CV Batch 56/300 loss 3.568365 loss_att 4.579394 loss_ctc 6.825464 loss_rnnt 2.818885 hw_loss 0.211864 history loss 3.784120 rank 1
2023-03-01 13:48:24,478 DEBUG CV Batch 56/300 loss 3.568365 loss_att 4.579394 loss_ctc 6.825464 loss_rnnt 2.818885 hw_loss 0.211864 history loss 3.784120 rank 4
2023-03-01 13:48:24,818 DEBUG CV Batch 56/300 loss 3.568365 loss_att 4.579394 loss_ctc 6.825464 loss_rnnt 2.818885 hw_loss 0.211864 history loss 3.784120 rank 6
2023-03-01 13:48:24,856 DEBUG CV Batch 56/300 loss 3.568365 loss_att 4.579394 loss_ctc 6.825464 loss_rnnt 2.818885 hw_loss 0.211864 history loss 3.784120 rank 2
2023-03-01 13:48:24,939 DEBUG CV Batch 56/300 loss 3.568365 loss_att 4.579394 loss_ctc 6.825464 loss_rnnt 2.818885 hw_loss 0.211864 history loss 3.784120 rank 3
2023-03-01 13:48:25,616 DEBUG CV Batch 56/300 loss 3.568365 loss_att 4.579394 loss_ctc 6.825464 loss_rnnt 2.818885 hw_loss 0.211864 history loss 3.784120 rank 7
2023-03-01 13:48:26,381 DEBUG CV Batch 56/300 loss 3.568365 loss_att 4.579394 loss_ctc 6.825464 loss_rnnt 2.818885 hw_loss 0.211864 history loss 3.784120 rank 0
2023-03-01 13:48:36,547 DEBUG CV Batch 56/400 loss 17.195692 loss_att 62.990643 loss_ctc 7.135759 loss_rnnt 9.258704 hw_loss 0.223728 history loss 4.592507 rank 4
2023-03-01 13:48:36,778 DEBUG CV Batch 56/400 loss 17.195692 loss_att 62.990643 loss_ctc 7.135759 loss_rnnt 9.258704 hw_loss 0.223728 history loss 4.592507 rank 5
2023-03-01 13:48:36,836 DEBUG CV Batch 56/400 loss 17.195692 loss_att 62.990643 loss_ctc 7.135759 loss_rnnt 9.258704 hw_loss 0.223728 history loss 4.592507 rank 1
2023-03-01 13:48:36,989 DEBUG CV Batch 56/400 loss 17.195692 loss_att 62.990643 loss_ctc 7.135759 loss_rnnt 9.258704 hw_loss 0.223728 history loss 4.592507 rank 6
2023-03-01 13:48:37,109 DEBUG CV Batch 56/400 loss 17.195692 loss_att 62.990643 loss_ctc 7.135759 loss_rnnt 9.258704 hw_loss 0.223728 history loss 4.592507 rank 2
2023-03-01 13:48:37,144 DEBUG CV Batch 56/400 loss 17.195692 loss_att 62.990643 loss_ctc 7.135759 loss_rnnt 9.258704 hw_loss 0.223728 history loss 4.592507 rank 3
2023-03-01 13:48:38,165 DEBUG CV Batch 56/400 loss 17.195692 loss_att 62.990643 loss_ctc 7.135759 loss_rnnt 9.258704 hw_loss 0.223728 history loss 4.592507 rank 7
2023-03-01 13:48:39,367 DEBUG CV Batch 56/400 loss 17.195692 loss_att 62.990643 loss_ctc 7.135759 loss_rnnt 9.258704 hw_loss 0.223728 history loss 4.592507 rank 0
2023-03-01 13:48:47,218 DEBUG CV Batch 56/500 loss 3.851606 loss_att 3.944931 loss_ctc 5.315779 loss_rnnt 3.520622 hw_loss 0.219555 history loss 5.209069 rank 4
2023-03-01 13:48:47,523 DEBUG CV Batch 56/500 loss 3.851606 loss_att 3.944931 loss_ctc 5.315779 loss_rnnt 3.520622 hw_loss 0.219555 history loss 5.209069 rank 5
2023-03-01 13:48:47,899 DEBUG CV Batch 56/500 loss 3.851606 loss_att 3.944931 loss_ctc 5.315779 loss_rnnt 3.520622 hw_loss 0.219555 history loss 5.209069 rank 2
2023-03-01 13:48:47,987 DEBUG CV Batch 56/500 loss 3.851606 loss_att 3.944931 loss_ctc 5.315779 loss_rnnt 3.520622 hw_loss 0.219555 history loss 5.209069 rank 6
2023-03-01 13:48:48,026 DEBUG CV Batch 56/500 loss 3.851606 loss_att 3.944931 loss_ctc 5.315779 loss_rnnt 3.520622 hw_loss 0.219555 history loss 5.209069 rank 3
2023-03-01 13:48:48,037 DEBUG CV Batch 56/500 loss 3.851606 loss_att 3.944931 loss_ctc 5.315779 loss_rnnt 3.520622 hw_loss 0.219555 history loss 5.209069 rank 1
2023-03-01 13:48:49,470 DEBUG CV Batch 56/500 loss 3.851606 loss_att 3.944931 loss_ctc 5.315779 loss_rnnt 3.520622 hw_loss 0.219555 history loss 5.209069 rank 7
2023-03-01 13:48:51,003 DEBUG CV Batch 56/500 loss 3.851606 loss_att 3.944931 loss_ctc 5.315779 loss_rnnt 3.520622 hw_loss 0.219555 history loss 5.209069 rank 0
2023-03-01 13:48:59,453 DEBUG CV Batch 56/600 loss 7.869580 loss_att 6.964096 loss_ctc 10.402307 loss_rnnt 7.502794 hw_loss 0.394098 history loss 6.071150 rank 4
2023-03-01 13:48:59,807 DEBUG CV Batch 56/600 loss 7.869580 loss_att 6.964096 loss_ctc 10.402307 loss_rnnt 7.502794 hw_loss 0.394098 history loss 6.071150 rank 5
2023-03-01 13:49:00,095 DEBUG CV Batch 56/600 loss 7.869580 loss_att 6.964096 loss_ctc 10.402307 loss_rnnt 7.502794 hw_loss 0.394098 history loss 6.071150 rank 1
2023-03-01 13:49:00,207 DEBUG CV Batch 56/600 loss 7.869580 loss_att 6.964096 loss_ctc 10.402307 loss_rnnt 7.502794 hw_loss 0.394098 history loss 6.071150 rank 2
2023-03-01 13:49:00,377 DEBUG CV Batch 56/600 loss 7.869580 loss_att 6.964096 loss_ctc 10.402307 loss_rnnt 7.502794 hw_loss 0.394098 history loss 6.071150 rank 6
2023-03-01 13:49:00,566 DEBUG CV Batch 56/600 loss 7.869580 loss_att 6.964096 loss_ctc 10.402307 loss_rnnt 7.502794 hw_loss 0.394098 history loss 6.071150 rank 3
2023-03-01 13:49:02,248 DEBUG CV Batch 56/600 loss 7.869580 loss_att 6.964096 loss_ctc 10.402307 loss_rnnt 7.502794 hw_loss 0.394098 history loss 6.071150 rank 7
2023-03-01 13:49:03,828 DEBUG CV Batch 56/600 loss 7.869580 loss_att 6.964096 loss_ctc 10.402307 loss_rnnt 7.502794 hw_loss 0.394098 history loss 6.071150 rank 0
2023-03-01 13:49:10,708 DEBUG CV Batch 56/700 loss 12.958773 loss_att 36.898781 loss_ctc 16.113880 loss_rnnt 7.749808 hw_loss 0.000529 history loss 6.642401 rank 4
2023-03-01 13:49:11,237 DEBUG CV Batch 56/700 loss 12.958773 loss_att 36.898781 loss_ctc 16.113880 loss_rnnt 7.749808 hw_loss 0.000529 history loss 6.642401 rank 1
2023-03-01 13:49:11,260 DEBUG CV Batch 56/700 loss 12.958773 loss_att 36.898781 loss_ctc 16.113880 loss_rnnt 7.749808 hw_loss 0.000529 history loss 6.642401 rank 5
2023-03-01 13:49:11,615 DEBUG CV Batch 56/700 loss 12.958773 loss_att 36.898781 loss_ctc 16.113880 loss_rnnt 7.749808 hw_loss 0.000529 history loss 6.642401 rank 2
2023-03-01 13:49:12,093 DEBUG CV Batch 56/700 loss 12.958773 loss_att 36.898781 loss_ctc 16.113880 loss_rnnt 7.749808 hw_loss 0.000529 history loss 6.642401 rank 3
2023-03-01 13:49:12,222 DEBUG CV Batch 56/700 loss 12.958773 loss_att 36.898781 loss_ctc 16.113880 loss_rnnt 7.749808 hw_loss 0.000529 history loss 6.642401 rank 6
2023-03-01 13:49:14,305 DEBUG CV Batch 56/700 loss 12.958773 loss_att 36.898781 loss_ctc 16.113880 loss_rnnt 7.749808 hw_loss 0.000529 history loss 6.642401 rank 7
2023-03-01 13:49:15,964 DEBUG CV Batch 56/700 loss 12.958773 loss_att 36.898781 loss_ctc 16.113880 loss_rnnt 7.749808 hw_loss 0.000529 history loss 6.642401 rank 0
2023-03-01 13:49:22,478 DEBUG CV Batch 56/800 loss 6.651362 loss_att 6.748884 loss_ctc 12.083488 loss_rnnt 5.752575 hw_loss 0.290623 history loss 6.164019 rank 1
2023-03-01 13:49:22,484 DEBUG CV Batch 56/800 loss 6.651362 loss_att 6.748884 loss_ctc 12.083488 loss_rnnt 5.752575 hw_loss 0.290624 history loss 6.164019 rank 4
2023-03-01 13:49:22,962 DEBUG CV Batch 56/800 loss 6.651362 loss_att 6.748884 loss_ctc 12.083488 loss_rnnt 5.752575 hw_loss 0.290623 history loss 6.164019 rank 5
2023-03-01 13:49:23,115 DEBUG CV Batch 56/800 loss 6.651362 loss_att 6.748884 loss_ctc 12.083488 loss_rnnt 5.752575 hw_loss 0.290624 history loss 6.164019 rank 2
2023-03-01 13:49:23,756 DEBUG CV Batch 56/800 loss 6.651362 loss_att 6.748884 loss_ctc 12.083488 loss_rnnt 5.752575 hw_loss 0.290624 history loss 6.164019 rank 3
2023-03-01 13:49:23,908 DEBUG CV Batch 56/800 loss 6.651362 loss_att 6.748884 loss_ctc 12.083488 loss_rnnt 5.752575 hw_loss 0.290623 history loss 6.164019 rank 6
2023-03-01 13:49:26,352 DEBUG CV Batch 56/800 loss 6.651362 loss_att 6.748884 loss_ctc 12.083488 loss_rnnt 5.752575 hw_loss 0.290624 history loss 6.164019 rank 7
2023-03-01 13:49:28,193 DEBUG CV Batch 56/800 loss 6.651362 loss_att 6.748884 loss_ctc 12.083488 loss_rnnt 5.752575 hw_loss 0.290624 history loss 6.164019 rank 0
2023-03-01 13:49:35,581 DEBUG CV Batch 56/900 loss 9.173717 loss_att 8.542299 loss_ctc 16.644861 loss_rnnt 8.228652 hw_loss 0.140994 history loss 5.993574 rank 1
2023-03-01 13:49:35,710 DEBUG CV Batch 56/900 loss 9.173717 loss_att 8.542299 loss_ctc 16.644861 loss_rnnt 8.228652 hw_loss 0.140994 history loss 5.993574 rank 4
2023-03-01 13:49:36,463 DEBUG CV Batch 56/900 loss 9.173717 loss_att 8.542299 loss_ctc 16.644861 loss_rnnt 8.228652 hw_loss 0.140994 history loss 5.993574 rank 5
2023-03-01 13:49:36,767 DEBUG CV Batch 56/900 loss 9.173717 loss_att 8.542299 loss_ctc 16.644861 loss_rnnt 8.228652 hw_loss 0.140994 history loss 5.993574 rank 2
2023-03-01 13:49:37,339 DEBUG CV Batch 56/900 loss 9.173717 loss_att 8.542299 loss_ctc 16.644861 loss_rnnt 8.228652 hw_loss 0.140994 history loss 5.993574 rank 3
2023-03-01 13:49:37,693 DEBUG CV Batch 56/900 loss 9.173717 loss_att 8.542299 loss_ctc 16.644861 loss_rnnt 8.228652 hw_loss 0.140994 history loss 5.993574 rank 6
2023-03-01 13:49:40,245 DEBUG CV Batch 56/900 loss 9.173717 loss_att 8.542299 loss_ctc 16.644861 loss_rnnt 8.228652 hw_loss 0.140994 history loss 5.993574 rank 7
2023-03-01 13:49:42,120 DEBUG CV Batch 56/900 loss 9.173717 loss_att 8.542299 loss_ctc 16.644861 loss_rnnt 8.228652 hw_loss 0.140994 history loss 5.993574 rank 0
2023-03-01 13:49:47,886 DEBUG CV Batch 56/1000 loss 3.848057 loss_att 3.668931 loss_ctc 4.502413 loss_rnnt 3.698734 hw_loss 0.183565 history loss 5.798227 rank 1
2023-03-01 13:49:47,991 DEBUG CV Batch 56/1000 loss 3.848057 loss_att 3.668931 loss_ctc 4.502413 loss_rnnt 3.698734 hw_loss 0.183565 history loss 5.798227 rank 4
2023-03-01 13:49:48,987 DEBUG CV Batch 56/1000 loss 3.848057 loss_att 3.668931 loss_ctc 4.502413 loss_rnnt 3.698734 hw_loss 0.183565 history loss 5.798227 rank 5
2023-03-01 13:49:49,376 DEBUG CV Batch 56/1000 loss 3.848057 loss_att 3.668931 loss_ctc 4.502413 loss_rnnt 3.698734 hw_loss 0.183565 history loss 5.798227 rank 2
2023-03-01 13:49:49,814 DEBUG CV Batch 56/1000 loss 3.848057 loss_att 3.668931 loss_ctc 4.502413 loss_rnnt 3.698734 hw_loss 0.183565 history loss 5.798227 rank 3
2023-03-01 13:49:50,151 DEBUG CV Batch 56/1000 loss 3.848057 loss_att 3.668931 loss_ctc 4.502413 loss_rnnt 3.698734 hw_loss 0.183565 history loss 5.798227 rank 6
2023-03-01 13:49:53,131 DEBUG CV Batch 56/1000 loss 3.848057 loss_att 3.668931 loss_ctc 4.502413 loss_rnnt 3.698734 hw_loss 0.183565 history loss 5.798227 rank 7
2023-03-01 13:49:55,239 DEBUG CV Batch 56/1000 loss 3.848057 loss_att 3.668931 loss_ctc 4.502413 loss_rnnt 3.698734 hw_loss 0.183565 history loss 5.798227 rank 0
2023-03-01 13:49:59,582 DEBUG CV Batch 56/1100 loss 5.173595 loss_att 4.801661 loss_ctc 8.418139 loss_rnnt 4.608730 hw_loss 0.387459 history loss 5.756764 rank 1
2023-03-01 13:49:59,773 DEBUG CV Batch 56/1100 loss 5.173595 loss_att 4.801661 loss_ctc 8.418139 loss_rnnt 4.608730 hw_loss 0.387459 history loss 5.756764 rank 4
2023-03-01 13:50:00,995 DEBUG CV Batch 56/1100 loss 5.173595 loss_att 4.801661 loss_ctc 8.418139 loss_rnnt 4.608730 hw_loss 0.387459 history loss 5.756764 rank 5
2023-03-01 13:50:01,412 DEBUG CV Batch 56/1100 loss 5.173595 loss_att 4.801661 loss_ctc 8.418139 loss_rnnt 4.608730 hw_loss 0.387460 history loss 5.756764 rank 2
2023-03-01 13:50:02,090 DEBUG CV Batch 56/1100 loss 5.173595 loss_att 4.801661 loss_ctc 8.418139 loss_rnnt 4.608730 hw_loss 0.387459 history loss 5.756764 rank 3
2023-03-01 13:50:02,404 DEBUG CV Batch 56/1100 loss 5.173595 loss_att 4.801661 loss_ctc 8.418139 loss_rnnt 4.608730 hw_loss 0.387459 history loss 5.756764 rank 6
2023-03-01 13:50:05,627 DEBUG CV Batch 56/1100 loss 5.173595 loss_att 4.801661 loss_ctc 8.418139 loss_rnnt 4.608730 hw_loss 0.387459 history loss 5.756764 rank 7
2023-03-01 13:50:08,052 DEBUG CV Batch 56/1100 loss 5.173595 loss_att 4.801661 loss_ctc 8.418139 loss_rnnt 4.608730 hw_loss 0.387459 history loss 5.756764 rank 0
2023-03-01 13:50:10,256 DEBUG CV Batch 56/1200 loss 6.286493 loss_att 6.091733 loss_ctc 6.658095 loss_rnnt 6.130624 hw_loss 0.272387 history loss 6.033391 rank 1
2023-03-01 13:50:10,495 DEBUG CV Batch 56/1200 loss 6.286493 loss_att 6.091733 loss_ctc 6.658095 loss_rnnt 6.130624 hw_loss 0.272387 history loss 6.033391 rank 4
2023-03-01 13:50:11,686 DEBUG CV Batch 56/1200 loss 6.286493 loss_att 6.091733 loss_ctc 6.658095 loss_rnnt 6.130624 hw_loss 0.272387 history loss 6.033391 rank 5
2023-03-01 13:50:12,363 DEBUG CV Batch 56/1200 loss 6.286493 loss_att 6.091733 loss_ctc 6.658095 loss_rnnt 6.130624 hw_loss 0.272387 history loss 6.033391 rank 2
2023-03-01 13:50:13,455 DEBUG CV Batch 56/1200 loss 6.286493 loss_att 6.091733 loss_ctc 6.658095 loss_rnnt 6.130624 hw_loss 0.272387 history loss 6.033391 rank 3
2023-03-01 13:50:13,545 DEBUG CV Batch 56/1200 loss 6.286493 loss_att 6.091733 loss_ctc 6.658095 loss_rnnt 6.130624 hw_loss 0.272387 history loss 6.033391 rank 6
2023-03-01 13:50:16,965 DEBUG CV Batch 56/1200 loss 6.286493 loss_att 6.091733 loss_ctc 6.658095 loss_rnnt 6.130624 hw_loss 0.272387 history loss 6.033391 rank 7
2023-03-01 13:50:19,589 DEBUG CV Batch 56/1200 loss 6.286493 loss_att 6.091733 loss_ctc 6.658095 loss_rnnt 6.130624 hw_loss 0.272387 history loss 6.033391 rank 0
2023-03-01 13:50:22,313 DEBUG CV Batch 56/1300 loss 5.044178 loss_att 4.667706 loss_ctc 7.781392 loss_rnnt 4.641776 hw_loss 0.211376 history loss 6.325584 rank 1
2023-03-01 13:50:22,414 DEBUG CV Batch 56/1300 loss 5.044178 loss_att 4.667706 loss_ctc 7.781392 loss_rnnt 4.641776 hw_loss 0.211376 history loss 6.325584 rank 4
2023-03-01 13:50:23,972 DEBUG CV Batch 56/1300 loss 5.044178 loss_att 4.667706 loss_ctc 7.781392 loss_rnnt 4.641776 hw_loss 0.211376 history loss 6.325584 rank 5
2023-03-01 13:50:24,508 DEBUG CV Batch 56/1300 loss 5.044178 loss_att 4.667706 loss_ctc 7.781392 loss_rnnt 4.641776 hw_loss 0.211376 history loss 6.325584 rank 2
2023-03-01 13:50:25,912 DEBUG CV Batch 56/1300 loss 5.044178 loss_att 4.667706 loss_ctc 7.781392 loss_rnnt 4.641776 hw_loss 0.211376 history loss 6.325584 rank 3
2023-03-01 13:50:26,007 DEBUG CV Batch 56/1300 loss 5.044178 loss_att 4.667706 loss_ctc 7.781392 loss_rnnt 4.641776 hw_loss 0.211376 history loss 6.325584 rank 6
2023-03-01 13:50:29,578 DEBUG CV Batch 56/1300 loss 5.044178 loss_att 4.667706 loss_ctc 7.781392 loss_rnnt 4.641776 hw_loss 0.211376 history loss 6.325584 rank 7
2023-03-01 13:50:32,403 DEBUG CV Batch 56/1300 loss 5.044178 loss_att 4.667706 loss_ctc 7.781392 loss_rnnt 4.641776 hw_loss 0.211376 history loss 6.325584 rank 0
2023-03-01 13:50:33,382 DEBUG CV Batch 56/1400 loss 2.572930 loss_att 8.775871 loss_ctc 3.040509 loss_rnnt 1.218953 hw_loss 0.095710 history loss 6.614693 rank 1
2023-03-01 13:50:33,839 DEBUG CV Batch 56/1400 loss 2.572930 loss_att 8.775871 loss_ctc 3.040509 loss_rnnt 1.218953 hw_loss 0.095710 history loss 6.614693 rank 4
2023-03-01 13:50:35,364 DEBUG CV Batch 56/1400 loss 2.572930 loss_att 8.775871 loss_ctc 3.040509 loss_rnnt 1.218953 hw_loss 0.095710 history loss 6.614693 rank 5
2023-03-01 13:50:35,844 DEBUG CV Batch 56/1400 loss 2.572930 loss_att 8.775871 loss_ctc 3.040509 loss_rnnt 1.218953 hw_loss 0.095710 history loss 6.614693 rank 2
2023-03-01 13:50:37,322 DEBUG CV Batch 56/1400 loss 2.572930 loss_att 8.775871 loss_ctc 3.040509 loss_rnnt 1.218953 hw_loss 0.095710 history loss 6.614693 rank 3
2023-03-01 13:50:37,674 DEBUG CV Batch 56/1400 loss 2.572930 loss_att 8.775871 loss_ctc 3.040509 loss_rnnt 1.218953 hw_loss 0.095710 history loss 6.614693 rank 6
2023-03-01 13:50:41,473 DEBUG CV Batch 56/1400 loss 2.572930 loss_att 8.775871 loss_ctc 3.040509 loss_rnnt 1.218953 hw_loss 0.095710 history loss 6.614693 rank 7
2023-03-01 13:50:44,427 DEBUG CV Batch 56/1400 loss 2.572930 loss_att 8.775871 loss_ctc 3.040509 loss_rnnt 1.218953 hw_loss 0.095710 history loss 6.614693 rank 0
2023-03-01 13:50:44,934 DEBUG CV Batch 56/1500 loss 6.632702 loss_att 6.778874 loss_ctc 6.134082 loss_rnnt 6.509058 hw_loss 0.301675 history loss 6.475182 rank 1
2023-03-01 13:50:45,465 DEBUG CV Batch 56/1500 loss 6.632702 loss_att 6.778874 loss_ctc 6.134082 loss_rnnt 6.509058 hw_loss 0.301675 history loss 6.475182 rank 4
2023-03-01 13:50:47,286 DEBUG CV Batch 56/1500 loss 6.632702 loss_att 6.778874 loss_ctc 6.134082 loss_rnnt 6.509058 hw_loss 0.301675 history loss 6.475182 rank 5
2023-03-01 13:50:47,575 DEBUG CV Batch 56/1500 loss 6.632702 loss_att 6.778874 loss_ctc 6.134082 loss_rnnt 6.509058 hw_loss 0.301675 history loss 6.475182 rank 2
2023-03-01 13:50:49,079 DEBUG CV Batch 56/1500 loss 6.632702 loss_att 6.778874 loss_ctc 6.134082 loss_rnnt 6.509058 hw_loss 0.301675 history loss 6.475182 rank 3
2023-03-01 13:50:49,578 DEBUG CV Batch 56/1500 loss 6.632702 loss_att 6.778874 loss_ctc 6.134082 loss_rnnt 6.509058 hw_loss 0.301675 history loss 6.475182 rank 6
2023-03-01 13:50:53,659 DEBUG CV Batch 56/1500 loss 6.632702 loss_att 6.778874 loss_ctc 6.134082 loss_rnnt 6.509058 hw_loss 0.301675 history loss 6.475182 rank 7
2023-03-01 13:50:56,729 DEBUG CV Batch 56/1500 loss 6.632702 loss_att 6.778874 loss_ctc 6.134082 loss_rnnt 6.509058 hw_loss 0.301675 history loss 6.475182 rank 0
2023-03-01 13:50:57,845 DEBUG CV Batch 56/1600 loss 10.449702 loss_att 13.619113 loss_ctc 14.872218 loss_rnnt 9.108743 hw_loss 0.220141 history loss 6.437208 rank 1
2023-03-01 13:50:58,687 DEBUG CV Batch 56/1600 loss 10.449702 loss_att 13.619113 loss_ctc 14.872218 loss_rnnt 9.108743 hw_loss 0.220141 history loss 6.437208 rank 4
2023-03-01 13:51:00,488 DEBUG CV Batch 56/1600 loss 10.449702 loss_att 13.619113 loss_ctc 14.872218 loss_rnnt 9.108743 hw_loss 0.220141 history loss 6.437208 rank 5
2023-03-01 13:51:00,807 DEBUG CV Batch 56/1600 loss 10.449702 loss_att 13.619113 loss_ctc 14.872218 loss_rnnt 9.108743 hw_loss 0.220141 history loss 6.437208 rank 2
2023-03-01 13:51:02,429 DEBUG CV Batch 56/1600 loss 10.449702 loss_att 13.619113 loss_ctc 14.872218 loss_rnnt 9.108743 hw_loss 0.220141 history loss 6.437208 rank 3
2023-03-01 13:51:02,875 DEBUG CV Batch 56/1600 loss 10.449702 loss_att 13.619113 loss_ctc 14.872218 loss_rnnt 9.108743 hw_loss 0.220141 history loss 6.437208 rank 6
2023-03-01 13:51:07,139 DEBUG CV Batch 56/1600 loss 10.449702 loss_att 13.619113 loss_ctc 14.872218 loss_rnnt 9.108743 hw_loss 0.220141 history loss 6.437208 rank 7
2023-03-01 13:51:10,212 DEBUG CV Batch 56/1700 loss 7.857862 loss_att 6.620670 loss_ctc 15.015202 loss_rnnt 7.013450 hw_loss 0.257885 history loss 6.370492 rank 1
2023-03-01 13:51:10,557 DEBUG CV Batch 56/1600 loss 10.449702 loss_att 13.619113 loss_ctc 14.872218 loss_rnnt 9.108743 hw_loss 0.220141 history loss 6.437208 rank 0
2023-03-01 13:51:11,170 DEBUG CV Batch 56/1700 loss 7.857862 loss_att 6.620670 loss_ctc 15.015202 loss_rnnt 7.013450 hw_loss 0.257885 history loss 6.370492 rank 4
2023-03-01 13:51:13,381 DEBUG CV Batch 56/1700 loss 7.857862 loss_att 6.620670 loss_ctc 15.015202 loss_rnnt 7.013450 hw_loss 0.257885 history loss 6.370492 rank 2
2023-03-01 13:51:13,449 DEBUG CV Batch 56/1700 loss 7.857862 loss_att 6.620670 loss_ctc 15.015202 loss_rnnt 7.013450 hw_loss 0.257885 history loss 6.370492 rank 5
2023-03-01 13:51:14,926 DEBUG CV Batch 56/1700 loss 7.857862 loss_att 6.620670 loss_ctc 15.015202 loss_rnnt 7.013450 hw_loss 0.257885 history loss 6.370492 rank 3
2023-03-01 13:51:15,519 DEBUG CV Batch 56/1700 loss 7.857862 loss_att 6.620670 loss_ctc 15.015202 loss_rnnt 7.013450 hw_loss 0.257885 history loss 6.370492 rank 6
2023-03-01 13:51:19,214 INFO Epoch 56 CV info cv_loss 6.352697170494453
2023-03-01 13:51:19,215 INFO Epoch 57 TRAIN info lr 0.00028554045032239134
2023-03-01 13:51:19,219 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 13:51:19,598 DEBUG CV Batch 56/1700 loss 7.857862 loss_att 6.620670 loss_ctc 15.015202 loss_rnnt 7.013450 hw_loss 0.257885 history loss 6.370492 rank 7
2023-03-01 13:51:20,226 INFO Epoch 56 CV info cv_loss 6.352697168758605
2023-03-01 13:51:20,227 INFO Epoch 57 TRAIN info lr 0.0002855432440916877
2023-03-01 13:51:20,231 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 13:51:22,745 INFO Epoch 56 CV info cv_loss 6.352697169434854
2023-03-01 13:51:22,746 INFO Epoch 57 TRAIN info lr 0.00028554883187630097
2023-03-01 13:51:22,749 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 13:51:22,784 INFO Epoch 56 CV info cv_loss 6.352697169154878
2023-03-01 13:51:22,784 INFO Epoch 57 TRAIN info lr 0.00028554510665011024
2023-03-01 13:51:22,789 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 13:51:23,165 DEBUG CV Batch 56/1700 loss 7.857862 loss_att 6.620670 loss_ctc 15.015202 loss_rnnt 7.013450 hw_loss 0.257885 history loss 6.370492 rank 0
2023-03-01 13:51:24,330 INFO Epoch 56 CV info cv_loss 6.352697169137649
2023-03-01 13:51:24,331 INFO Epoch 57 TRAIN info lr 0.000285544175366343
2023-03-01 13:51:24,332 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 13:51:25,192 INFO Epoch 56 CV info cv_loss 6.352697168444171
2023-03-01 13:51:25,193 INFO Epoch 57 TRAIN info lr 0.00028555348861407435
2023-03-01 13:51:25,199 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 13:51:29,150 INFO Epoch 56 CV info cv_loss 6.352697168205115
2023-03-01 13:51:29,150 INFO Epoch 57 TRAIN info lr 0.0002855446410070877
2023-03-01 13:51:29,155 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 13:51:33,003 INFO Epoch 56 CV info cv_loss 6.35269716918503
2023-03-01 13:51:33,003 INFO Checkpoint: save to checkpoint exp/2_27_rnnt_bias_loss_2_class_both_finetune/56.pt
2023-03-01 13:51:33,551 INFO Epoch 57 TRAIN info lr 0.00028555535137297623
2023-03-01 13:51:33,555 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 13:52:31,154 DEBUG TRAIN Batch 57/0 loss 7.716208 loss_att 7.514516 loss_ctc 10.699704 loss_rnnt 7.165960 hw_loss 0.361473 lr 0.00028554 rank 4
2023-03-01 13:52:31,154 DEBUG TRAIN Batch 57/0 loss 7.762913 loss_att 8.180517 loss_ctc 12.045009 loss_rnnt 6.890765 hw_loss 0.408153 lr 0.00028554 rank 3
2023-03-01 13:52:31,157 DEBUG TRAIN Batch 57/0 loss 7.527902 loss_att 7.505618 loss_ctc 10.999944 loss_rnnt 6.907434 hw_loss 0.303721 lr 0.00028554 rank 2
2023-03-01 13:52:31,161 DEBUG TRAIN Batch 57/0 loss 7.154784 loss_att 6.758643 loss_ctc 11.292882 loss_rnnt 6.470402 hw_loss 0.397246 lr 0.00028555 rank 6
2023-03-01 13:52:31,161 DEBUG TRAIN Batch 57/0 loss 7.417634 loss_att 7.644579 loss_ctc 12.579831 loss_rnnt 6.521414 hw_loss 0.304759 lr 0.00028554 rank 7
2023-03-01 13:52:31,162 DEBUG TRAIN Batch 57/0 loss 6.307162 loss_att 6.759192 loss_ctc 10.640554 loss_rnnt 5.443508 hw_loss 0.366493 lr 0.00028555 rank 5
2023-03-01 13:52:31,182 DEBUG TRAIN Batch 57/0 loss 6.047897 loss_att 6.625118 loss_ctc 8.896229 loss_rnnt 5.349752 hw_loss 0.380483 lr 0.00028555 rank 0
2023-03-01 13:52:31,207 DEBUG TRAIN Batch 57/0 loss 6.732116 loss_att 6.759781 loss_ctc 8.935685 loss_rnnt 6.263700 hw_loss 0.317013 lr 0.00028554 rank 1
2023-03-01 13:53:08,525 DEBUG TRAIN Batch 57/100 loss 7.643987 loss_att 9.612308 loss_ctc 9.544098 loss_rnnt 6.861505 hw_loss 0.254007 lr 0.00028553 rank 2
2023-03-01 13:53:08,526 DEBUG TRAIN Batch 57/100 loss 3.114506 loss_att 7.168449 loss_ctc 5.791484 loss_rnnt 1.790467 hw_loss 0.293101 lr 0.00028554 rank 0
2023-03-01 13:53:08,528 DEBUG TRAIN Batch 57/100 loss 7.813779 loss_att 9.622505 loss_ctc 9.698391 loss_rnnt 7.071597 hw_loss 0.242168 lr 0.00028553 rank 7
2023-03-01 13:53:08,528 DEBUG TRAIN Batch 57/100 loss 4.190875 loss_att 6.673698 loss_ctc 4.708565 loss_rnnt 3.562275 hw_loss 0.118142 lr 0.00028554 rank 6
2023-03-01 13:53:08,531 DEBUG TRAIN Batch 57/100 loss 6.248390 loss_att 9.063126 loss_ctc 11.644721 loss_rnnt 4.906217 hw_loss 0.111968 lr 0.00028553 rank 1
2023-03-01 13:53:08,533 DEBUG TRAIN Batch 57/100 loss 8.051880 loss_att 11.457546 loss_ctc 13.867309 loss_rnnt 6.594256 hw_loss 0.002063 lr 0.00028553 rank 3
2023-03-01 13:53:08,544 DEBUG TRAIN Batch 57/100 loss 8.785495 loss_att 11.922335 loss_ctc 15.183719 loss_rnnt 7.175528 hw_loss 0.242816 lr 0.00028553 rank 4
2023-03-01 13:53:08,550 DEBUG TRAIN Batch 57/100 loss 3.361593 loss_att 6.597353 loss_ctc 6.204875 loss_rnnt 2.188759 hw_loss 0.274833 lr 0.00028554 rank 5
2023-03-01 13:53:46,803 DEBUG TRAIN Batch 57/200 loss 4.075176 loss_att 7.335493 loss_ctc 6.354537 loss_rnnt 3.011165 hw_loss 0.202561 lr 0.00028552 rank 7
2023-03-01 13:53:46,823 DEBUG TRAIN Batch 57/200 loss 3.985653 loss_att 5.767668 loss_ctc 7.255816 loss_rnnt 3.104091 hw_loss 0.167132 lr 0.00028552 rank 1
2023-03-01 13:53:46,824 DEBUG TRAIN Batch 57/200 loss 5.199452 loss_att 8.109035 loss_ctc 8.455330 loss_rnnt 4.092338 hw_loss 0.170777 lr 0.00028552 rank 3
2023-03-01 13:53:46,825 DEBUG TRAIN Batch 57/200 loss 4.543536 loss_att 9.121399 loss_ctc 12.093906 loss_rnnt 2.541692 hw_loss 0.149167 lr 0.00028553 rank 6
2023-03-01 13:53:46,827 DEBUG TRAIN Batch 57/200 loss 3.517944 loss_att 4.355181 loss_ctc 4.967079 loss_rnnt 3.022573 hw_loss 0.252573 lr 0.00028553 rank 5
2023-03-01 13:53:46,829 DEBUG TRAIN Batch 57/200 loss 11.041093 loss_att 18.614351 loss_ctc 24.345839 loss_rnnt 7.670736 hw_loss 0.153261 lr 0.00028553 rank 0
2023-03-01 13:53:46,830 DEBUG TRAIN Batch 57/200 loss 3.762145 loss_att 6.749755 loss_ctc 6.545106 loss_rnnt 2.633396 hw_loss 0.300311 lr 0.00028552 rank 4
2023-03-01 13:53:46,833 DEBUG TRAIN Batch 57/200 loss 3.834453 loss_att 5.165505 loss_ctc 6.623258 loss_rnnt 3.098427 hw_loss 0.183704 lr 0.00028552 rank 2
2023-03-01 13:54:24,880 DEBUG TRAIN Batch 57/300 loss 14.649618 loss_att 17.523312 loss_ctc 22.606430 loss_rnnt 12.968744 hw_loss 0.084799 lr 0.00028552 rank 0
2023-03-01 13:54:24,882 DEBUG TRAIN Batch 57/300 loss 4.197597 loss_att 5.947290 loss_ctc 9.111932 loss_rnnt 3.116368 hw_loss 0.142587 lr 0.00028551 rank 1
2023-03-01 13:54:24,885 DEBUG TRAIN Batch 57/300 loss 5.504888 loss_att 9.499788 loss_ctc 13.118042 loss_rnnt 3.590427 hw_loss 0.188238 lr 0.00028551 rank 2
2023-03-01 13:54:24,886 DEBUG TRAIN Batch 57/300 loss 7.924079 loss_att 10.872122 loss_ctc 11.680696 loss_rnnt 6.804280 hw_loss 0.054953 lr 0.00028551 rank 5
2023-03-01 13:54:24,886 DEBUG TRAIN Batch 57/300 loss 7.144979 loss_att 9.730264 loss_ctc 10.590483 loss_rnnt 6.083343 hw_loss 0.159710 lr 0.00028552 rank 6
2023-03-01 13:54:24,887 DEBUG TRAIN Batch 57/300 loss 4.407722 loss_att 8.696443 loss_ctc 7.894751 loss_rnnt 2.999854 hw_loss 0.159726 lr 0.00028551 rank 7
2023-03-01 13:54:24,889 DEBUG TRAIN Batch 57/300 loss 6.582792 loss_att 9.807443 loss_ctc 10.053537 loss_rnnt 5.434364 hw_loss 0.076372 lr 0.00028551 rank 4
2023-03-01 13:54:24,893 DEBUG TRAIN Batch 57/300 loss 5.748513 loss_att 8.809632 loss_ctc 9.930072 loss_rnnt 4.481963 hw_loss 0.181472 lr 0.00028551 rank 3
2023-03-01 13:55:26,407 DEBUG TRAIN Batch 57/400 loss 9.044598 loss_att 10.258022 loss_ctc 15.351931 loss_rnnt 7.738952 hw_loss 0.416219 lr 0.00028550 rank 5
2023-03-01 13:55:26,419 DEBUG TRAIN Batch 57/400 loss 7.030334 loss_att 8.786579 loss_ctc 8.308434 loss_rnnt 6.386000 hw_loss 0.230010 lr 0.00028550 rank 7
2023-03-01 13:55:26,419 DEBUG TRAIN Batch 57/400 loss 9.341359 loss_att 12.743853 loss_ctc 13.095058 loss_rnnt 8.082609 hw_loss 0.145796 lr 0.00028550 rank 2
2023-03-01 13:55:26,421 DEBUG TRAIN Batch 57/400 loss 7.054372 loss_att 12.271112 loss_ctc 14.222830 loss_rnnt 4.885647 hw_loss 0.317968 lr 0.00028551 rank 0
2023-03-01 13:55:26,421 DEBUG TRAIN Batch 57/400 loss 6.464016 loss_att 8.351369 loss_ctc 9.106374 loss_rnnt 5.568451 hw_loss 0.310840 lr 0.00028550 rank 3
2023-03-01 13:55:26,424 DEBUG TRAIN Batch 57/400 loss 10.564984 loss_att 13.666607 loss_ctc 14.298225 loss_rnnt 9.321532 hw_loss 0.235055 lr 0.00028551 rank 6
2023-03-01 13:55:26,428 DEBUG TRAIN Batch 57/400 loss 6.485868 loss_att 10.361590 loss_ctc 14.238787 loss_rnnt 4.482538 hw_loss 0.364618 lr 0.00028550 rank 4
2023-03-01 13:55:26,425 DEBUG TRAIN Batch 57/400 loss 5.344074 loss_att 10.410196 loss_ctc 11.212827 loss_rnnt 3.432549 hw_loss 0.217126 lr 0.00028549 rank 1
2023-03-01 13:56:04,953 DEBUG TRAIN Batch 57/500 loss 6.488321 loss_att 7.363964 loss_ctc 9.444720 loss_rnnt 5.775405 hw_loss 0.269253 lr 0.00028549 rank 6
2023-03-01 13:56:04,955 DEBUG TRAIN Batch 57/500 loss 6.330948 loss_att 7.167315 loss_ctc 7.256544 loss_rnnt 5.898245 hw_loss 0.266281 lr 0.00028549 rank 2
2023-03-01 13:56:04,957 DEBUG TRAIN Batch 57/500 loss 2.917568 loss_att 5.595861 loss_ctc 5.194695 loss_rnnt 2.019650 hw_loss 0.109956 lr 0.00028549 rank 3
2023-03-01 13:56:04,963 DEBUG TRAIN Batch 57/500 loss 4.011880 loss_att 6.423005 loss_ctc 5.769135 loss_rnnt 3.048032 hw_loss 0.463728 lr 0.00028550 rank 0
2023-03-01 13:56:04,970 DEBUG TRAIN Batch 57/500 loss 9.929653 loss_att 11.959881 loss_ctc 16.117823 loss_rnnt 8.595256 hw_loss 0.193616 lr 0.00028549 rank 7
2023-03-01 13:56:04,972 DEBUG TRAIN Batch 57/500 loss 8.231433 loss_att 10.853473 loss_ctc 15.654615 loss_rnnt 6.568732 hw_loss 0.278504 lr 0.00028549 rank 5
2023-03-01 13:56:04,971 DEBUG TRAIN Batch 57/500 loss 7.386659 loss_att 11.542778 loss_ctc 15.247778 loss_rnnt 5.410388 hw_loss 0.181683 lr 0.00028548 rank 1
2023-03-01 13:56:05,017 DEBUG TRAIN Batch 57/500 loss 12.383714 loss_att 15.338164 loss_ctc 19.481316 loss_rnnt 10.755569 hw_loss 0.170451 lr 0.00028548 rank 4
2023-03-01 13:56:43,412 DEBUG TRAIN Batch 57/600 loss 12.328732 loss_att 14.983527 loss_ctc 18.591291 loss_rnnt 10.795790 hw_loss 0.313080 lr 0.00028549 rank 0
2023-03-01 13:56:43,414 DEBUG TRAIN Batch 57/600 loss 3.782185 loss_att 5.509849 loss_ctc 5.552450 loss_rnnt 3.095432 hw_loss 0.197221 lr 0.00028547 rank 4
2023-03-01 13:56:43,414 DEBUG TRAIN Batch 57/600 loss 2.583491 loss_att 4.448122 loss_ctc 6.420002 loss_rnnt 1.590534 hw_loss 0.203429 lr 0.00028547 rank 2
2023-03-01 13:56:43,415 DEBUG TRAIN Batch 57/600 loss 6.807535 loss_att 6.817756 loss_ctc 10.275836 loss_rnnt 6.181666 hw_loss 0.302596 lr 0.00028547 rank 7
2023-03-01 13:56:43,417 DEBUG TRAIN Batch 57/600 loss 5.668291 loss_att 7.395078 loss_ctc 7.906680 loss_rnnt 4.900203 hw_loss 0.233023 lr 0.00028548 rank 5
2023-03-01 13:56:43,421 DEBUG TRAIN Batch 57/600 loss 10.522156 loss_att 12.436804 loss_ctc 15.178019 loss_rnnt 9.361374 hw_loss 0.294506 lr 0.00028547 rank 3
2023-03-01 13:56:43,423 DEBUG TRAIN Batch 57/600 loss 8.270232 loss_att 10.364455 loss_ctc 14.664375 loss_rnnt 6.892737 hw_loss 0.198934 lr 0.00028548 rank 6
2023-03-01 13:56:43,462 DEBUG TRAIN Batch 57/600 loss 11.447442 loss_att 12.888801 loss_ctc 16.337879 loss_rnnt 10.268035 hw_loss 0.448270 lr 0.00028547 rank 1
2023-03-01 13:57:23,251 DEBUG TRAIN Batch 57/700 loss 3.063423 loss_att 6.449294 loss_ctc 7.763698 loss_rnnt 1.680235 hw_loss 0.148708 lr 0.00028546 rank 2
2023-03-01 13:57:23,252 DEBUG TRAIN Batch 57/700 loss 8.354935 loss_att 10.524119 loss_ctc 11.948973 loss_rnnt 7.328856 hw_loss 0.211945 lr 0.00028546 rank 1
2023-03-01 13:57:23,257 DEBUG TRAIN Batch 57/700 loss 4.887923 loss_att 9.687098 loss_ctc 12.160563 loss_rnnt 2.826179 hw_loss 0.247919 lr 0.00028546 rank 4
2023-03-01 13:57:23,265 DEBUG TRAIN Batch 57/700 loss 1.727741 loss_att 6.176922 loss_ctc 3.220238 loss_rnnt 0.512433 hw_loss 0.237134 lr 0.00028547 rank 0
2023-03-01 13:57:23,266 DEBUG TRAIN Batch 57/700 loss 5.019650 loss_att 9.393651 loss_ctc 9.861338 loss_rnnt 3.388933 hw_loss 0.206921 lr 0.00028547 rank 5
2023-03-01 13:57:23,289 DEBUG TRAIN Batch 57/700 loss 5.699002 loss_att 8.204993 loss_ctc 8.684753 loss_rnnt 4.700295 hw_loss 0.186391 lr 0.00028546 rank 7
2023-03-01 13:57:23,302 DEBUG TRAIN Batch 57/700 loss 6.422318 loss_att 10.709046 loss_ctc 10.570780 loss_rnnt 4.906273 hw_loss 0.197945 lr 0.00028547 rank 6
2023-03-01 13:57:23,304 DEBUG TRAIN Batch 57/700 loss 4.196187 loss_att 6.560157 loss_ctc 7.451394 loss_rnnt 3.147893 hw_loss 0.265262 lr 0.00028546 rank 3
2023-03-01 13:58:27,627 DEBUG TRAIN Batch 57/800 loss 6.770464 loss_att 9.892055 loss_ctc 13.179450 loss_rnnt 5.222422 hw_loss 0.129736 lr 0.00028546 rank 0
2023-03-01 13:58:27,637 DEBUG TRAIN Batch 57/800 loss 9.768483 loss_att 11.462099 loss_ctc 14.898790 loss_rnnt 8.606208 hw_loss 0.261582 lr 0.00028545 rank 2
2023-03-01 13:58:27,638 DEBUG TRAIN Batch 57/800 loss 2.567897 loss_att 8.311546 loss_ctc 2.889465 loss_rnnt 1.222976 hw_loss 0.287465 lr 0.00028545 rank 7
2023-03-01 13:58:27,643 DEBUG TRAIN Batch 57/800 loss 7.671717 loss_att 9.143824 loss_ctc 11.622011 loss_rnnt 6.775633 hw_loss 0.140544 lr 0.00028545 rank 1
2023-03-01 13:58:27,645 DEBUG TRAIN Batch 57/800 loss 5.224976 loss_att 8.499084 loss_ctc 7.196125 loss_rnnt 4.185463 hw_loss 0.228507 lr 0.00028546 rank 5
2023-03-01 13:58:27,646 DEBUG TRAIN Batch 57/800 loss 1.150045 loss_att 3.544048 loss_ctc 1.427937 loss_rnnt 0.510507 hw_loss 0.231910 lr 0.00028546 rank 6
2023-03-01 13:58:27,649 DEBUG TRAIN Batch 57/800 loss 3.345207 loss_att 5.764937 loss_ctc 4.135299 loss_rnnt 2.645917 hw_loss 0.206247 lr 0.00028545 rank 3
2023-03-01 13:58:27,652 DEBUG TRAIN Batch 57/800 loss 6.141125 loss_att 9.241512 loss_ctc 10.417224 loss_rnnt 4.793473 hw_loss 0.295178 lr 0.00028545 rank 4
2023-03-01 13:59:06,026 DEBUG TRAIN Batch 57/900 loss 6.159180 loss_att 10.733973 loss_ctc 13.093512 loss_rnnt 4.171551 hw_loss 0.277673 lr 0.00028544 rank 2
2023-03-01 13:59:06,028 DEBUG TRAIN Batch 57/900 loss 4.083516 loss_att 6.232677 loss_ctc 5.908826 loss_rnnt 3.214368 hw_loss 0.367389 lr 0.00028544 rank 1
2023-03-01 13:59:06,032 DEBUG TRAIN Batch 57/900 loss 6.681773 loss_att 10.953321 loss_ctc 11.281651 loss_rnnt 5.099145 hw_loss 0.215628 lr 0.00028544 rank 5
2023-03-01 13:59:06,046 DEBUG TRAIN Batch 57/900 loss 3.832000 loss_att 7.276691 loss_ctc 7.509047 loss_rnnt 2.611624 hw_loss 0.077184 lr 0.00028544 rank 7
2023-03-01 13:59:06,046 DEBUG TRAIN Batch 57/900 loss 6.809703 loss_att 10.691647 loss_ctc 8.959154 loss_rnnt 5.721433 hw_loss 0.047416 lr 0.00028545 rank 0
2023-03-01 13:59:06,046 DEBUG TRAIN Batch 57/900 loss 5.192896 loss_att 8.062419 loss_ctc 7.155301 loss_rnnt 4.260492 hw_loss 0.181584 lr 0.00028545 rank 6
2023-03-01 13:59:06,048 DEBUG TRAIN Batch 57/900 loss 12.154840 loss_att 13.216558 loss_ctc 14.661087 loss_rnnt 11.477945 hw_loss 0.244469 lr 0.00028544 rank 4
2023-03-01 13:59:06,049 DEBUG TRAIN Batch 57/900 loss 8.648381 loss_att 13.475340 loss_ctc 13.855165 loss_rnnt 6.926732 hw_loss 0.116287 lr 0.00028544 rank 3
2023-03-01 13:59:44,585 DEBUG TRAIN Batch 57/1000 loss 13.014704 loss_att 13.155389 loss_ctc 20.977425 loss_rnnt 11.844423 hw_loss 0.150838 lr 0.00028543 rank 5
2023-03-01 13:59:44,589 DEBUG TRAIN Batch 57/1000 loss 7.619713 loss_att 10.335304 loss_ctc 10.913682 loss_rnnt 6.517326 hw_loss 0.225135 lr 0.00028543 rank 2
2023-03-01 13:59:44,598 DEBUG TRAIN Batch 57/1000 loss 7.792650 loss_att 12.134793 loss_ctc 15.804575 loss_rnnt 5.756162 hw_loss 0.187128 lr 0.00028544 rank 0
2023-03-01 13:59:44,598 DEBUG TRAIN Batch 57/1000 loss 4.521597 loss_att 6.058475 loss_ctc 6.643354 loss_rnnt 3.827330 hw_loss 0.194983 lr 0.00028543 rank 7
2023-03-01 13:59:44,608 DEBUG TRAIN Batch 57/1000 loss 4.516022 loss_att 5.708723 loss_ctc 5.053021 loss_rnnt 4.120662 hw_loss 0.159785 lr 0.00028542 rank 1
2023-03-01 13:59:44,612 DEBUG TRAIN Batch 57/1000 loss 5.197844 loss_att 8.233729 loss_ctc 8.712989 loss_rnnt 4.062846 hw_loss 0.110878 lr 0.00028543 rank 4
2023-03-01 13:59:44,620 DEBUG TRAIN Batch 57/1000 loss 8.659147 loss_att 12.911102 loss_ctc 18.690247 loss_rnnt 6.399892 hw_loss 0.133845 lr 0.00028543 rank 3
2023-03-01 13:59:44,624 DEBUG TRAIN Batch 57/1000 loss 6.267271 loss_att 10.523043 loss_ctc 10.064714 loss_rnnt 4.773610 hw_loss 0.255338 lr 0.00028544 rank 6
2023-03-01 14:00:49,296 DEBUG TRAIN Batch 57/1100 loss 7.075031 loss_att 8.059639 loss_ctc 11.092279 loss_rnnt 6.240138 hw_loss 0.191883 lr 0.00028543 rank 0
2023-03-01 14:00:49,296 DEBUG TRAIN Batch 57/1100 loss 6.059209 loss_att 8.748762 loss_ctc 11.111279 loss_rnnt 4.808219 hw_loss 0.074006 lr 0.00028541 rank 1
2023-03-01 14:00:49,298 DEBUG TRAIN Batch 57/1100 loss 4.231799 loss_att 7.082560 loss_ctc 7.252518 loss_rnnt 3.076715 hw_loss 0.341566 lr 0.00028543 rank 6
2023-03-01 14:00:49,303 DEBUG TRAIN Batch 57/1100 loss 5.014388 loss_att 8.088821 loss_ctc 12.288960 loss_rnnt 3.415058 hw_loss 0.027187 lr 0.00028542 rank 5
2023-03-01 14:00:49,305 DEBUG TRAIN Batch 57/1100 loss 5.676847 loss_att 8.980270 loss_ctc 7.290504 loss_rnnt 4.666279 hw_loss 0.252617 lr 0.00028542 rank 3
2023-03-01 14:00:49,307 DEBUG TRAIN Batch 57/1100 loss 8.839528 loss_att 9.958984 loss_ctc 12.792638 loss_rnnt 7.926555 hw_loss 0.303750 lr 0.00028542 rank 7
2023-03-01 14:00:49,310 DEBUG TRAIN Batch 57/1100 loss 9.872992 loss_att 12.883213 loss_ctc 15.700250 loss_rnnt 8.369015 hw_loss 0.234308 lr 0.00028542 rank 2
2023-03-01 14:00:49,323 DEBUG TRAIN Batch 57/1100 loss 4.917202 loss_att 7.550544 loss_ctc 8.438163 loss_rnnt 3.809421 hw_loss 0.209347 lr 0.00028541 rank 4
2023-03-01 14:01:28,618 DEBUG TRAIN Batch 57/1200 loss 8.265903 loss_att 9.974276 loss_ctc 11.848094 loss_rnnt 7.309183 hw_loss 0.257665 lr 0.00028541 rank 6
2023-03-01 14:01:28,621 DEBUG TRAIN Batch 57/1200 loss 4.029180 loss_att 5.994183 loss_ctc 6.766660 loss_rnnt 3.164827 hw_loss 0.199416 lr 0.00028542 rank 0
2023-03-01 14:01:28,622 DEBUG TRAIN Batch 57/1200 loss 5.903286 loss_att 7.860355 loss_ctc 9.533741 loss_rnnt 4.883564 hw_loss 0.270464 lr 0.00028540 rank 7
2023-03-01 14:01:28,622 DEBUG TRAIN Batch 57/1200 loss 6.090652 loss_att 8.771356 loss_ctc 10.534615 loss_rnnt 4.904144 hw_loss 0.108448 lr 0.00028540 rank 1
2023-03-01 14:01:28,623 DEBUG TRAIN Batch 57/1200 loss 2.635177 loss_att 5.420809 loss_ctc 4.611015 loss_rnnt 1.701765 hw_loss 0.211576 lr 0.00028540 rank 3
2023-03-01 14:01:28,629 DEBUG TRAIN Batch 57/1200 loss 6.029078 loss_att 9.549717 loss_ctc 11.022457 loss_rnnt 4.529985 hw_loss 0.242215 lr 0.00028540 rank 4
2023-03-01 14:01:28,630 DEBUG TRAIN Batch 57/1200 loss 8.726284 loss_att 11.789243 loss_ctc 17.020664 loss_rnnt 6.918485 hw_loss 0.167418 lr 0.00028541 rank 2
2023-03-01 14:01:28,669 DEBUG TRAIN Batch 57/1200 loss 8.063754 loss_att 8.723887 loss_ctc 12.378010 loss_rnnt 7.220761 hw_loss 0.254496 lr 0.00028541 rank 5
2023-03-01 14:02:07,528 DEBUG TRAIN Batch 57/1300 loss 6.363137 loss_att 7.463801 loss_ctc 10.212153 loss_rnnt 5.443503 hw_loss 0.349311 lr 0.00028540 rank 5
2023-03-01 14:02:07,529 DEBUG TRAIN Batch 57/1300 loss 5.808113 loss_att 7.377488 loss_ctc 9.734847 loss_rnnt 4.763145 hw_loss 0.389115 lr 0.00028540 rank 0
2023-03-01 14:02:07,531 DEBUG TRAIN Batch 57/1300 loss 2.546479 loss_att 6.007774 loss_ctc 3.655067 loss_rnnt 1.587536 hw_loss 0.222884 lr 0.00028539 rank 7
2023-03-01 14:02:07,532 DEBUG TRAIN Batch 57/1300 loss 6.122894 loss_att 7.833504 loss_ctc 11.396149 loss_rnnt 4.938470 hw_loss 0.261002 lr 0.00028540 rank 6
2023-03-01 14:02:07,537 DEBUG TRAIN Batch 57/1300 loss 7.268626 loss_att 7.876224 loss_ctc 11.371820 loss_rnnt 6.402769 hw_loss 0.369834 lr 0.00028539 rank 3
2023-03-01 14:02:07,546 DEBUG TRAIN Batch 57/1300 loss 3.864900 loss_att 6.755915 loss_ctc 7.336257 loss_rnnt 2.763154 hw_loss 0.113805 lr 0.00028539 rank 1
2023-03-01 14:02:07,566 DEBUG TRAIN Batch 57/1300 loss 11.525883 loss_att 11.127590 loss_ctc 15.869066 loss_rnnt 10.864922 hw_loss 0.302866 lr 0.00028539 rank 2
2023-03-01 14:02:07,572 DEBUG TRAIN Batch 57/1300 loss 5.904534 loss_att 7.146674 loss_ctc 9.523037 loss_rnnt 4.985759 hw_loss 0.352275 lr 0.00028539 rank 4
2023-03-01 14:02:47,012 DEBUG TRAIN Batch 57/1400 loss 3.633824 loss_att 6.291889 loss_ctc 7.017271 loss_rnnt 2.469001 hw_loss 0.341409 lr 0.00028538 rank 1
2023-03-01 14:02:47,013 DEBUG TRAIN Batch 57/1400 loss 5.940617 loss_att 7.450570 loss_ctc 9.268463 loss_rnnt 5.064695 hw_loss 0.244157 lr 0.00028538 rank 2
2023-03-01 14:02:47,017 DEBUG TRAIN Batch 57/1400 loss 2.233858 loss_att 4.927144 loss_ctc 2.817210 loss_rnnt 1.528699 hw_loss 0.166352 lr 0.00028539 rank 5
2023-03-01 14:02:47,017 DEBUG TRAIN Batch 57/1400 loss 1.781209 loss_att 4.138238 loss_ctc 2.226228 loss_rnnt 1.115200 hw_loss 0.253626 lr 0.00028538 rank 7
2023-03-01 14:02:47,020 DEBUG TRAIN Batch 57/1400 loss 1.763386 loss_att 5.527830 loss_ctc 3.956508 loss_rnnt 0.561404 hw_loss 0.293770 lr 0.00028539 rank 6
2023-03-01 14:02:47,033 DEBUG TRAIN Batch 57/1400 loss 4.915710 loss_att 8.851698 loss_ctc 9.989015 loss_rnnt 3.393366 hw_loss 0.110072 lr 0.00028539 rank 0
2023-03-01 14:02:47,046 DEBUG TRAIN Batch 57/1400 loss 6.391666 loss_att 9.919841 loss_ctc 12.083170 loss_rnnt 4.844917 hw_loss 0.154213 lr 0.00028538 rank 4
2023-03-01 14:02:47,054 DEBUG TRAIN Batch 57/1400 loss 7.193260 loss_att 10.007137 loss_ctc 10.604308 loss_rnnt 6.056126 hw_loss 0.224160 lr 0.00028538 rank 3
2023-03-01 14:03:51,068 DEBUG TRAIN Batch 57/1500 loss 3.632895 loss_att 8.844232 loss_ctc 7.339017 loss_rnnt 1.972145 hw_loss 0.233122 lr 0.00028537 rank 5
2023-03-01 14:03:51,070 DEBUG TRAIN Batch 57/1500 loss 3.179101 loss_att 6.671530 loss_ctc 9.091602 loss_rnnt 1.632727 hw_loss 0.111665 lr 0.00028537 rank 1
2023-03-01 14:03:51,082 DEBUG TRAIN Batch 57/1500 loss 3.832456 loss_att 5.725499 loss_ctc 8.362860 loss_rnnt 2.718529 hw_loss 0.246123 lr 0.00028538 rank 6
2023-03-01 14:03:51,085 DEBUG TRAIN Batch 57/1500 loss 2.647706 loss_att 5.959156 loss_ctc 5.595401 loss_rnnt 1.506647 hw_loss 0.160770 lr 0.00028538 rank 0
2023-03-01 14:03:51,085 DEBUG TRAIN Batch 57/1500 loss 10.281837 loss_att 12.940720 loss_ctc 19.613503 loss_rnnt 8.420986 hw_loss 0.159096 lr 0.00028537 rank 3
2023-03-01 14:03:51,088 DEBUG TRAIN Batch 57/1500 loss 4.654886 loss_att 6.084260 loss_ctc 7.740429 loss_rnnt 3.759580 hw_loss 0.371297 lr 0.00028537 rank 7
2023-03-01 14:03:51,090 DEBUG TRAIN Batch 57/1500 loss 8.022118 loss_att 10.607851 loss_ctc 13.110682 loss_rnnt 6.700159 hw_loss 0.236880 lr 0.00028537 rank 4
2023-03-01 14:03:51,089 DEBUG TRAIN Batch 57/1500 loss 7.938382 loss_att 10.099222 loss_ctc 10.404123 loss_rnnt 7.089242 hw_loss 0.165385 lr 0.00028537 rank 2
2023-03-01 14:04:28,922 DEBUG TRAIN Batch 57/1600 loss 9.071487 loss_att 11.219495 loss_ctc 12.024115 loss_rnnt 8.094909 hw_loss 0.287426 lr 0.00028536 rank 4
2023-03-01 14:04:28,944 DEBUG TRAIN Batch 57/1600 loss 6.304966 loss_att 11.432312 loss_ctc 15.982725 loss_rnnt 3.910192 hw_loss 0.148009 lr 0.00028536 rank 5
2023-03-01 14:04:28,946 DEBUG TRAIN Batch 57/1600 loss 3.624057 loss_att 6.232862 loss_ctc 5.776174 loss_rnnt 2.740708 hw_loss 0.139949 lr 0.00028536 rank 7
2023-03-01 14:04:28,945 DEBUG TRAIN Batch 57/1600 loss 8.899083 loss_att 11.883038 loss_ctc 22.269880 loss_rnnt 6.449301 hw_loss 0.131661 lr 0.00028535 rank 1
2023-03-01 14:04:28,947 DEBUG TRAIN Batch 57/1600 loss 5.443976 loss_att 11.309525 loss_ctc 12.125652 loss_rnnt 3.267354 hw_loss 0.211167 lr 0.00028537 rank 0
2023-03-01 14:04:28,964 DEBUG TRAIN Batch 57/1600 loss 4.448839 loss_att 7.804497 loss_ctc 8.017920 loss_rnnt 3.210455 hw_loss 0.171327 lr 0.00028536 rank 2
2023-03-01 14:04:28,969 DEBUG TRAIN Batch 57/1600 loss 6.650209 loss_att 10.190007 loss_ctc 10.468271 loss_rnnt 5.382889 hw_loss 0.094285 lr 0.00028536 rank 3
2023-03-01 14:04:28,979 DEBUG TRAIN Batch 57/1600 loss 4.908695 loss_att 8.964928 loss_ctc 10.329002 loss_rnnt 3.271466 hw_loss 0.193641 lr 0.00028537 rank 6
2023-03-01 14:05:07,322 DEBUG TRAIN Batch 57/1700 loss 2.172159 loss_att 5.130024 loss_ctc 4.089710 loss_rnnt 1.274741 hw_loss 0.094074 lr 0.00028535 rank 5
2023-03-01 14:05:07,322 DEBUG TRAIN Batch 57/1700 loss 3.637907 loss_att 7.017559 loss_ctc 9.637585 loss_rnnt 2.126518 hw_loss 0.066567 lr 0.00028535 rank 3
2023-03-01 14:05:07,330 DEBUG TRAIN Batch 57/1700 loss 5.558792 loss_att 7.410831 loss_ctc 8.846405 loss_rnnt 4.640337 hw_loss 0.205684 lr 0.00028536 rank 6
2023-03-01 14:05:07,332 DEBUG TRAIN Batch 57/1700 loss 5.842110 loss_att 9.950071 loss_ctc 10.943872 loss_rnnt 4.272732 hw_loss 0.126658 lr 0.00028535 rank 2
2023-03-01 14:05:07,334 DEBUG TRAIN Batch 57/1700 loss 3.914682 loss_att 5.888569 loss_ctc 7.321280 loss_rnnt 2.904446 hw_loss 0.302335 lr 0.00028536 rank 0
2023-03-01 14:05:07,336 DEBUG TRAIN Batch 57/1700 loss 5.582667 loss_att 8.461374 loss_ctc 13.721986 loss_rnnt 3.811367 hw_loss 0.206843 lr 0.00028535 rank 4
2023-03-01 14:05:07,339 DEBUG TRAIN Batch 57/1700 loss 6.108447 loss_att 10.116712 loss_ctc 13.139362 loss_rnnt 4.259002 hw_loss 0.206880 lr 0.00028535 rank 7
2023-03-01 14:05:07,341 DEBUG TRAIN Batch 57/1700 loss 8.010324 loss_att 10.470473 loss_ctc 12.491030 loss_rnnt 6.813180 hw_loss 0.201911 lr 0.00028534 rank 1
2023-03-01 14:06:12,294 DEBUG TRAIN Batch 57/1800 loss 5.253409 loss_att 8.640957 loss_ctc 11.669322 loss_rnnt 3.573396 hw_loss 0.275717 lr 0.00028535 rank 0
2023-03-01 14:06:12,302 DEBUG TRAIN Batch 57/1800 loss 8.636379 loss_att 10.830095 loss_ctc 14.627425 loss_rnnt 7.328905 hw_loss 0.131108 lr 0.00028533 rank 7
2023-03-01 14:06:12,302 DEBUG TRAIN Batch 57/1800 loss 5.325295 loss_att 7.916395 loss_ctc 10.407180 loss_rnnt 3.988317 hw_loss 0.264701 lr 0.00028534 rank 6
2023-03-01 14:06:12,305 DEBUG TRAIN Batch 57/1800 loss 5.682289 loss_att 6.603674 loss_ctc 7.662448 loss_rnnt 5.088280 hw_loss 0.273208 lr 0.00028533 rank 1
2023-03-01 14:06:12,309 DEBUG TRAIN Batch 57/1800 loss 3.362218 loss_att 6.443384 loss_ctc 8.209249 loss_rnnt 1.929516 hw_loss 0.319123 lr 0.00028533 rank 3
2023-03-01 14:06:12,312 DEBUG TRAIN Batch 57/1800 loss 7.991478 loss_att 10.386419 loss_ctc 14.151096 loss_rnnt 6.571506 hw_loss 0.224443 lr 0.00028534 rank 2
2023-03-01 14:06:12,315 DEBUG TRAIN Batch 57/1800 loss 7.221969 loss_att 7.281912 loss_ctc 9.175393 loss_rnnt 6.920939 hw_loss 0.053598 lr 0.00028534 rank 5
2023-03-01 14:06:12,360 DEBUG TRAIN Batch 57/1800 loss 3.885541 loss_att 6.800985 loss_ctc 6.753631 loss_rnnt 2.817363 hw_loss 0.192520 lr 0.00028533 rank 4
2023-03-01 14:06:50,806 DEBUG TRAIN Batch 57/1900 loss 6.410129 loss_att 8.491510 loss_ctc 11.443576 loss_rnnt 5.172153 hw_loss 0.282325 lr 0.00028533 rank 5
2023-03-01 14:06:50,810 DEBUG TRAIN Batch 57/1900 loss 5.590105 loss_att 6.861987 loss_ctc 9.190450 loss_rnnt 4.746750 hw_loss 0.204248 lr 0.00028532 rank 2
2023-03-01 14:06:50,810 DEBUG TRAIN Batch 57/1900 loss 3.794016 loss_att 5.051117 loss_ctc 5.950640 loss_rnnt 3.070939 hw_loss 0.345200 lr 0.00028532 rank 7
2023-03-01 14:06:50,810 DEBUG TRAIN Batch 57/1900 loss 9.975266 loss_att 10.754132 loss_ctc 15.161386 loss_rnnt 8.981151 hw_loss 0.275362 lr 0.00028533 rank 6
2023-03-01 14:06:50,815 DEBUG TRAIN Batch 57/1900 loss 4.429479 loss_att 6.999786 loss_ctc 7.755521 loss_rnnt 3.304737 hw_loss 0.313515 lr 0.00028533 rank 0
2023-03-01 14:06:50,819 DEBUG TRAIN Batch 57/1900 loss 8.081516 loss_att 11.194204 loss_ctc 11.640732 loss_rnnt 6.896142 hw_loss 0.165515 lr 0.00028532 rank 3
2023-03-01 14:06:50,830 DEBUG TRAIN Batch 57/1900 loss 7.192671 loss_att 9.292049 loss_ctc 15.995173 loss_rnnt 5.477697 hw_loss 0.227683 lr 0.00028532 rank 4
2023-03-01 14:06:50,850 DEBUG TRAIN Batch 57/1900 loss 5.326337 loss_att 7.927210 loss_ctc 9.296629 loss_rnnt 4.137543 hw_loss 0.261087 lr 0.00028532 rank 1
2023-03-01 14:07:28,744 DEBUG TRAIN Batch 57/2000 loss 2.761821 loss_att 4.788506 loss_ctc 2.853917 loss_rnnt 2.285943 hw_loss 0.109242 lr 0.00028532 rank 6
2023-03-01 14:07:28,746 DEBUG TRAIN Batch 57/2000 loss 5.042895 loss_att 9.591828 loss_ctc 12.216681 loss_rnnt 3.065655 hw_loss 0.208027 lr 0.00028531 rank 4
2023-03-01 14:07:28,758 DEBUG TRAIN Batch 57/2000 loss 3.130332 loss_att 6.896178 loss_ctc 5.781952 loss_rnnt 1.898186 hw_loss 0.235177 lr 0.00028531 rank 7
2023-03-01 14:07:28,760 DEBUG TRAIN Batch 57/2000 loss 10.060185 loss_att 10.826667 loss_ctc 14.912157 loss_rnnt 9.112974 hw_loss 0.275595 lr 0.00028531 rank 1
2023-03-01 14:07:28,760 DEBUG TRAIN Batch 57/2000 loss 3.074298 loss_att 6.190967 loss_ctc 4.335212 loss_rnnt 2.202571 hw_loss 0.150507 lr 0.00028531 rank 2
2023-03-01 14:07:28,764 DEBUG TRAIN Batch 57/2000 loss 2.117902 loss_att 6.319650 loss_ctc 4.581247 loss_rnnt 0.787288 hw_loss 0.303408 lr 0.00028532 rank 0
2023-03-01 14:07:28,772 DEBUG TRAIN Batch 57/2000 loss 4.044711 loss_att 7.015991 loss_ctc 6.997485 loss_rnnt 2.975829 hw_loss 0.151730 lr 0.00028532 rank 5
2023-03-01 14:07:28,783 DEBUG TRAIN Batch 57/2000 loss 5.154219 loss_att 9.267208 loss_ctc 11.339535 loss_rnnt 3.365594 hw_loss 0.264973 lr 0.00028531 rank 3
2023-03-01 14:08:08,050 DEBUG TRAIN Batch 57/2100 loss 6.838616 loss_att 8.748467 loss_ctc 11.079636 loss_rnnt 5.790915 hw_loss 0.187990 lr 0.00028530 rank 1
2023-03-01 14:08:08,061 DEBUG TRAIN Batch 57/2100 loss 4.773693 loss_att 7.265330 loss_ctc 8.740414 loss_rnnt 3.691655 hw_loss 0.102777 lr 0.00028530 rank 5
2023-03-01 14:08:08,063 DEBUG TRAIN Batch 57/2100 loss 6.663777 loss_att 10.991528 loss_ctc 14.686771 loss_rnnt 4.628413 hw_loss 0.187653 lr 0.00028531 rank 6
2023-03-01 14:08:08,073 DEBUG TRAIN Batch 57/2100 loss 2.738491 loss_att 6.181937 loss_ctc 5.852169 loss_rnnt 1.542960 hw_loss 0.171908 lr 0.00028531 rank 0
2023-03-01 14:08:08,075 DEBUG TRAIN Batch 57/2100 loss 5.679607 loss_att 8.100314 loss_ctc 10.805298 loss_rnnt 4.371387 hw_loss 0.263725 lr 0.00028530 rank 2
2023-03-01 14:08:08,075 DEBUG TRAIN Batch 57/2100 loss 3.538973 loss_att 6.726724 loss_ctc 4.346451 loss_rnnt 2.670419 hw_loss 0.231262 lr 0.00028530 rank 3
2023-03-01 14:08:08,077 DEBUG TRAIN Batch 57/2100 loss 6.218299 loss_att 9.970929 loss_ctc 11.434630 loss_rnnt 4.610431 hw_loss 0.303435 lr 0.00028530 rank 7
2023-03-01 14:08:08,097 DEBUG TRAIN Batch 57/2100 loss 7.122814 loss_att 10.901951 loss_ctc 13.382731 loss_rnnt 5.351915 hw_loss 0.338282 lr 0.00028530 rank 4
2023-03-01 14:09:11,976 DEBUG TRAIN Batch 57/2200 loss 6.788261 loss_att 10.069014 loss_ctc 10.894005 loss_rnnt 5.522636 hw_loss 0.116330 lr 0.00028529 rank 7
2023-03-01 14:09:11,976 DEBUG TRAIN Batch 57/2200 loss 8.599482 loss_att 11.339973 loss_ctc 11.683825 loss_rnnt 7.412497 hw_loss 0.426826 lr 0.00028529 rank 4
2023-03-01 14:09:11,976 DEBUG TRAIN Batch 57/2200 loss 10.506373 loss_att 14.774183 loss_ctc 14.187767 loss_rnnt 9.030327 hw_loss 0.246811 lr 0.00028529 rank 2
2023-03-01 14:09:11,977 DEBUG TRAIN Batch 57/2200 loss 4.787983 loss_att 8.812344 loss_ctc 7.120833 loss_rnnt 3.638736 hw_loss 0.062490 lr 0.00028530 rank 0
2023-03-01 14:09:11,977 DEBUG TRAIN Batch 57/2200 loss 4.091559 loss_att 8.106587 loss_ctc 8.057940 loss_rnnt 2.655128 hw_loss 0.196078 lr 0.00028529 rank 5
2023-03-01 14:09:11,977 DEBUG TRAIN Batch 57/2200 loss 3.053153 loss_att 6.340736 loss_ctc 4.086536 loss_rnnt 2.140904 hw_loss 0.219277 lr 0.00028529 rank 3
2023-03-01 14:09:11,982 DEBUG TRAIN Batch 57/2200 loss 4.366051 loss_att 7.762317 loss_ctc 9.016718 loss_rnnt 2.950218 hw_loss 0.218422 lr 0.00028528 rank 1
2023-03-01 14:09:11,984 DEBUG TRAIN Batch 57/2200 loss 6.601658 loss_att 8.940216 loss_ctc 11.537577 loss_rnnt 5.357448 hw_loss 0.221956 lr 0.00028530 rank 6
2023-03-01 14:09:50,018 DEBUG TRAIN Batch 57/2300 loss 13.609571 loss_att 14.648737 loss_ctc 17.748875 loss_rnnt 12.742667 hw_loss 0.200934 lr 0.00028528 rank 3
2023-03-01 14:09:50,032 DEBUG TRAIN Batch 57/2300 loss 3.527917 loss_att 5.412608 loss_ctc 6.885884 loss_rnnt 2.593467 hw_loss 0.205844 lr 0.00028527 rank 1
2023-03-01 14:09:50,034 DEBUG TRAIN Batch 57/2300 loss 9.037400 loss_att 10.475983 loss_ctc 11.052160 loss_rnnt 8.371245 hw_loss 0.205881 lr 0.00028528 rank 2
2023-03-01 14:09:50,037 DEBUG TRAIN Batch 57/2300 loss 2.744353 loss_att 5.497932 loss_ctc 5.680746 loss_rnnt 1.699155 hw_loss 0.193056 lr 0.00028529 rank 6
2023-03-01 14:09:50,038 DEBUG TRAIN Batch 57/2300 loss 7.332151 loss_att 9.155223 loss_ctc 16.060221 loss_rnnt 5.680812 hw_loss 0.230594 lr 0.00028529 rank 0
2023-03-01 14:09:50,040 DEBUG TRAIN Batch 57/2300 loss 4.793010 loss_att 7.926172 loss_ctc 9.970507 loss_rnnt 3.354759 hw_loss 0.227410 lr 0.00028528 rank 7
2023-03-01 14:09:50,043 DEBUG TRAIN Batch 57/2300 loss 5.238438 loss_att 7.188210 loss_ctc 7.842447 loss_rnnt 4.385060 hw_loss 0.217915 lr 0.00028528 rank 5
2023-03-01 14:09:50,085 DEBUG TRAIN Batch 57/2300 loss 3.697873 loss_att 6.166042 loss_ctc 7.852993 loss_rnnt 2.531650 hw_loss 0.222324 lr 0.00028528 rank 4
2023-03-01 14:10:28,428 DEBUG TRAIN Batch 57/2400 loss 6.724489 loss_att 10.321629 loss_ctc 11.649890 loss_rnnt 5.276675 hw_loss 0.134372 lr 0.00028527 rank 5
2023-03-01 14:10:28,432 DEBUG TRAIN Batch 57/2400 loss 5.668491 loss_att 8.324914 loss_ctc 7.603327 loss_rnnt 4.746428 hw_loss 0.249001 lr 0.00028526 rank 1
2023-03-01 14:10:28,434 DEBUG TRAIN Batch 57/2400 loss 6.410767 loss_att 10.812366 loss_ctc 12.105494 loss_rnnt 4.631317 hw_loss 0.262188 lr 0.00028528 rank 0
2023-03-01 14:10:28,446 DEBUG TRAIN Batch 57/2400 loss 11.661879 loss_att 13.910634 loss_ctc 18.812391 loss_rnnt 10.114463 hw_loss 0.270492 lr 0.00028527 rank 6
2023-03-01 14:10:28,446 DEBUG TRAIN Batch 57/2400 loss 7.621652 loss_att 9.648515 loss_ctc 11.794356 loss_rnnt 6.586995 hw_loss 0.136732 lr 0.00028527 rank 2
2023-03-01 14:10:28,451 DEBUG TRAIN Batch 57/2400 loss 11.432660 loss_att 12.770864 loss_ctc 20.628124 loss_rnnt 9.849173 hw_loss 0.168348 lr 0.00028527 rank 7
2023-03-01 14:10:28,453 DEBUG TRAIN Batch 57/2400 loss 6.198852 loss_att 8.983668 loss_ctc 10.597619 loss_rnnt 4.917739 hw_loss 0.258090 lr 0.00028526 rank 4
2023-03-01 14:10:28,495 DEBUG TRAIN Batch 57/2400 loss 7.195801 loss_att 9.149742 loss_ctc 12.711344 loss_rnnt 5.945459 hw_loss 0.232776 lr 0.00028526 rank 3
2023-03-01 14:11:33,765 DEBUG TRAIN Batch 57/2500 loss 8.625631 loss_att 9.856255 loss_ctc 12.180829 loss_rnnt 7.788342 hw_loss 0.219637 lr 0.00028525 rank 4
2023-03-01 14:11:33,766 DEBUG TRAIN Batch 57/2500 loss 7.498307 loss_att 9.335108 loss_ctc 15.315804 loss_rnnt 6.015845 hw_loss 0.136442 lr 0.00028526 rank 5
2023-03-01 14:11:33,778 DEBUG TRAIN Batch 57/2500 loss 7.553866 loss_att 8.944503 loss_ctc 15.628574 loss_rnnt 6.103063 hw_loss 0.180088 lr 0.00028526 rank 0
2023-03-01 14:11:33,779 DEBUG TRAIN Batch 57/2500 loss 3.160010 loss_att 5.167657 loss_ctc 8.399349 loss_rnnt 2.001674 hw_loss 0.109177 lr 0.00028525 rank 7
2023-03-01 14:11:33,783 DEBUG TRAIN Batch 57/2500 loss 7.370397 loss_att 9.819950 loss_ctc 13.283556 loss_rnnt 6.036808 hw_loss 0.103609 lr 0.00028525 rank 1
2023-03-01 14:11:33,785 DEBUG TRAIN Batch 57/2500 loss 8.244326 loss_att 10.345087 loss_ctc 11.956253 loss_rnnt 7.188849 hw_loss 0.263249 lr 0.00028526 rank 6
2023-03-01 14:11:33,821 DEBUG TRAIN Batch 57/2500 loss 6.429756 loss_att 8.411643 loss_ctc 9.421095 loss_rnnt 5.476271 hw_loss 0.296743 lr 0.00028525 rank 3
2023-03-01 14:11:33,853 DEBUG TRAIN Batch 57/2500 loss 2.531604 loss_att 4.653121 loss_ctc 5.840547 loss_rnnt 1.583749 hw_loss 0.154423 lr 0.00028525 rank 2
2023-03-01 14:12:12,261 DEBUG TRAIN Batch 57/2600 loss 1.852388 loss_att 4.327091 loss_ctc 2.030397 loss_rnnt 1.274955 hw_loss 0.110170 lr 0.00028525 rank 6
2023-03-01 14:12:12,263 DEBUG TRAIN Batch 57/2600 loss 5.975600 loss_att 11.111288 loss_ctc 16.384747 loss_rnnt 3.408679 hw_loss 0.284808 lr 0.00028524 rank 1
2023-03-01 14:12:12,267 DEBUG TRAIN Batch 57/2600 loss 4.053293 loss_att 7.240772 loss_ctc 11.020966 loss_rnnt 2.336344 hw_loss 0.282056 lr 0.00028524 rank 3
2023-03-01 14:12:12,279 DEBUG TRAIN Batch 57/2600 loss 4.485963 loss_att 8.184456 loss_ctc 7.946692 loss_rnnt 3.236758 hw_loss 0.090143 lr 0.00028525 rank 0
2023-03-01 14:12:12,281 DEBUG TRAIN Batch 57/2600 loss 3.121192 loss_att 4.759972 loss_ctc 4.832456 loss_rnnt 2.494190 hw_loss 0.133270 lr 0.00028524 rank 7
2023-03-01 14:12:12,281 DEBUG TRAIN Batch 57/2600 loss 4.896482 loss_att 5.665829 loss_ctc 7.331815 loss_rnnt 4.289590 hw_loss 0.240584 lr 0.00028524 rank 2
2023-03-01 14:12:12,284 DEBUG TRAIN Batch 57/2600 loss 7.125377 loss_att 8.764736 loss_ctc 14.422128 loss_rnnt 5.626752 hw_loss 0.370973 lr 0.00028525 rank 5
2023-03-01 14:12:12,283 DEBUG TRAIN Batch 57/2600 loss 5.944562 loss_att 9.547235 loss_ctc 8.929526 loss_rnnt 4.772083 hw_loss 0.101157 lr 0.00028524 rank 4
2023-03-01 14:12:50,600 DEBUG TRAIN Batch 57/2700 loss 2.605089 loss_att 5.113460 loss_ctc 3.534198 loss_rnnt 1.927882 hw_loss 0.096847 lr 0.00028524 rank 6
2023-03-01 14:12:50,607 DEBUG TRAIN Batch 57/2700 loss 4.054981 loss_att 7.296744 loss_ctc 7.667453 loss_rnnt 2.808008 hw_loss 0.219296 lr 0.00028523 rank 7
2023-03-01 14:12:50,611 DEBUG TRAIN Batch 57/2700 loss 5.670431 loss_att 8.257415 loss_ctc 9.695374 loss_rnnt 4.569057 hw_loss 0.088720 lr 0.00028524 rank 0
2023-03-01 14:12:50,618 DEBUG TRAIN Batch 57/2700 loss 5.769547 loss_att 9.452372 loss_ctc 7.836337 loss_rnnt 4.658852 hw_loss 0.184795 lr 0.00028523 rank 2
2023-03-01 14:12:50,618 DEBUG TRAIN Batch 57/2700 loss 6.152238 loss_att 10.034426 loss_ctc 10.851921 loss_rnnt 4.699314 hw_loss 0.093493 lr 0.00028523 rank 5
2023-03-01 14:12:50,619 DEBUG TRAIN Batch 57/2700 loss 3.109146 loss_att 7.074343 loss_ctc 4.562028 loss_rnnt 2.084808 hw_loss 0.070465 lr 0.00028523 rank 3
2023-03-01 14:12:50,620 DEBUG TRAIN Batch 57/2700 loss 6.141415 loss_att 8.590452 loss_ctc 7.504458 loss_rnnt 5.376376 hw_loss 0.175298 lr 0.00028523 rank 4
2023-03-01 14:12:50,664 DEBUG TRAIN Batch 57/2700 loss 2.546137 loss_att 5.165608 loss_ctc 4.593074 loss_rnnt 1.649312 hw_loss 0.187511 lr 0.00028523 rank 1
2023-03-01 14:13:30,187 DEBUG TRAIN Batch 57/2800 loss 3.835760 loss_att 6.979098 loss_ctc 6.672531 loss_rnnt 2.713722 hw_loss 0.215877 lr 0.00028523 rank 0
2023-03-01 14:13:30,198 DEBUG TRAIN Batch 57/2800 loss 3.209267 loss_att 5.203713 loss_ctc 8.389773 loss_rnnt 1.985181 hw_loss 0.252118 lr 0.00028522 rank 2
2023-03-01 14:13:30,199 DEBUG TRAIN Batch 57/2800 loss 2.905779 loss_att 4.703627 loss_ctc 8.537911 loss_rnnt 1.716521 hw_loss 0.147633 lr 0.00028521 rank 1
2023-03-01 14:13:30,199 DEBUG TRAIN Batch 57/2800 loss 3.107771 loss_att 5.365722 loss_ctc 5.098274 loss_rnnt 2.284179 hw_loss 0.199878 lr 0.00028522 rank 5
2023-03-01 14:13:30,199 DEBUG TRAIN Batch 57/2800 loss 3.390409 loss_att 5.646330 loss_ctc 9.178568 loss_rnnt 2.065419 hw_loss 0.191347 lr 0.00028522 rank 3
2023-03-01 14:13:30,201 DEBUG TRAIN Batch 57/2800 loss 2.037752 loss_att 4.245386 loss_ctc 3.384405 loss_rnnt 1.343522 hw_loss 0.137156 lr 0.00028522 rank 7
2023-03-01 14:13:30,201 DEBUG TRAIN Batch 57/2800 loss 8.005839 loss_att 10.114573 loss_ctc 11.172774 loss_rnnt 6.997138 hw_loss 0.308806 lr 0.00028522 rank 4
2023-03-01 14:13:30,204 DEBUG TRAIN Batch 57/2800 loss 7.121773 loss_att 9.735942 loss_ctc 10.375217 loss_rnnt 6.072682 hw_loss 0.173370 lr 0.00028523 rank 6
2023-03-01 14:14:36,877 DEBUG TRAIN Batch 57/2900 loss 4.763104 loss_att 6.354935 loss_ctc 6.015934 loss_rnnt 4.186118 hw_loss 0.171706 lr 0.00028521 rank 4
2023-03-01 14:14:36,877 DEBUG TRAIN Batch 57/2900 loss 5.484559 loss_att 7.943177 loss_ctc 7.420978 loss_rnnt 4.632866 hw_loss 0.190838 lr 0.00028521 rank 2
2023-03-01 14:14:36,885 DEBUG TRAIN Batch 57/2900 loss 10.689809 loss_att 13.725522 loss_ctc 17.802589 loss_rnnt 9.051744 hw_loss 0.154784 lr 0.00028521 rank 5
2023-03-01 14:14:36,884 DEBUG TRAIN Batch 57/2900 loss 2.658719 loss_att 6.763433 loss_ctc 4.843815 loss_rnnt 1.470252 hw_loss 0.142834 lr 0.00028522 rank 6
2023-03-01 14:14:36,892 DEBUG TRAIN Batch 57/2900 loss 11.882325 loss_att 16.323057 loss_ctc 21.484856 loss_rnnt 9.596046 hw_loss 0.220867 lr 0.00028521 rank 7
2023-03-01 14:14:36,897 DEBUG TRAIN Batch 57/2900 loss 4.218533 loss_att 6.897967 loss_ctc 7.426783 loss_rnnt 3.174804 hw_loss 0.150141 lr 0.00028522 rank 0
2023-03-01 14:14:36,928 DEBUG TRAIN Batch 57/2900 loss 6.434621 loss_att 10.144058 loss_ctc 9.788963 loss_rnnt 5.145926 hw_loss 0.186679 lr 0.00028521 rank 3
2023-03-01 14:14:36,932 DEBUG TRAIN Batch 57/2900 loss 9.305181 loss_att 11.144798 loss_ctc 16.618277 loss_rnnt 7.855649 hw_loss 0.199742 lr 0.00028520 rank 1
2023-03-01 14:15:15,058 DEBUG TRAIN Batch 57/3000 loss 11.118980 loss_att 14.538782 loss_ctc 14.884651 loss_rnnt 9.827112 hw_loss 0.198409 lr 0.00028519 rank 4
2023-03-01 14:15:15,066 DEBUG TRAIN Batch 57/3000 loss 6.241569 loss_att 8.304147 loss_ctc 9.145135 loss_rnnt 5.357102 hw_loss 0.159014 lr 0.00028520 rank 7
2023-03-01 14:15:15,070 DEBUG TRAIN Batch 57/3000 loss 6.181777 loss_att 8.159669 loss_ctc 10.382592 loss_rnnt 5.149209 hw_loss 0.144150 lr 0.00028519 rank 1
2023-03-01 14:15:15,076 DEBUG TRAIN Batch 57/3000 loss 3.698731 loss_att 5.603367 loss_ctc 6.751431 loss_rnnt 2.770451 hw_loss 0.263112 lr 0.00028521 rank 0
2023-03-01 14:15:15,076 DEBUG TRAIN Batch 57/3000 loss 5.689297 loss_att 8.861748 loss_ctc 11.843200 loss_rnnt 4.093152 hw_loss 0.264627 lr 0.00028520 rank 2
2023-03-01 14:15:15,079 DEBUG TRAIN Batch 57/3000 loss 6.145609 loss_att 9.826250 loss_ctc 8.282053 loss_rnnt 5.029298 hw_loss 0.178732 lr 0.00028520 rank 3
2023-03-01 14:15:15,080 DEBUG TRAIN Batch 57/3000 loss 3.546617 loss_att 5.758608 loss_ctc 5.189971 loss_rnnt 2.820112 hw_loss 0.121862 lr 0.00028520 rank 5
2023-03-01 14:15:15,087 DEBUG TRAIN Batch 57/3000 loss 6.143426 loss_att 7.457681 loss_ctc 8.169860 loss_rnnt 5.455014 hw_loss 0.291318 lr 0.00028520 rank 6
2023-03-01 14:15:53,929 DEBUG TRAIN Batch 57/3100 loss 6.943308 loss_att 8.214045 loss_ctc 10.737799 loss_rnnt 6.089392 hw_loss 0.175943 lr 0.00028518 rank 1
2023-03-01 14:15:53,943 DEBUG TRAIN Batch 57/3100 loss 13.171761 loss_att 14.884832 loss_ctc 22.830904 loss_rnnt 11.464546 hw_loss 0.143837 lr 0.00028518 rank 7
2023-03-01 14:15:53,942 DEBUG TRAIN Batch 57/3100 loss 7.656187 loss_att 12.070108 loss_ctc 10.811146 loss_rnnt 6.209195 hw_loss 0.269149 lr 0.00028519 rank 5
2023-03-01 14:15:53,944 DEBUG TRAIN Batch 57/3100 loss 7.198187 loss_att 7.889958 loss_ctc 11.467965 loss_rnnt 6.342910 hw_loss 0.276784 lr 0.00028519 rank 0
2023-03-01 14:15:53,947 DEBUG TRAIN Batch 57/3100 loss 4.663512 loss_att 7.778476 loss_ctc 6.857641 loss_rnnt 3.583086 hw_loss 0.309155 lr 0.00028518 rank 3
2023-03-01 14:15:53,947 DEBUG TRAIN Batch 57/3100 loss 6.896874 loss_att 10.489616 loss_ctc 17.600496 loss_rnnt 4.636580 hw_loss 0.214868 lr 0.00028519 rank 6
2023-03-01 14:15:53,960 DEBUG TRAIN Batch 57/3100 loss 2.569306 loss_att 4.403125 loss_ctc 5.825363 loss_rnnt 1.626775 hw_loss 0.265550 lr 0.00028518 rank 4
2023-03-01 14:15:53,968 DEBUG TRAIN Batch 57/3100 loss 9.995050 loss_att 13.012929 loss_ctc 13.859537 loss_rnnt 8.752108 hw_loss 0.232693 lr 0.00028518 rank 2
2023-03-01 14:17:01,659 DEBUG TRAIN Batch 57/3200 loss 7.431111 loss_att 11.772207 loss_ctc 9.813110 loss_rnnt 6.153398 hw_loss 0.172303 lr 0.00028518 rank 0
2023-03-01 14:17:01,676 DEBUG TRAIN Batch 57/3200 loss 5.594380 loss_att 6.389500 loss_ctc 10.382971 loss_rnnt 4.655119 hw_loss 0.265796 lr 0.00028517 rank 1
2023-03-01 14:17:01,677 DEBUG TRAIN Batch 57/3200 loss 6.122363 loss_att 8.218054 loss_ctc 10.000476 loss_rnnt 5.017166 hw_loss 0.316832 lr 0.00028517 rank 2
2023-03-01 14:17:01,679 DEBUG TRAIN Batch 57/3200 loss 4.279839 loss_att 4.675707 loss_ctc 5.232013 loss_rnnt 4.042984 hw_loss 0.057609 lr 0.00028517 rank 7
2023-03-01 14:17:01,678 DEBUG TRAIN Batch 57/3200 loss 6.863635 loss_att 8.344322 loss_ctc 12.413126 loss_rnnt 5.672948 hw_loss 0.289906 lr 0.00028517 rank 4
2023-03-01 14:17:01,679 DEBUG TRAIN Batch 57/3200 loss 5.102168 loss_att 7.006194 loss_ctc 6.666448 loss_rnnt 4.405058 hw_loss 0.202000 lr 0.00028518 rank 5
2023-03-01 14:17:01,679 DEBUG TRAIN Batch 57/3200 loss 7.556589 loss_att 7.674163 loss_ctc 10.995086 loss_rnnt 6.946205 hw_loss 0.240755 lr 0.00028518 rank 6
2023-03-01 14:17:01,688 DEBUG TRAIN Batch 57/3200 loss 8.120519 loss_att 9.096450 loss_ctc 12.120285 loss_rnnt 7.258417 hw_loss 0.250526 lr 0.00028517 rank 3
2023-03-01 14:17:39,903 DEBUG TRAIN Batch 57/3300 loss 3.278422 loss_att 6.256792 loss_ctc 5.327754 loss_rnnt 2.256636 hw_loss 0.286627 lr 0.00028516 rank 1
2023-03-01 14:17:39,918 DEBUG TRAIN Batch 57/3300 loss 6.427442 loss_att 6.773776 loss_ctc 8.750734 loss_rnnt 5.986217 hw_loss 0.116599 lr 0.00028516 rank 5
2023-03-01 14:17:39,919 DEBUG TRAIN Batch 57/3300 loss 2.180282 loss_att 4.378439 loss_ctc 3.133175 loss_rnnt 1.505271 hw_loss 0.203113 lr 0.00028517 rank 6
2023-03-01 14:17:39,921 DEBUG TRAIN Batch 57/3300 loss 3.143740 loss_att 5.874393 loss_ctc 6.564067 loss_rnnt 1.994280 hw_loss 0.276162 lr 0.00028516 rank 7
2023-03-01 14:17:39,923 DEBUG TRAIN Batch 57/3300 loss 3.057777 loss_att 7.849252 loss_ctc 7.385406 loss_rnnt 1.439309 hw_loss 0.155917 lr 0.00028517 rank 0
2023-03-01 14:17:39,926 DEBUG TRAIN Batch 57/3300 loss 7.552961 loss_att 10.688730 loss_ctc 10.914032 loss_rnnt 6.372103 hw_loss 0.197927 lr 0.00028516 rank 3
2023-03-01 14:17:39,927 DEBUG TRAIN Batch 57/3300 loss 11.492077 loss_att 13.720700 loss_ctc 17.770077 loss_rnnt 10.176729 hw_loss 0.061042 lr 0.00028516 rank 2
2023-03-01 14:17:39,967 DEBUG TRAIN Batch 57/3300 loss 3.648490 loss_att 10.023640 loss_ctc 5.232131 loss_rnnt 2.047728 hw_loss 0.214838 lr 0.00028516 rank 4
2023-03-01 14:18:18,220 DEBUG TRAIN Batch 57/3400 loss 3.865510 loss_att 5.894584 loss_ctc 4.767139 loss_rnnt 3.215969 hw_loss 0.231580 lr 0.00028515 rank 4
2023-03-01 14:18:18,220 DEBUG TRAIN Batch 57/3400 loss 10.670997 loss_att 15.967484 loss_ctc 20.600664 loss_rnnt 8.096920 hw_loss 0.357795 lr 0.00028515 rank 7
2023-03-01 14:18:18,221 DEBUG TRAIN Batch 57/3400 loss 6.049488 loss_att 10.514955 loss_ctc 11.268759 loss_rnnt 4.365298 hw_loss 0.178489 lr 0.00028516 rank 0
2023-03-01 14:18:18,221 DEBUG TRAIN Batch 57/3400 loss 1.228872 loss_att 4.246395 loss_ctc 3.580472 loss_rnnt 0.202218 hw_loss 0.205505 lr 0.00028515 rank 3
2023-03-01 14:18:18,225 DEBUG TRAIN Batch 57/3400 loss 3.107443 loss_att 4.978795 loss_ctc 5.750052 loss_rnnt 2.298722 hw_loss 0.153944 lr 0.00028515 rank 5
2023-03-01 14:18:18,239 DEBUG TRAIN Batch 57/3400 loss 8.946490 loss_att 11.984418 loss_ctc 12.273169 loss_rnnt 7.874105 hw_loss 0.039828 lr 0.00028515 rank 2
2023-03-01 14:18:18,257 DEBUG TRAIN Batch 57/3400 loss 2.777002 loss_att 6.343764 loss_ctc 6.776597 loss_rnnt 1.409084 hw_loss 0.227412 lr 0.00028515 rank 1
2023-03-01 14:18:18,266 DEBUG TRAIN Batch 57/3400 loss 4.390534 loss_att 6.811597 loss_ctc 5.736052 loss_rnnt 3.559232 hw_loss 0.314413 lr 0.00028516 rank 6
2023-03-01 14:18:57,421 DEBUG TRAIN Batch 57/3500 loss 6.372094 loss_att 9.801486 loss_ctc 9.151968 loss_rnnt 5.098771 hw_loss 0.406491 lr 0.00028514 rank 2
2023-03-01 14:18:57,424 DEBUG TRAIN Batch 57/3500 loss 9.997542 loss_att 14.885790 loss_ctc 20.917124 loss_rnnt 7.456466 hw_loss 0.201530 lr 0.00028513 rank 1
2023-03-01 14:18:57,437 DEBUG TRAIN Batch 57/3500 loss 3.958066 loss_att 6.573054 loss_ctc 5.252608 loss_rnnt 3.079383 hw_loss 0.343273 lr 0.00028514 rank 7
2023-03-01 14:18:57,439 DEBUG TRAIN Batch 57/3500 loss 1.789653 loss_att 4.391748 loss_ctc 2.939490 loss_rnnt 1.001288 hw_loss 0.214938 lr 0.00028514 rank 4
2023-03-01 14:18:57,439 DEBUG TRAIN Batch 57/3500 loss 3.673003 loss_att 6.551510 loss_ctc 6.389222 loss_rnnt 2.600945 hw_loss 0.251614 lr 0.00028515 rank 6
2023-03-01 14:18:57,441 DEBUG TRAIN Batch 57/3500 loss 3.510876 loss_att 5.070689 loss_ctc 5.765187 loss_rnnt 2.823797 hw_loss 0.139766 lr 0.00028514 rank 3
2023-03-01 14:18:57,442 DEBUG TRAIN Batch 57/3500 loss 4.816628 loss_att 7.515611 loss_ctc 7.141710 loss_rnnt 3.877049 hw_loss 0.168320 lr 0.00028515 rank 0
2023-03-01 14:18:57,452 DEBUG TRAIN Batch 57/3500 loss 5.058228 loss_att 7.004755 loss_ctc 11.658713 loss_rnnt 3.663642 hw_loss 0.234779 lr 0.00028514 rank 5
2023-03-01 14:20:02,822 DEBUG TRAIN Batch 57/3600 loss 6.923703 loss_att 10.811902 loss_ctc 11.886520 loss_rnnt 5.356255 hw_loss 0.240187 lr 0.00028513 rank 5
2023-03-01 14:20:02,823 DEBUG TRAIN Batch 57/3600 loss 10.432880 loss_att 10.742769 loss_ctc 15.699281 loss_rnnt 9.504949 hw_loss 0.307062 lr 0.00028512 rank 1
2023-03-01 14:20:02,825 DEBUG TRAIN Batch 57/3600 loss 8.236843 loss_att 11.223996 loss_ctc 14.081957 loss_rnnt 6.804427 hw_loss 0.104319 lr 0.00028513 rank 6
2023-03-01 14:20:02,830 DEBUG TRAIN Batch 57/3600 loss 5.888711 loss_att 8.828827 loss_ctc 7.937664 loss_rnnt 4.943451 hw_loss 0.157580 lr 0.00028512 rank 4
2023-03-01 14:20:02,838 DEBUG TRAIN Batch 57/3600 loss 4.347959 loss_att 6.583171 loss_ctc 8.204289 loss_rnnt 3.201677 hw_loss 0.346990 lr 0.00028514 rank 0
2023-03-01 14:20:02,841 DEBUG TRAIN Batch 57/3600 loss 6.316528 loss_att 10.018601 loss_ctc 15.677399 loss_rnnt 4.204571 hw_loss 0.231423 lr 0.00028513 rank 2
2023-03-01 14:20:02,848 DEBUG TRAIN Batch 57/3600 loss 13.305832 loss_att 15.223185 loss_ctc 19.175453 loss_rnnt 11.981301 hw_loss 0.297081 lr 0.00028513 rank 7
2023-03-01 14:20:02,893 DEBUG TRAIN Batch 57/3600 loss 7.931482 loss_att 10.328727 loss_ctc 11.287659 loss_rnnt 6.878007 hw_loss 0.237254 lr 0.00028513 rank 3
2023-03-01 14:20:41,150 DEBUG TRAIN Batch 57/3700 loss 5.930675 loss_att 7.398726 loss_ctc 7.951216 loss_rnnt 5.206015 hw_loss 0.303082 lr 0.00028511 rank 7
2023-03-01 14:20:41,150 DEBUG TRAIN Batch 57/3700 loss 7.589071 loss_att 10.142418 loss_ctc 11.676135 loss_rnnt 6.448797 hw_loss 0.158741 lr 0.00028511 rank 1
2023-03-01 14:20:41,155 DEBUG TRAIN Batch 57/3700 loss 12.960631 loss_att 15.065985 loss_ctc 20.345043 loss_rnnt 11.446748 hw_loss 0.202920 lr 0.00028512 rank 6
2023-03-01 14:20:41,156 DEBUG TRAIN Batch 57/3700 loss 6.166753 loss_att 7.944993 loss_ctc 7.704976 loss_rnnt 5.502455 hw_loss 0.194161 lr 0.00028513 rank 0
2023-03-01 14:20:41,157 DEBUG TRAIN Batch 57/3700 loss 2.351395 loss_att 4.324466 loss_ctc 4.176639 loss_rnnt 1.562835 hw_loss 0.282339 lr 0.00028511 rank 4
2023-03-01 14:20:41,161 DEBUG TRAIN Batch 57/3700 loss 8.606844 loss_att 10.166702 loss_ctc 11.391179 loss_rnnt 7.741817 hw_loss 0.340892 lr 0.00028511 rank 3
2023-03-01 14:20:41,162 DEBUG TRAIN Batch 57/3700 loss 2.008082 loss_att 3.880600 loss_ctc 2.522055 loss_rnnt 1.433799 hw_loss 0.246094 lr 0.00028511 rank 2
2023-03-01 14:20:41,205 DEBUG TRAIN Batch 57/3700 loss 4.051254 loss_att 8.631122 loss_ctc 10.623028 loss_rnnt 2.120199 hw_loss 0.260335 lr 0.00028512 rank 5
2023-03-01 14:21:20,313 DEBUG TRAIN Batch 57/3800 loss 5.069689 loss_att 7.240269 loss_ctc 7.665886 loss_rnnt 4.181834 hw_loss 0.201710 lr 0.00028510 rank 2
2023-03-01 14:21:20,319 DEBUG TRAIN Batch 57/3800 loss 5.525047 loss_att 8.022938 loss_ctc 8.540464 loss_rnnt 4.471664 hw_loss 0.284529 lr 0.00028511 rank 6
2023-03-01 14:21:20,330 DEBUG TRAIN Batch 57/3800 loss 8.532504 loss_att 9.561389 loss_ctc 12.705919 loss_rnnt 7.646886 hw_loss 0.231349 lr 0.00028510 rank 1
2023-03-01 14:21:20,331 DEBUG TRAIN Batch 57/3800 loss 8.887334 loss_att 8.686742 loss_ctc 13.442281 loss_rnnt 8.166817 hw_loss 0.287453 lr 0.00028510 rank 7
2023-03-01 14:21:20,331 DEBUG TRAIN Batch 57/3800 loss 9.989222 loss_att 11.687810 loss_ctc 13.859872 loss_rnnt 9.057820 hw_loss 0.141741 lr 0.00028510 rank 4
2023-03-01 14:21:20,333 DEBUG TRAIN Batch 57/3800 loss 5.903762 loss_att 7.203326 loss_ctc 10.194636 loss_rnnt 4.921395 hw_loss 0.281884 lr 0.00028511 rank 0
2023-03-01 14:21:20,336 DEBUG TRAIN Batch 57/3800 loss 7.899054 loss_att 9.077122 loss_ctc 8.873477 loss_rnnt 7.436761 hw_loss 0.181416 lr 0.00028511 rank 5
2023-03-01 14:21:20,339 DEBUG TRAIN Batch 57/3800 loss 5.850834 loss_att 8.531946 loss_ctc 10.715705 loss_rnnt 4.503178 hw_loss 0.305221 lr 0.00028510 rank 3
2023-03-01 14:22:29,712 DEBUG TRAIN Batch 57/3900 loss 4.070889 loss_att 7.729675 loss_ctc 6.323222 loss_rnnt 2.984699 hw_loss 0.101476 lr 0.00028509 rank 7
2023-03-01 14:22:29,729 DEBUG TRAIN Batch 57/3900 loss 9.162043 loss_att 10.275874 loss_ctc 13.825144 loss_rnnt 8.199774 hw_loss 0.220792 lr 0.00028509 rank 2
2023-03-01 14:22:29,733 DEBUG TRAIN Batch 57/3900 loss 3.464740 loss_att 5.896876 loss_ctc 6.001128 loss_rnnt 2.507905 hw_loss 0.247916 lr 0.00028509 rank 3
2023-03-01 14:22:29,735 DEBUG TRAIN Batch 57/3900 loss 4.170926 loss_att 6.585280 loss_ctc 8.238966 loss_rnnt 3.054798 hw_loss 0.170347 lr 0.00028510 rank 6
2023-03-01 14:22:29,741 DEBUG TRAIN Batch 57/3900 loss 3.330259 loss_att 7.010731 loss_ctc 6.090746 loss_rnnt 2.175148 hw_loss 0.095534 lr 0.00028510 rank 0
2023-03-01 14:22:29,775 DEBUG TRAIN Batch 57/3900 loss 4.853342 loss_att 5.578824 loss_ctc 7.431365 loss_rnnt 4.162449 hw_loss 0.378864 lr 0.00028510 rank 5
2023-03-01 14:22:29,784 DEBUG TRAIN Batch 57/3900 loss 2.273024 loss_att 4.987962 loss_ctc 3.168043 loss_rnnt 1.508602 hw_loss 0.191434 lr 0.00028509 rank 4
2023-03-01 14:22:29,789 DEBUG TRAIN Batch 57/3900 loss 9.563417 loss_att 13.146575 loss_ctc 13.584277 loss_rnnt 8.254483 hw_loss 0.105352 lr 0.00028509 rank 1
2023-03-01 14:23:08,487 DEBUG TRAIN Batch 57/4000 loss 4.792405 loss_att 10.000052 loss_ctc 8.860119 loss_rnnt 3.124154 hw_loss 0.158174 lr 0.00028508 rank 7
2023-03-01 14:23:08,490 DEBUG TRAIN Batch 57/4000 loss 8.226670 loss_att 9.562401 loss_ctc 9.165871 loss_rnnt 7.736231 hw_loss 0.183875 lr 0.00028509 rank 0
2023-03-01 14:23:08,491 DEBUG TRAIN Batch 57/4000 loss 3.133886 loss_att 6.204698 loss_ctc 6.927574 loss_rnnt 1.861018 hw_loss 0.286650 lr 0.00028509 rank 6
2023-03-01 14:23:08,493 DEBUG TRAIN Batch 57/4000 loss 3.580026 loss_att 5.627316 loss_ctc 5.939101 loss_rnnt 2.773916 hw_loss 0.153954 lr 0.00028508 rank 3
2023-03-01 14:23:08,494 DEBUG TRAIN Batch 57/4000 loss 3.923225 loss_att 6.065207 loss_ctc 8.913480 loss_rnnt 2.757009 hw_loss 0.135847 lr 0.00028508 rank 5
2023-03-01 14:23:08,494 DEBUG TRAIN Batch 57/4000 loss 0.798317 loss_att 3.563034 loss_ctc 0.880718 loss_rnnt 0.147508 hw_loss 0.162897 lr 0.00028508 rank 1
2023-03-01 14:23:08,496 DEBUG TRAIN Batch 57/4000 loss 2.813859 loss_att 7.403082 loss_ctc 4.909538 loss_rnnt 1.513190 hw_loss 0.193874 lr 0.00028508 rank 4
2023-03-01 14:23:08,495 DEBUG TRAIN Batch 57/4000 loss 12.806493 loss_att 15.100899 loss_ctc 18.992954 loss_rnnt 11.418854 hw_loss 0.194805 lr 0.00028508 rank 2
2023-03-01 14:23:47,345 DEBUG TRAIN Batch 57/4100 loss 13.395778 loss_att 16.246342 loss_ctc 16.663868 loss_rnnt 12.267857 hw_loss 0.228868 lr 0.00028507 rank 7
2023-03-01 14:23:47,344 DEBUG TRAIN Batch 57/4100 loss 3.671930 loss_att 5.616687 loss_ctc 6.153086 loss_rnnt 2.817772 hw_loss 0.251973 lr 0.00028506 rank 1
2023-03-01 14:23:47,348 DEBUG TRAIN Batch 57/4100 loss 3.763788 loss_att 6.143822 loss_ctc 4.651117 loss_rnnt 3.153740 hw_loss 0.029495 lr 0.00028507 rank 5
2023-03-01 14:23:47,348 DEBUG TRAIN Batch 57/4100 loss 5.010957 loss_att 7.850565 loss_ctc 11.738752 loss_rnnt 3.432248 hw_loss 0.213278 lr 0.00028508 rank 6
2023-03-01 14:23:47,350 DEBUG TRAIN Batch 57/4100 loss 16.165865 loss_att 19.605282 loss_ctc 24.860758 loss_rnnt 14.239198 hw_loss 0.148999 lr 0.00028507 rank 4
2023-03-01 14:23:47,351 DEBUG TRAIN Batch 57/4100 loss 4.977458 loss_att 8.205955 loss_ctc 7.518146 loss_rnnt 3.848760 hw_loss 0.270451 lr 0.00028508 rank 0
2023-03-01 14:23:47,353 DEBUG TRAIN Batch 57/4100 loss 6.590303 loss_att 12.029064 loss_ctc 17.075788 loss_rnnt 4.024711 hw_loss 0.149577 lr 0.00028507 rank 2
2023-03-01 14:23:47,356 DEBUG TRAIN Batch 57/4100 loss 6.728435 loss_att 8.768787 loss_ctc 11.922076 loss_rnnt 5.535413 hw_loss 0.173372 lr 0.00028507 rank 3
2023-03-01 14:24:26,534 DEBUG TRAIN Batch 57/4200 loss 6.384709 loss_att 8.358331 loss_ctc 9.628906 loss_rnnt 5.435145 hw_loss 0.229274 lr 0.00028506 rank 5
2023-03-01 14:24:26,534 DEBUG TRAIN Batch 57/4200 loss 4.997104 loss_att 9.370398 loss_ctc 7.706966 loss_rnnt 3.742871 hw_loss 0.034236 lr 0.00028505 rank 1
2023-03-01 14:24:26,545 DEBUG TRAIN Batch 57/4200 loss 4.535742 loss_att 5.759776 loss_ctc 8.267256 loss_rnnt 3.585211 hw_loss 0.390354 lr 0.00028506 rank 4
2023-03-01 14:24:26,547 DEBUG TRAIN Batch 57/4200 loss 2.412030 loss_att 5.071582 loss_ctc 3.687869 loss_rnnt 1.624187 hw_loss 0.160912 lr 0.00028506 rank 2
2023-03-01 14:24:26,548 DEBUG TRAIN Batch 57/4200 loss 9.998535 loss_att 11.071784 loss_ctc 14.719901 loss_rnnt 9.032344 hw_loss 0.228799 lr 0.00028507 rank 0
2023-03-01 14:24:26,550 DEBUG TRAIN Batch 57/4200 loss 7.124340 loss_att 9.745341 loss_ctc 12.700935 loss_rnnt 5.761517 hw_loss 0.178267 lr 0.00028506 rank 7
2023-03-01 14:24:26,551 DEBUG TRAIN Batch 57/4200 loss 6.915764 loss_att 8.414380 loss_ctc 9.142576 loss_rnnt 6.221921 hw_loss 0.182272 lr 0.00028506 rank 3
2023-03-01 14:24:26,557 DEBUG TRAIN Batch 57/4200 loss 6.907115 loss_att 9.795084 loss_ctc 11.142714 loss_rnnt 5.668180 hw_loss 0.181113 lr 0.00028507 rank 6
2023-03-01 14:25:35,352 DEBUG TRAIN Batch 57/4300 loss 12.254035 loss_att 17.056139 loss_ctc 20.641953 loss_rnnt 10.063448 hw_loss 0.209581 lr 0.00028505 rank 5
2023-03-01 14:25:35,353 DEBUG TRAIN Batch 57/4300 loss 7.967454 loss_att 10.696391 loss_ctc 11.650749 loss_rnnt 6.845984 hw_loss 0.158581 lr 0.00028504 rank 4
2023-03-01 14:25:35,355 DEBUG TRAIN Batch 57/4300 loss 5.633672 loss_att 8.473447 loss_ctc 7.299473 loss_rnnt 4.710238 hw_loss 0.250071 lr 0.00028505 rank 6
2023-03-01 14:25:35,357 DEBUG TRAIN Batch 57/4300 loss 11.516213 loss_att 12.616929 loss_ctc 14.818732 loss_rnnt 10.769009 hw_loss 0.162610 lr 0.00028506 rank 0
2023-03-01 14:25:35,358 DEBUG TRAIN Batch 57/4300 loss 8.226927 loss_att 11.787834 loss_ctc 21.100426 loss_rnnt 5.705244 hw_loss 0.174442 lr 0.00028505 rank 2
2023-03-01 14:25:35,361 DEBUG TRAIN Batch 57/4300 loss 8.874291 loss_att 11.970413 loss_ctc 13.427168 loss_rnnt 7.572604 hw_loss 0.141398 lr 0.00028504 rank 1
2023-03-01 14:25:35,361 DEBUG TRAIN Batch 57/4300 loss 11.317112 loss_att 14.233357 loss_ctc 19.571133 loss_rnnt 9.564595 hw_loss 0.128869 lr 0.00028504 rank 7
2023-03-01 14:25:35,360 DEBUG TRAIN Batch 57/4300 loss 4.503729 loss_att 6.293708 loss_ctc 8.656689 loss_rnnt 3.529301 hw_loss 0.117571 lr 0.00028504 rank 3
2023-03-01 14:26:14,243 DEBUG TRAIN Batch 57/4400 loss 3.453074 loss_att 5.328447 loss_ctc 6.168978 loss_rnnt 2.606744 hw_loss 0.204628 lr 0.00028504 rank 0
2023-03-01 14:26:14,249 DEBUG TRAIN Batch 57/4400 loss 7.013464 loss_att 7.325097 loss_ctc 8.910393 loss_rnnt 6.589597 hw_loss 0.203655 lr 0.00028503 rank 7
2023-03-01 14:26:14,249 DEBUG TRAIN Batch 57/4400 loss 5.301975 loss_att 7.053429 loss_ctc 9.181049 loss_rnnt 4.284595 hw_loss 0.281023 lr 0.00028503 rank 4
2023-03-01 14:26:14,250 DEBUG TRAIN Batch 57/4400 loss 4.037590 loss_att 5.795538 loss_ctc 5.382175 loss_rnnt 3.407179 hw_loss 0.186643 lr 0.00028503 rank 1
2023-03-01 14:26:14,252 DEBUG TRAIN Batch 57/4400 loss 8.841606 loss_att 11.702714 loss_ctc 15.120069 loss_rnnt 7.342162 hw_loss 0.168926 lr 0.00028504 rank 5
2023-03-01 14:26:14,252 DEBUG TRAIN Batch 57/4400 loss 8.130144 loss_att 12.001111 loss_ctc 12.104037 loss_rnnt 6.736416 hw_loss 0.168151 lr 0.00028503 rank 2
2023-03-01 14:26:14,253 DEBUG TRAIN Batch 57/4400 loss 5.577374 loss_att 8.130431 loss_ctc 10.698314 loss_rnnt 4.295330 hw_loss 0.166202 lr 0.00028504 rank 6
2023-03-01 14:26:14,296 DEBUG TRAIN Batch 57/4400 loss 8.999711 loss_att 10.900705 loss_ctc 16.352348 loss_rnnt 7.492284 hw_loss 0.275393 lr 0.00028503 rank 3
2023-03-01 14:26:53,357 DEBUG TRAIN Batch 57/4500 loss 9.308431 loss_att 12.037390 loss_ctc 12.236019 loss_rnnt 8.247034 hw_loss 0.234861 lr 0.00028502 rank 3
2023-03-01 14:26:53,364 DEBUG TRAIN Batch 57/4500 loss 8.686223 loss_att 12.281606 loss_ctc 14.489264 loss_rnnt 7.039653 hw_loss 0.288291 lr 0.00028503 rank 0
2023-03-01 14:26:53,366 DEBUG TRAIN Batch 57/4500 loss 5.023114 loss_att 9.058439 loss_ctc 10.383263 loss_rnnt 3.319542 hw_loss 0.340913 lr 0.00028503 rank 6
2023-03-01 14:26:53,369 DEBUG TRAIN Batch 57/4500 loss 5.178578 loss_att 7.620996 loss_ctc 7.995872 loss_rnnt 4.178290 hw_loss 0.255311 lr 0.00028502 rank 4
2023-03-01 14:26:53,370 DEBUG TRAIN Batch 57/4500 loss 8.042669 loss_att 11.891043 loss_ctc 16.470192 loss_rnnt 6.044546 hw_loss 0.196461 lr 0.00028502 rank 1
2023-03-01 14:26:53,371 DEBUG TRAIN Batch 57/4500 loss 14.449187 loss_att 15.875725 loss_ctc 21.297676 loss_rnnt 13.122110 hw_loss 0.241193 lr 0.00028502 rank 7
2023-03-01 14:26:53,372 DEBUG TRAIN Batch 57/4500 loss 3.698523 loss_att 6.129433 loss_ctc 6.479262 loss_rnnt 2.720708 hw_loss 0.226625 lr 0.00028502 rank 2
2023-03-01 14:26:53,376 DEBUG TRAIN Batch 57/4500 loss 4.313099 loss_att 6.448812 loss_ctc 8.037906 loss_rnnt 3.278557 hw_loss 0.207673 lr 0.00028503 rank 5
2023-03-01 14:28:01,011 DEBUG TRAIN Batch 57/4600 loss 3.800257 loss_att 6.076183 loss_ctc 12.160055 loss_rnnt 2.097283 hw_loss 0.249654 lr 0.00028501 rank 1
2023-03-01 14:28:01,015 DEBUG TRAIN Batch 57/4600 loss 5.540119 loss_att 9.694784 loss_ctc 9.886631 loss_rnnt 4.025743 hw_loss 0.194825 lr 0.00028502 rank 6
2023-03-01 14:28:01,024 DEBUG TRAIN Batch 57/4600 loss 4.248393 loss_att 8.278072 loss_ctc 11.540215 loss_rnnt 2.288148 hw_loss 0.341375 lr 0.00028501 rank 3
2023-03-01 14:28:01,028 DEBUG TRAIN Batch 57/4600 loss 4.556198 loss_att 6.739733 loss_ctc 8.077246 loss_rnnt 3.628710 hw_loss 0.039952 lr 0.00028502 rank 0
2023-03-01 14:28:01,028 DEBUG TRAIN Batch 57/4600 loss 5.076973 loss_att 6.673002 loss_ctc 5.063524 loss_rnnt 4.634235 hw_loss 0.234985 lr 0.00028501 rank 7
2023-03-01 14:28:01,030 DEBUG TRAIN Batch 57/4600 loss 2.091168 loss_att 5.161187 loss_ctc 3.121598 loss_rnnt 1.198483 hw_loss 0.264920 lr 0.00028501 rank 2
2023-03-01 14:28:01,030 DEBUG TRAIN Batch 57/4600 loss 6.741099 loss_att 9.781454 loss_ctc 10.916712 loss_rnnt 5.393068 hw_loss 0.343523 lr 0.00028501 rank 4
2023-03-01 14:28:01,071 DEBUG TRAIN Batch 57/4600 loss 9.959600 loss_att 12.375780 loss_ctc 18.152393 loss_rnnt 8.334533 hw_loss 0.092738 lr 0.00028501 rank 5
2023-03-01 14:28:40,991 DEBUG TRAIN Batch 57/4700 loss 10.036345 loss_att 13.071779 loss_ctc 15.799262 loss_rnnt 8.518610 hw_loss 0.266739 lr 0.00028501 rank 0
2023-03-01 14:28:40,994 DEBUG TRAIN Batch 57/4700 loss 8.040580 loss_att 11.785828 loss_ctc 11.725552 loss_rnnt 6.740156 hw_loss 0.112582 lr 0.00028500 rank 3
2023-03-01 14:28:40,995 DEBUG TRAIN Batch 57/4700 loss 2.540219 loss_att 6.498463 loss_ctc 5.015660 loss_rnnt 1.301720 hw_loss 0.218985 lr 0.00028501 rank 6
2023-03-01 14:28:40,996 DEBUG TRAIN Batch 57/4700 loss 4.722573 loss_att 8.018336 loss_ctc 8.991342 loss_rnnt 3.350815 hw_loss 0.268942 lr 0.00028500 rank 7
2023-03-01 14:28:40,998 DEBUG TRAIN Batch 57/4700 loss 5.136652 loss_att 9.987799 loss_ctc 10.365867 loss_rnnt 3.347948 hw_loss 0.227337 lr 0.00028500 rank 5
2023-03-01 14:28:41,001 DEBUG TRAIN Batch 57/4700 loss 6.654553 loss_att 11.947343 loss_ctc 12.137333 loss_rnnt 4.750865 hw_loss 0.213925 lr 0.00028500 rank 2
2023-03-01 14:28:41,003 DEBUG TRAIN Batch 57/4700 loss 2.240228 loss_att 6.364482 loss_ctc 4.476264 loss_rnnt 0.940648 hw_loss 0.331109 lr 0.00028500 rank 4
2023-03-01 14:28:41,008 DEBUG TRAIN Batch 57/4700 loss 3.130305 loss_att 6.424644 loss_ctc 5.876579 loss_rnnt 1.989620 hw_loss 0.216837 lr 0.00028499 rank 1
2023-03-01 14:29:19,888 DEBUG TRAIN Batch 57/4800 loss 4.203028 loss_att 8.708529 loss_ctc 5.952607 loss_rnnt 2.927437 hw_loss 0.264773 lr 0.00028499 rank 5
2023-03-01 14:29:19,891 DEBUG TRAIN Batch 57/4800 loss 5.376070 loss_att 8.581999 loss_ctc 8.073691 loss_rnnt 4.333920 hw_loss 0.077402 lr 0.00028500 rank 6
2023-03-01 14:29:19,901 DEBUG TRAIN Batch 57/4800 loss 5.932137 loss_att 9.829604 loss_ctc 9.582930 loss_rnnt 4.622284 hw_loss 0.081724 lr 0.00028498 rank 1
2023-03-01 14:29:19,903 DEBUG TRAIN Batch 57/4800 loss 4.328845 loss_att 4.918262 loss_ctc 5.497741 loss_rnnt 4.008556 hw_loss 0.087284 lr 0.00028499 rank 2
2023-03-01 14:29:19,903 DEBUG TRAIN Batch 57/4800 loss 6.001791 loss_att 9.365143 loss_ctc 10.273436 loss_rnnt 4.692285 hw_loss 0.126157 lr 0.00028499 rank 3
2023-03-01 14:29:19,904 DEBUG TRAIN Batch 57/4800 loss 5.077385 loss_att 7.242482 loss_ctc 9.479208 loss_rnnt 3.895715 hw_loss 0.303265 lr 0.00028499 rank 7
2023-03-01 14:29:19,907 DEBUG TRAIN Batch 57/4800 loss 6.794312 loss_att 8.258089 loss_ctc 8.288356 loss_rnnt 6.213293 hw_loss 0.166982 lr 0.00028499 rank 4
2023-03-01 14:29:19,911 DEBUG TRAIN Batch 57/4800 loss 5.042390 loss_att 7.554988 loss_ctc 7.772038 loss_rnnt 4.035799 hw_loss 0.262724 lr 0.00028500 rank 0
2023-03-01 14:29:59,206 DEBUG TRAIN Batch 57/4900 loss 4.819588 loss_att 8.893255 loss_ctc 7.938701 loss_rnnt 3.480942 hw_loss 0.202557 lr 0.00028498 rank 7
2023-03-01 14:29:59,225 DEBUG TRAIN Batch 57/4900 loss 1.940072 loss_att 4.285921 loss_ctc 2.995736 loss_rnnt 1.199286 hw_loss 0.245363 lr 0.00028499 rank 0
2023-03-01 14:29:59,230 DEBUG TRAIN Batch 57/4900 loss 5.135986 loss_att 8.019330 loss_ctc 8.095031 loss_rnnt 4.039534 hw_loss 0.234834 lr 0.00028497 rank 4
2023-03-01 14:29:59,231 DEBUG TRAIN Batch 57/4900 loss 4.549436 loss_att 7.165240 loss_ctc 9.034047 loss_rnnt 3.253783 hw_loss 0.327270 lr 0.00028498 rank 6
2023-03-01 14:29:59,232 DEBUG TRAIN Batch 57/4900 loss 11.143723 loss_att 14.372768 loss_ctc 15.344028 loss_rnnt 9.828579 hw_loss 0.204928 lr 0.00028498 rank 3
2023-03-01 14:29:59,242 DEBUG TRAIN Batch 57/4900 loss 4.978595 loss_att 7.375189 loss_ctc 7.256859 loss_rnnt 4.061629 hw_loss 0.251023 lr 0.00028498 rank 5
2023-03-01 14:29:59,245 DEBUG TRAIN Batch 57/4900 loss 3.469485 loss_att 4.533952 loss_ctc 4.918828 loss_rnnt 2.871826 hw_loss 0.359100 lr 0.00028497 rank 1
2023-03-01 14:29:59,271 DEBUG TRAIN Batch 57/4900 loss 8.693289 loss_att 13.267721 loss_ctc 13.139167 loss_rnnt 7.089444 hw_loss 0.180325 lr 0.00028498 rank 2
2023-03-01 14:31:08,678 DEBUG TRAIN Batch 57/5000 loss 3.777843 loss_att 6.813882 loss_ctc 7.615450 loss_rnnt 2.518700 hw_loss 0.262975 lr 0.00028497 rank 6
2023-03-01 14:31:08,687 DEBUG TRAIN Batch 57/5000 loss 5.498185 loss_att 6.922297 loss_ctc 9.662129 loss_rnnt 4.493714 hw_loss 0.308353 lr 0.00028497 rank 0
2023-03-01 14:31:08,691 DEBUG TRAIN Batch 57/5000 loss 6.883977 loss_att 10.036938 loss_ctc 10.716474 loss_rnnt 5.610825 hw_loss 0.246677 lr 0.00028497 rank 5
2023-03-01 14:31:08,694 DEBUG TRAIN Batch 57/5000 loss 6.818079 loss_att 8.926380 loss_ctc 11.741997 loss_rnnt 5.693071 hw_loss 0.087796 lr 0.00028496 rank 7
2023-03-01 14:31:08,700 DEBUG TRAIN Batch 57/5000 loss 6.596433 loss_att 9.068755 loss_ctc 8.487034 loss_rnnt 5.679425 hw_loss 0.319618 lr 0.00028496 rank 3
2023-03-01 14:31:08,713 DEBUG TRAIN Batch 57/5000 loss 4.540071 loss_att 7.594728 loss_ctc 11.137445 loss_rnnt 3.000094 hw_loss 0.092616 lr 0.00028496 rank 1
2023-03-01 14:31:08,723 DEBUG TRAIN Batch 57/5000 loss 6.966826 loss_att 11.068757 loss_ctc 13.971880 loss_rnnt 5.131299 hw_loss 0.152127 lr 0.00028496 rank 2
2023-03-01 14:31:08,725 DEBUG TRAIN Batch 57/5000 loss 5.124871 loss_att 5.367105 loss_ctc 9.218177 loss_rnnt 4.359203 hw_loss 0.321464 lr 0.00028496 rank 4
2023-03-01 14:31:48,105 DEBUG TRAIN Batch 57/5100 loss 2.975797 loss_att 5.120416 loss_ctc 4.361276 loss_rnnt 2.281205 hw_loss 0.151758 lr 0.00028495 rank 1
2023-03-01 14:31:48,121 DEBUG TRAIN Batch 57/5100 loss 1.031461 loss_att 3.300544 loss_ctc 1.665696 loss_rnnt 0.344981 hw_loss 0.277686 lr 0.00028495 rank 3
2023-03-01 14:31:48,123 DEBUG TRAIN Batch 57/5100 loss 4.360788 loss_att 6.763000 loss_ctc 8.078473 loss_rnnt 3.239780 hw_loss 0.271638 lr 0.00028496 rank 6
2023-03-01 14:31:48,123 DEBUG TRAIN Batch 57/5100 loss 5.556969 loss_att 8.765451 loss_ctc 10.168972 loss_rnnt 4.241626 hw_loss 0.110085 lr 0.00028496 rank 0
2023-03-01 14:31:48,124 DEBUG TRAIN Batch 57/5100 loss 7.060740 loss_att 8.900074 loss_ctc 12.356154 loss_rnnt 5.880349 hw_loss 0.199628 lr 0.00028496 rank 5
2023-03-01 14:31:48,128 DEBUG TRAIN Batch 57/5100 loss 7.658854 loss_att 9.006805 loss_ctc 14.297473 loss_rnnt 6.359334 hw_loss 0.271463 lr 0.00028495 rank 2
2023-03-01 14:31:48,152 DEBUG TRAIN Batch 57/5100 loss 3.835498 loss_att 5.402540 loss_ctc 5.217207 loss_rnnt 3.205354 hw_loss 0.248452 lr 0.00028495 rank 4
2023-03-01 14:31:48,163 DEBUG TRAIN Batch 57/5100 loss 1.787963 loss_att 5.449023 loss_ctc 2.688901 loss_rnnt 0.814926 hw_loss 0.226311 lr 0.00028495 rank 7
2023-03-01 14:32:26,750 DEBUG TRAIN Batch 57/5200 loss 9.902885 loss_att 13.334843 loss_ctc 16.816862 loss_rnnt 8.189501 hw_loss 0.197117 lr 0.00028495 rank 0
2023-03-01 14:32:26,752 DEBUG TRAIN Batch 57/5200 loss 2.060720 loss_att 4.836862 loss_ctc 3.472532 loss_rnnt 1.186664 hw_loss 0.244849 lr 0.00028494 rank 2
2023-03-01 14:32:26,755 DEBUG TRAIN Batch 57/5200 loss 6.703396 loss_att 9.897696 loss_ctc 10.737112 loss_rnnt 5.364875 hw_loss 0.303436 lr 0.00028494 rank 7
2023-03-01 14:32:26,755 DEBUG TRAIN Batch 57/5200 loss 1.851505 loss_att 5.251357 loss_ctc 4.029795 loss_rnnt 0.782881 hw_loss 0.184153 lr 0.00028494 rank 3
2023-03-01 14:32:26,755 DEBUG TRAIN Batch 57/5200 loss 7.944594 loss_att 13.167490 loss_ctc 16.956356 loss_rnnt 5.520965 hw_loss 0.332778 lr 0.00028494 rank 1
2023-03-01 14:32:26,756 DEBUG TRAIN Batch 57/5200 loss 7.289363 loss_att 9.296364 loss_ctc 9.877094 loss_rnnt 6.484481 hw_loss 0.109598 lr 0.00028495 rank 6
2023-03-01 14:32:26,757 DEBUG TRAIN Batch 57/5200 loss 11.626134 loss_att 11.154549 loss_ctc 15.856960 loss_rnnt 11.019340 hw_loss 0.256877 lr 0.00028494 rank 5
2023-03-01 14:32:26,757 DEBUG TRAIN Batch 57/5200 loss 4.441673 loss_att 8.868719 loss_ctc 8.105633 loss_rnnt 3.019615 hw_loss 0.090228 lr 0.00028494 rank 4
2023-03-01 14:33:06,633 DEBUG TRAIN Batch 57/5300 loss 3.309869 loss_att 5.398726 loss_ctc 4.098462 loss_rnnt 2.652575 hw_loss 0.251956 lr 0.00028493 rank 5
2023-03-01 14:33:06,634 DEBUG TRAIN Batch 57/5300 loss 4.653226 loss_att 6.885785 loss_ctc 7.246255 loss_rnnt 3.778738 hw_loss 0.154199 lr 0.00028494 rank 0
2023-03-01 14:33:06,635 DEBUG TRAIN Batch 57/5300 loss 1.678785 loss_att 4.236193 loss_ctc 2.442607 loss_rnnt 0.925207 hw_loss 0.262974 lr 0.00028493 rank 1
2023-03-01 14:33:06,636 DEBUG TRAIN Batch 57/5300 loss 6.426289 loss_att 8.888993 loss_ctc 6.804276 loss_rnnt 5.830205 hw_loss 0.099646 lr 0.00028493 rank 4
2023-03-01 14:33:06,635 DEBUG TRAIN Batch 57/5300 loss 4.191745 loss_att 7.364954 loss_ctc 8.497790 loss_rnnt 2.837073 hw_loss 0.273543 lr 0.00028494 rank 6
2023-03-01 14:33:06,636 DEBUG TRAIN Batch 57/5300 loss 1.117988 loss_att 3.182159 loss_ctc 1.534567 loss_rnnt 0.526326 hw_loss 0.231158 lr 0.00028493 rank 7
2023-03-01 14:33:06,650 DEBUG TRAIN Batch 57/5300 loss 3.645823 loss_att 7.508018 loss_ctc 7.551312 loss_rnnt 2.206204 hw_loss 0.274588 lr 0.00028493 rank 3
2023-03-01 14:33:06,658 DEBUG TRAIN Batch 57/5300 loss 7.327423 loss_att 10.626816 loss_ctc 14.148186 loss_rnnt 5.655590 hw_loss 0.192224 lr 0.00028493 rank 2
2023-03-01 14:34:15,056 DEBUG TRAIN Batch 57/5400 loss 12.584054 loss_att 14.213238 loss_ctc 17.978107 loss_rnnt 11.413635 hw_loss 0.235078 lr 0.00028491 rank 1
2023-03-01 14:34:15,057 DEBUG TRAIN Batch 57/5400 loss 4.693904 loss_att 6.350300 loss_ctc 6.484575 loss_rnnt 3.943399 hw_loss 0.338381 lr 0.00028492 rank 5
2023-03-01 14:34:15,059 DEBUG TRAIN Batch 57/5400 loss 6.465806 loss_att 9.004930 loss_ctc 11.890881 loss_rnnt 5.167010 hw_loss 0.126803 lr 0.00028493 rank 6
2023-03-01 14:34:15,066 DEBUG TRAIN Batch 57/5400 loss 5.554739 loss_att 7.597344 loss_ctc 10.595547 loss_rnnt 4.430979 hw_loss 0.080871 lr 0.00028492 rank 2
2023-03-01 14:34:15,078 DEBUG TRAIN Batch 57/5400 loss 3.066807 loss_att 6.898136 loss_ctc 4.811795 loss_rnnt 1.918897 hw_loss 0.279335 lr 0.00028492 rank 7
2023-03-01 14:34:15,081 DEBUG TRAIN Batch 57/5400 loss 5.589620 loss_att 8.008268 loss_ctc 6.943406 loss_rnnt 4.859070 hw_loss 0.124340 lr 0.00028492 rank 4
2023-03-01 14:34:15,085 DEBUG TRAIN Batch 57/5400 loss 5.678489 loss_att 8.405237 loss_ctc 8.428769 loss_rnnt 4.671928 hw_loss 0.177200 lr 0.00028493 rank 0
2023-03-01 14:34:15,097 DEBUG TRAIN Batch 57/5400 loss 9.507866 loss_att 11.527399 loss_ctc 11.712421 loss_rnnt 8.672011 hw_loss 0.258762 lr 0.00028492 rank 3
2023-03-01 14:34:53,579 DEBUG TRAIN Batch 57/5500 loss 9.292809 loss_att 13.877544 loss_ctc 16.498264 loss_rnnt 7.283880 hw_loss 0.246100 lr 0.00028491 rank 7
2023-03-01 14:34:53,580 DEBUG TRAIN Batch 57/5500 loss 2.668454 loss_att 5.693477 loss_ctc 3.480597 loss_rnnt 1.819238 hw_loss 0.254859 lr 0.00028492 rank 0
2023-03-01 14:34:53,601 DEBUG TRAIN Batch 57/5500 loss 2.213311 loss_att 5.810218 loss_ctc 7.177338 loss_rnnt 0.771159 hw_loss 0.114188 lr 0.00028490 rank 1
2023-03-01 14:34:53,605 DEBUG TRAIN Batch 57/5500 loss 8.262909 loss_att 14.495447 loss_ctc 10.206716 loss_rnnt 6.618848 hw_loss 0.259459 lr 0.00028491 rank 6
2023-03-01 14:34:53,605 DEBUG TRAIN Batch 57/5500 loss 6.267053 loss_att 8.791729 loss_ctc 15.910172 loss_rnnt 4.391662 hw_loss 0.158825 lr 0.00028491 rank 5
2023-03-01 14:34:53,607 DEBUG TRAIN Batch 57/5500 loss 2.899204 loss_att 5.264005 loss_ctc 5.199619 loss_rnnt 1.959145 hw_loss 0.300707 lr 0.00028491 rank 2
2023-03-01 14:34:53,609 DEBUG TRAIN Batch 57/5500 loss 4.773521 loss_att 7.709081 loss_ctc 7.314473 loss_rnnt 3.834761 hw_loss 0.024104 lr 0.00028490 rank 4
2023-03-01 14:34:53,611 DEBUG TRAIN Batch 57/5500 loss 2.579514 loss_att 4.736697 loss_ctc 4.447594 loss_rnnt 1.792236 hw_loss 0.200182 lr 0.00028491 rank 3
2023-03-01 14:35:33,516 DEBUG TRAIN Batch 57/5600 loss 5.361094 loss_att 8.447569 loss_ctc 10.794577 loss_rnnt 3.847666 hw_loss 0.321879 lr 0.00028489 rank 4
2023-03-01 14:35:33,530 DEBUG TRAIN Batch 57/5600 loss 7.322694 loss_att 8.219864 loss_ctc 9.719436 loss_rnnt 6.739935 hw_loss 0.157050 lr 0.00028489 rank 7
2023-03-01 14:35:33,529 DEBUG TRAIN Batch 57/5600 loss 3.418989 loss_att 4.984517 loss_ctc 4.750419 loss_rnnt 2.778604 hw_loss 0.280793 lr 0.00028491 rank 0
2023-03-01 14:35:33,533 DEBUG TRAIN Batch 57/5600 loss 3.194393 loss_att 5.148870 loss_ctc 5.380405 loss_rnnt 2.425189 hw_loss 0.162826 lr 0.00028489 rank 1
2023-03-01 14:35:33,534 DEBUG TRAIN Batch 57/5600 loss 9.262972 loss_att 12.694548 loss_ctc 16.382551 loss_rnnt 7.461516 hw_loss 0.310993 lr 0.00028490 rank 6
2023-03-01 14:35:33,535 DEBUG TRAIN Batch 57/5600 loss 2.371282 loss_att 4.260010 loss_ctc 5.301097 loss_rnnt 1.489005 hw_loss 0.213542 lr 0.00028489 rank 2
2023-03-01 14:35:33,537 DEBUG TRAIN Batch 57/5600 loss 6.921933 loss_att 8.802855 loss_ctc 10.936984 loss_rnnt 5.891286 hw_loss 0.223353 lr 0.00028489 rank 3
2023-03-01 14:35:33,543 DEBUG TRAIN Batch 57/5600 loss 4.823014 loss_att 7.784722 loss_ctc 7.606191 loss_rnnt 3.756392 hw_loss 0.193482 lr 0.00028490 rank 5
2023-03-01 14:36:43,547 DEBUG TRAIN Batch 57/5700 loss 6.523123 loss_att 8.652889 loss_ctc 11.048284 loss_rnnt 5.413123 hw_loss 0.151299 lr 0.00028488 rank 1
2023-03-01 14:36:43,549 DEBUG TRAIN Batch 57/5700 loss 6.864212 loss_att 9.947846 loss_ctc 9.758089 loss_rnnt 5.748528 hw_loss 0.212072 lr 0.00028488 rank 4
2023-03-01 14:36:43,557 DEBUG TRAIN Batch 57/5700 loss 6.872772 loss_att 10.519583 loss_ctc 10.984421 loss_rnnt 5.504411 hw_loss 0.170210 lr 0.00028489 rank 0
2023-03-01 14:36:43,557 DEBUG TRAIN Batch 57/5700 loss 2.348185 loss_att 5.356788 loss_ctc 6.268949 loss_rnnt 1.115811 hw_loss 0.202285 lr 0.00028488 rank 7
2023-03-01 14:36:43,561 DEBUG TRAIN Batch 57/5700 loss 8.885267 loss_att 12.729259 loss_ctc 13.978239 loss_rnnt 7.316466 hw_loss 0.226763 lr 0.00028489 rank 5
2023-03-01 14:36:43,561 DEBUG TRAIN Batch 57/5700 loss 7.332220 loss_att 9.393204 loss_ctc 12.630904 loss_rnnt 6.177399 hw_loss 0.067749 lr 0.00028489 rank 6
2023-03-01 14:36:43,564 DEBUG TRAIN Batch 57/5700 loss 4.711844 loss_att 5.467661 loss_ctc 9.009890 loss_rnnt 3.812962 hw_loss 0.327461 lr 0.00028488 rank 3
2023-03-01 14:36:43,567 DEBUG TRAIN Batch 57/5700 loss 13.850558 loss_att 16.332970 loss_ctc 22.362473 loss_rnnt 12.159307 hw_loss 0.112215 lr 0.00028488 rank 2
2023-03-01 14:37:22,228 DEBUG TRAIN Batch 57/5800 loss 1.630686 loss_att 4.988290 loss_ctc 4.335172 loss_rnnt 0.549247 hw_loss 0.092475 lr 0.00028488 rank 0
2023-03-01 14:37:22,229 DEBUG TRAIN Batch 57/5800 loss 4.727519 loss_att 8.557363 loss_ctc 10.884948 loss_rnnt 2.996697 hw_loss 0.269741 lr 0.00028487 rank 7
2023-03-01 14:37:22,242 DEBUG TRAIN Batch 57/5800 loss 5.047596 loss_att 9.652964 loss_ctc 8.850272 loss_rnnt 3.619036 hw_loss 0.000867 lr 0.00028487 rank 2
2023-03-01 14:37:22,243 DEBUG TRAIN Batch 57/5800 loss 1.403958 loss_att 4.882957 loss_ctc 3.119035 loss_rnnt 0.449702 hw_loss 0.055836 lr 0.00028487 rank 3
2023-03-01 14:37:22,243 DEBUG TRAIN Batch 57/5800 loss 3.690998 loss_att 5.107863 loss_ctc 8.156930 loss_rnnt 2.811558 hw_loss 0.001142 lr 0.00028488 rank 6
2023-03-01 14:37:22,247 DEBUG TRAIN Batch 57/5800 loss 5.281550 loss_att 6.143777 loss_ctc 8.699864 loss_rnnt 4.559486 hw_loss 0.175955 lr 0.00028487 rank 1
2023-03-01 14:37:22,251 DEBUG TRAIN Batch 57/5800 loss 5.957941 loss_att 7.007277 loss_ctc 8.713345 loss_rnnt 5.273381 hw_loss 0.201198 lr 0.00028487 rank 4
2023-03-01 14:37:22,303 DEBUG TRAIN Batch 57/5800 loss 7.478585 loss_att 8.780046 loss_ctc 10.689821 loss_rnnt 6.760247 hw_loss 0.056027 lr 0.00028488 rank 5
2023-03-01 14:38:01,138 DEBUG TRAIN Batch 57/5900 loss 7.958913 loss_att 9.010937 loss_ctc 10.898535 loss_rnnt 7.259242 hw_loss 0.182468 lr 0.00028487 rank 6
2023-03-01 14:38:01,143 DEBUG TRAIN Batch 57/5900 loss 2.513349 loss_att 6.105402 loss_ctc 5.089447 loss_rnnt 1.326842 hw_loss 0.233657 lr 0.00028486 rank 2
2023-03-01 14:38:01,152 DEBUG TRAIN Batch 57/5900 loss 6.602349 loss_att 8.451859 loss_ctc 12.126390 loss_rnnt 5.361602 hw_loss 0.251825 lr 0.00028486 rank 7
2023-03-01 14:38:01,154 DEBUG TRAIN Batch 57/5900 loss 4.185384 loss_att 6.610498 loss_ctc 9.068567 loss_rnnt 2.950043 hw_loss 0.186051 lr 0.00028487 rank 0
2023-03-01 14:38:01,155 DEBUG TRAIN Batch 57/5900 loss 2.939152 loss_att 7.376070 loss_ctc 8.760211 loss_rnnt 1.173368 hw_loss 0.191736 lr 0.00028486 rank 3
2023-03-01 14:38:01,156 DEBUG TRAIN Batch 57/5900 loss 3.482547 loss_att 6.701789 loss_ctc 2.606426 loss_rnnt 2.903300 hw_loss 0.097903 lr 0.00028486 rank 5
2023-03-01 14:38:01,159 DEBUG TRAIN Batch 57/5900 loss 3.076831 loss_att 7.050528 loss_ctc 3.710939 loss_rnnt 2.086377 hw_loss 0.208437 lr 0.00028486 rank 1
2023-03-01 14:38:01,162 DEBUG TRAIN Batch 57/5900 loss 3.817063 loss_att 7.514309 loss_ctc 8.049780 loss_rnnt 2.455984 hw_loss 0.107377 lr 0.00028486 rank 4
2023-03-01 14:38:41,243 DEBUG TRAIN Batch 57/6000 loss 8.964848 loss_att 13.079896 loss_ctc 11.265068 loss_rnnt 7.737636 hw_loss 0.182823 lr 0.00028486 rank 6
2023-03-01 14:38:41,249 DEBUG TRAIN Batch 57/6000 loss 5.370683 loss_att 10.066928 loss_ctc 11.498623 loss_rnnt 3.562629 hw_loss 0.097025 lr 0.00028485 rank 2
2023-03-01 14:38:41,250 DEBUG TRAIN Batch 57/6000 loss 4.811301 loss_att 7.137789 loss_ctc 6.272615 loss_rnnt 4.124854 hw_loss 0.049327 lr 0.00028485 rank 5
2023-03-01 14:38:41,257 DEBUG TRAIN Batch 57/6000 loss 4.995607 loss_att 8.623006 loss_ctc 7.753011 loss_rnnt 3.817882 hw_loss 0.158609 lr 0.00028485 rank 7
2023-03-01 14:38:41,262 DEBUG TRAIN Batch 57/6000 loss 9.456780 loss_att 12.936353 loss_ctc 16.251396 loss_rnnt 7.777197 hw_loss 0.145726 lr 0.00028486 rank 0
2023-03-01 14:38:41,263 DEBUG TRAIN Batch 57/6000 loss 2.727116 loss_att 4.364463 loss_ctc 3.542470 loss_rnnt 2.204371 hw_loss 0.162302 lr 0.00028485 rank 3
2023-03-01 14:38:41,266 DEBUG TRAIN Batch 57/6000 loss 11.082842 loss_att 14.763670 loss_ctc 21.948196 loss_rnnt 8.770661 hw_loss 0.238690 lr 0.00028485 rank 4
2023-03-01 14:38:41,282 DEBUG TRAIN Batch 57/6000 loss 7.378590 loss_att 10.150673 loss_ctc 13.170230 loss_rnnt 5.983987 hw_loss 0.127438 lr 0.00028484 rank 1
2023-03-01 14:39:49,818 DEBUG TRAIN Batch 57/6100 loss 6.392121 loss_att 8.789085 loss_ctc 8.084869 loss_rnnt 5.621314 hw_loss 0.123216 lr 0.00028485 rank 0
2023-03-01 14:39:49,839 DEBUG TRAIN Batch 57/6100 loss 6.012167 loss_att 11.263500 loss_ctc 16.289015 loss_rnnt 3.547154 hw_loss 0.083437 lr 0.00028483 rank 1
2023-03-01 14:39:49,841 DEBUG TRAIN Batch 57/6100 loss 5.023165 loss_att 9.095284 loss_ctc 7.920332 loss_rnnt 3.621973 hw_loss 0.375898 lr 0.00028484 rank 7
2023-03-01 14:39:49,843 DEBUG TRAIN Batch 57/6100 loss 7.064761 loss_att 9.954880 loss_ctc 12.971696 loss_rnnt 5.640101 hw_loss 0.110709 lr 0.00028485 rank 6
2023-03-01 14:39:49,846 DEBUG TRAIN Batch 57/6100 loss 7.410272 loss_att 10.202082 loss_ctc 9.111062 loss_rnnt 6.468143 hw_loss 0.294365 lr 0.00028484 rank 5
2023-03-01 14:39:49,846 DEBUG TRAIN Batch 57/6100 loss 8.352796 loss_att 8.979612 loss_ctc 12.959009 loss_rnnt 7.509737 hw_loss 0.194123 lr 0.00028484 rank 2
2023-03-01 14:39:49,855 DEBUG TRAIN Batch 57/6100 loss 6.351346 loss_att 10.686513 loss_ctc 12.632044 loss_rnnt 4.516154 hw_loss 0.245124 lr 0.00028484 rank 3
2023-03-01 14:39:49,895 DEBUG TRAIN Batch 57/6100 loss 5.791903 loss_att 8.469049 loss_ctc 10.306623 loss_rnnt 4.530479 hw_loss 0.232558 lr 0.00028484 rank 4
2023-03-01 14:40:29,527 DEBUG TRAIN Batch 57/6200 loss 7.225711 loss_att 9.474687 loss_ctc 9.384291 loss_rnnt 6.387662 hw_loss 0.188331 lr 0.00028483 rank 7
2023-03-01 14:40:29,538 DEBUG TRAIN Batch 57/6200 loss 4.902626 loss_att 7.100412 loss_ctc 8.890171 loss_rnnt 3.848860 hw_loss 0.154755 lr 0.00028484 rank 0
2023-03-01 14:40:29,541 DEBUG TRAIN Batch 57/6200 loss 1.528786 loss_att 3.563156 loss_ctc 2.668657 loss_rnnt 0.855574 hw_loss 0.214414 lr 0.00028483 rank 5
2023-03-01 14:40:29,544 DEBUG TRAIN Batch 57/6200 loss 6.222249 loss_att 10.338910 loss_ctc 11.815851 loss_rnnt 4.515972 hw_loss 0.257120 lr 0.00028482 rank 4
2023-03-01 14:40:29,544 DEBUG TRAIN Batch 57/6200 loss 6.152010 loss_att 9.355393 loss_ctc 8.727958 loss_rnnt 5.005339 hw_loss 0.304755 lr 0.00028483 rank 6
2023-03-01 14:40:29,544 DEBUG TRAIN Batch 57/6200 loss 9.289777 loss_att 11.219889 loss_ctc 10.242117 loss_rnnt 8.679113 hw_loss 0.183117 lr 0.00028483 rank 2
2023-03-01 14:40:29,548 DEBUG TRAIN Batch 57/6200 loss 2.299673 loss_att 4.407739 loss_ctc 4.301921 loss_rnnt 1.557055 hw_loss 0.101324 lr 0.00028482 rank 1
2023-03-01 14:40:29,548 DEBUG TRAIN Batch 57/6200 loss 3.116523 loss_att 5.632777 loss_ctc 5.825928 loss_rnnt 2.213952 hw_loss 0.071374 lr 0.00028482 rank 3
2023-03-01 14:41:09,953 DEBUG TRAIN Batch 57/6300 loss 6.407832 loss_att 6.678106 loss_ctc 9.349245 loss_rnnt 5.838482 hw_loss 0.230823 lr 0.00028482 rank 0
2023-03-01 14:41:09,953 DEBUG TRAIN Batch 57/6300 loss 7.866773 loss_att 9.278936 loss_ctc 10.739697 loss_rnnt 7.104667 hw_loss 0.181155 lr 0.00028481 rank 4
2023-03-01 14:41:09,955 DEBUG TRAIN Batch 57/6300 loss 4.036939 loss_att 7.029032 loss_ctc 7.931923 loss_rnnt 2.777202 hw_loss 0.266225 lr 0.00028482 rank 5
2023-03-01 14:41:09,955 DEBUG TRAIN Batch 57/6300 loss 2.762477 loss_att 3.471411 loss_ctc 4.116231 loss_rnnt 2.308060 hw_loss 0.247743 lr 0.00028481 rank 7
2023-03-01 14:41:09,956 DEBUG TRAIN Batch 57/6300 loss 4.155742 loss_att 6.576088 loss_ctc 7.976308 loss_rnnt 3.036585 hw_loss 0.235647 lr 0.00028482 rank 6
2023-03-01 14:41:09,957 DEBUG TRAIN Batch 57/6300 loss 4.180757 loss_att 6.282677 loss_ctc 7.024859 loss_rnnt 3.254399 hw_loss 0.237676 lr 0.00028481 rank 1
2023-03-01 14:41:09,959 DEBUG TRAIN Batch 57/6300 loss 6.958183 loss_att 8.110413 loss_ctc 9.016555 loss_rnnt 6.348285 hw_loss 0.196881 lr 0.00028481 rank 3
2023-03-01 14:41:09,959 DEBUG TRAIN Batch 57/6300 loss 6.096613 loss_att 8.942704 loss_ctc 7.702206 loss_rnnt 5.233485 hw_loss 0.149683 lr 0.00028481 rank 2
2023-03-01 14:42:20,182 DEBUG TRAIN Batch 57/6400 loss 9.749893 loss_att 11.541321 loss_ctc 20.533318 loss_rnnt 7.871007 hw_loss 0.155271 lr 0.00028480 rank 3
2023-03-01 14:42:20,193 DEBUG TRAIN Batch 57/6400 loss 1.598584 loss_att 3.166589 loss_ctc 3.375185 loss_rnnt 0.926514 hw_loss 0.227978 lr 0.00028480 rank 2
2023-03-01 14:42:20,198 DEBUG TRAIN Batch 57/6400 loss 13.809605 loss_att 15.385109 loss_ctc 23.481153 loss_rnnt 12.028079 hw_loss 0.331660 lr 0.00028481 rank 6
2023-03-01 14:42:20,198 DEBUG TRAIN Batch 57/6400 loss 5.417582 loss_att 6.468154 loss_ctc 8.205500 loss_rnnt 4.660044 hw_loss 0.329440 lr 0.00028480 rank 1
2023-03-01 14:42:20,199 DEBUG TRAIN Batch 57/6400 loss 2.951530 loss_att 6.208246 loss_ctc 4.600365 loss_rnnt 2.080186 hw_loss 0.000293 lr 0.00028480 rank 4
2023-03-01 14:42:20,212 DEBUG TRAIN Batch 57/6400 loss 5.874973 loss_att 8.180286 loss_ctc 14.042341 loss_rnnt 4.247798 hw_loss 0.144618 lr 0.00028481 rank 5
2023-03-01 14:42:20,226 DEBUG TRAIN Batch 57/6400 loss 1.754110 loss_att 5.880383 loss_ctc 2.308197 loss_rnnt 0.729648 hw_loss 0.234991 lr 0.00028480 rank 7
2023-03-01 14:42:20,255 DEBUG TRAIN Batch 57/6400 loss 2.400451 loss_att 5.645454 loss_ctc 2.723084 loss_rnnt 1.604820 hw_loss 0.194273 lr 0.00028481 rank 0
2023-03-01 14:42:59,318 DEBUG TRAIN Batch 57/6500 loss 3.302697 loss_att 4.784178 loss_ctc 4.783645 loss_rnnt 2.670366 hw_loss 0.259828 lr 0.00028479 rank 1
2023-03-01 14:42:59,328 DEBUG TRAIN Batch 57/6500 loss 2.789981 loss_att 4.419295 loss_ctc 5.108441 loss_rnnt 2.051688 hw_loss 0.193691 lr 0.00028479 rank 7
2023-03-01 14:42:59,331 DEBUG TRAIN Batch 57/6500 loss 8.827409 loss_att 11.863390 loss_ctc 12.102244 loss_rnnt 7.641282 hw_loss 0.266784 lr 0.00028480 rank 0
2023-03-01 14:42:59,338 DEBUG TRAIN Batch 57/6500 loss 4.799693 loss_att 9.150352 loss_ctc 11.475375 loss_rnnt 2.934915 hw_loss 0.196041 lr 0.00028479 rank 3
2023-03-01 14:42:59,341 DEBUG TRAIN Batch 57/6500 loss 3.399804 loss_att 5.852077 loss_ctc 7.925291 loss_rnnt 2.203314 hw_loss 0.192446 lr 0.00028479 rank 5
2023-03-01 14:42:59,341 DEBUG TRAIN Batch 57/6500 loss 6.341649 loss_att 10.267820 loss_ctc 11.176956 loss_rnnt 4.801494 hw_loss 0.206648 lr 0.00028480 rank 6
2023-03-01 14:42:59,341 DEBUG TRAIN Batch 57/6500 loss 2.839930 loss_att 6.737619 loss_ctc 7.087688 loss_rnnt 1.384648 hw_loss 0.205080 lr 0.00028479 rank 4
2023-03-01 14:42:59,381 DEBUG TRAIN Batch 57/6500 loss 10.107893 loss_att 10.989286 loss_ctc 13.126287 loss_rnnt 9.436579 hw_loss 0.173594 lr 0.00028479 rank 2
2023-03-01 14:43:38,075 DEBUG TRAIN Batch 57/6600 loss 2.568445 loss_att 6.278848 loss_ctc 5.172579 loss_rnnt 1.402986 hw_loss 0.142801 lr 0.00028478 rank 4
2023-03-01 14:43:38,085 DEBUG TRAIN Batch 57/6600 loss 4.046403 loss_att 8.712757 loss_ctc 8.433531 loss_rnnt 2.423746 hw_loss 0.195819 lr 0.00028478 rank 2
2023-03-01 14:43:38,096 DEBUG TRAIN Batch 57/6600 loss 4.735332 loss_att 7.719792 loss_ctc 10.284604 loss_rnnt 3.248622 hw_loss 0.281091 lr 0.00028478 rank 7
2023-03-01 14:43:38,096 DEBUG TRAIN Batch 57/6600 loss 4.073314 loss_att 6.113306 loss_ctc 8.251438 loss_rnnt 3.043497 hw_loss 0.121378 lr 0.00028479 rank 0
2023-03-01 14:43:38,098 DEBUG TRAIN Batch 57/6600 loss 3.984761 loss_att 7.690257 loss_ctc 5.873022 loss_rnnt 2.828549 hw_loss 0.306270 lr 0.00028478 rank 3
2023-03-01 14:43:38,098 DEBUG TRAIN Batch 57/6600 loss 4.171075 loss_att 7.004182 loss_ctc 4.288483 loss_rnnt 3.509749 hw_loss 0.148219 lr 0.00028478 rank 5
2023-03-01 14:43:38,104 DEBUG TRAIN Batch 57/6600 loss 10.597001 loss_att 9.668967 loss_ctc 15.033545 loss_rnnt 10.098129 hw_loss 0.174263 lr 0.00028479 rank 6
2023-03-01 14:43:38,146 DEBUG TRAIN Batch 57/6600 loss 10.604475 loss_att 13.974231 loss_ctc 24.483343 loss_rnnt 8.020183 hw_loss 0.112171 lr 0.00028477 rank 1
2023-03-01 14:44:17,345 DEBUG TRAIN Batch 57/6700 loss 8.687868 loss_att 12.142582 loss_ctc 15.320834 loss_rnnt 7.010652 hw_loss 0.191021 lr 0.00028478 rank 0
2023-03-01 14:44:17,345 DEBUG TRAIN Batch 57/6700 loss 5.011338 loss_att 7.472430 loss_ctc 7.034003 loss_rnnt 4.135958 hw_loss 0.212761 lr 0.00028477 rank 2
2023-03-01 14:44:17,346 DEBUG TRAIN Batch 57/6700 loss 7.271548 loss_att 9.971089 loss_ctc 15.243636 loss_rnnt 5.582826 hw_loss 0.161002 lr 0.00028477 rank 5
2023-03-01 14:44:17,346 DEBUG TRAIN Batch 57/6700 loss 5.928210 loss_att 9.083737 loss_ctc 10.664010 loss_rnnt 4.495112 hw_loss 0.319786 lr 0.00028478 rank 6
2023-03-01 14:44:17,349 DEBUG TRAIN Batch 57/6700 loss 2.728755 loss_att 4.916950 loss_ctc 4.914269 loss_rnnt 1.912304 hw_loss 0.163894 lr 0.00028477 rank 3
2023-03-01 14:44:17,351 DEBUG TRAIN Batch 57/6700 loss 10.579856 loss_att 15.551476 loss_ctc 17.565439 loss_rnnt 8.505609 hw_loss 0.278458 lr 0.00028477 rank 7
2023-03-01 14:44:17,360 DEBUG TRAIN Batch 57/6700 loss 3.334535 loss_att 5.939577 loss_ctc 7.671613 loss_rnnt 2.159971 hw_loss 0.141146 lr 0.00028477 rank 4
2023-03-01 14:44:17,380 DEBUG TRAIN Batch 57/6700 loss 4.403297 loss_att 5.345971 loss_ctc 10.575296 loss_rnnt 3.255738 hw_loss 0.255171 lr 0.00028476 rank 1
2023-03-01 14:45:25,669 DEBUG TRAIN Batch 57/6800 loss 6.630144 loss_att 9.617713 loss_ctc 13.400176 loss_rnnt 5.040643 hw_loss 0.167467 lr 0.00028475 rank 1
2023-03-01 14:45:25,674 DEBUG TRAIN Batch 57/6800 loss 1.676078 loss_att 4.258561 loss_ctc 2.320655 loss_rnnt 0.961741 hw_loss 0.209806 lr 0.00028476 rank 7
2023-03-01 14:45:25,675 DEBUG TRAIN Batch 57/6800 loss 9.999081 loss_att 13.421512 loss_ctc 18.290977 loss_rnnt 8.070843 hw_loss 0.259061 lr 0.00028476 rank 6
2023-03-01 14:45:25,675 DEBUG TRAIN Batch 57/6800 loss 4.012908 loss_att 6.290864 loss_ctc 6.775510 loss_rnnt 3.083645 hw_loss 0.197482 lr 0.00028476 rank 2
2023-03-01 14:45:25,678 DEBUG TRAIN Batch 57/6800 loss 3.394910 loss_att 5.937362 loss_ctc 5.966844 loss_rnnt 2.454751 hw_loss 0.166396 lr 0.00028477 rank 0
2023-03-01 14:45:25,679 DEBUG TRAIN Batch 57/6800 loss 4.797663 loss_att 6.729144 loss_ctc 6.845607 loss_rnnt 4.052524 hw_loss 0.160845 lr 0.00028476 rank 5
2023-03-01 14:45:25,680 DEBUG TRAIN Batch 57/6800 loss 5.372274 loss_att 7.606416 loss_ctc 8.274538 loss_rnnt 4.409510 hw_loss 0.241813 lr 0.00028475 rank 4
2023-03-01 14:45:25,687 DEBUG TRAIN Batch 57/6800 loss 6.254200 loss_att 8.443188 loss_ctc 7.711097 loss_rnnt 5.520653 hw_loss 0.190305 lr 0.00028476 rank 3
2023-03-01 14:46:04,171 DEBUG TRAIN Batch 57/6900 loss 6.191570 loss_att 9.101870 loss_ctc 11.165117 loss_rnnt 4.793633 hw_loss 0.286381 lr 0.00028474 rank 7
2023-03-01 14:46:04,176 DEBUG TRAIN Batch 57/6900 loss 3.821364 loss_att 6.538217 loss_ctc 8.638416 loss_rnnt 2.584797 hw_loss 0.095480 lr 0.00028475 rank 5
2023-03-01 14:46:04,176 DEBUG TRAIN Batch 57/6900 loss 4.989438 loss_att 8.398449 loss_ctc 9.813892 loss_rnnt 3.583805 hw_loss 0.151067 lr 0.00028474 rank 1
2023-03-01 14:46:04,178 DEBUG TRAIN Batch 57/6900 loss 11.073050 loss_att 13.295753 loss_ctc 15.554095 loss_rnnt 9.989394 hw_loss 0.078083 lr 0.00028475 rank 0
2023-03-01 14:46:04,179 DEBUG TRAIN Batch 57/6900 loss 11.953342 loss_att 12.610878 loss_ctc 22.454166 loss_rnnt 10.371074 hw_loss 0.094972 lr 0.00028474 rank 4
2023-03-01 14:46:04,181 DEBUG TRAIN Batch 57/6900 loss 14.605657 loss_att 16.564072 loss_ctc 21.464941 loss_rnnt 13.264661 hw_loss 0.065141 lr 0.00028475 rank 6
2023-03-01 14:46:04,186 DEBUG TRAIN Batch 57/6900 loss 4.811927 loss_att 7.367666 loss_ctc 11.294783 loss_rnnt 3.309150 hw_loss 0.238590 lr 0.00028474 rank 3
2023-03-01 14:46:04,224 DEBUG TRAIN Batch 57/6900 loss 4.184793 loss_att 6.521803 loss_ctc 9.430642 loss_rnnt 2.916107 hw_loss 0.190945 lr 0.00028474 rank 2
2023-03-01 14:46:43,357 DEBUG TRAIN Batch 57/7000 loss 4.712310 loss_att 7.229097 loss_ctc 10.795242 loss_rnnt 3.270230 hw_loss 0.239370 lr 0.00028474 rank 5
2023-03-01 14:46:43,362 DEBUG TRAIN Batch 57/7000 loss 4.508243 loss_att 7.952620 loss_ctc 10.641655 loss_rnnt 2.897449 hw_loss 0.195243 lr 0.00028473 rank 7
2023-03-01 14:46:43,364 DEBUG TRAIN Batch 57/7000 loss 10.138336 loss_att 10.920886 loss_ctc 12.894550 loss_rnnt 9.483086 hw_loss 0.246085 lr 0.00028474 rank 0
2023-03-01 14:46:43,366 DEBUG TRAIN Batch 57/7000 loss 3.362852 loss_att 5.473254 loss_ctc 5.622848 loss_rnnt 2.536778 hw_loss 0.192488 lr 0.00028474 rank 6
2023-03-01 14:46:43,370 DEBUG TRAIN Batch 57/7000 loss 5.663253 loss_att 6.731575 loss_ctc 9.170334 loss_rnnt 4.829649 hw_loss 0.285615 lr 0.00028473 rank 3
2023-03-01 14:46:43,371 DEBUG TRAIN Batch 57/7000 loss 4.116576 loss_att 7.010563 loss_ctc 7.909585 loss_rnnt 2.927519 hw_loss 0.195984 lr 0.00028473 rank 2
2023-03-01 14:46:43,386 DEBUG TRAIN Batch 57/7000 loss 5.669050 loss_att 6.188997 loss_ctc 8.614895 loss_rnnt 5.028039 hw_loss 0.270453 lr 0.00028473 rank 1
2023-03-01 14:46:43,400 DEBUG TRAIN Batch 57/7000 loss 4.752974 loss_att 5.789886 loss_ctc 6.605939 loss_rnnt 4.164096 hw_loss 0.252063 lr 0.00028473 rank 4
2023-03-01 14:47:54,333 DEBUG TRAIN Batch 57/7100 loss 6.249599 loss_att 7.765896 loss_ctc 10.437671 loss_rnnt 5.254367 hw_loss 0.250431 lr 0.00028473 rank 5
2023-03-01 14:47:54,344 DEBUG TRAIN Batch 57/7100 loss 3.112009 loss_att 4.232518 loss_ctc 5.643361 loss_rnnt 2.368313 hw_loss 0.341399 lr 0.00028472 rank 2
2023-03-01 14:47:54,349 DEBUG TRAIN Batch 57/7100 loss 4.818577 loss_att 9.565472 loss_ctc 10.132599 loss_rnnt 3.127378 hw_loss 0.062409 lr 0.00028472 rank 3
2023-03-01 14:47:54,361 DEBUG TRAIN Batch 57/7100 loss 4.555546 loss_att 7.327041 loss_ctc 5.063631 loss_rnnt 3.824259 hw_loss 0.204830 lr 0.00028473 rank 0
2023-03-01 14:47:54,370 DEBUG TRAIN Batch 57/7100 loss 6.118947 loss_att 10.522150 loss_ctc 11.606974 loss_rnnt 4.396946 hw_loss 0.205543 lr 0.00028472 rank 1
2023-03-01 14:47:54,370 DEBUG TRAIN Batch 57/7100 loss 1.484242 loss_att 5.384062 loss_ctc 2.712269 loss_rnnt 0.411041 hw_loss 0.242812 lr 0.00028472 rank 7
2023-03-01 14:47:54,385 DEBUG TRAIN Batch 57/7100 loss 3.903872 loss_att 6.812160 loss_ctc 8.936890 loss_rnnt 2.549592 hw_loss 0.190413 lr 0.00028472 rank 4
2023-03-01 14:47:54,399 DEBUG TRAIN Batch 57/7100 loss 6.384912 loss_att 8.708698 loss_ctc 12.540431 loss_rnnt 4.984676 hw_loss 0.215140 lr 0.00028473 rank 6
2023-03-01 14:48:33,061 DEBUG TRAIN Batch 57/7200 loss 5.605900 loss_att 6.904939 loss_ctc 7.055078 loss_rnnt 5.152487 hw_loss 0.000716 lr 0.00028472 rank 6
2023-03-01 14:48:33,074 DEBUG TRAIN Batch 57/7200 loss 1.634437 loss_att 5.169222 loss_ctc 2.164014 loss_rnnt 0.748743 hw_loss 0.202738 lr 0.00028471 rank 2
2023-03-01 14:48:33,078 DEBUG TRAIN Batch 57/7200 loss 2.173615 loss_att 6.114968 loss_ctc 3.858589 loss_rnnt 1.066349 hw_loss 0.176873 lr 0.00028472 rank 0
2023-03-01 14:48:33,079 DEBUG TRAIN Batch 57/7200 loss 4.556088 loss_att 8.640131 loss_ctc 7.648182 loss_rnnt 3.282204 hw_loss 0.083993 lr 0.00028471 rank 1
2023-03-01 14:48:33,081 DEBUG TRAIN Batch 57/7200 loss 4.594305 loss_att 7.202923 loss_ctc 6.283039 loss_rnnt 3.711146 hw_loss 0.255507 lr 0.00028471 rank 7
2023-03-01 14:48:33,082 DEBUG TRAIN Batch 57/7200 loss 3.889544 loss_att 7.788197 loss_ctc 9.166910 loss_rnnt 2.238434 hw_loss 0.314493 lr 0.00028471 rank 4
2023-03-01 14:48:33,085 DEBUG TRAIN Batch 57/7200 loss 2.897983 loss_att 6.289217 loss_ctc 5.050070 loss_rnnt 1.805060 hw_loss 0.239495 lr 0.00028471 rank 5
2023-03-01 14:48:33,100 DEBUG TRAIN Batch 57/7200 loss 2.783397 loss_att 6.498011 loss_ctc 7.381331 loss_rnnt 1.285539 hw_loss 0.266021 lr 0.00028471 rank 3
2023-03-01 14:49:12,223 DEBUG TRAIN Batch 57/7300 loss 1.375557 loss_att 4.397426 loss_ctc 3.121938 loss_rnnt 0.437057 hw_loss 0.189891 lr 0.00028470 rank 2
2023-03-01 14:49:12,233 DEBUG TRAIN Batch 57/7300 loss 10.418493 loss_att 14.207112 loss_ctc 16.363655 loss_rnnt 8.745033 hw_loss 0.230714 lr 0.00028470 rank 4
2023-03-01 14:49:12,234 DEBUG TRAIN Batch 57/7300 loss 8.621569 loss_att 11.610281 loss_ctc 13.879974 loss_rnnt 7.138855 hw_loss 0.344718 lr 0.00028471 rank 0
2023-03-01 14:49:12,235 DEBUG TRAIN Batch 57/7300 loss 6.382367 loss_att 9.788677 loss_ctc 11.598810 loss_rnnt 4.871706 hw_loss 0.251013 lr 0.00028470 rank 5
2023-03-01 14:49:12,234 DEBUG TRAIN Batch 57/7300 loss 6.146132 loss_att 8.277615 loss_ctc 8.720171 loss_rnnt 5.234533 hw_loss 0.266430 lr 0.00028471 rank 6
2023-03-01 14:49:12,235 DEBUG TRAIN Batch 57/7300 loss 7.922253 loss_att 9.423198 loss_ctc 12.088413 loss_rnnt 6.919272 hw_loss 0.276194 lr 0.00028470 rank 7
2023-03-01 14:49:12,235 DEBUG TRAIN Batch 57/7300 loss 4.463012 loss_att 7.056538 loss_ctc 5.608587 loss_rnnt 3.689414 hw_loss 0.191530 lr 0.00028470 rank 3
2023-03-01 14:49:12,238 DEBUG TRAIN Batch 57/7300 loss 3.430587 loss_att 5.979383 loss_ctc 9.650761 loss_rnnt 1.973501 hw_loss 0.221195 lr 0.00028469 rank 1
2023-03-01 14:49:51,593 DEBUG TRAIN Batch 57/7400 loss 7.271983 loss_att 9.801783 loss_ctc 8.217781 loss_rnnt 6.532083 hw_loss 0.202188 lr 0.00028469 rank 4
2023-03-01 14:49:51,607 DEBUG TRAIN Batch 57/7400 loss 4.260148 loss_att 6.728966 loss_ctc 9.159772 loss_rnnt 3.042780 hw_loss 0.131852 lr 0.00028469 rank 7
2023-03-01 14:49:51,608 DEBUG TRAIN Batch 57/7400 loss 7.023480 loss_att 7.886796 loss_ctc 9.502970 loss_rnnt 6.386834 hw_loss 0.250095 lr 0.00028470 rank 0
2023-03-01 14:49:51,609 DEBUG TRAIN Batch 57/7400 loss 7.951086 loss_att 13.143557 loss_ctc 13.501951 loss_rnnt 6.146358 hw_loss 0.048970 lr 0.00028470 rank 6
2023-03-01 14:49:51,611 DEBUG TRAIN Batch 57/7400 loss 11.241514 loss_att 13.871862 loss_ctc 24.794220 loss_rnnt 8.825203 hw_loss 0.156025 lr 0.00028469 rank 2
2023-03-01 14:49:51,613 DEBUG TRAIN Batch 57/7400 loss 3.532984 loss_att 7.245293 loss_ctc 8.490438 loss_rnnt 2.009857 hw_loss 0.224384 lr 0.00028469 rank 5
2023-03-01 14:49:51,615 DEBUG TRAIN Batch 57/7400 loss 15.077453 loss_att 17.860346 loss_ctc 25.952002 loss_rnnt 12.934274 hw_loss 0.256236 lr 0.00028469 rank 3
2023-03-01 14:49:51,661 DEBUG TRAIN Batch 57/7400 loss 8.321507 loss_att 10.676067 loss_ctc 11.018856 loss_rnnt 7.306349 hw_loss 0.346124 lr 0.00028468 rank 1
2023-03-01 14:51:01,425 DEBUG TRAIN Batch 57/7500 loss 6.352426 loss_att 8.371429 loss_ctc 10.162951 loss_rnnt 5.320402 hw_loss 0.225286 lr 0.00028469 rank 0
2023-03-01 14:51:01,434 DEBUG TRAIN Batch 57/7500 loss 5.304481 loss_att 7.635587 loss_ctc 11.294558 loss_rnnt 3.921063 hw_loss 0.222224 lr 0.00028467 rank 1
2023-03-01 14:51:01,437 DEBUG TRAIN Batch 57/7500 loss 3.495581 loss_att 4.371332 loss_ctc 3.832266 loss_rnnt 3.180714 hw_loss 0.177796 lr 0.00028467 rank 3
2023-03-01 14:51:01,437 DEBUG TRAIN Batch 57/7500 loss 6.478925 loss_att 9.925409 loss_ctc 11.874098 loss_rnnt 4.965857 hw_loss 0.195776 lr 0.00028468 rank 2
2023-03-01 14:51:01,442 DEBUG TRAIN Batch 57/7500 loss 8.123879 loss_att 10.207894 loss_ctc 12.003818 loss_rnnt 7.115476 hw_loss 0.139269 lr 0.00028468 rank 7
2023-03-01 14:51:01,441 DEBUG TRAIN Batch 57/7500 loss 2.657077 loss_att 6.694753 loss_ctc 6.179848 loss_rnnt 1.264434 hw_loss 0.216383 lr 0.00028467 rank 4
2023-03-01 14:51:01,447 DEBUG TRAIN Batch 57/7500 loss 13.472771 loss_att 19.892937 loss_ctc 27.196903 loss_rnnt 10.236059 hw_loss 0.230242 lr 0.00028468 rank 5
2023-03-01 14:51:01,486 DEBUG TRAIN Batch 57/7500 loss 2.108277 loss_att 5.897871 loss_ctc 7.452715 loss_rnnt 0.493634 hw_loss 0.270248 lr 0.00028468 rank 6
2023-03-01 14:51:40,706 DEBUG TRAIN Batch 57/7600 loss 2.139685 loss_att 4.966572 loss_ctc 2.590612 loss_rnnt 1.336647 hw_loss 0.332882 lr 0.00028466 rank 2
2023-03-01 14:51:40,714 DEBUG TRAIN Batch 57/7600 loss 4.853155 loss_att 6.796511 loss_ctc 6.931363 loss_rnnt 4.023931 hw_loss 0.306485 lr 0.00028466 rank 7
2023-03-01 14:51:40,717 DEBUG TRAIN Batch 57/7600 loss 4.457809 loss_att 6.998362 loss_ctc 7.105850 loss_rnnt 3.550933 hw_loss 0.085675 lr 0.00028466 rank 3
2023-03-01 14:51:40,718 DEBUG TRAIN Batch 57/7600 loss 5.356375 loss_att 8.126460 loss_ctc 8.419173 loss_rnnt 4.253833 hw_loss 0.262784 lr 0.00028466 rank 1
2023-03-01 14:51:40,719 DEBUG TRAIN Batch 57/7600 loss 7.417666 loss_att 9.184628 loss_ctc 12.461702 loss_rnnt 6.281760 hw_loss 0.206206 lr 0.00028467 rank 6
2023-03-01 14:51:40,721 DEBUG TRAIN Batch 57/7600 loss 10.371945 loss_att 11.515980 loss_ctc 14.449198 loss_rnnt 9.393802 hw_loss 0.385695 lr 0.00028467 rank 0
2023-03-01 14:51:40,724 DEBUG TRAIN Batch 57/7600 loss 4.221801 loss_att 6.354872 loss_ctc 6.088901 loss_rnnt 3.425889 hw_loss 0.225657 lr 0.00028467 rank 5
2023-03-01 14:51:40,727 DEBUG TRAIN Batch 57/7600 loss 4.013596 loss_att 6.965475 loss_ctc 5.913996 loss_rnnt 3.046765 hw_loss 0.230752 lr 0.00028466 rank 4
2023-03-01 14:52:19,566 DEBUG TRAIN Batch 57/7700 loss 3.077709 loss_att 6.606895 loss_ctc 10.916195 loss_rnnt 1.191773 hw_loss 0.253065 lr 0.00028465 rank 4
2023-03-01 14:52:19,580 DEBUG TRAIN Batch 57/7700 loss 3.920117 loss_att 7.272058 loss_ctc 6.343202 loss_rnnt 2.887666 hw_loss 0.073096 lr 0.00028466 rank 0
2023-03-01 14:52:19,581 DEBUG TRAIN Batch 57/7700 loss 7.628494 loss_att 10.358961 loss_ctc 9.954177 loss_rnnt 6.683806 hw_loss 0.165943 lr 0.00028465 rank 7
2023-03-01 14:52:19,581 DEBUG TRAIN Batch 57/7700 loss 5.714504 loss_att 7.881244 loss_ctc 10.811309 loss_rnnt 4.538064 hw_loss 0.119096 lr 0.00028465 rank 2
2023-03-01 14:52:19,582 DEBUG TRAIN Batch 57/7700 loss 7.087303 loss_att 10.921181 loss_ctc 11.665977 loss_rnnt 5.593935 hw_loss 0.217693 lr 0.00028465 rank 3
2023-03-01 14:52:19,584 DEBUG TRAIN Batch 57/7700 loss 9.493974 loss_att 10.509008 loss_ctc 14.431727 loss_rnnt 8.510920 hw_loss 0.228151 lr 0.00028466 rank 5
2023-03-01 14:52:19,584 DEBUG TRAIN Batch 57/7700 loss 11.624229 loss_att 12.113586 loss_ctc 18.845718 loss_rnnt 10.385267 hw_loss 0.334172 lr 0.00028465 rank 1
2023-03-01 14:52:19,612 DEBUG TRAIN Batch 57/7700 loss 5.380523 loss_att 9.408245 loss_ctc 10.111862 loss_rnnt 3.899894 hw_loss 0.082949 lr 0.00028466 rank 6
2023-03-01 14:52:59,513 DEBUG TRAIN Batch 57/7800 loss 1.092216 loss_att 3.092946 loss_ctc 2.374958 loss_rnnt 0.458545 hw_loss 0.117175 lr 0.00028464 rank 1
2023-03-01 14:52:59,513 DEBUG TRAIN Batch 57/7800 loss 1.993424 loss_att 4.196786 loss_ctc 2.847570 loss_rnnt 1.339902 hw_loss 0.185555 lr 0.00028464 rank 3
2023-03-01 14:52:59,516 DEBUG TRAIN Batch 57/7800 loss 4.968100 loss_att 6.808523 loss_ctc 5.258380 loss_rnnt 4.372123 hw_loss 0.354727 lr 0.00028464 rank 7
2023-03-01 14:52:59,515 DEBUG TRAIN Batch 57/7800 loss 9.112562 loss_att 10.650257 loss_ctc 13.019325 loss_rnnt 8.237564 hw_loss 0.087294 lr 0.00028465 rank 0
2023-03-01 14:52:59,527 DEBUG TRAIN Batch 57/7800 loss 4.221838 loss_att 6.290491 loss_ctc 8.016171 loss_rnnt 3.206812 hw_loss 0.178846 lr 0.00028465 rank 6
2023-03-01 14:52:59,538 DEBUG TRAIN Batch 57/7800 loss 2.039415 loss_att 4.917136 loss_ctc 4.245196 loss_rnnt 1.059981 hw_loss 0.205848 lr 0.00028464 rank 2
2023-03-01 14:52:59,543 DEBUG TRAIN Batch 57/7800 loss 2.545350 loss_att 5.692187 loss_ctc 5.566524 loss_rnnt 1.308037 hw_loss 0.384605 lr 0.00028464 rank 4
2023-03-01 14:52:59,544 DEBUG TRAIN Batch 57/7800 loss 2.523200 loss_att 6.602246 loss_ctc 8.442447 loss_rnnt 0.853736 hw_loss 0.120791 lr 0.00028464 rank 5
2023-03-01 14:54:08,470 DEBUG TRAIN Batch 57/7900 loss 2.855094 loss_att 6.354245 loss_ctc 4.010250 loss_rnnt 1.866215 hw_loss 0.253177 lr 0.00028464 rank 0
2023-03-01 14:54:08,470 DEBUG TRAIN Batch 57/7900 loss 2.613786 loss_att 4.343714 loss_ctc 2.154419 loss_rnnt 2.167457 hw_loss 0.302985 lr 0.00028463 rank 7
2023-03-01 14:54:08,473 DEBUG TRAIN Batch 57/7900 loss 5.969554 loss_att 8.604694 loss_ctc 9.034541 loss_rnnt 4.934368 hw_loss 0.186549 lr 0.00028464 rank 6
2023-03-01 14:54:08,477 DEBUG TRAIN Batch 57/7900 loss 6.591404 loss_att 10.130284 loss_ctc 8.486904 loss_rnnt 5.571727 hw_loss 0.110940 lr 0.00028463 rank 4
2023-03-01 14:54:08,477 DEBUG TRAIN Batch 57/7900 loss 2.904439 loss_att 4.966159 loss_ctc 8.576433 loss_rnnt 1.661139 hw_loss 0.140042 lr 0.00028463 rank 2
2023-03-01 14:54:08,494 DEBUG TRAIN Batch 57/7900 loss 5.216585 loss_att 8.280277 loss_ctc 10.863910 loss_rnnt 3.712987 hw_loss 0.258531 lr 0.00028462 rank 1
2023-03-01 14:54:08,496 DEBUG TRAIN Batch 57/7900 loss 9.082805 loss_att 12.760399 loss_ctc 15.158377 loss_rnnt 7.385595 hw_loss 0.284279 lr 0.00028463 rank 3
2023-03-01 14:54:08,520 DEBUG TRAIN Batch 57/7900 loss 7.084433 loss_att 11.541152 loss_ctc 18.677742 loss_rnnt 4.511781 hw_loss 0.254125 lr 0.00028463 rank 5
2023-03-01 14:54:47,381 DEBUG TRAIN Batch 57/8000 loss 6.222830 loss_att 10.105795 loss_ctc 17.042999 loss_rnnt 3.879851 hw_loss 0.231933 lr 0.00028462 rank 3
2023-03-01 14:54:47,386 DEBUG TRAIN Batch 57/8000 loss 7.878507 loss_att 11.039104 loss_ctc 12.555841 loss_rnnt 6.503242 hw_loss 0.224064 lr 0.00028462 rank 2
2023-03-01 14:54:47,389 DEBUG TRAIN Batch 57/8000 loss 8.723773 loss_att 11.955060 loss_ctc 13.167864 loss_rnnt 7.368724 hw_loss 0.217962 lr 0.00028462 rank 5
2023-03-01 14:54:47,395 DEBUG TRAIN Batch 57/8000 loss 4.552877 loss_att 7.271939 loss_ctc 5.178085 loss_rnnt 3.765053 hw_loss 0.301221 lr 0.00028463 rank 0
2023-03-01 14:54:47,395 DEBUG TRAIN Batch 57/8000 loss 11.297140 loss_att 14.195340 loss_ctc 19.097418 loss_rnnt 9.576875 hw_loss 0.188603 lr 0.00028463 rank 6
2023-03-01 14:54:47,398 DEBUG TRAIN Batch 57/8000 loss 7.292697 loss_att 8.788740 loss_ctc 9.822220 loss_rnnt 6.540753 hw_loss 0.216495 lr 0.00028461 rank 1
2023-03-01 14:54:47,401 DEBUG TRAIN Batch 57/8000 loss 8.168519 loss_att 11.104048 loss_ctc 16.423008 loss_rnnt 6.390523 hw_loss 0.169295 lr 0.00028462 rank 7
2023-03-01 14:54:47,404 DEBUG TRAIN Batch 57/8000 loss 5.846522 loss_att 10.635565 loss_ctc 12.285457 loss_rnnt 3.926160 hw_loss 0.195054 lr 0.00028462 rank 4
2023-03-01 14:55:26,529 DEBUG TRAIN Batch 57/8100 loss 6.453272 loss_att 9.259753 loss_ctc 10.928111 loss_rnnt 5.160835 hw_loss 0.252177 lr 0.00028461 rank 6
2023-03-01 14:55:26,541 DEBUG TRAIN Batch 57/8100 loss 5.927981 loss_att 9.510931 loss_ctc 10.530855 loss_rnnt 4.516378 hw_loss 0.152430 lr 0.00028461 rank 3
2023-03-01 14:55:26,541 DEBUG TRAIN Batch 57/8100 loss 7.197038 loss_att 11.325525 loss_ctc 13.909681 loss_rnnt 5.342084 hw_loss 0.251694 lr 0.00028461 rank 2
2023-03-01 14:55:26,541 DEBUG TRAIN Batch 57/8100 loss 2.571180 loss_att 5.961319 loss_ctc 4.890334 loss_rnnt 1.505908 hw_loss 0.146294 lr 0.00028460 rank 1
2023-03-01 14:55:26,547 DEBUG TRAIN Batch 57/8100 loss 5.174598 loss_att 8.784735 loss_ctc 9.156324 loss_rnnt 3.832397 hw_loss 0.167393 lr 0.00028461 rank 7
2023-03-01 14:55:26,548 DEBUG TRAIN Batch 57/8100 loss 2.194913 loss_att 5.356351 loss_ctc 4.608088 loss_rnnt 1.132303 hw_loss 0.203562 lr 0.00028462 rank 0
2023-03-01 14:55:26,566 DEBUG TRAIN Batch 57/8100 loss 6.121295 loss_att 9.412028 loss_ctc 14.353483 loss_rnnt 4.302798 hw_loss 0.117609 lr 0.00028461 rank 5
2023-03-01 14:55:26,596 DEBUG TRAIN Batch 57/8100 loss 5.086799 loss_att 7.799274 loss_ctc 8.356164 loss_rnnt 3.953575 hw_loss 0.290274 lr 0.00028460 rank 4
2023-03-01 14:56:06,927 DEBUG TRAIN Batch 57/8200 loss 10.785136 loss_att 14.401620 loss_ctc 19.820362 loss_rnnt 8.767432 hw_loss 0.168208 lr 0.00028459 rank 1
2023-03-01 14:56:06,927 DEBUG TRAIN Batch 57/8200 loss 3.612345 loss_att 4.737118 loss_ctc 6.710359 loss_rnnt 2.836102 hw_loss 0.259161 lr 0.00028460 rank 6
2023-03-01 14:56:06,940 DEBUG TRAIN Batch 57/8200 loss 5.333688 loss_att 8.565216 loss_ctc 11.936589 loss_rnnt 3.666557 hw_loss 0.263321 lr 0.00028460 rank 0
2023-03-01 14:56:06,944 DEBUG TRAIN Batch 57/8200 loss 8.047169 loss_att 10.701522 loss_ctc 14.537120 loss_rnnt 6.559973 hw_loss 0.170621 lr 0.00028459 rank 4
2023-03-01 14:56:06,945 DEBUG TRAIN Batch 57/8200 loss 9.320590 loss_att 9.550702 loss_ctc 11.562385 loss_rnnt 8.788096 hw_loss 0.351685 lr 0.00028459 rank 7
2023-03-01 14:56:06,947 DEBUG TRAIN Batch 57/8200 loss 3.174323 loss_att 6.279608 loss_ctc 6.163448 loss_rnnt 1.988032 hw_loss 0.312531 lr 0.00028460 rank 5
2023-03-01 14:56:06,952 DEBUG TRAIN Batch 57/8200 loss 7.430939 loss_att 10.007402 loss_ctc 10.562387 loss_rnnt 6.365310 hw_loss 0.249017 lr 0.00028459 rank 3
2023-03-01 14:56:06,991 DEBUG TRAIN Batch 57/8200 loss 3.107274 loss_att 6.362894 loss_ctc 6.172755 loss_rnnt 1.982402 hw_loss 0.121905 lr 0.00028459 rank 2
2023-03-01 14:56:45,418 DEBUG TRAIN Batch 57/8300 loss 3.027753 loss_att 5.924379 loss_ctc 7.074891 loss_rnnt 1.813768 hw_loss 0.178202 lr 0.00028458 rank 2
2023-03-01 14:56:45,419 DEBUG TRAIN Batch 57/8300 loss 7.410266 loss_att 10.315158 loss_ctc 13.191286 loss_rnnt 6.017117 hw_loss 0.077566 lr 0.00028458 rank 1
2023-03-01 14:56:45,420 DEBUG TRAIN Batch 57/8300 loss 10.232481 loss_att 11.521021 loss_ctc 13.621260 loss_rnnt 9.446842 hw_loss 0.142674 lr 0.00028458 rank 4
2023-03-01 14:56:45,428 DEBUG TRAIN Batch 57/8300 loss 4.751762 loss_att 6.271284 loss_ctc 7.923120 loss_rnnt 3.895195 hw_loss 0.243404 lr 0.00028458 rank 3
2023-03-01 14:56:45,438 DEBUG TRAIN Batch 57/8300 loss 7.041504 loss_att 11.562331 loss_ctc 11.962234 loss_rnnt 5.337481 hw_loss 0.269551 lr 0.00028458 rank 7
2023-03-01 14:56:45,441 DEBUG TRAIN Batch 57/8300 loss 3.663525 loss_att 5.036085 loss_ctc 7.854873 loss_rnnt 2.691931 hw_loss 0.259193 lr 0.00028459 rank 0
2023-03-01 14:56:45,441 DEBUG TRAIN Batch 57/8300 loss 5.572621 loss_att 7.870482 loss_ctc 6.879619 loss_rnnt 4.836810 hw_loss 0.191197 lr 0.00028459 rank 5
2023-03-01 14:56:45,447 DEBUG TRAIN Batch 57/8300 loss 5.372876 loss_att 8.409607 loss_ctc 6.985682 loss_rnnt 4.452338 hw_loss 0.184033 lr 0.00028459 rank 6
2023-03-01 14:57:10,126 DEBUG CV Batch 57/0 loss 0.795830 loss_att 0.786646 loss_ctc 1.319619 loss_rnnt 0.506492 hw_loss 0.415004 history loss 0.766354 rank 7
2023-03-01 14:57:10,189 DEBUG CV Batch 57/0 loss 0.795830 loss_att 0.786646 loss_ctc 1.319619 loss_rnnt 0.506492 hw_loss 0.415004 history loss 0.766354 rank 5
2023-03-01 14:57:10,197 DEBUG CV Batch 57/0 loss 0.795830 loss_att 0.786646 loss_ctc 1.319619 loss_rnnt 0.506492 hw_loss 0.415004 history loss 0.766354 rank 1
2023-03-01 14:57:10,232 DEBUG CV Batch 57/0 loss 0.795830 loss_att 0.786646 loss_ctc 1.319619 loss_rnnt 0.506492 hw_loss 0.415004 history loss 0.766354 rank 0
2023-03-01 14:57:10,238 DEBUG CV Batch 57/0 loss 0.795830 loss_att 0.786646 loss_ctc 1.319619 loss_rnnt 0.506492 hw_loss 0.415004 history loss 0.766354 rank 6
2023-03-01 14:57:10,249 DEBUG CV Batch 57/0 loss 0.795830 loss_att 0.786646 loss_ctc 1.319619 loss_rnnt 0.506492 hw_loss 0.415004 history loss 0.766354 rank 3
2023-03-01 14:57:10,356 DEBUG CV Batch 57/0 loss 0.795830 loss_att 0.786646 loss_ctc 1.319619 loss_rnnt 0.506492 hw_loss 0.415004 history loss 0.766354 rank 4
2023-03-01 14:57:10,449 DEBUG CV Batch 57/0 loss 0.795830 loss_att 0.786646 loss_ctc 1.319619 loss_rnnt 0.506492 hw_loss 0.415004 history loss 0.766354 rank 2
2023-03-01 14:57:21,559 DEBUG CV Batch 57/100 loss 3.510157 loss_att 4.380694 loss_ctc 9.588514 loss_rnnt 2.396052 hw_loss 0.242906 history loss 3.064342 rank 1
2023-03-01 14:57:21,654 DEBUG CV Batch 57/100 loss 3.510157 loss_att 4.380694 loss_ctc 9.588514 loss_rnnt 2.396052 hw_loss 0.242906 history loss 3.064342 rank 4
2023-03-01 14:57:21,683 DEBUG CV Batch 57/100 loss 3.510157 loss_att 4.380694 loss_ctc 9.588514 loss_rnnt 2.396052 hw_loss 0.242906 history loss 3.064342 rank 6
2023-03-01 14:57:21,819 DEBUG CV Batch 57/100 loss 3.510157 loss_att 4.380694 loss_ctc 9.588514 loss_rnnt 2.396052 hw_loss 0.242906 history loss 3.064342 rank 5
2023-03-01 14:57:21,845 DEBUG CV Batch 57/100 loss 3.510157 loss_att 4.380694 loss_ctc 9.588514 loss_rnnt 2.396052 hw_loss 0.242906 history loss 3.064342 rank 3
2023-03-01 14:57:21,968 DEBUG CV Batch 57/100 loss 3.510157 loss_att 4.380694 loss_ctc 9.588514 loss_rnnt 2.396052 hw_loss 0.242906 history loss 3.064342 rank 7
2023-03-01 14:57:22,036 DEBUG CV Batch 57/100 loss 3.510157 loss_att 4.380694 loss_ctc 9.588514 loss_rnnt 2.396052 hw_loss 0.242906 history loss 3.064342 rank 2
2023-03-01 14:57:22,297 DEBUG CV Batch 57/100 loss 3.510157 loss_att 4.380694 loss_ctc 9.588514 loss_rnnt 2.396052 hw_loss 0.242906 history loss 3.064342 rank 0
2023-03-01 14:57:35,211 DEBUG CV Batch 57/200 loss 5.547732 loss_att 9.588552 loss_ctc 7.091858 loss_rnnt 4.434165 hw_loss 0.186599 history loss 3.673234 rank 1
2023-03-01 14:57:35,401 DEBUG CV Batch 57/200 loss 5.547732 loss_att 9.588552 loss_ctc 7.091858 loss_rnnt 4.434165 hw_loss 0.186599 history loss 3.673234 rank 6
2023-03-01 14:57:35,492 DEBUG CV Batch 57/200 loss 5.547732 loss_att 9.588552 loss_ctc 7.091858 loss_rnnt 4.434165 hw_loss 0.186599 history loss 3.673234 rank 4
2023-03-01 14:57:35,659 DEBUG CV Batch 57/200 loss 5.547732 loss_att 9.588552 loss_ctc 7.091858 loss_rnnt 4.434165 hw_loss 0.186599 history loss 3.673234 rank 3
2023-03-01 14:57:35,814 DEBUG CV Batch 57/200 loss 5.547732 loss_att 9.588552 loss_ctc 7.091858 loss_rnnt 4.434165 hw_loss 0.186599 history loss 3.673234 rank 2
2023-03-01 14:57:35,826 DEBUG CV Batch 57/200 loss 5.547732 loss_att 9.588552 loss_ctc 7.091858 loss_rnnt 4.434165 hw_loss 0.186599 history loss 3.673234 rank 5
2023-03-01 14:57:35,897 DEBUG CV Batch 57/200 loss 5.547732 loss_att 9.588552 loss_ctc 7.091858 loss_rnnt 4.434165 hw_loss 0.186599 history loss 3.673234 rank 7
2023-03-01 14:57:36,432 DEBUG CV Batch 57/200 loss 5.547732 loss_att 9.588552 loss_ctc 7.091858 loss_rnnt 4.434165 hw_loss 0.186599 history loss 3.673234 rank 0
2023-03-01 14:57:47,368 DEBUG CV Batch 57/300 loss 5.361396 loss_att 5.794659 loss_ctc 9.168390 loss_rnnt 4.620372 hw_loss 0.275198 history loss 3.809824 rank 1
2023-03-01 14:57:47,446 DEBUG CV Batch 57/300 loss 5.361395 loss_att 5.794659 loss_ctc 9.168390 loss_rnnt 4.620372 hw_loss 0.275198 history loss 3.809824 rank 4
2023-03-01 14:57:47,481 DEBUG CV Batch 57/300 loss 5.361396 loss_att 5.794659 loss_ctc 9.168390 loss_rnnt 4.620372 hw_loss 0.275198 history loss 3.809824 rank 6
2023-03-01 14:57:47,733 DEBUG CV Batch 57/300 loss 5.361395 loss_att 5.794659 loss_ctc 9.168390 loss_rnnt 4.620372 hw_loss 0.275198 history loss 3.809824 rank 3
2023-03-01 14:57:47,743 DEBUG CV Batch 57/300 loss 5.361395 loss_att 5.794659 loss_ctc 9.168390 loss_rnnt 4.620372 hw_loss 0.275198 history loss 3.809824 rank 5
2023-03-01 14:57:47,957 DEBUG CV Batch 57/300 loss 5.361395 loss_att 5.794659 loss_ctc 9.168390 loss_rnnt 4.620372 hw_loss 0.275198 history loss 3.809824 rank 2
2023-03-01 14:57:48,451 DEBUG CV Batch 57/300 loss 5.361395 loss_att 5.794659 loss_ctc 9.168390 loss_rnnt 4.620372 hw_loss 0.275198 history loss 3.809824 rank 7
2023-03-01 14:57:49,499 DEBUG CV Batch 57/300 loss 5.361396 loss_att 5.794659 loss_ctc 9.168390 loss_rnnt 4.620372 hw_loss 0.275198 history loss 3.809824 rank 0
2023-03-01 14:57:59,486 DEBUG CV Batch 57/400 loss 20.303841 loss_att 72.461105 loss_ctc 12.663500 loss_rnnt 10.798736 hw_loss 0.173181 history loss 4.603125 rank 1
2023-03-01 14:57:59,687 DEBUG CV Batch 57/400 loss 20.303841 loss_att 72.461105 loss_ctc 12.663500 loss_rnnt 10.798736 hw_loss 0.173181 history loss 4.603125 rank 6
2023-03-01 14:57:59,821 DEBUG CV Batch 57/400 loss 20.303841 loss_att 72.461105 loss_ctc 12.663500 loss_rnnt 10.798736 hw_loss 0.173181 history loss 4.603125 rank 4
2023-03-01 14:57:59,893 DEBUG CV Batch 57/400 loss 20.303841 loss_att 72.461105 loss_ctc 12.663500 loss_rnnt 10.798736 hw_loss 0.173181 history loss 4.603125 rank 3
2023-03-01 14:57:59,947 DEBUG CV Batch 57/400 loss 20.303841 loss_att 72.461105 loss_ctc 12.663500 loss_rnnt 10.798736 hw_loss 0.173181 history loss 4.603125 rank 5
2023-03-01 14:58:00,314 DEBUG CV Batch 57/400 loss 20.303841 loss_att 72.461105 loss_ctc 12.663500 loss_rnnt 10.798736 hw_loss 0.173181 history loss 4.603125 rank 2
2023-03-01 14:58:01,189 DEBUG CV Batch 57/400 loss 20.303841 loss_att 72.461105 loss_ctc 12.663500 loss_rnnt 10.798736 hw_loss 0.173181 history loss 4.603125 rank 7
2023-03-01 14:58:02,424 DEBUG CV Batch 57/400 loss 20.303841 loss_att 72.461105 loss_ctc 12.663500 loss_rnnt 10.798736 hw_loss 0.173181 history loss 4.603125 rank 0
2023-03-01 14:58:09,830 DEBUG CV Batch 57/500 loss 2.347413 loss_att 3.194673 loss_ctc 2.987486 loss_rnnt 1.978652 hw_loss 0.213685 history loss 5.194629 rank 1
2023-03-01 14:58:10,090 DEBUG CV Batch 57/500 loss 2.347413 loss_att 3.194673 loss_ctc 2.987486 loss_rnnt 1.978652 hw_loss 0.213685 history loss 5.194629 rank 4
2023-03-01 14:58:10,233 DEBUG CV Batch 57/500 loss 2.347413 loss_att 3.194673 loss_ctc 2.987486 loss_rnnt 1.978652 hw_loss 0.213685 history loss 5.194629 rank 6
2023-03-01 14:58:10,304 DEBUG CV Batch 57/500 loss 2.347413 loss_att 3.194673 loss_ctc 2.987486 loss_rnnt 1.978652 hw_loss 0.213685 history loss 5.194629 rank 5
2023-03-01 14:58:10,814 DEBUG CV Batch 57/500 loss 2.347413 loss_att 3.194673 loss_ctc 2.987486 loss_rnnt 1.978652 hw_loss 0.213685 history loss 5.194629 rank 2
2023-03-01 14:58:10,839 DEBUG CV Batch 57/500 loss 2.347413 loss_att 3.194673 loss_ctc 2.987486 loss_rnnt 1.978652 hw_loss 0.213685 history loss 5.194629 rank 3
2023-03-01 14:58:12,273 DEBUG CV Batch 57/500 loss 2.347413 loss_att 3.194673 loss_ctc 2.987486 loss_rnnt 1.978652 hw_loss 0.213685 history loss 5.194629 rank 7
2023-03-01 14:58:13,835 DEBUG CV Batch 57/500 loss 2.347413 loss_att 3.194673 loss_ctc 2.987486 loss_rnnt 1.978652 hw_loss 0.213685 history loss 5.194629 rank 0
2023-03-01 14:58:21,839 DEBUG CV Batch 57/600 loss 6.868559 loss_att 6.461038 loss_ctc 9.282007 loss_rnnt 6.416992 hw_loss 0.396147 history loss 6.047659 rank 1
2023-03-01 14:58:22,018 DEBUG CV Batch 57/600 loss 6.868559 loss_att 6.461038 loss_ctc 9.282007 loss_rnnt 6.416992 hw_loss 0.396147 history loss 6.047659 rank 4
2023-03-01 14:58:22,423 DEBUG CV Batch 57/600 loss 6.868559 loss_att 6.461038 loss_ctc 9.282007 loss_rnnt 6.416992 hw_loss 0.396147 history loss 6.047659 rank 6
2023-03-01 14:58:22,463 DEBUG CV Batch 57/600 loss 6.868559 loss_att 6.461038 loss_ctc 9.282007 loss_rnnt 6.416992 hw_loss 0.396147 history loss 6.047659 rank 5
2023-03-01 14:58:23,243 DEBUG CV Batch 57/600 loss 6.868559 loss_att 6.461038 loss_ctc 9.282007 loss_rnnt 6.416992 hw_loss 0.396147 history loss 6.047659 rank 3
2023-03-01 14:58:23,355 DEBUG CV Batch 57/600 loss 6.868559 loss_att 6.461038 loss_ctc 9.282007 loss_rnnt 6.416992 hw_loss 0.396147 history loss 6.047659 rank 2
2023-03-01 14:58:24,858 DEBUG CV Batch 57/600 loss 6.868559 loss_att 6.461038 loss_ctc 9.282007 loss_rnnt 6.416992 hw_loss 0.396147 history loss 6.047659 rank 7
2023-03-01 14:58:26,786 DEBUG CV Batch 57/600 loss 6.868559 loss_att 6.461038 loss_ctc 9.282007 loss_rnnt 6.416992 hw_loss 0.396147 history loss 6.047659 rank 0
2023-03-01 14:58:33,132 DEBUG CV Batch 57/700 loss 13.116344 loss_att 32.229340 loss_ctc 17.873230 loss_rnnt 8.491936 hw_loss 0.314170 history loss 6.579025 rank 1
2023-03-01 14:58:33,170 DEBUG CV Batch 57/700 loss 13.116344 loss_att 32.229340 loss_ctc 17.873230 loss_rnnt 8.491936 hw_loss 0.314170 history loss 6.579025 rank 4
2023-03-01 14:58:34,002 DEBUG CV Batch 57/700 loss 13.116344 loss_att 32.229340 loss_ctc 17.873230 loss_rnnt 8.491936 hw_loss 0.314170 history loss 6.579025 rank 5
2023-03-01 14:58:34,145 DEBUG CV Batch 57/700 loss 13.116344 loss_att 32.229340 loss_ctc 17.873230 loss_rnnt 8.491936 hw_loss 0.314170 history loss 6.579025 rank 6
2023-03-01 14:58:34,793 DEBUG CV Batch 57/700 loss 13.116344 loss_att 32.229340 loss_ctc 17.873230 loss_rnnt 8.491936 hw_loss 0.314170 history loss 6.579025 rank 3
2023-03-01 14:58:34,877 DEBUG CV Batch 57/700 loss 13.116344 loss_att 32.229340 loss_ctc 17.873230 loss_rnnt 8.491936 hw_loss 0.314170 history loss 6.579025 rank 2
2023-03-01 14:58:36,870 DEBUG CV Batch 57/700 loss 13.116344 loss_att 32.229340 loss_ctc 17.873230 loss_rnnt 8.491936 hw_loss 0.314170 history loss 6.579025 rank 7
2023-03-01 14:58:38,884 DEBUG CV Batch 57/700 loss 13.116344 loss_att 32.229340 loss_ctc 17.873230 loss_rnnt 8.491936 hw_loss 0.314170 history loss 6.579025 rank 0
2023-03-01 14:58:44,083 DEBUG CV Batch 57/800 loss 6.608456 loss_att 7.096551 loss_ctc 14.343803 loss_rnnt 5.368948 hw_loss 0.207205 history loss 6.103595 rank 1
2023-03-01 14:58:44,508 DEBUG CV Batch 57/800 loss 6.608456 loss_att 7.096551 loss_ctc 14.343803 loss_rnnt 5.368948 hw_loss 0.207205 history loss 6.103595 rank 4
2023-03-01 14:58:45,026 DEBUG CV Batch 57/800 loss 6.608456 loss_att 7.096551 loss_ctc 14.343803 loss_rnnt 5.368948 hw_loss 0.207205 history loss 6.103595 rank 5
2023-03-01 14:58:45,498 DEBUG CV Batch 57/800 loss 6.608456 loss_att 7.096551 loss_ctc 14.343803 loss_rnnt 5.368948 hw_loss 0.207205 history loss 6.103595 rank 6
2023-03-01 14:58:45,912 DEBUG CV Batch 57/800 loss 6.608456 loss_att 7.096551 loss_ctc 14.343803 loss_rnnt 5.368948 hw_loss 0.207205 history loss 6.103595 rank 3
2023-03-01 14:58:45,967 DEBUG CV Batch 57/800 loss 6.608456 loss_att 7.096551 loss_ctc 14.343803 loss_rnnt 5.368948 hw_loss 0.207205 history loss 6.103595 rank 2
2023-03-01 14:58:48,673 DEBUG CV Batch 57/800 loss 6.608456 loss_att 7.096551 loss_ctc 14.343803 loss_rnnt 5.368948 hw_loss 0.207205 history loss 6.103595 rank 7
2023-03-01 14:58:50,906 DEBUG CV Batch 57/800 loss 6.608456 loss_att 7.096551 loss_ctc 14.343803 loss_rnnt 5.368948 hw_loss 0.207205 history loss 6.103595 rank 0
2023-03-01 14:58:57,258 DEBUG CV Batch 57/900 loss 9.120558 loss_att 10.399364 loss_ctc 16.872311 loss_rnnt 7.723872 hw_loss 0.201294 history loss 5.943391 rank 1
2023-03-01 14:58:57,789 DEBUG CV Batch 57/900 loss 9.120558 loss_att 10.399364 loss_ctc 16.872311 loss_rnnt 7.723872 hw_loss 0.201294 history loss 5.943391 rank 4
2023-03-01 14:58:58,301 DEBUG CV Batch 57/900 loss 9.120558 loss_att 10.399364 loss_ctc 16.872311 loss_rnnt 7.723872 hw_loss 0.201294 history loss 5.943391 rank 5
2023-03-01 14:58:59,169 DEBUG CV Batch 57/900 loss 9.120558 loss_att 10.399364 loss_ctc 16.872311 loss_rnnt 7.723872 hw_loss 0.201294 history loss 5.943391 rank 6
2023-03-01 14:58:59,447 DEBUG CV Batch 57/900 loss 9.120558 loss_att 10.399364 loss_ctc 16.872311 loss_rnnt 7.723872 hw_loss 0.201294 history loss 5.943391 rank 3
2023-03-01 14:58:59,499 DEBUG CV Batch 57/900 loss 9.120558 loss_att 10.399364 loss_ctc 16.872311 loss_rnnt 7.723872 hw_loss 0.201294 history loss 5.943391 rank 2
2023-03-01 14:59:02,558 DEBUG CV Batch 57/900 loss 9.120558 loss_att 10.399364 loss_ctc 16.872311 loss_rnnt 7.723872 hw_loss 0.201294 history loss 5.943391 rank 7
2023-03-01 14:59:05,021 DEBUG CV Batch 57/900 loss 9.120558 loss_att 10.399364 loss_ctc 16.872311 loss_rnnt 7.723872 hw_loss 0.201294 history loss 5.943391 rank 0
2023-03-01 14:59:09,218 DEBUG CV Batch 57/1000 loss 3.690346 loss_att 3.765798 loss_ctc 4.470558 loss_rnnt 3.426138 hw_loss 0.272044 history loss 5.754796 rank 1
2023-03-01 14:59:09,770 DEBUG CV Batch 57/1000 loss 3.690346 loss_att 3.765798 loss_ctc 4.470558 loss_rnnt 3.426138 hw_loss 0.272044 history loss 5.754796 rank 4
2023-03-01 14:59:10,655 DEBUG CV Batch 57/1000 loss 3.690346 loss_att 3.765798 loss_ctc 4.470558 loss_rnnt 3.426138 hw_loss 0.272044 history loss 5.754796 rank 5
2023-03-01 14:59:11,865 DEBUG CV Batch 57/1000 loss 3.690346 loss_att 3.765798 loss_ctc 4.470558 loss_rnnt 3.426138 hw_loss 0.272044 history loss 5.754796 rank 3
2023-03-01 14:59:12,085 DEBUG CV Batch 57/1000 loss 3.690346 loss_att 3.765798 loss_ctc 4.470558 loss_rnnt 3.426138 hw_loss 0.272044 history loss 5.754796 rank 2
2023-03-01 14:59:12,141 DEBUG CV Batch 57/1000 loss 3.690346 loss_att 3.765798 loss_ctc 4.470558 loss_rnnt 3.426138 hw_loss 0.272044 history loss 5.754796 rank 6
2023-03-01 14:59:15,655 DEBUG CV Batch 57/1000 loss 3.690346 loss_att 3.765798 loss_ctc 4.470558 loss_rnnt 3.426138 hw_loss 0.272044 history loss 5.754796 rank 7
2023-03-01 14:59:18,117 DEBUG CV Batch 57/1000 loss 3.690346 loss_att 3.765798 loss_ctc 4.470558 loss_rnnt 3.426138 hw_loss 0.272044 history loss 5.754796 rank 0
2023-03-01 14:59:21,203 DEBUG CV Batch 57/1100 loss 4.507714 loss_att 4.401326 loss_ctc 7.689804 loss_rnnt 3.899304 hw_loss 0.385141 history loss 5.717837 rank 1
2023-03-01 14:59:21,588 DEBUG CV Batch 57/1100 loss 4.507714 loss_att 4.401326 loss_ctc 7.689804 loss_rnnt 3.899304 hw_loss 0.385141 history loss 5.717837 rank 4
2023-03-01 14:59:23,015 DEBUG CV Batch 57/1100 loss 4.507714 loss_att 4.401326 loss_ctc 7.689804 loss_rnnt 3.899304 hw_loss 0.385141 history loss 5.717837 rank 5
2023-03-01 14:59:24,170 DEBUG CV Batch 57/1100 loss 4.507714 loss_att 4.401326 loss_ctc 7.689804 loss_rnnt 3.899304 hw_loss 0.385141 history loss 5.717837 rank 3
2023-03-01 14:59:24,201 DEBUG CV Batch 57/1100 loss 4.507714 loss_att 4.401326 loss_ctc 7.689804 loss_rnnt 3.899304 hw_loss 0.385141 history loss 5.717837 rank 2
2023-03-01 14:59:24,692 DEBUG CV Batch 57/1100 loss 4.507714 loss_att 4.401326 loss_ctc 7.689804 loss_rnnt 3.899304 hw_loss 0.385141 history loss 5.717837 rank 6
2023-03-01 14:59:28,292 DEBUG CV Batch 57/1100 loss 4.507714 loss_att 4.401326 loss_ctc 7.689804 loss_rnnt 3.899304 hw_loss 0.385141 history loss 5.717837 rank 7
2023-03-01 14:59:30,822 DEBUG CV Batch 57/1100 loss 4.507714 loss_att 4.401326 loss_ctc 7.689804 loss_rnnt 3.899304 hw_loss 0.385141 history loss 5.717837 rank 0
2023-03-01 14:59:31,519 DEBUG CV Batch 57/1200 loss 5.831134 loss_att 5.962026 loss_ctc 6.596328 loss_rnnt 5.505536 hw_loss 0.370114 history loss 5.984498 rank 1
2023-03-01 14:59:31,884 DEBUG CV Batch 57/1200 loss 5.831134 loss_att 5.962026 loss_ctc 6.596328 loss_rnnt 5.505536 hw_loss 0.370114 history loss 5.984498 rank 4
2023-03-01 14:59:33,865 DEBUG CV Batch 57/1200 loss 5.831134 loss_att 5.962026 loss_ctc 6.596328 loss_rnnt 5.505536 hw_loss 0.370114 history loss 5.984498 rank 5
2023-03-01 14:59:34,906 DEBUG CV Batch 57/1200 loss 5.831134 loss_att 5.962026 loss_ctc 6.596328 loss_rnnt 5.505536 hw_loss 0.370114 history loss 5.984498 rank 3
2023-03-01 14:59:35,125 DEBUG CV Batch 57/1200 loss 5.831134 loss_att 5.962026 loss_ctc 6.596328 loss_rnnt 5.505536 hw_loss 0.370114 history loss 5.984498 rank 2
2023-03-01 14:59:35,828 DEBUG CV Batch 57/1200 loss 5.831134 loss_att 5.962026 loss_ctc 6.596328 loss_rnnt 5.505536 hw_loss 0.370114 history loss 5.984498 rank 6
2023-03-01 14:59:39,582 DEBUG CV Batch 57/1200 loss 5.831134 loss_att 5.962026 loss_ctc 6.596328 loss_rnnt 5.505536 hw_loss 0.370114 history loss 5.984498 rank 7
2023-03-01 14:59:42,181 DEBUG CV Batch 57/1200 loss 5.831134 loss_att 5.962026 loss_ctc 6.596328 loss_rnnt 5.505536 hw_loss 0.370114 history loss 5.984498 rank 0
2023-03-01 14:59:43,385 DEBUG CV Batch 57/1300 loss 4.971367 loss_att 4.629644 loss_ctc 7.760386 loss_rnnt 4.511166 hw_loss 0.293770 history loss 6.277945 rank 1
2023-03-01 14:59:43,763 DEBUG CV Batch 57/1300 loss 4.971367 loss_att 4.629644 loss_ctc 7.760386 loss_rnnt 4.511166 hw_loss 0.293770 history loss 6.277945 rank 4
2023-03-01 14:59:46,157 DEBUG CV Batch 57/1300 loss 4.971367 loss_att 4.629644 loss_ctc 7.760386 loss_rnnt 4.511166 hw_loss 0.293770 history loss 6.277945 rank 5
2023-03-01 14:59:47,133 DEBUG CV Batch 57/1300 loss 4.971367 loss_att 4.629644 loss_ctc 7.760386 loss_rnnt 4.511166 hw_loss 0.293770 history loss 6.277945 rank 3
2023-03-01 14:59:47,331 DEBUG CV Batch 57/1300 loss 4.971367 loss_att 4.629644 loss_ctc 7.760386 loss_rnnt 4.511166 hw_loss 0.293770 history loss 6.277945 rank 2
2023-03-01 14:59:48,125 DEBUG CV Batch 57/1300 loss 4.971367 loss_att 4.629644 loss_ctc 7.760386 loss_rnnt 4.511166 hw_loss 0.293770 history loss 6.277945 rank 6
2023-03-01 14:59:52,132 DEBUG CV Batch 57/1300 loss 4.971367 loss_att 4.629644 loss_ctc 7.760386 loss_rnnt 4.511166 hw_loss 0.293770 history loss 6.277945 rank 7
2023-03-01 14:59:54,418 DEBUG CV Batch 57/1400 loss 5.509965 loss_att 16.009518 loss_ctc 6.397533 loss_rnnt 3.239325 hw_loss 0.098227 history loss 6.543377 rank 1
2023-03-01 14:59:54,708 DEBUG CV Batch 57/1400 loss 5.509965 loss_att 16.009518 loss_ctc 6.397533 loss_rnnt 3.239325 hw_loss 0.098227 history loss 6.543377 rank 4
2023-03-01 14:59:55,032 DEBUG CV Batch 57/1300 loss 4.971367 loss_att 4.629644 loss_ctc 7.760386 loss_rnnt 4.511166 hw_loss 0.293770 history loss 6.277945 rank 0
2023-03-01 14:59:57,818 DEBUG CV Batch 57/1400 loss 5.509965 loss_att 16.009518 loss_ctc 6.397533 loss_rnnt 3.239325 hw_loss 0.098227 history loss 6.543377 rank 5
2023-03-01 14:59:58,710 DEBUG CV Batch 57/1400 loss 5.509965 loss_att 16.009518 loss_ctc 6.397533 loss_rnnt 3.239325 hw_loss 0.098227 history loss 6.543377 rank 3
2023-03-01 14:59:59,134 DEBUG CV Batch 57/1400 loss 5.509965 loss_att 16.009518 loss_ctc 6.397533 loss_rnnt 3.239325 hw_loss 0.098227 history loss 6.543377 rank 2
2023-03-01 14:59:59,909 DEBUG CV Batch 57/1400 loss 5.509965 loss_att 16.009518 loss_ctc 6.397533 loss_rnnt 3.239325 hw_loss 0.098227 history loss 6.543377 rank 6
2023-03-01 15:00:03,915 DEBUG CV Batch 57/1400 loss 5.509965 loss_att 16.009518 loss_ctc 6.397533 loss_rnnt 3.239325 hw_loss 0.098227 history loss 6.543377 rank 7
2023-03-01 15:00:05,499 DEBUG CV Batch 57/1500 loss 7.080775 loss_att 6.885871 loss_ctc 6.488027 loss_rnnt 7.112012 hw_loss 0.162705 history loss 6.406944 rank 1
2023-03-01 15:00:05,826 DEBUG CV Batch 57/1500 loss 7.080775 loss_att 6.885871 loss_ctc 6.488027 loss_rnnt 7.112012 hw_loss 0.162705 history loss 6.406944 rank 4
2023-03-01 15:00:06,998 DEBUG CV Batch 57/1400 loss 5.509965 loss_att 16.009518 loss_ctc 6.397533 loss_rnnt 3.239325 hw_loss 0.098227 history loss 6.543377 rank 0
2023-03-01 15:00:09,516 DEBUG CV Batch 57/1500 loss 7.080775 loss_att 6.885871 loss_ctc 6.488027 loss_rnnt 7.112012 hw_loss 0.162705 history loss 6.406944 rank 5
2023-03-01 15:00:10,210 DEBUG CV Batch 57/1500 loss 7.080775 loss_att 6.885871 loss_ctc 6.488027 loss_rnnt 7.112012 hw_loss 0.162705 history loss 6.406944 rank 3
2023-03-01 15:00:10,831 DEBUG CV Batch 57/1500 loss 7.080775 loss_att 6.885871 loss_ctc 6.488027 loss_rnnt 7.112012 hw_loss 0.162705 history loss 6.406944 rank 2
2023-03-01 15:00:12,122 DEBUG CV Batch 57/1500 loss 7.080775 loss_att 6.885871 loss_ctc 6.488027 loss_rnnt 7.112012 hw_loss 0.162705 history loss 6.406944 rank 6
2023-03-01 15:00:16,103 DEBUG CV Batch 57/1500 loss 7.080775 loss_att 6.885871 loss_ctc 6.488027 loss_rnnt 7.112012 hw_loss 0.162705 history loss 6.406944 rank 7
2023-03-01 15:00:18,537 DEBUG CV Batch 57/1600 loss 9.382636 loss_att 13.503521 loss_ctc 11.054837 loss_rnnt 8.233729 hw_loss 0.190818 history loss 6.377601 rank 1
2023-03-01 15:00:18,822 DEBUG CV Batch 57/1600 loss 9.382636 loss_att 13.503521 loss_ctc 11.054837 loss_rnnt 8.233729 hw_loss 0.190818 history loss 6.377601 rank 4
2023-03-01 15:00:19,318 DEBUG CV Batch 57/1500 loss 7.080775 loss_att 6.885871 loss_ctc 6.488027 loss_rnnt 7.112012 hw_loss 0.162705 history loss 6.406944 rank 0
2023-03-01 15:00:22,795 DEBUG CV Batch 57/1600 loss 9.382636 loss_att 13.503521 loss_ctc 11.054837 loss_rnnt 8.233729 hw_loss 0.190818 history loss 6.377601 rank 5
2023-03-01 15:00:23,596 DEBUG CV Batch 57/1600 loss 9.382636 loss_att 13.503521 loss_ctc 11.054837 loss_rnnt 8.233729 hw_loss 0.190818 history loss 6.377601 rank 3
2023-03-01 15:00:24,182 DEBUG CV Batch 57/1600 loss 9.382636 loss_att 13.503521 loss_ctc 11.054837 loss_rnnt 8.233729 hw_loss 0.190818 history loss 6.377601 rank 2
2023-03-01 15:00:25,792 DEBUG CV Batch 57/1600 loss 9.382636 loss_att 13.503521 loss_ctc 11.054837 loss_rnnt 8.233729 hw_loss 0.190818 history loss 6.377601 rank 6
2023-03-01 15:00:29,616 DEBUG CV Batch 57/1600 loss 9.382636 loss_att 13.503521 loss_ctc 11.054837 loss_rnnt 8.233729 hw_loss 0.190818 history loss 6.377601 rank 7
2023-03-01 15:00:31,040 DEBUG CV Batch 57/1700 loss 7.837623 loss_att 6.066475 loss_ctc 14.829080 loss_rnnt 7.087379 hw_loss 0.323024 history loss 6.315753 rank 1
2023-03-01 15:00:31,464 DEBUG CV Batch 57/1700 loss 7.837623 loss_att 6.066475 loss_ctc 14.829080 loss_rnnt 7.087379 hw_loss 0.323024 history loss 6.315753 rank 4
2023-03-01 15:00:32,964 DEBUG CV Batch 57/1600 loss 9.382636 loss_att 13.503521 loss_ctc 11.054837 loss_rnnt 8.233729 hw_loss 0.190818 history loss 6.377601 rank 0
2023-03-01 15:00:35,370 DEBUG CV Batch 57/1700 loss 7.837623 loss_att 6.066475 loss_ctc 14.829080 loss_rnnt 7.087379 hw_loss 0.323024 history loss 6.315753 rank 5
2023-03-01 15:00:36,477 DEBUG CV Batch 57/1700 loss 7.837623 loss_att 6.066475 loss_ctc 14.829080 loss_rnnt 7.087379 hw_loss 0.323024 history loss 6.315753 rank 3
2023-03-01 15:00:36,882 DEBUG CV Batch 57/1700 loss 7.837623 loss_att 6.066475 loss_ctc 14.829080 loss_rnnt 7.087379 hw_loss 0.323024 history loss 6.315753 rank 2
2023-03-01 15:00:38,824 DEBUG CV Batch 57/1700 loss 7.837623 loss_att 6.066475 loss_ctc 14.829080 loss_rnnt 7.087379 hw_loss 0.323024 history loss 6.315753 rank 6
2023-03-01 15:00:40,168 INFO Epoch 57 CV info cv_loss 6.300261586814072
2023-03-01 15:00:40,169 INFO Epoch 58 TRAIN info lr 0.00028457547477746
2023-03-01 15:00:40,174 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 15:00:40,647 INFO Epoch 57 CV info cv_loss 6.300261585142834
2023-03-01 15:00:40,647 INFO Epoch 58 TRAIN info lr 0.00028457731846200324
2023-03-01 15:00:40,652 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 15:00:42,117 DEBUG CV Batch 57/1700 loss 7.837623 loss_att 6.066475 loss_ctc 14.829080 loss_rnnt 7.087379 hw_loss 0.323024 history loss 6.315753 rank 7
2023-03-01 15:00:44,671 INFO Epoch 57 CV info cv_loss 6.300261586025833
2023-03-01 15:00:44,671 INFO Epoch 58 TRAIN info lr 0.00028458423259820193
2023-03-01 15:00:44,676 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 15:00:45,548 DEBUG CV Batch 57/1700 loss 7.837623 loss_att 6.066475 loss_ctc 14.829080 loss_rnnt 7.087379 hw_loss 0.323024 history loss 6.315753 rank 0
2023-03-01 15:00:45,823 INFO Epoch 57 CV info cv_loss 6.300261587184501
2023-03-01 15:00:45,823 INFO Epoch 58 TRAIN info lr 0.0002845787012489271
2023-03-01 15:00:45,828 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 15:00:46,536 INFO Epoch 57 CV info cv_loss 6.300261585745858
2023-03-01 15:00:46,536 INFO Epoch 58 TRAIN info lr 0.0002845805449961817
2023-03-01 15:00:46,540 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 15:00:48,033 INFO Epoch 57 CV info cv_loss 6.300261584927467
2023-03-01 15:00:48,033 INFO Epoch 58 TRAIN info lr 0.00028458653742226194
2023-03-01 15:00:48,039 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 15:00:51,465 INFO Epoch 57 CV info cv_loss 6.3002615870122085
2023-03-01 15:00:51,465 INFO Epoch 58 TRAIN info lr 0.0002845782403177128
2023-03-01 15:00:51,467 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 15:00:55,159 INFO Epoch 57 CV info cv_loss 6.3002615853237405
2023-03-01 15:00:55,159 INFO Checkpoint: save to checkpoint exp/2_27_rnnt_bias_loss_2_class_both_finetune/57.pt
2023-03-01 15:00:55,738 INFO Epoch 58 TRAIN info lr 0.00028458838132183024
2023-03-01 15:00:55,742 INFO using accumulate grad, new batch size is 4 times larger than before
2023-03-01 15:01:57,468 DEBUG TRAIN Batch 58/0 loss 11.133547 loss_att 11.500398 loss_ctc 17.762981 loss_rnnt 10.017675 hw_loss 0.297331 lr 0.00028458 rank 2
2023-03-01 15:01:57,469 DEBUG TRAIN Batch 58/0 loss 5.603463 loss_att 6.818527 loss_ctc 10.445688 loss_rnnt 4.521236 hw_loss 0.362969 lr 0.00028459 rank 6
2023-03-01 15:01:57,471 DEBUG TRAIN Batch 58/0 loss 10.863704 loss_att 10.975390 loss_ctc 16.006691 loss_rnnt 9.979305 hw_loss 0.330618 lr 0.00028458 rank 4
2023-03-01 15:01:57,475 DEBUG TRAIN Batch 58/0 loss 8.312505 loss_att 7.972006 loss_ctc 11.095531 loss_rnnt 7.831418 hw_loss 0.333969 lr 0.00028458 rank 1
2023-03-01 15:01:57,475 DEBUG TRAIN Batch 58/0 loss 5.778642 loss_att 6.357713 loss_ctc 8.053836 loss_rnnt 5.225711 hw_loss 0.250794 lr 0.00028458 rank 3
2023-03-01 15:01:57,476 DEBUG TRAIN Batch 58/0 loss 4.955599 loss_att 5.420666 loss_ctc 7.082025 loss_rnnt 4.383289 hw_loss 0.367076 lr 0.00028458 rank 7
2023-03-01 15:01:57,477 DEBUG TRAIN Batch 58/0 loss 4.732466 loss_att 6.157393 loss_ctc 8.478746 loss_rnnt 3.766517 hw_loss 0.340237 lr 0.00028458 rank 5
2023-03-01 15:01:57,512 DEBUG TRAIN Batch 58/0 loss 8.069535 loss_att 8.426036 loss_ctc 11.170065 loss_rnnt 7.468453 hw_loss 0.218208 lr 0.00028459 rank 0
2023-03-01 15:02:34,824 DEBUG TRAIN Batch 58/100 loss 6.187016 loss_att 9.222116 loss_ctc 10.309826 loss_rnnt 4.959062 hw_loss 0.133548 lr 0.00028458 rank 0
2023-03-01 15:02:34,839 DEBUG TRAIN Batch 58/100 loss 5.080559 loss_att 8.087854 loss_ctc 9.191873 loss_rnnt 3.751156 hw_loss 0.337068 lr 0.00028457 rank 6
2023-03-01 15:02:34,840 DEBUG TRAIN Batch 58/100 loss 4.975177 loss_att 8.958803 loss_ctc 9.913680 loss_rnnt 3.355978 hw_loss 0.307514 lr 0.00028457 rank 7
2023-03-01 15:02:34,842 DEBUG TRAIN Batch 58/100 loss 4.459820 loss_att 9.678140 loss_ctc 10.091679 loss_rnnt 2.644818 hw_loss 0.038295 lr 0.00028456 rank 1
2023-03-01 15:02:34,849 DEBUG TRAIN Batch 58/100 loss 2.453166 loss_att 7.510776 loss_ctc 6.024805 loss_rnnt 0.862258 hw_loss 0.193437 lr 0.00028457 rank 5
2023-03-01 15:02:34,849 DEBUG TRAIN Batch 58/100 loss 5.267729 loss_att 9.018884 loss_ctc 8.637037 loss_rnnt 3.930718 hw_loss 0.257885 lr 0.00028457 rank 3
2023-03-01 15:02:34,852 DEBUG TRAIN Batch 58/100 loss 4.797670 loss_att 7.027286 loss_ctc 7.684324 loss_rnnt 3.825982 hw_loss 0.264145 lr 0.00028457 rank 4
2023-03-01 15:02:34,857 DEBUG TRAIN Batch 58/100 loss 11.609713 loss_att 13.977621 loss_ctc 18.796507 loss_rnnt 10.076206 hw_loss 0.190657 lr 0.00028457 rank 2
2023-03-01 15:03:13,027 DEBUG TRAIN Batch 58/200 loss 4.345416 loss_att 7.896401 loss_ctc 6.713774 loss_rnnt 3.274796 hw_loss 0.083704 lr 0.00028455 rank 7
2023-03-01 15:03:13,030 DEBUG TRAIN Batch 58/200 loss 9.492992 loss_att 15.097021 loss_ctc 13.717892 loss_rnnt 7.712760 hw_loss 0.180201 lr 0.00028456 rank 5
2023-03-01 15:03:13,042 DEBUG TRAIN Batch 58/200 loss 4.651129 loss_att 6.911936 loss_ctc 5.923303 loss_rnnt 3.911961 hw_loss 0.220094 lr 0.00028456 rank 3
2023-03-01 15:03:13,047 DEBUG TRAIN Batch 58/200 loss 4.053516 loss_att 6.293594 loss_ctc 6.530160 loss_rnnt 3.235252 hw_loss 0.075055 lr 0.00028456 rank 0
2023-03-01 15:03:13,047 DEBUG TRAIN Batch 58/200 loss 2.406491 loss_att 5.090699 loss_ctc 4.798878 loss_rnnt 1.383006 hw_loss 0.314359 lr 0.00028456 rank 2
2023-03-01 15:03:13,049 DEBUG TRAIN Batch 58/200 loss 6.197827 loss_att 9.558506 loss_ctc 11.290541 loss_rnnt 4.689913 hw_loss 0.293906 lr 0.00028455 rank 1
2023-03-01 15:03:13,076 DEBUG TRAIN Batch 58/200 loss 4.629416 loss_att 8.412996 loss_ctc 6.159196 loss_rnnt 3.520988 hw_loss 0.277013 lr 0.00028455 rank 4
2023-03-01 15:03:13,079 DEBUG TRAIN Batch 58/200 loss 2.969935 loss_att 6.362601 loss_ctc 5.149397 loss_rnnt 1.841944 hw_loss 0.297866 lr 0.00028456 rank 6
2023-03-01 15:03:51,728 DEBUG TRAIN Batch 58/300 loss 6.842431 loss_att 9.660456 loss_ctc 11.403914 loss_rnnt 5.517606 hw_loss 0.286917 lr 0.00028454 rank 3
2023-03-01 15:03:51,739 DEBUG TRAIN Batch 58/300 loss 8.789449 loss_att 11.471379 loss_ctc 12.473906 loss_rnnt 7.636401 hw_loss 0.235125 lr 0.00028454 rank 7
2023-03-01 15:03:51,749 DEBUG TRAIN Batch 58/300 loss 7.476154 loss_att 10.822029 loss_ctc 11.424114 loss_rnnt 6.178112 hw_loss 0.192137 lr 0.00028454 rank 1
2023-03-01 15:03:51,751 DEBUG TRAIN Batch 58/300 loss 3.127460 loss_att 5.693833 loss_ctc 3.957291 loss_rnnt 2.373699 hw_loss 0.243453 lr 0.00028455 rank 5
2023-03-01 15:03:51,751 DEBUG TRAIN Batch 58/300 loss 8.756311 loss_att 9.407351 loss_ctc 13.066006 loss_rnnt 7.956490 hw_loss 0.178104 lr 0.00028455 rank 6
2023-03-01 15:03:51,752 DEBUG TRAIN Batch 58/300 loss 6.143832 loss_att 8.857428 loss_ctc 8.517637 loss_rnnt 5.161125 hw_loss 0.231526 lr 0.00028455 rank 2
2023-03-01 15:03:51,755 DEBUG TRAIN Batch 58/300 loss 5.038933 loss_att 8.210678 loss_ctc 7.614242 loss_rnnt 3.974329 hw_loss 0.162901 lr 0.00028454 rank 4
2023-03-01 15:03:51,755 DEBUG TRAIN Batch 58/300 loss 4.365451 loss_att 7.355322 loss_ctc 11.718616 loss_rnnt 2.630625 hw_loss 0.293306 lr 0.00028455 rank 0
2023-03-01 15:05:02,024 DEBUG TRAIN Batch 58/400 loss 11.588127 loss_att 12.475496 loss_ctc 15.048136 loss_rnnt 10.837095 hw_loss 0.210422 lr 0.00028454 rank 6
2023-03-01 15:05:02,024 DEBUG TRAIN Batch 58/400 loss 7.608948 loss_att 9.064732 loss_ctc 10.148956 loss_rnnt 6.852415 hw_loss 0.237578 lr 0.00028454 rank 5
2023-03-01 15:05:02,026 DEBUG TRAIN Batch 58/400 loss 6.074346 loss_att 8.259655 loss_ctc 7.611682 loss_rnnt 5.342387 hw_loss 0.168597 lr 0.00028453 rank 4
2023-03-01 15:05:02,025 DEBUG TRAIN Batch 58/400 loss 4.859110 loss_att 7.363050 loss_ctc 7.910830 loss_rnnt 3.858778 hw_loss 0.173715 lr 0.00028453 rank 7
2023-03-01 15:05:02,027 DEBUG TRAIN Batch 58/400 loss 4.540382 loss_att 7.150067 loss_ctc 8.706961 loss_rnnt 3.354153 hw_loss 0.203902 lr 0.00028454 rank 0
2023-03-01 15:05:02,031 DEBUG TRAIN Batch 58/400 loss 3.021582 loss_att 6.992263 loss_ctc 6.688019 loss_rnnt 1.615171 hw_loss 0.231406 lr 0.00028453 rank 2
2023-03-01 15:05:02,031 DEBUG TRAIN Batch 58/400 loss 5.111845 loss_att 6.423392 loss_ctc 11.218364 loss_rnnt 3.910334 hw_loss 0.234376 lr 0.00028453 rank 3
2023-03-01 15:05:02,032 DEBUG TRAIN Batch 58/400 loss 4.973900 loss_att 8.721720 loss_ctc 6.054099 loss_rnnt 3.962126 hw_loss 0.221593 lr 0.00028453 rank 1
2023-03-01 15:05:40,322 DEBUG TRAIN Batch 58/500 loss 4.652325 loss_att 7.731940 loss_ctc 11.911098 loss_rnnt 3.001274 hw_loss 0.126170 lr 0.00028452 rank 7
2023-03-01 15:05:40,325 DEBUG TRAIN Batch 58/500 loss 11.256577 loss_att 14.017689 loss_ctc 19.531605 loss_rnnt 9.525689 hw_loss 0.141239 lr 0.00028453 rank 0
2023-03-01 15:05:40,330 DEBUG TRAIN Batch 58/500 loss 3.010574 loss_att 6.160121 loss_ctc 7.142747 loss_rnnt 1.691546 hw_loss 0.259053 lr 0.00028452 rank 3
2023-03-01 15:05:40,330 DEBUG TRAIN Batch 58/500 loss 3.769306 loss_att 6.678275 loss_ctc 6.143314 loss_rnnt 2.784702 hw_loss 0.161766 lr 0.00028452 rank 1
2023-03-01 15:05:40,330 DEBUG TRAIN Batch 58/500 loss 6.888103 loss_att 9.640681 loss_ctc 10.871108 loss_rnnt 5.667578 hw_loss 0.260517 lr 0.00028452 rank 4
2023-03-01 15:05:40,332 DEBUG TRAIN Batch 58/500 loss 4.792784 loss_att 7.716483 loss_ctc 8.635198 loss_rnnt 3.595278 hw_loss 0.188332 lr 0.00028452 rank 2
2023-03-01 15:05:40,333 DEBUG TRAIN Batch 58/500 loss 4.702596 loss_att 7.471437 loss_ctc 5.965847 loss_rnnt 3.866661 hw_loss 0.213251 lr 0.00028453 rank 6
2023-03-01 15:05:40,377 DEBUG TRAIN Batch 58/500 loss 4.677684 loss_att 8.017787 loss_ctc 9.254489 loss_rnnt 3.187541 hw_loss 0.397279 lr 0.00028453 rank 5
2023-03-01 15:06:19,554 DEBUG TRAIN Batch 58/600 loss 6.240956 loss_att 10.320631 loss_ctc 11.410142 loss_rnnt 4.578382 hw_loss 0.295153 lr 0.00028451 rank 1
2023-03-01 15:06:19,567 DEBUG TRAIN Batch 58/600 loss 8.187811 loss_att 10.261277 loss_ctc 14.225409 loss_rnnt 6.879868 hw_loss 0.165445 lr 0.00028451 rank 7
2023-03-01 15:06:19,568 DEBUG TRAIN Batch 58/600 loss 4.599843 loss_att 6.912819 loss_ctc 8.707408 loss_rnnt 3.483983 hw_loss 0.197978 lr 0.00028452 rank 0
2023-03-01 15:06:19,568 DEBUG TRAIN Batch 58/600 loss 5.025644 loss_att 6.224221 loss_ctc 7.699369 loss_rnnt 4.224120 hw_loss 0.384960 lr 0.00028452 rank 6
2023-03-01 15:06:19,569 DEBUG TRAIN Batch 58/600 loss 10.660673 loss_att 12.098480 loss_ctc 15.936930 loss_rnnt 9.495766 hw_loss 0.325960 lr 0.00028451 rank 2
2023-03-01 15:06:19,569 DEBUG TRAIN Batch 58/600 loss 6.917333 loss_att 9.898323 loss_ctc 9.533284 loss_rnnt 5.842136 hw_loss 0.244134 lr 0.00028451 rank 4
2023-03-01 15:06:19,573 DEBUG TRAIN Batch 58/600 loss 7.776131 loss_att 10.256535 loss_ctc 17.436983 loss_rnnt 5.847045 hw_loss 0.271672 lr 0.00028451 rank 5
2023-03-01 15:06:19,615 DEBUG TRAIN Batch 58/600 loss 4.835623 loss_att 7.102439 loss_ctc 9.069661 loss_rnnt 3.697635 hw_loss 0.225161 lr 0.00028451 rank 3
2023-03-01 15:06:59,445 DEBUG TRAIN Batch 58/700 loss 3.802417 loss_att 7.512636 loss_ctc 13.243763 loss_rnnt 1.679455 hw_loss 0.228886 lr 0.00028450 rank 5
2023-03-01 15:06:59,450 DEBUG TRAIN Batch 58/700 loss 3.062836 loss_att 5.281052 loss_ctc 3.154277 loss_rnnt 2.486587 hw_loss 0.225778 lr 0.00028450 rank 3
2023-03-01 15:06:59,467 DEBUG TRAIN Batch 58/700 loss 6.165325 loss_att 8.738113 loss_ctc 9.722921 loss_rnnt 5.052541 hw_loss 0.232274 lr 0.00028450 rank 7
2023-03-01 15:06:59,467 DEBUG TRAIN Batch 58/700 loss 5.012207 loss_att 7.786295 loss_ctc 6.332905 loss_rnnt 4.113170 hw_loss 0.315236 lr 0.00028451 rank 0
2023-03-01 15:06:59,469 DEBUG TRAIN Batch 58/700 loss 2.809586 loss_att 5.609662 loss_ctc 5.906598 loss_rnnt 1.694961 hw_loss 0.265639 lr 0.00028450 rank 4
2023-03-01 15:06:59,473 DEBUG TRAIN Batch 58/700 loss 7.534065 loss_att 10.416168 loss_ctc 12.807302 loss_rnnt 6.229311 hw_loss 0.047317 lr 0.00028451 rank 6
2023-03-01 15:06:59,479 DEBUG TRAIN Batch 58/700 loss 7.034914 loss_att 8.432424 loss_ctc 9.145586 loss_rnnt 6.291910 hw_loss 0.341398 lr 0.00028450 rank 2
2023-03-01 15:06:59,485 DEBUG TRAIN Batch 58/700 loss 9.087067 loss_att 16.587639 loss_ctc 17.239464 loss_rnnt 6.364608 hw_loss 0.253796 lr 0.00028449 rank 1
2023-03-01 15:08:08,184 DEBUG TRAIN Batch 58/800 loss 2.030617 loss_att 4.382811 loss_ctc 3.566389 loss_rnnt 1.279840 hw_loss 0.141690 lr 0.00028449 rank 7
2023-03-01 15:08:08,185 DEBUG TRAIN Batch 58/800 loss 6.044402 loss_att 11.492710 loss_ctc 11.154597 loss_rnnt 4.136759 hw_loss 0.256166 lr 0.00028449 rank 2
2023-03-01 15:08:08,187 DEBUG TRAIN Batch 58/800 loss 6.744971 loss_att 9.406895 loss_ctc 9.838932 loss_rnnt 5.680519 hw_loss 0.224137 lr 0.00028449 rank 3
2023-03-01 15:08:08,188 DEBUG TRAIN Batch 58/800 loss 4.958215 loss_att 9.263886 loss_ctc 8.400432 loss_rnnt 3.561450 hw_loss 0.143754 lr 0.00028450 rank 0
2023-03-01 15:08:08,189 DEBUG TRAIN Batch 58/800 loss 4.776084 loss_att 7.582195 loss_ctc 9.708204 loss_rnnt 3.423943 hw_loss 0.249943 lr 0.00028449 rank 5
2023-03-01 15:08:08,192 DEBUG TRAIN Batch 58/800 loss 9.263675 loss_att 9.037722 loss_ctc 11.194969 loss_rnnt 8.859344 hw_loss 0.360030 lr 0.00028448 rank 1
2023-03-01 15:08:08,200 DEBUG TRAIN Batch 58/800 loss 4.744706 loss_att 9.006558 loss_ctc 8.857454 loss_rnnt 3.230650 hw_loss 0.212472 lr 0.00028449 rank 6
2023-03-01 15:08:08,243 DEBUG TRAIN Batch 58/800 loss 1.589098 loss_att 5.343338 loss_ctc 2.651961 loss_rnnt 0.576584 hw_loss 0.224908 lr 0.00028448 rank 4
2023-03-01 15:08:47,033 DEBUG TRAIN Batch 58/900 loss 6.367901 loss_att 10.724854 loss_ctc 11.730005 loss_rnnt 4.711142 hw_loss 0.132039 lr 0.00028447 rank 4
2023-03-01 15:08:47,033 DEBUG TRAIN Batch 58/900 loss 2.228483 loss_att 3.432774 loss_ctc 2.633855 loss_rnnt 1.816748 hw_loss 0.219052 lr 0.00028448 rank 2
2023-03-01 15:08:47,034 DEBUG TRAIN Batch 58/900 loss 5.549814 loss_att 9.752569 loss_ctc 11.840646 loss_rnnt 3.750194 hw_loss 0.225546 lr 0.00028448 rank 5
2023-03-01 15:08:47,034 DEBUG TRAIN Batch 58/900 loss 7.476247 loss_att 12.939011 loss_ctc 21.448515 loss_rnnt 4.363796 hw_loss 0.294241 lr 0.00028448 rank 6
2023-03-01 15:08:47,038 DEBUG TRAIN Batch 58/900 loss 3.758811 loss_att 6.324141 loss_ctc 9.121432 loss_rnnt 2.455721 hw_loss 0.140640 lr 0.00028447 rank 3
2023-03-01 15:08:47,043 DEBUG TRAIN Batch 58/900 loss 3.540677 loss_att 6.180996 loss_ctc 5.741341 loss_rnnt 2.673560 hw_loss 0.085558 lr 0.00028447 rank 7
2023-03-01 15:08:47,046 DEBUG TRAIN Batch 58/900 loss 4.607026 loss_att 8.053562 loss_ctc 8.347261 loss_rnnt 3.307331 hw_loss 0.209417 lr 0.00028448 rank 0
2023-03-01 15:08:47,051 DEBUG TRAIN Batch 58/900 loss 1.905222 loss_att 4.890418 loss_ctc 4.965053 loss_rnnt 0.865832 hw_loss 0.064451 lr 0.00028447 rank 1
2023-03-01 15:09:26,018 DEBUG TRAIN Batch 58/1000 loss 6.608588 loss_att 7.515547 loss_ctc 8.581571 loss_rnnt 6.121562 hw_loss 0.079817 lr 0.00028446 rank 4
2023-03-01 15:09:26,019 DEBUG TRAIN Batch 58/1000 loss 2.800360 loss_att 5.028624 loss_ctc 4.963528 loss_rnnt 1.977602 hw_loss 0.166280 lr 0.00028446 rank 3
2023-03-01 15:09:26,021 DEBUG TRAIN Batch 58/1000 loss 5.438135 loss_att 8.431457 loss_ctc 6.478932 loss_rnnt 4.659876 hw_loss 0.076540 lr 0.00028446 rank 2
2023-03-01 15:09:26,023 DEBUG TRAIN Batch 58/1000 loss 10.438132 loss_att 11.357041 loss_ctc 13.941387 loss_rnnt 9.698550 hw_loss 0.166314 lr 0.00028446 rank 7
2023-03-01 15:09:26,023 DEBUG TRAIN Batch 58/1000 loss 2.063121 loss_att 4.178400 loss_ctc 2.371562 loss_rnnt 1.424400 hw_loss 0.327262 lr 0.00028447 rank 6
2023-03-01 15:09:26,023 DEBUG TRAIN Batch 58/1000 loss 6.823809 loss_att 8.963217 loss_ctc 14.848869 loss_rnnt 5.257360 hw_loss 0.128547 lr 0.00028447 rank 0
2023-03-01 15:09:26,036 DEBUG TRAIN Batch 58/1000 loss 6.095424 loss_att 9.814777 loss_ctc 9.017397 loss_rnnt 4.897101 hw_loss 0.121603 lr 0.00028447 rank 5
2023-03-01 15:09:26,054 DEBUG TRAIN Batch 58/1000 loss 4.416326 loss_att 6.555933 loss_ctc 5.253223 loss_rnnt 3.768252 hw_loss 0.203559 lr 0.00028446 rank 1
2023-03-01 15:10:34,465 DEBUG TRAIN Batch 58/1100 loss 2.640365 loss_att 4.789880 loss_ctc 4.832466 loss_rnnt 1.793857 hw_loss 0.233109 lr 0.00028445 rank 7
2023-03-01 15:10:34,485 DEBUG TRAIN Batch 58/1100 loss 3.637522 loss_att 6.249652 loss_ctc 7.446901 loss_rnnt 2.413433 hw_loss 0.363275 lr 0.00028446 rank 0
2023-03-01 15:10:34,488 DEBUG TRAIN Batch 58/1100 loss 8.727498 loss_att 13.712502 loss_ctc 18.387869 loss_rnnt 6.334600 hw_loss 0.202215 lr 0.00028446 rank 5
2023-03-01 15:10:34,490 DEBUG TRAIN Batch 58/1100 loss 5.001425 loss_att 7.279197 loss_ctc 8.556650 loss_rnnt 4.035243 hw_loss 0.068620 lr 0.00028445 rank 2
2023-03-01 15:10:34,491 DEBUG TRAIN Batch 58/1100 loss 8.094539 loss_att 9.792982 loss_ctc 11.107678 loss_rnnt 7.193767 hw_loss 0.298747 lr 0.00028445 rank 1
2023-03-01 15:10:34,490 DEBUG TRAIN Batch 58/1100 loss 8.465113 loss_att 11.579535 loss_ctc 10.559931 loss_rnnt 7.494350 hw_loss 0.128564 lr 0.00028445 rank 4
2023-03-01 15:10:34,492 DEBUG TRAIN Batch 58/1100 loss 5.342961 loss_att 8.370617 loss_ctc 9.185244 loss_rnnt 4.077395 hw_loss 0.276995 lr 0.00028445 rank 3
2023-03-01 15:10:34,496 DEBUG TRAIN Batch 58/1100 loss 1.306521 loss_att 4.638786 loss_ctc 2.737717 loss_rnnt 0.334061 hw_loss 0.215963 lr 0.00028446 rank 6
2023-03-01 15:11:13,312 DEBUG TRAIN Batch 58/1200 loss 2.630990 loss_att 6.783632 loss_ctc 4.335178 loss_rnnt 1.495853 hw_loss 0.145093 lr 0.00028445 rank 5
2023-03-01 15:11:13,316 DEBUG TRAIN Batch 58/1200 loss 7.399461 loss_att 9.861116 loss_ctc 13.778409 loss_rnnt 5.940048 hw_loss 0.218542 lr 0.00028444 rank 1
2023-03-01 15:11:13,318 DEBUG TRAIN Batch 58/1200 loss 9.781981 loss_att 11.644625 loss_ctc 14.134259 loss_rnnt 8.669590 hw_loss 0.299170 lr 0.00028444 rank 7
2023-03-01 15:11:13,320 DEBUG TRAIN Batch 58/1200 loss 4.467980 loss_att 6.998261 loss_ctc 7.992605 loss_rnnt 3.344285 hw_loss 0.276916 lr 0.00028445 rank 0
2023-03-01 15:11:13,322 DEBUG TRAIN Batch 58/1200 loss 3.584388 loss_att 6.859859 loss_ctc 8.282630 loss_rnnt 2.169204 hw_loss 0.250606 lr 0.00028444 rank 4
2023-03-01 15:11:13,324 DEBUG TRAIN Batch 58/1200 loss 5.737095 loss_att 9.357318 loss_ctc 9.193997 loss_rnnt 4.435026 hw_loss 0.219571 lr 0.00028444 rank 3
2023-03-01 15:11:13,324 DEBUG TRAIN Batch 58/1200 loss 6.814351 loss_att 10.184495 loss_ctc 10.418619 loss_rnnt 5.599736 hw_loss 0.112530 lr 0.00028445 rank 6
2023-03-01 15:11:13,329 DEBUG TRAIN Batch 58/1200 loss 8.920958 loss_att 10.796740 loss_ctc 14.097508 loss_rnnt 7.785165 hw_loss 0.132055 lr 0.00028444 rank 2
2023-03-01 15:11:51,777 DEBUG TRAIN Batch 58/1300 loss 3.210958 loss_att 8.126356 loss_ctc 6.484823 loss_rnnt 1.767118 hw_loss 0.045460 lr 0.00028443 rank 7
2023-03-01 15:11:51,777 DEBUG TRAIN Batch 58/1300 loss 3.795322 loss_att 6.166047 loss_ctc 7.881776 loss_rnnt 2.724513 hw_loss 0.097132 lr 0.00028444 rank 0
2023-03-01 15:11:51,780 DEBUG TRAIN Batch 58/1300 loss 12.431564 loss_att 12.389167 loss_ctc 14.268417 loss_rnnt 12.063686 hw_loss 0.246457 lr 0.00028443 rank 3
2023-03-01 15:11:51,781 DEBUG TRAIN Batch 58/1300 loss 2.109693 loss_att 5.079672 loss_ctc 3.801151 loss_rnnt 1.217895 hw_loss 0.135514 lr 0.00028443 rank 5
2023-03-01 15:11:51,788 DEBUG TRAIN Batch 58/1300 loss 3.232088 loss_att 7.497783 loss_ctc 7.390525 loss_rnnt 1.671605 hw_loss 0.286661 lr 0.00028443 rank 4
2023-03-01 15:11:51,809 DEBUG TRAIN Batch 58/1300 loss 6.851536 loss_att 7.544566 loss_ctc 9.807924 loss_rnnt 6.141824 hw_loss 0.331727 lr 0.00028443 rank 1
2023-03-01 15:11:51,814 DEBUG TRAIN Batch 58/1300 loss 5.374577 loss_att 12.466774 loss_ctc 9.505404 loss_rnnt 3.338586 hw_loss 0.125202 lr 0.00028443 rank 2
2023-03-01 15:11:51,817 DEBUG TRAIN Batch 58/1300 loss 2.150755 loss_att 5.177408 loss_ctc 4.855256 loss_rnnt 1.064978 hw_loss 0.224712 lr 0.00028444 rank 6
2023-03-01 15:12:32,201 DEBUG TRAIN Batch 58/1400 loss 4.138608 loss_att 6.426686 loss_ctc 6.706430 loss_rnnt 3.187198 hw_loss 0.283910 lr 0.00028442 rank 5
2023-03-01 15:12:32,217 DEBUG TRAIN Batch 58/1400 loss 5.108032 loss_att 7.799240 loss_ctc 10.376818 loss_rnnt 3.789478 hw_loss 0.145890 lr 0.00028442 rank 4
2023-03-01 15:12:32,219 DEBUG TRAIN Batch 58/1400 loss 13.842873 loss_att 18.878370 loss_ctc 26.375698 loss_rnnt 10.971872 hw_loss 0.361606 lr 0.00028443 rank 0
2023-03-01 15:12:32,220 DEBUG TRAIN Batch 58/1400 loss 1.374677 loss_att 3.767117 loss_ctc 3.084411 loss_rnnt 0.539479 hw_loss 0.241398 lr 0.00028442 rank 3
2023-03-01 15:12:32,223 DEBUG TRAIN Batch 58/1400 loss 3.666894 loss_att 6.762835 loss_ctc 4.610295 loss_rnnt 2.807855 hw_loss 0.213871 lr 0.00028442 rank 7
2023-03-01 15:12:32,224 DEBUG TRAIN Batch 58/1400 loss 3.548631 loss_att 6.330152 loss_ctc 13.435367 loss_rnnt 1.602623 hw_loss 0.134011 lr 0.00028442 rank 2
2023-03-01 15:12:32,249 DEBUG TRAIN Batch 58/1400 loss 4.599294 loss_att 7.979148 loss_ctc 8.850136 loss_rnnt 3.251326 hw_loss 0.197284 lr 0.00028441 rank 1
2023-03-01 15:12:32,286 DEBUG TRAIN Batch 58/1400 loss 5.155264 loss_att 10.600016 loss_ctc 7.366085 loss_rnnt 3.697219 hw_loss 0.139346 lr 0.00028442 rank 6
2023-03-01 15:13:37,616 DEBUG TRAIN Batch 58/1500 loss 6.375799 loss_att 7.967185 loss_ctc 8.507092 loss_rnnt 5.688553 hw_loss 0.158992 lr 0.00028442 rank 0
2023-03-01 15:13:37,632 DEBUG TRAIN Batch 58/1500 loss 4.681922 loss_att 7.875658 loss_ctc 7.327966 loss_rnnt 3.638730 hw_loss 0.096823 lr 0.00028441 rank 7
2023-03-01 15:13:37,635 DEBUG TRAIN Batch 58/1500 loss 14.535964 loss_att 15.009299 loss_ctc 22.341402 loss_rnnt 13.278356 hw_loss 0.229153 lr 0.00028441 rank 5
2023-03-01 15:13:37,636 DEBUG TRAIN Batch 58/1500 loss 5.909703 loss_att 9.496056 loss_ctc 13.890120 loss_rnnt 4.051761 hw_loss 0.143655 lr 0.00028441 rank 6
2023-03-01 15:13:37,638 DEBUG TRAIN Batch 58/1500 loss 5.096228 loss_att 9.174704 loss_ctc 9.000564 loss_rnnt 3.662573 hw_loss 0.182589 lr 0.00028440 rank 1
2023-03-01 15:13:37,644 DEBUG TRAIN Batch 58/1500 loss 3.910041 loss_att 7.969048 loss_ctc 10.197401 loss_rnnt 2.151838 hw_loss 0.202662 lr 0.00028441 rank 2
2023-03-01 15:13:37,647 DEBUG TRAIN Batch 58/1500 loss 2.859309 loss_att 5.100295 loss_ctc 4.831645 loss_rnnt 2.114349 hw_loss 0.063346 lr 0.00028440 rank 4
2023-03-01 15:13:37,660 DEBUG TRAIN Batch 58/1500 loss 5.958464 loss_att 7.544014 loss_ctc 12.155663 loss_rnnt 4.707857 hw_loss 0.201007 lr 0.00028441 rank 3
2023-03-01 15:14:16,241 DEBUG TRAIN Batch 58/1600 loss 6.944801 loss_att 8.922981 loss_ctc 9.910107 loss_rnnt 6.017349 hw_loss 0.255828 lr 0.00028439 rank 7
2023-03-01 15:14:16,247 DEBUG TRAIN Batch 58/1600 loss 9.312751 loss_att 12.310651 loss_ctc 12.593763 loss_rnnt 8.112961 hw_loss 0.305140 lr 0.00028439 rank 4
2023-03-01 15:14:16,260 DEBUG TRAIN Batch 58/1600 loss 9.039009 loss_att 10.763279 loss_ctc 10.863888 loss_rnnt 8.347294 hw_loss 0.194143 lr 0.00028440 rank 0
2023-03-01 15:14:16,260 DEBUG TRAIN Batch 58/1600 loss 10.040480 loss_att 14.117839 loss_ctc 17.374981 loss_rnnt 8.114328 hw_loss 0.248897 lr 0.00028439 rank 1
2023-03-01 15:14:16,260 DEBUG TRAIN Batch 58/1600 loss 6.274467 loss_att 8.147129 loss_ctc 10.726917 loss_rnnt 5.135244 hw_loss 0.320681 lr 0.00028440 rank 6
2023-03-01 15:14:16,264 DEBUG TRAIN Batch 58/1600 loss 6.776934 loss_att 10.932342 loss_ctc 12.459995 loss_rnnt 5.079971 hw_loss 0.202761 lr 0.00028440 rank 2
2023-03-01 15:14:16,265 DEBUG TRAIN Batch 58/1600 loss 6.008646 loss_att 10.521828 loss_ctc 8.578526 loss_rnnt 4.601365 hw_loss 0.303739 lr 0.00028440 rank 5
2023-03-01 15:14:16,285 DEBUG TRAIN Batch 58/1600 loss 5.072504 loss_att 6.974607 loss_ctc 6.906326 loss_rnnt 4.271867 hw_loss 0.329449 lr 0.00028439 rank 3
2023-03-01 15:14:55,564 DEBUG TRAIN Batch 58/1700 loss 7.049447 loss_att 10.225203 loss_ctc 10.458920 loss_rnnt 5.896363 hw_loss 0.118753 lr 0.00028438 rank 2
2023-03-01 15:14:55,574 DEBUG TRAIN Batch 58/1700 loss 6.614664 loss_att 9.820303 loss_ctc 11.245420 loss_rnnt 5.248042 hw_loss 0.202612 lr 0.00028438 rank 7
2023-03-01 15:14:55,575 DEBUG TRAIN Batch 58/1700 loss 5.129858 loss_att 7.524441 loss_ctc 5.874877 loss_rnnt 4.436366 hw_loss 0.216072 lr 0.00028438 rank 1
2023-03-01 15:14:55,576 DEBUG TRAIN Batch 58/1700 loss 6.231579 loss_att 9.116984 loss_ctc 12.346472 loss_rnnt 4.801784 hw_loss 0.070117 lr 0.00028439 rank 0
2023-03-01 15:14:55,579 DEBUG TRAIN Batch 58/1700 loss 4.015433 loss_att 7.847690 loss_ctc 5.085300 loss_rnnt 2.979375 hw_loss 0.238045 lr 0.00028438 rank 3
2023-03-01 15:14:55,586 DEBUG TRAIN Batch 58/1700 loss 3.602285 loss_att 7.504160 loss_ctc 5.810890 loss_rnnt 2.433631 hw_loss 0.175872 lr 0.00028439 rank 6
2023-03-01 15:14:55,607 DEBUG TRAIN Batch 58/1700 loss 5.115318 loss_att 7.217511 loss_ctc 7.862554 loss_rnnt 4.223116 hw_loss 0.197747 lr 0.00028439 rank 5
2023-03-01 15:14:55,624 DEBUG TRAIN Batch 58/1700 loss 7.664041 loss_att 11.534999 loss_ctc 10.998717 loss_rnnt 6.393820 hw_loss 0.096386 lr 0.00028438 rank 4
2023-03-01 15:16:04,764 DEBUG TRAIN Batch 58/1800 loss 3.447960 loss_att 4.895281 loss_ctc 5.705930 loss_rnnt 2.762834 hw_loss 0.177373 lr 0.00028438 rank 0
2023-03-01 15:16:04,765 DEBUG TRAIN Batch 58/1800 loss 7.686606 loss_att 10.416608 loss_ctc 12.701082 loss_rnnt 6.442040 hw_loss 0.056190 lr 0.00028438 rank 6
2023-03-01 15:16:04,767 DEBUG TRAIN Batch 58/1800 loss 5.582162 loss_att 8.964287 loss_ctc 8.779979 loss_rnnt 4.304645 hw_loss 0.327594 lr 0.00028437 rank 7
2023-03-01 15:16:04,772 DEBUG TRAIN Batch 58/1800 loss 7.732439 loss_att 11.614143 loss_ctc 12.049911 loss_rnnt 6.214022 hw_loss 0.312022 lr 0.00028437 rank 2
2023-03-01 15:16:04,772 DEBUG TRAIN Batch 58/1800 loss 5.018961 loss_att 7.304341 loss_ctc 12.454914 loss_rnnt 3.505083 hw_loss 0.122516 lr 0.00028437 rank 1
2023-03-01 15:16:04,773 DEBUG TRAIN Batch 58/1800 loss 6.277816 loss_att 8.043588 loss_ctc 8.910585 loss_rnnt 5.455038 hw_loss 0.222354 lr 0.00028437 rank 3
2023-03-01 15:16:04,773 DEBUG TRAIN Batch 58/1800 loss 5.131451 loss_att 6.944117 loss_ctc 9.328569 loss_rnnt 4.150831 hw_loss 0.109633 lr 0.00028437 rank 4
2023-03-01 15:16:04,810 DEBUG TRAIN Batch 58/1800 loss 12.023028 loss_att 9.644190 loss_ctc 15.677018 loss_rnnt 11.975971 hw_loss 0.066798 lr 0.00028438 rank 5
2023-03-01 15:16:43,510 DEBUG TRAIN Batch 58/1900 loss 2.784014 loss_att 7.097272 loss_ctc 5.999816 loss_rnnt 1.420523 hw_loss 0.135123 lr 0.00028437 rank 5
2023-03-01 15:16:43,520 DEBUG TRAIN Batch 58/1900 loss 3.778090 loss_att 5.534741 loss_ctc 3.968121 loss_rnnt 3.341419 hw_loss 0.112504 lr 0.00028437 rank 0
2023-03-01 15:16:43,521 DEBUG TRAIN Batch 58/1900 loss 5.479016 loss_att 5.926494 loss_ctc 8.763956 loss_rnnt 4.820292 hw_loss 0.246068 lr 0.00028436 rank 4
2023-03-01 15:16:43,524 DEBUG TRAIN Batch 58/1900 loss 5.757601 loss_att 5.722942 loss_ctc 7.622603 loss_rnnt 5.410717 hw_loss 0.197155 lr 0.00028436 rank 7
2023-03-01 15:16:43,524 DEBUG TRAIN Batch 58/1900 loss 4.647738 loss_att 5.298654 loss_ctc 6.146692 loss_rnnt 4.189923 hw_loss 0.239572 lr 0.00028437 rank 6
2023-03-01 15:16:43,525 DEBUG TRAIN Batch 58/1900 loss 3.741255 loss_att 4.389228 loss_ctc 4.302949 loss_rnnt 3.387640 hw_loss 0.279614 lr 0.00028436 rank 3
2023-03-01 15:16:43,526 DEBUG TRAIN Batch 58/1900 loss 5.746482 loss_att 7.070366 loss_ctc 9.450108 loss_rnnt 4.820753 hw_loss 0.313379 lr 0.00028436 rank 2
2023-03-01 15:16:43,528 DEBUG TRAIN Batch 58/1900 loss 5.326143 loss_att 8.368137 loss_ctc 7.872417 loss_rnnt 4.297222 hw_loss 0.151909 lr 0.00028436 rank 1
2023-03-01 15:17:22,160 DEBUG TRAIN Batch 58/2000 loss 5.509860 loss_att 9.605524 loss_ctc 9.958136 loss_rnnt 3.935336 hw_loss 0.304289 lr 0.00028435 rank 3
2023-03-01 15:17:22,168 DEBUG TRAIN Batch 58/2000 loss 3.461340 loss_att 6.630956 loss_ctc 5.868015 loss_rnnt 2.326644 hw_loss 0.337281 lr 0.00028434 rank 1
2023-03-01 15:17:22,177 DEBUG TRAIN Batch 58/2000 loss 3.153711 loss_att 6.410279 loss_ctc 7.364399 loss_rnnt 1.867650 hw_loss 0.137479 lr 0.00028435 rank 4
2023-03-01 15:17:22,179 DEBUG TRAIN Batch 58/2000 loss 1.439220 loss_att 3.476937 loss_ctc 1.548407 loss_rnnt 0.907563 hw_loss 0.205417 lr 0.00028435 rank 7
2023-03-01 15:17:22,179 DEBUG TRAIN Batch 58/2000 loss 5.243937 loss_att 8.821624 loss_ctc 9.074354 loss_rnnt 3.900182 hw_loss 0.220304 lr 0.00028435 rank 5
2023-03-01 15:17:22,181 DEBUG TRAIN Batch 58/2000 loss 10.506491 loss_att 14.425917 loss_ctc 20.681540 loss_rnnt 8.232009 hw_loss 0.251108 lr 0.00028436 rank 0
2023-03-01 15:17:22,183 DEBUG TRAIN Batch 58/2000 loss 7.262958 loss_att 8.663021 loss_ctc 15.414325 loss_rnnt 5.786337 hw_loss 0.205800 lr 0.00028436 rank 6
2023-03-01 15:17:22,227 DEBUG TRAIN Batch 58/2000 loss 5.220739 loss_att 9.449732 loss_ctc 10.020228 loss_rnnt 3.638900 hw_loss 0.180204 lr 0.00028435 rank 2
2023-03-01 15:18:02,314 DEBUG TRAIN Batch 58/2100 loss 4.658762 loss_att 7.619606 loss_ctc 6.395365 loss_rnnt 3.764916 hw_loss 0.131493 lr 0.00028434 rank 4
2023-03-01 15:18:02,318 DEBUG TRAIN Batch 58/2100 loss 4.586920 loss_att 6.797211 loss_ctc 5.749231 loss_rnnt 3.971248 hw_loss 0.034949 lr 0.00028433 rank 1
2023-03-01 15:18:02,325 DEBUG TRAIN Batch 58/2100 loss 3.421078 loss_att 6.762392 loss_ctc 6.432603 loss_rnnt 2.227659 hw_loss 0.231786 lr 0.00028434 rank 2
2023-03-01 15:18:02,328 DEBUG TRAIN Batch 58/2100 loss 3.208056 loss_att 4.839086 loss_ctc 4.420455 loss_rnnt 2.592569 hw_loss 0.239303 lr 0.00028434 rank 6
2023-03-01 15:18:02,328 DEBUG TRAIN Batch 58/2100 loss 4.185266 loss_att 9.401464 loss_ctc 9.092394 loss_rnnt 2.408262 hw_loss 0.149027 lr 0.00028434 rank 7
2023-03-01 15:18:02,332 DEBUG TRAIN Batch 58/2100 loss 7.733469 loss_att 8.908663 loss_ctc 11.098169 loss_rnnt 6.973186 hw_loss 0.143659 lr 0.00028435 rank 0
2023-03-01 15:18:02,341 DEBUG TRAIN Batch 58/2100 loss 6.188244 loss_att 9.666675 loss_ctc 10.843651 loss_rnnt 4.686177 hw_loss 0.348111 lr 0.00028434 rank 5
2023-03-01 15:18:02,347 DEBUG TRAIN Batch 58/2100 loss 3.147388 loss_att 6.747900 loss_ctc 4.920518 loss_rnnt 2.109370 hw_loss 0.152809 lr 0.00028434 rank 3
2023-03-01 15:19:10,581 DEBUG TRAIN Batch 58/2200 loss 3.124669 loss_att 5.033399 loss_ctc 3.858317 loss_rnnt 2.503432 hw_loss 0.265634 lr 0.00028433 rank 3
2023-03-01 15:19:10,591 DEBUG TRAIN Batch 58/2200 loss 4.104156 loss_att 5.833892 loss_ctc 7.442032 loss_rnnt 3.181247 hw_loss 0.247336 lr 0.00028432 rank 4
2023-03-01 15:19:10,594 DEBUG TRAIN Batch 58/2200 loss 5.394306 loss_att 6.738213 loss_ctc 7.486415 loss_rnnt 4.729863 hw_loss 0.218839 lr 0.00028432 rank 7
2023-03-01 15:19:10,597 DEBUG TRAIN Batch 58/2200 loss 11.207149 loss_att 15.539091 loss_ctc 17.695164 loss_rnnt 9.361619 hw_loss 0.213886 lr 0.00028432 rank 1
2023-03-01 15:19:10,599 DEBUG TRAIN Batch 58/2200 loss 2.857722 loss_att 5.201240 loss_ctc 4.110382 loss_rnnt 2.149052 hw_loss 0.136773 lr 0.00028433 rank 6
2023-03-01 15:19:10,600 DEBUG TRAIN Batch 58/2200 loss 6.332962 loss_att 11.114478 loss_ctc 10.207484 loss_rnnt 4.730316 hw_loss 0.243261 lr 0.00028433 rank 0
2023-03-01 15:19:10,627 DEBUG TRAIN Batch 58/2200 loss 3.733154 loss_att 6.871955 loss_ctc 7.500776 loss_rnnt 2.541743 hw_loss 0.114938 lr 0.00028433 rank 5
2023-03-01 15:19:10,635 DEBUG TRAIN Batch 58/2200 loss 7.295072 loss_att 13.015201 loss_ctc 15.343611 loss_rnnt 4.974721 hw_loss 0.193475 lr 0.00028433 rank 2
2023-03-01 15:19:49,472 DEBUG TRAIN Batch 58/2300 loss 5.670373 loss_att 9.371218 loss_ctc 11.719254 loss_rnnt 4.061234 hw_loss 0.117100 lr 0.00028432 rank 5
2023-03-01 15:19:49,485 DEBUG TRAIN Batch 58/2300 loss 8.845781 loss_att 11.964918 loss_ctc 21.965275 loss_rnnt 6.409213 hw_loss 0.119017 lr 0.00028431 rank 1
2023-03-01 15:19:49,486 DEBUG TRAIN Batch 58/2300 loss 4.470409 loss_att 7.689223 loss_ctc 7.566585 loss_rnnt 3.236221 hw_loss 0.333003 lr 0.00028431 rank 3
2023-03-01 15:19:49,487 DEBUG TRAIN Batch 58/2300 loss 2.998717 loss_att 6.968061 loss_ctc 6.111124 loss_rnnt 1.724841 hw_loss 0.121912 lr 0.00028432 rank 0
2023-03-01 15:19:49,488 DEBUG TRAIN Batch 58/2300 loss 2.952136 loss_att 5.753372 loss_ctc 6.786710 loss_rnnt 1.821539 hw_loss 0.110762 lr 0.00028431 rank 7
2023-03-01 15:19:49,490 DEBUG TRAIN Batch 58/2300 loss 9.674429 loss_att 12.704906 loss_ctc 15.729774 loss_rnnt 8.086988 hw_loss 0.326186 lr 0.00028432 rank 2
2023-03-01 15:19:49,493 DEBUG TRAIN Batch 58/2300 loss 2.175371 loss_att 4.675699 loss_ctc 3.035449 loss_rnnt 1.456592 hw_loss 0.195067 lr 0.00028432 rank 6
2023-03-01 15:19:49,503 DEBUG TRAIN Batch 58/2300 loss 8.097548 loss_att 10.197285 loss_ctc 15.062286 loss_rnnt 6.664383 hw_loss 0.158599 lr 0.00028431 rank 4
2023-03-01 15:20:28,468 DEBUG TRAIN Batch 58/2400 loss 3.611591 loss_att 5.837375 loss_ctc 5.765681 loss_rnnt 2.749864 hw_loss 0.242546 lr 0.00028430 rank 3
2023-03-01 15:20:28,470 DEBUG TRAIN Batch 58/2400 loss 5.039186 loss_att 6.831451 loss_ctc 7.235576 loss_rnnt 4.248434 hw_loss 0.261464 lr 0.00028430 rank 7
2023-03-01 15:20:28,471 DEBUG TRAIN Batch 58/2400 loss 11.990450 loss_att 14.443514 loss_ctc 18.895916 loss_rnnt 10.467604 hw_loss 0.209070 lr 0.00028430 rank 1
2023-03-01 15:20:28,472 DEBUG TRAIN Batch 58/2400 loss 3.354952 loss_att 6.178913 loss_ctc 7.980303 loss_rnnt 2.078011 hw_loss 0.178941 lr 0.00028430 rank 4
2023-03-01 15:20:28,474 DEBUG TRAIN Batch 58/2400 loss 5.636511 loss_att 9.446938 loss_ctc 15.496535 loss_rnnt 3.447636 hw_loss 0.210223 lr 0.00028431 rank 0
2023-03-01 15:20:28,476 DEBUG TRAIN Batch 58/2400 loss 5.242143 loss_att 7.193309 loss_ctc 8.479474 loss_rnnt 4.273720 hw_loss 0.274771 lr 0.00028431 rank 5
2023-03-01 15:20:28,476 DEBUG TRAIN Batch 58/2400 loss 5.057345 loss_att 7.893145 loss_ctc 7.882654 loss_rnnt 4.033380 hw_loss 0.150183 lr 0.00028430 rank 2
2023-03-01 15:20:28,481 DEBUG TRAIN Batch 58/2400 loss 9.412908 loss_att 10.814212 loss_ctc 13.454455 loss_rnnt 8.463243 hw_loss 0.244743 lr 0.00028431 rank 6
2023-03-01 15:21:34,517 DEBUG TRAIN Batch 58/2500 loss 5.688859 loss_att 6.437081 loss_ctc 7.175434 loss_rnnt 5.173796 hw_loss 0.313515 lr 0.00028430 rank 6
2023-03-01 15:21:34,519 DEBUG TRAIN Batch 58/2500 loss 5.163204 loss_att 7.153602 loss_ctc 7.384838 loss_rnnt 4.362918 hw_loss 0.198728 lr 0.00028430 rank 5
2023-03-01 15:21:34,523 DEBUG TRAIN Batch 58/2500 loss 5.794047 loss_att 6.200518 loss_ctc 6.895496 loss_rnnt 5.448840 hw_loss 0.219476 lr 0.00028429 rank 7
2023-03-01 15:21:34,528 DEBUG TRAIN Batch 58/2500 loss 7.588609 loss_att 7.261406 loss_ctc 10.952356 loss_rnnt 7.003245 hw_loss 0.379322 lr 0.00028430 rank 0
2023-03-01 15:21:34,528 DEBUG TRAIN Batch 58/2500 loss 8.980316 loss_att 8.854598 loss_ctc 12.756808 loss_rnnt 8.376704 hw_loss 0.234795 lr 0.00028429 rank 2
2023-03-01 15:21:34,532 DEBUG TRAIN Batch 58/2500 loss 4.431662 loss_att 5.387590 loss_ctc 5.034290 loss_rnnt 4.045694 hw_loss 0.214558 lr 0.00028429 rank 4
2023-03-01 15:21:34,534 DEBUG TRAIN Batch 58/2500 loss 6.625394 loss_att 10.117099 loss_ctc 11.551073 loss_rnnt 5.101242 hw_loss 0.316977 lr 0.00028429 rank 3
2023-03-01 15:21:34,541 DEBUG TRAIN Batch 58/2500 loss 4.273179 loss_att 5.479705 loss_ctc 6.624203 loss_rnnt 3.569505 hw_loss 0.279184 lr 0.00028429 rank 1
2023-03-01 15:22:13,369 DEBUG TRAIN Batch 58/2600 loss 4.403102 loss_att 7.943680 loss_ctc 8.226772 loss_rnnt 3.110923 hw_loss 0.139203 lr 0.00028428 rank 4
2023-03-01 15:22:13,380 DEBUG TRAIN Batch 58/2600 loss 3.926144 loss_att 6.986101 loss_ctc 7.184062 loss_rnnt 2.791019 hw_loss 0.166395 lr 0.00028429 rank 0
2023-03-01 15:22:13,382 DEBUG TRAIN Batch 58/2600 loss 4.855612 loss_att 6.528868 loss_ctc 9.540461 loss_rnnt 3.774431 hw_loss 0.228532 lr 0.00028428 rank 1
2023-03-01 15:22:13,384 DEBUG TRAIN Batch 58/2600 loss 1.618251 loss_att 3.732540 loss_ctc 3.488168 loss_rnnt 0.845742 hw_loss 0.188117 lr 0.00028428 rank 5
2023-03-01 15:22:13,383 DEBUG TRAIN Batch 58/2600 loss 6.854671 loss_att 11.675355 loss_ctc 10.788191 loss_rnnt 5.315907 hw_loss 0.094045 lr 0.00028428 rank 7
2023-03-01 15:22:13,384 DEBUG TRAIN Batch 58/2600 loss 6.980387 loss_att 12.345783 loss_ctc 11.628246 loss_rnnt 5.223703 hw_loss 0.119792 lr 0.00028428 rank 3
2023-03-01 15:22:13,387 DEBUG TRAIN Batch 58/2600 loss 1.585775 loss_att 4.987618 loss_ctc 3.263211 loss_rnnt 0.586035 hw_loss 0.179462 lr 0.00028429 rank 6
2023-03-01 15:22:13,389 DEBUG TRAIN Batch 58/2600 loss 4.608812 loss_att 6.987264 loss_ctc 8.924551 loss_rnnt 3.518153 hw_loss 0.074132 lr 0.00028428 rank 2
2023-03-01 15:22:51,889 DEBUG TRAIN Batch 58/2700 loss 6.004236 loss_att 7.813466 loss_ctc 6.882291 loss_rnnt 5.391303 hw_loss 0.251274 lr 0.00028427 rank 7
2023-03-01 15:22:51,892 DEBUG TRAIN Batch 58/2700 loss 1.437444 loss_att 3.818905 loss_ctc 3.024240 loss_rnnt 0.598782 hw_loss 0.282746 lr 0.00028427 rank 3
2023-03-01 15:22:51,894 DEBUG TRAIN Batch 58/2700 loss 4.697312 loss_att 8.178547 loss_ctc 7.807329 loss_rnnt 3.515308 hw_loss 0.133291 lr 0.00028426 rank 1
2023-03-01 15:22:51,894 DEBUG TRAIN Batch 58/2700 loss 3.210060 loss_att 6.663882 loss_ctc 5.647969 loss_rnnt 2.103163 hw_loss 0.170770 lr 0.00028427 rank 2
2023-03-01 15:22:51,897 DEBUG TRAIN Batch 58/2700 loss 8.061920 loss_att 8.093966 loss_ctc 10.145297 loss_rnnt 7.647333 hw_loss 0.244490 lr 0.00028427 rank 5
2023-03-01 15:22:51,896 DEBUG TRAIN Batch 58/2700 loss 1.822733 loss_att 4.484756 loss_ctc 3.760073 loss_rnnt 0.899553 hw_loss 0.248370 lr 0.00028428 rank 0
2023-03-01 15:22:51,897 DEBUG TRAIN Batch 58/2700 loss 7.581295 loss_att 9.934014 loss_ctc 11.143927 loss_rnnt 6.544897 hw_loss 0.170319 lr 0.00028428 rank 6
2023-03-01 15:22:51,938 DEBUG TRAIN Batch 58/2700 loss 5.692911 loss_att 8.492850 loss_ctc 11.906805 loss_rnnt 4.282529 hw_loss 0.041015 lr 0.00028427 rank 4
2023-03-01 15:23:31,486 DEBUG TRAIN Batch 58/2800 loss 6.126996 loss_att 11.292918 loss_ctc 9.746443 loss_rnnt 4.524278 hw_loss 0.163014 lr 0.00028426 rank 2
2023-03-01 15:23:31,488 DEBUG TRAIN Batch 58/2800 loss 7.025717 loss_att 9.783216 loss_ctc 13.741168 loss_rnnt 5.503882 hw_loss 0.140516 lr 0.00028426 rank 7
2023-03-01 15:23:31,492 DEBUG TRAIN Batch 58/2800 loss 5.323275 loss_att 8.099911 loss_ctc 6.754656 loss_rnnt 4.480709 hw_loss 0.180728 lr 0.00028426 rank 6
2023-03-01 15:23:31,501 DEBUG TRAIN Batch 58/2800 loss 1.214242 loss_att 2.777067 loss_ctc 3.671999 loss_rnnt 0.445826 hw_loss 0.240281 lr 0.00028425 rank 4
2023-03-01 15:23:31,505 DEBUG TRAIN Batch 58/2800 loss 10.568533 loss_att 13.535597 loss_ctc 20.533073 loss_rnnt 8.499419 hw_loss 0.275802 lr 0.00028427 rank 0
2023-03-01 15:23:31,519 DEBUG TRAIN Batch 58/2800 loss 6.994677 loss_att 12.070887 loss_ctc 15.622397 loss_rnnt 4.745192 hw_loss 0.157277 lr 0.00028426 rank 5
2023-03-01 15:23:31,529 DEBUG TRAIN Batch 58/2800 loss 1.537882 loss_att 4.035857 loss_ctc 3.007916 loss_rnnt 0.732648 hw_loss 0.205565 lr 0.00028426 rank 3
2023-03-01 15:23:31,531 DEBUG TRAIN Batch 58/2800 loss 7.426552 loss_att 9.699888 loss_ctc 14.317000 loss_rnnt 5.931357 hw_loss 0.228377 lr 0.00028425 rank 1
2023-03-01 15:24:35,759 DEBUG TRAIN Batch 58/2900 loss 2.256029 loss_att 4.741378 loss_ctc 2.750522 loss_rnnt 1.548024 hw_loss 0.271880 lr 0.00028424 rank 4
2023-03-01 15:24:35,775 DEBUG TRAIN Batch 58/2900 loss 14.365009 loss_att 16.662739 loss_ctc 24.914379 loss_rnnt 12.396369 hw_loss 0.192211 lr 0.00028425 rank 0
2023-03-01 15:24:35,775 DEBUG TRAIN Batch 58/2900 loss 9.322629 loss_att 14.038828 loss_ctc 12.405006 loss_rnnt 7.913279 hw_loss 0.103361 lr 0.00028425 rank 2
2023-03-01 15:24:35,777 DEBUG TRAIN Batch 58/2900 loss 2.918045 loss_att 6.375623 loss_ctc 5.663464 loss_rnnt 1.676482 hw_loss 0.344985 lr 0.00028424 rank 7
2023-03-01 15:24:35,778 DEBUG TRAIN Batch 58/2900 loss 3.143681 loss_att 6.992978 loss_ctc 5.673645 loss_rnnt 1.987384 hw_loss 0.092077 lr 0.00028424 rank 3
2023-03-01 15:24:35,779 DEBUG TRAIN Batch 58/2900 loss 6.364295 loss_att 8.032045 loss_ctc 9.552781 loss_rnnt 5.537549 hw_loss 0.127620 lr 0.00028425 rank 5
2023-03-01 15:24:35,782 DEBUG TRAIN Batch 58/2900 loss 5.200110 loss_att 10.907121 loss_ctc 13.937999 loss_rnnt 2.793509 hw_loss 0.187775 lr 0.00028424 rank 1
2023-03-01 15:24:35,797 DEBUG TRAIN Batch 58/2900 loss 7.181560 loss_att 9.983955 loss_ctc 11.834717 loss_rnnt 5.849838 hw_loss 0.282789 lr 0.00028425 rank 6
2023-03-01 15:25:14,580 DEBUG TRAIN Batch 58/3000 loss 6.190809 loss_att 7.808678 loss_ctc 8.788220 loss_rnnt 5.427391 hw_loss 0.175355 lr 0.00028423 rank 1
2023-03-01 15:25:14,587 DEBUG TRAIN Batch 58/3000 loss 0.885798 loss_att 2.483119 loss_ctc 0.957705 loss_rnnt 0.401276 hw_loss 0.291508 lr 0.00028424 rank 2
2023-03-01 15:25:14,595 DEBUG TRAIN Batch 58/3000 loss 4.492552 loss_att 9.182050 loss_ctc 11.039552 loss_rnnt 2.553681 hw_loss 0.240071 lr 0.00028423 rank 3
2023-03-01 15:25:14,596 DEBUG TRAIN Batch 58/3000 loss 2.774961 loss_att 5.991734 loss_ctc 4.437685 loss_rnnt 1.849481 hw_loss 0.113303 lr 0.00028424 rank 6
2023-03-01 15:25:14,598 DEBUG TRAIN Batch 58/3000 loss 13.074701 loss_att 16.118858 loss_ctc 21.977839 loss_rnnt 11.183150 hw_loss 0.179317 lr 0.00028423 rank 7
2023-03-01 15:25:14,598 DEBUG TRAIN Batch 58/3000 loss 5.151301 loss_att 8.643896 loss_ctc 11.745101 loss_rnnt 3.468259 hw_loss 0.197530 lr 0.00028424 rank 0
2023-03-01 15:25:14,599 DEBUG TRAIN Batch 58/3000 loss 4.247547 loss_att 6.602281 loss_ctc 4.985441 loss_rnnt 3.589973 hw_loss 0.165453 lr 0.00028423 rank 4
2023-03-01 15:25:14,649 DEBUG TRAIN Batch 58/3000 loss 4.180392 loss_att 6.492887 loss_ctc 7.720702 loss_rnnt 3.083423 hw_loss 0.304553 lr 0.00028424 rank 5
2023-03-01 15:25:53,483 DEBUG TRAIN Batch 58/3100 loss 7.849060 loss_att 9.842598 loss_ctc 13.091146 loss_rnnt 6.669848 hw_loss 0.152924 lr 0.00028423 rank 0
2023-03-01 15:25:53,483 DEBUG TRAIN Batch 58/3100 loss 3.986627 loss_att 5.061990 loss_ctc 7.132634 loss_rnnt 3.235071 hw_loss 0.219404 lr 0.00028422 rank 4
2023-03-01 15:25:53,484 DEBUG TRAIN Batch 58/3100 loss 9.051120 loss_att 11.640279 loss_ctc 17.156960 loss_rnnt 7.317028 hw_loss 0.254028 lr 0.00028423 rank 6
2023-03-01 15:25:53,486 DEBUG TRAIN Batch 58/3100 loss 2.313282 loss_att 4.076111 loss_ctc 3.609569 loss_rnnt 1.680359 hw_loss 0.201599 lr 0.00028422 rank 7
2023-03-01 15:25:53,486 DEBUG TRAIN Batch 58/3100 loss 7.786252 loss_att 9.533402 loss_ctc 15.774042 loss_rnnt 6.287148 hw_loss 0.158691 lr 0.00028422 rank 3
2023-03-01 15:25:53,491 DEBUG TRAIN Batch 58/3100 loss 3.887204 loss_att 5.984584 loss_ctc 7.019711 loss_rnnt 2.953817 hw_loss 0.180457 lr 0.00028422 rank 2
2023-03-01 15:25:53,491 DEBUG TRAIN Batch 58/3100 loss 8.425722 loss_att 9.933402 loss_ctc 14.856125 loss_rnnt 7.165423 hw_loss 0.190080 lr 0.00028422 rank 1
2023-03-01 15:25:53,494 DEBUG TRAIN Batch 58/3100 loss 4.082736 loss_att 8.144053 loss_ctc 7.591035 loss_rnnt 2.751573 hw_loss 0.095864 lr 0.00028423 rank 5
2023-03-01 15:26:58,846 DEBUG TRAIN Batch 58/3200 loss 4.823222 loss_att 6.642054 loss_ctc 7.885396 loss_rnnt 3.921129 hw_loss 0.243820 lr 0.00028421 rank 1
2023-03-01 15:26:58,853 DEBUG TRAIN Batch 58/3200 loss 9.663637 loss_att 10.054672 loss_ctc 14.971675 loss_rnnt 8.751076 hw_loss 0.237406 lr 0.00028422 rank 6
2023-03-01 15:26:58,856 DEBUG TRAIN Batch 58/3200 loss 3.287955 loss_att 5.492920 loss_ctc 6.783408 loss_rnnt 2.314788 hw_loss 0.123962 lr 0.00028422 rank 5
2023-03-01 15:26:58,873 DEBUG TRAIN Batch 58/3200 loss 4.722012 loss_att 6.363338 loss_ctc 4.289373 loss_rnnt 4.287808 hw_loss 0.306793 lr 0.00028421 rank 2
2023-03-01 15:26:58,874 DEBUG TRAIN Batch 58/3200 loss 12.204481 loss_att 12.329441 loss_ctc 16.941603 loss_rnnt 11.478651 hw_loss 0.129790 lr 0.00028421 rank 7
2023-03-01 15:26:58,874 DEBUG TRAIN Batch 58/3200 loss 2.685308 loss_att 6.032638 loss_ctc 4.109129 loss_rnnt 1.719658 hw_loss 0.199390 lr 0.00028421 rank 4
2023-03-01 15:26:58,883 DEBUG TRAIN Batch 58/3200 loss 4.410614 loss_att 6.966518 loss_ctc 7.631953 loss_rnnt 3.405763 hw_loss 0.120297 lr 0.00028422 rank 0
2023-03-01 15:26:58,885 DEBUG TRAIN Batch 58/3200 loss 4.402666 loss_att 7.337183 loss_ctc 4.997738 loss_rnnt 3.615503 hw_loss 0.226718 lr 0.00028421 rank 3
2023-03-01 15:27:38,026 DEBUG TRAIN Batch 58/3300 loss 3.695501 loss_att 6.549525 loss_ctc 7.067654 loss_rnnt 2.490928 hw_loss 0.345279 lr 0.00028421 rank 0
2023-03-01 15:27:38,028 DEBUG TRAIN Batch 58/3300 loss 5.696748 loss_att 7.533010 loss_ctc 11.435062 loss_rnnt 4.448897 hw_loss 0.216543 lr 0.00028420 rank 7
2023-03-01 15:27:38,029 DEBUG TRAIN Batch 58/3300 loss 10.268868 loss_att 14.937182 loss_ctc 19.747900 loss_rnnt 7.995569 hw_loss 0.142062 lr 0.00028420 rank 2
2023-03-01 15:27:38,029 DEBUG TRAIN Batch 58/3300 loss 1.907850 loss_att 6.891760 loss_ctc 3.921721 loss_rnnt 0.621943 hw_loss 0.038641 lr 0.00028420 rank 5
2023-03-01 15:27:38,030 DEBUG TRAIN Batch 58/3300 loss 1.893857 loss_att 4.296903 loss_ctc 3.240385 loss_rnnt 1.089206 hw_loss 0.270945 lr 0.00028420 rank 3
2023-03-01 15:27:38,032 DEBUG TRAIN Batch 58/3300 loss 5.532920 loss_att 7.231633 loss_ctc 11.160593 loss_rnnt 4.308537 hw_loss 0.251784 lr 0.00028420 rank 1
2023-03-01 15:27:38,032 DEBUG TRAIN Batch 58/3300 loss 4.938444 loss_att 9.995824 loss_ctc 11.714305 loss_rnnt 2.904195 hw_loss 0.223735 lr 0.00028421 rank 6
2023-03-01 15:27:38,035 DEBUG TRAIN Batch 58/3300 loss 5.672771 loss_att 7.764792 loss_ctc 9.553278 loss_rnnt 4.549828 hw_loss 0.350886 lr 0.00028420 rank 4
2023-03-01 15:28:16,885 DEBUG TRAIN Batch 58/3400 loss 3.695954 loss_att 7.648775 loss_ctc 8.551638 loss_rnnt 2.203141 hw_loss 0.102794 lr 0.00028418 rank 1
2023-03-01 15:28:16,889 DEBUG TRAIN Batch 58/3400 loss 3.298407 loss_att 5.972514 loss_ctc 5.781743 loss_rnnt 2.339901 hw_loss 0.173574 lr 0.00028419 rank 7
2023-03-01 15:28:16,890 DEBUG TRAIN Batch 58/3400 loss 10.664477 loss_att 13.734869 loss_ctc 20.457214 loss_rnnt 8.696211 hw_loss 0.090919 lr 0.00028419 rank 2
2023-03-01 15:28:16,891 DEBUG TRAIN Batch 58/3400 loss 7.190013 loss_att 9.030598 loss_ctc 7.939912 loss_rnnt 6.625149 hw_loss 0.181428 lr 0.00028420 rank 6
2023-03-01 15:28:16,894 DEBUG TRAIN Batch 58/3400 loss 1.899271 loss_att 4.567081 loss_ctc 3.720330 loss_rnnt 0.993954 hw_loss 0.241775 lr 0.00028419 rank 3
2023-03-01 15:28:16,901 DEBUG TRAIN Batch 58/3400 loss 3.229239 loss_att 7.796976 loss_ctc 6.487761 loss_rnnt 1.717784 hw_loss 0.306445 lr 0.00028419 rank 4
2023-03-01 15:28:16,906 DEBUG TRAIN Batch 58/3400 loss 1.925649 loss_att 4.957481 loss_ctc 3.516960 loss_rnnt 0.982532 hw_loss 0.233580 lr 0.00028420 rank 0
2023-03-01 15:28:16,909 DEBUG TRAIN Batch 58/3400 loss 7.934232 loss_att 9.553528 loss_ctc 10.266608 loss_rnnt 7.188277 hw_loss 0.208335 lr 0.00028419 rank 5
2023-03-01 15:28:56,325 DEBUG TRAIN Batch 58/3500 loss 9.909085 loss_att 12.741844 loss_ctc 18.929338 loss_rnnt 7.954906 hw_loss 0.346737 lr 0.00028417 rank 1
2023-03-01 15:28:56,326 DEBUG TRAIN Batch 58/3500 loss 3.756446 loss_att 5.705130 loss_ctc 6.562057 loss_rnnt 2.889065 hw_loss 0.194180 lr 0.00028417 rank 4
2023-03-01 15:28:56,329 DEBUG TRAIN Batch 58/3500 loss 4.335216 loss_att 7.672689 loss_ctc 6.808287 loss_rnnt 3.209633 hw_loss 0.240647 lr 0.00028418 rank 2
2023-03-01 15:28:56,330 DEBUG TRAIN Batch 58/3500 loss 4.676092 loss_att 6.186877 loss_ctc 5.612650 loss_rnnt 4.091204 hw_loss 0.295981 lr 0.00028419 rank 0
2023-03-01 15:28:56,332 DEBUG TRAIN Batch 58/3500 loss 6.210440 loss_att 8.114796 loss_ctc 10.791706 loss_rnnt 5.052274 hw_loss 0.312113 lr 0.00028418 rank 3
2023-03-01 15:28:56,332 DEBUG TRAIN Batch 58/3500 loss 2.722282 loss_att 5.782432 loss_ctc 5.600259 loss_rnnt 1.650916 hw_loss 0.141760 lr 0.00028418 rank 6
2023-03-01 15:28:56,344 DEBUG TRAIN Batch 58/3500 loss 5.798409 loss_att 8.363573 loss_ctc 8.178298 loss_rnnt 4.880750 hw_loss 0.163703 lr 0.00028418 rank 7
2023-03-01 15:28:56,357 DEBUG TRAIN Batch 58/3500 loss 4.159687 loss_att 7.764844 loss_ctc 10.470837 loss_rnnt 2.525452 hw_loss 0.134470 lr 0.00028418 rank 5
2023-03-01 15:30:00,972 DEBUG TRAIN Batch 58/3600 loss 6.538575 loss_att 8.161503 loss_ctc 11.929329 loss_rnnt 5.334760 hw_loss 0.300866 lr 0.00028417 rank 0
2023-03-01 15:30:00,974 DEBUG TRAIN Batch 58/3600 loss 9.846504 loss_att 12.829224 loss_ctc 17.115128 loss_rnnt 8.222656 hw_loss 0.109039 lr 0.00028416 rank 7
2023-03-01 15:30:00,978 DEBUG TRAIN Batch 58/3600 loss 9.407990 loss_att 13.883195 loss_ctc 22.825253 loss_rnnt 6.623449 hw_loss 0.188494 lr 0.00028416 rank 3
2023-03-01 15:30:00,978 DEBUG TRAIN Batch 58/3600 loss 13.469196 loss_att 16.770527 loss_ctc 22.513992 loss_rnnt 11.439528 hw_loss 0.306432 lr 0.00028416 rank 4
2023-03-01 15:30:00,977 DEBUG TRAIN Batch 58/3600 loss 5.123205 loss_att 9.737735 loss_ctc 9.890508 loss_rnnt 3.430301 hw_loss 0.251922 lr 0.00028416 rank 1
2023-03-01 15:30:00,979 DEBUG TRAIN Batch 58/3600 loss 6.242233 loss_att 7.138574 loss_ctc 11.355112 loss_rnnt 5.223685 hw_loss 0.295429 lr 0.00028417 rank 2
2023-03-01 15:30:00,982 DEBUG TRAIN Batch 58/3600 loss 6.736245 loss_att 10.491186 loss_ctc 12.090550 loss_rnnt 5.177900 hw_loss 0.175218 lr 0.00028417 rank 5
2023-03-01 15:30:00,984 DEBUG TRAIN Batch 58/3600 loss 6.589942 loss_att 9.040394 loss_ctc 10.632092 loss_rnnt 5.426988 hw_loss 0.251082 lr 0.00028417 rank 6
2023-03-01 15:30:39,785 DEBUG TRAIN Batch 58/3700 loss 6.165409 loss_att 7.587425 loss_ctc 11.393505 loss_rnnt 5.092873 hw_loss 0.170726 lr 0.00028416 rank 5
2023-03-01 15:30:39,800 DEBUG TRAIN Batch 58/3700 loss 7.583456 loss_att 9.465379 loss_ctc 10.949066 loss_rnnt 6.625874 hw_loss 0.248342 lr 0.00028416 rank 0
2023-03-01 15:30:39,800 DEBUG TRAIN Batch 58/3700 loss 8.795620 loss_att 11.305973 loss_ctc 13.921567 loss_rnnt 7.526310 hw_loss 0.157087 lr 0.00028416 rank 6
2023-03-01 15:30:39,801 DEBUG TRAIN Batch 58/3700 loss 5.304580 loss_att 7.506884 loss_ctc 8.330842 loss_rnnt 4.378148 hw_loss 0.154630 lr 0.00028415 rank 7
2023-03-01 15:30:39,801 DEBUG TRAIN Batch 58/3700 loss 1.266453 loss_att 3.192842 loss_ctc 2.077144 loss_rnnt 0.693860 hw_loss 0.148543 lr 0.00028415 rank 1
2023-03-01 15:30:39,805 DEBUG TRAIN Batch 58/3700 loss 9.379224 loss_att 11.188670 loss_ctc 14.085071 loss_rnnt 8.313727 hw_loss 0.142801 lr 0.00028415 rank 4
2023-03-01 15:30:39,808 DEBUG TRAIN Batch 58/3700 loss 5.763506 loss_att 8.490614 loss_ctc 9.939821 loss_rnnt 4.499624 hw_loss 0.303035 lr 0.00028415 rank 2
2023-03-01 15:30:39,825 DEBUG TRAIN Batch 58/3700 loss 12.248267 loss_att 12.912101 loss_ctc 15.435740 loss_rnnt 11.587679 hw_loss 0.192795 lr 0.00028415 rank 3
2023-03-01 15:31:18,090 DEBUG TRAIN Batch 58/3800 loss 8.982933 loss_att 12.508476 loss_ctc 15.967211 loss_rnnt 7.206620 hw_loss 0.262438 lr 0.00028415 rank 5
2023-03-01 15:31:18,101 DEBUG TRAIN Batch 58/3800 loss 2.671012 loss_att 7.438615 loss_ctc 6.568440 loss_rnnt 1.074818 hw_loss 0.230655 lr 0.00028415 rank 0
2023-03-01 15:31:18,104 DEBUG TRAIN Batch 58/3800 loss 10.744497 loss_att 10.985404 loss_ctc 17.391651 loss_rnnt 9.695723 hw_loss 0.214324 lr 0.00028414 rank 4
2023-03-01 15:31:18,104 DEBUG TRAIN Batch 58/3800 loss 3.364398 loss_att 5.849767 loss_ctc 6.395179 loss_rnnt 2.383694 hw_loss 0.149111 lr 0.00028414 rank 3
2023-03-01 15:31:18,105 DEBUG TRAIN Batch 58/3800 loss 4.285142 loss_att 6.220661 loss_ctc 8.059628 loss_rnnt 3.236788 hw_loss 0.296224 lr 0.00028415 rank 6
2023-03-01 15:31:18,106 DEBUG TRAIN Batch 58/3800 loss 10.231441 loss_att 11.084427 loss_ctc 13.770287 loss_rnnt 9.504061 hw_loss 0.159256 lr 0.00028414 rank 7
2023-03-01 15:31:18,106 DEBUG TRAIN Batch 58/3800 loss 4.366067 loss_att 8.040469 loss_ctc 9.917240 loss_rnnt 2.724524 hw_loss 0.312198 lr 0.00028414 rank 2
2023-03-01 15:31:18,150 DEBUG TRAIN Batch 58/3800 loss 7.384951 loss_att 9.502851 loss_ctc 13.311017 loss_rnnt 6.053682 hw_loss 0.220398 lr 0.00028414 rank 1
2023-03-01 15:31:57,968 DEBUG TRAIN Batch 58/3900 loss 5.626488 loss_att 10.680265 loss_ctc 10.894145 loss_rnnt 3.847497 hw_loss 0.123527 lr 0.00028414 rank 6
2023-03-01 15:31:57,972 DEBUG TRAIN Batch 58/3900 loss 3.946475 loss_att 6.664047 loss_ctc 9.226816 loss_rnnt 2.646549 hw_loss 0.098186 lr 0.00028413 rank 3
2023-03-01 15:31:57,980 DEBUG TRAIN Batch 58/3900 loss 2.222806 loss_att 5.572658 loss_ctc 4.014449 loss_rnnt 1.220078 hw_loss 0.176010 lr 0.00028413 rank 4
2023-03-01 15:31:57,981 DEBUG TRAIN Batch 58/3900 loss 8.688434 loss_att 14.071493 loss_ctc 17.078968 loss_rnnt 6.329454 hw_loss 0.306807 lr 0.00028414 rank 5
2023-03-01 15:31:57,981 DEBUG TRAIN Batch 58/3900 loss 4.719512 loss_att 7.925462 loss_ctc 9.801687 loss_rnnt 3.347776 hw_loss 0.099229 lr 0.00028414 rank 0
2023-03-01 15:31:57,981 DEBUG TRAIN Batch 58/3900 loss 8.390874 loss_att 13.193810 loss_ctc 13.424173 loss_rnnt 6.575315 hw_loss 0.344749 lr 0.00028413 rank 7
2023-03-01 15:31:57,986 DEBUG TRAIN Batch 58/3900 loss 2.902326 loss_att 6.008416 loss_ctc 5.381409 loss_rnnt 1.754886 hw_loss 0.366895 lr 0.00028413 rank 1
2023-03-01 15:31:57,988 DEBUG TRAIN Batch 58/3900 loss 14.235968 loss_att 19.123077 loss_ctc 32.693657 loss_rnnt 10.624395 hw_loss 0.324609 lr 0.00028413 rank 2
2023-03-01 15:33:03,731 DEBUG TRAIN Batch 58/4000 loss 9.987638 loss_att 13.383017 loss_ctc 15.053524 loss_rnnt 8.558940 hw_loss 0.139069 lr 0.00028412 rank 2
2023-03-01 15:33:03,743 DEBUG TRAIN Batch 58/4000 loss 4.466043 loss_att 6.508975 loss_ctc 6.182859 loss_rnnt 3.706805 hw_loss 0.228269 lr 0.00028413 rank 0
2023-03-01 15:33:03,747 DEBUG TRAIN Batch 58/4000 loss 6.561126 loss_att 7.771223 loss_ctc 8.360453 loss_rnnt 6.002711 hw_loss 0.143411 lr 0.00028412 rank 3
2023-03-01 15:33:03,750 DEBUG TRAIN Batch 58/4000 loss 3.209241 loss_att 5.242487 loss_ctc 5.836690 loss_rnnt 2.295935 hw_loss 0.293118 lr 0.00028412 rank 7
2023-03-01 15:33:03,751 DEBUG TRAIN Batch 58/4000 loss 2.100204 loss_att 5.129102 loss_ctc 3.270724 loss_rnnt 1.185516 hw_loss 0.286572 lr 0.00028412 rank 1
2023-03-01 15:33:03,752 DEBUG TRAIN Batch 58/4000 loss 4.502646 loss_att 8.540505 loss_ctc 7.732941 loss_rnnt 3.115668 hw_loss 0.278814 lr 0.00028413 rank 6
2023-03-01 15:33:03,759 DEBUG TRAIN Batch 58/4000 loss 8.816692 loss_att 9.905029 loss_ctc 11.022559 loss_rnnt 8.204918 hw_loss 0.187482 lr 0.00028412 rank 4
2023-03-01 15:33:03,771 DEBUG TRAIN Batch 58/4000 loss 6.048542 loss_att 9.522629 loss_ctc 12.174550 loss_rnnt 4.389565 hw_loss 0.276295 lr 0.00028412 rank 5
2023-03-01 15:33:41,737 DEBUG TRAIN Batch 58/4100 loss 7.820824 loss_att 10.824148 loss_ctc 13.844285 loss_rnnt 6.304745 hw_loss 0.210534 lr 0.00028411 rank 4
2023-03-01 15:33:41,738 DEBUG TRAIN Batch 58/4100 loss 7.879275 loss_att 10.363875 loss_ctc 10.949332 loss_rnnt 6.918231 hw_loss 0.102718 lr 0.00028411 rank 5
2023-03-01 15:33:41,749 DEBUG TRAIN Batch 58/4100 loss 4.150049 loss_att 6.893022 loss_ctc 5.282790 loss_rnnt 3.255182 hw_loss 0.366076 lr 0.00028410 rank 1
2023-03-01 15:33:41,753 DEBUG TRAIN Batch 58/4100 loss 1.389963 loss_att 4.107026 loss_ctc 2.139387 loss_rnnt 0.666562 hw_loss 0.150121 lr 0.00028412 rank 0
2023-03-01 15:33:41,753 DEBUG TRAIN Batch 58/4100 loss 4.779882 loss_att 7.547257 loss_ctc 5.587442 loss_rnnt 4.036423 hw_loss 0.154331 lr 0.00028411 rank 3
2023-03-01 15:33:41,756 DEBUG TRAIN Batch 58/4100 loss 5.109997 loss_att 7.627951 loss_ctc 7.994220 loss_rnnt 4.159457 hw_loss 0.116974 lr 0.00028411 rank 6
2023-03-01 15:33:41,763 DEBUG TRAIN Batch 58/4100 loss 19.034880 loss_att 21.657902 loss_ctc 28.422203 loss_rnnt 17.120142 hw_loss 0.259669 lr 0.00028411 rank 7
2023-03-01 15:33:41,769 DEBUG TRAIN Batch 58/4100 loss 4.585593 loss_att 6.920637 loss_ctc 8.993349 loss_rnnt 3.375674 hw_loss 0.291018 lr 0.00028411 rank 2
2023-03-01 15:34:20,786 DEBUG TRAIN Batch 58/4200 loss 4.549571 loss_att 5.737887 loss_ctc 6.289172 loss_rnnt 3.954928 hw_loss 0.234435 lr 0.00028410 rank 2
2023-03-01 15:34:20,787 DEBUG TRAIN Batch 58/4200 loss 4.588311 loss_att 6.054851 loss_ctc 3.758313 loss_rnnt 4.342342 hw_loss 0.118737 lr 0.00028410 rank 6
2023-03-01 15:34:20,789 DEBUG TRAIN Batch 58/4200 loss 4.220094 loss_att 6.105144 loss_ctc 5.656962 loss_rnnt 3.528007 hw_loss 0.231552 lr 0.00028410 rank 7
2023-03-01 15:34:20,797 DEBUG TRAIN Batch 58/4200 loss 9.430398 loss_att 12.455595 loss_ctc 12.247034 loss_rnnt 8.314987 hw_loss 0.252787 lr 0.00028410 rank 5
2023-03-01 15:34:20,799 DEBUG TRAIN Batch 58/4200 loss 6.038615 loss_att 8.930950 loss_ctc 9.029192 loss_rnnt 4.997545 hw_loss 0.119736 lr 0.00028410 rank 3
2023-03-01 15:34:20,800 DEBUG TRAIN Batch 58/4200 loss 2.185222 loss_att 4.530952 loss_ctc 3.249032 loss_rnnt 1.452235 hw_loss 0.228751 lr 0.00028409 rank 4
2023-03-01 15:34:20,802 DEBUG TRAIN Batch 58/4200 loss 3.034311 loss_att 6.887231 loss_ctc 6.103577 loss_rnnt 1.745247 hw_loss 0.204835 lr 0.00028411 rank 0
2023-03-01 15:34:20,824 DEBUG TRAIN Batch 58/4200 loss 6.717085 loss_att 10.161637 loss_ctc 9.097280 loss_rnnt 5.595205 hw_loss 0.216769 lr 0.00028409 rank 1
2023-03-01 15:35:27,738 DEBUG TRAIN Batch 58/4300 loss 14.013797 loss_att 16.181791 loss_ctc 17.712540 loss_rnnt 13.002235 hw_loss 0.158995 lr 0.00028409 rank 2
2023-03-01 15:35:27,743 DEBUG TRAIN Batch 58/4300 loss 3.404597 loss_att 6.465764 loss_ctc 7.163763 loss_rnnt 2.222090 hw_loss 0.129471 lr 0.00028409 rank 6
2023-03-01 15:35:27,745 DEBUG TRAIN Batch 58/4300 loss 4.376873 loss_att 7.069027 loss_ctc 8.190944 loss_rnnt 3.185809 hw_loss 0.270169 lr 0.00028408 rank 7
2023-03-01 15:35:27,744 DEBUG TRAIN Batch 58/4300 loss 1.971143 loss_att 4.396804 loss_ctc 4.486076 loss_rnnt 0.999476 hw_loss 0.283521 lr 0.00028408 rank 1
2023-03-01 15:35:27,746 DEBUG TRAIN Batch 58/4300 loss 8.926476 loss_att 9.219952 loss_ctc 14.747589 loss_rnnt 8.006092 hw_loss 0.160390 lr 0.00028408 rank 4
2023-03-01 15:35:27,749 DEBUG TRAIN Batch 58/4300 loss 4.646901 loss_att 6.103986 loss_ctc 9.982928 loss_rnnt 3.463964 hw_loss 0.337594 lr 0.00028409 rank 0
2023-03-01 15:35:27,750 DEBUG TRAIN Batch 58/4300 loss 5.758704 loss_att 8.735743 loss_ctc 9.786727 loss_rnnt 4.566304 hw_loss 0.112353 lr 0.00028409 rank 5
2023-03-01 15:35:27,757 DEBUG TRAIN Batch 58/4300 loss 8.258846 loss_att 12.047939 loss_ctc 16.869505 loss_rnnt 6.254572 hw_loss 0.184438 lr 0.00028408 rank 3
2023-03-01 15:36:06,294 DEBUG TRAIN Batch 58/4400 loss 11.373680 loss_att 13.473852 loss_ctc 17.609343 loss_rnnt 10.077464 hw_loss 0.083926 lr 0.00028407 rank 7
2023-03-01 15:36:06,295 DEBUG TRAIN Batch 58/4400 loss 6.382197 loss_att 8.653809 loss_ctc 9.783320 loss_rnnt 5.349622 hw_loss 0.233943 lr 0.00028408 rank 5
2023-03-01 15:36:06,297 DEBUG TRAIN Batch 58/4400 loss 3.543683 loss_att 8.210215 loss_ctc 5.018923 loss_rnnt 2.372245 hw_loss 0.077685 lr 0.00028408 rank 0
2023-03-01 15:36:06,298 DEBUG TRAIN Batch 58/4400 loss 5.550944 loss_att 7.210594 loss_ctc 8.561231 loss_rnnt 4.669292 hw_loss 0.278156 lr 0.00028407 rank 3
2023-03-01 15:36:06,299 DEBUG TRAIN Batch 58/4400 loss 4.187912 loss_att 5.784648 loss_ctc 5.633163 loss_rnnt 3.600021 hw_loss 0.142208 lr 0.00028407 rank 1
2023-03-01 15:36:06,308 DEBUG TRAIN Batch 58/4400 loss 2.970327 loss_att 4.580009 loss_ctc 3.706139 loss_rnnt 2.387660 hw_loss 0.304917 lr 0.00028408 rank 6
2023-03-01 15:36:06,319 DEBUG TRAIN Batch 58/4400 loss 5.159142 loss_att 6.285144 loss_ctc 7.940554 loss_rnnt 4.385311 hw_loss 0.333328 lr 0.00028407 rank 4
2023-03-01 15:36:06,343 DEBUG TRAIN Batch 58/4400 loss 3.095238 loss_att 7.151047 loss_ctc 6.203484 loss_rnnt 1.778945 hw_loss 0.170059 lr 0.00028407 rank 2
2023-03-01 15:36:44,795 DEBUG TRAIN Batch 58/4500 loss 6.330522 loss_att 10.520012 loss_ctc 8.284137 loss_rnnt 5.041264 hw_loss 0.357895 lr 0.00028406 rank 3
2023-03-01 15:36:44,796 DEBUG TRAIN Batch 58/4500 loss 5.739109 loss_att 6.044006 loss_ctc 7.274866 loss_rnnt 5.274364 hw_loss 0.373122 lr 0.00028406 rank 1
2023-03-01 15:36:44,801 DEBUG TRAIN Batch 58/4500 loss 2.119756 loss_att 5.492308 loss_ctc 5.408135 loss_rnnt 0.891711 hw_loss 0.215781 lr 0.00028406 rank 4
2023-03-01 15:36:44,803 DEBUG TRAIN Batch 58/4500 loss 2.397112 loss_att 4.591491 loss_ctc 4.881184 loss_rnnt 1.520706 hw_loss 0.199352 lr 0.00028406 rank 2
2023-03-01 15:36:44,813 DEBUG TRAIN Batch 58/4500 loss 3.245418 loss_att 8.529118 loss_ctc 10.841785 loss_rnnt 1.043348 hw_loss 0.248402 lr 0.00028407 rank 6
2023-03-01 15:36:44,814 DEBUG TRAIN Batch 58/4500 loss 3.745097 loss_att 9.351015 loss_ctc 8.812473 loss_rnnt 1.776831 hw_loss 0.321435 lr 0.00028406 rank 7
2023-03-01 15:36:44,816 DEBUG TRAIN Batch 58/4500 loss 5.478940 loss_att 9.511836 loss_ctc 10.090158 loss_rnnt 3.964294 hw_loss 0.174818 lr 0.00028407 rank 0
2023-03-01 15:36:44,819 DEBUG TRAIN Batch 58/4500 loss 6.522355 loss_att 11.552927 loss_ctc 9.362844 loss_rnnt 5.071447 hw_loss 0.123866 lr 0.00028407 rank 5
