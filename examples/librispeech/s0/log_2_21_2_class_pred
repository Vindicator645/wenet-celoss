/home/work_nfs5_ssd/kxhuang/wenet-encoder_decoder_bias/examples/librispeech/s0/data/lang_char/train_960_unigram5000
dictionary: /home/work_nfs5_ssd/kxhuang/wenet-encoder_decoder_bias/examples/librispeech/s0/data/lang_char/train_960_unigram5000_units.txt
run_2_21_rnnt_bias_0-3word_finetune.sh: init method is file:///home/work_nfs6/tyxu/workspace/wenet-bias-celoss/examples/librispeech/s0/exp/2_21_rnnt_bias_loss_2_class_1word_finetune/ddp_init
2023-02-21 21:31:16,399 INFO training on multiple gpus, this gpu 0
2023-02-21 21:31:16,399 INFO training on multiple gpus, this gpu 2
2023-02-21 21:31:16,400 INFO training on multiple gpus, this gpu 6
2023-02-21 21:31:16,400 INFO training on multiple gpus, this gpu 3
2023-02-21 21:31:16,400 INFO training on multiple gpus, this gpu 7
2023-02-21 21:31:16,401 INFO training on multiple gpus, this gpu 4
2023-02-21 21:31:16,402 INFO training on multiple gpus, this gpu 5
2023-02-21 21:31:16,405 INFO training on multiple gpus, this gpu 1
2023-02-21 21:31:22,653 INFO Added key: store_based_barrier_key:1 to store for rank: 0
2023-02-21 21:31:24,549 INFO Added key: store_based_barrier_key:1 to store for rank: 1
2023-02-21 21:31:25,215 INFO Added key: store_based_barrier_key:1 to store for rank: 4
2023-02-21 21:31:25,537 INFO Added key: store_based_barrier_key:1 to store for rank: 2
2023-02-21 21:31:25,963 INFO Added key: store_based_barrier_key:1 to store for rank: 3
2023-02-21 21:31:27,550 INFO Added key: store_based_barrier_key:1 to store for rank: 6
2023-02-21 21:31:27,722 INFO Added key: store_based_barrier_key:1 to store for rank: 5
2023-02-21 21:31:27,724 INFO Added key: store_based_barrier_key:1 to store for rank: 7
2023-02-21 21:31:27,724 INFO Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-21 21:31:27,725 INFO Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-21 21:31:27,727 INFO Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-21 21:31:27,728 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-21 21:31:27,728 INFO Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-21 21:31:27,731 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-21 21:31:27,733 INFO Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-21 21:31:27,734 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-21 21:31:39,981 INFO Checkpoint: loading from checkpoint exp/2_21_rnnt_bias_loss_2_class_1word_finetune/10.pt for GPU
2023-02-21 21:31:40,007 INFO Checkpoint: loading from checkpoint exp/2_21_rnnt_bias_loss_2_class_1word_finetune/10.pt for GPU
2023-02-21 21:31:40,033 INFO Checkpoint: loading from checkpoint exp/2_21_rnnt_bias_loss_2_class_1word_finetune/10.pt for GPU
2023-02-21 21:31:40,057 INFO Checkpoint: loading from checkpoint exp/2_21_rnnt_bias_loss_2_class_1word_finetune/10.pt for GPU
2023-02-21 21:31:40,082 INFO Checkpoint: loading from checkpoint exp/2_21_rnnt_bias_loss_2_class_1word_finetune/10.pt for GPU
2023-02-21 21:31:40,109 INFO Checkpoint: loading from checkpoint exp/2_21_rnnt_bias_loss_2_class_1word_finetune/10.pt for GPU
2023-02-21 21:31:40,136 INFO Checkpoint: loading from checkpoint exp/2_21_rnnt_bias_loss_2_class_1word_finetune/10.pt for GPU
2023-02-21 21:31:40,160 INFO Checkpoint: loading from checkpoint exp/2_21_rnnt_bias_loss_2_class_1word_finetune/10.pt for GPU
2023-02-21 21:31:55,076 INFO Epoch 11 TRAIN info lr 4e-08
2023-02-21 21:31:55,078 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=256, out_features=2, bias=True)
    (hw_output_layer_enc): Linear(in_features=256, out_features=256, bias=True)
    (hw_output_layer_dec): Linear(in_features=256, out_features=256, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58499370
2023-02-21 21:31:55,163 INFO Epoch 11 TRAIN info lr 4e-08
2023-02-21 21:31:55,165 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-21 21:31:55,167 INFO Epoch 11 TRAIN info lr 4e-08
2023-02-21 21:31:55,169 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=256, out_features=2, bias=True)
    (hw_output_layer_enc): Linear(in_features=256, out_features=256, bias=True)
    (hw_output_layer_dec): Linear(in_features=256, out_features=256, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58499370
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=256, out_features=2, bias=True)
    (hw_output_layer_enc): Linear(in_features=256, out_features=256, bias=True)
    (hw_output_layer_dec): Linear(in_features=256, out_features=256, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58499370
2023-02-21 21:31:55,223 INFO Epoch 11 TRAIN info lr 4e-08
2023-02-21 21:31:55,225 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=256, out_features=2, bias=True)
    (hw_output_layer_enc): Linear(in_features=256, out_features=256, bias=True)
    (hw_output_layer_dec): Linear(in_features=256, out_features=256, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58499370
2023-02-21 21:31:55,313 INFO Epoch 11 TRAIN info lr 4e-08
2023-02-21 21:31:55,316 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=256, out_features=2, bias=True)
    (hw_output_layer_enc): Linear(in_features=256, out_features=256, bias=True)
    (hw_output_layer_dec): Linear(in_features=256, out_features=256, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58499370
2023-02-21 21:31:55,432 INFO Epoch 11 TRAIN info lr 4e-08
2023-02-21 21:31:55,434 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=256, out_features=2, bias=True)
    (hw_output_layer_enc): Linear(in_features=256, out_features=256, bias=True)
    (hw_output_layer_dec): Linear(in_features=256, out_features=256, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58499370
2023-02-21 21:31:55,537 INFO Epoch 11 TRAIN info lr 4e-08
2023-02-21 21:31:55,537 INFO Epoch 11 TRAIN info lr 4e-08
2023-02-21 21:31:55,540 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-21 21:31:55,540 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=256, out_features=2, bias=True)
    (hw_output_layer_enc): Linear(in_features=256, out_features=256, bias=True)
    (hw_output_layer_dec): Linear(in_features=256, out_features=256, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58499370
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=256, out_features=2, bias=True)
    (hw_output_layer_enc): Linear(in_features=256, out_features=256, bias=True)
    (hw_output_layer_dec): Linear(in_features=256, out_features=256, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58499370
2023-02-21 21:33:10,155 DEBUG TRAIN Batch 11/0 loss 418.985138 loss_att 76.679771 loss_ctc 1006.346313 loss_rnnt 408.629059 hw_loss 0.941828 lr 0.00052195 rank 4
2023-02-21 21:33:10,171 DEBUG TRAIN Batch 11/0 loss 736.748718 loss_att 80.918839 loss_ctc 967.595581 loss_rnnt 836.706543 hw_loss 0.803580 lr 0.00052195 rank 0
2023-02-21 21:33:10,180 DEBUG TRAIN Batch 11/0 loss 627.331970 loss_att 81.567635 loss_ctc 1093.549194 loss_rnnt 673.909851 hw_loss 0.773747 lr 0.00052195 rank 7
2023-02-21 21:33:10,186 DEBUG TRAIN Batch 11/0 loss 445.926025 loss_att 83.871246 loss_ctc 1123.761719 loss_rnnt 427.440002 hw_loss 0.972862 lr 0.00052195 rank 5
2023-02-21 21:33:10,190 DEBUG TRAIN Batch 11/0 loss 527.013794 loss_att 75.069893 loss_ctc 835.107971 loss_rnnt 575.803650 hw_loss 0.974464 lr 0.00052195 rank 6
2023-02-21 21:33:10,193 DEBUG TRAIN Batch 11/0 loss 571.826538 loss_att 85.597237 loss_ctc 1251.978271 loss_rnnt 578.025818 hw_loss 0.674395 lr 0.00052195 rank 3
2023-02-21 21:33:10,219 DEBUG TRAIN Batch 11/0 loss 332.087433 loss_att 78.074890 loss_ctc 993.784058 loss_rnnt 294.310944 hw_loss 0.661396 lr 0.00052195 rank 1
2023-02-21 21:33:10,236 DEBUG TRAIN Batch 11/0 loss 439.129364 loss_att 82.274895 loss_ctc 1043.483887 loss_rnnt 429.374237 hw_loss 1.022648 lr 0.00052195 rank 2
2023-02-21 21:34:29,358 DEBUG TRAIN Batch 11/100 loss 220.567535 loss_att 265.816193 loss_ctc 306.040680 loss_rnnt 199.949860 hw_loss 0.321598 lr 0.00052167 rank 7
2023-02-21 21:34:29,362 DEBUG TRAIN Batch 11/100 loss 320.377106 loss_att 325.052216 loss_ctc 412.919403 loss_rnnt 307.078735 hw_loss 0.045693 lr 0.00052167 rank 0
2023-02-21 21:34:29,366 DEBUG TRAIN Batch 11/100 loss 252.791107 loss_att 288.822083 loss_ctc 333.540771 loss_rnnt 234.707062 hw_loss 0.208522 lr 0.00052167 rank 1
2023-02-21 21:34:29,367 DEBUG TRAIN Batch 11/100 loss 292.839417 loss_att 328.295502 loss_ctc 375.881287 loss_rnnt 274.536682 hw_loss 0.261064 lr 0.00052167 rank 5
2023-02-21 21:34:29,367 DEBUG TRAIN Batch 11/100 loss 254.416840 loss_att 273.061218 loss_ctc 323.412140 loss_rnnt 241.346680 hw_loss 0.266072 lr 0.00052167 rank 6
2023-02-21 21:34:29,369 DEBUG TRAIN Batch 11/100 loss 274.226318 loss_att 299.807892 loss_ctc 349.302582 loss_rnnt 258.946655 hw_loss 0.287188 lr 0.00052167 rank 4
2023-02-21 21:34:29,369 DEBUG TRAIN Batch 11/100 loss 256.916901 loss_att 262.197266 loss_ctc 331.355072 loss_rnnt 245.821945 hw_loss 0.213413 lr 0.00052167 rank 3
2023-02-21 21:34:29,370 DEBUG TRAIN Batch 11/100 loss 243.965210 loss_att 268.298553 loss_ctc 331.879639 loss_rnnt 227.242188 hw_loss 0.252092 lr 0.00052167 rank 2
2023-02-21 21:35:45,598 DEBUG TRAIN Batch 11/200 loss 172.716171 loss_att 287.417450 loss_ctc 162.724670 loss_rnnt 151.010483 hw_loss 0.183055 lr 0.00052139 rank 5
2023-02-21 21:35:45,599 DEBUG TRAIN Batch 11/200 loss 152.989822 loss_att 253.389923 loss_ctc 157.372589 loss_rnnt 132.211990 hw_loss 0.212657 lr 0.00052139 rank 7
2023-02-21 21:35:45,602 DEBUG TRAIN Batch 11/200 loss 184.802292 loss_att 282.180359 loss_ctc 189.692429 loss_rnnt 164.465668 hw_loss 0.391844 lr 0.00052139 rank 0
2023-02-21 21:35:45,604 DEBUG TRAIN Batch 11/200 loss 146.748459 loss_att 242.398117 loss_ctc 153.802246 loss_rnnt 126.540207 hw_loss 0.258418 lr 0.00052139 rank 4
2023-02-21 21:35:45,606 DEBUG TRAIN Batch 11/200 loss 169.316986 loss_att 278.762360 loss_ctc 178.622910 loss_rnnt 146.073044 hw_loss 0.213912 lr 0.00052139 rank 1
2023-02-21 21:35:45,606 DEBUG TRAIN Batch 11/200 loss 169.529434 loss_att 257.165344 loss_ctc 178.173065 loss_rnnt 150.666962 hw_loss 0.342749 lr 0.00052139 rank 2
2023-02-21 21:35:45,606 DEBUG TRAIN Batch 11/200 loss 153.082932 loss_att 263.794098 loss_ctc 148.499359 loss_rnnt 131.390717 hw_loss 0.302080 lr 0.00052139 rank 6
2023-02-21 21:35:45,649 DEBUG TRAIN Batch 11/200 loss 172.855728 loss_att 283.829132 loss_ctc 168.690338 loss_rnnt 151.119461 hw_loss 0.181824 lr 0.00052139 rank 3
2023-02-21 21:37:04,028 DEBUG TRAIN Batch 11/300 loss 177.565079 loss_att 318.586975 loss_ctc 179.615952 loss_rnnt 148.913193 hw_loss 0.326343 lr 0.00052110 rank 0
2023-02-21 21:37:04,031 DEBUG TRAIN Batch 11/300 loss 144.056503 loss_att 284.527710 loss_ctc 137.012268 loss_rnnt 116.800507 hw_loss 0.189370 lr 0.00052110 rank 7
2023-02-21 21:37:04,033 DEBUG TRAIN Batch 11/300 loss 131.008270 loss_att 246.721161 loss_ctc 119.917900 loss_rnnt 109.255508 hw_loss 0.166679 lr 0.00052110 rank 5
2023-02-21 21:37:04,035 DEBUG TRAIN Batch 11/300 loss 123.211487 loss_att 265.486877 loss_ctc 107.682747 loss_rnnt 96.718460 hw_loss 0.203326 lr 0.00052110 rank 4
2023-02-21 21:37:04,036 DEBUG TRAIN Batch 11/300 loss 139.267288 loss_att 270.928558 loss_ctc 132.259949 loss_rnnt 113.763588 hw_loss 0.198298 lr 0.00052110 rank 6
2023-02-21 21:37:04,042 DEBUG TRAIN Batch 11/300 loss 157.475998 loss_att 275.595245 loss_ctc 150.507172 loss_rnnt 134.565521 hw_loss 0.404642 lr 0.00052110 rank 2
2023-02-21 21:37:04,042 DEBUG TRAIN Batch 11/300 loss 138.144745 loss_att 257.626617 loss_ctc 136.084106 loss_rnnt 114.397171 hw_loss 0.236138 lr 0.00052110 rank 1
2023-02-21 21:37:04,065 DEBUG TRAIN Batch 11/300 loss 158.992477 loss_att 293.877472 loss_ctc 155.951843 loss_rnnt 132.315674 hw_loss 0.197303 lr 0.00052110 rank 3
2023-02-21 21:38:20,253 DEBUG TRAIN Batch 11/400 loss 116.531891 loss_att 270.319092 loss_ctc 105.123039 loss_rnnt 87.113770 hw_loss 0.340977 lr 0.00052082 rank 0
2023-02-21 21:38:20,255 DEBUG TRAIN Batch 11/400 loss 117.096519 loss_att 243.346008 loss_ctc 103.765274 loss_rnnt 93.503891 hw_loss 0.225438 lr 0.00052082 rank 4
2023-02-21 21:38:20,259 DEBUG TRAIN Batch 11/400 loss 133.558029 loss_att 251.567963 loss_ctc 123.605179 loss_rnnt 111.152596 hw_loss 0.244689 lr 0.00052082 rank 7
2023-02-21 21:38:20,260 DEBUG TRAIN Batch 11/400 loss 114.773987 loss_att 258.827271 loss_ctc 102.728386 loss_rnnt 87.413467 hw_loss 0.292353 lr 0.00052082 rank 5
2023-02-21 21:38:20,262 DEBUG TRAIN Batch 11/400 loss 89.625916 loss_att 224.937500 loss_ctc 76.099823 loss_rnnt 64.178207 hw_loss 0.354122 lr 0.00052082 rank 6
2023-02-21 21:38:20,263 DEBUG TRAIN Batch 11/400 loss 110.777542 loss_att 214.461456 loss_ctc 110.299400 loss_rnnt 90.003380 hw_loss 0.189626 lr 0.00052082 rank 2
2023-02-21 21:38:20,264 DEBUG TRAIN Batch 11/400 loss 102.564827 loss_att 260.920105 loss_ctc 87.521851 loss_rnnt 72.775246 hw_loss 0.232984 lr 0.00052082 rank 3
2023-02-21 21:38:20,266 DEBUG TRAIN Batch 11/400 loss 127.375671 loss_att 262.782074 loss_ctc 119.412804 loss_rnnt 101.326355 hw_loss 0.055770 lr 0.00052082 rank 1
2023-02-21 21:39:35,606 DEBUG TRAIN Batch 11/500 loss 73.150520 loss_att 194.231827 loss_ctc 59.478813 loss_rnnt 50.601139 hw_loss 0.292528 lr 0.00052054 rank 6
2023-02-21 21:39:35,610 DEBUG TRAIN Batch 11/500 loss 159.678955 loss_att 264.846375 loss_ctc 165.064453 loss_rnnt 137.738419 hw_loss 0.354315 lr 0.00052054 rank 7
2023-02-21 21:39:35,610 DEBUG TRAIN Batch 11/500 loss 71.415367 loss_att 188.337128 loss_ctc 69.299492 loss_rnnt 48.230865 hw_loss 0.154256 lr 0.00052054 rank 5
2023-02-21 21:39:35,612 DEBUG TRAIN Batch 11/500 loss 93.533714 loss_att 221.892426 loss_ctc 82.846848 loss_rnnt 69.184738 hw_loss 0.191508 lr 0.00052054 rank 4
2023-02-21 21:39:35,613 DEBUG TRAIN Batch 11/500 loss 96.322037 loss_att 220.168564 loss_ctc 89.132568 loss_rnnt 72.392509 hw_loss 0.222788 lr 0.00052054 rank 0
2023-02-21 21:39:35,613 DEBUG TRAIN Batch 11/500 loss 85.193756 loss_att 199.093735 loss_ctc 76.449669 loss_rnnt 63.425163 hw_loss 0.289654 lr 0.00052054 rank 2
2023-02-21 21:39:35,616 DEBUG TRAIN Batch 11/500 loss 97.411522 loss_att 225.195953 loss_ctc 89.588730 loss_rnnt 72.781563 hw_loss 0.217692 lr 0.00052054 rank 1
2023-02-21 21:39:35,618 DEBUG TRAIN Batch 11/500 loss 104.573074 loss_att 218.005219 loss_ctc 98.798615 loss_rnnt 82.464935 hw_loss 0.359332 lr 0.00052054 rank 3
2023-02-21 21:40:50,636 DEBUG TRAIN Batch 11/600 loss 44.592567 loss_att 89.854126 loss_ctc 41.924847 loss_rnnt 35.717793 hw_loss 0.334039 lr 0.00052026 rank 0
2023-02-21 21:40:50,636 DEBUG TRAIN Batch 11/600 loss 65.217125 loss_att 135.172089 loss_ctc 60.224854 loss_rnnt 51.743080 hw_loss 0.278790 lr 0.00052026 rank 1
2023-02-21 21:40:50,637 DEBUG TRAIN Batch 11/600 loss 51.462662 loss_att 114.721756 loss_ctc 41.860741 loss_rnnt 39.928596 hw_loss 0.304691 lr 0.00052026 rank 4
2023-02-21 21:40:50,638 DEBUG TRAIN Batch 11/600 loss 91.976929 loss_att 188.871216 loss_ctc 90.337059 loss_rnnt 72.659142 hw_loss 0.295466 lr 0.00052026 rank 7
2023-02-21 21:40:50,639 DEBUG TRAIN Batch 11/600 loss 73.018669 loss_att 152.341492 loss_ctc 70.468086 loss_rnnt 57.342632 hw_loss 0.284156 lr 0.00052026 rank 2
2023-02-21 21:40:50,639 DEBUG TRAIN Batch 11/600 loss 52.378994 loss_att 128.330429 loss_ctc 48.117596 loss_rnnt 37.540413 hw_loss 0.405904 lr 0.00052026 rank 3
2023-02-21 21:40:50,638 DEBUG TRAIN Batch 11/600 loss 44.022198 loss_att 92.550629 loss_ctc 46.265213 loss_rnnt 33.845482 hw_loss 0.322429 lr 0.00052026 rank 5
2023-02-21 21:40:50,641 DEBUG TRAIN Batch 11/600 loss 68.686363 loss_att 164.206207 loss_ctc 64.234612 loss_rnnt 50.015537 hw_loss 0.300787 lr 0.00052026 rank 6
2023-02-21 21:42:09,575 DEBUG TRAIN Batch 11/700 loss 61.234322 loss_att 159.124359 loss_ctc 56.964581 loss_rnnt 42.088238 hw_loss 0.257592 lr 0.00051997 rank 0
2023-02-21 21:42:09,576 DEBUG TRAIN Batch 11/700 loss 102.383324 loss_att 194.499405 loss_ctc 98.802521 loss_rnnt 84.394966 hw_loss 0.079839 lr 0.00051997 rank 5
2023-02-21 21:42:09,580 DEBUG TRAIN Batch 11/700 loss 67.126411 loss_att 166.721588 loss_ctc 54.735428 loss_rnnt 48.755127 hw_loss 0.195721 lr 0.00051997 rank 4
2023-02-21 21:42:09,584 DEBUG TRAIN Batch 11/700 loss 99.700653 loss_att 231.111877 loss_ctc 86.327515 loss_rnnt 75.057587 hw_loss 0.269808 lr 0.00051997 rank 3
2023-02-21 21:42:09,588 DEBUG TRAIN Batch 11/700 loss 72.007149 loss_att 193.916031 loss_ctc 55.216156 loss_rnnt 49.802086 hw_loss 0.116402 lr 0.00051997 rank 1
2023-02-21 21:42:09,590 DEBUG TRAIN Batch 11/700 loss 75.226448 loss_att 166.090454 loss_ctc 77.983009 loss_rnnt 56.600185 hw_loss 0.161099 lr 0.00051997 rank 2
2023-02-21 21:42:09,600 DEBUG TRAIN Batch 11/700 loss 105.343575 loss_att 204.837341 loss_ctc 103.489433 loss_rnnt 85.536118 hw_loss 0.292351 lr 0.00051997 rank 6
2023-02-21 21:42:09,605 DEBUG TRAIN Batch 11/700 loss 101.632797 loss_att 226.797394 loss_ctc 94.944260 loss_rnnt 77.374405 hw_loss 0.219871 lr 0.00051997 rank 7
2023-02-21 21:43:24,433 DEBUG TRAIN Batch 11/800 loss 51.761364 loss_att 133.363571 loss_ctc 44.714977 loss_rnnt 36.298847 hw_loss 0.152982 lr 0.00051969 rank 7
2023-02-21 21:43:24,436 DEBUG TRAIN Batch 11/800 loss 89.165421 loss_att 191.730835 loss_ctc 78.041992 loss_rnnt 70.055130 hw_loss 0.150615 lr 0.00051969 rank 1
2023-02-21 21:43:24,437 DEBUG TRAIN Batch 11/800 loss 84.466553 loss_att 211.153473 loss_ctc 88.155197 loss_rnnt 58.524776 hw_loss 0.211070 lr 0.00051969 rank 5
2023-02-21 21:43:24,438 DEBUG TRAIN Batch 11/800 loss 74.250458 loss_att 188.302536 loss_ctc 63.882214 loss_rnnt 52.774376 hw_loss 0.090184 lr 0.00051969 rank 0
2023-02-21 21:43:24,438 DEBUG TRAIN Batch 11/800 loss 59.621483 loss_att 136.314789 loss_ctc 52.557304 loss_rnnt 45.104462 hw_loss 0.225463 lr 0.00051969 rank 4
2023-02-21 21:43:24,441 DEBUG TRAIN Batch 11/800 loss 95.852470 loss_att 195.876266 loss_ctc 90.334106 loss_rnnt 76.470093 hw_loss 0.212626 lr 0.00051969 rank 6
2023-02-21 21:43:24,443 DEBUG TRAIN Batch 11/800 loss 37.844452 loss_att 110.124680 loss_ctc 29.582703 loss_rnnt 24.420658 hw_loss 0.129961 lr 0.00051969 rank 3
2023-02-21 21:43:24,487 DEBUG TRAIN Batch 11/800 loss 78.634674 loss_att 193.912308 loss_ctc 81.196686 loss_rnnt 55.209427 hw_loss 0.052725 lr 0.00051969 rank 2
2023-02-21 21:44:39,989 DEBUG TRAIN Batch 11/900 loss 67.708076 loss_att 123.100227 loss_ctc 71.232574 loss_rnnt 56.159649 hw_loss 0.000141 lr 0.00051941 rank 4
2023-02-21 21:44:39,992 DEBUG TRAIN Batch 11/900 loss 51.552921 loss_att 112.148109 loss_ctc 52.114967 loss_rnnt 39.271645 hw_loss 0.163681 lr 0.00051941 rank 1
2023-02-21 21:44:39,992 DEBUG TRAIN Batch 11/900 loss 54.042618 loss_att 129.322861 loss_ctc 47.641327 loss_rnnt 39.642487 hw_loss 0.370472 lr 0.00051941 rank 5
2023-02-21 21:44:39,993 DEBUG TRAIN Batch 11/900 loss 49.666317 loss_att 118.814735 loss_ctc 52.473869 loss_rnnt 35.323151 hw_loss 0.260898 lr 0.00051941 rank 0
2023-02-21 21:44:39,993 DEBUG TRAIN Batch 11/900 loss 55.142071 loss_att 125.822067 loss_ctc 48.357719 loss_rnnt 41.807327 hw_loss 0.193730 lr 0.00051941 rank 2
2023-02-21 21:44:39,995 DEBUG TRAIN Batch 11/900 loss 67.322777 loss_att 138.649048 loss_ctc 67.384239 loss_rnnt 52.959526 hw_loss 0.168378 lr 0.00051941 rank 7
2023-02-21 21:44:39,997 DEBUG TRAIN Batch 11/900 loss 44.981533 loss_att 104.655273 loss_ctc 41.625240 loss_rnnt 33.407791 hw_loss 0.162180 lr 0.00051941 rank 3
2023-02-21 21:44:39,998 DEBUG TRAIN Batch 11/900 loss 84.775482 loss_att 165.656357 loss_ctc 87.093559 loss_rnnt 68.093796 hw_loss 0.368311 lr 0.00051941 rank 6
2023-02-21 21:45:55,706 DEBUG TRAIN Batch 11/1000 loss 41.953121 loss_att 88.427452 loss_ctc 41.709167 loss_rnnt 32.519218 hw_loss 0.321682 lr 0.00051913 rank 7
2023-02-21 21:45:55,708 DEBUG TRAIN Batch 11/1000 loss 43.824387 loss_att 102.672470 loss_ctc 40.647545 loss_rnnt 32.296066 hw_loss 0.341778 lr 0.00051913 rank 2
2023-02-21 21:45:55,711 DEBUG TRAIN Batch 11/1000 loss 43.358250 loss_att 85.937767 loss_ctc 46.904465 loss_rnnt 34.226173 hw_loss 0.268768 lr 0.00051913 rank 4
2023-02-21 21:45:55,712 DEBUG TRAIN Batch 11/1000 loss 66.435898 loss_att 126.818459 loss_ctc 74.912460 loss_rnnt 53.090698 hw_loss 0.259644 lr 0.00051913 rank 5
2023-02-21 21:45:55,712 DEBUG TRAIN Batch 11/1000 loss 50.212467 loss_att 106.605698 loss_ctc 47.941925 loss_rnnt 39.127960 hw_loss 0.203623 lr 0.00051913 rank 3
2023-02-21 21:45:55,712 DEBUG TRAIN Batch 11/1000 loss 66.134926 loss_att 124.324326 loss_ctc 62.394836 loss_rnnt 54.912216 hw_loss 0.156575 lr 0.00051913 rank 6
2023-02-21 21:45:55,713 DEBUG TRAIN Batch 11/1000 loss 53.951767 loss_att 126.676010 loss_ctc 47.727608 loss_rnnt 40.064964 hw_loss 0.322208 lr 0.00051913 rank 0
2023-02-21 21:45:55,763 DEBUG TRAIN Batch 11/1000 loss 63.158585 loss_att 132.917053 loss_ctc 57.912079 loss_rnnt 49.793823 hw_loss 0.211128 lr 0.00051913 rank 1
2023-02-21 21:47:13,300 DEBUG TRAIN Batch 11/1100 loss 36.960747 loss_att 68.103867 loss_ctc 36.220119 loss_rnnt 30.715576 hw_loss 0.216182 lr 0.00051885 rank 0
2023-02-21 21:47:13,304 DEBUG TRAIN Batch 11/1100 loss 55.385147 loss_att 96.380989 loss_ctc 61.772385 loss_rnnt 46.203377 hw_loss 0.245557 lr 0.00051885 rank 5
2023-02-21 21:47:13,307 DEBUG TRAIN Batch 11/1100 loss 52.228199 loss_att 97.621803 loss_ctc 55.399063 loss_rnnt 42.610085 hw_loss 0.218638 lr 0.00051885 rank 1
2023-02-21 21:47:13,307 DEBUG TRAIN Batch 11/1100 loss 58.468483 loss_att 103.078964 loss_ctc 58.134789 loss_rnnt 49.456230 hw_loss 0.252467 lr 0.00051885 rank 6
2023-02-21 21:47:13,308 DEBUG TRAIN Batch 11/1100 loss 62.239609 loss_att 113.798477 loss_ctc 56.474983 loss_rnnt 52.647446 hw_loss 0.091876 lr 0.00051885 rank 4
2023-02-21 21:47:13,308 DEBUG TRAIN Batch 11/1100 loss 57.147671 loss_att 106.915016 loss_ctc 53.807720 loss_rnnt 47.492371 hw_loss 0.275925 lr 0.00051885 rank 7
2023-02-21 21:47:13,309 DEBUG TRAIN Batch 11/1100 loss 64.090881 loss_att 128.142639 loss_ctc 66.716438 loss_rnnt 50.849976 hw_loss 0.150903 lr 0.00051885 rank 2
2023-02-21 21:47:13,356 DEBUG TRAIN Batch 11/1100 loss 49.793636 loss_att 92.795609 loss_ctc 44.555645 loss_rnnt 41.740921 hw_loss 0.282598 lr 0.00051885 rank 3
2023-02-21 21:48:29,087 DEBUG TRAIN Batch 11/1200 loss 37.890549 loss_att 77.128464 loss_ctc 43.297802 loss_rnnt 29.149160 hw_loss 0.324069 lr 0.00051857 rank 7
2023-02-21 21:48:29,088 DEBUG TRAIN Batch 11/1200 loss 38.327122 loss_att 65.219688 loss_ctc 40.352203 loss_rnnt 32.589233 hw_loss 0.167553 lr 0.00051857 rank 4
2023-02-21 21:48:29,088 DEBUG TRAIN Batch 11/1200 loss 37.376835 loss_att 66.190483 loss_ctc 38.935638 loss_rnnt 31.231184 hw_loss 0.328273 lr 0.00051857 rank 3
2023-02-21 21:48:29,092 DEBUG TRAIN Batch 11/1200 loss 26.230902 loss_att 39.727013 loss_ctc 27.605085 loss_rnnt 23.219990 hw_loss 0.240866 lr 0.00051857 rank 0
2023-02-21 21:48:29,092 DEBUG TRAIN Batch 11/1200 loss 47.415993 loss_att 66.001839 loss_ctc 50.314938 loss_rnnt 43.217800 hw_loss 0.177187 lr 0.00051857 rank 5
2023-02-21 21:48:29,096 DEBUG TRAIN Batch 11/1200 loss 35.891506 loss_att 54.567806 loss_ctc 42.410625 loss_rnnt 31.111303 hw_loss 0.329485 lr 0.00051857 rank 6
2023-02-21 21:48:29,097 DEBUG TRAIN Batch 11/1200 loss 55.832787 loss_att 92.581528 loss_ctc 60.180767 loss_rnnt 47.805557 hw_loss 0.183278 lr 0.00051857 rank 2
2023-02-21 21:48:29,144 DEBUG TRAIN Batch 11/1200 loss 47.896854 loss_att 78.134872 loss_ctc 50.659538 loss_rnnt 41.328712 hw_loss 0.285342 lr 0.00051857 rank 1
2023-02-21 21:49:44,811 DEBUG TRAIN Batch 11/1300 loss 41.221741 loss_att 88.061829 loss_ctc 41.466663 loss_rnnt 31.769003 hw_loss 0.097617 lr 0.00051829 rank 5
2023-02-21 21:49:44,817 DEBUG TRAIN Batch 11/1300 loss 40.730087 loss_att 91.092766 loss_ctc 44.047848 loss_rnnt 30.091854 hw_loss 0.231251 lr 0.00051829 rank 0
2023-02-21 21:49:44,817 DEBUG TRAIN Batch 11/1300 loss 38.423203 loss_att 82.719513 loss_ctc 32.623077 loss_rnnt 30.145248 hw_loss 0.360079 lr 0.00051829 rank 3
2023-02-21 21:49:44,820 DEBUG TRAIN Batch 11/1300 loss 25.973352 loss_att 43.101265 loss_ctc 26.761816 loss_rnnt 22.274750 hw_loss 0.314795 lr 0.00051829 rank 1
2023-02-21 21:49:44,821 DEBUG TRAIN Batch 11/1300 loss 49.359787 loss_att 104.784332 loss_ctc 45.005489 loss_rnnt 38.761982 hw_loss 0.175243 lr 0.00051829 rank 2
2023-02-21 21:49:44,821 DEBUG TRAIN Batch 11/1300 loss 50.581970 loss_att 86.884254 loss_ctc 47.032940 loss_rnnt 43.709679 hw_loss 0.159452 lr 0.00051829 rank 6
2023-02-21 21:49:44,842 DEBUG TRAIN Batch 11/1300 loss 55.939724 loss_att 88.028099 loss_ctc 55.060577 loss_rnnt 49.594238 hw_loss 0.084430 lr 0.00051829 rank 4
2023-02-21 21:49:44,853 DEBUG TRAIN Batch 11/1300 loss 48.956028 loss_att 84.105301 loss_ctc 47.953182 loss_rnnt 41.847744 hw_loss 0.397770 lr 0.00051829 rank 7
2023-02-21 21:51:02,173 DEBUG TRAIN Batch 11/1400 loss 52.706154 loss_att 83.838539 loss_ctc 55.027126 loss_rnnt 46.071442 hw_loss 0.185193 lr 0.00051802 rank 4
2023-02-21 21:51:02,178 DEBUG TRAIN Batch 11/1400 loss 77.901649 loss_att 125.375412 loss_ctc 89.996544 loss_rnnt 66.668053 hw_loss 0.236612 lr 0.00051802 rank 0
2023-02-21 21:51:02,179 DEBUG TRAIN Batch 11/1400 loss 31.193624 loss_att 61.003719 loss_ctc 27.862036 loss_rnnt 25.550900 hw_loss 0.234222 lr 0.00051802 rank 6
2023-02-21 21:51:02,180 DEBUG TRAIN Batch 11/1400 loss 34.708961 loss_att 64.058144 loss_ctc 37.289772 loss_rnnt 28.360432 hw_loss 0.252344 lr 0.00051802 rank 5
2023-02-21 21:51:02,187 DEBUG TRAIN Batch 11/1400 loss 47.502052 loss_att 90.737564 loss_ctc 44.939938 loss_rnnt 39.036774 hw_loss 0.299603 lr 0.00051802 rank 7
2023-02-21 21:51:02,188 DEBUG TRAIN Batch 11/1400 loss 43.188011 loss_att 70.466652 loss_ctc 42.611710 loss_rnnt 37.732773 hw_loss 0.143166 lr 0.00051802 rank 3
2023-02-21 21:51:02,208 DEBUG TRAIN Batch 11/1400 loss 72.317818 loss_att 110.014122 loss_ctc 71.830040 loss_rnnt 64.757370 hw_loss 0.161670 lr 0.00051802 rank 2
2023-02-21 21:51:02,218 DEBUG TRAIN Batch 11/1400 loss 25.260391 loss_att 58.412590 loss_ctc 29.924541 loss_rnnt 17.799267 hw_loss 0.391495 lr 0.00051802 rank 1
2023-02-21 21:52:16,977 DEBUG TRAIN Batch 11/1500 loss 27.089619 loss_att 45.819592 loss_ctc 33.787460 loss_rnnt 22.369629 hw_loss 0.151776 lr 0.00051774 rank 0
2023-02-21 21:52:16,977 DEBUG TRAIN Batch 11/1500 loss 41.344337 loss_att 66.333549 loss_ctc 39.883652 loss_rnnt 36.432491 hw_loss 0.203933 lr 0.00051774 rank 5
2023-02-21 21:52:16,981 DEBUG TRAIN Batch 11/1500 loss 33.967598 loss_att 61.194038 loss_ctc 42.188530 loss_rnnt 27.377132 hw_loss 0.091977 lr 0.00051774 rank 4
2023-02-21 21:52:16,981 DEBUG TRAIN Batch 11/1500 loss 22.729116 loss_att 54.436325 loss_ctc 26.851583 loss_rnnt 15.706907 hw_loss 0.245823 lr 0.00051774 rank 6
2023-02-21 21:52:16,982 DEBUG TRAIN Batch 11/1500 loss 47.275177 loss_att 74.979408 loss_ctc 47.186829 loss_rnnt 41.708721 hw_loss 0.070115 lr 0.00051774 rank 7
2023-02-21 21:52:16,982 DEBUG TRAIN Batch 11/1500 loss 28.835573 loss_att 56.481331 loss_ctc 27.447361 loss_rnnt 23.376837 hw_loss 0.215025 lr 0.00051774 rank 2
2023-02-21 21:52:16,983 DEBUG TRAIN Batch 11/1500 loss 36.028702 loss_att 73.732010 loss_ctc 36.558708 loss_rnnt 28.285526 hw_loss 0.247211 lr 0.00051774 rank 3
2023-02-21 21:52:16,985 DEBUG TRAIN Batch 11/1500 loss 32.545250 loss_att 51.682304 loss_ctc 30.683849 loss_rnnt 28.876715 hw_loss 0.167466 lr 0.00051774 rank 1
2023-02-21 21:53:30,758 DEBUG TRAIN Batch 11/1600 loss 35.818707 loss_att 64.334488 loss_ctc 38.286896 loss_rnnt 29.665928 hw_loss 0.225990 lr 0.00051746 rank 5
2023-02-21 21:53:30,760 DEBUG TRAIN Batch 11/1600 loss 38.804096 loss_att 62.220982 loss_ctc 38.766365 loss_rnnt 34.047821 hw_loss 0.146113 lr 0.00051746 rank 7
2023-02-21 21:53:30,760 DEBUG TRAIN Batch 11/1600 loss 52.496956 loss_att 83.929970 loss_ctc 64.043640 loss_rnnt 44.557224 hw_loss 0.212932 lr 0.00051746 rank 0
2023-02-21 21:53:30,762 DEBUG TRAIN Batch 11/1600 loss 34.090836 loss_att 50.269058 loss_ctc 36.701218 loss_rnnt 30.411852 hw_loss 0.178659 lr 0.00051746 rank 4
2023-02-21 21:53:30,763 DEBUG TRAIN Batch 11/1600 loss 44.708881 loss_att 80.566101 loss_ctc 39.696976 loss_rnnt 38.075157 hw_loss 0.244756 lr 0.00051746 rank 1
2023-02-21 21:53:30,764 DEBUG TRAIN Batch 11/1600 loss 25.165060 loss_att 43.237732 loss_ctc 23.811398 loss_rnnt 21.629349 hw_loss 0.190619 lr 0.00051746 rank 3
2023-02-21 21:53:30,764 DEBUG TRAIN Batch 11/1600 loss 19.878468 loss_att 34.787224 loss_ctc 23.394915 loss_rnnt 16.311958 hw_loss 0.217310 lr 0.00051746 rank 6
2023-02-21 21:53:30,768 DEBUG TRAIN Batch 11/1600 loss 28.878443 loss_att 49.807518 loss_ctc 31.127598 loss_rnnt 24.242119 hw_loss 0.282414 lr 0.00051746 rank 2
2023-02-21 21:54:46,573 DEBUG TRAIN Batch 11/1700 loss 26.928955 loss_att 45.012966 loss_ctc 31.837555 loss_rnnt 22.551682 hw_loss 0.198731 lr 0.00051718 rank 7
2023-02-21 21:54:46,577 DEBUG TRAIN Batch 11/1700 loss 27.855015 loss_att 41.337891 loss_ctc 30.546219 loss_rnnt 24.709230 hw_loss 0.169465 lr 0.00051718 rank 5
2023-02-21 21:54:46,579 DEBUG TRAIN Batch 11/1700 loss 34.640495 loss_att 49.415154 loss_ctc 36.250710 loss_rnnt 31.328537 hw_loss 0.266877 lr 0.00051718 rank 0
2023-02-21 21:54:46,580 DEBUG TRAIN Batch 11/1700 loss 38.599251 loss_att 61.026436 loss_ctc 42.882236 loss_rnnt 33.399155 hw_loss 0.269240 lr 0.00051718 rank 6
2023-02-21 21:54:46,581 DEBUG TRAIN Batch 11/1700 loss 24.336409 loss_att 48.764168 loss_ctc 27.669815 loss_rnnt 18.907457 hw_loss 0.185521 lr 0.00051718 rank 1
2023-02-21 21:54:46,583 DEBUG TRAIN Batch 11/1700 loss 42.475159 loss_att 56.690289 loss_ctc 45.444031 loss_rnnt 39.112339 hw_loss 0.232393 lr 0.00051718 rank 2
2023-02-21 21:54:46,586 DEBUG TRAIN Batch 11/1700 loss 46.855343 loss_att 68.653381 loss_ctc 52.879120 loss_rnnt 41.619865 hw_loss 0.136312 lr 0.00051718 rank 3
2023-02-21 21:54:46,591 DEBUG TRAIN Batch 11/1700 loss 39.098450 loss_att 60.488377 loss_ctc 42.745716 loss_rnnt 34.162067 hw_loss 0.322674 lr 0.00051718 rank 4
2023-02-21 21:56:05,161 DEBUG TRAIN Batch 11/1800 loss 31.495970 loss_att 45.795364 loss_ctc 35.905319 loss_rnnt 27.952923 hw_loss 0.178606 lr 0.00051691 rank 4
2023-02-21 21:56:05,163 DEBUG TRAIN Batch 11/1800 loss 39.450233 loss_att 53.058098 loss_ctc 39.391060 loss_rnnt 36.600433 hw_loss 0.255226 lr 0.00051691 rank 0
2023-02-21 21:56:05,163 DEBUG TRAIN Batch 11/1800 loss 35.441811 loss_att 42.598289 loss_ctc 37.077850 loss_rnnt 33.701900 hw_loss 0.169643 lr 0.00051691 rank 5
2023-02-21 21:56:05,165 DEBUG TRAIN Batch 11/1800 loss 33.714504 loss_att 50.081509 loss_ctc 39.676067 loss_rnnt 29.479298 hw_loss 0.312982 lr 0.00051691 rank 7
2023-02-21 21:56:05,171 DEBUG TRAIN Batch 11/1800 loss 24.445204 loss_att 36.249233 loss_ctc 24.806393 loss_rnnt 21.871119 hw_loss 0.309600 lr 0.00051691 rank 2
2023-02-21 21:56:05,171 DEBUG TRAIN Batch 11/1800 loss 35.438370 loss_att 52.139702 loss_ctc 41.455017 loss_rnnt 31.251099 hw_loss 0.083969 lr 0.00051691 rank 3
2023-02-21 21:56:05,171 DEBUG TRAIN Batch 11/1800 loss 36.114220 loss_att 52.362755 loss_ctc 38.431114 loss_rnnt 32.446732 hw_loss 0.204116 lr 0.00051691 rank 1
2023-02-21 21:56:05,217 DEBUG TRAIN Batch 11/1800 loss 31.296606 loss_att 51.304836 loss_ctc 31.978964 loss_rnnt 27.100697 hw_loss 0.193647 lr 0.00051691 rank 6
2023-02-21 21:57:19,730 DEBUG TRAIN Batch 11/1900 loss 32.225201 loss_att 53.558525 loss_ctc 35.494690 loss_rnnt 27.463223 hw_loss 0.111338 lr 0.00051663 rank 0
2023-02-21 21:57:19,733 DEBUG TRAIN Batch 11/1900 loss 36.081600 loss_att 45.420120 loss_ctc 41.055531 loss_rnnt 33.433830 hw_loss 0.219146 lr 0.00051663 rank 1
2023-02-21 21:57:19,735 DEBUG TRAIN Batch 11/1900 loss 26.286861 loss_att 29.984959 loss_ctc 28.459526 loss_rnnt 25.133484 hw_loss 0.232628 lr 0.00051663 rank 7
2023-02-21 21:57:19,737 DEBUG TRAIN Batch 11/1900 loss 17.599007 loss_att 17.297741 loss_ctc 21.096395 loss_rnnt 17.046873 hw_loss 0.273877 lr 0.00051663 rank 5
2023-02-21 21:57:19,741 DEBUG TRAIN Batch 11/1900 loss 22.985174 loss_att 29.108322 loss_ctc 27.088093 loss_rnnt 21.011002 hw_loss 0.379662 lr 0.00051663 rank 6
2023-02-21 21:57:19,743 DEBUG TRAIN Batch 11/1900 loss 20.335947 loss_att 25.058605 loss_ctc 21.867842 loss_rnnt 19.048788 hw_loss 0.259453 lr 0.00051663 rank 4
2023-02-21 21:57:19,743 DEBUG TRAIN Batch 11/1900 loss 19.964178 loss_att 32.220104 loss_ctc 22.314812 loss_rnnt 17.129578 hw_loss 0.131246 lr 0.00051663 rank 2
2023-02-21 21:57:19,745 DEBUG TRAIN Batch 11/1900 loss 18.412960 loss_att 20.212101 loss_ctc 22.616560 loss_rnnt 17.315985 hw_loss 0.331256 lr 0.00051663 rank 3
2023-02-21 21:58:33,383 DEBUG TRAIN Batch 11/2000 loss 45.908493 loss_att 70.344368 loss_ctc 54.695808 loss_rnnt 39.771133 hw_loss 0.147264 lr 0.00051636 rank 4
2023-02-21 21:58:33,386 DEBUG TRAIN Batch 11/2000 loss 46.841537 loss_att 65.472946 loss_ctc 55.202541 loss_rnnt 42.000397 hw_loss 0.000102 lr 0.00051636 rank 0
2023-02-21 21:58:33,390 DEBUG TRAIN Batch 11/2000 loss 37.119095 loss_att 49.296387 loss_ctc 44.041698 loss_rnnt 33.661613 hw_loss 0.185641 lr 0.00051636 rank 3
2023-02-21 21:58:33,390 DEBUG TRAIN Batch 11/2000 loss 37.285381 loss_att 59.551605 loss_ctc 43.772686 loss_rnnt 31.848721 hw_loss 0.222080 lr 0.00051636 rank 5
2023-02-21 21:58:33,391 DEBUG TRAIN Batch 11/2000 loss 43.440960 loss_att 49.666348 loss_ctc 49.317024 loss_rnnt 41.326824 hw_loss 0.160474 lr 0.00051636 rank 7
2023-02-21 21:58:33,392 DEBUG TRAIN Batch 11/2000 loss 45.788849 loss_att 67.766151 loss_ctc 49.102032 loss_rnnt 40.824379 hw_loss 0.238590 lr 0.00051636 rank 6
2023-02-21 21:58:33,393 DEBUG TRAIN Batch 11/2000 loss 21.480459 loss_att 34.764740 loss_ctc 24.972387 loss_rnnt 18.300209 hw_loss 0.108382 lr 0.00051636 rank 2
2023-02-21 21:58:33,431 DEBUG TRAIN Batch 11/2000 loss 40.085484 loss_att 58.989216 loss_ctc 40.036781 loss_rnnt 36.191601 hw_loss 0.224318 lr 0.00051636 rank 1
2023-02-21 21:59:50,204 DEBUG TRAIN Batch 11/2100 loss 29.361559 loss_att 49.021130 loss_ctc 25.561895 loss_rnnt 25.806763 hw_loss 0.242816 lr 0.00051608 rank 4
2023-02-21 21:59:50,206 DEBUG TRAIN Batch 11/2100 loss 18.329018 loss_att 29.832895 loss_ctc 19.689110 loss_rnnt 15.778297 hw_loss 0.128624 lr 0.00051608 rank 7
2023-02-21 21:59:50,209 DEBUG TRAIN Batch 11/2100 loss 41.610165 loss_att 58.750282 loss_ctc 44.086178 loss_rnnt 37.676636 hw_loss 0.328817 lr 0.00051608 rank 5
2023-02-21 21:59:50,209 DEBUG TRAIN Batch 11/2100 loss 18.568272 loss_att 33.710205 loss_ctc 22.724859 loss_rnnt 14.841350 hw_loss 0.270607 lr 0.00051608 rank 0
2023-02-21 21:59:50,213 DEBUG TRAIN Batch 11/2100 loss 28.285252 loss_att 46.760452 loss_ctc 26.128765 loss_rnnt 24.779501 hw_loss 0.184203 lr 0.00051608 rank 2
2023-02-21 21:59:50,214 DEBUG TRAIN Batch 11/2100 loss 26.371145 loss_att 40.187847 loss_ctc 24.028580 loss_rnnt 23.669691 hw_loss 0.469602 lr 0.00051608 rank 3
2023-02-21 21:59:50,214 DEBUG TRAIN Batch 11/2100 loss 32.251060 loss_att 51.382030 loss_ctc 41.219299 loss_rnnt 27.096413 hw_loss 0.248787 lr 0.00051608 rank 1
2023-02-21 21:59:50,217 DEBUG TRAIN Batch 11/2100 loss 35.966572 loss_att 53.638817 loss_ctc 43.608330 loss_rnnt 31.314384 hw_loss 0.185323 lr 0.00051608 rank 6
2023-02-21 22:01:05,820 DEBUG TRAIN Batch 11/2200 loss 31.380066 loss_att 44.106102 loss_ctc 30.248249 loss_rnnt 28.903692 hw_loss 0.153896 lr 0.00051581 rank 0
2023-02-21 22:01:05,822 DEBUG TRAIN Batch 11/2200 loss 36.144718 loss_att 55.653244 loss_ctc 40.247585 loss_rnnt 31.619133 hw_loss 0.144052 lr 0.00051581 rank 7
2023-02-21 22:01:05,823 DEBUG TRAIN Batch 11/2200 loss 39.779694 loss_att 64.790382 loss_ctc 48.221443 loss_rnnt 33.517605 hw_loss 0.251980 lr 0.00051581 rank 3
2023-02-21 22:01:05,824 DEBUG TRAIN Batch 11/2200 loss 49.590836 loss_att 69.820450 loss_ctc 53.863876 loss_rnnt 44.802834 hw_loss 0.323137 lr 0.00051581 rank 4
2023-02-21 22:01:05,825 DEBUG TRAIN Batch 11/2200 loss 35.232620 loss_att 51.629257 loss_ctc 41.105438 loss_rnnt 31.096096 hw_loss 0.139032 lr 0.00051581 rank 1
2023-02-21 22:01:05,826 DEBUG TRAIN Batch 11/2200 loss 51.141743 loss_att 66.899017 loss_ctc 62.023640 loss_rnnt 46.406349 hw_loss 0.249417 lr 0.00051581 rank 6
2023-02-21 22:01:05,827 DEBUG TRAIN Batch 11/2200 loss 33.424923 loss_att 47.478756 loss_ctc 36.293015 loss_rnnt 30.068409 hw_loss 0.306249 lr 0.00051581 rank 2
2023-02-21 22:01:05,827 DEBUG TRAIN Batch 11/2200 loss 34.360157 loss_att 52.036797 loss_ctc 34.462566 loss_rnnt 30.677231 hw_loss 0.251136 lr 0.00051581 rank 5
2023-02-21 22:02:21,263 DEBUG TRAIN Batch 11/2300 loss 35.800755 loss_att 49.357769 loss_ctc 39.524178 loss_rnnt 32.466213 hw_loss 0.237534 lr 0.00051553 rank 5
2023-02-21 22:02:21,263 DEBUG TRAIN Batch 11/2300 loss 44.053501 loss_att 59.906380 loss_ctc 46.542080 loss_rnnt 40.459946 hw_loss 0.170935 lr 0.00051553 rank 7
2023-02-21 22:02:21,264 DEBUG TRAIN Batch 11/2300 loss 29.820822 loss_att 39.498501 loss_ctc 33.209217 loss_rnnt 27.279009 hw_loss 0.289676 lr 0.00051553 rank 4
2023-02-21 22:02:21,265 DEBUG TRAIN Batch 11/2300 loss 31.889473 loss_att 47.757069 loss_ctc 31.574654 loss_rnnt 28.658821 hw_loss 0.185828 lr 0.00051553 rank 3
2023-02-21 22:02:21,265 DEBUG TRAIN Batch 11/2300 loss 40.203037 loss_att 67.627396 loss_ctc 38.002960 loss_rnnt 34.858261 hw_loss 0.287333 lr 0.00051553 rank 6
2023-02-21 22:02:21,265 DEBUG TRAIN Batch 11/2300 loss 33.121719 loss_att 50.936554 loss_ctc 37.602715 loss_rnnt 28.888020 hw_loss 0.137373 lr 0.00051553 rank 2
2023-02-21 22:02:21,269 DEBUG TRAIN Batch 11/2300 loss 20.634874 loss_att 32.987320 loss_ctc 21.665575 loss_rnnt 17.945858 hw_loss 0.152065 lr 0.00051553 rank 0
2023-02-21 22:02:21,269 DEBUG TRAIN Batch 11/2300 loss 56.617699 loss_att 75.996246 loss_ctc 61.545277 loss_rnnt 52.005253 hw_loss 0.149476 lr 0.00051553 rank 1
2023-02-21 22:03:36,392 DEBUG TRAIN Batch 11/2400 loss 38.743938 loss_att 52.221905 loss_ctc 48.072517 loss_rnnt 34.672485 hw_loss 0.247597 lr 0.00051526 rank 5
2023-02-21 22:03:36,392 DEBUG TRAIN Batch 11/2400 loss 30.392807 loss_att 39.635826 loss_ctc 31.124115 loss_rnnt 28.328934 hw_loss 0.220804 lr 0.00051526 rank 4
2023-02-21 22:03:36,393 DEBUG TRAIN Batch 11/2400 loss 20.403013 loss_att 23.493496 loss_ctc 20.971899 loss_rnnt 19.568333 hw_loss 0.263871 lr 0.00051526 rank 3
2023-02-21 22:03:36,396 DEBUG TRAIN Batch 11/2400 loss 18.380135 loss_att 30.100552 loss_ctc 16.064188 loss_rnnt 16.212107 hw_loss 0.248881 lr 0.00051526 rank 6
2023-02-21 22:03:36,397 DEBUG TRAIN Batch 11/2400 loss 23.018568 loss_att 35.677540 loss_ctc 24.786667 loss_rnnt 20.141005 hw_loss 0.206294 lr 0.00051526 rank 1
2023-02-21 22:03:36,399 DEBUG TRAIN Batch 11/2400 loss 18.150862 loss_att 21.382780 loss_ctc 14.346742 loss_rnnt 17.961832 hw_loss 0.093486 lr 0.00051526 rank 0
2023-02-21 22:03:36,402 DEBUG TRAIN Batch 11/2400 loss 21.503704 loss_att 31.227766 loss_ctc 20.679482 loss_rnnt 19.565884 hw_loss 0.192945 lr 0.00051526 rank 2
2023-02-21 22:03:36,401 DEBUG TRAIN Batch 11/2400 loss 32.670910 loss_att 43.297070 loss_ctc 36.136448 loss_rnnt 29.966114 hw_loss 0.220287 lr 0.00051526 rank 7
2023-02-21 22:04:55,287 DEBUG TRAIN Batch 11/2500 loss 26.233500 loss_att 37.312485 loss_ctc 26.213879 loss_rnnt 23.875631 hw_loss 0.271291 lr 0.00051499 rank 4
2023-02-21 22:04:55,291 DEBUG TRAIN Batch 11/2500 loss 28.029102 loss_att 31.918270 loss_ctc 32.875858 loss_rnnt 26.518860 hw_loss 0.161577 lr 0.00051499 rank 0
2023-02-21 22:04:55,296 DEBUG TRAIN Batch 11/2500 loss 27.636847 loss_att 27.856148 loss_ctc 30.048277 loss_rnnt 27.126980 hw_loss 0.270905 lr 0.00051499 rank 5
2023-02-21 22:04:55,300 DEBUG TRAIN Batch 11/2500 loss 30.103218 loss_att 40.251923 loss_ctc 35.874344 loss_rnnt 27.169806 hw_loss 0.251602 lr 0.00051499 rank 7
2023-02-21 22:04:55,301 DEBUG TRAIN Batch 11/2500 loss 33.947220 loss_att 34.085297 loss_ctc 38.387051 loss_rnnt 33.172974 hw_loss 0.289975 lr 0.00051499 rank 6
2023-02-21 22:04:55,301 DEBUG TRAIN Batch 11/2500 loss 21.722660 loss_att 30.706474 loss_ctc 26.278534 loss_rnnt 19.189507 hw_loss 0.241765 lr 0.00051499 rank 3
2023-02-21 22:04:55,303 DEBUG TRAIN Batch 11/2500 loss 16.238260 loss_att 20.766174 loss_ctc 17.270546 loss_rnnt 14.985901 hw_loss 0.392138 lr 0.00051499 rank 2
2023-02-21 22:04:55,342 DEBUG TRAIN Batch 11/2500 loss 31.989656 loss_att 44.594643 loss_ctc 34.987915 loss_rnnt 28.966198 hw_loss 0.192550 lr 0.00051499 rank 1
2023-02-21 22:06:10,408 DEBUG TRAIN Batch 11/2600 loss 26.805475 loss_att 40.879295 loss_ctc 26.708233 loss_rnnt 23.837021 hw_loss 0.312474 lr 0.00051471 rank 7
2023-02-21 22:06:10,412 DEBUG TRAIN Batch 11/2600 loss 24.897575 loss_att 38.730648 loss_ctc 30.281866 loss_rnnt 21.249298 hw_loss 0.307044 lr 0.00051471 rank 0
2023-02-21 22:06:10,413 DEBUG TRAIN Batch 11/2600 loss 49.542423 loss_att 65.428375 loss_ctc 49.371243 loss_rnnt 46.284637 hw_loss 0.193910 lr 0.00051471 rank 4
2023-02-21 22:06:10,417 DEBUG TRAIN Batch 11/2600 loss 31.483818 loss_att 47.172516 loss_ctc 33.269325 loss_rnnt 28.017965 hw_loss 0.168832 lr 0.00051471 rank 6
2023-02-21 22:06:10,417 DEBUG TRAIN Batch 11/2600 loss 24.589241 loss_att 40.172504 loss_ctc 26.456625 loss_rnnt 21.073677 hw_loss 0.281116 lr 0.00051471 rank 1
2023-02-21 22:06:10,417 DEBUG TRAIN Batch 11/2600 loss 25.466829 loss_att 44.565231 loss_ctc 27.481258 loss_rnnt 21.263744 hw_loss 0.215277 lr 0.00051471 rank 5
2023-02-21 22:06:10,421 DEBUG TRAIN Batch 11/2600 loss 30.475494 loss_att 52.506996 loss_ctc 26.131126 loss_rnnt 26.533855 hw_loss 0.214852 lr 0.00051471 rank 2
2023-02-21 22:06:10,423 DEBUG TRAIN Batch 11/2600 loss 11.670621 loss_att 23.370914 loss_ctc 11.981323 loss_rnnt 9.223861 hw_loss 0.122389 lr 0.00051471 rank 3
2023-02-21 22:07:25,052 DEBUG TRAIN Batch 11/2700 loss 26.421844 loss_att 49.053612 loss_ctc 30.499075 loss_rnnt 21.290840 hw_loss 0.114415 lr 0.00051444 rank 7
2023-02-21 22:07:25,053 DEBUG TRAIN Batch 11/2700 loss 49.104393 loss_att 63.118774 loss_ctc 61.519150 loss_rnnt 44.563366 hw_loss 0.155344 lr 0.00051444 rank 3
2023-02-21 22:07:25,054 DEBUG TRAIN Batch 11/2700 loss 26.798107 loss_att 36.276016 loss_ctc 30.165272 loss_rnnt 24.300034 hw_loss 0.287883 lr 0.00051444 rank 0
2023-02-21 22:07:25,054 DEBUG TRAIN Batch 11/2700 loss 33.230263 loss_att 46.278080 loss_ctc 33.464970 loss_rnnt 30.487030 hw_loss 0.191952 lr 0.00051444 rank 1
2023-02-21 22:07:25,054 DEBUG TRAIN Batch 11/2700 loss 28.339842 loss_att 47.105686 loss_ctc 27.745022 loss_rnnt 24.592552 hw_loss 0.137680 lr 0.00051444 rank 4
2023-02-21 22:07:25,056 DEBUG TRAIN Batch 11/2700 loss 19.323957 loss_att 34.216793 loss_ctc 22.327246 loss_rnnt 15.896833 hw_loss 0.090223 lr 0.00051444 rank 5
2023-02-21 22:07:25,057 DEBUG TRAIN Batch 11/2700 loss 44.548954 loss_att 54.469765 loss_ctc 53.676178 loss_rnnt 41.138527 hw_loss 0.392442 lr 0.00051444 rank 2
2023-02-21 22:07:25,103 DEBUG TRAIN Batch 11/2700 loss 21.412474 loss_att 36.635784 loss_ctc 28.228325 loss_rnnt 17.358177 hw_loss 0.189100 lr 0.00051444 rank 6
2023-02-21 22:08:42,408 DEBUG TRAIN Batch 11/2800 loss 18.756517 loss_att 23.727440 loss_ctc 22.410217 loss_rnnt 17.095367 hw_loss 0.337136 lr 0.00051417 rank 4
2023-02-21 22:08:42,408 DEBUG TRAIN Batch 11/2800 loss 44.983803 loss_att 49.939934 loss_ctc 54.678493 loss_rnnt 42.570862 hw_loss 0.242047 lr 0.00051417 rank 7
2023-02-21 22:08:42,410 DEBUG TRAIN Batch 11/2800 loss 33.041142 loss_att 44.266258 loss_ctc 38.090832 loss_rnnt 30.037497 hw_loss 0.159988 lr 0.00051417 rank 5
2023-02-21 22:08:42,411 DEBUG TRAIN Batch 11/2800 loss 25.991371 loss_att 32.322716 loss_ctc 25.900845 loss_rnnt 24.566895 hw_loss 0.319271 lr 0.00051417 rank 6
2023-02-21 22:08:42,413 DEBUG TRAIN Batch 11/2800 loss 41.643429 loss_att 59.962646 loss_ctc 42.646439 loss_rnnt 37.791580 hw_loss 0.101758 lr 0.00051417 rank 0
2023-02-21 22:08:42,419 DEBUG TRAIN Batch 11/2800 loss 21.652880 loss_att 31.964001 loss_ctc 20.934116 loss_rnnt 19.614258 hw_loss 0.135435 lr 0.00051417 rank 2
2023-02-21 22:08:42,419 DEBUG TRAIN Batch 11/2800 loss 12.954550 loss_att 27.406952 loss_ctc 12.352533 loss_rnnt 10.017555 hw_loss 0.237717 lr 0.00051417 rank 3
2023-02-21 22:08:42,420 DEBUG TRAIN Batch 11/2800 loss 15.033570 loss_att 23.253996 loss_ctc 16.996246 loss_rnnt 13.002775 hw_loss 0.234411 lr 0.00051417 rank 1
2023-02-21 22:09:57,054 DEBUG TRAIN Batch 11/2900 loss 30.575029 loss_att 41.755688 loss_ctc 32.066555 loss_rnnt 28.049946 hw_loss 0.168901 lr 0.00051390 rank 0
2023-02-21 22:09:57,056 DEBUG TRAIN Batch 11/2900 loss 31.440975 loss_att 37.643440 loss_ctc 33.310200 loss_rnnt 29.936586 hw_loss 0.027493 lr 0.00051390 rank 5
2023-02-21 22:09:57,059 DEBUG TRAIN Batch 11/2900 loss 27.212734 loss_att 35.047974 loss_ctc 29.490477 loss_rnnt 25.245621 hw_loss 0.180686 lr 0.00051390 rank 3
2023-02-21 22:09:57,060 DEBUG TRAIN Batch 11/2900 loss 28.138077 loss_att 40.972813 loss_ctc 33.298012 loss_rnnt 24.777252 hw_loss 0.198535 lr 0.00051390 rank 7
2023-02-21 22:09:57,061 DEBUG TRAIN Batch 11/2900 loss 20.076731 loss_att 33.666397 loss_ctc 20.161293 loss_rnnt 17.210440 hw_loss 0.257030 lr 0.00051390 rank 1
2023-02-21 22:09:57,061 DEBUG TRAIN Batch 11/2900 loss 16.119133 loss_att 24.116251 loss_ctc 13.250777 loss_rnnt 14.797312 hw_loss 0.196581 lr 0.00051390 rank 4
2023-02-21 22:09:57,062 DEBUG TRAIN Batch 11/2900 loss 34.359795 loss_att 45.267990 loss_ctc 40.760021 loss_rnnt 31.197931 hw_loss 0.237861 lr 0.00051390 rank 6
2023-02-21 22:09:57,067 DEBUG TRAIN Batch 11/2900 loss 29.495975 loss_att 35.559349 loss_ctc 32.083370 loss_rnnt 27.808456 hw_loss 0.243484 lr 0.00051390 rank 2
2023-02-21 22:11:12,088 DEBUG TRAIN Batch 11/3000 loss 20.296671 loss_att 31.834923 loss_ctc 24.295429 loss_rnnt 17.324963 hw_loss 0.245419 lr 0.00051362 rank 7
2023-02-21 22:11:12,089 DEBUG TRAIN Batch 11/3000 loss 23.430880 loss_att 36.671333 loss_ctc 27.043003 loss_rnnt 20.218126 hw_loss 0.155710 lr 0.00051362 rank 0
2023-02-21 22:11:12,090 DEBUG TRAIN Batch 11/3000 loss 29.291630 loss_att 41.518337 loss_ctc 33.276875 loss_rnnt 26.182186 hw_loss 0.248882 lr 0.00051362 rank 5
2023-02-21 22:11:12,090 DEBUG TRAIN Batch 11/3000 loss 29.213444 loss_att 35.749313 loss_ctc 33.119114 loss_rnnt 27.303486 hw_loss 0.153800 lr 0.00051362 rank 6
2023-02-21 22:11:12,092 DEBUG TRAIN Batch 11/3000 loss 16.560305 loss_att 22.975250 loss_ctc 18.977642 loss_rnnt 14.786751 hw_loss 0.315474 lr 0.00051362 rank 4
2023-02-21 22:11:12,094 DEBUG TRAIN Batch 11/3000 loss 18.836031 loss_att 30.049946 loss_ctc 17.012913 loss_rnnt 16.634689 hw_loss 0.378078 lr 0.00051362 rank 1
2023-02-21 22:11:12,094 DEBUG TRAIN Batch 11/3000 loss 15.382250 loss_att 20.403677 loss_ctc 17.631569 loss_rnnt 13.872393 hw_loss 0.385617 lr 0.00051362 rank 2
2023-02-21 22:11:12,096 DEBUG TRAIN Batch 11/3000 loss 29.394007 loss_att 40.502888 loss_ctc 27.031685 loss_rnnt 27.340626 hw_loss 0.274834 lr 0.00051362 rank 3
2023-02-21 22:12:27,723 DEBUG TRAIN Batch 11/3100 loss 25.000017 loss_att 26.980598 loss_ctc 31.706415 loss_rnnt 23.584295 hw_loss 0.235160 lr 0.00051335 rank 4
2023-02-21 22:12:27,726 DEBUG TRAIN Batch 11/3100 loss 22.876989 loss_att 26.016636 loss_ctc 27.056143 loss_rnnt 21.561031 hw_loss 0.245268 lr 0.00051335 rank 5
2023-02-21 22:12:27,727 DEBUG TRAIN Batch 11/3100 loss 18.581713 loss_att 23.224039 loss_ctc 22.584869 loss_rnnt 17.015991 hw_loss 0.194069 lr 0.00051335 rank 7
2023-02-21 22:12:27,731 DEBUG TRAIN Batch 11/3100 loss 11.626406 loss_att 18.364931 loss_ctc 13.857727 loss_rnnt 9.897833 hw_loss 0.156297 lr 0.00051335 rank 6
2023-02-21 22:12:27,731 DEBUG TRAIN Batch 11/3100 loss 23.692461 loss_att 31.328476 loss_ctc 25.642298 loss_rnnt 21.834553 hw_loss 0.132607 lr 0.00051335 rank 0
2023-02-21 22:12:27,732 DEBUG TRAIN Batch 11/3100 loss 20.339958 loss_att 28.288906 loss_ctc 24.138256 loss_rnnt 18.091368 hw_loss 0.285677 lr 0.00051335 rank 2
2023-02-21 22:12:27,744 DEBUG TRAIN Batch 11/3100 loss 27.487383 loss_att 24.483194 loss_ctc 25.339209 loss_rnnt 28.271675 hw_loss 0.193066 lr 0.00051335 rank 1
2023-02-21 22:12:27,774 DEBUG TRAIN Batch 11/3100 loss 31.454586 loss_att 37.212547 loss_ctc 41.481094 loss_rnnt 28.848242 hw_loss 0.221032 lr 0.00051335 rank 3
2023-02-21 22:13:46,179 DEBUG TRAIN Batch 11/3200 loss 15.366716 loss_att 17.275557 loss_ctc 14.926669 loss_rnnt 14.867955 hw_loss 0.329373 lr 0.00051308 rank 0
2023-02-21 22:13:46,179 DEBUG TRAIN Batch 11/3200 loss 26.319283 loss_att 32.985325 loss_ctc 24.867512 loss_rnnt 25.079708 hw_loss 0.187376 lr 0.00051308 rank 7
2023-02-21 22:13:46,180 DEBUG TRAIN Batch 11/3200 loss 19.476624 loss_att 34.858402 loss_ctc 15.870414 loss_rnnt 16.830730 hw_loss 0.094434 lr 0.00051308 rank 4
2023-02-21 22:13:46,182 DEBUG TRAIN Batch 11/3200 loss 27.628025 loss_att 48.377663 loss_ctc 31.853392 loss_rnnt 22.843792 hw_loss 0.132984 lr 0.00051308 rank 5
2023-02-21 22:13:46,184 DEBUG TRAIN Batch 11/3200 loss 22.486467 loss_att 37.628632 loss_ctc 25.994955 loss_rnnt 18.915125 hw_loss 0.140833 lr 0.00051308 rank 2
2023-02-21 22:13:46,190 DEBUG TRAIN Batch 11/3200 loss 25.547956 loss_att 44.550293 loss_ctc 26.054531 loss_rnnt 21.532112 hw_loss 0.277185 lr 0.00051308 rank 1
2023-02-21 22:13:46,191 DEBUG TRAIN Batch 11/3200 loss 27.772442 loss_att 51.300972 loss_ctc 28.168102 loss_rnnt 22.934605 hw_loss 0.148823 lr 0.00051308 rank 3
2023-02-21 22:13:46,194 DEBUG TRAIN Batch 11/3200 loss 19.221630 loss_att 28.286966 loss_ctc 17.801056 loss_rnnt 17.492199 hw_loss 0.198326 lr 0.00051308 rank 6
2023-02-21 22:15:00,762 DEBUG TRAIN Batch 11/3300 loss 12.878500 loss_att 23.287397 loss_ctc 13.307178 loss_rnnt 10.554866 hw_loss 0.346307 lr 0.00051281 rank 1
2023-02-21 22:15:00,764 DEBUG TRAIN Batch 11/3300 loss 19.635303 loss_att 30.254156 loss_ctc 18.979900 loss_rnnt 17.526213 hw_loss 0.136326 lr 0.00051281 rank 5
2023-02-21 22:15:00,765 DEBUG TRAIN Batch 11/3300 loss 13.676680 loss_att 26.011358 loss_ctc 12.154708 loss_rnnt 11.297652 hw_loss 0.215666 lr 0.00051281 rank 4
2023-02-21 22:15:00,765 DEBUG TRAIN Batch 11/3300 loss 34.174160 loss_att 40.759518 loss_ctc 37.924042 loss_rnnt 32.225918 hw_loss 0.245978 lr 0.00051281 rank 7
2023-02-21 22:15:00,765 DEBUG TRAIN Batch 11/3300 loss 34.316422 loss_att 44.786884 loss_ctc 44.574844 loss_rnnt 30.835365 hw_loss 0.035951 lr 0.00051281 rank 3
2023-02-21 22:15:00,768 DEBUG TRAIN Batch 11/3300 loss 22.386091 loss_att 31.763950 loss_ctc 27.549500 loss_rnnt 19.781513 hw_loss 0.076034 lr 0.00051281 rank 6
2023-02-21 22:15:00,769 DEBUG TRAIN Batch 11/3300 loss 32.482662 loss_att 46.532478 loss_ctc 27.287098 loss_rnnt 30.201385 hw_loss 0.307601 lr 0.00051281 rank 2
2023-02-21 22:15:00,773 DEBUG TRAIN Batch 11/3300 loss 26.253956 loss_att 39.662449 loss_ctc 30.674416 loss_rnnt 22.807739 hw_loss 0.328355 lr 0.00051281 rank 0
2023-02-21 22:16:14,210 DEBUG TRAIN Batch 11/3400 loss 18.143700 loss_att 27.219225 loss_ctc 14.512165 loss_rnnt 16.596592 hw_loss 0.405387 lr 0.00051254 rank 4
2023-02-21 22:16:14,213 DEBUG TRAIN Batch 11/3400 loss 34.908352 loss_att 46.365646 loss_ctc 44.070099 loss_rnnt 31.316931 hw_loss 0.146991 lr 0.00051254 rank 7
2023-02-21 22:16:14,214 DEBUG TRAIN Batch 11/3400 loss 15.905663 loss_att 31.361900 loss_ctc 14.870462 loss_rnnt 12.860537 hw_loss 0.172321 lr 0.00051254 rank 5
2023-02-21 22:16:14,214 DEBUG TRAIN Batch 11/3400 loss 38.211361 loss_att 52.862717 loss_ctc 51.628765 loss_rnnt 33.360344 hw_loss 0.247047 lr 0.00051254 rank 0
2023-02-21 22:16:14,215 DEBUG TRAIN Batch 11/3400 loss 31.787573 loss_att 35.356396 loss_ctc 36.056988 loss_rnnt 30.478951 hw_loss 0.048005 lr 0.00051254 rank 3
2023-02-21 22:16:14,216 DEBUG TRAIN Batch 11/3400 loss 24.368376 loss_att 37.247360 loss_ctc 25.399864 loss_rnnt 21.580154 hw_loss 0.140423 lr 0.00051254 rank 6
2023-02-21 22:16:14,220 DEBUG TRAIN Batch 11/3400 loss 38.532368 loss_att 57.937248 loss_ctc 43.319672 loss_rnnt 33.903976 hw_loss 0.204571 lr 0.00051254 rank 1
2023-02-21 22:16:14,221 DEBUG TRAIN Batch 11/3400 loss 23.047560 loss_att 36.478622 loss_ctc 27.744919 loss_rnnt 19.671854 hw_loss 0.118455 lr 0.00051254 rank 2
2023-02-21 22:17:29,937 DEBUG TRAIN Batch 11/3500 loss 37.657356 loss_att 52.842728 loss_ctc 40.498543 loss_rnnt 34.072693 hw_loss 0.316424 lr 0.00051228 rank 4
2023-02-21 22:17:29,938 DEBUG TRAIN Batch 11/3500 loss 20.153158 loss_att 24.042120 loss_ctc 22.306206 loss_rnnt 18.999802 hw_loss 0.165921 lr 0.00051228 rank 7
2023-02-21 22:17:29,939 DEBUG TRAIN Batch 11/3500 loss 24.291965 loss_att 29.672279 loss_ctc 25.849598 loss_rnnt 22.918591 hw_loss 0.168056 lr 0.00051228 rank 6
2023-02-21 22:17:29,940 DEBUG TRAIN Batch 11/3500 loss 25.699503 loss_att 42.189301 loss_ctc 27.048792 loss_rnnt 22.144960 hw_loss 0.143765 lr 0.00051228 rank 3
2023-02-21 22:17:29,941 DEBUG TRAIN Batch 11/3500 loss 35.965061 loss_att 44.177860 loss_ctc 39.160080 loss_rnnt 33.795174 hw_loss 0.189984 lr 0.00051228 rank 1
2023-02-21 22:17:29,944 DEBUG TRAIN Batch 11/3500 loss 17.841442 loss_att 32.527180 loss_ctc 18.566238 loss_rnnt 14.715979 hw_loss 0.171896 lr 0.00051228 rank 2
2023-02-21 22:17:29,969 DEBUG TRAIN Batch 11/3500 loss 26.272469 loss_att 34.674854 loss_ctc 30.146454 loss_rnnt 24.034725 hw_loss 0.076381 lr 0.00051228 rank 5
2023-02-21 22:17:29,976 DEBUG TRAIN Batch 11/3500 loss 43.994598 loss_att 60.392559 loss_ctc 52.524757 loss_rnnt 39.520035 hw_loss 0.108028 lr 0.00051228 rank 0
2023-02-21 22:18:46,389 DEBUG TRAIN Batch 11/3600 loss 27.869152 loss_att 31.872522 loss_ctc 27.724651 loss_rnnt 26.990078 hw_loss 0.183129 lr 0.00051201 rank 4
2023-02-21 22:18:46,395 DEBUG TRAIN Batch 11/3600 loss 30.007151 loss_att 36.899681 loss_ctc 31.421694 loss_rnnt 28.388742 hw_loss 0.096176 lr 0.00051201 rank 0
2023-02-21 22:18:46,398 DEBUG TRAIN Batch 11/3600 loss 22.133677 loss_att 34.228409 loss_ctc 27.080944 loss_rnnt 18.950100 hw_loss 0.196864 lr 0.00051201 rank 7
2023-02-21 22:18:46,399 DEBUG TRAIN Batch 11/3600 loss 24.473549 loss_att 29.851864 loss_ctc 25.954697 loss_rnnt 23.094959 hw_loss 0.197696 lr 0.00051201 rank 5
2023-02-21 22:18:46,400 DEBUG TRAIN Batch 11/3600 loss 33.291050 loss_att 37.116806 loss_ctc 42.200466 loss_rnnt 31.247440 hw_loss 0.169750 lr 0.00051201 rank 1
2023-02-21 22:18:46,400 DEBUG TRAIN Batch 11/3600 loss 24.082071 loss_att 30.165573 loss_ctc 25.190208 loss_rnnt 22.639988 hw_loss 0.145557 lr 0.00051201 rank 3
2023-02-21 22:18:46,400 DEBUG TRAIN Batch 11/3600 loss 32.803490 loss_att 49.684849 loss_ctc 36.020405 loss_rnnt 28.887772 hw_loss 0.207233 lr 0.00051201 rank 2
2023-02-21 22:18:46,405 DEBUG TRAIN Batch 11/3600 loss 27.164043 loss_att 31.659065 loss_ctc 34.756470 loss_rnnt 25.166603 hw_loss 0.161461 lr 0.00051201 rank 6
2023-02-21 22:20:03,668 DEBUG TRAIN Batch 11/3700 loss 29.711628 loss_att 42.689079 loss_ctc 35.359001 loss_rnnt 26.283743 hw_loss 0.148899 lr 0.00051174 rank 0
2023-02-21 22:20:03,668 DEBUG TRAIN Batch 11/3700 loss 17.943741 loss_att 27.497906 loss_ctc 16.386524 loss_rnnt 16.141575 hw_loss 0.185553 lr 0.00051174 rank 4
2023-02-21 22:20:03,671 DEBUG TRAIN Batch 11/3700 loss 17.359901 loss_att 20.119928 loss_ctc 21.965231 loss_rnnt 16.099245 hw_loss 0.177386 lr 0.00051174 rank 5
2023-02-21 22:20:03,674 DEBUG TRAIN Batch 11/3700 loss 21.778023 loss_att 27.521336 loss_ctc 25.119267 loss_rnnt 20.104155 hw_loss 0.149451 lr 0.00051174 rank 3
2023-02-21 22:20:03,674 DEBUG TRAIN Batch 11/3700 loss 24.648355 loss_att 29.911547 loss_ctc 29.004343 loss_rnnt 22.885098 hw_loss 0.243417 lr 0.00051174 rank 7
2023-02-21 22:20:03,677 DEBUG TRAIN Batch 11/3700 loss 30.468695 loss_att 39.194103 loss_ctc 38.902916 loss_rnnt 27.480957 hw_loss 0.221426 lr 0.00051174 rank 2
2023-02-21 22:20:03,701 DEBUG TRAIN Batch 11/3700 loss 29.750345 loss_att 36.926399 loss_ctc 29.822886 loss_rnnt 28.254696 hw_loss 0.095189 lr 0.00051174 rank 1
2023-02-21 22:20:03,738 DEBUG TRAIN Batch 11/3700 loss 19.301809 loss_att 22.810833 loss_ctc 16.018389 loss_rnnt 18.900961 hw_loss 0.256562 lr 0.00051174 rank 6
2023-02-21 22:21:17,846 DEBUG TRAIN Batch 11/3800 loss 21.065714 loss_att 25.379114 loss_ctc 26.593243 loss_rnnt 19.348358 hw_loss 0.220631 lr 0.00051147 rank 0
2023-02-21 22:21:17,851 DEBUG TRAIN Batch 11/3800 loss 13.363492 loss_att 20.823338 loss_ctc 14.293455 loss_rnnt 11.589111 hw_loss 0.297033 lr 0.00051147 rank 2
2023-02-21 22:21:17,852 DEBUG TRAIN Batch 11/3800 loss 18.529978 loss_att 34.625027 loss_ctc 21.805466 loss_rnnt 14.813938 hw_loss 0.113058 lr 0.00051147 rank 5
2023-02-21 22:21:17,852 DEBUG TRAIN Batch 11/3800 loss 23.322771 loss_att 22.862001 loss_ctc 24.519979 loss_rnnt 23.093702 hw_loss 0.302992 lr 0.00051147 rank 7
2023-02-21 22:21:17,853 DEBUG TRAIN Batch 11/3800 loss 22.481447 loss_att 30.995253 loss_ctc 26.493742 loss_rnnt 20.123642 hw_loss 0.225132 lr 0.00051147 rank 3
2023-02-21 22:21:17,853 DEBUG TRAIN Batch 11/3800 loss 16.793062 loss_att 20.142517 loss_ctc 18.277824 loss_rnnt 15.798106 hw_loss 0.238303 lr 0.00051147 rank 1
2023-02-21 22:21:17,854 DEBUG TRAIN Batch 11/3800 loss 14.640645 loss_att 14.931887 loss_ctc 17.178495 loss_rnnt 14.075107 hw_loss 0.316706 lr 0.00051147 rank 4
2023-02-21 22:21:17,897 DEBUG TRAIN Batch 11/3800 loss 10.774933 loss_att 10.802281 loss_ctc 11.302552 loss_rnnt 10.586958 hw_loss 0.210292 lr 0.00051147 rank 6
2023-02-21 22:22:34,838 DEBUG TRAIN Batch 11/3900 loss 20.321527 loss_att 35.231346 loss_ctc 22.680960 loss_rnnt 16.916599 hw_loss 0.203199 lr 0.00051120 rank 6
2023-02-21 22:22:34,841 DEBUG TRAIN Batch 11/3900 loss 17.386440 loss_att 25.159449 loss_ctc 16.507637 loss_rnnt 15.928207 hw_loss 0.039008 lr 0.00051120 rank 4
2023-02-21 22:22:34,843 DEBUG TRAIN Batch 11/3900 loss 31.550497 loss_att 48.304436 loss_ctc 37.403114 loss_rnnt 27.309956 hw_loss 0.205133 lr 0.00051120 rank 0
2023-02-21 22:22:34,842 DEBUG TRAIN Batch 11/3900 loss 43.393002 loss_att 59.528458 loss_ctc 47.669949 loss_rnnt 39.530041 hw_loss 0.123022 lr 0.00051120 rank 7
2023-02-21 22:22:34,846 DEBUG TRAIN Batch 11/3900 loss 17.645260 loss_att 21.284531 loss_ctc 17.419724 loss_rnnt 16.878117 hw_loss 0.130055 lr 0.00051120 rank 5
2023-02-21 22:22:34,847 DEBUG TRAIN Batch 11/3900 loss 28.798071 loss_att 37.089684 loss_ctc 31.903357 loss_rnnt 26.635006 hw_loss 0.170072 lr 0.00051120 rank 1
2023-02-21 22:22:34,863 DEBUG TRAIN Batch 11/3900 loss 26.037930 loss_att 33.297821 loss_ctc 31.820141 loss_rnnt 23.701778 hw_loss 0.212273 lr 0.00051120 rank 2
2023-02-21 22:22:34,864 DEBUG TRAIN Batch 11/3900 loss 12.448516 loss_att 18.616062 loss_ctc 9.027487 loss_rnnt 11.599067 hw_loss 0.135144 lr 0.00051120 rank 3
2023-02-21 22:23:49,716 DEBUG TRAIN Batch 11/4000 loss 25.891239 loss_att 32.071434 loss_ctc 27.608084 loss_rnnt 24.369503 hw_loss 0.106474 lr 0.00051094 rank 5
2023-02-21 22:23:49,719 DEBUG TRAIN Batch 11/4000 loss 7.094975 loss_att 12.450112 loss_ctc 6.733537 loss_rnnt 5.935158 hw_loss 0.256839 lr 0.00051094 rank 7
2023-02-21 22:23:49,722 DEBUG TRAIN Batch 11/4000 loss 18.042290 loss_att 27.264294 loss_ctc 22.736019 loss_rnnt 15.445041 hw_loss 0.238160 lr 0.00051094 rank 2
2023-02-21 22:23:49,722 DEBUG TRAIN Batch 11/4000 loss 41.024155 loss_att 53.922230 loss_ctc 47.042294 loss_rnnt 37.530331 hw_loss 0.209614 lr 0.00051094 rank 0
2023-02-21 22:23:49,723 DEBUG TRAIN Batch 11/4000 loss 20.290674 loss_att 34.788925 loss_ctc 16.654196 loss_rnnt 17.810339 hw_loss 0.122906 lr 0.00051094 rank 4
2023-02-21 22:23:49,725 DEBUG TRAIN Batch 11/4000 loss 31.468155 loss_att 41.315563 loss_ctc 41.245026 loss_rnnt 28.082287 hw_loss 0.211512 lr 0.00051094 rank 1
2023-02-21 22:23:49,727 DEBUG TRAIN Batch 11/4000 loss 11.226705 loss_att 16.040888 loss_ctc 17.298433 loss_rnnt 9.333933 hw_loss 0.225695 lr 0.00051094 rank 6
2023-02-21 22:23:49,769 DEBUG TRAIN Batch 11/4000 loss 27.512613 loss_att 36.899021 loss_ctc 28.545609 loss_rnnt 25.246281 hw_loss 0.471220 lr 0.00051094 rank 3
2023-02-21 22:25:04,403 DEBUG TRAIN Batch 11/4100 loss 15.953894 loss_att 21.194431 loss_ctc 20.486467 loss_rnnt 14.244511 hw_loss 0.106747 lr 0.00051067 rank 4
2023-02-21 22:25:04,406 DEBUG TRAIN Batch 11/4100 loss 14.596230 loss_att 23.019300 loss_ctc 14.820606 loss_rnnt 12.780140 hw_loss 0.190422 lr 0.00051067 rank 5
2023-02-21 22:25:04,406 DEBUG TRAIN Batch 11/4100 loss 25.505739 loss_att 37.472935 loss_ctc 33.038689 loss_rnnt 22.058201 hw_loss 0.093200 lr 0.00051067 rank 0
2023-02-21 22:25:04,409 DEBUG TRAIN Batch 11/4100 loss 13.806428 loss_att 19.308836 loss_ctc 13.011149 loss_rnnt 12.718734 hw_loss 0.174844 lr 0.00051067 rank 7
2023-02-21 22:25:04,412 DEBUG TRAIN Batch 11/4100 loss 25.523699 loss_att 31.490223 loss_ctc 25.452909 loss_rnnt 24.261749 hw_loss 0.146401 lr 0.00051067 rank 6
2023-02-21 22:25:04,412 DEBUG TRAIN Batch 11/4100 loss 16.418112 loss_att 26.210365 loss_ctc 18.811026 loss_rnnt 14.059637 hw_loss 0.151817 lr 0.00051067 rank 3
2023-02-21 22:25:04,413 DEBUG TRAIN Batch 11/4100 loss 26.509888 loss_att 31.788599 loss_ctc 26.825108 loss_rnnt 25.252439 hw_loss 0.299397 lr 0.00051067 rank 1
2023-02-21 22:25:04,459 DEBUG TRAIN Batch 11/4100 loss 28.688259 loss_att 33.439457 loss_ctc 28.332762 loss_rnnt 27.704981 hw_loss 0.150820 lr 0.00051067 rank 2
2023-02-21 22:26:20,096 DEBUG TRAIN Batch 11/4200 loss 36.159943 loss_att 41.047161 loss_ctc 39.976189 loss_rnnt 34.555225 hw_loss 0.222074 lr 0.00051040 rank 0
2023-02-21 22:26:20,097 DEBUG TRAIN Batch 11/4200 loss 36.563408 loss_att 44.136410 loss_ctc 39.757317 loss_rnnt 34.524979 hw_loss 0.183710 lr 0.00051040 rank 7
2023-02-21 22:26:20,099 DEBUG TRAIN Batch 11/4200 loss 20.661861 loss_att 25.581532 loss_ctc 19.215225 loss_rnnt 19.770672 hw_loss 0.187762 lr 0.00051040 rank 6
2023-02-21 22:26:20,102 DEBUG TRAIN Batch 11/4200 loss 13.639071 loss_att 19.885187 loss_ctc 15.383097 loss_rnnt 12.043983 hw_loss 0.212491 lr 0.00051040 rank 3
2023-02-21 22:26:20,103 DEBUG TRAIN Batch 11/4200 loss 23.958290 loss_att 35.707420 loss_ctc 26.239857 loss_rnnt 21.196072 hw_loss 0.202842 lr 0.00051040 rank 5
2023-02-21 22:26:20,106 DEBUG TRAIN Batch 11/4200 loss 17.754063 loss_att 25.064629 loss_ctc 18.728212 loss_rnnt 16.057323 hw_loss 0.196383 lr 0.00051040 rank 2
2023-02-21 22:26:20,106 DEBUG TRAIN Batch 11/4200 loss 13.736973 loss_att 22.905130 loss_ctc 12.473192 loss_rnnt 11.981608 hw_loss 0.169193 lr 0.00051040 rank 4
2023-02-21 22:26:20,147 DEBUG TRAIN Batch 11/4200 loss 13.569571 loss_att 24.301733 loss_ctc 17.025236 loss_rnnt 10.770313 hw_loss 0.360133 lr 0.00051040 rank 1
2023-02-21 22:27:39,720 DEBUG TRAIN Batch 11/4300 loss 22.867855 loss_att 28.176466 loss_ctc 23.992672 loss_rnnt 21.554871 hw_loss 0.189914 lr 0.00051014 rank 7
2023-02-21 22:27:39,723 DEBUG TRAIN Batch 11/4300 loss 17.199310 loss_att 21.158316 loss_ctc 20.492119 loss_rnnt 15.855626 hw_loss 0.211577 lr 0.00051014 rank 4
2023-02-21 22:27:39,726 DEBUG TRAIN Batch 11/4300 loss 39.009300 loss_att 48.976601 loss_ctc 49.689842 loss_rnnt 35.450542 hw_loss 0.264798 lr 0.00051014 rank 1
2023-02-21 22:27:39,732 DEBUG TRAIN Batch 11/4300 loss 18.455193 loss_att 24.652508 loss_ctc 17.374214 loss_rnnt 17.263224 hw_loss 0.181192 lr 0.00051014 rank 3
2023-02-21 22:27:39,761 DEBUG TRAIN Batch 11/4300 loss 19.526911 loss_att 24.373068 loss_ctc 23.394754 loss_rnnt 17.987911 hw_loss 0.101354 lr 0.00051014 rank 2
2023-02-21 22:27:39,765 DEBUG TRAIN Batch 11/4300 loss 24.798550 loss_att 33.751129 loss_ctc 32.851093 loss_rnnt 21.864920 hw_loss 0.130207 lr 0.00051014 rank 5
2023-02-21 22:27:39,770 DEBUG TRAIN Batch 11/4300 loss 15.597222 loss_att 24.302694 loss_ctc 19.942080 loss_rnnt 13.228802 hw_loss 0.090019 lr 0.00051014 rank 0
2023-02-21 22:27:39,772 DEBUG TRAIN Batch 11/4300 loss 25.412085 loss_att 29.864483 loss_ctc 29.919392 loss_rnnt 23.784466 hw_loss 0.255311 lr 0.00051014 rank 6
2023-02-21 22:28:55,853 DEBUG TRAIN Batch 11/4400 loss 20.196636 loss_att 26.082361 loss_ctc 19.446585 loss_rnnt 18.986303 hw_loss 0.249744 lr 0.00050987 rank 0
2023-02-21 22:28:55,857 DEBUG TRAIN Batch 11/4400 loss 11.280304 loss_att 18.965572 loss_ctc 12.868228 loss_rnnt 9.378017 hw_loss 0.287830 lr 0.00050987 rank 1
2023-02-21 22:28:55,857 DEBUG TRAIN Batch 11/4400 loss 12.223191 loss_att 16.641285 loss_ctc 13.402835 loss_rnnt 11.086671 hw_loss 0.179279 lr 0.00050987 rank 7
2023-02-21 22:28:55,859 DEBUG TRAIN Batch 11/4400 loss 37.955219 loss_att 74.567703 loss_ctc 33.135628 loss_rnnt 31.222090 hw_loss 0.099845 lr 0.00050987 rank 5
2023-02-21 22:28:55,860 DEBUG TRAIN Batch 11/4400 loss 9.434437 loss_att 16.073635 loss_ctc 15.702606 loss_rnnt 7.205453 hw_loss 0.122601 lr 0.00050987 rank 2
2023-02-21 22:28:55,861 DEBUG TRAIN Batch 11/4400 loss 22.622314 loss_att 21.632004 loss_ctc 23.609684 loss_rnnt 22.537134 hw_loss 0.284237 lr 0.00050987 rank 3
2023-02-21 22:28:55,862 DEBUG TRAIN Batch 11/4400 loss 16.204937 loss_att 17.923706 loss_ctc 16.029243 loss_rnnt 15.729761 hw_loss 0.290336 lr 0.00050987 rank 4
2023-02-21 22:28:55,914 DEBUG TRAIN Batch 11/4400 loss 13.118880 loss_att 17.955118 loss_ctc 16.327812 loss_rnnt 11.609049 hw_loss 0.215110 lr 0.00050987 rank 6
2023-02-21 22:30:10,778 DEBUG TRAIN Batch 11/4500 loss 5.760401 loss_att 12.377616 loss_ctc 5.940256 loss_rnnt 4.298322 hw_loss 0.214979 lr 0.00050961 rank 7
2023-02-21 22:30:10,779 DEBUG TRAIN Batch 11/4500 loss 35.797783 loss_att 43.877850 loss_ctc 40.495224 loss_rnnt 33.472565 hw_loss 0.155402 lr 0.00050961 rank 3
2023-02-21 22:30:10,781 DEBUG TRAIN Batch 11/4500 loss 17.281605 loss_att 27.563316 loss_ctc 20.401173 loss_rnnt 14.674749 hw_loss 0.252323 lr 0.00050961 rank 4
2023-02-21 22:30:10,783 DEBUG TRAIN Batch 11/4500 loss 9.309792 loss_att 19.957796 loss_ctc 15.818235 loss_rnnt 6.261247 hw_loss 0.095909 lr 0.00050961 rank 2
2023-02-21 22:30:10,785 DEBUG TRAIN Batch 11/4500 loss 25.287836 loss_att 34.750778 loss_ctc 32.069405 loss_rnnt 22.397003 hw_loss 0.176319 lr 0.00050961 rank 1
2023-02-21 22:30:10,788 DEBUG TRAIN Batch 11/4500 loss 13.969787 loss_att 21.065624 loss_ctc 13.188784 loss_rnnt 12.552053 hw_loss 0.192562 lr 0.00050961 rank 6
2023-02-21 22:30:10,815 DEBUG TRAIN Batch 11/4500 loss 22.924091 loss_att 30.677982 loss_ctc 27.170532 loss_rnnt 20.708431 hw_loss 0.185041 lr 0.00050961 rank 5
2023-02-21 22:30:10,818 DEBUG TRAIN Batch 11/4500 loss 15.908403 loss_att 14.485470 loss_ctc 18.591871 loss_rnnt 15.658476 hw_loss 0.331350 lr 0.00050961 rank 0
2023-02-21 22:31:27,628 DEBUG TRAIN Batch 11/4600 loss 29.582928 loss_att 41.860714 loss_ctc 35.255596 loss_rnnt 26.291397 hw_loss 0.149276 lr 0.00050934 rank 0
2023-02-21 22:31:27,632 DEBUG TRAIN Batch 11/4600 loss 19.658453 loss_att 27.371693 loss_ctc 24.965664 loss_rnnt 17.313969 hw_loss 0.176638 lr 0.00050934 rank 5
2023-02-21 22:31:27,633 DEBUG TRAIN Batch 11/4600 loss 19.887974 loss_att 32.668648 loss_ctc 23.899710 loss_rnnt 16.746868 hw_loss 0.093888 lr 0.00050934 rank 3
2023-02-21 22:31:27,633 DEBUG TRAIN Batch 11/4600 loss 23.908821 loss_att 33.837368 loss_ctc 26.977385 loss_rnnt 21.420349 hw_loss 0.175536 lr 0.00050934 rank 7
2023-02-21 22:31:27,634 DEBUG TRAIN Batch 11/4600 loss 24.492563 loss_att 33.132195 loss_ctc 27.563793 loss_rnnt 22.266722 hw_loss 0.165784 lr 0.00050934 rank 6
2023-02-21 22:31:27,638 DEBUG TRAIN Batch 11/4600 loss 63.255371 loss_att 86.427238 loss_ctc 72.459953 loss_rnnt 57.337669 hw_loss 0.105095 lr 0.00050934 rank 4
2023-02-21 22:31:27,639 DEBUG TRAIN Batch 11/4600 loss 26.243900 loss_att 34.950806 loss_ctc 37.299633 loss_rnnt 22.888493 hw_loss 0.262367 lr 0.00050934 rank 1
2023-02-21 22:31:27,642 DEBUG TRAIN Batch 11/4600 loss 10.097202 loss_att 16.969093 loss_ctc 7.890761 loss_rnnt 8.856517 hw_loss 0.300936 lr 0.00050934 rank 2
2023-02-21 22:32:43,965 DEBUG TRAIN Batch 11/4700 loss 34.126884 loss_att 46.210075 loss_ctc 38.175507 loss_rnnt 30.991203 hw_loss 0.336046 lr 0.00050908 rank 7
2023-02-21 22:32:43,965 DEBUG TRAIN Batch 11/4700 loss 14.912947 loss_att 22.827074 loss_ctc 15.858539 loss_rnnt 13.043709 hw_loss 0.300628 lr 0.00050908 rank 0
2023-02-21 22:32:43,966 DEBUG TRAIN Batch 11/4700 loss 11.058387 loss_att 18.706923 loss_ctc 10.351726 loss_rnnt 9.544613 hw_loss 0.146792 lr 0.00050908 rank 5
2023-02-21 22:32:43,967 DEBUG TRAIN Batch 11/4700 loss 28.101927 loss_att 44.345169 loss_ctc 37.479874 loss_rnnt 23.447561 hw_loss 0.291232 lr 0.00050908 rank 1
2023-02-21 22:32:43,969 DEBUG TRAIN Batch 11/4700 loss 34.048431 loss_att 46.891289 loss_ctc 42.872105 loss_rnnt 30.282030 hw_loss 0.040010 lr 0.00050908 rank 4
2023-02-21 22:32:43,971 DEBUG TRAIN Batch 11/4700 loss 26.784231 loss_att 34.101425 loss_ctc 34.151592 loss_rnnt 24.272964 hw_loss 0.122838 lr 0.00050908 rank 6
2023-02-21 22:32:43,973 DEBUG TRAIN Batch 11/4700 loss 10.861148 loss_att 18.942503 loss_ctc 12.759295 loss_rnnt 8.843987 hw_loss 0.277133 lr 0.00050908 rank 3
2023-02-21 22:32:44,019 DEBUG TRAIN Batch 11/4700 loss 25.686056 loss_att 34.695137 loss_ctc 27.761856 loss_rnnt 23.511614 hw_loss 0.179719 lr 0.00050908 rank 2
2023-02-21 22:33:58,993 DEBUG TRAIN Batch 11/4800 loss 7.041956 loss_att 13.651157 loss_ctc 7.086245 loss_rnnt 5.646379 hw_loss 0.127186 lr 0.00050882 rank 0
2023-02-21 22:33:58,994 DEBUG TRAIN Batch 11/4800 loss 27.640121 loss_att 30.415081 loss_ctc 31.425673 loss_rnnt 26.445122 hw_loss 0.253631 lr 0.00050882 rank 7
2023-02-21 22:33:58,994 DEBUG TRAIN Batch 11/4800 loss 20.278418 loss_att 29.329544 loss_ctc 22.449860 loss_rnnt 18.031981 hw_loss 0.275038 lr 0.00050882 rank 5
2023-02-21 22:33:58,995 DEBUG TRAIN Batch 11/4800 loss 17.801828 loss_att 24.517977 loss_ctc 22.142315 loss_rnnt 15.776354 hw_loss 0.194087 lr 0.00050882 rank 1
2023-02-21 22:33:58,998 DEBUG TRAIN Batch 11/4800 loss 19.187916 loss_att 31.007084 loss_ctc 24.760254 loss_rnnt 15.948540 hw_loss 0.248555 lr 0.00050882 rank 4
2023-02-21 22:33:59,002 DEBUG TRAIN Batch 11/4800 loss 28.347937 loss_att 34.178074 loss_ctc 35.929096 loss_rnnt 26.074667 hw_loss 0.180794 lr 0.00050882 rank 3
2023-02-21 22:33:59,004 DEBUG TRAIN Batch 11/4800 loss 22.372232 loss_att 21.762859 loss_ctc 23.251947 loss_rnnt 22.280727 hw_loss 0.180158 lr 0.00050882 rank 2
2023-02-21 22:33:59,047 DEBUG TRAIN Batch 11/4800 loss 19.588879 loss_att 25.706692 loss_ctc 23.797646 loss_rnnt 17.660069 hw_loss 0.270150 lr 0.00050882 rank 6
2023-02-21 22:35:14,547 DEBUG TRAIN Batch 11/4900 loss 35.189827 loss_att 46.466225 loss_ctc 41.622032 loss_rnnt 31.953135 hw_loss 0.232092 lr 0.00050855 rank 7
2023-02-21 22:35:14,547 DEBUG TRAIN Batch 11/4900 loss 17.224789 loss_att 18.267910 loss_ctc 17.883976 loss_rnnt 16.777512 hw_loss 0.282681 lr 0.00050855 rank 4
2023-02-21 22:35:14,551 DEBUG TRAIN Batch 11/4900 loss 11.528208 loss_att 20.111807 loss_ctc 15.019682 loss_rnnt 9.240366 hw_loss 0.197985 lr 0.00050855 rank 0
2023-02-21 22:35:14,551 DEBUG TRAIN Batch 11/4900 loss 30.307049 loss_att 37.213161 loss_ctc 31.591293 loss_rnnt 28.711172 hw_loss 0.081415 lr 0.00050855 rank 6
2023-02-21 22:35:14,552 DEBUG TRAIN Batch 11/4900 loss 7.605851 loss_att 12.040895 loss_ctc 7.209500 loss_rnnt 6.737510 hw_loss 0.064086 lr 0.00050855 rank 5
2023-02-21 22:35:14,553 DEBUG TRAIN Batch 11/4900 loss 14.225091 loss_att 16.698561 loss_ctc 16.024698 loss_rnnt 13.360383 hw_loss 0.243876 lr 0.00050855 rank 2
2023-02-21 22:35:14,556 DEBUG TRAIN Batch 11/4900 loss 21.609020 loss_att 26.472340 loss_ctc 25.745386 loss_rnnt 20.025713 hw_loss 0.110861 lr 0.00050855 rank 3
2023-02-21 22:35:14,603 DEBUG TRAIN Batch 11/4900 loss 16.296259 loss_att 21.213367 loss_ctc 20.218887 loss_rnnt 14.686544 hw_loss 0.193643 lr 0.00050855 rank 1
2023-02-21 22:36:31,929 DEBUG TRAIN Batch 11/5000 loss 18.278294 loss_att 21.459944 loss_ctc 26.577419 loss_rnnt 16.402855 hw_loss 0.248549 lr 0.00050829 rank 0
2023-02-21 22:36:31,929 DEBUG TRAIN Batch 11/5000 loss 24.701164 loss_att 29.124432 loss_ctc 24.125942 loss_rnnt 23.811245 hw_loss 0.153683 lr 0.00050829 rank 1
2023-02-21 22:36:31,929 DEBUG TRAIN Batch 11/5000 loss 28.351463 loss_att 26.926228 loss_ctc 33.922108 loss_rnnt 27.733448 hw_loss 0.300579 lr 0.00050829 rank 6
2023-02-21 22:36:31,929 DEBUG TRAIN Batch 11/5000 loss 16.244347 loss_att 21.526552 loss_ctc 18.769606 loss_rnnt 14.789882 hw_loss 0.114979 lr 0.00050829 rank 4
2023-02-21 22:36:31,931 DEBUG TRAIN Batch 11/5000 loss 24.947725 loss_att 32.417973 loss_ctc 33.031658 loss_rnnt 22.202467 hw_loss 0.325036 lr 0.00050829 rank 7
2023-02-21 22:36:31,931 DEBUG TRAIN Batch 11/5000 loss 13.528715 loss_att 17.326157 loss_ctc 15.002352 loss_rnnt 12.480433 hw_loss 0.173077 lr 0.00050829 rank 3
2023-02-21 22:36:31,934 DEBUG TRAIN Batch 11/5000 loss 18.882078 loss_att 19.789669 loss_ctc 20.180693 loss_rnnt 18.449791 hw_loss 0.145537 lr 0.00050829 rank 5
2023-02-21 22:36:31,979 DEBUG TRAIN Batch 11/5000 loss 16.858957 loss_att 23.064465 loss_ctc 19.371759 loss_rnnt 15.164486 hw_loss 0.221869 lr 0.00050829 rank 2
2023-02-21 22:37:47,328 DEBUG TRAIN Batch 11/5100 loss 15.034282 loss_att 14.498129 loss_ctc 15.903851 loss_rnnt 14.858446 hw_loss 0.313356 lr 0.00050803 rank 0
2023-02-21 22:37:47,328 DEBUG TRAIN Batch 11/5100 loss 14.234845 loss_att 21.144600 loss_ctc 16.944607 loss_rnnt 12.408889 hw_loss 0.155070 lr 0.00050803 rank 5
2023-02-21 22:37:47,329 DEBUG TRAIN Batch 11/5100 loss 18.291042 loss_att 27.074535 loss_ctc 24.677170 loss_rnnt 15.682707 hw_loss 0.000286 lr 0.00050803 rank 7
2023-02-21 22:37:47,334 DEBUG TRAIN Batch 11/5100 loss 14.532624 loss_att 14.727247 loss_ctc 15.283945 loss_rnnt 14.188066 hw_loss 0.385229 lr 0.00050803 rank 3
2023-02-21 22:37:47,334 DEBUG TRAIN Batch 11/5100 loss 19.470118 loss_att 25.370342 loss_ctc 20.739618 loss_rnnt 17.978632 hw_loss 0.266575 lr 0.00050803 rank 6
2023-02-21 22:37:47,334 DEBUG TRAIN Batch 11/5100 loss 13.951511 loss_att 13.908989 loss_ctc 12.555141 loss_rnnt 14.058390 hw_loss 0.164640 lr 0.00050803 rank 1
2023-02-21 22:37:47,336 DEBUG TRAIN Batch 11/5100 loss 17.870613 loss_att 23.832903 loss_ctc 16.630060 loss_rnnt 16.776615 hw_loss 0.125527 lr 0.00050803 rank 4
2023-02-21 22:37:47,340 DEBUG TRAIN Batch 11/5100 loss 11.358504 loss_att 16.477697 loss_ctc 17.444445 loss_rnnt 9.428440 hw_loss 0.177685 lr 0.00050803 rank 2
2023-02-21 22:39:03,165 DEBUG TRAIN Batch 11/5200 loss 15.499010 loss_att 23.512539 loss_ctc 15.219679 loss_rnnt 13.771976 hw_loss 0.302948 lr 0.00050776 rank 5
2023-02-21 22:39:03,165 DEBUG TRAIN Batch 11/5200 loss 6.820946 loss_att 15.715671 loss_ctc 8.484709 loss_rnnt 4.803040 hw_loss 0.032113 lr 0.00050776 rank 4
2023-02-21 22:39:03,168 DEBUG TRAIN Batch 11/5200 loss 27.723911 loss_att 31.074451 loss_ctc 30.353470 loss_rnnt 26.629492 hw_loss 0.138195 lr 0.00050776 rank 0
2023-02-21 22:39:03,169 DEBUG TRAIN Batch 11/5200 loss 14.763927 loss_att 21.311954 loss_ctc 18.494949 loss_rnnt 12.856110 hw_loss 0.188892 lr 0.00050776 rank 6
2023-02-21 22:39:03,170 DEBUG TRAIN Batch 11/5200 loss 51.035812 loss_att 64.375839 loss_ctc 56.459137 loss_rnnt 47.475990 hw_loss 0.316329 lr 0.00050776 rank 2
2023-02-21 22:39:03,171 DEBUG TRAIN Batch 11/5200 loss 16.792767 loss_att 19.391201 loss_ctc 20.219948 loss_rnnt 15.800601 hw_loss 0.029102 lr 0.00050776 rank 7
2023-02-21 22:39:03,171 DEBUG TRAIN Batch 11/5200 loss 21.970591 loss_att 30.216812 loss_ctc 22.193527 loss_rnnt 20.206036 hw_loss 0.160473 lr 0.00050776 rank 3
2023-02-21 22:39:03,218 DEBUG TRAIN Batch 11/5200 loss 17.151270 loss_att 27.769369 loss_ctc 21.529068 loss_rnnt 14.380568 hw_loss 0.118834 lr 0.00050776 rank 1
2023-02-21 22:40:20,280 DEBUG TRAIN Batch 11/5300 loss 27.181957 loss_att 32.785431 loss_ctc 33.370918 loss_rnnt 25.163315 hw_loss 0.136412 lr 0.00050750 rank 0
2023-02-21 22:40:20,280 DEBUG TRAIN Batch 11/5300 loss 22.834078 loss_att 31.012632 loss_ctc 23.686646 loss_rnnt 20.906233 hw_loss 0.334611 lr 0.00050750 rank 7
2023-02-21 22:40:20,281 DEBUG TRAIN Batch 11/5300 loss 19.558750 loss_att 26.178589 loss_ctc 22.094193 loss_rnnt 17.841099 hw_loss 0.104292 lr 0.00050750 rank 6
2023-02-21 22:40:20,281 DEBUG TRAIN Batch 11/5300 loss 15.566812 loss_att 18.760815 loss_ctc 17.162388 loss_rnnt 14.679289 hw_loss 0.067459 lr 0.00050750 rank 4
2023-02-21 22:40:20,284 DEBUG TRAIN Batch 11/5300 loss 25.504282 loss_att 27.336107 loss_ctc 34.073303 loss_rnnt 23.889023 hw_loss 0.199422 lr 0.00050750 rank 3
2023-02-21 22:40:20,286 DEBUG TRAIN Batch 11/5300 loss 15.921432 loss_att 27.229046 loss_ctc 21.440372 loss_rnnt 12.823637 hw_loss 0.188276 lr 0.00050750 rank 2
2023-02-21 22:40:20,287 DEBUG TRAIN Batch 11/5300 loss 37.797737 loss_att 37.766647 loss_ctc 42.241997 loss_rnnt 37.130199 hw_loss 0.152222 lr 0.00050750 rank 5
2023-02-21 22:40:20,329 DEBUG TRAIN Batch 11/5300 loss 20.225101 loss_att 31.682270 loss_ctc 21.171944 loss_rnnt 17.692307 hw_loss 0.215842 lr 0.00050750 rank 1
2023-02-21 22:41:36,568 DEBUG TRAIN Batch 11/5400 loss 25.819960 loss_att 40.961456 loss_ctc 29.734503 loss_rnnt 22.160761 hw_loss 0.204303 lr 0.00050724 rank 4
2023-02-21 22:41:36,570 DEBUG TRAIN Batch 11/5400 loss 9.377100 loss_att 13.779500 loss_ctc 8.973366 loss_rnnt 8.446988 hw_loss 0.193992 lr 0.00050724 rank 0
2023-02-21 22:41:36,571 DEBUG TRAIN Batch 11/5400 loss 10.392598 loss_att 19.214609 loss_ctc 15.286438 loss_rnnt 7.932199 hw_loss 0.081532 lr 0.00050724 rank 6
2023-02-21 22:41:36,573 DEBUG TRAIN Batch 11/5400 loss 24.775436 loss_att 32.503197 loss_ctc 29.839451 loss_rnnt 22.478554 hw_loss 0.142736 lr 0.00050724 rank 7
2023-02-21 22:41:36,574 DEBUG TRAIN Batch 11/5400 loss 19.882212 loss_att 28.413456 loss_ctc 24.169081 loss_rnnt 17.579163 hw_loss 0.047284 lr 0.00050724 rank 5
2023-02-21 22:41:36,574 DEBUG TRAIN Batch 11/5400 loss 17.847168 loss_att 28.369179 loss_ctc 22.565380 loss_rnnt 15.008936 hw_loss 0.196375 lr 0.00050724 rank 3
2023-02-21 22:41:36,577 DEBUG TRAIN Batch 11/5400 loss 31.170034 loss_att 38.962086 loss_ctc 40.484112 loss_rnnt 28.277241 hw_loss 0.173447 lr 0.00050724 rank 1
2023-02-21 22:41:36,579 DEBUG TRAIN Batch 11/5400 loss 16.704287 loss_att 29.805763 loss_ctc 20.598877 loss_rnnt 13.526724 hw_loss 0.071232 lr 0.00050724 rank 2
2023-02-21 22:42:51,920 DEBUG TRAIN Batch 11/5500 loss 13.157204 loss_att 16.709352 loss_ctc 17.396111 loss_rnnt 11.859394 hw_loss 0.041612 lr 0.00050698 rank 4
2023-02-21 22:42:51,921 DEBUG TRAIN Batch 11/5500 loss 20.344973 loss_att 28.301588 loss_ctc 23.264986 loss_rnnt 18.243315 hw_loss 0.226872 lr 0.00050698 rank 5
2023-02-21 22:42:51,926 DEBUG TRAIN Batch 11/5500 loss 19.782696 loss_att 26.056541 loss_ctc 20.202013 loss_rnnt 18.358648 hw_loss 0.212569 lr 0.00050698 rank 6
2023-02-21 22:42:51,926 DEBUG TRAIN Batch 11/5500 loss 21.528057 loss_att 27.740669 loss_ctc 27.774817 loss_rnnt 19.337692 hw_loss 0.215517 lr 0.00050698 rank 7
2023-02-21 22:42:51,928 DEBUG TRAIN Batch 11/5500 loss 29.823599 loss_att 40.576637 loss_ctc 36.181435 loss_rnnt 26.760931 hw_loss 0.120652 lr 0.00050698 rank 0
2023-02-21 22:42:51,929 DEBUG TRAIN Batch 11/5500 loss 20.564348 loss_att 25.393101 loss_ctc 24.654930 loss_rnnt 19.035007 hw_loss 0.034083 lr 0.00050698 rank 1
2023-02-21 22:42:51,931 DEBUG TRAIN Batch 11/5500 loss 28.535185 loss_att 38.176693 loss_ctc 37.971382 loss_rnnt 25.242214 hw_loss 0.199706 lr 0.00050698 rank 3
2023-02-21 22:42:51,931 DEBUG TRAIN Batch 11/5500 loss 20.142847 loss_att 22.971214 loss_ctc 23.379585 loss_rnnt 19.145504 hw_loss 0.000196 lr 0.00050698 rank 2
2023-02-21 22:44:06,593 DEBUG TRAIN Batch 11/5600 loss 40.719521 loss_att 46.592049 loss_ctc 48.867344 loss_rnnt 38.381126 hw_loss 0.145331 lr 0.00050672 rank 1
2023-02-21 22:44:06,593 DEBUG TRAIN Batch 11/5600 loss 16.063898 loss_att 26.174141 loss_ctc 21.130854 loss_rnnt 13.283696 hw_loss 0.154797 lr 0.00050672 rank 0
2023-02-21 22:44:06,597 DEBUG TRAIN Batch 11/5600 loss 12.737229 loss_att 17.848814 loss_ctc 15.739630 loss_rnnt 11.255282 hw_loss 0.111205 lr 0.00050672 rank 4
2023-02-21 22:44:06,598 DEBUG TRAIN Batch 11/5600 loss 30.472679 loss_att 34.553513 loss_ctc 37.484039 loss_rnnt 28.682501 hw_loss 0.073433 lr 0.00050672 rank 5
2023-02-21 22:44:06,600 DEBUG TRAIN Batch 11/5600 loss 17.771729 loss_att 21.846586 loss_ctc 18.760351 loss_rnnt 16.764984 hw_loss 0.112418 lr 0.00050672 rank 6
2023-02-21 22:44:06,601 DEBUG TRAIN Batch 11/5600 loss 15.491597 loss_att 21.564175 loss_ctc 18.249643 loss_rnnt 13.822864 hw_loss 0.162146 lr 0.00050672 rank 2
2023-02-21 22:44:06,601 DEBUG TRAIN Batch 11/5600 loss 15.503386 loss_att 18.207081 loss_ctc 17.954031 loss_rnnt 14.583246 hw_loss 0.098716 lr 0.00050672 rank 3
2023-02-21 22:44:06,603 DEBUG TRAIN Batch 11/5600 loss 9.742307 loss_att 15.651395 loss_ctc 12.824915 loss_rnnt 8.072299 hw_loss 0.144704 lr 0.00050672 rank 7
2023-02-21 22:45:24,789 DEBUG TRAIN Batch 11/5700 loss 19.110979 loss_att 19.414013 loss_ctc 21.391111 loss_rnnt 18.600246 hw_loss 0.273950 lr 0.00050646 rank 7
2023-02-21 22:45:24,789 DEBUG TRAIN Batch 11/5700 loss 17.516531 loss_att 20.082249 loss_ctc 18.626455 loss_rnnt 16.765358 hw_loss 0.168824 lr 0.00050646 rank 1
2023-02-21 22:45:24,793 DEBUG TRAIN Batch 11/5700 loss 39.311630 loss_att 45.007164 loss_ctc 46.443237 loss_rnnt 37.157845 hw_loss 0.119623 lr 0.00050646 rank 5
2023-02-21 22:45:24,796 DEBUG TRAIN Batch 11/5700 loss 30.062618 loss_att 42.441814 loss_ctc 32.420582 loss_rnnt 27.211056 hw_loss 0.114993 lr 0.00050646 rank 2
2023-02-21 22:45:24,796 DEBUG TRAIN Batch 11/5700 loss 30.334637 loss_att 41.363914 loss_ctc 36.742523 loss_rnnt 27.205856 hw_loss 0.128513 lr 0.00050646 rank 6
2023-02-21 22:45:24,797 DEBUG TRAIN Batch 11/5700 loss 13.805642 loss_att 16.798983 loss_ctc 15.993738 loss_rnnt 12.837256 hw_loss 0.146195 lr 0.00050646 rank 4
2023-02-21 22:45:24,798 DEBUG TRAIN Batch 11/5700 loss 9.157851 loss_att 13.360891 loss_ctc 9.943931 loss_rnnt 8.117320 hw_loss 0.178337 lr 0.00050646 rank 3
2023-02-21 22:45:24,803 DEBUG TRAIN Batch 11/5700 loss 26.798746 loss_att 27.466469 loss_ctc 31.678905 loss_rnnt 25.890446 hw_loss 0.232627 lr 0.00050646 rank 0
2023-02-21 22:46:38,637 DEBUG TRAIN Batch 11/5800 loss 12.533281 loss_att 20.956036 loss_ctc 12.506395 loss_rnnt 10.801967 hw_loss 0.094403 lr 0.00050620 rank 0
2023-02-21 22:46:38,641 DEBUG TRAIN Batch 11/5800 loss 16.030655 loss_att 27.454731 loss_ctc 26.444242 loss_rnnt 12.286772 hw_loss 0.132357 lr 0.00050620 rank 5
2023-02-21 22:46:38,642 DEBUG TRAIN Batch 11/5800 loss 10.152591 loss_att 16.242647 loss_ctc 12.462563 loss_rnnt 8.576612 hw_loss 0.093696 lr 0.00050620 rank 4
2023-02-21 22:46:38,642 DEBUG TRAIN Batch 11/5800 loss 23.776972 loss_att 37.477287 loss_ctc 27.245667 loss_rnnt 20.514500 hw_loss 0.112343 lr 0.00050620 rank 7
2023-02-21 22:46:38,648 DEBUG TRAIN Batch 11/5800 loss 26.648872 loss_att 39.121090 loss_ctc 27.305998 loss_rnnt 24.036995 hw_loss 0.055906 lr 0.00050620 rank 6
2023-02-21 22:46:38,648 DEBUG TRAIN Batch 11/5800 loss 14.930337 loss_att 16.965181 loss_ctc 15.525250 loss_rnnt 14.328570 hw_loss 0.216519 lr 0.00050620 rank 1
2023-02-21 22:46:38,648 DEBUG TRAIN Batch 11/5800 loss 17.145699 loss_att 22.862135 loss_ctc 21.033585 loss_rnnt 15.352061 hw_loss 0.247434 lr 0.00050620 rank 3
2023-02-21 22:46:38,651 DEBUG TRAIN Batch 11/5800 loss 6.905130 loss_att 16.397465 loss_ctc 6.087123 loss_rnnt 4.988388 hw_loss 0.238768 lr 0.00050620 rank 2
2023-02-21 22:47:54,093 DEBUG TRAIN Batch 11/5900 loss 17.726835 loss_att 21.702600 loss_ctc 20.902332 loss_rnnt 16.409317 hw_loss 0.185561 lr 0.00050594 rank 5
2023-02-21 22:47:54,095 DEBUG TRAIN Batch 11/5900 loss 12.968993 loss_att 16.457022 loss_ctc 17.069479 loss_rnnt 11.629279 hw_loss 0.178831 lr 0.00050594 rank 4
2023-02-21 22:47:54,098 DEBUG TRAIN Batch 11/5900 loss 24.263683 loss_att 22.335678 loss_ctc 23.688259 loss_rnnt 24.664480 hw_loss 0.115367 lr 0.00050594 rank 0
2023-02-21 22:47:54,101 DEBUG TRAIN Batch 11/5900 loss 33.419910 loss_att 47.182587 loss_ctc 49.276413 loss_rnnt 28.438141 hw_loss 0.215694 lr 0.00050594 rank 7
2023-02-21 22:47:54,102 DEBUG TRAIN Batch 11/5900 loss 12.255028 loss_att 14.703175 loss_ctc 12.605612 loss_rnnt 11.658117 hw_loss 0.113507 lr 0.00050594 rank 2
2023-02-21 22:47:54,104 DEBUG TRAIN Batch 11/5900 loss 15.094444 loss_att 22.425137 loss_ctc 18.820768 loss_rnnt 13.014088 hw_loss 0.220077 lr 0.00050594 rank 6
2023-02-21 22:47:54,105 DEBUG TRAIN Batch 11/5900 loss 19.376930 loss_att 28.482237 loss_ctc 28.020298 loss_rnnt 16.291082 hw_loss 0.210632 lr 0.00050594 rank 1
2023-02-21 22:47:54,106 DEBUG TRAIN Batch 11/5900 loss 29.229202 loss_att 30.824919 loss_ctc 34.923378 loss_rnnt 28.060074 hw_loss 0.170179 lr 0.00050594 rank 3
2023-02-21 22:49:11,185 DEBUG TRAIN Batch 11/6000 loss 14.173748 loss_att 21.984970 loss_ctc 18.654604 loss_rnnt 11.959597 hw_loss 0.102111 lr 0.00050568 rank 7
2023-02-21 22:49:11,188 DEBUG TRAIN Batch 11/6000 loss 23.900637 loss_att 29.463583 loss_ctc 28.453588 loss_rnnt 22.041748 hw_loss 0.261073 lr 0.00050568 rank 5
2023-02-21 22:49:11,192 DEBUG TRAIN Batch 11/6000 loss 24.129969 loss_att 32.546204 loss_ctc 28.181990 loss_rnnt 21.813362 hw_loss 0.174540 lr 0.00050568 rank 6
2023-02-21 22:49:11,193 DEBUG TRAIN Batch 11/6000 loss 13.739367 loss_att 19.904278 loss_ctc 20.176998 loss_rnnt 11.542707 hw_loss 0.197486 lr 0.00050568 rank 2
2023-02-21 22:49:11,193 DEBUG TRAIN Batch 11/6000 loss 5.655791 loss_att 11.057511 loss_ctc 7.127298 loss_rnnt 4.225184 hw_loss 0.288865 lr 0.00050568 rank 4
2023-02-21 22:49:11,195 DEBUG TRAIN Batch 11/6000 loss 24.366171 loss_att 31.367336 loss_ctc 35.437618 loss_rnnt 21.399870 hw_loss 0.168512 lr 0.00050568 rank 0
2023-02-21 22:49:11,198 DEBUG TRAIN Batch 11/6000 loss 15.895062 loss_att 17.839695 loss_ctc 16.408089 loss_rnnt 15.323886 hw_loss 0.213463 lr 0.00050568 rank 1
2023-02-21 22:49:11,244 DEBUG TRAIN Batch 11/6000 loss 10.172408 loss_att 15.600869 loss_ctc 13.583552 loss_rnnt 8.592164 hw_loss 0.074495 lr 0.00050568 rank 3
2023-02-21 22:50:28,563 DEBUG TRAIN Batch 11/6100 loss 25.155069 loss_att 32.239319 loss_ctc 25.099270 loss_rnnt 23.638662 hw_loss 0.200618 lr 0.00050542 rank 1
2023-02-21 22:50:28,567 DEBUG TRAIN Batch 11/6100 loss 19.451729 loss_att 24.291718 loss_ctc 21.634382 loss_rnnt 18.092968 hw_loss 0.187013 lr 0.00050542 rank 4
2023-02-21 22:50:28,569 DEBUG TRAIN Batch 11/6100 loss 13.049357 loss_att 18.023643 loss_ctc 13.735470 loss_rnnt 11.896564 hw_loss 0.124601 lr 0.00050542 rank 0
2023-02-21 22:50:28,570 DEBUG TRAIN Batch 11/6100 loss 27.902746 loss_att 34.991451 loss_ctc 32.237694 loss_rnnt 25.778614 hw_loss 0.240740 lr 0.00050542 rank 5
2023-02-21 22:50:28,571 DEBUG TRAIN Batch 11/6100 loss 30.470324 loss_att 30.012007 loss_ctc 35.986702 loss_rnnt 29.712261 hw_loss 0.214141 lr 0.00050542 rank 6
2023-02-21 22:50:28,570 DEBUG TRAIN Batch 11/6100 loss 24.017254 loss_att 30.970064 loss_ctc 27.524263 loss_rnnt 22.107782 hw_loss 0.096200 lr 0.00050542 rank 7
2023-02-21 22:50:28,573 DEBUG TRAIN Batch 11/6100 loss 17.824581 loss_att 19.541883 loss_ctc 18.401884 loss_rnnt 17.370394 hw_loss 0.063288 lr 0.00050542 rank 2
2023-02-21 22:50:28,577 DEBUG TRAIN Batch 11/6100 loss 12.651128 loss_att 14.183500 loss_ctc 12.678818 loss_rnnt 12.279735 hw_loss 0.114802 lr 0.00050542 rank 3
2023-02-21 22:51:42,567 DEBUG TRAIN Batch 11/6200 loss 21.703587 loss_att 26.454367 loss_ctc 29.099522 loss_rnnt 19.662699 hw_loss 0.196139 lr 0.00050517 rank 7
2023-02-21 22:51:42,570 DEBUG TRAIN Batch 11/6200 loss 13.697957 loss_att 18.585379 loss_ctc 14.423479 loss_rnnt 12.561541 hw_loss 0.116619 lr 0.00050517 rank 0
2023-02-21 22:51:42,572 DEBUG TRAIN Batch 11/6200 loss 22.118441 loss_att 22.080589 loss_ctc 26.438503 loss_rnnt 21.453072 hw_loss 0.181748 lr 0.00050517 rank 4
2023-02-21 22:51:42,574 DEBUG TRAIN Batch 11/6200 loss 15.677478 loss_att 18.832256 loss_ctc 19.187546 loss_rnnt 14.475870 hw_loss 0.192454 lr 0.00050517 rank 6
2023-02-21 22:51:42,577 DEBUG TRAIN Batch 11/6200 loss 14.974974 loss_att 16.490734 loss_ctc 20.032652 loss_rnnt 13.946138 hw_loss 0.096235 lr 0.00050517 rank 2
2023-02-21 22:51:42,579 DEBUG TRAIN Batch 11/6200 loss 15.019102 loss_att 20.105150 loss_ctc 18.157146 loss_rnnt 13.498655 hw_loss 0.159059 lr 0.00050517 rank 5
2023-02-21 22:51:42,581 DEBUG TRAIN Batch 11/6200 loss 11.191212 loss_att 16.742292 loss_ctc 11.760954 loss_rnnt 9.915701 hw_loss 0.167492 lr 0.00050517 rank 3
2023-02-21 22:51:42,619 DEBUG TRAIN Batch 11/6200 loss 20.271524 loss_att 22.021481 loss_ctc 21.584858 loss_rnnt 19.650791 hw_loss 0.179306 lr 0.00050517 rank 1
2023-02-21 22:52:58,396 DEBUG TRAIN Batch 11/6300 loss 26.946737 loss_att 29.233706 loss_ctc 31.394913 loss_rnnt 25.792326 hw_loss 0.194864 lr 0.00050491 rank 4
2023-02-21 22:52:58,397 DEBUG TRAIN Batch 11/6300 loss 21.523848 loss_att 23.786945 loss_ctc 28.196447 loss_rnnt 20.055933 hw_loss 0.235524 lr 0.00050491 rank 5
2023-02-21 22:52:58,397 DEBUG TRAIN Batch 11/6300 loss 16.666817 loss_att 20.599972 loss_ctc 20.843222 loss_rnnt 15.243163 hw_loss 0.150319 lr 0.00050491 rank 7
2023-02-21 22:52:58,400 DEBUG TRAIN Batch 11/6300 loss 29.448406 loss_att 40.262253 loss_ctc 30.770805 loss_rnnt 27.033169 hw_loss 0.142784 lr 0.00050491 rank 1
2023-02-21 22:52:58,402 DEBUG TRAIN Batch 11/6300 loss 14.578495 loss_att 18.717676 loss_ctc 19.445112 loss_rnnt 12.927190 hw_loss 0.327348 lr 0.00050491 rank 0
2023-02-21 22:52:58,405 DEBUG TRAIN Batch 11/6300 loss 16.986147 loss_att 18.290676 loss_ctc 20.821785 loss_rnnt 16.097849 hw_loss 0.217450 lr 0.00050491 rank 2
2023-02-21 22:52:58,409 DEBUG TRAIN Batch 11/6300 loss 14.880739 loss_att 20.384007 loss_ctc 16.696451 loss_rnnt 13.449144 hw_loss 0.166585 lr 0.00050491 rank 3
2023-02-21 22:52:58,453 DEBUG TRAIN Batch 11/6300 loss 26.129997 loss_att 33.017334 loss_ctc 32.443794 loss_rnnt 23.820118 hw_loss 0.169822 lr 0.00050491 rank 6
2023-02-21 22:54:17,173 DEBUG TRAIN Batch 11/6400 loss 17.041536 loss_att 25.072706 loss_ctc 13.475170 loss_rnnt 15.789664 hw_loss 0.227167 lr 0.00050465 rank 4
2023-02-21 22:54:17,175 DEBUG TRAIN Batch 11/6400 loss 27.489460 loss_att 37.696346 loss_ctc 36.882980 loss_rnnt 24.116592 hw_loss 0.148165 lr 0.00050465 rank 7
2023-02-21 22:54:17,175 DEBUG TRAIN Batch 11/6400 loss 17.187445 loss_att 22.558458 loss_ctc 18.657921 loss_rnnt 15.902630 hw_loss 0.027282 lr 0.00050465 rank 5
2023-02-21 22:54:17,178 DEBUG TRAIN Batch 11/6400 loss 16.441767 loss_att 24.603716 loss_ctc 17.394382 loss_rnnt 14.621982 hw_loss 0.113216 lr 0.00050465 rank 6
2023-02-21 22:54:17,178 DEBUG TRAIN Batch 11/6400 loss 19.228300 loss_att 19.550434 loss_ctc 21.845261 loss_rnnt 18.630249 hw_loss 0.346305 lr 0.00050465 rank 0
2023-02-21 22:54:17,179 DEBUG TRAIN Batch 11/6400 loss 23.956835 loss_att 26.139750 loss_ctc 26.478174 loss_rnnt 23.047129 hw_loss 0.256767 lr 0.00050465 rank 1
2023-02-21 22:54:17,184 DEBUG TRAIN Batch 11/6400 loss 14.985697 loss_att 20.765717 loss_ctc 18.161758 loss_rnnt 13.271479 hw_loss 0.252634 lr 0.00050465 rank 2
2023-02-21 22:54:17,185 DEBUG TRAIN Batch 11/6400 loss 13.580557 loss_att 13.931913 loss_ctc 15.381435 loss_rnnt 13.056623 hw_loss 0.400399 lr 0.00050465 rank 3
2023-02-21 22:55:32,025 DEBUG TRAIN Batch 11/6500 loss 13.272672 loss_att 17.495522 loss_ctc 17.648659 loss_rnnt 11.778580 hw_loss 0.123857 lr 0.00050439 rank 4
2023-02-21 22:55:32,029 DEBUG TRAIN Batch 11/6500 loss 22.551170 loss_att 22.212065 loss_ctc 16.963627 loss_rnnt 23.198112 hw_loss 0.311033 lr 0.00050439 rank 6
2023-02-21 22:55:32,030 DEBUG TRAIN Batch 11/6500 loss 27.975819 loss_att 29.913067 loss_ctc 28.156673 loss_rnnt 27.505033 hw_loss 0.111036 lr 0.00050439 rank 1
2023-02-21 22:55:32,031 DEBUG TRAIN Batch 11/6500 loss 33.507664 loss_att 42.976288 loss_ctc 36.956970 loss_rnnt 31.152519 hw_loss 0.002830 lr 0.00050439 rank 0
2023-02-21 22:55:32,031 DEBUG TRAIN Batch 11/6500 loss 24.301661 loss_att 35.370426 loss_ctc 28.310574 loss_rnnt 21.553310 hw_loss 0.000146 lr 0.00050439 rank 7
2023-02-21 22:55:32,034 DEBUG TRAIN Batch 11/6500 loss 35.052483 loss_att 37.525467 loss_ctc 45.387337 loss_rnnt 33.147579 hw_loss 0.060612 lr 0.00050439 rank 3
2023-02-21 22:55:32,034 DEBUG TRAIN Batch 11/6500 loss 31.382895 loss_att 36.479939 loss_ctc 33.151512 loss_rnnt 30.049465 hw_loss 0.146635 lr 0.00050439 rank 5
2023-02-21 22:55:32,036 DEBUG TRAIN Batch 11/6500 loss 39.575371 loss_att 42.310383 loss_ctc 39.250801 loss_rnnt 39.022064 hw_loss 0.092962 lr 0.00050439 rank 2
2023-02-21 22:56:45,934 DEBUG TRAIN Batch 11/6600 loss 13.634412 loss_att 18.730680 loss_ctc 17.218113 loss_rnnt 11.997156 hw_loss 0.262826 lr 0.00050414 rank 4
2023-02-21 22:56:45,937 DEBUG TRAIN Batch 11/6600 loss 20.285837 loss_att 28.689600 loss_ctc 21.193890 loss_rnnt 18.419167 hw_loss 0.121585 lr 0.00050414 rank 7
2023-02-21 22:56:45,938 DEBUG TRAIN Batch 11/6600 loss 13.528681 loss_att 20.490345 loss_ctc 14.075752 loss_rnnt 11.970211 hw_loss 0.174736 lr 0.00050414 rank 0
2023-02-21 22:56:45,938 DEBUG TRAIN Batch 11/6600 loss 15.507993 loss_att 26.559311 loss_ctc 21.177490 loss_rnnt 12.458261 hw_loss 0.156623 lr 0.00050414 rank 6
2023-02-21 22:56:45,944 DEBUG TRAIN Batch 11/6600 loss 14.574004 loss_att 17.500360 loss_ctc 15.665221 loss_rnnt 13.689909 hw_loss 0.287490 lr 0.00050414 rank 5
2023-02-21 22:56:45,946 DEBUG TRAIN Batch 11/6600 loss 23.700420 loss_att 30.036926 loss_ctc 29.370527 loss_rnnt 21.558094 hw_loss 0.223143 lr 0.00050414 rank 3
2023-02-21 22:56:45,948 DEBUG TRAIN Batch 11/6600 loss 15.109582 loss_att 20.795586 loss_ctc 16.994495 loss_rnnt 13.613211 hw_loss 0.202217 lr 0.00050414 rank 1
2023-02-21 22:56:45,951 DEBUG TRAIN Batch 11/6600 loss 9.127794 loss_att 15.439003 loss_ctc 8.442284 loss_rnnt 7.814343 hw_loss 0.267395 lr 0.00050414 rank 2
2023-02-21 22:58:02,232 DEBUG TRAIN Batch 11/6700 loss 27.103062 loss_att 31.406931 loss_ctc 29.575495 loss_rnnt 25.805225 hw_loss 0.201380 lr 0.00050388 rank 1
2023-02-21 22:58:02,232 DEBUG TRAIN Batch 11/6700 loss 15.897359 loss_att 19.772617 loss_ctc 18.364935 loss_rnnt 14.773228 hw_loss 0.037630 lr 0.00050388 rank 0
2023-02-21 22:58:02,234 DEBUG TRAIN Batch 11/6700 loss 28.499104 loss_att 39.917038 loss_ctc 31.126312 loss_rnnt 25.824238 hw_loss 0.076844 lr 0.00050388 rank 7
2023-02-21 22:58:02,237 DEBUG TRAIN Batch 11/6700 loss 20.283278 loss_att 24.556305 loss_ctc 22.734755 loss_rnnt 18.967340 hw_loss 0.252126 lr 0.00050388 rank 5
2023-02-21 22:58:02,237 DEBUG TRAIN Batch 11/6700 loss 17.063612 loss_att 25.024405 loss_ctc 20.068333 loss_rnnt 14.983002 hw_loss 0.164668 lr 0.00050388 rank 6
2023-02-21 22:58:02,239 DEBUG TRAIN Batch 11/6700 loss 21.203190 loss_att 31.208405 loss_ctc 27.369740 loss_rnnt 18.289549 hw_loss 0.169481 lr 0.00050388 rank 4
2023-02-21 22:58:02,239 DEBUG TRAIN Batch 11/6700 loss 14.689296 loss_att 19.968418 loss_ctc 15.477806 loss_rnnt 13.417683 hw_loss 0.207475 lr 0.00050388 rank 3
2023-02-21 22:58:02,241 DEBUG TRAIN Batch 11/6700 loss 26.909775 loss_att 30.585209 loss_ctc 33.269249 loss_rnnt 25.231861 hw_loss 0.177926 lr 0.00050388 rank 2
2023-02-21 22:59:19,519 DEBUG TRAIN Batch 11/6800 loss 14.439636 loss_att 19.947096 loss_ctc 15.668175 loss_rnnt 13.101971 hw_loss 0.135692 lr 0.00050363 rank 7
2023-02-21 22:59:19,523 DEBUG TRAIN Batch 11/6800 loss 20.494400 loss_att 26.431641 loss_ctc 20.007732 loss_rnnt 19.299967 hw_loss 0.134764 lr 0.00050363 rank 0
2023-02-21 22:59:19,523 DEBUG TRAIN Batch 11/6800 loss 26.482561 loss_att 35.328175 loss_ctc 31.397173 loss_rnnt 23.974495 hw_loss 0.156867 lr 0.00050363 rank 4
2023-02-21 22:59:19,525 DEBUG TRAIN Batch 11/6800 loss 15.701211 loss_att 21.590599 loss_ctc 19.489193 loss_rnnt 13.854472 hw_loss 0.307119 lr 0.00050363 rank 6
2023-02-21 22:59:19,527 DEBUG TRAIN Batch 11/6800 loss 12.609533 loss_att 17.562923 loss_ctc 14.543124 loss_rnnt 11.299170 hw_loss 0.116015 lr 0.00050363 rank 5
2023-02-21 22:59:19,528 DEBUG TRAIN Batch 11/6800 loss 9.682519 loss_att 18.280600 loss_ctc 12.670689 loss_rnnt 7.458523 hw_loss 0.198669 lr 0.00050363 rank 1
2023-02-21 22:59:19,528 DEBUG TRAIN Batch 11/6800 loss 23.292540 loss_att 30.778442 loss_ctc 30.217844 loss_rnnt 20.793747 hw_loss 0.146701 lr 0.00050363 rank 3
2023-02-21 22:59:19,529 DEBUG TRAIN Batch 11/6800 loss 19.592251 loss_att 23.853724 loss_ctc 21.497532 loss_rnnt 18.368576 hw_loss 0.220019 lr 0.00050363 rank 2
2023-02-21 23:00:34,857 DEBUG TRAIN Batch 11/6900 loss 17.766594 loss_att 18.159237 loss_ctc 21.988510 loss_rnnt 17.033247 hw_loss 0.172311 lr 0.00050337 rank 5
2023-02-21 23:00:34,864 DEBUG TRAIN Batch 11/6900 loss 29.496408 loss_att 33.084881 loss_ctc 36.600296 loss_rnnt 27.744518 hw_loss 0.163145 lr 0.00050337 rank 4
2023-02-21 23:00:34,866 DEBUG TRAIN Batch 11/6900 loss 29.567369 loss_att 31.380709 loss_ctc 36.707272 loss_rnnt 28.177013 hw_loss 0.141940 lr 0.00050337 rank 2
2023-02-21 23:00:34,868 DEBUG TRAIN Batch 11/6900 loss 23.802322 loss_att 27.446362 loss_ctc 24.002354 loss_rnnt 22.955555 hw_loss 0.171159 lr 0.00050337 rank 0
2023-02-21 23:00:34,869 DEBUG TRAIN Batch 11/6900 loss 15.733412 loss_att 17.753735 loss_ctc 18.293667 loss_rnnt 14.864964 hw_loss 0.230655 lr 0.00050337 rank 6
2023-02-21 23:00:34,872 DEBUG TRAIN Batch 11/6900 loss 7.524379 loss_att 10.415993 loss_ctc 6.851511 loss_rnnt 6.876753 hw_loss 0.298162 lr 0.00050337 rank 3
2023-02-21 23:00:34,873 DEBUG TRAIN Batch 11/6900 loss 19.217796 loss_att 25.506687 loss_ctc 24.304283 loss_rnnt 17.202747 hw_loss 0.148260 lr 0.00050337 rank 1
2023-02-21 23:00:34,877 DEBUG TRAIN Batch 11/6900 loss 19.425043 loss_att 26.673485 loss_ctc 25.286676 loss_rnnt 17.107746 hw_loss 0.161359 lr 0.00050337 rank 7
2023-02-21 23:01:50,105 DEBUG TRAIN Batch 11/7000 loss 21.517426 loss_att 29.614202 loss_ctc 26.606861 loss_rnnt 19.169779 hw_loss 0.093184 lr 0.00050312 rank 6
2023-02-21 23:01:50,109 DEBUG TRAIN Batch 11/7000 loss 17.075197 loss_att 24.088697 loss_ctc 19.979923 loss_rnnt 15.200999 hw_loss 0.157876 lr 0.00050312 rank 7
2023-02-21 23:01:50,110 DEBUG TRAIN Batch 11/7000 loss 13.914215 loss_att 19.863493 loss_ctc 13.529556 loss_rnnt 12.658228 hw_loss 0.220162 lr 0.00050312 rank 0
2023-02-21 23:01:50,111 DEBUG TRAIN Batch 11/7000 loss 12.781966 loss_att 14.852086 loss_ctc 17.978720 loss_rnnt 11.604579 hw_loss 0.132118 lr 0.00050312 rank 4
2023-02-21 23:01:50,111 DEBUG TRAIN Batch 11/7000 loss 18.554199 loss_att 27.326445 loss_ctc 19.044662 loss_rnnt 16.589729 hw_loss 0.271175 lr 0.00050312 rank 5
2023-02-21 23:01:50,112 DEBUG TRAIN Batch 11/7000 loss 23.259544 loss_att 26.142620 loss_ctc 27.037323 loss_rnnt 22.059580 hw_loss 0.224337 lr 0.00050312 rank 1
2023-02-21 23:01:50,116 DEBUG TRAIN Batch 11/7000 loss 15.605747 loss_att 16.963108 loss_ctc 17.164015 loss_rnnt 15.015150 hw_loss 0.208796 lr 0.00050312 rank 3
2023-02-21 23:01:50,116 DEBUG TRAIN Batch 11/7000 loss 21.327211 loss_att 31.192871 loss_ctc 25.193897 loss_rnnt 18.760735 hw_loss 0.145852 lr 0.00050312 rank 2
2023-02-21 23:03:07,650 DEBUG TRAIN Batch 11/7100 loss 5.781339 loss_att 11.414916 loss_ctc 8.044513 loss_rnnt 4.307413 hw_loss 0.085227 lr 0.00050286 rank 0
2023-02-21 23:03:07,651 DEBUG TRAIN Batch 11/7100 loss 28.890320 loss_att 39.045124 loss_ctc 38.011200 loss_rnnt 25.558493 hw_loss 0.158901 lr 0.00050286 rank 4
2023-02-21 23:03:07,654 DEBUG TRAIN Batch 11/7100 loss 18.656820 loss_att 21.545143 loss_ctc 21.763439 loss_rnnt 17.618032 hw_loss 0.087951 lr 0.00050286 rank 5
2023-02-21 23:03:07,654 DEBUG TRAIN Batch 11/7100 loss 17.335392 loss_att 24.678396 loss_ctc 18.682802 loss_rnnt 15.570549 hw_loss 0.218600 lr 0.00050286 rank 7
2023-02-21 23:03:07,661 DEBUG TRAIN Batch 11/7100 loss 15.096066 loss_att 17.807194 loss_ctc 18.502544 loss_rnnt 13.999293 hw_loss 0.188156 lr 0.00050286 rank 6
2023-02-21 23:03:07,663 DEBUG TRAIN Batch 11/7100 loss 13.429922 loss_att 16.718899 loss_ctc 16.039352 loss_rnnt 12.325300 hw_loss 0.185442 lr 0.00050286 rank 1
2023-02-21 23:03:07,664 DEBUG TRAIN Batch 11/7100 loss 14.035533 loss_att 20.592869 loss_ctc 13.685493 loss_rnnt 12.688671 hw_loss 0.153875 lr 0.00050286 rank 3
2023-02-21 23:03:07,665 DEBUG TRAIN Batch 11/7100 loss 18.334728 loss_att 21.009546 loss_ctc 21.223141 loss_rnnt 17.326393 hw_loss 0.165469 lr 0.00050286 rank 2
2023-02-21 23:04:22,874 DEBUG TRAIN Batch 11/7200 loss 29.586716 loss_att 31.705517 loss_ctc 29.488125 loss_rnnt 29.130560 hw_loss 0.085390 lr 0.00050261 rank 7
2023-02-21 23:04:22,877 DEBUG TRAIN Batch 11/7200 loss 15.374062 loss_att 19.046011 loss_ctc 16.801819 loss_rnnt 14.414711 hw_loss 0.064864 lr 0.00050261 rank 5
2023-02-21 23:04:22,878 DEBUG TRAIN Batch 11/7200 loss 6.913439 loss_att 13.632004 loss_ctc 6.558646 loss_rnnt 5.565160 hw_loss 0.097260 lr 0.00050261 rank 0
2023-02-21 23:04:22,879 DEBUG TRAIN Batch 11/7200 loss 19.705658 loss_att 23.751532 loss_ctc 22.171406 loss_rnnt 18.540257 hw_loss 0.051488 lr 0.00050261 rank 6
2023-02-21 23:04:22,880 DEBUG TRAIN Batch 11/7200 loss 27.577570 loss_att 30.751257 loss_ctc 31.567816 loss_rnnt 26.332691 hw_loss 0.146449 lr 0.00050261 rank 1
2023-02-21 23:04:22,880 DEBUG TRAIN Batch 11/7200 loss 11.465801 loss_att 20.584627 loss_ctc 16.389175 loss_rnnt 8.944342 hw_loss 0.077334 lr 0.00050261 rank 4
2023-02-21 23:04:22,883 DEBUG TRAIN Batch 11/7200 loss 41.694717 loss_att 43.823090 loss_ctc 49.394814 loss_rnnt 40.220470 hw_loss 0.041057 lr 0.00050261 rank 2
2023-02-21 23:04:22,886 DEBUG TRAIN Batch 11/7200 loss 11.077080 loss_att 18.507874 loss_ctc 16.609772 loss_rnnt 8.773519 hw_loss 0.149456 lr 0.00050261 rank 3
2023-02-21 23:05:37,107 DEBUG TRAIN Batch 11/7300 loss 28.154230 loss_att 38.997143 loss_ctc 34.524792 loss_rnnt 25.038788 hw_loss 0.182722 lr 0.00050235 rank 4
2023-02-21 23:05:37,111 DEBUG TRAIN Batch 11/7300 loss 9.287433 loss_att 13.007337 loss_ctc 9.867982 loss_rnnt 8.356325 hw_loss 0.205725 lr 0.00050235 rank 6
2023-02-21 23:05:37,113 DEBUG TRAIN Batch 11/7300 loss 14.671849 loss_att 17.817207 loss_ctc 18.509445 loss_rnnt 13.456164 hw_loss 0.140502 lr 0.00050235 rank 0
2023-02-21 23:05:37,116 DEBUG TRAIN Batch 11/7300 loss 20.978424 loss_att 29.116211 loss_ctc 26.427670 loss_rnnt 18.480358 hw_loss 0.269888 lr 0.00050235 rank 5
2023-02-21 23:05:37,117 DEBUG TRAIN Batch 11/7300 loss 22.802603 loss_att 29.388840 loss_ctc 25.354034 loss_rnnt 21.057720 hw_loss 0.163961 lr 0.00050235 rank 3
2023-02-21 23:05:37,117 DEBUG TRAIN Batch 11/7300 loss 18.722580 loss_att 21.106424 loss_ctc 25.569429 loss_rnnt 17.259281 hw_loss 0.138032 lr 0.00050235 rank 7
2023-02-21 23:05:37,123 DEBUG TRAIN Batch 11/7300 loss 20.259968 loss_att 29.774450 loss_ctc 22.934559 loss_rnnt 17.895901 hw_loss 0.196045 lr 0.00050235 rank 2
2023-02-21 23:05:37,172 DEBUG TRAIN Batch 11/7300 loss 16.104958 loss_att 22.062387 loss_ctc 21.045576 loss_rnnt 14.127821 hw_loss 0.237940 lr 0.00050235 rank 1
2023-02-21 23:06:53,072 DEBUG TRAIN Batch 11/7400 loss 8.413774 loss_att 11.952171 loss_ctc 12.675562 loss_rnnt 7.075205 hw_loss 0.117472 lr 0.00050210 rank 7
2023-02-21 23:06:53,079 DEBUG TRAIN Batch 11/7400 loss 16.037823 loss_att 20.278725 loss_ctc 16.581131 loss_rnnt 15.043585 hw_loss 0.138031 lr 0.00050210 rank 0
2023-02-21 23:06:53,079 DEBUG TRAIN Batch 11/7400 loss 23.991095 loss_att 25.564861 loss_ctc 31.090145 loss_rnnt 22.624355 hw_loss 0.197709 lr 0.00050210 rank 2
2023-02-21 23:06:53,080 DEBUG TRAIN Batch 11/7400 loss 10.274905 loss_att 14.331335 loss_ctc 10.948841 loss_rnnt 9.341155 hw_loss 0.061139 lr 0.00050210 rank 5
2023-02-21 23:06:53,082 DEBUG TRAIN Batch 11/7400 loss 31.527531 loss_att 35.308739 loss_ctc 37.535393 loss_rnnt 29.944685 hw_loss 0.047916 lr 0.00050210 rank 6
2023-02-21 23:06:53,083 DEBUG TRAIN Batch 11/7400 loss 24.364283 loss_att 29.968597 loss_ctc 31.656487 loss_rnnt 22.200655 hw_loss 0.132124 lr 0.00050210 rank 1
2023-02-21 23:06:53,083 DEBUG TRAIN Batch 11/7400 loss 22.529610 loss_att 36.364025 loss_ctc 25.862932 loss_rnnt 19.221413 hw_loss 0.181629 lr 0.00050210 rank 4
2023-02-21 23:06:53,087 DEBUG TRAIN Batch 11/7400 loss 13.217351 loss_att 16.816730 loss_ctc 17.821613 loss_rnnt 11.730083 hw_loss 0.287793 lr 0.00050210 rank 3
2023-02-21 23:08:10,918 DEBUG TRAIN Batch 11/7500 loss 16.689259 loss_att 22.113857 loss_ctc 20.481808 loss_rnnt 15.066496 hw_loss 0.060318 lr 0.00050185 rank 4
2023-02-21 23:08:10,919 DEBUG TRAIN Batch 11/7500 loss 28.832918 loss_att 29.469528 loss_ctc 33.902267 loss_rnnt 27.902960 hw_loss 0.237609 lr 0.00050185 rank 7
2023-02-21 23:08:10,920 DEBUG TRAIN Batch 11/7500 loss 8.155537 loss_att 13.247721 loss_ctc 9.811539 loss_rnnt 6.756239 hw_loss 0.300112 lr 0.00050185 rank 5
2023-02-21 23:08:10,919 DEBUG TRAIN Batch 11/7500 loss 21.509977 loss_att 28.503277 loss_ctc 26.513186 loss_rnnt 19.301525 hw_loss 0.267558 lr 0.00050185 rank 0
2023-02-21 23:08:10,922 DEBUG TRAIN Batch 11/7500 loss 23.196648 loss_att 27.436466 loss_ctc 25.246496 loss_rnnt 21.994961 hw_loss 0.150766 lr 0.00050185 rank 3
2023-02-21 23:08:10,923 DEBUG TRAIN Batch 11/7500 loss 26.744059 loss_att 30.482601 loss_ctc 32.083023 loss_rnnt 25.164305 hw_loss 0.225347 lr 0.00050185 rank 2
2023-02-21 23:08:10,924 DEBUG TRAIN Batch 11/7500 loss 11.495112 loss_att 18.332155 loss_ctc 12.510591 loss_rnnt 9.947567 hw_loss 0.083885 lr 0.00050185 rank 1
2023-02-21 23:08:10,927 DEBUG TRAIN Batch 11/7500 loss 15.763511 loss_att 21.706259 loss_ctc 16.940134 loss_rnnt 14.360062 hw_loss 0.108780 lr 0.00050185 rank 6
2023-02-21 23:09:28,149 DEBUG TRAIN Batch 11/7600 loss 17.317253 loss_att 22.550186 loss_ctc 23.634975 loss_rnnt 15.344980 hw_loss 0.156233 lr 0.00050160 rank 0
2023-02-21 23:09:28,156 DEBUG TRAIN Batch 11/7600 loss 23.534315 loss_att 25.830383 loss_ctc 23.396069 loss_rnnt 23.065781 hw_loss 0.052035 lr 0.00050160 rank 6
2023-02-21 23:09:28,157 DEBUG TRAIN Batch 11/7600 loss 11.872106 loss_att 13.786561 loss_ctc 14.449100 loss_rnnt 11.029763 hw_loss 0.217221 lr 0.00050160 rank 5
2023-02-21 23:09:28,159 DEBUG TRAIN Batch 11/7600 loss 15.510616 loss_att 19.460098 loss_ctc 20.059586 loss_rnnt 14.001126 hw_loss 0.211995 lr 0.00050160 rank 3
2023-02-21 23:09:28,159 DEBUG TRAIN Batch 11/7600 loss 14.722206 loss_att 18.153555 loss_ctc 18.148825 loss_rnnt 13.432574 hw_loss 0.274648 lr 0.00050160 rank 7
2023-02-21 23:09:28,161 DEBUG TRAIN Batch 11/7600 loss 19.868650 loss_att 24.414656 loss_ctc 23.065948 loss_rnnt 18.418175 hw_loss 0.215562 lr 0.00050160 rank 4
2023-02-21 23:09:28,186 DEBUG TRAIN Batch 11/7600 loss 16.982510 loss_att 23.603622 loss_ctc 21.048838 loss_rnnt 15.000288 hw_loss 0.217166 lr 0.00050160 rank 2
2023-02-21 23:09:28,196 DEBUG TRAIN Batch 11/7600 loss 15.918883 loss_att 18.555492 loss_ctc 19.697096 loss_rnnt 14.777466 hw_loss 0.206875 lr 0.00050160 rank 1
2023-02-21 23:10:42,862 DEBUG TRAIN Batch 11/7700 loss 21.849512 loss_att 25.116241 loss_ctc 28.103018 loss_rnnt 20.277622 hw_loss 0.158890 lr 0.00050134 rank 0
2023-02-21 23:10:42,865 DEBUG TRAIN Batch 11/7700 loss 17.355654 loss_att 25.546104 loss_ctc 23.933346 loss_rnnt 14.718280 hw_loss 0.229233 lr 0.00050134 rank 4
2023-02-21 23:10:42,867 DEBUG TRAIN Batch 11/7700 loss 15.860829 loss_att 26.156755 loss_ctc 16.203247 loss_rnnt 13.545477 hw_loss 0.394709 lr 0.00050134 rank 7
2023-02-21 23:10:42,869 DEBUG TRAIN Batch 11/7700 loss 11.666752 loss_att 12.950827 loss_ctc 14.152791 loss_rnnt 10.947124 hw_loss 0.246265 lr 0.00050134 rank 1
2023-02-21 23:10:42,869 DEBUG TRAIN Batch 11/7700 loss 12.446620 loss_att 24.147837 loss_ctc 14.618425 loss_rnnt 9.753363 hw_loss 0.118949 lr 0.00050134 rank 2
2023-02-21 23:10:42,873 DEBUG TRAIN Batch 11/7700 loss 21.023033 loss_att 29.547417 loss_ctc 26.133759 loss_rnnt 18.636673 hw_loss 0.000097 lr 0.00050134 rank 6
2023-02-21 23:10:42,874 DEBUG TRAIN Batch 11/7700 loss 16.926210 loss_att 27.487534 loss_ctc 20.148298 loss_rnnt 14.363047 hw_loss 0.039912 lr 0.00050134 rank 5
2023-02-21 23:10:42,920 DEBUG TRAIN Batch 11/7700 loss 25.166285 loss_att 34.631733 loss_ctc 33.845177 loss_rnnt 22.053312 hw_loss 0.117554 lr 0.00050134 rank 3
2023-02-21 23:12:00,001 DEBUG TRAIN Batch 11/7800 loss 17.661837 loss_att 24.157143 loss_ctc 23.867977 loss_rnnt 15.455371 hw_loss 0.149847 lr 0.00050109 rank 4
2023-02-21 23:12:00,002 DEBUG TRAIN Batch 11/7800 loss 22.582525 loss_att 30.036892 loss_ctc 27.177258 loss_rnnt 20.382465 hw_loss 0.181041 lr 0.00050109 rank 5
2023-02-21 23:12:00,003 DEBUG TRAIN Batch 11/7800 loss 30.279202 loss_att 33.791828 loss_ctc 34.335369 loss_rnnt 28.889946 hw_loss 0.273580 lr 0.00050109 rank 0
2023-02-21 23:12:00,004 DEBUG TRAIN Batch 11/7800 loss 14.545322 loss_att 23.070574 loss_ctc 19.352493 loss_rnnt 12.097862 hw_loss 0.190224 lr 0.00050109 rank 7
2023-02-21 23:12:00,004 DEBUG TRAIN Batch 11/7800 loss 19.466110 loss_att 26.704203 loss_ctc 28.184101 loss_rnnt 16.780739 hw_loss 0.141284 lr 0.00050109 rank 6
2023-02-21 23:12:00,009 DEBUG TRAIN Batch 11/7800 loss 17.979986 loss_att 31.667526 loss_ctc 22.721329 loss_rnnt 14.513945 hw_loss 0.180663 lr 0.00050109 rank 3
2023-02-21 23:12:00,013 DEBUG TRAIN Batch 11/7800 loss 21.700506 loss_att 29.134893 loss_ctc 21.710300 loss_rnnt 20.066261 hw_loss 0.273865 lr 0.00050109 rank 1
2023-02-21 23:12:00,015 DEBUG TRAIN Batch 11/7800 loss 13.536221 loss_att 22.762239 loss_ctc 15.006961 loss_rnnt 11.444942 hw_loss 0.093706 lr 0.00050109 rank 2
2023-02-21 23:13:15,716 DEBUG TRAIN Batch 11/7900 loss 23.415113 loss_att 28.868689 loss_ctc 23.955153 loss_rnnt 22.102516 hw_loss 0.281020 lr 0.00050084 rank 0
2023-02-21 23:13:15,725 DEBUG TRAIN Batch 11/7900 loss 19.373716 loss_att 25.234276 loss_ctc 27.894592 loss_rnnt 16.949221 hw_loss 0.218000 lr 0.00050084 rank 7
2023-02-21 23:13:15,725 DEBUG TRAIN Batch 11/7900 loss 25.935705 loss_att 34.621487 loss_ctc 29.460760 loss_rnnt 23.575893 hw_loss 0.286223 lr 0.00050084 rank 3
2023-02-21 23:13:15,725 DEBUG TRAIN Batch 11/7900 loss 24.800716 loss_att 31.099674 loss_ctc 34.866623 loss_rnnt 22.080597 hw_loss 0.221639 lr 0.00050084 rank 4
2023-02-21 23:13:15,727 DEBUG TRAIN Batch 11/7900 loss 27.709200 loss_att 32.059875 loss_ctc 33.966461 loss_rnnt 25.855892 hw_loss 0.279136 lr 0.00050084 rank 5
2023-02-21 23:13:15,727 DEBUG TRAIN Batch 11/7900 loss 11.605312 loss_att 17.594593 loss_ctc 16.232874 loss_rnnt 9.704522 hw_loss 0.161110 lr 0.00050084 rank 6
2023-02-21 23:13:15,731 DEBUG TRAIN Batch 11/7900 loss 18.187550 loss_att 22.311396 loss_ctc 19.279961 loss_rnnt 17.112640 hw_loss 0.195910 lr 0.00050084 rank 2
2023-02-21 23:13:15,764 DEBUG TRAIN Batch 11/7900 loss 22.274878 loss_att 28.804699 loss_ctc 26.343580 loss_rnnt 20.385244 hw_loss 0.077203 lr 0.00050084 rank 1
2023-02-21 23:14:32,102 DEBUG TRAIN Batch 11/8000 loss 18.539238 loss_att 22.235573 loss_ctc 17.829739 loss_rnnt 17.785419 hw_loss 0.204661 lr 0.00050059 rank 0
2023-02-21 23:14:32,104 DEBUG TRAIN Batch 11/8000 loss 18.843292 loss_att 18.815514 loss_ctc 18.015091 loss_rnnt 18.905291 hw_loss 0.101219 lr 0.00050059 rank 7
2023-02-21 23:14:32,108 DEBUG TRAIN Batch 11/8000 loss 20.700054 loss_att 26.183107 loss_ctc 28.072067 loss_rnnt 18.530502 hw_loss 0.168764 lr 0.00050059 rank 1
2023-02-21 23:14:32,109 DEBUG TRAIN Batch 11/8000 loss 14.453353 loss_att 19.866175 loss_ctc 16.825911 loss_rnnt 13.031828 hw_loss 0.042411 lr 0.00050059 rank 5
2023-02-21 23:14:32,110 DEBUG TRAIN Batch 11/8000 loss 14.734474 loss_att 20.862835 loss_ctc 19.173679 loss_rnnt 12.848222 hw_loss 0.128786 lr 0.00050059 rank 4
2023-02-21 23:14:32,111 DEBUG TRAIN Batch 11/8000 loss 19.178049 loss_att 18.738785 loss_ctc 24.181122 loss_rnnt 18.490133 hw_loss 0.203801 lr 0.00050059 rank 6
2023-02-21 23:14:32,112 DEBUG TRAIN Batch 11/8000 loss 19.928671 loss_att 22.591219 loss_ctc 25.160851 loss_rnnt 18.697989 hw_loss 0.001028 lr 0.00050059 rank 2
2023-02-21 23:14:32,152 DEBUG TRAIN Batch 11/8000 loss 16.435675 loss_att 19.750902 loss_ctc 18.380466 loss_rnnt 15.452704 hw_loss 0.113658 lr 0.00050059 rank 3
2023-02-21 23:15:47,748 DEBUG TRAIN Batch 11/8100 loss 10.888428 loss_att 15.481920 loss_ctc 14.029113 loss_rnnt 9.464306 hw_loss 0.162497 lr 0.00050034 rank 7
2023-02-21 23:15:47,754 DEBUG TRAIN Batch 11/8100 loss 11.540985 loss_att 13.297344 loss_ctc 16.160246 loss_rnnt 10.484596 hw_loss 0.167279 lr 0.00050034 rank 4
2023-02-21 23:15:47,757 DEBUG TRAIN Batch 11/8100 loss 28.052490 loss_att 34.449772 loss_ctc 34.277306 loss_rnnt 25.863129 hw_loss 0.149869 lr 0.00050034 rank 1
2023-02-21 23:15:47,760 DEBUG TRAIN Batch 11/8100 loss 23.849037 loss_att 25.681725 loss_ctc 28.640392 loss_rnnt 22.781521 hw_loss 0.116503 lr 0.00050034 rank 5
2023-02-21 23:15:47,760 DEBUG TRAIN Batch 11/8100 loss 6.096921 loss_att 11.617936 loss_ctc 7.293184 loss_rnnt 4.833077 hw_loss 0.000261 lr 0.00050034 rank 3
2023-02-21 23:15:47,761 DEBUG TRAIN Batch 11/8100 loss 35.234913 loss_att 37.971966 loss_ctc 43.952408 loss_rnnt 33.435940 hw_loss 0.167304 lr 0.00050034 rank 0
2023-02-21 23:15:47,762 DEBUG TRAIN Batch 11/8100 loss 30.191725 loss_att 35.260334 loss_ctc 38.175301 loss_rnnt 27.993237 hw_loss 0.225548 lr 0.00050034 rank 2
2023-02-21 23:15:47,764 DEBUG TRAIN Batch 11/8100 loss 16.708704 loss_att 19.233541 loss_ctc 16.321146 loss_rnnt 16.117065 hw_loss 0.259400 lr 0.00050034 rank 6
2023-02-21 23:17:04,306 DEBUG TRAIN Batch 11/8200 loss 15.900959 loss_att 21.488361 loss_ctc 16.979813 loss_rnnt 14.562183 hw_loss 0.145215 lr 0.00050009 rank 0
2023-02-21 23:17:04,310 DEBUG TRAIN Batch 11/8200 loss 24.971516 loss_att 25.339079 loss_ctc 31.770626 loss_rnnt 23.939873 hw_loss 0.096719 lr 0.00050009 rank 7
2023-02-21 23:17:04,311 DEBUG TRAIN Batch 11/8200 loss 11.919091 loss_att 13.867750 loss_ctc 15.735644 loss_rnnt 10.878763 hw_loss 0.265730 lr 0.00050009 rank 4
2023-02-21 23:17:04,311 DEBUG TRAIN Batch 11/8200 loss 9.403454 loss_att 16.836752 loss_ctc 13.355594 loss_rnnt 7.297566 hw_loss 0.173014 lr 0.00050009 rank 3
2023-02-21 23:17:04,313 DEBUG TRAIN Batch 11/8200 loss 11.733798 loss_att 12.535995 loss_ctc 13.596437 loss_rnnt 11.169280 hw_loss 0.291985 lr 0.00050009 rank 6
2023-02-21 23:17:04,313 DEBUG TRAIN Batch 11/8200 loss 15.762018 loss_att 15.004425 loss_ctc 18.703474 loss_rnnt 15.420074 hw_loss 0.189881 lr 0.00050009 rank 5
2023-02-21 23:17:04,316 DEBUG TRAIN Batch 11/8200 loss 8.147255 loss_att 8.336801 loss_ctc 9.257165 loss_rnnt 7.807524 hw_loss 0.288440 lr 0.00050009 rank 2
2023-02-21 23:17:04,317 DEBUG TRAIN Batch 11/8200 loss 16.045200 loss_att 22.284946 loss_ctc 22.361307 loss_rnnt 13.859970 hw_loss 0.178375 lr 0.00050009 rank 1
2023-02-21 23:18:18,587 DEBUG TRAIN Batch 11/8300 loss 11.620091 loss_att 17.146061 loss_ctc 14.347972 loss_rnnt 10.071333 hw_loss 0.149716 lr 0.00049984 rank 0
2023-02-21 23:18:18,588 DEBUG TRAIN Batch 11/8300 loss 7.623605 loss_att 13.451193 loss_ctc 10.687748 loss_rnnt 5.929329 hw_loss 0.225388 lr 0.00049984 rank 7
2023-02-21 23:18:18,588 DEBUG TRAIN Batch 11/8300 loss 16.983906 loss_att 22.752441 loss_ctc 26.170128 loss_rnnt 14.458209 hw_loss 0.275924 lr 0.00049984 rank 6
2023-02-21 23:18:18,590 DEBUG TRAIN Batch 11/8300 loss 30.551441 loss_att 36.632149 loss_ctc 38.150707 loss_rnnt 28.293427 hw_loss 0.053691 lr 0.00049984 rank 5
2023-02-21 23:18:18,591 DEBUG TRAIN Batch 11/8300 loss 8.855026 loss_att 10.981227 loss_ctc 12.666267 loss_rnnt 7.839614 hw_loss 0.153764 lr 0.00049984 rank 4
2023-02-21 23:18:18,593 DEBUG TRAIN Batch 11/8300 loss 21.258604 loss_att 34.525242 loss_ctc 24.656830 loss_rnnt 18.074211 hw_loss 0.146194 lr 0.00049984 rank 3
2023-02-21 23:18:18,594 DEBUG TRAIN Batch 11/8300 loss 20.312258 loss_att 21.153122 loss_ctc 21.996302 loss_rnnt 19.734558 hw_loss 0.346852 lr 0.00049984 rank 1
2023-02-21 23:18:18,597 DEBUG TRAIN Batch 11/8300 loss 15.708473 loss_att 17.756248 loss_ctc 20.530693 loss_rnnt 14.579050 hw_loss 0.144195 lr 0.00049984 rank 2
2023-02-21 23:19:05,006 DEBUG CV Batch 11/0 loss 2.778355 loss_att 2.638990 loss_ctc 3.292406 loss_rnnt 2.499123 hw_loss 0.447308 history loss 2.675453 rank 3
2023-02-21 23:19:05,009 DEBUG CV Batch 11/0 loss 2.778355 loss_att 2.638990 loss_ctc 3.292406 loss_rnnt 2.499123 hw_loss 0.447308 history loss 2.675453 rank 7
2023-02-21 23:19:05,010 DEBUG CV Batch 11/0 loss 2.778355 loss_att 2.638990 loss_ctc 3.292406 loss_rnnt 2.499123 hw_loss 0.447308 history loss 2.675453 rank 5
2023-02-21 23:19:05,014 DEBUG CV Batch 11/0 loss 2.778355 loss_att 2.638990 loss_ctc 3.292406 loss_rnnt 2.499123 hw_loss 0.447308 history loss 2.675453 rank 6
2023-02-21 23:19:05,017 DEBUG CV Batch 11/0 loss 2.778355 loss_att 2.638990 loss_ctc 3.292406 loss_rnnt 2.499123 hw_loss 0.447308 history loss 2.675453 rank 0
2023-02-21 23:19:05,019 DEBUG CV Batch 11/0 loss 2.778355 loss_att 2.638990 loss_ctc 3.292406 loss_rnnt 2.499123 hw_loss 0.447308 history loss 2.675453 rank 4
2023-02-21 23:19:05,037 DEBUG CV Batch 11/0 loss 2.778355 loss_att 2.638990 loss_ctc 3.292406 loss_rnnt 2.499123 hw_loss 0.447308 history loss 2.675453 rank 1
2023-02-21 23:19:05,040 DEBUG CV Batch 11/0 loss 2.778355 loss_att 2.638990 loss_ctc 3.292406 loss_rnnt 2.499123 hw_loss 0.447308 history loss 2.675453 rank 2
2023-02-21 23:19:16,192 DEBUG CV Batch 11/100 loss 12.491810 loss_att 12.243717 loss_ctc 13.628210 loss_rnnt 12.254435 hw_loss 0.254014 history loss 5.388932 rank 4
2023-02-21 23:19:16,214 DEBUG CV Batch 11/100 loss 12.491810 loss_att 12.243717 loss_ctc 13.628210 loss_rnnt 12.254435 hw_loss 0.254014 history loss 5.388932 rank 0
2023-02-21 23:19:16,276 DEBUG CV Batch 11/100 loss 12.491810 loss_att 12.243717 loss_ctc 13.628210 loss_rnnt 12.254435 hw_loss 0.254014 history loss 5.388932 rank 6
2023-02-21 23:19:16,434 DEBUG CV Batch 11/100 loss 12.491810 loss_att 12.243717 loss_ctc 13.628210 loss_rnnt 12.254435 hw_loss 0.254014 history loss 5.388932 rank 1
2023-02-21 23:19:16,605 DEBUG CV Batch 11/100 loss 12.491810 loss_att 12.243717 loss_ctc 13.628210 loss_rnnt 12.254435 hw_loss 0.254014 history loss 5.388932 rank 7
2023-02-21 23:19:16,662 DEBUG CV Batch 11/100 loss 12.491810 loss_att 12.243717 loss_ctc 13.628210 loss_rnnt 12.254435 hw_loss 0.254014 history loss 5.388932 rank 5
2023-02-21 23:19:16,794 DEBUG CV Batch 11/100 loss 12.491810 loss_att 12.243717 loss_ctc 13.628210 loss_rnnt 12.254435 hw_loss 0.254014 history loss 5.388932 rank 3
2023-02-21 23:19:16,857 DEBUG CV Batch 11/100 loss 12.491810 loss_att 12.243717 loss_ctc 13.628210 loss_rnnt 12.254435 hw_loss 0.254014 history loss 5.388932 rank 2
2023-02-21 23:19:29,578 DEBUG CV Batch 11/200 loss 13.690742 loss_att 25.655828 loss_ctc 18.189383 loss_rnnt 10.597995 hw_loss 0.187336 history loss 6.200301 rank 0
2023-02-21 23:19:29,582 DEBUG CV Batch 11/200 loss 13.690742 loss_att 25.655828 loss_ctc 18.189383 loss_rnnt 10.597995 hw_loss 0.187336 history loss 6.200301 rank 4
2023-02-21 23:19:29,807 DEBUG CV Batch 11/200 loss 13.690742 loss_att 25.655828 loss_ctc 18.189383 loss_rnnt 10.597995 hw_loss 0.187336 history loss 6.200301 rank 6
2023-02-21 23:19:29,856 DEBUG CV Batch 11/200 loss 13.690742 loss_att 25.655828 loss_ctc 18.189383 loss_rnnt 10.597995 hw_loss 0.187336 history loss 6.200301 rank 1
2023-02-21 23:19:29,950 DEBUG CV Batch 11/200 loss 13.690742 loss_att 25.655828 loss_ctc 18.189383 loss_rnnt 10.597995 hw_loss 0.187336 history loss 6.200301 rank 7
2023-02-21 23:19:30,080 DEBUG CV Batch 11/200 loss 13.690742 loss_att 25.655828 loss_ctc 18.189383 loss_rnnt 10.597995 hw_loss 0.187336 history loss 6.200301 rank 5
2023-02-21 23:19:30,297 DEBUG CV Batch 11/200 loss 13.690742 loss_att 25.655828 loss_ctc 18.189383 loss_rnnt 10.597995 hw_loss 0.187336 history loss 6.200301 rank 3
2023-02-21 23:19:30,460 DEBUG CV Batch 11/200 loss 13.690742 loss_att 25.655828 loss_ctc 18.189383 loss_rnnt 10.597995 hw_loss 0.187336 history loss 6.200301 rank 2
2023-02-21 23:19:41,845 DEBUG CV Batch 11/300 loss 9.297303 loss_att 8.876174 loss_ctc 11.050119 loss_rnnt 9.015388 hw_loss 0.248310 history loss 6.423325 rank 0
2023-02-21 23:19:42,047 DEBUG CV Batch 11/300 loss 9.297303 loss_att 8.876174 loss_ctc 11.050119 loss_rnnt 9.015388 hw_loss 0.248310 history loss 6.423325 rank 7
2023-02-21 23:19:42,108 DEBUG CV Batch 11/300 loss 9.297303 loss_att 8.876174 loss_ctc 11.050119 loss_rnnt 9.015388 hw_loss 0.248310 history loss 6.423325 rank 4
2023-02-21 23:19:42,387 DEBUG CV Batch 11/300 loss 9.297303 loss_att 8.876174 loss_ctc 11.050119 loss_rnnt 9.015388 hw_loss 0.248310 history loss 6.423325 rank 1
2023-02-21 23:19:42,461 DEBUG CV Batch 11/300 loss 9.297303 loss_att 8.876174 loss_ctc 11.050119 loss_rnnt 9.015388 hw_loss 0.248310 history loss 6.423325 rank 5
2023-02-21 23:19:42,491 DEBUG CV Batch 11/300 loss 9.297303 loss_att 8.876174 loss_ctc 11.050119 loss_rnnt 9.015388 hw_loss 0.248310 history loss 6.423325 rank 6
2023-02-21 23:19:42,541 DEBUG CV Batch 11/300 loss 9.297303 loss_att 8.876174 loss_ctc 11.050119 loss_rnnt 9.015388 hw_loss 0.248310 history loss 6.423325 rank 3
2023-02-21 23:19:43,317 DEBUG CV Batch 11/300 loss 9.297303 loss_att 8.876174 loss_ctc 11.050119 loss_rnnt 9.015388 hw_loss 0.248310 history loss 6.423325 rank 2
2023-02-21 23:19:53,944 DEBUG CV Batch 11/400 loss 33.041138 loss_att 140.219711 loss_ctc 13.741261 loss_rnnt 14.098088 hw_loss 0.151216 history loss 7.709927 rank 0
2023-02-21 23:19:54,065 DEBUG CV Batch 11/400 loss 33.041138 loss_att 140.219711 loss_ctc 13.741261 loss_rnnt 14.098088 hw_loss 0.151216 history loss 7.709927 rank 7
2023-02-21 23:19:54,188 DEBUG CV Batch 11/400 loss 33.041138 loss_att 140.219711 loss_ctc 13.741261 loss_rnnt 14.098088 hw_loss 0.151216 history loss 7.709927 rank 4
2023-02-21 23:19:54,615 DEBUG CV Batch 11/400 loss 33.041138 loss_att 140.219711 loss_ctc 13.741261 loss_rnnt 14.098088 hw_loss 0.151216 history loss 7.709927 rank 5
2023-02-21 23:19:54,619 DEBUG CV Batch 11/400 loss 33.041138 loss_att 140.219711 loss_ctc 13.741261 loss_rnnt 14.098088 hw_loss 0.151216 history loss 7.709927 rank 1
2023-02-21 23:19:54,736 DEBUG CV Batch 11/400 loss 33.041138 loss_att 140.219711 loss_ctc 13.741261 loss_rnnt 14.098088 hw_loss 0.151216 history loss 7.709927 rank 6
2023-02-21 23:19:54,756 DEBUG CV Batch 11/400 loss 33.041138 loss_att 140.219711 loss_ctc 13.741261 loss_rnnt 14.098088 hw_loss 0.151216 history loss 7.709927 rank 3
2023-02-21 23:19:55,541 DEBUG CV Batch 11/400 loss 33.041138 loss_att 140.219711 loss_ctc 13.741261 loss_rnnt 14.098088 hw_loss 0.151216 history loss 7.709927 rank 2
2023-02-21 23:20:04,552 DEBUG CV Batch 11/500 loss 7.993023 loss_att 10.106344 loss_ctc 11.408748 loss_rnnt 7.086763 hw_loss 0.052811 history loss 8.787116 rank 0
2023-02-21 23:20:04,577 DEBUG CV Batch 11/500 loss 7.993023 loss_att 10.106344 loss_ctc 11.408748 loss_rnnt 7.086763 hw_loss 0.052811 history loss 8.787116 rank 7
2023-02-21 23:20:04,787 DEBUG CV Batch 11/500 loss 7.993023 loss_att 10.106344 loss_ctc 11.408748 loss_rnnt 7.086763 hw_loss 0.052811 history loss 8.787116 rank 4
2023-02-21 23:20:05,214 DEBUG CV Batch 11/500 loss 7.993023 loss_att 10.106344 loss_ctc 11.408748 loss_rnnt 7.086763 hw_loss 0.052811 history loss 8.787116 rank 5
2023-02-21 23:20:05,240 DEBUG CV Batch 11/500 loss 7.993023 loss_att 10.106344 loss_ctc 11.408748 loss_rnnt 7.086763 hw_loss 0.052811 history loss 8.787116 rank 1
2023-02-21 23:20:05,366 DEBUG CV Batch 11/500 loss 7.993023 loss_att 10.106344 loss_ctc 11.408748 loss_rnnt 7.086763 hw_loss 0.052811 history loss 8.787116 rank 6
2023-02-21 23:20:05,587 DEBUG CV Batch 11/500 loss 7.993023 loss_att 10.106344 loss_ctc 11.408748 loss_rnnt 7.086763 hw_loss 0.052811 history loss 8.787116 rank 3
2023-02-21 23:20:06,240 DEBUG CV Batch 11/500 loss 7.993023 loss_att 10.106344 loss_ctc 11.408748 loss_rnnt 7.086763 hw_loss 0.052811 history loss 8.787116 rank 2
2023-02-21 23:20:16,634 DEBUG CV Batch 11/600 loss 10.716827 loss_att 10.511766 loss_ctc 13.103018 loss_rnnt 10.265242 hw_loss 0.327071 history loss 9.952681 rank 0
2023-02-21 23:20:16,785 DEBUG CV Batch 11/600 loss 10.716827 loss_att 10.511766 loss_ctc 13.103018 loss_rnnt 10.265242 hw_loss 0.327071 history loss 9.952681 rank 7
2023-02-21 23:20:16,938 DEBUG CV Batch 11/600 loss 10.716827 loss_att 10.511766 loss_ctc 13.103018 loss_rnnt 10.265242 hw_loss 0.327071 history loss 9.952681 rank 4
2023-02-21 23:20:17,345 DEBUG CV Batch 11/600 loss 10.716827 loss_att 10.511766 loss_ctc 13.103018 loss_rnnt 10.265242 hw_loss 0.327071 history loss 9.952681 rank 5
2023-02-21 23:20:17,966 DEBUG CV Batch 11/600 loss 10.716827 loss_att 10.511766 loss_ctc 13.103018 loss_rnnt 10.265242 hw_loss 0.327071 history loss 9.952681 rank 3
2023-02-21 23:20:18,088 DEBUG CV Batch 11/600 loss 10.716827 loss_att 10.511766 loss_ctc 13.103018 loss_rnnt 10.265242 hw_loss 0.327071 history loss 9.952681 rank 1
2023-02-21 23:20:18,381 DEBUG CV Batch 11/600 loss 10.716827 loss_att 10.511766 loss_ctc 13.103018 loss_rnnt 10.265242 hw_loss 0.327071 history loss 9.952681 rank 6
2023-02-21 23:20:18,547 DEBUG CV Batch 11/600 loss 10.716827 loss_att 10.511766 loss_ctc 13.103018 loss_rnnt 10.265242 hw_loss 0.327071 history loss 9.952681 rank 2
2023-02-21 23:20:27,970 DEBUG CV Batch 11/700 loss 30.147310 loss_att 93.005402 loss_ctc 37.255894 loss_rnnt 16.590778 hw_loss 0.069568 history loss 10.879714 rank 0
2023-02-21 23:20:28,079 DEBUG CV Batch 11/700 loss 30.147310 loss_att 93.005402 loss_ctc 37.255894 loss_rnnt 16.590778 hw_loss 0.069568 history loss 10.879714 rank 7
2023-02-21 23:20:28,249 DEBUG CV Batch 11/700 loss 30.147310 loss_att 93.005402 loss_ctc 37.255894 loss_rnnt 16.590778 hw_loss 0.069568 history loss 10.879714 rank 4
2023-02-21 23:20:29,074 DEBUG CV Batch 11/700 loss 30.147310 loss_att 93.005402 loss_ctc 37.255894 loss_rnnt 16.590778 hw_loss 0.069568 history loss 10.879714 rank 5
2023-02-21 23:20:29,463 DEBUG CV Batch 11/700 loss 30.147310 loss_att 93.005402 loss_ctc 37.255894 loss_rnnt 16.590778 hw_loss 0.069568 history loss 10.879714 rank 3
2023-02-21 23:20:30,053 DEBUG CV Batch 11/700 loss 30.147310 loss_att 93.005402 loss_ctc 37.255894 loss_rnnt 16.590778 hw_loss 0.069568 history loss 10.879714 rank 2
2023-02-21 23:20:30,169 DEBUG CV Batch 11/700 loss 30.147310 loss_att 93.005402 loss_ctc 37.255894 loss_rnnt 16.590778 hw_loss 0.069568 history loss 10.879714 rank 1
2023-02-21 23:20:30,471 DEBUG CV Batch 11/700 loss 30.147310 loss_att 93.005402 loss_ctc 37.255894 loss_rnnt 16.590778 hw_loss 0.069568 history loss 10.879714 rank 6
2023-02-21 23:20:39,183 DEBUG CV Batch 11/800 loss 17.344763 loss_att 15.627792 loss_ctc 19.797194 loss_rnnt 17.211781 hw_loss 0.280098 history loss 10.143845 rank 0
2023-02-21 23:20:39,266 DEBUG CV Batch 11/800 loss 17.344763 loss_att 15.627792 loss_ctc 19.797194 loss_rnnt 17.211781 hw_loss 0.280098 history loss 10.143845 rank 7
2023-02-21 23:20:39,495 DEBUG CV Batch 11/800 loss 17.344763 loss_att 15.627792 loss_ctc 19.797194 loss_rnnt 17.211781 hw_loss 0.280098 history loss 10.143845 rank 4
2023-02-21 23:20:40,382 DEBUG CV Batch 11/800 loss 17.344763 loss_att 15.627792 loss_ctc 19.797194 loss_rnnt 17.211781 hw_loss 0.280098 history loss 10.143845 rank 5
2023-02-21 23:20:40,886 DEBUG CV Batch 11/800 loss 17.344763 loss_att 15.627792 loss_ctc 19.797194 loss_rnnt 17.211781 hw_loss 0.280098 history loss 10.143845 rank 3
2023-02-21 23:20:41,463 DEBUG CV Batch 11/800 loss 17.344763 loss_att 15.627792 loss_ctc 19.797194 loss_rnnt 17.211781 hw_loss 0.280098 history loss 10.143845 rank 1
2023-02-21 23:20:41,556 DEBUG CV Batch 11/800 loss 17.344763 loss_att 15.627792 loss_ctc 19.797194 loss_rnnt 17.211781 hw_loss 0.280098 history loss 10.143845 rank 2
2023-02-21 23:20:42,060 DEBUG CV Batch 11/800 loss 17.344763 loss_att 15.627792 loss_ctc 19.797194 loss_rnnt 17.211781 hw_loss 0.280098 history loss 10.143845 rank 6
2023-02-21 23:20:52,409 DEBUG CV Batch 11/900 loss 18.209871 loss_att 33.131134 loss_ctc 25.429773 loss_rnnt 14.254643 hw_loss 0.015604 history loss 9.876483 rank 0
2023-02-21 23:20:52,572 DEBUG CV Batch 11/900 loss 18.209871 loss_att 33.131134 loss_ctc 25.429773 loss_rnnt 14.254643 hw_loss 0.015604 history loss 9.876483 rank 7
2023-02-21 23:20:52,787 DEBUG CV Batch 11/900 loss 18.209871 loss_att 33.131134 loss_ctc 25.429773 loss_rnnt 14.254643 hw_loss 0.015604 history loss 9.876483 rank 4
2023-02-21 23:20:53,877 DEBUG CV Batch 11/900 loss 18.209871 loss_att 33.131134 loss_ctc 25.429773 loss_rnnt 14.254643 hw_loss 0.015604 history loss 9.876483 rank 5
2023-02-21 23:20:54,220 DEBUG CV Batch 11/900 loss 18.209871 loss_att 33.131134 loss_ctc 25.429773 loss_rnnt 14.254643 hw_loss 0.015604 history loss 9.876483 rank 3
2023-02-21 23:20:54,774 DEBUG CV Batch 11/900 loss 18.209871 loss_att 33.131134 loss_ctc 25.429773 loss_rnnt 14.254643 hw_loss 0.015604 history loss 9.876483 rank 1
2023-02-21 23:20:54,853 DEBUG CV Batch 11/900 loss 18.209871 loss_att 33.131134 loss_ctc 25.429773 loss_rnnt 14.254643 hw_loss 0.015604 history loss 9.876483 rank 2
2023-02-21 23:20:55,800 DEBUG CV Batch 11/900 loss 18.209871 loss_att 33.131134 loss_ctc 25.429773 loss_rnnt 14.254643 hw_loss 0.015604 history loss 9.876483 rank 6
2023-02-21 23:21:04,618 DEBUG CV Batch 11/1000 loss 4.980906 loss_att 5.825151 loss_ctc 5.148054 loss_rnnt 4.706364 hw_loss 0.156386 history loss 9.567247 rank 0
2023-02-21 23:21:04,765 DEBUG CV Batch 11/1000 loss 4.980906 loss_att 5.825151 loss_ctc 5.148054 loss_rnnt 4.706364 hw_loss 0.156386 history loss 9.567247 rank 7
2023-02-21 23:21:05,028 DEBUG CV Batch 11/1000 loss 4.980906 loss_att 5.825151 loss_ctc 5.148054 loss_rnnt 4.706364 hw_loss 0.156386 history loss 9.567247 rank 4
2023-02-21 23:21:06,361 DEBUG CV Batch 11/1000 loss 4.980906 loss_att 5.825151 loss_ctc 5.148054 loss_rnnt 4.706364 hw_loss 0.156386 history loss 9.567247 rank 5
2023-02-21 23:21:06,476 DEBUG CV Batch 11/1000 loss 4.980906 loss_att 5.825151 loss_ctc 5.148054 loss_rnnt 4.706364 hw_loss 0.156386 history loss 9.567247 rank 3
2023-02-21 23:21:07,055 DEBUG CV Batch 11/1000 loss 4.980906 loss_att 5.825151 loss_ctc 5.148054 loss_rnnt 4.706364 hw_loss 0.156386 history loss 9.567247 rank 2
2023-02-21 23:21:07,363 DEBUG CV Batch 11/1000 loss 4.980906 loss_att 5.825151 loss_ctc 5.148054 loss_rnnt 4.706364 hw_loss 0.156386 history loss 9.567247 rank 1
2023-02-21 23:21:08,102 DEBUG CV Batch 11/1000 loss 4.980906 loss_att 5.825151 loss_ctc 5.148054 loss_rnnt 4.706364 hw_loss 0.156386 history loss 9.567247 rank 6
2023-02-21 23:21:16,414 DEBUG CV Batch 11/1100 loss 8.185633 loss_att 7.268129 loss_ctc 9.946985 loss_rnnt 7.974743 hw_loss 0.299145 history loss 9.538227 rank 0
2023-02-21 23:21:16,717 DEBUG CV Batch 11/1100 loss 8.185633 loss_att 7.268129 loss_ctc 9.946985 loss_rnnt 7.974743 hw_loss 0.299145 history loss 9.538227 rank 7
2023-02-21 23:21:16,855 DEBUG CV Batch 11/1100 loss 8.185633 loss_att 7.268129 loss_ctc 9.946985 loss_rnnt 7.974743 hw_loss 0.299145 history loss 9.538227 rank 4
2023-02-21 23:21:18,300 DEBUG CV Batch 11/1100 loss 8.185633 loss_att 7.268129 loss_ctc 9.946985 loss_rnnt 7.974743 hw_loss 0.299145 history loss 9.538227 rank 5
2023-02-21 23:21:18,522 DEBUG CV Batch 11/1100 loss 8.185633 loss_att 7.268129 loss_ctc 9.946985 loss_rnnt 7.974743 hw_loss 0.299145 history loss 9.538227 rank 3
2023-02-21 23:21:19,047 DEBUG CV Batch 11/1100 loss 8.185633 loss_att 7.268129 loss_ctc 9.946985 loss_rnnt 7.974743 hw_loss 0.299145 history loss 9.538227 rank 2
2023-02-21 23:21:19,457 DEBUG CV Batch 11/1100 loss 8.185633 loss_att 7.268129 loss_ctc 9.946985 loss_rnnt 7.974743 hw_loss 0.299145 history loss 9.538227 rank 1
2023-02-21 23:21:20,181 DEBUG CV Batch 11/1100 loss 8.185633 loss_att 7.268129 loss_ctc 9.946985 loss_rnnt 7.974743 hw_loss 0.299145 history loss 9.538227 rank 6
2023-02-21 23:21:26,952 DEBUG CV Batch 11/1200 loss 12.852956 loss_att 14.021650 loss_ctc 15.004827 loss_rnnt 12.266485 hw_loss 0.123406 history loss 10.008049 rank 0
2023-02-21 23:21:27,331 DEBUG CV Batch 11/1200 loss 12.852956 loss_att 14.021650 loss_ctc 15.004827 loss_rnnt 12.266485 hw_loss 0.123406 history loss 10.008049 rank 7
2023-02-21 23:21:27,485 DEBUG CV Batch 11/1200 loss 12.852956 loss_att 14.021650 loss_ctc 15.004827 loss_rnnt 12.266485 hw_loss 0.123406 history loss 10.008049 rank 4
2023-02-21 23:21:28,901 DEBUG CV Batch 11/1200 loss 12.852956 loss_att 14.021650 loss_ctc 15.004827 loss_rnnt 12.266485 hw_loss 0.123406 history loss 10.008049 rank 5
2023-02-21 23:21:29,215 DEBUG CV Batch 11/1200 loss 12.852956 loss_att 14.021650 loss_ctc 15.004827 loss_rnnt 12.266485 hw_loss 0.123406 history loss 10.008049 rank 3
2023-02-21 23:21:29,648 DEBUG CV Batch 11/1200 loss 12.852956 loss_att 14.021650 loss_ctc 15.004827 loss_rnnt 12.266485 hw_loss 0.123406 history loss 10.008049 rank 2
2023-02-21 23:21:30,850 DEBUG CV Batch 11/1200 loss 12.852956 loss_att 14.021650 loss_ctc 15.004827 loss_rnnt 12.266485 hw_loss 0.123406 history loss 10.008049 rank 1
2023-02-21 23:21:30,872 DEBUG CV Batch 11/1200 loss 12.852956 loss_att 14.021650 loss_ctc 15.004827 loss_rnnt 12.266485 hw_loss 0.123406 history loss 10.008049 rank 6
2023-02-21 23:21:39,003 DEBUG CV Batch 11/1300 loss 9.448542 loss_att 8.534943 loss_ctc 10.998718 loss_rnnt 9.246107 hw_loss 0.334620 history loss 10.380557 rank 0
2023-02-21 23:21:39,299 DEBUG CV Batch 11/1300 loss 9.448542 loss_att 8.534943 loss_ctc 10.998718 loss_rnnt 9.246107 hw_loss 0.334620 history loss 10.380557 rank 7
2023-02-21 23:21:39,482 DEBUG CV Batch 11/1300 loss 9.448542 loss_att 8.534943 loss_ctc 10.998718 loss_rnnt 9.246107 hw_loss 0.334620 history loss 10.380557 rank 4
2023-02-21 23:21:40,898 DEBUG CV Batch 11/1300 loss 9.448542 loss_att 8.534943 loss_ctc 10.998718 loss_rnnt 9.246107 hw_loss 0.334620 history loss 10.380557 rank 5
2023-02-21 23:21:41,305 DEBUG CV Batch 11/1300 loss 9.448542 loss_att 8.534943 loss_ctc 10.998718 loss_rnnt 9.246107 hw_loss 0.334620 history loss 10.380557 rank 3
2023-02-21 23:21:41,766 DEBUG CV Batch 11/1300 loss 9.448542 loss_att 8.534943 loss_ctc 10.998718 loss_rnnt 9.246107 hw_loss 0.334620 history loss 10.380557 rank 2
2023-02-21 23:21:42,982 DEBUG CV Batch 11/1300 loss 9.448542 loss_att 8.534943 loss_ctc 10.998718 loss_rnnt 9.246107 hw_loss 0.334620 history loss 10.380557 rank 6
2023-02-21 23:21:43,083 DEBUG CV Batch 11/1300 loss 9.448542 loss_att 8.534943 loss_ctc 10.998718 loss_rnnt 9.246107 hw_loss 0.334620 history loss 10.380557 rank 1
2023-02-21 23:21:50,197 DEBUG CV Batch 11/1400 loss 12.895954 loss_att 59.962082 loss_ctc 5.876759 loss_rnnt 4.319554 hw_loss 0.185751 history loss 10.832407 rank 0
2023-02-21 23:21:50,488 DEBUG CV Batch 11/1400 loss 12.895954 loss_att 59.962082 loss_ctc 5.876759 loss_rnnt 4.319554 hw_loss 0.185751 history loss 10.832407 rank 7
2023-02-21 23:21:50,663 DEBUG CV Batch 11/1400 loss 12.895954 loss_att 59.962082 loss_ctc 5.876759 loss_rnnt 4.319554 hw_loss 0.185751 history loss 10.832407 rank 4
2023-02-21 23:21:52,156 DEBUG CV Batch 11/1400 loss 12.895954 loss_att 59.962082 loss_ctc 5.876759 loss_rnnt 4.319554 hw_loss 0.185751 history loss 10.832407 rank 5
2023-02-21 23:21:52,745 DEBUG CV Batch 11/1400 loss 12.895954 loss_att 59.962082 loss_ctc 5.876759 loss_rnnt 4.319554 hw_loss 0.185751 history loss 10.832407 rank 3
2023-02-21 23:21:53,065 DEBUG CV Batch 11/1400 loss 12.895954 loss_att 59.962082 loss_ctc 5.876759 loss_rnnt 4.319554 hw_loss 0.185751 history loss 10.832407 rank 2
2023-02-21 23:21:54,359 DEBUG CV Batch 11/1400 loss 12.895954 loss_att 59.962082 loss_ctc 5.876759 loss_rnnt 4.319554 hw_loss 0.185751 history loss 10.832407 rank 6
2023-02-21 23:21:55,574 DEBUG CV Batch 11/1400 loss 12.895954 loss_att 59.962082 loss_ctc 5.876759 loss_rnnt 4.319554 hw_loss 0.185751 history loss 10.832407 rank 1
2023-02-21 23:22:01,655 DEBUG CV Batch 11/1500 loss 10.012694 loss_att 10.900380 loss_ctc 7.287037 loss_rnnt 10.036285 hw_loss 0.304299 history loss 10.572078 rank 0
2023-02-21 23:22:01,887 DEBUG CV Batch 11/1500 loss 10.012694 loss_att 10.900380 loss_ctc 7.287037 loss_rnnt 10.036285 hw_loss 0.304299 history loss 10.572078 rank 7
2023-02-21 23:22:02,046 DEBUG CV Batch 11/1500 loss 10.012694 loss_att 10.900380 loss_ctc 7.287037 loss_rnnt 10.036285 hw_loss 0.304299 history loss 10.572078 rank 4
2023-02-21 23:22:03,579 DEBUG CV Batch 11/1500 loss 10.012694 loss_att 10.900380 loss_ctc 7.287037 loss_rnnt 10.036285 hw_loss 0.304299 history loss 10.572078 rank 5
2023-02-21 23:22:04,433 DEBUG CV Batch 11/1500 loss 10.012694 loss_att 10.900380 loss_ctc 7.287037 loss_rnnt 10.036285 hw_loss 0.304299 history loss 10.572078 rank 3
2023-02-21 23:22:04,735 DEBUG CV Batch 11/1500 loss 10.012694 loss_att 10.900380 loss_ctc 7.287037 loss_rnnt 10.036285 hw_loss 0.304299 history loss 10.572078 rank 2
2023-02-21 23:22:05,986 DEBUG CV Batch 11/1500 loss 10.012694 loss_att 10.900380 loss_ctc 7.287037 loss_rnnt 10.036285 hw_loss 0.304299 history loss 10.572078 rank 6
2023-02-21 23:22:07,014 DEBUG CV Batch 11/1500 loss 10.012694 loss_att 10.900380 loss_ctc 7.287037 loss_rnnt 10.036285 hw_loss 0.304299 history loss 10.572078 rank 1
2023-02-21 23:22:14,549 DEBUG CV Batch 11/1600 loss 14.608234 loss_att 26.308167 loss_ctc 18.992012 loss_rnnt 11.583193 hw_loss 0.188531 history loss 10.456846 rank 0
2023-02-21 23:22:14,901 DEBUG CV Batch 11/1600 loss 14.608234 loss_att 26.308167 loss_ctc 18.992012 loss_rnnt 11.583193 hw_loss 0.188531 history loss 10.456846 rank 7
2023-02-21 23:22:14,965 DEBUG CV Batch 11/1600 loss 14.608234 loss_att 26.308167 loss_ctc 18.992012 loss_rnnt 11.583193 hw_loss 0.188531 history loss 10.456846 rank 4
2023-02-21 23:22:16,575 DEBUG CV Batch 11/1600 loss 14.608234 loss_att 26.308167 loss_ctc 18.992012 loss_rnnt 11.583193 hw_loss 0.188531 history loss 10.456846 rank 5
2023-02-21 23:22:17,746 DEBUG CV Batch 11/1600 loss 14.608234 loss_att 26.308167 loss_ctc 18.992012 loss_rnnt 11.583193 hw_loss 0.188531 history loss 10.456846 rank 2
2023-02-21 23:22:17,794 DEBUG CV Batch 11/1600 loss 14.608234 loss_att 26.308167 loss_ctc 18.992012 loss_rnnt 11.583193 hw_loss 0.188531 history loss 10.456846 rank 3
2023-02-21 23:22:19,139 DEBUG CV Batch 11/1600 loss 14.608234 loss_att 26.308167 loss_ctc 18.992012 loss_rnnt 11.583193 hw_loss 0.188531 history loss 10.456846 rank 6
2023-02-21 23:22:20,030 DEBUG CV Batch 11/1600 loss 14.608234 loss_att 26.308167 loss_ctc 18.992012 loss_rnnt 11.583193 hw_loss 0.188531 history loss 10.456846 rank 1
2023-02-21 23:22:26,733 DEBUG CV Batch 11/1700 loss 11.989846 loss_att 11.270660 loss_ctc 15.835855 loss_rnnt 11.475913 hw_loss 0.271817 history loss 10.318420 rank 0
2023-02-21 23:22:27,210 DEBUG CV Batch 11/1700 loss 11.989846 loss_att 11.270660 loss_ctc 15.835855 loss_rnnt 11.475913 hw_loss 0.271817 history loss 10.318420 rank 4
2023-02-21 23:22:27,254 DEBUG CV Batch 11/1700 loss 11.989846 loss_att 11.270660 loss_ctc 15.835855 loss_rnnt 11.475913 hw_loss 0.271817 history loss 10.318420 rank 7
2023-02-21 23:22:28,851 DEBUG CV Batch 11/1700 loss 11.989846 loss_att 11.270660 loss_ctc 15.835855 loss_rnnt 11.475913 hw_loss 0.271817 history loss 10.318420 rank 5
2023-02-21 23:22:30,398 DEBUG CV Batch 11/1700 loss 11.989846 loss_att 11.270660 loss_ctc 15.835855 loss_rnnt 11.475913 hw_loss 0.271817 history loss 10.318420 rank 2
2023-02-21 23:22:30,489 DEBUG CV Batch 11/1700 loss 11.989846 loss_att 11.270660 loss_ctc 15.835855 loss_rnnt 11.475913 hw_loss 0.271817 history loss 10.318420 rank 3
2023-02-21 23:22:31,788 DEBUG CV Batch 11/1700 loss 11.989846 loss_att 11.270660 loss_ctc 15.835855 loss_rnnt 11.475913 hw_loss 0.271817 history loss 10.318420 rank 6
2023-02-21 23:22:32,249 DEBUG CV Batch 11/1700 loss 11.989846 loss_att 11.270660 loss_ctc 15.835855 loss_rnnt 11.475913 hw_loss 0.271817 history loss 10.318420 rank 1
2023-02-21 23:22:35,725 INFO Epoch 11 CV info cv_loss 10.261958013717658
2023-02-21 23:22:35,726 INFO Checkpoint: save to checkpoint exp/2_21_rnnt_bias_loss_2_class_1word_finetune/11.pt
2023-02-21 23:22:36,552 INFO Epoch 11 CV info cv_loss 10.261958012709746
2023-02-21 23:22:36,553 INFO Epoch 12 TRAIN info lr 0.0004997576762762659
2023-02-21 23:22:36,553 INFO Epoch 11 CV info cv_loss 10.261958012761434
2023-02-21 23:22:36,554 INFO Epoch 12 TRAIN info lr 0.0004997302185033558
2023-02-21 23:22:36,556 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-21 23:22:36,559 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-21 23:22:37,818 INFO Epoch 11 CV info cv_loss 10.261958012373777
2023-02-21 23:22:37,819 INFO Epoch 12 TRAIN info lr 0.0004997252266672312
2023-02-21 23:22:37,824 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-21 23:22:39,534 INFO Epoch 11 CV info cv_loss 10.261958012838965
2023-02-21 23:22:39,535 INFO Epoch 12 TRAIN info lr 0.0004997027652557178
2023-02-21 23:22:39,539 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-21 23:22:39,694 INFO Epoch 11 CV info cv_loss 10.261958013347229
2023-02-21 23:22:39,695 INFO Epoch 12 TRAIN info lr 0.0004997252266672312
2023-02-21 23:22:39,699 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-21 23:22:39,830 INFO Epoch 12 TRAIN info lr 0.0004997951259889105
2023-02-21 23:22:39,836 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-21 23:22:41,308 INFO Epoch 11 CV info cv_loss 10.261958012218713
2023-02-21 23:22:41,309 INFO Epoch 12 TRAIN info lr 0.0004997751517611834
2023-02-21 23:22:41,312 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-21 23:22:41,692 INFO Epoch 11 CV info cv_loss 10.26195801273559
2023-02-21 23:22:41,694 INFO Epoch 12 TRAIN info lr 0.0004997277225665945
2023-02-21 23:22:41,697 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-21 23:23:55,712 DEBUG TRAIN Batch 12/0 loss 10.954156 loss_att 11.091644 loss_ctc 12.071291 loss_rnnt 10.515779 hw_loss 0.491114 lr 0.00049979 rank 0
2023-02-21 23:23:55,713 DEBUG TRAIN Batch 12/0 loss 16.134638 loss_att 16.270214 loss_ctc 19.456425 loss_rnnt 15.481314 hw_loss 0.343697 lr 0.00049972 rank 5
2023-02-21 23:23:55,717 DEBUG TRAIN Batch 12/0 loss 9.315712 loss_att 8.972015 loss_ctc 9.615582 loss_rnnt 9.182945 hw_loss 0.302856 lr 0.00049976 rank 4
2023-02-21 23:23:55,719 DEBUG TRAIN Batch 12/0 loss 18.760532 loss_att 16.891865 loss_ctc 22.180014 loss_rnnt 18.507086 hw_loss 0.321095 lr 0.00049973 rank 7
2023-02-21 23:23:55,721 DEBUG TRAIN Batch 12/0 loss 14.124054 loss_att 13.067117 loss_ctc 14.453395 loss_rnnt 14.145353 hw_loss 0.274081 lr 0.00049972 rank 3
2023-02-21 23:23:55,725 DEBUG TRAIN Batch 12/0 loss 19.330210 loss_att 16.828478 loss_ctc 23.631361 loss_rnnt 19.074694 hw_loss 0.341952 lr 0.00049977 rank 1
2023-02-21 23:23:55,731 DEBUG TRAIN Batch 12/0 loss 10.519049 loss_att 9.232302 loss_ctc 11.882934 loss_rnnt 10.371795 hw_loss 0.417661 lr 0.00049970 rank 2
2023-02-21 23:23:55,769 DEBUG TRAIN Batch 12/0 loss 11.258660 loss_att 10.816183 loss_ctc 12.684760 loss_rnnt 10.955659 hw_loss 0.377532 lr 0.00049973 rank 6
2023-02-21 23:25:10,116 DEBUG TRAIN Batch 12/100 loss 19.669558 loss_att 21.644663 loss_ctc 26.372099 loss_rnnt 18.302208 hw_loss 0.147479 lr 0.00049954 rank 0
2023-02-21 23:25:10,117 DEBUG TRAIN Batch 12/100 loss 7.668095 loss_att 10.589632 loss_ctc 11.900924 loss_rnnt 6.464256 hw_loss 0.103414 lr 0.00049951 rank 4
2023-02-21 23:25:10,121 DEBUG TRAIN Batch 12/100 loss 12.075113 loss_att 14.345313 loss_ctc 14.232191 loss_rnnt 11.296126 hw_loss 0.070007 lr 0.00049952 rank 1
2023-02-21 23:25:10,123 DEBUG TRAIN Batch 12/100 loss 29.135643 loss_att 33.209663 loss_ctc 40.588177 loss_rnnt 26.655111 hw_loss 0.260103 lr 0.00049948 rank 7
2023-02-21 23:25:10,123 DEBUG TRAIN Batch 12/100 loss 18.214470 loss_att 28.524691 loss_ctc 24.030386 loss_rnnt 15.314750 hw_loss 0.116661 lr 0.00049945 rank 2
2023-02-21 23:25:10,124 DEBUG TRAIN Batch 12/100 loss 18.192089 loss_att 21.954315 loss_ctc 26.537048 loss_rnnt 16.236013 hw_loss 0.170571 lr 0.00049947 rank 5
2023-02-21 23:25:10,126 DEBUG TRAIN Batch 12/100 loss 7.000222 loss_att 15.798615 loss_ctc 7.795010 loss_rnnt 5.029373 hw_loss 0.197247 lr 0.00049947 rank 3
2023-02-21 23:25:10,173 DEBUG TRAIN Batch 12/100 loss 26.867247 loss_att 31.860643 loss_ctc 30.232754 loss_rnnt 25.316940 hw_loss 0.192924 lr 0.00049948 rank 6
2023-02-21 23:26:25,705 DEBUG TRAIN Batch 12/200 loss 28.422388 loss_att 31.700291 loss_ctc 40.543297 loss_rnnt 26.116766 hw_loss 0.063605 lr 0.00049922 rank 5
2023-02-21 23:26:25,707 DEBUG TRAIN Batch 12/200 loss 5.656559 loss_att 10.083574 loss_ctc 6.236631 loss_rnnt 4.599855 hw_loss 0.176171 lr 0.00049926 rank 4
2023-02-21 23:26:25,707 DEBUG TRAIN Batch 12/200 loss 15.187885 loss_att 19.472313 loss_ctc 18.945656 loss_rnnt 13.743986 hw_loss 0.161209 lr 0.00049923 rank 7
2023-02-21 23:26:25,709 DEBUG TRAIN Batch 12/200 loss 29.750034 loss_att 32.803356 loss_ctc 35.731209 loss_rnnt 28.341726 hw_loss 0.000293 lr 0.00049929 rank 0
2023-02-21 23:26:25,713 DEBUG TRAIN Batch 12/200 loss 23.421499 loss_att 30.906731 loss_ctc 28.268192 loss_rnnt 21.234661 hw_loss 0.081688 lr 0.00049927 rank 1
2023-02-21 23:26:25,715 DEBUG TRAIN Batch 12/200 loss 17.678391 loss_att 28.009171 loss_ctc 27.604124 loss_rnnt 14.240573 hw_loss 0.090431 lr 0.00049922 rank 3
2023-02-21 23:26:25,715 DEBUG TRAIN Batch 12/200 loss 25.268122 loss_att 30.314636 loss_ctc 33.818481 loss_rnnt 23.043247 hw_loss 0.141607 lr 0.00049920 rank 2
2023-02-21 23:26:25,761 DEBUG TRAIN Batch 12/200 loss 5.031096 loss_att 12.458790 loss_ctc 4.710112 loss_rnnt 3.452086 hw_loss 0.255505 lr 0.00049923 rank 6
2023-02-21 23:27:41,979 DEBUG TRAIN Batch 12/300 loss 19.520311 loss_att 26.520058 loss_ctc 19.516670 loss_rnnt 18.030544 hw_loss 0.169318 lr 0.00049898 rank 7
2023-02-21 23:27:41,983 DEBUG TRAIN Batch 12/300 loss 15.958302 loss_att 19.898396 loss_ctc 17.447901 loss_rnnt 14.897194 hw_loss 0.139641 lr 0.00049898 rank 5
2023-02-21 23:27:41,987 DEBUG TRAIN Batch 12/300 loss 12.096820 loss_att 15.415810 loss_ctc 16.127546 loss_rnnt 10.834948 hw_loss 0.113706 lr 0.00049903 rank 1
2023-02-21 23:27:41,987 DEBUG TRAIN Batch 12/300 loss 14.619117 loss_att 18.419231 loss_ctc 15.315514 loss_rnnt 13.623758 hw_loss 0.267152 lr 0.00049905 rank 0
2023-02-21 23:27:41,987 DEBUG TRAIN Batch 12/300 loss 21.608255 loss_att 25.832359 loss_ctc 27.168604 loss_rnnt 19.925129 hw_loss 0.181736 lr 0.00049895 rank 2
2023-02-21 23:27:41,988 DEBUG TRAIN Batch 12/300 loss 8.814176 loss_att 12.367848 loss_ctc 8.458252 loss_rnnt 8.079250 hw_loss 0.134339 lr 0.00049898 rank 3
2023-02-21 23:27:41,989 DEBUG TRAIN Batch 12/300 loss 24.440607 loss_att 36.208420 loss_ctc 30.682060 loss_rnnt 21.153967 hw_loss 0.189157 lr 0.00049901 rank 4
2023-02-21 23:27:41,989 DEBUG TRAIN Batch 12/300 loss 16.018517 loss_att 22.664515 loss_ctc 18.610096 loss_rnnt 14.254108 hw_loss 0.168120 lr 0.00049898 rank 6
2023-02-21 23:28:59,307 DEBUG TRAIN Batch 12/400 loss 12.448151 loss_att 14.994295 loss_ctc 15.655102 loss_rnnt 11.399683 hw_loss 0.209334 lr 0.00049873 rank 5
2023-02-21 23:28:59,313 DEBUG TRAIN Batch 12/400 loss 22.384203 loss_att 25.264969 loss_ctc 26.547462 loss_rnnt 21.141235 hw_loss 0.209461 lr 0.00049873 rank 7
2023-02-21 23:28:59,312 DEBUG TRAIN Batch 12/400 loss 21.121618 loss_att 31.778122 loss_ctc 26.441910 loss_rnnt 18.167402 hw_loss 0.212894 lr 0.00049880 rank 0
2023-02-21 23:28:59,316 DEBUG TRAIN Batch 12/400 loss 55.521805 loss_att 63.266880 loss_ctc 65.011337 loss_rnnt 52.569019 hw_loss 0.259689 lr 0.00049873 rank 3
2023-02-21 23:28:59,316 DEBUG TRAIN Batch 12/400 loss 30.542284 loss_att 33.541229 loss_ctc 34.678841 loss_rnnt 29.307362 hw_loss 0.156731 lr 0.00049871 rank 2
2023-02-21 23:28:59,315 DEBUG TRAIN Batch 12/400 loss 15.753911 loss_att 22.368475 loss_ctc 20.690636 loss_rnnt 13.670900 hw_loss 0.191002 lr 0.00049876 rank 4
2023-02-21 23:28:59,317 DEBUG TRAIN Batch 12/400 loss 14.338467 loss_att 19.424500 loss_ctc 16.193899 loss_rnnt 12.937845 hw_loss 0.255043 lr 0.00049878 rank 1
2023-02-21 23:28:59,362 DEBUG TRAIN Batch 12/400 loss 16.609848 loss_att 23.028687 loss_ctc 21.288284 loss_rnnt 14.617426 hw_loss 0.159117 lr 0.00049873 rank 6
2023-02-21 23:30:15,522 DEBUG TRAIN Batch 12/500 loss 16.667990 loss_att 22.815117 loss_ctc 20.780617 loss_rnnt 14.743303 hw_loss 0.275456 lr 0.00049851 rank 4
2023-02-21 23:30:15,524 DEBUG TRAIN Batch 12/500 loss 15.750781 loss_att 18.895523 loss_ctc 16.699429 loss_rnnt 14.919628 hw_loss 0.141971 lr 0.00049848 rank 7
2023-02-21 23:30:15,528 DEBUG TRAIN Batch 12/500 loss 13.916823 loss_att 17.141685 loss_ctc 15.587778 loss_rnnt 12.943054 hw_loss 0.198756 lr 0.00049848 rank 5
2023-02-21 23:30:15,528 DEBUG TRAIN Batch 12/500 loss 13.668674 loss_att 16.496771 loss_ctc 16.275229 loss_rnnt 12.671481 hw_loss 0.157563 lr 0.00049855 rank 0
2023-02-21 23:30:15,529 DEBUG TRAIN Batch 12/500 loss 10.820329 loss_att 15.056868 loss_ctc 15.960707 loss_rnnt 9.222805 hw_loss 0.121563 lr 0.00049848 rank 6
2023-02-21 23:30:15,533 DEBUG TRAIN Batch 12/500 loss 31.675388 loss_att 36.239334 loss_ctc 37.759014 loss_rnnt 29.855778 hw_loss 0.179379 lr 0.00049848 rank 3
2023-02-21 23:30:15,541 DEBUG TRAIN Batch 12/500 loss 10.024887 loss_att 13.729026 loss_ctc 11.352175 loss_rnnt 8.977448 hw_loss 0.243074 lr 0.00049846 rank 2
2023-02-21 23:30:15,573 DEBUG TRAIN Batch 12/500 loss 17.641619 loss_att 24.316765 loss_ctc 19.735331 loss_rnnt 15.832027 hw_loss 0.366377 lr 0.00049853 rank 1
2023-02-21 23:31:30,107 DEBUG TRAIN Batch 12/600 loss 20.532637 loss_att 17.941166 loss_ctc 22.726706 loss_rnnt 20.691317 hw_loss 0.125757 lr 0.00049823 rank 5
2023-02-21 23:31:30,108 DEBUG TRAIN Batch 12/600 loss 15.751209 loss_att 17.467039 loss_ctc 17.025333 loss_rnnt 15.135318 hw_loss 0.192829 lr 0.00049826 rank 4
2023-02-21 23:31:30,112 DEBUG TRAIN Batch 12/600 loss 17.482630 loss_att 20.279537 loss_ctc 22.241545 loss_rnnt 16.191978 hw_loss 0.181403 lr 0.00049823 rank 3
2023-02-21 23:31:30,112 DEBUG TRAIN Batch 12/600 loss 13.140116 loss_att 12.409612 loss_ctc 15.373289 loss_rnnt 12.857538 hw_loss 0.245479 lr 0.00049830 rank 0
2023-02-21 23:31:30,115 DEBUG TRAIN Batch 12/600 loss 21.767736 loss_att 22.534740 loss_ctc 24.730566 loss_rnnt 21.021805 hw_loss 0.370290 lr 0.00049824 rank 7
2023-02-21 23:31:30,116 DEBUG TRAIN Batch 12/600 loss 17.912930 loss_att 19.549763 loss_ctc 21.612289 loss_rnnt 16.983250 hw_loss 0.204498 lr 0.00049828 rank 1
2023-02-21 23:31:30,117 DEBUG TRAIN Batch 12/600 loss 13.257229 loss_att 15.629765 loss_ctc 14.459122 loss_rnnt 12.538080 hw_loss 0.158229 lr 0.00049821 rank 2
2023-02-21 23:31:30,119 DEBUG TRAIN Batch 12/600 loss 15.959228 loss_att 17.512877 loss_ctc 23.668991 loss_rnnt 14.537258 hw_loss 0.156133 lr 0.00049823 rank 6
2023-02-21 23:32:46,880 DEBUG TRAIN Batch 12/700 loss 12.552290 loss_att 21.117863 loss_ctc 18.259781 loss_rnnt 9.960426 hw_loss 0.220780 lr 0.00049805 rank 0
2023-02-21 23:32:46,881 DEBUG TRAIN Batch 12/700 loss 8.842013 loss_att 13.591043 loss_ctc 14.352538 loss_rnnt 7.048443 hw_loss 0.204426 lr 0.00049802 rank 4
2023-02-21 23:32:46,884 DEBUG TRAIN Batch 12/700 loss 14.539793 loss_att 16.424969 loss_ctc 16.648132 loss_rnnt 13.811317 hw_loss 0.131866 lr 0.00049798 rank 5
2023-02-21 23:32:46,889 DEBUG TRAIN Batch 12/700 loss 14.445997 loss_att 17.075071 loss_ctc 15.021420 loss_rnnt 13.713493 hw_loss 0.243687 lr 0.00049803 rank 1
2023-02-21 23:32:46,891 DEBUG TRAIN Batch 12/700 loss 16.886343 loss_att 19.828709 loss_ctc 27.807362 loss_rnnt 14.737669 hw_loss 0.195124 lr 0.00049796 rank 2
2023-02-21 23:32:46,893 DEBUG TRAIN Batch 12/700 loss 16.844927 loss_att 20.856224 loss_ctc 17.430775 loss_rnnt 15.963176 hw_loss 0.002584 lr 0.00049798 rank 3
2023-02-21 23:32:46,909 DEBUG TRAIN Batch 12/700 loss 13.616433 loss_att 16.071678 loss_ctc 16.802731 loss_rnnt 12.596011 hw_loss 0.196002 lr 0.00049799 rank 6
2023-02-21 23:32:46,912 DEBUG TRAIN Batch 12/700 loss 10.119453 loss_att 14.533226 loss_ctc 13.272057 loss_rnnt 8.734867 hw_loss 0.152784 lr 0.00049799 rank 7
2023-02-21 23:34:01,645 DEBUG TRAIN Batch 12/800 loss 13.940734 loss_att 20.801430 loss_ctc 12.462332 loss_rnnt 12.686438 hw_loss 0.148647 lr 0.00049781 rank 0
2023-02-21 23:34:01,646 DEBUG TRAIN Batch 12/800 loss 10.352327 loss_att 12.617586 loss_ctc 12.286448 loss_rnnt 9.548080 hw_loss 0.174961 lr 0.00049777 rank 4
2023-02-21 23:34:01,650 DEBUG TRAIN Batch 12/800 loss 9.404532 loss_att 18.293406 loss_ctc 14.808456 loss_rnnt 6.816946 hw_loss 0.167417 lr 0.00049779 rank 1
2023-02-21 23:34:01,651 DEBUG TRAIN Batch 12/800 loss 18.016890 loss_att 23.622566 loss_ctc 25.450695 loss_rnnt 15.816794 hw_loss 0.164602 lr 0.00049774 rank 7
2023-02-21 23:34:01,653 DEBUG TRAIN Batch 12/800 loss 33.004070 loss_att 36.422649 loss_ctc 40.920116 loss_rnnt 31.215775 hw_loss 0.092081 lr 0.00049774 rank 3
2023-02-21 23:34:01,654 DEBUG TRAIN Batch 12/800 loss 28.530737 loss_att 31.427116 loss_ctc 35.739468 loss_rnnt 26.841467 hw_loss 0.279059 lr 0.00049774 rank 6
2023-02-21 23:34:01,656 DEBUG TRAIN Batch 12/800 loss 16.767187 loss_att 22.282488 loss_ctc 22.367588 loss_rnnt 14.792007 hw_loss 0.235125 lr 0.00049774 rank 5
2023-02-21 23:34:01,661 DEBUG TRAIN Batch 12/800 loss 18.229355 loss_att 23.855970 loss_ctc 24.896551 loss_rnnt 16.104336 hw_loss 0.207631 lr 0.00049772 rank 2
2023-02-21 23:35:17,251 DEBUG TRAIN Batch 12/900 loss 19.510948 loss_att 25.767282 loss_ctc 23.747715 loss_rnnt 17.526119 hw_loss 0.316233 lr 0.00049749 rank 5
2023-02-21 23:35:17,251 DEBUG TRAIN Batch 12/900 loss 11.376809 loss_att 14.210987 loss_ctc 16.592564 loss_rnnt 10.039375 hw_loss 0.140935 lr 0.00049756 rank 0
2023-02-21 23:35:17,252 DEBUG TRAIN Batch 12/900 loss 15.534084 loss_att 24.369184 loss_ctc 21.333584 loss_rnnt 12.920699 hw_loss 0.137057 lr 0.00049750 rank 7
2023-02-21 23:35:17,257 DEBUG TRAIN Batch 12/900 loss 17.046688 loss_att 22.685524 loss_ctc 24.188274 loss_rnnt 14.889920 hw_loss 0.143983 lr 0.00049752 rank 4
2023-02-21 23:35:17,259 DEBUG TRAIN Batch 12/900 loss 7.866291 loss_att 10.697395 loss_ctc 9.202799 loss_rnnt 6.988147 hw_loss 0.250730 lr 0.00049749 rank 6
2023-02-21 23:35:17,259 DEBUG TRAIN Batch 12/900 loss 16.495539 loss_att 23.260357 loss_ctc 16.874039 loss_rnnt 14.959115 hw_loss 0.249363 lr 0.00049747 rank 2
2023-02-21 23:35:17,261 DEBUG TRAIN Batch 12/900 loss 19.149025 loss_att 22.294138 loss_ctc 25.960537 loss_rnnt 17.480213 hw_loss 0.246726 lr 0.00049749 rank 3
2023-02-21 23:35:17,302 DEBUG TRAIN Batch 12/900 loss 12.169974 loss_att 16.146450 loss_ctc 13.960875 loss_rnnt 11.071823 hw_loss 0.120129 lr 0.00049754 rank 1
2023-02-21 23:36:33,017 DEBUG TRAIN Batch 12/1000 loss 10.402670 loss_att 17.359859 loss_ctc 16.059814 loss_rnnt 8.145157 hw_loss 0.209604 lr 0.00049729 rank 1
2023-02-21 23:36:33,019 DEBUG TRAIN Batch 12/1000 loss 19.213179 loss_att 24.258850 loss_ctc 20.751747 loss_rnnt 17.921284 hw_loss 0.145529 lr 0.00049725 rank 5
2023-02-21 23:36:33,021 DEBUG TRAIN Batch 12/1000 loss 30.853550 loss_att 39.622887 loss_ctc 34.463455 loss_rnnt 28.547235 hw_loss 0.133358 lr 0.00049728 rank 4
2023-02-21 23:36:33,022 DEBUG TRAIN Batch 12/1000 loss 14.823099 loss_att 16.352512 loss_ctc 18.653934 loss_rnnt 13.951585 hw_loss 0.102848 lr 0.00049731 rank 0
2023-02-21 23:36:33,022 DEBUG TRAIN Batch 12/1000 loss 22.272188 loss_att 26.393181 loss_ctc 26.479858 loss_rnnt 20.810310 hw_loss 0.143735 lr 0.00049725 rank 3
2023-02-21 23:36:33,023 DEBUG TRAIN Batch 12/1000 loss 10.540345 loss_att 14.903400 loss_ctc 11.705547 loss_rnnt 9.356255 hw_loss 0.292723 lr 0.00049725 rank 7
2023-02-21 23:36:33,023 DEBUG TRAIN Batch 12/1000 loss 18.626234 loss_att 23.523191 loss_ctc 21.709393 loss_rnnt 17.180866 hw_loss 0.102914 lr 0.00049725 rank 6
2023-02-21 23:36:33,029 DEBUG TRAIN Batch 12/1000 loss 18.301563 loss_att 23.900518 loss_ctc 25.579132 loss_rnnt 16.119534 hw_loss 0.172304 lr 0.00049722 rank 2
2023-02-21 23:37:50,234 DEBUG TRAIN Batch 12/1100 loss 18.641512 loss_att 25.295212 loss_ctc 24.509663 loss_rnnt 16.408283 hw_loss 0.225128 lr 0.00049700 rank 7
2023-02-21 23:37:50,237 DEBUG TRAIN Batch 12/1100 loss 17.303289 loss_att 17.565109 loss_ctc 19.136602 loss_rnnt 16.887306 hw_loss 0.223461 lr 0.00049707 rank 0
2023-02-21 23:37:50,240 DEBUG TRAIN Batch 12/1100 loss 29.514421 loss_att 32.101570 loss_ctc 29.461941 loss_rnnt 28.867535 hw_loss 0.255855 lr 0.00049703 rank 4
2023-02-21 23:37:50,241 DEBUG TRAIN Batch 12/1100 loss 28.078579 loss_att 34.499939 loss_ctc 32.374233 loss_rnnt 26.091717 hw_loss 0.243444 lr 0.00049700 rank 6
2023-02-21 23:37:50,244 DEBUG TRAIN Batch 12/1100 loss 22.561371 loss_att 25.959745 loss_ctc 23.228205 loss_rnnt 21.718136 hw_loss 0.139970 lr 0.00049705 rank 1
2023-02-21 23:37:50,246 DEBUG TRAIN Batch 12/1100 loss 20.287991 loss_att 26.095943 loss_ctc 25.881144 loss_rnnt 18.229858 hw_loss 0.282726 lr 0.00049700 rank 3
2023-02-21 23:37:50,246 DEBUG TRAIN Batch 12/1100 loss 19.338030 loss_att 19.356043 loss_ctc 15.841545 loss_rnnt 19.726341 hw_loss 0.139284 lr 0.00049700 rank 5
2023-02-21 23:37:50,248 DEBUG TRAIN Batch 12/1100 loss 14.403151 loss_att 19.285137 loss_ctc 19.316170 loss_rnnt 12.698116 hw_loss 0.137939 lr 0.00049698 rank 2
2023-02-21 23:39:05,709 DEBUG TRAIN Batch 12/1200 loss 12.003557 loss_att 15.540161 loss_ctc 11.382205 loss_rnnt 11.218589 hw_loss 0.300927 lr 0.00049676 rank 7
2023-02-21 23:39:05,711 DEBUG TRAIN Batch 12/1200 loss 9.917790 loss_att 12.829181 loss_ctc 13.322986 loss_rnnt 8.784313 hw_loss 0.182200 lr 0.00049682 rank 0
2023-02-21 23:39:05,712 DEBUG TRAIN Batch 12/1200 loss 14.462649 loss_att 19.233532 loss_ctc 18.450232 loss_rnnt 12.847194 hw_loss 0.243004 lr 0.00049675 rank 5
2023-02-21 23:39:05,713 DEBUG TRAIN Batch 12/1200 loss 15.976247 loss_att 19.389820 loss_ctc 22.246275 loss_rnnt 14.308124 hw_loss 0.280136 lr 0.00049679 rank 4
2023-02-21 23:39:05,717 DEBUG TRAIN Batch 12/1200 loss 23.632563 loss_att 26.679529 loss_ctc 29.088850 loss_rnnt 22.186676 hw_loss 0.204347 lr 0.00049676 rank 6
2023-02-21 23:39:05,718 DEBUG TRAIN Batch 12/1200 loss 18.988087 loss_att 21.942066 loss_ctc 24.879553 loss_rnnt 17.515144 hw_loss 0.181162 lr 0.00049673 rank 2
2023-02-21 23:39:05,725 DEBUG TRAIN Batch 12/1200 loss 15.308686 loss_att 15.185659 loss_ctc 17.675537 loss_rnnt 14.958113 hw_loss 0.111750 lr 0.00049675 rank 3
2023-02-21 23:39:05,756 DEBUG TRAIN Batch 12/1200 loss 18.604797 loss_att 21.787077 loss_ctc 22.129490 loss_rnnt 17.406790 hw_loss 0.171739 lr 0.00049680 rank 1
2023-02-21 23:40:21,664 DEBUG TRAIN Batch 12/1300 loss 14.422012 loss_att 18.346672 loss_ctc 19.039764 loss_rnnt 12.974803 hw_loss 0.087332 lr 0.00049654 rank 4
2023-02-21 23:40:21,666 DEBUG TRAIN Batch 12/1300 loss 12.237427 loss_att 12.281696 loss_ctc 14.365900 loss_rnnt 11.878680 hw_loss 0.123930 lr 0.00049651 rank 7
2023-02-21 23:40:21,666 DEBUG TRAIN Batch 12/1300 loss 16.658724 loss_att 16.642765 loss_ctc 19.154167 loss_rnnt 16.138739 hw_loss 0.357097 lr 0.00049651 rank 6
2023-02-21 23:40:21,670 DEBUG TRAIN Batch 12/1300 loss 12.492475 loss_att 20.135117 loss_ctc 12.057676 loss_rnnt 10.906849 hw_loss 0.215756 lr 0.00049651 rank 5
2023-02-21 23:40:21,670 DEBUG TRAIN Batch 12/1300 loss 12.452776 loss_att 15.308969 loss_ctc 16.150576 loss_rnnt 11.370386 hw_loss 0.033955 lr 0.00049658 rank 0
2023-02-21 23:40:21,672 DEBUG TRAIN Batch 12/1300 loss 15.472037 loss_att 19.598625 loss_ctc 17.017307 loss_rnnt 14.424759 hw_loss 0.029860 lr 0.00049656 rank 1
2023-02-21 23:40:21,679 DEBUG TRAIN Batch 12/1300 loss 23.493786 loss_att 28.592979 loss_ctc 26.400757 loss_rnnt 21.959585 hw_loss 0.237684 lr 0.00049649 rank 2
2023-02-21 23:40:21,714 DEBUG TRAIN Batch 12/1300 loss 10.875008 loss_att 16.127945 loss_ctc 17.126526 loss_rnnt 8.871643 hw_loss 0.223578 lr 0.00049651 rank 3
2023-02-21 23:41:39,810 DEBUG TRAIN Batch 12/1400 loss 15.905269 loss_att 18.986853 loss_ctc 20.589947 loss_rnnt 14.581653 hw_loss 0.155016 lr 0.00049633 rank 0
2023-02-21 23:41:39,811 DEBUG TRAIN Batch 12/1400 loss 21.460367 loss_att 29.220608 loss_ctc 30.216818 loss_rnnt 18.682293 hw_loss 0.109688 lr 0.00049626 rank 5
2023-02-21 23:41:39,811 DEBUG TRAIN Batch 12/1400 loss 5.339017 loss_att 9.709003 loss_ctc 9.111259 loss_rnnt 3.908163 hw_loss 0.101046 lr 0.00049630 rank 4
2023-02-21 23:41:39,811 DEBUG TRAIN Batch 12/1400 loss 16.623116 loss_att 25.103760 loss_ctc 18.576263 loss_rnnt 14.598793 hw_loss 0.127076 lr 0.00049631 rank 1
2023-02-21 23:41:39,818 DEBUG TRAIN Batch 12/1400 loss 21.174389 loss_att 26.268917 loss_ctc 27.135685 loss_rnnt 19.360500 hw_loss 0.000266 lr 0.00049627 rank 7
2023-02-21 23:41:39,819 DEBUG TRAIN Batch 12/1400 loss 20.073811 loss_att 20.131052 loss_ctc 20.687054 loss_rnnt 19.904520 hw_loss 0.142648 lr 0.00049624 rank 2
2023-02-21 23:41:39,819 DEBUG TRAIN Batch 12/1400 loss 3.954012 loss_att 8.798355 loss_ctc 3.740289 loss_rnnt 2.936785 hw_loss 0.144103 lr 0.00049626 rank 3
2023-02-21 23:41:39,820 DEBUG TRAIN Batch 12/1400 loss 42.748798 loss_att 40.262917 loss_ctc 45.698936 loss_rnnt 42.837608 hw_loss 0.028160 lr 0.00049627 rank 6
2023-02-21 23:42:55,541 DEBUG TRAIN Batch 12/1500 loss 17.066107 loss_att 20.040276 loss_ctc 16.993784 loss_rnnt 16.448130 hw_loss 0.061473 lr 0.00049609 rank 0
2023-02-21 23:42:55,545 DEBUG TRAIN Batch 12/1500 loss 25.803701 loss_att 39.986267 loss_ctc 34.743790 loss_rnnt 21.629475 hw_loss 0.273190 lr 0.00049603 rank 7
2023-02-21 23:42:55,546 DEBUG TRAIN Batch 12/1500 loss 29.871222 loss_att 33.453613 loss_ctc 33.595001 loss_rnnt 28.534180 hw_loss 0.232609 lr 0.00049602 rank 3
2023-02-21 23:42:55,547 DEBUG TRAIN Batch 12/1500 loss 26.886330 loss_att 31.825104 loss_ctc 31.472778 loss_rnnt 25.199974 hw_loss 0.163266 lr 0.00049602 rank 5
2023-02-21 23:42:55,548 DEBUG TRAIN Batch 12/1500 loss 13.364308 loss_att 14.974477 loss_ctc 16.264946 loss_rnnt 12.519359 hw_loss 0.255308 lr 0.00049605 rank 4
2023-02-21 23:42:55,552 DEBUG TRAIN Batch 12/1500 loss 22.863737 loss_att 29.491848 loss_ctc 30.633204 loss_rnnt 20.352180 hw_loss 0.281260 lr 0.00049600 rank 2
2023-02-21 23:42:55,552 DEBUG TRAIN Batch 12/1500 loss 17.162218 loss_att 20.432541 loss_ctc 21.765179 loss_rnnt 15.880237 hw_loss 0.026601 lr 0.00049602 rank 6
2023-02-21 23:42:55,554 DEBUG TRAIN Batch 12/1500 loss 9.407938 loss_att 18.734381 loss_ctc 9.123597 loss_rnnt 7.523371 hw_loss 0.107230 lr 0.00049607 rank 1
2023-02-21 23:44:11,273 DEBUG TRAIN Batch 12/1600 loss 10.115097 loss_att 12.227766 loss_ctc 12.046242 loss_rnnt 9.320533 hw_loss 0.214773 lr 0.00049581 rank 4
2023-02-21 23:44:11,275 DEBUG TRAIN Batch 12/1600 loss 26.880302 loss_att 29.522243 loss_ctc 29.641600 loss_rnnt 25.929058 hw_loss 0.102531 lr 0.00049578 rank 7
2023-02-21 23:44:11,276 DEBUG TRAIN Batch 12/1600 loss 9.965079 loss_att 16.797825 loss_ctc 14.426437 loss_rnnt 7.910744 hw_loss 0.174259 lr 0.00049583 rank 1
2023-02-21 23:44:11,277 DEBUG TRAIN Batch 12/1600 loss 15.524143 loss_att 17.613131 loss_ctc 21.970049 loss_rnnt 14.159750 hw_loss 0.163392 lr 0.00049578 rank 6
2023-02-21 23:44:11,278 DEBUG TRAIN Batch 12/1600 loss 33.205853 loss_att 38.022484 loss_ctc 38.447468 loss_rnnt 31.463644 hw_loss 0.150002 lr 0.00049584 rank 0
2023-02-21 23:44:11,278 DEBUG TRAIN Batch 12/1600 loss 24.284889 loss_att 28.728027 loss_ctc 24.862827 loss_rnnt 23.210087 hw_loss 0.204592 lr 0.00049578 rank 5
2023-02-21 23:44:11,280 DEBUG TRAIN Batch 12/1600 loss 23.443331 loss_att 24.417450 loss_ctc 28.956276 loss_rnnt 22.495287 hw_loss 0.034053 lr 0.00049575 rank 2
2023-02-21 23:44:11,321 DEBUG TRAIN Batch 12/1600 loss 20.433460 loss_att 22.184937 loss_ctc 24.921288 loss_rnnt 19.369940 hw_loss 0.215342 lr 0.00049578 rank 3
2023-02-21 23:45:26,251 DEBUG TRAIN Batch 12/1700 loss 14.640307 loss_att 24.226604 loss_ctc 16.458645 loss_rnnt 12.403762 hw_loss 0.144078 lr 0.00049556 rank 4
2023-02-21 23:45:26,253 DEBUG TRAIN Batch 12/1700 loss 19.383846 loss_att 24.654894 loss_ctc 18.026993 loss_rnnt 18.509018 hw_loss 0.002876 lr 0.00049560 rank 0
2023-02-21 23:45:26,254 DEBUG TRAIN Batch 12/1700 loss 19.577734 loss_att 20.759634 loss_ctc 23.200937 loss_rnnt 18.765736 hw_loss 0.173484 lr 0.00049553 rank 3
2023-02-21 23:45:26,256 DEBUG TRAIN Batch 12/1700 loss 13.786942 loss_att 15.471147 loss_ctc 16.434023 loss_rnnt 13.004290 hw_loss 0.174125 lr 0.00049554 rank 7
2023-02-21 23:45:26,259 DEBUG TRAIN Batch 12/1700 loss 11.309877 loss_att 12.753572 loss_ctc 13.051357 loss_rnnt 10.678483 hw_loss 0.207110 lr 0.00049551 rank 2
2023-02-21 23:45:26,258 DEBUG TRAIN Batch 12/1700 loss 14.779429 loss_att 22.535532 loss_ctc 16.814756 loss_rnnt 12.864154 hw_loss 0.173771 lr 0.00049554 rank 6
2023-02-21 23:45:26,259 DEBUG TRAIN Batch 12/1700 loss 15.013230 loss_att 19.788860 loss_ctc 17.621899 loss_rnnt 13.630730 hw_loss 0.149159 lr 0.00049553 rank 5
2023-02-21 23:45:26,260 DEBUG TRAIN Batch 12/1700 loss 8.508265 loss_att 13.452732 loss_ctc 7.850003 loss_rnnt 7.491202 hw_loss 0.217380 lr 0.00049558 rank 1
2023-02-21 23:46:44,224 DEBUG TRAIN Batch 12/1800 loss 23.719378 loss_att 23.299667 loss_ctc 26.562105 loss_rnnt 23.320183 hw_loss 0.195205 lr 0.00049536 rank 0
2023-02-21 23:46:44,225 DEBUG TRAIN Batch 12/1800 loss 15.507836 loss_att 20.126358 loss_ctc 18.292524 loss_rnnt 14.074106 hw_loss 0.260126 lr 0.00049532 rank 4
2023-02-21 23:46:44,225 DEBUG TRAIN Batch 12/1800 loss 14.287077 loss_att 16.287617 loss_ctc 16.060675 loss_rnnt 13.526611 hw_loss 0.232269 lr 0.00049529 rank 5
2023-02-21 23:46:44,226 DEBUG TRAIN Batch 12/1800 loss 20.174953 loss_att 22.715649 loss_ctc 28.091278 loss_rnnt 18.489014 hw_loss 0.229295 lr 0.00049527 rank 2
2023-02-21 23:46:44,227 DEBUG TRAIN Batch 12/1800 loss 15.790130 loss_att 17.772879 loss_ctc 18.693542 loss_rnnt 14.905566 hw_loss 0.189174 lr 0.00049529 rank 3
2023-02-21 23:46:44,229 DEBUG TRAIN Batch 12/1800 loss 21.057037 loss_att 23.984383 loss_ctc 28.893276 loss_rnnt 19.310936 hw_loss 0.217125 lr 0.00049529 rank 6
2023-02-21 23:46:44,230 DEBUG TRAIN Batch 12/1800 loss 14.342223 loss_att 17.975780 loss_ctc 15.414035 loss_rnnt 13.354486 hw_loss 0.221467 lr 0.00049529 rank 7
2023-02-21 23:46:44,272 DEBUG TRAIN Batch 12/1800 loss 7.153087 loss_att 12.706551 loss_ctc 11.714159 loss_rnnt 5.338720 hw_loss 0.179121 lr 0.00049534 rank 1
2023-02-21 23:48:01,330 DEBUG TRAIN Batch 12/1900 loss 23.438292 loss_att 27.128746 loss_ctc 30.929716 loss_rnnt 21.540165 hw_loss 0.302204 lr 0.00049505 rank 7
2023-02-21 23:48:01,331 DEBUG TRAIN Batch 12/1900 loss 20.752531 loss_att 19.515732 loss_ctc 24.514799 loss_rnnt 20.409513 hw_loss 0.166392 lr 0.00049512 rank 0
2023-02-21 23:48:01,335 DEBUG TRAIN Batch 12/1900 loss 20.256571 loss_att 18.771744 loss_ctc 26.847403 loss_rnnt 19.616556 hw_loss 0.109130 lr 0.00049508 rank 4
2023-02-21 23:48:01,335 DEBUG TRAIN Batch 12/1900 loss 11.647038 loss_att 10.997146 loss_ctc 15.028093 loss_rnnt 11.192372 hw_loss 0.250940 lr 0.00049505 rank 5
2023-02-21 23:48:01,337 DEBUG TRAIN Batch 12/1900 loss 12.064679 loss_att 12.502608 loss_ctc 13.553825 loss_rnnt 11.639478 hw_loss 0.260741 lr 0.00049503 rank 2
2023-02-21 23:48:01,341 DEBUG TRAIN Batch 12/1900 loss 18.278429 loss_att 22.092144 loss_ctc 22.727863 loss_rnnt 16.803789 hw_loss 0.222449 lr 0.00049505 rank 6
2023-02-21 23:48:01,344 DEBUG TRAIN Batch 12/1900 loss 10.993698 loss_att 12.250620 loss_ctc 15.816772 loss_rnnt 9.955173 hw_loss 0.270121 lr 0.00049510 rank 1
2023-02-21 23:48:01,383 DEBUG TRAIN Batch 12/1900 loss 20.653095 loss_att 29.578451 loss_ctc 26.272833 loss_rnnt 18.048275 hw_loss 0.132096 lr 0.00049505 rank 3
2023-02-21 23:49:17,227 DEBUG TRAIN Batch 12/2000 loss 17.977791 loss_att 23.161617 loss_ctc 20.255177 loss_rnnt 16.556328 hw_loss 0.151963 lr 0.00049484 rank 4
2023-02-21 23:49:17,228 DEBUG TRAIN Batch 12/2000 loss 22.028574 loss_att 28.050880 loss_ctc 19.817169 loss_rnnt 21.062422 hw_loss 0.106023 lr 0.00049481 rank 7
2023-02-21 23:49:17,231 DEBUG TRAIN Batch 12/2000 loss 22.160191 loss_att 27.484631 loss_ctc 28.574362 loss_rnnt 20.182085 hw_loss 0.108737 lr 0.00049480 rank 3
2023-02-21 23:49:17,233 DEBUG TRAIN Batch 12/2000 loss 12.732921 loss_att 19.216032 loss_ctc 16.035126 loss_rnnt 10.852062 hw_loss 0.269892 lr 0.00049487 rank 0
2023-02-21 23:49:17,236 DEBUG TRAIN Batch 12/2000 loss 22.615892 loss_att 21.377026 loss_ctc 20.983322 loss_rnnt 22.983770 hw_loss 0.182947 lr 0.00049485 rank 1
2023-02-21 23:49:17,236 DEBUG TRAIN Batch 12/2000 loss 28.211742 loss_att 30.742191 loss_ctc 30.128607 loss_rnnt 27.340130 hw_loss 0.206135 lr 0.00049480 rank 5
2023-02-21 23:49:17,237 DEBUG TRAIN Batch 12/2000 loss 16.483057 loss_att 23.846172 loss_ctc 18.896454 loss_rnnt 14.652260 hw_loss 0.068225 lr 0.00049481 rank 6
2023-02-21 23:49:17,239 DEBUG TRAIN Batch 12/2000 loss 12.774546 loss_att 16.922482 loss_ctc 15.329275 loss_rnnt 11.496965 hw_loss 0.201303 lr 0.00049478 rank 2
2023-02-21 23:50:33,389 DEBUG TRAIN Batch 12/2100 loss 9.183172 loss_att 12.216995 loss_ctc 8.544600 loss_rnnt 8.560325 hw_loss 0.189800 lr 0.00049456 rank 5
2023-02-21 23:50:33,392 DEBUG TRAIN Batch 12/2100 loss 22.673151 loss_att 26.429554 loss_ctc 31.040731 loss_rnnt 20.663477 hw_loss 0.267589 lr 0.00049456 rank 6
2023-02-21 23:50:33,394 DEBUG TRAIN Batch 12/2100 loss 4.972291 loss_att 8.063377 loss_ctc 5.297456 loss_rnnt 4.295336 hw_loss 0.028840 lr 0.00049457 rank 7
2023-02-21 23:50:33,395 DEBUG TRAIN Batch 12/2100 loss 9.472987 loss_att 11.202513 loss_ctc 10.116349 loss_rnnt 8.963439 hw_loss 0.145991 lr 0.00049459 rank 4
2023-02-21 23:50:33,397 DEBUG TRAIN Batch 12/2100 loss 30.225269 loss_att 32.334129 loss_ctc 32.818157 loss_rnnt 29.346874 hw_loss 0.207949 lr 0.00049454 rank 2
2023-02-21 23:50:33,398 DEBUG TRAIN Batch 12/2100 loss 11.714169 loss_att 15.054261 loss_ctc 15.454508 loss_rnnt 10.459848 hw_loss 0.164229 lr 0.00049463 rank 0
2023-02-21 23:50:33,398 DEBUG TRAIN Batch 12/2100 loss 14.976123 loss_att 21.401897 loss_ctc 14.470381 loss_rnnt 13.684715 hw_loss 0.138162 lr 0.00049461 rank 1
2023-02-21 23:50:33,443 DEBUG TRAIN Batch 12/2100 loss 17.219759 loss_att 21.586300 loss_ctc 18.974213 loss_rnnt 15.964472 hw_loss 0.277594 lr 0.00049456 rank 3
2023-02-21 23:51:49,206 DEBUG TRAIN Batch 12/2200 loss 15.798307 loss_att 19.694366 loss_ctc 19.838333 loss_rnnt 14.403458 hw_loss 0.144315 lr 0.00049435 rank 4
2023-02-21 23:51:49,209 DEBUG TRAIN Batch 12/2200 loss 11.310390 loss_att 12.459501 loss_ctc 14.604707 loss_rnnt 10.534204 hw_loss 0.200853 lr 0.00049437 rank 1
2023-02-21 23:51:49,210 DEBUG TRAIN Batch 12/2200 loss 9.604345 loss_att 13.612757 loss_ctc 11.060949 loss_rnnt 8.555513 hw_loss 0.099253 lr 0.00049432 rank 5
2023-02-21 23:51:49,211 DEBUG TRAIN Batch 12/2200 loss 8.541583 loss_att 16.328859 loss_ctc 11.334980 loss_rnnt 6.611631 hw_loss 0.000084 lr 0.00049439 rank 0
2023-02-21 23:51:49,213 DEBUG TRAIN Batch 12/2200 loss 14.411002 loss_att 18.385958 loss_ctc 14.251785 loss_rnnt 13.591063 hw_loss 0.086585 lr 0.00049432 rank 6
2023-02-21 23:51:49,217 DEBUG TRAIN Batch 12/2200 loss 13.539397 loss_att 16.879267 loss_ctc 16.061764 loss_rnnt 12.496698 hw_loss 0.072016 lr 0.00049432 rank 3
2023-02-21 23:51:49,218 DEBUG TRAIN Batch 12/2200 loss 17.005854 loss_att 19.320108 loss_ctc 16.703272 loss_rnnt 16.490875 hw_loss 0.173381 lr 0.00049430 rank 2
2023-02-21 23:51:49,217 DEBUG TRAIN Batch 12/2200 loss 19.976160 loss_att 23.687990 loss_ctc 30.106674 loss_rnnt 17.869184 hw_loss 0.026019 lr 0.00049433 rank 7
2023-02-21 23:53:03,961 DEBUG TRAIN Batch 12/2300 loss 15.999923 loss_att 20.947033 loss_ctc 21.851368 loss_rnnt 14.172493 hw_loss 0.108403 lr 0.00049415 rank 0
2023-02-21 23:53:03,965 DEBUG TRAIN Batch 12/2300 loss 8.309246 loss_att 12.251241 loss_ctc 12.863719 loss_rnnt 6.828754 hw_loss 0.159053 lr 0.00049406 rank 2
2023-02-21 23:53:03,965 DEBUG TRAIN Batch 12/2300 loss 16.118986 loss_att 19.721422 loss_ctc 21.206184 loss_rnnt 14.649442 hw_loss 0.132681 lr 0.00049411 rank 4
2023-02-21 23:53:03,965 DEBUG TRAIN Batch 12/2300 loss 22.667509 loss_att 29.469885 loss_ctc 24.673914 loss_rnnt 20.930458 hw_loss 0.204478 lr 0.00049408 rank 5
2023-02-21 23:53:03,967 DEBUG TRAIN Batch 12/2300 loss 13.746878 loss_att 17.658043 loss_ctc 24.991488 loss_rnnt 11.393780 hw_loss 0.134220 lr 0.00049408 rank 7
2023-02-21 23:53:03,969 DEBUG TRAIN Batch 12/2300 loss 24.133865 loss_att 29.005001 loss_ctc 26.511902 loss_rnnt 22.792763 hw_loss 0.093385 lr 0.00049408 rank 6
2023-02-21 23:53:03,970 DEBUG TRAIN Batch 12/2300 loss 25.719250 loss_att 27.709356 loss_ctc 29.295803 loss_rnnt 24.727646 hw_loss 0.218831 lr 0.00049413 rank 1
2023-02-21 23:53:03,971 DEBUG TRAIN Batch 12/2300 loss 22.152540 loss_att 25.091745 loss_ctc 28.548370 loss_rnnt 20.619251 hw_loss 0.173758 lr 0.00049408 rank 3
2023-02-21 23:54:19,891 DEBUG TRAIN Batch 12/2400 loss 16.693638 loss_att 19.227821 loss_ctc 20.142124 loss_rnnt 15.624204 hw_loss 0.192749 lr 0.00049384 rank 5
2023-02-21 23:54:19,893 DEBUG TRAIN Batch 12/2400 loss 14.580973 loss_att 15.507236 loss_ctc 19.143497 loss_rnnt 13.748686 hw_loss 0.072560 lr 0.00049384 rank 7
2023-02-21 23:54:19,893 DEBUG TRAIN Batch 12/2400 loss 6.618799 loss_att 9.398050 loss_ctc 7.478428 loss_rnnt 5.795080 hw_loss 0.287347 lr 0.00049387 rank 4
2023-02-21 23:54:19,894 DEBUG TRAIN Batch 12/2400 loss 18.570366 loss_att 25.790184 loss_ctc 24.032700 loss_rnnt 16.316813 hw_loss 0.152397 lr 0.00049391 rank 0
2023-02-21 23:54:19,896 DEBUG TRAIN Batch 12/2400 loss 24.152895 loss_att 30.168205 loss_ctc 28.664551 loss_rnnt 22.232052 hw_loss 0.217928 lr 0.00049389 rank 1
2023-02-21 23:54:19,901 DEBUG TRAIN Batch 12/2400 loss 13.897815 loss_att 17.346657 loss_ctc 17.235502 loss_rnnt 12.696200 hw_loss 0.125292 lr 0.00049382 rank 2
2023-02-21 23:54:19,901 DEBUG TRAIN Batch 12/2400 loss 16.897724 loss_att 20.974445 loss_ctc 25.274168 loss_rnnt 14.889110 hw_loss 0.143268 lr 0.00049384 rank 3
2023-02-21 23:54:19,940 DEBUG TRAIN Batch 12/2400 loss 22.267277 loss_att 26.952084 loss_ctc 26.573385 loss_rnnt 20.740553 hw_loss 0.029278 lr 0.00049384 rank 6
2023-02-21 23:55:38,750 DEBUG TRAIN Batch 12/2500 loss 14.419887 loss_att 17.445961 loss_ctc 19.034718 loss_rnnt 13.110814 hw_loss 0.166022 lr 0.00049360 rank 5
2023-02-21 23:55:38,750 DEBUG TRAIN Batch 12/2500 loss 14.169751 loss_att 13.770440 loss_ctc 16.673985 loss_rnnt 13.740364 hw_loss 0.328784 lr 0.00049360 rank 7
2023-02-21 23:55:38,752 DEBUG TRAIN Batch 12/2500 loss 9.345454 loss_att 9.963984 loss_ctc 12.562696 loss_rnnt 8.629497 hw_loss 0.306163 lr 0.00049363 rank 4
2023-02-21 23:55:38,754 DEBUG TRAIN Batch 12/2500 loss 22.342249 loss_att 25.279209 loss_ctc 27.403122 loss_rnnt 20.970261 hw_loss 0.205897 lr 0.00049366 rank 0
2023-02-21 23:55:38,756 DEBUG TRAIN Batch 12/2500 loss 16.107340 loss_att 18.623533 loss_ctc 21.565971 loss_rnnt 14.774931 hw_loss 0.190039 lr 0.00049360 rank 6
2023-02-21 23:55:38,756 DEBUG TRAIN Batch 12/2500 loss 12.693149 loss_att 15.690563 loss_ctc 18.458735 loss_rnnt 11.257775 hw_loss 0.125897 lr 0.00049365 rank 1
2023-02-21 23:55:38,764 DEBUG TRAIN Batch 12/2500 loss 19.939714 loss_att 18.681759 loss_ctc 23.854294 loss_rnnt 19.504944 hw_loss 0.308283 lr 0.00049358 rank 2
2023-02-21 23:55:38,805 DEBUG TRAIN Batch 12/2500 loss 14.424257 loss_att 21.109142 loss_ctc 21.922134 loss_rnnt 11.879429 hw_loss 0.390251 lr 0.00049360 rank 3
2023-02-21 23:56:54,462 DEBUG TRAIN Batch 12/2600 loss 12.855193 loss_att 18.821445 loss_ctc 15.462326 loss_rnnt 11.214030 hw_loss 0.188053 lr 0.00049336 rank 7
2023-02-21 23:56:54,464 DEBUG TRAIN Batch 12/2600 loss 13.102201 loss_att 13.792408 loss_ctc 13.218870 loss_rnnt 12.818220 hw_loss 0.244473 lr 0.00049336 rank 3
2023-02-21 23:56:54,466 DEBUG TRAIN Batch 12/2600 loss 11.085810 loss_att 19.824465 loss_ctc 17.900543 loss_rnnt 8.264882 hw_loss 0.308560 lr 0.00049336 rank 5
2023-02-21 23:56:54,465 DEBUG TRAIN Batch 12/2600 loss 30.251772 loss_att 34.673172 loss_ctc 32.005600 loss_rnnt 29.104223 hw_loss 0.055173 lr 0.00049342 rank 0
2023-02-21 23:56:54,467 DEBUG TRAIN Batch 12/2600 loss 20.287952 loss_att 22.881315 loss_ctc 26.155548 loss_rnnt 18.832508 hw_loss 0.289543 lr 0.00049336 rank 6
2023-02-21 23:56:54,468 DEBUG TRAIN Batch 12/2600 loss 27.605150 loss_att 30.618179 loss_ctc 38.919731 loss_rnnt 25.392485 hw_loss 0.190217 lr 0.00049334 rank 2
2023-02-21 23:56:54,470 DEBUG TRAIN Batch 12/2600 loss 23.625456 loss_att 28.719240 loss_ctc 32.816093 loss_rnnt 21.263699 hw_loss 0.220468 lr 0.00049339 rank 4
2023-02-21 23:56:54,474 DEBUG TRAIN Batch 12/2600 loss 7.037446 loss_att 12.893961 loss_ctc 6.533404 loss_rnnt 5.827270 hw_loss 0.198897 lr 0.00049341 rank 1
2023-02-21 23:58:09,107 DEBUG TRAIN Batch 12/2700 loss 15.638913 loss_att 21.472198 loss_ctc 15.700460 loss_rnnt 14.379686 hw_loss 0.158180 lr 0.00049312 rank 5
2023-02-21 23:58:09,110 DEBUG TRAIN Batch 12/2700 loss 18.871084 loss_att 22.511274 loss_ctc 21.234734 loss_rnnt 17.743423 hw_loss 0.158380 lr 0.00049317 rank 1
2023-02-21 23:58:09,110 DEBUG TRAIN Batch 12/2700 loss 21.777447 loss_att 22.544338 loss_ctc 21.141195 loss_rnnt 21.677954 hw_loss 0.058028 lr 0.00049312 rank 7
2023-02-21 23:58:09,111 DEBUG TRAIN Batch 12/2700 loss 15.369268 loss_att 18.005703 loss_ctc 19.205540 loss_rnnt 14.242659 hw_loss 0.164664 lr 0.00049318 rank 0
2023-02-21 23:58:09,112 DEBUG TRAIN Batch 12/2700 loss 13.928029 loss_att 19.433464 loss_ctc 17.454243 loss_rnnt 12.337158 hw_loss 0.036789 lr 0.00049315 rank 4
2023-02-21 23:58:09,113 DEBUG TRAIN Batch 12/2700 loss 16.234283 loss_att 17.396763 loss_ctc 18.380775 loss_rnnt 15.655886 hw_loss 0.111944 lr 0.00049312 rank 3
2023-02-21 23:58:09,114 DEBUG TRAIN Batch 12/2700 loss 17.043146 loss_att 21.767836 loss_ctc 21.749855 loss_rnnt 15.399633 hw_loss 0.133151 lr 0.00049312 rank 6
2023-02-21 23:58:09,117 DEBUG TRAIN Batch 12/2700 loss 11.067459 loss_att 20.309181 loss_ctc 13.825084 loss_rnnt 8.796827 hw_loss 0.102383 lr 0.00049310 rank 2
2023-02-21 23:59:25,684 DEBUG TRAIN Batch 12/2800 loss 16.616177 loss_att 21.900028 loss_ctc 24.101173 loss_rnnt 14.523707 hw_loss 0.070687 lr 0.00049291 rank 4
2023-02-21 23:59:25,687 DEBUG TRAIN Batch 12/2800 loss 20.053808 loss_att 22.291670 loss_ctc 20.610205 loss_rnnt 19.420477 hw_loss 0.209202 lr 0.00049288 rank 3
2023-02-21 23:59:25,688 DEBUG TRAIN Batch 12/2800 loss 21.294905 loss_att 25.027082 loss_ctc 25.526632 loss_rnnt 19.855013 hw_loss 0.242294 lr 0.00049294 rank 0
2023-02-21 23:59:25,688 DEBUG TRAIN Batch 12/2800 loss 10.190410 loss_att 17.599031 loss_ctc 11.428392 loss_rnnt 8.459222 hw_loss 0.158245 lr 0.00049288 rank 7
2023-02-21 23:59:25,689 DEBUG TRAIN Batch 12/2800 loss 9.910403 loss_att 13.667129 loss_ctc 9.814651 loss_rnnt 9.089217 hw_loss 0.154888 lr 0.00049288 rank 6
2023-02-21 23:59:25,690 DEBUG TRAIN Batch 12/2800 loss 4.398137 loss_att 8.295677 loss_ctc 4.523499 loss_rnnt 3.543636 hw_loss 0.109273 lr 0.00049288 rank 5
2023-02-21 23:59:25,693 DEBUG TRAIN Batch 12/2800 loss 26.100628 loss_att 32.029621 loss_ctc 32.175835 loss_rnnt 24.055542 hw_loss 0.092366 lr 0.00049293 rank 1
2023-02-21 23:59:25,697 DEBUG TRAIN Batch 12/2800 loss 13.660919 loss_att 17.633375 loss_ctc 14.465662 loss_rnnt 12.692354 hw_loss 0.125201 lr 0.00049286 rank 2
2023-02-22 00:00:42,343 DEBUG TRAIN Batch 12/2900 loss 13.028835 loss_att 16.701118 loss_ctc 18.537962 loss_rnnt 11.484822 hw_loss 0.140636 lr 0.00049271 rank 0
2023-02-22 00:00:42,343 DEBUG TRAIN Batch 12/2900 loss 11.772436 loss_att 17.467808 loss_ctc 18.027948 loss_rnnt 9.721716 hw_loss 0.145457 lr 0.00049267 rank 4
2023-02-22 00:00:42,344 DEBUG TRAIN Batch 12/2900 loss 9.718402 loss_att 13.677206 loss_ctc 13.780243 loss_rnnt 8.353692 hw_loss 0.058821 lr 0.00049264 rank 6
2023-02-22 00:00:42,345 DEBUG TRAIN Batch 12/2900 loss 22.519829 loss_att 24.751402 loss_ctc 27.938799 loss_rnnt 21.277443 hw_loss 0.137892 lr 0.00049264 rank 5
2023-02-22 00:00:42,347 DEBUG TRAIN Batch 12/2900 loss 27.002815 loss_att 37.752689 loss_ctc 33.797054 loss_rnnt 23.887348 hw_loss 0.111734 lr 0.00049262 rank 2
2023-02-22 00:00:42,347 DEBUG TRAIN Batch 12/2900 loss 15.955770 loss_att 20.196653 loss_ctc 19.547646 loss_rnnt 14.524656 hw_loss 0.195040 lr 0.00049264 rank 7
2023-02-22 00:00:42,352 DEBUG TRAIN Batch 12/2900 loss 12.359478 loss_att 18.532637 loss_ctc 12.392298 loss_rnnt 10.966030 hw_loss 0.289574 lr 0.00049264 rank 3
2023-02-22 00:00:42,353 DEBUG TRAIN Batch 12/2900 loss 22.585979 loss_att 25.060299 loss_ctc 27.396923 loss_rnnt 21.332401 hw_loss 0.219857 lr 0.00049269 rank 1
2023-02-22 00:01:58,173 DEBUG TRAIN Batch 12/3000 loss 12.892460 loss_att 17.618477 loss_ctc 18.646931 loss_rnnt 11.102074 hw_loss 0.146101 lr 0.00049247 rank 0
2023-02-22 00:01:58,173 DEBUG TRAIN Batch 12/3000 loss 25.069260 loss_att 24.022442 loss_ctc 25.790518 loss_rnnt 25.106367 hw_loss 0.142664 lr 0.00049243 rank 4
2023-02-22 00:01:58,175 DEBUG TRAIN Batch 12/3000 loss 18.790825 loss_att 21.936792 loss_ctc 19.646820 loss_rnnt 17.958578 hw_loss 0.166726 lr 0.00049240 rank 5
2023-02-22 00:01:58,177 DEBUG TRAIN Batch 12/3000 loss 18.297707 loss_att 24.378479 loss_ctc 22.385235 loss_rnnt 16.442902 hw_loss 0.175585 lr 0.00049240 rank 7
2023-02-22 00:01:58,178 DEBUG TRAIN Batch 12/3000 loss 19.133520 loss_att 24.099180 loss_ctc 25.734575 loss_rnnt 17.178864 hw_loss 0.152594 lr 0.00049240 rank 6
2023-02-22 00:01:58,178 DEBUG TRAIN Batch 12/3000 loss 15.908319 loss_att 18.030991 loss_ctc 20.129827 loss_rnnt 14.817389 hw_loss 0.194113 lr 0.00049240 rank 3
2023-02-22 00:01:58,182 DEBUG TRAIN Batch 12/3000 loss 12.395033 loss_att 16.401455 loss_ctc 15.550258 loss_rnnt 11.068359 hw_loss 0.196296 lr 0.00049238 rank 2
2023-02-22 00:01:58,216 DEBUG TRAIN Batch 12/3000 loss 21.993904 loss_att 25.130116 loss_ctc 22.366535 loss_rnnt 21.221357 hw_loss 0.179287 lr 0.00049245 rank 1
2023-02-22 00:03:15,571 DEBUG TRAIN Batch 12/3100 loss 19.604578 loss_att 20.567341 loss_ctc 21.423883 loss_rnnt 19.113102 hw_loss 0.105653 lr 0.00049216 rank 5
2023-02-22 00:03:15,572 DEBUG TRAIN Batch 12/3100 loss 11.728582 loss_att 15.409685 loss_ctc 11.983345 loss_rnnt 10.862125 hw_loss 0.180503 lr 0.00049223 rank 0
2023-02-22 00:03:15,574 DEBUG TRAIN Batch 12/3100 loss 36.992359 loss_att 35.567963 loss_ctc 39.848679 loss_rnnt 36.791451 hw_loss 0.196774 lr 0.00049216 rank 6
2023-02-22 00:03:15,575 DEBUG TRAIN Batch 12/3100 loss 13.582947 loss_att 17.061432 loss_ctc 17.644566 loss_rnnt 12.245096 hw_loss 0.188631 lr 0.00049219 rank 4
2023-02-22 00:03:15,576 DEBUG TRAIN Batch 12/3100 loss 8.504347 loss_att 11.474660 loss_ctc 10.815417 loss_rnnt 7.548773 hw_loss 0.100064 lr 0.00049221 rank 1
2023-02-22 00:03:15,576 DEBUG TRAIN Batch 12/3100 loss 16.301031 loss_att 25.793581 loss_ctc 19.178959 loss_rnnt 13.928177 hw_loss 0.169912 lr 0.00049216 rank 3
2023-02-22 00:03:15,577 DEBUG TRAIN Batch 12/3100 loss 11.357881 loss_att 12.862953 loss_ctc 15.546860 loss_rnnt 10.368963 hw_loss 0.242571 lr 0.00049214 rank 2
2023-02-22 00:03:15,577 DEBUG TRAIN Batch 12/3100 loss 17.980570 loss_att 19.360863 loss_ctc 18.042006 loss_rnnt 17.553524 hw_loss 0.267746 lr 0.00049217 rank 7
2023-02-22 00:04:35,156 DEBUG TRAIN Batch 12/3200 loss 12.793749 loss_att 13.237671 loss_ctc 16.897486 loss_rnnt 12.028063 hw_loss 0.243253 lr 0.00049193 rank 7
2023-02-22 00:04:35,157 DEBUG TRAIN Batch 12/3200 loss 23.299822 loss_att 30.972229 loss_ctc 22.983852 loss_rnnt 21.720112 hw_loss 0.163792 lr 0.00049192 rank 5
2023-02-22 00:04:35,158 DEBUG TRAIN Batch 12/3200 loss 14.247216 loss_att 16.346581 loss_ctc 18.611271 loss_rnnt 13.120130 hw_loss 0.235012 lr 0.00049199 rank 0
2023-02-22 00:04:35,158 DEBUG TRAIN Batch 12/3200 loss 15.237538 loss_att 20.571789 loss_ctc 19.008308 loss_rnnt 13.607566 hw_loss 0.113160 lr 0.00049195 rank 4
2023-02-22 00:04:35,161 DEBUG TRAIN Batch 12/3200 loss 19.234756 loss_att 30.191475 loss_ctc 23.147848 loss_rnnt 16.476131 hw_loss 0.085378 lr 0.00049192 rank 3
2023-02-22 00:04:35,170 DEBUG TRAIN Batch 12/3200 loss 14.478686 loss_att 15.507174 loss_ctc 18.160507 loss_rnnt 13.679991 hw_loss 0.191419 lr 0.00049197 rank 1
2023-02-22 00:04:35,170 DEBUG TRAIN Batch 12/3200 loss 5.373141 loss_att 10.884345 loss_ctc 6.927244 loss_rnnt 4.033089 hw_loss 0.057371 lr 0.00049190 rank 2
2023-02-22 00:04:35,213 DEBUG TRAIN Batch 12/3200 loss 12.937900 loss_att 14.918169 loss_ctc 14.651587 loss_rnnt 12.233756 hw_loss 0.149247 lr 0.00049192 rank 6
2023-02-22 00:05:50,902 DEBUG TRAIN Batch 12/3300 loss 23.451128 loss_att 23.805021 loss_ctc 29.741844 loss_rnnt 22.464294 hw_loss 0.144925 lr 0.00049175 rank 0
2023-02-22 00:05:50,908 DEBUG TRAIN Batch 12/3300 loss 8.791927 loss_att 13.851532 loss_ctc 10.615606 loss_rnnt 7.436355 hw_loss 0.188426 lr 0.00049168 rank 5
2023-02-22 00:05:50,909 DEBUG TRAIN Batch 12/3300 loss 11.866300 loss_att 17.991545 loss_ctc 15.325064 loss_rnnt 10.100980 hw_loss 0.148318 lr 0.00049169 rank 7
2023-02-22 00:05:50,909 DEBUG TRAIN Batch 12/3300 loss 17.152447 loss_att 20.119541 loss_ctc 20.879589 loss_rnnt 15.991138 hw_loss 0.133002 lr 0.00049173 rank 1
2023-02-22 00:05:50,910 DEBUG TRAIN Batch 12/3300 loss 16.077566 loss_att 14.621109 loss_ctc 18.816288 loss_rnnt 15.823929 hw_loss 0.337062 lr 0.00049169 rank 6
2023-02-22 00:05:50,910 DEBUG TRAIN Batch 12/3300 loss 6.310802 loss_att 11.154931 loss_ctc 8.743949 loss_rnnt 4.928995 hw_loss 0.166055 lr 0.00049172 rank 4
2023-02-22 00:05:50,913 DEBUG TRAIN Batch 12/3300 loss 15.596803 loss_att 18.014366 loss_ctc 20.979708 loss_rnnt 14.315649 hw_loss 0.149850 lr 0.00049168 rank 3
2023-02-22 00:05:50,913 DEBUG TRAIN Batch 12/3300 loss 14.303952 loss_att 19.366175 loss_ctc 19.768719 loss_rnnt 12.477303 hw_loss 0.160445 lr 0.00049166 rank 2
2023-02-22 00:07:04,927 DEBUG TRAIN Batch 12/3400 loss 20.783239 loss_att 28.144806 loss_ctc 28.138769 loss_rnnt 18.283674 hw_loss 0.087215 lr 0.00049151 rank 0
2023-02-22 00:07:04,929 DEBUG TRAIN Batch 12/3400 loss 12.376300 loss_att 21.197115 loss_ctc 13.291839 loss_rnnt 10.462074 hw_loss 0.052482 lr 0.00049145 rank 6
2023-02-22 00:07:04,930 DEBUG TRAIN Batch 12/3400 loss 12.833138 loss_att 19.384161 loss_ctc 19.575890 loss_rnnt 10.557934 hw_loss 0.123687 lr 0.00049145 rank 5
2023-02-22 00:07:04,930 DEBUG TRAIN Batch 12/3400 loss 22.870041 loss_att 26.574657 loss_ctc 25.099600 loss_rnnt 21.725922 hw_loss 0.198604 lr 0.00049145 rank 7
2023-02-22 00:07:04,932 DEBUG TRAIN Batch 12/3400 loss 15.760431 loss_att 19.074469 loss_ctc 18.514019 loss_rnnt 14.590762 hw_loss 0.261969 lr 0.00049149 rank 1
2023-02-22 00:07:04,932 DEBUG TRAIN Batch 12/3400 loss 9.398615 loss_att 12.849644 loss_ctc 7.628818 loss_rnnt 8.870062 hw_loss 0.139350 lr 0.00049148 rank 4
2023-02-22 00:07:04,935 DEBUG TRAIN Batch 12/3400 loss 18.106829 loss_att 21.755270 loss_ctc 21.510857 loss_rnnt 16.856693 hw_loss 0.124829 lr 0.00049145 rank 3
2023-02-22 00:07:04,935 DEBUG TRAIN Batch 12/3400 loss 14.804818 loss_att 17.933235 loss_ctc 18.182133 loss_rnnt 13.656006 hw_loss 0.136538 lr 0.00049143 rank 2
2023-02-22 00:08:20,175 DEBUG TRAIN Batch 12/3500 loss 16.006941 loss_att 23.650215 loss_ctc 20.957592 loss_rnnt 13.680672 hw_loss 0.257863 lr 0.00049124 rank 4
2023-02-22 00:08:20,179 DEBUG TRAIN Batch 12/3500 loss 16.444981 loss_att 18.621845 loss_ctc 22.017017 loss_rnnt 15.194166 hw_loss 0.135948 lr 0.00049121 rank 6
2023-02-22 00:08:20,181 DEBUG TRAIN Batch 12/3500 loss 14.970115 loss_att 16.972965 loss_ctc 15.261421 loss_rnnt 14.412370 hw_loss 0.221876 lr 0.00049121 rank 5
2023-02-22 00:08:20,182 DEBUG TRAIN Batch 12/3500 loss 16.831379 loss_att 17.772303 loss_ctc 19.667128 loss_rnnt 16.186758 hw_loss 0.146881 lr 0.00049128 rank 0
2023-02-22 00:08:20,184 DEBUG TRAIN Batch 12/3500 loss 15.162635 loss_att 22.662830 loss_ctc 16.839033 loss_rnnt 13.406570 hw_loss 0.060947 lr 0.00049126 rank 1
2023-02-22 00:08:20,184 DEBUG TRAIN Batch 12/3500 loss 22.653036 loss_att 27.566872 loss_ctc 34.410210 loss_rnnt 20.027351 hw_loss 0.141177 lr 0.00049119 rank 2
2023-02-22 00:08:20,186 DEBUG TRAIN Batch 12/3500 loss 6.715663 loss_att 9.312314 loss_ctc 8.555056 loss_rnnt 5.837012 hw_loss 0.213880 lr 0.00049121 rank 7
2023-02-22 00:08:20,190 DEBUG TRAIN Batch 12/3500 loss 14.000338 loss_att 18.473858 loss_ctc 16.700691 loss_rnnt 12.682240 hw_loss 0.118775 lr 0.00049121 rank 3
2023-02-22 00:09:36,991 DEBUG TRAIN Batch 12/3600 loss 15.477247 loss_att 18.314327 loss_ctc 19.091499 loss_rnnt 14.346268 hw_loss 0.153116 lr 0.00049097 rank 5
2023-02-22 00:09:36,994 DEBUG TRAIN Batch 12/3600 loss 18.312147 loss_att 19.353882 loss_ctc 21.061138 loss_rnnt 17.632256 hw_loss 0.196899 lr 0.00049100 rank 4
2023-02-22 00:09:36,997 DEBUG TRAIN Batch 12/3600 loss 11.481653 loss_att 15.904871 loss_ctc 17.417500 loss_rnnt 9.719329 hw_loss 0.161690 lr 0.00049098 rank 7
2023-02-22 00:09:36,999 DEBUG TRAIN Batch 12/3600 loss 16.365662 loss_att 18.231516 loss_ctc 18.198368 loss_rnnt 15.659863 hw_loss 0.165502 lr 0.00049102 rank 1
2023-02-22 00:09:37,000 DEBUG TRAIN Batch 12/3600 loss 19.508427 loss_att 21.331303 loss_ctc 22.077091 loss_rnnt 18.765726 hw_loss 0.066820 lr 0.00049104 rank 0
2023-02-22 00:09:37,002 DEBUG TRAIN Batch 12/3600 loss 20.636871 loss_att 25.364222 loss_ctc 23.984695 loss_rnnt 19.118843 hw_loss 0.236589 lr 0.00049095 rank 2
2023-02-22 00:09:37,003 DEBUG TRAIN Batch 12/3600 loss 15.208345 loss_att 17.820950 loss_ctc 17.507689 loss_rnnt 14.312845 hw_loss 0.124501 lr 0.00049097 rank 3
2023-02-22 00:09:37,045 DEBUG TRAIN Batch 12/3600 loss 19.102905 loss_att 27.583811 loss_ctc 23.276684 loss_rnnt 16.781481 hw_loss 0.128884 lr 0.00049098 rank 6
2023-02-22 00:10:53,521 DEBUG TRAIN Batch 12/3700 loss 14.703711 loss_att 23.451714 loss_ctc 20.340435 loss_rnnt 12.066031 hw_loss 0.255970 lr 0.00049074 rank 7
2023-02-22 00:10:53,524 DEBUG TRAIN Batch 12/3700 loss 14.913411 loss_att 19.571808 loss_ctc 20.598995 loss_rnnt 13.149126 hw_loss 0.139738 lr 0.00049078 rank 1
2023-02-22 00:10:53,525 DEBUG TRAIN Batch 12/3700 loss 13.556852 loss_att 16.977390 loss_ctc 18.109556 loss_rnnt 12.109502 hw_loss 0.292902 lr 0.00049072 rank 2
2023-02-22 00:10:53,527 DEBUG TRAIN Batch 12/3700 loss 11.304221 loss_att 16.719950 loss_ctc 17.434603 loss_rnnt 9.357461 hw_loss 0.086678 lr 0.00049080 rank 0
2023-02-22 00:10:53,530 DEBUG TRAIN Batch 12/3700 loss 12.802201 loss_att 14.535329 loss_ctc 18.809381 loss_rnnt 11.550287 hw_loss 0.195618 lr 0.00049077 rank 4
2023-02-22 00:10:53,531 DEBUG TRAIN Batch 12/3700 loss 15.043195 loss_att 17.875511 loss_ctc 16.469767 loss_rnnt 14.203087 hw_loss 0.156441 lr 0.00049074 rank 5
2023-02-22 00:10:53,532 DEBUG TRAIN Batch 12/3700 loss 13.884148 loss_att 14.683922 loss_ctc 17.153854 loss_rnnt 13.171228 hw_loss 0.219380 lr 0.00049074 rank 3
2023-02-22 00:10:53,534 DEBUG TRAIN Batch 12/3700 loss 7.520600 loss_att 10.536013 loss_ctc 10.987507 loss_rnnt 6.370209 hw_loss 0.159478 lr 0.00049074 rank 6
2023-02-22 00:12:07,497 DEBUG TRAIN Batch 12/3800 loss 15.138560 loss_att 15.564399 loss_ctc 18.211584 loss_rnnt 14.541974 hw_loss 0.190654 lr 0.00049053 rank 4
2023-02-22 00:12:07,499 DEBUG TRAIN Batch 12/3800 loss 17.192192 loss_att 16.331566 loss_ctc 19.077139 loss_rnnt 17.014708 hw_loss 0.184282 lr 0.00049050 rank 5
2023-02-22 00:12:07,503 DEBUG TRAIN Batch 12/3800 loss 12.986181 loss_att 13.098526 loss_ctc 14.542265 loss_rnnt 12.582577 hw_loss 0.325607 lr 0.00049048 rank 2
2023-02-22 00:12:07,504 DEBUG TRAIN Batch 12/3800 loss 6.953215 loss_att 10.409483 loss_ctc 8.317714 loss_rnnt 5.892944 hw_loss 0.350783 lr 0.00049050 rank 7
2023-02-22 00:12:07,506 DEBUG TRAIN Batch 12/3800 loss 16.364580 loss_att 17.506470 loss_ctc 18.634247 loss_rnnt 15.742698 hw_loss 0.170407 lr 0.00049057 rank 0
2023-02-22 00:12:07,507 DEBUG TRAIN Batch 12/3800 loss 24.911640 loss_att 32.291664 loss_ctc 37.909637 loss_rnnt 21.638960 hw_loss 0.119267 lr 0.00049050 rank 6
2023-02-22 00:12:07,509 DEBUG TRAIN Batch 12/3800 loss 23.513027 loss_att 26.749271 loss_ctc 32.740097 loss_rnnt 21.505966 hw_loss 0.242884 lr 0.00049050 rank 3
2023-02-22 00:12:07,513 DEBUG TRAIN Batch 12/3800 loss 15.092611 loss_att 20.745373 loss_ctc 19.559458 loss_rnnt 13.307396 hw_loss 0.110781 lr 0.00049055 rank 1
2023-02-22 00:13:25,817 DEBUG TRAIN Batch 12/3900 loss 30.772396 loss_att 36.836113 loss_ctc 38.787014 loss_rnnt 28.407034 hw_loss 0.157506 lr 0.00049026 rank 5
2023-02-22 00:13:25,818 DEBUG TRAIN Batch 12/3900 loss 12.006329 loss_att 14.315551 loss_ctc 13.114622 loss_rnnt 11.269045 hw_loss 0.239373 lr 0.00049033 rank 0
2023-02-22 00:13:25,819 DEBUG TRAIN Batch 12/3900 loss 22.193195 loss_att 29.010227 loss_ctc 29.052689 loss_rnnt 19.821455 hw_loss 0.175755 lr 0.00049026 rank 3
2023-02-22 00:13:25,820 DEBUG TRAIN Batch 12/3900 loss 13.627818 loss_att 16.664118 loss_ctc 18.178768 loss_rnnt 12.308655 hw_loss 0.197081 lr 0.00049030 rank 4
2023-02-22 00:13:25,823 DEBUG TRAIN Batch 12/3900 loss 18.288971 loss_att 26.722797 loss_ctc 23.055965 loss_rnnt 15.885715 hw_loss 0.151672 lr 0.00049027 rank 7
2023-02-22 00:13:25,825 DEBUG TRAIN Batch 12/3900 loss 18.164268 loss_att 18.268314 loss_ctc 21.478413 loss_rnnt 17.582455 hw_loss 0.223346 lr 0.00049027 rank 6
2023-02-22 00:13:25,825 DEBUG TRAIN Batch 12/3900 loss 22.091425 loss_att 29.158474 loss_ctc 24.308212 loss_rnnt 20.305344 hw_loss 0.144564 lr 0.00049024 rank 2
2023-02-22 00:13:25,826 DEBUG TRAIN Batch 12/3900 loss 36.698284 loss_att 41.492970 loss_ctc 37.322453 loss_rnnt 35.543404 hw_loss 0.211354 lr 0.00049031 rank 1
2023-02-22 00:14:40,672 DEBUG TRAIN Batch 12/4000 loss 10.596121 loss_att 13.581256 loss_ctc 16.053087 loss_rnnt 9.199706 hw_loss 0.134612 lr 0.00049009 rank 0
2023-02-22 00:14:40,675 DEBUG TRAIN Batch 12/4000 loss 12.338835 loss_att 15.906733 loss_ctc 13.363680 loss_rnnt 11.450350 hw_loss 0.071736 lr 0.00049008 rank 1
2023-02-22 00:14:40,675 DEBUG TRAIN Batch 12/4000 loss 17.127481 loss_att 22.400818 loss_ctc 21.212444 loss_rnnt 15.459747 hw_loss 0.128259 lr 0.00049006 rank 4
2023-02-22 00:14:40,675 DEBUG TRAIN Batch 12/4000 loss 13.823118 loss_att 19.712975 loss_ctc 16.158188 loss_rnnt 12.333742 hw_loss 0.000113 lr 0.00049003 rank 5
2023-02-22 00:14:40,677 DEBUG TRAIN Batch 12/4000 loss 10.012782 loss_att 16.009014 loss_ctc 14.993655 loss_rnnt 8.064535 hw_loss 0.159159 lr 0.00049003 rank 7
2023-02-22 00:14:40,682 DEBUG TRAIN Batch 12/4000 loss 22.512550 loss_att 25.769270 loss_ctc 27.726177 loss_rnnt 21.115440 hw_loss 0.094905 lr 0.00049003 rank 3
2023-02-22 00:14:40,685 DEBUG TRAIN Batch 12/4000 loss 8.651930 loss_att 14.398900 loss_ctc 12.094971 loss_rnnt 6.999408 hw_loss 0.082605 lr 0.00049003 rank 6
2023-02-22 00:14:40,686 DEBUG TRAIN Batch 12/4000 loss 21.730398 loss_att 24.920792 loss_ctc 23.744345 loss_rnnt 20.697105 hw_loss 0.237542 lr 0.00049001 rank 2
2023-02-22 00:15:56,037 DEBUG TRAIN Batch 12/4100 loss 13.139655 loss_att 17.916975 loss_ctc 14.589358 loss_rnnt 11.948101 hw_loss 0.080244 lr 0.00048982 rank 4
2023-02-22 00:15:56,039 DEBUG TRAIN Batch 12/4100 loss 11.172754 loss_att 14.454239 loss_ctc 16.670265 loss_rnnt 9.671186 hw_loss 0.210508 lr 0.00048986 rank 0
2023-02-22 00:15:56,041 DEBUG TRAIN Batch 12/4100 loss 24.089613 loss_att 37.581947 loss_ctc 30.068005 loss_rnnt 20.558172 hw_loss 0.067227 lr 0.00048980 rank 7
2023-02-22 00:15:56,041 DEBUG TRAIN Batch 12/4100 loss 7.872941 loss_att 15.728706 loss_ctc 11.192463 loss_rnnt 5.766394 hw_loss 0.173983 lr 0.00048979 rank 5
2023-02-22 00:15:56,042 DEBUG TRAIN Batch 12/4100 loss 15.836796 loss_att 17.025007 loss_ctc 17.792458 loss_rnnt 15.254678 hw_loss 0.156977 lr 0.00048979 rank 3
2023-02-22 00:15:56,045 DEBUG TRAIN Batch 12/4100 loss 9.755032 loss_att 10.827990 loss_ctc 15.076599 loss_rnnt 8.691922 hw_loss 0.260576 lr 0.00048984 rank 1
2023-02-22 00:15:56,046 DEBUG TRAIN Batch 12/4100 loss 10.105043 loss_att 17.638468 loss_ctc 10.841497 loss_rnnt 8.345653 hw_loss 0.289709 lr 0.00048980 rank 6
2023-02-22 00:15:56,047 DEBUG TRAIN Batch 12/4100 loss 16.537750 loss_att 20.970573 loss_ctc 21.387932 loss_rnnt 14.865818 hw_loss 0.260021 lr 0.00048977 rank 2
2023-02-22 00:17:12,248 DEBUG TRAIN Batch 12/4200 loss 23.578602 loss_att 30.438160 loss_ctc 31.867908 loss_rnnt 21.009167 hw_loss 0.173023 lr 0.00048962 rank 0
2023-02-22 00:17:12,247 DEBUG TRAIN Batch 12/4200 loss 13.915084 loss_att 17.496456 loss_ctc 20.923845 loss_rnnt 12.192089 hw_loss 0.135409 lr 0.00048956 rank 5
2023-02-22 00:17:12,248 DEBUG TRAIN Batch 12/4200 loss 33.768574 loss_att 40.790264 loss_ctc 41.269138 loss_rnnt 31.273945 hw_loss 0.169151 lr 0.00048961 rank 1
2023-02-22 00:17:12,250 DEBUG TRAIN Batch 12/4200 loss 9.706429 loss_att 12.660442 loss_ctc 11.009146 loss_rnnt 8.859062 hw_loss 0.155378 lr 0.00048959 rank 4
2023-02-22 00:17:12,252 DEBUG TRAIN Batch 12/4200 loss 10.783305 loss_att 18.129452 loss_ctc 11.670263 loss_rnnt 9.076779 hw_loss 0.223191 lr 0.00048956 rank 7
2023-02-22 00:17:12,256 DEBUG TRAIN Batch 12/4200 loss 22.460287 loss_att 27.855551 loss_ctc 31.543110 loss_rnnt 20.084019 hw_loss 0.161572 lr 0.00048956 rank 6
2023-02-22 00:17:12,261 DEBUG TRAIN Batch 12/4200 loss 16.063597 loss_att 18.152519 loss_ctc 21.456051 loss_rnnt 14.845655 hw_loss 0.152183 lr 0.00048956 rank 3
2023-02-22 00:17:12,300 DEBUG TRAIN Batch 12/4200 loss 11.701520 loss_att 14.553190 loss_ctc 14.273024 loss_rnnt 10.723553 hw_loss 0.121436 lr 0.00048954 rank 2
2023-02-22 00:18:29,787 DEBUG TRAIN Batch 12/4300 loss 10.518623 loss_att 11.694523 loss_ctc 11.296170 loss_rnnt 10.111402 hw_loss 0.128193 lr 0.00048932 rank 3
2023-02-22 00:18:29,788 DEBUG TRAIN Batch 12/4300 loss 13.867506 loss_att 16.302177 loss_ctc 18.925514 loss_rnnt 12.602007 hw_loss 0.195304 lr 0.00048939 rank 0
2023-02-22 00:18:29,788 DEBUG TRAIN Batch 12/4300 loss 18.833494 loss_att 19.835608 loss_ctc 24.596291 loss_rnnt 17.731287 hw_loss 0.250145 lr 0.00048932 rank 5
2023-02-22 00:18:29,789 DEBUG TRAIN Batch 12/4300 loss 21.007769 loss_att 24.922401 loss_ctc 24.999771 loss_rnnt 19.680275 hw_loss 0.023062 lr 0.00048935 rank 4
2023-02-22 00:18:29,791 DEBUG TRAIN Batch 12/4300 loss 30.435236 loss_att 38.915356 loss_ctc 38.998188 loss_rnnt 27.498920 hw_loss 0.184808 lr 0.00048933 rank 7
2023-02-22 00:18:29,795 DEBUG TRAIN Batch 12/4300 loss 16.006586 loss_att 23.886478 loss_ctc 22.475336 loss_rnnt 13.477391 hw_loss 0.170090 lr 0.00048933 rank 6
2023-02-22 00:18:29,798 DEBUG TRAIN Batch 12/4300 loss 13.429073 loss_att 17.500088 loss_ctc 16.937229 loss_rnnt 12.053558 hw_loss 0.175422 lr 0.00048930 rank 2
2023-02-22 00:18:29,840 DEBUG TRAIN Batch 12/4300 loss 11.109070 loss_att 14.679501 loss_ctc 15.064203 loss_rnnt 9.801125 hw_loss 0.124702 lr 0.00048937 rank 1
2023-02-22 00:19:45,396 DEBUG TRAIN Batch 12/4400 loss 12.138048 loss_att 14.001856 loss_ctc 16.253294 loss_rnnt 11.096600 hw_loss 0.224976 lr 0.00048912 rank 4
2023-02-22 00:19:45,400 DEBUG TRAIN Batch 12/4400 loss 16.155815 loss_att 15.434022 loss_ctc 17.260689 loss_rnnt 16.077892 hw_loss 0.140562 lr 0.00048914 rank 1
2023-02-22 00:19:45,400 DEBUG TRAIN Batch 12/4400 loss 22.453478 loss_att 22.368248 loss_ctc 27.858490 loss_rnnt 21.653717 hw_loss 0.180259 lr 0.00048907 rank 2
2023-02-22 00:19:45,402 DEBUG TRAIN Batch 12/4400 loss 17.737659 loss_att 19.352480 loss_ctc 22.115055 loss_rnnt 16.799454 hw_loss 0.059227 lr 0.00048916 rank 0
2023-02-22 00:19:45,403 DEBUG TRAIN Batch 12/4400 loss 12.475573 loss_att 16.326782 loss_ctc 15.895467 loss_rnnt 11.208613 hw_loss 0.076373 lr 0.00048909 rank 7
2023-02-22 00:19:45,406 DEBUG TRAIN Batch 12/4400 loss 10.563615 loss_att 13.915525 loss_ctc 14.219815 loss_rnnt 9.219047 hw_loss 0.350048 lr 0.00048909 rank 5
2023-02-22 00:19:45,406 DEBUG TRAIN Batch 12/4400 loss 9.956143 loss_att 11.019027 loss_ctc 12.645694 loss_rnnt 9.221191 hw_loss 0.307067 lr 0.00048909 rank 3
2023-02-22 00:19:45,406 DEBUG TRAIN Batch 12/4400 loss 28.504974 loss_att 32.469894 loss_ctc 36.639931 loss_rnnt 26.520733 hw_loss 0.199871 lr 0.00048909 rank 6
2023-02-22 00:21:00,884 DEBUG TRAIN Batch 12/4500 loss 14.233031 loss_att 14.658599 loss_ctc 15.697050 loss_rnnt 13.867228 hw_loss 0.160290 lr 0.00048886 rank 7
2023-02-22 00:21:00,884 DEBUG TRAIN Batch 12/4500 loss 14.351041 loss_att 16.168285 loss_ctc 19.518433 loss_rnnt 13.215091 hw_loss 0.156592 lr 0.00048886 rank 5
2023-02-22 00:21:00,885 DEBUG TRAIN Batch 12/4500 loss 18.860331 loss_att 25.470808 loss_ctc 24.134892 loss_rnnt 16.723888 hw_loss 0.208259 lr 0.00048892 rank 0
2023-02-22 00:21:00,889 DEBUG TRAIN Batch 12/4500 loss 21.522987 loss_att 20.469769 loss_ctc 22.848190 loss_rnnt 21.497496 hw_loss 0.111454 lr 0.00048886 rank 6
2023-02-22 00:21:00,889 DEBUG TRAIN Batch 12/4500 loss 16.365858 loss_att 17.108389 loss_ctc 19.646154 loss_rnnt 15.649199 hw_loss 0.245216 lr 0.00048890 rank 1
2023-02-22 00:21:00,889 DEBUG TRAIN Batch 12/4500 loss 16.698551 loss_att 14.499327 loss_ctc 18.124168 loss_rnnt 16.839909 hw_loss 0.203254 lr 0.00048889 rank 4
2023-02-22 00:21:00,892 DEBUG TRAIN Batch 12/4500 loss 19.892969 loss_att 22.186371 loss_ctc 30.125944 loss_rnnt 17.954311 hw_loss 0.216713 lr 0.00048886 rank 3
2023-02-22 00:21:00,895 DEBUG TRAIN Batch 12/4500 loss 21.402002 loss_att 27.500206 loss_ctc 24.756996 loss_rnnt 19.690523 hw_loss 0.083447 lr 0.00048884 rank 2
2023-02-22 00:22:17,716 DEBUG TRAIN Batch 12/4600 loss 13.792833 loss_att 16.173954 loss_ctc 18.119865 loss_rnnt 12.668245 hw_loss 0.133923 lr 0.00048862 rank 5
2023-02-22 00:22:17,717 DEBUG TRAIN Batch 12/4600 loss 12.208974 loss_att 12.685870 loss_ctc 13.919349 loss_rnnt 11.811778 hw_loss 0.138312 lr 0.00048863 rank 7
2023-02-22 00:22:17,718 DEBUG TRAIN Batch 12/4600 loss 14.510588 loss_att 20.357182 loss_ctc 19.198154 loss_rnnt 12.672056 hw_loss 0.082884 lr 0.00048869 rank 0
2023-02-22 00:22:17,721 DEBUG TRAIN Batch 12/4600 loss 8.069213 loss_att 17.573971 loss_ctc 7.992578 loss_rnnt 6.162971 hw_loss 0.029080 lr 0.00048862 rank 3
2023-02-22 00:22:17,721 DEBUG TRAIN Batch 12/4600 loss 8.079605 loss_att 14.575802 loss_ctc 7.977585 loss_rnnt 6.743695 hw_loss 0.094261 lr 0.00048860 rank 2
2023-02-22 00:22:17,721 DEBUG TRAIN Batch 12/4600 loss 11.464095 loss_att 14.915734 loss_ctc 14.111255 loss_rnnt 10.335143 hw_loss 0.160633 lr 0.00048865 rank 4
2023-02-22 00:22:17,723 DEBUG TRAIN Batch 12/4600 loss 35.160252 loss_att 52.384418 loss_ctc 37.762390 loss_rnnt 31.349653 hw_loss 0.035277 lr 0.00048863 rank 6
2023-02-22 00:22:17,723 DEBUG TRAIN Batch 12/4600 loss 9.464444 loss_att 13.347527 loss_ctc 9.425768 loss_rnnt 8.692511 hw_loss 0.000889 lr 0.00048867 rank 1
2023-02-22 00:23:32,300 DEBUG TRAIN Batch 12/4700 loss 17.888489 loss_att 22.863369 loss_ctc 28.098846 loss_rnnt 15.472548 hw_loss 0.111718 lr 0.00048842 rank 4
2023-02-22 00:23:32,303 DEBUG TRAIN Batch 12/4700 loss 19.262861 loss_att 26.240623 loss_ctc 24.066149 loss_rnnt 17.123877 hw_loss 0.193114 lr 0.00048837 rank 2
2023-02-22 00:23:32,304 DEBUG TRAIN Batch 12/4700 loss 7.386269 loss_att 17.538612 loss_ctc 9.252884 loss_rnnt 5.035785 hw_loss 0.133374 lr 0.00048839 rank 6
2023-02-22 00:23:32,305 DEBUG TRAIN Batch 12/4700 loss 8.574122 loss_att 13.982821 loss_ctc 12.288470 loss_rnnt 6.916261 hw_loss 0.151642 lr 0.00048839 rank 3
2023-02-22 00:23:32,305 DEBUG TRAIN Batch 12/4700 loss 14.113365 loss_att 18.024368 loss_ctc 20.490393 loss_rnnt 12.369304 hw_loss 0.209231 lr 0.00048839 rank 7
2023-02-22 00:23:32,306 DEBUG TRAIN Batch 12/4700 loss 18.273447 loss_att 23.487823 loss_ctc 22.319138 loss_rnnt 16.680363 hw_loss 0.020217 lr 0.00048846 rank 0
2023-02-22 00:23:32,307 DEBUG TRAIN Batch 12/4700 loss 21.032928 loss_att 25.426659 loss_ctc 31.565369 loss_rnnt 18.662201 hw_loss 0.164358 lr 0.00048839 rank 5
2023-02-22 00:23:32,311 DEBUG TRAIN Batch 12/4700 loss 10.797538 loss_att 11.489817 loss_ctc 11.366129 loss_rnnt 10.504912 hw_loss 0.146921 lr 0.00048844 rank 1
2023-02-22 00:24:47,916 DEBUG TRAIN Batch 12/4800 loss 14.567948 loss_att 20.645699 loss_ctc 17.879509 loss_rnnt 12.818813 hw_loss 0.172581 lr 0.00048816 rank 5
2023-02-22 00:24:47,917 DEBUG TRAIN Batch 12/4800 loss 7.489286 loss_att 12.174826 loss_ctc 10.191769 loss_rnnt 6.169057 hw_loss 0.042731 lr 0.00048822 rank 0
2023-02-22 00:24:47,918 DEBUG TRAIN Batch 12/4800 loss 17.894411 loss_att 22.149120 loss_ctc 19.856211 loss_rnnt 16.718264 hw_loss 0.119311 lr 0.00048820 rank 1
2023-02-22 00:24:47,918 DEBUG TRAIN Batch 12/4800 loss 16.133724 loss_att 21.082710 loss_ctc 19.092810 loss_rnnt 14.598461 hw_loss 0.282977 lr 0.00048816 rank 7
2023-02-22 00:24:47,920 DEBUG TRAIN Batch 12/4800 loss 8.532212 loss_att 12.106403 loss_ctc 8.116885 loss_rnnt 7.838840 hw_loss 0.063583 lr 0.00048816 rank 6
2023-02-22 00:24:47,924 DEBUG TRAIN Batch 12/4800 loss 13.615597 loss_att 16.499493 loss_ctc 16.141228 loss_rnnt 12.611616 hw_loss 0.169596 lr 0.00048814 rank 2
2023-02-22 00:24:47,929 DEBUG TRAIN Batch 12/4800 loss 19.167204 loss_att 21.764904 loss_ctc 25.748596 loss_rnnt 17.701588 hw_loss 0.128544 lr 0.00048819 rank 4
2023-02-22 00:24:47,928 DEBUG TRAIN Batch 12/4800 loss 11.530464 loss_att 14.843315 loss_ctc 12.268179 loss_rnnt 10.724995 hw_loss 0.083505 lr 0.00048816 rank 3
2023-02-22 00:26:03,549 DEBUG TRAIN Batch 12/4900 loss 20.595293 loss_att 26.860567 loss_ctc 28.495588 loss_rnnt 18.177021 hw_loss 0.209710 lr 0.00048793 rank 7
2023-02-22 00:26:03,553 DEBUG TRAIN Batch 12/4900 loss 14.110794 loss_att 17.751101 loss_ctc 18.229261 loss_rnnt 12.749953 hw_loss 0.156843 lr 0.00048792 rank 5
2023-02-22 00:26:03,554 DEBUG TRAIN Batch 12/4900 loss 14.149875 loss_att 16.120008 loss_ctc 16.333952 loss_rnnt 13.391275 hw_loss 0.137553 lr 0.00048795 rank 4
2023-02-22 00:26:03,554 DEBUG TRAIN Batch 12/4900 loss 11.525331 loss_att 17.651783 loss_ctc 12.629885 loss_rnnt 10.054372 hw_loss 0.184492 lr 0.00048799 rank 0
2023-02-22 00:26:03,556 DEBUG TRAIN Batch 12/4900 loss 23.670420 loss_att 26.832047 loss_ctc 30.280319 loss_rnnt 22.040672 hw_loss 0.217690 lr 0.00048790 rank 2
2023-02-22 00:26:03,557 DEBUG TRAIN Batch 12/4900 loss 14.967955 loss_att 20.436790 loss_ctc 18.237221 loss_rnnt 13.372902 hw_loss 0.122596 lr 0.00048792 rank 3
2023-02-22 00:26:03,558 DEBUG TRAIN Batch 12/4900 loss 29.440430 loss_att 35.952820 loss_ctc 38.411995 loss_rnnt 26.844561 hw_loss 0.182215 lr 0.00048797 rank 1
2023-02-22 00:26:03,606 DEBUG TRAIN Batch 12/4900 loss 16.079256 loss_att 21.477777 loss_ctc 27.610432 loss_rnnt 13.406273 hw_loss 0.104602 lr 0.00048793 rank 6
2023-02-22 00:27:21,962 DEBUG TRAIN Batch 12/5000 loss 19.154703 loss_att 20.459049 loss_ctc 23.233259 loss_rnnt 18.272779 hw_loss 0.144840 lr 0.00048772 rank 4
2023-02-22 00:27:21,963 DEBUG TRAIN Batch 12/5000 loss 27.499676 loss_att 32.496971 loss_ctc 33.321850 loss_rnnt 25.636803 hw_loss 0.163356 lr 0.00048770 rank 7
2023-02-22 00:27:21,968 DEBUG TRAIN Batch 12/5000 loss 14.896236 loss_att 19.444832 loss_ctc 17.719416 loss_rnnt 13.508008 hw_loss 0.191409 lr 0.00048769 rank 5
2023-02-22 00:27:21,969 DEBUG TRAIN Batch 12/5000 loss 20.199230 loss_att 21.944349 loss_ctc 27.008490 loss_rnnt 18.839367 hw_loss 0.193010 lr 0.00048776 rank 0
2023-02-22 00:27:21,971 DEBUG TRAIN Batch 12/5000 loss 31.214329 loss_att 33.347473 loss_ctc 37.032726 loss_rnnt 29.921286 hw_loss 0.169928 lr 0.00048769 rank 3
2023-02-22 00:27:21,975 DEBUG TRAIN Batch 12/5000 loss 9.738005 loss_att 12.432766 loss_ctc 11.919125 loss_rnnt 8.793303 hw_loss 0.215499 lr 0.00048767 rank 2
2023-02-22 00:27:21,976 DEBUG TRAIN Batch 12/5000 loss 24.493048 loss_att 27.866653 loss_ctc 29.066467 loss_rnnt 23.085958 hw_loss 0.229833 lr 0.00048774 rank 1
2023-02-22 00:27:22,022 DEBUG TRAIN Batch 12/5000 loss 49.414814 loss_att 48.431007 loss_ctc 54.384518 loss_rnnt 48.863247 hw_loss 0.160698 lr 0.00048769 rank 6
2023-02-22 00:28:38,097 DEBUG TRAIN Batch 12/5100 loss 24.824493 loss_att 32.656761 loss_ctc 26.787024 loss_rnnt 22.844494 hw_loss 0.284767 lr 0.00048749 rank 4
2023-02-22 00:28:38,098 DEBUG TRAIN Batch 12/5100 loss 17.445507 loss_att 18.956734 loss_ctc 19.594965 loss_rnnt 16.722712 hw_loss 0.251163 lr 0.00048747 rank 7
2023-02-22 00:28:38,102 DEBUG TRAIN Batch 12/5100 loss 14.805861 loss_att 18.378944 loss_ctc 18.343790 loss_rnnt 13.502684 hw_loss 0.219069 lr 0.00048753 rank 0
2023-02-22 00:28:38,103 DEBUG TRAIN Batch 12/5100 loss 23.000006 loss_att 24.080944 loss_ctc 26.561277 loss_rnnt 22.257162 hw_loss 0.097161 lr 0.00048751 rank 1
2023-02-22 00:28:38,102 DEBUG TRAIN Batch 12/5100 loss 18.261059 loss_att 18.450813 loss_ctc 22.543100 loss_rnnt 17.505045 hw_loss 0.275856 lr 0.00048746 rank 5
2023-02-22 00:28:38,108 DEBUG TRAIN Batch 12/5100 loss 13.836317 loss_att 19.641300 loss_ctc 18.912540 loss_rnnt 11.973438 hw_loss 0.046973 lr 0.00048746 rank 3
2023-02-22 00:28:38,108 DEBUG TRAIN Batch 12/5100 loss 14.898083 loss_att 15.661551 loss_ctc 21.068592 loss_rnnt 13.800999 hw_loss 0.228105 lr 0.00048746 rank 6
2023-02-22 00:28:38,155 DEBUG TRAIN Batch 12/5100 loss 15.746173 loss_att 20.514551 loss_ctc 23.191452 loss_rnnt 13.685882 hw_loss 0.213584 lr 0.00048744 rank 2
2023-02-22 00:29:52,254 DEBUG TRAIN Batch 12/5200 loss 31.541298 loss_att 41.625282 loss_ctc 42.255417 loss_rnnt 27.984938 hw_loss 0.208150 lr 0.00048726 rank 4
2023-02-22 00:29:52,256 DEBUG TRAIN Batch 12/5200 loss 9.798594 loss_att 12.124212 loss_ctc 8.793685 loss_rnnt 9.312784 hw_loss 0.290014 lr 0.00048723 rank 7
2023-02-22 00:29:52,261 DEBUG TRAIN Batch 12/5200 loss 16.827559 loss_att 20.735310 loss_ctc 21.041517 loss_rnnt 15.357661 hw_loss 0.237158 lr 0.00048729 rank 0
2023-02-22 00:29:52,262 DEBUG TRAIN Batch 12/5200 loss 22.925274 loss_att 32.024254 loss_ctc 30.252914 loss_rnnt 20.027424 hw_loss 0.189436 lr 0.00048721 rank 2
2023-02-22 00:29:52,265 DEBUG TRAIN Batch 12/5200 loss 11.745623 loss_att 13.015229 loss_ctc 11.514095 loss_rnnt 11.403544 hw_loss 0.223176 lr 0.00048728 rank 1
2023-02-22 00:29:52,266 DEBUG TRAIN Batch 12/5200 loss 18.625240 loss_att 26.332560 loss_ctc 22.686546 loss_rnnt 16.428810 hw_loss 0.212738 lr 0.00048723 rank 3
2023-02-22 00:29:52,267 DEBUG TRAIN Batch 12/5200 loss 9.737050 loss_att 11.514235 loss_ctc 11.244654 loss_rnnt 9.057138 hw_loss 0.231487 lr 0.00048723 rank 6
2023-02-22 00:29:52,268 DEBUG TRAIN Batch 12/5200 loss 11.570180 loss_att 16.903524 loss_ctc 13.011950 loss_rnnt 10.203815 hw_loss 0.201490 lr 0.00048723 rank 5
2023-02-22 00:31:09,474 DEBUG TRAIN Batch 12/5300 loss 18.008070 loss_att 22.036219 loss_ctc 20.035366 loss_rnnt 16.907869 hw_loss 0.045496 lr 0.00048700 rank 7
2023-02-22 00:31:09,476 DEBUG TRAIN Batch 12/5300 loss 11.133184 loss_att 14.752674 loss_ctc 14.695730 loss_rnnt 9.801101 hw_loss 0.249711 lr 0.00048706 rank 0
2023-02-22 00:31:09,478 DEBUG TRAIN Batch 12/5300 loss 12.005411 loss_att 16.703365 loss_ctc 12.264995 loss_rnnt 10.926680 hw_loss 0.195993 lr 0.00048703 rank 4
2023-02-22 00:31:09,480 DEBUG TRAIN Batch 12/5300 loss 8.803720 loss_att 15.974378 loss_ctc 15.725843 loss_rnnt 6.313310 hw_loss 0.249991 lr 0.00048698 rank 2
2023-02-22 00:31:09,482 DEBUG TRAIN Batch 12/5300 loss 10.562251 loss_att 14.081573 loss_ctc 8.901705 loss_rnnt 9.981918 hw_loss 0.183515 lr 0.00048700 rank 5
2023-02-22 00:31:09,482 DEBUG TRAIN Batch 12/5300 loss 15.558976 loss_att 17.549913 loss_ctc 15.299370 loss_rnnt 15.080477 hw_loss 0.215485 lr 0.00048700 rank 3
2023-02-22 00:31:09,485 DEBUG TRAIN Batch 12/5300 loss 27.056738 loss_att 32.470161 loss_ctc 30.267120 loss_rnnt 25.479956 hw_loss 0.123839 lr 0.00048704 rank 1
2023-02-22 00:31:09,531 DEBUG TRAIN Batch 12/5300 loss 12.986036 loss_att 21.216068 loss_ctc 16.857468 loss_rnnt 10.741099 hw_loss 0.155136 lr 0.00048700 rank 6
2023-02-22 00:32:25,489 DEBUG TRAIN Batch 12/5400 loss 16.089142 loss_att 22.730835 loss_ctc 22.126730 loss_rnnt 13.880704 hw_loss 0.140788 lr 0.00048683 rank 0
2023-02-22 00:32:25,494 DEBUG TRAIN Batch 12/5400 loss 11.861732 loss_att 15.650532 loss_ctc 12.321891 loss_rnnt 10.963650 hw_loss 0.148065 lr 0.00048681 rank 1
2023-02-22 00:32:25,496 DEBUG TRAIN Batch 12/5400 loss 13.852392 loss_att 18.863884 loss_ctc 15.328787 loss_rnnt 12.596973 hw_loss 0.105501 lr 0.00048675 rank 2
2023-02-22 00:32:25,497 DEBUG TRAIN Batch 12/5400 loss 17.202873 loss_att 18.132715 loss_ctc 22.107742 loss_rnnt 16.241045 hw_loss 0.228521 lr 0.00048680 rank 4
2023-02-22 00:32:25,498 DEBUG TRAIN Batch 12/5400 loss 13.769410 loss_att 19.334051 loss_ctc 16.067387 loss_rnnt 12.227174 hw_loss 0.230459 lr 0.00048677 rank 3
2023-02-22 00:32:25,498 DEBUG TRAIN Batch 12/5400 loss 15.959797 loss_att 18.173321 loss_ctc 19.017262 loss_rnnt 15.038594 hw_loss 0.132817 lr 0.00048677 rank 5
2023-02-22 00:32:25,498 DEBUG TRAIN Batch 12/5400 loss 20.769653 loss_att 26.157394 loss_ctc 27.609976 loss_rnnt 18.633133 hw_loss 0.275494 lr 0.00048677 rank 7
2023-02-22 00:32:25,505 DEBUG TRAIN Batch 12/5400 loss 20.073488 loss_att 23.909021 loss_ctc 25.883553 loss_rnnt 18.457644 hw_loss 0.138865 lr 0.00048677 rank 6
2023-02-22 00:33:40,223 DEBUG TRAIN Batch 12/5500 loss 8.257423 loss_att 11.704498 loss_ctc 8.002974 loss_rnnt 7.571336 hw_loss 0.057372 lr 0.00048660 rank 0
2023-02-22 00:33:40,225 DEBUG TRAIN Batch 12/5500 loss 10.879715 loss_att 14.255146 loss_ctc 13.736339 loss_rnnt 9.713505 hw_loss 0.206702 lr 0.00048657 rank 4
2023-02-22 00:33:40,227 DEBUG TRAIN Batch 12/5500 loss 19.703287 loss_att 21.869293 loss_ctc 28.313742 loss_rnnt 18.020996 hw_loss 0.189429 lr 0.00048654 rank 7
2023-02-22 00:33:40,230 DEBUG TRAIN Batch 12/5500 loss 19.238823 loss_att 21.486687 loss_ctc 19.461517 loss_rnnt 18.667744 hw_loss 0.172152 lr 0.00048654 rank 6
2023-02-22 00:33:40,230 DEBUG TRAIN Batch 12/5500 loss 15.563639 loss_att 19.279682 loss_ctc 18.572315 loss_rnnt 14.311537 hw_loss 0.202008 lr 0.00048652 rank 2
2023-02-22 00:33:40,233 DEBUG TRAIN Batch 12/5500 loss 15.761690 loss_att 20.157866 loss_ctc 21.656929 loss_rnnt 13.999147 hw_loss 0.182389 lr 0.00048654 rank 5
2023-02-22 00:33:40,234 DEBUG TRAIN Batch 12/5500 loss 10.741202 loss_att 15.119120 loss_ctc 15.537119 loss_rnnt 9.107845 hw_loss 0.221847 lr 0.00048654 rank 3
2023-02-22 00:33:40,281 DEBUG TRAIN Batch 12/5500 loss 16.402359 loss_att 21.843941 loss_ctc 20.327118 loss_rnnt 14.756006 hw_loss 0.065125 lr 0.00048658 rank 1
2023-02-22 00:34:56,048 DEBUG TRAIN Batch 12/5600 loss 12.956675 loss_att 16.517988 loss_ctc 16.488329 loss_rnnt 11.698647 hw_loss 0.140396 lr 0.00048637 rank 0
2023-02-22 00:34:56,050 DEBUG TRAIN Batch 12/5600 loss 10.678062 loss_att 16.901285 loss_ctc 14.421326 loss_rnnt 8.826069 hw_loss 0.202961 lr 0.00048631 rank 3
2023-02-22 00:34:56,052 DEBUG TRAIN Batch 12/5600 loss 10.306083 loss_att 14.826965 loss_ctc 14.046295 loss_rnnt 8.831029 hw_loss 0.135341 lr 0.00048631 rank 5
2023-02-22 00:34:56,054 DEBUG TRAIN Batch 12/5600 loss 24.070877 loss_att 26.001259 loss_ctc 27.994864 loss_rnnt 23.036068 hw_loss 0.235381 lr 0.00048631 rank 7
2023-02-22 00:34:56,057 DEBUG TRAIN Batch 12/5600 loss 5.424203 loss_att 9.831446 loss_ctc 7.332098 loss_rnnt 4.175723 hw_loss 0.211211 lr 0.00048634 rank 4
2023-02-22 00:34:56,063 DEBUG TRAIN Batch 12/5600 loss 12.285620 loss_att 17.159973 loss_ctc 18.473278 loss_rnnt 10.416268 hw_loss 0.130234 lr 0.00048635 rank 1
2023-02-22 00:34:56,063 DEBUG TRAIN Batch 12/5600 loss 10.852243 loss_att 16.519808 loss_ctc 14.127279 loss_rnnt 9.204627 hw_loss 0.145186 lr 0.00048631 rank 6
2023-02-22 00:34:56,103 DEBUG TRAIN Batch 12/5600 loss 16.619152 loss_att 19.680202 loss_ctc 18.001057 loss_rnnt 15.707977 hw_loss 0.215081 lr 0.00048629 rank 2
2023-02-22 00:36:13,835 DEBUG TRAIN Batch 12/5700 loss 12.608833 loss_att 15.135894 loss_ctc 16.034744 loss_rnnt 11.534403 hw_loss 0.210430 lr 0.00048608 rank 7
2023-02-22 00:36:13,838 DEBUG TRAIN Batch 12/5700 loss 9.620367 loss_att 13.568050 loss_ctc 13.873660 loss_rnnt 8.115870 hw_loss 0.277227 lr 0.00048614 rank 0
2023-02-22 00:36:13,842 DEBUG TRAIN Batch 12/5700 loss 13.152929 loss_att 17.771648 loss_ctc 19.666531 loss_rnnt 11.329697 hw_loss 0.058140 lr 0.00048606 rank 2
2023-02-22 00:36:13,843 DEBUG TRAIN Batch 12/5700 loss 18.163290 loss_att 25.848444 loss_ctc 20.368744 loss_rnnt 16.310879 hw_loss 0.039971 lr 0.00048611 rank 4
2023-02-22 00:36:13,842 DEBUG TRAIN Batch 12/5700 loss 14.465373 loss_att 20.097168 loss_ctc 17.864380 loss_rnnt 12.780128 hw_loss 0.198158 lr 0.00048608 rank 6
2023-02-22 00:36:13,846 DEBUG TRAIN Batch 12/5700 loss 10.434475 loss_att 11.645290 loss_ctc 11.551769 loss_rnnt 9.970619 hw_loss 0.136349 lr 0.00048608 rank 5
2023-02-22 00:36:13,848 DEBUG TRAIN Batch 12/5700 loss 10.813306 loss_att 12.634874 loss_ctc 13.024920 loss_rnnt 10.075975 hw_loss 0.146502 lr 0.00048608 rank 3
2023-02-22 00:36:13,847 DEBUG TRAIN Batch 12/5700 loss 12.225277 loss_att 18.106129 loss_ctc 17.686529 loss_rnnt 10.261657 hw_loss 0.111157 lr 0.00048612 rank 1
2023-02-22 00:37:29,901 DEBUG TRAIN Batch 12/5800 loss 32.269165 loss_att 40.178463 loss_ctc 40.904282 loss_rnnt 29.464565 hw_loss 0.133860 lr 0.00048589 rank 1
2023-02-22 00:37:29,902 DEBUG TRAIN Batch 12/5800 loss 6.502313 loss_att 5.668288 loss_ctc 8.241362 loss_rnnt 6.367422 hw_loss 0.130917 lr 0.00048591 rank 0
2023-02-22 00:37:29,903 DEBUG TRAIN Batch 12/5800 loss 10.946544 loss_att 15.341993 loss_ctc 11.946115 loss_rnnt 9.866375 hw_loss 0.127130 lr 0.00048585 rank 7
2023-02-22 00:37:29,904 DEBUG TRAIN Batch 12/5800 loss 10.239310 loss_att 12.679223 loss_ctc 14.009975 loss_rnnt 9.159575 hw_loss 0.166872 lr 0.00048585 rank 6
2023-02-22 00:37:29,904 DEBUG TRAIN Batch 12/5800 loss 18.626389 loss_att 26.721869 loss_ctc 23.288860 loss_rnnt 16.334497 hw_loss 0.095872 lr 0.00048588 rank 4
2023-02-22 00:37:29,906 DEBUG TRAIN Batch 12/5800 loss 5.831936 loss_att 12.912692 loss_ctc 6.273254 loss_rnnt 4.239733 hw_loss 0.219766 lr 0.00048585 rank 5
2023-02-22 00:37:29,909 DEBUG TRAIN Batch 12/5800 loss 11.923859 loss_att 13.135677 loss_ctc 15.154306 loss_rnnt 11.207720 hw_loss 0.080715 lr 0.00048585 rank 3
2023-02-22 00:37:29,952 DEBUG TRAIN Batch 12/5800 loss 10.462633 loss_att 14.429501 loss_ctc 13.066759 loss_rnnt 9.272367 hw_loss 0.093142 lr 0.00048583 rank 2
2023-02-22 00:38:45,685 DEBUG TRAIN Batch 12/5900 loss 17.855555 loss_att 22.495260 loss_ctc 25.059685 loss_rnnt 15.929417 hw_loss 0.070586 lr 0.00048562 rank 5
2023-02-22 00:38:45,686 DEBUG TRAIN Batch 12/5900 loss 15.955997 loss_att 22.050285 loss_ctc 22.788273 loss_rnnt 13.764408 hw_loss 0.115803 lr 0.00048568 rank 0
2023-02-22 00:38:45,688 DEBUG TRAIN Batch 12/5900 loss 12.727185 loss_att 14.949361 loss_ctc 14.051746 loss_rnnt 12.059126 hw_loss 0.088156 lr 0.00048565 rank 4
2023-02-22 00:38:45,689 DEBUG TRAIN Batch 12/5900 loss 9.890204 loss_att 13.196657 loss_ctc 13.214041 loss_rnnt 8.750934 hw_loss 0.065256 lr 0.00048566 rank 1
2023-02-22 00:38:45,689 DEBUG TRAIN Batch 12/5900 loss 16.490955 loss_att 25.845352 loss_ctc 19.131941 loss_rnnt 14.204531 hw_loss 0.118901 lr 0.00048562 rank 6
2023-02-22 00:38:45,689 DEBUG TRAIN Batch 12/5900 loss 10.789710 loss_att 16.720371 loss_ctc 18.512043 loss_rnnt 8.498013 hw_loss 0.142354 lr 0.00048562 rank 7
2023-02-22 00:38:45,691 DEBUG TRAIN Batch 12/5900 loss 15.899262 loss_att 16.186596 loss_ctc 19.357870 loss_rnnt 15.280645 hw_loss 0.187505 lr 0.00048560 rank 2
2023-02-22 00:38:45,694 DEBUG TRAIN Batch 12/5900 loss 18.557896 loss_att 22.631882 loss_ctc 21.445984 loss_rnnt 17.288254 hw_loss 0.130809 lr 0.00048562 rank 3
2023-02-22 00:40:03,836 DEBUG TRAIN Batch 12/6000 loss 14.512314 loss_att 19.086086 loss_ctc 17.601727 loss_rnnt 13.149426 hw_loss 0.067898 lr 0.00048542 rank 4
2023-02-22 00:40:03,837 DEBUG TRAIN Batch 12/6000 loss 13.381374 loss_att 21.286076 loss_ctc 19.240242 loss_rnnt 10.872252 hw_loss 0.275625 lr 0.00048545 rank 0
2023-02-22 00:40:03,838 DEBUG TRAIN Batch 12/6000 loss 20.325825 loss_att 22.229977 loss_ctc 24.770424 loss_rnnt 19.291302 hw_loss 0.114522 lr 0.00048539 rank 6
2023-02-22 00:40:03,843 DEBUG TRAIN Batch 12/6000 loss 19.623198 loss_att 22.139229 loss_ctc 23.320648 loss_rnnt 18.494530 hw_loss 0.248376 lr 0.00048543 rank 1
2023-02-22 00:40:03,844 DEBUG TRAIN Batch 12/6000 loss 12.138250 loss_att 14.756594 loss_ctc 13.946125 loss_rnnt 11.373472 hw_loss 0.000113 lr 0.00048539 rank 7
2023-02-22 00:40:03,845 DEBUG TRAIN Batch 12/6000 loss 10.710043 loss_att 10.378593 loss_ctc 11.479655 loss_rnnt 10.587202 hw_loss 0.162216 lr 0.00048537 rank 2
2023-02-22 00:40:03,847 DEBUG TRAIN Batch 12/6000 loss 8.215535 loss_att 14.051752 loss_ctc 12.778506 loss_rnnt 6.376352 hw_loss 0.119145 lr 0.00048539 rank 3
2023-02-22 00:40:03,848 DEBUG TRAIN Batch 12/6000 loss 20.691259 loss_att 21.461430 loss_ctc 20.788197 loss_rnnt 20.450678 hw_loss 0.138038 lr 0.00048539 rank 5
2023-02-22 00:41:21,003 DEBUG TRAIN Batch 12/6100 loss 8.163141 loss_att 12.479610 loss_ctc 10.649732 loss_rnnt 6.876990 hw_loss 0.171209 lr 0.00048519 rank 4
2023-02-22 00:41:21,004 DEBUG TRAIN Batch 12/6100 loss 9.661770 loss_att 16.706570 loss_ctc 13.183510 loss_rnnt 7.728741 hw_loss 0.102196 lr 0.00048522 rank 0
2023-02-22 00:41:21,006 DEBUG TRAIN Batch 12/6100 loss 14.572551 loss_att 20.610554 loss_ctc 20.767242 loss_rnnt 12.494049 hw_loss 0.084266 lr 0.00048521 rank 1
2023-02-22 00:41:21,007 DEBUG TRAIN Batch 12/6100 loss 16.810785 loss_att 22.644810 loss_ctc 19.316906 loss_rnnt 15.303157 hw_loss 0.012517 lr 0.00048516 rank 5
2023-02-22 00:41:21,009 DEBUG TRAIN Batch 12/6100 loss 13.310802 loss_att 15.636395 loss_ctc 17.222889 loss_rnnt 12.160812 hw_loss 0.306107 lr 0.00048516 rank 7
2023-02-22 00:41:21,014 DEBUG TRAIN Batch 12/6100 loss 16.389414 loss_att 23.661982 loss_ctc 20.163204 loss_rnnt 14.333601 hw_loss 0.183985 lr 0.00048516 rank 3
2023-02-22 00:41:21,014 DEBUG TRAIN Batch 12/6100 loss 18.721722 loss_att 21.309425 loss_ctc 21.980659 loss_rnnt 17.657341 hw_loss 0.210592 lr 0.00048516 rank 6
2023-02-22 00:41:21,015 DEBUG TRAIN Batch 12/6100 loss 20.017647 loss_att 22.572334 loss_ctc 24.441875 loss_rnnt 18.829338 hw_loss 0.164015 lr 0.00048514 rank 2
2023-02-22 00:42:35,681 DEBUG TRAIN Batch 12/6200 loss 14.189702 loss_att 22.325583 loss_ctc 18.386068 loss_rnnt 11.908819 hw_loss 0.176609 lr 0.00048500 rank 0
2023-02-22 00:42:35,684 DEBUG TRAIN Batch 12/6200 loss 18.636332 loss_att 20.308163 loss_ctc 19.415447 loss_rnnt 18.151278 hw_loss 0.087764 lr 0.00048496 rank 4
2023-02-22 00:42:35,687 DEBUG TRAIN Batch 12/6200 loss 21.998240 loss_att 27.026775 loss_ctc 23.586403 loss_rnnt 20.710579 hw_loss 0.131622 lr 0.00048493 rank 5
2023-02-22 00:42:35,690 DEBUG TRAIN Batch 12/6200 loss 11.303356 loss_att 14.594035 loss_ctc 11.667881 loss_rnnt 10.546184 hw_loss 0.094564 lr 0.00048491 rank 2
2023-02-22 00:42:35,692 DEBUG TRAIN Batch 12/6200 loss 13.944858 loss_att 14.776321 loss_ctc 17.698246 loss_rnnt 13.158950 hw_loss 0.223428 lr 0.00048498 rank 1
2023-02-22 00:42:35,694 DEBUG TRAIN Batch 12/6200 loss 18.555634 loss_att 19.070774 loss_ctc 18.200439 loss_rnnt 18.371798 hw_loss 0.240312 lr 0.00048493 rank 3
2023-02-22 00:42:35,694 DEBUG TRAIN Batch 12/6200 loss 13.088284 loss_att 16.259081 loss_ctc 18.362190 loss_rnnt 11.665565 hw_loss 0.160078 lr 0.00048494 rank 7
2023-02-22 00:42:35,740 DEBUG TRAIN Batch 12/6200 loss 16.097767 loss_att 20.909283 loss_ctc 23.556976 loss_rnnt 13.980865 hw_loss 0.300069 lr 0.00048493 rank 6
2023-02-22 00:43:52,036 DEBUG TRAIN Batch 12/6300 loss 16.925779 loss_att 18.380133 loss_ctc 17.743553 loss_rnnt 16.430805 hw_loss 0.178252 lr 0.00048471 rank 7
2023-02-22 00:43:52,039 DEBUG TRAIN Batch 12/6300 loss 13.270106 loss_att 18.056337 loss_ctc 17.455360 loss_rnnt 11.734566 hw_loss 0.037986 lr 0.00048468 rank 2
2023-02-22 00:43:52,041 DEBUG TRAIN Batch 12/6300 loss 13.229012 loss_att 19.217644 loss_ctc 16.873638 loss_rnnt 11.436969 hw_loss 0.203187 lr 0.00048470 rank 5
2023-02-22 00:43:52,043 DEBUG TRAIN Batch 12/6300 loss 25.443413 loss_att 27.308714 loss_ctc 28.862331 loss_rnnt 24.484789 hw_loss 0.243203 lr 0.00048473 rank 4
2023-02-22 00:43:52,044 DEBUG TRAIN Batch 12/6300 loss 17.712109 loss_att 19.984238 loss_ctc 21.749598 loss_rnnt 16.654501 hw_loss 0.121592 lr 0.00048477 rank 0
2023-02-22 00:43:52,045 DEBUG TRAIN Batch 12/6300 loss 11.561218 loss_att 16.464159 loss_ctc 16.504372 loss_rnnt 9.844717 hw_loss 0.144047 lr 0.00048471 rank 6
2023-02-22 00:43:52,047 DEBUG TRAIN Batch 12/6300 loss 10.269501 loss_att 12.861293 loss_ctc 12.812737 loss_rnnt 9.210487 hw_loss 0.377918 lr 0.00048470 rank 3
2023-02-22 00:43:52,048 DEBUG TRAIN Batch 12/6300 loss 15.041879 loss_att 17.336962 loss_ctc 17.133244 loss_rnnt 14.218406 hw_loss 0.160514 lr 0.00048475 rank 1
2023-02-22 00:45:10,593 DEBUG TRAIN Batch 12/6400 loss 13.044892 loss_att 13.064582 loss_ctc 16.687790 loss_rnnt 12.391999 hw_loss 0.306066 lr 0.00048454 rank 0
2023-02-22 00:45:10,596 DEBUG TRAIN Batch 12/6400 loss 18.035563 loss_att 16.004719 loss_ctc 21.337551 loss_rnnt 17.894188 hw_loss 0.201151 lr 0.00048448 rank 5
2023-02-22 00:45:10,598 DEBUG TRAIN Batch 12/6400 loss 15.579230 loss_att 22.125086 loss_ctc 26.677994 loss_rnnt 12.693611 hw_loss 0.181149 lr 0.00048451 rank 4
2023-02-22 00:45:10,599 DEBUG TRAIN Batch 12/6400 loss 12.804243 loss_att 18.534294 loss_ctc 18.292889 loss_rnnt 10.853310 hw_loss 0.137072 lr 0.00048446 rank 2
2023-02-22 00:45:10,600 DEBUG TRAIN Batch 12/6400 loss 19.510769 loss_att 19.945454 loss_ctc 24.765411 loss_rnnt 18.645758 hw_loss 0.145231 lr 0.00048452 rank 1
2023-02-22 00:45:10,600 DEBUG TRAIN Batch 12/6400 loss 8.538448 loss_att 14.580170 loss_ctc 11.457350 loss_rnnt 6.908031 hw_loss 0.061664 lr 0.00048448 rank 7
2023-02-22 00:45:10,600 DEBUG TRAIN Batch 12/6400 loss 12.541344 loss_att 13.924467 loss_ctc 12.562912 loss_rnnt 12.211396 hw_loss 0.094586 lr 0.00048448 rank 6
2023-02-22 00:45:10,632 DEBUG TRAIN Batch 12/6400 loss 7.381160 loss_att 10.703199 loss_ctc 11.557978 loss_rnnt 6.081985 hw_loss 0.145983 lr 0.00048448 rank 3
2023-02-22 00:46:25,134 DEBUG TRAIN Batch 12/6500 loss 15.568238 loss_att 23.521753 loss_ctc 17.551018 loss_rnnt 13.655097 hw_loss 0.108877 lr 0.00048431 rank 0
2023-02-22 00:46:25,137 DEBUG TRAIN Batch 12/6500 loss 19.744333 loss_att 21.121719 loss_ctc 29.105225 loss_rnnt 18.109100 hw_loss 0.209319 lr 0.00048429 rank 1
2023-02-22 00:46:25,137 DEBUG TRAIN Batch 12/6500 loss 12.687207 loss_att 17.581619 loss_ctc 17.613503 loss_rnnt 10.940104 hw_loss 0.208839 lr 0.00048425 rank 5
2023-02-22 00:46:25,137 DEBUG TRAIN Batch 12/6500 loss 13.727060 loss_att 17.565781 loss_ctc 13.875307 loss_rnnt 12.868914 hw_loss 0.132442 lr 0.00048425 rank 7
2023-02-22 00:46:25,138 DEBUG TRAIN Batch 12/6500 loss 14.479251 loss_att 19.652103 loss_ctc 16.947952 loss_rnnt 13.044391 hw_loss 0.133367 lr 0.00048428 rank 4
2023-02-22 00:46:25,139 DEBUG TRAIN Batch 12/6500 loss 20.595398 loss_att 22.683508 loss_ctc 22.070438 loss_rnnt 19.861336 hw_loss 0.224564 lr 0.00048425 rank 3
2023-02-22 00:46:25,141 DEBUG TRAIN Batch 12/6500 loss 17.024536 loss_att 21.546364 loss_ctc 23.578499 loss_rnnt 15.117270 hw_loss 0.241945 lr 0.00048423 rank 2
2023-02-22 00:46:25,188 DEBUG TRAIN Batch 12/6500 loss 30.272419 loss_att 39.948757 loss_ctc 36.598328 loss_rnnt 27.493626 hw_loss 0.000134 lr 0.00048425 rank 6
2023-02-22 00:47:40,121 DEBUG TRAIN Batch 12/6600 loss 10.091024 loss_att 13.626904 loss_ctc 12.904699 loss_rnnt 8.913839 hw_loss 0.177849 lr 0.00048403 rank 7
2023-02-22 00:47:40,122 DEBUG TRAIN Batch 12/6600 loss 19.752203 loss_att 18.973427 loss_ctc 23.913237 loss_rnnt 19.297577 hw_loss 0.104208 lr 0.00048405 rank 4
2023-02-22 00:47:40,126 DEBUG TRAIN Batch 12/6600 loss 16.158705 loss_att 21.173313 loss_ctc 23.273520 loss_rnnt 14.207103 hw_loss 0.000071 lr 0.00048407 rank 1
2023-02-22 00:47:40,126 DEBUG TRAIN Batch 12/6600 loss 12.801313 loss_att 17.291550 loss_ctc 13.602940 loss_rnnt 11.616038 hw_loss 0.338144 lr 0.00048409 rank 0
2023-02-22 00:47:40,128 DEBUG TRAIN Batch 12/6600 loss 22.884552 loss_att 23.386141 loss_ctc 27.376265 loss_rnnt 22.185293 hw_loss 0.000085 lr 0.00048402 rank 5
2023-02-22 00:47:40,133 DEBUG TRAIN Batch 12/6600 loss 26.097321 loss_att 26.541416 loss_ctc 25.939758 loss_rnnt 25.906357 hw_loss 0.230913 lr 0.00048402 rank 3
2023-02-22 00:47:40,133 DEBUG TRAIN Batch 12/6600 loss 18.895609 loss_att 24.961933 loss_ctc 24.906897 loss_rnnt 16.838648 hw_loss 0.079109 lr 0.00048402 rank 6
2023-02-22 00:47:40,139 DEBUG TRAIN Batch 12/6600 loss 9.219901 loss_att 12.979628 loss_ctc 11.480490 loss_rnnt 8.063948 hw_loss 0.192367 lr 0.00048400 rank 2
2023-02-22 00:48:57,320 DEBUG TRAIN Batch 12/6700 loss 14.149763 loss_att 17.788343 loss_ctc 18.315090 loss_rnnt 12.773079 hw_loss 0.175485 lr 0.00048383 rank 4
2023-02-22 00:48:57,321 DEBUG TRAIN Batch 12/6700 loss 11.803588 loss_att 13.698112 loss_ctc 15.099669 loss_rnnt 10.909697 hw_loss 0.141579 lr 0.00048380 rank 7
2023-02-22 00:48:57,323 DEBUG TRAIN Batch 12/6700 loss 9.920149 loss_att 14.030321 loss_ctc 13.285818 loss_rnnt 8.546783 hw_loss 0.192328 lr 0.00048380 rank 5
2023-02-22 00:48:57,323 DEBUG TRAIN Batch 12/6700 loss 16.840706 loss_att 16.672169 loss_ctc 19.870609 loss_rnnt 16.418396 hw_loss 0.097557 lr 0.00048386 rank 0
2023-02-22 00:48:57,324 DEBUG TRAIN Batch 12/6700 loss 13.717804 loss_att 18.289568 loss_ctc 13.916105 loss_rnnt 12.687590 hw_loss 0.167665 lr 0.00048378 rank 2
2023-02-22 00:48:57,326 DEBUG TRAIN Batch 12/6700 loss 13.324136 loss_att 17.378395 loss_ctc 13.877050 loss_rnnt 12.323398 hw_loss 0.217809 lr 0.00048384 rank 1
2023-02-22 00:48:57,327 DEBUG TRAIN Batch 12/6700 loss 32.680595 loss_att 37.895790 loss_ctc 39.663551 loss_rnnt 30.644081 hw_loss 0.117025 lr 0.00048380 rank 6
2023-02-22 00:48:57,328 DEBUG TRAIN Batch 12/6700 loss 22.350140 loss_att 23.758308 loss_ctc 26.639698 loss_rnnt 21.478914 hw_loss 0.033094 lr 0.00048380 rank 3
2023-02-22 00:50:14,646 DEBUG TRAIN Batch 12/6800 loss 15.785764 loss_att 16.584892 loss_ctc 18.668831 loss_rnnt 15.149312 hw_loss 0.172906 lr 0.00048361 rank 1
2023-02-22 00:50:14,648 DEBUG TRAIN Batch 12/6800 loss 27.899826 loss_att 30.106422 loss_ctc 38.541725 loss_rnnt 25.961857 hw_loss 0.145741 lr 0.00048357 rank 5
2023-02-22 00:50:14,649 DEBUG TRAIN Batch 12/6800 loss 23.212643 loss_att 33.495209 loss_ctc 30.977070 loss_rnnt 20.057045 hw_loss 0.119678 lr 0.00048363 rank 0
2023-02-22 00:50:14,650 DEBUG TRAIN Batch 12/6800 loss 28.399004 loss_att 29.297174 loss_ctc 31.866587 loss_rnnt 27.657536 hw_loss 0.186537 lr 0.00048360 rank 4
2023-02-22 00:50:14,651 DEBUG TRAIN Batch 12/6800 loss 28.838591 loss_att 30.952085 loss_ctc 34.893181 loss_rnnt 27.503632 hw_loss 0.196837 lr 0.00048357 rank 6
2023-02-22 00:50:14,653 DEBUG TRAIN Batch 12/6800 loss 10.278991 loss_att 12.297777 loss_ctc 12.947058 loss_rnnt 9.481366 hw_loss 0.071486 lr 0.00048357 rank 7
2023-02-22 00:50:14,655 DEBUG TRAIN Batch 12/6800 loss 14.860748 loss_att 16.996239 loss_ctc 16.602730 loss_rnnt 14.046638 hw_loss 0.290155 lr 0.00048357 rank 3
2023-02-22 00:50:14,700 DEBUG TRAIN Batch 12/6800 loss 15.284471 loss_att 16.444677 loss_ctc 16.488062 loss_rnnt 14.807276 hw_loss 0.158763 lr 0.00048355 rank 2
2023-02-22 00:51:28,956 DEBUG TRAIN Batch 12/6900 loss 17.320316 loss_att 23.682409 loss_ctc 17.176556 loss_rnnt 16.013632 hw_loss 0.100194 lr 0.00048341 rank 0
2023-02-22 00:51:28,958 DEBUG TRAIN Batch 12/6900 loss 16.096169 loss_att 21.394648 loss_ctc 18.303217 loss_rnnt 14.657203 hw_loss 0.159369 lr 0.00048335 rank 7
2023-02-22 00:51:28,960 DEBUG TRAIN Batch 12/6900 loss 13.254225 loss_att 14.766650 loss_ctc 14.272977 loss_rnnt 12.758537 hw_loss 0.107567 lr 0.00048334 rank 5
2023-02-22 00:51:28,964 DEBUG TRAIN Batch 12/6900 loss 10.037110 loss_att 14.012979 loss_ctc 12.245076 loss_rnnt 8.845667 hw_loss 0.191013 lr 0.00048335 rank 6
2023-02-22 00:51:28,963 DEBUG TRAIN Batch 12/6900 loss 19.637270 loss_att 19.883062 loss_ctc 27.587515 loss_rnnt 18.448334 hw_loss 0.149520 lr 0.00048337 rank 4
2023-02-22 00:51:28,966 DEBUG TRAIN Batch 12/6900 loss 13.446144 loss_att 15.717520 loss_ctc 14.682205 loss_rnnt 12.683069 hw_loss 0.269982 lr 0.00048339 rank 1
2023-02-22 00:51:28,966 DEBUG TRAIN Batch 12/6900 loss 13.531909 loss_att 14.239466 loss_ctc 15.880198 loss_rnnt 12.946821 hw_loss 0.244635 lr 0.00048332 rank 2
2023-02-22 00:51:29,011 DEBUG TRAIN Batch 12/6900 loss 7.285597 loss_att 13.300512 loss_ctc 8.817241 loss_rnnt 5.750040 hw_loss 0.240667 lr 0.00048334 rank 3
2023-02-22 00:52:45,213 DEBUG TRAIN Batch 12/7000 loss 9.702808 loss_att 11.406923 loss_ctc 12.298968 loss_rnnt 8.967673 hw_loss 0.090295 lr 0.00048318 rank 0
2023-02-22 00:52:45,219 DEBUG TRAIN Batch 12/7000 loss 18.208591 loss_att 28.917976 loss_ctc 23.764668 loss_rnnt 15.252937 hw_loss 0.136812 lr 0.00048315 rank 4
2023-02-22 00:52:45,220 DEBUG TRAIN Batch 12/7000 loss 10.705100 loss_att 17.429735 loss_ctc 13.618118 loss_rnnt 8.957783 hw_loss 0.026227 lr 0.00048312 rank 7
2023-02-22 00:52:45,221 DEBUG TRAIN Batch 12/7000 loss 12.851356 loss_att 15.252382 loss_ctc 12.340406 loss_rnnt 12.344452 hw_loss 0.177795 lr 0.00048316 rank 1
2023-02-22 00:52:45,221 DEBUG TRAIN Batch 12/7000 loss 18.007845 loss_att 19.258007 loss_ctc 23.567541 loss_rnnt 16.852018 hw_loss 0.308441 lr 0.00048312 rank 5
2023-02-22 00:52:45,222 DEBUG TRAIN Batch 12/7000 loss 11.372606 loss_att 19.114788 loss_ctc 15.927801 loss_rnnt 9.138143 hw_loss 0.147502 lr 0.00048310 rank 2
2023-02-22 00:52:45,224 DEBUG TRAIN Batch 12/7000 loss 8.272207 loss_att 13.811535 loss_ctc 11.179694 loss_rnnt 6.641300 hw_loss 0.253832 lr 0.00048312 rank 6
2023-02-22 00:52:45,224 DEBUG TRAIN Batch 12/7000 loss 7.721711 loss_att 8.950062 loss_ctc 9.423552 loss_rnnt 7.140228 hw_loss 0.204190 lr 0.00048312 rank 3
2023-02-22 00:54:04,010 DEBUG TRAIN Batch 12/7100 loss 6.000329 loss_att 10.388360 loss_ctc 7.296287 loss_rnnt 4.884395 hw_loss 0.122874 lr 0.00048292 rank 4
2023-02-22 00:54:04,011 DEBUG TRAIN Batch 12/7100 loss 13.985188 loss_att 22.839392 loss_ctc 20.303219 loss_rnnt 11.271819 hw_loss 0.187730 lr 0.00048289 rank 5
2023-02-22 00:54:04,013 DEBUG TRAIN Batch 12/7100 loss 10.638918 loss_att 13.600094 loss_ctc 14.595191 loss_rnnt 9.427755 hw_loss 0.171421 lr 0.00048290 rank 7
2023-02-22 00:54:04,013 DEBUG TRAIN Batch 12/7100 loss 13.479310 loss_att 17.581820 loss_ctc 16.422409 loss_rnnt 12.172581 hw_loss 0.175904 lr 0.00048287 rank 2
2023-02-22 00:54:04,015 DEBUG TRAIN Batch 12/7100 loss 6.770589 loss_att 11.941126 loss_ctc 9.671627 loss_rnnt 5.287372 hw_loss 0.116821 lr 0.00048289 rank 6
2023-02-22 00:54:04,018 DEBUG TRAIN Batch 12/7100 loss 14.086065 loss_att 16.022593 loss_ctc 17.947838 loss_rnnt 13.096675 hw_loss 0.163466 lr 0.00048289 rank 3
2023-02-22 00:54:04,021 DEBUG TRAIN Batch 12/7100 loss 21.534208 loss_att 26.268454 loss_ctc 27.187475 loss_rnnt 19.788137 hw_loss 0.085226 lr 0.00048294 rank 1
2023-02-22 00:54:04,034 DEBUG TRAIN Batch 12/7100 loss 14.065423 loss_att 18.551586 loss_ctc 15.332342 loss_rnnt 12.844790 hw_loss 0.289646 lr 0.00048296 rank 0
2023-02-22 00:55:19,470 DEBUG TRAIN Batch 12/7200 loss 15.219238 loss_att 20.222221 loss_ctc 20.030125 loss_rnnt 13.491984 hw_loss 0.159759 lr 0.00048273 rank 0
2023-02-22 00:55:19,472 DEBUG TRAIN Batch 12/7200 loss 12.873059 loss_att 17.366268 loss_ctc 16.977201 loss_rnnt 11.367526 hw_loss 0.111885 lr 0.00048265 rank 2
2023-02-22 00:55:19,472 DEBUG TRAIN Batch 12/7200 loss 6.378821 loss_att 11.178324 loss_ctc 8.318585 loss_rnnt 5.077353 hw_loss 0.155499 lr 0.00048267 rank 7
2023-02-22 00:55:19,474 DEBUG TRAIN Batch 12/7200 loss 7.183214 loss_att 9.872334 loss_ctc 9.107529 loss_rnnt 6.275614 hw_loss 0.212252 lr 0.00048267 rank 6
2023-02-22 00:55:19,477 DEBUG TRAIN Batch 12/7200 loss 13.848258 loss_att 17.110596 loss_ctc 14.655684 loss_rnnt 13.022503 hw_loss 0.123057 lr 0.00048270 rank 4
2023-02-22 00:55:19,478 DEBUG TRAIN Batch 12/7200 loss 19.145014 loss_att 20.350670 loss_ctc 22.616928 loss_rnnt 18.407612 hw_loss 0.062527 lr 0.00048271 rank 1
2023-02-22 00:55:19,479 DEBUG TRAIN Batch 12/7200 loss 15.708765 loss_att 17.024462 loss_ctc 18.344814 loss_rnnt 15.094123 hw_loss 0.000057 lr 0.00048267 rank 5
2023-02-22 00:55:19,517 DEBUG TRAIN Batch 12/7200 loss 5.892912 loss_att 7.923120 loss_ctc 6.506433 loss_rnnt 5.257601 hw_loss 0.276500 lr 0.00048267 rank 3
2023-02-22 00:56:34,522 DEBUG TRAIN Batch 12/7300 loss 12.009229 loss_att 13.128645 loss_ctc 16.477329 loss_rnnt 11.122402 hw_loss 0.125995 lr 0.00048251 rank 0
2023-02-22 00:56:34,523 DEBUG TRAIN Batch 12/7300 loss 19.447880 loss_att 21.469168 loss_ctc 19.729115 loss_rnnt 18.896442 hw_loss 0.205656 lr 0.00048244 rank 3
2023-02-22 00:56:34,527 DEBUG TRAIN Batch 12/7300 loss 17.400610 loss_att 24.294945 loss_ctc 19.594532 loss_rnnt 15.635315 hw_loss 0.176071 lr 0.00048244 rank 5
2023-02-22 00:56:34,527 DEBUG TRAIN Batch 12/7300 loss 6.187776 loss_att 11.791739 loss_ctc 9.198380 loss_rnnt 4.578510 hw_loss 0.163236 lr 0.00048244 rank 6
2023-02-22 00:56:34,528 DEBUG TRAIN Batch 12/7300 loss 13.133746 loss_att 19.695194 loss_ctc 18.328224 loss_rnnt 11.087114 hw_loss 0.078270 lr 0.00048245 rank 7
2023-02-22 00:56:34,528 DEBUG TRAIN Batch 12/7300 loss 12.315742 loss_att 18.779587 loss_ctc 17.169500 loss_rnnt 10.279030 hw_loss 0.181453 lr 0.00048242 rank 2
2023-02-22 00:56:34,529 DEBUG TRAIN Batch 12/7300 loss 16.473206 loss_att 20.821522 loss_ctc 21.775146 loss_rnnt 14.837738 hw_loss 0.110396 lr 0.00048247 rank 4
2023-02-22 00:56:34,531 DEBUG TRAIN Batch 12/7300 loss 28.367388 loss_att 28.822258 loss_ctc 29.023657 loss_rnnt 28.138891 hw_loss 0.093782 lr 0.00048249 rank 1
2023-02-22 00:57:49,386 DEBUG TRAIN Batch 12/7400 loss 18.052168 loss_att 20.442835 loss_ctc 26.170753 loss_rnnt 16.485716 hw_loss 0.010954 lr 0.00048222 rank 7
2023-02-22 00:57:49,387 DEBUG TRAIN Batch 12/7400 loss 10.074289 loss_att 18.214924 loss_ctc 13.996084 loss_rnnt 7.912987 hw_loss 0.019255 lr 0.00048228 rank 0
2023-02-22 00:57:49,387 DEBUG TRAIN Batch 12/7400 loss 11.147297 loss_att 15.705470 loss_ctc 16.229084 loss_rnnt 9.510178 hw_loss 0.089837 lr 0.00048222 rank 3
2023-02-22 00:57:49,388 DEBUG TRAIN Batch 12/7400 loss 12.292012 loss_att 14.736803 loss_ctc 17.791059 loss_rnnt 10.883447 hw_loss 0.349501 lr 0.00048222 rank 5
2023-02-22 00:57:49,389 DEBUG TRAIN Batch 12/7400 loss 13.219001 loss_att 14.266927 loss_ctc 18.834213 loss_rnnt 12.235869 hw_loss 0.046595 lr 0.00048225 rank 4
2023-02-22 00:57:49,391 DEBUG TRAIN Batch 12/7400 loss 22.967630 loss_att 26.465385 loss_ctc 28.266146 loss_rnnt 21.481441 hw_loss 0.150317 lr 0.00048222 rank 6
2023-02-22 00:57:49,395 DEBUG TRAIN Batch 12/7400 loss 23.129505 loss_att 28.312658 loss_ctc 32.669041 loss_rnnt 20.760902 hw_loss 0.112564 lr 0.00048226 rank 1
2023-02-22 00:57:49,398 DEBUG TRAIN Batch 12/7400 loss 16.066645 loss_att 19.006889 loss_ctc 17.763950 loss_rnnt 15.139393 hw_loss 0.211682 lr 0.00048220 rank 2
2023-02-22 00:59:07,293 DEBUG TRAIN Batch 12/7500 loss 26.749975 loss_att 25.935234 loss_ctc 28.509220 loss_rnnt 26.571033 hw_loss 0.201231 lr 0.00048206 rank 0
2023-02-22 00:59:07,294 DEBUG TRAIN Batch 12/7500 loss 13.759360 loss_att 16.887669 loss_ctc 17.886580 loss_rnnt 12.475245 hw_loss 0.202794 lr 0.00048202 rank 4
2023-02-22 00:59:07,294 DEBUG TRAIN Batch 12/7500 loss 15.903665 loss_att 21.602196 loss_ctc 23.198830 loss_rnnt 13.760958 hw_loss 0.056831 lr 0.00048204 rank 1
2023-02-22 00:59:07,295 DEBUG TRAIN Batch 12/7500 loss 14.664400 loss_att 13.345235 loss_ctc 17.662842 loss_rnnt 14.442667 hw_loss 0.160824 lr 0.00048199 rank 3
2023-02-22 00:59:07,299 DEBUG TRAIN Batch 12/7500 loss 17.919189 loss_att 21.989950 loss_ctc 23.583183 loss_rnnt 16.296595 hw_loss 0.099833 lr 0.00048200 rank 7
2023-02-22 00:59:07,303 DEBUG TRAIN Batch 12/7500 loss 15.407401 loss_att 20.783354 loss_ctc 19.982340 loss_rnnt 13.630594 hw_loss 0.171796 lr 0.00048199 rank 5
2023-02-22 00:59:07,305 DEBUG TRAIN Batch 12/7500 loss 17.582191 loss_att 18.929054 loss_ctc 22.960510 loss_rnnt 16.440420 hw_loss 0.291166 lr 0.00048200 rank 6
2023-02-22 00:59:07,350 DEBUG TRAIN Batch 12/7500 loss 13.384196 loss_att 14.269581 loss_ctc 15.338442 loss_rnnt 12.860888 hw_loss 0.160623 lr 0.00048197 rank 2
2023-02-22 01:00:23,619 DEBUG TRAIN Batch 12/7600 loss 10.002176 loss_att 12.199756 loss_ctc 11.873387 loss_rnnt 9.181098 hw_loss 0.247625 lr 0.00048177 rank 7
2023-02-22 01:00:23,622 DEBUG TRAIN Batch 12/7600 loss 14.028082 loss_att 16.628073 loss_ctc 16.192556 loss_rnnt 13.125470 hw_loss 0.176280 lr 0.00048183 rank 0
2023-02-22 01:00:23,622 DEBUG TRAIN Batch 12/7600 loss 14.914601 loss_att 15.988263 loss_ctc 20.182291 loss_rnnt 13.919022 hw_loss 0.147164 lr 0.00048177 rank 5
2023-02-22 01:00:23,625 DEBUG TRAIN Batch 12/7600 loss 13.166067 loss_att 14.865981 loss_ctc 17.460796 loss_rnnt 12.168872 hw_loss 0.158591 lr 0.00048181 rank 1
2023-02-22 01:00:23,626 DEBUG TRAIN Batch 12/7600 loss 13.483866 loss_att 19.494745 loss_ctc 17.170801 loss_rnnt 11.662703 hw_loss 0.238868 lr 0.00048180 rank 4
2023-02-22 01:00:23,626 DEBUG TRAIN Batch 12/7600 loss 11.681922 loss_att 13.320710 loss_ctc 17.394146 loss_rnnt 10.510023 hw_loss 0.154708 lr 0.00048177 rank 3
2023-02-22 01:00:23,628 DEBUG TRAIN Batch 12/7600 loss 28.479115 loss_att 28.664856 loss_ctc 36.146988 loss_rnnt 27.280191 hw_loss 0.261360 lr 0.00048177 rank 6
2023-02-22 01:00:23,672 DEBUG TRAIN Batch 12/7600 loss 18.681210 loss_att 23.297100 loss_ctc 25.155514 loss_rnnt 16.819641 hw_loss 0.140905 lr 0.00048175 rank 2
2023-02-22 01:01:39,847 DEBUG TRAIN Batch 12/7700 loss 7.835999 loss_att 14.268235 loss_ctc 8.962885 loss_rnnt 6.332368 hw_loss 0.125499 lr 0.00048155 rank 7
2023-02-22 01:01:39,847 DEBUG TRAIN Batch 12/7700 loss 12.615940 loss_att 12.467057 loss_ctc 15.478541 loss_rnnt 12.142528 hw_loss 0.227828 lr 0.00048155 rank 5
2023-02-22 01:01:39,850 DEBUG TRAIN Batch 12/7700 loss 11.110940 loss_att 10.788226 loss_ctc 12.628384 loss_rnnt 10.847367 hw_loss 0.235855 lr 0.00048159 rank 1
2023-02-22 01:01:39,854 DEBUG TRAIN Batch 12/7700 loss 11.258324 loss_att 11.020913 loss_ctc 13.233047 loss_rnnt 10.871022 hw_loss 0.321537 lr 0.00048155 rank 6
2023-02-22 01:01:39,854 DEBUG TRAIN Batch 12/7700 loss 12.065340 loss_att 14.483929 loss_ctc 9.898906 loss_rnnt 11.806772 hw_loss 0.119449 lr 0.00048161 rank 0
2023-02-22 01:01:39,856 DEBUG TRAIN Batch 12/7700 loss 10.950803 loss_att 16.909285 loss_ctc 13.250648 loss_rnnt 9.289022 hw_loss 0.306446 lr 0.00048158 rank 4
2023-02-22 01:01:39,860 DEBUG TRAIN Batch 12/7700 loss 21.226419 loss_att 21.523127 loss_ctc 23.460159 loss_rnnt 20.836948 hw_loss 0.060554 lr 0.00048153 rank 2
2023-02-22 01:01:39,911 DEBUG TRAIN Batch 12/7700 loss 4.714188 loss_att 7.453516 loss_ctc 5.518907 loss_rnnt 4.030586 hw_loss 0.053325 lr 0.00048155 rank 3
2023-02-22 01:02:57,071 DEBUG TRAIN Batch 12/7800 loss 5.420077 loss_att 10.193940 loss_ctc 6.742176 loss_rnnt 4.190060 hw_loss 0.185558 lr 0.00048133 rank 7
2023-02-22 01:02:57,072 DEBUG TRAIN Batch 12/7800 loss 14.847253 loss_att 21.139074 loss_ctc 17.699024 loss_rnnt 13.177050 hw_loss 0.059253 lr 0.00048139 rank 0
2023-02-22 01:02:57,074 DEBUG TRAIN Batch 12/7800 loss 12.709275 loss_att 16.227489 loss_ctc 13.941076 loss_rnnt 11.725208 hw_loss 0.217846 lr 0.00048132 rank 5
2023-02-22 01:02:57,076 DEBUG TRAIN Batch 12/7800 loss 7.445539 loss_att 12.881457 loss_ctc 7.914673 loss_rnnt 6.239729 hw_loss 0.105142 lr 0.00048135 rank 4
2023-02-22 01:02:57,079 DEBUG TRAIN Batch 12/7800 loss 13.708801 loss_att 14.869334 loss_ctc 15.302196 loss_rnnt 13.113956 hw_loss 0.281788 lr 0.00048132 rank 3
2023-02-22 01:02:57,080 DEBUG TRAIN Batch 12/7800 loss 9.493761 loss_att 16.559006 loss_ctc 10.589945 loss_rnnt 7.804060 hw_loss 0.244676 lr 0.00048133 rank 6
2023-02-22 01:02:57,085 DEBUG TRAIN Batch 12/7800 loss 10.824918 loss_att 17.155781 loss_ctc 17.277744 loss_rnnt 8.562171 hw_loss 0.255370 lr 0.00048130 rank 2
2023-02-22 01:02:57,085 DEBUG TRAIN Batch 12/7800 loss 11.256243 loss_att 14.765760 loss_ctc 14.828815 loss_rnnt 9.987688 hw_loss 0.169326 lr 0.00048137 rank 1
2023-02-22 01:04:13,476 DEBUG TRAIN Batch 12/7900 loss 9.941022 loss_att 13.785680 loss_ctc 12.355848 loss_rnnt 8.723303 hw_loss 0.237771 lr 0.00048111 rank 7
2023-02-22 01:04:13,476 DEBUG TRAIN Batch 12/7900 loss 10.890512 loss_att 15.182232 loss_ctc 13.348022 loss_rnnt 9.651098 hw_loss 0.100130 lr 0.00048115 rank 1
2023-02-22 01:04:13,477 DEBUG TRAIN Batch 12/7900 loss 12.247635 loss_att 18.113895 loss_ctc 14.997085 loss_rnnt 10.612873 hw_loss 0.177970 lr 0.00048110 rank 6
2023-02-22 01:04:13,477 DEBUG TRAIN Batch 12/7900 loss 22.235886 loss_att 27.284639 loss_ctc 28.171194 loss_rnnt 20.340199 hw_loss 0.177309 lr 0.00048110 rank 3
2023-02-22 01:04:13,478 DEBUG TRAIN Batch 12/7900 loss 13.275557 loss_att 16.090248 loss_ctc 14.169493 loss_rnnt 12.551682 hw_loss 0.078274 lr 0.00048110 rank 5
2023-02-22 01:04:13,479 DEBUG TRAIN Batch 12/7900 loss 14.415058 loss_att 15.528581 loss_ctc 17.513014 loss_rnnt 13.744189 hw_loss 0.065819 lr 0.00048116 rank 0
2023-02-22 01:04:13,480 DEBUG TRAIN Batch 12/7900 loss 12.607952 loss_att 16.549696 loss_ctc 18.587978 loss_rnnt 10.996384 hw_loss 0.048529 lr 0.00048108 rank 2
2023-02-22 01:04:13,483 DEBUG TRAIN Batch 12/7900 loss 9.583703 loss_att 13.887505 loss_ctc 12.017294 loss_rnnt 8.330748 hw_loss 0.126968 lr 0.00048113 rank 4
2023-02-22 01:05:29,544 DEBUG TRAIN Batch 12/8000 loss 16.304270 loss_att 18.113415 loss_ctc 20.875561 loss_rnnt 15.310436 hw_loss 0.042184 lr 0.00048088 rank 7
2023-02-22 01:05:29,549 DEBUG TRAIN Batch 12/8000 loss 12.679512 loss_att 16.578897 loss_ctc 13.104687 loss_rnnt 11.795005 hw_loss 0.089890 lr 0.00048088 rank 5
2023-02-22 01:05:29,552 DEBUG TRAIN Batch 12/8000 loss 17.015055 loss_att 17.554796 loss_ctc 19.738375 loss_rnnt 16.511354 hw_loss 0.061201 lr 0.00048086 rank 2
2023-02-22 01:05:29,552 DEBUG TRAIN Batch 12/8000 loss 16.359650 loss_att 22.150057 loss_ctc 19.614246 loss_rnnt 14.694162 hw_loss 0.137735 lr 0.00048094 rank 0
2023-02-22 01:05:29,552 DEBUG TRAIN Batch 12/8000 loss 24.707455 loss_att 27.137598 loss_ctc 32.100960 loss_rnnt 23.129471 hw_loss 0.199038 lr 0.00048092 rank 1
2023-02-22 01:05:29,555 DEBUG TRAIN Batch 12/8000 loss 15.501672 loss_att 20.656593 loss_ctc 16.797590 loss_rnnt 14.213202 hw_loss 0.158809 lr 0.00048088 rank 6
2023-02-22 01:05:29,557 DEBUG TRAIN Batch 12/8000 loss 8.358215 loss_att 12.508589 loss_ctc 10.983610 loss_rnnt 6.985873 hw_loss 0.360404 lr 0.00048091 rank 4
2023-02-22 01:05:29,597 DEBUG TRAIN Batch 12/8000 loss 11.804508 loss_att 15.029536 loss_ctc 15.725115 loss_rnnt 10.587252 hw_loss 0.092819 lr 0.00048088 rank 3
2023-02-22 01:06:44,180 DEBUG TRAIN Batch 12/8100 loss 13.882700 loss_att 19.231615 loss_ctc 15.620662 loss_rnnt 12.492656 hw_loss 0.166000 lr 0.00048066 rank 7
2023-02-22 01:06:44,181 DEBUG TRAIN Batch 12/8100 loss 14.156745 loss_att 17.009052 loss_ctc 16.975407 loss_rnnt 13.139378 hw_loss 0.133284 lr 0.00048072 rank 0
2023-02-22 01:06:44,186 DEBUG TRAIN Batch 12/8100 loss 13.565660 loss_att 18.962944 loss_ctc 16.764835 loss_rnnt 11.954594 hw_loss 0.196975 lr 0.00048068 rank 4
2023-02-22 01:06:44,187 DEBUG TRAIN Batch 12/8100 loss 12.135263 loss_att 15.362165 loss_ctc 16.229939 loss_rnnt 10.832478 hw_loss 0.208967 lr 0.00048066 rank 5
2023-02-22 01:06:44,190 DEBUG TRAIN Batch 12/8100 loss 11.758737 loss_att 15.113892 loss_ctc 13.091155 loss_rnnt 10.779093 hw_loss 0.245544 lr 0.00048064 rank 2
2023-02-22 01:06:44,192 DEBUG TRAIN Batch 12/8100 loss 24.050642 loss_att 28.006737 loss_ctc 25.688736 loss_rnnt 22.978176 hw_loss 0.117814 lr 0.00048066 rank 6
2023-02-22 01:06:44,215 DEBUG TRAIN Batch 12/8100 loss 14.037314 loss_att 17.677492 loss_ctc 19.247478 loss_rnnt 12.504806 hw_loss 0.205848 lr 0.00048066 rank 3
2023-02-22 01:06:44,253 DEBUG TRAIN Batch 12/8100 loss 17.679840 loss_att 19.089439 loss_ctc 19.395432 loss_rnnt 17.139488 hw_loss 0.055660 lr 0.00048070 rank 1
2023-02-22 01:08:01,105 DEBUG TRAIN Batch 12/8200 loss 25.666988 loss_att 25.988110 loss_ctc 28.484642 loss_rnnt 25.182962 hw_loss 0.082713 lr 0.00048043 rank 5
2023-02-22 01:08:01,106 DEBUG TRAIN Batch 12/8200 loss 15.748155 loss_att 19.002932 loss_ctc 20.539127 loss_rnnt 14.382334 hw_loss 0.142626 lr 0.00048044 rank 7
2023-02-22 01:08:01,108 DEBUG TRAIN Batch 12/8200 loss 16.615973 loss_att 20.472416 loss_ctc 21.430780 loss_rnnt 15.116051 hw_loss 0.162488 lr 0.00048050 rank 0
2023-02-22 01:08:01,111 DEBUG TRAIN Batch 12/8200 loss 12.715831 loss_att 13.916008 loss_ctc 17.109478 loss_rnnt 11.764759 hw_loss 0.234781 lr 0.00048046 rank 4
2023-02-22 01:08:01,112 DEBUG TRAIN Batch 12/8200 loss 15.229604 loss_att 17.205746 loss_ctc 21.129011 loss_rnnt 13.912491 hw_loss 0.253681 lr 0.00048043 rank 3
2023-02-22 01:08:01,112 DEBUG TRAIN Batch 12/8200 loss 21.349251 loss_att 26.659929 loss_ctc 28.794836 loss_rnnt 19.226870 hw_loss 0.126560 lr 0.00048048 rank 1
2023-02-22 01:08:01,113 DEBUG TRAIN Batch 12/8200 loss 4.973691 loss_att 8.806248 loss_ctc 6.695521 loss_rnnt 3.923370 hw_loss 0.101687 lr 0.00048044 rank 6
2023-02-22 01:08:01,159 DEBUG TRAIN Batch 12/8200 loss 20.416735 loss_att 22.349594 loss_ctc 31.676664 loss_rnnt 18.408697 hw_loss 0.225261 lr 0.00048041 rank 2
2023-02-22 01:09:15,036 DEBUG TRAIN Batch 12/8300 loss 9.303027 loss_att 9.709051 loss_ctc 11.394884 loss_rnnt 8.793769 hw_loss 0.279636 lr 0.00048021 rank 5
2023-02-22 01:09:15,037 DEBUG TRAIN Batch 12/8300 loss 16.694059 loss_att 20.226082 loss_ctc 22.262314 loss_rnnt 15.190132 hw_loss 0.103295 lr 0.00048024 rank 4
2023-02-22 01:09:15,041 DEBUG TRAIN Batch 12/8300 loss 22.986591 loss_att 27.260616 loss_ctc 29.086126 loss_rnnt 21.260754 hw_loss 0.108303 lr 0.00048022 rank 7
2023-02-22 01:09:15,042 DEBUG TRAIN Batch 12/8300 loss 23.484291 loss_att 24.609573 loss_ctc 27.011944 loss_rnnt 22.685631 hw_loss 0.193592 lr 0.00048026 rank 1
2023-02-22 01:09:15,041 DEBUG TRAIN Batch 12/8300 loss 29.933924 loss_att 34.740803 loss_ctc 35.406124 loss_rnnt 28.222931 hw_loss 0.037479 lr 0.00048027 rank 0
2023-02-22 01:09:15,043 DEBUG TRAIN Batch 12/8300 loss 4.415231 loss_att 10.196749 loss_ctc 5.224263 loss_rnnt 3.091465 hw_loss 0.111732 lr 0.00048019 rank 2
2023-02-22 01:09:15,045 DEBUG TRAIN Batch 12/8300 loss 14.373035 loss_att 19.717514 loss_ctc 22.156006 loss_rnnt 12.158691 hw_loss 0.201972 lr 0.00048021 rank 3
2023-02-22 01:09:15,089 DEBUG TRAIN Batch 12/8300 loss 9.606886 loss_att 10.572393 loss_ctc 11.222988 loss_rnnt 9.035007 hw_loss 0.306184 lr 0.00048021 rank 6
2023-02-22 01:10:02,788 DEBUG CV Batch 12/0 loss 3.530832 loss_att 3.295005 loss_ctc 4.553947 loss_rnnt 3.258364 hw_loss 0.343533 history loss 3.400060 rank 1
2023-02-22 01:10:02,790 DEBUG CV Batch 12/0 loss 3.530832 loss_att 3.295005 loss_ctc 4.553947 loss_rnnt 3.258364 hw_loss 0.343533 history loss 3.400060 rank 0
2023-02-22 01:10:02,791 DEBUG CV Batch 12/0 loss 3.530832 loss_att 3.295005 loss_ctc 4.553947 loss_rnnt 3.258364 hw_loss 0.343533 history loss 3.400060 rank 6
2023-02-22 01:10:02,791 DEBUG CV Batch 12/0 loss 3.530832 loss_att 3.295005 loss_ctc 4.553947 loss_rnnt 3.258364 hw_loss 0.343533 history loss 3.400060 rank 7
2023-02-22 01:10:02,792 DEBUG CV Batch 12/0 loss 3.530832 loss_att 3.295005 loss_ctc 4.553947 loss_rnnt 3.258364 hw_loss 0.343533 history loss 3.400060 rank 3
2023-02-22 01:10:02,796 DEBUG CV Batch 12/0 loss 3.530832 loss_att 3.295005 loss_ctc 4.553947 loss_rnnt 3.258364 hw_loss 0.343533 history loss 3.400060 rank 5
2023-02-22 01:10:02,805 DEBUG CV Batch 12/0 loss 3.530832 loss_att 3.295005 loss_ctc 4.553947 loss_rnnt 3.258364 hw_loss 0.343533 history loss 3.400060 rank 2
2023-02-22 01:10:02,810 DEBUG CV Batch 12/0 loss 3.530832 loss_att 3.295005 loss_ctc 4.553947 loss_rnnt 3.258364 hw_loss 0.343533 history loss 3.400060 rank 4
2023-02-22 01:10:13,884 DEBUG CV Batch 12/100 loss 13.900404 loss_att 11.319187 loss_ctc 14.351947 loss_rnnt 14.257843 hw_loss 0.184872 history loss 4.792493 rank 0
2023-02-22 01:10:13,932 DEBUG CV Batch 12/100 loss 13.900404 loss_att 11.319187 loss_ctc 14.351947 loss_rnnt 14.257843 hw_loss 0.184872 history loss 4.792493 rank 7
2023-02-22 01:10:14,024 DEBUG CV Batch 12/100 loss 13.900404 loss_att 11.319187 loss_ctc 14.351947 loss_rnnt 14.257843 hw_loss 0.184872 history loss 4.792493 rank 6
2023-02-22 01:10:14,046 DEBUG CV Batch 12/100 loss 13.900404 loss_att 11.319187 loss_ctc 14.351947 loss_rnnt 14.257843 hw_loss 0.184872 history loss 4.792493 rank 1
2023-02-22 01:10:14,046 DEBUG CV Batch 12/100 loss 13.900404 loss_att 11.319187 loss_ctc 14.351947 loss_rnnt 14.257843 hw_loss 0.184872 history loss 4.792493 rank 5
2023-02-22 01:10:14,048 DEBUG CV Batch 12/100 loss 13.900404 loss_att 11.319187 loss_ctc 14.351947 loss_rnnt 14.257843 hw_loss 0.184872 history loss 4.792493 rank 4
2023-02-22 01:10:14,147 DEBUG CV Batch 12/100 loss 13.900404 loss_att 11.319187 loss_ctc 14.351947 loss_rnnt 14.257843 hw_loss 0.184872 history loss 4.792493 rank 3
2023-02-22 01:10:14,358 DEBUG CV Batch 12/100 loss 13.900404 loss_att 11.319187 loss_ctc 14.351947 loss_rnnt 14.257843 hw_loss 0.184872 history loss 4.792493 rank 2
2023-02-22 01:10:27,149 DEBUG CV Batch 12/200 loss 14.092881 loss_att 24.018768 loss_ctc 18.996162 loss_rnnt 11.358234 hw_loss 0.179433 history loss 5.529562 rank 0
2023-02-22 01:10:27,274 DEBUG CV Batch 12/200 loss 14.092881 loss_att 24.018768 loss_ctc 18.996162 loss_rnnt 11.358234 hw_loss 0.179433 history loss 5.529562 rank 7
2023-02-22 01:10:27,362 DEBUG CV Batch 12/200 loss 14.092881 loss_att 24.018768 loss_ctc 18.996162 loss_rnnt 11.358234 hw_loss 0.179433 history loss 5.529562 rank 5
2023-02-22 01:10:27,410 DEBUG CV Batch 12/200 loss 14.092881 loss_att 24.018768 loss_ctc 18.996162 loss_rnnt 11.358234 hw_loss 0.179433 history loss 5.529562 rank 4
2023-02-22 01:10:27,505 DEBUG CV Batch 12/200 loss 14.092881 loss_att 24.018768 loss_ctc 18.996162 loss_rnnt 11.358234 hw_loss 0.179433 history loss 5.529562 rank 6
2023-02-22 01:10:27,553 DEBUG CV Batch 12/200 loss 14.092881 loss_att 24.018768 loss_ctc 18.996162 loss_rnnt 11.358234 hw_loss 0.179433 history loss 5.529562 rank 1
2023-02-22 01:10:27,644 DEBUG CV Batch 12/200 loss 14.092881 loss_att 24.018768 loss_ctc 18.996162 loss_rnnt 11.358234 hw_loss 0.179433 history loss 5.529562 rank 3
2023-02-22 01:10:28,242 DEBUG CV Batch 12/200 loss 14.092881 loss_att 24.018768 loss_ctc 18.996162 loss_rnnt 11.358234 hw_loss 0.179433 history loss 5.529562 rank 2
2023-02-22 01:10:39,203 DEBUG CV Batch 12/300 loss 5.612884 loss_att 6.277378 loss_ctc 8.384079 loss_rnnt 4.955364 hw_loss 0.290865 history loss 5.624925 rank 0
2023-02-22 01:10:39,286 DEBUG CV Batch 12/300 loss 5.612884 loss_att 6.277378 loss_ctc 8.384079 loss_rnnt 4.955364 hw_loss 0.290865 history loss 5.624925 rank 7
2023-02-22 01:10:39,485 DEBUG CV Batch 12/300 loss 5.612884 loss_att 6.277378 loss_ctc 8.384079 loss_rnnt 4.955364 hw_loss 0.290865 history loss 5.624925 rank 5
2023-02-22 01:10:39,523 DEBUG CV Batch 12/300 loss 5.612884 loss_att 6.277378 loss_ctc 8.384079 loss_rnnt 4.955364 hw_loss 0.290865 history loss 5.624925 rank 4
2023-02-22 01:10:39,648 DEBUG CV Batch 12/300 loss 5.612884 loss_att 6.277378 loss_ctc 8.384079 loss_rnnt 4.955364 hw_loss 0.290865 history loss 5.624925 rank 1
2023-02-22 01:10:39,833 DEBUG CV Batch 12/300 loss 5.612884 loss_att 6.277378 loss_ctc 8.384079 loss_rnnt 4.955364 hw_loss 0.290865 history loss 5.624925 rank 3
2023-02-22 01:10:40,380 DEBUG CV Batch 12/300 loss 5.612884 loss_att 6.277378 loss_ctc 8.384079 loss_rnnt 4.955364 hw_loss 0.290865 history loss 5.624925 rank 6
2023-02-22 01:10:40,489 DEBUG CV Batch 12/300 loss 5.612884 loss_att 6.277378 loss_ctc 8.384079 loss_rnnt 4.955364 hw_loss 0.290865 history loss 5.624925 rank 2
2023-02-22 01:10:51,337 DEBUG CV Batch 12/400 loss 22.858650 loss_att 106.435440 loss_ctc 7.395514 loss_rnnt 8.082366 hw_loss 0.230017 history loss 6.743087 rank 0
2023-02-22 01:10:51,407 DEBUG CV Batch 12/400 loss 22.858650 loss_att 106.435440 loss_ctc 7.395514 loss_rnnt 8.082366 hw_loss 0.230017 history loss 6.743087 rank 7
2023-02-22 01:10:51,564 DEBUG CV Batch 12/400 loss 22.858650 loss_att 106.435440 loss_ctc 7.395514 loss_rnnt 8.082366 hw_loss 0.230017 history loss 6.743087 rank 4
2023-02-22 01:10:51,720 DEBUG CV Batch 12/400 loss 22.858650 loss_att 106.435440 loss_ctc 7.395514 loss_rnnt 8.082366 hw_loss 0.230017 history loss 6.743087 rank 5
2023-02-22 01:10:52,108 DEBUG CV Batch 12/400 loss 22.858650 loss_att 106.435440 loss_ctc 7.395514 loss_rnnt 8.082366 hw_loss 0.230017 history loss 6.743087 rank 3
2023-02-22 01:10:52,610 DEBUG CV Batch 12/400 loss 22.858650 loss_att 106.435440 loss_ctc 7.395514 loss_rnnt 8.082366 hw_loss 0.230017 history loss 6.743087 rank 6
2023-02-22 01:10:52,759 DEBUG CV Batch 12/400 loss 22.858650 loss_att 106.435440 loss_ctc 7.395514 loss_rnnt 8.082366 hw_loss 0.230017 history loss 6.743087 rank 2
2023-02-22 01:10:52,808 DEBUG CV Batch 12/400 loss 22.858650 loss_att 106.435440 loss_ctc 7.395514 loss_rnnt 8.082366 hw_loss 0.230017 history loss 6.743087 rank 1
2023-02-22 01:11:01,777 DEBUG CV Batch 12/500 loss 5.623692 loss_att 7.084677 loss_ctc 7.477371 loss_rnnt 5.029932 hw_loss 0.102011 history loss 7.733219 rank 0
2023-02-22 01:11:01,974 DEBUG CV Batch 12/500 loss 5.623692 loss_att 7.084677 loss_ctc 7.477371 loss_rnnt 5.029932 hw_loss 0.102011 history loss 7.733219 rank 7
2023-02-22 01:11:02,138 DEBUG CV Batch 12/500 loss 5.623692 loss_att 7.084677 loss_ctc 7.477371 loss_rnnt 5.029932 hw_loss 0.102011 history loss 7.733219 rank 4
2023-02-22 01:11:02,332 DEBUG CV Batch 12/500 loss 5.623692 loss_att 7.084677 loss_ctc 7.477371 loss_rnnt 5.029932 hw_loss 0.102011 history loss 7.733219 rank 5
2023-02-22 01:11:02,755 DEBUG CV Batch 12/500 loss 5.623692 loss_att 7.084677 loss_ctc 7.477371 loss_rnnt 5.029932 hw_loss 0.102011 history loss 7.733219 rank 3
2023-02-22 01:11:03,259 DEBUG CV Batch 12/500 loss 5.623692 loss_att 7.084677 loss_ctc 7.477371 loss_rnnt 5.029932 hw_loss 0.102011 history loss 7.733219 rank 6
2023-02-22 01:11:03,625 DEBUG CV Batch 12/500 loss 5.623692 loss_att 7.084677 loss_ctc 7.477371 loss_rnnt 5.029932 hw_loss 0.102011 history loss 7.733219 rank 2
2023-02-22 01:11:03,632 DEBUG CV Batch 12/500 loss 5.623692 loss_att 7.084677 loss_ctc 7.477371 loss_rnnt 5.029932 hw_loss 0.102011 history loss 7.733219 rank 1
2023-02-22 01:11:13,857 DEBUG CV Batch 12/600 loss 8.537681 loss_att 8.569127 loss_ctc 11.016175 loss_rnnt 8.028850 hw_loss 0.322643 history loss 8.713790 rank 0
2023-02-22 01:11:14,084 DEBUG CV Batch 12/600 loss 8.537681 loss_att 8.569127 loss_ctc 11.016175 loss_rnnt 8.028850 hw_loss 0.322643 history loss 8.713790 rank 7
2023-02-22 01:11:14,325 DEBUG CV Batch 12/600 loss 8.537681 loss_att 8.569127 loss_ctc 11.016175 loss_rnnt 8.028850 hw_loss 0.322643 history loss 8.713790 rank 4
2023-02-22 01:11:14,406 DEBUG CV Batch 12/600 loss 8.537681 loss_att 8.569127 loss_ctc 11.016175 loss_rnnt 8.028850 hw_loss 0.322643 history loss 8.713790 rank 5
2023-02-22 01:11:15,003 DEBUG CV Batch 12/600 loss 8.537681 loss_att 8.569127 loss_ctc 11.016175 loss_rnnt 8.028850 hw_loss 0.322643 history loss 8.713790 rank 3
2023-02-22 01:11:15,807 DEBUG CV Batch 12/600 loss 8.537681 loss_att 8.569127 loss_ctc 11.016175 loss_rnnt 8.028850 hw_loss 0.322643 history loss 8.713790 rank 2
2023-02-22 01:11:15,845 DEBUG CV Batch 12/600 loss 8.537681 loss_att 8.569127 loss_ctc 11.016175 loss_rnnt 8.028850 hw_loss 0.322643 history loss 8.713790 rank 6
2023-02-22 01:11:15,891 DEBUG CV Batch 12/600 loss 8.537681 loss_att 8.569127 loss_ctc 11.016175 loss_rnnt 8.028850 hw_loss 0.322643 history loss 8.713790 rank 1
2023-02-22 01:11:25,190 DEBUG CV Batch 12/700 loss 27.364233 loss_att 90.704857 loss_ctc 25.663319 loss_rnnt 14.893791 hw_loss 0.054573 history loss 9.562683 rank 0
2023-02-22 01:11:25,489 DEBUG CV Batch 12/700 loss 27.364233 loss_att 90.704857 loss_ctc 25.663319 loss_rnnt 14.893791 hw_loss 0.054573 history loss 9.562683 rank 7
2023-02-22 01:11:25,647 DEBUG CV Batch 12/700 loss 27.364233 loss_att 90.704857 loss_ctc 25.663319 loss_rnnt 14.893791 hw_loss 0.054573 history loss 9.562683 rank 4
2023-02-22 01:11:25,879 DEBUG CV Batch 12/700 loss 27.364233 loss_att 90.704857 loss_ctc 25.663319 loss_rnnt 14.893791 hw_loss 0.054573 history loss 9.562683 rank 5
2023-02-22 01:11:26,474 DEBUG CV Batch 12/700 loss 27.364233 loss_att 90.704857 loss_ctc 25.663319 loss_rnnt 14.893791 hw_loss 0.054573 history loss 9.562683 rank 3
2023-02-22 01:11:27,298 DEBUG CV Batch 12/700 loss 27.364233 loss_att 90.704857 loss_ctc 25.663319 loss_rnnt 14.893791 hw_loss 0.054573 history loss 9.562683 rank 2
2023-02-22 01:11:27,336 DEBUG CV Batch 12/700 loss 27.364233 loss_att 90.704857 loss_ctc 25.663319 loss_rnnt 14.893791 hw_loss 0.054573 history loss 9.562683 rank 6
2023-02-22 01:11:28,222 DEBUG CV Batch 12/700 loss 27.364233 loss_att 90.704857 loss_ctc 25.663319 loss_rnnt 14.893791 hw_loss 0.054573 history loss 9.562683 rank 1
2023-02-22 01:11:36,286 DEBUG CV Batch 12/800 loss 17.780825 loss_att 14.147276 loss_ctc 19.283741 loss_rnnt 18.153715 hw_loss 0.287680 history loss 8.920301 rank 0
2023-02-22 01:11:36,830 DEBUG CV Batch 12/800 loss 17.780825 loss_att 14.147276 loss_ctc 19.283741 loss_rnnt 18.153715 hw_loss 0.287680 history loss 8.920301 rank 7
2023-02-22 01:11:36,939 DEBUG CV Batch 12/800 loss 17.780825 loss_att 14.147276 loss_ctc 19.283741 loss_rnnt 18.153715 hw_loss 0.287680 history loss 8.920301 rank 4
2023-02-22 01:11:37,069 DEBUG CV Batch 12/800 loss 17.780825 loss_att 14.147276 loss_ctc 19.283741 loss_rnnt 18.153715 hw_loss 0.287680 history loss 8.920301 rank 5
2023-02-22 01:11:37,817 DEBUG CV Batch 12/800 loss 17.780825 loss_att 14.147276 loss_ctc 19.283741 loss_rnnt 18.153715 hw_loss 0.287680 history loss 8.920301 rank 3
2023-02-22 01:11:38,592 DEBUG CV Batch 12/800 loss 17.780825 loss_att 14.147276 loss_ctc 19.283741 loss_rnnt 18.153715 hw_loss 0.287680 history loss 8.920301 rank 2
2023-02-22 01:11:38,811 DEBUG CV Batch 12/800 loss 17.780825 loss_att 14.147276 loss_ctc 19.283741 loss_rnnt 18.153715 hw_loss 0.287680 history loss 8.920301 rank 6
2023-02-22 01:11:40,223 DEBUG CV Batch 12/800 loss 17.780825 loss_att 14.147276 loss_ctc 19.283741 loss_rnnt 18.153715 hw_loss 0.287680 history loss 8.920301 rank 1
2023-02-22 01:11:49,738 DEBUG CV Batch 12/900 loss 23.698196 loss_att 38.282463 loss_ctc 29.146191 loss_rnnt 20.053331 hw_loss 0.003022 history loss 8.701943 rank 0
2023-02-22 01:11:50,062 DEBUG CV Batch 12/900 loss 23.698196 loss_att 38.282463 loss_ctc 29.146191 loss_rnnt 20.053331 hw_loss 0.003022 history loss 8.701943 rank 7
2023-02-22 01:11:50,244 DEBUG CV Batch 12/900 loss 23.698196 loss_att 38.282463 loss_ctc 29.146191 loss_rnnt 20.053331 hw_loss 0.003022 history loss 8.701943 rank 4
2023-02-22 01:11:50,473 DEBUG CV Batch 12/900 loss 23.698196 loss_att 38.282463 loss_ctc 29.146191 loss_rnnt 20.053331 hw_loss 0.003022 history loss 8.701943 rank 5
2023-02-22 01:11:51,176 DEBUG CV Batch 12/900 loss 23.698196 loss_att 38.282463 loss_ctc 29.146191 loss_rnnt 20.053331 hw_loss 0.003022 history loss 8.701943 rank 3
2023-02-22 01:11:51,876 DEBUG CV Batch 12/900 loss 23.698196 loss_att 38.282463 loss_ctc 29.146191 loss_rnnt 20.053331 hw_loss 0.003022 history loss 8.701943 rank 2
2023-02-22 01:11:52,890 DEBUG CV Batch 12/900 loss 23.698196 loss_att 38.282463 loss_ctc 29.146191 loss_rnnt 20.053331 hw_loss 0.003022 history loss 8.701943 rank 6
2023-02-22 01:11:53,522 DEBUG CV Batch 12/900 loss 23.698196 loss_att 38.282463 loss_ctc 29.146191 loss_rnnt 20.053331 hw_loss 0.003022 history loss 8.701943 rank 1
2023-02-22 01:12:02,148 DEBUG CV Batch 12/1000 loss 6.205618 loss_att 7.483746 loss_ctc 7.453299 loss_rnnt 5.721239 hw_loss 0.116994 history loss 8.404500 rank 0
2023-02-22 01:12:02,185 DEBUG CV Batch 12/1000 loss 6.205618 loss_att 7.483746 loss_ctc 7.453299 loss_rnnt 5.721239 hw_loss 0.116994 history loss 8.404500 rank 7
2023-02-22 01:12:02,324 DEBUG CV Batch 12/1000 loss 6.205618 loss_att 7.483746 loss_ctc 7.453299 loss_rnnt 5.721239 hw_loss 0.116994 history loss 8.404500 rank 4
2023-02-22 01:12:02,654 DEBUG CV Batch 12/1000 loss 6.205618 loss_att 7.483746 loss_ctc 7.453299 loss_rnnt 5.721239 hw_loss 0.116994 history loss 8.404500 rank 5
2023-02-22 01:12:03,543 DEBUG CV Batch 12/1000 loss 6.205618 loss_att 7.483746 loss_ctc 7.453299 loss_rnnt 5.721239 hw_loss 0.116994 history loss 8.404500 rank 3
2023-02-22 01:12:04,174 DEBUG CV Batch 12/1000 loss 6.205618 loss_att 7.483746 loss_ctc 7.453299 loss_rnnt 5.721239 hw_loss 0.116994 history loss 8.404500 rank 2
2023-02-22 01:12:05,443 DEBUG CV Batch 12/1000 loss 6.205618 loss_att 7.483746 loss_ctc 7.453299 loss_rnnt 5.721239 hw_loss 0.116994 history loss 8.404500 rank 6
2023-02-22 01:12:06,025 DEBUG CV Batch 12/1000 loss 6.205618 loss_att 7.483746 loss_ctc 7.453299 loss_rnnt 5.721239 hw_loss 0.116994 history loss 8.404500 rank 1
2023-02-22 01:12:14,118 DEBUG CV Batch 12/1100 loss 8.504781 loss_att 7.595539 loss_ctc 10.268478 loss_rnnt 8.252295 hw_loss 0.373453 history loss 8.386692 rank 0
2023-02-22 01:12:14,141 DEBUG CV Batch 12/1100 loss 8.504781 loss_att 7.595539 loss_ctc 10.268478 loss_rnnt 8.252295 hw_loss 0.373453 history loss 8.386692 rank 7
2023-02-22 01:12:14,258 DEBUG CV Batch 12/1100 loss 8.504781 loss_att 7.595539 loss_ctc 10.268478 loss_rnnt 8.252295 hw_loss 0.373453 history loss 8.386692 rank 4
2023-02-22 01:12:14,558 DEBUG CV Batch 12/1100 loss 8.504781 loss_att 7.595539 loss_ctc 10.268478 loss_rnnt 8.252295 hw_loss 0.373453 history loss 8.386692 rank 5
2023-02-22 01:12:15,503 DEBUG CV Batch 12/1100 loss 8.504781 loss_att 7.595539 loss_ctc 10.268478 loss_rnnt 8.252295 hw_loss 0.373453 history loss 8.386692 rank 3
2023-02-22 01:12:16,308 DEBUG CV Batch 12/1100 loss 8.504781 loss_att 7.595539 loss_ctc 10.268478 loss_rnnt 8.252295 hw_loss 0.373453 history loss 8.386692 rank 2
2023-02-22 01:12:17,468 DEBUG CV Batch 12/1100 loss 8.504781 loss_att 7.595539 loss_ctc 10.268478 loss_rnnt 8.252295 hw_loss 0.373453 history loss 8.386692 rank 6
2023-02-22 01:12:18,031 DEBUG CV Batch 12/1100 loss 8.504781 loss_att 7.595539 loss_ctc 10.268478 loss_rnnt 8.252295 hw_loss 0.373453 history loss 8.386692 rank 1
2023-02-22 01:12:24,656 DEBUG CV Batch 12/1200 loss 7.660513 loss_att 8.568495 loss_ctc 9.796426 loss_rnnt 7.049010 hw_loss 0.272098 history loss 8.794415 rank 0
2023-02-22 01:12:24,749 DEBUG CV Batch 12/1200 loss 7.660513 loss_att 8.568495 loss_ctc 9.796426 loss_rnnt 7.049010 hw_loss 0.272098 history loss 8.794415 rank 7
2023-02-22 01:12:24,837 DEBUG CV Batch 12/1200 loss 7.660513 loss_att 8.568495 loss_ctc 9.796426 loss_rnnt 7.049010 hw_loss 0.272098 history loss 8.794415 rank 4
2023-02-22 01:12:25,155 DEBUG CV Batch 12/1200 loss 7.660513 loss_att 8.568495 loss_ctc 9.796426 loss_rnnt 7.049010 hw_loss 0.272098 history loss 8.794415 rank 5
2023-02-22 01:12:26,175 DEBUG CV Batch 12/1200 loss 7.660513 loss_att 8.568495 loss_ctc 9.796426 loss_rnnt 7.049010 hw_loss 0.272098 history loss 8.794415 rank 3
2023-02-22 01:12:27,042 DEBUG CV Batch 12/1200 loss 7.660513 loss_att 8.568495 loss_ctc 9.796426 loss_rnnt 7.049010 hw_loss 0.272098 history loss 8.794415 rank 2
2023-02-22 01:12:28,125 DEBUG CV Batch 12/1200 loss 7.660513 loss_att 8.568495 loss_ctc 9.796426 loss_rnnt 7.049010 hw_loss 0.272098 history loss 8.794415 rank 6
2023-02-22 01:12:29,061 DEBUG CV Batch 12/1200 loss 7.660513 loss_att 8.568495 loss_ctc 9.796426 loss_rnnt 7.049010 hw_loss 0.272098 history loss 8.794415 rank 1
2023-02-22 01:12:36,659 DEBUG CV Batch 12/1300 loss 8.043350 loss_att 7.120252 loss_ctc 9.798132 loss_rnnt 7.843328 hw_loss 0.282508 history loss 9.111635 rank 7
2023-02-22 01:12:36,671 DEBUG CV Batch 12/1300 loss 8.043350 loss_att 7.120252 loss_ctc 9.798132 loss_rnnt 7.843328 hw_loss 0.282508 history loss 9.111635 rank 0
2023-02-22 01:12:36,758 DEBUG CV Batch 12/1300 loss 8.043350 loss_att 7.120252 loss_ctc 9.798132 loss_rnnt 7.843328 hw_loss 0.282508 history loss 9.111635 rank 4
2023-02-22 01:12:37,059 DEBUG CV Batch 12/1300 loss 8.043350 loss_att 7.120252 loss_ctc 9.798132 loss_rnnt 7.843328 hw_loss 0.282508 history loss 9.111635 rank 5
2023-02-22 01:12:38,225 DEBUG CV Batch 12/1300 loss 8.043350 loss_att 7.120252 loss_ctc 9.798132 loss_rnnt 7.843328 hw_loss 0.282508 history loss 9.111635 rank 3
2023-02-22 01:12:39,149 DEBUG CV Batch 12/1300 loss 8.043350 loss_att 7.120252 loss_ctc 9.798132 loss_rnnt 7.843328 hw_loss 0.282508 history loss 9.111635 rank 2
2023-02-22 01:12:40,226 DEBUG CV Batch 12/1300 loss 8.043350 loss_att 7.120252 loss_ctc 9.798132 loss_rnnt 7.843328 hw_loss 0.282508 history loss 9.111635 rank 6
2023-02-22 01:12:41,508 DEBUG CV Batch 12/1300 loss 8.043350 loss_att 7.120252 loss_ctc 9.798132 loss_rnnt 7.843328 hw_loss 0.282508 history loss 9.111635 rank 1
2023-02-22 01:12:47,809 DEBUG CV Batch 12/1400 loss 14.941293 loss_att 56.598675 loss_ctc 8.012219 loss_rnnt 7.532252 hw_loss 0.002701 history loss 9.515695 rank 7
2023-02-22 01:12:47,861 DEBUG CV Batch 12/1400 loss 14.941293 loss_att 56.598675 loss_ctc 8.012219 loss_rnnt 7.532252 hw_loss 0.002701 history loss 9.515695 rank 0
2023-02-22 01:12:47,926 DEBUG CV Batch 12/1400 loss 14.941293 loss_att 56.598675 loss_ctc 8.012219 loss_rnnt 7.532252 hw_loss 0.002701 history loss 9.515695 rank 4
2023-02-22 01:12:48,292 DEBUG CV Batch 12/1400 loss 14.941293 loss_att 56.598675 loss_ctc 8.012219 loss_rnnt 7.532252 hw_loss 0.002701 history loss 9.515695 rank 5
2023-02-22 01:12:49,574 DEBUG CV Batch 12/1400 loss 14.941293 loss_att 56.598675 loss_ctc 8.012219 loss_rnnt 7.532252 hw_loss 0.002701 history loss 9.515695 rank 3
2023-02-22 01:12:50,426 DEBUG CV Batch 12/1400 loss 14.941293 loss_att 56.598675 loss_ctc 8.012219 loss_rnnt 7.532252 hw_loss 0.002701 history loss 9.515695 rank 2
2023-02-22 01:12:51,603 DEBUG CV Batch 12/1400 loss 14.941293 loss_att 56.598675 loss_ctc 8.012219 loss_rnnt 7.532252 hw_loss 0.002701 history loss 9.515695 rank 6
2023-02-22 01:12:52,782 DEBUG CV Batch 12/1400 loss 14.941293 loss_att 56.598675 loss_ctc 8.012219 loss_rnnt 7.532252 hw_loss 0.002701 history loss 9.515695 rank 1
2023-02-22 01:12:59,246 DEBUG CV Batch 12/1500 loss 6.967213 loss_att 8.615896 loss_ctc 4.868368 loss_rnnt 6.854355 hw_loss 0.118064 history loss 9.285733 rank 0
2023-02-22 01:12:59,250 DEBUG CV Batch 12/1500 loss 6.967213 loss_att 8.615896 loss_ctc 4.868368 loss_rnnt 6.854355 hw_loss 0.118064 history loss 9.285733 rank 7
2023-02-22 01:12:59,372 DEBUG CV Batch 12/1500 loss 6.967213 loss_att 8.615896 loss_ctc 4.868368 loss_rnnt 6.854355 hw_loss 0.118064 history loss 9.285733 rank 4
2023-02-22 01:12:59,680 DEBUG CV Batch 12/1500 loss 6.967213 loss_att 8.615896 loss_ctc 4.868368 loss_rnnt 6.854355 hw_loss 0.118064 history loss 9.285733 rank 5
2023-02-22 01:13:01,317 DEBUG CV Batch 12/1500 loss 6.967213 loss_att 8.615896 loss_ctc 4.868368 loss_rnnt 6.854355 hw_loss 0.118064 history loss 9.285733 rank 3
2023-02-22 01:13:01,998 DEBUG CV Batch 12/1500 loss 6.967213 loss_att 8.615896 loss_ctc 4.868368 loss_rnnt 6.854355 hw_loss 0.118064 history loss 9.285733 rank 2
2023-02-22 01:13:03,036 DEBUG CV Batch 12/1500 loss 6.967213 loss_att 8.615896 loss_ctc 4.868368 loss_rnnt 6.854355 hw_loss 0.118064 history loss 9.285733 rank 6
2023-02-22 01:13:04,347 DEBUG CV Batch 12/1500 loss 6.967213 loss_att 8.615896 loss_ctc 4.868368 loss_rnnt 6.854355 hw_loss 0.118064 history loss 9.285733 rank 1
2023-02-22 01:13:12,065 DEBUG CV Batch 12/1600 loss 10.970129 loss_att 19.310490 loss_ctc 11.662808 loss_rnnt 9.161674 hw_loss 0.090051 history loss 9.197628 rank 7
2023-02-22 01:13:12,116 DEBUG CV Batch 12/1600 loss 10.970129 loss_att 19.310490 loss_ctc 11.662808 loss_rnnt 9.161674 hw_loss 0.090051 history loss 9.197628 rank 0
2023-02-22 01:13:12,349 DEBUG CV Batch 12/1600 loss 10.970129 loss_att 19.310490 loss_ctc 11.662808 loss_rnnt 9.161674 hw_loss 0.090051 history loss 9.197628 rank 4
2023-02-22 01:13:12,714 DEBUG CV Batch 12/1600 loss 10.970129 loss_att 19.310490 loss_ctc 11.662808 loss_rnnt 9.161674 hw_loss 0.090051 history loss 9.197628 rank 5
2023-02-22 01:13:15,051 DEBUG CV Batch 12/1600 loss 10.970129 loss_att 19.310490 loss_ctc 11.662808 loss_rnnt 9.161674 hw_loss 0.090051 history loss 9.197628 rank 2
2023-02-22 01:13:15,614 DEBUG CV Batch 12/1600 loss 10.970129 loss_att 19.310490 loss_ctc 11.662808 loss_rnnt 9.161674 hw_loss 0.090051 history loss 9.197628 rank 3
2023-02-22 01:13:16,313 DEBUG CV Batch 12/1600 loss 10.970129 loss_att 19.310490 loss_ctc 11.662808 loss_rnnt 9.161674 hw_loss 0.090051 history loss 9.197628 rank 6
2023-02-22 01:13:17,415 DEBUG CV Batch 12/1600 loss 10.970129 loss_att 19.310490 loss_ctc 11.662808 loss_rnnt 9.161674 hw_loss 0.090051 history loss 9.197628 rank 1
2023-02-22 01:13:24,329 DEBUG CV Batch 12/1700 loss 14.362054 loss_att 12.792145 loss_ctc 18.722757 loss_rnnt 13.975484 hw_loss 0.223357 history loss 9.055504 rank 7
2023-02-22 01:13:24,339 DEBUG CV Batch 12/1700 loss 14.362054 loss_att 12.792145 loss_ctc 18.722757 loss_rnnt 13.975484 hw_loss 0.223357 history loss 9.055504 rank 0
2023-02-22 01:13:24,683 DEBUG CV Batch 12/1700 loss 14.362054 loss_att 12.792145 loss_ctc 18.722757 loss_rnnt 13.975484 hw_loss 0.223357 history loss 9.055504 rank 4
2023-02-22 01:13:25,095 DEBUG CV Batch 12/1700 loss 14.362054 loss_att 12.792145 loss_ctc 18.722757 loss_rnnt 13.975484 hw_loss 0.223357 history loss 9.055504 rank 5
2023-02-22 01:13:27,370 DEBUG CV Batch 12/1700 loss 14.362054 loss_att 12.792145 loss_ctc 18.722757 loss_rnnt 13.975484 hw_loss 0.223357 history loss 9.055504 rank 2
2023-02-22 01:13:28,138 DEBUG CV Batch 12/1700 loss 14.362054 loss_att 12.792145 loss_ctc 18.722757 loss_rnnt 13.975484 hw_loss 0.223357 history loss 9.055504 rank 3
2023-02-22 01:13:29,632 DEBUG CV Batch 12/1700 loss 14.362054 loss_att 12.792145 loss_ctc 18.722757 loss_rnnt 13.975484 hw_loss 0.223357 history loss 9.055504 rank 1
2023-02-22 01:13:29,805 DEBUG CV Batch 12/1700 loss 14.362054 loss_att 12.792145 loss_ctc 18.722757 loss_rnnt 13.975484 hw_loss 0.223357 history loss 9.055504 rank 6
2023-02-22 01:13:33,312 INFO Epoch 12 CV info cv_loss 8.997521276887674
2023-02-22 01:13:33,313 INFO Checkpoint: save to checkpoint exp/2_21_rnnt_bias_loss_2_class_1word_finetune/12.pt
2023-02-22 01:13:33,358 INFO Epoch 12 CV info cv_loss 8.997521276517244
2023-02-22 01:13:33,360 INFO Epoch 13 TRAIN info lr 0.00048012821519400966
2023-02-22 01:13:33,363 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 01:13:33,670 INFO Epoch 12 CV info cv_loss 8.997521277051352
2023-02-22 01:13:33,671 INFO Epoch 13 TRAIN info lr 0.00048012157449302343
2023-02-22 01:13:33,675 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 01:13:33,948 INFO Epoch 13 TRAIN info lr 0.00048021013983558805
2023-02-22 01:13:33,952 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 01:13:34,135 INFO Epoch 12 CV info cv_loss 8.997521277378707
2023-02-22 01:13:34,136 INFO Epoch 13 TRAIN info lr 0.00048013928364134265
2023-02-22 01:13:34,140 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 01:13:36,442 INFO Epoch 12 CV info cv_loss 8.997521278619216
2023-02-22 01:13:36,443 INFO Epoch 13 TRAIN info lr 0.0004800905881979911
2023-02-22 01:13:36,448 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 01:13:37,218 INFO Epoch 12 CV info cv_loss 8.99752127520782
2023-02-22 01:13:37,219 INFO Epoch 13 TRAIN info lr 0.00048011936098725944
2023-02-22 01:13:37,222 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 01:13:38,655 INFO Epoch 12 CV info cv_loss 8.997521277551
2023-02-22 01:13:38,655 INFO Epoch 13 TRAIN info lr 0.0004802123545971549
2023-02-22 01:13:38,659 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 01:13:39,859 INFO Epoch 12 CV info cv_loss 8.997521276775684
2023-02-22 01:13:39,861 INFO Epoch 13 TRAIN info lr 0.0004801503528541973
2023-02-22 01:13:39,864 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 01:14:53,255 DEBUG TRAIN Batch 13/0 loss 8.920713 loss_att 9.517391 loss_ctc 11.779552 loss_rnnt 8.263664 hw_loss 0.293502 lr 0.00048012 rank 3
2023-02-22 01:14:53,256 DEBUG TRAIN Batch 13/0 loss 14.265826 loss_att 12.494216 loss_ctc 16.323494 loss_rnnt 14.251295 hw_loss 0.177185 lr 0.00048015 rank 6
2023-02-22 01:14:53,258 DEBUG TRAIN Batch 13/0 loss 8.979479 loss_att 8.287968 loss_ctc 11.011744 loss_rnnt 8.680808 hw_loss 0.311259 lr 0.00048012 rank 4
2023-02-22 01:14:53,260 DEBUG TRAIN Batch 13/0 loss 14.813121 loss_att 12.470384 loss_ctc 16.912439 loss_rnnt 14.862822 hw_loss 0.260508 lr 0.00048014 rank 5
2023-02-22 01:14:53,260 DEBUG TRAIN Batch 13/0 loss 15.084602 loss_att 13.497646 loss_ctc 18.147562 loss_rnnt 14.840092 hw_loss 0.287825 lr 0.00048013 rank 7
2023-02-22 01:14:53,262 DEBUG TRAIN Batch 13/0 loss 10.938783 loss_att 10.523802 loss_ctc 12.410073 loss_rnnt 10.699492 hw_loss 0.236469 lr 0.00048021 rank 0
2023-02-22 01:14:53,265 DEBUG TRAIN Batch 13/0 loss 7.775000 loss_att 7.785150 loss_ctc 10.211525 loss_rnnt 7.272972 hw_loss 0.328366 lr 0.00048009 rank 2
2023-02-22 01:14:53,287 DEBUG TRAIN Batch 13/0 loss 12.533279 loss_att 11.831432 loss_ctc 15.883336 loss_rnnt 12.054485 hw_loss 0.323416 lr 0.00048021 rank 1
2023-02-22 01:16:07,633 DEBUG TRAIN Batch 13/100 loss 11.519937 loss_att 16.358120 loss_ctc 11.313601 loss_rnnt 10.485188 hw_loss 0.177417 lr 0.00047990 rank 4
2023-02-22 01:16:07,634 DEBUG TRAIN Batch 13/100 loss 4.310056 loss_att 8.051645 loss_ctc 3.733950 loss_rnnt 3.604751 hw_loss 0.063376 lr 0.00047987 rank 2
2023-02-22 01:16:07,637 DEBUG TRAIN Batch 13/100 loss 14.123794 loss_att 19.678946 loss_ctc 20.468563 loss_rnnt 12.086075 hw_loss 0.151351 lr 0.00047993 rank 6
2023-02-22 01:16:07,637 DEBUG TRAIN Batch 13/100 loss 7.935442 loss_att 9.934780 loss_ctc 10.988799 loss_rnnt 7.071342 hw_loss 0.107096 lr 0.00047992 rank 5
2023-02-22 01:16:07,639 DEBUG TRAIN Batch 13/100 loss 25.291449 loss_att 30.037159 loss_ctc 30.635742 loss_rnnt 23.628830 hw_loss 0.001694 lr 0.00047999 rank 0
2023-02-22 01:16:07,639 DEBUG TRAIN Batch 13/100 loss 5.760934 loss_att 11.776617 loss_ctc 4.948380 loss_rnnt 4.561915 hw_loss 0.195419 lr 0.00047999 rank 1
2023-02-22 01:16:07,641 DEBUG TRAIN Batch 13/100 loss 12.163166 loss_att 19.442074 loss_ctc 13.126987 loss_rnnt 10.555454 hw_loss 0.043914 lr 0.00047990 rank 7
2023-02-22 01:16:07,644 DEBUG TRAIN Batch 13/100 loss 9.703119 loss_att 17.010876 loss_ctc 12.825071 loss_rnnt 7.787394 hw_loss 0.071088 lr 0.00047990 rank 3
2023-02-22 01:17:22,447 DEBUG TRAIN Batch 13/200 loss 10.451065 loss_att 11.230730 loss_ctc 11.532715 loss_rnnt 10.091665 hw_loss 0.111090 lr 0.00047968 rank 7
2023-02-22 01:17:22,452 DEBUG TRAIN Batch 13/200 loss 13.981436 loss_att 20.245470 loss_ctc 18.772751 loss_rnnt 12.053236 hw_loss 0.068533 lr 0.00047977 rank 1
2023-02-22 01:17:22,453 DEBUG TRAIN Batch 13/200 loss 12.556183 loss_att 13.921913 loss_ctc 17.619865 loss_rnnt 11.576550 hw_loss 0.058741 lr 0.00047968 rank 4
2023-02-22 01:17:22,454 DEBUG TRAIN Batch 13/200 loss 9.981119 loss_att 15.126167 loss_ctc 11.936530 loss_rnnt 8.611114 hw_loss 0.150513 lr 0.00047969 rank 5
2023-02-22 01:17:22,454 DEBUG TRAIN Batch 13/200 loss 6.459047 loss_att 10.203926 loss_ctc 7.063267 loss_rnnt 5.517097 hw_loss 0.210773 lr 0.00047977 rank 0
2023-02-22 01:17:22,456 DEBUG TRAIN Batch 13/200 loss 23.050661 loss_att 21.695240 loss_ctc 24.732901 loss_rnnt 23.063025 hw_loss 0.064544 lr 0.00047965 rank 2
2023-02-22 01:17:22,457 DEBUG TRAIN Batch 13/200 loss 20.337147 loss_att 25.158447 loss_ctc 28.274883 loss_rnnt 18.279652 hw_loss 0.065380 lr 0.00047971 rank 6
2023-02-22 01:17:22,458 DEBUG TRAIN Batch 13/200 loss 8.230893 loss_att 10.404374 loss_ctc 10.714564 loss_rnnt 7.365484 hw_loss 0.186669 lr 0.00047968 rank 3
2023-02-22 01:18:39,091 DEBUG TRAIN Batch 13/300 loss 16.554182 loss_att 20.109514 loss_ctc 22.905121 loss_rnnt 14.945998 hw_loss 0.094361 lr 0.00047954 rank 0
2023-02-22 01:18:39,093 DEBUG TRAIN Batch 13/300 loss 9.266424 loss_att 13.410941 loss_ctc 11.939909 loss_rnnt 8.024210 hw_loss 0.106585 lr 0.00047946 rank 4
2023-02-22 01:18:39,093 DEBUG TRAIN Batch 13/300 loss 11.851315 loss_att 15.795977 loss_ctc 16.339308 loss_rnnt 10.431640 hw_loss 0.060648 lr 0.00047949 rank 6
2023-02-22 01:18:39,095 DEBUG TRAIN Batch 13/300 loss 21.700838 loss_att 26.328068 loss_ctc 32.675064 loss_rnnt 19.263260 hw_loss 0.091689 lr 0.00047943 rank 2
2023-02-22 01:18:39,096 DEBUG TRAIN Batch 13/300 loss 16.095213 loss_att 25.166595 loss_ctc 27.938240 loss_rnnt 12.614374 hw_loss 0.164046 lr 0.00047946 rank 7
2023-02-22 01:18:39,098 DEBUG TRAIN Batch 13/300 loss 9.120865 loss_att 11.436609 loss_ctc 10.554708 loss_rnnt 8.424392 hw_loss 0.079022 lr 0.00047955 rank 1
2023-02-22 01:18:39,103 DEBUG TRAIN Batch 13/300 loss 20.304577 loss_att 24.474586 loss_ctc 26.000910 loss_rnnt 18.569761 hw_loss 0.264941 lr 0.00047945 rank 3
2023-02-22 01:18:39,103 DEBUG TRAIN Batch 13/300 loss 23.684435 loss_att 23.240112 loss_ctc 23.152130 loss_rnnt 23.757093 hw_loss 0.163465 lr 0.00047947 rank 5
2023-02-22 01:19:56,090 DEBUG TRAIN Batch 13/400 loss 10.312061 loss_att 13.704192 loss_ctc 11.899373 loss_rnnt 9.355407 hw_loss 0.124851 lr 0.00047932 rank 0
2023-02-22 01:19:56,093 DEBUG TRAIN Batch 13/400 loss 11.733057 loss_att 16.416798 loss_ctc 13.960247 loss_rnnt 10.384253 hw_loss 0.215808 lr 0.00047924 rank 7
2023-02-22 01:19:56,095 DEBUG TRAIN Batch 13/400 loss 23.900272 loss_att 24.169128 loss_ctc 26.110559 loss_rnnt 23.522226 hw_loss 0.055441 lr 0.00047927 rank 6
2023-02-22 01:19:56,095 DEBUG TRAIN Batch 13/400 loss 13.664941 loss_att 19.141428 loss_ctc 18.231789 loss_rnnt 11.909589 hw_loss 0.095891 lr 0.00047933 rank 1
2023-02-22 01:19:56,095 DEBUG TRAIN Batch 13/400 loss 16.469475 loss_att 15.979437 loss_ctc 16.787663 loss_rnnt 16.505325 hw_loss 0.036996 lr 0.00047921 rank 2
2023-02-22 01:19:56,099 DEBUG TRAIN Batch 13/400 loss 15.207651 loss_att 16.815838 loss_ctc 19.678671 loss_rnnt 14.202215 hw_loss 0.164368 lr 0.00047924 rank 4
2023-02-22 01:19:56,099 DEBUG TRAIN Batch 13/400 loss 12.676273 loss_att 13.039618 loss_ctc 14.388198 loss_rnnt 12.282004 hw_loss 0.175018 lr 0.00047925 rank 5
2023-02-22 01:19:56,100 DEBUG TRAIN Batch 13/400 loss 24.743635 loss_att 26.859705 loss_ctc 25.343487 loss_rnnt 24.137949 hw_loss 0.192168 lr 0.00047923 rank 3
2023-02-22 01:21:12,633 DEBUG TRAIN Batch 13/500 loss 24.093193 loss_att 26.174892 loss_ctc 27.789770 loss_rnnt 23.040632 hw_loss 0.268772 lr 0.00047902 rank 7
2023-02-22 01:21:12,637 DEBUG TRAIN Batch 13/500 loss 11.072669 loss_att 12.700577 loss_ctc 11.785021 loss_rnnt 10.556269 hw_loss 0.179699 lr 0.00047905 rank 6
2023-02-22 01:21:12,638 DEBUG TRAIN Batch 13/500 loss 11.970308 loss_att 14.714012 loss_ctc 14.346745 loss_rnnt 11.056498 hw_loss 0.090397 lr 0.00047902 rank 4
2023-02-22 01:21:12,639 DEBUG TRAIN Batch 13/500 loss 15.829570 loss_att 20.347553 loss_ctc 19.063541 loss_rnnt 14.407478 hw_loss 0.163686 lr 0.00047911 rank 1
2023-02-22 01:21:12,639 DEBUG TRAIN Batch 13/500 loss 10.965368 loss_att 14.282818 loss_ctc 13.046887 loss_rnnt 9.961362 hw_loss 0.118090 lr 0.00047910 rank 0
2023-02-22 01:21:12,641 DEBUG TRAIN Batch 13/500 loss 22.573141 loss_att 22.885792 loss_ctc 28.268162 loss_rnnt 21.658531 hw_loss 0.173892 lr 0.00047903 rank 5
2023-02-22 01:21:12,642 DEBUG TRAIN Batch 13/500 loss 12.625086 loss_att 16.555796 loss_ctc 13.860457 loss_rnnt 11.642580 hw_loss 0.059339 lr 0.00047899 rank 2
2023-02-22 01:21:12,688 DEBUG TRAIN Batch 13/500 loss 6.765548 loss_att 9.721490 loss_ctc 8.819788 loss_rnnt 5.805160 hw_loss 0.178688 lr 0.00047901 rank 3
2023-02-22 01:22:29,378 DEBUG TRAIN Batch 13/600 loss 15.622910 loss_att 14.793075 loss_ctc 17.504583 loss_rnnt 15.406440 hw_loss 0.246650 lr 0.00047881 rank 5
2023-02-22 01:22:29,381 DEBUG TRAIN Batch 13/600 loss 16.465117 loss_att 16.690979 loss_ctc 18.109859 loss_rnnt 16.146564 hw_loss 0.101399 lr 0.00047888 rank 0
2023-02-22 01:22:29,387 DEBUG TRAIN Batch 13/600 loss 20.931797 loss_att 20.228512 loss_ctc 24.473509 loss_rnnt 20.536222 hw_loss 0.120005 lr 0.00047880 rank 4
2023-02-22 01:22:29,389 DEBUG TRAIN Batch 13/600 loss 13.457652 loss_att 13.565987 loss_ctc 15.107492 loss_rnnt 13.088812 hw_loss 0.238492 lr 0.00047877 rank 2
2023-02-22 01:22:29,389 DEBUG TRAIN Batch 13/600 loss 16.154364 loss_att 17.065294 loss_ctc 22.079237 loss_rnnt 15.075102 hw_loss 0.200803 lr 0.00047883 rank 6
2023-02-22 01:22:29,391 DEBUG TRAIN Batch 13/600 loss 9.854130 loss_att 11.297358 loss_ctc 12.207533 loss_rnnt 9.179890 hw_loss 0.134637 lr 0.00047880 rank 7
2023-02-22 01:22:29,393 DEBUG TRAIN Batch 13/600 loss 12.369011 loss_att 11.949415 loss_ctc 13.478063 loss_rnnt 12.175417 hw_loss 0.243073 lr 0.00047879 rank 3
2023-02-22 01:22:29,441 DEBUG TRAIN Batch 13/600 loss 20.297977 loss_att 23.310383 loss_ctc 26.043819 loss_rnnt 18.787588 hw_loss 0.265868 lr 0.00047889 rank 1
2023-02-22 01:23:46,915 DEBUG TRAIN Batch 13/700 loss 22.323586 loss_att 24.561333 loss_ctc 26.924091 loss_rnnt 21.126516 hw_loss 0.255221 lr 0.00047858 rank 4
2023-02-22 01:23:46,917 DEBUG TRAIN Batch 13/700 loss 22.193552 loss_att 23.996115 loss_ctc 28.469244 loss_rnnt 20.935944 hw_loss 0.113135 lr 0.00047859 rank 5
2023-02-22 01:23:46,919 DEBUG TRAIN Batch 13/700 loss 16.932096 loss_att 22.338015 loss_ctc 22.728149 loss_rnnt 15.062041 hw_loss 0.030124 lr 0.00047867 rank 1
2023-02-22 01:23:46,921 DEBUG TRAIN Batch 13/700 loss 7.311166 loss_att 9.829948 loss_ctc 8.998753 loss_rnnt 6.550737 hw_loss 0.059364 lr 0.00047867 rank 0
2023-02-22 01:23:46,921 DEBUG TRAIN Batch 13/700 loss 10.394408 loss_att 14.650654 loss_ctc 14.033851 loss_rnnt 8.990333 hw_loss 0.126689 lr 0.00047858 rank 7
2023-02-22 01:23:46,948 DEBUG TRAIN Batch 13/700 loss 9.989560 loss_att 16.290537 loss_ctc 15.350551 loss_rnnt 7.961945 hw_loss 0.098665 lr 0.00047858 rank 3
2023-02-22 01:23:46,957 DEBUG TRAIN Batch 13/700 loss 14.831535 loss_att 24.437082 loss_ctc 19.481453 loss_rnnt 12.232524 hw_loss 0.108587 lr 0.00047861 rank 6
2023-02-22 01:23:46,970 DEBUG TRAIN Batch 13/700 loss 9.017269 loss_att 13.225919 loss_ctc 10.575607 loss_rnnt 7.849171 hw_loss 0.222357 lr 0.00047855 rank 2
2023-02-22 01:25:02,871 DEBUG TRAIN Batch 13/800 loss 5.341792 loss_att 11.817896 loss_ctc 5.596438 loss_rnnt 3.944464 hw_loss 0.127790 lr 0.00047836 rank 7
2023-02-22 01:25:02,876 DEBUG TRAIN Batch 13/800 loss 2.791133 loss_att 7.181147 loss_ctc 4.263824 loss_rnnt 1.626930 hw_loss 0.168453 lr 0.00047838 rank 5
2023-02-22 01:25:02,876 DEBUG TRAIN Batch 13/800 loss 16.856335 loss_att 19.343796 loss_ctc 23.996975 loss_rnnt 15.296400 hw_loss 0.206917 lr 0.00047845 rank 0
2023-02-22 01:25:02,877 DEBUG TRAIN Batch 13/800 loss 17.616856 loss_att 25.064199 loss_ctc 24.513937 loss_rnnt 15.166153 hw_loss 0.078044 lr 0.00047845 rank 1
2023-02-22 01:25:02,878 DEBUG TRAIN Batch 13/800 loss 13.172584 loss_att 13.942785 loss_ctc 12.755061 loss_rnnt 12.974013 hw_loss 0.187876 lr 0.00047836 rank 4
2023-02-22 01:25:02,878 DEBUG TRAIN Batch 13/800 loss 11.297665 loss_att 19.420982 loss_ctc 22.157339 loss_rnnt 8.158993 hw_loss 0.123850 lr 0.00047833 rank 2
2023-02-22 01:25:02,879 DEBUG TRAIN Batch 13/800 loss 13.898662 loss_att 16.836115 loss_ctc 13.728357 loss_rnnt 13.252940 hw_loss 0.151758 lr 0.00047836 rank 3
2023-02-22 01:25:02,924 DEBUG TRAIN Batch 13/800 loss 7.312422 loss_att 12.173512 loss_ctc 6.382956 loss_rnnt 6.432610 hw_loss 0.059105 lr 0.00047839 rank 6
2023-02-22 01:26:17,497 DEBUG TRAIN Batch 13/900 loss 16.024424 loss_att 21.640882 loss_ctc 23.242994 loss_rnnt 13.859990 hw_loss 0.147494 lr 0.00047823 rank 0
2023-02-22 01:26:17,497 DEBUG TRAIN Batch 13/900 loss 9.464819 loss_att 14.257966 loss_ctc 12.973365 loss_rnnt 7.904476 hw_loss 0.251077 lr 0.00047815 rank 7
2023-02-22 01:26:17,498 DEBUG TRAIN Batch 13/900 loss 13.076499 loss_att 20.043646 loss_ctc 17.334501 loss_rnnt 11.060810 hw_loss 0.102236 lr 0.00047814 rank 4
2023-02-22 01:26:17,499 DEBUG TRAIN Batch 13/900 loss 11.102155 loss_att 14.483995 loss_ctc 12.142582 loss_rnnt 10.208381 hw_loss 0.147530 lr 0.00047814 rank 3
2023-02-22 01:26:17,501 DEBUG TRAIN Batch 13/900 loss 12.093102 loss_att 13.827731 loss_ctc 10.998890 loss_rnnt 11.741394 hw_loss 0.282519 lr 0.00047823 rank 1
2023-02-22 01:26:17,501 DEBUG TRAIN Batch 13/900 loss 8.517550 loss_att 12.140946 loss_ctc 9.515127 loss_rnnt 7.617178 hw_loss 0.080027 lr 0.00047816 rank 5
2023-02-22 01:26:17,506 DEBUG TRAIN Batch 13/900 loss 12.423918 loss_att 13.301626 loss_ctc 20.792877 loss_rnnt 11.069286 hw_loss 0.118555 lr 0.00047811 rank 2
2023-02-22 01:26:17,508 DEBUG TRAIN Batch 13/900 loss 26.029963 loss_att 33.813465 loss_ctc 37.956696 loss_rnnt 22.845692 hw_loss 0.070009 lr 0.00047817 rank 6
2023-02-22 01:27:31,895 DEBUG TRAIN Batch 13/1000 loss 11.289482 loss_att 15.933176 loss_ctc 16.005074 loss_rnnt 9.693405 hw_loss 0.072359 lr 0.00047794 rank 5
2023-02-22 01:27:31,896 DEBUG TRAIN Batch 13/1000 loss 22.784529 loss_att 25.867344 loss_ctc 27.743233 loss_rnnt 21.433668 hw_loss 0.137135 lr 0.00047792 rank 4
2023-02-22 01:27:31,896 DEBUG TRAIN Batch 13/1000 loss 14.816317 loss_att 17.123354 loss_ctc 19.944277 loss_rnnt 13.638285 hw_loss 0.061678 lr 0.00047795 rank 6
2023-02-22 01:27:31,901 DEBUG TRAIN Batch 13/1000 loss 13.176753 loss_att 18.129002 loss_ctc 18.560440 loss_rnnt 11.422600 hw_loss 0.086025 lr 0.00047793 rank 7
2023-02-22 01:27:31,901 DEBUG TRAIN Batch 13/1000 loss 25.197290 loss_att 30.158024 loss_ctc 34.786064 loss_rnnt 22.873764 hw_loss 0.099142 lr 0.00047801 rank 0
2023-02-22 01:27:31,901 DEBUG TRAIN Batch 13/1000 loss 27.304991 loss_att 30.556831 loss_ctc 29.918133 loss_rnnt 26.246872 hw_loss 0.111246 lr 0.00047792 rank 3
2023-02-22 01:27:31,904 DEBUG TRAIN Batch 13/1000 loss 8.582218 loss_att 15.725295 loss_ctc 8.032210 loss_rnnt 7.149483 hw_loss 0.145226 lr 0.00047801 rank 1
2023-02-22 01:27:31,946 DEBUG TRAIN Batch 13/1000 loss 19.463699 loss_att 25.770420 loss_ctc 23.676605 loss_rnnt 17.585041 hw_loss 0.104237 lr 0.00047789 rank 2
2023-02-22 01:28:49,071 DEBUG TRAIN Batch 13/1100 loss 19.398626 loss_att 26.195267 loss_ctc 22.226999 loss_rnnt 17.583414 hw_loss 0.147688 lr 0.00047779 rank 0
2023-02-22 01:28:49,074 DEBUG TRAIN Batch 13/1100 loss 12.641946 loss_att 15.385229 loss_ctc 14.207445 loss_rnnt 11.839546 hw_loss 0.084392 lr 0.00047771 rank 7
2023-02-22 01:28:49,075 DEBUG TRAIN Batch 13/1100 loss 10.011873 loss_att 13.095336 loss_ctc 16.036526 loss_rnnt 8.465097 hw_loss 0.237744 lr 0.00047770 rank 4
2023-02-22 01:28:49,077 DEBUG TRAIN Batch 13/1100 loss 13.200834 loss_att 16.280001 loss_ctc 18.519459 loss_rnnt 11.754838 hw_loss 0.226898 lr 0.00047770 rank 3
2023-02-22 01:28:49,077 DEBUG TRAIN Batch 13/1100 loss 14.754277 loss_att 18.386738 loss_ctc 15.277958 loss_rnnt 13.894103 hw_loss 0.119734 lr 0.00047772 rank 5
2023-02-22 01:28:49,078 DEBUG TRAIN Batch 13/1100 loss 18.610098 loss_att 22.718643 loss_ctc 23.493410 loss_rnnt 17.114952 hw_loss 0.041864 lr 0.00047773 rank 6
2023-02-22 01:28:49,084 DEBUG TRAIN Batch 13/1100 loss 19.231531 loss_att 22.078491 loss_ctc 20.272640 loss_rnnt 18.421341 hw_loss 0.191219 lr 0.00047767 rank 2
2023-02-22 01:28:49,120 DEBUG TRAIN Batch 13/1100 loss 11.187733 loss_att 15.433380 loss_ctc 14.510867 loss_rnnt 9.777626 hw_loss 0.221047 lr 0.00047779 rank 1
2023-02-22 01:30:03,241 DEBUG TRAIN Batch 13/1200 loss 12.351936 loss_att 14.037265 loss_ctc 14.292844 loss_rnnt 11.645634 hw_loss 0.207094 lr 0.00047749 rank 4
2023-02-22 01:30:03,243 DEBUG TRAIN Batch 13/1200 loss 17.128815 loss_att 16.415768 loss_ctc 20.378899 loss_rnnt 16.722698 hw_loss 0.216340 lr 0.00047750 rank 5
2023-02-22 01:30:03,246 DEBUG TRAIN Batch 13/1200 loss 14.279202 loss_att 16.891312 loss_ctc 18.040985 loss_rnnt 13.148412 hw_loss 0.200243 lr 0.00047748 rank 3
2023-02-22 01:30:03,247 DEBUG TRAIN Batch 13/1200 loss 9.592081 loss_att 12.463164 loss_ctc 13.422909 loss_rnnt 8.369221 hw_loss 0.258501 lr 0.00047745 rank 2
2023-02-22 01:30:03,248 DEBUG TRAIN Batch 13/1200 loss 27.091415 loss_att 29.380823 loss_ctc 31.507309 loss_rnnt 25.900656 hw_loss 0.270178 lr 0.00047757 rank 0
2023-02-22 01:30:03,248 DEBUG TRAIN Batch 13/1200 loss 12.328568 loss_att 15.022524 loss_ctc 13.964450 loss_rnnt 11.500812 hw_loss 0.132841 lr 0.00047749 rank 7
2023-02-22 01:30:03,250 DEBUG TRAIN Batch 13/1200 loss 10.779557 loss_att 13.310436 loss_ctc 12.965674 loss_rnnt 9.914332 hw_loss 0.126687 lr 0.00047757 rank 1
2023-02-22 01:30:03,253 DEBUG TRAIN Batch 13/1200 loss 10.381087 loss_att 12.597079 loss_ctc 13.522835 loss_rnnt 9.406604 hw_loss 0.210725 lr 0.00047751 rank 6
2023-02-22 01:31:18,097 DEBUG TRAIN Batch 13/1300 loss 27.204752 loss_att 29.170229 loss_ctc 29.086103 loss_rnnt 26.432755 hw_loss 0.240103 lr 0.00047727 rank 4
2023-02-22 01:31:18,099 DEBUG TRAIN Batch 13/1300 loss 13.476213 loss_att 16.556286 loss_ctc 15.749939 loss_rnnt 12.457515 hw_loss 0.186601 lr 0.00047728 rank 5
2023-02-22 01:31:18,099 DEBUG TRAIN Batch 13/1300 loss 12.887334 loss_att 17.102776 loss_ctc 17.883015 loss_rnnt 11.352020 hw_loss 0.049003 lr 0.00047727 rank 7
2023-02-22 01:31:18,099 DEBUG TRAIN Batch 13/1300 loss 12.518318 loss_att 11.519484 loss_ctc 14.311082 loss_rnnt 12.338043 hw_loss 0.264386 lr 0.00047727 rank 3
2023-02-22 01:31:18,100 DEBUG TRAIN Batch 13/1300 loss 8.911988 loss_att 9.663729 loss_ctc 11.221690 loss_rnnt 8.383921 hw_loss 0.130799 lr 0.00047735 rank 0
2023-02-22 01:31:18,102 DEBUG TRAIN Batch 13/1300 loss 13.301575 loss_att 15.015347 loss_ctc 15.815758 loss_rnnt 12.549956 hw_loss 0.138075 lr 0.00047736 rank 1
2023-02-22 01:31:18,106 DEBUG TRAIN Batch 13/1300 loss 13.887871 loss_att 14.035601 loss_ctc 19.464636 loss_rnnt 13.001294 hw_loss 0.212742 lr 0.00047730 rank 6
2023-02-22 01:31:18,151 DEBUG TRAIN Batch 13/1300 loss 19.189173 loss_att 26.308842 loss_ctc 20.488091 loss_rnnt 17.530655 hw_loss 0.115114 lr 0.00047724 rank 2
2023-02-22 01:32:35,414 DEBUG TRAIN Batch 13/1400 loss 26.471699 loss_att 30.393795 loss_ctc 31.577560 loss_rnnt 24.968567 hw_loss 0.071116 lr 0.00047706 rank 7
2023-02-22 01:32:35,415 DEBUG TRAIN Batch 13/1400 loss 14.675723 loss_att 22.482880 loss_ctc 17.648256 loss_rnnt 12.650035 hw_loss 0.127348 lr 0.00047707 rank 5
2023-02-22 01:32:35,418 DEBUG TRAIN Batch 13/1400 loss 13.857407 loss_att 18.871166 loss_ctc 15.598425 loss_rnnt 12.526157 hw_loss 0.180677 lr 0.00047714 rank 1
2023-02-22 01:32:35,421 DEBUG TRAIN Batch 13/1400 loss 9.825803 loss_att 13.685516 loss_ctc 14.121017 loss_rnnt 8.397108 hw_loss 0.157606 lr 0.00047714 rank 0
2023-02-22 01:32:35,421 DEBUG TRAIN Batch 13/1400 loss 5.746133 loss_att 10.366699 loss_ctc 5.521942 loss_rnnt 4.758949 hw_loss 0.174306 lr 0.00047708 rank 6
2023-02-22 01:32:35,423 DEBUG TRAIN Batch 13/1400 loss 13.923808 loss_att 20.822399 loss_ctc 19.243689 loss_rnnt 11.706305 hw_loss 0.240879 lr 0.00047705 rank 4
2023-02-22 01:32:35,426 DEBUG TRAIN Batch 13/1400 loss 19.917116 loss_att 21.009268 loss_ctc 17.492018 loss_rnnt 19.977968 hw_loss 0.082622 lr 0.00047702 rank 2
2023-02-22 01:32:35,427 DEBUG TRAIN Batch 13/1400 loss 10.906343 loss_att 19.965038 loss_ctc 19.063042 loss_rnnt 7.945356 hw_loss 0.115667 lr 0.00047705 rank 3
2023-02-22 01:33:51,620 DEBUG TRAIN Batch 13/1500 loss 5.343733 loss_att 8.422529 loss_ctc 6.864044 loss_rnnt 4.454867 hw_loss 0.131996 lr 0.00047684 rank 7
2023-02-22 01:33:51,623 DEBUG TRAIN Batch 13/1500 loss 19.309341 loss_att 25.466293 loss_ctc 29.796673 loss_rnnt 16.659096 hw_loss 0.038520 lr 0.00047692 rank 0
2023-02-22 01:33:51,623 DEBUG TRAIN Batch 13/1500 loss 15.199546 loss_att 18.118422 loss_ctc 20.289902 loss_rnnt 13.870115 hw_loss 0.125515 lr 0.00047683 rank 4
2023-02-22 01:33:51,628 DEBUG TRAIN Batch 13/1500 loss 6.179349 loss_att 10.148400 loss_ctc 8.871279 loss_rnnt 4.956643 hw_loss 0.131197 lr 0.00047685 rank 5
2023-02-22 01:33:51,631 DEBUG TRAIN Batch 13/1500 loss 25.668428 loss_att 29.702961 loss_ctc 29.567991 loss_rnnt 24.221670 hw_loss 0.224831 lr 0.00047686 rank 6
2023-02-22 01:33:51,632 DEBUG TRAIN Batch 13/1500 loss 5.558645 loss_att 9.031935 loss_ctc 6.933218 loss_rnnt 4.614283 hw_loss 0.124553 lr 0.00047683 rank 3
2023-02-22 01:33:51,632 DEBUG TRAIN Batch 13/1500 loss 18.160435 loss_att 21.806723 loss_ctc 23.203815 loss_rnnt 16.686985 hw_loss 0.134516 lr 0.00047692 rank 1
2023-02-22 01:33:51,634 DEBUG TRAIN Batch 13/1500 loss 29.351578 loss_att 34.271408 loss_ctc 35.489773 loss_rnnt 27.482159 hw_loss 0.125680 lr 0.00047680 rank 2
2023-02-22 01:35:05,757 DEBUG TRAIN Batch 13/1600 loss 17.914791 loss_att 19.520178 loss_ctc 22.440796 loss_rnnt 16.923435 hw_loss 0.125270 lr 0.00047663 rank 5
2023-02-22 01:35:05,757 DEBUG TRAIN Batch 13/1600 loss 15.835380 loss_att 18.485981 loss_ctc 19.268131 loss_rnnt 14.743973 hw_loss 0.194223 lr 0.00047664 rank 6
2023-02-22 01:35:05,758 DEBUG TRAIN Batch 13/1600 loss 8.454203 loss_att 9.471919 loss_ctc 10.273829 loss_rnnt 7.957133 hw_loss 0.095456 lr 0.00047662 rank 4
2023-02-22 01:35:05,759 DEBUG TRAIN Batch 13/1600 loss 13.157151 loss_att 14.903470 loss_ctc 15.704027 loss_rnnt 12.390883 hw_loss 0.145163 lr 0.00047661 rank 3
2023-02-22 01:35:05,761 DEBUG TRAIN Batch 13/1600 loss 6.724201 loss_att 9.466720 loss_ctc 8.881578 loss_rnnt 5.831308 hw_loss 0.106386 lr 0.00047671 rank 1
2023-02-22 01:35:05,762 DEBUG TRAIN Batch 13/1600 loss 11.011600 loss_att 15.769284 loss_ctc 12.311453 loss_rnnt 9.822266 hw_loss 0.120907 lr 0.00047670 rank 0
2023-02-22 01:35:05,762 DEBUG TRAIN Batch 13/1600 loss 15.982244 loss_att 20.107162 loss_ctc 17.270361 loss_rnnt 14.911152 hw_loss 0.139425 lr 0.00047662 rank 7
2023-02-22 01:35:05,767 DEBUG TRAIN Batch 13/1600 loss 10.505852 loss_att 14.234331 loss_ctc 10.288114 loss_rnnt 9.730506 hw_loss 0.110027 lr 0.00047659 rank 2
2023-02-22 01:36:20,632 DEBUG TRAIN Batch 13/1700 loss 16.410137 loss_att 21.344261 loss_ctc 17.854679 loss_rnnt 15.124339 hw_loss 0.199436 lr 0.00047640 rank 4
2023-02-22 01:36:20,635 DEBUG TRAIN Batch 13/1700 loss 17.236412 loss_att 17.654371 loss_ctc 17.994152 loss_rnnt 16.966196 hw_loss 0.160485 lr 0.00047640 rank 3
2023-02-22 01:36:20,637 DEBUG TRAIN Batch 13/1700 loss 9.978858 loss_att 13.617105 loss_ctc 15.890697 loss_rnnt 8.347568 hw_loss 0.216366 lr 0.00047642 rank 5
2023-02-22 01:36:20,638 DEBUG TRAIN Batch 13/1700 loss 21.984743 loss_att 24.917233 loss_ctc 23.978344 loss_rnnt 21.070791 hw_loss 0.115575 lr 0.00047649 rank 1
2023-02-22 01:36:20,638 DEBUG TRAIN Batch 13/1700 loss 14.836426 loss_att 16.359350 loss_ctc 19.387976 loss_rnnt 13.804683 hw_loss 0.225535 lr 0.00047637 rank 2
2023-02-22 01:36:20,640 DEBUG TRAIN Batch 13/1700 loss 14.455315 loss_att 18.004890 loss_ctc 16.072487 loss_rnnt 13.459740 hw_loss 0.131321 lr 0.00047649 rank 0
2023-02-22 01:36:20,641 DEBUG TRAIN Batch 13/1700 loss 10.713774 loss_att 14.500700 loss_ctc 16.097178 loss_rnnt 9.100668 hw_loss 0.258624 lr 0.00047641 rank 7
2023-02-22 01:36:20,689 DEBUG TRAIN Batch 13/1700 loss 11.835279 loss_att 15.535786 loss_ctc 13.594739 loss_rnnt 10.712914 hw_loss 0.276878 lr 0.00047643 rank 6
2023-02-22 01:37:38,344 DEBUG TRAIN Batch 13/1800 loss 16.308920 loss_att 19.220428 loss_ctc 18.299713 loss_rnnt 15.398608 hw_loss 0.117322 lr 0.00047620 rank 5
2023-02-22 01:37:38,347 DEBUG TRAIN Batch 13/1800 loss 14.815447 loss_att 16.432096 loss_ctc 17.997232 loss_rnnt 14.031717 hw_loss 0.067802 lr 0.00047619 rank 7
2023-02-22 01:37:38,352 DEBUG TRAIN Batch 13/1800 loss 14.712631 loss_att 21.940556 loss_ctc 19.038441 loss_rnnt 12.610590 hw_loss 0.149404 lr 0.00047627 rank 0
2023-02-22 01:37:38,355 DEBUG TRAIN Batch 13/1800 loss 7.787283 loss_att 9.137132 loss_ctc 10.153853 loss_rnnt 7.115319 hw_loss 0.162096 lr 0.00047627 rank 1
2023-02-22 01:37:38,355 DEBUG TRAIN Batch 13/1800 loss 18.499147 loss_att 20.417866 loss_ctc 20.276932 loss_rnnt 17.819775 hw_loss 0.109859 lr 0.00047618 rank 4
2023-02-22 01:37:38,357 DEBUG TRAIN Batch 13/1800 loss 13.422208 loss_att 13.835848 loss_ctc 14.151181 loss_rnnt 13.199366 hw_loss 0.080469 lr 0.00047615 rank 2
2023-02-22 01:37:38,361 DEBUG TRAIN Batch 13/1800 loss 16.271616 loss_att 22.909664 loss_ctc 21.706291 loss_rnnt 14.131538 hw_loss 0.164707 lr 0.00047618 rank 3
2023-02-22 01:37:38,406 DEBUG TRAIN Batch 13/1800 loss 5.006909 loss_att 9.127761 loss_ctc 5.766413 loss_rnnt 4.012823 hw_loss 0.128717 lr 0.00047621 rank 6
2023-02-22 01:38:54,047 DEBUG TRAIN Batch 13/1900 loss 9.840357 loss_att 11.121903 loss_ctc 13.219669 loss_rnnt 8.958815 hw_loss 0.327485 lr 0.00047597 rank 7
2023-02-22 01:38:54,048 DEBUG TRAIN Batch 13/1900 loss 18.606203 loss_att 21.611137 loss_ctc 24.044907 loss_rnnt 17.129568 hw_loss 0.282163 lr 0.00047597 rank 4
2023-02-22 01:38:54,052 DEBUG TRAIN Batch 13/1900 loss 12.896255 loss_att 18.382853 loss_ctc 15.063773 loss_rnnt 11.449438 hw_loss 0.113428 lr 0.00047599 rank 5
2023-02-22 01:38:54,053 DEBUG TRAIN Batch 13/1900 loss 11.307876 loss_att 10.517045 loss_ctc 13.088086 loss_rnnt 11.127949 hw_loss 0.188873 lr 0.00047605 rank 0
2023-02-22 01:38:54,054 DEBUG TRAIN Batch 13/1900 loss 8.217359 loss_att 13.376543 loss_ctc 9.889261 loss_rnnt 6.962406 hw_loss 0.000365 lr 0.00047594 rank 2
2023-02-22 01:38:54,054 DEBUG TRAIN Batch 13/1900 loss 5.746580 loss_att 8.354714 loss_ctc 8.039984 loss_rnnt 4.828090 hw_loss 0.170766 lr 0.00047600 rank 6
2023-02-22 01:38:54,064 DEBUG TRAIN Batch 13/1900 loss 10.457376 loss_att 10.562348 loss_ctc 14.073620 loss_rnnt 9.858499 hw_loss 0.179469 lr 0.00047597 rank 3
2023-02-22 01:38:54,102 DEBUG TRAIN Batch 13/1900 loss 12.206061 loss_att 10.614195 loss_ctc 13.479305 loss_rnnt 12.246228 hw_loss 0.203323 lr 0.00047606 rank 1
2023-02-22 01:40:07,340 DEBUG TRAIN Batch 13/2000 loss 21.165094 loss_att 27.594013 loss_ctc 28.204855 loss_rnnt 18.860453 hw_loss 0.150420 lr 0.00047575 rank 3
2023-02-22 01:40:07,340 DEBUG TRAIN Batch 13/2000 loss 13.294024 loss_att 22.409359 loss_ctc 22.194296 loss_rnnt 10.196716 hw_loss 0.164134 lr 0.00047584 rank 1
2023-02-22 01:40:07,341 DEBUG TRAIN Batch 13/2000 loss 23.644161 loss_att 26.276939 loss_ctc 29.698402 loss_rnnt 22.246014 hw_loss 0.120673 lr 0.00047576 rank 7
2023-02-22 01:40:07,341 DEBUG TRAIN Batch 13/2000 loss 34.452576 loss_att 41.756882 loss_ctc 41.381592 loss_rnnt 31.995621 hw_loss 0.135426 lr 0.00047577 rank 5
2023-02-22 01:40:07,341 DEBUG TRAIN Batch 13/2000 loss 19.536745 loss_att 20.285908 loss_ctc 22.014730 loss_rnnt 18.982552 hw_loss 0.138676 lr 0.00047584 rank 0
2023-02-22 01:40:07,342 DEBUG TRAIN Batch 13/2000 loss 22.292400 loss_att 26.490179 loss_ctc 24.255461 loss_rnnt 21.163456 hw_loss 0.051841 lr 0.00047572 rank 2
2023-02-22 01:40:07,344 DEBUG TRAIN Batch 13/2000 loss 17.294813 loss_att 18.808443 loss_ctc 21.295811 loss_rnnt 16.442230 hw_loss 0.030730 lr 0.00047575 rank 4
2023-02-22 01:40:07,345 DEBUG TRAIN Batch 13/2000 loss 14.093761 loss_att 15.732366 loss_ctc 16.208729 loss_rnnt 13.431355 hw_loss 0.098795 lr 0.00047578 rank 6
2023-02-22 01:41:24,819 DEBUG TRAIN Batch 13/2100 loss 23.957603 loss_att 27.863544 loss_ctc 35.243217 loss_rnnt 21.618404 hw_loss 0.099870 lr 0.00047554 rank 7
2023-02-22 01:41:24,821 DEBUG TRAIN Batch 13/2100 loss 9.624923 loss_att 12.678053 loss_ctc 12.920105 loss_rnnt 8.539770 hw_loss 0.065943 lr 0.00047557 rank 6
2023-02-22 01:41:24,822 DEBUG TRAIN Batch 13/2100 loss 9.012799 loss_att 14.098297 loss_ctc 17.149990 loss_rnnt 6.768055 hw_loss 0.267538 lr 0.00047554 rank 4
2023-02-22 01:41:24,823 DEBUG TRAIN Batch 13/2100 loss 13.718831 loss_att 18.087002 loss_ctc 16.766279 loss_rnnt 12.399599 hw_loss 0.073630 lr 0.00047562 rank 0
2023-02-22 01:41:24,824 DEBUG TRAIN Batch 13/2100 loss 15.628854 loss_att 20.094234 loss_ctc 18.413338 loss_rnnt 14.267744 hw_loss 0.181443 lr 0.00047551 rank 2
2023-02-22 01:41:24,825 DEBUG TRAIN Batch 13/2100 loss 6.165251 loss_att 9.278415 loss_ctc 8.700760 loss_rnnt 5.124826 hw_loss 0.149482 lr 0.00047554 rank 3
2023-02-22 01:41:24,825 DEBUG TRAIN Batch 13/2100 loss 4.490849 loss_att 9.784711 loss_ctc 7.122236 loss_rnnt 3.030429 hw_loss 0.095243 lr 0.00047555 rank 5
2023-02-22 01:41:24,827 DEBUG TRAIN Batch 13/2100 loss 9.734419 loss_att 14.540341 loss_ctc 10.932983 loss_rnnt 8.486691 hw_loss 0.237627 lr 0.00047563 rank 1
2023-02-22 01:42:41,756 DEBUG TRAIN Batch 13/2200 loss 13.224750 loss_att 13.659760 loss_ctc 13.014778 loss_rnnt 13.108086 hw_loss 0.108111 lr 0.00047532 rank 4
2023-02-22 01:42:41,758 DEBUG TRAIN Batch 13/2200 loss 15.695402 loss_att 18.202225 loss_ctc 25.791267 loss_rnnt 13.771968 hw_loss 0.142416 lr 0.00047541 rank 0
2023-02-22 01:42:41,758 DEBUG TRAIN Batch 13/2200 loss 16.330475 loss_att 20.134781 loss_ctc 22.256676 loss_rnnt 14.729325 hw_loss 0.093990 lr 0.00047534 rank 5
2023-02-22 01:42:41,759 DEBUG TRAIN Batch 13/2200 loss 12.453793 loss_att 15.559260 loss_ctc 14.561946 loss_rnnt 11.524189 hw_loss 0.051418 lr 0.00047533 rank 7
2023-02-22 01:42:41,760 DEBUG TRAIN Batch 13/2200 loss 11.134803 loss_att 15.189725 loss_ctc 19.225861 loss_rnnt 9.161975 hw_loss 0.155693 lr 0.00047529 rank 2
2023-02-22 01:42:41,762 DEBUG TRAIN Batch 13/2200 loss 15.466259 loss_att 17.027857 loss_ctc 21.607265 loss_rnnt 14.227842 hw_loss 0.201182 lr 0.00047535 rank 6
2023-02-22 01:42:41,763 DEBUG TRAIN Batch 13/2200 loss 33.410709 loss_att 34.482204 loss_ctc 46.212646 loss_rnnt 31.423117 hw_loss 0.124448 lr 0.00047541 rank 1
2023-02-22 01:42:41,769 DEBUG TRAIN Batch 13/2200 loss 7.601097 loss_att 13.234322 loss_ctc 9.188082 loss_rnnt 6.157064 hw_loss 0.198357 lr 0.00047532 rank 3
2023-02-22 01:43:55,615 DEBUG TRAIN Batch 13/2300 loss 19.056158 loss_att 21.099432 loss_ctc 23.560783 loss_rnnt 17.993938 hw_loss 0.099278 lr 0.00047519 rank 0
2023-02-22 01:43:55,618 DEBUG TRAIN Batch 13/2300 loss 13.280911 loss_att 16.211132 loss_ctc 19.152790 loss_rnnt 11.824022 hw_loss 0.164862 lr 0.00047511 rank 4
2023-02-22 01:43:55,622 DEBUG TRAIN Batch 13/2300 loss 8.450165 loss_att 12.693382 loss_ctc 12.405549 loss_rnnt 6.932090 hw_loss 0.266337 lr 0.00047511 rank 7
2023-02-22 01:43:55,623 DEBUG TRAIN Batch 13/2300 loss 11.465541 loss_att 14.790634 loss_ctc 14.500489 loss_rnnt 10.336727 hw_loss 0.110878 lr 0.00047508 rank 2
2023-02-22 01:43:55,623 DEBUG TRAIN Batch 13/2300 loss 15.780672 loss_att 20.620190 loss_ctc 18.529587 loss_rnnt 14.294222 hw_loss 0.285045 lr 0.00047513 rank 5
2023-02-22 01:43:55,625 DEBUG TRAIN Batch 13/2300 loss 9.914628 loss_att 12.682180 loss_ctc 13.677862 loss_rnnt 8.798817 hw_loss 0.113504 lr 0.00047514 rank 6
2023-02-22 01:43:55,628 DEBUG TRAIN Batch 13/2300 loss 17.066511 loss_att 20.422699 loss_ctc 19.304443 loss_rnnt 15.999781 hw_loss 0.182062 lr 0.00047520 rank 1
2023-02-22 01:43:55,671 DEBUG TRAIN Batch 13/2300 loss 5.702534 loss_att 8.716352 loss_ctc 6.444344 loss_rnnt 4.883866 hw_loss 0.219367 lr 0.00047511 rank 3
2023-02-22 01:45:10,675 DEBUG TRAIN Batch 13/2400 loss 6.564699 loss_att 10.655780 loss_ctc 12.855358 loss_rnnt 4.854283 hw_loss 0.100208 lr 0.00047489 rank 4
2023-02-22 01:45:10,676 DEBUG TRAIN Batch 13/2400 loss 19.457628 loss_att 24.897919 loss_ctc 28.840847 loss_rnnt 16.981174 hw_loss 0.257433 lr 0.00047492 rank 6
2023-02-22 01:45:10,680 DEBUG TRAIN Batch 13/2400 loss 16.688219 loss_att 16.809761 loss_ctc 21.392248 loss_rnnt 15.953269 hw_loss 0.156448 lr 0.00047498 rank 0
2023-02-22 01:45:10,679 DEBUG TRAIN Batch 13/2400 loss 13.894758 loss_att 18.278862 loss_ctc 15.136307 loss_rnnt 12.772403 hw_loss 0.149990 lr 0.00047491 rank 5
2023-02-22 01:45:10,684 DEBUG TRAIN Batch 13/2400 loss 10.988561 loss_att 14.378066 loss_ctc 15.856627 loss_rnnt 9.595226 hw_loss 0.124420 lr 0.00047489 rank 3
2023-02-22 01:45:10,684 DEBUG TRAIN Batch 13/2400 loss 18.048805 loss_att 22.296162 loss_ctc 21.695190 loss_rnnt 16.637079 hw_loss 0.142626 lr 0.00047498 rank 1
2023-02-22 01:45:10,685 DEBUG TRAIN Batch 13/2400 loss 7.780017 loss_att 11.194184 loss_ctc 8.234021 loss_rnnt 6.982521 hw_loss 0.101492 lr 0.00047490 rank 7
2023-02-22 01:45:10,688 DEBUG TRAIN Batch 13/2400 loss 9.304508 loss_att 12.508686 loss_ctc 12.780609 loss_rnnt 8.116585 hw_loss 0.156764 lr 0.00047486 rank 2
2023-02-22 01:46:30,502 DEBUG TRAIN Batch 13/2500 loss 11.430876 loss_att 10.731441 loss_ctc 14.028093 loss_rnnt 11.030467 hw_loss 0.363752 lr 0.00047470 rank 5
2023-02-22 01:46:30,502 DEBUG TRAIN Batch 13/2500 loss 17.260616 loss_att 19.729799 loss_ctc 22.221912 loss_rnnt 15.971265 hw_loss 0.251263 lr 0.00047468 rank 4
2023-02-22 01:46:30,503 DEBUG TRAIN Batch 13/2500 loss 10.611620 loss_att 11.556655 loss_ctc 13.489927 loss_rnnt 9.854621 hw_loss 0.345410 lr 0.00047477 rank 0
2023-02-22 01:46:30,503 DEBUG TRAIN Batch 13/2500 loss 8.252612 loss_att 11.597815 loss_ctc 9.802308 loss_rnnt 7.299875 hw_loss 0.144507 lr 0.00047469 rank 7
2023-02-22 01:46:30,505 DEBUG TRAIN Batch 13/2500 loss 7.868638 loss_att 8.280487 loss_ctc 9.169793 loss_rnnt 7.492235 hw_loss 0.226024 lr 0.00047468 rank 3
2023-02-22 01:46:30,505 DEBUG TRAIN Batch 13/2500 loss 13.287773 loss_att 16.860580 loss_ctc 15.769704 loss_rnnt 12.241779 hw_loss 0.000953 lr 0.00047477 rank 1
2023-02-22 01:46:30,509 DEBUG TRAIN Batch 13/2500 loss 15.004292 loss_att 17.123022 loss_ctc 15.519699 loss_rnnt 14.415774 hw_loss 0.180097 lr 0.00047471 rank 6
2023-02-22 01:46:30,511 DEBUG TRAIN Batch 13/2500 loss 14.469914 loss_att 15.105455 loss_ctc 15.799200 loss_rnnt 13.979041 hw_loss 0.349739 lr 0.00047465 rank 2
2023-02-22 01:47:46,303 DEBUG TRAIN Batch 13/2600 loss 10.894020 loss_att 10.123484 loss_ctc 15.147013 loss_rnnt 10.302690 hw_loss 0.334449 lr 0.00047447 rank 4
2023-02-22 01:47:46,305 DEBUG TRAIN Batch 13/2600 loss 17.456623 loss_att 23.234289 loss_ctc 21.622284 loss_rnnt 15.616217 hw_loss 0.242724 lr 0.00047447 rank 7
2023-02-22 01:47:46,306 DEBUG TRAIN Batch 13/2600 loss 18.476023 loss_att 21.416843 loss_ctc 21.496265 loss_rnnt 17.430775 hw_loss 0.101973 lr 0.00047446 rank 3
2023-02-22 01:47:46,306 DEBUG TRAIN Batch 13/2600 loss 10.439198 loss_att 12.691492 loss_ctc 14.301985 loss_rnnt 9.362112 hw_loss 0.209229 lr 0.00047455 rank 0
2023-02-22 01:47:46,310 DEBUG TRAIN Batch 13/2600 loss 9.900900 loss_att 15.250949 loss_ctc 18.333395 loss_rnnt 7.678468 hw_loss 0.052667 lr 0.00047449 rank 6
2023-02-22 01:47:46,312 DEBUG TRAIN Batch 13/2600 loss 7.963813 loss_att 13.972095 loss_ctc 8.094254 loss_rnnt 6.744531 hw_loss 0.000436 lr 0.00047444 rank 2
2023-02-22 01:47:46,313 DEBUG TRAIN Batch 13/2600 loss 20.724712 loss_att 24.049427 loss_ctc 23.940365 loss_rnnt 19.540707 hw_loss 0.169329 lr 0.00047455 rank 1
2023-02-22 01:47:46,318 DEBUG TRAIN Batch 13/2600 loss 12.769427 loss_att 14.397009 loss_ctc 18.787786 loss_rnnt 11.568281 hw_loss 0.137216 lr 0.00047448 rank 5
2023-02-22 01:49:00,522 DEBUG TRAIN Batch 13/2700 loss 14.464637 loss_att 21.396048 loss_ctc 19.821508 loss_rnnt 12.270586 hw_loss 0.175345 lr 0.00047427 rank 5
2023-02-22 01:49:00,522 DEBUG TRAIN Batch 13/2700 loss 11.423772 loss_att 16.334044 loss_ctc 14.204761 loss_rnnt 9.935781 hw_loss 0.253381 lr 0.00047425 rank 4
2023-02-22 01:49:00,528 DEBUG TRAIN Batch 13/2700 loss 5.395279 loss_att 9.949348 loss_ctc 7.875131 loss_rnnt 4.069828 hw_loss 0.157480 lr 0.00047426 rank 7
2023-02-22 01:49:00,532 DEBUG TRAIN Batch 13/2700 loss 9.282802 loss_att 15.389298 loss_ctc 16.862961 loss_rnnt 7.012509 hw_loss 0.071821 lr 0.00047434 rank 0
2023-02-22 01:49:00,532 DEBUG TRAIN Batch 13/2700 loss 7.079328 loss_att 9.100655 loss_ctc 9.367975 loss_rnnt 6.312544 hw_loss 0.107560 lr 0.00047425 rank 3
2023-02-22 01:49:00,533 DEBUG TRAIN Batch 13/2700 loss 44.124176 loss_att 45.286743 loss_ctc 53.767288 loss_rnnt 42.513042 hw_loss 0.174137 lr 0.00047422 rank 2
2023-02-22 01:49:00,534 DEBUG TRAIN Batch 13/2700 loss 11.093595 loss_att 13.923660 loss_ctc 17.034306 loss_rnnt 9.652740 hw_loss 0.155150 lr 0.00047428 rank 6
2023-02-22 01:49:00,535 DEBUG TRAIN Batch 13/2700 loss 11.040288 loss_att 13.989059 loss_ctc 11.028194 loss_rnnt 10.407883 hw_loss 0.082994 lr 0.00047434 rank 1
2023-02-22 01:50:16,905 DEBUG TRAIN Batch 13/2800 loss 26.219812 loss_att 26.477215 loss_ctc 29.641571 loss_rnnt 25.631855 hw_loss 0.150450 lr 0.00047406 rank 5
2023-02-22 01:50:16,909 DEBUG TRAIN Batch 13/2800 loss 15.948776 loss_att 20.271523 loss_ctc 25.000286 loss_rnnt 13.767210 hw_loss 0.206529 lr 0.00047404 rank 4
2023-02-22 01:50:16,909 DEBUG TRAIN Batch 13/2800 loss 28.570316 loss_att 30.835571 loss_ctc 37.156975 loss_rnnt 26.856628 hw_loss 0.217029 lr 0.00047413 rank 1
2023-02-22 01:50:16,910 DEBUG TRAIN Batch 13/2800 loss 6.503009 loss_att 7.913656 loss_ctc 8.542513 loss_rnnt 5.897066 hw_loss 0.097274 lr 0.00047404 rank 3
2023-02-22 01:50:16,911 DEBUG TRAIN Batch 13/2800 loss 12.806598 loss_att 15.518837 loss_ctc 15.256415 loss_rnnt 11.899945 hw_loss 0.070428 lr 0.00047412 rank 0
2023-02-22 01:50:16,911 DEBUG TRAIN Batch 13/2800 loss 15.583459 loss_att 23.857082 loss_ctc 20.489012 loss_rnnt 13.165816 hw_loss 0.204082 lr 0.00047405 rank 7
2023-02-22 01:50:16,914 DEBUG TRAIN Batch 13/2800 loss 13.075847 loss_att 20.060833 loss_ctc 15.815620 loss_rnnt 11.236259 hw_loss 0.144916 lr 0.00047407 rank 6
2023-02-22 01:50:16,914 DEBUG TRAIN Batch 13/2800 loss 12.673692 loss_att 15.722862 loss_ctc 16.589611 loss_rnnt 11.494503 hw_loss 0.088561 lr 0.00047401 rank 2
2023-02-22 01:51:34,240 DEBUG TRAIN Batch 13/2900 loss 9.779066 loss_att 12.561013 loss_ctc 11.536667 loss_rnnt 8.920882 hw_loss 0.126465 lr 0.00047391 rank 0
2023-02-22 01:51:34,245 DEBUG TRAIN Batch 13/2900 loss 14.742878 loss_att 18.569679 loss_ctc 17.787184 loss_rnnt 13.474445 hw_loss 0.182186 lr 0.00047382 rank 3
2023-02-22 01:51:34,246 DEBUG TRAIN Batch 13/2900 loss 10.163543 loss_att 13.443541 loss_ctc 9.804019 loss_rnnt 9.493152 hw_loss 0.116866 lr 0.00047383 rank 4
2023-02-22 01:51:34,247 DEBUG TRAIN Batch 13/2900 loss 24.364002 loss_att 30.585081 loss_ctc 31.185957 loss_rnnt 22.125151 hw_loss 0.159453 lr 0.00047383 rank 7
2023-02-22 01:51:34,247 DEBUG TRAIN Batch 13/2900 loss 11.572165 loss_att 15.415207 loss_ctc 19.221205 loss_rnnt 9.704698 hw_loss 0.148100 lr 0.00047391 rank 1
2023-02-22 01:51:34,250 DEBUG TRAIN Batch 13/2900 loss 10.896885 loss_att 14.817330 loss_ctc 11.853275 loss_rnnt 9.983047 hw_loss 0.004179 lr 0.00047385 rank 6
2023-02-22 01:51:34,251 DEBUG TRAIN Batch 13/2900 loss 18.017590 loss_att 21.112984 loss_ctc 22.468773 loss_rnnt 16.717281 hw_loss 0.164509 lr 0.00047380 rank 2
2023-02-22 01:51:34,251 DEBUG TRAIN Batch 13/2900 loss 9.710599 loss_att 12.750627 loss_ctc 12.296740 loss_rnnt 8.655939 hw_loss 0.190943 lr 0.00047384 rank 5
2023-02-22 01:52:49,786 DEBUG TRAIN Batch 13/3000 loss 18.781681 loss_att 21.209427 loss_ctc 24.588905 loss_rnnt 17.406403 hw_loss 0.216437 lr 0.00047361 rank 4
2023-02-22 01:52:49,787 DEBUG TRAIN Batch 13/3000 loss 9.200831 loss_att 15.261324 loss_ctc 12.024014 loss_rnnt 7.504138 hw_loss 0.202818 lr 0.00047370 rank 1
2023-02-22 01:52:49,788 DEBUG TRAIN Batch 13/3000 loss 16.783199 loss_att 19.762014 loss_ctc 21.073631 loss_rnnt 15.538486 hw_loss 0.144176 lr 0.00047363 rank 5
2023-02-22 01:52:49,792 DEBUG TRAIN Batch 13/3000 loss 11.063169 loss_att 16.230862 loss_ctc 10.905885 loss_rnnt 9.987481 hw_loss 0.118348 lr 0.00047362 rank 7
2023-02-22 01:52:49,793 DEBUG TRAIN Batch 13/3000 loss 18.963081 loss_att 22.789686 loss_ctc 22.207531 loss_rnnt 17.671003 hw_loss 0.176556 lr 0.00047370 rank 0
2023-02-22 01:52:49,795 DEBUG TRAIN Batch 13/3000 loss 23.155024 loss_att 21.775242 loss_ctc 29.953342 loss_rnnt 22.399788 hw_loss 0.233903 lr 0.00047358 rank 2
2023-02-22 01:52:49,796 DEBUG TRAIN Batch 13/3000 loss 20.604767 loss_att 24.858000 loss_ctc 26.064606 loss_rnnt 18.881866 hw_loss 0.270515 lr 0.00047364 rank 6
2023-02-22 01:52:49,797 DEBUG TRAIN Batch 13/3000 loss 19.592134 loss_att 25.755695 loss_ctc 27.550121 loss_rnnt 17.218315 hw_loss 0.150080 lr 0.00047361 rank 3
2023-02-22 01:54:04,598 DEBUG TRAIN Batch 13/3100 loss 10.908222 loss_att 16.089487 loss_ctc 11.633722 loss_rnnt 9.687331 hw_loss 0.164824 lr 0.00047341 rank 7
2023-02-22 01:54:04,603 DEBUG TRAIN Batch 13/3100 loss 11.204277 loss_att 10.783002 loss_ctc 14.614542 loss_rnnt 10.634333 hw_loss 0.374058 lr 0.00047349 rank 0
2023-02-22 01:54:04,603 DEBUG TRAIN Batch 13/3100 loss 19.487156 loss_att 20.814648 loss_ctc 21.377838 loss_rnnt 18.957811 hw_loss 0.022038 lr 0.00047340 rank 4
2023-02-22 01:54:04,605 DEBUG TRAIN Batch 13/3100 loss 9.350566 loss_att 10.815820 loss_ctc 10.282190 loss_rnnt 8.822767 hw_loss 0.207245 lr 0.00047349 rank 1
2023-02-22 01:54:04,605 DEBUG TRAIN Batch 13/3100 loss 4.858430 loss_att 11.000246 loss_ctc 7.426977 loss_rnnt 3.263250 hw_loss 0.045644 lr 0.00047342 rank 5
2023-02-22 01:54:04,606 DEBUG TRAIN Batch 13/3100 loss 23.813629 loss_att 26.288414 loss_ctc 28.308622 loss_rnnt 22.620665 hw_loss 0.185017 lr 0.00047337 rank 2
2023-02-22 01:54:04,607 DEBUG TRAIN Batch 13/3100 loss 22.513609 loss_att 26.887684 loss_ctc 25.442133 loss_rnnt 21.072683 hw_loss 0.329329 lr 0.00047340 rank 3
2023-02-22 01:54:04,616 DEBUG TRAIN Batch 13/3100 loss 8.756645 loss_att 12.025089 loss_ctc 12.565567 loss_rnnt 7.436668 hw_loss 0.297060 lr 0.00047343 rank 6
2023-02-22 01:55:22,868 DEBUG TRAIN Batch 13/3200 loss 11.341497 loss_att 12.665030 loss_ctc 14.054431 loss_rnnt 10.587924 hw_loss 0.238393 lr 0.00047320 rank 7
2023-02-22 01:55:22,867 DEBUG TRAIN Batch 13/3200 loss 13.419827 loss_att 13.898752 loss_ctc 16.001846 loss_rnnt 12.830374 hw_loss 0.280125 lr 0.00047319 rank 4
2023-02-22 01:55:22,868 DEBUG TRAIN Batch 13/3200 loss 6.796241 loss_att 7.899723 loss_ctc 9.109527 loss_rnnt 6.143236 hw_loss 0.232256 lr 0.00047322 rank 6
2023-02-22 01:55:22,869 DEBUG TRAIN Batch 13/3200 loss 22.613155 loss_att 25.213249 loss_ctc 28.453812 loss_rnnt 21.226154 hw_loss 0.165425 lr 0.00047321 rank 5
2023-02-22 01:55:22,873 DEBUG TRAIN Batch 13/3200 loss 15.572501 loss_att 18.485106 loss_ctc 16.929136 loss_rnnt 14.771818 hw_loss 0.069896 lr 0.00047327 rank 0
2023-02-22 01:55:22,876 DEBUG TRAIN Batch 13/3200 loss 12.072226 loss_att 13.045789 loss_ctc 12.957530 loss_rnnt 11.738471 hw_loss 0.039381 lr 0.00047319 rank 3
2023-02-22 01:55:22,877 DEBUG TRAIN Batch 13/3200 loss 14.262603 loss_att 12.982867 loss_ctc 17.655931 loss_rnnt 13.949913 hw_loss 0.217861 lr 0.00047316 rank 2
2023-02-22 01:55:22,879 DEBUG TRAIN Batch 13/3200 loss 14.106286 loss_att 12.741572 loss_ctc 16.143061 loss_rnnt 13.962023 hw_loss 0.273066 lr 0.00047328 rank 1
2023-02-22 01:56:38,232 DEBUG TRAIN Batch 13/3300 loss 23.918589 loss_att 25.783163 loss_ctc 33.815613 loss_rnnt 22.102642 hw_loss 0.231434 lr 0.00047306 rank 0
2023-02-22 01:56:38,233 DEBUG TRAIN Batch 13/3300 loss 11.789950 loss_att 14.950126 loss_ctc 12.420622 loss_rnnt 11.030681 hw_loss 0.080897 lr 0.00047298 rank 4
2023-02-22 01:56:38,237 DEBUG TRAIN Batch 13/3300 loss 3.942357 loss_att 8.221569 loss_ctc 6.662630 loss_rnnt 2.644224 hw_loss 0.149227 lr 0.00047298 rank 7
2023-02-22 01:56:38,237 DEBUG TRAIN Batch 13/3300 loss 4.574285 loss_att 8.023027 loss_ctc 5.690675 loss_rnnt 3.662570 hw_loss 0.137089 lr 0.00047299 rank 5
2023-02-22 01:56:38,239 DEBUG TRAIN Batch 13/3300 loss 16.877808 loss_att 19.683538 loss_ctc 17.616207 loss_rnnt 16.138521 hw_loss 0.149414 lr 0.00047298 rank 3
2023-02-22 01:56:38,240 DEBUG TRAIN Batch 13/3300 loss 7.157262 loss_att 14.950148 loss_ctc 10.195100 loss_rnnt 5.158915 hw_loss 0.065110 lr 0.00047300 rank 6
2023-02-22 01:56:38,250 DEBUG TRAIN Batch 13/3300 loss 11.685075 loss_att 19.661421 loss_ctc 18.808302 loss_rnnt 9.010152 hw_loss 0.243544 lr 0.00047295 rank 2
2023-02-22 01:56:38,256 DEBUG TRAIN Batch 13/3300 loss 5.732341 loss_att 10.054939 loss_ctc 10.321407 loss_rnnt 4.190400 hw_loss 0.122897 lr 0.00047306 rank 1
2023-02-22 01:57:53,009 DEBUG TRAIN Batch 13/3400 loss 7.296451 loss_att 9.627391 loss_ctc 10.643802 loss_rnnt 6.260230 hw_loss 0.231975 lr 0.00047276 rank 3
2023-02-22 01:57:53,009 DEBUG TRAIN Batch 13/3400 loss 10.704502 loss_att 14.022455 loss_ctc 12.808088 loss_rnnt 9.725218 hw_loss 0.066026 lr 0.00047285 rank 0
2023-02-22 01:57:53,012 DEBUG TRAIN Batch 13/3400 loss 19.596493 loss_att 22.229456 loss_ctc 25.981785 loss_rnnt 18.164614 hw_loss 0.101084 lr 0.00047274 rank 2
2023-02-22 01:57:53,014 DEBUG TRAIN Batch 13/3400 loss 13.909205 loss_att 15.986570 loss_ctc 16.051926 loss_rnnt 13.104980 hw_loss 0.193230 lr 0.00047277 rank 7
2023-02-22 01:57:53,013 DEBUG TRAIN Batch 13/3400 loss 12.402987 loss_att 15.380310 loss_ctc 13.669991 loss_rnnt 11.532845 hw_loss 0.198266 lr 0.00047278 rank 5
2023-02-22 01:57:53,013 DEBUG TRAIN Batch 13/3400 loss 8.548837 loss_att 13.207102 loss_ctc 13.534157 loss_rnnt 6.903461 hw_loss 0.091901 lr 0.00047277 rank 4
2023-02-22 01:57:53,015 DEBUG TRAIN Batch 13/3400 loss 5.624757 loss_att 9.462978 loss_ctc 7.987386 loss_rnnt 4.406163 hw_loss 0.254872 lr 0.00047285 rank 1
2023-02-22 01:57:53,017 DEBUG TRAIN Batch 13/3400 loss 7.600112 loss_att 11.770050 loss_ctc 11.698296 loss_rnnt 6.188781 hw_loss 0.057974 lr 0.00047279 rank 6
2023-02-22 01:59:09,738 DEBUG TRAIN Batch 13/3500 loss 11.239441 loss_att 16.140182 loss_ctc 15.767651 loss_rnnt 9.567854 hw_loss 0.164397 lr 0.00047256 rank 7
2023-02-22 01:59:09,741 DEBUG TRAIN Batch 13/3500 loss 14.831836 loss_att 19.283998 loss_ctc 15.497948 loss_rnnt 13.825343 hw_loss 0.051083 lr 0.00047255 rank 3
2023-02-22 01:59:09,741 DEBUG TRAIN Batch 13/3500 loss 9.972786 loss_att 12.277101 loss_ctc 10.006813 loss_rnnt 9.442218 hw_loss 0.122192 lr 0.00047264 rank 1
2023-02-22 01:59:09,743 DEBUG TRAIN Batch 13/3500 loss 16.074175 loss_att 18.120295 loss_ctc 22.127926 loss_rnnt 14.761852 hw_loss 0.179872 lr 0.00047253 rank 2
2023-02-22 01:59:09,745 DEBUG TRAIN Batch 13/3500 loss 16.420012 loss_att 17.944355 loss_ctc 20.657124 loss_rnnt 15.439608 hw_loss 0.207352 lr 0.00047257 rank 5
2023-02-22 01:59:09,746 DEBUG TRAIN Batch 13/3500 loss 12.960418 loss_att 17.968222 loss_ctc 17.735111 loss_rnnt 11.245728 hw_loss 0.143443 lr 0.00047264 rank 0
2023-02-22 01:59:09,746 DEBUG TRAIN Batch 13/3500 loss 21.141085 loss_att 25.400560 loss_ctc 25.764118 loss_rnnt 19.621769 hw_loss 0.095658 lr 0.00047255 rank 4
2023-02-22 01:59:09,772 DEBUG TRAIN Batch 13/3500 loss 5.712042 loss_att 9.819954 loss_ctc 6.289932 loss_rnnt 4.770396 hw_loss 0.080645 lr 0.00047258 rank 6
2023-02-22 02:00:26,621 DEBUG TRAIN Batch 13/3600 loss 8.236182 loss_att 11.826557 loss_ctc 9.869831 loss_rnnt 7.201053 hw_loss 0.186064 lr 0.00047235 rank 7
2023-02-22 02:00:26,623 DEBUG TRAIN Batch 13/3600 loss 10.812829 loss_att 13.131660 loss_ctc 12.236503 loss_rnnt 10.003399 hw_loss 0.292205 lr 0.00047234 rank 4
2023-02-22 02:00:26,625 DEBUG TRAIN Batch 13/3600 loss 12.789035 loss_att 15.854931 loss_ctc 15.965315 loss_rnnt 11.713413 hw_loss 0.073008 lr 0.00047236 rank 5
2023-02-22 02:00:26,626 DEBUG TRAIN Batch 13/3600 loss 10.914720 loss_att 12.905556 loss_ctc 15.814046 loss_rnnt 9.826988 hw_loss 0.068100 lr 0.00047243 rank 0
2023-02-22 02:00:26,629 DEBUG TRAIN Batch 13/3600 loss 14.829660 loss_att 17.880100 loss_ctc 20.661150 loss_rnnt 13.335617 hw_loss 0.199542 lr 0.00047237 rank 6
2023-02-22 02:00:26,630 DEBUG TRAIN Batch 13/3600 loss 4.906783 loss_att 8.086123 loss_ctc 7.443539 loss_rnnt 3.863564 hw_loss 0.129594 lr 0.00047243 rank 1
2023-02-22 02:00:26,634 DEBUG TRAIN Batch 13/3600 loss 14.004942 loss_att 16.184120 loss_ctc 19.764593 loss_rnnt 12.787100 hw_loss 0.026350 lr 0.00047231 rank 2
2023-02-22 02:00:26,676 DEBUG TRAIN Batch 13/3600 loss 19.593922 loss_att 21.841656 loss_ctc 23.004480 loss_rnnt 18.617283 hw_loss 0.135654 lr 0.00047234 rank 3
2023-02-22 02:01:41,131 DEBUG TRAIN Batch 13/3700 loss 11.275917 loss_att 12.490355 loss_ctc 13.425056 loss_rnnt 10.685923 hw_loss 0.113540 lr 0.00047214 rank 7
2023-02-22 02:01:41,137 DEBUG TRAIN Batch 13/3700 loss 6.869948 loss_att 10.614540 loss_ctc 10.290828 loss_rnnt 5.579775 hw_loss 0.159630 lr 0.00047215 rank 5
2023-02-22 02:01:41,138 DEBUG TRAIN Batch 13/3700 loss 44.767719 loss_att 49.421242 loss_ctc 57.276802 loss_rnnt 42.085529 hw_loss 0.156762 lr 0.00047213 rank 4
2023-02-22 02:01:41,139 DEBUG TRAIN Batch 13/3700 loss 17.663422 loss_att 19.160004 loss_ctc 23.894527 loss_rnnt 16.467525 hw_loss 0.123308 lr 0.00047222 rank 0
2023-02-22 02:01:41,140 DEBUG TRAIN Batch 13/3700 loss 13.885433 loss_att 18.603973 loss_ctc 16.663303 loss_rnnt 12.530430 hw_loss 0.076710 lr 0.00047222 rank 1
2023-02-22 02:01:41,140 DEBUG TRAIN Batch 13/3700 loss 16.105869 loss_att 16.199539 loss_ctc 17.888119 loss_rnnt 15.810339 hw_loss 0.073431 lr 0.00047213 rank 3
2023-02-22 02:01:41,141 DEBUG TRAIN Batch 13/3700 loss 4.672057 loss_att 7.958981 loss_ctc 6.978102 loss_rnnt 3.627534 hw_loss 0.149372 lr 0.00047216 rank 6
2023-02-22 02:01:41,150 DEBUG TRAIN Batch 13/3700 loss 8.224969 loss_att 10.081285 loss_ctc 9.831833 loss_rnnt 7.600541 hw_loss 0.072969 lr 0.00047210 rank 2
2023-02-22 02:02:55,653 DEBUG TRAIN Batch 13/3800 loss 16.102583 loss_att 18.985016 loss_ctc 21.987728 loss_rnnt 14.634549 hw_loss 0.200362 lr 0.00047193 rank 7
2023-02-22 02:02:55,653 DEBUG TRAIN Batch 13/3800 loss 10.629641 loss_att 18.027475 loss_ctc 15.391281 loss_rnnt 8.430418 hw_loss 0.158944 lr 0.00047201 rank 0
2023-02-22 02:02:55,655 DEBUG TRAIN Batch 13/3800 loss 9.957056 loss_att 10.045147 loss_ctc 12.088011 loss_rnnt 9.573825 hw_loss 0.152786 lr 0.00047195 rank 6
2023-02-22 02:02:55,656 DEBUG TRAIN Batch 13/3800 loss 13.610197 loss_att 15.920559 loss_ctc 20.471273 loss_rnnt 12.053221 hw_loss 0.337677 lr 0.00047192 rank 4
2023-02-22 02:02:55,659 DEBUG TRAIN Batch 13/3800 loss 6.643739 loss_att 11.596981 loss_ctc 8.318341 loss_rnnt 5.428668 hw_loss 0.002140 lr 0.00047194 rank 5
2023-02-22 02:02:55,661 DEBUG TRAIN Batch 13/3800 loss 37.781796 loss_att 34.799728 loss_ctc 41.672783 loss_rnnt 37.720345 hw_loss 0.260753 lr 0.00047201 rank 1
2023-02-22 02:02:55,663 DEBUG TRAIN Batch 13/3800 loss 18.503128 loss_att 16.707638 loss_ctc 22.890577 loss_rnnt 18.155155 hw_loss 0.228897 lr 0.00047192 rank 3
2023-02-22 02:02:55,665 DEBUG TRAIN Batch 13/3800 loss 10.545997 loss_att 12.901434 loss_ctc 14.155289 loss_rnnt 9.474902 hw_loss 0.222690 lr 0.00047189 rank 2
2023-02-22 02:04:12,626 DEBUG TRAIN Batch 13/3900 loss 14.145049 loss_att 16.811352 loss_ctc 20.366323 loss_rnnt 12.686279 hw_loss 0.180010 lr 0.00047172 rank 7
2023-02-22 02:04:12,628 DEBUG TRAIN Batch 13/3900 loss 18.485195 loss_att 26.226124 loss_ctc 26.734266 loss_rnnt 15.768311 hw_loss 0.129041 lr 0.00047171 rank 3
2023-02-22 02:04:12,630 DEBUG TRAIN Batch 13/3900 loss 4.790878 loss_att 8.778403 loss_ctc 6.452533 loss_rnnt 3.680425 hw_loss 0.171363 lr 0.00047173 rank 5
2023-02-22 02:04:12,632 DEBUG TRAIN Batch 13/3900 loss 13.131182 loss_att 16.510071 loss_ctc 16.838776 loss_rnnt 11.926321 hw_loss 0.065130 lr 0.00047180 rank 0
2023-02-22 02:04:12,632 DEBUG TRAIN Batch 13/3900 loss 10.880504 loss_att 13.645464 loss_ctc 13.208824 loss_rnnt 9.892043 hw_loss 0.234423 lr 0.00047174 rank 6
2023-02-22 02:04:12,632 DEBUG TRAIN Batch 13/3900 loss 15.406694 loss_att 25.752138 loss_ctc 17.336140 loss_rnnt 12.981581 hw_loss 0.185186 lr 0.00047180 rank 1
2023-02-22 02:04:12,646 DEBUG TRAIN Batch 13/3900 loss 10.495568 loss_att 13.273639 loss_ctc 11.153613 loss_rnnt 9.850155 hw_loss 0.003863 lr 0.00047171 rank 4
2023-02-22 02:04:12,653 DEBUG TRAIN Batch 13/3900 loss 19.223299 loss_att 27.417395 loss_ctc 28.101027 loss_rnnt 16.249521 hw_loss 0.283611 lr 0.00047168 rank 2
2023-02-22 02:05:26,632 DEBUG TRAIN Batch 13/4000 loss 15.946570 loss_att 20.625263 loss_ctc 16.490280 loss_rnnt 14.906521 hw_loss 0.059656 lr 0.00047150 rank 3
2023-02-22 02:05:26,633 DEBUG TRAIN Batch 13/4000 loss 18.635979 loss_att 21.857941 loss_ctc 24.522873 loss_rnnt 17.090847 hw_loss 0.217161 lr 0.00047159 rank 0
2023-02-22 02:05:26,633 DEBUG TRAIN Batch 13/4000 loss 9.207416 loss_att 15.342703 loss_ctc 13.182360 loss_rnnt 7.340297 hw_loss 0.206377 lr 0.00047150 rank 4
2023-02-22 02:05:26,634 DEBUG TRAIN Batch 13/4000 loss 18.881639 loss_att 23.127298 loss_ctc 24.765171 loss_rnnt 17.226809 hw_loss 0.039801 lr 0.00047153 rank 6
2023-02-22 02:05:26,636 DEBUG TRAIN Batch 13/4000 loss 10.299171 loss_att 12.662598 loss_ctc 11.592482 loss_rnnt 9.609178 hw_loss 0.084125 lr 0.00047152 rank 5
2023-02-22 02:05:26,638 DEBUG TRAIN Batch 13/4000 loss 12.805513 loss_att 22.208874 loss_ctc 12.873459 loss_rnnt 10.890142 hw_loss 0.048075 lr 0.00047151 rank 7
2023-02-22 02:05:26,640 DEBUG TRAIN Batch 13/4000 loss 18.891499 loss_att 20.038799 loss_ctc 20.961411 loss_rnnt 18.317595 hw_loss 0.128354 lr 0.00047159 rank 1
2023-02-22 02:05:26,645 DEBUG TRAIN Batch 13/4000 loss 15.512609 loss_att 19.963112 loss_ctc 20.630013 loss_rnnt 13.824633 hw_loss 0.216665 lr 0.00047147 rank 2
2023-02-22 02:06:42,305 DEBUG TRAIN Batch 13/4100 loss 15.797041 loss_att 22.877298 loss_ctc 20.670300 loss_rnnt 13.694365 hw_loss 0.069107 lr 0.00047138 rank 1
2023-02-22 02:06:42,305 DEBUG TRAIN Batch 13/4100 loss 11.126894 loss_att 16.496864 loss_ctc 16.284304 loss_rnnt 9.253646 hw_loss 0.209250 lr 0.00047138 rank 0
2023-02-22 02:06:42,307 DEBUG TRAIN Batch 13/4100 loss 5.278473 loss_att 8.998281 loss_ctc 5.735401 loss_rnnt 4.384168 hw_loss 0.167662 lr 0.00047129 rank 4
2023-02-22 02:06:42,308 DEBUG TRAIN Batch 13/4100 loss 4.708203 loss_att 8.581290 loss_ctc 8.420274 loss_rnnt 3.379054 hw_loss 0.111730 lr 0.00047130 rank 7
2023-02-22 02:06:42,308 DEBUG TRAIN Batch 13/4100 loss 17.420300 loss_att 17.691418 loss_ctc 19.554010 loss_rnnt 16.990402 hw_loss 0.170960 lr 0.00047126 rank 2
2023-02-22 02:06:42,311 DEBUG TRAIN Batch 13/4100 loss 17.999872 loss_att 20.917852 loss_ctc 24.263607 loss_rnnt 16.497162 hw_loss 0.157405 lr 0.00047131 rank 5
2023-02-22 02:06:42,312 DEBUG TRAIN Batch 13/4100 loss 14.954899 loss_att 18.777264 loss_ctc 19.489456 loss_rnnt 13.479426 hw_loss 0.199485 lr 0.00047132 rank 6
2023-02-22 02:06:42,315 DEBUG TRAIN Batch 13/4100 loss 8.166154 loss_att 12.083073 loss_ctc 11.564795 loss_rnnt 6.901787 hw_loss 0.052182 lr 0.00047129 rank 3
2023-02-22 02:07:58,347 DEBUG TRAIN Batch 13/4200 loss 20.565546 loss_att 20.808130 loss_ctc 32.074829 loss_rnnt 18.940514 hw_loss 0.078645 lr 0.00047109 rank 7
2023-02-22 02:07:58,348 DEBUG TRAIN Batch 13/4200 loss 10.260024 loss_att 17.586412 loss_ctc 13.184150 loss_rnnt 8.380033 hw_loss 0.046556 lr 0.00047108 rank 4
2023-02-22 02:07:58,349 DEBUG TRAIN Batch 13/4200 loss 12.469337 loss_att 15.302056 loss_ctc 14.459524 loss_rnnt 11.549726 hw_loss 0.164454 lr 0.00047117 rank 0
2023-02-22 02:07:58,350 DEBUG TRAIN Batch 13/4200 loss 10.282642 loss_att 11.943807 loss_ctc 15.545793 loss_rnnt 9.161304 hw_loss 0.163784 lr 0.00047106 rank 2
2023-02-22 02:07:58,351 DEBUG TRAIN Batch 13/4200 loss 9.550658 loss_att 13.046225 loss_ctc 12.474358 loss_rnnt 8.342190 hw_loss 0.224115 lr 0.00047110 rank 5
2023-02-22 02:07:58,354 DEBUG TRAIN Batch 13/4200 loss 13.646877 loss_att 17.325972 loss_ctc 22.474308 loss_rnnt 11.644737 hw_loss 0.167495 lr 0.00047111 rank 6
2023-02-22 02:07:58,357 DEBUG TRAIN Batch 13/4200 loss 14.725001 loss_att 16.321720 loss_ctc 15.935980 loss_rnnt 14.193631 hw_loss 0.094803 lr 0.00047117 rank 1
2023-02-22 02:07:58,360 DEBUG TRAIN Batch 13/4200 loss 8.905272 loss_att 11.619402 loss_ctc 16.021978 loss_rnnt 7.345881 hw_loss 0.126881 lr 0.00047108 rank 3
2023-02-22 02:09:16,275 DEBUG TRAIN Batch 13/4300 loss 8.624868 loss_att 10.716640 loss_ctc 10.020009 loss_rnnt 7.900275 hw_loss 0.225413 lr 0.00047089 rank 5
2023-02-22 02:09:16,276 DEBUG TRAIN Batch 13/4300 loss 16.089060 loss_att 18.671541 loss_ctc 21.944309 loss_rnnt 14.680631 hw_loss 0.208559 lr 0.00047096 rank 0
2023-02-22 02:09:16,281 DEBUG TRAIN Batch 13/4300 loss 14.451700 loss_att 15.418707 loss_ctc 16.826683 loss_rnnt 13.905979 hw_loss 0.066852 lr 0.00047088 rank 7
2023-02-22 02:09:16,282 DEBUG TRAIN Batch 13/4300 loss 16.377090 loss_att 20.496017 loss_ctc 21.699375 loss_rnnt 14.778723 hw_loss 0.121777 lr 0.00047088 rank 4
2023-02-22 02:09:16,285 DEBUG TRAIN Batch 13/4300 loss 10.226748 loss_att 12.533984 loss_ctc 13.023656 loss_rnnt 9.289785 hw_loss 0.192364 lr 0.00047087 rank 3
2023-02-22 02:09:16,286 DEBUG TRAIN Batch 13/4300 loss 17.279982 loss_att 21.399990 loss_ctc 20.620037 loss_rnnt 15.900099 hw_loss 0.207262 lr 0.00047085 rank 2
2023-02-22 02:09:16,286 DEBUG TRAIN Batch 13/4300 loss 14.338007 loss_att 18.760616 loss_ctc 19.494678 loss_rnnt 12.682340 hw_loss 0.156729 lr 0.00047090 rank 6
2023-02-22 02:09:16,334 DEBUG TRAIN Batch 13/4300 loss 12.654816 loss_att 14.179561 loss_ctc 12.646474 loss_rnnt 12.288793 hw_loss 0.116599 lr 0.00047096 rank 1
2023-02-22 02:10:31,184 DEBUG TRAIN Batch 13/4400 loss 15.402854 loss_att 16.176186 loss_ctc 21.056498 loss_rnnt 14.380172 hw_loss 0.214119 lr 0.00047067 rank 7
2023-02-22 02:10:31,186 DEBUG TRAIN Batch 13/4400 loss 14.879759 loss_att 16.913225 loss_ctc 21.163773 loss_rnnt 13.573903 hw_loss 0.114926 lr 0.00047067 rank 4
2023-02-22 02:10:31,188 DEBUG TRAIN Batch 13/4400 loss 10.311567 loss_att 11.998955 loss_ctc 13.278559 loss_rnnt 9.466205 hw_loss 0.210537 lr 0.00047068 rank 5
2023-02-22 02:10:31,189 DEBUG TRAIN Batch 13/4400 loss 14.282180 loss_att 17.449863 loss_ctc 18.886343 loss_rnnt 12.942179 hw_loss 0.173579 lr 0.00047064 rank 2
2023-02-22 02:10:31,189 DEBUG TRAIN Batch 13/4400 loss 12.215123 loss_att 12.568790 loss_ctc 13.830012 loss_rnnt 11.800877 hw_loss 0.240365 lr 0.00047066 rank 3
2023-02-22 02:10:31,193 DEBUG TRAIN Batch 13/4400 loss 15.206292 loss_att 16.536577 loss_ctc 19.962149 loss_rnnt 14.293857 hw_loss 0.022995 lr 0.00047075 rank 1
2023-02-22 02:10:31,193 DEBUG TRAIN Batch 13/4400 loss 12.524458 loss_att 12.281441 loss_ctc 16.521511 loss_rnnt 11.910589 hw_loss 0.242872 lr 0.00047075 rank 0
2023-02-22 02:10:31,194 DEBUG TRAIN Batch 13/4400 loss 8.543448 loss_att 9.457791 loss_ctc 9.386848 loss_rnnt 8.141613 hw_loss 0.199712 lr 0.00047069 rank 6
2023-02-22 02:11:46,974 DEBUG TRAIN Batch 13/4500 loss 17.749224 loss_att 21.634537 loss_ctc 23.652090 loss_rnnt 16.084101 hw_loss 0.189396 lr 0.00047046 rank 7
2023-02-22 02:11:46,974 DEBUG TRAIN Batch 13/4500 loss 6.895942 loss_att 7.444287 loss_ctc 8.754923 loss_rnnt 6.414206 hw_loss 0.232883 lr 0.00047046 rank 3
2023-02-22 02:11:46,975 DEBUG TRAIN Batch 13/4500 loss 14.550615 loss_att 21.543009 loss_ctc 17.592510 loss_rnnt 12.636009 hw_loss 0.207267 lr 0.00047047 rank 5
2023-02-22 02:11:46,976 DEBUG TRAIN Batch 13/4500 loss 14.225623 loss_att 18.822121 loss_ctc 18.868286 loss_rnnt 12.638119 hw_loss 0.092218 lr 0.00047049 rank 6
2023-02-22 02:11:46,975 DEBUG TRAIN Batch 13/4500 loss 12.600677 loss_att 15.427250 loss_ctc 17.876375 loss_rnnt 11.322113 hw_loss 0.018415 lr 0.00047054 rank 0
2023-02-22 02:11:46,976 DEBUG TRAIN Batch 13/4500 loss 19.432571 loss_att 22.694267 loss_ctc 23.846382 loss_rnnt 18.098185 hw_loss 0.175383 lr 0.00047046 rank 4
2023-02-22 02:11:46,977 DEBUG TRAIN Batch 13/4500 loss 15.010453 loss_att 19.798016 loss_ctc 20.916182 loss_rnnt 13.153645 hw_loss 0.209745 lr 0.00047054 rank 1
2023-02-22 02:11:46,981 DEBUG TRAIN Batch 13/4500 loss 10.337134 loss_att 12.043173 loss_ctc 13.737665 loss_rnnt 9.391763 hw_loss 0.282673 lr 0.00047043 rank 2
2023-02-22 02:13:03,684 DEBUG TRAIN Batch 13/4600 loss 5.792233 loss_att 8.765238 loss_ctc 8.335280 loss_rnnt 4.803712 hw_loss 0.102840 lr 0.00047027 rank 5
2023-02-22 02:13:03,684 DEBUG TRAIN Batch 13/4600 loss 11.050248 loss_att 15.502495 loss_ctc 13.397459 loss_rnnt 9.846165 hw_loss 0.001262 lr 0.00047026 rank 7
2023-02-22 02:13:03,690 DEBUG TRAIN Batch 13/4600 loss 9.795811 loss_att 13.208978 loss_ctc 14.463974 loss_rnnt 8.427043 hw_loss 0.119462 lr 0.00047033 rank 0
2023-02-22 02:13:03,692 DEBUG TRAIN Batch 13/4600 loss 10.076593 loss_att 16.810524 loss_ctc 14.834814 loss_rnnt 8.034840 hw_loss 0.113509 lr 0.00047022 rank 2
2023-02-22 02:13:03,692 DEBUG TRAIN Batch 13/4600 loss 3.960625 loss_att 8.036380 loss_ctc 6.012435 loss_rnnt 2.777562 hw_loss 0.176883 lr 0.00047025 rank 4
2023-02-22 02:13:03,693 DEBUG TRAIN Batch 13/4600 loss 18.365133 loss_att 21.361591 loss_ctc 22.160620 loss_rnnt 17.247473 hw_loss 0.023067 lr 0.00047028 rank 6
2023-02-22 02:13:03,698 DEBUG TRAIN Batch 13/4600 loss 6.378635 loss_att 13.018311 loss_ctc 5.418204 loss_rnnt 5.068276 hw_loss 0.207153 lr 0.00047025 rank 3
2023-02-22 02:13:03,744 DEBUG TRAIN Batch 13/4600 loss 11.204485 loss_att 14.969534 loss_ctc 14.718222 loss_rnnt 9.898151 hw_loss 0.159048 lr 0.00047034 rank 1
2023-02-22 02:14:19,384 DEBUG TRAIN Batch 13/4700 loss 17.862911 loss_att 19.812483 loss_ctc 25.206263 loss_rnnt 16.388655 hw_loss 0.197304 lr 0.00047006 rank 5
2023-02-22 02:14:19,385 DEBUG TRAIN Batch 13/4700 loss 7.574355 loss_att 11.737720 loss_ctc 9.403406 loss_rnnt 6.391885 hw_loss 0.198606 lr 0.00047007 rank 6
2023-02-22 02:14:19,385 DEBUG TRAIN Batch 13/4700 loss 5.284921 loss_att 8.880034 loss_ctc 7.132561 loss_rnnt 4.194025 hw_loss 0.235351 lr 0.00047013 rank 0
2023-02-22 02:14:19,388 DEBUG TRAIN Batch 13/4700 loss 24.562193 loss_att 34.396606 loss_ctc 36.220676 loss_rnnt 20.955170 hw_loss 0.160642 lr 0.00047004 rank 4
2023-02-22 02:14:19,387 DEBUG TRAIN Batch 13/4700 loss 6.080606 loss_att 8.614527 loss_ctc 7.181115 loss_rnnt 5.307861 hw_loss 0.223549 lr 0.00047005 rank 7
2023-02-22 02:14:19,396 DEBUG TRAIN Batch 13/4700 loss 6.869151 loss_att 10.816850 loss_ctc 11.523123 loss_rnnt 5.370149 hw_loss 0.166749 lr 0.00047013 rank 1
2023-02-22 02:14:19,397 DEBUG TRAIN Batch 13/4700 loss 16.923277 loss_att 19.720499 loss_ctc 20.720505 loss_rnnt 15.736996 hw_loss 0.226011 lr 0.00047001 rank 2
2023-02-22 02:14:19,436 DEBUG TRAIN Batch 13/4700 loss 10.306398 loss_att 15.184912 loss_ctc 14.239910 loss_rnnt 8.691772 hw_loss 0.214602 lr 0.00047004 rank 3
2023-02-22 02:15:34,358 DEBUG TRAIN Batch 13/4800 loss 14.027822 loss_att 21.918455 loss_ctc 24.070343 loss_rnnt 11.045830 hw_loss 0.121617 lr 0.00046992 rank 0
2023-02-22 02:15:34,359 DEBUG TRAIN Batch 13/4800 loss 18.839880 loss_att 22.380428 loss_ctc 25.262665 loss_rnnt 17.156496 hw_loss 0.222939 lr 0.00046984 rank 7
2023-02-22 02:15:34,360 DEBUG TRAIN Batch 13/4800 loss 9.523736 loss_att 15.647075 loss_ctc 13.176486 loss_rnnt 7.786326 hw_loss 0.048203 lr 0.00046981 rank 2
2023-02-22 02:15:34,362 DEBUG TRAIN Batch 13/4800 loss 17.674061 loss_att 21.144897 loss_ctc 21.202671 loss_rnnt 16.406719 hw_loss 0.192546 lr 0.00046985 rank 5
2023-02-22 02:15:34,361 DEBUG TRAIN Batch 13/4800 loss 18.779535 loss_att 18.437790 loss_ctc 21.562248 loss_rnnt 18.463535 hw_loss 0.024979 lr 0.00046983 rank 3
2023-02-22 02:15:34,362 DEBUG TRAIN Batch 13/4800 loss 7.544955 loss_att 12.486779 loss_ctc 7.395427 loss_rnnt 6.553435 hw_loss 0.043298 lr 0.00046983 rank 4
2023-02-22 02:15:34,363 DEBUG TRAIN Batch 13/4800 loss 11.412533 loss_att 13.855455 loss_ctc 16.014149 loss_rnnt 10.160995 hw_loss 0.280134 lr 0.00046986 rank 6
2023-02-22 02:15:34,414 DEBUG TRAIN Batch 13/4800 loss 12.143922 loss_att 15.503288 loss_ctc 17.515648 loss_rnnt 10.672116 hw_loss 0.156939 lr 0.00046992 rank 1
2023-02-22 02:16:49,687 DEBUG TRAIN Batch 13/4900 loss 8.646831 loss_att 13.497518 loss_ctc 11.144040 loss_rnnt 7.311430 hw_loss 0.060566 lr 0.00046971 rank 0
2023-02-22 02:16:49,689 DEBUG TRAIN Batch 13/4900 loss 16.938122 loss_att 21.595488 loss_ctc 23.906004 loss_rnnt 14.989124 hw_loss 0.165886 lr 0.00046963 rank 4
2023-02-22 02:16:49,691 DEBUG TRAIN Batch 13/4900 loss 20.522650 loss_att 26.051411 loss_ctc 26.607456 loss_rnnt 18.515587 hw_loss 0.168759 lr 0.00046963 rank 7
2023-02-22 02:16:49,695 DEBUG TRAIN Batch 13/4900 loss 11.853147 loss_att 19.083691 loss_ctc 14.549314 loss_rnnt 9.978954 hw_loss 0.128614 lr 0.00046963 rank 3
2023-02-22 02:16:49,696 DEBUG TRAIN Batch 13/4900 loss 17.563967 loss_att 17.808258 loss_ctc 19.390400 loss_rnnt 17.199314 hw_loss 0.135504 lr 0.00046964 rank 5
2023-02-22 02:16:49,696 DEBUG TRAIN Batch 13/4900 loss 13.734093 loss_att 19.533661 loss_ctc 17.742678 loss_rnnt 11.916805 hw_loss 0.230429 lr 0.00046960 rank 2
2023-02-22 02:16:49,707 DEBUG TRAIN Batch 13/4900 loss 6.775423 loss_att 9.259597 loss_ctc 8.718393 loss_rnnt 5.970476 hw_loss 0.091966 lr 0.00046971 rank 1
2023-02-22 02:16:49,740 DEBUG TRAIN Batch 13/4900 loss 8.787869 loss_att 11.147066 loss_ctc 13.409950 loss_rnnt 7.623504 hw_loss 0.142965 lr 0.00046965 rank 6
2023-02-22 02:18:06,876 DEBUG TRAIN Batch 13/5000 loss 11.468682 loss_att 12.445042 loss_ctc 15.010447 loss_rnnt 10.708721 hw_loss 0.173351 lr 0.00046942 rank 4
2023-02-22 02:18:06,880 DEBUG TRAIN Batch 13/5000 loss 14.171223 loss_att 17.450022 loss_ctc 16.995203 loss_rnnt 13.019132 hw_loss 0.224627 lr 0.00046944 rank 5
2023-02-22 02:18:06,883 DEBUG TRAIN Batch 13/5000 loss 12.193525 loss_att 14.978350 loss_ctc 14.765993 loss_rnnt 11.219984 hw_loss 0.137963 lr 0.00046939 rank 2
2023-02-22 02:18:06,883 DEBUG TRAIN Batch 13/5000 loss 9.255179 loss_att 10.381763 loss_ctc 11.071485 loss_rnnt 8.707358 hw_loss 0.150619 lr 0.00046950 rank 0
2023-02-22 02:18:06,883 DEBUG TRAIN Batch 13/5000 loss 8.469407 loss_att 10.804008 loss_ctc 11.168674 loss_rnnt 7.544713 hw_loss 0.183508 lr 0.00046943 rank 7
2023-02-22 02:18:06,884 DEBUG TRAIN Batch 13/5000 loss 15.939193 loss_att 17.662292 loss_ctc 25.510138 loss_rnnt 14.283772 hw_loss 0.065015 lr 0.00046942 rank 3
2023-02-22 02:18:06,884 DEBUG TRAIN Batch 13/5000 loss 13.272537 loss_att 17.939026 loss_ctc 18.511482 loss_rnnt 11.544579 hw_loss 0.180251 lr 0.00046951 rank 1
2023-02-22 02:18:06,888 DEBUG TRAIN Batch 13/5000 loss 13.065343 loss_att 18.032459 loss_ctc 18.817881 loss_rnnt 11.211009 hw_loss 0.176072 lr 0.00046945 rank 6
2023-02-22 02:19:21,890 DEBUG TRAIN Batch 13/5100 loss 24.015957 loss_att 26.271889 loss_ctc 32.523235 loss_rnnt 22.407211 hw_loss 0.043602 lr 0.00046921 rank 4
2023-02-22 02:19:21,895 DEBUG TRAIN Batch 13/5100 loss 8.169740 loss_att 12.069277 loss_ctc 15.443739 loss_rnnt 6.322664 hw_loss 0.182441 lr 0.00046930 rank 0
2023-02-22 02:19:21,895 DEBUG TRAIN Batch 13/5100 loss 12.469912 loss_att 13.453964 loss_ctc 14.616308 loss_rnnt 11.803406 hw_loss 0.344078 lr 0.00046922 rank 7
2023-02-22 02:19:21,897 DEBUG TRAIN Batch 13/5100 loss 10.857232 loss_att 15.639194 loss_ctc 12.359007 loss_rnnt 9.639509 hw_loss 0.114551 lr 0.00046923 rank 5
2023-02-22 02:19:21,900 DEBUG TRAIN Batch 13/5100 loss 7.847490 loss_att 9.111138 loss_ctc 11.288013 loss_rnnt 7.008660 hw_loss 0.238805 lr 0.00046930 rank 1
2023-02-22 02:19:21,903 DEBUG TRAIN Batch 13/5100 loss 15.269140 loss_att 19.894028 loss_ctc 24.344158 loss_rnnt 13.067916 hw_loss 0.124208 lr 0.00046918 rank 2
2023-02-22 02:19:21,903 DEBUG TRAIN Batch 13/5100 loss 7.995615 loss_att 8.731304 loss_ctc 11.254436 loss_rnnt 7.316312 hw_loss 0.183103 lr 0.00046921 rank 3
2023-02-22 02:19:21,945 DEBUG TRAIN Batch 13/5100 loss 17.976595 loss_att 18.765770 loss_ctc 22.041367 loss_rnnt 17.106045 hw_loss 0.320149 lr 0.00046924 rank 6
2023-02-22 02:20:38,132 DEBUG TRAIN Batch 13/5200 loss 13.254044 loss_att 14.028236 loss_ctc 16.557564 loss_rnnt 12.577853 hw_loss 0.151657 lr 0.00046901 rank 4
2023-02-22 02:20:38,132 DEBUG TRAIN Batch 13/5200 loss 12.587158 loss_att 14.718280 loss_ctc 12.147940 loss_rnnt 12.183222 hw_loss 0.068015 lr 0.00046909 rank 0
2023-02-22 02:20:38,135 DEBUG TRAIN Batch 13/5200 loss 18.200207 loss_att 20.770760 loss_ctc 20.067932 loss_rnnt 17.354904 hw_loss 0.154052 lr 0.00046901 rank 3
2023-02-22 02:20:38,137 DEBUG TRAIN Batch 13/5200 loss 24.867462 loss_att 26.659437 loss_ctc 31.167503 loss_rnnt 23.655256 hw_loss 0.025883 lr 0.00046901 rank 7
2023-02-22 02:20:38,139 DEBUG TRAIN Batch 13/5200 loss 8.100985 loss_att 12.078687 loss_ctc 12.138747 loss_rnnt 6.679946 hw_loss 0.163368 lr 0.00046903 rank 6
2023-02-22 02:20:38,142 DEBUG TRAIN Batch 13/5200 loss 9.531798 loss_att 13.005581 loss_ctc 12.046324 loss_rnnt 8.416531 hw_loss 0.159826 lr 0.00046902 rank 5
2023-02-22 02:20:38,142 DEBUG TRAIN Batch 13/5200 loss 10.662672 loss_att 12.308373 loss_ctc 13.245172 loss_rnnt 9.839725 hw_loss 0.280261 lr 0.00046898 rank 2
2023-02-22 02:20:38,185 DEBUG TRAIN Batch 13/5200 loss 20.030090 loss_att 22.035713 loss_ctc 32.342445 loss_rnnt 17.897326 hw_loss 0.168735 lr 0.00046909 rank 1
2023-02-22 02:21:56,012 DEBUG TRAIN Batch 13/5300 loss 16.751392 loss_att 25.558765 loss_ctc 24.074657 loss_rnnt 13.946689 hw_loss 0.125235 lr 0.00046888 rank 0
2023-02-22 02:21:56,013 DEBUG TRAIN Batch 13/5300 loss 18.606110 loss_att 23.368818 loss_ctc 26.970360 loss_rnnt 16.493422 hw_loss 0.084215 lr 0.00046880 rank 4
2023-02-22 02:21:56,017 DEBUG TRAIN Batch 13/5300 loss 13.434468 loss_att 15.780960 loss_ctc 13.322220 loss_rnnt 12.913749 hw_loss 0.124477 lr 0.00046881 rank 7
2023-02-22 02:21:56,018 DEBUG TRAIN Batch 13/5300 loss 16.369938 loss_att 19.748671 loss_ctc 17.214518 loss_rnnt 15.490982 hw_loss 0.169872 lr 0.00046889 rank 1
2023-02-22 02:21:56,020 DEBUG TRAIN Batch 13/5300 loss 6.246125 loss_att 11.013616 loss_ctc 10.417793 loss_rnnt 4.654774 hw_loss 0.153057 lr 0.00046883 rank 6
2023-02-22 02:21:56,021 DEBUG TRAIN Batch 13/5300 loss 5.712497 loss_att 8.062163 loss_ctc 3.991534 loss_rnnt 5.427711 hw_loss 0.083092 lr 0.00046882 rank 5
2023-02-22 02:21:56,040 DEBUG TRAIN Batch 13/5300 loss 23.533817 loss_att 27.708134 loss_ctc 32.380653 loss_rnnt 21.418257 hw_loss 0.189602 lr 0.00046880 rank 3
2023-02-22 02:21:56,047 DEBUG TRAIN Batch 13/5300 loss 11.213588 loss_att 12.231333 loss_ctc 13.260851 loss_rnnt 10.709501 hw_loss 0.051693 lr 0.00046877 rank 2
2023-02-22 02:23:12,077 DEBUG TRAIN Batch 13/5400 loss 14.777048 loss_att 19.813641 loss_ctc 20.244389 loss_rnnt 12.887098 hw_loss 0.288101 lr 0.00046860 rank 7
2023-02-22 02:23:12,079 DEBUG TRAIN Batch 13/5400 loss 34.052010 loss_att 36.839844 loss_ctc 47.051933 loss_rnnt 31.739384 hw_loss 0.040754 lr 0.00046862 rank 6
2023-02-22 02:23:12,080 DEBUG TRAIN Batch 13/5400 loss 21.770561 loss_att 26.311089 loss_ctc 27.021992 loss_rnnt 20.021935 hw_loss 0.263119 lr 0.00046868 rank 0
2023-02-22 02:23:12,083 DEBUG TRAIN Batch 13/5400 loss 9.877637 loss_att 12.802614 loss_ctc 12.547047 loss_rnnt 8.894287 hw_loss 0.079562 lr 0.00046861 rank 5
2023-02-22 02:23:12,082 DEBUG TRAIN Batch 13/5400 loss 12.251565 loss_att 15.704612 loss_ctc 16.122028 loss_rnnt 11.028837 hw_loss 0.030107 lr 0.00046860 rank 4
2023-02-22 02:23:12,084 DEBUG TRAIN Batch 13/5400 loss 14.474648 loss_att 19.704849 loss_ctc 15.056733 loss_rnnt 13.331051 hw_loss 0.037398 lr 0.00046859 rank 3
2023-02-22 02:23:12,086 DEBUG TRAIN Batch 13/5400 loss 11.768703 loss_att 16.275965 loss_ctc 16.037998 loss_rnnt 10.225098 hw_loss 0.136711 lr 0.00046868 rank 1
2023-02-22 02:23:12,087 DEBUG TRAIN Batch 13/5400 loss 6.059457 loss_att 12.414389 loss_ctc 8.231678 loss_rnnt 4.413156 hw_loss 0.160660 lr 0.00046857 rank 2
2023-02-22 02:24:28,139 DEBUG TRAIN Batch 13/5500 loss 17.224215 loss_att 24.173372 loss_ctc 24.339613 loss_rnnt 14.843361 hw_loss 0.079318 lr 0.00046841 rank 5
2023-02-22 02:24:28,141 DEBUG TRAIN Batch 13/5500 loss 35.354477 loss_att 34.634483 loss_ctc 48.472767 loss_rnnt 33.657269 hw_loss 0.172691 lr 0.00046840 rank 7
2023-02-22 02:24:28,143 DEBUG TRAIN Batch 13/5500 loss 13.355473 loss_att 16.549524 loss_ctc 15.133852 loss_rnnt 12.385108 hw_loss 0.177072 lr 0.00046847 rank 0
2023-02-22 02:24:28,147 DEBUG TRAIN Batch 13/5500 loss 10.277764 loss_att 14.050503 loss_ctc 11.031223 loss_rnnt 9.377394 hw_loss 0.085053 lr 0.00046847 rank 1
2023-02-22 02:24:28,147 DEBUG TRAIN Batch 13/5500 loss 14.494708 loss_att 16.014574 loss_ctc 17.088001 loss_rnnt 13.771152 hw_loss 0.138395 lr 0.00046839 rank 4
2023-02-22 02:24:28,150 DEBUG TRAIN Batch 13/5500 loss 9.752236 loss_att 11.288012 loss_ctc 11.393078 loss_rnnt 9.122684 hw_loss 0.194285 lr 0.00046839 rank 3
2023-02-22 02:24:28,152 DEBUG TRAIN Batch 13/5500 loss 15.219644 loss_att 18.550293 loss_ctc 18.772831 loss_rnnt 13.967375 hw_loss 0.210713 lr 0.00046836 rank 2
2023-02-22 02:24:28,196 DEBUG TRAIN Batch 13/5500 loss 12.646675 loss_att 15.491004 loss_ctc 17.977106 loss_rnnt 11.330080 hw_loss 0.069384 lr 0.00046842 rank 6
2023-02-22 02:25:44,680 DEBUG TRAIN Batch 13/5600 loss 11.214613 loss_att 12.299410 loss_ctc 16.904484 loss_rnnt 10.125541 hw_loss 0.212743 lr 0.00046827 rank 0
2023-02-22 02:25:44,685 DEBUG TRAIN Batch 13/5600 loss 18.777554 loss_att 20.769014 loss_ctc 24.966759 loss_rnnt 17.485561 hw_loss 0.128385 lr 0.00046827 rank 1
2023-02-22 02:25:44,684 DEBUG TRAIN Batch 13/5600 loss 11.946966 loss_att 13.498567 loss_ctc 17.271473 loss_rnnt 10.881635 hw_loss 0.084519 lr 0.00046821 rank 6
2023-02-22 02:25:44,685 DEBUG TRAIN Batch 13/5600 loss 19.271851 loss_att 19.890518 loss_ctc 23.252966 loss_rnnt 18.613781 hw_loss 0.006600 lr 0.00046818 rank 4
2023-02-22 02:25:44,686 DEBUG TRAIN Batch 13/5600 loss 11.925378 loss_att 13.743191 loss_ctc 17.542469 loss_rnnt 10.753029 hw_loss 0.112203 lr 0.00046820 rank 5
2023-02-22 02:25:44,687 DEBUG TRAIN Batch 13/5600 loss 20.464375 loss_att 21.384663 loss_ctc 24.282032 loss_rnnt 19.698265 hw_loss 0.136932 lr 0.00046819 rank 7
2023-02-22 02:25:44,687 DEBUG TRAIN Batch 13/5600 loss 10.534088 loss_att 15.907197 loss_ctc 16.780552 loss_rnnt 8.602299 hw_loss 0.045574 lr 0.00046816 rank 2
2023-02-22 02:25:44,689 DEBUG TRAIN Batch 13/5600 loss 24.724102 loss_att 27.515617 loss_ctc 26.726851 loss_rnnt 23.763256 hw_loss 0.254081 lr 0.00046818 rank 3
2023-02-22 02:27:02,430 DEBUG TRAIN Batch 13/5700 loss 15.409477 loss_att 18.720642 loss_ctc 21.512222 loss_rnnt 13.847522 hw_loss 0.161295 lr 0.00046799 rank 7
2023-02-22 02:27:02,435 DEBUG TRAIN Batch 13/5700 loss 30.948454 loss_att 41.088577 loss_ctc 43.910816 loss_rnnt 27.143845 hw_loss 0.090505 lr 0.00046801 rank 6
2023-02-22 02:27:02,435 DEBUG TRAIN Batch 13/5700 loss 28.278622 loss_att 25.899868 loss_ctc 32.425755 loss_rnnt 28.046124 hw_loss 0.291188 lr 0.00046798 rank 4
2023-02-22 02:27:02,438 DEBUG TRAIN Batch 13/5700 loss 9.212100 loss_att 10.948812 loss_ctc 12.822235 loss_rnnt 8.337347 hw_loss 0.086360 lr 0.00046806 rank 1
2023-02-22 02:27:02,440 DEBUG TRAIN Batch 13/5700 loss 8.216075 loss_att 12.658024 loss_ctc 8.812231 loss_rnnt 7.118864 hw_loss 0.242499 lr 0.00046795 rank 2
2023-02-22 02:27:02,446 DEBUG TRAIN Batch 13/5700 loss 15.816327 loss_att 25.771637 loss_ctc 19.608160 loss_rnnt 13.268840 hw_loss 0.095338 lr 0.00046806 rank 0
2023-02-22 02:27:02,456 DEBUG TRAIN Batch 13/5700 loss 6.362067 loss_att 6.725002 loss_ctc 6.995284 loss_rnnt 6.079460 hw_loss 0.235484 lr 0.00046800 rank 5
2023-02-22 02:27:02,477 DEBUG TRAIN Batch 13/5700 loss 23.196478 loss_att 23.339159 loss_ctc 27.474791 loss_rnnt 22.439487 hw_loss 0.296273 lr 0.00046798 rank 3
2023-02-22 02:28:18,722 DEBUG TRAIN Batch 13/5800 loss 23.476412 loss_att 26.197874 loss_ctc 30.576857 loss_rnnt 21.881199 hw_loss 0.195361 lr 0.00046786 rank 0
2023-02-22 02:28:18,722 DEBUG TRAIN Batch 13/5800 loss 3.360787 loss_att 7.570941 loss_ctc 7.786279 loss_rnnt 1.813552 hw_loss 0.215884 lr 0.00046779 rank 5
2023-02-22 02:28:18,722 DEBUG TRAIN Batch 13/5800 loss 10.497923 loss_att 14.811466 loss_ctc 15.930267 loss_rnnt 8.839417 hw_loss 0.134033 lr 0.00046777 rank 4
2023-02-22 02:28:18,723 DEBUG TRAIN Batch 13/5800 loss 12.158155 loss_att 14.316040 loss_ctc 16.178137 loss_rnnt 11.097153 hw_loss 0.175175 lr 0.00046778 rank 7
2023-02-22 02:28:18,723 DEBUG TRAIN Batch 13/5800 loss 14.257681 loss_att 17.467489 loss_ctc 21.276829 loss_rnnt 12.645075 hw_loss 0.065170 lr 0.00046775 rank 2
2023-02-22 02:28:18,723 DEBUG TRAIN Batch 13/5800 loss 8.353443 loss_att 9.821727 loss_ctc 11.218311 loss_rnnt 7.522595 hw_loss 0.291015 lr 0.00046786 rank 1
2023-02-22 02:28:18,724 DEBUG TRAIN Batch 13/5800 loss 17.610878 loss_att 19.498209 loss_ctc 20.827938 loss_rnnt 16.693804 hw_loss 0.207495 lr 0.00046780 rank 6
2023-02-22 02:28:18,726 DEBUG TRAIN Batch 13/5800 loss 16.080196 loss_att 21.592718 loss_ctc 21.543091 loss_rnnt 14.249236 hw_loss 0.000134 lr 0.00046777 rank 3
2023-02-22 02:29:33,349 DEBUG TRAIN Batch 13/5900 loss 8.020666 loss_att 10.884672 loss_ctc 12.359637 loss_rnnt 6.846799 hw_loss 0.042254 lr 0.00046765 rank 0
2023-02-22 02:29:33,350 DEBUG TRAIN Batch 13/5900 loss 7.149756 loss_att 11.319260 loss_ctc 8.141834 loss_rnnt 6.093733 hw_loss 0.168462 lr 0.00046759 rank 5
2023-02-22 02:29:33,352 DEBUG TRAIN Batch 13/5900 loss 11.625831 loss_att 17.295940 loss_ctc 20.659473 loss_rnnt 9.227280 hw_loss 0.112581 lr 0.00046760 rank 6
2023-02-22 02:29:33,352 DEBUG TRAIN Batch 13/5900 loss 11.325099 loss_att 16.668386 loss_ctc 18.839581 loss_rnnt 9.231638 hw_loss 0.042884 lr 0.00046754 rank 2
2023-02-22 02:29:33,354 DEBUG TRAIN Batch 13/5900 loss 9.639567 loss_att 12.190172 loss_ctc 12.988608 loss_rnnt 8.627732 hw_loss 0.103453 lr 0.00046757 rank 4
2023-02-22 02:29:33,353 DEBUG TRAIN Batch 13/5900 loss 19.599352 loss_att 22.594315 loss_ctc 26.588829 loss_rnnt 18.068398 hw_loss 0.000062 lr 0.00046758 rank 7
2023-02-22 02:29:33,358 DEBUG TRAIN Batch 13/5900 loss 11.961134 loss_att 14.236188 loss_ctc 12.790468 loss_rnnt 11.307951 hw_loss 0.164240 lr 0.00046765 rank 1
2023-02-22 02:29:33,361 DEBUG TRAIN Batch 13/5900 loss 5.652640 loss_att 10.268167 loss_ctc 7.861898 loss_rnnt 4.362186 hw_loss 0.136463 lr 0.00046757 rank 3
2023-02-22 02:30:49,520 DEBUG TRAIN Batch 13/6000 loss 14.795116 loss_att 17.092018 loss_ctc 22.822586 loss_rnnt 13.204676 hw_loss 0.113868 lr 0.00046745 rank 1
2023-02-22 02:30:49,521 DEBUG TRAIN Batch 13/6000 loss 19.324743 loss_att 29.607239 loss_ctc 21.486790 loss_rnnt 16.872585 hw_loss 0.201348 lr 0.00046736 rank 3
2023-02-22 02:30:49,521 DEBUG TRAIN Batch 13/6000 loss 18.820196 loss_att 22.027779 loss_ctc 23.546402 loss_rnnt 17.414698 hw_loss 0.250910 lr 0.00046745 rank 0
2023-02-22 02:30:49,521 DEBUG TRAIN Batch 13/6000 loss 10.462339 loss_att 14.011153 loss_ctc 14.785663 loss_rnnt 9.088206 hw_loss 0.164865 lr 0.00046739 rank 6
2023-02-22 02:30:49,522 DEBUG TRAIN Batch 13/6000 loss 11.107102 loss_att 14.973415 loss_ctc 17.021036 loss_rnnt 9.466912 hw_loss 0.147005 lr 0.00046738 rank 5
2023-02-22 02:30:49,525 DEBUG TRAIN Batch 13/6000 loss 19.305668 loss_att 23.727709 loss_ctc 25.284698 loss_rnnt 17.551867 hw_loss 0.135354 lr 0.00046737 rank 4
2023-02-22 02:30:49,525 DEBUG TRAIN Batch 13/6000 loss 4.825215 loss_att 7.906186 loss_ctc 7.170406 loss_rnnt 3.829497 hw_loss 0.125310 lr 0.00046734 rank 2
2023-02-22 02:30:49,526 DEBUG TRAIN Batch 13/6000 loss 11.506376 loss_att 16.474243 loss_ctc 16.841301 loss_rnnt 9.668347 hw_loss 0.249624 lr 0.00046737 rank 7
2023-02-22 02:32:07,125 DEBUG TRAIN Batch 13/6100 loss 18.713619 loss_att 22.023823 loss_ctc 22.230949 loss_rnnt 17.531746 hw_loss 0.095353 lr 0.00046719 rank 6
2023-02-22 02:32:07,125 DEBUG TRAIN Batch 13/6100 loss 9.148281 loss_att 12.077609 loss_ctc 10.551120 loss_rnnt 8.316916 hw_loss 0.109604 lr 0.00046717 rank 7
2023-02-22 02:32:07,127 DEBUG TRAIN Batch 13/6100 loss 11.489815 loss_att 14.699125 loss_ctc 16.747730 loss_rnnt 10.014157 hw_loss 0.248886 lr 0.00046716 rank 4
2023-02-22 02:32:07,127 DEBUG TRAIN Batch 13/6100 loss 12.606745 loss_att 15.306005 loss_ctc 15.907239 loss_rnnt 11.542351 hw_loss 0.158390 lr 0.00046718 rank 5
2023-02-22 02:32:07,127 DEBUG TRAIN Batch 13/6100 loss 18.495886 loss_att 23.689342 loss_ctc 28.214886 loss_rnnt 16.068676 hw_loss 0.173720 lr 0.00046724 rank 0
2023-02-22 02:32:07,129 DEBUG TRAIN Batch 13/6100 loss 12.939978 loss_att 19.477066 loss_ctc 15.749148 loss_rnnt 11.224062 hw_loss 0.063638 lr 0.00046724 rank 1
2023-02-22 02:32:07,129 DEBUG TRAIN Batch 13/6100 loss 9.686841 loss_att 15.201838 loss_ctc 19.844387 loss_rnnt 7.095982 hw_loss 0.250352 lr 0.00046716 rank 3
2023-02-22 02:32:07,131 DEBUG TRAIN Batch 13/6100 loss 8.963669 loss_att 13.236928 loss_ctc 13.268606 loss_rnnt 7.444654 hw_loss 0.169446 lr 0.00046713 rank 2
2023-02-22 02:33:20,827 DEBUG TRAIN Batch 13/6200 loss 10.114029 loss_att 13.136635 loss_ctc 11.657437 loss_rnnt 9.231689 hw_loss 0.135057 lr 0.00046696 rank 4
2023-02-22 02:33:20,830 DEBUG TRAIN Batch 13/6200 loss 10.238153 loss_att 12.058366 loss_ctc 12.366326 loss_rnnt 9.507724 hw_loss 0.154934 lr 0.00046696 rank 7
2023-02-22 02:33:20,831 DEBUG TRAIN Batch 13/6200 loss 20.494852 loss_att 22.903572 loss_ctc 25.091347 loss_rnnt 19.273594 hw_loss 0.237466 lr 0.00046704 rank 1
2023-02-22 02:33:20,832 DEBUG TRAIN Batch 13/6200 loss 14.698846 loss_att 19.089470 loss_ctc 17.522526 loss_rnnt 13.396264 hw_loss 0.089936 lr 0.00046698 rank 6
2023-02-22 02:33:20,832 DEBUG TRAIN Batch 13/6200 loss 6.878373 loss_att 8.617130 loss_ctc 8.864965 loss_rnnt 6.147633 hw_loss 0.221454 lr 0.00046704 rank 0
2023-02-22 02:33:20,833 DEBUG TRAIN Batch 13/6200 loss 12.995127 loss_att 14.236523 loss_ctc 16.085224 loss_rnnt 12.303737 hw_loss 0.058306 lr 0.00046697 rank 5
2023-02-22 02:33:20,834 DEBUG TRAIN Batch 13/6200 loss 19.624466 loss_att 24.282711 loss_ctc 24.771364 loss_rnnt 17.895672 hw_loss 0.207922 lr 0.00046696 rank 3
2023-02-22 02:33:20,837 DEBUG TRAIN Batch 13/6200 loss 9.056262 loss_att 10.788564 loss_ctc 10.367823 loss_rnnt 8.421307 hw_loss 0.213038 lr 0.00046693 rank 2
2023-02-22 02:34:36,914 DEBUG TRAIN Batch 13/6300 loss 7.731205 loss_att 9.281509 loss_ctc 7.419774 loss_rnnt 7.370344 hw_loss 0.173109 lr 0.00046673 rank 2
2023-02-22 02:34:36,915 DEBUG TRAIN Batch 13/6300 loss 11.304401 loss_att 13.905210 loss_ctc 13.779430 loss_rnnt 10.339433 hw_loss 0.215254 lr 0.00046684 rank 1
2023-02-22 02:34:36,917 DEBUG TRAIN Batch 13/6300 loss 13.649475 loss_att 13.767256 loss_ctc 18.979328 loss_rnnt 12.827674 hw_loss 0.164247 lr 0.00046677 rank 5
2023-02-22 02:34:36,917 DEBUG TRAIN Batch 13/6300 loss 8.055657 loss_att 11.324121 loss_ctc 11.443310 loss_rnnt 6.892884 hw_loss 0.107613 lr 0.00046678 rank 6
2023-02-22 02:34:36,918 DEBUG TRAIN Batch 13/6300 loss 9.286777 loss_att 10.378114 loss_ctc 12.537000 loss_rnnt 8.463461 hw_loss 0.321909 lr 0.00046684 rank 0
2023-02-22 02:34:36,920 DEBUG TRAIN Batch 13/6300 loss 11.409511 loss_att 12.364746 loss_ctc 14.806752 loss_rnnt 10.601164 hw_loss 0.308124 lr 0.00046675 rank 4
2023-02-22 02:34:36,920 DEBUG TRAIN Batch 13/6300 loss 10.398282 loss_att 10.611890 loss_ctc 12.295917 loss_rnnt 10.048096 hw_loss 0.102088 lr 0.00046676 rank 7
2023-02-22 02:34:36,969 DEBUG TRAIN Batch 13/6300 loss 10.157608 loss_att 12.774466 loss_ctc 14.526558 loss_rnnt 8.986200 hw_loss 0.122828 lr 0.00046675 rank 3
2023-02-22 02:35:55,978 DEBUG TRAIN Batch 13/6400 loss 5.294067 loss_att 11.928469 loss_ctc 4.897651 loss_rnnt 4.001367 hw_loss 0.035017 lr 0.00046655 rank 4
2023-02-22 02:35:55,983 DEBUG TRAIN Batch 13/6400 loss 49.051834 loss_att 48.462879 loss_ctc 60.929123 loss_rnnt 47.585846 hw_loss 0.000269 lr 0.00046652 rank 2
2023-02-22 02:35:55,983 DEBUG TRAIN Batch 13/6400 loss 34.281837 loss_att 46.549286 loss_ctc 41.211380 loss_rnnt 30.777832 hw_loss 0.237327 lr 0.00046656 rank 7
2023-02-22 02:35:55,984 DEBUG TRAIN Batch 13/6400 loss 25.360987 loss_att 31.745607 loss_ctc 40.793999 loss_rnnt 21.855055 hw_loss 0.321138 lr 0.00046663 rank 0
2023-02-22 02:35:55,986 DEBUG TRAIN Batch 13/6400 loss 5.808577 loss_att 8.282594 loss_ctc 6.781682 loss_rnnt 5.116210 hw_loss 0.127154 lr 0.00046663 rank 1
2023-02-22 02:35:55,987 DEBUG TRAIN Batch 13/6400 loss 11.313858 loss_att 15.019773 loss_ctc 14.264739 loss_rnnt 10.068600 hw_loss 0.207422 lr 0.00046657 rank 5
2023-02-22 02:35:55,988 DEBUG TRAIN Batch 13/6400 loss 9.395592 loss_att 8.933978 loss_ctc 10.308165 loss_rnnt 9.185961 hw_loss 0.338020 lr 0.00046655 rank 3
2023-02-22 02:35:56,015 DEBUG TRAIN Batch 13/6400 loss 14.153487 loss_att 14.093914 loss_ctc 17.827986 loss_rnnt 13.587314 hw_loss 0.165292 lr 0.00046658 rank 6
2023-02-22 02:37:13,367 DEBUG TRAIN Batch 13/6500 loss 13.797165 loss_att 20.119463 loss_ctc 19.102365 loss_rnnt 11.703951 hw_loss 0.227613 lr 0.00046635 rank 7
2023-02-22 02:37:13,369 DEBUG TRAIN Batch 13/6500 loss 8.358643 loss_att 9.243385 loss_ctc 9.155241 loss_rnnt 8.048705 hw_loss 0.050207 lr 0.00046635 rank 4
2023-02-22 02:37:13,370 DEBUG TRAIN Batch 13/6500 loss 8.740312 loss_att 12.907451 loss_ctc 8.883764 loss_rnnt 7.775119 hw_loss 0.211196 lr 0.00046636 rank 5
2023-02-22 02:37:13,372 DEBUG TRAIN Batch 13/6500 loss 11.461960 loss_att 16.296471 loss_ctc 15.613261 loss_rnnt 9.883250 hw_loss 0.109315 lr 0.00046643 rank 0
2023-02-22 02:37:13,376 DEBUG TRAIN Batch 13/6500 loss 13.950034 loss_att 18.773230 loss_ctc 20.717316 loss_rnnt 12.083014 hw_loss 0.000144 lr 0.00046635 rank 3
2023-02-22 02:37:13,378 DEBUG TRAIN Batch 13/6500 loss 12.062824 loss_att 12.773123 loss_ctc 16.034876 loss_rnnt 11.253022 hw_loss 0.259002 lr 0.00046632 rank 2
2023-02-22 02:37:13,379 DEBUG TRAIN Batch 13/6500 loss 11.369090 loss_att 10.578669 loss_ctc 14.326942 loss_rnnt 11.009790 hw_loss 0.230629 lr 0.00046637 rank 6
2023-02-22 02:37:13,422 DEBUG TRAIN Batch 13/6500 loss 8.548085 loss_att 11.878284 loss_ctc 12.546204 loss_rnnt 7.256671 hw_loss 0.173046 lr 0.00046643 rank 1
2023-02-22 02:38:29,229 DEBUG TRAIN Batch 13/6600 loss 9.403381 loss_att 13.301539 loss_ctc 12.356757 loss_rnnt 8.099447 hw_loss 0.244723 lr 0.00046623 rank 0
2023-02-22 02:38:29,230 DEBUG TRAIN Batch 13/6600 loss 17.426405 loss_att 18.690664 loss_ctc 20.378504 loss_rnnt 16.734861 hw_loss 0.084523 lr 0.00046615 rank 4
2023-02-22 02:38:29,236 DEBUG TRAIN Batch 13/6600 loss 9.823924 loss_att 13.217482 loss_ctc 18.846752 loss_rnnt 7.800149 hw_loss 0.266288 lr 0.00046623 rank 1
2023-02-22 02:38:29,238 DEBUG TRAIN Batch 13/6600 loss 22.281744 loss_att 21.257095 loss_ctc 25.199842 loss_rnnt 22.070692 hw_loss 0.050444 lr 0.00046616 rank 5
2023-02-22 02:38:29,239 DEBUG TRAIN Batch 13/6600 loss 11.370160 loss_att 12.625832 loss_ctc 15.506514 loss_rnnt 10.555010 hw_loss 0.023442 lr 0.00046617 rank 6
2023-02-22 02:38:29,241 DEBUG TRAIN Batch 13/6600 loss 16.027767 loss_att 17.128696 loss_ctc 17.432850 loss_rnnt 15.488972 hw_loss 0.246122 lr 0.00046615 rank 7
2023-02-22 02:38:29,243 DEBUG TRAIN Batch 13/6600 loss 2.955141 loss_att 6.118160 loss_ctc 5.599000 loss_rnnt 1.969974 hw_loss 0.000090 lr 0.00046612 rank 2
2023-02-22 02:38:29,287 DEBUG TRAIN Batch 13/6600 loss 7.730100 loss_att 10.620857 loss_ctc 10.123631 loss_rnnt 6.770175 hw_loss 0.117441 lr 0.00046614 rank 3
2023-02-22 02:39:45,634 DEBUG TRAIN Batch 13/6700 loss 11.572741 loss_att 16.752377 loss_ctc 15.876143 loss_rnnt 9.874359 hw_loss 0.166251 lr 0.00046595 rank 7
2023-02-22 02:39:45,634 DEBUG TRAIN Batch 13/6700 loss 12.722164 loss_att 13.841494 loss_ctc 16.654657 loss_rnnt 11.884691 hw_loss 0.167390 lr 0.00046602 rank 0
2023-02-22 02:39:45,635 DEBUG TRAIN Batch 13/6700 loss 16.085039 loss_att 16.439539 loss_ctc 19.015457 loss_rnnt 15.589201 hw_loss 0.064157 lr 0.00046596 rank 5
2023-02-22 02:39:45,636 DEBUG TRAIN Batch 13/6700 loss 10.653444 loss_att 12.514698 loss_ctc 16.022499 loss_rnnt 9.502573 hw_loss 0.117650 lr 0.00046594 rank 3
2023-02-22 02:39:45,639 DEBUG TRAIN Batch 13/6700 loss 7.204535 loss_att 12.534925 loss_ctc 8.084007 loss_rnnt 5.936192 hw_loss 0.159381 lr 0.00046594 rank 4
2023-02-22 02:39:45,640 DEBUG TRAIN Batch 13/6700 loss 2.295964 loss_att 5.803782 loss_ctc 3.205072 loss_rnnt 1.434000 hw_loss 0.073473 lr 0.00046597 rank 6
2023-02-22 02:39:45,641 DEBUG TRAIN Batch 13/6700 loss 8.661846 loss_att 14.321425 loss_ctc 8.616285 loss_rnnt 7.508002 hw_loss 0.052504 lr 0.00046591 rank 2
2023-02-22 02:39:45,644 DEBUG TRAIN Batch 13/6700 loss 9.988345 loss_att 12.776918 loss_ctc 13.489761 loss_rnnt 8.915463 hw_loss 0.090582 lr 0.00046603 rank 1
2023-02-22 02:41:02,091 DEBUG TRAIN Batch 13/6800 loss 7.767218 loss_att 13.949579 loss_ctc 10.087818 loss_rnnt 6.201764 hw_loss 0.036688 lr 0.00046571 rank 2
2023-02-22 02:41:02,093 DEBUG TRAIN Batch 13/6800 loss 16.435549 loss_att 18.014217 loss_ctc 20.820431 loss_rnnt 15.511786 hw_loss 0.043837 lr 0.00046575 rank 7
2023-02-22 02:41:02,094 DEBUG TRAIN Batch 13/6800 loss 17.037952 loss_att 20.548618 loss_ctc 23.670025 loss_rnnt 15.364775 hw_loss 0.162692 lr 0.00046574 rank 4
2023-02-22 02:41:02,095 DEBUG TRAIN Batch 13/6800 loss 9.667701 loss_att 13.087128 loss_ctc 11.599873 loss_rnnt 8.618361 hw_loss 0.202184 lr 0.00046582 rank 0
2023-02-22 02:41:02,100 DEBUG TRAIN Batch 13/6800 loss 15.289519 loss_att 17.151119 loss_ctc 20.346390 loss_rnnt 14.158419 hw_loss 0.158493 lr 0.00046574 rank 3
2023-02-22 02:41:02,100 DEBUG TRAIN Batch 13/6800 loss 12.592869 loss_att 14.500021 loss_ctc 19.011850 loss_rnnt 11.305304 hw_loss 0.094259 lr 0.00046582 rank 1
2023-02-22 02:41:02,101 DEBUG TRAIN Batch 13/6800 loss 9.345726 loss_att 11.195657 loss_ctc 10.954767 loss_rnnt 8.652864 hw_loss 0.203130 lr 0.00046577 rank 6
2023-02-22 02:41:02,101 DEBUG TRAIN Batch 13/6800 loss 19.245874 loss_att 22.728458 loss_ctc 23.939749 loss_rnnt 17.859011 hw_loss 0.120932 lr 0.00046576 rank 5
2023-02-22 02:42:18,597 DEBUG TRAIN Batch 13/6900 loss 14.159026 loss_att 16.716999 loss_ctc 16.639774 loss_rnnt 13.236716 hw_loss 0.149903 lr 0.00046554 rank 4
2023-02-22 02:42:18,599 DEBUG TRAIN Batch 13/6900 loss 15.237190 loss_att 17.857389 loss_ctc 20.095919 loss_rnnt 13.971263 hw_loss 0.176358 lr 0.00046555 rank 5
2023-02-22 02:42:18,599 DEBUG TRAIN Batch 13/6900 loss 10.592394 loss_att 12.821743 loss_ctc 15.590785 loss_rnnt 9.376842 hw_loss 0.193559 lr 0.00046562 rank 0
2023-02-22 02:42:18,599 DEBUG TRAIN Batch 13/6900 loss 9.146649 loss_att 12.065357 loss_ctc 12.079660 loss_rnnt 8.079869 hw_loss 0.172444 lr 0.00046554 rank 7
2023-02-22 02:42:18,600 DEBUG TRAIN Batch 13/6900 loss 5.239159 loss_att 8.472939 loss_ctc 7.069746 loss_rnnt 4.296468 hw_loss 0.097229 lr 0.00046556 rank 6
2023-02-22 02:42:18,601 DEBUG TRAIN Batch 13/6900 loss 15.056474 loss_att 18.053352 loss_ctc 17.573605 loss_rnnt 14.048578 hw_loss 0.136691 lr 0.00046551 rank 2
2023-02-22 02:42:18,601 DEBUG TRAIN Batch 13/6900 loss 14.321150 loss_att 21.385908 loss_ctc 19.963219 loss_rnnt 12.131985 hw_loss 0.044883 lr 0.00046554 rank 3
2023-02-22 02:42:18,646 DEBUG TRAIN Batch 13/6900 loss 8.506877 loss_att 10.987934 loss_ctc 12.284868 loss_rnnt 7.448771 hw_loss 0.109053 lr 0.00046562 rank 1
2023-02-22 02:43:32,805 DEBUG TRAIN Batch 13/7000 loss 6.457619 loss_att 13.104202 loss_ctc 8.320780 loss_rnnt 4.879813 hw_loss 0.000127 lr 0.00046535 rank 5
2023-02-22 02:43:32,806 DEBUG TRAIN Batch 13/7000 loss 3.708493 loss_att 5.249161 loss_ctc 5.047868 loss_rnnt 3.170642 hw_loss 0.095875 lr 0.00046534 rank 4
2023-02-22 02:43:32,806 DEBUG TRAIN Batch 13/7000 loss 17.324169 loss_att 20.441204 loss_ctc 22.971128 loss_rnnt 15.884539 hw_loss 0.118676 lr 0.00046542 rank 0
2023-02-22 02:43:32,807 DEBUG TRAIN Batch 13/7000 loss 14.011968 loss_att 14.650793 loss_ctc 19.760191 loss_rnnt 13.031662 hw_loss 0.161460 lr 0.00046534 rank 7
2023-02-22 02:43:32,812 DEBUG TRAIN Batch 13/7000 loss 6.726966 loss_att 10.987999 loss_ctc 9.543715 loss_rnnt 5.370670 hw_loss 0.240980 lr 0.00046531 rank 2
2023-02-22 02:43:32,838 DEBUG TRAIN Batch 13/7000 loss 17.842354 loss_att 21.325256 loss_ctc 21.133671 loss_rnnt 16.635477 hw_loss 0.133971 lr 0.00046536 rank 6
2023-02-22 02:43:32,843 DEBUG TRAIN Batch 13/7000 loss 15.070281 loss_att 15.693760 loss_ctc 18.990747 loss_rnnt 14.346590 hw_loss 0.142998 lr 0.00046542 rank 1
2023-02-22 02:43:32,855 DEBUG TRAIN Batch 13/7000 loss 14.552652 loss_att 15.966103 loss_ctc 16.956945 loss_rnnt 13.872925 hw_loss 0.143370 lr 0.00046533 rank 3
2023-02-22 02:44:50,738 DEBUG TRAIN Batch 13/7100 loss 12.951006 loss_att 14.257313 loss_ctc 15.035305 loss_rnnt 12.386050 hw_loss 0.048352 lr 0.00046514 rank 4
2023-02-22 02:44:50,741 DEBUG TRAIN Batch 13/7100 loss 6.115949 loss_att 11.297121 loss_ctc 9.178650 loss_rnnt 4.670792 hw_loss 0.001056 lr 0.00046522 rank 0
2023-02-22 02:44:50,742 DEBUG TRAIN Batch 13/7100 loss 4.479730 loss_att 8.788185 loss_ctc 4.954479 loss_rnnt 3.520720 hw_loss 0.063787 lr 0.00046515 rank 5
2023-02-22 02:44:50,743 DEBUG TRAIN Batch 13/7100 loss 15.338314 loss_att 20.020653 loss_ctc 27.793051 loss_rnnt 12.670573 hw_loss 0.132451 lr 0.00046513 rank 3
2023-02-22 02:44:50,745 DEBUG TRAIN Batch 13/7100 loss 17.348019 loss_att 19.512566 loss_ctc 18.687029 loss_rnnt 16.655365 hw_loss 0.152269 lr 0.00046514 rank 7
2023-02-22 02:44:50,751 DEBUG TRAIN Batch 13/7100 loss 17.011868 loss_att 21.845936 loss_ctc 20.703770 loss_rnnt 15.459177 hw_loss 0.175543 lr 0.00046516 rank 6
2023-02-22 02:44:50,773 DEBUG TRAIN Batch 13/7100 loss 13.431990 loss_att 16.732170 loss_ctc 15.263765 loss_rnnt 12.420514 hw_loss 0.201003 lr 0.00046511 rank 2
2023-02-22 02:44:50,789 DEBUG TRAIN Batch 13/7100 loss 9.531588 loss_att 15.670621 loss_ctc 12.939085 loss_rnnt 7.773620 hw_loss 0.142178 lr 0.00046522 rank 1
2023-02-22 02:46:07,308 DEBUG TRAIN Batch 13/7200 loss 7.504557 loss_att 10.744276 loss_ctc 11.313185 loss_rnnt 6.329729 hw_loss 0.035751 lr 0.00046493 rank 4
2023-02-22 02:46:07,309 DEBUG TRAIN Batch 13/7200 loss 5.999940 loss_att 11.868181 loss_ctc 8.395290 loss_rnnt 4.444501 hw_loss 0.117019 lr 0.00046494 rank 7
2023-02-22 02:46:07,309 DEBUG TRAIN Batch 13/7200 loss 25.197899 loss_att 31.736734 loss_ctc 32.529934 loss_rnnt 22.833359 hw_loss 0.148441 lr 0.00046502 rank 1
2023-02-22 02:46:07,310 DEBUG TRAIN Batch 13/7200 loss 5.327850 loss_att 7.673210 loss_ctc 4.649292 loss_rnnt 4.868562 hw_loss 0.151295 lr 0.00046493 rank 3
2023-02-22 02:46:07,310 DEBUG TRAIN Batch 13/7200 loss 15.852727 loss_att 16.267139 loss_ctc 18.243631 loss_rnnt 15.399878 hw_loss 0.095963 lr 0.00046495 rank 5
2023-02-22 02:46:07,310 DEBUG TRAIN Batch 13/7200 loss 11.442336 loss_att 16.311781 loss_ctc 12.147717 loss_rnnt 10.293902 hw_loss 0.150927 lr 0.00046501 rank 0
2023-02-22 02:46:07,313 DEBUG TRAIN Batch 13/7200 loss 10.416514 loss_att 16.924076 loss_ctc 14.663622 loss_rnnt 8.420180 hw_loss 0.241015 lr 0.00046491 rank 2
2023-02-22 02:46:07,362 DEBUG TRAIN Batch 13/7200 loss 16.418367 loss_att 21.566360 loss_ctc 19.054647 loss_rnnt 15.000771 hw_loss 0.068427 lr 0.00046496 rank 6
2023-02-22 02:47:22,788 DEBUG TRAIN Batch 13/7300 loss 6.402647 loss_att 11.615578 loss_ctc 6.867245 loss_rnnt 5.201877 hw_loss 0.180446 lr 0.00046475 rank 5
2023-02-22 02:47:22,790 DEBUG TRAIN Batch 13/7300 loss 10.347013 loss_att 14.823946 loss_ctc 11.626869 loss_rnnt 9.182401 hw_loss 0.184831 lr 0.00046474 rank 7
2023-02-22 02:47:22,793 DEBUG TRAIN Batch 13/7300 loss 12.577106 loss_att 16.862751 loss_ctc 18.622013 loss_rnnt 10.827199 hw_loss 0.162728 lr 0.00046473 rank 4
2023-02-22 02:47:22,796 DEBUG TRAIN Batch 13/7300 loss 11.043210 loss_att 15.254025 loss_ctc 12.168132 loss_rnnt 9.998755 hw_loss 0.098067 lr 0.00046476 rank 6
2023-02-22 02:47:22,798 DEBUG TRAIN Batch 13/7300 loss 2.710526 loss_att 4.699830 loss_ctc 4.459205 loss_rnnt 2.030416 hw_loss 0.092048 lr 0.00046473 rank 3
2023-02-22 02:47:22,798 DEBUG TRAIN Batch 13/7300 loss 13.951582 loss_att 15.140005 loss_ctc 19.816235 loss_rnnt 12.881706 hw_loss 0.094195 lr 0.00046482 rank 1
2023-02-22 02:47:22,798 DEBUG TRAIN Batch 13/7300 loss 22.665638 loss_att 25.323021 loss_ctc 27.545639 loss_rnnt 21.470139 hw_loss 0.025044 lr 0.00046481 rank 0
2023-02-22 02:47:22,803 DEBUG TRAIN Batch 13/7300 loss 10.906624 loss_att 16.875128 loss_ctc 14.024680 loss_rnnt 9.228201 hw_loss 0.129339 lr 0.00046471 rank 2
2023-02-22 02:48:39,783 DEBUG TRAIN Batch 13/7400 loss 11.263614 loss_att 13.751900 loss_ctc 11.661146 loss_rnnt 10.594379 hw_loss 0.222323 lr 0.00046461 rank 0
2023-02-22 02:48:39,783 DEBUG TRAIN Batch 13/7400 loss 15.139931 loss_att 22.338196 loss_ctc 17.051418 loss_rnnt 13.359574 hw_loss 0.160948 lr 0.00046461 rank 1
2023-02-22 02:48:39,783 DEBUG TRAIN Batch 13/7400 loss 7.282125 loss_att 11.630867 loss_ctc 9.088346 loss_rnnt 6.109477 hw_loss 0.116384 lr 0.00046454 rank 7
2023-02-22 02:48:39,785 DEBUG TRAIN Batch 13/7400 loss 10.776139 loss_att 13.090910 loss_ctc 13.862072 loss_rnnt 9.784458 hw_loss 0.219880 lr 0.00046456 rank 6
2023-02-22 02:48:39,788 DEBUG TRAIN Batch 13/7400 loss 5.868112 loss_att 10.448471 loss_ctc 5.718042 loss_rnnt 4.883085 hw_loss 0.166807 lr 0.00046450 rank 2
2023-02-22 02:48:39,789 DEBUG TRAIN Batch 13/7400 loss 10.470117 loss_att 11.641924 loss_ctc 13.570934 loss_rnnt 9.743706 hw_loss 0.147387 lr 0.00046453 rank 4
2023-02-22 02:48:39,792 DEBUG TRAIN Batch 13/7400 loss 8.869496 loss_att 15.172366 loss_ctc 14.415168 loss_rnnt 6.852439 hw_loss 0.031988 lr 0.00046455 rank 5
2023-02-22 02:48:39,836 DEBUG TRAIN Batch 13/7400 loss 16.155378 loss_att 21.349998 loss_ctc 26.129444 loss_rnnt 13.709763 hw_loss 0.144027 lr 0.00046453 rank 3
2023-02-22 02:49:57,397 DEBUG TRAIN Batch 13/7500 loss 9.241250 loss_att 13.626925 loss_ctc 9.539940 loss_rnnt 8.268886 hw_loss 0.103884 lr 0.00046434 rank 7
2023-02-22 02:49:57,402 DEBUG TRAIN Batch 13/7500 loss 9.092900 loss_att 10.473737 loss_ctc 8.787509 loss_rnnt 8.779868 hw_loss 0.145471 lr 0.00046441 rank 0
2023-02-22 02:49:57,404 DEBUG TRAIN Batch 13/7500 loss 13.409295 loss_att 19.385380 loss_ctc 21.022490 loss_rnnt 11.135716 hw_loss 0.118629 lr 0.00046430 rank 2
2023-02-22 02:49:57,404 DEBUG TRAIN Batch 13/7500 loss 11.952303 loss_att 15.245588 loss_ctc 15.702604 loss_rnnt 10.764210 hw_loss 0.055117 lr 0.00046441 rank 1
2023-02-22 02:49:57,406 DEBUG TRAIN Batch 13/7500 loss 17.232407 loss_att 19.450615 loss_ctc 26.538174 loss_rnnt 15.486722 hw_loss 0.114887 lr 0.00046433 rank 4
2023-02-22 02:49:57,406 DEBUG TRAIN Batch 13/7500 loss 14.132739 loss_att 19.314825 loss_ctc 22.667366 loss_rnnt 11.859604 hw_loss 0.185186 lr 0.00046433 rank 3
2023-02-22 02:49:57,411 DEBUG TRAIN Batch 13/7500 loss 11.366894 loss_att 14.440042 loss_ctc 14.173583 loss_rnnt 10.267171 hw_loss 0.207876 lr 0.00046435 rank 5
2023-02-22 02:49:57,457 DEBUG TRAIN Batch 13/7500 loss 13.566406 loss_att 16.387629 loss_ctc 16.012268 loss_rnnt 12.567043 hw_loss 0.204381 lr 0.00046436 rank 6
2023-02-22 02:51:12,648 DEBUG TRAIN Batch 13/7600 loss 9.341282 loss_att 15.041254 loss_ctc 13.954909 loss_rnnt 7.510620 hw_loss 0.141594 lr 0.00046415 rank 5
2023-02-22 02:51:12,649 DEBUG TRAIN Batch 13/7600 loss 15.826447 loss_att 22.604139 loss_ctc 17.333223 loss_rnnt 14.121383 hw_loss 0.278665 lr 0.00046421 rank 0
2023-02-22 02:51:12,649 DEBUG TRAIN Batch 13/7600 loss 14.688818 loss_att 18.218376 loss_ctc 21.177183 loss_rnnt 13.045356 hw_loss 0.135816 lr 0.00046413 rank 3
2023-02-22 02:51:12,651 DEBUG TRAIN Batch 13/7600 loss 18.036667 loss_att 17.803833 loss_ctc 21.065689 loss_rnnt 17.564129 hw_loss 0.216066 lr 0.00046413 rank 4
2023-02-22 02:51:12,651 DEBUG TRAIN Batch 13/7600 loss 18.207283 loss_att 20.241344 loss_ctc 21.448408 loss_rnnt 17.283951 hw_loss 0.158192 lr 0.00046416 rank 6
2023-02-22 02:51:12,652 DEBUG TRAIN Batch 13/7600 loss 12.661735 loss_att 13.567358 loss_ctc 16.851337 loss_rnnt 11.787200 hw_loss 0.252742 lr 0.00046414 rank 7
2023-02-22 02:51:12,658 DEBUG TRAIN Batch 13/7600 loss 16.252691 loss_att 21.335482 loss_ctc 21.158764 loss_rnnt 14.493492 hw_loss 0.165934 lr 0.00046410 rank 2
2023-02-22 02:51:12,659 DEBUG TRAIN Batch 13/7600 loss 8.063695 loss_att 12.354404 loss_ctc 11.301760 loss_rnnt 6.711267 hw_loss 0.117269 lr 0.00046421 rank 1
2023-02-22 02:52:28,926 DEBUG TRAIN Batch 13/7700 loss 3.354490 loss_att 7.927250 loss_ctc 3.500028 loss_rnnt 2.371034 hw_loss 0.092812 lr 0.00046394 rank 7
2023-02-22 02:52:28,930 DEBUG TRAIN Batch 13/7700 loss 25.417150 loss_att 31.718445 loss_ctc 32.597481 loss_rnnt 23.106817 hw_loss 0.173806 lr 0.00046393 rank 4
2023-02-22 02:52:28,931 DEBUG TRAIN Batch 13/7700 loss 21.421776 loss_att 23.904305 loss_ctc 25.949108 loss_rnnt 20.234480 hw_loss 0.163395 lr 0.00046401 rank 0
2023-02-22 02:52:28,932 DEBUG TRAIN Batch 13/7700 loss 27.382290 loss_att 36.593437 loss_ctc 32.426998 loss_rnnt 24.783285 hw_loss 0.157776 lr 0.00046395 rank 5
2023-02-22 02:52:28,931 DEBUG TRAIN Batch 13/7700 loss 10.161635 loss_att 12.807576 loss_ctc 12.497477 loss_rnnt 9.254370 hw_loss 0.124935 lr 0.00046393 rank 3
2023-02-22 02:52:28,931 DEBUG TRAIN Batch 13/7700 loss 10.367007 loss_att 13.757314 loss_ctc 16.903679 loss_rnnt 8.712098 hw_loss 0.197422 lr 0.00046390 rank 2
2023-02-22 02:52:28,936 DEBUG TRAIN Batch 13/7700 loss 17.355688 loss_att 20.046734 loss_ctc 20.633368 loss_rnnt 16.282022 hw_loss 0.184561 lr 0.00046396 rank 6
2023-02-22 02:52:28,991 DEBUG TRAIN Batch 13/7700 loss 13.150452 loss_att 11.891077 loss_ctc 16.508646 loss_rnnt 12.894757 hw_loss 0.112143 lr 0.00046401 rank 1
2023-02-22 02:53:45,944 DEBUG TRAIN Batch 13/7800 loss 4.387722 loss_att 8.995605 loss_ctc 3.985624 loss_rnnt 3.367672 hw_loss 0.285161 lr 0.00046373 rank 4
2023-02-22 02:53:45,947 DEBUG TRAIN Batch 13/7800 loss 13.779580 loss_att 19.226461 loss_ctc 18.977390 loss_rnnt 11.955893 hw_loss 0.077381 lr 0.00046374 rank 7
2023-02-22 02:53:45,948 DEBUG TRAIN Batch 13/7800 loss 7.888163 loss_att 12.779645 loss_ctc 10.409128 loss_rnnt 6.532589 hw_loss 0.077155 lr 0.00046376 rank 6
2023-02-22 02:53:45,949 DEBUG TRAIN Batch 13/7800 loss 15.817834 loss_att 17.313524 loss_ctc 18.871967 loss_rnnt 15.065575 hw_loss 0.086069 lr 0.00046375 rank 5
2023-02-22 02:53:45,955 DEBUG TRAIN Batch 13/7800 loss 12.554180 loss_att 14.840917 loss_ctc 15.235926 loss_rnnt 11.652765 hw_loss 0.162186 lr 0.00046381 rank 0
2023-02-22 02:53:45,956 DEBUG TRAIN Batch 13/7800 loss 23.134510 loss_att 39.613033 loss_ctc 32.047409 loss_rnnt 18.584560 hw_loss 0.123480 lr 0.00046370 rank 2
2023-02-22 02:53:45,957 DEBUG TRAIN Batch 13/7800 loss 8.439196 loss_att 14.502349 loss_ctc 11.865152 loss_rnnt 6.689846 hw_loss 0.149857 lr 0.00046381 rank 1
2023-02-22 02:53:45,960 DEBUG TRAIN Batch 13/7800 loss 11.008674 loss_att 12.634821 loss_ctc 16.822865 loss_rnnt 9.876360 hw_loss 0.059734 lr 0.00046373 rank 3
2023-02-22 02:55:01,717 DEBUG TRAIN Batch 13/7900 loss 25.145369 loss_att 31.707203 loss_ctc 37.254784 loss_rnnt 22.126326 hw_loss 0.172664 lr 0.00046353 rank 4
2023-02-22 02:55:01,717 DEBUG TRAIN Batch 13/7900 loss 16.524940 loss_att 20.701963 loss_ctc 21.335577 loss_rnnt 15.030767 hw_loss 0.032528 lr 0.00046354 rank 7
2023-02-22 02:55:01,719 DEBUG TRAIN Batch 13/7900 loss 8.996669 loss_att 12.595364 loss_ctc 16.322622 loss_rnnt 7.208568 hw_loss 0.171691 lr 0.00046355 rank 5
2023-02-22 02:55:01,720 DEBUG TRAIN Batch 13/7900 loss 16.108562 loss_att 20.623411 loss_ctc 18.584417 loss_rnnt 14.770114 hw_loss 0.197557 lr 0.00046353 rank 3
2023-02-22 02:55:01,721 DEBUG TRAIN Batch 13/7900 loss 10.655742 loss_att 11.875691 loss_ctc 14.314873 loss_rnnt 9.854340 hw_loss 0.130364 lr 0.00046361 rank 0
2023-02-22 02:55:01,721 DEBUG TRAIN Batch 13/7900 loss 22.294180 loss_att 24.443356 loss_ctc 26.925159 loss_rnnt 21.145887 hw_loss 0.189360 lr 0.00046362 rank 1
2023-02-22 02:55:01,722 DEBUG TRAIN Batch 13/7900 loss 12.820394 loss_att 17.053595 loss_ctc 15.273830 loss_rnnt 11.585402 hw_loss 0.114801 lr 0.00046356 rank 6
2023-02-22 02:55:01,732 DEBUG TRAIN Batch 13/7900 loss 12.091733 loss_att 16.057182 loss_ctc 13.953879 loss_rnnt 11.050300 hw_loss 0.000107 lr 0.00046351 rank 2
2023-02-22 02:56:14,984 DEBUG TRAIN Batch 13/8000 loss 4.621440 loss_att 8.046275 loss_ctc 6.928796 loss_rnnt 3.542904 hw_loss 0.161103 lr 0.00046341 rank 0
2023-02-22 02:56:14,986 DEBUG TRAIN Batch 13/8000 loss 20.112225 loss_att 23.305902 loss_ctc 28.371771 loss_rnnt 18.254343 hw_loss 0.221007 lr 0.00046333 rank 3
2023-02-22 02:56:14,988 DEBUG TRAIN Batch 13/8000 loss 11.737847 loss_att 14.984755 loss_ctc 16.300817 loss_rnnt 10.444686 hw_loss 0.066346 lr 0.00046335 rank 5
2023-02-22 02:56:14,989 DEBUG TRAIN Batch 13/8000 loss 10.141302 loss_att 13.186077 loss_ctc 12.867167 loss_rnnt 9.103181 hw_loss 0.123219 lr 0.00046334 rank 7
2023-02-22 02:56:14,991 DEBUG TRAIN Batch 13/8000 loss 19.195650 loss_att 22.610731 loss_ctc 22.778828 loss_rnnt 17.976141 hw_loss 0.110132 lr 0.00046342 rank 1
2023-02-22 02:56:14,991 DEBUG TRAIN Batch 13/8000 loss 10.750324 loss_att 12.164215 loss_ctc 10.569799 loss_rnnt 10.418736 hw_loss 0.136650 lr 0.00046336 rank 6
2023-02-22 02:56:14,991 DEBUG TRAIN Batch 13/8000 loss 12.330585 loss_att 15.528841 loss_ctc 14.302466 loss_rnnt 11.379211 hw_loss 0.091507 lr 0.00046331 rank 2
2023-02-22 02:56:14,994 DEBUG TRAIN Batch 13/8000 loss 18.644369 loss_att 21.413242 loss_ctc 22.948023 loss_rnnt 17.423235 hw_loss 0.175384 lr 0.00046333 rank 4
2023-02-22 02:57:31,162 DEBUG TRAIN Batch 13/8100 loss 18.344940 loss_att 20.278454 loss_ctc 28.721029 loss_rnnt 16.516670 hw_loss 0.108913 lr 0.00046314 rank 4
2023-02-22 02:57:31,164 DEBUG TRAIN Batch 13/8100 loss 28.858854 loss_att 29.360243 loss_ctc 32.163010 loss_rnnt 28.191004 hw_loss 0.238158 lr 0.00046315 rank 5
2023-02-22 02:57:31,165 DEBUG TRAIN Batch 13/8100 loss 19.355265 loss_att 21.990767 loss_ctc 21.598591 loss_rnnt 18.447788 hw_loss 0.152374 lr 0.00046316 rank 6
2023-02-22 02:57:31,167 DEBUG TRAIN Batch 13/8100 loss 13.686681 loss_att 18.909254 loss_ctc 19.261951 loss_rnnt 11.857252 hw_loss 0.077898 lr 0.00046314 rank 7
2023-02-22 02:57:31,169 DEBUG TRAIN Batch 13/8100 loss 9.422518 loss_att 12.046848 loss_ctc 11.839530 loss_rnnt 8.452094 hw_loss 0.231165 lr 0.00046322 rank 0
2023-02-22 02:57:31,171 DEBUG TRAIN Batch 13/8100 loss 11.870241 loss_att 13.022120 loss_ctc 19.770449 loss_rnnt 10.529219 hw_loss 0.107412 lr 0.00046322 rank 1
2023-02-22 02:57:31,173 DEBUG TRAIN Batch 13/8100 loss 6.042823 loss_att 12.785979 loss_ctc 8.070557 loss_rnnt 4.331649 hw_loss 0.172835 lr 0.00046313 rank 3
2023-02-22 02:57:31,173 DEBUG TRAIN Batch 13/8100 loss 5.303697 loss_att 9.249538 loss_ctc 7.882077 loss_rnnt 4.097550 hw_loss 0.137240 lr 0.00046311 rank 2
2023-02-22 02:58:46,989 DEBUG TRAIN Batch 13/8200 loss 15.430408 loss_att 20.964056 loss_ctc 17.203419 loss_rnnt 13.991089 hw_loss 0.180352 lr 0.00046302 rank 0
2023-02-22 02:58:46,995 DEBUG TRAIN Batch 13/8200 loss 9.195667 loss_att 10.532932 loss_ctc 11.133407 loss_rnnt 8.565340 hw_loss 0.195955 lr 0.00046294 rank 7
2023-02-22 02:58:46,996 DEBUG TRAIN Batch 13/8200 loss 16.421082 loss_att 17.197796 loss_ctc 25.463726 loss_rnnt 15.015274 hw_loss 0.083963 lr 0.00046294 rank 4
2023-02-22 02:58:46,998 DEBUG TRAIN Batch 13/8200 loss 17.096636 loss_att 19.913239 loss_ctc 22.362968 loss_rnnt 15.724876 hw_loss 0.199244 lr 0.00046302 rank 1
2023-02-22 02:58:47,000 DEBUG TRAIN Batch 13/8200 loss 14.697257 loss_att 16.669931 loss_ctc 18.207047 loss_rnnt 13.791796 hw_loss 0.080541 lr 0.00046294 rank 3
2023-02-22 02:58:47,000 DEBUG TRAIN Batch 13/8200 loss 15.922700 loss_att 19.349232 loss_ctc 20.861464 loss_rnnt 14.494158 hw_loss 0.158874 lr 0.00046296 rank 6
2023-02-22 02:58:47,000 DEBUG TRAIN Batch 13/8200 loss 11.532467 loss_att 10.996828 loss_ctc 14.458761 loss_rnnt 11.114039 hw_loss 0.253842 lr 0.00046295 rank 5
2023-02-22 02:58:47,050 DEBUG TRAIN Batch 13/8200 loss 9.667549 loss_att 14.117896 loss_ctc 15.956927 loss_rnnt 7.875785 hw_loss 0.118335 lr 0.00046291 rank 2
2023-02-22 03:00:01,814 DEBUG TRAIN Batch 13/8300 loss 11.426538 loss_att 12.007390 loss_ctc 15.258594 loss_rnnt 10.737080 hw_loss 0.116903 lr 0.00046275 rank 5
2023-02-22 03:00:01,817 DEBUG TRAIN Batch 13/8300 loss 9.622896 loss_att 14.311449 loss_ctc 13.710876 loss_rnnt 8.121840 hw_loss 0.034278 lr 0.00046274 rank 4
2023-02-22 03:00:01,818 DEBUG TRAIN Batch 13/8300 loss 10.117124 loss_att 19.875137 loss_ctc 14.918633 loss_rnnt 7.433149 hw_loss 0.172819 lr 0.00046282 rank 0
2023-02-22 03:00:01,823 DEBUG TRAIN Batch 13/8300 loss 9.464518 loss_att 16.354284 loss_ctc 11.608036 loss_rnnt 7.720904 hw_loss 0.149731 lr 0.00046274 rank 3
2023-02-22 03:00:01,823 DEBUG TRAIN Batch 13/8300 loss 12.917213 loss_att 16.408554 loss_ctc 17.027740 loss_rnnt 11.588649 hw_loss 0.154176 lr 0.00046274 rank 7
2023-02-22 03:00:01,824 DEBUG TRAIN Batch 13/8300 loss 10.515419 loss_att 11.523500 loss_ctc 13.573809 loss_rnnt 9.803395 hw_loss 0.192417 lr 0.00046282 rank 1
2023-02-22 03:00:01,825 DEBUG TRAIN Batch 13/8300 loss 6.810346 loss_att 10.603633 loss_ctc 9.696101 loss_rnnt 5.648999 hw_loss 0.033602 lr 0.00046271 rank 2
2023-02-22 03:00:01,869 DEBUG TRAIN Batch 13/8300 loss 14.399886 loss_att 16.986200 loss_ctc 16.587961 loss_rnnt 13.553649 hw_loss 0.069807 lr 0.00046276 rank 6
2023-02-22 03:00:55,631 DEBUG CV Batch 13/0 loss 3.547466 loss_att 3.193811 loss_ctc 4.877409 loss_rnnt 3.272137 hw_loss 0.316377 history loss 3.416079 rank 3
2023-02-22 03:00:55,635 DEBUG CV Batch 13/0 loss 3.547466 loss_att 3.193811 loss_ctc 4.877409 loss_rnnt 3.272137 hw_loss 0.316377 history loss 3.416079 rank 1
2023-02-22 03:00:55,635 DEBUG CV Batch 13/0 loss 3.547466 loss_att 3.193811 loss_ctc 4.877409 loss_rnnt 3.272137 hw_loss 0.316377 history loss 3.416079 rank 7
2023-02-22 03:00:55,639 DEBUG CV Batch 13/0 loss 3.547466 loss_att 3.193811 loss_ctc 4.877409 loss_rnnt 3.272137 hw_loss 0.316377 history loss 3.416079 rank 2
2023-02-22 03:00:55,642 DEBUG CV Batch 13/0 loss 3.547466 loss_att 3.193811 loss_ctc 4.877409 loss_rnnt 3.272137 hw_loss 0.316377 history loss 3.416079 rank 6
2023-02-22 03:00:55,662 DEBUG CV Batch 13/0 loss 3.547466 loss_att 3.193811 loss_ctc 4.877409 loss_rnnt 3.272137 hw_loss 0.316377 history loss 3.416079 rank 0
2023-02-22 03:00:55,670 DEBUG CV Batch 13/0 loss 3.547466 loss_att 3.193811 loss_ctc 4.877409 loss_rnnt 3.272137 hw_loss 0.316377 history loss 3.416079 rank 5
2023-02-22 03:00:55,676 DEBUG CV Batch 13/0 loss 3.547466 loss_att 3.193811 loss_ctc 4.877409 loss_rnnt 3.272137 hw_loss 0.316377 history loss 3.416079 rank 4
2023-02-22 03:01:06,731 DEBUG CV Batch 13/100 loss 10.607287 loss_att 10.400718 loss_ctc 12.198603 loss_rnnt 10.307953 hw_loss 0.240886 history loss 4.392735 rank 7
2023-02-22 03:01:06,838 DEBUG CV Batch 13/100 loss 10.607287 loss_att 10.400718 loss_ctc 12.198603 loss_rnnt 10.307953 hw_loss 0.240886 history loss 4.392735 rank 0
2023-02-22 03:01:06,880 DEBUG CV Batch 13/100 loss 10.607287 loss_att 10.400718 loss_ctc 12.198603 loss_rnnt 10.307953 hw_loss 0.240886 history loss 4.392735 rank 5
2023-02-22 03:01:06,934 DEBUG CV Batch 13/100 loss 10.607287 loss_att 10.400718 loss_ctc 12.198603 loss_rnnt 10.307953 hw_loss 0.240886 history loss 4.392735 rank 6
2023-02-22 03:01:06,945 DEBUG CV Batch 13/100 loss 10.607287 loss_att 10.400718 loss_ctc 12.198603 loss_rnnt 10.307953 hw_loss 0.240886 history loss 4.392735 rank 1
2023-02-22 03:01:07,018 DEBUG CV Batch 13/100 loss 10.607287 loss_att 10.400718 loss_ctc 12.198603 loss_rnnt 10.307953 hw_loss 0.240886 history loss 4.392735 rank 2
2023-02-22 03:01:07,034 DEBUG CV Batch 13/100 loss 10.607287 loss_att 10.400718 loss_ctc 12.198603 loss_rnnt 10.307953 hw_loss 0.240886 history loss 4.392735 rank 4
2023-02-22 03:01:08,165 DEBUG CV Batch 13/100 loss 10.607287 loss_att 10.400718 loss_ctc 12.198603 loss_rnnt 10.307953 hw_loss 0.240886 history loss 4.392735 rank 3
2023-02-22 03:01:20,078 DEBUG CV Batch 13/200 loss 11.002613 loss_att 24.608551 loss_ctc 10.063856 loss_rnnt 8.330132 hw_loss 0.143365 history loss 5.061076 rank 7
2023-02-22 03:01:20,190 DEBUG CV Batch 13/200 loss 11.002613 loss_att 24.608551 loss_ctc 10.063856 loss_rnnt 8.330132 hw_loss 0.143365 history loss 5.061076 rank 0
2023-02-22 03:01:20,302 DEBUG CV Batch 13/200 loss 11.002613 loss_att 24.608551 loss_ctc 10.063856 loss_rnnt 8.330132 hw_loss 0.143365 history loss 5.061076 rank 5
2023-02-22 03:01:20,344 DEBUG CV Batch 13/200 loss 11.002613 loss_att 24.608551 loss_ctc 10.063856 loss_rnnt 8.330132 hw_loss 0.143365 history loss 5.061076 rank 1
2023-02-22 03:01:20,474 DEBUG CV Batch 13/200 loss 11.002613 loss_att 24.608551 loss_ctc 10.063856 loss_rnnt 8.330132 hw_loss 0.143365 history loss 5.061076 rank 4
2023-02-22 03:01:20,495 DEBUG CV Batch 13/200 loss 11.002613 loss_att 24.608551 loss_ctc 10.063856 loss_rnnt 8.330132 hw_loss 0.143365 history loss 5.061076 rank 2
2023-02-22 03:01:20,527 DEBUG CV Batch 13/200 loss 11.002613 loss_att 24.608551 loss_ctc 10.063856 loss_rnnt 8.330132 hw_loss 0.143365 history loss 5.061076 rank 6
2023-02-22 03:01:21,983 DEBUG CV Batch 13/200 loss 11.002613 loss_att 24.608551 loss_ctc 10.063856 loss_rnnt 8.330132 hw_loss 0.143365 history loss 5.061076 rank 3
2023-02-22 03:01:32,201 DEBUG CV Batch 13/300 loss 5.598867 loss_att 6.264901 loss_ctc 7.937453 loss_rnnt 5.054161 hw_loss 0.186914 history loss 5.262739 rank 7
2023-02-22 03:01:32,265 DEBUG CV Batch 13/300 loss 5.598867 loss_att 6.264901 loss_ctc 7.937453 loss_rnnt 5.054161 hw_loss 0.186914 history loss 5.262739 rank 0
2023-02-22 03:01:32,405 DEBUG CV Batch 13/300 loss 5.598867 loss_att 6.264901 loss_ctc 7.937453 loss_rnnt 5.054161 hw_loss 0.186914 history loss 5.262739 rank 5
2023-02-22 03:01:32,480 DEBUG CV Batch 13/300 loss 5.598867 loss_att 6.264901 loss_ctc 7.937453 loss_rnnt 5.054161 hw_loss 0.186914 history loss 5.262739 rank 1
2023-02-22 03:01:32,533 DEBUG CV Batch 13/300 loss 5.598867 loss_att 6.264901 loss_ctc 7.937453 loss_rnnt 5.054161 hw_loss 0.186914 history loss 5.262739 rank 4
2023-02-22 03:01:32,659 DEBUG CV Batch 13/300 loss 5.598867 loss_att 6.264901 loss_ctc 7.937453 loss_rnnt 5.054161 hw_loss 0.186914 history loss 5.262739 rank 2
2023-02-22 03:01:33,278 DEBUG CV Batch 13/300 loss 5.598867 loss_att 6.264901 loss_ctc 7.937453 loss_rnnt 5.054161 hw_loss 0.186914 history loss 5.262739 rank 6
2023-02-22 03:01:34,440 DEBUG CV Batch 13/300 loss 5.598867 loss_att 6.264901 loss_ctc 7.937453 loss_rnnt 5.054161 hw_loss 0.186914 history loss 5.262739 rank 3
2023-02-22 03:01:44,294 DEBUG CV Batch 13/400 loss 32.122601 loss_att 108.620468 loss_ctc 21.202110 loss_rnnt 18.279079 hw_loss 0.000023 history loss 6.422282 rank 7
2023-02-22 03:01:44,386 DEBUG CV Batch 13/400 loss 32.122601 loss_att 108.620468 loss_ctc 21.202110 loss_rnnt 18.279079 hw_loss 0.000023 history loss 6.422282 rank 0
2023-02-22 03:01:44,460 DEBUG CV Batch 13/400 loss 32.122601 loss_att 108.620468 loss_ctc 21.202110 loss_rnnt 18.279079 hw_loss 0.000023 history loss 6.422282 rank 5
2023-02-22 03:01:44,668 DEBUG CV Batch 13/400 loss 32.122601 loss_att 108.620468 loss_ctc 21.202110 loss_rnnt 18.279079 hw_loss 0.000023 history loss 6.422282 rank 1
2023-02-22 03:01:44,672 DEBUG CV Batch 13/400 loss 32.122601 loss_att 108.620468 loss_ctc 21.202110 loss_rnnt 18.279079 hw_loss 0.000023 history loss 6.422282 rank 4
2023-02-22 03:01:45,563 DEBUG CV Batch 13/400 loss 32.122601 loss_att 108.620468 loss_ctc 21.202110 loss_rnnt 18.279079 hw_loss 0.000023 history loss 6.422282 rank 6
2023-02-22 03:01:46,326 DEBUG CV Batch 13/400 loss 32.122601 loss_att 108.620468 loss_ctc 21.202110 loss_rnnt 18.279079 hw_loss 0.000023 history loss 6.422282 rank 2
2023-02-22 03:01:46,632 DEBUG CV Batch 13/400 loss 32.122601 loss_att 108.620468 loss_ctc 21.202110 loss_rnnt 18.279079 hw_loss 0.000023 history loss 6.422282 rank 3
2023-02-22 03:01:54,969 DEBUG CV Batch 13/500 loss 7.970537 loss_att 8.048470 loss_ctc 9.005132 loss_rnnt 7.770837 hw_loss 0.086563 history loss 7.334053 rank 7
2023-02-22 03:01:54,979 DEBUG CV Batch 13/500 loss 7.970537 loss_att 8.048470 loss_ctc 9.005132 loss_rnnt 7.770837 hw_loss 0.086563 history loss 7.334053 rank 0
2023-02-22 03:01:55,093 DEBUG CV Batch 13/500 loss 7.970537 loss_att 8.048470 loss_ctc 9.005132 loss_rnnt 7.770837 hw_loss 0.086563 history loss 7.334053 rank 5
2023-02-22 03:01:55,217 DEBUG CV Batch 13/500 loss 7.970537 loss_att 8.048470 loss_ctc 9.005132 loss_rnnt 7.770837 hw_loss 0.086563 history loss 7.334053 rank 4
2023-02-22 03:01:56,118 DEBUG CV Batch 13/500 loss 7.970537 loss_att 8.048470 loss_ctc 9.005132 loss_rnnt 7.770837 hw_loss 0.086563 history loss 7.334053 rank 1
2023-02-22 03:01:56,231 DEBUG CV Batch 13/500 loss 7.970537 loss_att 8.048470 loss_ctc 9.005132 loss_rnnt 7.770837 hw_loss 0.086563 history loss 7.334053 rank 6
2023-02-22 03:01:57,261 DEBUG CV Batch 13/500 loss 7.970537 loss_att 8.048470 loss_ctc 9.005132 loss_rnnt 7.770837 hw_loss 0.086563 history loss 7.334053 rank 2
2023-02-22 03:01:57,553 DEBUG CV Batch 13/500 loss 7.970537 loss_att 8.048470 loss_ctc 9.005132 loss_rnnt 7.770837 hw_loss 0.086563 history loss 7.334053 rank 3
2023-02-22 03:02:07,080 DEBUG CV Batch 13/600 loss 9.958632 loss_att 9.816557 loss_ctc 11.598705 loss_rnnt 9.629082 hw_loss 0.261165 history loss 8.325430 rank 0
2023-02-22 03:02:07,120 DEBUG CV Batch 13/600 loss 9.958632 loss_att 9.816557 loss_ctc 11.598705 loss_rnnt 9.629082 hw_loss 0.261165 history loss 8.325430 rank 7
2023-02-22 03:02:07,192 DEBUG CV Batch 13/600 loss 9.958632 loss_att 9.816557 loss_ctc 11.598705 loss_rnnt 9.629082 hw_loss 0.261165 history loss 8.325430 rank 5
2023-02-22 03:02:07,267 DEBUG CV Batch 13/600 loss 9.958632 loss_att 9.816557 loss_ctc 11.598705 loss_rnnt 9.629082 hw_loss 0.261165 history loss 8.325430 rank 4
2023-02-22 03:02:08,410 DEBUG CV Batch 13/600 loss 9.958632 loss_att 9.816557 loss_ctc 11.598705 loss_rnnt 9.629082 hw_loss 0.261165 history loss 8.325430 rank 1
2023-02-22 03:02:08,462 DEBUG CV Batch 13/600 loss 9.958632 loss_att 9.816557 loss_ctc 11.598705 loss_rnnt 9.629082 hw_loss 0.261165 history loss 8.325430 rank 6
2023-02-22 03:02:09,508 DEBUG CV Batch 13/600 loss 9.958632 loss_att 9.816557 loss_ctc 11.598705 loss_rnnt 9.629082 hw_loss 0.261165 history loss 8.325430 rank 2
2023-02-22 03:02:09,874 DEBUG CV Batch 13/600 loss 9.958632 loss_att 9.816557 loss_ctc 11.598705 loss_rnnt 9.629082 hw_loss 0.261165 history loss 8.325430 rank 3
2023-02-22 03:02:18,426 DEBUG CV Batch 13/700 loss 28.948807 loss_att 69.015915 loss_ctc 25.515844 loss_rnnt 21.368399 hw_loss 0.046337 history loss 9.171908 rank 7
2023-02-22 03:02:18,431 DEBUG CV Batch 13/700 loss 28.948807 loss_att 69.015915 loss_ctc 25.515844 loss_rnnt 21.368399 hw_loss 0.046337 history loss 9.171908 rank 0
2023-02-22 03:02:18,600 DEBUG CV Batch 13/700 loss 28.948807 loss_att 69.015915 loss_ctc 25.515844 loss_rnnt 21.368399 hw_loss 0.046337 history loss 9.171908 rank 5
2023-02-22 03:02:18,624 DEBUG CV Batch 13/700 loss 28.948807 loss_att 69.015915 loss_ctc 25.515844 loss_rnnt 21.368399 hw_loss 0.046337 history loss 9.171908 rank 4
2023-02-22 03:02:19,911 DEBUG CV Batch 13/700 loss 28.948807 loss_att 69.015915 loss_ctc 25.515844 loss_rnnt 21.368399 hw_loss 0.046337 history loss 9.171908 rank 6
2023-02-22 03:02:20,980 DEBUG CV Batch 13/700 loss 28.948807 loss_att 69.015915 loss_ctc 25.515844 loss_rnnt 21.368399 hw_loss 0.046337 history loss 9.171908 rank 2
2023-02-22 03:02:21,225 DEBUG CV Batch 13/700 loss 28.948807 loss_att 69.015915 loss_ctc 25.515844 loss_rnnt 21.368399 hw_loss 0.046337 history loss 9.171908 rank 1
2023-02-22 03:02:21,427 DEBUG CV Batch 13/700 loss 28.948807 loss_att 69.015915 loss_ctc 25.515844 loss_rnnt 21.368399 hw_loss 0.046337 history loss 9.171908 rank 3
2023-02-22 03:02:29,590 DEBUG CV Batch 13/800 loss 15.411436 loss_att 13.809589 loss_ctc 17.632240 loss_rnnt 15.366953 hw_loss 0.128895 history loss 8.528614 rank 4
2023-02-22 03:02:29,651 DEBUG CV Batch 13/800 loss 15.411436 loss_att 13.809589 loss_ctc 17.632240 loss_rnnt 15.366953 hw_loss 0.128895 history loss 8.528614 rank 0
2023-02-22 03:02:29,663 DEBUG CV Batch 13/800 loss 15.411436 loss_att 13.809589 loss_ctc 17.632240 loss_rnnt 15.366953 hw_loss 0.128895 history loss 8.528614 rank 7
2023-02-22 03:02:29,795 DEBUG CV Batch 13/800 loss 15.411436 loss_att 13.809589 loss_ctc 17.632240 loss_rnnt 15.366953 hw_loss 0.128895 history loss 8.528614 rank 5
2023-02-22 03:02:31,464 DEBUG CV Batch 13/800 loss 15.411436 loss_att 13.809589 loss_ctc 17.632240 loss_rnnt 15.366953 hw_loss 0.128895 history loss 8.528614 rank 6
2023-02-22 03:02:32,307 DEBUG CV Batch 13/800 loss 15.411436 loss_att 13.809589 loss_ctc 17.632240 loss_rnnt 15.366953 hw_loss 0.128895 history loss 8.528614 rank 2
2023-02-22 03:02:32,570 DEBUG CV Batch 13/800 loss 15.411436 loss_att 13.809589 loss_ctc 17.632240 loss_rnnt 15.366953 hw_loss 0.128895 history loss 8.528614 rank 1
2023-02-22 03:02:32,775 DEBUG CV Batch 13/800 loss 15.411436 loss_att 13.809589 loss_ctc 17.632240 loss_rnnt 15.366953 hw_loss 0.128895 history loss 8.528614 rank 3
2023-02-22 03:02:42,766 DEBUG CV Batch 13/900 loss 16.767784 loss_att 25.751961 loss_ctc 22.856850 loss_rnnt 14.122890 hw_loss 0.067841 history loss 8.283801 rank 4
2023-02-22 03:02:42,835 DEBUG CV Batch 13/900 loss 16.767784 loss_att 25.751961 loss_ctc 22.856850 loss_rnnt 14.122890 hw_loss 0.067841 history loss 8.283801 rank 0
2023-02-22 03:02:42,893 DEBUG CV Batch 13/900 loss 16.767784 loss_att 25.751961 loss_ctc 22.856850 loss_rnnt 14.122890 hw_loss 0.067841 history loss 8.283801 rank 7
2023-02-22 03:02:43,093 DEBUG CV Batch 13/900 loss 16.767784 loss_att 25.751961 loss_ctc 22.856850 loss_rnnt 14.122890 hw_loss 0.067841 history loss 8.283801 rank 5
2023-02-22 03:02:44,811 DEBUG CV Batch 13/900 loss 16.767784 loss_att 25.751961 loss_ctc 22.856850 loss_rnnt 14.122890 hw_loss 0.067841 history loss 8.283801 rank 6
2023-02-22 03:02:45,653 DEBUG CV Batch 13/900 loss 16.767784 loss_att 25.751961 loss_ctc 22.856850 loss_rnnt 14.122890 hw_loss 0.067841 history loss 8.283801 rank 2
2023-02-22 03:02:45,918 DEBUG CV Batch 13/900 loss 16.767784 loss_att 25.751961 loss_ctc 22.856850 loss_rnnt 14.122890 hw_loss 0.067841 history loss 8.283801 rank 1
2023-02-22 03:02:46,394 DEBUG CV Batch 13/900 loss 16.767784 loss_att 25.751961 loss_ctc 22.856850 loss_rnnt 14.122890 hw_loss 0.067841 history loss 8.283801 rank 3
2023-02-22 03:02:54,839 DEBUG CV Batch 13/1000 loss 6.132843 loss_att 7.349339 loss_ctc 7.676161 loss_rnnt 5.585875 hw_loss 0.183548 history loss 8.018858 rank 4
2023-02-22 03:02:54,948 DEBUG CV Batch 13/1000 loss 6.132843 loss_att 7.349339 loss_ctc 7.676161 loss_rnnt 5.585875 hw_loss 0.183548 history loss 8.018858 rank 0
2023-02-22 03:02:55,141 DEBUG CV Batch 13/1000 loss 6.132843 loss_att 7.349339 loss_ctc 7.676161 loss_rnnt 5.585875 hw_loss 0.183548 history loss 8.018858 rank 7
2023-02-22 03:02:55,308 DEBUG CV Batch 13/1000 loss 6.132843 loss_att 7.349339 loss_ctc 7.676161 loss_rnnt 5.585875 hw_loss 0.183548 history loss 8.018858 rank 5
2023-02-22 03:02:57,204 DEBUG CV Batch 13/1000 loss 6.132843 loss_att 7.349339 loss_ctc 7.676161 loss_rnnt 5.585875 hw_loss 0.183548 history loss 8.018858 rank 6
2023-02-22 03:02:58,107 DEBUG CV Batch 13/1000 loss 6.132843 loss_att 7.349339 loss_ctc 7.676161 loss_rnnt 5.585875 hw_loss 0.183548 history loss 8.018858 rank 2
2023-02-22 03:02:58,807 DEBUG CV Batch 13/1000 loss 6.132843 loss_att 7.349339 loss_ctc 7.676161 loss_rnnt 5.585875 hw_loss 0.183548 history loss 8.018858 rank 3
2023-02-22 03:02:59,491 DEBUG CV Batch 13/1000 loss 6.132843 loss_att 7.349339 loss_ctc 7.676161 loss_rnnt 5.585875 hw_loss 0.183548 history loss 8.018858 rank 1
2023-02-22 03:03:06,763 DEBUG CV Batch 13/1100 loss 7.538429 loss_att 6.745194 loss_ctc 10.089540 loss_rnnt 7.194484 hw_loss 0.304581 history loss 8.016718 rank 4
2023-02-22 03:03:06,821 DEBUG CV Batch 13/1100 loss 7.538429 loss_att 6.745194 loss_ctc 10.089540 loss_rnnt 7.194484 hw_loss 0.304581 history loss 8.016718 rank 0
2023-02-22 03:03:06,998 DEBUG CV Batch 13/1100 loss 7.538429 loss_att 6.745194 loss_ctc 10.089540 loss_rnnt 7.194484 hw_loss 0.304581 history loss 8.016718 rank 7
2023-02-22 03:03:07,189 DEBUG CV Batch 13/1100 loss 7.538429 loss_att 6.745194 loss_ctc 10.089540 loss_rnnt 7.194484 hw_loss 0.304581 history loss 8.016718 rank 5
2023-02-22 03:03:09,265 DEBUG CV Batch 13/1100 loss 7.538429 loss_att 6.745194 loss_ctc 10.089540 loss_rnnt 7.194484 hw_loss 0.304581 history loss 8.016718 rank 6
2023-02-22 03:03:10,119 DEBUG CV Batch 13/1100 loss 7.538429 loss_att 6.745194 loss_ctc 10.089540 loss_rnnt 7.194484 hw_loss 0.304581 history loss 8.016718 rank 2
2023-02-22 03:03:10,863 DEBUG CV Batch 13/1100 loss 7.538429 loss_att 6.745194 loss_ctc 10.089540 loss_rnnt 7.194484 hw_loss 0.304581 history loss 8.016718 rank 3
2023-02-22 03:03:12,800 DEBUG CV Batch 13/1100 loss 7.538429 loss_att 6.745194 loss_ctc 10.089540 loss_rnnt 7.194484 hw_loss 0.304581 history loss 8.016718 rank 1
2023-02-22 03:03:17,399 DEBUG CV Batch 13/1200 loss 9.106421 loss_att 11.237078 loss_ctc 9.592574 loss_rnnt 8.521413 hw_loss 0.176357 history loss 8.403393 rank 4
2023-02-22 03:03:17,401 DEBUG CV Batch 13/1200 loss 9.106421 loss_att 11.237078 loss_ctc 9.592574 loss_rnnt 8.521413 hw_loss 0.176357 history loss 8.403393 rank 0
2023-02-22 03:03:17,770 DEBUG CV Batch 13/1200 loss 9.106421 loss_att 11.237078 loss_ctc 9.592574 loss_rnnt 8.521413 hw_loss 0.176357 history loss 8.403393 rank 7
2023-02-22 03:03:17,934 DEBUG CV Batch 13/1200 loss 9.106421 loss_att 11.237078 loss_ctc 9.592574 loss_rnnt 8.521413 hw_loss 0.176357 history loss 8.403393 rank 5
2023-02-22 03:03:20,020 DEBUG CV Batch 13/1200 loss 9.106421 loss_att 11.237078 loss_ctc 9.592574 loss_rnnt 8.521413 hw_loss 0.176357 history loss 8.403393 rank 6
2023-02-22 03:03:20,877 DEBUG CV Batch 13/1200 loss 9.106421 loss_att 11.237078 loss_ctc 9.592574 loss_rnnt 8.521413 hw_loss 0.176357 history loss 8.403393 rank 2
2023-02-22 03:03:21,691 DEBUG CV Batch 13/1200 loss 9.106421 loss_att 11.237078 loss_ctc 9.592574 loss_rnnt 8.521413 hw_loss 0.176357 history loss 8.403393 rank 3
2023-02-22 03:03:24,876 DEBUG CV Batch 13/1200 loss 9.106421 loss_att 11.237078 loss_ctc 9.592574 loss_rnnt 8.521413 hw_loss 0.176357 history loss 8.403393 rank 1
2023-02-22 03:03:29,325 DEBUG CV Batch 13/1300 loss 7.707466 loss_att 7.447478 loss_ctc 9.103381 loss_rnnt 7.440673 hw_loss 0.248755 history loss 8.712807 rank 0
2023-02-22 03:03:29,515 DEBUG CV Batch 13/1300 loss 7.707466 loss_att 7.447478 loss_ctc 9.103381 loss_rnnt 7.440673 hw_loss 0.248755 history loss 8.712807 rank 4
2023-02-22 03:03:29,736 DEBUG CV Batch 13/1300 loss 7.707466 loss_att 7.447478 loss_ctc 9.103381 loss_rnnt 7.440673 hw_loss 0.248755 history loss 8.712807 rank 7
2023-02-22 03:03:29,929 DEBUG CV Batch 13/1300 loss 7.707466 loss_att 7.447478 loss_ctc 9.103381 loss_rnnt 7.440673 hw_loss 0.248755 history loss 8.712807 rank 5
2023-02-22 03:03:32,177 DEBUG CV Batch 13/1300 loss 7.707466 loss_att 7.447478 loss_ctc 9.103381 loss_rnnt 7.440673 hw_loss 0.248755 history loss 8.712807 rank 6
2023-02-22 03:03:32,971 DEBUG CV Batch 13/1300 loss 7.707466 loss_att 7.447478 loss_ctc 9.103381 loss_rnnt 7.440673 hw_loss 0.248755 history loss 8.712807 rank 2
2023-02-22 03:03:33,941 DEBUG CV Batch 13/1300 loss 7.707466 loss_att 7.447478 loss_ctc 9.103381 loss_rnnt 7.440673 hw_loss 0.248755 history loss 8.712807 rank 3
2023-02-22 03:03:37,338 DEBUG CV Batch 13/1300 loss 7.707466 loss_att 7.447478 loss_ctc 9.103381 loss_rnnt 7.440673 hw_loss 0.248755 history loss 8.712807 rank 1
2023-02-22 03:03:40,559 DEBUG CV Batch 13/1400 loss 14.947637 loss_att 41.787243 loss_ctc 7.129051 loss_rnnt 10.580793 hw_loss 0.077623 history loss 9.124850 rank 0
2023-02-22 03:03:40,880 DEBUG CV Batch 13/1400 loss 14.947637 loss_att 41.787243 loss_ctc 7.129051 loss_rnnt 10.580793 hw_loss 0.077623 history loss 9.124850 rank 4
2023-02-22 03:03:40,966 DEBUG CV Batch 13/1400 loss 14.947637 loss_att 41.787243 loss_ctc 7.129051 loss_rnnt 10.580793 hw_loss 0.077623 history loss 9.124850 rank 7
2023-02-22 03:03:41,166 DEBUG CV Batch 13/1400 loss 14.947637 loss_att 41.787243 loss_ctc 7.129051 loss_rnnt 10.580793 hw_loss 0.077623 history loss 9.124850 rank 5
2023-02-22 03:03:43,565 DEBUG CV Batch 13/1400 loss 14.947637 loss_att 41.787243 loss_ctc 7.129051 loss_rnnt 10.580793 hw_loss 0.077623 history loss 9.124850 rank 6
2023-02-22 03:03:44,344 DEBUG CV Batch 13/1400 loss 14.947637 loss_att 41.787243 loss_ctc 7.129051 loss_rnnt 10.580793 hw_loss 0.077623 history loss 9.124850 rank 2
2023-02-22 03:03:45,372 DEBUG CV Batch 13/1400 loss 14.947637 loss_att 41.787243 loss_ctc 7.129051 loss_rnnt 10.580793 hw_loss 0.077623 history loss 9.124850 rank 3
2023-02-22 03:03:48,660 DEBUG CV Batch 13/1400 loss 14.947637 loss_att 41.787243 loss_ctc 7.129051 loss_rnnt 10.580793 hw_loss 0.077623 history loss 9.124850 rank 1
2023-02-22 03:03:52,116 DEBUG CV Batch 13/1500 loss 7.285404 loss_att 7.846208 loss_ctc 6.110511 loss_rnnt 7.281600 hw_loss 0.090554 history loss 8.911508 rank 0
2023-02-22 03:03:52,352 DEBUG CV Batch 13/1500 loss 7.285404 loss_att 7.846208 loss_ctc 6.110511 loss_rnnt 7.281600 hw_loss 0.090554 history loss 8.911508 rank 4
2023-02-22 03:03:52,415 DEBUG CV Batch 13/1500 loss 7.285404 loss_att 7.846208 loss_ctc 6.110511 loss_rnnt 7.281600 hw_loss 0.090554 history loss 8.911508 rank 7
2023-02-22 03:03:52,637 DEBUG CV Batch 13/1500 loss 7.285404 loss_att 7.846208 loss_ctc 6.110511 loss_rnnt 7.281600 hw_loss 0.090554 history loss 8.911508 rank 5
2023-02-22 03:03:55,133 DEBUG CV Batch 13/1500 loss 7.285404 loss_att 7.846208 loss_ctc 6.110511 loss_rnnt 7.281600 hw_loss 0.090554 history loss 8.911508 rank 6
2023-02-22 03:03:55,935 DEBUG CV Batch 13/1500 loss 7.285404 loss_att 7.846208 loss_ctc 6.110511 loss_rnnt 7.281600 hw_loss 0.090554 history loss 8.911508 rank 2
2023-02-22 03:03:57,734 DEBUG CV Batch 13/1500 loss 7.285404 loss_att 7.846208 loss_ctc 6.110511 loss_rnnt 7.281600 hw_loss 0.090554 history loss 8.911508 rank 3
2023-02-22 03:04:00,193 DEBUG CV Batch 13/1500 loss 7.285404 loss_att 7.846208 loss_ctc 6.110511 loss_rnnt 7.281600 hw_loss 0.090554 history loss 8.911508 rank 1
2023-02-22 03:04:04,993 DEBUG CV Batch 13/1600 loss 12.797457 loss_att 17.214447 loss_ctc 14.382538 loss_rnnt 11.673978 hw_loss 0.053881 history loss 8.812826 rank 0
2023-02-22 03:04:05,268 DEBUG CV Batch 13/1600 loss 12.797457 loss_att 17.214447 loss_ctc 14.382538 loss_rnnt 11.673978 hw_loss 0.053881 history loss 8.812826 rank 4
2023-02-22 03:04:05,292 DEBUG CV Batch 13/1600 loss 12.797457 loss_att 17.214447 loss_ctc 14.382538 loss_rnnt 11.673978 hw_loss 0.053881 history loss 8.812826 rank 7
2023-02-22 03:04:05,547 DEBUG CV Batch 13/1600 loss 12.797457 loss_att 17.214447 loss_ctc 14.382538 loss_rnnt 11.673978 hw_loss 0.053881 history loss 8.812826 rank 5
2023-02-22 03:04:08,250 DEBUG CV Batch 13/1600 loss 12.797457 loss_att 17.214447 loss_ctc 14.382538 loss_rnnt 11.673978 hw_loss 0.053881 history loss 8.812826 rank 6
2023-02-22 03:04:09,053 DEBUG CV Batch 13/1600 loss 12.797457 loss_att 17.214447 loss_ctc 14.382538 loss_rnnt 11.673978 hw_loss 0.053881 history loss 8.812826 rank 2
2023-02-22 03:04:11,046 DEBUG CV Batch 13/1600 loss 12.797457 loss_att 17.214447 loss_ctc 14.382538 loss_rnnt 11.673978 hw_loss 0.053881 history loss 8.812826 rank 3
2023-02-22 03:04:13,259 DEBUG CV Batch 13/1600 loss 12.797457 loss_att 17.214447 loss_ctc 14.382538 loss_rnnt 11.673978 hw_loss 0.053881 history loss 8.812826 rank 1
2023-02-22 03:04:17,337 DEBUG CV Batch 13/1700 loss 13.169126 loss_att 12.706100 loss_ctc 18.204990 loss_rnnt 12.523088 hw_loss 0.125984 history loss 8.701144 rank 0
2023-02-22 03:04:17,626 DEBUG CV Batch 13/1700 loss 13.169126 loss_att 12.706100 loss_ctc 18.204990 loss_rnnt 12.523088 hw_loss 0.125984 history loss 8.701144 rank 7
2023-02-22 03:04:17,645 DEBUG CV Batch 13/1700 loss 13.169126 loss_att 12.706100 loss_ctc 18.204990 loss_rnnt 12.523088 hw_loss 0.125984 history loss 8.701144 rank 4
2023-02-22 03:04:17,864 DEBUG CV Batch 13/1700 loss 13.169126 loss_att 12.706100 loss_ctc 18.204990 loss_rnnt 12.523088 hw_loss 0.125984 history loss 8.701144 rank 5
2023-02-22 03:04:20,623 DEBUG CV Batch 13/1700 loss 13.169126 loss_att 12.706100 loss_ctc 18.204990 loss_rnnt 12.523088 hw_loss 0.125984 history loss 8.701144 rank 6
2023-02-22 03:04:21,548 DEBUG CV Batch 13/1700 loss 13.169126 loss_att 12.706100 loss_ctc 18.204990 loss_rnnt 12.523088 hw_loss 0.125984 history loss 8.701144 rank 2
2023-02-22 03:04:24,625 DEBUG CV Batch 13/1700 loss 13.169125 loss_att 12.706100 loss_ctc 18.204990 loss_rnnt 12.523088 hw_loss 0.125984 history loss 8.701144 rank 3
2023-02-22 03:04:25,336 DEBUG CV Batch 13/1700 loss 13.169126 loss_att 12.706100 loss_ctc 18.204990 loss_rnnt 12.523088 hw_loss 0.125984 history loss 8.701144 rank 1
2023-02-22 03:04:26,403 INFO Epoch 13 CV info cv_loss 8.653463735730684
2023-02-22 03:04:26,404 INFO Checkpoint: save to checkpoint exp/2_21_rnnt_bias_loss_2_class_1word_finetune/13.pt
2023-02-22 03:04:26,706 INFO Epoch 13 CV info cv_loss 8.653463735506703
2023-02-22 03:04:26,708 INFO Epoch 14 TRAIN info lr 0.0004626596205253395
2023-02-22 03:04:26,712 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 03:04:26,773 INFO Epoch 13 CV info cv_loss 8.653463735713455
2023-02-22 03:04:26,774 INFO Epoch 14 TRAIN info lr 0.0004626596205253395
2023-02-22 03:04:26,778 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 03:04:27,021 INFO Epoch 13 CV info cv_loss 8.653463734843376
2023-02-22 03:04:27,022 INFO Epoch 14 TRAIN info lr 0.0004626536785933618
2023-02-22 03:04:27,025 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 03:04:27,460 INFO Epoch 14 TRAIN info lr 0.0004626893336197016
2023-02-22 03:04:27,464 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 03:04:29,739 INFO Epoch 13 CV info cv_loss 8.653463736032196
2023-02-22 03:04:29,740 INFO Epoch 14 TRAIN info lr 0.00046274084988066503
2023-02-22 03:04:29,743 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 03:04:30,557 INFO Epoch 13 CV info cv_loss 8.653463734955366
2023-02-22 03:04:30,558 INFO Epoch 14 TRAIN info lr 0.00046267150507614546
2023-02-22 03:04:30,560 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 03:04:34,427 INFO Epoch 13 CV info cv_loss 8.653463735411941
2023-02-22 03:04:34,428 INFO Epoch 14 TRAIN info lr 0.00046277057862900424
2023-02-22 03:04:34,431 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 03:04:34,794 INFO Epoch 13 CV info cv_loss 8.65346373522242
2023-02-22 03:04:34,796 INFO Epoch 14 TRAIN info lr 0.0004626655626862625
2023-02-22 03:04:34,801 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 03:05:47,313 DEBUG TRAIN Batch 14/0 loss 12.340490 loss_att 12.739645 loss_ctc 17.021387 loss_rnnt 11.510955 hw_loss 0.235472 lr 0.00046265 rank 5
2023-02-22 03:05:47,313 DEBUG TRAIN Batch 14/0 loss 13.636856 loss_att 12.286765 loss_ctc 15.583215 loss_rnnt 13.491876 hw_loss 0.291530 lr 0.00046266 rank 7
2023-02-22 03:05:47,313 DEBUG TRAIN Batch 14/0 loss 10.350825 loss_att 9.041862 loss_ctc 10.677361 loss_rnnt 10.442799 hw_loss 0.236776 lr 0.00046269 rank 0
2023-02-22 03:05:47,314 DEBUG TRAIN Batch 14/0 loss 13.627865 loss_att 11.959340 loss_ctc 15.245811 loss_rnnt 13.588345 hw_loss 0.295311 lr 0.00046266 rank 4
2023-02-22 03:05:47,316 DEBUG TRAIN Batch 14/0 loss 12.073390 loss_att 11.908374 loss_ctc 13.496094 loss_rnnt 11.771032 hw_loss 0.273127 lr 0.00046267 rank 2
2023-02-22 03:05:47,335 DEBUG TRAIN Batch 14/0 loss 7.860065 loss_att 6.841755 loss_ctc 9.000929 loss_rnnt 7.726490 hw_loss 0.347102 lr 0.00046266 rank 3
2023-02-22 03:05:47,347 DEBUG TRAIN Batch 14/0 loss 14.628009 loss_att 13.819880 loss_ctc 17.420008 loss_rnnt 14.279823 hw_loss 0.257896 lr 0.00046274 rank 6
2023-02-22 03:05:47,406 DEBUG TRAIN Batch 14/0 loss 10.535904 loss_att 9.541367 loss_ctc 12.894605 loss_rnnt 10.308441 hw_loss 0.209769 lr 0.00046277 rank 1
2023-02-22 03:07:01,933 DEBUG TRAIN Batch 14/100 loss 42.082363 loss_att 46.413208 loss_ctc 54.847145 loss_rnnt 39.476009 hw_loss 0.071645 lr 0.00046246 rank 7
2023-02-22 03:07:01,933 DEBUG TRAIN Batch 14/100 loss 28.687315 loss_att 30.780159 loss_ctc 33.299107 loss_rnnt 27.605444 hw_loss 0.090746 lr 0.00046249 rank 0
2023-02-22 03:07:01,934 DEBUG TRAIN Batch 14/100 loss 3.849938 loss_att 7.320658 loss_ctc 4.996826 loss_rnnt 2.913548 hw_loss 0.167489 lr 0.00046254 rank 6
2023-02-22 03:07:01,936 DEBUG TRAIN Batch 14/100 loss 8.128383 loss_att 12.313103 loss_ctc 13.805690 loss_rnnt 6.517043 hw_loss 0.032665 lr 0.00046246 rank 4
2023-02-22 03:07:01,936 DEBUG TRAIN Batch 14/100 loss 15.168581 loss_att 20.524059 loss_ctc 19.206633 loss_rnnt 13.467484 hw_loss 0.171742 lr 0.00046245 rank 5
2023-02-22 03:07:01,937 DEBUG TRAIN Batch 14/100 loss 15.302832 loss_att 20.428066 loss_ctc 19.984955 loss_rnnt 13.653483 hw_loss 0.000035 lr 0.00046257 rank 1
2023-02-22 03:07:01,943 DEBUG TRAIN Batch 14/100 loss 10.092132 loss_att 13.533344 loss_ctc 12.926990 loss_rnnt 8.979430 hw_loss 0.087147 lr 0.00046247 rank 2
2023-02-22 03:07:01,953 DEBUG TRAIN Batch 14/100 loss 9.352526 loss_att 14.987774 loss_ctc 15.012061 loss_rnnt 7.427011 hw_loss 0.082237 lr 0.00046247 rank 3
2023-02-22 03:08:15,628 DEBUG TRAIN Batch 14/200 loss 9.869761 loss_att 12.514784 loss_ctc 13.608036 loss_rnnt 8.835941 hw_loss 0.011962 lr 0.00046226 rank 5
2023-02-22 03:08:15,630 DEBUG TRAIN Batch 14/200 loss 9.194286 loss_att 12.519977 loss_ctc 8.545080 loss_rnnt 8.548807 hw_loss 0.125442 lr 0.00046234 rank 6
2023-02-22 03:08:15,631 DEBUG TRAIN Batch 14/200 loss 17.217905 loss_att 18.242935 loss_ctc 18.298588 loss_rnnt 16.778908 hw_loss 0.168562 lr 0.00046229 rank 0
2023-02-22 03:08:15,633 DEBUG TRAIN Batch 14/200 loss 10.574141 loss_att 17.218559 loss_ctc 16.539661 loss_rnnt 8.390872 hw_loss 0.110592 lr 0.00046227 rank 2
2023-02-22 03:08:15,633 DEBUG TRAIN Batch 14/200 loss 10.874467 loss_att 15.103308 loss_ctc 20.998922 loss_rnnt 8.571529 hw_loss 0.201076 lr 0.00046226 rank 7
2023-02-22 03:08:15,633 DEBUG TRAIN Batch 14/200 loss 11.464306 loss_att 12.767950 loss_ctc 15.349144 loss_rnnt 10.598560 hw_loss 0.163199 lr 0.00046227 rank 3
2023-02-22 03:08:15,634 DEBUG TRAIN Batch 14/200 loss 11.226992 loss_att 18.552290 loss_ctc 15.625388 loss_rnnt 9.106882 hw_loss 0.128620 lr 0.00046226 rank 4
2023-02-22 03:08:15,682 DEBUG TRAIN Batch 14/200 loss 17.317005 loss_att 18.412792 loss_ctc 19.231270 loss_rnnt 16.767670 hw_loss 0.140515 lr 0.00046237 rank 1
2023-02-22 03:09:31,412 DEBUG TRAIN Batch 14/300 loss 10.481159 loss_att 15.126785 loss_ctc 16.148750 loss_rnnt 8.717244 hw_loss 0.148332 lr 0.00046209 rank 0
2023-02-22 03:09:31,413 DEBUG TRAIN Batch 14/300 loss 7.684831 loss_att 10.508973 loss_ctc 13.184273 loss_rnnt 6.295386 hw_loss 0.171295 lr 0.00046206 rank 7
2023-02-22 03:09:31,416 DEBUG TRAIN Batch 14/300 loss 11.108566 loss_att 14.980009 loss_ctc 11.853497 loss_rnnt 10.157965 hw_loss 0.144353 lr 0.00046215 rank 6
2023-02-22 03:09:31,417 DEBUG TRAIN Batch 14/300 loss 13.386518 loss_att 16.359539 loss_ctc 16.938347 loss_rnnt 12.217157 hw_loss 0.189710 lr 0.00046207 rank 3
2023-02-22 03:09:31,417 DEBUG TRAIN Batch 14/300 loss 9.585726 loss_att 13.351992 loss_ctc 11.492712 loss_rnnt 8.553822 hw_loss 0.045723 lr 0.00046208 rank 2
2023-02-22 03:09:31,420 DEBUG TRAIN Batch 14/300 loss 12.090351 loss_att 16.182089 loss_ctc 18.384209 loss_rnnt 10.370806 hw_loss 0.116281 lr 0.00046206 rank 4
2023-02-22 03:09:31,422 DEBUG TRAIN Batch 14/300 loss 8.606627 loss_att 10.931107 loss_ctc 10.991097 loss_rnnt 7.767566 hw_loss 0.105443 lr 0.00046206 rank 5
2023-02-22 03:09:31,446 DEBUG TRAIN Batch 14/300 loss 12.484520 loss_att 15.018982 loss_ctc 14.248620 loss_rnnt 11.669329 hw_loss 0.137033 lr 0.00046218 rank 1
2023-02-22 03:10:47,856 DEBUG TRAIN Batch 14/400 loss 6.918553 loss_att 10.594799 loss_ctc 8.171430 loss_rnnt 5.918279 hw_loss 0.183703 lr 0.00046190 rank 0
2023-02-22 03:10:47,861 DEBUG TRAIN Batch 14/400 loss 8.568745 loss_att 12.125263 loss_ctc 10.601631 loss_rnnt 7.507668 hw_loss 0.147603 lr 0.00046187 rank 4
2023-02-22 03:10:47,861 DEBUG TRAIN Batch 14/400 loss 17.732449 loss_att 22.929029 loss_ctc 23.566126 loss_rnnt 15.805546 hw_loss 0.205809 lr 0.00046187 rank 7
2023-02-22 03:10:47,863 DEBUG TRAIN Batch 14/400 loss 19.624983 loss_att 25.257675 loss_ctc 28.966938 loss_rnnt 17.173267 hw_loss 0.149215 lr 0.00046198 rank 1
2023-02-22 03:10:47,866 DEBUG TRAIN Batch 14/400 loss 20.337721 loss_att 22.515713 loss_ctc 24.653276 loss_rnnt 19.309914 hw_loss 0.031500 lr 0.00046186 rank 5
2023-02-22 03:10:47,867 DEBUG TRAIN Batch 14/400 loss 16.104078 loss_att 17.434490 loss_ctc 19.446737 loss_rnnt 15.283586 hw_loss 0.203853 lr 0.00046187 rank 3
2023-02-22 03:10:47,867 DEBUG TRAIN Batch 14/400 loss 14.508568 loss_att 21.114803 loss_ctc 15.834373 loss_rnnt 12.871727 hw_loss 0.260286 lr 0.00046195 rank 6
2023-02-22 03:10:47,870 DEBUG TRAIN Batch 14/400 loss 17.845818 loss_att 19.663979 loss_ctc 20.050186 loss_rnnt 17.111900 hw_loss 0.143194 lr 0.00046188 rank 2
2023-02-22 03:12:03,273 DEBUG TRAIN Batch 14/500 loss 13.577170 loss_att 15.485296 loss_ctc 15.335574 loss_rnnt 12.803850 hw_loss 0.294825 lr 0.00046166 rank 5
2023-02-22 03:12:03,274 DEBUG TRAIN Batch 14/500 loss 4.387531 loss_att 7.742668 loss_ctc 4.945935 loss_rnnt 3.598614 hw_loss 0.081442 lr 0.00046175 rank 6
2023-02-22 03:12:03,275 DEBUG TRAIN Batch 14/500 loss 10.099282 loss_att 11.564631 loss_ctc 14.580640 loss_rnnt 9.130317 hw_loss 0.146966 lr 0.00046168 rank 2
2023-02-22 03:12:03,275 DEBUG TRAIN Batch 14/500 loss 12.819316 loss_att 14.844719 loss_ctc 15.700302 loss_rnnt 11.933015 hw_loss 0.182039 lr 0.00046167 rank 4
2023-02-22 03:12:03,276 DEBUG TRAIN Batch 14/500 loss 14.591440 loss_att 16.747423 loss_ctc 18.824831 loss_rnnt 13.495191 hw_loss 0.188625 lr 0.00046170 rank 0
2023-02-22 03:12:03,276 DEBUG TRAIN Batch 14/500 loss 9.885516 loss_att 13.533810 loss_ctc 12.324891 loss_rnnt 8.774472 hw_loss 0.105252 lr 0.00046167 rank 7
2023-02-22 03:12:03,280 DEBUG TRAIN Batch 14/500 loss 5.963155 loss_att 8.604263 loss_ctc 9.131241 loss_rnnt 4.912157 hw_loss 0.188185 lr 0.00046178 rank 1
2023-02-22 03:12:03,323 DEBUG TRAIN Batch 14/500 loss 10.007574 loss_att 13.051040 loss_ctc 12.969276 loss_rnnt 8.966805 hw_loss 0.069715 lr 0.00046168 rank 3
2023-02-22 03:13:19,472 DEBUG TRAIN Batch 14/600 loss 10.922505 loss_att 12.725946 loss_ctc 13.247053 loss_rnnt 10.150787 hw_loss 0.189545 lr 0.00046147 rank 4
2023-02-22 03:13:19,474 DEBUG TRAIN Batch 14/600 loss 16.157541 loss_att 16.201870 loss_ctc 20.753450 loss_rnnt 15.449537 hw_loss 0.161909 lr 0.00046147 rank 7
2023-02-22 03:13:19,474 DEBUG TRAIN Batch 14/600 loss 10.631695 loss_att 11.851893 loss_ctc 11.933727 loss_rnnt 10.183912 hw_loss 0.056511 lr 0.00046147 rank 5
2023-02-22 03:13:19,475 DEBUG TRAIN Batch 14/600 loss 21.076948 loss_att 22.066401 loss_ctc 25.574768 loss_rnnt 20.236752 hw_loss 0.079871 lr 0.00046158 rank 1
2023-02-22 03:13:19,476 DEBUG TRAIN Batch 14/600 loss 19.073824 loss_att 22.219967 loss_ctc 23.497633 loss_rnnt 17.795202 hw_loss 0.111663 lr 0.00046148 rank 3
2023-02-22 03:13:19,478 DEBUG TRAIN Batch 14/600 loss 15.753115 loss_att 16.102955 loss_ctc 21.312857 loss_rnnt 14.882729 hw_loss 0.110848 lr 0.00046150 rank 0
2023-02-22 03:13:19,479 DEBUG TRAIN Batch 14/600 loss 7.079043 loss_att 7.508461 loss_ctc 8.836031 loss_rnnt 6.591485 hw_loss 0.313892 lr 0.00046149 rank 2
2023-02-22 03:13:19,483 DEBUG TRAIN Batch 14/600 loss 10.409752 loss_att 11.804215 loss_ctc 13.020339 loss_rnnt 9.639373 hw_loss 0.268891 lr 0.00046155 rank 6
2023-02-22 03:14:37,048 DEBUG TRAIN Batch 14/700 loss 20.096678 loss_att 23.217070 loss_ctc 20.959286 loss_rnnt 19.225460 hw_loss 0.247731 lr 0.00046131 rank 0
2023-02-22 03:14:37,051 DEBUG TRAIN Batch 14/700 loss 7.890716 loss_att 12.032263 loss_ctc 9.699310 loss_rnnt 6.776683 hw_loss 0.083583 lr 0.00046128 rank 7
2023-02-22 03:14:37,057 DEBUG TRAIN Batch 14/700 loss 5.836225 loss_att 13.979811 loss_ctc 6.437126 loss_rnnt 4.082521 hw_loss 0.084123 lr 0.00046128 rank 4
2023-02-22 03:14:37,056 DEBUG TRAIN Batch 14/700 loss 19.000957 loss_att 19.047728 loss_ctc 25.862980 loss_rnnt 17.937778 hw_loss 0.260420 lr 0.00046139 rank 1
2023-02-22 03:14:37,059 DEBUG TRAIN Batch 14/700 loss 7.026672 loss_att 11.535960 loss_ctc 9.361634 loss_rnnt 5.764286 hw_loss 0.092251 lr 0.00046136 rank 6
2023-02-22 03:14:37,061 DEBUG TRAIN Batch 14/700 loss 8.533192 loss_att 14.316617 loss_ctc 11.092421 loss_rnnt 6.959991 hw_loss 0.141158 lr 0.00046127 rank 5
2023-02-22 03:14:37,061 DEBUG TRAIN Batch 14/700 loss 19.522318 loss_att 24.037041 loss_ctc 20.182495 loss_rnnt 18.440533 hw_loss 0.170285 lr 0.00046129 rank 2
2023-02-22 03:14:37,063 DEBUG TRAIN Batch 14/700 loss 13.309061 loss_att 12.820221 loss_ctc 15.403643 loss_rnnt 13.001763 hw_loss 0.235853 lr 0.00046128 rank 3
2023-02-22 03:15:52,802 DEBUG TRAIN Batch 14/800 loss 15.350157 loss_att 21.633734 loss_ctc 21.577396 loss_rnnt 13.234716 hw_loss 0.053301 lr 0.00046108 rank 4
2023-02-22 03:15:52,805 DEBUG TRAIN Batch 14/800 loss 28.261105 loss_att 28.721863 loss_ctc 33.163353 loss_rnnt 27.429718 hw_loss 0.160504 lr 0.00046111 rank 0
2023-02-22 03:15:52,810 DEBUG TRAIN Batch 14/800 loss 9.744658 loss_att 15.047047 loss_ctc 14.558681 loss_rnnt 7.987446 hw_loss 0.102871 lr 0.00046119 rank 1
2023-02-22 03:15:52,810 DEBUG TRAIN Batch 14/800 loss 19.799179 loss_att 22.843483 loss_ctc 25.989117 loss_rnnt 18.251289 hw_loss 0.213192 lr 0.00046108 rank 5
2023-02-22 03:15:52,811 DEBUG TRAIN Batch 14/800 loss 8.895464 loss_att 15.166221 loss_ctc 14.353107 loss_rnnt 6.843044 hw_loss 0.132341 lr 0.00046109 rank 2
2023-02-22 03:15:52,814 DEBUG TRAIN Batch 14/800 loss 16.871635 loss_att 20.238157 loss_ctc 23.066748 loss_rnnt 15.310759 hw_loss 0.115423 lr 0.00046109 rank 3
2023-02-22 03:15:52,815 DEBUG TRAIN Batch 14/800 loss 14.291666 loss_att 18.874109 loss_ctc 20.934225 loss_rnnt 12.455362 hw_loss 0.064012 lr 0.00046108 rank 7
2023-02-22 03:15:52,816 DEBUG TRAIN Batch 14/800 loss 5.491762 loss_att 8.388620 loss_ctc 5.415111 loss_rnnt 4.855200 hw_loss 0.126395 lr 0.00046116 rank 6
2023-02-22 03:17:08,327 DEBUG TRAIN Batch 14/900 loss 12.671221 loss_att 18.930361 loss_ctc 17.049480 loss_rnnt 10.761534 hw_loss 0.138921 lr 0.00046089 rank 7
2023-02-22 03:17:08,328 DEBUG TRAIN Batch 14/900 loss 14.028987 loss_att 12.255840 loss_ctc 18.255005 loss_rnnt 13.743927 hw_loss 0.142912 lr 0.00046089 rank 4
2023-02-22 03:17:08,332 DEBUG TRAIN Batch 14/900 loss 23.965090 loss_att 24.748980 loss_ctc 28.958931 loss_rnnt 23.133722 hw_loss 0.016395 lr 0.00046091 rank 0
2023-02-22 03:17:08,334 DEBUG TRAIN Batch 14/900 loss 17.982325 loss_att 21.045294 loss_ctc 19.346737 loss_rnnt 17.085417 hw_loss 0.191988 lr 0.00046097 rank 6
2023-02-22 03:17:08,335 DEBUG TRAIN Batch 14/900 loss 21.002052 loss_att 26.133213 loss_ctc 29.257978 loss_rnnt 18.784374 hw_loss 0.169978 lr 0.00046090 rank 2
2023-02-22 03:17:08,335 DEBUG TRAIN Batch 14/900 loss 15.032638 loss_att 17.312378 loss_ctc 22.369514 loss_rnnt 13.517877 hw_loss 0.151053 lr 0.00046088 rank 5
2023-02-22 03:17:08,335 DEBUG TRAIN Batch 14/900 loss 10.627189 loss_att 14.117414 loss_ctc 9.949340 loss_rnnt 9.979652 hw_loss 0.074757 lr 0.00046089 rank 3
2023-02-22 03:17:08,341 DEBUG TRAIN Batch 14/900 loss 9.676268 loss_att 11.564233 loss_ctc 14.914343 loss_rnnt 8.528291 hw_loss 0.134950 lr 0.00046099 rank 1
2023-02-22 03:18:24,730 DEBUG TRAIN Batch 14/1000 loss 17.607988 loss_att 16.347277 loss_ctc 23.348148 loss_rnnt 17.050598 hw_loss 0.082833 lr 0.00046069 rank 7
2023-02-22 03:18:24,732 DEBUG TRAIN Batch 14/1000 loss 10.906260 loss_att 15.402201 loss_ctc 14.338971 loss_rnnt 9.480969 hw_loss 0.128264 lr 0.00046068 rank 5
2023-02-22 03:18:24,732 DEBUG TRAIN Batch 14/1000 loss 14.551530 loss_att 15.972466 loss_ctc 17.495533 loss_rnnt 13.735522 hw_loss 0.261160 lr 0.00046072 rank 0
2023-02-22 03:18:24,734 DEBUG TRAIN Batch 14/1000 loss 9.972777 loss_att 11.791418 loss_ctc 11.669046 loss_rnnt 9.290709 hw_loss 0.172820 lr 0.00046069 rank 4
2023-02-22 03:18:24,736 DEBUG TRAIN Batch 14/1000 loss 15.324918 loss_att 17.266951 loss_ctc 15.880478 loss_rnnt 14.778767 hw_loss 0.156883 lr 0.00046070 rank 2
2023-02-22 03:18:24,736 DEBUG TRAIN Batch 14/1000 loss 19.229286 loss_att 26.599308 loss_ctc 26.450886 loss_rnnt 16.779062 hw_loss 0.025011 lr 0.00046070 rank 3
2023-02-22 03:18:24,740 DEBUG TRAIN Batch 14/1000 loss 11.458148 loss_att 18.301498 loss_ctc 16.730709 loss_rnnt 9.304909 hw_loss 0.152925 lr 0.00046080 rank 1
2023-02-22 03:18:24,742 DEBUG TRAIN Batch 14/1000 loss 11.529132 loss_att 12.145193 loss_ctc 13.042611 loss_rnnt 11.121880 hw_loss 0.154205 lr 0.00046077 rank 6
2023-02-22 03:19:42,863 DEBUG TRAIN Batch 14/1100 loss 14.839087 loss_att 16.607624 loss_ctc 23.343857 loss_rnnt 13.187922 hw_loss 0.306539 lr 0.00046049 rank 4
2023-02-22 03:19:42,864 DEBUG TRAIN Batch 14/1100 loss 11.458038 loss_att 13.414644 loss_ctc 13.417340 loss_rnnt 10.768553 hw_loss 0.069233 lr 0.00046049 rank 5
2023-02-22 03:19:42,869 DEBUG TRAIN Batch 14/1100 loss 7.995697 loss_att 11.593132 loss_ctc 9.503497 loss_rnnt 6.965336 hw_loss 0.205938 lr 0.00046052 rank 0
2023-02-22 03:19:42,869 DEBUG TRAIN Batch 14/1100 loss 9.505868 loss_att 14.836999 loss_ctc 14.778959 loss_rnnt 7.683613 hw_loss 0.099283 lr 0.00046049 rank 7
2023-02-22 03:19:42,872 DEBUG TRAIN Batch 14/1100 loss 12.372145 loss_att 16.123560 loss_ctc 15.860081 loss_rnnt 11.085420 hw_loss 0.133843 lr 0.00046057 rank 6
2023-02-22 03:19:42,872 DEBUG TRAIN Batch 14/1100 loss 13.022607 loss_att 13.746325 loss_ctc 16.707386 loss_rnnt 12.357168 hw_loss 0.055111 lr 0.00046060 rank 1
2023-02-22 03:19:42,872 DEBUG TRAIN Batch 14/1100 loss 11.692139 loss_att 17.165770 loss_ctc 19.043972 loss_rnnt 9.514728 hw_loss 0.192078 lr 0.00046050 rank 3
2023-02-22 03:19:42,912 DEBUG TRAIN Batch 14/1100 loss 13.167832 loss_att 19.186974 loss_ctc 16.803665 loss_rnnt 11.446916 hw_loss 0.060582 lr 0.00046051 rank 2
2023-02-22 03:20:59,518 DEBUG TRAIN Batch 14/1200 loss 8.801115 loss_att 10.911630 loss_ctc 12.137590 loss_rnnt 7.845872 hw_loss 0.165519 lr 0.00046030 rank 7
2023-02-22 03:20:59,520 DEBUG TRAIN Batch 14/1200 loss 16.481358 loss_att 16.759851 loss_ctc 19.072845 loss_rnnt 15.976476 hw_loss 0.194347 lr 0.00046029 rank 5
2023-02-22 03:20:59,523 DEBUG TRAIN Batch 14/1200 loss 7.888258 loss_att 10.699400 loss_ctc 11.078078 loss_rnnt 6.836122 hw_loss 0.121122 lr 0.00046033 rank 0
2023-02-22 03:20:59,524 DEBUG TRAIN Batch 14/1200 loss 15.368791 loss_att 19.086006 loss_ctc 23.729618 loss_rnnt 13.354891 hw_loss 0.291897 lr 0.00046030 rank 3
2023-02-22 03:20:59,524 DEBUG TRAIN Batch 14/1200 loss 21.109341 loss_att 21.309635 loss_ctc 26.874542 loss_rnnt 20.220213 hw_loss 0.150706 lr 0.00046038 rank 6
2023-02-22 03:20:59,526 DEBUG TRAIN Batch 14/1200 loss 8.280140 loss_att 11.134750 loss_ctc 12.157172 loss_rnnt 7.068305 hw_loss 0.232453 lr 0.00046030 rank 4
2023-02-22 03:20:59,531 DEBUG TRAIN Batch 14/1200 loss 11.634351 loss_att 14.071617 loss_ctc 13.391169 loss_rnnt 10.839045 hw_loss 0.138019 lr 0.00046041 rank 1
2023-02-22 03:20:59,571 DEBUG TRAIN Batch 14/1200 loss 12.695976 loss_att 11.747038 loss_ctc 14.208186 loss_rnnt 12.597968 hw_loss 0.161568 lr 0.00046031 rank 2
2023-02-22 03:22:14,226 DEBUG TRAIN Batch 14/1300 loss 10.613739 loss_att 12.963300 loss_ctc 11.210071 loss_rnnt 10.042236 hw_loss 0.041398 lr 0.00046010 rank 4
2023-02-22 03:22:14,230 DEBUG TRAIN Batch 14/1300 loss 10.513481 loss_att 15.154087 loss_ctc 13.203442 loss_rnnt 9.185226 hw_loss 0.077761 lr 0.00046010 rank 5
2023-02-22 03:22:14,231 DEBUG TRAIN Batch 14/1300 loss 6.256021 loss_att 11.168416 loss_ctc 7.072862 loss_rnnt 5.104985 hw_loss 0.111833 lr 0.00046013 rank 0
2023-02-22 03:22:14,234 DEBUG TRAIN Batch 14/1300 loss 23.593952 loss_att 23.777489 loss_ctc 27.696514 loss_rnnt 22.816696 hw_loss 0.362888 lr 0.00046011 rank 3
2023-02-22 03:22:14,236 DEBUG TRAIN Batch 14/1300 loss 24.863024 loss_att 29.663431 loss_ctc 33.097572 loss_rnnt 22.729988 hw_loss 0.140652 lr 0.00046010 rank 7
2023-02-22 03:22:14,238 DEBUG TRAIN Batch 14/1300 loss 9.330980 loss_att 11.194032 loss_ctc 10.275066 loss_rnnt 8.767173 hw_loss 0.122473 lr 0.00046012 rank 2
2023-02-22 03:22:14,242 DEBUG TRAIN Batch 14/1300 loss 12.279833 loss_att 14.881804 loss_ctc 15.144699 loss_rnnt 11.261873 hw_loss 0.216717 lr 0.00046021 rank 1
2023-02-22 03:22:14,283 DEBUG TRAIN Batch 14/1300 loss 6.372807 loss_att 9.055793 loss_ctc 7.332480 loss_rnnt 5.613935 hw_loss 0.176844 lr 0.00046018 rank 6
2023-02-22 03:23:32,359 DEBUG TRAIN Batch 14/1400 loss 16.597651 loss_att 20.162903 loss_ctc 20.776285 loss_rnnt 15.169127 hw_loss 0.296853 lr 0.00045991 rank 4
2023-02-22 03:23:32,359 DEBUG TRAIN Batch 14/1400 loss 11.404108 loss_att 14.083036 loss_ctc 13.032485 loss_rnnt 10.545276 hw_loss 0.198621 lr 0.00045990 rank 5
2023-02-22 03:23:32,361 DEBUG TRAIN Batch 14/1400 loss 6.753709 loss_att 10.587445 loss_ctc 7.212968 loss_rnnt 5.898605 hw_loss 0.050855 lr 0.00046002 rank 1
2023-02-22 03:23:32,365 DEBUG TRAIN Batch 14/1400 loss 12.963593 loss_att 15.248323 loss_ctc 13.750130 loss_rnnt 12.305236 hw_loss 0.181012 lr 0.00045991 rank 7
2023-02-22 03:23:32,367 DEBUG TRAIN Batch 14/1400 loss 9.621919 loss_att 15.043459 loss_ctc 12.227480 loss_rnnt 8.176569 hw_loss 0.025560 lr 0.00045994 rank 0
2023-02-22 03:23:32,372 DEBUG TRAIN Batch 14/1400 loss 4.993272 loss_att 11.462214 loss_ctc 7.388803 loss_rnnt 3.293236 hw_loss 0.162831 lr 0.00045992 rank 2
2023-02-22 03:23:32,392 DEBUG TRAIN Batch 14/1400 loss 9.692655 loss_att 13.356901 loss_ctc 10.964736 loss_rnnt 8.739174 hw_loss 0.095663 lr 0.00045999 rank 6
2023-02-22 03:23:32,419 DEBUG TRAIN Batch 14/1400 loss 5.300074 loss_att 11.025582 loss_ctc 5.942206 loss_rnnt 4.006751 hw_loss 0.117380 lr 0.00045992 rank 3
2023-02-22 03:24:53,889 DEBUG TRAIN Batch 14/1500 loss 18.395384 loss_att 25.638256 loss_ctc 24.787979 loss_rnnt 16.007698 hw_loss 0.162682 lr 0.00045974 rank 0
2023-02-22 03:24:53,889 DEBUG TRAIN Batch 14/1500 loss 19.634563 loss_att 24.365536 loss_ctc 22.238060 loss_rnnt 18.268255 hw_loss 0.136840 lr 0.00045971 rank 7
2023-02-22 03:24:53,897 DEBUG TRAIN Batch 14/1500 loss 10.770777 loss_att 12.178660 loss_ctc 14.733079 loss_rnnt 9.914861 hw_loss 0.086310 lr 0.00045971 rank 5
2023-02-22 03:24:53,897 DEBUG TRAIN Batch 14/1500 loss 23.067822 loss_att 26.413473 loss_ctc 30.215084 loss_rnnt 21.402029 hw_loss 0.081924 lr 0.00045979 rank 6
2023-02-22 03:24:53,897 DEBUG TRAIN Batch 14/1500 loss 9.440791 loss_att 11.326038 loss_ctc 12.815126 loss_rnnt 8.570496 hw_loss 0.081254 lr 0.00045982 rank 1
2023-02-22 03:24:53,898 DEBUG TRAIN Batch 14/1500 loss 8.199921 loss_att 9.961117 loss_ctc 10.961994 loss_rnnt 7.411337 hw_loss 0.127628 lr 0.00045971 rank 4
2023-02-22 03:24:53,899 DEBUG TRAIN Batch 14/1500 loss 12.541886 loss_att 14.851586 loss_ctc 13.706129 loss_rnnt 11.880215 hw_loss 0.083433 lr 0.00045973 rank 2
2023-02-22 03:24:53,902 DEBUG TRAIN Batch 14/1500 loss 3.975717 loss_att 9.098682 loss_ctc 5.904231 loss_rnnt 2.662690 hw_loss 0.058685 lr 0.00045972 rank 3
2023-02-22 03:26:08,716 DEBUG TRAIN Batch 14/1600 loss 7.798629 loss_att 11.578711 loss_ctc 9.210745 loss_rnnt 6.757707 hw_loss 0.181171 lr 0.00045955 rank 0
2023-02-22 03:26:08,716 DEBUG TRAIN Batch 14/1600 loss 21.054344 loss_att 25.561142 loss_ctc 29.146210 loss_rnnt 19.000282 hw_loss 0.138352 lr 0.00045952 rank 7
2023-02-22 03:26:08,719 DEBUG TRAIN Batch 14/1600 loss 10.836320 loss_att 16.199472 loss_ctc 15.410739 loss_rnnt 9.058061 hw_loss 0.179449 lr 0.00045952 rank 4
2023-02-22 03:26:08,720 DEBUG TRAIN Batch 14/1600 loss 10.934642 loss_att 16.339226 loss_ctc 15.116074 loss_rnnt 9.254538 hw_loss 0.078118 lr 0.00045960 rank 6
2023-02-22 03:26:08,723 DEBUG TRAIN Batch 14/1600 loss 14.384140 loss_att 16.249100 loss_ctc 20.271276 loss_rnnt 13.186562 hw_loss 0.074315 lr 0.00045951 rank 5
2023-02-22 03:26:08,724 DEBUG TRAIN Batch 14/1600 loss 13.162638 loss_att 16.663330 loss_ctc 14.019753 loss_rnnt 12.216988 hw_loss 0.246054 lr 0.00045953 rank 3
2023-02-22 03:26:08,725 DEBUG TRAIN Batch 14/1600 loss 7.926981 loss_att 11.123584 loss_ctc 12.208591 loss_rnnt 6.630595 hw_loss 0.161596 lr 0.00045963 rank 1
2023-02-22 03:26:08,730 DEBUG TRAIN Batch 14/1600 loss 10.356237 loss_att 12.304304 loss_ctc 13.774349 loss_rnnt 9.459330 hw_loss 0.096647 lr 0.00045953 rank 2
2023-02-22 03:27:24,899 DEBUG TRAIN Batch 14/1700 loss 19.016954 loss_att 18.580305 loss_ctc 20.613335 loss_rnnt 18.839367 hw_loss 0.097624 lr 0.00045933 rank 4
2023-02-22 03:27:24,903 DEBUG TRAIN Batch 14/1700 loss 11.125633 loss_att 15.080860 loss_ctc 14.464254 loss_rnnt 9.743955 hw_loss 0.272782 lr 0.00045936 rank 0
2023-02-22 03:27:24,903 DEBUG TRAIN Batch 14/1700 loss 26.057310 loss_att 29.536043 loss_ctc 35.205715 loss_rnnt 24.084789 hw_loss 0.106855 lr 0.00045932 rank 5
2023-02-22 03:27:24,904 DEBUG TRAIN Batch 14/1700 loss 14.470061 loss_att 12.934192 loss_ctc 19.000614 loss_rnnt 14.115664 hw_loss 0.107805 lr 0.00045933 rank 7
2023-02-22 03:27:24,905 DEBUG TRAIN Batch 14/1700 loss 7.375163 loss_att 11.385921 loss_ctc 11.587180 loss_rnnt 5.982768 hw_loss 0.053702 lr 0.00045934 rank 2
2023-02-22 03:27:24,906 DEBUG TRAIN Batch 14/1700 loss 19.230976 loss_att 19.834969 loss_ctc 22.497448 loss_rnnt 18.597599 hw_loss 0.144461 lr 0.00045941 rank 6
2023-02-22 03:27:24,906 DEBUG TRAIN Batch 14/1700 loss 6.137842 loss_att 12.819324 loss_ctc 6.533262 loss_rnnt 4.653499 hw_loss 0.178732 lr 0.00045933 rank 3
2023-02-22 03:27:24,909 DEBUG TRAIN Batch 14/1700 loss 7.694306 loss_att 12.237429 loss_ctc 8.005440 loss_rnnt 6.680119 hw_loss 0.120148 lr 0.00045944 rank 1
2023-02-22 03:28:47,266 DEBUG TRAIN Batch 14/1800 loss 11.168179 loss_att 14.737302 loss_ctc 15.058603 loss_rnnt 9.839945 hw_loss 0.179411 lr 0.00045916 rank 0
2023-02-22 03:28:47,271 DEBUG TRAIN Batch 14/1800 loss 10.386683 loss_att 14.217622 loss_ctc 13.794868 loss_rnnt 9.073785 hw_loss 0.173031 lr 0.00045913 rank 5
2023-02-22 03:28:47,274 DEBUG TRAIN Batch 14/1800 loss 3.958266 loss_att 6.425216 loss_ctc 7.076396 loss_rnnt 2.975581 hw_loss 0.137895 lr 0.00045913 rank 4
2023-02-22 03:28:47,276 DEBUG TRAIN Batch 14/1800 loss 14.190179 loss_att 14.737558 loss_ctc 19.964947 loss_rnnt 13.224507 hw_loss 0.161675 lr 0.00045924 rank 1
2023-02-22 03:28:47,276 DEBUG TRAIN Batch 14/1800 loss 2.694432 loss_att 5.836802 loss_ctc 2.535532 loss_rnnt 2.007487 hw_loss 0.149358 lr 0.00045914 rank 3
2023-02-22 03:28:47,277 DEBUG TRAIN Batch 14/1800 loss 7.971255 loss_att 9.843845 loss_ctc 11.317801 loss_rnnt 7.039994 hw_loss 0.207256 lr 0.00045913 rank 7
2023-02-22 03:28:47,280 DEBUG TRAIN Batch 14/1800 loss 8.360283 loss_att 10.889925 loss_ctc 11.838438 loss_rnnt 7.344967 hw_loss 0.085565 lr 0.00045921 rank 6
2023-02-22 03:28:47,323 DEBUG TRAIN Batch 14/1800 loss 9.399230 loss_att 9.146648 loss_ctc 10.770849 loss_rnnt 9.177088 hw_loss 0.168330 lr 0.00045914 rank 2
2023-02-22 03:30:02,788 DEBUG TRAIN Batch 14/1900 loss 29.443794 loss_att 30.211010 loss_ctc 35.285713 loss_rnnt 28.430168 hw_loss 0.152357 lr 0.00045894 rank 7
2023-02-22 03:30:02,791 DEBUG TRAIN Batch 14/1900 loss 17.753716 loss_att 19.555508 loss_ctc 20.505323 loss_rnnt 16.950621 hw_loss 0.142231 lr 0.00045895 rank 3
2023-02-22 03:30:02,793 DEBUG TRAIN Batch 14/1900 loss 12.912171 loss_att 12.718627 loss_ctc 15.548575 loss_rnnt 12.498226 hw_loss 0.189627 lr 0.00045893 rank 5
2023-02-22 03:30:02,793 DEBUG TRAIN Batch 14/1900 loss 10.491687 loss_att 14.228269 loss_ctc 12.547132 loss_rnnt 9.430099 hw_loss 0.075400 lr 0.00045894 rank 4
2023-02-22 03:30:02,794 DEBUG TRAIN Batch 14/1900 loss 14.140850 loss_att 14.282025 loss_ctc 18.359354 loss_rnnt 13.384345 hw_loss 0.310880 lr 0.00045897 rank 0
2023-02-22 03:30:02,795 DEBUG TRAIN Batch 14/1900 loss 8.139244 loss_att 14.510931 loss_ctc 8.526320 loss_rnnt 6.686353 hw_loss 0.238017 lr 0.00045905 rank 1
2023-02-22 03:30:02,795 DEBUG TRAIN Batch 14/1900 loss 13.990597 loss_att 19.844223 loss_ctc 18.241528 loss_rnnt 12.188602 hw_loss 0.120896 lr 0.00045895 rank 2
2023-02-22 03:30:02,802 DEBUG TRAIN Batch 14/1900 loss 21.798035 loss_att 25.616215 loss_ctc 23.265364 loss_rnnt 20.759447 hw_loss 0.148701 lr 0.00045902 rank 6
2023-02-22 03:31:18,467 DEBUG TRAIN Batch 14/2000 loss 6.502129 loss_att 9.182177 loss_ctc 7.806418 loss_rnnt 5.736224 hw_loss 0.104980 lr 0.00045885 rank 1
2023-02-22 03:31:18,470 DEBUG TRAIN Batch 14/2000 loss 9.716459 loss_att 11.660597 loss_ctc 11.673270 loss_rnnt 8.965643 hw_loss 0.189527 lr 0.00045875 rank 4
2023-02-22 03:31:18,471 DEBUG TRAIN Batch 14/2000 loss 14.958005 loss_att 20.488331 loss_ctc 17.670067 loss_rnnt 13.415260 hw_loss 0.140759 lr 0.00045874 rank 5
2023-02-22 03:31:18,471 DEBUG TRAIN Batch 14/2000 loss 20.657896 loss_att 27.550919 loss_ctc 30.272606 loss_rnnt 17.978247 hw_loss 0.035787 lr 0.00045878 rank 0
2023-02-22 03:31:18,474 DEBUG TRAIN Batch 14/2000 loss 19.333380 loss_att 21.427128 loss_ctc 27.880089 loss_rnnt 17.628197 hw_loss 0.275382 lr 0.00045883 rank 6
2023-02-22 03:31:18,474 DEBUG TRAIN Batch 14/2000 loss 9.213974 loss_att 9.272804 loss_ctc 10.562477 loss_rnnt 8.921540 hw_loss 0.189126 lr 0.00045875 rank 3
2023-02-22 03:31:18,474 DEBUG TRAIN Batch 14/2000 loss 7.054829 loss_att 13.347117 loss_ctc 9.670622 loss_rnnt 5.422396 hw_loss 0.047254 lr 0.00045875 rank 7
2023-02-22 03:31:18,525 DEBUG TRAIN Batch 14/2000 loss 1.974237 loss_att 3.828341 loss_ctc 2.355906 loss_rnnt 1.446372 hw_loss 0.199040 lr 0.00045876 rank 2
2023-02-22 03:32:36,596 DEBUG TRAIN Batch 14/2100 loss 18.499954 loss_att 20.248220 loss_ctc 18.142607 loss_rnnt 18.113167 hw_loss 0.158962 lr 0.00045855 rank 5
2023-02-22 03:32:36,600 DEBUG TRAIN Batch 14/2100 loss 10.435848 loss_att 14.591822 loss_ctc 15.608652 loss_rnnt 8.851920 hw_loss 0.118174 lr 0.00045855 rank 7
2023-02-22 03:32:36,601 DEBUG TRAIN Batch 14/2100 loss 11.411052 loss_att 15.312348 loss_ctc 15.902395 loss_rnnt 9.960897 hw_loss 0.133217 lr 0.00045866 rank 1
2023-02-22 03:32:36,602 DEBUG TRAIN Batch 14/2100 loss 8.191960 loss_att 12.284714 loss_ctc 12.432291 loss_rnnt 6.735371 hw_loss 0.136241 lr 0.00045858 rank 0
2023-02-22 03:32:36,605 DEBUG TRAIN Batch 14/2100 loss 11.437454 loss_att 13.791372 loss_ctc 13.092097 loss_rnnt 10.688231 hw_loss 0.108413 lr 0.00045856 rank 3
2023-02-22 03:32:36,607 DEBUG TRAIN Batch 14/2100 loss 7.059059 loss_att 11.297425 loss_ctc 9.340122 loss_rnnt 5.860119 hw_loss 0.088360 lr 0.00045855 rank 4
2023-02-22 03:32:36,610 DEBUG TRAIN Batch 14/2100 loss 7.551447 loss_att 13.570622 loss_ctc 14.091879 loss_rnnt 5.388407 hw_loss 0.163403 lr 0.00045863 rank 6
2023-02-22 03:32:36,652 DEBUG TRAIN Batch 14/2100 loss 11.634961 loss_att 13.538729 loss_ctc 17.469772 loss_rnnt 10.444493 hw_loss 0.059511 lr 0.00045857 rank 2
2023-02-22 03:33:59,689 DEBUG TRAIN Batch 14/2200 loss 8.572718 loss_att 10.438393 loss_ctc 10.489961 loss_rnnt 7.842664 hw_loss 0.189913 lr 0.00045836 rank 7
2023-02-22 03:33:59,690 DEBUG TRAIN Batch 14/2200 loss 14.274906 loss_att 14.691825 loss_ctc 20.049400 loss_rnnt 13.345818 hw_loss 0.142074 lr 0.00045836 rank 5
2023-02-22 03:33:59,693 DEBUG TRAIN Batch 14/2200 loss 13.152113 loss_att 14.438580 loss_ctc 17.412418 loss_rnnt 12.243753 hw_loss 0.155674 lr 0.00045839 rank 0
2023-02-22 03:33:59,693 DEBUG TRAIN Batch 14/2200 loss 10.888534 loss_att 14.534051 loss_ctc 13.895175 loss_rnnt 9.710785 hw_loss 0.089547 lr 0.00045836 rank 4
2023-02-22 03:33:59,695 DEBUG TRAIN Batch 14/2200 loss 6.419847 loss_att 8.788900 loss_ctc 9.154926 loss_rnnt 5.488788 hw_loss 0.173573 lr 0.00045837 rank 3
2023-02-22 03:33:59,696 DEBUG TRAIN Batch 14/2200 loss 17.673357 loss_att 23.759504 loss_ctc 23.450241 loss_rnnt 15.617680 hw_loss 0.127871 lr 0.00045847 rank 1
2023-02-22 03:33:59,698 DEBUG TRAIN Batch 14/2200 loss 2.220811 loss_att 5.704798 loss_ctc 2.376505 loss_rnnt 1.496538 hw_loss 0.012593 lr 0.00045844 rank 6
2023-02-22 03:33:59,699 DEBUG TRAIN Batch 14/2200 loss 10.487273 loss_att 12.517505 loss_ctc 12.980052 loss_rnnt 9.669464 hw_loss 0.148861 lr 0.00045837 rank 2
2023-02-22 03:35:15,543 DEBUG TRAIN Batch 14/2300 loss 11.887566 loss_att 15.542933 loss_ctc 16.399763 loss_rnnt 10.511106 hw_loss 0.082048 lr 0.00045817 rank 4
2023-02-22 03:35:15,544 DEBUG TRAIN Batch 14/2300 loss 12.834066 loss_att 15.781384 loss_ctc 19.037079 loss_rnnt 11.358840 hw_loss 0.110053 lr 0.00045820 rank 0
2023-02-22 03:35:15,544 DEBUG TRAIN Batch 14/2300 loss 10.552562 loss_att 15.057047 loss_ctc 14.643675 loss_rnnt 9.055381 hw_loss 0.095253 lr 0.00045828 rank 1
2023-02-22 03:35:15,544 DEBUG TRAIN Batch 14/2300 loss 10.750500 loss_att 11.997778 loss_ctc 11.756834 loss_rnnt 10.314024 hw_loss 0.099079 lr 0.00045816 rank 5
2023-02-22 03:35:15,544 DEBUG TRAIN Batch 14/2300 loss 11.130056 loss_att 12.870661 loss_ctc 15.201626 loss_rnnt 10.203310 hw_loss 0.067029 lr 0.00045825 rank 6
2023-02-22 03:35:15,546 DEBUG TRAIN Batch 14/2300 loss 10.586517 loss_att 12.831394 loss_ctc 12.978837 loss_rnnt 9.725480 hw_loss 0.174535 lr 0.00045817 rank 7
2023-02-22 03:35:15,554 DEBUG TRAIN Batch 14/2300 loss 10.433708 loss_att 13.749416 loss_ctc 14.093786 loss_rnnt 9.158161 hw_loss 0.233240 lr 0.00045818 rank 2
2023-02-22 03:35:15,594 DEBUG TRAIN Batch 14/2300 loss 7.008373 loss_att 11.176529 loss_ctc 11.087603 loss_rnnt 5.546041 hw_loss 0.159006 lr 0.00045817 rank 3
2023-02-22 03:36:30,639 DEBUG TRAIN Batch 14/2400 loss 21.149532 loss_att 28.199398 loss_ctc 27.629028 loss_rnnt 18.850582 hw_loss 0.046959 lr 0.00045798 rank 7
2023-02-22 03:36:30,641 DEBUG TRAIN Batch 14/2400 loss 14.472898 loss_att 14.473367 loss_ctc 18.425886 loss_rnnt 13.862088 hw_loss 0.156846 lr 0.00045798 rank 4
2023-02-22 03:36:30,645 DEBUG TRAIN Batch 14/2400 loss 9.940752 loss_att 12.776084 loss_ctc 12.735067 loss_rnnt 8.931762 hw_loss 0.130029 lr 0.00045797 rank 5
2023-02-22 03:36:30,648 DEBUG TRAIN Batch 14/2400 loss 15.998257 loss_att 16.622831 loss_ctc 20.662792 loss_rnnt 15.206985 hw_loss 0.083284 lr 0.00045800 rank 0
2023-02-22 03:36:30,648 DEBUG TRAIN Batch 14/2400 loss 10.011407 loss_att 16.777134 loss_ctc 13.071910 loss_rnnt 8.192659 hw_loss 0.107878 lr 0.00045798 rank 3
2023-02-22 03:36:30,649 DEBUG TRAIN Batch 14/2400 loss 13.226287 loss_att 14.727767 loss_ctc 15.093281 loss_rnnt 12.652826 hw_loss 0.045435 lr 0.00045808 rank 1
2023-02-22 03:36:30,651 DEBUG TRAIN Batch 14/2400 loss 7.235913 loss_att 8.950712 loss_ctc 9.109721 loss_rnnt 6.518672 hw_loss 0.233324 lr 0.00045805 rank 6
2023-02-22 03:36:30,694 DEBUG TRAIN Batch 14/2400 loss 11.274528 loss_att 12.589032 loss_ctc 16.980846 loss_rnnt 10.145734 hw_loss 0.196967 lr 0.00045799 rank 2
2023-02-22 03:37:48,493 DEBUG TRAIN Batch 14/2500 loss 15.224847 loss_att 18.622988 loss_ctc 17.675545 loss_rnnt 14.136195 hw_loss 0.154244 lr 0.00045778 rank 7
2023-02-22 03:37:48,493 DEBUG TRAIN Batch 14/2500 loss 15.750556 loss_att 16.761971 loss_ctc 18.426525 loss_rnnt 15.027480 hw_loss 0.307496 lr 0.00045781 rank 0
2023-02-22 03:37:48,497 DEBUG TRAIN Batch 14/2500 loss 11.456902 loss_att 15.144552 loss_ctc 13.294642 loss_rnnt 10.465630 hw_loss 0.016331 lr 0.00045780 rank 2
2023-02-22 03:37:48,496 DEBUG TRAIN Batch 14/2500 loss 15.777767 loss_att 14.323154 loss_ctc 19.088367 loss_rnnt 15.534358 hw_loss 0.174221 lr 0.00045778 rank 5
2023-02-22 03:37:48,497 DEBUG TRAIN Batch 14/2500 loss 16.659773 loss_att 17.609013 loss_ctc 19.527269 loss_rnnt 16.027161 hw_loss 0.113306 lr 0.00045779 rank 3
2023-02-22 03:37:48,498 DEBUG TRAIN Batch 14/2500 loss 16.552992 loss_att 15.986223 loss_ctc 21.188089 loss_rnnt 15.948675 hw_loss 0.186859 lr 0.00045786 rank 6
2023-02-22 03:37:48,501 DEBUG TRAIN Batch 14/2500 loss 12.605067 loss_att 12.890374 loss_ctc 14.977887 loss_rnnt 12.099178 hw_loss 0.248347 lr 0.00045778 rank 4
2023-02-22 03:37:48,505 DEBUG TRAIN Batch 14/2500 loss 10.845882 loss_att 11.594515 loss_ctc 14.669355 loss_rnnt 10.143311 hw_loss 0.080717 lr 0.00045789 rank 1
2023-02-22 03:39:03,739 DEBUG TRAIN Batch 14/2600 loss 6.084597 loss_att 8.553020 loss_ctc 8.054989 loss_rnnt 5.280589 hw_loss 0.089257 lr 0.00045759 rank 4
2023-02-22 03:39:03,741 DEBUG TRAIN Batch 14/2600 loss 9.265911 loss_att 11.918628 loss_ctc 10.624529 loss_rnnt 8.522086 hw_loss 0.060248 lr 0.00045759 rank 5
2023-02-22 03:39:03,741 DEBUG TRAIN Batch 14/2600 loss 18.822515 loss_att 25.176332 loss_ctc 32.487286 loss_rnnt 15.657820 hw_loss 0.134932 lr 0.00045759 rank 7
2023-02-22 03:39:03,742 DEBUG TRAIN Batch 14/2600 loss 8.750923 loss_att 8.947962 loss_ctc 17.772419 loss_rnnt 7.443396 hw_loss 0.122350 lr 0.00045767 rank 6
2023-02-22 03:39:03,742 DEBUG TRAIN Batch 14/2600 loss 16.497341 loss_att 23.027073 loss_ctc 18.271772 loss_rnnt 14.900930 hw_loss 0.101015 lr 0.00045760 rank 2
2023-02-22 03:39:03,743 DEBUG TRAIN Batch 14/2600 loss 21.704712 loss_att 23.002499 loss_ctc 26.007721 loss_rnnt 20.829996 hw_loss 0.077665 lr 0.00045770 rank 1
2023-02-22 03:39:03,743 DEBUG TRAIN Batch 14/2600 loss 11.448217 loss_att 15.829144 loss_ctc 10.972617 loss_rnnt 10.563126 hw_loss 0.135600 lr 0.00045762 rank 0
2023-02-22 03:39:03,788 DEBUG TRAIN Batch 14/2600 loss 6.728836 loss_att 8.111932 loss_ctc 8.742730 loss_rnnt 6.096435 hw_loss 0.163620 lr 0.00045760 rank 3
2023-02-22 03:40:18,699 DEBUG TRAIN Batch 14/2700 loss 6.361952 loss_att 8.617265 loss_ctc 6.059463 loss_rnnt 5.851387 hw_loss 0.187190 lr 0.00045740 rank 4
2023-02-22 03:40:18,702 DEBUG TRAIN Batch 14/2700 loss 19.103251 loss_att 24.266693 loss_ctc 28.684561 loss_rnnt 16.751518 hw_loss 0.077881 lr 0.00045748 rank 6
2023-02-22 03:40:18,703 DEBUG TRAIN Batch 14/2700 loss 10.049027 loss_att 14.251184 loss_ctc 14.422657 loss_rnnt 8.614463 hw_loss 0.020592 lr 0.00045740 rank 7
2023-02-22 03:40:18,705 DEBUG TRAIN Batch 14/2700 loss 12.444510 loss_att 14.105777 loss_ctc 16.411495 loss_rnnt 11.490696 hw_loss 0.173679 lr 0.00045743 rank 0
2023-02-22 03:40:18,706 DEBUG TRAIN Batch 14/2700 loss 9.965718 loss_att 12.128057 loss_ctc 16.905684 loss_rnnt 8.549245 hw_loss 0.110019 lr 0.00045740 rank 5
2023-02-22 03:40:18,707 DEBUG TRAIN Batch 14/2700 loss 24.968510 loss_att 27.390217 loss_ctc 34.868938 loss_rnnt 23.090025 hw_loss 0.138910 lr 0.00045741 rank 2
2023-02-22 03:40:18,717 DEBUG TRAIN Batch 14/2700 loss 12.262156 loss_att 21.547853 loss_ctc 18.123617 loss_rnnt 9.507998 hw_loss 0.216546 lr 0.00045741 rank 3
2023-02-22 03:40:18,750 DEBUG TRAIN Batch 14/2700 loss 12.722125 loss_att 15.363455 loss_ctc 15.768317 loss_rnnt 11.724915 hw_loss 0.117724 lr 0.00045751 rank 1
2023-02-22 03:41:36,054 DEBUG TRAIN Batch 14/2800 loss 6.714024 loss_att 12.825621 loss_ctc 8.059351 loss_rnnt 5.261247 hw_loss 0.095777 lr 0.00045724 rank 0
2023-02-22 03:41:36,056 DEBUG TRAIN Batch 14/2800 loss 17.483637 loss_att 22.289982 loss_ctc 25.479599 loss_rnnt 15.424476 hw_loss 0.059559 lr 0.00045721 rank 7
2023-02-22 03:41:36,061 DEBUG TRAIN Batch 14/2800 loss 9.852326 loss_att 13.180399 loss_ctc 13.385397 loss_rnnt 8.614594 hw_loss 0.189454 lr 0.00045732 rank 1
2023-02-22 03:41:36,062 DEBUG TRAIN Batch 14/2800 loss 8.409563 loss_att 10.563886 loss_ctc 12.023589 loss_rnnt 7.434640 hw_loss 0.116601 lr 0.00045729 rank 6
2023-02-22 03:41:36,063 DEBUG TRAIN Batch 14/2800 loss 31.155024 loss_att 32.171921 loss_ctc 44.934898 loss_rnnt 29.046234 hw_loss 0.127674 lr 0.00045720 rank 5
2023-02-22 03:41:36,063 DEBUG TRAIN Batch 14/2800 loss 9.518731 loss_att 13.170847 loss_ctc 13.724099 loss_rnnt 8.147618 hw_loss 0.149950 lr 0.00045721 rank 4
2023-02-22 03:41:36,069 DEBUG TRAIN Batch 14/2800 loss 16.611814 loss_att 23.799990 loss_ctc 19.620127 loss_rnnt 14.704180 hw_loss 0.129169 lr 0.00045722 rank 2
2023-02-22 03:41:36,073 DEBUG TRAIN Batch 14/2800 loss 12.672433 loss_att 16.750753 loss_ctc 15.397479 loss_rnnt 11.432747 hw_loss 0.113779 lr 0.00045722 rank 3
2023-02-22 03:42:52,034 DEBUG TRAIN Batch 14/2900 loss 15.422729 loss_att 18.343557 loss_ctc 19.130543 loss_rnnt 14.329404 hw_loss 0.027721 lr 0.00045702 rank 4
2023-02-22 03:42:52,035 DEBUG TRAIN Batch 14/2900 loss 14.915621 loss_att 16.803295 loss_ctc 15.427174 loss_rnnt 14.398251 hw_loss 0.134304 lr 0.00045701 rank 5
2023-02-22 03:42:52,035 DEBUG TRAIN Batch 14/2900 loss 9.382206 loss_att 12.985044 loss_ctc 14.246060 loss_rnnt 7.980333 hw_loss 0.061483 lr 0.00045713 rank 1
2023-02-22 03:42:52,039 DEBUG TRAIN Batch 14/2900 loss 8.238764 loss_att 14.480736 loss_ctc 13.790031 loss_rnnt 6.150210 hw_loss 0.187484 lr 0.00045705 rank 0
2023-02-22 03:42:52,042 DEBUG TRAIN Batch 14/2900 loss 17.614700 loss_att 24.313755 loss_ctc 24.600086 loss_rnnt 15.292639 hw_loss 0.095373 lr 0.00045702 rank 3
2023-02-22 03:42:52,042 DEBUG TRAIN Batch 14/2900 loss 22.486301 loss_att 26.685749 loss_ctc 29.479364 loss_rnnt 20.622879 hw_loss 0.170857 lr 0.00045702 rank 7
2023-02-22 03:42:52,043 DEBUG TRAIN Batch 14/2900 loss 11.329758 loss_att 12.492207 loss_ctc 16.132689 loss_rnnt 10.329966 hw_loss 0.237960 lr 0.00045710 rank 6
2023-02-22 03:42:52,086 DEBUG TRAIN Batch 14/2900 loss 22.543356 loss_att 25.407593 loss_ctc 25.478573 loss_rnnt 21.543091 hw_loss 0.067601 lr 0.00045703 rank 2
2023-02-22 03:44:08,436 DEBUG TRAIN Batch 14/3000 loss 6.037882 loss_att 10.085979 loss_ctc 10.173996 loss_rnnt 4.615615 hw_loss 0.114685 lr 0.00045683 rank 4
2023-02-22 03:44:08,437 DEBUG TRAIN Batch 14/3000 loss 17.786980 loss_att 21.882435 loss_ctc 23.961319 loss_rnnt 16.077908 hw_loss 0.125126 lr 0.00045683 rank 3
2023-02-22 03:44:08,438 DEBUG TRAIN Batch 14/3000 loss 11.413336 loss_att 15.931170 loss_ctc 10.437942 loss_rnnt 10.572038 hw_loss 0.127096 lr 0.00045686 rank 0
2023-02-22 03:44:08,440 DEBUG TRAIN Batch 14/3000 loss 20.108582 loss_att 23.868830 loss_ctc 27.056435 loss_rnnt 18.325623 hw_loss 0.195992 lr 0.00045693 rank 1
2023-02-22 03:44:08,440 DEBUG TRAIN Batch 14/3000 loss 7.600817 loss_att 10.216516 loss_ctc 10.725176 loss_rnnt 6.532718 hw_loss 0.240708 lr 0.00045683 rank 7
2023-02-22 03:44:08,441 DEBUG TRAIN Batch 14/3000 loss 19.058023 loss_att 20.989317 loss_ctc 25.470221 loss_rnnt 17.743145 hw_loss 0.138109 lr 0.00045682 rank 5
2023-02-22 03:44:08,443 DEBUG TRAIN Batch 14/3000 loss 10.649908 loss_att 12.578659 loss_ctc 11.795162 loss_rnnt 9.952892 hw_loss 0.297310 lr 0.00045691 rank 6
2023-02-22 03:44:08,491 DEBUG TRAIN Batch 14/3000 loss 11.839673 loss_att 14.707470 loss_ctc 11.170510 loss_rnnt 11.347410 hw_loss 0.014861 lr 0.00045684 rank 2
2023-02-22 03:45:23,749 DEBUG TRAIN Batch 14/3100 loss 19.309780 loss_att 23.651800 loss_ctc 26.544502 loss_rnnt 17.406174 hw_loss 0.132321 lr 0.00045672 rank 6
2023-02-22 03:45:23,751 DEBUG TRAIN Batch 14/3100 loss 23.064560 loss_att 23.023355 loss_ctc 30.236542 loss_rnnt 22.013962 hw_loss 0.192329 lr 0.00045664 rank 7
2023-02-22 03:45:23,753 DEBUG TRAIN Batch 14/3100 loss 7.205642 loss_att 11.182514 loss_ctc 10.634003 loss_rnnt 5.872041 hw_loss 0.152083 lr 0.00045665 rank 2
2023-02-22 03:45:23,754 DEBUG TRAIN Batch 14/3100 loss 9.839231 loss_att 9.387703 loss_ctc 13.335245 loss_rnnt 9.391779 hw_loss 0.134292 lr 0.00045667 rank 0
2023-02-22 03:45:23,754 DEBUG TRAIN Batch 14/3100 loss 11.090644 loss_att 12.222525 loss_ctc 14.841603 loss_rnnt 10.270857 hw_loss 0.174906 lr 0.00045664 rank 3
2023-02-22 03:45:23,756 DEBUG TRAIN Batch 14/3100 loss 18.510962 loss_att 19.853682 loss_ctc 22.128826 loss_rnnt 17.724298 hw_loss 0.067005 lr 0.00045663 rank 5
2023-02-22 03:45:23,758 DEBUG TRAIN Batch 14/3100 loss 13.473406 loss_att 15.858177 loss_ctc 14.541059 loss_rnnt 12.779323 hw_loss 0.140206 lr 0.00045664 rank 4
2023-02-22 03:45:23,802 DEBUG TRAIN Batch 14/3100 loss 15.015248 loss_att 16.388277 loss_ctc 16.942999 loss_rnnt 14.411280 hw_loss 0.135616 lr 0.00045674 rank 1
2023-02-22 03:46:43,464 DEBUG TRAIN Batch 14/3200 loss 7.933625 loss_att 11.018785 loss_ctc 11.413370 loss_rnnt 6.812828 hw_loss 0.074624 lr 0.00045645 rank 4
2023-02-22 03:46:43,464 DEBUG TRAIN Batch 14/3200 loss 5.599261 loss_att 9.760864 loss_ctc 8.349764 loss_rnnt 4.315769 hw_loss 0.158322 lr 0.00045648 rank 0
2023-02-22 03:46:43,465 DEBUG TRAIN Batch 14/3200 loss 6.295285 loss_att 7.591946 loss_ctc 10.185199 loss_rnnt 5.494268 hw_loss 0.043181 lr 0.00045645 rank 3
2023-02-22 03:46:43,469 DEBUG TRAIN Batch 14/3200 loss 9.267570 loss_att 8.739075 loss_ctc 10.828002 loss_rnnt 9.054179 hw_loss 0.208185 lr 0.00045655 rank 1
2023-02-22 03:46:43,469 DEBUG TRAIN Batch 14/3200 loss 11.347341 loss_att 13.955221 loss_ctc 14.411300 loss_rnnt 10.404715 hw_loss 0.023477 lr 0.00045652 rank 6
2023-02-22 03:46:43,470 DEBUG TRAIN Batch 14/3200 loss 9.905338 loss_att 12.928324 loss_ctc 14.372658 loss_rnnt 8.616730 hw_loss 0.165691 lr 0.00045645 rank 7
2023-02-22 03:46:43,470 DEBUG TRAIN Batch 14/3200 loss 5.100437 loss_att 8.173038 loss_ctc 5.562732 loss_rnnt 4.371675 hw_loss 0.098630 lr 0.00045646 rank 2
2023-02-22 03:46:43,481 DEBUG TRAIN Batch 14/3200 loss 17.885271 loss_att 21.963875 loss_ctc 25.248175 loss_rnnt 15.983882 hw_loss 0.194900 lr 0.00045644 rank 5
2023-02-22 03:47:58,871 DEBUG TRAIN Batch 14/3300 loss 11.594318 loss_att 15.993905 loss_ctc 15.984848 loss_rnnt 10.090546 hw_loss 0.072096 lr 0.00045626 rank 4
2023-02-22 03:47:58,873 DEBUG TRAIN Batch 14/3300 loss 5.252269 loss_att 9.337181 loss_ctc 9.316067 loss_rnnt 3.840797 hw_loss 0.098720 lr 0.00045629 rank 0
2023-02-22 03:47:58,876 DEBUG TRAIN Batch 14/3300 loss 9.216376 loss_att 10.328250 loss_ctc 11.929607 loss_rnnt 8.585289 hw_loss 0.088028 lr 0.00045626 rank 7
2023-02-22 03:47:58,878 DEBUG TRAIN Batch 14/3300 loss 7.406404 loss_att 11.355641 loss_ctc 10.645237 loss_rnnt 6.099858 hw_loss 0.159100 lr 0.00045636 rank 1
2023-02-22 03:47:58,879 DEBUG TRAIN Batch 14/3300 loss 9.031288 loss_att 15.480942 loss_ctc 12.194620 loss_rnnt 7.231716 hw_loss 0.164745 lr 0.00045627 rank 2
2023-02-22 03:47:58,880 DEBUG TRAIN Batch 14/3300 loss 8.900224 loss_att 8.757627 loss_ctc 10.499830 loss_rnnt 8.515310 hw_loss 0.375285 lr 0.00045626 rank 3
2023-02-22 03:47:58,882 DEBUG TRAIN Batch 14/3300 loss 6.765821 loss_att 10.609679 loss_ctc 8.805264 loss_rnnt 5.630460 hw_loss 0.177493 lr 0.00045625 rank 5
2023-02-22 03:47:58,925 DEBUG TRAIN Batch 14/3300 loss 10.705228 loss_att 16.972473 loss_ctc 14.777026 loss_rnnt 8.831412 hw_loss 0.145239 lr 0.00045633 rank 6
2023-02-22 03:49:14,262 DEBUG TRAIN Batch 14/3400 loss 13.064398 loss_att 18.045055 loss_ctc 19.843781 loss_rnnt 11.077738 hw_loss 0.162394 lr 0.00045606 rank 5
2023-02-22 03:49:14,263 DEBUG TRAIN Batch 14/3400 loss 9.503250 loss_att 11.244551 loss_ctc 9.825145 loss_rnnt 9.109364 hw_loss 0.005075 lr 0.00045610 rank 0
2023-02-22 03:49:14,265 DEBUG TRAIN Batch 14/3400 loss 22.700235 loss_att 25.445107 loss_ctc 31.105556 loss_rnnt 21.009197 hw_loss 0.040035 lr 0.00045614 rank 6
2023-02-22 03:49:14,265 DEBUG TRAIN Batch 14/3400 loss 8.401420 loss_att 9.511576 loss_ctc 10.744648 loss_rnnt 7.775556 hw_loss 0.171378 lr 0.00045607 rank 7
2023-02-22 03:49:14,267 DEBUG TRAIN Batch 14/3400 loss 12.411344 loss_att 16.558897 loss_ctc 15.837053 loss_rnnt 10.998383 hw_loss 0.237543 lr 0.00045607 rank 3
2023-02-22 03:49:14,272 DEBUG TRAIN Batch 14/3400 loss 11.779607 loss_att 12.170019 loss_ctc 12.659533 loss_rnnt 11.470625 hw_loss 0.212956 lr 0.00045607 rank 4
2023-02-22 03:49:14,273 DEBUG TRAIN Batch 14/3400 loss 18.229237 loss_att 20.009750 loss_ctc 23.453644 loss_rnnt 17.157236 hw_loss 0.036206 lr 0.00045608 rank 2
2023-02-22 03:49:14,273 DEBUG TRAIN Batch 14/3400 loss 18.976372 loss_att 19.759911 loss_ctc 20.271519 loss_rnnt 18.576111 hw_loss 0.132877 lr 0.00045617 rank 1
2023-02-22 03:50:29,563 DEBUG TRAIN Batch 14/3500 loss 14.269518 loss_att 18.910496 loss_ctc 21.396765 loss_rnnt 12.348667 hw_loss 0.079418 lr 0.00045588 rank 7
2023-02-22 03:50:29,563 DEBUG TRAIN Batch 14/3500 loss 6.827109 loss_att 9.282034 loss_ctc 9.104738 loss_rnnt 5.960634 hw_loss 0.134636 lr 0.00045588 rank 4
2023-02-22 03:50:29,568 DEBUG TRAIN Batch 14/3500 loss 12.639482 loss_att 16.155472 loss_ctc 18.688511 loss_rnnt 11.065340 hw_loss 0.120765 lr 0.00045598 rank 1
2023-02-22 03:50:29,569 DEBUG TRAIN Batch 14/3500 loss 22.851099 loss_att 26.479507 loss_ctc 30.642654 loss_rnnt 21.045908 hw_loss 0.076187 lr 0.00045591 rank 0
2023-02-22 03:50:29,571 DEBUG TRAIN Batch 14/3500 loss 24.917820 loss_att 25.282993 loss_ctc 29.774200 loss_rnnt 24.124748 hw_loss 0.135970 lr 0.00045589 rank 2
2023-02-22 03:50:29,571 DEBUG TRAIN Batch 14/3500 loss 11.944167 loss_att 14.466140 loss_ctc 14.274556 loss_rnnt 11.061815 hw_loss 0.126071 lr 0.00045587 rank 5
2023-02-22 03:50:29,573 DEBUG TRAIN Batch 14/3500 loss 9.564984 loss_att 12.503689 loss_ctc 12.049423 loss_rnnt 8.613323 hw_loss 0.061239 lr 0.00045588 rank 3
2023-02-22 03:50:29,618 DEBUG TRAIN Batch 14/3500 loss 12.855550 loss_att 11.452121 loss_ctc 16.961380 loss_rnnt 12.450029 hw_loss 0.260177 lr 0.00045596 rank 6
2023-02-22 03:51:47,587 DEBUG TRAIN Batch 14/3600 loss 15.637302 loss_att 19.581867 loss_ctc 18.226849 loss_rnnt 14.385284 hw_loss 0.220933 lr 0.00045572 rank 0
2023-02-22 03:51:47,589 DEBUG TRAIN Batch 14/3600 loss 6.716147 loss_att 10.280564 loss_ctc 8.862227 loss_rnnt 5.631307 hw_loss 0.160898 lr 0.00045570 rank 2
2023-02-22 03:51:47,590 DEBUG TRAIN Batch 14/3600 loss 17.196999 loss_att 17.608932 loss_ctc 20.588354 loss_rnnt 16.593973 hw_loss 0.128355 lr 0.00045569 rank 7
2023-02-22 03:51:47,593 DEBUG TRAIN Batch 14/3600 loss 6.061276 loss_att 7.068850 loss_ctc 7.380099 loss_rnnt 5.616446 hw_loss 0.126510 lr 0.00045569 rank 4
2023-02-22 03:51:47,593 DEBUG TRAIN Batch 14/3600 loss 11.240727 loss_att 14.847282 loss_ctc 15.288095 loss_rnnt 9.900715 hw_loss 0.148223 lr 0.00045568 rank 5
2023-02-22 03:51:47,595 DEBUG TRAIN Batch 14/3600 loss 3.845482 loss_att 8.137226 loss_ctc 4.701949 loss_rnnt 2.872715 hw_loss 0.000418 lr 0.00045577 rank 6
2023-02-22 03:51:47,597 DEBUG TRAIN Batch 14/3600 loss 3.028086 loss_att 6.008226 loss_ctc 3.688046 loss_rnnt 2.296499 hw_loss 0.089183 lr 0.00045579 rank 1
2023-02-22 03:51:47,600 DEBUG TRAIN Batch 14/3600 loss 15.917118 loss_att 20.022144 loss_ctc 22.469906 loss_rnnt 14.128745 hw_loss 0.175617 lr 0.00045569 rank 3
2023-02-22 03:53:03,219 DEBUG TRAIN Batch 14/3700 loss 8.278362 loss_att 11.323022 loss_ctc 9.952660 loss_rnnt 7.306882 hw_loss 0.261203 lr 0.00045550 rank 4
2023-02-22 03:53:03,221 DEBUG TRAIN Batch 14/3700 loss 9.581981 loss_att 12.934717 loss_ctc 12.867966 loss_rnnt 8.321362 hw_loss 0.284886 lr 0.00045549 rank 5
2023-02-22 03:53:03,228 DEBUG TRAIN Batch 14/3700 loss 9.936661 loss_att 12.339522 loss_ctc 12.644197 loss_rnnt 8.983536 hw_loss 0.209152 lr 0.00045553 rank 0
2023-02-22 03:53:03,230 DEBUG TRAIN Batch 14/3700 loss 16.427935 loss_att 18.777735 loss_ctc 22.949198 loss_rnnt 14.984842 hw_loss 0.194308 lr 0.00045551 rank 2
2023-02-22 03:53:03,230 DEBUG TRAIN Batch 14/3700 loss 21.432226 loss_att 24.489576 loss_ctc 27.386078 loss_rnnt 20.014040 hw_loss 0.024130 lr 0.00045560 rank 1
2023-02-22 03:53:03,231 DEBUG TRAIN Batch 14/3700 loss 9.571616 loss_att 11.049547 loss_ctc 14.510882 loss_rnnt 8.570930 hw_loss 0.087245 lr 0.00045550 rank 7
2023-02-22 03:53:03,232 DEBUG TRAIN Batch 14/3700 loss 4.169511 loss_att 9.204458 loss_ctc 5.070718 loss_rnnt 2.939034 hw_loss 0.193738 lr 0.00045550 rank 3
2023-02-22 03:53:03,234 DEBUG TRAIN Batch 14/3700 loss 15.353143 loss_att 17.905844 loss_ctc 22.044111 loss_rnnt 13.926111 hw_loss 0.045677 lr 0.00045558 rank 6
2023-02-22 03:54:18,992 DEBUG TRAIN Batch 14/3800 loss 12.220069 loss_att 16.526525 loss_ctc 24.513210 loss_rnnt 9.692924 hw_loss 0.050190 lr 0.00045531 rank 7
2023-02-22 03:54:18,995 DEBUG TRAIN Batch 14/3800 loss 15.364945 loss_att 37.782406 loss_ctc 18.396465 loss_rnnt 10.435941 hw_loss 0.077456 lr 0.00045530 rank 5
2023-02-22 03:54:18,997 DEBUG TRAIN Batch 14/3800 loss 8.391134 loss_att 9.547940 loss_ctc 10.649342 loss_rnnt 7.779802 hw_loss 0.147892 lr 0.00045531 rank 4
2023-02-22 03:54:18,997 DEBUG TRAIN Batch 14/3800 loss 13.894065 loss_att 17.641567 loss_ctc 16.559509 loss_rnnt 12.611499 hw_loss 0.333137 lr 0.00045539 rank 6
2023-02-22 03:54:19,000 DEBUG TRAIN Batch 14/3800 loss 11.441094 loss_att 14.879637 loss_ctc 13.734493 loss_rnnt 10.347619 hw_loss 0.187461 lr 0.00045534 rank 0
2023-02-22 03:54:19,001 DEBUG TRAIN Batch 14/3800 loss 11.023957 loss_att 15.556123 loss_ctc 15.206200 loss_rnnt 9.529039 hw_loss 0.057846 lr 0.00045532 rank 3
2023-02-22 03:54:19,005 DEBUG TRAIN Batch 14/3800 loss 16.023165 loss_att 16.383936 loss_ctc 18.929405 loss_rnnt 15.412485 hw_loss 0.283173 lr 0.00045532 rank 2
2023-02-22 03:54:19,007 DEBUG TRAIN Batch 14/3800 loss 11.485828 loss_att 13.048813 loss_ctc 14.667143 loss_rnnt 10.665693 hw_loss 0.156304 lr 0.00045542 rank 1
2023-02-22 03:55:37,215 DEBUG TRAIN Batch 14/3900 loss 8.667240 loss_att 12.595349 loss_ctc 14.249830 loss_rnnt 7.100353 hw_loss 0.069224 lr 0.00045512 rank 5
2023-02-22 03:55:37,215 DEBUG TRAIN Batch 14/3900 loss 8.373924 loss_att 9.906125 loss_ctc 10.093396 loss_rnnt 7.742684 hw_loss 0.179132 lr 0.00045513 rank 3
2023-02-22 03:55:37,218 DEBUG TRAIN Batch 14/3900 loss 14.999113 loss_att 16.468098 loss_ctc 17.224623 loss_rnnt 14.320288 hw_loss 0.165551 lr 0.00045520 rank 6
2023-02-22 03:55:37,222 DEBUG TRAIN Batch 14/3900 loss 18.794308 loss_att 22.550024 loss_ctc 23.652205 loss_rnnt 17.349012 hw_loss 0.087062 lr 0.00045515 rank 0
2023-02-22 03:55:37,224 DEBUG TRAIN Batch 14/3900 loss 8.236210 loss_att 11.706657 loss_ctc 9.368760 loss_rnnt 7.307796 hw_loss 0.156220 lr 0.00045523 rank 1
2023-02-22 03:55:37,225 DEBUG TRAIN Batch 14/3900 loss 6.107728 loss_att 10.639082 loss_ctc 7.853960 loss_rnnt 4.919791 hw_loss 0.091567 lr 0.00045512 rank 7
2023-02-22 03:55:37,226 DEBUG TRAIN Batch 14/3900 loss 12.379226 loss_att 13.216138 loss_ctc 13.633739 loss_rnnt 11.937817 hw_loss 0.200172 lr 0.00045513 rank 2
2023-02-22 03:55:37,242 DEBUG TRAIN Batch 14/3900 loss 6.895417 loss_att 12.248436 loss_ctc 14.272422 loss_rnnt 4.741874 hw_loss 0.186259 lr 0.00045512 rank 4
2023-02-22 03:56:52,000 DEBUG TRAIN Batch 14/4000 loss 8.714206 loss_att 11.004509 loss_ctc 11.796759 loss_rnnt 7.768989 hw_loss 0.142779 lr 0.00045494 rank 3
2023-02-22 03:56:52,000 DEBUG TRAIN Batch 14/4000 loss 19.017469 loss_att 24.504814 loss_ctc 30.025854 loss_rnnt 16.397293 hw_loss 0.102979 lr 0.00045493 rank 7
2023-02-22 03:56:52,002 DEBUG TRAIN Batch 14/4000 loss 11.341002 loss_att 14.872170 loss_ctc 12.276003 loss_rnnt 10.450193 hw_loss 0.112328 lr 0.00045496 rank 0
2023-02-22 03:56:52,002 DEBUG TRAIN Batch 14/4000 loss 19.123308 loss_att 19.212393 loss_ctc 23.224377 loss_rnnt 18.509453 hw_loss 0.092304 lr 0.00045493 rank 5
2023-02-22 03:56:52,003 DEBUG TRAIN Batch 14/4000 loss 9.417965 loss_att 11.473907 loss_ctc 11.021346 loss_rnnt 8.663705 hw_loss 0.242411 lr 0.00045493 rank 4
2023-02-22 03:56:52,007 DEBUG TRAIN Batch 14/4000 loss 16.887260 loss_att 15.603855 loss_ctc 26.216528 loss_rnnt 15.858768 hw_loss 0.077383 lr 0.00045494 rank 2
2023-02-22 03:56:52,008 DEBUG TRAIN Batch 14/4000 loss 10.715389 loss_att 14.912422 loss_ctc 20.123703 loss_rnnt 8.605110 hw_loss 0.030808 lr 0.00045501 rank 6
2023-02-22 03:56:52,008 DEBUG TRAIN Batch 14/4000 loss 10.102440 loss_att 12.405596 loss_ctc 12.834576 loss_rnnt 9.172894 hw_loss 0.196181 lr 0.00045504 rank 1
2023-02-22 03:58:07,591 DEBUG TRAIN Batch 14/4100 loss 9.906003 loss_att 12.357219 loss_ctc 12.161528 loss_rnnt 9.055721 hw_loss 0.111190 lr 0.00045474 rank 4
2023-02-22 03:58:07,594 DEBUG TRAIN Batch 14/4100 loss 13.564959 loss_att 18.398247 loss_ctc 16.801340 loss_rnnt 12.129206 hw_loss 0.070458 lr 0.00045485 rank 1
2023-02-22 03:58:07,594 DEBUG TRAIN Batch 14/4100 loss 21.793243 loss_att 26.661400 loss_ctc 30.734489 loss_rnnt 19.576777 hw_loss 0.095004 lr 0.00045474 rank 7
2023-02-22 03:58:07,595 DEBUG TRAIN Batch 14/4100 loss 32.359547 loss_att 36.482910 loss_ctc 42.678364 loss_rnnt 30.093929 hw_loss 0.122061 lr 0.00045476 rank 2
2023-02-22 03:58:07,597 DEBUG TRAIN Batch 14/4100 loss 19.507397 loss_att 18.164213 loss_ctc 23.511776 loss_rnnt 19.151747 hw_loss 0.169443 lr 0.00045475 rank 3
2023-02-22 03:58:07,597 DEBUG TRAIN Batch 14/4100 loss 12.110806 loss_att 15.496926 loss_ctc 18.168175 loss_rnnt 10.552200 hw_loss 0.138248 lr 0.00045477 rank 0
2023-02-22 03:58:07,598 DEBUG TRAIN Batch 14/4100 loss 15.572352 loss_att 18.864834 loss_ctc 18.255444 loss_rnnt 14.532937 hw_loss 0.043449 lr 0.00045474 rank 5
2023-02-22 03:58:07,646 DEBUG TRAIN Batch 14/4100 loss 14.489464 loss_att 18.423294 loss_ctc 20.328264 loss_rnnt 12.884721 hw_loss 0.074006 lr 0.00045482 rank 6
2023-02-22 03:59:23,308 DEBUG TRAIN Batch 14/4200 loss 18.408939 loss_att 19.971340 loss_ctc 19.089523 loss_rnnt 17.897154 hw_loss 0.203552 lr 0.00045456 rank 7
2023-02-22 03:59:23,309 DEBUG TRAIN Batch 14/4200 loss 19.016838 loss_att 19.218113 loss_ctc 25.712317 loss_rnnt 17.997206 hw_loss 0.162464 lr 0.00045458 rank 0
2023-02-22 03:59:23,313 DEBUG TRAIN Batch 14/4200 loss 26.250496 loss_att 26.812710 loss_ctc 36.863171 loss_rnnt 24.684368 hw_loss 0.072491 lr 0.00045456 rank 4
2023-02-22 03:59:23,315 DEBUG TRAIN Batch 14/4200 loss 16.810452 loss_att 22.342388 loss_ctc 22.157503 loss_rnnt 14.890100 hw_loss 0.189420 lr 0.00045456 rank 3
2023-02-22 03:59:23,314 DEBUG TRAIN Batch 14/4200 loss 14.513624 loss_att 18.127630 loss_ctc 17.617846 loss_rnnt 13.313215 hw_loss 0.119459 lr 0.00045463 rank 6
2023-02-22 03:59:23,315 DEBUG TRAIN Batch 14/4200 loss 15.881495 loss_att 15.118272 loss_ctc 19.211693 loss_rnnt 15.551613 hw_loss 0.072185 lr 0.00045466 rank 1
2023-02-22 03:59:23,316 DEBUG TRAIN Batch 14/4200 loss 20.029770 loss_att 21.088387 loss_ctc 22.342262 loss_rnnt 19.410603 hw_loss 0.185832 lr 0.00045457 rank 2
2023-02-22 03:59:23,318 DEBUG TRAIN Batch 14/4200 loss 15.965680 loss_att 20.924969 loss_ctc 20.051683 loss_rnnt 14.383112 hw_loss 0.086080 lr 0.00045455 rank 5
2023-02-22 04:00:41,984 DEBUG TRAIN Batch 14/4300 loss 9.602513 loss_att 11.403571 loss_ctc 13.738692 loss_rnnt 8.598986 hw_loss 0.172171 lr 0.00045437 rank 4
2023-02-22 04:00:41,986 DEBUG TRAIN Batch 14/4300 loss 8.450358 loss_att 11.657948 loss_ctc 8.392036 loss_rnnt 7.741702 hw_loss 0.140465 lr 0.00045438 rank 2
2023-02-22 04:00:41,987 DEBUG TRAIN Batch 14/4300 loss 12.133248 loss_att 15.241274 loss_ctc 17.660229 loss_rnnt 10.716681 hw_loss 0.108809 lr 0.00045436 rank 5
2023-02-22 04:00:41,987 DEBUG TRAIN Batch 14/4300 loss 5.928898 loss_att 7.535640 loss_ctc 6.419285 loss_rnnt 5.520092 hw_loss 0.041388 lr 0.00045437 rank 7
2023-02-22 04:00:41,990 DEBUG TRAIN Batch 14/4300 loss 8.970168 loss_att 12.307414 loss_ctc 15.411929 loss_rnnt 7.409369 hw_loss 0.064593 lr 0.00045437 rank 3
2023-02-22 04:00:41,990 DEBUG TRAIN Batch 14/4300 loss 11.932319 loss_att 11.732020 loss_ctc 15.791313 loss_rnnt 11.403312 hw_loss 0.102253 lr 0.00045445 rank 6
2023-02-22 04:00:41,990 DEBUG TRAIN Batch 14/4300 loss 13.496407 loss_att 16.904530 loss_ctc 17.687567 loss_rnnt 12.114391 hw_loss 0.265440 lr 0.00045440 rank 0
2023-02-22 04:00:42,039 DEBUG TRAIN Batch 14/4300 loss 13.449740 loss_att 15.885242 loss_ctc 19.255373 loss_rnnt 12.151253 hw_loss 0.069943 lr 0.00045447 rank 1
2023-02-22 04:01:58,775 DEBUG TRAIN Batch 14/4400 loss 5.321302 loss_att 7.141616 loss_ctc 6.417675 loss_rnnt 4.683353 hw_loss 0.239445 lr 0.00045421 rank 0
2023-02-22 04:01:58,778 DEBUG TRAIN Batch 14/4400 loss 6.031898 loss_att 8.482203 loss_ctc 8.869003 loss_rnnt 5.006232 hw_loss 0.294984 lr 0.00045418 rank 7
2023-02-22 04:01:58,779 DEBUG TRAIN Batch 14/4400 loss 18.942631 loss_att 23.482153 loss_ctc 25.604719 loss_rnnt 17.081636 hw_loss 0.121519 lr 0.00045418 rank 4
2023-02-22 04:01:58,780 DEBUG TRAIN Batch 14/4400 loss 9.641417 loss_att 13.587536 loss_ctc 13.899769 loss_rnnt 8.222559 hw_loss 0.115973 lr 0.00045418 rank 5
2023-02-22 04:01:58,782 DEBUG TRAIN Batch 14/4400 loss 6.088329 loss_att 9.072634 loss_ctc 8.075057 loss_rnnt 5.150979 hw_loss 0.141735 lr 0.00045429 rank 1
2023-02-22 04:01:58,784 DEBUG TRAIN Batch 14/4400 loss 14.463861 loss_att 15.107216 loss_ctc 18.926979 loss_rnnt 13.663772 hw_loss 0.143129 lr 0.00045426 rank 6
2023-02-22 04:01:58,785 DEBUG TRAIN Batch 14/4400 loss 12.907460 loss_att 11.716619 loss_ctc 13.899417 loss_rnnt 12.906916 hw_loss 0.199595 lr 0.00045419 rank 2
2023-02-22 04:01:58,788 DEBUG TRAIN Batch 14/4400 loss 20.077658 loss_att 24.059845 loss_ctc 22.551056 loss_rnnt 18.841782 hw_loss 0.205596 lr 0.00045419 rank 3
2023-02-22 04:03:13,689 DEBUG TRAIN Batch 14/4500 loss 18.263248 loss_att 23.489483 loss_ctc 24.547325 loss_rnnt 16.299932 hw_loss 0.150362 lr 0.00045399 rank 7
2023-02-22 04:03:13,689 DEBUG TRAIN Batch 14/4500 loss 6.442513 loss_att 10.869129 loss_ctc 9.348572 loss_rnnt 5.124427 hw_loss 0.084915 lr 0.00045402 rank 0
2023-02-22 04:03:13,689 DEBUG TRAIN Batch 14/4500 loss 15.782976 loss_att 16.680449 loss_ctc 18.254208 loss_rnnt 15.217356 hw_loss 0.106177 lr 0.00045400 rank 3
2023-02-22 04:03:13,690 DEBUG TRAIN Batch 14/4500 loss 17.555878 loss_att 22.160831 loss_ctc 20.797203 loss_rnnt 16.102924 hw_loss 0.187095 lr 0.00045410 rank 1
2023-02-22 04:03:13,690 DEBUG TRAIN Batch 14/4500 loss 18.873362 loss_att 24.960447 loss_ctc 27.341637 loss_rnnt 16.481321 hw_loss 0.085351 lr 0.00045399 rank 4
2023-02-22 04:03:13,691 DEBUG TRAIN Batch 14/4500 loss 5.076472 loss_att 8.059964 loss_ctc 7.590000 loss_rnnt 4.057882 hw_loss 0.162664 lr 0.00045407 rank 6
2023-02-22 04:03:13,696 DEBUG TRAIN Batch 14/4500 loss 15.824027 loss_att 21.909365 loss_ctc 22.389471 loss_rnnt 13.731461 hw_loss 0.000200 lr 0.00045399 rank 5
2023-02-22 04:03:13,698 DEBUG TRAIN Batch 14/4500 loss 5.252310 loss_att 9.538692 loss_ctc 9.731136 loss_rnnt 3.759151 hw_loss 0.072572 lr 0.00045401 rank 2
2023-02-22 04:04:31,793 DEBUG TRAIN Batch 14/4600 loss 8.342609 loss_att 10.582088 loss_ctc 11.815242 loss_rnnt 7.323781 hw_loss 0.202340 lr 0.00045381 rank 4
2023-02-22 04:04:31,800 DEBUG TRAIN Batch 14/4600 loss 7.262076 loss_att 12.616634 loss_ctc 10.429127 loss_rnnt 5.731500 hw_loss 0.070108 lr 0.00045382 rank 2
2023-02-22 04:04:31,801 DEBUG TRAIN Batch 14/4600 loss 20.681431 loss_att 26.184219 loss_ctc 26.770742 loss_rnnt 18.704189 hw_loss 0.121454 lr 0.00045380 rank 5
2023-02-22 04:04:31,802 DEBUG TRAIN Batch 14/4600 loss 24.114264 loss_att 22.637629 loss_ctc 27.694855 loss_rnnt 23.858997 hw_loss 0.137208 lr 0.00045381 rank 7
2023-02-22 04:04:31,803 DEBUG TRAIN Batch 14/4600 loss 17.081402 loss_att 20.074371 loss_ctc 26.907631 loss_rnnt 15.151637 hw_loss 0.039386 lr 0.00045384 rank 0
2023-02-22 04:04:31,804 DEBUG TRAIN Batch 14/4600 loss 6.280441 loss_att 11.256725 loss_ctc 9.612940 loss_rnnt 4.764446 hw_loss 0.143258 lr 0.00045391 rank 1
2023-02-22 04:04:31,804 DEBUG TRAIN Batch 14/4600 loss 6.553634 loss_att 9.599733 loss_ctc 9.772176 loss_rnnt 5.439271 hw_loss 0.142507 lr 0.00045381 rank 3
2023-02-22 04:04:31,808 DEBUG TRAIN Batch 14/4600 loss 16.672894 loss_att 15.868130 loss_ctc 17.229069 loss_rnnt 16.623459 hw_loss 0.255433 lr 0.00045388 rank 6
2023-02-22 04:05:48,872 DEBUG TRAIN Batch 14/4700 loss 8.661654 loss_att 13.113698 loss_ctc 9.344936 loss_rnnt 7.581132 hw_loss 0.185643 lr 0.00045365 rank 0
2023-02-22 04:05:48,878 DEBUG TRAIN Batch 14/4700 loss 11.576491 loss_att 18.720501 loss_ctc 13.692329 loss_rnnt 9.838964 hw_loss 0.049902 lr 0.00045370 rank 6
2023-02-22 04:05:48,878 DEBUG TRAIN Batch 14/4700 loss 14.473825 loss_att 18.521214 loss_ctc 20.266827 loss_rnnt 12.850283 hw_loss 0.078120 lr 0.00045361 rank 5
2023-02-22 04:05:48,881 DEBUG TRAIN Batch 14/4700 loss 15.593981 loss_att 17.229250 loss_ctc 18.261202 loss_rnnt 14.853528 hw_loss 0.108317 lr 0.00045363 rank 2
2023-02-22 04:05:48,882 DEBUG TRAIN Batch 14/4700 loss 4.015079 loss_att 6.469717 loss_ctc 6.457706 loss_rnnt 3.095872 hw_loss 0.192366 lr 0.00045362 rank 7
2023-02-22 04:05:48,885 DEBUG TRAIN Batch 14/4700 loss 17.135469 loss_att 18.515739 loss_ctc 20.780581 loss_rnnt 16.215345 hw_loss 0.296354 lr 0.00045362 rank 4
2023-02-22 04:05:48,886 DEBUG TRAIN Batch 14/4700 loss 10.130247 loss_att 13.439192 loss_ctc 14.952979 loss_rnnt 8.815946 hw_loss 0.017777 lr 0.00045363 rank 3
2023-02-22 04:05:48,930 DEBUG TRAIN Batch 14/4700 loss 6.358333 loss_att 9.848748 loss_ctc 11.281547 loss_rnnt 4.918446 hw_loss 0.160080 lr 0.00045372 rank 1
2023-02-22 04:07:04,465 DEBUG TRAIN Batch 14/4800 loss 17.397434 loss_att 20.177647 loss_ctc 20.877598 loss_rnnt 16.345207 hw_loss 0.060307 lr 0.00045343 rank 7
2023-02-22 04:07:04,469 DEBUG TRAIN Batch 14/4800 loss 12.736326 loss_att 16.556599 loss_ctc 17.428509 loss_rnnt 11.239029 hw_loss 0.201782 lr 0.00045343 rank 5
2023-02-22 04:07:04,470 DEBUG TRAIN Batch 14/4800 loss 16.267797 loss_att 17.508949 loss_ctc 20.574188 loss_rnnt 15.358587 hw_loss 0.162742 lr 0.00045346 rank 0
2023-02-22 04:07:04,474 DEBUG TRAIN Batch 14/4800 loss 11.188038 loss_att 14.019233 loss_ctc 16.031967 loss_rnnt 9.866461 hw_loss 0.205275 lr 0.00045345 rank 2
2023-02-22 04:07:04,474 DEBUG TRAIN Batch 14/4800 loss 17.880754 loss_att 19.454216 loss_ctc 26.562714 loss_rnnt 16.304819 hw_loss 0.194339 lr 0.00045354 rank 1
2023-02-22 04:07:04,474 DEBUG TRAIN Batch 14/4800 loss 7.856833 loss_att 12.273816 loss_ctc 11.549307 loss_rnnt 6.413085 hw_loss 0.127542 lr 0.00045343 rank 4
2023-02-22 04:07:04,475 DEBUG TRAIN Batch 14/4800 loss 9.827198 loss_att 14.992763 loss_ctc 10.064548 loss_rnnt 8.635501 hw_loss 0.238009 lr 0.00045351 rank 6
2023-02-22 04:07:04,480 DEBUG TRAIN Batch 14/4800 loss 7.862554 loss_att 11.727463 loss_ctc 11.337264 loss_rnnt 6.531587 hw_loss 0.177543 lr 0.00045344 rank 3
2023-02-22 04:08:19,000 DEBUG TRAIN Batch 14/4900 loss 18.119247 loss_att 19.675650 loss_ctc 25.401337 loss_rnnt 16.771805 hw_loss 0.122281 lr 0.00045324 rank 5
2023-02-22 04:08:19,005 DEBUG TRAIN Batch 14/4900 loss 6.616259 loss_att 9.116192 loss_ctc 6.429350 loss_rnnt 6.054225 hw_loss 0.163067 lr 0.00045326 rank 2
2023-02-22 04:08:19,004 DEBUG TRAIN Batch 14/4900 loss 10.062554 loss_att 13.102347 loss_ctc 14.896769 loss_rnnt 8.771822 hw_loss 0.071648 lr 0.00045328 rank 0
2023-02-22 04:08:19,006 DEBUG TRAIN Batch 14/4900 loss 13.676650 loss_att 13.677912 loss_ctc 15.721491 loss_rnnt 13.304396 hw_loss 0.186293 lr 0.00045325 rank 7
2023-02-22 04:08:19,009 DEBUG TRAIN Batch 14/4900 loss 10.360734 loss_att 13.829382 loss_ctc 18.125683 loss_rnnt 8.502510 hw_loss 0.242187 lr 0.00045332 rank 6
2023-02-22 04:08:19,012 DEBUG TRAIN Batch 14/4900 loss 12.163975 loss_att 17.309032 loss_ctc 16.234222 loss_rnnt 10.520668 hw_loss 0.134240 lr 0.00045325 rank 4
2023-02-22 04:08:19,037 DEBUG TRAIN Batch 14/4900 loss 18.396347 loss_att 22.404593 loss_ctc 19.345207 loss_rnnt 17.351313 hw_loss 0.219130 lr 0.00045335 rank 1
2023-02-22 04:08:19,047 DEBUG TRAIN Batch 14/4900 loss 11.833921 loss_att 18.036980 loss_ctc 16.134102 loss_rnnt 9.943359 hw_loss 0.143612 lr 0.00045325 rank 3
2023-02-22 04:09:36,586 DEBUG TRAIN Batch 14/5000 loss 16.928831 loss_att 18.454676 loss_ctc 21.691315 loss_rnnt 15.854128 hw_loss 0.252256 lr 0.00045306 rank 7
2023-02-22 04:09:36,590 DEBUG TRAIN Batch 14/5000 loss 15.495230 loss_att 18.683487 loss_ctc 20.916172 loss_rnnt 14.095124 hw_loss 0.074363 lr 0.00045306 rank 4
2023-02-22 04:09:36,590 DEBUG TRAIN Batch 14/5000 loss 12.276836 loss_att 13.886878 loss_ctc 16.720051 loss_rnnt 11.274443 hw_loss 0.164922 lr 0.00045307 rank 2
2023-02-22 04:09:36,591 DEBUG TRAIN Batch 14/5000 loss 7.501608 loss_att 10.994976 loss_ctc 12.853442 loss_rnnt 6.018844 hw_loss 0.132210 lr 0.00045317 rank 1
2023-02-22 04:09:36,591 DEBUG TRAIN Batch 14/5000 loss 20.014011 loss_att 18.174782 loss_ctc 25.278397 loss_rnnt 19.620125 hw_loss 0.112150 lr 0.00045314 rank 6
2023-02-22 04:09:36,595 DEBUG TRAIN Batch 14/5000 loss 12.614247 loss_att 14.859635 loss_ctc 15.238538 loss_rnnt 11.711159 hw_loss 0.195199 lr 0.00045309 rank 0
2023-02-22 04:09:36,598 DEBUG TRAIN Batch 14/5000 loss 19.616842 loss_att 20.124790 loss_ctc 25.910793 loss_rnnt 18.636896 hw_loss 0.073428 lr 0.00045307 rank 3
2023-02-22 04:09:36,610 DEBUG TRAIN Batch 14/5000 loss 11.881983 loss_att 17.241293 loss_ctc 17.183102 loss_rnnt 9.992613 hw_loss 0.207547 lr 0.00045306 rank 5
2023-02-22 04:10:51,811 DEBUG TRAIN Batch 14/5100 loss 7.501246 loss_att 12.364719 loss_ctc 12.628161 loss_rnnt 5.746651 hw_loss 0.184336 lr 0.00045288 rank 7
2023-02-22 04:10:51,812 DEBUG TRAIN Batch 14/5100 loss 9.089466 loss_att 11.503605 loss_ctc 12.361626 loss_rnnt 8.155719 hw_loss 0.027435 lr 0.00045290 rank 0
2023-02-22 04:10:51,814 DEBUG TRAIN Batch 14/5100 loss 7.688264 loss_att 12.582214 loss_ctc 11.755771 loss_rnnt 6.125326 hw_loss 0.078403 lr 0.00045298 rank 1
2023-02-22 04:10:51,816 DEBUG TRAIN Batch 14/5100 loss 13.116261 loss_att 16.581293 loss_ctc 17.519337 loss_rnnt 11.735030 hw_loss 0.189650 lr 0.00045288 rank 3
2023-02-22 04:10:51,819 DEBUG TRAIN Batch 14/5100 loss 14.210142 loss_att 14.281504 loss_ctc 17.424006 loss_rnnt 13.688741 hw_loss 0.147399 lr 0.00045288 rank 4
2023-02-22 04:10:51,821 DEBUG TRAIN Batch 14/5100 loss 5.254175 loss_att 8.356947 loss_ctc 6.715459 loss_rnnt 4.339049 hw_loss 0.186999 lr 0.00045289 rank 2
2023-02-22 04:10:51,821 DEBUG TRAIN Batch 14/5100 loss 18.394945 loss_att 24.409252 loss_ctc 19.735950 loss_rnnt 16.968266 hw_loss 0.084410 lr 0.00045287 rank 5
2023-02-22 04:10:51,867 DEBUG TRAIN Batch 14/5100 loss 7.927804 loss_att 15.953776 loss_ctc 9.782278 loss_rnnt 5.968519 hw_loss 0.200301 lr 0.00045295 rank 6
2023-02-22 04:12:07,901 DEBUG TRAIN Batch 14/5200 loss 6.742829 loss_att 8.291159 loss_ctc 13.261363 loss_rnnt 5.508874 hw_loss 0.103408 lr 0.00045272 rank 0
2023-02-22 04:12:07,904 DEBUG TRAIN Batch 14/5200 loss 36.442413 loss_att 40.193901 loss_ctc 33.955078 loss_rnnt 35.952362 hw_loss 0.133871 lr 0.00045269 rank 4
2023-02-22 04:12:07,903 DEBUG TRAIN Batch 14/5200 loss 12.644851 loss_att 14.043192 loss_ctc 18.328079 loss_rnnt 11.604942 hw_loss 0.004645 lr 0.00045279 rank 1
2023-02-22 04:12:07,906 DEBUG TRAIN Batch 14/5200 loss 8.790987 loss_att 12.407383 loss_ctc 11.393480 loss_rnnt 7.651151 hw_loss 0.130420 lr 0.00045268 rank 5
2023-02-22 04:12:07,908 DEBUG TRAIN Batch 14/5200 loss 7.258758 loss_att 14.997902 loss_ctc 9.172694 loss_rnnt 5.363770 hw_loss 0.172440 lr 0.00045269 rank 7
2023-02-22 04:12:07,908 DEBUG TRAIN Batch 14/5200 loss 21.653740 loss_att 23.688263 loss_ctc 27.267872 loss_rnnt 20.447468 hw_loss 0.095280 lr 0.00045270 rank 3
2023-02-22 04:12:07,909 DEBUG TRAIN Batch 14/5200 loss 4.546299 loss_att 8.147159 loss_ctc 6.563892 loss_rnnt 3.541053 hw_loss 0.030113 lr 0.00045277 rank 6
2023-02-22 04:12:07,912 DEBUG TRAIN Batch 14/5200 loss 9.760472 loss_att 13.170425 loss_ctc 12.672618 loss_rnnt 8.683034 hw_loss 0.013427 lr 0.00045270 rank 2
2023-02-22 04:13:25,106 DEBUG TRAIN Batch 14/5300 loss 7.924381 loss_att 12.371988 loss_ctc 13.798626 loss_rnnt 6.211758 hw_loss 0.074753 lr 0.00045250 rank 5
2023-02-22 04:13:25,106 DEBUG TRAIN Batch 14/5300 loss 13.618589 loss_att 16.748266 loss_ctc 18.028549 loss_rnnt 12.362656 hw_loss 0.078760 lr 0.00045250 rank 4
2023-02-22 04:13:25,108 DEBUG TRAIN Batch 14/5300 loss 19.815477 loss_att 23.611328 loss_ctc 27.705978 loss_rnnt 17.951500 hw_loss 0.098893 lr 0.00045252 rank 2
2023-02-22 04:13:25,108 DEBUG TRAIN Batch 14/5300 loss 9.132500 loss_att 10.534160 loss_ctc 9.799369 loss_rnnt 8.659080 hw_loss 0.195323 lr 0.00045250 rank 7
2023-02-22 04:13:25,109 DEBUG TRAIN Batch 14/5300 loss 9.792918 loss_att 12.259068 loss_ctc 9.790771 loss_rnnt 9.241797 hw_loss 0.109084 lr 0.00045261 rank 1
2023-02-22 04:13:25,110 DEBUG TRAIN Batch 14/5300 loss 8.394437 loss_att 10.547279 loss_ctc 13.792986 loss_rnnt 7.219402 hw_loss 0.046236 lr 0.00045253 rank 0
2023-02-22 04:13:25,113 DEBUG TRAIN Batch 14/5300 loss 4.461824 loss_att 9.157660 loss_ctc 4.604265 loss_rnnt 3.480044 hw_loss 0.044289 lr 0.00045251 rank 3
2023-02-22 04:13:25,118 DEBUG TRAIN Batch 14/5300 loss 11.643847 loss_att 16.983383 loss_ctc 13.208998 loss_rnnt 10.322792 hw_loss 0.083366 lr 0.00045258 rank 6
2023-02-22 04:14:41,787 DEBUG TRAIN Batch 14/5400 loss 9.358303 loss_att 14.304571 loss_ctc 11.498100 loss_rnnt 8.010586 hw_loss 0.137172 lr 0.00045232 rank 7
2023-02-22 04:14:41,789 DEBUG TRAIN Batch 14/5400 loss 26.073547 loss_att 33.162071 loss_ctc 36.232914 loss_rnnt 23.162544 hw_loss 0.260093 lr 0.00045232 rank 3
2023-02-22 04:14:41,791 DEBUG TRAIN Batch 14/5400 loss 15.327774 loss_att 18.381649 loss_ctc 20.034653 loss_rnnt 13.984921 hw_loss 0.195927 lr 0.00045240 rank 6
2023-02-22 04:14:41,794 DEBUG TRAIN Batch 14/5400 loss 4.349758 loss_att 7.479646 loss_ctc 4.670783 loss_rnnt 3.611660 hw_loss 0.129969 lr 0.00045231 rank 5
2023-02-22 04:14:41,794 DEBUG TRAIN Batch 14/5400 loss 28.599680 loss_att 34.914299 loss_ctc 37.693443 loss_rnnt 26.047001 hw_loss 0.144847 lr 0.00045235 rank 0
2023-02-22 04:14:41,795 DEBUG TRAIN Batch 14/5400 loss 12.563237 loss_att 16.763927 loss_ctc 20.797241 loss_rnnt 10.545427 hw_loss 0.149634 lr 0.00045232 rank 4
2023-02-22 04:14:41,797 DEBUG TRAIN Batch 14/5400 loss 14.354733 loss_att 18.961807 loss_ctc 20.409992 loss_rnnt 12.587535 hw_loss 0.072030 lr 0.00045242 rank 1
2023-02-22 04:14:41,799 DEBUG TRAIN Batch 14/5400 loss 21.151724 loss_att 23.855339 loss_ctc 23.632023 loss_rnnt 20.227312 hw_loss 0.099341 lr 0.00045233 rank 2
2023-02-22 04:15:56,041 DEBUG TRAIN Batch 14/5500 loss 10.298329 loss_att 10.232716 loss_ctc 14.161389 loss_rnnt 9.673181 hw_loss 0.230995 lr 0.00045213 rank 7
2023-02-22 04:15:56,043 DEBUG TRAIN Batch 14/5500 loss 10.506263 loss_att 12.990789 loss_ctc 16.610113 loss_rnnt 9.116525 hw_loss 0.148096 lr 0.00045213 rank 4
2023-02-22 04:15:56,044 DEBUG TRAIN Batch 14/5500 loss 11.172400 loss_att 15.400454 loss_ctc 11.383317 loss_rnnt 10.243307 hw_loss 0.103801 lr 0.00045216 rank 0
2023-02-22 04:15:56,046 DEBUG TRAIN Batch 14/5500 loss 7.964605 loss_att 10.250387 loss_ctc 12.348515 loss_rnnt 6.876752 hw_loss 0.086578 lr 0.00045213 rank 5
2023-02-22 04:15:56,047 DEBUG TRAIN Batch 14/5500 loss 6.364135 loss_att 9.623095 loss_ctc 8.553211 loss_rnnt 5.337243 hw_loss 0.156043 lr 0.00045221 rank 6
2023-02-22 04:15:56,047 DEBUG TRAIN Batch 14/5500 loss 15.869139 loss_att 18.042130 loss_ctc 24.350945 loss_rnnt 14.222455 hw_loss 0.152205 lr 0.00045224 rank 1
2023-02-22 04:15:56,048 DEBUG TRAIN Batch 14/5500 loss 9.854471 loss_att 13.912994 loss_ctc 11.651262 loss_rnnt 8.723213 hw_loss 0.149965 lr 0.00045215 rank 2
2023-02-22 04:15:56,049 DEBUG TRAIN Batch 14/5500 loss 6.776947 loss_att 8.669524 loss_ctc 9.482639 loss_rnnt 5.986762 hw_loss 0.095458 lr 0.00045214 rank 3
2023-02-22 04:17:11,801 DEBUG TRAIN Batch 14/5600 loss 9.480433 loss_att 12.059872 loss_ctc 12.340189 loss_rnnt 8.491983 hw_loss 0.171114 lr 0.00045198 rank 0
2023-02-22 04:17:11,806 DEBUG TRAIN Batch 14/5600 loss 15.511481 loss_att 19.124519 loss_ctc 21.656603 loss_rnnt 13.906228 hw_loss 0.118679 lr 0.00045195 rank 4
2023-02-22 04:17:11,812 DEBUG TRAIN Batch 14/5600 loss 12.128676 loss_att 12.366947 loss_ctc 16.623743 loss_rnnt 11.353656 hw_loss 0.240044 lr 0.00045194 rank 5
2023-02-22 04:17:11,816 DEBUG TRAIN Batch 14/5600 loss 18.622076 loss_att 20.640274 loss_ctc 24.757483 loss_rnnt 17.280497 hw_loss 0.224785 lr 0.00045203 rank 6
2023-02-22 04:17:11,816 DEBUG TRAIN Batch 14/5600 loss 21.279736 loss_att 23.368917 loss_ctc 33.234573 loss_rnnt 19.158237 hw_loss 0.205661 lr 0.00045195 rank 7
2023-02-22 04:17:11,821 DEBUG TRAIN Batch 14/5600 loss 9.467312 loss_att 13.274781 loss_ctc 10.737593 loss_rnnt 8.442478 hw_loss 0.176192 lr 0.00045196 rank 3
2023-02-22 04:17:11,821 DEBUG TRAIN Batch 14/5600 loss 8.052370 loss_att 11.054604 loss_ctc 11.745749 loss_rnnt 6.843405 hw_loss 0.217625 lr 0.00045196 rank 2
2023-02-22 04:17:11,858 DEBUG TRAIN Batch 14/5600 loss 13.455473 loss_att 17.274796 loss_ctc 21.009949 loss_rnnt 11.606728 hw_loss 0.145530 lr 0.00045205 rank 1
2023-02-22 04:18:30,636 DEBUG TRAIN Batch 14/5700 loss 19.549198 loss_att 18.821079 loss_ctc 23.052898 loss_rnnt 19.040077 hw_loss 0.351720 lr 0.00045179 rank 0
2023-02-22 04:18:30,638 DEBUG TRAIN Batch 14/5700 loss 10.898332 loss_att 12.286126 loss_ctc 14.442440 loss_rnnt 10.024693 hw_loss 0.231618 lr 0.00045184 rank 6
2023-02-22 04:18:30,638 DEBUG TRAIN Batch 14/5700 loss 7.818233 loss_att 11.570103 loss_ctc 11.501358 loss_rnnt 6.551562 hw_loss 0.047276 lr 0.00045176 rank 5
2023-02-22 04:18:30,639 DEBUG TRAIN Batch 14/5700 loss 3.621766 loss_att 6.511992 loss_ctc 6.205779 loss_rnnt 2.624428 hw_loss 0.140170 lr 0.00045178 rank 2
2023-02-22 04:18:30,639 DEBUG TRAIN Batch 14/5700 loss 11.618104 loss_att 14.481864 loss_ctc 14.794692 loss_rnnt 10.498325 hw_loss 0.231528 lr 0.00045177 rank 4
2023-02-22 04:18:30,640 DEBUG TRAIN Batch 14/5700 loss 9.731381 loss_att 12.914029 loss_ctc 10.599132 loss_rnnt 8.927947 hw_loss 0.096008 lr 0.00045177 rank 7
2023-02-22 04:18:30,645 DEBUG TRAIN Batch 14/5700 loss 13.769498 loss_att 17.972876 loss_ctc 18.500278 loss_rnnt 12.206980 hw_loss 0.170758 lr 0.00045177 rank 3
2023-02-22 04:18:30,661 DEBUG TRAIN Batch 14/5700 loss 9.081487 loss_att 9.439060 loss_ctc 10.655207 loss_rnnt 8.652108 hw_loss 0.277564 lr 0.00045187 rank 1
2023-02-22 04:19:45,063 DEBUG TRAIN Batch 14/5800 loss 26.448891 loss_att 39.352074 loss_ctc 28.905148 loss_rnnt 23.473255 hw_loss 0.126557 lr 0.00045158 rank 7
2023-02-22 04:19:45,068 DEBUG TRAIN Batch 14/5800 loss 8.185634 loss_att 10.961804 loss_ctc 10.242594 loss_rnnt 7.323106 hw_loss 0.061935 lr 0.00045158 rank 5
2023-02-22 04:19:45,072 DEBUG TRAIN Batch 14/5800 loss 4.274692 loss_att 9.176203 loss_ctc 4.835331 loss_rnnt 3.108528 hw_loss 0.208332 lr 0.00045159 rank 2
2023-02-22 04:19:45,072 DEBUG TRAIN Batch 14/5800 loss 19.255348 loss_att 24.008068 loss_ctc 25.273312 loss_rnnt 17.426186 hw_loss 0.142916 lr 0.00045161 rank 0
2023-02-22 04:19:45,072 DEBUG TRAIN Batch 14/5800 loss 11.005683 loss_att 16.794159 loss_ctc 17.752760 loss_rnnt 8.837176 hw_loss 0.208501 lr 0.00045158 rank 4
2023-02-22 04:19:45,075 DEBUG TRAIN Batch 14/5800 loss 5.767979 loss_att 7.073161 loss_ctc 8.815104 loss_rnnt 5.023704 hw_loss 0.144293 lr 0.00045159 rank 3
2023-02-22 04:19:45,077 DEBUG TRAIN Batch 14/5800 loss 5.656965 loss_att 9.334431 loss_ctc 5.971275 loss_rnnt 4.808176 hw_loss 0.133853 lr 0.00045168 rank 1
2023-02-22 04:19:45,112 DEBUG TRAIN Batch 14/5800 loss 4.183028 loss_att 8.553535 loss_ctc 7.372291 loss_rnnt 2.786451 hw_loss 0.182326 lr 0.00045166 rank 6
2023-02-22 04:21:01,233 DEBUG TRAIN Batch 14/5900 loss 23.606106 loss_att 27.944256 loss_ctc 29.711182 loss_rnnt 21.877472 hw_loss 0.088108 lr 0.00045147 rank 6
2023-02-22 04:21:01,234 DEBUG TRAIN Batch 14/5900 loss 16.164736 loss_att 19.966265 loss_ctc 23.208059 loss_rnnt 14.381733 hw_loss 0.156725 lr 0.00045139 rank 5
2023-02-22 04:21:01,237 DEBUG TRAIN Batch 14/5900 loss 6.565935 loss_att 10.193914 loss_ctc 11.484416 loss_rnnt 5.124168 hw_loss 0.113201 lr 0.00045140 rank 7
2023-02-22 04:21:01,237 DEBUG TRAIN Batch 14/5900 loss 14.752677 loss_att 16.797848 loss_ctc 15.356357 loss_rnnt 14.197685 hw_loss 0.122749 lr 0.00045142 rank 0
2023-02-22 04:21:01,238 DEBUG TRAIN Batch 14/5900 loss 6.292122 loss_att 10.866858 loss_ctc 7.381563 loss_rnnt 5.163520 hw_loss 0.128244 lr 0.00045150 rank 1
2023-02-22 04:21:01,239 DEBUG TRAIN Batch 14/5900 loss 6.350902 loss_att 11.565339 loss_ctc 7.834643 loss_rnnt 4.989791 hw_loss 0.225735 lr 0.00045140 rank 3
2023-02-22 04:21:01,239 DEBUG TRAIN Batch 14/5900 loss 12.466262 loss_att 17.757212 loss_ctc 14.391529 loss_rnnt 11.102161 hw_loss 0.092265 lr 0.00045140 rank 4
2023-02-22 04:21:01,240 DEBUG TRAIN Batch 14/5900 loss 20.330484 loss_att 22.041246 loss_ctc 22.362829 loss_rnnt 19.686882 hw_loss 0.057134 lr 0.00045141 rank 2
2023-02-22 04:22:18,471 DEBUG TRAIN Batch 14/6000 loss 17.392599 loss_att 21.756649 loss_ctc 27.459444 loss_rnnt 15.063265 hw_loss 0.214269 lr 0.00045121 rank 7
2023-02-22 04:22:18,472 DEBUG TRAIN Batch 14/6000 loss 10.394081 loss_att 12.330793 loss_ctc 12.503252 loss_rnnt 9.620451 hw_loss 0.196997 lr 0.00045121 rank 5
2023-02-22 04:22:18,473 DEBUG TRAIN Batch 14/6000 loss 18.225672 loss_att 22.710373 loss_ctc 24.867134 loss_rnnt 16.429369 hw_loss 0.025933 lr 0.00045124 rank 0
2023-02-22 04:22:18,476 DEBUG TRAIN Batch 14/6000 loss 12.251235 loss_att 17.205353 loss_ctc 16.492493 loss_rnnt 10.602728 hw_loss 0.172843 lr 0.00045132 rank 1
2023-02-22 04:22:18,478 DEBUG TRAIN Batch 14/6000 loss 5.524083 loss_att 11.289478 loss_ctc 5.144889 loss_rnnt 4.361560 hw_loss 0.112505 lr 0.00045122 rank 3
2023-02-22 04:22:18,479 DEBUG TRAIN Batch 14/6000 loss 10.744271 loss_att 12.268006 loss_ctc 15.278540 loss_rnnt 9.732802 hw_loss 0.191536 lr 0.00045121 rank 4
2023-02-22 04:22:18,479 DEBUG TRAIN Batch 14/6000 loss 6.622670 loss_att 12.035997 loss_ctc 8.275740 loss_rnnt 5.296155 hw_loss 0.043950 lr 0.00045129 rank 6
2023-02-22 04:22:18,485 DEBUG TRAIN Batch 14/6000 loss 10.056005 loss_att 13.827860 loss_ctc 12.744167 loss_rnnt 8.872435 hw_loss 0.132709 lr 0.00045122 rank 2
2023-02-22 04:23:34,379 DEBUG TRAIN Batch 14/6100 loss 35.331570 loss_att 41.380508 loss_ctc 48.985832 loss_rnnt 32.245995 hw_loss 0.103531 lr 0.00045103 rank 4
2023-02-22 04:23:34,384 DEBUG TRAIN Batch 14/6100 loss 10.254681 loss_att 13.394163 loss_ctc 11.163977 loss_rnnt 9.441320 hw_loss 0.120420 lr 0.00045103 rank 7
2023-02-22 04:23:34,384 DEBUG TRAIN Batch 14/6100 loss 15.546962 loss_att 17.083317 loss_ctc 18.370928 loss_rnnt 14.832314 hw_loss 0.057843 lr 0.00045106 rank 0
2023-02-22 04:23:34,385 DEBUG TRAIN Batch 14/6100 loss 13.731591 loss_att 15.989223 loss_ctc 22.382786 loss_rnnt 12.045269 hw_loss 0.152442 lr 0.00045102 rank 5
2023-02-22 04:23:34,388 DEBUG TRAIN Batch 14/6100 loss 5.422806 loss_att 9.940829 loss_ctc 9.172133 loss_rnnt 3.999454 hw_loss 0.037194 lr 0.00045103 rank 3
2023-02-22 04:23:34,388 DEBUG TRAIN Batch 14/6100 loss 11.063472 loss_att 14.089428 loss_ctc 15.676294 loss_rnnt 9.797748 hw_loss 0.085295 lr 0.00045110 rank 6
2023-02-22 04:23:34,390 DEBUG TRAIN Batch 14/6100 loss 12.841673 loss_att 16.192757 loss_ctc 19.669638 loss_rnnt 11.187463 hw_loss 0.137996 lr 0.00045104 rank 2
2023-02-22 04:23:34,435 DEBUG TRAIN Batch 14/6100 loss 10.731644 loss_att 11.128119 loss_ctc 12.797155 loss_rnnt 10.336334 hw_loss 0.076149 lr 0.00045113 rank 1
2023-02-22 04:24:50,887 DEBUG TRAIN Batch 14/6200 loss 20.896673 loss_att 25.053661 loss_ctc 24.638929 loss_rnnt 19.492788 hw_loss 0.137847 lr 0.00045085 rank 7
2023-02-22 04:24:50,893 DEBUG TRAIN Batch 14/6200 loss 12.402268 loss_att 14.112955 loss_ctc 11.477737 loss_rnnt 12.126978 hw_loss 0.105794 lr 0.00045095 rank 1
2023-02-22 04:24:50,895 DEBUG TRAIN Batch 14/6200 loss 16.665504 loss_att 19.731266 loss_ctc 21.532066 loss_rnnt 15.305544 hw_loss 0.183619 lr 0.00045085 rank 4
2023-02-22 04:24:50,896 DEBUG TRAIN Batch 14/6200 loss 7.529747 loss_att 11.181526 loss_ctc 10.181238 loss_rnnt 6.348694 hw_loss 0.182185 lr 0.00045086 rank 2
2023-02-22 04:24:50,895 DEBUG TRAIN Batch 14/6200 loss 8.682774 loss_att 13.700845 loss_ctc 15.927141 loss_rnnt 6.582414 hw_loss 0.245304 lr 0.00045084 rank 5
2023-02-22 04:24:50,897 DEBUG TRAIN Batch 14/6200 loss 6.364485 loss_att 9.416325 loss_ctc 11.349751 loss_rnnt 5.004264 hw_loss 0.159659 lr 0.00045092 rank 6
2023-02-22 04:24:50,898 DEBUG TRAIN Batch 14/6200 loss 20.850733 loss_att 24.329666 loss_ctc 28.078421 loss_rnnt 19.176762 hw_loss 0.027175 lr 0.00045087 rank 0
2023-02-22 04:24:50,949 DEBUG TRAIN Batch 14/6200 loss 11.385670 loss_att 15.084143 loss_ctc 14.846886 loss_rnnt 10.120046 hw_loss 0.120812 lr 0.00045085 rank 3
2023-02-22 04:26:06,421 DEBUG TRAIN Batch 14/6300 loss 6.930667 loss_att 8.892745 loss_ctc 9.555037 loss_rnnt 6.173234 hw_loss 0.028316 lr 0.00045066 rank 7
2023-02-22 04:26:06,425 DEBUG TRAIN Batch 14/6300 loss 12.525456 loss_att 15.141489 loss_ctc 16.764776 loss_rnnt 11.392627 hw_loss 0.083216 lr 0.00045074 rank 6
2023-02-22 04:26:06,425 DEBUG TRAIN Batch 14/6300 loss 12.388824 loss_att 11.290931 loss_ctc 14.392508 loss_rnnt 12.241859 hw_loss 0.186349 lr 0.00045066 rank 5
2023-02-22 04:26:06,425 DEBUG TRAIN Batch 14/6300 loss 13.584897 loss_att 13.758692 loss_ctc 15.435440 loss_rnnt 13.185984 hw_loss 0.220152 lr 0.00045077 rank 1
2023-02-22 04:26:06,427 DEBUG TRAIN Batch 14/6300 loss 9.861705 loss_att 14.038771 loss_ctc 14.049750 loss_rnnt 8.417234 hw_loss 0.094972 lr 0.00045066 rank 4
2023-02-22 04:26:06,430 DEBUG TRAIN Batch 14/6300 loss 8.042331 loss_att 7.957540 loss_ctc 9.257030 loss_rnnt 7.774719 hw_loss 0.229894 lr 0.00045067 rank 2
2023-02-22 04:26:06,437 DEBUG TRAIN Batch 14/6300 loss 18.917362 loss_att 20.059122 loss_ctc 30.119278 loss_rnnt 17.064034 hw_loss 0.246354 lr 0.00045069 rank 0
2023-02-22 04:26:06,478 DEBUG TRAIN Batch 14/6300 loss 13.664328 loss_att 16.270214 loss_ctc 16.146236 loss_rnnt 12.689695 hw_loss 0.229749 lr 0.00045067 rank 3
2023-02-22 04:27:23,837 DEBUG TRAIN Batch 14/6400 loss 14.080327 loss_att 18.772957 loss_ctc 15.697590 loss_rnnt 12.873970 hw_loss 0.097866 lr 0.00045055 rank 6
2023-02-22 04:27:23,837 DEBUG TRAIN Batch 14/6400 loss 20.738836 loss_att 23.358784 loss_ctc 24.664572 loss_rnnt 19.575041 hw_loss 0.218202 lr 0.00045049 rank 3
2023-02-22 04:27:23,837 DEBUG TRAIN Batch 14/6400 loss 15.686192 loss_att 18.659891 loss_ctc 15.101630 loss_rnnt 15.065535 hw_loss 0.194735 lr 0.00045051 rank 0
2023-02-22 04:27:23,838 DEBUG TRAIN Batch 14/6400 loss 6.361502 loss_att 7.989290 loss_ctc 10.068805 loss_rnnt 5.442512 hw_loss 0.185861 lr 0.00045048 rank 4
2023-02-22 04:27:23,838 DEBUG TRAIN Batch 14/6400 loss 10.606761 loss_att 15.267040 loss_ctc 15.792681 loss_rnnt 8.958590 hw_loss 0.046237 lr 0.00045048 rank 7
2023-02-22 04:27:23,840 DEBUG TRAIN Batch 14/6400 loss 11.902641 loss_att 14.806210 loss_ctc 15.740985 loss_rnnt 10.728271 hw_loss 0.153522 lr 0.00045047 rank 5
2023-02-22 04:27:23,842 DEBUG TRAIN Batch 14/6400 loss 5.740197 loss_att 8.971651 loss_ctc 5.975351 loss_rnnt 4.992821 hw_loss 0.130746 lr 0.00045058 rank 1
2023-02-22 04:27:23,845 DEBUG TRAIN Batch 14/6400 loss 16.481045 loss_att 20.503954 loss_ctc 17.952625 loss_rnnt 15.448580 hw_loss 0.059384 lr 0.00045049 rank 2
2023-02-22 04:28:40,090 DEBUG TRAIN Batch 14/6500 loss 11.888415 loss_att 17.805405 loss_ctc 18.631310 loss_rnnt 9.778030 hw_loss 0.052377 lr 0.00045030 rank 7
2023-02-22 04:28:40,091 DEBUG TRAIN Batch 14/6500 loss 8.203569 loss_att 12.686766 loss_ctc 9.912845 loss_rnnt 6.987850 hw_loss 0.170955 lr 0.00045030 rank 3
2023-02-22 04:28:40,091 DEBUG TRAIN Batch 14/6500 loss 7.274212 loss_att 10.402810 loss_ctc 9.312727 loss_rnnt 6.342679 hw_loss 0.063771 lr 0.00045030 rank 4
2023-02-22 04:28:40,091 DEBUG TRAIN Batch 14/6500 loss 12.016863 loss_att 19.108276 loss_ctc 12.030577 loss_rnnt 10.531661 hw_loss 0.122045 lr 0.00045031 rank 2
2023-02-22 04:28:40,093 DEBUG TRAIN Batch 14/6500 loss 9.580054 loss_att 10.849863 loss_ctc 10.034297 loss_rnnt 9.191500 hw_loss 0.138800 lr 0.00045029 rank 5
2023-02-22 04:28:40,094 DEBUG TRAIN Batch 14/6500 loss 12.178809 loss_att 18.255226 loss_ctc 18.146469 loss_rnnt 10.133001 hw_loss 0.065317 lr 0.00045032 rank 0
2023-02-22 04:28:40,096 DEBUG TRAIN Batch 14/6500 loss 12.631401 loss_att 13.293939 loss_ctc 17.385551 loss_rnnt 11.772998 hw_loss 0.172516 lr 0.00045037 rank 6
2023-02-22 04:28:40,097 DEBUG TRAIN Batch 14/6500 loss 11.992147 loss_att 16.755323 loss_ctc 17.310766 loss_rnnt 10.264215 hw_loss 0.124030 lr 0.00045040 rank 1
2023-02-22 04:29:55,425 DEBUG TRAIN Batch 14/6600 loss 18.158497 loss_att 23.528637 loss_ctc 23.234421 loss_rnnt 16.312874 hw_loss 0.177758 lr 0.00045011 rank 4
2023-02-22 04:29:55,426 DEBUG TRAIN Batch 14/6600 loss 14.591084 loss_att 17.225708 loss_ctc 18.931047 loss_rnnt 13.416097 hw_loss 0.130123 lr 0.00045014 rank 0
2023-02-22 04:29:55,427 DEBUG TRAIN Batch 14/6600 loss 19.688665 loss_att 23.584276 loss_ctc 29.538498 loss_rnnt 17.480129 hw_loss 0.217698 lr 0.00045012 rank 3
2023-02-22 04:29:55,431 DEBUG TRAIN Batch 14/6600 loss 6.089551 loss_att 10.612716 loss_ctc 9.872271 loss_rnnt 4.595848 hw_loss 0.158828 lr 0.00045011 rank 5
2023-02-22 04:29:55,431 DEBUG TRAIN Batch 14/6600 loss 9.818810 loss_att 14.328752 loss_ctc 11.664713 loss_rnnt 8.602856 hw_loss 0.127211 lr 0.00045011 rank 7
2023-02-22 04:29:55,433 DEBUG TRAIN Batch 14/6600 loss 5.483825 loss_att 9.089641 loss_ctc 7.343935 loss_rnnt 4.418067 hw_loss 0.181089 lr 0.00045019 rank 6
2023-02-22 04:29:55,437 DEBUG TRAIN Batch 14/6600 loss 9.027463 loss_att 11.204857 loss_ctc 10.456291 loss_rnnt 8.314976 hw_loss 0.162183 lr 0.00045013 rank 2
2023-02-22 04:29:55,437 DEBUG TRAIN Batch 14/6600 loss 21.256224 loss_att 24.558712 loss_ctc 26.534904 loss_rnnt 19.855141 hw_loss 0.068926 lr 0.00045022 rank 1
2023-02-22 04:31:11,559 DEBUG TRAIN Batch 14/6700 loss 12.970634 loss_att 12.842472 loss_ctc 18.789761 loss_rnnt 12.140972 hw_loss 0.148895 lr 0.00044996 rank 0
2023-02-22 04:31:11,560 DEBUG TRAIN Batch 14/6700 loss 5.084285 loss_att 7.739203 loss_ctc 7.357849 loss_rnnt 4.179983 hw_loss 0.131581 lr 0.00044993 rank 7
2023-02-22 04:31:11,562 DEBUG TRAIN Batch 14/6700 loss 8.496129 loss_att 11.620718 loss_ctc 12.123489 loss_rnnt 7.314469 hw_loss 0.137049 lr 0.00044993 rank 5
2023-02-22 04:31:11,566 DEBUG TRAIN Batch 14/6700 loss 6.696750 loss_att 10.590978 loss_ctc 8.421075 loss_rnnt 5.586763 hw_loss 0.189810 lr 0.00044993 rank 4
2023-02-22 04:31:11,567 DEBUG TRAIN Batch 14/6700 loss 16.600945 loss_att 16.988693 loss_ctc 20.287931 loss_rnnt 15.985930 hw_loss 0.085997 lr 0.00045003 rank 1
2023-02-22 04:31:11,570 DEBUG TRAIN Batch 14/6700 loss 21.073921 loss_att 28.888298 loss_ctc 25.192699 loss_rnnt 18.866442 hw_loss 0.178940 lr 0.00044994 rank 2
2023-02-22 04:31:11,611 DEBUG TRAIN Batch 14/6700 loss 20.615101 loss_att 23.355944 loss_ctc 23.844770 loss_rnnt 19.601139 hw_loss 0.065946 lr 0.00045001 rank 6
2023-02-22 04:31:11,638 DEBUG TRAIN Batch 14/6700 loss 9.572659 loss_att 12.735727 loss_ctc 13.786383 loss_rnnt 8.340222 hw_loss 0.071234 lr 0.00044994 rank 3
2023-02-22 04:32:29,581 DEBUG TRAIN Batch 14/6800 loss 11.192793 loss_att 13.501490 loss_ctc 16.623314 loss_rnnt 9.900928 hw_loss 0.198854 lr 0.00044975 rank 7
2023-02-22 04:32:29,580 DEBUG TRAIN Batch 14/6800 loss 11.770809 loss_att 16.689976 loss_ctc 15.390862 loss_rnnt 10.277464 hw_loss 0.050322 lr 0.00044975 rank 4
2023-02-22 04:32:29,586 DEBUG TRAIN Batch 14/6800 loss 10.721902 loss_att 13.896263 loss_ctc 17.047808 loss_rnnt 9.174376 hw_loss 0.129750 lr 0.00044976 rank 2
2023-02-22 04:32:29,586 DEBUG TRAIN Batch 14/6800 loss 16.934582 loss_att 18.816299 loss_ctc 27.068035 loss_rnnt 15.060710 hw_loss 0.274505 lr 0.00044978 rank 0
2023-02-22 04:32:29,589 DEBUG TRAIN Batch 14/6800 loss 17.064110 loss_att 18.223602 loss_ctc 20.418198 loss_rnnt 16.364567 hw_loss 0.038308 lr 0.00044974 rank 5
2023-02-22 04:32:29,590 DEBUG TRAIN Batch 14/6800 loss 18.544252 loss_att 21.133198 loss_ctc 24.277103 loss_rnnt 17.187685 hw_loss 0.139492 lr 0.00044982 rank 6
2023-02-22 04:32:29,589 DEBUG TRAIN Batch 14/6800 loss 13.037741 loss_att 14.125360 loss_ctc 24.638386 loss_rnnt 11.168590 hw_loss 0.196641 lr 0.00044985 rank 1
2023-02-22 04:32:29,590 DEBUG TRAIN Batch 14/6800 loss 11.499650 loss_att 14.682457 loss_ctc 20.598385 loss_rnnt 9.570942 hw_loss 0.148091 lr 0.00044976 rank 3
2023-02-22 04:33:45,245 DEBUG TRAIN Batch 14/6900 loss 25.696646 loss_att 25.123978 loss_ctc 31.787382 loss_rnnt 24.894354 hw_loss 0.196365 lr 0.00044956 rank 5
2023-02-22 04:33:45,249 DEBUG TRAIN Batch 14/6900 loss 5.142551 loss_att 5.822177 loss_ctc 8.048114 loss_rnnt 4.587909 hw_loss 0.058703 lr 0.00044957 rank 7
2023-02-22 04:33:45,249 DEBUG TRAIN Batch 14/6900 loss 13.441282 loss_att 15.341084 loss_ctc 19.170567 loss_rnnt 12.163940 hw_loss 0.250268 lr 0.00044960 rank 0
2023-02-22 04:33:45,252 DEBUG TRAIN Batch 14/6900 loss 12.188762 loss_att 13.386728 loss_ctc 18.173374 loss_rnnt 11.103566 hw_loss 0.089353 lr 0.00044967 rank 1
2023-02-22 04:33:45,253 DEBUG TRAIN Batch 14/6900 loss 10.988660 loss_att 12.535726 loss_ctc 15.038979 loss_rnnt 10.043941 hw_loss 0.178621 lr 0.00044957 rank 4
2023-02-22 04:33:45,253 DEBUG TRAIN Batch 14/6900 loss 8.370725 loss_att 9.320290 loss_ctc 10.936400 loss_rnnt 7.784654 hw_loss 0.101375 lr 0.00044964 rank 6
2023-02-22 04:33:45,257 DEBUG TRAIN Batch 14/6900 loss 10.088815 loss_att 11.343016 loss_ctc 13.402843 loss_rnnt 9.303837 hw_loss 0.173002 lr 0.00044958 rank 2
2023-02-22 04:33:45,302 DEBUG TRAIN Batch 14/6900 loss 14.552423 loss_att 17.187862 loss_ctc 17.657431 loss_rnnt 13.589762 hw_loss 0.040444 lr 0.00044957 rank 3
2023-02-22 04:34:59,926 DEBUG TRAIN Batch 14/7000 loss 6.455906 loss_att 11.082479 loss_ctc 8.646399 loss_rnnt 5.212419 hw_loss 0.048950 lr 0.00044938 rank 5
2023-02-22 04:34:59,927 DEBUG TRAIN Batch 14/7000 loss 7.835265 loss_att 12.188047 loss_ctc 10.180396 loss_rnnt 6.545775 hw_loss 0.199216 lr 0.00044939 rank 7
2023-02-22 04:34:59,930 DEBUG TRAIN Batch 14/7000 loss 15.908119 loss_att 19.582296 loss_ctc 20.802547 loss_rnnt 14.490095 hw_loss 0.057373 lr 0.00044941 rank 0
2023-02-22 04:34:59,934 DEBUG TRAIN Batch 14/7000 loss 12.289679 loss_att 13.857245 loss_ctc 14.816622 loss_rnnt 11.573617 hw_loss 0.123042 lr 0.00044939 rank 4
2023-02-22 04:34:59,935 DEBUG TRAIN Batch 14/7000 loss 8.109222 loss_att 9.445907 loss_ctc 8.662579 loss_rnnt 7.656517 hw_loss 0.209229 lr 0.00044939 rank 3
2023-02-22 04:34:59,938 DEBUG TRAIN Batch 14/7000 loss 9.584322 loss_att 13.115911 loss_ctc 14.804785 loss_rnnt 8.101110 hw_loss 0.151557 lr 0.00044940 rank 2
2023-02-22 04:34:59,937 DEBUG TRAIN Batch 14/7000 loss 8.605173 loss_att 12.967153 loss_ctc 7.104372 loss_rnnt 7.874557 hw_loss 0.109361 lr 0.00044946 rank 6
2023-02-22 04:34:59,975 DEBUG TRAIN Batch 14/7000 loss 3.529831 loss_att 6.368071 loss_ctc 3.887384 loss_rnnt 2.855812 hw_loss 0.110057 lr 0.00044949 rank 1
2023-02-22 04:36:18,319 DEBUG TRAIN Batch 14/7100 loss 10.627908 loss_att 10.974147 loss_ctc 13.081543 loss_rnnt 10.107904 hw_loss 0.231757 lr 0.00044921 rank 3
2023-02-22 04:36:18,321 DEBUG TRAIN Batch 14/7100 loss 6.126658 loss_att 9.081741 loss_ctc 8.349180 loss_rnnt 5.192935 hw_loss 0.086944 lr 0.00044920 rank 5
2023-02-22 04:36:18,322 DEBUG TRAIN Batch 14/7100 loss 5.602270 loss_att 7.728634 loss_ctc 9.572838 loss_rnnt 4.621966 hw_loss 0.048041 lr 0.00044921 rank 4
2023-02-22 04:36:18,323 DEBUG TRAIN Batch 14/7100 loss 13.493000 loss_att 17.128300 loss_ctc 17.289709 loss_rnnt 12.213022 hw_loss 0.087542 lr 0.00044921 rank 7
2023-02-22 04:36:18,323 DEBUG TRAIN Batch 14/7100 loss 17.580265 loss_att 17.913246 loss_ctc 23.872250 loss_rnnt 16.603706 hw_loss 0.133179 lr 0.00044931 rank 1
2023-02-22 04:36:18,324 DEBUG TRAIN Batch 14/7100 loss 5.632496 loss_att 11.097738 loss_ctc 12.041660 loss_rnnt 3.645586 hw_loss 0.073701 lr 0.00044922 rank 2
2023-02-22 04:36:18,324 DEBUG TRAIN Batch 14/7100 loss 6.776775 loss_att 9.431546 loss_ctc 8.173079 loss_rnnt 6.058065 hw_loss 0.002968 lr 0.00044923 rank 0
2023-02-22 04:36:18,329 DEBUG TRAIN Batch 14/7100 loss 3.991577 loss_att 7.466397 loss_ctc 4.587935 loss_rnnt 3.139947 hw_loss 0.144661 lr 0.00044928 rank 6
2023-02-22 04:37:33,905 DEBUG TRAIN Batch 14/7200 loss 13.628665 loss_att 18.988077 loss_ctc 20.826012 loss_rnnt 11.508827 hw_loss 0.165579 lr 0.00044902 rank 4
2023-02-22 04:37:33,911 DEBUG TRAIN Batch 14/7200 loss 20.357899 loss_att 24.603004 loss_ctc 25.497925 loss_rnnt 18.823488 hw_loss 0.000095 lr 0.00044905 rank 0
2023-02-22 04:37:33,911 DEBUG TRAIN Batch 14/7200 loss 14.453297 loss_att 18.433178 loss_ctc 17.614073 loss_rnnt 13.157578 hw_loss 0.146826 lr 0.00044902 rank 7
2023-02-22 04:37:33,914 DEBUG TRAIN Batch 14/7200 loss 7.761474 loss_att 10.064458 loss_ctc 11.282701 loss_rnnt 6.794198 hw_loss 0.069714 lr 0.00044902 rank 5
2023-02-22 04:37:33,915 DEBUG TRAIN Batch 14/7200 loss 8.779772 loss_att 15.938730 loss_ctc 11.265684 loss_rnnt 6.988174 hw_loss 0.053157 lr 0.00044903 rank 3
2023-02-22 04:37:33,916 DEBUG TRAIN Batch 14/7200 loss 12.638121 loss_att 17.315950 loss_ctc 16.844759 loss_rnnt 11.062180 hw_loss 0.149044 lr 0.00044913 rank 1
2023-02-22 04:37:33,916 DEBUG TRAIN Batch 14/7200 loss 10.625259 loss_att 14.675659 loss_ctc 15.485655 loss_rnnt 9.121325 hw_loss 0.085876 lr 0.00044910 rank 6
2023-02-22 04:37:33,917 DEBUG TRAIN Batch 14/7200 loss 11.194375 loss_att 13.213035 loss_ctc 12.576340 loss_rnnt 10.456492 hw_loss 0.281040 lr 0.00044903 rank 2
2023-02-22 04:38:48,981 DEBUG TRAIN Batch 14/7300 loss 9.953109 loss_att 13.005392 loss_ctc 12.437862 loss_rnnt 8.853659 hw_loss 0.295676 lr 0.00044884 rank 4
2023-02-22 04:38:48,983 DEBUG TRAIN Batch 14/7300 loss 10.502989 loss_att 16.747822 loss_ctc 14.398932 loss_rnnt 8.664593 hw_loss 0.131194 lr 0.00044884 rank 7
2023-02-22 04:38:48,985 DEBUG TRAIN Batch 14/7300 loss 5.068640 loss_att 8.393085 loss_ctc 6.976768 loss_rnnt 4.107925 hw_loss 0.077641 lr 0.00044884 rank 5
2023-02-22 04:38:48,986 DEBUG TRAIN Batch 14/7300 loss 9.108524 loss_att 11.277287 loss_ctc 12.240030 loss_rnnt 8.221475 hw_loss 0.067055 lr 0.00044892 rank 6
2023-02-22 04:38:48,987 DEBUG TRAIN Batch 14/7300 loss 10.446466 loss_att 15.106413 loss_ctc 13.317842 loss_rnnt 9.008087 hw_loss 0.231638 lr 0.00044887 rank 0
2023-02-22 04:38:48,992 DEBUG TRAIN Batch 14/7300 loss 16.690765 loss_att 21.593628 loss_ctc 23.902676 loss_rnnt 14.735099 hw_loss 0.025327 lr 0.00044885 rank 3
2023-02-22 04:38:48,994 DEBUG TRAIN Batch 14/7300 loss 13.622231 loss_att 13.060495 loss_ctc 18.242592 loss_rnnt 13.046453 hw_loss 0.135148 lr 0.00044885 rank 2
2023-02-22 04:38:49,036 DEBUG TRAIN Batch 14/7300 loss 15.025207 loss_att 18.557531 loss_ctc 16.388340 loss_rnnt 14.032248 hw_loss 0.196392 lr 0.00044894 rank 1
2023-02-22 04:40:04,996 DEBUG TRAIN Batch 14/7400 loss 13.234997 loss_att 18.270975 loss_ctc 14.632777 loss_rnnt 11.950953 hw_loss 0.169645 lr 0.00044866 rank 7
2023-02-22 04:40:04,997 DEBUG TRAIN Batch 14/7400 loss 21.485523 loss_att 23.882418 loss_ctc 24.184772 loss_rnnt 20.608553 hw_loss 0.070667 lr 0.00044874 rank 6
2023-02-22 04:40:05,001 DEBUG TRAIN Batch 14/7400 loss 17.481520 loss_att 18.883677 loss_ctc 21.335405 loss_rnnt 16.592939 hw_loss 0.176807 lr 0.00044866 rank 5
2023-02-22 04:40:05,001 DEBUG TRAIN Batch 14/7400 loss 9.784432 loss_att 14.056271 loss_ctc 12.629189 loss_rnnt 8.488500 hw_loss 0.116743 lr 0.00044866 rank 4
2023-02-22 04:40:05,003 DEBUG TRAIN Batch 14/7400 loss 13.533001 loss_att 18.099789 loss_ctc 21.147068 loss_rnnt 11.498810 hw_loss 0.198045 lr 0.00044867 rank 3
2023-02-22 04:40:05,003 DEBUG TRAIN Batch 14/7400 loss 11.339013 loss_att 16.407707 loss_ctc 14.585751 loss_rnnt 9.797624 hw_loss 0.177659 lr 0.00044876 rank 1
2023-02-22 04:40:05,007 DEBUG TRAIN Batch 14/7400 loss 10.068913 loss_att 12.153473 loss_ctc 12.628745 loss_rnnt 9.263922 hw_loss 0.087691 lr 0.00044867 rank 2
2023-02-22 04:40:05,008 DEBUG TRAIN Batch 14/7400 loss 39.840073 loss_att 43.454300 loss_ctc 57.020172 loss_rnnt 36.774471 hw_loss 0.097641 lr 0.00044869 rank 0
2023-02-22 04:41:22,791 DEBUG TRAIN Batch 14/7500 loss 11.661238 loss_att 11.656351 loss_ctc 10.401093 loss_rnnt 11.714923 hw_loss 0.216209 lr 0.00044848 rank 7
2023-02-22 04:41:22,793 DEBUG TRAIN Batch 14/7500 loss 13.532251 loss_att 16.091394 loss_ctc 19.467482 loss_rnnt 12.214754 hw_loss 0.026821 lr 0.00044858 rank 1
2023-02-22 04:41:22,793 DEBUG TRAIN Batch 14/7500 loss 7.942003 loss_att 11.652885 loss_ctc 11.844501 loss_rnnt 6.574502 hw_loss 0.196859 lr 0.00044851 rank 0
2023-02-22 04:41:22,793 DEBUG TRAIN Batch 14/7500 loss 16.799274 loss_att 19.733240 loss_ctc 19.813875 loss_rnnt 15.772088 hw_loss 0.072090 lr 0.00044848 rank 4
2023-02-22 04:41:22,795 DEBUG TRAIN Batch 14/7500 loss 0.932627 loss_att 3.150386 loss_ctc 1.472120 loss_rnnt 0.399662 hw_loss 0.032776 lr 0.00044856 rank 6
2023-02-22 04:41:22,795 DEBUG TRAIN Batch 14/7500 loss 12.400964 loss_att 13.693280 loss_ctc 15.842429 loss_rnnt 11.594054 hw_loss 0.167969 lr 0.00044848 rank 5
2023-02-22 04:41:22,805 DEBUG TRAIN Batch 14/7500 loss 11.952699 loss_att 16.592466 loss_ctc 15.395324 loss_rnnt 10.505768 hw_loss 0.112425 lr 0.00044849 rank 3
2023-02-22 04:41:22,806 DEBUG TRAIN Batch 14/7500 loss 16.290268 loss_att 16.375252 loss_ctc 21.219477 loss_rnnt 15.551959 hw_loss 0.120160 lr 0.00044849 rank 2
2023-02-22 04:42:37,630 DEBUG TRAIN Batch 14/7600 loss 21.847876 loss_att 23.307331 loss_ctc 29.578465 loss_rnnt 20.463768 hw_loss 0.115261 lr 0.00044830 rank 7
2023-02-22 04:42:37,633 DEBUG TRAIN Batch 14/7600 loss 18.697138 loss_att 25.302906 loss_ctc 27.645409 loss_rnnt 16.033772 hw_loss 0.279581 lr 0.00044830 rank 4
2023-02-22 04:42:37,633 DEBUG TRAIN Batch 14/7600 loss 13.037033 loss_att 18.199619 loss_ctc 15.871119 loss_rnnt 11.588851 hw_loss 0.070851 lr 0.00044830 rank 5
2023-02-22 04:42:37,636 DEBUG TRAIN Batch 14/7600 loss 8.940887 loss_att 8.432028 loss_ctc 10.781275 loss_rnnt 8.673300 hw_loss 0.232453 lr 0.00044840 rank 1
2023-02-22 04:42:37,636 DEBUG TRAIN Batch 14/7600 loss 10.831526 loss_att 13.764621 loss_ctc 10.654858 loss_rnnt 10.185805 hw_loss 0.154981 lr 0.00044831 rank 2
2023-02-22 04:42:37,636 DEBUG TRAIN Batch 14/7600 loss 17.091631 loss_att 17.354958 loss_ctc 24.943075 loss_rnnt 15.861704 hw_loss 0.244504 lr 0.00044833 rank 0
2023-02-22 04:42:37,641 DEBUG TRAIN Batch 14/7600 loss 9.929598 loss_att 11.193246 loss_ctc 16.573774 loss_rnnt 8.686698 hw_loss 0.195528 lr 0.00044838 rank 6
2023-02-22 04:42:37,642 DEBUG TRAIN Batch 14/7600 loss 29.862999 loss_att 24.948242 loss_ctc 35.585674 loss_rnnt 29.909883 hw_loss 0.324454 lr 0.00044831 rank 3
2023-02-22 04:43:52,460 DEBUG TRAIN Batch 14/7700 loss 28.802034 loss_att 28.517605 loss_ctc 34.255234 loss_rnnt 28.041111 hw_loss 0.170088 lr 0.00044812 rank 4
2023-02-22 04:43:52,462 DEBUG TRAIN Batch 14/7700 loss 9.708897 loss_att 13.975496 loss_ctc 12.551311 loss_rnnt 8.399254 hw_loss 0.145001 lr 0.00044812 rank 5
2023-02-22 04:43:52,462 DEBUG TRAIN Batch 14/7700 loss 9.828273 loss_att 14.521757 loss_ctc 11.846786 loss_rnnt 8.550930 hw_loss 0.130331 lr 0.00044813 rank 2
2023-02-22 04:43:52,464 DEBUG TRAIN Batch 14/7700 loss 17.870975 loss_att 21.095379 loss_ctc 24.396544 loss_rnnt 16.330269 hw_loss 0.048282 lr 0.00044812 rank 7
2023-02-22 04:43:52,468 DEBUG TRAIN Batch 14/7700 loss 10.666364 loss_att 17.416929 loss_ctc 17.510509 loss_rnnt 8.280476 hw_loss 0.231042 lr 0.00044815 rank 0
2023-02-22 04:43:52,470 DEBUG TRAIN Batch 14/7700 loss 19.304100 loss_att 21.500483 loss_ctc 24.398329 loss_rnnt 18.083008 hw_loss 0.192345 lr 0.00044813 rank 3
2023-02-22 04:43:52,489 DEBUG TRAIN Batch 14/7700 loss 5.618637 loss_att 11.599921 loss_ctc 7.053425 loss_rnnt 4.139525 hw_loss 0.171656 lr 0.00044820 rank 6
2023-02-22 04:43:52,517 DEBUG TRAIN Batch 14/7700 loss 11.726283 loss_att 17.065845 loss_ctc 15.990358 loss_rnnt 10.040276 hw_loss 0.092909 lr 0.00044822 rank 1
2023-02-22 04:45:11,718 DEBUG TRAIN Batch 14/7800 loss 7.596869 loss_att 13.243612 loss_ctc 10.851866 loss_rnnt 5.911155 hw_loss 0.229436 lr 0.00044797 rank 0
2023-02-22 04:45:11,720 DEBUG TRAIN Batch 14/7800 loss 6.931304 loss_att 9.873902 loss_ctc 10.747719 loss_rnnt 5.754179 hw_loss 0.149533 lr 0.00044794 rank 5
2023-02-22 04:45:11,720 DEBUG TRAIN Batch 14/7800 loss 14.167240 loss_att 16.491037 loss_ctc 20.905468 loss_rnnt 12.739482 hw_loss 0.121065 lr 0.00044802 rank 6
2023-02-22 04:45:11,721 DEBUG TRAIN Batch 14/7800 loss 9.979488 loss_att 12.572215 loss_ctc 13.808520 loss_rnnt 8.908649 hw_loss 0.078291 lr 0.00044794 rank 7
2023-02-22 04:45:11,724 DEBUG TRAIN Batch 14/7800 loss 13.583963 loss_att 21.084641 loss_ctc 19.486355 loss_rnnt 11.227768 hw_loss 0.129516 lr 0.00044794 rank 4
2023-02-22 04:45:11,725 DEBUG TRAIN Batch 14/7800 loss 11.992986 loss_att 14.556057 loss_ctc 17.368843 loss_rnnt 10.725852 hw_loss 0.070761 lr 0.00044795 rank 2
2023-02-22 04:45:11,732 DEBUG TRAIN Batch 14/7800 loss 20.379877 loss_att 20.893312 loss_ctc 22.946661 loss_rnnt 19.894089 hw_loss 0.076617 lr 0.00044804 rank 1
2023-02-22 04:45:11,737 DEBUG TRAIN Batch 14/7800 loss 4.201085 loss_att 9.493692 loss_ctc 8.633305 loss_rnnt 2.497134 hw_loss 0.102122 lr 0.00044795 rank 3
2023-02-22 04:46:27,739 DEBUG TRAIN Batch 14/7900 loss 9.867829 loss_att 13.203516 loss_ctc 12.748739 loss_rnnt 8.762367 hw_loss 0.101630 lr 0.00044776 rank 7
2023-02-22 04:46:27,740 DEBUG TRAIN Batch 14/7900 loss 1.526521 loss_att 3.945096 loss_ctc 2.120249 loss_rnnt 0.806812 hw_loss 0.294056 lr 0.00044779 rank 0
2023-02-22 04:46:27,740 DEBUG TRAIN Batch 14/7900 loss 8.194160 loss_att 10.415147 loss_ctc 9.404346 loss_rnnt 7.545387 hw_loss 0.081033 lr 0.00044786 rank 1
2023-02-22 04:46:27,742 DEBUG TRAIN Batch 14/7900 loss 6.275170 loss_att 10.534872 loss_ctc 9.733453 loss_rnnt 4.870635 hw_loss 0.171545 lr 0.00044776 rank 5
2023-02-22 04:46:27,742 DEBUG TRAIN Batch 14/7900 loss 5.080945 loss_att 8.555637 loss_ctc 5.904935 loss_rnnt 4.236444 hw_loss 0.074430 lr 0.00044776 rank 4
2023-02-22 04:46:27,746 DEBUG TRAIN Batch 14/7900 loss 12.645723 loss_att 17.331228 loss_ctc 20.205463 loss_rnnt 10.640166 hw_loss 0.113420 lr 0.00044777 rank 2
2023-02-22 04:46:27,747 DEBUG TRAIN Batch 14/7900 loss 17.054981 loss_att 20.745483 loss_ctc 19.205376 loss_rnnt 16.007481 hw_loss 0.042526 lr 0.00044784 rank 6
2023-02-22 04:46:27,793 DEBUG TRAIN Batch 14/7900 loss 25.747192 loss_att 24.958031 loss_ctc 28.089172 loss_rnnt 25.592701 hw_loss 0.000103 lr 0.00044777 rank 3
2023-02-22 04:47:42,647 DEBUG TRAIN Batch 14/8000 loss 6.287055 loss_att 9.402861 loss_ctc 7.948985 loss_rnnt 5.396043 hw_loss 0.086740 lr 0.00044758 rank 4
2023-02-22 04:47:42,653 DEBUG TRAIN Batch 14/8000 loss 7.740263 loss_att 11.267439 loss_ctc 11.425446 loss_rnnt 6.468924 hw_loss 0.139774 lr 0.00044758 rank 7
2023-02-22 04:47:42,653 DEBUG TRAIN Batch 14/8000 loss 6.606585 loss_att 9.692053 loss_ctc 12.411278 loss_rnnt 5.190418 hw_loss 0.047089 lr 0.00044759 rank 3
2023-02-22 04:47:42,654 DEBUG TRAIN Batch 14/8000 loss 8.773026 loss_att 9.954550 loss_ctc 10.842785 loss_rnnt 8.177920 hw_loss 0.155311 lr 0.00044758 rank 5
2023-02-22 04:47:42,658 DEBUG TRAIN Batch 14/8000 loss 18.353086 loss_att 22.887520 loss_ctc 23.629131 loss_rnnt 16.668236 hw_loss 0.139671 lr 0.00044768 rank 1
2023-02-22 04:47:42,659 DEBUG TRAIN Batch 14/8000 loss 12.617999 loss_att 14.571979 loss_ctc 17.794628 loss_rnnt 11.461246 hw_loss 0.142011 lr 0.00044761 rank 0
2023-02-22 04:47:42,661 DEBUG TRAIN Batch 14/8000 loss 16.633762 loss_att 18.578737 loss_ctc 20.807480 loss_rnnt 15.622004 hw_loss 0.124253 lr 0.00044759 rank 2
2023-02-22 04:47:42,663 DEBUG TRAIN Batch 14/8000 loss 10.850046 loss_att 16.279644 loss_ctc 16.768461 loss_rnnt 8.957308 hw_loss 0.033181 lr 0.00044766 rank 6
2023-02-22 04:48:58,654 DEBUG TRAIN Batch 14/8100 loss 6.273717 loss_att 8.913967 loss_ctc 10.355809 loss_rnnt 5.121371 hw_loss 0.150031 lr 0.00044741 rank 2
2023-02-22 04:48:58,654 DEBUG TRAIN Batch 14/8100 loss 15.990499 loss_att 24.569790 loss_ctc 24.302868 loss_rnnt 13.135137 hw_loss 0.058478 lr 0.00044740 rank 4
2023-02-22 04:48:58,655 DEBUG TRAIN Batch 14/8100 loss 8.326127 loss_att 9.972374 loss_ctc 9.913130 loss_rnnt 7.720525 hw_loss 0.121409 lr 0.00044743 rank 0
2023-02-22 04:48:58,656 DEBUG TRAIN Batch 14/8100 loss 8.175815 loss_att 10.329752 loss_ctc 10.440135 loss_rnnt 7.359533 hw_loss 0.156723 lr 0.00044740 rank 5
2023-02-22 04:48:58,657 DEBUG TRAIN Batch 14/8100 loss 16.436678 loss_att 17.663887 loss_ctc 22.989996 loss_rnnt 15.256436 hw_loss 0.114417 lr 0.00044750 rank 1
2023-02-22 04:48:58,657 DEBUG TRAIN Batch 14/8100 loss 11.872167 loss_att 15.076637 loss_ctc 14.771196 loss_rnnt 10.821383 hw_loss 0.043786 lr 0.00044741 rank 3
2023-02-22 04:48:58,658 DEBUG TRAIN Batch 14/8100 loss 7.566895 loss_att 10.625390 loss_ctc 11.247395 loss_rnnt 6.405578 hw_loss 0.110410 lr 0.00044740 rank 7
2023-02-22 04:48:58,663 DEBUG TRAIN Batch 14/8100 loss 15.007303 loss_att 18.305756 loss_ctc 20.617666 loss_rnnt 13.524972 hw_loss 0.139860 lr 0.00044748 rank 6
2023-02-22 04:50:14,867 DEBUG TRAIN Batch 14/8200 loss 6.199862 loss_att 6.993779 loss_ctc 6.989479 loss_rnnt 5.872131 hw_loss 0.119370 lr 0.00044722 rank 5
2023-02-22 04:50:14,870 DEBUG TRAIN Batch 14/8200 loss 14.300413 loss_att 18.147068 loss_ctc 20.176205 loss_rnnt 12.660679 hw_loss 0.163057 lr 0.00044722 rank 4
2023-02-22 04:50:14,872 DEBUG TRAIN Batch 14/8200 loss 13.276710 loss_att 14.904587 loss_ctc 17.977354 loss_rnnt 12.235892 hw_loss 0.165917 lr 0.00044732 rank 1
2023-02-22 04:50:14,873 DEBUG TRAIN Batch 14/8200 loss 14.278519 loss_att 16.462708 loss_ctc 18.639494 loss_rnnt 13.190841 hw_loss 0.130082 lr 0.00044730 rank 6
2023-02-22 04:50:14,874 DEBUG TRAIN Batch 14/8200 loss 13.311747 loss_att 15.802855 loss_ctc 16.080511 loss_rnnt 12.352239 hw_loss 0.172719 lr 0.00044725 rank 0
2023-02-22 04:50:14,876 DEBUG TRAIN Batch 14/8200 loss 13.768124 loss_att 17.576786 loss_ctc 20.793074 loss_rnnt 12.004731 hw_loss 0.121876 lr 0.00044722 rank 7
2023-02-22 04:50:14,879 DEBUG TRAIN Batch 14/8200 loss 19.833763 loss_att 21.758753 loss_ctc 24.356697 loss_rnnt 18.795385 hw_loss 0.094358 lr 0.00044724 rank 2
2023-02-22 04:50:14,879 DEBUG TRAIN Batch 14/8200 loss 7.790745 loss_att 9.801797 loss_ctc 13.357985 loss_rnnt 6.598193 hw_loss 0.090081 lr 0.00044723 rank 3
2023-02-22 04:51:28,939 DEBUG TRAIN Batch 14/8300 loss 9.368554 loss_att 12.672071 loss_ctc 18.833908 loss_rnnt 7.372739 hw_loss 0.136995 lr 0.00044705 rank 7
2023-02-22 04:51:28,941 DEBUG TRAIN Batch 14/8300 loss 26.718817 loss_att 26.525122 loss_ctc 34.740448 loss_rnnt 25.593868 hw_loss 0.176511 lr 0.00044707 rank 0
2023-02-22 04:51:28,943 DEBUG TRAIN Batch 14/8300 loss 9.886763 loss_att 13.276027 loss_ctc 14.310104 loss_rnnt 8.579790 hw_loss 0.073762 lr 0.00044705 rank 3
2023-02-22 04:51:28,945 DEBUG TRAIN Batch 14/8300 loss 12.470248 loss_att 19.752174 loss_ctc 17.128504 loss_rnnt 10.392670 hw_loss 0.000175 lr 0.00044712 rank 6
2023-02-22 04:51:28,946 DEBUG TRAIN Batch 14/8300 loss 13.892324 loss_att 16.598257 loss_ctc 18.822182 loss_rnnt 12.662004 hw_loss 0.059661 lr 0.00044715 rank 1
2023-02-22 04:51:28,948 DEBUG TRAIN Batch 14/8300 loss 7.527215 loss_att 10.515947 loss_ctc 9.944250 loss_rnnt 6.607169 hw_loss 0.000054 lr 0.00044706 rank 2
2023-02-22 04:51:28,975 DEBUG TRAIN Batch 14/8300 loss 10.357314 loss_att 12.250629 loss_ctc 13.341763 loss_rnnt 9.502401 hw_loss 0.146854 lr 0.00044705 rank 4
2023-02-22 04:51:28,986 DEBUG TRAIN Batch 14/8300 loss 9.497006 loss_att 13.027502 loss_ctc 12.667187 loss_rnnt 8.307144 hw_loss 0.114510 lr 0.00044704 rank 5
2023-02-22 04:52:17,925 DEBUG CV Batch 14/0 loss 2.136397 loss_att 2.132456 loss_ctc 2.896633 loss_rnnt 1.895602 hw_loss 0.262909 history loss 2.057271 rank 1
2023-02-22 04:52:17,927 DEBUG CV Batch 14/0 loss 2.136397 loss_att 2.132456 loss_ctc 2.896633 loss_rnnt 1.895602 hw_loss 0.262909 history loss 2.057271 rank 3
2023-02-22 04:52:17,929 DEBUG CV Batch 14/0 loss 2.136397 loss_att 2.132456 loss_ctc 2.896633 loss_rnnt 1.895602 hw_loss 0.262909 history loss 2.057271 rank 4
2023-02-22 04:52:17,934 DEBUG CV Batch 14/0 loss 2.136397 loss_att 2.132456 loss_ctc 2.896633 loss_rnnt 1.895602 hw_loss 0.262909 history loss 2.057271 rank 0
2023-02-22 04:52:17,934 DEBUG CV Batch 14/0 loss 2.136397 loss_att 2.132456 loss_ctc 2.896633 loss_rnnt 1.895602 hw_loss 0.262909 history loss 2.057271 rank 5
2023-02-22 04:52:17,935 DEBUG CV Batch 14/0 loss 2.136397 loss_att 2.132456 loss_ctc 2.896633 loss_rnnt 1.895602 hw_loss 0.262909 history loss 2.057271 rank 2
2023-02-22 04:52:17,945 DEBUG CV Batch 14/0 loss 2.136397 loss_att 2.132456 loss_ctc 2.896633 loss_rnnt 1.895602 hw_loss 0.262909 history loss 2.057271 rank 7
2023-02-22 04:52:17,950 DEBUG CV Batch 14/0 loss 2.136397 loss_att 2.132456 loss_ctc 2.896633 loss_rnnt 1.895602 hw_loss 0.262909 history loss 2.057271 rank 6
2023-02-22 04:52:29,098 DEBUG CV Batch 14/100 loss 10.570991 loss_att 10.673274 loss_ctc 12.931963 loss_rnnt 10.109614 hw_loss 0.236481 history loss 3.943091 rank 7
2023-02-22 04:52:29,107 DEBUG CV Batch 14/100 loss 10.570991 loss_att 10.673274 loss_ctc 12.931963 loss_rnnt 10.109614 hw_loss 0.236481 history loss 3.943091 rank 0
2023-02-22 04:52:29,116 DEBUG CV Batch 14/100 loss 10.570991 loss_att 10.673274 loss_ctc 12.931963 loss_rnnt 10.109614 hw_loss 0.236481 history loss 3.943091 rank 4
2023-02-22 04:52:29,132 DEBUG CV Batch 14/100 loss 10.570991 loss_att 10.673274 loss_ctc 12.931963 loss_rnnt 10.109614 hw_loss 0.236481 history loss 3.943091 rank 5
2023-02-22 04:52:29,180 DEBUG CV Batch 14/100 loss 10.570991 loss_att 10.673274 loss_ctc 12.931963 loss_rnnt 10.109614 hw_loss 0.236481 history loss 3.943091 rank 1
2023-02-22 04:52:29,239 DEBUG CV Batch 14/100 loss 10.570991 loss_att 10.673274 loss_ctc 12.931963 loss_rnnt 10.109614 hw_loss 0.236481 history loss 3.943091 rank 3
2023-02-22 04:52:29,390 DEBUG CV Batch 14/100 loss 10.570991 loss_att 10.673274 loss_ctc 12.931963 loss_rnnt 10.109614 hw_loss 0.236481 history loss 3.943091 rank 2
2023-02-22 04:52:29,828 DEBUG CV Batch 14/100 loss 10.570991 loss_att 10.673274 loss_ctc 12.931963 loss_rnnt 10.109614 hw_loss 0.236481 history loss 3.943091 rank 6
2023-02-22 04:52:42,433 DEBUG CV Batch 14/200 loss 8.103253 loss_att 17.162882 loss_ctc 7.583749 loss_rnnt 6.360528 hw_loss 0.000127 history loss 4.518258 rank 0
2023-02-22 04:52:42,441 DEBUG CV Batch 14/200 loss 8.103253 loss_att 17.162882 loss_ctc 7.583749 loss_rnnt 6.360528 hw_loss 0.000127 history loss 4.518258 rank 7
2023-02-22 04:52:42,471 DEBUG CV Batch 14/200 loss 8.103253 loss_att 17.162882 loss_ctc 7.583749 loss_rnnt 6.360528 hw_loss 0.000127 history loss 4.518258 rank 4
2023-02-22 04:52:42,539 DEBUG CV Batch 14/200 loss 8.103253 loss_att 17.162882 loss_ctc 7.583749 loss_rnnt 6.360528 hw_loss 0.000127 history loss 4.518258 rank 5
2023-02-22 04:52:42,803 DEBUG CV Batch 14/200 loss 8.103253 loss_att 17.162882 loss_ctc 7.583749 loss_rnnt 6.360528 hw_loss 0.000127 history loss 4.518258 rank 3
2023-02-22 04:52:42,983 DEBUG CV Batch 14/200 loss 8.103253 loss_att 17.162882 loss_ctc 7.583749 loss_rnnt 6.360528 hw_loss 0.000127 history loss 4.518258 rank 2
2023-02-22 04:52:43,374 DEBUG CV Batch 14/200 loss 8.103253 loss_att 17.162882 loss_ctc 7.583749 loss_rnnt 6.360528 hw_loss 0.000127 history loss 4.518258 rank 1
2023-02-22 04:52:43,590 DEBUG CV Batch 14/200 loss 8.103253 loss_att 17.162882 loss_ctc 7.583749 loss_rnnt 6.360528 hw_loss 0.000127 history loss 4.518258 rank 6
2023-02-22 04:52:54,482 DEBUG CV Batch 14/300 loss 4.752438 loss_att 5.406860 loss_ctc 6.714533 loss_rnnt 4.272367 hw_loss 0.164200 history loss 4.636919 rank 0
2023-02-22 04:52:54,492 DEBUG CV Batch 14/300 loss 4.752438 loss_att 5.406860 loss_ctc 6.714533 loss_rnnt 4.272367 hw_loss 0.164200 history loss 4.636919 rank 4
2023-02-22 04:52:54,506 DEBUG CV Batch 14/300 loss 4.752438 loss_att 5.406860 loss_ctc 6.714533 loss_rnnt 4.272367 hw_loss 0.164200 history loss 4.636919 rank 7
2023-02-22 04:52:54,589 DEBUG CV Batch 14/300 loss 4.752438 loss_att 5.406860 loss_ctc 6.714533 loss_rnnt 4.272367 hw_loss 0.164200 history loss 4.636919 rank 5
2023-02-22 04:52:55,202 DEBUG CV Batch 14/300 loss 4.752438 loss_att 5.406860 loss_ctc 6.714533 loss_rnnt 4.272367 hw_loss 0.164200 history loss 4.636919 rank 2
2023-02-22 04:52:55,623 DEBUG CV Batch 14/300 loss 4.752438 loss_att 5.406860 loss_ctc 6.714533 loss_rnnt 4.272367 hw_loss 0.164200 history loss 4.636919 rank 1
2023-02-22 04:52:55,748 DEBUG CV Batch 14/300 loss 4.752438 loss_att 5.406860 loss_ctc 6.714533 loss_rnnt 4.272367 hw_loss 0.164200 history loss 4.636919 rank 3
2023-02-22 04:52:55,772 DEBUG CV Batch 14/300 loss 4.752438 loss_att 5.406860 loss_ctc 6.714533 loss_rnnt 4.272367 hw_loss 0.164200 history loss 4.636919 rank 6
2023-02-22 04:53:06,492 DEBUG CV Batch 14/400 loss 20.975052 loss_att 108.392555 loss_ctc 8.073919 loss_rnnt 5.155278 hw_loss 0.105792 history loss 5.617029 rank 0
2023-02-22 04:53:06,599 DEBUG CV Batch 14/400 loss 20.975052 loss_att 108.392555 loss_ctc 8.073919 loss_rnnt 5.155278 hw_loss 0.105792 history loss 5.617029 rank 7
2023-02-22 04:53:06,601 DEBUG CV Batch 14/400 loss 20.975052 loss_att 108.392555 loss_ctc 8.073919 loss_rnnt 5.155278 hw_loss 0.105792 history loss 5.617029 rank 4
2023-02-22 04:53:06,747 DEBUG CV Batch 14/400 loss 20.975052 loss_att 108.392555 loss_ctc 8.073919 loss_rnnt 5.155278 hw_loss 0.105792 history loss 5.617029 rank 5
2023-02-22 04:53:07,509 DEBUG CV Batch 14/400 loss 20.975052 loss_att 108.392555 loss_ctc 8.073919 loss_rnnt 5.155278 hw_loss 0.105792 history loss 5.617029 rank 2
2023-02-22 04:53:07,756 DEBUG CV Batch 14/400 loss 20.975052 loss_att 108.392555 loss_ctc 8.073919 loss_rnnt 5.155278 hw_loss 0.105792 history loss 5.617029 rank 1
2023-02-22 04:53:08,038 DEBUG CV Batch 14/400 loss 20.975052 loss_att 108.392555 loss_ctc 8.073919 loss_rnnt 5.155278 hw_loss 0.105792 history loss 5.617029 rank 6
2023-02-22 04:53:08,043 DEBUG CV Batch 14/400 loss 20.975052 loss_att 108.392555 loss_ctc 8.073919 loss_rnnt 5.155278 hw_loss 0.105792 history loss 5.617029 rank 3
2023-02-22 04:53:16,970 DEBUG CV Batch 14/500 loss 6.721886 loss_att 7.640445 loss_ctc 8.989969 loss_rnnt 6.208117 hw_loss 0.051838 history loss 6.457337 rank 0
2023-02-22 04:53:17,057 DEBUG CV Batch 14/500 loss 6.721886 loss_att 7.640445 loss_ctc 8.989969 loss_rnnt 6.208117 hw_loss 0.051838 history loss 6.457337 rank 7
2023-02-22 04:53:17,075 DEBUG CV Batch 14/500 loss 6.721886 loss_att 7.640445 loss_ctc 8.989969 loss_rnnt 6.208117 hw_loss 0.051838 history loss 6.457337 rank 4
2023-02-22 04:53:17,314 DEBUG CV Batch 14/500 loss 6.721886 loss_att 7.640445 loss_ctc 8.989969 loss_rnnt 6.208117 hw_loss 0.051838 history loss 6.457337 rank 5
2023-02-22 04:53:18,202 DEBUG CV Batch 14/500 loss 6.721886 loss_att 7.640445 loss_ctc 8.989969 loss_rnnt 6.208117 hw_loss 0.051838 history loss 6.457337 rank 2
2023-02-22 04:53:18,425 DEBUG CV Batch 14/500 loss 6.721886 loss_att 7.640445 loss_ctc 8.989969 loss_rnnt 6.208117 hw_loss 0.051838 history loss 6.457337 rank 1
2023-02-22 04:53:18,780 DEBUG CV Batch 14/500 loss 6.721886 loss_att 7.640445 loss_ctc 8.989969 loss_rnnt 6.208117 hw_loss 0.051838 history loss 6.457337 rank 3
2023-02-22 04:53:19,620 DEBUG CV Batch 14/500 loss 6.721886 loss_att 7.640445 loss_ctc 8.989969 loss_rnnt 6.208117 hw_loss 0.051838 history loss 6.457337 rank 6
2023-02-22 04:53:29,006 DEBUG CV Batch 14/600 loss 6.441832 loss_att 6.954924 loss_ctc 9.152230 loss_rnnt 5.876773 hw_loss 0.189475 history loss 7.483078 rank 0
2023-02-22 04:53:29,068 DEBUG CV Batch 14/600 loss 6.441832 loss_att 6.954924 loss_ctc 9.152230 loss_rnnt 5.876773 hw_loss 0.189476 history loss 7.483078 rank 4
2023-02-22 04:53:29,117 DEBUG CV Batch 14/600 loss 6.441832 loss_att 6.954924 loss_ctc 9.152230 loss_rnnt 5.876773 hw_loss 0.189476 history loss 7.483078 rank 7
2023-02-22 04:53:29,417 DEBUG CV Batch 14/600 loss 6.441832 loss_att 6.954924 loss_ctc 9.152230 loss_rnnt 5.876773 hw_loss 0.189475 history loss 7.483078 rank 5
2023-02-22 04:53:30,513 DEBUG CV Batch 14/600 loss 6.441832 loss_att 6.954924 loss_ctc 9.152230 loss_rnnt 5.876773 hw_loss 0.189475 history loss 7.483078 rank 2
2023-02-22 04:53:30,671 DEBUG CV Batch 14/600 loss 6.441832 loss_att 6.954924 loss_ctc 9.152230 loss_rnnt 5.876773 hw_loss 0.189476 history loss 7.483078 rank 1
2023-02-22 04:53:31,020 DEBUG CV Batch 14/600 loss 6.441832 loss_att 6.954924 loss_ctc 9.152230 loss_rnnt 5.876773 hw_loss 0.189475 history loss 7.483078 rank 3
2023-02-22 04:53:31,877 DEBUG CV Batch 14/600 loss 6.441832 loss_att 6.954924 loss_ctc 9.152230 loss_rnnt 5.876773 hw_loss 0.189476 history loss 7.483078 rank 6
2023-02-22 04:53:40,360 DEBUG CV Batch 14/700 loss 20.813465 loss_att 51.577625 loss_ctc 19.487415 loss_rnnt 14.811304 hw_loss 0.049002 history loss 8.244507 rank 0
2023-02-22 04:53:40,517 DEBUG CV Batch 14/700 loss 20.813465 loss_att 51.577625 loss_ctc 19.487415 loss_rnnt 14.811304 hw_loss 0.049002 history loss 8.244507 rank 4
2023-02-22 04:53:40,523 DEBUG CV Batch 14/700 loss 20.813465 loss_att 51.577625 loss_ctc 19.487415 loss_rnnt 14.811304 hw_loss 0.049002 history loss 8.244507 rank 7
2023-02-22 04:53:40,811 DEBUG CV Batch 14/700 loss 20.813465 loss_att 51.577625 loss_ctc 19.487415 loss_rnnt 14.811304 hw_loss 0.049002 history loss 8.244507 rank 5
2023-02-22 04:53:42,018 DEBUG CV Batch 14/700 loss 20.813465 loss_att 51.577625 loss_ctc 19.487415 loss_rnnt 14.811304 hw_loss 0.049002 history loss 8.244507 rank 2
2023-02-22 04:53:42,567 DEBUG CV Batch 14/700 loss 20.813465 loss_att 51.577625 loss_ctc 19.487415 loss_rnnt 14.811304 hw_loss 0.049002 history loss 8.244507 rank 3
2023-02-22 04:53:42,886 DEBUG CV Batch 14/700 loss 20.813465 loss_att 51.577625 loss_ctc 19.487415 loss_rnnt 14.811304 hw_loss 0.049002 history loss 8.244507 rank 1
2023-02-22 04:53:43,775 DEBUG CV Batch 14/700 loss 20.813465 loss_att 51.577625 loss_ctc 19.487415 loss_rnnt 14.811304 hw_loss 0.049002 history loss 8.244507 rank 6
2023-02-22 04:53:51,431 DEBUG CV Batch 14/800 loss 14.457136 loss_att 12.647316 loss_ctc 18.160061 loss_rnnt 14.255455 hw_loss 0.131103 history loss 7.661055 rank 0
2023-02-22 04:53:51,613 DEBUG CV Batch 14/800 loss 14.457136 loss_att 12.647316 loss_ctc 18.160061 loss_rnnt 14.255455 hw_loss 0.131103 history loss 7.661055 rank 7
2023-02-22 04:53:51,664 DEBUG CV Batch 14/800 loss 14.457136 loss_att 12.647316 loss_ctc 18.160061 loss_rnnt 14.255455 hw_loss 0.131103 history loss 7.661055 rank 4
2023-02-22 04:53:52,003 DEBUG CV Batch 14/800 loss 14.457136 loss_att 12.647316 loss_ctc 18.160061 loss_rnnt 14.255455 hw_loss 0.131103 history loss 7.661055 rank 5
2023-02-22 04:53:53,558 DEBUG CV Batch 14/800 loss 14.457136 loss_att 12.647316 loss_ctc 18.160061 loss_rnnt 14.255455 hw_loss 0.131103 history loss 7.661055 rank 2
2023-02-22 04:53:53,894 DEBUG CV Batch 14/800 loss 14.457136 loss_att 12.647316 loss_ctc 18.160061 loss_rnnt 14.255455 hw_loss 0.131103 history loss 7.661055 rank 3
2023-02-22 04:53:54,283 DEBUG CV Batch 14/800 loss 14.457136 loss_att 12.647316 loss_ctc 18.160061 loss_rnnt 14.255455 hw_loss 0.131103 history loss 7.661055 rank 1
2023-02-22 04:53:55,267 DEBUG CV Batch 14/800 loss 14.457136 loss_att 12.647316 loss_ctc 18.160061 loss_rnnt 14.255455 hw_loss 0.131103 history loss 7.661055 rank 6
2023-02-22 04:54:04,779 DEBUG CV Batch 14/900 loss 14.561718 loss_att 18.359116 loss_ctc 23.646238 loss_rnnt 12.567165 hw_loss 0.044631 history loss 7.439949 rank 0
2023-02-22 04:54:04,902 DEBUG CV Batch 14/900 loss 14.561718 loss_att 18.359116 loss_ctc 23.646238 loss_rnnt 12.567165 hw_loss 0.044631 history loss 7.439949 rank 7
2023-02-22 04:54:04,985 DEBUG CV Batch 14/900 loss 14.561718 loss_att 18.359116 loss_ctc 23.646238 loss_rnnt 12.567165 hw_loss 0.044631 history loss 7.439949 rank 4
2023-02-22 04:54:05,579 DEBUG CV Batch 14/900 loss 14.561718 loss_att 18.359116 loss_ctc 23.646238 loss_rnnt 12.567165 hw_loss 0.044631 history loss 7.439949 rank 5
2023-02-22 04:54:06,817 DEBUG CV Batch 14/900 loss 14.561718 loss_att 18.359116 loss_ctc 23.646238 loss_rnnt 12.567165 hw_loss 0.044631 history loss 7.439949 rank 2
2023-02-22 04:54:07,262 DEBUG CV Batch 14/900 loss 14.561718 loss_att 18.359116 loss_ctc 23.646238 loss_rnnt 12.567165 hw_loss 0.044631 history loss 7.439949 rank 3
2023-02-22 04:54:07,590 DEBUG CV Batch 14/900 loss 14.561718 loss_att 18.359116 loss_ctc 23.646238 loss_rnnt 12.567165 hw_loss 0.044631 history loss 7.439949 rank 1
2023-02-22 04:54:08,620 DEBUG CV Batch 14/900 loss 14.561718 loss_att 18.359116 loss_ctc 23.646238 loss_rnnt 12.567165 hw_loss 0.044631 history loss 7.439949 rank 6
2023-02-22 04:54:17,073 DEBUG CV Batch 14/1000 loss 3.825708 loss_att 5.136747 loss_ctc 4.910829 loss_rnnt 3.324899 hw_loss 0.176096 history loss 7.180486 rank 4
2023-02-22 04:54:17,124 DEBUG CV Batch 14/1000 loss 3.825708 loss_att 5.136747 loss_ctc 4.910829 loss_rnnt 3.324899 hw_loss 0.176096 history loss 7.180486 rank 7
2023-02-22 04:54:17,221 DEBUG CV Batch 14/1000 loss 3.825708 loss_att 5.136747 loss_ctc 4.910829 loss_rnnt 3.324899 hw_loss 0.176096 history loss 7.180486 rank 0
2023-02-22 04:54:17,777 DEBUG CV Batch 14/1000 loss 3.825708 loss_att 5.136747 loss_ctc 4.910829 loss_rnnt 3.324899 hw_loss 0.176096 history loss 7.180486 rank 5
2023-02-22 04:54:19,088 DEBUG CV Batch 14/1000 loss 3.825708 loss_att 5.136747 loss_ctc 4.910829 loss_rnnt 3.324899 hw_loss 0.176096 history loss 7.180486 rank 2
2023-02-22 04:54:19,532 DEBUG CV Batch 14/1000 loss 3.825708 loss_att 5.136747 loss_ctc 4.910829 loss_rnnt 3.324899 hw_loss 0.176096 history loss 7.180486 rank 3
2023-02-22 04:54:19,876 DEBUG CV Batch 14/1000 loss 3.825708 loss_att 5.136747 loss_ctc 4.910829 loss_rnnt 3.324899 hw_loss 0.176096 history loss 7.180486 rank 1
2023-02-22 04:54:21,174 DEBUG CV Batch 14/1000 loss 3.825708 loss_att 5.136747 loss_ctc 4.910829 loss_rnnt 3.324899 hw_loss 0.176096 history loss 7.180486 rank 6
2023-02-22 04:54:28,984 DEBUG CV Batch 14/1100 loss 6.509987 loss_att 5.839231 loss_ctc 8.763359 loss_rnnt 6.201473 hw_loss 0.266652 history loss 7.154237 rank 7
2023-02-22 04:54:29,034 DEBUG CV Batch 14/1100 loss 6.509987 loss_att 5.839231 loss_ctc 8.763359 loss_rnnt 6.201473 hw_loss 0.266652 history loss 7.154237 rank 4
2023-02-22 04:54:29,197 DEBUG CV Batch 14/1100 loss 6.509987 loss_att 5.839231 loss_ctc 8.763359 loss_rnnt 6.201473 hw_loss 0.266652 history loss 7.154237 rank 0
2023-02-22 04:54:29,669 DEBUG CV Batch 14/1100 loss 6.509987 loss_att 5.839231 loss_ctc 8.763359 loss_rnnt 6.201473 hw_loss 0.266652 history loss 7.154237 rank 5
2023-02-22 04:54:31,053 DEBUG CV Batch 14/1100 loss 6.509987 loss_att 5.839231 loss_ctc 8.763359 loss_rnnt 6.201473 hw_loss 0.266652 history loss 7.154237 rank 2
2023-02-22 04:54:31,581 DEBUG CV Batch 14/1100 loss 6.509987 loss_att 5.839231 loss_ctc 8.763359 loss_rnnt 6.201473 hw_loss 0.266652 history loss 7.154237 rank 3
2023-02-22 04:54:31,879 DEBUG CV Batch 14/1100 loss 6.509987 loss_att 5.839231 loss_ctc 8.763359 loss_rnnt 6.201473 hw_loss 0.266652 history loss 7.154237 rank 1
2023-02-22 04:54:33,247 DEBUG CV Batch 14/1100 loss 6.509987 loss_att 5.839231 loss_ctc 8.763359 loss_rnnt 6.201473 hw_loss 0.266652 history loss 7.154237 rank 6
2023-02-22 04:54:39,555 DEBUG CV Batch 14/1200 loss 5.995761 loss_att 8.193952 loss_ctc 8.411272 loss_rnnt 5.144395 hw_loss 0.168112 history loss 7.493539 rank 7
2023-02-22 04:54:39,561 DEBUG CV Batch 14/1200 loss 5.995761 loss_att 8.193952 loss_ctc 8.411272 loss_rnnt 5.144395 hw_loss 0.168112 history loss 7.493539 rank 4
2023-02-22 04:54:39,768 DEBUG CV Batch 14/1200 loss 5.995761 loss_att 8.193952 loss_ctc 8.411272 loss_rnnt 5.144395 hw_loss 0.168112 history loss 7.493539 rank 0
2023-02-22 04:54:40,365 DEBUG CV Batch 14/1200 loss 5.995761 loss_att 8.193952 loss_ctc 8.411272 loss_rnnt 5.144395 hw_loss 0.168112 history loss 7.493539 rank 5
2023-02-22 04:54:41,782 DEBUG CV Batch 14/1200 loss 5.995761 loss_att 8.193952 loss_ctc 8.411272 loss_rnnt 5.144395 hw_loss 0.168112 history loss 7.493539 rank 2
2023-02-22 04:54:42,509 DEBUG CV Batch 14/1200 loss 5.995761 loss_att 8.193952 loss_ctc 8.411272 loss_rnnt 5.144395 hw_loss 0.168112 history loss 7.493539 rank 3
2023-02-22 04:54:42,528 DEBUG CV Batch 14/1200 loss 5.995761 loss_att 8.193952 loss_ctc 8.411272 loss_rnnt 5.144395 hw_loss 0.168112 history loss 7.493539 rank 1
2023-02-22 04:54:43,982 DEBUG CV Batch 14/1200 loss 5.995761 loss_att 8.193952 loss_ctc 8.411272 loss_rnnt 5.144395 hw_loss 0.168112 history loss 7.493539 rank 6
2023-02-22 04:54:51,439 DEBUG CV Batch 14/1300 loss 6.517275 loss_att 6.249121 loss_ctc 8.880294 loss_rnnt 6.122514 hw_loss 0.249978 history loss 7.829461 rank 4
2023-02-22 04:54:51,509 DEBUG CV Batch 14/1300 loss 6.517275 loss_att 6.249121 loss_ctc 8.880294 loss_rnnt 6.122514 hw_loss 0.249978 history loss 7.829461 rank 7
2023-02-22 04:54:51,721 DEBUG CV Batch 14/1300 loss 6.517275 loss_att 6.249121 loss_ctc 8.880294 loss_rnnt 6.122514 hw_loss 0.249978 history loss 7.829461 rank 0
2023-02-22 04:54:52,324 DEBUG CV Batch 14/1300 loss 6.517275 loss_att 6.249121 loss_ctc 8.880294 loss_rnnt 6.122514 hw_loss 0.249978 history loss 7.829461 rank 5
2023-02-22 04:54:53,909 DEBUG CV Batch 14/1300 loss 6.517275 loss_att 6.249121 loss_ctc 8.880294 loss_rnnt 6.122514 hw_loss 0.249978 history loss 7.829461 rank 2
2023-02-22 04:54:54,471 DEBUG CV Batch 14/1300 loss 6.517275 loss_att 6.249121 loss_ctc 8.880294 loss_rnnt 6.122514 hw_loss 0.249978 history loss 7.829461 rank 1
2023-02-22 04:54:54,998 DEBUG CV Batch 14/1300 loss 6.517275 loss_att 6.249121 loss_ctc 8.880294 loss_rnnt 6.122514 hw_loss 0.249978 history loss 7.829461 rank 3
2023-02-22 04:54:56,069 DEBUG CV Batch 14/1300 loss 6.517275 loss_att 6.249121 loss_ctc 8.880294 loss_rnnt 6.122514 hw_loss 0.249978 history loss 7.829461 rank 6
2023-02-22 04:55:02,655 DEBUG CV Batch 14/1400 loss 13.979355 loss_att 38.624584 loss_ctc 8.900017 loss_rnnt 9.664557 hw_loss 0.118119 history loss 8.201904 rank 7
2023-02-22 04:55:02,692 DEBUG CV Batch 14/1400 loss 13.979355 loss_att 38.624584 loss_ctc 8.900017 loss_rnnt 9.664557 hw_loss 0.118119 history loss 8.201904 rank 4
2023-02-22 04:55:02,938 DEBUG CV Batch 14/1400 loss 13.979355 loss_att 38.624584 loss_ctc 8.900017 loss_rnnt 9.664557 hw_loss 0.118119 history loss 8.201904 rank 0
2023-02-22 04:55:03,614 DEBUG CV Batch 14/1400 loss 13.979355 loss_att 38.624584 loss_ctc 8.900017 loss_rnnt 9.664557 hw_loss 0.118119 history loss 8.201904 rank 5
2023-02-22 04:55:05,723 DEBUG CV Batch 14/1400 loss 13.979355 loss_att 38.624584 loss_ctc 8.900017 loss_rnnt 9.664557 hw_loss 0.118119 history loss 8.201904 rank 2
2023-02-22 04:55:05,735 DEBUG CV Batch 14/1400 loss 13.979355 loss_att 38.624584 loss_ctc 8.900017 loss_rnnt 9.664557 hw_loss 0.118119 history loss 8.201904 rank 1
2023-02-22 04:55:06,409 DEBUG CV Batch 14/1400 loss 13.979355 loss_att 38.624584 loss_ctc 8.900017 loss_rnnt 9.664557 hw_loss 0.118119 history loss 8.201904 rank 3
2023-02-22 04:55:07,447 DEBUG CV Batch 14/1400 loss 13.979355 loss_att 38.624584 loss_ctc 8.900017 loss_rnnt 9.664557 hw_loss 0.118119 history loss 8.201904 rank 6
2023-02-22 04:55:14,104 DEBUG CV Batch 14/1500 loss 8.218681 loss_att 9.251386 loss_ctc 7.887342 loss_rnnt 7.953394 hw_loss 0.192986 history loss 8.007509 rank 7
2023-02-22 04:55:14,139 DEBUG CV Batch 14/1500 loss 8.218681 loss_att 9.251386 loss_ctc 7.887342 loss_rnnt 7.953394 hw_loss 0.192986 history loss 8.007509 rank 4
2023-02-22 04:55:14,366 DEBUG CV Batch 14/1500 loss 8.218681 loss_att 9.251386 loss_ctc 7.887342 loss_rnnt 7.953394 hw_loss 0.192986 history loss 8.007509 rank 0
2023-02-22 04:55:14,964 DEBUG CV Batch 14/1500 loss 8.218681 loss_att 9.251386 loss_ctc 7.887342 loss_rnnt 7.953394 hw_loss 0.192986 history loss 8.007509 rank 5
2023-02-22 04:55:17,272 DEBUG CV Batch 14/1500 loss 8.218681 loss_att 9.251386 loss_ctc 7.887342 loss_rnnt 7.953394 hw_loss 0.192986 history loss 8.007509 rank 1
2023-02-22 04:55:18,239 DEBUG CV Batch 14/1500 loss 8.218681 loss_att 9.251386 loss_ctc 7.887342 loss_rnnt 7.953394 hw_loss 0.192986 history loss 8.007509 rank 3
2023-02-22 04:55:18,664 DEBUG CV Batch 14/1500 loss 8.218681 loss_att 9.251386 loss_ctc 7.887342 loss_rnnt 7.953394 hw_loss 0.192986 history loss 8.007509 rank 2
2023-02-22 04:55:18,953 DEBUG CV Batch 14/1500 loss 8.218681 loss_att 9.251386 loss_ctc 7.887342 loss_rnnt 7.953394 hw_loss 0.192986 history loss 8.007509 rank 6
2023-02-22 04:55:27,031 DEBUG CV Batch 14/1600 loss 6.918518 loss_att 12.098192 loss_ctc 9.307869 loss_rnnt 5.539562 hw_loss 0.045825 history loss 7.926360 rank 4
2023-02-22 04:55:27,222 DEBUG CV Batch 14/1600 loss 6.918518 loss_att 12.098192 loss_ctc 9.307869 loss_rnnt 5.539562 hw_loss 0.045825 history loss 7.926360 rank 7
2023-02-22 04:55:27,279 DEBUG CV Batch 14/1600 loss 6.918518 loss_att 12.098192 loss_ctc 9.307869 loss_rnnt 5.539562 hw_loss 0.045825 history loss 7.926360 rank 0
2023-02-22 04:55:28,018 DEBUG CV Batch 14/1600 loss 6.918518 loss_att 12.098192 loss_ctc 9.307869 loss_rnnt 5.539562 hw_loss 0.045825 history loss 7.926360 rank 5
2023-02-22 04:55:30,391 DEBUG CV Batch 14/1600 loss 6.918518 loss_att 12.098192 loss_ctc 9.307869 loss_rnnt 5.539562 hw_loss 0.045825 history loss 7.926360 rank 1
2023-02-22 04:55:31,366 DEBUG CV Batch 14/1600 loss 6.918518 loss_att 12.098192 loss_ctc 9.307869 loss_rnnt 5.539562 hw_loss 0.045825 history loss 7.926360 rank 3
2023-02-22 04:55:31,841 DEBUG CV Batch 14/1600 loss 6.918518 loss_att 12.098192 loss_ctc 9.307869 loss_rnnt 5.539562 hw_loss 0.045825 history loss 7.926360 rank 2
2023-02-22 04:55:32,104 DEBUG CV Batch 14/1600 loss 6.918518 loss_att 12.098192 loss_ctc 9.307869 loss_rnnt 5.539562 hw_loss 0.045825 history loss 7.926360 rank 6
2023-02-22 04:55:39,318 DEBUG CV Batch 14/1700 loss 11.225210 loss_att 9.984143 loss_ctc 15.688236 loss_rnnt 10.791903 hw_loss 0.162094 history loss 7.812884 rank 4
2023-02-22 04:55:39,443 DEBUG CV Batch 14/1700 loss 11.225210 loss_att 9.984143 loss_ctc 15.688236 loss_rnnt 10.791903 hw_loss 0.162094 history loss 7.812884 rank 7
2023-02-22 04:55:39,522 DEBUG CV Batch 14/1700 loss 11.225210 loss_att 9.984143 loss_ctc 15.688236 loss_rnnt 10.791903 hw_loss 0.162094 history loss 7.812884 rank 0
2023-02-22 04:55:40,626 DEBUG CV Batch 14/1700 loss 11.225210 loss_att 9.984143 loss_ctc 15.688236 loss_rnnt 10.791903 hw_loss 0.162094 history loss 7.812884 rank 5
2023-02-22 04:55:42,815 DEBUG CV Batch 14/1700 loss 11.225210 loss_att 9.984143 loss_ctc 15.688236 loss_rnnt 10.791903 hw_loss 0.162094 history loss 7.812884 rank 1
2023-02-22 04:55:43,973 DEBUG CV Batch 14/1700 loss 11.225210 loss_att 9.984143 loss_ctc 15.688236 loss_rnnt 10.791903 hw_loss 0.162094 history loss 7.812884 rank 3
2023-02-22 04:55:44,218 DEBUG CV Batch 14/1700 loss 11.225210 loss_att 9.984143 loss_ctc 15.688236 loss_rnnt 10.791903 hw_loss 0.162094 history loss 7.812884 rank 2
2023-02-22 04:55:44,435 DEBUG CV Batch 14/1700 loss 11.225210 loss_att 9.984143 loss_ctc 15.688236 loss_rnnt 10.791903 hw_loss 0.162094 history loss 7.812884 rank 6
2023-02-22 04:55:48,326 INFO Epoch 14 CV info cv_loss 7.772702349409889
2023-02-22 04:55:48,327 INFO Epoch 15 TRAIN info lr 0.0004470115919029179
2023-02-22 04:55:48,330 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 04:55:48,419 INFO Epoch 14 CV info cv_loss 7.772702350555636
2023-02-22 04:55:48,424 INFO Epoch 15 TRAIN info lr 0.0004469544370606276
2023-02-22 04:55:48,428 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 04:55:48,520 INFO Epoch 14 CV info cv_loss 7.772702349315129
2023-02-22 04:55:48,522 INFO Checkpoint: save to checkpoint exp/2_21_rnnt_bias_loss_2_class_1word_finetune/14.pt
2023-02-22 04:55:49,251 INFO Epoch 15 TRAIN info lr 0.00044700623270499536
2023-02-22 04:55:49,255 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 04:55:49,677 INFO Epoch 14 CV info cv_loss 7.772702348781022
2023-02-22 04:55:49,679 INFO Epoch 15 TRAIN info lr 0.0004469383662108998
2023-02-22 04:55:49,682 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 04:55:51,847 INFO Epoch 14 CV info cv_loss 7.772702348772407
2023-02-22 04:55:51,848 INFO Epoch 15 TRAIN info lr 0.0004470580463606669
2023-02-22 04:55:51,851 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 04:55:53,255 INFO Epoch 14 CV info cv_loss 7.772702349840621
2023-02-22 04:55:53,255 INFO Epoch 15 TRAIN info lr 0.00044697229559373077
2023-02-22 04:55:53,258 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 04:55:53,459 INFO Epoch 14 CV info cv_loss 7.7727023518650595
2023-02-22 04:55:53,460 INFO Epoch 15 TRAIN info lr 0.000447050898578328
2023-02-22 04:55:53,464 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 04:55:54,048 INFO Epoch 14 CV info cv_loss 7.7727023489016265
2023-02-22 04:55:54,049 INFO Epoch 15 TRAIN info lr 0.00044702767065329376
2023-02-22 04:55:54,053 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 04:57:07,869 DEBUG TRAIN Batch 15/0 loss 11.821376 loss_att 10.479668 loss_ctc 13.201533 loss_rnnt 11.813599 hw_loss 0.172684 lr 0.00044701 rank 4
2023-02-22 04:57:07,887 DEBUG TRAIN Batch 15/0 loss 12.022840 loss_att 11.260879 loss_ctc 15.090240 loss_rnnt 11.640440 hw_loss 0.235890 lr 0.00044697 rank 2
2023-02-22 04:57:07,888 DEBUG TRAIN Batch 15/0 loss 14.780725 loss_att 13.458069 loss_ctc 16.985744 loss_rnnt 14.612390 hw_loss 0.260369 lr 0.00044700 rank 0
2023-02-22 04:57:07,895 DEBUG TRAIN Batch 15/0 loss 9.041989 loss_att 9.158071 loss_ctc 10.498937 loss_rnnt 8.674857 hw_loss 0.280607 lr 0.00044703 rank 3
2023-02-22 04:57:07,897 DEBUG TRAIN Batch 15/0 loss 12.037402 loss_att 10.225391 loss_ctc 13.653912 loss_rnnt 12.076857 hw_loss 0.201402 lr 0.00044694 rank 5
2023-02-22 04:57:07,901 DEBUG TRAIN Batch 15/0 loss 11.321961 loss_att 10.024214 loss_ctc 15.356181 loss_rnnt 10.898948 hw_loss 0.271251 lr 0.00044706 rank 1
2023-02-22 04:57:07,901 DEBUG TRAIN Batch 15/0 loss 6.014252 loss_att 6.379554 loss_ctc 7.634535 loss_rnnt 5.629563 hw_loss 0.179232 lr 0.00044695 rank 7
2023-02-22 04:57:07,904 DEBUG TRAIN Batch 15/0 loss 10.054873 loss_att 9.548331 loss_ctc 12.028493 loss_rnnt 9.741882 hw_loss 0.283403 lr 0.00044705 rank 6
2023-02-22 04:58:20,975 DEBUG TRAIN Batch 15/100 loss 9.558253 loss_att 16.630707 loss_ctc 11.682478 loss_rnnt 7.817717 hw_loss 0.080279 lr 0.00044676 rank 5
2023-02-22 04:58:20,977 DEBUG TRAIN Batch 15/100 loss 4.842499 loss_att 11.457485 loss_ctc 6.875059 loss_rnnt 3.164065 hw_loss 0.158304 lr 0.00044683 rank 0
2023-02-22 04:58:20,978 DEBUG TRAIN Batch 15/100 loss 7.277010 loss_att 10.193071 loss_ctc 8.002269 loss_rnnt 6.538517 hw_loss 0.109837 lr 0.00044677 rank 7
2023-02-22 04:58:20,981 DEBUG TRAIN Batch 15/100 loss 18.204691 loss_att 19.233545 loss_ctc 23.766918 loss_rnnt 17.233162 hw_loss 0.045238 lr 0.00044685 rank 3
2023-02-22 04:58:20,982 DEBUG TRAIN Batch 15/100 loss 5.427015 loss_att 13.055132 loss_ctc 6.922105 loss_rnnt 3.680744 hw_loss 0.039941 lr 0.00044683 rank 4
2023-02-22 04:58:20,982 DEBUG TRAIN Batch 15/100 loss 8.552245 loss_att 11.074653 loss_ctc 13.012197 loss_rnnt 7.376519 hw_loss 0.143594 lr 0.00044687 rank 6
2023-02-22 04:58:20,983 DEBUG TRAIN Batch 15/100 loss 15.633523 loss_att 19.223595 loss_ctc 16.252960 loss_rnnt 14.768314 hw_loss 0.121130 lr 0.00044688 rank 1
2023-02-22 04:58:20,986 DEBUG TRAIN Batch 15/100 loss 12.617802 loss_att 13.002425 loss_ctc 14.050510 loss_rnnt 12.270262 hw_loss 0.149226 lr 0.00044679 rank 2
2023-02-22 04:59:35,715 DEBUG TRAIN Batch 15/200 loss 8.350758 loss_att 12.077805 loss_ctc 11.683147 loss_rnnt 6.982269 hw_loss 0.335176 lr 0.00044665 rank 4
2023-02-22 04:59:35,715 DEBUG TRAIN Batch 15/200 loss 10.400582 loss_att 15.652517 loss_ctc 14.516421 loss_rnnt 8.766414 hw_loss 0.065632 lr 0.00044665 rank 0
2023-02-22 04:59:35,716 DEBUG TRAIN Batch 15/200 loss 22.123802 loss_att 23.254908 loss_ctc 28.974958 loss_rnnt 20.899384 hw_loss 0.158833 lr 0.00044670 rank 1
2023-02-22 04:59:35,719 DEBUG TRAIN Batch 15/200 loss 4.649775 loss_att 10.135944 loss_ctc 6.101528 loss_rnnt 3.287206 hw_loss 0.134565 lr 0.00044658 rank 5
2023-02-22 04:59:35,720 DEBUG TRAIN Batch 15/200 loss 11.786419 loss_att 14.429008 loss_ctc 14.317817 loss_rnnt 10.867449 hw_loss 0.099247 lr 0.00044660 rank 7
2023-02-22 04:59:35,722 DEBUG TRAIN Batch 15/200 loss 7.519966 loss_att 11.370152 loss_ctc 10.858875 loss_rnnt 6.242230 hw_loss 0.117207 lr 0.00044661 rank 2
2023-02-22 04:59:35,723 DEBUG TRAIN Batch 15/200 loss 15.727837 loss_att 16.160757 loss_ctc 20.422644 loss_rnnt 14.924961 hw_loss 0.169344 lr 0.00044669 rank 6
2023-02-22 04:59:35,725 DEBUG TRAIN Batch 15/200 loss 11.833069 loss_att 16.329130 loss_ctc 14.219325 loss_rnnt 10.549678 hw_loss 0.123772 lr 0.00044667 rank 3
2023-02-22 05:00:53,028 DEBUG TRAIN Batch 15/300 loss 16.592669 loss_att 18.726757 loss_ctc 18.552364 loss_rnnt 15.784262 hw_loss 0.225558 lr 0.00044642 rank 7
2023-02-22 05:00:53,030 DEBUG TRAIN Batch 15/300 loss 11.198504 loss_att 15.602516 loss_ctc 18.728134 loss_rnnt 9.248853 hw_loss 0.121683 lr 0.00044647 rank 4
2023-02-22 05:00:53,033 DEBUG TRAIN Batch 15/300 loss 11.678851 loss_att 13.361459 loss_ctc 15.322346 loss_rnnt 10.723812 hw_loss 0.248846 lr 0.00044647 rank 0
2023-02-22 05:00:53,038 DEBUG TRAIN Batch 15/300 loss 9.768652 loss_att 11.497574 loss_ctc 12.034002 loss_rnnt 9.031352 hw_loss 0.167754 lr 0.00044640 rank 5
2023-02-22 05:00:53,038 DEBUG TRAIN Batch 15/300 loss 11.839622 loss_att 13.317045 loss_ctc 13.143351 loss_rnnt 11.306017 hw_loss 0.120545 lr 0.00044652 rank 1
2023-02-22 05:00:53,043 DEBUG TRAIN Batch 15/300 loss 13.263716 loss_att 18.514950 loss_ctc 18.929951 loss_rnnt 11.374840 hw_loss 0.155871 lr 0.00044651 rank 6
2023-02-22 05:00:53,042 DEBUG TRAIN Batch 15/300 loss 9.980356 loss_att 15.352715 loss_ctc 10.447195 loss_rnnt 8.756398 hw_loss 0.163577 lr 0.00044644 rank 2
2023-02-22 05:00:53,044 DEBUG TRAIN Batch 15/300 loss 14.581413 loss_att 19.230047 loss_ctc 18.541634 loss_rnnt 13.078751 hw_loss 0.084200 lr 0.00044649 rank 3
2023-02-22 05:02:09,944 DEBUG TRAIN Batch 15/400 loss 8.753467 loss_att 10.211044 loss_ctc 10.145759 loss_rnnt 8.146997 hw_loss 0.242464 lr 0.00044631 rank 3
2023-02-22 05:02:09,945 DEBUG TRAIN Batch 15/400 loss 15.554288 loss_att 19.702473 loss_ctc 20.622223 loss_rnnt 13.942303 hw_loss 0.199920 lr 0.00044622 rank 5
2023-02-22 05:02:09,946 DEBUG TRAIN Batch 15/400 loss 7.723825 loss_att 9.465873 loss_ctc 10.304543 loss_rnnt 6.903432 hw_loss 0.239789 lr 0.00044634 rank 6
2023-02-22 05:02:09,946 DEBUG TRAIN Batch 15/400 loss 11.985596 loss_att 15.050260 loss_ctc 16.114594 loss_rnnt 10.758832 hw_loss 0.118682 lr 0.00044630 rank 4
2023-02-22 05:02:09,947 DEBUG TRAIN Batch 15/400 loss 2.766839 loss_att 5.610848 loss_ctc 3.501625 loss_rnnt 1.982534 hw_loss 0.220370 lr 0.00044629 rank 0
2023-02-22 05:02:09,948 DEBUG TRAIN Batch 15/400 loss 6.119519 loss_att 8.294046 loss_ctc 8.675961 loss_rnnt 5.269911 hw_loss 0.138456 lr 0.00044634 rank 1
2023-02-22 05:02:09,953 DEBUG TRAIN Batch 15/400 loss 26.665911 loss_att 28.466892 loss_ctc 37.679115 loss_rnnt 24.722229 hw_loss 0.215734 lr 0.00044624 rank 7
2023-02-22 05:02:09,955 DEBUG TRAIN Batch 15/400 loss 11.091615 loss_att 13.409034 loss_ctc 13.676407 loss_rnnt 10.202251 hw_loss 0.152325 lr 0.00044626 rank 2
2023-02-22 05:03:25,470 DEBUG TRAIN Batch 15/500 loss 11.661888 loss_att 13.252148 loss_ctc 15.191332 loss_rnnt 10.825581 hw_loss 0.089367 lr 0.00044611 rank 0
2023-02-22 05:03:25,471 DEBUG TRAIN Batch 15/500 loss 8.309760 loss_att 10.426127 loss_ctc 9.092325 loss_rnnt 7.734121 hw_loss 0.090043 lr 0.00044614 rank 3
2023-02-22 05:03:25,472 DEBUG TRAIN Batch 15/500 loss 5.687818 loss_att 8.231478 loss_ctc 8.414059 loss_rnnt 4.779490 hw_loss 0.067682 lr 0.00044617 rank 1
2023-02-22 05:03:25,472 DEBUG TRAIN Batch 15/500 loss 14.934155 loss_att 18.792175 loss_ctc 18.174904 loss_rnnt 13.651081 hw_loss 0.148816 lr 0.00044612 rank 4
2023-02-22 05:03:25,473 DEBUG TRAIN Batch 15/500 loss 9.928756 loss_att 13.668211 loss_ctc 10.259488 loss_rnnt 9.057858 hw_loss 0.147952 lr 0.00044605 rank 5
2023-02-22 05:03:25,475 DEBUG TRAIN Batch 15/500 loss 4.146759 loss_att 7.094072 loss_ctc 6.819982 loss_rnnt 3.146225 hw_loss 0.102452 lr 0.00044606 rank 7
2023-02-22 05:03:25,481 DEBUG TRAIN Batch 15/500 loss 9.725152 loss_att 14.338526 loss_ctc 14.156731 loss_rnnt 8.205215 hw_loss 0.011973 lr 0.00044616 rank 6
2023-02-22 05:03:25,482 DEBUG TRAIN Batch 15/500 loss 5.456091 loss_att 8.357828 loss_ctc 7.653420 loss_rnnt 4.524518 hw_loss 0.109214 lr 0.00044608 rank 2
2023-02-22 05:04:40,720 DEBUG TRAIN Batch 15/600 loss 9.794318 loss_att 11.821947 loss_ctc 14.977160 loss_rnnt 8.565779 hw_loss 0.247441 lr 0.00044594 rank 4
2023-02-22 05:04:40,720 DEBUG TRAIN Batch 15/600 loss 11.287948 loss_att 10.202569 loss_ctc 15.754423 loss_rnnt 10.804902 hw_loss 0.196110 lr 0.00044587 rank 5
2023-02-22 05:04:40,722 DEBUG TRAIN Batch 15/600 loss 8.420162 loss_att 9.390306 loss_ctc 12.022370 loss_rnnt 7.670933 hw_loss 0.140449 lr 0.00044594 rank 0
2023-02-22 05:04:40,724 DEBUG TRAIN Batch 15/600 loss 7.745900 loss_att 9.987230 loss_ctc 11.394464 loss_rnnt 6.722786 hw_loss 0.165699 lr 0.00044589 rank 7
2023-02-22 05:04:40,726 DEBUG TRAIN Batch 15/600 loss 12.138128 loss_att 12.015875 loss_ctc 16.667118 loss_rnnt 11.442184 hw_loss 0.218491 lr 0.00044590 rank 2
2023-02-22 05:04:40,727 DEBUG TRAIN Batch 15/600 loss 15.927444 loss_att 15.900148 loss_ctc 19.234657 loss_rnnt 15.359035 hw_loss 0.249201 lr 0.00044598 rank 6
2023-02-22 05:04:40,735 DEBUG TRAIN Batch 15/600 loss 9.159853 loss_att 9.554088 loss_ctc 11.464051 loss_rnnt 8.678055 hw_loss 0.179483 lr 0.00044599 rank 1
2023-02-22 05:04:40,738 DEBUG TRAIN Batch 15/600 loss 8.940892 loss_att 9.190239 loss_ctc 11.137419 loss_rnnt 8.539351 hw_loss 0.110254 lr 0.00044596 rank 3
2023-02-22 05:05:58,467 DEBUG TRAIN Batch 15/700 loss 14.087109 loss_att 18.271658 loss_ctc 15.165545 loss_rnnt 13.043274 hw_loss 0.118375 lr 0.00044576 rank 0
2023-02-22 05:05:58,468 DEBUG TRAIN Batch 15/700 loss 16.339596 loss_att 20.835972 loss_ctc 18.775497 loss_rnnt 15.019366 hw_loss 0.180311 lr 0.00044571 rank 7
2023-02-22 05:05:58,469 DEBUG TRAIN Batch 15/700 loss 9.545568 loss_att 12.609869 loss_ctc 11.324058 loss_rnnt 8.580196 hw_loss 0.216334 lr 0.00044569 rank 5
2023-02-22 05:05:58,474 DEBUG TRAIN Batch 15/700 loss 22.417362 loss_att 30.612616 loss_ctc 30.149101 loss_rnnt 19.636114 hw_loss 0.208686 lr 0.00044573 rank 2
2023-02-22 05:05:58,475 DEBUG TRAIN Batch 15/700 loss 18.797451 loss_att 22.894041 loss_ctc 24.856499 loss_rnnt 17.133644 hw_loss 0.068656 lr 0.00044580 rank 6
2023-02-22 05:05:58,476 DEBUG TRAIN Batch 15/700 loss 5.314436 loss_att 7.926549 loss_ctc 8.360079 loss_rnnt 4.275325 hw_loss 0.207380 lr 0.00044578 rank 3
2023-02-22 05:05:58,476 DEBUG TRAIN Batch 15/700 loss 10.737673 loss_att 15.997355 loss_ctc 14.665260 loss_rnnt 9.129570 hw_loss 0.060916 lr 0.00044576 rank 4
2023-02-22 05:05:58,519 DEBUG TRAIN Batch 15/700 loss 4.988423 loss_att 7.886036 loss_ctc 7.395944 loss_rnnt 4.002540 hw_loss 0.160045 lr 0.00044581 rank 1
2023-02-22 05:07:14,169 DEBUG TRAIN Batch 15/800 loss 4.722809 loss_att 7.414751 loss_ctc 7.465405 loss_rnnt 3.754932 hw_loss 0.119642 lr 0.00044551 rank 5
2023-02-22 05:07:14,170 DEBUG TRAIN Batch 15/800 loss 8.913478 loss_att 14.129930 loss_ctc 14.501680 loss_rnnt 7.088457 hw_loss 0.068693 lr 0.00044558 rank 0
2023-02-22 05:07:14,171 DEBUG TRAIN Batch 15/800 loss 11.110274 loss_att 10.307866 loss_ctc 11.635820 loss_rnnt 11.167879 hw_loss 0.061506 lr 0.00044553 rank 7
2023-02-22 05:07:14,172 DEBUG TRAIN Batch 15/800 loss 18.491714 loss_att 24.335678 loss_ctc 27.932468 loss_rnnt 16.011433 hw_loss 0.098853 lr 0.00044559 rank 4
2023-02-22 05:07:14,176 DEBUG TRAIN Batch 15/800 loss 13.734303 loss_att 13.857924 loss_ctc 17.674660 loss_rnnt 13.157864 hw_loss 0.049380 lr 0.00044563 rank 1
2023-02-22 05:07:14,177 DEBUG TRAIN Batch 15/800 loss 12.025630 loss_att 16.471792 loss_ctc 16.094807 loss_rnnt 10.545217 hw_loss 0.091169 lr 0.00044555 rank 2
2023-02-22 05:07:14,179 DEBUG TRAIN Batch 15/800 loss 19.127140 loss_att 24.609634 loss_ctc 30.637341 loss_rnnt 16.422606 hw_loss 0.137522 lr 0.00044560 rank 3
2023-02-22 05:07:14,225 DEBUG TRAIN Batch 15/800 loss 14.400240 loss_att 21.183479 loss_ctc 16.759174 loss_rnnt 12.656590 hw_loss 0.135897 lr 0.00044563 rank 6
2023-02-22 05:08:28,913 DEBUG TRAIN Batch 15/900 loss 20.399433 loss_att 22.944485 loss_ctc 25.253155 loss_rnnt 19.115997 hw_loss 0.238615 lr 0.00044541 rank 0
2023-02-22 05:08:28,914 DEBUG TRAIN Batch 15/900 loss 15.622250 loss_att 19.012451 loss_ctc 18.320629 loss_rnnt 14.483290 hw_loss 0.189632 lr 0.00044546 rank 1
2023-02-22 05:08:28,916 DEBUG TRAIN Batch 15/900 loss 13.693662 loss_att 16.727922 loss_ctc 16.905165 loss_rnnt 12.605736 hw_loss 0.099136 lr 0.00044545 rank 6
2023-02-22 05:08:28,916 DEBUG TRAIN Batch 15/900 loss 7.223574 loss_att 13.505418 loss_ctc 9.978182 loss_rnnt 5.548839 hw_loss 0.095785 lr 0.00044535 rank 7
2023-02-22 05:08:28,917 DEBUG TRAIN Batch 15/900 loss 19.792881 loss_att 21.610233 loss_ctc 29.481834 loss_rnnt 18.010353 hw_loss 0.238496 lr 0.00044537 rank 2
2023-02-22 05:08:28,917 DEBUG TRAIN Batch 15/900 loss 5.244726 loss_att 9.293631 loss_ctc 5.813728 loss_rnnt 4.305527 hw_loss 0.100409 lr 0.00044541 rank 4
2023-02-22 05:08:28,919 DEBUG TRAIN Batch 15/900 loss 17.965134 loss_att 17.254789 loss_ctc 20.910952 loss_rnnt 17.629726 hw_loss 0.158813 lr 0.00044534 rank 5
2023-02-22 05:08:28,921 DEBUG TRAIN Batch 15/900 loss 10.598417 loss_att 14.645985 loss_ctc 13.706303 loss_rnnt 9.306878 hw_loss 0.126827 lr 0.00044543 rank 3
2023-02-22 05:09:44,024 DEBUG TRAIN Batch 15/1000 loss 11.859076 loss_att 14.299318 loss_ctc 13.123037 loss_rnnt 11.102312 hw_loss 0.187852 lr 0.00044516 rank 5
2023-02-22 05:09:44,027 DEBUG TRAIN Batch 15/1000 loss 7.682487 loss_att 10.610296 loss_ctc 9.053627 loss_rnnt 6.863751 hw_loss 0.094416 lr 0.00044523 rank 4
2023-02-22 05:09:44,030 DEBUG TRAIN Batch 15/1000 loss 10.083904 loss_att 13.741240 loss_ctc 14.401613 loss_rnnt 8.715231 hw_loss 0.115336 lr 0.00044523 rank 0
2023-02-22 05:09:44,030 DEBUG TRAIN Batch 15/1000 loss 9.639090 loss_att 12.940298 loss_ctc 17.747658 loss_rnnt 7.863924 hw_loss 0.063338 lr 0.00044518 rank 7
2023-02-22 05:09:44,033 DEBUG TRAIN Batch 15/1000 loss 7.195035 loss_att 11.716923 loss_ctc 11.976961 loss_rnnt 5.568069 hw_loss 0.159373 lr 0.00044525 rank 3
2023-02-22 05:09:44,033 DEBUG TRAIN Batch 15/1000 loss 13.770859 loss_att 19.501181 loss_ctc 23.570765 loss_rnnt 11.287230 hw_loss 0.057959 lr 0.00044528 rank 1
2023-02-22 05:09:44,034 DEBUG TRAIN Batch 15/1000 loss 8.162643 loss_att 13.153502 loss_ctc 10.377724 loss_rnnt 6.845984 hw_loss 0.043395 lr 0.00044520 rank 2
2023-02-22 05:09:44,079 DEBUG TRAIN Batch 15/1000 loss 13.214828 loss_att 14.811503 loss_ctc 15.509636 loss_rnnt 12.506264 hw_loss 0.156102 lr 0.00044527 rank 6
2023-02-22 05:11:02,354 DEBUG TRAIN Batch 15/1100 loss 15.727330 loss_att 19.032701 loss_ctc 18.113359 loss_rnnt 14.679104 hw_loss 0.129405 lr 0.00044506 rank 4
2023-02-22 05:11:02,354 DEBUG TRAIN Batch 15/1100 loss 12.634029 loss_att 15.830702 loss_ctc 16.368429 loss_rnnt 11.440728 hw_loss 0.105089 lr 0.00044505 rank 0
2023-02-22 05:11:02,357 DEBUG TRAIN Batch 15/1100 loss 5.864947 loss_att 8.633459 loss_ctc 9.286127 loss_rnnt 4.740832 hw_loss 0.214229 lr 0.00044500 rank 7
2023-02-22 05:11:02,360 DEBUG TRAIN Batch 15/1100 loss 7.890063 loss_att 14.283604 loss_ctc 12.265571 loss_rnnt 6.006448 hw_loss 0.040323 lr 0.00044510 rank 6
2023-02-22 05:11:02,361 DEBUG TRAIN Batch 15/1100 loss 16.575291 loss_att 19.037724 loss_ctc 23.978828 loss_rnnt 15.066677 hw_loss 0.054350 lr 0.00044510 rank 1
2023-02-22 05:11:02,362 DEBUG TRAIN Batch 15/1100 loss 11.534416 loss_att 15.934696 loss_ctc 17.502483 loss_rnnt 9.843618 hw_loss 0.028123 lr 0.00044499 rank 5
2023-02-22 05:11:02,364 DEBUG TRAIN Batch 15/1100 loss 16.370731 loss_att 20.631151 loss_ctc 21.473454 loss_rnnt 14.766061 hw_loss 0.135419 lr 0.00044502 rank 2
2023-02-22 05:11:02,366 DEBUG TRAIN Batch 15/1100 loss 17.227322 loss_att 21.855343 loss_ctc 27.856964 loss_rnnt 14.883862 hw_loss 0.001067 lr 0.00044507 rank 3
2023-02-22 05:12:18,615 DEBUG TRAIN Batch 15/1200 loss 7.593291 loss_att 9.465518 loss_ctc 11.290313 loss_rnnt 6.664991 hw_loss 0.114220 lr 0.00044483 rank 7
2023-02-22 05:12:18,616 DEBUG TRAIN Batch 15/1200 loss 9.732866 loss_att 11.209146 loss_ctc 16.323835 loss_rnnt 8.503514 hw_loss 0.103687 lr 0.00044488 rank 4
2023-02-22 05:12:18,616 DEBUG TRAIN Batch 15/1200 loss 8.831120 loss_att 9.155301 loss_ctc 11.825032 loss_rnnt 8.260272 hw_loss 0.200296 lr 0.00044481 rank 5
2023-02-22 05:12:18,617 DEBUG TRAIN Batch 15/1200 loss 7.029685 loss_att 9.270021 loss_ctc 9.419862 loss_rnnt 6.182266 hw_loss 0.151241 lr 0.00044484 rank 2
2023-02-22 05:12:18,618 DEBUG TRAIN Batch 15/1200 loss 17.267941 loss_att 20.337048 loss_ctc 22.451918 loss_rnnt 15.817458 hw_loss 0.272745 lr 0.00044493 rank 1
2023-02-22 05:12:18,621 DEBUG TRAIN Batch 15/1200 loss 12.540577 loss_att 11.728863 loss_ctc 12.085321 loss_rnnt 12.660338 hw_loss 0.193654 lr 0.00044488 rank 0
2023-02-22 05:12:18,623 DEBUG TRAIN Batch 15/1200 loss 14.050936 loss_att 15.440914 loss_ctc 17.036093 loss_rnnt 13.345976 hw_loss 0.054269 lr 0.00044492 rank 6
2023-02-22 05:12:18,628 DEBUG TRAIN Batch 15/1200 loss 8.765169 loss_att 11.790348 loss_ctc 10.778672 loss_rnnt 7.836364 hw_loss 0.103694 lr 0.00044490 rank 3
2023-02-22 05:13:32,960 DEBUG TRAIN Batch 15/1300 loss 9.806890 loss_att 9.498846 loss_ctc 12.948586 loss_rnnt 9.326866 hw_loss 0.230137 lr 0.00044471 rank 4
2023-02-22 05:13:32,966 DEBUG TRAIN Batch 15/1300 loss 15.491228 loss_att 16.903248 loss_ctc 19.627575 loss_rnnt 14.487274 hw_loss 0.318820 lr 0.00044470 rank 0
2023-02-22 05:13:32,968 DEBUG TRAIN Batch 15/1300 loss 8.145148 loss_att 12.673519 loss_ctc 14.314032 loss_rnnt 6.333095 hw_loss 0.157243 lr 0.00044463 rank 5
2023-02-22 05:13:32,969 DEBUG TRAIN Batch 15/1300 loss 8.037765 loss_att 12.200333 loss_ctc 9.608799 loss_rnnt 6.952351 hw_loss 0.081429 lr 0.00044465 rank 7
2023-02-22 05:13:32,972 DEBUG TRAIN Batch 15/1300 loss 21.887903 loss_att 25.454760 loss_ctc 30.704166 loss_rnnt 19.840857 hw_loss 0.296574 lr 0.00044474 rank 6
2023-02-22 05:13:32,973 DEBUG TRAIN Batch 15/1300 loss 5.742409 loss_att 10.703787 loss_ctc 6.828182 loss_rnnt 4.500343 hw_loss 0.196912 lr 0.00044467 rank 2
2023-02-22 05:13:32,990 DEBUG TRAIN Batch 15/1300 loss 2.945509 loss_att 9.026719 loss_ctc 5.321928 loss_rnnt 1.355857 hw_loss 0.106039 lr 0.00044475 rank 1
2023-02-22 05:13:33,002 DEBUG TRAIN Batch 15/1300 loss 4.892185 loss_att 10.724940 loss_ctc 6.060055 loss_rnnt 3.510105 hw_loss 0.112150 lr 0.00044472 rank 3
2023-02-22 05:14:50,611 DEBUG TRAIN Batch 15/1400 loss 5.777582 loss_att 9.351592 loss_ctc 8.922224 loss_rnnt 4.581762 hw_loss 0.115746 lr 0.00044453 rank 4
2023-02-22 05:14:50,612 DEBUG TRAIN Batch 15/1400 loss 11.679429 loss_att 14.019141 loss_ctc 14.265169 loss_rnnt 10.841097 hw_loss 0.048046 lr 0.00044452 rank 0
2023-02-22 05:14:50,614 DEBUG TRAIN Batch 15/1400 loss 15.059695 loss_att 14.023003 loss_ctc 17.512203 loss_rnnt 14.818614 hw_loss 0.227660 lr 0.00044446 rank 5
2023-02-22 05:14:50,615 DEBUG TRAIN Batch 15/1400 loss 4.382330 loss_att 7.650973 loss_ctc 8.233990 loss_rnnt 3.196774 hw_loss 0.034263 lr 0.00044458 rank 1
2023-02-22 05:14:50,616 DEBUG TRAIN Batch 15/1400 loss 14.897646 loss_att 18.310684 loss_ctc 17.766251 loss_rnnt 13.718703 hw_loss 0.213478 lr 0.00044447 rank 7
2023-02-22 05:14:50,618 DEBUG TRAIN Batch 15/1400 loss 7.785282 loss_att 10.126734 loss_ctc 11.834032 loss_rnnt 6.697680 hw_loss 0.149021 lr 0.00044455 rank 3
2023-02-22 05:14:50,620 DEBUG TRAIN Batch 15/1400 loss 6.993424 loss_att 9.833030 loss_ctc 10.832428 loss_rnnt 5.841783 hw_loss 0.134724 lr 0.00044449 rank 2
2023-02-22 05:14:50,621 DEBUG TRAIN Batch 15/1400 loss 3.943508 loss_att 6.232391 loss_ctc 5.170081 loss_rnnt 3.195116 hw_loss 0.238261 lr 0.00044457 rank 6
2023-02-22 05:16:08,351 DEBUG TRAIN Batch 15/1500 loss 5.186544 loss_att 10.357786 loss_ctc 6.473399 loss_rnnt 3.903685 hw_loss 0.144432 lr 0.00044435 rank 0
2023-02-22 05:16:08,355 DEBUG TRAIN Batch 15/1500 loss 15.376483 loss_att 20.237911 loss_ctc 23.084995 loss_rnnt 13.240924 hw_loss 0.254012 lr 0.00044428 rank 5
2023-02-22 05:16:08,356 DEBUG TRAIN Batch 15/1500 loss 7.673465 loss_att 9.759983 loss_ctc 7.368978 loss_rnnt 7.270372 hw_loss 0.049475 lr 0.00044432 rank 2
2023-02-22 05:16:08,357 DEBUG TRAIN Batch 15/1500 loss 14.378143 loss_att 21.676540 loss_ctc 16.657309 loss_rnnt 12.551848 hw_loss 0.117614 lr 0.00044435 rank 4
2023-02-22 05:16:08,358 DEBUG TRAIN Batch 15/1500 loss 14.045687 loss_att 17.545664 loss_ctc 16.086033 loss_rnnt 12.943130 hw_loss 0.244713 lr 0.00044437 rank 3
2023-02-22 05:16:08,360 DEBUG TRAIN Batch 15/1500 loss 11.565436 loss_att 12.784094 loss_ctc 18.214567 loss_rnnt 10.366182 hw_loss 0.129322 lr 0.00044430 rank 7
2023-02-22 05:16:08,362 DEBUG TRAIN Batch 15/1500 loss 18.575731 loss_att 19.004698 loss_ctc 22.153908 loss_rnnt 17.945786 hw_loss 0.125741 lr 0.00044439 rank 6
2023-02-22 05:16:08,365 DEBUG TRAIN Batch 15/1500 loss 13.351480 loss_att 15.427671 loss_ctc 17.230947 loss_rnnt 12.399645 hw_loss 0.036250 lr 0.00044440 rank 1
2023-02-22 05:17:22,623 DEBUG TRAIN Batch 15/1600 loss 10.496130 loss_att 13.182253 loss_ctc 11.765127 loss_rnnt 9.770606 hw_loss 0.035812 lr 0.00044418 rank 4
2023-02-22 05:17:22,628 DEBUG TRAIN Batch 15/1600 loss 8.591564 loss_att 9.341370 loss_ctc 10.727886 loss_rnnt 8.058407 hw_loss 0.184411 lr 0.00044411 rank 5
2023-02-22 05:17:22,629 DEBUG TRAIN Batch 15/1600 loss 15.893748 loss_att 17.778610 loss_ctc 22.046289 loss_rnnt 14.595415 hw_loss 0.189415 lr 0.00044412 rank 7
2023-02-22 05:17:22,633 DEBUG TRAIN Batch 15/1600 loss 15.886545 loss_att 22.752367 loss_ctc 24.578590 loss_rnnt 13.293616 hw_loss 0.114048 lr 0.00044417 rank 0
2023-02-22 05:17:22,633 DEBUG TRAIN Batch 15/1600 loss 9.782091 loss_att 10.693530 loss_ctc 10.970790 loss_rnnt 9.361561 hw_loss 0.149530 lr 0.00044414 rank 2
2023-02-22 05:17:22,633 DEBUG TRAIN Batch 15/1600 loss 10.626816 loss_att 16.411451 loss_ctc 13.693026 loss_rnnt 8.980100 hw_loss 0.151800 lr 0.00044419 rank 3
2023-02-22 05:17:22,636 DEBUG TRAIN Batch 15/1600 loss 18.531771 loss_att 19.027170 loss_ctc 23.151365 loss_rnnt 17.754520 hw_loss 0.116668 lr 0.00044422 rank 6
2023-02-22 05:17:22,683 DEBUG TRAIN Batch 15/1600 loss 10.232584 loss_att 12.077991 loss_ctc 12.697486 loss_rnnt 9.429579 hw_loss 0.197383 lr 0.00044422 rank 1
2023-02-22 05:18:37,465 DEBUG TRAIN Batch 15/1700 loss 12.128939 loss_att 17.298302 loss_ctc 16.932207 loss_rnnt 10.363883 hw_loss 0.170150 lr 0.00044405 rank 1
2023-02-22 05:18:37,469 DEBUG TRAIN Batch 15/1700 loss 12.304345 loss_att 15.459964 loss_ctc 20.773865 loss_rnnt 10.495619 hw_loss 0.090625 lr 0.00044393 rank 5
2023-02-22 05:18:37,470 DEBUG TRAIN Batch 15/1700 loss 13.073570 loss_att 16.466732 loss_ctc 17.606598 loss_rnnt 11.681141 hw_loss 0.205112 lr 0.00044400 rank 0
2023-02-22 05:18:37,471 DEBUG TRAIN Batch 15/1700 loss 9.765982 loss_att 14.708936 loss_ctc 13.983394 loss_rnnt 8.111445 hw_loss 0.194294 lr 0.00044402 rank 3
2023-02-22 05:18:37,471 DEBUG TRAIN Batch 15/1700 loss 7.324323 loss_att 9.133868 loss_ctc 6.898604 loss_rnnt 6.928854 hw_loss 0.169353 lr 0.00044395 rank 7
2023-02-22 05:18:37,471 DEBUG TRAIN Batch 15/1700 loss 5.783325 loss_att 10.478924 loss_ctc 8.088490 loss_rnnt 4.472647 hw_loss 0.120381 lr 0.00044397 rank 2
2023-02-22 05:18:37,473 DEBUG TRAIN Batch 15/1700 loss 4.865876 loss_att 9.609262 loss_ctc 6.972538 loss_rnnt 3.614176 hw_loss 0.041500 lr 0.00044400 rank 4
2023-02-22 05:18:37,477 DEBUG TRAIN Batch 15/1700 loss 22.921043 loss_att 23.736225 loss_ctc 27.246403 loss_rnnt 22.123293 hw_loss 0.108746 lr 0.00044404 rank 6
2023-02-22 05:19:55,735 DEBUG TRAIN Batch 15/1800 loss 13.128848 loss_att 13.454981 loss_ctc 13.696085 loss_rnnt 12.878245 hw_loss 0.205772 lr 0.00044377 rank 7
2023-02-22 05:19:55,739 DEBUG TRAIN Batch 15/1800 loss 12.214495 loss_att 13.162239 loss_ctc 13.684868 loss_rnnt 11.697050 hw_loss 0.247214 lr 0.00044384 rank 3
2023-02-22 05:19:55,740 DEBUG TRAIN Batch 15/1800 loss 12.816060 loss_att 16.552364 loss_ctc 15.599559 loss_rnnt 11.613335 hw_loss 0.158122 lr 0.00044382 rank 0
2023-02-22 05:19:55,741 DEBUG TRAIN Batch 15/1800 loss 13.735144 loss_att 14.982224 loss_ctc 22.010031 loss_rnnt 12.302363 hw_loss 0.150086 lr 0.00044387 rank 6
2023-02-22 05:19:55,740 DEBUG TRAIN Batch 15/1800 loss 19.454855 loss_att 20.642857 loss_ctc 25.627914 loss_rnnt 18.267370 hw_loss 0.237770 lr 0.00044383 rank 4
2023-02-22 05:19:55,745 DEBUG TRAIN Batch 15/1800 loss 4.016218 loss_att 7.576088 loss_ctc 7.107072 loss_rnnt 2.818728 hw_loss 0.137630 lr 0.00044387 rank 1
2023-02-22 05:19:55,747 DEBUG TRAIN Batch 15/1800 loss 5.651490 loss_att 7.260554 loss_ctc 7.898983 loss_rnnt 5.004691 hw_loss 0.047476 lr 0.00044376 rank 5
2023-02-22 05:19:55,752 DEBUG TRAIN Batch 15/1800 loss 9.318128 loss_att 10.889112 loss_ctc 11.027149 loss_rnnt 8.712807 hw_loss 0.118601 lr 0.00044379 rank 2
2023-02-22 05:21:09,614 DEBUG TRAIN Batch 15/1900 loss 10.164944 loss_att 14.461642 loss_ctc 11.925806 loss_rnnt 9.013462 hw_loss 0.107552 lr 0.00044358 rank 5
2023-02-22 05:21:09,615 DEBUG TRAIN Batch 15/1900 loss 5.855560 loss_att 7.293165 loss_ctc 8.582581 loss_rnnt 5.096132 hw_loss 0.203071 lr 0.00044365 rank 4
2023-02-22 05:21:09,617 DEBUG TRAIN Batch 15/1900 loss 8.629230 loss_att 9.942603 loss_ctc 11.143126 loss_rnnt 7.943677 hw_loss 0.164423 lr 0.00044360 rank 7
2023-02-22 05:21:09,621 DEBUG TRAIN Batch 15/1900 loss 7.858331 loss_att 8.476989 loss_ctc 12.940524 loss_rnnt 6.945526 hw_loss 0.208963 lr 0.00044365 rank 0
2023-02-22 05:21:09,624 DEBUG TRAIN Batch 15/1900 loss 22.485231 loss_att 24.904247 loss_ctc 29.772009 loss_rnnt 20.964073 hw_loss 0.123342 lr 0.00044369 rank 6
2023-02-22 05:21:09,624 DEBUG TRAIN Batch 15/1900 loss 6.108991 loss_att 8.864120 loss_ctc 7.962768 loss_rnnt 5.268818 hw_loss 0.078707 lr 0.00044367 rank 3
2023-02-22 05:21:09,625 DEBUG TRAIN Batch 15/1900 loss 9.238755 loss_att 9.098787 loss_ctc 13.453779 loss_rnnt 8.608547 hw_loss 0.180371 lr 0.00044370 rank 1
2023-02-22 05:21:09,627 DEBUG TRAIN Batch 15/1900 loss 10.346767 loss_att 9.774471 loss_ctc 12.669518 loss_rnnt 10.008813 hw_loss 0.267587 lr 0.00044362 rank 2
2023-02-22 05:22:24,729 DEBUG TRAIN Batch 15/2000 loss 13.886786 loss_att 16.068323 loss_ctc 19.276960 loss_rnnt 12.641747 hw_loss 0.168828 lr 0.00044341 rank 5
2023-02-22 05:22:24,734 DEBUG TRAIN Batch 15/2000 loss 4.782637 loss_att 9.850580 loss_ctc 7.316358 loss_rnnt 3.399786 hw_loss 0.058936 lr 0.00044349 rank 3
2023-02-22 05:22:24,738 DEBUG TRAIN Batch 15/2000 loss 6.320274 loss_att 12.041115 loss_ctc 10.328087 loss_rnnt 4.556379 hw_loss 0.160033 lr 0.00044347 rank 0
2023-02-22 05:22:24,739 DEBUG TRAIN Batch 15/2000 loss 9.684538 loss_att 13.501545 loss_ctc 14.096634 loss_rnnt 8.248151 hw_loss 0.158824 lr 0.00044348 rank 4
2023-02-22 05:22:24,740 DEBUG TRAIN Batch 15/2000 loss 8.335535 loss_att 13.119387 loss_ctc 14.026045 loss_rnnt 6.508671 hw_loss 0.208798 lr 0.00044342 rank 7
2023-02-22 05:22:24,740 DEBUG TRAIN Batch 15/2000 loss 27.280008 loss_att 28.397091 loss_ctc 36.173012 loss_rnnt 25.777309 hw_loss 0.175406 lr 0.00044352 rank 1
2023-02-22 05:22:24,744 DEBUG TRAIN Batch 15/2000 loss 16.259132 loss_att 17.937592 loss_ctc 23.711164 loss_rnnt 14.840200 hw_loss 0.168068 lr 0.00044344 rank 2
2023-02-22 05:22:24,791 DEBUG TRAIN Batch 15/2000 loss 6.896773 loss_att 10.548073 loss_ctc 8.873900 loss_rnnt 5.847536 hw_loss 0.103801 lr 0.00044352 rank 6
2023-02-22 05:23:41,905 DEBUG TRAIN Batch 15/2100 loss 5.516824 loss_att 7.838410 loss_ctc 7.245239 loss_rnnt 4.712739 hw_loss 0.204961 lr 0.00044330 rank 0
2023-02-22 05:23:41,905 DEBUG TRAIN Batch 15/2100 loss 10.564983 loss_att 11.866405 loss_ctc 11.956038 loss_rnnt 10.097666 hw_loss 0.040424 lr 0.00044330 rank 4
2023-02-22 05:23:41,907 DEBUG TRAIN Batch 15/2100 loss 8.608547 loss_att 11.402299 loss_ctc 11.110133 loss_rnnt 7.583133 hw_loss 0.249598 lr 0.00044325 rank 7
2023-02-22 05:23:41,909 DEBUG TRAIN Batch 15/2100 loss 8.572330 loss_att 12.131371 loss_ctc 8.257236 loss_rnnt 7.864992 hw_loss 0.070390 lr 0.00044323 rank 5
2023-02-22 05:23:41,916 DEBUG TRAIN Batch 15/2100 loss 4.492479 loss_att 7.930371 loss_ctc 5.728787 loss_rnnt 3.524956 hw_loss 0.215820 lr 0.00044334 rank 6
2023-02-22 05:23:41,917 DEBUG TRAIN Batch 15/2100 loss 9.213127 loss_att 13.347534 loss_ctc 13.415543 loss_rnnt 7.714745 hw_loss 0.208461 lr 0.00044335 rank 1
2023-02-22 05:23:41,920 DEBUG TRAIN Batch 15/2100 loss 6.964272 loss_att 10.656702 loss_ctc 8.798828 loss_rnnt 5.910068 hw_loss 0.133334 lr 0.00044327 rank 2
2023-02-22 05:23:41,922 DEBUG TRAIN Batch 15/2100 loss 5.068389 loss_att 10.083372 loss_ctc 7.286191 loss_rnnt 3.704988 hw_loss 0.121308 lr 0.00044332 rank 3
2023-02-22 05:24:57,380 DEBUG TRAIN Batch 15/2200 loss 10.290040 loss_att 14.285423 loss_ctc 15.935903 loss_rnnt 8.644400 hw_loss 0.175841 lr 0.00044306 rank 5
2023-02-22 05:24:57,381 DEBUG TRAIN Batch 15/2200 loss 13.113913 loss_att 17.342861 loss_ctc 19.422657 loss_rnnt 11.311588 hw_loss 0.216317 lr 0.00044308 rank 7
2023-02-22 05:24:57,385 DEBUG TRAIN Batch 15/2200 loss 25.575905 loss_att 34.711620 loss_ctc 38.083881 loss_rnnt 21.984741 hw_loss 0.180545 lr 0.00044315 rank 3
2023-02-22 05:24:57,386 DEBUG TRAIN Batch 15/2200 loss 4.588758 loss_att 7.205432 loss_ctc 7.090288 loss_rnnt 3.673099 hw_loss 0.110223 lr 0.00044313 rank 4
2023-02-22 05:24:57,388 DEBUG TRAIN Batch 15/2200 loss 4.806586 loss_att 9.600151 loss_ctc 7.466974 loss_rnnt 3.414921 hw_loss 0.146690 lr 0.00044317 rank 6
2023-02-22 05:24:57,389 DEBUG TRAIN Batch 15/2200 loss 12.529211 loss_att 17.552977 loss_ctc 16.969910 loss_rnnt 10.849841 hw_loss 0.154733 lr 0.00044313 rank 0
2023-02-22 05:24:57,390 DEBUG TRAIN Batch 15/2200 loss 11.108225 loss_att 14.725685 loss_ctc 14.869289 loss_rnnt 9.840931 hw_loss 0.079363 lr 0.00044318 rank 1
2023-02-22 05:24:57,391 DEBUG TRAIN Batch 15/2200 loss 8.352894 loss_att 10.836088 loss_ctc 11.620539 loss_rnnt 7.398500 hw_loss 0.041379 lr 0.00044309 rank 2
2023-02-22 05:26:12,845 DEBUG TRAIN Batch 15/2300 loss 6.438674 loss_att 9.327293 loss_ctc 7.754233 loss_rnnt 5.634999 hw_loss 0.094768 lr 0.00044295 rank 0
2023-02-22 05:26:12,845 DEBUG TRAIN Batch 15/2300 loss 9.336158 loss_att 13.163757 loss_ctc 15.176787 loss_rnnt 7.738638 hw_loss 0.099843 lr 0.00044300 rank 1
2023-02-22 05:26:12,848 DEBUG TRAIN Batch 15/2300 loss 15.531836 loss_att 17.848089 loss_ctc 20.131485 loss_rnnt 14.374393 hw_loss 0.151698 lr 0.00044290 rank 7
2023-02-22 05:26:12,851 DEBUG TRAIN Batch 15/2300 loss 7.926261 loss_att 14.292094 loss_ctc 13.727543 loss_rnnt 5.851050 hw_loss 0.053514 lr 0.00044296 rank 4
2023-02-22 05:26:12,852 DEBUG TRAIN Batch 15/2300 loss 11.544698 loss_att 12.578260 loss_ctc 14.168715 loss_rnnt 10.909222 hw_loss 0.147930 lr 0.00044297 rank 3
2023-02-22 05:26:12,852 DEBUG TRAIN Batch 15/2300 loss 10.225333 loss_att 11.272676 loss_ctc 17.304634 loss_rnnt 9.040659 hw_loss 0.058686 lr 0.00044289 rank 5
2023-02-22 05:26:12,853 DEBUG TRAIN Batch 15/2300 loss 7.342664 loss_att 11.122959 loss_ctc 13.528103 loss_rnnt 5.660232 hw_loss 0.190590 lr 0.00044300 rank 6
2023-02-22 05:26:12,900 DEBUG TRAIN Batch 15/2300 loss 21.287783 loss_att 21.779484 loss_ctc 24.828981 loss_rnnt 20.627138 hw_loss 0.169019 lr 0.00044292 rank 2
2023-02-22 05:27:27,559 DEBUG TRAIN Batch 15/2400 loss 12.417815 loss_att 15.714607 loss_ctc 13.638867 loss_rnnt 11.525084 hw_loss 0.132312 lr 0.00044278 rank 4
2023-02-22 05:27:27,559 DEBUG TRAIN Batch 15/2400 loss 6.509174 loss_att 8.610302 loss_ctc 9.473517 loss_rnnt 5.629656 hw_loss 0.120087 lr 0.00044282 rank 6
2023-02-22 05:27:27,561 DEBUG TRAIN Batch 15/2400 loss 13.423123 loss_att 16.096230 loss_ctc 15.549321 loss_rnnt 12.538617 hw_loss 0.124486 lr 0.00044278 rank 0
2023-02-22 05:27:27,561 DEBUG TRAIN Batch 15/2400 loss 38.439754 loss_att 37.489388 loss_ctc 47.080898 loss_rnnt 37.380379 hw_loss 0.182433 lr 0.00044274 rank 2
2023-02-22 05:27:27,563 DEBUG TRAIN Batch 15/2400 loss 14.870385 loss_att 17.373755 loss_ctc 18.728748 loss_rnnt 13.746763 hw_loss 0.203435 lr 0.00044273 rank 7
2023-02-22 05:27:27,565 DEBUG TRAIN Batch 15/2400 loss 18.192606 loss_att 19.383354 loss_ctc 31.331844 loss_rnnt 16.129360 hw_loss 0.137250 lr 0.00044283 rank 1
2023-02-22 05:27:27,567 DEBUG TRAIN Batch 15/2400 loss 5.431061 loss_att 8.534828 loss_ctc 7.894837 loss_rnnt 4.439843 hw_loss 0.078676 lr 0.00044271 rank 5
2023-02-22 05:27:27,569 DEBUG TRAIN Batch 15/2400 loss 15.413138 loss_att 14.740755 loss_ctc 19.063551 loss_rnnt 14.963178 hw_loss 0.183218 lr 0.00044280 rank 3
2023-02-22 05:28:46,450 DEBUG TRAIN Batch 15/2500 loss 16.852226 loss_att 16.345587 loss_ctc 22.019661 loss_rnnt 16.138182 hw_loss 0.236963 lr 0.00044254 rank 5
2023-02-22 05:28:46,451 DEBUG TRAIN Batch 15/2500 loss 11.176553 loss_att 11.626295 loss_ctc 12.678926 loss_rnnt 10.773359 hw_loss 0.211741 lr 0.00044255 rank 7
2023-02-22 05:28:46,452 DEBUG TRAIN Batch 15/2500 loss 11.525410 loss_att 12.763487 loss_ctc 13.681900 loss_rnnt 10.899723 hw_loss 0.169760 lr 0.00044261 rank 4
2023-02-22 05:28:46,453 DEBUG TRAIN Batch 15/2500 loss 10.415874 loss_att 12.954561 loss_ctc 12.542230 loss_rnnt 9.526506 hw_loss 0.183967 lr 0.00044260 rank 0
2023-02-22 05:28:46,457 DEBUG TRAIN Batch 15/2500 loss 11.135891 loss_att 11.101267 loss_ctc 13.295220 loss_rnnt 10.684855 hw_loss 0.318844 lr 0.00044263 rank 3
2023-02-22 05:28:46,459 DEBUG TRAIN Batch 15/2500 loss 23.680143 loss_att 27.403194 loss_ctc 26.686300 loss_rnnt 22.495827 hw_loss 0.072907 lr 0.00044265 rank 6
2023-02-22 05:28:46,460 DEBUG TRAIN Batch 15/2500 loss 8.550874 loss_att 10.308168 loss_ctc 12.591677 loss_rnnt 7.592114 hw_loss 0.128486 lr 0.00044265 rank 1
2023-02-22 05:28:46,465 DEBUG TRAIN Batch 15/2500 loss 7.791737 loss_att 10.352240 loss_ctc 9.197658 loss_rnnt 7.047503 hw_loss 0.083768 lr 0.00044257 rank 2
2023-02-22 05:30:00,303 DEBUG TRAIN Batch 15/2600 loss 13.660124 loss_att 17.383776 loss_ctc 17.198198 loss_rnnt 12.346331 hw_loss 0.182470 lr 0.00044244 rank 4
2023-02-22 05:30:00,306 DEBUG TRAIN Batch 15/2600 loss 12.504504 loss_att 15.098572 loss_ctc 15.377710 loss_rnnt 11.507996 hw_loss 0.177375 lr 0.00044243 rank 0
2023-02-22 05:30:00,306 DEBUG TRAIN Batch 15/2600 loss 10.686001 loss_att 14.737800 loss_ctc 14.720585 loss_rnnt 9.174669 hw_loss 0.305677 lr 0.00044248 rank 1
2023-02-22 05:30:00,308 DEBUG TRAIN Batch 15/2600 loss 4.444581 loss_att 10.214286 loss_ctc 9.409880 loss_rnnt 2.623291 hw_loss 0.009954 lr 0.00044238 rank 7
2023-02-22 05:30:00,311 DEBUG TRAIN Batch 15/2600 loss 21.112526 loss_att 22.280197 loss_ctc 35.786388 loss_rnnt 18.840485 hw_loss 0.153739 lr 0.00044245 rank 3
2023-02-22 05:30:00,314 DEBUG TRAIN Batch 15/2600 loss 7.801947 loss_att 9.632041 loss_ctc 8.905463 loss_rnnt 7.212996 hw_loss 0.142118 lr 0.00044247 rank 6
2023-02-22 05:30:00,314 DEBUG TRAIN Batch 15/2600 loss 7.398220 loss_att 9.882635 loss_ctc 11.622589 loss_rnnt 6.259444 hw_loss 0.147456 lr 0.00044237 rank 5
2023-02-22 05:30:00,357 DEBUG TRAIN Batch 15/2600 loss 10.390218 loss_att 12.756405 loss_ctc 15.630758 loss_rnnt 9.159886 hw_loss 0.109416 lr 0.00044240 rank 2
2023-02-22 05:31:15,323 DEBUG TRAIN Batch 15/2700 loss 4.436505 loss_att 9.692148 loss_ctc 4.992527 loss_rnnt 3.267443 hw_loss 0.082120 lr 0.00044219 rank 5
2023-02-22 05:31:15,324 DEBUG TRAIN Batch 15/2700 loss 8.576496 loss_att 13.552096 loss_ctc 14.439562 loss_rnnt 6.704084 hw_loss 0.179155 lr 0.00044221 rank 7
2023-02-22 05:31:15,331 DEBUG TRAIN Batch 15/2700 loss 6.580293 loss_att 10.576773 loss_ctc 9.195030 loss_rnnt 5.384391 hw_loss 0.089950 lr 0.00044226 rank 0
2023-02-22 05:31:15,333 DEBUG TRAIN Batch 15/2700 loss 5.948624 loss_att 10.213658 loss_ctc 8.121964 loss_rnnt 4.761591 hw_loss 0.082964 lr 0.00044231 rank 1
2023-02-22 05:31:15,333 DEBUG TRAIN Batch 15/2700 loss 13.561130 loss_att 17.046803 loss_ctc 15.862425 loss_rnnt 12.509901 hw_loss 0.088603 lr 0.00044226 rank 4
2023-02-22 05:31:15,335 DEBUG TRAIN Batch 15/2700 loss 8.827663 loss_att 10.070398 loss_ctc 10.852271 loss_rnnt 8.265715 hw_loss 0.081477 lr 0.00044230 rank 6
2023-02-22 05:31:15,338 DEBUG TRAIN Batch 15/2700 loss 8.048717 loss_att 10.805120 loss_ctc 9.719903 loss_rnnt 7.233417 hw_loss 0.077239 lr 0.00044223 rank 2
2023-02-22 05:31:15,338 DEBUG TRAIN Batch 15/2700 loss 3.945131 loss_att 7.838113 loss_ctc 4.698759 loss_rnnt 3.002528 hw_loss 0.119106 lr 0.00044228 rank 3
2023-02-22 05:32:32,032 DEBUG TRAIN Batch 15/2800 loss 11.226926 loss_att 14.827406 loss_ctc 15.642065 loss_rnnt 9.865261 hw_loss 0.099157 lr 0.00044202 rank 5
2023-02-22 05:32:32,035 DEBUG TRAIN Batch 15/2800 loss 22.870605 loss_att 25.023685 loss_ctc 32.152748 loss_rnnt 21.177299 hw_loss 0.047005 lr 0.00044209 rank 4
2023-02-22 05:32:32,036 DEBUG TRAIN Batch 15/2800 loss 5.801293 loss_att 9.576944 loss_ctc 7.849027 loss_rnnt 4.715973 hw_loss 0.107173 lr 0.00044214 rank 1
2023-02-22 05:32:32,037 DEBUG TRAIN Batch 15/2800 loss 20.538071 loss_att 22.672159 loss_ctc 27.195736 loss_rnnt 19.107456 hw_loss 0.217706 lr 0.00044203 rank 7
2023-02-22 05:32:32,037 DEBUG TRAIN Batch 15/2800 loss 12.956532 loss_att 18.294271 loss_ctc 20.359921 loss_rnnt 10.869151 hw_loss 0.061340 lr 0.00044213 rank 6
2023-02-22 05:32:32,038 DEBUG TRAIN Batch 15/2800 loss 11.061282 loss_att 15.550605 loss_ctc 15.131570 loss_rnnt 9.580013 hw_loss 0.076310 lr 0.00044211 rank 3
2023-02-22 05:32:32,039 DEBUG TRAIN Batch 15/2800 loss 5.618651 loss_att 8.010262 loss_ctc 5.360345 loss_rnnt 5.150282 hw_loss 0.045915 lr 0.00044205 rank 2
2023-02-22 05:32:32,041 DEBUG TRAIN Batch 15/2800 loss 3.405050 loss_att 6.534055 loss_ctc 6.011252 loss_rnnt 2.327727 hw_loss 0.195052 lr 0.00044209 rank 0
2023-02-22 05:33:48,610 DEBUG TRAIN Batch 15/2900 loss 17.798529 loss_att 22.024172 loss_ctc 23.383541 loss_rnnt 16.117872 hw_loss 0.170363 lr 0.00044186 rank 7
2023-02-22 05:33:48,617 DEBUG TRAIN Batch 15/2900 loss 9.184985 loss_att 13.026901 loss_ctc 11.247252 loss_rnnt 8.068319 hw_loss 0.137463 lr 0.00044191 rank 0
2023-02-22 05:33:48,617 DEBUG TRAIN Batch 15/2900 loss 6.324551 loss_att 9.653452 loss_ctc 9.610862 loss_rnnt 5.173724 hw_loss 0.087885 lr 0.00044192 rank 4
2023-02-22 05:33:48,618 DEBUG TRAIN Batch 15/2900 loss 9.080817 loss_att 12.702692 loss_ctc 11.916603 loss_rnnt 7.862105 hw_loss 0.217935 lr 0.00044188 rank 2
2023-02-22 05:33:48,621 DEBUG TRAIN Batch 15/2900 loss 12.496806 loss_att 14.881044 loss_ctc 14.538434 loss_rnnt 11.661882 hw_loss 0.160984 lr 0.00044185 rank 5
2023-02-22 05:33:48,622 DEBUG TRAIN Batch 15/2900 loss 6.936460 loss_att 12.141291 loss_ctc 12.636553 loss_rnnt 5.040426 hw_loss 0.178229 lr 0.00044196 rank 1
2023-02-22 05:33:48,623 DEBUG TRAIN Batch 15/2900 loss 10.298225 loss_att 13.120461 loss_ctc 13.421756 loss_rnnt 9.256411 hw_loss 0.114181 lr 0.00044193 rank 3
2023-02-22 05:33:48,625 DEBUG TRAIN Batch 15/2900 loss 7.440515 loss_att 10.186152 loss_ctc 10.951920 loss_rnnt 6.325066 hw_loss 0.184001 lr 0.00044196 rank 6
2023-02-22 05:35:04,699 DEBUG TRAIN Batch 15/3000 loss 12.867268 loss_att 15.533588 loss_ctc 15.977285 loss_rnnt 11.806705 hw_loss 0.211179 lr 0.00044176 rank 3
2023-02-22 05:35:04,701 DEBUG TRAIN Batch 15/3000 loss 6.118026 loss_att 10.449143 loss_ctc 10.565813 loss_rnnt 4.573449 hw_loss 0.159964 lr 0.00044174 rank 0
2023-02-22 05:35:04,702 DEBUG TRAIN Batch 15/3000 loss 7.217071 loss_att 9.830665 loss_ctc 8.869473 loss_rnnt 6.414924 hw_loss 0.110827 lr 0.00044169 rank 7
2023-02-22 05:35:04,704 DEBUG TRAIN Batch 15/3000 loss 11.682498 loss_att 15.929006 loss_ctc 17.237560 loss_rnnt 10.005936 hw_loss 0.162348 lr 0.00044175 rank 4
2023-02-22 05:35:04,706 DEBUG TRAIN Batch 15/3000 loss 10.892273 loss_att 14.673320 loss_ctc 13.714890 loss_rnnt 9.726664 hw_loss 0.061969 lr 0.00044171 rank 2
2023-02-22 05:35:04,706 DEBUG TRAIN Batch 15/3000 loss 14.354959 loss_att 17.721123 loss_ctc 16.957731 loss_rnnt 13.319254 hw_loss 0.028939 lr 0.00044179 rank 1
2023-02-22 05:35:04,710 DEBUG TRAIN Batch 15/3000 loss 12.824119 loss_att 15.047187 loss_ctc 16.891899 loss_rnnt 11.747855 hw_loss 0.167399 lr 0.00044167 rank 5
2023-02-22 05:35:04,711 DEBUG TRAIN Batch 15/3000 loss 10.125463 loss_att 17.206995 loss_ctc 16.338192 loss_rnnt 7.852338 hw_loss 0.053352 lr 0.00044178 rank 6
2023-02-22 05:36:20,137 DEBUG TRAIN Batch 15/3100 loss 23.144629 loss_att 24.306576 loss_ctc 28.487190 loss_rnnt 22.139694 hw_loss 0.112881 lr 0.00044150 rank 5
2023-02-22 05:36:20,142 DEBUG TRAIN Batch 15/3100 loss 15.722713 loss_att 18.516777 loss_ctc 18.614948 loss_rnnt 14.681836 hw_loss 0.180810 lr 0.00044157 rank 4
2023-02-22 05:36:20,143 DEBUG TRAIN Batch 15/3100 loss 6.485427 loss_att 7.831898 loss_ctc 8.969309 loss_rnnt 5.800498 hw_loss 0.158347 lr 0.00044161 rank 6
2023-02-22 05:36:20,145 DEBUG TRAIN Batch 15/3100 loss 8.793459 loss_att 11.208836 loss_ctc 12.821527 loss_rnnt 7.701266 hw_loss 0.135079 lr 0.00044152 rank 7
2023-02-22 05:36:20,146 DEBUG TRAIN Batch 15/3100 loss 10.158394 loss_att 11.707891 loss_ctc 14.303624 loss_rnnt 9.180922 hw_loss 0.215392 lr 0.00044157 rank 0
2023-02-22 05:36:20,147 DEBUG TRAIN Batch 15/3100 loss 11.195482 loss_att 14.297087 loss_ctc 17.452671 loss_rnnt 9.652136 hw_loss 0.166374 lr 0.00044162 rank 1
2023-02-22 05:36:20,154 DEBUG TRAIN Batch 15/3100 loss 9.354299 loss_att 13.895754 loss_ctc 18.164196 loss_rnnt 7.271140 hw_loss 0.000402 lr 0.00044153 rank 2
2023-02-22 05:36:20,198 DEBUG TRAIN Batch 15/3100 loss 10.501267 loss_att 12.278666 loss_ctc 12.275888 loss_rnnt 9.813829 hw_loss 0.178767 lr 0.00044159 rank 3
2023-02-22 05:37:38,610 DEBUG TRAIN Batch 15/3200 loss 8.277631 loss_att 8.943794 loss_ctc 11.376774 loss_rnnt 7.609466 hw_loss 0.228214 lr 0.00044140 rank 0
2023-02-22 05:37:38,614 DEBUG TRAIN Batch 15/3200 loss 6.313392 loss_att 7.681345 loss_ctc 6.392665 loss_rnnt 5.929719 hw_loss 0.186585 lr 0.00044145 rank 1
2023-02-22 05:37:38,617 DEBUG TRAIN Batch 15/3200 loss 6.661262 loss_att 13.265736 loss_ctc 11.336792 loss_rnnt 4.622312 hw_loss 0.177471 lr 0.00044140 rank 4
2023-02-22 05:37:38,618 DEBUG TRAIN Batch 15/3200 loss 17.933483 loss_att 25.719856 loss_ctc 25.845520 loss_rnnt 15.272453 hw_loss 0.091532 lr 0.00044135 rank 7
2023-02-22 05:37:38,622 DEBUG TRAIN Batch 15/3200 loss 15.073009 loss_att 19.639889 loss_ctc 20.732906 loss_rnnt 13.306458 hw_loss 0.184729 lr 0.00044144 rank 6
2023-02-22 05:37:38,642 DEBUG TRAIN Batch 15/3200 loss 4.109377 loss_att 7.054708 loss_ctc 7.613769 loss_rnnt 2.999543 hw_loss 0.100342 lr 0.00044142 rank 3
2023-02-22 05:37:38,673 DEBUG TRAIN Batch 15/3200 loss 6.388974 loss_att 6.757632 loss_ctc 7.933793 loss_rnnt 5.971318 hw_loss 0.258652 lr 0.00044136 rank 2
2023-02-22 05:37:38,683 DEBUG TRAIN Batch 15/3200 loss 6.623591 loss_att 13.105914 loss_ctc 11.387930 loss_rnnt 4.691857 hw_loss 0.000044 lr 0.00044133 rank 5
2023-02-22 05:38:54,521 DEBUG TRAIN Batch 15/3300 loss 8.802576 loss_att 12.925440 loss_ctc 12.420657 loss_rnnt 7.413585 hw_loss 0.153766 lr 0.00044116 rank 5
2023-02-22 05:38:54,524 DEBUG TRAIN Batch 15/3300 loss 6.733315 loss_att 12.197630 loss_ctc 13.076610 loss_rnnt 4.764422 hw_loss 0.056732 lr 0.00044127 rank 6
2023-02-22 05:38:54,525 DEBUG TRAIN Batch 15/3300 loss 9.349304 loss_att 16.379429 loss_ctc 15.673156 loss_rnnt 7.027174 hw_loss 0.136733 lr 0.00044122 rank 0
2023-02-22 05:38:54,529 DEBUG TRAIN Batch 15/3300 loss 8.298944 loss_att 10.665976 loss_ctc 13.409907 loss_rnnt 7.076452 hw_loss 0.126794 lr 0.00044117 rank 7
2023-02-22 05:38:54,530 DEBUG TRAIN Batch 15/3300 loss 7.228643 loss_att 12.880367 loss_ctc 9.693851 loss_rnnt 5.647125 hw_loss 0.229648 lr 0.00044123 rank 4
2023-02-22 05:38:54,532 DEBUG TRAIN Batch 15/3300 loss 6.885996 loss_att 12.843983 loss_ctc 8.059922 loss_rnnt 5.433058 hw_loss 0.196532 lr 0.00044127 rank 1
2023-02-22 05:38:54,532 DEBUG TRAIN Batch 15/3300 loss 8.031575 loss_att 10.632919 loss_ctc 10.445239 loss_rnnt 7.157730 hw_loss 0.059541 lr 0.00044124 rank 3
2023-02-22 05:38:54,534 DEBUG TRAIN Batch 15/3300 loss 16.133961 loss_att 25.230345 loss_ctc 18.166767 loss_rnnt 13.941154 hw_loss 0.192165 lr 0.00044119 rank 2
2023-02-22 05:40:09,359 DEBUG TRAIN Batch 15/3400 loss 7.785250 loss_att 11.185767 loss_ctc 11.714035 loss_rnnt 6.494776 hw_loss 0.162249 lr 0.00044105 rank 0
2023-02-22 05:40:09,360 DEBUG TRAIN Batch 15/3400 loss 2.558826 loss_att 5.351472 loss_ctc 4.590526 loss_rnnt 1.568406 hw_loss 0.301869 lr 0.00044100 rank 7
2023-02-22 05:40:09,365 DEBUG TRAIN Batch 15/3400 loss 10.009286 loss_att 14.122217 loss_ctc 15.524449 loss_rnnt 8.363977 hw_loss 0.163812 lr 0.00044099 rank 5
2023-02-22 05:40:09,367 DEBUG TRAIN Batch 15/3400 loss 22.992031 loss_att 24.991169 loss_ctc 24.165648 loss_rnnt 22.373161 hw_loss 0.117296 lr 0.00044110 rank 1
2023-02-22 05:40:09,367 DEBUG TRAIN Batch 15/3400 loss 9.645570 loss_att 13.863108 loss_ctc 16.925615 loss_rnnt 7.751338 hw_loss 0.150096 lr 0.00044106 rank 4
2023-02-22 05:40:09,368 DEBUG TRAIN Batch 15/3400 loss 14.465095 loss_att 19.674437 loss_ctc 18.276039 loss_rnnt 12.858715 hw_loss 0.105723 lr 0.00044109 rank 6
2023-02-22 05:40:09,370 DEBUG TRAIN Batch 15/3400 loss 10.997998 loss_att 15.624822 loss_ctc 12.451803 loss_rnnt 9.768745 hw_loss 0.206341 lr 0.00044107 rank 3
2023-02-22 05:40:09,373 DEBUG TRAIN Batch 15/3400 loss 19.055145 loss_att 19.814552 loss_ctc 21.778297 loss_rnnt 18.485271 hw_loss 0.102947 lr 0.00044102 rank 2
2023-02-22 05:41:25,749 DEBUG TRAIN Batch 15/3500 loss 18.369190 loss_att 21.894934 loss_ctc 24.377279 loss_rnnt 16.750423 hw_loss 0.211010 lr 0.00044092 rank 6
2023-02-22 05:41:25,751 DEBUG TRAIN Batch 15/3500 loss 6.462752 loss_att 8.179153 loss_ctc 8.108450 loss_rnnt 5.804798 hw_loss 0.178591 lr 0.00044088 rank 0
2023-02-22 05:41:25,752 DEBUG TRAIN Batch 15/3500 loss 15.395270 loss_att 17.576555 loss_ctc 22.014116 loss_rnnt 14.026204 hw_loss 0.094303 lr 0.00044089 rank 4
2023-02-22 05:41:25,752 DEBUG TRAIN Batch 15/3500 loss 14.460083 loss_att 15.858660 loss_ctc 17.970823 loss_rnnt 13.659285 hw_loss 0.099348 lr 0.00044082 rank 5
2023-02-22 05:41:25,752 DEBUG TRAIN Batch 15/3500 loss 8.977873 loss_att 14.101551 loss_ctc 12.115230 loss_rnnt 7.445832 hw_loss 0.166858 lr 0.00044085 rank 2
2023-02-22 05:41:25,752 DEBUG TRAIN Batch 15/3500 loss 13.563305 loss_att 17.608555 loss_ctc 21.982231 loss_rnnt 11.591853 hw_loss 0.074774 lr 0.00044090 rank 3
2023-02-22 05:41:25,754 DEBUG TRAIN Batch 15/3500 loss 9.252057 loss_att 14.334270 loss_ctc 11.272958 loss_rnnt 7.952192 hw_loss 0.026189 lr 0.00044083 rank 7
2023-02-22 05:41:25,757 DEBUG TRAIN Batch 15/3500 loss 8.710704 loss_att 14.463192 loss_ctc 16.706238 loss_rnnt 6.459541 hw_loss 0.064861 lr 0.00044093 rank 1
2023-02-22 05:42:42,350 DEBUG TRAIN Batch 15/3600 loss 8.133848 loss_att 10.543490 loss_ctc 10.800426 loss_rnnt 7.180520 hw_loss 0.217227 lr 0.00044066 rank 7
2023-02-22 05:42:42,349 DEBUG TRAIN Batch 15/3600 loss 5.534837 loss_att 10.594088 loss_ctc 8.730094 loss_rnnt 4.010164 hw_loss 0.162729 lr 0.00044073 rank 3
2023-02-22 05:42:42,350 DEBUG TRAIN Batch 15/3600 loss 7.063842 loss_att 10.701298 loss_ctc 11.976538 loss_rnnt 5.636065 hw_loss 0.084861 lr 0.00044068 rank 2
2023-02-22 05:42:42,352 DEBUG TRAIN Batch 15/3600 loss 4.869821 loss_att 8.510237 loss_ctc 8.623071 loss_rnnt 3.589457 hw_loss 0.097216 lr 0.00044071 rank 4
2023-02-22 05:42:42,354 DEBUG TRAIN Batch 15/3600 loss 6.389782 loss_att 7.943466 loss_ctc 9.717838 loss_rnnt 5.545259 hw_loss 0.168837 lr 0.00044071 rank 0
2023-02-22 05:42:42,355 DEBUG TRAIN Batch 15/3600 loss 8.323341 loss_att 11.665277 loss_ctc 12.436349 loss_rnnt 7.047123 hw_loss 0.111430 lr 0.00044075 rank 6
2023-02-22 05:42:42,355 DEBUG TRAIN Batch 15/3600 loss 11.913221 loss_att 12.884943 loss_ctc 17.585938 loss_rnnt 10.895637 hw_loss 0.125398 lr 0.00044064 rank 5
2023-02-22 05:42:42,358 DEBUG TRAIN Batch 15/3600 loss 10.667625 loss_att 15.655195 loss_ctc 14.102842 loss_rnnt 9.156357 hw_loss 0.104485 lr 0.00044076 rank 1
2023-02-22 05:43:56,419 DEBUG TRAIN Batch 15/3700 loss 15.593843 loss_att 17.200462 loss_ctc 21.287430 loss_rnnt 14.408425 hw_loss 0.196775 lr 0.00044051 rank 2
2023-02-22 05:43:56,419 DEBUG TRAIN Batch 15/3700 loss 10.485428 loss_att 12.901735 loss_ctc 13.534027 loss_rnnt 9.501397 hw_loss 0.176789 lr 0.00044047 rank 5
2023-02-22 05:43:56,420 DEBUG TRAIN Batch 15/3700 loss 10.573933 loss_att 13.198044 loss_ctc 15.967654 loss_rnnt 9.292275 hw_loss 0.070634 lr 0.00044059 rank 1
2023-02-22 05:43:56,422 DEBUG TRAIN Batch 15/3700 loss 17.126125 loss_att 19.862917 loss_ctc 21.117693 loss_rnnt 15.958522 hw_loss 0.165066 lr 0.00044054 rank 4
2023-02-22 05:43:56,425 DEBUG TRAIN Batch 15/3700 loss 19.745373 loss_att 21.414139 loss_ctc 25.245564 loss_rnnt 18.561028 hw_loss 0.219814 lr 0.00044049 rank 7
2023-02-22 05:43:56,426 DEBUG TRAIN Batch 15/3700 loss 4.569672 loss_att 8.072454 loss_ctc 7.267244 loss_rnnt 3.435995 hw_loss 0.137710 lr 0.00044054 rank 0
2023-02-22 05:43:56,428 DEBUG TRAIN Batch 15/3700 loss 9.569017 loss_att 13.389158 loss_ctc 13.372907 loss_rnnt 8.143412 hw_loss 0.289486 lr 0.00044058 rank 6
2023-02-22 05:43:56,467 DEBUG TRAIN Batch 15/3700 loss 12.447181 loss_att 16.218105 loss_ctc 16.046341 loss_rnnt 11.171206 hw_loss 0.078565 lr 0.00044056 rank 3
2023-02-22 05:45:12,356 DEBUG TRAIN Batch 15/3800 loss 12.826982 loss_att 14.208946 loss_ctc 17.688923 loss_rnnt 11.830505 hw_loss 0.134674 lr 0.00044030 rank 5
2023-02-22 05:45:12,359 DEBUG TRAIN Batch 15/3800 loss 10.772293 loss_att 11.067088 loss_ctc 14.557605 loss_rnnt 10.121245 hw_loss 0.163841 lr 0.00044039 rank 3
2023-02-22 05:45:12,360 DEBUG TRAIN Batch 15/3800 loss 8.547297 loss_att 10.288371 loss_ctc 11.789473 loss_rnnt 7.670990 hw_loss 0.179627 lr 0.00044032 rank 7
2023-02-22 05:45:12,363 DEBUG TRAIN Batch 15/3800 loss 11.693374 loss_att 12.363168 loss_ctc 16.123777 loss_rnnt 10.830690 hw_loss 0.258755 lr 0.00044037 rank 4
2023-02-22 05:45:12,362 DEBUG TRAIN Batch 15/3800 loss 11.134096 loss_att 15.220321 loss_ctc 14.697266 loss_rnnt 9.751225 hw_loss 0.169753 lr 0.00044037 rank 0
2023-02-22 05:45:12,367 DEBUG TRAIN Batch 15/3800 loss 8.712237 loss_att 10.896318 loss_ctc 11.482984 loss_rnnt 7.844476 hw_loss 0.115336 lr 0.00044042 rank 1
2023-02-22 05:45:12,368 DEBUG TRAIN Batch 15/3800 loss 11.826736 loss_att 13.699193 loss_ctc 14.094193 loss_rnnt 11.093700 hw_loss 0.105407 lr 0.00044033 rank 2
2023-02-22 05:45:12,371 DEBUG TRAIN Batch 15/3800 loss 8.109355 loss_att 9.438598 loss_ctc 11.399982 loss_rnnt 7.229632 hw_loss 0.328356 lr 0.00044041 rank 6
2023-02-22 05:46:30,376 DEBUG TRAIN Batch 15/3900 loss 14.304786 loss_att 16.004139 loss_ctc 19.790586 loss_rnnt 13.184895 hw_loss 0.091088 lr 0.00044025 rank 1
2023-02-22 05:46:30,375 DEBUG TRAIN Batch 15/3900 loss 16.227772 loss_att 20.324272 loss_ctc 29.051125 loss_rnnt 13.563555 hw_loss 0.253381 lr 0.00044022 rank 3
2023-02-22 05:46:30,377 DEBUG TRAIN Batch 15/3900 loss 26.814806 loss_att 26.553133 loss_ctc 35.212185 loss_rnnt 25.598888 hw_loss 0.278629 lr 0.00044024 rank 6
2023-02-22 05:46:30,378 DEBUG TRAIN Batch 15/3900 loss 6.665037 loss_att 12.390850 loss_ctc 8.817188 loss_rnnt 5.184688 hw_loss 0.090436 lr 0.00044015 rank 7
2023-02-22 05:46:30,380 DEBUG TRAIN Batch 15/3900 loss 6.364269 loss_att 6.987483 loss_ctc 9.661608 loss_rnnt 5.728558 hw_loss 0.133918 lr 0.00044016 rank 2
2023-02-22 05:46:30,380 DEBUG TRAIN Batch 15/3900 loss 4.868954 loss_att 7.980027 loss_ctc 4.201839 loss_rnnt 4.241943 hw_loss 0.175771 lr 0.00044020 rank 0
2023-02-22 05:46:30,382 DEBUG TRAIN Batch 15/3900 loss 10.577079 loss_att 15.566706 loss_ctc 16.588480 loss_rnnt 8.649085 hw_loss 0.241029 lr 0.00044020 rank 4
2023-02-22 05:46:30,382 DEBUG TRAIN Batch 15/3900 loss 8.270791 loss_att 8.442825 loss_ctc 8.400938 loss_rnnt 8.157127 hw_loss 0.116069 lr 0.00044013 rank 5
2023-02-22 05:47:45,029 DEBUG TRAIN Batch 15/4000 loss 5.893148 loss_att 8.322677 loss_ctc 6.555681 loss_rnnt 5.228854 hw_loss 0.168846 lr 0.00044008 rank 1
2023-02-22 05:47:45,030 DEBUG TRAIN Batch 15/4000 loss 11.809395 loss_att 17.102709 loss_ctc 17.182438 loss_rnnt 9.992522 hw_loss 0.078382 lr 0.00043998 rank 7
2023-02-22 05:47:45,030 DEBUG TRAIN Batch 15/4000 loss 3.300642 loss_att 7.290538 loss_ctc 6.345522 loss_rnnt 2.063500 hw_loss 0.062210 lr 0.00044003 rank 0
2023-02-22 05:47:45,030 DEBUG TRAIN Batch 15/4000 loss 6.741397 loss_att 9.727459 loss_ctc 7.051677 loss_rnnt 6.048746 hw_loss 0.101378 lr 0.00044003 rank 4
2023-02-22 05:47:45,033 DEBUG TRAIN Batch 15/4000 loss 5.369129 loss_att 11.060830 loss_ctc 8.885278 loss_rnnt 3.662339 hw_loss 0.186805 lr 0.00043996 rank 5
2023-02-22 05:47:45,034 DEBUG TRAIN Batch 15/4000 loss 8.636937 loss_att 11.756907 loss_ctc 10.570356 loss_rnnt 7.649989 hw_loss 0.197184 lr 0.00043999 rank 2
2023-02-22 05:47:45,034 DEBUG TRAIN Batch 15/4000 loss 6.427865 loss_att 9.666319 loss_ctc 6.958162 loss_rnnt 5.597962 hw_loss 0.209071 lr 0.00044005 rank 3
2023-02-22 05:47:45,088 DEBUG TRAIN Batch 15/4000 loss 14.113847 loss_att 17.099476 loss_ctc 18.053364 loss_rnnt 12.942001 hw_loss 0.092721 lr 0.00044007 rank 6
2023-02-22 05:49:00,195 DEBUG TRAIN Batch 15/4100 loss 5.753269 loss_att 11.674795 loss_ctc 8.010576 loss_rnnt 4.168895 hw_loss 0.185802 lr 0.00043981 rank 7
2023-02-22 05:49:00,196 DEBUG TRAIN Batch 15/4100 loss 10.207647 loss_att 12.826328 loss_ctc 12.212423 loss_rnnt 9.388859 hw_loss 0.052030 lr 0.00043979 rank 5
2023-02-22 05:49:00,199 DEBUG TRAIN Batch 15/4100 loss 19.464783 loss_att 23.798336 loss_ctc 22.757065 loss_rnnt 18.106251 hw_loss 0.099095 lr 0.00043986 rank 4
2023-02-22 05:49:00,201 DEBUG TRAIN Batch 15/4100 loss 8.719547 loss_att 12.365471 loss_ctc 15.894473 loss_rnnt 6.943416 hw_loss 0.169295 lr 0.00043991 rank 1
2023-02-22 05:49:00,203 DEBUG TRAIN Batch 15/4100 loss 14.197217 loss_att 15.914429 loss_ctc 15.146526 loss_rnnt 13.671534 hw_loss 0.104375 lr 0.00043988 rank 3
2023-02-22 05:49:00,202 DEBUG TRAIN Batch 15/4100 loss 8.347075 loss_att 10.752000 loss_ctc 11.190134 loss_rnnt 7.410272 hw_loss 0.143893 lr 0.00043986 rank 0
2023-02-22 05:49:00,209 DEBUG TRAIN Batch 15/4100 loss 20.173496 loss_att 22.959995 loss_ctc 26.806137 loss_rnnt 18.630531 hw_loss 0.189956 lr 0.00043982 rank 2
2023-02-22 05:49:00,250 DEBUG TRAIN Batch 15/4100 loss 6.933039 loss_att 10.992368 loss_ctc 9.663475 loss_rnnt 5.704999 hw_loss 0.097716 lr 0.00043990 rank 6
2023-02-22 05:50:16,595 DEBUG TRAIN Batch 15/4200 loss 16.204430 loss_att 17.677917 loss_ctc 19.629993 loss_rnnt 15.352083 hw_loss 0.189200 lr 0.00043969 rank 4
2023-02-22 05:50:16,595 DEBUG TRAIN Batch 15/4200 loss 10.663511 loss_att 14.209700 loss_ctc 18.499235 loss_rnnt 8.829217 hw_loss 0.150551 lr 0.00043964 rank 7
2023-02-22 05:50:16,596 DEBUG TRAIN Batch 15/4200 loss 14.195497 loss_att 16.733639 loss_ctc 22.710375 loss_rnnt 12.438634 hw_loss 0.213591 lr 0.00043973 rank 6
2023-02-22 05:50:16,597 DEBUG TRAIN Batch 15/4200 loss 14.678143 loss_att 18.910378 loss_ctc 19.244606 loss_rnnt 13.155852 hw_loss 0.125592 lr 0.00043962 rank 5
2023-02-22 05:50:16,598 DEBUG TRAIN Batch 15/4200 loss 9.922689 loss_att 13.500132 loss_ctc 11.792831 loss_rnnt 8.915734 hw_loss 0.078964 lr 0.00043971 rank 3
2023-02-22 05:50:16,599 DEBUG TRAIN Batch 15/4200 loss 6.156128 loss_att 11.444190 loss_ctc 8.769264 loss_rnnt 4.671920 hw_loss 0.146585 lr 0.00043973 rank 1
2023-02-22 05:50:16,602 DEBUG TRAIN Batch 15/4200 loss 9.306152 loss_att 13.365103 loss_ctc 16.074436 loss_rnnt 7.511108 hw_loss 0.151530 lr 0.00043969 rank 0
2023-02-22 05:50:16,603 DEBUG TRAIN Batch 15/4200 loss 6.586233 loss_att 8.938520 loss_ctc 7.665202 loss_rnnt 5.887715 hw_loss 0.157870 lr 0.00043965 rank 2
2023-02-22 05:51:34,080 DEBUG TRAIN Batch 15/4300 loss 21.969101 loss_att 23.610140 loss_ctc 32.234383 loss_rnnt 20.219271 hw_loss 0.099218 lr 0.00043952 rank 0
2023-02-22 05:51:34,081 DEBUG TRAIN Batch 15/4300 loss 8.322614 loss_att 10.983784 loss_ctc 8.743315 loss_rnnt 7.692744 hw_loss 0.077891 lr 0.00043947 rank 7
2023-02-22 05:51:34,082 DEBUG TRAIN Batch 15/4300 loss 9.364494 loss_att 11.982686 loss_ctc 12.694523 loss_rnnt 8.341832 hw_loss 0.103162 lr 0.00043945 rank 5
2023-02-22 05:51:34,082 DEBUG TRAIN Batch 15/4300 loss 7.180676 loss_att 11.993328 loss_ctc 8.969172 loss_rnnt 5.917819 hw_loss 0.115987 lr 0.00043952 rank 4
2023-02-22 05:51:34,082 DEBUG TRAIN Batch 15/4300 loss 5.465776 loss_att 8.533157 loss_ctc 4.413676 loss_rnnt 4.941089 hw_loss 0.096546 lr 0.00043956 rank 1
2023-02-22 05:51:34,083 DEBUG TRAIN Batch 15/4300 loss 7.125112 loss_att 9.404602 loss_ctc 8.598917 loss_rnnt 6.392363 hw_loss 0.150645 lr 0.00043956 rank 6
2023-02-22 05:51:34,091 DEBUG TRAIN Batch 15/4300 loss 7.900628 loss_att 10.308657 loss_ctc 11.389683 loss_rnnt 6.886325 hw_loss 0.126543 lr 0.00043948 rank 2
2023-02-22 05:51:34,134 DEBUG TRAIN Batch 15/4300 loss 21.590023 loss_att 22.410065 loss_ctc 28.226578 loss_rnnt 20.500963 hw_loss 0.075329 lr 0.00043954 rank 3
2023-02-22 05:52:49,360 DEBUG TRAIN Batch 15/4400 loss 10.609156 loss_att 13.049270 loss_ctc 13.681220 loss_rnnt 9.647861 hw_loss 0.119370 lr 0.00043930 rank 7
2023-02-22 05:52:49,363 DEBUG TRAIN Batch 15/4400 loss 8.539956 loss_att 9.842290 loss_ctc 8.841727 loss_rnnt 8.135155 hw_loss 0.195183 lr 0.00043935 rank 4
2023-02-22 05:52:49,363 DEBUG TRAIN Batch 15/4400 loss 5.296532 loss_att 8.708910 loss_ctc 7.472515 loss_rnnt 4.246535 hw_loss 0.145106 lr 0.00043940 rank 1
2023-02-22 05:52:49,366 DEBUG TRAIN Batch 15/4400 loss 6.156735 loss_att 7.850792 loss_ctc 8.085283 loss_rnnt 5.503561 hw_loss 0.107291 lr 0.00043928 rank 5
2023-02-22 05:52:49,367 DEBUG TRAIN Batch 15/4400 loss 17.769253 loss_att 18.503208 loss_ctc 21.383915 loss_rnnt 17.048826 hw_loss 0.171900 lr 0.00043935 rank 0
2023-02-22 05:52:49,367 DEBUG TRAIN Batch 15/4400 loss 6.945232 loss_att 7.766132 loss_ctc 8.716735 loss_rnnt 6.473793 hw_loss 0.133236 lr 0.00043939 rank 6
2023-02-22 05:52:49,371 DEBUG TRAIN Batch 15/4400 loss 13.030645 loss_att 17.297359 loss_ctc 16.280422 loss_rnnt 11.700144 hw_loss 0.082225 lr 0.00043931 rank 2
2023-02-22 05:52:49,372 DEBUG TRAIN Batch 15/4400 loss 11.400354 loss_att 14.420126 loss_ctc 14.964029 loss_rnnt 10.307390 hw_loss 0.025973 lr 0.00043937 rank 3
2023-02-22 05:54:05,611 DEBUG TRAIN Batch 15/4500 loss 11.637362 loss_att 12.214993 loss_ctc 14.832007 loss_rnnt 10.951528 hw_loss 0.270667 lr 0.00043918 rank 0
2023-02-22 05:54:05,611 DEBUG TRAIN Batch 15/4500 loss 11.715546 loss_att 11.566243 loss_ctc 13.747484 loss_rnnt 11.336226 hw_loss 0.259228 lr 0.00043913 rank 7
2023-02-22 05:54:05,611 DEBUG TRAIN Batch 15/4500 loss 3.878028 loss_att 6.586642 loss_ctc 5.057848 loss_rnnt 3.041522 hw_loss 0.257763 lr 0.00043923 rank 1
2023-02-22 05:54:05,614 DEBUG TRAIN Batch 15/4500 loss 12.035790 loss_att 15.483231 loss_ctc 13.840128 loss_rnnt 11.067389 hw_loss 0.071877 lr 0.00043918 rank 4
2023-02-22 05:54:05,617 DEBUG TRAIN Batch 15/4500 loss 6.084576 loss_att 7.421949 loss_ctc 7.382808 loss_rnnt 5.590814 hw_loss 0.099731 lr 0.00043911 rank 5
2023-02-22 05:54:05,618 DEBUG TRAIN Batch 15/4500 loss 12.187961 loss_att 15.695240 loss_ctc 14.955677 loss_rnnt 11.048686 hw_loss 0.128982 lr 0.00043922 rank 6
2023-02-22 05:54:05,622 DEBUG TRAIN Batch 15/4500 loss 10.211192 loss_att 10.562999 loss_ctc 12.705547 loss_rnnt 9.639250 hw_loss 0.316875 lr 0.00043914 rank 2
2023-02-22 05:54:05,662 DEBUG TRAIN Batch 15/4500 loss 12.265827 loss_att 15.451950 loss_ctc 18.601212 loss_rnnt 10.740204 hw_loss 0.081901 lr 0.00043920 rank 3
2023-02-22 05:55:23,908 DEBUG TRAIN Batch 15/4600 loss 23.756390 loss_att 20.904840 loss_ctc 27.841400 loss_rnnt 23.726080 hw_loss 0.104910 lr 0.00043901 rank 0
2023-02-22 05:55:23,909 DEBUG TRAIN Batch 15/4600 loss 16.791159 loss_att 22.674541 loss_ctc 23.371204 loss_rnnt 14.697710 hw_loss 0.073933 lr 0.00043901 rank 4
2023-02-22 05:55:23,910 DEBUG TRAIN Batch 15/4600 loss 9.739674 loss_att 18.501186 loss_ctc 12.837971 loss_rnnt 7.500628 hw_loss 0.138068 lr 0.00043903 rank 3
2023-02-22 05:55:23,910 DEBUG TRAIN Batch 15/4600 loss 11.518303 loss_att 14.646112 loss_ctc 16.548843 loss_rnnt 10.138718 hw_loss 0.156158 lr 0.00043906 rank 1
2023-02-22 05:55:23,912 DEBUG TRAIN Batch 15/4600 loss 16.239250 loss_att 18.715164 loss_ctc 18.407589 loss_rnnt 15.388220 hw_loss 0.125131 lr 0.00043896 rank 7
2023-02-22 05:55:23,913 DEBUG TRAIN Batch 15/4600 loss 9.243777 loss_att 16.048885 loss_ctc 14.038963 loss_rnnt 7.183977 hw_loss 0.111415 lr 0.00043894 rank 5
2023-02-22 05:55:23,916 DEBUG TRAIN Batch 15/4600 loss 9.981111 loss_att 14.421572 loss_ctc 12.099257 loss_rnnt 8.750775 hw_loss 0.112168 lr 0.00043897 rank 2
2023-02-22 05:55:23,957 DEBUG TRAIN Batch 15/4600 loss 19.395792 loss_att 21.413643 loss_ctc 26.430706 loss_rnnt 18.021217 hw_loss 0.061906 lr 0.00043905 rank 6
2023-02-22 05:56:39,830 DEBUG TRAIN Batch 15/4700 loss 6.237115 loss_att 9.232552 loss_ctc 8.347768 loss_rnnt 5.244626 hw_loss 0.209964 lr 0.00043884 rank 4
2023-02-22 05:56:39,831 DEBUG TRAIN Batch 15/4700 loss 22.015432 loss_att 23.335245 loss_ctc 25.151096 loss_rnnt 21.304710 hw_loss 0.053759 lr 0.00043877 rank 5
2023-02-22 05:56:39,833 DEBUG TRAIN Batch 15/4700 loss 4.540568 loss_att 7.721763 loss_ctc 5.673114 loss_rnnt 3.700785 hw_loss 0.098508 lr 0.00043888 rank 6
2023-02-22 05:56:39,833 DEBUG TRAIN Batch 15/4700 loss 9.747838 loss_att 13.349543 loss_ctc 15.069674 loss_rnnt 8.301102 hw_loss 0.031530 lr 0.00043879 rank 7
2023-02-22 05:56:39,834 DEBUG TRAIN Batch 15/4700 loss 11.268497 loss_att 16.615545 loss_ctc 14.008250 loss_rnnt 9.754320 hw_loss 0.149003 lr 0.00043884 rank 0
2023-02-22 05:56:39,837 DEBUG TRAIN Batch 15/4700 loss 11.378885 loss_att 15.432350 loss_ctc 17.299582 loss_rnnt 9.652779 hw_loss 0.236225 lr 0.00043886 rank 3
2023-02-22 05:56:39,837 DEBUG TRAIN Batch 15/4700 loss 7.535769 loss_att 11.381135 loss_ctc 9.884526 loss_rnnt 6.309478 hw_loss 0.270095 lr 0.00043889 rank 1
2023-02-22 05:56:39,840 DEBUG TRAIN Batch 15/4700 loss 3.437221 loss_att 6.005339 loss_ctc 5.446645 loss_rnnt 2.655174 hw_loss 0.000938 lr 0.00043881 rank 2
2023-02-22 05:57:54,167 DEBUG TRAIN Batch 15/4800 loss 10.386597 loss_att 13.367466 loss_ctc 11.489110 loss_rnnt 9.555351 hw_loss 0.165131 lr 0.00043867 rank 4
2023-02-22 05:57:54,168 DEBUG TRAIN Batch 15/4800 loss 13.084119 loss_att 16.868694 loss_ctc 21.494179 loss_rnnt 11.119722 hw_loss 0.161512 lr 0.00043867 rank 0
2023-02-22 05:57:54,171 DEBUG TRAIN Batch 15/4800 loss 6.720623 loss_att 10.091445 loss_ctc 7.771427 loss_rnnt 5.807604 hw_loss 0.185154 lr 0.00043862 rank 7
2023-02-22 05:57:54,172 DEBUG TRAIN Batch 15/4800 loss 19.934856 loss_att 24.267273 loss_ctc 25.256437 loss_rnnt 18.220633 hw_loss 0.259116 lr 0.00043860 rank 5
2023-02-22 05:57:54,174 DEBUG TRAIN Batch 15/4800 loss 4.685105 loss_att 8.536471 loss_ctc 6.298242 loss_rnnt 3.624285 hw_loss 0.141490 lr 0.00043872 rank 1
2023-02-22 05:57:54,177 DEBUG TRAIN Batch 15/4800 loss 12.186017 loss_att 18.422035 loss_ctc 16.928732 loss_rnnt 10.273208 hw_loss 0.062333 lr 0.00043864 rank 2
2023-02-22 05:57:54,177 DEBUG TRAIN Batch 15/4800 loss 16.712481 loss_att 20.088623 loss_ctc 23.598454 loss_rnnt 15.051721 hw_loss 0.126375 lr 0.00043869 rank 3
2023-02-22 05:57:54,226 DEBUG TRAIN Batch 15/4800 loss 14.647814 loss_att 20.265249 loss_ctc 16.858984 loss_rnnt 13.187864 hw_loss 0.078075 lr 0.00043871 rank 6
2023-02-22 05:59:10,519 DEBUG TRAIN Batch 15/4900 loss 18.788467 loss_att 20.703016 loss_ctc 26.484703 loss_rnnt 17.341434 hw_loss 0.071173 lr 0.00043845 rank 7
2023-02-22 05:59:10,519 DEBUG TRAIN Batch 15/4900 loss 6.753776 loss_att 9.695989 loss_ctc 11.886621 loss_rnnt 5.424394 hw_loss 0.106050 lr 0.00043844 rank 5
2023-02-22 05:59:10,521 DEBUG TRAIN Batch 15/4900 loss 13.734819 loss_att 15.487593 loss_ctc 17.120888 loss_rnnt 12.865662 hw_loss 0.125863 lr 0.00043851 rank 4
2023-02-22 05:59:10,521 DEBUG TRAIN Batch 15/4900 loss 19.858984 loss_att 21.570732 loss_ctc 27.888302 loss_rnnt 18.411077 hw_loss 0.065588 lr 0.00043854 rank 6
2023-02-22 05:59:10,523 DEBUG TRAIN Batch 15/4900 loss 17.408880 loss_att 21.321499 loss_ctc 26.135414 loss_rnnt 15.352613 hw_loss 0.206640 lr 0.00043855 rank 1
2023-02-22 05:59:10,527 DEBUG TRAIN Batch 15/4900 loss 10.897893 loss_att 13.164371 loss_ctc 13.238548 loss_rnnt 10.059715 hw_loss 0.136489 lr 0.00043850 rank 0
2023-02-22 05:59:10,528 DEBUG TRAIN Batch 15/4900 loss 9.323065 loss_att 11.566611 loss_ctc 10.823371 loss_rnnt 8.628538 hw_loss 0.085830 lr 0.00043847 rank 2
2023-02-22 05:59:10,531 DEBUG TRAIN Batch 15/4900 loss 15.146873 loss_att 18.358469 loss_ctc 19.862082 loss_rnnt 13.833248 hw_loss 0.079896 lr 0.00043852 rank 3
2023-02-22 06:00:28,790 DEBUG TRAIN Batch 15/5000 loss 19.517012 loss_att 21.216536 loss_ctc 29.145187 loss_rnnt 17.850595 hw_loss 0.080168 lr 0.00043834 rank 4
2023-02-22 06:00:28,793 DEBUG TRAIN Batch 15/5000 loss 6.549072 loss_att 10.192602 loss_ctc 8.520157 loss_rnnt 5.540619 hw_loss 0.031754 lr 0.00043837 rank 6
2023-02-22 06:00:28,793 DEBUG TRAIN Batch 15/5000 loss 12.931251 loss_att 16.998104 loss_ctc 20.495834 loss_rnnt 11.069801 hw_loss 0.073999 lr 0.00043828 rank 7
2023-02-22 06:00:28,793 DEBUG TRAIN Batch 15/5000 loss 5.953774 loss_att 9.280572 loss_ctc 9.624188 loss_rnnt 4.798770 hw_loss 0.000480 lr 0.00043833 rank 0
2023-02-22 06:00:28,795 DEBUG TRAIN Batch 15/5000 loss 6.671863 loss_att 8.299788 loss_ctc 8.672472 loss_rnnt 6.015468 hw_loss 0.120116 lr 0.00043827 rank 5
2023-02-22 06:00:28,797 DEBUG TRAIN Batch 15/5000 loss 14.536383 loss_att 16.075806 loss_ctc 17.138485 loss_rnnt 13.810679 hw_loss 0.132886 lr 0.00043838 rank 1
2023-02-22 06:00:28,797 DEBUG TRAIN Batch 15/5000 loss 13.476954 loss_att 17.548470 loss_ctc 18.428280 loss_rnnt 11.976401 hw_loss 0.048888 lr 0.00043835 rank 3
2023-02-22 06:00:28,797 DEBUG TRAIN Batch 15/5000 loss 8.287542 loss_att 11.356973 loss_ctc 10.976968 loss_rnnt 7.179532 hw_loss 0.254126 lr 0.00043830 rank 2
2023-02-22 06:01:45,150 DEBUG TRAIN Batch 15/5100 loss 13.161521 loss_att 14.822321 loss_ctc 14.576406 loss_rnnt 12.458883 hw_loss 0.340927 lr 0.00043811 rank 7
2023-02-22 06:01:45,153 DEBUG TRAIN Batch 15/5100 loss 10.786528 loss_att 11.913338 loss_ctc 15.314602 loss_rnnt 9.866556 hw_loss 0.170373 lr 0.00043816 rank 0
2023-02-22 06:01:45,153 DEBUG TRAIN Batch 15/5100 loss 10.586143 loss_att 10.533129 loss_ctc 13.251977 loss_rnnt 10.125618 hw_loss 0.216907 lr 0.00043817 rank 4
2023-02-22 06:01:45,155 DEBUG TRAIN Batch 15/5100 loss 5.824934 loss_att 8.239922 loss_ctc 7.270704 loss_rnnt 5.111359 hw_loss 0.070891 lr 0.00043821 rank 6
2023-02-22 06:01:45,157 DEBUG TRAIN Batch 15/5100 loss 11.592728 loss_att 11.334929 loss_ctc 13.975401 loss_rnnt 11.245319 hw_loss 0.152398 lr 0.00043813 rank 2
2023-02-22 06:01:45,156 DEBUG TRAIN Batch 15/5100 loss 11.236046 loss_att 12.712212 loss_ctc 16.841034 loss_rnnt 10.117035 hw_loss 0.143338 lr 0.00043810 rank 5
2023-02-22 06:01:45,157 DEBUG TRAIN Batch 15/5100 loss 6.672167 loss_att 9.945646 loss_ctc 11.250083 loss_rnnt 5.342484 hw_loss 0.121121 lr 0.00043818 rank 3
2023-02-22 06:01:45,204 DEBUG TRAIN Batch 15/5100 loss 7.160582 loss_att 8.737047 loss_ctc 6.666936 loss_rnnt 6.800266 hw_loss 0.207829 lr 0.00043821 rank 1
2023-02-22 06:03:00,047 DEBUG TRAIN Batch 15/5200 loss 8.791904 loss_att 9.771946 loss_ctc 10.773708 loss_rnnt 8.288063 hw_loss 0.081737 lr 0.00043800 rank 0
2023-02-22 06:03:00,054 DEBUG TRAIN Batch 15/5200 loss 10.129056 loss_att 10.435816 loss_ctc 9.704011 loss_rnnt 10.054859 hw_loss 0.130345 lr 0.00043793 rank 5
2023-02-22 06:03:00,055 DEBUG TRAIN Batch 15/5200 loss 13.543616 loss_att 16.267570 loss_ctc 15.123618 loss_rnnt 12.749759 hw_loss 0.072000 lr 0.00043804 rank 6
2023-02-22 06:03:00,055 DEBUG TRAIN Batch 15/5200 loss 12.596125 loss_att 16.350918 loss_ctc 16.132984 loss_rnnt 11.360535 hw_loss 0.024468 lr 0.00043800 rank 4
2023-02-22 06:03:00,056 DEBUG TRAIN Batch 15/5200 loss 23.555288 loss_att 29.836128 loss_ctc 33.264854 loss_rnnt 20.939499 hw_loss 0.121900 lr 0.00043795 rank 7
2023-02-22 06:03:00,057 DEBUG TRAIN Batch 15/5200 loss 6.817914 loss_att 11.271639 loss_ctc 8.309950 loss_rnnt 5.728164 hw_loss 0.000124 lr 0.00043802 rank 3
2023-02-22 06:03:00,058 DEBUG TRAIN Batch 15/5200 loss 8.330061 loss_att 12.179141 loss_ctc 13.441055 loss_rnnt 6.808764 hw_loss 0.131278 lr 0.00043804 rank 1
2023-02-22 06:03:00,104 DEBUG TRAIN Batch 15/5200 loss 10.830872 loss_att 13.989551 loss_ctc 14.763992 loss_rnnt 9.668226 hw_loss 0.012176 lr 0.00043796 rank 2
2023-02-22 06:04:16,874 DEBUG TRAIN Batch 15/5300 loss 7.316441 loss_att 11.248984 loss_ctc 10.661638 loss_rnnt 5.905650 hw_loss 0.334229 lr 0.00043785 rank 3
2023-02-22 06:04:16,874 DEBUG TRAIN Batch 15/5300 loss 6.105026 loss_att 10.910488 loss_ctc 9.198160 loss_rnnt 4.669981 hw_loss 0.115378 lr 0.00043776 rank 5
2023-02-22 06:04:16,877 DEBUG TRAIN Batch 15/5300 loss 22.026657 loss_att 24.834778 loss_ctc 28.982885 loss_rnnt 20.507198 hw_loss 0.056889 lr 0.00043783 rank 4
2023-02-22 06:04:16,878 DEBUG TRAIN Batch 15/5300 loss 4.851641 loss_att 8.570534 loss_ctc 6.174782 loss_rnnt 3.796921 hw_loss 0.252231 lr 0.00043787 rank 6
2023-02-22 06:04:16,881 DEBUG TRAIN Batch 15/5300 loss 9.154689 loss_att 15.883913 loss_ctc 11.027611 loss_rnnt 7.484884 hw_loss 0.139193 lr 0.00043778 rank 7
2023-02-22 06:04:16,882 DEBUG TRAIN Batch 15/5300 loss 11.275517 loss_att 15.672794 loss_ctc 14.933165 loss_rnnt 9.878527 hw_loss 0.055970 lr 0.00043783 rank 0
2023-02-22 06:04:16,886 DEBUG TRAIN Batch 15/5300 loss 13.027192 loss_att 14.380537 loss_ctc 13.578925 loss_rnnt 12.609537 hw_loss 0.137662 lr 0.00043780 rank 2
2023-02-22 06:04:16,920 DEBUG TRAIN Batch 15/5300 loss 21.531637 loss_att 21.606117 loss_ctc 27.607214 loss_rnnt 20.619284 hw_loss 0.163840 lr 0.00043788 rank 1
2023-02-22 06:05:32,777 DEBUG TRAIN Batch 15/5400 loss 4.588930 loss_att 6.910806 loss_ctc 7.235549 loss_rnnt 3.660711 hw_loss 0.208052 lr 0.00043766 rank 0
2023-02-22 06:05:32,782 DEBUG TRAIN Batch 15/5400 loss 9.595491 loss_att 11.402700 loss_ctc 11.257004 loss_rnnt 8.935558 hw_loss 0.144294 lr 0.00043761 rank 7
2023-02-22 06:05:32,783 DEBUG TRAIN Batch 15/5400 loss 14.185979 loss_att 18.028694 loss_ctc 22.484550 loss_rnnt 12.220219 hw_loss 0.170139 lr 0.00043766 rank 4
2023-02-22 06:05:32,784 DEBUG TRAIN Batch 15/5400 loss 8.240328 loss_att 9.725205 loss_ctc 14.093964 loss_rnnt 7.099277 hw_loss 0.119232 lr 0.00043760 rank 5
2023-02-22 06:05:32,787 DEBUG TRAIN Batch 15/5400 loss 4.231890 loss_att 6.816964 loss_ctc 4.360639 loss_rnnt 3.650162 hw_loss 0.089149 lr 0.00043771 rank 1
2023-02-22 06:05:32,788 DEBUG TRAIN Batch 15/5400 loss 10.351195 loss_att 12.464088 loss_ctc 12.838591 loss_rnnt 9.559393 hw_loss 0.070447 lr 0.00043770 rank 6
2023-02-22 06:05:32,789 DEBUG TRAIN Batch 15/5400 loss 13.954519 loss_att 16.444908 loss_ctc 17.697037 loss_rnnt 12.908955 hw_loss 0.090910 lr 0.00043768 rank 3
2023-02-22 06:05:32,791 DEBUG TRAIN Batch 15/5400 loss 10.160069 loss_att 14.724723 loss_ctc 18.202335 loss_rnnt 8.142375 hw_loss 0.060865 lr 0.00043763 rank 2
2023-02-22 06:06:47,125 DEBUG TRAIN Batch 15/5500 loss 13.839922 loss_att 17.864183 loss_ctc 21.619762 loss_rnnt 11.980291 hw_loss 0.032751 lr 0.00043744 rank 7
2023-02-22 06:06:47,125 DEBUG TRAIN Batch 15/5500 loss 18.923023 loss_att 20.289812 loss_ctc 26.143215 loss_rnnt 17.657890 hw_loss 0.054530 lr 0.00043746 rank 2
2023-02-22 06:06:47,127 DEBUG TRAIN Batch 15/5500 loss 5.161335 loss_att 8.996826 loss_ctc 5.890344 loss_rnnt 4.245852 hw_loss 0.095969 lr 0.00043743 rank 5
2023-02-22 06:06:47,128 DEBUG TRAIN Batch 15/5500 loss 15.331845 loss_att 19.235914 loss_ctc 19.155445 loss_rnnt 13.992470 hw_loss 0.091403 lr 0.00043749 rank 0
2023-02-22 06:06:47,129 DEBUG TRAIN Batch 15/5500 loss 16.929146 loss_att 18.620945 loss_ctc 18.678368 loss_rnnt 16.246708 hw_loss 0.207838 lr 0.00043754 rank 1
2023-02-22 06:06:47,129 DEBUG TRAIN Batch 15/5500 loss 11.450574 loss_att 13.567513 loss_ctc 24.738232 loss_rnnt 9.214919 hw_loss 0.076087 lr 0.00043753 rank 6
2023-02-22 06:06:47,130 DEBUG TRAIN Batch 15/5500 loss 7.941336 loss_att 10.701769 loss_ctc 12.396481 loss_rnnt 6.736763 hw_loss 0.109622 lr 0.00043750 rank 4
2023-02-22 06:06:47,136 DEBUG TRAIN Batch 15/5500 loss 7.209692 loss_att 12.442461 loss_ctc 10.223902 loss_rnnt 5.682013 hw_loss 0.148557 lr 0.00043751 rank 3
2023-02-22 06:08:01,790 DEBUG TRAIN Batch 15/5600 loss 13.340088 loss_att 13.149956 loss_ctc 21.774044 loss_rnnt 12.253304 hw_loss 0.000531 lr 0.00043726 rank 5
2023-02-22 06:08:01,791 DEBUG TRAIN Batch 15/5600 loss 10.589085 loss_att 12.062786 loss_ctc 15.320312 loss_rnnt 9.569074 hw_loss 0.177076 lr 0.00043732 rank 0
2023-02-22 06:08:01,791 DEBUG TRAIN Batch 15/5600 loss 5.539239 loss_att 11.169086 loss_ctc 9.738246 loss_rnnt 3.748140 hw_loss 0.197366 lr 0.00043728 rank 7
2023-02-22 06:08:01,792 DEBUG TRAIN Batch 15/5600 loss 15.692382 loss_att 18.837097 loss_ctc 20.847086 loss_rnnt 14.275963 hw_loss 0.187841 lr 0.00043737 rank 1
2023-02-22 06:08:01,795 DEBUG TRAIN Batch 15/5600 loss 5.583973 loss_att 8.733962 loss_ctc 8.364645 loss_rnnt 4.575799 hw_loss 0.013913 lr 0.00043733 rank 4
2023-02-22 06:08:01,795 DEBUG TRAIN Batch 15/5600 loss 5.882530 loss_att 7.743375 loss_ctc 10.730979 loss_rnnt 4.737626 hw_loss 0.236767 lr 0.00043734 rank 3
2023-02-22 06:08:01,799 DEBUG TRAIN Batch 15/5600 loss 4.865137 loss_att 6.682479 loss_ctc 8.094707 loss_rnnt 4.017822 hw_loss 0.099821 lr 0.00043729 rank 2
2023-02-22 06:08:01,803 DEBUG TRAIN Batch 15/5600 loss 6.149549 loss_att 9.351506 loss_ctc 7.260386 loss_rnnt 5.318743 hw_loss 0.079319 lr 0.00043737 rank 6
2023-02-22 06:09:20,082 DEBUG TRAIN Batch 15/5700 loss 8.410405 loss_att 9.949393 loss_ctc 10.712502 loss_rnnt 7.785626 hw_loss 0.018815 lr 0.00043716 rank 4
2023-02-22 06:09:20,088 DEBUG TRAIN Batch 15/5700 loss 17.027004 loss_att 18.904716 loss_ctc 24.047340 loss_rnnt 15.643278 hw_loss 0.135259 lr 0.00043709 rank 5
2023-02-22 06:09:20,088 DEBUG TRAIN Batch 15/5700 loss 7.427097 loss_att 8.184500 loss_ctc 6.654258 loss_rnnt 7.309054 hw_loss 0.130515 lr 0.00043711 rank 7
2023-02-22 06:09:20,091 DEBUG TRAIN Batch 15/5700 loss 13.874499 loss_att 18.656757 loss_ctc 20.523270 loss_rnnt 11.987597 hw_loss 0.082402 lr 0.00043716 rank 0
2023-02-22 06:09:20,095 DEBUG TRAIN Batch 15/5700 loss 7.472268 loss_att 7.580266 loss_ctc 9.518448 loss_rnnt 7.079808 hw_loss 0.183818 lr 0.00043718 rank 3
2023-02-22 06:09:20,096 DEBUG TRAIN Batch 15/5700 loss 13.615057 loss_att 15.193433 loss_ctc 17.655094 loss_rnnt 12.700888 hw_loss 0.112168 lr 0.00043720 rank 6
2023-02-22 06:09:20,099 DEBUG TRAIN Batch 15/5700 loss 10.605684 loss_att 11.872682 loss_ctc 14.753621 loss_rnnt 9.759700 hw_loss 0.074114 lr 0.00043721 rank 1
2023-02-22 06:09:20,099 DEBUG TRAIN Batch 15/5700 loss 10.602775 loss_att 12.914412 loss_ctc 11.960693 loss_rnnt 9.877068 hw_loss 0.154358 lr 0.00043713 rank 2
2023-02-22 06:10:36,065 DEBUG TRAIN Batch 15/5800 loss 13.324390 loss_att 14.081010 loss_ctc 16.378490 loss_rnnt 12.633822 hw_loss 0.247561 lr 0.00043694 rank 7
2023-02-22 06:10:36,066 DEBUG TRAIN Batch 15/5800 loss 10.567821 loss_att 19.538933 loss_ctc 19.516590 loss_rnnt 7.524853 hw_loss 0.104206 lr 0.00043693 rank 5
2023-02-22 06:10:36,070 DEBUG TRAIN Batch 15/5800 loss 16.431681 loss_att 23.349411 loss_ctc 18.181190 loss_rnnt 14.739223 hw_loss 0.141836 lr 0.00043699 rank 0
2023-02-22 06:10:36,070 DEBUG TRAIN Batch 15/5800 loss 13.747591 loss_att 14.247912 loss_ctc 14.148307 loss_rnnt 13.527431 hw_loss 0.125001 lr 0.00043703 rank 6
2023-02-22 06:10:36,072 DEBUG TRAIN Batch 15/5800 loss 16.632921 loss_att 21.069246 loss_ctc 21.062218 loss_rnnt 15.147026 hw_loss 0.015106 lr 0.00043701 rank 3
2023-02-22 06:10:36,072 DEBUG TRAIN Batch 15/5800 loss 5.018989 loss_att 8.100135 loss_ctc 8.192043 loss_rnnt 3.892813 hw_loss 0.162887 lr 0.00043700 rank 4
2023-02-22 06:10:36,074 DEBUG TRAIN Batch 15/5800 loss 14.256421 loss_att 14.158604 loss_ctc 17.033089 loss_rnnt 13.803164 hw_loss 0.192371 lr 0.00043704 rank 1
2023-02-22 06:10:36,111 DEBUG TRAIN Batch 15/5800 loss 4.984104 loss_att 11.022511 loss_ctc 5.554204 loss_rnnt 3.629848 hw_loss 0.132303 lr 0.00043696 rank 2
2023-02-22 06:11:51,848 DEBUG TRAIN Batch 15/5900 loss 11.050697 loss_att 13.802666 loss_ctc 15.994273 loss_rnnt 9.750021 hw_loss 0.170883 lr 0.00043676 rank 5
2023-02-22 06:11:51,850 DEBUG TRAIN Batch 15/5900 loss 10.851933 loss_att 12.200546 loss_ctc 13.005583 loss_rnnt 10.294982 hw_loss 0.000140 lr 0.00043682 rank 0
2023-02-22 06:11:51,851 DEBUG TRAIN Batch 15/5900 loss 16.591867 loss_att 20.934734 loss_ctc 18.388975 loss_rnnt 15.432509 hw_loss 0.095942 lr 0.00043678 rank 7
2023-02-22 06:11:51,855 DEBUG TRAIN Batch 15/5900 loss 17.148268 loss_att 17.238827 loss_ctc 16.988197 loss_rnnt 17.032051 hw_loss 0.223966 lr 0.00043684 rank 3
2023-02-22 06:11:51,855 DEBUG TRAIN Batch 15/5900 loss 19.396126 loss_att 20.535233 loss_ctc 27.333965 loss_rnnt 18.066280 hw_loss 0.081836 lr 0.00043683 rank 4
2023-02-22 06:11:51,857 DEBUG TRAIN Batch 15/5900 loss 8.370817 loss_att 14.625795 loss_ctc 16.379143 loss_rnnt 5.989779 hw_loss 0.116748 lr 0.00043687 rank 6
2023-02-22 06:11:51,862 DEBUG TRAIN Batch 15/5900 loss 10.139276 loss_att 18.062374 loss_ctc 14.927707 loss_rnnt 7.852907 hw_loss 0.118673 lr 0.00043687 rank 1
2023-02-22 06:11:51,901 DEBUG TRAIN Batch 15/5900 loss 10.755141 loss_att 14.931602 loss_ctc 19.028740 loss_rnnt 8.693830 hw_loss 0.230386 lr 0.00043679 rank 2
2023-02-22 06:13:08,830 DEBUG TRAIN Batch 15/6000 loss 7.806435 loss_att 9.925150 loss_ctc 10.262877 loss_rnnt 7.054606 hw_loss 0.001051 lr 0.00043659 rank 5
2023-02-22 06:13:08,832 DEBUG TRAIN Batch 15/6000 loss 6.027040 loss_att 9.540838 loss_ctc 10.315615 loss_rnnt 4.695619 hw_loss 0.106598 lr 0.00043666 rank 4
2023-02-22 06:13:08,835 DEBUG TRAIN Batch 15/6000 loss 8.302688 loss_att 12.100862 loss_ctc 11.153632 loss_rnnt 7.011104 hw_loss 0.284671 lr 0.00043663 rank 2
2023-02-22 06:13:08,837 DEBUG TRAIN Batch 15/6000 loss 10.123890 loss_att 14.010314 loss_ctc 11.815341 loss_rnnt 9.042574 hw_loss 0.147195 lr 0.00043661 rank 7
2023-02-22 06:13:08,839 DEBUG TRAIN Batch 15/6000 loss 21.930719 loss_att 24.245975 loss_ctc 29.381123 loss_rnnt 20.374104 hw_loss 0.187836 lr 0.00043666 rank 0
2023-02-22 06:13:08,838 DEBUG TRAIN Batch 15/6000 loss 13.725385 loss_att 19.529636 loss_ctc 20.528891 loss_rnnt 11.637125 hw_loss 0.038017 lr 0.00043670 rank 6
2023-02-22 06:13:08,838 DEBUG TRAIN Batch 15/6000 loss 14.250294 loss_att 18.053619 loss_ctc 19.490582 loss_rnnt 12.686672 hw_loss 0.195470 lr 0.00043668 rank 3
2023-02-22 06:13:08,839 DEBUG TRAIN Batch 15/6000 loss 7.830925 loss_att 10.119667 loss_ctc 11.178516 loss_rnnt 6.866443 hw_loss 0.113230 lr 0.00043671 rank 1
2023-02-22 06:14:25,190 DEBUG TRAIN Batch 15/6100 loss 18.508518 loss_att 20.283810 loss_ctc 24.004295 loss_rnnt 17.342052 hw_loss 0.147445 lr 0.00043644 rank 7
2023-02-22 06:14:25,193 DEBUG TRAIN Batch 15/6100 loss 11.706122 loss_att 14.940472 loss_ctc 15.752962 loss_rnnt 10.473182 hw_loss 0.087172 lr 0.00043650 rank 4
2023-02-22 06:14:25,194 DEBUG TRAIN Batch 15/6100 loss 10.203856 loss_att 12.453085 loss_ctc 13.897239 loss_rnnt 9.212116 hw_loss 0.092705 lr 0.00043654 rank 1
2023-02-22 06:14:25,196 DEBUG TRAIN Batch 15/6100 loss 20.433674 loss_att 23.364788 loss_ctc 23.382103 loss_rnnt 19.385544 hw_loss 0.128967 lr 0.00043649 rank 0
2023-02-22 06:14:25,199 DEBUG TRAIN Batch 15/6100 loss 8.264186 loss_att 11.676275 loss_ctc 11.724483 loss_rnnt 7.100367 hw_loss 0.037554 lr 0.00043646 rank 2
2023-02-22 06:14:25,200 DEBUG TRAIN Batch 15/6100 loss 9.732755 loss_att 13.880340 loss_ctc 14.527260 loss_rnnt 8.161710 hw_loss 0.191739 lr 0.00043643 rank 5
2023-02-22 06:14:25,201 DEBUG TRAIN Batch 15/6100 loss 12.459579 loss_att 17.427111 loss_ctc 20.013180 loss_rnnt 10.405946 hw_loss 0.099340 lr 0.00043653 rank 6
2023-02-22 06:14:25,202 DEBUG TRAIN Batch 15/6100 loss 14.406271 loss_att 15.701556 loss_ctc 20.295839 loss_rnnt 13.256758 hw_loss 0.197214 lr 0.00043651 rank 3
2023-02-22 06:15:39,650 DEBUG TRAIN Batch 15/6200 loss 10.826967 loss_att 13.750174 loss_ctc 15.333055 loss_rnnt 9.600626 hw_loss 0.076665 lr 0.00043633 rank 4
2023-02-22 06:15:39,650 DEBUG TRAIN Batch 15/6200 loss 15.536377 loss_att 18.319952 loss_ctc 22.907425 loss_rnnt 13.909292 hw_loss 0.164180 lr 0.00043626 rank 5
2023-02-22 06:15:39,654 DEBUG TRAIN Batch 15/6200 loss 10.319604 loss_att 11.033028 loss_ctc 12.915007 loss_rnnt 9.768955 hw_loss 0.116081 lr 0.00043634 rank 3
2023-02-22 06:15:39,656 DEBUG TRAIN Batch 15/6200 loss 14.508590 loss_att 19.802757 loss_ctc 21.531908 loss_rnnt 12.472195 hw_loss 0.077097 lr 0.00043632 rank 0
2023-02-22 06:15:39,658 DEBUG TRAIN Batch 15/6200 loss 18.516649 loss_att 17.657003 loss_ctc 23.122654 loss_rnnt 17.996431 hw_loss 0.146275 lr 0.00043628 rank 7
2023-02-22 06:15:39,660 DEBUG TRAIN Batch 15/6200 loss 16.869696 loss_att 23.014189 loss_ctc 21.782257 loss_rnnt 14.951753 hw_loss 0.063813 lr 0.00043637 rank 1
2023-02-22 06:15:39,660 DEBUG TRAIN Batch 15/6200 loss 5.732708 loss_att 8.528003 loss_ctc 9.007373 loss_rnnt 4.712976 hw_loss 0.045097 lr 0.00043629 rank 2
2023-02-22 06:15:39,660 DEBUG TRAIN Batch 15/6200 loss 21.532925 loss_att 24.758516 loss_ctc 27.986032 loss_rnnt 19.922771 hw_loss 0.196163 lr 0.00043637 rank 6
2023-02-22 06:16:55,649 DEBUG TRAIN Batch 15/6300 loss 15.374224 loss_att 17.007648 loss_ctc 20.124464 loss_rnnt 14.300038 hw_loss 0.214002 lr 0.00043618 rank 3
2023-02-22 06:16:55,651 DEBUG TRAIN Batch 15/6300 loss 7.238236 loss_att 9.394038 loss_ctc 10.595840 loss_rnnt 6.333768 hw_loss 0.048051 lr 0.00043616 rank 4
2023-02-22 06:16:55,651 DEBUG TRAIN Batch 15/6300 loss 7.159044 loss_att 10.438425 loss_ctc 10.778517 loss_rnnt 5.905473 hw_loss 0.215808 lr 0.00043613 rank 2
2023-02-22 06:16:55,652 DEBUG TRAIN Batch 15/6300 loss 11.103980 loss_att 12.859622 loss_ctc 17.713474 loss_rnnt 9.813698 hw_loss 0.108539 lr 0.00043616 rank 0
2023-02-22 06:16:55,653 DEBUG TRAIN Batch 15/6300 loss 12.042959 loss_att 14.363846 loss_ctc 18.071852 loss_rnnt 10.685523 hw_loss 0.167636 lr 0.00043610 rank 5
2023-02-22 06:16:55,655 DEBUG TRAIN Batch 15/6300 loss 9.559547 loss_att 10.583482 loss_ctc 10.549984 loss_rnnt 9.141526 hw_loss 0.152203 lr 0.00043621 rank 1
2023-02-22 06:16:55,656 DEBUG TRAIN Batch 15/6300 loss 12.595200 loss_att 16.012436 loss_ctc 18.825323 loss_rnnt 10.983014 hw_loss 0.183854 lr 0.00043620 rank 6
2023-02-22 06:16:55,656 DEBUG TRAIN Batch 15/6300 loss 12.213387 loss_att 14.592712 loss_ctc 18.269304 loss_rnnt 10.838888 hw_loss 0.170963 lr 0.00043611 rank 7
2023-02-22 06:18:14,225 DEBUG TRAIN Batch 15/6400 loss 12.291228 loss_att 12.626287 loss_ctc 14.618866 loss_rnnt 11.813733 hw_loss 0.187748 lr 0.00043593 rank 5
2023-02-22 06:18:14,226 DEBUG TRAIN Batch 15/6400 loss 20.789057 loss_att 20.968128 loss_ctc 28.085232 loss_rnnt 19.737904 hw_loss 0.079720 lr 0.00043600 rank 4
2023-02-22 06:18:14,227 DEBUG TRAIN Batch 15/6400 loss 20.894716 loss_att 21.365997 loss_ctc 26.752396 loss_rnnt 19.930492 hw_loss 0.166776 lr 0.00043599 rank 0
2023-02-22 06:18:14,230 DEBUG TRAIN Batch 15/6400 loss 6.262258 loss_att 6.947759 loss_ctc 8.192056 loss_rnnt 5.797613 hw_loss 0.131698 lr 0.00043594 rank 7
2023-02-22 06:18:14,231 DEBUG TRAIN Batch 15/6400 loss 19.978735 loss_att 25.422760 loss_ctc 23.817455 loss_rnnt 18.344990 hw_loss 0.062083 lr 0.00043603 rank 6
2023-02-22 06:18:14,232 DEBUG TRAIN Batch 15/6400 loss 15.690364 loss_att 17.200802 loss_ctc 21.077724 loss_rnnt 14.586527 hw_loss 0.156439 lr 0.00043604 rank 1
2023-02-22 06:18:14,236 DEBUG TRAIN Batch 15/6400 loss 6.362647 loss_att 11.326803 loss_ctc 8.337055 loss_rnnt 5.102077 hw_loss 0.008408 lr 0.00043596 rank 2
2023-02-22 06:18:14,239 DEBUG TRAIN Batch 15/6400 loss 22.500399 loss_att 27.809723 loss_ctc 27.900681 loss_rnnt 20.615948 hw_loss 0.192276 lr 0.00043601 rank 3
2023-02-22 06:19:29,779 DEBUG TRAIN Batch 15/6500 loss 13.010382 loss_att 14.434586 loss_ctc 13.144821 loss_rnnt 12.646715 hw_loss 0.114189 lr 0.00043576 rank 5
2023-02-22 06:19:29,780 DEBUG TRAIN Batch 15/6500 loss 7.312256 loss_att 9.516181 loss_ctc 11.387126 loss_rnnt 6.308761 hw_loss 0.036365 lr 0.00043587 rank 1
2023-02-22 06:19:29,781 DEBUG TRAIN Batch 15/6500 loss 16.338993 loss_att 19.136602 loss_ctc 18.646645 loss_rnnt 15.423058 hw_loss 0.091360 lr 0.00043583 rank 0
2023-02-22 06:19:29,782 DEBUG TRAIN Batch 15/6500 loss 8.704843 loss_att 10.180625 loss_ctc 10.308324 loss_rnnt 8.106066 hw_loss 0.168419 lr 0.00043583 rank 4
2023-02-22 06:19:29,782 DEBUG TRAIN Batch 15/6500 loss 11.179140 loss_att 15.482090 loss_ctc 13.654052 loss_rnnt 9.933041 hw_loss 0.104104 lr 0.00043585 rank 3
2023-02-22 06:19:29,784 DEBUG TRAIN Batch 15/6500 loss 10.614633 loss_att 14.851695 loss_ctc 12.453278 loss_rnnt 9.521006 hw_loss 0.001991 lr 0.00043578 rank 7
2023-02-22 06:19:29,786 DEBUG TRAIN Batch 15/6500 loss 22.382509 loss_att 24.420940 loss_ctc 31.082710 loss_rnnt 20.790844 hw_loss 0.044906 lr 0.00043587 rank 6
2023-02-22 06:19:29,787 DEBUG TRAIN Batch 15/6500 loss 14.473486 loss_att 17.137066 loss_ctc 16.487371 loss_rnnt 13.595405 hw_loss 0.144090 lr 0.00043580 rank 2
2023-02-22 06:20:46,055 DEBUG TRAIN Batch 15/6600 loss 9.885894 loss_att 12.071421 loss_ctc 10.525191 loss_rnnt 9.324261 hw_loss 0.073667 lr 0.00043561 rank 7
2023-02-22 06:20:46,060 DEBUG TRAIN Batch 15/6600 loss 17.140465 loss_att 24.190376 loss_ctc 22.557037 loss_rnnt 14.914192 hw_loss 0.176402 lr 0.00043571 rank 1
2023-02-22 06:20:46,059 DEBUG TRAIN Batch 15/6600 loss 11.278610 loss_att 14.352829 loss_ctc 16.400978 loss_rnnt 9.851343 hw_loss 0.242700 lr 0.00043560 rank 5
2023-02-22 06:20:46,060 DEBUG TRAIN Batch 15/6600 loss 10.138326 loss_att 12.803071 loss_ctc 13.329514 loss_rnnt 9.142929 hw_loss 0.069291 lr 0.00043567 rank 4
2023-02-22 06:20:46,062 DEBUG TRAIN Batch 15/6600 loss 4.513170 loss_att 7.852636 loss_ctc 9.048742 loss_rnnt 3.193805 hw_loss 0.087616 lr 0.00043566 rank 0
2023-02-22 06:20:46,068 DEBUG TRAIN Batch 15/6600 loss 8.954572 loss_att 11.871614 loss_ctc 10.833414 loss_rnnt 8.063540 hw_loss 0.107082 lr 0.00043563 rank 2
2023-02-22 06:20:46,069 DEBUG TRAIN Batch 15/6600 loss 11.873906 loss_att 14.996469 loss_ctc 21.915098 loss_rnnt 9.820182 hw_loss 0.169472 lr 0.00043568 rank 3
2023-02-22 06:20:46,070 DEBUG TRAIN Batch 15/6600 loss 9.559184 loss_att 11.326902 loss_ctc 16.898191 loss_rnnt 8.148113 hw_loss 0.148111 lr 0.00043570 rank 6
2023-02-22 06:22:02,650 DEBUG TRAIN Batch 15/6700 loss 12.884787 loss_att 17.945612 loss_ctc 17.027573 loss_rnnt 11.242239 hw_loss 0.146271 lr 0.00043543 rank 5
2023-02-22 06:22:02,650 DEBUG TRAIN Batch 15/6700 loss 8.628283 loss_att 10.910778 loss_ctc 13.991812 loss_rnnt 7.404597 hw_loss 0.097592 lr 0.00043550 rank 4
2023-02-22 06:22:02,654 DEBUG TRAIN Batch 15/6700 loss 9.920622 loss_att 13.291808 loss_ctc 13.419243 loss_rnnt 8.712635 hw_loss 0.126126 lr 0.00043545 rank 7
2023-02-22 06:22:02,655 DEBUG TRAIN Batch 15/6700 loss 6.723045 loss_att 10.513815 loss_ctc 11.237890 loss_rnnt 5.309423 hw_loss 0.100290 lr 0.00043550 rank 0
2023-02-22 06:22:02,658 DEBUG TRAIN Batch 15/6700 loss 8.725049 loss_att 14.191739 loss_ctc 11.877867 loss_rnnt 7.167319 hw_loss 0.082531 lr 0.00043554 rank 1
2023-02-22 06:22:02,659 DEBUG TRAIN Batch 15/6700 loss 9.694186 loss_att 12.838362 loss_ctc 11.962217 loss_rnnt 8.701572 hw_loss 0.115078 lr 0.00043552 rank 3
2023-02-22 06:22:02,660 DEBUG TRAIN Batch 15/6700 loss 17.385794 loss_att 19.356232 loss_ctc 23.963623 loss_rnnt 16.056763 hw_loss 0.108561 lr 0.00043554 rank 6
2023-02-22 06:22:02,664 DEBUG TRAIN Batch 15/6700 loss 11.342069 loss_att 14.553246 loss_ctc 14.871497 loss_rnnt 10.157921 hw_loss 0.133727 lr 0.00043546 rank 2
2023-02-22 06:23:19,600 DEBUG TRAIN Batch 15/6800 loss 10.987509 loss_att 15.984676 loss_ctc 15.734181 loss_rnnt 9.336859 hw_loss 0.034363 lr 0.00043527 rank 5
2023-02-22 06:23:19,603 DEBUG TRAIN Batch 15/6800 loss 18.013182 loss_att 21.810421 loss_ctc 26.431496 loss_rnnt 16.051289 hw_loss 0.150008 lr 0.00043538 rank 1
2023-02-22 06:23:19,603 DEBUG TRAIN Batch 15/6800 loss 6.671249 loss_att 11.324354 loss_ctc 9.418386 loss_rnnt 5.332933 hw_loss 0.077643 lr 0.00043528 rank 7
2023-02-22 06:23:19,606 DEBUG TRAIN Batch 15/6800 loss 14.769865 loss_att 14.584799 loss_ctc 19.583397 loss_rnnt 14.090446 hw_loss 0.139927 lr 0.00043535 rank 3
2023-02-22 06:23:19,606 DEBUG TRAIN Batch 15/6800 loss 7.372646 loss_att 10.536864 loss_ctc 8.060777 loss_rnnt 6.581152 hw_loss 0.125437 lr 0.00043534 rank 4
2023-02-22 06:23:19,607 DEBUG TRAIN Batch 15/6800 loss 17.843023 loss_att 23.045645 loss_ctc 24.420010 loss_rnnt 15.878578 hw_loss 0.088105 lr 0.00043533 rank 0
2023-02-22 06:23:19,608 DEBUG TRAIN Batch 15/6800 loss 18.436754 loss_att 19.765539 loss_ctc 25.903133 loss_rnnt 17.106876 hw_loss 0.128631 lr 0.00043530 rank 2
2023-02-22 06:23:19,655 DEBUG TRAIN Batch 15/6800 loss 5.593435 loss_att 7.332417 loss_ctc 7.657124 loss_rnnt 4.848175 hw_loss 0.229323 lr 0.00043537 rank 6
2023-02-22 06:24:34,106 DEBUG TRAIN Batch 15/6900 loss 24.866089 loss_att 26.064533 loss_ctc 28.574623 loss_rnnt 24.109385 hw_loss 0.042273 lr 0.00043512 rank 7
2023-02-22 06:24:34,112 DEBUG TRAIN Batch 15/6900 loss 16.400976 loss_att 19.899136 loss_ctc 21.897114 loss_rnnt 14.903601 hw_loss 0.121735 lr 0.00043517 rank 0
2023-02-22 06:24:34,113 DEBUG TRAIN Batch 15/6900 loss 7.915627 loss_att 11.939885 loss_ctc 13.131738 loss_rnnt 6.332359 hw_loss 0.155501 lr 0.00043510 rank 5
2023-02-22 06:24:34,114 DEBUG TRAIN Batch 15/6900 loss 10.194261 loss_att 12.457296 loss_ctc 15.172676 loss_rnnt 9.045297 hw_loss 0.061065 lr 0.00043521 rank 1
2023-02-22 06:24:34,115 DEBUG TRAIN Batch 15/6900 loss 17.670033 loss_att 21.795860 loss_ctc 26.279936 loss_rnnt 15.627891 hw_loss 0.129358 lr 0.00043517 rank 4
2023-02-22 06:24:34,116 DEBUG TRAIN Batch 15/6900 loss 7.794640 loss_att 10.250654 loss_ctc 9.229533 loss_rnnt 7.016327 hw_loss 0.179607 lr 0.00043519 rank 3
2023-02-22 06:24:34,117 DEBUG TRAIN Batch 15/6900 loss 15.609806 loss_att 16.598198 loss_ctc 20.298698 loss_rnnt 14.661645 hw_loss 0.234930 lr 0.00043513 rank 2
2023-02-22 06:24:34,119 DEBUG TRAIN Batch 15/6900 loss 11.246245 loss_att 12.858665 loss_ctc 14.037760 loss_rnnt 10.458480 hw_loss 0.174526 lr 0.00043521 rank 6
2023-02-22 06:25:50,059 DEBUG TRAIN Batch 15/7000 loss 15.459095 loss_att 15.464571 loss_ctc 19.061117 loss_rnnt 14.898170 hw_loss 0.149177 lr 0.00043500 rank 0
2023-02-22 06:25:50,061 DEBUG TRAIN Batch 15/7000 loss 13.018579 loss_att 13.226863 loss_ctc 15.993994 loss_rnnt 12.450847 hw_loss 0.242537 lr 0.00043504 rank 6
2023-02-22 06:25:50,062 DEBUG TRAIN Batch 15/7000 loss 10.988936 loss_att 12.406706 loss_ctc 14.317367 loss_rnnt 10.161932 hw_loss 0.186864 lr 0.00043501 rank 4
2023-02-22 06:25:50,063 DEBUG TRAIN Batch 15/7000 loss 10.077442 loss_att 11.086757 loss_ctc 14.284335 loss_rnnt 9.236122 hw_loss 0.147260 lr 0.00043494 rank 5
2023-02-22 06:25:50,064 DEBUG TRAIN Batch 15/7000 loss 14.357906 loss_att 17.281441 loss_ctc 15.904429 loss_rnnt 13.437140 hw_loss 0.243483 lr 0.00043502 rank 3
2023-02-22 06:25:50,069 DEBUG TRAIN Batch 15/7000 loss 11.026381 loss_att 13.257658 loss_ctc 15.319439 loss_rnnt 9.881654 hw_loss 0.236370 lr 0.00043497 rank 2
2023-02-22 06:25:50,070 DEBUG TRAIN Batch 15/7000 loss 8.826072 loss_att 9.834578 loss_ctc 10.275141 loss_rnnt 8.337291 hw_loss 0.176008 lr 0.00043495 rank 7
2023-02-22 06:25:50,114 DEBUG TRAIN Batch 15/7000 loss 6.983590 loss_att 9.372169 loss_ctc 8.995954 loss_rnnt 6.177991 hw_loss 0.111689 lr 0.00043505 rank 1
2023-02-22 06:27:08,010 DEBUG TRAIN Batch 15/7100 loss 10.557468 loss_att 16.909475 loss_ctc 16.510670 loss_rnnt 8.462351 hw_loss 0.058040 lr 0.00043484 rank 0
2023-02-22 06:27:08,014 DEBUG TRAIN Batch 15/7100 loss 5.389378 loss_att 8.702818 loss_ctc 10.008221 loss_rnnt 4.011666 hw_loss 0.185958 lr 0.00043477 rank 5
2023-02-22 06:27:08,014 DEBUG TRAIN Batch 15/7100 loss 8.562573 loss_att 13.055405 loss_ctc 9.524848 loss_rnnt 7.471828 hw_loss 0.119767 lr 0.00043479 rank 7
2023-02-22 06:27:08,016 DEBUG TRAIN Batch 15/7100 loss 11.727586 loss_att 14.196346 loss_ctc 14.677160 loss_rnnt 10.788595 hw_loss 0.097429 lr 0.00043486 rank 3
2023-02-22 06:27:08,016 DEBUG TRAIN Batch 15/7100 loss 11.601844 loss_att 16.634655 loss_ctc 18.019032 loss_rnnt 9.714587 hw_loss 0.047006 lr 0.00043484 rank 4
2023-02-22 06:27:08,027 DEBUG TRAIN Batch 15/7100 loss 10.661034 loss_att 13.270295 loss_ctc 16.221487 loss_rnnt 9.347885 hw_loss 0.093567 lr 0.00043488 rank 6
2023-02-22 06:27:08,029 DEBUG TRAIN Batch 15/7100 loss 19.716757 loss_att 23.683685 loss_ctc 30.193935 loss_rnnt 17.499004 hw_loss 0.051392 lr 0.00043481 rank 2
2023-02-22 06:27:08,030 DEBUG TRAIN Batch 15/7100 loss 6.793522 loss_att 7.039684 loss_ctc 8.381700 loss_rnnt 6.450898 hw_loss 0.153065 lr 0.00043488 rank 1
2023-02-22 06:28:23,799 DEBUG TRAIN Batch 15/7200 loss 11.301689 loss_att 12.791356 loss_ctc 17.377270 loss_rnnt 10.150124 hw_loss 0.081666 lr 0.00043461 rank 5
2023-02-22 06:28:23,799 DEBUG TRAIN Batch 15/7200 loss 6.654333 loss_att 12.093737 loss_ctc 12.507210 loss_rnnt 4.724565 hw_loss 0.115319 lr 0.00043468 rank 4
2023-02-22 06:28:23,805 DEBUG TRAIN Batch 15/7200 loss 11.449739 loss_att 14.370502 loss_ctc 16.771324 loss_rnnt 10.071040 hw_loss 0.159376 lr 0.00043462 rank 7
2023-02-22 06:28:23,806 DEBUG TRAIN Batch 15/7200 loss 11.758273 loss_att 13.871290 loss_ctc 14.516918 loss_rnnt 10.967765 hw_loss 0.000161 lr 0.00043471 rank 6
2023-02-22 06:28:23,808 DEBUG TRAIN Batch 15/7200 loss 12.487363 loss_att 13.991812 loss_ctc 15.321648 loss_rnnt 11.706312 hw_loss 0.191732 lr 0.00043472 rank 1
2023-02-22 06:28:23,807 DEBUG TRAIN Batch 15/7200 loss 12.823234 loss_att 16.908026 loss_ctc 21.009975 loss_rnnt 10.884117 hw_loss 0.057360 lr 0.00043467 rank 0
2023-02-22 06:28:23,813 DEBUG TRAIN Batch 15/7200 loss 5.494431 loss_att 12.995409 loss_ctc 6.045894 loss_rnnt 3.844637 hw_loss 0.142629 lr 0.00043464 rank 2
2023-02-22 06:28:23,857 DEBUG TRAIN Batch 15/7200 loss 9.579351 loss_att 11.515184 loss_ctc 12.296931 loss_rnnt 8.817600 hw_loss 0.022950 lr 0.00043469 rank 3
2023-02-22 06:29:39,105 DEBUG TRAIN Batch 15/7300 loss 1.928300 loss_att 4.753221 loss_ctc 1.504817 loss_rnnt 1.301443 hw_loss 0.221883 lr 0.00043446 rank 7
2023-02-22 06:29:39,105 DEBUG TRAIN Batch 15/7300 loss 9.967087 loss_att 13.879183 loss_ctc 12.610594 loss_rnnt 8.782171 hw_loss 0.093804 lr 0.00043451 rank 0
2023-02-22 06:29:39,107 DEBUG TRAIN Batch 15/7300 loss 12.647988 loss_att 17.806683 loss_ctc 21.389639 loss_rnnt 10.318851 hw_loss 0.247209 lr 0.00043456 rank 1
2023-02-22 06:29:39,108 DEBUG TRAIN Batch 15/7300 loss 6.673019 loss_att 7.927044 loss_ctc 10.200972 loss_rnnt 5.880588 hw_loss 0.133561 lr 0.00043451 rank 4
2023-02-22 06:29:39,110 DEBUG TRAIN Batch 15/7300 loss 15.010003 loss_att 20.196203 loss_ctc 19.802773 loss_rnnt 13.319138 hw_loss 0.027355 lr 0.00043445 rank 5
2023-02-22 06:29:39,118 DEBUG TRAIN Batch 15/7300 loss 21.513062 loss_att 26.094261 loss_ctc 23.470411 loss_rnnt 20.307636 hw_loss 0.052888 lr 0.00043448 rank 2
2023-02-22 06:29:39,119 DEBUG TRAIN Batch 15/7300 loss 6.690347 loss_att 11.985712 loss_ctc 8.988541 loss_rnnt 5.324737 hw_loss 0.000209 lr 0.00043455 rank 6
2023-02-22 06:29:39,123 DEBUG TRAIN Batch 15/7300 loss 11.485540 loss_att 13.635838 loss_ctc 14.418657 loss_rnnt 10.588679 hw_loss 0.141973 lr 0.00043453 rank 3
2023-02-22 06:30:54,139 DEBUG TRAIN Batch 15/7400 loss 14.927874 loss_att 15.831796 loss_ctc 18.693882 loss_rnnt 14.162247 hw_loss 0.155076 lr 0.00043434 rank 0
2023-02-22 06:30:54,141 DEBUG TRAIN Batch 15/7400 loss 8.757008 loss_att 12.586464 loss_ctc 12.938475 loss_rnnt 7.425900 hw_loss 0.014414 lr 0.00043439 rank 6
2023-02-22 06:30:54,142 DEBUG TRAIN Batch 15/7400 loss 6.910758 loss_att 10.711513 loss_ctc 10.031859 loss_rnnt 5.678552 hw_loss 0.104827 lr 0.00043428 rank 5
2023-02-22 06:30:54,143 DEBUG TRAIN Batch 15/7400 loss 5.855149 loss_att 8.368215 loss_ctc 7.257662 loss_rnnt 5.085753 hw_loss 0.149588 lr 0.00043436 rank 3
2023-02-22 06:30:54,144 DEBUG TRAIN Batch 15/7400 loss 10.169143 loss_att 14.924822 loss_ctc 10.217361 loss_rnnt 9.104596 hw_loss 0.200588 lr 0.00043435 rank 4
2023-02-22 06:30:54,145 DEBUG TRAIN Batch 15/7400 loss 21.577723 loss_att 25.927656 loss_ctc 25.721210 loss_rnnt 20.078030 hw_loss 0.144827 lr 0.00043439 rank 1
2023-02-22 06:30:54,148 DEBUG TRAIN Batch 15/7400 loss 8.842969 loss_att 10.867829 loss_ctc 12.051868 loss_rnnt 7.910374 hw_loss 0.187069 lr 0.00043430 rank 7
2023-02-22 06:30:54,148 DEBUG TRAIN Batch 15/7400 loss 14.105412 loss_att 15.541864 loss_ctc 18.216465 loss_rnnt 13.214743 hw_loss 0.103574 lr 0.00043431 rank 2
2023-02-22 06:32:10,410 DEBUG TRAIN Batch 15/7500 loss 8.346478 loss_att 12.198488 loss_ctc 13.679474 loss_rnnt 6.810708 hw_loss 0.101817 lr 0.00043412 rank 5
2023-02-22 06:32:10,410 DEBUG TRAIN Batch 15/7500 loss 14.457353 loss_att 15.623111 loss_ctc 16.595600 loss_rnnt 13.832072 hw_loss 0.200678 lr 0.00043413 rank 7
2023-02-22 06:32:10,412 DEBUG TRAIN Batch 15/7500 loss 8.643605 loss_att 11.254924 loss_ctc 10.399942 loss_rnnt 7.841046 hw_loss 0.086468 lr 0.00043419 rank 4
2023-02-22 06:32:10,413 DEBUG TRAIN Batch 15/7500 loss 10.347542 loss_att 14.168395 loss_ctc 13.507142 loss_rnnt 9.106163 hw_loss 0.104865 lr 0.00043418 rank 0
2023-02-22 06:32:10,413 DEBUG TRAIN Batch 15/7500 loss 12.582396 loss_att 15.704473 loss_ctc 20.338062 loss_rnnt 10.891672 hw_loss 0.060409 lr 0.00043423 rank 1
2023-02-22 06:32:10,413 DEBUG TRAIN Batch 15/7500 loss 7.101167 loss_att 10.658095 loss_ctc 8.781593 loss_rnnt 6.079079 hw_loss 0.162459 lr 0.00043420 rank 3
2023-02-22 06:32:10,418 DEBUG TRAIN Batch 15/7500 loss 8.356713 loss_att 10.517474 loss_ctc 11.982903 loss_rnnt 7.348642 hw_loss 0.173301 lr 0.00043422 rank 6
2023-02-22 06:32:10,466 DEBUG TRAIN Batch 15/7500 loss 31.319647 loss_att 33.383827 loss_ctc 48.808769 loss_rnnt 28.528988 hw_loss 0.086142 lr 0.00043415 rank 2
2023-02-22 06:33:26,334 DEBUG TRAIN Batch 15/7600 loss 9.853264 loss_att 12.112299 loss_ctc 15.249230 loss_rnnt 8.638487 hw_loss 0.081577 lr 0.00043402 rank 0
2023-02-22 06:33:26,334 DEBUG TRAIN Batch 15/7600 loss 15.413364 loss_att 18.004957 loss_ctc 16.435965 loss_rnnt 14.724566 hw_loss 0.063998 lr 0.00043402 rank 4
2023-02-22 06:33:26,336 DEBUG TRAIN Batch 15/7600 loss 16.512348 loss_att 19.101809 loss_ctc 18.904179 loss_rnnt 15.593720 hw_loss 0.153422 lr 0.00043406 rank 1
2023-02-22 06:33:26,336 DEBUG TRAIN Batch 15/7600 loss 8.272350 loss_att 10.435287 loss_ctc 9.914026 loss_rnnt 7.548335 hw_loss 0.136007 lr 0.00043397 rank 7
2023-02-22 06:33:26,339 DEBUG TRAIN Batch 15/7600 loss 15.351708 loss_att 17.583710 loss_ctc 21.686863 loss_rnnt 13.969559 hw_loss 0.170744 lr 0.00043399 rank 2
2023-02-22 06:33:26,340 DEBUG TRAIN Batch 15/7600 loss 12.157294 loss_att 13.634925 loss_ctc 15.027159 loss_rnnt 11.399738 hw_loss 0.148840 lr 0.00043404 rank 3
2023-02-22 06:33:26,342 DEBUG TRAIN Batch 15/7600 loss 4.687782 loss_att 6.869428 loss_ctc 5.386691 loss_rnnt 4.117384 hw_loss 0.076652 lr 0.00043395 rank 5
2023-02-22 06:33:26,391 DEBUG TRAIN Batch 15/7600 loss 4.984730 loss_att 8.035934 loss_ctc 8.806766 loss_rnnt 3.811013 hw_loss 0.101010 lr 0.00043406 rank 6
2023-02-22 06:34:40,350 DEBUG TRAIN Batch 15/7700 loss 11.133467 loss_att 12.607514 loss_ctc 12.576977 loss_rnnt 10.523246 hw_loss 0.230518 lr 0.00043381 rank 7
2023-02-22 06:34:40,353 DEBUG TRAIN Batch 15/7700 loss 14.497282 loss_att 15.482903 loss_ctc 18.187628 loss_rnnt 13.738662 hw_loss 0.130220 lr 0.00043389 rank 6
2023-02-22 06:34:40,354 DEBUG TRAIN Batch 15/7700 loss 26.068569 loss_att 28.931511 loss_ctc 30.451431 loss_rnnt 24.803030 hw_loss 0.203566 lr 0.00043386 rank 4
2023-02-22 06:34:40,354 DEBUG TRAIN Batch 15/7700 loss 11.637329 loss_att 13.364441 loss_ctc 18.969704 loss_rnnt 10.231430 hw_loss 0.155299 lr 0.00043379 rank 5
2023-02-22 06:34:40,357 DEBUG TRAIN Batch 15/7700 loss 10.495221 loss_att 12.370239 loss_ctc 15.444648 loss_rnnt 9.303138 hw_loss 0.294668 lr 0.00043390 rank 1
2023-02-22 06:34:40,357 DEBUG TRAIN Batch 15/7700 loss 15.169002 loss_att 17.256359 loss_ctc 19.904762 loss_rnnt 14.035457 hw_loss 0.158695 lr 0.00043385 rank 0
2023-02-22 06:34:40,362 DEBUG TRAIN Batch 15/7700 loss 17.625319 loss_att 21.668140 loss_ctc 24.913483 loss_rnnt 15.739906 hw_loss 0.197049 lr 0.00043382 rank 2
2023-02-22 06:34:40,403 DEBUG TRAIN Batch 15/7700 loss 16.473459 loss_att 20.846783 loss_ctc 22.104126 loss_rnnt 14.814548 hw_loss 0.062793 lr 0.00043387 rank 3
2023-02-22 06:35:57,951 DEBUG TRAIN Batch 15/7800 loss 8.748414 loss_att 9.679650 loss_ctc 10.148787 loss_rnnt 8.306545 hw_loss 0.129196 lr 0.00043364 rank 7
2023-02-22 06:35:57,952 DEBUG TRAIN Batch 15/7800 loss 4.235038 loss_att 8.376228 loss_ctc 5.840683 loss_rnnt 3.192590 hw_loss 0.000231 lr 0.00043374 rank 1
2023-02-22 06:35:57,953 DEBUG TRAIN Batch 15/7800 loss 10.463305 loss_att 14.043889 loss_ctc 12.320183 loss_rnnt 9.452118 hw_loss 0.089038 lr 0.00043370 rank 4
2023-02-22 06:35:57,954 DEBUG TRAIN Batch 15/7800 loss 7.429989 loss_att 9.640970 loss_ctc 9.196247 loss_rnnt 6.696742 hw_loss 0.104157 lr 0.00043363 rank 5
2023-02-22 06:35:57,955 DEBUG TRAIN Batch 15/7800 loss 11.008649 loss_att 14.280176 loss_ctc 12.996215 loss_rnnt 10.011827 hw_loss 0.145329 lr 0.00043369 rank 0
2023-02-22 06:35:57,955 DEBUG TRAIN Batch 15/7800 loss 15.302875 loss_att 20.337769 loss_ctc 21.049187 loss_rnnt 13.432170 hw_loss 0.182907 lr 0.00043373 rank 6
2023-02-22 06:35:57,956 DEBUG TRAIN Batch 15/7800 loss 18.245289 loss_att 19.937202 loss_ctc 21.313084 loss_rnnt 17.446850 hw_loss 0.095653 lr 0.00043371 rank 3
2023-02-22 06:35:58,008 DEBUG TRAIN Batch 15/7800 loss 9.416102 loss_att 10.733739 loss_ctc 9.677184 loss_rnnt 9.028838 hw_loss 0.166735 lr 0.00043366 rank 2
2023-02-22 06:37:14,544 DEBUG TRAIN Batch 15/7900 loss 3.637432 loss_att 5.760185 loss_ctc 1.717776 loss_rnnt 3.443585 hw_loss 0.047345 lr 0.00043353 rank 0
2023-02-22 06:37:14,545 DEBUG TRAIN Batch 15/7900 loss 12.566312 loss_att 18.250416 loss_ctc 12.111979 loss_rnnt 11.451640 hw_loss 0.072056 lr 0.00043348 rank 7
2023-02-22 06:37:14,546 DEBUG TRAIN Batch 15/7900 loss 9.917065 loss_att 11.171024 loss_ctc 9.126635 loss_rnnt 9.726020 hw_loss 0.085584 lr 0.00043353 rank 4
2023-02-22 06:37:14,546 DEBUG TRAIN Batch 15/7900 loss 12.914598 loss_att 16.456335 loss_ctc 18.664677 loss_rnnt 11.418391 hw_loss 0.039717 lr 0.00043347 rank 5
2023-02-22 06:37:14,552 DEBUG TRAIN Batch 15/7900 loss 6.739732 loss_att 11.770386 loss_ctc 10.868322 loss_rnnt 5.154364 hw_loss 0.053924 lr 0.00043357 rank 1
2023-02-22 06:37:14,553 DEBUG TRAIN Batch 15/7900 loss 19.799164 loss_att 19.689266 loss_ctc 20.056486 loss_rnnt 19.763567 hw_loss 0.043626 lr 0.00043355 rank 3
2023-02-22 06:37:14,554 DEBUG TRAIN Batch 15/7900 loss 12.089329 loss_att 15.950436 loss_ctc 15.668921 loss_rnnt 10.788191 hw_loss 0.096820 lr 0.00043357 rank 6
2023-02-22 06:37:14,554 DEBUG TRAIN Batch 15/7900 loss 5.321313 loss_att 9.966427 loss_ctc 7.735000 loss_rnnt 4.035444 hw_loss 0.065665 lr 0.00043350 rank 2
2023-02-22 06:38:30,450 DEBUG TRAIN Batch 15/8000 loss 8.790463 loss_att 10.419439 loss_ctc 13.194593 loss_rnnt 7.835214 hw_loss 0.079194 lr 0.00043330 rank 5
2023-02-22 06:38:30,454 DEBUG TRAIN Batch 15/8000 loss 17.355501 loss_att 19.085022 loss_ctc 22.971092 loss_rnnt 16.219696 hw_loss 0.077165 lr 0.00043336 rank 0
2023-02-22 06:38:30,454 DEBUG TRAIN Batch 15/8000 loss 5.754695 loss_att 10.367639 loss_ctc 7.992252 loss_rnnt 4.475129 hw_loss 0.109945 lr 0.00043337 rank 4
2023-02-22 06:38:30,455 DEBUG TRAIN Batch 15/8000 loss 8.411365 loss_att 13.076074 loss_ctc 14.138212 loss_rnnt 6.672104 hw_loss 0.080135 lr 0.00043332 rank 7
2023-02-22 06:38:30,460 DEBUG TRAIN Batch 15/8000 loss 13.412030 loss_att 14.442598 loss_ctc 14.793655 loss_rnnt 12.943198 hw_loss 0.147192 lr 0.00043338 rank 3
2023-02-22 06:38:30,462 DEBUG TRAIN Batch 15/8000 loss 6.021441 loss_att 9.979766 loss_ctc 9.112466 loss_rnnt 4.762438 hw_loss 0.103504 lr 0.00043333 rank 2
2023-02-22 06:38:30,463 DEBUG TRAIN Batch 15/8000 loss 12.969396 loss_att 11.642772 loss_ctc 23.143219 loss_rnnt 11.834190 hw_loss 0.082538 lr 0.00043341 rank 1
2023-02-22 06:38:30,502 DEBUG TRAIN Batch 15/8000 loss 8.482625 loss_att 11.876444 loss_ctc 10.820324 loss_rnnt 7.441918 hw_loss 0.094218 lr 0.00043341 rank 6
2023-02-22 06:39:45,973 DEBUG TRAIN Batch 15/8100 loss 17.565519 loss_att 24.616810 loss_ctc 23.706905 loss_rnnt 15.292139 hw_loss 0.083006 lr 0.00043320 rank 0
2023-02-22 06:39:45,975 DEBUG TRAIN Batch 15/8100 loss 16.889088 loss_att 21.348434 loss_ctc 21.721985 loss_rnnt 15.262528 hw_loss 0.169320 lr 0.00043315 rank 7
2023-02-22 06:39:45,978 DEBUG TRAIN Batch 15/8100 loss 7.459507 loss_att 12.939152 loss_ctc 10.980000 loss_rnnt 5.828213 hw_loss 0.123685 lr 0.00043321 rank 4
2023-02-22 06:39:45,979 DEBUG TRAIN Batch 15/8100 loss 8.832474 loss_att 11.022392 loss_ctc 10.109734 loss_rnnt 8.151331 hw_loss 0.136610 lr 0.00043314 rank 5
2023-02-22 06:39:45,980 DEBUG TRAIN Batch 15/8100 loss 13.905839 loss_att 15.962813 loss_ctc 15.657495 loss_rnnt 13.228192 hw_loss 0.061309 lr 0.00043325 rank 1
2023-02-22 06:39:45,984 DEBUG TRAIN Batch 15/8100 loss 12.636514 loss_att 15.646385 loss_ctc 22.390696 loss_rnnt 10.654117 hw_loss 0.149745 lr 0.00043322 rank 3
2023-02-22 06:39:45,985 DEBUG TRAIN Batch 15/8100 loss 8.624872 loss_att 10.636141 loss_ctc 10.669586 loss_rnnt 7.880551 hw_loss 0.130199 lr 0.00043324 rank 6
2023-02-22 06:39:46,025 DEBUG TRAIN Batch 15/8100 loss 7.904537 loss_att 9.970592 loss_ctc 10.406914 loss_rnnt 7.121312 hw_loss 0.068180 lr 0.00043317 rank 2
2023-02-22 06:41:02,128 DEBUG TRAIN Batch 15/8200 loss 8.146089 loss_att 10.547474 loss_ctc 11.758966 loss_rnnt 7.121810 hw_loss 0.116782 lr 0.00043304 rank 4
2023-02-22 06:41:02,131 DEBUG TRAIN Batch 15/8200 loss 10.370736 loss_att 13.335413 loss_ctc 15.168884 loss_rnnt 9.076317 hw_loss 0.115746 lr 0.00043308 rank 6
2023-02-22 06:41:02,130 DEBUG TRAIN Batch 15/8200 loss 14.024155 loss_att 14.361132 loss_ctc 18.187500 loss_rnnt 13.305258 hw_loss 0.180729 lr 0.00043299 rank 7
2023-02-22 06:41:02,131 DEBUG TRAIN Batch 15/8200 loss 9.292058 loss_att 11.521959 loss_ctc 14.236762 loss_rnnt 8.092992 hw_loss 0.175859 lr 0.00043298 rank 5
2023-02-22 06:41:02,134 DEBUG TRAIN Batch 15/8200 loss 10.686337 loss_att 13.139250 loss_ctc 18.126095 loss_rnnt 9.095896 hw_loss 0.202298 lr 0.00043306 rank 3
2023-02-22 06:41:02,134 DEBUG TRAIN Batch 15/8200 loss 15.512194 loss_att 18.576916 loss_ctc 24.190514 loss_rnnt 13.680370 hw_loss 0.115819 lr 0.00043304 rank 0
2023-02-22 06:41:02,141 DEBUG TRAIN Batch 15/8200 loss 6.196816 loss_att 6.396182 loss_ctc 8.755105 loss_rnnt 5.764728 hw_loss 0.095833 lr 0.00043309 rank 1
2023-02-22 06:41:02,185 DEBUG TRAIN Batch 15/8200 loss 21.890465 loss_att 23.216661 loss_ctc 28.139076 loss_rnnt 20.662148 hw_loss 0.243617 lr 0.00043301 rank 2
2023-02-22 06:42:15,886 DEBUG TRAIN Batch 15/8300 loss 14.905798 loss_att 15.149265 loss_ctc 21.356852 loss_rnnt 13.944846 hw_loss 0.097724 lr 0.00043282 rank 5
2023-02-22 06:42:15,886 DEBUG TRAIN Batch 15/8300 loss 7.419608 loss_att 11.779094 loss_ctc 11.165209 loss_rnnt 5.955882 hw_loss 0.173279 lr 0.00043283 rank 7
2023-02-22 06:42:15,888 DEBUG TRAIN Batch 15/8300 loss 6.269233 loss_att 11.483999 loss_ctc 7.987174 loss_rnnt 4.968493 hw_loss 0.053864 lr 0.00043288 rank 4
2023-02-22 06:42:15,892 DEBUG TRAIN Batch 15/8300 loss 20.845894 loss_att 27.158670 loss_ctc 25.096945 loss_rnnt 18.940159 hw_loss 0.143197 lr 0.00043292 rank 6
2023-02-22 06:42:15,892 DEBUG TRAIN Batch 15/8300 loss 13.819142 loss_att 16.766077 loss_ctc 17.090469 loss_rnnt 12.742142 hw_loss 0.096442 lr 0.00043288 rank 0
2023-02-22 06:42:15,895 DEBUG TRAIN Batch 15/8300 loss 7.480471 loss_att 13.645140 loss_ctc 13.625133 loss_rnnt 5.379935 hw_loss 0.090588 lr 0.00043290 rank 3
2023-02-22 06:42:15,898 DEBUG TRAIN Batch 15/8300 loss 14.949551 loss_att 15.443048 loss_ctc 21.043188 loss_rnnt 13.946686 hw_loss 0.171900 lr 0.00043285 rank 2
2023-02-22 06:42:15,900 DEBUG TRAIN Batch 15/8300 loss 17.985613 loss_att 20.509041 loss_ctc 23.399834 loss_rnnt 16.685127 hw_loss 0.138569 lr 0.00043292 rank 1
2023-02-22 06:43:00,497 DEBUG CV Batch 15/0 loss 2.858852 loss_att 2.851844 loss_ctc 3.879162 loss_rnnt 2.582600 hw_loss 0.265523 history loss 2.752969 rank 5
2023-02-22 06:43:00,499 DEBUG CV Batch 15/0 loss 2.858852 loss_att 2.851844 loss_ctc 3.879162 loss_rnnt 2.582600 hw_loss 0.265523 history loss 2.752969 rank 7
2023-02-22 06:43:00,500 DEBUG CV Batch 15/0 loss 2.858852 loss_att 2.851844 loss_ctc 3.879162 loss_rnnt 2.582600 hw_loss 0.265523 history loss 2.752969 rank 2
2023-02-22 06:43:00,502 DEBUG CV Batch 15/0 loss 2.858852 loss_att 2.851844 loss_ctc 3.879162 loss_rnnt 2.582600 hw_loss 0.265523 history loss 2.752969 rank 4
2023-02-22 06:43:00,505 DEBUG CV Batch 15/0 loss 2.858852 loss_att 2.851844 loss_ctc 3.879162 loss_rnnt 2.582600 hw_loss 0.265523 history loss 2.752969 rank 0
2023-02-22 06:43:00,514 DEBUG CV Batch 15/0 loss 2.858852 loss_att 2.851844 loss_ctc 3.879162 loss_rnnt 2.582600 hw_loss 0.265523 history loss 2.752969 rank 3
2023-02-22 06:43:00,516 DEBUG CV Batch 15/0 loss 2.858852 loss_att 2.851844 loss_ctc 3.879162 loss_rnnt 2.582600 hw_loss 0.265523 history loss 2.752969 rank 1
2023-02-22 06:43:00,524 DEBUG CV Batch 15/0 loss 2.858852 loss_att 2.851844 loss_ctc 3.879162 loss_rnnt 2.582600 hw_loss 0.265523 history loss 2.752969 rank 6
2023-02-22 06:43:11,645 DEBUG CV Batch 15/100 loss 10.333501 loss_att 8.520347 loss_ctc 11.688586 loss_rnnt 10.422649 hw_loss 0.174008 history loss 3.906222 rank 4
2023-02-22 06:43:11,663 DEBUG CV Batch 15/100 loss 10.333501 loss_att 8.520347 loss_ctc 11.688586 loss_rnnt 10.422649 hw_loss 0.174008 history loss 3.906222 rank 0
2023-02-22 06:43:11,670 DEBUG CV Batch 15/100 loss 10.333501 loss_att 8.520347 loss_ctc 11.688586 loss_rnnt 10.422649 hw_loss 0.174008 history loss 3.906222 rank 5
2023-02-22 06:43:11,726 DEBUG CV Batch 15/100 loss 10.333501 loss_att 8.520347 loss_ctc 11.688586 loss_rnnt 10.422649 hw_loss 0.174008 history loss 3.906222 rank 7
2023-02-22 06:43:11,757 DEBUG CV Batch 15/100 loss 10.333501 loss_att 8.520347 loss_ctc 11.688586 loss_rnnt 10.422649 hw_loss 0.174008 history loss 3.906222 rank 6
2023-02-22 06:43:11,806 DEBUG CV Batch 15/100 loss 10.333501 loss_att 8.520347 loss_ctc 11.688586 loss_rnnt 10.422649 hw_loss 0.174008 history loss 3.906222 rank 2
2023-02-22 06:43:11,820 DEBUG CV Batch 15/100 loss 10.333501 loss_att 8.520347 loss_ctc 11.688586 loss_rnnt 10.422649 hw_loss 0.174008 history loss 3.906222 rank 1
2023-02-22 06:43:11,851 DEBUG CV Batch 15/100 loss 10.333501 loss_att 8.520347 loss_ctc 11.688586 loss_rnnt 10.422649 hw_loss 0.174008 history loss 3.906222 rank 3
2023-02-22 06:43:24,998 DEBUG CV Batch 15/200 loss 8.480922 loss_att 15.972776 loss_ctc 8.484308 loss_rnnt 6.898915 hw_loss 0.155972 history loss 4.448864 rank 4
2023-02-22 06:43:25,021 DEBUG CV Batch 15/200 loss 8.480922 loss_att 15.972776 loss_ctc 8.484308 loss_rnnt 6.898915 hw_loss 0.155972 history loss 4.448864 rank 5
2023-02-22 06:43:25,100 DEBUG CV Batch 15/200 loss 8.480922 loss_att 15.972776 loss_ctc 8.484308 loss_rnnt 6.898915 hw_loss 0.155972 history loss 4.448864 rank 7
2023-02-22 06:43:25,100 DEBUG CV Batch 15/200 loss 8.480922 loss_att 15.972776 loss_ctc 8.484308 loss_rnnt 6.898915 hw_loss 0.155972 history loss 4.448864 rank 0
2023-02-22 06:43:25,273 DEBUG CV Batch 15/200 loss 8.480922 loss_att 15.972776 loss_ctc 8.484308 loss_rnnt 6.898915 hw_loss 0.155972 history loss 4.448864 rank 1
2023-02-22 06:43:25,314 DEBUG CV Batch 15/200 loss 8.480922 loss_att 15.972776 loss_ctc 8.484308 loss_rnnt 6.898915 hw_loss 0.155972 history loss 4.448864 rank 2
2023-02-22 06:43:25,337 DEBUG CV Batch 15/200 loss 8.480922 loss_att 15.972776 loss_ctc 8.484308 loss_rnnt 6.898915 hw_loss 0.155972 history loss 4.448864 rank 3
2023-02-22 06:43:25,345 DEBUG CV Batch 15/200 loss 8.480922 loss_att 15.972776 loss_ctc 8.484308 loss_rnnt 6.898915 hw_loss 0.155972 history loss 4.448864 rank 6
2023-02-22 06:43:37,138 DEBUG CV Batch 15/300 loss 5.952950 loss_att 5.398847 loss_ctc 6.379646 loss_rnnt 5.875323 hw_loss 0.246666 history loss 4.636118 rank 5
2023-02-22 06:43:37,185 DEBUG CV Batch 15/300 loss 5.952950 loss_att 5.398847 loss_ctc 6.379646 loss_rnnt 5.875323 hw_loss 0.246666 history loss 4.636118 rank 7
2023-02-22 06:43:37,195 DEBUG CV Batch 15/300 loss 5.952950 loss_att 5.398847 loss_ctc 6.379646 loss_rnnt 5.875323 hw_loss 0.246666 history loss 4.636118 rank 4
2023-02-22 06:43:37,205 DEBUG CV Batch 15/300 loss 5.952950 loss_att 5.398847 loss_ctc 6.379646 loss_rnnt 5.875323 hw_loss 0.246666 history loss 4.636118 rank 0
2023-02-22 06:43:37,347 DEBUG CV Batch 15/300 loss 5.952950 loss_att 5.398847 loss_ctc 6.379646 loss_rnnt 5.875323 hw_loss 0.246666 history loss 4.636118 rank 1
2023-02-22 06:43:37,440 DEBUG CV Batch 15/300 loss 5.952950 loss_att 5.398847 loss_ctc 6.379646 loss_rnnt 5.875323 hw_loss 0.246666 history loss 4.636118 rank 2
2023-02-22 06:43:37,511 DEBUG CV Batch 15/300 loss 5.952950 loss_att 5.398847 loss_ctc 6.379646 loss_rnnt 5.875323 hw_loss 0.246666 history loss 4.636118 rank 6
2023-02-22 06:43:37,548 DEBUG CV Batch 15/300 loss 5.952950 loss_att 5.398847 loss_ctc 6.379646 loss_rnnt 5.875323 hw_loss 0.246666 history loss 4.636118 rank 3
2023-02-22 06:43:49,224 DEBUG CV Batch 15/400 loss 22.625004 loss_att 89.844467 loss_ctc 13.746512 loss_rnnt 10.291034 hw_loss 0.138520 history loss 5.749955 rank 0
2023-02-22 06:43:49,268 DEBUG CV Batch 15/400 loss 22.625004 loss_att 89.844467 loss_ctc 13.746512 loss_rnnt 10.291034 hw_loss 0.138520 history loss 5.749955 rank 5
2023-02-22 06:43:49,300 DEBUG CV Batch 15/400 loss 22.625004 loss_att 89.844467 loss_ctc 13.746512 loss_rnnt 10.291034 hw_loss 0.138520 history loss 5.749955 rank 7
2023-02-22 06:43:49,316 DEBUG CV Batch 15/400 loss 22.625004 loss_att 89.844467 loss_ctc 13.746512 loss_rnnt 10.291034 hw_loss 0.138520 history loss 5.749955 rank 4
2023-02-22 06:43:49,540 DEBUG CV Batch 15/400 loss 22.625004 loss_att 89.844467 loss_ctc 13.746512 loss_rnnt 10.291034 hw_loss 0.138520 history loss 5.749955 rank 1
2023-02-22 06:43:49,748 DEBUG CV Batch 15/400 loss 22.625004 loss_att 89.844467 loss_ctc 13.746512 loss_rnnt 10.291034 hw_loss 0.138520 history loss 5.749955 rank 3
2023-02-22 06:43:50,091 DEBUG CV Batch 15/400 loss 22.625004 loss_att 89.844467 loss_ctc 13.746512 loss_rnnt 10.291034 hw_loss 0.138520 history loss 5.749955 rank 6
2023-02-22 06:43:50,306 DEBUG CV Batch 15/400 loss 22.625004 loss_att 89.844467 loss_ctc 13.746512 loss_rnnt 10.291034 hw_loss 0.138520 history loss 5.749955 rank 2
2023-02-22 06:43:59,664 DEBUG CV Batch 15/500 loss 9.021936 loss_att 9.347901 loss_ctc 10.026031 loss_rnnt 8.741495 hw_loss 0.152567 history loss 6.651422 rank 0
2023-02-22 06:43:59,849 DEBUG CV Batch 15/500 loss 9.021936 loss_att 9.347901 loss_ctc 10.026031 loss_rnnt 8.741495 hw_loss 0.152567 history loss 6.651422 rank 4
2023-02-22 06:43:59,856 DEBUG CV Batch 15/500 loss 9.021936 loss_att 9.347901 loss_ctc 10.026031 loss_rnnt 8.741495 hw_loss 0.152567 history loss 6.651422 rank 7
2023-02-22 06:43:59,933 DEBUG CV Batch 15/500 loss 9.021936 loss_att 9.347901 loss_ctc 10.026031 loss_rnnt 8.741495 hw_loss 0.152567 history loss 6.651422 rank 5
2023-02-22 06:44:00,109 DEBUG CV Batch 15/500 loss 9.021936 loss_att 9.347901 loss_ctc 10.026031 loss_rnnt 8.741495 hw_loss 0.152567 history loss 6.651422 rank 1
2023-02-22 06:44:00,455 DEBUG CV Batch 15/500 loss 9.021936 loss_att 9.347901 loss_ctc 10.026031 loss_rnnt 8.741495 hw_loss 0.152567 history loss 6.651422 rank 3
2023-02-22 06:44:01,021 DEBUG CV Batch 15/500 loss 9.021936 loss_att 9.347901 loss_ctc 10.026031 loss_rnnt 8.741495 hw_loss 0.152567 history loss 6.651422 rank 2
2023-02-22 06:44:01,152 DEBUG CV Batch 15/500 loss 9.021936 loss_att 9.347901 loss_ctc 10.026031 loss_rnnt 8.741495 hw_loss 0.152567 history loss 6.651422 rank 6
2023-02-22 06:44:11,684 DEBUG CV Batch 15/600 loss 7.467187 loss_att 7.751157 loss_ctc 9.928433 loss_rnnt 7.023816 hw_loss 0.109522 history loss 7.641950 rank 0
2023-02-22 06:44:11,929 DEBUG CV Batch 15/600 loss 7.467187 loss_att 7.751157 loss_ctc 9.928433 loss_rnnt 7.023816 hw_loss 0.109522 history loss 7.641950 rank 4
2023-02-22 06:44:11,944 DEBUG CV Batch 15/600 loss 7.467187 loss_att 7.751157 loss_ctc 9.928433 loss_rnnt 7.023816 hw_loss 0.109522 history loss 7.641950 rank 7
2023-02-22 06:44:11,986 DEBUG CV Batch 15/600 loss 7.467187 loss_att 7.751157 loss_ctc 9.928433 loss_rnnt 7.023816 hw_loss 0.109522 history loss 7.641950 rank 5
2023-02-22 06:44:12,202 DEBUG CV Batch 15/600 loss 7.467187 loss_att 7.751157 loss_ctc 9.928433 loss_rnnt 7.023816 hw_loss 0.109522 history loss 7.641950 rank 1
2023-02-22 06:44:12,723 DEBUG CV Batch 15/600 loss 7.467187 loss_att 7.751157 loss_ctc 9.928433 loss_rnnt 7.023816 hw_loss 0.109522 history loss 7.641950 rank 3
2023-02-22 06:44:13,134 DEBUG CV Batch 15/600 loss 7.467187 loss_att 7.751157 loss_ctc 9.928433 loss_rnnt 7.023816 hw_loss 0.109522 history loss 7.641950 rank 2
2023-02-22 06:44:13,942 DEBUG CV Batch 15/600 loss 7.467187 loss_att 7.751157 loss_ctc 9.928433 loss_rnnt 7.023816 hw_loss 0.109522 history loss 7.641950 rank 6
2023-02-22 06:44:23,024 DEBUG CV Batch 15/700 loss 17.688244 loss_att 48.912003 loss_ctc 15.637413 loss_rnnt 11.668322 hw_loss 0.091153 history loss 8.412283 rank 0
2023-02-22 06:44:23,277 DEBUG CV Batch 15/700 loss 17.688244 loss_att 48.912003 loss_ctc 15.637413 loss_rnnt 11.668322 hw_loss 0.091153 history loss 8.412283 rank 4
2023-02-22 06:44:23,340 DEBUG CV Batch 15/700 loss 17.688244 loss_att 48.912003 loss_ctc 15.637413 loss_rnnt 11.668322 hw_loss 0.091153 history loss 8.412283 rank 5
2023-02-22 06:44:23,344 DEBUG CV Batch 15/700 loss 17.688244 loss_att 48.912003 loss_ctc 15.637413 loss_rnnt 11.668322 hw_loss 0.091153 history loss 8.412283 rank 7
2023-02-22 06:44:23,655 DEBUG CV Batch 15/700 loss 17.688244 loss_att 48.912003 loss_ctc 15.637413 loss_rnnt 11.668322 hw_loss 0.091153 history loss 8.412283 rank 1
2023-02-22 06:44:24,263 DEBUG CV Batch 15/700 loss 17.688244 loss_att 48.912003 loss_ctc 15.637413 loss_rnnt 11.668322 hw_loss 0.091153 history loss 8.412283 rank 3
2023-02-22 06:44:24,655 DEBUG CV Batch 15/700 loss 17.688244 loss_att 48.912003 loss_ctc 15.637413 loss_rnnt 11.668322 hw_loss 0.091153 history loss 8.412283 rank 2
2023-02-22 06:44:25,419 DEBUG CV Batch 15/700 loss 17.688244 loss_att 48.912003 loss_ctc 15.637413 loss_rnnt 11.668322 hw_loss 0.091153 history loss 8.412283 rank 6
2023-02-22 06:44:34,151 DEBUG CV Batch 15/800 loss 14.668560 loss_att 11.893495 loss_ctc 18.432861 loss_rnnt 14.636153 hw_loss 0.160336 history loss 7.809421 rank 0
2023-02-22 06:44:34,451 DEBUG CV Batch 15/800 loss 14.668560 loss_att 11.893495 loss_ctc 18.432861 loss_rnnt 14.636153 hw_loss 0.160336 history loss 7.809421 rank 4
2023-02-22 06:44:34,605 DEBUG CV Batch 15/800 loss 14.668560 loss_att 11.893495 loss_ctc 18.432861 loss_rnnt 14.636153 hw_loss 0.160336 history loss 7.809421 rank 7
2023-02-22 06:44:34,611 DEBUG CV Batch 15/800 loss 14.668560 loss_att 11.893495 loss_ctc 18.432861 loss_rnnt 14.636153 hw_loss 0.160336 history loss 7.809421 rank 5
2023-02-22 06:44:34,909 DEBUG CV Batch 15/800 loss 14.668560 loss_att 11.893495 loss_ctc 18.432861 loss_rnnt 14.636153 hw_loss 0.160336 history loss 7.809421 rank 1
2023-02-22 06:44:35,740 DEBUG CV Batch 15/800 loss 14.668560 loss_att 11.893495 loss_ctc 18.432861 loss_rnnt 14.636153 hw_loss 0.160336 history loss 7.809421 rank 3
2023-02-22 06:44:35,999 DEBUG CV Batch 15/800 loss 14.668560 loss_att 11.893495 loss_ctc 18.432861 loss_rnnt 14.636153 hw_loss 0.160336 history loss 7.809421 rank 2
2023-02-22 06:44:36,920 DEBUG CV Batch 15/800 loss 14.668560 loss_att 11.893495 loss_ctc 18.432861 loss_rnnt 14.636153 hw_loss 0.160336 history loss 7.809421 rank 6
2023-02-22 06:44:47,447 DEBUG CV Batch 15/900 loss 14.122050 loss_att 17.238331 loss_ctc 24.514212 loss_rnnt 12.062335 hw_loss 0.095321 history loss 7.561940 rank 0
2023-02-22 06:44:47,697 DEBUG CV Batch 15/900 loss 14.122050 loss_att 17.238331 loss_ctc 24.514212 loss_rnnt 12.062335 hw_loss 0.095321 history loss 7.561940 rank 4
2023-02-22 06:44:48,000 DEBUG CV Batch 15/900 loss 14.122050 loss_att 17.238331 loss_ctc 24.514212 loss_rnnt 12.062335 hw_loss 0.095321 history loss 7.561940 rank 7
2023-02-22 06:44:48,020 DEBUG CV Batch 15/900 loss 14.122050 loss_att 17.238331 loss_ctc 24.514212 loss_rnnt 12.062335 hw_loss 0.095321 history loss 7.561940 rank 5
2023-02-22 06:44:48,338 DEBUG CV Batch 15/900 loss 14.122050 loss_att 17.238331 loss_ctc 24.514212 loss_rnnt 12.062335 hw_loss 0.095321 history loss 7.561940 rank 1
2023-02-22 06:44:49,209 DEBUG CV Batch 15/900 loss 14.122050 loss_att 17.238331 loss_ctc 24.514212 loss_rnnt 12.062335 hw_loss 0.095321 history loss 7.561940 rank 3
2023-02-22 06:44:49,328 DEBUG CV Batch 15/900 loss 14.122050 loss_att 17.238331 loss_ctc 24.514212 loss_rnnt 12.062335 hw_loss 0.095321 history loss 7.561940 rank 2
2023-02-22 06:44:50,416 DEBUG CV Batch 15/900 loss 14.122050 loss_att 17.238331 loss_ctc 24.514212 loss_rnnt 12.062335 hw_loss 0.095321 history loss 7.561940 rank 6
2023-02-22 06:44:59,591 DEBUG CV Batch 15/1000 loss 3.944249 loss_att 4.868443 loss_ctc 4.392566 loss_rnnt 3.613643 hw_loss 0.161235 history loss 7.299278 rank 0
2023-02-22 06:44:59,792 DEBUG CV Batch 15/1000 loss 3.944249 loss_att 4.868443 loss_ctc 4.392566 loss_rnnt 3.613643 hw_loss 0.161235 history loss 7.299278 rank 4
2023-02-22 06:45:00,174 DEBUG CV Batch 15/1000 loss 3.944249 loss_att 4.868443 loss_ctc 4.392566 loss_rnnt 3.613643 hw_loss 0.161235 history loss 7.299278 rank 7
2023-02-22 06:45:00,246 DEBUG CV Batch 15/1000 loss 3.944249 loss_att 4.868443 loss_ctc 4.392566 loss_rnnt 3.613643 hw_loss 0.161235 history loss 7.299278 rank 5
2023-02-22 06:45:00,583 DEBUG CV Batch 15/1000 loss 3.944249 loss_att 4.868443 loss_ctc 4.392566 loss_rnnt 3.613643 hw_loss 0.161235 history loss 7.299278 rank 1
2023-02-22 06:45:01,526 DEBUG CV Batch 15/1000 loss 3.944249 loss_att 4.868443 loss_ctc 4.392566 loss_rnnt 3.613643 hw_loss 0.161235 history loss 7.299278 rank 3
2023-02-22 06:45:01,725 DEBUG CV Batch 15/1000 loss 3.944249 loss_att 4.868443 loss_ctc 4.392566 loss_rnnt 3.613643 hw_loss 0.161235 history loss 7.299278 rank 2
2023-02-22 06:45:02,740 DEBUG CV Batch 15/1000 loss 3.944249 loss_att 4.868443 loss_ctc 4.392566 loss_rnnt 3.613643 hw_loss 0.161235 history loss 7.299278 rank 6
2023-02-22 06:45:11,467 DEBUG CV Batch 15/1100 loss 6.572660 loss_att 5.884123 loss_ctc 8.456665 loss_rnnt 6.291008 hw_loss 0.315300 history loss 7.291521 rank 0
2023-02-22 06:45:11,656 DEBUG CV Batch 15/1100 loss 6.572660 loss_att 5.884123 loss_ctc 8.456665 loss_rnnt 6.291008 hw_loss 0.315300 history loss 7.291521 rank 4
2023-02-22 06:45:12,029 DEBUG CV Batch 15/1100 loss 6.572660 loss_att 5.884123 loss_ctc 8.456665 loss_rnnt 6.291008 hw_loss 0.315300 history loss 7.291521 rank 7
2023-02-22 06:45:12,609 DEBUG CV Batch 15/1100 loss 6.572660 loss_att 5.884123 loss_ctc 8.456665 loss_rnnt 6.291008 hw_loss 0.315300 history loss 7.291521 rank 5
2023-02-22 06:45:13,101 DEBUG CV Batch 15/1100 loss 6.572660 loss_att 5.884123 loss_ctc 8.456665 loss_rnnt 6.291008 hw_loss 0.315300 history loss 7.291521 rank 1
2023-02-22 06:45:13,625 DEBUG CV Batch 15/1100 loss 6.572660 loss_att 5.884123 loss_ctc 8.456665 loss_rnnt 6.291008 hw_loss 0.315300 history loss 7.291521 rank 3
2023-02-22 06:45:13,820 DEBUG CV Batch 15/1100 loss 6.572660 loss_att 5.884123 loss_ctc 8.456665 loss_rnnt 6.291008 hw_loss 0.315300 history loss 7.291521 rank 2
2023-02-22 06:45:14,758 DEBUG CV Batch 15/1100 loss 6.572660 loss_att 5.884123 loss_ctc 8.456665 loss_rnnt 6.291008 hw_loss 0.315300 history loss 7.291521 rank 6
2023-02-22 06:45:22,052 DEBUG CV Batch 15/1200 loss 10.808182 loss_att 11.229378 loss_ctc 11.892464 loss_rnnt 10.446131 hw_loss 0.249826 history loss 7.676563 rank 0
2023-02-22 06:45:22,258 DEBUG CV Batch 15/1200 loss 10.808182 loss_att 11.229378 loss_ctc 11.892464 loss_rnnt 10.446131 hw_loss 0.249826 history loss 7.676563 rank 4
2023-02-22 06:45:22,630 DEBUG CV Batch 15/1200 loss 10.808182 loss_att 11.229378 loss_ctc 11.892464 loss_rnnt 10.446131 hw_loss 0.249826 history loss 7.676563 rank 7
2023-02-22 06:45:23,138 DEBUG CV Batch 15/1200 loss 10.808182 loss_att 11.229378 loss_ctc 11.892464 loss_rnnt 10.446131 hw_loss 0.249826 history loss 7.676563 rank 5
2023-02-22 06:45:23,812 DEBUG CV Batch 15/1200 loss 10.808182 loss_att 11.229378 loss_ctc 11.892464 loss_rnnt 10.446131 hw_loss 0.249826 history loss 7.676563 rank 1
2023-02-22 06:45:24,333 DEBUG CV Batch 15/1200 loss 10.808182 loss_att 11.229378 loss_ctc 11.892464 loss_rnnt 10.446131 hw_loss 0.249826 history loss 7.676563 rank 3
2023-02-22 06:45:24,605 DEBUG CV Batch 15/1200 loss 10.808182 loss_att 11.229378 loss_ctc 11.892464 loss_rnnt 10.446131 hw_loss 0.249826 history loss 7.676563 rank 2
2023-02-22 06:45:25,552 DEBUG CV Batch 15/1200 loss 10.808182 loss_att 11.229378 loss_ctc 11.892464 loss_rnnt 10.446131 hw_loss 0.249826 history loss 7.676563 rank 6
2023-02-22 06:45:34,030 DEBUG CV Batch 15/1300 loss 8.256842 loss_att 7.336230 loss_ctc 9.163586 loss_rnnt 8.197721 hw_loss 0.229395 history loss 7.994952 rank 0
2023-02-22 06:45:34,268 DEBUG CV Batch 15/1300 loss 8.256842 loss_att 7.336230 loss_ctc 9.163586 loss_rnnt 8.197721 hw_loss 0.229395 history loss 7.994952 rank 4
2023-02-22 06:45:34,557 DEBUG CV Batch 15/1300 loss 8.256842 loss_att 7.336230 loss_ctc 9.163586 loss_rnnt 8.197721 hw_loss 0.229395 history loss 7.994952 rank 7
2023-02-22 06:45:35,129 DEBUG CV Batch 15/1300 loss 8.256842 loss_att 7.336230 loss_ctc 9.163586 loss_rnnt 8.197721 hw_loss 0.229395 history loss 7.994952 rank 5
2023-02-22 06:45:35,857 DEBUG CV Batch 15/1300 loss 8.256842 loss_att 7.336230 loss_ctc 9.163586 loss_rnnt 8.197721 hw_loss 0.229395 history loss 7.994952 rank 1
2023-02-22 06:45:36,480 DEBUG CV Batch 15/1300 loss 8.256842 loss_att 7.336230 loss_ctc 9.163586 loss_rnnt 8.197721 hw_loss 0.229395 history loss 7.994952 rank 3
2023-02-22 06:45:36,845 DEBUG CV Batch 15/1300 loss 8.256842 loss_att 7.336230 loss_ctc 9.163586 loss_rnnt 8.197721 hw_loss 0.229395 history loss 7.994952 rank 2
2023-02-22 06:45:37,662 DEBUG CV Batch 15/1300 loss 8.256842 loss_att 7.336230 loss_ctc 9.163586 loss_rnnt 8.197721 hw_loss 0.229395 history loss 7.994952 rank 6
2023-02-22 06:45:45,252 DEBUG CV Batch 15/1400 loss 10.828386 loss_att 30.539982 loss_ctc 7.969599 loss_rnnt 7.243266 hw_loss 0.044949 history loss 8.365930 rank 0
2023-02-22 06:45:45,514 DEBUG CV Batch 15/1400 loss 10.828386 loss_att 30.539982 loss_ctc 7.969599 loss_rnnt 7.243266 hw_loss 0.044949 history loss 8.365930 rank 4
2023-02-22 06:45:45,733 DEBUG CV Batch 15/1400 loss 10.828386 loss_att 30.539982 loss_ctc 7.969599 loss_rnnt 7.243266 hw_loss 0.044949 history loss 8.365930 rank 7
2023-02-22 06:45:46,338 DEBUG CV Batch 15/1400 loss 10.828386 loss_att 30.539982 loss_ctc 7.969599 loss_rnnt 7.243266 hw_loss 0.044949 history loss 8.365930 rank 5
2023-02-22 06:45:47,154 DEBUG CV Batch 15/1400 loss 10.828386 loss_att 30.539982 loss_ctc 7.969599 loss_rnnt 7.243266 hw_loss 0.044949 history loss 8.365930 rank 1
2023-02-22 06:45:47,809 DEBUG CV Batch 15/1400 loss 10.828386 loss_att 30.539982 loss_ctc 7.969599 loss_rnnt 7.243266 hw_loss 0.044949 history loss 8.365930 rank 3
2023-02-22 06:45:48,805 DEBUG CV Batch 15/1400 loss 10.828386 loss_att 30.539982 loss_ctc 7.969599 loss_rnnt 7.243266 hw_loss 0.044949 history loss 8.365930 rank 2
2023-02-22 06:45:49,016 DEBUG CV Batch 15/1400 loss 10.828386 loss_att 30.539982 loss_ctc 7.969599 loss_rnnt 7.243266 hw_loss 0.044949 history loss 8.365930 rank 6
2023-02-22 06:45:56,714 DEBUG CV Batch 15/1500 loss 8.790809 loss_att 8.751166 loss_ctc 10.250716 loss_rnnt 8.501719 hw_loss 0.191933 history loss 8.173465 rank 0
2023-02-22 06:45:56,913 DEBUG CV Batch 15/1500 loss 8.790809 loss_att 8.751166 loss_ctc 10.250716 loss_rnnt 8.501719 hw_loss 0.191933 history loss 8.173465 rank 4
2023-02-22 06:45:57,136 DEBUG CV Batch 15/1500 loss 8.790809 loss_att 8.751166 loss_ctc 10.250716 loss_rnnt 8.501719 hw_loss 0.191933 history loss 8.173465 rank 7
2023-02-22 06:45:57,922 DEBUG CV Batch 15/1500 loss 8.790809 loss_att 8.751166 loss_ctc 10.250716 loss_rnnt 8.501719 hw_loss 0.191933 history loss 8.173465 rank 5
2023-02-22 06:45:59,430 DEBUG CV Batch 15/1500 loss 8.790809 loss_att 8.751166 loss_ctc 10.250716 loss_rnnt 8.501719 hw_loss 0.191933 history loss 8.173465 rank 1
2023-02-22 06:45:59,525 DEBUG CV Batch 15/1500 loss 8.790809 loss_att 8.751166 loss_ctc 10.250716 loss_rnnt 8.501719 hw_loss 0.191933 history loss 8.173465 rank 3
2023-02-22 06:46:00,324 DEBUG CV Batch 15/1500 loss 8.790809 loss_att 8.751166 loss_ctc 10.250716 loss_rnnt 8.501719 hw_loss 0.191933 history loss 8.173465 rank 2
2023-02-22 06:46:00,452 DEBUG CV Batch 15/1500 loss 8.790809 loss_att 8.751166 loss_ctc 10.250716 loss_rnnt 8.501719 hw_loss 0.191933 history loss 8.173465 rank 6
2023-02-22 06:46:09,717 DEBUG CV Batch 15/1600 loss 9.309245 loss_att 16.760647 loss_ctc 11.943771 loss_rnnt 7.384136 hw_loss 0.156672 history loss 8.074959 rank 0
2023-02-22 06:46:09,853 DEBUG CV Batch 15/1600 loss 9.309245 loss_att 16.760647 loss_ctc 11.943771 loss_rnnt 7.384136 hw_loss 0.156672 history loss 8.074959 rank 4
2023-02-22 06:46:10,057 DEBUG CV Batch 15/1600 loss 9.309245 loss_att 16.760647 loss_ctc 11.943771 loss_rnnt 7.384136 hw_loss 0.156672 history loss 8.074959 rank 7
2023-02-22 06:46:11,030 DEBUG CV Batch 15/1600 loss 9.309245 loss_att 16.760647 loss_ctc 11.943771 loss_rnnt 7.384136 hw_loss 0.156672 history loss 8.074959 rank 5
2023-02-22 06:46:12,590 DEBUG CV Batch 15/1600 loss 9.309245 loss_att 16.760647 loss_ctc 11.943771 loss_rnnt 7.384136 hw_loss 0.156672 history loss 8.074959 rank 3
2023-02-22 06:46:13,343 DEBUG CV Batch 15/1600 loss 9.309245 loss_att 16.760647 loss_ctc 11.943771 loss_rnnt 7.384136 hw_loss 0.156672 history loss 8.074959 rank 1
2023-02-22 06:46:13,438 DEBUG CV Batch 15/1600 loss 9.309245 loss_att 16.760647 loss_ctc 11.943771 loss_rnnt 7.384136 hw_loss 0.156672 history loss 8.074959 rank 2
2023-02-22 06:46:13,466 DEBUG CV Batch 15/1600 loss 9.309245 loss_att 16.760647 loss_ctc 11.943771 loss_rnnt 7.384136 hw_loss 0.156672 history loss 8.074959 rank 6
2023-02-22 06:46:22,077 DEBUG CV Batch 15/1700 loss 8.759993 loss_att 9.243831 loss_ctc 13.641769 loss_rnnt 7.931376 hw_loss 0.151772 history loss 7.959759 rank 0
2023-02-22 06:46:22,106 DEBUG CV Batch 15/1700 loss 8.759993 loss_att 9.243831 loss_ctc 13.641769 loss_rnnt 7.931376 hw_loss 0.151772 history loss 7.959759 rank 4
2023-02-22 06:46:22,291 DEBUG CV Batch 15/1700 loss 8.759993 loss_att 9.243831 loss_ctc 13.641769 loss_rnnt 7.931376 hw_loss 0.151772 history loss 7.959759 rank 7
2023-02-22 06:46:23,438 DEBUG CV Batch 15/1700 loss 8.759993 loss_att 9.243831 loss_ctc 13.641769 loss_rnnt 7.931376 hw_loss 0.151772 history loss 7.959759 rank 5
2023-02-22 06:46:25,564 DEBUG CV Batch 15/1700 loss 8.759993 loss_att 9.243831 loss_ctc 13.641769 loss_rnnt 7.931376 hw_loss 0.151772 history loss 7.959759 rank 3
2023-02-22 06:46:25,675 DEBUG CV Batch 15/1700 loss 8.759993 loss_att 9.243831 loss_ctc 13.641769 loss_rnnt 7.931376 hw_loss 0.151772 history loss 7.959759 rank 1
2023-02-22 06:46:25,703 DEBUG CV Batch 15/1700 loss 8.759993 loss_att 9.243831 loss_ctc 13.641769 loss_rnnt 7.931376 hw_loss 0.151772 history loss 7.959759 rank 6
2023-02-22 06:46:25,727 DEBUG CV Batch 15/1700 loss 8.759993 loss_att 9.243831 loss_ctc 13.641769 loss_rnnt 7.931376 hw_loss 0.151772 history loss 7.959759 rank 2
2023-02-22 06:46:31,066 INFO Epoch 15 CV info cv_loss 7.911422474604584
2023-02-22 06:46:31,067 INFO Checkpoint: save to checkpoint exp/2_21_rnnt_bias_loss_2_class_1word_finetune/15.pt
2023-02-22 06:46:31,065 INFO Epoch 15 CV info cv_loss 7.911422473432994
2023-02-22 06:46:31,067 INFO Epoch 16 TRAIN info lr 0.0004328233830665656
2023-02-22 06:46:31,070 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 06:46:31,273 INFO Epoch 15 CV info cv_loss 7.911422474604584
2023-02-22 06:46:31,274 INFO Epoch 16 TRAIN info lr 0.00043279095333714784
2023-02-22 06:46:31,277 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 06:46:32,526 INFO Epoch 16 TRAIN info lr 0.000432836356999696
2023-02-22 06:46:32,530 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 06:46:32,621 INFO Epoch 15 CV info cv_loss 7.911422473932642
2023-02-22 06:46:32,622 INFO Epoch 16 TRAIN info lr 0.00043278284704371234
2023-02-22 06:46:32,624 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 06:46:34,702 INFO Epoch 15 CV info cv_loss 7.911422472795511
2023-02-22 06:46:34,704 INFO Epoch 16 TRAIN info lr 0.0004328801526389711
2023-02-22 06:46:34,709 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 06:46:34,727 INFO Epoch 15 CV info cv_loss 7.911422473312389
2023-02-22 06:46:34,728 INFO Epoch 16 TRAIN info lr 0.00043284771014828337
2023-02-22 06:46:34,731 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 06:46:34,751 INFO Epoch 15 CV info cv_loss 7.911422474156623
2023-02-22 06:46:34,752 INFO Epoch 16 TRAIN info lr 0.00043279581733185837
2023-02-22 06:46:34,755 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 06:46:35,514 INFO Epoch 15 CV info cv_loss 7.911422474725189
2023-02-22 06:46:35,515 INFO Epoch 16 TRAIN info lr 0.00043281203183204316
2023-02-22 06:46:35,519 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 06:47:49,035 DEBUG TRAIN Batch 16/0 loss 9.803267 loss_att 9.186773 loss_ctc 11.708557 loss_rnnt 9.564522 hw_loss 0.202509 lr 0.00043283 rank 0
2023-02-22 06:47:49,035 DEBUG TRAIN Batch 16/0 loss 8.740516 loss_att 7.750145 loss_ctc 10.052354 loss_rnnt 8.648893 hw_loss 0.215224 lr 0.00043279 rank 7
2023-02-22 06:47:49,039 DEBUG TRAIN Batch 16/0 loss 12.851994 loss_att 12.312757 loss_ctc 13.970902 loss_rnnt 12.682224 hw_loss 0.240806 lr 0.00043278 rank 5
2023-02-22 06:47:49,039 DEBUG TRAIN Batch 16/0 loss 10.411828 loss_att 9.285561 loss_ctc 12.515418 loss_rnnt 10.222412 hw_loss 0.251605 lr 0.00043282 rank 4
2023-02-22 06:47:49,054 DEBUG TRAIN Batch 16/0 loss 10.705896 loss_att 10.204155 loss_ctc 15.297255 loss_rnnt 10.086939 hw_loss 0.200858 lr 0.00043281 rank 3
2023-02-22 06:47:49,063 DEBUG TRAIN Batch 16/0 loss 10.661330 loss_att 10.270069 loss_ctc 13.005490 loss_rnnt 10.300512 hw_loss 0.237216 lr 0.00043279 rank 2
2023-02-22 06:47:49,071 DEBUG TRAIN Batch 16/0 loss 11.103025 loss_att 11.031982 loss_ctc 12.732558 loss_rnnt 10.756890 hw_loss 0.268262 lr 0.00043288 rank 1
2023-02-22 06:47:49,079 DEBUG TRAIN Batch 16/0 loss 4.594923 loss_att 5.658128 loss_ctc 7.336814 loss_rnnt 3.907714 hw_loss 0.204342 lr 0.00043285 rank 6
2023-02-22 06:49:04,996 DEBUG TRAIN Batch 16/100 loss 8.129017 loss_att 11.471781 loss_ctc 11.927599 loss_rnnt 6.879470 hw_loss 0.139718 lr 0.00043263 rank 7
2023-02-22 06:49:04,998 DEBUG TRAIN Batch 16/100 loss 9.590322 loss_att 13.103323 loss_ctc 12.938319 loss_rnnt 8.320078 hw_loss 0.227332 lr 0.00043266 rank 4
2023-02-22 06:49:05,003 DEBUG TRAIN Batch 16/100 loss 4.952339 loss_att 9.287656 loss_ctc 8.789991 loss_rnnt 3.478477 hw_loss 0.178332 lr 0.00043272 rank 1
2023-02-22 06:49:05,005 DEBUG TRAIN Batch 16/100 loss 16.064915 loss_att 19.696218 loss_ctc 19.066776 loss_rnnt 14.924426 hw_loss 0.026212 lr 0.00043267 rank 0
2023-02-22 06:49:05,005 DEBUG TRAIN Batch 16/100 loss 8.504100 loss_att 10.949752 loss_ctc 12.636917 loss_rnnt 7.384216 hw_loss 0.149456 lr 0.00043262 rank 5
2023-02-22 06:49:05,009 DEBUG TRAIN Batch 16/100 loss 8.262540 loss_att 10.454078 loss_ctc 12.494148 loss_rnnt 7.195857 hw_loss 0.120302 lr 0.00043263 rank 2
2023-02-22 06:49:05,010 DEBUG TRAIN Batch 16/100 loss 7.450066 loss_att 16.965153 loss_ctc 12.142711 loss_rnnt 4.882536 hw_loss 0.072798 lr 0.00043268 rank 6
2023-02-22 06:49:05,010 DEBUG TRAIN Batch 16/100 loss 10.173182 loss_att 14.821143 loss_ctc 14.397715 loss_rnnt 8.633450 hw_loss 0.087878 lr 0.00043265 rank 3
2023-02-22 06:50:19,310 DEBUG TRAIN Batch 16/200 loss 5.030241 loss_att 8.844886 loss_ctc 7.450859 loss_rnnt 3.914242 hw_loss 0.056853 lr 0.00043247 rank 7
2023-02-22 06:50:19,311 DEBUG TRAIN Batch 16/200 loss 5.852461 loss_att 7.969106 loss_ctc 6.120820 loss_rnnt 5.364952 hw_loss 0.053247 lr 0.00043246 rank 5
2023-02-22 06:50:19,312 DEBUG TRAIN Batch 16/200 loss 5.294129 loss_att 6.883782 loss_ctc 7.109933 loss_rnnt 4.622940 hw_loss 0.208410 lr 0.00043251 rank 0
2023-02-22 06:50:19,314 DEBUG TRAIN Batch 16/200 loss 7.021298 loss_att 10.348683 loss_ctc 11.191195 loss_rnnt 5.718500 hw_loss 0.152503 lr 0.00043252 rank 6
2023-02-22 06:50:19,314 DEBUG TRAIN Batch 16/200 loss 10.826497 loss_att 14.459291 loss_ctc 12.424871 loss_rnnt 9.770278 hw_loss 0.218520 lr 0.00043250 rank 4
2023-02-22 06:50:19,317 DEBUG TRAIN Batch 16/200 loss 9.503043 loss_att 12.636070 loss_ctc 10.147835 loss_rnnt 8.728295 hw_loss 0.116568 lr 0.00043249 rank 3
2023-02-22 06:50:19,319 DEBUG TRAIN Batch 16/200 loss 7.658116 loss_att 11.596071 loss_ctc 12.294258 loss_rnnt 6.178270 hw_loss 0.138944 lr 0.00043247 rank 2
2023-02-22 06:50:19,320 DEBUG TRAIN Batch 16/200 loss 11.591560 loss_att 13.733960 loss_ctc 14.528425 loss_rnnt 10.731140 hw_loss 0.075672 lr 0.00043255 rank 1
2023-02-22 06:51:35,396 DEBUG TRAIN Batch 16/300 loss 8.557481 loss_att 10.656924 loss_ctc 11.711630 loss_rnnt 7.628183 hw_loss 0.166603 lr 0.00043235 rank 0
2023-02-22 06:51:35,398 DEBUG TRAIN Batch 16/300 loss 10.674068 loss_att 13.097565 loss_ctc 17.207182 loss_rnnt 9.299604 hw_loss 0.035032 lr 0.00043230 rank 7
2023-02-22 06:51:35,400 DEBUG TRAIN Batch 16/300 loss 8.111981 loss_att 13.552466 loss_ctc 10.025785 loss_rnnt 6.722484 hw_loss 0.086674 lr 0.00043232 rank 3
2023-02-22 06:51:35,403 DEBUG TRAIN Batch 16/300 loss 13.398161 loss_att 17.072498 loss_ctc 17.597885 loss_rnnt 12.011272 hw_loss 0.172609 lr 0.00043231 rank 2
2023-02-22 06:51:35,404 DEBUG TRAIN Batch 16/300 loss 5.357689 loss_att 9.359842 loss_ctc 6.433699 loss_rnnt 4.268162 hw_loss 0.273051 lr 0.00043234 rank 4
2023-02-22 06:51:35,405 DEBUG TRAIN Batch 16/300 loss 10.101458 loss_att 12.025520 loss_ctc 16.003056 loss_rnnt 8.843339 hw_loss 0.162049 lr 0.00043236 rank 6
2023-02-22 06:51:35,407 DEBUG TRAIN Batch 16/300 loss 20.470083 loss_att 18.697216 loss_ctc 23.750460 loss_rnnt 20.357376 hw_loss 0.056059 lr 0.00043239 rank 1
2023-02-22 06:51:35,407 DEBUG TRAIN Batch 16/300 loss 12.044374 loss_att 14.006469 loss_ctc 16.796474 loss_rnnt 10.958396 hw_loss 0.112401 lr 0.00043230 rank 5
2023-02-22 06:52:51,042 DEBUG TRAIN Batch 16/400 loss 14.816584 loss_att 17.634857 loss_ctc 21.908569 loss_rnnt 13.242517 hw_loss 0.121526 lr 0.00043214 rank 7
2023-02-22 06:52:51,045 DEBUG TRAIN Batch 16/400 loss 8.969817 loss_att 9.944075 loss_ctc 11.081048 loss_rnnt 8.421391 hw_loss 0.135144 lr 0.00043220 rank 6
2023-02-22 06:52:51,046 DEBUG TRAIN Batch 16/400 loss 5.087502 loss_att 9.220274 loss_ctc 6.878524 loss_rnnt 3.958721 hw_loss 0.118919 lr 0.00043213 rank 5
2023-02-22 06:52:51,047 DEBUG TRAIN Batch 16/400 loss 9.096177 loss_att 11.734504 loss_ctc 11.370856 loss_rnnt 8.239178 hw_loss 0.048829 lr 0.00043216 rank 3
2023-02-22 06:52:51,048 DEBUG TRAIN Batch 16/400 loss 11.983197 loss_att 14.727997 loss_ctc 15.084569 loss_rnnt 10.948838 hw_loss 0.134777 lr 0.00043217 rank 4
2023-02-22 06:52:51,050 DEBUG TRAIN Batch 16/400 loss 13.245680 loss_att 15.362508 loss_ctc 17.892630 loss_rnnt 12.147884 hw_loss 0.102818 lr 0.00043219 rank 0
2023-02-22 06:52:51,052 DEBUG TRAIN Batch 16/400 loss 8.487007 loss_att 12.338331 loss_ctc 12.213501 loss_rnnt 7.171870 hw_loss 0.090012 lr 0.00043223 rank 1
2023-02-22 06:52:51,055 DEBUG TRAIN Batch 16/400 loss 8.936769 loss_att 11.658021 loss_ctc 13.903563 loss_rnnt 7.698083 hw_loss 0.060368 lr 0.00043215 rank 2
2023-02-22 06:54:04,948 DEBUG TRAIN Batch 16/500 loss 12.294774 loss_att 16.096310 loss_ctc 15.715670 loss_rnnt 11.039227 hw_loss 0.073349 lr 0.00043201 rank 4
2023-02-22 06:54:04,951 DEBUG TRAIN Batch 16/500 loss 16.929470 loss_att 18.904043 loss_ctc 21.135015 loss_rnnt 15.878741 hw_loss 0.178265 lr 0.00043204 rank 6
2023-02-22 06:54:04,952 DEBUG TRAIN Batch 16/500 loss 13.233733 loss_att 14.446548 loss_ctc 16.721661 loss_rnnt 12.437984 hw_loss 0.165240 lr 0.00043203 rank 0
2023-02-22 06:54:04,953 DEBUG TRAIN Batch 16/500 loss 9.818651 loss_att 13.151876 loss_ctc 13.143009 loss_rnnt 8.678794 hw_loss 0.056183 lr 0.00043197 rank 5
2023-02-22 06:54:04,953 DEBUG TRAIN Batch 16/500 loss 12.602382 loss_att 15.639719 loss_ctc 19.291767 loss_rnnt 10.975496 hw_loss 0.239063 lr 0.00043207 rank 1
2023-02-22 06:54:04,954 DEBUG TRAIN Batch 16/500 loss 12.718837 loss_att 14.489510 loss_ctc 15.972588 loss_rnnt 11.869280 hw_loss 0.115479 lr 0.00043198 rank 7
2023-02-22 06:54:04,957 DEBUG TRAIN Batch 16/500 loss 5.879680 loss_att 9.129327 loss_ctc 7.964700 loss_rnnt 4.903507 hw_loss 0.090451 lr 0.00043200 rank 3
2023-02-22 06:54:04,959 DEBUG TRAIN Batch 16/500 loss 8.180960 loss_att 10.868408 loss_ctc 9.358792 loss_rnnt 7.434132 hw_loss 0.098053 lr 0.00043199 rank 2
2023-02-22 06:55:19,816 DEBUG TRAIN Batch 16/600 loss 10.552265 loss_att 11.969049 loss_ctc 14.065844 loss_rnnt 9.752835 hw_loss 0.089240 lr 0.00043191 rank 1
2023-02-22 06:55:19,819 DEBUG TRAIN Batch 16/600 loss 5.136377 loss_att 7.429669 loss_ctc 6.410233 loss_rnnt 4.439265 hw_loss 0.128636 lr 0.00043186 rank 0
2023-02-22 06:55:19,821 DEBUG TRAIN Batch 16/600 loss 15.091420 loss_att 15.362764 loss_ctc 19.706284 loss_rnnt 14.258295 hw_loss 0.306638 lr 0.00043181 rank 5
2023-02-22 06:55:19,822 DEBUG TRAIN Batch 16/600 loss 5.813916 loss_att 7.330752 loss_ctc 8.763772 loss_rnnt 5.006612 hw_loss 0.207419 lr 0.00043182 rank 7
2023-02-22 06:55:19,824 DEBUG TRAIN Batch 16/600 loss 8.888090 loss_att 10.040186 loss_ctc 11.509293 loss_rnnt 8.153895 hw_loss 0.289279 lr 0.00043188 rank 6
2023-02-22 06:55:19,825 DEBUG TRAIN Batch 16/600 loss 18.290728 loss_att 17.875687 loss_ctc 21.442503 loss_rnnt 17.843134 hw_loss 0.206935 lr 0.00043185 rank 4
2023-02-22 06:55:19,825 DEBUG TRAIN Batch 16/600 loss 9.428695 loss_att 10.604002 loss_ctc 13.536665 loss_rnnt 8.593311 hw_loss 0.098613 lr 0.00043184 rank 3
2023-02-22 06:55:19,826 DEBUG TRAIN Batch 16/600 loss 8.673588 loss_att 10.371297 loss_ctc 11.787241 loss_rnnt 7.810901 hw_loss 0.202485 lr 0.00043182 rank 2
2023-02-22 06:56:37,171 DEBUG TRAIN Batch 16/700 loss 6.776071 loss_att 9.592845 loss_ctc 6.935906 loss_rnnt 6.134630 hw_loss 0.106453 lr 0.00043169 rank 4
2023-02-22 06:56:37,174 DEBUG TRAIN Batch 16/700 loss 3.778388 loss_att 7.333261 loss_ctc 5.147089 loss_rnnt 2.872882 hw_loss 0.022570 lr 0.00043172 rank 6
2023-02-22 06:56:37,175 DEBUG TRAIN Batch 16/700 loss 11.655567 loss_att 14.231966 loss_ctc 14.960594 loss_rnnt 10.624434 hw_loss 0.140967 lr 0.00043166 rank 7
2023-02-22 06:56:37,183 DEBUG TRAIN Batch 16/700 loss 4.630461 loss_att 9.060786 loss_ctc 6.596374 loss_rnnt 3.364301 hw_loss 0.221198 lr 0.00043165 rank 5
2023-02-22 06:56:37,183 DEBUG TRAIN Batch 16/700 loss 14.254953 loss_att 18.264441 loss_ctc 19.447891 loss_rnnt 12.685919 hw_loss 0.140150 lr 0.00043175 rank 1
2023-02-22 06:56:37,184 DEBUG TRAIN Batch 16/700 loss 20.520113 loss_att 24.882095 loss_ctc 29.569878 loss_rnnt 18.400867 hw_loss 0.075399 lr 0.00043166 rank 2
2023-02-22 06:56:37,186 DEBUG TRAIN Batch 16/700 loss 14.584467 loss_att 18.054235 loss_ctc 20.896420 loss_rnnt 12.997097 hw_loss 0.097166 lr 0.00043168 rank 3
2023-02-22 06:56:37,193 DEBUG TRAIN Batch 16/700 loss 7.686309 loss_att 13.628330 loss_ctc 16.559975 loss_rnnt 5.257196 hw_loss 0.107913 lr 0.00043170 rank 0
2023-02-22 06:57:52,585 DEBUG TRAIN Batch 16/800 loss 10.748350 loss_att 13.309425 loss_ctc 11.049098 loss_rnnt 10.172781 hw_loss 0.043601 lr 0.00043154 rank 0
2023-02-22 06:57:52,589 DEBUG TRAIN Batch 16/800 loss 12.207443 loss_att 15.483562 loss_ctc 16.058346 loss_rnnt 11.037646 hw_loss 0.002098 lr 0.00043153 rank 4
2023-02-22 06:57:52,591 DEBUG TRAIN Batch 16/800 loss 8.486147 loss_att 12.804256 loss_ctc 13.561294 loss_rnnt 6.929365 hw_loss 0.030891 lr 0.00043159 rank 1
2023-02-22 06:57:52,593 DEBUG TRAIN Batch 16/800 loss 4.233406 loss_att 6.916634 loss_ctc 4.816886 loss_rnnt 3.579968 hw_loss 0.073115 lr 0.00043150 rank 2
2023-02-22 06:57:52,593 DEBUG TRAIN Batch 16/800 loss 6.130458 loss_att 12.208626 loss_ctc 7.014668 loss_rnnt 4.696074 hw_loss 0.189104 lr 0.00043152 rank 3
2023-02-22 06:57:52,612 DEBUG TRAIN Batch 16/800 loss 10.874410 loss_att 12.612680 loss_ctc 13.704692 loss_rnnt 10.063440 hw_loss 0.161144 lr 0.00043150 rank 7
2023-02-22 06:57:52,625 DEBUG TRAIN Batch 16/800 loss 20.304493 loss_att 21.531471 loss_ctc 38.148872 loss_rnnt 17.586922 hw_loss 0.174232 lr 0.00043149 rank 5
2023-02-22 06:57:52,639 DEBUG TRAIN Batch 16/800 loss 4.822598 loss_att 10.147900 loss_ctc 9.539863 loss_rnnt 3.064790 hw_loss 0.119587 lr 0.00043155 rank 6
2023-02-22 06:59:06,256 DEBUG TRAIN Batch 16/900 loss 5.220138 loss_att 7.768558 loss_ctc 7.995533 loss_rnnt 4.299986 hw_loss 0.075779 lr 0.00043133 rank 5
2023-02-22 06:59:06,261 DEBUG TRAIN Batch 16/900 loss 15.425271 loss_att 18.614819 loss_ctc 24.219427 loss_rnnt 13.590498 hw_loss 0.045581 lr 0.00043134 rank 7
2023-02-22 06:59:06,262 DEBUG TRAIN Batch 16/900 loss 12.651196 loss_att 17.665665 loss_ctc 19.665016 loss_rnnt 10.678148 hw_loss 0.065581 lr 0.00043139 rank 6
2023-02-22 06:59:06,263 DEBUG TRAIN Batch 16/900 loss 11.803766 loss_att 16.326038 loss_ctc 18.318047 loss_rnnt 9.960526 hw_loss 0.131655 lr 0.00043137 rank 4
2023-02-22 06:59:06,265 DEBUG TRAIN Batch 16/900 loss 21.337719 loss_att 24.497738 loss_ctc 31.105249 loss_rnnt 19.359678 hw_loss 0.081933 lr 0.00043138 rank 0
2023-02-22 06:59:06,266 DEBUG TRAIN Batch 16/900 loss 9.116504 loss_att 12.022198 loss_ctc 13.779802 loss_rnnt 7.896030 hw_loss 0.032928 lr 0.00043136 rank 3
2023-02-22 06:59:06,267 DEBUG TRAIN Batch 16/900 loss 5.724181 loss_att 9.026096 loss_ctc 7.338173 loss_rnnt 4.722819 hw_loss 0.235837 lr 0.00043134 rank 2
2023-02-22 06:59:06,267 DEBUG TRAIN Batch 16/900 loss 8.804061 loss_att 12.232734 loss_ctc 10.207284 loss_rnnt 7.857461 hw_loss 0.138316 lr 0.00043143 rank 1
2023-02-22 07:00:21,461 DEBUG TRAIN Batch 16/1000 loss 10.015420 loss_att 12.900800 loss_ctc 11.093424 loss_rnnt 9.214233 hw_loss 0.150707 lr 0.00043122 rank 0
2023-02-22 07:00:21,462 DEBUG TRAIN Batch 16/1000 loss 11.987923 loss_att 17.035387 loss_ctc 20.314617 loss_rnnt 9.835459 hw_loss 0.061396 lr 0.00043121 rank 4
2023-02-22 07:00:21,465 DEBUG TRAIN Batch 16/1000 loss 5.423927 loss_att 8.621826 loss_ctc 8.197113 loss_rnnt 4.267616 hw_loss 0.275575 lr 0.00043127 rank 1
2023-02-22 07:00:21,467 DEBUG TRAIN Batch 16/1000 loss 10.024055 loss_att 11.880399 loss_ctc 13.022852 loss_rnnt 9.204432 hw_loss 0.090968 lr 0.00043118 rank 7
2023-02-22 07:00:21,467 DEBUG TRAIN Batch 16/1000 loss 4.170590 loss_att 7.393540 loss_ctc 5.086570 loss_rnnt 3.345952 hw_loss 0.108596 lr 0.00043118 rank 2
2023-02-22 07:00:21,469 DEBUG TRAIN Batch 16/1000 loss 10.334274 loss_att 13.855761 loss_ctc 15.026963 loss_rnnt 8.894379 hw_loss 0.206074 lr 0.00043117 rank 5
2023-02-22 07:00:21,473 DEBUG TRAIN Batch 16/1000 loss 6.836610 loss_att 10.413887 loss_ctc 12.677453 loss_rnnt 5.340263 hw_loss 0.003960 lr 0.00043120 rank 3
2023-02-22 07:00:21,512 DEBUG TRAIN Batch 16/1000 loss 11.941808 loss_att 14.893236 loss_ctc 19.249557 loss_rnnt 10.300985 hw_loss 0.142819 lr 0.00043123 rank 6
2023-02-22 07:01:38,878 DEBUG TRAIN Batch 16/1100 loss 11.539310 loss_att 15.054333 loss_ctc 18.006290 loss_rnnt 9.852571 hw_loss 0.227756 lr 0.00043110 rank 1
2023-02-22 07:01:38,882 DEBUG TRAIN Batch 16/1100 loss 8.502881 loss_att 10.470711 loss_ctc 8.700670 loss_rnnt 8.028417 hw_loss 0.102235 lr 0.00043101 rank 5
2023-02-22 07:01:38,882 DEBUG TRAIN Batch 16/1100 loss 24.797451 loss_att 27.132931 loss_ctc 38.056252 loss_rnnt 22.495472 hw_loss 0.125702 lr 0.00043105 rank 4
2023-02-22 07:01:38,882 DEBUG TRAIN Batch 16/1100 loss 10.274446 loss_att 14.224310 loss_ctc 15.478584 loss_rnnt 8.696117 hw_loss 0.177136 lr 0.00043104 rank 3
2023-02-22 07:01:38,883 DEBUG TRAIN Batch 16/1100 loss 21.625603 loss_att 22.133718 loss_ctc 30.034451 loss_rnnt 20.271664 hw_loss 0.245874 lr 0.00043107 rank 6
2023-02-22 07:01:38,885 DEBUG TRAIN Batch 16/1100 loss 12.080561 loss_att 15.581406 loss_ctc 18.224562 loss_rnnt 10.483814 hw_loss 0.145083 lr 0.00043106 rank 0
2023-02-22 07:01:38,886 DEBUG TRAIN Batch 16/1100 loss 8.661606 loss_att 10.716459 loss_ctc 11.272270 loss_rnnt 7.843068 hw_loss 0.111522 lr 0.00043102 rank 7
2023-02-22 07:01:38,935 DEBUG TRAIN Batch 16/1100 loss 15.898776 loss_att 21.626879 loss_ctc 24.244362 loss_rnnt 13.584146 hw_loss 0.105493 lr 0.00043102 rank 2
2023-02-22 07:02:53,796 DEBUG TRAIN Batch 16/1200 loss 11.163772 loss_att 13.165492 loss_ctc 13.912986 loss_rnnt 10.297015 hw_loss 0.187220 lr 0.00043089 rank 4
2023-02-22 07:02:53,800 DEBUG TRAIN Batch 16/1200 loss 10.996409 loss_att 11.569220 loss_ctc 12.986350 loss_rnnt 10.519337 hw_loss 0.182223 lr 0.00043086 rank 7
2023-02-22 07:02:53,804 DEBUG TRAIN Batch 16/1200 loss 15.449543 loss_att 17.850517 loss_ctc 20.951054 loss_rnnt 14.162716 hw_loss 0.137058 lr 0.00043094 rank 1
2023-02-22 07:02:53,804 DEBUG TRAIN Batch 16/1200 loss 12.587799 loss_att 15.255627 loss_ctc 17.468271 loss_rnnt 11.369198 hw_loss 0.064322 lr 0.00043090 rank 0
2023-02-22 07:02:53,804 DEBUG TRAIN Batch 16/1200 loss 14.246190 loss_att 16.248989 loss_ctc 20.266273 loss_rnnt 12.995498 hw_loss 0.088978 lr 0.00043091 rank 6
2023-02-22 07:02:53,807 DEBUG TRAIN Batch 16/1200 loss 11.558821 loss_att 13.918449 loss_ctc 16.381315 loss_rnnt 10.309875 hw_loss 0.251291 lr 0.00043085 rank 5
2023-02-22 07:02:53,808 DEBUG TRAIN Batch 16/1200 loss 13.331015 loss_att 14.061156 loss_ctc 16.688362 loss_rnnt 12.608836 hw_loss 0.240944 lr 0.00043088 rank 3
2023-02-22 07:02:53,811 DEBUG TRAIN Batch 16/1200 loss 7.691793 loss_att 11.401254 loss_ctc 12.938097 loss_rnnt 6.147874 hw_loss 0.192224 lr 0.00043086 rank 2
2023-02-22 07:04:09,961 DEBUG TRAIN Batch 16/1300 loss 9.559270 loss_att 13.814269 loss_ctc 10.457071 loss_rnnt 8.568039 hw_loss 0.038483 lr 0.00043070 rank 7
2023-02-22 07:04:09,964 DEBUG TRAIN Batch 16/1300 loss 2.828451 loss_att 3.927550 loss_ctc 2.842215 loss_rnnt 2.569320 hw_loss 0.070267 lr 0.00043069 rank 5
2023-02-22 07:04:09,966 DEBUG TRAIN Batch 16/1300 loss 8.616239 loss_att 11.990494 loss_ctc 11.664282 loss_rnnt 7.479676 hw_loss 0.103699 lr 0.00043073 rank 4
2023-02-22 07:04:09,965 DEBUG TRAIN Batch 16/1300 loss 10.511332 loss_att 12.704641 loss_ctc 18.407478 loss_rnnt 8.930507 hw_loss 0.167519 lr 0.00043074 rank 0
2023-02-22 07:04:09,968 DEBUG TRAIN Batch 16/1300 loss 7.589659 loss_att 11.454423 loss_ctc 10.826541 loss_rnnt 6.323453 hw_loss 0.115628 lr 0.00043075 rank 6
2023-02-22 07:04:09,969 DEBUG TRAIN Batch 16/1300 loss 18.659557 loss_att 24.048603 loss_ctc 24.725002 loss_rnnt 16.685675 hw_loss 0.163778 lr 0.00043072 rank 3
2023-02-22 07:04:09,970 DEBUG TRAIN Batch 16/1300 loss 8.075253 loss_att 8.275602 loss_ctc 9.849532 loss_rnnt 7.647893 hw_loss 0.282601 lr 0.00043070 rank 2
2023-02-22 07:04:10,016 DEBUG TRAIN Batch 16/1300 loss 12.989158 loss_att 15.738487 loss_ctc 20.606670 loss_rnnt 11.322280 hw_loss 0.190020 lr 0.00043078 rank 1
2023-02-22 07:05:27,427 DEBUG TRAIN Batch 16/1400 loss 12.808582 loss_att 16.741697 loss_ctc 17.277201 loss_rnnt 11.366107 hw_loss 0.112567 lr 0.00043056 rank 3
2023-02-22 07:05:27,428 DEBUG TRAIN Batch 16/1400 loss 6.927515 loss_att 9.635779 loss_ctc 6.824899 loss_rnnt 6.297319 hw_loss 0.191671 lr 0.00043054 rank 7
2023-02-22 07:05:27,429 DEBUG TRAIN Batch 16/1400 loss 12.321802 loss_att 15.278460 loss_ctc 15.451282 loss_rnnt 11.259447 hw_loss 0.100798 lr 0.00043058 rank 0
2023-02-22 07:05:27,429 DEBUG TRAIN Batch 16/1400 loss 7.008709 loss_att 9.284614 loss_ctc 8.676132 loss_rnnt 6.274800 hw_loss 0.105759 lr 0.00043053 rank 5
2023-02-22 07:05:27,429 DEBUG TRAIN Batch 16/1400 loss 10.913483 loss_att 15.448689 loss_ctc 13.725716 loss_rnnt 9.580200 hw_loss 0.096141 lr 0.00043057 rank 4
2023-02-22 07:05:27,432 DEBUG TRAIN Batch 16/1400 loss 11.271453 loss_att 14.104035 loss_ctc 13.676941 loss_rnnt 10.334494 hw_loss 0.093207 lr 0.00043063 rank 1
2023-02-22 07:05:27,435 DEBUG TRAIN Batch 16/1400 loss 15.326001 loss_att 18.088932 loss_ctc 24.942337 loss_rnnt 13.486323 hw_loss 0.009212 lr 0.00043054 rank 2
2023-02-22 07:05:27,438 DEBUG TRAIN Batch 16/1400 loss 14.183519 loss_att 18.387932 loss_ctc 16.350834 loss_rnnt 12.949111 hw_loss 0.196033 lr 0.00043059 rank 6
2023-02-22 07:06:43,689 DEBUG TRAIN Batch 16/1500 loss 11.264030 loss_att 15.232345 loss_ctc 17.654440 loss_rnnt 9.478694 hw_loss 0.261783 lr 0.00043037 rank 5
2023-02-22 07:06:43,690 DEBUG TRAIN Batch 16/1500 loss 3.060956 loss_att 7.369113 loss_ctc 4.014670 loss_rnnt 2.071681 hw_loss 0.000905 lr 0.00043041 rank 4
2023-02-22 07:06:43,690 DEBUG TRAIN Batch 16/1500 loss 10.391212 loss_att 10.968701 loss_ctc 16.199450 loss_rnnt 9.434412 hw_loss 0.125379 lr 0.00043042 rank 0
2023-02-22 07:06:43,691 DEBUG TRAIN Batch 16/1500 loss 18.916798 loss_att 20.736620 loss_ctc 25.095329 loss_rnnt 17.611115 hw_loss 0.221091 lr 0.00043038 rank 7
2023-02-22 07:06:43,694 DEBUG TRAIN Batch 16/1500 loss 7.548691 loss_att 13.080370 loss_ctc 13.422114 loss_rnnt 5.636968 hw_loss 0.041745 lr 0.00043043 rank 6
2023-02-22 07:06:43,694 DEBUG TRAIN Batch 16/1500 loss 6.276537 loss_att 7.803681 loss_ctc 7.351365 loss_rnnt 5.746945 hw_loss 0.151600 lr 0.00043047 rank 1
2023-02-22 07:06:43,697 DEBUG TRAIN Batch 16/1500 loss 5.733535 loss_att 8.472805 loss_ctc 8.173429 loss_rnnt 4.820045 hw_loss 0.075594 lr 0.00043038 rank 2
2023-02-22 07:06:43,738 DEBUG TRAIN Batch 16/1500 loss 10.236432 loss_att 12.857333 loss_ctc 15.184728 loss_rnnt 9.009981 hw_loss 0.079681 lr 0.00043040 rank 3
2023-02-22 07:07:58,660 DEBUG TRAIN Batch 16/1600 loss 8.377261 loss_att 11.025629 loss_ctc 10.623217 loss_rnnt 7.425875 hw_loss 0.229220 lr 0.00043022 rank 7
2023-02-22 07:07:58,660 DEBUG TRAIN Batch 16/1600 loss 9.843393 loss_att 13.251471 loss_ctc 13.576383 loss_rnnt 8.562861 hw_loss 0.189722 lr 0.00043025 rank 4
2023-02-22 07:07:58,661 DEBUG TRAIN Batch 16/1600 loss 10.554993 loss_att 11.499504 loss_ctc 17.171089 loss_rnnt 9.437706 hw_loss 0.086696 lr 0.00043021 rank 5
2023-02-22 07:07:58,662 DEBUG TRAIN Batch 16/1600 loss 16.824312 loss_att 18.669849 loss_ctc 19.143711 loss_rnnt 16.073298 hw_loss 0.136222 lr 0.00043031 rank 1
2023-02-22 07:07:58,663 DEBUG TRAIN Batch 16/1600 loss 11.083885 loss_att 14.053139 loss_ctc 13.052084 loss_rnnt 10.165694 hw_loss 0.116089 lr 0.00043026 rank 0
2023-02-22 07:07:58,664 DEBUG TRAIN Batch 16/1600 loss 12.244664 loss_att 13.327942 loss_ctc 13.979145 loss_rnnt 11.749006 hw_loss 0.089510 lr 0.00043022 rank 2
2023-02-22 07:07:58,670 DEBUG TRAIN Batch 16/1600 loss 6.632898 loss_att 10.235926 loss_ctc 10.876019 loss_rnnt 5.283537 hw_loss 0.118135 lr 0.00043024 rank 3
2023-02-22 07:07:58,711 DEBUG TRAIN Batch 16/1600 loss 7.039586 loss_att 10.687539 loss_ctc 9.774988 loss_rnnt 5.903978 hw_loss 0.077431 lr 0.00043027 rank 6
2023-02-22 07:09:14,590 DEBUG TRAIN Batch 16/1700 loss 7.645482 loss_att 12.170118 loss_ctc 11.223379 loss_rnnt 6.170460 hw_loss 0.174454 lr 0.00043015 rank 1
2023-02-22 07:09:14,590 DEBUG TRAIN Batch 16/1700 loss 9.117716 loss_att 14.026875 loss_ctc 14.053230 loss_rnnt 7.388947 hw_loss 0.166628 lr 0.00043010 rank 0
2023-02-22 07:09:14,592 DEBUG TRAIN Batch 16/1700 loss 6.726679 loss_att 9.182421 loss_ctc 7.873928 loss_rnnt 6.058380 hw_loss 0.045345 lr 0.00043006 rank 7
2023-02-22 07:09:14,593 DEBUG TRAIN Batch 16/1700 loss 12.921531 loss_att 17.175632 loss_ctc 19.064499 loss_rnnt 11.161165 hw_loss 0.169651 lr 0.00043005 rank 5
2023-02-22 07:09:14,596 DEBUG TRAIN Batch 16/1700 loss 6.901764 loss_att 9.231787 loss_ctc 8.326864 loss_rnnt 6.146502 hw_loss 0.186082 lr 0.00043011 rank 6
2023-02-22 07:09:14,596 DEBUG TRAIN Batch 16/1700 loss 13.572554 loss_att 19.020189 loss_ctc 18.205376 loss_rnnt 11.830954 hw_loss 0.064433 lr 0.00043009 rank 4
2023-02-22 07:09:14,601 DEBUG TRAIN Batch 16/1700 loss 11.843396 loss_att 13.662291 loss_ctc 13.526318 loss_rnnt 11.217440 hw_loss 0.070850 lr 0.00043006 rank 2
2023-02-22 07:09:14,638 DEBUG TRAIN Batch 16/1700 loss 16.912556 loss_att 17.658991 loss_ctc 18.565935 loss_rnnt 16.450041 hw_loss 0.173958 lr 0.00043008 rank 3
2023-02-22 07:10:32,936 DEBUG TRAIN Batch 16/1800 loss 11.619637 loss_att 14.205503 loss_ctc 16.988600 loss_rnnt 10.314694 hw_loss 0.134828 lr 0.00042989 rank 5
2023-02-22 07:10:32,936 DEBUG TRAIN Batch 16/1800 loss 13.075124 loss_att 16.310778 loss_ctc 18.149450 loss_rnnt 11.698791 hw_loss 0.098675 lr 0.00042994 rank 0
2023-02-22 07:10:32,936 DEBUG TRAIN Batch 16/1800 loss 7.685329 loss_att 10.298192 loss_ctc 9.705998 loss_rnnt 6.848794 hw_loss 0.083512 lr 0.00042990 rank 7
2023-02-22 07:10:32,938 DEBUG TRAIN Batch 16/1800 loss 16.280064 loss_att 18.800362 loss_ctc 23.365711 loss_rnnt 14.772943 hw_loss 0.109324 lr 0.00042993 rank 4
2023-02-22 07:10:32,941 DEBUG TRAIN Batch 16/1800 loss 17.878742 loss_att 17.862492 loss_ctc 23.074108 loss_rnnt 17.078663 hw_loss 0.207399 lr 0.00042999 rank 1
2023-02-22 07:10:32,942 DEBUG TRAIN Batch 16/1800 loss 4.633214 loss_att 6.507112 loss_ctc 6.299318 loss_rnnt 3.921727 hw_loss 0.214802 lr 0.00042996 rank 6
2023-02-22 07:10:32,945 DEBUG TRAIN Batch 16/1800 loss 6.161800 loss_att 8.526447 loss_ctc 10.552589 loss_rnnt 5.068727 hw_loss 0.065073 lr 0.00042992 rank 3
2023-02-22 07:10:32,946 DEBUG TRAIN Batch 16/1800 loss 25.383783 loss_att 28.223743 loss_ctc 32.890755 loss_rnnt 23.688179 hw_loss 0.237525 lr 0.00042990 rank 2
2023-02-22 07:11:48,984 DEBUG TRAIN Batch 16/1900 loss 3.758717 loss_att 8.179608 loss_ctc 3.925463 loss_rnnt 2.771909 hw_loss 0.150745 lr 0.00042979 rank 0
2023-02-22 07:11:48,986 DEBUG TRAIN Batch 16/1900 loss 12.356102 loss_att 13.845670 loss_ctc 13.749464 loss_rnnt 11.871699 hw_loss 0.001327 lr 0.00042974 rank 7
2023-02-22 07:11:48,990 DEBUG TRAIN Batch 16/1900 loss 7.809559 loss_att 8.342736 loss_ctc 11.016388 loss_rnnt 7.183537 hw_loss 0.172143 lr 0.00042977 rank 4
2023-02-22 07:11:48,989 DEBUG TRAIN Batch 16/1900 loss 8.640523 loss_att 14.723911 loss_ctc 7.809727 loss_rnnt 7.523334 hw_loss 0.021158 lr 0.00042973 rank 5
2023-02-22 07:11:48,994 DEBUG TRAIN Batch 16/1900 loss 16.590910 loss_att 20.309292 loss_ctc 20.721504 loss_rnnt 15.244741 hw_loss 0.097026 lr 0.00042983 rank 1
2023-02-22 07:11:48,995 DEBUG TRAIN Batch 16/1900 loss 6.573139 loss_att 10.050599 loss_ctc 7.296372 loss_rnnt 5.655713 hw_loss 0.235318 lr 0.00042980 rank 6
2023-02-22 07:11:48,995 DEBUG TRAIN Batch 16/1900 loss 7.198594 loss_att 9.135999 loss_ctc 10.518179 loss_rnnt 6.250204 hw_loss 0.221807 lr 0.00042976 rank 3
2023-02-22 07:11:48,997 DEBUG TRAIN Batch 16/1900 loss 11.218646 loss_att 11.654156 loss_ctc 12.684041 loss_rnnt 10.821189 hw_loss 0.215569 lr 0.00042975 rank 2
2023-02-22 07:13:04,505 DEBUG TRAIN Batch 16/2000 loss 12.827810 loss_att 16.975376 loss_ctc 20.323536 loss_rnnt 10.966139 hw_loss 0.061367 lr 0.00042963 rank 0
2023-02-22 07:13:04,505 DEBUG TRAIN Batch 16/2000 loss 9.937292 loss_att 14.893480 loss_ctc 12.493294 loss_rnnt 8.507927 hw_loss 0.182488 lr 0.00042961 rank 4
2023-02-22 07:13:04,506 DEBUG TRAIN Batch 16/2000 loss 12.292642 loss_att 17.824234 loss_ctc 16.486401 loss_rnnt 10.570337 hw_loss 0.106534 lr 0.00042957 rank 5
2023-02-22 07:13:04,509 DEBUG TRAIN Batch 16/2000 loss 17.990736 loss_att 21.907869 loss_ctc 28.534828 loss_rnnt 15.787939 hw_loss 0.025298 lr 0.00042960 rank 3
2023-02-22 07:13:04,511 DEBUG TRAIN Batch 16/2000 loss 7.241815 loss_att 16.568691 loss_ctc 13.867050 loss_rnnt 4.442569 hw_loss 0.094698 lr 0.00042967 rank 1
2023-02-22 07:13:04,515 DEBUG TRAIN Batch 16/2000 loss 4.264683 loss_att 7.439015 loss_ctc 7.579439 loss_rnnt 3.141049 hw_loss 0.087751 lr 0.00042958 rank 7
2023-02-22 07:13:04,516 DEBUG TRAIN Batch 16/2000 loss 12.469540 loss_att 17.101231 loss_ctc 15.612475 loss_rnnt 11.031061 hw_loss 0.174527 lr 0.00042964 rank 6
2023-02-22 07:13:04,562 DEBUG TRAIN Batch 16/2000 loss 3.730932 loss_att 5.836241 loss_ctc 2.998329 loss_rnnt 3.354576 hw_loss 0.099328 lr 0.00042959 rank 2
2023-02-22 07:14:22,075 DEBUG TRAIN Batch 16/2100 loss 13.434054 loss_att 19.101994 loss_ctc 20.867762 loss_rnnt 11.283294 hw_loss 0.048774 lr 0.00042951 rank 1
2023-02-22 07:14:22,077 DEBUG TRAIN Batch 16/2100 loss 3.193957 loss_att 5.406421 loss_ctc 5.811775 loss_rnnt 2.348859 hw_loss 0.100429 lr 0.00042947 rank 0
2023-02-22 07:14:22,078 DEBUG TRAIN Batch 16/2100 loss 10.552242 loss_att 11.740425 loss_ctc 13.893402 loss_rnnt 9.863609 hw_loss 0.010329 lr 0.00042942 rank 5
2023-02-22 07:14:22,080 DEBUG TRAIN Batch 16/2100 loss 6.151724 loss_att 8.058535 loss_ctc 9.644169 loss_rnnt 5.259602 hw_loss 0.084565 lr 0.00042944 rank 3
2023-02-22 07:14:22,082 DEBUG TRAIN Batch 16/2100 loss 9.384227 loss_att 14.055058 loss_ctc 16.685089 loss_rnnt 7.404510 hw_loss 0.135189 lr 0.00042948 rank 6
2023-02-22 07:14:22,084 DEBUG TRAIN Batch 16/2100 loss 10.356174 loss_att 17.399012 loss_ctc 14.886160 loss_rnnt 8.305824 hw_loss 0.070845 lr 0.00042943 rank 2
2023-02-22 07:14:22,100 DEBUG TRAIN Batch 16/2100 loss 3.447749 loss_att 6.630955 loss_ctc 4.423622 loss_rnnt 2.636680 hw_loss 0.083083 lr 0.00042946 rank 4
2023-02-22 07:14:22,108 DEBUG TRAIN Batch 16/2100 loss 24.035093 loss_att 27.645962 loss_ctc 35.803810 loss_rnnt 21.695755 hw_loss 0.090002 lr 0.00042942 rank 7
2023-02-22 07:15:39,100 DEBUG TRAIN Batch 16/2200 loss 12.182876 loss_att 15.643257 loss_ctc 15.814853 loss_rnnt 10.880346 hw_loss 0.236603 lr 0.00042930 rank 4
2023-02-22 07:15:39,105 DEBUG TRAIN Batch 16/2200 loss 8.829520 loss_att 10.931015 loss_ctc 11.561975 loss_rnnt 7.994895 hw_loss 0.093748 lr 0.00042926 rank 5
2023-02-22 07:15:39,107 DEBUG TRAIN Batch 16/2200 loss 11.065038 loss_att 13.515544 loss_ctc 18.838375 loss_rnnt 9.467286 hw_loss 0.133510 lr 0.00042935 rank 1
2023-02-22 07:15:39,107 DEBUG TRAIN Batch 16/2200 loss 10.601682 loss_att 13.422260 loss_ctc 14.703499 loss_rnnt 9.409481 hw_loss 0.152205 lr 0.00042929 rank 3
2023-02-22 07:15:39,108 DEBUG TRAIN Batch 16/2200 loss 13.462327 loss_att 15.959249 loss_ctc 19.250025 loss_rnnt 12.152036 hw_loss 0.073526 lr 0.00042927 rank 7
2023-02-22 07:15:39,109 DEBUG TRAIN Batch 16/2200 loss 6.188148 loss_att 8.006692 loss_ctc 7.305645 loss_rnnt 5.667704 hw_loss 0.014506 lr 0.00042931 rank 0
2023-02-22 07:15:39,110 DEBUG TRAIN Batch 16/2200 loss 15.879490 loss_att 17.452028 loss_ctc 20.991272 loss_rnnt 14.873875 hw_loss 0.017880 lr 0.00042932 rank 6
2023-02-22 07:15:39,155 DEBUG TRAIN Batch 16/2200 loss 16.797773 loss_att 16.676922 loss_ctc 16.913853 loss_rnnt 16.728720 hw_loss 0.145776 lr 0.00042927 rank 2
2023-02-22 07:16:53,048 DEBUG TRAIN Batch 16/2300 loss 4.052112 loss_att 6.670793 loss_ctc 5.064076 loss_rnnt 3.239027 hw_loss 0.289538 lr 0.00042911 rank 7
2023-02-22 07:16:53,052 DEBUG TRAIN Batch 16/2300 loss 21.116028 loss_att 22.204052 loss_ctc 27.931147 loss_rnnt 19.914433 hw_loss 0.141202 lr 0.00042910 rank 5
2023-02-22 07:16:53,056 DEBUG TRAIN Batch 16/2300 loss 14.361993 loss_att 17.504866 loss_ctc 19.070354 loss_rnnt 13.002440 hw_loss 0.193494 lr 0.00042915 rank 0
2023-02-22 07:16:53,058 DEBUG TRAIN Batch 16/2300 loss 13.808908 loss_att 16.965092 loss_ctc 18.058064 loss_rnnt 12.535300 hw_loss 0.142156 lr 0.00042911 rank 2
2023-02-22 07:16:53,059 DEBUG TRAIN Batch 16/2300 loss 8.983610 loss_att 13.860456 loss_ctc 19.005779 loss_rnnt 6.659524 hw_loss 0.023300 lr 0.00042916 rank 6
2023-02-22 07:16:53,059 DEBUG TRAIN Batch 16/2300 loss 11.282862 loss_att 15.550678 loss_ctc 16.094561 loss_rnnt 9.722708 hw_loss 0.121931 lr 0.00042914 rank 4
2023-02-22 07:16:53,064 DEBUG TRAIN Batch 16/2300 loss 13.735058 loss_att 17.401283 loss_ctc 20.712858 loss_rnnt 12.011518 hw_loss 0.112352 lr 0.00042919 rank 1
2023-02-22 07:16:53,110 DEBUG TRAIN Batch 16/2300 loss 12.536942 loss_att 16.813267 loss_ctc 16.846073 loss_rnnt 11.043555 hw_loss 0.119197 lr 0.00042913 rank 3
2023-02-22 07:18:09,997 DEBUG TRAIN Batch 16/2400 loss 19.012119 loss_att 19.195475 loss_ctc 24.888426 loss_rnnt 18.112236 hw_loss 0.149447 lr 0.00042904 rank 1
2023-02-22 07:18:09,997 DEBUG TRAIN Batch 16/2400 loss 14.276633 loss_att 14.628799 loss_ctc 17.070480 loss_rnnt 13.799979 hw_loss 0.063203 lr 0.00042894 rank 5
2023-02-22 07:18:09,999 DEBUG TRAIN Batch 16/2400 loss 8.940328 loss_att 10.557269 loss_ctc 9.471601 loss_rnnt 8.412692 hw_loss 0.250146 lr 0.00042898 rank 4
2023-02-22 07:18:10,000 DEBUG TRAIN Batch 16/2400 loss 8.255486 loss_att 10.521026 loss_ctc 10.090276 loss_rnnt 7.448674 hw_loss 0.204498 lr 0.00042895 rank 7
2023-02-22 07:18:10,002 DEBUG TRAIN Batch 16/2400 loss 14.488414 loss_att 15.304106 loss_ctc 19.459118 loss_rnnt 13.551773 hw_loss 0.207641 lr 0.00042897 rank 3
2023-02-22 07:18:10,001 DEBUG TRAIN Batch 16/2400 loss 23.688440 loss_att 24.627714 loss_ctc 32.772968 loss_rnnt 22.214302 hw_loss 0.140654 lr 0.00042899 rank 0
2023-02-22 07:18:10,019 DEBUG TRAIN Batch 16/2400 loss 5.150716 loss_att 6.680863 loss_ctc 5.635355 loss_rnnt 4.684687 hw_loss 0.178839 lr 0.00042901 rank 6
2023-02-22 07:18:10,050 DEBUG TRAIN Batch 16/2400 loss 7.303263 loss_att 8.431340 loss_ctc 12.279385 loss_rnnt 6.336452 hw_loss 0.145709 lr 0.00042895 rank 2
2023-02-22 07:19:28,845 DEBUG TRAIN Batch 16/2500 loss 7.843429 loss_att 7.754822 loss_ctc 11.427139 loss_rnnt 7.289686 hw_loss 0.175567 lr 0.00042884 rank 0
2023-02-22 07:19:28,852 DEBUG TRAIN Batch 16/2500 loss 9.635333 loss_att 11.184776 loss_ctc 12.327771 loss_rnnt 8.893919 hw_loss 0.136001 lr 0.00042879 rank 7
2023-02-22 07:19:28,856 DEBUG TRAIN Batch 16/2500 loss 12.830631 loss_att 12.083881 loss_ctc 15.910091 loss_rnnt 12.465296 hw_loss 0.195169 lr 0.00042882 rank 4
2023-02-22 07:19:28,859 DEBUG TRAIN Batch 16/2500 loss 10.007053 loss_att 10.831431 loss_ctc 11.553396 loss_rnnt 9.600369 hw_loss 0.066804 lr 0.00042888 rank 1
2023-02-22 07:19:28,859 DEBUG TRAIN Batch 16/2500 loss 4.705451 loss_att 4.718316 loss_ctc 6.039551 loss_rnnt 4.394602 hw_loss 0.244492 lr 0.00042885 rank 6
2023-02-22 07:19:28,862 DEBUG TRAIN Batch 16/2500 loss 10.691371 loss_att 11.762091 loss_ctc 14.947937 loss_rnnt 9.789169 hw_loss 0.225967 lr 0.00042881 rank 3
2023-02-22 07:19:28,864 DEBUG TRAIN Batch 16/2500 loss 16.920563 loss_att 17.184742 loss_ctc 24.577902 loss_rnnt 15.705156 hw_loss 0.265484 lr 0.00042880 rank 2
2023-02-22 07:19:28,878 DEBUG TRAIN Batch 16/2500 loss 16.785505 loss_att 17.633440 loss_ctc 23.346252 loss_rnnt 15.668848 hw_loss 0.135570 lr 0.00042878 rank 5
2023-02-22 07:20:43,574 DEBUG TRAIN Batch 16/2600 loss 12.734898 loss_att 16.742661 loss_ctc 13.645904 loss_rnnt 11.750181 hw_loss 0.115680 lr 0.00042868 rank 0
2023-02-22 07:20:43,575 DEBUG TRAIN Batch 16/2600 loss 15.729495 loss_att 21.873352 loss_ctc 25.081757 loss_rnnt 13.132605 hw_loss 0.227159 lr 0.00042867 rank 4
2023-02-22 07:20:43,576 DEBUG TRAIN Batch 16/2600 loss 8.313482 loss_att 10.606773 loss_ctc 14.199860 loss_rnnt 7.020624 hw_loss 0.092532 lr 0.00042863 rank 5
2023-02-22 07:20:43,577 DEBUG TRAIN Batch 16/2600 loss 9.939159 loss_att 15.258399 loss_ctc 15.793838 loss_rnnt 8.074216 hw_loss 0.038383 lr 0.00042863 rank 7
2023-02-22 07:20:43,578 DEBUG TRAIN Batch 16/2600 loss 17.397345 loss_att 22.512888 loss_ctc 21.867191 loss_rnnt 15.692249 hw_loss 0.161263 lr 0.00042869 rank 6
2023-02-22 07:20:43,580 DEBUG TRAIN Batch 16/2600 loss 7.303444 loss_att 9.746443 loss_ctc 10.338474 loss_rnnt 6.350774 hw_loss 0.111375 lr 0.00042872 rank 1
2023-02-22 07:20:43,582 DEBUG TRAIN Batch 16/2600 loss 2.394747 loss_att 8.135336 loss_ctc 1.467174 loss_rnnt 1.305610 hw_loss 0.121305 lr 0.00042866 rank 3
2023-02-22 07:20:43,620 DEBUG TRAIN Batch 16/2600 loss 7.585572 loss_att 9.958900 loss_ctc 8.084606 loss_rnnt 7.002998 hw_loss 0.077570 lr 0.00042864 rank 2
2023-02-22 07:21:57,607 DEBUG TRAIN Batch 16/2700 loss 9.480922 loss_att 11.962415 loss_ctc 12.422156 loss_rnnt 8.439854 hw_loss 0.286133 lr 0.00042852 rank 0
2023-02-22 07:21:57,609 DEBUG TRAIN Batch 16/2700 loss 6.408983 loss_att 10.462670 loss_ctc 7.149333 loss_rnnt 5.478104 hw_loss 0.040179 lr 0.00042848 rank 7
2023-02-22 07:21:57,611 DEBUG TRAIN Batch 16/2700 loss 11.076027 loss_att 12.642937 loss_ctc 16.891026 loss_rnnt 9.924326 hw_loss 0.118099 lr 0.00042856 rank 1
2023-02-22 07:21:57,611 DEBUG TRAIN Batch 16/2700 loss 12.729450 loss_att 15.095718 loss_ctc 16.162136 loss_rnnt 11.768333 hw_loss 0.056572 lr 0.00042853 rank 6
2023-02-22 07:21:57,613 DEBUG TRAIN Batch 16/2700 loss 14.200481 loss_att 21.052471 loss_ctc 17.311108 loss_rnnt 12.415310 hw_loss 0.000043 lr 0.00042851 rank 4
2023-02-22 07:21:57,617 DEBUG TRAIN Batch 16/2700 loss 22.198256 loss_att 28.140829 loss_ctc 30.942055 loss_rnnt 19.775627 hw_loss 0.128011 lr 0.00042847 rank 5
2023-02-22 07:21:57,618 DEBUG TRAIN Batch 16/2700 loss 6.286098 loss_att 9.303846 loss_ctc 8.628103 loss_rnnt 5.321036 hw_loss 0.092334 lr 0.00042848 rank 2
2023-02-22 07:21:57,622 DEBUG TRAIN Batch 16/2700 loss 17.168112 loss_att 21.967457 loss_ctc 22.041260 loss_rnnt 15.558467 hw_loss 0.000043 lr 0.00042850 rank 3
2023-02-22 07:23:14,789 DEBUG TRAIN Batch 16/2800 loss 8.278827 loss_att 12.055809 loss_ctc 14.312117 loss_rnnt 6.607208 hw_loss 0.209594 lr 0.00042835 rank 4
2023-02-22 07:23:14,790 DEBUG TRAIN Batch 16/2800 loss 21.690992 loss_att 25.566658 loss_ctc 29.084026 loss_rnnt 19.823906 hw_loss 0.199151 lr 0.00042836 rank 0
2023-02-22 07:23:14,792 DEBUG TRAIN Batch 16/2800 loss 15.565342 loss_att 17.976866 loss_ctc 18.532280 loss_rnnt 14.603161 hw_loss 0.158034 lr 0.00042831 rank 5
2023-02-22 07:23:14,797 DEBUG TRAIN Batch 16/2800 loss 4.547279 loss_att 10.091258 loss_ctc 6.912047 loss_rnnt 3.041687 hw_loss 0.152801 lr 0.00042832 rank 7
2023-02-22 07:23:14,797 DEBUG TRAIN Batch 16/2800 loss 5.926436 loss_att 8.234649 loss_ctc 7.772678 loss_rnnt 5.188423 hw_loss 0.056633 lr 0.00042832 rank 2
2023-02-22 07:23:14,801 DEBUG TRAIN Batch 16/2800 loss 13.948909 loss_att 17.919449 loss_ctc 19.728943 loss_rnnt 12.315210 hw_loss 0.129222 lr 0.00042837 rank 6
2023-02-22 07:23:14,803 DEBUG TRAIN Batch 16/2800 loss 10.312307 loss_att 13.698565 loss_ctc 13.544334 loss_rnnt 9.142711 hw_loss 0.115142 lr 0.00042841 rank 1
2023-02-22 07:23:14,814 DEBUG TRAIN Batch 16/2800 loss 5.840604 loss_att 9.369503 loss_ctc 8.950562 loss_rnnt 4.636817 hw_loss 0.156275 lr 0.00042834 rank 3
2023-02-22 07:24:31,828 DEBUG TRAIN Batch 16/2900 loss 13.604131 loss_att 16.015617 loss_ctc 18.395464 loss_rnnt 12.451344 hw_loss 0.059334 lr 0.00042821 rank 0
2023-02-22 07:24:31,830 DEBUG TRAIN Batch 16/2900 loss 15.036613 loss_att 19.530378 loss_ctc 20.363890 loss_rnnt 13.420695 hw_loss 0.012864 lr 0.00042816 rank 7
2023-02-22 07:24:31,835 DEBUG TRAIN Batch 16/2900 loss 6.655533 loss_att 6.792587 loss_ctc 7.223975 loss_rnnt 6.500972 hw_loss 0.096297 lr 0.00042822 rank 6
2023-02-22 07:24:31,835 DEBUG TRAIN Batch 16/2900 loss 8.610094 loss_att 9.645038 loss_ctc 8.978850 loss_rnnt 8.300527 hw_loss 0.100145 lr 0.00042816 rank 5
2023-02-22 07:24:31,842 DEBUG TRAIN Batch 16/2900 loss 12.444241 loss_att 14.566063 loss_ctc 18.925110 loss_rnnt 11.118144 hw_loss 0.070528 lr 0.00042819 rank 4
2023-02-22 07:24:31,842 DEBUG TRAIN Batch 16/2900 loss 11.849919 loss_att 13.271611 loss_ctc 16.638411 loss_rnnt 10.834512 hw_loss 0.173631 lr 0.00042818 rank 3
2023-02-22 07:24:31,842 DEBUG TRAIN Batch 16/2900 loss 10.139077 loss_att 12.754946 loss_ctc 14.244954 loss_rnnt 9.023839 hw_loss 0.083650 lr 0.00042817 rank 2
2023-02-22 07:24:31,884 DEBUG TRAIN Batch 16/2900 loss 12.068621 loss_att 16.428795 loss_ctc 18.549803 loss_rnnt 10.266768 hw_loss 0.123113 lr 0.00042825 rank 1
2023-02-22 07:25:46,885 DEBUG TRAIN Batch 16/3000 loss 10.927107 loss_att 14.705961 loss_ctc 13.875574 loss_rnnt 9.696465 hw_loss 0.153266 lr 0.00042800 rank 5
2023-02-22 07:25:46,885 DEBUG TRAIN Batch 16/3000 loss 18.567652 loss_att 24.778950 loss_ctc 25.732258 loss_rnnt 16.327019 hw_loss 0.080801 lr 0.00042805 rank 0
2023-02-22 07:25:46,885 DEBUG TRAIN Batch 16/3000 loss 14.127934 loss_att 18.777628 loss_ctc 16.988607 loss_rnnt 12.730951 hw_loss 0.160539 lr 0.00042801 rank 7
2023-02-22 07:25:46,886 DEBUG TRAIN Batch 16/3000 loss 12.067651 loss_att 14.454958 loss_ctc 15.896888 loss_rnnt 11.048292 hw_loss 0.058748 lr 0.00042804 rank 4
2023-02-22 07:25:46,891 DEBUG TRAIN Batch 16/3000 loss 13.299314 loss_att 14.664826 loss_ctc 16.420969 loss_rnnt 12.547726 hw_loss 0.116748 lr 0.00042809 rank 1
2023-02-22 07:25:46,894 DEBUG TRAIN Batch 16/3000 loss 21.664049 loss_att 22.378414 loss_ctc 29.967142 loss_rnnt 20.314016 hw_loss 0.187653 lr 0.00042801 rank 2
2023-02-22 07:25:46,895 DEBUG TRAIN Batch 16/3000 loss 19.229519 loss_att 22.850075 loss_ctc 26.439301 loss_rnnt 17.506859 hw_loss 0.069835 lr 0.00042806 rank 6
2023-02-22 07:25:46,897 DEBUG TRAIN Batch 16/3000 loss 16.524303 loss_att 15.800629 loss_ctc 18.018242 loss_rnnt 16.449537 hw_loss 0.038081 lr 0.00042803 rank 3
2023-02-22 07:27:00,871 DEBUG TRAIN Batch 16/3100 loss 10.693913 loss_att 9.653119 loss_ctc 13.466669 loss_rnnt 10.406370 hw_loss 0.236255 lr 0.00042784 rank 5
2023-02-22 07:27:00,874 DEBUG TRAIN Batch 16/3100 loss 15.852190 loss_att 17.885975 loss_ctc 22.788509 loss_rnnt 14.485370 hw_loss 0.066038 lr 0.00042790 rank 6
2023-02-22 07:27:00,873 DEBUG TRAIN Batch 16/3100 loss 9.749249 loss_att 13.031067 loss_ctc 11.713401 loss_rnnt 8.770730 hw_loss 0.113001 lr 0.00042785 rank 7
2023-02-22 07:27:00,874 DEBUG TRAIN Batch 16/3100 loss 21.536724 loss_att 21.845621 loss_ctc 29.937155 loss_rnnt 20.203928 hw_loss 0.283047 lr 0.00042787 rank 3
2023-02-22 07:27:00,874 DEBUG TRAIN Batch 16/3100 loss 23.427538 loss_att 24.477272 loss_ctc 28.385736 loss_rnnt 22.480062 hw_loss 0.143321 lr 0.00042788 rank 4
2023-02-22 07:27:00,875 DEBUG TRAIN Batch 16/3100 loss 4.899534 loss_att 6.445402 loss_ctc 6.443556 loss_rnnt 4.307252 hw_loss 0.144824 lr 0.00042794 rank 1
2023-02-22 07:27:00,877 DEBUG TRAIN Batch 16/3100 loss 6.168477 loss_att 7.287147 loss_ctc 7.461283 loss_rnnt 5.615914 hw_loss 0.293351 lr 0.00042789 rank 0
2023-02-22 07:27:00,877 DEBUG TRAIN Batch 16/3100 loss 6.624116 loss_att 7.856637 loss_ctc 9.183271 loss_rnnt 5.937378 hw_loss 0.185650 lr 0.00042785 rank 2
2023-02-22 07:28:19,258 DEBUG TRAIN Batch 16/3200 loss 10.762125 loss_att 14.835288 loss_ctc 17.454811 loss_rnnt 9.018642 hw_loss 0.068421 lr 0.00042772 rank 4
2023-02-22 07:28:19,259 DEBUG TRAIN Batch 16/3200 loss 9.683831 loss_att 11.289038 loss_ctc 13.709836 loss_rnnt 8.752444 hw_loss 0.137897 lr 0.00042774 rank 0
2023-02-22 07:28:19,261 DEBUG TRAIN Batch 16/3200 loss 8.741231 loss_att 8.696514 loss_ctc 10.963531 loss_rnnt 8.342327 hw_loss 0.209139 lr 0.00042769 rank 7
2023-02-22 07:28:19,263 DEBUG TRAIN Batch 16/3200 loss 7.908566 loss_att 12.032394 loss_ctc 9.299500 loss_rnnt 6.789143 hw_loss 0.204749 lr 0.00042775 rank 6
2023-02-22 07:28:19,263 DEBUG TRAIN Batch 16/3200 loss 8.693464 loss_att 12.407650 loss_ctc 10.546461 loss_rnnt 7.614970 hw_loss 0.166110 lr 0.00042768 rank 5
2023-02-22 07:28:19,266 DEBUG TRAIN Batch 16/3200 loss 14.568342 loss_att 14.500881 loss_ctc 14.829852 loss_rnnt 14.509487 hw_loss 0.070271 lr 0.00042771 rank 3
2023-02-22 07:28:19,288 DEBUG TRAIN Batch 16/3200 loss 6.914522 loss_att 7.735612 loss_ctc 6.611377 loss_rnnt 6.782903 hw_loss 0.014664 lr 0.00042770 rank 2
2023-02-22 07:28:19,313 DEBUG TRAIN Batch 16/3200 loss 9.231880 loss_att 10.106119 loss_ctc 11.617432 loss_rnnt 8.661077 hw_loss 0.146028 lr 0.00042778 rank 1
2023-02-22 07:29:34,797 DEBUG TRAIN Batch 16/3300 loss 12.926813 loss_att 14.899212 loss_ctc 18.064400 loss_rnnt 11.732485 hw_loss 0.215315 lr 0.00042757 rank 4
2023-02-22 07:29:34,797 DEBUG TRAIN Batch 16/3300 loss 7.257524 loss_att 10.787342 loss_ctc 8.300510 loss_rnnt 6.329465 hw_loss 0.155680 lr 0.00042758 rank 0
2023-02-22 07:29:34,802 DEBUG TRAIN Batch 16/3300 loss 19.630474 loss_att 22.163567 loss_ctc 27.513876 loss_rnnt 18.026913 hw_loss 0.085914 lr 0.00042754 rank 7
2023-02-22 07:29:34,805 DEBUG TRAIN Batch 16/3300 loss 7.900821 loss_att 8.937191 loss_ctc 10.024208 loss_rnnt 7.275320 hw_loss 0.253329 lr 0.00042753 rank 5
2023-02-22 07:29:34,805 DEBUG TRAIN Batch 16/3300 loss 8.463657 loss_att 12.386048 loss_ctc 11.517447 loss_rnnt 7.189926 hw_loss 0.153902 lr 0.00042759 rank 6
2023-02-22 07:29:34,806 DEBUG TRAIN Batch 16/3300 loss 10.652682 loss_att 14.469738 loss_ctc 15.642906 loss_rnnt 9.170523 hw_loss 0.100097 lr 0.00042762 rank 1
2023-02-22 07:29:34,810 DEBUG TRAIN Batch 16/3300 loss 4.976180 loss_att 7.145904 loss_ctc 5.497510 loss_rnnt 4.472513 hw_loss 0.000395 lr 0.00042754 rank 2
2023-02-22 07:29:34,856 DEBUG TRAIN Batch 16/3300 loss 4.691032 loss_att 10.036907 loss_ctc 10.636532 loss_rnnt 2.714678 hw_loss 0.214585 lr 0.00042756 rank 3
2023-02-22 07:30:49,741 DEBUG TRAIN Batch 16/3400 loss 10.007245 loss_att 13.714466 loss_ctc 13.730278 loss_rnnt 8.709891 hw_loss 0.111572 lr 0.00042742 rank 0
2023-02-22 07:30:49,743 DEBUG TRAIN Batch 16/3400 loss 5.736759 loss_att 7.970294 loss_ctc 12.359327 loss_rnnt 4.406421 hw_loss 0.001167 lr 0.00042747 rank 1
2023-02-22 07:30:49,745 DEBUG TRAIN Batch 16/3400 loss 11.449012 loss_att 14.783539 loss_ctc 15.682556 loss_rnnt 10.159516 hw_loss 0.108969 lr 0.00042743 rank 6
2023-02-22 07:30:49,745 DEBUG TRAIN Batch 16/3400 loss 10.679046 loss_att 14.721888 loss_ctc 13.705656 loss_rnnt 9.373360 hw_loss 0.175442 lr 0.00042737 rank 5
2023-02-22 07:30:49,745 DEBUG TRAIN Batch 16/3400 loss 24.765102 loss_att 24.076237 loss_ctc 29.659931 loss_rnnt 24.171072 hw_loss 0.148423 lr 0.00042741 rank 4
2023-02-22 07:30:49,747 DEBUG TRAIN Batch 16/3400 loss 5.963265 loss_att 11.209461 loss_ctc 8.489326 loss_rnnt 4.436199 hw_loss 0.264410 lr 0.00042738 rank 7
2023-02-22 07:30:49,749 DEBUG TRAIN Batch 16/3400 loss 6.821806 loss_att 10.151139 loss_ctc 8.963589 loss_rnnt 5.840878 hw_loss 0.055291 lr 0.00042740 rank 3
2023-02-22 07:30:49,751 DEBUG TRAIN Batch 16/3400 loss 10.353530 loss_att 14.936951 loss_ctc 15.292273 loss_rnnt 8.734400 hw_loss 0.082403 lr 0.00042738 rank 2
2023-02-22 07:32:05,547 DEBUG TRAIN Batch 16/3500 loss 11.185102 loss_att 14.484838 loss_ctc 13.672260 loss_rnnt 10.152534 hw_loss 0.076876 lr 0.00042722 rank 7
2023-02-22 07:32:05,553 DEBUG TRAIN Batch 16/3500 loss 12.084850 loss_att 18.142076 loss_ctc 16.375223 loss_rnnt 10.256712 hw_loss 0.083706 lr 0.00042727 rank 0
2023-02-22 07:32:05,556 DEBUG TRAIN Batch 16/3500 loss 11.191519 loss_att 13.930004 loss_ctc 16.348015 loss_rnnt 9.890391 hw_loss 0.123558 lr 0.00042723 rank 2
2023-02-22 07:32:05,555 DEBUG TRAIN Batch 16/3500 loss 11.594503 loss_att 15.422459 loss_ctc 19.754715 loss_rnnt 9.715829 hw_loss 0.046978 lr 0.00042724 rank 3
2023-02-22 07:32:05,557 DEBUG TRAIN Batch 16/3500 loss 13.861064 loss_att 18.611652 loss_ctc 14.558531 loss_rnnt 12.784369 hw_loss 0.062963 lr 0.00042722 rank 5
2023-02-22 07:32:05,557 DEBUG TRAIN Batch 16/3500 loss 10.048711 loss_att 12.130423 loss_ctc 15.851297 loss_rnnt 8.824697 hw_loss 0.063733 lr 0.00042726 rank 4
2023-02-22 07:32:05,569 DEBUG TRAIN Batch 16/3500 loss 14.973934 loss_att 15.493105 loss_ctc 20.729067 loss_rnnt 14.024965 hw_loss 0.145843 lr 0.00042728 rank 6
2023-02-22 07:32:05,602 DEBUG TRAIN Batch 16/3500 loss 14.240098 loss_att 17.519016 loss_ctc 18.092968 loss_rnnt 13.042099 hw_loss 0.053436 lr 0.00042731 rank 1
2023-02-22 07:33:22,700 DEBUG TRAIN Batch 16/3600 loss 26.812536 loss_att 29.638947 loss_ctc 33.734108 loss_rnnt 25.236115 hw_loss 0.165491 lr 0.00042710 rank 4
2023-02-22 07:33:22,701 DEBUG TRAIN Batch 16/3600 loss 20.959351 loss_att 22.629129 loss_ctc 24.242279 loss_rnnt 20.063835 hw_loss 0.232190 lr 0.00042709 rank 3
2023-02-22 07:33:22,702 DEBUG TRAIN Batch 16/3600 loss 7.784307 loss_att 12.511146 loss_ctc 13.657394 loss_rnnt 5.992432 hw_loss 0.118932 lr 0.00042706 rank 5
2023-02-22 07:33:22,702 DEBUG TRAIN Batch 16/3600 loss 11.302423 loss_att 14.136503 loss_ctc 13.951571 loss_rnnt 10.278307 hw_loss 0.195148 lr 0.00042707 rank 7
2023-02-22 07:33:22,705 DEBUG TRAIN Batch 16/3600 loss 10.685436 loss_att 11.523376 loss_ctc 15.466569 loss_rnnt 9.802084 hw_loss 0.146776 lr 0.00042715 rank 1
2023-02-22 07:33:22,708 DEBUG TRAIN Batch 16/3600 loss 12.057053 loss_att 17.162407 loss_ctc 17.102995 loss_rnnt 10.304060 hw_loss 0.110866 lr 0.00042711 rank 0
2023-02-22 07:33:22,709 DEBUG TRAIN Batch 16/3600 loss 12.096873 loss_att 12.233005 loss_ctc 13.995922 loss_rnnt 11.696175 hw_loss 0.225499 lr 0.00042712 rank 6
2023-02-22 07:33:22,752 DEBUG TRAIN Batch 16/3600 loss 12.478020 loss_att 14.056297 loss_ctc 16.417763 loss_rnnt 11.570900 hw_loss 0.124060 lr 0.00042707 rank 2
2023-02-22 07:34:37,921 DEBUG TRAIN Batch 16/3700 loss 6.253108 loss_att 9.884655 loss_ctc 7.444851 loss_rnnt 5.337426 hw_loss 0.057137 lr 0.00042696 rank 0
2023-02-22 07:34:37,922 DEBUG TRAIN Batch 16/3700 loss 8.176744 loss_att 9.305932 loss_ctc 10.471211 loss_rnnt 7.540721 hw_loss 0.195479 lr 0.00042690 rank 5
2023-02-22 07:34:37,923 DEBUG TRAIN Batch 16/3700 loss 4.453612 loss_att 6.395700 loss_ctc 7.556169 loss_rnnt 3.638962 hw_loss 0.023547 lr 0.00042691 rank 7
2023-02-22 07:34:37,923 DEBUG TRAIN Batch 16/3700 loss 21.101227 loss_att 24.128557 loss_ctc 30.060179 loss_rnnt 19.215536 hw_loss 0.160683 lr 0.00042694 rank 4
2023-02-22 07:34:37,924 DEBUG TRAIN Batch 16/3700 loss 18.727573 loss_att 18.469511 loss_ctc 20.246521 loss_rnnt 18.528208 hw_loss 0.090846 lr 0.00042700 rank 1
2023-02-22 07:34:37,929 DEBUG TRAIN Batch 16/3700 loss 13.860862 loss_att 15.949747 loss_ctc 19.296143 loss_rnnt 12.593602 hw_loss 0.233958 lr 0.00042697 rank 6
2023-02-22 07:34:37,930 DEBUG TRAIN Batch 16/3700 loss 9.516982 loss_att 9.883702 loss_ctc 12.075523 loss_rnnt 9.012740 hw_loss 0.168298 lr 0.00042693 rank 3
2023-02-22 07:34:37,931 DEBUG TRAIN Batch 16/3700 loss 12.144614 loss_att 14.267491 loss_ctc 12.860590 loss_rnnt 11.549800 hw_loss 0.140203 lr 0.00042692 rank 2
2023-02-22 07:35:54,031 DEBUG TRAIN Batch 16/3800 loss 18.197540 loss_att 20.508045 loss_ctc 20.758596 loss_rnnt 17.353724 hw_loss 0.075450 lr 0.00042680 rank 0
2023-02-22 07:35:54,038 DEBUG TRAIN Batch 16/3800 loss 6.436495 loss_att 7.747513 loss_ctc 8.342382 loss_rnnt 5.799668 hw_loss 0.225947 lr 0.00042679 rank 4
2023-02-22 07:35:54,038 DEBUG TRAIN Batch 16/3800 loss 27.372860 loss_att 33.832893 loss_ctc 33.518124 loss_rnnt 25.148581 hw_loss 0.211698 lr 0.00042675 rank 5
2023-02-22 07:35:54,039 DEBUG TRAIN Batch 16/3800 loss 13.115407 loss_att 13.748205 loss_ctc 14.326406 loss_rnnt 12.765853 hw_loss 0.115364 lr 0.00042676 rank 7
2023-02-22 07:35:54,040 DEBUG TRAIN Batch 16/3800 loss 9.885489 loss_att 10.590199 loss_ctc 14.361037 loss_rnnt 9.038238 hw_loss 0.205446 lr 0.00042676 rank 2
2023-02-22 07:35:54,040 DEBUG TRAIN Batch 16/3800 loss 8.208897 loss_att 9.607672 loss_ctc 10.287496 loss_rnnt 7.515820 hw_loss 0.255330 lr 0.00042681 rank 6
2023-02-22 07:35:54,041 DEBUG TRAIN Batch 16/3800 loss 15.385213 loss_att 21.296385 loss_ctc 18.905800 loss_rnnt 13.644909 hw_loss 0.166232 lr 0.00042684 rank 1
2023-02-22 07:35:54,042 DEBUG TRAIN Batch 16/3800 loss 7.258743 loss_att 8.026743 loss_ctc 8.014763 loss_rnnt 6.914652 hw_loss 0.168166 lr 0.00042678 rank 3
2023-02-22 07:37:11,517 DEBUG TRAIN Batch 16/3900 loss 12.169013 loss_att 14.080997 loss_ctc 14.195969 loss_rnnt 11.448507 hw_loss 0.127218 lr 0.00042661 rank 2
2023-02-22 07:37:11,518 DEBUG TRAIN Batch 16/3900 loss 9.711619 loss_att 13.764769 loss_ctc 17.700926 loss_rnnt 7.820335 hw_loss 0.028899 lr 0.00042659 rank 5
2023-02-22 07:37:11,519 DEBUG TRAIN Batch 16/3900 loss 9.200464 loss_att 11.604195 loss_ctc 11.959219 loss_rnnt 8.303437 hw_loss 0.090838 lr 0.00042669 rank 1
2023-02-22 07:37:11,521 DEBUG TRAIN Batch 16/3900 loss 4.571227 loss_att 5.672787 loss_ctc 6.369773 loss_rnnt 4.042508 hw_loss 0.128626 lr 0.00042665 rank 0
2023-02-22 07:37:11,522 DEBUG TRAIN Batch 16/3900 loss 9.709103 loss_att 14.686516 loss_ctc 13.519650 loss_rnnt 8.125064 hw_loss 0.150907 lr 0.00042662 rank 3
2023-02-22 07:37:11,524 DEBUG TRAIN Batch 16/3900 loss 12.361797 loss_att 14.689493 loss_ctc 17.877293 loss_rnnt 11.058683 hw_loss 0.191578 lr 0.00042666 rank 6
2023-02-22 07:37:11,546 DEBUG TRAIN Batch 16/3900 loss 11.790302 loss_att 14.882473 loss_ctc 16.830387 loss_rnnt 10.453556 hw_loss 0.086814 lr 0.00042660 rank 7
2023-02-22 07:37:11,559 DEBUG TRAIN Batch 16/3900 loss 10.548489 loss_att 14.462568 loss_ctc 14.193110 loss_rnnt 9.177433 hw_loss 0.191792 lr 0.00042663 rank 4
2023-02-22 07:38:26,583 DEBUG TRAIN Batch 16/4000 loss 6.277153 loss_att 9.936865 loss_ctc 8.693972 loss_rnnt 5.095037 hw_loss 0.239870 lr 0.00042648 rank 4
2023-02-22 07:38:26,586 DEBUG TRAIN Batch 16/4000 loss 16.037466 loss_att 20.110695 loss_ctc 27.095356 loss_rnnt 13.747984 hw_loss 0.000843 lr 0.00042645 rank 7
2023-02-22 07:38:26,589 DEBUG TRAIN Batch 16/4000 loss 16.646601 loss_att 15.452223 loss_ctc 19.174850 loss_rnnt 16.448980 hw_loss 0.186365 lr 0.00042649 rank 0
2023-02-22 07:38:26,590 DEBUG TRAIN Batch 16/4000 loss 10.845512 loss_att 15.019433 loss_ctc 19.116592 loss_rnnt 8.855313 hw_loss 0.098631 lr 0.00042644 rank 5
2023-02-22 07:38:26,591 DEBUG TRAIN Batch 16/4000 loss 17.032074 loss_att 20.931824 loss_ctc 24.338629 loss_rnnt 15.223659 hw_loss 0.101732 lr 0.00042647 rank 3
2023-02-22 07:38:26,593 DEBUG TRAIN Batch 16/4000 loss 8.727151 loss_att 11.154073 loss_ctc 9.080093 loss_rnnt 8.114141 hw_loss 0.151062 lr 0.00042653 rank 1
2023-02-22 07:38:26,595 DEBUG TRAIN Batch 16/4000 loss 4.960168 loss_att 8.066916 loss_ctc 7.297336 loss_rnnt 3.955452 hw_loss 0.134520 lr 0.00042645 rank 2
2023-02-22 07:38:26,595 DEBUG TRAIN Batch 16/4000 loss 32.478046 loss_att 39.730911 loss_ctc 53.042679 loss_rnnt 28.214188 hw_loss 0.133749 lr 0.00042650 rank 6
2023-02-22 07:39:41,533 DEBUG TRAIN Batch 16/4100 loss 1.511016 loss_att 3.805625 loss_ctc 4.324740 loss_rnnt 0.622115 hw_loss 0.102780 lr 0.00042628 rank 5
2023-02-22 07:39:41,533 DEBUG TRAIN Batch 16/4100 loss 16.227747 loss_att 20.329060 loss_ctc 22.692484 loss_rnnt 14.545071 hw_loss 0.000842 lr 0.00042632 rank 4
2023-02-22 07:39:41,537 DEBUG TRAIN Batch 16/4100 loss 11.459685 loss_att 16.004576 loss_ctc 16.922106 loss_rnnt 9.822151 hw_loss 0.000438 lr 0.00042638 rank 1
2023-02-22 07:39:41,538 DEBUG TRAIN Batch 16/4100 loss 10.635281 loss_att 13.096693 loss_ctc 15.877413 loss_rnnt 9.414812 hw_loss 0.054814 lr 0.00042633 rank 0
2023-02-22 07:39:41,538 DEBUG TRAIN Batch 16/4100 loss 10.735946 loss_att 15.404230 loss_ctc 15.966497 loss_rnnt 9.007088 hw_loss 0.183363 lr 0.00042629 rank 7
2023-02-22 07:39:41,540 DEBUG TRAIN Batch 16/4100 loss 10.716130 loss_att 12.489297 loss_ctc 15.143692 loss_rnnt 9.682335 hw_loss 0.166539 lr 0.00042631 rank 3
2023-02-22 07:39:41,541 DEBUG TRAIN Batch 16/4100 loss 9.636973 loss_att 12.335969 loss_ctc 14.425895 loss_rnnt 8.392949 hw_loss 0.123190 lr 0.00042635 rank 6
2023-02-22 07:39:41,543 DEBUG TRAIN Batch 16/4100 loss 8.850665 loss_att 12.588022 loss_ctc 15.766139 loss_rnnt 7.121486 hw_loss 0.111835 lr 0.00042630 rank 2
2023-02-22 07:40:57,770 DEBUG TRAIN Batch 16/4200 loss 14.299956 loss_att 17.617645 loss_ctc 21.248075 loss_rnnt 12.637161 hw_loss 0.136579 lr 0.00042617 rank 4
2023-02-22 07:40:57,772 DEBUG TRAIN Batch 16/4200 loss 3.875155 loss_att 6.440025 loss_ctc 4.800412 loss_rnnt 3.193153 hw_loss 0.085614 lr 0.00042618 rank 0
2023-02-22 07:40:57,774 DEBUG TRAIN Batch 16/4200 loss 12.887261 loss_att 14.223297 loss_ctc 13.816457 loss_rnnt 12.417717 hw_loss 0.147084 lr 0.00042614 rank 7
2023-02-22 07:40:57,774 DEBUG TRAIN Batch 16/4200 loss 5.512944 loss_att 7.945363 loss_ctc 6.249310 loss_rnnt 4.891466 hw_loss 0.069022 lr 0.00042613 rank 5
2023-02-22 07:40:57,778 DEBUG TRAIN Batch 16/4200 loss 10.172455 loss_att 12.195816 loss_ctc 13.512777 loss_rnnt 9.238117 hw_loss 0.158043 lr 0.00042616 rank 3
2023-02-22 07:40:57,780 DEBUG TRAIN Batch 16/4200 loss 12.986315 loss_att 15.878742 loss_ctc 16.081858 loss_rnnt 11.918882 hw_loss 0.142891 lr 0.00042619 rank 6
2023-02-22 07:40:57,787 DEBUG TRAIN Batch 16/4200 loss 20.890537 loss_att 24.604847 loss_ctc 27.852961 loss_rnnt 19.160398 hw_loss 0.110540 lr 0.00042614 rank 2
2023-02-22 07:40:57,819 DEBUG TRAIN Batch 16/4200 loss 13.300717 loss_att 15.624063 loss_ctc 18.366251 loss_rnnt 12.096748 hw_loss 0.119803 lr 0.00042622 rank 1
2023-02-22 07:42:16,658 DEBUG TRAIN Batch 16/4300 loss 15.977007 loss_att 19.087162 loss_ctc 18.156160 loss_rnnt 15.036500 hw_loss 0.052354 lr 0.00042598 rank 7
2023-02-22 07:42:16,660 DEBUG TRAIN Batch 16/4300 loss 15.251856 loss_att 19.760296 loss_ctc 22.540157 loss_rnnt 13.290697 hw_loss 0.164429 lr 0.00042597 rank 5
2023-02-22 07:42:16,665 DEBUG TRAIN Batch 16/4300 loss 9.496152 loss_att 10.609586 loss_ctc 11.457024 loss_rnnt 8.939980 hw_loss 0.135066 lr 0.00042600 rank 3
2023-02-22 07:42:16,666 DEBUG TRAIN Batch 16/4300 loss 17.002224 loss_att 20.228683 loss_ctc 24.007729 loss_rnnt 15.357546 hw_loss 0.122472 lr 0.00042603 rank 0
2023-02-22 07:42:16,667 DEBUG TRAIN Batch 16/4300 loss 11.023786 loss_att 14.183539 loss_ctc 15.859661 loss_rnnt 9.674858 hw_loss 0.135361 lr 0.00042601 rank 4
2023-02-22 07:42:16,674 DEBUG TRAIN Batch 16/4300 loss 7.618893 loss_att 10.575862 loss_ctc 12.697561 loss_rnnt 6.256846 hw_loss 0.175306 lr 0.00042604 rank 6
2023-02-22 07:42:16,676 DEBUG TRAIN Batch 16/4300 loss 16.949495 loss_att 20.445814 loss_ctc 24.053127 loss_rnnt 15.247271 hw_loss 0.104641 lr 0.00042607 rank 1
2023-02-22 07:42:16,716 DEBUG TRAIN Batch 16/4300 loss 10.776849 loss_att 15.159060 loss_ctc 15.483412 loss_rnnt 9.219942 hw_loss 0.099229 lr 0.00042599 rank 2
2023-02-22 07:43:32,878 DEBUG TRAIN Batch 16/4400 loss 8.967732 loss_att 12.283142 loss_ctc 10.438816 loss_rnnt 8.089981 hw_loss 0.034735 lr 0.00042587 rank 0
2023-02-22 07:43:32,879 DEBUG TRAIN Batch 16/4400 loss 5.082190 loss_att 6.101869 loss_ctc 7.393558 loss_rnnt 4.533364 hw_loss 0.068827 lr 0.00042586 rank 4
2023-02-22 07:43:32,881 DEBUG TRAIN Batch 16/4400 loss 9.785062 loss_att 8.877153 loss_ctc 11.682563 loss_rnnt 9.557203 hw_loss 0.293323 lr 0.00042585 rank 3
2023-02-22 07:43:32,882 DEBUG TRAIN Batch 16/4400 loss 6.839548 loss_att 9.086295 loss_ctc 7.764369 loss_rnnt 6.176186 hw_loss 0.170067 lr 0.00042583 rank 7
2023-02-22 07:43:32,887 DEBUG TRAIN Batch 16/4400 loss 8.569526 loss_att 10.164776 loss_ctc 12.226885 loss_rnnt 7.690872 hw_loss 0.134917 lr 0.00042582 rank 5
2023-02-22 07:43:32,917 DEBUG TRAIN Batch 16/4400 loss 11.867549 loss_att 12.726366 loss_ctc 15.589554 loss_rnnt 11.120616 hw_loss 0.147943 lr 0.00042588 rank 6
2023-02-22 07:43:32,919 DEBUG TRAIN Batch 16/4400 loss 6.776678 loss_att 7.635559 loss_ctc 9.891667 loss_rnnt 6.077780 hw_loss 0.209605 lr 0.00042583 rank 2
2023-02-22 07:43:32,928 DEBUG TRAIN Batch 16/4400 loss 4.226340 loss_att 5.521918 loss_ctc 5.912658 loss_rnnt 3.637532 hw_loss 0.196593 lr 0.00042591 rank 1
2023-02-22 07:44:48,980 DEBUG TRAIN Batch 16/4500 loss 10.066128 loss_att 16.071047 loss_ctc 15.429144 loss_rnnt 8.071020 hw_loss 0.148227 lr 0.00042567 rank 7
2023-02-22 07:44:48,981 DEBUG TRAIN Batch 16/4500 loss 11.756146 loss_att 13.616212 loss_ctc 13.952597 loss_rnnt 11.004478 hw_loss 0.162740 lr 0.00042572 rank 0
2023-02-22 07:44:48,981 DEBUG TRAIN Batch 16/4500 loss 8.498080 loss_att 11.053386 loss_ctc 12.738663 loss_rnnt 7.315518 hw_loss 0.198918 lr 0.00042570 rank 4
2023-02-22 07:44:48,985 DEBUG TRAIN Batch 16/4500 loss 8.146958 loss_att 11.487169 loss_ctc 11.536242 loss_rnnt 7.026880 hw_loss 0.000247 lr 0.00042576 rank 1
2023-02-22 07:44:48,985 DEBUG TRAIN Batch 16/4500 loss 16.084877 loss_att 19.447756 loss_ctc 21.352734 loss_rnnt 14.671591 hw_loss 0.071871 lr 0.00042567 rank 5
2023-02-22 07:44:48,985 DEBUG TRAIN Batch 16/4500 loss 9.844277 loss_att 10.706516 loss_ctc 12.887785 loss_rnnt 9.231293 hw_loss 0.065129 lr 0.00042568 rank 2
2023-02-22 07:44:48,986 DEBUG TRAIN Batch 16/4500 loss 31.768545 loss_att 45.913033 loss_ctc 33.057785 loss_rnnt 28.736090 hw_loss 0.059359 lr 0.00042569 rank 3
2023-02-22 07:44:49,026 DEBUG TRAIN Batch 16/4500 loss 3.974891 loss_att 6.383540 loss_ctc 4.885056 loss_rnnt 3.364094 hw_loss 0.014460 lr 0.00042573 rank 6
2023-02-22 07:46:05,132 DEBUG TRAIN Batch 16/4600 loss 15.310147 loss_att 18.245770 loss_ctc 25.070309 loss_rnnt 13.416126 hw_loss 0.010389 lr 0.00042557 rank 6
2023-02-22 07:46:05,133 DEBUG TRAIN Batch 16/4600 loss 6.925714 loss_att 9.658178 loss_ctc 10.237265 loss_rnnt 5.865046 hw_loss 0.136192 lr 0.00042552 rank 2
2023-02-22 07:46:05,134 DEBUG TRAIN Batch 16/4600 loss 10.284043 loss_att 13.538034 loss_ctc 14.629669 loss_rnnt 8.987565 hw_loss 0.124243 lr 0.00042554 rank 3
2023-02-22 07:46:05,136 DEBUG TRAIN Batch 16/4600 loss 13.146869 loss_att 15.174689 loss_ctc 17.834127 loss_rnnt 12.037771 hw_loss 0.147311 lr 0.00042560 rank 1
2023-02-22 07:46:05,138 DEBUG TRAIN Batch 16/4600 loss 14.142315 loss_att 17.478497 loss_ctc 12.189517 loss_rnnt 13.710983 hw_loss 0.045877 lr 0.00042556 rank 0
2023-02-22 07:46:05,138 DEBUG TRAIN Batch 16/4600 loss 7.333766 loss_att 12.483204 loss_ctc 11.769046 loss_rnnt 5.712299 hw_loss 0.000392 lr 0.00042555 rank 4
2023-02-22 07:46:05,140 DEBUG TRAIN Batch 16/4600 loss 4.711163 loss_att 9.235720 loss_ctc 6.580526 loss_rnnt 3.485141 hw_loss 0.134742 lr 0.00042552 rank 7
2023-02-22 07:46:05,143 DEBUG TRAIN Batch 16/4600 loss 7.255458 loss_att 12.708325 loss_ctc 13.950035 loss_rnnt 5.226157 hw_loss 0.086470 lr 0.00042551 rank 5
2023-02-22 07:47:21,605 DEBUG TRAIN Batch 16/4700 loss 10.251528 loss_att 13.394806 loss_ctc 16.224443 loss_rnnt 8.795179 hw_loss 0.058695 lr 0.00042541 rank 0
2023-02-22 07:47:21,613 DEBUG TRAIN Batch 16/4700 loss 12.929402 loss_att 15.698364 loss_ctc 20.225735 loss_rnnt 11.369245 hw_loss 0.062852 lr 0.00042542 rank 6
2023-02-22 07:47:21,613 DEBUG TRAIN Batch 16/4700 loss 8.363902 loss_att 9.885775 loss_ctc 12.035480 loss_rnnt 7.555925 hw_loss 0.026360 lr 0.00042536 rank 5
2023-02-22 07:47:21,615 DEBUG TRAIN Batch 16/4700 loss 11.559290 loss_att 15.198040 loss_ctc 11.975932 loss_rnnt 10.724939 hw_loss 0.095713 lr 0.00042540 rank 4
2023-02-22 07:47:21,615 DEBUG TRAIN Batch 16/4700 loss 8.698778 loss_att 12.931553 loss_ctc 14.273100 loss_rnnt 7.036527 hw_loss 0.135851 lr 0.00042545 rank 1
2023-02-22 07:47:21,615 DEBUG TRAIN Batch 16/4700 loss 4.369219 loss_att 6.484738 loss_ctc 6.971338 loss_rnnt 3.481997 hw_loss 0.219692 lr 0.00042536 rank 7
2023-02-22 07:47:21,620 DEBUG TRAIN Batch 16/4700 loss 12.932695 loss_att 17.889011 loss_ctc 19.678020 loss_rnnt 10.948528 hw_loss 0.175365 lr 0.00042538 rank 3
2023-02-22 07:47:21,667 DEBUG TRAIN Batch 16/4700 loss 5.562786 loss_att 9.220229 loss_ctc 9.881992 loss_rnnt 4.235661 hw_loss 0.037015 lr 0.00042537 rank 2
2023-02-22 07:48:37,343 DEBUG TRAIN Batch 16/4800 loss 4.427224 loss_att 7.109459 loss_ctc 6.658143 loss_rnnt 3.550823 hw_loss 0.079683 lr 0.00042525 rank 0
2023-02-22 07:48:37,343 DEBUG TRAIN Batch 16/4800 loss 14.829100 loss_att 17.298468 loss_ctc 19.943996 loss_rnnt 13.604791 hw_loss 0.090839 lr 0.00042524 rank 4
2023-02-22 07:48:37,344 DEBUG TRAIN Batch 16/4800 loss 8.737463 loss_att 10.737452 loss_ctc 13.017004 loss_rnnt 7.667900 hw_loss 0.185549 lr 0.00042521 rank 7
2023-02-22 07:48:37,345 DEBUG TRAIN Batch 16/4800 loss 15.438689 loss_att 16.360462 loss_ctc 21.002960 loss_rnnt 14.428377 hw_loss 0.157602 lr 0.00042523 rank 3
2023-02-22 07:48:37,345 DEBUG TRAIN Batch 16/4800 loss 18.813370 loss_att 22.539330 loss_ctc 26.510563 loss_rnnt 16.943949 hw_loss 0.183632 lr 0.00042520 rank 5
2023-02-22 07:48:37,348 DEBUG TRAIN Batch 16/4800 loss 14.585835 loss_att 15.452576 loss_ctc 20.048168 loss_rnnt 13.643869 hw_loss 0.075571 lr 0.00042526 rank 6
2023-02-22 07:48:37,350 DEBUG TRAIN Batch 16/4800 loss 9.615807 loss_att 12.102041 loss_ctc 15.377478 loss_rnnt 8.242682 hw_loss 0.201853 lr 0.00042530 rank 1
2023-02-22 07:48:37,396 DEBUG TRAIN Batch 16/4800 loss 14.545162 loss_att 15.906467 loss_ctc 17.020069 loss_rnnt 13.849817 hw_loss 0.174553 lr 0.00042522 rank 2
2023-02-22 07:49:54,114 DEBUG TRAIN Batch 16/4900 loss 7.966431 loss_att 10.305662 loss_ctc 7.873405 loss_rnnt 7.471078 hw_loss 0.074831 lr 0.00042510 rank 0
2023-02-22 07:49:54,117 DEBUG TRAIN Batch 16/4900 loss 9.707294 loss_att 12.467748 loss_ctc 12.240044 loss_rnnt 8.815989 hw_loss 0.002840 lr 0.00042506 rank 7
2023-02-22 07:49:54,117 DEBUG TRAIN Batch 16/4900 loss 8.979774 loss_att 12.136954 loss_ctc 12.388992 loss_rnnt 7.797413 hw_loss 0.180681 lr 0.00042509 rank 4
2023-02-22 07:49:54,118 DEBUG TRAIN Batch 16/4900 loss 14.316787 loss_att 16.370995 loss_ctc 16.938633 loss_rnnt 13.528494 hw_loss 0.052261 lr 0.00042505 rank 5
2023-02-22 07:49:54,118 DEBUG TRAIN Batch 16/4900 loss 13.887674 loss_att 18.313807 loss_ctc 19.406021 loss_rnnt 12.260078 hw_loss 0.012355 lr 0.00042514 rank 1
2023-02-22 07:49:54,126 DEBUG TRAIN Batch 16/4900 loss 5.484580 loss_att 8.086330 loss_ctc 6.870210 loss_rnnt 4.701868 hw_loss 0.145522 lr 0.00042511 rank 6
2023-02-22 07:49:54,127 DEBUG TRAIN Batch 16/4900 loss 15.449988 loss_att 17.416500 loss_ctc 19.564571 loss_rnnt 14.442335 hw_loss 0.123263 lr 0.00042506 rank 2
2023-02-22 07:49:54,127 DEBUG TRAIN Batch 16/4900 loss 17.608593 loss_att 18.720211 loss_ctc 25.281712 loss_rnnt 16.316263 hw_loss 0.087984 lr 0.00042508 rank 3
2023-02-22 07:51:12,234 DEBUG TRAIN Batch 16/5000 loss 13.062989 loss_att 13.934786 loss_ctc 18.330585 loss_rnnt 12.051297 hw_loss 0.253098 lr 0.00042499 rank 1
2023-02-22 07:51:12,235 DEBUG TRAIN Batch 16/5000 loss 9.429346 loss_att 11.131815 loss_ctc 14.142079 loss_rnnt 8.395977 hw_loss 0.120956 lr 0.00042490 rank 7
2023-02-22 07:51:12,235 DEBUG TRAIN Batch 16/5000 loss 13.472520 loss_att 14.238640 loss_ctc 19.974579 loss_rnnt 12.381155 hw_loss 0.133502 lr 0.00042490 rank 5
2023-02-22 07:51:12,237 DEBUG TRAIN Batch 16/5000 loss 11.224565 loss_att 16.803944 loss_ctc 18.133728 loss_rnnt 9.104250 hw_loss 0.156032 lr 0.00042493 rank 4
2023-02-22 07:51:12,238 DEBUG TRAIN Batch 16/5000 loss 11.593460 loss_att 14.222435 loss_ctc 16.430275 loss_rnnt 10.366760 hw_loss 0.104991 lr 0.00042495 rank 0
2023-02-22 07:51:12,238 DEBUG TRAIN Batch 16/5000 loss 4.447112 loss_att 7.098212 loss_ctc 7.384462 loss_rnnt 3.486899 hw_loss 0.071900 lr 0.00042491 rank 2
2023-02-22 07:51:12,240 DEBUG TRAIN Batch 16/5000 loss 7.443824 loss_att 10.669189 loss_ctc 11.411177 loss_rnnt 6.226411 hw_loss 0.081299 lr 0.00042492 rank 3
2023-02-22 07:51:12,284 DEBUG TRAIN Batch 16/5000 loss 13.289996 loss_att 16.399403 loss_ctc 18.013008 loss_rnnt 11.976535 hw_loss 0.115959 lr 0.00042496 rank 6
2023-02-22 07:52:27,523 DEBUG TRAIN Batch 16/5100 loss 12.800144 loss_att 13.092083 loss_ctc 16.723207 loss_rnnt 12.088921 hw_loss 0.243302 lr 0.00042478 rank 4
2023-02-22 07:52:27,526 DEBUG TRAIN Batch 16/5100 loss 5.572062 loss_att 8.668136 loss_ctc 8.240328 loss_rnnt 4.532241 hw_loss 0.121569 lr 0.00042475 rank 7
2023-02-22 07:52:27,527 DEBUG TRAIN Batch 16/5100 loss 24.174633 loss_att 26.198917 loss_ctc 31.753229 loss_rnnt 22.736471 hw_loss 0.042795 lr 0.00042479 rank 0
2023-02-22 07:52:27,530 DEBUG TRAIN Batch 16/5100 loss 10.537190 loss_att 17.901398 loss_ctc 20.599060 loss_rnnt 7.589727 hw_loss 0.249449 lr 0.00042474 rank 5
2023-02-22 07:52:27,530 DEBUG TRAIN Batch 16/5100 loss 9.316309 loss_att 10.142075 loss_ctc 13.105075 loss_rnnt 8.495913 hw_loss 0.281392 lr 0.00042480 rank 6
2023-02-22 07:52:27,533 DEBUG TRAIN Batch 16/5100 loss 17.419628 loss_att 20.173223 loss_ctc 17.973896 loss_rnnt 16.715904 hw_loss 0.148316 lr 0.00042476 rank 2
2023-02-22 07:52:27,533 DEBUG TRAIN Batch 16/5100 loss 10.525020 loss_att 13.051146 loss_ctc 12.896942 loss_rnnt 9.665981 hw_loss 0.070420 lr 0.00042477 rank 3
2023-02-22 07:52:27,535 DEBUG TRAIN Batch 16/5100 loss 15.737210 loss_att 14.828339 loss_ctc 18.562801 loss_rnnt 15.502203 hw_loss 0.075069 lr 0.00042483 rank 1
2023-02-22 07:53:43,084 DEBUG TRAIN Batch 16/5200 loss 21.735897 loss_att 24.093750 loss_ctc 24.775570 loss_rnnt 20.816525 hw_loss 0.079709 lr 0.00042459 rank 5
2023-02-22 07:53:43,088 DEBUG TRAIN Batch 16/5200 loss 10.294991 loss_att 13.438074 loss_ctc 14.495151 loss_rnnt 9.087033 hw_loss 0.036223 lr 0.00042464 rank 0
2023-02-22 07:53:43,089 DEBUG TRAIN Batch 16/5200 loss 23.026707 loss_att 24.559753 loss_ctc 33.385040 loss_rnnt 21.277431 hw_loss 0.115412 lr 0.00042463 rank 4
2023-02-22 07:53:43,090 DEBUG TRAIN Batch 16/5200 loss 4.981894 loss_att 8.567926 loss_ctc 8.630882 loss_rnnt 3.751202 hw_loss 0.050539 lr 0.00042460 rank 7
2023-02-22 07:53:43,092 DEBUG TRAIN Batch 16/5200 loss 6.597461 loss_att 8.389920 loss_ctc 8.313507 loss_rnnt 5.977650 hw_loss 0.060962 lr 0.00042462 rank 3
2023-02-22 07:53:43,092 DEBUG TRAIN Batch 16/5200 loss 12.017048 loss_att 16.219372 loss_ctc 18.211628 loss_rnnt 10.305031 hw_loss 0.085514 lr 0.00042460 rank 2
2023-02-22 07:53:43,092 DEBUG TRAIN Batch 16/5200 loss 14.295327 loss_att 19.186960 loss_ctc 20.402126 loss_rnnt 12.430380 hw_loss 0.135714 lr 0.00042468 rank 1
2023-02-22 07:53:43,094 DEBUG TRAIN Batch 16/5200 loss 8.881973 loss_att 18.150692 loss_ctc 15.186731 loss_rnnt 6.101431 hw_loss 0.161558 lr 0.00042465 rank 6
2023-02-22 07:55:00,258 DEBUG TRAIN Batch 16/5300 loss 5.023621 loss_att 9.318399 loss_ctc 7.168159 loss_rnnt 3.851184 hw_loss 0.051643 lr 0.00042450 rank 6
2023-02-22 07:55:00,261 DEBUG TRAIN Batch 16/5300 loss 7.264502 loss_att 12.704327 loss_ctc 13.403614 loss_rnnt 5.226251 hw_loss 0.247007 lr 0.00042453 rank 1
2023-02-22 07:55:00,262 DEBUG TRAIN Batch 16/5300 loss 8.839853 loss_att 14.051161 loss_ctc 15.125029 loss_rnnt 6.929489 hw_loss 0.056401 lr 0.00042447 rank 4
2023-02-22 07:55:00,262 DEBUG TRAIN Batch 16/5300 loss 7.674172 loss_att 10.132841 loss_ctc 10.203444 loss_rnnt 6.756839 hw_loss 0.165681 lr 0.00042444 rank 7
2023-02-22 07:55:00,264 DEBUG TRAIN Batch 16/5300 loss 9.496696 loss_att 14.203399 loss_ctc 13.543573 loss_rnnt 7.937819 hw_loss 0.146164 lr 0.00042446 rank 3
2023-02-22 07:55:00,279 DEBUG TRAIN Batch 16/5300 loss 9.510880 loss_att 13.608817 loss_ctc 13.981799 loss_rnnt 8.094203 hw_loss 0.001811 lr 0.00042449 rank 0
2023-02-22 07:55:00,284 DEBUG TRAIN Batch 16/5300 loss 23.123787 loss_att 22.997814 loss_ctc 29.540945 loss_rnnt 22.179924 hw_loss 0.212694 lr 0.00042444 rank 5
2023-02-22 07:55:00,312 DEBUG TRAIN Batch 16/5300 loss 10.462994 loss_att 13.694153 loss_ctc 18.319349 loss_rnnt 8.724852 hw_loss 0.083243 lr 0.00042445 rank 2
2023-02-22 07:56:17,158 DEBUG TRAIN Batch 16/5400 loss 10.505724 loss_att 13.846186 loss_ctc 15.510366 loss_rnnt 9.125592 hw_loss 0.083911 lr 0.00042438 rank 1
2023-02-22 07:56:17,163 DEBUG TRAIN Batch 16/5400 loss 7.314163 loss_att 9.453295 loss_ctc 10.816461 loss_rnnt 6.341557 hw_loss 0.145887 lr 0.00042434 rank 6
2023-02-22 07:56:17,164 DEBUG TRAIN Batch 16/5400 loss 8.415998 loss_att 12.837084 loss_ctc 12.510993 loss_rnnt 6.933629 hw_loss 0.097784 lr 0.00042431 rank 3
2023-02-22 07:56:17,164 DEBUG TRAIN Batch 16/5400 loss 9.471576 loss_att 15.246965 loss_ctc 14.757886 loss_rnnt 7.588072 hw_loss 0.044220 lr 0.00042429 rank 7
2023-02-22 07:56:17,165 DEBUG TRAIN Batch 16/5400 loss 3.824716 loss_att 8.750595 loss_ctc 6.847239 loss_rnnt 2.392103 hw_loss 0.083315 lr 0.00042432 rank 4
2023-02-22 07:56:17,167 DEBUG TRAIN Batch 16/5400 loss 6.049061 loss_att 11.598000 loss_ctc 8.829515 loss_rnnt 4.433336 hw_loss 0.253517 lr 0.00042433 rank 0
2023-02-22 07:56:17,167 DEBUG TRAIN Batch 16/5400 loss 14.068647 loss_att 18.389502 loss_ctc 21.838900 loss_rnnt 12.136570 hw_loss 0.059762 lr 0.00042428 rank 5
2023-02-22 07:56:17,171 DEBUG TRAIN Batch 16/5400 loss 9.855230 loss_att 13.752526 loss_ctc 13.161416 loss_rnnt 8.566563 hw_loss 0.128219 lr 0.00042430 rank 2
2023-02-22 07:57:33,509 DEBUG TRAIN Batch 16/5500 loss 4.982335 loss_att 6.990772 loss_ctc 7.374838 loss_rnnt 4.188004 hw_loss 0.138080 lr 0.00042418 rank 0
2023-02-22 07:57:33,509 DEBUG TRAIN Batch 16/5500 loss 6.961664 loss_att 10.404797 loss_ctc 7.594488 loss_rnnt 6.133261 hw_loss 0.103874 lr 0.00042417 rank 4
2023-02-22 07:57:33,510 DEBUG TRAIN Batch 16/5500 loss 13.794488 loss_att 16.301285 loss_ctc 20.575596 loss_rnnt 12.352584 hw_loss 0.068243 lr 0.00042414 rank 7
2023-02-22 07:57:33,512 DEBUG TRAIN Batch 16/5500 loss 11.213606 loss_att 12.731222 loss_ctc 15.847904 loss_rnnt 10.227168 hw_loss 0.121891 lr 0.00042416 rank 3
2023-02-22 07:57:33,513 DEBUG TRAIN Batch 16/5500 loss 18.188526 loss_att 20.357622 loss_ctc 22.451504 loss_rnnt 17.075565 hw_loss 0.207641 lr 0.00042422 rank 1
2023-02-22 07:57:33,513 DEBUG TRAIN Batch 16/5500 loss 9.645451 loss_att 11.029829 loss_ctc 12.403615 loss_rnnt 8.946629 hw_loss 0.101606 lr 0.00042414 rank 2
2023-02-22 07:57:33,515 DEBUG TRAIN Batch 16/5500 loss 11.841522 loss_att 16.185528 loss_ctc 17.219467 loss_rnnt 10.228203 hw_loss 0.051484 lr 0.00042413 rank 5
2023-02-22 07:57:33,556 DEBUG TRAIN Batch 16/5500 loss 14.201592 loss_att 15.148314 loss_ctc 19.065702 loss_rnnt 13.262127 hw_loss 0.190449 lr 0.00042419 rank 6
2023-02-22 07:58:48,409 DEBUG TRAIN Batch 16/5600 loss 13.256711 loss_att 16.190372 loss_ctc 19.479641 loss_rnnt 11.775418 hw_loss 0.121566 lr 0.00042399 rank 7
2023-02-22 07:58:48,411 DEBUG TRAIN Batch 16/5600 loss 6.952587 loss_att 8.440244 loss_ctc 9.030251 loss_rnnt 6.337542 hw_loss 0.075921 lr 0.00042401 rank 3
2023-02-22 07:58:48,411 DEBUG TRAIN Batch 16/5600 loss 17.634680 loss_att 20.802301 loss_ctc 23.061832 loss_rnnt 16.169834 hw_loss 0.201934 lr 0.00042403 rank 0
2023-02-22 07:58:48,413 DEBUG TRAIN Batch 16/5600 loss 10.605171 loss_att 14.216949 loss_ctc 17.088007 loss_rnnt 8.987941 hw_loss 0.057182 lr 0.00042407 rank 1
2023-02-22 07:58:48,414 DEBUG TRAIN Batch 16/5600 loss 9.020374 loss_att 12.836354 loss_ctc 14.988576 loss_rnnt 7.415985 hw_loss 0.085186 lr 0.00042404 rank 6
2023-02-22 07:58:48,415 DEBUG TRAIN Batch 16/5600 loss 7.502552 loss_att 8.411553 loss_ctc 7.531197 loss_rnnt 7.303669 hw_loss 0.024869 lr 0.00042402 rank 4
2023-02-22 07:58:48,422 DEBUG TRAIN Batch 16/5600 loss 10.267181 loss_att 10.742856 loss_ctc 16.107937 loss_rnnt 9.359291 hw_loss 0.063728 lr 0.00042399 rank 2
2023-02-22 07:58:48,468 DEBUG TRAIN Batch 16/5600 loss 9.332431 loss_att 13.054195 loss_ctc 13.647142 loss_rnnt 7.996265 hw_loss 0.030974 lr 0.00042398 rank 5
2023-02-22 08:00:08,043 DEBUG TRAIN Batch 16/5700 loss 5.974401 loss_att 11.420541 loss_ctc 8.844278 loss_rnnt 4.489432 hw_loss 0.024543 lr 0.00042383 rank 7
2023-02-22 08:00:08,043 DEBUG TRAIN Batch 16/5700 loss 7.721838 loss_att 9.968785 loss_ctc 8.872012 loss_rnnt 7.010581 hw_loss 0.203460 lr 0.00042388 rank 0
2023-02-22 08:00:08,046 DEBUG TRAIN Batch 16/5700 loss 5.917697 loss_att 6.678700 loss_ctc 7.675165 loss_rnnt 5.424981 hw_loss 0.199098 lr 0.00042383 rank 5
2023-02-22 08:00:08,050 DEBUG TRAIN Batch 16/5700 loss 12.689958 loss_att 14.285501 loss_ctc 17.331205 loss_rnnt 11.667505 hw_loss 0.158456 lr 0.00042389 rank 6
2023-02-22 08:00:08,052 DEBUG TRAIN Batch 16/5700 loss 8.857161 loss_att 12.555804 loss_ctc 11.612231 loss_rnnt 7.657370 hw_loss 0.173851 lr 0.00042385 rank 3
2023-02-22 08:00:08,052 DEBUG TRAIN Batch 16/5700 loss 8.058052 loss_att 12.015366 loss_ctc 13.302978 loss_rnnt 6.493742 hw_loss 0.137858 lr 0.00042386 rank 4
2023-02-22 08:00:08,054 DEBUG TRAIN Batch 16/5700 loss 13.081562 loss_att 12.371634 loss_ctc 15.736505 loss_rnnt 12.730591 hw_loss 0.260558 lr 0.00042392 rank 1
2023-02-22 08:00:08,058 DEBUG TRAIN Batch 16/5700 loss 6.701138 loss_att 12.613527 loss_ctc 9.102154 loss_rnnt 5.153207 hw_loss 0.084971 lr 0.00042384 rank 2
2023-02-22 08:01:23,306 DEBUG TRAIN Batch 16/5800 loss 8.822302 loss_att 9.749165 loss_ctc 11.967276 loss_rnnt 8.096140 hw_loss 0.227737 lr 0.00042372 rank 0
2023-02-22 08:01:23,308 DEBUG TRAIN Batch 16/5800 loss 12.547726 loss_att 16.163332 loss_ctc 16.691462 loss_rnnt 11.199934 hw_loss 0.135321 lr 0.00042373 rank 6
2023-02-22 08:01:23,309 DEBUG TRAIN Batch 16/5800 loss 14.460964 loss_att 16.694141 loss_ctc 18.984417 loss_rnnt 13.375141 hw_loss 0.067616 lr 0.00042371 rank 4
2023-02-22 08:01:23,310 DEBUG TRAIN Batch 16/5800 loss 11.129531 loss_att 15.679277 loss_ctc 13.538912 loss_rnnt 9.763231 hw_loss 0.253313 lr 0.00042368 rank 7
2023-02-22 08:01:23,312 DEBUG TRAIN Batch 16/5800 loss 11.251731 loss_att 18.170990 loss_ctc 19.672493 loss_rnnt 8.716971 hw_loss 0.052763 lr 0.00042370 rank 3
2023-02-22 08:01:23,313 DEBUG TRAIN Batch 16/5800 loss 15.107189 loss_att 17.840466 loss_ctc 21.820881 loss_rnnt 13.633337 hw_loss 0.060073 lr 0.00042367 rank 5
2023-02-22 08:01:23,317 DEBUG TRAIN Batch 16/5800 loss 7.812162 loss_att 10.831474 loss_ctc 10.274428 loss_rnnt 6.848207 hw_loss 0.059606 lr 0.00042369 rank 2
2023-02-22 08:01:23,359 DEBUG TRAIN Batch 16/5800 loss 4.208126 loss_att 6.842667 loss_ctc 5.692404 loss_rnnt 3.430104 hw_loss 0.099768 lr 0.00042377 rank 1
2023-02-22 08:02:38,217 DEBUG TRAIN Batch 16/5900 loss 8.266219 loss_att 11.539421 loss_ctc 11.053637 loss_rnnt 7.201488 hw_loss 0.072065 lr 0.00042356 rank 4
2023-02-22 08:02:38,221 DEBUG TRAIN Batch 16/5900 loss 4.294805 loss_att 7.774617 loss_ctc 4.934388 loss_rnnt 3.513420 hw_loss 0.000271 lr 0.00042353 rank 2
2023-02-22 08:02:38,222 DEBUG TRAIN Batch 16/5900 loss 14.833422 loss_att 17.976919 loss_ctc 18.732361 loss_rnnt 13.611303 hw_loss 0.137927 lr 0.00042352 rank 5
2023-02-22 08:02:38,224 DEBUG TRAIN Batch 16/5900 loss 14.019580 loss_att 19.246517 loss_ctc 19.348539 loss_rnnt 12.210432 hw_loss 0.099814 lr 0.00042361 rank 1
2023-02-22 08:02:38,225 DEBUG TRAIN Batch 16/5900 loss 8.849575 loss_att 9.557644 loss_ctc 14.022868 loss_rnnt 7.971856 hw_loss 0.086872 lr 0.00042353 rank 7
2023-02-22 08:02:38,226 DEBUG TRAIN Batch 16/5900 loss 7.745886 loss_att 11.620331 loss_ctc 10.705131 loss_rnnt 6.539605 hw_loss 0.069048 lr 0.00042357 rank 0
2023-02-22 08:02:38,233 DEBUG TRAIN Batch 16/5900 loss 10.860929 loss_att 11.505230 loss_ctc 12.616622 loss_rnnt 10.466066 hw_loss 0.059831 lr 0.00042358 rank 6
2023-02-22 08:02:38,271 DEBUG TRAIN Batch 16/5900 loss 9.314041 loss_att 13.029106 loss_ctc 13.418076 loss_rnnt 7.942610 hw_loss 0.152275 lr 0.00042355 rank 3
2023-02-22 08:03:55,367 DEBUG TRAIN Batch 16/6000 loss 24.544682 loss_att 29.164825 loss_ctc 30.142864 loss_rnnt 22.863884 hw_loss 0.019396 lr 0.00042337 rank 5
2023-02-22 08:03:55,367 DEBUG TRAIN Batch 16/6000 loss 2.614421 loss_att 5.034162 loss_ctc 4.208955 loss_rnnt 1.864257 hw_loss 0.100522 lr 0.00042341 rank 4
2023-02-22 08:03:55,368 DEBUG TRAIN Batch 16/6000 loss 8.403890 loss_att 10.485023 loss_ctc 11.825766 loss_rnnt 7.420455 hw_loss 0.208045 lr 0.00042342 rank 0
2023-02-22 08:03:55,371 DEBUG TRAIN Batch 16/6000 loss 11.304754 loss_att 15.555754 loss_ctc 19.786673 loss_rnnt 9.285667 hw_loss 0.071182 lr 0.00042338 rank 7
2023-02-22 08:03:55,377 DEBUG TRAIN Batch 16/6000 loss 13.617783 loss_att 16.526920 loss_ctc 15.727516 loss_rnnt 12.713604 hw_loss 0.076973 lr 0.00042343 rank 6
2023-02-22 08:03:55,378 DEBUG TRAIN Batch 16/6000 loss 7.471299 loss_att 10.730361 loss_ctc 9.385792 loss_rnnt 6.479198 hw_loss 0.159417 lr 0.00042346 rank 1
2023-02-22 08:03:55,381 DEBUG TRAIN Batch 16/6000 loss 6.218824 loss_att 10.998499 loss_ctc 9.655953 loss_rnnt 4.792345 hw_loss 0.022988 lr 0.00042340 rank 3
2023-02-22 08:03:55,382 DEBUG TRAIN Batch 16/6000 loss 14.818165 loss_att 18.791161 loss_ctc 19.336208 loss_rnnt 13.340389 hw_loss 0.151446 lr 0.00042338 rank 2
2023-02-22 08:05:11,957 DEBUG TRAIN Batch 16/6100 loss 6.602820 loss_att 10.891905 loss_ctc 12.120853 loss_rnnt 4.950017 hw_loss 0.111091 lr 0.00042327 rank 0
2023-02-22 08:05:11,959 DEBUG TRAIN Batch 16/6100 loss 8.630308 loss_att 11.366443 loss_ctc 8.861082 loss_rnnt 7.993972 hw_loss 0.109387 lr 0.00042322 rank 5
2023-02-22 08:05:11,960 DEBUG TRAIN Batch 16/6100 loss 8.730391 loss_att 13.159168 loss_ctc 11.118171 loss_rnnt 7.409580 hw_loss 0.218784 lr 0.00042323 rank 2
2023-02-22 08:05:11,960 DEBUG TRAIN Batch 16/6100 loss 4.750742 loss_att 7.887661 loss_ctc 7.910951 loss_rnnt 3.630811 hw_loss 0.133474 lr 0.00042323 rank 7
2023-02-22 08:05:11,960 DEBUG TRAIN Batch 16/6100 loss 16.863140 loss_att 16.742092 loss_ctc 21.533112 loss_rnnt 16.176411 hw_loss 0.165517 lr 0.00042326 rank 4
2023-02-22 08:05:11,961 DEBUG TRAIN Batch 16/6100 loss 10.982185 loss_att 13.313879 loss_ctc 16.409534 loss_rnnt 9.665785 hw_loss 0.237028 lr 0.00042331 rank 1
2023-02-22 08:05:11,961 DEBUG TRAIN Batch 16/6100 loss 9.082853 loss_att 11.679579 loss_ctc 15.370155 loss_rnnt 7.574754 hw_loss 0.282088 lr 0.00042328 rank 6
2023-02-22 08:05:12,009 DEBUG TRAIN Batch 16/6100 loss 6.674274 loss_att 9.348814 loss_ctc 9.254034 loss_rnnt 5.713015 hw_loss 0.154467 lr 0.00042325 rank 3
2023-02-22 08:06:26,781 DEBUG TRAIN Batch 16/6200 loss 19.003731 loss_att 21.297775 loss_ctc 28.765968 loss_rnnt 17.204470 hw_loss 0.072789 lr 0.00042307 rank 7
2023-02-22 08:06:26,782 DEBUG TRAIN Batch 16/6200 loss 17.473162 loss_att 24.167812 loss_ctc 22.995197 loss_rnnt 15.297718 hw_loss 0.187953 lr 0.00042312 rank 0
2023-02-22 08:06:26,786 DEBUG TRAIN Batch 16/6200 loss 22.868431 loss_att 24.329590 loss_ctc 32.236622 loss_rnnt 21.310352 hw_loss 0.031413 lr 0.00042310 rank 4
2023-02-22 08:06:26,788 DEBUG TRAIN Batch 16/6200 loss 7.091485 loss_att 9.877773 loss_ctc 11.063657 loss_rnnt 5.925323 hw_loss 0.148650 lr 0.00042307 rank 5
2023-02-22 08:06:26,790 DEBUG TRAIN Batch 16/6200 loss 12.306461 loss_att 14.612892 loss_ctc 15.518988 loss_rnnt 11.362578 hw_loss 0.101738 lr 0.00042309 rank 3
2023-02-22 08:06:26,792 DEBUG TRAIN Batch 16/6200 loss 11.479254 loss_att 12.994791 loss_ctc 14.143764 loss_rnnt 10.783121 hw_loss 0.070795 lr 0.00042313 rank 6
2023-02-22 08:06:26,794 DEBUG TRAIN Batch 16/6200 loss 17.154398 loss_att 16.434246 loss_ctc 21.071001 loss_rnnt 16.713133 hw_loss 0.118281 lr 0.00042316 rank 1
2023-02-22 08:06:26,837 DEBUG TRAIN Batch 16/6200 loss 9.529005 loss_att 11.908924 loss_ctc 12.282375 loss_rnnt 8.677236 hw_loss 0.016257 lr 0.00042308 rank 2
2023-02-22 08:07:41,436 DEBUG TRAIN Batch 16/6300 loss 14.944578 loss_att 16.694624 loss_ctc 21.363647 loss_rnnt 13.677489 hw_loss 0.114757 lr 0.00042292 rank 7
2023-02-22 08:07:41,442 DEBUG TRAIN Batch 16/6300 loss 2.965048 loss_att 5.726911 loss_ctc 3.833908 loss_rnnt 2.204169 hw_loss 0.173734 lr 0.00042298 rank 6
2023-02-22 08:07:41,443 DEBUG TRAIN Batch 16/6300 loss 7.938503 loss_att 7.521524 loss_ctc 10.551258 loss_rnnt 7.555842 hw_loss 0.220667 lr 0.00042293 rank 2
2023-02-22 08:07:41,445 DEBUG TRAIN Batch 16/6300 loss 9.051673 loss_att 9.975305 loss_ctc 11.939700 loss_rnnt 8.424323 hw_loss 0.107912 lr 0.00042295 rank 4
2023-02-22 08:07:41,446 DEBUG TRAIN Batch 16/6300 loss 18.494289 loss_att 18.255318 loss_ctc 25.903339 loss_rnnt 17.527359 hw_loss 0.050345 lr 0.00042301 rank 1
2023-02-22 08:07:41,447 DEBUG TRAIN Batch 16/6300 loss 11.112617 loss_att 11.901044 loss_ctc 14.068258 loss_rnnt 10.487448 hw_loss 0.137626 lr 0.00042297 rank 0
2023-02-22 08:07:41,449 DEBUG TRAIN Batch 16/6300 loss 10.302889 loss_att 11.247108 loss_ctc 13.047369 loss_rnnt 9.667572 hw_loss 0.151017 lr 0.00042292 rank 5
2023-02-22 08:07:41,450 DEBUG TRAIN Batch 16/6300 loss 6.868190 loss_att 10.186156 loss_ctc 10.935691 loss_rnnt 5.557487 hw_loss 0.196457 lr 0.00042294 rank 3
2023-02-22 08:09:00,531 DEBUG TRAIN Batch 16/6400 loss 11.580651 loss_att 12.820398 loss_ctc 13.420404 loss_rnnt 11.011372 hw_loss 0.142559 lr 0.00042281 rank 0
2023-02-22 08:09:00,531 DEBUG TRAIN Batch 16/6400 loss 3.748673 loss_att 7.006335 loss_ctc 4.078568 loss_rnnt 3.009909 hw_loss 0.081088 lr 0.00042277 rank 7
2023-02-22 08:09:00,538 DEBUG TRAIN Batch 16/6400 loss 8.693093 loss_att 8.377790 loss_ctc 10.957489 loss_rnnt 8.363355 hw_loss 0.170400 lr 0.00042280 rank 4
2023-02-22 08:09:00,538 DEBUG TRAIN Batch 16/6400 loss 13.362285 loss_att 16.070120 loss_ctc 20.515003 loss_rnnt 11.816165 hw_loss 0.095356 lr 0.00042276 rank 5
2023-02-22 08:09:00,541 DEBUG TRAIN Batch 16/6400 loss 8.190268 loss_att 13.310223 loss_ctc 9.925624 loss_rnnt 6.915872 hw_loss 0.035669 lr 0.00042278 rank 2
2023-02-22 08:09:00,544 DEBUG TRAIN Batch 16/6400 loss 2.437301 loss_att 5.142850 loss_ctc 3.789752 loss_rnnt 1.686574 hw_loss 0.054918 lr 0.00042279 rank 3
2023-02-22 08:09:00,547 DEBUG TRAIN Batch 16/6400 loss 6.551708 loss_att 7.008527 loss_ctc 7.733702 loss_rnnt 6.191696 hw_loss 0.208217 lr 0.00042286 rank 1
2023-02-22 08:09:00,595 DEBUG TRAIN Batch 16/6400 loss 19.202255 loss_att 16.734976 loss_ctc 23.649517 loss_rnnt 18.976130 hw_loss 0.237397 lr 0.00042282 rank 6
2023-02-22 08:10:16,834 DEBUG TRAIN Batch 16/6500 loss 8.270827 loss_att 9.988281 loss_ctc 13.419162 loss_rnnt 7.210194 hw_loss 0.057558 lr 0.00042262 rank 7
2023-02-22 08:10:16,837 DEBUG TRAIN Batch 16/6500 loss 7.260542 loss_att 7.497863 loss_ctc 8.355313 loss_rnnt 6.951887 hw_loss 0.216041 lr 0.00042266 rank 0
2023-02-22 08:10:16,840 DEBUG TRAIN Batch 16/6500 loss 10.961609 loss_att 15.122004 loss_ctc 13.646320 loss_rnnt 9.702278 hw_loss 0.129918 lr 0.00042261 rank 5
2023-02-22 08:10:16,840 DEBUG TRAIN Batch 16/6500 loss 4.181717 loss_att 6.770656 loss_ctc 4.727158 loss_rnnt 3.565192 hw_loss 0.048772 lr 0.00042267 rank 6
2023-02-22 08:10:16,841 DEBUG TRAIN Batch 16/6500 loss 14.276711 loss_att 18.781410 loss_ctc 24.245716 loss_rnnt 11.955940 hw_loss 0.169930 lr 0.00042265 rank 4
2023-02-22 08:10:16,841 DEBUG TRAIN Batch 16/6500 loss 6.039984 loss_att 9.681105 loss_ctc 9.390732 loss_rnnt 4.827594 hw_loss 0.070124 lr 0.00042270 rank 1
2023-02-22 08:10:16,842 DEBUG TRAIN Batch 16/6500 loss 10.348735 loss_att 13.835112 loss_ctc 19.783352 loss_rnnt 8.357262 hw_loss 0.067965 lr 0.00042263 rank 2
2023-02-22 08:10:16,846 DEBUG TRAIN Batch 16/6500 loss 5.275013 loss_att 8.103440 loss_ctc 5.100982 loss_rnnt 4.621696 hw_loss 0.207817 lr 0.00042264 rank 3
2023-02-22 08:11:32,432 DEBUG TRAIN Batch 16/6600 loss 6.584325 loss_att 9.998433 loss_ctc 9.036853 loss_rnnt 5.504535 hw_loss 0.131184 lr 0.00042251 rank 0
2023-02-22 08:11:32,434 DEBUG TRAIN Batch 16/6600 loss 7.777774 loss_att 12.390990 loss_ctc 12.802320 loss_rnnt 6.137237 hw_loss 0.089913 lr 0.00042255 rank 1
2023-02-22 08:11:32,434 DEBUG TRAIN Batch 16/6600 loss 5.779592 loss_att 9.784891 loss_ctc 8.564229 loss_rnnt 4.518797 hw_loss 0.165843 lr 0.00042250 rank 4
2023-02-22 08:11:32,439 DEBUG TRAIN Batch 16/6600 loss 5.987155 loss_att 9.178281 loss_ctc 8.250710 loss_rnnt 5.023893 hw_loss 0.043557 lr 0.00042247 rank 7
2023-02-22 08:11:32,440 DEBUG TRAIN Batch 16/6600 loss 8.798602 loss_att 10.909653 loss_ctc 9.761784 loss_rnnt 8.200256 hw_loss 0.089459 lr 0.00042252 rank 6
2023-02-22 08:11:32,441 DEBUG TRAIN Batch 16/6600 loss 8.739239 loss_att 10.391461 loss_ctc 9.840899 loss_rnnt 8.230161 hw_loss 0.059522 lr 0.00042249 rank 3
2023-02-22 08:11:32,442 DEBUG TRAIN Batch 16/6600 loss 16.788099 loss_att 19.569059 loss_ctc 26.489746 loss_rnnt 14.922440 hw_loss 0.029840 lr 0.00042246 rank 5
2023-02-22 08:11:32,445 DEBUG TRAIN Batch 16/6600 loss 14.251075 loss_att 17.266588 loss_ctc 18.164413 loss_rnnt 13.049550 hw_loss 0.143708 lr 0.00042247 rank 2
2023-02-22 08:12:49,158 DEBUG TRAIN Batch 16/6700 loss 16.039782 loss_att 17.473091 loss_ctc 24.055593 loss_rnnt 14.636458 hw_loss 0.089787 lr 0.00042236 rank 0
2023-02-22 08:12:49,158 DEBUG TRAIN Batch 16/6700 loss 9.103044 loss_att 12.280021 loss_ctc 13.687792 loss_rnnt 7.803563 hw_loss 0.098973 lr 0.00042231 rank 5
2023-02-22 08:12:49,159 DEBUG TRAIN Batch 16/6700 loss 12.221347 loss_att 15.431437 loss_ctc 14.817539 loss_rnnt 11.100010 hw_loss 0.249675 lr 0.00042235 rank 4
2023-02-22 08:12:49,161 DEBUG TRAIN Batch 16/6700 loss 9.073659 loss_att 11.948857 loss_ctc 9.973675 loss_rnnt 8.324665 hw_loss 0.101161 lr 0.00042234 rank 3
2023-02-22 08:12:49,163 DEBUG TRAIN Batch 16/6700 loss 12.070594 loss_att 14.563294 loss_ctc 18.433147 loss_rnnt 10.678371 hw_loss 0.085015 lr 0.00042240 rank 1
2023-02-22 08:12:49,165 DEBUG TRAIN Batch 16/6700 loss 11.891586 loss_att 17.256443 loss_ctc 19.664196 loss_rnnt 9.737937 hw_loss 0.083120 lr 0.00042232 rank 7
2023-02-22 08:12:49,183 DEBUG TRAIN Batch 16/6700 loss 18.918186 loss_att 19.954470 loss_ctc 23.042809 loss_rnnt 18.041576 hw_loss 0.223882 lr 0.00042232 rank 2
2023-02-22 08:12:49,212 DEBUG TRAIN Batch 16/6700 loss 6.320231 loss_att 9.625298 loss_ctc 9.948861 loss_rnnt 5.127853 hw_loss 0.089151 lr 0.00042237 rank 6
2023-02-22 08:14:05,776 DEBUG TRAIN Batch 16/6800 loss 12.911411 loss_att 14.929295 loss_ctc 14.934526 loss_rnnt 12.135206 hw_loss 0.192899 lr 0.00042217 rank 7
2023-02-22 08:14:05,776 DEBUG TRAIN Batch 16/6800 loss 14.636162 loss_att 17.298752 loss_ctc 26.368938 loss_rnnt 12.443278 hw_loss 0.179991 lr 0.00042221 rank 0
2023-02-22 08:14:05,778 DEBUG TRAIN Batch 16/6800 loss 8.792629 loss_att 12.171740 loss_ctc 10.747162 loss_rnnt 7.797845 hw_loss 0.109419 lr 0.00042220 rank 4
2023-02-22 08:14:05,780 DEBUG TRAIN Batch 16/6800 loss 5.424316 loss_att 10.524683 loss_ctc 7.277122 loss_rnnt 4.082386 hw_loss 0.140279 lr 0.00042216 rank 5
2023-02-22 08:14:05,782 DEBUG TRAIN Batch 16/6800 loss 10.719805 loss_att 17.480904 loss_ctc 15.294559 loss_rnnt 8.672458 hw_loss 0.159673 lr 0.00042225 rank 1
2023-02-22 08:14:05,784 DEBUG TRAIN Batch 16/6800 loss 14.081646 loss_att 16.002628 loss_ctc 19.108965 loss_rnnt 12.960445 hw_loss 0.125052 lr 0.00042222 rank 6
2023-02-22 08:14:05,785 DEBUG TRAIN Batch 16/6800 loss 10.850318 loss_att 14.346540 loss_ctc 18.352371 loss_rnnt 9.097530 hw_loss 0.099879 lr 0.00042217 rank 2
2023-02-22 08:14:05,789 DEBUG TRAIN Batch 16/6800 loss 13.431029 loss_att 13.106632 loss_ctc 17.104961 loss_rnnt 12.970828 hw_loss 0.066045 lr 0.00042219 rank 3
2023-02-22 08:15:18,901 DEBUG TRAIN Batch 16/6900 loss 15.423250 loss_att 17.023857 loss_ctc 19.463215 loss_rnnt 14.477308 hw_loss 0.163423 lr 0.00042205 rank 4
2023-02-22 08:15:18,903 DEBUG TRAIN Batch 16/6900 loss 8.951813 loss_att 14.145308 loss_ctc 13.057966 loss_rnnt 7.333381 hw_loss 0.060462 lr 0.00042206 rank 0
2023-02-22 08:15:18,903 DEBUG TRAIN Batch 16/6900 loss 7.261331 loss_att 9.211012 loss_ctc 7.027214 loss_rnnt 6.792007 hw_loss 0.207381 lr 0.00042202 rank 7
2023-02-22 08:15:18,904 DEBUG TRAIN Batch 16/6900 loss 15.534695 loss_att 19.065802 loss_ctc 20.993050 loss_rnnt 13.981767 hw_loss 0.222984 lr 0.00042207 rank 6
2023-02-22 08:15:18,904 DEBUG TRAIN Batch 16/6900 loss 23.075386 loss_att 25.091164 loss_ctc 33.933491 loss_rnnt 21.164310 hw_loss 0.112819 lr 0.00042201 rank 5
2023-02-22 08:15:18,909 DEBUG TRAIN Batch 16/6900 loss 5.033874 loss_att 8.159839 loss_ctc 8.124840 loss_rnnt 3.865094 hw_loss 0.246483 lr 0.00042210 rank 1
2023-02-22 08:15:18,910 DEBUG TRAIN Batch 16/6900 loss 11.014733 loss_att 13.557489 loss_ctc 14.184061 loss_rnnt 9.991785 hw_loss 0.172162 lr 0.00042202 rank 2
2023-02-22 08:15:18,911 DEBUG TRAIN Batch 16/6900 loss 5.988173 loss_att 10.100471 loss_ctc 7.664572 loss_rnnt 4.871354 hw_loss 0.132824 lr 0.00042204 rank 3
2023-02-22 08:16:34,965 DEBUG TRAIN Batch 16/7000 loss 9.175464 loss_att 13.546566 loss_ctc 14.636790 loss_rnnt 7.508405 hw_loss 0.121238 lr 0.00042192 rank 6
2023-02-22 08:16:34,966 DEBUG TRAIN Batch 16/7000 loss 15.973839 loss_att 16.368805 loss_ctc 17.872374 loss_rnnt 15.584767 hw_loss 0.106764 lr 0.00042191 rank 0
2023-02-22 08:16:34,968 DEBUG TRAIN Batch 16/7000 loss 21.002556 loss_att 24.472057 loss_ctc 32.844387 loss_rnnt 18.686493 hw_loss 0.081097 lr 0.00042187 rank 7
2023-02-22 08:16:34,968 DEBUG TRAIN Batch 16/7000 loss 8.251283 loss_att 9.516474 loss_ctc 13.595549 loss_rnnt 7.191895 hw_loss 0.175842 lr 0.00042186 rank 5
2023-02-22 08:16:34,970 DEBUG TRAIN Batch 16/7000 loss 13.367358 loss_att 15.063556 loss_ctc 15.187076 loss_rnnt 12.711448 hw_loss 0.138828 lr 0.00042190 rank 4
2023-02-22 08:16:34,972 DEBUG TRAIN Batch 16/7000 loss 8.017045 loss_att 11.054301 loss_ctc 9.593016 loss_rnnt 7.139694 hw_loss 0.112069 lr 0.00042187 rank 2
2023-02-22 08:16:34,971 DEBUG TRAIN Batch 16/7000 loss 10.095832 loss_att 12.562159 loss_ctc 14.056607 loss_rnnt 8.994743 hw_loss 0.149474 lr 0.00042195 rank 1
2023-02-22 08:16:35,017 DEBUG TRAIN Batch 16/7000 loss 11.929070 loss_att 15.989876 loss_ctc 13.260317 loss_rnnt 10.869757 hw_loss 0.130598 lr 0.00042189 rank 3
2023-02-22 08:17:53,867 DEBUG TRAIN Batch 16/7100 loss 12.328152 loss_att 11.403257 loss_ctc 12.883336 loss_rnnt 12.327371 hw_loss 0.209502 lr 0.00042176 rank 0
2023-02-22 08:17:53,870 DEBUG TRAIN Batch 16/7100 loss 18.435444 loss_att 22.915182 loss_ctc 23.619787 loss_rnnt 16.798233 hw_loss 0.093785 lr 0.00042175 rank 4
2023-02-22 08:17:53,873 DEBUG TRAIN Batch 16/7100 loss 3.051150 loss_att 6.209225 loss_ctc 2.620094 loss_rnnt 2.400813 hw_loss 0.142867 lr 0.00042172 rank 7
2023-02-22 08:17:53,875 DEBUG TRAIN Batch 16/7100 loss 9.184495 loss_att 12.465561 loss_ctc 10.052101 loss_rnnt 8.379240 hw_loss 0.062551 lr 0.00042174 rank 3
2023-02-22 08:17:53,877 DEBUG TRAIN Batch 16/7100 loss 5.059815 loss_att 8.156598 loss_ctc 5.809050 loss_rnnt 4.324094 hw_loss 0.030874 lr 0.00042171 rank 5
2023-02-22 08:17:53,880 DEBUG TRAIN Batch 16/7100 loss 7.099579 loss_att 11.468805 loss_ctc 9.161186 loss_rnnt 5.899586 hw_loss 0.096127 lr 0.00042177 rank 6
2023-02-22 08:17:53,887 DEBUG TRAIN Batch 16/7100 loss 4.075083 loss_att 6.984494 loss_ctc 5.467126 loss_rnnt 3.251686 hw_loss 0.104829 lr 0.00042180 rank 1
2023-02-22 08:17:53,890 DEBUG TRAIN Batch 16/7100 loss 4.369784 loss_att 6.796656 loss_ctc 5.813916 loss_rnnt 3.636930 hw_loss 0.102991 lr 0.00042172 rank 2
2023-02-22 08:19:08,617 DEBUG TRAIN Batch 16/7200 loss 8.861740 loss_att 12.182257 loss_ctc 10.845970 loss_rnnt 7.848303 hw_loss 0.158944 lr 0.00042157 rank 7
2023-02-22 08:19:08,622 DEBUG TRAIN Batch 16/7200 loss 13.464381 loss_att 17.641644 loss_ctc 16.631630 loss_rnnt 12.158652 hw_loss 0.089955 lr 0.00042160 rank 4
2023-02-22 08:19:08,624 DEBUG TRAIN Batch 16/7200 loss 9.406717 loss_att 12.934642 loss_ctc 14.689573 loss_rnnt 7.959599 hw_loss 0.069660 lr 0.00042156 rank 5
2023-02-22 08:19:08,626 DEBUG TRAIN Batch 16/7200 loss 4.573414 loss_att 5.947171 loss_ctc 6.648115 loss_rnnt 3.956910 hw_loss 0.122112 lr 0.00042165 rank 1
2023-02-22 08:19:08,627 DEBUG TRAIN Batch 16/7200 loss 13.752447 loss_att 14.762329 loss_ctc 19.427496 loss_rnnt 12.716690 hw_loss 0.144574 lr 0.00042157 rank 2
2023-02-22 08:19:08,628 DEBUG TRAIN Batch 16/7200 loss 9.895813 loss_att 13.788960 loss_ctc 15.040339 loss_rnnt 8.409611 hw_loss 0.040568 lr 0.00042161 rank 0
2023-02-22 08:19:08,630 DEBUG TRAIN Batch 16/7200 loss 14.355075 loss_att 15.953588 loss_ctc 19.844639 loss_rnnt 13.192505 hw_loss 0.207985 lr 0.00042159 rank 3
2023-02-22 08:19:08,676 DEBUG TRAIN Batch 16/7200 loss 17.336426 loss_att 18.643236 loss_ctc 20.960747 loss_rnnt 16.587471 hw_loss 0.008155 lr 0.00042162 rank 6
2023-02-22 08:20:24,515 DEBUG TRAIN Batch 16/7300 loss 8.318300 loss_att 10.049808 loss_ctc 13.688438 loss_rnnt 7.181830 hw_loss 0.139032 lr 0.00042141 rank 5
2023-02-22 08:20:24,522 DEBUG TRAIN Batch 16/7300 loss 13.827461 loss_att 16.524223 loss_ctc 20.036333 loss_rnnt 12.389335 hw_loss 0.132982 lr 0.00042146 rank 0
2023-02-22 08:20:24,524 DEBUG TRAIN Batch 16/7300 loss 9.673341 loss_att 12.567385 loss_ctc 12.942370 loss_rnnt 8.658585 hw_loss 0.000144 lr 0.00042147 rank 6
2023-02-22 08:20:24,523 DEBUG TRAIN Batch 16/7300 loss 8.451912 loss_att 10.733452 loss_ctc 12.414995 loss_rnnt 7.393931 hw_loss 0.137365 lr 0.00042145 rank 4
2023-02-22 08:20:24,524 DEBUG TRAIN Batch 16/7300 loss 7.084455 loss_att 7.943521 loss_ctc 7.850345 loss_rnnt 6.744274 hw_loss 0.124215 lr 0.00042142 rank 7
2023-02-22 08:20:24,526 DEBUG TRAIN Batch 16/7300 loss 9.726061 loss_att 11.304323 loss_ctc 14.358569 loss_rnnt 8.738277 hw_loss 0.102120 lr 0.00042144 rank 3
2023-02-22 08:20:24,527 DEBUG TRAIN Batch 16/7300 loss 17.442404 loss_att 21.929420 loss_ctc 25.149826 loss_rnnt 15.475260 hw_loss 0.078905 lr 0.00042142 rank 2
2023-02-22 08:20:24,571 DEBUG TRAIN Batch 16/7300 loss 8.962957 loss_att 11.684346 loss_ctc 11.248691 loss_rnnt 8.023688 hw_loss 0.169174 lr 0.00042150 rank 1
2023-02-22 08:21:41,194 DEBUG TRAIN Batch 16/7400 loss 6.378315 loss_att 9.986878 loss_ctc 10.935534 loss_rnnt 4.979880 hw_loss 0.129551 lr 0.00042126 rank 5
2023-02-22 08:21:41,195 DEBUG TRAIN Batch 16/7400 loss 11.972632 loss_att 15.933699 loss_ctc 16.072935 loss_rnnt 10.535727 hw_loss 0.183723 lr 0.00042131 rank 0
2023-02-22 08:21:41,197 DEBUG TRAIN Batch 16/7400 loss 5.665137 loss_att 9.211799 loss_ctc 8.925512 loss_rnnt 4.421636 hw_loss 0.186473 lr 0.00042127 rank 2
2023-02-22 08:21:41,197 DEBUG TRAIN Batch 16/7400 loss 12.389344 loss_att 13.675306 loss_ctc 20.671974 loss_rnnt 10.940201 hw_loss 0.164249 lr 0.00042132 rank 6
2023-02-22 08:21:41,196 DEBUG TRAIN Batch 16/7400 loss 15.130994 loss_att 18.593019 loss_ctc 20.143318 loss_rnnt 13.753038 hw_loss 0.032326 lr 0.00042135 rank 1
2023-02-22 08:21:41,198 DEBUG TRAIN Batch 16/7400 loss 10.230507 loss_att 13.193163 loss_ctc 13.591410 loss_rnnt 9.158545 hw_loss 0.058707 lr 0.00042127 rank 7
2023-02-22 08:21:41,202 DEBUG TRAIN Batch 16/7400 loss 8.058798 loss_att 12.231179 loss_ctc 11.109880 loss_rnnt 6.752266 hw_loss 0.122332 lr 0.00042129 rank 3
2023-02-22 08:21:41,202 DEBUG TRAIN Batch 16/7400 loss 6.709219 loss_att 10.469672 loss_ctc 8.929871 loss_rnnt 5.597703 hw_loss 0.118758 lr 0.00042130 rank 4
2023-02-22 08:22:59,597 DEBUG TRAIN Batch 16/7500 loss 9.579922 loss_att 13.504228 loss_ctc 11.564676 loss_rnnt 8.474106 hw_loss 0.105600 lr 0.00042115 rank 4
2023-02-22 08:22:59,599 DEBUG TRAIN Batch 16/7500 loss 17.475737 loss_att 19.228758 loss_ctc 23.079678 loss_rnnt 16.336090 hw_loss 0.078469 lr 0.00042120 rank 1
2023-02-22 08:22:59,599 DEBUG TRAIN Batch 16/7500 loss 6.044371 loss_att 8.772129 loss_ctc 7.658478 loss_rnnt 5.223136 hw_loss 0.113378 lr 0.00042116 rank 0
2023-02-22 08:22:59,599 DEBUG TRAIN Batch 16/7500 loss 3.309026 loss_att 6.075663 loss_ctc 5.022055 loss_rnnt 2.484233 hw_loss 0.080739 lr 0.00042111 rank 5
2023-02-22 08:22:59,600 DEBUG TRAIN Batch 16/7500 loss 11.246899 loss_att 11.229143 loss_ctc 15.012019 loss_rnnt 10.706649 hw_loss 0.078347 lr 0.00042112 rank 2
2023-02-22 08:22:59,600 DEBUG TRAIN Batch 16/7500 loss 14.077292 loss_att 16.821085 loss_ctc 16.730869 loss_rnnt 13.091937 hw_loss 0.155226 lr 0.00042112 rank 7
2023-02-22 08:22:59,605 DEBUG TRAIN Batch 16/7500 loss 8.487719 loss_att 8.337221 loss_ctc 11.077710 loss_rnnt 8.067908 hw_loss 0.196086 lr 0.00042114 rank 3
2023-02-22 08:22:59,652 DEBUG TRAIN Batch 16/7500 loss 9.387693 loss_att 11.859131 loss_ctc 12.079362 loss_rnnt 8.500944 hw_loss 0.062948 lr 0.00042117 rank 6
2023-02-22 08:24:15,511 DEBUG TRAIN Batch 16/7600 loss 10.660036 loss_att 12.199500 loss_ctc 16.611866 loss_rnnt 9.540849 hw_loss 0.033221 lr 0.00042096 rank 5
2023-02-22 08:24:15,512 DEBUG TRAIN Batch 16/7600 loss 10.189489 loss_att 12.648067 loss_ctc 13.921892 loss_rnnt 9.121948 hw_loss 0.146572 lr 0.00042100 rank 4
2023-02-22 08:24:15,514 DEBUG TRAIN Batch 16/7600 loss 11.130235 loss_att 14.430019 loss_ctc 14.380460 loss_rnnt 9.969775 hw_loss 0.125888 lr 0.00042102 rank 6
2023-02-22 08:24:15,516 DEBUG TRAIN Batch 16/7600 loss 10.617311 loss_att 13.590004 loss_ctc 11.253703 loss_rnnt 9.869629 hw_loss 0.128046 lr 0.00042101 rank 0
2023-02-22 08:24:15,518 DEBUG TRAIN Batch 16/7600 loss 10.657159 loss_att 11.918507 loss_ctc 14.804735 loss_rnnt 9.812546 hw_loss 0.073750 lr 0.00042097 rank 7
2023-02-22 08:24:15,524 DEBUG TRAIN Batch 16/7600 loss 12.066793 loss_att 14.194017 loss_ctc 14.947838 loss_rnnt 11.203930 hw_loss 0.099900 lr 0.00042105 rank 1
2023-02-22 08:24:15,524 DEBUG TRAIN Batch 16/7600 loss 6.425970 loss_att 8.790676 loss_ctc 6.671426 loss_rnnt 5.801823 hw_loss 0.222145 lr 0.00042099 rank 3
2023-02-22 08:24:15,530 DEBUG TRAIN Batch 16/7600 loss 16.183731 loss_att 19.750498 loss_ctc 20.795364 loss_rnnt 14.798429 hw_loss 0.106995 lr 0.00042097 rank 2
2023-02-22 08:25:31,480 DEBUG TRAIN Batch 16/7700 loss 19.722052 loss_att 24.552908 loss_ctc 33.553562 loss_rnnt 16.875767 hw_loss 0.067341 lr 0.00042085 rank 4
2023-02-22 08:25:31,482 DEBUG TRAIN Batch 16/7700 loss 7.355791 loss_att 12.827984 loss_ctc 13.155296 loss_rnnt 5.399919 hw_loss 0.165310 lr 0.00042081 rank 5
2023-02-22 08:25:31,482 DEBUG TRAIN Batch 16/7700 loss 5.707966 loss_att 8.319681 loss_ctc 6.519163 loss_rnnt 5.044729 hw_loss 0.061377 lr 0.00042084 rank 3
2023-02-22 08:25:31,482 DEBUG TRAIN Batch 16/7700 loss 9.859262 loss_att 12.598735 loss_ctc 11.142065 loss_rnnt 9.073721 hw_loss 0.124885 lr 0.00042082 rank 7
2023-02-22 08:25:31,483 DEBUG TRAIN Batch 16/7700 loss 12.542987 loss_att 17.574265 loss_ctc 18.930403 loss_rnnt 10.624585 hw_loss 0.113417 lr 0.00042086 rank 0
2023-02-22 08:25:31,483 DEBUG TRAIN Batch 16/7700 loss 11.664378 loss_att 12.405619 loss_ctc 15.723860 loss_rnnt 10.828375 hw_loss 0.274673 lr 0.00042090 rank 1
2023-02-22 08:25:31,484 DEBUG TRAIN Batch 16/7700 loss 8.208624 loss_att 11.475703 loss_ctc 16.260115 loss_rnnt 6.461114 hw_loss 0.038553 lr 0.00042087 rank 6
2023-02-22 08:25:31,533 DEBUG TRAIN Batch 16/7700 loss 16.082758 loss_att 18.886662 loss_ctc 22.340298 loss_rnnt 14.625681 hw_loss 0.116174 lr 0.00042083 rank 2
2023-02-22 08:26:49,768 DEBUG TRAIN Batch 16/7800 loss 8.853294 loss_att 11.267342 loss_ctc 11.797262 loss_rnnt 7.944442 hw_loss 0.062841 lr 0.00042067 rank 7
2023-02-22 08:26:49,774 DEBUG TRAIN Batch 16/7800 loss 7.339183 loss_att 9.988210 loss_ctc 10.015409 loss_rnnt 6.383806 hw_loss 0.128891 lr 0.00042070 rank 4
2023-02-22 08:26:49,776 DEBUG TRAIN Batch 16/7800 loss 7.386672 loss_att 8.880069 loss_ctc 8.997310 loss_rnnt 6.798492 hw_loss 0.140154 lr 0.00042072 rank 6
2023-02-22 08:26:49,778 DEBUG TRAIN Batch 16/7800 loss 11.936961 loss_att 14.687931 loss_ctc 16.871971 loss_rnnt 10.686979 hw_loss 0.078353 lr 0.00042066 rank 5
2023-02-22 08:26:49,781 DEBUG TRAIN Batch 16/7800 loss 25.138580 loss_att 22.746880 loss_ctc 32.981304 loss_rnnt 24.535610 hw_loss 0.066777 lr 0.00042075 rank 1
2023-02-22 08:26:49,784 DEBUG TRAIN Batch 16/7800 loss 7.780599 loss_att 11.021863 loss_ctc 11.907619 loss_rnnt 6.538098 hw_loss 0.082460 lr 0.00042069 rank 3
2023-02-22 08:26:49,786 DEBUG TRAIN Batch 16/7800 loss 6.603287 loss_att 10.733886 loss_ctc 11.775726 loss_rnnt 5.018810 hw_loss 0.128809 lr 0.00042071 rank 0
2023-02-22 08:26:49,827 DEBUG TRAIN Batch 16/7800 loss 8.101624 loss_att 11.257163 loss_ctc 13.790748 loss_rnnt 6.696813 hw_loss 0.028412 lr 0.00042068 rank 2
2023-02-22 08:28:06,447 DEBUG TRAIN Batch 16/7900 loss 8.988009 loss_att 11.937561 loss_ctc 13.087691 loss_rnnt 7.771251 hw_loss 0.150420 lr 0.00042056 rank 0
2023-02-22 08:28:06,447 DEBUG TRAIN Batch 16/7900 loss 12.406382 loss_att 18.348228 loss_ctc 16.470238 loss_rnnt 10.621506 hw_loss 0.102483 lr 0.00042060 rank 1
2023-02-22 08:28:06,448 DEBUG TRAIN Batch 16/7900 loss 6.734856 loss_att 9.808099 loss_ctc 8.368271 loss_rnnt 5.902370 hw_loss 0.000090 lr 0.00042052 rank 5
2023-02-22 08:28:06,449 DEBUG TRAIN Batch 16/7900 loss 10.253799 loss_att 16.206749 loss_ctc 11.603708 loss_rnnt 8.876278 hw_loss 0.013019 lr 0.00042055 rank 4
2023-02-22 08:28:06,452 DEBUG TRAIN Batch 16/7900 loss 10.223166 loss_att 13.899611 loss_ctc 14.487862 loss_rnnt 8.870037 hw_loss 0.092276 lr 0.00042058 rank 6
2023-02-22 08:28:06,455 DEBUG TRAIN Batch 16/7900 loss 8.440855 loss_att 13.190035 loss_ctc 11.174103 loss_rnnt 7.084949 hw_loss 0.078071 lr 0.00042053 rank 2
2023-02-22 08:28:06,455 DEBUG TRAIN Batch 16/7900 loss 9.971080 loss_att 12.803141 loss_ctc 12.692036 loss_rnnt 8.961714 hw_loss 0.150298 lr 0.00042052 rank 7
2023-02-22 08:28:06,501 DEBUG TRAIN Batch 16/7900 loss 16.733093 loss_att 21.092979 loss_ctc 26.586727 loss_rnnt 14.471132 hw_loss 0.142814 lr 0.00042054 rank 3
2023-02-22 08:29:20,824 DEBUG TRAIN Batch 16/8000 loss 11.252370 loss_att 13.760624 loss_ctc 15.700123 loss_rnnt 10.084873 hw_loss 0.136522 lr 0.00042040 rank 4
2023-02-22 08:29:20,825 DEBUG TRAIN Batch 16/8000 loss 6.936164 loss_att 9.790907 loss_ctc 12.224682 loss_rnnt 5.618649 hw_loss 0.077680 lr 0.00042039 rank 3
2023-02-22 08:29:20,830 DEBUG TRAIN Batch 16/8000 loss 18.434650 loss_att 22.333925 loss_ctc 25.404200 loss_rnnt 16.698164 hw_loss 0.051299 lr 0.00042042 rank 0
2023-02-22 08:29:20,830 DEBUG TRAIN Batch 16/8000 loss 8.000068 loss_att 12.308616 loss_ctc 10.859615 loss_rnnt 6.698840 hw_loss 0.109209 lr 0.00042037 rank 7
2023-02-22 08:29:20,831 DEBUG TRAIN Batch 16/8000 loss 11.788356 loss_att 16.383192 loss_ctc 14.326485 loss_rnnt 10.453444 hw_loss 0.145366 lr 0.00042037 rank 5
2023-02-22 08:29:20,832 DEBUG TRAIN Batch 16/8000 loss 15.075896 loss_att 19.286999 loss_ctc 23.276144 loss_rnnt 13.077699 hw_loss 0.117394 lr 0.00042043 rank 6
2023-02-22 08:29:20,833 DEBUG TRAIN Batch 16/8000 loss 13.273259 loss_att 16.782501 loss_ctc 15.834975 loss_rnnt 12.201334 hw_loss 0.053464 lr 0.00042038 rank 2
2023-02-22 08:29:20,832 DEBUG TRAIN Batch 16/8000 loss 17.603624 loss_att 19.542000 loss_ctc 20.765930 loss_rnnt 16.686682 hw_loss 0.201804 lr 0.00042046 rank 1
2023-02-22 08:30:35,768 DEBUG TRAIN Batch 16/8100 loss 7.229859 loss_att 12.636093 loss_ctc 7.674398 loss_rnnt 6.068813 hw_loss 0.038489 lr 0.00042022 rank 5
2023-02-22 08:30:35,773 DEBUG TRAIN Batch 16/8100 loss 9.111171 loss_att 12.882727 loss_ctc 13.040849 loss_rnnt 7.763388 hw_loss 0.130340 lr 0.00042027 rank 0
2023-02-22 08:30:35,774 DEBUG TRAIN Batch 16/8100 loss 9.899524 loss_att 12.647007 loss_ctc 13.639692 loss_rnnt 8.815251 hw_loss 0.067660 lr 0.00042023 rank 7
2023-02-22 08:30:35,773 DEBUG TRAIN Batch 16/8100 loss 11.835712 loss_att 10.996696 loss_ctc 13.041270 loss_rnnt 11.817129 hw_loss 0.048087 lr 0.00042025 rank 3
2023-02-22 08:30:35,778 DEBUG TRAIN Batch 16/8100 loss 12.224805 loss_att 14.896194 loss_ctc 14.212564 loss_rnnt 11.401915 hw_loss 0.044210 lr 0.00042026 rank 4
2023-02-22 08:30:35,778 DEBUG TRAIN Batch 16/8100 loss 16.696381 loss_att 22.983974 loss_ctc 25.287556 loss_rnnt 14.239174 hw_loss 0.101624 lr 0.00042031 rank 1
2023-02-22 08:30:35,780 DEBUG TRAIN Batch 16/8100 loss 12.757437 loss_att 15.172573 loss_ctc 18.115402 loss_rnnt 11.460493 hw_loss 0.186600 lr 0.00042023 rank 2
2023-02-22 08:30:35,787 DEBUG TRAIN Batch 16/8100 loss 13.588250 loss_att 15.907217 loss_ctc 15.327573 loss_rnnt 12.864157 hw_loss 0.053235 lr 0.00042028 rank 6
2023-02-22 08:31:51,615 DEBUG TRAIN Batch 16/8200 loss 20.436392 loss_att 21.572195 loss_ctc 28.310274 loss_rnnt 19.099848 hw_loss 0.111625 lr 0.00042012 rank 0
2023-02-22 08:31:51,618 DEBUG TRAIN Batch 16/8200 loss 13.592917 loss_att 17.250530 loss_ctc 20.852449 loss_rnnt 11.832280 hw_loss 0.114705 lr 0.00042016 rank 1
2023-02-22 08:31:51,622 DEBUG TRAIN Batch 16/8200 loss 7.136252 loss_att 9.410555 loss_ctc 10.982704 loss_rnnt 6.074734 hw_loss 0.175869 lr 0.00042008 rank 7
2023-02-22 08:31:51,622 DEBUG TRAIN Batch 16/8200 loss 24.365784 loss_att 25.474476 loss_ctc 33.584419 loss_rnnt 22.861795 hw_loss 0.099557 lr 0.00042011 rank 4
2023-02-22 08:31:51,625 DEBUG TRAIN Batch 16/8200 loss 11.281756 loss_att 17.562172 loss_ctc 14.277213 loss_rnnt 9.601007 hw_loss 0.047386 lr 0.00042013 rank 6
2023-02-22 08:31:51,625 DEBUG TRAIN Batch 16/8200 loss 29.290775 loss_att 29.187435 loss_ctc 34.392639 loss_rnnt 28.565147 hw_loss 0.123836 lr 0.00042007 rank 5
2023-02-22 08:31:51,628 DEBUG TRAIN Batch 16/8200 loss 6.367576 loss_att 10.847908 loss_ctc 10.895007 loss_rnnt 4.763766 hw_loss 0.195160 lr 0.00042010 rank 3
2023-02-22 08:31:51,630 DEBUG TRAIN Batch 16/8200 loss 6.577140 loss_att 7.050298 loss_ctc 9.205153 loss_rnnt 6.038637 hw_loss 0.175256 lr 0.00042008 rank 2
2023-02-22 08:33:05,658 DEBUG TRAIN Batch 16/8300 loss 14.605111 loss_att 17.152504 loss_ctc 22.577017 loss_rnnt 12.984118 hw_loss 0.091111 lr 0.00042001 rank 1
2023-02-22 08:33:05,658 DEBUG TRAIN Batch 16/8300 loss 11.928941 loss_att 12.687045 loss_ctc 16.515284 loss_rnnt 11.097990 hw_loss 0.127157 lr 0.00041993 rank 7
2023-02-22 08:33:05,659 DEBUG TRAIN Batch 16/8300 loss 8.526769 loss_att 12.974655 loss_ctc 10.027785 loss_rnnt 7.356915 hw_loss 0.150266 lr 0.00041997 rank 0
2023-02-22 08:33:05,662 DEBUG TRAIN Batch 16/8300 loss 9.384153 loss_att 10.693629 loss_ctc 12.895885 loss_rnnt 8.606219 hw_loss 0.089641 lr 0.00041996 rank 4
2023-02-22 08:33:05,662 DEBUG TRAIN Batch 16/8300 loss 9.429601 loss_att 12.725374 loss_ctc 15.614052 loss_rnnt 7.888969 hw_loss 0.106656 lr 0.00041992 rank 5
2023-02-22 08:33:05,664 DEBUG TRAIN Batch 16/8300 loss 11.793118 loss_att 14.956671 loss_ctc 19.031118 loss_rnnt 10.129148 hw_loss 0.124108 lr 0.00041995 rank 3
2023-02-22 08:33:05,666 DEBUG TRAIN Batch 16/8300 loss 19.901796 loss_att 22.120520 loss_ctc 28.745419 loss_rnnt 18.224266 hw_loss 0.102438 lr 0.00041998 rank 6
2023-02-22 08:33:05,667 DEBUG TRAIN Batch 16/8300 loss 14.230514 loss_att 17.421759 loss_ctc 25.185644 loss_rnnt 12.120693 hw_loss 0.020413 lr 0.00041993 rank 2
2023-02-22 08:34:01,393 DEBUG CV Batch 16/0 loss 2.136414 loss_att 2.337836 loss_ctc 2.481229 loss_rnnt 1.960156 hw_loss 0.168746 history loss 2.057287 rank 3
2023-02-22 08:34:01,402 DEBUG CV Batch 16/0 loss 2.136414 loss_att 2.337836 loss_ctc 2.481229 loss_rnnt 1.960156 hw_loss 0.168746 history loss 2.057287 rank 2
2023-02-22 08:34:01,405 DEBUG CV Batch 16/0 loss 2.136414 loss_att 2.337836 loss_ctc 2.481229 loss_rnnt 1.960156 hw_loss 0.168746 history loss 2.057287 rank 5
2023-02-22 08:34:01,410 DEBUG CV Batch 16/0 loss 2.136414 loss_att 2.337836 loss_ctc 2.481229 loss_rnnt 1.960156 hw_loss 0.168746 history loss 2.057287 rank 1
2023-02-22 08:34:01,412 DEBUG CV Batch 16/0 loss 2.136414 loss_att 2.337836 loss_ctc 2.481229 loss_rnnt 1.960156 hw_loss 0.168746 history loss 2.057287 rank 0
2023-02-22 08:34:01,426 DEBUG CV Batch 16/0 loss 2.136414 loss_att 2.337836 loss_ctc 2.481229 loss_rnnt 1.960156 hw_loss 0.168746 history loss 2.057287 rank 6
2023-02-22 08:34:01,431 DEBUG CV Batch 16/0 loss 2.136414 loss_att 2.337836 loss_ctc 2.481229 loss_rnnt 1.960156 hw_loss 0.168746 history loss 2.057287 rank 4
2023-02-22 08:34:01,436 DEBUG CV Batch 16/0 loss 2.136414 loss_att 2.337836 loss_ctc 2.481229 loss_rnnt 1.960156 hw_loss 0.168746 history loss 2.057287 rank 7
2023-02-22 08:34:12,551 DEBUG CV Batch 16/100 loss 9.851789 loss_att 7.870838 loss_ctc 11.135880 loss_rnnt 9.982271 hw_loss 0.177178 history loss 3.853278 rank 0
2023-02-22 08:34:12,567 DEBUG CV Batch 16/100 loss 9.851789 loss_att 7.870838 loss_ctc 11.135880 loss_rnnt 9.982271 hw_loss 0.177178 history loss 3.853278 rank 4
2023-02-22 08:34:12,570 DEBUG CV Batch 16/100 loss 9.851789 loss_att 7.870838 loss_ctc 11.135880 loss_rnnt 9.982271 hw_loss 0.177178 history loss 3.853278 rank 7
2023-02-22 08:34:12,595 DEBUG CV Batch 16/100 loss 9.851789 loss_att 7.870838 loss_ctc 11.135880 loss_rnnt 9.982271 hw_loss 0.177178 history loss 3.853278 rank 5
2023-02-22 08:34:12,698 DEBUG CV Batch 16/100 loss 9.851789 loss_att 7.870838 loss_ctc 11.135880 loss_rnnt 9.982271 hw_loss 0.177178 history loss 3.853278 rank 3
2023-02-22 08:34:12,709 DEBUG CV Batch 16/100 loss 9.851789 loss_att 7.870838 loss_ctc 11.135880 loss_rnnt 9.982271 hw_loss 0.177178 history loss 3.853278 rank 1
2023-02-22 08:34:12,805 DEBUG CV Batch 16/100 loss 9.851789 loss_att 7.870838 loss_ctc 11.135880 loss_rnnt 9.982271 hw_loss 0.177178 history loss 3.853278 rank 6
2023-02-22 08:34:13,958 DEBUG CV Batch 16/100 loss 9.851789 loss_att 7.870838 loss_ctc 11.135880 loss_rnnt 9.982271 hw_loss 0.177178 history loss 3.853278 rank 2
2023-02-22 08:34:25,860 DEBUG CV Batch 16/200 loss 6.361917 loss_att 12.679217 loss_ctc 6.040176 loss_rnnt 5.100546 hw_loss 0.076518 history loss 4.461610 rank 0
2023-02-22 08:34:25,896 DEBUG CV Batch 16/200 loss 6.361917 loss_att 12.679217 loss_ctc 6.040176 loss_rnnt 5.100546 hw_loss 0.076518 history loss 4.461610 rank 7
2023-02-22 08:34:25,897 DEBUG CV Batch 16/200 loss 6.361917 loss_att 12.679217 loss_ctc 6.040176 loss_rnnt 5.100546 hw_loss 0.076518 history loss 4.461610 rank 4
2023-02-22 08:34:25,971 DEBUG CV Batch 16/200 loss 6.361917 loss_att 12.679217 loss_ctc 6.040176 loss_rnnt 5.100546 hw_loss 0.076518 history loss 4.461610 rank 5
2023-02-22 08:34:26,132 DEBUG CV Batch 16/200 loss 6.361917 loss_att 12.679217 loss_ctc 6.040176 loss_rnnt 5.100546 hw_loss 0.076518 history loss 4.461610 rank 1
2023-02-22 08:34:26,247 DEBUG CV Batch 16/200 loss 6.361917 loss_att 12.679217 loss_ctc 6.040176 loss_rnnt 5.100546 hw_loss 0.076518 history loss 4.461610 rank 3
2023-02-22 08:34:26,256 DEBUG CV Batch 16/200 loss 6.361917 loss_att 12.679217 loss_ctc 6.040176 loss_rnnt 5.100546 hw_loss 0.076518 history loss 4.461610 rank 6
2023-02-22 08:34:27,738 DEBUG CV Batch 16/200 loss 6.361917 loss_att 12.679217 loss_ctc 6.040176 loss_rnnt 5.100546 hw_loss 0.076518 history loss 4.461610 rank 2
2023-02-22 08:34:37,917 DEBUG CV Batch 16/300 loss 6.174325 loss_att 5.785604 loss_ctc 7.252753 loss_rnnt 6.031254 hw_loss 0.144419 history loss 4.577204 rank 0
2023-02-22 08:34:37,949 DEBUG CV Batch 16/300 loss 6.174325 loss_att 5.785604 loss_ctc 7.252753 loss_rnnt 6.031254 hw_loss 0.144419 history loss 4.577204 rank 7
2023-02-22 08:34:37,974 DEBUG CV Batch 16/300 loss 6.174325 loss_att 5.785604 loss_ctc 7.252753 loss_rnnt 6.031254 hw_loss 0.144419 history loss 4.577204 rank 4
2023-02-22 08:34:38,113 DEBUG CV Batch 16/300 loss 6.174325 loss_att 5.785604 loss_ctc 7.252753 loss_rnnt 6.031254 hw_loss 0.144419 history loss 4.577204 rank 5
2023-02-22 08:34:38,324 DEBUG CV Batch 16/300 loss 6.174325 loss_att 5.785604 loss_ctc 7.252753 loss_rnnt 6.031254 hw_loss 0.144419 history loss 4.577204 rank 1
2023-02-22 08:34:38,386 DEBUG CV Batch 16/300 loss 6.174325 loss_att 5.785604 loss_ctc 7.252753 loss_rnnt 6.031254 hw_loss 0.144419 history loss 4.577204 rank 3
2023-02-22 08:34:38,508 DEBUG CV Batch 16/300 loss 6.174325 loss_att 5.785604 loss_ctc 7.252753 loss_rnnt 6.031254 hw_loss 0.144419 history loss 4.577204 rank 6
2023-02-22 08:34:40,065 DEBUG CV Batch 16/300 loss 6.174325 loss_att 5.785604 loss_ctc 7.252753 loss_rnnt 6.031254 hw_loss 0.144419 history loss 4.577204 rank 2
2023-02-22 08:34:49,968 DEBUG CV Batch 16/400 loss 23.340059 loss_att 96.805412 loss_ctc 12.215998 loss_rnnt 10.129774 hw_loss 0.000790 history loss 5.583095 rank 0
2023-02-22 08:34:50,009 DEBUG CV Batch 16/400 loss 23.340059 loss_att 96.805412 loss_ctc 12.215998 loss_rnnt 10.129774 hw_loss 0.000790 history loss 5.583095 rank 4
2023-02-22 08:34:50,033 DEBUG CV Batch 16/400 loss 23.340059 loss_att 96.805412 loss_ctc 12.215998 loss_rnnt 10.129774 hw_loss 0.000790 history loss 5.583095 rank 7
2023-02-22 08:34:50,189 DEBUG CV Batch 16/400 loss 23.340059 loss_att 96.805412 loss_ctc 12.215998 loss_rnnt 10.129774 hw_loss 0.000790 history loss 5.583095 rank 5
2023-02-22 08:34:50,520 DEBUG CV Batch 16/400 loss 23.340059 loss_att 96.805412 loss_ctc 12.215998 loss_rnnt 10.129774 hw_loss 0.000790 history loss 5.583095 rank 1
2023-02-22 08:34:50,718 DEBUG CV Batch 16/400 loss 23.340059 loss_att 96.805412 loss_ctc 12.215998 loss_rnnt 10.129774 hw_loss 0.000790 history loss 5.583095 rank 3
2023-02-22 08:34:50,784 DEBUG CV Batch 16/400 loss 23.340059 loss_att 96.805412 loss_ctc 12.215998 loss_rnnt 10.129774 hw_loss 0.000790 history loss 5.583095 rank 6
2023-02-22 08:34:52,339 DEBUG CV Batch 16/400 loss 23.340059 loss_att 96.805412 loss_ctc 12.215998 loss_rnnt 10.129774 hw_loss 0.000790 history loss 5.583095 rank 2
2023-02-22 08:35:00,375 DEBUG CV Batch 16/500 loss 4.702563 loss_att 6.221889 loss_ctc 6.538764 loss_rnnt 4.103188 hw_loss 0.095032 history loss 6.411385 rank 0
2023-02-22 08:35:00,531 DEBUG CV Batch 16/500 loss 4.702563 loss_att 6.221889 loss_ctc 6.538764 loss_rnnt 4.103188 hw_loss 0.095032 history loss 6.411385 rank 7
2023-02-22 08:35:00,560 DEBUG CV Batch 16/500 loss 4.702563 loss_att 6.221889 loss_ctc 6.538764 loss_rnnt 4.103188 hw_loss 0.095032 history loss 6.411385 rank 4
2023-02-22 08:35:00,808 DEBUG CV Batch 16/500 loss 4.702563 loss_att 6.221889 loss_ctc 6.538764 loss_rnnt 4.103188 hw_loss 0.095032 history loss 6.411385 rank 5
2023-02-22 08:35:01,194 DEBUG CV Batch 16/500 loss 4.702563 loss_att 6.221889 loss_ctc 6.538764 loss_rnnt 4.103188 hw_loss 0.095032 history loss 6.411385 rank 1
2023-02-22 08:35:01,450 DEBUG CV Batch 16/500 loss 4.702563 loss_att 6.221889 loss_ctc 6.538764 loss_rnnt 4.103188 hw_loss 0.095032 history loss 6.411385 rank 6
2023-02-22 08:35:01,460 DEBUG CV Batch 16/500 loss 4.702563 loss_att 6.221889 loss_ctc 6.538764 loss_rnnt 4.103188 hw_loss 0.095032 history loss 6.411385 rank 3
2023-02-22 08:35:03,060 DEBUG CV Batch 16/500 loss 4.702563 loss_att 6.221889 loss_ctc 6.538764 loss_rnnt 4.103188 hw_loss 0.095032 history loss 6.411385 rank 2
2023-02-22 08:35:12,482 DEBUG CV Batch 16/600 loss 8.270959 loss_att 8.514479 loss_ctc 10.550151 loss_rnnt 7.798614 hw_loss 0.224528 history loss 7.385052 rank 0
2023-02-22 08:35:12,586 DEBUG CV Batch 16/600 loss 8.270959 loss_att 8.514479 loss_ctc 10.550151 loss_rnnt 7.798614 hw_loss 0.224528 history loss 7.385052 rank 7
2023-02-22 08:35:12,625 DEBUG CV Batch 16/600 loss 8.270959 loss_att 8.514479 loss_ctc 10.550151 loss_rnnt 7.798614 hw_loss 0.224529 history loss 7.385052 rank 4
2023-02-22 08:35:12,986 DEBUG CV Batch 16/600 loss 8.270959 loss_att 8.514479 loss_ctc 10.550151 loss_rnnt 7.798614 hw_loss 0.224528 history loss 7.385052 rank 5
2023-02-22 08:35:13,398 DEBUG CV Batch 16/600 loss 8.270959 loss_att 8.514479 loss_ctc 10.550151 loss_rnnt 7.798614 hw_loss 0.224528 history loss 7.385052 rank 1
2023-02-22 08:35:13,695 DEBUG CV Batch 16/600 loss 8.270959 loss_att 8.514479 loss_ctc 10.550151 loss_rnnt 7.798614 hw_loss 0.224528 history loss 7.385052 rank 3
2023-02-22 08:35:15,151 DEBUG CV Batch 16/600 loss 8.270959 loss_att 8.514479 loss_ctc 10.550151 loss_rnnt 7.798614 hw_loss 0.224528 history loss 7.385052 rank 6
2023-02-22 08:35:15,381 DEBUG CV Batch 16/600 loss 8.270959 loss_att 8.514479 loss_ctc 10.550151 loss_rnnt 7.798614 hw_loss 0.224528 history loss 7.385052 rank 2
2023-02-22 08:35:23,810 DEBUG CV Batch 16/700 loss 20.497099 loss_att 51.366722 loss_ctc 19.314808 loss_rnnt 14.443362 hw_loss 0.070224 history loss 8.130630 rank 0
2023-02-22 08:35:23,947 DEBUG CV Batch 16/700 loss 20.497099 loss_att 51.366722 loss_ctc 19.314808 loss_rnnt 14.443362 hw_loss 0.070224 history loss 8.130630 rank 4
2023-02-22 08:35:23,948 DEBUG CV Batch 16/700 loss 20.497099 loss_att 51.366722 loss_ctc 19.314808 loss_rnnt 14.443362 hw_loss 0.070224 history loss 8.130630 rank 7
2023-02-22 08:35:24,331 DEBUG CV Batch 16/700 loss 20.497099 loss_att 51.366722 loss_ctc 19.314808 loss_rnnt 14.443362 hw_loss 0.070224 history loss 8.130630 rank 5
2023-02-22 08:35:24,935 DEBUG CV Batch 16/700 loss 20.497099 loss_att 51.366722 loss_ctc 19.314808 loss_rnnt 14.443362 hw_loss 0.070224 history loss 8.130630 rank 1
2023-02-22 08:35:25,287 DEBUG CV Batch 16/700 loss 20.497099 loss_att 51.366722 loss_ctc 19.314808 loss_rnnt 14.443362 hw_loss 0.070224 history loss 8.130630 rank 3
2023-02-22 08:35:26,839 DEBUG CV Batch 16/700 loss 20.497099 loss_att 51.366722 loss_ctc 19.314808 loss_rnnt 14.443362 hw_loss 0.070224 history loss 8.130630 rank 2
2023-02-22 08:35:27,277 DEBUG CV Batch 16/700 loss 20.497099 loss_att 51.366722 loss_ctc 19.314808 loss_rnnt 14.443362 hw_loss 0.070224 history loss 8.130630 rank 6
2023-02-22 08:35:34,948 DEBUG CV Batch 16/800 loss 14.359207 loss_att 10.588630 loss_ctc 15.768553 loss_rnnt 14.826068 hw_loss 0.186266 history loss 7.554599 rank 0
2023-02-22 08:35:35,115 DEBUG CV Batch 16/800 loss 14.359207 loss_att 10.588630 loss_ctc 15.768553 loss_rnnt 14.826068 hw_loss 0.186266 history loss 7.554599 rank 7
2023-02-22 08:35:35,149 DEBUG CV Batch 16/800 loss 14.359207 loss_att 10.588630 loss_ctc 15.768553 loss_rnnt 14.826068 hw_loss 0.186266 history loss 7.554599 rank 4
2023-02-22 08:35:35,592 DEBUG CV Batch 16/800 loss 14.359207 loss_att 10.588630 loss_ctc 15.768553 loss_rnnt 14.826068 hw_loss 0.186266 history loss 7.554599 rank 5
2023-02-22 08:35:36,279 DEBUG CV Batch 16/800 loss 14.359207 loss_att 10.588630 loss_ctc 15.768553 loss_rnnt 14.826068 hw_loss 0.186266 history loss 7.554599 rank 1
2023-02-22 08:35:36,862 DEBUG CV Batch 16/800 loss 14.359207 loss_att 10.588630 loss_ctc 15.768553 loss_rnnt 14.826068 hw_loss 0.186266 history loss 7.554599 rank 3
2023-02-22 08:35:38,236 DEBUG CV Batch 16/800 loss 14.359207 loss_att 10.588630 loss_ctc 15.768553 loss_rnnt 14.826068 hw_loss 0.186266 history loss 7.554599 rank 2
2023-02-22 08:35:38,742 DEBUG CV Batch 16/800 loss 14.359207 loss_att 10.588630 loss_ctc 15.768553 loss_rnnt 14.826068 hw_loss 0.186266 history loss 7.554599 rank 6
2023-02-22 08:35:48,279 DEBUG CV Batch 16/900 loss 14.029407 loss_att 15.829273 loss_ctc 21.875299 loss_rnnt 12.596233 hw_loss 0.050777 history loss 7.340251 rank 0
2023-02-22 08:35:48,392 DEBUG CV Batch 16/900 loss 14.029407 loss_att 15.829273 loss_ctc 21.875299 loss_rnnt 12.596233 hw_loss 0.050777 history loss 7.340251 rank 7
2023-02-22 08:35:48,516 DEBUG CV Batch 16/900 loss 14.029407 loss_att 15.829273 loss_ctc 21.875299 loss_rnnt 12.596233 hw_loss 0.050777 history loss 7.340251 rank 4
2023-02-22 08:35:48,868 DEBUG CV Batch 16/900 loss 14.029407 loss_att 15.829273 loss_ctc 21.875299 loss_rnnt 12.596233 hw_loss 0.050777 history loss 7.340251 rank 5
2023-02-22 08:35:49,582 DEBUG CV Batch 16/900 loss 14.029407 loss_att 15.829273 loss_ctc 21.875299 loss_rnnt 12.596233 hw_loss 0.050777 history loss 7.340251 rank 1
2023-02-22 08:35:50,311 DEBUG CV Batch 16/900 loss 14.029407 loss_att 15.829273 loss_ctc 21.875299 loss_rnnt 12.596233 hw_loss 0.050777 history loss 7.340251 rank 3
2023-02-22 08:35:51,625 DEBUG CV Batch 16/900 loss 14.029407 loss_att 15.829273 loss_ctc 21.875299 loss_rnnt 12.596233 hw_loss 0.050777 history loss 7.340251 rank 2
2023-02-22 08:35:52,095 DEBUG CV Batch 16/900 loss 14.029407 loss_att 15.829273 loss_ctc 21.875299 loss_rnnt 12.596233 hw_loss 0.050777 history loss 7.340251 rank 6
2023-02-22 08:36:00,415 DEBUG CV Batch 16/1000 loss 4.094553 loss_att 4.897434 loss_ctc 5.587144 loss_rnnt 3.641609 hw_loss 0.175041 history loss 7.081626 rank 0
2023-02-22 08:36:00,484 DEBUG CV Batch 16/1000 loss 4.094553 loss_att 4.897434 loss_ctc 5.587144 loss_rnnt 3.641609 hw_loss 0.175041 history loss 7.081626 rank 7
2023-02-22 08:36:00,624 DEBUG CV Batch 16/1000 loss 4.094553 loss_att 4.897434 loss_ctc 5.587144 loss_rnnt 3.641609 hw_loss 0.175041 history loss 7.081626 rank 4
2023-02-22 08:36:01,121 DEBUG CV Batch 16/1000 loss 4.094553 loss_att 4.897434 loss_ctc 5.587144 loss_rnnt 3.641609 hw_loss 0.175041 history loss 7.081626 rank 5
2023-02-22 08:36:02,169 DEBUG CV Batch 16/1000 loss 4.094553 loss_att 4.897434 loss_ctc 5.587144 loss_rnnt 3.641609 hw_loss 0.175041 history loss 7.081626 rank 1
2023-02-22 08:36:02,786 DEBUG CV Batch 16/1000 loss 4.094553 loss_att 4.897434 loss_ctc 5.587144 loss_rnnt 3.641609 hw_loss 0.175041 history loss 7.081626 rank 3
2023-02-22 08:36:04,167 DEBUG CV Batch 16/1000 loss 4.094553 loss_att 4.897434 loss_ctc 5.587144 loss_rnnt 3.641609 hw_loss 0.175041 history loss 7.081626 rank 2
2023-02-22 08:36:04,360 DEBUG CV Batch 16/1000 loss 4.094553 loss_att 4.897434 loss_ctc 5.587144 loss_rnnt 3.641609 hw_loss 0.175041 history loss 7.081626 rank 6
2023-02-22 08:36:12,239 DEBUG CV Batch 16/1100 loss 6.882595 loss_att 5.943839 loss_ctc 8.599001 loss_rnnt 6.730689 hw_loss 0.207756 history loss 7.061212 rank 0
2023-02-22 08:36:12,449 DEBUG CV Batch 16/1100 loss 6.882595 loss_att 5.943839 loss_ctc 8.599001 loss_rnnt 6.730689 hw_loss 0.207756 history loss 7.061212 rank 7
2023-02-22 08:36:12,509 DEBUG CV Batch 16/1100 loss 6.882595 loss_att 5.943839 loss_ctc 8.599001 loss_rnnt 6.730689 hw_loss 0.207756 history loss 7.061212 rank 4
2023-02-22 08:36:13,100 DEBUG CV Batch 16/1100 loss 6.882595 loss_att 5.943839 loss_ctc 8.599001 loss_rnnt 6.730689 hw_loss 0.207756 history loss 7.061212 rank 5
2023-02-22 08:36:14,053 DEBUG CV Batch 16/1100 loss 6.882595 loss_att 5.943839 loss_ctc 8.599001 loss_rnnt 6.730689 hw_loss 0.207756 history loss 7.061212 rank 1
2023-02-22 08:36:14,832 DEBUG CV Batch 16/1100 loss 6.882595 loss_att 5.943839 loss_ctc 8.599001 loss_rnnt 6.730689 hw_loss 0.207756 history loss 7.061212 rank 3
2023-02-22 08:36:16,242 DEBUG CV Batch 16/1100 loss 6.882595 loss_att 5.943839 loss_ctc 8.599001 loss_rnnt 6.730689 hw_loss 0.207756 history loss 7.061212 rank 2
2023-02-22 08:36:16,412 DEBUG CV Batch 16/1100 loss 6.882595 loss_att 5.943839 loss_ctc 8.599001 loss_rnnt 6.730689 hw_loss 0.207756 history loss 7.061212 rank 6
2023-02-22 08:36:22,794 DEBUG CV Batch 16/1200 loss 7.783952 loss_att 7.739408 loss_ctc 9.018445 loss_rnnt 7.592731 hw_loss 0.066621 history loss 7.411633 rank 0
2023-02-22 08:36:23,027 DEBUG CV Batch 16/1200 loss 7.783952 loss_att 7.739408 loss_ctc 9.018445 loss_rnnt 7.592731 hw_loss 0.066621 history loss 7.411633 rank 7
2023-02-22 08:36:23,057 DEBUG CV Batch 16/1200 loss 7.783952 loss_att 7.739408 loss_ctc 9.018445 loss_rnnt 7.592731 hw_loss 0.066621 history loss 7.411633 rank 4
2023-02-22 08:36:23,738 DEBUG CV Batch 16/1200 loss 7.783952 loss_att 7.739408 loss_ctc 9.018445 loss_rnnt 7.592731 hw_loss 0.066621 history loss 7.411633 rank 5
2023-02-22 08:36:24,722 DEBUG CV Batch 16/1200 loss 7.783952 loss_att 7.739408 loss_ctc 9.018445 loss_rnnt 7.592731 hw_loss 0.066621 history loss 7.411633 rank 1
2023-02-22 08:36:26,733 DEBUG CV Batch 16/1200 loss 7.783952 loss_att 7.739408 loss_ctc 9.018445 loss_rnnt 7.592731 hw_loss 0.066621 history loss 7.411633 rank 3
2023-02-22 08:36:26,991 DEBUG CV Batch 16/1200 loss 7.783952 loss_att 7.739408 loss_ctc 9.018445 loss_rnnt 7.592731 hw_loss 0.066621 history loss 7.411633 rank 2
2023-02-22 08:36:27,115 DEBUG CV Batch 16/1200 loss 7.783952 loss_att 7.739408 loss_ctc 9.018445 loss_rnnt 7.592731 hw_loss 0.066621 history loss 7.411633 rank 6
2023-02-22 08:36:34,823 DEBUG CV Batch 16/1300 loss 7.029745 loss_att 6.851344 loss_ctc 8.905385 loss_rnnt 6.758519 hw_loss 0.106538 history loss 7.726887 rank 0
2023-02-22 08:36:34,922 DEBUG CV Batch 16/1300 loss 7.029745 loss_att 6.851344 loss_ctc 8.905385 loss_rnnt 6.758519 hw_loss 0.106538 history loss 7.726887 rank 7
2023-02-22 08:36:34,966 DEBUG CV Batch 16/1300 loss 7.029745 loss_att 6.851344 loss_ctc 8.905385 loss_rnnt 6.758519 hw_loss 0.106538 history loss 7.726887 rank 4
2023-02-22 08:36:35,688 DEBUG CV Batch 16/1300 loss 7.029745 loss_att 6.851344 loss_ctc 8.905385 loss_rnnt 6.758519 hw_loss 0.106538 history loss 7.726887 rank 5
2023-02-22 08:36:36,896 DEBUG CV Batch 16/1300 loss 7.029745 loss_att 6.851344 loss_ctc 8.905385 loss_rnnt 6.758519 hw_loss 0.106538 history loss 7.726887 rank 1
2023-02-22 08:36:39,041 DEBUG CV Batch 16/1300 loss 7.029745 loss_att 6.851344 loss_ctc 8.905385 loss_rnnt 6.758519 hw_loss 0.106538 history loss 7.726887 rank 2
2023-02-22 08:36:39,127 DEBUG CV Batch 16/1300 loss 7.029745 loss_att 6.851344 loss_ctc 8.905385 loss_rnnt 6.758519 hw_loss 0.106538 history loss 7.726887 rank 6
2023-02-22 08:36:40,163 DEBUG CV Batch 16/1300 loss 7.029745 loss_att 6.851344 loss_ctc 8.905385 loss_rnnt 6.758519 hw_loss 0.106538 history loss 7.726887 rank 3
2023-02-22 08:36:46,054 DEBUG CV Batch 16/1400 loss 14.841202 loss_att 34.620632 loss_ctc 9.734231 loss_rnnt 11.565990 hw_loss 0.000477 history loss 8.091795 rank 0
2023-02-22 08:36:46,147 DEBUG CV Batch 16/1400 loss 14.841202 loss_att 34.620632 loss_ctc 9.734231 loss_rnnt 11.565990 hw_loss 0.000477 history loss 8.091795 rank 7
2023-02-22 08:36:46,333 DEBUG CV Batch 16/1400 loss 14.841202 loss_att 34.620632 loss_ctc 9.734231 loss_rnnt 11.565990 hw_loss 0.000477 history loss 8.091795 rank 4
2023-02-22 08:36:47,097 DEBUG CV Batch 16/1400 loss 14.841202 loss_att 34.620632 loss_ctc 9.734231 loss_rnnt 11.565990 hw_loss 0.000477 history loss 8.091795 rank 5
2023-02-22 08:36:48,211 DEBUG CV Batch 16/1400 loss 14.841202 loss_att 34.620632 loss_ctc 9.734231 loss_rnnt 11.565990 hw_loss 0.000477 history loss 8.091795 rank 1
2023-02-22 08:36:50,469 DEBUG CV Batch 16/1400 loss 14.841202 loss_att 34.620632 loss_ctc 9.734231 loss_rnnt 11.565990 hw_loss 0.000477 history loss 8.091795 rank 6
2023-02-22 08:36:50,717 DEBUG CV Batch 16/1400 loss 14.841202 loss_att 34.620632 loss_ctc 9.734231 loss_rnnt 11.565990 hw_loss 0.000477 history loss 8.091795 rank 2
2023-02-22 08:36:51,529 DEBUG CV Batch 16/1400 loss 14.841202 loss_att 34.620632 loss_ctc 9.734231 loss_rnnt 11.565990 hw_loss 0.000477 history loss 8.091795 rank 3
2023-02-22 08:36:57,579 DEBUG CV Batch 16/1500 loss 7.377305 loss_att 8.088047 loss_ctc 7.374116 loss_rnnt 7.197116 hw_loss 0.072124 history loss 7.908919 rank 0
2023-02-22 08:36:57,616 DEBUG CV Batch 16/1500 loss 7.377305 loss_att 8.088047 loss_ctc 7.374116 loss_rnnt 7.197116 hw_loss 0.072124 history loss 7.908919 rank 7
2023-02-22 08:36:57,754 DEBUG CV Batch 16/1500 loss 7.377305 loss_att 8.088047 loss_ctc 7.374116 loss_rnnt 7.197116 hw_loss 0.072124 history loss 7.908919 rank 4
2023-02-22 08:36:58,569 DEBUG CV Batch 16/1500 loss 7.377305 loss_att 8.088047 loss_ctc 7.374116 loss_rnnt 7.197116 hw_loss 0.072124 history loss 7.908919 rank 5
2023-02-22 08:36:59,738 DEBUG CV Batch 16/1500 loss 7.377305 loss_att 8.088047 loss_ctc 7.374116 loss_rnnt 7.197116 hw_loss 0.072124 history loss 7.908919 rank 1
2023-02-22 08:37:02,316 DEBUG CV Batch 16/1500 loss 7.377305 loss_att 8.088047 loss_ctc 7.374116 loss_rnnt 7.197116 hw_loss 0.072124 history loss 7.908919 rank 2
2023-02-22 08:37:02,976 DEBUG CV Batch 16/1500 loss 7.377305 loss_att 8.088047 loss_ctc 7.374116 loss_rnnt 7.197116 hw_loss 0.072124 history loss 7.908919 rank 6
2023-02-22 08:37:03,020 DEBUG CV Batch 16/1500 loss 7.377305 loss_att 8.088047 loss_ctc 7.374116 loss_rnnt 7.197116 hw_loss 0.072124 history loss 7.908919 rank 3
2023-02-22 08:37:10,487 DEBUG CV Batch 16/1600 loss 11.443856 loss_att 14.578652 loss_ctc 17.267836 loss_rnnt 9.992072 hw_loss 0.090551 history loss 7.831150 rank 0
2023-02-22 08:37:10,589 DEBUG CV Batch 16/1600 loss 11.443856 loss_att 14.578652 loss_ctc 17.267836 loss_rnnt 9.992072 hw_loss 0.090551 history loss 7.831150 rank 7
2023-02-22 08:37:10,636 DEBUG CV Batch 16/1600 loss 11.443856 loss_att 14.578652 loss_ctc 17.267836 loss_rnnt 9.992072 hw_loss 0.090551 history loss 7.831150 rank 4
2023-02-22 08:37:11,880 DEBUG CV Batch 16/1600 loss 11.443856 loss_att 14.578652 loss_ctc 17.267836 loss_rnnt 9.992072 hw_loss 0.090551 history loss 7.831150 rank 5
2023-02-22 08:37:12,750 DEBUG CV Batch 16/1600 loss 11.443856 loss_att 14.578652 loss_ctc 17.267836 loss_rnnt 9.992072 hw_loss 0.090551 history loss 7.831150 rank 1
2023-02-22 08:37:15,363 DEBUG CV Batch 16/1600 loss 11.443856 loss_att 14.578652 loss_ctc 17.267836 loss_rnnt 9.992072 hw_loss 0.090551 history loss 7.831150 rank 2
2023-02-22 08:37:16,098 DEBUG CV Batch 16/1600 loss 11.443856 loss_att 14.578652 loss_ctc 17.267836 loss_rnnt 9.992072 hw_loss 0.090551 history loss 7.831150 rank 3
2023-02-22 08:37:16,235 DEBUG CV Batch 16/1600 loss 11.443856 loss_att 14.578652 loss_ctc 17.267836 loss_rnnt 9.992072 hw_loss 0.090551 history loss 7.831150 rank 6
2023-02-22 08:37:22,687 DEBUG CV Batch 16/1700 loss 9.146437 loss_att 8.372722 loss_ctc 14.184140 loss_rnnt 8.583026 hw_loss 0.087114 history loss 7.723038 rank 0
2023-02-22 08:37:22,921 DEBUG CV Batch 16/1700 loss 9.146437 loss_att 8.372722 loss_ctc 14.184140 loss_rnnt 8.583026 hw_loss 0.087114 history loss 7.723038 rank 4
2023-02-22 08:37:23,003 DEBUG CV Batch 16/1700 loss 9.146437 loss_att 8.372722 loss_ctc 14.184140 loss_rnnt 8.583026 hw_loss 0.087114 history loss 7.723038 rank 7
2023-02-22 08:37:24,179 DEBUG CV Batch 16/1700 loss 9.146437 loss_att 8.372722 loss_ctc 14.184140 loss_rnnt 8.583026 hw_loss 0.087114 history loss 7.723038 rank 5
2023-02-22 08:37:25,233 DEBUG CV Batch 16/1700 loss 9.146437 loss_att 8.372722 loss_ctc 14.184140 loss_rnnt 8.583026 hw_loss 0.087114 history loss 7.723038 rank 1
2023-02-22 08:37:27,945 DEBUG CV Batch 16/1700 loss 9.146437 loss_att 8.372722 loss_ctc 14.184140 loss_rnnt 8.583026 hw_loss 0.087114 history loss 7.723038 rank 2
2023-02-22 08:37:28,434 DEBUG CV Batch 16/1700 loss 9.146437 loss_att 8.372722 loss_ctc 14.184140 loss_rnnt 8.583026 hw_loss 0.087114 history loss 7.723038 rank 3
2023-02-22 08:37:28,860 DEBUG CV Batch 16/1700 loss 9.146437 loss_att 8.372722 loss_ctc 14.184140 loss_rnnt 8.583026 hw_loss 0.087114 history loss 7.723038 rank 6
2023-02-22 08:37:31,675 INFO Epoch 16 CV info cv_loss 7.6798832151763685
2023-02-22 08:37:31,676 INFO Checkpoint: save to checkpoint exp/2_21_rnnt_bias_loss_2_class_1word_finetune/16.pt
2023-02-22 08:37:31,930 INFO Epoch 16 CV info cv_loss 7.679883216587014
2023-02-22 08:37:31,931 INFO Epoch 17 TRAIN info lr 0.00041991016898825916
2023-02-22 08:37:31,934 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 08:37:32,173 INFO Epoch 16 CV info cv_loss 7.6798832186976
2023-02-22 08:37:32,177 INFO Epoch 17 TRAIN info lr 0.00041987759497148335
2023-02-22 08:37:32,181 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 08:37:32,550 INFO Epoch 17 TRAIN info lr 0.0004199309018557182
2023-02-22 08:37:32,554 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 08:37:33,223 INFO Epoch 16 CV info cv_loss 7.679883216782997
2023-02-22 08:37:33,225 INFO Epoch 17 TRAIN info lr 0.0004198761145144706
2023-02-22 08:37:33,229 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 08:37:34,416 INFO Epoch 16 CV info cv_loss 7.679883215869846
2023-02-22 08:37:34,418 INFO Epoch 17 TRAIN info lr 0.0004199708953455685
2023-02-22 08:37:34,422 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 08:37:37,570 INFO Epoch 16 CV info cv_loss 7.679883214986846
2023-02-22 08:37:37,571 INFO Epoch 17 TRAIN info lr 0.0004198494689658057
2023-02-22 08:37:37,574 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 08:37:37,941 INFO Epoch 16 CV info cv_loss 7.679883217713377
2023-02-22 08:37:37,943 INFO Epoch 17 TRAIN info lr 0.0004199397883105024
2023-02-22 08:37:37,948 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 08:37:37,959 INFO Epoch 16 CV info cv_loss 7.679883216481485
2023-02-22 08:37:37,960 INFO Epoch 17 TRAIN info lr 0.00041985538976044946
2023-02-22 08:37:37,964 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 08:38:50,170 DEBUG TRAIN Batch 17/0 loss 11.366668 loss_att 11.227088 loss_ctc 14.581786 loss_rnnt 10.857010 hw_loss 0.204172 lr 0.00041988 rank 7
2023-02-22 08:38:50,174 DEBUG TRAIN Batch 17/0 loss 11.750575 loss_att 10.745468 loss_ctc 15.463173 loss_rnnt 11.373667 hw_loss 0.155467 lr 0.00041987 rank 5
2023-02-22 08:38:50,176 DEBUG TRAIN Batch 17/0 loss 9.251161 loss_att 8.570080 loss_ctc 11.641545 loss_rnnt 8.931448 hw_loss 0.257271 lr 0.00041993 rank 0
2023-02-22 08:38:50,180 DEBUG TRAIN Batch 17/0 loss 8.813864 loss_att 7.844028 loss_ctc 10.412052 loss_rnnt 8.686388 hw_loss 0.203158 lr 0.00041991 rank 4
2023-02-22 08:38:50,183 DEBUG TRAIN Batch 17/0 loss 11.620881 loss_att 11.326231 loss_ctc 13.419213 loss_rnnt 11.331899 hw_loss 0.202754 lr 0.00041985 rank 2
2023-02-22 08:38:50,206 DEBUG TRAIN Batch 17/0 loss 7.038244 loss_att 6.812536 loss_ctc 8.747815 loss_rnnt 6.715161 hw_loss 0.263028 lr 0.00041997 rank 1
2023-02-22 08:38:50,213 DEBUG TRAIN Batch 17/0 loss 11.467807 loss_att 11.020380 loss_ctc 14.375051 loss_rnnt 11.045092 hw_loss 0.233565 lr 0.00041985 rank 3
2023-02-22 08:38:50,284 DEBUG TRAIN Batch 17/0 loss 12.074240 loss_att 11.519468 loss_ctc 16.551018 loss_rnnt 11.484172 hw_loss 0.195223 lr 0.00041994 rank 6
2023-02-22 08:40:05,052 DEBUG TRAIN Batch 17/100 loss 5.374644 loss_att 14.323470 loss_ctc 6.957784 loss_rnnt 3.301126 hw_loss 0.136250 lr 0.00041973 rank 5
2023-02-22 08:40:05,054 DEBUG TRAIN Batch 17/100 loss 8.450732 loss_att 11.615846 loss_ctc 8.755730 loss_rnnt 7.688280 hw_loss 0.166430 lr 0.00041978 rank 0
2023-02-22 08:40:05,058 DEBUG TRAIN Batch 17/100 loss 13.348665 loss_att 14.484362 loss_ctc 13.157120 loss_rnnt 13.064568 hw_loss 0.154684 lr 0.00041976 rank 4
2023-02-22 08:40:05,059 DEBUG TRAIN Batch 17/100 loss 6.618236 loss_att 10.902976 loss_ctc 9.239362 loss_rnnt 5.373640 hw_loss 0.071559 lr 0.00041971 rank 2
2023-02-22 08:40:05,060 DEBUG TRAIN Batch 17/100 loss 4.927447 loss_att 8.826618 loss_ctc 6.055097 loss_rnnt 3.969072 hw_loss 0.052853 lr 0.00041982 rank 1
2023-02-22 08:40:05,061 DEBUG TRAIN Batch 17/100 loss 3.585724 loss_att 6.004098 loss_ctc 4.534846 loss_rnnt 2.916271 hw_loss 0.111054 lr 0.00041970 rank 3
2023-02-22 08:40:05,061 DEBUG TRAIN Batch 17/100 loss 8.149045 loss_att 11.228455 loss_ctc 11.680443 loss_rnnt 6.982882 hw_loss 0.148929 lr 0.00041973 rank 7
2023-02-22 08:40:05,109 DEBUG TRAIN Batch 17/100 loss 17.021042 loss_att 18.088627 loss_ctc 17.280544 loss_rnnt 16.738905 hw_loss 0.063793 lr 0.00041979 rank 6
2023-02-22 08:41:21,270 DEBUG TRAIN Batch 17/200 loss 8.224960 loss_att 12.678750 loss_ctc 9.688612 loss_rnnt 7.084736 hw_loss 0.101838 lr 0.00041958 rank 7
2023-02-22 08:41:21,270 DEBUG TRAIN Batch 17/200 loss 8.384612 loss_att 11.975667 loss_ctc 11.260895 loss_rnnt 7.252579 hw_loss 0.056845 lr 0.00041967 rank 1
2023-02-22 08:41:21,272 DEBUG TRAIN Batch 17/200 loss 3.522575 loss_att 7.355324 loss_ctc 7.542617 loss_rnnt 2.173764 hw_loss 0.086729 lr 0.00041963 rank 0
2023-02-22 08:41:21,272 DEBUG TRAIN Batch 17/200 loss 6.342052 loss_att 10.895576 loss_ctc 6.972335 loss_rnnt 5.282711 hw_loss 0.121122 lr 0.00041956 rank 2
2023-02-22 08:41:21,273 DEBUG TRAIN Batch 17/200 loss 5.539618 loss_att 7.406282 loss_ctc 6.787424 loss_rnnt 4.890370 hw_loss 0.205390 lr 0.00041958 rank 5
2023-02-22 08:41:21,275 DEBUG TRAIN Batch 17/200 loss 6.146278 loss_att 9.997665 loss_ctc 10.550079 loss_rnnt 4.712408 hw_loss 0.143286 lr 0.00041961 rank 4
2023-02-22 08:41:21,276 DEBUG TRAIN Batch 17/200 loss 13.829886 loss_att 16.826609 loss_ctc 21.215958 loss_rnnt 12.190970 hw_loss 0.102677 lr 0.00041955 rank 3
2023-02-22 08:41:21,324 DEBUG TRAIN Batch 17/200 loss 8.709735 loss_att 12.347784 loss_ctc 8.370264 loss_rnnt 7.973997 hw_loss 0.100108 lr 0.00041964 rank 6
2023-02-22 08:42:37,324 DEBUG TRAIN Batch 17/300 loss 27.876328 loss_att 31.844738 loss_ctc 34.302654 loss_rnnt 26.101715 hw_loss 0.232661 lr 0.00041949 rank 0
2023-02-22 08:42:37,326 DEBUG TRAIN Batch 17/300 loss 11.995779 loss_att 15.451070 loss_ctc 13.984620 loss_rnnt 10.963359 hw_loss 0.142845 lr 0.00041941 rank 2
2023-02-22 08:42:37,328 DEBUG TRAIN Batch 17/300 loss 27.329056 loss_att 27.147232 loss_ctc 41.473763 loss_rnnt 25.374649 hw_loss 0.196517 lr 0.00041947 rank 4
2023-02-22 08:42:37,329 DEBUG TRAIN Batch 17/300 loss 6.882626 loss_att 11.491254 loss_ctc 9.413427 loss_rnnt 5.527680 hw_loss 0.179588 lr 0.00041949 rank 6
2023-02-22 08:42:37,331 DEBUG TRAIN Batch 17/300 loss 7.008719 loss_att 10.612043 loss_ctc 9.530521 loss_rnnt 5.897078 hw_loss 0.102631 lr 0.00041940 rank 3
2023-02-22 08:42:37,332 DEBUG TRAIN Batch 17/300 loss 14.052653 loss_att 19.575474 loss_ctc 19.267857 loss_rnnt 12.200268 hw_loss 0.098363 lr 0.00041953 rank 1
2023-02-22 08:42:37,333 DEBUG TRAIN Batch 17/300 loss 13.999711 loss_att 18.055630 loss_ctc 18.936317 loss_rnnt 12.471794 hw_loss 0.109722 lr 0.00041943 rank 5
2023-02-22 08:42:37,334 DEBUG TRAIN Batch 17/300 loss 8.171843 loss_att 10.886619 loss_ctc 14.254321 loss_rnnt 6.752501 hw_loss 0.122604 lr 0.00041943 rank 7
2023-02-22 08:43:54,642 DEBUG TRAIN Batch 17/400 loss 14.746573 loss_att 15.466869 loss_ctc 15.770803 loss_rnnt 14.393976 hw_loss 0.134951 lr 0.00041929 rank 7
2023-02-22 08:43:54,647 DEBUG TRAIN Batch 17/400 loss 15.991464 loss_att 17.528400 loss_ctc 18.717709 loss_rnnt 15.271906 hw_loss 0.091257 lr 0.00041932 rank 4
2023-02-22 08:43:54,649 DEBUG TRAIN Batch 17/400 loss 10.065133 loss_att 13.662827 loss_ctc 13.091817 loss_rnnt 8.851284 hw_loss 0.170161 lr 0.00041934 rank 0
2023-02-22 08:43:54,650 DEBUG TRAIN Batch 17/400 loss 9.262726 loss_att 12.514646 loss_ctc 12.023802 loss_rnnt 8.143276 hw_loss 0.189227 lr 0.00041935 rank 6
2023-02-22 08:43:54,650 DEBUG TRAIN Batch 17/400 loss 8.834075 loss_att 9.169312 loss_ctc 11.113735 loss_rnnt 8.462626 hw_loss 0.000836 lr 0.00041928 rank 5
2023-02-22 08:43:54,651 DEBUG TRAIN Batch 17/400 loss 15.860209 loss_att 19.296150 loss_ctc 21.605524 loss_rnnt 14.362413 hw_loss 0.083556 lr 0.00041938 rank 1
2023-02-22 08:43:54,652 DEBUG TRAIN Batch 17/400 loss 9.900834 loss_att 12.077134 loss_ctc 12.566763 loss_rnnt 9.061332 hw_loss 0.091473 lr 0.00041926 rank 3
2023-02-22 08:43:54,697 DEBUG TRAIN Batch 17/400 loss 13.118368 loss_att 14.212755 loss_ctc 16.809792 loss_rnnt 12.310219 hw_loss 0.182030 lr 0.00041926 rank 2
2023-02-22 08:45:09,765 DEBUG TRAIN Batch 17/500 loss 7.895035 loss_att 11.866227 loss_ctc 9.974318 loss_rnnt 6.736938 hw_loss 0.162413 lr 0.00041914 rank 7
2023-02-22 08:45:09,768 DEBUG TRAIN Batch 17/500 loss 3.090929 loss_att 6.138732 loss_ctc 7.036733 loss_rnnt 1.905729 hw_loss 0.092872 lr 0.00041919 rank 0
2023-02-22 08:45:09,770 DEBUG TRAIN Batch 17/500 loss 8.509382 loss_att 11.474876 loss_ctc 9.874765 loss_rnnt 7.683614 hw_loss 0.094910 lr 0.00041914 rank 5
2023-02-22 08:45:09,772 DEBUG TRAIN Batch 17/500 loss 10.060804 loss_att 12.376949 loss_ctc 14.815354 loss_rnnt 8.845615 hw_loss 0.221285 lr 0.00041911 rank 3
2023-02-22 08:45:09,772 DEBUG TRAIN Batch 17/500 loss 9.006165 loss_att 11.056861 loss_ctc 10.749506 loss_rnnt 8.312113 hw_loss 0.096501 lr 0.00041923 rank 1
2023-02-22 08:45:09,773 DEBUG TRAIN Batch 17/500 loss 14.886047 loss_att 16.125803 loss_ctc 21.431145 loss_rnnt 13.696364 hw_loss 0.129472 lr 0.00041917 rank 4
2023-02-22 08:45:09,777 DEBUG TRAIN Batch 17/500 loss 14.219035 loss_att 16.939871 loss_ctc 19.075211 loss_rnnt 12.920282 hw_loss 0.200804 lr 0.00041912 rank 2
2023-02-22 08:45:09,821 DEBUG TRAIN Batch 17/500 loss 15.580950 loss_att 17.683475 loss_ctc 18.231010 loss_rnnt 14.736977 hw_loss 0.131487 lr 0.00041920 rank 6
2023-02-22 08:46:24,496 DEBUG TRAIN Batch 17/600 loss 11.225171 loss_att 14.056584 loss_ctc 12.904552 loss_rnnt 10.379135 hw_loss 0.104691 lr 0.00041902 rank 4
2023-02-22 08:46:24,496 DEBUG TRAIN Batch 17/600 loss 15.232885 loss_att 16.589561 loss_ctc 20.077871 loss_rnnt 14.204634 hw_loss 0.207974 lr 0.00041905 rank 6
2023-02-22 08:46:24,497 DEBUG TRAIN Batch 17/600 loss 9.407327 loss_att 12.296148 loss_ctc 12.028509 loss_rnnt 8.358086 hw_loss 0.228721 lr 0.00041904 rank 0
2023-02-22 08:46:24,497 DEBUG TRAIN Batch 17/600 loss 13.022943 loss_att 14.839527 loss_ctc 19.376495 loss_rnnt 11.683252 hw_loss 0.242310 lr 0.00041899 rank 5
2023-02-22 08:46:24,499 DEBUG TRAIN Batch 17/600 loss 17.185661 loss_att 19.329178 loss_ctc 24.984863 loss_rnnt 15.675772 hw_loss 0.077422 lr 0.00041897 rank 2
2023-02-22 08:46:24,500 DEBUG TRAIN Batch 17/600 loss 11.685512 loss_att 14.866838 loss_ctc 19.636803 loss_rnnt 9.959206 hw_loss 0.056001 lr 0.00041896 rank 3
2023-02-22 08:46:24,501 DEBUG TRAIN Batch 17/600 loss 7.225111 loss_att 10.379428 loss_ctc 8.610135 loss_rnnt 6.320737 hw_loss 0.166574 lr 0.00041899 rank 7
2023-02-22 08:46:24,502 DEBUG TRAIN Batch 17/600 loss 11.988249 loss_att 14.189998 loss_ctc 16.085796 loss_rnnt 10.841313 hw_loss 0.300460 lr 0.00041908 rank 1
2023-02-22 08:47:42,366 DEBUG TRAIN Batch 17/700 loss 4.725945 loss_att 7.606093 loss_ctc 5.772533 loss_rnnt 3.932017 hw_loss 0.146912 lr 0.00041884 rank 5
2023-02-22 08:47:42,366 DEBUG TRAIN Batch 17/700 loss 6.364596 loss_att 8.708731 loss_ctc 6.113866 loss_rnnt 5.881389 hw_loss 0.089647 lr 0.00041882 rank 3
2023-02-22 08:47:42,368 DEBUG TRAIN Batch 17/700 loss 9.088223 loss_att 16.044090 loss_ctc 18.491497 loss_rnnt 6.364314 hw_loss 0.148063 lr 0.00041884 rank 7
2023-02-22 08:47:42,371 DEBUG TRAIN Batch 17/700 loss 27.417688 loss_att 31.542307 loss_ctc 43.768402 loss_rnnt 24.367550 hw_loss 0.084601 lr 0.00041894 rank 1
2023-02-22 08:47:42,371 DEBUG TRAIN Batch 17/700 loss 19.178497 loss_att 21.902929 loss_ctc 24.817036 loss_rnnt 17.842720 hw_loss 0.073285 lr 0.00041890 rank 0
2023-02-22 08:47:42,372 DEBUG TRAIN Batch 17/700 loss 15.032888 loss_att 16.384716 loss_ctc 21.718197 loss_rnnt 13.793427 hw_loss 0.145729 lr 0.00041891 rank 6
2023-02-22 08:47:42,384 DEBUG TRAIN Batch 17/700 loss 5.026509 loss_att 7.894584 loss_ctc 4.749868 loss_rnnt 4.407216 hw_loss 0.154806 lr 0.00041888 rank 4
2023-02-22 08:47:42,413 DEBUG TRAIN Batch 17/700 loss 8.254520 loss_att 11.986124 loss_ctc 9.536898 loss_rnnt 7.313649 hw_loss 0.044189 lr 0.00041882 rank 2
2023-02-22 08:48:58,859 DEBUG TRAIN Batch 17/800 loss 5.053675 loss_att 8.049668 loss_ctc 5.001278 loss_rnnt 4.412803 hw_loss 0.091237 lr 0.00041875 rank 0
2023-02-22 08:48:58,862 DEBUG TRAIN Batch 17/800 loss 6.926575 loss_att 12.319677 loss_ctc 9.526731 loss_rnnt 5.427474 hw_loss 0.138363 lr 0.00041873 rank 4
2023-02-22 08:48:58,862 DEBUG TRAIN Batch 17/800 loss 7.584524 loss_att 10.776162 loss_ctc 10.995147 loss_rnnt 6.345592 hw_loss 0.273476 lr 0.00041870 rank 7
2023-02-22 08:48:58,863 DEBUG TRAIN Batch 17/800 loss 27.957777 loss_att 29.536818 loss_ctc 28.692389 loss_rnnt 27.470768 hw_loss 0.137343 lr 0.00041867 rank 3
2023-02-22 08:48:58,865 DEBUG TRAIN Batch 17/800 loss 7.978408 loss_att 12.399899 loss_ctc 13.238058 loss_rnnt 6.354998 hw_loss 0.070924 lr 0.00041870 rank 5
2023-02-22 08:48:58,867 DEBUG TRAIN Batch 17/800 loss 5.908799 loss_att 11.890127 loss_ctc 7.826768 loss_rnnt 4.406896 hw_loss 0.093577 lr 0.00041876 rank 6
2023-02-22 08:48:58,868 DEBUG TRAIN Batch 17/800 loss 11.147472 loss_att 17.930666 loss_ctc 17.854408 loss_rnnt 8.851130 hw_loss 0.085211 lr 0.00041867 rank 2
2023-02-22 08:48:58,871 DEBUG TRAIN Batch 17/800 loss 10.474225 loss_att 13.878568 loss_ctc 14.799774 loss_rnnt 9.178677 hw_loss 0.071136 lr 0.00041879 rank 1
2023-02-22 08:50:13,244 DEBUG TRAIN Batch 17/900 loss 4.952346 loss_att 8.820527 loss_ctc 7.043819 loss_rnnt 3.879138 hw_loss 0.038829 lr 0.00041860 rank 0
2023-02-22 08:50:13,245 DEBUG TRAIN Batch 17/900 loss 10.911423 loss_att 14.298508 loss_ctc 15.060444 loss_rnnt 9.671255 hw_loss 0.017903 lr 0.00041858 rank 4
2023-02-22 08:50:13,245 DEBUG TRAIN Batch 17/900 loss 7.822398 loss_att 9.602587 loss_ctc 10.043976 loss_rnnt 7.087984 hw_loss 0.154060 lr 0.00041855 rank 7
2023-02-22 08:50:13,249 DEBUG TRAIN Batch 17/900 loss 14.681106 loss_att 17.240099 loss_ctc 21.226246 loss_rnnt 13.198752 hw_loss 0.183506 lr 0.00041855 rank 5
2023-02-22 08:50:13,253 DEBUG TRAIN Batch 17/900 loss 7.831034 loss_att 13.740966 loss_ctc 15.761867 loss_rnnt 5.561768 hw_loss 0.055941 lr 0.00041852 rank 3
2023-02-22 08:50:13,253 DEBUG TRAIN Batch 17/900 loss 10.011156 loss_att 12.204393 loss_ctc 14.092689 loss_rnnt 8.973759 hw_loss 0.102274 lr 0.00041864 rank 1
2023-02-22 08:50:13,254 DEBUG TRAIN Batch 17/900 loss 5.322613 loss_att 10.195160 loss_ctc 10.318134 loss_rnnt 3.664752 hw_loss 0.032404 lr 0.00041861 rank 6
2023-02-22 08:50:13,256 DEBUG TRAIN Batch 17/900 loss 4.120323 loss_att 6.227507 loss_ctc 4.049339 loss_rnnt 3.650467 hw_loss 0.108533 lr 0.00041853 rank 2
2023-02-22 08:51:29,506 DEBUG TRAIN Batch 17/1000 loss 4.964804 loss_att 7.365643 loss_ctc 8.032584 loss_rnnt 4.010256 hw_loss 0.122519 lr 0.00041846 rank 0
2023-02-22 08:51:29,507 DEBUG TRAIN Batch 17/1000 loss 7.442354 loss_att 9.746371 loss_ctc 10.846304 loss_rnnt 6.477657 hw_loss 0.093812 lr 0.00041840 rank 7
2023-02-22 08:51:29,508 DEBUG TRAIN Batch 17/1000 loss 10.899714 loss_att 15.572951 loss_ctc 14.063173 loss_rnnt 9.395651 hw_loss 0.276793 lr 0.00041838 rank 3
2023-02-22 08:51:29,508 DEBUG TRAIN Batch 17/1000 loss 14.117911 loss_att 17.246647 loss_ctc 18.220716 loss_rnnt 12.891933 hw_loss 0.099730 lr 0.00041840 rank 5
2023-02-22 08:51:29,509 DEBUG TRAIN Batch 17/1000 loss 7.446196 loss_att 11.330780 loss_ctc 9.728699 loss_rnnt 6.305835 hw_loss 0.110834 lr 0.00041850 rank 1
2023-02-22 08:51:29,512 DEBUG TRAIN Batch 17/1000 loss 7.786106 loss_att 13.127739 loss_ctc 13.067149 loss_rnnt 5.900063 hw_loss 0.212956 lr 0.00041844 rank 4
2023-02-22 08:51:29,513 DEBUG TRAIN Batch 17/1000 loss 10.806484 loss_att 13.611286 loss_ctc 14.523204 loss_rnnt 9.743622 hw_loss 0.011889 lr 0.00041846 rank 6
2023-02-22 08:51:29,516 DEBUG TRAIN Batch 17/1000 loss 8.929646 loss_att 13.505796 loss_ctc 15.584852 loss_rnnt 7.044935 hw_loss 0.153977 lr 0.00041838 rank 2
2023-02-22 08:52:47,077 DEBUG TRAIN Batch 17/1100 loss 12.044766 loss_att 14.142670 loss_ctc 13.928525 loss_rnnt 11.315913 hw_loss 0.108945 lr 0.00041826 rank 7
2023-02-22 08:52:47,084 DEBUG TRAIN Batch 17/1100 loss 7.348288 loss_att 12.129305 loss_ctc 13.337522 loss_rnnt 5.556887 hw_loss 0.068687 lr 0.00041826 rank 5
2023-02-22 08:52:47,086 DEBUG TRAIN Batch 17/1100 loss 8.949821 loss_att 12.185190 loss_ctc 11.275786 loss_rnnt 7.919833 hw_loss 0.136473 lr 0.00041823 rank 3
2023-02-22 08:52:47,086 DEBUG TRAIN Batch 17/1100 loss 8.912694 loss_att 9.212306 loss_ctc 11.374113 loss_rnnt 8.485242 hw_loss 0.073764 lr 0.00041831 rank 0
2023-02-22 08:52:47,087 DEBUG TRAIN Batch 17/1100 loss 13.167727 loss_att 17.315468 loss_ctc 20.866545 loss_rnnt 11.201170 hw_loss 0.207185 lr 0.00041835 rank 1
2023-02-22 08:52:47,089 DEBUG TRAIN Batch 17/1100 loss 4.843566 loss_att 8.630934 loss_ctc 7.196185 loss_rnnt 3.665911 hw_loss 0.199685 lr 0.00041832 rank 6
2023-02-22 08:52:47,089 DEBUG TRAIN Batch 17/1100 loss 7.128196 loss_att 9.616845 loss_ctc 10.882931 loss_rnnt 6.076616 hw_loss 0.099784 lr 0.00041829 rank 4
2023-02-22 08:52:47,093 DEBUG TRAIN Batch 17/1100 loss 16.208166 loss_att 16.985596 loss_ctc 23.680746 loss_rnnt 15.009682 hw_loss 0.087475 lr 0.00041824 rank 2
2023-02-22 08:54:02,543 DEBUG TRAIN Batch 17/1200 loss 7.156112 loss_att 8.920707 loss_ctc 11.747823 loss_rnnt 6.119833 hw_loss 0.133374 lr 0.00041814 rank 4
2023-02-22 08:54:02,546 DEBUG TRAIN Batch 17/1200 loss 4.741167 loss_att 5.521648 loss_ctc 6.628765 loss_rnnt 4.218115 hw_loss 0.216140 lr 0.00041811 rank 7
2023-02-22 08:54:02,546 DEBUG TRAIN Batch 17/1200 loss 8.029292 loss_att 12.097558 loss_ctc 12.864421 loss_rnnt 6.518320 hw_loss 0.098691 lr 0.00041817 rank 6
2023-02-22 08:54:02,547 DEBUG TRAIN Batch 17/1200 loss 9.098564 loss_att 11.804120 loss_ctc 13.326447 loss_rnnt 7.938072 hw_loss 0.104367 lr 0.00041811 rank 5
2023-02-22 08:54:02,550 DEBUG TRAIN Batch 17/1200 loss 10.342954 loss_att 12.982449 loss_ctc 12.658543 loss_rnnt 9.468715 hw_loss 0.070492 lr 0.00041816 rank 0
2023-02-22 08:54:02,552 DEBUG TRAIN Batch 17/1200 loss 6.734647 loss_att 8.859000 loss_ctc 9.973098 loss_rnnt 5.801722 hw_loss 0.142989 lr 0.00041820 rank 1
2023-02-22 08:54:02,553 DEBUG TRAIN Batch 17/1200 loss 10.294077 loss_att 11.955455 loss_ctc 13.761839 loss_rnnt 9.400618 hw_loss 0.185280 lr 0.00041809 rank 2
2023-02-22 08:54:02,598 DEBUG TRAIN Batch 17/1200 loss 8.913567 loss_att 11.806211 loss_ctc 12.466445 loss_rnnt 7.763597 hw_loss 0.183232 lr 0.00041808 rank 3
2023-02-22 08:55:17,815 DEBUG TRAIN Batch 17/1300 loss 19.110430 loss_att 27.343746 loss_ctc 23.850048 loss_rnnt 16.804211 hw_loss 0.051760 lr 0.00041802 rank 0
2023-02-22 08:55:17,817 DEBUG TRAIN Batch 17/1300 loss 7.596236 loss_att 10.589115 loss_ctc 8.660080 loss_rnnt 6.814415 hw_loss 0.077625 lr 0.00041800 rank 4
2023-02-22 08:55:17,821 DEBUG TRAIN Batch 17/1300 loss 11.263378 loss_att 12.054865 loss_ctc 15.845919 loss_rnnt 10.396106 hw_loss 0.183695 lr 0.00041796 rank 5
2023-02-22 08:55:17,825 DEBUG TRAIN Batch 17/1300 loss 11.927868 loss_att 18.524336 loss_ctc 21.759232 loss_rnnt 9.234672 hw_loss 0.118227 lr 0.00041794 rank 3
2023-02-22 08:55:17,826 DEBUG TRAIN Batch 17/1300 loss 9.280383 loss_att 11.797806 loss_ctc 12.019871 loss_rnnt 8.374928 hw_loss 0.068825 lr 0.00041794 rank 2
2023-02-22 08:55:17,826 DEBUG TRAIN Batch 17/1300 loss 10.856715 loss_att 13.658070 loss_ctc 12.340179 loss_rnnt 9.986242 hw_loss 0.210762 lr 0.00041796 rank 7
2023-02-22 08:55:17,827 DEBUG TRAIN Batch 17/1300 loss 6.821200 loss_att 10.337618 loss_ctc 11.558538 loss_rnnt 5.460840 hw_loss 0.047684 lr 0.00041806 rank 1
2023-02-22 08:55:17,875 DEBUG TRAIN Batch 17/1300 loss 11.557965 loss_att 11.998187 loss_ctc 15.295555 loss_rnnt 10.853613 hw_loss 0.221181 lr 0.00041803 rank 6
2023-02-22 08:56:34,762 DEBUG TRAIN Batch 17/1400 loss 11.736980 loss_att 16.437897 loss_ctc 14.522792 loss_rnnt 10.355049 hw_loss 0.131825 lr 0.00041782 rank 5
2023-02-22 08:56:34,768 DEBUG TRAIN Batch 17/1400 loss 12.875520 loss_att 14.519524 loss_ctc 16.105984 loss_rnnt 12.036572 hw_loss 0.148908 lr 0.00041787 rank 0
2023-02-22 08:56:34,768 DEBUG TRAIN Batch 17/1400 loss 10.972554 loss_att 15.679173 loss_ctc 14.797094 loss_rnnt 9.442448 hw_loss 0.147833 lr 0.00041779 rank 3
2023-02-22 08:56:34,770 DEBUG TRAIN Batch 17/1400 loss 6.418446 loss_att 10.179587 loss_ctc 11.358101 loss_rnnt 5.000991 hw_loss 0.012387 lr 0.00041788 rank 6
2023-02-22 08:56:34,773 DEBUG TRAIN Batch 17/1400 loss 17.250711 loss_att 21.898293 loss_ctc 29.409786 loss_rnnt 14.641120 hw_loss 0.110374 lr 0.00041782 rank 7
2023-02-22 08:56:34,774 DEBUG TRAIN Batch 17/1400 loss 15.907065 loss_att 17.848965 loss_ctc 19.080811 loss_rnnt 14.946597 hw_loss 0.279228 lr 0.00041785 rank 4
2023-02-22 08:56:34,777 DEBUG TRAIN Batch 17/1400 loss 15.302479 loss_att 17.835518 loss_ctc 25.292166 loss_rnnt 13.423506 hw_loss 0.075764 lr 0.00041791 rank 1
2023-02-22 08:56:34,779 DEBUG TRAIN Batch 17/1400 loss 16.354916 loss_att 23.399452 loss_ctc 22.854164 loss_rnnt 14.047544 hw_loss 0.059811 lr 0.00041780 rank 2
2023-02-22 08:57:51,959 DEBUG TRAIN Batch 17/1500 loss 12.169891 loss_att 16.244160 loss_ctc 15.402210 loss_rnnt 10.818106 hw_loss 0.198669 lr 0.00041767 rank 7
2023-02-22 08:57:51,965 DEBUG TRAIN Batch 17/1500 loss 16.138966 loss_att 18.409374 loss_ctc 20.829670 loss_rnnt 14.961649 hw_loss 0.183385 lr 0.00041770 rank 4
2023-02-22 08:57:51,966 DEBUG TRAIN Batch 17/1500 loss 2.932799 loss_att 8.347147 loss_ctc 5.903171 loss_rnnt 1.388021 hw_loss 0.123485 lr 0.00041767 rank 5
2023-02-22 08:57:51,969 DEBUG TRAIN Batch 17/1500 loss 11.789497 loss_att 14.240734 loss_ctc 16.626133 loss_rnnt 10.587142 hw_loss 0.126045 lr 0.00041773 rank 0
2023-02-22 08:57:51,970 DEBUG TRAIN Batch 17/1500 loss 3.690308 loss_att 6.021001 loss_ctc 3.713187 loss_rnnt 3.144565 hw_loss 0.143537 lr 0.00041765 rank 3
2023-02-22 08:57:51,971 DEBUG TRAIN Batch 17/1500 loss 13.081610 loss_att 18.257599 loss_ctc 20.935703 loss_rnnt 10.863102 hw_loss 0.255182 lr 0.00041776 rank 1
2023-02-22 08:57:51,974 DEBUG TRAIN Batch 17/1500 loss 6.517243 loss_att 10.195412 loss_ctc 7.140148 loss_rnnt 5.648445 hw_loss 0.093956 lr 0.00041765 rank 2
2023-02-22 08:57:52,023 DEBUG TRAIN Batch 17/1500 loss 5.408884 loss_att 8.578320 loss_ctc 7.757195 loss_rnnt 4.417549 hw_loss 0.083137 lr 0.00041773 rank 6
2023-02-22 08:59:05,813 DEBUG TRAIN Batch 17/1600 loss 9.065621 loss_att 13.410511 loss_ctc 12.504327 loss_rnnt 7.697508 hw_loss 0.076201 lr 0.00041753 rank 7
2023-02-22 08:59:05,818 DEBUG TRAIN Batch 17/1600 loss 7.118606 loss_att 16.158222 loss_ctc 9.023186 loss_rnnt 4.963391 hw_loss 0.175026 lr 0.00041756 rank 4
2023-02-22 08:59:05,818 DEBUG TRAIN Batch 17/1600 loss 14.466682 loss_att 18.046709 loss_ctc 23.131046 loss_rnnt 12.567372 hw_loss 0.052605 lr 0.00041762 rank 1
2023-02-22 08:59:05,820 DEBUG TRAIN Batch 17/1600 loss 11.815655 loss_att 16.320293 loss_ctc 20.804615 loss_rnnt 9.694327 hw_loss 0.041011 lr 0.00041758 rank 0
2023-02-22 08:59:05,821 DEBUG TRAIN Batch 17/1600 loss 8.135295 loss_att 12.180405 loss_ctc 12.507116 loss_rnnt 6.644632 hw_loss 0.185123 lr 0.00041751 rank 2
2023-02-22 08:59:05,821 DEBUG TRAIN Batch 17/1600 loss 10.562089 loss_att 11.749591 loss_ctc 15.267501 loss_rnnt 9.644951 hw_loss 0.097966 lr 0.00041750 rank 3
2023-02-22 08:59:05,825 DEBUG TRAIN Batch 17/1600 loss 7.716459 loss_att 12.581044 loss_ctc 12.382364 loss_rnnt 6.061332 hw_loss 0.112666 lr 0.00041753 rank 5
2023-02-22 08:59:05,826 DEBUG TRAIN Batch 17/1600 loss 8.808300 loss_att 14.162079 loss_ctc 14.932144 loss_rnnt 6.871194 hw_loss 0.093446 lr 0.00041759 rank 6
2023-02-22 09:00:22,811 DEBUG TRAIN Batch 17/1700 loss 3.059795 loss_att 6.603279 loss_ctc 4.662804 loss_rnnt 2.086927 hw_loss 0.094568 lr 0.00041743 rank 0
2023-02-22 09:00:22,814 DEBUG TRAIN Batch 17/1700 loss 8.682627 loss_att 10.728047 loss_ctc 12.668567 loss_rnnt 7.701565 hw_loss 0.075973 lr 0.00041744 rank 6
2023-02-22 09:00:22,817 DEBUG TRAIN Batch 17/1700 loss 10.153443 loss_att 12.130568 loss_ctc 12.823906 loss_rnnt 9.338674 hw_loss 0.118656 lr 0.00041741 rank 4
2023-02-22 09:00:22,817 DEBUG TRAIN Batch 17/1700 loss 10.084111 loss_att 14.406263 loss_ctc 17.331306 loss_rnnt 8.202337 hw_loss 0.095719 lr 0.00041735 rank 3
2023-02-22 09:00:22,818 DEBUG TRAIN Batch 17/1700 loss 12.569994 loss_att 17.943954 loss_ctc 21.321148 loss_rnnt 10.271291 hw_loss 0.107046 lr 0.00041747 rank 1
2023-02-22 09:00:22,818 DEBUG TRAIN Batch 17/1700 loss 9.881446 loss_att 15.500002 loss_ctc 15.823761 loss_rnnt 7.959282 hw_loss 0.011520 lr 0.00041738 rank 7
2023-02-22 09:00:22,818 DEBUG TRAIN Batch 17/1700 loss 7.742206 loss_att 10.287539 loss_ctc 9.542507 loss_rnnt 6.894064 hw_loss 0.185690 lr 0.00041738 rank 5
2023-02-22 09:00:22,819 DEBUG TRAIN Batch 17/1700 loss 15.463503 loss_att 19.508293 loss_ctc 23.660427 loss_rnnt 13.497395 hw_loss 0.120425 lr 0.00041736 rank 2
2023-02-22 09:01:41,227 DEBUG TRAIN Batch 17/1800 loss 10.217701 loss_att 11.742999 loss_ctc 13.819794 loss_rnnt 9.391260 hw_loss 0.077065 lr 0.00041727 rank 4
2023-02-22 09:01:41,228 DEBUG TRAIN Batch 17/1800 loss 6.415944 loss_att 9.421690 loss_ctc 11.712410 loss_rnnt 5.076109 hw_loss 0.060917 lr 0.00041729 rank 0
2023-02-22 09:01:41,229 DEBUG TRAIN Batch 17/1800 loss 12.650550 loss_att 14.453920 loss_ctc 15.272717 loss_rnnt 11.876221 hw_loss 0.120062 lr 0.00041724 rank 7
2023-02-22 09:01:41,231 DEBUG TRAIN Batch 17/1800 loss 8.035785 loss_att 11.908154 loss_ctc 12.851074 loss_rnnt 6.572473 hw_loss 0.087749 lr 0.00041730 rank 6
2023-02-22 09:01:41,234 DEBUG TRAIN Batch 17/1800 loss 14.250571 loss_att 15.334564 loss_ctc 19.486399 loss_rnnt 13.272647 hw_loss 0.118153 lr 0.00041733 rank 1
2023-02-22 09:01:41,238 DEBUG TRAIN Batch 17/1800 loss 11.834738 loss_att 16.445286 loss_ctc 16.560112 loss_rnnt 10.213782 hw_loss 0.128992 lr 0.00041723 rank 5
2023-02-22 09:01:41,240 DEBUG TRAIN Batch 17/1800 loss 7.717581 loss_att 11.165627 loss_ctc 11.984836 loss_rnnt 6.411261 hw_loss 0.089520 lr 0.00041721 rank 2
2023-02-22 09:01:41,241 DEBUG TRAIN Batch 17/1800 loss 15.486877 loss_att 15.229403 loss_ctc 20.041121 loss_rnnt 14.856044 hw_loss 0.140806 lr 0.00041721 rank 3
2023-02-22 09:02:56,690 DEBUG TRAIN Batch 17/1900 loss 9.500627 loss_att 11.071614 loss_ctc 10.869557 loss_rnnt 8.905097 hw_loss 0.185266 lr 0.00041714 rank 0
2023-02-22 09:02:56,694 DEBUG TRAIN Batch 17/1900 loss 13.505284 loss_att 16.198395 loss_ctc 25.615616 loss_rnnt 11.312508 hw_loss 0.073958 lr 0.00041718 rank 1
2023-02-22 09:02:56,697 DEBUG TRAIN Batch 17/1900 loss 4.677979 loss_att 7.421498 loss_ctc 2.545872 loss_rnnt 4.362224 hw_loss 0.096250 lr 0.00041715 rank 6
2023-02-22 09:02:56,697 DEBUG TRAIN Batch 17/1900 loss 8.393194 loss_att 10.153021 loss_ctc 11.406017 loss_rnnt 7.564261 hw_loss 0.141108 lr 0.00041709 rank 5
2023-02-22 09:02:56,698 DEBUG TRAIN Batch 17/1900 loss 6.879927 loss_att 7.743021 loss_ctc 9.509525 loss_rnnt 6.324423 hw_loss 0.060510 lr 0.00041712 rank 4
2023-02-22 09:02:56,701 DEBUG TRAIN Batch 17/1900 loss 10.050288 loss_att 10.627418 loss_ctc 15.727115 loss_rnnt 9.095783 hw_loss 0.154069 lr 0.00041709 rank 7
2023-02-22 09:02:56,704 DEBUG TRAIN Batch 17/1900 loss 16.546753 loss_att 17.676502 loss_ctc 18.012789 loss_rnnt 16.043711 hw_loss 0.153036 lr 0.00041707 rank 2
2023-02-22 09:02:56,748 DEBUG TRAIN Batch 17/1900 loss 9.753513 loss_att 13.876289 loss_ctc 14.912477 loss_rnnt 8.205066 hw_loss 0.067559 lr 0.00041706 rank 3
2023-02-22 09:04:11,104 DEBUG TRAIN Batch 17/2000 loss 7.763334 loss_att 11.877334 loss_ctc 12.646361 loss_rnnt 6.277189 hw_loss 0.023015 lr 0.00041698 rank 4
2023-02-22 09:04:11,107 DEBUG TRAIN Batch 17/2000 loss 11.049178 loss_att 11.891520 loss_ctc 12.601546 loss_rnnt 10.656431 hw_loss 0.032433 lr 0.00041700 rank 0
2023-02-22 09:04:11,108 DEBUG TRAIN Batch 17/2000 loss 9.203946 loss_att 12.989927 loss_ctc 9.857665 loss_rnnt 8.310417 hw_loss 0.092194 lr 0.00041694 rank 5
2023-02-22 09:04:11,113 DEBUG TRAIN Batch 17/2000 loss 8.819337 loss_att 12.277831 loss_ctc 14.065100 loss_rnnt 7.395328 hw_loss 0.061644 lr 0.00041701 rank 6
2023-02-22 09:04:11,115 DEBUG TRAIN Batch 17/2000 loss 5.183753 loss_att 9.253163 loss_ctc 10.315710 loss_rnnt 3.648957 hw_loss 0.068725 lr 0.00041692 rank 3
2023-02-22 09:04:11,115 DEBUG TRAIN Batch 17/2000 loss 20.307547 loss_att 21.005173 loss_ctc 23.156887 loss_rnnt 19.740311 hw_loss 0.089622 lr 0.00041704 rank 1
2023-02-22 09:04:11,117 DEBUG TRAIN Batch 17/2000 loss 8.267589 loss_att 12.105210 loss_ctc 12.282702 loss_rnnt 6.937778 hw_loss 0.050508 lr 0.00041695 rank 7
2023-02-22 09:04:11,118 DEBUG TRAIN Batch 17/2000 loss 7.218272 loss_att 11.004486 loss_ctc 11.395407 loss_rnnt 5.879608 hw_loss 0.045882 lr 0.00041692 rank 2
2023-02-22 09:05:28,934 DEBUG TRAIN Batch 17/2100 loss 6.104829 loss_att 7.971707 loss_ctc 7.311403 loss_rnnt 5.508673 hw_loss 0.116071 lr 0.00041685 rank 0
2023-02-22 09:05:28,940 DEBUG TRAIN Batch 17/2100 loss 11.445391 loss_att 15.273981 loss_ctc 16.165142 loss_rnnt 9.965588 hw_loss 0.158972 lr 0.00041678 rank 2
2023-02-22 09:05:28,943 DEBUG TRAIN Batch 17/2100 loss 2.739038 loss_att 5.918221 loss_ctc 3.695612 loss_rnnt 1.948534 hw_loss 0.050858 lr 0.00041683 rank 4
2023-02-22 09:05:28,949 DEBUG TRAIN Batch 17/2100 loss 13.513181 loss_att 17.920399 loss_ctc 20.517912 loss_rnnt 11.616510 hw_loss 0.152366 lr 0.00041677 rank 3
2023-02-22 09:05:28,950 DEBUG TRAIN Batch 17/2100 loss 20.916410 loss_att 24.698608 loss_ctc 26.340437 loss_rnnt 19.289307 hw_loss 0.276484 lr 0.00041689 rank 1
2023-02-22 09:05:28,954 DEBUG TRAIN Batch 17/2100 loss 4.089943 loss_att 7.716488 loss_ctc 6.313932 loss_rnnt 3.026258 hw_loss 0.078458 lr 0.00041680 rank 5
2023-02-22 09:05:28,958 DEBUG TRAIN Batch 17/2100 loss 4.935911 loss_att 8.558902 loss_ctc 5.638868 loss_rnnt 4.061035 hw_loss 0.106032 lr 0.00041680 rank 7
2023-02-22 09:05:28,992 DEBUG TRAIN Batch 17/2100 loss 10.636350 loss_att 15.472475 loss_ctc 22.090649 loss_rnnt 8.105268 hw_loss 0.068656 lr 0.00041686 rank 6
2023-02-22 09:06:46,086 DEBUG TRAIN Batch 17/2200 loss 9.321544 loss_att 13.503870 loss_ctc 13.534555 loss_rnnt 7.892862 hw_loss 0.057152 lr 0.00041666 rank 5
2023-02-22 09:06:46,090 DEBUG TRAIN Batch 17/2200 loss 7.044255 loss_att 9.235125 loss_ctc 8.679506 loss_rnnt 6.270347 hw_loss 0.220688 lr 0.00041669 rank 4
2023-02-22 09:06:46,092 DEBUG TRAIN Batch 17/2200 loss 13.477644 loss_att 14.579111 loss_ctc 16.430380 loss_rnnt 12.836861 hw_loss 0.050234 lr 0.00041672 rank 6
2023-02-22 09:06:46,092 DEBUG TRAIN Batch 17/2200 loss 4.959725 loss_att 7.323023 loss_ctc 7.934942 loss_rnnt 4.043044 hw_loss 0.088737 lr 0.00041666 rank 7
2023-02-22 09:06:46,094 DEBUG TRAIN Batch 17/2200 loss 10.557516 loss_att 13.565306 loss_ctc 16.396503 loss_rnnt 9.091115 hw_loss 0.161833 lr 0.00041675 rank 1
2023-02-22 09:06:46,094 DEBUG TRAIN Batch 17/2200 loss 9.782258 loss_att 11.264540 loss_ctc 14.179518 loss_rnnt 8.879843 hw_loss 0.036857 lr 0.00041671 rank 0
2023-02-22 09:06:46,100 DEBUG TRAIN Batch 17/2200 loss 8.900170 loss_att 11.350763 loss_ctc 11.201843 loss_rnnt 8.032557 hw_loss 0.132384 lr 0.00041663 rank 2
2023-02-22 09:06:46,102 DEBUG TRAIN Batch 17/2200 loss 16.361759 loss_att 18.879023 loss_ctc 18.191036 loss_rnnt 15.602154 hw_loss 0.022971 lr 0.00041663 rank 3
2023-02-22 09:08:01,639 DEBUG TRAIN Batch 17/2300 loss 15.421986 loss_att 18.646202 loss_ctc 22.306549 loss_rnnt 13.760575 hw_loss 0.184923 lr 0.00041656 rank 0
2023-02-22 09:08:01,639 DEBUG TRAIN Batch 17/2300 loss 8.399783 loss_att 10.994513 loss_ctc 10.521939 loss_rnnt 7.553988 hw_loss 0.082305 lr 0.00041651 rank 5
2023-02-22 09:08:01,641 DEBUG TRAIN Batch 17/2300 loss 15.721352 loss_att 20.879095 loss_ctc 23.117983 loss_rnnt 13.615191 hw_loss 0.165739 lr 0.00041651 rank 7
2023-02-22 09:08:01,642 DEBUG TRAIN Batch 17/2300 loss 8.216540 loss_att 14.829353 loss_ctc 13.445810 loss_rnnt 6.185736 hw_loss 0.020636 lr 0.00041649 rank 2
2023-02-22 09:08:01,642 DEBUG TRAIN Batch 17/2300 loss 8.766764 loss_att 9.132129 loss_ctc 9.152064 loss_rnnt 8.622399 hw_loss 0.037345 lr 0.00041654 rank 4
2023-02-22 09:08:01,642 DEBUG TRAIN Batch 17/2300 loss 10.867386 loss_att 12.095539 loss_ctc 15.767084 loss_rnnt 9.949821 hw_loss 0.034951 lr 0.00041648 rank 3
2023-02-22 09:08:01,645 DEBUG TRAIN Batch 17/2300 loss 7.678126 loss_att 10.885979 loss_ctc 11.334373 loss_rnnt 6.422301 hw_loss 0.237667 lr 0.00041660 rank 1
2023-02-22 09:08:01,694 DEBUG TRAIN Batch 17/2300 loss 6.933241 loss_att 9.599242 loss_ctc 10.941740 loss_rnnt 5.796248 hw_loss 0.129986 lr 0.00041657 rank 6
2023-02-22 09:09:16,732 DEBUG TRAIN Batch 17/2400 loss 12.667912 loss_att 15.146350 loss_ctc 14.380908 loss_rnnt 11.920802 hw_loss 0.043167 lr 0.00041640 rank 4
2023-02-22 09:09:16,734 DEBUG TRAIN Batch 17/2400 loss 6.399024 loss_att 8.515038 loss_ctc 10.736303 loss_rnnt 5.380146 hw_loss 0.032571 lr 0.00041642 rank 0
2023-02-22 09:09:16,734 DEBUG TRAIN Batch 17/2400 loss 10.816561 loss_att 14.074268 loss_ctc 13.359583 loss_rnnt 9.736017 hw_loss 0.168625 lr 0.00041635 rank 2
2023-02-22 09:09:16,735 DEBUG TRAIN Batch 17/2400 loss 13.337083 loss_att 15.298841 loss_ctc 16.089489 loss_rnnt 12.501225 hw_loss 0.143472 lr 0.00041646 rank 1
2023-02-22 09:09:16,734 DEBUG TRAIN Batch 17/2400 loss 6.766838 loss_att 12.847662 loss_ctc 10.093436 loss_rnnt 5.074454 hw_loss 0.061260 lr 0.00041637 rank 5
2023-02-22 09:09:16,736 DEBUG TRAIN Batch 17/2400 loss 11.978618 loss_att 17.043587 loss_ctc 17.008369 loss_rnnt 10.200838 hw_loss 0.176536 lr 0.00041634 rank 3
2023-02-22 09:09:16,738 DEBUG TRAIN Batch 17/2400 loss 11.398937 loss_att 14.981123 loss_ctc 17.765291 loss_rnnt 9.738630 hw_loss 0.178168 lr 0.00041637 rank 7
2023-02-22 09:09:16,741 DEBUG TRAIN Batch 17/2400 loss 11.551023 loss_att 12.747870 loss_ctc 16.358236 loss_rnnt 10.622604 hw_loss 0.090163 lr 0.00041643 rank 6
2023-02-22 09:10:35,089 DEBUG TRAIN Batch 17/2500 loss 10.491878 loss_att 12.162466 loss_ctc 14.895302 loss_rnnt 9.477737 hw_loss 0.174185 lr 0.00041622 rank 7
2023-02-22 09:10:35,093 DEBUG TRAIN Batch 17/2500 loss 10.158575 loss_att 11.992566 loss_ctc 13.124400 loss_rnnt 9.328096 hw_loss 0.127943 lr 0.00041628 rank 6
2023-02-22 09:10:35,094 DEBUG TRAIN Batch 17/2500 loss 9.163934 loss_att 10.533905 loss_ctc 12.676798 loss_rnnt 8.279278 hw_loss 0.266773 lr 0.00041620 rank 2
2023-02-22 09:10:35,094 DEBUG TRAIN Batch 17/2500 loss 8.997321 loss_att 9.922037 loss_ctc 10.509720 loss_rnnt 8.507437 hw_loss 0.193666 lr 0.00041628 rank 0
2023-02-22 09:10:35,095 DEBUG TRAIN Batch 17/2500 loss 10.764244 loss_att 11.716406 loss_ctc 13.929589 loss_rnnt 10.027969 hw_loss 0.232120 lr 0.00041620 rank 3
2023-02-22 09:10:35,096 DEBUG TRAIN Batch 17/2500 loss 8.715510 loss_att 10.494119 loss_ctc 10.469786 loss_rnnt 8.030420 hw_loss 0.178998 lr 0.00041631 rank 1
2023-02-22 09:10:35,129 DEBUG TRAIN Batch 17/2500 loss 13.828186 loss_att 14.998646 loss_ctc 15.294711 loss_rnnt 13.337506 hw_loss 0.114469 lr 0.00041625 rank 4
2023-02-22 09:10:35,135 DEBUG TRAIN Batch 17/2500 loss 12.466783 loss_att 13.896345 loss_ctc 16.542234 loss_rnnt 11.609596 hw_loss 0.052275 lr 0.00041622 rank 5
2023-02-22 09:11:49,794 DEBUG TRAIN Batch 17/2600 loss 10.299082 loss_att 12.464920 loss_ctc 12.396414 loss_rnnt 9.540506 hw_loss 0.085808 lr 0.00041608 rank 7
2023-02-22 09:11:49,798 DEBUG TRAIN Batch 17/2600 loss 8.907349 loss_att 11.458540 loss_ctc 8.371384 loss_rnnt 8.366501 hw_loss 0.191384 lr 0.00041611 rank 4
2023-02-22 09:11:49,798 DEBUG TRAIN Batch 17/2600 loss 4.733402 loss_att 8.376616 loss_ctc 7.667741 loss_rnnt 3.534941 hw_loss 0.147323 lr 0.00041613 rank 0
2023-02-22 09:11:49,800 DEBUG TRAIN Batch 17/2600 loss 8.652699 loss_att 13.082241 loss_ctc 13.779144 loss_rnnt 7.068279 hw_loss 0.028094 lr 0.00041608 rank 5
2023-02-22 09:11:49,801 DEBUG TRAIN Batch 17/2600 loss 7.203563 loss_att 13.342063 loss_ctc 9.835402 loss_rnnt 5.577821 hw_loss 0.088367 lr 0.00041617 rank 1
2023-02-22 09:11:49,803 DEBUG TRAIN Batch 17/2600 loss 17.074793 loss_att 20.139633 loss_ctc 21.928013 loss_rnnt 15.738818 hw_loss 0.142329 lr 0.00041605 rank 3
2023-02-22 09:11:49,806 DEBUG TRAIN Batch 17/2600 loss 10.660746 loss_att 12.833655 loss_ctc 14.361671 loss_rnnt 9.675962 hw_loss 0.106397 lr 0.00041606 rank 2
2023-02-22 09:11:49,806 DEBUG TRAIN Batch 17/2600 loss 7.096771 loss_att 8.355664 loss_ctc 8.840416 loss_rnnt 6.559728 hw_loss 0.098959 lr 0.00041614 rank 6
2023-02-22 09:13:03,966 DEBUG TRAIN Batch 17/2700 loss 4.181319 loss_att 9.021437 loss_ctc 7.615657 loss_rnnt 2.718375 hw_loss 0.069391 lr 0.00041597 rank 4
2023-02-22 09:13:03,969 DEBUG TRAIN Batch 17/2700 loss 9.375442 loss_att 13.095342 loss_ctc 13.457247 loss_rnnt 8.052700 hw_loss 0.064725 lr 0.00041600 rank 6
2023-02-22 09:13:03,970 DEBUG TRAIN Batch 17/2700 loss 9.733054 loss_att 11.749367 loss_ctc 11.438469 loss_rnnt 9.051312 hw_loss 0.095794 lr 0.00041593 rank 5
2023-02-22 09:13:03,971 DEBUG TRAIN Batch 17/2700 loss 9.528932 loss_att 13.217471 loss_ctc 18.235077 loss_rnnt 7.583630 hw_loss 0.087701 lr 0.00041594 rank 7
2023-02-22 09:13:03,970 DEBUG TRAIN Batch 17/2700 loss 13.108786 loss_att 17.068653 loss_ctc 18.548054 loss_rnnt 11.530487 hw_loss 0.114544 lr 0.00041599 rank 0
2023-02-22 09:13:03,971 DEBUG TRAIN Batch 17/2700 loss 9.021297 loss_att 15.152839 loss_ctc 16.091822 loss_rnnt 6.784339 hw_loss 0.127337 lr 0.00041591 rank 3
2023-02-22 09:13:03,979 DEBUG TRAIN Batch 17/2700 loss 2.639721 loss_att 6.573835 loss_ctc 5.879388 loss_rnnt 1.312460 hw_loss 0.203405 lr 0.00041591 rank 2
2023-02-22 09:13:04,017 DEBUG TRAIN Batch 17/2700 loss 5.616553 loss_att 9.826775 loss_ctc 9.436995 loss_rnnt 4.195825 hw_loss 0.129923 lr 0.00041603 rank 1
2023-02-22 09:14:21,657 DEBUG TRAIN Batch 17/2800 loss 23.069525 loss_att 26.750681 loss_ctc 31.899887 loss_rnnt 21.071255 hw_loss 0.158736 lr 0.00041579 rank 5
2023-02-22 09:14:21,658 DEBUG TRAIN Batch 17/2800 loss 9.495794 loss_att 10.764485 loss_ctc 16.795536 loss_rnnt 8.215759 hw_loss 0.099370 lr 0.00041579 rank 7
2023-02-22 09:14:21,657 DEBUG TRAIN Batch 17/2800 loss 11.347258 loss_att 13.761738 loss_ctc 17.903152 loss_rnnt 9.964417 hw_loss 0.048420 lr 0.00041576 rank 3
2023-02-22 09:14:21,658 DEBUG TRAIN Batch 17/2800 loss 17.037800 loss_att 21.173033 loss_ctc 24.171268 loss_rnnt 15.215226 hw_loss 0.083247 lr 0.00041584 rank 0
2023-02-22 09:14:21,660 DEBUG TRAIN Batch 17/2800 loss 12.202109 loss_att 15.070583 loss_ctc 23.782461 loss_rnnt 10.000144 hw_loss 0.157920 lr 0.00041582 rank 4
2023-02-22 09:14:21,667 DEBUG TRAIN Batch 17/2800 loss 7.753696 loss_att 11.574680 loss_ctc 11.121605 loss_rnnt 6.457292 hw_loss 0.155912 lr 0.00041577 rank 2
2023-02-22 09:14:21,675 DEBUG TRAIN Batch 17/2800 loss 13.468927 loss_att 17.690571 loss_ctc 17.642988 loss_rnnt 12.032835 hw_loss 0.066043 lr 0.00041585 rank 6
2023-02-22 09:14:21,709 DEBUG TRAIN Batch 17/2800 loss 10.957178 loss_att 13.762053 loss_ctc 11.776779 loss_rnnt 10.237926 hw_loss 0.091869 lr 0.00041588 rank 1
2023-02-22 09:15:38,562 DEBUG TRAIN Batch 17/2900 loss 12.513617 loss_att 16.740471 loss_ctc 18.715118 loss_rnnt 10.790342 hw_loss 0.095696 lr 0.00041565 rank 7
2023-02-22 09:15:38,570 DEBUG TRAIN Batch 17/2900 loss 15.089245 loss_att 17.710838 loss_ctc 21.042992 loss_rnnt 13.703735 hw_loss 0.126296 lr 0.00041571 rank 6
2023-02-22 09:15:38,570 DEBUG TRAIN Batch 17/2900 loss 8.245939 loss_att 10.967110 loss_ctc 12.932409 loss_rnnt 6.936117 hw_loss 0.263860 lr 0.00041568 rank 4
2023-02-22 09:15:38,571 DEBUG TRAIN Batch 17/2900 loss 6.060372 loss_att 7.995569 loss_ctc 7.230835 loss_rnnt 5.437119 hw_loss 0.150284 lr 0.00041570 rank 0
2023-02-22 09:15:38,572 DEBUG TRAIN Batch 17/2900 loss 15.696918 loss_att 18.967274 loss_ctc 23.461929 loss_rnnt 13.956022 hw_loss 0.096542 lr 0.00041562 rank 3
2023-02-22 09:15:38,573 DEBUG TRAIN Batch 17/2900 loss 8.797709 loss_att 9.437389 loss_ctc 10.309055 loss_rnnt 8.427000 hw_loss 0.077362 lr 0.00041565 rank 5
2023-02-22 09:15:38,575 DEBUG TRAIN Batch 17/2900 loss 6.453131 loss_att 10.516265 loss_ctc 7.055786 loss_rnnt 5.500443 hw_loss 0.111952 lr 0.00041574 rank 1
2023-02-22 09:15:38,579 DEBUG TRAIN Batch 17/2900 loss 6.197406 loss_att 7.733105 loss_ctc 6.619825 loss_rnnt 5.767411 hw_loss 0.124748 lr 0.00041563 rank 2
2023-02-22 09:16:53,463 DEBUG TRAIN Batch 17/3000 loss 15.191958 loss_att 22.298687 loss_ctc 22.930937 loss_rnnt 12.684088 hw_loss 0.102491 lr 0.00041550 rank 5
2023-02-22 09:16:53,463 DEBUG TRAIN Batch 17/3000 loss 15.424593 loss_att 19.783407 loss_ctc 21.611647 loss_rnnt 13.712576 hw_loss 0.028714 lr 0.00041556 rank 0
2023-02-22 09:16:53,464 DEBUG TRAIN Batch 17/3000 loss 8.572996 loss_att 11.107086 loss_ctc 10.560544 loss_rnnt 7.715287 hw_loss 0.161032 lr 0.00041554 rank 4
2023-02-22 09:16:53,466 DEBUG TRAIN Batch 17/3000 loss 17.892473 loss_att 17.950485 loss_ctc 21.399609 loss_rnnt 17.391314 hw_loss 0.041134 lr 0.00041550 rank 7
2023-02-22 09:16:53,468 DEBUG TRAIN Batch 17/3000 loss 12.098853 loss_att 14.040640 loss_ctc 16.293995 loss_rnnt 11.111034 hw_loss 0.075204 lr 0.00041548 rank 3
2023-02-22 09:16:53,471 DEBUG TRAIN Batch 17/3000 loss 7.984942 loss_att 11.546984 loss_ctc 13.845514 loss_rnnt 6.403159 hw_loss 0.164935 lr 0.00041556 rank 6
2023-02-22 09:16:53,475 DEBUG TRAIN Batch 17/3000 loss 4.625234 loss_att 8.277660 loss_ctc 6.489477 loss_rnnt 3.605492 hw_loss 0.076294 lr 0.00041559 rank 1
2023-02-22 09:16:53,477 DEBUG TRAIN Batch 17/3000 loss 5.897254 loss_att 9.021147 loss_ctc 6.821538 loss_rnnt 5.100539 hw_loss 0.091311 lr 0.00041548 rank 2
2023-02-22 09:18:09,684 DEBUG TRAIN Batch 17/3100 loss 13.782037 loss_att 15.439925 loss_ctc 17.926401 loss_rnnt 12.810365 hw_loss 0.164087 lr 0.00041542 rank 6
2023-02-22 09:18:09,685 DEBUG TRAIN Batch 17/3100 loss 18.044216 loss_att 18.855015 loss_ctc 22.866365 loss_rnnt 17.195744 hw_loss 0.081300 lr 0.00041536 rank 7
2023-02-22 09:18:09,686 DEBUG TRAIN Batch 17/3100 loss 11.019708 loss_att 14.373047 loss_ctc 12.868080 loss_rnnt 10.044460 hw_loss 0.108993 lr 0.00041541 rank 0
2023-02-22 09:18:09,688 DEBUG TRAIN Batch 17/3100 loss 8.368212 loss_att 11.117809 loss_ctc 13.757198 loss_rnnt 7.011555 hw_loss 0.165387 lr 0.00041536 rank 5
2023-02-22 09:18:09,691 DEBUG TRAIN Batch 17/3100 loss 9.943462 loss_att 10.879796 loss_ctc 12.991652 loss_rnnt 9.235044 hw_loss 0.215114 lr 0.00041533 rank 3
2023-02-22 09:18:09,690 DEBUG TRAIN Batch 17/3100 loss 9.834368 loss_att 12.723745 loss_ctc 11.815980 loss_rnnt 8.912101 hw_loss 0.150330 lr 0.00041539 rank 4
2023-02-22 09:18:09,693 DEBUG TRAIN Batch 17/3100 loss 10.875541 loss_att 14.636986 loss_ctc 17.123350 loss_rnnt 9.212932 hw_loss 0.144899 lr 0.00041545 rank 1
2023-02-22 09:18:09,694 DEBUG TRAIN Batch 17/3100 loss 13.612117 loss_att 14.712498 loss_ctc 20.254313 loss_rnnt 12.463392 hw_loss 0.080666 lr 0.00041534 rank 2
2023-02-22 09:19:28,081 DEBUG TRAIN Batch 17/3200 loss 6.845203 loss_att 7.810660 loss_ctc 9.789606 loss_rnnt 6.168569 hw_loss 0.170543 lr 0.00041525 rank 4
2023-02-22 09:19:28,082 DEBUG TRAIN Batch 17/3200 loss 10.395622 loss_att 11.287632 loss_ctc 15.002021 loss_rnnt 9.496730 hw_loss 0.199320 lr 0.00041522 rank 7
2023-02-22 09:19:28,083 DEBUG TRAIN Batch 17/3200 loss 4.262340 loss_att 5.591394 loss_ctc 4.906114 loss_rnnt 3.814013 hw_loss 0.181276 lr 0.00041527 rank 0
2023-02-22 09:19:28,084 DEBUG TRAIN Batch 17/3200 loss 9.598595 loss_att 10.341111 loss_ctc 12.191359 loss_rnnt 9.046332 hw_loss 0.108856 lr 0.00041522 rank 5
2023-02-22 09:19:28,093 DEBUG TRAIN Batch 17/3200 loss 12.837172 loss_att 17.441803 loss_ctc 16.365192 loss_rnnt 11.403828 hw_loss 0.078779 lr 0.00041531 rank 1
2023-02-22 09:19:28,094 DEBUG TRAIN Batch 17/3200 loss 8.035211 loss_att 12.954970 loss_ctc 11.299608 loss_rnnt 6.576468 hw_loss 0.074132 lr 0.00041528 rank 6
2023-02-22 09:19:28,094 DEBUG TRAIN Batch 17/3200 loss 14.599797 loss_att 18.903877 loss_ctc 21.915747 loss_rnnt 12.746112 hw_loss 0.032642 lr 0.00041519 rank 3
2023-02-22 09:19:28,141 DEBUG TRAIN Batch 17/3200 loss 3.597751 loss_att 5.876932 loss_ctc 7.531051 loss_rnnt 2.533565 hw_loss 0.157330 lr 0.00041520 rank 2
2023-02-22 09:20:42,959 DEBUG TRAIN Batch 17/3300 loss 10.716241 loss_att 10.010244 loss_ctc 13.638258 loss_rnnt 10.381681 hw_loss 0.161542 lr 0.00041513 rank 0
2023-02-22 09:20:42,959 DEBUG TRAIN Batch 17/3300 loss 21.120901 loss_att 23.315485 loss_ctc 26.975128 loss_rnnt 19.888481 hw_loss 0.024262 lr 0.00041507 rank 5
2023-02-22 09:20:42,960 DEBUG TRAIN Batch 17/3300 loss 14.454529 loss_att 18.687063 loss_ctc 17.496078 loss_rnnt 13.161948 hw_loss 0.076000 lr 0.00041505 rank 3
2023-02-22 09:20:42,966 DEBUG TRAIN Batch 17/3300 loss 6.645709 loss_att 6.976587 loss_ctc 9.062654 loss_rnnt 6.196822 hw_loss 0.113349 lr 0.00041511 rank 4
2023-02-22 09:20:42,967 DEBUG TRAIN Batch 17/3300 loss 9.472531 loss_att 11.485798 loss_ctc 17.460058 loss_rnnt 7.956678 hw_loss 0.090368 lr 0.00041516 rank 1
2023-02-22 09:20:42,967 DEBUG TRAIN Batch 17/3300 loss 11.802510 loss_att 14.351493 loss_ctc 14.105530 loss_rnnt 10.943245 hw_loss 0.079498 lr 0.00041513 rank 6
2023-02-22 09:20:42,970 DEBUG TRAIN Batch 17/3300 loss 10.674286 loss_att 14.124928 loss_ctc 17.714979 loss_rnnt 9.045271 hw_loss 0.000239 lr 0.00041507 rank 7
2023-02-22 09:20:43,017 DEBUG TRAIN Batch 17/3300 loss 12.177609 loss_att 12.793976 loss_ctc 15.868727 loss_rnnt 11.478366 hw_loss 0.157162 lr 0.00041505 rank 2
2023-02-22 09:21:57,903 DEBUG TRAIN Batch 17/3400 loss 9.067193 loss_att 13.579824 loss_ctc 13.111000 loss_rnnt 7.558326 hw_loss 0.125938 lr 0.00041493 rank 7
2023-02-22 09:21:57,904 DEBUG TRAIN Batch 17/3400 loss 16.665794 loss_att 21.475998 loss_ctc 22.523495 loss_rnnt 14.871501 hw_loss 0.096050 lr 0.00041498 rank 0
2023-02-22 09:21:57,908 DEBUG TRAIN Batch 17/3400 loss 12.423246 loss_att 13.569229 loss_ctc 11.956493 loss_rnnt 12.155525 hw_loss 0.188922 lr 0.00041490 rank 3
2023-02-22 09:21:57,908 DEBUG TRAIN Batch 17/3400 loss 9.186857 loss_att 13.343899 loss_ctc 12.438762 loss_rnnt 7.858627 hw_loss 0.118566 lr 0.00041496 rank 4
2023-02-22 09:21:57,909 DEBUG TRAIN Batch 17/3400 loss 6.684199 loss_att 10.063841 loss_ctc 8.240316 loss_rnnt 5.713968 hw_loss 0.162789 lr 0.00041493 rank 5
2023-02-22 09:21:57,910 DEBUG TRAIN Batch 17/3400 loss 13.599401 loss_att 15.808540 loss_ctc 17.471487 loss_rnnt 12.608594 hw_loss 0.061316 lr 0.00041491 rank 2
2023-02-22 09:21:57,915 DEBUG TRAIN Batch 17/3400 loss 13.062128 loss_att 16.940910 loss_ctc 23.374638 loss_rnnt 10.888968 hw_loss 0.042008 lr 0.00041499 rank 6
2023-02-22 09:21:57,917 DEBUG TRAIN Batch 17/3400 loss 9.986189 loss_att 15.169069 loss_ctc 16.912235 loss_rnnt 7.906442 hw_loss 0.224433 lr 0.00041502 rank 1
2023-02-22 09:23:14,294 DEBUG TRAIN Batch 17/3500 loss 18.693380 loss_att 18.865187 loss_ctc 24.393978 loss_rnnt 17.797792 hw_loss 0.189646 lr 0.00041479 rank 7
2023-02-22 09:23:14,293 DEBUG TRAIN Batch 17/3500 loss 14.563286 loss_att 19.500441 loss_ctc 23.104719 loss_rnnt 12.399118 hw_loss 0.071021 lr 0.00041484 rank 0
2023-02-22 09:23:14,294 DEBUG TRAIN Batch 17/3500 loss 2.205247 loss_att 6.607419 loss_ctc 3.554557 loss_rnnt 1.035122 hw_loss 0.205842 lr 0.00041479 rank 5
2023-02-22 09:23:14,295 DEBUG TRAIN Batch 17/3500 loss 7.820127 loss_att 12.800991 loss_ctc 15.490484 loss_rnnt 5.762015 hw_loss 0.073546 lr 0.00041476 rank 3
2023-02-22 09:23:14,297 DEBUG TRAIN Batch 17/3500 loss 9.989957 loss_att 13.183125 loss_ctc 12.998890 loss_rnnt 8.840303 hw_loss 0.205928 lr 0.00041482 rank 4
2023-02-22 09:23:14,299 DEBUG TRAIN Batch 17/3500 loss 7.287168 loss_att 10.251539 loss_ctc 7.779559 loss_rnnt 6.574732 hw_loss 0.101081 lr 0.00041488 rank 1
2023-02-22 09:23:14,300 DEBUG TRAIN Batch 17/3500 loss 14.574977 loss_att 18.088856 loss_ctc 23.079676 loss_rnnt 12.656536 hw_loss 0.153198 lr 0.00041477 rank 2
2023-02-22 09:23:14,304 DEBUG TRAIN Batch 17/3500 loss 12.092708 loss_att 13.990757 loss_ctc 15.826336 loss_rnnt 11.166082 hw_loss 0.092246 lr 0.00041485 rank 6
2023-02-22 09:24:31,947 DEBUG TRAIN Batch 17/3600 loss 8.576335 loss_att 9.843744 loss_ctc 10.373784 loss_rnnt 8.009764 hw_loss 0.137679 lr 0.00041465 rank 7
2023-02-22 09:24:31,954 DEBUG TRAIN Batch 17/3600 loss 2.563882 loss_att 6.052432 loss_ctc 4.937326 loss_rnnt 1.491999 hw_loss 0.108213 lr 0.00041464 rank 5
2023-02-22 09:24:31,954 DEBUG TRAIN Batch 17/3600 loss 9.121946 loss_att 12.052428 loss_ctc 12.641916 loss_rnnt 8.007268 hw_loss 0.111098 lr 0.00041462 rank 2
2023-02-22 09:24:31,954 DEBUG TRAIN Batch 17/3600 loss 4.933024 loss_att 7.245067 loss_ctc 6.845566 loss_rnnt 4.156830 hw_loss 0.110212 lr 0.00041474 rank 1
2023-02-22 09:24:31,954 DEBUG TRAIN Batch 17/3600 loss 15.069390 loss_att 17.770763 loss_ctc 15.090887 loss_rnnt 14.447032 hw_loss 0.148532 lr 0.00041470 rank 0
2023-02-22 09:24:31,955 DEBUG TRAIN Batch 17/3600 loss 9.378716 loss_att 11.807726 loss_ctc 16.816044 loss_rnnt 7.845948 hw_loss 0.103728 lr 0.00041468 rank 4
2023-02-22 09:24:31,958 DEBUG TRAIN Batch 17/3600 loss 15.826187 loss_att 15.729627 loss_ctc 21.490250 loss_rnnt 15.018538 hw_loss 0.134534 lr 0.00041462 rank 3
2023-02-22 09:24:31,961 DEBUG TRAIN Batch 17/3600 loss 17.703501 loss_att 24.891521 loss_ctc 23.861166 loss_rnnt 15.398680 hw_loss 0.086617 lr 0.00041471 rank 6
2023-02-22 09:25:46,957 DEBUG TRAIN Batch 17/3700 loss 9.862177 loss_att 10.786018 loss_ctc 12.704636 loss_rnnt 9.168152 hw_loss 0.244240 lr 0.00041455 rank 0
2023-02-22 09:25:46,958 DEBUG TRAIN Batch 17/3700 loss 4.189234 loss_att 6.268292 loss_ctc 6.791723 loss_rnnt 3.340632 hw_loss 0.160860 lr 0.00041450 rank 7
2023-02-22 09:25:46,958 DEBUG TRAIN Batch 17/3700 loss 12.573736 loss_att 14.030234 loss_ctc 17.416895 loss_rnnt 11.591646 hw_loss 0.084440 lr 0.00041450 rank 5
2023-02-22 09:25:46,959 DEBUG TRAIN Batch 17/3700 loss 7.365556 loss_att 9.124407 loss_ctc 9.350317 loss_rnnt 6.701801 hw_loss 0.088781 lr 0.00041453 rank 4
2023-02-22 09:25:46,961 DEBUG TRAIN Batch 17/3700 loss 12.869007 loss_att 17.035034 loss_ctc 22.424747 loss_rnnt 10.670027 hw_loss 0.171896 lr 0.00041459 rank 1
2023-02-22 09:25:46,963 DEBUG TRAIN Batch 17/3700 loss 13.867455 loss_att 13.599714 loss_ctc 16.760792 loss_rnnt 13.431546 hw_loss 0.194399 lr 0.00041448 rank 3
2023-02-22 09:25:46,962 DEBUG TRAIN Batch 17/3700 loss 11.531652 loss_att 12.373164 loss_ctc 15.404745 loss_rnnt 10.754404 hw_loss 0.173498 lr 0.00041448 rank 2
2023-02-22 09:25:46,964 DEBUG TRAIN Batch 17/3700 loss 8.315219 loss_att 11.024405 loss_ctc 11.494715 loss_rnnt 7.276068 hw_loss 0.137589 lr 0.00041456 rank 6
2023-02-22 09:27:03,421 DEBUG TRAIN Batch 17/3800 loss 11.117188 loss_att 11.289937 loss_ctc 13.298418 loss_rnnt 10.681159 hw_loss 0.207466 lr 0.00041436 rank 5
2023-02-22 09:27:03,423 DEBUG TRAIN Batch 17/3800 loss 7.063431 loss_att 6.856595 loss_ctc 10.398005 loss_rnnt 6.576218 hw_loss 0.157445 lr 0.00041442 rank 6
2023-02-22 09:27:03,428 DEBUG TRAIN Batch 17/3800 loss 10.287604 loss_att 10.675038 loss_ctc 14.077715 loss_rnnt 9.578186 hw_loss 0.237347 lr 0.00041439 rank 4
2023-02-22 09:27:03,429 DEBUG TRAIN Batch 17/3800 loss 6.457133 loss_att 8.411974 loss_ctc 9.135090 loss_rnnt 5.662700 hw_loss 0.087007 lr 0.00041441 rank 0
2023-02-22 09:27:03,429 DEBUG TRAIN Batch 17/3800 loss 11.303513 loss_att 13.198040 loss_ctc 18.189819 loss_rnnt 9.949854 hw_loss 0.106086 lr 0.00041445 rank 1
2023-02-22 09:27:03,430 DEBUG TRAIN Batch 17/3800 loss 8.991506 loss_att 10.419914 loss_ctc 13.233054 loss_rnnt 8.021472 hw_loss 0.222774 lr 0.00041436 rank 7
2023-02-22 09:27:03,435 DEBUG TRAIN Batch 17/3800 loss 8.865319 loss_att 10.927769 loss_ctc 8.586191 loss_rnnt 8.406568 hw_loss 0.156522 lr 0.00041434 rank 2
2023-02-22 09:27:03,474 DEBUG TRAIN Batch 17/3800 loss 7.179465 loss_att 13.690495 loss_ctc 10.730091 loss_rnnt 5.286580 hw_loss 0.219866 lr 0.00041433 rank 3
2023-02-22 09:28:22,699 DEBUG TRAIN Batch 17/3900 loss 12.949992 loss_att 15.266571 loss_ctc 20.366587 loss_rnnt 11.447277 hw_loss 0.094725 lr 0.00041427 rank 0
2023-02-22 09:28:22,705 DEBUG TRAIN Batch 17/3900 loss 6.277986 loss_att 9.466115 loss_ctc 7.847990 loss_rnnt 5.413711 hw_loss 0.032465 lr 0.00041425 rank 4
2023-02-22 09:28:22,706 DEBUG TRAIN Batch 17/3900 loss 2.145989 loss_att 6.656393 loss_ctc 4.443992 loss_rnnt 0.910422 hw_loss 0.050786 lr 0.00041431 rank 1
2023-02-22 09:28:22,710 DEBUG TRAIN Batch 17/3900 loss 10.683139 loss_att 15.697283 loss_ctc 15.378374 loss_rnnt 8.990335 hw_loss 0.119893 lr 0.00041428 rank 6
2023-02-22 09:28:22,719 DEBUG TRAIN Batch 17/3900 loss 10.988041 loss_att 15.383987 loss_ctc 16.690435 loss_rnnt 9.325173 hw_loss 0.043796 lr 0.00041420 rank 2
2023-02-22 09:28:22,724 DEBUG TRAIN Batch 17/3900 loss 12.037718 loss_att 14.573748 loss_ctc 18.303802 loss_rnnt 10.644600 hw_loss 0.094562 lr 0.00041422 rank 5
2023-02-22 09:28:22,731 DEBUG TRAIN Batch 17/3900 loss 4.539283 loss_att 7.495724 loss_ctc 4.648383 loss_rnnt 3.885911 hw_loss 0.089135 lr 0.00041419 rank 3
2023-02-22 09:28:22,754 DEBUG TRAIN Batch 17/3900 loss 13.629111 loss_att 18.229630 loss_ctc 19.613895 loss_rnnt 11.880777 hw_loss 0.056735 lr 0.00041422 rank 7
2023-02-22 09:29:38,766 DEBUG TRAIN Batch 17/4000 loss 9.679079 loss_att 12.127659 loss_ctc 10.513991 loss_rnnt 8.998644 hw_loss 0.148871 lr 0.00041413 rank 0
2023-02-22 09:29:38,767 DEBUG TRAIN Batch 17/4000 loss 21.895575 loss_att 23.376568 loss_ctc 26.163151 loss_rnnt 21.016069 hw_loss 0.026802 lr 0.00041417 rank 1
2023-02-22 09:29:38,770 DEBUG TRAIN Batch 17/4000 loss 14.056201 loss_att 18.725456 loss_ctc 22.806648 loss_rnnt 11.921859 hw_loss 0.063308 lr 0.00041408 rank 7
2023-02-22 09:29:38,772 DEBUG TRAIN Batch 17/4000 loss 4.672570 loss_att 5.607359 loss_ctc 6.077207 loss_rnnt 4.248665 hw_loss 0.093115 lr 0.00041408 rank 5
2023-02-22 09:29:38,772 DEBUG TRAIN Batch 17/4000 loss 11.007076 loss_att 13.551302 loss_ctc 17.955051 loss_rnnt 9.519831 hw_loss 0.097508 lr 0.00041411 rank 4
2023-02-22 09:29:38,773 DEBUG TRAIN Batch 17/4000 loss 40.272785 loss_att 45.884727 loss_ctc 55.647789 loss_rnnt 37.049389 hw_loss 0.095643 lr 0.00041405 rank 3
2023-02-22 09:29:38,775 DEBUG TRAIN Batch 17/4000 loss 6.616553 loss_att 9.655085 loss_ctc 8.783449 loss_rnnt 5.658881 hw_loss 0.114461 lr 0.00041406 rank 2
2023-02-22 09:29:38,775 DEBUG TRAIN Batch 17/4000 loss 8.687578 loss_att 14.635222 loss_ctc 13.214823 loss_rnnt 6.886168 hw_loss 0.015465 lr 0.00041414 rank 6
2023-02-22 09:30:53,691 DEBUG TRAIN Batch 17/4100 loss 7.443641 loss_att 9.625165 loss_ctc 9.920223 loss_rnnt 6.606337 hw_loss 0.132729 lr 0.00041393 rank 5
2023-02-22 09:30:53,692 DEBUG TRAIN Batch 17/4100 loss 6.387146 loss_att 10.000851 loss_ctc 11.114056 loss_rnnt 4.992574 hw_loss 0.077956 lr 0.00041397 rank 4
2023-02-22 09:30:53,696 DEBUG TRAIN Batch 17/4100 loss 15.013013 loss_att 19.879490 loss_ctc 21.205406 loss_rnnt 13.128742 hw_loss 0.159980 lr 0.00041399 rank 6
2023-02-22 09:30:53,697 DEBUG TRAIN Batch 17/4100 loss 15.900027 loss_att 20.794147 loss_ctc 22.772291 loss_rnnt 13.957221 hw_loss 0.089399 lr 0.00041399 rank 0
2023-02-22 09:30:53,697 DEBUG TRAIN Batch 17/4100 loss 7.329612 loss_att 12.358579 loss_ctc 11.549744 loss_rnnt 5.708767 hw_loss 0.098189 lr 0.00041393 rank 7
2023-02-22 09:30:53,701 DEBUG TRAIN Batch 17/4100 loss 19.386862 loss_att 24.305103 loss_ctc 31.710276 loss_rnnt 16.717484 hw_loss 0.079892 lr 0.00041391 rank 3
2023-02-22 09:30:53,702 DEBUG TRAIN Batch 17/4100 loss 11.245912 loss_att 13.902510 loss_ctc 15.654133 loss_rnnt 10.024669 hw_loss 0.191551 lr 0.00041402 rank 1
2023-02-22 09:30:53,703 DEBUG TRAIN Batch 17/4100 loss 11.822987 loss_att 16.135124 loss_ctc 19.644867 loss_rnnt 9.793692 hw_loss 0.232405 lr 0.00041391 rank 2
2023-02-22 09:32:11,005 DEBUG TRAIN Batch 17/4200 loss 13.956574 loss_att 18.160625 loss_ctc 18.038776 loss_rnnt 12.512977 hw_loss 0.109675 lr 0.00041385 rank 6
2023-02-22 09:32:11,006 DEBUG TRAIN Batch 17/4200 loss 9.147264 loss_att 13.649462 loss_ctc 11.495251 loss_rnnt 7.823159 hw_loss 0.207374 lr 0.00041382 rank 4
2023-02-22 09:32:11,008 DEBUG TRAIN Batch 17/4200 loss 18.259527 loss_att 22.018084 loss_ctc 30.285774 loss_rnnt 15.875082 hw_loss 0.054812 lr 0.00041379 rank 7
2023-02-22 09:32:11,009 DEBUG TRAIN Batch 17/4200 loss 14.066546 loss_att 17.154528 loss_ctc 26.899805 loss_rnnt 11.634979 hw_loss 0.192881 lr 0.00041379 rank 5
2023-02-22 09:32:11,010 DEBUG TRAIN Batch 17/4200 loss 14.235888 loss_att 18.509184 loss_ctc 17.501888 loss_rnnt 12.863771 hw_loss 0.153731 lr 0.00041384 rank 0
2023-02-22 09:32:11,010 DEBUG TRAIN Batch 17/4200 loss 13.851341 loss_att 15.254857 loss_ctc 17.130974 loss_rnnt 13.079679 hw_loss 0.100639 lr 0.00041377 rank 3
2023-02-22 09:32:11,010 DEBUG TRAIN Batch 17/4200 loss 19.463598 loss_att 21.256626 loss_ctc 27.497059 loss_rnnt 17.939112 hw_loss 0.177658 lr 0.00041377 rank 2
2023-02-22 09:32:11,012 DEBUG TRAIN Batch 17/4200 loss 12.706470 loss_att 17.030064 loss_ctc 19.088602 loss_rnnt 10.900085 hw_loss 0.170091 lr 0.00041388 rank 1
2023-02-22 09:33:29,851 DEBUG TRAIN Batch 17/4300 loss 13.442539 loss_att 19.102711 loss_ctc 18.139717 loss_rnnt 11.628387 hw_loss 0.104675 lr 0.00041365 rank 5
2023-02-22 09:33:29,855 DEBUG TRAIN Batch 17/4300 loss 8.504552 loss_att 11.825104 loss_ctc 11.253500 loss_rnnt 7.360784 hw_loss 0.212122 lr 0.00041365 rank 7
2023-02-22 09:33:29,856 DEBUG TRAIN Batch 17/4300 loss 5.389866 loss_att 7.000744 loss_ctc 7.785435 loss_rnnt 4.668056 hw_loss 0.150423 lr 0.00041362 rank 3
2023-02-22 09:33:29,857 DEBUG TRAIN Batch 17/4300 loss 9.583496 loss_att 12.437514 loss_ctc 11.906969 loss_rnnt 8.670746 hw_loss 0.060281 lr 0.00041370 rank 0
2023-02-22 09:33:29,858 DEBUG TRAIN Batch 17/4300 loss 6.437062 loss_att 9.602229 loss_ctc 9.053001 loss_rnnt 5.359375 hw_loss 0.179741 lr 0.00041368 rank 4
2023-02-22 09:33:29,861 DEBUG TRAIN Batch 17/4300 loss 9.067677 loss_att 11.292643 loss_ctc 14.051788 loss_rnnt 7.839794 hw_loss 0.221892 lr 0.00041371 rank 6
2023-02-22 09:33:29,861 DEBUG TRAIN Batch 17/4300 loss 11.609643 loss_att 15.806297 loss_ctc 17.059975 loss_rnnt 10.014099 hw_loss 0.055316 lr 0.00041374 rank 1
2023-02-22 09:33:29,862 DEBUG TRAIN Batch 17/4300 loss 12.185970 loss_att 11.890999 loss_ctc 17.523779 loss_rnnt 11.477607 hw_loss 0.104346 lr 0.00041363 rank 2
2023-02-22 09:34:45,142 DEBUG TRAIN Batch 17/4400 loss 16.116205 loss_att 17.809286 loss_ctc 22.704351 loss_rnnt 14.820084 hw_loss 0.148288 lr 0.00041356 rank 0
2023-02-22 09:34:45,145 DEBUG TRAIN Batch 17/4400 loss 14.604403 loss_att 18.189831 loss_ctc 24.364346 loss_rnnt 12.469006 hw_loss 0.219350 lr 0.00041351 rank 7
2023-02-22 09:34:45,150 DEBUG TRAIN Batch 17/4400 loss 11.037129 loss_att 13.543152 loss_ctc 16.436951 loss_rnnt 9.780964 hw_loss 0.065596 lr 0.00041351 rank 5
2023-02-22 09:34:45,151 DEBUG TRAIN Batch 17/4400 loss 7.145019 loss_att 8.330502 loss_ctc 8.732917 loss_rnnt 6.607863 hw_loss 0.165638 lr 0.00041354 rank 4
2023-02-22 09:34:45,151 DEBUG TRAIN Batch 17/4400 loss 15.777582 loss_att 17.673424 loss_ctc 20.461025 loss_rnnt 14.735176 hw_loss 0.072710 lr 0.00041360 rank 1
2023-02-22 09:34:45,151 DEBUG TRAIN Batch 17/4400 loss 9.859557 loss_att 12.173967 loss_ctc 13.367255 loss_rnnt 8.878605 hw_loss 0.094458 lr 0.00041357 rank 6
2023-02-22 09:34:45,152 DEBUG TRAIN Batch 17/4400 loss 18.812872 loss_att 18.543598 loss_ctc 26.849506 loss_rnnt 17.764521 hw_loss 0.057478 lr 0.00041348 rank 3
2023-02-22 09:34:45,154 DEBUG TRAIN Batch 17/4400 loss 18.656134 loss_att 22.394264 loss_ctc 25.566641 loss_rnnt 16.911009 hw_loss 0.142682 lr 0.00041349 rank 2
2023-02-22 09:35:58,488 DEBUG TRAIN Batch 17/4500 loss 6.644019 loss_att 7.128329 loss_ctc 8.330644 loss_rnnt 6.205652 hw_loss 0.218665 lr 0.00041337 rank 7
2023-02-22 09:35:58,490 DEBUG TRAIN Batch 17/4500 loss 7.047313 loss_att 11.693576 loss_ctc 7.922160 loss_rnnt 5.930625 hw_loss 0.132728 lr 0.00041343 rank 6
2023-02-22 09:35:58,491 DEBUG TRAIN Batch 17/4500 loss 4.024246 loss_att 6.910843 loss_ctc 4.636115 loss_rnnt 3.309477 hw_loss 0.104750 lr 0.00041346 rank 1
2023-02-22 09:35:58,491 DEBUG TRAIN Batch 17/4500 loss 9.015976 loss_att 12.855659 loss_ctc 10.859416 loss_rnnt 7.966642 hw_loss 0.066759 lr 0.00041335 rank 2
2023-02-22 09:35:58,491 DEBUG TRAIN Batch 17/4500 loss 9.449672 loss_att 15.047014 loss_ctc 13.687943 loss_rnnt 7.651993 hw_loss 0.212077 lr 0.00041342 rank 0
2023-02-22 09:35:58,494 DEBUG TRAIN Batch 17/4500 loss 12.395452 loss_att 13.523091 loss_ctc 17.405355 loss_rnnt 11.432726 hw_loss 0.129771 lr 0.00041337 rank 5
2023-02-22 09:35:58,496 DEBUG TRAIN Batch 17/4500 loss 6.435032 loss_att 10.619618 loss_ctc 8.416431 loss_rnnt 5.314610 hw_loss 0.036222 lr 0.00041340 rank 4
2023-02-22 09:35:58,496 DEBUG TRAIN Batch 17/4500 loss 10.190874 loss_att 12.279430 loss_ctc 14.137573 loss_rnnt 9.202831 hw_loss 0.082698 lr 0.00041334 rank 3
2023-02-22 09:37:16,164 DEBUG TRAIN Batch 17/4600 loss 9.021411 loss_att 10.433581 loss_ctc 13.461679 loss_rnnt 8.043509 hw_loss 0.193937 lr 0.00041323 rank 7
2023-02-22 09:37:16,168 DEBUG TRAIN Batch 17/4600 loss 9.888191 loss_att 17.016470 loss_ctc 11.887932 loss_rnnt 8.194917 hw_loss 0.001849 lr 0.00041320 rank 3
2023-02-22 09:37:16,168 DEBUG TRAIN Batch 17/4600 loss 14.523032 loss_att 13.455188 loss_ctc 16.539780 loss_rnnt 14.412471 hw_loss 0.103558 lr 0.00041323 rank 5
2023-02-22 09:37:16,168 DEBUG TRAIN Batch 17/4600 loss 15.078798 loss_att 17.290213 loss_ctc 23.968071 loss_rnnt 13.379154 hw_loss 0.135232 lr 0.00041321 rank 2
2023-02-22 09:37:16,168 DEBUG TRAIN Batch 17/4600 loss 7.968664 loss_att 10.141586 loss_ctc 10.426340 loss_rnnt 7.151395 hw_loss 0.103113 lr 0.00041329 rank 6
2023-02-22 09:37:16,169 DEBUG TRAIN Batch 17/4600 loss 6.102674 loss_att 10.301056 loss_ctc 10.869922 loss_rnnt 4.607279 hw_loss 0.037658 lr 0.00041326 rank 4
2023-02-22 09:37:16,173 DEBUG TRAIN Batch 17/4600 loss 9.543417 loss_att 10.607315 loss_ctc 11.500505 loss_rnnt 8.979064 hw_loss 0.169928 lr 0.00041328 rank 0
2023-02-22 09:37:16,177 DEBUG TRAIN Batch 17/4600 loss 9.647955 loss_att 15.145836 loss_ctc 17.839184 loss_rnnt 7.429668 hw_loss 0.049776 lr 0.00041332 rank 1
2023-02-22 09:38:32,073 DEBUG TRAIN Batch 17/4700 loss 8.298369 loss_att 9.143398 loss_ctc 14.000319 loss_rnnt 7.311588 hw_loss 0.107842 lr 0.00041314 rank 0
2023-02-22 09:38:32,077 DEBUG TRAIN Batch 17/4700 loss 14.054681 loss_att 17.201477 loss_ctc 19.061592 loss_rnnt 12.671907 hw_loss 0.160922 lr 0.00041318 rank 1
2023-02-22 09:38:32,077 DEBUG TRAIN Batch 17/4700 loss 11.328424 loss_att 13.802343 loss_ctc 18.237333 loss_rnnt 9.847013 hw_loss 0.122695 lr 0.00041307 rank 2
2023-02-22 09:38:32,079 DEBUG TRAIN Batch 17/4700 loss 9.074332 loss_att 13.500392 loss_ctc 13.121900 loss_rnnt 7.582303 hw_loss 0.125889 lr 0.00041312 rank 4
2023-02-22 09:38:32,079 DEBUG TRAIN Batch 17/4700 loss 11.561158 loss_att 15.816212 loss_ctc 16.487663 loss_rnnt 9.994171 hw_loss 0.110828 lr 0.00041306 rank 3
2023-02-22 09:38:32,081 DEBUG TRAIN Batch 17/4700 loss 21.583263 loss_att 25.624149 loss_ctc 28.769156 loss_rnnt 19.733229 hw_loss 0.157014 lr 0.00041308 rank 5
2023-02-22 09:38:32,082 DEBUG TRAIN Batch 17/4700 loss 18.419508 loss_att 20.429722 loss_ctc 25.443748 loss_rnnt 16.990095 hw_loss 0.170262 lr 0.00041309 rank 7
2023-02-22 09:38:32,085 DEBUG TRAIN Batch 17/4700 loss 6.974442 loss_att 10.627837 loss_ctc 9.704047 loss_rnnt 5.815489 hw_loss 0.120612 lr 0.00041315 rank 6
2023-02-22 09:39:47,132 DEBUG TRAIN Batch 17/4800 loss 8.179877 loss_att 10.806690 loss_ctc 11.063416 loss_rnnt 7.223104 hw_loss 0.088007 lr 0.00041295 rank 7
2023-02-22 09:39:47,134 DEBUG TRAIN Batch 17/4800 loss 8.302109 loss_att 10.865980 loss_ctc 9.669273 loss_rnnt 7.526913 hw_loss 0.150249 lr 0.00041303 rank 1
2023-02-22 09:39:47,135 DEBUG TRAIN Batch 17/4800 loss 3.382867 loss_att 7.777999 loss_ctc 4.276092 loss_rnnt 2.371374 hw_loss 0.025069 lr 0.00041294 rank 5
2023-02-22 09:39:47,135 DEBUG TRAIN Batch 17/4800 loss 6.193061 loss_att 9.770341 loss_ctc 10.263240 loss_rnnt 4.878726 hw_loss 0.105354 lr 0.00041300 rank 0
2023-02-22 09:39:47,136 DEBUG TRAIN Batch 17/4800 loss 11.434872 loss_att 12.172166 loss_ctc 12.035227 loss_rnnt 11.169777 hw_loss 0.070480 lr 0.00041300 rank 6
2023-02-22 09:39:47,137 DEBUG TRAIN Batch 17/4800 loss 10.811124 loss_att 17.004974 loss_ctc 14.294542 loss_rnnt 9.050569 hw_loss 0.107493 lr 0.00041292 rank 2
2023-02-22 09:39:47,137 DEBUG TRAIN Batch 17/4800 loss 8.155290 loss_att 10.205365 loss_ctc 10.317968 loss_rnnt 7.432874 hw_loss 0.045080 lr 0.00041298 rank 4
2023-02-22 09:39:47,140 DEBUG TRAIN Batch 17/4800 loss 10.261724 loss_att 12.196335 loss_ctc 13.372938 loss_rnnt 9.414989 hw_loss 0.084348 lr 0.00041292 rank 3
2023-02-22 09:41:02,726 DEBUG TRAIN Batch 17/4900 loss 2.658730 loss_att 4.929040 loss_ctc 4.697244 loss_rnnt 1.857529 hw_loss 0.141257 lr 0.00041280 rank 5
2023-02-22 09:41:02,727 DEBUG TRAIN Batch 17/4900 loss 5.445873 loss_att 7.257625 loss_ctc 6.460893 loss_rnnt 4.876294 hw_loss 0.134799 lr 0.00041280 rank 7
2023-02-22 09:41:02,730 DEBUG TRAIN Batch 17/4900 loss 10.713385 loss_att 14.538635 loss_ctc 14.246025 loss_rnnt 9.442069 hw_loss 0.066087 lr 0.00041289 rank 1
2023-02-22 09:41:02,732 DEBUG TRAIN Batch 17/4900 loss 9.314518 loss_att 11.022140 loss_ctc 11.752443 loss_rnnt 8.597058 hw_loss 0.095395 lr 0.00041278 rank 2
2023-02-22 09:41:02,732 DEBUG TRAIN Batch 17/4900 loss 11.563460 loss_att 15.880404 loss_ctc 18.773396 loss_rnnt 9.720744 hw_loss 0.033757 lr 0.00041286 rank 0
2023-02-22 09:41:02,734 DEBUG TRAIN Batch 17/4900 loss 3.231869 loss_att 6.258037 loss_ctc 4.122801 loss_rnnt 2.454085 hw_loss 0.100799 lr 0.00041284 rank 4
2023-02-22 09:41:02,737 DEBUG TRAIN Batch 17/4900 loss 10.235839 loss_att 11.584380 loss_ctc 15.320027 loss_rnnt 9.240656 hw_loss 0.089218 lr 0.00041278 rank 3
2023-02-22 09:41:02,782 DEBUG TRAIN Batch 17/4900 loss 8.186204 loss_att 10.541163 loss_ctc 12.208885 loss_rnnt 7.150290 hw_loss 0.053558 lr 0.00041286 rank 6
2023-02-22 09:42:20,844 DEBUG TRAIN Batch 17/5000 loss 13.624291 loss_att 12.044195 loss_ctc 17.583910 loss_rnnt 13.360291 hw_loss 0.097632 lr 0.00041269 rank 4
2023-02-22 09:42:20,845 DEBUG TRAIN Batch 17/5000 loss 7.130532 loss_att 9.830650 loss_ctc 9.941834 loss_rnnt 6.166882 hw_loss 0.091476 lr 0.00041266 rank 7
2023-02-22 09:42:20,846 DEBUG TRAIN Batch 17/5000 loss 6.337009 loss_att 10.097922 loss_ctc 9.453039 loss_rnnt 5.101477 hw_loss 0.127272 lr 0.00041271 rank 0
2023-02-22 09:42:20,850 DEBUG TRAIN Batch 17/5000 loss 17.897541 loss_att 20.874756 loss_ctc 24.286489 loss_rnnt 16.371208 hw_loss 0.148184 lr 0.00041266 rank 5
2023-02-22 09:42:20,855 DEBUG TRAIN Batch 17/5000 loss 11.978412 loss_att 13.642950 loss_ctc 15.758526 loss_rnnt 11.021046 hw_loss 0.225831 lr 0.00041264 rank 2
2023-02-22 09:42:20,855 DEBUG TRAIN Batch 17/5000 loss 10.537038 loss_att 11.604749 loss_ctc 16.118446 loss_rnnt 9.513150 hw_loss 0.124045 lr 0.00041272 rank 6
2023-02-22 09:42:20,904 DEBUG TRAIN Batch 17/5000 loss 7.021031 loss_att 8.995892 loss_ctc 9.866975 loss_rnnt 6.108705 hw_loss 0.258552 lr 0.00041275 rank 1
2023-02-22 09:42:20,924 DEBUG TRAIN Batch 17/5000 loss 7.653991 loss_att 8.167326 loss_ctc 11.753142 loss_rnnt 6.860918 hw_loss 0.269723 lr 0.00041264 rank 3
2023-02-22 09:43:36,165 DEBUG TRAIN Batch 17/5100 loss 4.562713 loss_att 7.941114 loss_ctc 4.960413 loss_rnnt 3.799402 hw_loss 0.064882 lr 0.00041255 rank 4
2023-02-22 09:43:36,166 DEBUG TRAIN Batch 17/5100 loss 10.654435 loss_att 10.057600 loss_ctc 14.021387 loss_rnnt 10.220070 hw_loss 0.196508 lr 0.00041252 rank 7
2023-02-22 09:43:36,166 DEBUG TRAIN Batch 17/5100 loss 8.519675 loss_att 12.246466 loss_ctc 11.493549 loss_rnnt 7.302911 hw_loss 0.140416 lr 0.00041252 rank 5
2023-02-22 09:43:36,167 DEBUG TRAIN Batch 17/5100 loss 8.566857 loss_att 9.158922 loss_ctc 11.138115 loss_rnnt 8.027480 hw_loss 0.146494 lr 0.00041257 rank 0
2023-02-22 09:43:36,170 DEBUG TRAIN Batch 17/5100 loss 7.364866 loss_att 8.683258 loss_ctc 10.699942 loss_rnnt 6.636539 hw_loss 0.037447 lr 0.00041250 rank 2
2023-02-22 09:43:36,173 DEBUG TRAIN Batch 17/5100 loss 4.469325 loss_att 8.503678 loss_ctc 5.157764 loss_rnnt 3.540432 hw_loss 0.056682 lr 0.00041250 rank 3
2023-02-22 09:43:36,189 DEBUG TRAIN Batch 17/5100 loss 6.131971 loss_att 9.327414 loss_ctc 8.902836 loss_rnnt 5.086544 hw_loss 0.069169 lr 0.00041261 rank 1
2023-02-22 09:43:36,196 DEBUG TRAIN Batch 17/5100 loss 13.628182 loss_att 15.393608 loss_ctc 18.752758 loss_rnnt 12.569357 hw_loss 0.042121 lr 0.00041258 rank 6
2023-02-22 09:44:52,498 DEBUG TRAIN Batch 17/5200 loss 3.498190 loss_att 6.789550 loss_ctc 3.646011 loss_rnnt 2.791666 hw_loss 0.053517 lr 0.00041243 rank 0
2023-02-22 09:44:52,503 DEBUG TRAIN Batch 17/5200 loss 5.854857 loss_att 11.683645 loss_ctc 9.934980 loss_rnnt 4.093065 hw_loss 0.097535 lr 0.00041238 rank 7
2023-02-22 09:44:52,505 DEBUG TRAIN Batch 17/5200 loss 18.229084 loss_att 21.492767 loss_ctc 21.171373 loss_rnnt 17.142300 hw_loss 0.078267 lr 0.00041247 rank 1
2023-02-22 09:44:52,509 DEBUG TRAIN Batch 17/5200 loss 18.603979 loss_att 19.518021 loss_ctc 24.748638 loss_rnnt 17.518906 hw_loss 0.155582 lr 0.00041238 rank 5
2023-02-22 09:44:52,510 DEBUG TRAIN Batch 17/5200 loss 5.165881 loss_att 8.316595 loss_ctc 8.319300 loss_rnnt 4.043316 hw_loss 0.134938 lr 0.00041241 rank 4
2023-02-22 09:44:52,513 DEBUG TRAIN Batch 17/5200 loss 18.866341 loss_att 20.605280 loss_ctc 28.820614 loss_rnnt 17.160690 hw_loss 0.057424 lr 0.00041244 rank 6
2023-02-22 09:44:52,513 DEBUG TRAIN Batch 17/5200 loss 9.931352 loss_att 11.605851 loss_ctc 12.713074 loss_rnnt 9.195818 hw_loss 0.055756 lr 0.00041236 rank 2
2023-02-22 09:44:52,518 DEBUG TRAIN Batch 17/5200 loss 7.658477 loss_att 11.523148 loss_ctc 11.429741 loss_rnnt 6.302663 hw_loss 0.150083 lr 0.00041236 rank 3
2023-02-22 09:46:08,874 DEBUG TRAIN Batch 17/5300 loss 5.118212 loss_att 9.699021 loss_ctc 12.116256 loss_rnnt 3.253586 hw_loss 0.028859 lr 0.00041229 rank 0
2023-02-22 09:46:08,877 DEBUG TRAIN Batch 17/5300 loss 7.432353 loss_att 8.523784 loss_ctc 9.590138 loss_rnnt 6.834939 hw_loss 0.171419 lr 0.00041224 rank 5
2023-02-22 09:46:08,877 DEBUG TRAIN Batch 17/5300 loss 12.223384 loss_att 16.522228 loss_ctc 17.963108 loss_rnnt 10.520901 hw_loss 0.145158 lr 0.00041224 rank 7
2023-02-22 09:46:08,878 DEBUG TRAIN Batch 17/5300 loss 13.525173 loss_att 16.249935 loss_ctc 18.144377 loss_rnnt 12.348773 hw_loss 0.029164 lr 0.00041227 rank 4
2023-02-22 09:46:08,879 DEBUG TRAIN Batch 17/5300 loss 18.982550 loss_att 21.015808 loss_ctc 22.857067 loss_rnnt 17.996544 hw_loss 0.117661 lr 0.00041222 rank 3
2023-02-22 09:46:08,881 DEBUG TRAIN Batch 17/5300 loss 7.603747 loss_att 9.482188 loss_ctc 10.336504 loss_rnnt 6.822504 hw_loss 0.077228 lr 0.00041233 rank 1
2023-02-22 09:46:08,881 DEBUG TRAIN Batch 17/5300 loss 6.243256 loss_att 8.488316 loss_ctc 7.816979 loss_rnnt 5.476204 hw_loss 0.202894 lr 0.00041222 rank 2
2023-02-22 09:46:08,884 DEBUG TRAIN Batch 17/5300 loss 5.859210 loss_att 9.520462 loss_ctc 7.747804 loss_rnnt 4.781290 hw_loss 0.175981 lr 0.00041230 rank 6
2023-02-22 09:47:25,442 DEBUG TRAIN Batch 17/5400 loss 13.842202 loss_att 16.580894 loss_ctc 19.716408 loss_rnnt 12.418211 hw_loss 0.174426 lr 0.00041210 rank 7
2023-02-22 09:47:25,448 DEBUG TRAIN Batch 17/5400 loss 6.795321 loss_att 9.270452 loss_ctc 10.166765 loss_rnnt 5.813308 hw_loss 0.070240 lr 0.00041208 rank 3
2023-02-22 09:47:25,448 DEBUG TRAIN Batch 17/5400 loss 6.865004 loss_att 10.465218 loss_ctc 10.781837 loss_rnnt 5.576829 hw_loss 0.086038 lr 0.00041213 rank 4
2023-02-22 09:47:25,449 DEBUG TRAIN Batch 17/5400 loss 11.776675 loss_att 14.129212 loss_ctc 13.420876 loss_rnnt 11.059336 hw_loss 0.051757 lr 0.00041215 rank 0
2023-02-22 09:47:25,451 DEBUG TRAIN Batch 17/5400 loss 15.629998 loss_att 21.468893 loss_ctc 20.725883 loss_rnnt 13.776851 hw_loss 0.011097 lr 0.00041210 rank 5
2023-02-22 09:47:25,454 DEBUG TRAIN Batch 17/5400 loss 10.432099 loss_att 14.463393 loss_ctc 12.751107 loss_rnnt 9.243462 hw_loss 0.137210 lr 0.00041219 rank 1
2023-02-22 09:47:25,455 DEBUG TRAIN Batch 17/5400 loss 9.777485 loss_att 12.944887 loss_ctc 14.730664 loss_rnnt 8.462864 hw_loss 0.038844 lr 0.00041208 rank 2
2023-02-22 09:47:25,456 DEBUG TRAIN Batch 17/5400 loss 12.662332 loss_att 17.060108 loss_ctc 17.098969 loss_rnnt 11.109355 hw_loss 0.153505 lr 0.00041216 rank 6
2023-02-22 09:48:41,098 DEBUG TRAIN Batch 17/5500 loss 8.409661 loss_att 14.242775 loss_ctc 11.997367 loss_rnnt 6.703537 hw_loss 0.114639 lr 0.00041196 rank 5
2023-02-22 09:48:41,101 DEBUG TRAIN Batch 17/5500 loss 4.931095 loss_att 6.325903 loss_ctc 6.268230 loss_rnnt 4.401880 hw_loss 0.134942 lr 0.00041199 rank 4
2023-02-22 09:48:41,103 DEBUG TRAIN Batch 17/5500 loss 4.308658 loss_att 6.753554 loss_ctc 6.014291 loss_rnnt 3.548300 hw_loss 0.082424 lr 0.00041196 rank 7
2023-02-22 09:48:41,105 DEBUG TRAIN Batch 17/5500 loss 6.881960 loss_att 9.249076 loss_ctc 8.667871 loss_rnnt 6.101085 hw_loss 0.129997 lr 0.00041201 rank 0
2023-02-22 09:48:41,107 DEBUG TRAIN Batch 17/5500 loss 9.199866 loss_att 10.595783 loss_ctc 9.757620 loss_rnnt 8.750607 hw_loss 0.179452 lr 0.00041202 rank 6
2023-02-22 09:48:41,109 DEBUG TRAIN Batch 17/5500 loss 10.082783 loss_att 15.056683 loss_ctc 16.004984 loss_rnnt 8.243367 hw_loss 0.103141 lr 0.00041205 rank 1
2023-02-22 09:48:41,137 DEBUG TRAIN Batch 17/5500 loss 16.985405 loss_att 21.436600 loss_ctc 30.117039 loss_rnnt 14.306333 hw_loss 0.071154 lr 0.00041194 rank 3
2023-02-22 09:48:41,146 DEBUG TRAIN Batch 17/5500 loss 9.871236 loss_att 13.592366 loss_ctc 15.774684 loss_rnnt 8.287546 hw_loss 0.098132 lr 0.00041194 rank 2
2023-02-22 09:49:56,484 DEBUG TRAIN Batch 17/5600 loss 11.667263 loss_att 13.875406 loss_ctc 16.505894 loss_rnnt 10.562399 hw_loss 0.033908 lr 0.00041187 rank 0
2023-02-22 09:49:56,486 DEBUG TRAIN Batch 17/5600 loss 17.761969 loss_att 22.085358 loss_ctc 23.895344 loss_rnnt 16.034277 hw_loss 0.084811 lr 0.00041188 rank 6
2023-02-22 09:49:56,488 DEBUG TRAIN Batch 17/5600 loss 7.366063 loss_att 9.632152 loss_ctc 9.602280 loss_rnnt 6.549946 hw_loss 0.121381 lr 0.00041182 rank 5
2023-02-22 09:49:56,488 DEBUG TRAIN Batch 17/5600 loss 4.548345 loss_att 7.641271 loss_ctc 8.500263 loss_rnnt 3.384496 hw_loss 0.034390 lr 0.00041182 rank 7
2023-02-22 09:49:56,488 DEBUG TRAIN Batch 17/5600 loss 8.534347 loss_att 9.889318 loss_ctc 13.706343 loss_rnnt 7.547919 hw_loss 0.048440 lr 0.00041191 rank 1
2023-02-22 09:49:56,499 DEBUG TRAIN Batch 17/5600 loss 6.181717 loss_att 9.636288 loss_ctc 10.411983 loss_rnnt 4.858868 hw_loss 0.127314 lr 0.00041180 rank 2
2023-02-22 09:49:56,507 DEBUG TRAIN Batch 17/5600 loss 2.872073 loss_att 5.196675 loss_ctc 4.746898 loss_rnnt 2.125198 hw_loss 0.059959 lr 0.00041185 rank 4
2023-02-22 09:49:56,540 DEBUG TRAIN Batch 17/5600 loss 9.361780 loss_att 11.159444 loss_ctc 12.835375 loss_rnnt 8.503228 hw_loss 0.067262 lr 0.00041180 rank 3
2023-02-22 09:51:14,485 DEBUG TRAIN Batch 17/5700 loss 10.331042 loss_att 11.764461 loss_ctc 12.784167 loss_rnnt 9.651365 hw_loss 0.123580 lr 0.00041173 rank 0
2023-02-22 09:51:14,487 DEBUG TRAIN Batch 17/5700 loss 10.966808 loss_att 13.798557 loss_ctc 12.920360 loss_rnnt 10.063289 hw_loss 0.143803 lr 0.00041168 rank 7
2023-02-22 09:51:14,488 DEBUG TRAIN Batch 17/5700 loss 8.852242 loss_att 12.837034 loss_ctc 9.350304 loss_rnnt 7.940802 hw_loss 0.090137 lr 0.00041166 rank 3
2023-02-22 09:51:14,489 DEBUG TRAIN Batch 17/5700 loss 8.760549 loss_att 9.772895 loss_ctc 12.145428 loss_rnnt 8.045765 hw_loss 0.114369 lr 0.00041177 rank 1
2023-02-22 09:51:14,490 DEBUG TRAIN Batch 17/5700 loss 10.565452 loss_att 10.425105 loss_ctc 14.969377 loss_rnnt 9.893517 hw_loss 0.211527 lr 0.00041166 rank 2
2023-02-22 09:51:14,491 DEBUG TRAIN Batch 17/5700 loss 8.506085 loss_att 11.751671 loss_ctc 12.284748 loss_rnnt 7.269676 hw_loss 0.156507 lr 0.00041168 rank 5
2023-02-22 09:51:14,492 DEBUG TRAIN Batch 17/5700 loss 11.955258 loss_att 11.704230 loss_ctc 14.723119 loss_rnnt 11.577518 hw_loss 0.110433 lr 0.00041171 rank 4
2023-02-22 09:51:14,495 DEBUG TRAIN Batch 17/5700 loss 13.668280 loss_att 22.498238 loss_ctc 23.732002 loss_rnnt 10.560408 hw_loss 0.000096 lr 0.00041174 rank 6
2023-02-22 09:52:27,809 DEBUG TRAIN Batch 17/5800 loss 8.396426 loss_att 10.454865 loss_ctc 13.734131 loss_rnnt 7.240128 hw_loss 0.061721 lr 0.00041159 rank 0
2023-02-22 09:52:27,814 DEBUG TRAIN Batch 17/5800 loss 13.513876 loss_att 15.543137 loss_ctc 20.910269 loss_rnnt 12.110653 hw_loss 0.020971 lr 0.00041154 rank 7
2023-02-22 09:52:27,815 DEBUG TRAIN Batch 17/5800 loss 7.490303 loss_att 10.067083 loss_ctc 10.434149 loss_rnnt 6.538245 hw_loss 0.082854 lr 0.00041152 rank 3
2023-02-22 09:52:27,817 DEBUG TRAIN Batch 17/5800 loss 12.615040 loss_att 15.875837 loss_ctc 16.350149 loss_rnnt 11.449766 hw_loss 0.028315 lr 0.00041157 rank 4
2023-02-22 09:52:27,818 DEBUG TRAIN Batch 17/5800 loss 10.257281 loss_att 11.162710 loss_ctc 12.767135 loss_rnnt 9.687329 hw_loss 0.101659 lr 0.00041154 rank 5
2023-02-22 09:52:27,819 DEBUG TRAIN Batch 17/5800 loss 12.501395 loss_att 14.377449 loss_ctc 16.075832 loss_rnnt 11.619812 hw_loss 0.055841 lr 0.00041160 rank 6
2023-02-22 09:52:27,819 DEBUG TRAIN Batch 17/5800 loss 8.769794 loss_att 10.985093 loss_ctc 13.439011 loss_rnnt 7.674463 hw_loss 0.055703 lr 0.00041163 rank 1
2023-02-22 09:52:27,822 DEBUG TRAIN Batch 17/5800 loss 7.326341 loss_att 9.692227 loss_ctc 11.590426 loss_rnnt 6.229982 hw_loss 0.102444 lr 0.00041152 rank 2
2023-02-22 09:53:42,566 DEBUG TRAIN Batch 17/5900 loss 9.487372 loss_att 10.811956 loss_ctc 11.506270 loss_rnnt 8.897531 hw_loss 0.104508 lr 0.00041140 rank 7
2023-02-22 09:53:42,567 DEBUG TRAIN Batch 17/5900 loss 17.466822 loss_att 20.446180 loss_ctc 26.035086 loss_rnnt 15.682135 hw_loss 0.086959 lr 0.00041144 rank 4
2023-02-22 09:53:42,569 DEBUG TRAIN Batch 17/5900 loss 6.036500 loss_att 8.524649 loss_ctc 10.291163 loss_rnnt 4.911193 hw_loss 0.113227 lr 0.00041146 rank 0
2023-02-22 09:53:42,572 DEBUG TRAIN Batch 17/5900 loss 4.754243 loss_att 8.422657 loss_ctc 6.232915 loss_rnnt 3.810817 hw_loss 0.023600 lr 0.00041146 rank 6
2023-02-22 09:53:42,572 DEBUG TRAIN Batch 17/5900 loss 6.858478 loss_att 7.527712 loss_ctc 10.188331 loss_rnnt 6.151519 hw_loss 0.242122 lr 0.00041140 rank 5
2023-02-22 09:53:42,574 DEBUG TRAIN Batch 17/5900 loss 17.202698 loss_att 18.570450 loss_ctc 24.040886 loss_rnnt 15.954377 hw_loss 0.118147 lr 0.00041138 rank 3
2023-02-22 09:53:42,577 DEBUG TRAIN Batch 17/5900 loss 6.249903 loss_att 10.380669 loss_ctc 9.717354 loss_rnnt 4.868771 hw_loss 0.173724 lr 0.00041149 rank 1
2023-02-22 09:53:42,577 DEBUG TRAIN Batch 17/5900 loss 11.835785 loss_att 16.093306 loss_ctc 15.564161 loss_rnnt 10.359631 hw_loss 0.239124 lr 0.00041138 rank 2
2023-02-22 09:54:59,537 DEBUG TRAIN Batch 17/6000 loss 14.790502 loss_att 18.597528 loss_ctc 20.707123 loss_rnnt 13.184225 hw_loss 0.104977 lr 0.00041132 rank 0
2023-02-22 09:54:59,537 DEBUG TRAIN Batch 17/6000 loss 5.663906 loss_att 8.808317 loss_ctc 7.641399 loss_rnnt 4.714380 hw_loss 0.106832 lr 0.00041126 rank 5
2023-02-22 09:54:59,540 DEBUG TRAIN Batch 17/6000 loss 9.304773 loss_att 12.469093 loss_ctc 12.027817 loss_rnnt 8.270985 hw_loss 0.070971 lr 0.00041127 rank 7
2023-02-22 09:54:59,540 DEBUG TRAIN Batch 17/6000 loss 12.912029 loss_att 15.137276 loss_ctc 16.850456 loss_rnnt 11.906411 hw_loss 0.066459 lr 0.00041130 rank 4
2023-02-22 09:54:59,542 DEBUG TRAIN Batch 17/6000 loss 3.273640 loss_att 6.233774 loss_ctc 4.841620 loss_rnnt 2.384899 hw_loss 0.164344 lr 0.00041124 rank 3
2023-02-22 09:54:59,544 DEBUG TRAIN Batch 17/6000 loss 15.086849 loss_att 19.543991 loss_ctc 20.137964 loss_rnnt 13.472997 hw_loss 0.091765 lr 0.00041132 rank 6
2023-02-22 09:54:59,546 DEBUG TRAIN Batch 17/6000 loss 14.361674 loss_att 17.124996 loss_ctc 16.289524 loss_rnnt 13.481898 hw_loss 0.131374 lr 0.00041135 rank 1
2023-02-22 09:54:59,550 DEBUG TRAIN Batch 17/6000 loss 12.462924 loss_att 15.960567 loss_ctc 19.070084 loss_rnnt 10.816483 hw_loss 0.123670 lr 0.00041124 rank 2
2023-02-22 09:56:16,484 DEBUG TRAIN Batch 17/6100 loss 12.444166 loss_att 15.856998 loss_ctc 15.469351 loss_rnnt 11.275886 hw_loss 0.154418 lr 0.00041118 rank 0
2023-02-22 09:56:16,487 DEBUG TRAIN Batch 17/6100 loss 10.870347 loss_att 14.925276 loss_ctc 15.980779 loss_rnnt 9.358873 hw_loss 0.035806 lr 0.00041111 rank 2
2023-02-22 09:56:16,488 DEBUG TRAIN Batch 17/6100 loss 10.589879 loss_att 13.220457 loss_ctc 11.080549 loss_rnnt 9.975641 hw_loss 0.042563 lr 0.00041110 rank 3
2023-02-22 09:56:16,489 DEBUG TRAIN Batch 17/6100 loss 8.672077 loss_att 12.426916 loss_ctc 20.386997 loss_rnnt 6.243880 hw_loss 0.216074 lr 0.00041113 rank 7
2023-02-22 09:56:16,489 DEBUG TRAIN Batch 17/6100 loss 12.156938 loss_att 13.004109 loss_ctc 11.581078 loss_rnnt 12.035158 hw_loss 0.054609 lr 0.00041113 rank 5
2023-02-22 09:56:16,491 DEBUG TRAIN Batch 17/6100 loss 10.657343 loss_att 12.871433 loss_ctc 15.701334 loss_rnnt 9.483418 hw_loss 0.109830 lr 0.00041116 rank 4
2023-02-22 09:56:16,493 DEBUG TRAIN Batch 17/6100 loss 5.594138 loss_att 10.855655 loss_ctc 10.269447 loss_rnnt 3.828176 hw_loss 0.169281 lr 0.00041119 rank 6
2023-02-22 09:56:16,537 DEBUG TRAIN Batch 17/6100 loss 7.321142 loss_att 11.469168 loss_ctc 10.525723 loss_rnnt 6.028228 hw_loss 0.067560 lr 0.00041121 rank 1
2023-02-22 09:57:31,538 DEBUG TRAIN Batch 17/6200 loss 7.925261 loss_att 12.062035 loss_ctc 11.798559 loss_rnnt 6.536690 hw_loss 0.083957 lr 0.00041104 rank 0
2023-02-22 09:57:31,540 DEBUG TRAIN Batch 17/6200 loss 13.064080 loss_att 17.602600 loss_ctc 21.493620 loss_rnnt 10.997358 hw_loss 0.065771 lr 0.00041099 rank 7
2023-02-22 09:57:31,541 DEBUG TRAIN Batch 17/6200 loss 17.552853 loss_att 20.002579 loss_ctc 22.082685 loss_rnnt 16.458851 hw_loss 0.000146 lr 0.00041099 rank 5
2023-02-22 09:57:31,545 DEBUG TRAIN Batch 17/6200 loss 8.087226 loss_att 12.179562 loss_ctc 12.524898 loss_rnnt 6.566517 hw_loss 0.207285 lr 0.00041097 rank 2
2023-02-22 09:57:31,545 DEBUG TRAIN Batch 17/6200 loss 9.647667 loss_att 12.745061 loss_ctc 14.575281 loss_rnnt 8.293886 hw_loss 0.144912 lr 0.00041105 rank 6
2023-02-22 09:57:31,546 DEBUG TRAIN Batch 17/6200 loss 17.714468 loss_att 17.227739 loss_ctc 20.417797 loss_rnnt 17.431801 hw_loss 0.036692 lr 0.00041108 rank 1
2023-02-22 09:57:31,547 DEBUG TRAIN Batch 17/6200 loss 10.984775 loss_att 15.312897 loss_ctc 17.617428 loss_rnnt 9.214252 hw_loss 0.038521 lr 0.00041102 rank 4
2023-02-22 09:57:31,550 DEBUG TRAIN Batch 17/6200 loss 12.910473 loss_att 14.280874 loss_ctc 15.928775 loss_rnnt 12.199763 hw_loss 0.064107 lr 0.00041096 rank 3
2023-02-22 09:58:47,574 DEBUG TRAIN Batch 17/6300 loss 7.527186 loss_att 10.088605 loss_ctc 10.364670 loss_rnnt 6.521143 hw_loss 0.216425 lr 0.00041090 rank 0
2023-02-22 09:58:47,575 DEBUG TRAIN Batch 17/6300 loss 10.764210 loss_att 12.681017 loss_ctc 16.117630 loss_rnnt 9.595098 hw_loss 0.134926 lr 0.00041091 rank 6
2023-02-22 09:58:47,575 DEBUG TRAIN Batch 17/6300 loss 7.239925 loss_att 11.150984 loss_ctc 10.200782 loss_rnnt 6.007696 hw_loss 0.103569 lr 0.00041085 rank 7
2023-02-22 09:58:47,579 DEBUG TRAIN Batch 17/6300 loss 11.893638 loss_att 16.216312 loss_ctc 17.091799 loss_rnnt 10.313334 hw_loss 0.042526 lr 0.00041085 rank 5
2023-02-22 09:58:47,582 DEBUG TRAIN Batch 17/6300 loss 8.478049 loss_att 10.936153 loss_ctc 14.250842 loss_rnnt 7.164506 hw_loss 0.097907 lr 0.00041088 rank 4
2023-02-22 09:58:47,584 DEBUG TRAIN Batch 17/6300 loss 7.788722 loss_att 7.390826 loss_ctc 9.001678 loss_rnnt 7.613980 hw_loss 0.173612 lr 0.00041082 rank 3
2023-02-22 09:58:47,589 DEBUG TRAIN Batch 17/6300 loss 8.725647 loss_att 10.372825 loss_ctc 11.592194 loss_rnnt 7.951445 hw_loss 0.117302 lr 0.00041083 rank 2
2023-02-22 09:58:47,627 DEBUG TRAIN Batch 17/6300 loss 16.131771 loss_att 16.550110 loss_ctc 19.122261 loss_rnnt 15.580821 hw_loss 0.128530 lr 0.00041094 rank 1
2023-02-22 10:00:05,712 DEBUG TRAIN Batch 17/6400 loss 9.304073 loss_att 10.399203 loss_ctc 14.213982 loss_rnnt 8.406618 hw_loss 0.044577 lr 0.00041071 rank 7
2023-02-22 10:00:05,714 DEBUG TRAIN Batch 17/6400 loss 16.571892 loss_att 18.071068 loss_ctc 20.597168 loss_rnnt 15.609508 hw_loss 0.235959 lr 0.00041074 rank 4
2023-02-22 10:00:05,716 DEBUG TRAIN Batch 17/6400 loss 4.947752 loss_att 9.964691 loss_ctc 9.641319 loss_rnnt 3.250136 hw_loss 0.128286 lr 0.00041068 rank 3
2023-02-22 10:00:05,718 DEBUG TRAIN Batch 17/6400 loss 7.297252 loss_att 11.456188 loss_ctc 11.720814 loss_rnnt 5.824353 hw_loss 0.096194 lr 0.00041071 rank 5
2023-02-22 10:00:05,721 DEBUG TRAIN Batch 17/6400 loss 3.887302 loss_att 7.920984 loss_ctc 2.467446 loss_rnnt 3.186241 hw_loss 0.156823 lr 0.00041076 rank 0
2023-02-22 10:00:05,723 DEBUG TRAIN Batch 17/6400 loss 7.367681 loss_att 12.643219 loss_ctc 11.294643 loss_rnnt 5.772094 hw_loss 0.031657 lr 0.00041077 rank 6
2023-02-22 10:00:05,723 DEBUG TRAIN Batch 17/6400 loss 12.801526 loss_att 20.287563 loss_ctc 17.511276 loss_rnnt 10.606607 hw_loss 0.130771 lr 0.00041069 rank 2
2023-02-22 10:00:05,767 DEBUG TRAIN Batch 17/6400 loss 3.562747 loss_att 7.003935 loss_ctc 4.204095 loss_rnnt 2.757327 hw_loss 0.059380 lr 0.00041080 rank 1
2023-02-22 10:01:21,024 DEBUG TRAIN Batch 17/6500 loss 6.287683 loss_att 6.471190 loss_ctc 8.846983 loss_rnnt 5.861395 hw_loss 0.090650 lr 0.00041057 rank 5
2023-02-22 10:01:21,027 DEBUG TRAIN Batch 17/6500 loss 5.240759 loss_att 7.919551 loss_ctc 7.372649 loss_rnnt 4.315120 hw_loss 0.198055 lr 0.00041057 rank 7
2023-02-22 10:01:21,027 DEBUG TRAIN Batch 17/6500 loss 6.619853 loss_att 10.911914 loss_ctc 9.155123 loss_rnnt 5.371085 hw_loss 0.098099 lr 0.00041062 rank 0
2023-02-22 10:01:21,028 DEBUG TRAIN Batch 17/6500 loss 11.495492 loss_att 14.403700 loss_ctc 16.956709 loss_rnnt 10.106350 hw_loss 0.148759 lr 0.00041060 rank 4
2023-02-22 10:01:21,029 DEBUG TRAIN Batch 17/6500 loss 4.809570 loss_att 7.700407 loss_ctc 6.928556 loss_rnnt 3.871917 hw_loss 0.144290 lr 0.00041063 rank 6
2023-02-22 10:01:21,029 DEBUG TRAIN Batch 17/6500 loss 8.831574 loss_att 11.218060 loss_ctc 11.758049 loss_rnnt 7.907140 hw_loss 0.106763 lr 0.00041066 rank 1
2023-02-22 10:01:21,029 DEBUG TRAIN Batch 17/6500 loss 8.729023 loss_att 12.630961 loss_ctc 16.471996 loss_rnnt 6.840282 hw_loss 0.142416 lr 0.00041055 rank 3
2023-02-22 10:01:21,030 DEBUG TRAIN Batch 17/6500 loss 12.224500 loss_att 16.776398 loss_ctc 18.756437 loss_rnnt 10.372311 hw_loss 0.132908 lr 0.00041055 rank 2
2023-02-22 10:02:35,319 DEBUG TRAIN Batch 17/6600 loss 6.691969 loss_att 12.822916 loss_ctc 8.253704 loss_rnnt 5.223609 hw_loss 0.063635 lr 0.00041043 rank 7
2023-02-22 10:02:35,323 DEBUG TRAIN Batch 17/6600 loss 3.326114 loss_att 7.053005 loss_ctc 3.541603 loss_rnnt 2.483332 hw_loss 0.128761 lr 0.00041046 rank 4
2023-02-22 10:02:35,326 DEBUG TRAIN Batch 17/6600 loss 8.582642 loss_att 12.352373 loss_ctc 11.098614 loss_rnnt 7.433502 hw_loss 0.111995 lr 0.00041041 rank 3
2023-02-22 10:02:35,327 DEBUG TRAIN Batch 17/6600 loss 9.709995 loss_att 12.545142 loss_ctc 15.089033 loss_rnnt 8.363483 hw_loss 0.116770 lr 0.00041049 rank 6
2023-02-22 10:02:35,328 DEBUG TRAIN Batch 17/6600 loss 8.100307 loss_att 11.220982 loss_ctc 11.557825 loss_rnnt 6.952002 hw_loss 0.118437 lr 0.00041052 rank 1
2023-02-22 10:02:35,329 DEBUG TRAIN Batch 17/6600 loss 10.553781 loss_att 11.552851 loss_ctc 12.869926 loss_rnnt 9.950166 hw_loss 0.178090 lr 0.00041048 rank 0
2023-02-22 10:02:35,331 DEBUG TRAIN Batch 17/6600 loss 7.906736 loss_att 14.457914 loss_ctc 10.059186 loss_rnnt 6.305459 hw_loss 0.007588 lr 0.00041043 rank 5
2023-02-22 10:02:35,334 DEBUG TRAIN Batch 17/6600 loss 6.313964 loss_att 10.273590 loss_ctc 9.096886 loss_rnnt 5.111626 hw_loss 0.073793 lr 0.00041041 rank 2
2023-02-22 10:03:51,090 DEBUG TRAIN Batch 17/6700 loss 13.057568 loss_att 14.657730 loss_ctc 14.229650 loss_rnnt 12.544935 hw_loss 0.068104 lr 0.00041029 rank 5
2023-02-22 10:03:51,090 DEBUG TRAIN Batch 17/6700 loss 8.632217 loss_att 10.994263 loss_ctc 10.352272 loss_rnnt 7.849977 hw_loss 0.150919 lr 0.00041030 rank 7
2023-02-22 10:03:51,090 DEBUG TRAIN Batch 17/6700 loss 3.444757 loss_att 5.475076 loss_ctc 5.814091 loss_rnnt 2.644798 hw_loss 0.146220 lr 0.00041038 rank 1
2023-02-22 10:03:51,090 DEBUG TRAIN Batch 17/6700 loss 16.284472 loss_att 18.612003 loss_ctc 21.330736 loss_rnnt 15.100250 hw_loss 0.086025 lr 0.00041035 rank 0
2023-02-22 10:03:51,094 DEBUG TRAIN Batch 17/6700 loss 10.041408 loss_att 12.297136 loss_ctc 12.900805 loss_rnnt 9.163934 hw_loss 0.084517 lr 0.00041033 rank 4
2023-02-22 10:03:51,095 DEBUG TRAIN Batch 17/6700 loss 9.833200 loss_att 14.561543 loss_ctc 12.880501 loss_rnnt 8.386904 hw_loss 0.176851 lr 0.00041035 rank 6
2023-02-22 10:03:51,095 DEBUG TRAIN Batch 17/6700 loss 15.458233 loss_att 17.265884 loss_ctc 17.555023 loss_rnnt 14.715457 hw_loss 0.190638 lr 0.00041027 rank 3
2023-02-22 10:03:51,096 DEBUG TRAIN Batch 17/6700 loss 17.237896 loss_att 18.790020 loss_ctc 22.585945 loss_rnnt 16.085770 hw_loss 0.241178 lr 0.00041027 rank 2
2023-02-22 10:05:08,452 DEBUG TRAIN Batch 17/6800 loss 7.622662 loss_att 11.721967 loss_ctc 11.534534 loss_rnnt 6.209075 hw_loss 0.135268 lr 0.00041013 rank 3
2023-02-22 10:05:08,460 DEBUG TRAIN Batch 17/6800 loss 10.674678 loss_att 12.958841 loss_ctc 14.399486 loss_rnnt 9.710697 hw_loss 0.019700 lr 0.00041019 rank 4
2023-02-22 10:05:08,460 DEBUG TRAIN Batch 17/6800 loss 3.861267 loss_att 7.907645 loss_ctc 7.647272 loss_rnnt 2.477269 hw_loss 0.131103 lr 0.00041021 rank 0
2023-02-22 10:05:08,461 DEBUG TRAIN Batch 17/6800 loss 8.551331 loss_att 12.738604 loss_ctc 12.768106 loss_rnnt 7.126381 hw_loss 0.047358 lr 0.00041024 rank 1
2023-02-22 10:05:08,462 DEBUG TRAIN Batch 17/6800 loss 14.421158 loss_att 19.592535 loss_ctc 23.864273 loss_rnnt 12.083270 hw_loss 0.083494 lr 0.00041016 rank 5
2023-02-22 10:05:08,464 DEBUG TRAIN Batch 17/6800 loss 8.474015 loss_att 10.649986 loss_ctc 10.584366 loss_rnnt 7.673735 hw_loss 0.156949 lr 0.00041022 rank 6
2023-02-22 10:05:08,466 DEBUG TRAIN Batch 17/6800 loss 6.869821 loss_att 8.711843 loss_ctc 7.096502 loss_rnnt 6.421461 hw_loss 0.093245 lr 0.00041014 rank 2
2023-02-22 10:05:08,470 DEBUG TRAIN Batch 17/6800 loss 6.218606 loss_att 10.716380 loss_ctc 8.478544 loss_rnnt 4.978045 hw_loss 0.074401 lr 0.00041016 rank 7
2023-02-22 10:06:23,691 DEBUG TRAIN Batch 17/6900 loss 15.853633 loss_att 18.453753 loss_ctc 24.591959 loss_rnnt 14.096068 hw_loss 0.135806 lr 0.00041002 rank 7
2023-02-22 10:06:23,696 DEBUG TRAIN Batch 17/6900 loss 8.360686 loss_att 9.549600 loss_ctc 10.163353 loss_rnnt 7.791619 hw_loss 0.170490 lr 0.00041000 rank 2
2023-02-22 10:06:23,696 DEBUG TRAIN Batch 17/6900 loss 7.606784 loss_att 10.065586 loss_ctc 11.970858 loss_rnnt 6.486885 hw_loss 0.086741 lr 0.00041005 rank 4
2023-02-22 10:06:23,700 DEBUG TRAIN Batch 17/6900 loss 10.946795 loss_att 13.831100 loss_ctc 13.866568 loss_rnnt 9.930371 hw_loss 0.094236 lr 0.00041007 rank 0
2023-02-22 10:06:23,703 DEBUG TRAIN Batch 17/6900 loss 11.713373 loss_att 14.757523 loss_ctc 16.628756 loss_rnnt 10.407028 hw_loss 0.078995 lr 0.00041002 rank 5
2023-02-22 10:06:23,704 DEBUG TRAIN Batch 17/6900 loss 8.435815 loss_att 10.575835 loss_ctc 15.751318 loss_rnnt 6.964419 hw_loss 0.127482 lr 0.00041008 rank 6
2023-02-22 10:06:23,704 DEBUG TRAIN Batch 17/6900 loss 11.358244 loss_att 13.153702 loss_ctc 15.796127 loss_rnnt 10.371481 hw_loss 0.067415 lr 0.00041011 rank 1
2023-02-22 10:06:23,746 DEBUG TRAIN Batch 17/6900 loss 9.571599 loss_att 9.195998 loss_ctc 14.045363 loss_rnnt 8.956812 hw_loss 0.175135 lr 0.00040999 rank 3
2023-02-22 10:07:39,727 DEBUG TRAIN Batch 17/7000 loss 3.275197 loss_att 6.632046 loss_ctc 5.580954 loss_rnnt 2.196867 hw_loss 0.186612 lr 0.00040994 rank 6
2023-02-22 10:07:39,729 DEBUG TRAIN Batch 17/7000 loss 9.036901 loss_att 9.292778 loss_ctc 11.574522 loss_rnnt 8.530663 hw_loss 0.218839 lr 0.00040993 rank 0
2023-02-22 10:07:39,732 DEBUG TRAIN Batch 17/7000 loss 13.687952 loss_att 14.893047 loss_ctc 19.454803 loss_rnnt 12.548090 hw_loss 0.243616 lr 0.00040986 rank 2
2023-02-22 10:07:39,733 DEBUG TRAIN Batch 17/7000 loss 6.336366 loss_att 10.501293 loss_ctc 8.980672 loss_rnnt 5.071583 hw_loss 0.148545 lr 0.00040997 rank 1
2023-02-22 10:07:39,734 DEBUG TRAIN Batch 17/7000 loss 18.320065 loss_att 21.457109 loss_ctc 27.526310 loss_rnnt 16.416792 hw_loss 0.090685 lr 0.00040988 rank 7
2023-02-22 10:07:39,735 DEBUG TRAIN Batch 17/7000 loss 10.223218 loss_att 10.352486 loss_ctc 11.199409 loss_rnnt 10.023914 hw_loss 0.081172 lr 0.00040988 rank 5
2023-02-22 10:07:39,735 DEBUG TRAIN Batch 17/7000 loss 14.432048 loss_att 18.221291 loss_ctc 20.076210 loss_rnnt 12.876860 hw_loss 0.083975 lr 0.00040991 rank 4
2023-02-22 10:07:39,736 DEBUG TRAIN Batch 17/7000 loss 16.367765 loss_att 17.965630 loss_ctc 17.078375 loss_rnnt 15.908745 hw_loss 0.083812 lr 0.00040986 rank 3
2023-02-22 10:08:57,557 DEBUG TRAIN Batch 17/7100 loss 7.144820 loss_att 7.203728 loss_ctc 10.435241 loss_rnnt 6.555379 hw_loss 0.260506 lr 0.00040974 rank 7
2023-02-22 10:08:57,561 DEBUG TRAIN Batch 17/7100 loss 10.536614 loss_att 13.085584 loss_ctc 11.639135 loss_rnnt 9.794228 hw_loss 0.160481 lr 0.00040977 rank 4
2023-02-22 10:08:57,563 DEBUG TRAIN Batch 17/7100 loss 5.654618 loss_att 9.669838 loss_ctc 6.962929 loss_rnnt 4.644345 hw_loss 0.061477 lr 0.00040979 rank 0
2023-02-22 10:08:57,563 DEBUG TRAIN Batch 17/7100 loss 13.933603 loss_att 17.970762 loss_ctc 21.333757 loss_rnnt 12.047142 hw_loss 0.173140 lr 0.00040974 rank 5
2023-02-22 10:08:57,565 DEBUG TRAIN Batch 17/7100 loss 7.539418 loss_att 11.161788 loss_ctc 11.559638 loss_rnnt 6.236446 hw_loss 0.079627 lr 0.00040980 rank 6
2023-02-22 10:08:57,566 DEBUG TRAIN Batch 17/7100 loss 7.581247 loss_att 10.998073 loss_ctc 10.579187 loss_rnnt 6.440643 hw_loss 0.107837 lr 0.00040972 rank 3
2023-02-22 10:08:57,566 DEBUG TRAIN Batch 17/7100 loss 2.644544 loss_att 8.050217 loss_ctc 5.197017 loss_rnnt 1.125804 hw_loss 0.182392 lr 0.00040972 rank 2
2023-02-22 10:08:57,607 DEBUG TRAIN Batch 17/7100 loss 10.176503 loss_att 12.396751 loss_ctc 13.805702 loss_rnnt 9.220905 hw_loss 0.051853 lr 0.00040983 rank 1
2023-02-22 10:10:13,757 DEBUG TRAIN Batch 17/7200 loss 5.851625 loss_att 11.042688 loss_ctc 12.153579 loss_rnnt 3.927010 hw_loss 0.086517 lr 0.00040961 rank 7
2023-02-22 10:10:13,760 DEBUG TRAIN Batch 17/7200 loss 14.355861 loss_att 18.464235 loss_ctc 19.192434 loss_rnnt 12.837799 hw_loss 0.096580 lr 0.00040966 rank 0
2023-02-22 10:10:13,762 DEBUG TRAIN Batch 17/7200 loss 5.966617 loss_att 10.479279 loss_ctc 11.172709 loss_rnnt 4.296287 hw_loss 0.138097 lr 0.00040969 rank 1
2023-02-22 10:10:13,763 DEBUG TRAIN Batch 17/7200 loss 14.455566 loss_att 15.591883 loss_ctc 18.026632 loss_rnnt 13.684050 hw_loss 0.127712 lr 0.00040964 rank 4
2023-02-22 10:10:13,764 DEBUG TRAIN Batch 17/7200 loss 2.182262 loss_att 6.713151 loss_ctc 4.378350 loss_rnnt 0.905846 hw_loss 0.145175 lr 0.00040958 rank 3
2023-02-22 10:10:13,765 DEBUG TRAIN Batch 17/7200 loss 9.439982 loss_att 10.258615 loss_ctc 12.322019 loss_rnnt 8.838802 hw_loss 0.099716 lr 0.00040960 rank 5
2023-02-22 10:10:13,766 DEBUG TRAIN Batch 17/7200 loss 2.456977 loss_att 4.317364 loss_ctc 3.035681 loss_rnnt 1.957404 hw_loss 0.094379 lr 0.00040966 rank 6
2023-02-22 10:10:13,767 DEBUG TRAIN Batch 17/7200 loss 10.543559 loss_att 13.704199 loss_ctc 15.710470 loss_rnnt 9.182664 hw_loss 0.074710 lr 0.00040959 rank 2
2023-02-22 10:11:27,829 DEBUG TRAIN Batch 17/7300 loss 4.443714 loss_att 5.879772 loss_ctc 4.856099 loss_rnnt 4.031116 hw_loss 0.132002 lr 0.00040947 rank 5
2023-02-22 10:11:27,831 DEBUG TRAIN Batch 17/7300 loss 17.646124 loss_att 22.674158 loss_ctc 24.242437 loss_rnnt 15.708061 hw_loss 0.099278 lr 0.00040947 rank 7
2023-02-22 10:11:27,833 DEBUG TRAIN Batch 17/7300 loss 13.418328 loss_att 16.981529 loss_ctc 24.263893 loss_rnnt 11.241077 hw_loss 0.034752 lr 0.00040944 rank 3
2023-02-22 10:11:27,833 DEBUG TRAIN Batch 17/7300 loss 5.975713 loss_att 10.233055 loss_ctc 13.172043 loss_rnnt 4.093703 hw_loss 0.133182 lr 0.00040950 rank 4
2023-02-22 10:11:27,836 DEBUG TRAIN Batch 17/7300 loss 7.450279 loss_att 9.748918 loss_ctc 10.728083 loss_rnnt 6.461380 hw_loss 0.172746 lr 0.00040953 rank 6
2023-02-22 10:11:27,838 DEBUG TRAIN Batch 17/7300 loss 8.950422 loss_att 10.695313 loss_ctc 15.931592 loss_rnnt 7.616249 hw_loss 0.101947 lr 0.00040952 rank 0
2023-02-22 10:11:27,840 DEBUG TRAIN Batch 17/7300 loss 11.774737 loss_att 14.580792 loss_ctc 14.833767 loss_rnnt 10.764609 hw_loss 0.076963 lr 0.00040945 rank 2
2023-02-22 10:11:27,865 DEBUG TRAIN Batch 17/7300 loss 9.906993 loss_att 12.430787 loss_ctc 11.523500 loss_rnnt 9.161681 hw_loss 0.046910 lr 0.00040956 rank 1
2023-02-22 10:12:44,434 DEBUG TRAIN Batch 17/7400 loss 11.875943 loss_att 13.096298 loss_ctc 12.503258 loss_rnnt 11.465984 hw_loss 0.154210 lr 0.00040933 rank 7
2023-02-22 10:12:44,437 DEBUG TRAIN Batch 17/7400 loss 16.125715 loss_att 17.404091 loss_ctc 21.285805 loss_rnnt 15.136286 hw_loss 0.085767 lr 0.00040931 rank 3
2023-02-22 10:12:44,437 DEBUG TRAIN Batch 17/7400 loss 13.741932 loss_att 17.113754 loss_ctc 19.785421 loss_rnnt 12.242421 hw_loss 0.036276 lr 0.00040938 rank 0
2023-02-22 10:12:44,437 DEBUG TRAIN Batch 17/7400 loss 21.188013 loss_att 22.984434 loss_ctc 30.702118 loss_rnnt 19.523769 hw_loss 0.068270 lr 0.00040936 rank 4
2023-02-22 10:12:44,440 DEBUG TRAIN Batch 17/7400 loss 11.673525 loss_att 19.166336 loss_ctc 17.722250 loss_rnnt 9.281792 hw_loss 0.162514 lr 0.00040933 rank 5
2023-02-22 10:12:44,441 DEBUG TRAIN Batch 17/7400 loss 11.891632 loss_att 16.215050 loss_ctc 17.383379 loss_rnnt 10.253239 hw_loss 0.077770 lr 0.00040939 rank 6
2023-02-22 10:12:44,443 DEBUG TRAIN Batch 17/7400 loss 8.744533 loss_att 12.085036 loss_ctc 15.770297 loss_rnnt 7.068422 hw_loss 0.133577 lr 0.00040942 rank 1
2023-02-22 10:12:44,448 DEBUG TRAIN Batch 17/7400 loss 11.011207 loss_att 13.806515 loss_ctc 14.582417 loss_rnnt 9.889174 hw_loss 0.162769 lr 0.00040931 rank 2
2023-02-22 10:14:02,282 DEBUG TRAIN Batch 17/7500 loss 11.316230 loss_att 12.523365 loss_ctc 16.948706 loss_rnnt 10.262148 hw_loss 0.115610 lr 0.00040917 rank 3
2023-02-22 10:14:02,285 DEBUG TRAIN Batch 17/7500 loss 7.762491 loss_att 10.034454 loss_ctc 11.007297 loss_rnnt 6.790580 hw_loss 0.159145 lr 0.00040919 rank 7
2023-02-22 10:14:02,285 DEBUG TRAIN Batch 17/7500 loss 4.789226 loss_att 6.366767 loss_ctc 5.894905 loss_rnnt 4.268878 hw_loss 0.107655 lr 0.00040924 rank 0
2023-02-22 10:14:02,286 DEBUG TRAIN Batch 17/7500 loss 4.815371 loss_att 8.839799 loss_ctc 8.198536 loss_rnnt 3.461933 hw_loss 0.182744 lr 0.00040922 rank 4
2023-02-22 10:14:02,286 DEBUG TRAIN Batch 17/7500 loss 3.685853 loss_att 6.729198 loss_ctc 4.154882 loss_rnnt 2.953985 hw_loss 0.113741 lr 0.00040917 rank 2
2023-02-22 10:14:02,288 DEBUG TRAIN Batch 17/7500 loss 5.299234 loss_att 7.011318 loss_ctc 5.067527 loss_rnnt 4.891613 hw_loss 0.180185 lr 0.00040925 rank 6
2023-02-22 10:14:02,287 DEBUG TRAIN Batch 17/7500 loss 15.625563 loss_att 18.530428 loss_ctc 24.019428 loss_rnnt 13.906037 hw_loss 0.036317 lr 0.00040919 rank 5
2023-02-22 10:14:02,289 DEBUG TRAIN Batch 17/7500 loss 8.753259 loss_att 11.395017 loss_ctc 13.824781 loss_rnnt 7.488650 hw_loss 0.112601 lr 0.00040928 rank 1
2023-02-22 10:15:17,542 DEBUG TRAIN Batch 17/7600 loss 11.155910 loss_att 10.874608 loss_ctc 17.292307 loss_rnnt 10.272739 hw_loss 0.227335 lr 0.00040909 rank 4
2023-02-22 10:15:17,542 DEBUG TRAIN Batch 17/7600 loss 10.346987 loss_att 11.167404 loss_ctc 14.525841 loss_rnnt 9.538199 hw_loss 0.164105 lr 0.00040906 rank 7
2023-02-22 10:15:17,543 DEBUG TRAIN Batch 17/7600 loss 14.273549 loss_att 13.579239 loss_ctc 18.799833 loss_rnnt 13.778750 hw_loss 0.056543 lr 0.00040911 rank 0
2023-02-22 10:15:17,545 DEBUG TRAIN Batch 17/7600 loss 5.748075 loss_att 10.827501 loss_ctc 7.046617 loss_rnnt 4.517992 hw_loss 0.076986 lr 0.00040906 rank 5
2023-02-22 10:15:17,548 DEBUG TRAIN Batch 17/7600 loss 21.555725 loss_att 23.500652 loss_ctc 25.167822 loss_rnnt 20.671316 hw_loss 0.025892 lr 0.00040912 rank 6
2023-02-22 10:15:17,549 DEBUG TRAIN Batch 17/7600 loss 11.517125 loss_att 11.814367 loss_ctc 13.890090 loss_rnnt 11.044923 hw_loss 0.180674 lr 0.00040903 rank 3
2023-02-22 10:15:17,551 DEBUG TRAIN Batch 17/7600 loss 13.747921 loss_att 16.791340 loss_ctc 20.913692 loss_rnnt 12.144348 hw_loss 0.073971 lr 0.00040914 rank 1
2023-02-22 10:15:17,552 DEBUG TRAIN Batch 17/7600 loss 11.230477 loss_att 11.915163 loss_ctc 14.696671 loss_rnnt 10.566201 hw_loss 0.122212 lr 0.00040904 rank 2
2023-02-22 10:16:32,853 DEBUG TRAIN Batch 17/7700 loss 7.651243 loss_att 12.856937 loss_ctc 11.458865 loss_rnnt 6.085979 hw_loss 0.030828 lr 0.00040895 rank 4
2023-02-22 10:16:32,854 DEBUG TRAIN Batch 17/7700 loss 5.680184 loss_att 9.006944 loss_ctc 5.764204 loss_rnnt 4.986835 hw_loss 0.031490 lr 0.00040901 rank 1
2023-02-22 10:16:32,857 DEBUG TRAIN Batch 17/7700 loss 10.278787 loss_att 14.222218 loss_ctc 17.728331 loss_rnnt 8.432579 hw_loss 0.120467 lr 0.00040889 rank 3
2023-02-22 10:16:32,858 DEBUG TRAIN Batch 17/7700 loss 9.030488 loss_att 11.561069 loss_ctc 11.475763 loss_rnnt 8.165899 hw_loss 0.060817 lr 0.00040897 rank 0
2023-02-22 10:16:32,858 DEBUG TRAIN Batch 17/7700 loss 5.174358 loss_att 7.807649 loss_ctc 7.689799 loss_rnnt 4.248882 hw_loss 0.118923 lr 0.00040892 rank 5
2023-02-22 10:16:32,859 DEBUG TRAIN Batch 17/7700 loss 13.961464 loss_att 15.608881 loss_ctc 20.056728 loss_rnnt 12.777343 hw_loss 0.078629 lr 0.00040890 rank 2
2023-02-22 10:16:32,859 DEBUG TRAIN Batch 17/7700 loss 7.196791 loss_att 9.878151 loss_ctc 8.654451 loss_rnnt 6.418247 hw_loss 0.089844 lr 0.00040892 rank 7
2023-02-22 10:16:32,863 DEBUG TRAIN Batch 17/7700 loss 7.004408 loss_att 11.624527 loss_ctc 13.988007 loss_rnnt 5.043844 hw_loss 0.197613 lr 0.00040898 rank 6
2023-02-22 10:17:50,983 DEBUG TRAIN Batch 17/7800 loss 7.272430 loss_att 10.384092 loss_ctc 10.999634 loss_rnnt 6.141361 hw_loss 0.022081 lr 0.00040887 rank 1
2023-02-22 10:17:50,983 DEBUG TRAIN Batch 17/7800 loss 2.708660 loss_att 4.134922 loss_ctc 5.575478 loss_rnnt 1.960343 hw_loss 0.151541 lr 0.00040884 rank 6
2023-02-22 10:17:50,984 DEBUG TRAIN Batch 17/7800 loss 6.896490 loss_att 7.803990 loss_ctc 8.349302 loss_rnnt 6.472800 hw_loss 0.090901 lr 0.00040878 rank 5
2023-02-22 10:17:50,986 DEBUG TRAIN Batch 17/7800 loss 10.034482 loss_att 15.046946 loss_ctc 17.654453 loss_rnnt 8.015594 hw_loss 0.000745 lr 0.00040881 rank 4
2023-02-22 10:17:50,986 DEBUG TRAIN Batch 17/7800 loss 15.470209 loss_att 19.355541 loss_ctc 22.598526 loss_rnnt 13.643382 hw_loss 0.186223 lr 0.00040878 rank 7
2023-02-22 10:17:50,988 DEBUG TRAIN Batch 17/7800 loss 10.994135 loss_att 19.442631 loss_ctc 19.915352 loss_rnnt 8.074781 hw_loss 0.075297 lr 0.00040883 rank 0
2023-02-22 10:17:50,990 DEBUG TRAIN Batch 17/7800 loss 9.358356 loss_att 14.204824 loss_ctc 11.643280 loss_rnnt 8.002922 hw_loss 0.152783 lr 0.00040876 rank 3
2023-02-22 10:17:51,037 DEBUG TRAIN Batch 17/7800 loss 14.717467 loss_att 17.114977 loss_ctc 17.492687 loss_rnnt 13.845927 hw_loss 0.041267 lr 0.00040876 rank 2
2023-02-22 10:19:06,960 DEBUG TRAIN Batch 17/7900 loss 11.063485 loss_att 12.907439 loss_ctc 13.135052 loss_rnnt 10.356136 hw_loss 0.116905 lr 0.00040868 rank 4
2023-02-22 10:19:06,966 DEBUG TRAIN Batch 17/7900 loss 19.991327 loss_att 24.139942 loss_ctc 23.751204 loss_rnnt 18.582218 hw_loss 0.146380 lr 0.00040865 rank 7
2023-02-22 10:19:06,968 DEBUG TRAIN Batch 17/7900 loss 9.261042 loss_att 12.827316 loss_ctc 9.573414 loss_rnnt 8.428010 hw_loss 0.146489 lr 0.00040865 rank 5
2023-02-22 10:19:06,971 DEBUG TRAIN Batch 17/7900 loss 14.789579 loss_att 17.859386 loss_ctc 21.376572 loss_rnnt 13.199865 hw_loss 0.182788 lr 0.00040870 rank 6
2023-02-22 10:19:06,971 DEBUG TRAIN Batch 17/7900 loss 7.350853 loss_att 10.852110 loss_ctc 9.944122 loss_rnnt 6.259643 hw_loss 0.084730 lr 0.00040873 rank 1
2023-02-22 10:19:06,971 DEBUG TRAIN Batch 17/7900 loss 6.493437 loss_att 9.063861 loss_ctc 8.509878 loss_rnnt 5.671047 hw_loss 0.073963 lr 0.00040870 rank 0
2023-02-22 10:19:06,972 DEBUG TRAIN Batch 17/7900 loss 7.899608 loss_att 9.428413 loss_ctc 12.033561 loss_rnnt 6.951534 hw_loss 0.170848 lr 0.00040863 rank 2
2023-02-22 10:19:07,021 DEBUG TRAIN Batch 17/7900 loss 7.315944 loss_att 10.258850 loss_ctc 13.525595 loss_rnnt 5.788827 hw_loss 0.207342 lr 0.00040862 rank 3
2023-02-22 10:20:22,024 DEBUG TRAIN Batch 17/8000 loss 6.435385 loss_att 9.002420 loss_ctc 12.295467 loss_rnnt 5.126072 hw_loss 0.027301 lr 0.00040851 rank 7
2023-02-22 10:20:22,026 DEBUG TRAIN Batch 17/8000 loss 5.438437 loss_att 7.850672 loss_ctc 8.628506 loss_rnnt 4.490053 hw_loss 0.076117 lr 0.00040856 rank 0
2023-02-22 10:20:22,027 DEBUG TRAIN Batch 17/8000 loss 12.358585 loss_att 16.054808 loss_ctc 18.893583 loss_rnnt 10.631611 hw_loss 0.218244 lr 0.00040851 rank 5
2023-02-22 10:20:22,028 DEBUG TRAIN Batch 17/8000 loss 3.432561 loss_att 5.911625 loss_ctc 6.252183 loss_rnnt 2.501522 hw_loss 0.111143 lr 0.00040860 rank 1
2023-02-22 10:20:22,029 DEBUG TRAIN Batch 17/8000 loss 17.860563 loss_att 20.357809 loss_ctc 23.413723 loss_rnnt 16.498308 hw_loss 0.229467 lr 0.00040849 rank 3
2023-02-22 10:20:22,031 DEBUG TRAIN Batch 17/8000 loss 8.505486 loss_att 12.832903 loss_ctc 10.535363 loss_rnnt 7.353065 hw_loss 0.030538 lr 0.00040857 rank 6
2023-02-22 10:20:22,031 DEBUG TRAIN Batch 17/8000 loss 6.130464 loss_att 9.741529 loss_ctc 8.830985 loss_rnnt 4.983588 hw_loss 0.121112 lr 0.00040854 rank 4
2023-02-22 10:20:22,078 DEBUG TRAIN Batch 17/8000 loss 15.068852 loss_att 17.635025 loss_ctc 21.498745 loss_rnnt 13.647443 hw_loss 0.095353 lr 0.00040849 rank 2
2023-02-22 10:21:38,852 DEBUG TRAIN Batch 17/8100 loss 7.932428 loss_att 9.561220 loss_ctc 9.404046 loss_rnnt 7.408060 hw_loss 0.004489 lr 0.00040837 rank 7
2023-02-22 10:21:38,855 DEBUG TRAIN Batch 17/8100 loss 12.937752 loss_att 13.854778 loss_ctc 16.628159 loss_rnnt 12.199408 hw_loss 0.117910 lr 0.00040842 rank 0
2023-02-22 10:21:38,856 DEBUG TRAIN Batch 17/8100 loss 8.118378 loss_att 12.143982 loss_ctc 14.442881 loss_rnnt 6.385563 hw_loss 0.158301 lr 0.00040843 rank 6
2023-02-22 10:21:38,857 DEBUG TRAIN Batch 17/8100 loss 5.936182 loss_att 11.240877 loss_ctc 9.453587 loss_rnnt 4.379328 hw_loss 0.050489 lr 0.00040837 rank 5
2023-02-22 10:21:38,857 DEBUG TRAIN Batch 17/8100 loss 9.617390 loss_att 11.915949 loss_ctc 15.724915 loss_rnnt 8.307568 hw_loss 0.067073 lr 0.00040840 rank 4
2023-02-22 10:21:38,859 DEBUG TRAIN Batch 17/8100 loss 8.006610 loss_att 10.807384 loss_ctc 13.061148 loss_rnnt 6.707581 hw_loss 0.121756 lr 0.00040835 rank 2
2023-02-22 10:21:38,860 DEBUG TRAIN Batch 17/8100 loss 11.433996 loss_att 12.712253 loss_ctc 15.351416 loss_rnnt 10.571348 hw_loss 0.158763 lr 0.00040846 rank 1
2023-02-22 10:21:38,905 DEBUG TRAIN Batch 17/8100 loss 11.537705 loss_att 16.741234 loss_ctc 13.921412 loss_rnnt 10.173433 hw_loss 0.010761 lr 0.00040835 rank 3
2023-02-22 10:22:55,622 DEBUG TRAIN Batch 17/8200 loss 14.360807 loss_att 17.318569 loss_ctc 19.790510 loss_rnnt 13.006680 hw_loss 0.072404 lr 0.00040827 rank 4
2023-02-22 10:22:55,623 DEBUG TRAIN Batch 17/8200 loss 16.223728 loss_att 16.850124 loss_ctc 23.854813 loss_rnnt 15.041426 hw_loss 0.074146 lr 0.00040824 rank 5
2023-02-22 10:22:55,626 DEBUG TRAIN Batch 17/8200 loss 4.846195 loss_att 5.701181 loss_ctc 4.384839 loss_rnnt 4.591708 hw_loss 0.271880 lr 0.00040824 rank 7
2023-02-22 10:22:55,627 DEBUG TRAIN Batch 17/8200 loss 3.557992 loss_att 5.901312 loss_ctc 4.878942 loss_rnnt 2.844423 hw_loss 0.128960 lr 0.00040830 rank 6
2023-02-22 10:22:55,628 DEBUG TRAIN Batch 17/8200 loss 8.832462 loss_att 10.031719 loss_ctc 13.486658 loss_rnnt 7.881178 hw_loss 0.170386 lr 0.00040829 rank 0
2023-02-22 10:22:55,629 DEBUG TRAIN Batch 17/8200 loss 11.461556 loss_att 10.783941 loss_ctc 14.613674 loss_rnnt 11.067710 hw_loss 0.204539 lr 0.00040832 rank 1
2023-02-22 10:22:55,631 DEBUG TRAIN Batch 17/8200 loss 10.092914 loss_att 12.400985 loss_ctc 13.996434 loss_rnnt 9.035541 hw_loss 0.141171 lr 0.00040822 rank 2
2023-02-22 10:22:55,630 DEBUG TRAIN Batch 17/8200 loss 9.651033 loss_att 12.550921 loss_ctc 14.102230 loss_rnnt 8.440073 hw_loss 0.070293 lr 0.00040821 rank 3
2023-02-22 10:24:10,317 DEBUG TRAIN Batch 17/8300 loss 12.698489 loss_att 15.872154 loss_ctc 13.202051 loss_rnnt 11.969806 hw_loss 0.050269 lr 0.00040813 rank 4
2023-02-22 10:24:10,318 DEBUG TRAIN Batch 17/8300 loss 11.837294 loss_att 14.302132 loss_ctc 13.589894 loss_rnnt 10.969761 hw_loss 0.264159 lr 0.00040815 rank 0
2023-02-22 10:24:10,318 DEBUG TRAIN Batch 17/8300 loss 16.899643 loss_att 18.678886 loss_ctc 20.682396 loss_rnnt 15.954451 hw_loss 0.159329 lr 0.00040810 rank 5
2023-02-22 10:24:10,323 DEBUG TRAIN Batch 17/8300 loss 6.998147 loss_att 9.533441 loss_ctc 11.289907 loss_rnnt 5.852347 hw_loss 0.124701 lr 0.00040808 rank 3
2023-02-22 10:24:10,325 DEBUG TRAIN Batch 17/8300 loss 9.477322 loss_att 15.291424 loss_ctc 9.822826 loss_rnnt 8.219337 hw_loss 0.092057 lr 0.00040819 rank 1
2023-02-22 10:24:10,325 DEBUG TRAIN Batch 17/8300 loss 5.213567 loss_att 6.777709 loss_ctc 7.993228 loss_rnnt 4.453670 hw_loss 0.143339 lr 0.00040810 rank 7
2023-02-22 10:24:10,327 DEBUG TRAIN Batch 17/8300 loss 8.913766 loss_att 15.323793 loss_ctc 13.093792 loss_rnnt 7.041633 hw_loss 0.061483 lr 0.00040816 rank 6
2023-02-22 10:24:10,330 DEBUG TRAIN Batch 17/8300 loss 4.673834 loss_att 4.698619 loss_ctc 5.581214 loss_rnnt 4.443264 hw_loss 0.196179 lr 0.00040808 rank 2
2023-02-22 10:24:56,946 DEBUG CV Batch 17/0 loss 2.264174 loss_att 2.402324 loss_ctc 2.811932 loss_rnnt 2.037941 hw_loss 0.235442 history loss 2.180316 rank 4
2023-02-22 10:24:56,952 DEBUG CV Batch 17/0 loss 2.264174 loss_att 2.402324 loss_ctc 2.811932 loss_rnnt 2.037941 hw_loss 0.235442 history loss 2.180316 rank 5
2023-02-22 10:24:56,954 DEBUG CV Batch 17/0 loss 2.264174 loss_att 2.402324 loss_ctc 2.811932 loss_rnnt 2.037941 hw_loss 0.235442 history loss 2.180316 rank 6
2023-02-22 10:24:56,962 DEBUG CV Batch 17/0 loss 2.264174 loss_att 2.402324 loss_ctc 2.811932 loss_rnnt 2.037941 hw_loss 0.235442 history loss 2.180316 rank 0
2023-02-22 10:24:56,966 DEBUG CV Batch 17/0 loss 2.264174 loss_att 2.402324 loss_ctc 2.811932 loss_rnnt 2.037941 hw_loss 0.235442 history loss 2.180316 rank 1
2023-02-22 10:24:56,968 DEBUG CV Batch 17/0 loss 2.264174 loss_att 2.402324 loss_ctc 2.811932 loss_rnnt 2.037941 hw_loss 0.235442 history loss 2.180316 rank 7
2023-02-22 10:24:56,969 DEBUG CV Batch 17/0 loss 2.264174 loss_att 2.402324 loss_ctc 2.811932 loss_rnnt 2.037941 hw_loss 0.235442 history loss 2.180316 rank 3
2023-02-22 10:24:56,974 DEBUG CV Batch 17/0 loss 2.264174 loss_att 2.402324 loss_ctc 2.811932 loss_rnnt 2.037941 hw_loss 0.235442 history loss 2.180316 rank 2
2023-02-22 10:25:08,070 DEBUG CV Batch 17/100 loss 7.549935 loss_att 7.708240 loss_ctc 10.022960 loss_rnnt 7.140464 hw_loss 0.090138 history loss 3.522318 rank 0
2023-02-22 10:25:08,150 DEBUG CV Batch 17/100 loss 7.549935 loss_att 7.708240 loss_ctc 10.022960 loss_rnnt 7.140464 hw_loss 0.090138 history loss 3.522318 rank 4
2023-02-22 10:25:08,218 DEBUG CV Batch 17/100 loss 7.549935 loss_att 7.708240 loss_ctc 10.022960 loss_rnnt 7.140464 hw_loss 0.090138 history loss 3.522318 rank 5
2023-02-22 10:25:08,231 DEBUG CV Batch 17/100 loss 7.549935 loss_att 7.708240 loss_ctc 10.022960 loss_rnnt 7.140464 hw_loss 0.090138 history loss 3.522318 rank 7
2023-02-22 10:25:08,241 DEBUG CV Batch 17/100 loss 7.549935 loss_att 7.708240 loss_ctc 10.022960 loss_rnnt 7.140464 hw_loss 0.090138 history loss 3.522318 rank 1
2023-02-22 10:25:08,290 DEBUG CV Batch 17/100 loss 7.549935 loss_att 7.708240 loss_ctc 10.022960 loss_rnnt 7.140464 hw_loss 0.090138 history loss 3.522318 rank 6
2023-02-22 10:25:08,292 DEBUG CV Batch 17/100 loss 7.549935 loss_att 7.708240 loss_ctc 10.022960 loss_rnnt 7.140464 hw_loss 0.090138 history loss 3.522318 rank 3
2023-02-22 10:25:08,292 DEBUG CV Batch 17/100 loss 7.549935 loss_att 7.708240 loss_ctc 10.022960 loss_rnnt 7.140464 hw_loss 0.090138 history loss 3.522318 rank 2
2023-02-22 10:25:21,399 DEBUG CV Batch 17/200 loss 6.230168 loss_att 11.731076 loss_ctc 7.542179 loss_rnnt 4.945392 hw_loss 0.018112 history loss 4.124056 rank 0
2023-02-22 10:25:21,533 DEBUG CV Batch 17/200 loss 6.230168 loss_att 11.731076 loss_ctc 7.542179 loss_rnnt 4.945392 hw_loss 0.018112 history loss 4.124056 rank 4
2023-02-22 10:25:21,595 DEBUG CV Batch 17/200 loss 6.230168 loss_att 11.731076 loss_ctc 7.542179 loss_rnnt 4.945392 hw_loss 0.018112 history loss 4.124056 rank 5
2023-02-22 10:25:21,780 DEBUG CV Batch 17/200 loss 6.230168 loss_att 11.731076 loss_ctc 7.542179 loss_rnnt 4.945392 hw_loss 0.018112 history loss 4.124056 rank 2
2023-02-22 10:25:21,799 DEBUG CV Batch 17/200 loss 6.230168 loss_att 11.731076 loss_ctc 7.542179 loss_rnnt 4.945392 hw_loss 0.018112 history loss 4.124056 rank 6
2023-02-22 10:25:21,832 DEBUG CV Batch 17/200 loss 6.230168 loss_att 11.731076 loss_ctc 7.542179 loss_rnnt 4.945392 hw_loss 0.018112 history loss 4.124056 rank 7
2023-02-22 10:25:21,837 DEBUG CV Batch 17/200 loss 6.230168 loss_att 11.731076 loss_ctc 7.542179 loss_rnnt 4.945392 hw_loss 0.018112 history loss 4.124056 rank 3
2023-02-22 10:25:22,452 DEBUG CV Batch 17/200 loss 6.230168 loss_att 11.731076 loss_ctc 7.542179 loss_rnnt 4.945392 hw_loss 0.018112 history loss 4.124056 rank 1
2023-02-22 10:25:33,461 DEBUG CV Batch 17/300 loss 4.217409 loss_att 5.011510 loss_ctc 7.684104 loss_rnnt 3.544119 hw_loss 0.097955 history loss 4.301270 rank 0
2023-02-22 10:25:33,621 DEBUG CV Batch 17/300 loss 4.217409 loss_att 5.011510 loss_ctc 7.684104 loss_rnnt 3.544119 hw_loss 0.097955 history loss 4.301270 rank 4
2023-02-22 10:25:33,681 DEBUG CV Batch 17/300 loss 4.217409 loss_att 5.011510 loss_ctc 7.684104 loss_rnnt 3.544119 hw_loss 0.097955 history loss 4.301270 rank 5
2023-02-22 10:25:33,930 DEBUG CV Batch 17/300 loss 4.217409 loss_att 5.011510 loss_ctc 7.684104 loss_rnnt 3.544119 hw_loss 0.097955 history loss 4.301270 rank 2
2023-02-22 10:25:33,931 DEBUG CV Batch 17/300 loss 4.217409 loss_att 5.011510 loss_ctc 7.684104 loss_rnnt 3.544119 hw_loss 0.097955 history loss 4.301270 rank 7
2023-02-22 10:25:34,002 DEBUG CV Batch 17/300 loss 4.217409 loss_att 5.011510 loss_ctc 7.684104 loss_rnnt 3.544119 hw_loss 0.097955 history loss 4.301270 rank 3
2023-02-22 10:25:34,054 DEBUG CV Batch 17/300 loss 4.217409 loss_att 5.011510 loss_ctc 7.684104 loss_rnnt 3.544119 hw_loss 0.097955 history loss 4.301270 rank 6
2023-02-22 10:25:34,691 DEBUG CV Batch 17/300 loss 4.217409 loss_att 5.011510 loss_ctc 7.684104 loss_rnnt 3.544119 hw_loss 0.097955 history loss 4.301270 rank 1
2023-02-22 10:25:45,485 DEBUG CV Batch 17/400 loss 25.716099 loss_att 135.533325 loss_ctc 11.802453 loss_rnnt 5.607733 hw_loss 0.000134 history loss 5.292422 rank 0
2023-02-22 10:25:45,738 DEBUG CV Batch 17/400 loss 25.716099 loss_att 135.533325 loss_ctc 11.802453 loss_rnnt 5.607733 hw_loss 0.000134 history loss 5.292422 rank 4
2023-02-22 10:25:45,915 DEBUG CV Batch 17/400 loss 25.716099 loss_att 135.533325 loss_ctc 11.802453 loss_rnnt 5.607733 hw_loss 0.000134 history loss 5.292422 rank 5
2023-02-22 10:25:46,106 DEBUG CV Batch 17/400 loss 25.716099 loss_att 135.533325 loss_ctc 11.802453 loss_rnnt 5.607733 hw_loss 0.000134 history loss 5.292422 rank 7
2023-02-22 10:25:46,184 DEBUG CV Batch 17/400 loss 25.716099 loss_att 135.533325 loss_ctc 11.802453 loss_rnnt 5.607733 hw_loss 0.000134 history loss 5.292422 rank 6
2023-02-22 10:25:46,267 DEBUG CV Batch 17/400 loss 25.716099 loss_att 135.533325 loss_ctc 11.802453 loss_rnnt 5.607733 hw_loss 0.000134 history loss 5.292422 rank 3
2023-02-22 10:25:46,408 DEBUG CV Batch 17/400 loss 25.716099 loss_att 135.533325 loss_ctc 11.802453 loss_rnnt 5.607733 hw_loss 0.000134 history loss 5.292422 rank 2
2023-02-22 10:25:46,931 DEBUG CV Batch 17/400 loss 25.716099 loss_att 135.533325 loss_ctc 11.802453 loss_rnnt 5.607733 hw_loss 0.000134 history loss 5.292422 rank 1
2023-02-22 10:25:56,000 DEBUG CV Batch 17/500 loss 4.521915 loss_att 5.427671 loss_ctc 6.627733 loss_rnnt 3.998403 hw_loss 0.115471 history loss 6.124407 rank 0
2023-02-22 10:25:56,183 DEBUG CV Batch 17/500 loss 4.521915 loss_att 5.427671 loss_ctc 6.627733 loss_rnnt 3.998403 hw_loss 0.115471 history loss 6.124407 rank 4
2023-02-22 10:25:56,555 DEBUG CV Batch 17/500 loss 4.521915 loss_att 5.427671 loss_ctc 6.627733 loss_rnnt 3.998403 hw_loss 0.115471 history loss 6.124407 rank 5
2023-02-22 10:25:56,613 DEBUG CV Batch 17/500 loss 4.521915 loss_att 5.427671 loss_ctc 6.627733 loss_rnnt 3.998403 hw_loss 0.115471 history loss 6.124407 rank 7
2023-02-22 10:25:56,748 DEBUG CV Batch 17/500 loss 4.521915 loss_att 5.427671 loss_ctc 6.627733 loss_rnnt 3.998403 hw_loss 0.115471 history loss 6.124407 rank 6
2023-02-22 10:25:56,994 DEBUG CV Batch 17/500 loss 4.521915 loss_att 5.427671 loss_ctc 6.627733 loss_rnnt 3.998403 hw_loss 0.115471 history loss 6.124407 rank 3
2023-02-22 10:25:57,200 DEBUG CV Batch 17/500 loss 4.521915 loss_att 5.427671 loss_ctc 6.627733 loss_rnnt 3.998403 hw_loss 0.115471 history loss 6.124407 rank 2
2023-02-22 10:25:57,701 DEBUG CV Batch 17/500 loss 4.521915 loss_att 5.427671 loss_ctc 6.627733 loss_rnnt 3.998403 hw_loss 0.115471 history loss 6.124407 rank 1
2023-02-22 10:26:08,059 DEBUG CV Batch 17/600 loss 6.881077 loss_att 7.598113 loss_ctc 9.875468 loss_rnnt 6.239007 hw_loss 0.186393 history loss 7.109165 rank 0
2023-02-22 10:26:08,229 DEBUG CV Batch 17/600 loss 6.881077 loss_att 7.598113 loss_ctc 9.875468 loss_rnnt 6.239007 hw_loss 0.186393 history loss 7.109165 rank 4
2023-02-22 10:26:08,657 DEBUG CV Batch 17/600 loss 6.881077 loss_att 7.598113 loss_ctc 9.875468 loss_rnnt 6.239007 hw_loss 0.186393 history loss 7.109165 rank 7
2023-02-22 10:26:08,682 DEBUG CV Batch 17/600 loss 6.881077 loss_att 7.598113 loss_ctc 9.875468 loss_rnnt 6.239007 hw_loss 0.186393 history loss 7.109165 rank 5
2023-02-22 10:26:09,163 DEBUG CV Batch 17/600 loss 6.881077 loss_att 7.598113 loss_ctc 9.875468 loss_rnnt 6.239007 hw_loss 0.186393 history loss 7.109165 rank 3
2023-02-22 10:26:09,375 DEBUG CV Batch 17/600 loss 6.881077 loss_att 7.598113 loss_ctc 9.875468 loss_rnnt 6.239007 hw_loss 0.186393 history loss 7.109165 rank 2
2023-02-22 10:26:09,820 DEBUG CV Batch 17/600 loss 6.881077 loss_att 7.598113 loss_ctc 9.875468 loss_rnnt 6.239007 hw_loss 0.186393 history loss 7.109165 rank 1
2023-02-22 10:26:10,195 DEBUG CV Batch 17/600 loss 6.881077 loss_att 7.598113 loss_ctc 9.875468 loss_rnnt 6.239007 hw_loss 0.186393 history loss 7.109165 rank 6
2023-02-22 10:26:19,414 DEBUG CV Batch 17/700 loss 16.046185 loss_att 63.288788 loss_ctc 21.727926 loss_rnnt 5.840026 hw_loss 0.000134 history loss 7.824665 rank 0
2023-02-22 10:26:19,564 DEBUG CV Batch 17/700 loss 16.046185 loss_att 63.288788 loss_ctc 21.727926 loss_rnnt 5.840026 hw_loss 0.000134 history loss 7.824665 rank 4
2023-02-22 10:26:20,020 DEBUG CV Batch 17/700 loss 16.046185 loss_att 63.288788 loss_ctc 21.727926 loss_rnnt 5.840026 hw_loss 0.000134 history loss 7.824665 rank 7
2023-02-22 10:26:20,051 DEBUG CV Batch 17/700 loss 16.046185 loss_att 63.288788 loss_ctc 21.727926 loss_rnnt 5.840026 hw_loss 0.000134 history loss 7.824665 rank 5
2023-02-22 10:26:20,617 DEBUG CV Batch 17/700 loss 16.046185 loss_att 63.288788 loss_ctc 21.727926 loss_rnnt 5.840026 hw_loss 0.000134 history loss 7.824665 rank 3
2023-02-22 10:26:20,869 DEBUG CV Batch 17/700 loss 16.046185 loss_att 63.288788 loss_ctc 21.727926 loss_rnnt 5.840026 hw_loss 0.000134 history loss 7.824665 rank 2
2023-02-22 10:26:21,229 DEBUG CV Batch 17/700 loss 16.046185 loss_att 63.288788 loss_ctc 21.727926 loss_rnnt 5.840026 hw_loss 0.000134 history loss 7.824665 rank 1
2023-02-22 10:26:21,677 DEBUG CV Batch 17/700 loss 16.046185 loss_att 63.288788 loss_ctc 21.727926 loss_rnnt 5.840026 hw_loss 0.000134 history loss 7.824665 rank 6
2023-02-22 10:26:30,540 DEBUG CV Batch 17/800 loss 12.013218 loss_att 10.953190 loss_ctc 16.171143 loss_rnnt 11.578512 hw_loss 0.173104 history loss 7.243384 rank 0
2023-02-22 10:26:30,743 DEBUG CV Batch 17/800 loss 12.013218 loss_att 10.953190 loss_ctc 16.171143 loss_rnnt 11.578512 hw_loss 0.173104 history loss 7.243384 rank 4
2023-02-22 10:26:31,179 DEBUG CV Batch 17/800 loss 12.013218 loss_att 10.953190 loss_ctc 16.171143 loss_rnnt 11.578512 hw_loss 0.173104 history loss 7.243384 rank 7
2023-02-22 10:26:31,286 DEBUG CV Batch 17/800 loss 12.013218 loss_att 10.953190 loss_ctc 16.171143 loss_rnnt 11.578512 hw_loss 0.173104 history loss 7.243384 rank 5
2023-02-22 10:26:32,162 DEBUG CV Batch 17/800 loss 12.013218 loss_att 10.953190 loss_ctc 16.171143 loss_rnnt 11.578512 hw_loss 0.173104 history loss 7.243384 rank 2
2023-02-22 10:26:32,412 DEBUG CV Batch 17/800 loss 12.013218 loss_att 10.953190 loss_ctc 16.171143 loss_rnnt 11.578512 hw_loss 0.173104 history loss 7.243384 rank 3
2023-02-22 10:26:32,535 DEBUG CV Batch 17/800 loss 12.013218 loss_att 10.953190 loss_ctc 16.171143 loss_rnnt 11.578512 hw_loss 0.173104 history loss 7.243384 rank 1
2023-02-22 10:26:33,141 DEBUG CV Batch 17/800 loss 12.013218 loss_att 10.953190 loss_ctc 16.171143 loss_rnnt 11.578512 hw_loss 0.173104 history loss 7.243384 rank 6
2023-02-22 10:26:43,853 DEBUG CV Batch 17/900 loss 14.037800 loss_att 17.292034 loss_ctc 19.847536 loss_rnnt 12.591929 hw_loss 0.038236 history loss 7.026766 rank 0
2023-02-22 10:26:44,107 DEBUG CV Batch 17/900 loss 14.037800 loss_att 17.292034 loss_ctc 19.847536 loss_rnnt 12.591929 hw_loss 0.038236 history loss 7.026766 rank 4
2023-02-22 10:26:44,535 DEBUG CV Batch 17/900 loss 14.037800 loss_att 17.292034 loss_ctc 19.847536 loss_rnnt 12.591929 hw_loss 0.038236 history loss 7.026766 rank 7
2023-02-22 10:26:44,643 DEBUG CV Batch 17/900 loss 14.037800 loss_att 17.292034 loss_ctc 19.847536 loss_rnnt 12.591929 hw_loss 0.038236 history loss 7.026766 rank 5
2023-02-22 10:26:45,624 DEBUG CV Batch 17/900 loss 14.037800 loss_att 17.292034 loss_ctc 19.847536 loss_rnnt 12.591929 hw_loss 0.038236 history loss 7.026766 rank 2
2023-02-22 10:26:45,654 DEBUG CV Batch 17/900 loss 14.037800 loss_att 17.292034 loss_ctc 19.847536 loss_rnnt 12.591929 hw_loss 0.038236 history loss 7.026766 rank 3
2023-02-22 10:26:46,396 DEBUG CV Batch 17/900 loss 14.037800 loss_att 17.292034 loss_ctc 19.847536 loss_rnnt 12.591929 hw_loss 0.038236 history loss 7.026766 rank 1
2023-02-22 10:26:47,138 DEBUG CV Batch 17/900 loss 14.037800 loss_att 17.292034 loss_ctc 19.847536 loss_rnnt 12.591929 hw_loss 0.038236 history loss 7.026766 rank 6
2023-02-22 10:26:56,072 DEBUG CV Batch 17/1000 loss 3.902875 loss_att 5.012496 loss_ctc 5.495367 loss_rnnt 3.393679 hw_loss 0.140513 history loss 6.784435 rank 0
2023-02-22 10:26:56,436 DEBUG CV Batch 17/1000 loss 3.902875 loss_att 5.012496 loss_ctc 5.495367 loss_rnnt 3.393679 hw_loss 0.140513 history loss 6.784435 rank 4
2023-02-22 10:26:56,681 DEBUG CV Batch 17/1000 loss 3.902875 loss_att 5.012496 loss_ctc 5.495367 loss_rnnt 3.393679 hw_loss 0.140513 history loss 6.784435 rank 7
2023-02-22 10:26:56,836 DEBUG CV Batch 17/1000 loss 3.902875 loss_att 5.012496 loss_ctc 5.495367 loss_rnnt 3.393679 hw_loss 0.140513 history loss 6.784435 rank 5
2023-02-22 10:26:57,892 DEBUG CV Batch 17/1000 loss 3.902875 loss_att 5.012496 loss_ctc 5.495367 loss_rnnt 3.393679 hw_loss 0.140513 history loss 6.784435 rank 3
2023-02-22 10:26:57,935 DEBUG CV Batch 17/1000 loss 3.902875 loss_att 5.012496 loss_ctc 5.495367 loss_rnnt 3.393679 hw_loss 0.140513 history loss 6.784435 rank 2
2023-02-22 10:26:59,084 DEBUG CV Batch 17/1000 loss 3.902875 loss_att 5.012496 loss_ctc 5.495367 loss_rnnt 3.393679 hw_loss 0.140513 history loss 6.784435 rank 1
2023-02-22 10:26:59,424 DEBUG CV Batch 17/1000 loss 3.902875 loss_att 5.012496 loss_ctc 5.495367 loss_rnnt 3.393679 hw_loss 0.140513 history loss 6.784435 rank 6
2023-02-22 10:27:07,996 DEBUG CV Batch 17/1100 loss 6.793680 loss_att 6.270287 loss_ctc 8.709688 loss_rnnt 6.509706 hw_loss 0.249721 history loss 6.764893 rank 0
2023-02-22 10:27:08,390 DEBUG CV Batch 17/1100 loss 6.793680 loss_att 6.270287 loss_ctc 8.709688 loss_rnnt 6.509706 hw_loss 0.249721 history loss 6.764893 rank 4
2023-02-22 10:27:08,564 DEBUG CV Batch 17/1100 loss 6.793680 loss_att 6.270287 loss_ctc 8.709688 loss_rnnt 6.509706 hw_loss 0.249721 history loss 6.764893 rank 7
2023-02-22 10:27:09,135 DEBUG CV Batch 17/1100 loss 6.793680 loss_att 6.270287 loss_ctc 8.709688 loss_rnnt 6.509706 hw_loss 0.249721 history loss 6.764893 rank 5
2023-02-22 10:27:09,891 DEBUG CV Batch 17/1100 loss 6.793680 loss_att 6.270287 loss_ctc 8.709688 loss_rnnt 6.509706 hw_loss 0.249721 history loss 6.764893 rank 3
2023-02-22 10:27:09,942 DEBUG CV Batch 17/1100 loss 6.793680 loss_att 6.270287 loss_ctc 8.709688 loss_rnnt 6.509706 hw_loss 0.249721 history loss 6.764893 rank 2
2023-02-22 10:27:11,135 DEBUG CV Batch 17/1100 loss 6.793680 loss_att 6.270287 loss_ctc 8.709688 loss_rnnt 6.509706 hw_loss 0.249721 history loss 6.764893 rank 1
2023-02-22 10:27:11,489 DEBUG CV Batch 17/1100 loss 6.793680 loss_att 6.270287 loss_ctc 8.709688 loss_rnnt 6.509706 hw_loss 0.249721 history loss 6.764893 rank 6
2023-02-22 10:27:18,649 DEBUG CV Batch 17/1200 loss 6.842584 loss_att 7.472326 loss_ctc 7.275059 loss_rnnt 6.617132 hw_loss 0.078450 history loss 7.114331 rank 0
2023-02-22 10:27:18,911 DEBUG CV Batch 17/1200 loss 6.842584 loss_att 7.472326 loss_ctc 7.275059 loss_rnnt 6.617132 hw_loss 0.078450 history loss 7.114331 rank 4
2023-02-22 10:27:19,079 DEBUG CV Batch 17/1200 loss 6.842584 loss_att 7.472326 loss_ctc 7.275059 loss_rnnt 6.617132 hw_loss 0.078450 history loss 7.114331 rank 7
2023-02-22 10:27:19,726 DEBUG CV Batch 17/1200 loss 6.842584 loss_att 7.472326 loss_ctc 7.275059 loss_rnnt 6.617132 hw_loss 0.078450 history loss 7.114331 rank 5
2023-02-22 10:27:20,698 DEBUG CV Batch 17/1200 loss 6.842584 loss_att 7.472326 loss_ctc 7.275059 loss_rnnt 6.617132 hw_loss 0.078450 history loss 7.114331 rank 2
2023-02-22 10:27:20,864 DEBUG CV Batch 17/1200 loss 6.842584 loss_att 7.472326 loss_ctc 7.275059 loss_rnnt 6.617132 hw_loss 0.078450 history loss 7.114331 rank 3
2023-02-22 10:27:21,734 DEBUG CV Batch 17/1200 loss 6.842584 loss_att 7.472326 loss_ctc 7.275059 loss_rnnt 6.617132 hw_loss 0.078450 history loss 7.114331 rank 1
2023-02-22 10:27:22,203 DEBUG CV Batch 17/1200 loss 6.842584 loss_att 7.472326 loss_ctc 7.275059 loss_rnnt 6.617132 hw_loss 0.078450 history loss 7.114331 rank 6
2023-02-22 10:27:30,591 DEBUG CV Batch 17/1300 loss 5.624324 loss_att 6.180892 loss_ctc 7.318376 loss_rnnt 5.217818 hw_loss 0.129971 history loss 7.436312 rank 0
2023-02-22 10:27:30,859 DEBUG CV Batch 17/1300 loss 5.624324 loss_att 6.180892 loss_ctc 7.318376 loss_rnnt 5.217818 hw_loss 0.129971 history loss 7.436312 rank 4
2023-02-22 10:27:30,943 DEBUG CV Batch 17/1300 loss 5.624324 loss_att 6.180892 loss_ctc 7.318376 loss_rnnt 5.217818 hw_loss 0.129971 history loss 7.436312 rank 7
2023-02-22 10:27:31,749 DEBUG CV Batch 17/1300 loss 5.624324 loss_att 6.180892 loss_ctc 7.318376 loss_rnnt 5.217818 hw_loss 0.129971 history loss 7.436312 rank 5
2023-02-22 10:27:33,359 DEBUG CV Batch 17/1300 loss 5.624324 loss_att 6.180892 loss_ctc 7.318376 loss_rnnt 5.217818 hw_loss 0.129971 history loss 7.436312 rank 3
2023-02-22 10:27:33,514 DEBUG CV Batch 17/1300 loss 5.624324 loss_att 6.180892 loss_ctc 7.318376 loss_rnnt 5.217818 hw_loss 0.129971 history loss 7.436312 rank 2
2023-02-22 10:27:33,705 DEBUG CV Batch 17/1300 loss 5.624324 loss_att 6.180892 loss_ctc 7.318376 loss_rnnt 5.217818 hw_loss 0.129971 history loss 7.436312 rank 1
2023-02-22 10:27:34,323 DEBUG CV Batch 17/1300 loss 5.624324 loss_att 6.180892 loss_ctc 7.318376 loss_rnnt 5.217818 hw_loss 0.129971 history loss 7.436312 rank 6
2023-02-22 10:27:41,802 DEBUG CV Batch 17/1400 loss 11.559182 loss_att 36.630692 loss_ctc 6.607142 loss_rnnt 7.141754 hw_loss 0.118871 history loss 7.786149 rank 0
2023-02-22 10:27:42,063 DEBUG CV Batch 17/1400 loss 11.559182 loss_att 36.630692 loss_ctc 6.607142 loss_rnnt 7.141754 hw_loss 0.118871 history loss 7.786149 rank 4
2023-02-22 10:27:42,092 DEBUG CV Batch 17/1400 loss 11.559182 loss_att 36.630692 loss_ctc 6.607142 loss_rnnt 7.141754 hw_loss 0.118871 history loss 7.786149 rank 7
2023-02-22 10:27:42,988 DEBUG CV Batch 17/1400 loss 11.559182 loss_att 36.630692 loss_ctc 6.607142 loss_rnnt 7.141754 hw_loss 0.118871 history loss 7.786149 rank 5
2023-02-22 10:27:44,742 DEBUG CV Batch 17/1400 loss 11.559182 loss_att 36.630692 loss_ctc 6.607142 loss_rnnt 7.141754 hw_loss 0.118871 history loss 7.786149 rank 3
2023-02-22 10:27:44,982 DEBUG CV Batch 17/1400 loss 11.559182 loss_att 36.630692 loss_ctc 6.607142 loss_rnnt 7.141754 hw_loss 0.118871 history loss 7.786149 rank 1
2023-02-22 10:27:45,141 DEBUG CV Batch 17/1400 loss 11.559182 loss_att 36.630692 loss_ctc 6.607142 loss_rnnt 7.141754 hw_loss 0.118871 history loss 7.786149 rank 2
2023-02-22 10:27:45,706 DEBUG CV Batch 17/1400 loss 11.559182 loss_att 36.630692 loss_ctc 6.607142 loss_rnnt 7.141754 hw_loss 0.118871 history loss 7.786149 rank 6
2023-02-22 10:27:53,217 DEBUG CV Batch 17/1500 loss 7.710301 loss_att 8.656987 loss_ctc 8.144397 loss_rnnt 7.350273 hw_loss 0.211522 history loss 7.611685 rank 0
2023-02-22 10:27:53,492 DEBUG CV Batch 17/1500 loss 7.710301 loss_att 8.656987 loss_ctc 8.144397 loss_rnnt 7.350273 hw_loss 0.211522 history loss 7.611685 rank 4
2023-02-22 10:27:53,613 DEBUG CV Batch 17/1500 loss 7.710301 loss_att 8.656987 loss_ctc 8.144397 loss_rnnt 7.350273 hw_loss 0.211522 history loss 7.611685 rank 7
2023-02-22 10:27:54,291 DEBUG CV Batch 17/1500 loss 7.710301 loss_att 8.656987 loss_ctc 8.144397 loss_rnnt 7.350273 hw_loss 0.211522 history loss 7.611685 rank 5
2023-02-22 10:27:56,421 DEBUG CV Batch 17/1500 loss 7.710301 loss_att 8.656987 loss_ctc 8.144397 loss_rnnt 7.350273 hw_loss 0.211522 history loss 7.611685 rank 3
2023-02-22 10:27:56,569 DEBUG CV Batch 17/1500 loss 7.710301 loss_att 8.656987 loss_ctc 8.144397 loss_rnnt 7.350273 hw_loss 0.211522 history loss 7.611685 rank 1
2023-02-22 10:27:56,743 DEBUG CV Batch 17/1500 loss 7.710301 loss_att 8.656987 loss_ctc 8.144397 loss_rnnt 7.350273 hw_loss 0.211522 history loss 7.611685 rank 2
2023-02-22 10:27:57,256 DEBUG CV Batch 17/1500 loss 7.710301 loss_att 8.656987 loss_ctc 8.144397 loss_rnnt 7.350273 hw_loss 0.211522 history loss 7.611685 rank 6
2023-02-22 10:28:06,175 DEBUG CV Batch 17/1600 loss 8.785854 loss_att 14.348015 loss_ctc 12.179014 loss_rnnt 7.098982 hw_loss 0.228784 history loss 7.541542 rank 0
2023-02-22 10:28:06,496 DEBUG CV Batch 17/1600 loss 8.785854 loss_att 14.348015 loss_ctc 12.179014 loss_rnnt 7.098982 hw_loss 0.228784 history loss 7.541542 rank 7
2023-02-22 10:28:06,619 DEBUG CV Batch 17/1600 loss 8.785854 loss_att 14.348015 loss_ctc 12.179014 loss_rnnt 7.098982 hw_loss 0.228784 history loss 7.541542 rank 4
2023-02-22 10:28:07,325 DEBUG CV Batch 17/1600 loss 8.785854 loss_att 14.348015 loss_ctc 12.179014 loss_rnnt 7.098982 hw_loss 0.228784 history loss 7.541542 rank 5
2023-02-22 10:28:09,526 DEBUG CV Batch 17/1600 loss 8.785854 loss_att 14.348015 loss_ctc 12.179014 loss_rnnt 7.098982 hw_loss 0.228784 history loss 7.541542 rank 1
2023-02-22 10:28:09,780 DEBUG CV Batch 17/1600 loss 8.785854 loss_att 14.348015 loss_ctc 12.179014 loss_rnnt 7.098982 hw_loss 0.228784 history loss 7.541542 rank 2
2023-02-22 10:28:10,332 DEBUG CV Batch 17/1600 loss 8.785854 loss_att 14.348015 loss_ctc 12.179014 loss_rnnt 7.098982 hw_loss 0.228784 history loss 7.541542 rank 3
2023-02-22 10:28:10,370 DEBUG CV Batch 17/1600 loss 8.785854 loss_att 14.348015 loss_ctc 12.179014 loss_rnnt 7.098982 hw_loss 0.228784 history loss 7.541542 rank 6
2023-02-22 10:28:18,548 DEBUG CV Batch 17/1700 loss 11.861420 loss_att 10.095324 loss_ctc 16.110687 loss_rnnt 11.567101 hw_loss 0.151817 history loss 7.450301 rank 0
2023-02-22 10:28:18,709 DEBUG CV Batch 17/1700 loss 11.861420 loss_att 10.095324 loss_ctc 16.110687 loss_rnnt 11.567101 hw_loss 0.151817 history loss 7.450301 rank 7
2023-02-22 10:28:18,885 DEBUG CV Batch 17/1700 loss 11.861420 loss_att 10.095324 loss_ctc 16.110687 loss_rnnt 11.567101 hw_loss 0.151817 history loss 7.450301 rank 4
2023-02-22 10:28:19,756 DEBUG CV Batch 17/1700 loss 11.861420 loss_att 10.095324 loss_ctc 16.110687 loss_rnnt 11.567101 hw_loss 0.151817 history loss 7.450301 rank 5
2023-02-22 10:28:21,792 DEBUG CV Batch 17/1700 loss 11.861420 loss_att 10.095324 loss_ctc 16.110687 loss_rnnt 11.567101 hw_loss 0.151817 history loss 7.450301 rank 1
2023-02-22 10:28:22,162 DEBUG CV Batch 17/1700 loss 11.861420 loss_att 10.095324 loss_ctc 16.110687 loss_rnnt 11.567101 hw_loss 0.151817 history loss 7.450301 rank 2
2023-02-22 10:28:22,747 DEBUG CV Batch 17/1700 loss 11.861420 loss_att 10.095324 loss_ctc 16.110687 loss_rnnt 11.567101 hw_loss 0.151817 history loss 7.450301 rank 6
2023-02-22 10:28:22,900 DEBUG CV Batch 17/1700 loss 11.861420 loss_att 10.095324 loss_ctc 16.110687 loss_rnnt 11.567101 hw_loss 0.151817 history loss 7.450301 rank 3
2023-02-22 10:28:27,518 INFO Epoch 17 CV info cv_loss 7.417028798780822
2023-02-22 10:28:27,519 INFO Checkpoint: save to checkpoint exp/2_21_rnnt_bias_loss_2_class_1word_finetune/17.pt
2023-02-22 10:28:27,669 INFO Epoch 17 CV info cv_loss 7.417028799246012
2023-02-22 10:28:27,670 INFO Epoch 18 TRAIN info lr 0.0004080769341288056
2023-02-22 10:28:27,673 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 10:28:27,869 INFO Epoch 17 CV info cv_loss 7.417028799211553
2023-02-22 10:28:27,870 INFO Epoch 18 TRAIN info lr 0.0004080769341288056
2023-02-22 10:28:27,874 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 10:28:28,250 INFO Epoch 18 TRAIN info lr 0.0004081041191408688
2023-02-22 10:28:28,254 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 10:28:28,880 INFO Epoch 17 CV info cv_loss 7.417028799754275
2023-02-22 10:28:28,883 INFO Epoch 18 TRAIN info lr 0.0004080946037686553
2023-02-22 10:28:28,887 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 10:28:30,795 INFO Epoch 17 CV info cv_loss 7.4170287988497385
2023-02-22 10:28:30,796 INFO Epoch 18 TRAIN info lr 0.00040811363517871137
2023-02-22 10:28:30,799 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 10:28:31,812 INFO Epoch 17 CV info cv_loss 7.417028799581982
2023-02-22 10:28:31,813 INFO Epoch 18 TRAIN info lr 0.00040809188521312754
2023-02-22 10:28:31,816 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 10:28:32,020 INFO Epoch 17 CV info cv_loss 7.417028799840422
2023-02-22 10:28:32,021 INFO Epoch 18 TRAIN info lr 0.00040801578770927955
2023-02-22 10:28:32,024 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 10:28:32,220 INFO Epoch 17 CV info cv_loss 7.417028799246012
2023-02-22 10:28:32,221 INFO Epoch 18 TRAIN info lr 0.00040803480809423773
2023-02-22 10:28:32,225 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 10:29:45,297 DEBUG TRAIN Batch 18/0 loss 12.452722 loss_att 11.307096 loss_ctc 13.814173 loss_rnnt 12.404976 hw_loss 0.178769 lr 0.00040808 rank 4
2023-02-22 10:29:45,299 DEBUG TRAIN Batch 18/0 loss 8.541740 loss_att 8.379673 loss_ctc 11.082817 loss_rnnt 8.134294 hw_loss 0.189469 lr 0.00040809 rank 6
2023-02-22 10:29:45,302 DEBUG TRAIN Batch 18/0 loss 11.493190 loss_att 12.212924 loss_ctc 15.165172 loss_rnnt 10.743249 hw_loss 0.218243 lr 0.00040810 rank 0
2023-02-22 10:29:45,304 DEBUG TRAIN Batch 18/0 loss 12.465374 loss_att 10.098192 loss_ctc 14.650242 loss_rnnt 12.574602 hw_loss 0.136674 lr 0.00040808 rank 7
2023-02-22 10:29:45,312 DEBUG TRAIN Batch 18/0 loss 11.404656 loss_att 10.690063 loss_ctc 14.142220 loss_rnnt 11.061981 hw_loss 0.226100 lr 0.00040809 rank 5
2023-02-22 10:29:45,324 DEBUG TRAIN Batch 18/0 loss 8.721527 loss_att 8.516192 loss_ctc 11.519365 loss_rnnt 8.300035 hw_loss 0.167840 lr 0.00040801 rank 3
2023-02-22 10:29:45,331 DEBUG TRAIN Batch 18/0 loss 14.284255 loss_att 13.927225 loss_ctc 17.979797 loss_rnnt 13.785686 hw_loss 0.144820 lr 0.00040811 rank 1
2023-02-22 10:29:45,405 DEBUG TRAIN Batch 18/0 loss 11.897748 loss_att 11.855990 loss_ctc 14.287786 loss_rnnt 11.511595 hw_loss 0.142189 lr 0.00040803 rank 2
2023-02-22 10:30:59,618 DEBUG TRAIN Batch 18/100 loss 5.571211 loss_att 9.543112 loss_ctc 8.274182 loss_rnnt 4.318967 hw_loss 0.182751 lr 0.00040797 rank 0
2023-02-22 10:30:59,620 DEBUG TRAIN Batch 18/100 loss 12.813407 loss_att 13.438623 loss_ctc 16.676731 loss_rnnt 12.103117 hw_loss 0.131507 lr 0.00040788 rank 3
2023-02-22 10:30:59,620 DEBUG TRAIN Batch 18/100 loss 8.490907 loss_att 13.994038 loss_ctc 8.340672 loss_rnnt 7.341896 hw_loss 0.128280 lr 0.00040794 rank 7
2023-02-22 10:30:59,621 DEBUG TRAIN Batch 18/100 loss 11.359288 loss_att 14.620294 loss_ctc 18.878120 loss_rnnt 9.671616 hw_loss 0.061799 lr 0.00040795 rank 6
2023-02-22 10:30:59,622 DEBUG TRAIN Batch 18/100 loss 6.306547 loss_att 11.010712 loss_ctc 9.337813 loss_rnnt 4.961143 hw_loss 0.000754 lr 0.00040794 rank 4
2023-02-22 10:30:59,623 DEBUG TRAIN Batch 18/100 loss 3.263532 loss_att 5.774623 loss_ctc 2.199345 loss_rnnt 2.842297 hw_loss 0.114205 lr 0.00040796 rank 5
2023-02-22 10:30:59,626 DEBUG TRAIN Batch 18/100 loss 8.590830 loss_att 11.288896 loss_ctc 10.791214 loss_rnnt 7.725821 hw_loss 0.060020 lr 0.00040798 rank 1
2023-02-22 10:30:59,627 DEBUG TRAIN Batch 18/100 loss 5.835903 loss_att 11.346384 loss_ctc 7.110591 loss_rnnt 4.444654 hw_loss 0.223489 lr 0.00040790 rank 2
2023-02-22 10:32:13,926 DEBUG TRAIN Batch 18/200 loss 11.788860 loss_att 15.682930 loss_ctc 18.199635 loss_rnnt 10.069618 hw_loss 0.160608 lr 0.00040780 rank 7
2023-02-22 10:32:13,926 DEBUG TRAIN Batch 18/200 loss 12.535338 loss_att 16.118958 loss_ctc 19.023651 loss_rnnt 10.937021 hw_loss 0.030910 lr 0.00040783 rank 0
2023-02-22 10:32:13,927 DEBUG TRAIN Batch 18/200 loss 8.032517 loss_att 14.322670 loss_ctc 15.863432 loss_rnnt 5.712095 hw_loss 0.034256 lr 0.00040776 rank 2
2023-02-22 10:32:13,928 DEBUG TRAIN Batch 18/200 loss 6.688334 loss_att 10.484930 loss_ctc 9.229265 loss_rnnt 5.547067 hw_loss 0.080918 lr 0.00040780 rank 4
2023-02-22 10:32:13,929 DEBUG TRAIN Batch 18/200 loss 23.823776 loss_att 26.762676 loss_ctc 31.510681 loss_rnnt 22.128256 hw_loss 0.155286 lr 0.00040774 rank 3
2023-02-22 10:32:13,930 DEBUG TRAIN Batch 18/200 loss 7.033065 loss_att 10.314631 loss_ctc 9.672111 loss_rnnt 6.012141 hw_loss 0.023883 lr 0.00040782 rank 5
2023-02-22 10:32:13,932 DEBUG TRAIN Batch 18/200 loss 15.973843 loss_att 18.283195 loss_ctc 16.911142 loss_rnnt 15.373524 hw_loss 0.025265 lr 0.00040782 rank 6
2023-02-22 10:32:13,978 DEBUG TRAIN Batch 18/200 loss 3.544266 loss_att 6.334582 loss_ctc 4.710154 loss_rnnt 2.790774 hw_loss 0.074956 lr 0.00040784 rank 1
2023-02-22 10:33:29,661 DEBUG TRAIN Batch 18/300 loss 16.587507 loss_att 22.850426 loss_ctc 22.855015 loss_rnnt 14.376857 hw_loss 0.229496 lr 0.00040770 rank 0
2023-02-22 10:33:29,663 DEBUG TRAIN Batch 18/300 loss 9.717454 loss_att 13.132539 loss_ctc 12.828634 loss_rnnt 8.551004 hw_loss 0.128641 lr 0.00040767 rank 7
2023-02-22 10:33:29,664 DEBUG TRAIN Batch 18/300 loss 4.614368 loss_att 8.983774 loss_ctc 6.690338 loss_rnnt 3.404783 hw_loss 0.110453 lr 0.00040767 rank 4
2023-02-22 10:33:29,667 DEBUG TRAIN Batch 18/300 loss 8.067717 loss_att 11.426820 loss_ctc 9.375283 loss_rnnt 7.176820 hw_loss 0.083876 lr 0.00040761 rank 3
2023-02-22 10:33:29,667 DEBUG TRAIN Batch 18/300 loss 10.960513 loss_att 13.084688 loss_ctc 13.324151 loss_rnnt 10.174967 hw_loss 0.085423 lr 0.00040763 rank 2
2023-02-22 10:33:29,668 DEBUG TRAIN Batch 18/300 loss 7.362352 loss_att 11.474355 loss_ctc 11.123556 loss_rnnt 6.013455 hw_loss 0.046878 lr 0.00040769 rank 5
2023-02-22 10:33:29,668 DEBUG TRAIN Batch 18/300 loss 2.313560 loss_att 4.864656 loss_ctc 4.281266 loss_rnnt 1.446085 hw_loss 0.177927 lr 0.00040768 rank 6
2023-02-22 10:33:29,676 DEBUG TRAIN Batch 18/300 loss 6.995106 loss_att 8.912939 loss_ctc 8.571860 loss_rnnt 6.348960 hw_loss 0.098148 lr 0.00040771 rank 1
2023-02-22 10:34:46,158 DEBUG TRAIN Batch 18/400 loss 5.350771 loss_att 8.578796 loss_ctc 8.768290 loss_rnnt 4.172101 hw_loss 0.145118 lr 0.00040753 rank 7
2023-02-22 10:34:46,159 DEBUG TRAIN Batch 18/400 loss 15.543817 loss_att 17.219353 loss_ctc 20.456947 loss_rnnt 14.512572 hw_loss 0.076974 lr 0.00040753 rank 4
2023-02-22 10:34:46,159 DEBUG TRAIN Batch 18/400 loss 14.706769 loss_att 16.464819 loss_ctc 19.088257 loss_rnnt 13.706769 hw_loss 0.120359 lr 0.00040755 rank 5
2023-02-22 10:34:46,160 DEBUG TRAIN Batch 18/400 loss 5.326649 loss_att 7.774057 loss_ctc 6.327222 loss_rnnt 4.643635 hw_loss 0.112729 lr 0.00040749 rank 2
2023-02-22 10:34:46,163 DEBUG TRAIN Batch 18/400 loss 5.725335 loss_att 8.667403 loss_ctc 9.848253 loss_rnnt 4.557075 hw_loss 0.056484 lr 0.00040755 rank 6
2023-02-22 10:34:46,162 DEBUG TRAIN Batch 18/400 loss 9.248671 loss_att 11.186974 loss_ctc 12.976025 loss_rnnt 8.321287 hw_loss 0.080141 lr 0.00040756 rank 0
2023-02-22 10:34:46,164 DEBUG TRAIN Batch 18/400 loss 10.117524 loss_att 12.323954 loss_ctc 11.925738 loss_rnnt 9.416910 hw_loss 0.034188 lr 0.00040757 rank 1
2023-02-22 10:34:46,167 DEBUG TRAIN Batch 18/400 loss 17.717155 loss_att 21.359493 loss_ctc 24.503914 loss_rnnt 16.017059 hw_loss 0.125110 lr 0.00040747 rank 3
2023-02-22 10:36:00,638 DEBUG TRAIN Batch 18/500 loss 14.133508 loss_att 18.077353 loss_ctc 20.344263 loss_rnnt 12.487898 hw_loss 0.053888 lr 0.00040742 rank 5
2023-02-22 10:36:00,639 DEBUG TRAIN Batch 18/500 loss 11.228782 loss_att 13.594679 loss_ctc 14.674517 loss_rnnt 10.216214 hw_loss 0.149917 lr 0.00040740 rank 4
2023-02-22 10:36:00,639 DEBUG TRAIN Batch 18/500 loss 7.481961 loss_att 9.522925 loss_ctc 10.203265 loss_rnnt 6.682762 hw_loss 0.052810 lr 0.00040736 rank 2
2023-02-22 10:36:00,639 DEBUG TRAIN Batch 18/500 loss 5.666440 loss_att 7.207882 loss_ctc 9.337457 loss_rnnt 4.797944 hw_loss 0.132635 lr 0.00040742 rank 0
2023-02-22 10:36:00,642 DEBUG TRAIN Batch 18/500 loss 9.449392 loss_att 10.070064 loss_ctc 11.953333 loss_rnnt 8.941365 hw_loss 0.093813 lr 0.00040734 rank 3
2023-02-22 10:36:00,643 DEBUG TRAIN Batch 18/500 loss 5.848608 loss_att 9.854314 loss_ctc 9.274684 loss_rnnt 4.539212 hw_loss 0.096458 lr 0.00040740 rank 7
2023-02-22 10:36:00,647 DEBUG TRAIN Batch 18/500 loss 19.240782 loss_att 21.587790 loss_ctc 24.463261 loss_rnnt 18.032692 hw_loss 0.079421 lr 0.00040741 rank 6
2023-02-22 10:36:00,687 DEBUG TRAIN Batch 18/500 loss 7.295071 loss_att 9.366104 loss_ctc 10.424356 loss_rnnt 6.433623 hw_loss 0.056256 lr 0.00040743 rank 1
2023-02-22 10:37:15,873 DEBUG TRAIN Batch 18/600 loss 16.878542 loss_att 19.164148 loss_ctc 20.599127 loss_rnnt 15.844174 hw_loss 0.152191 lr 0.00040728 rank 5
2023-02-22 10:37:15,874 DEBUG TRAIN Batch 18/600 loss 7.304648 loss_att 9.460804 loss_ctc 10.819538 loss_rnnt 6.253699 hw_loss 0.283248 lr 0.00040726 rank 4
2023-02-22 10:37:15,881 DEBUG TRAIN Batch 18/600 loss 10.237758 loss_att 12.344852 loss_ctc 15.426455 loss_rnnt 9.091774 hw_loss 0.061385 lr 0.00040729 rank 0
2023-02-22 10:37:15,881 DEBUG TRAIN Batch 18/600 loss 3.703341 loss_att 7.121451 loss_ctc 6.911533 loss_rnnt 2.560122 hw_loss 0.059695 lr 0.00040722 rank 2
2023-02-22 10:37:15,883 DEBUG TRAIN Batch 18/600 loss 8.863210 loss_att 10.643728 loss_ctc 13.042893 loss_rnnt 7.825684 hw_loss 0.232745 lr 0.00040726 rank 7
2023-02-22 10:37:15,884 DEBUG TRAIN Batch 18/600 loss 10.850686 loss_att 12.327515 loss_ctc 13.072013 loss_rnnt 10.225062 hw_loss 0.063904 lr 0.00040728 rank 6
2023-02-22 10:37:15,886 DEBUG TRAIN Batch 18/600 loss 4.769122 loss_att 6.775187 loss_ctc 6.397683 loss_rnnt 4.035254 hw_loss 0.216586 lr 0.00040720 rank 3
2023-02-22 10:37:15,928 DEBUG TRAIN Batch 18/600 loss 6.830451 loss_att 9.267112 loss_ctc 11.601600 loss_rnnt 5.635960 hw_loss 0.133137 lr 0.00040730 rank 1
2023-02-22 10:38:34,838 DEBUG TRAIN Batch 18/700 loss 9.349891 loss_att 11.030333 loss_ctc 11.244682 loss_rnnt 8.726944 hw_loss 0.064162 lr 0.00040713 rank 4
2023-02-22 10:38:34,838 DEBUG TRAIN Batch 18/700 loss 8.678882 loss_att 12.657625 loss_ctc 12.135246 loss_rnnt 7.383172 hw_loss 0.073334 lr 0.00040713 rank 7
2023-02-22 10:38:34,840 DEBUG TRAIN Batch 18/700 loss 6.685426 loss_att 10.331545 loss_ctc 9.462535 loss_rnnt 5.544921 hw_loss 0.076875 lr 0.00040715 rank 0
2023-02-22 10:38:34,841 DEBUG TRAIN Batch 18/700 loss 9.911301 loss_att 15.858822 loss_ctc 17.034117 loss_rnnt 7.724813 hw_loss 0.088639 lr 0.00040709 rank 2
2023-02-22 10:38:34,841 DEBUG TRAIN Batch 18/700 loss 13.058718 loss_att 13.902310 loss_ctc 16.063629 loss_rnnt 12.434723 hw_loss 0.102416 lr 0.00040715 rank 5
2023-02-22 10:38:34,842 DEBUG TRAIN Batch 18/700 loss 13.388685 loss_att 12.824034 loss_ctc 18.051064 loss_rnnt 12.799260 hw_loss 0.151321 lr 0.00040714 rank 6
2023-02-22 10:38:34,841 DEBUG TRAIN Batch 18/700 loss 2.715854 loss_att 5.344985 loss_ctc 3.169456 loss_rnnt 2.110672 hw_loss 0.035390 lr 0.00040716 rank 1
2023-02-22 10:38:34,844 DEBUG TRAIN Batch 18/700 loss 6.249705 loss_att 12.773901 loss_ctc 8.118667 loss_rnnt 4.674402 hw_loss 0.039879 lr 0.00040707 rank 3
2023-02-22 10:39:50,598 DEBUG TRAIN Batch 18/800 loss 12.400226 loss_att 13.461752 loss_ctc 15.945902 loss_rnnt 11.618046 hw_loss 0.182097 lr 0.00040699 rank 4
2023-02-22 10:39:50,600 DEBUG TRAIN Batch 18/800 loss 6.912202 loss_att 12.751748 loss_ctc 9.106073 loss_rnnt 5.442715 hw_loss 0.016992 lr 0.00040699 rank 7
2023-02-22 10:39:50,606 DEBUG TRAIN Batch 18/800 loss 9.192947 loss_att 13.284918 loss_ctc 17.566092 loss_rnnt 7.223802 hw_loss 0.064374 lr 0.00040701 rank 5
2023-02-22 10:39:50,608 DEBUG TRAIN Batch 18/800 loss 9.140351 loss_att 15.039259 loss_ctc 12.518009 loss_rnnt 7.485971 hw_loss 0.045459 lr 0.00040703 rank 1
2023-02-22 10:39:50,611 DEBUG TRAIN Batch 18/800 loss 8.349318 loss_att 12.852848 loss_ctc 17.399031 loss_rnnt 6.148669 hw_loss 0.174963 lr 0.00040693 rank 3
2023-02-22 10:39:50,610 DEBUG TRAIN Batch 18/800 loss 6.784435 loss_att 11.731374 loss_ctc 8.974144 loss_rnnt 5.411722 hw_loss 0.171308 lr 0.00040702 rank 0
2023-02-22 10:39:50,615 DEBUG TRAIN Batch 18/800 loss 23.704731 loss_att 31.050129 loss_ctc 26.493170 loss_rnnt 21.800558 hw_loss 0.118692 lr 0.00040701 rank 6
2023-02-22 10:39:50,613 DEBUG TRAIN Batch 18/800 loss 12.849048 loss_att 15.204638 loss_ctc 16.081482 loss_rnnt 11.923782 hw_loss 0.043417 lr 0.00040695 rank 2
2023-02-22 10:41:05,957 DEBUG TRAIN Batch 18/900 loss 12.511954 loss_att 16.219261 loss_ctc 19.485538 loss_rnnt 10.824238 hw_loss 0.030831 lr 0.00040687 rank 6
2023-02-22 10:41:05,957 DEBUG TRAIN Batch 18/900 loss 6.037567 loss_att 8.925169 loss_ctc 8.464592 loss_rnnt 5.049743 hw_loss 0.162564 lr 0.00040686 rank 4
2023-02-22 10:41:05,966 DEBUG TRAIN Batch 18/900 loss 9.155727 loss_att 10.654136 loss_ctc 10.011972 loss_rnnt 8.700769 hw_loss 0.077081 lr 0.00040680 rank 3
2023-02-22 10:41:05,966 DEBUG TRAIN Batch 18/900 loss 14.972471 loss_att 19.343256 loss_ctc 19.988739 loss_rnnt 13.389433 hw_loss 0.075087 lr 0.00040688 rank 5
2023-02-22 10:41:05,967 DEBUG TRAIN Batch 18/900 loss 6.413000 loss_att 11.781198 loss_ctc 9.316707 loss_rnnt 4.903724 hw_loss 0.090892 lr 0.00040689 rank 1
2023-02-22 10:41:05,990 DEBUG TRAIN Batch 18/900 loss 12.637513 loss_att 14.480249 loss_ctc 23.242220 loss_rnnt 10.802971 hw_loss 0.097564 lr 0.00040686 rank 7
2023-02-22 10:41:06,000 DEBUG TRAIN Batch 18/900 loss 10.333428 loss_att 14.247120 loss_ctc 17.256290 loss_rnnt 8.613600 hw_loss 0.026328 lr 0.00040688 rank 0
2023-02-22 10:41:06,015 DEBUG TRAIN Batch 18/900 loss 10.849641 loss_att 11.638750 loss_ctc 17.334524 loss_rnnt 9.680161 hw_loss 0.275638 lr 0.00040682 rank 2
2023-02-22 10:42:21,919 DEBUG TRAIN Batch 18/1000 loss 11.257973 loss_att 14.490108 loss_ctc 14.070527 loss_rnnt 10.192995 hw_loss 0.081645 lr 0.00040672 rank 7
2023-02-22 10:42:21,922 DEBUG TRAIN Batch 18/1000 loss 23.890158 loss_att 26.632616 loss_ctc 29.549389 loss_rnnt 22.540012 hw_loss 0.088294 lr 0.00040672 rank 4
2023-02-22 10:42:21,923 DEBUG TRAIN Batch 18/1000 loss 11.356174 loss_att 15.115604 loss_ctc 15.017171 loss_rnnt 10.044339 hw_loss 0.134655 lr 0.00040674 rank 5
2023-02-22 10:42:21,923 DEBUG TRAIN Batch 18/1000 loss 16.921373 loss_att 17.997822 loss_ctc 23.309383 loss_rnnt 15.775835 hw_loss 0.147212 lr 0.00040674 rank 6
2023-02-22 10:42:21,926 DEBUG TRAIN Batch 18/1000 loss 6.359492 loss_att 10.300448 loss_ctc 12.738475 loss_rnnt 4.700945 hw_loss 0.037170 lr 0.00040676 rank 1
2023-02-22 10:42:21,927 DEBUG TRAIN Batch 18/1000 loss 13.467362 loss_att 14.286699 loss_ctc 19.618053 loss_rnnt 12.462216 hw_loss 0.039723 lr 0.00040675 rank 0
2023-02-22 10:42:21,931 DEBUG TRAIN Batch 18/1000 loss 9.502012 loss_att 10.424026 loss_ctc 11.172731 loss_rnnt 9.054689 hw_loss 0.075294 lr 0.00040668 rank 2
2023-02-22 10:42:21,935 DEBUG TRAIN Batch 18/1000 loss 12.248224 loss_att 17.754278 loss_ctc 15.220761 loss_rnnt 10.700635 hw_loss 0.093826 lr 0.00040666 rank 3
2023-02-22 10:43:38,311 DEBUG TRAIN Batch 18/1100 loss 7.028684 loss_att 8.548034 loss_ctc 7.863796 loss_rnnt 6.513471 hw_loss 0.187490 lr 0.00040659 rank 7
2023-02-22 10:43:38,318 DEBUG TRAIN Batch 18/1100 loss 13.585375 loss_att 17.421661 loss_ctc 19.997837 loss_rnnt 11.962891 hw_loss 0.000433 lr 0.00040661 rank 5
2023-02-22 10:43:38,319 DEBUG TRAIN Batch 18/1100 loss 6.147449 loss_att 8.637217 loss_ctc 7.165978 loss_rnnt 5.480434 hw_loss 0.062357 lr 0.00040659 rank 4
2023-02-22 10:43:38,319 DEBUG TRAIN Batch 18/1100 loss 13.092158 loss_att 15.836237 loss_ctc 22.786739 loss_rnnt 11.223475 hw_loss 0.051105 lr 0.00040655 rank 2
2023-02-22 10:43:38,320 DEBUG TRAIN Batch 18/1100 loss 10.774577 loss_att 12.781405 loss_ctc 13.477810 loss_rnnt 9.890339 hw_loss 0.229577 lr 0.00040662 rank 0
2023-02-22 10:43:38,321 DEBUG TRAIN Batch 18/1100 loss 8.089338 loss_att 10.210467 loss_ctc 13.746504 loss_rnnt 6.856733 hw_loss 0.101419 lr 0.00040663 rank 1
2023-02-22 10:43:38,322 DEBUG TRAIN Batch 18/1100 loss 8.405909 loss_att 9.734043 loss_ctc 8.304830 loss_rnnt 8.079351 hw_loss 0.139513 lr 0.00040653 rank 3
2023-02-22 10:43:38,322 DEBUG TRAIN Batch 18/1100 loss 9.472337 loss_att 12.103236 loss_ctc 11.552928 loss_rnnt 8.601848 hw_loss 0.125433 lr 0.00040660 rank 6
2023-02-22 10:44:53,570 DEBUG TRAIN Batch 18/1200 loss 7.589930 loss_att 11.453479 loss_ctc 8.915987 loss_rnnt 6.586370 hw_loss 0.101330 lr 0.00040647 rank 5
2023-02-22 10:44:53,571 DEBUG TRAIN Batch 18/1200 loss 14.090390 loss_att 16.519531 loss_ctc 18.994659 loss_rnnt 12.894051 hw_loss 0.106142 lr 0.00040648 rank 0
2023-02-22 10:44:53,574 DEBUG TRAIN Batch 18/1200 loss 15.811404 loss_att 19.441629 loss_ctc 20.166477 loss_rnnt 14.455071 hw_loss 0.093019 lr 0.00040647 rank 6
2023-02-22 10:44:53,576 DEBUG TRAIN Batch 18/1200 loss 15.792819 loss_att 17.840153 loss_ctc 25.890509 loss_rnnt 14.005888 hw_loss 0.058325 lr 0.00040645 rank 7
2023-02-22 10:44:53,576 DEBUG TRAIN Batch 18/1200 loss 6.762999 loss_att 8.616175 loss_ctc 8.827093 loss_rnnt 6.026962 hw_loss 0.169105 lr 0.00040641 rank 2
2023-02-22 10:44:53,577 DEBUG TRAIN Batch 18/1200 loss 13.947709 loss_att 15.647985 loss_ctc 22.289206 loss_rnnt 12.477893 hw_loss 0.032928 lr 0.00040645 rank 4
2023-02-22 10:44:53,579 DEBUG TRAIN Batch 18/1200 loss 5.772914 loss_att 8.016467 loss_ctc 7.379628 loss_rnnt 5.042064 hw_loss 0.127332 lr 0.00040649 rank 1
2023-02-22 10:44:53,583 DEBUG TRAIN Batch 18/1200 loss 11.014785 loss_att 15.380896 loss_ctc 18.316542 loss_rnnt 9.097709 hw_loss 0.131787 lr 0.00040639 rank 3
2023-02-22 10:46:08,896 DEBUG TRAIN Batch 18/1300 loss 13.922950 loss_att 11.602480 loss_ctc 16.959740 loss_rnnt 13.899952 hw_loss 0.154100 lr 0.00040632 rank 4
2023-02-22 10:46:08,896 DEBUG TRAIN Batch 18/1300 loss 8.039590 loss_att 11.100422 loss_ctc 13.517543 loss_rnnt 6.684181 hw_loss 0.024092 lr 0.00040628 rank 2
2023-02-22 10:46:08,897 DEBUG TRAIN Batch 18/1300 loss 4.946196 loss_att 9.626893 loss_ctc 7.046422 loss_rnnt 3.707345 hw_loss 0.042525 lr 0.00040635 rank 0
2023-02-22 10:46:08,897 DEBUG TRAIN Batch 18/1300 loss 3.467266 loss_att 5.504892 loss_ctc 4.346880 loss_rnnt 2.903914 hw_loss 0.072271 lr 0.00040634 rank 5
2023-02-22 10:46:08,899 DEBUG TRAIN Batch 18/1300 loss 16.201899 loss_att 15.008404 loss_ctc 18.702208 loss_rnnt 16.095753 hw_loss 0.021504 lr 0.00040632 rank 7
2023-02-22 10:46:08,898 DEBUG TRAIN Batch 18/1300 loss 10.253011 loss_att 12.945457 loss_ctc 13.993471 loss_rnnt 9.143373 hw_loss 0.135788 lr 0.00040636 rank 1
2023-02-22 10:46:08,899 DEBUG TRAIN Batch 18/1300 loss 13.699082 loss_att 15.662205 loss_ctc 15.546285 loss_rnnt 12.973226 hw_loss 0.163008 lr 0.00040633 rank 6
2023-02-22 10:46:08,906 DEBUG TRAIN Batch 18/1300 loss 8.371943 loss_att 8.502096 loss_ctc 9.474240 loss_rnnt 8.100895 hw_loss 0.183835 lr 0.00040626 rank 3
2023-02-22 10:47:25,872 DEBUG TRAIN Batch 18/1400 loss 17.093407 loss_att 19.600943 loss_ctc 21.256376 loss_rnnt 15.975109 hw_loss 0.115737 lr 0.00040619 rank 7
2023-02-22 10:47:25,874 DEBUG TRAIN Batch 18/1400 loss 6.835011 loss_att 10.531986 loss_ctc 10.036317 loss_rnnt 5.575544 hw_loss 0.174811 lr 0.00040620 rank 5
2023-02-22 10:47:25,875 DEBUG TRAIN Batch 18/1400 loss 3.542005 loss_att 5.827123 loss_ctc 4.446109 loss_rnnt 2.906131 hw_loss 0.109317 lr 0.00040619 rank 4
2023-02-22 10:47:25,879 DEBUG TRAIN Batch 18/1400 loss 9.587937 loss_att 13.585740 loss_ctc 19.048092 loss_rnnt 7.476650 hw_loss 0.094451 lr 0.00040621 rank 0
2023-02-22 10:47:25,879 DEBUG TRAIN Batch 18/1400 loss 18.828175 loss_att 18.551102 loss_ctc 22.877119 loss_rnnt 18.272535 hw_loss 0.133491 lr 0.00040622 rank 1
2023-02-22 10:47:25,880 DEBUG TRAIN Batch 18/1400 loss 8.466194 loss_att 11.380712 loss_ctc 11.095793 loss_rnnt 7.472307 hw_loss 0.113198 lr 0.00040620 rank 6
2023-02-22 10:47:25,882 DEBUG TRAIN Batch 18/1400 loss 7.292457 loss_att 8.751278 loss_ctc 12.619226 loss_rnnt 6.235284 hw_loss 0.103448 lr 0.00040613 rank 3
2023-02-22 10:47:25,886 DEBUG TRAIN Batch 18/1400 loss 4.265273 loss_att 6.873859 loss_ctc 5.838992 loss_rnnt 3.502656 hw_loss 0.058256 lr 0.00040614 rank 2
2023-02-22 10:48:41,399 DEBUG TRAIN Batch 18/1500 loss 10.389979 loss_att 11.412453 loss_ctc 14.814068 loss_rnnt 9.557913 hw_loss 0.070674 lr 0.00040605 rank 7
2023-02-22 10:48:41,401 DEBUG TRAIN Batch 18/1500 loss 9.303637 loss_att 12.694868 loss_ctc 10.016480 loss_rnnt 8.493259 hw_loss 0.069535 lr 0.00040605 rank 4
2023-02-22 10:48:41,401 DEBUG TRAIN Batch 18/1500 loss 10.174313 loss_att 10.761131 loss_ctc 11.469944 loss_rnnt 9.843699 hw_loss 0.075935 lr 0.00040607 rank 5
2023-02-22 10:48:41,405 DEBUG TRAIN Batch 18/1500 loss 7.603265 loss_att 10.396547 loss_ctc 12.067866 loss_rnnt 6.335838 hw_loss 0.212794 lr 0.00040608 rank 0
2023-02-22 10:48:41,405 DEBUG TRAIN Batch 18/1500 loss 16.068317 loss_att 17.104668 loss_ctc 19.908079 loss_rnnt 15.347605 hw_loss 0.002765 lr 0.00040599 rank 3
2023-02-22 10:48:41,407 DEBUG TRAIN Batch 18/1500 loss 11.243361 loss_att 14.006198 loss_ctc 12.726162 loss_rnnt 10.460383 hw_loss 0.061315 lr 0.00040609 rank 1
2023-02-22 10:48:41,415 DEBUG TRAIN Batch 18/1500 loss 4.609933 loss_att 6.861494 loss_ctc 7.200600 loss_rnnt 3.795145 hw_loss 0.035728 lr 0.00040601 rank 2
2023-02-22 10:48:41,448 DEBUG TRAIN Batch 18/1500 loss 11.149195 loss_att 13.957602 loss_ctc 16.623692 loss_rnnt 9.783105 hw_loss 0.139642 lr 0.00040607 rank 6
2023-02-22 10:49:56,353 DEBUG TRAIN Batch 18/1600 loss 6.402692 loss_att 9.480892 loss_ctc 9.487748 loss_rnnt 5.334880 hw_loss 0.076558 lr 0.00040592 rank 4
2023-02-22 10:49:56,358 DEBUG TRAIN Batch 18/1600 loss 10.209124 loss_att 15.092262 loss_ctc 17.978424 loss_rnnt 8.126839 hw_loss 0.130781 lr 0.00040594 rank 0
2023-02-22 10:49:56,358 DEBUG TRAIN Batch 18/1600 loss 21.184860 loss_att 24.728848 loss_ctc 29.343515 loss_rnnt 19.312429 hw_loss 0.142148 lr 0.00040594 rank 5
2023-02-22 10:49:56,359 DEBUG TRAIN Batch 18/1600 loss 6.330865 loss_att 10.021932 loss_ctc 10.832497 loss_rnnt 4.949202 hw_loss 0.081063 lr 0.00040588 rank 2
2023-02-22 10:49:56,363 DEBUG TRAIN Batch 18/1600 loss 13.276670 loss_att 15.961199 loss_ctc 15.685135 loss_rnnt 12.353085 hw_loss 0.122907 lr 0.00040592 rank 7
2023-02-22 10:49:56,363 DEBUG TRAIN Batch 18/1600 loss 5.775468 loss_att 8.727006 loss_ctc 9.364676 loss_rnnt 4.622879 hw_loss 0.156975 lr 0.00040586 rank 3
2023-02-22 10:49:56,363 DEBUG TRAIN Batch 18/1600 loss 16.620768 loss_att 15.373506 loss_ctc 28.359280 loss_rnnt 15.248283 hw_loss 0.106504 lr 0.00040595 rank 1
2023-02-22 10:49:56,366 DEBUG TRAIN Batch 18/1600 loss 14.263476 loss_att 19.433006 loss_ctc 15.031428 loss_rnnt 13.003160 hw_loss 0.232527 lr 0.00040593 rank 6
2023-02-22 10:51:11,361 DEBUG TRAIN Batch 18/1700 loss 10.993996 loss_att 17.366440 loss_ctc 14.459552 loss_rnnt 9.201988 hw_loss 0.103958 lr 0.00040581 rank 0
2023-02-22 10:51:11,364 DEBUG TRAIN Batch 18/1700 loss 11.634267 loss_att 15.246510 loss_ctc 15.224609 loss_rnnt 10.355879 hw_loss 0.144802 lr 0.00040580 rank 5
2023-02-22 10:51:11,364 DEBUG TRAIN Batch 18/1700 loss 3.457080 loss_att 6.450271 loss_ctc 5.460919 loss_rnnt 2.532520 hw_loss 0.110142 lr 0.00040574 rank 2
2023-02-22 10:51:11,367 DEBUG TRAIN Batch 18/1700 loss 8.922715 loss_att 13.475700 loss_ctc 10.606684 loss_rnnt 7.767716 hw_loss 0.037262 lr 0.00040578 rank 4
2023-02-22 10:51:11,368 DEBUG TRAIN Batch 18/1700 loss 15.811604 loss_att 17.326378 loss_ctc 18.767977 loss_rnnt 15.061058 hw_loss 0.100141 lr 0.00040572 rank 3
2023-02-22 10:51:11,369 DEBUG TRAIN Batch 18/1700 loss 14.244471 loss_att 16.817822 loss_ctc 20.034504 loss_rnnt 12.898999 hw_loss 0.110243 lr 0.00040578 rank 7
2023-02-22 10:51:11,373 DEBUG TRAIN Batch 18/1700 loss 8.844411 loss_att 12.659803 loss_ctc 13.702785 loss_rnnt 7.376989 hw_loss 0.106050 lr 0.00040580 rank 6
2023-02-22 10:51:11,392 DEBUG TRAIN Batch 18/1700 loss 13.570528 loss_att 14.078907 loss_ctc 14.698858 loss_rnnt 13.255093 hw_loss 0.118716 lr 0.00040582 rank 1
2023-02-22 10:52:28,669 DEBUG TRAIN Batch 18/1800 loss 5.302139 loss_att 7.717607 loss_ctc 7.437193 loss_rnnt 4.484590 hw_loss 0.093340 lr 0.00040567 rank 5
2023-02-22 10:52:28,672 DEBUG TRAIN Batch 18/1800 loss 9.383830 loss_att 9.378119 loss_ctc 10.963000 loss_rnnt 9.148653 hw_loss 0.048306 lr 0.00040568 rank 0
2023-02-22 10:52:28,674 DEBUG TRAIN Batch 18/1800 loss 8.857670 loss_att 12.846798 loss_ctc 15.320500 loss_rnnt 7.091188 hw_loss 0.200523 lr 0.00040565 rank 7
2023-02-22 10:52:28,675 DEBUG TRAIN Batch 18/1800 loss 12.063885 loss_att 12.422820 loss_ctc 14.953087 loss_rnnt 11.582011 hw_loss 0.046610 lr 0.00040559 rank 3
2023-02-22 10:52:28,675 DEBUG TRAIN Batch 18/1800 loss 6.678141 loss_att 10.711538 loss_ctc 10.540854 loss_rnnt 5.313831 hw_loss 0.079879 lr 0.00040567 rank 6
2023-02-22 10:52:28,678 DEBUG TRAIN Batch 18/1800 loss 10.215740 loss_att 13.494383 loss_ctc 13.703062 loss_rnnt 8.994816 hw_loss 0.187911 lr 0.00040565 rank 4
2023-02-22 10:52:28,679 DEBUG TRAIN Batch 18/1800 loss 5.843026 loss_att 8.320595 loss_ctc 10.321235 loss_rnnt 4.704319 hw_loss 0.086434 lr 0.00040561 rank 2
2023-02-22 10:52:28,681 DEBUG TRAIN Batch 18/1800 loss 8.404219 loss_att 10.056060 loss_ctc 10.188067 loss_rnnt 7.765752 hw_loss 0.131722 lr 0.00040569 rank 1
2023-02-22 10:53:44,669 DEBUG TRAIN Batch 18/1900 loss 10.286964 loss_att 10.289600 loss_ctc 13.682403 loss_rnnt 9.715443 hw_loss 0.221755 lr 0.00040554 rank 0
2023-02-22 10:53:44,672 DEBUG TRAIN Batch 18/1900 loss 7.405009 loss_att 8.892657 loss_ctc 10.231914 loss_rnnt 6.638814 hw_loss 0.172022 lr 0.00040552 rank 4
2023-02-22 10:53:44,673 DEBUG TRAIN Batch 18/1900 loss 10.601866 loss_att 10.384597 loss_ctc 14.572876 loss_rnnt 9.999947 hw_loss 0.217321 lr 0.00040548 rank 2
2023-02-22 10:53:44,676 DEBUG TRAIN Batch 18/1900 loss 19.979654 loss_att 24.337387 loss_ctc 25.402832 loss_rnnt 18.344620 hw_loss 0.075744 lr 0.00040552 rank 7
2023-02-22 10:53:44,677 DEBUG TRAIN Batch 18/1900 loss 12.428801 loss_att 13.897374 loss_ctc 20.244101 loss_rnnt 11.020029 hw_loss 0.136905 lr 0.00040553 rank 6
2023-02-22 10:53:44,677 DEBUG TRAIN Batch 18/1900 loss 10.449472 loss_att 11.836274 loss_ctc 14.558951 loss_rnnt 9.551838 hw_loss 0.135645 lr 0.00040553 rank 5
2023-02-22 10:53:44,686 DEBUG TRAIN Batch 18/1900 loss 7.537969 loss_att 10.174969 loss_ctc 9.192301 loss_rnnt 6.702855 hw_loss 0.163379 lr 0.00040555 rank 1
2023-02-22 10:53:44,719 DEBUG TRAIN Batch 18/1900 loss 11.445974 loss_att 11.975112 loss_ctc 18.290958 loss_rnnt 10.380874 hw_loss 0.087392 lr 0.00040546 rank 3
2023-02-22 10:54:59,451 DEBUG TRAIN Batch 18/2000 loss 6.006306 loss_att 10.649704 loss_ctc 12.086143 loss_rnnt 4.245691 hw_loss 0.039919 lr 0.00040538 rank 4
2023-02-22 10:54:59,452 DEBUG TRAIN Batch 18/2000 loss 7.663925 loss_att 7.744621 loss_ctc 9.816468 loss_rnnt 7.230190 hw_loss 0.244855 lr 0.00040542 rank 1
2023-02-22 10:54:59,456 DEBUG TRAIN Batch 18/2000 loss 9.539501 loss_att 9.645623 loss_ctc 10.901039 loss_rnnt 9.210762 hw_loss 0.236207 lr 0.00040540 rank 6
2023-02-22 10:54:59,459 DEBUG TRAIN Batch 18/2000 loss 14.174283 loss_att 15.849358 loss_ctc 21.155554 loss_rnnt 12.867727 hw_loss 0.076319 lr 0.00040538 rank 7
2023-02-22 10:54:59,459 DEBUG TRAIN Batch 18/2000 loss 8.270750 loss_att 11.970915 loss_ctc 9.903345 loss_rnnt 7.282495 hw_loss 0.057267 lr 0.00040541 rank 0
2023-02-22 10:54:59,459 DEBUG TRAIN Batch 18/2000 loss 2.970994 loss_att 6.301601 loss_ctc 5.951916 loss_rnnt 1.907003 hw_loss 0.000776 lr 0.00040540 rank 5
2023-02-22 10:54:59,462 DEBUG TRAIN Batch 18/2000 loss 3.594543 loss_att 4.571350 loss_ctc 3.621557 loss_rnnt 3.340848 hw_loss 0.102622 lr 0.00040532 rank 3
2023-02-22 10:54:59,514 DEBUG TRAIN Batch 18/2000 loss 12.881580 loss_att 17.311260 loss_ctc 17.032623 loss_rnnt 11.426760 hw_loss 0.028897 lr 0.00040534 rank 2
2023-02-22 10:56:17,298 DEBUG TRAIN Batch 18/2100 loss 17.873497 loss_att 22.105881 loss_ctc 24.224777 loss_rnnt 16.132427 hw_loss 0.089542 lr 0.00040527 rank 5
2023-02-22 10:56:17,301 DEBUG TRAIN Batch 18/2100 loss 13.917144 loss_att 17.773890 loss_ctc 18.393703 loss_rnnt 12.511747 hw_loss 0.069700 lr 0.00040525 rank 7
2023-02-22 10:56:17,302 DEBUG TRAIN Batch 18/2100 loss 12.543191 loss_att 14.193853 loss_ctc 16.055521 loss_rnnt 11.630009 hw_loss 0.215137 lr 0.00040528 rank 0
2023-02-22 10:56:17,303 DEBUG TRAIN Batch 18/2100 loss 5.319442 loss_att 7.127009 loss_ctc 7.332583 loss_rnnt 4.689296 hw_loss 0.000401 lr 0.00040519 rank 3
2023-02-22 10:56:17,304 DEBUG TRAIN Batch 18/2100 loss 8.115837 loss_att 14.408022 loss_ctc 16.222012 loss_rnnt 5.736283 hw_loss 0.075549 lr 0.00040527 rank 6
2023-02-22 10:56:17,306 DEBUG TRAIN Batch 18/2100 loss 5.731587 loss_att 8.082203 loss_ctc 7.663062 loss_rnnt 4.966916 hw_loss 0.069408 lr 0.00040525 rank 4
2023-02-22 10:56:17,334 DEBUG TRAIN Batch 18/2100 loss 20.005856 loss_att 24.026348 loss_ctc 35.759956 loss_rnnt 17.048002 hw_loss 0.099766 lr 0.00040529 rank 1
2023-02-22 10:56:17,341 DEBUG TRAIN Batch 18/2100 loss 5.796649 loss_att 8.787837 loss_ctc 8.203247 loss_rnnt 4.754200 hw_loss 0.231246 lr 0.00040521 rank 2
2023-02-22 10:57:33,543 DEBUG TRAIN Batch 18/2200 loss 12.632827 loss_att 16.010132 loss_ctc 23.165474 loss_rnnt 10.474223 hw_loss 0.147732 lr 0.00040506 rank 3
2023-02-22 10:57:33,546 DEBUG TRAIN Batch 18/2200 loss 16.635227 loss_att 24.534988 loss_ctc 25.248930 loss_rnnt 13.843027 hw_loss 0.119538 lr 0.00040512 rank 4
2023-02-22 10:57:33,547 DEBUG TRAIN Batch 18/2200 loss 10.200627 loss_att 13.259813 loss_ctc 14.198792 loss_rnnt 8.958014 hw_loss 0.183165 lr 0.00040512 rank 7
2023-02-22 10:57:33,548 DEBUG TRAIN Batch 18/2200 loss 8.592759 loss_att 9.710501 loss_ctc 8.371286 loss_rnnt 8.354349 hw_loss 0.083235 lr 0.00040513 rank 6
2023-02-22 10:57:33,548 DEBUG TRAIN Batch 18/2200 loss 1.691858 loss_att 4.156231 loss_ctc 2.991017 loss_rnnt 1.000844 hw_loss 0.046721 lr 0.00040514 rank 5
2023-02-22 10:57:33,549 DEBUG TRAIN Batch 18/2200 loss 15.678356 loss_att 19.216095 loss_ctc 22.065781 loss_rnnt 14.103796 hw_loss 0.028791 lr 0.00040508 rank 2
2023-02-22 10:57:33,550 DEBUG TRAIN Batch 18/2200 loss 12.399574 loss_att 16.369463 loss_ctc 16.911867 loss_rnnt 10.952623 hw_loss 0.096250 lr 0.00040514 rank 0
2023-02-22 10:57:33,552 DEBUG TRAIN Batch 18/2200 loss 13.480811 loss_att 13.280464 loss_ctc 18.546700 loss_rnnt 12.793879 hw_loss 0.096657 lr 0.00040515 rank 1
2023-02-22 10:58:47,698 DEBUG TRAIN Batch 18/2300 loss 6.792294 loss_att 9.713758 loss_ctc 8.182282 loss_rnnt 6.022592 hw_loss 0.000144 lr 0.00040499 rank 4
2023-02-22 10:58:47,699 DEBUG TRAIN Batch 18/2300 loss 7.792268 loss_att 10.101645 loss_ctc 11.703283 loss_rnnt 6.757044 hw_loss 0.097273 lr 0.00040501 rank 0
2023-02-22 10:58:47,704 DEBUG TRAIN Batch 18/2300 loss 16.716213 loss_att 20.730150 loss_ctc 19.859385 loss_rnnt 15.434849 hw_loss 0.111544 lr 0.00040500 rank 5
2023-02-22 10:58:47,705 DEBUG TRAIN Batch 18/2300 loss 12.213742 loss_att 14.224180 loss_ctc 17.445601 loss_rnnt 11.047218 hw_loss 0.125352 lr 0.00040500 rank 6
2023-02-22 10:58:47,706 DEBUG TRAIN Batch 18/2300 loss 4.106988 loss_att 5.605563 loss_ctc 5.583240 loss_rnnt 3.527607 hw_loss 0.155310 lr 0.00040499 rank 7
2023-02-22 10:58:47,708 DEBUG TRAIN Batch 18/2300 loss 11.929618 loss_att 16.086178 loss_ctc 16.714302 loss_rnnt 10.407318 hw_loss 0.099431 lr 0.00040493 rank 3
2023-02-22 10:58:47,709 DEBUG TRAIN Batch 18/2300 loss 15.569890 loss_att 17.362980 loss_ctc 20.147461 loss_rnnt 14.518579 hw_loss 0.154405 lr 0.00040502 rank 1
2023-02-22 10:58:47,711 DEBUG TRAIN Batch 18/2300 loss 19.050333 loss_att 20.888229 loss_ctc 25.033976 loss_rnnt 17.810390 hw_loss 0.139770 lr 0.00040494 rank 2
2023-02-22 11:00:02,898 DEBUG TRAIN Batch 18/2400 loss 10.076324 loss_att 12.773161 loss_ctc 16.012037 loss_rnnt 8.723135 hw_loss 0.041986 lr 0.00040488 rank 0
2023-02-22 11:00:02,900 DEBUG TRAIN Batch 18/2400 loss 5.173635 loss_att 8.454349 loss_ctc 10.011846 loss_rnnt 3.853534 hw_loss 0.035370 lr 0.00040485 rank 4
2023-02-22 11:00:02,901 DEBUG TRAIN Batch 18/2400 loss 9.176994 loss_att 11.055819 loss_ctc 13.063841 loss_rnnt 8.257975 hw_loss 0.046892 lr 0.00040479 rank 3
2023-02-22 11:00:02,904 DEBUG TRAIN Batch 18/2400 loss 7.948073 loss_att 11.883192 loss_ctc 16.068659 loss_rnnt 6.020715 hw_loss 0.107979 lr 0.00040487 rank 5
2023-02-22 11:00:02,905 DEBUG TRAIN Batch 18/2400 loss 7.902780 loss_att 11.895602 loss_ctc 16.020763 loss_rnnt 5.954117 hw_loss 0.126936 lr 0.00040487 rank 6
2023-02-22 11:00:02,907 DEBUG TRAIN Batch 18/2400 loss 15.018090 loss_att 16.227173 loss_ctc 18.853634 loss_rnnt 14.206163 hw_loss 0.110069 lr 0.00040485 rank 7
2023-02-22 11:00:02,909 DEBUG TRAIN Batch 18/2400 loss 8.516871 loss_att 15.460415 loss_ctc 12.575484 loss_rnnt 6.483437 hw_loss 0.194208 lr 0.00040481 rank 2
2023-02-22 11:00:02,911 DEBUG TRAIN Batch 18/2400 loss 18.802565 loss_att 20.381849 loss_ctc 21.631016 loss_rnnt 18.027418 hw_loss 0.154055 lr 0.00040489 rank 1
2023-02-22 11:01:21,800 DEBUG TRAIN Batch 18/2500 loss 20.587267 loss_att 24.110012 loss_ctc 27.098888 loss_rnnt 18.925747 hw_loss 0.166412 lr 0.00040474 rank 5
2023-02-22 11:01:21,802 DEBUG TRAIN Batch 18/2500 loss 7.523751 loss_att 8.624640 loss_ctc 10.118670 loss_rnnt 6.807343 hw_loss 0.281703 lr 0.00040472 rank 7
2023-02-22 11:01:21,803 DEBUG TRAIN Batch 18/2500 loss 8.390888 loss_att 10.602940 loss_ctc 12.709576 loss_rnnt 7.354629 hw_loss 0.033796 lr 0.00040476 rank 1
2023-02-22 11:01:21,803 DEBUG TRAIN Batch 18/2500 loss 13.929359 loss_att 13.587590 loss_ctc 17.422272 loss_rnnt 13.466949 hw_loss 0.121957 lr 0.00040473 rank 6
2023-02-22 11:01:21,803 DEBUG TRAIN Batch 18/2500 loss 10.655358 loss_att 10.019503 loss_ctc 12.510148 loss_rnnt 10.419568 hw_loss 0.216854 lr 0.00040475 rank 0
2023-02-22 11:01:21,806 DEBUG TRAIN Batch 18/2500 loss 6.888436 loss_att 9.557027 loss_ctc 12.209321 loss_rnnt 5.567621 hw_loss 0.145586 lr 0.00040472 rank 4
2023-02-22 11:01:21,810 DEBUG TRAIN Batch 18/2500 loss 7.690414 loss_att 9.448869 loss_ctc 9.513297 loss_rnnt 7.025537 hw_loss 0.131504 lr 0.00040468 rank 2
2023-02-22 11:01:21,814 DEBUG TRAIN Batch 18/2500 loss 6.158606 loss_att 8.202965 loss_ctc 8.201371 loss_rnnt 5.432013 hw_loss 0.085034 lr 0.00040466 rank 3
2023-02-22 11:02:36,727 DEBUG TRAIN Batch 18/2600 loss 10.466929 loss_att 15.155038 loss_ctc 13.542799 loss_rnnt 9.097950 hw_loss 0.039828 lr 0.00040461 rank 0
2023-02-22 11:02:36,737 DEBUG TRAIN Batch 18/2600 loss 7.650482 loss_att 10.588981 loss_ctc 10.655018 loss_rnnt 6.596658 hw_loss 0.122849 lr 0.00040460 rank 5
2023-02-22 11:02:36,737 DEBUG TRAIN Batch 18/2600 loss 14.414115 loss_att 14.003466 loss_ctc 18.326801 loss_rnnt 13.865699 hw_loss 0.204102 lr 0.00040459 rank 4
2023-02-22 11:02:36,739 DEBUG TRAIN Batch 18/2600 loss 8.174151 loss_att 9.283695 loss_ctc 12.378639 loss_rnnt 7.354098 hw_loss 0.070397 lr 0.00040460 rank 6
2023-02-22 11:02:36,739 DEBUG TRAIN Batch 18/2600 loss 7.957075 loss_att 10.367048 loss_ctc 14.076702 loss_rnnt 6.626778 hw_loss 0.060660 lr 0.00040459 rank 7
2023-02-22 11:02:36,740 DEBUG TRAIN Batch 18/2600 loss 6.730241 loss_att 10.486665 loss_ctc 9.016811 loss_rnnt 5.626654 hw_loss 0.088924 lr 0.00040453 rank 3
2023-02-22 11:02:36,741 DEBUG TRAIN Batch 18/2600 loss 6.124250 loss_att 8.506107 loss_ctc 8.904552 loss_rnnt 5.235903 hw_loss 0.077380 lr 0.00040455 rank 2
2023-02-22 11:02:36,741 DEBUG TRAIN Batch 18/2600 loss 9.856091 loss_att 10.978674 loss_ctc 14.779189 loss_rnnt 8.850735 hw_loss 0.233303 lr 0.00040462 rank 1
2023-02-22 11:03:51,225 DEBUG TRAIN Batch 18/2700 loss 6.274938 loss_att 9.639232 loss_ctc 9.116081 loss_rnnt 5.182057 hw_loss 0.077256 lr 0.00040447 rank 5
2023-02-22 11:03:51,227 DEBUG TRAIN Batch 18/2700 loss 7.853487 loss_att 10.496366 loss_ctc 8.424816 loss_rnnt 7.204963 hw_loss 0.082071 lr 0.00040445 rank 4
2023-02-22 11:03:51,228 DEBUG TRAIN Batch 18/2700 loss 8.533649 loss_att 10.633962 loss_ctc 14.061705 loss_rnnt 7.376427 hw_loss 0.000163 lr 0.00040440 rank 3
2023-02-22 11:03:51,228 DEBUG TRAIN Batch 18/2700 loss 7.749680 loss_att 10.605370 loss_ctc 13.040706 loss_rnnt 6.400458 hw_loss 0.136151 lr 0.00040449 rank 1
2023-02-22 11:03:51,229 DEBUG TRAIN Batch 18/2700 loss 10.990794 loss_att 18.567268 loss_ctc 14.923805 loss_rnnt 8.930511 hw_loss 0.038599 lr 0.00040445 rank 7
2023-02-22 11:03:51,229 DEBUG TRAIN Batch 18/2700 loss 10.577467 loss_att 11.254393 loss_ctc 14.053004 loss_rnnt 9.906870 hw_loss 0.134638 lr 0.00040448 rank 0
2023-02-22 11:03:51,232 DEBUG TRAIN Batch 18/2700 loss 6.995361 loss_att 8.639155 loss_ctc 7.131465 loss_rnnt 6.622633 hw_loss 0.048415 lr 0.00040441 rank 2
2023-02-22 11:03:51,233 DEBUG TRAIN Batch 18/2700 loss 18.519051 loss_att 22.679861 loss_ctc 24.670364 loss_rnnt 16.753017 hw_loss 0.213179 lr 0.00040447 rank 6
2023-02-22 11:05:09,256 DEBUG TRAIN Batch 18/2800 loss 6.431041 loss_att 12.227629 loss_ctc 12.334864 loss_rnnt 4.447247 hw_loss 0.069938 lr 0.00040434 rank 5
2023-02-22 11:05:09,259 DEBUG TRAIN Batch 18/2800 loss 3.574592 loss_att 6.683070 loss_ctc 4.833662 loss_rnnt 2.758723 hw_loss 0.049307 lr 0.00040432 rank 4
2023-02-22 11:05:09,263 DEBUG TRAIN Batch 18/2800 loss 7.986476 loss_att 11.631255 loss_ctc 11.145519 loss_rnnt 6.775775 hw_loss 0.113511 lr 0.00040435 rank 0
2023-02-22 11:05:09,263 DEBUG TRAIN Batch 18/2800 loss 13.785819 loss_att 16.206575 loss_ctc 15.843645 loss_rnnt 12.946616 hw_loss 0.151265 lr 0.00040434 rank 6
2023-02-22 11:05:09,263 DEBUG TRAIN Batch 18/2800 loss 18.150438 loss_att 19.028639 loss_ctc 28.848431 loss_rnnt 16.464840 hw_loss 0.156673 lr 0.00040432 rank 7
2023-02-22 11:05:09,264 DEBUG TRAIN Batch 18/2800 loss 2.837891 loss_att 7.024292 loss_ctc 4.482873 loss_rnnt 1.740739 hw_loss 0.076015 lr 0.00040426 rank 3
2023-02-22 11:05:09,267 DEBUG TRAIN Batch 18/2800 loss 6.786866 loss_att 11.309175 loss_ctc 9.097998 loss_rnnt 5.552260 hw_loss 0.041238 lr 0.00040428 rank 2
2023-02-22 11:05:09,268 DEBUG TRAIN Batch 18/2800 loss 4.221351 loss_att 8.557373 loss_ctc 7.931273 loss_rnnt 2.837928 hw_loss 0.040429 lr 0.00040436 rank 1
2023-02-22 11:06:24,489 DEBUG TRAIN Batch 18/2900 loss 8.294722 loss_att 15.563453 loss_ctc 8.966406 loss_rnnt 6.663386 hw_loss 0.165057 lr 0.00040421 rank 5
2023-02-22 11:06:24,493 DEBUG TRAIN Batch 18/2900 loss 11.693221 loss_att 16.206991 loss_ctc 19.988686 loss_rnnt 9.630510 hw_loss 0.101053 lr 0.00040422 rank 0
2023-02-22 11:06:24,493 DEBUG TRAIN Batch 18/2900 loss 18.362022 loss_att 21.512091 loss_ctc 26.800266 loss_rnnt 16.544710 hw_loss 0.116619 lr 0.00040419 rank 7
2023-02-22 11:06:24,495 DEBUG TRAIN Batch 18/2900 loss 10.304880 loss_att 14.974131 loss_ctc 13.022821 loss_rnnt 8.934768 hw_loss 0.138508 lr 0.00040420 rank 6
2023-02-22 11:06:24,495 DEBUG TRAIN Batch 18/2900 loss 10.119676 loss_att 13.548559 loss_ctc 14.708466 loss_rnnt 8.753464 hw_loss 0.128619 lr 0.00040415 rank 2
2023-02-22 11:06:24,498 DEBUG TRAIN Batch 18/2900 loss 12.630127 loss_att 16.368362 loss_ctc 19.592943 loss_rnnt 10.927749 hw_loss 0.049417 lr 0.00040419 rank 4
2023-02-22 11:06:24,499 DEBUG TRAIN Batch 18/2900 loss 5.363089 loss_att 9.888211 loss_ctc 6.629753 loss_rnnt 4.242961 hw_loss 0.086652 lr 0.00040423 rank 1
2023-02-22 11:06:24,500 DEBUG TRAIN Batch 18/2900 loss 14.461989 loss_att 17.456806 loss_ctc 20.690247 loss_rnnt 12.943916 hw_loss 0.166266 lr 0.00040413 rank 3
2023-02-22 11:07:40,585 DEBUG TRAIN Batch 18/3000 loss 9.487349 loss_att 10.683189 loss_ctc 11.892639 loss_rnnt 8.912503 hw_loss 0.028071 lr 0.00040406 rank 7
2023-02-22 11:07:40,593 DEBUG TRAIN Batch 18/3000 loss 5.699323 loss_att 8.956707 loss_ctc 6.592621 loss_rnnt 4.837514 hw_loss 0.171047 lr 0.00040400 rank 3
2023-02-22 11:07:40,594 DEBUG TRAIN Batch 18/3000 loss 8.112348 loss_att 9.474113 loss_ctc 8.199657 loss_rnnt 7.822989 hw_loss 0.010058 lr 0.00040409 rank 1
2023-02-22 11:07:40,594 DEBUG TRAIN Batch 18/3000 loss 6.526097 loss_att 10.468238 loss_ctc 8.174577 loss_rnnt 5.456334 hw_loss 0.115382 lr 0.00040406 rank 4
2023-02-22 11:07:40,594 DEBUG TRAIN Batch 18/3000 loss 8.931306 loss_att 12.245998 loss_ctc 12.529535 loss_rnnt 7.762278 hw_loss 0.049361 lr 0.00040407 rank 6
2023-02-22 11:07:40,620 DEBUG TRAIN Batch 18/3000 loss 14.311809 loss_att 15.174105 loss_ctc 16.802326 loss_rnnt 13.768708 hw_loss 0.072320 lr 0.00040408 rank 5
2023-02-22 11:07:40,632 DEBUG TRAIN Batch 18/3000 loss 15.820739 loss_att 19.027542 loss_ctc 20.251232 loss_rnnt 14.588476 hw_loss 0.000317 lr 0.00040408 rank 0
2023-02-22 11:07:40,635 DEBUG TRAIN Batch 18/3000 loss 7.640712 loss_att 9.297980 loss_ctc 8.948385 loss_rnnt 7.116451 hw_loss 0.034595 lr 0.00040402 rank 2
2023-02-22 11:08:57,373 DEBUG TRAIN Batch 18/3100 loss 8.631917 loss_att 11.699942 loss_ctc 12.157240 loss_rnnt 7.484801 hw_loss 0.119002 lr 0.00040394 rank 6
2023-02-22 11:08:57,373 DEBUG TRAIN Batch 18/3100 loss 12.544174 loss_att 15.057793 loss_ctc 14.853571 loss_rnnt 11.648714 hw_loss 0.159029 lr 0.00040387 rank 3
2023-02-22 11:08:57,374 DEBUG TRAIN Batch 18/3100 loss 14.488677 loss_att 16.352488 loss_ctc 18.749619 loss_rnnt 13.500151 hw_loss 0.089323 lr 0.00040395 rank 0
2023-02-22 11:08:57,375 DEBUG TRAIN Batch 18/3100 loss 10.697438 loss_att 10.202357 loss_ctc 12.757714 loss_rnnt 10.433805 hw_loss 0.164898 lr 0.00040393 rank 7
2023-02-22 11:08:57,375 DEBUG TRAIN Batch 18/3100 loss 6.765028 loss_att 9.075146 loss_ctc 10.526356 loss_rnnt 5.768919 hw_loss 0.061078 lr 0.00040394 rank 5
2023-02-22 11:08:57,377 DEBUG TRAIN Batch 18/3100 loss 7.733173 loss_att 9.901703 loss_ctc 14.081924 loss_rnnt 6.395634 hw_loss 0.107500 lr 0.00040393 rank 4
2023-02-22 11:08:57,377 DEBUG TRAIN Batch 18/3100 loss 13.511036 loss_att 16.186131 loss_ctc 18.304976 loss_rnnt 12.282404 hw_loss 0.102039 lr 0.00040389 rank 2
2023-02-22 11:08:57,426 DEBUG TRAIN Batch 18/3100 loss 8.942908 loss_att 12.256227 loss_ctc 9.592463 loss_rnnt 8.154455 hw_loss 0.073467 lr 0.00040396 rank 1
2023-02-22 11:10:15,984 DEBUG TRAIN Batch 18/3200 loss 14.355000 loss_att 18.601259 loss_ctc 15.752734 loss_rnnt 13.217781 hw_loss 0.190506 lr 0.00040381 rank 5
2023-02-22 11:10:15,991 DEBUG TRAIN Batch 18/3200 loss 9.356144 loss_att 12.460602 loss_ctc 12.987213 loss_rnnt 8.159334 hw_loss 0.172079 lr 0.00040379 rank 7
2023-02-22 11:10:15,991 DEBUG TRAIN Batch 18/3200 loss 11.689094 loss_att 14.724621 loss_ctc 14.535429 loss_rnnt 10.651355 hw_loss 0.095853 lr 0.00040379 rank 4
2023-02-22 11:10:15,992 DEBUG TRAIN Batch 18/3200 loss 11.050541 loss_att 12.442082 loss_ctc 16.731680 loss_rnnt 9.905158 hw_loss 0.205482 lr 0.00040381 rank 6
2023-02-22 11:10:15,993 DEBUG TRAIN Batch 18/3200 loss 6.374205 loss_att 8.038406 loss_ctc 9.392448 loss_rnnt 5.545288 hw_loss 0.175583 lr 0.00040383 rank 1
2023-02-22 11:10:15,993 DEBUG TRAIN Batch 18/3200 loss 12.802014 loss_att 12.667464 loss_ctc 14.310561 loss_rnnt 12.548153 hw_loss 0.149310 lr 0.00040374 rank 3
2023-02-22 11:10:16,007 DEBUG TRAIN Batch 18/3200 loss 8.829210 loss_att 12.417306 loss_ctc 10.056843 loss_rnnt 7.921233 hw_loss 0.050013 lr 0.00040382 rank 0
2023-02-22 11:10:16,037 DEBUG TRAIN Batch 18/3200 loss 8.114826 loss_att 12.655645 loss_ctc 8.435780 loss_rnnt 7.093601 hw_loss 0.131752 lr 0.00040375 rank 2
2023-02-22 11:11:32,308 DEBUG TRAIN Batch 18/3300 loss 18.676336 loss_att 24.079563 loss_ctc 23.592476 loss_rnnt 16.902052 hw_loss 0.071538 lr 0.00040362 rank 2
2023-02-22 11:11:32,309 DEBUG TRAIN Batch 18/3300 loss 6.626600 loss_att 8.890894 loss_ctc 6.456390 loss_rnnt 6.082864 hw_loss 0.212947 lr 0.00040366 rank 4
2023-02-22 11:11:32,310 DEBUG TRAIN Batch 18/3300 loss 5.109119 loss_att 10.246080 loss_ctc 9.210802 loss_rnnt 3.479888 hw_loss 0.103026 lr 0.00040366 rank 7
2023-02-22 11:11:32,310 DEBUG TRAIN Batch 18/3300 loss 12.307918 loss_att 17.487869 loss_ctc 13.656726 loss_rnnt 11.039527 hw_loss 0.098551 lr 0.00040368 rank 5
2023-02-22 11:11:32,310 DEBUG TRAIN Batch 18/3300 loss 8.016058 loss_att 10.698852 loss_ctc 11.208644 loss_rnnt 7.007258 hw_loss 0.087306 lr 0.00040369 rank 0
2023-02-22 11:11:32,315 DEBUG TRAIN Batch 18/3300 loss 11.950265 loss_att 16.900755 loss_ctc 16.629316 loss_rnnt 10.286417 hw_loss 0.093518 lr 0.00040368 rank 6
2023-02-22 11:11:32,317 DEBUG TRAIN Batch 18/3300 loss 10.761726 loss_att 13.932624 loss_ctc 12.672603 loss_rnnt 9.802771 hw_loss 0.131236 lr 0.00040370 rank 1
2023-02-22 11:11:32,360 DEBUG TRAIN Batch 18/3300 loss 8.803761 loss_att 10.998795 loss_ctc 10.185804 loss_rnnt 8.118698 hw_loss 0.115843 lr 0.00040360 rank 3
2023-02-22 11:12:47,979 DEBUG TRAIN Batch 18/3400 loss 5.019362 loss_att 7.664238 loss_ctc 6.483494 loss_rnnt 4.235142 hw_loss 0.112551 lr 0.00040355 rank 6
2023-02-22 11:12:47,982 DEBUG TRAIN Batch 18/3400 loss 12.839303 loss_att 14.116088 loss_ctc 22.380987 loss_rnnt 11.258200 hw_loss 0.100352 lr 0.00040356 rank 0
2023-02-22 11:12:47,984 DEBUG TRAIN Batch 18/3400 loss 8.467231 loss_att 11.463152 loss_ctc 10.710689 loss_rnnt 7.477010 hw_loss 0.172329 lr 0.00040349 rank 2
2023-02-22 11:12:47,984 DEBUG TRAIN Batch 18/3400 loss 12.707719 loss_att 12.850479 loss_ctc 16.297453 loss_rnnt 12.126449 hw_loss 0.138912 lr 0.00040353 rank 7
2023-02-22 11:12:47,985 DEBUG TRAIN Batch 18/3400 loss 10.895772 loss_att 12.172119 loss_ctc 13.197836 loss_rnnt 10.237727 hw_loss 0.179689 lr 0.00040355 rank 5
2023-02-22 11:12:47,985 DEBUG TRAIN Batch 18/3400 loss 10.075742 loss_att 11.965521 loss_ctc 10.997836 loss_rnnt 9.556849 hw_loss 0.033734 lr 0.00040353 rank 4
2023-02-22 11:12:47,988 DEBUG TRAIN Batch 18/3400 loss 19.944334 loss_att 25.441500 loss_ctc 25.715773 loss_rnnt 18.024242 hw_loss 0.095875 lr 0.00040357 rank 1
2023-02-22 11:12:48,033 DEBUG TRAIN Batch 18/3400 loss 11.630243 loss_att 12.434826 loss_ctc 12.564516 loss_rnnt 11.275333 hw_loss 0.130170 lr 0.00040347 rank 3
2023-02-22 11:14:05,684 DEBUG TRAIN Batch 18/3500 loss 9.545642 loss_att 12.270238 loss_ctc 12.521512 loss_rnnt 8.547634 hw_loss 0.105572 lr 0.00040343 rank 0
2023-02-22 11:14:05,685 DEBUG TRAIN Batch 18/3500 loss 10.094422 loss_att 12.644883 loss_ctc 10.634493 loss_rnnt 9.502155 hw_loss 0.019063 lr 0.00040340 rank 4
2023-02-22 11:14:05,686 DEBUG TRAIN Batch 18/3500 loss 7.742500 loss_att 9.610618 loss_ctc 10.798549 loss_rnnt 6.931205 hw_loss 0.056623 lr 0.00040342 rank 5
2023-02-22 11:14:05,689 DEBUG TRAIN Batch 18/3500 loss 9.122694 loss_att 11.719764 loss_ctc 14.004963 loss_rnnt 7.923471 hw_loss 0.054074 lr 0.00040341 rank 6
2023-02-22 11:14:05,690 DEBUG TRAIN Batch 18/3500 loss 5.407028 loss_att 7.050268 loss_ctc 8.869110 loss_rnnt 4.579983 hw_loss 0.068974 lr 0.00040340 rank 7
2023-02-22 11:14:05,690 DEBUG TRAIN Batch 18/3500 loss 13.406506 loss_att 19.018843 loss_ctc 19.330229 loss_rnnt 11.449188 hw_loss 0.084414 lr 0.00040334 rank 3
2023-02-22 11:14:05,691 DEBUG TRAIN Batch 18/3500 loss 6.664068 loss_att 8.690160 loss_ctc 8.102003 loss_rnnt 6.030669 hw_loss 0.068355 lr 0.00040336 rank 2
2023-02-22 11:14:05,735 DEBUG TRAIN Batch 18/3500 loss 10.905567 loss_att 16.053089 loss_ctc 17.569252 loss_rnnt 8.974234 hw_loss 0.025008 lr 0.00040344 rank 1
2023-02-22 11:15:22,647 DEBUG TRAIN Batch 18/3600 loss 4.396633 loss_att 7.968042 loss_ctc 5.390759 loss_rnnt 3.498123 hw_loss 0.096894 lr 0.00040329 rank 5
2023-02-22 11:15:22,647 DEBUG TRAIN Batch 18/3600 loss 9.405678 loss_att 13.428732 loss_ctc 14.420391 loss_rnnt 7.872580 hw_loss 0.112234 lr 0.00040330 rank 0
2023-02-22 11:15:22,650 DEBUG TRAIN Batch 18/3600 loss 14.486835 loss_att 18.432178 loss_ctc 21.585388 loss_rnnt 12.706278 hw_loss 0.084400 lr 0.00040330 rank 1
2023-02-22 11:15:22,651 DEBUG TRAIN Batch 18/3600 loss 9.090711 loss_att 13.559129 loss_ctc 15.561943 loss_rnnt 7.235592 hw_loss 0.184883 lr 0.00040328 rank 6
2023-02-22 11:15:22,653 DEBUG TRAIN Batch 18/3600 loss 13.340623 loss_att 13.619576 loss_ctc 19.913895 loss_rnnt 12.380235 hw_loss 0.052804 lr 0.00040327 rank 4
2023-02-22 11:15:22,655 DEBUG TRAIN Batch 18/3600 loss 16.843864 loss_att 19.895855 loss_ctc 24.990208 loss_rnnt 15.128408 hw_loss 0.035403 lr 0.00040321 rank 3
2023-02-22 11:15:22,655 DEBUG TRAIN Batch 18/3600 loss 9.948934 loss_att 10.154945 loss_ctc 12.428049 loss_rnnt 9.536348 hw_loss 0.076564 lr 0.00040327 rank 7
2023-02-22 11:15:22,659 DEBUG TRAIN Batch 18/3600 loss 13.945844 loss_att 15.645324 loss_ctc 19.401737 loss_rnnt 12.846543 hw_loss 0.059906 lr 0.00040323 rank 2
2023-02-22 11:16:39,002 DEBUG TRAIN Batch 18/3700 loss 4.658489 loss_att 7.100471 loss_ctc 5.784442 loss_rnnt 3.937846 hw_loss 0.153972 lr 0.00040316 rank 0
2023-02-22 11:16:39,009 DEBUG TRAIN Batch 18/3700 loss 6.429729 loss_att 8.790751 loss_ctc 8.835067 loss_rnnt 5.521588 hw_loss 0.216046 lr 0.00040310 rank 2
2023-02-22 11:16:39,011 DEBUG TRAIN Batch 18/3700 loss 7.076026 loss_att 11.460785 loss_ctc 11.243784 loss_rnnt 5.554531 hw_loss 0.166581 lr 0.00040314 rank 7
2023-02-22 11:16:39,013 DEBUG TRAIN Batch 18/3700 loss 4.432998 loss_att 8.209320 loss_ctc 5.895842 loss_rnnt 3.408573 hw_loss 0.138966 lr 0.00040314 rank 4
2023-02-22 11:16:39,014 DEBUG TRAIN Batch 18/3700 loss 10.713378 loss_att 12.546988 loss_ctc 12.965834 loss_rnnt 9.972030 hw_loss 0.139311 lr 0.00040316 rank 5
2023-02-22 11:16:39,015 DEBUG TRAIN Batch 18/3700 loss 11.506276 loss_att 13.666126 loss_ctc 16.297131 loss_rnnt 10.396238 hw_loss 0.073664 lr 0.00040315 rank 6
2023-02-22 11:16:39,017 DEBUG TRAIN Batch 18/3700 loss 5.639372 loss_att 8.982044 loss_ctc 9.127603 loss_rnnt 4.500267 hw_loss 0.010263 lr 0.00040308 rank 3
2023-02-22 11:16:39,017 DEBUG TRAIN Batch 18/3700 loss 7.098316 loss_att 9.605183 loss_ctc 7.968332 loss_rnnt 6.463068 hw_loss 0.033513 lr 0.00040317 rank 1
2023-02-22 11:17:54,314 DEBUG TRAIN Batch 18/3800 loss 8.675989 loss_att 7.710567 loss_ctc 10.811208 loss_rnnt 8.465137 hw_loss 0.223577 lr 0.00040303 rank 0
2023-02-22 11:17:54,316 DEBUG TRAIN Batch 18/3800 loss 8.707398 loss_att 10.977779 loss_ctc 13.466281 loss_rnnt 7.493569 hw_loss 0.234816 lr 0.00040302 rank 5
2023-02-22 11:17:54,318 DEBUG TRAIN Batch 18/3800 loss 3.537829 loss_att 5.512718 loss_ctc 6.124250 loss_rnnt 2.679164 hw_loss 0.222809 lr 0.00040301 rank 4
2023-02-22 11:17:54,320 DEBUG TRAIN Batch 18/3800 loss 6.294133 loss_att 7.677179 loss_ctc 8.799897 loss_rnnt 5.642336 hw_loss 0.077035 lr 0.00040304 rank 1
2023-02-22 11:17:54,320 DEBUG TRAIN Batch 18/3800 loss 5.627121 loss_att 9.833348 loss_ctc 9.915648 loss_rnnt 4.175437 hw_loss 0.072441 lr 0.00040301 rank 7
2023-02-22 11:17:54,321 DEBUG TRAIN Batch 18/3800 loss 13.787292 loss_att 16.093643 loss_ctc 20.476471 loss_rnnt 12.387596 hw_loss 0.087255 lr 0.00040295 rank 3
2023-02-22 11:17:54,352 DEBUG TRAIN Batch 18/3800 loss 4.442252 loss_att 5.589968 loss_ctc 7.510626 loss_rnnt 3.759246 hw_loss 0.083148 lr 0.00040297 rank 2
2023-02-22 11:17:54,367 DEBUG TRAIN Batch 18/3800 loss 7.382478 loss_att 10.594501 loss_ctc 14.012809 loss_rnnt 5.752362 hw_loss 0.194376 lr 0.00040302 rank 6
2023-02-22 11:19:12,464 DEBUG TRAIN Batch 18/3900 loss 8.620367 loss_att 10.177969 loss_ctc 10.696231 loss_rnnt 8.018968 hw_loss 0.024557 lr 0.00040289 rank 5
2023-02-22 11:19:12,466 DEBUG TRAIN Batch 18/3900 loss 22.194544 loss_att 23.679998 loss_ctc 28.387405 loss_rnnt 20.999134 hw_loss 0.136133 lr 0.00040288 rank 4
2023-02-22 11:19:12,468 DEBUG TRAIN Batch 18/3900 loss 5.141806 loss_att 10.457016 loss_ctc 7.999949 loss_rnnt 3.630795 hw_loss 0.125406 lr 0.00040290 rank 0
2023-02-22 11:19:12,468 DEBUG TRAIN Batch 18/3900 loss 4.437584 loss_att 6.651414 loss_ctc 6.757566 loss_rnnt 3.583753 hw_loss 0.190751 lr 0.00040282 rank 3
2023-02-22 11:19:12,469 DEBUG TRAIN Batch 18/3900 loss 8.956607 loss_att 9.737830 loss_ctc 12.041336 loss_rnnt 8.286392 hw_loss 0.192512 lr 0.00040289 rank 6
2023-02-22 11:19:12,471 DEBUG TRAIN Batch 18/3900 loss 2.920820 loss_att 5.253610 loss_ctc 4.137970 loss_rnnt 2.260732 hw_loss 0.058582 lr 0.00040288 rank 7
2023-02-22 11:19:12,477 DEBUG TRAIN Batch 18/3900 loss 5.723828 loss_att 10.934157 loss_ctc 6.853626 loss_rnnt 4.465487 hw_loss 0.123067 lr 0.00040284 rank 2
2023-02-22 11:19:12,534 DEBUG TRAIN Batch 18/3900 loss 8.528975 loss_att 8.951593 loss_ctc 11.726608 loss_rnnt 7.897799 hw_loss 0.225565 lr 0.00040291 rank 1
2023-02-22 11:20:26,622 DEBUG TRAIN Batch 18/4000 loss 4.297922 loss_att 8.178535 loss_ctc 5.039097 loss_rnnt 3.323779 hw_loss 0.185993 lr 0.00040277 rank 0
2023-02-22 11:20:26,624 DEBUG TRAIN Batch 18/4000 loss 3.658155 loss_att 5.650176 loss_ctc 6.173130 loss_rnnt 2.922319 hw_loss 0.003941 lr 0.00040276 rank 5
2023-02-22 11:20:26,626 DEBUG TRAIN Batch 18/4000 loss 8.695288 loss_att 12.532135 loss_ctc 11.076159 loss_rnnt 7.532554 hw_loss 0.146090 lr 0.00040275 rank 4
2023-02-22 11:20:26,627 DEBUG TRAIN Batch 18/4000 loss 8.673890 loss_att 11.698350 loss_ctc 14.875658 loss_rnnt 7.205603 hw_loss 0.068423 lr 0.00040270 rank 2
2023-02-22 11:20:26,629 DEBUG TRAIN Batch 18/4000 loss 8.509364 loss_att 9.941277 loss_ctc 11.149561 loss_rnnt 7.851249 hw_loss 0.036948 lr 0.00040269 rank 3
2023-02-22 11:20:26,630 DEBUG TRAIN Batch 18/4000 loss 19.706091 loss_att 23.060764 loss_ctc 28.087019 loss_rnnt 17.858494 hw_loss 0.111013 lr 0.00040278 rank 1
2023-02-22 11:20:26,630 DEBUG TRAIN Batch 18/4000 loss 8.857291 loss_att 13.999370 loss_ctc 13.870163 loss_rnnt 7.110567 hw_loss 0.093611 lr 0.00040276 rank 6
2023-02-22 11:20:26,631 DEBUG TRAIN Batch 18/4000 loss 16.379810 loss_att 17.334621 loss_ctc 23.530647 loss_rnnt 15.224887 hw_loss 0.019716 lr 0.00040275 rank 7
2023-02-22 11:21:40,244 DEBUG TRAIN Batch 18/4100 loss 7.126472 loss_att 10.457962 loss_ctc 7.632476 loss_rnnt 6.338143 hw_loss 0.102308 lr 0.00040264 rank 0
2023-02-22 11:21:40,251 DEBUG TRAIN Batch 18/4100 loss 5.764809 loss_att 7.939587 loss_ctc 6.022291 loss_rnnt 5.251307 hw_loss 0.082903 lr 0.00040263 rank 6
2023-02-22 11:21:40,251 DEBUG TRAIN Batch 18/4100 loss 26.485781 loss_att 25.217070 loss_ctc 37.775963 loss_rnnt 25.141592 hw_loss 0.173579 lr 0.00040265 rank 1
2023-02-22 11:21:40,254 DEBUG TRAIN Batch 18/4100 loss 6.369704 loss_att 10.003468 loss_ctc 9.827241 loss_rnnt 5.116282 hw_loss 0.123120 lr 0.00040261 rank 7
2023-02-22 11:21:40,256 DEBUG TRAIN Batch 18/4100 loss 12.284575 loss_att 16.885788 loss_ctc 18.462143 loss_rnnt 10.493303 hw_loss 0.088786 lr 0.00040261 rank 4
2023-02-22 11:21:40,255 DEBUG TRAIN Batch 18/4100 loss 5.640327 loss_att 9.792805 loss_ctc 6.704727 loss_rnnt 4.621103 hw_loss 0.087767 lr 0.00040256 rank 3
2023-02-22 11:21:40,257 DEBUG TRAIN Batch 18/4100 loss 6.689940 loss_att 9.482066 loss_ctc 7.369503 loss_rnnt 5.986547 hw_loss 0.101924 lr 0.00040263 rank 5
2023-02-22 11:21:40,258 DEBUG TRAIN Batch 18/4100 loss 10.324640 loss_att 12.256470 loss_ctc 14.094389 loss_rnnt 9.388880 hw_loss 0.087679 lr 0.00040257 rank 2
2023-02-22 11:22:56,754 DEBUG TRAIN Batch 18/4200 loss 2.880251 loss_att 6.459826 loss_ctc 5.299628 loss_rnnt 1.765991 hw_loss 0.142052 lr 0.00040244 rank 2
2023-02-22 11:22:56,754 DEBUG TRAIN Batch 18/4200 loss 4.784585 loss_att 8.160759 loss_ctc 9.273997 loss_rnnt 3.423545 hw_loss 0.163533 lr 0.00040251 rank 0
2023-02-22 11:22:56,759 DEBUG TRAIN Batch 18/4200 loss 11.540802 loss_att 17.142395 loss_ctc 18.883970 loss_rnnt 9.314758 hw_loss 0.237440 lr 0.00040243 rank 3
2023-02-22 11:22:56,760 DEBUG TRAIN Batch 18/4200 loss 18.415829 loss_att 24.362642 loss_ctc 28.317848 loss_rnnt 15.859060 hw_loss 0.088382 lr 0.00040248 rank 7
2023-02-22 11:22:56,762 DEBUG TRAIN Batch 18/4200 loss 8.353797 loss_att 12.511446 loss_ctc 11.169639 loss_rnnt 7.101140 hw_loss 0.085653 lr 0.00040250 rank 5
2023-02-22 11:22:56,763 DEBUG TRAIN Batch 18/4200 loss 12.120012 loss_att 20.563423 loss_ctc 18.715267 loss_rnnt 9.498684 hw_loss 0.099897 lr 0.00040250 rank 6
2023-02-22 11:22:56,782 DEBUG TRAIN Batch 18/4200 loss 5.618349 loss_att 8.923858 loss_ctc 11.713234 loss_rnnt 4.119576 hw_loss 0.046914 lr 0.00040248 rank 4
2023-02-22 11:22:56,806 DEBUG TRAIN Batch 18/4200 loss 11.323435 loss_att 14.633162 loss_ctc 19.406965 loss_rnnt 9.533363 hw_loss 0.094351 lr 0.00040252 rank 1
2023-02-22 11:24:13,371 DEBUG TRAIN Batch 18/4300 loss 8.544671 loss_att 8.377600 loss_ctc 10.872660 loss_rnnt 8.165632 hw_loss 0.191352 lr 0.00040238 rank 0
2023-02-22 11:24:13,372 DEBUG TRAIN Batch 18/4300 loss 11.449791 loss_att 11.525295 loss_ctc 13.695215 loss_rnnt 11.113828 hw_loss 0.040262 lr 0.00040237 rank 6
2023-02-22 11:24:13,372 DEBUG TRAIN Batch 18/4300 loss 4.932039 loss_att 9.052797 loss_ctc 7.245825 loss_rnnt 3.744417 hw_loss 0.103061 lr 0.00040237 rank 5
2023-02-22 11:24:13,375 DEBUG TRAIN Batch 18/4300 loss 6.398438 loss_att 10.007221 loss_ctc 9.059265 loss_rnnt 5.242235 hw_loss 0.149379 lr 0.00040235 rank 4
2023-02-22 11:24:13,375 DEBUG TRAIN Batch 18/4300 loss 12.152546 loss_att 15.167371 loss_ctc 13.794761 loss_rnnt 11.273618 hw_loss 0.106876 lr 0.00040231 rank 2
2023-02-22 11:24:13,376 DEBUG TRAIN Batch 18/4300 loss 19.226358 loss_att 23.131216 loss_ctc 30.570217 loss_rnnt 16.842136 hw_loss 0.170130 lr 0.00040239 rank 1
2023-02-22 11:24:13,376 DEBUG TRAIN Batch 18/4300 loss 6.074198 loss_att 8.846296 loss_ctc 7.029873 loss_rnnt 5.354051 hw_loss 0.071821 lr 0.00040235 rank 7
2023-02-22 11:24:13,381 DEBUG TRAIN Batch 18/4300 loss 3.170330 loss_att 6.206751 loss_ctc 4.512877 loss_rnnt 2.326909 hw_loss 0.107118 lr 0.00040230 rank 3
2023-02-22 11:25:28,755 DEBUG TRAIN Batch 18/4400 loss 6.754814 loss_att 10.759779 loss_ctc 7.800486 loss_rnnt 5.767166 hw_loss 0.088561 lr 0.00040224 rank 5
2023-02-22 11:25:28,759 DEBUG TRAIN Batch 18/4400 loss 8.590906 loss_att 9.297136 loss_ctc 11.664036 loss_rnnt 7.973783 hw_loss 0.123987 lr 0.00040222 rank 7
2023-02-22 11:25:28,760 DEBUG TRAIN Batch 18/4400 loss 9.176466 loss_att 9.413247 loss_ctc 9.883567 loss_rnnt 8.941432 hw_loss 0.175120 lr 0.00040225 rank 0
2023-02-22 11:25:28,764 DEBUG TRAIN Batch 18/4400 loss 10.171131 loss_att 13.757668 loss_ctc 14.592359 loss_rnnt 8.827322 hw_loss 0.069384 lr 0.00040224 rank 6
2023-02-22 11:25:28,766 DEBUG TRAIN Batch 18/4400 loss 10.452024 loss_att 11.731704 loss_ctc 14.761059 loss_rnnt 9.542339 hw_loss 0.148517 lr 0.00040218 rank 2
2023-02-22 11:25:28,766 DEBUG TRAIN Batch 18/4400 loss 19.076239 loss_att 19.279240 loss_ctc 22.507782 loss_rnnt 18.475519 hw_loss 0.192339 lr 0.00040226 rank 1
2023-02-22 11:25:28,767 DEBUG TRAIN Batch 18/4400 loss 12.595780 loss_att 17.204100 loss_ctc 17.302555 loss_rnnt 11.040174 hw_loss 0.011950 lr 0.00040222 rank 4
2023-02-22 11:25:28,807 DEBUG TRAIN Batch 18/4400 loss 6.331457 loss_att 8.675550 loss_ctc 9.296783 loss_rnnt 5.404285 hw_loss 0.118080 lr 0.00040217 rank 3
2023-02-22 11:26:42,801 DEBUG TRAIN Batch 18/4500 loss 20.779312 loss_att 24.276930 loss_ctc 24.680996 loss_rnnt 19.437376 hw_loss 0.229101 lr 0.00040211 rank 5
2023-02-22 11:26:42,801 DEBUG TRAIN Batch 18/4500 loss 15.413740 loss_att 16.424412 loss_ctc 22.748642 loss_rnnt 14.222117 hw_loss 0.021564 lr 0.00040212 rank 0
2023-02-22 11:26:42,801 DEBUG TRAIN Batch 18/4500 loss 5.530033 loss_att 8.283896 loss_ctc 9.293189 loss_rnnt 4.414291 hw_loss 0.118529 lr 0.00040205 rank 2
2023-02-22 11:26:42,801 DEBUG TRAIN Batch 18/4500 loss 8.283706 loss_att 9.418072 loss_ctc 12.777166 loss_rnnt 7.395045 hw_loss 0.117485 lr 0.00040211 rank 6
2023-02-22 11:26:42,803 DEBUG TRAIN Batch 18/4500 loss 19.883804 loss_att 25.229465 loss_ctc 26.411129 loss_rnnt 17.929880 hw_loss 0.027153 lr 0.00040209 rank 7
2023-02-22 11:26:42,803 DEBUG TRAIN Batch 18/4500 loss 12.538838 loss_att 14.708078 loss_ctc 18.562883 loss_rnnt 11.211395 hw_loss 0.169479 lr 0.00040209 rank 4
2023-02-22 11:26:42,804 DEBUG TRAIN Batch 18/4500 loss 9.170174 loss_att 11.705099 loss_ctc 14.245226 loss_rnnt 7.924041 hw_loss 0.117140 lr 0.00040204 rank 3
2023-02-22 11:26:42,808 DEBUG TRAIN Batch 18/4500 loss 10.111588 loss_att 12.371689 loss_ctc 14.540431 loss_rnnt 8.966187 hw_loss 0.192876 lr 0.00040213 rank 1
2023-02-22 11:27:59,816 DEBUG TRAIN Batch 18/4600 loss 7.714657 loss_att 12.286350 loss_ctc 10.253157 loss_rnnt 6.425167 hw_loss 0.068784 lr 0.00040198 rank 6
2023-02-22 11:27:59,821 DEBUG TRAIN Batch 18/4600 loss 2.331277 loss_att 5.237753 loss_ctc 3.097988 loss_rnnt 1.603562 hw_loss 0.082859 lr 0.00040191 rank 3
2023-02-22 11:27:59,822 DEBUG TRAIN Batch 18/4600 loss 7.862512 loss_att 9.606469 loss_ctc 8.894865 loss_rnnt 7.344476 hw_loss 0.059246 lr 0.00040196 rank 7
2023-02-22 11:27:59,822 DEBUG TRAIN Batch 18/4600 loss 7.264205 loss_att 11.819239 loss_ctc 9.468840 loss_rnnt 5.987906 hw_loss 0.133767 lr 0.00040200 rank 1
2023-02-22 11:27:59,828 DEBUG TRAIN Batch 18/4600 loss 4.572654 loss_att 7.900511 loss_ctc 8.062902 loss_rnnt 3.419308 hw_loss 0.042016 lr 0.00040199 rank 0
2023-02-22 11:27:59,829 DEBUG TRAIN Batch 18/4600 loss 3.410969 loss_att 6.411345 loss_ctc 7.487675 loss_rnnt 2.212361 hw_loss 0.103072 lr 0.00040196 rank 4
2023-02-22 11:27:59,854 DEBUG TRAIN Batch 18/4600 loss 9.861139 loss_att 12.539339 loss_ctc 16.352890 loss_rnnt 8.407152 hw_loss 0.098963 lr 0.00040198 rank 5
2023-02-22 11:27:59,867 DEBUG TRAIN Batch 18/4600 loss 6.752928 loss_att 11.558091 loss_ctc 10.842127 loss_rnnt 5.200947 hw_loss 0.085729 lr 0.00040192 rank 2
2023-02-22 11:29:15,400 DEBUG TRAIN Batch 18/4700 loss 13.132360 loss_att 14.925121 loss_ctc 13.586413 loss_rnnt 12.663588 hw_loss 0.093147 lr 0.00040185 rank 5
2023-02-22 11:29:15,405 DEBUG TRAIN Batch 18/4700 loss 18.281096 loss_att 25.833946 loss_ctc 28.531759 loss_rnnt 15.313892 hw_loss 0.168519 lr 0.00040183 rank 7
2023-02-22 11:29:15,406 DEBUG TRAIN Batch 18/4700 loss 11.659431 loss_att 15.028693 loss_ctc 20.304827 loss_rnnt 9.766670 hw_loss 0.124103 lr 0.00040186 rank 0
2023-02-22 11:29:15,408 DEBUG TRAIN Batch 18/4700 loss 3.845811 loss_att 7.993522 loss_ctc 7.134881 loss_rnnt 2.544840 hw_loss 0.061661 lr 0.00040183 rank 4
2023-02-22 11:29:15,411 DEBUG TRAIN Batch 18/4700 loss 14.344100 loss_att 20.279287 loss_ctc 24.503584 loss_rnnt 11.723728 hw_loss 0.147631 lr 0.00040178 rank 3
2023-02-22 11:29:15,412 DEBUG TRAIN Batch 18/4700 loss 10.933706 loss_att 14.171337 loss_ctc 11.664999 loss_rnnt 10.172591 hw_loss 0.030155 lr 0.00040187 rank 1
2023-02-22 11:29:15,414 DEBUG TRAIN Batch 18/4700 loss 4.393746 loss_att 8.661482 loss_ctc 6.533328 loss_rnnt 3.215350 hw_loss 0.074196 lr 0.00040179 rank 2
2023-02-22 11:29:15,416 DEBUG TRAIN Batch 18/4700 loss 6.339226 loss_att 8.850691 loss_ctc 9.910979 loss_rnnt 5.334244 hw_loss 0.049604 lr 0.00040185 rank 6
2023-02-22 11:30:30,715 DEBUG TRAIN Batch 18/4800 loss 10.011145 loss_att 12.458038 loss_ctc 12.975817 loss_rnnt 9.084860 hw_loss 0.078029 lr 0.00040170 rank 7
2023-02-22 11:30:30,717 DEBUG TRAIN Batch 18/4800 loss 10.894437 loss_att 14.873852 loss_ctc 19.032221 loss_rnnt 8.950883 hw_loss 0.117435 lr 0.00040173 rank 0
2023-02-22 11:30:30,719 DEBUG TRAIN Batch 18/4800 loss 10.821877 loss_att 13.694714 loss_ctc 13.773918 loss_rnnt 9.780909 hw_loss 0.136491 lr 0.00040170 rank 4
2023-02-22 11:30:30,720 DEBUG TRAIN Batch 18/4800 loss 9.579634 loss_att 13.518040 loss_ctc 10.468739 loss_rnnt 8.612723 hw_loss 0.113777 lr 0.00040172 rank 5
2023-02-22 11:30:30,724 DEBUG TRAIN Batch 18/4800 loss 12.572068 loss_att 16.073481 loss_ctc 17.581783 loss_rnnt 11.137896 hw_loss 0.123612 lr 0.00040172 rank 6
2023-02-22 11:30:30,726 DEBUG TRAIN Batch 18/4800 loss 13.578938 loss_att 16.153954 loss_ctc 19.750658 loss_rnnt 12.172512 hw_loss 0.128487 lr 0.00040166 rank 2
2023-02-22 11:30:30,728 DEBUG TRAIN Batch 18/4800 loss 8.523237 loss_att 11.276020 loss_ctc 12.241745 loss_rnnt 7.417219 hw_loss 0.111865 lr 0.00040174 rank 1
2023-02-22 11:30:30,767 DEBUG TRAIN Batch 18/4800 loss 10.637602 loss_att 13.778921 loss_ctc 14.112133 loss_rnnt 9.477304 hw_loss 0.128931 lr 0.00040165 rank 3
2023-02-22 11:31:46,513 DEBUG TRAIN Batch 18/4900 loss 3.488849 loss_att 6.980853 loss_ctc 6.318066 loss_rnnt 2.403289 hw_loss 0.018621 lr 0.00040159 rank 5
2023-02-22 11:31:46,516 DEBUG TRAIN Batch 18/4900 loss 14.729590 loss_att 20.095306 loss_ctc 21.721046 loss_rnnt 12.661483 hw_loss 0.117695 lr 0.00040160 rank 0
2023-02-22 11:31:46,516 DEBUG TRAIN Batch 18/4900 loss 6.435287 loss_att 7.514864 loss_ctc 7.401168 loss_rnnt 6.056337 hw_loss 0.064220 lr 0.00040157 rank 7
2023-02-22 11:31:46,517 DEBUG TRAIN Batch 18/4900 loss 9.501016 loss_att 9.598011 loss_ctc 10.863634 loss_rnnt 9.226093 hw_loss 0.138450 lr 0.00040157 rank 4
2023-02-22 11:31:46,522 DEBUG TRAIN Batch 18/4900 loss 8.049951 loss_att 10.416512 loss_ctc 11.553581 loss_rnnt 7.079313 hw_loss 0.056576 lr 0.00040161 rank 1
2023-02-22 11:31:46,523 DEBUG TRAIN Batch 18/4900 loss 11.483333 loss_att 13.819180 loss_ctc 12.213535 loss_rnnt 10.822900 hw_loss 0.179818 lr 0.00040159 rank 6
2023-02-22 11:31:46,526 DEBUG TRAIN Batch 18/4900 loss 3.603364 loss_att 6.439631 loss_ctc 5.533917 loss_rnnt 2.713004 hw_loss 0.123186 lr 0.00040153 rank 2
2023-02-22 11:31:46,575 DEBUG TRAIN Batch 18/4900 loss 13.811038 loss_att 18.330788 loss_ctc 22.265789 loss_rnnt 11.708824 hw_loss 0.133057 lr 0.00040152 rank 3
2023-02-22 11:33:04,920 DEBUG TRAIN Batch 18/5000 loss 5.752503 loss_att 8.449245 loss_ctc 7.188952 loss_rnnt 4.952518 hw_loss 0.129582 lr 0.00040146 rank 5
2023-02-22 11:33:04,924 DEBUG TRAIN Batch 18/5000 loss 12.271536 loss_att 16.090578 loss_ctc 16.323742 loss_rnnt 10.868510 hw_loss 0.185482 lr 0.00040141 rank 2
2023-02-22 11:33:04,925 DEBUG TRAIN Batch 18/5000 loss 4.613594 loss_att 7.349973 loss_ctc 6.629799 loss_rnnt 3.776820 hw_loss 0.038756 lr 0.00040147 rank 0
2023-02-22 11:33:04,925 DEBUG TRAIN Batch 18/5000 loss 6.780377 loss_att 8.629293 loss_ctc 10.160953 loss_rnnt 5.864320 hw_loss 0.179119 lr 0.00040145 rank 7
2023-02-22 11:33:04,926 DEBUG TRAIN Batch 18/5000 loss 9.393536 loss_att 13.422976 loss_ctc 16.201590 loss_rnnt 7.620914 hw_loss 0.110611 lr 0.00040145 rank 4
2023-02-22 11:33:04,927 DEBUG TRAIN Batch 18/5000 loss 14.170533 loss_att 16.067905 loss_ctc 18.934050 loss_rnnt 13.126810 hw_loss 0.054587 lr 0.00040148 rank 1
2023-02-22 11:33:04,929 DEBUG TRAIN Batch 18/5000 loss 17.046650 loss_att 24.417179 loss_ctc 26.655018 loss_rnnt 14.173197 hw_loss 0.221681 lr 0.00040139 rank 3
2023-02-22 11:33:04,973 DEBUG TRAIN Batch 18/5000 loss 11.123474 loss_att 14.056681 loss_ctc 13.346804 loss_rnnt 10.161640 hw_loss 0.147653 lr 0.00040146 rank 6
2023-02-22 11:34:19,184 DEBUG TRAIN Batch 18/5100 loss 7.751691 loss_att 9.021746 loss_ctc 8.645841 loss_rnnt 7.334274 hw_loss 0.082850 lr 0.00040134 rank 0
2023-02-22 11:34:19,185 DEBUG TRAIN Batch 18/5100 loss 7.278688 loss_att 10.557422 loss_ctc 11.652385 loss_rnnt 5.996536 hw_loss 0.081087 lr 0.00040133 rank 5
2023-02-22 11:34:19,185 DEBUG TRAIN Batch 18/5100 loss 15.429399 loss_att 17.925735 loss_ctc 25.742893 loss_rnnt 13.473212 hw_loss 0.153349 lr 0.00040132 rank 4
2023-02-22 11:34:19,186 DEBUG TRAIN Batch 18/5100 loss 25.921227 loss_att 32.776730 loss_ctc 34.304314 loss_rnnt 23.330933 hw_loss 0.190217 lr 0.00040132 rank 7
2023-02-22 11:34:19,186 DEBUG TRAIN Batch 18/5100 loss 7.108888 loss_att 9.942305 loss_ctc 13.182736 loss_rnnt 5.700604 hw_loss 0.059536 lr 0.00040135 rank 1
2023-02-22 11:34:19,189 DEBUG TRAIN Batch 18/5100 loss 12.544506 loss_att 13.692575 loss_ctc 17.160685 loss_rnnt 11.635885 hw_loss 0.119095 lr 0.00040133 rank 6
2023-02-22 11:34:19,190 DEBUG TRAIN Batch 18/5100 loss 10.982244 loss_att 12.350568 loss_ctc 14.778449 loss_rnnt 10.094094 hw_loss 0.203106 lr 0.00040126 rank 3
2023-02-22 11:34:19,191 DEBUG TRAIN Batch 18/5100 loss 11.769238 loss_att 14.288328 loss_ctc 17.682562 loss_rnnt 10.403647 hw_loss 0.137494 lr 0.00040128 rank 2
2023-02-22 11:35:34,699 DEBUG TRAIN Batch 18/5200 loss 3.018935 loss_att 5.045684 loss_ctc 6.205961 loss_rnnt 2.102851 hw_loss 0.160869 lr 0.00040119 rank 7
2023-02-22 11:35:34,703 DEBUG TRAIN Batch 18/5200 loss 2.531830 loss_att 5.770351 loss_ctc 4.579227 loss_rnnt 1.537737 hw_loss 0.137629 lr 0.00040113 rank 3
2023-02-22 11:35:34,705 DEBUG TRAIN Batch 18/5200 loss 5.651996 loss_att 9.212239 loss_ctc 6.470285 loss_rnnt 4.763686 hw_loss 0.125918 lr 0.00040119 rank 4
2023-02-22 11:35:34,707 DEBUG TRAIN Batch 18/5200 loss 5.339854 loss_att 6.809810 loss_ctc 8.000847 loss_rnnt 4.630186 hw_loss 0.114145 lr 0.00040121 rank 0
2023-02-22 11:35:34,707 DEBUG TRAIN Batch 18/5200 loss 11.856654 loss_att 12.538107 loss_ctc 15.630149 loss_rnnt 11.102325 hw_loss 0.215447 lr 0.00040120 rank 5
2023-02-22 11:35:34,707 DEBUG TRAIN Batch 18/5200 loss 10.060801 loss_att 11.652774 loss_ctc 14.175681 loss_rnnt 9.155178 hw_loss 0.072331 lr 0.00040120 rank 6
2023-02-22 11:35:34,710 DEBUG TRAIN Batch 18/5200 loss 8.739642 loss_att 13.049776 loss_ctc 14.159163 loss_rnnt 7.079581 hw_loss 0.141434 lr 0.00040122 rank 1
2023-02-22 11:35:34,712 DEBUG TRAIN Batch 18/5200 loss 3.570718 loss_att 7.076684 loss_ctc 6.458407 loss_rnnt 2.452059 hw_loss 0.060826 lr 0.00040115 rank 2
2023-02-22 11:36:51,936 DEBUG TRAIN Batch 18/5300 loss 8.658551 loss_att 11.211311 loss_ctc 9.625308 loss_rnnt 7.957853 hw_loss 0.114834 lr 0.00040106 rank 7
2023-02-22 11:36:51,940 DEBUG TRAIN Batch 18/5300 loss 8.714911 loss_att 11.085091 loss_ctc 9.512333 loss_rnnt 8.102280 hw_loss 0.060509 lr 0.00040108 rank 0
2023-02-22 11:36:51,943 DEBUG TRAIN Batch 18/5300 loss 16.805439 loss_att 21.590542 loss_ctc 24.101685 loss_rnnt 14.843552 hw_loss 0.060063 lr 0.00040100 rank 3
2023-02-22 11:36:51,944 DEBUG TRAIN Batch 18/5300 loss 5.338941 loss_att 8.987875 loss_ctc 10.158007 loss_rnnt 3.951814 hw_loss 0.027745 lr 0.00040107 rank 6
2023-02-22 11:36:51,944 DEBUG TRAIN Batch 18/5300 loss 16.490705 loss_att 17.058496 loss_ctc 21.053955 loss_rnnt 15.753332 hw_loss 0.028842 lr 0.00040109 rank 1
2023-02-22 11:36:51,945 DEBUG TRAIN Batch 18/5300 loss 7.487971 loss_att 8.855312 loss_ctc 9.539031 loss_rnnt 6.887287 hw_loss 0.100765 lr 0.00040102 rank 2
2023-02-22 11:36:51,945 DEBUG TRAIN Batch 18/5300 loss 9.523695 loss_att 13.051204 loss_ctc 15.125731 loss_rnnt 8.047745 hw_loss 0.044082 lr 0.00040107 rank 5
2023-02-22 11:36:51,947 DEBUG TRAIN Batch 18/5300 loss 7.147962 loss_att 9.321706 loss_ctc 6.654513 loss_rnnt 6.778928 hw_loss 0.000146 lr 0.00040106 rank 4
2023-02-22 11:38:07,834 DEBUG TRAIN Batch 18/5400 loss 8.864751 loss_att 12.816095 loss_ctc 10.762875 loss_rnnt 7.785936 hw_loss 0.066490 lr 0.00040093 rank 7
2023-02-22 11:38:07,835 DEBUG TRAIN Batch 18/5400 loss 5.534936 loss_att 8.905773 loss_ctc 9.419495 loss_rnnt 4.298069 hw_loss 0.083922 lr 0.00040095 rank 0
2023-02-22 11:38:07,841 DEBUG TRAIN Batch 18/5400 loss 8.387641 loss_att 11.775691 loss_ctc 11.843683 loss_rnnt 7.214066 hw_loss 0.065924 lr 0.00040094 rank 6
2023-02-22 11:38:07,843 DEBUG TRAIN Batch 18/5400 loss 14.917368 loss_att 19.641119 loss_ctc 20.769489 loss_rnnt 13.167805 hw_loss 0.045994 lr 0.00040089 rank 2
2023-02-22 11:38:07,846 DEBUG TRAIN Batch 18/5400 loss 9.747192 loss_att 13.887350 loss_ctc 16.064938 loss_rnnt 7.985265 hw_loss 0.171619 lr 0.00040093 rank 4
2023-02-22 11:38:07,847 DEBUG TRAIN Batch 18/5400 loss 17.305063 loss_att 18.927097 loss_ctc 23.555058 loss_rnnt 16.081444 hw_loss 0.123526 lr 0.00040096 rank 1
2023-02-22 11:38:07,849 DEBUG TRAIN Batch 18/5400 loss 10.389005 loss_att 11.335439 loss_ctc 12.856898 loss_rnnt 9.848602 hw_loss 0.041367 lr 0.00040095 rank 5
2023-02-22 11:38:07,853 DEBUG TRAIN Batch 18/5400 loss 7.188921 loss_att 10.069405 loss_ctc 11.094635 loss_rnnt 6.056324 hw_loss 0.067008 lr 0.00040087 rank 3
2023-02-22 11:39:21,736 DEBUG TRAIN Batch 18/5500 loss 6.138524 loss_att 9.244625 loss_ctc 7.709441 loss_rnnt 5.252680 hw_loss 0.103440 lr 0.00040082 rank 5
2023-02-22 11:39:21,739 DEBUG TRAIN Batch 18/5500 loss 13.006768 loss_att 16.412447 loss_ctc 19.498632 loss_rnnt 11.391867 hw_loss 0.127845 lr 0.00040080 rank 7
2023-02-22 11:39:21,740 DEBUG TRAIN Batch 18/5500 loss 14.041880 loss_att 15.466249 loss_ctc 18.292362 loss_rnnt 13.147572 hw_loss 0.080069 lr 0.00040081 rank 6
2023-02-22 11:39:21,747 DEBUG TRAIN Batch 18/5500 loss 7.606502 loss_att 10.408830 loss_ctc 9.925570 loss_rnnt 6.684162 hw_loss 0.098746 lr 0.00040083 rank 0
2023-02-22 11:39:21,747 DEBUG TRAIN Batch 18/5500 loss 5.944845 loss_att 7.782746 loss_ctc 8.198150 loss_rnnt 5.235949 hw_loss 0.076642 lr 0.00040080 rank 4
2023-02-22 11:39:21,748 DEBUG TRAIN Batch 18/5500 loss 5.414512 loss_att 7.251976 loss_ctc 6.094655 loss_rnnt 4.884929 hw_loss 0.133885 lr 0.00040083 rank 1
2023-02-22 11:39:21,748 DEBUG TRAIN Batch 18/5500 loss 3.291204 loss_att 6.313113 loss_ctc 2.568251 loss_rnnt 2.739363 hw_loss 0.082224 lr 0.00040074 rank 3
2023-02-22 11:39:21,748 DEBUG TRAIN Batch 18/5500 loss 18.780657 loss_att 20.145309 loss_ctc 25.547897 loss_rnnt 17.528015 hw_loss 0.145148 lr 0.00040076 rank 2
2023-02-22 11:40:37,504 DEBUG TRAIN Batch 18/5600 loss 13.672380 loss_att 16.189688 loss_ctc 17.209326 loss_rnnt 12.679614 hw_loss 0.033208 lr 0.00040070 rank 0
2023-02-22 11:40:37,504 DEBUG TRAIN Batch 18/5600 loss 10.019254 loss_att 12.818888 loss_ctc 13.030851 loss_rnnt 9.032994 hw_loss 0.046473 lr 0.00040067 rank 7
2023-02-22 11:40:37,509 DEBUG TRAIN Batch 18/5600 loss 5.432006 loss_att 6.647339 loss_ctc 7.439735 loss_rnnt 4.808759 hw_loss 0.210905 lr 0.00040063 rank 2
2023-02-22 11:40:37,512 DEBUG TRAIN Batch 18/5600 loss 10.510560 loss_att 14.544291 loss_ctc 16.072220 loss_rnnt 8.947657 hw_loss 0.027381 lr 0.00040071 rank 1
2023-02-22 11:40:37,515 DEBUG TRAIN Batch 18/5600 loss 16.012465 loss_att 19.856371 loss_ctc 24.803270 loss_rnnt 14.009806 hw_loss 0.115819 lr 0.00040067 rank 4
2023-02-22 11:40:37,515 DEBUG TRAIN Batch 18/5600 loss 8.401860 loss_att 11.751677 loss_ctc 10.026987 loss_rnnt 7.444356 hw_loss 0.132857 lr 0.00040069 rank 5
2023-02-22 11:40:37,516 DEBUG TRAIN Batch 18/5600 loss 3.074210 loss_att 5.449744 loss_ctc 5.713681 loss_rnnt 2.177610 hw_loss 0.130432 lr 0.00040061 rank 3
2023-02-22 11:40:37,516 DEBUG TRAIN Batch 18/5600 loss 3.621896 loss_att 7.177629 loss_ctc 5.039519 loss_rnnt 2.660683 hw_loss 0.114468 lr 0.00040069 rank 6
2023-02-22 11:41:56,161 DEBUG TRAIN Batch 18/5700 loss 8.530583 loss_att 8.949568 loss_ctc 10.571241 loss_rnnt 8.109649 hw_loss 0.121969 lr 0.00040057 rank 0
2023-02-22 11:41:56,164 DEBUG TRAIN Batch 18/5700 loss 7.733725 loss_att 9.060513 loss_ctc 9.811494 loss_rnnt 7.162509 hw_loss 0.054044 lr 0.00040056 rank 6
2023-02-22 11:41:56,164 DEBUG TRAIN Batch 18/5700 loss 4.780790 loss_att 6.453507 loss_ctc 8.272433 loss_rnnt 3.940579 hw_loss 0.075215 lr 0.00040054 rank 4
2023-02-22 11:41:56,166 DEBUG TRAIN Batch 18/5700 loss 10.714585 loss_att 12.654978 loss_ctc 13.482463 loss_rnnt 9.896670 hw_loss 0.113974 lr 0.00040058 rank 1
2023-02-22 11:41:56,166 DEBUG TRAIN Batch 18/5700 loss 8.267850 loss_att 7.848348 loss_ctc 10.038657 loss_rnnt 8.021397 hw_loss 0.176712 lr 0.00040050 rank 2
2023-02-22 11:41:56,167 DEBUG TRAIN Batch 18/5700 loss 12.565445 loss_att 16.734066 loss_ctc 16.969778 loss_rnnt 11.114347 hw_loss 0.056493 lr 0.00040054 rank 7
2023-02-22 11:41:56,169 DEBUG TRAIN Batch 18/5700 loss 17.038153 loss_att 19.107216 loss_ctc 22.528135 loss_rnnt 15.803968 hw_loss 0.165702 lr 0.00040056 rank 5
2023-02-22 11:41:56,173 DEBUG TRAIN Batch 18/5700 loss 5.061751 loss_att 6.616035 loss_ctc 6.227211 loss_rnnt 4.578949 hw_loss 0.031032 lr 0.00040048 rank 3
2023-02-22 11:43:11,223 DEBUG TRAIN Batch 18/5800 loss 11.434958 loss_att 18.199827 loss_ctc 14.965335 loss_rnnt 9.567581 hw_loss 0.081913 lr 0.00040041 rank 4
2023-02-22 11:43:11,226 DEBUG TRAIN Batch 18/5800 loss 14.810559 loss_att 17.012438 loss_ctc 18.138241 loss_rnnt 13.849643 hw_loss 0.144095 lr 0.00040043 rank 5
2023-02-22 11:43:11,227 DEBUG TRAIN Batch 18/5800 loss 4.593400 loss_att 8.841216 loss_ctc 5.957771 loss_rnnt 3.512146 hw_loss 0.093327 lr 0.00040044 rank 0
2023-02-22 11:43:11,230 DEBUG TRAIN Batch 18/5800 loss 8.177669 loss_att 11.031561 loss_ctc 10.484560 loss_rnnt 7.291034 hw_loss 0.015508 lr 0.00040036 rank 3
2023-02-22 11:43:11,231 DEBUG TRAIN Batch 18/5800 loss 7.477952 loss_att 8.541325 loss_ctc 9.405446 loss_rnnt 6.890741 hw_loss 0.220381 lr 0.00040043 rank 6
2023-02-22 11:43:11,231 DEBUG TRAIN Batch 18/5800 loss 8.123960 loss_att 11.689559 loss_ctc 12.407931 loss_rnnt 6.829561 hw_loss 0.018903 lr 0.00040041 rank 7
2023-02-22 11:43:11,234 DEBUG TRAIN Batch 18/5800 loss 5.910340 loss_att 5.589178 loss_ctc 7.587609 loss_rnnt 5.656816 hw_loss 0.176476 lr 0.00040045 rank 1
2023-02-22 11:43:11,279 DEBUG TRAIN Batch 18/5800 loss 13.303800 loss_att 18.623714 loss_ctc 17.215687 loss_rnnt 11.718158 hw_loss 0.000138 lr 0.00040037 rank 2
2023-02-22 11:44:26,966 DEBUG TRAIN Batch 18/5900 loss 10.699180 loss_att 13.317802 loss_ctc 12.730459 loss_rnnt 9.803135 hw_loss 0.190283 lr 0.00040032 rank 1
2023-02-22 11:44:26,966 DEBUG TRAIN Batch 18/5900 loss 5.793273 loss_att 8.930449 loss_ctc 13.633156 loss_rnnt 4.062577 hw_loss 0.108643 lr 0.00040029 rank 4
2023-02-22 11:44:26,966 DEBUG TRAIN Batch 18/5900 loss 8.220536 loss_att 9.190481 loss_ctc 11.917768 loss_rnnt 7.483363 hw_loss 0.094164 lr 0.00040029 rank 7
2023-02-22 11:44:26,966 DEBUG TRAIN Batch 18/5900 loss 6.980576 loss_att 10.059026 loss_ctc 9.353968 loss_rnnt 6.008130 hw_loss 0.075568 lr 0.00040030 rank 6
2023-02-22 11:44:26,968 DEBUG TRAIN Batch 18/5900 loss 9.225693 loss_att 11.240282 loss_ctc 11.478393 loss_rnnt 8.496289 hw_loss 0.048984 lr 0.00040025 rank 2
2023-02-22 11:44:26,968 DEBUG TRAIN Batch 18/5900 loss 6.706711 loss_att 9.160389 loss_ctc 7.614409 loss_rnnt 6.041521 hw_loss 0.100178 lr 0.00040031 rank 0
2023-02-22 11:44:26,974 DEBUG TRAIN Batch 18/5900 loss 14.035663 loss_att 17.987978 loss_ctc 26.227303 loss_rnnt 11.604570 hw_loss 0.028269 lr 0.00040030 rank 5
2023-02-22 11:44:26,974 DEBUG TRAIN Batch 18/5900 loss 3.800976 loss_att 8.433477 loss_ctc 3.758516 loss_rnnt 2.819546 hw_loss 0.113609 lr 0.00040023 rank 3
2023-02-22 11:45:44,959 DEBUG TRAIN Batch 18/6000 loss 13.784645 loss_att 14.559584 loss_ctc 18.975140 loss_rnnt 12.871065 hw_loss 0.124737 lr 0.00040017 rank 5
2023-02-22 11:45:44,959 DEBUG TRAIN Batch 18/6000 loss 2.835769 loss_att 5.691316 loss_ctc 4.151901 loss_rnnt 2.026268 hw_loss 0.117950 lr 0.00040016 rank 4
2023-02-22 11:45:44,961 DEBUG TRAIN Batch 18/6000 loss 16.436487 loss_att 16.751211 loss_ctc 18.019760 loss_rnnt 16.129597 hw_loss 0.061580 lr 0.00040018 rank 0
2023-02-22 11:45:44,961 DEBUG TRAIN Batch 18/6000 loss 15.289102 loss_att 16.968777 loss_ctc 16.465729 loss_rnnt 14.752947 hw_loss 0.081252 lr 0.00040016 rank 7
2023-02-22 11:45:44,965 DEBUG TRAIN Batch 18/6000 loss 11.610968 loss_att 15.030902 loss_ctc 16.215866 loss_rnnt 10.273540 hw_loss 0.073976 lr 0.00040012 rank 2
2023-02-22 11:45:44,984 DEBUG TRAIN Batch 18/6000 loss 23.792086 loss_att 25.726807 loss_ctc 27.542496 loss_rnnt 22.865570 hw_loss 0.074093 lr 0.00040019 rank 1
2023-02-22 11:45:44,990 DEBUG TRAIN Batch 18/6000 loss 10.313934 loss_att 11.829639 loss_ctc 12.955667 loss_rnnt 9.602407 hw_loss 0.105291 lr 0.00040017 rank 6
2023-02-22 11:45:45,001 DEBUG TRAIN Batch 18/6000 loss 12.780773 loss_att 14.491606 loss_ctc 14.916824 loss_rnnt 12.150592 hw_loss 0.006017 lr 0.00040010 rank 3
2023-02-22 11:47:01,881 DEBUG TRAIN Batch 18/6100 loss 10.629094 loss_att 13.524895 loss_ctc 13.670437 loss_rnnt 9.568820 hw_loss 0.141753 lr 0.00040006 rank 0
2023-02-22 11:47:01,887 DEBUG TRAIN Batch 18/6100 loss 12.132165 loss_att 14.604746 loss_ctc 16.254410 loss_rnnt 10.993904 hw_loss 0.176461 lr 0.00040005 rank 5
2023-02-22 11:47:01,889 DEBUG TRAIN Batch 18/6100 loss 13.231781 loss_att 14.921495 loss_ctc 18.825056 loss_rnnt 12.069584 hw_loss 0.147157 lr 0.00040004 rank 6
2023-02-22 11:47:01,892 DEBUG TRAIN Batch 18/6100 loss 13.276043 loss_att 19.908447 loss_ctc 21.133669 loss_rnnt 10.867300 hw_loss 0.064835 lr 0.00039997 rank 3
2023-02-22 11:47:01,893 DEBUG TRAIN Batch 18/6100 loss 10.594079 loss_att 13.338593 loss_ctc 16.310448 loss_rnnt 9.233750 hw_loss 0.092332 lr 0.00040003 rank 4
2023-02-22 11:47:01,893 DEBUG TRAIN Batch 18/6100 loss 10.528714 loss_att 12.604748 loss_ctc 14.298985 loss_rnnt 9.546289 hw_loss 0.120966 lr 0.00040003 rank 7
2023-02-22 11:47:01,894 DEBUG TRAIN Batch 18/6100 loss 6.267287 loss_att 9.225977 loss_ctc 10.663590 loss_rnnt 5.017570 hw_loss 0.134635 lr 0.00040006 rank 1
2023-02-22 11:47:01,949 DEBUG TRAIN Batch 18/6100 loss 5.405680 loss_att 7.354587 loss_ctc 8.609982 loss_rnnt 4.533371 hw_loss 0.103664 lr 0.00039999 rank 2
2023-02-22 11:48:15,157 DEBUG TRAIN Batch 18/6200 loss 12.959467 loss_att 16.134666 loss_ctc 17.110935 loss_rnnt 11.723864 hw_loss 0.088186 lr 0.00039990 rank 4
2023-02-22 11:48:15,163 DEBUG TRAIN Batch 18/6200 loss 8.661107 loss_att 10.983870 loss_ctc 11.666521 loss_rnnt 7.712018 hw_loss 0.157152 lr 0.00039992 rank 6
2023-02-22 11:48:15,164 DEBUG TRAIN Batch 18/6200 loss 5.417410 loss_att 8.519440 loss_ctc 7.128459 loss_rnnt 4.472764 hw_loss 0.180188 lr 0.00039994 rank 1
2023-02-22 11:48:15,165 DEBUG TRAIN Batch 18/6200 loss 10.509144 loss_att 11.547485 loss_ctc 13.738315 loss_rnnt 9.813679 hw_loss 0.107327 lr 0.00039993 rank 0
2023-02-22 11:48:15,168 DEBUG TRAIN Batch 18/6200 loss 9.149527 loss_att 12.117210 loss_ctc 12.790823 loss_rnnt 8.021295 hw_loss 0.092229 lr 0.00039986 rank 2
2023-02-22 11:48:15,171 DEBUG TRAIN Batch 18/6200 loss 8.562002 loss_att 10.178946 loss_ctc 10.078751 loss_rnnt 8.008460 hw_loss 0.052352 lr 0.00039990 rank 7
2023-02-22 11:48:15,173 DEBUG TRAIN Batch 18/6200 loss 25.329664 loss_att 25.169247 loss_ctc 33.465141 loss_rnnt 24.216209 hw_loss 0.114018 lr 0.00039992 rank 5
2023-02-22 11:48:15,177 DEBUG TRAIN Batch 18/6200 loss 3.721437 loss_att 8.173647 loss_ctc 5.877575 loss_rnnt 2.469616 hw_loss 0.138549 lr 0.00039984 rank 3
2023-02-22 11:49:31,390 DEBUG TRAIN Batch 18/6300 loss 10.795717 loss_att 14.905563 loss_ctc 18.523893 loss_rnnt 8.828268 hw_loss 0.215730 lr 0.00039977 rank 4
2023-02-22 11:49:31,395 DEBUG TRAIN Batch 18/6300 loss 12.339301 loss_att 16.953875 loss_ctc 16.317650 loss_rnnt 10.840711 hw_loss 0.084804 lr 0.00039979 rank 5
2023-02-22 11:49:31,396 DEBUG TRAIN Batch 18/6300 loss 14.001097 loss_att 16.384583 loss_ctc 20.522099 loss_rnnt 12.573926 hw_loss 0.151888 lr 0.00039980 rank 0
2023-02-22 11:49:31,396 DEBUG TRAIN Batch 18/6300 loss 8.886183 loss_att 9.110615 loss_ctc 11.532245 loss_rnnt 8.363764 hw_loss 0.233858 lr 0.00039977 rank 7
2023-02-22 11:49:31,399 DEBUG TRAIN Batch 18/6300 loss 14.686870 loss_att 18.611279 loss_ctc 19.865885 loss_rnnt 13.151991 hw_loss 0.111491 lr 0.00039972 rank 3
2023-02-22 11:49:31,399 DEBUG TRAIN Batch 18/6300 loss 5.732453 loss_att 9.984569 loss_ctc 6.438752 loss_rnnt 4.706106 hw_loss 0.153282 lr 0.00039979 rank 6
2023-02-22 11:49:31,400 DEBUG TRAIN Batch 18/6300 loss 12.196472 loss_att 16.217669 loss_ctc 17.360252 loss_rnnt 10.600332 hw_loss 0.193867 lr 0.00039981 rank 1
2023-02-22 11:49:31,401 DEBUG TRAIN Batch 18/6300 loss 6.332182 loss_att 7.568878 loss_ctc 7.542772 loss_rnnt 5.867251 hw_loss 0.105336 lr 0.00039973 rank 2
2023-02-22 11:50:49,445 DEBUG TRAIN Batch 18/6400 loss 8.600937 loss_att 10.875834 loss_ctc 10.297128 loss_rnnt 7.866586 hw_loss 0.099775 lr 0.00039965 rank 7
2023-02-22 11:50:49,446 DEBUG TRAIN Batch 18/6400 loss 8.813927 loss_att 8.230528 loss_ctc 10.929585 loss_rnnt 8.577893 hw_loss 0.132423 lr 0.00039965 rank 4
2023-02-22 11:50:49,446 DEBUG TRAIN Batch 18/6400 loss 7.669631 loss_att 9.013429 loss_ctc 9.284666 loss_rnnt 7.123990 hw_loss 0.115391 lr 0.00039966 rank 6
2023-02-22 11:50:49,447 DEBUG TRAIN Batch 18/6400 loss 10.171494 loss_att 13.660442 loss_ctc 17.348816 loss_rnnt 8.480742 hw_loss 0.067472 lr 0.00039967 rank 0
2023-02-22 11:50:49,448 DEBUG TRAIN Batch 18/6400 loss 7.489742 loss_att 9.748286 loss_ctc 10.941283 loss_rnnt 6.495792 hw_loss 0.153817 lr 0.00039966 rank 5
2023-02-22 11:50:49,452 DEBUG TRAIN Batch 18/6400 loss 5.214969 loss_att 10.136080 loss_ctc 6.664412 loss_rnnt 3.937714 hw_loss 0.187075 lr 0.00039961 rank 2
2023-02-22 11:50:49,453 DEBUG TRAIN Batch 18/6400 loss 14.917135 loss_att 18.638756 loss_ctc 18.547009 loss_rnnt 13.662796 hw_loss 0.048808 lr 0.00039959 rank 3
2023-02-22 11:50:49,455 DEBUG TRAIN Batch 18/6400 loss 11.603682 loss_att 12.037081 loss_ctc 15.022808 loss_rnnt 11.016009 hw_loss 0.084580 lr 0.00039968 rank 1
2023-02-22 11:52:04,342 DEBUG TRAIN Batch 18/6500 loss 10.224748 loss_att 11.469347 loss_ctc 19.803940 loss_rnnt 8.689211 hw_loss 0.017609 lr 0.00039954 rank 0
2023-02-22 11:52:04,345 DEBUG TRAIN Batch 18/6500 loss 3.858678 loss_att 6.983530 loss_ctc 7.257030 loss_rnnt 2.717028 hw_loss 0.119187 lr 0.00039955 rank 1
2023-02-22 11:52:04,349 DEBUG TRAIN Batch 18/6500 loss 8.185536 loss_att 10.554130 loss_ctc 10.583469 loss_rnnt 7.369184 hw_loss 0.042957 lr 0.00039953 rank 5
2023-02-22 11:52:04,349 DEBUG TRAIN Batch 18/6500 loss 7.580244 loss_att 11.502046 loss_ctc 10.745910 loss_rnnt 6.331188 hw_loss 0.079886 lr 0.00039953 rank 6
2023-02-22 11:52:04,350 DEBUG TRAIN Batch 18/6500 loss 8.396601 loss_att 10.936048 loss_ctc 11.566631 loss_rnnt 7.424985 hw_loss 0.076978 lr 0.00039952 rank 7
2023-02-22 11:52:04,351 DEBUG TRAIN Batch 18/6500 loss 9.599438 loss_att 12.607032 loss_ctc 11.286180 loss_rnnt 8.710124 hw_loss 0.117930 lr 0.00039952 rank 4
2023-02-22 11:52:04,354 DEBUG TRAIN Batch 18/6500 loss 13.251667 loss_att 15.852201 loss_ctc 18.956083 loss_rnnt 11.879356 hw_loss 0.171779 lr 0.00039946 rank 3
2023-02-22 11:52:04,357 DEBUG TRAIN Batch 18/6500 loss 10.182677 loss_att 12.036316 loss_ctc 20.256893 loss_rnnt 8.392345 hw_loss 0.143203 lr 0.00039948 rank 2
2023-02-22 11:53:19,972 DEBUG TRAIN Batch 18/6600 loss 7.175527 loss_att 10.481747 loss_ctc 8.613625 loss_rnnt 6.256183 hw_loss 0.124412 lr 0.00039942 rank 0
2023-02-22 11:53:19,978 DEBUG TRAIN Batch 18/6600 loss 20.957653 loss_att 23.145626 loss_ctc 24.087097 loss_rnnt 20.065863 hw_loss 0.069255 lr 0.00039939 rank 4
2023-02-22 11:53:19,977 DEBUG TRAIN Batch 18/6600 loss 6.185503 loss_att 9.937230 loss_ctc 8.359215 loss_rnnt 5.094725 hw_loss 0.094884 lr 0.00039941 rank 5
2023-02-22 11:53:19,978 DEBUG TRAIN Batch 18/6600 loss 5.482761 loss_att 8.529598 loss_ctc 7.937223 loss_rnnt 4.502894 hw_loss 0.081071 lr 0.00039943 rank 1
2023-02-22 11:53:19,982 DEBUG TRAIN Batch 18/6600 loss 16.668036 loss_att 21.109457 loss_ctc 27.524178 loss_rnnt 14.246706 hw_loss 0.160424 lr 0.00039939 rank 7
2023-02-22 11:53:19,982 DEBUG TRAIN Batch 18/6600 loss 13.349296 loss_att 14.931826 loss_ctc 18.580133 loss_rnnt 12.228529 hw_loss 0.200281 lr 0.00039933 rank 3
2023-02-22 11:53:19,985 DEBUG TRAIN Batch 18/6600 loss 8.209968 loss_att 10.296599 loss_ctc 15.850384 loss_rnnt 6.738857 hw_loss 0.065741 lr 0.00039940 rank 6
2023-02-22 11:53:19,985 DEBUG TRAIN Batch 18/6600 loss 6.084559 loss_att 9.068029 loss_ctc 7.543439 loss_rnnt 5.184639 hw_loss 0.203830 lr 0.00039935 rank 2
2023-02-22 11:54:36,841 DEBUG TRAIN Batch 18/6700 loss 5.429306 loss_att 10.010357 loss_ctc 6.663276 loss_rnnt 4.298600 hw_loss 0.093686 lr 0.00039928 rank 5
2023-02-22 11:54:36,845 DEBUG TRAIN Batch 18/6700 loss 12.058890 loss_att 16.121099 loss_ctc 20.763088 loss_rnnt 10.022758 hw_loss 0.118371 lr 0.00039926 rank 4
2023-02-22 11:54:36,848 DEBUG TRAIN Batch 18/6700 loss 18.346010 loss_att 23.931986 loss_ctc 28.466858 loss_rnnt 15.825307 hw_loss 0.101368 lr 0.00039922 rank 2
2023-02-22 11:54:36,848 DEBUG TRAIN Batch 18/6700 loss 12.723895 loss_att 17.615799 loss_ctc 17.695507 loss_rnnt 11.048307 hw_loss 0.064360 lr 0.00039928 rank 6
2023-02-22 11:54:36,849 DEBUG TRAIN Batch 18/6700 loss 7.983432 loss_att 12.497311 loss_ctc 15.796656 loss_rnnt 6.000475 hw_loss 0.072033 lr 0.00039926 rank 7
2023-02-22 11:54:36,850 DEBUG TRAIN Batch 18/6700 loss 15.668263 loss_att 20.979683 loss_ctc 22.782887 loss_rnnt 13.652164 hw_loss 0.009748 lr 0.00039929 rank 0
2023-02-22 11:54:36,853 DEBUG TRAIN Batch 18/6700 loss 13.695400 loss_att 17.256981 loss_ctc 19.849960 loss_rnnt 12.151213 hw_loss 0.021120 lr 0.00039921 rank 3
2023-02-22 11:54:36,854 DEBUG TRAIN Batch 18/6700 loss 14.465202 loss_att 17.132149 loss_ctc 17.184166 loss_rnnt 13.514702 hw_loss 0.102344 lr 0.00039930 rank 1
2023-02-22 11:55:53,786 DEBUG TRAIN Batch 18/6800 loss 8.899658 loss_att 11.695555 loss_ctc 12.706439 loss_rnnt 7.784825 hw_loss 0.090154 lr 0.00039914 rank 7
2023-02-22 11:55:53,788 DEBUG TRAIN Batch 18/6800 loss 10.762946 loss_att 13.125540 loss_ctc 13.456659 loss_rnnt 9.902797 hw_loss 0.053379 lr 0.00039917 rank 1
2023-02-22 11:55:53,789 DEBUG TRAIN Batch 18/6800 loss 3.661918 loss_att 6.222300 loss_ctc 6.367057 loss_rnnt 2.731390 hw_loss 0.108312 lr 0.00039916 rank 0
2023-02-22 11:55:53,790 DEBUG TRAIN Batch 18/6800 loss 8.754124 loss_att 12.829382 loss_ctc 16.659134 loss_rnnt 6.877582 hw_loss 0.014043 lr 0.00039915 rank 5
2023-02-22 11:55:53,790 DEBUG TRAIN Batch 18/6800 loss 12.237556 loss_att 14.132782 loss_ctc 16.361830 loss_rnnt 11.229270 hw_loss 0.148756 lr 0.00039914 rank 4
2023-02-22 11:55:53,792 DEBUG TRAIN Batch 18/6800 loss 8.825988 loss_att 11.328670 loss_ctc 11.318846 loss_rnnt 7.990668 hw_loss 0.004504 lr 0.00039910 rank 2
2023-02-22 11:55:53,793 DEBUG TRAIN Batch 18/6800 loss 9.702883 loss_att 13.008106 loss_ctc 17.225517 loss_rnnt 7.959111 hw_loss 0.149453 lr 0.00039908 rank 3
2023-02-22 11:55:53,836 DEBUG TRAIN Batch 18/6800 loss 10.798669 loss_att 12.829343 loss_ctc 11.984860 loss_rnnt 10.188203 hw_loss 0.086573 lr 0.00039915 rank 6
2023-02-22 11:57:09,772 DEBUG TRAIN Batch 18/6900 loss 7.092498 loss_att 8.852385 loss_ctc 7.529506 loss_rnnt 6.666223 hw_loss 0.030056 lr 0.00039901 rank 4
2023-02-22 11:57:09,774 DEBUG TRAIN Batch 18/6900 loss 8.557853 loss_att 8.433015 loss_ctc 10.025390 loss_rnnt 8.306047 hw_loss 0.152063 lr 0.00039901 rank 7
2023-02-22 11:57:09,776 DEBUG TRAIN Batch 18/6900 loss 18.128958 loss_att 20.879295 loss_ctc 23.755985 loss_rnnt 16.761728 hw_loss 0.125416 lr 0.00039897 rank 2
2023-02-22 11:57:09,777 DEBUG TRAIN Batch 18/6900 loss 3.771902 loss_att 6.609048 loss_ctc 5.990146 loss_rnnt 2.835233 hw_loss 0.137763 lr 0.00039903 rank 5
2023-02-22 11:57:09,779 DEBUG TRAIN Batch 18/6900 loss 9.853149 loss_att 11.355766 loss_ctc 14.548879 loss_rnnt 8.862378 hw_loss 0.120281 lr 0.00039903 rank 0
2023-02-22 11:57:09,781 DEBUG TRAIN Batch 18/6900 loss 9.035298 loss_att 13.095029 loss_ctc 15.086437 loss_rnnt 7.333211 hw_loss 0.156229 lr 0.00039904 rank 1
2023-02-22 11:57:09,788 DEBUG TRAIN Batch 18/6900 loss 5.463110 loss_att 8.959667 loss_ctc 6.858694 loss_rnnt 4.500540 hw_loss 0.144714 lr 0.00039902 rank 6
2023-02-22 11:57:09,823 DEBUG TRAIN Batch 18/6900 loss 11.163312 loss_att 12.354334 loss_ctc 13.714006 loss_rnnt 10.500159 hw_loss 0.159104 lr 0.00039895 rank 3
2023-02-22 11:58:27,074 DEBUG TRAIN Batch 18/7000 loss 12.574876 loss_att 13.104670 loss_ctc 17.310658 loss_rnnt 11.774543 hw_loss 0.118008 lr 0.00039888 rank 4
2023-02-22 11:58:27,076 DEBUG TRAIN Batch 18/7000 loss 17.840813 loss_att 18.727118 loss_ctc 20.670818 loss_rnnt 17.275684 hw_loss 0.019750 lr 0.00039890 rank 5
2023-02-22 11:58:27,076 DEBUG TRAIN Batch 18/7000 loss 6.426053 loss_att 6.839658 loss_ctc 8.277243 loss_rnnt 5.982971 hw_loss 0.212879 lr 0.00039891 rank 0
2023-02-22 11:58:27,079 DEBUG TRAIN Batch 18/7000 loss 11.495472 loss_att 13.156597 loss_ctc 18.510166 loss_rnnt 10.136912 hw_loss 0.170702 lr 0.00039888 rank 7
2023-02-22 11:58:27,082 DEBUG TRAIN Batch 18/7000 loss 9.319800 loss_att 11.352527 loss_ctc 12.358792 loss_rnnt 8.440884 hw_loss 0.125948 lr 0.00039892 rank 1
2023-02-22 11:58:27,084 DEBUG TRAIN Batch 18/7000 loss 7.033221 loss_att 6.740355 loss_ctc 9.878521 loss_rnnt 6.618447 hw_loss 0.176200 lr 0.00039884 rank 2
2023-02-22 11:58:27,107 DEBUG TRAIN Batch 18/7000 loss 8.274864 loss_att 8.457565 loss_ctc 11.097610 loss_rnnt 7.763757 hw_loss 0.184126 lr 0.00039883 rank 3
2023-02-22 11:58:27,128 DEBUG TRAIN Batch 18/7000 loss 15.108937 loss_att 12.992151 loss_ctc 24.487082 loss_rnnt 14.256794 hw_loss 0.047026 lr 0.00039890 rank 6
2023-02-22 11:59:46,618 DEBUG TRAIN Batch 18/7100 loss 4.213413 loss_att 7.354308 loss_ctc 4.857686 loss_rnnt 3.453423 hw_loss 0.086076 lr 0.00039876 rank 7
2023-02-22 11:59:46,617 DEBUG TRAIN Batch 18/7100 loss 11.244769 loss_att 14.952275 loss_ctc 17.796738 loss_rnnt 9.590071 hw_loss 0.074250 lr 0.00039878 rank 0
2023-02-22 11:59:46,619 DEBUG TRAIN Batch 18/7100 loss 7.810731 loss_att 10.468030 loss_ctc 11.572018 loss_rnnt 6.711459 hw_loss 0.124327 lr 0.00039876 rank 4
2023-02-22 11:59:46,623 DEBUG TRAIN Batch 18/7100 loss 7.593650 loss_att 8.917565 loss_ctc 8.406450 loss_rnnt 7.168612 hw_loss 0.097280 lr 0.00039877 rank 5
2023-02-22 11:59:46,625 DEBUG TRAIN Batch 18/7100 loss 8.230490 loss_att 8.849481 loss_ctc 9.427794 loss_rnnt 7.926623 hw_loss 0.038302 lr 0.00039877 rank 6
2023-02-22 11:59:46,634 DEBUG TRAIN Batch 18/7100 loss 4.611204 loss_att 6.960132 loss_ctc 5.133522 loss_rnnt 4.030515 hw_loss 0.077365 lr 0.00039872 rank 2
2023-02-22 11:59:46,639 DEBUG TRAIN Batch 18/7100 loss 10.391747 loss_att 15.044933 loss_ctc 12.529563 loss_rnnt 9.112739 hw_loss 0.118745 lr 0.00039870 rank 3
2023-02-22 11:59:46,682 DEBUG TRAIN Batch 18/7100 loss 8.061888 loss_att 10.736956 loss_ctc 9.731929 loss_rnnt 7.255600 hw_loss 0.091130 lr 0.00039879 rank 1
2023-02-22 12:01:03,445 DEBUG TRAIN Batch 18/7200 loss 14.021233 loss_att 19.806162 loss_ctc 19.175348 loss_rnnt 12.101161 hw_loss 0.142256 lr 0.00039864 rank 5
2023-02-22 12:01:03,451 DEBUG TRAIN Batch 18/7200 loss 17.366972 loss_att 20.863735 loss_ctc 26.766159 loss_rnnt 15.363551 hw_loss 0.095332 lr 0.00039863 rank 7
2023-02-22 12:01:03,453 DEBUG TRAIN Batch 18/7200 loss 13.291417 loss_att 18.413805 loss_ctc 17.212082 loss_rnnt 11.652437 hw_loss 0.172025 lr 0.00039865 rank 0
2023-02-22 12:01:03,454 DEBUG TRAIN Batch 18/7200 loss 4.890110 loss_att 10.177942 loss_ctc 8.298702 loss_rnnt 3.330940 hw_loss 0.088358 lr 0.00039864 rank 6
2023-02-22 12:01:03,455 DEBUG TRAIN Batch 18/7200 loss 7.479946 loss_att 11.284830 loss_ctc 9.050842 loss_rnnt 6.448364 hw_loss 0.114660 lr 0.00039863 rank 4
2023-02-22 12:01:03,455 DEBUG TRAIN Batch 18/7200 loss 14.522021 loss_att 16.629429 loss_ctc 16.080521 loss_rnnt 13.842731 hw_loss 0.093767 lr 0.00039866 rank 1
2023-02-22 12:01:03,457 DEBUG TRAIN Batch 18/7200 loss 22.191372 loss_att 22.111109 loss_ctc 29.341019 loss_rnnt 21.189215 hw_loss 0.121738 lr 0.00039859 rank 2
2023-02-22 12:01:03,496 DEBUG TRAIN Batch 18/7200 loss 9.856347 loss_att 12.098655 loss_ctc 15.554895 loss_rnnt 8.596796 hw_loss 0.096157 lr 0.00039857 rank 3
2023-02-22 12:02:17,943 DEBUG TRAIN Batch 18/7300 loss 11.238715 loss_att 13.478786 loss_ctc 15.844038 loss_rnnt 10.106423 hw_loss 0.131688 lr 0.00039852 rank 6
2023-02-22 12:02:17,945 DEBUG TRAIN Batch 18/7300 loss 7.158991 loss_att 9.236746 loss_ctc 9.254786 loss_rnnt 6.440242 hw_loss 0.044548 lr 0.00039852 rank 5
2023-02-22 12:02:17,945 DEBUG TRAIN Batch 18/7300 loss 10.366682 loss_att 15.003099 loss_ctc 16.645609 loss_rnnt 8.549909 hw_loss 0.098061 lr 0.00039850 rank 7
2023-02-22 12:02:17,946 DEBUG TRAIN Batch 18/7300 loss 4.378385 loss_att 9.027644 loss_ctc 5.739044 loss_rnnt 3.257559 hw_loss 0.017911 lr 0.00039854 rank 1
2023-02-22 12:02:17,946 DEBUG TRAIN Batch 18/7300 loss 8.294861 loss_att 10.171951 loss_ctc 12.451076 loss_rnnt 7.306951 hw_loss 0.109368 lr 0.00039844 rank 3
2023-02-22 12:02:17,965 DEBUG TRAIN Batch 18/7300 loss 11.814302 loss_att 14.424928 loss_ctc 17.420301 loss_rnnt 10.513532 hw_loss 0.058460 lr 0.00039853 rank 0
2023-02-22 12:02:17,969 DEBUG TRAIN Batch 18/7300 loss 13.894450 loss_att 17.488934 loss_ctc 19.045746 loss_rnnt 12.446175 hw_loss 0.079763 lr 0.00039850 rank 4
2023-02-22 12:02:17,992 DEBUG TRAIN Batch 18/7300 loss 6.155900 loss_att 9.207157 loss_ctc 10.515893 loss_rnnt 4.944982 hw_loss 0.036252 lr 0.00039846 rank 2
2023-02-22 12:03:34,141 DEBUG TRAIN Batch 18/7400 loss 7.207273 loss_att 9.860210 loss_ctc 8.257376 loss_rnnt 6.503607 hw_loss 0.061997 lr 0.00039840 rank 0
2023-02-22 12:03:34,141 DEBUG TRAIN Batch 18/7400 loss 19.864006 loss_att 25.176220 loss_ctc 23.728558 loss_rnnt 18.226772 hw_loss 0.111593 lr 0.00039839 rank 5
2023-02-22 12:03:34,143 DEBUG TRAIN Batch 18/7400 loss 9.561340 loss_att 12.921180 loss_ctc 14.265738 loss_rnnt 8.214336 hw_loss 0.089594 lr 0.00039838 rank 4
2023-02-22 12:03:34,148 DEBUG TRAIN Batch 18/7400 loss 13.753967 loss_att 19.770586 loss_ctc 23.744808 loss_rnnt 11.132011 hw_loss 0.162224 lr 0.00039838 rank 7
2023-02-22 12:03:34,149 DEBUG TRAIN Batch 18/7400 loss 7.640323 loss_att 9.982167 loss_ctc 12.247928 loss_rnnt 6.454691 hw_loss 0.192968 lr 0.00039834 rank 2
2023-02-22 12:03:34,150 DEBUG TRAIN Batch 18/7400 loss 7.691761 loss_att 10.601250 loss_ctc 10.684919 loss_rnnt 6.671178 hw_loss 0.074244 lr 0.00039839 rank 6
2023-02-22 12:03:34,153 DEBUG TRAIN Batch 18/7400 loss 10.182695 loss_att 12.921711 loss_ctc 12.827953 loss_rnnt 9.268549 hw_loss 0.025577 lr 0.00039841 rank 1
2023-02-22 12:03:34,200 DEBUG TRAIN Batch 18/7400 loss 9.688206 loss_att 10.578030 loss_ctc 11.878292 loss_rnnt 9.184883 hw_loss 0.062526 lr 0.00039832 rank 3
2023-02-22 12:04:51,708 DEBUG TRAIN Batch 18/7500 loss 9.228703 loss_att 11.424151 loss_ctc 14.930168 loss_rnnt 7.963786 hw_loss 0.123060 lr 0.00039827 rank 0
2023-02-22 12:04:51,707 DEBUG TRAIN Batch 18/7500 loss 8.725510 loss_att 15.955359 loss_ctc 12.553392 loss_rnnt 6.707063 hw_loss 0.116425 lr 0.00039827 rank 5
2023-02-22 12:04:51,707 DEBUG TRAIN Batch 18/7500 loss 11.691682 loss_att 14.138617 loss_ctc 13.938066 loss_rnnt 10.865152 hw_loss 0.070545 lr 0.00039825 rank 4
2023-02-22 12:04:51,708 DEBUG TRAIN Batch 18/7500 loss 10.548841 loss_att 11.454593 loss_ctc 14.758173 loss_rnnt 9.744025 hw_loss 0.117037 lr 0.00039825 rank 7
2023-02-22 12:04:51,711 DEBUG TRAIN Batch 18/7500 loss 12.388610 loss_att 14.302694 loss_ctc 15.400717 loss_rnnt 11.563025 hw_loss 0.077164 lr 0.00039828 rank 1
2023-02-22 12:04:51,717 DEBUG TRAIN Batch 18/7500 loss 9.084628 loss_att 12.362540 loss_ctc 10.856039 loss_rnnt 8.129851 hw_loss 0.118138 lr 0.00039819 rank 3
2023-02-22 12:04:51,719 DEBUG TRAIN Batch 18/7500 loss 7.084701 loss_att 8.598308 loss_ctc 8.877894 loss_rnnt 6.459145 hw_loss 0.157018 lr 0.00039821 rank 2
2023-02-22 12:04:51,768 DEBUG TRAIN Batch 18/7500 loss 7.304677 loss_att 9.930029 loss_ctc 11.511034 loss_rnnt 6.145281 hw_loss 0.137773 lr 0.00039826 rank 6
2023-02-22 12:06:08,418 DEBUG TRAIN Batch 18/7600 loss 2.829401 loss_att 5.245548 loss_ctc 4.513972 loss_rnnt 2.080600 hw_loss 0.076805 lr 0.00039815 rank 0
2023-02-22 12:06:08,418 DEBUG TRAIN Batch 18/7600 loss 10.329526 loss_att 14.919386 loss_ctc 14.361667 loss_rnnt 8.809422 hw_loss 0.120961 lr 0.00039812 rank 7
2023-02-22 12:06:08,419 DEBUG TRAIN Batch 18/7600 loss 7.630538 loss_att 12.870048 loss_ctc 11.140210 loss_rnnt 6.058717 hw_loss 0.104930 lr 0.00039814 rank 5
2023-02-22 12:06:08,419 DEBUG TRAIN Batch 18/7600 loss 5.374018 loss_att 8.213112 loss_ctc 6.922247 loss_rnnt 4.553592 hw_loss 0.086580 lr 0.00039814 rank 6
2023-02-22 12:06:08,420 DEBUG TRAIN Batch 18/7600 loss 12.231515 loss_att 12.727476 loss_ctc 16.479853 loss_rnnt 11.510956 hw_loss 0.102979 lr 0.00039812 rank 4
2023-02-22 12:06:08,423 DEBUG TRAIN Batch 18/7600 loss 10.014367 loss_att 12.620538 loss_ctc 14.008238 loss_rnnt 8.870728 hw_loss 0.168542 lr 0.00039807 rank 3
2023-02-22 12:06:08,425 DEBUG TRAIN Batch 18/7600 loss 11.029084 loss_att 14.987625 loss_ctc 18.270206 loss_rnnt 9.216989 hw_loss 0.102944 lr 0.00039816 rank 1
2023-02-22 12:06:08,425 DEBUG TRAIN Batch 18/7600 loss 11.136591 loss_att 15.946253 loss_ctc 14.960392 loss_rnnt 9.627201 hw_loss 0.070531 lr 0.00039808 rank 2
2023-02-22 12:07:24,983 DEBUG TRAIN Batch 18/7700 loss 7.137817 loss_att 11.750093 loss_ctc 10.674640 loss_rnnt 5.698454 hw_loss 0.084997 lr 0.00039796 rank 2
2023-02-22 12:07:24,984 DEBUG TRAIN Batch 18/7700 loss 6.817489 loss_att 6.565631 loss_ctc 9.084056 loss_rnnt 6.485344 hw_loss 0.150575 lr 0.00039800 rank 4
2023-02-22 12:07:24,985 DEBUG TRAIN Batch 18/7700 loss 2.829015 loss_att 3.836798 loss_ctc 3.594902 loss_rnnt 2.471304 hw_loss 0.101317 lr 0.00039803 rank 1
2023-02-22 12:07:24,987 DEBUG TRAIN Batch 18/7700 loss 16.062416 loss_att 19.052601 loss_ctc 20.367157 loss_rnnt 14.828058 hw_loss 0.116918 lr 0.00039802 rank 0
2023-02-22 12:07:24,987 DEBUG TRAIN Batch 18/7700 loss 7.816508 loss_att 9.709332 loss_ctc 10.317530 loss_rnnt 7.022046 hw_loss 0.154550 lr 0.00039801 rank 5
2023-02-22 12:07:24,987 DEBUG TRAIN Batch 18/7700 loss 8.877962 loss_att 10.923235 loss_ctc 11.517673 loss_rnnt 8.060132 hw_loss 0.106526 lr 0.00039800 rank 7
2023-02-22 12:07:24,988 DEBUG TRAIN Batch 18/7700 loss 8.934037 loss_att 10.579927 loss_ctc 11.455270 loss_rnnt 8.183281 hw_loss 0.160150 lr 0.00039801 rank 6
2023-02-22 12:07:24,991 DEBUG TRAIN Batch 18/7700 loss 11.263780 loss_att 13.290731 loss_ctc 15.972430 loss_rnnt 10.166611 hw_loss 0.119922 lr 0.00039794 rank 3
2023-02-22 12:08:41,869 DEBUG TRAIN Batch 18/7800 loss 7.546941 loss_att 11.384953 loss_ctc 11.595263 loss_rnnt 6.194864 hw_loss 0.083810 lr 0.00039787 rank 7
2023-02-22 12:08:41,872 DEBUG TRAIN Batch 18/7800 loss 5.511292 loss_att 9.755157 loss_ctc 6.716567 loss_rnnt 4.482384 hw_loss 0.036432 lr 0.00039781 rank 3
2023-02-22 12:08:41,875 DEBUG TRAIN Batch 18/7800 loss 5.574160 loss_att 9.622811 loss_ctc 10.222980 loss_rnnt 4.025228 hw_loss 0.223798 lr 0.00039783 rank 2
2023-02-22 12:08:41,877 DEBUG TRAIN Batch 18/7800 loss 4.345354 loss_att 6.267142 loss_ctc 4.603892 loss_rnnt 3.886594 hw_loss 0.074869 lr 0.00039789 rank 5
2023-02-22 12:08:41,880 DEBUG TRAIN Batch 18/7800 loss 15.057519 loss_att 18.626385 loss_ctc 17.610775 loss_rnnt 13.973437 hw_loss 0.056014 lr 0.00039788 rank 6
2023-02-22 12:08:41,879 DEBUG TRAIN Batch 18/7800 loss 8.659328 loss_att 11.374004 loss_ctc 18.022274 loss_rnnt 6.851139 hw_loss 0.031613 lr 0.00039787 rank 4
2023-02-22 12:08:41,881 DEBUG TRAIN Batch 18/7800 loss 12.830150 loss_att 13.054612 loss_ctc 12.142524 loss_rnnt 12.856818 hw_loss 0.037729 lr 0.00039790 rank 0
2023-02-22 12:08:41,881 DEBUG TRAIN Batch 18/7800 loss 9.344660 loss_att 11.806204 loss_ctc 14.767550 loss_rnnt 8.053452 hw_loss 0.142211 lr 0.00039790 rank 1
2023-02-22 12:09:58,421 DEBUG TRAIN Batch 18/7900 loss 5.955544 loss_att 9.547308 loss_ctc 8.016552 loss_rnnt 4.926461 hw_loss 0.067366 lr 0.00039774 rank 7
2023-02-22 12:09:58,424 DEBUG TRAIN Batch 18/7900 loss 9.913846 loss_att 15.140638 loss_ctc 16.626476 loss_rnnt 7.888775 hw_loss 0.158803 lr 0.00039776 rank 5
2023-02-22 12:09:58,426 DEBUG TRAIN Batch 18/7900 loss 7.508808 loss_att 10.944431 loss_ctc 9.525436 loss_rnnt 6.536513 hw_loss 0.030536 lr 0.00039777 rank 0
2023-02-22 12:09:58,427 DEBUG TRAIN Batch 18/7900 loss 12.553913 loss_att 15.243225 loss_ctc 19.034782 loss_rnnt 11.107106 hw_loss 0.084052 lr 0.00039771 rank 2
2023-02-22 12:09:58,427 DEBUG TRAIN Batch 18/7900 loss 20.683043 loss_att 22.619061 loss_ctc 30.253696 loss_rnnt 18.982906 hw_loss 0.069082 lr 0.00039774 rank 4
2023-02-22 12:09:58,428 DEBUG TRAIN Batch 18/7900 loss 25.668198 loss_att 26.672916 loss_ctc 41.603863 loss_rnnt 23.286667 hw_loss 0.104686 lr 0.00039778 rank 1
2023-02-22 12:09:58,428 DEBUG TRAIN Batch 18/7900 loss 6.473424 loss_att 8.826824 loss_ctc 7.859118 loss_rnnt 5.778135 hw_loss 0.074717 lr 0.00039776 rank 6
2023-02-22 12:09:58,476 DEBUG TRAIN Batch 18/7900 loss 10.883745 loss_att 13.182891 loss_ctc 14.478947 loss_rnnt 9.933680 hw_loss 0.020394 lr 0.00039769 rank 3
2023-02-22 12:11:13,612 DEBUG TRAIN Batch 18/8000 loss 20.403063 loss_att 19.531216 loss_ctc 25.683510 loss_rnnt 19.826347 hw_loss 0.088174 lr 0.00039762 rank 7
2023-02-22 12:11:13,617 DEBUG TRAIN Batch 18/8000 loss 4.438810 loss_att 7.479134 loss_ctc 7.991098 loss_rnnt 3.319953 hw_loss 0.069664 lr 0.00039756 rank 3
2023-02-22 12:11:13,618 DEBUG TRAIN Batch 18/8000 loss 20.178713 loss_att 20.276089 loss_ctc 27.255047 loss_rnnt 19.206554 hw_loss 0.017194 lr 0.00039764 rank 5
2023-02-22 12:11:13,619 DEBUG TRAIN Batch 18/8000 loss 14.994001 loss_att 17.878342 loss_ctc 23.733480 loss_rnnt 13.191982 hw_loss 0.112287 lr 0.00039758 rank 2
2023-02-22 12:11:13,621 DEBUG TRAIN Batch 18/8000 loss 8.365200 loss_att 11.727650 loss_ctc 13.522701 loss_rnnt 6.982946 hw_loss 0.041433 lr 0.00039762 rank 4
2023-02-22 12:11:13,621 DEBUG TRAIN Batch 18/8000 loss 4.379522 loss_att 6.453051 loss_ctc 4.983127 loss_rnnt 3.884252 hw_loss 0.000159 lr 0.00039763 rank 6
2023-02-22 12:11:13,625 DEBUG TRAIN Batch 18/8000 loss 4.952575 loss_att 7.192273 loss_ctc 6.145969 loss_rnnt 4.266345 hw_loss 0.148447 lr 0.00039764 rank 0
2023-02-22 12:11:13,628 DEBUG TRAIN Batch 18/8000 loss 15.395275 loss_att 17.085388 loss_ctc 22.520462 loss_rnnt 14.035038 hw_loss 0.135354 lr 0.00039765 rank 1
2023-02-22 12:12:28,409 DEBUG TRAIN Batch 18/8100 loss 14.002412 loss_att 15.572247 loss_ctc 19.271814 loss_rnnt 12.970553 hw_loss 0.028696 lr 0.00039749 rank 7
2023-02-22 12:12:28,415 DEBUG TRAIN Batch 18/8100 loss 13.858718 loss_att 14.730911 loss_ctc 21.362843 loss_rnnt 12.624594 hw_loss 0.110882 lr 0.00039749 rank 4
2023-02-22 12:12:28,418 DEBUG TRAIN Batch 18/8100 loss 18.782263 loss_att 17.140593 loss_ctc 24.762768 loss_rnnt 18.226557 hw_loss 0.162449 lr 0.00039744 rank 3
2023-02-22 12:12:28,420 DEBUG TRAIN Batch 18/8100 loss 11.358919 loss_att 13.792547 loss_ctc 14.886980 loss_rnnt 10.394220 hw_loss 0.014185 lr 0.00039751 rank 6
2023-02-22 12:12:28,421 DEBUG TRAIN Batch 18/8100 loss 9.230995 loss_att 11.378026 loss_ctc 12.989700 loss_rnnt 8.267968 hw_loss 0.060861 lr 0.00039752 rank 0
2023-02-22 12:12:28,421 DEBUG TRAIN Batch 18/8100 loss 7.627615 loss_att 12.666822 loss_ctc 10.643780 loss_rnnt 6.144816 hw_loss 0.136506 lr 0.00039751 rank 5
2023-02-22 12:12:28,424 DEBUG TRAIN Batch 18/8100 loss 13.092527 loss_att 15.047640 loss_ctc 14.694921 loss_rnnt 12.438465 hw_loss 0.092602 lr 0.00039753 rank 1
2023-02-22 12:12:28,428 DEBUG TRAIN Batch 18/8100 loss 6.504275 loss_att 7.813081 loss_ctc 8.276049 loss_rnnt 5.943065 hw_loss 0.118524 lr 0.00039745 rank 2
2023-02-22 12:13:44,458 DEBUG TRAIN Batch 18/8200 loss 8.790349 loss_att 10.620574 loss_ctc 12.590571 loss_rnnt 7.826478 hw_loss 0.170868 lr 0.00039737 rank 4
2023-02-22 12:13:44,458 DEBUG TRAIN Batch 18/8200 loss 11.369349 loss_att 14.200428 loss_ctc 14.087166 loss_rnnt 10.405020 hw_loss 0.067007 lr 0.00039738 rank 5
2023-02-22 12:13:44,460 DEBUG TRAIN Batch 18/8200 loss 4.864636 loss_att 7.605601 loss_ctc 8.157019 loss_rnnt 3.834917 hw_loss 0.079766 lr 0.00039739 rank 0
2023-02-22 12:13:44,462 DEBUG TRAIN Batch 18/8200 loss 7.863219 loss_att 9.983730 loss_ctc 10.207809 loss_rnnt 7.059213 hw_loss 0.126172 lr 0.00039738 rank 6
2023-02-22 12:13:44,461 DEBUG TRAIN Batch 18/8200 loss 7.117449 loss_att 9.783615 loss_ctc 9.308819 loss_rnnt 6.175733 hw_loss 0.218062 lr 0.00039733 rank 2
2023-02-22 12:13:44,462 DEBUG TRAIN Batch 18/8200 loss 11.411342 loss_att 12.016793 loss_ctc 13.771358 loss_rnnt 10.871149 hw_loss 0.195811 lr 0.00039737 rank 7
2023-02-22 12:13:44,463 DEBUG TRAIN Batch 18/8200 loss 6.616360 loss_att 10.332253 loss_ctc 11.034429 loss_rnnt 5.170379 hw_loss 0.213237 lr 0.00039731 rank 3
2023-02-22 12:13:44,465 DEBUG TRAIN Batch 18/8200 loss 21.229445 loss_att 22.402304 loss_ctc 33.858418 loss_rnnt 19.213570 hw_loss 0.182700 lr 0.00039740 rank 1
2023-02-22 12:14:58,731 DEBUG TRAIN Batch 18/8300 loss 9.482042 loss_att 12.559368 loss_ctc 11.723396 loss_rnnt 8.491299 hw_loss 0.143309 lr 0.00039724 rank 7
2023-02-22 12:14:58,734 DEBUG TRAIN Batch 18/8300 loss 2.388515 loss_att 7.646557 loss_ctc 7.148101 loss_rnnt 0.693916 hw_loss 0.015711 lr 0.00039726 rank 6
2023-02-22 12:14:58,737 DEBUG TRAIN Batch 18/8300 loss 16.176788 loss_att 18.426805 loss_ctc 29.849316 loss_rnnt 13.847256 hw_loss 0.105984 lr 0.00039726 rank 5
2023-02-22 12:14:58,738 DEBUG TRAIN Batch 18/8300 loss 4.471124 loss_att 6.911716 loss_ctc 7.882933 loss_rnnt 3.471974 hw_loss 0.105232 lr 0.00039727 rank 0
2023-02-22 12:14:58,738 DEBUG TRAIN Batch 18/8300 loss 8.904485 loss_att 15.701483 loss_ctc 13.271332 loss_rnnt 6.903133 hw_loss 0.111947 lr 0.00039724 rank 4
2023-02-22 12:14:58,739 DEBUG TRAIN Batch 18/8300 loss 7.809175 loss_att 11.033501 loss_ctc 10.029263 loss_rnnt 6.867270 hw_loss 0.001930 lr 0.00039720 rank 2
2023-02-22 12:14:58,739 DEBUG TRAIN Batch 18/8300 loss 20.198851 loss_att 20.383179 loss_ctc 27.587940 loss_rnnt 19.114237 hw_loss 0.117250 lr 0.00039728 rank 1
2023-02-22 12:14:58,741 DEBUG TRAIN Batch 18/8300 loss 5.859335 loss_att 10.995306 loss_ctc 7.426305 loss_rnnt 4.609684 hw_loss 0.025366 lr 0.00039719 rank 3
2023-02-22 12:15:44,396 DEBUG CV Batch 18/0 loss 2.177585 loss_att 2.314985 loss_ctc 2.887715 loss_rnnt 1.956597 hw_loss 0.185296 history loss 2.096934 rank 7
2023-02-22 12:15:44,403 DEBUG CV Batch 18/0 loss 2.177585 loss_att 2.314985 loss_ctc 2.887715 loss_rnnt 1.956597 hw_loss 0.185296 history loss 2.096934 rank 1
2023-02-22 12:15:44,406 DEBUG CV Batch 18/0 loss 2.177585 loss_att 2.314985 loss_ctc 2.887715 loss_rnnt 1.956597 hw_loss 0.185296 history loss 2.096934 rank 3
2023-02-22 12:15:44,413 DEBUG CV Batch 18/0 loss 2.177585 loss_att 2.314985 loss_ctc 2.887715 loss_rnnt 1.956597 hw_loss 0.185296 history loss 2.096934 rank 5
2023-02-22 12:15:44,414 DEBUG CV Batch 18/0 loss 2.177585 loss_att 2.314985 loss_ctc 2.887715 loss_rnnt 1.956597 hw_loss 0.185296 history loss 2.096934 rank 0
2023-02-22 12:15:44,421 DEBUG CV Batch 18/0 loss 2.177585 loss_att 2.314985 loss_ctc 2.887715 loss_rnnt 1.956597 hw_loss 0.185296 history loss 2.096934 rank 6
2023-02-22 12:15:44,423 DEBUG CV Batch 18/0 loss 2.177585 loss_att 2.314985 loss_ctc 2.887715 loss_rnnt 1.956597 hw_loss 0.185296 history loss 2.096934 rank 2
2023-02-22 12:15:44,424 DEBUG CV Batch 18/0 loss 2.177585 loss_att 2.314985 loss_ctc 2.887715 loss_rnnt 1.956597 hw_loss 0.185296 history loss 2.096934 rank 4
2023-02-22 12:15:55,556 DEBUG CV Batch 18/100 loss 7.780540 loss_att 7.720166 loss_ctc 10.800990 loss_rnnt 7.374282 hw_loss 0.029263 history loss 3.586704 rank 4
2023-02-22 12:15:55,591 DEBUG CV Batch 18/100 loss 7.780540 loss_att 7.720166 loss_ctc 10.800990 loss_rnnt 7.374282 hw_loss 0.029263 history loss 3.586704 rank 5
2023-02-22 12:15:55,592 DEBUG CV Batch 18/100 loss 7.780540 loss_att 7.720166 loss_ctc 10.800990 loss_rnnt 7.374282 hw_loss 0.029263 history loss 3.586704 rank 7
2023-02-22 12:15:55,593 DEBUG CV Batch 18/100 loss 7.780540 loss_att 7.720166 loss_ctc 10.800990 loss_rnnt 7.374282 hw_loss 0.029263 history loss 3.586704 rank 0
2023-02-22 12:15:55,684 DEBUG CV Batch 18/100 loss 7.780540 loss_att 7.720166 loss_ctc 10.800990 loss_rnnt 7.374282 hw_loss 0.029263 history loss 3.586704 rank 3
2023-02-22 12:15:55,727 DEBUG CV Batch 18/100 loss 7.780540 loss_att 7.720166 loss_ctc 10.800990 loss_rnnt 7.374282 hw_loss 0.029263 history loss 3.586704 rank 1
2023-02-22 12:15:55,804 DEBUG CV Batch 18/100 loss 7.780540 loss_att 7.720166 loss_ctc 10.800990 loss_rnnt 7.374282 hw_loss 0.029263 history loss 3.586704 rank 2
2023-02-22 12:15:55,847 DEBUG CV Batch 18/100 loss 7.780540 loss_att 7.720166 loss_ctc 10.800990 loss_rnnt 7.374282 hw_loss 0.029263 history loss 3.586704 rank 6
2023-02-22 12:16:08,860 DEBUG CV Batch 18/200 loss 9.963531 loss_att 14.671362 loss_ctc 9.498822 loss_rnnt 9.008952 hw_loss 0.140576 history loss 4.174052 rank 5
2023-02-22 12:16:08,861 DEBUG CV Batch 18/200 loss 9.963531 loss_att 14.671362 loss_ctc 9.498822 loss_rnnt 9.008952 hw_loss 0.140576 history loss 4.174052 rank 4
2023-02-22 12:16:08,884 DEBUG CV Batch 18/200 loss 9.963531 loss_att 14.671362 loss_ctc 9.498822 loss_rnnt 9.008952 hw_loss 0.140576 history loss 4.174052 rank 7
2023-02-22 12:16:08,905 DEBUG CV Batch 18/200 loss 9.963531 loss_att 14.671362 loss_ctc 9.498822 loss_rnnt 9.008952 hw_loss 0.140576 history loss 4.174052 rank 0
2023-02-22 12:16:09,093 DEBUG CV Batch 18/200 loss 9.963531 loss_att 14.671362 loss_ctc 9.498822 loss_rnnt 9.008952 hw_loss 0.140576 history loss 4.174052 rank 1
2023-02-22 12:16:09,271 DEBUG CV Batch 18/200 loss 9.963531 loss_att 14.671362 loss_ctc 9.498822 loss_rnnt 9.008952 hw_loss 0.140576 history loss 4.174052 rank 3
2023-02-22 12:16:09,285 DEBUG CV Batch 18/200 loss 9.963531 loss_att 14.671362 loss_ctc 9.498822 loss_rnnt 9.008952 hw_loss 0.140576 history loss 4.174052 rank 2
2023-02-22 12:16:09,436 DEBUG CV Batch 18/200 loss 9.963531 loss_att 14.671362 loss_ctc 9.498822 loss_rnnt 9.008952 hw_loss 0.140576 history loss 4.174052 rank 6
2023-02-22 12:16:20,947 DEBUG CV Batch 18/300 loss 4.111372 loss_att 4.757407 loss_ctc 6.693138 loss_rnnt 3.510546 hw_loss 0.238843 history loss 4.314909 rank 7
2023-02-22 12:16:20,957 DEBUG CV Batch 18/300 loss 4.111372 loss_att 4.757407 loss_ctc 6.693138 loss_rnnt 3.510546 hw_loss 0.238843 history loss 4.314909 rank 4
2023-02-22 12:16:21,016 DEBUG CV Batch 18/300 loss 4.111372 loss_att 4.757407 loss_ctc 6.693138 loss_rnnt 3.510546 hw_loss 0.238843 history loss 4.314909 rank 5
2023-02-22 12:16:21,066 DEBUG CV Batch 18/300 loss 4.111372 loss_att 4.757407 loss_ctc 6.693138 loss_rnnt 3.510546 hw_loss 0.238843 history loss 4.314909 rank 0
2023-02-22 12:16:21,324 DEBUG CV Batch 18/300 loss 4.111372 loss_att 4.757407 loss_ctc 6.693138 loss_rnnt 3.510546 hw_loss 0.238843 history loss 4.314909 rank 1
2023-02-22 12:16:21,490 DEBUG CV Batch 18/300 loss 4.111372 loss_att 4.757407 loss_ctc 6.693138 loss_rnnt 3.510546 hw_loss 0.238843 history loss 4.314909 rank 2
2023-02-22 12:16:21,583 DEBUG CV Batch 18/300 loss 4.111372 loss_att 4.757407 loss_ctc 6.693138 loss_rnnt 3.510546 hw_loss 0.238843 history loss 4.314909 rank 3
2023-02-22 12:16:22,360 DEBUG CV Batch 18/300 loss 4.111372 loss_att 4.757407 loss_ctc 6.693138 loss_rnnt 3.510546 hw_loss 0.238843 history loss 4.314909 rank 6
2023-02-22 12:16:32,971 DEBUG CV Batch 18/400 loss 22.286383 loss_att 97.503014 loss_ctc 15.210986 loss_rnnt 8.177552 hw_loss 0.016666 history loss 5.275209 rank 7
2023-02-22 12:16:33,012 DEBUG CV Batch 18/400 loss 22.286383 loss_att 97.503014 loss_ctc 15.210986 loss_rnnt 8.177552 hw_loss 0.016666 history loss 5.275209 rank 4
2023-02-22 12:16:33,105 DEBUG CV Batch 18/400 loss 22.286383 loss_att 97.503014 loss_ctc 15.210986 loss_rnnt 8.177552 hw_loss 0.016666 history loss 5.275209 rank 5
2023-02-22 12:16:33,132 DEBUG CV Batch 18/400 loss 22.286383 loss_att 97.503014 loss_ctc 15.210986 loss_rnnt 8.177552 hw_loss 0.016666 history loss 5.275209 rank 0
2023-02-22 12:16:33,777 DEBUG CV Batch 18/400 loss 22.286383 loss_att 97.503014 loss_ctc 15.210986 loss_rnnt 8.177552 hw_loss 0.016666 history loss 5.275209 rank 2
2023-02-22 12:16:33,898 DEBUG CV Batch 18/400 loss 22.286383 loss_att 97.503014 loss_ctc 15.210986 loss_rnnt 8.177552 hw_loss 0.016666 history loss 5.275209 rank 3
2023-02-22 12:16:34,456 DEBUG CV Batch 18/400 loss 22.286383 loss_att 97.503014 loss_ctc 15.210986 loss_rnnt 8.177552 hw_loss 0.016666 history loss 5.275209 rank 1
2023-02-22 12:16:34,630 DEBUG CV Batch 18/400 loss 22.286383 loss_att 97.503014 loss_ctc 15.210986 loss_rnnt 8.177552 hw_loss 0.016666 history loss 5.275209 rank 6
2023-02-22 12:16:43,438 DEBUG CV Batch 18/500 loss 5.440243 loss_att 6.908409 loss_ctc 8.203141 loss_rnnt 4.743165 hw_loss 0.065734 history loss 6.047610 rank 7
2023-02-22 12:16:43,500 DEBUG CV Batch 18/500 loss 5.440243 loss_att 6.908409 loss_ctc 8.203141 loss_rnnt 4.743165 hw_loss 0.065734 history loss 6.047610 rank 4
2023-02-22 12:16:43,560 DEBUG CV Batch 18/500 loss 5.440243 loss_att 6.908409 loss_ctc 8.203141 loss_rnnt 4.743165 hw_loss 0.065734 history loss 6.047610 rank 0
2023-02-22 12:16:43,717 DEBUG CV Batch 18/500 loss 5.440243 loss_att 6.908409 loss_ctc 8.203141 loss_rnnt 4.743165 hw_loss 0.065734 history loss 6.047610 rank 5
2023-02-22 12:16:44,775 DEBUG CV Batch 18/500 loss 5.440243 loss_att 6.908409 loss_ctc 8.203141 loss_rnnt 4.743165 hw_loss 0.065734 history loss 6.047610 rank 3
2023-02-22 12:16:45,256 DEBUG CV Batch 18/500 loss 5.440243 loss_att 6.908409 loss_ctc 8.203141 loss_rnnt 4.743165 hw_loss 0.065734 history loss 6.047610 rank 6
2023-02-22 12:16:45,277 DEBUG CV Batch 18/500 loss 5.440243 loss_att 6.908409 loss_ctc 8.203141 loss_rnnt 4.743165 hw_loss 0.065734 history loss 6.047610 rank 1
2023-02-22 12:16:45,327 DEBUG CV Batch 18/500 loss 5.440243 loss_att 6.908409 loss_ctc 8.203141 loss_rnnt 4.743165 hw_loss 0.065734 history loss 6.047610 rank 2
2023-02-22 12:16:55,482 DEBUG CV Batch 18/600 loss 6.450620 loss_att 7.656658 loss_ctc 8.938763 loss_rnnt 5.755169 hw_loss 0.229673 history loss 6.983318 rank 7
2023-02-22 12:16:55,533 DEBUG CV Batch 18/600 loss 6.450620 loss_att 7.656658 loss_ctc 8.938763 loss_rnnt 5.755169 hw_loss 0.229673 history loss 6.983318 rank 4
2023-02-22 12:16:55,669 DEBUG CV Batch 18/600 loss 6.450620 loss_att 7.656658 loss_ctc 8.938763 loss_rnnt 5.755169 hw_loss 0.229673 history loss 6.983318 rank 0
2023-02-22 12:16:55,894 DEBUG CV Batch 18/600 loss 6.450620 loss_att 7.656658 loss_ctc 8.938763 loss_rnnt 5.755169 hw_loss 0.229673 history loss 6.983318 rank 5
2023-02-22 12:16:57,077 DEBUG CV Batch 18/600 loss 6.450620 loss_att 7.656658 loss_ctc 8.938763 loss_rnnt 5.755169 hw_loss 0.229673 history loss 6.983318 rank 3
2023-02-22 12:16:57,542 DEBUG CV Batch 18/600 loss 6.450620 loss_att 7.656658 loss_ctc 8.938763 loss_rnnt 5.755169 hw_loss 0.229673 history loss 6.983318 rank 6
2023-02-22 12:16:57,586 DEBUG CV Batch 18/600 loss 6.450620 loss_att 7.656658 loss_ctc 8.938763 loss_rnnt 5.755169 hw_loss 0.229673 history loss 6.983318 rank 2
2023-02-22 12:16:58,290 DEBUG CV Batch 18/600 loss 6.450620 loss_att 7.656658 loss_ctc 8.938763 loss_rnnt 5.755169 hw_loss 0.229673 history loss 6.983318 rank 1
2023-02-22 12:17:06,862 DEBUG CV Batch 18/700 loss 16.222178 loss_att 44.481155 loss_ctc 19.280651 loss_rnnt 10.127552 hw_loss 0.065685 history loss 7.653831 rank 7
2023-02-22 12:17:06,963 DEBUG CV Batch 18/700 loss 16.222178 loss_att 44.481155 loss_ctc 19.280651 loss_rnnt 10.127552 hw_loss 0.065685 history loss 7.653831 rank 4
2023-02-22 12:17:07,062 DEBUG CV Batch 18/700 loss 16.222178 loss_att 44.481155 loss_ctc 19.280651 loss_rnnt 10.127552 hw_loss 0.065685 history loss 7.653831 rank 0
2023-02-22 12:17:07,355 DEBUG CV Batch 18/700 loss 16.222178 loss_att 44.481155 loss_ctc 19.280651 loss_rnnt 10.127552 hw_loss 0.065685 history loss 7.653831 rank 5
2023-02-22 12:17:08,622 DEBUG CV Batch 18/700 loss 16.222178 loss_att 44.481155 loss_ctc 19.280651 loss_rnnt 10.127552 hw_loss 0.065685 history loss 7.653831 rank 3
2023-02-22 12:17:09,044 DEBUG CV Batch 18/700 loss 16.222178 loss_att 44.481155 loss_ctc 19.280651 loss_rnnt 10.127552 hw_loss 0.065685 history loss 7.653831 rank 2
2023-02-22 12:17:09,322 DEBUG CV Batch 18/700 loss 16.222178 loss_att 44.481155 loss_ctc 19.280651 loss_rnnt 10.127552 hw_loss 0.065685 history loss 7.653831 rank 6
2023-02-22 12:17:10,518 DEBUG CV Batch 18/700 loss 16.222178 loss_att 44.481155 loss_ctc 19.280651 loss_rnnt 10.127552 hw_loss 0.065685 history loss 7.653831 rank 1
2023-02-22 12:17:18,018 DEBUG CV Batch 18/800 loss 11.901469 loss_att 10.561892 loss_ctc 15.822206 loss_rnnt 11.581417 hw_loss 0.122255 history loss 7.112422 rank 7
2023-02-22 12:17:18,200 DEBUG CV Batch 18/800 loss 11.901469 loss_att 10.561892 loss_ctc 15.822206 loss_rnnt 11.581417 hw_loss 0.122255 history loss 7.112422 rank 4
2023-02-22 12:17:18,235 DEBUG CV Batch 18/800 loss 11.901469 loss_att 10.561892 loss_ctc 15.822206 loss_rnnt 11.581417 hw_loss 0.122255 history loss 7.112422 rank 0
2023-02-22 12:17:18,672 DEBUG CV Batch 18/800 loss 11.901469 loss_att 10.561892 loss_ctc 15.822206 loss_rnnt 11.581417 hw_loss 0.122255 history loss 7.112422 rank 5
2023-02-22 12:17:20,163 DEBUG CV Batch 18/800 loss 11.901469 loss_att 10.561892 loss_ctc 15.822206 loss_rnnt 11.581417 hw_loss 0.122255 history loss 7.112422 rank 3
2023-02-22 12:17:20,482 DEBUG CV Batch 18/800 loss 11.901469 loss_att 10.561892 loss_ctc 15.822206 loss_rnnt 11.581417 hw_loss 0.122255 history loss 7.112422 rank 2
2023-02-22 12:17:21,037 DEBUG CV Batch 18/800 loss 11.901469 loss_att 10.561892 loss_ctc 15.822206 loss_rnnt 11.581417 hw_loss 0.122255 history loss 7.112422 rank 6
2023-02-22 12:17:22,594 DEBUG CV Batch 18/800 loss 11.901469 loss_att 10.561892 loss_ctc 15.822206 loss_rnnt 11.581417 hw_loss 0.122255 history loss 7.112422 rank 1
2023-02-22 12:17:31,332 DEBUG CV Batch 18/900 loss 12.805968 loss_att 16.946480 loss_ctc 21.228458 loss_rnnt 10.822562 hw_loss 0.060573 history loss 6.905744 rank 7
2023-02-22 12:17:31,506 DEBUG CV Batch 18/900 loss 12.805968 loss_att 16.946480 loss_ctc 21.228458 loss_rnnt 10.822562 hw_loss 0.060573 history loss 6.905744 rank 0
2023-02-22 12:17:31,536 DEBUG CV Batch 18/900 loss 12.805968 loss_att 16.946480 loss_ctc 21.228458 loss_rnnt 10.822562 hw_loss 0.060573 history loss 6.905744 rank 4
2023-02-22 12:17:31,929 DEBUG CV Batch 18/900 loss 12.805968 loss_att 16.946480 loss_ctc 21.228458 loss_rnnt 10.822562 hw_loss 0.060573 history loss 6.905744 rank 5
2023-02-22 12:17:33,554 DEBUG CV Batch 18/900 loss 12.805968 loss_att 16.946480 loss_ctc 21.228458 loss_rnnt 10.822562 hw_loss 0.060573 history loss 6.905744 rank 3
2023-02-22 12:17:33,898 DEBUG CV Batch 18/900 loss 12.805968 loss_att 16.946480 loss_ctc 21.228458 loss_rnnt 10.822562 hw_loss 0.060573 history loss 6.905744 rank 2
2023-02-22 12:17:34,463 DEBUG CV Batch 18/900 loss 12.805968 loss_att 16.946480 loss_ctc 21.228458 loss_rnnt 10.822562 hw_loss 0.060573 history loss 6.905744 rank 6
2023-02-22 12:17:36,204 DEBUG CV Batch 18/900 loss 12.805968 loss_att 16.946480 loss_ctc 21.228458 loss_rnnt 10.822562 hw_loss 0.060573 history loss 6.905744 rank 1
2023-02-22 12:17:43,520 DEBUG CV Batch 18/1000 loss 3.983071 loss_att 4.911530 loss_ctc 4.760316 loss_rnnt 3.591426 hw_loss 0.191851 history loss 6.668295 rank 7
2023-02-22 12:17:43,645 DEBUG CV Batch 18/1000 loss 3.983071 loss_att 4.911530 loss_ctc 4.760316 loss_rnnt 3.591426 hw_loss 0.191851 history loss 6.668295 rank 4
2023-02-22 12:17:43,711 DEBUG CV Batch 18/1000 loss 3.983071 loss_att 4.911530 loss_ctc 4.760316 loss_rnnt 3.591426 hw_loss 0.191851 history loss 6.668295 rank 0
2023-02-22 12:17:44,081 DEBUG CV Batch 18/1000 loss 3.983071 loss_att 4.911530 loss_ctc 4.760316 loss_rnnt 3.591426 hw_loss 0.191851 history loss 6.668295 rank 5
2023-02-22 12:17:46,112 DEBUG CV Batch 18/1000 loss 3.983071 loss_att 4.911530 loss_ctc 4.760316 loss_rnnt 3.591426 hw_loss 0.191851 history loss 6.668295 rank 3
2023-02-22 12:17:46,190 DEBUG CV Batch 18/1000 loss 3.983071 loss_att 4.911530 loss_ctc 4.760316 loss_rnnt 3.591426 hw_loss 0.191851 history loss 6.668295 rank 2
2023-02-22 12:17:47,430 DEBUG CV Batch 18/1000 loss 3.983071 loss_att 4.911530 loss_ctc 4.760316 loss_rnnt 3.591426 hw_loss 0.191851 history loss 6.668295 rank 6
2023-02-22 12:17:48,913 DEBUG CV Batch 18/1000 loss 3.983071 loss_att 4.911530 loss_ctc 4.760316 loss_rnnt 3.591426 hw_loss 0.191851 history loss 6.668295 rank 1
2023-02-22 12:17:55,415 DEBUG CV Batch 18/1100 loss 7.052468 loss_att 6.129931 loss_ctc 9.266484 loss_rnnt 6.817834 hw_loss 0.232385 history loss 6.663913 rank 7
2023-02-22 12:17:55,566 DEBUG CV Batch 18/1100 loss 7.052468 loss_att 6.129931 loss_ctc 9.266484 loss_rnnt 6.817834 hw_loss 0.232385 history loss 6.663913 rank 4
2023-02-22 12:17:55,677 DEBUG CV Batch 18/1100 loss 7.052468 loss_att 6.129931 loss_ctc 9.266484 loss_rnnt 6.817834 hw_loss 0.232385 history loss 6.663913 rank 0
2023-02-22 12:17:56,084 DEBUG CV Batch 18/1100 loss 7.052468 loss_att 6.129931 loss_ctc 9.266484 loss_rnnt 6.817834 hw_loss 0.232385 history loss 6.663913 rank 5
2023-02-22 12:17:58,156 DEBUG CV Batch 18/1100 loss 7.052468 loss_att 6.129931 loss_ctc 9.266484 loss_rnnt 6.817834 hw_loss 0.232385 history loss 6.663913 rank 3
2023-02-22 12:17:58,199 DEBUG CV Batch 18/1100 loss 7.052468 loss_att 6.129931 loss_ctc 9.266484 loss_rnnt 6.817834 hw_loss 0.232385 history loss 6.663913 rank 2
2023-02-22 12:17:59,550 DEBUG CV Batch 18/1100 loss 7.052468 loss_att 6.129931 loss_ctc 9.266484 loss_rnnt 6.817834 hw_loss 0.232385 history loss 6.663913 rank 6
2023-02-22 12:18:01,808 DEBUG CV Batch 18/1100 loss 7.052468 loss_att 6.129931 loss_ctc 9.266484 loss_rnnt 6.817834 hw_loss 0.232385 history loss 6.663913 rank 1
2023-02-22 12:18:06,052 DEBUG CV Batch 18/1200 loss 7.131487 loss_att 7.786589 loss_ctc 8.863315 loss_rnnt 6.670361 hw_loss 0.185993 history loss 6.988024 rank 7
2023-02-22 12:18:06,183 DEBUG CV Batch 18/1200 loss 7.131487 loss_att 7.786589 loss_ctc 8.863315 loss_rnnt 6.670361 hw_loss 0.185993 history loss 6.988024 rank 4
2023-02-22 12:18:06,301 DEBUG CV Batch 18/1200 loss 7.131487 loss_att 7.786589 loss_ctc 8.863315 loss_rnnt 6.670361 hw_loss 0.185993 history loss 6.988024 rank 0
2023-02-22 12:18:06,746 DEBUG CV Batch 18/1200 loss 7.131487 loss_att 7.786589 loss_ctc 8.863315 loss_rnnt 6.670361 hw_loss 0.185993 history loss 6.988024 rank 5
2023-02-22 12:18:08,895 DEBUG CV Batch 18/1200 loss 7.131487 loss_att 7.786589 loss_ctc 8.863315 loss_rnnt 6.670361 hw_loss 0.185993 history loss 6.988024 rank 2
2023-02-22 12:18:09,233 DEBUG CV Batch 18/1200 loss 7.131487 loss_att 7.786589 loss_ctc 8.863315 loss_rnnt 6.670361 hw_loss 0.185993 history loss 6.988024 rank 3
2023-02-22 12:18:10,326 DEBUG CV Batch 18/1200 loss 7.131487 loss_att 7.786589 loss_ctc 8.863315 loss_rnnt 6.670361 hw_loss 0.185993 history loss 6.988024 rank 6
2023-02-22 12:18:12,711 DEBUG CV Batch 18/1200 loss 7.131487 loss_att 7.786589 loss_ctc 8.863315 loss_rnnt 6.670361 hw_loss 0.185993 history loss 6.988024 rank 1
2023-02-22 12:18:18,074 DEBUG CV Batch 18/1300 loss 5.397051 loss_att 5.314701 loss_ctc 7.028689 loss_rnnt 5.113623 hw_loss 0.154399 history loss 7.293728 rank 7
2023-02-22 12:18:18,077 DEBUG CV Batch 18/1300 loss 5.397051 loss_att 5.314701 loss_ctc 7.028689 loss_rnnt 5.113623 hw_loss 0.154399 history loss 7.293728 rank 4
2023-02-22 12:18:18,260 DEBUG CV Batch 18/1300 loss 5.397051 loss_att 5.314701 loss_ctc 7.028689 loss_rnnt 5.113623 hw_loss 0.154399 history loss 7.293728 rank 0
2023-02-22 12:18:18,733 DEBUG CV Batch 18/1300 loss 5.397051 loss_att 5.314701 loss_ctc 7.028689 loss_rnnt 5.113623 hw_loss 0.154399 history loss 7.293728 rank 5
2023-02-22 12:18:21,081 DEBUG CV Batch 18/1300 loss 5.397051 loss_att 5.314701 loss_ctc 7.028689 loss_rnnt 5.113623 hw_loss 0.154399 history loss 7.293728 rank 2
2023-02-22 12:18:21,394 DEBUG CV Batch 18/1300 loss 5.397051 loss_att 5.314701 loss_ctc 7.028689 loss_rnnt 5.113623 hw_loss 0.154399 history loss 7.293728 rank 3
2023-02-22 12:18:22,457 DEBUG CV Batch 18/1300 loss 5.397051 loss_att 5.314701 loss_ctc 7.028689 loss_rnnt 5.113623 hw_loss 0.154399 history loss 7.293728 rank 6
2023-02-22 12:18:24,757 DEBUG CV Batch 18/1300 loss 5.397051 loss_att 5.314701 loss_ctc 7.028689 loss_rnnt 5.113623 hw_loss 0.154399 history loss 7.293728 rank 1
2023-02-22 12:18:29,284 DEBUG CV Batch 18/1400 loss 8.304945 loss_att 18.681076 loss_ctc 8.921536 loss_rnnt 6.147296 hw_loss 0.000395 history loss 7.621376 rank 4
2023-02-22 12:18:29,419 DEBUG CV Batch 18/1400 loss 8.304945 loss_att 18.681076 loss_ctc 8.921536 loss_rnnt 6.147296 hw_loss 0.000395 history loss 7.621376 rank 7
2023-02-22 12:18:29,461 DEBUG CV Batch 18/1400 loss 8.304945 loss_att 18.681076 loss_ctc 8.921536 loss_rnnt 6.147296 hw_loss 0.000395 history loss 7.621376 rank 0
2023-02-22 12:18:30,075 DEBUG CV Batch 18/1400 loss 8.304945 loss_att 18.681076 loss_ctc 8.921536 loss_rnnt 6.147296 hw_loss 0.000395 history loss 7.621376 rank 5
2023-02-22 12:18:32,512 DEBUG CV Batch 18/1400 loss 8.304945 loss_att 18.681076 loss_ctc 8.921536 loss_rnnt 6.147296 hw_loss 0.000395 history loss 7.621376 rank 2
2023-02-22 12:18:32,906 DEBUG CV Batch 18/1400 loss 8.304945 loss_att 18.681076 loss_ctc 8.921536 loss_rnnt 6.147296 hw_loss 0.000395 history loss 7.621376 rank 3
2023-02-22 12:18:33,829 DEBUG CV Batch 18/1400 loss 8.304945 loss_att 18.681076 loss_ctc 8.921536 loss_rnnt 6.147296 hw_loss 0.000395 history loss 7.621376 rank 6
2023-02-22 12:18:36,680 DEBUG CV Batch 18/1400 loss 8.304945 loss_att 18.681076 loss_ctc 8.921536 loss_rnnt 6.147296 hw_loss 0.000395 history loss 7.621376 rank 1
2023-02-22 12:18:40,641 DEBUG CV Batch 18/1500 loss 7.350156 loss_att 8.115987 loss_ctc 6.616550 loss_rnnt 7.258371 hw_loss 0.068311 history loss 7.448150 rank 4
2023-02-22 12:18:40,863 DEBUG CV Batch 18/1500 loss 7.350156 loss_att 8.115987 loss_ctc 6.616550 loss_rnnt 7.258371 hw_loss 0.068311 history loss 7.448150 rank 0
2023-02-22 12:18:40,907 DEBUG CV Batch 18/1500 loss 7.350156 loss_att 8.115987 loss_ctc 6.616550 loss_rnnt 7.258371 hw_loss 0.068311 history loss 7.448150 rank 7
2023-02-22 12:18:41,549 DEBUG CV Batch 18/1500 loss 7.350156 loss_att 8.115987 loss_ctc 6.616550 loss_rnnt 7.258371 hw_loss 0.068311 history loss 7.448150 rank 5
2023-02-22 12:18:44,300 DEBUG CV Batch 18/1500 loss 7.350156 loss_att 8.115987 loss_ctc 6.616550 loss_rnnt 7.258371 hw_loss 0.068311 history loss 7.448150 rank 2
2023-02-22 12:18:44,620 DEBUG CV Batch 18/1500 loss 7.350156 loss_att 8.115987 loss_ctc 6.616550 loss_rnnt 7.258371 hw_loss 0.068311 history loss 7.448150 rank 3
2023-02-22 12:18:45,386 DEBUG CV Batch 18/1500 loss 7.350156 loss_att 8.115987 loss_ctc 6.616550 loss_rnnt 7.258371 hw_loss 0.068311 history loss 7.448150 rank 6
2023-02-22 12:18:49,493 DEBUG CV Batch 18/1500 loss 7.350156 loss_att 8.115987 loss_ctc 6.616550 loss_rnnt 7.258371 hw_loss 0.068311 history loss 7.448150 rank 1
2023-02-22 12:18:53,563 DEBUG CV Batch 18/1600 loss 9.402244 loss_att 13.983315 loss_ctc 11.369749 loss_rnnt 8.128641 hw_loss 0.178226 history loss 7.375341 rank 4
2023-02-22 12:18:53,796 DEBUG CV Batch 18/1600 loss 9.402244 loss_att 13.983315 loss_ctc 11.369749 loss_rnnt 8.128641 hw_loss 0.178226 history loss 7.375341 rank 0
2023-02-22 12:18:53,846 DEBUG CV Batch 18/1600 loss 9.402244 loss_att 13.983315 loss_ctc 11.369749 loss_rnnt 8.128641 hw_loss 0.178226 history loss 7.375341 rank 7
2023-02-22 12:18:54,529 DEBUG CV Batch 18/1600 loss 9.402244 loss_att 13.983315 loss_ctc 11.369749 loss_rnnt 8.128641 hw_loss 0.178226 history loss 7.375341 rank 5
2023-02-22 12:18:57,425 DEBUG CV Batch 18/1600 loss 9.402244 loss_att 13.983315 loss_ctc 11.369749 loss_rnnt 8.128641 hw_loss 0.178226 history loss 7.375341 rank 2
2023-02-22 12:18:57,737 DEBUG CV Batch 18/1600 loss 9.402244 loss_att 13.983315 loss_ctc 11.369749 loss_rnnt 8.128641 hw_loss 0.178226 history loss 7.375341 rank 3
2023-02-22 12:18:58,458 DEBUG CV Batch 18/1600 loss 9.402244 loss_att 13.983315 loss_ctc 11.369749 loss_rnnt 8.128641 hw_loss 0.178226 history loss 7.375341 rank 6
2023-02-22 12:19:03,465 DEBUG CV Batch 18/1600 loss 9.402244 loss_att 13.983315 loss_ctc 11.369749 loss_rnnt 8.128641 hw_loss 0.178226 history loss 7.375341 rank 1
2023-02-22 12:19:05,858 DEBUG CV Batch 18/1700 loss 8.318881 loss_att 9.102325 loss_ctc 13.036592 loss_rnnt 7.408772 hw_loss 0.233234 history loss 7.272128 rank 4
2023-02-22 12:19:06,040 DEBUG CV Batch 18/1700 loss 8.318881 loss_att 9.102325 loss_ctc 13.036592 loss_rnnt 7.408772 hw_loss 0.233234 history loss 7.272128 rank 0
2023-02-22 12:19:06,066 DEBUG CV Batch 18/1700 loss 8.318881 loss_att 9.102325 loss_ctc 13.036592 loss_rnnt 7.408772 hw_loss 0.233234 history loss 7.272128 rank 7
2023-02-22 12:19:06,883 DEBUG CV Batch 18/1700 loss 8.318881 loss_att 9.102325 loss_ctc 13.036592 loss_rnnt 7.408772 hw_loss 0.233234 history loss 7.272128 rank 5
2023-02-22 12:19:10,023 DEBUG CV Batch 18/1700 loss 8.318881 loss_att 9.102325 loss_ctc 13.036592 loss_rnnt 7.408772 hw_loss 0.233234 history loss 7.272128 rank 2
2023-02-22 12:19:10,141 DEBUG CV Batch 18/1700 loss 8.318881 loss_att 9.102325 loss_ctc 13.036592 loss_rnnt 7.408772 hw_loss 0.233234 history loss 7.272128 rank 3
2023-02-22 12:19:10,811 DEBUG CV Batch 18/1700 loss 8.318881 loss_att 9.102325 loss_ctc 13.036592 loss_rnnt 7.408772 hw_loss 0.233234 history loss 7.272128 rank 6
2023-02-22 12:19:15,025 INFO Epoch 18 CV info cv_loss 7.238139130869668
2023-02-22 12:19:15,026 INFO Checkpoint: save to checkpoint exp/2_21_rnnt_bias_loss_2_class_1word_finetune/18.pt
2023-02-22 12:19:15,086 INFO Epoch 18 CV info cv_loss 7.238139131537302
2023-02-22 12:19:15,086 INFO Epoch 18 CV info cv_loss 7.238139131588991
2023-02-22 12:19:15,087 INFO Epoch 19 TRAIN info lr 0.0003971757945950584
2023-02-22 12:19:15,087 INFO Epoch 19 TRAIN info lr 0.000397202111861242
2023-02-22 12:19:15,091 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 12:19:15,091 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 12:19:15,982 INFO Epoch 18 CV info cv_loss 7.23813913255383
2023-02-22 12:19:15,983 INFO Epoch 19 TRAIN info lr 0.0003972372096886376
2023-02-22 12:19:15,986 INFO Epoch 19 TRAIN info lr 0.0003972271807885764
2023-02-22 12:19:15,986 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 12:19:15,990 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 12:19:16,185 DEBUG CV Batch 18/1700 loss 8.318881 loss_att 9.102325 loss_ctc 13.036592 loss_rnnt 7.408772 hw_loss 0.233234 history loss 7.272128 rank 1
2023-02-22 12:19:19,220 INFO Epoch 18 CV info cv_loss 7.238139130701683
2023-02-22 12:19:19,221 INFO Epoch 19 TRAIN info lr 0.0003971469769238127
2023-02-22 12:19:19,226 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 12:19:19,299 INFO Epoch 18 CV info cv_loss 7.238139131610527
2023-02-22 12:19:19,300 INFO Epoch 19 TRAIN info lr 0.0003971344494579028
2023-02-22 12:19:19,303 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 12:19:20,054 INFO Epoch 18 CV info cv_loss 7.238139131571761
2023-02-22 12:19:20,056 INFO Epoch 19 TRAIN info lr 0.0003972422244235292
2023-02-22 12:19:20,061 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 12:19:25,450 INFO Epoch 18 CV info cv_loss 7.238139131968034
2023-02-22 12:19:25,452 INFO Epoch 19 TRAIN info lr 0.0003972497468819766
2023-02-22 12:19:25,455 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 12:20:40,391 DEBUG TRAIN Batch 19/0 loss 6.609259 loss_att 6.936617 loss_ctc 7.079976 loss_rnnt 6.366627 hw_loss 0.214495 lr 0.00039723 rank 0
2023-02-22 12:20:40,392 DEBUG TRAIN Batch 19/0 loss 9.653300 loss_att 9.694043 loss_ctc 12.329565 loss_rnnt 9.197356 hw_loss 0.170550 lr 0.00039724 rank 6
2023-02-22 12:20:40,397 DEBUG TRAIN Batch 19/0 loss 10.026623 loss_att 10.044359 loss_ctc 13.299070 loss_rnnt 9.493635 hw_loss 0.174589 lr 0.00039713 rank 3
2023-02-22 12:20:40,399 DEBUG TRAIN Batch 19/0 loss 10.247508 loss_att 9.791601 loss_ctc 13.032435 loss_rnnt 9.851499 hw_loss 0.217250 lr 0.00039720 rank 4
2023-02-22 12:20:40,399 DEBUG TRAIN Batch 19/0 loss 11.856043 loss_att 11.026419 loss_ctc 14.967289 loss_rnnt 11.491091 hw_loss 0.217580 lr 0.00039715 rank 2
2023-02-22 12:20:40,405 DEBUG TRAIN Batch 19/0 loss 10.355121 loss_att 9.672394 loss_ctc 12.831313 loss_rnnt 10.036695 hw_loss 0.234022 lr 0.00039717 rank 7
2023-02-22 12:20:40,416 DEBUG TRAIN Batch 19/0 loss 10.663269 loss_att 10.599988 loss_ctc 12.625355 loss_rnnt 10.316789 hw_loss 0.182859 lr 0.00039724 rank 5
2023-02-22 12:20:40,429 DEBUG TRAIN Batch 19/0 loss 9.732754 loss_att 9.009144 loss_ctc 12.081182 loss_rnnt 9.444945 hw_loss 0.223886 lr 0.00039725 rank 1
2023-02-22 12:21:53,907 DEBUG TRAIN Batch 19/100 loss 4.412344 loss_att 8.411614 loss_ctc 5.924088 loss_rnnt 3.371118 hw_loss 0.074638 lr 0.00039701 rank 3
2023-02-22 12:21:53,909 DEBUG TRAIN Batch 19/100 loss 8.640466 loss_att 11.644935 loss_ctc 10.243216 loss_rnnt 7.792226 hw_loss 0.063086 lr 0.00039710 rank 0
2023-02-22 12:21:53,910 DEBUG TRAIN Batch 19/100 loss 11.513109 loss_att 14.840298 loss_ctc 21.249989 loss_rnnt 9.514623 hw_loss 0.065247 lr 0.00039712 rank 1
2023-02-22 12:21:53,911 DEBUG TRAIN Batch 19/100 loss 2.859102 loss_att 4.952964 loss_ctc 3.059550 loss_rnnt 2.357355 hw_loss 0.105468 lr 0.00039708 rank 4
2023-02-22 12:21:53,911 DEBUG TRAIN Batch 19/100 loss 16.399029 loss_att 16.726986 loss_ctc 17.799124 loss_rnnt 16.110237 hw_loss 0.068480 lr 0.00039711 rank 5
2023-02-22 12:21:53,914 DEBUG TRAIN Batch 19/100 loss 3.167239 loss_att 5.967518 loss_ctc 7.123701 loss_rnnt 2.064515 hw_loss 0.028388 lr 0.00039705 rank 7
2023-02-22 12:21:53,915 DEBUG TRAIN Batch 19/100 loss 11.694416 loss_att 13.973093 loss_ctc 14.985877 loss_rnnt 10.774002 hw_loss 0.048409 lr 0.00039702 rank 2
2023-02-22 12:21:53,918 DEBUG TRAIN Batch 19/100 loss 6.820620 loss_att 8.678806 loss_ctc 8.611578 loss_rnnt 6.207242 hw_loss 0.005523 lr 0.00039712 rank 6
2023-02-22 12:23:08,530 DEBUG TRAIN Batch 19/200 loss 5.274275 loss_att 10.390275 loss_ctc 9.547438 loss_rnnt 3.620700 hw_loss 0.113663 lr 0.00039699 rank 5
2023-02-22 12:23:08,531 DEBUG TRAIN Batch 19/200 loss 17.665173 loss_att 17.566425 loss_ctc 19.380302 loss_rnnt 17.391233 hw_loss 0.121884 lr 0.00039695 rank 4
2023-02-22 12:23:08,531 DEBUG TRAIN Batch 19/200 loss 6.356527 loss_att 8.999212 loss_ctc 13.775592 loss_rnnt 4.724073 hw_loss 0.215078 lr 0.00039690 rank 2
2023-02-22 12:23:08,532 DEBUG TRAIN Batch 19/200 loss 5.520358 loss_att 8.772184 loss_ctc 7.274316 loss_rnnt 4.559559 hw_loss 0.143572 lr 0.00039692 rank 7
2023-02-22 12:23:08,535 DEBUG TRAIN Batch 19/200 loss 11.524196 loss_att 14.102633 loss_ctc 17.625881 loss_rnnt 10.192487 hw_loss 0.004619 lr 0.00039698 rank 0
2023-02-22 12:23:08,535 DEBUG TRAIN Batch 19/200 loss 7.663548 loss_att 9.247023 loss_ctc 14.080435 loss_rnnt 6.401029 hw_loss 0.169198 lr 0.00039700 rank 1
2023-02-22 12:23:08,537 DEBUG TRAIN Batch 19/200 loss 8.094990 loss_att 12.288686 loss_ctc 12.548285 loss_rnnt 6.610155 hw_loss 0.098107 lr 0.00039688 rank 3
2023-02-22 12:23:08,539 DEBUG TRAIN Batch 19/200 loss 5.755261 loss_att 9.973253 loss_ctc 8.839921 loss_rnnt 4.415231 hw_loss 0.159646 lr 0.00039699 rank 6
2023-02-22 12:24:24,974 DEBUG TRAIN Batch 19/300 loss 5.550201 loss_att 8.180586 loss_ctc 6.092818 loss_rnnt 4.920432 hw_loss 0.058768 lr 0.00039683 rank 4
2023-02-22 12:24:24,975 DEBUG TRAIN Batch 19/300 loss 8.131840 loss_att 12.086803 loss_ctc 14.252367 loss_rnnt 6.456705 hw_loss 0.127635 lr 0.00039677 rank 2
2023-02-22 12:24:24,977 DEBUG TRAIN Batch 19/300 loss 14.044884 loss_att 16.211546 loss_ctc 23.328218 loss_rnnt 12.334426 hw_loss 0.073777 lr 0.00039687 rank 6
2023-02-22 12:24:24,977 DEBUG TRAIN Batch 19/300 loss 14.784100 loss_att 15.671419 loss_ctc 16.262178 loss_rnnt 14.374185 hw_loss 0.066326 lr 0.00039676 rank 3
2023-02-22 12:24:24,977 DEBUG TRAIN Batch 19/300 loss 9.102029 loss_att 9.612331 loss_ctc 8.377357 loss_rnnt 9.024806 hw_loss 0.134599 lr 0.00039685 rank 0
2023-02-22 12:24:25,004 DEBUG TRAIN Batch 19/300 loss 7.720756 loss_att 10.772034 loss_ctc 13.269501 loss_rnnt 6.288601 hw_loss 0.153875 lr 0.00039686 rank 5
2023-02-22 12:24:25,013 DEBUG TRAIN Batch 19/300 loss 9.946054 loss_att 11.697359 loss_ctc 12.801982 loss_rnnt 9.128676 hw_loss 0.161861 lr 0.00039680 rank 7
2023-02-22 12:24:25,027 DEBUG TRAIN Batch 19/300 loss 10.920728 loss_att 15.648653 loss_ctc 16.009462 loss_rnnt 9.245853 hw_loss 0.095231 lr 0.00039687 rank 1
2023-02-22 12:25:41,972 DEBUG TRAIN Batch 19/400 loss 8.329731 loss_att 11.080346 loss_ctc 10.925907 loss_rnnt 7.396741 hw_loss 0.068833 lr 0.00039667 rank 7
2023-02-22 12:25:41,975 DEBUG TRAIN Batch 19/400 loss 10.865134 loss_att 14.419014 loss_ctc 14.697405 loss_rnnt 9.602580 hw_loss 0.076515 lr 0.00039674 rank 5
2023-02-22 12:25:41,978 DEBUG TRAIN Batch 19/400 loss 10.501952 loss_att 12.112850 loss_ctc 12.587851 loss_rnnt 9.794202 hw_loss 0.201468 lr 0.00039674 rank 6
2023-02-22 12:25:41,981 DEBUG TRAIN Batch 19/400 loss 5.777714 loss_att 7.117930 loss_ctc 7.169788 loss_rnnt 5.221103 hw_loss 0.193046 lr 0.00039673 rank 0
2023-02-22 12:25:41,983 DEBUG TRAIN Batch 19/400 loss 13.625140 loss_att 18.905867 loss_ctc 19.621696 loss_rnnt 11.737226 hw_loss 0.060427 lr 0.00039675 rank 1
2023-02-22 12:25:41,986 DEBUG TRAIN Batch 19/400 loss 7.415067 loss_att 11.243149 loss_ctc 9.031113 loss_rnnt 6.419147 hw_loss 0.027809 lr 0.00039670 rank 4
2023-02-22 12:25:41,987 DEBUG TRAIN Batch 19/400 loss 15.316906 loss_att 18.871635 loss_ctc 21.710651 loss_rnnt 13.718113 hw_loss 0.066277 lr 0.00039665 rank 2
2023-02-22 12:25:42,031 DEBUG TRAIN Batch 19/400 loss 11.956637 loss_att 16.003483 loss_ctc 17.424875 loss_rnnt 10.413694 hw_loss 0.008393 lr 0.00039663 rank 3
2023-02-22 12:26:58,171 DEBUG TRAIN Batch 19/500 loss 2.892077 loss_att 4.851660 loss_ctc 5.016918 loss_rnnt 2.113877 hw_loss 0.193071 lr 0.00039660 rank 0
2023-02-22 12:26:58,171 DEBUG TRAIN Batch 19/500 loss 7.473883 loss_att 9.017074 loss_ctc 11.281321 loss_rnnt 6.586022 hw_loss 0.134183 lr 0.00039661 rank 5
2023-02-22 12:26:58,173 DEBUG TRAIN Batch 19/500 loss 9.706652 loss_att 12.309786 loss_ctc 9.755396 loss_rnnt 9.160485 hw_loss 0.035700 lr 0.00039662 rank 6
2023-02-22 12:26:58,174 DEBUG TRAIN Batch 19/500 loss 5.293901 loss_att 9.684738 loss_ctc 10.767584 loss_rnnt 3.619365 hw_loss 0.124772 lr 0.00039655 rank 7
2023-02-22 12:26:58,175 DEBUG TRAIN Batch 19/500 loss 18.796558 loss_att 18.220749 loss_ctc 21.041115 loss_rnnt 18.597790 hw_loss 0.027479 lr 0.00039662 rank 1
2023-02-22 12:26:58,178 DEBUG TRAIN Batch 19/500 loss 5.164976 loss_att 7.369311 loss_ctc 6.362408 loss_rnnt 4.521518 hw_loss 0.080501 lr 0.00039658 rank 4
2023-02-22 12:26:58,181 DEBUG TRAIN Batch 19/500 loss 15.530067 loss_att 19.388750 loss_ctc 21.577765 loss_rnnt 13.849590 hw_loss 0.191962 lr 0.00039651 rank 3
2023-02-22 12:26:58,181 DEBUG TRAIN Batch 19/500 loss 6.428895 loss_att 11.780981 loss_ctc 9.344747 loss_rnnt 4.922591 hw_loss 0.088325 lr 0.00039652 rank 2
2023-02-22 12:28:13,577 DEBUG TRAIN Batch 19/600 loss 13.766642 loss_att 16.174881 loss_ctc 20.684401 loss_rnnt 12.307733 hw_loss 0.102922 lr 0.00039640 rank 2
2023-02-22 12:28:13,580 DEBUG TRAIN Batch 19/600 loss 16.862066 loss_att 17.877918 loss_ctc 21.451826 loss_rnnt 15.979955 hw_loss 0.125576 lr 0.00039649 rank 6
2023-02-22 12:28:13,580 DEBUG TRAIN Batch 19/600 loss 17.327288 loss_att 17.523071 loss_ctc 22.284151 loss_rnnt 16.584326 hw_loss 0.080419 lr 0.00039638 rank 3
2023-02-22 12:28:13,581 DEBUG TRAIN Batch 19/600 loss 10.273793 loss_att 11.206533 loss_ctc 13.278125 loss_rnnt 9.660407 hw_loss 0.049240 lr 0.00039649 rank 5
2023-02-22 12:28:13,581 DEBUG TRAIN Batch 19/600 loss 8.880608 loss_att 11.261368 loss_ctc 12.542759 loss_rnnt 7.851926 hw_loss 0.120454 lr 0.00039650 rank 1
2023-02-22 12:28:13,581 DEBUG TRAIN Batch 19/600 loss 4.675433 loss_att 6.777107 loss_ctc 5.442220 loss_rnnt 4.113380 hw_loss 0.074025 lr 0.00039642 rank 7
2023-02-22 12:28:13,610 DEBUG TRAIN Batch 19/600 loss 7.486263 loss_att 7.821817 loss_ctc 10.238253 loss_rnnt 6.947970 hw_loss 0.195470 lr 0.00039648 rank 0
2023-02-22 12:28:13,623 DEBUG TRAIN Batch 19/600 loss 10.172394 loss_att 10.693848 loss_ctc 11.837187 loss_rnnt 9.800593 hw_loss 0.085382 lr 0.00039645 rank 4
2023-02-22 12:29:31,126 DEBUG TRAIN Batch 19/700 loss 4.308589 loss_att 9.613811 loss_ctc 7.256545 loss_rnnt 2.754904 hw_loss 0.186712 lr 0.00039633 rank 4
2023-02-22 12:29:31,135 DEBUG TRAIN Batch 19/700 loss 10.729233 loss_att 12.741371 loss_ctc 13.767984 loss_rnnt 9.905229 hw_loss 0.030766 lr 0.00039626 rank 3
2023-02-22 12:29:31,135 DEBUG TRAIN Batch 19/700 loss 6.102370 loss_att 9.569276 loss_ctc 8.603968 loss_rnnt 5.014684 hw_loss 0.113923 lr 0.00039636 rank 5
2023-02-22 12:29:31,137 DEBUG TRAIN Batch 19/700 loss 19.244473 loss_att 21.446945 loss_ctc 25.192631 loss_rnnt 17.987513 hw_loss 0.043833 lr 0.00039637 rank 1
2023-02-22 12:29:31,143 DEBUG TRAIN Batch 19/700 loss 6.783587 loss_att 9.430574 loss_ctc 8.437965 loss_rnnt 5.984852 hw_loss 0.091412 lr 0.00039637 rank 6
2023-02-22 12:29:31,146 DEBUG TRAIN Batch 19/700 loss 2.097127 loss_att 5.209395 loss_ctc 2.911838 loss_rnnt 1.351521 hw_loss 0.027234 lr 0.00039635 rank 0
2023-02-22 12:29:31,152 DEBUG TRAIN Batch 19/700 loss 18.419094 loss_att 22.064873 loss_ctc 25.805424 loss_rnnt 16.684721 hw_loss 0.038200 lr 0.00039627 rank 2
2023-02-22 12:29:31,156 DEBUG TRAIN Batch 19/700 loss 3.355718 loss_att 6.839746 loss_ctc 4.878817 loss_rnnt 2.347741 hw_loss 0.202673 lr 0.00039630 rank 7
2023-02-22 12:30:45,560 DEBUG TRAIN Batch 19/800 loss 4.009437 loss_att 5.895321 loss_ctc 4.642021 loss_rnnt 3.508038 hw_loss 0.074770 lr 0.00039620 rank 4
2023-02-22 12:30:45,563 DEBUG TRAIN Batch 19/800 loss 3.941826 loss_att 6.716676 loss_ctc 5.999624 loss_rnnt 3.011282 hw_loss 0.189752 lr 0.00039624 rank 6
2023-02-22 12:30:45,565 DEBUG TRAIN Batch 19/800 loss 4.493309 loss_att 7.595873 loss_ctc 7.652560 loss_rnnt 3.412739 hw_loss 0.072795 lr 0.00039624 rank 5
2023-02-22 12:30:45,566 DEBUG TRAIN Batch 19/800 loss 12.190513 loss_att 15.158549 loss_ctc 20.141815 loss_rnnt 10.467518 hw_loss 0.129773 lr 0.00039618 rank 7
2023-02-22 12:30:45,569 DEBUG TRAIN Batch 19/800 loss 3.083274 loss_att 5.397271 loss_ctc 5.133508 loss_rnnt 2.304412 hw_loss 0.080059 lr 0.00039625 rank 1
2023-02-22 12:30:45,568 DEBUG TRAIN Batch 19/800 loss 24.530445 loss_att 24.153887 loss_ctc 29.248562 loss_rnnt 23.957382 hw_loss 0.036174 lr 0.00039615 rank 2
2023-02-22 12:30:45,569 DEBUG TRAIN Batch 19/800 loss 9.652782 loss_att 12.779289 loss_ctc 15.901884 loss_rnnt 8.128140 hw_loss 0.123987 lr 0.00039613 rank 3
2023-02-22 12:30:45,570 DEBUG TRAIN Batch 19/800 loss 5.631564 loss_att 8.038487 loss_ctc 6.270110 loss_rnnt 5.019435 hw_loss 0.085509 lr 0.00039623 rank 0
2023-02-22 12:31:59,829 DEBUG TRAIN Batch 19/900 loss 5.475471 loss_att 7.173924 loss_ctc 6.596600 loss_rnnt 4.905347 hw_loss 0.151782 lr 0.00039610 rank 0
2023-02-22 12:31:59,829 DEBUG TRAIN Batch 19/900 loss 10.110252 loss_att 13.384084 loss_ctc 12.141685 loss_rnnt 9.170575 hw_loss 0.026350 lr 0.00039612 rank 1
2023-02-22 12:31:59,829 DEBUG TRAIN Batch 19/900 loss 10.597728 loss_att 19.856934 loss_ctc 14.395727 loss_rnnt 8.182643 hw_loss 0.106583 lr 0.00039608 rank 4
2023-02-22 12:31:59,832 DEBUG TRAIN Batch 19/900 loss 4.927722 loss_att 6.287848 loss_ctc 5.441177 loss_rnnt 4.566787 hw_loss 0.038341 lr 0.00039601 rank 3
2023-02-22 12:31:59,832 DEBUG TRAIN Batch 19/900 loss 3.556726 loss_att 7.579622 loss_ctc 4.681562 loss_rnnt 2.542517 hw_loss 0.111846 lr 0.00039605 rank 7
2023-02-22 12:31:59,832 DEBUG TRAIN Batch 19/900 loss 5.868244 loss_att 7.943766 loss_ctc 9.525493 loss_rnnt 4.893905 hw_loss 0.134253 lr 0.00039611 rank 5
2023-02-22 12:31:59,833 DEBUG TRAIN Batch 19/900 loss 5.875631 loss_att 10.592651 loss_ctc 8.568211 loss_rnnt 4.570037 hw_loss 0.005963 lr 0.00039602 rank 2
2023-02-22 12:31:59,835 DEBUG TRAIN Batch 19/900 loss 5.480729 loss_att 7.739251 loss_ctc 6.830373 loss_rnnt 4.794774 hw_loss 0.101809 lr 0.00039612 rank 6
2023-02-22 12:33:15,314 DEBUG TRAIN Batch 19/1000 loss 5.502108 loss_att 10.484289 loss_ctc 10.242599 loss_rnnt 3.833262 hw_loss 0.075645 lr 0.00039598 rank 0
2023-02-22 12:33:15,315 DEBUG TRAIN Batch 19/1000 loss 4.582235 loss_att 6.797958 loss_ctc 7.234161 loss_rnnt 3.713957 hw_loss 0.134142 lr 0.00039595 rank 4
2023-02-22 12:33:15,319 DEBUG TRAIN Batch 19/1000 loss 14.947552 loss_att 18.561161 loss_ctc 19.596968 loss_rnnt 13.567917 hw_loss 0.069359 lr 0.00039593 rank 7
2023-02-22 12:33:15,320 DEBUG TRAIN Batch 19/1000 loss 16.676601 loss_att 21.432686 loss_ctc 21.620535 loss_rnnt 14.977087 hw_loss 0.167072 lr 0.00039599 rank 5
2023-02-22 12:33:15,321 DEBUG TRAIN Batch 19/1000 loss 21.409578 loss_att 26.523745 loss_ctc 28.552826 loss_rnnt 19.373688 hw_loss 0.113673 lr 0.00039600 rank 1
2023-02-22 12:33:15,323 DEBUG TRAIN Batch 19/1000 loss 7.624655 loss_att 10.474187 loss_ctc 12.050298 loss_rnnt 6.421171 hw_loss 0.081548 lr 0.00039589 rank 3
2023-02-22 12:33:15,326 DEBUG TRAIN Batch 19/1000 loss 7.111395 loss_att 9.731921 loss_ctc 11.778170 loss_rnnt 5.931320 hw_loss 0.063249 lr 0.00039590 rank 2
2023-02-22 12:33:15,369 DEBUG TRAIN Batch 19/1000 loss 8.228351 loss_att 10.799828 loss_ctc 8.552427 loss_rnnt 7.637621 hw_loss 0.062294 lr 0.00039599 rank 6
2023-02-22 12:34:32,544 DEBUG TRAIN Batch 19/1100 loss 7.097207 loss_att 10.132156 loss_ctc 11.255167 loss_rnnt 5.903278 hw_loss 0.061019 lr 0.00039585 rank 0
2023-02-22 12:34:32,544 DEBUG TRAIN Batch 19/1100 loss 5.088987 loss_att 9.738872 loss_ctc 6.487111 loss_rnnt 3.938418 hw_loss 0.064077 lr 0.00039580 rank 7
2023-02-22 12:34:32,544 DEBUG TRAIN Batch 19/1100 loss 4.956723 loss_att 8.609653 loss_ctc 7.655617 loss_rnnt 3.830230 hw_loss 0.067600 lr 0.00039577 rank 2
2023-02-22 12:34:32,547 DEBUG TRAIN Batch 19/1100 loss 7.775288 loss_att 11.621965 loss_ctc 13.066273 loss_rnnt 6.277901 hw_loss 0.042350 lr 0.00039583 rank 4
2023-02-22 12:34:32,547 DEBUG TRAIN Batch 19/1100 loss 12.973526 loss_att 17.283928 loss_ctc 22.638672 loss_rnnt 10.773806 hw_loss 0.091786 lr 0.00039586 rank 5
2023-02-22 12:34:32,548 DEBUG TRAIN Batch 19/1100 loss 9.202240 loss_att 11.999521 loss_ctc 12.626528 loss_rnnt 8.120267 hw_loss 0.123646 lr 0.00039587 rank 6
2023-02-22 12:34:32,549 DEBUG TRAIN Batch 19/1100 loss 13.342174 loss_att 18.062180 loss_ctc 20.131792 loss_rnnt 11.459827 hw_loss 0.061994 lr 0.00039576 rank 3
2023-02-22 12:34:32,552 DEBUG TRAIN Batch 19/1100 loss 10.995131 loss_att 13.752538 loss_ctc 15.692062 loss_rnnt 9.789932 hw_loss 0.051489 lr 0.00039588 rank 1
2023-02-22 12:35:48,024 DEBUG TRAIN Batch 19/1200 loss 6.078788 loss_att 7.926466 loss_ctc 6.564799 loss_rnnt 5.594292 hw_loss 0.094049 lr 0.00039571 rank 4
2023-02-22 12:35:48,029 DEBUG TRAIN Batch 19/1200 loss 10.357070 loss_att 10.312811 loss_ctc 16.436136 loss_rnnt 9.516736 hw_loss 0.072456 lr 0.00039574 rank 5
2023-02-22 12:35:48,030 DEBUG TRAIN Batch 19/1200 loss 8.193830 loss_att 10.606427 loss_ctc 11.250165 loss_rnnt 7.253320 hw_loss 0.094650 lr 0.00039568 rank 7
2023-02-22 12:35:48,031 DEBUG TRAIN Batch 19/1200 loss 8.043637 loss_att 12.366623 loss_ctc 10.829728 loss_rnnt 6.737184 hw_loss 0.131957 lr 0.00039573 rank 0
2023-02-22 12:35:48,033 DEBUG TRAIN Batch 19/1200 loss 7.104964 loss_att 8.873564 loss_ctc 11.029810 loss_rnnt 6.185243 hw_loss 0.080039 lr 0.00039564 rank 3
2023-02-22 12:35:48,035 DEBUG TRAIN Batch 19/1200 loss 5.791096 loss_att 7.511897 loss_ctc 9.533229 loss_rnnt 4.897010 hw_loss 0.095577 lr 0.00039575 rank 6
2023-02-22 12:35:48,034 DEBUG TRAIN Batch 19/1200 loss 7.007630 loss_att 9.147989 loss_ctc 10.242685 loss_rnnt 6.047847 hw_loss 0.188194 lr 0.00039565 rank 2
2023-02-22 12:35:48,078 DEBUG TRAIN Batch 19/1200 loss 11.215117 loss_att 12.446430 loss_ctc 14.152507 loss_rnnt 10.525390 hw_loss 0.097148 lr 0.00039575 rank 1
2023-02-22 12:37:03,476 DEBUG TRAIN Batch 19/1300 loss 8.807754 loss_att 10.282231 loss_ctc 14.030167 loss_rnnt 7.737314 hw_loss 0.148543 lr 0.00039562 rank 5
2023-02-22 12:37:03,478 DEBUG TRAIN Batch 19/1300 loss 2.448347 loss_att 6.027733 loss_ctc 2.092309 loss_rnnt 1.748137 hw_loss 0.059635 lr 0.00039561 rank 0
2023-02-22 12:37:03,479 DEBUG TRAIN Batch 19/1300 loss 8.825080 loss_att 9.604214 loss_ctc 13.483330 loss_rnnt 8.013949 hw_loss 0.064132 lr 0.00039556 rank 7
2023-02-22 12:37:03,481 DEBUG TRAIN Batch 19/1300 loss 13.949744 loss_att 18.050900 loss_ctc 21.670696 loss_rnnt 12.083583 hw_loss 0.030883 lr 0.00039551 rank 3
2023-02-22 12:37:03,480 DEBUG TRAIN Batch 19/1300 loss 9.764058 loss_att 9.634701 loss_ctc 11.477558 loss_rnnt 9.532398 hw_loss 0.054495 lr 0.00039558 rank 4
2023-02-22 12:37:03,481 DEBUG TRAIN Batch 19/1300 loss 20.292839 loss_att 20.431471 loss_ctc 27.423527 loss_rnnt 19.233929 hw_loss 0.150798 lr 0.00039563 rank 1
2023-02-22 12:37:03,484 DEBUG TRAIN Batch 19/1300 loss 1.714175 loss_att 4.721839 loss_ctc 2.879392 loss_rnnt 0.930082 hw_loss 0.050996 lr 0.00039553 rank 2
2023-02-22 12:37:03,531 DEBUG TRAIN Batch 19/1300 loss 6.366096 loss_att 10.562814 loss_ctc 8.471148 loss_rnnt 5.162111 hw_loss 0.157441 lr 0.00039562 rank 6
2023-02-22 12:38:21,160 DEBUG TRAIN Batch 19/1400 loss 10.418741 loss_att 12.753329 loss_ctc 15.580189 loss_rnnt 9.246498 hw_loss 0.032124 lr 0.00039548 rank 0
2023-02-22 12:38:21,161 DEBUG TRAIN Batch 19/1400 loss 9.776252 loss_att 11.475955 loss_ctc 9.572604 loss_rnnt 9.425445 hw_loss 0.071288 lr 0.00039549 rank 5
2023-02-22 12:38:21,163 DEBUG TRAIN Batch 19/1400 loss 2.214704 loss_att 6.348730 loss_ctc 2.556153 loss_rnnt 1.284984 hw_loss 0.107603 lr 0.00039550 rank 1
2023-02-22 12:38:21,164 DEBUG TRAIN Batch 19/1400 loss 7.546025 loss_att 10.307714 loss_ctc 11.146111 loss_rnnt 6.432890 hw_loss 0.151472 lr 0.00039539 rank 3
2023-02-22 12:38:21,164 DEBUG TRAIN Batch 19/1400 loss 5.524990 loss_att 10.409017 loss_ctc 8.846538 loss_rnnt 3.979949 hw_loss 0.235054 lr 0.00039546 rank 4
2023-02-22 12:38:21,164 DEBUG TRAIN Batch 19/1400 loss 3.569641 loss_att 6.972921 loss_ctc 6.098630 loss_rnnt 2.464589 hw_loss 0.163496 lr 0.00039543 rank 7
2023-02-22 12:38:21,171 DEBUG TRAIN Batch 19/1400 loss 6.139768 loss_att 8.020471 loss_ctc 7.157466 loss_rnnt 5.488351 hw_loss 0.261717 lr 0.00039550 rank 6
2023-02-22 12:38:21,170 DEBUG TRAIN Batch 19/1400 loss 9.476018 loss_att 10.367444 loss_ctc 13.468310 loss_rnnt 8.724995 hw_loss 0.075810 lr 0.00039540 rank 2
2023-02-22 12:39:36,548 DEBUG TRAIN Batch 19/1500 loss 16.711399 loss_att 20.741259 loss_ctc 18.249075 loss_rnnt 15.653956 hw_loss 0.087089 lr 0.00039527 rank 3
2023-02-22 12:39:36,549 DEBUG TRAIN Batch 19/1500 loss 8.759506 loss_att 10.311293 loss_ctc 9.816452 loss_rnnt 8.226073 hw_loss 0.154031 lr 0.00039528 rank 2
2023-02-22 12:39:36,549 DEBUG TRAIN Batch 19/1500 loss 11.530202 loss_att 16.140232 loss_ctc 20.294350 loss_rnnt 9.329792 hw_loss 0.205969 lr 0.00039531 rank 7
2023-02-22 12:39:36,550 DEBUG TRAIN Batch 19/1500 loss 2.207775 loss_att 6.343463 loss_ctc 4.165483 loss_rnnt 1.104016 hw_loss 0.029238 lr 0.00039533 rank 4
2023-02-22 12:39:36,550 DEBUG TRAIN Batch 19/1500 loss 6.197188 loss_att 9.804872 loss_ctc 9.046906 loss_rnnt 5.040689 hw_loss 0.103124 lr 0.00039536 rank 0
2023-02-22 12:39:36,551 DEBUG TRAIN Batch 19/1500 loss 9.405384 loss_att 11.740885 loss_ctc 12.005999 loss_rnnt 8.576900 hw_loss 0.027441 lr 0.00039537 rank 5
2023-02-22 12:39:36,554 DEBUG TRAIN Batch 19/1500 loss 6.099594 loss_att 9.623861 loss_ctc 9.923746 loss_rnnt 4.827454 hw_loss 0.107625 lr 0.00039538 rank 1
2023-02-22 12:39:36,556 DEBUG TRAIN Batch 19/1500 loss 4.900079 loss_att 7.338652 loss_ctc 7.080303 loss_rnnt 4.024120 hw_loss 0.182904 lr 0.00039537 rank 6
2023-02-22 12:40:50,056 DEBUG TRAIN Batch 19/1600 loss 15.719397 loss_att 16.515432 loss_ctc 19.384466 loss_rnnt 15.047456 hw_loss 0.045107 lr 0.00039524 rank 0
2023-02-22 12:40:50,056 DEBUG TRAIN Batch 19/1600 loss 13.942159 loss_att 18.084496 loss_ctc 21.508049 loss_rnnt 12.015091 hw_loss 0.168405 lr 0.00039525 rank 5
2023-02-22 12:40:50,058 DEBUG TRAIN Batch 19/1600 loss 10.642217 loss_att 15.088413 loss_ctc 10.516783 loss_rnnt 9.700495 hw_loss 0.129763 lr 0.00039521 rank 4
2023-02-22 12:40:50,059 DEBUG TRAIN Batch 19/1600 loss 12.100218 loss_att 13.150042 loss_ctc 15.548185 loss_rnnt 11.375168 hw_loss 0.103794 lr 0.00039514 rank 3
2023-02-22 12:40:50,060 DEBUG TRAIN Batch 19/1600 loss 6.510310 loss_att 9.386717 loss_ctc 11.723134 loss_rnnt 5.167824 hw_loss 0.135301 lr 0.00039525 rank 6
2023-02-22 12:40:50,060 DEBUG TRAIN Batch 19/1600 loss 9.545358 loss_att 13.395140 loss_ctc 17.719868 loss_rnnt 7.599356 hw_loss 0.161457 lr 0.00039518 rank 7
2023-02-22 12:40:50,065 DEBUG TRAIN Batch 19/1600 loss 7.370295 loss_att 10.249284 loss_ctc 9.172132 loss_rnnt 6.515387 hw_loss 0.072872 lr 0.00039526 rank 1
2023-02-22 12:40:50,066 DEBUG TRAIN Batch 19/1600 loss 20.302145 loss_att 25.829681 loss_ctc 32.927090 loss_rnnt 17.426453 hw_loss 0.162861 lr 0.00039516 rank 2
2023-02-22 12:42:05,341 DEBUG TRAIN Batch 19/1700 loss 11.036674 loss_att 12.881845 loss_ctc 13.698212 loss_rnnt 10.203484 hw_loss 0.204908 lr 0.00039506 rank 7
2023-02-22 12:42:05,341 DEBUG TRAIN Batch 19/1700 loss 14.912879 loss_att 18.167377 loss_ctc 22.812128 loss_rnnt 13.177382 hw_loss 0.058810 lr 0.00039513 rank 1
2023-02-22 12:42:05,342 DEBUG TRAIN Batch 19/1700 loss 5.680404 loss_att 8.553773 loss_ctc 8.025030 loss_rnnt 4.782064 hw_loss 0.020717 lr 0.00039512 rank 5
2023-02-22 12:42:05,343 DEBUG TRAIN Batch 19/1700 loss 9.101771 loss_att 12.160213 loss_ctc 15.042019 loss_rnnt 7.643913 hw_loss 0.101507 lr 0.00039502 rank 3
2023-02-22 12:42:05,343 DEBUG TRAIN Batch 19/1700 loss 6.431683 loss_att 8.412020 loss_ctc 6.512608 loss_rnnt 5.979420 hw_loss 0.085135 lr 0.00039503 rank 2
2023-02-22 12:42:05,343 DEBUG TRAIN Batch 19/1700 loss 13.493940 loss_att 17.407616 loss_ctc 16.327980 loss_rnnt 12.295965 hw_loss 0.070068 lr 0.00039511 rank 0
2023-02-22 12:42:05,344 DEBUG TRAIN Batch 19/1700 loss 9.792272 loss_att 10.980055 loss_ctc 11.478724 loss_rnnt 9.316888 hw_loss 0.024314 lr 0.00039513 rank 6
2023-02-22 12:42:05,345 DEBUG TRAIN Batch 19/1700 loss 14.809383 loss_att 17.763613 loss_ctc 22.625851 loss_rnnt 13.080314 hw_loss 0.180050 lr 0.00039509 rank 4
2023-02-22 12:43:23,108 DEBUG TRAIN Batch 19/1800 loss 9.055482 loss_att 11.556944 loss_ctc 13.406626 loss_rnnt 7.931719 hw_loss 0.081219 lr 0.00039499 rank 0
2023-02-22 12:43:23,111 DEBUG TRAIN Batch 19/1800 loss 6.825182 loss_att 9.583458 loss_ctc 10.418207 loss_rnnt 5.747931 hw_loss 0.087237 lr 0.00039501 rank 1
2023-02-22 12:43:23,113 DEBUG TRAIN Batch 19/1800 loss 8.170997 loss_att 10.524716 loss_ctc 12.813282 loss_rnnt 7.035585 hw_loss 0.085681 lr 0.00039496 rank 4
2023-02-22 12:43:23,114 DEBUG TRAIN Batch 19/1800 loss 10.116132 loss_att 13.039087 loss_ctc 14.649434 loss_rnnt 8.854278 hw_loss 0.136542 lr 0.00039500 rank 5
2023-02-22 12:43:23,115 DEBUG TRAIN Batch 19/1800 loss 8.599812 loss_att 10.558223 loss_ctc 10.283228 loss_rnnt 7.953759 hw_loss 0.056091 lr 0.00039494 rank 7
2023-02-22 12:43:23,116 DEBUG TRAIN Batch 19/1800 loss 11.279468 loss_att 14.431252 loss_ctc 16.100113 loss_rnnt 9.982644 hw_loss 0.044462 lr 0.00039500 rank 6
2023-02-22 12:43:23,118 DEBUG TRAIN Batch 19/1800 loss 12.264928 loss_att 13.390832 loss_ctc 16.881018 loss_rnnt 11.337139 hw_loss 0.163368 lr 0.00039490 rank 3
2023-02-22 12:43:23,162 DEBUG TRAIN Batch 19/1800 loss 8.429975 loss_att 9.917455 loss_ctc 12.992271 loss_rnnt 7.500122 hw_loss 0.045095 lr 0.00039491 rank 2
2023-02-22 12:44:37,316 DEBUG TRAIN Batch 19/1900 loss 16.510408 loss_att 14.901478 loss_ctc 20.083714 loss_rnnt 16.248978 hw_loss 0.200204 lr 0.00039484 rank 4
2023-02-22 12:44:37,316 DEBUG TRAIN Batch 19/1900 loss 14.150994 loss_att 14.099470 loss_ctc 16.608698 loss_rnnt 13.744926 hw_loss 0.166272 lr 0.00039488 rank 5
2023-02-22 12:44:37,319 DEBUG TRAIN Batch 19/1900 loss 6.375275 loss_att 12.088929 loss_ctc 6.618951 loss_rnnt 5.189939 hw_loss 0.018965 lr 0.00039477 rank 3
2023-02-22 12:44:37,319 DEBUG TRAIN Batch 19/1900 loss 7.452641 loss_att 8.094821 loss_ctc 8.592980 loss_rnnt 7.035730 hw_loss 0.255806 lr 0.00039487 rank 0
2023-02-22 12:44:37,324 DEBUG TRAIN Batch 19/1900 loss 7.809893 loss_att 10.236305 loss_ctc 10.525633 loss_rnnt 6.905509 hw_loss 0.106882 lr 0.00039481 rank 7
2023-02-22 12:44:37,325 DEBUG TRAIN Batch 19/1900 loss 9.383179 loss_att 9.016924 loss_ctc 11.557044 loss_rnnt 9.038565 hw_loss 0.240030 lr 0.00039479 rank 2
2023-02-22 12:44:37,327 DEBUG TRAIN Batch 19/1900 loss 16.783775 loss_att 19.047880 loss_ctc 19.204763 loss_rnnt 15.956882 hw_loss 0.096142 lr 0.00039488 rank 6
2023-02-22 12:44:37,328 DEBUG TRAIN Batch 19/1900 loss 8.103281 loss_att 9.842649 loss_ctc 11.319000 loss_rnnt 7.272068 hw_loss 0.102331 lr 0.00039489 rank 1
2023-02-22 12:45:51,975 DEBUG TRAIN Batch 19/2000 loss 2.683266 loss_att 5.107928 loss_ctc 4.785343 loss_rnnt 1.882578 hw_loss 0.066522 lr 0.00039474 rank 0
2023-02-22 12:45:51,977 DEBUG TRAIN Batch 19/2000 loss 11.586364 loss_att 14.971379 loss_ctc 19.539965 loss_rnnt 9.746974 hw_loss 0.191075 lr 0.00039469 rank 7
2023-02-22 12:45:51,978 DEBUG TRAIN Batch 19/2000 loss 12.316505 loss_att 13.505473 loss_ctc 20.156353 loss_rnnt 10.940115 hw_loss 0.174908 lr 0.00039476 rank 6
2023-02-22 12:45:51,978 DEBUG TRAIN Batch 19/2000 loss 9.307150 loss_att 12.016205 loss_ctc 16.545570 loss_rnnt 7.737248 hw_loss 0.118062 lr 0.00039475 rank 5
2023-02-22 12:45:51,978 DEBUG TRAIN Batch 19/2000 loss 12.320983 loss_att 14.036499 loss_ctc 13.803566 loss_rnnt 11.729280 hw_loss 0.095475 lr 0.00039472 rank 4
2023-02-22 12:45:51,979 DEBUG TRAIN Batch 19/2000 loss 5.487671 loss_att 9.769242 loss_ctc 10.545341 loss_rnnt 3.884988 hw_loss 0.135024 lr 0.00039465 rank 3
2023-02-22 12:45:51,990 DEBUG TRAIN Batch 19/2000 loss 11.887171 loss_att 16.567734 loss_ctc 13.614154 loss_rnnt 10.720649 hw_loss 0.000273 lr 0.00039466 rank 2
2023-02-22 12:45:52,026 DEBUG TRAIN Batch 19/2000 loss 6.086487 loss_att 9.407645 loss_ctc 11.728096 loss_rnnt 4.651008 hw_loss 0.035688 lr 0.00039476 rank 1
2023-02-22 12:47:08,219 DEBUG TRAIN Batch 19/2100 loss 9.990493 loss_att 12.699757 loss_ctc 16.301678 loss_rnnt 8.581678 hw_loss 0.047758 lr 0.00039463 rank 6
2023-02-22 12:47:08,222 DEBUG TRAIN Batch 19/2100 loss 8.964763 loss_att 12.483677 loss_ctc 16.060280 loss_rnnt 7.216862 hw_loss 0.183841 lr 0.00039453 rank 3
2023-02-22 12:47:08,223 DEBUG TRAIN Batch 19/2100 loss 14.530790 loss_att 16.974464 loss_ctc 18.956758 loss_rnnt 13.389315 hw_loss 0.117398 lr 0.00039454 rank 2
2023-02-22 12:47:08,224 DEBUG TRAIN Batch 19/2100 loss 8.825629 loss_att 13.248276 loss_ctc 9.493693 loss_rnnt 7.812300 hw_loss 0.074484 lr 0.00039462 rank 0
2023-02-22 12:47:08,224 DEBUG TRAIN Batch 19/2100 loss 5.845210 loss_att 9.757297 loss_ctc 6.167724 loss_rnnt 4.991527 hw_loss 0.052996 lr 0.00039459 rank 4
2023-02-22 12:47:08,224 DEBUG TRAIN Batch 19/2100 loss 4.579091 loss_att 7.569506 loss_ctc 7.911348 loss_rnnt 3.466184 hw_loss 0.132232 lr 0.00039463 rank 5
2023-02-22 12:47:08,227 DEBUG TRAIN Batch 19/2100 loss 5.485813 loss_att 7.823645 loss_ctc 8.646736 loss_rnnt 4.566476 hw_loss 0.056838 lr 0.00039457 rank 7
2023-02-22 12:47:08,229 DEBUG TRAIN Batch 19/2100 loss 17.929657 loss_att 21.848217 loss_ctc 33.888851 loss_rnnt 14.926039 hw_loss 0.172522 lr 0.00039464 rank 1
2023-02-22 12:48:24,632 DEBUG TRAIN Batch 19/2200 loss 11.400719 loss_att 14.386263 loss_ctc 16.883003 loss_rnnt 10.072431 hw_loss 0.000390 lr 0.00039447 rank 4
2023-02-22 12:48:24,637 DEBUG TRAIN Batch 19/2200 loss 2.841608 loss_att 5.716312 loss_ctc 4.192799 loss_rnnt 2.078867 hw_loss 0.014327 lr 0.00039450 rank 0
2023-02-22 12:48:24,639 DEBUG TRAIN Batch 19/2200 loss 15.458977 loss_att 19.105822 loss_ctc 19.706253 loss_rnnt 14.155937 hw_loss 0.013813 lr 0.00039442 rank 2
2023-02-22 12:48:24,640 DEBUG TRAIN Batch 19/2200 loss 13.679419 loss_att 19.470524 loss_ctc 21.076054 loss_rnnt 11.523657 hw_loss 0.021230 lr 0.00039445 rank 7
2023-02-22 12:48:24,641 DEBUG TRAIN Batch 19/2200 loss 5.543169 loss_att 9.478451 loss_ctc 7.573620 loss_rnnt 4.436624 hw_loss 0.091430 lr 0.00039451 rank 5
2023-02-22 12:48:24,641 DEBUG TRAIN Batch 19/2200 loss 9.885486 loss_att 13.092145 loss_ctc 15.183890 loss_rnnt 8.519378 hw_loss 0.034354 lr 0.00039452 rank 1
2023-02-22 12:48:24,644 DEBUG TRAIN Batch 19/2200 loss 12.279094 loss_att 12.993090 loss_ctc 22.433033 loss_rnnt 10.728899 hw_loss 0.100382 lr 0.00039441 rank 3
2023-02-22 12:48:24,646 DEBUG TRAIN Batch 19/2200 loss 9.891212 loss_att 15.685500 loss_ctc 14.968453 loss_rnnt 7.999383 hw_loss 0.105010 lr 0.00039451 rank 6
2023-02-22 12:49:39,712 DEBUG TRAIN Batch 19/2300 loss 9.881549 loss_att 12.662469 loss_ctc 14.557482 loss_rnnt 8.654593 hw_loss 0.088712 lr 0.00039432 rank 7
2023-02-22 12:49:39,714 DEBUG TRAIN Batch 19/2300 loss 17.937355 loss_att 21.322968 loss_ctc 27.239132 loss_rnnt 15.961819 hw_loss 0.109082 lr 0.00039439 rank 6
2023-02-22 12:49:39,715 DEBUG TRAIN Batch 19/2300 loss 18.020552 loss_att 17.956865 loss_ctc 22.793182 loss_rnnt 17.355576 hw_loss 0.077557 lr 0.00039428 rank 3
2023-02-22 12:49:39,719 DEBUG TRAIN Batch 19/2300 loss 9.776919 loss_att 12.619131 loss_ctc 13.044203 loss_rnnt 8.730707 hw_loss 0.078998 lr 0.00039440 rank 1
2023-02-22 12:49:39,722 DEBUG TRAIN Batch 19/2300 loss 15.285837 loss_att 23.192133 loss_ctc 23.586420 loss_rnnt 12.522787 hw_loss 0.140713 lr 0.00039438 rank 5
2023-02-22 12:49:39,722 DEBUG TRAIN Batch 19/2300 loss 5.722468 loss_att 7.303939 loss_ctc 6.994988 loss_rnnt 5.147074 hw_loss 0.167685 lr 0.00039435 rank 4
2023-02-22 12:49:39,724 DEBUG TRAIN Batch 19/2300 loss 11.179425 loss_att 16.470133 loss_ctc 14.062492 loss_rnnt 9.709326 hw_loss 0.051653 lr 0.00039437 rank 0
2023-02-22 12:49:39,767 DEBUG TRAIN Batch 19/2300 loss 7.890108 loss_att 10.198997 loss_ctc 11.913420 loss_rnnt 6.832935 hw_loss 0.110539 lr 0.00039430 rank 2
2023-02-22 12:50:56,411 DEBUG TRAIN Batch 19/2400 loss 7.071744 loss_att 8.498544 loss_ctc 7.948244 loss_rnnt 6.625090 hw_loss 0.083300 lr 0.00039420 rank 7
2023-02-22 12:50:56,412 DEBUG TRAIN Batch 19/2400 loss 6.376175 loss_att 9.222293 loss_ctc 7.034950 loss_rnnt 5.694292 hw_loss 0.046544 lr 0.00039423 rank 4
2023-02-22 12:50:56,413 DEBUG TRAIN Batch 19/2400 loss 9.044913 loss_att 12.352768 loss_ctc 11.969963 loss_rnnt 7.900502 hw_loss 0.174062 lr 0.00039425 rank 0
2023-02-22 12:50:56,415 DEBUG TRAIN Batch 19/2400 loss 7.054390 loss_att 9.975658 loss_ctc 12.524102 loss_rnnt 5.685392 hw_loss 0.103967 lr 0.00039427 rank 6
2023-02-22 12:50:56,416 DEBUG TRAIN Batch 19/2400 loss 16.253473 loss_att 19.868170 loss_ctc 21.598669 loss_rnnt 14.779457 hw_loss 0.071971 lr 0.00039426 rank 5
2023-02-22 12:50:56,416 DEBUG TRAIN Batch 19/2400 loss 8.956763 loss_att 10.648594 loss_ctc 15.638714 loss_rnnt 7.650294 hw_loss 0.144705 lr 0.00039427 rank 1
2023-02-22 12:50:56,418 DEBUG TRAIN Batch 19/2400 loss 8.548330 loss_att 12.043648 loss_ctc 15.479267 loss_rnnt 6.854643 hw_loss 0.132185 lr 0.00039417 rank 2
2023-02-22 12:50:56,461 DEBUG TRAIN Batch 19/2400 loss 10.409110 loss_att 10.907875 loss_ctc 13.560509 loss_rnnt 9.797145 hw_loss 0.172551 lr 0.00039416 rank 3
2023-02-22 12:52:14,629 DEBUG TRAIN Batch 19/2500 loss 13.454115 loss_att 13.666980 loss_ctc 19.253803 loss_rnnt 12.539680 hw_loss 0.184820 lr 0.00039414 rank 5
2023-02-22 12:52:14,633 DEBUG TRAIN Batch 19/2500 loss 7.647603 loss_att 9.038078 loss_ctc 9.593781 loss_rnnt 7.030858 hw_loss 0.148423 lr 0.00039408 rank 7
2023-02-22 12:52:14,633 DEBUG TRAIN Batch 19/2500 loss 4.342406 loss_att 8.571921 loss_ctc 7.746420 loss_rnnt 2.979385 hw_loss 0.118594 lr 0.00039410 rank 4
2023-02-22 12:52:14,636 DEBUG TRAIN Batch 19/2500 loss 12.006175 loss_att 13.150515 loss_ctc 13.679179 loss_rnnt 11.511131 hw_loss 0.080829 lr 0.00039415 rank 1
2023-02-22 12:52:14,636 DEBUG TRAIN Batch 19/2500 loss 7.412627 loss_att 7.641867 loss_ctc 11.335156 loss_rnnt 6.733801 hw_loss 0.206202 lr 0.00039414 rank 6
2023-02-22 12:52:14,638 DEBUG TRAIN Batch 19/2500 loss 8.728135 loss_att 12.273170 loss_ctc 13.748176 loss_rnnt 7.315656 hw_loss 0.063999 lr 0.00039413 rank 0
2023-02-22 12:52:14,641 DEBUG TRAIN Batch 19/2500 loss 6.537835 loss_att 8.234670 loss_ctc 8.457197 loss_rnnt 5.932896 hw_loss 0.018107 lr 0.00039404 rank 3
2023-02-22 12:52:14,679 DEBUG TRAIN Batch 19/2500 loss 9.169918 loss_att 12.463077 loss_ctc 12.450961 loss_rnnt 8.040090 hw_loss 0.063233 lr 0.00039405 rank 2
2023-02-22 12:53:30,550 DEBUG TRAIN Batch 19/2600 loss 16.227154 loss_att 24.169882 loss_ctc 30.952114 loss_rnnt 12.645119 hw_loss 0.056551 lr 0.00039396 rank 7
2023-02-22 12:53:30,555 DEBUG TRAIN Batch 19/2600 loss 6.741515 loss_att 6.759685 loss_ctc 9.772616 loss_rnnt 6.260025 hw_loss 0.138206 lr 0.00039398 rank 4
2023-02-22 12:53:30,555 DEBUG TRAIN Batch 19/2600 loss 14.691701 loss_att 17.239441 loss_ctc 22.277420 loss_rnnt 13.154533 hw_loss 0.030356 lr 0.00039401 rank 0
2023-02-22 12:53:30,558 DEBUG TRAIN Batch 19/2600 loss 10.694405 loss_att 10.728998 loss_ctc 14.230130 loss_rnnt 10.083663 hw_loss 0.248237 lr 0.00039393 rank 2
2023-02-22 12:53:30,558 DEBUG TRAIN Batch 19/2600 loss 6.536401 loss_att 10.045736 loss_ctc 9.656559 loss_rnnt 5.359048 hw_loss 0.111497 lr 0.00039403 rank 1
2023-02-22 12:53:30,559 DEBUG TRAIN Batch 19/2600 loss 13.606652 loss_att 16.535725 loss_ctc 16.836563 loss_rnnt 12.557624 hw_loss 0.061046 lr 0.00039392 rank 3
2023-02-22 12:53:30,563 DEBUG TRAIN Batch 19/2600 loss 8.805714 loss_att 14.393123 loss_ctc 12.868429 loss_rnnt 7.111271 hw_loss 0.066122 lr 0.00039402 rank 5
2023-02-22 12:53:30,602 DEBUG TRAIN Batch 19/2600 loss 11.000436 loss_att 14.038950 loss_ctc 16.971638 loss_rnnt 9.596213 hw_loss 0.000675 lr 0.00039402 rank 6
2023-02-22 12:54:45,888 DEBUG TRAIN Batch 19/2700 loss 3.896049 loss_att 5.508327 loss_ctc 4.636955 loss_rnnt 3.436105 hw_loss 0.072563 lr 0.00039386 rank 4
2023-02-22 12:54:45,889 DEBUG TRAIN Batch 19/2700 loss 8.979987 loss_att 12.652950 loss_ctc 14.316679 loss_rnnt 7.468763 hw_loss 0.122011 lr 0.00039390 rank 6
2023-02-22 12:54:45,893 DEBUG TRAIN Batch 19/2700 loss 12.807369 loss_att 15.728363 loss_ctc 15.806252 loss_rnnt 11.792595 hw_loss 0.057606 lr 0.00039388 rank 0
2023-02-22 12:54:45,893 DEBUG TRAIN Batch 19/2700 loss 7.676589 loss_att 11.834839 loss_ctc 10.284168 loss_rnnt 6.444517 hw_loss 0.098898 lr 0.00039383 rank 7
2023-02-22 12:54:45,893 DEBUG TRAIN Batch 19/2700 loss 5.425407 loss_att 7.947342 loss_ctc 6.355428 loss_rnnt 4.796124 hw_loss 0.001674 lr 0.00039391 rank 1
2023-02-22 12:54:45,893 DEBUG TRAIN Batch 19/2700 loss 9.393595 loss_att 16.782946 loss_ctc 13.276510 loss_rnnt 7.352616 hw_loss 0.085099 lr 0.00039389 rank 5
2023-02-22 12:54:45,895 DEBUG TRAIN Batch 19/2700 loss 11.110742 loss_att 14.969482 loss_ctc 21.333374 loss_rnnt 8.896779 hw_loss 0.148493 lr 0.00039381 rank 2
2023-02-22 12:54:45,897 DEBUG TRAIN Batch 19/2700 loss 15.503368 loss_att 21.991251 loss_ctc 28.301525 loss_rnnt 12.384002 hw_loss 0.216318 lr 0.00039379 rank 3
2023-02-22 12:56:02,824 DEBUG TRAIN Batch 19/2800 loss 5.484923 loss_att 9.891483 loss_ctc 9.847930 loss_rnnt 3.950934 hw_loss 0.133018 lr 0.00039376 rank 0
2023-02-22 12:56:02,824 DEBUG TRAIN Batch 19/2800 loss 3.647684 loss_att 8.988821 loss_ctc 8.674170 loss_rnnt 1.870120 hw_loss 0.073385 lr 0.00039371 rank 7
2023-02-22 12:56:02,827 DEBUG TRAIN Batch 19/2800 loss 8.756468 loss_att 12.255011 loss_ctc 12.001339 loss_rnnt 7.554405 hw_loss 0.130697 lr 0.00039368 rank 2
2023-02-22 12:56:02,828 DEBUG TRAIN Batch 19/2800 loss 10.788321 loss_att 15.077052 loss_ctc 14.648359 loss_rnnt 9.306429 hw_loss 0.205266 lr 0.00039374 rank 4
2023-02-22 12:56:02,831 DEBUG TRAIN Batch 19/2800 loss 8.280665 loss_att 10.208477 loss_ctc 11.767057 loss_rnnt 7.385981 hw_loss 0.083005 lr 0.00039378 rank 6
2023-02-22 12:56:02,831 DEBUG TRAIN Batch 19/2800 loss 8.884770 loss_att 10.584237 loss_ctc 10.603245 loss_rnnt 8.226553 hw_loss 0.167239 lr 0.00039377 rank 5
2023-02-22 12:56:02,837 DEBUG TRAIN Batch 19/2800 loss 4.590439 loss_att 8.896564 loss_ctc 7.776171 loss_rnnt 3.246333 hw_loss 0.108968 lr 0.00039367 rank 3
2023-02-22 12:56:02,878 DEBUG TRAIN Batch 19/2800 loss 11.176137 loss_att 14.661236 loss_ctc 18.231632 loss_rnnt 9.498041 hw_loss 0.075644 lr 0.00039378 rank 1
2023-02-22 12:57:18,965 DEBUG TRAIN Batch 19/2900 loss 12.948529 loss_att 13.689452 loss_ctc 19.725660 loss_rnnt 11.827208 hw_loss 0.130350 lr 0.00039359 rank 7
2023-02-22 12:57:18,968 DEBUG TRAIN Batch 19/2900 loss 5.764032 loss_att 9.626657 loss_ctc 7.515354 loss_rnnt 4.723634 hw_loss 0.064432 lr 0.00039365 rank 5
2023-02-22 12:57:18,972 DEBUG TRAIN Batch 19/2900 loss 8.213309 loss_att 12.305411 loss_ctc 12.687680 loss_rnnt 6.763777 hw_loss 0.064741 lr 0.00039362 rank 4
2023-02-22 12:57:18,973 DEBUG TRAIN Batch 19/2900 loss 5.810521 loss_att 9.184734 loss_ctc 9.484744 loss_rnnt 4.631663 hw_loss 0.026473 lr 0.00039364 rank 0
2023-02-22 12:57:18,975 DEBUG TRAIN Batch 19/2900 loss 16.649734 loss_att 21.375942 loss_ctc 25.393745 loss_rnnt 14.476830 hw_loss 0.115864 lr 0.00039366 rank 1
2023-02-22 12:57:18,976 DEBUG TRAIN Batch 19/2900 loss 6.584008 loss_att 10.647941 loss_ctc 9.776514 loss_rnnt 5.330010 hw_loss 0.029144 lr 0.00039355 rank 3
2023-02-22 12:57:18,976 DEBUG TRAIN Batch 19/2900 loss 8.577332 loss_att 11.087263 loss_ctc 18.956293 loss_rnnt 6.673625 hw_loss 0.033483 lr 0.00039356 rank 2
2023-02-22 12:57:18,980 DEBUG TRAIN Batch 19/2900 loss 9.227568 loss_att 10.977474 loss_ctc 13.817331 loss_rnnt 8.241707 hw_loss 0.044832 lr 0.00039365 rank 6
2023-02-22 12:58:35,829 DEBUG TRAIN Batch 19/3000 loss 22.914103 loss_att 24.486691 loss_ctc 30.660627 loss_rnnt 21.511127 hw_loss 0.104222 lr 0.00039349 rank 4
2023-02-22 12:58:35,829 DEBUG TRAIN Batch 19/3000 loss 7.559618 loss_att 12.298580 loss_ctc 13.156496 loss_rnnt 5.817175 hw_loss 0.090750 lr 0.00039347 rank 7
2023-02-22 12:58:35,831 DEBUG TRAIN Batch 19/3000 loss 9.287103 loss_att 9.680511 loss_ctc 14.159209 loss_rnnt 8.478287 hw_loss 0.150974 lr 0.00039352 rank 0
2023-02-22 12:58:35,834 DEBUG TRAIN Batch 19/3000 loss 8.725428 loss_att 11.487597 loss_ctc 10.373087 loss_rnnt 7.859877 hw_loss 0.175181 lr 0.00039354 rank 1
2023-02-22 12:58:35,835 DEBUG TRAIN Batch 19/3000 loss 11.952559 loss_att 16.866924 loss_ctc 15.031705 loss_rnnt 10.510320 hw_loss 0.091526 lr 0.00039353 rank 6
2023-02-22 12:58:35,838 DEBUG TRAIN Batch 19/3000 loss 7.435565 loss_att 8.416386 loss_ctc 8.756906 loss_rnnt 7.019060 hw_loss 0.082807 lr 0.00039353 rank 5
2023-02-22 12:58:35,838 DEBUG TRAIN Batch 19/3000 loss 7.877537 loss_att 10.210096 loss_ctc 11.636521 loss_rnnt 6.884298 hw_loss 0.047866 lr 0.00039344 rank 2
2023-02-22 12:58:35,878 DEBUG TRAIN Batch 19/3000 loss 12.138461 loss_att 13.727040 loss_ctc 16.177973 loss_rnnt 11.176147 hw_loss 0.198744 lr 0.00039343 rank 3
2023-02-22 12:59:52,095 DEBUG TRAIN Batch 19/3100 loss 14.278904 loss_att 16.794043 loss_ctc 22.160191 loss_rnnt 12.656527 hw_loss 0.128459 lr 0.00039335 rank 7
2023-02-22 12:59:52,095 DEBUG TRAIN Batch 19/3100 loss 7.595142 loss_att 11.129704 loss_ctc 11.465949 loss_rnnt 6.313659 hw_loss 0.109619 lr 0.00039341 rank 5
2023-02-22 12:59:52,099 DEBUG TRAIN Batch 19/3100 loss 4.465755 loss_att 7.407706 loss_ctc 6.171028 loss_rnnt 3.571362 hw_loss 0.147438 lr 0.00039340 rank 0
2023-02-22 12:59:52,100 DEBUG TRAIN Batch 19/3100 loss 9.509798 loss_att 10.247761 loss_ctc 12.743983 loss_rnnt 8.868314 hw_loss 0.117499 lr 0.00039337 rank 4
2023-02-22 12:59:52,100 DEBUG TRAIN Batch 19/3100 loss 7.806025 loss_att 10.359969 loss_ctc 8.386027 loss_rnnt 7.206579 hw_loss 0.021233 lr 0.00039331 rank 3
2023-02-22 12:59:52,104 DEBUG TRAIN Batch 19/3100 loss 9.110006 loss_att 11.933310 loss_ctc 12.154060 loss_rnnt 8.067183 hw_loss 0.135542 lr 0.00039342 rank 1
2023-02-22 12:59:52,107 DEBUG TRAIN Batch 19/3100 loss 4.305066 loss_att 5.042082 loss_ctc 5.487702 loss_rnnt 3.967282 hw_loss 0.061305 lr 0.00039332 rank 2
2023-02-22 12:59:52,153 DEBUG TRAIN Batch 19/3100 loss 3.376510 loss_att 5.526173 loss_ctc 4.968585 loss_rnnt 2.626907 hw_loss 0.201363 lr 0.00039341 rank 6
2023-02-22 13:01:10,846 DEBUG TRAIN Batch 19/3200 loss 8.965055 loss_att 9.878932 loss_ctc 12.736496 loss_rnnt 8.207982 hw_loss 0.133946 lr 0.00039325 rank 4
2023-02-22 13:01:10,849 DEBUG TRAIN Batch 19/3200 loss 9.338054 loss_att 14.390993 loss_ctc 15.661980 loss_rnnt 7.430002 hw_loss 0.101763 lr 0.00039322 rank 7
2023-02-22 13:01:10,852 DEBUG TRAIN Batch 19/3200 loss 23.359629 loss_att 26.031223 loss_ctc 26.776646 loss_rnnt 22.353659 hw_loss 0.030095 lr 0.00039327 rank 0
2023-02-22 13:01:10,856 DEBUG TRAIN Batch 19/3200 loss 17.491293 loss_att 18.185480 loss_ctc 24.978588 loss_rnnt 16.284424 hw_loss 0.130736 lr 0.00039330 rank 1
2023-02-22 13:01:10,859 DEBUG TRAIN Batch 19/3200 loss 6.497960 loss_att 6.958150 loss_ctc 7.673648 loss_rnnt 6.122614 hw_loss 0.237279 lr 0.00039320 rank 2
2023-02-22 13:01:10,860 DEBUG TRAIN Batch 19/3200 loss 12.506100 loss_att 13.376493 loss_ctc 12.875479 loss_rnnt 12.223524 hw_loss 0.111088 lr 0.00039318 rank 3
2023-02-22 13:01:10,906 DEBUG TRAIN Batch 19/3200 loss 4.095438 loss_att 7.021749 loss_ctc 5.793113 loss_rnnt 3.258292 hw_loss 0.047861 lr 0.00039329 rank 6
2023-02-22 13:01:10,934 DEBUG TRAIN Batch 19/3200 loss 7.245835 loss_att 9.845242 loss_ctc 10.028736 loss_rnnt 6.334669 hw_loss 0.037936 lr 0.00039328 rank 5
2023-02-22 13:02:24,436 DEBUG TRAIN Batch 19/3300 loss 15.492729 loss_att 19.173126 loss_ctc 34.323448 loss_rnnt 12.219939 hw_loss 0.048651 lr 0.00039313 rank 4
2023-02-22 13:02:24,438 DEBUG TRAIN Batch 19/3300 loss 7.161383 loss_att 10.094001 loss_ctc 7.977029 loss_rnnt 6.426823 hw_loss 0.073659 lr 0.00039316 rank 5
2023-02-22 13:02:24,438 DEBUG TRAIN Batch 19/3300 loss 22.504793 loss_att 25.986000 loss_ctc 29.918022 loss_rnnt 20.792942 hw_loss 0.050958 lr 0.00039307 rank 2
2023-02-22 13:02:24,439 DEBUG TRAIN Batch 19/3300 loss 5.382574 loss_att 8.249941 loss_ctc 12.337855 loss_rnnt 3.831916 hw_loss 0.093401 lr 0.00039315 rank 0
2023-02-22 13:02:24,441 DEBUG TRAIN Batch 19/3300 loss 9.003170 loss_att 10.674559 loss_ctc 10.117081 loss_rnnt 8.455783 hw_loss 0.121103 lr 0.00039310 rank 7
2023-02-22 13:02:24,441 DEBUG TRAIN Batch 19/3300 loss 7.590828 loss_att 11.147057 loss_ctc 13.977641 loss_rnnt 5.993749 hw_loss 0.064234 lr 0.00039306 rank 3
2023-02-22 13:02:24,443 DEBUG TRAIN Batch 19/3300 loss 10.753933 loss_att 13.417961 loss_ctc 12.146093 loss_rnnt 10.012032 hw_loss 0.044014 lr 0.00039317 rank 1
2023-02-22 13:02:24,448 DEBUG TRAIN Batch 19/3300 loss 5.513994 loss_att 10.939912 loss_ctc 11.519095 loss_rnnt 3.563805 hw_loss 0.120610 lr 0.00039317 rank 6
2023-02-22 13:03:39,871 DEBUG TRAIN Batch 19/3400 loss 3.316597 loss_att 7.340205 loss_ctc 6.601021 loss_rnnt 2.027195 hw_loss 0.087669 lr 0.00039305 rank 6
2023-02-22 13:03:39,871 DEBUG TRAIN Batch 19/3400 loss 2.913697 loss_att 6.289638 loss_ctc 4.996203 loss_rnnt 1.931371 hw_loss 0.055255 lr 0.00039301 rank 4
2023-02-22 13:03:39,874 DEBUG TRAIN Batch 19/3400 loss 3.189028 loss_att 5.177923 loss_ctc 4.473182 loss_rnnt 2.597560 hw_loss 0.042130 lr 0.00039303 rank 0
2023-02-22 13:03:39,874 DEBUG TRAIN Batch 19/3400 loss 11.800233 loss_att 13.716075 loss_ctc 13.956634 loss_rnnt 11.129438 hw_loss 0.000199 lr 0.00039295 rank 2
2023-02-22 13:03:39,875 DEBUG TRAIN Batch 19/3400 loss 10.082008 loss_att 10.200306 loss_ctc 10.601919 loss_rnnt 9.965137 hw_loss 0.044794 lr 0.00039304 rank 5
2023-02-22 13:03:39,875 DEBUG TRAIN Batch 19/3400 loss 8.180691 loss_att 11.752336 loss_ctc 12.769847 loss_rnnt 6.800710 hw_loss 0.100809 lr 0.00039298 rank 7
2023-02-22 13:03:39,876 DEBUG TRAIN Batch 19/3400 loss 10.991552 loss_att 15.501678 loss_ctc 12.006754 loss_rnnt 9.861824 hw_loss 0.173144 lr 0.00039305 rank 1
2023-02-22 13:03:39,926 DEBUG TRAIN Batch 19/3400 loss 6.590578 loss_att 10.002367 loss_ctc 11.134079 loss_rnnt 5.248199 hw_loss 0.101664 lr 0.00039294 rank 3
2023-02-22 13:04:57,067 DEBUG TRAIN Batch 19/3500 loss 8.821874 loss_att 12.246831 loss_ctc 10.333064 loss_rnnt 7.895299 hw_loss 0.075172 lr 0.00039289 rank 4
2023-02-22 13:04:57,068 DEBUG TRAIN Batch 19/3500 loss 5.681652 loss_att 8.829070 loss_ctc 8.818625 loss_rnnt 4.578153 hw_loss 0.104534 lr 0.00039282 rank 3
2023-02-22 13:04:57,072 DEBUG TRAIN Batch 19/3500 loss 14.215410 loss_att 21.243425 loss_ctc 23.653809 loss_rnnt 11.551094 hw_loss 0.000487 lr 0.00039292 rank 6
2023-02-22 13:04:57,074 DEBUG TRAIN Batch 19/3500 loss 11.943016 loss_att 14.808596 loss_ctc 12.926632 loss_rnnt 11.220427 hw_loss 0.034358 lr 0.00039292 rank 5
2023-02-22 13:04:57,077 DEBUG TRAIN Batch 19/3500 loss 7.960399 loss_att 10.299605 loss_ctc 14.523054 loss_rnnt 6.577274 hw_loss 0.075492 lr 0.00039283 rank 2
2023-02-22 13:04:57,076 DEBUG TRAIN Batch 19/3500 loss 7.312045 loss_att 8.805461 loss_ctc 7.709943 loss_rnnt 6.908291 hw_loss 0.097533 lr 0.00039286 rank 7
2023-02-22 13:04:57,089 DEBUG TRAIN Batch 19/3500 loss 9.167945 loss_att 12.328742 loss_ctc 18.410744 loss_rnnt 7.220284 hw_loss 0.155864 lr 0.00039291 rank 0
2023-02-22 13:04:57,089 DEBUG TRAIN Batch 19/3500 loss 10.129780 loss_att 15.242439 loss_ctc 12.259852 loss_rnnt 8.799215 hw_loss 0.045042 lr 0.00039293 rank 1
2023-02-22 13:06:13,645 DEBUG TRAIN Batch 19/3600 loss 4.893870 loss_att 8.738914 loss_ctc 8.412200 loss_rnnt 3.588428 hw_loss 0.126230 lr 0.00039274 rank 7
2023-02-22 13:06:13,646 DEBUG TRAIN Batch 19/3600 loss 5.067427 loss_att 7.476404 loss_ctc 7.982292 loss_rnnt 4.136981 hw_loss 0.112504 lr 0.00039270 rank 3
2023-02-22 13:06:13,648 DEBUG TRAIN Batch 19/3600 loss 9.267155 loss_att 15.313370 loss_ctc 13.484357 loss_rnnt 7.490585 hw_loss 0.009436 lr 0.00039271 rank 2
2023-02-22 13:06:13,649 DEBUG TRAIN Batch 19/3600 loss 11.665959 loss_att 14.246404 loss_ctc 15.591690 loss_rnnt 10.582979 hw_loss 0.081487 lr 0.00039280 rank 6
2023-02-22 13:06:13,649 DEBUG TRAIN Batch 19/3600 loss 12.662503 loss_att 16.636845 loss_ctc 17.898790 loss_rnnt 11.157921 hw_loss 0.021641 lr 0.00039276 rank 4
2023-02-22 13:06:13,650 DEBUG TRAIN Batch 19/3600 loss 15.746617 loss_att 17.255119 loss_ctc 23.508320 loss_rnnt 14.349833 hw_loss 0.112856 lr 0.00039279 rank 0
2023-02-22 13:06:13,651 DEBUG TRAIN Batch 19/3600 loss 13.826642 loss_att 15.594253 loss_ctc 15.917364 loss_rnnt 13.155973 hw_loss 0.071968 lr 0.00039280 rank 5
2023-02-22 13:06:13,655 DEBUG TRAIN Batch 19/3600 loss 4.564775 loss_att 7.464980 loss_ctc 6.265994 loss_rnnt 3.723100 hw_loss 0.065259 lr 0.00039281 rank 1
2023-02-22 13:07:28,004 DEBUG TRAIN Batch 19/3700 loss 8.964481 loss_att 11.256767 loss_ctc 10.839215 loss_rnnt 8.196068 hw_loss 0.112486 lr 0.00039267 rank 0
2023-02-22 13:07:28,007 DEBUG TRAIN Batch 19/3700 loss 6.079003 loss_att 8.154230 loss_ctc 7.064695 loss_rnnt 5.510641 hw_loss 0.041046 lr 0.00039264 rank 4
2023-02-22 13:07:28,008 DEBUG TRAIN Batch 19/3700 loss 14.029118 loss_att 14.698606 loss_ctc 14.851011 loss_rnnt 13.721015 hw_loss 0.121162 lr 0.00039262 rank 7
2023-02-22 13:07:28,011 DEBUG TRAIN Batch 19/3700 loss 10.660759 loss_att 13.348415 loss_ctc 15.037897 loss_rnnt 9.480461 hw_loss 0.110903 lr 0.00039268 rank 5
2023-02-22 13:07:28,013 DEBUG TRAIN Batch 19/3700 loss 16.715353 loss_att 19.845968 loss_ctc 24.275980 loss_rnnt 14.958453 hw_loss 0.230051 lr 0.00039268 rank 6
2023-02-22 13:07:28,013 DEBUG TRAIN Batch 19/3700 loss 4.192781 loss_att 7.540328 loss_ctc 5.768945 loss_rnnt 3.280369 hw_loss 0.061401 lr 0.00039269 rank 1
2023-02-22 13:07:28,016 DEBUG TRAIN Batch 19/3700 loss 11.627090 loss_att 11.212950 loss_ctc 16.038355 loss_rnnt 11.010240 hw_loss 0.209081 lr 0.00039258 rank 3
2023-02-22 13:07:28,018 DEBUG TRAIN Batch 19/3700 loss 13.343158 loss_att 15.402000 loss_ctc 17.061916 loss_rnnt 12.390048 hw_loss 0.085326 lr 0.00039259 rank 2
2023-02-22 13:08:44,611 DEBUG TRAIN Batch 19/3800 loss 12.984805 loss_att 14.092839 loss_ctc 14.988290 loss_rnnt 12.428006 hw_loss 0.127615 lr 0.00039256 rank 5
2023-02-22 13:08:44,617 DEBUG TRAIN Batch 19/3800 loss 9.892834 loss_att 10.844073 loss_ctc 12.553209 loss_rnnt 9.266734 hw_loss 0.152130 lr 0.00039250 rank 7
2023-02-22 13:08:44,618 DEBUG TRAIN Batch 19/3800 loss 8.704953 loss_att 9.899455 loss_ctc 14.226684 loss_rnnt 7.615528 hw_loss 0.214300 lr 0.00039255 rank 0
2023-02-22 13:08:44,620 DEBUG TRAIN Batch 19/3800 loss 5.987952 loss_att 7.769010 loss_ctc 8.786777 loss_rnnt 5.129574 hw_loss 0.241855 lr 0.00039252 rank 4
2023-02-22 13:08:44,625 DEBUG TRAIN Batch 19/3800 loss 15.079128 loss_att 17.659431 loss_ctc 25.543419 loss_rnnt 13.082760 hw_loss 0.159502 lr 0.00039257 rank 1
2023-02-22 13:08:44,628 DEBUG TRAIN Batch 19/3800 loss 5.986561 loss_att 9.925024 loss_ctc 12.757305 loss_rnnt 4.295937 hw_loss 0.000309 lr 0.00039246 rank 3
2023-02-22 13:08:44,630 DEBUG TRAIN Batch 19/3800 loss 7.933541 loss_att 10.058333 loss_ctc 9.815637 loss_rnnt 7.132714 hw_loss 0.234230 lr 0.00039247 rank 2
2023-02-22 13:08:44,676 DEBUG TRAIN Batch 19/3800 loss 8.374763 loss_att 8.630632 loss_ctc 11.660017 loss_rnnt 7.796713 hw_loss 0.166576 lr 0.00039256 rank 6
2023-02-22 13:10:03,181 DEBUG TRAIN Batch 19/3900 loss 6.767961 loss_att 11.983576 loss_ctc 11.260001 loss_rnnt 5.077568 hw_loss 0.090620 lr 0.00039244 rank 5
2023-02-22 13:10:03,181 DEBUG TRAIN Batch 19/3900 loss 3.790418 loss_att 6.001923 loss_ctc 4.143975 loss_rnnt 3.227886 hw_loss 0.137043 lr 0.00039238 rank 7
2023-02-22 13:10:03,181 DEBUG TRAIN Batch 19/3900 loss 9.783270 loss_att 10.100426 loss_ctc 12.081496 loss_rnnt 9.309143 hw_loss 0.195496 lr 0.00039245 rank 1
2023-02-22 13:10:03,185 DEBUG TRAIN Batch 19/3900 loss 6.099328 loss_att 7.169317 loss_ctc 10.083512 loss_rnnt 5.333221 hw_loss 0.039157 lr 0.00039244 rank 6
2023-02-22 13:10:03,189 DEBUG TRAIN Batch 19/3900 loss 4.629602 loss_att 7.727215 loss_ctc 10.034071 loss_rnnt 3.240668 hw_loss 0.091530 lr 0.00039234 rank 3
2023-02-22 13:10:03,190 DEBUG TRAIN Batch 19/3900 loss 3.048216 loss_att 6.132559 loss_ctc 4.422058 loss_rnnt 2.187662 hw_loss 0.113450 lr 0.00039235 rank 2
2023-02-22 13:10:03,193 DEBUG TRAIN Batch 19/3900 loss 4.032835 loss_att 5.018412 loss_ctc 4.644344 loss_rnnt 3.700161 hw_loss 0.101295 lr 0.00039243 rank 0
2023-02-22 13:10:03,200 DEBUG TRAIN Batch 19/3900 loss 13.011220 loss_att 16.363956 loss_ctc 19.145876 loss_rnnt 11.402859 hw_loss 0.224735 lr 0.00039240 rank 4
2023-02-22 13:11:19,560 DEBUG TRAIN Batch 19/4000 loss 7.948528 loss_att 14.310476 loss_ctc 14.483952 loss_rnnt 5.769416 hw_loss 0.066248 lr 0.00039233 rank 1
2023-02-22 13:11:19,560 DEBUG TRAIN Batch 19/4000 loss 2.030301 loss_att 4.243926 loss_ctc 2.784271 loss_rnnt 1.462568 hw_loss 0.045898 lr 0.00039230 rank 0
2023-02-22 13:11:19,562 DEBUG TRAIN Batch 19/4000 loss 13.513149 loss_att 14.669994 loss_ctc 17.943373 loss_rnnt 12.651210 hw_loss 0.074764 lr 0.00039231 rank 5
2023-02-22 13:11:19,567 DEBUG TRAIN Batch 19/4000 loss 6.999174 loss_att 12.332890 loss_ctc 12.133394 loss_rnnt 5.227941 hw_loss 0.037363 lr 0.00039232 rank 6
2023-02-22 13:11:19,569 DEBUG TRAIN Batch 19/4000 loss 10.785874 loss_att 15.118313 loss_ctc 16.808144 loss_rnnt 9.073997 hw_loss 0.079537 lr 0.00039226 rank 7
2023-02-22 13:11:19,569 DEBUG TRAIN Batch 19/4000 loss 6.523999 loss_att 8.778907 loss_ctc 11.437385 loss_rnnt 5.351757 hw_loss 0.124015 lr 0.00039228 rank 4
2023-02-22 13:11:19,577 DEBUG TRAIN Batch 19/4000 loss 3.026720 loss_att 6.750944 loss_ctc 4.126802 loss_rnnt 2.103538 hw_loss 0.059362 lr 0.00039223 rank 2
2023-02-22 13:11:19,612 DEBUG TRAIN Batch 19/4000 loss 6.331558 loss_att 8.139744 loss_ctc 6.445797 loss_rnnt 5.886451 hw_loss 0.127948 lr 0.00039222 rank 3
2023-02-22 13:12:35,465 DEBUG TRAIN Batch 19/4100 loss 11.303235 loss_att 14.313702 loss_ctc 17.362722 loss_rnnt 9.796625 hw_loss 0.181096 lr 0.00039218 rank 0
2023-02-22 13:12:35,467 DEBUG TRAIN Batch 19/4100 loss 8.321808 loss_att 11.766117 loss_ctc 11.037585 loss_rnnt 7.195769 hw_loss 0.140761 lr 0.00039216 rank 4
2023-02-22 13:12:35,468 DEBUG TRAIN Batch 19/4100 loss 9.241481 loss_att 12.544510 loss_ctc 12.466482 loss_rnnt 8.073025 hw_loss 0.145969 lr 0.00039219 rank 5
2023-02-22 13:12:35,469 DEBUG TRAIN Batch 19/4100 loss 4.998215 loss_att 6.076176 loss_ctc 6.613019 loss_rnnt 4.488429 hw_loss 0.147913 lr 0.00039213 rank 7
2023-02-22 13:12:35,470 DEBUG TRAIN Batch 19/4100 loss 9.181225 loss_att 10.275078 loss_ctc 10.328349 loss_rnnt 8.765581 hw_loss 0.082355 lr 0.00039220 rank 6
2023-02-22 13:12:35,472 DEBUG TRAIN Batch 19/4100 loss 10.604357 loss_att 12.786148 loss_ctc 13.921871 loss_rnnt 9.722504 hw_loss 0.005925 lr 0.00039221 rank 1
2023-02-22 13:12:35,473 DEBUG TRAIN Batch 19/4100 loss 1.964625 loss_att 5.606161 loss_ctc 3.380268 loss_rnnt 1.015357 hw_loss 0.060391 lr 0.00039211 rank 2
2023-02-22 13:12:35,474 DEBUG TRAIN Batch 19/4100 loss 15.532871 loss_att 18.291798 loss_ctc 21.932690 loss_rnnt 14.064770 hw_loss 0.118140 lr 0.00039209 rank 3
2023-02-22 13:13:51,304 DEBUG TRAIN Batch 19/4200 loss 7.220034 loss_att 8.871237 loss_ctc 8.749934 loss_rnnt 6.656278 hw_loss 0.055366 lr 0.00039204 rank 4
2023-02-22 13:13:51,305 DEBUG TRAIN Batch 19/4200 loss 10.618546 loss_att 13.949596 loss_ctc 13.616179 loss_rnnt 9.481222 hw_loss 0.133933 lr 0.00039207 rank 5
2023-02-22 13:13:51,310 DEBUG TRAIN Batch 19/4200 loss 8.932403 loss_att 12.674721 loss_ctc 15.251583 loss_rnnt 7.246591 hw_loss 0.177732 lr 0.00039201 rank 7
2023-02-22 13:13:51,311 DEBUG TRAIN Batch 19/4200 loss 7.275093 loss_att 9.982980 loss_ctc 14.156701 loss_rnnt 5.779177 hw_loss 0.068984 lr 0.00039206 rank 0
2023-02-22 13:13:51,312 DEBUG TRAIN Batch 19/4200 loss 27.812716 loss_att 31.958866 loss_ctc 37.627663 loss_rnnt 25.631563 hw_loss 0.081117 lr 0.00039197 rank 3
2023-02-22 13:13:51,313 DEBUG TRAIN Batch 19/4200 loss 11.137687 loss_att 12.592819 loss_ctc 13.068907 loss_rnnt 10.570911 hw_loss 0.034226 lr 0.00039208 rank 6
2023-02-22 13:13:51,315 DEBUG TRAIN Batch 19/4200 loss 14.609300 loss_att 19.049356 loss_ctc 15.215423 loss_rnnt 13.578181 hw_loss 0.116794 lr 0.00039209 rank 1
2023-02-22 13:13:51,318 DEBUG TRAIN Batch 19/4200 loss 25.056768 loss_att 26.880606 loss_ctc 31.888166 loss_rnnt 23.736015 hw_loss 0.084625 lr 0.00039199 rank 2
2023-02-22 13:15:08,875 DEBUG TRAIN Batch 19/4300 loss 14.000906 loss_att 16.995071 loss_ctc 18.266273 loss_rnnt 12.741011 hw_loss 0.173150 lr 0.00039192 rank 4
2023-02-22 13:15:08,876 DEBUG TRAIN Batch 19/4300 loss 7.785590 loss_att 10.531688 loss_ctc 11.483816 loss_rnnt 6.705832 hw_loss 0.070203 lr 0.00039196 rank 1
2023-02-22 13:15:08,877 DEBUG TRAIN Batch 19/4300 loss 11.382669 loss_att 13.147888 loss_ctc 15.056961 loss_rnnt 10.525176 hw_loss 0.027271 lr 0.00039195 rank 5
2023-02-22 13:15:08,877 DEBUG TRAIN Batch 19/4300 loss 17.209967 loss_att 21.830044 loss_ctc 26.510975 loss_rnnt 14.983332 hw_loss 0.117157 lr 0.00039189 rank 7
2023-02-22 13:15:08,882 DEBUG TRAIN Batch 19/4300 loss 10.812580 loss_att 11.582996 loss_ctc 10.635415 loss_rnnt 10.617236 hw_loss 0.121656 lr 0.00039187 rank 2
2023-02-22 13:15:08,882 DEBUG TRAIN Batch 19/4300 loss 10.565688 loss_att 12.968882 loss_ctc 16.601700 loss_rnnt 9.262289 hw_loss 0.033672 lr 0.00039194 rank 0
2023-02-22 13:15:08,885 DEBUG TRAIN Batch 19/4300 loss 6.050027 loss_att 10.052809 loss_ctc 8.510075 loss_rnnt 4.864777 hw_loss 0.106291 lr 0.00039196 rank 6
2023-02-22 13:15:08,886 DEBUG TRAIN Batch 19/4300 loss 14.013709 loss_att 16.230999 loss_ctc 16.487825 loss_rnnt 13.202517 hw_loss 0.070970 lr 0.00039185 rank 3
2023-02-22 13:16:23,907 DEBUG TRAIN Batch 19/4400 loss 7.666381 loss_att 10.523082 loss_ctc 10.619782 loss_rnnt 6.650669 hw_loss 0.094849 lr 0.00039183 rank 5
2023-02-22 13:16:23,909 DEBUG TRAIN Batch 19/4400 loss 6.180329 loss_att 8.398005 loss_ctc 6.164229 loss_rnnt 5.720026 hw_loss 0.035463 lr 0.00039182 rank 0
2023-02-22 13:16:23,911 DEBUG TRAIN Batch 19/4400 loss 14.831180 loss_att 15.766191 loss_ctc 19.436169 loss_rnnt 14.024237 hw_loss 0.011140 lr 0.00039180 rank 4
2023-02-22 13:16:23,912 DEBUG TRAIN Batch 19/4400 loss 12.176958 loss_att 14.769866 loss_ctc 16.623831 loss_rnnt 11.026717 hw_loss 0.072644 lr 0.00039184 rank 1
2023-02-22 13:16:23,913 DEBUG TRAIN Batch 19/4400 loss 15.004862 loss_att 17.600590 loss_ctc 24.476503 loss_rnnt 13.188712 hw_loss 0.063973 lr 0.00039177 rank 7
2023-02-22 13:16:23,914 DEBUG TRAIN Batch 19/4400 loss 10.088190 loss_att 11.916906 loss_ctc 13.185023 loss_rnnt 9.252779 hw_loss 0.106420 lr 0.00039184 rank 6
2023-02-22 13:16:23,915 DEBUG TRAIN Batch 19/4400 loss 18.469774 loss_att 20.886854 loss_ctc 24.446989 loss_rnnt 17.137571 hw_loss 0.097171 lr 0.00039175 rank 2
2023-02-22 13:16:23,921 DEBUG TRAIN Batch 19/4400 loss 24.359653 loss_att 27.919184 loss_ctc 28.106482 loss_rnnt 23.060745 hw_loss 0.163922 lr 0.00039173 rank 3
2023-02-22 13:17:39,021 DEBUG TRAIN Batch 19/4500 loss 9.222740 loss_att 12.939006 loss_ctc 14.711596 loss_rnnt 7.689849 hw_loss 0.108357 lr 0.00039172 rank 6
2023-02-22 13:17:39,022 DEBUG TRAIN Batch 19/4500 loss 7.352171 loss_att 7.876516 loss_ctc 10.739240 loss_rnnt 6.750779 hw_loss 0.084213 lr 0.00039172 rank 1
2023-02-22 13:17:39,023 DEBUG TRAIN Batch 19/4500 loss 5.545971 loss_att 8.176225 loss_ctc 6.567695 loss_rnnt 4.848501 hw_loss 0.065980 lr 0.00039165 rank 7
2023-02-22 13:17:39,024 DEBUG TRAIN Batch 19/4500 loss 7.684546 loss_att 10.858345 loss_ctc 14.040317 loss_rnnt 6.184084 hw_loss 0.034250 lr 0.00039171 rank 5
2023-02-22 13:17:39,025 DEBUG TRAIN Batch 19/4500 loss 10.395178 loss_att 11.960563 loss_ctc 13.944122 loss_rnnt 9.518453 hw_loss 0.169604 lr 0.00039168 rank 4
2023-02-22 13:17:39,025 DEBUG TRAIN Batch 19/4500 loss 7.650448 loss_att 10.100616 loss_ctc 8.171993 loss_rnnt 7.019493 hw_loss 0.133841 lr 0.00039170 rank 0
2023-02-22 13:17:39,027 DEBUG TRAIN Batch 19/4500 loss 9.296751 loss_att 11.879551 loss_ctc 11.935616 loss_rnnt 8.393774 hw_loss 0.064815 lr 0.00039161 rank 3
2023-02-22 13:17:39,030 DEBUG TRAIN Batch 19/4500 loss 11.444435 loss_att 15.688169 loss_ctc 14.784770 loss_rnnt 10.138439 hw_loss 0.022259 lr 0.00039163 rank 2
2023-02-22 13:18:57,063 DEBUG TRAIN Batch 19/4600 loss 2.986524 loss_att 6.802098 loss_ctc 5.032775 loss_rnnt 1.885466 hw_loss 0.122083 lr 0.00039156 rank 4
2023-02-22 13:18:57,064 DEBUG TRAIN Batch 19/4600 loss 6.178110 loss_att 9.858852 loss_ctc 9.129492 loss_rnnt 4.996563 hw_loss 0.097275 lr 0.00039159 rank 5
2023-02-22 13:18:57,065 DEBUG TRAIN Batch 19/4600 loss 11.440357 loss_att 14.619499 loss_ctc 15.745998 loss_rnnt 10.190006 hw_loss 0.075817 lr 0.00039158 rank 0
2023-02-22 13:18:57,066 DEBUG TRAIN Batch 19/4600 loss 7.276515 loss_att 10.042100 loss_ctc 10.435192 loss_rnnt 6.257262 hw_loss 0.084336 lr 0.00039149 rank 3
2023-02-22 13:18:57,068 DEBUG TRAIN Batch 19/4600 loss 6.266692 loss_att 10.061336 loss_ctc 7.650977 loss_rnnt 5.300108 hw_loss 0.043282 lr 0.00039153 rank 7
2023-02-22 13:18:57,069 DEBUG TRAIN Batch 19/4600 loss 9.733713 loss_att 10.200455 loss_ctc 10.840228 loss_rnnt 9.447757 hw_loss 0.084513 lr 0.00039160 rank 6
2023-02-22 13:18:57,073 DEBUG TRAIN Batch 19/4600 loss 6.594824 loss_att 9.883824 loss_ctc 10.242689 loss_rnnt 5.350633 hw_loss 0.187518 lr 0.00039160 rank 1
2023-02-22 13:18:57,074 DEBUG TRAIN Batch 19/4600 loss 5.643723 loss_att 10.398508 loss_ctc 6.203193 loss_rnnt 4.574655 hw_loss 0.081590 lr 0.00039151 rank 2
2023-02-22 13:20:13,028 DEBUG TRAIN Batch 19/4700 loss 5.039455 loss_att 7.525785 loss_ctc 6.139216 loss_rnnt 4.371630 hw_loss 0.044859 lr 0.00039147 rank 5
2023-02-22 13:20:13,029 DEBUG TRAIN Batch 19/4700 loss 10.172091 loss_att 12.209513 loss_ctc 9.832591 loss_rnnt 9.781461 hw_loss 0.053271 lr 0.00039141 rank 7
2023-02-22 13:20:13,030 DEBUG TRAIN Batch 19/4700 loss 10.326290 loss_att 14.844965 loss_ctc 14.544563 loss_rnnt 8.823659 hw_loss 0.068361 lr 0.00039144 rank 4
2023-02-22 13:20:13,032 DEBUG TRAIN Batch 19/4700 loss 9.410497 loss_att 11.731101 loss_ctc 16.220734 loss_rnnt 7.970090 hw_loss 0.127975 lr 0.00039139 rank 2
2023-02-22 13:20:13,033 DEBUG TRAIN Batch 19/4700 loss 11.127818 loss_att 13.558401 loss_ctc 13.454454 loss_rnnt 10.228948 hw_loss 0.192253 lr 0.00039146 rank 0
2023-02-22 13:20:13,034 DEBUG TRAIN Batch 19/4700 loss 7.801879 loss_att 9.384763 loss_ctc 12.946083 loss_rnnt 6.761436 hw_loss 0.071198 lr 0.00039148 rank 1
2023-02-22 13:20:13,034 DEBUG TRAIN Batch 19/4700 loss 11.593048 loss_att 14.367403 loss_ctc 14.403788 loss_rnnt 10.638412 hw_loss 0.046873 lr 0.00039148 rank 6
2023-02-22 13:20:13,035 DEBUG TRAIN Batch 19/4700 loss 5.012911 loss_att 7.106377 loss_ctc 7.323367 loss_rnnt 4.199077 hw_loss 0.163273 lr 0.00039137 rank 3
2023-02-22 13:21:27,115 DEBUG TRAIN Batch 19/4800 loss 6.004088 loss_att 7.704927 loss_ctc 7.072396 loss_rnnt 5.478223 hw_loss 0.081105 lr 0.00039136 rank 1
2023-02-22 13:21:27,115 DEBUG TRAIN Batch 19/4800 loss 10.140214 loss_att 13.250484 loss_ctc 11.739719 loss_rnnt 9.295025 hw_loss 0.018501 lr 0.00039132 rank 4
2023-02-22 13:21:27,118 DEBUG TRAIN Batch 19/4800 loss 6.196636 loss_att 9.282293 loss_ctc 7.783890 loss_rnnt 5.339060 hw_loss 0.054020 lr 0.00039134 rank 0
2023-02-22 13:21:27,119 DEBUG TRAIN Batch 19/4800 loss 11.329564 loss_att 12.959991 loss_ctc 15.991379 loss_rnnt 10.349327 hw_loss 0.061081 lr 0.00039125 rank 3
2023-02-22 13:21:27,121 DEBUG TRAIN Batch 19/4800 loss 6.212139 loss_att 9.071974 loss_ctc 10.651875 loss_rnnt 4.996804 hw_loss 0.096380 lr 0.00039127 rank 2
2023-02-22 13:21:27,122 DEBUG TRAIN Batch 19/4800 loss 4.737657 loss_att 7.763022 loss_ctc 6.265013 loss_rnnt 3.844285 hw_loss 0.158721 lr 0.00039129 rank 7
2023-02-22 13:21:27,122 DEBUG TRAIN Batch 19/4800 loss 8.846567 loss_att 12.505630 loss_ctc 14.762691 loss_rnnt 7.288870 hw_loss 0.069501 lr 0.00039136 rank 6
2023-02-22 13:21:27,123 DEBUG TRAIN Batch 19/4800 loss 5.713706 loss_att 7.373863 loss_ctc 7.651300 loss_rnnt 5.039993 hw_loss 0.156252 lr 0.00039135 rank 5
2023-02-22 13:22:43,740 DEBUG TRAIN Batch 19/4900 loss 9.690224 loss_att 12.606325 loss_ctc 12.201980 loss_rnnt 8.744510 hw_loss 0.051736 lr 0.00039120 rank 4
2023-02-22 13:22:43,743 DEBUG TRAIN Batch 19/4900 loss 11.045507 loss_att 14.596951 loss_ctc 13.662948 loss_rnnt 9.890368 hw_loss 0.179733 lr 0.00039117 rank 7
2023-02-22 13:22:43,744 DEBUG TRAIN Batch 19/4900 loss 4.666484 loss_att 7.284399 loss_ctc 7.798592 loss_rnnt 3.698271 hw_loss 0.050652 lr 0.00039124 rank 1
2023-02-22 13:22:43,743 DEBUG TRAIN Batch 19/4900 loss 9.174511 loss_att 10.757358 loss_ctc 14.006817 loss_rnnt 8.146254 hw_loss 0.126338 lr 0.00039124 rank 6
2023-02-22 13:22:43,745 DEBUG TRAIN Batch 19/4900 loss 11.922914 loss_att 15.390080 loss_ctc 17.753092 loss_rnnt 10.410192 hw_loss 0.078618 lr 0.00039123 rank 5
2023-02-22 13:22:43,745 DEBUG TRAIN Batch 19/4900 loss 4.673038 loss_att 6.787333 loss_ctc 7.289037 loss_rnnt 3.819741 hw_loss 0.153072 lr 0.00039113 rank 3
2023-02-22 13:22:43,746 DEBUG TRAIN Batch 19/4900 loss 8.748537 loss_att 11.360960 loss_ctc 12.155599 loss_rnnt 7.684477 hw_loss 0.163688 lr 0.00039122 rank 0
2023-02-22 13:22:43,746 DEBUG TRAIN Batch 19/4900 loss 9.347945 loss_att 13.386585 loss_ctc 14.455107 loss_rnnt 7.835503 hw_loss 0.044549 lr 0.00039115 rank 2
2023-02-22 13:24:01,284 DEBUG TRAIN Batch 19/5000 loss 5.001164 loss_att 7.683909 loss_ctc 6.837190 loss_rnnt 4.129607 hw_loss 0.169133 lr 0.00039112 rank 6
2023-02-22 13:24:01,284 DEBUG TRAIN Batch 19/5000 loss 10.186025 loss_att 13.780905 loss_ctc 15.903418 loss_rnnt 8.662909 hw_loss 0.078414 lr 0.00039108 rank 4
2023-02-22 13:24:01,286 DEBUG TRAIN Batch 19/5000 loss 10.073318 loss_att 11.511892 loss_ctc 15.267749 loss_rnnt 9.022662 hw_loss 0.131908 lr 0.00039105 rank 7
2023-02-22 13:24:01,286 DEBUG TRAIN Batch 19/5000 loss 11.477939 loss_att 15.172897 loss_ctc 13.437304 loss_rnnt 10.453135 hw_loss 0.046054 lr 0.00039112 rank 1
2023-02-22 13:24:01,288 DEBUG TRAIN Batch 19/5000 loss 7.694993 loss_att 10.801629 loss_ctc 13.971183 loss_rnnt 6.153216 hw_loss 0.156794 lr 0.00039110 rank 0
2023-02-22 13:24:01,289 DEBUG TRAIN Batch 19/5000 loss 6.963299 loss_att 10.317606 loss_ctc 11.931167 loss_rnnt 5.536379 hw_loss 0.175643 lr 0.00039111 rank 5
2023-02-22 13:24:01,290 DEBUG TRAIN Batch 19/5000 loss 7.741278 loss_att 8.697989 loss_ctc 10.325610 loss_rnnt 7.174919 hw_loss 0.057075 lr 0.00039103 rank 2
2023-02-22 13:24:01,337 DEBUG TRAIN Batch 19/5000 loss 4.960952 loss_att 7.036147 loss_ctc 7.187541 loss_rnnt 4.171113 hw_loss 0.146103 lr 0.00039101 rank 3
2023-02-22 13:25:17,196 DEBUG TRAIN Batch 19/5100 loss 5.877497 loss_att 7.683780 loss_ctc 8.789649 loss_rnnt 5.044557 hw_loss 0.156371 lr 0.00039098 rank 0
2023-02-22 13:25:17,198 DEBUG TRAIN Batch 19/5100 loss 9.060890 loss_att 10.516465 loss_ctc 12.750191 loss_rnnt 8.195581 hw_loss 0.154289 lr 0.00039099 rank 5
2023-02-22 13:25:17,200 DEBUG TRAIN Batch 19/5100 loss 4.656556 loss_att 7.737880 loss_ctc 5.215365 loss_rnnt 3.946633 hw_loss 0.035907 lr 0.00039096 rank 4
2023-02-22 13:25:17,201 DEBUG TRAIN Batch 19/5100 loss 13.031139 loss_att 12.683947 loss_ctc 16.713543 loss_rnnt 12.539280 hw_loss 0.131833 lr 0.00039093 rank 7
2023-02-22 13:25:17,202 DEBUG TRAIN Batch 19/5100 loss 6.886132 loss_att 9.421684 loss_ctc 7.490280 loss_rnnt 6.224587 hw_loss 0.138526 lr 0.00039089 rank 3
2023-02-22 13:25:17,207 DEBUG TRAIN Batch 19/5100 loss 7.546061 loss_att 12.101534 loss_ctc 15.192709 loss_rnnt 5.597860 hw_loss 0.032912 lr 0.00039100 rank 6
2023-02-22 13:25:17,208 DEBUG TRAIN Batch 19/5100 loss 20.388350 loss_att 20.344877 loss_ctc 28.066013 loss_rnnt 19.305279 hw_loss 0.127644 lr 0.00039100 rank 1
2023-02-22 13:25:17,255 DEBUG TRAIN Batch 19/5100 loss 11.974880 loss_att 11.387653 loss_ctc 14.854154 loss_rnnt 11.594511 hw_loss 0.213584 lr 0.00039091 rank 2
2023-02-22 13:26:32,599 DEBUG TRAIN Batch 19/5200 loss 5.487460 loss_att 10.916034 loss_ctc 9.796328 loss_rnnt 3.776093 hw_loss 0.095881 lr 0.00039087 rank 5
2023-02-22 13:26:32,604 DEBUG TRAIN Batch 19/5200 loss 7.222389 loss_att 8.948959 loss_ctc 9.131870 loss_rnnt 6.591910 hw_loss 0.057315 lr 0.00039084 rank 4
2023-02-22 13:26:32,604 DEBUG TRAIN Batch 19/5200 loss 13.208350 loss_att 15.542599 loss_ctc 20.659328 loss_rnnt 11.716352 hw_loss 0.059407 lr 0.00039081 rank 7
2023-02-22 13:26:32,605 DEBUG TRAIN Batch 19/5200 loss 12.186510 loss_att 15.956754 loss_ctc 14.278975 loss_rnnt 11.103473 hw_loss 0.093738 lr 0.00039089 rank 1
2023-02-22 13:26:32,606 DEBUG TRAIN Batch 19/5200 loss 9.421318 loss_att 9.773104 loss_ctc 14.631927 loss_rnnt 8.612269 hw_loss 0.082394 lr 0.00039086 rank 0
2023-02-22 13:26:32,609 DEBUG TRAIN Batch 19/5200 loss 5.563510 loss_att 9.620353 loss_ctc 10.463339 loss_rnnt 4.063482 hw_loss 0.066282 lr 0.00039078 rank 3
2023-02-22 13:26:32,613 DEBUG TRAIN Batch 19/5200 loss 12.409245 loss_att 15.426691 loss_ctc 15.186858 loss_rnnt 11.386477 hw_loss 0.091744 lr 0.00039088 rank 6
2023-02-22 13:26:32,658 DEBUG TRAIN Batch 19/5200 loss 11.908890 loss_att 13.962536 loss_ctc 16.562469 loss_rnnt 10.819715 hw_loss 0.108690 lr 0.00039079 rank 2
2023-02-22 13:27:50,222 DEBUG TRAIN Batch 19/5300 loss 4.816240 loss_att 8.117084 loss_ctc 10.328828 loss_rnnt 3.371277 hw_loss 0.093342 lr 0.00039072 rank 4
2023-02-22 13:27:50,225 DEBUG TRAIN Batch 19/5300 loss 5.616147 loss_att 8.189428 loss_ctc 6.769228 loss_rnnt 4.895353 hw_loss 0.098238 lr 0.00039074 rank 0
2023-02-22 13:27:50,226 DEBUG TRAIN Batch 19/5300 loss 24.779177 loss_att 25.963749 loss_ctc 35.432961 loss_rnnt 23.079123 hw_loss 0.079941 lr 0.00039070 rank 7
2023-02-22 13:27:50,227 DEBUG TRAIN Batch 19/5300 loss 14.177458 loss_att 16.543583 loss_ctc 16.099274 loss_rnnt 13.433805 hw_loss 0.026598 lr 0.00039077 rank 1
2023-02-22 13:27:50,229 DEBUG TRAIN Batch 19/5300 loss 14.314979 loss_att 19.604782 loss_ctc 18.539768 loss_rnnt 12.640299 hw_loss 0.100148 lr 0.00039076 rank 6
2023-02-22 13:27:50,229 DEBUG TRAIN Batch 19/5300 loss 5.877317 loss_att 9.433192 loss_ctc 8.710126 loss_rnnt 4.772896 hw_loss 0.029134 lr 0.00039075 rank 5
2023-02-22 13:27:50,231 DEBUG TRAIN Batch 19/5300 loss 6.553325 loss_att 11.568084 loss_ctc 9.740756 loss_rnnt 5.096489 hw_loss 0.054174 lr 0.00039066 rank 3
2023-02-22 13:27:50,232 DEBUG TRAIN Batch 19/5300 loss 12.687893 loss_att 15.777652 loss_ctc 19.904781 loss_rnnt 11.046623 hw_loss 0.114499 lr 0.00039067 rank 2
2023-02-22 13:29:05,761 DEBUG TRAIN Batch 19/5400 loss 2.656999 loss_att 5.982230 loss_ctc 4.076707 loss_rnnt 1.774618 hw_loss 0.052576 lr 0.00039060 rank 4
2023-02-22 13:29:05,762 DEBUG TRAIN Batch 19/5400 loss 10.398934 loss_att 14.098892 loss_ctc 13.011280 loss_rnnt 9.304510 hw_loss 0.011476 lr 0.00039058 rank 7
2023-02-22 13:29:05,763 DEBUG TRAIN Batch 19/5400 loss 5.247829 loss_att 9.507006 loss_ctc 9.810888 loss_rnnt 3.743113 hw_loss 0.083387 lr 0.00039063 rank 0
2023-02-22 13:29:05,763 DEBUG TRAIN Batch 19/5400 loss 10.375084 loss_att 15.989048 loss_ctc 18.131718 loss_rnnt 8.209830 hw_loss 0.015455 lr 0.00039063 rank 5
2023-02-22 13:29:05,768 DEBUG TRAIN Batch 19/5400 loss 12.935520 loss_att 17.441385 loss_ctc 17.171900 loss_rnnt 11.382697 hw_loss 0.162750 lr 0.00039055 rank 2
2023-02-22 13:29:05,773 DEBUG TRAIN Batch 19/5400 loss 6.700024 loss_att 11.792336 loss_ctc 7.152396 loss_rnnt 5.586075 hw_loss 0.065946 lr 0.00039065 rank 1
2023-02-22 13:29:05,774 DEBUG TRAIN Batch 19/5400 loss 11.520061 loss_att 14.821280 loss_ctc 19.303753 loss_rnnt 9.799728 hw_loss 0.041745 lr 0.00039054 rank 3
2023-02-22 13:29:05,776 DEBUG TRAIN Batch 19/5400 loss 9.800591 loss_att 13.218394 loss_ctc 11.425333 loss_rnnt 8.798375 hw_loss 0.191290 lr 0.00039064 rank 6
2023-02-22 13:30:20,330 DEBUG TRAIN Batch 19/5500 loss 15.774629 loss_att 15.789366 loss_ctc 19.029823 loss_rnnt 15.292165 hw_loss 0.085295 lr 0.00039052 rank 5
2023-02-22 13:30:20,333 DEBUG TRAIN Batch 19/5500 loss 12.420732 loss_att 18.338043 loss_ctc 21.065945 loss_rnnt 10.021370 hw_loss 0.118508 lr 0.00039053 rank 1
2023-02-22 13:30:20,336 DEBUG TRAIN Batch 19/5500 loss 8.493375 loss_att 10.660802 loss_ctc 11.493118 loss_rnnt 7.619998 hw_loss 0.074860 lr 0.00039046 rank 7
2023-02-22 13:30:20,338 DEBUG TRAIN Batch 19/5500 loss 9.512553 loss_att 14.521492 loss_ctc 12.536765 loss_rnnt 8.049162 hw_loss 0.109453 lr 0.00039048 rank 4
2023-02-22 13:30:20,339 DEBUG TRAIN Batch 19/5500 loss 9.145174 loss_att 13.152760 loss_ctc 12.905030 loss_rnnt 7.794113 hw_loss 0.090433 lr 0.00039051 rank 0
2023-02-22 13:30:20,345 DEBUG TRAIN Batch 19/5500 loss 7.931814 loss_att 10.768713 loss_ctc 12.060398 loss_rnnt 6.809126 hw_loss 0.009056 lr 0.00039052 rank 6
2023-02-22 13:30:20,346 DEBUG TRAIN Batch 19/5500 loss 13.965948 loss_att 14.076142 loss_ctc 16.987669 loss_rnnt 13.512939 hw_loss 0.052638 lr 0.00039042 rank 3
2023-02-22 13:30:20,346 DEBUG TRAIN Batch 19/5500 loss 5.526351 loss_att 8.542625 loss_ctc 8.516464 loss_rnnt 4.451845 hw_loss 0.136067 lr 0.00039043 rank 2
2023-02-22 13:31:36,286 DEBUG TRAIN Batch 19/5600 loss 5.861477 loss_att 12.730071 loss_ctc 10.496635 loss_rnnt 3.807129 hw_loss 0.117392 lr 0.00039036 rank 4
2023-02-22 13:31:36,287 DEBUG TRAIN Batch 19/5600 loss 8.748276 loss_att 9.830606 loss_ctc 11.946959 loss_rnnt 8.067765 hw_loss 0.070412 lr 0.00039039 rank 0
2023-02-22 13:31:36,289 DEBUG TRAIN Batch 19/5600 loss 4.895550 loss_att 6.943824 loss_ctc 7.364050 loss_rnnt 4.105023 hw_loss 0.097011 lr 0.00039034 rank 7
2023-02-22 13:31:36,292 DEBUG TRAIN Batch 19/5600 loss 9.124713 loss_att 17.442482 loss_ctc 13.795486 loss_rnnt 6.760612 hw_loss 0.145834 lr 0.00039030 rank 3
2023-02-22 13:31:36,293 DEBUG TRAIN Batch 19/5600 loss 7.406652 loss_att 9.802691 loss_ctc 7.803839 loss_rnnt 6.825542 hw_loss 0.091770 lr 0.00039031 rank 2
2023-02-22 13:31:36,293 DEBUG TRAIN Batch 19/5600 loss 9.880736 loss_att 13.889326 loss_ctc 16.878941 loss_rnnt 8.097234 hw_loss 0.091295 lr 0.00039040 rank 5
2023-02-22 13:31:36,322 DEBUG TRAIN Batch 19/5600 loss 10.716469 loss_att 14.406283 loss_ctc 13.283587 loss_rnnt 9.591215 hw_loss 0.084390 lr 0.00039041 rank 1
2023-02-22 13:31:36,332 DEBUG TRAIN Batch 19/5600 loss 9.295741 loss_att 10.803284 loss_ctc 14.051558 loss_rnnt 8.286505 hw_loss 0.138035 lr 0.00039040 rank 6
2023-02-22 13:32:55,811 DEBUG TRAIN Batch 19/5700 loss 5.143475 loss_att 7.648266 loss_ctc 9.370509 loss_rnnt 4.048150 hw_loss 0.057677 lr 0.00039024 rank 4
2023-02-22 13:32:55,812 DEBUG TRAIN Batch 19/5700 loss 9.646685 loss_att 10.107311 loss_ctc 12.777501 loss_rnnt 9.027720 hw_loss 0.205118 lr 0.00039028 rank 6
2023-02-22 13:32:55,817 DEBUG TRAIN Batch 19/5700 loss 13.400548 loss_att 13.689353 loss_ctc 21.244150 loss_rnnt 12.242963 hw_loss 0.101268 lr 0.00039027 rank 0
2023-02-22 13:32:55,820 DEBUG TRAIN Batch 19/5700 loss 12.182827 loss_att 13.343819 loss_ctc 19.428904 loss_rnnt 10.895850 hw_loss 0.166193 lr 0.00039022 rank 7
2023-02-22 13:32:55,820 DEBUG TRAIN Batch 19/5700 loss 9.527302 loss_att 11.682704 loss_ctc 12.012820 loss_rnnt 8.704853 hw_loss 0.112436 lr 0.00039028 rank 5
2023-02-22 13:32:55,821 DEBUG TRAIN Batch 19/5700 loss 12.129601 loss_att 12.885975 loss_ctc 16.217379 loss_rnnt 11.340870 hw_loss 0.173288 lr 0.00039018 rank 3
2023-02-22 13:32:55,829 DEBUG TRAIN Batch 19/5700 loss 11.340422 loss_att 11.175230 loss_ctc 14.541408 loss_rnnt 10.845387 hw_loss 0.189888 lr 0.00039029 rank 1
2023-02-22 13:32:55,865 DEBUG TRAIN Batch 19/5700 loss 6.642108 loss_att 7.184263 loss_ctc 9.146140 loss_rnnt 6.125783 hw_loss 0.138793 lr 0.00039019 rank 2
2023-02-22 13:34:11,759 DEBUG TRAIN Batch 19/5800 loss 13.415042 loss_att 12.939602 loss_ctc 19.486212 loss_rnnt 12.623917 hw_loss 0.143859 lr 0.00039013 rank 4
2023-02-22 13:34:11,759 DEBUG TRAIN Batch 19/5800 loss 9.067957 loss_att 13.186319 loss_ctc 17.228374 loss_rnnt 7.156187 hw_loss 0.000080 lr 0.00039010 rank 7
2023-02-22 13:34:11,761 DEBUG TRAIN Batch 19/5800 loss 6.364616 loss_att 6.469166 loss_ctc 7.886962 loss_rnnt 6.085536 hw_loss 0.103482 lr 0.00039007 rank 2
2023-02-22 13:34:11,762 DEBUG TRAIN Batch 19/5800 loss 2.177678 loss_att 4.640491 loss_ctc 2.701555 loss_rnnt 1.569128 hw_loss 0.086507 lr 0.00039015 rank 0
2023-02-22 13:34:11,764 DEBUG TRAIN Batch 19/5800 loss 5.361803 loss_att 8.135323 loss_ctc 6.662542 loss_rnnt 4.606151 hw_loss 0.051593 lr 0.00039016 rank 5
2023-02-22 13:34:11,768 DEBUG TRAIN Batch 19/5800 loss 8.433058 loss_att 10.762052 loss_ctc 11.643400 loss_rnnt 7.442859 hw_loss 0.180665 lr 0.00039006 rank 3
2023-02-22 13:34:11,768 DEBUG TRAIN Batch 19/5800 loss 3.546604 loss_att 6.702153 loss_ctc 5.485089 loss_rnnt 2.612346 hw_loss 0.083781 lr 0.00039016 rank 6
2023-02-22 13:34:11,772 DEBUG TRAIN Batch 19/5800 loss 15.179976 loss_att 20.012440 loss_ctc 22.254406 loss_rnnt 13.186507 hw_loss 0.156971 lr 0.00039017 rank 1
2023-02-22 13:35:26,450 DEBUG TRAIN Batch 19/5900 loss 19.029675 loss_att 22.707399 loss_ctc 27.088552 loss_rnnt 17.161739 hw_loss 0.108511 lr 0.00038998 rank 7
2023-02-22 13:35:26,450 DEBUG TRAIN Batch 19/5900 loss 5.818426 loss_att 8.621332 loss_ctc 7.392820 loss_rnnt 4.998018 hw_loss 0.093575 lr 0.00039003 rank 0
2023-02-22 13:35:26,451 DEBUG TRAIN Batch 19/5900 loss 3.955011 loss_att 5.344870 loss_ctc 7.245731 loss_rnnt 3.207836 hw_loss 0.057076 lr 0.00039001 rank 4
2023-02-22 13:35:26,452 DEBUG TRAIN Batch 19/5900 loss 2.305648 loss_att 5.655596 loss_ctc 4.418945 loss_rnnt 1.321177 hw_loss 0.061328 lr 0.00038994 rank 3
2023-02-22 13:35:26,453 DEBUG TRAIN Batch 19/5900 loss 8.983857 loss_att 11.149306 loss_ctc 13.878112 loss_rnnt 7.865294 hw_loss 0.061701 lr 0.00039004 rank 5
2023-02-22 13:35:26,456 DEBUG TRAIN Batch 19/5900 loss 7.070367 loss_att 10.965003 loss_ctc 10.353025 loss_rnnt 5.795778 hw_loss 0.108700 lr 0.00039004 rank 6
2023-02-22 13:35:26,458 DEBUG TRAIN Batch 19/5900 loss 8.460289 loss_att 11.447485 loss_ctc 11.600345 loss_rnnt 7.406071 hw_loss 0.071448 lr 0.00038995 rank 2
2023-02-22 13:35:26,496 DEBUG TRAIN Batch 19/5900 loss 11.216519 loss_att 12.088739 loss_ctc 14.315444 loss_rnnt 10.624734 hw_loss 0.007784 lr 0.00039005 rank 1
2023-02-22 13:36:43,580 DEBUG TRAIN Batch 19/6000 loss 7.274608 loss_att 10.756159 loss_ctc 9.105251 loss_rnnt 6.314160 hw_loss 0.037594 lr 0.00038986 rank 7
2023-02-22 13:36:43,582 DEBUG TRAIN Batch 19/6000 loss 4.601388 loss_att 7.935225 loss_ctc 6.786250 loss_rnnt 3.630456 hw_loss 0.024092 lr 0.00038992 rank 5
2023-02-22 13:36:43,584 DEBUG TRAIN Batch 19/6000 loss 8.785577 loss_att 12.306935 loss_ctc 14.405917 loss_rnnt 7.290561 hw_loss 0.077559 lr 0.00038982 rank 3
2023-02-22 13:36:43,585 DEBUG TRAIN Batch 19/6000 loss 5.165398 loss_att 7.786930 loss_ctc 5.072549 loss_rnnt 4.628066 hw_loss 0.047636 lr 0.00038989 rank 4
2023-02-22 13:36:43,586 DEBUG TRAIN Batch 19/6000 loss 5.549037 loss_att 7.322908 loss_ctc 8.919462 loss_rnnt 4.730206 hw_loss 0.027501 lr 0.00038991 rank 0
2023-02-22 13:36:43,587 DEBUG TRAIN Batch 19/6000 loss 8.118553 loss_att 11.437822 loss_ctc 10.435499 loss_rnnt 7.061006 hw_loss 0.158939 lr 0.00038993 rank 6
2023-02-22 13:36:43,590 DEBUG TRAIN Batch 19/6000 loss 12.939527 loss_att 13.638969 loss_ctc 22.014690 loss_rnnt 11.513912 hw_loss 0.141942 lr 0.00038993 rank 1
2023-02-22 13:36:43,635 DEBUG TRAIN Batch 19/6000 loss 6.885447 loss_att 9.427090 loss_ctc 10.427906 loss_rnnt 5.845569 hw_loss 0.111041 lr 0.00038984 rank 2
2023-02-22 13:38:00,070 DEBUG TRAIN Batch 19/6100 loss 14.183216 loss_att 17.077778 loss_ctc 19.742365 loss_rnnt 12.852791 hw_loss 0.019299 lr 0.00038980 rank 5
2023-02-22 13:38:00,075 DEBUG TRAIN Batch 19/6100 loss 9.913166 loss_att 11.845651 loss_ctc 14.836399 loss_rnnt 8.806865 hw_loss 0.118825 lr 0.00038974 rank 7
2023-02-22 13:38:00,075 DEBUG TRAIN Batch 19/6100 loss 10.355707 loss_att 14.643436 loss_ctc 13.740891 loss_rnnt 8.984751 hw_loss 0.116349 lr 0.00038977 rank 4
2023-02-22 13:38:00,078 DEBUG TRAIN Batch 19/6100 loss 16.663189 loss_att 25.961491 loss_ctc 28.404964 loss_rnnt 13.151505 hw_loss 0.162100 lr 0.00038981 rank 6
2023-02-22 13:38:00,079 DEBUG TRAIN Batch 19/6100 loss 9.048465 loss_att 12.651468 loss_ctc 16.391872 loss_rnnt 7.304631 hw_loss 0.082710 lr 0.00038971 rank 3
2023-02-22 13:38:00,084 DEBUG TRAIN Batch 19/6100 loss 9.552208 loss_att 13.083717 loss_ctc 14.867203 loss_rnnt 8.051495 hw_loss 0.160772 lr 0.00038979 rank 0
2023-02-22 13:38:00,084 DEBUG TRAIN Batch 19/6100 loss 16.026449 loss_att 14.255199 loss_ctc 20.711048 loss_rnnt 15.700569 hw_loss 0.104095 lr 0.00038981 rank 1
2023-02-22 13:38:00,084 DEBUG TRAIN Batch 19/6100 loss 6.407367 loss_att 9.864288 loss_ctc 10.433207 loss_rnnt 5.129988 hw_loss 0.092281 lr 0.00038972 rank 2
2023-02-22 13:39:15,583 DEBUG TRAIN Batch 19/6200 loss 12.167913 loss_att 15.383839 loss_ctc 17.745453 loss_rnnt 10.761902 hw_loss 0.035912 lr 0.00038965 rank 4
2023-02-22 13:39:15,585 DEBUG TRAIN Batch 19/6200 loss 4.685331 loss_att 8.275620 loss_ctc 6.841571 loss_rnnt 3.634232 hw_loss 0.085393 lr 0.00038967 rank 0
2023-02-22 13:39:15,585 DEBUG TRAIN Batch 19/6200 loss 13.708997 loss_att 15.610916 loss_ctc 21.354515 loss_rnnt 12.260879 hw_loss 0.090622 lr 0.00038963 rank 7
2023-02-22 13:39:15,588 DEBUG TRAIN Batch 19/6200 loss 8.200935 loss_att 9.653868 loss_ctc 14.336963 loss_rnnt 6.968635 hw_loss 0.231708 lr 0.00038969 rank 6
2023-02-22 13:39:15,589 DEBUG TRAIN Batch 19/6200 loss 2.072460 loss_att 4.479578 loss_ctc 2.415385 loss_rnnt 1.516405 hw_loss 0.054203 lr 0.00038968 rank 5
2023-02-22 13:39:15,588 DEBUG TRAIN Batch 19/6200 loss 5.644109 loss_att 10.123743 loss_ctc 9.369607 loss_rnnt 4.226277 hw_loss 0.047198 lr 0.00038970 rank 1
2023-02-22 13:39:15,589 DEBUG TRAIN Batch 19/6200 loss 4.587366 loss_att 6.699636 loss_ctc 6.106201 loss_rnnt 3.908202 hw_loss 0.101620 lr 0.00038959 rank 3
2023-02-22 13:39:15,590 DEBUG TRAIN Batch 19/6200 loss 11.962047 loss_att 16.026756 loss_ctc 22.290997 loss_rnnt 9.727493 hw_loss 0.083283 lr 0.00038960 rank 2
2023-02-22 13:40:30,527 DEBUG TRAIN Batch 19/6300 loss 14.588618 loss_att 14.628375 loss_ctc 21.992853 loss_rnnt 13.504208 hw_loss 0.167300 lr 0.00038958 rank 1
2023-02-22 13:40:30,528 DEBUG TRAIN Batch 19/6300 loss 19.429115 loss_att 24.007486 loss_ctc 26.419266 loss_rnnt 17.539497 hw_loss 0.078608 lr 0.00038953 rank 4
2023-02-22 13:40:30,528 DEBUG TRAIN Batch 19/6300 loss 9.476182 loss_att 13.100931 loss_ctc 13.201763 loss_rnnt 8.144717 hw_loss 0.205821 lr 0.00038947 rank 3
2023-02-22 13:40:30,529 DEBUG TRAIN Batch 19/6300 loss 8.980162 loss_att 11.483097 loss_ctc 13.303111 loss_rnnt 7.853864 hw_loss 0.092467 lr 0.00038951 rank 7
2023-02-22 13:40:30,529 DEBUG TRAIN Batch 19/6300 loss 8.143281 loss_att 11.939711 loss_ctc 12.473282 loss_rnnt 6.767009 hw_loss 0.074349 lr 0.00038957 rank 5
2023-02-22 13:40:30,529 DEBUG TRAIN Batch 19/6300 loss 9.572662 loss_att 10.012574 loss_ctc 12.744111 loss_rnnt 9.019996 hw_loss 0.078420 lr 0.00038956 rank 0
2023-02-22 13:40:30,534 DEBUG TRAIN Batch 19/6300 loss 8.470637 loss_att 9.516899 loss_ctc 14.253426 loss_rnnt 7.370819 hw_loss 0.224114 lr 0.00038957 rank 6
2023-02-22 13:40:30,580 DEBUG TRAIN Batch 19/6300 loss 14.734072 loss_att 17.588938 loss_ctc 21.125626 loss_rnnt 13.289529 hw_loss 0.040052 lr 0.00038948 rank 2
2023-02-22 13:41:49,390 DEBUG TRAIN Batch 19/6400 loss 12.453858 loss_att 11.353730 loss_ctc 16.803577 loss_rnnt 11.964999 hw_loss 0.241730 lr 0.00038945 rank 5
2023-02-22 13:41:49,391 DEBUG TRAIN Batch 19/6400 loss 7.919326 loss_att 10.716783 loss_ctc 9.418258 loss_rnnt 7.130289 hw_loss 0.055666 lr 0.00038939 rank 7
2023-02-22 13:41:49,392 DEBUG TRAIN Batch 19/6400 loss 8.824224 loss_att 8.735563 loss_ctc 11.132534 loss_rnnt 8.408142 hw_loss 0.236326 lr 0.00038944 rank 0
2023-02-22 13:41:49,394 DEBUG TRAIN Batch 19/6400 loss 3.459379 loss_att 5.868469 loss_ctc 5.205632 loss_rnnt 2.664472 hw_loss 0.150478 lr 0.00038945 rank 6
2023-02-22 13:41:49,394 DEBUG TRAIN Batch 19/6400 loss 11.038799 loss_att 12.263885 loss_ctc 14.722496 loss_rnnt 10.245928 hw_loss 0.106302 lr 0.00038936 rank 2
2023-02-22 13:41:49,395 DEBUG TRAIN Batch 19/6400 loss 19.151077 loss_att 21.384678 loss_ctc 27.341660 loss_rnnt 17.524967 hw_loss 0.163708 lr 0.00038946 rank 1
2023-02-22 13:41:49,397 DEBUG TRAIN Batch 19/6400 loss 11.136557 loss_att 17.081560 loss_ctc 17.155804 loss_rnnt 9.098284 hw_loss 0.087573 lr 0.00038935 rank 3
2023-02-22 13:41:49,397 DEBUG TRAIN Batch 19/6400 loss 14.443463 loss_att 17.411686 loss_ctc 21.134769 loss_rnnt 12.931790 hw_loss 0.048477 lr 0.00038941 rank 4
2023-02-22 13:43:05,995 DEBUG TRAIN Batch 19/6500 loss 4.495024 loss_att 6.857892 loss_ctc 5.755525 loss_rnnt 3.817052 hw_loss 0.069998 lr 0.00038932 rank 0
2023-02-22 13:43:05,999 DEBUG TRAIN Batch 19/6500 loss 9.433628 loss_att 12.445196 loss_ctc 11.373577 loss_rnnt 8.529408 hw_loss 0.081089 lr 0.00038930 rank 4
2023-02-22 13:43:06,003 DEBUG TRAIN Batch 19/6500 loss 3.851009 loss_att 7.880249 loss_ctc 7.589666 loss_rnnt 2.495149 hw_loss 0.096607 lr 0.00038927 rank 7
2023-02-22 13:43:06,004 DEBUG TRAIN Batch 19/6500 loss 5.402583 loss_att 7.913858 loss_ctc 7.732975 loss_rnnt 4.582881 hw_loss 0.012615 lr 0.00038933 rank 6
2023-02-22 13:43:06,005 DEBUG TRAIN Batch 19/6500 loss 4.919020 loss_att 7.752871 loss_ctc 11.793113 loss_rnnt 3.335906 hw_loss 0.187121 lr 0.00038933 rank 5
2023-02-22 13:43:06,008 DEBUG TRAIN Batch 19/6500 loss 6.189721 loss_att 10.332466 loss_ctc 12.752078 loss_rnnt 4.463780 hw_loss 0.042019 lr 0.00038924 rank 2
2023-02-22 13:43:06,010 DEBUG TRAIN Batch 19/6500 loss 5.712943 loss_att 8.329514 loss_ctc 12.054113 loss_rnnt 4.233402 hw_loss 0.207630 lr 0.00038934 rank 1
2023-02-22 13:43:06,056 DEBUG TRAIN Batch 19/6500 loss 13.467000 loss_att 15.972841 loss_ctc 20.630835 loss_rnnt 11.939830 hw_loss 0.132793 lr 0.00038923 rank 3
2023-02-22 13:44:21,579 DEBUG TRAIN Batch 19/6600 loss 9.442131 loss_att 11.858130 loss_ctc 12.910362 loss_rnnt 8.419223 hw_loss 0.144896 lr 0.00038920 rank 0
2023-02-22 13:44:21,579 DEBUG TRAIN Batch 19/6600 loss 12.163367 loss_att 14.085815 loss_ctc 12.845995 loss_rnnt 11.668837 hw_loss 0.035672 lr 0.00038922 rank 1
2023-02-22 13:44:21,582 DEBUG TRAIN Batch 19/6600 loss 16.505632 loss_att 23.522579 loss_ctc 26.581709 loss_rnnt 13.728947 hw_loss 0.055909 lr 0.00038913 rank 2
2023-02-22 13:44:21,583 DEBUG TRAIN Batch 19/6600 loss 16.526564 loss_att 16.429249 loss_ctc 22.921482 loss_rnnt 15.652820 hw_loss 0.076032 lr 0.00038921 rank 5
2023-02-22 13:44:21,584 DEBUG TRAIN Batch 19/6600 loss 9.128308 loss_att 12.320532 loss_ctc 12.717854 loss_rnnt 7.962985 hw_loss 0.090511 lr 0.00038912 rank 3
2023-02-22 13:44:21,584 DEBUG TRAIN Batch 19/6600 loss 11.505901 loss_att 12.856605 loss_ctc 17.624382 loss_rnnt 10.413940 hw_loss 0.011295 lr 0.00038918 rank 4
2023-02-22 13:44:21,586 DEBUG TRAIN Batch 19/6600 loss 12.833981 loss_att 16.007923 loss_ctc 18.183014 loss_rnnt 11.460484 hw_loss 0.047820 lr 0.00038915 rank 7
2023-02-22 13:44:21,586 DEBUG TRAIN Batch 19/6600 loss 10.571230 loss_att 11.641431 loss_ctc 15.320481 loss_rnnt 9.654922 hw_loss 0.129436 lr 0.00038922 rank 6
2023-02-22 13:45:37,527 DEBUG TRAIN Batch 19/6700 loss 1.915624 loss_att 4.700641 loss_ctc 3.177212 loss_rnnt 1.173615 hw_loss 0.031487 lr 0.00038904 rank 7
2023-02-22 13:45:37,529 DEBUG TRAIN Batch 19/6700 loss 11.305664 loss_att 15.270973 loss_ctc 16.179604 loss_rnnt 9.826032 hw_loss 0.068836 lr 0.00038908 rank 0
2023-02-22 13:45:37,529 DEBUG TRAIN Batch 19/6700 loss 6.810466 loss_att 12.225621 loss_ctc 8.531446 loss_rnnt 5.431422 hw_loss 0.124778 lr 0.00038906 rank 4
2023-02-22 13:45:37,529 DEBUG TRAIN Batch 19/6700 loss 8.403358 loss_att 10.136127 loss_ctc 14.410091 loss_rnnt 7.211758 hw_loss 0.082778 lr 0.00038910 rank 6
2023-02-22 13:45:37,533 DEBUG TRAIN Batch 19/6700 loss 11.926263 loss_att 16.298061 loss_ctc 17.622673 loss_rnnt 10.187860 hw_loss 0.195979 lr 0.00038909 rank 5
2023-02-22 13:45:37,538 DEBUG TRAIN Batch 19/6700 loss 11.118333 loss_att 15.484212 loss_ctc 15.837010 loss_rnnt 9.554364 hw_loss 0.115566 lr 0.00038911 rank 1
2023-02-22 13:45:37,545 DEBUG TRAIN Batch 19/6700 loss 7.904113 loss_att 10.850718 loss_ctc 14.817620 loss_rnnt 6.356320 hw_loss 0.068757 lr 0.00038900 rank 3
2023-02-22 13:45:37,547 DEBUG TRAIN Batch 19/6700 loss 20.385931 loss_att 20.930340 loss_ctc 23.451229 loss_rnnt 19.839548 hw_loss 0.053989 lr 0.00038901 rank 2
2023-02-22 13:46:54,098 DEBUG TRAIN Batch 19/6800 loss 5.376640 loss_att 8.565971 loss_ctc 7.842930 loss_rnnt 4.365822 hw_loss 0.082713 lr 0.00038892 rank 7
2023-02-22 13:46:54,102 DEBUG TRAIN Batch 19/6800 loss 5.149202 loss_att 8.188442 loss_ctc 9.026636 loss_rnnt 3.972633 hw_loss 0.096994 lr 0.00038888 rank 3
2023-02-22 13:46:54,103 DEBUG TRAIN Batch 19/6800 loss 12.476785 loss_att 13.688898 loss_ctc 15.868441 loss_rnnt 11.711739 hw_loss 0.132006 lr 0.00038898 rank 5
2023-02-22 13:46:54,103 DEBUG TRAIN Batch 19/6800 loss 5.400325 loss_att 9.951926 loss_ctc 8.352090 loss_rnnt 4.084883 hw_loss 0.021664 lr 0.00038894 rank 4
2023-02-22 13:46:54,104 DEBUG TRAIN Batch 19/6800 loss 9.401469 loss_att 12.047093 loss_ctc 12.937687 loss_rnnt 8.301992 hw_loss 0.185354 lr 0.00038898 rank 6
2023-02-22 13:46:54,106 DEBUG TRAIN Batch 19/6800 loss 5.773391 loss_att 9.519659 loss_ctc 7.449621 loss_rnnt 4.766757 hw_loss 0.063531 lr 0.00038899 rank 1
2023-02-22 13:46:54,107 DEBUG TRAIN Batch 19/6800 loss 8.897663 loss_att 10.692888 loss_ctc 12.928774 loss_rnnt 8.000229 hw_loss 0.001703 lr 0.00038897 rank 0
2023-02-22 13:46:54,109 DEBUG TRAIN Batch 19/6800 loss 8.269468 loss_att 12.691121 loss_ctc 13.799986 loss_rnnt 6.538746 hw_loss 0.204356 lr 0.00038889 rank 2
2023-02-22 13:48:09,909 DEBUG TRAIN Batch 19/6900 loss 7.294473 loss_att 10.563788 loss_ctc 12.049565 loss_rnnt 5.937016 hw_loss 0.130464 lr 0.00038885 rank 0
2023-02-22 13:48:09,910 DEBUG TRAIN Batch 19/6900 loss 12.141296 loss_att 14.603009 loss_ctc 19.067219 loss_rnnt 10.668512 hw_loss 0.106845 lr 0.00038880 rank 7
2023-02-22 13:48:09,912 DEBUG TRAIN Batch 19/6900 loss 10.053541 loss_att 10.995980 loss_ctc 12.915392 loss_rnnt 9.394833 hw_loss 0.166201 lr 0.00038886 rank 5
2023-02-22 13:48:09,912 DEBUG TRAIN Batch 19/6900 loss 10.290945 loss_att 13.199209 loss_ctc 15.387115 loss_rnnt 9.003109 hw_loss 0.050052 lr 0.00038883 rank 4
2023-02-22 13:48:09,918 DEBUG TRAIN Batch 19/6900 loss 16.203913 loss_att 17.042711 loss_ctc 24.968166 loss_rnnt 14.807271 hw_loss 0.113092 lr 0.00038887 rank 1
2023-02-22 13:48:09,919 DEBUG TRAIN Batch 19/6900 loss 13.639215 loss_att 14.995911 loss_ctc 17.287098 loss_rnnt 12.809275 hw_loss 0.135404 lr 0.00038876 rank 3
2023-02-22 13:48:09,921 DEBUG TRAIN Batch 19/6900 loss 8.538442 loss_att 11.832009 loss_ctc 13.088663 loss_rnnt 7.225440 hw_loss 0.089235 lr 0.00038886 rank 6
2023-02-22 13:48:09,963 DEBUG TRAIN Batch 19/6900 loss 7.386399 loss_att 9.107972 loss_ctc 8.514889 loss_rnnt 6.857841 hw_loss 0.063335 lr 0.00038877 rank 2
2023-02-22 13:49:25,737 DEBUG TRAIN Batch 19/7000 loss 21.594650 loss_att 26.190676 loss_ctc 34.136734 loss_rnnt 18.991896 hw_loss 0.021134 lr 0.00038875 rank 1
2023-02-22 13:49:25,739 DEBUG TRAIN Batch 19/7000 loss 8.344942 loss_att 8.648601 loss_ctc 10.227789 loss_rnnt 7.951739 hw_loss 0.152672 lr 0.00038866 rank 2
2023-02-22 13:49:25,742 DEBUG TRAIN Batch 19/7000 loss 7.987367 loss_att 10.095242 loss_ctc 8.569429 loss_rnnt 7.449103 hw_loss 0.073275 lr 0.00038868 rank 7
2023-02-22 13:49:25,743 DEBUG TRAIN Batch 19/7000 loss 10.792861 loss_att 11.314278 loss_ctc 14.902493 loss_rnnt 10.086728 hw_loss 0.101060 lr 0.00038871 rank 4
2023-02-22 13:49:25,744 DEBUG TRAIN Batch 19/7000 loss 11.101014 loss_att 13.106926 loss_ctc 13.856577 loss_rnnt 10.254848 hw_loss 0.145457 lr 0.00038874 rank 5
2023-02-22 13:49:25,746 DEBUG TRAIN Batch 19/7000 loss 4.616793 loss_att 6.900514 loss_ctc 6.632051 loss_rnnt 3.849564 hw_loss 0.078344 lr 0.00038875 rank 6
2023-02-22 13:49:25,746 DEBUG TRAIN Batch 19/7000 loss 18.281109 loss_att 18.505402 loss_ctc 27.746733 loss_rnnt 16.934748 hw_loss 0.073908 lr 0.00038873 rank 0
2023-02-22 13:49:25,750 DEBUG TRAIN Batch 19/7000 loss 11.034703 loss_att 12.688535 loss_ctc 16.438156 loss_rnnt 9.974350 hw_loss 0.017112 lr 0.00038864 rank 3
2023-02-22 13:50:44,571 DEBUG TRAIN Batch 19/7100 loss 11.669235 loss_att 16.277765 loss_ctc 18.825912 loss_rnnt 9.726002 hw_loss 0.126195 lr 0.00038857 rank 7
2023-02-22 13:50:44,578 DEBUG TRAIN Batch 19/7100 loss 7.746678 loss_att 8.656704 loss_ctc 12.000368 loss_rnnt 6.917754 hw_loss 0.149550 lr 0.00038862 rank 5
2023-02-22 13:50:44,579 DEBUG TRAIN Batch 19/7100 loss 27.336781 loss_att 36.481071 loss_ctc 35.062286 loss_rnnt 24.427128 hw_loss 0.095112 lr 0.00038859 rank 4
2023-02-22 13:50:44,579 DEBUG TRAIN Batch 19/7100 loss 6.076349 loss_att 8.451183 loss_ctc 7.520909 loss_rnnt 5.354936 hw_loss 0.100947 lr 0.00038861 rank 0
2023-02-22 13:50:44,586 DEBUG TRAIN Batch 19/7100 loss 4.690177 loss_att 7.125183 loss_ctc 5.642597 loss_rnnt 4.073992 hw_loss 0.004115 lr 0.00038863 rank 6
2023-02-22 13:50:44,585 DEBUG TRAIN Batch 19/7100 loss 13.841030 loss_att 15.318163 loss_ctc 17.574654 loss_rnnt 13.032004 hw_loss 0.029593 lr 0.00038853 rank 3
2023-02-22 13:50:44,586 DEBUG TRAIN Batch 19/7100 loss 3.644382 loss_att 7.658236 loss_ctc 4.611230 loss_rnnt 2.684262 hw_loss 0.053318 lr 0.00038854 rank 2
2023-02-22 13:50:44,588 DEBUG TRAIN Batch 19/7100 loss 7.934295 loss_att 11.140745 loss_ctc 12.779167 loss_rnnt 6.616720 hw_loss 0.056815 lr 0.00038864 rank 1
2023-02-22 13:52:00,085 DEBUG TRAIN Batch 19/7200 loss 2.029036 loss_att 5.762565 loss_ctc 2.652510 loss_rnnt 1.192228 hw_loss 0.013073 lr 0.00038850 rank 0
2023-02-22 13:52:00,087 DEBUG TRAIN Batch 19/7200 loss 10.720266 loss_att 13.204083 loss_ctc 16.591146 loss_rnnt 9.363866 hw_loss 0.144098 lr 0.00038845 rank 7
2023-02-22 13:52:00,089 DEBUG TRAIN Batch 19/7200 loss 8.640023 loss_att 10.065007 loss_ctc 10.045827 loss_rnnt 8.099059 hw_loss 0.128490 lr 0.00038847 rank 4
2023-02-22 13:52:00,089 DEBUG TRAIN Batch 19/7200 loss 6.837824 loss_att 9.575527 loss_ctc 9.273802 loss_rnnt 5.943836 hw_loss 0.040593 lr 0.00038851 rank 5
2023-02-22 13:52:00,090 DEBUG TRAIN Batch 19/7200 loss 7.492621 loss_att 11.036560 loss_ctc 11.836931 loss_rnnt 6.183046 hw_loss 0.040398 lr 0.00038841 rank 3
2023-02-22 13:52:00,090 DEBUG TRAIN Batch 19/7200 loss 7.525340 loss_att 11.076697 loss_ctc 12.436413 loss_rnnt 6.106670 hw_loss 0.100478 lr 0.00038842 rank 2
2023-02-22 13:52:00,092 DEBUG TRAIN Batch 19/7200 loss 4.878724 loss_att 7.703972 loss_ctc 5.299466 loss_rnnt 4.203401 hw_loss 0.101578 lr 0.00038851 rank 6
2023-02-22 13:52:00,130 DEBUG TRAIN Batch 19/7200 loss 13.434967 loss_att 16.916639 loss_ctc 18.022499 loss_rnnt 12.126390 hw_loss 0.001069 lr 0.00038852 rank 1
2023-02-22 13:53:15,355 DEBUG TRAIN Batch 19/7300 loss 16.419495 loss_att 17.115669 loss_ctc 23.701199 loss_rnnt 15.239799 hw_loss 0.130433 lr 0.00038829 rank 3
2023-02-22 13:53:15,355 DEBUG TRAIN Batch 19/7300 loss 4.400181 loss_att 6.988636 loss_ctc 6.571450 loss_rnnt 3.503317 hw_loss 0.168131 lr 0.00038840 rank 1
2023-02-22 13:53:15,356 DEBUG TRAIN Batch 19/7300 loss 8.391454 loss_att 14.803707 loss_ctc 11.478720 loss_rnnt 6.672389 hw_loss 0.046834 lr 0.00038839 rank 5
2023-02-22 13:53:15,358 DEBUG TRAIN Batch 19/7300 loss 13.636096 loss_att 18.688248 loss_ctc 20.508223 loss_rnnt 11.681740 hw_loss 0.051831 lr 0.00038836 rank 4
2023-02-22 13:53:15,358 DEBUG TRAIN Batch 19/7300 loss 6.975290 loss_att 9.151339 loss_ctc 9.361486 loss_rnnt 6.169577 hw_loss 0.098145 lr 0.00038838 rank 0
2023-02-22 13:53:15,360 DEBUG TRAIN Batch 19/7300 loss 8.005950 loss_att 12.518752 loss_ctc 12.030310 loss_rnnt 6.523990 hw_loss 0.080285 lr 0.00038839 rank 6
2023-02-22 13:53:15,360 DEBUG TRAIN Batch 19/7300 loss 10.292298 loss_att 14.917461 loss_ctc 11.617586 loss_rnnt 9.154482 hw_loss 0.067647 lr 0.00038833 rank 7
2023-02-22 13:53:15,363 DEBUG TRAIN Batch 19/7300 loss 7.519528 loss_att 10.046570 loss_ctc 13.207951 loss_rnnt 6.196366 hw_loss 0.111182 lr 0.00038830 rank 2
2023-02-22 13:54:30,345 DEBUG TRAIN Batch 19/7400 loss 9.744873 loss_att 12.745307 loss_ctc 11.806854 loss_rnnt 8.803137 hw_loss 0.125099 lr 0.00038826 rank 0
2023-02-22 13:54:30,346 DEBUG TRAIN Batch 19/7400 loss 7.467403 loss_att 10.548298 loss_ctc 11.319458 loss_rnnt 6.289096 hw_loss 0.090975 lr 0.00038827 rank 5
2023-02-22 13:54:30,348 DEBUG TRAIN Batch 19/7400 loss 10.223936 loss_att 14.846413 loss_ctc 14.933596 loss_rnnt 8.642106 hw_loss 0.055086 lr 0.00038819 rank 2
2023-02-22 13:54:30,349 DEBUG TRAIN Batch 19/7400 loss 12.246213 loss_att 13.416567 loss_ctc 17.494446 loss_rnnt 11.185503 hw_loss 0.237887 lr 0.00038828 rank 1
2023-02-22 13:54:30,350 DEBUG TRAIN Batch 19/7400 loss 4.090442 loss_att 8.912621 loss_ctc 7.976515 loss_rnnt 2.549356 hw_loss 0.109702 lr 0.00038824 rank 4
2023-02-22 13:54:30,353 DEBUG TRAIN Batch 19/7400 loss 4.118613 loss_att 6.769785 loss_ctc 5.058447 loss_rnnt 3.456221 hw_loss 0.012837 lr 0.00038821 rank 7
2023-02-22 13:54:30,354 DEBUG TRAIN Batch 19/7400 loss 11.481349 loss_att 12.099924 loss_ctc 12.239338 loss_rnnt 11.255333 hw_loss 0.002315 lr 0.00038818 rank 3
2023-02-22 13:54:30,369 DEBUG TRAIN Batch 19/7400 loss 9.025701 loss_att 11.400890 loss_ctc 10.823090 loss_rnnt 8.262770 hw_loss 0.090452 lr 0.00038828 rank 6
2023-02-22 13:55:48,323 DEBUG TRAIN Batch 19/7500 loss 9.354082 loss_att 11.741222 loss_ctc 13.705599 loss_rnnt 8.267826 hw_loss 0.053673 lr 0.00038815 rank 0
2023-02-22 13:55:48,326 DEBUG TRAIN Batch 19/7500 loss 2.843932 loss_att 4.725729 loss_ctc 3.813264 loss_rnnt 2.291934 hw_loss 0.086989 lr 0.00038810 rank 7
2023-02-22 13:55:48,330 DEBUG TRAIN Batch 19/7500 loss 14.838629 loss_att 16.297602 loss_ctc 22.636971 loss_rnnt 13.497955 hw_loss 0.017065 lr 0.00038812 rank 4
2023-02-22 13:55:48,332 DEBUG TRAIN Batch 19/7500 loss 6.686739 loss_att 9.659425 loss_ctc 8.888305 loss_rnnt 5.758388 hw_loss 0.075509 lr 0.00038806 rank 3
2023-02-22 13:55:48,333 DEBUG TRAIN Batch 19/7500 loss 8.836383 loss_att 11.898414 loss_ctc 10.676125 loss_rnnt 7.895300 hw_loss 0.156335 lr 0.00038815 rank 5
2023-02-22 13:55:48,333 DEBUG TRAIN Batch 19/7500 loss 8.383880 loss_att 12.141106 loss_ctc 11.102611 loss_rnnt 7.217671 hw_loss 0.097997 lr 0.00038817 rank 1
2023-02-22 13:55:48,333 DEBUG TRAIN Batch 19/7500 loss 4.359906 loss_att 7.769001 loss_ctc 6.246577 loss_rnnt 3.349242 hw_loss 0.144916 lr 0.00038807 rank 2
2023-02-22 13:55:48,380 DEBUG TRAIN Batch 19/7500 loss 6.113787 loss_att 9.241995 loss_ctc 6.906532 loss_rnnt 5.323415 hw_loss 0.110685 lr 0.00038816 rank 6
2023-02-22 13:57:04,848 DEBUG TRAIN Batch 19/7600 loss 11.228567 loss_att 14.612108 loss_ctc 16.085962 loss_rnnt 9.851255 hw_loss 0.099283 lr 0.00038804 rank 5
2023-02-22 13:57:04,849 DEBUG TRAIN Batch 19/7600 loss 10.962926 loss_att 14.363699 loss_ctc 18.631458 loss_rnnt 9.178628 hw_loss 0.153135 lr 0.00038801 rank 4
2023-02-22 13:57:04,849 DEBUG TRAIN Batch 19/7600 loss 11.338264 loss_att 11.138086 loss_ctc 15.227404 loss_rnnt 10.712908 hw_loss 0.275320 lr 0.00038798 rank 7
2023-02-22 13:57:04,849 DEBUG TRAIN Batch 19/7600 loss 7.253128 loss_att 8.097830 loss_ctc 9.919775 loss_rnnt 6.638606 hw_loss 0.168803 lr 0.00038803 rank 0
2023-02-22 13:57:04,853 DEBUG TRAIN Batch 19/7600 loss 11.389177 loss_att 11.186847 loss_ctc 13.537952 loss_rnnt 11.050322 hw_loss 0.174036 lr 0.00038804 rank 6
2023-02-22 13:57:04,856 DEBUG TRAIN Batch 19/7600 loss 11.769650 loss_att 11.962760 loss_ctc 17.139845 loss_rnnt 10.928829 hw_loss 0.161572 lr 0.00038794 rank 3
2023-02-22 13:57:04,856 DEBUG TRAIN Batch 19/7600 loss 11.770852 loss_att 12.713047 loss_ctc 16.848280 loss_rnnt 10.846602 hw_loss 0.110290 lr 0.00038805 rank 1
2023-02-22 13:57:04,857 DEBUG TRAIN Batch 19/7600 loss 5.989537 loss_att 7.012303 loss_ctc 8.138839 loss_rnnt 5.457776 hw_loss 0.076189 lr 0.00038795 rank 2
2023-02-22 13:58:19,753 DEBUG TRAIN Batch 19/7700 loss 10.219562 loss_att 10.460565 loss_ctc 14.168926 loss_rnnt 9.564719 hw_loss 0.150112 lr 0.00038789 rank 4
2023-02-22 13:58:19,754 DEBUG TRAIN Batch 19/7700 loss 12.712143 loss_att 15.605891 loss_ctc 15.718616 loss_rnnt 11.702929 hw_loss 0.055503 lr 0.00038786 rank 7
2023-02-22 13:58:19,755 DEBUG TRAIN Batch 19/7700 loss 11.893281 loss_att 12.755674 loss_ctc 15.006577 loss_rnnt 11.272362 hw_loss 0.062502 lr 0.00038783 rank 3
2023-02-22 13:58:19,755 DEBUG TRAIN Batch 19/7700 loss 8.555778 loss_att 13.720538 loss_ctc 14.665075 loss_rnnt 6.614997 hw_loss 0.174855 lr 0.00038793 rank 6
2023-02-22 13:58:19,758 DEBUG TRAIN Batch 19/7700 loss 11.597254 loss_att 18.785341 loss_ctc 20.280807 loss_rnnt 8.961033 hw_loss 0.076491 lr 0.00038791 rank 0
2023-02-22 13:58:19,759 DEBUG TRAIN Batch 19/7700 loss 10.127081 loss_att 13.417524 loss_ctc 16.662815 loss_rnnt 8.550653 hw_loss 0.087952 lr 0.00038793 rank 1
2023-02-22 13:58:19,760 DEBUG TRAIN Batch 19/7700 loss 9.092020 loss_att 10.763867 loss_ctc 13.341823 loss_rnnt 8.135450 hw_loss 0.104174 lr 0.00038792 rank 5
2023-02-22 13:58:19,760 DEBUG TRAIN Batch 19/7700 loss 10.387889 loss_att 10.649572 loss_ctc 13.767271 loss_rnnt 9.780584 hw_loss 0.195717 lr 0.00038784 rank 2
2023-02-22 13:59:37,862 DEBUG TRAIN Batch 19/7800 loss 5.564692 loss_att 10.116655 loss_ctc 9.420710 loss_rnnt 4.049253 hw_loss 0.170458 lr 0.00038780 rank 5
2023-02-22 13:59:37,870 DEBUG TRAIN Batch 19/7800 loss 9.143806 loss_att 11.607198 loss_ctc 14.784494 loss_rnnt 7.853355 hw_loss 0.085650 lr 0.00038777 rank 4
2023-02-22 13:59:37,873 DEBUG TRAIN Batch 19/7800 loss 17.410330 loss_att 22.695242 loss_ctc 23.840315 loss_rnnt 15.437914 hw_loss 0.108942 lr 0.00038782 rank 1
2023-02-22 13:59:37,873 DEBUG TRAIN Batch 19/7800 loss 3.789773 loss_att 6.966269 loss_ctc 7.252180 loss_rnnt 2.661153 hw_loss 0.059375 lr 0.00038775 rank 7
2023-02-22 13:59:37,876 DEBUG TRAIN Batch 19/7800 loss 12.936169 loss_att 15.125918 loss_ctc 25.184357 loss_rnnt 10.781267 hw_loss 0.157237 lr 0.00038771 rank 3
2023-02-22 13:59:37,888 DEBUG TRAIN Batch 19/7800 loss 5.043557 loss_att 6.597411 loss_ctc 7.522489 loss_rnnt 4.363490 hw_loss 0.072696 lr 0.00038780 rank 0
2023-02-22 13:59:37,894 DEBUG TRAIN Batch 19/7800 loss 4.189897 loss_att 5.557307 loss_ctc 5.750514 loss_rnnt 3.675471 hw_loss 0.061613 lr 0.00038781 rank 6
2023-02-22 13:59:37,902 DEBUG TRAIN Batch 19/7800 loss 5.270061 loss_att 6.197512 loss_ctc 3.916470 loss_rnnt 5.199169 hw_loss 0.123526 lr 0.00038772 rank 2
2023-02-22 14:00:53,789 DEBUG TRAIN Batch 19/7900 loss 2.676201 loss_att 6.118126 loss_ctc 5.578523 loss_rnnt 1.591984 hw_loss 0.016604 lr 0.00038769 rank 5
2023-02-22 14:00:53,790 DEBUG TRAIN Batch 19/7900 loss 6.660162 loss_att 10.007941 loss_ctc 12.806637 loss_rnnt 5.106349 hw_loss 0.121363 lr 0.00038766 rank 4
2023-02-22 14:00:53,793 DEBUG TRAIN Batch 19/7900 loss 4.420782 loss_att 9.906007 loss_ctc 6.493960 loss_rnnt 2.979190 hw_loss 0.127732 lr 0.00038768 rank 0
2023-02-22 14:00:53,797 DEBUG TRAIN Batch 19/7900 loss 6.938516 loss_att 8.390515 loss_ctc 7.635015 loss_rnnt 6.500372 hw_loss 0.102895 lr 0.00038763 rank 7
2023-02-22 14:00:53,799 DEBUG TRAIN Batch 19/7900 loss 9.349016 loss_att 10.812750 loss_ctc 13.422604 loss_rnnt 8.472361 hw_loss 0.076433 lr 0.00038759 rank 3
2023-02-22 14:00:53,799 DEBUG TRAIN Batch 19/7900 loss 11.669845 loss_att 13.402049 loss_ctc 16.493305 loss_rnnt 10.619070 hw_loss 0.114761 lr 0.00038769 rank 6
2023-02-22 14:00:53,800 DEBUG TRAIN Batch 19/7900 loss 4.912345 loss_att 6.665982 loss_ctc 5.788970 loss_rnnt 4.402465 hw_loss 0.079255 lr 0.00038760 rank 2
2023-02-22 14:00:53,801 DEBUG TRAIN Batch 19/7900 loss 9.212664 loss_att 12.648674 loss_ctc 14.208051 loss_rnnt 7.827033 hw_loss 0.060705 lr 0.00038770 rank 1
2023-02-22 14:02:09,540 DEBUG TRAIN Batch 19/8000 loss 15.087583 loss_att 16.580929 loss_ctc 19.411331 loss_rnnt 14.185855 hw_loss 0.049795 lr 0.00038757 rank 5
2023-02-22 14:02:09,542 DEBUG TRAIN Batch 19/8000 loss 8.064228 loss_att 11.505474 loss_ctc 12.428023 loss_rnnt 6.762741 hw_loss 0.058870 lr 0.00038758 rank 1
2023-02-22 14:02:09,545 DEBUG TRAIN Batch 19/8000 loss 15.360424 loss_att 19.200926 loss_ctc 23.877335 loss_rnnt 13.387741 hw_loss 0.129365 lr 0.00038751 rank 7
2023-02-22 14:02:09,545 DEBUG TRAIN Batch 19/8000 loss 10.934747 loss_att 16.341713 loss_ctc 17.528175 loss_rnnt 8.952381 hw_loss 0.040967 lr 0.00038756 rank 0
2023-02-22 14:02:09,547 DEBUG TRAIN Batch 19/8000 loss 8.813756 loss_att 11.050728 loss_ctc 12.400366 loss_rnnt 7.877077 hw_loss 0.020757 lr 0.00038749 rank 2
2023-02-22 14:02:09,548 DEBUG TRAIN Batch 19/8000 loss 11.537463 loss_att 15.443295 loss_ctc 13.770704 loss_rnnt 10.425905 hw_loss 0.061175 lr 0.00038748 rank 3
2023-02-22 14:02:09,550 DEBUG TRAIN Batch 19/8000 loss 11.036234 loss_att 13.508533 loss_ctc 16.097706 loss_rnnt 9.852818 hw_loss 0.026421 lr 0.00038754 rank 4
2023-02-22 14:02:09,552 DEBUG TRAIN Batch 19/8000 loss 14.477378 loss_att 17.697563 loss_ctc 20.009560 loss_rnnt 13.016203 hw_loss 0.149091 lr 0.00038758 rank 6
2023-02-22 14:03:25,390 DEBUG TRAIN Batch 19/8100 loss 9.771517 loss_att 11.931427 loss_ctc 13.749514 loss_rnnt 8.752295 hw_loss 0.106575 lr 0.00038745 rank 0
2023-02-22 14:03:25,390 DEBUG TRAIN Batch 19/8100 loss 10.531837 loss_att 11.976938 loss_ctc 12.672928 loss_rnnt 9.920097 hw_loss 0.069822 lr 0.00038742 rank 4
2023-02-22 14:03:25,392 DEBUG TRAIN Batch 19/8100 loss 4.921756 loss_att 7.769773 loss_ctc 8.085117 loss_rnnt 3.860365 hw_loss 0.131263 lr 0.00038740 rank 7
2023-02-22 14:03:25,395 DEBUG TRAIN Batch 19/8100 loss 13.045221 loss_att 15.595606 loss_ctc 18.509808 loss_rnnt 11.760166 hw_loss 0.086937 lr 0.00038745 rank 5
2023-02-22 14:03:25,398 DEBUG TRAIN Batch 19/8100 loss 20.098867 loss_att 22.402332 loss_ctc 27.465796 loss_rnnt 18.587566 hw_loss 0.128160 lr 0.00038736 rank 3
2023-02-22 14:03:25,398 DEBUG TRAIN Batch 19/8100 loss 13.069704 loss_att 15.224785 loss_ctc 15.253135 loss_rnnt 12.303353 hw_loss 0.082894 lr 0.00038747 rank 1
2023-02-22 14:03:25,415 DEBUG TRAIN Batch 19/8100 loss 10.873507 loss_att 13.409810 loss_ctc 15.596111 loss_rnnt 9.642631 hw_loss 0.176129 lr 0.00038746 rank 6
2023-02-22 14:03:25,427 DEBUG TRAIN Batch 19/8100 loss 5.890208 loss_att 9.270708 loss_ctc 11.677805 loss_rnnt 4.416395 hw_loss 0.048813 lr 0.00038737 rank 2
2023-02-22 14:04:42,814 DEBUG TRAIN Batch 19/8200 loss 13.116824 loss_att 13.593843 loss_ctc 15.010783 loss_rnnt 12.683273 hw_loss 0.160534 lr 0.00038728 rank 7
2023-02-22 14:04:42,818 DEBUG TRAIN Batch 19/8200 loss 14.017765 loss_att 16.495369 loss_ctc 23.330233 loss_rnnt 12.238541 hw_loss 0.078829 lr 0.00038733 rank 0
2023-02-22 14:04:42,820 DEBUG TRAIN Batch 19/8200 loss 12.259800 loss_att 13.233097 loss_ctc 13.559916 loss_rnnt 11.866207 hw_loss 0.047972 lr 0.00038734 rank 5
2023-02-22 14:04:42,820 DEBUG TRAIN Batch 19/8200 loss 12.045100 loss_att 18.422533 loss_ctc 21.360023 loss_rnnt 9.481393 hw_loss 0.086683 lr 0.00038731 rank 4
2023-02-22 14:04:42,824 DEBUG TRAIN Batch 19/8200 loss 10.382497 loss_att 9.744493 loss_ctc 11.575288 loss_rnnt 10.248644 hw_loss 0.192029 lr 0.00038734 rank 6
2023-02-22 14:04:42,824 DEBUG TRAIN Batch 19/8200 loss 5.822576 loss_att 7.203032 loss_ctc 7.324131 loss_rnnt 5.316835 hw_loss 0.055205 lr 0.00038735 rank 1
2023-02-22 14:04:42,825 DEBUG TRAIN Batch 19/8200 loss 13.931237 loss_att 13.549825 loss_ctc 17.085798 loss_rnnt 13.525968 hw_loss 0.114269 lr 0.00038724 rank 3
2023-02-22 14:04:42,827 DEBUG TRAIN Batch 19/8200 loss 16.508228 loss_att 17.891588 loss_ctc 19.593487 loss_rnnt 15.765633 hw_loss 0.102289 lr 0.00038725 rank 2
2023-02-22 14:05:57,717 DEBUG TRAIN Batch 19/8300 loss 9.003769 loss_att 10.569595 loss_ctc 13.998725 loss_rnnt 7.992984 hw_loss 0.059298 lr 0.00038721 rank 0
2023-02-22 14:05:57,718 DEBUG TRAIN Batch 19/8300 loss 9.602262 loss_att 13.250753 loss_ctc 10.354317 loss_rnnt 8.715182 hw_loss 0.107077 lr 0.00038717 rank 7
2023-02-22 14:05:57,718 DEBUG TRAIN Batch 19/8300 loss 3.585098 loss_att 6.524527 loss_ctc 4.050593 loss_rnnt 2.822858 hw_loss 0.210540 lr 0.00038722 rank 5
2023-02-22 14:05:57,719 DEBUG TRAIN Batch 19/8300 loss 6.288462 loss_att 8.975828 loss_ctc 8.137249 loss_rnnt 5.436557 hw_loss 0.127363 lr 0.00038719 rank 4
2023-02-22 14:05:57,719 DEBUG TRAIN Batch 19/8300 loss 9.303761 loss_att 12.165485 loss_ctc 12.141671 loss_rnnt 8.256545 hw_loss 0.180906 lr 0.00038714 rank 2
2023-02-22 14:05:57,719 DEBUG TRAIN Batch 19/8300 loss 9.472260 loss_att 13.266506 loss_ctc 15.089821 loss_rnnt 7.915293 hw_loss 0.092082 lr 0.00038723 rank 6
2023-02-22 14:05:57,721 DEBUG TRAIN Batch 19/8300 loss 9.440173 loss_att 10.409568 loss_ctc 8.860666 loss_rnnt 9.276093 hw_loss 0.089005 lr 0.00038713 rank 3
2023-02-22 14:05:57,760 DEBUG TRAIN Batch 19/8300 loss 11.210334 loss_att 14.808457 loss_ctc 14.460727 loss_rnnt 10.039628 hw_loss 0.033178 lr 0.00038723 rank 1
2023-02-22 14:06:44,985 DEBUG CV Batch 19/0 loss 2.513805 loss_att 2.504078 loss_ctc 3.250816 loss_rnnt 2.331366 hw_loss 0.161468 history loss 2.420701 rank 3
2023-02-22 14:06:44,994 DEBUG CV Batch 19/0 loss 2.513805 loss_att 2.504078 loss_ctc 3.250816 loss_rnnt 2.331366 hw_loss 0.161468 history loss 2.420701 rank 6
2023-02-22 14:06:44,995 DEBUG CV Batch 19/0 loss 2.513805 loss_att 2.504078 loss_ctc 3.250816 loss_rnnt 2.331366 hw_loss 0.161468 history loss 2.420701 rank 2
2023-02-22 14:06:44,999 DEBUG CV Batch 19/0 loss 2.513805 loss_att 2.504078 loss_ctc 3.250816 loss_rnnt 2.331366 hw_loss 0.161468 history loss 2.420701 rank 4
2023-02-22 14:06:45,001 DEBUG CV Batch 19/0 loss 2.513805 loss_att 2.504078 loss_ctc 3.250816 loss_rnnt 2.331366 hw_loss 0.161468 history loss 2.420701 rank 7
2023-02-22 14:06:45,011 DEBUG CV Batch 19/0 loss 2.513805 loss_att 2.504078 loss_ctc 3.250816 loss_rnnt 2.331366 hw_loss 0.161468 history loss 2.420701 rank 0
2023-02-22 14:06:45,012 DEBUG CV Batch 19/0 loss 2.513805 loss_att 2.504078 loss_ctc 3.250816 loss_rnnt 2.331366 hw_loss 0.161468 history loss 2.420701 rank 1
2023-02-22 14:06:45,025 DEBUG CV Batch 19/0 loss 2.513805 loss_att 2.504078 loss_ctc 3.250816 loss_rnnt 2.331366 hw_loss 0.161468 history loss 2.420701 rank 5
2023-02-22 14:06:56,121 DEBUG CV Batch 19/100 loss 7.420463 loss_att 7.178483 loss_ctc 9.886494 loss_rnnt 7.059968 hw_loss 0.150161 history loss 3.509517 rank 0
2023-02-22 14:06:56,135 DEBUG CV Batch 19/100 loss 7.420463 loss_att 7.178483 loss_ctc 9.886494 loss_rnnt 7.059968 hw_loss 0.150161 history loss 3.509517 rank 7
2023-02-22 14:06:56,193 DEBUG CV Batch 19/100 loss 7.420463 loss_att 7.178483 loss_ctc 9.886494 loss_rnnt 7.059968 hw_loss 0.150161 history loss 3.509517 rank 5
2023-02-22 14:06:56,208 DEBUG CV Batch 19/100 loss 7.420463 loss_att 7.178483 loss_ctc 9.886494 loss_rnnt 7.059968 hw_loss 0.150161 history loss 3.509517 rank 1
2023-02-22 14:06:56,210 DEBUG CV Batch 19/100 loss 7.420463 loss_att 7.178483 loss_ctc 9.886494 loss_rnnt 7.059968 hw_loss 0.150161 history loss 3.509517 rank 4
2023-02-22 14:06:56,214 DEBUG CV Batch 19/100 loss 7.420463 loss_att 7.178483 loss_ctc 9.886494 loss_rnnt 7.059968 hw_loss 0.150161 history loss 3.509517 rank 6
2023-02-22 14:06:56,294 DEBUG CV Batch 19/100 loss 7.420463 loss_att 7.178483 loss_ctc 9.886494 loss_rnnt 7.059968 hw_loss 0.150161 history loss 3.509517 rank 2
2023-02-22 14:06:56,758 DEBUG CV Batch 19/100 loss 7.420463 loss_att 7.178483 loss_ctc 9.886494 loss_rnnt 7.059968 hw_loss 0.150161 history loss 3.509517 rank 3
2023-02-22 14:07:09,465 DEBUG CV Batch 19/200 loss 3.660136 loss_att 11.684958 loss_ctc 4.267904 loss_rnnt 1.950952 hw_loss 0.043470 history loss 4.069180 rank 0
2023-02-22 14:07:09,517 DEBUG CV Batch 19/200 loss 3.660136 loss_att 11.684958 loss_ctc 4.267904 loss_rnnt 1.950952 hw_loss 0.043470 history loss 4.069180 rank 7
2023-02-22 14:07:09,574 DEBUG CV Batch 19/200 loss 3.660136 loss_att 11.684958 loss_ctc 4.267904 loss_rnnt 1.950952 hw_loss 0.043470 history loss 4.069180 rank 5
2023-02-22 14:07:09,634 DEBUG CV Batch 19/200 loss 3.660136 loss_att 11.684958 loss_ctc 4.267904 loss_rnnt 1.950952 hw_loss 0.043470 history loss 4.069180 rank 1
2023-02-22 14:07:09,674 DEBUG CV Batch 19/200 loss 3.660136 loss_att 11.684958 loss_ctc 4.267904 loss_rnnt 1.950952 hw_loss 0.043470 history loss 4.069180 rank 4
2023-02-22 14:07:09,746 DEBUG CV Batch 19/200 loss 3.660136 loss_att 11.684958 loss_ctc 4.267904 loss_rnnt 1.950952 hw_loss 0.043470 history loss 4.069180 rank 6
2023-02-22 14:07:09,749 DEBUG CV Batch 19/200 loss 3.660136 loss_att 11.684958 loss_ctc 4.267904 loss_rnnt 1.950952 hw_loss 0.043470 history loss 4.069180 rank 2
2023-02-22 14:07:11,599 DEBUG CV Batch 19/200 loss 3.660136 loss_att 11.684958 loss_ctc 4.267904 loss_rnnt 1.950952 hw_loss 0.043470 history loss 4.069180 rank 3
2023-02-22 14:07:21,551 DEBUG CV Batch 19/300 loss 4.834982 loss_att 4.919124 loss_ctc 6.368073 loss_rnnt 4.483049 hw_loss 0.245046 history loss 4.196721 rank 0
2023-02-22 14:07:21,632 DEBUG CV Batch 19/300 loss 4.834982 loss_att 4.919124 loss_ctc 6.368073 loss_rnnt 4.483049 hw_loss 0.245046 history loss 4.196721 rank 7
2023-02-22 14:07:21,650 DEBUG CV Batch 19/300 loss 4.834981 loss_att 4.919124 loss_ctc 6.368073 loss_rnnt 4.483049 hw_loss 0.245046 history loss 4.196721 rank 5
2023-02-22 14:07:21,718 DEBUG CV Batch 19/300 loss 4.834982 loss_att 4.919124 loss_ctc 6.368073 loss_rnnt 4.483049 hw_loss 0.245046 history loss 4.196721 rank 4
2023-02-22 14:07:21,853 DEBUG CV Batch 19/300 loss 4.834981 loss_att 4.919124 loss_ctc 6.368073 loss_rnnt 4.483049 hw_loss 0.245046 history loss 4.196721 rank 1
2023-02-22 14:07:21,955 DEBUG CV Batch 19/300 loss 4.834982 loss_att 4.919124 loss_ctc 6.368073 loss_rnnt 4.483049 hw_loss 0.245046 history loss 4.196721 rank 6
2023-02-22 14:07:22,654 DEBUG CV Batch 19/300 loss 4.834982 loss_att 4.919124 loss_ctc 6.368073 loss_rnnt 4.483049 hw_loss 0.245046 history loss 4.196721 rank 2
2023-02-22 14:07:24,324 DEBUG CV Batch 19/300 loss 4.834982 loss_att 4.919124 loss_ctc 6.368073 loss_rnnt 4.483049 hw_loss 0.245046 history loss 4.196721 rank 3
2023-02-22 14:07:33,539 DEBUG CV Batch 19/400 loss 27.451300 loss_att 123.023239 loss_ctc 12.174861 loss_rnnt 10.339996 hw_loss 0.063319 history loss 5.111506 rank 0
2023-02-22 14:07:33,749 DEBUG CV Batch 19/400 loss 27.451300 loss_att 123.023239 loss_ctc 12.174861 loss_rnnt 10.339996 hw_loss 0.063319 history loss 5.111506 rank 5
2023-02-22 14:07:33,764 DEBUG CV Batch 19/400 loss 27.451300 loss_att 123.023239 loss_ctc 12.174861 loss_rnnt 10.339996 hw_loss 0.063319 history loss 5.111506 rank 7
2023-02-22 14:07:33,780 DEBUG CV Batch 19/400 loss 27.451300 loss_att 123.023239 loss_ctc 12.174861 loss_rnnt 10.339996 hw_loss 0.063319 history loss 5.111506 rank 4
2023-02-22 14:07:34,006 DEBUG CV Batch 19/400 loss 27.451300 loss_att 123.023239 loss_ctc 12.174861 loss_rnnt 10.339996 hw_loss 0.063319 history loss 5.111506 rank 1
2023-02-22 14:07:34,105 DEBUG CV Batch 19/400 loss 27.451300 loss_att 123.023239 loss_ctc 12.174861 loss_rnnt 10.339996 hw_loss 0.063319 history loss 5.111506 rank 6
2023-02-22 14:07:34,974 DEBUG CV Batch 19/400 loss 27.451300 loss_att 123.023239 loss_ctc 12.174861 loss_rnnt 10.339996 hw_loss 0.063319 history loss 5.111506 rank 2
2023-02-22 14:07:37,164 DEBUG CV Batch 19/400 loss 27.451300 loss_att 123.023239 loss_ctc 12.174861 loss_rnnt 10.339996 hw_loss 0.063319 history loss 5.111506 rank 3
2023-02-22 14:07:43,993 DEBUG CV Batch 19/500 loss 6.859606 loss_att 6.757330 loss_ctc 8.194307 loss_rnnt 6.649194 hw_loss 0.099200 history loss 5.805784 rank 0
2023-02-22 14:07:44,340 DEBUG CV Batch 19/500 loss 6.859606 loss_att 6.757330 loss_ctc 8.194307 loss_rnnt 6.649194 hw_loss 0.099200 history loss 5.805784 rank 7
2023-02-22 14:07:44,354 DEBUG CV Batch 19/500 loss 6.859606 loss_att 6.757330 loss_ctc 8.194307 loss_rnnt 6.649194 hw_loss 0.099200 history loss 5.805784 rank 4
2023-02-22 14:07:44,358 DEBUG CV Batch 19/500 loss 6.859606 loss_att 6.757330 loss_ctc 8.194307 loss_rnnt 6.649194 hw_loss 0.099200 history loss 5.805784 rank 5
2023-02-22 14:07:44,630 DEBUG CV Batch 19/500 loss 6.859606 loss_att 6.757330 loss_ctc 8.194307 loss_rnnt 6.649194 hw_loss 0.099200 history loss 5.805784 rank 1
2023-02-22 14:07:44,854 DEBUG CV Batch 19/500 loss 6.859606 loss_att 6.757330 loss_ctc 8.194307 loss_rnnt 6.649194 hw_loss 0.099200 history loss 5.805784 rank 6
2023-02-22 14:07:45,675 DEBUG CV Batch 19/500 loss 6.859606 loss_att 6.757330 loss_ctc 8.194307 loss_rnnt 6.649194 hw_loss 0.099200 history loss 5.805784 rank 2
2023-02-22 14:07:49,394 DEBUG CV Batch 19/500 loss 6.859606 loss_att 6.757330 loss_ctc 8.194307 loss_rnnt 6.649194 hw_loss 0.099200 history loss 5.805784 rank 3
2023-02-22 14:07:56,085 DEBUG CV Batch 19/600 loss 6.263310 loss_att 6.813285 loss_ctc 8.403186 loss_rnnt 5.783269 hw_loss 0.158866 history loss 6.749258 rank 0
2023-02-22 14:07:56,358 DEBUG CV Batch 19/600 loss 6.263310 loss_att 6.813285 loss_ctc 8.403186 loss_rnnt 5.783269 hw_loss 0.158866 history loss 6.749258 rank 7
2023-02-22 14:07:56,450 DEBUG CV Batch 19/600 loss 6.263310 loss_att 6.813285 loss_ctc 8.403186 loss_rnnt 5.783269 hw_loss 0.158866 history loss 6.749258 rank 4
2023-02-22 14:07:56,470 DEBUG CV Batch 19/600 loss 6.263310 loss_att 6.813285 loss_ctc 8.403186 loss_rnnt 5.783269 hw_loss 0.158866 history loss 6.749258 rank 5
2023-02-22 14:07:56,798 DEBUG CV Batch 19/600 loss 6.263310 loss_att 6.813285 loss_ctc 8.403186 loss_rnnt 5.783269 hw_loss 0.158866 history loss 6.749258 rank 1
2023-02-22 14:07:57,087 DEBUG CV Batch 19/600 loss 6.263310 loss_att 6.813285 loss_ctc 8.403186 loss_rnnt 5.783269 hw_loss 0.158866 history loss 6.749258 rank 6
2023-02-22 14:07:58,020 DEBUG CV Batch 19/600 loss 6.263310 loss_att 6.813285 loss_ctc 8.403186 loss_rnnt 5.783269 hw_loss 0.158866 history loss 6.749258 rank 2
2023-02-22 14:08:01,813 DEBUG CV Batch 19/600 loss 6.263310 loss_att 6.813285 loss_ctc 8.403186 loss_rnnt 5.783269 hw_loss 0.158866 history loss 6.749258 rank 3
2023-02-22 14:08:07,559 DEBUG CV Batch 19/700 loss 16.490528 loss_att 51.320068 loss_ctc 19.042690 loss_rnnt 9.184251 hw_loss 0.000154 history loss 7.391496 rank 0
2023-02-22 14:08:07,724 DEBUG CV Batch 19/700 loss 16.490528 loss_att 51.320068 loss_ctc 19.042690 loss_rnnt 9.184251 hw_loss 0.000154 history loss 7.391496 rank 7
2023-02-22 14:08:07,840 DEBUG CV Batch 19/700 loss 16.490528 loss_att 51.320068 loss_ctc 19.042690 loss_rnnt 9.184251 hw_loss 0.000154 history loss 7.391496 rank 4
2023-02-22 14:08:07,957 DEBUG CV Batch 19/700 loss 16.490528 loss_att 51.320068 loss_ctc 19.042690 loss_rnnt 9.184251 hw_loss 0.000154 history loss 7.391496 rank 5
2023-02-22 14:08:08,589 DEBUG CV Batch 19/700 loss 16.490528 loss_att 51.320068 loss_ctc 19.042690 loss_rnnt 9.184251 hw_loss 0.000154 history loss 7.391496 rank 6
2023-02-22 14:08:09,028 DEBUG CV Batch 19/700 loss 16.490528 loss_att 51.320068 loss_ctc 19.042690 loss_rnnt 9.184251 hw_loss 0.000154 history loss 7.391496 rank 1
2023-02-22 14:08:09,481 DEBUG CV Batch 19/700 loss 16.490528 loss_att 51.320068 loss_ctc 19.042690 loss_rnnt 9.184251 hw_loss 0.000154 history loss 7.391496 rank 2
2023-02-22 14:08:13,256 DEBUG CV Batch 19/700 loss 16.490528 loss_att 51.320068 loss_ctc 19.042690 loss_rnnt 9.184251 hw_loss 0.000154 history loss 7.391496 rank 3
2023-02-22 14:08:18,683 DEBUG CV Batch 19/800 loss 10.859167 loss_att 10.525950 loss_ctc 16.293690 loss_rnnt 10.150344 hw_loss 0.095369 history loss 6.863035 rank 0
2023-02-22 14:08:18,865 DEBUG CV Batch 19/800 loss 10.859167 loss_att 10.525950 loss_ctc 16.293690 loss_rnnt 10.150344 hw_loss 0.095369 history loss 6.863035 rank 7
2023-02-22 14:08:19,159 DEBUG CV Batch 19/800 loss 10.859167 loss_att 10.525950 loss_ctc 16.293690 loss_rnnt 10.150344 hw_loss 0.095369 history loss 6.863035 rank 4
2023-02-22 14:08:19,235 DEBUG CV Batch 19/800 loss 10.859167 loss_att 10.525950 loss_ctc 16.293690 loss_rnnt 10.150344 hw_loss 0.095369 history loss 6.863035 rank 5
2023-02-22 14:08:19,952 DEBUG CV Batch 19/800 loss 10.859167 loss_att 10.525950 loss_ctc 16.293690 loss_rnnt 10.150344 hw_loss 0.095369 history loss 6.863035 rank 6
2023-02-22 14:08:20,423 DEBUG CV Batch 19/800 loss 10.859167 loss_att 10.525950 loss_ctc 16.293690 loss_rnnt 10.150344 hw_loss 0.095369 history loss 6.863035 rank 1
2023-02-22 14:08:20,826 DEBUG CV Batch 19/800 loss 10.859167 loss_att 10.525950 loss_ctc 16.293690 loss_rnnt 10.150344 hw_loss 0.095369 history loss 6.863035 rank 2
2023-02-22 14:08:24,728 DEBUG CV Batch 19/800 loss 10.859167 loss_att 10.525950 loss_ctc 16.293690 loss_rnnt 10.150344 hw_loss 0.095369 history loss 6.863035 rank 3
2023-02-22 14:08:31,935 DEBUG CV Batch 19/900 loss 15.162987 loss_att 21.315678 loss_ctc 22.775349 loss_rnnt 12.838476 hw_loss 0.148111 history loss 6.669992 rank 0
2023-02-22 14:08:32,081 DEBUG CV Batch 19/900 loss 15.162987 loss_att 21.315678 loss_ctc 22.775349 loss_rnnt 12.838476 hw_loss 0.148111 history loss 6.669992 rank 7
2023-02-22 14:08:32,429 DEBUG CV Batch 19/900 loss 15.162987 loss_att 21.315678 loss_ctc 22.775349 loss_rnnt 12.838476 hw_loss 0.148111 history loss 6.669992 rank 4
2023-02-22 14:08:32,511 DEBUG CV Batch 19/900 loss 15.162987 loss_att 21.315678 loss_ctc 22.775349 loss_rnnt 12.838476 hw_loss 0.148111 history loss 6.669992 rank 5
2023-02-22 14:08:33,286 DEBUG CV Batch 19/900 loss 15.162987 loss_att 21.315678 loss_ctc 22.775349 loss_rnnt 12.838476 hw_loss 0.148111 history loss 6.669992 rank 6
2023-02-22 14:08:33,747 DEBUG CV Batch 19/900 loss 15.162987 loss_att 21.315678 loss_ctc 22.775349 loss_rnnt 12.838476 hw_loss 0.148111 history loss 6.669992 rank 1
2023-02-22 14:08:34,166 DEBUG CV Batch 19/900 loss 15.162987 loss_att 21.315678 loss_ctc 22.775349 loss_rnnt 12.838476 hw_loss 0.148111 history loss 6.669992 rank 2
2023-02-22 14:08:38,134 DEBUG CV Batch 19/900 loss 15.162987 loss_att 21.315678 loss_ctc 22.775349 loss_rnnt 12.838476 hw_loss 0.148111 history loss 6.669992 rank 3
2023-02-22 14:08:44,086 DEBUG CV Batch 19/1000 loss 4.057312 loss_att 5.075797 loss_ctc 4.490757 loss_rnnt 3.756469 hw_loss 0.073788 history loss 6.441728 rank 0
2023-02-22 14:08:44,198 DEBUG CV Batch 19/1000 loss 4.057312 loss_att 5.075797 loss_ctc 4.490757 loss_rnnt 3.756469 hw_loss 0.073788 history loss 6.441728 rank 7
2023-02-22 14:08:44,593 DEBUG CV Batch 19/1000 loss 4.057312 loss_att 5.075797 loss_ctc 4.490757 loss_rnnt 3.756469 hw_loss 0.073788 history loss 6.441728 rank 4
2023-02-22 14:08:44,729 DEBUG CV Batch 19/1000 loss 4.057312 loss_att 5.075797 loss_ctc 4.490757 loss_rnnt 3.756469 hw_loss 0.073788 history loss 6.441728 rank 5
2023-02-22 14:08:45,520 DEBUG CV Batch 19/1000 loss 4.057312 loss_att 5.075797 loss_ctc 4.490757 loss_rnnt 3.756469 hw_loss 0.073788 history loss 6.441728 rank 6
2023-02-22 14:08:45,934 DEBUG CV Batch 19/1000 loss 4.057312 loss_att 5.075797 loss_ctc 4.490757 loss_rnnt 3.756469 hw_loss 0.073788 history loss 6.441728 rank 1
2023-02-22 14:08:46,341 DEBUG CV Batch 19/1000 loss 4.057312 loss_att 5.075797 loss_ctc 4.490757 loss_rnnt 3.756469 hw_loss 0.073788 history loss 6.441728 rank 2
2023-02-22 14:08:51,224 DEBUG CV Batch 19/1000 loss 4.057312 loss_att 5.075797 loss_ctc 4.490757 loss_rnnt 3.756469 hw_loss 0.073788 history loss 6.441728 rank 3
2023-02-22 14:08:55,989 DEBUG CV Batch 19/1100 loss 6.468621 loss_att 6.011850 loss_ctc 9.076532 loss_rnnt 6.101977 hw_loss 0.206767 history loss 6.425468 rank 0
2023-02-22 14:08:56,098 DEBUG CV Batch 19/1100 loss 6.468621 loss_att 6.011850 loss_ctc 9.076532 loss_rnnt 6.101977 hw_loss 0.206767 history loss 6.425468 rank 7
2023-02-22 14:08:56,630 DEBUG CV Batch 19/1100 loss 6.468621 loss_att 6.011850 loss_ctc 9.076532 loss_rnnt 6.101977 hw_loss 0.206767 history loss 6.425468 rank 4
2023-02-22 14:08:56,879 DEBUG CV Batch 19/1100 loss 6.468621 loss_att 6.011850 loss_ctc 9.076532 loss_rnnt 6.101977 hw_loss 0.206767 history loss 6.425468 rank 5
2023-02-22 14:08:57,564 DEBUG CV Batch 19/1100 loss 6.468621 loss_att 6.011850 loss_ctc 9.076532 loss_rnnt 6.101977 hw_loss 0.206767 history loss 6.425468 rank 6
2023-02-22 14:08:57,905 DEBUG CV Batch 19/1100 loss 6.468621 loss_att 6.011850 loss_ctc 9.076532 loss_rnnt 6.101977 hw_loss 0.206767 history loss 6.425468 rank 1
2023-02-22 14:08:58,347 DEBUG CV Batch 19/1100 loss 6.468621 loss_att 6.011850 loss_ctc 9.076532 loss_rnnt 6.101977 hw_loss 0.206767 history loss 6.425468 rank 2
2023-02-22 14:09:03,267 DEBUG CV Batch 19/1100 loss 6.468621 loss_att 6.011850 loss_ctc 9.076532 loss_rnnt 6.101977 hw_loss 0.206767 history loss 6.425468 rank 3
2023-02-22 14:09:06,623 DEBUG CV Batch 19/1200 loss 7.850669 loss_att 8.379677 loss_ctc 9.777577 loss_rnnt 7.450190 hw_loss 0.070793 history loss 6.722200 rank 0
2023-02-22 14:09:06,673 DEBUG CV Batch 19/1200 loss 7.850669 loss_att 8.379677 loss_ctc 9.777577 loss_rnnt 7.450190 hw_loss 0.070793 history loss 6.722200 rank 7
2023-02-22 14:09:07,313 DEBUG CV Batch 19/1200 loss 7.850669 loss_att 8.379677 loss_ctc 9.777577 loss_rnnt 7.450190 hw_loss 0.070793 history loss 6.722200 rank 4
2023-02-22 14:09:07,524 DEBUG CV Batch 19/1200 loss 7.850669 loss_att 8.379677 loss_ctc 9.777577 loss_rnnt 7.450190 hw_loss 0.070793 history loss 6.722200 rank 5
2023-02-22 14:09:08,602 DEBUG CV Batch 19/1200 loss 7.850669 loss_att 8.379677 loss_ctc 9.777577 loss_rnnt 7.450190 hw_loss 0.070793 history loss 6.722200 rank 1
2023-02-22 14:09:09,066 DEBUG CV Batch 19/1200 loss 7.850669 loss_att 8.379677 loss_ctc 9.777577 loss_rnnt 7.450190 hw_loss 0.070793 history loss 6.722200 rank 2
2023-02-22 14:09:09,082 DEBUG CV Batch 19/1200 loss 7.850669 loss_att 8.379677 loss_ctc 9.777577 loss_rnnt 7.450190 hw_loss 0.070793 history loss 6.722200 rank 6
2023-02-22 14:09:14,217 DEBUG CV Batch 19/1200 loss 7.850669 loss_att 8.379677 loss_ctc 9.777577 loss_rnnt 7.450190 hw_loss 0.070793 history loss 6.722200 rank 3
2023-02-22 14:09:18,547 DEBUG CV Batch 19/1300 loss 5.503145 loss_att 5.531383 loss_ctc 7.572737 loss_rnnt 5.149820 hw_loss 0.134498 history loss 7.034695 rank 0
2023-02-22 14:09:18,626 DEBUG CV Batch 19/1300 loss 5.503145 loss_att 5.531383 loss_ctc 7.572737 loss_rnnt 5.149820 hw_loss 0.134498 history loss 7.034695 rank 7
2023-02-22 14:09:19,356 DEBUG CV Batch 19/1300 loss 5.503145 loss_att 5.531383 loss_ctc 7.572737 loss_rnnt 5.149820 hw_loss 0.134498 history loss 7.034695 rank 4
2023-02-22 14:09:19,513 DEBUG CV Batch 19/1300 loss 5.503145 loss_att 5.531383 loss_ctc 7.572737 loss_rnnt 5.149820 hw_loss 0.134498 history loss 7.034695 rank 5
2023-02-22 14:09:20,665 DEBUG CV Batch 19/1300 loss 5.503145 loss_att 5.531383 loss_ctc 7.572737 loss_rnnt 5.149820 hw_loss 0.134498 history loss 7.034695 rank 1
2023-02-22 14:09:21,107 DEBUG CV Batch 19/1300 loss 5.503145 loss_att 5.531383 loss_ctc 7.572737 loss_rnnt 5.149820 hw_loss 0.134498 history loss 7.034695 rank 6
2023-02-22 14:09:21,179 DEBUG CV Batch 19/1300 loss 5.503145 loss_att 5.531383 loss_ctc 7.572737 loss_rnnt 5.149820 hw_loss 0.134498 history loss 7.034695 rank 2
2023-02-22 14:09:26,791 DEBUG CV Batch 19/1300 loss 5.503145 loss_att 5.531383 loss_ctc 7.572737 loss_rnnt 5.149820 hw_loss 0.134498 history loss 7.034695 rank 3
2023-02-22 14:09:29,766 DEBUG CV Batch 19/1400 loss 19.638613 loss_att 43.169411 loss_ctc 14.464062 loss_rnnt 15.601498 hw_loss 0.039177 history loss 7.350780 rank 7
2023-02-22 14:09:29,768 DEBUG CV Batch 19/1400 loss 19.638613 loss_att 43.169411 loss_ctc 14.464062 loss_rnnt 15.601498 hw_loss 0.039177 history loss 7.350780 rank 0
2023-02-22 14:09:30,634 DEBUG CV Batch 19/1400 loss 19.638613 loss_att 43.169411 loss_ctc 14.464062 loss_rnnt 15.601498 hw_loss 0.039177 history loss 7.350780 rank 4
2023-02-22 14:09:30,838 DEBUG CV Batch 19/1400 loss 19.638613 loss_att 43.169411 loss_ctc 14.464062 loss_rnnt 15.601498 hw_loss 0.039177 history loss 7.350780 rank 5
2023-02-22 14:09:31,963 DEBUG CV Batch 19/1400 loss 19.638613 loss_att 43.169411 loss_ctc 14.464062 loss_rnnt 15.601498 hw_loss 0.039177 history loss 7.350780 rank 1
2023-02-22 14:09:32,446 DEBUG CV Batch 19/1400 loss 19.638613 loss_att 43.169411 loss_ctc 14.464062 loss_rnnt 15.601498 hw_loss 0.039177 history loss 7.350780 rank 6
2023-02-22 14:09:33,329 DEBUG CV Batch 19/1400 loss 19.638613 loss_att 43.169411 loss_ctc 14.464062 loss_rnnt 15.601498 hw_loss 0.039177 history loss 7.350780 rank 2
2023-02-22 14:09:38,196 DEBUG CV Batch 19/1400 loss 19.638613 loss_att 43.169411 loss_ctc 14.464062 loss_rnnt 15.601498 hw_loss 0.039177 history loss 7.350780 rank 3
2023-02-22 14:09:41,231 DEBUG CV Batch 19/1500 loss 7.509753 loss_att 7.407464 loss_ctc 7.599859 loss_rnnt 7.465195 hw_loss 0.099379 history loss 7.196039 rank 0
2023-02-22 14:09:41,240 DEBUG CV Batch 19/1500 loss 7.509753 loss_att 7.407464 loss_ctc 7.599859 loss_rnnt 7.465195 hw_loss 0.099379 history loss 7.196039 rank 7
2023-02-22 14:09:42,041 DEBUG CV Batch 19/1500 loss 7.509753 loss_att 7.407464 loss_ctc 7.599859 loss_rnnt 7.465195 hw_loss 0.099379 history loss 7.196039 rank 4
2023-02-22 14:09:42,319 DEBUG CV Batch 19/1500 loss 7.509753 loss_att 7.407464 loss_ctc 7.599859 loss_rnnt 7.465195 hw_loss 0.099379 history loss 7.196039 rank 5
2023-02-22 14:09:43,499 DEBUG CV Batch 19/1500 loss 7.509753 loss_att 7.407464 loss_ctc 7.599859 loss_rnnt 7.465195 hw_loss 0.099379 history loss 7.196039 rank 1
2023-02-22 14:09:44,778 DEBUG CV Batch 19/1500 loss 7.509753 loss_att 7.407464 loss_ctc 7.599859 loss_rnnt 7.465195 hw_loss 0.099379 history loss 7.196039 rank 6
2023-02-22 14:09:44,911 DEBUG CV Batch 19/1500 loss 7.509753 loss_att 7.407464 loss_ctc 7.599859 loss_rnnt 7.465195 hw_loss 0.099379 history loss 7.196039 rank 2
2023-02-22 14:09:49,839 DEBUG CV Batch 19/1500 loss 7.509753 loss_att 7.407464 loss_ctc 7.599859 loss_rnnt 7.465195 hw_loss 0.099379 history loss 7.196039 rank 3
2023-02-22 14:09:54,113 DEBUG CV Batch 19/1600 loss 13.866644 loss_att 18.767849 loss_ctc 14.249113 loss_rnnt 12.810436 hw_loss 0.046821 history loss 7.132097 rank 0
2023-02-22 14:09:54,233 DEBUG CV Batch 19/1600 loss 13.866644 loss_att 18.767849 loss_ctc 14.249113 loss_rnnt 12.810436 hw_loss 0.046821 history loss 7.132097 rank 7
2023-02-22 14:09:54,974 DEBUG CV Batch 19/1600 loss 13.866644 loss_att 18.767849 loss_ctc 14.249113 loss_rnnt 12.810436 hw_loss 0.046821 history loss 7.132097 rank 4
2023-02-22 14:09:55,320 DEBUG CV Batch 19/1600 loss 13.866644 loss_att 18.767849 loss_ctc 14.249113 loss_rnnt 12.810436 hw_loss 0.046821 history loss 7.132097 rank 5
2023-02-22 14:09:56,509 DEBUG CV Batch 19/1600 loss 13.866644 loss_att 18.767849 loss_ctc 14.249113 loss_rnnt 12.810436 hw_loss 0.046821 history loss 7.132097 rank 1
2023-02-22 14:09:57,827 DEBUG CV Batch 19/1600 loss 13.866644 loss_att 18.767849 loss_ctc 14.249113 loss_rnnt 12.810436 hw_loss 0.046821 history loss 7.132097 rank 6
2023-02-22 14:09:57,985 DEBUG CV Batch 19/1600 loss 13.866644 loss_att 18.767849 loss_ctc 14.249113 loss_rnnt 12.810436 hw_loss 0.046821 history loss 7.132097 rank 2
2023-02-22 14:10:02,906 DEBUG CV Batch 19/1600 loss 13.866644 loss_att 18.767849 loss_ctc 14.249113 loss_rnnt 12.810436 hw_loss 0.046821 history loss 7.132097 rank 3
2023-02-22 14:10:06,330 DEBUG CV Batch 19/1700 loss 8.157154 loss_att 8.441886 loss_ctc 12.264463 loss_rnnt 7.484410 hw_loss 0.127793 history loss 7.050902 rank 0
2023-02-22 14:10:06,481 DEBUG CV Batch 19/1700 loss 8.157154 loss_att 8.441886 loss_ctc 12.264463 loss_rnnt 7.484410 hw_loss 0.127793 history loss 7.050902 rank 7
2023-02-22 14:10:07,207 DEBUG CV Batch 19/1700 loss 8.157154 loss_att 8.441886 loss_ctc 12.264463 loss_rnnt 7.484410 hw_loss 0.127793 history loss 7.050902 rank 4
2023-02-22 14:10:07,794 DEBUG CV Batch 19/1700 loss 8.157154 loss_att 8.441886 loss_ctc 12.264463 loss_rnnt 7.484410 hw_loss 0.127793 history loss 7.050902 rank 5
2023-02-22 14:10:08,915 DEBUG CV Batch 19/1700 loss 8.157154 loss_att 8.441886 loss_ctc 12.264463 loss_rnnt 7.484410 hw_loss 0.127793 history loss 7.050902 rank 1
2023-02-22 14:10:10,253 DEBUG CV Batch 19/1700 loss 8.157154 loss_att 8.441886 loss_ctc 12.264463 loss_rnnt 7.484410 hw_loss 0.127793 history loss 7.050902 rank 6
2023-02-22 14:10:10,400 DEBUG CV Batch 19/1700 loss 8.157154 loss_att 8.441886 loss_ctc 12.264463 loss_rnnt 7.484410 hw_loss 0.127793 history loss 7.050902 rank 2
2023-02-22 14:10:15,119 DEBUG CV Batch 19/1700 loss 8.157154 loss_att 8.441886 loss_ctc 12.264463 loss_rnnt 7.484410 hw_loss 0.127793 history loss 7.050902 rank 3
2023-02-22 14:10:15,305 INFO Epoch 19 CV info cv_loss 7.025688008699377
2023-02-22 14:10:15,306 INFO Checkpoint: save to checkpoint exp/2_21_rnnt_bias_loss_2_class_1word_finetune/19.pt
2023-02-22 14:10:15,493 INFO Epoch 19 CV info cv_loss 7.025688009612528
2023-02-22 14:10:15,494 INFO Epoch 20 TRAIN info lr 0.0003871110182075366
2023-02-22 14:10:15,498 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 14:10:17,191 INFO Epoch 19 CV info cv_loss 7.025688008931972
2023-02-22 14:10:17,193 INFO Epoch 20 TRAIN info lr 0.0003871667203064686
2023-02-22 14:10:17,191 INFO Epoch 19 CV info cv_loss 7.025688009026733
2023-02-22 14:10:17,193 INFO Epoch 20 TRAIN info lr 0.00038719922430381713
2023-02-22 14:10:17,198 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 14:10:17,198 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 14:10:18,393 INFO Epoch 19 CV info cv_loss 7.025688008372021
2023-02-22 14:10:18,395 INFO Epoch 20 TRAIN info lr 0.0003871771671271769
2023-02-22 14:10:18,399 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 14:10:19,585 INFO Epoch 19 CV info cv_loss 7.025688008535699
2023-02-22 14:10:19,586 INFO Epoch 20 TRAIN info lr 0.0003871655596008107
2023-02-22 14:10:19,586 INFO Epoch 19 CV info cv_loss 7.025688008389251
2023-02-22 14:10:19,587 INFO Epoch 20 TRAIN info lr 0.00038710405713547494
2023-02-22 14:10:19,589 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 14:10:19,591 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 14:10:21,241 INFO Epoch 20 TRAIN info lr 0.0003871725239913507
2023-02-22 14:10:21,245 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 14:10:24,282 INFO Epoch 19 CV info cv_loss 7.0256880085873865
2023-02-22 14:10:24,282 INFO Epoch 20 TRAIN info lr 0.0003870692574071529
2023-02-22 14:10:24,286 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 14:11:36,809 DEBUG TRAIN Batch 20/0 loss 7.334327 loss_att 6.674298 loss_ctc 8.929240 loss_rnnt 7.164487 hw_loss 0.167232 lr 0.00038716 rank 6
2023-02-22 14:11:36,811 DEBUG TRAIN Batch 20/0 loss 11.103261 loss_att 11.551259 loss_ctc 15.776541 loss_rnnt 10.275160 hw_loss 0.216369 lr 0.00038720 rank 5
2023-02-22 14:11:36,812 DEBUG TRAIN Batch 20/0 loss 7.530020 loss_att 7.660890 loss_ctc 9.259147 loss_rnnt 7.180048 hw_loss 0.174839 lr 0.00038711 rank 7
2023-02-22 14:11:36,819 DEBUG TRAIN Batch 20/0 loss 6.409125 loss_att 6.481964 loss_ctc 7.961595 loss_rnnt 6.069628 hw_loss 0.221125 lr 0.00038717 rank 0
2023-02-22 14:11:36,819 DEBUG TRAIN Batch 20/0 loss 7.400215 loss_att 6.996557 loss_ctc 8.729000 loss_rnnt 7.168780 hw_loss 0.253117 lr 0.00038717 rank 4
2023-02-22 14:11:36,828 DEBUG TRAIN Batch 20/0 loss 6.638447 loss_att 7.088118 loss_ctc 8.005129 loss_rnnt 6.285960 hw_loss 0.150617 lr 0.00038710 rank 2
2023-02-22 14:11:36,834 DEBUG TRAIN Batch 20/0 loss 9.998230 loss_att 9.211842 loss_ctc 12.007072 loss_rnnt 9.811676 hw_loss 0.142474 lr 0.00038707 rank 3
2023-02-22 14:11:36,839 DEBUG TRAIN Batch 20/0 loss 7.535272 loss_att 7.768984 loss_ctc 10.074420 loss_rnnt 7.039429 hw_loss 0.207277 lr 0.00038718 rank 1
2023-02-22 14:12:51,568 DEBUG TRAIN Batch 20/100 loss 3.644942 loss_att 8.264750 loss_ctc 3.794239 loss_rnnt 2.649078 hw_loss 0.097492 lr 0.00038706 rank 0
2023-02-22 14:12:51,569 DEBUG TRAIN Batch 20/100 loss 6.021254 loss_att 11.416292 loss_ctc 7.188476 loss_rnnt 4.771806 hw_loss 0.027770 lr 0.00038699 rank 7
2023-02-22 14:12:51,571 DEBUG TRAIN Batch 20/100 loss 11.334199 loss_att 16.157909 loss_ctc 15.640307 loss_rnnt 9.763744 hw_loss 0.059183 lr 0.00038699 rank 2
2023-02-22 14:12:51,573 DEBUG TRAIN Batch 20/100 loss 9.645888 loss_att 13.919237 loss_ctc 15.079504 loss_rnnt 7.977107 hw_loss 0.168056 lr 0.00038708 rank 5
2023-02-22 14:12:51,573 DEBUG TRAIN Batch 20/100 loss 1.739338 loss_att 4.797449 loss_ctc 4.215669 loss_rnnt 0.737738 hw_loss 0.112126 lr 0.00038705 rank 6
2023-02-22 14:12:51,573 DEBUG TRAIN Batch 20/100 loss 8.785050 loss_att 8.289273 loss_ctc 18.963903 loss_rnnt 7.446111 hw_loss 0.151714 lr 0.00038695 rank 3
2023-02-22 14:12:51,573 DEBUG TRAIN Batch 20/100 loss 8.534180 loss_att 11.809372 loss_ctc 13.763637 loss_rnnt 7.099388 hw_loss 0.154672 lr 0.00038705 rank 4
2023-02-22 14:12:51,578 DEBUG TRAIN Batch 20/100 loss 4.558276 loss_att 9.380108 loss_ctc 9.787357 loss_rnnt 2.839036 hw_loss 0.108116 lr 0.00038706 rank 1
2023-02-22 14:14:05,278 DEBUG TRAIN Batch 20/200 loss 8.437366 loss_att 10.131926 loss_ctc 11.382006 loss_rnnt 7.633121 hw_loss 0.136340 lr 0.00038697 rank 5
2023-02-22 14:14:05,280 DEBUG TRAIN Batch 20/200 loss 8.026791 loss_att 12.794541 loss_ctc 11.605583 loss_rnnt 6.562879 hw_loss 0.062231 lr 0.00038693 rank 4
2023-02-22 14:14:05,287 DEBUG TRAIN Batch 20/200 loss 12.481982 loss_att 16.081322 loss_ctc 14.450378 loss_rnnt 11.433436 hw_loss 0.124174 lr 0.00038694 rank 0
2023-02-22 14:14:05,287 DEBUG TRAIN Batch 20/200 loss 4.961422 loss_att 8.720397 loss_ctc 9.192156 loss_rnnt 3.620554 hw_loss 0.046830 lr 0.00038693 rank 6
2023-02-22 14:14:05,289 DEBUG TRAIN Batch 20/200 loss 9.111663 loss_att 12.033134 loss_ctc 17.347326 loss_rnnt 7.412567 hw_loss 0.031338 lr 0.00038694 rank 1
2023-02-22 14:14:05,290 DEBUG TRAIN Batch 20/200 loss 7.430191 loss_att 10.147547 loss_ctc 11.041084 loss_rnnt 6.360536 hw_loss 0.083872 lr 0.00038687 rank 2
2023-02-22 14:14:05,290 DEBUG TRAIN Batch 20/200 loss 2.090595 loss_att 4.962351 loss_ctc 4.381382 loss_rnnt 1.173461 hw_loss 0.070019 lr 0.00038688 rank 7
2023-02-22 14:14:05,338 DEBUG TRAIN Batch 20/200 loss 4.634109 loss_att 7.794588 loss_ctc 8.971489 loss_rnnt 3.336175 hw_loss 0.164101 lr 0.00038684 rank 3
2023-02-22 14:15:20,932 DEBUG TRAIN Batch 20/300 loss 7.272215 loss_att 11.331512 loss_ctc 8.127450 loss_rnnt 6.261851 hw_loss 0.158388 lr 0.00038685 rank 5
2023-02-22 14:15:20,937 DEBUG TRAIN Batch 20/300 loss 9.962385 loss_att 12.152786 loss_ctc 14.950290 loss_rnnt 8.819468 hw_loss 0.074594 lr 0.00038682 rank 4
2023-02-22 14:15:20,937 DEBUG TRAIN Batch 20/300 loss 9.738109 loss_att 12.692810 loss_ctc 12.843739 loss_rnnt 8.638109 hw_loss 0.178077 lr 0.00038682 rank 0
2023-02-22 14:15:20,939 DEBUG TRAIN Batch 20/300 loss 14.638582 loss_att 21.166012 loss_ctc 25.970276 loss_rnnt 11.750618 hw_loss 0.134223 lr 0.00038672 rank 3
2023-02-22 14:15:20,940 DEBUG TRAIN Batch 20/300 loss 9.599247 loss_att 13.487615 loss_ctc 14.425016 loss_rnnt 8.168587 hw_loss 0.017907 lr 0.00038683 rank 1
2023-02-22 14:15:20,942 DEBUG TRAIN Batch 20/300 loss 7.223958 loss_att 10.791411 loss_ctc 10.206215 loss_rnnt 6.023507 hw_loss 0.167487 lr 0.00038676 rank 7
2023-02-22 14:15:20,942 DEBUG TRAIN Batch 20/300 loss 11.921206 loss_att 14.918588 loss_ctc 19.889828 loss_rnnt 10.205121 hw_loss 0.101486 lr 0.00038682 rank 6
2023-02-22 14:15:20,948 DEBUG TRAIN Batch 20/300 loss 12.864463 loss_att 13.988276 loss_ctc 17.427446 loss_rnnt 11.992800 hw_loss 0.072190 lr 0.00038676 rank 2
2023-02-22 14:16:37,506 DEBUG TRAIN Batch 20/400 loss 9.868781 loss_att 11.522093 loss_ctc 11.550674 loss_rnnt 9.239861 hw_loss 0.138759 lr 0.00038665 rank 7
2023-02-22 14:16:37,510 DEBUG TRAIN Batch 20/400 loss 15.756802 loss_att 17.050915 loss_ctc 26.025883 loss_rnnt 14.107700 hw_loss 0.039502 lr 0.00038670 rank 6
2023-02-22 14:16:37,512 DEBUG TRAIN Batch 20/400 loss 10.694679 loss_att 13.526784 loss_ctc 14.312473 loss_rnnt 9.606590 hw_loss 0.073678 lr 0.00038673 rank 5
2023-02-22 14:16:37,513 DEBUG TRAIN Batch 20/400 loss 5.409836 loss_att 6.923939 loss_ctc 8.225736 loss_rnnt 4.668351 hw_loss 0.118520 lr 0.00038670 rank 4
2023-02-22 14:16:37,513 DEBUG TRAIN Batch 20/400 loss 18.560133 loss_att 25.353157 loss_ctc 25.203238 loss_rnnt 16.271244 hw_loss 0.083508 lr 0.00038671 rank 1
2023-02-22 14:16:37,514 DEBUG TRAIN Batch 20/400 loss 5.862748 loss_att 9.076059 loss_ctc 8.878785 loss_rnnt 4.777397 hw_loss 0.076032 lr 0.00038671 rank 0
2023-02-22 14:16:37,519 DEBUG TRAIN Batch 20/400 loss 8.658648 loss_att 10.155555 loss_ctc 11.294928 loss_rnnt 7.936472 hw_loss 0.133670 lr 0.00038664 rank 2
2023-02-22 14:16:37,519 DEBUG TRAIN Batch 20/400 loss 10.677236 loss_att 13.293524 loss_ctc 14.564525 loss_rnnt 9.622345 hw_loss 0.024988 lr 0.00038661 rank 3
2023-02-22 14:17:53,004 DEBUG TRAIN Batch 20/500 loss 11.377794 loss_att 15.576813 loss_ctc 21.363831 loss_rnnt 9.192416 hw_loss 0.026443 lr 0.00038653 rank 7
2023-02-22 14:17:53,003 DEBUG TRAIN Batch 20/500 loss 6.075435 loss_att 6.233918 loss_ctc 9.885855 loss_rnnt 5.493886 hw_loss 0.078370 lr 0.00038649 rank 3
2023-02-22 14:17:53,005 DEBUG TRAIN Batch 20/500 loss 6.852726 loss_att 8.255709 loss_ctc 7.647646 loss_rnnt 6.349945 hw_loss 0.217864 lr 0.00038659 rank 0
2023-02-22 14:17:53,007 DEBUG TRAIN Batch 20/500 loss 8.896338 loss_att 9.766588 loss_ctc 11.142876 loss_rnnt 8.384242 hw_loss 0.072206 lr 0.00038662 rank 5
2023-02-22 14:17:53,011 DEBUG TRAIN Batch 20/500 loss 11.245515 loss_att 14.814869 loss_ctc 14.424814 loss_rnnt 10.076649 hw_loss 0.058290 lr 0.00038659 rank 4
2023-02-22 14:17:53,012 DEBUG TRAIN Batch 20/500 loss 14.590792 loss_att 15.419685 loss_ctc 19.535954 loss_rnnt 13.756547 hw_loss 0.017083 lr 0.00038659 rank 6
2023-02-22 14:17:53,012 DEBUG TRAIN Batch 20/500 loss 12.558735 loss_att 16.123428 loss_ctc 16.545012 loss_rnnt 11.247705 hw_loss 0.124852 lr 0.00038660 rank 1
2023-02-22 14:17:53,016 DEBUG TRAIN Batch 20/500 loss 5.121350 loss_att 8.006530 loss_ctc 8.465214 loss_rnnt 4.026953 hw_loss 0.134086 lr 0.00038652 rank 2
2023-02-22 14:19:08,422 DEBUG TRAIN Batch 20/600 loss 9.185597 loss_att 11.235992 loss_ctc 13.305481 loss_rnnt 8.187323 hw_loss 0.072896 lr 0.00038650 rank 5
2023-02-22 14:19:08,423 DEBUG TRAIN Batch 20/600 loss 8.726103 loss_att 11.778676 loss_ctc 12.111196 loss_rnnt 7.613997 hw_loss 0.094208 lr 0.00038642 rank 7
2023-02-22 14:19:08,426 DEBUG TRAIN Batch 20/600 loss 8.988302 loss_att 8.388099 loss_ctc 10.143892 loss_rnnt 8.895318 hw_loss 0.110524 lr 0.00038637 rank 3
2023-02-22 14:19:08,426 DEBUG TRAIN Batch 20/600 loss 6.039048 loss_att 7.456881 loss_ctc 7.553728 loss_rnnt 5.514355 hw_loss 0.073441 lr 0.00038648 rank 0
2023-02-22 14:19:08,427 DEBUG TRAIN Batch 20/600 loss 10.655433 loss_att 9.626750 loss_ctc 13.558069 loss_rnnt 10.384481 hw_loss 0.168131 lr 0.00038647 rank 4
2023-02-22 14:19:08,428 DEBUG TRAIN Batch 20/600 loss 11.249278 loss_att 12.295743 loss_ctc 14.584534 loss_rnnt 10.539637 hw_loss 0.104340 lr 0.00038647 rank 6
2023-02-22 14:19:08,430 DEBUG TRAIN Batch 20/600 loss 6.181132 loss_att 9.377060 loss_ctc 8.678866 loss_rnnt 5.157637 hw_loss 0.096148 lr 0.00038648 rank 1
2023-02-22 14:19:08,430 DEBUG TRAIN Batch 20/600 loss 12.261939 loss_att 13.392658 loss_ctc 17.140259 loss_rnnt 11.325868 hw_loss 0.111535 lr 0.00038641 rank 2
2023-02-22 14:20:26,284 DEBUG TRAIN Batch 20/700 loss 12.225202 loss_att 16.900274 loss_ctc 20.019932 loss_rnnt 10.229592 hw_loss 0.039932 lr 0.00038639 rank 5
2023-02-22 14:20:26,285 DEBUG TRAIN Batch 20/700 loss 4.439568 loss_att 10.099201 loss_ctc 6.873685 loss_rnnt 2.910076 hw_loss 0.136906 lr 0.00038635 rank 6
2023-02-22 14:20:26,288 DEBUG TRAIN Batch 20/700 loss 2.301330 loss_att 4.742093 loss_ctc 5.438126 loss_rnnt 1.380000 hw_loss 0.028010 lr 0.00038636 rank 4
2023-02-22 14:20:26,289 DEBUG TRAIN Batch 20/700 loss 14.149401 loss_att 17.812487 loss_ctc 21.449333 loss_rnnt 12.392879 hw_loss 0.094835 lr 0.00038636 rank 0
2023-02-22 14:20:26,289 DEBUG TRAIN Batch 20/700 loss 5.541643 loss_att 9.454120 loss_ctc 7.588004 loss_rnnt 4.438134 hw_loss 0.090311 lr 0.00038630 rank 7
2023-02-22 14:20:26,290 DEBUG TRAIN Batch 20/700 loss 3.203056 loss_att 5.513962 loss_ctc 3.044318 loss_rnnt 2.750184 hw_loss 0.022229 lr 0.00038626 rank 3
2023-02-22 14:20:26,292 DEBUG TRAIN Batch 20/700 loss 6.640600 loss_att 10.489765 loss_ctc 7.642882 loss_rnnt 5.667896 hw_loss 0.129812 lr 0.00038629 rank 2
2023-02-22 14:20:26,297 DEBUG TRAIN Batch 20/700 loss 7.924602 loss_att 12.078617 loss_ctc 14.002971 loss_rnnt 6.257026 hw_loss 0.049358 lr 0.00038637 rank 1
2023-02-22 14:21:41,084 DEBUG TRAIN Batch 20/800 loss 12.022966 loss_att 14.097270 loss_ctc 15.947531 loss_rnnt 11.045208 hw_loss 0.074290 lr 0.00038624 rank 4
2023-02-22 14:21:41,085 DEBUG TRAIN Batch 20/800 loss 8.348672 loss_att 11.341792 loss_ctc 11.930527 loss_rnnt 7.264361 hw_loss 0.015199 lr 0.00038619 rank 7
2023-02-22 14:21:41,087 DEBUG TRAIN Batch 20/800 loss 7.466730 loss_att 9.760260 loss_ctc 12.684436 loss_rnnt 6.312291 hw_loss 0.000072 lr 0.00038625 rank 0
2023-02-22 14:21:41,088 DEBUG TRAIN Batch 20/800 loss 9.469188 loss_att 12.990707 loss_ctc 11.757915 loss_rnnt 8.416322 hw_loss 0.081370 lr 0.00038614 rank 3
2023-02-22 14:21:41,087 DEBUG TRAIN Batch 20/800 loss 5.653244 loss_att 10.842784 loss_ctc 11.495143 loss_rnnt 3.756646 hw_loss 0.149569 lr 0.00038627 rank 5
2023-02-22 14:21:41,090 DEBUG TRAIN Batch 20/800 loss 12.152470 loss_att 14.901455 loss_ctc 12.173407 loss_rnnt 11.564619 hw_loss 0.066119 lr 0.00038625 rank 1
2023-02-22 14:21:41,090 DEBUG TRAIN Batch 20/800 loss 9.573294 loss_att 12.893482 loss_ctc 14.401100 loss_rnnt 8.237368 hw_loss 0.052838 lr 0.00038624 rank 6
2023-02-22 14:21:41,095 DEBUG TRAIN Batch 20/800 loss 12.824477 loss_att 16.176615 loss_ctc 22.045034 loss_rnnt 10.895560 hw_loss 0.054528 lr 0.00038618 rank 2
2023-02-22 14:22:55,164 DEBUG TRAIN Batch 20/900 loss 11.158942 loss_att 13.184302 loss_ctc 12.028548 loss_rnnt 10.622623 hw_loss 0.028683 lr 0.00038607 rank 7
2023-02-22 14:22:55,168 DEBUG TRAIN Batch 20/900 loss 9.355951 loss_att 12.024463 loss_ctc 15.467699 loss_rnnt 7.980954 hw_loss 0.049490 lr 0.00038614 rank 1
2023-02-22 14:22:55,168 DEBUG TRAIN Batch 20/900 loss 7.847679 loss_att 8.973331 loss_ctc 9.831751 loss_rnnt 7.291673 hw_loss 0.124372 lr 0.00038613 rank 0
2023-02-22 14:22:55,169 DEBUG TRAIN Batch 20/900 loss 5.892672 loss_att 10.059618 loss_ctc 10.474003 loss_rnnt 4.367562 hw_loss 0.151643 lr 0.00038613 rank 4
2023-02-22 14:22:55,170 DEBUG TRAIN Batch 20/900 loss 9.788123 loss_att 15.369284 loss_ctc 14.192797 loss_rnnt 8.016540 hw_loss 0.127617 lr 0.00038616 rank 5
2023-02-22 14:22:55,172 DEBUG TRAIN Batch 20/900 loss 13.760221 loss_att 13.927061 loss_ctc 13.157640 loss_rnnt 13.776950 hw_loss 0.056716 lr 0.00038612 rank 6
2023-02-22 14:22:55,172 DEBUG TRAIN Batch 20/900 loss 3.688428 loss_att 7.120751 loss_ctc 4.762358 loss_rnnt 2.807828 hw_loss 0.095520 lr 0.00038603 rank 3
2023-02-22 14:22:55,223 DEBUG TRAIN Batch 20/900 loss 4.353316 loss_att 10.814801 loss_ctc 6.812653 loss_rnnt 2.680639 hw_loss 0.098379 lr 0.00038606 rank 2
2023-02-22 14:24:11,329 DEBUG TRAIN Batch 20/1000 loss 22.550474 loss_att 26.789278 loss_ctc 33.275570 loss_rnnt 20.249195 hw_loss 0.044068 lr 0.00038602 rank 0
2023-02-22 14:24:11,334 DEBUG TRAIN Batch 20/1000 loss 9.086402 loss_att 12.828074 loss_ctc 12.616623 loss_rnnt 7.799726 hw_loss 0.126835 lr 0.00038601 rank 4
2023-02-22 14:24:11,336 DEBUG TRAIN Batch 20/1000 loss 11.743797 loss_att 14.032327 loss_ctc 17.589027 loss_rnnt 10.416523 hw_loss 0.169134 lr 0.00038604 rank 5
2023-02-22 14:24:11,340 DEBUG TRAIN Batch 20/1000 loss 7.124134 loss_att 9.634466 loss_ctc 10.127470 loss_rnnt 6.119082 hw_loss 0.192264 lr 0.00038595 rank 7
2023-02-22 14:24:11,340 DEBUG TRAIN Batch 20/1000 loss 16.570650 loss_att 20.106976 loss_ctc 23.860472 loss_rnnt 14.848178 hw_loss 0.081056 lr 0.00038591 rank 3
2023-02-22 14:24:11,340 DEBUG TRAIN Batch 20/1000 loss 7.328125 loss_att 9.988914 loss_ctc 9.308672 loss_rnnt 6.493911 hw_loss 0.071216 lr 0.00038601 rank 6
2023-02-22 14:24:11,346 DEBUG TRAIN Batch 20/1000 loss 1.755513 loss_att 5.108054 loss_ctc 2.923170 loss_rnnt 0.865256 hw_loss 0.120115 lr 0.00038602 rank 1
2023-02-22 14:24:11,352 DEBUG TRAIN Batch 20/1000 loss 5.263885 loss_att 8.253072 loss_ctc 6.142097 loss_rnnt 4.454804 hw_loss 0.176529 lr 0.00038595 rank 2
2023-02-22 14:25:29,784 DEBUG TRAIN Batch 20/1100 loss 11.158224 loss_att 13.969599 loss_ctc 13.214921 loss_rnnt 10.308170 hw_loss 0.025411 lr 0.00038584 rank 7
2023-02-22 14:25:29,786 DEBUG TRAIN Batch 20/1100 loss 14.265224 loss_att 13.146055 loss_ctc 18.677771 loss_rnnt 13.879851 hw_loss 0.039128 lr 0.00038590 rank 0
2023-02-22 14:25:29,786 DEBUG TRAIN Batch 20/1100 loss 6.065667 loss_att 8.633942 loss_ctc 11.199153 loss_rnnt 4.822393 hw_loss 0.084664 lr 0.00038593 rank 5
2023-02-22 14:25:29,787 DEBUG TRAIN Batch 20/1100 loss 3.012610 loss_att 5.218698 loss_ctc 5.732762 loss_rnnt 2.187460 hw_loss 0.039836 lr 0.00038590 rank 4
2023-02-22 14:25:29,788 DEBUG TRAIN Batch 20/1100 loss 15.504560 loss_att 18.852644 loss_ctc 22.481480 loss_rnnt 13.839302 hw_loss 0.122600 lr 0.00038583 rank 2
2023-02-22 14:25:29,788 DEBUG TRAIN Batch 20/1100 loss 5.445411 loss_att 7.430986 loss_ctc 7.050444 loss_rnnt 4.823370 hw_loss 0.020476 lr 0.00038591 rank 1
2023-02-22 14:25:29,790 DEBUG TRAIN Batch 20/1100 loss 5.451072 loss_att 8.210035 loss_ctc 8.059156 loss_rnnt 4.503679 hw_loss 0.089729 lr 0.00038580 rank 3
2023-02-22 14:25:29,834 DEBUG TRAIN Batch 20/1100 loss 8.077552 loss_att 10.197857 loss_ctc 14.519187 loss_rnnt 6.757412 hw_loss 0.069741 lr 0.00038589 rank 6
2023-02-22 14:26:44,737 DEBUG TRAIN Batch 20/1200 loss 6.798064 loss_att 10.488909 loss_ctc 9.849942 loss_rnnt 5.617938 hw_loss 0.065701 lr 0.00038579 rank 0
2023-02-22 14:26:44,738 DEBUG TRAIN Batch 20/1200 loss 5.651599 loss_att 8.110069 loss_ctc 8.044978 loss_rnnt 4.753353 hw_loss 0.163940 lr 0.00038578 rank 6
2023-02-22 14:26:44,741 DEBUG TRAIN Batch 20/1200 loss 5.878522 loss_att 6.155355 loss_ctc 8.937711 loss_rnnt 5.363146 hw_loss 0.097720 lr 0.00038578 rank 4
2023-02-22 14:26:44,742 DEBUG TRAIN Batch 20/1200 loss 7.343685 loss_att 8.952858 loss_ctc 10.329518 loss_rnnt 6.554730 hw_loss 0.129390 lr 0.00038579 rank 1
2023-02-22 14:26:44,744 DEBUG TRAIN Batch 20/1200 loss 2.170029 loss_att 4.850189 loss_ctc 3.129094 loss_rnnt 1.415454 hw_loss 0.170002 lr 0.00038572 rank 2
2023-02-22 14:26:44,744 DEBUG TRAIN Batch 20/1200 loss 12.859556 loss_att 15.472515 loss_ctc 16.957411 loss_rnnt 11.745256 hw_loss 0.084989 lr 0.00038573 rank 7
2023-02-22 14:26:44,746 DEBUG TRAIN Batch 20/1200 loss 7.830714 loss_att 9.852641 loss_ctc 10.153987 loss_rnnt 7.051522 hw_loss 0.121942 lr 0.00038581 rank 5
2023-02-22 14:26:44,749 DEBUG TRAIN Batch 20/1200 loss 16.953098 loss_att 17.289543 loss_ctc 25.421543 loss_rnnt 15.702143 hw_loss 0.102263 lr 0.00038568 rank 3
2023-02-22 14:27:59,181 DEBUG TRAIN Batch 20/1300 loss 2.968601 loss_att 4.126993 loss_ctc 3.646268 loss_rnnt 2.620632 hw_loss 0.048628 lr 0.00038561 rank 7
2023-02-22 14:27:59,189 DEBUG TRAIN Batch 20/1300 loss 13.378129 loss_att 17.142994 loss_ctc 20.358498 loss_rnnt 11.686740 hw_loss 0.014438 lr 0.00038570 rank 5
2023-02-22 14:27:59,190 DEBUG TRAIN Batch 20/1300 loss 4.561824 loss_att 9.379975 loss_ctc 7.431146 loss_rnnt 3.196463 hw_loss 0.035915 lr 0.00038567 rank 0
2023-02-22 14:27:59,191 DEBUG TRAIN Batch 20/1300 loss 9.411872 loss_att 13.989046 loss_ctc 17.975540 loss_rnnt 7.269544 hw_loss 0.159508 lr 0.00038568 rank 1
2023-02-22 14:27:59,195 DEBUG TRAIN Batch 20/1300 loss 7.369298 loss_att 14.157877 loss_ctc 13.000445 loss_rnnt 5.249845 hw_loss 0.020469 lr 0.00038557 rank 3
2023-02-22 14:27:59,196 DEBUG TRAIN Batch 20/1300 loss 10.919425 loss_att 12.434256 loss_ctc 13.962074 loss_rnnt 10.177032 hw_loss 0.063262 lr 0.00038567 rank 4
2023-02-22 14:27:59,197 DEBUG TRAIN Batch 20/1300 loss 10.366606 loss_att 10.280276 loss_ctc 12.233962 loss_rnnt 10.038043 hw_loss 0.181590 lr 0.00038566 rank 6
2023-02-22 14:27:59,199 DEBUG TRAIN Batch 20/1300 loss 4.736463 loss_att 11.148708 loss_ctc 7.902068 loss_rnnt 3.024577 hw_loss 0.013791 lr 0.00038560 rank 2
2023-02-22 14:29:15,980 DEBUG TRAIN Batch 20/1400 loss 6.793490 loss_att 10.344664 loss_ctc 11.371978 loss_rnnt 5.379163 hw_loss 0.175551 lr 0.00038555 rank 4
2023-02-22 14:29:15,982 DEBUG TRAIN Batch 20/1400 loss 9.004001 loss_att 9.126246 loss_ctc 11.201628 loss_rnnt 8.657469 hw_loss 0.054499 lr 0.00038556 rank 0
2023-02-22 14:29:15,981 DEBUG TRAIN Batch 20/1400 loss 8.045372 loss_att 10.515102 loss_ctc 14.849236 loss_rnnt 6.590046 hw_loss 0.101622 lr 0.00038550 rank 7
2023-02-22 14:29:15,988 DEBUG TRAIN Batch 20/1400 loss 7.984951 loss_att 12.202326 loss_ctc 10.502676 loss_rnnt 6.739385 hw_loss 0.124488 lr 0.00038549 rank 2
2023-02-22 14:29:15,990 DEBUG TRAIN Batch 20/1400 loss 8.016562 loss_att 11.299715 loss_ctc 13.643656 loss_rnnt 6.594868 hw_loss 0.027719 lr 0.00038558 rank 5
2023-02-22 14:29:15,990 DEBUG TRAIN Batch 20/1400 loss 1.689411 loss_att 4.560419 loss_ctc 2.531403 loss_rnnt 0.914558 hw_loss 0.165725 lr 0.00038556 rank 1
2023-02-22 14:29:15,995 DEBUG TRAIN Batch 20/1400 loss 5.958143 loss_att 11.909346 loss_ctc 9.162522 loss_rnnt 4.288927 hw_loss 0.096985 lr 0.00038545 rank 3
2023-02-22 14:29:16,035 DEBUG TRAIN Batch 20/1400 loss 19.085289 loss_att 18.933899 loss_ctc 25.660717 loss_rnnt 18.150295 hw_loss 0.166024 lr 0.00038555 rank 6
2023-02-22 14:30:31,140 DEBUG TRAIN Batch 20/1500 loss 11.999474 loss_att 18.009481 loss_ctc 22.066639 loss_rnnt 9.442680 hw_loss 0.023442 lr 0.00038544 rank 4
2023-02-22 14:30:31,140 DEBUG TRAIN Batch 20/1500 loss 7.516060 loss_att 9.806477 loss_ctc 8.644533 loss_rnnt 6.861075 hw_loss 0.087072 lr 0.00038547 rank 5
2023-02-22 14:30:31,144 DEBUG TRAIN Batch 20/1500 loss 6.540551 loss_att 10.397530 loss_ctc 8.968960 loss_rnnt 5.422700 hw_loss 0.042501 lr 0.00038534 rank 3
2023-02-22 14:30:31,143 DEBUG TRAIN Batch 20/1500 loss 3.178027 loss_att 5.971373 loss_ctc 4.992907 loss_rnnt 2.301161 hw_loss 0.142899 lr 0.00038544 rank 0
2023-02-22 14:30:31,145 DEBUG TRAIN Batch 20/1500 loss 8.372622 loss_att 13.411616 loss_ctc 14.156851 loss_rnnt 6.593433 hw_loss 0.000300 lr 0.00038537 rank 2
2023-02-22 14:30:31,146 DEBUG TRAIN Batch 20/1500 loss 8.393361 loss_att 11.024864 loss_ctc 17.884338 loss_rnnt 6.530502 hw_loss 0.133303 lr 0.00038545 rank 1
2023-02-22 14:30:31,148 DEBUG TRAIN Batch 20/1500 loss 6.034975 loss_att 8.223778 loss_ctc 6.984441 loss_rnnt 5.427683 hw_loss 0.080506 lr 0.00038538 rank 7
2023-02-22 14:30:31,195 DEBUG TRAIN Batch 20/1500 loss 19.419029 loss_att 25.162821 loss_ctc 27.660576 loss_rnnt 17.116013 hw_loss 0.103844 lr 0.00038544 rank 6
2023-02-22 14:31:46,031 DEBUG TRAIN Batch 20/1600 loss 5.770066 loss_att 7.572838 loss_ctc 8.641885 loss_rnnt 4.980824 hw_loss 0.085834 lr 0.00038532 rank 4
2023-02-22 14:31:46,032 DEBUG TRAIN Batch 20/1600 loss 5.075311 loss_att 7.928543 loss_ctc 8.070769 loss_rnnt 4.097943 hw_loss 0.013739 lr 0.00038535 rank 5
2023-02-22 14:31:46,035 DEBUG TRAIN Batch 20/1600 loss 6.032466 loss_att 10.178318 loss_ctc 10.216849 loss_rnnt 4.618149 hw_loss 0.051053 lr 0.00038532 rank 6
2023-02-22 14:31:46,036 DEBUG TRAIN Batch 20/1600 loss 12.753804 loss_att 17.364813 loss_ctc 17.835350 loss_rnnt 11.151730 hw_loss 0.004374 lr 0.00038527 rank 7
2023-02-22 14:31:46,043 DEBUG TRAIN Batch 20/1600 loss 11.555674 loss_att 14.764061 loss_ctc 14.556316 loss_rnnt 10.449209 hw_loss 0.121316 lr 0.00038533 rank 1
2023-02-22 14:31:46,045 DEBUG TRAIN Batch 20/1600 loss 4.931038 loss_att 7.197674 loss_ctc 6.509678 loss_rnnt 4.242421 hw_loss 0.046508 lr 0.00038523 rank 3
2023-02-22 14:31:46,046 DEBUG TRAIN Batch 20/1600 loss 8.343364 loss_att 10.546987 loss_ctc 10.092727 loss_rnnt 7.633470 hw_loss 0.067352 lr 0.00038526 rank 2
2023-02-22 14:31:46,046 DEBUG TRAIN Batch 20/1600 loss 5.405460 loss_att 8.803461 loss_ctc 9.721530 loss_rnnt 4.139723 hw_loss 0.019989 lr 0.00038533 rank 0
2023-02-22 14:33:02,145 DEBUG TRAIN Batch 20/1700 loss 11.495027 loss_att 12.816146 loss_ctc 17.020819 loss_rnnt 10.424591 hw_loss 0.130198 lr 0.00038524 rank 5
2023-02-22 14:33:02,146 DEBUG TRAIN Batch 20/1700 loss 12.583444 loss_att 17.510956 loss_ctc 18.948303 loss_rnnt 10.703525 hw_loss 0.085816 lr 0.00038521 rank 4
2023-02-22 14:33:02,148 DEBUG TRAIN Batch 20/1700 loss 8.470597 loss_att 12.989351 loss_ctc 15.545662 loss_rnnt 6.592663 hw_loss 0.057829 lr 0.00038521 rank 0
2023-02-22 14:33:02,150 DEBUG TRAIN Batch 20/1700 loss 12.578074 loss_att 14.779131 loss_ctc 14.824173 loss_rnnt 11.785421 hw_loss 0.099303 lr 0.00038522 rank 1
2023-02-22 14:33:02,151 DEBUG TRAIN Batch 20/1700 loss 5.626462 loss_att 9.719364 loss_ctc 9.395670 loss_rnnt 4.288301 hw_loss 0.031911 lr 0.00038515 rank 7
2023-02-22 14:33:02,154 DEBUG TRAIN Batch 20/1700 loss 10.182429 loss_att 14.093063 loss_ctc 12.930912 loss_rnnt 8.997310 hw_loss 0.068493 lr 0.00038515 rank 2
2023-02-22 14:33:02,155 DEBUG TRAIN Batch 20/1700 loss 6.268480 loss_att 9.121349 loss_ctc 8.359020 loss_rnnt 5.342679 hw_loss 0.143414 lr 0.00038521 rank 6
2023-02-22 14:33:02,201 DEBUG TRAIN Batch 20/1700 loss 4.945156 loss_att 8.665290 loss_ctc 9.965248 loss_rnnt 3.501405 hw_loss 0.056961 lr 0.00038511 rank 3
2023-02-22 14:34:20,344 DEBUG TRAIN Batch 20/1800 loss 7.891778 loss_att 9.132748 loss_ctc 10.067065 loss_rnnt 7.309770 hw_loss 0.082079 lr 0.00038509 rank 4
2023-02-22 14:34:20,346 DEBUG TRAIN Batch 20/1800 loss 5.160696 loss_att 6.802018 loss_ctc 5.887433 loss_rnnt 4.663652 hw_loss 0.134778 lr 0.00038513 rank 5
2023-02-22 14:34:20,346 DEBUG TRAIN Batch 20/1800 loss 2.468186 loss_att 4.802273 loss_ctc 3.345568 loss_rnnt 1.883780 hw_loss 0.001133 lr 0.00038510 rank 0
2023-02-22 14:34:20,350 DEBUG TRAIN Batch 20/1800 loss 14.189446 loss_att 17.156506 loss_ctc 22.218401 loss_rnnt 12.481314 hw_loss 0.082864 lr 0.00038504 rank 7
2023-02-22 14:34:20,353 DEBUG TRAIN Batch 20/1800 loss 5.899984 loss_att 7.749463 loss_ctc 8.288417 loss_rnnt 5.174840 hw_loss 0.068982 lr 0.00038503 rank 2
2023-02-22 14:34:20,354 DEBUG TRAIN Batch 20/1800 loss 9.988441 loss_att 13.003708 loss_ctc 14.408587 loss_rnnt 8.737729 hw_loss 0.109322 lr 0.00038510 rank 1
2023-02-22 14:34:20,355 DEBUG TRAIN Batch 20/1800 loss 8.057054 loss_att 11.627703 loss_ctc 12.102055 loss_rnnt 6.762281 hw_loss 0.077453 lr 0.00038500 rank 3
2023-02-22 14:34:20,400 DEBUG TRAIN Batch 20/1800 loss 6.432171 loss_att 8.100546 loss_ctc 9.664775 loss_rnnt 5.629297 hw_loss 0.071599 lr 0.00038509 rank 6
2023-02-22 14:35:36,304 DEBUG TRAIN Batch 20/1900 loss 8.293888 loss_att 11.644389 loss_ctc 11.605881 loss_rnnt 7.097586 hw_loss 0.158630 lr 0.00038498 rank 0
2023-02-22 14:35:36,305 DEBUG TRAIN Batch 20/1900 loss 5.663155 loss_att 9.144342 loss_ctc 9.398486 loss_rnnt 4.404668 hw_loss 0.120386 lr 0.00038492 rank 7
2023-02-22 14:35:36,304 DEBUG TRAIN Batch 20/1900 loss 9.680121 loss_att 13.260746 loss_ctc 14.154281 loss_rnnt 8.319029 hw_loss 0.090774 lr 0.00038501 rank 5
2023-02-22 14:35:36,305 DEBUG TRAIN Batch 20/1900 loss 9.462104 loss_att 9.394791 loss_ctc 11.813780 loss_rnnt 9.128590 hw_loss 0.062662 lr 0.00038498 rank 6
2023-02-22 14:35:36,306 DEBUG TRAIN Batch 20/1900 loss 5.095494 loss_att 10.635553 loss_ctc 8.415434 loss_rnnt 3.467868 hw_loss 0.144290 lr 0.00038498 rank 4
2023-02-22 14:35:36,307 DEBUG TRAIN Batch 20/1900 loss 13.672568 loss_att 13.900368 loss_ctc 17.149900 loss_rnnt 13.058640 hw_loss 0.196358 lr 0.00038488 rank 3
2023-02-22 14:35:36,309 DEBUG TRAIN Batch 20/1900 loss 11.693555 loss_att 16.245148 loss_ctc 18.110723 loss_rnnt 9.921950 hw_loss 0.010619 lr 0.00038499 rank 1
2023-02-22 14:35:36,309 DEBUG TRAIN Batch 20/1900 loss 5.647807 loss_att 8.699377 loss_ctc 8.277368 loss_rnnt 4.643885 hw_loss 0.080624 lr 0.00038492 rank 2
2023-02-22 14:36:52,136 DEBUG TRAIN Batch 20/2000 loss 1.592946 loss_att 4.352278 loss_ctc 3.989068 loss_rnnt 0.698677 hw_loss 0.042974 lr 0.00038490 rank 5
2023-02-22 14:36:52,139 DEBUG TRAIN Batch 20/2000 loss 7.306745 loss_att 11.483433 loss_ctc 14.469855 loss_rnnt 5.504541 hw_loss 0.022095 lr 0.00038480 rank 2
2023-02-22 14:36:52,142 DEBUG TRAIN Batch 20/2000 loss 14.382808 loss_att 16.723598 loss_ctc 20.381004 loss_rnnt 13.064409 hw_loss 0.094650 lr 0.00038486 rank 4
2023-02-22 14:36:52,143 DEBUG TRAIN Batch 20/2000 loss 11.211928 loss_att 12.879339 loss_ctc 12.039641 loss_rnnt 10.677462 hw_loss 0.169917 lr 0.00038487 rank 0
2023-02-22 14:36:52,144 DEBUG TRAIN Batch 20/2000 loss 6.472494 loss_att 10.079575 loss_ctc 9.033911 loss_rnnt 5.409284 hw_loss 0.000510 lr 0.00038481 rank 7
2023-02-22 14:36:52,144 DEBUG TRAIN Batch 20/2000 loss 5.169312 loss_att 8.636896 loss_ctc 8.082365 loss_rnnt 4.054166 hw_loss 0.062290 lr 0.00038488 rank 1
2023-02-22 14:36:52,145 DEBUG TRAIN Batch 20/2000 loss 1.726444 loss_att 4.245800 loss_ctc 1.934766 loss_rnnt 1.149402 hw_loss 0.085114 lr 0.00038486 rank 6
2023-02-22 14:36:52,145 DEBUG TRAIN Batch 20/2000 loss 3.676402 loss_att 8.236847 loss_ctc 8.699233 loss_rnnt 2.014129 hw_loss 0.150887 lr 0.00038477 rank 3
2023-02-22 14:38:08,502 DEBUG TRAIN Batch 20/2100 loss 8.536824 loss_att 12.403525 loss_ctc 11.576509 loss_rnnt 7.240461 hw_loss 0.220747 lr 0.00038475 rank 4
2023-02-22 14:38:08,504 DEBUG TRAIN Batch 20/2100 loss 7.783066 loss_att 10.652775 loss_ctc 13.910739 loss_rnnt 6.386959 hw_loss 0.009642 lr 0.00038478 rank 5
2023-02-22 14:38:08,505 DEBUG TRAIN Batch 20/2100 loss 17.623644 loss_att 22.060417 loss_ctc 22.013189 loss_rnnt 16.097565 hw_loss 0.100221 lr 0.00038470 rank 7
2023-02-22 14:38:08,510 DEBUG TRAIN Batch 20/2100 loss 12.076764 loss_att 14.739252 loss_ctc 25.463629 loss_rnnt 9.678576 hw_loss 0.151454 lr 0.00038475 rank 6
2023-02-22 14:38:08,511 DEBUG TRAIN Batch 20/2100 loss 9.776452 loss_att 11.179752 loss_ctc 13.743801 loss_rnnt 8.941606 hw_loss 0.047261 lr 0.00038476 rank 0
2023-02-22 14:38:08,513 DEBUG TRAIN Batch 20/2100 loss 13.819204 loss_att 16.588898 loss_ctc 19.804840 loss_rnnt 12.415937 hw_loss 0.096082 lr 0.00038466 rank 3
2023-02-22 14:38:08,558 DEBUG TRAIN Batch 20/2100 loss 8.251714 loss_att 9.576611 loss_ctc 11.789036 loss_rnnt 7.470745 hw_loss 0.083149 lr 0.00038476 rank 1
2023-02-22 14:38:08,582 DEBUG TRAIN Batch 20/2100 loss 5.959135 loss_att 9.013907 loss_ctc 9.982595 loss_rnnt 4.772145 hw_loss 0.074201 lr 0.00038469 rank 2
2023-02-22 14:39:24,948 DEBUG TRAIN Batch 20/2200 loss 5.718125 loss_att 9.658433 loss_ctc 9.675522 loss_rnnt 4.348472 hw_loss 0.101136 lr 0.00038467 rank 5
2023-02-22 14:39:24,947 DEBUG TRAIN Batch 20/2200 loss 4.272075 loss_att 7.766166 loss_ctc 4.369716 loss_rnnt 3.529720 hw_loss 0.057222 lr 0.00038464 rank 4
2023-02-22 14:39:24,949 DEBUG TRAIN Batch 20/2200 loss 6.690566 loss_att 10.475154 loss_ctc 8.844401 loss_rnnt 5.629223 hw_loss 0.032339 lr 0.00038465 rank 1
2023-02-22 14:39:24,951 DEBUG TRAIN Batch 20/2200 loss 13.007141 loss_att 16.730873 loss_ctc 14.578108 loss_rnnt 12.033809 hw_loss 0.035858 lr 0.00038458 rank 7
2023-02-22 14:39:24,953 DEBUG TRAIN Batch 20/2200 loss 7.629139 loss_att 10.762525 loss_ctc 10.836875 loss_rnnt 6.522687 hw_loss 0.097642 lr 0.00038464 rank 0
2023-02-22 14:39:24,957 DEBUG TRAIN Batch 20/2200 loss 13.472469 loss_att 15.824268 loss_ctc 16.323513 loss_rnnt 12.601843 hw_loss 0.037741 lr 0.00038464 rank 6
2023-02-22 14:39:24,958 DEBUG TRAIN Batch 20/2200 loss 2.808556 loss_att 4.929521 loss_ctc 4.065621 loss_rnnt 2.192287 hw_loss 0.045875 lr 0.00038458 rank 2
2023-02-22 14:39:25,004 DEBUG TRAIN Batch 20/2200 loss 9.920757 loss_att 12.979080 loss_ctc 13.253475 loss_rnnt 8.819709 hw_loss 0.084416 lr 0.00038454 rank 3
2023-02-22 14:40:41,393 DEBUG TRAIN Batch 20/2300 loss 11.529217 loss_att 14.676973 loss_ctc 16.733559 loss_rnnt 10.152854 hw_loss 0.099186 lr 0.00038453 rank 0
2023-02-22 14:40:41,394 DEBUG TRAIN Batch 20/2300 loss 8.373899 loss_att 11.057314 loss_ctc 10.265100 loss_rnnt 7.532648 hw_loss 0.098268 lr 0.00038452 rank 4
2023-02-22 14:40:41,396 DEBUG TRAIN Batch 20/2300 loss 4.481199 loss_att 7.334851 loss_ctc 7.117818 loss_rnnt 3.460712 hw_loss 0.184137 lr 0.00038443 rank 3
2023-02-22 14:40:41,398 DEBUG TRAIN Batch 20/2300 loss 3.295660 loss_att 6.777561 loss_ctc 4.814183 loss_rnnt 2.346875 hw_loss 0.093629 lr 0.00038456 rank 5
2023-02-22 14:40:41,397 DEBUG TRAIN Batch 20/2300 loss 8.182279 loss_att 8.989383 loss_ctc 11.078446 loss_rnnt 7.601700 hw_loss 0.061879 lr 0.00038447 rank 7
2023-02-22 14:40:41,400 DEBUG TRAIN Batch 20/2300 loss 6.854277 loss_att 7.710952 loss_ctc 7.804168 loss_rnnt 6.461648 hw_loss 0.177454 lr 0.00038446 rank 2
2023-02-22 14:40:41,405 DEBUG TRAIN Batch 20/2300 loss 11.253789 loss_att 13.465643 loss_ctc 14.852373 loss_rnnt 10.280103 hw_loss 0.096571 lr 0.00038452 rank 6
2023-02-22 14:40:41,439 DEBUG TRAIN Batch 20/2300 loss 12.381663 loss_att 16.210714 loss_ctc 17.358677 loss_rnnt 10.867702 hw_loss 0.158530 lr 0.00038453 rank 1
2023-02-22 14:41:57,918 DEBUG TRAIN Batch 20/2400 loss 9.197608 loss_att 11.496438 loss_ctc 12.126196 loss_rnnt 8.282727 hw_loss 0.121193 lr 0.00038436 rank 7
2023-02-22 14:41:57,918 DEBUG TRAIN Batch 20/2400 loss 7.197136 loss_att 9.068894 loss_ctc 8.864187 loss_rnnt 6.569922 hw_loss 0.057354 lr 0.00038441 rank 4
2023-02-22 14:41:57,921 DEBUG TRAIN Batch 20/2400 loss 12.311801 loss_att 15.635569 loss_ctc 16.121647 loss_rnnt 11.083244 hw_loss 0.104667 lr 0.00038442 rank 0
2023-02-22 14:41:57,922 DEBUG TRAIN Batch 20/2400 loss 7.907038 loss_att 7.480494 loss_ctc 8.194160 loss_rnnt 7.916990 hw_loss 0.069513 lr 0.00038444 rank 5
2023-02-22 14:41:57,924 DEBUG TRAIN Batch 20/2400 loss 10.005474 loss_att 12.191319 loss_ctc 12.248353 loss_rnnt 9.262224 hw_loss 0.013182 lr 0.00038441 rank 6
2023-02-22 14:41:57,924 DEBUG TRAIN Batch 20/2400 loss 12.117152 loss_att 18.081902 loss_ctc 17.160170 loss_rnnt 10.186479 hw_loss 0.122477 lr 0.00038431 rank 3
2023-02-22 14:41:57,927 DEBUG TRAIN Batch 20/2400 loss 16.942831 loss_att 15.332340 loss_ctc 18.220922 loss_rnnt 17.027546 hw_loss 0.125571 lr 0.00038442 rank 1
2023-02-22 14:41:57,929 DEBUG TRAIN Batch 20/2400 loss 3.300913 loss_att 5.449364 loss_ctc 5.214596 loss_rnnt 2.526545 hw_loss 0.167850 lr 0.00038435 rank 2
2023-02-22 14:43:17,464 DEBUG TRAIN Batch 20/2500 loss 10.585265 loss_att 12.985902 loss_ctc 15.376631 loss_rnnt 9.385929 hw_loss 0.150674 lr 0.00038430 rank 0
2023-02-22 14:43:17,466 DEBUG TRAIN Batch 20/2500 loss 10.152802 loss_att 14.087101 loss_ctc 12.632034 loss_rnnt 9.008177 hw_loss 0.051003 lr 0.00038433 rank 5
2023-02-22 14:43:17,471 DEBUG TRAIN Batch 20/2500 loss 10.200172 loss_att 15.654434 loss_ctc 13.655172 loss_rnnt 8.581485 hw_loss 0.125941 lr 0.00038424 rank 7
2023-02-22 14:43:17,473 DEBUG TRAIN Batch 20/2500 loss 10.344741 loss_att 11.642100 loss_ctc 14.510571 loss_rnnt 9.409517 hw_loss 0.225576 lr 0.00038430 rank 4
2023-02-22 14:43:17,478 DEBUG TRAIN Batch 20/2500 loss 10.834435 loss_att 14.824197 loss_ctc 16.170578 loss_rnnt 9.286618 hw_loss 0.071958 lr 0.00038429 rank 6
2023-02-22 14:43:17,479 DEBUG TRAIN Batch 20/2500 loss 10.053151 loss_att 11.282809 loss_ctc 15.015967 loss_rnnt 9.106966 hw_loss 0.072273 lr 0.00038431 rank 1
2023-02-22 14:43:17,482 DEBUG TRAIN Batch 20/2500 loss 11.427014 loss_att 13.800603 loss_ctc 15.664265 loss_rnnt 10.312328 hw_loss 0.140629 lr 0.00038420 rank 3
2023-02-22 14:43:17,486 DEBUG TRAIN Batch 20/2500 loss 9.878609 loss_att 12.628031 loss_ctc 11.838858 loss_rnnt 9.007127 hw_loss 0.112932 lr 0.00038423 rank 2
2023-02-22 14:44:33,349 DEBUG TRAIN Batch 20/2600 loss 11.519246 loss_att 15.661217 loss_ctc 18.657108 loss_rnnt 9.726284 hw_loss 0.024096 lr 0.00038419 rank 0
2023-02-22 14:44:33,352 DEBUG TRAIN Batch 20/2600 loss 9.944489 loss_att 13.449347 loss_ctc 13.066153 loss_rnnt 8.800257 hw_loss 0.050701 lr 0.00038418 rank 4
2023-02-22 14:44:33,353 DEBUG TRAIN Batch 20/2600 loss 8.982544 loss_att 11.768829 loss_ctc 15.122005 loss_rnnt 7.516013 hw_loss 0.170022 lr 0.00038421 rank 5
2023-02-22 14:44:33,353 DEBUG TRAIN Batch 20/2600 loss 9.961533 loss_att 13.590481 loss_ctc 17.839283 loss_rnnt 8.119112 hw_loss 0.124245 lr 0.00038419 rank 1
2023-02-22 14:44:33,353 DEBUG TRAIN Batch 20/2600 loss 11.849477 loss_att 13.268522 loss_ctc 13.715256 loss_rnnt 11.211043 hw_loss 0.198475 lr 0.00038413 rank 7
2023-02-22 14:44:33,357 DEBUG TRAIN Batch 20/2600 loss 9.350485 loss_att 10.983765 loss_ctc 13.953282 loss_rnnt 8.311087 hw_loss 0.185693 lr 0.00038409 rank 3
2023-02-22 14:44:33,357 DEBUG TRAIN Batch 20/2600 loss 6.970990 loss_att 8.663143 loss_ctc 10.152156 loss_rnnt 6.180727 hw_loss 0.051895 lr 0.00038412 rank 2
2023-02-22 14:44:33,407 DEBUG TRAIN Batch 20/2600 loss 9.614297 loss_att 13.103880 loss_ctc 15.866829 loss_rnnt 8.048396 hw_loss 0.064337 lr 0.00038418 rank 6
2023-02-22 14:45:48,250 DEBUG TRAIN Batch 20/2700 loss 5.596031 loss_att 8.038553 loss_ctc 6.243005 loss_rnnt 4.992520 hw_loss 0.053894 lr 0.00038407 rank 4
2023-02-22 14:45:48,250 DEBUG TRAIN Batch 20/2700 loss 12.746676 loss_att 17.640480 loss_ctc 21.098923 loss_rnnt 10.654236 hw_loss 0.000088 lr 0.00038401 rank 7
2023-02-22 14:45:48,251 DEBUG TRAIN Batch 20/2700 loss 18.047609 loss_att 21.291843 loss_ctc 25.438953 loss_rnnt 16.387226 hw_loss 0.048793 lr 0.00038407 rank 0
2023-02-22 14:45:48,252 DEBUG TRAIN Batch 20/2700 loss 3.449370 loss_att 8.375992 loss_ctc 5.200034 loss_rnnt 2.181544 hw_loss 0.092026 lr 0.00038408 rank 1
2023-02-22 14:45:48,252 DEBUG TRAIN Batch 20/2700 loss 13.601757 loss_att 19.058977 loss_ctc 14.887529 loss_rnnt 12.313964 hw_loss 0.046711 lr 0.00038410 rank 5
2023-02-22 14:45:48,254 DEBUG TRAIN Batch 20/2700 loss 8.360054 loss_att 13.366709 loss_ctc 11.744499 loss_rnnt 6.858636 hw_loss 0.091552 lr 0.00038397 rank 3
2023-02-22 14:45:48,254 DEBUG TRAIN Batch 20/2700 loss 7.601774 loss_att 9.143604 loss_ctc 13.379135 loss_rnnt 6.455536 hw_loss 0.126670 lr 0.00038401 rank 2
2023-02-22 14:45:48,255 DEBUG TRAIN Batch 20/2700 loss 10.200922 loss_att 11.816057 loss_ctc 12.044230 loss_rnnt 9.632074 hw_loss 0.000086 lr 0.00038407 rank 6
2023-02-22 14:47:05,171 DEBUG TRAIN Batch 20/2800 loss 16.937323 loss_att 19.147081 loss_ctc 23.348656 loss_rnnt 15.584094 hw_loss 0.105812 lr 0.00038390 rank 7
2023-02-22 14:47:05,173 DEBUG TRAIN Batch 20/2800 loss 10.530364 loss_att 11.507845 loss_ctc 10.877398 loss_rnnt 10.255751 hw_loss 0.061587 lr 0.00038396 rank 4
2023-02-22 14:47:05,177 DEBUG TRAIN Batch 20/2800 loss 6.915961 loss_att 8.821904 loss_ctc 7.566798 loss_rnnt 6.412149 hw_loss 0.067209 lr 0.00038386 rank 3
2023-02-22 14:47:05,178 DEBUG TRAIN Batch 20/2800 loss 20.016569 loss_att 21.327408 loss_ctc 20.629135 loss_rnnt 19.627129 hw_loss 0.085491 lr 0.00038395 rank 6
2023-02-22 14:47:05,179 DEBUG TRAIN Batch 20/2800 loss 10.811402 loss_att 11.716515 loss_ctc 15.087208 loss_rnnt 9.987064 hw_loss 0.137264 lr 0.00038396 rank 0
2023-02-22 14:47:05,179 DEBUG TRAIN Batch 20/2800 loss 10.781589 loss_att 12.209188 loss_ctc 14.396063 loss_rnnt 9.974400 hw_loss 0.074510 lr 0.00038399 rank 5
2023-02-22 14:47:05,180 DEBUG TRAIN Batch 20/2800 loss 6.224510 loss_att 8.198016 loss_ctc 8.012591 loss_rnnt 5.530576 hw_loss 0.114042 lr 0.00038389 rank 2
2023-02-22 14:47:05,189 DEBUG TRAIN Batch 20/2800 loss 8.044394 loss_att 11.874286 loss_ctc 14.086057 loss_rnnt 6.382173 hw_loss 0.170039 lr 0.00038397 rank 1
2023-02-22 14:48:21,853 DEBUG TRAIN Batch 20/2900 loss 5.784587 loss_att 9.506517 loss_ctc 12.690571 loss_rnnt 4.070796 hw_loss 0.091138 lr 0.00038384 rank 4
2023-02-22 14:48:21,860 DEBUG TRAIN Batch 20/2900 loss 21.218391 loss_att 23.067314 loss_ctc 33.987785 loss_rnnt 19.136646 hw_loss 0.017576 lr 0.00038385 rank 0
2023-02-22 14:48:21,860 DEBUG TRAIN Batch 20/2900 loss 12.335565 loss_att 16.556185 loss_ctc 18.940298 loss_rnnt 10.562953 hw_loss 0.089730 lr 0.00038387 rank 5
2023-02-22 14:48:21,861 DEBUG TRAIN Batch 20/2900 loss 5.592844 loss_att 7.679279 loss_ctc 7.523151 loss_rnnt 4.860709 hw_loss 0.107764 lr 0.00038385 rank 1
2023-02-22 14:48:21,865 DEBUG TRAIN Batch 20/2900 loss 10.537872 loss_att 12.659248 loss_ctc 14.133725 loss_rnnt 9.621994 hw_loss 0.022794 lr 0.00038379 rank 7
2023-02-22 14:48:21,865 DEBUG TRAIN Batch 20/2900 loss 5.058843 loss_att 7.938267 loss_ctc 7.328076 loss_rnnt 4.142821 hw_loss 0.070449 lr 0.00038378 rank 2
2023-02-22 14:48:21,904 DEBUG TRAIN Batch 20/2900 loss 8.200050 loss_att 11.720173 loss_ctc 11.403532 loss_rnnt 7.054244 hw_loss 0.027470 lr 0.00038384 rank 6
2023-02-22 14:48:21,906 DEBUG TRAIN Batch 20/2900 loss 6.482823 loss_att 9.557490 loss_ctc 10.994356 loss_rnnt 5.240147 hw_loss 0.049134 lr 0.00038375 rank 3
2023-02-22 14:49:37,276 DEBUG TRAIN Batch 20/3000 loss 9.444979 loss_att 10.883009 loss_ctc 12.764681 loss_rnnt 8.647372 hw_loss 0.126326 lr 0.00038373 rank 4
2023-02-22 14:49:37,277 DEBUG TRAIN Batch 20/3000 loss 8.225003 loss_att 12.928676 loss_ctc 12.143421 loss_rnnt 6.718438 hw_loss 0.081326 lr 0.00038374 rank 0
2023-02-22 14:49:37,277 DEBUG TRAIN Batch 20/3000 loss 4.806899 loss_att 6.873394 loss_ctc 6.684528 loss_rnnt 4.088669 hw_loss 0.102339 lr 0.00038376 rank 5
2023-02-22 14:49:37,278 DEBUG TRAIN Batch 20/3000 loss 2.894530 loss_att 6.292507 loss_ctc 4.305380 loss_rnnt 1.974788 hw_loss 0.097562 lr 0.00038368 rank 7
2023-02-22 14:49:37,281 DEBUG TRAIN Batch 20/3000 loss 4.277781 loss_att 6.003146 loss_ctc 5.935092 loss_rnnt 3.674954 hw_loss 0.068962 lr 0.00038373 rank 6
2023-02-22 14:49:37,281 DEBUG TRAIN Batch 20/3000 loss 8.983126 loss_att 12.921105 loss_ctc 14.490772 loss_rnnt 7.428882 hw_loss 0.060555 lr 0.00038374 rank 1
2023-02-22 14:49:37,284 DEBUG TRAIN Batch 20/3000 loss 14.136221 loss_att 18.587749 loss_ctc 19.722054 loss_rnnt 12.473626 hw_loss 0.051584 lr 0.00038363 rank 3
2023-02-22 14:49:37,285 DEBUG TRAIN Batch 20/3000 loss 9.719588 loss_att 11.359243 loss_ctc 12.969504 loss_rnnt 8.929811 hw_loss 0.053482 lr 0.00038367 rank 2
2023-02-22 14:50:51,704 DEBUG TRAIN Batch 20/3100 loss 15.409198 loss_att 17.954231 loss_ctc 19.316399 loss_rnnt 14.276212 hw_loss 0.193160 lr 0.00038356 rank 7
2023-02-22 14:50:51,708 DEBUG TRAIN Batch 20/3100 loss 8.596235 loss_att 8.624535 loss_ctc 19.343199 loss_rnnt 7.108758 hw_loss 0.091668 lr 0.00038362 rank 6
2023-02-22 14:50:51,708 DEBUG TRAIN Batch 20/3100 loss 6.498058 loss_att 9.146730 loss_ctc 7.748678 loss_rnnt 5.731905 hw_loss 0.130631 lr 0.00038352 rank 3
2023-02-22 14:50:51,708 DEBUG TRAIN Batch 20/3100 loss 9.926523 loss_att 11.020972 loss_ctc 13.201185 loss_rnnt 9.240310 hw_loss 0.057567 lr 0.00038362 rank 0
2023-02-22 14:50:51,710 DEBUG TRAIN Batch 20/3100 loss 2.902512 loss_att 3.567856 loss_ctc 3.611108 loss_rnnt 2.607247 hw_loss 0.126970 lr 0.00038365 rank 5
2023-02-22 14:50:51,712 DEBUG TRAIN Batch 20/3100 loss 6.017284 loss_att 11.555416 loss_ctc 10.898479 loss_rnnt 4.200607 hw_loss 0.109172 lr 0.00038356 rank 2
2023-02-22 14:50:51,713 DEBUG TRAIN Batch 20/3100 loss 11.397802 loss_att 12.542447 loss_ctc 15.392505 loss_rnnt 10.540669 hw_loss 0.179208 lr 0.00038362 rank 4
2023-02-22 14:50:51,758 DEBUG TRAIN Batch 20/3100 loss 6.522615 loss_att 7.831195 loss_ctc 9.429756 loss_rnnt 5.753622 hw_loss 0.224359 lr 0.00038363 rank 1
2023-02-22 14:52:09,828 DEBUG TRAIN Batch 20/3200 loss 4.785782 loss_att 10.207999 loss_ctc 8.052113 loss_rnnt 3.182817 hw_loss 0.155645 lr 0.00038350 rank 4
2023-02-22 14:52:09,834 DEBUG TRAIN Batch 20/3200 loss 11.601159 loss_att 14.222439 loss_ctc 16.453922 loss_rnnt 10.378555 hw_loss 0.096212 lr 0.00038345 rank 7
2023-02-22 14:52:09,837 DEBUG TRAIN Batch 20/3200 loss 6.580466 loss_att 8.378525 loss_ctc 10.535703 loss_rnnt 5.688077 hw_loss 0.010148 lr 0.00038341 rank 3
2023-02-22 14:52:09,837 DEBUG TRAIN Batch 20/3200 loss 11.885480 loss_att 12.920152 loss_ctc 14.659949 loss_rnnt 11.243507 hw_loss 0.122080 lr 0.00038354 rank 5
2023-02-22 14:52:09,847 DEBUG TRAIN Batch 20/3200 loss 5.746268 loss_att 7.669204 loss_ctc 6.332553 loss_rnnt 5.194698 hw_loss 0.166523 lr 0.00038344 rank 2
2023-02-22 14:52:09,849 DEBUG TRAIN Batch 20/3200 loss 6.249147 loss_att 7.163663 loss_ctc 7.927786 loss_rnnt 5.747364 hw_loss 0.178242 lr 0.00038350 rank 6
2023-02-22 14:52:09,850 DEBUG TRAIN Batch 20/3200 loss 3.676510 loss_att 6.731048 loss_ctc 6.199378 loss_rnnt 2.691547 hw_loss 0.070634 lr 0.00038351 rank 1
2023-02-22 14:52:09,850 DEBUG TRAIN Batch 20/3200 loss 11.338735 loss_att 16.870239 loss_ctc 11.873083 loss_rnnt 10.107468 hw_loss 0.100725 lr 0.00038351 rank 0
2023-02-22 14:53:25,919 DEBUG TRAIN Batch 20/3300 loss 13.809731 loss_att 16.792988 loss_ctc 15.029269 loss_rnnt 13.012836 hw_loss 0.070572 lr 0.00038330 rank 3
2023-02-22 14:53:25,920 DEBUG TRAIN Batch 20/3300 loss 9.971551 loss_att 15.094397 loss_ctc 14.592157 loss_rnnt 8.322401 hw_loss 0.015939 lr 0.00038340 rank 1
2023-02-22 14:53:25,921 DEBUG TRAIN Batch 20/3300 loss 6.615792 loss_att 6.246820 loss_ctc 9.158766 loss_rnnt 6.266656 hw_loss 0.157252 lr 0.00038334 rank 7
2023-02-22 14:53:25,921 DEBUG TRAIN Batch 20/3300 loss 3.256075 loss_att 3.927897 loss_ctc 1.629719 loss_rnnt 3.308092 hw_loss 0.057123 lr 0.00038333 rank 2
2023-02-22 14:53:25,922 DEBUG TRAIN Batch 20/3300 loss 6.909441 loss_att 8.208053 loss_ctc 6.964326 loss_rnnt 6.626024 hw_loss 0.030707 lr 0.00038340 rank 0
2023-02-22 14:53:25,922 DEBUG TRAIN Batch 20/3300 loss 17.997614 loss_att 21.995304 loss_ctc 24.946499 loss_rnnt 16.241177 hw_loss 0.056963 lr 0.00038339 rank 4
2023-02-22 14:53:25,922 DEBUG TRAIN Batch 20/3300 loss 8.078922 loss_att 13.737331 loss_ctc 14.282046 loss_rnnt 6.057470 hw_loss 0.117538 lr 0.00038342 rank 5
2023-02-22 14:53:25,928 DEBUG TRAIN Batch 20/3300 loss 9.094118 loss_att 10.985092 loss_ctc 9.969620 loss_rnnt 8.575157 hw_loss 0.045061 lr 0.00038339 rank 6
2023-02-22 14:54:42,373 DEBUG TRAIN Batch 20/3400 loss 6.272020 loss_att 8.559267 loss_ctc 10.696720 loss_rnnt 5.166400 hw_loss 0.109146 lr 0.00038331 rank 5
2023-02-22 14:54:42,375 DEBUG TRAIN Batch 20/3400 loss 13.898852 loss_att 15.707237 loss_ctc 19.578680 loss_rnnt 12.778551 hw_loss 0.002464 lr 0.00038322 rank 2
2023-02-22 14:54:42,375 DEBUG TRAIN Batch 20/3400 loss 17.675013 loss_att 17.013245 loss_ctc 23.844395 loss_rnnt 16.953213 hw_loss 0.059191 lr 0.00038322 rank 7
2023-02-22 14:54:42,377 DEBUG TRAIN Batch 20/3400 loss 5.006306 loss_att 9.525532 loss_ctc 8.895563 loss_rnnt 3.580094 hw_loss 0.007121 lr 0.00038328 rank 0
2023-02-22 14:54:42,379 DEBUG TRAIN Batch 20/3400 loss 8.548229 loss_att 13.048666 loss_ctc 10.956081 loss_rnnt 7.224618 hw_loss 0.192144 lr 0.00038328 rank 4
2023-02-22 14:54:42,380 DEBUG TRAIN Batch 20/3400 loss 7.223616 loss_att 9.066517 loss_ctc 9.961175 loss_rnnt 6.421649 hw_loss 0.128211 lr 0.00038329 rank 1
2023-02-22 14:54:42,382 DEBUG TRAIN Batch 20/3400 loss 15.510165 loss_att 17.076256 loss_ctc 21.902313 loss_rnnt 14.297464 hw_loss 0.088491 lr 0.00038318 rank 3
2023-02-22 14:54:42,423 DEBUG TRAIN Batch 20/3400 loss 7.351160 loss_att 12.192097 loss_ctc 11.509078 loss_rnnt 5.783903 hw_loss 0.083776 lr 0.00038328 rank 6
2023-02-22 14:55:58,418 DEBUG TRAIN Batch 20/3500 loss 3.999867 loss_att 6.284929 loss_ctc 4.144661 loss_rnnt 3.411603 hw_loss 0.209899 lr 0.00038311 rank 7
2023-02-22 14:55:58,418 DEBUG TRAIN Batch 20/3500 loss 10.960476 loss_att 12.293600 loss_ctc 16.746964 loss_rnnt 9.885954 hw_loss 0.068186 lr 0.00038320 rank 5
2023-02-22 14:55:58,422 DEBUG TRAIN Batch 20/3500 loss 7.832963 loss_att 10.788982 loss_ctc 10.459014 loss_rnnt 6.823246 hw_loss 0.128197 lr 0.00038317 rank 0
2023-02-22 14:55:58,425 DEBUG TRAIN Batch 20/3500 loss 8.761230 loss_att 11.130567 loss_ctc 9.805655 loss_rnnt 8.085024 hw_loss 0.118279 lr 0.00038316 rank 6
2023-02-22 14:55:58,425 DEBUG TRAIN Batch 20/3500 loss 13.996895 loss_att 16.573069 loss_ctc 20.447983 loss_rnnt 12.569505 hw_loss 0.097519 lr 0.00038307 rank 3
2023-02-22 14:55:58,425 DEBUG TRAIN Batch 20/3500 loss 16.622345 loss_att 17.858723 loss_ctc 22.965191 loss_rnnt 15.488907 hw_loss 0.075840 lr 0.00038311 rank 2
2023-02-22 14:55:58,425 DEBUG TRAIN Batch 20/3500 loss 11.717689 loss_att 12.208542 loss_ctc 17.439709 loss_rnnt 10.811592 hw_loss 0.084356 lr 0.00038317 rank 4
2023-02-22 14:55:58,429 DEBUG TRAIN Batch 20/3500 loss 5.644124 loss_att 10.489594 loss_ctc 9.162428 loss_rnnt 4.164035 hw_loss 0.078539 lr 0.00038318 rank 1
2023-02-22 14:57:16,569 DEBUG TRAIN Batch 20/3600 loss 10.478939 loss_att 11.961202 loss_ctc 13.430870 loss_rnnt 9.740032 hw_loss 0.091620 lr 0.00038300 rank 7
2023-02-22 14:57:16,569 DEBUG TRAIN Batch 20/3600 loss 7.828560 loss_att 9.746025 loss_ctc 8.523041 loss_rnnt 7.337276 hw_loss 0.028487 lr 0.00038306 rank 0
2023-02-22 14:57:16,572 DEBUG TRAIN Batch 20/3600 loss 13.915572 loss_att 15.496724 loss_ctc 19.960321 loss_rnnt 12.759499 hw_loss 0.063519 lr 0.00038308 rank 5
2023-02-22 14:57:16,573 DEBUG TRAIN Batch 20/3600 loss 8.538003 loss_att 10.467159 loss_ctc 12.002250 loss_rnnt 7.603910 hw_loss 0.161929 lr 0.00038305 rank 4
2023-02-22 14:57:16,578 DEBUG TRAIN Batch 20/3600 loss 9.484708 loss_att 10.668037 loss_ctc 11.062895 loss_rnnt 9.024970 hw_loss 0.023712 lr 0.00038296 rank 3
2023-02-22 14:57:16,579 DEBUG TRAIN Batch 20/3600 loss 15.898946 loss_att 19.069214 loss_ctc 19.079689 loss_rnnt 14.764903 hw_loss 0.142295 lr 0.00038306 rank 1
2023-02-22 14:57:16,580 DEBUG TRAIN Batch 20/3600 loss 4.367332 loss_att 7.300438 loss_ctc 3.979581 loss_rnnt 3.808958 hw_loss 0.043974 lr 0.00038305 rank 6
2023-02-22 14:57:16,586 DEBUG TRAIN Batch 20/3600 loss 13.248205 loss_att 17.013992 loss_ctc 20.030615 loss_rnnt 11.531259 hw_loss 0.111500 lr 0.00038299 rank 2
2023-02-22 14:58:33,471 DEBUG TRAIN Batch 20/3700 loss 10.292399 loss_att 11.199353 loss_ctc 13.865986 loss_rnnt 9.558565 hw_loss 0.142433 lr 0.00038294 rank 4
2023-02-22 14:58:33,472 DEBUG TRAIN Batch 20/3700 loss 11.157661 loss_att 14.045261 loss_ctc 16.757673 loss_rnnt 9.810385 hw_loss 0.043290 lr 0.00038295 rank 0
2023-02-22 14:58:33,474 DEBUG TRAIN Batch 20/3700 loss 7.078942 loss_att 8.582103 loss_ctc 8.899028 loss_rnnt 6.430673 hw_loss 0.196798 lr 0.00038297 rank 5
2023-02-22 14:58:33,475 DEBUG TRAIN Batch 20/3700 loss 5.475232 loss_att 10.465076 loss_ctc 8.362699 loss_rnnt 4.057669 hw_loss 0.064873 lr 0.00038289 rank 7
2023-02-22 14:58:33,477 DEBUG TRAIN Batch 20/3700 loss 9.450830 loss_att 10.749214 loss_ctc 11.079053 loss_rnnt 8.889451 hw_loss 0.158634 lr 0.00038295 rank 1
2023-02-22 14:58:33,477 DEBUG TRAIN Batch 20/3700 loss 16.809862 loss_att 20.113903 loss_ctc 24.106115 loss_rnnt 15.132645 hw_loss 0.081703 lr 0.00038288 rank 2
2023-02-22 14:58:33,479 DEBUG TRAIN Batch 20/3700 loss 11.517711 loss_att 11.942156 loss_ctc 13.511135 loss_rnnt 11.157173 hw_loss 0.018484 lr 0.00038285 rank 3
2023-02-22 14:58:33,519 DEBUG TRAIN Batch 20/3700 loss 6.183388 loss_att 8.310007 loss_ctc 9.728296 loss_rnnt 5.230098 hw_loss 0.103709 lr 0.00038294 rank 6
2023-02-22 14:59:50,208 DEBUG TRAIN Batch 20/3800 loss 11.950435 loss_att 11.243623 loss_ctc 16.746319 loss_rnnt 11.409534 hw_loss 0.080273 lr 0.00038284 rank 1
2023-02-22 14:59:50,207 DEBUG TRAIN Batch 20/3800 loss 10.617854 loss_att 12.623838 loss_ctc 14.762443 loss_rnnt 9.634624 hw_loss 0.055168 lr 0.00038273 rank 3
2023-02-22 14:59:50,210 DEBUG TRAIN Batch 20/3800 loss 4.706440 loss_att 8.234272 loss_ctc 8.199320 loss_rnnt 3.506669 hw_loss 0.053416 lr 0.00038286 rank 5
2023-02-22 14:59:50,212 DEBUG TRAIN Batch 20/3800 loss 8.160087 loss_att 13.996412 loss_ctc 11.233649 loss_rnnt 6.525369 hw_loss 0.108082 lr 0.00038283 rank 4
2023-02-22 14:59:50,212 DEBUG TRAIN Batch 20/3800 loss 6.797203 loss_att 8.677752 loss_ctc 9.663022 loss_rnnt 5.966063 hw_loss 0.136724 lr 0.00038283 rank 6
2023-02-22 14:59:50,215 DEBUG TRAIN Batch 20/3800 loss 7.568039 loss_att 10.867708 loss_ctc 11.870762 loss_rnnt 6.280545 hw_loss 0.100995 lr 0.00038278 rank 7
2023-02-22 14:59:50,215 DEBUG TRAIN Batch 20/3800 loss 11.057354 loss_att 12.103492 loss_ctc 16.434509 loss_rnnt 10.033305 hw_loss 0.183500 lr 0.00038277 rank 2
2023-02-22 14:59:50,215 DEBUG TRAIN Batch 20/3800 loss 15.500319 loss_att 22.172516 loss_ctc 22.458731 loss_rnnt 13.225711 hw_loss 0.023212 lr 0.00038283 rank 0
2023-02-22 15:01:07,489 DEBUG TRAIN Batch 20/3900 loss 14.957886 loss_att 14.363025 loss_ctc 21.536467 loss_rnnt 14.156009 hw_loss 0.081948 lr 0.00038275 rank 5
2023-02-22 15:01:07,490 DEBUG TRAIN Batch 20/3900 loss 8.371868 loss_att 8.812395 loss_ctc 10.467340 loss_rnnt 7.919820 hw_loss 0.158525 lr 0.00038272 rank 6
2023-02-22 15:01:07,490 DEBUG TRAIN Batch 20/3900 loss 14.731183 loss_att 14.826830 loss_ctc 22.988020 loss_rnnt 13.518866 hw_loss 0.173018 lr 0.00038272 rank 0
2023-02-22 15:01:07,491 DEBUG TRAIN Batch 20/3900 loss 8.230940 loss_att 12.686087 loss_ctc 16.230331 loss_rnnt 6.198538 hw_loss 0.140227 lr 0.00038272 rank 4
2023-02-22 15:01:07,496 DEBUG TRAIN Batch 20/3900 loss 7.515894 loss_att 8.435465 loss_ctc 9.587299 loss_rnnt 6.968496 hw_loss 0.163682 lr 0.00038266 rank 7
2023-02-22 15:01:07,498 DEBUG TRAIN Batch 20/3900 loss 4.560575 loss_att 5.968300 loss_ctc 6.648223 loss_rnnt 3.908916 hw_loss 0.172054 lr 0.00038273 rank 1
2023-02-22 15:01:07,516 DEBUG TRAIN Batch 20/3900 loss 11.209614 loss_att 14.405869 loss_ctc 14.221867 loss_rnnt 10.140526 hw_loss 0.052882 lr 0.00038266 rank 2
2023-02-22 15:01:07,553 DEBUG TRAIN Batch 20/3900 loss 6.650461 loss_att 11.644255 loss_ctc 15.343649 loss_rnnt 4.410326 hw_loss 0.154285 lr 0.00038262 rank 3
2023-02-22 15:02:22,914 DEBUG TRAIN Batch 20/4000 loss 10.194441 loss_att 13.315741 loss_ctc 13.761971 loss_rnnt 9.046041 hw_loss 0.090881 lr 0.00038264 rank 5
2023-02-22 15:02:22,922 DEBUG TRAIN Batch 20/4000 loss 7.443403 loss_att 8.351192 loss_ctc 8.349503 loss_rnnt 7.080293 hw_loss 0.113884 lr 0.00038255 rank 7
2023-02-22 15:02:22,924 DEBUG TRAIN Batch 20/4000 loss 11.389180 loss_att 13.728065 loss_ctc 16.453838 loss_rnnt 10.198500 hw_loss 0.089280 lr 0.00038260 rank 4
2023-02-22 15:02:22,925 DEBUG TRAIN Batch 20/4000 loss 10.004569 loss_att 13.198603 loss_ctc 15.533741 loss_rnnt 8.579203 hw_loss 0.092507 lr 0.00038260 rank 6
2023-02-22 15:02:22,925 DEBUG TRAIN Batch 20/4000 loss 7.465349 loss_att 11.063174 loss_ctc 11.006876 loss_rnnt 6.231718 hw_loss 0.078493 lr 0.00038261 rank 0
2023-02-22 15:02:22,928 DEBUG TRAIN Batch 20/4000 loss 15.302333 loss_att 16.658209 loss_ctc 17.658737 loss_rnnt 14.641624 hw_loss 0.141274 lr 0.00038261 rank 1
2023-02-22 15:02:22,929 DEBUG TRAIN Batch 20/4000 loss 12.024610 loss_att 13.642085 loss_ctc 19.274326 loss_rnnt 10.637454 hw_loss 0.181934 lr 0.00038254 rank 2
2023-02-22 15:02:22,974 DEBUG TRAIN Batch 20/4000 loss 11.104066 loss_att 13.683168 loss_ctc 14.924968 loss_rnnt 10.036732 hw_loss 0.078861 lr 0.00038251 rank 3
2023-02-22 15:03:38,035 DEBUG TRAIN Batch 20/4100 loss 10.183393 loss_att 12.290410 loss_ctc 12.393667 loss_rnnt 9.430521 hw_loss 0.068937 lr 0.00038252 rank 5
2023-02-22 15:03:38,040 DEBUG TRAIN Batch 20/4100 loss 13.345699 loss_att 14.105898 loss_ctc 13.184250 loss_rnnt 13.177261 hw_loss 0.071108 lr 0.00038250 rank 0
2023-02-22 15:03:38,041 DEBUG TRAIN Batch 20/4100 loss 14.077265 loss_att 14.467302 loss_ctc 17.470045 loss_rnnt 13.504176 hw_loss 0.080083 lr 0.00038244 rank 7
2023-02-22 15:03:38,042 DEBUG TRAIN Batch 20/4100 loss 20.876255 loss_att 23.169359 loss_ctc 28.553951 loss_rnnt 19.345102 hw_loss 0.091571 lr 0.00038249 rank 6
2023-02-22 15:03:38,043 DEBUG TRAIN Batch 20/4100 loss 4.516755 loss_att 7.662554 loss_ctc 6.078798 loss_rnnt 3.561274 hw_loss 0.221342 lr 0.00038249 rank 4
2023-02-22 15:03:38,047 DEBUG TRAIN Batch 20/4100 loss 10.591480 loss_att 13.506577 loss_ctc 13.811498 loss_rnnt 9.560023 hw_loss 0.035818 lr 0.00038243 rank 2
2023-02-22 15:03:38,047 DEBUG TRAIN Batch 20/4100 loss 8.475303 loss_att 12.224178 loss_ctc 8.562927 loss_rnnt 7.605850 hw_loss 0.202489 lr 0.00038240 rank 3
2023-02-22 15:03:38,093 DEBUG TRAIN Batch 20/4100 loss 7.453633 loss_att 9.181390 loss_ctc 8.855422 loss_rnnt 6.851576 hw_loss 0.130500 lr 0.00038250 rank 1
2023-02-22 15:04:53,841 DEBUG TRAIN Batch 20/4200 loss 4.730248 loss_att 9.400326 loss_ctc 8.365618 loss_rnnt 3.233530 hw_loss 0.146225 lr 0.00038233 rank 7
2023-02-22 15:04:53,847 DEBUG TRAIN Batch 20/4200 loss 6.783677 loss_att 10.277325 loss_ctc 8.217201 loss_rnnt 5.851414 hw_loss 0.079494 lr 0.00038241 rank 5
2023-02-22 15:04:53,847 DEBUG TRAIN Batch 20/4200 loss 12.044561 loss_att 17.576674 loss_ctc 20.544132 loss_rnnt 9.753151 hw_loss 0.096961 lr 0.00038229 rank 3
2023-02-22 15:04:53,848 DEBUG TRAIN Batch 20/4200 loss 9.455852 loss_att 10.733561 loss_ctc 15.371927 loss_rnnt 8.319485 hw_loss 0.172527 lr 0.00038232 rank 2
2023-02-22 15:04:53,852 DEBUG TRAIN Batch 20/4200 loss 8.971507 loss_att 11.447152 loss_ctc 12.918600 loss_rnnt 7.916055 hw_loss 0.063831 lr 0.00038239 rank 1
2023-02-22 15:04:53,852 DEBUG TRAIN Batch 20/4200 loss 7.532457 loss_att 11.091915 loss_ctc 8.215583 loss_rnnt 6.657791 hw_loss 0.134420 lr 0.00038238 rank 6
2023-02-22 15:04:53,864 DEBUG TRAIN Batch 20/4200 loss 21.596767 loss_att 27.170799 loss_ctc 28.152271 loss_rnnt 19.530178 hw_loss 0.145717 lr 0.00038239 rank 0
2023-02-22 15:04:53,869 DEBUG TRAIN Batch 20/4200 loss 9.593774 loss_att 12.735192 loss_ctc 12.969774 loss_rnnt 8.444551 hw_loss 0.132762 lr 0.00038238 rank 4
2023-02-22 15:06:11,752 DEBUG TRAIN Batch 20/4300 loss 7.158348 loss_att 9.742154 loss_ctc 11.562246 loss_rnnt 6.024116 hw_loss 0.056782 lr 0.00038222 rank 7
2023-02-22 15:06:11,754 DEBUG TRAIN Batch 20/4300 loss 4.825072 loss_att 7.716785 loss_ctc 6.961727 loss_rnnt 3.921281 hw_loss 0.076052 lr 0.00038227 rank 4
2023-02-22 15:06:11,757 DEBUG TRAIN Batch 20/4300 loss 12.649658 loss_att 13.542747 loss_ctc 17.565441 loss_rnnt 11.736611 hw_loss 0.148109 lr 0.00038228 rank 1
2023-02-22 15:06:11,757 DEBUG TRAIN Batch 20/4300 loss 11.697522 loss_att 11.985519 loss_ctc 15.516864 loss_rnnt 11.010341 hw_loss 0.225632 lr 0.00038230 rank 5
2023-02-22 15:06:11,761 DEBUG TRAIN Batch 20/4300 loss 9.135627 loss_att 10.224074 loss_ctc 12.039016 loss_rnnt 8.468972 hw_loss 0.115961 lr 0.00038227 rank 0
2023-02-22 15:06:11,764 DEBUG TRAIN Batch 20/4300 loss 5.940236 loss_att 9.116046 loss_ctc 8.897693 loss_rnnt 4.881788 hw_loss 0.054296 lr 0.00038227 rank 6
2023-02-22 15:06:11,766 DEBUG TRAIN Batch 20/4300 loss 7.157169 loss_att 9.293727 loss_ctc 9.712793 loss_rnnt 6.371594 hw_loss 0.032838 lr 0.00038221 rank 2
2023-02-22 15:06:11,814 DEBUG TRAIN Batch 20/4300 loss 6.988380 loss_att 10.438551 loss_ctc 12.269629 loss_rnnt 5.579914 hw_loss 0.026748 lr 0.00038218 rank 3
2023-02-22 15:07:26,243 DEBUG TRAIN Batch 20/4400 loss 14.429407 loss_att 17.826843 loss_ctc 15.581018 loss_rnnt 13.574336 hw_loss 0.041319 lr 0.00038216 rank 0
2023-02-22 15:07:26,243 DEBUG TRAIN Batch 20/4400 loss 5.406711 loss_att 9.381952 loss_ctc 7.811604 loss_rnnt 4.245507 hw_loss 0.085319 lr 0.00038216 rank 4
2023-02-22 15:07:26,249 DEBUG TRAIN Batch 20/4400 loss 15.755083 loss_att 20.306087 loss_ctc 24.365292 loss_rnnt 13.691848 hw_loss 0.009390 lr 0.00038219 rank 5
2023-02-22 15:07:26,251 DEBUG TRAIN Batch 20/4400 loss 16.197535 loss_att 24.772896 loss_ctc 28.326056 loss_rnnt 12.833532 hw_loss 0.059614 lr 0.00038210 rank 7
2023-02-22 15:07:26,251 DEBUG TRAIN Batch 20/4400 loss 8.878304 loss_att 9.780489 loss_ctc 10.954048 loss_rnnt 8.389606 hw_loss 0.059055 lr 0.00038206 rank 3
2023-02-22 15:07:26,252 DEBUG TRAIN Batch 20/4400 loss 9.607158 loss_att 11.297721 loss_ctc 14.608131 loss_rnnt 8.518828 hw_loss 0.156415 lr 0.00038210 rank 2
2023-02-22 15:07:26,252 DEBUG TRAIN Batch 20/4400 loss 10.942946 loss_att 13.623074 loss_ctc 13.588591 loss_rnnt 10.006923 hw_loss 0.088586 lr 0.00038216 rank 6
2023-02-22 15:07:26,253 DEBUG TRAIN Batch 20/4400 loss 11.839178 loss_att 12.887318 loss_ctc 14.248009 loss_rnnt 11.276451 hw_loss 0.059854 lr 0.00038217 rank 1
2023-02-22 15:08:40,202 DEBUG TRAIN Batch 20/4500 loss 3.353289 loss_att 6.429763 loss_ctc 5.243827 loss_rnnt 2.485716 hw_loss 0.000388 lr 0.00038205 rank 0
2023-02-22 15:08:40,202 DEBUG TRAIN Batch 20/4500 loss 8.799313 loss_att 9.042884 loss_ctc 11.206016 loss_rnnt 8.361764 hw_loss 0.127388 lr 0.00038195 rank 3
2023-02-22 15:08:40,205 DEBUG TRAIN Batch 20/4500 loss 12.685666 loss_att 14.842587 loss_ctc 19.435730 loss_rnnt 11.297346 hw_loss 0.106740 lr 0.00038205 rank 4
2023-02-22 15:08:40,205 DEBUG TRAIN Batch 20/4500 loss 3.581266 loss_att 6.488851 loss_ctc 5.202732 loss_rnnt 2.741460 hw_loss 0.078928 lr 0.00038206 rank 1
2023-02-22 15:08:40,206 DEBUG TRAIN Batch 20/4500 loss 15.324519 loss_att 17.087215 loss_ctc 20.162458 loss_rnnt 14.270541 hw_loss 0.105712 lr 0.00038204 rank 6
2023-02-22 15:08:40,209 DEBUG TRAIN Batch 20/4500 loss 17.959866 loss_att 22.675461 loss_ctc 28.443535 loss_rnnt 15.578489 hw_loss 0.075818 lr 0.00038199 rank 2
2023-02-22 15:08:40,234 DEBUG TRAIN Batch 20/4500 loss 13.021753 loss_att 14.684795 loss_ctc 19.790873 loss_rnnt 11.734205 hw_loss 0.098233 lr 0.00038199 rank 7
2023-02-22 15:08:40,240 DEBUG TRAIN Batch 20/4500 loss 13.145147 loss_att 16.687967 loss_ctc 22.925003 loss_rnnt 11.108246 hw_loss 0.045666 lr 0.00038208 rank 5
2023-02-22 15:09:56,939 DEBUG TRAIN Batch 20/4600 loss 17.000769 loss_att 20.770552 loss_ctc 21.937214 loss_rnnt 15.439907 hw_loss 0.278835 lr 0.00038197 rank 5
2023-02-22 15:09:56,940 DEBUG TRAIN Batch 20/4600 loss 15.104976 loss_att 19.678432 loss_ctc 21.487335 loss_rnnt 13.281015 hw_loss 0.109289 lr 0.00038194 rank 1
2023-02-22 15:09:56,943 DEBUG TRAIN Batch 20/4600 loss 4.794901 loss_att 7.868225 loss_ctc 5.350692 loss_rnnt 4.005129 hw_loss 0.189379 lr 0.00038194 rank 0
2023-02-22 15:09:56,945 DEBUG TRAIN Batch 20/4600 loss 4.260550 loss_att 8.988821 loss_ctc 8.355293 loss_rnnt 2.730564 hw_loss 0.071935 lr 0.00038188 rank 7
2023-02-22 15:09:56,945 DEBUG TRAIN Batch 20/4600 loss 17.098253 loss_att 23.900362 loss_ctc 28.914495 loss_rnnt 14.085586 hw_loss 0.143901 lr 0.00038187 rank 2
2023-02-22 15:09:56,945 DEBUG TRAIN Batch 20/4600 loss 7.866416 loss_att 9.970339 loss_ctc 6.937252 loss_rnnt 7.506653 hw_loss 0.117877 lr 0.00038193 rank 4
2023-02-22 15:09:56,946 DEBUG TRAIN Batch 20/4600 loss 3.349309 loss_att 6.477239 loss_ctc 8.511627 loss_rnnt 2.034996 hw_loss 0.000784 lr 0.00038193 rank 6
2023-02-22 15:09:56,949 DEBUG TRAIN Batch 20/4600 loss 6.213603 loss_att 9.916561 loss_ctc 11.075217 loss_rnnt 4.784290 hw_loss 0.075949 lr 0.00038184 rank 3
2023-02-22 15:11:13,328 DEBUG TRAIN Batch 20/4700 loss 9.914928 loss_att 12.546766 loss_ctc 14.975299 loss_rnnt 8.646144 hw_loss 0.126940 lr 0.00038182 rank 4
2023-02-22 15:11:13,331 DEBUG TRAIN Batch 20/4700 loss 9.156427 loss_att 13.252060 loss_ctc 13.918907 loss_rnnt 7.647799 hw_loss 0.102196 lr 0.00038182 rank 6
2023-02-22 15:11:13,334 DEBUG TRAIN Batch 20/4700 loss 5.432505 loss_att 8.224205 loss_ctc 9.116309 loss_rnnt 4.295475 hw_loss 0.164094 lr 0.00038177 rank 7
2023-02-22 15:11:13,333 DEBUG TRAIN Batch 20/4700 loss 6.746353 loss_att 9.689909 loss_ctc 7.632427 loss_rnnt 6.006173 hw_loss 0.062484 lr 0.00038185 rank 5
2023-02-22 15:11:13,335 DEBUG TRAIN Batch 20/4700 loss 4.746291 loss_att 7.598868 loss_ctc 5.569731 loss_rnnt 4.001384 hw_loss 0.121125 lr 0.00038183 rank 0
2023-02-22 15:11:13,337 DEBUG TRAIN Batch 20/4700 loss 12.477922 loss_att 14.773793 loss_ctc 18.034184 loss_rnnt 11.247032 hw_loss 0.057902 lr 0.00038183 rank 1
2023-02-22 15:11:13,339 DEBUG TRAIN Batch 20/4700 loss 3.665476 loss_att 7.095478 loss_ctc 6.424026 loss_rnnt 2.577115 hw_loss 0.064788 lr 0.00038176 rank 2
2023-02-22 15:11:13,384 DEBUG TRAIN Batch 20/4700 loss 6.725436 loss_att 8.248091 loss_ctc 9.564348 loss_rnnt 5.990282 hw_loss 0.097691 lr 0.00038173 rank 3
2023-02-22 15:12:29,598 DEBUG TRAIN Batch 20/4800 loss 12.172362 loss_att 14.621183 loss_ctc 20.028971 loss_rnnt 10.599972 hw_loss 0.065772 lr 0.00038171 rank 4
2023-02-22 15:12:29,602 DEBUG TRAIN Batch 20/4800 loss 9.134353 loss_att 11.278524 loss_ctc 11.628033 loss_rnnt 8.338522 hw_loss 0.064696 lr 0.00038166 rank 7
2023-02-22 15:12:29,602 DEBUG TRAIN Batch 20/4800 loss 13.884206 loss_att 16.784294 loss_ctc 16.937243 loss_rnnt 12.856128 hw_loss 0.076855 lr 0.00038174 rank 5
2023-02-22 15:12:29,606 DEBUG TRAIN Batch 20/4800 loss 11.850643 loss_att 15.607477 loss_ctc 18.003870 loss_rnnt 10.252490 hw_loss 0.049417 lr 0.00038172 rank 0
2023-02-22 15:12:29,609 DEBUG TRAIN Batch 20/4800 loss 6.162621 loss_att 8.677244 loss_ctc 10.995646 loss_rnnt 4.934345 hw_loss 0.151778 lr 0.00038162 rank 3
2023-02-22 15:12:29,611 DEBUG TRAIN Batch 20/4800 loss 3.984396 loss_att 6.119724 loss_ctc 5.015030 loss_rnnt 3.338293 hw_loss 0.153038 lr 0.00038171 rank 6
2023-02-22 15:12:29,613 DEBUG TRAIN Batch 20/4800 loss 8.336758 loss_att 11.332795 loss_ctc 10.322581 loss_rnnt 7.395667 hw_loss 0.144576 lr 0.00038172 rank 1
2023-02-22 15:12:29,613 DEBUG TRAIN Batch 20/4800 loss 7.239288 loss_att 10.857046 loss_ctc 9.850800 loss_rnnt 6.158751 hw_loss 0.016470 lr 0.00038165 rank 2
2023-02-22 15:13:44,881 DEBUG TRAIN Batch 20/4900 loss 10.480053 loss_att 14.239182 loss_ctc 14.502021 loss_rnnt 9.123927 hw_loss 0.127570 lr 0.00038161 rank 0
2023-02-22 15:13:44,881 DEBUG TRAIN Batch 20/4900 loss 6.549886 loss_att 11.185732 loss_ctc 11.044242 loss_rnnt 4.992359 hw_loss 0.058334 lr 0.00038155 rank 7
2023-02-22 15:13:44,883 DEBUG TRAIN Batch 20/4900 loss 16.095869 loss_att 20.058895 loss_ctc 24.184113 loss_rnnt 14.161364 hw_loss 0.119000 lr 0.00038160 rank 4
2023-02-22 15:13:44,884 DEBUG TRAIN Batch 20/4900 loss 10.199605 loss_att 10.387460 loss_ctc 16.562550 loss_rnnt 9.277436 hw_loss 0.067884 lr 0.00038161 rank 1
2023-02-22 15:13:44,886 DEBUG TRAIN Batch 20/4900 loss 7.524302 loss_att 10.360568 loss_ctc 11.642086 loss_rnnt 6.336988 hw_loss 0.133170 lr 0.00038163 rank 5
2023-02-22 15:13:44,889 DEBUG TRAIN Batch 20/4900 loss 5.491023 loss_att 7.637101 loss_ctc 9.638471 loss_rnnt 4.438251 hw_loss 0.132307 lr 0.00038160 rank 6
2023-02-22 15:13:44,890 DEBUG TRAIN Batch 20/4900 loss 10.307902 loss_att 12.098925 loss_ctc 13.275155 loss_rnnt 9.515705 hw_loss 0.071923 lr 0.00038154 rank 2
2023-02-22 15:13:44,924 DEBUG TRAIN Batch 20/4900 loss 13.240904 loss_att 16.247349 loss_ctc 18.053013 loss_rnnt 11.964572 hw_loss 0.062678 lr 0.00038151 rank 3
2023-02-22 15:15:02,872 DEBUG TRAIN Batch 20/5000 loss 6.519088 loss_att 10.022694 loss_ctc 12.146373 loss_rnnt 5.046037 hw_loss 0.041297 lr 0.00038149 rank 4
2023-02-22 15:15:02,875 DEBUG TRAIN Batch 20/5000 loss 8.080680 loss_att 11.667706 loss_ctc 14.081181 loss_rnnt 6.461222 hw_loss 0.191223 lr 0.00038144 rank 7
2023-02-22 15:15:02,876 DEBUG TRAIN Batch 20/5000 loss 11.279380 loss_att 12.836506 loss_ctc 15.502477 loss_rnnt 10.399090 hw_loss 0.010846 lr 0.00038140 rank 3
2023-02-22 15:15:02,877 DEBUG TRAIN Batch 20/5000 loss 7.634887 loss_att 10.229430 loss_ctc 11.897787 loss_rnnt 6.507583 hw_loss 0.075016 lr 0.00038149 rank 0
2023-02-22 15:15:02,877 DEBUG TRAIN Batch 20/5000 loss 5.776093 loss_att 9.991304 loss_ctc 10.029734 loss_rnnt 4.335949 hw_loss 0.056153 lr 0.00038152 rank 5
2023-02-22 15:15:02,885 DEBUG TRAIN Batch 20/5000 loss 20.837732 loss_att 20.963293 loss_ctc 23.654682 loss_rnnt 20.413990 hw_loss 0.043196 lr 0.00038143 rank 2
2023-02-22 15:15:02,885 DEBUG TRAIN Batch 20/5000 loss 12.011059 loss_att 17.578699 loss_ctc 17.780945 loss_rnnt 10.116417 hw_loss 0.022115 lr 0.00038149 rank 6
2023-02-22 15:15:02,930 DEBUG TRAIN Batch 20/5000 loss 6.944001 loss_att 12.093476 loss_ctc 8.230947 loss_rnnt 5.678288 hw_loss 0.120421 lr 0.00038150 rank 1
2023-02-22 15:16:17,947 DEBUG TRAIN Batch 20/5100 loss 8.212194 loss_att 12.464557 loss_ctc 9.838171 loss_rnnt 7.089010 hw_loss 0.104841 lr 0.00038138 rank 4
2023-02-22 15:16:17,954 DEBUG TRAIN Batch 20/5100 loss 13.047889 loss_att 18.636562 loss_ctc 21.104500 loss_rnnt 10.817724 hw_loss 0.071655 lr 0.00038138 rank 0
2023-02-22 15:16:17,954 DEBUG TRAIN Batch 20/5100 loss 6.373382 loss_att 7.535395 loss_ctc 13.276832 loss_rnnt 5.153110 hw_loss 0.126394 lr 0.00038141 rank 5
2023-02-22 15:16:17,954 DEBUG TRAIN Batch 20/5100 loss 6.320961 loss_att 8.618412 loss_ctc 12.173549 loss_rnnt 5.041509 hw_loss 0.074280 lr 0.00038133 rank 7
2023-02-22 15:16:17,958 DEBUG TRAIN Batch 20/5100 loss 10.511206 loss_att 9.939562 loss_ctc 10.347487 loss_rnnt 10.595447 hw_loss 0.097343 lr 0.00038139 rank 1
2023-02-22 15:16:17,962 DEBUG TRAIN Batch 20/5100 loss 10.677275 loss_att 11.470305 loss_ctc 15.653348 loss_rnnt 9.735677 hw_loss 0.224091 lr 0.00038129 rank 3
2023-02-22 15:16:17,961 DEBUG TRAIN Batch 20/5100 loss 11.706134 loss_att 13.716574 loss_ctc 15.969278 loss_rnnt 10.684587 hw_loss 0.095699 lr 0.00038138 rank 6
2023-02-22 15:16:17,966 DEBUG TRAIN Batch 20/5100 loss 9.762317 loss_att 13.402592 loss_ctc 18.277578 loss_rnnt 7.860708 hw_loss 0.071599 lr 0.00038132 rank 2
2023-02-22 15:17:33,146 DEBUG TRAIN Batch 20/5200 loss 5.970185 loss_att 10.566761 loss_ctc 8.256269 loss_rnnt 4.720741 hw_loss 0.047469 lr 0.00038117 rank 3
2023-02-22 15:17:33,146 DEBUG TRAIN Batch 20/5200 loss 8.983895 loss_att 13.543553 loss_ctc 12.613932 loss_rnnt 7.515140 hw_loss 0.136539 lr 0.00038127 rank 0
2023-02-22 15:17:33,146 DEBUG TRAIN Batch 20/5200 loss 11.961962 loss_att 17.233086 loss_ctc 22.124479 loss_rnnt 9.497595 hw_loss 0.103387 lr 0.00038128 rank 1
2023-02-22 15:17:33,147 DEBUG TRAIN Batch 20/5200 loss 10.892903 loss_att 12.438385 loss_ctc 13.036694 loss_rnnt 10.259300 hw_loss 0.072503 lr 0.00038127 rank 4
2023-02-22 15:17:33,148 DEBUG TRAIN Batch 20/5200 loss 11.829249 loss_att 16.697205 loss_ctc 17.392189 loss_rnnt 10.039373 hw_loss 0.139800 lr 0.00038130 rank 5
2023-02-22 15:17:33,149 DEBUG TRAIN Batch 20/5200 loss 14.282992 loss_att 13.528579 loss_ctc 19.224812 loss_rnnt 13.653654 hw_loss 0.227458 lr 0.00038121 rank 7
2023-02-22 15:17:33,149 DEBUG TRAIN Batch 20/5200 loss 14.336749 loss_att 17.607384 loss_ctc 16.588417 loss_rnnt 13.345866 hw_loss 0.068500 lr 0.00038121 rank 2
2023-02-22 15:17:33,149 DEBUG TRAIN Batch 20/5200 loss 7.258435 loss_att 6.966110 loss_ctc 9.975038 loss_rnnt 6.877103 hw_loss 0.145468 lr 0.00038127 rank 6
2023-02-22 15:18:50,285 DEBUG TRAIN Batch 20/5300 loss 8.720736 loss_att 15.994895 loss_ctc 9.224590 loss_rnnt 7.104504 hw_loss 0.176660 lr 0.00038116 rank 6
2023-02-22 15:18:50,287 DEBUG TRAIN Batch 20/5300 loss 3.773541 loss_att 7.752770 loss_ctc 6.903361 loss_rnnt 2.500120 hw_loss 0.112998 lr 0.00038116 rank 0
2023-02-22 15:18:50,288 DEBUG TRAIN Batch 20/5300 loss 7.640098 loss_att 10.265077 loss_ctc 7.688419 loss_rnnt 7.096798 hw_loss 0.022241 lr 0.00038110 rank 7
2023-02-22 15:18:50,288 DEBUG TRAIN Batch 20/5300 loss 12.765487 loss_att 15.101753 loss_ctc 17.268482 loss_rnnt 11.662594 hw_loss 0.066073 lr 0.00038116 rank 4
2023-02-22 15:18:50,289 DEBUG TRAIN Batch 20/5300 loss 10.819492 loss_att 14.085989 loss_ctc 16.116920 loss_rnnt 9.426608 hw_loss 0.062365 lr 0.00038119 rank 5
2023-02-22 15:18:50,291 DEBUG TRAIN Batch 20/5300 loss 9.703254 loss_att 12.459236 loss_ctc 14.156288 loss_rnnt 8.516036 hw_loss 0.079282 lr 0.00038106 rank 3
2023-02-22 15:18:50,293 DEBUG TRAIN Batch 20/5300 loss 9.520646 loss_att 14.759518 loss_ctc 18.023800 loss_rnnt 7.224267 hw_loss 0.215345 lr 0.00038117 rank 1
2023-02-22 15:18:50,294 DEBUG TRAIN Batch 20/5300 loss 10.293533 loss_att 14.231848 loss_ctc 11.489738 loss_rnnt 9.303377 hw_loss 0.080625 lr 0.00038110 rank 2
2023-02-22 15:20:06,774 DEBUG TRAIN Batch 20/5400 loss 10.811341 loss_att 15.450428 loss_ctc 19.693264 loss_rnnt 8.655304 hw_loss 0.082433 lr 0.00038105 rank 4
2023-02-22 15:20:06,777 DEBUG TRAIN Batch 20/5400 loss 9.738400 loss_att 11.499735 loss_ctc 8.016783 loss_rnnt 9.582148 hw_loss 0.062879 lr 0.00038108 rank 5
2023-02-22 15:20:06,781 DEBUG TRAIN Batch 20/5400 loss 5.712225 loss_att 8.320767 loss_ctc 10.285192 loss_rnnt 4.516185 hw_loss 0.121130 lr 0.00038095 rank 3
2023-02-22 15:20:06,783 DEBUG TRAIN Batch 20/5400 loss 5.555885 loss_att 7.859013 loss_ctc 9.097624 loss_rnnt 4.561086 hw_loss 0.116141 lr 0.00038099 rank 7
2023-02-22 15:20:06,783 DEBUG TRAIN Batch 20/5400 loss 9.962654 loss_att 12.074035 loss_ctc 13.748032 loss_rnnt 8.991144 hw_loss 0.083471 lr 0.00038099 rank 2
2023-02-22 15:20:06,784 DEBUG TRAIN Batch 20/5400 loss 6.878132 loss_att 9.448478 loss_ctc 9.842690 loss_rnnt 5.861374 hw_loss 0.201403 lr 0.00038105 rank 0
2023-02-22 15:20:06,788 DEBUG TRAIN Batch 20/5400 loss 8.898227 loss_att 12.369942 loss_ctc 8.939300 loss_rnnt 8.168585 hw_loss 0.055915 lr 0.00038104 rank 6
2023-02-22 15:20:06,792 DEBUG TRAIN Batch 20/5400 loss 9.498799 loss_att 12.242246 loss_ctc 13.876282 loss_rnnt 8.305012 hw_loss 0.115191 lr 0.00038106 rank 1
2023-02-22 15:21:22,711 DEBUG TRAIN Batch 20/5500 loss 4.376367 loss_att 8.320940 loss_ctc 6.255111 loss_rnnt 3.318255 hw_loss 0.035056 lr 0.00038084 rank 3
2023-02-22 15:21:22,711 DEBUG TRAIN Batch 20/5500 loss 7.142839 loss_att 9.208864 loss_ctc 11.862117 loss_rnnt 6.088873 hw_loss 0.021607 lr 0.00038095 rank 1
2023-02-22 15:21:22,713 DEBUG TRAIN Batch 20/5500 loss 10.239895 loss_att 15.017703 loss_ctc 14.757582 loss_rnnt 8.626637 hw_loss 0.103756 lr 0.00038088 rank 7
2023-02-22 15:21:22,713 DEBUG TRAIN Batch 20/5500 loss 7.949954 loss_att 12.676551 loss_ctc 15.748466 loss_rnnt 5.895886 hw_loss 0.129273 lr 0.00038094 rank 0
2023-02-22 15:21:22,714 DEBUG TRAIN Batch 20/5500 loss 11.476443 loss_att 12.941635 loss_ctc 14.470708 loss_rnnt 10.759300 hw_loss 0.046631 lr 0.00038097 rank 5
2023-02-22 15:21:22,714 DEBUG TRAIN Batch 20/5500 loss 8.243052 loss_att 9.521301 loss_ctc 10.737519 loss_rnnt 7.603608 hw_loss 0.095997 lr 0.00038094 rank 4
2023-02-22 15:21:22,716 DEBUG TRAIN Batch 20/5500 loss 7.974380 loss_att 9.755341 loss_ctc 10.851711 loss_rnnt 7.179873 hw_loss 0.102506 lr 0.00038088 rank 2
2023-02-22 15:21:22,724 DEBUG TRAIN Batch 20/5500 loss 8.985078 loss_att 12.011236 loss_ctc 11.439806 loss_rnnt 7.972107 hw_loss 0.150830 lr 0.00038093 rank 6
2023-02-22 15:22:39,542 DEBUG TRAIN Batch 20/5600 loss 4.383168 loss_att 8.425900 loss_ctc 7.957784 loss_rnnt 3.061926 hw_loss 0.067651 lr 0.00038073 rank 3
2023-02-22 15:22:39,542 DEBUG TRAIN Batch 20/5600 loss 7.814121 loss_att 10.105764 loss_ctc 11.538206 loss_rnnt 6.795371 hw_loss 0.119769 lr 0.00038077 rank 7
2023-02-22 15:22:39,544 DEBUG TRAIN Batch 20/5600 loss 13.430772 loss_att 15.561377 loss_ctc 18.963291 loss_rnnt 12.243629 hw_loss 0.043786 lr 0.00038086 rank 5
2023-02-22 15:22:39,544 DEBUG TRAIN Batch 20/5600 loss 11.385533 loss_att 17.356243 loss_ctc 14.214340 loss_rnnt 9.752296 hw_loss 0.116101 lr 0.00038082 rank 4
2023-02-22 15:22:39,546 DEBUG TRAIN Batch 20/5600 loss 3.813859 loss_att 6.537298 loss_ctc 5.903059 loss_rnnt 2.903902 hw_loss 0.162582 lr 0.00038083 rank 1
2023-02-22 15:22:39,545 DEBUG TRAIN Batch 20/5600 loss 3.729345 loss_att 7.619649 loss_ctc 7.682131 loss_rnnt 2.350700 hw_loss 0.137899 lr 0.00038082 rank 6
2023-02-22 15:22:39,548 DEBUG TRAIN Batch 20/5600 loss 9.427896 loss_att 10.107271 loss_ctc 11.616983 loss_rnnt 8.883800 hw_loss 0.218144 lr 0.00038083 rank 0
2023-02-22 15:22:39,549 DEBUG TRAIN Batch 20/5600 loss 7.089648 loss_att 7.647693 loss_ctc 10.226957 loss_rnnt 6.433930 hw_loss 0.235877 lr 0.00038077 rank 2
2023-02-22 15:23:57,631 DEBUG TRAIN Batch 20/5700 loss 3.596848 loss_att 5.674597 loss_ctc 4.342632 loss_rnnt 3.061613 hw_loss 0.037965 lr 0.00038072 rank 0
2023-02-22 15:23:57,634 DEBUG TRAIN Batch 20/5700 loss 9.816214 loss_att 12.458483 loss_ctc 9.413733 loss_rnnt 9.272877 hw_loss 0.128526 lr 0.00038065 rank 2
2023-02-22 15:23:57,635 DEBUG TRAIN Batch 20/5700 loss 6.201088 loss_att 8.353852 loss_ctc 8.802707 loss_rnnt 5.393137 hw_loss 0.057217 lr 0.00038062 rank 3
2023-02-22 15:23:57,635 DEBUG TRAIN Batch 20/5700 loss 11.408127 loss_att 11.802159 loss_ctc 14.809616 loss_rnnt 10.782397 hw_loss 0.175108 lr 0.00038071 rank 4
2023-02-22 15:23:57,636 DEBUG TRAIN Batch 20/5700 loss 10.069642 loss_att 11.270703 loss_ctc 13.163623 loss_rnnt 9.370928 hw_loss 0.086199 lr 0.00038072 rank 1
2023-02-22 15:23:57,636 DEBUG TRAIN Batch 20/5700 loss 9.990461 loss_att 11.390361 loss_ctc 14.151480 loss_rnnt 9.106274 hw_loss 0.092636 lr 0.00038071 rank 6
2023-02-22 15:23:57,637 DEBUG TRAIN Batch 20/5700 loss 19.723295 loss_att 24.683182 loss_ctc 24.017080 loss_rnnt 18.124054 hw_loss 0.065168 lr 0.00038075 rank 5
2023-02-22 15:23:57,638 DEBUG TRAIN Batch 20/5700 loss 10.948714 loss_att 13.094993 loss_ctc 16.440046 loss_rnnt 9.720677 hw_loss 0.124882 lr 0.00038066 rank 7
2023-02-22 15:25:13,992 DEBUG TRAIN Batch 20/5800 loss 10.664834 loss_att 12.740861 loss_ctc 15.586162 loss_rnnt 9.564878 hw_loss 0.053575 lr 0.00038064 rank 5
2023-02-22 15:25:13,993 DEBUG TRAIN Batch 20/5800 loss 10.311023 loss_att 12.884749 loss_ctc 13.264244 loss_rnnt 9.361654 hw_loss 0.076612 lr 0.00038061 rank 0
2023-02-22 15:25:13,993 DEBUG TRAIN Batch 20/5800 loss 8.531760 loss_att 9.539557 loss_ctc 11.351346 loss_rnnt 7.858160 hw_loss 0.180180 lr 0.00038055 rank 7
2023-02-22 15:25:13,994 DEBUG TRAIN Batch 20/5800 loss 5.202082 loss_att 7.929255 loss_ctc 8.313529 loss_rnnt 4.202228 hw_loss 0.074174 lr 0.00038060 rank 4
2023-02-22 15:25:13,995 DEBUG TRAIN Batch 20/5800 loss 4.778453 loss_att 7.754663 loss_ctc 7.333226 loss_rnnt 3.804728 hw_loss 0.070963 lr 0.00038061 rank 1
2023-02-22 15:25:13,995 DEBUG TRAIN Batch 20/5800 loss 6.479727 loss_att 7.510274 loss_ctc 9.558359 loss_rnnt 5.746922 hw_loss 0.217898 lr 0.00038051 rank 3
2023-02-22 15:25:14,000 DEBUG TRAIN Batch 20/5800 loss 10.095940 loss_att 12.182783 loss_ctc 14.774211 loss_rnnt 9.006374 hw_loss 0.090802 lr 0.00038060 rank 6
2023-02-22 15:25:14,045 DEBUG TRAIN Batch 20/5800 loss 8.781956 loss_att 11.557622 loss_ctc 10.657478 loss_rnnt 7.924525 hw_loss 0.097927 lr 0.00038054 rank 2
2023-02-22 15:26:29,550 DEBUG TRAIN Batch 20/5900 loss 12.647624 loss_att 16.287178 loss_ctc 19.208040 loss_rnnt 11.029448 hw_loss 0.029145 lr 0.00038050 rank 0
2023-02-22 15:26:29,555 DEBUG TRAIN Batch 20/5900 loss 6.845945 loss_att 9.140332 loss_ctc 9.041751 loss_rnnt 6.058745 hw_loss 0.066653 lr 0.00038050 rank 1
2023-02-22 15:26:29,555 DEBUG TRAIN Batch 20/5900 loss 8.871759 loss_att 12.994013 loss_ctc 11.841722 loss_rnnt 7.592953 hw_loss 0.109426 lr 0.00038052 rank 5
2023-02-22 15:26:29,557 DEBUG TRAIN Batch 20/5900 loss 9.707984 loss_att 12.306140 loss_ctc 12.190779 loss_rnnt 8.834785 hw_loss 0.042242 lr 0.00038043 rank 2
2023-02-22 15:26:29,558 DEBUG TRAIN Batch 20/5900 loss 13.487598 loss_att 16.524990 loss_ctc 20.397066 loss_rnnt 11.944992 hw_loss 0.025997 lr 0.00038044 rank 7
2023-02-22 15:26:29,558 DEBUG TRAIN Batch 20/5900 loss 10.175850 loss_att 12.750289 loss_ctc 17.165279 loss_rnnt 8.624628 hw_loss 0.195768 lr 0.00038049 rank 4
2023-02-22 15:26:29,561 DEBUG TRAIN Batch 20/5900 loss 6.532892 loss_att 11.923579 loss_ctc 7.634612 loss_rnnt 5.284247 hw_loss 0.044272 lr 0.00038040 rank 3
2023-02-22 15:26:29,608 DEBUG TRAIN Batch 20/5900 loss 4.211646 loss_att 8.898048 loss_ctc 5.716700 loss_rnnt 3.050471 hw_loss 0.043537 lr 0.00038049 rank 6
2023-02-22 15:27:46,796 DEBUG TRAIN Batch 20/6000 loss 19.635326 loss_att 22.222298 loss_ctc 26.991220 loss_rnnt 18.125389 hw_loss 0.022045 lr 0.00038039 rank 0
2023-02-22 15:27:46,799 DEBUG TRAIN Batch 20/6000 loss 2.641984 loss_att 5.632252 loss_ctc 5.323626 loss_rnnt 1.636783 hw_loss 0.092992 lr 0.00038038 rank 6
2023-02-22 15:27:46,800 DEBUG TRAIN Batch 20/6000 loss 8.008395 loss_att 10.332096 loss_ctc 13.543722 loss_rnnt 6.763003 hw_loss 0.079891 lr 0.00038038 rank 4
2023-02-22 15:27:46,800 DEBUG TRAIN Batch 20/6000 loss 5.707650 loss_att 7.449555 loss_ctc 13.817518 loss_rnnt 4.183891 hw_loss 0.176365 lr 0.00038041 rank 5
2023-02-22 15:27:46,800 DEBUG TRAIN Batch 20/6000 loss 11.922674 loss_att 13.512872 loss_ctc 13.848454 loss_rnnt 11.284298 hw_loss 0.119187 lr 0.00038039 rank 1
2023-02-22 15:27:46,803 DEBUG TRAIN Batch 20/6000 loss 6.410538 loss_att 8.627972 loss_ctc 6.542261 loss_rnnt 5.909874 hw_loss 0.074276 lr 0.00038033 rank 7
2023-02-22 15:27:46,823 DEBUG TRAIN Batch 20/6000 loss 4.504064 loss_att 6.992740 loss_ctc 6.615091 loss_rnnt 3.681039 hw_loss 0.082161 lr 0.00038029 rank 3
2023-02-22 15:27:46,869 DEBUG TRAIN Batch 20/6000 loss 12.131995 loss_att 13.627260 loss_ctc 15.420772 loss_rnnt 11.370041 hw_loss 0.045745 lr 0.00038032 rank 2
2023-02-22 15:29:04,262 DEBUG TRAIN Batch 20/6100 loss 5.881077 loss_att 8.837029 loss_ctc 9.355431 loss_rnnt 4.730215 hw_loss 0.180796 lr 0.00038018 rank 3
2023-02-22 15:29:04,263 DEBUG TRAIN Batch 20/6100 loss 15.703077 loss_att 18.456926 loss_ctc 21.820084 loss_rnnt 14.316593 hw_loss 0.037714 lr 0.00038027 rank 4
2023-02-22 15:29:04,264 DEBUG TRAIN Batch 20/6100 loss 6.790418 loss_att 7.797803 loss_ctc 9.305128 loss_rnnt 6.163414 hw_loss 0.169186 lr 0.00038028 rank 1
2023-02-22 15:29:04,267 DEBUG TRAIN Batch 20/6100 loss 9.782101 loss_att 13.363585 loss_ctc 16.005981 loss_rnnt 8.211515 hw_loss 0.045820 lr 0.00038028 rank 0
2023-02-22 15:29:04,268 DEBUG TRAIN Batch 20/6100 loss 5.326487 loss_att 8.979102 loss_ctc 7.672728 loss_rnnt 4.258585 hw_loss 0.046025 lr 0.00038027 rank 6
2023-02-22 15:29:04,269 DEBUG TRAIN Batch 20/6100 loss 13.078609 loss_att 14.861557 loss_ctc 19.565035 loss_rnnt 11.843958 hw_loss 0.024754 lr 0.00038021 rank 2
2023-02-22 15:29:04,286 DEBUG TRAIN Batch 20/6100 loss 3.805094 loss_att 6.864171 loss_ctc 6.578438 loss_rnnt 2.787607 hw_loss 0.067299 lr 0.00038022 rank 7
2023-02-22 15:29:04,289 DEBUG TRAIN Batch 20/6100 loss 12.453832 loss_att 13.624063 loss_ctc 16.863276 loss_rnnt 11.569723 hw_loss 0.116507 lr 0.00038030 rank 5
2023-02-22 15:30:20,182 DEBUG TRAIN Batch 20/6200 loss 11.595518 loss_att 13.431882 loss_ctc 14.039862 loss_rnnt 10.851286 hw_loss 0.095716 lr 0.00038019 rank 5
2023-02-22 15:30:20,183 DEBUG TRAIN Batch 20/6200 loss 10.729830 loss_att 13.731674 loss_ctc 13.145498 loss_rnnt 9.754290 hw_loss 0.099529 lr 0.00038016 rank 4
2023-02-22 15:30:20,183 DEBUG TRAIN Batch 20/6200 loss 12.209914 loss_att 12.607443 loss_ctc 16.635916 loss_rnnt 11.513684 hw_loss 0.049858 lr 0.00038017 rank 0
2023-02-22 15:30:20,185 DEBUG TRAIN Batch 20/6200 loss 10.673764 loss_att 14.791587 loss_ctc 15.624372 loss_rnnt 9.115404 hw_loss 0.140088 lr 0.00038011 rank 7
2023-02-22 15:30:20,189 DEBUG TRAIN Batch 20/6200 loss 7.447062 loss_att 10.336215 loss_ctc 13.151628 loss_rnnt 6.085090 hw_loss 0.044121 lr 0.00038017 rank 1
2023-02-22 15:30:20,189 DEBUG TRAIN Batch 20/6200 loss 4.777702 loss_att 6.748437 loss_ctc 6.371947 loss_rnnt 4.090084 hw_loss 0.151697 lr 0.00038016 rank 6
2023-02-22 15:30:20,191 DEBUG TRAIN Batch 20/6200 loss 5.912734 loss_att 8.307338 loss_ctc 8.682719 loss_rnnt 5.004329 hw_loss 0.112786 lr 0.00038010 rank 2
2023-02-22 15:30:20,236 DEBUG TRAIN Batch 20/6200 loss 10.118297 loss_att 12.053267 loss_ctc 17.634853 loss_rnnt 8.666494 hw_loss 0.117375 lr 0.00038007 rank 3
2023-02-22 15:31:36,779 DEBUG TRAIN Batch 20/6300 loss 5.968596 loss_att 6.792890 loss_ctc 10.546171 loss_rnnt 5.124390 hw_loss 0.129382 lr 0.00038005 rank 4
2023-02-22 15:31:36,780 DEBUG TRAIN Batch 20/6300 loss 20.091892 loss_att 22.879168 loss_ctc 29.187290 loss_rnnt 18.261234 hw_loss 0.113406 lr 0.00038006 rank 0
2023-02-22 15:31:36,779 DEBUG TRAIN Batch 20/6300 loss 8.548989 loss_att 10.353683 loss_ctc 11.978274 loss_rnnt 7.692116 hw_loss 0.072556 lr 0.00037996 rank 3
2023-02-22 15:31:36,782 DEBUG TRAIN Batch 20/6300 loss 12.938592 loss_att 18.859125 loss_ctc 24.288929 loss_rnnt 10.181247 hw_loss 0.112239 lr 0.00038000 rank 7
2023-02-22 15:31:36,783 DEBUG TRAIN Batch 20/6300 loss 4.797259 loss_att 7.668651 loss_ctc 7.938766 loss_rnnt 3.745932 hw_loss 0.109089 lr 0.00038005 rank 6
2023-02-22 15:31:36,783 DEBUG TRAIN Batch 20/6300 loss 4.458477 loss_att 9.153519 loss_ctc 7.645841 loss_rnnt 3.020220 hw_loss 0.139251 lr 0.00038008 rank 5
2023-02-22 15:31:36,786 DEBUG TRAIN Batch 20/6300 loss 1.521319 loss_att 4.548418 loss_ctc 3.931718 loss_rnnt 0.569470 hw_loss 0.046956 lr 0.00037999 rank 2
2023-02-22 15:31:36,788 DEBUG TRAIN Batch 20/6300 loss 8.773760 loss_att 9.466376 loss_ctc 14.074862 loss_rnnt 7.884814 hw_loss 0.081766 lr 0.00038006 rank 1
2023-02-22 15:32:55,317 DEBUG TRAIN Batch 20/6400 loss 13.547636 loss_att 23.773975 loss_ctc 15.655428 loss_rnnt 11.156016 hw_loss 0.122461 lr 0.00037994 rank 4
2023-02-22 15:32:55,320 DEBUG TRAIN Batch 20/6400 loss 6.097342 loss_att 8.669716 loss_ctc 10.308875 loss_rnnt 4.925643 hw_loss 0.179411 lr 0.00037989 rank 7
2023-02-22 15:32:55,320 DEBUG TRAIN Batch 20/6400 loss 10.823030 loss_att 11.886049 loss_ctc 14.989877 loss_rnnt 10.012003 hw_loss 0.080334 lr 0.00037985 rank 3
2023-02-22 15:32:55,323 DEBUG TRAIN Batch 20/6400 loss 12.827854 loss_att 16.249588 loss_ctc 20.272701 loss_rnnt 11.074148 hw_loss 0.143837 lr 0.00037995 rank 1
2023-02-22 15:32:55,324 DEBUG TRAIN Batch 20/6400 loss 3.210553 loss_att 7.784004 loss_ctc 6.562873 loss_rnnt 1.797922 hw_loss 0.095558 lr 0.00037997 rank 5
2023-02-22 15:32:55,324 DEBUG TRAIN Batch 20/6400 loss 5.215080 loss_att 6.976386 loss_ctc 7.092674 loss_rnnt 4.537884 hw_loss 0.139853 lr 0.00037995 rank 0
2023-02-22 15:32:55,325 DEBUG TRAIN Batch 20/6400 loss 10.010114 loss_att 14.837023 loss_ctc 15.794508 loss_rnnt 8.245872 hw_loss 0.051764 lr 0.00037989 rank 2
2023-02-22 15:32:55,328 DEBUG TRAIN Batch 20/6400 loss 4.181023 loss_att 5.365159 loss_ctc 6.750014 loss_rnnt 3.547036 hw_loss 0.102426 lr 0.00037994 rank 6
2023-02-22 15:34:10,192 DEBUG TRAIN Batch 20/6500 loss 16.857834 loss_att 22.981552 loss_ctc 21.112947 loss_rnnt 15.049807 hw_loss 0.029877 lr 0.00037987 rank 5
2023-02-22 15:34:10,192 DEBUG TRAIN Batch 20/6500 loss 5.571686 loss_att 7.590969 loss_ctc 8.383907 loss_rnnt 4.768217 hw_loss 0.046218 lr 0.00037974 rank 3
2023-02-22 15:34:10,192 DEBUG TRAIN Batch 20/6500 loss 8.084587 loss_att 12.399836 loss_ctc 12.437441 loss_rnnt 6.593390 hw_loss 0.089561 lr 0.00037984 rank 1
2023-02-22 15:34:10,193 DEBUG TRAIN Batch 20/6500 loss 6.253230 loss_att 10.724563 loss_ctc 8.058185 loss_rnnt 5.118258 hw_loss 0.000082 lr 0.00037978 rank 7
2023-02-22 15:34:10,195 DEBUG TRAIN Batch 20/6500 loss 11.436578 loss_att 16.005547 loss_ctc 18.177109 loss_rnnt 9.624004 hw_loss 0.000078 lr 0.00037984 rank 0
2023-02-22 15:34:10,197 DEBUG TRAIN Batch 20/6500 loss 9.165457 loss_att 10.378469 loss_ctc 10.300144 loss_rnnt 8.766275 hw_loss 0.009912 lr 0.00037983 rank 4
2023-02-22 15:34:10,201 DEBUG TRAIN Batch 20/6500 loss 5.490063 loss_att 11.286791 loss_ctc 8.878208 loss_rnnt 3.847013 hw_loss 0.059911 lr 0.00037978 rank 2
2023-02-22 15:34:10,203 DEBUG TRAIN Batch 20/6500 loss 8.905288 loss_att 16.262291 loss_ctc 11.197768 loss_rnnt 7.103410 hw_loss 0.046525 lr 0.00037983 rank 6
2023-02-22 15:35:25,940 DEBUG TRAIN Batch 20/6600 loss 14.405117 loss_att 18.725582 loss_ctc 22.279455 loss_rnnt 12.453625 hw_loss 0.070290 lr 0.00037973 rank 4
2023-02-22 15:35:25,941 DEBUG TRAIN Batch 20/6600 loss 8.793642 loss_att 12.008019 loss_ctc 14.093709 loss_rnnt 7.345617 hw_loss 0.184638 lr 0.00037976 rank 5
2023-02-22 15:35:25,941 DEBUG TRAIN Batch 20/6600 loss 7.248975 loss_att 12.183035 loss_ctc 13.419314 loss_rnnt 5.383966 hw_loss 0.104034 lr 0.00037967 rank 7
2023-02-22 15:35:25,943 DEBUG TRAIN Batch 20/6600 loss 10.615112 loss_att 15.696352 loss_ctc 14.097860 loss_rnnt 9.061899 hw_loss 0.136122 lr 0.00037973 rank 0
2023-02-22 15:35:25,945 DEBUG TRAIN Batch 20/6600 loss 8.047538 loss_att 9.262864 loss_ctc 14.369193 loss_rnnt 6.889588 hw_loss 0.134993 lr 0.00037972 rank 6
2023-02-22 15:35:25,946 DEBUG TRAIN Batch 20/6600 loss 8.848583 loss_att 10.726682 loss_ctc 10.908824 loss_rnnt 8.160104 hw_loss 0.071552 lr 0.00037967 rank 2
2023-02-22 15:35:25,953 DEBUG TRAIN Batch 20/6600 loss 5.282735 loss_att 10.549507 loss_ctc 6.025902 loss_rnnt 4.073558 hw_loss 0.106376 lr 0.00037963 rank 3
2023-02-22 15:35:25,955 DEBUG TRAIN Batch 20/6600 loss 1.854926 loss_att 3.059788 loss_ctc 2.031189 loss_rnnt 1.525142 hw_loss 0.122457 lr 0.00037973 rank 1
2023-02-22 15:36:42,145 DEBUG TRAIN Batch 20/6700 loss 2.941498 loss_att 6.094490 loss_ctc 4.600558 loss_rnnt 2.025829 hw_loss 0.119743 lr 0.00037965 rank 5
2023-02-22 15:36:42,146 DEBUG TRAIN Batch 20/6700 loss 8.672219 loss_att 9.439193 loss_ctc 12.996799 loss_rnnt 7.882147 hw_loss 0.112627 lr 0.00037962 rank 0
2023-02-22 15:36:42,151 DEBUG TRAIN Batch 20/6700 loss 22.650156 loss_att 29.520113 loss_ctc 38.422409 loss_rnnt 19.066420 hw_loss 0.200209 lr 0.00037956 rank 7
2023-02-22 15:36:42,152 DEBUG TRAIN Batch 20/6700 loss 4.416082 loss_att 7.888346 loss_ctc 5.946198 loss_rnnt 3.507006 hw_loss 0.019889 lr 0.00037962 rank 4
2023-02-22 15:36:42,152 DEBUG TRAIN Batch 20/6700 loss 7.214787 loss_att 9.876997 loss_ctc 10.603548 loss_rnnt 6.193829 hw_loss 0.068776 lr 0.00037963 rank 1
2023-02-22 15:36:42,153 DEBUG TRAIN Batch 20/6700 loss 9.662101 loss_att 10.971535 loss_ctc 13.708380 loss_rnnt 8.809188 hw_loss 0.096605 lr 0.00037961 rank 6
2023-02-22 15:36:42,157 DEBUG TRAIN Batch 20/6700 loss 23.042715 loss_att 23.965212 loss_ctc 37.018238 loss_rnnt 20.951111 hw_loss 0.081939 lr 0.00037952 rank 3
2023-02-22 15:36:42,176 DEBUG TRAIN Batch 20/6700 loss 8.832528 loss_att 11.153284 loss_ctc 12.446497 loss_rnnt 7.861745 hw_loss 0.046442 lr 0.00037956 rank 2
2023-02-22 15:37:58,960 DEBUG TRAIN Batch 20/6800 loss 19.600588 loss_att 21.545099 loss_ctc 31.314095 loss_rnnt 17.580420 hw_loss 0.130247 lr 0.00037951 rank 4
2023-02-22 15:37:58,963 DEBUG TRAIN Batch 20/6800 loss 10.829635 loss_att 14.532722 loss_ctc 16.287071 loss_rnnt 9.336867 hw_loss 0.045922 lr 0.00037945 rank 7
2023-02-22 15:37:58,964 DEBUG TRAIN Batch 20/6800 loss 7.484049 loss_att 9.702477 loss_ctc 11.999059 loss_rnnt 6.399898 hw_loss 0.072121 lr 0.00037954 rank 5
2023-02-22 15:37:58,968 DEBUG TRAIN Batch 20/6800 loss 16.795782 loss_att 17.700283 loss_ctc 20.712746 loss_rnnt 16.059788 hw_loss 0.061558 lr 0.00037951 rank 0
2023-02-22 15:37:58,969 DEBUG TRAIN Batch 20/6800 loss 9.998746 loss_att 14.301820 loss_ctc 18.819683 loss_rnnt 7.954492 hw_loss 0.014088 lr 0.00037951 rank 6
2023-02-22 15:37:58,972 DEBUG TRAIN Batch 20/6800 loss 14.205011 loss_att 13.930603 loss_ctc 19.226189 loss_rnnt 13.577300 hw_loss 0.024568 lr 0.00037941 rank 3
2023-02-22 15:37:58,975 DEBUG TRAIN Batch 20/6800 loss 7.707695 loss_att 10.484215 loss_ctc 12.962407 loss_rnnt 6.390470 hw_loss 0.114924 lr 0.00037945 rank 2
2023-02-22 15:37:58,992 DEBUG TRAIN Batch 20/6800 loss 10.446287 loss_att 9.789043 loss_ctc 11.838557 loss_rnnt 10.290906 hw_loss 0.189738 lr 0.00037952 rank 1
2023-02-22 15:39:14,062 DEBUG TRAIN Batch 20/6900 loss 10.068357 loss_att 10.834200 loss_ctc 15.261685 loss_rnnt 9.158792 hw_loss 0.119911 lr 0.00037943 rank 5
2023-02-22 15:39:14,065 DEBUG TRAIN Batch 20/6900 loss 11.145151 loss_att 10.610873 loss_ctc 15.001721 loss_rnnt 10.683661 hw_loss 0.101510 lr 0.00037940 rank 0
2023-02-22 15:39:14,065 DEBUG TRAIN Batch 20/6900 loss 11.021009 loss_att 12.856888 loss_ctc 15.327599 loss_rnnt 10.039508 hw_loss 0.075214 lr 0.00037940 rank 4
2023-02-22 15:39:14,069 DEBUG TRAIN Batch 20/6900 loss 5.678684 loss_att 7.007663 loss_ctc 9.076401 loss_rnnt 4.943766 hw_loss 0.030176 lr 0.00037934 rank 7
2023-02-22 15:39:14,072 DEBUG TRAIN Batch 20/6900 loss 9.794810 loss_att 13.025654 loss_ctc 12.214115 loss_rnnt 8.783360 hw_loss 0.080078 lr 0.00037940 rank 6
2023-02-22 15:39:14,074 DEBUG TRAIN Batch 20/6900 loss 14.712796 loss_att 22.029486 loss_ctc 24.868176 loss_rnnt 11.875250 hw_loss 0.037796 lr 0.00037931 rank 3
2023-02-22 15:39:14,075 DEBUG TRAIN Batch 20/6900 loss 7.370579 loss_att 9.203186 loss_ctc 9.328382 loss_rnnt 6.727289 hw_loss 0.029491 lr 0.00037934 rank 2
2023-02-22 15:39:14,078 DEBUG TRAIN Batch 20/6900 loss 33.844563 loss_att 30.103399 loss_ctc 39.586472 loss_rnnt 33.798473 hw_loss 0.053884 lr 0.00037941 rank 1
2023-02-22 15:40:30,019 DEBUG TRAIN Batch 20/7000 loss 12.276177 loss_att 13.381549 loss_ctc 18.399874 loss_rnnt 11.200957 hw_loss 0.070599 lr 0.00037929 rank 0
2023-02-22 15:40:30,020 DEBUG TRAIN Batch 20/7000 loss 4.917358 loss_att 7.703922 loss_ctc 6.604559 loss_rnnt 4.110219 hw_loss 0.046624 lr 0.00037920 rank 3
2023-02-22 15:40:30,021 DEBUG TRAIN Batch 20/7000 loss 10.722817 loss_att 9.972470 loss_ctc 14.360006 loss_rnnt 10.276353 hw_loss 0.209203 lr 0.00037929 rank 4
2023-02-22 15:40:30,024 DEBUG TRAIN Batch 20/7000 loss 9.788971 loss_att 11.776000 loss_ctc 11.118029 loss_rnnt 9.173759 hw_loss 0.076121 lr 0.00037924 rank 7
2023-02-22 15:40:30,024 DEBUG TRAIN Batch 20/7000 loss 22.381958 loss_att 26.025120 loss_ctc 35.169876 loss_rnnt 19.883133 hw_loss 0.122132 lr 0.00037932 rank 5
2023-02-22 15:40:30,025 DEBUG TRAIN Batch 20/7000 loss 6.438579 loss_att 7.538895 loss_ctc 8.277901 loss_rnnt 5.972427 hw_loss 0.001584 lr 0.00037923 rank 2
2023-02-22 15:40:30,026 DEBUG TRAIN Batch 20/7000 loss 14.738135 loss_att 16.993103 loss_ctc 18.131962 loss_rnnt 13.796943 hw_loss 0.070667 lr 0.00037930 rank 1
2023-02-22 15:40:30,028 DEBUG TRAIN Batch 20/7000 loss 10.548247 loss_att 14.069019 loss_ctc 16.785559 loss_rnnt 8.973636 hw_loss 0.072782 lr 0.00037929 rank 6
2023-02-22 15:41:49,061 DEBUG TRAIN Batch 20/7100 loss 4.581982 loss_att 8.415818 loss_ctc 7.779037 loss_rnnt 3.352004 hw_loss 0.069257 lr 0.00037918 rank 0
2023-02-22 15:41:49,064 DEBUG TRAIN Batch 20/7100 loss 15.406361 loss_att 19.226793 loss_ctc 23.797417 loss_rnnt 13.483554 hw_loss 0.074836 lr 0.00037919 rank 1
2023-02-22 15:41:49,065 DEBUG TRAIN Batch 20/7100 loss 8.241320 loss_att 12.443642 loss_ctc 11.143864 loss_rnnt 6.982294 hw_loss 0.059167 lr 0.00037918 rank 4
2023-02-22 15:41:49,068 DEBUG TRAIN Batch 20/7100 loss 16.290220 loss_att 19.171288 loss_ctc 18.399529 loss_rnnt 15.387889 hw_loss 0.084146 lr 0.00037912 rank 2
2023-02-22 15:41:49,070 DEBUG TRAIN Batch 20/7100 loss 8.968573 loss_att 12.739328 loss_ctc 12.928778 loss_rnnt 7.652551 hw_loss 0.063454 lr 0.00037921 rank 5
2023-02-22 15:41:49,070 DEBUG TRAIN Batch 20/7100 loss 13.600530 loss_att 13.621884 loss_ctc 19.775043 loss_rnnt 12.676729 hw_loss 0.180488 lr 0.00037913 rank 7
2023-02-22 15:41:49,071 DEBUG TRAIN Batch 20/7100 loss 12.122696 loss_att 12.993665 loss_ctc 18.466913 loss_rnnt 11.004395 hw_loss 0.184144 lr 0.00037918 rank 6
2023-02-22 15:41:49,073 DEBUG TRAIN Batch 20/7100 loss 7.982012 loss_att 10.002180 loss_ctc 15.136684 loss_rnnt 6.609186 hw_loss 0.027817 lr 0.00037909 rank 3
2023-02-22 15:43:04,668 DEBUG TRAIN Batch 20/7200 loss 11.609207 loss_att 15.111465 loss_ctc 14.545252 loss_rnnt 10.508437 hw_loss 0.016586 lr 0.00037908 rank 0
2023-02-22 15:43:04,672 DEBUG TRAIN Batch 20/7200 loss 4.669782 loss_att 8.175722 loss_ctc 6.829162 loss_rnnt 3.630902 hw_loss 0.093327 lr 0.00037907 rank 4
2023-02-22 15:43:04,673 DEBUG TRAIN Batch 20/7200 loss 8.252504 loss_att 12.674815 loss_ctc 10.583866 loss_rnnt 7.041330 hw_loss 0.029746 lr 0.00037902 rank 7
2023-02-22 15:43:04,674 DEBUG TRAIN Batch 20/7200 loss 9.216918 loss_att 11.289540 loss_ctc 14.145359 loss_rnnt 8.131083 hw_loss 0.026599 lr 0.00037910 rank 5
2023-02-22 15:43:04,681 DEBUG TRAIN Batch 20/7200 loss 13.605344 loss_att 20.417862 loss_ctc 19.997154 loss_rnnt 11.335503 hw_loss 0.103305 lr 0.00037907 rank 6
2023-02-22 15:43:04,681 DEBUG TRAIN Batch 20/7200 loss 6.394960 loss_att 9.421307 loss_ctc 8.961681 loss_rnnt 5.375214 hw_loss 0.135465 lr 0.00037901 rank 2
2023-02-22 15:43:04,682 DEBUG TRAIN Batch 20/7200 loss 8.236067 loss_att 10.617488 loss_ctc 10.671571 loss_rnnt 7.367812 hw_loss 0.126068 lr 0.00037908 rank 1
2023-02-22 15:43:04,720 DEBUG TRAIN Batch 20/7200 loss 3.699360 loss_att 7.847302 loss_ctc 6.970926 loss_rnnt 2.431062 hw_loss 0.004689 lr 0.00037898 rank 3
2023-02-22 15:44:20,091 DEBUG TRAIN Batch 20/7300 loss 11.328780 loss_att 12.594426 loss_ctc 12.486796 loss_rnnt 10.878153 hw_loss 0.080803 lr 0.00037899 rank 5
2023-02-22 15:44:20,091 DEBUG TRAIN Batch 20/7300 loss 3.813823 loss_att 6.228745 loss_ctc 7.739081 loss_rnnt 2.684154 hw_loss 0.231220 lr 0.00037897 rank 0
2023-02-22 15:44:20,093 DEBUG TRAIN Batch 20/7300 loss 10.812267 loss_att 12.318187 loss_ctc 15.821352 loss_rnnt 9.826306 hw_loss 0.031685 lr 0.00037896 rank 6
2023-02-22 15:44:20,093 DEBUG TRAIN Batch 20/7300 loss 6.004225 loss_att 7.875345 loss_ctc 6.672737 loss_rnnt 5.464708 hw_loss 0.142796 lr 0.00037891 rank 7
2023-02-22 15:44:20,094 DEBUG TRAIN Batch 20/7300 loss 9.199555 loss_att 11.523928 loss_ctc 11.421055 loss_rnnt 8.407107 hw_loss 0.058826 lr 0.00037896 rank 4
2023-02-22 15:44:20,093 DEBUG TRAIN Batch 20/7300 loss 9.007616 loss_att 10.455375 loss_ctc 10.339912 loss_rnnt 8.494446 hw_loss 0.086210 lr 0.00037887 rank 3
2023-02-22 15:44:20,097 DEBUG TRAIN Batch 20/7300 loss 4.361134 loss_att 6.985662 loss_ctc 6.674260 loss_rnnt 3.468614 hw_loss 0.110996 lr 0.00037897 rank 1
2023-02-22 15:44:20,098 DEBUG TRAIN Batch 20/7300 loss 8.948881 loss_att 10.848762 loss_ctc 11.385117 loss_rnnt 8.155844 hw_loss 0.165431 lr 0.00037890 rank 2
2023-02-22 15:45:36,412 DEBUG TRAIN Batch 20/7400 loss 8.464798 loss_att 11.744198 loss_ctc 13.622061 loss_rnnt 7.063859 hw_loss 0.107669 lr 0.00037888 rank 5
2023-02-22 15:45:36,415 DEBUG TRAIN Batch 20/7400 loss 26.041939 loss_att 31.886538 loss_ctc 35.448391 loss_rnnt 23.605562 hw_loss 0.024862 lr 0.00037880 rank 7
2023-02-22 15:45:36,417 DEBUG TRAIN Batch 20/7400 loss 12.252980 loss_att 16.680471 loss_ctc 15.693109 loss_rnnt 10.882572 hw_loss 0.049174 lr 0.00037886 rank 0
2023-02-22 15:45:36,418 DEBUG TRAIN Batch 20/7400 loss 13.180703 loss_att 15.245064 loss_ctc 17.783058 loss_rnnt 12.125621 hw_loss 0.053555 lr 0.00037885 rank 4
2023-02-22 15:45:36,420 DEBUG TRAIN Batch 20/7400 loss 8.204086 loss_att 10.350101 loss_ctc 10.890869 loss_rnnt 7.378729 hw_loss 0.071092 lr 0.00037879 rank 2
2023-02-22 15:45:36,420 DEBUG TRAIN Batch 20/7400 loss 9.873910 loss_att 11.667104 loss_ctc 10.965286 loss_rnnt 9.313886 hw_loss 0.104751 lr 0.00037876 rank 3
2023-02-22 15:45:36,421 DEBUG TRAIN Batch 20/7400 loss 11.321781 loss_att 11.132182 loss_ctc 12.755003 loss_rnnt 11.093000 hw_loss 0.141758 lr 0.00037886 rank 1
2023-02-22 15:45:36,423 DEBUG TRAIN Batch 20/7400 loss 15.314464 loss_att 17.663408 loss_ctc 23.118607 loss_rnnt 13.769664 hw_loss 0.064610 lr 0.00037885 rank 6
2023-02-22 15:46:53,363 DEBUG TRAIN Batch 20/7500 loss 7.386611 loss_att 10.732274 loss_ctc 10.949266 loss_rnnt 6.224875 hw_loss 0.032965 lr 0.00037874 rank 4
2023-02-22 15:46:53,368 DEBUG TRAIN Batch 20/7500 loss 12.365712 loss_att 16.567347 loss_ctc 22.850145 loss_rnnt 10.100253 hw_loss 0.051014 lr 0.00037869 rank 7
2023-02-22 15:46:53,369 DEBUG TRAIN Batch 20/7500 loss 6.496667 loss_att 7.330359 loss_ctc 6.636785 loss_rnnt 6.285374 hw_loss 0.048511 lr 0.00037875 rank 1
2023-02-22 15:46:53,370 DEBUG TRAIN Batch 20/7500 loss 11.888243 loss_att 13.672907 loss_ctc 15.618876 loss_rnnt 10.999364 hw_loss 0.064741 lr 0.00037877 rank 5
2023-02-22 15:46:53,371 DEBUG TRAIN Batch 20/7500 loss 9.093127 loss_att 9.490902 loss_ctc 10.181525 loss_rnnt 8.798246 hw_loss 0.131636 lr 0.00037875 rank 0
2023-02-22 15:46:53,375 DEBUG TRAIN Batch 20/7500 loss 8.197901 loss_att 10.982200 loss_ctc 11.299219 loss_rnnt 7.151245 hw_loss 0.143038 lr 0.00037874 rank 6
2023-02-22 15:46:53,389 DEBUG TRAIN Batch 20/7500 loss 15.234668 loss_att 13.728219 loss_ctc 18.832336 loss_rnnt 14.968616 hw_loss 0.164348 lr 0.00037868 rank 2
2023-02-22 15:46:53,392 DEBUG TRAIN Batch 20/7500 loss 12.497643 loss_att 17.662958 loss_ctc 18.405441 loss_rnnt 10.650759 hw_loss 0.048963 lr 0.00037865 rank 3
2023-02-22 15:48:09,438 DEBUG TRAIN Batch 20/7600 loss 12.362645 loss_att 14.462877 loss_ctc 16.966335 loss_rnnt 11.284597 hw_loss 0.082832 lr 0.00037863 rank 4
2023-02-22 15:48:09,438 DEBUG TRAIN Batch 20/7600 loss 5.904644 loss_att 8.964199 loss_ctc 7.776855 loss_rnnt 5.010991 hw_loss 0.060215 lr 0.00037867 rank 5
2023-02-22 15:48:09,442 DEBUG TRAIN Batch 20/7600 loss 5.234077 loss_att 8.089022 loss_ctc 8.032515 loss_rnnt 4.209542 hw_loss 0.150790 lr 0.00037864 rank 0
2023-02-22 15:48:09,443 DEBUG TRAIN Batch 20/7600 loss 14.383433 loss_att 21.185015 loss_ctc 20.375797 loss_rnnt 12.180700 hw_loss 0.081440 lr 0.00037854 rank 3
2023-02-22 15:48:09,447 DEBUG TRAIN Batch 20/7600 loss 11.581683 loss_att 15.392009 loss_ctc 16.479347 loss_rnnt 10.071438 hw_loss 0.178420 lr 0.00037864 rank 1
2023-02-22 15:48:09,448 DEBUG TRAIN Batch 20/7600 loss 19.231901 loss_att 21.942659 loss_ctc 25.539536 loss_rnnt 17.790451 hw_loss 0.109277 lr 0.00037858 rank 7
2023-02-22 15:48:09,449 DEBUG TRAIN Batch 20/7600 loss 7.755325 loss_att 13.711155 loss_ctc 12.415799 loss_rnnt 5.882938 hw_loss 0.112172 lr 0.00037863 rank 6
2023-02-22 15:48:09,496 DEBUG TRAIN Batch 20/7600 loss 9.990938 loss_att 13.314373 loss_ctc 16.450577 loss_rnnt 8.394743 hw_loss 0.131670 lr 0.00037858 rank 2
2023-02-22 15:49:25,733 DEBUG TRAIN Batch 20/7700 loss 2.710943 loss_att 5.954211 loss_ctc 3.746323 loss_rnnt 1.867825 hw_loss 0.105774 lr 0.00037853 rank 0
2023-02-22 15:49:25,735 DEBUG TRAIN Batch 20/7700 loss 11.080856 loss_att 12.091326 loss_ctc 15.568245 loss_rnnt 10.225000 hw_loss 0.103956 lr 0.00037847 rank 7
2023-02-22 15:49:25,741 DEBUG TRAIN Batch 20/7700 loss 8.931612 loss_att 13.002048 loss_ctc 17.864597 loss_rnnt 6.915020 hw_loss 0.021450 lr 0.00037853 rank 4
2023-02-22 15:49:25,743 DEBUG TRAIN Batch 20/7700 loss 15.638799 loss_att 19.514616 loss_ctc 25.949020 loss_rnnt 13.441582 hw_loss 0.088795 lr 0.00037856 rank 5
2023-02-22 15:49:25,745 DEBUG TRAIN Batch 20/7700 loss 12.351807 loss_att 13.052361 loss_ctc 19.626955 loss_rnnt 11.113478 hw_loss 0.240375 lr 0.00037853 rank 6
2023-02-22 15:49:25,746 DEBUG TRAIN Batch 20/7700 loss 3.980640 loss_att 6.512918 loss_ctc 9.636753 loss_rnnt 2.653131 hw_loss 0.125448 lr 0.00037844 rank 3
2023-02-22 15:49:25,745 DEBUG TRAIN Batch 20/7700 loss 2.569654 loss_att 6.136366 loss_ctc 7.852962 loss_rnnt 1.126740 hw_loss 0.047121 lr 0.00037847 rank 2
2023-02-22 15:49:25,780 DEBUG TRAIN Batch 20/7700 loss 15.064483 loss_att 19.852877 loss_ctc 22.201748 loss_rnnt 13.137298 hw_loss 0.033510 lr 0.00037854 rank 1
2023-02-22 15:50:44,654 DEBUG TRAIN Batch 20/7800 loss 8.009070 loss_att 11.150892 loss_ctc 11.318522 loss_rnnt 6.866060 hw_loss 0.137600 lr 0.00037842 rank 0
2023-02-22 15:50:44,658 DEBUG TRAIN Batch 20/7800 loss 2.896131 loss_att 5.073262 loss_ctc 4.640934 loss_rnnt 2.205040 hw_loss 0.043171 lr 0.00037845 rank 5
2023-02-22 15:50:44,659 DEBUG TRAIN Batch 20/7800 loss 9.392397 loss_att 13.256578 loss_ctc 11.307266 loss_rnnt 8.333630 hw_loss 0.057402 lr 0.00037843 rank 1
2023-02-22 15:50:44,661 DEBUG TRAIN Batch 20/7800 loss 3.721537 loss_att 5.866856 loss_ctc 6.819261 loss_rnnt 2.845719 hw_loss 0.063233 lr 0.00037842 rank 4
2023-02-22 15:50:44,661 DEBUG TRAIN Batch 20/7800 loss 22.906633 loss_att 22.284813 loss_ctc 33.318806 loss_rnnt 21.594227 hw_loss 0.090899 lr 0.00037837 rank 7
2023-02-22 15:50:44,661 DEBUG TRAIN Batch 20/7800 loss 13.797180 loss_att 14.716459 loss_ctc 19.274982 loss_rnnt 12.834504 hw_loss 0.090838 lr 0.00037836 rank 2
2023-02-22 15:50:44,665 DEBUG TRAIN Batch 20/7800 loss 5.294484 loss_att 7.775845 loss_ctc 11.076323 loss_rnnt 4.026624 hw_loss 0.001267 lr 0.00037833 rank 3
2023-02-22 15:50:44,712 DEBUG TRAIN Batch 20/7800 loss 4.385188 loss_att 6.631433 loss_ctc 4.903283 loss_rnnt 3.818234 hw_loss 0.091171 lr 0.00037842 rank 6
2023-02-22 15:52:00,777 DEBUG TRAIN Batch 20/7900 loss 7.023484 loss_att 8.942751 loss_ctc 16.106915 loss_rnnt 5.381797 hw_loss 0.087581 lr 0.00037834 rank 5
2023-02-22 15:52:00,781 DEBUG TRAIN Batch 20/7900 loss 8.783141 loss_att 12.074343 loss_ctc 13.273819 loss_rnnt 7.487352 hw_loss 0.072734 lr 0.00037831 rank 0
2023-02-22 15:52:00,784 DEBUG TRAIN Batch 20/7900 loss 13.475939 loss_att 14.764701 loss_ctc 17.923193 loss_rnnt 12.586779 hw_loss 0.072073 lr 0.00037831 rank 4
2023-02-22 15:52:00,784 DEBUG TRAIN Batch 20/7900 loss 13.974350 loss_att 17.118242 loss_ctc 17.503342 loss_rnnt 12.835513 hw_loss 0.074113 lr 0.00037826 rank 7
2023-02-22 15:52:00,785 DEBUG TRAIN Batch 20/7900 loss 3.521681 loss_att 6.592098 loss_ctc 4.323661 loss_rnnt 2.736925 hw_loss 0.119514 lr 0.00037832 rank 1
2023-02-22 15:52:00,788 DEBUG TRAIN Batch 20/7900 loss 4.658232 loss_att 7.538612 loss_ctc 9.071404 loss_rnnt 3.448304 hw_loss 0.085179 lr 0.00037831 rank 6
2023-02-22 15:52:00,788 DEBUG TRAIN Batch 20/7900 loss 7.738465 loss_att 8.618369 loss_ctc 9.773331 loss_rnnt 7.273791 hw_loss 0.032584 lr 0.00037822 rank 3
2023-02-22 15:52:00,832 DEBUG TRAIN Batch 20/7900 loss 10.347758 loss_att 13.770186 loss_ctc 16.489201 loss_rnnt 8.812179 hw_loss 0.060442 lr 0.00037825 rank 2
2023-02-22 15:53:15,799 DEBUG TRAIN Batch 20/8000 loss 6.213025 loss_att 11.415705 loss_ctc 9.562365 loss_rnnt 4.665187 hw_loss 0.113855 lr 0.00037823 rank 5
2023-02-22 15:53:15,804 DEBUG TRAIN Batch 20/8000 loss 13.378073 loss_att 15.026551 loss_ctc 15.078083 loss_rnnt 12.796760 hw_loss 0.046780 lr 0.00037815 rank 7
2023-02-22 15:53:15,807 DEBUG TRAIN Batch 20/8000 loss 9.152206 loss_att 12.513169 loss_ctc 11.502728 loss_rnnt 8.145262 hw_loss 0.040030 lr 0.00037821 rank 0
2023-02-22 15:53:15,808 DEBUG TRAIN Batch 20/8000 loss 9.371019 loss_att 9.658139 loss_ctc 8.343242 loss_rnnt 9.418591 hw_loss 0.060077 lr 0.00037820 rank 4
2023-02-22 15:53:15,810 DEBUG TRAIN Batch 20/8000 loss 9.566567 loss_att 11.346497 loss_ctc 16.305614 loss_rnnt 8.243003 hw_loss 0.129451 lr 0.00037811 rank 3
2023-02-22 15:53:15,810 DEBUG TRAIN Batch 20/8000 loss 15.823571 loss_att 17.494959 loss_ctc 23.086500 loss_rnnt 14.476193 hw_loss 0.083831 lr 0.00037821 rank 1
2023-02-22 15:53:15,812 DEBUG TRAIN Batch 20/8000 loss 6.070117 loss_att 8.224483 loss_ctc 8.225574 loss_rnnt 5.296811 hw_loss 0.103198 lr 0.00037820 rank 6
2023-02-22 15:53:15,814 DEBUG TRAIN Batch 20/8000 loss 12.525599 loss_att 14.922438 loss_ctc 17.370234 loss_rnnt 11.348685 hw_loss 0.096744 lr 0.00037814 rank 2
2023-02-22 15:54:30,053 DEBUG TRAIN Batch 20/8100 loss 17.786207 loss_att 24.163582 loss_ctc 23.739651 loss_rnnt 15.620726 hw_loss 0.180403 lr 0.00037809 rank 4
2023-02-22 15:54:30,057 DEBUG TRAIN Batch 20/8100 loss 6.982787 loss_att 9.571723 loss_ctc 9.506981 loss_rnnt 6.051216 hw_loss 0.144797 lr 0.00037812 rank 5
2023-02-22 15:54:30,059 DEBUG TRAIN Batch 20/8100 loss 14.428740 loss_att 17.184692 loss_ctc 20.253052 loss_rnnt 13.052972 hw_loss 0.090003 lr 0.00037804 rank 7
2023-02-22 15:54:30,060 DEBUG TRAIN Batch 20/8100 loss 9.258134 loss_att 9.045987 loss_ctc 13.589530 loss_rnnt 8.648740 hw_loss 0.139320 lr 0.00037810 rank 1
2023-02-22 15:54:30,061 DEBUG TRAIN Batch 20/8100 loss 10.686919 loss_att 15.969704 loss_ctc 17.057283 loss_rnnt 8.712821 hw_loss 0.127799 lr 0.00037810 rank 0
2023-02-22 15:54:30,061 DEBUG TRAIN Batch 20/8100 loss 6.777025 loss_att 8.365198 loss_ctc 11.095060 loss_rnnt 5.833290 hw_loss 0.094428 lr 0.00037803 rank 2
2023-02-22 15:54:30,062 DEBUG TRAIN Batch 20/8100 loss 8.049271 loss_att 13.047395 loss_ctc 13.873777 loss_rnnt 6.237965 hw_loss 0.065776 lr 0.00037800 rank 3
2023-02-22 15:54:30,065 DEBUG TRAIN Batch 20/8100 loss 7.222971 loss_att 10.593979 loss_ctc 13.810322 loss_rnnt 5.622395 hw_loss 0.090115 lr 0.00037809 rank 6
2023-02-22 15:55:46,742 DEBUG TRAIN Batch 20/8200 loss 9.783553 loss_att 9.263070 loss_ctc 11.578856 loss_rnnt 9.596754 hw_loss 0.096603 lr 0.00037798 rank 4
2023-02-22 15:55:46,742 DEBUG TRAIN Batch 20/8200 loss 11.889446 loss_att 14.540478 loss_ctc 16.572096 loss_rnnt 10.684484 hw_loss 0.094504 lr 0.00037799 rank 1
2023-02-22 15:55:46,744 DEBUG TRAIN Batch 20/8200 loss 11.330842 loss_att 33.282406 loss_ctc 19.557568 loss_rnnt 5.818704 hw_loss 0.046743 lr 0.00037799 rank 0
2023-02-22 15:55:46,750 DEBUG TRAIN Batch 20/8200 loss 9.067875 loss_att 8.643276 loss_ctc 11.294505 loss_rnnt 8.784771 hw_loss 0.133386 lr 0.00037802 rank 5
2023-02-22 15:55:46,750 DEBUG TRAIN Batch 20/8200 loss 16.390924 loss_att 17.247293 loss_ctc 24.269478 loss_rnnt 15.150919 hw_loss 0.034231 lr 0.00037793 rank 7
2023-02-22 15:55:46,753 DEBUG TRAIN Batch 20/8200 loss 4.240554 loss_att 7.466634 loss_ctc 5.865896 loss_rnnt 3.316632 hw_loss 0.116237 lr 0.00037789 rank 3
2023-02-22 15:55:46,753 DEBUG TRAIN Batch 20/8200 loss 8.304336 loss_att 9.541264 loss_ctc 11.158288 loss_rnnt 7.647656 hw_loss 0.053938 lr 0.00037798 rank 6
2023-02-22 15:55:46,798 DEBUG TRAIN Batch 20/8200 loss 15.007749 loss_att 14.841106 loss_ctc 17.067900 loss_rnnt 14.742157 hw_loss 0.045437 lr 0.00037793 rank 2
2023-02-22 15:57:00,675 DEBUG TRAIN Batch 20/8300 loss 14.306515 loss_att 20.500738 loss_ctc 25.431410 loss_rnnt 11.539038 hw_loss 0.084963 lr 0.00037782 rank 2
2023-02-22 15:57:00,680 DEBUG TRAIN Batch 20/8300 loss 10.459357 loss_att 13.193903 loss_ctc 13.633449 loss_rnnt 9.484683 hw_loss 0.008534 lr 0.00037788 rank 6
2023-02-22 15:57:00,680 DEBUG TRAIN Batch 20/8300 loss 8.011401 loss_att 15.928871 loss_ctc 11.411892 loss_rnnt 5.970261 hw_loss 0.007965 lr 0.00037788 rank 4
2023-02-22 15:57:00,681 DEBUG TRAIN Batch 20/8300 loss 13.970949 loss_att 23.495338 loss_ctc 25.081366 loss_rnnt 10.528566 hw_loss 0.105219 lr 0.00037791 rank 5
2023-02-22 15:57:00,682 DEBUG TRAIN Batch 20/8300 loss 13.578393 loss_att 13.766191 loss_ctc 13.452991 loss_rnnt 13.533015 hw_loss 0.046009 lr 0.00037789 rank 1
2023-02-22 15:57:00,706 DEBUG TRAIN Batch 20/8300 loss 24.114502 loss_att 23.945818 loss_ctc 27.905102 loss_rnnt 23.611137 hw_loss 0.059412 lr 0.00037783 rank 7
2023-02-22 15:57:00,711 DEBUG TRAIN Batch 20/8300 loss 5.884769 loss_att 7.678573 loss_ctc 13.809446 loss_rnnt 4.441741 hw_loss 0.051833 lr 0.00037788 rank 0
2023-02-22 15:57:00,730 DEBUG TRAIN Batch 20/8300 loss 11.724719 loss_att 13.763176 loss_ctc 19.059177 loss_rnnt 10.311704 hw_loss 0.051366 lr 0.00037779 rank 3
2023-02-22 15:57:59,006 DEBUG CV Batch 20/0 loss 2.350302 loss_att 2.462162 loss_ctc 3.159724 loss_rnnt 2.114366 hw_loss 0.198078 history loss 2.263254 rank 4
2023-02-22 15:57:59,008 DEBUG CV Batch 20/0 loss 2.350302 loss_att 2.462162 loss_ctc 3.159724 loss_rnnt 2.114366 hw_loss 0.198078 history loss 2.263254 rank 0
2023-02-22 15:57:59,010 DEBUG CV Batch 20/0 loss 2.350302 loss_att 2.462162 loss_ctc 3.159724 loss_rnnt 2.114366 hw_loss 0.198078 history loss 2.263254 rank 5
2023-02-22 15:57:59,012 DEBUG CV Batch 20/0 loss 2.350302 loss_att 2.462162 loss_ctc 3.159724 loss_rnnt 2.114366 hw_loss 0.198078 history loss 2.263254 rank 3
2023-02-22 15:57:59,014 DEBUG CV Batch 20/0 loss 2.350302 loss_att 2.462162 loss_ctc 3.159724 loss_rnnt 2.114366 hw_loss 0.198078 history loss 2.263254 rank 2
2023-02-22 15:57:59,015 DEBUG CV Batch 20/0 loss 2.350302 loss_att 2.462162 loss_ctc 3.159724 loss_rnnt 2.114366 hw_loss 0.198078 history loss 2.263254 rank 6
2023-02-22 15:57:59,025 DEBUG CV Batch 20/0 loss 2.350302 loss_att 2.462162 loss_ctc 3.159724 loss_rnnt 2.114366 hw_loss 0.198078 history loss 2.263254 rank 7
2023-02-22 15:57:59,033 DEBUG CV Batch 20/0 loss 2.350302 loss_att 2.462162 loss_ctc 3.159724 loss_rnnt 2.114366 hw_loss 0.198078 history loss 2.263254 rank 1
2023-02-22 15:58:10,079 DEBUG CV Batch 20/100 loss 7.834814 loss_att 7.247038 loss_ctc 9.880232 loss_rnnt 7.647736 hw_loss 0.059833 history loss 3.549367 rank 4
2023-02-22 15:58:10,121 DEBUG CV Batch 20/100 loss 7.834814 loss_att 7.247038 loss_ctc 9.880232 loss_rnnt 7.647736 hw_loss 0.059833 history loss 3.549367 rank 0
2023-02-22 15:58:10,184 DEBUG CV Batch 20/100 loss 7.834814 loss_att 7.247038 loss_ctc 9.880232 loss_rnnt 7.647736 hw_loss 0.059833 history loss 3.549367 rank 5
2023-02-22 15:58:10,253 DEBUG CV Batch 20/100 loss 7.834814 loss_att 7.247038 loss_ctc 9.880232 loss_rnnt 7.647736 hw_loss 0.059833 history loss 3.549367 rank 7
2023-02-22 15:58:10,297 DEBUG CV Batch 20/100 loss 7.834814 loss_att 7.247038 loss_ctc 9.880232 loss_rnnt 7.647736 hw_loss 0.059833 history loss 3.549367 rank 3
2023-02-22 15:58:10,387 DEBUG CV Batch 20/100 loss 7.834814 loss_att 7.247038 loss_ctc 9.880232 loss_rnnt 7.647736 hw_loss 0.059833 history loss 3.549367 rank 2
2023-02-22 15:58:10,513 DEBUG CV Batch 20/100 loss 7.834814 loss_att 7.247038 loss_ctc 9.880232 loss_rnnt 7.647736 hw_loss 0.059833 history loss 3.549367 rank 6
2023-02-22 15:58:11,065 DEBUG CV Batch 20/100 loss 7.834814 loss_att 7.247038 loss_ctc 9.880232 loss_rnnt 7.647736 hw_loss 0.059833 history loss 3.549367 rank 1
2023-02-22 15:58:23,430 DEBUG CV Batch 20/200 loss 7.204723 loss_att 14.022776 loss_ctc 6.578566 loss_rnnt 5.909265 hw_loss 0.028753 history loss 4.172675 rank 4
2023-02-22 15:58:23,527 DEBUG CV Batch 20/200 loss 7.204723 loss_att 14.022776 loss_ctc 6.578566 loss_rnnt 5.909265 hw_loss 0.028753 history loss 4.172675 rank 0
2023-02-22 15:58:23,575 DEBUG CV Batch 20/200 loss 7.204723 loss_att 14.022776 loss_ctc 6.578566 loss_rnnt 5.909265 hw_loss 0.028753 history loss 4.172675 rank 7
2023-02-22 15:58:23,584 DEBUG CV Batch 20/200 loss 7.204723 loss_att 14.022776 loss_ctc 6.578566 loss_rnnt 5.909265 hw_loss 0.028753 history loss 4.172675 rank 5
2023-02-22 15:58:23,809 DEBUG CV Batch 20/200 loss 7.204723 loss_att 14.022776 loss_ctc 6.578566 loss_rnnt 5.909265 hw_loss 0.028753 history loss 4.172675 rank 3
2023-02-22 15:58:23,997 DEBUG CV Batch 20/200 loss 7.204723 loss_att 14.022776 loss_ctc 6.578566 loss_rnnt 5.909265 hw_loss 0.028753 history loss 4.172675 rank 6
2023-02-22 15:58:24,481 DEBUG CV Batch 20/200 loss 7.204723 loss_att 14.022776 loss_ctc 6.578566 loss_rnnt 5.909265 hw_loss 0.028753 history loss 4.172675 rank 1
2023-02-22 15:58:24,920 DEBUG CV Batch 20/200 loss 7.204723 loss_att 14.022776 loss_ctc 6.578566 loss_rnnt 5.909265 hw_loss 0.028753 history loss 4.172675 rank 2
2023-02-22 15:58:35,453 DEBUG CV Batch 20/300 loss 4.910377 loss_att 5.208321 loss_ctc 6.733314 loss_rnnt 4.569248 hw_loss 0.072154 history loss 4.289148 rank 4
2023-02-22 15:58:35,601 DEBUG CV Batch 20/300 loss 4.910377 loss_att 5.208321 loss_ctc 6.733314 loss_rnnt 4.569248 hw_loss 0.072154 history loss 4.289148 rank 0
2023-02-22 15:58:35,611 DEBUG CV Batch 20/300 loss 4.910377 loss_att 5.208321 loss_ctc 6.733314 loss_rnnt 4.569248 hw_loss 0.072154 history loss 4.289148 rank 7
2023-02-22 15:58:35,652 DEBUG CV Batch 20/300 loss 4.910377 loss_att 5.208321 loss_ctc 6.733314 loss_rnnt 4.569248 hw_loss 0.072154 history loss 4.289148 rank 5
2023-02-22 15:58:35,995 DEBUG CV Batch 20/300 loss 4.910377 loss_att 5.208321 loss_ctc 6.733314 loss_rnnt 4.569248 hw_loss 0.072154 history loss 4.289148 rank 3
2023-02-22 15:58:36,200 DEBUG CV Batch 20/300 loss 4.910377 loss_att 5.208321 loss_ctc 6.733314 loss_rnnt 4.569248 hw_loss 0.072154 history loss 4.289148 rank 6
2023-02-22 15:58:36,713 DEBUG CV Batch 20/300 loss 4.910377 loss_att 5.208321 loss_ctc 6.733314 loss_rnnt 4.569248 hw_loss 0.072154 history loss 4.289148 rank 1
2023-02-22 15:58:38,412 DEBUG CV Batch 20/300 loss 4.910377 loss_att 5.208321 loss_ctc 6.733314 loss_rnnt 4.569248 hw_loss 0.072154 history loss 4.289148 rank 2
2023-02-22 15:58:47,540 DEBUG CV Batch 20/400 loss 19.287865 loss_att 94.492126 loss_ctc 9.611323 loss_rnnt 5.500931 hw_loss 0.068037 history loss 5.267761 rank 4
2023-02-22 15:58:47,725 DEBUG CV Batch 20/400 loss 19.287865 loss_att 94.492126 loss_ctc 9.611323 loss_rnnt 5.500931 hw_loss 0.068037 history loss 5.267761 rank 0
2023-02-22 15:58:47,739 DEBUG CV Batch 20/400 loss 19.287865 loss_att 94.492126 loss_ctc 9.611323 loss_rnnt 5.500931 hw_loss 0.068037 history loss 5.267761 rank 7
2023-02-22 15:58:47,830 DEBUG CV Batch 20/400 loss 19.287865 loss_att 94.492126 loss_ctc 9.611323 loss_rnnt 5.500931 hw_loss 0.068037 history loss 5.267761 rank 5
2023-02-22 15:58:48,177 DEBUG CV Batch 20/400 loss 19.287865 loss_att 94.492126 loss_ctc 9.611323 loss_rnnt 5.500931 hw_loss 0.068037 history loss 5.267761 rank 3
2023-02-22 15:58:48,392 DEBUG CV Batch 20/400 loss 19.287865 loss_att 94.492126 loss_ctc 9.611323 loss_rnnt 5.500931 hw_loss 0.068037 history loss 5.267761 rank 6
2023-02-22 15:58:49,299 DEBUG CV Batch 20/400 loss 19.287865 loss_att 94.492126 loss_ctc 9.611323 loss_rnnt 5.500931 hw_loss 0.068037 history loss 5.267761 rank 1
2023-02-22 15:58:50,567 DEBUG CV Batch 20/400 loss 19.287865 loss_att 94.492126 loss_ctc 9.611323 loss_rnnt 5.500931 hw_loss 0.068037 history loss 5.267761 rank 2
2023-02-22 15:58:58,042 DEBUG CV Batch 20/500 loss 6.480036 loss_att 6.871026 loss_ctc 8.348240 loss_rnnt 6.109197 hw_loss 0.081651 history loss 6.104671 rank 4
2023-02-22 15:58:58,231 DEBUG CV Batch 20/500 loss 6.480036 loss_att 6.871026 loss_ctc 8.348240 loss_rnnt 6.109197 hw_loss 0.081651 history loss 6.104671 rank 0
2023-02-22 15:58:58,261 DEBUG CV Batch 20/500 loss 6.480036 loss_att 6.871026 loss_ctc 8.348240 loss_rnnt 6.109197 hw_loss 0.081651 history loss 6.104671 rank 7
2023-02-22 15:58:58,435 DEBUG CV Batch 20/500 loss 6.480036 loss_att 6.871026 loss_ctc 8.348240 loss_rnnt 6.109197 hw_loss 0.081651 history loss 6.104671 rank 5
2023-02-22 15:58:58,909 DEBUG CV Batch 20/500 loss 6.480036 loss_att 6.871026 loss_ctc 8.348240 loss_rnnt 6.109197 hw_loss 0.081651 history loss 6.104671 rank 3
2023-02-22 15:58:58,998 DEBUG CV Batch 20/500 loss 6.480036 loss_att 6.871026 loss_ctc 8.348240 loss_rnnt 6.109197 hw_loss 0.081651 history loss 6.104671 rank 6
2023-02-22 15:59:00,297 DEBUG CV Batch 20/500 loss 6.480036 loss_att 6.871026 loss_ctc 8.348240 loss_rnnt 6.109197 hw_loss 0.081651 history loss 6.104671 rank 1
2023-02-22 15:59:01,394 DEBUG CV Batch 20/500 loss 6.480036 loss_att 6.871026 loss_ctc 8.348240 loss_rnnt 6.109197 hw_loss 0.081651 history loss 6.104671 rank 2
2023-02-22 15:59:10,186 DEBUG CV Batch 20/600 loss 7.050389 loss_att 7.297839 loss_ctc 10.118950 loss_rnnt 6.481992 hw_loss 0.205810 history loss 7.065866 rank 4
2023-02-22 15:59:10,290 DEBUG CV Batch 20/600 loss 7.050389 loss_att 7.297839 loss_ctc 10.118950 loss_rnnt 6.481992 hw_loss 0.205810 history loss 7.065866 rank 7
2023-02-22 15:59:10,342 DEBUG CV Batch 20/600 loss 7.050389 loss_att 7.297839 loss_ctc 10.118950 loss_rnnt 6.481992 hw_loss 0.205810 history loss 7.065866 rank 0
2023-02-22 15:59:10,451 DEBUG CV Batch 20/600 loss 7.050389 loss_att 7.297839 loss_ctc 10.118950 loss_rnnt 6.481992 hw_loss 0.205810 history loss 7.065866 rank 5
2023-02-22 15:59:11,072 DEBUG CV Batch 20/600 loss 7.050389 loss_att 7.297839 loss_ctc 10.118950 loss_rnnt 6.481992 hw_loss 0.205810 history loss 7.065866 rank 3
2023-02-22 15:59:11,236 DEBUG CV Batch 20/600 loss 7.050389 loss_att 7.297839 loss_ctc 10.118950 loss_rnnt 6.481992 hw_loss 0.205810 history loss 7.065866 rank 6
2023-02-22 15:59:12,658 DEBUG CV Batch 20/600 loss 7.050389 loss_att 7.297839 loss_ctc 10.118950 loss_rnnt 6.481992 hw_loss 0.205810 history loss 7.065866 rank 1
2023-02-22 15:59:13,679 DEBUG CV Batch 20/600 loss 7.050389 loss_att 7.297839 loss_ctc 10.118950 loss_rnnt 6.481992 hw_loss 0.205810 history loss 7.065866 rank 2
2023-02-22 15:59:21,551 DEBUG CV Batch 20/700 loss 13.553175 loss_att 41.064804 loss_ctc 19.230257 loss_rnnt 7.209275 hw_loss 0.158679 history loss 7.755722 rank 4
2023-02-22 15:59:21,682 DEBUG CV Batch 20/700 loss 13.553175 loss_att 41.064804 loss_ctc 19.230257 loss_rnnt 7.209275 hw_loss 0.158679 history loss 7.755722 rank 0
2023-02-22 15:59:21,702 DEBUG CV Batch 20/700 loss 13.553175 loss_att 41.064804 loss_ctc 19.230257 loss_rnnt 7.209275 hw_loss 0.158679 history loss 7.755722 rank 7
2023-02-22 15:59:21,961 DEBUG CV Batch 20/700 loss 13.553175 loss_att 41.064804 loss_ctc 19.230257 loss_rnnt 7.209275 hw_loss 0.158679 history loss 7.755722 rank 5
2023-02-22 15:59:22,581 DEBUG CV Batch 20/700 loss 13.553175 loss_att 41.064804 loss_ctc 19.230257 loss_rnnt 7.209275 hw_loss 0.158679 history loss 7.755722 rank 3
2023-02-22 15:59:22,698 DEBUG CV Batch 20/700 loss 13.553175 loss_att 41.064804 loss_ctc 19.230257 loss_rnnt 7.209275 hw_loss 0.158679 history loss 7.755722 rank 6
2023-02-22 15:59:24,085 DEBUG CV Batch 20/700 loss 13.553175 loss_att 41.064804 loss_ctc 19.230257 loss_rnnt 7.209275 hw_loss 0.158679 history loss 7.755722 rank 1
2023-02-22 15:59:26,016 DEBUG CV Batch 20/700 loss 13.553175 loss_att 41.064804 loss_ctc 19.230257 loss_rnnt 7.209275 hw_loss 0.158679 history loss 7.755722 rank 2
2023-02-22 15:59:32,792 DEBUG CV Batch 20/800 loss 11.924357 loss_att 9.900885 loss_ctc 14.828388 loss_rnnt 11.885792 hw_loss 0.105106 history loss 7.186228 rank 4
2023-02-22 15:59:32,835 DEBUG CV Batch 20/800 loss 11.924357 loss_att 9.900885 loss_ctc 14.828388 loss_rnnt 11.885792 hw_loss 0.105106 history loss 7.186228 rank 0
2023-02-22 15:59:32,911 DEBUG CV Batch 20/800 loss 11.924357 loss_att 9.900885 loss_ctc 14.828388 loss_rnnt 11.885792 hw_loss 0.105106 history loss 7.186228 rank 7
2023-02-22 15:59:33,218 DEBUG CV Batch 20/800 loss 11.924357 loss_att 9.900885 loss_ctc 14.828388 loss_rnnt 11.885792 hw_loss 0.105106 history loss 7.186228 rank 5
2023-02-22 15:59:33,965 DEBUG CV Batch 20/800 loss 11.924357 loss_att 9.900885 loss_ctc 14.828388 loss_rnnt 11.885792 hw_loss 0.105106 history loss 7.186228 rank 6
2023-02-22 15:59:33,985 DEBUG CV Batch 20/800 loss 11.924357 loss_att 9.900885 loss_ctc 14.828388 loss_rnnt 11.885792 hw_loss 0.105106 history loss 7.186228 rank 3
2023-02-22 15:59:35,482 DEBUG CV Batch 20/800 loss 11.924357 loss_att 9.900885 loss_ctc 14.828388 loss_rnnt 11.885792 hw_loss 0.105106 history loss 7.186228 rank 1
2023-02-22 15:59:38,706 DEBUG CV Batch 20/800 loss 11.924357 loss_att 9.900885 loss_ctc 14.828388 loss_rnnt 11.885792 hw_loss 0.105106 history loss 7.186228 rank 2
2023-02-22 15:59:45,986 DEBUG CV Batch 20/900 loss 14.367117 loss_att 16.231752 loss_ctc 20.359032 loss_rnnt 13.164226 hw_loss 0.058206 history loss 6.975680 rank 4
2023-02-22 15:59:46,041 DEBUG CV Batch 20/900 loss 14.367117 loss_att 16.231752 loss_ctc 20.359032 loss_rnnt 13.164226 hw_loss 0.058206 history loss 6.975680 rank 0
2023-02-22 15:59:46,101 DEBUG CV Batch 20/900 loss 14.367117 loss_att 16.231752 loss_ctc 20.359032 loss_rnnt 13.164226 hw_loss 0.058206 history loss 6.975680 rank 7
2023-02-22 15:59:46,551 DEBUG CV Batch 20/900 loss 14.367117 loss_att 16.231752 loss_ctc 20.359032 loss_rnnt 13.164226 hw_loss 0.058206 history loss 6.975680 rank 5
2023-02-22 15:59:47,316 DEBUG CV Batch 20/900 loss 14.367117 loss_att 16.231752 loss_ctc 20.359032 loss_rnnt 13.164226 hw_loss 0.058206 history loss 6.975680 rank 3
2023-02-22 15:59:47,359 DEBUG CV Batch 20/900 loss 14.367117 loss_att 16.231752 loss_ctc 20.359032 loss_rnnt 13.164226 hw_loss 0.058206 history loss 6.975680 rank 6
2023-02-22 15:59:48,788 DEBUG CV Batch 20/900 loss 14.367117 loss_att 16.231752 loss_ctc 20.359032 loss_rnnt 13.164226 hw_loss 0.058206 history loss 6.975680 rank 1
2023-02-22 15:59:52,102 DEBUG CV Batch 20/900 loss 14.367117 loss_att 16.231752 loss_ctc 20.359032 loss_rnnt 13.164226 hw_loss 0.058206 history loss 6.975680 rank 2
2023-02-22 15:59:58,135 DEBUG CV Batch 20/1000 loss 4.749884 loss_att 5.113583 loss_ctc 4.750858 loss_rnnt 4.575962 hw_loss 0.189474 history loss 6.727110 rank 4
2023-02-22 15:59:58,202 DEBUG CV Batch 20/1000 loss 4.749884 loss_att 5.113583 loss_ctc 4.750858 loss_rnnt 4.575962 hw_loss 0.189474 history loss 6.727110 rank 7
2023-02-22 15:59:58,244 DEBUG CV Batch 20/1000 loss 4.749884 loss_att 5.113583 loss_ctc 4.750858 loss_rnnt 4.575962 hw_loss 0.189474 history loss 6.727110 rank 0
2023-02-22 15:59:58,631 DEBUG CV Batch 20/1000 loss 4.749884 loss_att 5.113583 loss_ctc 4.750858 loss_rnnt 4.575962 hw_loss 0.189474 history loss 6.727110 rank 5
2023-02-22 15:59:59,553 DEBUG CV Batch 20/1000 loss 4.749884 loss_att 5.113583 loss_ctc 4.750858 loss_rnnt 4.575962 hw_loss 0.189474 history loss 6.727110 rank 3
2023-02-22 15:59:59,775 DEBUG CV Batch 20/1000 loss 4.749884 loss_att 5.113583 loss_ctc 4.750858 loss_rnnt 4.575962 hw_loss 0.189474 history loss 6.727110 rank 6
2023-02-22 16:00:01,143 DEBUG CV Batch 20/1000 loss 4.749884 loss_att 5.113583 loss_ctc 4.750858 loss_rnnt 4.575962 hw_loss 0.189474 history loss 6.727110 rank 1
2023-02-22 16:00:04,616 DEBUG CV Batch 20/1000 loss 4.749884 loss_att 5.113583 loss_ctc 4.750858 loss_rnnt 4.575962 hw_loss 0.189474 history loss 6.727110 rank 2
2023-02-22 16:00:09,984 DEBUG CV Batch 20/1100 loss 7.077489 loss_att 6.509177 loss_ctc 9.349683 loss_rnnt 6.777405 hw_loss 0.207725 history loss 6.716006 rank 4
2023-02-22 16:00:10,058 DEBUG CV Batch 20/1100 loss 7.077489 loss_att 6.509177 loss_ctc 9.349683 loss_rnnt 6.777405 hw_loss 0.207725 history loss 6.716006 rank 7
2023-02-22 16:00:10,128 DEBUG CV Batch 20/1100 loss 7.077489 loss_att 6.509177 loss_ctc 9.349683 loss_rnnt 6.777405 hw_loss 0.207725 history loss 6.716006 rank 0
2023-02-22 16:00:10,635 DEBUG CV Batch 20/1100 loss 7.077489 loss_att 6.509177 loss_ctc 9.349683 loss_rnnt 6.777405 hw_loss 0.207725 history loss 6.716006 rank 5
2023-02-22 16:00:11,539 DEBUG CV Batch 20/1100 loss 7.077489 loss_att 6.509177 loss_ctc 9.349683 loss_rnnt 6.777405 hw_loss 0.207725 history loss 6.716006 rank 3
2023-02-22 16:00:11,761 DEBUG CV Batch 20/1100 loss 7.077489 loss_att 6.509177 loss_ctc 9.349683 loss_rnnt 6.777405 hw_loss 0.207725 history loss 6.716006 rank 6
2023-02-22 16:00:13,246 DEBUG CV Batch 20/1100 loss 7.077489 loss_att 6.509177 loss_ctc 9.349683 loss_rnnt 6.777405 hw_loss 0.207725 history loss 6.716006 rank 1
2023-02-22 16:00:16,647 DEBUG CV Batch 20/1100 loss 7.077489 loss_att 6.509177 loss_ctc 9.349683 loss_rnnt 6.777405 hw_loss 0.207725 history loss 6.716006 rank 2
2023-02-22 16:00:20,497 DEBUG CV Batch 20/1200 loss 8.427683 loss_att 9.165368 loss_ctc 11.826512 loss_rnnt 7.764591 hw_loss 0.116958 history loss 7.063245 rank 7
2023-02-22 16:00:20,499 DEBUG CV Batch 20/1200 loss 8.427683 loss_att 9.165368 loss_ctc 11.826512 loss_rnnt 7.764591 hw_loss 0.116958 history loss 7.063245 rank 4
2023-02-22 16:00:20,618 DEBUG CV Batch 20/1200 loss 8.427683 loss_att 9.165368 loss_ctc 11.826512 loss_rnnt 7.764591 hw_loss 0.116958 history loss 7.063245 rank 0
2023-02-22 16:00:21,235 DEBUG CV Batch 20/1200 loss 8.427683 loss_att 9.165368 loss_ctc 11.826512 loss_rnnt 7.764591 hw_loss 0.116958 history loss 7.063245 rank 5
2023-02-22 16:00:22,260 DEBUG CV Batch 20/1200 loss 8.427683 loss_att 9.165368 loss_ctc 11.826512 loss_rnnt 7.764591 hw_loss 0.116958 history loss 7.063245 rank 3
2023-02-22 16:00:23,058 DEBUG CV Batch 20/1200 loss 8.427683 loss_att 9.165368 loss_ctc 11.826512 loss_rnnt 7.764591 hw_loss 0.116958 history loss 7.063245 rank 6
2023-02-22 16:00:24,088 DEBUG CV Batch 20/1200 loss 8.427683 loss_att 9.165368 loss_ctc 11.826512 loss_rnnt 7.764591 hw_loss 0.116958 history loss 7.063245 rank 1
2023-02-22 16:00:27,470 DEBUG CV Batch 20/1200 loss 8.427683 loss_att 9.165368 loss_ctc 11.826512 loss_rnnt 7.764591 hw_loss 0.116958 history loss 7.063245 rank 2
2023-02-22 16:00:32,430 DEBUG CV Batch 20/1300 loss 5.624879 loss_att 5.562391 loss_ctc 7.396772 loss_rnnt 5.354100 hw_loss 0.088168 history loss 7.379493 rank 7
2023-02-22 16:00:32,483 DEBUG CV Batch 20/1300 loss 5.624879 loss_att 5.562391 loss_ctc 7.396772 loss_rnnt 5.354100 hw_loss 0.088168 history loss 7.379493 rank 0
2023-02-22 16:00:32,483 DEBUG CV Batch 20/1300 loss 5.624879 loss_att 5.562391 loss_ctc 7.396772 loss_rnnt 5.354100 hw_loss 0.088168 history loss 7.379493 rank 4
2023-02-22 16:00:33,253 DEBUG CV Batch 20/1300 loss 5.624879 loss_att 5.562391 loss_ctc 7.396772 loss_rnnt 5.354100 hw_loss 0.088168 history loss 7.379493 rank 5
2023-02-22 16:00:34,518 DEBUG CV Batch 20/1300 loss 5.624879 loss_att 5.562391 loss_ctc 7.396772 loss_rnnt 5.354100 hw_loss 0.088168 history loss 7.379493 rank 3
2023-02-22 16:00:35,272 DEBUG CV Batch 20/1300 loss 5.624879 loss_att 5.562391 loss_ctc 7.396772 loss_rnnt 5.354100 hw_loss 0.088168 history loss 7.379493 rank 6
2023-02-22 16:00:36,210 DEBUG CV Batch 20/1300 loss 5.624879 loss_att 5.562391 loss_ctc 7.396772 loss_rnnt 5.354100 hw_loss 0.088168 history loss 7.379493 rank 1
2023-02-22 16:00:39,546 DEBUG CV Batch 20/1300 loss 5.624879 loss_att 5.562391 loss_ctc 7.396772 loss_rnnt 5.354100 hw_loss 0.088168 history loss 7.379493 rank 2
2023-02-22 16:00:43,557 DEBUG CV Batch 20/1400 loss 10.083320 loss_att 26.169277 loss_ctc 7.030081 loss_rnnt 7.229214 hw_loss 0.082524 history loss 7.718446 rank 7
2023-02-22 16:00:43,636 DEBUG CV Batch 20/1400 loss 10.083320 loss_att 26.169277 loss_ctc 7.030081 loss_rnnt 7.229214 hw_loss 0.082524 history loss 7.718446 rank 0
2023-02-22 16:00:43,760 DEBUG CV Batch 20/1400 loss 10.083320 loss_att 26.169277 loss_ctc 7.030081 loss_rnnt 7.229214 hw_loss 0.082524 history loss 7.718446 rank 4
2023-02-22 16:00:44,526 DEBUG CV Batch 20/1400 loss 10.083320 loss_att 26.169277 loss_ctc 7.030081 loss_rnnt 7.229214 hw_loss 0.082524 history loss 7.718446 rank 5
2023-02-22 16:00:45,798 DEBUG CV Batch 20/1400 loss 10.083320 loss_att 26.169277 loss_ctc 7.030081 loss_rnnt 7.229214 hw_loss 0.082524 history loss 7.718446 rank 3
2023-02-22 16:00:46,634 DEBUG CV Batch 20/1400 loss 10.083320 loss_att 26.169277 loss_ctc 7.030081 loss_rnnt 7.229214 hw_loss 0.082524 history loss 7.718446 rank 6
2023-02-22 16:00:47,515 DEBUG CV Batch 20/1400 loss 10.083320 loss_att 26.169277 loss_ctc 7.030081 loss_rnnt 7.229214 hw_loss 0.082524 history loss 7.718446 rank 1
2023-02-22 16:00:50,929 DEBUG CV Batch 20/1400 loss 10.083320 loss_att 26.169277 loss_ctc 7.030081 loss_rnnt 7.229214 hw_loss 0.082524 history loss 7.718446 rank 2
2023-02-22 16:00:54,938 DEBUG CV Batch 20/1500 loss 8.415893 loss_att 8.363878 loss_ctc 8.433254 loss_rnnt 8.361258 hw_loss 0.117606 history loss 7.539232 rank 7
2023-02-22 16:00:55,126 DEBUG CV Batch 20/1500 loss 8.415893 loss_att 8.363878 loss_ctc 8.433254 loss_rnnt 8.361258 hw_loss 0.117606 history loss 7.539232 rank 0
2023-02-22 16:00:55,158 DEBUG CV Batch 20/1500 loss 8.415893 loss_att 8.363878 loss_ctc 8.433254 loss_rnnt 8.361258 hw_loss 0.117606 history loss 7.539232 rank 4
2023-02-22 16:00:55,948 DEBUG CV Batch 20/1500 loss 8.415893 loss_att 8.363878 loss_ctc 8.433254 loss_rnnt 8.361258 hw_loss 0.117606 history loss 7.539232 rank 5
2023-02-22 16:00:57,435 DEBUG CV Batch 20/1500 loss 8.415893 loss_att 8.363878 loss_ctc 8.433254 loss_rnnt 8.361258 hw_loss 0.117606 history loss 7.539232 rank 3
2023-02-22 16:00:58,231 DEBUG CV Batch 20/1500 loss 8.415893 loss_att 8.363878 loss_ctc 8.433254 loss_rnnt 8.361258 hw_loss 0.117606 history loss 7.539232 rank 6
2023-02-22 16:00:59,035 DEBUG CV Batch 20/1500 loss 8.415893 loss_att 8.363878 loss_ctc 8.433254 loss_rnnt 8.361258 hw_loss 0.117606 history loss 7.539232 rank 1
2023-02-22 16:01:02,642 DEBUG CV Batch 20/1500 loss 8.415893 loss_att 8.363878 loss_ctc 8.433254 loss_rnnt 8.361258 hw_loss 0.117606 history loss 7.539232 rank 2
2023-02-22 16:01:07,781 DEBUG CV Batch 20/1600 loss 9.698771 loss_att 12.843197 loss_ctc 10.085010 loss_rnnt 9.000513 hw_loss 0.033512 history loss 7.468967 rank 7
2023-02-22 16:01:08,043 DEBUG CV Batch 20/1600 loss 9.698771 loss_att 12.843197 loss_ctc 10.085010 loss_rnnt 9.000513 hw_loss 0.033512 history loss 7.468967 rank 4
2023-02-22 16:01:08,112 DEBUG CV Batch 20/1600 loss 9.698771 loss_att 12.843197 loss_ctc 10.085010 loss_rnnt 9.000513 hw_loss 0.033512 history loss 7.468967 rank 0
2023-02-22 16:01:08,919 DEBUG CV Batch 20/1600 loss 9.698771 loss_att 12.843197 loss_ctc 10.085010 loss_rnnt 9.000513 hw_loss 0.033512 history loss 7.468967 rank 5
2023-02-22 16:01:10,541 DEBUG CV Batch 20/1600 loss 9.698771 loss_att 12.843197 loss_ctc 10.085010 loss_rnnt 9.000513 hw_loss 0.033512 history loss 7.468967 rank 3
2023-02-22 16:01:11,301 DEBUG CV Batch 20/1600 loss 9.698771 loss_att 12.843197 loss_ctc 10.085010 loss_rnnt 9.000513 hw_loss 0.033512 history loss 7.468967 rank 6
2023-02-22 16:01:12,068 DEBUG CV Batch 20/1600 loss 9.698771 loss_att 12.843197 loss_ctc 10.085010 loss_rnnt 9.000513 hw_loss 0.033512 history loss 7.468967 rank 1
2023-02-22 16:01:15,754 DEBUG CV Batch 20/1600 loss 9.698771 loss_att 12.843197 loss_ctc 10.085010 loss_rnnt 9.000513 hw_loss 0.033512 history loss 7.468967 rank 2
2023-02-22 16:01:20,036 DEBUG CV Batch 20/1700 loss 10.154345 loss_att 9.293369 loss_ctc 14.634813 loss_rnnt 9.639924 hw_loss 0.167287 history loss 7.367091 rank 7
2023-02-22 16:01:20,276 DEBUG CV Batch 20/1700 loss 10.154345 loss_att 9.293369 loss_ctc 14.634813 loss_rnnt 9.639924 hw_loss 0.167287 history loss 7.367091 rank 4
2023-02-22 16:01:20,442 DEBUG CV Batch 20/1700 loss 10.154345 loss_att 9.293369 loss_ctc 14.634813 loss_rnnt 9.639924 hw_loss 0.167287 history loss 7.367091 rank 0
2023-02-22 16:01:21,149 DEBUG CV Batch 20/1700 loss 10.154345 loss_att 9.293369 loss_ctc 14.634813 loss_rnnt 9.639924 hw_loss 0.167287 history loss 7.367091 rank 5
2023-02-22 16:01:22,946 DEBUG CV Batch 20/1700 loss 10.154345 loss_att 9.293369 loss_ctc 14.634813 loss_rnnt 9.639924 hw_loss 0.167287 history loss 7.367091 rank 3
2023-02-22 16:01:23,702 DEBUG CV Batch 20/1700 loss 10.154345 loss_att 9.293369 loss_ctc 14.634813 loss_rnnt 9.639924 hw_loss 0.167287 history loss 7.367091 rank 6
2023-02-22 16:01:24,712 DEBUG CV Batch 20/1700 loss 10.154345 loss_att 9.293369 loss_ctc 14.634813 loss_rnnt 9.639924 hw_loss 0.167287 history loss 7.367091 rank 1
2023-02-22 16:01:28,075 DEBUG CV Batch 20/1700 loss 10.154345 loss_att 9.293369 loss_ctc 14.634813 loss_rnnt 9.639924 hw_loss 0.167287 history loss 7.367091 rank 2
2023-02-22 16:01:29,030 INFO Epoch 20 CV info cv_loss 7.341712879107718
2023-02-22 16:01:29,031 INFO Epoch 21 TRAIN info lr 0.0003778036708099823
2023-02-22 16:01:29,035 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 16:01:29,322 INFO Epoch 20 CV info cv_loss 7.34171287783706
2023-02-22 16:01:29,324 INFO Epoch 21 TRAIN info lr 0.000377829557969052
2023-02-22 16:01:29,328 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 16:01:29,477 INFO Epoch 20 CV info cv_loss 7.341712878371167
2023-02-22 16:01:29,479 INFO Checkpoint: save to checkpoint exp/2_21_rnnt_bias_loss_2_class_1word_finetune/20.pt
2023-02-22 16:01:30,139 INFO Epoch 21 TRAIN info lr 0.0003778198496608147
2023-02-22 16:01:30,142 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 16:01:30,226 INFO Epoch 20 CV info cv_loss 7.341712878629606
2023-02-22 16:01:30,227 INFO Epoch 21 TRAIN info lr 0.00037784250354426204
2023-02-22 16:01:30,231 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 16:01:32,594 INFO Epoch 20 CV info cv_loss 7.341712878651142
2023-02-22 16:01:32,595 INFO Epoch 21 TRAIN info lr 0.000377772397590931
2023-02-22 16:01:32,599 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 16:01:32,832 INFO Epoch 20 CV info cv_loss 7.341712877957665
2023-02-22 16:01:32,834 INFO Epoch 21 TRAIN info lr 0.0003778662405552422
2023-02-22 16:01:32,839 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 16:01:33,817 INFO Epoch 20 CV info cv_loss 7.341712878194567
2023-02-22 16:01:33,818 INFO Epoch 21 TRAIN info lr 0.00037781229927177316
2023-02-22 16:01:33,823 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 16:01:37,206 INFO Epoch 20 CV info cv_loss 7.341712879581523
2023-02-22 16:01:37,207 INFO Epoch 21 TRAIN info lr 0.00037775299053305106
2023-02-22 16:01:37,210 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 16:02:49,757 DEBUG TRAIN Batch 21/0 loss 10.976274 loss_att 10.550689 loss_ctc 13.432340 loss_rnnt 10.654512 hw_loss 0.148884 lr 0.00037780 rank 7
2023-02-22 16:02:49,759 DEBUG TRAIN Batch 21/0 loss 10.137604 loss_att 9.404992 loss_ctc 12.069679 loss_rnnt 9.906247 hw_loss 0.225504 lr 0.00037782 rank 0
2023-02-22 16:02:49,764 DEBUG TRAIN Batch 21/0 loss 7.987115 loss_att 8.037869 loss_ctc 9.844447 loss_rnnt 7.660307 hw_loss 0.129399 lr 0.00037783 rank 4
2023-02-22 16:02:49,766 DEBUG TRAIN Batch 21/0 loss 10.887022 loss_att 10.718673 loss_ctc 14.083182 loss_rnnt 10.391883 hw_loss 0.192476 lr 0.00037784 rank 5
2023-02-22 16:02:49,767 DEBUG TRAIN Batch 21/0 loss 10.799743 loss_att 10.253389 loss_ctc 15.424798 loss_rnnt 10.197968 hw_loss 0.176945 lr 0.00037787 rank 6
2023-02-22 16:02:49,768 DEBUG TRAIN Batch 21/0 loss 7.865647 loss_att 8.242807 loss_ctc 10.997263 loss_rnnt 7.286285 hw_loss 0.161963 lr 0.00037781 rank 1
2023-02-22 16:02:49,794 DEBUG TRAIN Batch 21/0 loss 8.546158 loss_att 9.057081 loss_ctc 10.002088 loss_rnnt 8.126595 hw_loss 0.231098 lr 0.00037775 rank 2
2023-02-22 16:02:49,812 DEBUG TRAIN Batch 21/0 loss 6.539188 loss_att 6.811908 loss_ctc 7.500721 loss_rnnt 6.283405 hw_loss 0.136942 lr 0.00037777 rank 3
2023-02-22 16:04:04,332 DEBUG TRAIN Batch 21/100 loss 7.148975 loss_att 9.735147 loss_ctc 10.464195 loss_rnnt 6.155384 hw_loss 0.064364 lr 0.00037773 rank 5
2023-02-22 16:04:04,335 DEBUG TRAIN Batch 21/100 loss 3.537183 loss_att 6.278595 loss_ctc 3.985021 loss_rnnt 2.879978 hw_loss 0.092271 lr 0.00037776 rank 6
2023-02-22 16:04:04,335 DEBUG TRAIN Batch 21/100 loss 3.171069 loss_att 5.899660 loss_ctc 4.010690 loss_rnnt 2.456546 hw_loss 0.106605 lr 0.00037769 rank 7
2023-02-22 16:04:04,339 DEBUG TRAIN Batch 21/100 loss 9.358738 loss_att 13.161051 loss_ctc 13.648944 loss_rnnt 7.934699 hw_loss 0.171654 lr 0.00037766 rank 3
2023-02-22 16:04:04,341 DEBUG TRAIN Batch 21/100 loss 4.480965 loss_att 8.926952 loss_ctc 8.178309 loss_rnnt 3.006592 hw_loss 0.172866 lr 0.00037770 rank 1
2023-02-22 16:04:04,341 DEBUG TRAIN Batch 21/100 loss 6.287871 loss_att 9.528745 loss_ctc 8.615539 loss_rnnt 5.292473 hw_loss 0.069126 lr 0.00037771 rank 0
2023-02-22 16:04:04,341 DEBUG TRAIN Batch 21/100 loss 17.142380 loss_att 21.155270 loss_ctc 21.841122 loss_rnnt 15.677428 hw_loss 0.067264 lr 0.00037772 rank 4
2023-02-22 16:04:04,389 DEBUG TRAIN Batch 21/100 loss 4.807892 loss_att 7.920968 loss_ctc 5.668041 loss_rnnt 3.998427 hw_loss 0.135306 lr 0.00037764 rank 2
2023-02-22 16:05:19,676 DEBUG TRAIN Batch 21/200 loss 14.244320 loss_att 16.215952 loss_ctc 17.700569 loss_rnnt 13.337517 hw_loss 0.096830 lr 0.00037761 rank 4
2023-02-22 16:05:19,678 DEBUG TRAIN Batch 21/200 loss 17.724594 loss_att 22.235212 loss_ctc 19.049301 loss_rnnt 16.589603 hw_loss 0.105449 lr 0.00037763 rank 5
2023-02-22 16:05:19,678 DEBUG TRAIN Batch 21/200 loss 4.800179 loss_att 8.646715 loss_ctc 8.613667 loss_rnnt 3.502147 hw_loss 0.037987 lr 0.00037760 rank 0
2023-02-22 16:05:19,679 DEBUG TRAIN Batch 21/200 loss 9.103212 loss_att 13.054195 loss_ctc 12.619018 loss_rnnt 7.795738 hw_loss 0.090943 lr 0.00037765 rank 6
2023-02-22 16:05:19,680 DEBUG TRAIN Batch 21/200 loss 10.490513 loss_att 15.302305 loss_ctc 15.883010 loss_rnnt 8.724941 hw_loss 0.157900 lr 0.00037760 rank 1
2023-02-22 16:05:19,681 DEBUG TRAIN Batch 21/200 loss 12.853752 loss_att 15.558541 loss_ctc 19.276714 loss_rnnt 11.455658 hw_loss 0.001390 lr 0.00037754 rank 2
2023-02-22 16:05:19,682 DEBUG TRAIN Batch 21/200 loss 3.602572 loss_att 6.753756 loss_ctc 5.451076 loss_rnnt 2.693272 hw_loss 0.061118 lr 0.00037759 rank 7
2023-02-22 16:05:19,727 DEBUG TRAIN Batch 21/200 loss 9.170287 loss_att 11.845819 loss_ctc 11.147680 loss_rnnt 8.327997 hw_loss 0.081621 lr 0.00037756 rank 3
2023-02-22 16:06:34,649 DEBUG TRAIN Batch 21/300 loss 5.724505 loss_att 9.516088 loss_ctc 7.155496 loss_rnnt 4.736524 hw_loss 0.072874 lr 0.00037752 rank 5
2023-02-22 16:06:34,651 DEBUG TRAIN Batch 21/300 loss 9.149676 loss_att 11.947779 loss_ctc 9.432437 loss_rnnt 8.465384 hw_loss 0.163070 lr 0.00037750 rank 0
2023-02-22 16:06:34,652 DEBUG TRAIN Batch 21/300 loss 6.967327 loss_att 8.813715 loss_ctc 11.115118 loss_rnnt 5.968791 hw_loss 0.142912 lr 0.00037745 rank 3
2023-02-22 16:06:34,653 DEBUG TRAIN Batch 21/300 loss 6.768407 loss_att 8.245414 loss_ctc 9.617758 loss_rnnt 6.048069 hw_loss 0.084419 lr 0.00037749 rank 1
2023-02-22 16:06:34,655 DEBUG TRAIN Batch 21/300 loss 10.705750 loss_att 15.274660 loss_ctc 15.318935 loss_rnnt 9.137314 hw_loss 0.074178 lr 0.00037748 rank 7
2023-02-22 16:06:34,658 DEBUG TRAIN Batch 21/300 loss 9.716976 loss_att 11.318708 loss_ctc 14.139925 loss_rnnt 8.728979 hw_loss 0.146108 lr 0.00037751 rank 4
2023-02-22 16:06:34,659 DEBUG TRAIN Batch 21/300 loss 8.144136 loss_att 13.147182 loss_ctc 15.220996 loss_rnnt 6.085916 hw_loss 0.213807 lr 0.00037743 rank 2
2023-02-22 16:06:34,662 DEBUG TRAIN Batch 21/300 loss 7.714777 loss_att 9.149484 loss_ctc 8.725065 loss_rnnt 7.248981 hw_loss 0.082780 lr 0.00037754 rank 6
2023-02-22 16:07:50,339 DEBUG TRAIN Batch 21/400 loss 11.849720 loss_att 13.886316 loss_ctc 16.042591 loss_rnnt 10.830015 hw_loss 0.100004 lr 0.00037739 rank 0
2023-02-22 16:07:50,344 DEBUG TRAIN Batch 21/400 loss 7.494668 loss_att 12.212357 loss_ctc 12.158801 loss_rnnt 5.902712 hw_loss 0.049751 lr 0.00037738 rank 1
2023-02-22 16:07:50,345 DEBUG TRAIN Batch 21/400 loss 9.331150 loss_att 10.448502 loss_ctc 14.146433 loss_rnnt 8.447833 hw_loss 0.033394 lr 0.00037741 rank 5
2023-02-22 16:07:50,344 DEBUG TRAIN Batch 21/400 loss 9.858635 loss_att 12.296115 loss_ctc 16.014671 loss_rnnt 8.484322 hw_loss 0.123772 lr 0.00037740 rank 4
2023-02-22 16:07:50,345 DEBUG TRAIN Batch 21/400 loss 13.273944 loss_att 12.884657 loss_ctc 16.992674 loss_rnnt 12.790688 hw_loss 0.122407 lr 0.00037737 rank 7
2023-02-22 16:07:50,349 DEBUG TRAIN Batch 21/400 loss 6.040100 loss_att 10.220278 loss_ctc 9.040426 loss_rnnt 4.773547 hw_loss 0.057138 lr 0.00037743 rank 6
2023-02-22 16:07:50,349 DEBUG TRAIN Batch 21/400 loss 11.555064 loss_att 14.517097 loss_ctc 17.088213 loss_rnnt 10.180977 hw_loss 0.082364 lr 0.00037734 rank 3
2023-02-22 16:07:50,350 DEBUG TRAIN Batch 21/400 loss 10.277863 loss_att 13.475962 loss_ctc 14.514259 loss_rnnt 9.035821 hw_loss 0.070443 lr 0.00037732 rank 2
2023-02-22 16:09:04,626 DEBUG TRAIN Batch 21/500 loss 18.381487 loss_att 22.990625 loss_ctc 33.326675 loss_rnnt 15.360703 hw_loss 0.199245 lr 0.00037729 rank 4
2023-02-22 16:09:04,628 DEBUG TRAIN Batch 21/500 loss 2.371096 loss_att 5.760942 loss_ctc 4.998846 loss_rnnt 1.295713 hw_loss 0.088213 lr 0.00037723 rank 3
2023-02-22 16:09:04,629 DEBUG TRAIN Batch 21/500 loss 15.580742 loss_att 16.352121 loss_ctc 20.379341 loss_rnnt 14.706488 hw_loss 0.150308 lr 0.00037726 rank 7
2023-02-22 16:09:04,629 DEBUG TRAIN Batch 21/500 loss 8.644795 loss_att 11.725018 loss_ctc 12.937291 loss_rnnt 7.316682 hw_loss 0.262005 lr 0.00037728 rank 0
2023-02-22 16:09:04,634 DEBUG TRAIN Batch 21/500 loss 7.561791 loss_att 11.246382 loss_ctc 12.618155 loss_rnnt 6.081139 hw_loss 0.130409 lr 0.00037730 rank 5
2023-02-22 16:09:04,636 DEBUG TRAIN Batch 21/500 loss 22.149948 loss_att 22.820446 loss_ctc 24.960558 loss_rnnt 21.632874 hw_loss 0.015427 lr 0.00037727 rank 1
2023-02-22 16:09:04,637 DEBUG TRAIN Batch 21/500 loss 5.394559 loss_att 7.488040 loss_ctc 5.752059 loss_rnnt 4.918801 hw_loss 0.017615 lr 0.00037733 rank 6
2023-02-22 16:09:04,676 DEBUG TRAIN Batch 21/500 loss 9.441851 loss_att 13.681337 loss_ctc 13.928967 loss_rnnt 7.964779 hw_loss 0.057922 lr 0.00037721 rank 2
2023-02-22 16:10:20,853 DEBUG TRAIN Batch 21/600 loss 10.715167 loss_att 13.301245 loss_ctc 16.272163 loss_rnnt 9.402152 hw_loss 0.102876 lr 0.00037718 rank 4
2023-02-22 16:10:20,855 DEBUG TRAIN Batch 21/600 loss 7.858561 loss_att 9.303384 loss_ctc 11.328479 loss_rnnt 7.013522 hw_loss 0.175159 lr 0.00037716 rank 7
2023-02-22 16:10:20,855 DEBUG TRAIN Batch 21/600 loss 6.221404 loss_att 7.835718 loss_ctc 9.025275 loss_rnnt 5.463300 hw_loss 0.115110 lr 0.00037720 rank 5
2023-02-22 16:10:20,858 DEBUG TRAIN Batch 21/600 loss 7.417881 loss_att 8.801010 loss_ctc 10.659138 loss_rnnt 6.642745 hw_loss 0.124393 lr 0.00037713 rank 3
2023-02-22 16:10:20,858 DEBUG TRAIN Batch 21/600 loss 9.716079 loss_att 11.964881 loss_ctc 14.794589 loss_rnnt 8.477774 hw_loss 0.208892 lr 0.00037722 rank 6
2023-02-22 16:10:20,859 DEBUG TRAIN Batch 21/600 loss 10.279005 loss_att 12.708210 loss_ctc 18.501266 loss_rnnt 8.634499 hw_loss 0.116933 lr 0.00037711 rank 2
2023-02-22 16:10:20,859 DEBUG TRAIN Batch 21/600 loss 5.305956 loss_att 6.409904 loss_ctc 6.157851 loss_rnnt 4.881182 hw_loss 0.169497 lr 0.00037717 rank 0
2023-02-22 16:10:20,859 DEBUG TRAIN Batch 21/600 loss 8.974641 loss_att 10.514450 loss_ctc 12.996556 loss_rnnt 8.113471 hw_loss 0.031787 lr 0.00037717 rank 1
2023-02-22 16:11:38,929 DEBUG TRAIN Batch 21/700 loss 8.168155 loss_att 11.136626 loss_ctc 9.448672 loss_rnnt 7.359912 hw_loss 0.082148 lr 0.00037709 rank 5
2023-02-22 16:11:38,930 DEBUG TRAIN Batch 21/700 loss 4.318665 loss_att 8.143047 loss_ctc 8.544462 loss_rnnt 2.984142 hw_loss 0.011639 lr 0.00037708 rank 4
2023-02-22 16:11:38,934 DEBUG TRAIN Batch 21/700 loss 10.724270 loss_att 12.683889 loss_ctc 12.533743 loss_rnnt 10.044051 hw_loss 0.088187 lr 0.00037702 rank 3
2023-02-22 16:11:38,934 DEBUG TRAIN Batch 21/700 loss 11.213231 loss_att 13.134433 loss_ctc 18.612236 loss_rnnt 9.789808 hw_loss 0.098714 lr 0.00037705 rank 7
2023-02-22 16:11:38,935 DEBUG TRAIN Batch 21/700 loss 14.769972 loss_att 17.899845 loss_ctc 23.640915 loss_rnnt 12.957577 hw_loss 0.006801 lr 0.00037700 rank 2
2023-02-22 16:11:38,937 DEBUG TRAIN Batch 21/700 loss 5.961922 loss_att 12.841825 loss_ctc 8.390433 loss_rnnt 4.217922 hw_loss 0.082910 lr 0.00037706 rank 1
2023-02-22 16:11:38,936 DEBUG TRAIN Batch 21/700 loss 2.889447 loss_att 6.636104 loss_ctc 4.236919 loss_rnnt 1.898212 hw_loss 0.116703 lr 0.00037707 rank 0
2023-02-22 16:11:38,939 DEBUG TRAIN Batch 21/700 loss 7.669885 loss_att 13.371050 loss_ctc 10.986069 loss_rnnt 6.071205 hw_loss 0.030540 lr 0.00037711 rank 6
2023-02-22 16:12:53,644 DEBUG TRAIN Batch 21/800 loss 1.647575 loss_att 3.331773 loss_ctc 2.837702 loss_rnnt 1.106241 hw_loss 0.085897 lr 0.00037697 rank 4
2023-02-22 16:12:53,646 DEBUG TRAIN Batch 21/800 loss 11.094682 loss_att 18.731361 loss_ctc 19.907211 loss_rnnt 8.371202 hw_loss 0.039637 lr 0.00037700 rank 6
2023-02-22 16:12:53,650 DEBUG TRAIN Batch 21/800 loss 4.048157 loss_att 9.015386 loss_ctc 5.925632 loss_rnnt 2.755506 hw_loss 0.091639 lr 0.00037695 rank 1
2023-02-22 16:12:53,652 DEBUG TRAIN Batch 21/800 loss 4.536360 loss_att 6.430498 loss_ctc 7.270191 loss_rnnt 3.743716 hw_loss 0.092448 lr 0.00037696 rank 0
2023-02-22 16:12:53,652 DEBUG TRAIN Batch 21/800 loss 5.563056 loss_att 8.900470 loss_ctc 9.286146 loss_rnnt 4.354218 hw_loss 0.084267 lr 0.00037698 rank 5
2023-02-22 16:12:53,652 DEBUG TRAIN Batch 21/800 loss 4.838708 loss_att 8.218307 loss_ctc 6.290458 loss_rnnt 3.829300 hw_loss 0.262353 lr 0.00037694 rank 7
2023-02-22 16:12:53,653 DEBUG TRAIN Batch 21/800 loss 14.336091 loss_att 20.417091 loss_ctc 21.602819 loss_rnnt 12.073647 hw_loss 0.145026 lr 0.00037689 rank 2
2023-02-22 16:12:53,699 DEBUG TRAIN Batch 21/800 loss 7.375781 loss_att 8.009140 loss_ctc 8.602394 loss_rnnt 7.032053 hw_loss 0.100325 lr 0.00037691 rank 3
2023-02-22 16:14:07,429 DEBUG TRAIN Batch 21/900 loss 9.719722 loss_att 13.574415 loss_ctc 17.089375 loss_rnnt 7.904344 hw_loss 0.115909 lr 0.00037687 rank 5
2023-02-22 16:14:07,428 DEBUG TRAIN Batch 21/900 loss 16.940121 loss_att 20.836039 loss_ctc 23.612562 loss_rnnt 15.236705 hw_loss 0.064824 lr 0.00037685 rank 0
2023-02-22 16:14:07,429 DEBUG TRAIN Batch 21/900 loss 12.909015 loss_att 14.358643 loss_ctc 17.666576 loss_rnnt 11.947149 hw_loss 0.070497 lr 0.00037680 rank 3
2023-02-22 16:14:07,429 DEBUG TRAIN Batch 21/900 loss 13.597483 loss_att 16.126926 loss_ctc 22.258671 loss_rnnt 11.865337 hw_loss 0.133934 lr 0.00037686 rank 4
2023-02-22 16:14:07,430 DEBUG TRAIN Batch 21/900 loss 8.986280 loss_att 11.928501 loss_ctc 11.947145 loss_rnnt 7.942302 hw_loss 0.113912 lr 0.00037690 rank 6
2023-02-22 16:14:07,431 DEBUG TRAIN Batch 21/900 loss 5.421418 loss_att 8.896290 loss_ctc 6.254486 loss_rnnt 4.544961 hw_loss 0.132012 lr 0.00037684 rank 7
2023-02-22 16:14:07,431 DEBUG TRAIN Batch 21/900 loss 10.559700 loss_att 12.843112 loss_ctc 13.677617 loss_rnnt 9.626545 hw_loss 0.113907 lr 0.00037679 rank 2
2023-02-22 16:14:07,431 DEBUG TRAIN Batch 21/900 loss 9.221241 loss_att 13.339857 loss_ctc 16.897879 loss_rnnt 7.272058 hw_loss 0.191078 lr 0.00037684 rank 1
2023-02-22 16:15:23,431 DEBUG TRAIN Batch 21/1000 loss 6.818363 loss_att 11.534271 loss_ctc 7.858047 loss_rnnt 5.701454 hw_loss 0.065819 lr 0.00037679 rank 6
2023-02-22 16:15:23,430 DEBUG TRAIN Batch 21/1000 loss 5.152099 loss_att 8.663769 loss_ctc 8.038376 loss_rnnt 4.034687 hw_loss 0.056701 lr 0.00037677 rank 5
2023-02-22 16:15:23,434 DEBUG TRAIN Batch 21/1000 loss 7.240367 loss_att 8.586265 loss_ctc 9.085386 loss_rnnt 6.710107 hw_loss 0.028271 lr 0.00037674 rank 0
2023-02-22 16:15:23,434 DEBUG TRAIN Batch 21/1000 loss 10.044830 loss_att 10.562341 loss_ctc 11.950438 loss_rnnt 9.674964 hw_loss 0.023030 lr 0.00037673 rank 7
2023-02-22 16:15:23,436 DEBUG TRAIN Batch 21/1000 loss 7.511157 loss_att 11.567156 loss_ctc 9.397241 loss_rnnt 6.372463 hw_loss 0.142531 lr 0.00037674 rank 1
2023-02-22 16:15:23,436 DEBUG TRAIN Batch 21/1000 loss 12.068353 loss_att 14.608337 loss_ctc 17.988321 loss_rnnt 10.745703 hw_loss 0.047485 lr 0.00037668 rank 2
2023-02-22 16:15:23,438 DEBUG TRAIN Batch 21/1000 loss 9.223454 loss_att 14.005919 loss_ctc 13.485651 loss_rnnt 7.644797 hw_loss 0.101007 lr 0.00037675 rank 4
2023-02-22 16:15:23,439 DEBUG TRAIN Batch 21/1000 loss 7.326741 loss_att 8.901088 loss_ctc 10.105349 loss_rnnt 6.604291 hw_loss 0.069563 lr 0.00037670 rank 3
2023-02-22 16:16:40,285 DEBUG TRAIN Batch 21/1100 loss 3.044248 loss_att 5.553442 loss_ctc 4.990286 loss_rnnt 2.235266 hw_loss 0.089383 lr 0.00037664 rank 0
2023-02-22 16:16:40,288 DEBUG TRAIN Batch 21/1100 loss 5.709887 loss_att 8.311230 loss_ctc 8.214442 loss_rnnt 4.848627 hw_loss 0.013220 lr 0.00037662 rank 7
2023-02-22 16:16:40,293 DEBUG TRAIN Batch 21/1100 loss 8.421452 loss_att 11.685514 loss_ctc 12.025280 loss_rnnt 7.280587 hw_loss 0.014139 lr 0.00037666 rank 5
2023-02-22 16:16:40,294 DEBUG TRAIN Batch 21/1100 loss 9.152893 loss_att 12.674503 loss_ctc 12.501051 loss_rnnt 7.977439 hw_loss 0.046335 lr 0.00037665 rank 4
2023-02-22 16:16:40,297 DEBUG TRAIN Batch 21/1100 loss 13.591302 loss_att 16.557632 loss_ctc 18.532240 loss_rnnt 12.320193 hw_loss 0.035721 lr 0.00037659 rank 3
2023-02-22 16:16:40,297 DEBUG TRAIN Batch 21/1100 loss 5.827368 loss_att 9.156121 loss_ctc 8.998981 loss_rnnt 4.693310 hw_loss 0.085173 lr 0.00037668 rank 6
2023-02-22 16:16:40,302 DEBUG TRAIN Batch 21/1100 loss 4.762758 loss_att 6.166501 loss_ctc 6.221401 loss_rnnt 4.270358 hw_loss 0.032185 lr 0.00037657 rank 2
2023-02-22 16:16:40,339 DEBUG TRAIN Batch 21/1100 loss 5.173425 loss_att 7.595747 loss_ctc 7.644240 loss_rnnt 4.299928 hw_loss 0.111733 lr 0.00037663 rank 1
2023-02-22 16:17:55,905 DEBUG TRAIN Batch 21/1200 loss 9.906161 loss_att 12.685146 loss_ctc 13.401270 loss_rnnt 8.805429 hw_loss 0.147974 lr 0.00037653 rank 0
2023-02-22 16:17:55,905 DEBUG TRAIN Batch 21/1200 loss 6.082320 loss_att 7.066360 loss_ctc 8.515849 loss_rnnt 5.494937 hw_loss 0.123947 lr 0.00037651 rank 7
2023-02-22 16:17:55,907 DEBUG TRAIN Batch 21/1200 loss 11.856371 loss_att 13.756420 loss_ctc 16.333717 loss_rnnt 10.788635 hw_loss 0.170149 lr 0.00037655 rank 5
2023-02-22 16:17:55,908 DEBUG TRAIN Batch 21/1200 loss 8.301937 loss_att 10.437652 loss_ctc 13.455184 loss_rnnt 7.098492 hw_loss 0.167256 lr 0.00037654 rank 4
2023-02-22 16:17:55,910 DEBUG TRAIN Batch 21/1200 loss 15.628419 loss_att 14.784391 loss_ctc 21.198057 loss_rnnt 15.000664 hw_loss 0.101140 lr 0.00037646 rank 2
2023-02-22 16:17:55,910 DEBUG TRAIN Batch 21/1200 loss 9.255338 loss_att 11.260294 loss_ctc 13.323722 loss_rnnt 8.254211 hw_loss 0.108155 lr 0.00037652 rank 1
2023-02-22 16:17:55,917 DEBUG TRAIN Batch 21/1200 loss 4.886708 loss_att 6.730464 loss_ctc 8.243363 loss_rnnt 4.009243 hw_loss 0.114675 lr 0.00037648 rank 3
2023-02-22 16:17:55,954 DEBUG TRAIN Batch 21/1200 loss 6.067626 loss_att 8.836025 loss_ctc 7.942037 loss_rnnt 5.206287 hw_loss 0.108260 lr 0.00037658 rank 6
2023-02-22 16:19:10,421 DEBUG TRAIN Batch 21/1300 loss 9.649370 loss_att 9.142600 loss_ctc 11.867820 loss_rnnt 9.328322 hw_loss 0.237390 lr 0.00037641 rank 7
2023-02-22 16:19:10,425 DEBUG TRAIN Batch 21/1300 loss 10.731589 loss_att 13.905081 loss_ctc 15.126642 loss_rnnt 9.451710 hw_loss 0.110952 lr 0.00037643 rank 4
2023-02-22 16:19:10,429 DEBUG TRAIN Batch 21/1300 loss 7.679923 loss_att 7.502822 loss_ctc 10.978077 loss_rnnt 7.208684 hw_loss 0.125446 lr 0.00037645 rank 5
2023-02-22 16:19:10,432 DEBUG TRAIN Batch 21/1300 loss 13.156307 loss_att 12.633030 loss_ctc 16.353840 loss_rnnt 12.752176 hw_loss 0.154590 lr 0.00037642 rank 1
2023-02-22 16:19:10,434 DEBUG TRAIN Batch 21/1300 loss 5.482207 loss_att 6.904596 loss_ctc 5.600576 loss_rnnt 5.179043 hw_loss 0.005443 lr 0.00037636 rank 2
2023-02-22 16:19:10,436 DEBUG TRAIN Batch 21/1300 loss 7.208627 loss_att 9.940486 loss_ctc 14.152735 loss_rnnt 5.711216 hw_loss 0.047171 lr 0.00037647 rank 6
2023-02-22 16:19:10,437 DEBUG TRAIN Batch 21/1300 loss 6.586469 loss_att 9.208133 loss_ctc 5.541811 loss_rnnt 6.183388 hw_loss 0.033817 lr 0.00037642 rank 0
2023-02-22 16:19:10,483 DEBUG TRAIN Batch 21/1300 loss 7.460308 loss_att 13.953427 loss_ctc 12.512617 loss_rnnt 5.427255 hw_loss 0.113978 lr 0.00037638 rank 3
2023-02-22 16:20:28,449 DEBUG TRAIN Batch 21/1400 loss 22.461987 loss_att 25.770445 loss_ctc 28.258154 loss_rnnt 20.984432 hw_loss 0.080701 lr 0.00037634 rank 5
2023-02-22 16:20:28,451 DEBUG TRAIN Batch 21/1400 loss 6.726178 loss_att 8.935035 loss_ctc 11.036334 loss_rnnt 5.614316 hw_loss 0.178881 lr 0.00037633 rank 4
2023-02-22 16:20:28,454 DEBUG TRAIN Batch 21/1400 loss 13.511409 loss_att 21.784630 loss_ctc 21.490324 loss_rnnt 10.736690 hw_loss 0.105412 lr 0.00037625 rank 2
2023-02-22 16:20:28,455 DEBUG TRAIN Batch 21/1400 loss 12.624254 loss_att 16.263432 loss_ctc 20.963678 loss_rnnt 10.702018 hw_loss 0.154646 lr 0.00037636 rank 6
2023-02-22 16:20:28,457 DEBUG TRAIN Batch 21/1400 loss 8.001764 loss_att 10.251362 loss_ctc 11.057436 loss_rnnt 7.093767 hw_loss 0.094978 lr 0.00037631 rank 1
2023-02-22 16:20:28,458 DEBUG TRAIN Batch 21/1400 loss 5.794100 loss_att 8.504731 loss_ctc 8.540485 loss_rnnt 4.831706 hw_loss 0.101405 lr 0.00037630 rank 7
2023-02-22 16:20:28,459 DEBUG TRAIN Batch 21/1400 loss 1.209876 loss_att 4.393044 loss_ctc 2.099289 loss_rnnt 0.422023 hw_loss 0.061182 lr 0.00037632 rank 0
2023-02-22 16:20:28,502 DEBUG TRAIN Batch 21/1400 loss 8.391241 loss_att 11.380487 loss_ctc 10.944834 loss_rnnt 7.357191 hw_loss 0.179480 lr 0.00037627 rank 3
2023-02-22 16:21:44,920 DEBUG TRAIN Batch 21/1500 loss 4.558311 loss_att 6.333172 loss_ctc 6.765157 loss_rnnt 3.829060 hw_loss 0.150061 lr 0.00037620 rank 7
2023-02-22 16:21:44,922 DEBUG TRAIN Batch 21/1500 loss 8.732430 loss_att 12.210072 loss_ctc 14.413463 loss_rnnt 7.272760 hw_loss 0.012508 lr 0.00037621 rank 0
2023-02-22 16:21:44,924 DEBUG TRAIN Batch 21/1500 loss 13.193866 loss_att 12.880350 loss_ctc 15.717377 loss_rnnt 12.849269 hw_loss 0.132811 lr 0.00037623 rank 5
2023-02-22 16:21:44,927 DEBUG TRAIN Batch 21/1500 loss 15.171997 loss_att 20.462740 loss_ctc 24.215918 loss_rnnt 12.880466 hw_loss 0.051612 lr 0.00037622 rank 4
2023-02-22 16:21:44,931 DEBUG TRAIN Batch 21/1500 loss 7.823815 loss_att 11.994286 loss_ctc 12.501471 loss_rnnt 6.357685 hw_loss 0.015654 lr 0.00037616 rank 3
2023-02-22 16:21:44,933 DEBUG TRAIN Batch 21/1500 loss 8.740352 loss_att 10.205492 loss_ctc 11.517653 loss_rnnt 8.023298 hw_loss 0.100722 lr 0.00037620 rank 1
2023-02-22 16:21:44,935 DEBUG TRAIN Batch 21/1500 loss 5.112064 loss_att 7.228332 loss_ctc 6.557856 loss_rnnt 4.469512 hw_loss 0.049739 lr 0.00037615 rank 2
2023-02-22 16:21:44,935 DEBUG TRAIN Batch 21/1500 loss 6.849046 loss_att 10.836334 loss_ctc 8.403942 loss_rnnt 5.799688 hw_loss 0.083590 lr 0.00037626 rank 6
2023-02-22 16:22:59,891 DEBUG TRAIN Batch 21/1600 loss 8.761509 loss_att 10.640868 loss_ctc 12.176363 loss_rnnt 7.918467 hw_loss 0.022229 lr 0.00037609 rank 7
2023-02-22 16:22:59,893 DEBUG TRAIN Batch 21/1600 loss 12.559936 loss_att 13.392374 loss_ctc 19.036488 loss_rnnt 11.498842 hw_loss 0.058249 lr 0.00037611 rank 4
2023-02-22 16:22:59,896 DEBUG TRAIN Batch 21/1600 loss 15.119967 loss_att 16.246084 loss_ctc 23.731781 loss_rnnt 13.739155 hw_loss 0.013773 lr 0.00037610 rank 1
2023-02-22 16:22:59,899 DEBUG TRAIN Batch 21/1600 loss 10.867627 loss_att 12.995518 loss_ctc 17.093006 loss_rnnt 9.596034 hw_loss 0.029935 lr 0.00037615 rank 6
2023-02-22 16:22:59,899 DEBUG TRAIN Batch 21/1600 loss 6.152200 loss_att 9.330902 loss_ctc 10.513803 loss_rnnt 4.838553 hw_loss 0.180673 lr 0.00037610 rank 0
2023-02-22 16:22:59,901 DEBUG TRAIN Batch 21/1600 loss 8.533565 loss_att 10.475073 loss_ctc 10.419703 loss_rnnt 7.811706 hw_loss 0.153885 lr 0.00037606 rank 3
2023-02-22 16:22:59,903 DEBUG TRAIN Batch 21/1600 loss 15.717404 loss_att 18.334396 loss_ctc 20.456736 loss_rnnt 14.561706 hw_loss 0.000733 lr 0.00037613 rank 5
2023-02-22 16:22:59,906 DEBUG TRAIN Batch 21/1600 loss 8.311188 loss_att 10.077506 loss_ctc 12.621046 loss_rnnt 7.338700 hw_loss 0.083579 lr 0.00037604 rank 2
2023-02-22 16:24:15,463 DEBUG TRAIN Batch 21/1700 loss 11.577339 loss_att 12.807492 loss_ctc 16.037220 loss_rnnt 10.701262 hw_loss 0.066370 lr 0.00037602 rank 5
2023-02-22 16:24:15,465 DEBUG TRAIN Batch 21/1700 loss 2.869235 loss_att 5.133499 loss_ctc 3.496632 loss_rnnt 2.260553 hw_loss 0.135330 lr 0.00037600 rank 0
2023-02-22 16:24:15,464 DEBUG TRAIN Batch 21/1700 loss 10.787168 loss_att 13.869276 loss_ctc 14.079082 loss_rnnt 9.666971 hw_loss 0.121601 lr 0.00037604 rank 6
2023-02-22 16:24:15,464 DEBUG TRAIN Batch 21/1700 loss 9.681803 loss_att 11.534977 loss_ctc 13.145878 loss_rnnt 8.819630 hw_loss 0.055616 lr 0.00037595 rank 3
2023-02-22 16:24:15,467 DEBUG TRAIN Batch 21/1700 loss 10.628576 loss_att 15.784214 loss_ctc 17.571793 loss_rnnt 8.613259 hw_loss 0.109550 lr 0.00037598 rank 7
2023-02-22 16:24:15,468 DEBUG TRAIN Batch 21/1700 loss 11.268835 loss_att 13.425098 loss_ctc 14.849874 loss_rnnt 10.317006 hw_loss 0.080820 lr 0.00037593 rank 2
2023-02-22 16:24:15,469 DEBUG TRAIN Batch 21/1700 loss 8.579316 loss_att 13.185846 loss_ctc 12.766015 loss_rnnt 7.055086 hw_loss 0.083809 lr 0.00037601 rank 4
2023-02-22 16:24:15,475 DEBUG TRAIN Batch 21/1700 loss 15.652157 loss_att 18.035706 loss_ctc 24.381025 loss_rnnt 13.986644 hw_loss 0.046790 lr 0.00037599 rank 1
2023-02-22 16:25:33,603 DEBUG TRAIN Batch 21/1800 loss 9.066221 loss_att 11.887363 loss_ctc 19.858999 loss_rnnt 7.014919 hw_loss 0.090068 lr 0.00037589 rank 0
2023-02-22 16:25:33,606 DEBUG TRAIN Batch 21/1800 loss 3.312077 loss_att 7.529075 loss_ctc 5.620457 loss_rnnt 2.121841 hw_loss 0.073224 lr 0.00037588 rank 7
2023-02-22 16:25:33,606 DEBUG TRAIN Batch 21/1800 loss 12.858261 loss_att 17.408251 loss_ctc 22.315712 loss_rnnt 10.584643 hw_loss 0.192424 lr 0.00037590 rank 4
2023-02-22 16:25:33,612 DEBUG TRAIN Batch 21/1800 loss 7.454350 loss_att 8.274412 loss_ctc 10.505516 loss_rnnt 6.851195 hw_loss 0.060602 lr 0.00037588 rank 1
2023-02-22 16:25:33,612 DEBUG TRAIN Batch 21/1800 loss 6.332291 loss_att 9.187260 loss_ctc 9.235326 loss_rnnt 5.239685 hw_loss 0.252264 lr 0.00037591 rank 5
2023-02-22 16:25:33,614 DEBUG TRAIN Batch 21/1800 loss 7.935388 loss_att 10.840016 loss_ctc 12.091704 loss_rnnt 6.748943 hw_loss 0.096270 lr 0.00037594 rank 6
2023-02-22 16:25:33,616 DEBUG TRAIN Batch 21/1800 loss 8.357134 loss_att 10.536935 loss_ctc 12.425884 loss_rnnt 7.358084 hw_loss 0.038605 lr 0.00037585 rank 3
2023-02-22 16:25:33,618 DEBUG TRAIN Batch 21/1800 loss 12.246374 loss_att 13.812673 loss_ctc 19.436171 loss_rnnt 10.918619 hw_loss 0.104728 lr 0.00037583 rank 2
2023-02-22 16:26:50,154 DEBUG TRAIN Batch 21/1900 loss 14.747087 loss_att 15.213185 loss_ctc 18.085217 loss_rnnt 14.181281 hw_loss 0.051567 lr 0.00037577 rank 7
2023-02-22 16:26:50,157 DEBUG TRAIN Batch 21/1900 loss 11.245055 loss_att 11.828913 loss_ctc 14.599686 loss_rnnt 10.618887 hw_loss 0.116462 lr 0.00037579 rank 0
2023-02-22 16:26:50,158 DEBUG TRAIN Batch 21/1900 loss 6.614702 loss_att 8.519146 loss_ctc 9.956769 loss_rnnt 5.699427 hw_loss 0.166457 lr 0.00037583 rank 6
2023-02-22 16:26:50,161 DEBUG TRAIN Batch 21/1900 loss 7.398327 loss_att 7.580284 loss_ctc 11.195700 loss_rnnt 6.780290 hw_loss 0.141243 lr 0.00037580 rank 4
2023-02-22 16:26:50,162 DEBUG TRAIN Batch 21/1900 loss 10.122763 loss_att 10.763737 loss_ctc 15.008046 loss_rnnt 9.260418 hw_loss 0.155211 lr 0.00037572 rank 2
2023-02-22 16:26:50,161 DEBUG TRAIN Batch 21/1900 loss 7.324242 loss_att 8.352402 loss_ctc 8.887580 loss_rnnt 6.838094 hw_loss 0.135132 lr 0.00037581 rank 5
2023-02-22 16:26:50,166 DEBUG TRAIN Batch 21/1900 loss 6.047948 loss_att 10.008655 loss_ctc 7.459108 loss_rnnt 5.033428 hw_loss 0.064170 lr 0.00037578 rank 1
2023-02-22 16:26:50,207 DEBUG TRAIN Batch 21/1900 loss 22.048573 loss_att 24.029604 loss_ctc 29.636543 loss_rnnt 20.592377 hw_loss 0.090489 lr 0.00037574 rank 3
2023-02-22 16:28:04,524 DEBUG TRAIN Batch 21/2000 loss 10.036733 loss_att 13.645408 loss_ctc 13.177919 loss_rnnt 8.865337 hw_loss 0.057818 lr 0.00037568 rank 0
2023-02-22 16:28:04,528 DEBUG TRAIN Batch 21/2000 loss 8.186669 loss_att 12.531108 loss_ctc 11.979992 loss_rnnt 6.780847 hw_loss 0.058423 lr 0.00037569 rank 4
2023-02-22 16:28:04,528 DEBUG TRAIN Batch 21/2000 loss 6.009332 loss_att 11.495954 loss_ctc 11.153463 loss_rnnt 4.212415 hw_loss 0.025702 lr 0.00037570 rank 5
2023-02-22 16:28:04,528 DEBUG TRAIN Batch 21/2000 loss 8.036689 loss_att 10.652728 loss_ctc 10.950985 loss_rnnt 7.064641 hw_loss 0.113001 lr 0.00037566 rank 7
2023-02-22 16:28:04,531 DEBUG TRAIN Batch 21/2000 loss 2.482502 loss_att 5.435629 loss_ctc 6.082607 loss_rnnt 1.369794 hw_loss 0.078880 lr 0.00037573 rank 6
2023-02-22 16:28:04,532 DEBUG TRAIN Batch 21/2000 loss 3.964835 loss_att 7.049565 loss_ctc 5.582081 loss_rnnt 3.123294 hw_loss 0.016805 lr 0.00037563 rank 3
2023-02-22 16:28:04,536 DEBUG TRAIN Batch 21/2000 loss 7.522772 loss_att 13.592419 loss_ctc 10.487864 loss_rnnt 5.848312 hw_loss 0.122222 lr 0.00037567 rank 1
2023-02-22 16:28:04,538 DEBUG TRAIN Batch 21/2000 loss 1.900101 loss_att 5.061167 loss_ctc 1.947757 loss_rnnt 1.216232 hw_loss 0.084940 lr 0.00037561 rank 2
2023-02-22 16:29:22,214 DEBUG TRAIN Batch 21/2100 loss 4.355508 loss_att 7.106862 loss_ctc 6.638300 loss_rnnt 3.437254 hw_loss 0.119270 lr 0.00037553 rank 3
2023-02-22 16:29:22,217 DEBUG TRAIN Batch 21/2100 loss 11.957200 loss_att 12.809305 loss_ctc 12.235881 loss_rnnt 11.724022 hw_loss 0.047999 lr 0.00037557 rank 0
2023-02-22 16:29:22,217 DEBUG TRAIN Batch 21/2100 loss 5.336047 loss_att 7.902317 loss_ctc 10.735298 loss_rnnt 4.027763 hw_loss 0.140868 lr 0.00037556 rank 7
2023-02-22 16:29:22,218 DEBUG TRAIN Batch 21/2100 loss 2.557758 loss_att 6.477811 loss_ctc 5.673547 loss_rnnt 1.335112 hw_loss 0.043493 lr 0.00037558 rank 4
2023-02-22 16:29:22,219 DEBUG TRAIN Batch 21/2100 loss 5.159597 loss_att 9.812279 loss_ctc 11.046985 loss_rnnt 3.407358 hw_loss 0.068847 lr 0.00037560 rank 5
2023-02-22 16:29:22,222 DEBUG TRAIN Batch 21/2100 loss 8.229650 loss_att 10.600101 loss_ctc 8.659276 loss_rnnt 7.674142 hw_loss 0.045252 lr 0.00037557 rank 1
2023-02-22 16:29:22,225 DEBUG TRAIN Batch 21/2100 loss 15.692318 loss_att 19.201988 loss_ctc 23.373493 loss_rnnt 13.926147 hw_loss 0.075150 lr 0.00037551 rank 2
2023-02-22 16:29:22,224 DEBUG TRAIN Batch 21/2100 loss 3.793641 loss_att 6.525306 loss_ctc 3.838616 loss_rnnt 3.216391 hw_loss 0.046726 lr 0.00037562 rank 6
2023-02-22 16:30:37,905 DEBUG TRAIN Batch 21/2200 loss 12.866620 loss_att 18.652117 loss_ctc 23.429640 loss_rnnt 10.225952 hw_loss 0.140936 lr 0.00037549 rank 5
2023-02-22 16:30:37,905 DEBUG TRAIN Batch 21/2200 loss 4.649421 loss_att 7.761518 loss_ctc 7.704431 loss_rnnt 3.539728 hw_loss 0.149885 lr 0.00037547 rank 0
2023-02-22 16:30:37,908 DEBUG TRAIN Batch 21/2200 loss 12.868894 loss_att 15.837004 loss_ctc 17.660744 loss_rnnt 11.585989 hw_loss 0.094445 lr 0.00037545 rank 7
2023-02-22 16:30:37,908 DEBUG TRAIN Batch 21/2200 loss 9.424507 loss_att 11.960228 loss_ctc 11.316223 loss_rnnt 8.632599 hw_loss 0.061005 lr 0.00037548 rank 4
2023-02-22 16:30:37,909 DEBUG TRAIN Batch 21/2200 loss 9.309795 loss_att 11.394537 loss_ctc 12.119406 loss_rnnt 8.417318 hw_loss 0.189215 lr 0.00037540 rank 2
2023-02-22 16:30:37,913 DEBUG TRAIN Batch 21/2200 loss 13.088354 loss_att 19.081497 loss_ctc 20.893980 loss_rnnt 10.818156 hw_loss 0.057785 lr 0.00037542 rank 3
2023-02-22 16:30:37,913 DEBUG TRAIN Batch 21/2200 loss 13.795360 loss_att 17.760330 loss_ctc 20.002378 loss_rnnt 12.091602 hw_loss 0.155928 lr 0.00037546 rank 1
2023-02-22 16:30:37,913 DEBUG TRAIN Batch 21/2200 loss 11.760330 loss_att 15.920102 loss_ctc 14.178980 loss_rnnt 10.545096 hw_loss 0.113985 lr 0.00037551 rank 6
2023-02-22 16:31:53,624 DEBUG TRAIN Batch 21/2300 loss 3.093197 loss_att 5.372188 loss_ctc 4.278943 loss_rnnt 2.404000 hw_loss 0.141184 lr 0.00037538 rank 5
2023-02-22 16:31:53,625 DEBUG TRAIN Batch 21/2300 loss 12.214653 loss_att 16.031446 loss_ctc 18.890259 loss_rnnt 10.526579 hw_loss 0.064941 lr 0.00037536 rank 0
2023-02-22 16:31:53,626 DEBUG TRAIN Batch 21/2300 loss 20.725384 loss_att 21.131435 loss_ctc 23.193464 loss_rnnt 20.244411 hw_loss 0.132531 lr 0.00037535 rank 7
2023-02-22 16:31:53,628 DEBUG TRAIN Batch 21/2300 loss 9.623285 loss_att 10.712748 loss_ctc 12.946161 loss_rnnt 8.909348 hw_loss 0.099362 lr 0.00037537 rank 4
2023-02-22 16:31:53,630 DEBUG TRAIN Batch 21/2300 loss 8.218237 loss_att 13.331661 loss_ctc 10.257802 loss_rnnt 6.883736 hw_loss 0.074764 lr 0.00037541 rank 6
2023-02-22 16:31:53,635 DEBUG TRAIN Batch 21/2300 loss 16.116289 loss_att 15.680744 loss_ctc 18.049175 loss_rnnt 15.902323 hw_loss 0.081297 lr 0.00037530 rank 2
2023-02-22 16:31:53,635 DEBUG TRAIN Batch 21/2300 loss 9.951969 loss_att 12.661652 loss_ctc 15.409555 loss_rnnt 8.608727 hw_loss 0.138052 lr 0.00037532 rank 3
2023-02-22 16:31:53,635 DEBUG TRAIN Batch 21/2300 loss 7.993149 loss_att 11.972967 loss_ctc 12.208155 loss_rnnt 6.574997 hw_loss 0.112850 lr 0.00037535 rank 1
2023-02-22 16:33:08,691 DEBUG TRAIN Batch 21/2400 loss 18.026062 loss_att 20.353590 loss_ctc 27.047642 loss_rnnt 16.337673 hw_loss 0.037507 lr 0.00037527 rank 4
2023-02-22 16:33:08,692 DEBUG TRAIN Batch 21/2400 loss 4.580909 loss_att 8.648512 loss_ctc 8.164869 loss_rnnt 3.228399 hw_loss 0.114614 lr 0.00037528 rank 5
2023-02-22 16:33:08,693 DEBUG TRAIN Batch 21/2400 loss 8.929476 loss_att 10.740803 loss_ctc 11.142788 loss_rnnt 8.220531 hw_loss 0.096696 lr 0.00037526 rank 0
2023-02-22 16:33:08,696 DEBUG TRAIN Batch 21/2400 loss 13.215871 loss_att 14.106276 loss_ctc 16.675392 loss_rnnt 12.538452 hw_loss 0.071376 lr 0.00037519 rank 2
2023-02-22 16:33:08,697 DEBUG TRAIN Batch 21/2400 loss 4.173310 loss_att 7.587609 loss_ctc 6.935825 loss_rnnt 3.084135 hw_loss 0.071214 lr 0.00037524 rank 7
2023-02-22 16:33:08,699 DEBUG TRAIN Batch 21/2400 loss 9.717295 loss_att 13.628005 loss_ctc 17.166868 loss_rnnt 7.898920 hw_loss 0.080542 lr 0.00037525 rank 1
2023-02-22 16:33:08,699 DEBUG TRAIN Batch 21/2400 loss 6.451263 loss_att 9.995380 loss_ctc 7.019868 loss_rnnt 5.608220 hw_loss 0.109511 lr 0.00037530 rank 6
2023-02-22 16:33:08,710 DEBUG TRAIN Batch 21/2400 loss 19.058121 loss_att 20.037773 loss_ctc 27.057333 loss_rnnt 17.742535 hw_loss 0.099547 lr 0.00037521 rank 3
2023-02-22 16:34:26,528 DEBUG TRAIN Batch 21/2500 loss 15.506225 loss_att 20.669458 loss_ctc 22.212048 loss_rnnt 13.527264 hw_loss 0.097883 lr 0.00037515 rank 0
2023-02-22 16:34:26,531 DEBUG TRAIN Batch 21/2500 loss 7.091192 loss_att 8.992821 loss_ctc 11.912266 loss_rnnt 5.970141 hw_loss 0.183592 lr 0.00037516 rank 4
2023-02-22 16:34:26,533 DEBUG TRAIN Batch 21/2500 loss 7.172180 loss_att 9.452602 loss_ctc 8.910656 loss_rnnt 6.438007 hw_loss 0.086795 lr 0.00037514 rank 1
2023-02-22 16:34:26,538 DEBUG TRAIN Batch 21/2500 loss 11.531123 loss_att 13.810869 loss_ctc 16.690563 loss_rnnt 10.327991 hw_loss 0.111107 lr 0.00037517 rank 5
2023-02-22 16:34:26,538 DEBUG TRAIN Batch 21/2500 loss 16.298092 loss_att 17.524702 loss_ctc 22.974516 loss_rnnt 15.063765 hw_loss 0.185281 lr 0.00037513 rank 7
2023-02-22 16:34:26,540 DEBUG TRAIN Batch 21/2500 loss 10.503622 loss_att 12.237651 loss_ctc 16.533457 loss_rnnt 9.302916 hw_loss 0.093606 lr 0.00037510 rank 3
2023-02-22 16:34:26,540 DEBUG TRAIN Batch 21/2500 loss 14.030089 loss_att 14.647525 loss_ctc 18.444115 loss_rnnt 13.268597 hw_loss 0.092753 lr 0.00037509 rank 2
2023-02-22 16:34:26,540 DEBUG TRAIN Batch 21/2500 loss 11.510926 loss_att 12.315887 loss_ctc 15.410673 loss_rnnt 10.719922 hw_loss 0.206335 lr 0.00037520 rank 6
2023-02-22 16:35:41,666 DEBUG TRAIN Batch 21/2600 loss 5.357221 loss_att 9.835893 loss_ctc 9.733072 loss_rnnt 3.849941 hw_loss 0.052686 lr 0.00037503 rank 7
2023-02-22 16:35:41,668 DEBUG TRAIN Batch 21/2600 loss 7.284858 loss_att 9.107754 loss_ctc 12.524085 loss_rnnt 6.130733 hw_loss 0.170593 lr 0.00037505 rank 0
2023-02-22 16:35:41,668 DEBUG TRAIN Batch 21/2600 loss 6.978241 loss_att 10.977651 loss_ctc 11.231662 loss_rnnt 5.611069 hw_loss 0.000315 lr 0.00037505 rank 4
2023-02-22 16:35:41,671 DEBUG TRAIN Batch 21/2600 loss 4.935398 loss_att 7.747660 loss_ctc 6.616038 loss_rnnt 4.073167 hw_loss 0.141923 lr 0.00037500 rank 3
2023-02-22 16:35:41,672 DEBUG TRAIN Batch 21/2600 loss 12.309220 loss_att 14.598490 loss_ctc 18.084991 loss_rnnt 11.065689 hw_loss 0.029202 lr 0.00037498 rank 2
2023-02-22 16:35:41,674 DEBUG TRAIN Batch 21/2600 loss 7.092669 loss_att 10.060444 loss_ctc 10.524883 loss_rnnt 6.035866 hw_loss 0.010536 lr 0.00037509 rank 6
2023-02-22 16:35:41,674 DEBUG TRAIN Batch 21/2600 loss 14.420159 loss_att 16.932623 loss_ctc 19.044699 loss_rnnt 13.254176 hw_loss 0.087913 lr 0.00037507 rank 5
2023-02-22 16:35:41,680 DEBUG TRAIN Batch 21/2600 loss 9.405180 loss_att 9.611612 loss_ctc 12.082210 loss_rnnt 8.945284 hw_loss 0.115636 lr 0.00037504 rank 1
2023-02-22 16:36:57,097 DEBUG TRAIN Batch 21/2700 loss 6.656504 loss_att 9.021043 loss_ctc 9.608897 loss_rnnt 5.732215 hw_loss 0.108241 lr 0.00037496 rank 5
2023-02-22 16:36:57,098 DEBUG TRAIN Batch 21/2700 loss 0.938306 loss_att 3.479844 loss_ctc 0.970242 loss_rnnt 0.385668 hw_loss 0.075136 lr 0.00037499 rank 6
2023-02-22 16:36:57,099 DEBUG TRAIN Batch 21/2700 loss 9.036110 loss_att 12.448263 loss_ctc 13.663630 loss_rnnt 7.666280 hw_loss 0.131992 lr 0.00037492 rank 7
2023-02-22 16:36:57,099 DEBUG TRAIN Batch 21/2700 loss 7.089739 loss_att 8.843078 loss_ctc 10.764926 loss_rnnt 6.169739 hw_loss 0.148701 lr 0.00037495 rank 4
2023-02-22 16:36:57,100 DEBUG TRAIN Batch 21/2700 loss 6.666831 loss_att 9.799398 loss_ctc 8.028778 loss_rnnt 5.833624 hw_loss 0.047062 lr 0.00037494 rank 0
2023-02-22 16:36:57,101 DEBUG TRAIN Batch 21/2700 loss 8.214230 loss_att 13.936027 loss_ctc 18.250771 loss_rnnt 5.652563 hw_loss 0.148315 lr 0.00037487 rank 2
2023-02-22 16:36:57,105 DEBUG TRAIN Batch 21/2700 loss 3.555962 loss_att 9.957197 loss_ctc 5.875652 loss_rnnt 1.860610 hw_loss 0.198399 lr 0.00037489 rank 3
2023-02-22 16:36:57,105 DEBUG TRAIN Batch 21/2700 loss 3.846225 loss_att 5.539578 loss_ctc 4.263016 loss_rnnt 3.426488 hw_loss 0.047802 lr 0.00037493 rank 1
2023-02-22 16:38:13,625 DEBUG TRAIN Batch 21/2800 loss 7.243784 loss_att 10.572078 loss_ctc 8.815414 loss_rnnt 6.250062 hw_loss 0.222211 lr 0.00037484 rank 4
2023-02-22 16:38:13,628 DEBUG TRAIN Batch 21/2800 loss 6.569405 loss_att 8.300234 loss_ctc 8.890422 loss_rnnt 5.876353 hw_loss 0.070156 lr 0.00037486 rank 5
2023-02-22 16:38:13,629 DEBUG TRAIN Batch 21/2800 loss 10.941792 loss_att 10.941733 loss_ctc 14.668266 loss_rnnt 10.416282 hw_loss 0.053735 lr 0.00037477 rank 2
2023-02-22 16:38:13,630 DEBUG TRAIN Batch 21/2800 loss 16.023510 loss_att 22.215572 loss_ctc 25.964046 loss_rnnt 13.398166 hw_loss 0.115363 lr 0.00037483 rank 0
2023-02-22 16:38:13,630 DEBUG TRAIN Batch 21/2800 loss 7.343530 loss_att 8.574403 loss_ctc 7.654010 loss_rnnt 6.955945 hw_loss 0.187523 lr 0.00037479 rank 3
2023-02-22 16:38:13,630 DEBUG TRAIN Batch 21/2800 loss 8.490437 loss_att 11.894981 loss_ctc 11.777295 loss_rnnt 7.332032 hw_loss 0.073588 lr 0.00037488 rank 6
2023-02-22 16:38:13,630 DEBUG TRAIN Batch 21/2800 loss 12.073329 loss_att 14.313057 loss_ctc 17.356295 loss_rnnt 10.862258 hw_loss 0.110120 lr 0.00037482 rank 7
2023-02-22 16:38:13,632 DEBUG TRAIN Batch 21/2800 loss 6.075818 loss_att 9.123572 loss_ctc 5.215374 loss_rnnt 5.518306 hw_loss 0.117538 lr 0.00037483 rank 1
2023-02-22 16:39:31,466 DEBUG TRAIN Batch 21/2900 loss 15.745281 loss_att 18.130468 loss_ctc 22.515934 loss_rnnt 14.342697 hw_loss 0.042737 lr 0.00037473 rank 0
2023-02-22 16:39:31,470 DEBUG TRAIN Batch 21/2900 loss 4.429919 loss_att 6.773964 loss_ctc 5.692719 loss_rnnt 3.689372 hw_loss 0.193810 lr 0.00037471 rank 7
2023-02-22 16:39:31,470 DEBUG TRAIN Batch 21/2900 loss 1.852059 loss_att 4.553899 loss_ctc 4.078098 loss_rnnt 1.006836 hw_loss 0.015094 lr 0.00037477 rank 6
2023-02-22 16:39:31,470 DEBUG TRAIN Batch 21/2900 loss 9.445440 loss_att 11.040463 loss_ctc 11.727474 loss_rnnt 8.801609 hw_loss 0.038541 lr 0.00037475 rank 5
2023-02-22 16:39:31,471 DEBUG TRAIN Batch 21/2900 loss 9.762883 loss_att 11.873737 loss_ctc 10.225075 loss_rnnt 9.273583 hw_loss 0.010318 lr 0.00037474 rank 4
2023-02-22 16:39:31,473 DEBUG TRAIN Batch 21/2900 loss 2.051126 loss_att 4.341369 loss_ctc 3.451579 loss_rnnt 1.392127 hw_loss 0.026669 lr 0.00037472 rank 1
2023-02-22 16:39:31,477 DEBUG TRAIN Batch 21/2900 loss 2.732270 loss_att 6.520601 loss_ctc 3.629357 loss_rnnt 1.778680 hw_loss 0.143086 lr 0.00037468 rank 3
2023-02-22 16:39:31,478 DEBUG TRAIN Batch 21/2900 loss 7.804523 loss_att 9.581196 loss_ctc 9.551433 loss_rnnt 7.202131 hw_loss 0.026504 lr 0.00037466 rank 2
2023-02-22 16:40:46,225 DEBUG TRAIN Batch 21/3000 loss 7.526271 loss_att 9.653918 loss_ctc 9.853584 loss_rnnt 6.790370 hw_loss 0.000119 lr 0.00037465 rank 5
2023-02-22 16:40:46,225 DEBUG TRAIN Batch 21/3000 loss 6.996968 loss_att 10.389662 loss_ctc 11.245210 loss_rnnt 5.677420 hw_loss 0.139831 lr 0.00037463 rank 4
2023-02-22 16:40:46,235 DEBUG TRAIN Batch 21/3000 loss 17.188194 loss_att 22.622894 loss_ctc 30.830393 loss_rnnt 14.265886 hw_loss 0.030764 lr 0.00037462 rank 0
2023-02-22 16:40:46,235 DEBUG TRAIN Batch 21/3000 loss 6.094161 loss_att 8.665439 loss_ctc 8.005827 loss_rnnt 5.306630 hw_loss 0.034475 lr 0.00037462 rank 1
2023-02-22 16:40:46,235 DEBUG TRAIN Batch 21/3000 loss 5.091869 loss_att 11.492247 loss_ctc 8.093754 loss_rnnt 3.331254 hw_loss 0.150541 lr 0.00037461 rank 7
2023-02-22 16:40:46,235 DEBUG TRAIN Batch 21/3000 loss 4.794713 loss_att 6.314233 loss_ctc 6.788597 loss_rnnt 4.201801 hw_loss 0.043420 lr 0.00037458 rank 3
2023-02-22 16:40:46,236 DEBUG TRAIN Batch 21/3000 loss 10.576569 loss_att 11.075777 loss_ctc 10.722153 loss_rnnt 10.415576 hw_loss 0.078264 lr 0.00037456 rank 2
2023-02-22 16:40:46,283 DEBUG TRAIN Batch 21/3000 loss 10.682128 loss_att 12.576152 loss_ctc 14.837329 loss_rnnt 9.670807 hw_loss 0.147167 lr 0.00037467 rank 6
2023-02-22 16:42:00,590 DEBUG TRAIN Batch 21/3100 loss 18.620388 loss_att 21.060877 loss_ctc 22.347254 loss_rnnt 17.607441 hw_loss 0.052374 lr 0.00037450 rank 7
2023-02-22 16:42:00,591 DEBUG TRAIN Batch 21/3100 loss 6.641910 loss_att 9.267428 loss_ctc 11.242893 loss_rnnt 5.476308 hw_loss 0.050688 lr 0.00037454 rank 5
2023-02-22 16:42:00,594 DEBUG TRAIN Batch 21/3100 loss 9.726814 loss_att 12.351183 loss_ctc 13.856400 loss_rnnt 8.567107 hw_loss 0.157917 lr 0.00037453 rank 4
2023-02-22 16:42:00,599 DEBUG TRAIN Batch 21/3100 loss 9.886930 loss_att 12.485720 loss_ctc 13.353842 loss_rnnt 8.874228 hw_loss 0.057540 lr 0.00037451 rank 1
2023-02-22 16:42:00,599 DEBUG TRAIN Batch 21/3100 loss 8.193135 loss_att 11.276381 loss_ctc 9.947763 loss_rnnt 7.274950 hw_loss 0.126723 lr 0.00037452 rank 0
2023-02-22 16:42:00,603 DEBUG TRAIN Batch 21/3100 loss 8.198294 loss_att 9.787663 loss_ctc 11.743002 loss_rnnt 7.350470 hw_loss 0.107480 lr 0.00037456 rank 6
2023-02-22 16:42:00,608 DEBUG TRAIN Batch 21/3100 loss 8.000808 loss_att 9.720787 loss_ctc 13.166369 loss_rnnt 6.897929 hw_loss 0.131516 lr 0.00037445 rank 2
2023-02-22 16:42:00,629 DEBUG TRAIN Batch 21/3100 loss 8.621884 loss_att 9.516253 loss_ctc 11.753793 loss_rnnt 8.001142 hw_loss 0.045527 lr 0.00037447 rank 3
2023-02-22 16:43:18,994 DEBUG TRAIN Batch 21/3200 loss 10.636494 loss_att 12.706876 loss_ctc 16.415964 loss_rnnt 9.375381 hw_loss 0.143324 lr 0.00037440 rank 7
2023-02-22 16:43:18,995 DEBUG TRAIN Batch 21/3200 loss 10.613874 loss_att 15.423717 loss_ctc 15.854713 loss_rnnt 8.941663 hw_loss 0.021497 lr 0.00037441 rank 0
2023-02-22 16:43:18,997 DEBUG TRAIN Batch 21/3200 loss 8.310822 loss_att 9.436235 loss_ctc 10.404113 loss_rnnt 7.765684 hw_loss 0.076780 lr 0.00037437 rank 3
2023-02-22 16:43:18,998 DEBUG TRAIN Batch 21/3200 loss 1.944697 loss_att 4.260709 loss_ctc 2.868103 loss_rnnt 1.317976 hw_loss 0.075747 lr 0.00037435 rank 2
2023-02-22 16:43:18,999 DEBUG TRAIN Batch 21/3200 loss 5.257268 loss_att 7.900271 loss_ctc 7.709266 loss_rnnt 4.319553 hw_loss 0.154091 lr 0.00037446 rank 6
2023-02-22 16:43:19,000 DEBUG TRAIN Batch 21/3200 loss 6.291427 loss_att 8.630171 loss_ctc 10.523495 loss_rnnt 5.240884 hw_loss 0.034722 lr 0.00037444 rank 5
2023-02-22 16:43:18,999 DEBUG TRAIN Batch 21/3200 loss 9.158487 loss_att 9.815881 loss_ctc 11.043621 loss_rnnt 8.696428 hw_loss 0.148554 lr 0.00037441 rank 1
2023-02-22 16:43:19,024 DEBUG TRAIN Batch 21/3200 loss 9.543915 loss_att 13.983194 loss_ctc 17.211460 loss_rnnt 7.546161 hw_loss 0.164169 lr 0.00037442 rank 4
2023-02-22 16:44:33,954 DEBUG TRAIN Batch 21/3300 loss 4.739926 loss_att 9.262033 loss_ctc 7.099148 loss_rnnt 3.519404 hw_loss 0.002883 lr 0.00037426 rank 3
2023-02-22 16:44:33,954 DEBUG TRAIN Batch 21/3300 loss 8.118789 loss_att 12.061773 loss_ctc 11.757713 loss_rnnt 6.787941 hw_loss 0.106990 lr 0.00037435 rank 6
2023-02-22 16:44:33,956 DEBUG TRAIN Batch 21/3300 loss 5.746485 loss_att 8.410853 loss_ctc 9.253935 loss_rnnt 4.712642 hw_loss 0.062455 lr 0.00037431 rank 0
2023-02-22 16:44:33,956 DEBUG TRAIN Batch 21/3300 loss 4.275149 loss_att 9.307946 loss_ctc 8.304626 loss_rnnt 2.717417 hw_loss 0.026080 lr 0.00037430 rank 1
2023-02-22 16:44:33,957 DEBUG TRAIN Batch 21/3300 loss 5.544344 loss_att 8.979216 loss_ctc 10.378744 loss_rnnt 4.208813 hw_loss 0.007445 lr 0.00037429 rank 7
2023-02-22 16:44:33,957 DEBUG TRAIN Batch 21/3300 loss 11.711552 loss_att 16.570284 loss_ctc 23.161375 loss_rnnt 9.121836 hw_loss 0.171238 lr 0.00037432 rank 4
2023-02-22 16:44:33,961 DEBUG TRAIN Batch 21/3300 loss 9.952827 loss_att 13.107937 loss_ctc 16.860596 loss_rnnt 8.354900 hw_loss 0.086004 lr 0.00037433 rank 5
2023-02-22 16:44:34,004 DEBUG TRAIN Batch 21/3300 loss 3.796094 loss_att 7.191522 loss_ctc 5.185493 loss_rnnt 2.899450 hw_loss 0.060571 lr 0.00037424 rank 2
2023-02-22 16:45:49,464 DEBUG TRAIN Batch 21/3400 loss 2.978607 loss_att 5.585074 loss_ctc 5.867015 loss_rnnt 2.040319 hw_loss 0.059763 lr 0.00037419 rank 7
2023-02-22 16:45:49,466 DEBUG TRAIN Batch 21/3400 loss 10.110226 loss_att 12.890701 loss_ctc 15.665171 loss_rnnt 8.796648 hw_loss 0.031542 lr 0.00037425 rank 6
2023-02-22 16:45:49,466 DEBUG TRAIN Batch 21/3400 loss 13.867008 loss_att 15.509070 loss_ctc 17.864178 loss_rnnt 12.933598 hw_loss 0.135079 lr 0.00037423 rank 5
2023-02-22 16:45:49,470 DEBUG TRAIN Batch 21/3400 loss 6.961780 loss_att 11.125179 loss_ctc 8.007763 loss_rnnt 5.956137 hw_loss 0.062809 lr 0.00037416 rank 3
2023-02-22 16:45:49,473 DEBUG TRAIN Batch 21/3400 loss 5.089429 loss_att 6.951285 loss_ctc 7.237832 loss_rnnt 4.421985 hw_loss 0.016160 lr 0.00037420 rank 0
2023-02-22 16:45:49,474 DEBUG TRAIN Batch 21/3400 loss 12.176973 loss_att 16.063328 loss_ctc 18.617355 loss_rnnt 10.470122 hw_loss 0.132868 lr 0.00037421 rank 4
2023-02-22 16:45:49,475 DEBUG TRAIN Batch 21/3400 loss 16.891336 loss_att 17.253189 loss_ctc 22.397230 loss_rnnt 15.986989 hw_loss 0.183481 lr 0.00037414 rank 2
2023-02-22 16:45:49,520 DEBUG TRAIN Batch 21/3400 loss 6.280734 loss_att 9.558445 loss_ctc 8.414301 loss_rnnt 5.259013 hw_loss 0.153192 lr 0.00037420 rank 1
2023-02-22 16:47:06,536 DEBUG TRAIN Batch 21/3500 loss 13.446985 loss_att 18.318607 loss_ctc 20.527908 loss_rnnt 11.430290 hw_loss 0.184214 lr 0.00037405 rank 3
2023-02-22 16:47:06,537 DEBUG TRAIN Batch 21/3500 loss 11.170416 loss_att 12.011112 loss_ctc 14.779455 loss_rnnt 10.484811 hw_loss 0.067987 lr 0.00037412 rank 5
2023-02-22 16:47:06,537 DEBUG TRAIN Batch 21/3500 loss 8.111340 loss_att 9.751904 loss_ctc 12.159644 loss_rnnt 7.203228 hw_loss 0.075422 lr 0.00037408 rank 7
2023-02-22 16:47:06,537 DEBUG TRAIN Batch 21/3500 loss 7.787508 loss_att 11.056996 loss_ctc 10.731639 loss_rnnt 6.662134 hw_loss 0.147988 lr 0.00037409 rank 1
2023-02-22 16:47:06,537 DEBUG TRAIN Batch 21/3500 loss 12.429402 loss_att 12.986116 loss_ctc 16.809477 loss_rnnt 11.696281 hw_loss 0.070814 lr 0.00037410 rank 0
2023-02-22 16:47:06,538 DEBUG TRAIN Batch 21/3500 loss 6.673891 loss_att 8.046377 loss_ctc 9.023705 loss_rnnt 6.019979 hw_loss 0.123949 lr 0.00037403 rank 2
2023-02-22 16:47:06,538 DEBUG TRAIN Batch 21/3500 loss 7.764969 loss_att 10.569334 loss_ctc 9.621817 loss_rnnt 6.934878 hw_loss 0.040573 lr 0.00037411 rank 4
2023-02-22 16:47:06,541 DEBUG TRAIN Batch 21/3500 loss 5.091425 loss_att 8.965613 loss_ctc 7.152498 loss_rnnt 4.031933 hw_loss 0.018459 lr 0.00037414 rank 6
2023-02-22 16:48:22,387 DEBUG TRAIN Batch 21/3600 loss 12.465525 loss_att 14.255571 loss_ctc 18.569756 loss_rnnt 11.206389 hw_loss 0.163555 lr 0.00037400 rank 4
2023-02-22 16:48:22,390 DEBUG TRAIN Batch 21/3600 loss 13.461161 loss_att 16.031921 loss_ctc 21.742920 loss_rnnt 11.754159 hw_loss 0.166152 lr 0.00037398 rank 7
2023-02-22 16:48:22,390 DEBUG TRAIN Batch 21/3600 loss 5.520650 loss_att 9.081447 loss_ctc 8.560057 loss_rnnt 4.348084 hw_loss 0.103410 lr 0.00037399 rank 0
2023-02-22 16:48:22,391 DEBUG TRAIN Batch 21/3600 loss 5.627254 loss_att 13.303744 loss_ctc 11.928196 loss_rnnt 3.202952 hw_loss 0.091648 lr 0.00037402 rank 5
2023-02-22 16:48:22,398 DEBUG TRAIN Batch 21/3600 loss 5.586854 loss_att 8.023853 loss_ctc 11.308010 loss_rnnt 4.326319 hw_loss 0.019338 lr 0.00037399 rank 1
2023-02-22 16:48:22,399 DEBUG TRAIN Batch 21/3600 loss 15.769239 loss_att 15.908054 loss_ctc 17.544254 loss_rnnt 15.453588 hw_loss 0.096038 lr 0.00037393 rank 2
2023-02-22 16:48:22,400 DEBUG TRAIN Batch 21/3600 loss 4.717923 loss_att 7.917659 loss_ctc 10.766317 loss_rnnt 3.232416 hw_loss 0.073325 lr 0.00037395 rank 3
2023-02-22 16:48:22,401 DEBUG TRAIN Batch 21/3600 loss 11.231776 loss_att 12.079236 loss_ctc 13.529180 loss_rnnt 10.701094 hw_loss 0.102883 lr 0.00037404 rank 6
2023-02-22 16:49:37,700 DEBUG TRAIN Batch 21/3700 loss 9.092359 loss_att 11.007093 loss_ctc 14.319054 loss_rnnt 7.933911 hw_loss 0.147391 lr 0.00037390 rank 4
2023-02-22 16:49:37,700 DEBUG TRAIN Batch 21/3700 loss 14.956524 loss_att 17.708086 loss_ctc 20.314579 loss_rnnt 13.681433 hw_loss 0.019448 lr 0.00037387 rank 7
2023-02-22 16:49:37,701 DEBUG TRAIN Batch 21/3700 loss 13.971587 loss_att 18.264193 loss_ctc 24.999882 loss_rnnt 11.627945 hw_loss 0.027529 lr 0.00037391 rank 5
2023-02-22 16:49:37,704 DEBUG TRAIN Batch 21/3700 loss 19.815184 loss_att 23.115864 loss_ctc 30.435776 loss_rnnt 17.684160 hw_loss 0.102763 lr 0.00037389 rank 0
2023-02-22 16:49:37,705 DEBUG TRAIN Batch 21/3700 loss 5.565874 loss_att 7.605444 loss_ctc 9.351957 loss_rnnt 4.634183 hw_loss 0.035561 lr 0.00037384 rank 3
2023-02-22 16:49:37,705 DEBUG TRAIN Batch 21/3700 loss 11.351597 loss_att 15.301447 loss_ctc 16.002670 loss_rnnt 9.888613 hw_loss 0.099133 lr 0.00037388 rank 1
2023-02-22 16:49:37,707 DEBUG TRAIN Batch 21/3700 loss 8.686940 loss_att 9.915195 loss_ctc 10.317758 loss_rnnt 8.132284 hw_loss 0.171677 lr 0.00037383 rank 2
2023-02-22 16:49:37,749 DEBUG TRAIN Batch 21/3700 loss 7.271306 loss_att 8.816264 loss_ctc 9.771324 loss_rnnt 6.574749 hw_loss 0.101682 lr 0.00037393 rank 6
2023-02-22 16:50:54,611 DEBUG TRAIN Batch 21/3800 loss 8.741824 loss_att 11.144975 loss_ctc 14.796106 loss_rnnt 7.404974 hw_loss 0.091842 lr 0.00037374 rank 3
2023-02-22 16:50:54,613 DEBUG TRAIN Batch 21/3800 loss 6.099079 loss_att 7.737017 loss_ctc 7.719845 loss_rnnt 5.485935 hw_loss 0.130226 lr 0.00037377 rank 7
2023-02-22 16:50:54,613 DEBUG TRAIN Batch 21/3800 loss 7.812433 loss_att 9.428121 loss_ctc 10.981428 loss_rnnt 7.007855 hw_loss 0.110451 lr 0.00037381 rank 5
2023-02-22 16:50:54,614 DEBUG TRAIN Batch 21/3800 loss 9.957756 loss_att 11.752110 loss_ctc 12.182775 loss_rnnt 9.272547 hw_loss 0.055631 lr 0.00037379 rank 0
2023-02-22 16:50:54,613 DEBUG TRAIN Batch 21/3800 loss 8.188141 loss_att 9.143427 loss_ctc 10.799484 loss_rnnt 7.622787 hw_loss 0.048969 lr 0.00037372 rank 2
2023-02-22 16:50:54,615 DEBUG TRAIN Batch 21/3800 loss 3.326299 loss_att 6.678133 loss_ctc 5.395483 loss_rnnt 2.314834 hw_loss 0.122263 lr 0.00037383 rank 6
2023-02-22 16:50:54,615 DEBUG TRAIN Batch 21/3800 loss 6.812226 loss_att 7.153703 loss_ctc 8.932150 loss_rnnt 6.405187 hw_loss 0.105163 lr 0.00037379 rank 4
2023-02-22 16:50:54,631 DEBUG TRAIN Batch 21/3800 loss 10.621295 loss_att 13.153608 loss_ctc 16.713285 loss_rnnt 9.267863 hw_loss 0.065070 lr 0.00037378 rank 1
2023-02-22 16:52:12,609 DEBUG TRAIN Batch 21/3900 loss 8.196135 loss_att 8.905016 loss_ctc 11.166052 loss_rnnt 7.586991 hw_loss 0.133834 lr 0.00037368 rank 0
2023-02-22 16:52:12,609 DEBUG TRAIN Batch 21/3900 loss 12.008679 loss_att 15.884174 loss_ctc 22.041534 loss_rnnt 9.817991 hw_loss 0.146016 lr 0.00037369 rank 4
2023-02-22 16:52:12,613 DEBUG TRAIN Batch 21/3900 loss 23.922764 loss_att 29.028030 loss_ctc 35.140060 loss_rnnt 21.369804 hw_loss 0.068002 lr 0.00037370 rank 5
2023-02-22 16:52:12,613 DEBUG TRAIN Batch 21/3900 loss 8.945022 loss_att 11.439993 loss_ctc 12.302181 loss_rnnt 7.953474 hw_loss 0.084250 lr 0.00037373 rank 6
2023-02-22 16:52:12,617 DEBUG TRAIN Batch 21/3900 loss 19.380035 loss_att 19.707979 loss_ctc 22.950521 loss_rnnt 18.790245 hw_loss 0.090257 lr 0.00037364 rank 3
2023-02-22 16:52:12,618 DEBUG TRAIN Batch 21/3900 loss 1.824340 loss_att 5.405962 loss_ctc 3.295086 loss_rnnt 0.860711 hw_loss 0.096009 lr 0.00037362 rank 2
2023-02-22 16:52:12,618 DEBUG TRAIN Batch 21/3900 loss 5.323193 loss_att 10.565594 loss_ctc 8.057917 loss_rnnt 3.869479 hw_loss 0.076132 lr 0.00037367 rank 7
2023-02-22 16:52:12,618 DEBUG TRAIN Batch 21/3900 loss 8.396073 loss_att 9.157385 loss_ctc 11.106031 loss_rnnt 7.793059 hw_loss 0.167671 lr 0.00037367 rank 1
2023-02-22 16:53:26,966 DEBUG TRAIN Batch 21/4000 loss 4.281101 loss_att 7.253294 loss_ctc 4.748221 loss_rnnt 3.564350 hw_loss 0.112556 lr 0.00037353 rank 3
2023-02-22 16:53:26,966 DEBUG TRAIN Batch 21/4000 loss 7.049412 loss_att 10.130642 loss_ctc 9.220951 loss_rnnt 6.088730 hw_loss 0.102933 lr 0.00037360 rank 5
2023-02-22 16:53:26,966 DEBUG TRAIN Batch 21/4000 loss 7.782393 loss_att 9.308918 loss_ctc 11.703833 loss_rnnt 6.905286 hw_loss 0.091769 lr 0.00037356 rank 7
2023-02-22 16:53:26,969 DEBUG TRAIN Batch 21/4000 loss 10.415725 loss_att 13.743999 loss_ctc 17.800236 loss_rnnt 8.688593 hw_loss 0.144141 lr 0.00037358 rank 0
2023-02-22 16:53:26,972 DEBUG TRAIN Batch 21/4000 loss 12.444034 loss_att 18.482374 loss_ctc 18.232101 loss_rnnt 10.407956 hw_loss 0.106251 lr 0.00037359 rank 4
2023-02-22 16:53:26,972 DEBUG TRAIN Batch 21/4000 loss 7.929607 loss_att 14.391657 loss_ctc 18.517010 loss_rnnt 5.218925 hw_loss 0.012411 lr 0.00037362 rank 6
2023-02-22 16:53:26,976 DEBUG TRAIN Batch 21/4000 loss 9.100778 loss_att 12.959854 loss_ctc 12.129676 loss_rnnt 7.844404 hw_loss 0.151322 lr 0.00037357 rank 1
2023-02-22 16:53:27,019 DEBUG TRAIN Batch 21/4000 loss 9.560440 loss_att 14.229208 loss_ctc 13.301940 loss_rnnt 8.074799 hw_loss 0.099415 lr 0.00037351 rank 2
2023-02-22 16:54:42,375 DEBUG TRAIN Batch 21/4100 loss 15.935169 loss_att 19.437927 loss_ctc 21.411140 loss_rnnt 14.483711 hw_loss 0.038956 lr 0.00037347 rank 1
2023-02-22 16:54:42,376 DEBUG TRAIN Batch 21/4100 loss 9.715473 loss_att 14.222597 loss_ctc 12.444704 loss_rnnt 8.423624 hw_loss 0.049737 lr 0.00037348 rank 4
2023-02-22 16:54:42,379 DEBUG TRAIN Batch 21/4100 loss 10.902565 loss_att 14.713051 loss_ctc 15.798472 loss_rnnt 9.473402 hw_loss 0.026772 lr 0.00037349 rank 5
2023-02-22 16:54:42,379 DEBUG TRAIN Batch 21/4100 loss 15.803645 loss_att 19.574255 loss_ctc 29.861118 loss_rnnt 13.138821 hw_loss 0.068200 lr 0.00037347 rank 0
2023-02-22 16:54:42,382 DEBUG TRAIN Batch 21/4100 loss 9.638989 loss_att 13.197026 loss_ctc 12.006975 loss_rnnt 8.589053 hw_loss 0.042372 lr 0.00037346 rank 7
2023-02-22 16:54:42,385 DEBUG TRAIN Batch 21/4100 loss 2.053688 loss_att 3.938018 loss_ctc 1.766695 loss_rnnt 1.680833 hw_loss 0.064228 lr 0.00037343 rank 3
2023-02-22 16:54:42,387 DEBUG TRAIN Batch 21/4100 loss 10.819798 loss_att 13.727487 loss_ctc 14.603181 loss_rnnt 9.673090 hw_loss 0.113850 lr 0.00037341 rank 2
2023-02-22 16:54:42,387 DEBUG TRAIN Batch 21/4100 loss 12.190387 loss_att 17.995575 loss_ctc 21.484711 loss_rnnt 9.737749 hw_loss 0.098168 lr 0.00037352 rank 6
2023-02-22 16:55:58,100 DEBUG TRAIN Batch 21/4200 loss 9.290070 loss_att 13.714151 loss_ctc 14.660894 loss_rnnt 7.631434 hw_loss 0.108204 lr 0.00037335 rank 7
2023-02-22 16:55:58,101 DEBUG TRAIN Batch 21/4200 loss 7.664858 loss_att 9.012742 loss_ctc 9.475694 loss_rnnt 7.101947 hw_loss 0.097293 lr 0.00037339 rank 5
2023-02-22 16:55:58,104 DEBUG TRAIN Batch 21/4200 loss 6.437903 loss_att 6.552517 loss_ctc 7.947985 loss_rnnt 6.202188 hw_loss 0.021466 lr 0.00037337 rank 0
2023-02-22 16:55:58,106 DEBUG TRAIN Batch 21/4200 loss 3.760963 loss_att 7.169433 loss_ctc 7.029956 loss_rnnt 2.636902 hw_loss 0.012190 lr 0.00037330 rank 2
2023-02-22 16:55:58,110 DEBUG TRAIN Batch 21/4200 loss 9.386219 loss_att 11.498756 loss_ctc 12.468705 loss_rnnt 8.526400 hw_loss 0.049337 lr 0.00037341 rank 6
2023-02-22 16:55:58,111 DEBUG TRAIN Batch 21/4200 loss 8.868298 loss_att 12.198565 loss_ctc 13.820061 loss_rnnt 7.507853 hw_loss 0.064042 lr 0.00037338 rank 4
2023-02-22 16:55:58,117 DEBUG TRAIN Batch 21/4200 loss 6.933402 loss_att 9.893068 loss_ctc 9.630369 loss_rnnt 5.937692 hw_loss 0.082839 lr 0.00037332 rank 3
2023-02-22 16:55:58,150 DEBUG TRAIN Batch 21/4200 loss 6.780270 loss_att 8.918174 loss_ctc 8.235661 loss_rnnt 6.101176 hw_loss 0.107740 lr 0.00037336 rank 1
2023-02-22 16:57:16,034 DEBUG TRAIN Batch 21/4300 loss 12.323636 loss_att 13.648628 loss_ctc 14.583804 loss_rnnt 11.683906 hw_loss 0.137580 lr 0.00037325 rank 7
2023-02-22 16:57:16,035 DEBUG TRAIN Batch 21/4300 loss 5.791185 loss_att 8.344717 loss_ctc 9.046018 loss_rnnt 4.793834 hw_loss 0.098752 lr 0.00037326 rank 0
2023-02-22 16:57:16,036 DEBUG TRAIN Batch 21/4300 loss 19.186956 loss_att 22.706497 loss_ctc 23.169523 loss_rnnt 17.889698 hw_loss 0.116885 lr 0.00037329 rank 5
2023-02-22 16:57:16,041 DEBUG TRAIN Batch 21/4300 loss 4.833944 loss_att 7.280001 loss_ctc 5.780121 loss_rnnt 4.177740 hw_loss 0.076568 lr 0.00037327 rank 4
2023-02-22 16:57:16,044 DEBUG TRAIN Batch 21/4300 loss 8.903557 loss_att 11.256033 loss_ctc 12.360989 loss_rnnt 7.948985 hw_loss 0.043288 lr 0.00037326 rank 1
2023-02-22 16:57:16,044 DEBUG TRAIN Batch 21/4300 loss 9.861500 loss_att 14.120731 loss_ctc 13.791633 loss_rnnt 8.467058 hw_loss 0.034832 lr 0.00037331 rank 6
2023-02-22 16:57:16,046 DEBUG TRAIN Batch 21/4300 loss 4.050568 loss_att 6.269205 loss_ctc 5.204800 loss_rnnt 3.387053 hw_loss 0.123542 lr 0.00037320 rank 2
2023-02-22 16:57:16,046 DEBUG TRAIN Batch 21/4300 loss 6.064074 loss_att 9.838324 loss_ctc 9.829612 loss_rnnt 4.751440 hw_loss 0.104460 lr 0.00037322 rank 3
2023-02-22 16:58:31,940 DEBUG TRAIN Batch 21/4400 loss 3.831970 loss_att 4.497318 loss_ctc 5.988159 loss_rnnt 3.362677 hw_loss 0.091372 lr 0.00037318 rank 5
2023-02-22 16:58:31,940 DEBUG TRAIN Batch 21/4400 loss 10.438675 loss_att 11.246092 loss_ctc 15.117520 loss_rnnt 9.604009 hw_loss 0.092506 lr 0.00037317 rank 4
2023-02-22 16:58:31,941 DEBUG TRAIN Batch 21/4400 loss 13.039284 loss_att 15.007650 loss_ctc 17.159658 loss_rnnt 12.063383 hw_loss 0.061583 lr 0.00037316 rank 0
2023-02-22 16:58:31,945 DEBUG TRAIN Batch 21/4400 loss 5.417390 loss_att 6.791183 loss_ctc 7.585690 loss_rnnt 4.790585 hw_loss 0.118011 lr 0.00037314 rank 7
2023-02-22 16:58:31,948 DEBUG TRAIN Batch 21/4400 loss 9.287757 loss_att 9.124290 loss_ctc 13.601675 loss_rnnt 8.683252 hw_loss 0.116266 lr 0.00037321 rank 6
2023-02-22 16:58:31,950 DEBUG TRAIN Batch 21/4400 loss 12.437223 loss_att 15.208537 loss_ctc 16.976103 loss_rnnt 11.237468 hw_loss 0.075582 lr 0.00037311 rank 3
2023-02-22 16:58:31,953 DEBUG TRAIN Batch 21/4400 loss 3.842004 loss_att 8.106411 loss_ctc 7.607595 loss_rnnt 2.419599 hw_loss 0.126458 lr 0.00037310 rank 2
2023-02-22 16:58:31,956 DEBUG TRAIN Batch 21/4400 loss 12.097859 loss_att 11.938824 loss_ctc 14.672741 loss_rnnt 11.719612 hw_loss 0.125133 lr 0.00037315 rank 1
2023-02-22 16:59:49,210 DEBUG TRAIN Batch 21/4500 loss 7.625365 loss_att 9.340448 loss_ctc 9.465217 loss_rnnt 7.010715 hw_loss 0.049351 lr 0.00037305 rank 1
2023-02-22 16:59:49,211 DEBUG TRAIN Batch 21/4500 loss 8.280673 loss_att 9.362991 loss_ctc 13.455173 loss_rnnt 7.319633 hw_loss 0.102456 lr 0.00037306 rank 0
2023-02-22 16:59:49,212 DEBUG TRAIN Batch 21/4500 loss 10.376123 loss_att 11.952188 loss_ctc 10.601404 loss_rnnt 9.994057 hw_loss 0.069030 lr 0.00037308 rank 5
2023-02-22 16:59:49,216 DEBUG TRAIN Batch 21/4500 loss 12.656720 loss_att 14.171352 loss_ctc 18.778143 loss_rnnt 11.491901 hw_loss 0.085692 lr 0.00037304 rank 7
2023-02-22 16:59:49,218 DEBUG TRAIN Batch 21/4500 loss 13.573178 loss_att 12.659100 loss_ctc 17.884348 loss_rnnt 13.085373 hw_loss 0.179623 lr 0.00037307 rank 4
2023-02-22 16:59:49,221 DEBUG TRAIN Batch 21/4500 loss 7.679389 loss_att 8.678571 loss_ctc 10.417210 loss_rnnt 7.095016 hw_loss 0.036553 lr 0.00037301 rank 3
2023-02-22 16:59:49,225 DEBUG TRAIN Batch 21/4500 loss 7.988653 loss_att 10.069213 loss_ctc 10.979465 loss_rnnt 7.131887 hw_loss 0.078521 lr 0.00037310 rank 6
2023-02-22 16:59:49,227 DEBUG TRAIN Batch 21/4500 loss 11.477068 loss_att 18.250175 loss_ctc 11.941954 loss_rnnt 10.040056 hw_loss 0.038261 lr 0.00037299 rank 2
2023-02-22 17:01:06,990 DEBUG TRAIN Batch 21/4600 loss 7.302683 loss_att 10.834317 loss_ctc 9.809867 loss_rnnt 6.248434 hw_loss 0.025559 lr 0.00037294 rank 7
2023-02-22 17:01:06,990 DEBUG TRAIN Batch 21/4600 loss 10.203795 loss_att 13.569348 loss_ctc 15.705241 loss_rnnt 8.723614 hw_loss 0.137896 lr 0.00037295 rank 0
2023-02-22 17:01:06,991 DEBUG TRAIN Batch 21/4600 loss 6.184732 loss_att 10.703948 loss_ctc 10.097281 loss_rnnt 4.704391 hw_loss 0.102797 lr 0.00037296 rank 4
2023-02-22 17:01:06,995 DEBUG TRAIN Batch 21/4600 loss 9.718222 loss_att 12.525395 loss_ctc 13.927917 loss_rnnt 8.562707 hw_loss 0.061476 lr 0.00037289 rank 2
2023-02-22 17:01:06,996 DEBUG TRAIN Batch 21/4600 loss 10.158707 loss_att 13.060376 loss_ctc 11.859752 loss_rnnt 9.316597 hw_loss 0.065568 lr 0.00037300 rank 6
2023-02-22 17:01:06,997 DEBUG TRAIN Batch 21/4600 loss 12.319659 loss_att 16.518902 loss_ctc 17.733646 loss_rnnt 10.720079 hw_loss 0.070996 lr 0.00037297 rank 5
2023-02-22 17:01:06,998 DEBUG TRAIN Batch 21/4600 loss 8.765081 loss_att 15.372684 loss_ctc 15.279701 loss_rnnt 6.534735 hw_loss 0.075394 lr 0.00037291 rank 3
2023-02-22 17:01:07,000 DEBUG TRAIN Batch 21/4600 loss 4.453453 loss_att 5.130565 loss_ctc 5.095079 loss_rnnt 4.199162 hw_loss 0.062471 lr 0.00037295 rank 1
2023-02-22 17:02:23,072 DEBUG TRAIN Batch 21/4700 loss 12.910210 loss_att 17.232086 loss_ctc 22.227705 loss_rnnt 10.803322 hw_loss 0.000337 lr 0.00037286 rank 4
2023-02-22 17:02:23,074 DEBUG TRAIN Batch 21/4700 loss 10.844228 loss_att 16.181589 loss_ctc 15.987793 loss_rnnt 9.012077 hw_loss 0.147879 lr 0.00037283 rank 7
2023-02-22 17:02:23,076 DEBUG TRAIN Batch 21/4700 loss 15.543513 loss_att 18.589954 loss_ctc 23.223316 loss_rnnt 13.848858 hw_loss 0.115114 lr 0.00037287 rank 5
2023-02-22 17:02:23,078 DEBUG TRAIN Batch 21/4700 loss 7.139223 loss_att 11.622913 loss_ctc 10.735062 loss_rnnt 5.737064 hw_loss 0.048703 lr 0.00037285 rank 0
2023-02-22 17:02:23,080 DEBUG TRAIN Batch 21/4700 loss 4.710920 loss_att 7.699131 loss_ctc 5.985065 loss_rnnt 3.918468 hw_loss 0.046733 lr 0.00037280 rank 3
2023-02-22 17:02:23,082 DEBUG TRAIN Batch 21/4700 loss 11.643200 loss_att 14.920519 loss_ctc 20.558117 loss_rnnt 9.751403 hw_loss 0.089396 lr 0.00037284 rank 1
2023-02-22 17:02:23,083 DEBUG TRAIN Batch 21/4700 loss 19.203402 loss_att 17.837440 loss_ctc 27.286518 loss_rnnt 18.340477 hw_loss 0.109440 lr 0.00037278 rank 2
2023-02-22 17:02:23,087 DEBUG TRAIN Batch 21/4700 loss 9.229918 loss_att 12.691905 loss_ctc 10.218947 loss_rnnt 8.348934 hw_loss 0.106343 lr 0.00037289 rank 6
2023-02-22 17:03:38,039 DEBUG TRAIN Batch 21/4800 loss 11.182442 loss_att 11.830935 loss_ctc 15.342768 loss_rnnt 10.457586 hw_loss 0.075838 lr 0.00037275 rank 0
2023-02-22 17:03:38,044 DEBUG TRAIN Batch 21/4800 loss 9.060917 loss_att 14.345446 loss_ctc 15.489280 loss_rnnt 7.134336 hw_loss 0.023550 lr 0.00037275 rank 4
2023-02-22 17:03:38,047 DEBUG TRAIN Batch 21/4800 loss 6.771259 loss_att 9.571844 loss_ctc 10.328485 loss_rnnt 5.688246 hw_loss 0.091123 lr 0.00037277 rank 5
2023-02-22 17:03:38,050 DEBUG TRAIN Batch 21/4800 loss 7.921771 loss_att 9.929531 loss_ctc 11.613173 loss_rnnt 6.970022 hw_loss 0.108769 lr 0.00037279 rank 6
2023-02-22 17:03:38,050 DEBUG TRAIN Batch 21/4800 loss 5.755123 loss_att 9.413398 loss_ctc 9.467258 loss_rnnt 4.397667 hw_loss 0.245344 lr 0.00037274 rank 1
2023-02-22 17:03:38,051 DEBUG TRAIN Batch 21/4800 loss 11.173685 loss_att 12.912104 loss_ctc 14.740692 loss_rnnt 10.290686 hw_loss 0.111965 lr 0.00037270 rank 3
2023-02-22 17:03:38,051 DEBUG TRAIN Batch 21/4800 loss 3.260598 loss_att 4.923799 loss_ctc 3.066254 loss_rnnt 2.897108 hw_loss 0.106430 lr 0.00037273 rank 7
2023-02-22 17:03:38,093 DEBUG TRAIN Batch 21/4800 loss 8.767285 loss_att 12.224695 loss_ctc 14.230194 loss_rnnt 7.330122 hw_loss 0.032425 lr 0.00037268 rank 2
2023-02-22 17:04:54,159 DEBUG TRAIN Batch 21/4900 loss 10.854869 loss_att 13.722971 loss_ctc 15.133735 loss_rnnt 9.650213 hw_loss 0.113472 lr 0.00037266 rank 5
2023-02-22 17:04:54,159 DEBUG TRAIN Batch 21/4900 loss 5.205138 loss_att 8.078762 loss_ctc 6.305108 loss_rnnt 4.468789 hw_loss 0.028052 lr 0.00037260 rank 3
2023-02-22 17:04:54,161 DEBUG TRAIN Batch 21/4900 loss 13.131582 loss_att 14.726546 loss_ctc 19.809183 loss_rnnt 11.918745 hw_loss 0.006562 lr 0.00037264 rank 0
2023-02-22 17:04:54,164 DEBUG TRAIN Batch 21/4900 loss 8.119083 loss_att 11.551898 loss_ctc 13.842701 loss_rnnt 6.628822 hw_loss 0.076032 lr 0.00037263 rank 7
2023-02-22 17:04:54,164 DEBUG TRAIN Batch 21/4900 loss 12.545377 loss_att 15.718479 loss_ctc 17.447613 loss_rnnt 11.215073 hw_loss 0.078846 lr 0.00037263 rank 1
2023-02-22 17:04:54,167 DEBUG TRAIN Batch 21/4900 loss 5.647051 loss_att 8.150973 loss_ctc 7.328780 loss_rnnt 4.884439 hw_loss 0.070494 lr 0.00037269 rank 6
2023-02-22 17:04:54,168 DEBUG TRAIN Batch 21/4900 loss 6.952532 loss_att 9.407501 loss_ctc 12.397316 loss_rnnt 5.679098 hw_loss 0.105878 lr 0.00037265 rank 4
2023-02-22 17:04:54,197 DEBUG TRAIN Batch 21/4900 loss 15.643713 loss_att 16.245750 loss_ctc 17.104462 loss_rnnt 15.265413 hw_loss 0.118358 lr 0.00037258 rank 2
2023-02-22 17:06:11,760 DEBUG TRAIN Batch 21/5000 loss 16.135212 loss_att 17.335812 loss_ctc 18.735485 loss_rnnt 15.461038 hw_loss 0.163784 lr 0.00037254 rank 0
2023-02-22 17:06:11,761 DEBUG TRAIN Batch 21/5000 loss 5.222618 loss_att 8.782661 loss_ctc 7.959239 loss_rnnt 4.082172 hw_loss 0.119164 lr 0.00037252 rank 7
2023-02-22 17:06:11,761 DEBUG TRAIN Batch 21/5000 loss 5.207712 loss_att 8.168159 loss_ctc 7.344482 loss_rnnt 4.317710 hw_loss 0.024394 lr 0.00037255 rank 4
2023-02-22 17:06:11,762 DEBUG TRAIN Batch 21/5000 loss 7.858390 loss_att 9.500197 loss_ctc 9.864963 loss_rnnt 7.192188 hw_loss 0.131808 lr 0.00037256 rank 5
2023-02-22 17:06:11,764 DEBUG TRAIN Batch 21/5000 loss 13.905876 loss_att 15.389595 loss_ctc 20.430382 loss_rnnt 12.657723 hw_loss 0.152764 lr 0.00037253 rank 1
2023-02-22 17:06:11,770 DEBUG TRAIN Batch 21/5000 loss 8.602814 loss_att 13.345831 loss_ctc 11.305313 loss_rnnt 7.280464 hw_loss 0.025147 lr 0.00037247 rank 2
2023-02-22 17:06:11,770 DEBUG TRAIN Batch 21/5000 loss 13.972468 loss_att 15.099754 loss_ctc 17.260651 loss_rnnt 13.264700 hw_loss 0.082291 lr 0.00037249 rank 3
2023-02-22 17:06:11,807 DEBUG TRAIN Batch 21/5000 loss 8.586845 loss_att 10.615816 loss_ctc 13.251327 loss_rnnt 7.448209 hw_loss 0.207958 lr 0.00037258 rank 6
2023-02-22 17:07:27,796 DEBUG TRAIN Batch 21/5100 loss 7.680897 loss_att 11.331553 loss_ctc 7.348792 loss_rnnt 6.941358 hw_loss 0.100666 lr 0.00037248 rank 6
2023-02-22 17:07:27,796 DEBUG TRAIN Batch 21/5100 loss 9.071929 loss_att 11.810240 loss_ctc 14.221079 loss_rnnt 7.749452 hw_loss 0.165490 lr 0.00037244 rank 4
2023-02-22 17:07:27,796 DEBUG TRAIN Batch 21/5100 loss 8.106050 loss_att 11.837389 loss_ctc 13.479284 loss_rnnt 6.607027 hw_loss 0.068110 lr 0.00037246 rank 5
2023-02-22 17:07:27,797 DEBUG TRAIN Batch 21/5100 loss 6.089905 loss_att 10.272478 loss_ctc 9.045666 loss_rnnt 4.822809 hw_loss 0.068399 lr 0.00037237 rank 2
2023-02-22 17:07:27,798 DEBUG TRAIN Batch 21/5100 loss 8.370902 loss_att 9.761359 loss_ctc 11.409439 loss_rnnt 7.636106 hw_loss 0.096686 lr 0.00037242 rank 7
2023-02-22 17:07:27,798 DEBUG TRAIN Batch 21/5100 loss 13.274367 loss_att 14.275053 loss_ctc 18.682449 loss_rnnt 12.335376 hw_loss 0.033330 lr 0.00037243 rank 1
2023-02-22 17:07:27,800 DEBUG TRAIN Batch 21/5100 loss 10.681386 loss_att 11.820065 loss_ctc 14.959696 loss_rnnt 9.865372 hw_loss 0.033443 lr 0.00037243 rank 0
2023-02-22 17:07:27,813 DEBUG TRAIN Batch 21/5100 loss 12.797805 loss_att 16.540115 loss_ctc 19.270351 loss_rnnt 11.088544 hw_loss 0.183361 lr 0.00037239 rank 3
2023-02-22 17:08:43,108 DEBUG TRAIN Batch 21/5200 loss 21.637474 loss_att 25.387432 loss_ctc 22.657761 loss_rnnt 20.706203 hw_loss 0.084824 lr 0.00037235 rank 5
2023-02-22 17:08:43,108 DEBUG TRAIN Batch 21/5200 loss 5.542580 loss_att 7.035113 loss_ctc 7.502954 loss_rnnt 4.965687 hw_loss 0.031879 lr 0.00037232 rank 7
2023-02-22 17:08:43,113 DEBUG TRAIN Batch 21/5200 loss 13.766984 loss_att 20.809021 loss_ctc 23.882427 loss_rnnt 10.974157 hw_loss 0.066925 lr 0.00037234 rank 4
2023-02-22 17:08:43,114 DEBUG TRAIN Batch 21/5200 loss 10.933273 loss_att 10.725309 loss_ctc 14.210789 loss_rnnt 10.450601 hw_loss 0.163620 lr 0.00037229 rank 3
2023-02-22 17:08:43,114 DEBUG TRAIN Batch 21/5200 loss 5.701009 loss_att 8.318413 loss_ctc 8.339403 loss_rnnt 4.806350 hw_loss 0.036359 lr 0.00037233 rank 0
2023-02-22 17:08:43,116 DEBUG TRAIN Batch 21/5200 loss 8.734242 loss_att 13.229472 loss_ctc 11.160948 loss_rnnt 7.479581 hw_loss 0.060102 lr 0.00037232 rank 1
2023-02-22 17:08:43,118 DEBUG TRAIN Batch 21/5200 loss 12.173001 loss_att 14.139105 loss_ctc 16.097197 loss_rnnt 11.147479 hw_loss 0.204517 lr 0.00037227 rank 2
2023-02-22 17:08:43,119 DEBUG TRAIN Batch 21/5200 loss 2.601802 loss_att 5.153596 loss_ctc 5.829702 loss_rnnt 1.650876 hw_loss 0.019088 lr 0.00037238 rank 6
2023-02-22 17:10:01,441 DEBUG TRAIN Batch 21/5300 loss 5.746972 loss_att 8.902746 loss_ctc 8.265522 loss_rnnt 4.735307 hw_loss 0.083818 lr 0.00037222 rank 1
2023-02-22 17:10:01,442 DEBUG TRAIN Batch 21/5300 loss 10.441596 loss_att 14.067625 loss_ctc 13.065275 loss_rnnt 9.318098 hw_loss 0.090878 lr 0.00037218 rank 3
2023-02-22 17:10:01,444 DEBUG TRAIN Batch 21/5300 loss 5.129638 loss_att 7.032804 loss_ctc 6.683773 loss_rnnt 4.531099 hw_loss 0.020039 lr 0.00037224 rank 4
2023-02-22 17:10:01,444 DEBUG TRAIN Batch 21/5300 loss 10.292286 loss_att 11.350796 loss_ctc 13.517370 loss_rnnt 9.568923 hw_loss 0.153092 lr 0.00037225 rank 5
2023-02-22 17:10:01,450 DEBUG TRAIN Batch 21/5300 loss 2.856884 loss_att 6.334880 loss_ctc 5.171252 loss_rnnt 1.789057 hw_loss 0.119336 lr 0.00037227 rank 6
2023-02-22 17:10:01,473 DEBUG TRAIN Batch 21/5300 loss 10.079960 loss_att 13.829351 loss_ctc 13.280651 loss_rnnt 8.873469 hw_loss 0.055976 lr 0.00037223 rank 0
2023-02-22 17:10:01,476 DEBUG TRAIN Batch 21/5300 loss 7.791847 loss_att 11.285609 loss_ctc 11.811110 loss_rnnt 6.533021 hw_loss 0.045322 lr 0.00037221 rank 7
2023-02-22 17:10:01,492 DEBUG TRAIN Batch 21/5300 loss 13.843305 loss_att 15.498678 loss_ctc 15.943687 loss_rnnt 13.186049 hw_loss 0.086496 lr 0.00037216 rank 2
2023-02-22 17:11:18,253 DEBUG TRAIN Batch 21/5400 loss 10.016121 loss_att 12.568938 loss_ctc 15.178848 loss_rnnt 8.793293 hw_loss 0.044814 lr 0.00037206 rank 2
2023-02-22 17:11:18,253 DEBUG TRAIN Batch 21/5400 loss 10.960915 loss_att 14.252925 loss_ctc 13.225447 loss_rnnt 9.962020 hw_loss 0.072291 lr 0.00037212 rank 1
2023-02-22 17:11:18,253 DEBUG TRAIN Batch 21/5400 loss 4.559218 loss_att 8.549227 loss_ctc 7.790729 loss_rnnt 3.276294 hw_loss 0.101352 lr 0.00037213 rank 0
2023-02-22 17:11:18,254 DEBUG TRAIN Batch 21/5400 loss 9.138126 loss_att 11.910352 loss_ctc 12.215284 loss_rnnt 8.109308 hw_loss 0.120160 lr 0.00037211 rank 7
2023-02-22 17:11:18,255 DEBUG TRAIN Batch 21/5400 loss 4.475518 loss_att 6.197639 loss_ctc 6.875818 loss_rnnt 3.780595 hw_loss 0.057110 lr 0.00037213 rank 4
2023-02-22 17:11:18,256 DEBUG TRAIN Batch 21/5400 loss 13.145211 loss_att 14.402137 loss_ctc 20.562294 loss_rnnt 11.897911 hw_loss 0.013071 lr 0.00037215 rank 5
2023-02-22 17:11:18,276 DEBUG TRAIN Batch 21/5400 loss 12.589937 loss_att 12.380179 loss_ctc 18.242783 loss_rnnt 11.827140 hw_loss 0.095695 lr 0.00037217 rank 6
2023-02-22 17:11:18,286 DEBUG TRAIN Batch 21/5400 loss 2.605100 loss_att 5.066526 loss_ctc 3.556767 loss_rnnt 1.985684 hw_loss 0.000453 lr 0.00037208 rank 3
2023-02-22 17:12:34,396 DEBUG TRAIN Batch 21/5500 loss 4.820918 loss_att 8.241798 loss_ctc 7.730121 loss_rnnt 3.689585 hw_loss 0.111117 lr 0.00037202 rank 0
2023-02-22 17:12:34,399 DEBUG TRAIN Batch 21/5500 loss 12.873880 loss_att 16.172812 loss_ctc 18.821560 loss_rnnt 11.329357 hw_loss 0.171961 lr 0.00037201 rank 7
2023-02-22 17:12:34,400 DEBUG TRAIN Batch 21/5500 loss 13.257658 loss_att 15.555426 loss_ctc 18.478722 loss_rnnt 12.080114 hw_loss 0.040967 lr 0.00037204 rank 5
2023-02-22 17:12:34,403 DEBUG TRAIN Batch 21/5500 loss 7.548638 loss_att 11.475446 loss_ctc 10.635862 loss_rnnt 6.351440 hw_loss 0.000387 lr 0.00037203 rank 4
2023-02-22 17:12:34,405 DEBUG TRAIN Batch 21/5500 loss 7.579822 loss_att 10.586926 loss_ctc 15.230818 loss_rnnt 5.925949 hw_loss 0.060600 lr 0.00037198 rank 3
2023-02-22 17:12:34,406 DEBUG TRAIN Batch 21/5500 loss 9.676571 loss_att 12.500668 loss_ctc 14.238567 loss_rnnt 8.444391 hw_loss 0.110801 lr 0.00037202 rank 1
2023-02-22 17:12:34,406 DEBUG TRAIN Batch 21/5500 loss 14.433331 loss_att 15.911287 loss_ctc 15.683553 loss_rnnt 13.939155 hw_loss 0.059793 lr 0.00037196 rank 2
2023-02-22 17:12:34,447 DEBUG TRAIN Batch 21/5500 loss 14.208254 loss_att 15.402567 loss_ctc 27.891665 loss_rnnt 12.084817 hw_loss 0.112725 lr 0.00037207 rank 6
2023-02-22 17:13:50,429 DEBUG TRAIN Batch 21/5600 loss 12.911254 loss_att 17.489376 loss_ctc 21.885288 loss_rnnt 10.747817 hw_loss 0.096141 lr 0.00037190 rank 7
2023-02-22 17:13:50,429 DEBUG TRAIN Batch 21/5600 loss 15.662242 loss_att 16.107061 loss_ctc 20.915735 loss_rnnt 14.791011 hw_loss 0.153376 lr 0.00037194 rank 5
2023-02-22 17:13:50,430 DEBUG TRAIN Batch 21/5600 loss 8.079683 loss_att 10.429564 loss_ctc 12.836479 loss_rnnt 6.913855 hw_loss 0.115522 lr 0.00037196 rank 6
2023-02-22 17:13:50,430 DEBUG TRAIN Batch 21/5600 loss 10.900819 loss_att 12.967020 loss_ctc 16.046907 loss_rnnt 9.741445 hw_loss 0.112478 lr 0.00037191 rank 1
2023-02-22 17:13:50,431 DEBUG TRAIN Batch 21/5600 loss 20.146009 loss_att 21.421398 loss_ctc 32.894547 loss_rnnt 18.163694 hw_loss 0.051439 lr 0.00037187 rank 3
2023-02-22 17:13:50,431 DEBUG TRAIN Batch 21/5600 loss 10.381335 loss_att 12.176681 loss_ctc 15.156857 loss_rnnt 9.360339 hw_loss 0.047234 lr 0.00037193 rank 4
2023-02-22 17:13:50,432 DEBUG TRAIN Batch 21/5600 loss 8.477967 loss_att 8.628229 loss_ctc 11.020100 loss_rnnt 8.016037 hw_loss 0.174239 lr 0.00037186 rank 2
2023-02-22 17:13:50,433 DEBUG TRAIN Batch 21/5600 loss 12.946505 loss_att 15.562029 loss_ctc 16.924231 loss_rnnt 11.840340 hw_loss 0.098806 lr 0.00037192 rank 0
2023-02-22 17:15:09,056 DEBUG TRAIN Batch 21/5700 loss 7.864973 loss_att 7.751685 loss_ctc 9.798756 loss_rnnt 7.556406 hw_loss 0.137599 lr 0.00037184 rank 5
2023-02-22 17:15:09,061 DEBUG TRAIN Batch 21/5700 loss 5.095472 loss_att 7.249740 loss_ctc 6.539098 loss_rnnt 4.449178 hw_loss 0.043044 lr 0.00037182 rank 0
2023-02-22 17:15:09,062 DEBUG TRAIN Batch 21/5700 loss 5.390413 loss_att 8.205491 loss_ctc 6.044491 loss_rnnt 4.654565 hw_loss 0.160541 lr 0.00037183 rank 4
2023-02-22 17:15:09,062 DEBUG TRAIN Batch 21/5700 loss 10.713358 loss_att 13.108873 loss_ctc 14.454968 loss_rnnt 9.669678 hw_loss 0.123178 lr 0.00037180 rank 7
2023-02-22 17:15:09,065 DEBUG TRAIN Batch 21/5700 loss 3.108276 loss_att 5.504786 loss_ctc 4.253510 loss_rnnt 2.400937 hw_loss 0.141261 lr 0.00037177 rank 3
2023-02-22 17:15:09,067 DEBUG TRAIN Batch 21/5700 loss 16.019379 loss_att 18.776939 loss_ctc 22.910475 loss_rnnt 14.543495 hw_loss 0.010417 lr 0.00037181 rank 1
2023-02-22 17:15:09,068 DEBUG TRAIN Batch 21/5700 loss 15.179518 loss_att 20.099373 loss_ctc 23.397215 loss_rnnt 13.042312 hw_loss 0.107891 lr 0.00037175 rank 2
2023-02-22 17:15:09,070 DEBUG TRAIN Batch 21/5700 loss 10.328527 loss_att 13.937187 loss_ctc 14.793240 loss_rnnt 8.915107 hw_loss 0.180737 lr 0.00037186 rank 6
2023-02-22 17:16:25,341 DEBUG TRAIN Batch 21/5800 loss 7.893602 loss_att 7.726831 loss_ctc 10.199573 loss_rnnt 7.515816 hw_loss 0.194396 lr 0.00037170 rank 7
2023-02-22 17:16:25,341 DEBUG TRAIN Batch 21/5800 loss 6.292024 loss_att 9.307635 loss_ctc 9.921869 loss_rnnt 5.088722 hw_loss 0.217875 lr 0.00037171 rank 0
2023-02-22 17:16:25,344 DEBUG TRAIN Batch 21/5800 loss 6.396688 loss_att 10.167074 loss_ctc 7.347288 loss_rnnt 5.515800 hw_loss 0.000119 lr 0.00037165 rank 2
2023-02-22 17:16:25,346 DEBUG TRAIN Batch 21/5800 loss 13.640141 loss_att 13.868521 loss_ctc 18.429260 loss_rnnt 12.908474 hw_loss 0.088951 lr 0.00037167 rank 3
2023-02-22 17:16:25,347 DEBUG TRAIN Batch 21/5800 loss 7.105176 loss_att 9.028428 loss_ctc 9.444811 loss_rnnt 6.383541 hw_loss 0.046938 lr 0.00037176 rank 6
2023-02-22 17:16:25,347 DEBUG TRAIN Batch 21/5800 loss 4.991507 loss_att 7.827545 loss_ctc 7.792802 loss_rnnt 3.965081 hw_loss 0.160709 lr 0.00037172 rank 4
2023-02-22 17:16:25,347 DEBUG TRAIN Batch 21/5800 loss 8.592643 loss_att 14.184044 loss_ctc 14.216915 loss_rnnt 6.692333 hw_loss 0.060240 lr 0.00037171 rank 1
2023-02-22 17:16:25,348 DEBUG TRAIN Batch 21/5800 loss 2.781672 loss_att 5.250978 loss_ctc 5.598779 loss_rnnt 1.884878 hw_loss 0.051223 lr 0.00037174 rank 5
2023-02-22 17:17:39,160 DEBUG TRAIN Batch 21/5900 loss 12.909334 loss_att 13.678244 loss_ctc 15.824898 loss_rnnt 12.248359 hw_loss 0.222096 lr 0.00037162 rank 4
2023-02-22 17:17:39,166 DEBUG TRAIN Batch 21/5900 loss 4.093332 loss_att 8.483248 loss_ctc 7.601518 loss_rnnt 2.727481 hw_loss 0.037706 lr 0.00037157 rank 3
2023-02-22 17:17:39,166 DEBUG TRAIN Batch 21/5900 loss 10.858768 loss_att 13.164063 loss_ctc 13.410083 loss_rnnt 10.020352 hw_loss 0.069716 lr 0.00037163 rank 5
2023-02-22 17:17:39,166 DEBUG TRAIN Batch 21/5900 loss 8.465624 loss_att 12.001348 loss_ctc 12.860693 loss_rnnt 7.148290 hw_loss 0.045338 lr 0.00037161 rank 0
2023-02-22 17:17:39,168 DEBUG TRAIN Batch 21/5900 loss 3.927009 loss_att 6.847863 loss_ctc 6.604102 loss_rnnt 2.972263 hw_loss 0.025554 lr 0.00037160 rank 1
2023-02-22 17:17:39,168 DEBUG TRAIN Batch 21/5900 loss 8.800637 loss_att 11.821466 loss_ctc 15.747635 loss_rnnt 7.189363 hw_loss 0.151580 lr 0.00037166 rank 6
2023-02-22 17:17:39,168 DEBUG TRAIN Batch 21/5900 loss 7.206104 loss_att 8.230335 loss_ctc 11.617179 loss_rnnt 6.345853 hw_loss 0.126114 lr 0.00037160 rank 7
2023-02-22 17:17:39,174 DEBUG TRAIN Batch 21/5900 loss 6.068505 loss_att 8.865891 loss_ctc 8.787865 loss_rnnt 5.132929 hw_loss 0.025346 lr 0.00037155 rank 2
2023-02-22 17:18:56,433 DEBUG TRAIN Batch 21/6000 loss 14.159113 loss_att 17.909782 loss_ctc 21.143906 loss_rnnt 12.387782 hw_loss 0.168548 lr 0.00037146 rank 3
2023-02-22 17:18:56,434 DEBUG TRAIN Batch 21/6000 loss 10.013357 loss_att 11.209435 loss_ctc 10.430300 loss_rnnt 9.667355 hw_loss 0.095989 lr 0.00037149 rank 7
2023-02-22 17:18:56,435 DEBUG TRAIN Batch 21/6000 loss 6.844568 loss_att 8.960667 loss_ctc 9.160959 loss_rnnt 6.103574 hw_loss 0.016730 lr 0.00037151 rank 0
2023-02-22 17:18:56,435 DEBUG TRAIN Batch 21/6000 loss 9.422940 loss_att 13.006361 loss_ctc 14.098772 loss_rnnt 8.035192 hw_loss 0.089287 lr 0.00037155 rank 6
2023-02-22 17:18:56,436 DEBUG TRAIN Batch 21/6000 loss 3.533523 loss_att 8.465300 loss_ctc 6.536354 loss_rnnt 2.065279 hw_loss 0.152831 lr 0.00037150 rank 1
2023-02-22 17:18:56,436 DEBUG TRAIN Batch 21/6000 loss 6.912074 loss_att 9.720795 loss_ctc 13.189354 loss_rnnt 5.493202 hw_loss 0.037792 lr 0.00037152 rank 4
2023-02-22 17:18:56,438 DEBUG TRAIN Batch 21/6000 loss 6.469951 loss_att 10.870548 loss_ctc 9.120430 loss_rnnt 5.160038 hw_loss 0.143244 lr 0.00037153 rank 5
2023-02-22 17:18:56,438 DEBUG TRAIN Batch 21/6000 loss 8.423672 loss_att 10.313958 loss_ctc 11.344193 loss_rnnt 7.630205 hw_loss 0.048762 lr 0.00037144 rank 2
2023-02-22 17:20:14,161 DEBUG TRAIN Batch 21/6100 loss 8.050175 loss_att 9.768169 loss_ctc 9.716667 loss_rnnt 7.444838 hw_loss 0.074136 lr 0.00037142 rank 4
2023-02-22 17:20:14,162 DEBUG TRAIN Batch 21/6100 loss 5.777828 loss_att 7.846661 loss_ctc 8.294101 loss_rnnt 5.000226 hw_loss 0.053124 lr 0.00037139 rank 7
2023-02-22 17:20:14,165 DEBUG TRAIN Batch 21/6100 loss 14.211619 loss_att 17.109882 loss_ctc 21.408268 loss_rnnt 12.591937 hw_loss 0.150894 lr 0.00037136 rank 3
2023-02-22 17:20:14,165 DEBUG TRAIN Batch 21/6100 loss 6.925733 loss_att 9.682620 loss_ctc 9.037325 loss_rnnt 6.074966 hw_loss 0.033456 lr 0.00037143 rank 5
2023-02-22 17:20:14,165 DEBUG TRAIN Batch 21/6100 loss 5.891166 loss_att 10.061020 loss_ctc 7.798515 loss_rnnt 4.793826 hw_loss 0.016980 lr 0.00037141 rank 0
2023-02-22 17:20:14,168 DEBUG TRAIN Batch 21/6100 loss 5.183717 loss_att 8.310028 loss_ctc 8.751890 loss_rnnt 4.052332 hw_loss 0.056937 lr 0.00037145 rank 6
2023-02-22 17:20:14,169 DEBUG TRAIN Batch 21/6100 loss 3.115145 loss_att 5.075183 loss_ctc 3.692798 loss_rnnt 2.591035 hw_loss 0.103278 lr 0.00037140 rank 1
2023-02-22 17:20:14,175 DEBUG TRAIN Batch 21/6100 loss 10.957619 loss_att 12.231072 loss_ctc 14.573061 loss_rnnt 10.152908 hw_loss 0.127427 lr 0.00037134 rank 2
2023-02-22 17:21:27,998 DEBUG TRAIN Batch 21/6200 loss 10.717931 loss_att 14.442532 loss_ctc 17.549749 loss_rnnt 8.972044 hw_loss 0.168859 lr 0.00037133 rank 5
2023-02-22 17:21:27,998 DEBUG TRAIN Batch 21/6200 loss 19.080328 loss_att 19.444077 loss_ctc 26.496775 loss_rnnt 17.988001 hw_loss 0.057598 lr 0.00037130 rank 0
2023-02-22 17:21:28,005 DEBUG TRAIN Batch 21/6200 loss 4.811271 loss_att 7.117027 loss_ctc 5.272162 loss_rnnt 4.263453 hw_loss 0.047278 lr 0.00037131 rank 4
2023-02-22 17:21:28,005 DEBUG TRAIN Batch 21/6200 loss 3.184437 loss_att 5.662800 loss_ctc 5.088667 loss_rnnt 2.392159 hw_loss 0.080078 lr 0.00037129 rank 7
2023-02-22 17:21:28,007 DEBUG TRAIN Batch 21/6200 loss 10.286038 loss_att 11.340550 loss_ctc 14.844942 loss_rnnt 9.415205 hw_loss 0.097644 lr 0.00037126 rank 3
2023-02-22 17:21:28,009 DEBUG TRAIN Batch 21/6200 loss 9.237819 loss_att 13.809896 loss_ctc 13.146861 loss_rnnt 7.735083 hw_loss 0.125839 lr 0.00037130 rank 1
2023-02-22 17:21:28,009 DEBUG TRAIN Batch 21/6200 loss 20.140770 loss_att 23.410131 loss_ctc 30.527607 loss_rnnt 18.074192 hw_loss 0.052111 lr 0.00037124 rank 2
2023-02-22 17:21:28,054 DEBUG TRAIN Batch 21/6200 loss 10.663801 loss_att 13.618805 loss_ctc 17.365530 loss_rnnt 9.139626 hw_loss 0.074270 lr 0.00037135 rank 6
2023-02-22 17:22:44,580 DEBUG TRAIN Batch 21/6300 loss 7.782048 loss_att 11.450012 loss_ctc 10.586252 loss_rnnt 6.623151 hw_loss 0.096395 lr 0.00037121 rank 4
2023-02-22 17:22:44,583 DEBUG TRAIN Batch 21/6300 loss 11.350095 loss_att 11.761698 loss_ctc 16.704453 loss_rnnt 10.480906 hw_loss 0.136787 lr 0.00037116 rank 3
2023-02-22 17:22:44,584 DEBUG TRAIN Batch 21/6300 loss 6.255299 loss_att 8.883052 loss_ctc 9.423671 loss_rnnt 5.212433 hw_loss 0.177874 lr 0.00037119 rank 1
2023-02-22 17:22:44,583 DEBUG TRAIN Batch 21/6300 loss 9.452518 loss_att 12.659164 loss_ctc 15.913631 loss_rnnt 7.898610 hw_loss 0.095807 lr 0.00037122 rank 5
2023-02-22 17:22:44,584 DEBUG TRAIN Batch 21/6300 loss 8.810679 loss_att 11.187933 loss_ctc 10.165766 loss_rnnt 8.130783 hw_loss 0.044562 lr 0.00037120 rank 0
2023-02-22 17:22:44,585 DEBUG TRAIN Batch 21/6300 loss 11.403087 loss_att 17.793739 loss_ctc 20.405952 loss_rnnt 8.909454 hw_loss 0.028350 lr 0.00037114 rank 2
2023-02-22 17:22:44,587 DEBUG TRAIN Batch 21/6300 loss 3.567267 loss_att 6.600490 loss_ctc 6.196501 loss_rnnt 2.592082 hw_loss 0.033706 lr 0.00037119 rank 7
2023-02-22 17:22:44,629 DEBUG TRAIN Batch 21/6300 loss 2.007201 loss_att 4.734323 loss_ctc 2.605101 loss_rnnt 1.363471 hw_loss 0.034848 lr 0.00037125 rank 6
2023-02-22 17:24:02,679 DEBUG TRAIN Batch 21/6400 loss 9.589444 loss_att 10.992047 loss_ctc 10.587173 loss_rnnt 9.130780 hw_loss 0.084586 lr 0.00037112 rank 5
2023-02-22 17:24:02,682 DEBUG TRAIN Batch 21/6400 loss 6.738697 loss_att 8.118638 loss_ctc 10.946507 loss_rnnt 5.842575 hw_loss 0.110797 lr 0.00037108 rank 7
2023-02-22 17:24:02,684 DEBUG TRAIN Batch 21/6400 loss 10.015903 loss_att 12.077194 loss_ctc 16.581495 loss_rnnt 8.697720 hw_loss 0.057209 lr 0.00037111 rank 4
2023-02-22 17:24:02,686 DEBUG TRAIN Batch 21/6400 loss 10.871941 loss_att 10.562905 loss_ctc 14.944660 loss_rnnt 10.291266 hw_loss 0.186474 lr 0.00037109 rank 1
2023-02-22 17:24:02,690 DEBUG TRAIN Batch 21/6400 loss 9.731812 loss_att 11.464010 loss_ctc 14.255295 loss_rnnt 8.694473 hw_loss 0.164566 lr 0.00037110 rank 0
2023-02-22 17:24:02,692 DEBUG TRAIN Batch 21/6400 loss 11.622420 loss_att 14.139915 loss_ctc 15.734492 loss_rnnt 10.515986 hw_loss 0.102485 lr 0.00037105 rank 3
2023-02-22 17:24:02,694 DEBUG TRAIN Batch 21/6400 loss 2.158129 loss_att 4.163104 loss_ctc 2.246456 loss_rnnt 1.700327 hw_loss 0.084431 lr 0.00037104 rank 2
2023-02-22 17:24:02,695 DEBUG TRAIN Batch 21/6400 loss 5.696916 loss_att 9.456971 loss_ctc 10.503449 loss_rnnt 4.274662 hw_loss 0.055072 lr 0.00037114 rank 6
2023-02-22 17:25:19,687 DEBUG TRAIN Batch 21/6500 loss 7.722183 loss_att 10.147892 loss_ctc 9.940249 loss_rnnt 6.908478 hw_loss 0.061540 lr 0.00037101 rank 4
2023-02-22 17:25:19,688 DEBUG TRAIN Batch 21/6500 loss 10.407185 loss_att 12.434142 loss_ctc 12.728799 loss_rnnt 9.614955 hw_loss 0.144921 lr 0.00037100 rank 0
2023-02-22 17:25:19,689 DEBUG TRAIN Batch 21/6500 loss 7.491348 loss_att 11.186872 loss_ctc 10.028757 loss_rnnt 6.385436 hw_loss 0.053410 lr 0.00037102 rank 5
2023-02-22 17:25:19,690 DEBUG TRAIN Batch 21/6500 loss 9.244294 loss_att 12.576622 loss_ctc 14.450882 loss_rnnt 7.829265 hw_loss 0.101910 lr 0.00037093 rank 2
2023-02-22 17:25:19,691 DEBUG TRAIN Batch 21/6500 loss 3.969915 loss_att 6.955081 loss_ctc 9.033470 loss_rnnt 2.663529 hw_loss 0.064147 lr 0.00037104 rank 6
2023-02-22 17:25:19,692 DEBUG TRAIN Batch 21/6500 loss 8.635357 loss_att 9.083094 loss_ctc 10.376045 loss_rnnt 8.239906 hw_loss 0.138396 lr 0.00037095 rank 3
2023-02-22 17:25:19,691 DEBUG TRAIN Batch 21/6500 loss 7.165990 loss_att 10.077745 loss_ctc 10.277586 loss_rnnt 6.150092 hw_loss 0.035003 lr 0.00037098 rank 7
2023-02-22 17:25:19,735 DEBUG TRAIN Batch 21/6500 loss 10.270098 loss_att 15.320801 loss_ctc 18.040024 loss_rnnt 8.148547 hw_loss 0.141413 lr 0.00037099 rank 1
2023-02-22 17:26:35,924 DEBUG TRAIN Batch 21/6600 loss 4.359496 loss_att 9.526687 loss_ctc 6.387439 loss_rnnt 3.055588 hw_loss 0.000144 lr 0.00037088 rank 7
2023-02-22 17:26:35,925 DEBUG TRAIN Batch 21/6600 loss 5.794481 loss_att 8.845965 loss_ctc 8.541698 loss_rnnt 4.789635 hw_loss 0.052974 lr 0.00037089 rank 0
2023-02-22 17:26:35,925 DEBUG TRAIN Batch 21/6600 loss 6.445964 loss_att 7.760257 loss_ctc 9.247482 loss_rnnt 5.788700 hw_loss 0.039132 lr 0.00037090 rank 4
2023-02-22 17:26:35,929 DEBUG TRAIN Batch 21/6600 loss 9.978601 loss_att 12.129440 loss_ctc 12.820753 loss_rnnt 9.088950 hw_loss 0.150996 lr 0.00037089 rank 1
2023-02-22 17:26:35,929 DEBUG TRAIN Batch 21/6600 loss 4.279044 loss_att 7.826033 loss_ctc 5.187964 loss_rnnt 3.372271 hw_loss 0.142849 lr 0.00037085 rank 3
2023-02-22 17:26:35,930 DEBUG TRAIN Batch 21/6600 loss 6.503843 loss_att 10.926419 loss_ctc 13.338994 loss_rnnt 4.673733 hw_loss 0.064202 lr 0.00037094 rank 6
2023-02-22 17:26:35,933 DEBUG TRAIN Batch 21/6600 loss 12.905133 loss_att 16.336960 loss_ctc 16.064247 loss_rnnt 11.788877 hw_loss 0.016268 lr 0.00037083 rank 2
2023-02-22 17:26:35,935 DEBUG TRAIN Batch 21/6600 loss 8.280312 loss_att 9.619839 loss_ctc 9.715919 loss_rnnt 7.789825 hw_loss 0.058436 lr 0.00037092 rank 5
2023-02-22 17:27:52,610 DEBUG TRAIN Batch 21/6700 loss 14.082757 loss_att 17.590128 loss_ctc 24.888376 loss_rnnt 11.900934 hw_loss 0.074245 lr 0.00037081 rank 5
2023-02-22 17:27:52,612 DEBUG TRAIN Batch 21/6700 loss 2.988112 loss_att 4.243474 loss_ctc 3.349136 loss_rnnt 2.659670 hw_loss 0.054812 lr 0.00037079 rank 0
2023-02-22 17:27:52,615 DEBUG TRAIN Batch 21/6700 loss 14.371585 loss_att 15.576015 loss_ctc 19.154781 loss_rnnt 13.480567 hw_loss 0.023200 lr 0.00037084 rank 6
2023-02-22 17:27:52,616 DEBUG TRAIN Batch 21/6700 loss 9.302282 loss_att 11.407333 loss_ctc 10.796650 loss_rnnt 8.656200 hw_loss 0.048418 lr 0.00037078 rank 7
2023-02-22 17:27:52,617 DEBUG TRAIN Batch 21/6700 loss 5.904188 loss_att 8.542971 loss_ctc 6.834907 loss_rnnt 5.187139 hw_loss 0.122243 lr 0.00037075 rank 3
2023-02-22 17:27:52,617 DEBUG TRAIN Batch 21/6700 loss 5.004798 loss_att 10.228083 loss_ctc 9.214308 loss_rnnt 3.345428 hw_loss 0.100211 lr 0.00037079 rank 1
2023-02-22 17:27:52,621 DEBUG TRAIN Batch 21/6700 loss 13.781972 loss_att 16.816635 loss_ctc 20.196692 loss_rnnt 12.304684 hw_loss 0.028235 lr 0.00037080 rank 4
2023-02-22 17:27:52,623 DEBUG TRAIN Batch 21/6700 loss 12.337084 loss_att 15.903389 loss_ctc 17.379129 loss_rnnt 10.910383 hw_loss 0.077189 lr 0.00037073 rank 2
2023-02-22 17:29:10,098 DEBUG TRAIN Batch 21/6800 loss 3.177307 loss_att 8.181958 loss_ctc 5.699769 loss_rnnt 1.777023 hw_loss 0.118173 lr 0.00037069 rank 0
2023-02-22 17:29:10,102 DEBUG TRAIN Batch 21/6800 loss 6.357741 loss_att 8.401352 loss_ctc 6.239550 loss_rnnt 5.922249 hw_loss 0.079743 lr 0.00037068 rank 7
2023-02-22 17:29:10,104 DEBUG TRAIN Batch 21/6800 loss 21.915403 loss_att 23.376545 loss_ctc 32.826401 loss_rnnt 20.084568 hw_loss 0.157140 lr 0.00037071 rank 5
2023-02-22 17:29:10,105 DEBUG TRAIN Batch 21/6800 loss 14.320742 loss_att 16.356987 loss_ctc 26.254745 loss_rnnt 12.274378 hw_loss 0.089837 lr 0.00037068 rank 1
2023-02-22 17:29:10,106 DEBUG TRAIN Batch 21/6800 loss 8.927876 loss_att 14.079285 loss_ctc 16.749153 loss_rnnt 6.810850 hw_loss 0.082328 lr 0.00037070 rank 4
2023-02-22 17:29:10,109 DEBUG TRAIN Batch 21/6800 loss 10.784956 loss_att 12.264027 loss_ctc 17.316618 loss_rnnt 9.609375 hw_loss 0.016647 lr 0.00037065 rank 3
2023-02-22 17:29:10,110 DEBUG TRAIN Batch 21/6800 loss 7.433232 loss_att 9.854033 loss_ctc 8.023000 loss_rnnt 6.824621 hw_loss 0.085902 lr 0.00037063 rank 2
2023-02-22 17:29:10,111 DEBUG TRAIN Batch 21/6800 loss 11.028167 loss_att 12.144686 loss_ctc 14.523274 loss_rnnt 10.265821 hw_loss 0.136927 lr 0.00037073 rank 6
2023-02-22 17:30:25,185 DEBUG TRAIN Batch 21/6900 loss 9.685189 loss_att 11.922989 loss_ctc 15.397558 loss_rnnt 8.444752 hw_loss 0.058552 lr 0.00037060 rank 4
2023-02-22 17:30:25,187 DEBUG TRAIN Batch 21/6900 loss 12.420999 loss_att 13.550199 loss_ctc 15.034376 loss_rnnt 11.822285 hw_loss 0.045794 lr 0.00037061 rank 5
2023-02-22 17:30:25,190 DEBUG TRAIN Batch 21/6900 loss 9.632571 loss_att 10.586082 loss_ctc 14.317021 loss_rnnt 8.740694 hw_loss 0.143589 lr 0.00037063 rank 6
2023-02-22 17:30:25,190 DEBUG TRAIN Batch 21/6900 loss 10.427478 loss_att 11.504771 loss_ctc 12.110479 loss_rnnt 9.951258 hw_loss 0.068179 lr 0.00037059 rank 0
2023-02-22 17:30:25,193 DEBUG TRAIN Batch 21/6900 loss 17.431093 loss_att 21.700729 loss_ctc 24.278524 loss_rnnt 15.602368 hw_loss 0.115884 lr 0.00037057 rank 7
2023-02-22 17:30:25,197 DEBUG TRAIN Batch 21/6900 loss 7.292481 loss_att 8.887301 loss_ctc 14.012147 loss_rnnt 5.951327 hw_loss 0.236689 lr 0.00037058 rank 1
2023-02-22 17:30:25,199 DEBUG TRAIN Batch 21/6900 loss 18.360207 loss_att 23.258581 loss_ctc 29.420862 loss_rnnt 15.867366 hw_loss 0.072021 lr 0.00037054 rank 3
2023-02-22 17:30:25,203 DEBUG TRAIN Batch 21/6900 loss 3.057550 loss_att 4.215786 loss_ctc 4.558609 loss_rnnt 2.547076 hw_loss 0.147534 lr 0.00037053 rank 2
2023-02-22 17:31:40,980 DEBUG TRAIN Batch 21/7000 loss 4.504798 loss_att 7.054334 loss_ctc 6.172244 loss_rnnt 3.683993 hw_loss 0.166073 lr 0.00037051 rank 5
2023-02-22 17:31:40,985 DEBUG TRAIN Batch 21/7000 loss 10.491449 loss_att 14.822863 loss_ctc 14.581009 loss_rnnt 8.987277 hw_loss 0.173653 lr 0.00037042 rank 2
2023-02-22 17:31:40,986 DEBUG TRAIN Batch 21/7000 loss 16.901400 loss_att 17.627386 loss_ctc 21.589138 loss_rnnt 16.121725 hw_loss 0.017710 lr 0.00037049 rank 0
2023-02-22 17:31:40,987 DEBUG TRAIN Batch 21/7000 loss 9.988091 loss_att 12.494644 loss_ctc 16.632845 loss_rnnt 8.542707 hw_loss 0.108947 lr 0.00037050 rank 4
2023-02-22 17:31:40,987 DEBUG TRAIN Batch 21/7000 loss 3.200815 loss_att 5.251347 loss_ctc 5.086960 loss_rnnt 2.509038 hw_loss 0.056596 lr 0.00037048 rank 1
2023-02-22 17:31:40,987 DEBUG TRAIN Batch 21/7000 loss 8.542618 loss_att 10.061796 loss_ctc 11.134455 loss_rnnt 7.847695 hw_loss 0.085328 lr 0.00037047 rank 7
2023-02-22 17:31:40,988 DEBUG TRAIN Batch 21/7000 loss 10.895292 loss_att 14.305108 loss_ctc 15.171785 loss_rnnt 9.627513 hw_loss 0.029283 lr 0.00037053 rank 6
2023-02-22 17:31:41,040 DEBUG TRAIN Batch 21/7000 loss 11.708746 loss_att 14.452629 loss_ctc 18.055271 loss_rnnt 10.273088 hw_loss 0.076272 lr 0.00037044 rank 3
2023-02-22 17:32:58,401 DEBUG TRAIN Batch 21/7100 loss 4.757690 loss_att 8.703412 loss_ctc 7.206918 loss_rnnt 3.627413 hw_loss 0.027318 lr 0.00037039 rank 4
2023-02-22 17:32:58,404 DEBUG TRAIN Batch 21/7100 loss 4.952033 loss_att 6.785333 loss_ctc 6.096313 loss_rnnt 4.420731 hw_loss 0.022634 lr 0.00037041 rank 5
2023-02-22 17:32:58,406 DEBUG TRAIN Batch 21/7100 loss 6.154287 loss_att 8.160438 loss_ctc 10.696128 loss_rnnt 5.116856 hw_loss 0.057416 lr 0.00037037 rank 7
2023-02-22 17:32:58,407 DEBUG TRAIN Batch 21/7100 loss 7.078155 loss_att 12.580390 loss_ctc 9.551056 loss_rnnt 5.620003 hw_loss 0.052470 lr 0.00037032 rank 2
2023-02-22 17:32:58,408 DEBUG TRAIN Batch 21/7100 loss 16.159153 loss_att 16.987940 loss_ctc 21.385525 loss_rnnt 15.218458 hw_loss 0.146415 lr 0.00037039 rank 0
2023-02-22 17:32:58,411 DEBUG TRAIN Batch 21/7100 loss 6.653052 loss_att 9.126562 loss_ctc 8.259544 loss_rnnt 5.901272 hw_loss 0.080400 lr 0.00037043 rank 6
2023-02-22 17:32:58,413 DEBUG TRAIN Batch 21/7100 loss 6.646743 loss_att 8.487003 loss_ctc 6.750780 loss_rnnt 6.191730 hw_loss 0.137041 lr 0.00037038 rank 1
2023-02-22 17:32:58,415 DEBUG TRAIN Batch 21/7100 loss 15.240898 loss_att 16.456072 loss_ctc 20.877398 loss_rnnt 14.212997 hw_loss 0.062500 lr 0.00037034 rank 3
2023-02-22 17:34:14,160 DEBUG TRAIN Batch 21/7200 loss 4.858694 loss_att 9.253044 loss_ctc 9.296915 loss_rnnt 3.304947 hw_loss 0.155838 lr 0.00037029 rank 4
2023-02-22 17:34:14,162 DEBUG TRAIN Batch 21/7200 loss 10.353739 loss_att 15.888857 loss_ctc 15.702711 loss_rnnt 8.518209 hw_loss 0.028705 lr 0.00037033 rank 6
2023-02-22 17:34:14,163 DEBUG TRAIN Batch 21/7200 loss 13.084980 loss_att 14.451487 loss_ctc 17.199589 loss_rnnt 12.225843 hw_loss 0.069789 lr 0.00037027 rank 7
2023-02-22 17:34:14,163 DEBUG TRAIN Batch 21/7200 loss 9.015872 loss_att 9.577251 loss_ctc 11.220133 loss_rnnt 8.594378 hw_loss 0.028718 lr 0.00037028 rank 0
2023-02-22 17:34:14,164 DEBUG TRAIN Batch 21/7200 loss 13.885999 loss_att 17.869835 loss_ctc 25.367920 loss_rnnt 11.512480 hw_loss 0.085930 lr 0.00037031 rank 5
2023-02-22 17:34:14,166 DEBUG TRAIN Batch 21/7200 loss 6.947060 loss_att 8.691238 loss_ctc 9.607138 loss_rnnt 6.196422 hw_loss 0.088360 lr 0.00037028 rank 1
2023-02-22 17:34:14,168 DEBUG TRAIN Batch 21/7200 loss 12.684296 loss_att 13.400606 loss_ctc 15.514544 loss_rnnt 12.159130 hw_loss 0.008507 lr 0.00037024 rank 3
2023-02-22 17:34:14,219 DEBUG TRAIN Batch 21/7200 loss 11.716134 loss_att 17.762569 loss_ctc 24.222298 loss_rnnt 8.821401 hw_loss 0.033668 lr 0.00037022 rank 2
2023-02-22 17:35:29,327 DEBUG TRAIN Batch 21/7300 loss 9.868908 loss_att 12.739794 loss_ctc 14.601446 loss_rnnt 8.637411 hw_loss 0.049340 lr 0.00037018 rank 0
2023-02-22 17:35:29,328 DEBUG TRAIN Batch 21/7300 loss 14.400787 loss_att 17.275684 loss_ctc 18.404602 loss_rnnt 13.266051 hw_loss 0.048592 lr 0.00037020 rank 5
2023-02-22 17:35:29,330 DEBUG TRAIN Batch 21/7300 loss 12.259367 loss_att 14.147133 loss_ctc 19.391586 loss_rnnt 10.915405 hw_loss 0.028960 lr 0.00037018 rank 1
2023-02-22 17:35:29,331 DEBUG TRAIN Batch 21/7300 loss 3.367574 loss_att 5.381963 loss_ctc 5.770818 loss_rnnt 2.622252 hw_loss 0.041273 lr 0.00037019 rank 4
2023-02-22 17:35:29,331 DEBUG TRAIN Batch 21/7300 loss 5.724672 loss_att 8.452989 loss_ctc 9.287658 loss_rnnt 4.630805 hw_loss 0.137135 lr 0.00037017 rank 7
2023-02-22 17:35:29,332 DEBUG TRAIN Batch 21/7300 loss 3.422472 loss_att 7.577933 loss_ctc 7.007648 loss_rnnt 2.102422 hw_loss 0.020501 lr 0.00037014 rank 3
2023-02-22 17:35:29,333 DEBUG TRAIN Batch 21/7300 loss 9.013367 loss_att 11.548709 loss_ctc 16.288939 loss_rnnt 7.514849 hw_loss 0.040075 lr 0.00037012 rank 2
2023-02-22 17:35:29,380 DEBUG TRAIN Batch 21/7300 loss 7.817785 loss_att 10.699152 loss_ctc 10.248445 loss_rnnt 6.901608 hw_loss 0.029653 lr 0.00037023 rank 6
2023-02-22 17:36:45,753 DEBUG TRAIN Batch 21/7400 loss 7.387318 loss_att 10.699820 loss_ctc 10.695328 loss_rnnt 6.239885 hw_loss 0.082246 lr 0.00037007 rank 7
2023-02-22 17:36:45,755 DEBUG TRAIN Batch 21/7400 loss 6.950048 loss_att 9.036759 loss_ctc 12.658051 loss_rnnt 5.704664 hw_loss 0.125578 lr 0.00037009 rank 4
2023-02-22 17:36:45,755 DEBUG TRAIN Batch 21/7400 loss 12.216367 loss_att 13.199223 loss_ctc 16.899658 loss_rnnt 11.359609 hw_loss 0.067028 lr 0.00037007 rank 1
2023-02-22 17:36:45,756 DEBUG TRAIN Batch 21/7400 loss 9.184996 loss_att 11.992081 loss_ctc 8.981256 loss_rnnt 8.578752 hw_loss 0.134985 lr 0.00037008 rank 0
2023-02-22 17:36:45,758 DEBUG TRAIN Batch 21/7400 loss 9.095760 loss_att 12.312681 loss_ctc 15.590823 loss_rnnt 7.566504 hw_loss 0.037243 lr 0.00037004 rank 3
2023-02-22 17:36:45,758 DEBUG TRAIN Batch 21/7400 loss 14.073919 loss_att 15.164841 loss_ctc 19.725388 loss_rnnt 13.015395 hw_loss 0.162771 lr 0.00037012 rank 6
2023-02-22 17:36:45,758 DEBUG TRAIN Batch 21/7400 loss 7.228460 loss_att 12.837244 loss_ctc 8.650127 loss_rnnt 5.858615 hw_loss 0.109749 lr 0.00037010 rank 5
2023-02-22 17:36:45,762 DEBUG TRAIN Batch 21/7400 loss 5.977846 loss_att 10.333559 loss_ctc 10.921478 loss_rnnt 4.407454 hw_loss 0.075186 lr 0.00037002 rank 2
2023-02-22 17:38:03,516 DEBUG TRAIN Batch 21/7500 loss 9.055916 loss_att 9.870622 loss_ctc 13.476630 loss_rnnt 8.228520 hw_loss 0.140672 lr 0.00036996 rank 7
2023-02-22 17:38:03,523 DEBUG TRAIN Batch 21/7500 loss 4.879429 loss_att 7.746249 loss_ctc 8.160921 loss_rnnt 3.797394 hw_loss 0.133386 lr 0.00036998 rank 0
2023-02-22 17:38:03,524 DEBUG TRAIN Batch 21/7500 loss 8.005480 loss_att 8.347622 loss_ctc 11.768788 loss_rnnt 7.342019 hw_loss 0.174857 lr 0.00037002 rank 6
2023-02-22 17:38:03,524 DEBUG TRAIN Batch 21/7500 loss 3.887401 loss_att 6.159923 loss_ctc 5.897573 loss_rnnt 3.137359 hw_loss 0.051590 lr 0.00036997 rank 1
2023-02-22 17:38:03,525 DEBUG TRAIN Batch 21/7500 loss 8.245309 loss_att 14.940283 loss_ctc 11.056299 loss_rnnt 6.507629 hw_loss 0.044787 lr 0.00036999 rank 4
2023-02-22 17:38:03,525 DEBUG TRAIN Batch 21/7500 loss 14.835272 loss_att 16.604517 loss_ctc 22.036762 loss_rnnt 13.442523 hw_loss 0.147565 lr 0.00037000 rank 5
2023-02-22 17:38:03,525 DEBUG TRAIN Batch 21/7500 loss 9.078356 loss_att 12.138687 loss_ctc 17.079409 loss_rnnt 7.372906 hw_loss 0.049829 lr 0.00036994 rank 3
2023-02-22 17:38:03,526 DEBUG TRAIN Batch 21/7500 loss 6.811476 loss_att 9.865211 loss_ctc 8.638877 loss_rnnt 5.864974 hw_loss 0.172691 lr 0.00036992 rank 2
2023-02-22 17:39:17,131 DEBUG TRAIN Batch 21/7600 loss 5.714098 loss_att 8.187001 loss_ctc 6.743743 loss_rnnt 5.042782 hw_loss 0.073969 lr 0.00036992 rank 6
2023-02-22 17:39:17,131 DEBUG TRAIN Batch 21/7600 loss 8.326900 loss_att 11.057787 loss_ctc 11.399566 loss_rnnt 7.351839 hw_loss 0.035990 lr 0.00036989 rank 4
2023-02-22 17:39:17,132 DEBUG TRAIN Batch 21/7600 loss 7.196572 loss_att 9.190937 loss_ctc 11.554646 loss_rnnt 6.179290 hw_loss 0.069998 lr 0.00036986 rank 7
2023-02-22 17:39:17,133 DEBUG TRAIN Batch 21/7600 loss 15.708968 loss_att 16.415001 loss_ctc 20.884354 loss_rnnt 14.774178 hw_loss 0.194122 lr 0.00036988 rank 0
2023-02-22 17:39:17,136 DEBUG TRAIN Batch 21/7600 loss 12.826887 loss_att 18.953217 loss_ctc 18.300972 loss_rnnt 10.799683 hw_loss 0.135114 lr 0.00036990 rank 5
2023-02-22 17:39:17,136 DEBUG TRAIN Batch 21/7600 loss 8.970313 loss_att 10.402324 loss_ctc 11.461349 loss_rnnt 8.294142 hw_loss 0.108058 lr 0.00036987 rank 1
2023-02-22 17:39:17,137 DEBUG TRAIN Batch 21/7600 loss 3.721858 loss_att 5.227515 loss_ctc 5.425576 loss_rnnt 3.120389 hw_loss 0.137201 lr 0.00036982 rank 2
2023-02-22 17:39:17,141 DEBUG TRAIN Batch 21/7600 loss 8.045822 loss_att 9.702467 loss_ctc 11.083577 loss_rnnt 7.226395 hw_loss 0.155746 lr 0.00036983 rank 3
2023-02-22 17:40:32,799 DEBUG TRAIN Batch 21/7700 loss 6.923659 loss_att 8.814772 loss_ctc 11.608232 loss_rnnt 5.873405 hw_loss 0.088917 lr 0.00036978 rank 0
2023-02-22 17:40:32,800 DEBUG TRAIN Batch 21/7700 loss 8.961434 loss_att 13.047480 loss_ctc 10.242679 loss_rnnt 7.933858 hw_loss 0.074126 lr 0.00036977 rank 1
2023-02-22 17:40:32,800 DEBUG TRAIN Batch 21/7700 loss 8.416978 loss_att 11.829564 loss_ctc 11.530578 loss_rnnt 7.235522 hw_loss 0.157108 lr 0.00036980 rank 5
2023-02-22 17:40:32,801 DEBUG TRAIN Batch 21/7700 loss 11.288782 loss_att 11.208035 loss_ctc 16.054441 loss_rnnt 10.544502 hw_loss 0.234389 lr 0.00036973 rank 3
2023-02-22 17:40:32,801 DEBUG TRAIN Batch 21/7700 loss 12.017638 loss_att 18.272251 loss_ctc 18.257109 loss_rnnt 9.917043 hw_loss 0.033267 lr 0.00036979 rank 4
2023-02-22 17:40:32,802 DEBUG TRAIN Batch 21/7700 loss 1.809632 loss_att 4.125652 loss_ctc 4.189398 loss_rnnt 1.016224 hw_loss 0.024190 lr 0.00036982 rank 6
2023-02-22 17:40:32,803 DEBUG TRAIN Batch 21/7700 loss 7.894045 loss_att 6.802195 loss_ctc 10.275783 loss_rnnt 7.737752 hw_loss 0.107057 lr 0.00036976 rank 7
2023-02-22 17:40:32,808 DEBUG TRAIN Batch 21/7700 loss 7.425924 loss_att 9.994967 loss_ctc 11.546413 loss_rnnt 6.320558 hw_loss 0.079048 lr 0.00036971 rank 2
2023-02-22 17:41:50,672 DEBUG TRAIN Batch 21/7800 loss 10.424211 loss_att 13.291231 loss_ctc 19.165051 loss_rnnt 8.677855 hw_loss 0.014075 lr 0.00036970 rank 5
2023-02-22 17:41:50,671 DEBUG TRAIN Batch 21/7800 loss 17.058596 loss_att 19.473125 loss_ctc 28.067181 loss_rnnt 15.075020 hw_loss 0.061611 lr 0.00036967 rank 1
2023-02-22 17:41:50,673 DEBUG TRAIN Batch 21/7800 loss 10.146779 loss_att 12.195950 loss_ctc 15.832973 loss_rnnt 8.897161 hw_loss 0.153046 lr 0.00036968 rank 0
2023-02-22 17:41:50,674 DEBUG TRAIN Batch 21/7800 loss 2.151969 loss_att 4.463207 loss_ctc 4.610460 loss_rnnt 1.320940 hw_loss 0.076843 lr 0.00036966 rank 7
2023-02-22 17:41:50,674 DEBUG TRAIN Batch 21/7800 loss 6.946318 loss_att 11.572149 loss_ctc 13.292862 loss_rnnt 5.135599 hw_loss 0.073773 lr 0.00036969 rank 4
2023-02-22 17:41:50,675 DEBUG TRAIN Batch 21/7800 loss 12.322341 loss_att 13.815486 loss_ctc 17.803316 loss_rnnt 11.282570 hw_loss 0.019397 lr 0.00036963 rank 3
2023-02-22 17:41:50,706 DEBUG TRAIN Batch 21/7800 loss 6.635592 loss_att 9.107845 loss_ctc 9.065994 loss_rnnt 5.786118 hw_loss 0.058067 lr 0.00036961 rank 2
2023-02-22 17:41:50,727 DEBUG TRAIN Batch 21/7800 loss 17.398907 loss_att 23.464249 loss_ctc 28.940990 loss_rnnt 14.565985 hw_loss 0.151705 lr 0.00036972 rank 6
2023-02-22 17:43:07,160 DEBUG TRAIN Batch 21/7900 loss 9.623478 loss_att 14.874833 loss_ctc 17.089272 loss_rnnt 7.568184 hw_loss 0.017970 lr 0.00036956 rank 7
2023-02-22 17:43:07,160 DEBUG TRAIN Batch 21/7900 loss 10.201412 loss_att 12.290706 loss_ctc 12.729582 loss_rnnt 9.408854 hw_loss 0.070518 lr 0.00036958 rank 4
2023-02-22 17:43:07,164 DEBUG TRAIN Batch 21/7900 loss 8.743090 loss_att 11.239889 loss_ctc 12.636623 loss_rnnt 7.636106 hw_loss 0.165910 lr 0.00036951 rank 2
2023-02-22 17:43:07,166 DEBUG TRAIN Batch 21/7900 loss 5.920609 loss_att 8.642344 loss_ctc 11.231421 loss_rnnt 4.627286 hw_loss 0.076625 lr 0.00036958 rank 0
2023-02-22 17:43:07,168 DEBUG TRAIN Batch 21/7900 loss 11.888371 loss_att 14.576498 loss_ctc 13.820588 loss_rnnt 11.049181 hw_loss 0.082376 lr 0.00036960 rank 5
2023-02-22 17:43:07,169 DEBUG TRAIN Batch 21/7900 loss 13.119720 loss_att 16.952887 loss_ctc 17.826794 loss_rnnt 11.711922 hw_loss 0.025413 lr 0.00036953 rank 3
2023-02-22 17:43:07,175 DEBUG TRAIN Batch 21/7900 loss 1.036641 loss_att 3.485182 loss_ctc 1.993894 loss_rnnt 0.406938 hw_loss 0.023176 lr 0.00036957 rank 1
2023-02-22 17:43:07,216 DEBUG TRAIN Batch 21/7900 loss 7.532859 loss_att 11.765998 loss_ctc 12.787827 loss_rnnt 5.970745 hw_loss 0.027794 lr 0.00036962 rank 6
2023-02-22 17:44:22,668 DEBUG TRAIN Batch 21/8000 loss 7.217102 loss_att 12.562637 loss_ctc 10.956075 loss_rnnt 5.630032 hw_loss 0.036437 lr 0.00036948 rank 4
2023-02-22 17:44:22,668 DEBUG TRAIN Batch 21/8000 loss 12.189019 loss_att 15.741070 loss_ctc 16.105982 loss_rnnt 10.941046 hw_loss 0.028692 lr 0.00036950 rank 5
2023-02-22 17:44:22,669 DEBUG TRAIN Batch 21/8000 loss 8.632167 loss_att 10.758563 loss_ctc 11.770245 loss_rnnt 7.683221 hw_loss 0.197357 lr 0.00036941 rank 2
2023-02-22 17:44:22,669 DEBUG TRAIN Batch 21/8000 loss 7.993817 loss_att 10.966282 loss_ctc 11.653425 loss_rnnt 6.829796 hw_loss 0.152963 lr 0.00036947 rank 0
2023-02-22 17:44:22,670 DEBUG TRAIN Batch 21/8000 loss 9.552505 loss_att 13.328186 loss_ctc 15.854674 loss_rnnt 7.947579 hw_loss 0.017814 lr 0.00036946 rank 7
2023-02-22 17:44:22,671 DEBUG TRAIN Batch 21/8000 loss 11.147360 loss_att 14.352398 loss_ctc 15.513602 loss_rnnt 9.815859 hw_loss 0.203112 lr 0.00036952 rank 6
2023-02-22 17:44:22,673 DEBUG TRAIN Batch 21/8000 loss 12.064263 loss_att 11.827206 loss_ctc 14.280304 loss_rnnt 11.751719 hw_loss 0.120907 lr 0.00036947 rank 1
2023-02-22 17:44:22,674 DEBUG TRAIN Batch 21/8000 loss 5.110593 loss_att 8.067949 loss_ctc 5.723881 loss_rnnt 4.352883 hw_loss 0.158374 lr 0.00036943 rank 3
2023-02-22 17:45:36,815 DEBUG TRAIN Batch 21/8100 loss 11.464215 loss_att 15.569937 loss_ctc 17.844650 loss_rnnt 9.716882 hw_loss 0.141495 lr 0.00036936 rank 7
2023-02-22 17:45:36,815 DEBUG TRAIN Batch 21/8100 loss 12.609303 loss_att 13.607971 loss_ctc 16.715456 loss_rnnt 11.831438 hw_loss 0.057454 lr 0.00036939 rank 5
2023-02-22 17:45:36,821 DEBUG TRAIN Batch 21/8100 loss 8.716375 loss_att 10.718192 loss_ctc 13.091211 loss_rnnt 7.723782 hw_loss 0.016723 lr 0.00036937 rank 0
2023-02-22 17:45:36,821 DEBUG TRAIN Batch 21/8100 loss 4.404735 loss_att 8.269935 loss_ctc 7.214769 loss_rnnt 3.227389 hw_loss 0.055563 lr 0.00036933 rank 3
2023-02-22 17:45:36,823 DEBUG TRAIN Batch 21/8100 loss 4.040126 loss_att 5.879822 loss_ctc 4.456526 loss_rnnt 3.590564 hw_loss 0.048942 lr 0.00036938 rank 4
2023-02-22 17:45:36,823 DEBUG TRAIN Batch 21/8100 loss 13.275626 loss_att 17.370920 loss_ctc 19.045052 loss_rnnt 11.589940 hw_loss 0.182568 lr 0.00036937 rank 1
2023-02-22 17:45:36,827 DEBUG TRAIN Batch 21/8100 loss 9.935649 loss_att 13.599760 loss_ctc 14.863967 loss_rnnt 8.485391 hw_loss 0.113113 lr 0.00036931 rank 2
2023-02-22 17:45:36,864 DEBUG TRAIN Batch 21/8100 loss 7.039402 loss_att 7.597427 loss_ctc 9.826863 loss_rnnt 6.534547 hw_loss 0.040478 lr 0.00036942 rank 6
2023-02-22 17:46:54,362 DEBUG TRAIN Batch 21/8200 loss 6.149207 loss_att 6.515047 loss_ctc 7.049935 loss_rnnt 5.891933 hw_loss 0.120016 lr 0.00036927 rank 0
2023-02-22 17:46:54,366 DEBUG TRAIN Batch 21/8200 loss 5.204379 loss_att 5.510359 loss_ctc 6.605779 loss_rnnt 4.891871 hw_loss 0.120858 lr 0.00036929 rank 5
2023-02-22 17:46:54,367 DEBUG TRAIN Batch 21/8200 loss 6.055281 loss_att 8.072181 loss_ctc 9.238119 loss_rnnt 5.202025 hw_loss 0.047807 lr 0.00036926 rank 7
2023-02-22 17:46:54,368 DEBUG TRAIN Batch 21/8200 loss 10.928232 loss_att 13.314883 loss_ctc 18.759462 loss_rnnt 9.382537 hw_loss 0.045378 lr 0.00036928 rank 4
2023-02-22 17:46:54,372 DEBUG TRAIN Batch 21/8200 loss 7.926990 loss_att 10.457832 loss_ctc 13.769625 loss_rnnt 6.598515 hw_loss 0.081167 lr 0.00036927 rank 1
2023-02-22 17:46:54,373 DEBUG TRAIN Batch 21/8200 loss 12.782184 loss_att 14.677252 loss_ctc 16.709944 loss_rnnt 11.860919 hw_loss 0.034780 lr 0.00036921 rank 2
2023-02-22 17:46:54,403 DEBUG TRAIN Batch 21/8200 loss 8.570827 loss_att 12.355918 loss_ctc 11.341627 loss_rnnt 7.427489 hw_loss 0.031649 lr 0.00036923 rank 3
2023-02-22 17:46:54,409 DEBUG TRAIN Batch 21/8200 loss 8.669305 loss_att 11.238546 loss_ctc 11.639875 loss_rnnt 7.695961 hw_loss 0.118911 lr 0.00036932 rank 6
2023-02-22 17:48:09,944 DEBUG TRAIN Batch 21/8300 loss 15.786081 loss_att 16.975748 loss_ctc 22.415602 loss_rnnt 14.585301 hw_loss 0.147959 lr 0.00036916 rank 7
2023-02-22 17:48:09,943 DEBUG TRAIN Batch 21/8300 loss 11.776966 loss_att 14.622528 loss_ctc 21.988472 loss_rnnt 9.813095 hw_loss 0.062296 lr 0.00036917 rank 0
2023-02-22 17:48:09,945 DEBUG TRAIN Batch 21/8300 loss 7.523092 loss_att 9.206648 loss_ctc 12.045772 loss_rnnt 6.532607 hw_loss 0.095155 lr 0.00036911 rank 2
2023-02-22 17:48:09,945 DEBUG TRAIN Batch 21/8300 loss 2.182192 loss_att 5.250701 loss_ctc 4.619410 loss_rnnt 1.174499 hw_loss 0.129427 lr 0.00036919 rank 5
2023-02-22 17:48:09,948 DEBUG TRAIN Batch 21/8300 loss 9.043700 loss_att 11.852434 loss_ctc 14.676807 loss_rnnt 7.681279 hw_loss 0.092988 lr 0.00036917 rank 1
2023-02-22 17:48:09,948 DEBUG TRAIN Batch 21/8300 loss 7.311956 loss_att 9.619059 loss_ctc 10.456052 loss_rnnt 6.387982 hw_loss 0.081265 lr 0.00036918 rank 4
2023-02-22 17:48:09,948 DEBUG TRAIN Batch 21/8300 loss 3.367531 loss_att 6.689073 loss_ctc 5.322702 loss_rnnt 2.412432 hw_loss 0.056438 lr 0.00036913 rank 3
2023-02-22 17:48:09,998 DEBUG TRAIN Batch 21/8300 loss 6.253562 loss_att 11.329521 loss_ctc 9.078977 loss_rnnt 4.824806 hw_loss 0.069081 lr 0.00036922 rank 6
2023-02-22 17:49:02,064 DEBUG CV Batch 21/0 loss 2.098295 loss_att 2.312266 loss_ctc 2.910367 loss_rnnt 1.877201 hw_loss 0.131292 history loss 2.020580 rank 1
2023-02-22 17:49:02,066 DEBUG CV Batch 21/0 loss 2.098295 loss_att 2.312266 loss_ctc 2.910367 loss_rnnt 1.877201 hw_loss 0.131292 history loss 2.020580 rank 7
2023-02-22 17:49:02,067 DEBUG CV Batch 21/0 loss 2.098295 loss_att 2.312266 loss_ctc 2.910367 loss_rnnt 1.877201 hw_loss 0.131292 history loss 2.020580 rank 3
2023-02-22 17:49:02,067 DEBUG CV Batch 21/0 loss 2.098295 loss_att 2.312266 loss_ctc 2.910367 loss_rnnt 1.877201 hw_loss 0.131292 history loss 2.020580 rank 0
2023-02-22 17:49:02,069 DEBUG CV Batch 21/0 loss 2.098295 loss_att 2.312266 loss_ctc 2.910367 loss_rnnt 1.877201 hw_loss 0.131292 history loss 2.020580 rank 4
2023-02-22 17:49:02,072 DEBUG CV Batch 21/0 loss 2.098295 loss_att 2.312266 loss_ctc 2.910367 loss_rnnt 1.877201 hw_loss 0.131292 history loss 2.020580 rank 5
2023-02-22 17:49:02,078 DEBUG CV Batch 21/0 loss 2.098295 loss_att 2.312266 loss_ctc 2.910367 loss_rnnt 1.877201 hw_loss 0.131292 history loss 2.020580 rank 6
2023-02-22 17:49:02,093 DEBUG CV Batch 21/0 loss 2.098295 loss_att 2.312266 loss_ctc 2.910367 loss_rnnt 1.877201 hw_loss 0.131292 history loss 2.020580 rank 2
2023-02-22 17:49:13,228 DEBUG CV Batch 21/100 loss 9.447795 loss_att 8.071241 loss_ctc 11.457027 loss_rnnt 9.412304 hw_loss 0.080445 history loss 3.476820 rank 4
2023-02-22 17:49:13,261 DEBUG CV Batch 21/100 loss 9.447795 loss_att 8.071241 loss_ctc 11.457027 loss_rnnt 9.412304 hw_loss 0.080445 history loss 3.476820 rank 7
2023-02-22 17:49:13,289 DEBUG CV Batch 21/100 loss 9.447795 loss_att 8.071241 loss_ctc 11.457027 loss_rnnt 9.412304 hw_loss 0.080445 history loss 3.476820 rank 0
2023-02-22 17:49:13,313 DEBUG CV Batch 21/100 loss 9.447795 loss_att 8.071241 loss_ctc 11.457027 loss_rnnt 9.412304 hw_loss 0.080445 history loss 3.476820 rank 5
2023-02-22 17:49:13,388 DEBUG CV Batch 21/100 loss 9.447795 loss_att 8.071241 loss_ctc 11.457027 loss_rnnt 9.412304 hw_loss 0.080445 history loss 3.476820 rank 6
2023-02-22 17:49:13,398 DEBUG CV Batch 21/100 loss 9.447795 loss_att 8.071241 loss_ctc 11.457027 loss_rnnt 9.412304 hw_loss 0.080445 history loss 3.476820 rank 1
2023-02-22 17:49:13,439 DEBUG CV Batch 21/100 loss 9.447795 loss_att 8.071241 loss_ctc 11.457027 loss_rnnt 9.412304 hw_loss 0.080445 history loss 3.476820 rank 3
2023-02-22 17:49:13,491 DEBUG CV Batch 21/100 loss 9.447795 loss_att 8.071241 loss_ctc 11.457027 loss_rnnt 9.412304 hw_loss 0.080445 history loss 3.476820 rank 2
2023-02-22 17:49:26,552 DEBUG CV Batch 21/200 loss 4.521844 loss_att 8.499823 loss_ctc 4.486645 loss_rnnt 3.688571 hw_loss 0.079445 history loss 4.101600 rank 4
2023-02-22 17:49:26,608 DEBUG CV Batch 21/200 loss 4.521844 loss_att 8.499823 loss_ctc 4.486645 loss_rnnt 3.688571 hw_loss 0.079445 history loss 4.101600 rank 0
2023-02-22 17:49:26,662 DEBUG CV Batch 21/200 loss 4.521844 loss_att 8.499823 loss_ctc 4.486645 loss_rnnt 3.688571 hw_loss 0.079445 history loss 4.101600 rank 7
2023-02-22 17:49:26,676 DEBUG CV Batch 21/200 loss 4.521844 loss_att 8.499823 loss_ctc 4.486645 loss_rnnt 3.688571 hw_loss 0.079445 history loss 4.101600 rank 5
2023-02-22 17:49:26,850 DEBUG CV Batch 21/200 loss 4.521844 loss_att 8.499823 loss_ctc 4.486645 loss_rnnt 3.688571 hw_loss 0.079445 history loss 4.101600 rank 6
2023-02-22 17:49:26,941 DEBUG CV Batch 21/200 loss 4.521844 loss_att 8.499823 loss_ctc 4.486645 loss_rnnt 3.688571 hw_loss 0.079445 history loss 4.101600 rank 3
2023-02-22 17:49:27,131 DEBUG CV Batch 21/200 loss 4.521844 loss_att 8.499823 loss_ctc 4.486645 loss_rnnt 3.688571 hw_loss 0.079445 history loss 4.101600 rank 2
2023-02-22 17:49:27,580 DEBUG CV Batch 21/200 loss 4.521844 loss_att 8.499823 loss_ctc 4.486645 loss_rnnt 3.688571 hw_loss 0.079445 history loss 4.101600 rank 1
2023-02-22 17:49:38,548 DEBUG CV Batch 21/300 loss 6.284276 loss_att 6.128802 loss_ctc 8.969440 loss_rnnt 5.946205 hw_loss 0.020894 history loss 4.255162 rank 4
2023-02-22 17:49:38,721 DEBUG CV Batch 21/300 loss 6.284276 loss_att 6.128802 loss_ctc 8.969440 loss_rnnt 5.946205 hw_loss 0.020894 history loss 4.255162 rank 0
2023-02-22 17:49:38,732 DEBUG CV Batch 21/300 loss 6.284276 loss_att 6.128802 loss_ctc 8.969440 loss_rnnt 5.946205 hw_loss 0.020894 history loss 4.255162 rank 7
2023-02-22 17:49:38,781 DEBUG CV Batch 21/300 loss 6.284276 loss_att 6.128802 loss_ctc 8.969440 loss_rnnt 5.946205 hw_loss 0.020894 history loss 4.255162 rank 5
2023-02-22 17:49:39,075 DEBUG CV Batch 21/300 loss 6.284276 loss_att 6.128802 loss_ctc 8.969440 loss_rnnt 5.946205 hw_loss 0.020894 history loss 4.255162 rank 6
2023-02-22 17:49:39,201 DEBUG CV Batch 21/300 loss 6.284276 loss_att 6.128802 loss_ctc 8.969440 loss_rnnt 5.946205 hw_loss 0.020894 history loss 4.255162 rank 3
2023-02-22 17:49:39,893 DEBUG CV Batch 21/300 loss 6.284276 loss_att 6.128802 loss_ctc 8.969440 loss_rnnt 5.946205 hw_loss 0.020894 history loss 4.255162 rank 1
2023-02-22 17:49:40,037 DEBUG CV Batch 21/300 loss 6.284276 loss_att 6.128802 loss_ctc 8.969440 loss_rnnt 5.946205 hw_loss 0.020894 history loss 4.255162 rank 2
2023-02-22 17:49:50,606 DEBUG CV Batch 21/400 loss 20.045654 loss_att 97.916786 loss_ctc 8.033426 loss_rnnt 6.058437 hw_loss 0.027415 history loss 5.193237 rank 4
2023-02-22 17:49:50,803 DEBUG CV Batch 21/400 loss 20.045654 loss_att 97.916786 loss_ctc 8.033426 loss_rnnt 6.058437 hw_loss 0.027415 history loss 5.193237 rank 0
2023-02-22 17:49:50,855 DEBUG CV Batch 21/400 loss 20.045654 loss_att 97.916786 loss_ctc 8.033426 loss_rnnt 6.058437 hw_loss 0.027415 history loss 5.193237 rank 7
2023-02-22 17:49:51,002 DEBUG CV Batch 21/400 loss 20.045654 loss_att 97.916786 loss_ctc 8.033426 loss_rnnt 6.058437 hw_loss 0.027415 history loss 5.193237 rank 5
2023-02-22 17:49:51,242 DEBUG CV Batch 21/400 loss 20.045654 loss_att 97.916786 loss_ctc 8.033426 loss_rnnt 6.058437 hw_loss 0.027415 history loss 5.193237 rank 6
2023-02-22 17:49:52,042 DEBUG CV Batch 21/400 loss 20.045654 loss_att 97.916786 loss_ctc 8.033426 loss_rnnt 6.058437 hw_loss 0.027415 history loss 5.193237 rank 1
2023-02-22 17:49:52,192 DEBUG CV Batch 21/400 loss 20.045654 loss_att 97.916786 loss_ctc 8.033426 loss_rnnt 6.058437 hw_loss 0.027415 history loss 5.193237 rank 3
2023-02-22 17:49:52,224 DEBUG CV Batch 21/400 loss 20.045654 loss_att 97.916786 loss_ctc 8.033426 loss_rnnt 6.058437 hw_loss 0.027415 history loss 5.193237 rank 2
2023-02-22 17:50:01,169 DEBUG CV Batch 21/500 loss 6.648040 loss_att 6.681921 loss_ctc 8.574195 loss_rnnt 6.374692 hw_loss 0.018283 history loss 6.003117 rank 4
2023-02-22 17:50:01,330 DEBUG CV Batch 21/500 loss 6.648040 loss_att 6.681921 loss_ctc 8.574195 loss_rnnt 6.374692 hw_loss 0.018283 history loss 6.003117 rank 0
2023-02-22 17:50:01,460 DEBUG CV Batch 21/500 loss 6.648040 loss_att 6.681921 loss_ctc 8.574195 loss_rnnt 6.374692 hw_loss 0.018283 history loss 6.003117 rank 7
2023-02-22 17:50:01,693 DEBUG CV Batch 21/500 loss 6.648040 loss_att 6.681921 loss_ctc 8.574195 loss_rnnt 6.374692 hw_loss 0.018283 history loss 6.003117 rank 5
2023-02-22 17:50:01,988 DEBUG CV Batch 21/500 loss 6.648040 loss_att 6.681921 loss_ctc 8.574195 loss_rnnt 6.374692 hw_loss 0.018283 history loss 6.003117 rank 6
2023-02-22 17:50:02,955 DEBUG CV Batch 21/500 loss 6.648040 loss_att 6.681921 loss_ctc 8.574195 loss_rnnt 6.374692 hw_loss 0.018283 history loss 6.003117 rank 3
2023-02-22 17:50:03,131 DEBUG CV Batch 21/500 loss 6.648040 loss_att 6.681921 loss_ctc 8.574195 loss_rnnt 6.374692 hw_loss 0.018283 history loss 6.003117 rank 2
2023-02-22 17:50:03,415 DEBUG CV Batch 21/500 loss 6.648040 loss_att 6.681921 loss_ctc 8.574195 loss_rnnt 6.374692 hw_loss 0.018283 history loss 6.003117 rank 1
2023-02-22 17:50:13,265 DEBUG CV Batch 21/600 loss 6.407783 loss_att 7.070780 loss_ctc 8.017758 loss_rnnt 5.981067 hw_loss 0.148975 history loss 6.974220 rank 4
2023-02-22 17:50:13,338 DEBUG CV Batch 21/600 loss 6.407783 loss_att 7.070780 loss_ctc 8.017758 loss_rnnt 5.981067 hw_loss 0.148975 history loss 6.974220 rank 0
2023-02-22 17:50:13,553 DEBUG CV Batch 21/600 loss 6.407783 loss_att 7.070780 loss_ctc 8.017758 loss_rnnt 5.981067 hw_loss 0.148975 history loss 6.974220 rank 7
2023-02-22 17:50:13,825 DEBUG CV Batch 21/600 loss 6.407783 loss_att 7.070780 loss_ctc 8.017758 loss_rnnt 5.981067 hw_loss 0.148975 history loss 6.974220 rank 5
2023-02-22 17:50:14,280 DEBUG CV Batch 21/600 loss 6.407783 loss_att 7.070780 loss_ctc 8.017758 loss_rnnt 5.981067 hw_loss 0.148975 history loss 6.974220 rank 6
2023-02-22 17:50:15,326 DEBUG CV Batch 21/600 loss 6.407783 loss_att 7.070780 loss_ctc 8.017758 loss_rnnt 5.981067 hw_loss 0.148975 history loss 6.974220 rank 3
2023-02-22 17:50:15,351 DEBUG CV Batch 21/600 loss 6.407783 loss_att 7.070780 loss_ctc 8.017758 loss_rnnt 5.981067 hw_loss 0.148975 history loss 6.974220 rank 2
2023-02-22 17:50:15,624 DEBUG CV Batch 21/600 loss 6.407783 loss_att 7.070780 loss_ctc 8.017758 loss_rnnt 5.981067 hw_loss 0.148975 history loss 6.974220 rank 1
2023-02-22 17:50:24,575 DEBUG CV Batch 21/700 loss 13.671440 loss_att 41.411686 loss_ctc 13.353554 loss_rnnt 8.165238 hw_loss 0.001006 history loss 7.644041 rank 4
2023-02-22 17:50:24,674 DEBUG CV Batch 21/700 loss 13.671440 loss_att 41.411686 loss_ctc 13.353554 loss_rnnt 8.165238 hw_loss 0.001006 history loss 7.644041 rank 0
2023-02-22 17:50:25,020 DEBUG CV Batch 21/700 loss 13.671440 loss_att 41.411686 loss_ctc 13.353554 loss_rnnt 8.165238 hw_loss 0.001006 history loss 7.644041 rank 7
2023-02-22 17:50:25,203 DEBUG CV Batch 21/700 loss 13.671440 loss_att 41.411686 loss_ctc 13.353554 loss_rnnt 8.165238 hw_loss 0.001006 history loss 7.644041 rank 5
2023-02-22 17:50:25,745 DEBUG CV Batch 21/700 loss 13.671440 loss_att 41.411686 loss_ctc 13.353554 loss_rnnt 8.165238 hw_loss 0.001006 history loss 7.644041 rank 6
2023-02-22 17:50:26,772 DEBUG CV Batch 21/700 loss 13.671440 loss_att 41.411686 loss_ctc 13.353554 loss_rnnt 8.165238 hw_loss 0.001006 history loss 7.644041 rank 3
2023-02-22 17:50:27,124 DEBUG CV Batch 21/700 loss 13.671440 loss_att 41.411686 loss_ctc 13.353554 loss_rnnt 8.165238 hw_loss 0.001006 history loss 7.644041 rank 1
2023-02-22 17:50:27,231 DEBUG CV Batch 21/700 loss 13.671440 loss_att 41.411686 loss_ctc 13.353554 loss_rnnt 8.165238 hw_loss 0.001006 history loss 7.644041 rank 2
2023-02-22 17:50:35,774 DEBUG CV Batch 21/800 loss 13.358479 loss_att 10.282462 loss_ctc 16.118370 loss_rnnt 13.568904 hw_loss 0.068986 history loss 7.081708 rank 0
2023-02-22 17:50:35,859 DEBUG CV Batch 21/800 loss 13.358479 loss_att 10.282462 loss_ctc 16.118370 loss_rnnt 13.568904 hw_loss 0.068986 history loss 7.081708 rank 4
2023-02-22 17:50:36,170 DEBUG CV Batch 21/800 loss 13.358479 loss_att 10.282462 loss_ctc 16.118370 loss_rnnt 13.568904 hw_loss 0.068986 history loss 7.081708 rank 7
2023-02-22 17:50:36,510 DEBUG CV Batch 21/800 loss 13.358479 loss_att 10.282462 loss_ctc 16.118370 loss_rnnt 13.568904 hw_loss 0.068986 history loss 7.081708 rank 5
2023-02-22 17:50:37,165 DEBUG CV Batch 21/800 loss 13.358479 loss_att 10.282462 loss_ctc 16.118370 loss_rnnt 13.568904 hw_loss 0.068986 history loss 7.081708 rank 6
2023-02-22 17:50:38,198 DEBUG CV Batch 21/800 loss 13.358479 loss_att 10.282462 loss_ctc 16.118370 loss_rnnt 13.568904 hw_loss 0.068986 history loss 7.081708 rank 3
2023-02-22 17:50:38,456 DEBUG CV Batch 21/800 loss 13.358479 loss_att 10.282462 loss_ctc 16.118370 loss_rnnt 13.568904 hw_loss 0.068986 history loss 7.081708 rank 1
2023-02-22 17:50:39,503 DEBUG CV Batch 21/800 loss 13.358479 loss_att 10.282462 loss_ctc 16.118370 loss_rnnt 13.568904 hw_loss 0.068986 history loss 7.081708 rank 2
2023-02-22 17:50:49,105 DEBUG CV Batch 21/900 loss 13.244555 loss_att 20.298079 loss_ctc 22.160192 loss_rnnt 10.611958 hw_loss 0.062136 history loss 6.880113 rank 4
2023-02-22 17:50:49,265 DEBUG CV Batch 21/900 loss 13.244555 loss_att 20.298079 loss_ctc 22.160192 loss_rnnt 10.611958 hw_loss 0.062136 history loss 6.880113 rank 0
2023-02-22 17:50:49,410 DEBUG CV Batch 21/900 loss 13.244555 loss_att 20.298079 loss_ctc 22.160192 loss_rnnt 10.611958 hw_loss 0.062136 history loss 6.880113 rank 7
2023-02-22 17:50:49,900 DEBUG CV Batch 21/900 loss 13.244555 loss_att 20.298079 loss_ctc 22.160192 loss_rnnt 10.611958 hw_loss 0.062136 history loss 6.880113 rank 5
2023-02-22 17:50:50,478 DEBUG CV Batch 21/900 loss 13.244555 loss_att 20.298079 loss_ctc 22.160192 loss_rnnt 10.611958 hw_loss 0.062136 history loss 6.880113 rank 6
2023-02-22 17:50:51,495 DEBUG CV Batch 21/900 loss 13.244555 loss_att 20.298079 loss_ctc 22.160192 loss_rnnt 10.611958 hw_loss 0.062136 history loss 6.880113 rank 3
2023-02-22 17:50:51,718 DEBUG CV Batch 21/900 loss 13.244555 loss_att 20.298079 loss_ctc 22.160192 loss_rnnt 10.611958 hw_loss 0.062136 history loss 6.880113 rank 1
2023-02-22 17:50:53,102 DEBUG CV Batch 21/900 loss 13.244555 loss_att 20.298079 loss_ctc 22.160192 loss_rnnt 10.611958 hw_loss 0.062136 history loss 6.880113 rank 2
2023-02-22 17:51:01,301 DEBUG CV Batch 21/1000 loss 4.814913 loss_att 5.222483 loss_ctc 4.460593 loss_rnnt 4.656330 hw_loss 0.233084 history loss 6.643500 rank 4
2023-02-22 17:51:01,432 DEBUG CV Batch 21/1000 loss 4.814913 loss_att 5.222483 loss_ctc 4.460593 loss_rnnt 4.656330 hw_loss 0.233084 history loss 6.643500 rank 7
2023-02-22 17:51:01,649 DEBUG CV Batch 21/1000 loss 4.814913 loss_att 5.222483 loss_ctc 4.460593 loss_rnnt 4.656330 hw_loss 0.233084 history loss 6.643500 rank 0
2023-02-22 17:51:02,058 DEBUG CV Batch 21/1000 loss 4.814913 loss_att 5.222483 loss_ctc 4.460593 loss_rnnt 4.656330 hw_loss 0.233084 history loss 6.643500 rank 5
2023-02-22 17:51:02,742 DEBUG CV Batch 21/1000 loss 4.814913 loss_att 5.222483 loss_ctc 4.460593 loss_rnnt 4.656330 hw_loss 0.233084 history loss 6.643500 rank 6
2023-02-22 17:51:03,695 DEBUG CV Batch 21/1000 loss 4.814913 loss_att 5.222483 loss_ctc 4.460593 loss_rnnt 4.656330 hw_loss 0.233084 history loss 6.643500 rank 3
2023-02-22 17:51:05,119 DEBUG CV Batch 21/1000 loss 4.814913 loss_att 5.222483 loss_ctc 4.460593 loss_rnnt 4.656330 hw_loss 0.233084 history loss 6.643500 rank 1
2023-02-22 17:51:05,477 DEBUG CV Batch 21/1000 loss 4.814913 loss_att 5.222483 loss_ctc 4.460593 loss_rnnt 4.656330 hw_loss 0.233084 history loss 6.643500 rank 2
2023-02-22 17:51:13,250 DEBUG CV Batch 21/1100 loss 7.244350 loss_att 6.220503 loss_ctc 9.600937 loss_rnnt 7.050643 hw_loss 0.157997 history loss 6.626702 rank 4
2023-02-22 17:51:13,364 DEBUG CV Batch 21/1100 loss 7.244350 loss_att 6.220503 loss_ctc 9.600937 loss_rnnt 7.050643 hw_loss 0.157997 history loss 6.626702 rank 7
2023-02-22 17:51:13,625 DEBUG CV Batch 21/1100 loss 7.244350 loss_att 6.220503 loss_ctc 9.600937 loss_rnnt 7.050643 hw_loss 0.157997 history loss 6.626702 rank 0
2023-02-22 17:51:13,981 DEBUG CV Batch 21/1100 loss 7.244350 loss_att 6.220503 loss_ctc 9.600937 loss_rnnt 7.050643 hw_loss 0.157997 history loss 6.626702 rank 5
2023-02-22 17:51:14,663 DEBUG CV Batch 21/1100 loss 7.244350 loss_att 6.220503 loss_ctc 9.600937 loss_rnnt 7.050643 hw_loss 0.157997 history loss 6.626702 rank 6
2023-02-22 17:51:15,617 DEBUG CV Batch 21/1100 loss 7.244350 loss_att 6.220503 loss_ctc 9.600937 loss_rnnt 7.050643 hw_loss 0.157997 history loss 6.626702 rank 3
2023-02-22 17:51:17,533 DEBUG CV Batch 21/1100 loss 7.244350 loss_att 6.220503 loss_ctc 9.600937 loss_rnnt 7.050643 hw_loss 0.157997 history loss 6.626702 rank 2
2023-02-22 17:51:17,769 DEBUG CV Batch 21/1100 loss 7.244350 loss_att 6.220503 loss_ctc 9.600937 loss_rnnt 7.050643 hw_loss 0.157997 history loss 6.626702 rank 1
2023-02-22 17:51:23,861 DEBUG CV Batch 21/1200 loss 8.763816 loss_att 8.706057 loss_ctc 11.503695 loss_rnnt 8.332200 hw_loss 0.145970 history loss 6.959804 rank 4
2023-02-22 17:51:23,894 DEBUG CV Batch 21/1200 loss 8.763816 loss_att 8.706057 loss_ctc 11.503695 loss_rnnt 8.332200 hw_loss 0.145970 history loss 6.959804 rank 7
2023-02-22 17:51:24,209 DEBUG CV Batch 21/1200 loss 8.763816 loss_att 8.706057 loss_ctc 11.503695 loss_rnnt 8.332200 hw_loss 0.145970 history loss 6.959804 rank 0
2023-02-22 17:51:24,606 DEBUG CV Batch 21/1200 loss 8.763816 loss_att 8.706057 loss_ctc 11.503695 loss_rnnt 8.332200 hw_loss 0.145970 history loss 6.959804 rank 5
2023-02-22 17:51:25,471 DEBUG CV Batch 21/1200 loss 8.763816 loss_att 8.706057 loss_ctc 11.503695 loss_rnnt 8.332200 hw_loss 0.145970 history loss 6.959804 rank 6
2023-02-22 17:51:27,134 DEBUG CV Batch 21/1200 loss 8.763816 loss_att 8.706057 loss_ctc 11.503695 loss_rnnt 8.332200 hw_loss 0.145970 history loss 6.959804 rank 3
2023-02-22 17:51:28,248 DEBUG CV Batch 21/1200 loss 8.763816 loss_att 8.706057 loss_ctc 11.503695 loss_rnnt 8.332200 hw_loss 0.145970 history loss 6.959804 rank 2
2023-02-22 17:51:28,457 DEBUG CV Batch 21/1200 loss 8.763816 loss_att 8.706057 loss_ctc 11.503695 loss_rnnt 8.332200 hw_loss 0.145970 history loss 6.959804 rank 1
2023-02-22 17:51:35,835 DEBUG CV Batch 21/1300 loss 5.483455 loss_att 5.899094 loss_ctc 7.614458 loss_rnnt 5.052357 hw_loss 0.119693 history loss 7.279706 rank 7
2023-02-22 17:51:35,908 DEBUG CV Batch 21/1300 loss 5.483455 loss_att 5.899094 loss_ctc 7.614458 loss_rnnt 5.052357 hw_loss 0.119693 history loss 7.279706 rank 4
2023-02-22 17:51:36,112 DEBUG CV Batch 21/1300 loss 5.483455 loss_att 5.899094 loss_ctc 7.614458 loss_rnnt 5.052357 hw_loss 0.119693 history loss 7.279706 rank 0
2023-02-22 17:51:36,624 DEBUG CV Batch 21/1300 loss 5.483455 loss_att 5.899094 loss_ctc 7.614458 loss_rnnt 5.052357 hw_loss 0.119693 history loss 7.279706 rank 5
2023-02-22 17:51:37,535 DEBUG CV Batch 21/1300 loss 5.483455 loss_att 5.899094 loss_ctc 7.614458 loss_rnnt 5.052357 hw_loss 0.119693 history loss 7.279706 rank 6
2023-02-22 17:51:39,263 DEBUG CV Batch 21/1300 loss 5.483455 loss_att 5.899094 loss_ctc 7.614458 loss_rnnt 5.052357 hw_loss 0.119693 history loss 7.279706 rank 3
2023-02-22 17:51:40,304 DEBUG CV Batch 21/1300 loss 5.483455 loss_att 5.899094 loss_ctc 7.614458 loss_rnnt 5.052357 hw_loss 0.119693 history loss 7.279706 rank 2
2023-02-22 17:51:40,440 DEBUG CV Batch 21/1300 loss 5.483455 loss_att 5.899094 loss_ctc 7.614458 loss_rnnt 5.052357 hw_loss 0.119693 history loss 7.279706 rank 1
2023-02-22 17:51:47,024 DEBUG CV Batch 21/1400 loss 7.634252 loss_att 18.211506 loss_ctc 6.041855 loss_rnnt 5.643387 hw_loss 0.164499 history loss 7.611277 rank 7
2023-02-22 17:51:47,132 DEBUG CV Batch 21/1400 loss 7.634252 loss_att 18.211506 loss_ctc 6.041855 loss_rnnt 5.643387 hw_loss 0.164499 history loss 7.611277 rank 4
2023-02-22 17:51:47,336 DEBUG CV Batch 21/1400 loss 7.634252 loss_att 18.211506 loss_ctc 6.041855 loss_rnnt 5.643387 hw_loss 0.164499 history loss 7.611277 rank 0
2023-02-22 17:51:47,889 DEBUG CV Batch 21/1400 loss 7.634252 loss_att 18.211506 loss_ctc 6.041855 loss_rnnt 5.643387 hw_loss 0.164499 history loss 7.611277 rank 5
2023-02-22 17:51:48,819 DEBUG CV Batch 21/1400 loss 7.634252 loss_att 18.211506 loss_ctc 6.041855 loss_rnnt 5.643387 hw_loss 0.164499 history loss 7.611277 rank 6
2023-02-22 17:51:50,550 DEBUG CV Batch 21/1400 loss 7.634252 loss_att 18.211506 loss_ctc 6.041855 loss_rnnt 5.643387 hw_loss 0.164499 history loss 7.611277 rank 3
2023-02-22 17:51:51,669 DEBUG CV Batch 21/1400 loss 7.634252 loss_att 18.211506 loss_ctc 6.041855 loss_rnnt 5.643387 hw_loss 0.164499 history loss 7.611277 rank 2
2023-02-22 17:51:51,847 DEBUG CV Batch 21/1400 loss 7.634252 loss_att 18.211506 loss_ctc 6.041855 loss_rnnt 5.643387 hw_loss 0.164499 history loss 7.611277 rank 1
2023-02-22 17:51:58,551 DEBUG CV Batch 21/1500 loss 8.331962 loss_att 7.952113 loss_ctc 9.328711 loss_rnnt 8.226894 hw_loss 0.090258 history loss 7.430738 rank 7
2023-02-22 17:51:58,588 DEBUG CV Batch 21/1500 loss 8.331962 loss_att 7.952113 loss_ctc 9.328711 loss_rnnt 8.226894 hw_loss 0.090258 history loss 7.430738 rank 4
2023-02-22 17:51:58,747 DEBUG CV Batch 21/1500 loss 8.331962 loss_att 7.952113 loss_ctc 9.328711 loss_rnnt 8.226894 hw_loss 0.090258 history loss 7.430738 rank 0
2023-02-22 17:51:59,368 DEBUG CV Batch 21/1500 loss 8.331962 loss_att 7.952113 loss_ctc 9.328711 loss_rnnt 8.226894 hw_loss 0.090258 history loss 7.430738 rank 5
2023-02-22 17:52:00,496 DEBUG CV Batch 21/1500 loss 8.331962 loss_att 7.952113 loss_ctc 9.328711 loss_rnnt 8.226894 hw_loss 0.090258 history loss 7.430738 rank 6
2023-02-22 17:52:02,066 DEBUG CV Batch 21/1500 loss 8.331962 loss_att 7.952113 loss_ctc 9.328711 loss_rnnt 8.226894 hw_loss 0.090258 history loss 7.430738 rank 3
2023-02-22 17:52:03,272 DEBUG CV Batch 21/1500 loss 8.331962 loss_att 7.952113 loss_ctc 9.328711 loss_rnnt 8.226894 hw_loss 0.090258 history loss 7.430738 rank 2
2023-02-22 17:52:03,327 DEBUG CV Batch 21/1500 loss 8.331962 loss_att 7.952113 loss_ctc 9.328711 loss_rnnt 8.226894 hw_loss 0.090258 history loss 7.430738 rank 1
2023-02-22 17:52:11,487 DEBUG CV Batch 21/1600 loss 8.866309 loss_att 12.614578 loss_ctc 10.421047 loss_rnnt 7.888132 hw_loss 0.039797 history loss 7.367483 rank 7
2023-02-22 17:52:11,494 DEBUG CV Batch 21/1600 loss 8.866309 loss_att 12.614578 loss_ctc 10.421047 loss_rnnt 7.888132 hw_loss 0.039797 history loss 7.367483 rank 4
2023-02-22 17:52:11,678 DEBUG CV Batch 21/1600 loss 8.866309 loss_att 12.614578 loss_ctc 10.421047 loss_rnnt 7.888132 hw_loss 0.039797 history loss 7.367483 rank 0
2023-02-22 17:52:12,297 DEBUG CV Batch 21/1600 loss 8.866309 loss_att 12.614578 loss_ctc 10.421047 loss_rnnt 7.888132 hw_loss 0.039797 history loss 7.367483 rank 5
2023-02-22 17:52:14,168 DEBUG CV Batch 21/1600 loss 8.866309 loss_att 12.614578 loss_ctc 10.421047 loss_rnnt 7.888132 hw_loss 0.039797 history loss 7.367483 rank 6
2023-02-22 17:52:15,190 DEBUG CV Batch 21/1600 loss 8.866309 loss_att 12.614578 loss_ctc 10.421047 loss_rnnt 7.888132 hw_loss 0.039797 history loss 7.367483 rank 3
2023-02-22 17:52:16,370 DEBUG CV Batch 21/1600 loss 8.866309 loss_att 12.614578 loss_ctc 10.421047 loss_rnnt 7.888132 hw_loss 0.039797 history loss 7.367483 rank 2
2023-02-22 17:52:16,462 DEBUG CV Batch 21/1600 loss 8.866309 loss_att 12.614578 loss_ctc 10.421047 loss_rnnt 7.888132 hw_loss 0.039797 history loss 7.367483 rank 1
2023-02-22 17:52:23,739 DEBUG CV Batch 21/1700 loss 11.402098 loss_att 9.835703 loss_ctc 15.172915 loss_rnnt 11.122976 hw_loss 0.168047 history loss 7.273403 rank 7
2023-02-22 17:52:23,759 DEBUG CV Batch 21/1700 loss 11.402098 loss_att 9.835703 loss_ctc 15.172915 loss_rnnt 11.122976 hw_loss 0.168047 history loss 7.273403 rank 4
2023-02-22 17:52:23,904 DEBUG CV Batch 21/1700 loss 11.402098 loss_att 9.835703 loss_ctc 15.172915 loss_rnnt 11.122976 hw_loss 0.168047 history loss 7.273403 rank 0
2023-02-22 17:52:24,598 DEBUG CV Batch 21/1700 loss 11.402098 loss_att 9.835703 loss_ctc 15.172915 loss_rnnt 11.122976 hw_loss 0.168047 history loss 7.273403 rank 5
2023-02-22 17:52:26,578 DEBUG CV Batch 21/1700 loss 11.402098 loss_att 9.835703 loss_ctc 15.172915 loss_rnnt 11.122976 hw_loss 0.168047 history loss 7.273403 rank 6
2023-02-22 17:52:28,032 DEBUG CV Batch 21/1700 loss 11.402098 loss_att 9.835703 loss_ctc 15.172915 loss_rnnt 11.122976 hw_loss 0.168047 history loss 7.273403 rank 3
2023-02-22 17:52:28,637 DEBUG CV Batch 21/1700 loss 11.402098 loss_att 9.835703 loss_ctc 15.172915 loss_rnnt 11.122976 hw_loss 0.168047 history loss 7.273403 rank 2
2023-02-22 17:52:28,822 DEBUG CV Batch 21/1700 loss 11.402098 loss_att 9.835703 loss_ctc 15.172915 loss_rnnt 11.122976 hw_loss 0.168047 history loss 7.273403 rank 1
2023-02-22 17:52:32,683 INFO Epoch 21 CV info cv_loss 7.245241755745903
2023-02-22 17:52:32,684 INFO Epoch 22 TRAIN info lr 0.00036912483992235755
2023-02-22 17:52:32,688 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 17:52:32,753 INFO Epoch 21 CV info cv_loss 7.245241754643231
2023-02-22 17:52:32,753 INFO Epoch 22 TRAIN info lr 0.0003691479775314256
2023-02-22 17:52:32,756 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 17:52:32,869 INFO Epoch 21 CV info cv_loss 7.245241756788274
2023-02-22 17:52:32,871 INFO Checkpoint: save to checkpoint exp/2_21_rnnt_bias_loss_2_class_1word_finetune/21.pt
2023-02-22 17:52:33,489 INFO Epoch 22 TRAIN info lr 0.0003691489836131296
2023-02-22 17:52:33,493 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 17:52:33,609 INFO Epoch 21 CV info cv_loss 7.245241755758825
2023-02-22 17:52:33,611 INFO Epoch 22 TRAIN info lr 0.00036913892316624226
2023-02-22 17:52:33,616 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 17:52:35,634 INFO Epoch 21 CV info cv_loss 7.245241755711445
2023-02-22 17:52:35,635 INFO Epoch 22 TRAIN info lr 0.0003691540141450419
2023-02-22 17:52:35,638 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 17:52:37,051 INFO Epoch 21 CV info cv_loss 7.245241755362552
2023-02-22 17:52:37,051 INFO Epoch 22 TRAIN info lr 0.0003690976839319231
2023-02-22 17:52:37,055 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 17:52:37,715 INFO Epoch 21 CV info cv_loss 7.24524175530225
2023-02-22 17:52:37,716 INFO Epoch 22 TRAIN info lr 0.0003690685230614675
2023-02-22 17:52:37,719 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 17:52:37,889 INFO Epoch 21 CV info cv_loss 7.245241756150791
2023-02-22 17:52:37,890 INFO Epoch 22 TRAIN info lr 0.0003691359051925666
2023-02-22 17:52:37,893 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 17:53:51,461 DEBUG TRAIN Batch 22/0 loss 8.100048 loss_att 7.735930 loss_ctc 10.381768 loss_rnnt 7.813239 hw_loss 0.103882 lr 0.00036912 rank 7
2023-02-22 17:53:51,463 DEBUG TRAIN Batch 22/0 loss 10.557823 loss_att 9.963778 loss_ctc 13.744047 loss_rnnt 10.185238 hw_loss 0.124807 lr 0.00036915 rank 0
2023-02-22 17:53:51,466 DEBUG TRAIN Batch 22/0 loss 9.478370 loss_att 8.114536 loss_ctc 12.317615 loss_rnnt 9.333209 hw_loss 0.073803 lr 0.00036914 rank 5
2023-02-22 17:53:51,469 DEBUG TRAIN Batch 22/0 loss 9.485482 loss_att 9.910789 loss_ctc 12.796239 loss_rnnt 8.914200 hw_loss 0.083973 lr 0.00036915 rank 4
2023-02-22 17:53:51,473 DEBUG TRAIN Batch 22/0 loss 5.993897 loss_att 5.411808 loss_ctc 7.144351 loss_rnnt 5.916083 hw_loss 0.076572 lr 0.00036910 rank 3
2023-02-22 17:53:51,476 DEBUG TRAIN Batch 22/0 loss 5.468764 loss_att 5.699265 loss_ctc 8.012366 loss_rnnt 5.023260 hw_loss 0.112982 lr 0.00036915 rank 6
2023-02-22 17:53:51,513 DEBUG TRAIN Batch 22/0 loss 10.613272 loss_att 9.304431 loss_ctc 12.517429 loss_rnnt 10.595561 hw_loss 0.047985 lr 0.00036913 rank 1
2023-02-22 17:53:51,535 DEBUG TRAIN Batch 22/0 loss 10.217565 loss_att 9.714613 loss_ctc 14.574454 loss_rnnt 9.654193 hw_loss 0.155709 lr 0.00036907 rank 2
2023-02-22 17:55:07,747 DEBUG TRAIN Batch 22/100 loss 19.704058 loss_att 18.201920 loss_ctc 22.738930 loss_rnnt 19.586943 hw_loss 0.024177 lr 0.00036905 rank 4
2023-02-22 17:55:07,748 DEBUG TRAIN Batch 22/100 loss 6.318295 loss_att 8.651321 loss_ctc 8.496905 loss_rnnt 5.537929 hw_loss 0.043652 lr 0.00036904 rank 5
2023-02-22 17:55:07,750 DEBUG TRAIN Batch 22/100 loss 13.878809 loss_att 16.251551 loss_ctc 21.603811 loss_rnnt 12.323261 hw_loss 0.095623 lr 0.00036905 rank 0
2023-02-22 17:55:07,749 DEBUG TRAIN Batch 22/100 loss 7.968235 loss_att 9.217432 loss_ctc 11.849959 loss_rnnt 7.173753 hw_loss 0.050773 lr 0.00036900 rank 3
2023-02-22 17:55:07,750 DEBUG TRAIN Batch 22/100 loss 13.751135 loss_att 16.524075 loss_ctc 19.344185 loss_rnnt 12.419849 hw_loss 0.058045 lr 0.00036902 rank 7
2023-02-22 17:55:07,755 DEBUG TRAIN Batch 22/100 loss 7.610275 loss_att 8.824451 loss_ctc 11.081080 loss_rnnt 6.838619 hw_loss 0.123837 lr 0.00036905 rank 6
2023-02-22 17:55:07,758 DEBUG TRAIN Batch 22/100 loss 12.527642 loss_att 16.216972 loss_ctc 16.230862 loss_rnnt 11.214830 hw_loss 0.152217 lr 0.00036903 rank 1
2023-02-22 17:55:07,803 DEBUG TRAIN Batch 22/100 loss 11.628587 loss_att 15.926096 loss_ctc 17.118610 loss_rnnt 9.984087 hw_loss 0.099367 lr 0.00036897 rank 2
2023-02-22 17:56:23,655 DEBUG TRAIN Batch 22/200 loss 13.333741 loss_att 19.753313 loss_ctc 26.362423 loss_rnnt 10.255924 hw_loss 0.106394 lr 0.00036892 rank 7
2023-02-22 17:56:23,658 DEBUG TRAIN Batch 22/200 loss 8.294173 loss_att 9.702852 loss_ctc 14.519386 loss_rnnt 7.168109 hw_loss 0.026813 lr 0.00036895 rank 4
2023-02-22 17:56:23,660 DEBUG TRAIN Batch 22/200 loss 6.091655 loss_att 7.658672 loss_ctc 7.311117 loss_rnnt 5.515789 hw_loss 0.187254 lr 0.00036895 rank 6
2023-02-22 17:56:23,661 DEBUG TRAIN Batch 22/200 loss 5.128026 loss_att 8.151444 loss_ctc 7.132169 loss_rnnt 4.220538 hw_loss 0.066722 lr 0.00036895 rank 0
2023-02-22 17:56:23,661 DEBUG TRAIN Batch 22/200 loss 6.105133 loss_att 8.652010 loss_ctc 9.375053 loss_rnnt 5.149719 hw_loss 0.018841 lr 0.00036894 rank 5
2023-02-22 17:56:23,666 DEBUG TRAIN Batch 22/200 loss 13.334828 loss_att 17.895054 loss_ctc 19.251974 loss_rnnt 11.530089 hw_loss 0.194514 lr 0.00036893 rank 1
2023-02-22 17:56:23,669 DEBUG TRAIN Batch 22/200 loss 7.189324 loss_att 11.413105 loss_ctc 10.325773 loss_rnnt 5.909765 hw_loss 0.031145 lr 0.00036890 rank 3
2023-02-22 17:56:23,671 DEBUG TRAIN Batch 22/200 loss 5.733991 loss_att 10.814715 loss_ctc 10.994303 loss_rnnt 4.016214 hw_loss 0.000482 lr 0.00036887 rank 2
2023-02-22 17:57:39,194 DEBUG TRAIN Batch 22/300 loss 8.654813 loss_att 12.845818 loss_ctc 13.245411 loss_rnnt 7.180098 hw_loss 0.045812 lr 0.00036882 rank 7
2023-02-22 17:57:39,197 DEBUG TRAIN Batch 22/300 loss 6.297314 loss_att 8.507841 loss_ctc 9.062851 loss_rnnt 5.463617 hw_loss 0.042848 lr 0.00036885 rank 0
2023-02-22 17:57:39,199 DEBUG TRAIN Batch 22/300 loss 6.343994 loss_att 11.015295 loss_ctc 7.958474 loss_rnnt 5.183951 hw_loss 0.019721 lr 0.00036883 rank 1
2023-02-22 17:57:39,202 DEBUG TRAIN Batch 22/300 loss 14.926464 loss_att 19.541134 loss_ctc 23.960131 loss_rnnt 12.757469 hw_loss 0.077946 lr 0.00036884 rank 5
2023-02-22 17:57:39,204 DEBUG TRAIN Batch 22/300 loss 10.101541 loss_att 13.748449 loss_ctc 12.995426 loss_rnnt 8.930061 hw_loss 0.105461 lr 0.00036877 rank 2
2023-02-22 17:57:39,205 DEBUG TRAIN Batch 22/300 loss 1.935002 loss_att 5.883432 loss_ctc 3.798151 loss_rnnt 0.864515 hw_loss 0.060714 lr 0.00036880 rank 3
2023-02-22 17:57:39,206 DEBUG TRAIN Batch 22/300 loss 13.346560 loss_att 15.823895 loss_ctc 16.260813 loss_rnnt 12.397840 hw_loss 0.121287 lr 0.00036885 rank 6
2023-02-22 17:57:39,226 DEBUG TRAIN Batch 22/300 loss 9.979179 loss_att 14.282895 loss_ctc 17.409039 loss_rnnt 8.102171 hw_loss 0.048033 lr 0.00036885 rank 4
2023-02-22 17:58:56,257 DEBUG TRAIN Batch 22/400 loss 18.723370 loss_att 20.877951 loss_ctc 25.408566 loss_rnnt 17.368855 hw_loss 0.060451 lr 0.00036874 rank 5
2023-02-22 17:58:56,258 DEBUG TRAIN Batch 22/400 loss 9.893129 loss_att 13.255844 loss_ctc 14.703076 loss_rnnt 8.531068 hw_loss 0.090358 lr 0.00036872 rank 7
2023-02-22 17:58:56,258 DEBUG TRAIN Batch 22/400 loss 7.923560 loss_att 12.349961 loss_ctc 14.709507 loss_rnnt 6.117639 hw_loss 0.029715 lr 0.00036870 rank 3
2023-02-22 17:58:56,260 DEBUG TRAIN Batch 22/400 loss 9.555120 loss_att 16.233822 loss_ctc 15.946457 loss_rnnt 7.307777 hw_loss 0.111422 lr 0.00036875 rank 0
2023-02-22 17:58:56,261 DEBUG TRAIN Batch 22/400 loss 7.711550 loss_att 9.248169 loss_ctc 9.879219 loss_rnnt 7.090520 hw_loss 0.046282 lr 0.00036875 rank 4
2023-02-22 17:58:56,262 DEBUG TRAIN Batch 22/400 loss 4.375661 loss_att 7.304770 loss_ctc 5.123165 loss_rnnt 3.612425 hw_loss 0.145777 lr 0.00036873 rank 1
2023-02-22 17:58:56,266 DEBUG TRAIN Batch 22/400 loss 6.716660 loss_att 9.231708 loss_ctc 10.183405 loss_rnnt 5.722085 hw_loss 0.054998 lr 0.00036875 rank 6
2023-02-22 17:58:56,272 DEBUG TRAIN Batch 22/400 loss 8.363253 loss_att 13.418590 loss_ctc 14.351870 loss_rnnt 6.446709 hw_loss 0.200612 lr 0.00036867 rank 2
2023-02-22 18:00:11,316 DEBUG TRAIN Batch 22/500 loss 9.249319 loss_att 12.443729 loss_ctc 14.974962 loss_rnnt 7.796814 hw_loss 0.094132 lr 0.00036864 rank 4
2023-02-22 18:00:11,318 DEBUG TRAIN Batch 22/500 loss 14.577531 loss_att 16.754772 loss_ctc 14.692039 loss_rnnt 14.071199 hw_loss 0.104278 lr 0.00036863 rank 1
2023-02-22 18:00:11,320 DEBUG TRAIN Batch 22/500 loss 4.302268 loss_att 7.089689 loss_ctc 5.741868 loss_rnnt 3.515938 hw_loss 0.069185 lr 0.00036865 rank 0
2023-02-22 18:00:11,321 DEBUG TRAIN Batch 22/500 loss 8.985483 loss_att 11.001611 loss_ctc 13.608777 loss_rnnt 7.951385 hw_loss 0.027060 lr 0.00036862 rank 7
2023-02-22 18:00:11,323 DEBUG TRAIN Batch 22/500 loss 4.017026 loss_att 7.129513 loss_ctc 6.062877 loss_rnnt 3.073799 hw_loss 0.089907 lr 0.00036864 rank 5
2023-02-22 18:00:11,324 DEBUG TRAIN Batch 22/500 loss 8.859172 loss_att 11.185612 loss_ctc 13.716139 loss_rnnt 7.720149 hw_loss 0.049011 lr 0.00036859 rank 3
2023-02-22 18:00:11,327 DEBUG TRAIN Batch 22/500 loss 10.906323 loss_att 13.328488 loss_ctc 15.359365 loss_rnnt 9.748097 hw_loss 0.150100 lr 0.00036857 rank 2
2023-02-22 18:00:11,332 DEBUG TRAIN Batch 22/500 loss 14.803103 loss_att 15.686991 loss_ctc 20.942524 loss_rnnt 13.773435 hw_loss 0.064314 lr 0.00036865 rank 6
2023-02-22 18:01:26,579 DEBUG TRAIN Batch 22/600 loss 13.662601 loss_att 16.195652 loss_ctc 22.347023 loss_rnnt 11.947074 hw_loss 0.095616 lr 0.00036855 rank 0
2023-02-22 18:01:26,586 DEBUG TRAIN Batch 22/600 loss 13.105088 loss_att 13.632067 loss_ctc 21.289495 loss_rnnt 11.788371 hw_loss 0.225124 lr 0.00036852 rank 7
2023-02-22 18:01:26,588 DEBUG TRAIN Batch 22/600 loss 6.303403 loss_att 6.804610 loss_ctc 9.251554 loss_rnnt 5.744013 hw_loss 0.123867 lr 0.00036854 rank 5
2023-02-22 18:01:26,588 DEBUG TRAIN Batch 22/600 loss 8.565228 loss_att 12.515360 loss_ctc 10.416664 loss_rnnt 7.498747 hw_loss 0.055491 lr 0.00036854 rank 4
2023-02-22 18:01:26,589 DEBUG TRAIN Batch 22/600 loss 7.803259 loss_att 9.298136 loss_ctc 9.049790 loss_rnnt 7.290655 hw_loss 0.088921 lr 0.00036855 rank 6
2023-02-22 18:01:26,590 DEBUG TRAIN Batch 22/600 loss 10.629857 loss_att 14.365054 loss_ctc 16.795471 loss_rnnt 9.022727 hw_loss 0.071267 lr 0.00036853 rank 1
2023-02-22 18:01:26,593 DEBUG TRAIN Batch 22/600 loss 10.967477 loss_att 13.745447 loss_ctc 12.135600 loss_rnnt 10.209195 hw_loss 0.088008 lr 0.00036847 rank 2
2023-02-22 18:01:26,646 DEBUG TRAIN Batch 22/600 loss 9.137831 loss_att 10.841633 loss_ctc 13.427719 loss_rnnt 8.185551 hw_loss 0.074128 lr 0.00036849 rank 3
2023-02-22 18:02:44,150 DEBUG TRAIN Batch 22/700 loss 9.923391 loss_att 11.301361 loss_ctc 13.320723 loss_rnnt 9.139469 hw_loss 0.103784 lr 0.00036844 rank 4
2023-02-22 18:02:44,152 DEBUG TRAIN Batch 22/700 loss 11.244265 loss_att 16.249006 loss_ctc 19.709270 loss_rnnt 9.081049 hw_loss 0.063000 lr 0.00036842 rank 7
2023-02-22 18:02:44,155 DEBUG TRAIN Batch 22/700 loss 17.271893 loss_att 20.170998 loss_ctc 22.651699 loss_rnnt 15.940155 hw_loss 0.064895 lr 0.00036844 rank 5
2023-02-22 18:02:44,157 DEBUG TRAIN Batch 22/700 loss 5.567585 loss_att 6.973437 loss_ctc 6.887375 loss_rnnt 5.083389 hw_loss 0.050726 lr 0.00036843 rank 1
2023-02-22 18:02:44,159 DEBUG TRAIN Batch 22/700 loss 8.616739 loss_att 9.082053 loss_ctc 9.324207 loss_rnnt 8.364225 hw_loss 0.122105 lr 0.00036845 rank 0
2023-02-22 18:02:44,164 DEBUG TRAIN Batch 22/700 loss 11.317185 loss_att 12.796916 loss_ctc 13.994444 loss_rnnt 10.621523 hw_loss 0.080155 lr 0.00036845 rank 6
2023-02-22 18:02:44,176 DEBUG TRAIN Batch 22/700 loss 12.179681 loss_att 14.954436 loss_ctc 20.090170 loss_rnnt 10.464492 hw_loss 0.197824 lr 0.00036837 rank 2
2023-02-22 18:02:44,182 DEBUG TRAIN Batch 22/700 loss 12.849690 loss_att 17.874216 loss_ctc 16.160500 loss_rnnt 11.369522 hw_loss 0.063417 lr 0.00036839 rank 3
2023-02-22 18:04:01,304 DEBUG TRAIN Batch 22/800 loss 9.288919 loss_att 11.887098 loss_ctc 12.295015 loss_rnnt 8.321167 hw_loss 0.088695 lr 0.00036834 rank 5
2023-02-22 18:04:01,305 DEBUG TRAIN Batch 22/800 loss 7.257341 loss_att 9.000765 loss_ctc 6.560030 loss_rnnt 6.957790 hw_loss 0.082203 lr 0.00036834 rank 4
2023-02-22 18:04:01,307 DEBUG TRAIN Batch 22/800 loss 6.891623 loss_att 9.143060 loss_ctc 10.960185 loss_rnnt 5.892129 hw_loss 0.012621 lr 0.00036832 rank 7
2023-02-22 18:04:01,308 DEBUG TRAIN Batch 22/800 loss 2.486080 loss_att 4.739291 loss_ctc 4.334161 loss_rnnt 1.759551 hw_loss 0.055266 lr 0.00036835 rank 6
2023-02-22 18:04:01,308 DEBUG TRAIN Batch 22/800 loss 3.412166 loss_att 6.838921 loss_ctc 5.860006 loss_rnnt 2.393153 hw_loss 0.013657 lr 0.00036835 rank 0
2023-02-22 18:04:01,311 DEBUG TRAIN Batch 22/800 loss 8.282781 loss_att 10.843755 loss_ctc 13.239021 loss_rnnt 7.083747 hw_loss 0.048765 lr 0.00036827 rank 2
2023-02-22 18:04:01,312 DEBUG TRAIN Batch 22/800 loss 11.060666 loss_att 14.036567 loss_ctc 17.436279 loss_rnnt 9.580112 hw_loss 0.066176 lr 0.00036829 rank 3
2023-02-22 18:04:01,354 DEBUG TRAIN Batch 22/800 loss 4.994937 loss_att 6.817151 loss_ctc 7.782604 loss_rnnt 4.171665 hw_loss 0.163388 lr 0.00036833 rank 1
2023-02-22 18:05:17,777 DEBUG TRAIN Batch 22/900 loss 9.482022 loss_att 14.484789 loss_ctc 15.010227 loss_rnnt 7.708005 hw_loss 0.068192 lr 0.00036824 rank 4
2023-02-22 18:05:17,782 DEBUG TRAIN Batch 22/900 loss 9.606615 loss_att 15.262545 loss_ctc 18.914028 loss_rnnt 7.171016 hw_loss 0.118924 lr 0.00036825 rank 0
2023-02-22 18:05:17,784 DEBUG TRAIN Batch 22/900 loss 12.121842 loss_att 15.103917 loss_ctc 15.604121 loss_rnnt 11.016739 hw_loss 0.083220 lr 0.00036824 rank 5
2023-02-22 18:05:17,786 DEBUG TRAIN Batch 22/900 loss 13.919218 loss_att 20.183821 loss_ctc 26.341499 loss_rnnt 10.996788 hw_loss 0.024761 lr 0.00036823 rank 1
2023-02-22 18:05:17,786 DEBUG TRAIN Batch 22/900 loss 8.659155 loss_att 9.675036 loss_ctc 14.738238 loss_rnnt 7.610298 hw_loss 0.065879 lr 0.00036819 rank 3
2023-02-22 18:05:17,787 DEBUG TRAIN Batch 22/900 loss 7.098870 loss_att 9.161573 loss_ctc 10.000412 loss_rnnt 6.275051 hw_loss 0.045762 lr 0.00036817 rank 2
2023-02-22 18:05:17,792 DEBUG TRAIN Batch 22/900 loss 10.270099 loss_att 13.864463 loss_ctc 13.525871 loss_rnnt 9.067019 hw_loss 0.093944 lr 0.00036825 rank 6
2023-02-22 18:05:17,792 DEBUG TRAIN Batch 22/900 loss 3.928206 loss_att 6.003293 loss_ctc 3.550318 loss_rnnt 3.502803 hw_loss 0.113943 lr 0.00036822 rank 7
2023-02-22 18:06:33,253 DEBUG TRAIN Batch 22/1000 loss 4.971266 loss_att 9.473162 loss_ctc 5.727810 loss_rnnt 3.923557 hw_loss 0.087106 lr 0.00036812 rank 7
2023-02-22 18:06:33,254 DEBUG TRAIN Batch 22/1000 loss 12.757380 loss_att 17.414843 loss_ctc 23.923515 loss_rnnt 10.257998 hw_loss 0.148259 lr 0.00036810 rank 3
2023-02-22 18:06:33,255 DEBUG TRAIN Batch 22/1000 loss 10.679960 loss_att 14.096809 loss_ctc 17.095900 loss_rnnt 9.086569 hw_loss 0.102305 lr 0.00036807 rank 2
2023-02-22 18:06:33,256 DEBUG TRAIN Batch 22/1000 loss 5.966043 loss_att 8.726751 loss_ctc 7.153613 loss_rnnt 5.207829 hw_loss 0.089492 lr 0.00036814 rank 4
2023-02-22 18:06:33,257 DEBUG TRAIN Batch 22/1000 loss 10.454644 loss_att 11.520182 loss_ctc 17.993114 loss_rnnt 9.234126 hw_loss 0.004278 lr 0.00036815 rank 0
2023-02-22 18:06:33,261 DEBUG TRAIN Batch 22/1000 loss 7.115090 loss_att 9.782736 loss_ctc 10.091204 loss_rnnt 6.130551 hw_loss 0.101616 lr 0.00036814 rank 5
2023-02-22 18:06:33,263 DEBUG TRAIN Batch 22/1000 loss 14.681013 loss_att 19.636234 loss_ctc 22.306505 loss_rnnt 12.654465 hw_loss 0.035195 lr 0.00036813 rank 1
2023-02-22 18:06:33,263 DEBUG TRAIN Batch 22/1000 loss 12.716058 loss_att 16.047153 loss_ctc 22.418663 loss_rnnt 10.688173 hw_loss 0.127471 lr 0.00036815 rank 6
2023-02-22 18:07:51,128 DEBUG TRAIN Batch 22/1100 loss 4.852251 loss_att 8.076923 loss_ctc 9.494641 loss_rnnt 3.467570 hw_loss 0.226426 lr 0.00036802 rank 7
2023-02-22 18:07:51,132 DEBUG TRAIN Batch 22/1100 loss 8.691433 loss_att 15.653010 loss_ctc 10.600471 loss_rnnt 6.994140 hw_loss 0.094573 lr 0.00036803 rank 1
2023-02-22 18:07:51,134 DEBUG TRAIN Batch 22/1100 loss 7.559008 loss_att 10.946608 loss_ctc 14.175131 loss_rnnt 5.948599 hw_loss 0.095137 lr 0.00036804 rank 5
2023-02-22 18:07:51,134 DEBUG TRAIN Batch 22/1100 loss 13.159336 loss_att 17.048431 loss_ctc 23.872015 loss_rnnt 10.895162 hw_loss 0.108748 lr 0.00036805 rank 6
2023-02-22 18:07:51,136 DEBUG TRAIN Batch 22/1100 loss 6.276485 loss_att 8.038445 loss_ctc 6.568644 loss_rnnt 5.792182 hw_loss 0.174296 lr 0.00036805 rank 0
2023-02-22 18:07:51,136 DEBUG TRAIN Batch 22/1100 loss 13.120438 loss_att 13.767324 loss_ctc 16.977468 loss_rnnt 12.444391 hw_loss 0.060745 lr 0.00036805 rank 4
2023-02-22 18:07:51,139 DEBUG TRAIN Batch 22/1100 loss 11.933797 loss_att 13.874456 loss_ctc 15.240788 loss_rnnt 11.076359 hw_loss 0.053203 lr 0.00036797 rank 2
2023-02-22 18:07:51,182 DEBUG TRAIN Batch 22/1100 loss 6.771251 loss_att 10.469477 loss_ctc 9.277246 loss_rnnt 5.670097 hw_loss 0.051329 lr 0.00036800 rank 3
2023-02-22 18:09:07,221 DEBUG TRAIN Batch 22/1200 loss 11.219804 loss_att 12.201165 loss_ctc 14.100493 loss_rnnt 10.614659 hw_loss 0.046464 lr 0.00036792 rank 7
2023-02-22 18:09:07,222 DEBUG TRAIN Batch 22/1200 loss 8.009988 loss_att 9.779943 loss_ctc 11.266300 loss_rnnt 7.178388 hw_loss 0.081439 lr 0.00036795 rank 0
2023-02-22 18:09:07,225 DEBUG TRAIN Batch 22/1200 loss 14.370420 loss_att 15.492905 loss_ctc 18.066633 loss_rnnt 13.600356 hw_loss 0.098884 lr 0.00036794 rank 5
2023-02-22 18:09:07,229 DEBUG TRAIN Batch 22/1200 loss 5.714471 loss_att 6.132887 loss_ctc 7.843320 loss_rnnt 5.277178 hw_loss 0.130803 lr 0.00036795 rank 4
2023-02-22 18:09:07,230 DEBUG TRAIN Batch 22/1200 loss 4.423409 loss_att 7.263564 loss_ctc 5.952310 loss_rnnt 3.592958 hw_loss 0.109810 lr 0.00036787 rank 2
2023-02-22 18:09:07,230 DEBUG TRAIN Batch 22/1200 loss 6.066490 loss_att 7.854630 loss_ctc 7.919747 loss_rnnt 5.451818 hw_loss 0.018643 lr 0.00036790 rank 3
2023-02-22 18:09:07,232 DEBUG TRAIN Batch 22/1200 loss 8.450170 loss_att 10.307435 loss_ctc 13.991114 loss_rnnt 7.304811 hw_loss 0.065836 lr 0.00036795 rank 6
2023-02-22 18:09:07,278 DEBUG TRAIN Batch 22/1200 loss 13.293454 loss_att 16.066315 loss_ctc 19.493357 loss_rnnt 11.819461 hw_loss 0.173938 lr 0.00036793 rank 1
2023-02-22 18:10:23,662 DEBUG TRAIN Batch 22/1300 loss 6.354751 loss_att 8.949592 loss_ctc 7.486389 loss_rnnt 5.661764 hw_loss 0.043377 lr 0.00036782 rank 7
2023-02-22 18:10:23,666 DEBUG TRAIN Batch 22/1300 loss 12.221212 loss_att 16.225437 loss_ctc 15.974318 loss_rnnt 10.858020 hw_loss 0.116124 lr 0.00036785 rank 4
2023-02-22 18:10:23,666 DEBUG TRAIN Batch 22/1300 loss 4.991606 loss_att 11.423540 loss_ctc 7.270007 loss_rnnt 3.337877 hw_loss 0.119165 lr 0.00036777 rank 2
2023-02-22 18:10:23,670 DEBUG TRAIN Batch 22/1300 loss 4.503661 loss_att 7.041361 loss_ctc 7.088331 loss_rnnt 3.638759 hw_loss 0.023885 lr 0.00036784 rank 5
2023-02-22 18:10:23,670 DEBUG TRAIN Batch 22/1300 loss 10.905403 loss_att 10.986571 loss_ctc 14.852647 loss_rnnt 10.267148 hw_loss 0.179479 lr 0.00036785 rank 0
2023-02-22 18:10:23,673 DEBUG TRAIN Batch 22/1300 loss 11.396327 loss_att 12.239409 loss_ctc 15.698839 loss_rnnt 10.524220 hw_loss 0.243416 lr 0.00036780 rank 3
2023-02-22 18:10:23,694 DEBUG TRAIN Batch 22/1300 loss 9.011909 loss_att 9.270443 loss_ctc 10.848307 loss_rnnt 8.644725 hw_loss 0.132419 lr 0.00036783 rank 1
2023-02-22 18:10:23,707 DEBUG TRAIN Batch 22/1300 loss 5.175177 loss_att 9.284543 loss_ctc 9.599971 loss_rnnt 3.744640 hw_loss 0.035046 lr 0.00036785 rank 6
2023-02-22 18:11:42,496 DEBUG TRAIN Batch 22/1400 loss 9.710981 loss_att 11.046740 loss_ctc 11.200557 loss_rnnt 9.221766 hw_loss 0.043977 lr 0.00036775 rank 4
2023-02-22 18:11:42,499 DEBUG TRAIN Batch 22/1400 loss 12.157492 loss_att 18.003300 loss_ctc 16.388380 loss_rnnt 10.379722 hw_loss 0.083420 lr 0.00036770 rank 3
2023-02-22 18:11:42,500 DEBUG TRAIN Batch 22/1400 loss 4.218660 loss_att 10.247902 loss_ctc 5.575952 loss_rnnt 2.776601 hw_loss 0.103574 lr 0.00036773 rank 1
2023-02-22 18:11:42,500 DEBUG TRAIN Batch 22/1400 loss 11.202836 loss_att 15.363026 loss_ctc 16.235685 loss_rnnt 9.670005 hw_loss 0.055776 lr 0.00036767 rank 2
2023-02-22 18:11:42,501 DEBUG TRAIN Batch 22/1400 loss 9.035275 loss_att 15.835488 loss_ctc 13.739711 loss_rnnt 7.038640 hw_loss 0.017502 lr 0.00036774 rank 5
2023-02-22 18:11:42,504 DEBUG TRAIN Batch 22/1400 loss 3.616315 loss_att 6.740298 loss_ctc 4.797811 loss_rnnt 2.817101 hw_loss 0.031658 lr 0.00036775 rank 0
2023-02-22 18:11:42,503 DEBUG TRAIN Batch 22/1400 loss 8.143775 loss_att 12.752533 loss_ctc 15.010794 loss_rnnt 6.259057 hw_loss 0.088805 lr 0.00036772 rank 7
2023-02-22 18:11:42,506 DEBUG TRAIN Batch 22/1400 loss 6.365039 loss_att 10.186172 loss_ctc 8.243700 loss_rnnt 5.214603 hw_loss 0.254478 lr 0.00036775 rank 6
2023-02-22 18:12:58,431 DEBUG TRAIN Batch 22/1500 loss 9.163189 loss_att 13.060592 loss_ctc 14.005720 loss_rnnt 7.640121 hw_loss 0.183591 lr 0.00036764 rank 5
2023-02-22 18:12:58,433 DEBUG TRAIN Batch 22/1500 loss 15.301706 loss_att 18.754234 loss_ctc 24.403677 loss_rnnt 13.363975 hw_loss 0.063057 lr 0.00036760 rank 3
2023-02-22 18:12:58,433 DEBUG TRAIN Batch 22/1500 loss 5.564998 loss_att 8.513577 loss_ctc 8.313995 loss_rnnt 4.557426 hw_loss 0.096231 lr 0.00036765 rank 0
2023-02-22 18:12:58,433 DEBUG TRAIN Batch 22/1500 loss 7.888435 loss_att 11.422108 loss_ctc 9.872541 loss_rnnt 6.895401 hw_loss 0.040784 lr 0.00036765 rank 4
2023-02-22 18:12:58,434 DEBUG TRAIN Batch 22/1500 loss 4.322334 loss_att 5.086715 loss_ctc 8.728945 loss_rnnt 3.542250 hw_loss 0.074360 lr 0.00036762 rank 7
2023-02-22 18:12:58,441 DEBUG TRAIN Batch 22/1500 loss 6.882855 loss_att 8.719666 loss_ctc 12.958674 loss_rnnt 5.686337 hw_loss 0.035713 lr 0.00036764 rank 1
2023-02-22 18:12:58,441 DEBUG TRAIN Batch 22/1500 loss 11.055644 loss_att 14.300636 loss_ctc 16.727396 loss_rnnt 9.647274 hw_loss 0.005881 lr 0.00036765 rank 6
2023-02-22 18:12:58,443 DEBUG TRAIN Batch 22/1500 loss 18.890182 loss_att 21.054785 loss_ctc 30.671833 loss_rnnt 16.858976 hw_loss 0.051373 lr 0.00036757 rank 2
2023-02-22 18:14:13,935 DEBUG TRAIN Batch 22/1600 loss 10.028413 loss_att 12.748621 loss_ctc 12.084935 loss_rnnt 9.159727 hw_loss 0.094576 lr 0.00036755 rank 4
2023-02-22 18:14:13,941 DEBUG TRAIN Batch 22/1600 loss 7.659900 loss_att 15.279432 loss_ctc 13.889324 loss_rnnt 5.241166 hw_loss 0.120445 lr 0.00036752 rank 7
2023-02-22 18:14:13,943 DEBUG TRAIN Batch 22/1600 loss 8.065292 loss_att 8.831161 loss_ctc 11.305365 loss_rnnt 7.453108 hw_loss 0.050625 lr 0.00036755 rank 0
2023-02-22 18:14:13,945 DEBUG TRAIN Batch 22/1600 loss 7.889036 loss_att 11.414635 loss_ctc 10.288225 loss_rnnt 6.790110 hw_loss 0.138590 lr 0.00036747 rank 2
2023-02-22 18:14:13,946 DEBUG TRAIN Batch 22/1600 loss 12.459024 loss_att 14.739698 loss_ctc 16.239094 loss_rnnt 11.442688 hw_loss 0.105361 lr 0.00036754 rank 5
2023-02-22 18:14:13,946 DEBUG TRAIN Batch 22/1600 loss 7.431091 loss_att 8.541008 loss_ctc 8.618641 loss_rnnt 6.989951 hw_loss 0.114031 lr 0.00036755 rank 6
2023-02-22 18:14:13,947 DEBUG TRAIN Batch 22/1600 loss 9.416975 loss_att 10.943452 loss_ctc 11.827188 loss_rnnt 8.735545 hw_loss 0.102698 lr 0.00036750 rank 3
2023-02-22 18:14:13,947 DEBUG TRAIN Batch 22/1600 loss 6.011839 loss_att 9.352143 loss_ctc 6.528673 loss_rnnt 5.244508 hw_loss 0.056925 lr 0.00036754 rank 1
2023-02-22 18:15:29,457 DEBUG TRAIN Batch 22/1700 loss 11.018621 loss_att 12.358667 loss_ctc 12.772931 loss_rnnt 10.424131 hw_loss 0.173575 lr 0.00036745 rank 4
2023-02-22 18:15:29,461 DEBUG TRAIN Batch 22/1700 loss 7.917869 loss_att 10.088728 loss_ctc 9.608964 loss_rnnt 7.215136 hw_loss 0.080777 lr 0.00036744 rank 5
2023-02-22 18:15:29,463 DEBUG TRAIN Batch 22/1700 loss 8.110636 loss_att 9.452759 loss_ctc 9.772469 loss_rnnt 7.570565 hw_loss 0.093877 lr 0.00036743 rank 7
2023-02-22 18:15:29,462 DEBUG TRAIN Batch 22/1700 loss 10.144143 loss_att 14.875599 loss_ctc 16.974428 loss_rnnt 8.276083 hw_loss 0.020745 lr 0.00036745 rank 0
2023-02-22 18:15:29,466 DEBUG TRAIN Batch 22/1700 loss 11.829698 loss_att 14.261460 loss_ctc 17.026583 loss_rnnt 10.554948 hw_loss 0.179022 lr 0.00036740 rank 3
2023-02-22 18:15:29,468 DEBUG TRAIN Batch 22/1700 loss 12.855352 loss_att 17.137531 loss_ctc 17.130566 loss_rnnt 11.377433 hw_loss 0.096478 lr 0.00036744 rank 1
2023-02-22 18:15:29,469 DEBUG TRAIN Batch 22/1700 loss 3.608650 loss_att 6.317018 loss_ctc 8.898829 loss_rnnt 2.304757 hw_loss 0.106617 lr 0.00036737 rank 2
2023-02-22 18:15:29,518 DEBUG TRAIN Batch 22/1700 loss 6.549277 loss_att 8.900230 loss_ctc 8.739962 loss_rnnt 5.746197 hw_loss 0.076496 lr 0.00036745 rank 6
2023-02-22 18:16:47,467 DEBUG TRAIN Batch 22/1800 loss 3.599145 loss_att 5.027575 loss_ctc 4.722266 loss_rnnt 3.137347 hw_loss 0.049430 lr 0.00036735 rank 0
2023-02-22 18:16:47,468 DEBUG TRAIN Batch 22/1800 loss 9.346277 loss_att 10.129045 loss_ctc 12.983652 loss_rnnt 8.604239 hw_loss 0.188439 lr 0.00036735 rank 4
2023-02-22 18:16:47,470 DEBUG TRAIN Batch 22/1800 loss 7.363601 loss_att 9.934324 loss_ctc 12.374340 loss_rnnt 6.155375 hw_loss 0.048719 lr 0.00036734 rank 1
2023-02-22 18:16:47,470 DEBUG TRAIN Batch 22/1800 loss 7.717320 loss_att 10.695719 loss_ctc 12.620043 loss_rnnt 6.419136 hw_loss 0.091517 lr 0.00036736 rank 6
2023-02-22 18:16:47,472 DEBUG TRAIN Batch 22/1800 loss 5.825628 loss_att 8.067705 loss_ctc 6.869744 loss_rnnt 5.205462 hw_loss 0.061004 lr 0.00036734 rank 5
2023-02-22 18:16:47,476 DEBUG TRAIN Batch 22/1800 loss 5.100377 loss_att 8.460603 loss_ctc 8.315353 loss_rnnt 3.947158 hw_loss 0.098458 lr 0.00036730 rank 3
2023-02-22 18:16:47,476 DEBUG TRAIN Batch 22/1800 loss 15.589948 loss_att 18.253864 loss_ctc 21.838606 loss_rnnt 14.162064 hw_loss 0.116147 lr 0.00036733 rank 7
2023-02-22 18:16:47,486 DEBUG TRAIN Batch 22/1800 loss 11.212900 loss_att 11.812496 loss_ctc 16.543844 loss_rnnt 10.356147 hw_loss 0.048827 lr 0.00036727 rank 2
2023-02-22 18:18:02,119 DEBUG TRAIN Batch 22/1900 loss 17.422428 loss_att 20.770540 loss_ctc 27.712622 loss_rnnt 15.332802 hw_loss 0.089960 lr 0.00036725 rank 4
2023-02-22 18:18:02,119 DEBUG TRAIN Batch 22/1900 loss 7.965533 loss_att 7.520287 loss_ctc 10.269368 loss_rnnt 7.616113 hw_loss 0.246169 lr 0.00036717 rank 2
2023-02-22 18:18:02,121 DEBUG TRAIN Batch 22/1900 loss 10.686472 loss_att 11.985680 loss_ctc 15.629269 loss_rnnt 9.707795 hw_loss 0.112115 lr 0.00036724 rank 5
2023-02-22 18:18:02,121 DEBUG TRAIN Batch 22/1900 loss 5.894283 loss_att 6.764467 loss_ctc 9.232845 loss_rnnt 5.191183 hw_loss 0.157352 lr 0.00036726 rank 6
2023-02-22 18:18:02,121 DEBUG TRAIN Batch 22/1900 loss 6.132162 loss_att 7.996608 loss_ctc 8.064186 loss_rnnt 5.447410 hw_loss 0.101737 lr 0.00036725 rank 0
2023-02-22 18:18:02,122 DEBUG TRAIN Batch 22/1900 loss 8.352770 loss_att 9.028977 loss_ctc 11.744944 loss_rnnt 7.711939 hw_loss 0.099937 lr 0.00036723 rank 7
2023-02-22 18:18:02,123 DEBUG TRAIN Batch 22/1900 loss 3.611746 loss_att 5.349455 loss_ctc 6.646865 loss_rnnt 2.833017 hw_loss 0.049697 lr 0.00036720 rank 3
2023-02-22 18:18:02,125 DEBUG TRAIN Batch 22/1900 loss 19.768303 loss_att 20.156765 loss_ctc 36.359161 loss_rnnt 17.403362 hw_loss 0.140873 lr 0.00036724 rank 1
2023-02-22 18:19:16,498 DEBUG TRAIN Batch 22/2000 loss 12.720722 loss_att 16.939152 loss_ctc 18.715397 loss_rnnt 11.053027 hw_loss 0.046349 lr 0.00036715 rank 0
2023-02-22 18:19:16,500 DEBUG TRAIN Batch 22/2000 loss 3.404026 loss_att 6.791271 loss_ctc 6.484846 loss_rnnt 2.298242 hw_loss 0.032922 lr 0.00036715 rank 4
2023-02-22 18:19:16,500 DEBUG TRAIN Batch 22/2000 loss 6.682363 loss_att 9.672715 loss_ctc 10.028777 loss_rnnt 5.570601 hw_loss 0.126566 lr 0.00036714 rank 5
2023-02-22 18:19:16,503 DEBUG TRAIN Batch 22/2000 loss 6.563483 loss_att 10.615658 loss_ctc 12.500030 loss_rnnt 4.927498 hw_loss 0.063771 lr 0.00036713 rank 7
2023-02-22 18:19:16,504 DEBUG TRAIN Batch 22/2000 loss 3.870904 loss_att 6.806674 loss_ctc 5.953626 loss_rnnt 2.957869 hw_loss 0.090346 lr 0.00036707 rank 2
2023-02-22 18:19:16,505 DEBUG TRAIN Batch 22/2000 loss 2.058398 loss_att 6.127880 loss_ctc 2.371772 loss_rnnt 1.166609 hw_loss 0.067705 lr 0.00036716 rank 6
2023-02-22 18:19:16,509 DEBUG TRAIN Batch 22/2000 loss 11.917736 loss_att 15.163717 loss_ctc 14.180968 loss_rnnt 10.953528 hw_loss 0.024838 lr 0.00036710 rank 3
2023-02-22 18:19:16,546 DEBUG TRAIN Batch 22/2000 loss 11.887362 loss_att 13.977859 loss_ctc 17.658840 loss_rnnt 10.631393 hw_loss 0.128133 lr 0.00036714 rank 1
2023-02-22 18:20:34,018 DEBUG TRAIN Batch 22/2100 loss 15.482471 loss_att 18.964409 loss_ctc 21.521465 loss_rnnt 13.905794 hw_loss 0.140792 lr 0.00036705 rank 0
2023-02-22 18:20:34,020 DEBUG TRAIN Batch 22/2100 loss 4.736729 loss_att 6.474074 loss_ctc 5.881937 loss_rnnt 4.175724 hw_loss 0.114077 lr 0.00036703 rank 7
2023-02-22 18:20:34,021 DEBUG TRAIN Batch 22/2100 loss 8.292701 loss_att 11.628498 loss_ctc 9.000786 loss_rnnt 7.424081 hw_loss 0.200714 lr 0.00036704 rank 5
2023-02-22 18:20:34,023 DEBUG TRAIN Batch 22/2100 loss 5.637142 loss_att 10.193073 loss_ctc 8.390810 loss_rnnt 4.356771 hw_loss 0.003804 lr 0.00036706 rank 6
2023-02-22 18:20:34,027 DEBUG TRAIN Batch 22/2100 loss 4.861980 loss_att 7.611336 loss_ctc 6.707016 loss_rnnt 4.009514 hw_loss 0.106107 lr 0.00036705 rank 4
2023-02-22 18:20:34,028 DEBUG TRAIN Batch 22/2100 loss 15.463536 loss_att 18.489649 loss_ctc 21.297409 loss_rnnt 14.074207 hw_loss 0.011733 lr 0.00036697 rank 2
2023-02-22 18:20:34,030 DEBUG TRAIN Batch 22/2100 loss 8.775890 loss_att 11.531698 loss_ctc 13.593306 loss_rnnt 7.541099 hw_loss 0.077451 lr 0.00036700 rank 3
2023-02-22 18:20:34,074 DEBUG TRAIN Batch 22/2100 loss 9.885814 loss_att 12.664823 loss_ctc 11.004248 loss_rnnt 9.134143 hw_loss 0.087648 lr 0.00036704 rank 1
2023-02-22 18:21:50,049 DEBUG TRAIN Batch 22/2200 loss 5.483926 loss_att 8.968741 loss_ctc 8.739555 loss_rnnt 4.283649 hw_loss 0.129804 lr 0.00036696 rank 6
2023-02-22 18:21:50,051 DEBUG TRAIN Batch 22/2200 loss 14.093300 loss_att 17.816936 loss_ctc 21.637032 loss_rnnt 12.282066 hw_loss 0.113767 lr 0.00036693 rank 7
2023-02-22 18:21:50,052 DEBUG TRAIN Batch 22/2200 loss 8.475067 loss_att 12.924434 loss_ctc 10.826908 loss_rnnt 7.208019 hw_loss 0.119244 lr 0.00036695 rank 4
2023-02-22 18:21:50,053 DEBUG TRAIN Batch 22/2200 loss 8.530284 loss_att 11.625949 loss_ctc 11.223936 loss_rnnt 7.532647 hw_loss 0.036279 lr 0.00036694 rank 5
2023-02-22 18:21:50,053 DEBUG TRAIN Batch 22/2200 loss 10.256626 loss_att 12.163193 loss_ctc 12.391497 loss_rnnt 9.576967 hw_loss 0.025680 lr 0.00036695 rank 0
2023-02-22 18:21:50,054 DEBUG TRAIN Batch 22/2200 loss 9.397955 loss_att 16.027758 loss_ctc 14.306789 loss_rnnt 7.372354 hw_loss 0.084617 lr 0.00036688 rank 2
2023-02-22 18:21:50,055 DEBUG TRAIN Batch 22/2200 loss 8.262285 loss_att 14.154680 loss_ctc 11.547293 loss_rnnt 6.601887 hw_loss 0.082348 lr 0.00036690 rank 3
2023-02-22 18:21:50,058 DEBUG TRAIN Batch 22/2200 loss 13.761103 loss_att 15.585050 loss_ctc 20.587420 loss_rnnt 12.464228 hw_loss 0.041080 lr 0.00036694 rank 1
2023-02-22 18:23:04,817 DEBUG TRAIN Batch 22/2300 loss 21.870686 loss_att 22.225233 loss_ctc 30.456301 loss_rnnt 20.599091 hw_loss 0.104887 lr 0.00036683 rank 7
2023-02-22 18:23:04,819 DEBUG TRAIN Batch 22/2300 loss 3.601306 loss_att 5.284048 loss_ctc 4.575851 loss_rnnt 3.115698 hw_loss 0.035849 lr 0.00036685 rank 4
2023-02-22 18:23:04,822 DEBUG TRAIN Batch 22/2300 loss 8.737490 loss_att 12.769792 loss_ctc 10.681692 loss_rnnt 7.658275 hw_loss 0.025364 lr 0.00036685 rank 5
2023-02-22 18:23:04,822 DEBUG TRAIN Batch 22/2300 loss 5.301215 loss_att 7.939587 loss_ctc 9.070663 loss_rnnt 4.260810 hw_loss 0.019009 lr 0.00036678 rank 2
2023-02-22 18:23:04,824 DEBUG TRAIN Batch 22/2300 loss 5.433005 loss_att 9.353192 loss_ctc 8.986403 loss_rnnt 4.145364 hw_loss 0.055907 lr 0.00036686 rank 6
2023-02-22 18:23:04,824 DEBUG TRAIN Batch 22/2300 loss 12.795492 loss_att 16.254862 loss_ctc 18.012363 loss_rnnt 11.379228 hw_loss 0.054013 lr 0.00036684 rank 1
2023-02-22 18:23:04,825 DEBUG TRAIN Batch 22/2300 loss 13.745708 loss_att 16.455080 loss_ctc 19.506401 loss_rnnt 12.418387 hw_loss 0.032540 lr 0.00036686 rank 0
2023-02-22 18:23:04,827 DEBUG TRAIN Batch 22/2300 loss 9.607496 loss_att 12.433294 loss_ctc 13.077021 loss_rnnt 8.497931 hw_loss 0.153379 lr 0.00036681 rank 3
2023-02-22 18:24:19,932 DEBUG TRAIN Batch 22/2400 loss 13.036190 loss_att 14.240730 loss_ctc 18.266703 loss_rnnt 11.973094 hw_loss 0.233974 lr 0.00036675 rank 5
2023-02-22 18:24:19,936 DEBUG TRAIN Batch 22/2400 loss 6.655128 loss_att 8.728151 loss_ctc 10.563080 loss_rnnt 5.658651 hw_loss 0.114025 lr 0.00036676 rank 4
2023-02-22 18:24:19,937 DEBUG TRAIN Batch 22/2400 loss 6.174067 loss_att 8.901038 loss_ctc 8.390912 loss_rnnt 5.332592 hw_loss 0.000942 lr 0.00036676 rank 6
2023-02-22 18:24:19,937 DEBUG TRAIN Batch 22/2400 loss 27.408522 loss_att 30.758369 loss_ctc 38.472218 loss_rnnt 25.205536 hw_loss 0.108479 lr 0.00036673 rank 7
2023-02-22 18:24:19,937 DEBUG TRAIN Batch 22/2400 loss 6.460462 loss_att 10.312904 loss_ctc 11.692741 loss_rnnt 4.951621 hw_loss 0.076341 lr 0.00036671 rank 3
2023-02-22 18:24:19,939 DEBUG TRAIN Batch 22/2400 loss 6.522731 loss_att 10.050684 loss_ctc 9.399215 loss_rnnt 5.392927 hw_loss 0.076281 lr 0.00036676 rank 0
2023-02-22 18:24:19,940 DEBUG TRAIN Batch 22/2400 loss 6.370749 loss_att 9.941658 loss_ctc 13.327085 loss_rnnt 4.675810 hw_loss 0.099836 lr 0.00036674 rank 1
2023-02-22 18:24:19,944 DEBUG TRAIN Batch 22/2400 loss 8.502633 loss_att 11.400890 loss_ctc 14.959905 loss_rnnt 7.002870 hw_loss 0.110891 lr 0.00036668 rank 2
2023-02-22 18:25:38,628 DEBUG TRAIN Batch 22/2500 loss 4.318078 loss_att 6.142891 loss_ctc 5.391313 loss_rnnt 3.729549 hw_loss 0.150879 lr 0.00036663 rank 7
2023-02-22 18:25:38,630 DEBUG TRAIN Batch 22/2500 loss 6.625473 loss_att 9.477249 loss_ctc 10.391944 loss_rnnt 5.488306 hw_loss 0.121155 lr 0.00036665 rank 5
2023-02-22 18:25:38,631 DEBUG TRAIN Batch 22/2500 loss 9.256980 loss_att 13.400179 loss_ctc 18.237743 loss_rnnt 7.179754 hw_loss 0.095908 lr 0.00036666 rank 4
2023-02-22 18:25:38,634 DEBUG TRAIN Batch 22/2500 loss 6.204376 loss_att 7.685438 loss_ctc 7.435614 loss_rnnt 5.712457 hw_loss 0.059140 lr 0.00036666 rank 6
2023-02-22 18:25:38,634 DEBUG TRAIN Batch 22/2500 loss 8.644996 loss_att 13.388805 loss_ctc 14.955896 loss_rnnt 6.785031 hw_loss 0.130779 lr 0.00036666 rank 0
2023-02-22 18:25:38,635 DEBUG TRAIN Batch 22/2500 loss 4.091782 loss_att 5.686734 loss_ctc 5.882171 loss_rnnt 3.467043 hw_loss 0.125680 lr 0.00036665 rank 1
2023-02-22 18:25:38,637 DEBUG TRAIN Batch 22/2500 loss 14.956614 loss_att 16.490627 loss_ctc 20.694632 loss_rnnt 13.856482 hw_loss 0.052988 lr 0.00036661 rank 3
2023-02-22 18:25:38,686 DEBUG TRAIN Batch 22/2500 loss 9.817902 loss_att 12.251861 loss_ctc 13.281007 loss_rnnt 8.810745 hw_loss 0.109906 lr 0.00036658 rank 2
2023-02-22 18:26:53,382 DEBUG TRAIN Batch 22/2600 loss 4.913040 loss_att 8.526134 loss_ctc 5.036334 loss_rnnt 4.146320 hw_loss 0.051866 lr 0.00036655 rank 1
2023-02-22 18:26:53,384 DEBUG TRAIN Batch 22/2600 loss 8.547770 loss_att 13.270833 loss_ctc 13.134273 loss_rnnt 6.974338 hw_loss 0.032409 lr 0.00036656 rank 4
2023-02-22 18:26:53,386 DEBUG TRAIN Batch 22/2600 loss 7.537121 loss_att 8.285553 loss_ctc 11.166667 loss_rnnt 6.857883 hw_loss 0.085523 lr 0.00036656 rank 0
2023-02-22 18:26:53,386 DEBUG TRAIN Batch 22/2600 loss 5.637209 loss_att 9.551229 loss_ctc 12.593487 loss_rnnt 3.850453 hw_loss 0.143339 lr 0.00036654 rank 7
2023-02-22 18:26:53,387 DEBUG TRAIN Batch 22/2600 loss 17.364531 loss_att 20.528522 loss_ctc 28.792692 loss_rnnt 15.145241 hw_loss 0.117629 lr 0.00036655 rank 5
2023-02-22 18:26:53,388 DEBUG TRAIN Batch 22/2600 loss 9.549625 loss_att 9.757282 loss_ctc 13.902522 loss_rnnt 8.888742 hw_loss 0.073058 lr 0.00036651 rank 3
2023-02-22 18:26:53,389 DEBUG TRAIN Batch 22/2600 loss 12.128533 loss_att 15.380091 loss_ctc 18.252365 loss_rnnt 10.578935 hw_loss 0.155205 lr 0.00036648 rank 2
2023-02-22 18:26:53,392 DEBUG TRAIN Batch 22/2600 loss 8.956413 loss_att 10.073179 loss_ctc 13.819808 loss_rnnt 8.024673 hw_loss 0.112378 lr 0.00036656 rank 6
2023-02-22 18:28:09,612 DEBUG TRAIN Batch 22/2700 loss 6.155780 loss_att 10.624239 loss_ctc 8.838856 loss_rnnt 4.868732 hw_loss 0.066775 lr 0.00036646 rank 0
2023-02-22 18:28:09,614 DEBUG TRAIN Batch 22/2700 loss 7.448891 loss_att 9.989038 loss_ctc 13.001455 loss_rnnt 6.187972 hw_loss 0.023527 lr 0.00036644 rank 7
2023-02-22 18:28:09,614 DEBUG TRAIN Batch 22/2700 loss 6.388638 loss_att 8.579782 loss_ctc 10.539642 loss_rnnt 5.362765 hw_loss 0.064082 lr 0.00036646 rank 4
2023-02-22 18:28:09,615 DEBUG TRAIN Batch 22/2700 loss 1.615013 loss_att 3.958420 loss_ctc 3.906309 loss_rnnt 0.806515 hw_loss 0.064333 lr 0.00036645 rank 5
2023-02-22 18:28:09,617 DEBUG TRAIN Batch 22/2700 loss 1.653015 loss_att 5.058494 loss_ctc 2.253900 loss_rnnt 0.866001 hw_loss 0.048375 lr 0.00036647 rank 6
2023-02-22 18:28:09,617 DEBUG TRAIN Batch 22/2700 loss 10.623652 loss_att 12.627602 loss_ctc 14.462013 loss_rnnt 9.661329 hw_loss 0.093287 lr 0.00036645 rank 1
2023-02-22 18:28:09,618 DEBUG TRAIN Batch 22/2700 loss 4.151883 loss_att 7.766880 loss_ctc 5.502930 loss_rnnt 3.218570 hw_loss 0.056577 lr 0.00036638 rank 2
2023-02-22 18:28:09,664 DEBUG TRAIN Batch 22/2700 loss 4.438221 loss_att 8.347782 loss_ctc 9.939444 loss_rnnt 2.889854 hw_loss 0.061799 lr 0.00036641 rank 3
2023-02-22 18:29:26,649 DEBUG TRAIN Batch 22/2800 loss 3.109520 loss_att 5.231684 loss_ctc 5.123138 loss_rnnt 2.363241 hw_loss 0.100058 lr 0.00036635 rank 5
2023-02-22 18:29:26,650 DEBUG TRAIN Batch 22/2800 loss 5.438373 loss_att 9.025344 loss_ctc 6.465574 loss_rnnt 4.583887 hw_loss 0.000246 lr 0.00036636 rank 0
2023-02-22 18:29:26,652 DEBUG TRAIN Batch 22/2800 loss 6.930612 loss_att 10.490333 loss_ctc 9.525923 loss_rnnt 5.844088 hw_loss 0.053510 lr 0.00036634 rank 7
2023-02-22 18:29:26,652 DEBUG TRAIN Batch 22/2800 loss 13.816518 loss_att 15.485157 loss_ctc 23.146873 loss_rnnt 12.225186 hw_loss 0.025416 lr 0.00036628 rank 2
2023-02-22 18:29:26,652 DEBUG TRAIN Batch 22/2800 loss 13.051939 loss_att 16.414415 loss_ctc 14.452085 loss_rnnt 12.164335 hw_loss 0.053291 lr 0.00036636 rank 4
2023-02-22 18:29:26,656 DEBUG TRAIN Batch 22/2800 loss 10.771214 loss_att 13.870358 loss_ctc 14.274067 loss_rnnt 9.634636 hw_loss 0.093192 lr 0.00036635 rank 1
2023-02-22 18:29:26,661 DEBUG TRAIN Batch 22/2800 loss 20.362648 loss_att 21.580755 loss_ctc 24.517166 loss_rnnt 19.543705 hw_loss 0.040095 lr 0.00036637 rank 6
2023-02-22 18:29:26,695 DEBUG TRAIN Batch 22/2800 loss 8.052498 loss_att 10.454073 loss_ctc 11.060366 loss_rnnt 7.145948 hw_loss 0.047222 lr 0.00036631 rank 3
2023-02-22 18:30:43,423 DEBUG TRAIN Batch 22/2900 loss 7.110891 loss_att 8.929286 loss_ctc 12.745369 loss_rnnt 5.918244 hw_loss 0.145694 lr 0.00036626 rank 4
2023-02-22 18:30:43,427 DEBUG TRAIN Batch 22/2900 loss 5.295905 loss_att 7.770472 loss_ctc 5.995242 loss_rnnt 4.685299 hw_loss 0.042089 lr 0.00036624 rank 7
2023-02-22 18:30:43,428 DEBUG TRAIN Batch 22/2900 loss 7.490082 loss_att 12.377989 loss_ctc 13.684540 loss_rnnt 5.648231 hw_loss 0.071893 lr 0.00036625 rank 5
2023-02-22 18:30:43,431 DEBUG TRAIN Batch 22/2900 loss 16.313713 loss_att 19.640438 loss_ctc 24.198214 loss_rnnt 14.536108 hw_loss 0.114363 lr 0.00036626 rank 0
2023-02-22 18:30:43,433 DEBUG TRAIN Batch 22/2900 loss 8.145552 loss_att 10.408843 loss_ctc 12.943948 loss_rnnt 7.024022 hw_loss 0.054533 lr 0.00036625 rank 1
2023-02-22 18:30:43,433 DEBUG TRAIN Batch 22/2900 loss 6.720084 loss_att 9.690841 loss_ctc 12.646740 loss_rnnt 5.306621 hw_loss 0.054546 lr 0.00036627 rank 6
2023-02-22 18:30:43,436 DEBUG TRAIN Batch 22/2900 loss 13.302026 loss_att 14.246853 loss_ctc 21.089523 loss_rnnt 12.035734 hw_loss 0.073113 lr 0.00036621 rank 3
2023-02-22 18:30:43,439 DEBUG TRAIN Batch 22/2900 loss 2.127107 loss_att 4.294597 loss_ctc 2.478009 loss_rnnt 1.623381 hw_loss 0.043953 lr 0.00036619 rank 2
2023-02-22 18:31:57,978 DEBUG TRAIN Batch 22/3000 loss 10.657753 loss_att 12.527176 loss_ctc 14.572661 loss_rnnt 9.716659 hw_loss 0.084791 lr 0.00036616 rank 5
2023-02-22 18:31:57,982 DEBUG TRAIN Batch 22/3000 loss 6.183577 loss_att 10.772938 loss_ctc 10.249060 loss_rnnt 4.669940 hw_loss 0.100687 lr 0.00036617 rank 0
2023-02-22 18:31:57,984 DEBUG TRAIN Batch 22/3000 loss 7.754455 loss_att 10.532503 loss_ctc 10.954191 loss_rnnt 6.722947 hw_loss 0.092375 lr 0.00036609 rank 2
2023-02-22 18:31:57,988 DEBUG TRAIN Batch 22/3000 loss 13.487144 loss_att 15.040888 loss_ctc 18.560102 loss_rnnt 12.419101 hw_loss 0.151687 lr 0.00036617 rank 4
2023-02-22 18:31:57,991 DEBUG TRAIN Batch 22/3000 loss 5.565096 loss_att 8.119591 loss_ctc 9.295419 loss_rnnt 4.488740 hw_loss 0.127649 lr 0.00036614 rank 7
2023-02-22 18:31:57,991 DEBUG TRAIN Batch 22/3000 loss 10.591118 loss_att 16.269791 loss_ctc 15.189812 loss_rnnt 8.789970 hw_loss 0.097975 lr 0.00036617 rank 6
2023-02-22 18:31:57,992 DEBUG TRAIN Batch 22/3000 loss 9.151384 loss_att 10.647500 loss_ctc 14.835330 loss_rnnt 8.071572 hw_loss 0.042616 lr 0.00036612 rank 3
2023-02-22 18:31:57,992 DEBUG TRAIN Batch 22/3000 loss 13.755860 loss_att 14.816385 loss_ctc 18.248486 loss_rnnt 12.853467 hw_loss 0.171135 lr 0.00036615 rank 1
2023-02-22 18:33:14,984 DEBUG TRAIN Batch 22/3100 loss 9.113462 loss_att 12.140611 loss_ctc 11.367979 loss_rnnt 8.182560 hw_loss 0.046632 lr 0.00036607 rank 0
2023-02-22 18:33:14,987 DEBUG TRAIN Batch 22/3100 loss 14.266240 loss_att 17.373632 loss_ctc 19.510843 loss_rnnt 12.873262 hw_loss 0.135411 lr 0.00036604 rank 7
2023-02-22 18:33:14,988 DEBUG TRAIN Batch 22/3100 loss 14.908595 loss_att 15.763422 loss_ctc 20.736895 loss_rnnt 13.922640 hw_loss 0.071030 lr 0.00036606 rank 5
2023-02-22 18:33:14,991 DEBUG TRAIN Batch 22/3100 loss 8.499058 loss_att 15.513872 loss_ctc 10.506016 loss_rnnt 6.820333 hw_loss 0.015313 lr 0.00036607 rank 4
2023-02-22 18:33:14,992 DEBUG TRAIN Batch 22/3100 loss 4.889266 loss_att 6.293050 loss_ctc 7.680580 loss_rnnt 4.219729 hw_loss 0.031133 lr 0.00036602 rank 3
2023-02-22 18:33:14,993 DEBUG TRAIN Batch 22/3100 loss 5.767718 loss_att 7.263975 loss_ctc 9.253500 loss_rnnt 4.958862 hw_loss 0.084064 lr 0.00036607 rank 6
2023-02-22 18:33:14,997 DEBUG TRAIN Batch 22/3100 loss 9.169653 loss_att 12.262257 loss_ctc 12.882735 loss_rnnt 8.002113 hw_loss 0.101139 lr 0.00036606 rank 1
2023-02-22 18:33:14,998 DEBUG TRAIN Batch 22/3100 loss 2.429618 loss_att 5.421418 loss_ctc 4.101095 loss_rnnt 1.574375 hw_loss 0.063785 lr 0.00036599 rank 2
2023-02-22 18:34:33,504 DEBUG TRAIN Batch 22/3200 loss 7.653338 loss_att 9.640234 loss_ctc 10.082173 loss_rnnt 6.882602 hw_loss 0.092836 lr 0.00036595 rank 7
2023-02-22 18:34:33,506 DEBUG TRAIN Batch 22/3200 loss 11.071174 loss_att 10.366526 loss_ctc 14.123848 loss_rnnt 10.652188 hw_loss 0.286670 lr 0.00036596 rank 5
2023-02-22 18:34:33,508 DEBUG TRAIN Batch 22/3200 loss 8.560182 loss_att 10.994714 loss_ctc 13.690696 loss_rnnt 7.346434 hw_loss 0.080199 lr 0.00036596 rank 1
2023-02-22 18:34:33,511 DEBUG TRAIN Batch 22/3200 loss 7.826025 loss_att 8.762899 loss_ctc 9.116875 loss_rnnt 7.418070 hw_loss 0.090877 lr 0.00036597 rank 0
2023-02-22 18:34:33,511 DEBUG TRAIN Batch 22/3200 loss 10.164221 loss_att 13.746120 loss_ctc 15.760412 loss_rnnt 8.668996 hw_loss 0.061285 lr 0.00036597 rank 4
2023-02-22 18:34:33,512 DEBUG TRAIN Batch 22/3200 loss 4.762125 loss_att 7.757022 loss_ctc 6.725783 loss_rnnt 3.839133 hw_loss 0.116609 lr 0.00036597 rank 6
2023-02-22 18:34:33,513 DEBUG TRAIN Batch 22/3200 loss 9.226111 loss_att 9.128625 loss_ctc 11.589496 loss_rnnt 8.911597 hw_loss 0.035425 lr 0.00036592 rank 3
2023-02-22 18:34:33,560 DEBUG TRAIN Batch 22/3200 loss 19.122004 loss_att 23.999355 loss_ctc 35.484169 loss_rnnt 15.912106 hw_loss 0.099010 lr 0.00036589 rank 2
2023-02-22 18:35:48,419 DEBUG TRAIN Batch 22/3300 loss 10.806351 loss_att 12.886086 loss_ctc 14.105709 loss_rnnt 9.936457 hw_loss 0.026313 lr 0.00036587 rank 0
2023-02-22 18:35:48,420 DEBUG TRAIN Batch 22/3300 loss 7.380773 loss_att 9.139555 loss_ctc 11.660246 loss_rnnt 6.405171 hw_loss 0.099840 lr 0.00036585 rank 7
2023-02-22 18:35:48,420 DEBUG TRAIN Batch 22/3300 loss 10.379439 loss_att 11.646429 loss_ctc 14.896559 loss_rnnt 9.454752 hw_loss 0.129388 lr 0.00036586 rank 1
2023-02-22 18:35:48,422 DEBUG TRAIN Batch 22/3300 loss 9.361407 loss_att 14.953785 loss_ctc 14.548836 loss_rnnt 7.481843 hw_loss 0.130185 lr 0.00036587 rank 4
2023-02-22 18:35:48,423 DEBUG TRAIN Batch 22/3300 loss 8.458592 loss_att 10.069872 loss_ctc 9.523890 loss_rnnt 7.984022 hw_loss 0.019267 lr 0.00036586 rank 5
2023-02-22 18:35:48,426 DEBUG TRAIN Batch 22/3300 loss 6.024934 loss_att 8.454709 loss_ctc 9.735867 loss_rnnt 5.022100 hw_loss 0.041413 lr 0.00036588 rank 6
2023-02-22 18:35:48,432 DEBUG TRAIN Batch 22/3300 loss 6.761220 loss_att 10.613459 loss_ctc 8.292555 loss_rnnt 5.711469 hw_loss 0.140862 lr 0.00036579 rank 2
2023-02-22 18:35:48,473 DEBUG TRAIN Batch 22/3300 loss 7.777522 loss_att 9.169927 loss_ctc 11.305125 loss_rnnt 7.018669 hw_loss 0.018795 lr 0.00036582 rank 3
2023-02-22 18:37:04,117 DEBUG TRAIN Batch 22/3400 loss 12.725775 loss_att 15.020824 loss_ctc 19.093603 loss_rnnt 11.367556 hw_loss 0.094062 lr 0.00036577 rank 4
2023-02-22 18:37:04,120 DEBUG TRAIN Batch 22/3400 loss 5.529696 loss_att 6.615952 loss_ctc 6.074021 loss_rnnt 5.177332 hw_loss 0.117254 lr 0.00036577 rank 0
2023-02-22 18:37:04,121 DEBUG TRAIN Batch 22/3400 loss 11.294573 loss_att 12.616701 loss_ctc 15.462715 loss_rnnt 10.434786 hw_loss 0.074266 lr 0.00036575 rank 7
2023-02-22 18:37:04,122 DEBUG TRAIN Batch 22/3400 loss 14.028857 loss_att 16.563522 loss_ctc 21.076824 loss_rnnt 12.555449 hw_loss 0.050148 lr 0.00036576 rank 5
2023-02-22 18:37:04,124 DEBUG TRAIN Batch 22/3400 loss 3.346537 loss_att 6.898985 loss_ctc 4.465563 loss_rnnt 2.386833 hw_loss 0.187522 lr 0.00036570 rank 2
2023-02-22 18:37:04,125 DEBUG TRAIN Batch 22/3400 loss 9.241928 loss_att 11.254827 loss_ctc 12.345290 loss_rnnt 8.380454 hw_loss 0.084585 lr 0.00036578 rank 6
2023-02-22 18:37:04,125 DEBUG TRAIN Batch 22/3400 loss 4.245847 loss_att 5.236730 loss_ctc 6.547363 loss_rnnt 3.684355 hw_loss 0.105837 lr 0.00036572 rank 3
2023-02-22 18:37:04,171 DEBUG TRAIN Batch 22/3400 loss 3.042314 loss_att 5.660675 loss_ctc 4.041354 loss_rnnt 2.320154 hw_loss 0.122406 lr 0.00036576 rank 1
2023-02-22 18:38:20,950 DEBUG TRAIN Batch 22/3500 loss 8.073033 loss_att 11.247036 loss_ctc 9.552168 loss_rnnt 7.176027 hw_loss 0.121850 lr 0.00036563 rank 3
2023-02-22 18:38:20,952 DEBUG TRAIN Batch 22/3500 loss 7.423100 loss_att 12.756286 loss_ctc 12.981446 loss_rnnt 5.588968 hw_loss 0.049467 lr 0.00036568 rank 0
2023-02-22 18:38:20,952 DEBUG TRAIN Batch 22/3500 loss 12.165546 loss_att 15.802735 loss_ctc 14.876184 loss_rnnt 11.061565 hw_loss 0.028357 lr 0.00036567 rank 5
2023-02-22 18:38:20,953 DEBUG TRAIN Batch 22/3500 loss 13.652012 loss_att 14.443130 loss_ctc 15.584365 loss_rnnt 13.220442 hw_loss 0.029438 lr 0.00036565 rank 7
2023-02-22 18:38:20,955 DEBUG TRAIN Batch 22/3500 loss 10.018111 loss_att 12.449946 loss_ctc 15.567390 loss_rnnt 8.774029 hw_loss 0.033397 lr 0.00036568 rank 6
2023-02-22 18:38:20,954 DEBUG TRAIN Batch 22/3500 loss 10.275634 loss_att 13.455078 loss_ctc 15.229925 loss_rnnt 8.913735 hw_loss 0.122696 lr 0.00036568 rank 4
2023-02-22 18:38:20,984 DEBUG TRAIN Batch 22/3500 loss 13.524671 loss_att 14.374637 loss_ctc 21.548489 loss_rnnt 12.223091 hw_loss 0.115768 lr 0.00036560 rank 2
2023-02-22 18:38:20,987 DEBUG TRAIN Batch 22/3500 loss 11.045862 loss_att 15.733847 loss_ctc 17.856153 loss_rnnt 9.090121 hw_loss 0.206449 lr 0.00036566 rank 1
2023-02-22 18:39:37,865 DEBUG TRAIN Batch 22/3600 loss 12.418471 loss_att 16.026943 loss_ctc 18.565174 loss_rnnt 10.857841 hw_loss 0.036328 lr 0.00036557 rank 1
2023-02-22 18:39:37,866 DEBUG TRAIN Batch 22/3600 loss 3.606753 loss_att 6.077386 loss_ctc 6.725868 loss_rnnt 2.667019 hw_loss 0.055735 lr 0.00036558 rank 4
2023-02-22 18:39:37,866 DEBUG TRAIN Batch 22/3600 loss 7.151189 loss_att 10.928673 loss_ctc 11.524549 loss_rnnt 5.797319 hw_loss 0.028610 lr 0.00036558 rank 0
2023-02-22 18:39:37,866 DEBUG TRAIN Batch 22/3600 loss 2.287582 loss_att 4.012131 loss_ctc 3.722964 loss_rnnt 1.732296 hw_loss 0.035610 lr 0.00036556 rank 7
2023-02-22 18:39:37,868 DEBUG TRAIN Batch 22/3600 loss 12.948477 loss_att 15.790436 loss_ctc 22.213242 loss_rnnt 11.049374 hw_loss 0.178893 lr 0.00036558 rank 6
2023-02-22 18:39:37,869 DEBUG TRAIN Batch 22/3600 loss 3.991414 loss_att 7.314714 loss_ctc 5.955651 loss_rnnt 2.997220 hw_loss 0.126817 lr 0.00036557 rank 5
2023-02-22 18:39:37,869 DEBUG TRAIN Batch 22/3600 loss 4.879680 loss_att 6.552119 loss_ctc 6.103842 loss_rnnt 4.354171 hw_loss 0.052123 lr 0.00036550 rank 2
2023-02-22 18:39:37,869 DEBUG TRAIN Batch 22/3600 loss 8.015273 loss_att 9.631129 loss_ctc 8.871601 loss_rnnt 7.544769 hw_loss 0.062166 lr 0.00036553 rank 3
2023-02-22 18:40:53,070 DEBUG TRAIN Batch 22/3700 loss 9.100348 loss_att 9.922464 loss_ctc 11.950526 loss_rnnt 8.465086 hw_loss 0.170279 lr 0.00036548 rank 4
2023-02-22 18:40:53,074 DEBUG TRAIN Batch 22/3700 loss 13.161329 loss_att 15.269371 loss_ctc 16.498838 loss_rnnt 12.213836 hw_loss 0.151658 lr 0.00036549 rank 6
2023-02-22 18:40:53,075 DEBUG TRAIN Batch 22/3700 loss 7.400672 loss_att 9.478108 loss_ctc 11.392230 loss_rnnt 6.337635 hw_loss 0.216268 lr 0.00036540 rank 2
2023-02-22 18:40:53,076 DEBUG TRAIN Batch 22/3700 loss 12.503243 loss_att 14.394192 loss_ctc 19.172085 loss_rnnt 11.175657 hw_loss 0.112909 lr 0.00036546 rank 7
2023-02-22 18:40:53,078 DEBUG TRAIN Batch 22/3700 loss 15.336451 loss_att 17.463303 loss_ctc 18.002224 loss_rnnt 14.527765 hw_loss 0.052272 lr 0.00036547 rank 5
2023-02-22 18:40:53,080 DEBUG TRAIN Batch 22/3700 loss 4.200633 loss_att 8.336404 loss_ctc 6.936703 loss_rnnt 2.979335 hw_loss 0.055002 lr 0.00036543 rank 3
2023-02-22 18:40:53,080 DEBUG TRAIN Batch 22/3700 loss 5.901390 loss_att 9.102797 loss_ctc 11.601008 loss_rnnt 4.455776 hw_loss 0.085094 lr 0.00036547 rank 1
2023-02-22 18:40:53,082 DEBUG TRAIN Batch 22/3700 loss 12.531468 loss_att 18.480650 loss_ctc 21.008205 loss_rnnt 10.186245 hw_loss 0.047166 lr 0.00036548 rank 0
2023-02-22 18:42:09,045 DEBUG TRAIN Batch 22/3800 loss 6.723259 loss_att 8.887781 loss_ctc 8.607196 loss_rnnt 5.984033 hw_loss 0.103368 lr 0.00036538 rank 0
2023-02-22 18:42:09,047 DEBUG TRAIN Batch 22/3800 loss 12.128710 loss_att 14.260328 loss_ctc 17.209057 loss_rnnt 10.974279 hw_loss 0.095115 lr 0.00036538 rank 4
2023-02-22 18:42:09,048 DEBUG TRAIN Batch 22/3800 loss 9.114457 loss_att 13.328873 loss_ctc 13.527164 loss_rnnt 7.619539 hw_loss 0.119388 lr 0.00036537 rank 5
2023-02-22 18:42:09,051 DEBUG TRAIN Batch 22/3800 loss 11.270482 loss_att 13.072151 loss_ctc 14.295029 loss_rnnt 10.481315 hw_loss 0.047928 lr 0.00036536 rank 7
2023-02-22 18:42:09,052 DEBUG TRAIN Batch 22/3800 loss 13.235573 loss_att 14.043038 loss_ctc 17.679564 loss_rnnt 12.392436 hw_loss 0.167084 lr 0.00036539 rank 6
2023-02-22 18:42:09,056 DEBUG TRAIN Batch 22/3800 loss 7.113909 loss_att 8.540781 loss_ctc 10.370029 loss_rnnt 6.340306 hw_loss 0.101397 lr 0.00036531 rank 2
2023-02-22 18:42:09,074 DEBUG TRAIN Batch 22/3800 loss 6.107110 loss_att 6.865725 loss_ctc 9.564481 loss_rnnt 5.402249 hw_loss 0.172792 lr 0.00036537 rank 1
2023-02-22 18:42:09,085 DEBUG TRAIN Batch 22/3800 loss 7.627170 loss_att 9.245037 loss_ctc 11.456839 loss_rnnt 6.719614 hw_loss 0.137552 lr 0.00036533 rank 3
2023-02-22 18:43:27,621 DEBUG TRAIN Batch 22/3900 loss 5.484825 loss_att 8.136736 loss_ctc 8.967531 loss_rnnt 4.444721 hw_loss 0.085050 lr 0.00036528 rank 4
2023-02-22 18:43:27,624 DEBUG TRAIN Batch 22/3900 loss 5.038775 loss_att 9.300760 loss_ctc 6.828695 loss_rnnt 3.937771 hw_loss 0.018659 lr 0.00036529 rank 0
2023-02-22 18:43:27,629 DEBUG TRAIN Batch 22/3900 loss 8.807079 loss_att 12.094235 loss_ctc 15.084994 loss_rnnt 7.297390 hw_loss 0.028506 lr 0.00036527 rank 1
2023-02-22 18:43:27,631 DEBUG TRAIN Batch 22/3900 loss 11.797306 loss_att 14.758383 loss_ctc 18.238707 loss_rnnt 10.332653 hw_loss 0.025471 lr 0.00036526 rank 7
2023-02-22 18:43:27,633 DEBUG TRAIN Batch 22/3900 loss 9.265044 loss_att 12.174102 loss_ctc 15.678331 loss_rnnt 7.809288 hw_loss 0.035325 lr 0.00036521 rank 2
2023-02-22 18:43:27,635 DEBUG TRAIN Batch 22/3900 loss 11.026319 loss_att 16.023085 loss_ctc 16.767139 loss_rnnt 9.243832 hw_loss 0.033171 lr 0.00036528 rank 5
2023-02-22 18:43:27,637 DEBUG TRAIN Batch 22/3900 loss 8.028423 loss_att 7.739464 loss_ctc 10.053026 loss_rnnt 7.741174 hw_loss 0.140801 lr 0.00036529 rank 6
2023-02-22 18:43:27,652 DEBUG TRAIN Batch 22/3900 loss 12.682281 loss_att 16.406946 loss_ctc 17.308685 loss_rnnt 11.270690 hw_loss 0.093384 lr 0.00036524 rank 3
2023-02-22 18:44:43,482 DEBUG TRAIN Batch 22/4000 loss 4.960183 loss_att 8.284231 loss_ctc 9.883178 loss_rnnt 3.597239 hw_loss 0.078253 lr 0.00036518 rank 5
2023-02-22 18:44:43,483 DEBUG TRAIN Batch 22/4000 loss 7.408199 loss_att 8.081044 loss_ctc 10.216036 loss_rnnt 6.830220 hw_loss 0.129434 lr 0.00036519 rank 4
2023-02-22 18:44:43,485 DEBUG TRAIN Batch 22/4000 loss 12.014746 loss_att 16.483250 loss_ctc 21.589142 loss_rnnt 9.796542 hw_loss 0.089844 lr 0.00036519 rank 0
2023-02-22 18:44:43,486 DEBUG TRAIN Batch 22/4000 loss 5.653448 loss_att 8.276479 loss_ctc 10.975616 loss_rnnt 4.397243 hw_loss 0.041206 lr 0.00036519 rank 6
2023-02-22 18:44:43,489 DEBUG TRAIN Batch 22/4000 loss 10.859316 loss_att 13.947346 loss_ctc 16.711376 loss_rnnt 9.450773 hw_loss 0.019992 lr 0.00036516 rank 7
2023-02-22 18:44:43,492 DEBUG TRAIN Batch 22/4000 loss 3.259146 loss_att 6.124617 loss_ctc 5.903654 loss_rnnt 2.290580 hw_loss 0.080383 lr 0.00036518 rank 1
2023-02-22 18:44:43,498 DEBUG TRAIN Batch 22/4000 loss 5.647971 loss_att 6.960839 loss_ctc 7.942738 loss_rnnt 5.044543 hw_loss 0.065410 lr 0.00036514 rank 3
2023-02-22 18:44:43,538 DEBUG TRAIN Batch 22/4000 loss 13.278540 loss_att 17.271441 loss_ctc 18.770153 loss_rnnt 11.746803 hw_loss 0.001765 lr 0.00036511 rank 2
2023-02-22 18:45:58,696 DEBUG TRAIN Batch 22/4100 loss 7.280502 loss_att 9.859007 loss_ctc 10.539885 loss_rnnt 6.308094 hw_loss 0.041480 lr 0.00036501 rank 2
2023-02-22 18:45:58,695 DEBUG TRAIN Batch 22/4100 loss 12.766789 loss_att 16.235001 loss_ctc 14.718763 loss_rnnt 11.808630 hw_loss 0.007978 lr 0.00036508 rank 5
2023-02-22 18:45:58,696 DEBUG TRAIN Batch 22/4100 loss 4.125237 loss_att 6.904561 loss_ctc 7.152002 loss_rnnt 3.138778 hw_loss 0.050673 lr 0.00036509 rank 0
2023-02-22 18:45:58,697 DEBUG TRAIN Batch 22/4100 loss 8.394785 loss_att 11.008687 loss_ctc 12.849642 loss_rnnt 7.196080 hw_loss 0.153644 lr 0.00036510 rank 6
2023-02-22 18:45:58,697 DEBUG TRAIN Batch 22/4100 loss 5.910609 loss_att 8.901228 loss_ctc 6.568887 loss_rnnt 5.222068 hw_loss 0.004963 lr 0.00036507 rank 7
2023-02-22 18:45:58,699 DEBUG TRAIN Batch 22/4100 loss 8.718919 loss_att 13.125174 loss_ctc 14.315876 loss_rnnt 7.064226 hw_loss 0.050965 lr 0.00036509 rank 4
2023-02-22 18:45:58,704 DEBUG TRAIN Batch 22/4100 loss 14.111071 loss_att 16.715305 loss_ctc 17.295309 loss_rnnt 13.163104 hw_loss 0.004790 lr 0.00036504 rank 3
2023-02-22 18:45:58,746 DEBUG TRAIN Batch 22/4100 loss 9.001348 loss_att 11.154312 loss_ctc 12.601490 loss_rnnt 8.053294 hw_loss 0.070205 lr 0.00036508 rank 1
2023-02-22 18:47:15,795 DEBUG TRAIN Batch 22/4200 loss 10.485159 loss_att 13.700353 loss_ctc 15.466816 loss_rnnt 9.165632 hw_loss 0.023001 lr 0.00036499 rank 0
2023-02-22 18:47:15,796 DEBUG TRAIN Batch 22/4200 loss 7.011543 loss_att 9.362846 loss_ctc 10.329234 loss_rnnt 6.075657 hw_loss 0.043623 lr 0.00036499 rank 4
2023-02-22 18:47:15,799 DEBUG TRAIN Batch 22/4200 loss 10.400981 loss_att 12.231565 loss_ctc 14.292109 loss_rnnt 9.483075 hw_loss 0.061821 lr 0.00036498 rank 1
2023-02-22 18:47:15,805 DEBUG TRAIN Batch 22/4200 loss 4.914984 loss_att 8.066797 loss_ctc 6.455187 loss_rnnt 4.000834 hw_loss 0.147052 lr 0.00036500 rank 6
2023-02-22 18:47:15,810 DEBUG TRAIN Batch 22/4200 loss 26.428011 loss_att 29.182079 loss_ctc 34.967186 loss_rnnt 24.665415 hw_loss 0.137296 lr 0.00036492 rank 2
2023-02-22 18:47:15,831 DEBUG TRAIN Batch 22/4200 loss 8.275812 loss_att 10.304833 loss_ctc 12.306115 loss_rnnt 7.293294 hw_loss 0.073762 lr 0.00036498 rank 5
2023-02-22 18:47:15,839 DEBUG TRAIN Batch 22/4200 loss 8.476968 loss_att 10.565281 loss_ctc 13.015618 loss_rnnt 7.356668 hw_loss 0.182780 lr 0.00036497 rank 7
2023-02-22 18:47:15,856 DEBUG TRAIN Batch 22/4200 loss 6.800443 loss_att 9.843152 loss_ctc 11.712290 loss_rnnt 5.477033 hw_loss 0.112415 lr 0.00036494 rank 3
2023-02-22 18:48:32,830 DEBUG TRAIN Batch 22/4300 loss 3.580790 loss_att 6.484387 loss_ctc 6.185785 loss_rnnt 2.571473 hw_loss 0.152372 lr 0.00036490 rank 0
2023-02-22 18:48:32,831 DEBUG TRAIN Batch 22/4300 loss 6.939078 loss_att 10.657069 loss_ctc 9.784533 loss_rnnt 5.748717 hw_loss 0.126318 lr 0.00036490 rank 6
2023-02-22 18:48:32,834 DEBUG TRAIN Batch 22/4300 loss 4.561923 loss_att 7.586534 loss_ctc 7.188962 loss_rnnt 3.555250 hw_loss 0.096522 lr 0.00036488 rank 1
2023-02-22 18:48:32,834 DEBUG TRAIN Batch 22/4300 loss 14.149551 loss_att 18.407799 loss_ctc 22.194969 loss_rnnt 12.184355 hw_loss 0.076547 lr 0.00036489 rank 5
2023-02-22 18:48:32,836 DEBUG TRAIN Batch 22/4300 loss 7.094752 loss_att 10.038420 loss_ctc 9.400378 loss_rnnt 6.143627 hw_loss 0.103076 lr 0.00036487 rank 7
2023-02-22 18:48:32,838 DEBUG TRAIN Batch 22/4300 loss 3.446868 loss_att 6.224771 loss_ctc 5.848169 loss_rnnt 2.558174 hw_loss 0.024263 lr 0.00036490 rank 4
2023-02-22 18:48:32,840 DEBUG TRAIN Batch 22/4300 loss 7.622686 loss_att 10.460833 loss_ctc 10.854912 loss_rnnt 6.584907 hw_loss 0.073475 lr 0.00036485 rank 3
2023-02-22 18:48:32,843 DEBUG TRAIN Batch 22/4300 loss 10.665948 loss_att 11.805898 loss_ctc 15.770830 loss_rnnt 9.704694 hw_loss 0.098651 lr 0.00036482 rank 2
2023-02-22 18:49:48,931 DEBUG TRAIN Batch 22/4400 loss 8.097837 loss_att 11.354695 loss_ctc 10.666424 loss_rnnt 7.033495 hw_loss 0.132172 lr 0.00036480 rank 0
2023-02-22 18:49:48,935 DEBUG TRAIN Batch 22/4400 loss 11.816483 loss_att 13.105214 loss_ctc 14.586924 loss_rnnt 11.136245 hw_loss 0.099564 lr 0.00036479 rank 5
2023-02-22 18:49:48,937 DEBUG TRAIN Batch 22/4400 loss 4.964134 loss_att 7.966145 loss_ctc 9.877310 loss_rnnt 3.638619 hw_loss 0.131293 lr 0.00036480 rank 6
2023-02-22 18:49:48,937 DEBUG TRAIN Batch 22/4400 loss 6.240976 loss_att 7.549932 loss_ctc 8.275169 loss_rnnt 5.607739 hw_loss 0.187911 lr 0.00036479 rank 1
2023-02-22 18:49:48,937 DEBUG TRAIN Batch 22/4400 loss 10.911236 loss_att 12.731858 loss_ctc 16.140223 loss_rnnt 9.726653 hw_loss 0.231113 lr 0.00036480 rank 4
2023-02-22 18:49:48,939 DEBUG TRAIN Batch 22/4400 loss 9.159240 loss_att 11.327328 loss_ctc 13.604752 loss_rnnt 8.037582 hw_loss 0.178696 lr 0.00036478 rank 7
2023-02-22 18:49:48,939 DEBUG TRAIN Batch 22/4400 loss 4.308456 loss_att 7.056453 loss_ctc 5.650835 loss_rnnt 3.514451 hw_loss 0.122667 lr 0.00036472 rank 2
2023-02-22 18:49:48,947 DEBUG TRAIN Batch 22/4400 loss 6.953642 loss_att 9.440023 loss_ctc 10.693507 loss_rnnt 5.933476 hw_loss 0.045449 lr 0.00036475 rank 3
2023-02-22 18:51:03,755 DEBUG TRAIN Batch 22/4500 loss 12.501163 loss_att 13.349997 loss_ctc 18.556862 loss_rnnt 11.451729 hw_loss 0.135449 lr 0.00036468 rank 7
2023-02-22 18:51:03,758 DEBUG TRAIN Batch 22/4500 loss 8.984844 loss_att 9.263068 loss_ctc 12.400738 loss_rnnt 8.403929 hw_loss 0.130909 lr 0.00036470 rank 0
2023-02-22 18:51:03,759 DEBUG TRAIN Batch 22/4500 loss 6.318089 loss_att 6.561316 loss_ctc 9.083075 loss_rnnt 5.865559 hw_loss 0.066036 lr 0.00036471 rank 6
2023-02-22 18:51:03,762 DEBUG TRAIN Batch 22/4500 loss 5.649393 loss_att 7.552185 loss_ctc 8.675901 loss_rnnt 4.796056 hw_loss 0.129832 lr 0.00036465 rank 3
2023-02-22 18:51:03,764 DEBUG TRAIN Batch 22/4500 loss 5.037612 loss_att 8.137986 loss_ctc 7.212646 loss_rnnt 4.062963 hw_loss 0.121069 lr 0.00036469 rank 1
2023-02-22 18:51:03,765 DEBUG TRAIN Batch 22/4500 loss 6.044785 loss_att 9.805590 loss_ctc 10.513369 loss_rnnt 4.657977 hw_loss 0.072815 lr 0.00036470 rank 4
2023-02-22 18:51:03,765 DEBUG TRAIN Batch 22/4500 loss 6.302845 loss_att 6.276314 loss_ctc 8.311307 loss_rnnt 5.953388 hw_loss 0.163067 lr 0.00036469 rank 5
2023-02-22 18:51:03,774 DEBUG TRAIN Batch 22/4500 loss 1.834770 loss_att 4.484931 loss_ctc 2.779514 loss_rnnt 1.135783 hw_loss 0.080605 lr 0.00036462 rank 2
2023-02-22 18:52:20,988 DEBUG TRAIN Batch 22/4600 loss 5.942637 loss_att 9.482030 loss_ctc 9.851036 loss_rnnt 4.684305 hw_loss 0.055000 lr 0.00036458 rank 7
2023-02-22 18:52:20,989 DEBUG TRAIN Batch 22/4600 loss 12.478314 loss_att 16.865795 loss_ctc 20.352783 loss_rnnt 10.507998 hw_loss 0.080421 lr 0.00036461 rank 0
2023-02-22 18:52:20,992 DEBUG TRAIN Batch 22/4600 loss 10.629383 loss_att 12.228475 loss_ctc 12.632374 loss_rnnt 10.023401 hw_loss 0.035808 lr 0.00036460 rank 4
2023-02-22 18:52:20,994 DEBUG TRAIN Batch 22/4600 loss 4.954309 loss_att 8.322250 loss_ctc 6.223733 loss_rnnt 4.028778 hw_loss 0.155035 lr 0.00036460 rank 5
2023-02-22 18:52:20,997 DEBUG TRAIN Batch 22/4600 loss 8.110015 loss_att 12.233239 loss_ctc 10.557165 loss_rnnt 6.944701 hw_loss 0.026968 lr 0.00036453 rank 2
2023-02-22 18:52:20,998 DEBUG TRAIN Batch 22/4600 loss 12.196563 loss_att 14.767610 loss_ctc 18.319981 loss_rnnt 10.829685 hw_loss 0.067899 lr 0.00036456 rank 3
2023-02-22 18:52:21,000 DEBUG TRAIN Batch 22/4600 loss 8.650928 loss_att 13.054813 loss_ctc 13.212975 loss_rnnt 7.161603 hw_loss 0.000516 lr 0.00036459 rank 1
2023-02-22 18:52:21,003 DEBUG TRAIN Batch 22/4600 loss 10.622572 loss_att 14.415171 loss_ctc 11.122238 loss_rnnt 9.795642 hw_loss 0.003353 lr 0.00036461 rank 6
2023-02-22 18:53:37,275 DEBUG TRAIN Batch 22/4700 loss 6.137683 loss_att 12.454882 loss_ctc 8.843925 loss_rnnt 4.440854 hw_loss 0.136044 lr 0.00036451 rank 0
2023-02-22 18:53:37,277 DEBUG TRAIN Batch 22/4700 loss 7.469136 loss_att 10.371046 loss_ctc 12.592957 loss_rnnt 6.136190 hw_loss 0.130102 lr 0.00036451 rank 4
2023-02-22 18:53:37,279 DEBUG TRAIN Batch 22/4700 loss 5.022296 loss_att 7.246499 loss_ctc 7.573341 loss_rnnt 4.211755 hw_loss 0.047928 lr 0.00036450 rank 1
2023-02-22 18:53:37,281 DEBUG TRAIN Batch 22/4700 loss 4.501105 loss_att 5.802459 loss_ctc 3.519056 loss_rnnt 4.350492 hw_loss 0.039903 lr 0.00036446 rank 3
2023-02-22 18:53:37,282 DEBUG TRAIN Batch 22/4700 loss 3.981490 loss_att 6.263644 loss_ctc 5.467826 loss_rnnt 3.281255 hw_loss 0.085548 lr 0.00036450 rank 5
2023-02-22 18:53:37,282 DEBUG TRAIN Batch 22/4700 loss 11.696311 loss_att 14.109617 loss_ctc 15.960610 loss_rnnt 10.614082 hw_loss 0.058114 lr 0.00036449 rank 7
2023-02-22 18:53:37,286 DEBUG TRAIN Batch 22/4700 loss 12.025149 loss_att 11.948674 loss_ctc 14.766634 loss_rnnt 11.612594 hw_loss 0.116850 lr 0.00036451 rank 6
2023-02-22 18:53:37,289 DEBUG TRAIN Batch 22/4700 loss 4.478829 loss_att 7.501363 loss_ctc 6.076813 loss_rnnt 3.604179 hw_loss 0.107022 lr 0.00036443 rank 2
2023-02-22 18:54:52,723 DEBUG TRAIN Batch 22/4800 loss 9.207368 loss_att 10.436806 loss_ctc 10.898192 loss_rnnt 8.655798 hw_loss 0.150446 lr 0.00036441 rank 4
2023-02-22 18:54:52,723 DEBUG TRAIN Batch 22/4800 loss 6.220692 loss_att 8.497143 loss_ctc 9.000813 loss_rnnt 5.351907 hw_loss 0.080272 lr 0.00036439 rank 7
2023-02-22 18:54:52,725 DEBUG TRAIN Batch 22/4800 loss 10.140690 loss_att 12.257584 loss_ctc 11.402369 loss_rnnt 9.480305 hw_loss 0.128968 lr 0.00036441 rank 0
2023-02-22 18:54:52,728 DEBUG TRAIN Batch 22/4800 loss 16.750349 loss_att 19.730904 loss_ctc 23.256485 loss_rnnt 15.226412 hw_loss 0.113139 lr 0.00036440 rank 5
2023-02-22 18:54:52,731 DEBUG TRAIN Batch 22/4800 loss 4.232978 loss_att 7.826363 loss_ctc 6.727432 loss_rnnt 3.124202 hw_loss 0.107823 lr 0.00036440 rank 1
2023-02-22 18:54:52,731 DEBUG TRAIN Batch 22/4800 loss 6.297954 loss_att 9.690863 loss_ctc 10.364920 loss_rnnt 5.004431 hw_loss 0.136272 lr 0.00036433 rank 2
2023-02-22 18:54:52,732 DEBUG TRAIN Batch 22/4800 loss 8.665262 loss_att 11.190533 loss_ctc 11.555315 loss_rnnt 7.662334 hw_loss 0.211001 lr 0.00036436 rank 3
2023-02-22 18:54:52,733 DEBUG TRAIN Batch 22/4800 loss 11.085734 loss_att 12.827746 loss_ctc 14.347162 loss_rnnt 10.219084 hw_loss 0.156357 lr 0.00036442 rank 6
2023-02-22 18:56:07,852 DEBUG TRAIN Batch 22/4900 loss 2.468526 loss_att 5.642770 loss_ctc 3.906158 loss_rnnt 1.615245 hw_loss 0.050152 lr 0.00036429 rank 7
2023-02-22 18:56:07,855 DEBUG TRAIN Batch 22/4900 loss 7.077061 loss_att 8.672276 loss_ctc 7.810164 loss_rnnt 6.552200 hw_loss 0.202633 lr 0.00036432 rank 6
2023-02-22 18:56:07,856 DEBUG TRAIN Batch 22/4900 loss 11.083369 loss_att 13.355510 loss_ctc 18.350637 loss_rnnt 9.628942 hw_loss 0.058182 lr 0.00036430 rank 1
2023-02-22 18:56:07,856 DEBUG TRAIN Batch 22/4900 loss 9.943548 loss_att 14.294970 loss_ctc 13.387524 loss_rnnt 8.547331 hw_loss 0.125133 lr 0.00036431 rank 5
2023-02-22 18:56:07,857 DEBUG TRAIN Batch 22/4900 loss 3.826702 loss_att 6.082407 loss_ctc 5.824313 loss_rnnt 3.060984 hw_loss 0.090427 lr 0.00036431 rank 4
2023-02-22 18:56:07,858 DEBUG TRAIN Batch 22/4900 loss 8.450847 loss_att 11.061993 loss_ctc 12.261580 loss_rnnt 7.350151 hw_loss 0.131941 lr 0.00036431 rank 0
2023-02-22 18:56:07,860 DEBUG TRAIN Batch 22/4900 loss 6.134729 loss_att 8.976212 loss_ctc 6.712050 loss_rnnt 5.452519 hw_loss 0.069256 lr 0.00036424 rank 2
2023-02-22 18:56:07,862 DEBUG TRAIN Batch 22/4900 loss 6.664733 loss_att 9.100039 loss_ctc 9.722702 loss_rnnt 5.674896 hw_loss 0.178213 lr 0.00036427 rank 3
2023-02-22 18:57:26,419 DEBUG TRAIN Batch 22/5000 loss 6.063578 loss_att 7.521730 loss_ctc 8.299074 loss_rnnt 5.370821 hw_loss 0.193237 lr 0.00036422 rank 0
2023-02-22 18:57:26,421 DEBUG TRAIN Batch 22/5000 loss 7.986157 loss_att 9.586086 loss_ctc 10.812975 loss_rnnt 7.252110 hw_loss 0.069658 lr 0.00036417 rank 3
2023-02-22 18:57:26,422 DEBUG TRAIN Batch 22/5000 loss 5.422348 loss_att 8.441302 loss_ctc 9.743540 loss_rnnt 4.218583 hw_loss 0.044653 lr 0.00036422 rank 4
2023-02-22 18:57:26,426 DEBUG TRAIN Batch 22/5000 loss 12.699121 loss_att 13.888098 loss_ctc 20.524734 loss_rnnt 11.353026 hw_loss 0.121654 lr 0.00036419 rank 7
2023-02-22 18:57:26,427 DEBUG TRAIN Batch 22/5000 loss 8.511846 loss_att 11.692052 loss_ctc 11.174387 loss_rnnt 7.480294 hw_loss 0.075946 lr 0.00036421 rank 5
2023-02-22 18:57:26,427 DEBUG TRAIN Batch 22/5000 loss 12.197364 loss_att 13.081257 loss_ctc 24.728424 loss_rnnt 10.290586 hw_loss 0.110984 lr 0.00036414 rank 2
2023-02-22 18:57:26,430 DEBUG TRAIN Batch 22/5000 loss 8.506239 loss_att 12.596288 loss_ctc 14.607492 loss_rnnt 6.841522 hw_loss 0.062263 lr 0.00036421 rank 1
2023-02-22 18:57:26,431 DEBUG TRAIN Batch 22/5000 loss 7.296568 loss_att 11.689470 loss_ctc 15.003410 loss_rnnt 5.365940 hw_loss 0.045878 lr 0.00036422 rank 6
2023-02-22 18:58:41,621 DEBUG TRAIN Batch 22/5100 loss 8.976544 loss_att 8.775677 loss_ctc 12.323044 loss_rnnt 8.456679 hw_loss 0.213448 lr 0.00036412 rank 0
2023-02-22 18:58:41,621 DEBUG TRAIN Batch 22/5100 loss 7.659736 loss_att 9.110620 loss_ctc 9.849601 loss_rnnt 7.019217 hw_loss 0.109424 lr 0.00036410 rank 7
2023-02-22 18:58:41,622 DEBUG TRAIN Batch 22/5100 loss 4.528965 loss_att 6.280730 loss_ctc 6.755853 loss_rnnt 3.805068 hw_loss 0.143673 lr 0.00036411 rank 5
2023-02-22 18:58:41,626 DEBUG TRAIN Batch 22/5100 loss 4.700291 loss_att 7.321485 loss_ctc 7.577226 loss_rnnt 3.711909 hw_loss 0.151033 lr 0.00036412 rank 4
2023-02-22 18:58:41,629 DEBUG TRAIN Batch 22/5100 loss 20.628569 loss_att 22.756516 loss_ctc 29.920904 loss_rnnt 18.865141 hw_loss 0.185368 lr 0.00036407 rank 3
2023-02-22 18:58:41,629 DEBUG TRAIN Batch 22/5100 loss 6.622191 loss_att 8.203156 loss_ctc 9.868241 loss_rnnt 5.791345 hw_loss 0.153462 lr 0.00036413 rank 6
2023-02-22 18:58:41,630 DEBUG TRAIN Batch 22/5100 loss 5.328099 loss_att 10.949564 loss_ctc 7.180496 loss_rnnt 3.938982 hw_loss 0.033448 lr 0.00036411 rank 1
2023-02-22 18:58:41,678 DEBUG TRAIN Batch 22/5100 loss 11.959345 loss_att 13.113029 loss_ctc 15.215243 loss_rnnt 11.244758 hw_loss 0.093244 lr 0.00036404 rank 2
2023-02-22 18:59:56,026 DEBUG TRAIN Batch 22/5200 loss 5.377496 loss_att 9.973973 loss_ctc 6.676000 loss_rnnt 4.284920 hw_loss 0.000276 lr 0.00036402 rank 4
2023-02-22 18:59:56,027 DEBUG TRAIN Batch 22/5200 loss 8.824978 loss_att 13.230639 loss_ctc 12.608362 loss_rnnt 7.414304 hw_loss 0.047045 lr 0.00036402 rank 5
2023-02-22 18:59:56,030 DEBUG TRAIN Batch 22/5200 loss 9.944214 loss_att 12.371125 loss_ctc 11.201223 loss_rnnt 9.254490 hw_loss 0.068888 lr 0.00036400 rank 7
2023-02-22 18:59:56,033 DEBUG TRAIN Batch 22/5200 loss 2.840454 loss_att 5.679074 loss_ctc 4.485454 loss_rnnt 1.974201 hw_loss 0.148492 lr 0.00036403 rank 0
2023-02-22 18:59:56,034 DEBUG TRAIN Batch 22/5200 loss 5.636133 loss_att 8.868387 loss_ctc 9.324347 loss_rnnt 4.472701 hw_loss 0.047285 lr 0.00036403 rank 6
2023-02-22 18:59:56,039 DEBUG TRAIN Batch 22/5200 loss 3.062166 loss_att 4.415321 loss_ctc 3.304254 loss_rnnt 2.745874 hw_loss 0.025092 lr 0.00036398 rank 3
2023-02-22 18:59:56,038 DEBUG TRAIN Batch 22/5200 loss 25.111954 loss_att 27.214262 loss_ctc 41.127129 loss_rnnt 22.556103 hw_loss 0.000062 lr 0.00036395 rank 2
2023-02-22 18:59:56,085 DEBUG TRAIN Batch 22/5200 loss 6.247253 loss_att 11.844468 loss_ctc 11.586723 loss_rnnt 4.348005 hw_loss 0.127267 lr 0.00036401 rank 1
2023-02-22 19:01:13,945 DEBUG TRAIN Batch 22/5300 loss 8.373022 loss_att 10.506557 loss_ctc 13.436394 loss_rnnt 7.241308 hw_loss 0.056048 lr 0.00036393 rank 4
2023-02-22 19:01:13,951 DEBUG TRAIN Batch 22/5300 loss 9.049639 loss_att 13.419907 loss_ctc 15.634754 loss_rnnt 7.288068 hw_loss 0.017814 lr 0.00036393 rank 0
2023-02-22 19:01:13,952 DEBUG TRAIN Batch 22/5300 loss 25.717337 loss_att 27.778271 loss_ctc 35.286659 loss_rnnt 23.931553 hw_loss 0.183164 lr 0.00036388 rank 3
2023-02-22 19:01:13,953 DEBUG TRAIN Batch 22/5300 loss 7.722788 loss_att 12.774325 loss_ctc 10.160397 loss_rnnt 6.331136 hw_loss 0.105618 lr 0.00036393 rank 6
2023-02-22 19:01:13,957 DEBUG TRAIN Batch 22/5300 loss 2.326863 loss_att 5.340084 loss_ctc 2.816414 loss_rnnt 1.634040 hw_loss 0.046698 lr 0.00036392 rank 1
2023-02-22 19:01:13,959 DEBUG TRAIN Batch 22/5300 loss 6.632208 loss_att 12.166898 loss_ctc 8.973490 loss_rnnt 5.155230 hw_loss 0.108505 lr 0.00036385 rank 2
2023-02-22 19:01:13,974 DEBUG TRAIN Batch 22/5300 loss 18.403164 loss_att 20.538691 loss_ctc 25.787565 loss_rnnt 16.933868 hw_loss 0.108010 lr 0.00036391 rank 7
2023-02-22 19:01:13,988 DEBUG TRAIN Batch 22/5300 loss 8.729872 loss_att 11.814449 loss_ctc 11.556911 loss_rnnt 7.713006 hw_loss 0.043146 lr 0.00036392 rank 5
2023-02-22 19:02:31,037 DEBUG TRAIN Batch 22/5400 loss 5.111064 loss_att 9.931343 loss_ctc 7.209004 loss_rnnt 3.825253 hw_loss 0.078808 lr 0.00036381 rank 7
2023-02-22 19:02:31,039 DEBUG TRAIN Batch 22/5400 loss 7.007510 loss_att 10.404807 loss_ctc 12.095142 loss_rnnt 5.601642 hw_loss 0.090110 lr 0.00036382 rank 5
2023-02-22 19:02:31,041 DEBUG TRAIN Batch 22/5400 loss 4.975502 loss_att 8.608366 loss_ctc 10.417976 loss_rnnt 3.482545 hw_loss 0.076353 lr 0.00036384 rank 6
2023-02-22 19:02:31,042 DEBUG TRAIN Batch 22/5400 loss 1.542534 loss_att 2.900928 loss_ctc 2.263170 loss_rnnt 1.133276 hw_loss 0.077802 lr 0.00036383 rank 4
2023-02-22 19:02:31,044 DEBUG TRAIN Batch 22/5400 loss 9.722379 loss_att 14.057405 loss_ctc 14.844438 loss_rnnt 8.150056 hw_loss 0.041955 lr 0.00036383 rank 0
2023-02-22 19:02:31,046 DEBUG TRAIN Batch 22/5400 loss 6.468805 loss_att 10.864083 loss_ctc 10.657072 loss_rnnt 4.994318 hw_loss 0.069368 lr 0.00036382 rank 1
2023-02-22 19:02:31,047 DEBUG TRAIN Batch 22/5400 loss 22.440275 loss_att 26.239096 loss_ctc 28.471306 loss_rnnt 20.839142 hw_loss 0.069814 lr 0.00036378 rank 3
2023-02-22 19:02:31,054 DEBUG TRAIN Batch 22/5400 loss 8.564348 loss_att 9.323301 loss_ctc 12.302805 loss_rnnt 7.903091 hw_loss 0.020636 lr 0.00036376 rank 2
2023-02-22 19:03:44,590 DEBUG TRAIN Batch 22/5500 loss 6.380115 loss_att 8.442447 loss_ctc 9.142237 loss_rnnt 5.590997 hw_loss 0.015690 lr 0.00036373 rank 5
2023-02-22 19:03:44,594 DEBUG TRAIN Batch 22/5500 loss 12.845438 loss_att 14.761806 loss_ctc 18.183388 loss_rnnt 11.667879 hw_loss 0.154797 lr 0.00036371 rank 7
2023-02-22 19:03:44,596 DEBUG TRAIN Batch 22/5500 loss 10.234242 loss_att 14.700499 loss_ctc 17.258144 loss_rnnt 8.341309 hw_loss 0.118429 lr 0.00036374 rank 0
2023-02-22 19:03:44,596 DEBUG TRAIN Batch 22/5500 loss 8.931248 loss_att 10.994878 loss_ctc 14.176713 loss_rnnt 7.786346 hw_loss 0.061461 lr 0.00036373 rank 4
2023-02-22 19:03:44,596 DEBUG TRAIN Batch 22/5500 loss 7.816148 loss_att 10.827477 loss_ctc 12.399160 loss_rnnt 6.568805 hw_loss 0.063765 lr 0.00036369 rank 3
2023-02-22 19:03:44,599 DEBUG TRAIN Batch 22/5500 loss 8.494855 loss_att 10.349867 loss_ctc 11.409294 loss_rnnt 7.654229 hw_loss 0.151934 lr 0.00036374 rank 6
2023-02-22 19:03:44,599 DEBUG TRAIN Batch 22/5500 loss 13.245526 loss_att 16.149879 loss_ctc 19.902081 loss_rnnt 11.733356 hw_loss 0.082052 lr 0.00036366 rank 2
2023-02-22 19:03:44,601 DEBUG TRAIN Batch 22/5500 loss 6.890405 loss_att 10.043230 loss_ctc 10.484393 loss_rnnt 5.666779 hw_loss 0.213492 lr 0.00036372 rank 1
2023-02-22 19:04:59,549 DEBUG TRAIN Batch 22/5600 loss 8.693883 loss_att 12.495942 loss_ctc 13.789168 loss_rnnt 7.234000 hw_loss 0.037688 lr 0.00036364 rank 0
2023-02-22 19:04:59,551 DEBUG TRAIN Batch 22/5600 loss 5.838681 loss_att 8.539936 loss_ctc 6.276868 loss_rnnt 5.171042 hw_loss 0.129305 lr 0.00036362 rank 7
2023-02-22 19:04:59,551 DEBUG TRAIN Batch 22/5600 loss 8.740561 loss_att 9.099764 loss_ctc 12.655375 loss_rnnt 8.104310 hw_loss 0.079568 lr 0.00036363 rank 5
2023-02-22 19:04:59,554 DEBUG TRAIN Batch 22/5600 loss 18.804251 loss_att 20.558371 loss_ctc 25.717628 loss_rnnt 17.505140 hw_loss 0.049693 lr 0.00036359 rank 3
2023-02-22 19:04:59,555 DEBUG TRAIN Batch 22/5600 loss 11.480994 loss_att 14.945732 loss_ctc 16.196388 loss_rnnt 10.079340 hw_loss 0.149976 lr 0.00036364 rank 4
2023-02-22 19:04:59,555 DEBUG TRAIN Batch 22/5600 loss 8.371771 loss_att 9.438202 loss_ctc 12.198052 loss_rnnt 7.591484 hw_loss 0.106557 lr 0.00036363 rank 1
2023-02-22 19:04:59,558 DEBUG TRAIN Batch 22/5600 loss 7.795873 loss_att 11.152416 loss_ctc 12.056286 loss_rnnt 6.498964 hw_loss 0.107896 lr 0.00036356 rank 2
2023-02-22 19:04:59,558 DEBUG TRAIN Batch 22/5600 loss 3.284684 loss_att 6.905893 loss_ctc 6.137486 loss_rnnt 2.138249 hw_loss 0.078412 lr 0.00036364 rank 6
2023-02-22 19:06:18,132 DEBUG TRAIN Batch 22/5700 loss 12.623279 loss_att 13.780897 loss_ctc 17.863056 loss_rnnt 11.623662 hw_loss 0.130229 lr 0.00036354 rank 0
2023-02-22 19:06:18,140 DEBUG TRAIN Batch 22/5700 loss 7.327109 loss_att 7.276622 loss_ctc 11.093790 loss_rnnt 6.742192 hw_loss 0.173981 lr 0.00036352 rank 7
2023-02-22 19:06:18,140 DEBUG TRAIN Batch 22/5700 loss 18.446287 loss_att 18.348146 loss_ctc 26.024185 loss_rnnt 17.397961 hw_loss 0.107939 lr 0.00036347 rank 2
2023-02-22 19:06:18,140 DEBUG TRAIN Batch 22/5700 loss 13.026077 loss_att 13.242738 loss_ctc 14.152565 loss_rnnt 12.696239 hw_loss 0.255575 lr 0.00036353 rank 5
2023-02-22 19:06:18,141 DEBUG TRAIN Batch 22/5700 loss 9.552711 loss_att 11.223522 loss_ctc 13.357055 loss_rnnt 8.637367 hw_loss 0.138629 lr 0.00036355 rank 6
2023-02-22 19:06:18,144 DEBUG TRAIN Batch 22/5700 loss 6.514956 loss_att 8.733568 loss_ctc 9.320796 loss_rnnt 5.666029 hw_loss 0.058299 lr 0.00036349 rank 3
2023-02-22 19:06:18,144 DEBUG TRAIN Batch 22/5700 loss 11.876965 loss_att 11.488431 loss_ctc 16.871506 loss_rnnt 11.208451 hw_loss 0.150527 lr 0.00036353 rank 1
2023-02-22 19:06:18,200 DEBUG TRAIN Batch 22/5700 loss 6.042899 loss_att 9.846377 loss_ctc 9.327055 loss_rnnt 4.844293 hw_loss 0.000041 lr 0.00036354 rank 4
2023-02-22 19:07:31,714 DEBUG TRAIN Batch 22/5800 loss 12.261478 loss_att 14.355192 loss_ctc 15.621890 loss_rnnt 11.321882 hw_loss 0.136498 lr 0.00036342 rank 7
2023-02-22 19:07:31,714 DEBUG TRAIN Batch 22/5800 loss 1.253132 loss_att 3.976985 loss_ctc 2.209886 loss_rnnt 0.552773 hw_loss 0.052539 lr 0.00036344 rank 5
2023-02-22 19:07:31,716 DEBUG TRAIN Batch 22/5800 loss 10.335610 loss_att 13.149973 loss_ctc 12.559464 loss_rnnt 9.388062 hw_loss 0.165302 lr 0.00036344 rank 1
2023-02-22 19:07:31,719 DEBUG TRAIN Batch 22/5800 loss 11.254969 loss_att 15.156303 loss_ctc 16.542919 loss_rnnt 9.710185 hw_loss 0.111479 lr 0.00036345 rank 4
2023-02-22 19:07:31,719 DEBUG TRAIN Batch 22/5800 loss 8.281531 loss_att 10.206089 loss_ctc 11.429713 loss_rnnt 7.470184 hw_loss 0.012519 lr 0.00036340 rank 3
2023-02-22 19:07:31,720 DEBUG TRAIN Batch 22/5800 loss 3.682209 loss_att 8.051000 loss_ctc 7.066651 loss_rnnt 2.285395 hw_loss 0.134620 lr 0.00036345 rank 0
2023-02-22 19:07:31,721 DEBUG TRAIN Batch 22/5800 loss 8.385350 loss_att 12.169473 loss_ctc 19.399137 loss_rnnt 6.126576 hw_loss 0.062706 lr 0.00036345 rank 6
2023-02-22 19:07:31,724 DEBUG TRAIN Batch 22/5800 loss 12.378686 loss_att 18.461575 loss_ctc 26.426777 loss_rnnt 9.253920 hw_loss 0.065830 lr 0.00036337 rank 2
2023-02-22 19:08:47,795 DEBUG TRAIN Batch 22/5900 loss 4.513032 loss_att 6.411147 loss_ctc 6.945545 loss_rnnt 3.769014 hw_loss 0.075112 lr 0.00036333 rank 7
2023-02-22 19:08:47,796 DEBUG TRAIN Batch 22/5900 loss 9.615588 loss_att 12.768201 loss_ctc 14.935966 loss_rnnt 8.234318 hw_loss 0.077559 lr 0.00036335 rank 4
2023-02-22 19:08:47,796 DEBUG TRAIN Batch 22/5900 loss 15.835044 loss_att 17.507992 loss_ctc 23.473074 loss_rnnt 14.422751 hw_loss 0.111188 lr 0.00036335 rank 0
2023-02-22 19:08:47,796 DEBUG TRAIN Batch 22/5900 loss 11.546655 loss_att 13.439774 loss_ctc 12.654894 loss_rnnt 10.953533 hw_loss 0.125121 lr 0.00036334 rank 5
2023-02-22 19:08:47,800 DEBUG TRAIN Batch 22/5900 loss 21.430004 loss_att 28.553238 loss_ctc 30.213001 loss_rnnt 18.805214 hw_loss 0.054523 lr 0.00036327 rank 2
2023-02-22 19:08:47,800 DEBUG TRAIN Batch 22/5900 loss 6.163810 loss_att 8.600788 loss_ctc 8.915849 loss_rnnt 5.291891 hw_loss 0.032973 lr 0.00036334 rank 1
2023-02-22 19:08:47,802 DEBUG TRAIN Batch 22/5900 loss 6.240142 loss_att 9.360893 loss_ctc 10.559543 loss_rnnt 5.033738 hw_loss 0.011876 lr 0.00036330 rank 3
2023-02-22 19:08:47,804 DEBUG TRAIN Batch 22/5900 loss 8.430286 loss_att 9.694769 loss_ctc 14.755705 loss_rnnt 7.333838 hw_loss 0.000306 lr 0.00036336 rank 6
2023-02-22 19:10:04,267 DEBUG TRAIN Batch 22/6000 loss 14.305361 loss_att 18.142200 loss_ctc 17.213772 loss_rnnt 13.132611 hw_loss 0.032987 lr 0.00036326 rank 0
2023-02-22 19:10:04,267 DEBUG TRAIN Batch 22/6000 loss 9.777558 loss_att 11.587247 loss_ctc 10.834773 loss_rnnt 9.240662 hw_loss 0.063747 lr 0.00036323 rank 7
2023-02-22 19:10:04,270 DEBUG TRAIN Batch 22/6000 loss 5.717375 loss_att 10.000742 loss_ctc 11.617007 loss_rnnt 3.995868 hw_loss 0.146655 lr 0.00036325 rank 5
2023-02-22 19:10:04,270 DEBUG TRAIN Batch 22/6000 loss 6.682912 loss_att 9.996823 loss_ctc 11.141472 loss_rnnt 5.366006 hw_loss 0.111842 lr 0.00036325 rank 4
2023-02-22 19:10:04,270 DEBUG TRAIN Batch 22/6000 loss 7.033591 loss_att 8.362594 loss_ctc 11.578545 loss_rnnt 6.128423 hw_loss 0.062574 lr 0.00036324 rank 1
2023-02-22 19:10:04,273 DEBUG TRAIN Batch 22/6000 loss 11.479074 loss_att 11.907677 loss_ctc 10.764281 loss_rnnt 11.473043 hw_loss 0.029281 lr 0.00036321 rank 3
2023-02-22 19:10:04,276 DEBUG TRAIN Batch 22/6000 loss 7.790066 loss_att 10.424675 loss_ctc 14.988998 loss_rnnt 6.294177 hw_loss 0.017082 lr 0.00036326 rank 6
2023-02-22 19:10:04,323 DEBUG TRAIN Batch 22/6000 loss 12.961415 loss_att 15.957381 loss_ctc 15.212860 loss_rnnt 12.040984 hw_loss 0.039459 lr 0.00036318 rank 2
2023-02-22 19:11:20,801 DEBUG TRAIN Batch 22/6100 loss 6.879086 loss_att 10.784466 loss_ctc 10.427561 loss_rnnt 5.592068 hw_loss 0.061522 lr 0.00036314 rank 7
2023-02-22 19:11:20,802 DEBUG TRAIN Batch 22/6100 loss 7.879981 loss_att 13.007677 loss_ctc 12.264009 loss_rnnt 6.251832 hw_loss 0.033886 lr 0.00036315 rank 5
2023-02-22 19:11:20,801 DEBUG TRAIN Batch 22/6100 loss 10.663247 loss_att 13.879484 loss_ctc 15.198112 loss_rnnt 9.335304 hw_loss 0.150087 lr 0.00036315 rank 1
2023-02-22 19:11:20,804 DEBUG TRAIN Batch 22/6100 loss 14.033795 loss_att 17.596756 loss_ctc 16.732182 loss_rnnt 12.905664 hw_loss 0.104540 lr 0.00036316 rank 6
2023-02-22 19:11:20,804 DEBUG TRAIN Batch 22/6100 loss 15.354628 loss_att 17.037754 loss_ctc 22.127697 loss_rnnt 14.094772 hw_loss 0.037788 lr 0.00036316 rank 4
2023-02-22 19:11:20,806 DEBUG TRAIN Batch 22/6100 loss 9.371714 loss_att 14.388383 loss_ctc 15.035042 loss_rnnt 7.540187 hw_loss 0.137028 lr 0.00036316 rank 0
2023-02-22 19:11:20,807 DEBUG TRAIN Batch 22/6100 loss 5.482442 loss_att 8.750765 loss_ctc 9.249023 loss_rnnt 4.271444 hw_loss 0.103356 lr 0.00036308 rank 2
2023-02-22 19:11:20,810 DEBUG TRAIN Batch 22/6100 loss 5.290479 loss_att 7.541080 loss_ctc 9.819530 loss_rnnt 4.231050 hw_loss 0.010194 lr 0.00036311 rank 3
2023-02-22 19:12:36,992 DEBUG TRAIN Batch 22/6200 loss 10.826718 loss_att 11.917454 loss_ctc 14.987296 loss_rnnt 9.968131 hw_loss 0.160683 lr 0.00036306 rank 4
2023-02-22 19:12:36,995 DEBUG TRAIN Batch 22/6200 loss 7.228111 loss_att 8.872698 loss_ctc 9.240890 loss_rnnt 6.563204 hw_loss 0.126787 lr 0.00036306 rank 0
2023-02-22 19:12:37,000 DEBUG TRAIN Batch 22/6200 loss 8.811645 loss_att 10.408473 loss_ctc 12.515568 loss_rnnt 7.939508 hw_loss 0.110463 lr 0.00036302 rank 3
2023-02-22 19:12:37,002 DEBUG TRAIN Batch 22/6200 loss 14.297744 loss_att 18.350536 loss_ctc 19.747177 loss_rnnt 12.711528 hw_loss 0.091998 lr 0.00036304 rank 7
2023-02-22 19:12:37,002 DEBUG TRAIN Batch 22/6200 loss 7.708476 loss_att 10.434791 loss_ctc 10.663334 loss_rnnt 6.763130 hw_loss 0.011441 lr 0.00036299 rank 2
2023-02-22 19:12:37,003 DEBUG TRAIN Batch 22/6200 loss 7.032260 loss_att 8.455315 loss_ctc 7.391220 loss_rnnt 6.643657 hw_loss 0.105247 lr 0.00036307 rank 6
2023-02-22 19:12:37,004 DEBUG TRAIN Batch 22/6200 loss 11.886648 loss_att 13.988711 loss_ctc 15.198403 loss_rnnt 10.988358 hw_loss 0.068081 lr 0.00036305 rank 5
2023-02-22 19:12:37,008 DEBUG TRAIN Batch 22/6200 loss 16.425545 loss_att 18.000000 loss_ctc 20.465759 loss_rnnt 15.483976 hw_loss 0.164966 lr 0.00036305 rank 1
2023-02-22 19:13:51,362 DEBUG TRAIN Batch 22/6300 loss 9.758621 loss_att 11.262374 loss_ctc 13.084189 loss_rnnt 8.898476 hw_loss 0.217474 lr 0.00036297 rank 0
2023-02-22 19:13:51,364 DEBUG TRAIN Batch 22/6300 loss 6.967470 loss_att 9.555624 loss_ctc 8.814278 loss_rnnt 6.126689 hw_loss 0.144203 lr 0.00036296 rank 5
2023-02-22 19:13:51,369 DEBUG TRAIN Batch 22/6300 loss 6.469220 loss_att 6.413574 loss_ctc 8.577944 loss_rnnt 6.122616 hw_loss 0.143568 lr 0.00036297 rank 4
2023-02-22 19:13:51,370 DEBUG TRAIN Batch 22/6300 loss 15.084457 loss_att 16.037104 loss_ctc 17.992153 loss_rnnt 14.461466 hw_loss 0.083943 lr 0.00036296 rank 1
2023-02-22 19:13:51,376 DEBUG TRAIN Batch 22/6300 loss 14.550135 loss_att 18.620806 loss_ctc 18.563814 loss_rnnt 13.133135 hw_loss 0.126954 lr 0.00036297 rank 6
2023-02-22 19:13:51,380 DEBUG TRAIN Batch 22/6300 loss 5.703000 loss_att 7.138903 loss_ctc 10.091791 loss_rnnt 4.726467 hw_loss 0.195337 lr 0.00036295 rank 7
2023-02-22 19:13:51,380 DEBUG TRAIN Batch 22/6300 loss 10.111369 loss_att 11.820240 loss_ctc 13.843890 loss_rnnt 9.207458 hw_loss 0.120875 lr 0.00036289 rank 2
2023-02-22 19:13:51,380 DEBUG TRAIN Batch 22/6300 loss 10.232697 loss_att 13.411638 loss_ctc 12.544490 loss_rnnt 9.209198 hw_loss 0.149008 lr 0.00036292 rank 3
2023-02-22 19:15:09,903 DEBUG TRAIN Batch 22/6400 loss 9.673750 loss_att 14.819340 loss_ctc 11.076216 loss_rnnt 8.417926 hw_loss 0.074458 lr 0.00036285 rank 7
2023-02-22 19:15:09,906 DEBUG TRAIN Batch 22/6400 loss 2.837115 loss_att 6.799000 loss_ctc 3.579376 loss_rnnt 1.933044 hw_loss 0.023861 lr 0.00036286 rank 5
2023-02-22 19:15:09,909 DEBUG TRAIN Batch 22/6400 loss 8.261127 loss_att 7.782242 loss_ctc 10.934065 loss_rnnt 7.935480 hw_loss 0.121937 lr 0.00036282 rank 3
2023-02-22 19:15:09,910 DEBUG TRAIN Batch 22/6400 loss 12.519367 loss_att 12.960420 loss_ctc 15.508385 loss_rnnt 11.936944 hw_loss 0.179392 lr 0.00036286 rank 1
2023-02-22 19:15:09,912 DEBUG TRAIN Batch 22/6400 loss 3.608493 loss_att 6.305129 loss_ctc 3.419340 loss_rnnt 3.024428 hw_loss 0.131173 lr 0.00036287 rank 0
2023-02-22 19:15:09,912 DEBUG TRAIN Batch 22/6400 loss 8.746870 loss_att 9.882937 loss_ctc 11.985953 loss_rnnt 8.064339 hw_loss 0.043951 lr 0.00036280 rank 2
2023-02-22 19:15:09,918 DEBUG TRAIN Batch 22/6400 loss 8.366516 loss_att 10.607450 loss_ctc 13.226007 loss_rnnt 7.170728 hw_loss 0.186879 lr 0.00036288 rank 6
2023-02-22 19:15:09,962 DEBUG TRAIN Batch 22/6400 loss 7.486349 loss_att 10.694017 loss_ctc 10.906954 loss_rnnt 6.388630 hw_loss 0.000195 lr 0.00036287 rank 4
2023-02-22 19:16:25,855 DEBUG TRAIN Batch 22/6500 loss 7.600529 loss_att 9.620229 loss_ctc 9.932730 loss_rnnt 6.873538 hw_loss 0.022671 lr 0.00036278 rank 0
2023-02-22 19:16:25,856 DEBUG TRAIN Batch 22/6500 loss 4.272335 loss_att 6.494742 loss_ctc 9.068871 loss_rnnt 3.140544 hw_loss 0.089571 lr 0.00036275 rank 7
2023-02-22 19:16:25,858 DEBUG TRAIN Batch 22/6500 loss 7.565281 loss_att 11.801495 loss_ctc 12.514425 loss_rnnt 6.003604 hw_loss 0.102279 lr 0.00036278 rank 4
2023-02-22 19:16:25,860 DEBUG TRAIN Batch 22/6500 loss 7.328685 loss_att 10.349237 loss_ctc 14.795525 loss_rnnt 5.693522 hw_loss 0.066513 lr 0.00036276 rank 1
2023-02-22 19:16:25,860 DEBUG TRAIN Batch 22/6500 loss 4.207205 loss_att 7.770048 loss_ctc 8.094813 loss_rnnt 2.957834 hw_loss 0.034602 lr 0.00036277 rank 5
2023-02-22 19:16:25,862 DEBUG TRAIN Batch 22/6500 loss 13.451869 loss_att 17.671810 loss_ctc 18.663303 loss_rnnt 11.825459 hw_loss 0.164182 lr 0.00036270 rank 2
2023-02-22 19:16:25,864 DEBUG TRAIN Batch 22/6500 loss 7.079388 loss_att 11.813020 loss_ctc 10.105077 loss_rnnt 5.635445 hw_loss 0.175860 lr 0.00036278 rank 6
2023-02-22 19:16:25,908 DEBUG TRAIN Batch 22/6500 loss 9.197832 loss_att 10.883684 loss_ctc 11.837179 loss_rnnt 8.468083 hw_loss 0.076245 lr 0.00036273 rank 3
2023-02-22 19:17:40,133 DEBUG TRAIN Batch 22/6600 loss 5.664580 loss_att 8.403351 loss_ctc 6.966445 loss_rnnt 4.925622 hw_loss 0.033041 lr 0.00036268 rank 0
2023-02-22 19:17:40,137 DEBUG TRAIN Batch 22/6600 loss 9.984756 loss_att 10.761348 loss_ctc 10.973351 loss_rnnt 9.657572 hw_loss 0.075100 lr 0.00036266 rank 7
2023-02-22 19:17:40,138 DEBUG TRAIN Batch 22/6600 loss 4.284829 loss_att 5.722427 loss_ctc 6.108365 loss_rnnt 3.686661 hw_loss 0.126583 lr 0.00036268 rank 4
2023-02-22 19:17:40,139 DEBUG TRAIN Batch 22/6600 loss 16.786892 loss_att 18.742580 loss_ctc 27.590742 loss_rnnt 14.901060 hw_loss 0.101592 lr 0.00036267 rank 5
2023-02-22 19:17:40,141 DEBUG TRAIN Batch 22/6600 loss 12.290421 loss_att 12.808078 loss_ctc 15.223272 loss_rnnt 11.749657 hw_loss 0.086598 lr 0.00036269 rank 6
2023-02-22 19:17:40,142 DEBUG TRAIN Batch 22/6600 loss 10.178744 loss_att 12.873582 loss_ctc 11.890456 loss_rnnt 9.381899 hw_loss 0.055594 lr 0.00036261 rank 2
2023-02-22 19:17:40,144 DEBUG TRAIN Batch 22/6600 loss 3.955002 loss_att 5.872999 loss_ctc 5.737712 loss_rnnt 3.279556 hw_loss 0.101534 lr 0.00036263 rank 3
2023-02-22 19:17:40,147 DEBUG TRAIN Batch 22/6600 loss 17.578115 loss_att 22.184845 loss_ctc 32.258270 loss_rnnt 14.648861 hw_loss 0.094789 lr 0.00036267 rank 1
2023-02-22 19:18:55,857 DEBUG TRAIN Batch 22/6700 loss 6.194601 loss_att 9.253477 loss_ctc 6.588289 loss_rnnt 5.476560 hw_loss 0.100827 lr 0.00036259 rank 6
2023-02-22 19:18:55,856 DEBUG TRAIN Batch 22/6700 loss 7.027465 loss_att 10.686496 loss_ctc 11.259485 loss_rnnt 5.708585 hw_loss 0.042759 lr 0.00036259 rank 4
2023-02-22 19:18:55,858 DEBUG TRAIN Batch 22/6700 loss 10.249989 loss_att 11.672747 loss_ctc 15.578119 loss_rnnt 9.205744 hw_loss 0.092392 lr 0.00036258 rank 5
2023-02-22 19:18:55,860 DEBUG TRAIN Batch 22/6700 loss 2.275829 loss_att 5.225413 loss_ctc 4.701412 loss_rnnt 1.292218 hw_loss 0.131781 lr 0.00036257 rank 1
2023-02-22 19:18:55,862 DEBUG TRAIN Batch 22/6700 loss 13.062786 loss_att 17.721386 loss_ctc 19.216389 loss_rnnt 11.249936 hw_loss 0.113718 lr 0.00036256 rank 7
2023-02-22 19:18:55,864 DEBUG TRAIN Batch 22/6700 loss 15.169934 loss_att 17.863270 loss_ctc 17.111782 loss_rnnt 14.324020 hw_loss 0.090625 lr 0.00036254 rank 3
2023-02-22 19:18:55,865 DEBUG TRAIN Batch 22/6700 loss 4.822196 loss_att 7.890030 loss_ctc 4.870521 loss_rnnt 4.169605 hw_loss 0.061089 lr 0.00036259 rank 0
2023-02-22 19:18:55,867 DEBUG TRAIN Batch 22/6700 loss 5.460780 loss_att 8.251872 loss_ctc 8.339054 loss_rnnt 4.460506 hw_loss 0.109285 lr 0.00036251 rank 2
2023-02-22 19:20:13,020 DEBUG TRAIN Batch 22/6800 loss 15.364148 loss_att 16.471794 loss_ctc 19.237295 loss_rnnt 14.582850 hw_loss 0.081280 lr 0.00036249 rank 4
2023-02-22 19:20:13,024 DEBUG TRAIN Batch 22/6800 loss 5.724893 loss_att 8.157770 loss_ctc 5.954981 loss_rnnt 5.124947 hw_loss 0.155047 lr 0.00036249 rank 0
2023-02-22 19:20:13,026 DEBUG TRAIN Batch 22/6800 loss 3.928073 loss_att 6.721186 loss_ctc 5.484249 loss_rnnt 3.087616 hw_loss 0.139396 lr 0.00036248 rank 5
2023-02-22 19:20:13,027 DEBUG TRAIN Batch 22/6800 loss 8.166891 loss_att 10.698375 loss_ctc 13.809896 loss_rnnt 6.872802 hw_loss 0.066362 lr 0.00036248 rank 1
2023-02-22 19:20:13,029 DEBUG TRAIN Batch 22/6800 loss 7.742215 loss_att 11.976432 loss_ctc 12.218315 loss_rnnt 6.286714 hw_loss 0.022207 lr 0.00036247 rank 7
2023-02-22 19:20:13,031 DEBUG TRAIN Batch 22/6800 loss 6.655038 loss_att 8.929153 loss_ctc 10.306740 loss_rnnt 5.614138 hw_loss 0.185969 lr 0.00036241 rank 2
2023-02-22 19:20:13,033 DEBUG TRAIN Batch 22/6800 loss 12.376556 loss_att 15.740056 loss_ctc 16.877819 loss_rnnt 11.071554 hw_loss 0.060251 lr 0.00036250 rank 6
2023-02-22 19:20:13,033 DEBUG TRAIN Batch 22/6800 loss 7.509398 loss_att 8.860689 loss_ctc 6.946131 loss_rnnt 7.230122 hw_loss 0.157723 lr 0.00036244 rank 3
2023-02-22 19:21:28,058 DEBUG TRAIN Batch 22/6900 loss 8.177291 loss_att 9.844929 loss_ctc 10.451801 loss_rnnt 7.495115 hw_loss 0.085090 lr 0.00036240 rank 0
2023-02-22 19:21:28,060 DEBUG TRAIN Batch 22/6900 loss 4.648792 loss_att 7.078566 loss_ctc 9.484513 loss_rnnt 3.492627 hw_loss 0.047714 lr 0.00036232 rank 2
2023-02-22 19:21:28,062 DEBUG TRAIN Batch 22/6900 loss 9.131439 loss_att 11.087795 loss_ctc 15.692140 loss_rnnt 7.839964 hw_loss 0.047708 lr 0.00036239 rank 4
2023-02-22 19:21:28,064 DEBUG TRAIN Batch 22/6900 loss 5.876748 loss_att 8.274604 loss_ctc 7.286992 loss_rnnt 5.184530 hw_loss 0.046151 lr 0.00036240 rank 6
2023-02-22 19:21:28,066 DEBUG TRAIN Batch 22/6900 loss 6.443860 loss_att 10.035332 loss_ctc 12.183432 loss_rnnt 4.844642 hw_loss 0.216838 lr 0.00036235 rank 3
2023-02-22 19:21:28,073 DEBUG TRAIN Batch 22/6900 loss 3.608454 loss_att 4.656396 loss_ctc 5.268219 loss_rnnt 3.059985 hw_loss 0.220460 lr 0.00036237 rank 7
2023-02-22 19:21:28,087 DEBUG TRAIN Batch 22/6900 loss 10.418701 loss_att 12.503992 loss_ctc 15.509155 loss_rnnt 9.281252 hw_loss 0.078121 lr 0.00036239 rank 5
2023-02-22 19:21:28,112 DEBUG TRAIN Batch 22/6900 loss 22.893547 loss_att 28.673779 loss_ctc 29.002718 loss_rnnt 20.864790 hw_loss 0.109039 lr 0.00036238 rank 1
2023-02-22 19:22:44,118 DEBUG TRAIN Batch 22/7000 loss 6.825713 loss_att 7.045433 loss_ctc 8.497131 loss_rnnt 6.493059 hw_loss 0.123478 lr 0.00036229 rank 5
2023-02-22 19:22:44,121 DEBUG TRAIN Batch 22/7000 loss 5.333728 loss_att 10.114229 loss_ctc 6.018659 loss_rnnt 4.243013 hw_loss 0.081171 lr 0.00036230 rank 0
2023-02-22 19:22:44,121 DEBUG TRAIN Batch 22/7000 loss 6.003330 loss_att 7.360336 loss_ctc 7.903452 loss_rnnt 5.441370 hw_loss 0.069765 lr 0.00036231 rank 6
2023-02-22 19:22:44,122 DEBUG TRAIN Batch 22/7000 loss 20.135035 loss_att 23.046814 loss_ctc 27.951200 loss_rnnt 18.465260 hw_loss 0.084873 lr 0.00036230 rank 4
2023-02-22 19:22:44,123 DEBUG TRAIN Batch 22/7000 loss 12.882657 loss_att 14.104877 loss_ctc 16.851645 loss_rnnt 12.046165 hw_loss 0.117843 lr 0.00036225 rank 3
2023-02-22 19:22:44,125 DEBUG TRAIN Batch 22/7000 loss 4.610659 loss_att 7.946621 loss_ctc 7.335624 loss_rnnt 3.580108 hw_loss 0.000055 lr 0.00036228 rank 7
2023-02-22 19:22:44,131 DEBUG TRAIN Batch 22/7000 loss 5.672531 loss_att 6.767954 loss_ctc 9.301603 loss_rnnt 4.904115 hw_loss 0.122728 lr 0.00036222 rank 2
2023-02-22 19:22:44,165 DEBUG TRAIN Batch 22/7000 loss 13.538134 loss_att 15.891088 loss_ctc 18.730911 loss_rnnt 12.346616 hw_loss 0.053545 lr 0.00036229 rank 1
2023-02-22 19:24:02,695 DEBUG TRAIN Batch 22/7100 loss 4.526396 loss_att 9.416479 loss_ctc 8.491842 loss_rnnt 2.961826 hw_loss 0.108426 lr 0.00036221 rank 0
2023-02-22 19:24:02,696 DEBUG TRAIN Batch 22/7100 loss 8.032035 loss_att 10.915840 loss_ctc 16.204201 loss_rnnt 6.346168 hw_loss 0.036532 lr 0.00036220 rank 4
2023-02-22 19:24:02,698 DEBUG TRAIN Batch 22/7100 loss 5.471543 loss_att 8.038090 loss_ctc 8.945473 loss_rnnt 4.441229 hw_loss 0.100900 lr 0.00036220 rank 5
2023-02-22 19:24:02,699 DEBUG TRAIN Batch 22/7100 loss 2.662831 loss_att 5.309030 loss_ctc 2.665452 loss_rnnt 2.068956 hw_loss 0.120536 lr 0.00036221 rank 6
2023-02-22 19:24:02,700 DEBUG TRAIN Batch 22/7100 loss 15.582882 loss_att 18.208925 loss_ctc 23.018372 loss_rnnt 14.032898 hw_loss 0.062581 lr 0.00036213 rank 2
2023-02-22 19:24:02,701 DEBUG TRAIN Batch 22/7100 loss 6.355702 loss_att 8.262172 loss_ctc 11.075660 loss_rnnt 5.268299 hw_loss 0.143965 lr 0.00036218 rank 7
2023-02-22 19:24:02,706 DEBUG TRAIN Batch 22/7100 loss 5.345725 loss_att 8.093138 loss_ctc 9.238251 loss_rnnt 4.224681 hw_loss 0.098546 lr 0.00036216 rank 3
2023-02-22 19:24:02,721 DEBUG TRAIN Batch 22/7100 loss 4.061816 loss_att 7.591834 loss_ctc 7.440588 loss_rnnt 2.881753 hw_loss 0.044167 lr 0.00036219 rank 1
2023-02-22 19:25:19,041 DEBUG TRAIN Batch 22/7200 loss 9.241515 loss_att 15.542027 loss_ctc 16.399397 loss_rnnt 7.026985 hw_loss 0.000081 lr 0.00036210 rank 5
2023-02-22 19:25:19,047 DEBUG TRAIN Batch 22/7200 loss 5.335961 loss_att 10.953073 loss_ctc 10.402598 loss_rnnt 3.519023 hw_loss 0.033683 lr 0.00036211 rank 0
2023-02-22 19:25:19,048 DEBUG TRAIN Batch 22/7200 loss 8.725754 loss_att 11.246571 loss_ctc 15.399783 loss_rnnt 7.295774 hw_loss 0.067400 lr 0.00036206 rank 3
2023-02-22 19:25:19,049 DEBUG TRAIN Batch 22/7200 loss 11.599510 loss_att 14.548042 loss_ctc 17.151897 loss_rnnt 10.225886 hw_loss 0.081749 lr 0.00036212 rank 6
2023-02-22 19:25:19,049 DEBUG TRAIN Batch 22/7200 loss 11.540098 loss_att 18.678095 loss_ctc 25.685619 loss_rnnt 8.202892 hw_loss 0.044132 lr 0.00036211 rank 4
2023-02-22 19:25:19,050 DEBUG TRAIN Batch 22/7200 loss 10.513734 loss_att 13.023903 loss_ctc 15.071548 loss_rnnt 9.359850 hw_loss 0.082765 lr 0.00036209 rank 7
2023-02-22 19:25:19,053 DEBUG TRAIN Batch 22/7200 loss 8.348481 loss_att 12.748009 loss_ctc 10.695150 loss_rnnt 7.152427 hw_loss 0.006110 lr 0.00036210 rank 1
2023-02-22 19:25:19,056 DEBUG TRAIN Batch 22/7200 loss 10.762041 loss_att 11.657999 loss_ctc 13.523026 loss_rnnt 10.129249 hw_loss 0.160256 lr 0.00036203 rank 2
2023-02-22 19:26:34,372 DEBUG TRAIN Batch 22/7300 loss 7.545141 loss_att 11.821360 loss_ctc 10.158182 loss_rnnt 6.316490 hw_loss 0.046879 lr 0.00036199 rank 7
2023-02-22 19:26:34,374 DEBUG TRAIN Batch 22/7300 loss 5.373206 loss_att 9.654980 loss_ctc 9.397359 loss_rnnt 3.929596 hw_loss 0.095066 lr 0.00036197 rank 3
2023-02-22 19:26:34,376 DEBUG TRAIN Batch 22/7300 loss 12.552227 loss_att 15.995061 loss_ctc 22.235531 loss_rnnt 10.525248 hw_loss 0.088697 lr 0.00036201 rank 4
2023-02-22 19:26:34,377 DEBUG TRAIN Batch 22/7300 loss 17.364277 loss_att 17.809286 loss_ctc 21.099657 loss_rnnt 16.736444 hw_loss 0.076461 lr 0.00036201 rank 5
2023-02-22 19:26:34,378 DEBUG TRAIN Batch 22/7300 loss 4.010891 loss_att 7.941700 loss_ctc 7.610345 loss_rnnt 2.676171 hw_loss 0.128684 lr 0.00036202 rank 0
2023-02-22 19:26:34,380 DEBUG TRAIN Batch 22/7300 loss 11.362674 loss_att 14.579114 loss_ctc 20.654720 loss_rnnt 9.426097 hw_loss 0.101908 lr 0.00036200 rank 1
2023-02-22 19:26:34,384 DEBUG TRAIN Batch 22/7300 loss 9.636282 loss_att 12.729239 loss_ctc 13.359261 loss_rnnt 8.484123 hw_loss 0.069694 lr 0.00036194 rank 2
2023-02-22 19:26:34,427 DEBUG TRAIN Batch 22/7300 loss 4.145571 loss_att 8.520103 loss_ctc 9.944681 loss_rnnt 2.404549 hw_loss 0.174189 lr 0.00036202 rank 6
2023-02-22 19:27:51,278 DEBUG TRAIN Batch 22/7400 loss 4.683236 loss_att 5.795871 loss_ctc 4.739290 loss_rnnt 4.431095 hw_loss 0.041514 lr 0.00036192 rank 0
2023-02-22 19:27:51,282 DEBUG TRAIN Batch 22/7400 loss 7.841736 loss_att 9.731367 loss_ctc 14.755399 loss_rnnt 6.520931 hw_loss 0.039480 lr 0.00036192 rank 4
2023-02-22 19:27:51,282 DEBUG TRAIN Batch 22/7400 loss 10.670108 loss_att 12.972597 loss_ctc 13.149643 loss_rnnt 9.847689 hw_loss 0.058717 lr 0.00036193 rank 6
2023-02-22 19:27:51,286 DEBUG TRAIN Batch 22/7400 loss 6.562305 loss_att 8.611764 loss_ctc 8.975590 loss_rnnt 5.830409 hw_loss 0.000437 lr 0.00036190 rank 7
2023-02-22 19:27:51,287 DEBUG TRAIN Batch 22/7400 loss 9.066751 loss_att 11.558104 loss_ctc 11.509064 loss_rnnt 8.211347 hw_loss 0.059045 lr 0.00036191 rank 5
2023-02-22 19:27:51,291 DEBUG TRAIN Batch 22/7400 loss 8.025141 loss_att 14.619194 loss_ctc 14.542271 loss_rnnt 5.769981 hw_loss 0.126371 lr 0.00036191 rank 1
2023-02-22 19:27:51,292 DEBUG TRAIN Batch 22/7400 loss 2.574618 loss_att 5.887830 loss_ctc 2.167731 loss_rnnt 1.935687 hw_loss 0.057263 lr 0.00036187 rank 3
2023-02-22 19:27:51,297 DEBUG TRAIN Batch 22/7400 loss 12.233805 loss_att 14.827267 loss_ctc 19.413219 loss_rnnt 10.710315 hw_loss 0.089141 lr 0.00036185 rank 2
2023-02-22 19:29:09,740 DEBUG TRAIN Batch 22/7500 loss 11.832795 loss_att 13.080071 loss_ctc 14.789510 loss_rnnt 11.101138 hw_loss 0.164953 lr 0.00036180 rank 7
2023-02-22 19:29:09,743 DEBUG TRAIN Batch 22/7500 loss 6.298388 loss_att 8.738177 loss_ctc 4.816558 loss_rnnt 5.935325 hw_loss 0.136282 lr 0.00036182 rank 5
2023-02-22 19:29:09,745 DEBUG TRAIN Batch 22/7500 loss 5.081704 loss_att 6.539670 loss_ctc 6.422338 loss_rnnt 4.599607 hw_loss 0.022035 lr 0.00036183 rank 0
2023-02-22 19:29:09,746 DEBUG TRAIN Batch 22/7500 loss 9.817174 loss_att 12.082888 loss_ctc 13.117313 loss_rnnt 8.872384 hw_loss 0.096803 lr 0.00036178 rank 3
2023-02-22 19:29:09,746 DEBUG TRAIN Batch 22/7500 loss 9.712815 loss_att 13.382172 loss_ctc 13.111092 loss_rnnt 8.480545 hw_loss 0.084929 lr 0.00036175 rank 2
2023-02-22 19:29:09,746 DEBUG TRAIN Batch 22/7500 loss 12.490981 loss_att 10.954773 loss_ctc 13.440491 loss_rnnt 12.616908 hw_loss 0.102587 lr 0.00036181 rank 1
2023-02-22 19:29:09,747 DEBUG TRAIN Batch 22/7500 loss 7.247739 loss_att 9.059525 loss_ctc 10.075932 loss_rnnt 6.487247 hw_loss 0.039456 lr 0.00036183 rank 6
2023-02-22 19:29:09,751 DEBUG TRAIN Batch 22/7500 loss 9.762355 loss_att 12.437721 loss_ctc 13.609014 loss_rnnt 8.666342 hw_loss 0.090097 lr 0.00036183 rank 4
2023-02-22 19:30:25,140 DEBUG TRAIN Batch 22/7600 loss 5.211941 loss_att 6.839046 loss_ctc 7.400947 loss_rnnt 4.505040 hw_loss 0.168021 lr 0.00036173 rank 0
2023-02-22 19:30:25,141 DEBUG TRAIN Batch 22/7600 loss 6.589958 loss_att 7.390339 loss_ctc 9.191990 loss_rnnt 5.954914 hw_loss 0.240056 lr 0.00036173 rank 4
2023-02-22 19:30:25,142 DEBUG TRAIN Batch 22/7600 loss 6.145247 loss_att 10.313082 loss_ctc 11.356344 loss_rnnt 4.588659 hw_loss 0.052889 lr 0.00036171 rank 7
2023-02-22 19:30:25,147 DEBUG TRAIN Batch 22/7600 loss 7.106482 loss_att 8.873841 loss_ctc 10.182478 loss_rnnt 6.318039 hw_loss 0.046572 lr 0.00036172 rank 5
2023-02-22 19:30:25,150 DEBUG TRAIN Batch 22/7600 loss 5.362932 loss_att 9.793440 loss_ctc 8.316727 loss_rnnt 4.022732 hw_loss 0.112986 lr 0.00036172 rank 1
2023-02-22 19:30:25,150 DEBUG TRAIN Batch 22/7600 loss 5.796414 loss_att 8.030273 loss_ctc 9.555140 loss_rnnt 4.778805 hw_loss 0.130638 lr 0.00036168 rank 3
2023-02-22 19:30:25,151 DEBUG TRAIN Batch 22/7600 loss 5.073966 loss_att 7.060799 loss_ctc 8.233423 loss_rnnt 4.222412 hw_loss 0.061739 lr 0.00036174 rank 6
2023-02-22 19:30:25,195 DEBUG TRAIN Batch 22/7600 loss 8.463204 loss_att 11.552674 loss_ctc 10.047452 loss_rnnt 7.614612 hw_loss 0.036497 lr 0.00036166 rank 2
2023-02-22 19:31:41,155 DEBUG TRAIN Batch 22/7700 loss 15.173920 loss_att 15.867891 loss_ctc 16.831678 loss_rnnt 14.780508 hw_loss 0.062972 lr 0.00036161 rank 7
2023-02-22 19:31:41,158 DEBUG TRAIN Batch 22/7700 loss 11.460398 loss_att 13.786577 loss_ctc 12.999965 loss_rnnt 10.777400 hw_loss 0.023412 lr 0.00036163 rank 5
2023-02-22 19:31:41,160 DEBUG TRAIN Batch 22/7700 loss 9.225273 loss_att 11.254954 loss_ctc 12.149988 loss_rnnt 8.348856 hw_loss 0.150974 lr 0.00036162 rank 1
2023-02-22 19:31:41,160 DEBUG TRAIN Batch 22/7700 loss 8.927599 loss_att 14.291445 loss_ctc 17.091152 loss_rnnt 6.709174 hw_loss 0.107217 lr 0.00036164 rank 0
2023-02-22 19:31:41,161 DEBUG TRAIN Batch 22/7700 loss 7.580535 loss_att 10.922295 loss_ctc 12.011045 loss_rnnt 6.267963 hw_loss 0.100284 lr 0.00036164 rank 4
2023-02-22 19:31:41,163 DEBUG TRAIN Batch 22/7700 loss 11.515059 loss_att 15.438891 loss_ctc 13.167139 loss_rnnt 10.473867 hw_loss 0.067774 lr 0.00036164 rank 6
2023-02-22 19:31:41,171 DEBUG TRAIN Batch 22/7700 loss 5.598311 loss_att 7.344370 loss_ctc 6.803405 loss_rnnt 5.066607 hw_loss 0.040898 lr 0.00036156 rank 2
2023-02-22 19:31:41,211 DEBUG TRAIN Batch 22/7700 loss 9.172701 loss_att 11.196051 loss_ctc 9.303427 loss_rnnt 8.724935 hw_loss 0.048122 lr 0.00036159 rank 3
2023-02-22 19:32:57,656 DEBUG TRAIN Batch 22/7800 loss 14.317415 loss_att 15.651007 loss_ctc 29.509232 loss_rnnt 12.010352 hw_loss 0.027695 lr 0.00036154 rank 4
2023-02-22 19:32:57,659 DEBUG TRAIN Batch 22/7800 loss 14.715494 loss_att 17.353849 loss_ctc 18.595779 loss_rnnt 13.646833 hw_loss 0.044284 lr 0.00036154 rank 0
2023-02-22 19:32:57,662 DEBUG TRAIN Batch 22/7800 loss 7.192248 loss_att 9.092667 loss_ctc 6.220225 loss_rnnt 6.910296 hw_loss 0.059008 lr 0.00036153 rank 5
2023-02-22 19:32:57,664 DEBUG TRAIN Batch 22/7800 loss 10.379351 loss_att 15.986993 loss_ctc 12.234392 loss_rnnt 8.972969 hw_loss 0.070337 lr 0.00036152 rank 7
2023-02-22 19:32:57,669 DEBUG TRAIN Batch 22/7800 loss 5.311238 loss_att 7.600362 loss_ctc 4.543243 loss_rnnt 4.931647 hw_loss 0.045312 lr 0.00036155 rank 6
2023-02-22 19:32:57,669 DEBUG TRAIN Batch 22/7800 loss 5.624909 loss_att 8.098570 loss_ctc 7.868014 loss_rnnt 4.815221 hw_loss 0.029766 lr 0.00036153 rank 1
2023-02-22 19:32:57,670 DEBUG TRAIN Batch 22/7800 loss 10.810153 loss_att 14.267376 loss_ctc 11.826445 loss_rnnt 9.942957 hw_loss 0.075463 lr 0.00036147 rank 2
2023-02-22 19:32:57,671 DEBUG TRAIN Batch 22/7800 loss 4.488319 loss_att 6.965404 loss_ctc 4.433774 loss_rnnt 3.874180 hw_loss 0.236240 lr 0.00036149 rank 3
2023-02-22 19:34:14,221 DEBUG TRAIN Batch 22/7900 loss 15.219360 loss_att 19.901953 loss_ctc 24.334049 loss_rnnt 13.046829 hw_loss 0.038853 lr 0.00036145 rank 0
2023-02-22 19:34:14,223 DEBUG TRAIN Batch 22/7900 loss 5.151242 loss_att 9.273578 loss_ctc 7.538675 loss_rnnt 3.916996 hw_loss 0.171476 lr 0.00036144 rank 5
2023-02-22 19:34:14,225 DEBUG TRAIN Batch 22/7900 loss 5.838440 loss_att 8.385333 loss_ctc 7.930064 loss_rnnt 4.960549 hw_loss 0.168055 lr 0.00036143 rank 7
2023-02-22 19:34:14,225 DEBUG TRAIN Batch 22/7900 loss 5.046857 loss_att 7.165353 loss_ctc 7.915039 loss_rnnt 4.168936 hw_loss 0.134619 lr 0.00036144 rank 1
2023-02-22 19:34:14,227 DEBUG TRAIN Batch 22/7900 loss 6.874872 loss_att 9.321774 loss_ctc 9.701580 loss_rnnt 5.934524 hw_loss 0.138889 lr 0.00036145 rank 4
2023-02-22 19:34:14,229 DEBUG TRAIN Batch 22/7900 loss 3.718064 loss_att 6.708873 loss_ctc 7.794640 loss_rnnt 2.527645 hw_loss 0.091338 lr 0.00036145 rank 6
2023-02-22 19:34:14,233 DEBUG TRAIN Batch 22/7900 loss 2.799248 loss_att 4.564943 loss_ctc 5.049213 loss_rnnt 2.114747 hw_loss 0.058813 lr 0.00036140 rank 3
2023-02-22 19:34:14,281 DEBUG TRAIN Batch 22/7900 loss 6.923728 loss_att 10.281091 loss_ctc 10.414454 loss_rnnt 5.717642 hw_loss 0.129717 lr 0.00036137 rank 2
2023-02-22 19:35:28,170 DEBUG TRAIN Batch 22/8000 loss 11.616226 loss_att 12.696114 loss_ctc 17.635319 loss_rnnt 10.581557 hw_loss 0.030274 lr 0.00036134 rank 1
2023-02-22 19:35:28,171 DEBUG TRAIN Batch 22/8000 loss 5.161750 loss_att 10.572878 loss_ctc 8.348197 loss_rnnt 3.609035 hw_loss 0.085554 lr 0.00036135 rank 0
2023-02-22 19:35:28,171 DEBUG TRAIN Batch 22/8000 loss 6.544584 loss_att 9.925630 loss_ctc 7.520545 loss_rnnt 5.723952 hw_loss 0.026802 lr 0.00036135 rank 4
2023-02-22 19:35:28,174 DEBUG TRAIN Batch 22/8000 loss 5.676822 loss_att 6.695466 loss_ctc 7.489865 loss_rnnt 5.128700 hw_loss 0.192475 lr 0.00036131 rank 3
2023-02-22 19:35:28,174 DEBUG TRAIN Batch 22/8000 loss 10.158972 loss_att 11.439568 loss_ctc 14.531796 loss_rnnt 9.269653 hw_loss 0.094041 lr 0.00036134 rank 5
2023-02-22 19:35:28,175 DEBUG TRAIN Batch 22/8000 loss 4.284969 loss_att 8.285767 loss_ctc 8.246050 loss_rnnt 2.877168 hw_loss 0.149056 lr 0.00036133 rank 7
2023-02-22 19:35:28,177 DEBUG TRAIN Batch 22/8000 loss 16.006033 loss_att 20.800833 loss_ctc 21.208763 loss_rnnt 14.295979 hw_loss 0.107619 lr 0.00036136 rank 6
2023-02-22 19:35:28,178 DEBUG TRAIN Batch 22/8000 loss 7.101307 loss_att 8.681987 loss_ctc 9.781799 loss_rnnt 6.349277 hw_loss 0.147180 lr 0.00036128 rank 2
2023-02-22 19:36:43,464 DEBUG TRAIN Batch 22/8100 loss 10.364965 loss_att 11.690933 loss_ctc 15.700181 loss_rnnt 9.337465 hw_loss 0.095521 lr 0.00036125 rank 5
2023-02-22 19:36:43,467 DEBUG TRAIN Batch 22/8100 loss 3.652044 loss_att 5.859902 loss_ctc 6.523324 loss_rnnt 2.782018 hw_loss 0.085532 lr 0.00036124 rank 7
2023-02-22 19:36:43,469 DEBUG TRAIN Batch 22/8100 loss 2.821841 loss_att 6.388388 loss_ctc 4.348653 loss_rnnt 1.854198 hw_loss 0.095172 lr 0.00036126 rank 0
2023-02-22 19:36:43,469 DEBUG TRAIN Batch 22/8100 loss 6.171888 loss_att 9.731812 loss_ctc 7.315486 loss_rnnt 5.250959 hw_loss 0.105870 lr 0.00036126 rank 4
2023-02-22 19:36:43,470 DEBUG TRAIN Batch 22/8100 loss 2.907986 loss_att 6.242784 loss_ctc 4.972435 loss_rnnt 1.893727 hw_loss 0.135074 lr 0.00036121 rank 3
2023-02-22 19:36:43,476 DEBUG TRAIN Batch 22/8100 loss 8.847929 loss_att 10.860716 loss_ctc 10.944841 loss_rnnt 8.140476 hw_loss 0.047450 lr 0.00036126 rank 6
2023-02-22 19:36:43,486 DEBUG TRAIN Batch 22/8100 loss 8.547056 loss_att 9.078251 loss_ctc 11.376076 loss_rnnt 8.034767 hw_loss 0.054087 lr 0.00036118 rank 2
2023-02-22 19:36:43,517 DEBUG TRAIN Batch 22/8100 loss 5.451818 loss_att 8.147738 loss_ctc 9.445480 loss_rnnt 4.296867 hw_loss 0.156147 lr 0.00036125 rank 1
2023-02-22 19:37:59,738 DEBUG TRAIN Batch 22/8200 loss 9.559279 loss_att 12.072848 loss_ctc 15.378815 loss_rnnt 8.244176 hw_loss 0.068348 lr 0.00036116 rank 5
2023-02-22 19:37:59,739 DEBUG TRAIN Batch 22/8200 loss 6.651476 loss_att 9.830076 loss_ctc 11.382018 loss_rnnt 5.357133 hw_loss 0.052282 lr 0.00036109 rank 2
2023-02-22 19:37:59,741 DEBUG TRAIN Batch 22/8200 loss 10.654654 loss_att 12.259998 loss_ctc 14.899542 loss_rnnt 9.668346 hw_loss 0.186099 lr 0.00036114 rank 7
2023-02-22 19:37:59,742 DEBUG TRAIN Batch 22/8200 loss 9.745524 loss_att 11.419087 loss_ctc 14.532390 loss_rnnt 8.716166 hw_loss 0.105744 lr 0.00036116 rank 0
2023-02-22 19:37:59,745 DEBUG TRAIN Batch 22/8200 loss 11.731503 loss_att 13.075592 loss_ctc 17.137772 loss_rnnt 10.687634 hw_loss 0.101649 lr 0.00036116 rank 4
2023-02-22 19:37:59,745 DEBUG TRAIN Batch 22/8200 loss 8.041844 loss_att 11.116334 loss_ctc 13.534320 loss_rnnt 6.644151 hw_loss 0.094621 lr 0.00036117 rank 6
2023-02-22 19:37:59,745 DEBUG TRAIN Batch 22/8200 loss 6.667008 loss_att 11.123429 loss_ctc 11.140922 loss_rnnt 5.144098 hw_loss 0.065819 lr 0.00036115 rank 1
2023-02-22 19:37:59,788 DEBUG TRAIN Batch 22/8200 loss 8.927091 loss_att 10.725482 loss_ctc 12.692315 loss_rnnt 7.974064 hw_loss 0.171221 lr 0.00036112 rank 3
2023-02-22 19:39:12,741 DEBUG TRAIN Batch 22/8300 loss 12.299325 loss_att 14.913898 loss_ctc 20.475319 loss_rnnt 10.621588 hw_loss 0.121295 lr 0.00036107 rank 0
2023-02-22 19:39:12,742 DEBUG TRAIN Batch 22/8300 loss 4.577672 loss_att 5.372795 loss_ctc 4.189186 loss_rnnt 4.449210 hw_loss 0.039819 lr 0.00036108 rank 6
2023-02-22 19:39:12,742 DEBUG TRAIN Batch 22/8300 loss 6.192963 loss_att 11.172001 loss_ctc 7.593555 loss_rnnt 4.955564 hw_loss 0.102837 lr 0.00036107 rank 4
2023-02-22 19:39:12,744 DEBUG TRAIN Batch 22/8300 loss 9.254166 loss_att 14.591133 loss_ctc 11.448401 loss_rnnt 7.885296 hw_loss 0.016707 lr 0.00036106 rank 5
2023-02-22 19:39:12,746 DEBUG TRAIN Batch 22/8300 loss 8.624468 loss_att 11.380438 loss_ctc 10.650395 loss_rnnt 7.797658 hw_loss 0.010297 lr 0.00036105 rank 7
2023-02-22 19:39:12,747 DEBUG TRAIN Batch 22/8300 loss 9.467772 loss_att 15.084972 loss_ctc 14.952580 loss_rnnt 7.565230 hw_loss 0.089615 lr 0.00036106 rank 1
2023-02-22 19:39:12,750 DEBUG TRAIN Batch 22/8300 loss 10.716401 loss_att 12.103322 loss_ctc 16.653835 loss_rnnt 9.640436 hw_loss 0.012979 lr 0.00036100 rank 2
2023-02-22 19:39:12,752 DEBUG TRAIN Batch 22/8300 loss 12.158067 loss_att 16.274628 loss_ctc 20.429995 loss_rnnt 10.180429 hw_loss 0.096379 lr 0.00036102 rank 3
2023-02-22 19:39:58,571 DEBUG CV Batch 22/0 loss 1.725864 loss_att 1.895899 loss_ctc 2.209029 loss_rnnt 1.516359 hw_loss 0.208268 history loss 1.661943 rank 7
2023-02-22 19:39:58,572 DEBUG CV Batch 22/0 loss 1.725864 loss_att 1.895899 loss_ctc 2.209029 loss_rnnt 1.516359 hw_loss 0.208268 history loss 1.661943 rank 4
2023-02-22 19:39:58,573 DEBUG CV Batch 22/0 loss 1.725864 loss_att 1.895899 loss_ctc 2.209029 loss_rnnt 1.516359 hw_loss 0.208268 history loss 1.661943 rank 3
2023-02-22 19:39:58,576 DEBUG CV Batch 22/0 loss 1.725864 loss_att 1.895899 loss_ctc 2.209029 loss_rnnt 1.516359 hw_loss 0.208268 history loss 1.661943 rank 5
2023-02-22 19:39:58,580 DEBUG CV Batch 22/0 loss 1.725864 loss_att 1.895899 loss_ctc 2.209029 loss_rnnt 1.516359 hw_loss 0.208268 history loss 1.661943 rank 6
2023-02-22 19:39:58,587 DEBUG CV Batch 22/0 loss 1.725864 loss_att 1.895899 loss_ctc 2.209029 loss_rnnt 1.516359 hw_loss 0.208268 history loss 1.661943 rank 1
2023-02-22 19:39:58,591 DEBUG CV Batch 22/0 loss 1.725864 loss_att 1.895899 loss_ctc 2.209029 loss_rnnt 1.516359 hw_loss 0.208268 history loss 1.661943 rank 0
2023-02-22 19:39:58,596 DEBUG CV Batch 22/0 loss 1.725864 loss_att 1.895899 loss_ctc 2.209029 loss_rnnt 1.516359 hw_loss 0.208268 history loss 1.661943 rank 2
2023-02-22 19:40:09,721 DEBUG CV Batch 22/100 loss 7.527480 loss_att 7.389199 loss_ctc 11.743899 loss_rnnt 6.961186 hw_loss 0.059552 history loss 3.343428 rank 4
2023-02-22 19:40:09,736 DEBUG CV Batch 22/100 loss 7.527480 loss_att 7.389199 loss_ctc 11.743899 loss_rnnt 6.961186 hw_loss 0.059552 history loss 3.343428 rank 5
2023-02-22 19:40:09,824 DEBUG CV Batch 22/100 loss 7.527480 loss_att 7.389199 loss_ctc 11.743899 loss_rnnt 6.961186 hw_loss 0.059552 history loss 3.343428 rank 7
2023-02-22 19:40:09,889 DEBUG CV Batch 22/100 loss 7.527480 loss_att 7.389199 loss_ctc 11.743899 loss_rnnt 6.961186 hw_loss 0.059552 history loss 3.343428 rank 6
2023-02-22 19:40:09,909 DEBUG CV Batch 22/100 loss 7.527480 loss_att 7.389199 loss_ctc 11.743899 loss_rnnt 6.961186 hw_loss 0.059552 history loss 3.343428 rank 3
2023-02-22 19:40:10,001 DEBUG CV Batch 22/100 loss 7.527480 loss_att 7.389199 loss_ctc 11.743899 loss_rnnt 6.961186 hw_loss 0.059552 history loss 3.343428 rank 0
2023-02-22 19:40:10,038 DEBUG CV Batch 22/100 loss 7.527480 loss_att 7.389199 loss_ctc 11.743899 loss_rnnt 6.961186 hw_loss 0.059552 history loss 3.343428 rank 2
2023-02-22 19:40:10,339 DEBUG CV Batch 22/100 loss 7.527480 loss_att 7.389199 loss_ctc 11.743899 loss_rnnt 6.961186 hw_loss 0.059552 history loss 3.343428 rank 1
2023-02-22 19:40:23,087 DEBUG CV Batch 22/200 loss 6.616109 loss_att 10.062894 loss_ctc 5.628378 loss_rnnt 5.984102 hw_loss 0.139400 history loss 3.888717 rank 4
2023-02-22 19:40:23,161 DEBUG CV Batch 22/200 loss 6.616109 loss_att 10.062894 loss_ctc 5.628378 loss_rnnt 5.984102 hw_loss 0.139400 history loss 3.888717 rank 5
2023-02-22 19:40:23,191 DEBUG CV Batch 22/200 loss 6.616109 loss_att 10.062894 loss_ctc 5.628378 loss_rnnt 5.984102 hw_loss 0.139400 history loss 3.888717 rank 7
2023-02-22 19:40:23,370 DEBUG CV Batch 22/200 loss 6.616109 loss_att 10.062894 loss_ctc 5.628378 loss_rnnt 5.984102 hw_loss 0.139400 history loss 3.888717 rank 6
2023-02-22 19:40:23,420 DEBUG CV Batch 22/200 loss 6.616109 loss_att 10.062894 loss_ctc 5.628378 loss_rnnt 5.984102 hw_loss 0.139400 history loss 3.888717 rank 3
2023-02-22 19:40:23,474 DEBUG CV Batch 22/200 loss 6.616109 loss_att 10.062894 loss_ctc 5.628378 loss_rnnt 5.984102 hw_loss 0.139400 history loss 3.888717 rank 0
2023-02-22 19:40:23,496 DEBUG CV Batch 22/200 loss 6.616109 loss_att 10.062894 loss_ctc 5.628378 loss_rnnt 5.984102 hw_loss 0.139400 history loss 3.888717 rank 2
2023-02-22 19:40:24,013 DEBUG CV Batch 22/200 loss 6.616109 loss_att 10.062894 loss_ctc 5.628378 loss_rnnt 5.984102 hw_loss 0.139400 history loss 3.888717 rank 1
2023-02-22 19:40:35,137 DEBUG CV Batch 22/300 loss 5.487717 loss_att 5.844813 loss_ctc 7.731771 loss_rnnt 5.028912 hw_loss 0.165337 history loss 4.104035 rank 4
2023-02-22 19:40:35,253 DEBUG CV Batch 22/300 loss 5.487717 loss_att 5.844813 loss_ctc 7.731771 loss_rnnt 5.028912 hw_loss 0.165337 history loss 4.104035 rank 5
2023-02-22 19:40:35,304 DEBUG CV Batch 22/300 loss 5.487717 loss_att 5.844813 loss_ctc 7.731771 loss_rnnt 5.028912 hw_loss 0.165337 history loss 4.104035 rank 7
2023-02-22 19:40:35,552 DEBUG CV Batch 22/300 loss 5.487717 loss_att 5.844813 loss_ctc 7.731771 loss_rnnt 5.028912 hw_loss 0.165337 history loss 4.104035 rank 0
2023-02-22 19:40:35,617 DEBUG CV Batch 22/300 loss 5.487717 loss_att 5.844813 loss_ctc 7.731771 loss_rnnt 5.028912 hw_loss 0.165337 history loss 4.104035 rank 3
2023-02-22 19:40:35,624 DEBUG CV Batch 22/300 loss 5.487717 loss_att 5.844813 loss_ctc 7.731771 loss_rnnt 5.028912 hw_loss 0.165337 history loss 4.104035 rank 6
2023-02-22 19:40:35,697 DEBUG CV Batch 22/300 loss 5.487717 loss_att 5.844813 loss_ctc 7.731771 loss_rnnt 5.028912 hw_loss 0.165337 history loss 4.104035 rank 2
2023-02-22 19:40:36,223 DEBUG CV Batch 22/300 loss 5.487717 loss_att 5.844813 loss_ctc 7.731771 loss_rnnt 5.028912 hw_loss 0.165337 history loss 4.104035 rank 1
2023-02-22 19:40:47,194 DEBUG CV Batch 22/400 loss 23.047483 loss_att 101.412903 loss_ctc 13.045421 loss_rnnt 8.691483 hw_loss 0.030987 history loss 5.061790 rank 4
2023-02-22 19:40:47,358 DEBUG CV Batch 22/400 loss 23.047483 loss_att 101.412903 loss_ctc 13.045421 loss_rnnt 8.691483 hw_loss 0.030987 history loss 5.061790 rank 5
2023-02-22 19:40:47,374 DEBUG CV Batch 22/400 loss 23.047483 loss_att 101.412903 loss_ctc 13.045421 loss_rnnt 8.691483 hw_loss 0.030987 history loss 5.061790 rank 7
2023-02-22 19:40:47,625 DEBUG CV Batch 22/400 loss 23.047483 loss_att 101.412903 loss_ctc 13.045421 loss_rnnt 8.691483 hw_loss 0.030987 history loss 5.061790 rank 0
2023-02-22 19:40:47,774 DEBUG CV Batch 22/400 loss 23.047483 loss_att 101.412903 loss_ctc 13.045421 loss_rnnt 8.691483 hw_loss 0.030987 history loss 5.061790 rank 6
2023-02-22 19:40:47,896 DEBUG CV Batch 22/400 loss 23.047483 loss_att 101.412903 loss_ctc 13.045421 loss_rnnt 8.691483 hw_loss 0.030987 history loss 5.061790 rank 2
2023-02-22 19:40:48,377 DEBUG CV Batch 22/400 loss 23.047483 loss_att 101.412903 loss_ctc 13.045421 loss_rnnt 8.691483 hw_loss 0.030987 history loss 5.061790 rank 1
2023-02-22 19:40:48,551 DEBUG CV Batch 22/400 loss 23.047483 loss_att 101.412903 loss_ctc 13.045421 loss_rnnt 8.691483 hw_loss 0.030987 history loss 5.061790 rank 3
2023-02-22 19:40:57,753 DEBUG CV Batch 22/500 loss 5.256592 loss_att 5.957485 loss_ctc 7.798909 loss_rnnt 4.706903 hw_loss 0.132253 history loss 5.799435 rank 4
2023-02-22 19:40:57,934 DEBUG CV Batch 22/500 loss 5.256592 loss_att 5.957485 loss_ctc 7.798909 loss_rnnt 4.706903 hw_loss 0.132253 history loss 5.799435 rank 7
2023-02-22 19:40:57,963 DEBUG CV Batch 22/500 loss 5.256592 loss_att 5.957485 loss_ctc 7.798909 loss_rnnt 4.706903 hw_loss 0.132253 history loss 5.799435 rank 5
2023-02-22 19:40:58,082 DEBUG CV Batch 22/500 loss 5.256592 loss_att 5.957485 loss_ctc 7.798909 loss_rnnt 4.706903 hw_loss 0.132253 history loss 5.799435 rank 0
2023-02-22 19:40:58,412 DEBUG CV Batch 22/500 loss 5.256592 loss_att 5.957485 loss_ctc 7.798909 loss_rnnt 4.706903 hw_loss 0.132253 history loss 5.799435 rank 6
2023-02-22 19:40:58,574 DEBUG CV Batch 22/500 loss 5.256592 loss_att 5.957485 loss_ctc 7.798909 loss_rnnt 4.706903 hw_loss 0.132253 history loss 5.799435 rank 2
2023-02-22 19:40:59,109 DEBUG CV Batch 22/500 loss 5.256592 loss_att 5.957485 loss_ctc 7.798909 loss_rnnt 4.706903 hw_loss 0.132253 history loss 5.799435 rank 1
2023-02-22 19:40:59,312 DEBUG CV Batch 22/500 loss 5.256592 loss_att 5.957485 loss_ctc 7.798909 loss_rnnt 4.706903 hw_loss 0.132253 history loss 5.799435 rank 3
2023-02-22 19:41:09,897 DEBUG CV Batch 22/600 loss 5.515988 loss_att 5.931135 loss_ctc 8.375475 loss_rnnt 4.989305 hw_loss 0.116981 history loss 6.707407 rank 4
2023-02-22 19:41:10,012 DEBUG CV Batch 22/600 loss 5.515988 loss_att 5.931135 loss_ctc 8.375475 loss_rnnt 4.989305 hw_loss 0.116981 history loss 6.707407 rank 7
2023-02-22 19:41:10,073 DEBUG CV Batch 22/600 loss 5.515988 loss_att 5.931135 loss_ctc 8.375475 loss_rnnt 4.989305 hw_loss 0.116981 history loss 6.707407 rank 0
2023-02-22 19:41:10,100 DEBUG CV Batch 22/600 loss 5.515988 loss_att 5.931135 loss_ctc 8.375475 loss_rnnt 4.989305 hw_loss 0.116981 history loss 6.707407 rank 5
2023-02-22 19:41:10,559 DEBUG CV Batch 22/600 loss 5.515988 loss_att 5.931135 loss_ctc 8.375475 loss_rnnt 4.989305 hw_loss 0.116981 history loss 6.707407 rank 6
2023-02-22 19:41:10,641 DEBUG CV Batch 22/600 loss 5.515988 loss_att 5.931135 loss_ctc 8.375475 loss_rnnt 4.989305 hw_loss 0.116981 history loss 6.707407 rank 2
2023-02-22 19:41:11,394 DEBUG CV Batch 22/600 loss 5.515988 loss_att 5.931135 loss_ctc 8.375475 loss_rnnt 4.989305 hw_loss 0.116981 history loss 6.707407 rank 1
2023-02-22 19:41:11,551 DEBUG CV Batch 22/600 loss 5.515988 loss_att 5.931135 loss_ctc 8.375475 loss_rnnt 4.989305 hw_loss 0.116981 history loss 6.707407 rank 3
2023-02-22 19:41:21,276 DEBUG CV Batch 22/700 loss 11.813786 loss_att 45.761929 loss_ctc 13.431261 loss_rnnt 4.761850 hw_loss 0.087455 history loss 7.361422 rank 4
2023-02-22 19:41:21,413 DEBUG CV Batch 22/700 loss 11.813786 loss_att 45.761929 loss_ctc 13.431261 loss_rnnt 4.761850 hw_loss 0.087455 history loss 7.361422 rank 7
2023-02-22 19:41:21,491 DEBUG CV Batch 22/700 loss 11.813786 loss_att 45.761929 loss_ctc 13.431261 loss_rnnt 4.761850 hw_loss 0.087455 history loss 7.361422 rank 5
2023-02-22 19:41:21,513 DEBUG CV Batch 22/700 loss 11.813786 loss_att 45.761929 loss_ctc 13.431261 loss_rnnt 4.761850 hw_loss 0.087455 history loss 7.361422 rank 0
2023-02-22 19:41:22,019 DEBUG CV Batch 22/700 loss 11.813786 loss_att 45.761929 loss_ctc 13.431261 loss_rnnt 4.761850 hw_loss 0.087455 history loss 7.361422 rank 6
2023-02-22 19:41:22,113 DEBUG CV Batch 22/700 loss 11.813786 loss_att 45.761929 loss_ctc 13.431261 loss_rnnt 4.761850 hw_loss 0.087455 history loss 7.361422 rank 2
2023-02-22 19:41:22,951 DEBUG CV Batch 22/700 loss 11.813786 loss_att 45.761929 loss_ctc 13.431261 loss_rnnt 4.761850 hw_loss 0.087455 history loss 7.361422 rank 1
2023-02-22 19:41:23,540 DEBUG CV Batch 22/700 loss 11.813786 loss_att 45.761929 loss_ctc 13.431261 loss_rnnt 4.761850 hw_loss 0.087455 history loss 7.361422 rank 3
2023-02-22 19:41:32,479 DEBUG CV Batch 22/800 loss 11.643638 loss_att 10.551240 loss_ctc 17.482403 loss_rnnt 11.053192 hw_loss 0.057043 history loss 6.820737 rank 4
2023-02-22 19:41:32,626 DEBUG CV Batch 22/800 loss 11.643638 loss_att 10.551240 loss_ctc 17.482403 loss_rnnt 11.053192 hw_loss 0.057043 history loss 6.820737 rank 7
2023-02-22 19:41:32,668 DEBUG CV Batch 22/800 loss 11.643638 loss_att 10.551240 loss_ctc 17.482403 loss_rnnt 11.053192 hw_loss 0.057043 history loss 6.820737 rank 0
2023-02-22 19:41:32,792 DEBUG CV Batch 22/800 loss 11.643638 loss_att 10.551240 loss_ctc 17.482403 loss_rnnt 11.053192 hw_loss 0.057043 history loss 6.820737 rank 5
2023-02-22 19:41:33,350 DEBUG CV Batch 22/800 loss 11.643638 loss_att 10.551240 loss_ctc 17.482403 loss_rnnt 11.053192 hw_loss 0.057043 history loss 6.820737 rank 2
2023-02-22 19:41:33,393 DEBUG CV Batch 22/800 loss 11.643638 loss_att 10.551240 loss_ctc 17.482403 loss_rnnt 11.053192 hw_loss 0.057043 history loss 6.820737 rank 6
2023-02-22 19:41:34,322 DEBUG CV Batch 22/800 loss 11.643638 loss_att 10.551240 loss_ctc 17.482403 loss_rnnt 11.053192 hw_loss 0.057043 history loss 6.820737 rank 1
2023-02-22 19:41:35,184 DEBUG CV Batch 22/800 loss 11.643638 loss_att 10.551240 loss_ctc 17.482403 loss_rnnt 11.053192 hw_loss 0.057043 history loss 6.820737 rank 3
2023-02-22 19:41:45,722 DEBUG CV Batch 22/900 loss 14.795903 loss_att 17.976263 loss_ctc 21.891485 loss_rnnt 13.207947 hw_loss 0.010887 history loss 6.616410 rank 4
2023-02-22 19:41:45,915 DEBUG CV Batch 22/900 loss 14.795903 loss_att 17.976263 loss_ctc 21.891485 loss_rnnt 13.207947 hw_loss 0.010887 history loss 6.616410 rank 7
2023-02-22 19:41:45,973 DEBUG CV Batch 22/900 loss 14.795903 loss_att 17.976263 loss_ctc 21.891485 loss_rnnt 13.207947 hw_loss 0.010887 history loss 6.616410 rank 0
2023-02-22 19:41:46,034 DEBUG CV Batch 22/900 loss 14.795903 loss_att 17.976263 loss_ctc 21.891485 loss_rnnt 13.207947 hw_loss 0.010887 history loss 6.616410 rank 5
2023-02-22 19:41:46,786 DEBUG CV Batch 22/900 loss 14.795903 loss_att 17.976263 loss_ctc 21.891485 loss_rnnt 13.207947 hw_loss 0.010887 history loss 6.616410 rank 2
2023-02-22 19:41:47,072 DEBUG CV Batch 22/900 loss 14.795903 loss_att 17.976263 loss_ctc 21.891485 loss_rnnt 13.207947 hw_loss 0.010887 history loss 6.616410 rank 6
2023-02-22 19:41:47,617 DEBUG CV Batch 22/900 loss 14.795903 loss_att 17.976263 loss_ctc 21.891485 loss_rnnt 13.207947 hw_loss 0.010887 history loss 6.616410 rank 1
2023-02-22 19:41:48,609 DEBUG CV Batch 22/900 loss 14.795903 loss_att 17.976263 loss_ctc 21.891485 loss_rnnt 13.207947 hw_loss 0.010887 history loss 6.616410 rank 3
2023-02-22 19:41:57,877 DEBUG CV Batch 22/1000 loss 4.455205 loss_att 5.322819 loss_ctc 4.571773 loss_rnnt 4.224390 hw_loss 0.078284 history loss 6.399948 rank 4
2023-02-22 19:41:58,111 DEBUG CV Batch 22/1000 loss 4.455205 loss_att 5.322819 loss_ctc 4.571773 loss_rnnt 4.224390 hw_loss 0.078284 history loss 6.399948 rank 0
2023-02-22 19:41:58,119 DEBUG CV Batch 22/1000 loss 4.455205 loss_att 5.322819 loss_ctc 4.571773 loss_rnnt 4.224390 hw_loss 0.078284 history loss 6.399948 rank 7
2023-02-22 19:41:58,207 DEBUG CV Batch 22/1000 loss 4.455205 loss_att 5.322819 loss_ctc 4.571773 loss_rnnt 4.224390 hw_loss 0.078284 history loss 6.399948 rank 5
2023-02-22 19:41:59,001 DEBUG CV Batch 22/1000 loss 4.455205 loss_att 5.322819 loss_ctc 4.571773 loss_rnnt 4.224390 hw_loss 0.078284 history loss 6.399948 rank 2
2023-02-22 19:41:59,647 DEBUG CV Batch 22/1000 loss 4.455205 loss_att 5.322819 loss_ctc 4.571773 loss_rnnt 4.224390 hw_loss 0.078284 history loss 6.399948 rank 6
2023-02-22 19:41:59,863 DEBUG CV Batch 22/1000 loss 4.455205 loss_att 5.322819 loss_ctc 4.571773 loss_rnnt 4.224390 hw_loss 0.078284 history loss 6.399948 rank 1
2023-02-22 19:42:01,138 DEBUG CV Batch 22/1000 loss 4.455205 loss_att 5.322819 loss_ctc 4.571773 loss_rnnt 4.224390 hw_loss 0.078284 history loss 6.399948 rank 3
2023-02-22 19:42:09,788 DEBUG CV Batch 22/1100 loss 5.771846 loss_att 5.535386 loss_ctc 8.209640 loss_rnnt 5.399818 hw_loss 0.176777 history loss 6.389022 rank 4
2023-02-22 19:42:10,014 DEBUG CV Batch 22/1100 loss 5.771846 loss_att 5.535386 loss_ctc 8.209640 loss_rnnt 5.399818 hw_loss 0.176777 history loss 6.389022 rank 0
2023-02-22 19:42:10,036 DEBUG CV Batch 22/1100 loss 5.771846 loss_att 5.535386 loss_ctc 8.209640 loss_rnnt 5.399818 hw_loss 0.176777 history loss 6.389022 rank 7
2023-02-22 19:42:10,118 DEBUG CV Batch 22/1100 loss 5.771846 loss_att 5.535386 loss_ctc 8.209640 loss_rnnt 5.399818 hw_loss 0.176777 history loss 6.389022 rank 5
2023-02-22 19:42:10,870 DEBUG CV Batch 22/1100 loss 5.771846 loss_att 5.535386 loss_ctc 8.209640 loss_rnnt 5.399818 hw_loss 0.176777 history loss 6.389022 rank 2
2023-02-22 19:42:11,761 DEBUG CV Batch 22/1100 loss 5.771846 loss_att 5.535386 loss_ctc 8.209640 loss_rnnt 5.399818 hw_loss 0.176777 history loss 6.389022 rank 1
2023-02-22 19:42:12,315 DEBUG CV Batch 22/1100 loss 5.771846 loss_att 5.535386 loss_ctc 8.209640 loss_rnnt 5.399818 hw_loss 0.176777 history loss 6.389022 rank 6
2023-02-22 19:42:13,202 DEBUG CV Batch 22/1100 loss 5.771846 loss_att 5.535386 loss_ctc 8.209640 loss_rnnt 5.399818 hw_loss 0.176777 history loss 6.389022 rank 3
2023-02-22 19:42:20,301 DEBUG CV Batch 22/1200 loss 8.981857 loss_att 9.160169 loss_ctc 13.252978 loss_rnnt 8.356370 hw_loss 0.038143 history loss 6.710501 rank 4
2023-02-22 19:42:20,448 DEBUG CV Batch 22/1200 loss 8.981857 loss_att 9.160169 loss_ctc 13.252978 loss_rnnt 8.356370 hw_loss 0.038143 history loss 6.710501 rank 0
2023-02-22 19:42:20,639 DEBUG CV Batch 22/1200 loss 8.981857 loss_att 9.160169 loss_ctc 13.252978 loss_rnnt 8.356370 hw_loss 0.038143 history loss 6.710501 rank 7
2023-02-22 19:42:20,768 DEBUG CV Batch 22/1200 loss 8.981857 loss_att 9.160169 loss_ctc 13.252978 loss_rnnt 8.356370 hw_loss 0.038143 history loss 6.710501 rank 5
2023-02-22 19:42:21,508 DEBUG CV Batch 22/1200 loss 8.981857 loss_att 9.160169 loss_ctc 13.252978 loss_rnnt 8.356370 hw_loss 0.038143 history loss 6.710501 rank 2
2023-02-22 19:42:22,519 DEBUG CV Batch 22/1200 loss 8.981857 loss_att 9.160169 loss_ctc 13.252978 loss_rnnt 8.356370 hw_loss 0.038143 history loss 6.710501 rank 1
2023-02-22 19:42:23,019 DEBUG CV Batch 22/1200 loss 8.981857 loss_att 9.160169 loss_ctc 13.252978 loss_rnnt 8.356370 hw_loss 0.038143 history loss 6.710501 rank 6
2023-02-22 19:42:24,211 DEBUG CV Batch 22/1200 loss 8.981857 loss_att 9.160169 loss_ctc 13.252978 loss_rnnt 8.356370 hw_loss 0.038143 history loss 6.710501 rank 3
2023-02-22 19:42:32,320 DEBUG CV Batch 22/1300 loss 4.930577 loss_att 5.732990 loss_ctc 7.856099 loss_rnnt 4.306018 hw_loss 0.138763 history loss 7.010181 rank 4
2023-02-22 19:42:32,365 DEBUG CV Batch 22/1300 loss 4.930577 loss_att 5.732990 loss_ctc 7.856099 loss_rnnt 4.306018 hw_loss 0.138763 history loss 7.010181 rank 0
2023-02-22 19:42:32,512 DEBUG CV Batch 22/1300 loss 4.930577 loss_att 5.732990 loss_ctc 7.856099 loss_rnnt 4.306018 hw_loss 0.138763 history loss 7.010181 rank 7
2023-02-22 19:42:32,736 DEBUG CV Batch 22/1300 loss 4.930577 loss_att 5.732990 loss_ctc 7.856099 loss_rnnt 4.306018 hw_loss 0.138763 history loss 7.010181 rank 5
2023-02-22 19:42:33,536 DEBUG CV Batch 22/1300 loss 4.930577 loss_att 5.732990 loss_ctc 7.856099 loss_rnnt 4.306018 hw_loss 0.138763 history loss 7.010181 rank 2
2023-02-22 19:42:35,069 DEBUG CV Batch 22/1300 loss 4.930577 loss_att 5.732990 loss_ctc 7.856099 loss_rnnt 4.306018 hw_loss 0.138763 history loss 7.010181 rank 6
2023-02-22 19:42:35,216 DEBUG CV Batch 22/1300 loss 4.930577 loss_att 5.732990 loss_ctc 7.856099 loss_rnnt 4.306018 hw_loss 0.138763 history loss 7.010181 rank 1
2023-02-22 19:42:36,428 DEBUG CV Batch 22/1300 loss 4.930577 loss_att 5.732990 loss_ctc 7.856099 loss_rnnt 4.306018 hw_loss 0.138763 history loss 7.010181 rank 3
2023-02-22 19:42:43,474 DEBUG CV Batch 22/1400 loss 7.559985 loss_att 22.312269 loss_ctc 6.542071 loss_rnnt 4.686481 hw_loss 0.110192 history loss 7.328200 rank 4
2023-02-22 19:42:43,579 DEBUG CV Batch 22/1400 loss 7.559985 loss_att 22.312269 loss_ctc 6.542071 loss_rnnt 4.686481 hw_loss 0.110192 history loss 7.328200 rank 0
2023-02-22 19:42:43,704 DEBUG CV Batch 22/1400 loss 7.559985 loss_att 22.312269 loss_ctc 6.542071 loss_rnnt 4.686481 hw_loss 0.110192 history loss 7.328200 rank 7
2023-02-22 19:42:43,950 DEBUG CV Batch 22/1400 loss 7.559985 loss_att 22.312269 loss_ctc 6.542071 loss_rnnt 4.686481 hw_loss 0.110192 history loss 7.328200 rank 5
2023-02-22 19:42:44,834 DEBUG CV Batch 22/1400 loss 7.559985 loss_att 22.312269 loss_ctc 6.542071 loss_rnnt 4.686481 hw_loss 0.110192 history loss 7.328200 rank 2
2023-02-22 19:42:46,355 DEBUG CV Batch 22/1400 loss 7.559985 loss_att 22.312269 loss_ctc 6.542071 loss_rnnt 4.686481 hw_loss 0.110192 history loss 7.328200 rank 6
2023-02-22 19:42:47,307 DEBUG CV Batch 22/1400 loss 7.559985 loss_att 22.312269 loss_ctc 6.542071 loss_rnnt 4.686481 hw_loss 0.110192 history loss 7.328200 rank 1
2023-02-22 19:42:47,861 DEBUG CV Batch 22/1400 loss 7.559985 loss_att 22.312269 loss_ctc 6.542071 loss_rnnt 4.686481 hw_loss 0.110192 history loss 7.328200 rank 3
2023-02-22 19:42:54,953 DEBUG CV Batch 22/1500 loss 6.402660 loss_att 6.857441 loss_ctc 5.816097 loss_rnnt 6.360784 hw_loss 0.054616 history loss 7.148220 rank 4
2023-02-22 19:42:55,016 DEBUG CV Batch 22/1500 loss 6.402660 loss_att 6.857441 loss_ctc 5.816097 loss_rnnt 6.360784 hw_loss 0.054616 history loss 7.148220 rank 0
2023-02-22 19:42:55,151 DEBUG CV Batch 22/1500 loss 6.402660 loss_att 6.857441 loss_ctc 5.816097 loss_rnnt 6.360784 hw_loss 0.054616 history loss 7.148220 rank 7
2023-02-22 19:42:55,418 DEBUG CV Batch 22/1500 loss 6.402660 loss_att 6.857441 loss_ctc 5.816097 loss_rnnt 6.360784 hw_loss 0.054616 history loss 7.148220 rank 5
2023-02-22 19:42:56,400 DEBUG CV Batch 22/1500 loss 6.402660 loss_att 6.857441 loss_ctc 5.816097 loss_rnnt 6.360784 hw_loss 0.054616 history loss 7.148220 rank 2
2023-02-22 19:42:57,926 DEBUG CV Batch 22/1500 loss 6.402660 loss_att 6.857441 loss_ctc 5.816097 loss_rnnt 6.360784 hw_loss 0.054616 history loss 7.148220 rank 6
2023-02-22 19:42:59,170 DEBUG CV Batch 22/1500 loss 6.402660 loss_att 6.857441 loss_ctc 5.816097 loss_rnnt 6.360784 hw_loss 0.054616 history loss 7.148220 rank 1
2023-02-22 19:42:59,323 DEBUG CV Batch 22/1500 loss 6.402660 loss_att 6.857441 loss_ctc 5.816097 loss_rnnt 6.360784 hw_loss 0.054616 history loss 7.148220 rank 3
2023-02-22 19:43:07,933 DEBUG CV Batch 22/1600 loss 8.995254 loss_att 12.600808 loss_ctc 8.066577 loss_rnnt 8.369354 hw_loss 0.053647 history loss 7.074526 rank 0
2023-02-22 19:43:07,968 DEBUG CV Batch 22/1600 loss 8.995254 loss_att 12.600808 loss_ctc 8.066577 loss_rnnt 8.369354 hw_loss 0.053647 history loss 7.074526 rank 4
2023-02-22 19:43:08,048 DEBUG CV Batch 22/1600 loss 8.995254 loss_att 12.600808 loss_ctc 8.066577 loss_rnnt 8.369354 hw_loss 0.053647 history loss 7.074526 rank 7
2023-02-22 19:43:08,356 DEBUG CV Batch 22/1600 loss 8.995254 loss_att 12.600808 loss_ctc 8.066577 loss_rnnt 8.369354 hw_loss 0.053647 history loss 7.074526 rank 5
2023-02-22 19:43:09,470 DEBUG CV Batch 22/1600 loss 8.995254 loss_att 12.600808 loss_ctc 8.066577 loss_rnnt 8.369354 hw_loss 0.053647 history loss 7.074526 rank 2
2023-02-22 19:43:11,133 DEBUG CV Batch 22/1600 loss 8.995254 loss_att 12.600808 loss_ctc 8.066577 loss_rnnt 8.369354 hw_loss 0.053647 history loss 7.074526 rank 6
2023-02-22 19:43:12,498 DEBUG CV Batch 22/1600 loss 8.995254 loss_att 12.600808 loss_ctc 8.066577 loss_rnnt 8.369354 hw_loss 0.053647 history loss 7.074526 rank 3
2023-02-22 19:43:12,979 DEBUG CV Batch 22/1600 loss 8.995254 loss_att 12.600808 loss_ctc 8.066577 loss_rnnt 8.369354 hw_loss 0.053647 history loss 7.074526 rank 1
2023-02-22 19:43:20,170 DEBUG CV Batch 22/1700 loss 8.560220 loss_att 8.093239 loss_ctc 11.567921 loss_rnnt 8.183311 hw_loss 0.129898 history loss 6.986283 rank 0
2023-02-22 19:43:20,224 DEBUG CV Batch 22/1700 loss 8.560220 loss_att 8.093239 loss_ctc 11.567921 loss_rnnt 8.183311 hw_loss 0.129898 history loss 6.986283 rank 4
2023-02-22 19:43:20,253 DEBUG CV Batch 22/1700 loss 8.560220 loss_att 8.093239 loss_ctc 11.567921 loss_rnnt 8.183311 hw_loss 0.129898 history loss 6.986283 rank 7
2023-02-22 19:43:20,606 DEBUG CV Batch 22/1700 loss 8.560220 loss_att 8.093239 loss_ctc 11.567921 loss_rnnt 8.183311 hw_loss 0.129898 history loss 6.986283 rank 5
2023-02-22 19:43:21,835 DEBUG CV Batch 22/1700 loss 8.560220 loss_att 8.093239 loss_ctc 11.567921 loss_rnnt 8.183311 hw_loss 0.129898 history loss 6.986283 rank 2
2023-02-22 19:43:23,543 DEBUG CV Batch 22/1700 loss 8.560220 loss_att 8.093239 loss_ctc 11.567921 loss_rnnt 8.183311 hw_loss 0.129898 history loss 6.986283 rank 6
2023-02-22 19:43:24,821 DEBUG CV Batch 22/1700 loss 8.560220 loss_att 8.093239 loss_ctc 11.567921 loss_rnnt 8.183311 hw_loss 0.129898 history loss 6.986283 rank 3
2023-02-22 19:43:25,313 DEBUG CV Batch 22/1700 loss 8.560220 loss_att 8.093239 loss_ctc 11.567921 loss_rnnt 8.183311 hw_loss 0.129898 history loss 6.986283 rank 1
2023-02-22 19:43:29,108 INFO Epoch 22 CV info cv_loss 6.949325391707487
2023-02-22 19:43:29,109 INFO Checkpoint: save to checkpoint exp/2_21_rnnt_bias_loss_2_class_1word_finetune/22.pt
2023-02-22 19:43:29,219 INFO Epoch 22 CV info cv_loss 6.949325390510054
2023-02-22 19:43:29,220 INFO Epoch 23 TRAIN info lr 0.0003610310635753898
2023-02-22 19:43:29,225 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 19:43:29,238 INFO Epoch 22 CV info cv_loss 6.949325390544511
2023-02-22 19:43:29,239 INFO Epoch 23 TRAIN info lr 0.0003610000092849204
2023-02-22 19:43:29,242 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 19:43:29,695 INFO Epoch 22 CV info cv_loss 6.949325390535897
2023-02-22 19:43:29,696 INFO Epoch 23 TRAIN info lr 0.000361026357864718
2023-02-22 19:43:29,701 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 19:43:30,965 INFO Epoch 22 CV info cv_loss 6.9493253898294975
2023-02-22 19:43:30,966 INFO Epoch 23 TRAIN info lr 0.0003609746071886344
2023-02-22 19:43:30,970 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 19:43:31,182 INFO Epoch 23 TRAIN info lr 0.0003610254167446639
2023-02-22 19:43:31,188 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 19:43:32,651 INFO Epoch 22 CV info cv_loss 6.9493253912078385
2023-02-22 19:43:32,652 INFO Epoch 23 TRAIN info lr 0.00036104800565750657
2023-02-22 19:43:32,657 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 19:43:33,962 INFO Epoch 22 CV info cv_loss 6.949325391156151
2023-02-22 19:43:33,963 INFO Epoch 23 TRAIN info lr 0.0003609971865649499
2023-02-22 19:43:33,966 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 19:43:34,433 INFO Epoch 22 CV info cv_loss 6.949325391888395
2023-02-22 19:43:34,435 INFO Epoch 23 TRAIN info lr 0.00036103482827641467
2023-02-22 19:43:34,438 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 19:44:50,660 DEBUG TRAIN Batch 23/0 loss 9.082796 loss_att 8.621674 loss_ctc 11.456409 loss_rnnt 8.802319 hw_loss 0.105413 lr 0.00036105 rank 6
2023-02-22 19:44:50,662 DEBUG TRAIN Batch 23/0 loss 8.470811 loss_att 8.144472 loss_ctc 11.559085 loss_rnnt 8.074842 hw_loss 0.092750 lr 0.00036103 rank 5
2023-02-22 19:44:50,665 DEBUG TRAIN Batch 23/0 loss 7.859587 loss_att 9.301121 loss_ctc 11.011153 loss_rnnt 7.072819 hw_loss 0.146722 lr 0.00036100 rank 7
2023-02-22 19:44:50,666 DEBUG TRAIN Batch 23/0 loss 8.133397 loss_att 8.125175 loss_ctc 10.494784 loss_rnnt 7.728905 hw_loss 0.171158 lr 0.00036100 rank 3
2023-02-22 19:44:50,668 DEBUG TRAIN Batch 23/0 loss 7.918835 loss_att 8.136242 loss_ctc 10.703712 loss_rnnt 7.411950 hw_loss 0.172660 lr 0.00036097 rank 2
2023-02-22 19:44:50,677 DEBUG TRAIN Batch 23/0 loss 6.113092 loss_att 5.394398 loss_ctc 7.580354 loss_rnnt 5.970418 hw_loss 0.170208 lr 0.00036103 rank 1
2023-02-22 19:44:50,692 DEBUG TRAIN Batch 23/0 loss 5.845303 loss_att 6.120452 loss_ctc 7.946456 loss_rnnt 5.425583 hw_loss 0.158504 lr 0.00036103 rank 4
2023-02-22 19:44:50,704 DEBUG TRAIN Batch 23/0 loss 7.279216 loss_att 7.632895 loss_ctc 10.463203 loss_rnnt 6.698644 hw_loss 0.159946 lr 0.00036102 rank 0
2023-02-22 19:46:03,781 DEBUG TRAIN Batch 23/100 loss 13.069413 loss_att 17.982471 loss_ctc 18.379490 loss_rnnt 11.355810 hw_loss 0.043092 lr 0.00036094 rank 1
2023-02-22 19:46:03,783 DEBUG TRAIN Batch 23/100 loss 12.927441 loss_att 13.574791 loss_ctc 16.447208 loss_rnnt 12.317802 hw_loss 0.020372 lr 0.00036095 rank 6
2023-02-22 19:46:03,783 DEBUG TRAIN Batch 23/100 loss 14.060190 loss_att 16.971003 loss_ctc 21.007401 loss_rnnt 12.544116 hw_loss 0.014282 lr 0.00036090 rank 3
2023-02-22 19:46:03,784 DEBUG TRAIN Batch 23/100 loss 7.062464 loss_att 9.550001 loss_ctc 10.559370 loss_rnnt 6.026689 hw_loss 0.135025 lr 0.00036094 rank 4
2023-02-22 19:46:03,785 DEBUG TRAIN Batch 23/100 loss 5.798132 loss_att 9.315634 loss_ctc 10.107499 loss_rnnt 4.510204 hw_loss 0.018462 lr 0.00036091 rank 7
2023-02-22 19:46:03,786 DEBUG TRAIN Batch 23/100 loss 10.104828 loss_att 13.861717 loss_ctc 15.644972 loss_rnnt 8.535038 hw_loss 0.149487 lr 0.00036093 rank 0
2023-02-22 19:46:03,792 DEBUG TRAIN Batch 23/100 loss 3.486018 loss_att 6.628981 loss_ctc 5.839572 loss_rnnt 2.526789 hw_loss 0.031554 lr 0.00036093 rank 5
2023-02-22 19:46:03,794 DEBUG TRAIN Batch 23/100 loss 6.734863 loss_att 9.707412 loss_ctc 8.404952 loss_rnnt 5.854949 hw_loss 0.117611 lr 0.00036088 rank 2
2023-02-22 19:47:17,951 DEBUG TRAIN Batch 23/200 loss 5.271685 loss_att 7.868860 loss_ctc 9.880095 loss_rnnt 4.110038 hw_loss 0.052045 lr 0.00036084 rank 4
2023-02-22 19:47:17,953 DEBUG TRAIN Batch 23/200 loss 3.942611 loss_att 6.459804 loss_ctc 7.334655 loss_rnnt 2.867351 hw_loss 0.224155 lr 0.00036084 rank 0
2023-02-22 19:47:17,956 DEBUG TRAIN Batch 23/200 loss 10.953722 loss_att 15.424682 loss_ctc 12.610525 loss_rnnt 9.801827 hw_loss 0.068991 lr 0.00036086 rank 6
2023-02-22 19:47:17,957 DEBUG TRAIN Batch 23/200 loss 3.089640 loss_att 4.752569 loss_ctc 5.140411 loss_rnnt 2.438813 hw_loss 0.084009 lr 0.00036081 rank 7
2023-02-22 19:47:17,957 DEBUG TRAIN Batch 23/200 loss 11.634667 loss_att 18.993614 loss_ctc 17.915838 loss_rnnt 9.304222 hw_loss 0.039687 lr 0.00036084 rank 5
2023-02-22 19:47:17,960 DEBUG TRAIN Batch 23/200 loss 8.636807 loss_att 13.210495 loss_ctc 12.683285 loss_rnnt 7.160477 hw_loss 0.041368 lr 0.00036085 rank 1
2023-02-22 19:47:17,961 DEBUG TRAIN Batch 23/200 loss 16.344225 loss_att 18.520252 loss_ctc 20.694536 loss_rnnt 15.259570 hw_loss 0.130137 lr 0.00036081 rank 3
2023-02-22 19:47:17,967 DEBUG TRAIN Batch 23/200 loss 19.548302 loss_att 20.663784 loss_ctc 32.283691 loss_rnnt 17.619263 hw_loss 0.014795 lr 0.00036079 rank 2
2023-02-22 19:48:34,039 DEBUG TRAIN Batch 23/300 loss 9.969148 loss_att 12.054600 loss_ctc 14.192556 loss_rnnt 8.944061 hw_loss 0.084141 lr 0.00036074 rank 5
2023-02-22 19:48:34,039 DEBUG TRAIN Batch 23/300 loss 4.795681 loss_att 7.366229 loss_ctc 4.221872 loss_rnnt 4.323955 hw_loss 0.063984 lr 0.00036077 rank 6
2023-02-22 19:48:34,042 DEBUG TRAIN Batch 23/300 loss 4.511446 loss_att 7.758467 loss_ctc 4.894849 loss_rnnt 3.762886 hw_loss 0.090067 lr 0.00036072 rank 7
2023-02-22 19:48:34,043 DEBUG TRAIN Batch 23/300 loss 4.913660 loss_att 7.770348 loss_ctc 7.892342 loss_rnnt 3.945065 hw_loss 0.000188 lr 0.00036075 rank 1
2023-02-22 19:48:34,043 DEBUG TRAIN Batch 23/300 loss 5.922514 loss_att 9.089603 loss_ctc 8.205470 loss_rnnt 4.984492 hw_loss 0.000393 lr 0.00036075 rank 4
2023-02-22 19:48:34,044 DEBUG TRAIN Batch 23/300 loss 8.116355 loss_att 8.371050 loss_ctc 10.507103 loss_rnnt 7.724956 hw_loss 0.040678 lr 0.00036074 rank 0
2023-02-22 19:48:34,048 DEBUG TRAIN Batch 23/300 loss 10.610002 loss_att 12.011215 loss_ctc 14.461031 loss_rnnt 9.802114 hw_loss 0.026575 lr 0.00036069 rank 2
2023-02-22 19:48:34,052 DEBUG TRAIN Batch 23/300 loss 7.976015 loss_att 12.128376 loss_ctc 13.916340 loss_rnnt 6.338561 hw_loss 0.028010 lr 0.00036071 rank 3
2023-02-22 19:49:50,404 DEBUG TRAIN Batch 23/400 loss 12.631970 loss_att 16.576698 loss_ctc 16.385517 loss_rnnt 11.322111 hw_loss 0.038329 lr 0.00036065 rank 4
2023-02-22 19:49:50,404 DEBUG TRAIN Batch 23/400 loss 4.508279 loss_att 7.482551 loss_ctc 6.149267 loss_rnnt 3.629346 hw_loss 0.122400 lr 0.00036062 rank 7
2023-02-22 19:49:50,409 DEBUG TRAIN Batch 23/400 loss 8.013572 loss_att 9.761793 loss_ctc 11.309213 loss_rnnt 7.184713 hw_loss 0.074616 lr 0.00036065 rank 5
2023-02-22 19:49:50,412 DEBUG TRAIN Batch 23/400 loss 9.737245 loss_att 13.085615 loss_ctc 13.309873 loss_rnnt 8.556301 hw_loss 0.065472 lr 0.00036066 rank 1
2023-02-22 19:49:50,412 DEBUG TRAIN Batch 23/400 loss 2.248274 loss_att 4.804026 loss_ctc 5.342987 loss_rnnt 1.289799 hw_loss 0.065055 lr 0.00036065 rank 0
2023-02-22 19:49:50,415 DEBUG TRAIN Batch 23/400 loss 13.782310 loss_att 13.688864 loss_ctc 17.982079 loss_rnnt 13.151585 hw_loss 0.167709 lr 0.00036062 rank 3
2023-02-22 19:49:50,416 DEBUG TRAIN Batch 23/400 loss 7.853865 loss_att 11.753805 loss_ctc 15.340683 loss_rnnt 6.036383 hw_loss 0.073595 lr 0.00036067 rank 6
2023-02-22 19:49:50,420 DEBUG TRAIN Batch 23/400 loss 5.422445 loss_att 6.952071 loss_ctc 8.623543 loss_rnnt 4.634781 hw_loss 0.102987 lr 0.00036060 rank 2
2023-02-22 19:51:05,024 DEBUG TRAIN Batch 23/500 loss 17.111481 loss_att 19.334373 loss_ctc 21.669130 loss_rnnt 15.987918 hw_loss 0.133688 lr 0.00036056 rank 5
2023-02-22 19:51:05,028 DEBUG TRAIN Batch 23/500 loss 3.478744 loss_att 6.722712 loss_ctc 6.630147 loss_rnnt 2.362990 hw_loss 0.087699 lr 0.00036056 rank 4
2023-02-22 19:51:05,029 DEBUG TRAIN Batch 23/500 loss 7.814385 loss_att 9.362885 loss_ctc 9.666821 loss_rnnt 7.219367 hw_loss 0.071864 lr 0.00036050 rank 2
2023-02-22 19:51:05,029 DEBUG TRAIN Batch 23/500 loss 8.444009 loss_att 9.475811 loss_ctc 9.718536 loss_rnnt 8.026180 hw_loss 0.077871 lr 0.00036055 rank 0
2023-02-22 19:51:05,029 DEBUG TRAIN Batch 23/500 loss 13.462605 loss_att 15.959181 loss_ctc 20.989563 loss_rnnt 11.843447 hw_loss 0.217964 lr 0.00036056 rank 1
2023-02-22 19:51:05,034 DEBUG TRAIN Batch 23/500 loss 16.350687 loss_att 17.080532 loss_ctc 22.912792 loss_rnnt 15.318225 hw_loss 0.021647 lr 0.00036053 rank 3
2023-02-22 19:51:05,037 DEBUG TRAIN Batch 23/500 loss 6.527022 loss_att 9.545252 loss_ctc 10.202383 loss_rnnt 5.386928 hw_loss 0.086999 lr 0.00036053 rank 7
2023-02-22 19:51:05,038 DEBUG TRAIN Batch 23/500 loss 11.358532 loss_att 13.854986 loss_ctc 15.085445 loss_rnnt 10.265064 hw_loss 0.182352 lr 0.00036058 rank 6
2023-02-22 19:52:20,953 DEBUG TRAIN Batch 23/600 loss 6.374728 loss_att 8.539818 loss_ctc 10.543786 loss_rnnt 5.344244 hw_loss 0.077983 lr 0.00036044 rank 7
2023-02-22 19:52:20,955 DEBUG TRAIN Batch 23/600 loss 4.957894 loss_att 6.281794 loss_ctc 5.851093 loss_rnnt 4.494578 hw_loss 0.148957 lr 0.00036047 rank 4
2023-02-22 19:52:20,959 DEBUG TRAIN Batch 23/600 loss 7.171498 loss_att 20.838615 loss_ctc 9.739282 loss_rnnt 4.070334 hw_loss 0.047566 lr 0.00036046 rank 0
2023-02-22 19:52:20,960 DEBUG TRAIN Batch 23/600 loss 9.296383 loss_att 11.586123 loss_ctc 10.595335 loss_rnnt 8.614879 hw_loss 0.094431 lr 0.00036046 rank 5
2023-02-22 19:52:20,966 DEBUG TRAIN Batch 23/600 loss 13.533484 loss_att 14.341396 loss_ctc 18.273726 loss_rnnt 12.646277 hw_loss 0.175482 lr 0.00036047 rank 1
2023-02-22 19:52:20,966 DEBUG TRAIN Batch 23/600 loss 9.622646 loss_att 10.560540 loss_ctc 13.873245 loss_rnnt 8.810981 hw_loss 0.107514 lr 0.00036043 rank 3
2023-02-22 19:52:20,967 DEBUG TRAIN Batch 23/600 loss 13.165340 loss_att 15.186020 loss_ctc 19.487303 loss_rnnt 11.888007 hw_loss 0.056754 lr 0.00036041 rank 2
2023-02-22 19:52:21,006 DEBUG TRAIN Batch 23/600 loss 11.156259 loss_att 11.922705 loss_ctc 13.967449 loss_rnnt 10.584887 hw_loss 0.081108 lr 0.00036048 rank 6
2023-02-22 19:53:38,674 DEBUG TRAIN Batch 23/700 loss 8.306255 loss_att 9.376674 loss_ctc 13.500541 loss_rnnt 7.339041 hw_loss 0.113549 lr 0.00036034 rank 7
2023-02-22 19:53:38,675 DEBUG TRAIN Batch 23/700 loss 11.531631 loss_att 13.913401 loss_ctc 15.724704 loss_rnnt 10.480659 hw_loss 0.029139 lr 0.00036037 rank 0
2023-02-22 19:53:38,676 DEBUG TRAIN Batch 23/700 loss 4.701057 loss_att 8.103207 loss_ctc 7.007122 loss_rnnt 3.644128 hw_loss 0.129420 lr 0.00036038 rank 1
2023-02-22 19:53:38,676 DEBUG TRAIN Batch 23/700 loss 6.658804 loss_att 8.204706 loss_ctc 9.747786 loss_rnnt 5.920175 hw_loss 0.032973 lr 0.00036037 rank 4
2023-02-22 19:53:38,680 DEBUG TRAIN Batch 23/700 loss 9.532126 loss_att 11.939717 loss_ctc 14.583387 loss_rnnt 8.346662 hw_loss 0.057083 lr 0.00036034 rank 3
2023-02-22 19:53:38,683 DEBUG TRAIN Batch 23/700 loss 7.206122 loss_att 9.600481 loss_ctc 9.836836 loss_rnnt 6.354370 hw_loss 0.041472 lr 0.00036032 rank 2
2023-02-22 19:53:38,684 DEBUG TRAIN Batch 23/700 loss 6.919996 loss_att 11.135158 loss_ctc 9.772068 loss_rnnt 5.682388 hw_loss 0.026811 lr 0.00036039 rank 6
2023-02-22 19:53:38,694 DEBUG TRAIN Batch 23/700 loss 20.178566 loss_att 21.104410 loss_ctc 27.371750 loss_rnnt 18.955112 hw_loss 0.148488 lr 0.00036037 rank 5
2023-02-22 19:54:54,400 DEBUG TRAIN Batch 23/800 loss 12.408706 loss_att 15.773201 loss_ctc 15.002890 loss_rnnt 11.348885 hw_loss 0.076932 lr 0.00036027 rank 5
2023-02-22 19:54:54,400 DEBUG TRAIN Batch 23/800 loss 6.420806 loss_att 9.061251 loss_ctc 7.707182 loss_rnnt 5.669937 hw_loss 0.096121 lr 0.00036028 rank 4
2023-02-22 19:54:54,405 DEBUG TRAIN Batch 23/800 loss 9.076269 loss_att 11.032063 loss_ctc 12.327300 loss_rnnt 8.220579 hw_loss 0.058237 lr 0.00036025 rank 7
2023-02-22 19:54:54,404 DEBUG TRAIN Batch 23/800 loss 7.221812 loss_att 10.713398 loss_ctc 11.711433 loss_rnnt 5.884964 hw_loss 0.074840 lr 0.00036028 rank 1
2023-02-22 19:54:54,405 DEBUG TRAIN Batch 23/800 loss 10.869512 loss_att 16.022720 loss_ctc 18.065622 loss_rnnt 8.863702 hw_loss 0.029412 lr 0.00036027 rank 0
2023-02-22 19:54:54,408 DEBUG TRAIN Batch 23/800 loss 4.590721 loss_att 9.336666 loss_ctc 8.693716 loss_rnnt 3.090749 hw_loss 0.006970 lr 0.00036030 rank 6
2023-02-22 19:54:54,411 DEBUG TRAIN Batch 23/800 loss 9.112628 loss_att 10.576231 loss_ctc 14.270208 loss_rnnt 8.111272 hw_loss 0.039297 lr 0.00036025 rank 3
2023-02-22 19:54:54,457 DEBUG TRAIN Batch 23/800 loss 3.607353 loss_att 5.448773 loss_ctc 5.215754 loss_rnnt 2.995813 hw_loss 0.054005 lr 0.00036022 rank 2
2023-02-22 19:56:09,864 DEBUG TRAIN Batch 23/900 loss 19.418571 loss_att 20.679420 loss_ctc 24.538967 loss_rnnt 18.410435 hw_loss 0.137337 lr 0.00036016 rank 7
2023-02-22 19:56:09,864 DEBUG TRAIN Batch 23/900 loss 4.192352 loss_att 7.337931 loss_ctc 6.078037 loss_rnnt 3.287249 hw_loss 0.046054 lr 0.00036019 rank 4
2023-02-22 19:56:09,864 DEBUG TRAIN Batch 23/900 loss 9.787452 loss_att 14.213159 loss_ctc 20.342909 loss_rnnt 7.441398 hw_loss 0.100346 lr 0.00036020 rank 6
2023-02-22 19:56:09,865 DEBUG TRAIN Batch 23/900 loss 4.226760 loss_att 5.995334 loss_ctc 5.613606 loss_rnnt 3.631023 hw_loss 0.107079 lr 0.00036018 rank 5
2023-02-22 19:56:09,866 DEBUG TRAIN Batch 23/900 loss 7.315946 loss_att 10.468965 loss_ctc 13.073919 loss_rnnt 5.871908 hw_loss 0.085694 lr 0.00036019 rank 1
2023-02-22 19:56:09,866 DEBUG TRAIN Batch 23/900 loss 7.751976 loss_att 10.097331 loss_ctc 8.582245 loss_rnnt 7.111465 hw_loss 0.113883 lr 0.00036018 rank 0
2023-02-22 19:56:09,868 DEBUG TRAIN Batch 23/900 loss 8.525852 loss_att 14.783978 loss_ctc 12.214645 loss_rnnt 6.727017 hw_loss 0.103820 lr 0.00036013 rank 2
2023-02-22 19:56:09,875 DEBUG TRAIN Batch 23/900 loss 9.556249 loss_att 12.391768 loss_ctc 16.833338 loss_rnnt 7.975224 hw_loss 0.081827 lr 0.00036015 rank 3
2023-02-22 19:57:25,962 DEBUG TRAIN Batch 23/1000 loss 5.445304 loss_att 8.822486 loss_ctc 12.136309 loss_rnnt 3.838401 hw_loss 0.073749 lr 0.00036011 rank 6
2023-02-22 19:57:25,966 DEBUG TRAIN Batch 23/1000 loss 6.142916 loss_att 11.653503 loss_ctc 8.378624 loss_rnnt 4.717802 hw_loss 0.046693 lr 0.00036004 rank 2
2023-02-22 19:57:25,965 DEBUG TRAIN Batch 23/1000 loss 9.474955 loss_att 12.236343 loss_ctc 11.760088 loss_rnnt 8.607842 hw_loss 0.019030 lr 0.00036010 rank 1
2023-02-22 19:57:25,966 DEBUG TRAIN Batch 23/1000 loss 7.843536 loss_att 14.761623 loss_ctc 11.826874 loss_rnnt 5.864693 hw_loss 0.120215 lr 0.00036009 rank 5
2023-02-22 19:57:25,970 DEBUG TRAIN Batch 23/1000 loss 8.822304 loss_att 11.660182 loss_ctc 15.181504 loss_rnnt 7.342456 hw_loss 0.120708 lr 0.00036009 rank 0
2023-02-22 19:57:25,973 DEBUG TRAIN Batch 23/1000 loss 9.239685 loss_att 11.866449 loss_ctc 11.680304 loss_rnnt 8.341656 hw_loss 0.088613 lr 0.00036006 rank 3
2023-02-22 19:57:25,974 DEBUG TRAIN Batch 23/1000 loss 11.871540 loss_att 15.430739 loss_ctc 17.649414 loss_rnnt 10.352469 hw_loss 0.069090 lr 0.00036006 rank 7
2023-02-22 19:57:25,985 DEBUG TRAIN Batch 23/1000 loss 7.331728 loss_att 8.866801 loss_ctc 10.915655 loss_rnnt 6.493546 hw_loss 0.099955 lr 0.00036009 rank 4
2023-02-22 19:58:42,928 DEBUG TRAIN Batch 23/1100 loss 9.963468 loss_att 11.813865 loss_ctc 15.143772 loss_rnnt 8.858896 hw_loss 0.082098 lr 0.00035999 rank 0
2023-02-22 19:58:42,928 DEBUG TRAIN Batch 23/1100 loss 8.753263 loss_att 11.850766 loss_ctc 14.486840 loss_rnnt 7.339132 hw_loss 0.056537 lr 0.00035999 rank 5
2023-02-22 19:58:42,930 DEBUG TRAIN Batch 23/1100 loss 3.077706 loss_att 4.325834 loss_ctc 4.520773 loss_rnnt 2.579621 hw_loss 0.105092 lr 0.00035997 rank 7
2023-02-22 19:58:42,934 DEBUG TRAIN Batch 23/1100 loss 5.964894 loss_att 8.744993 loss_ctc 10.162119 loss_rnnt 4.787511 hw_loss 0.115751 lr 0.00036000 rank 4
2023-02-22 19:58:42,935 DEBUG TRAIN Batch 23/1100 loss 8.471331 loss_att 10.539887 loss_ctc 11.491973 loss_rnnt 7.602024 hw_loss 0.099080 lr 0.00035997 rank 3
2023-02-22 19:58:42,936 DEBUG TRAIN Batch 23/1100 loss 10.242831 loss_att 12.573733 loss_ctc 10.522910 loss_rnnt 9.714336 hw_loss 0.046821 lr 0.00036000 rank 1
2023-02-22 19:58:42,939 DEBUG TRAIN Batch 23/1100 loss 7.800979 loss_att 9.255129 loss_ctc 9.107076 loss_rnnt 7.309117 hw_loss 0.050409 lr 0.00035994 rank 2
2023-02-22 19:58:42,986 DEBUG TRAIN Batch 23/1100 loss 11.109110 loss_att 14.177224 loss_ctc 17.074665 loss_rnnt 9.675580 hw_loss 0.045936 lr 0.00036002 rank 6
2023-02-22 19:59:57,493 DEBUG TRAIN Batch 23/1200 loss 3.925379 loss_att 4.953724 loss_ctc 5.220856 loss_rnnt 3.490886 hw_loss 0.105175 lr 0.00035988 rank 7
2023-02-22 19:59:57,495 DEBUG TRAIN Batch 23/1200 loss 5.621380 loss_att 6.642917 loss_ctc 8.089842 loss_rnnt 4.990142 hw_loss 0.183379 lr 0.00035990 rank 0
2023-02-22 19:59:57,496 DEBUG TRAIN Batch 23/1200 loss 11.799628 loss_att 13.728776 loss_ctc 16.296829 loss_rnnt 10.760219 hw_loss 0.101163 lr 0.00035990 rank 5
2023-02-22 19:59:57,497 DEBUG TRAIN Batch 23/1200 loss 8.107434 loss_att 10.732092 loss_ctc 11.029284 loss_rnnt 7.177819 hw_loss 0.028318 lr 0.00035991 rank 4
2023-02-22 19:59:57,499 DEBUG TRAIN Batch 23/1200 loss 9.405922 loss_att 11.402979 loss_ctc 14.493955 loss_rnnt 8.260911 hw_loss 0.125990 lr 0.00035991 rank 1
2023-02-22 19:59:57,499 DEBUG TRAIN Batch 23/1200 loss 15.311760 loss_att 17.868898 loss_ctc 25.685225 loss_rnnt 13.385880 hw_loss 0.058731 lr 0.00035985 rank 2
2023-02-22 19:59:57,502 DEBUG TRAIN Batch 23/1200 loss 8.580393 loss_att 12.458658 loss_ctc 15.465281 loss_rnnt 6.811567 hw_loss 0.140977 lr 0.00035987 rank 3
2023-02-22 19:59:57,546 DEBUG TRAIN Batch 23/1200 loss 16.527010 loss_att 16.798367 loss_ctc 23.126547 loss_rnnt 15.561709 hw_loss 0.058298 lr 0.00035992 rank 6
2023-02-22 20:01:12,855 DEBUG TRAIN Batch 23/1300 loss 5.970115 loss_att 9.418608 loss_ctc 12.089012 loss_rnnt 4.411832 hw_loss 0.098871 lr 0.00035981 rank 4
2023-02-22 20:01:12,858 DEBUG TRAIN Batch 23/1300 loss 13.309396 loss_att 14.723297 loss_ctc 19.973356 loss_rnnt 12.085083 hw_loss 0.099386 lr 0.00035981 rank 0
2023-02-22 20:01:12,861 DEBUG TRAIN Batch 23/1300 loss 8.915009 loss_att 9.128732 loss_ctc 13.094255 loss_rnnt 8.237606 hw_loss 0.145176 lr 0.00035981 rank 5
2023-02-22 20:01:12,862 DEBUG TRAIN Batch 23/1300 loss 7.797819 loss_att 11.929406 loss_ctc 12.343338 loss_rnnt 6.297721 hw_loss 0.126956 lr 0.00035982 rank 1
2023-02-22 20:01:12,861 DEBUG TRAIN Batch 23/1300 loss 6.358760 loss_att 7.812842 loss_ctc 7.861014 loss_rnnt 5.831450 hw_loss 0.067861 lr 0.00035978 rank 7
2023-02-22 20:01:12,864 DEBUG TRAIN Batch 23/1300 loss 5.667037 loss_att 9.520606 loss_ctc 8.547259 loss_rnnt 4.496892 hw_loss 0.028876 lr 0.00035983 rank 6
2023-02-22 20:01:12,866 DEBUG TRAIN Batch 23/1300 loss 3.804720 loss_att 7.086173 loss_ctc 5.505134 loss_rnnt 2.904787 hw_loss 0.031728 lr 0.00035978 rank 3
2023-02-22 20:01:12,911 DEBUG TRAIN Batch 23/1300 loss 10.405381 loss_att 10.350788 loss_ctc 11.832998 loss_rnnt 10.126304 hw_loss 0.186839 lr 0.00035976 rank 2
2023-02-22 20:02:30,023 DEBUG TRAIN Batch 23/1400 loss 5.484789 loss_att 8.311482 loss_ctc 9.495911 loss_rnnt 4.381070 hw_loss 0.006683 lr 0.00035972 rank 4
2023-02-22 20:02:30,024 DEBUG TRAIN Batch 23/1400 loss 11.725813 loss_att 17.739874 loss_ctc 24.218651 loss_rnnt 8.846580 hw_loss 0.020080 lr 0.00035969 rank 7
2023-02-22 20:02:30,026 DEBUG TRAIN Batch 23/1400 loss 9.562176 loss_att 11.050848 loss_ctc 11.448405 loss_rnnt 8.976514 hw_loss 0.068303 lr 0.00035972 rank 1
2023-02-22 20:02:30,027 DEBUG TRAIN Batch 23/1400 loss 8.218372 loss_att 13.585859 loss_ctc 12.283081 loss_rnnt 6.507225 hw_loss 0.179415 lr 0.00035969 rank 3
2023-02-22 20:02:30,027 DEBUG TRAIN Batch 23/1400 loss 6.941231 loss_att 10.191555 loss_ctc 9.252719 loss_rnnt 5.971951 hw_loss 0.020657 lr 0.00035971 rank 0
2023-02-22 20:02:30,027 DEBUG TRAIN Batch 23/1400 loss 12.014387 loss_att 15.209616 loss_ctc 17.558674 loss_rnnt 10.621501 hw_loss 0.027379 lr 0.00035972 rank 5
2023-02-22 20:02:30,029 DEBUG TRAIN Batch 23/1400 loss 15.152032 loss_att 19.853138 loss_ctc 24.730740 loss_rnnt 12.904068 hw_loss 0.057340 lr 0.00035966 rank 2
2023-02-22 20:02:30,032 DEBUG TRAIN Batch 23/1400 loss 1.945419 loss_att 4.330789 loss_ctc 2.815679 loss_rnnt 1.334432 hw_loss 0.033522 lr 0.00035974 rank 6
2023-02-22 20:03:45,014 DEBUG TRAIN Batch 23/1500 loss 12.876583 loss_att 18.045456 loss_ctc 17.788134 loss_rnnt 11.181743 hw_loss 0.011611 lr 0.00035963 rank 4
2023-02-22 20:03:45,014 DEBUG TRAIN Batch 23/1500 loss 5.574135 loss_att 8.367125 loss_ctc 6.696445 loss_rnnt 4.844278 hw_loss 0.040532 lr 0.00035960 rank 7
2023-02-22 20:03:45,016 DEBUG TRAIN Batch 23/1500 loss 7.762962 loss_att 11.152252 loss_ctc 11.619595 loss_rnnt 6.553512 hw_loss 0.032576 lr 0.00035964 rank 6
2023-02-22 20:03:45,018 DEBUG TRAIN Batch 23/1500 loss 8.391748 loss_att 12.453987 loss_ctc 13.658150 loss_rnnt 6.807385 hw_loss 0.130740 lr 0.00035963 rank 1
2023-02-22 20:03:45,019 DEBUG TRAIN Batch 23/1500 loss 7.959033 loss_att 9.698206 loss_ctc 10.964785 loss_rnnt 7.173260 hw_loss 0.069697 lr 0.00035962 rank 0
2023-02-22 20:03:45,021 DEBUG TRAIN Batch 23/1500 loss 6.897265 loss_att 8.522453 loss_ctc 9.865639 loss_rnnt 6.081642 hw_loss 0.177757 lr 0.00035962 rank 5
2023-02-22 20:03:45,024 DEBUG TRAIN Batch 23/1500 loss 8.819091 loss_att 9.802294 loss_ctc 10.945873 loss_rnnt 8.311492 hw_loss 0.051354 lr 0.00035957 rank 2
2023-02-22 20:03:45,025 DEBUG TRAIN Batch 23/1500 loss 8.130501 loss_att 10.195328 loss_ctc 8.190033 loss_rnnt 7.647962 hw_loss 0.115565 lr 0.00035959 rank 3
2023-02-22 20:05:00,337 DEBUG TRAIN Batch 23/1600 loss 16.053699 loss_att 18.528263 loss_ctc 23.732819 loss_rnnt 14.504531 hw_loss 0.056950 lr 0.00035950 rank 7
2023-02-22 20:05:00,337 DEBUG TRAIN Batch 23/1600 loss 20.265528 loss_att 21.945791 loss_ctc 27.537025 loss_rnnt 18.891975 hw_loss 0.127440 lr 0.00035953 rank 4
2023-02-22 20:05:00,339 DEBUG TRAIN Batch 23/1600 loss 9.862051 loss_att 10.851429 loss_ctc 11.483445 loss_rnnt 9.381776 hw_loss 0.124150 lr 0.00035953 rank 0
2023-02-22 20:05:00,345 DEBUG TRAIN Batch 23/1600 loss 13.709516 loss_att 18.532425 loss_ctc 18.243633 loss_rnnt 12.054327 hw_loss 0.161360 lr 0.00035953 rank 5
2023-02-22 20:05:00,347 DEBUG TRAIN Batch 23/1600 loss 7.294631 loss_att 10.409397 loss_ctc 10.580493 loss_rnnt 6.181717 hw_loss 0.097212 lr 0.00035955 rank 6
2023-02-22 20:05:00,351 DEBUG TRAIN Batch 23/1600 loss 9.297414 loss_att 12.574006 loss_ctc 14.122969 loss_rnnt 7.968436 hw_loss 0.056723 lr 0.00035954 rank 1
2023-02-22 20:05:00,354 DEBUG TRAIN Batch 23/1600 loss 3.874904 loss_att 8.303095 loss_ctc 7.573428 loss_rnnt 2.451901 hw_loss 0.082927 lr 0.00035948 rank 2
2023-02-22 20:05:00,393 DEBUG TRAIN Batch 23/1600 loss 5.837242 loss_att 8.200043 loss_ctc 10.545544 loss_rnnt 4.681173 hw_loss 0.104503 lr 0.00035950 rank 3
2023-02-22 20:06:16,713 DEBUG TRAIN Batch 23/1700 loss 5.508000 loss_att 8.585814 loss_ctc 7.551207 loss_rnnt 4.600163 hw_loss 0.037212 lr 0.00035941 rank 7
2023-02-22 20:06:16,715 DEBUG TRAIN Batch 23/1700 loss 9.765565 loss_att 11.868151 loss_ctc 12.399153 loss_rnnt 8.980909 hw_loss 0.024361 lr 0.00035944 rank 5
2023-02-22 20:06:16,715 DEBUG TRAIN Batch 23/1700 loss 7.932467 loss_att 12.912993 loss_ctc 12.153607 loss_rnnt 6.316965 hw_loss 0.106084 lr 0.00035944 rank 0
2023-02-22 20:06:16,718 DEBUG TRAIN Batch 23/1700 loss 4.459875 loss_att 9.156281 loss_ctc 6.660781 loss_rnnt 3.175224 hw_loss 0.097341 lr 0.00035944 rank 4
2023-02-22 20:06:16,720 DEBUG TRAIN Batch 23/1700 loss 11.425674 loss_att 15.286942 loss_ctc 19.655523 loss_rnnt 9.485876 hw_loss 0.131684 lr 0.00035939 rank 2
2023-02-22 20:06:16,751 DEBUG TRAIN Batch 23/1700 loss 13.853505 loss_att 16.882511 loss_ctc 23.625858 loss_rnnt 11.858672 hw_loss 0.161345 lr 0.00035946 rank 6
2023-02-22 20:06:16,760 DEBUG TRAIN Batch 23/1700 loss 3.986277 loss_att 6.526470 loss_ctc 6.821921 loss_rnnt 3.058074 hw_loss 0.078898 lr 0.00035944 rank 1
2023-02-22 20:06:16,771 DEBUG TRAIN Batch 23/1700 loss 14.010692 loss_att 17.025532 loss_ctc 22.724876 loss_rnnt 12.188267 hw_loss 0.107935 lr 0.00035941 rank 3
2023-02-22 20:07:35,576 DEBUG TRAIN Batch 23/1800 loss 8.365041 loss_att 9.721770 loss_ctc 10.724710 loss_rnnt 7.718670 hw_loss 0.113253 lr 0.00035932 rank 7
2023-02-22 20:07:35,577 DEBUG TRAIN Batch 23/1800 loss 4.055708 loss_att 5.352464 loss_ctc 5.909692 loss_rnnt 3.503198 hw_loss 0.086176 lr 0.00035934 rank 5
2023-02-22 20:07:35,577 DEBUG TRAIN Batch 23/1800 loss 12.869917 loss_att 15.555689 loss_ctc 21.500330 loss_rnnt 11.101511 hw_loss 0.150990 lr 0.00035936 rank 6
2023-02-22 20:07:35,579 DEBUG TRAIN Batch 23/1800 loss 11.140444 loss_att 13.216682 loss_ctc 15.776596 loss_rnnt 10.064050 hw_loss 0.080608 lr 0.00035935 rank 4
2023-02-22 20:07:35,581 DEBUG TRAIN Batch 23/1800 loss 5.109818 loss_att 7.770840 loss_ctc 8.029399 loss_rnnt 4.167089 hw_loss 0.039839 lr 0.00035934 rank 0
2023-02-22 20:07:35,584 DEBUG TRAIN Batch 23/1800 loss 6.456607 loss_att 9.810133 loss_ctc 11.617170 loss_rnnt 5.034454 hw_loss 0.118823 lr 0.00035929 rank 2
2023-02-22 20:07:35,586 DEBUG TRAIN Batch 23/1800 loss 6.684592 loss_att 9.243158 loss_ctc 7.962144 loss_rnnt 5.932295 hw_loss 0.131707 lr 0.00035935 rank 1
2023-02-22 20:07:35,589 DEBUG TRAIN Batch 23/1800 loss 10.868294 loss_att 15.418459 loss_ctc 18.134207 loss_rnnt 8.922411 hw_loss 0.125741 lr 0.00035931 rank 3
2023-02-22 20:08:51,526 DEBUG TRAIN Batch 23/1900 loss 14.194386 loss_att 13.543211 loss_ctc 17.341934 loss_rnnt 13.856521 hw_loss 0.090800 lr 0.00035925 rank 0
2023-02-22 20:08:51,529 DEBUG TRAIN Batch 23/1900 loss 7.677908 loss_att 9.029892 loss_ctc 10.593817 loss_rnnt 6.979142 hw_loss 0.074214 lr 0.00035926 rank 4
2023-02-22 20:08:51,531 DEBUG TRAIN Batch 23/1900 loss 7.132703 loss_att 8.087793 loss_ctc 8.560066 loss_rnnt 6.693523 hw_loss 0.108463 lr 0.00035922 rank 7
2023-02-22 20:08:51,532 DEBUG TRAIN Batch 23/1900 loss 8.096971 loss_att 8.472000 loss_ctc 9.212194 loss_rnnt 7.784258 hw_loss 0.166895 lr 0.00035925 rank 5
2023-02-22 20:08:51,535 DEBUG TRAIN Batch 23/1900 loss 8.279865 loss_att 11.292531 loss_ctc 12.157312 loss_rnnt 7.120116 hw_loss 0.075418 lr 0.00035927 rank 6
2023-02-22 20:08:51,536 DEBUG TRAIN Batch 23/1900 loss 13.998530 loss_att 13.445259 loss_ctc 16.244846 loss_rnnt 13.727522 hw_loss 0.154039 lr 0.00035926 rank 1
2023-02-22 20:08:51,539 DEBUG TRAIN Batch 23/1900 loss 7.573479 loss_att 9.195482 loss_ctc 11.317514 loss_rnnt 6.713680 hw_loss 0.067863 lr 0.00035922 rank 3
2023-02-22 20:08:51,542 DEBUG TRAIN Batch 23/1900 loss 4.908142 loss_att 5.923995 loss_ctc 7.636310 loss_rnnt 4.274473 hw_loss 0.125142 lr 0.00035920 rank 2
2023-02-22 20:10:05,406 DEBUG TRAIN Batch 23/2000 loss 8.946773 loss_att 11.187409 loss_ctc 13.109037 loss_rnnt 7.912402 hw_loss 0.058642 lr 0.00035916 rank 5
2023-02-22 20:10:05,409 DEBUG TRAIN Batch 23/2000 loss 9.873539 loss_att 14.452206 loss_ctc 13.773555 loss_rnnt 8.408234 hw_loss 0.055441 lr 0.00035913 rank 7
2023-02-22 20:10:05,410 DEBUG TRAIN Batch 23/2000 loss 2.760877 loss_att 6.538524 loss_ctc 4.179405 loss_rnnt 1.755495 hw_loss 0.113840 lr 0.00035916 rank 0
2023-02-22 20:10:05,413 DEBUG TRAIN Batch 23/2000 loss 10.710160 loss_att 13.520384 loss_ctc 12.036540 loss_rnnt 9.905337 hw_loss 0.123612 lr 0.00035918 rank 6
2023-02-22 20:10:05,413 DEBUG TRAIN Batch 23/2000 loss 11.846640 loss_att 12.099909 loss_ctc 11.430532 loss_rnnt 11.785093 hw_loss 0.124452 lr 0.00035916 rank 4
2023-02-22 20:10:05,414 DEBUG TRAIN Batch 23/2000 loss 4.906206 loss_att 8.409233 loss_ctc 10.292756 loss_rnnt 3.399522 hw_loss 0.164761 lr 0.00035917 rank 1
2023-02-22 20:10:05,415 DEBUG TRAIN Batch 23/2000 loss 7.995307 loss_att 11.662188 loss_ctc 13.712626 loss_rnnt 6.463663 hw_loss 0.067423 lr 0.00035913 rank 3
2023-02-22 20:10:05,416 DEBUG TRAIN Batch 23/2000 loss 5.835521 loss_att 10.546473 loss_ctc 6.478076 loss_rnnt 4.727049 hw_loss 0.151139 lr 0.00035911 rank 2
2023-02-22 20:11:21,941 DEBUG TRAIN Batch 23/2100 loss 12.924095 loss_att 19.438812 loss_ctc 18.435629 loss_rnnt 10.850562 hw_loss 0.066971 lr 0.00035907 rank 4
2023-02-22 20:11:21,943 DEBUG TRAIN Batch 23/2100 loss 10.132520 loss_att 12.591595 loss_ctc 10.351482 loss_rnnt 9.560795 hw_loss 0.095089 lr 0.00035906 rank 0
2023-02-22 20:11:21,943 DEBUG TRAIN Batch 23/2100 loss 5.738082 loss_att 8.526122 loss_ctc 11.050167 loss_rnnt 4.444376 hw_loss 0.052163 lr 0.00035909 rank 6
2023-02-22 20:11:21,944 DEBUG TRAIN Batch 23/2100 loss 4.373694 loss_att 9.012007 loss_ctc 7.950498 loss_rnnt 2.936741 hw_loss 0.060718 lr 0.00035907 rank 1
2023-02-22 20:11:21,946 DEBUG TRAIN Batch 23/2100 loss 10.421376 loss_att 12.736242 loss_ctc 13.501582 loss_rnnt 9.517782 hw_loss 0.056111 lr 0.00035904 rank 3
2023-02-22 20:11:21,947 DEBUG TRAIN Batch 23/2100 loss 7.319784 loss_att 11.257164 loss_ctc 15.061312 loss_rnnt 5.473629 hw_loss 0.049641 lr 0.00035907 rank 5
2023-02-22 20:11:21,948 DEBUG TRAIN Batch 23/2100 loss 12.109394 loss_att 13.194907 loss_ctc 16.108963 loss_rnnt 11.291592 hw_loss 0.126419 lr 0.00035904 rank 7
2023-02-22 20:11:21,950 DEBUG TRAIN Batch 23/2100 loss 6.666680 loss_att 11.675233 loss_ctc 12.526634 loss_rnnt 4.789606 hw_loss 0.176318 lr 0.00035901 rank 2
2023-02-22 20:12:37,213 DEBUG TRAIN Batch 23/2200 loss 8.816649 loss_att 11.245399 loss_ctc 15.465184 loss_rnnt 7.396756 hw_loss 0.089387 lr 0.00035897 rank 0
2023-02-22 20:12:37,215 DEBUG TRAIN Batch 23/2200 loss 8.066314 loss_att 11.976989 loss_ctc 12.229078 loss_rnnt 6.631834 hw_loss 0.182456 lr 0.00035898 rank 4
2023-02-22 20:12:37,219 DEBUG TRAIN Batch 23/2200 loss 7.829520 loss_att 8.701205 loss_ctc 10.806121 loss_rnnt 7.217690 hw_loss 0.076149 lr 0.00035897 rank 5
2023-02-22 20:12:37,220 DEBUG TRAIN Batch 23/2200 loss 11.398752 loss_att 11.725882 loss_ctc 16.624798 loss_rnnt 10.612397 hw_loss 0.045231 lr 0.00035895 rank 7
2023-02-22 20:12:37,224 DEBUG TRAIN Batch 23/2200 loss 5.589491 loss_att 7.866507 loss_ctc 9.377215 loss_rnnt 4.605635 hw_loss 0.043917 lr 0.00035892 rank 2
2023-02-22 20:12:37,224 DEBUG TRAIN Batch 23/2200 loss 10.617924 loss_att 15.676229 loss_ctc 16.105143 loss_rnnt 8.836760 hw_loss 0.071013 lr 0.00035899 rank 6
2023-02-22 20:12:37,226 DEBUG TRAIN Batch 23/2200 loss 10.582631 loss_att 11.214760 loss_ctc 14.561984 loss_rnnt 9.881987 hw_loss 0.081822 lr 0.00035898 rank 1
2023-02-22 20:12:37,225 DEBUG TRAIN Batch 23/2200 loss 3.630497 loss_att 6.332367 loss_ctc 6.443188 loss_rnnt 2.663972 hw_loss 0.095860 lr 0.00035894 rank 3
2023-02-22 20:13:51,591 DEBUG TRAIN Batch 23/2300 loss 8.765349 loss_att 10.411055 loss_ctc 11.209411 loss_rnnt 8.053799 hw_loss 0.106002 lr 0.00035885 rank 7
2023-02-22 20:13:51,592 DEBUG TRAIN Batch 23/2300 loss 4.512169 loss_att 6.595371 loss_ctc 6.830768 loss_rnnt 3.763934 hw_loss 0.042090 lr 0.00035888 rank 5
2023-02-22 20:13:51,593 DEBUG TRAIN Batch 23/2300 loss 4.600970 loss_att 7.970459 loss_ctc 8.723116 loss_rnnt 3.357331 hw_loss 0.037730 lr 0.00035888 rank 4
2023-02-22 20:13:51,594 DEBUG TRAIN Batch 23/2300 loss 10.405932 loss_att 14.987375 loss_ctc 18.987869 loss_rnnt 8.321280 hw_loss 0.045197 lr 0.00035888 rank 0
2023-02-22 20:13:51,597 DEBUG TRAIN Batch 23/2300 loss 6.164096 loss_att 7.872500 loss_ctc 10.650106 loss_rnnt 5.173540 hw_loss 0.095140 lr 0.00035889 rank 1
2023-02-22 20:13:51,597 DEBUG TRAIN Batch 23/2300 loss 12.523140 loss_att 16.189156 loss_ctc 18.005974 loss_rnnt 11.006893 hw_loss 0.097498 lr 0.00035883 rank 2
2023-02-22 20:13:51,599 DEBUG TRAIN Batch 23/2300 loss 12.072690 loss_att 14.820917 loss_ctc 15.550062 loss_rnnt 11.034079 hw_loss 0.047469 lr 0.00035885 rank 3
2023-02-22 20:13:51,642 DEBUG TRAIN Batch 23/2300 loss 4.599295 loss_att 7.499711 loss_ctc 5.164407 loss_rnnt 3.905763 hw_loss 0.071437 lr 0.00035890 rank 6
2023-02-22 20:15:05,935 DEBUG TRAIN Batch 23/2400 loss 5.534838 loss_att 8.648534 loss_ctc 8.034357 loss_rnnt 4.510220 hw_loss 0.128643 lr 0.00035879 rank 0
2023-02-22 20:15:05,936 DEBUG TRAIN Batch 23/2400 loss 7.609518 loss_att 7.957322 loss_ctc 13.650316 loss_rnnt 6.689946 hw_loss 0.083571 lr 0.00035876 rank 7
2023-02-22 20:15:05,938 DEBUG TRAIN Batch 23/2400 loss 6.483510 loss_att 8.986105 loss_ctc 9.747840 loss_rnnt 5.491734 hw_loss 0.105025 lr 0.00035881 rank 6
2023-02-22 20:15:05,942 DEBUG TRAIN Batch 23/2400 loss 10.743105 loss_att 13.748360 loss_ctc 15.017495 loss_rnnt 9.496196 hw_loss 0.142389 lr 0.00035879 rank 5
2023-02-22 20:15:05,942 DEBUG TRAIN Batch 23/2400 loss 13.777039 loss_att 14.706839 loss_ctc 19.461889 loss_rnnt 12.730997 hw_loss 0.191438 lr 0.00035879 rank 4
2023-02-22 20:15:05,943 DEBUG TRAIN Batch 23/2400 loss 6.079286 loss_att 9.662721 loss_ctc 9.474922 loss_rnnt 4.886202 hw_loss 0.044336 lr 0.00035880 rank 1
2023-02-22 20:15:05,946 DEBUG TRAIN Batch 23/2400 loss 9.300695 loss_att 15.340935 loss_ctc 14.808617 loss_rnnt 7.317487 hw_loss 0.076447 lr 0.00035876 rank 3
2023-02-22 20:15:05,949 DEBUG TRAIN Batch 23/2400 loss 12.594123 loss_att 16.300524 loss_ctc 16.578751 loss_rnnt 11.267300 hw_loss 0.101735 lr 0.00035874 rank 2
2023-02-22 20:16:24,402 DEBUG TRAIN Batch 23/2500 loss 4.949080 loss_att 7.727396 loss_ctc 6.829904 loss_rnnt 4.070880 hw_loss 0.134550 lr 0.00035870 rank 1
2023-02-22 20:16:24,403 DEBUG TRAIN Batch 23/2500 loss 3.655119 loss_att 4.722558 loss_ctc 4.191146 loss_rnnt 3.318487 hw_loss 0.096889 lr 0.00035867 rank 7
2023-02-22 20:16:24,406 DEBUG TRAIN Batch 23/2500 loss 9.421881 loss_att 12.086001 loss_ctc 13.031389 loss_rnnt 8.302871 hw_loss 0.196722 lr 0.00035869 rank 0
2023-02-22 20:16:24,406 DEBUG TRAIN Batch 23/2500 loss 8.732302 loss_att 10.224064 loss_ctc 12.103709 loss_rnnt 7.897738 hw_loss 0.162544 lr 0.00035870 rank 5
2023-02-22 20:16:24,408 DEBUG TRAIN Batch 23/2500 loss 7.637979 loss_att 8.926429 loss_ctc 11.940290 loss_rnnt 6.768068 hw_loss 0.072336 lr 0.00035870 rank 4
2023-02-22 20:16:24,411 DEBUG TRAIN Batch 23/2500 loss 14.337200 loss_att 14.671094 loss_ctc 19.292194 loss_rnnt 13.536109 hw_loss 0.138087 lr 0.00035872 rank 6
2023-02-22 20:16:24,411 DEBUG TRAIN Batch 23/2500 loss 6.411811 loss_att 8.295193 loss_ctc 12.337601 loss_rnnt 5.228894 hw_loss 0.030254 lr 0.00035867 rank 3
2023-02-22 20:16:24,462 DEBUG TRAIN Batch 23/2500 loss 4.354750 loss_att 5.970914 loss_ctc 5.758514 loss_rnnt 3.832769 hw_loss 0.021711 lr 0.00035864 rank 2
2023-02-22 20:17:40,197 DEBUG TRAIN Batch 23/2600 loss 8.347211 loss_att 9.834267 loss_ctc 12.904257 loss_rnnt 7.421810 hw_loss 0.038219 lr 0.00035858 rank 7
2023-02-22 20:17:40,200 DEBUG TRAIN Batch 23/2600 loss 13.417221 loss_att 18.025988 loss_ctc 19.539526 loss_rnnt 11.657718 hw_loss 0.040204 lr 0.00035860 rank 0
2023-02-22 20:17:40,200 DEBUG TRAIN Batch 23/2600 loss 3.993383 loss_att 7.717732 loss_ctc 5.716516 loss_rnnt 2.997391 hw_loss 0.040071 lr 0.00035861 rank 1
2023-02-22 20:17:40,202 DEBUG TRAIN Batch 23/2600 loss 12.274097 loss_att 16.402399 loss_ctc 15.563598 loss_rnnt 10.996647 hw_loss 0.024733 lr 0.00035861 rank 4
2023-02-22 20:17:40,203 DEBUG TRAIN Batch 23/2600 loss 5.452838 loss_att 8.382897 loss_ctc 8.695972 loss_rnnt 4.365768 hw_loss 0.128702 lr 0.00035860 rank 5
2023-02-22 20:17:40,204 DEBUG TRAIN Batch 23/2600 loss 11.597455 loss_att 14.263529 loss_ctc 18.925901 loss_rnnt 10.032500 hw_loss 0.102402 lr 0.00035857 rank 3
2023-02-22 20:17:40,207 DEBUG TRAIN Batch 23/2600 loss 3.857102 loss_att 6.146680 loss_ctc 5.909942 loss_rnnt 3.125355 hw_loss 0.000224 lr 0.00035862 rank 6
2023-02-22 20:17:40,212 DEBUG TRAIN Batch 23/2600 loss 2.302580 loss_att 5.599568 loss_ctc 4.240520 loss_rnnt 1.326726 hw_loss 0.108870 lr 0.00035855 rank 2
2023-02-22 20:18:55,509 DEBUG TRAIN Batch 23/2700 loss 3.078863 loss_att 5.903099 loss_ctc 3.523803 loss_rnnt 2.453719 hw_loss 0.001820 lr 0.00035852 rank 4
2023-02-22 20:18:55,510 DEBUG TRAIN Batch 23/2700 loss 10.841277 loss_att 13.459416 loss_ctc 16.116226 loss_rnnt 9.574974 hw_loss 0.073780 lr 0.00035848 rank 3
2023-02-22 20:18:55,511 DEBUG TRAIN Batch 23/2700 loss 5.328876 loss_att 6.969549 loss_ctc 6.594093 loss_rnnt 4.767604 hw_loss 0.120828 lr 0.00035851 rank 0
2023-02-22 20:18:55,514 DEBUG TRAIN Batch 23/2700 loss 5.131396 loss_att 6.817705 loss_ctc 6.942579 loss_rnnt 4.521834 hw_loss 0.057766 lr 0.00035851 rank 5
2023-02-22 20:18:55,514 DEBUG TRAIN Batch 23/2700 loss 8.139691 loss_att 8.587889 loss_ctc 10.680374 loss_rnnt 7.669461 hw_loss 0.078436 lr 0.00035849 rank 7
2023-02-22 20:18:55,515 DEBUG TRAIN Batch 23/2700 loss 16.087149 loss_att 22.504812 loss_ctc 22.603016 loss_rnnt 13.931459 hw_loss 0.006326 lr 0.00035853 rank 6
2023-02-22 20:18:55,516 DEBUG TRAIN Batch 23/2700 loss 2.192659 loss_att 5.532057 loss_ctc 3.908940 loss_rnnt 1.263474 hw_loss 0.060876 lr 0.00035846 rank 2
2023-02-22 20:18:55,521 DEBUG TRAIN Batch 23/2700 loss 2.582232 loss_att 5.669755 loss_ctc 4.458429 loss_rnnt 1.674758 hw_loss 0.074645 lr 0.00035852 rank 1
2023-02-22 20:20:12,905 DEBUG TRAIN Batch 23/2800 loss 15.435381 loss_att 21.990858 loss_ctc 25.888947 loss_rnnt 12.719097 hw_loss 0.021337 lr 0.00035839 rank 7
2023-02-22 20:20:12,906 DEBUG TRAIN Batch 23/2800 loss 10.420476 loss_att 15.229259 loss_ctc 16.435448 loss_rnnt 8.633299 hw_loss 0.043919 lr 0.00035843 rank 1
2023-02-22 20:20:12,907 DEBUG TRAIN Batch 23/2800 loss 4.892443 loss_att 8.748457 loss_ctc 5.632365 loss_rnnt 4.006336 hw_loss 0.030467 lr 0.00035842 rank 0
2023-02-22 20:20:12,908 DEBUG TRAIN Batch 23/2800 loss 8.369224 loss_att 9.064751 loss_ctc 9.657093 loss_rnnt 8.001666 hw_loss 0.106381 lr 0.00035844 rank 6
2023-02-22 20:20:12,909 DEBUG TRAIN Batch 23/2800 loss 6.495100 loss_att 8.181067 loss_ctc 10.802219 loss_rnnt 5.531492 hw_loss 0.097747 lr 0.00035842 rank 5
2023-02-22 20:20:12,911 DEBUG TRAIN Batch 23/2800 loss 12.994086 loss_att 14.419357 loss_ctc 22.417370 loss_rnnt 11.427284 hw_loss 0.047456 lr 0.00035842 rank 4
2023-02-22 20:20:12,913 DEBUG TRAIN Batch 23/2800 loss 9.651030 loss_att 16.407465 loss_ctc 23.561316 loss_rnnt 6.395745 hw_loss 0.092423 lr 0.00035837 rank 2
2023-02-22 20:20:12,917 DEBUG TRAIN Batch 23/2800 loss 2.011983 loss_att 4.520560 loss_ctc 3.485613 loss_rnnt 1.284654 hw_loss 0.054617 lr 0.00035839 rank 3
2023-02-22 20:21:29,394 DEBUG TRAIN Batch 23/2900 loss 7.485252 loss_att 12.742924 loss_ctc 10.594780 loss_rnnt 5.998300 hw_loss 0.039028 lr 0.00035833 rank 5
2023-02-22 20:21:29,395 DEBUG TRAIN Batch 23/2900 loss 12.217640 loss_att 16.419243 loss_ctc 17.687366 loss_rnnt 10.639688 hw_loss 0.015626 lr 0.00035833 rank 4
2023-02-22 20:21:29,397 DEBUG TRAIN Batch 23/2900 loss 6.840731 loss_att 10.405450 loss_ctc 8.730952 loss_rnnt 5.836537 hw_loss 0.073538 lr 0.00035833 rank 0
2023-02-22 20:21:29,399 DEBUG TRAIN Batch 23/2900 loss 3.999679 loss_att 8.112957 loss_ctc 6.764831 loss_rnnt 2.773257 hw_loss 0.065774 lr 0.00035830 rank 7
2023-02-22 20:21:29,404 DEBUG TRAIN Batch 23/2900 loss 4.501043 loss_att 6.452274 loss_ctc 4.913527 loss_rnnt 3.995993 hw_loss 0.112137 lr 0.00035835 rank 6
2023-02-22 20:21:29,404 DEBUG TRAIN Batch 23/2900 loss 9.490582 loss_att 11.492645 loss_ctc 13.980768 loss_rnnt 8.436978 hw_loss 0.102185 lr 0.00035830 rank 3
2023-02-22 20:21:29,404 DEBUG TRAIN Batch 23/2900 loss 5.477026 loss_att 7.019207 loss_ctc 8.011980 loss_rnnt 4.791949 hw_loss 0.072461 lr 0.00035828 rank 2
2023-02-22 20:21:29,448 DEBUG TRAIN Batch 23/2900 loss 8.898511 loss_att 11.341471 loss_ctc 12.975981 loss_rnnt 7.847199 hw_loss 0.035732 lr 0.00035834 rank 1
2023-02-22 20:22:46,040 DEBUG TRAIN Batch 23/3000 loss 10.107931 loss_att 14.208162 loss_ctc 17.758495 loss_rnnt 8.234329 hw_loss 0.062775 lr 0.00035824 rank 4
2023-02-22 20:22:46,044 DEBUG TRAIN Batch 23/3000 loss 5.566639 loss_att 6.760398 loss_ctc 9.333855 loss_rnnt 4.766849 hw_loss 0.110144 lr 0.00035823 rank 5
2023-02-22 20:22:46,046 DEBUG TRAIN Batch 23/3000 loss 6.655371 loss_att 9.352503 loss_ctc 10.707014 loss_rnnt 5.546075 hw_loss 0.055594 lr 0.00035821 rank 7
2023-02-22 20:22:46,047 DEBUG TRAIN Batch 23/3000 loss 13.250879 loss_att 14.559665 loss_ctc 17.400753 loss_rnnt 12.427597 hw_loss 0.015392 lr 0.00035823 rank 0
2023-02-22 20:22:46,047 DEBUG TRAIN Batch 23/3000 loss 5.867908 loss_att 8.008265 loss_ctc 10.316267 loss_rnnt 4.813502 hw_loss 0.062287 lr 0.00035826 rank 6
2023-02-22 20:22:46,048 DEBUG TRAIN Batch 23/3000 loss 8.851268 loss_att 12.819723 loss_ctc 13.879007 loss_rnnt 7.351840 hw_loss 0.066322 lr 0.00035824 rank 1
2023-02-22 20:22:46,050 DEBUG TRAIN Batch 23/3000 loss 8.449140 loss_att 10.454520 loss_ctc 12.261057 loss_rnnt 7.510771 hw_loss 0.054444 lr 0.00035821 rank 3
2023-02-22 20:22:46,051 DEBUG TRAIN Batch 23/3000 loss 7.169902 loss_att 11.423820 loss_ctc 11.850660 loss_rnnt 5.642228 hw_loss 0.098978 lr 0.00035818 rank 2
2023-02-22 20:24:00,736 DEBUG TRAIN Batch 23/3100 loss 10.140900 loss_att 10.292755 loss_ctc 10.944793 loss_rnnt 9.968482 hw_loss 0.065364 lr 0.00035814 rank 5
2023-02-22 20:24:00,739 DEBUG TRAIN Batch 23/3100 loss 6.424551 loss_att 7.739001 loss_ctc 7.540082 loss_rnnt 5.989410 hw_loss 0.044087 lr 0.00035815 rank 4
2023-02-22 20:24:00,738 DEBUG TRAIN Batch 23/3100 loss 3.619924 loss_att 5.575888 loss_ctc 6.039430 loss_rnnt 2.854441 hw_loss 0.096917 lr 0.00035812 rank 7
2023-02-22 20:24:00,739 DEBUG TRAIN Batch 23/3100 loss 7.101875 loss_att 9.000835 loss_ctc 10.846510 loss_rnnt 6.132839 hw_loss 0.168673 lr 0.00035815 rank 1
2023-02-22 20:24:00,739 DEBUG TRAIN Batch 23/3100 loss 11.663567 loss_att 13.520235 loss_ctc 17.057291 loss_rnnt 10.512093 hw_loss 0.114332 lr 0.00035816 rank 6
2023-02-22 20:24:00,739 DEBUG TRAIN Batch 23/3100 loss 5.274229 loss_att 7.284937 loss_ctc 6.549811 loss_rnnt 4.634795 hw_loss 0.126027 lr 0.00035814 rank 0
2023-02-22 20:24:00,743 DEBUG TRAIN Batch 23/3100 loss 7.143154 loss_att 9.331970 loss_ctc 9.145053 loss_rnnt 6.370694 hw_loss 0.127081 lr 0.00035809 rank 2
2023-02-22 20:24:00,745 DEBUG TRAIN Batch 23/3100 loss 4.763494 loss_att 6.328431 loss_ctc 6.036690 loss_rnnt 4.215415 hw_loss 0.122498 lr 0.00035811 rank 3
2023-02-22 20:25:19,481 DEBUG TRAIN Batch 23/3200 loss 5.969288 loss_att 6.015808 loss_ctc 7.411669 loss_rnnt 5.729417 hw_loss 0.071717 lr 0.00035806 rank 1
2023-02-22 20:25:19,481 DEBUG TRAIN Batch 23/3200 loss 12.883204 loss_att 15.797409 loss_ctc 18.725296 loss_rnnt 11.429390 hw_loss 0.172548 lr 0.00035805 rank 5
2023-02-22 20:25:19,481 DEBUG TRAIN Batch 23/3200 loss 8.360424 loss_att 9.744897 loss_ctc 10.935061 loss_rnnt 7.698551 hw_loss 0.078176 lr 0.00035803 rank 7
2023-02-22 20:25:19,482 DEBUG TRAIN Batch 23/3200 loss 8.780789 loss_att 8.834576 loss_ctc 10.186018 loss_rnnt 8.552308 hw_loss 0.056924 lr 0.00035806 rank 4
2023-02-22 20:25:19,483 DEBUG TRAIN Batch 23/3200 loss 12.175651 loss_att 12.760424 loss_ctc 14.095876 loss_rnnt 11.724401 hw_loss 0.146747 lr 0.00035805 rank 0
2023-02-22 20:25:19,487 DEBUG TRAIN Batch 23/3200 loss 9.772199 loss_att 16.554207 loss_ctc 16.384315 loss_rnnt 7.469970 hw_loss 0.120396 lr 0.00035807 rank 6
2023-02-22 20:25:19,488 DEBUG TRAIN Batch 23/3200 loss 8.736567 loss_att 9.105518 loss_ctc 12.421199 loss_rnnt 8.106544 hw_loss 0.121776 lr 0.00035802 rank 3
2023-02-22 20:25:19,489 DEBUG TRAIN Batch 23/3200 loss 9.829902 loss_att 14.874903 loss_ctc 15.864182 loss_rnnt 8.002802 hw_loss 0.025365 lr 0.00035800 rank 2
2023-02-22 20:26:34,002 DEBUG TRAIN Batch 23/3300 loss 24.524569 loss_att 33.596596 loss_ctc 38.568848 loss_rnnt 20.767780 hw_loss 0.130898 lr 0.00035793 rank 7
2023-02-22 20:26:34,004 DEBUG TRAIN Batch 23/3300 loss 11.414772 loss_att 14.262331 loss_ctc 17.576994 loss_rnnt 9.977775 hw_loss 0.085981 lr 0.00035798 rank 6
2023-02-22 20:26:34,004 DEBUG TRAIN Batch 23/3300 loss 12.891906 loss_att 16.874073 loss_ctc 19.851671 loss_rnnt 11.146357 hw_loss 0.039648 lr 0.00035797 rank 1
2023-02-22 20:26:34,004 DEBUG TRAIN Batch 23/3300 loss 6.825634 loss_att 11.437920 loss_ctc 9.798024 loss_rnnt 5.506807 hw_loss 0.000096 lr 0.00035796 rank 0
2023-02-22 20:26:34,006 DEBUG TRAIN Batch 23/3300 loss 2.045320 loss_att 5.287583 loss_ctc 4.115390 loss_rnnt 1.107154 hw_loss 0.025695 lr 0.00035796 rank 5
2023-02-22 20:26:34,010 DEBUG TRAIN Batch 23/3300 loss 9.719860 loss_att 12.619909 loss_ctc 10.495753 loss_rnnt 9.016281 hw_loss 0.037718 lr 0.00035793 rank 3
2023-02-22 20:26:34,010 DEBUG TRAIN Batch 23/3300 loss 22.479197 loss_att 25.491877 loss_ctc 33.027519 loss_rnnt 20.470121 hw_loss 0.000181 lr 0.00035796 rank 4
2023-02-22 20:26:34,016 DEBUG TRAIN Batch 23/3300 loss 7.886389 loss_att 12.483948 loss_ctc 11.436908 loss_rnnt 6.462999 hw_loss 0.057143 lr 0.00035791 rank 2
2023-02-22 20:27:49,071 DEBUG TRAIN Batch 23/3400 loss 6.234257 loss_att 8.464493 loss_ctc 8.206673 loss_rnnt 5.507649 hw_loss 0.032947 lr 0.00035787 rank 5
2023-02-22 20:27:49,074 DEBUG TRAIN Batch 23/3400 loss 3.609181 loss_att 7.363326 loss_ctc 4.787371 loss_rnnt 2.691999 hw_loss 0.017364 lr 0.00035788 rank 1
2023-02-22 20:27:49,075 DEBUG TRAIN Batch 23/3400 loss 7.629983 loss_att 11.197804 loss_ctc 12.534362 loss_rnnt 6.218202 hw_loss 0.083063 lr 0.00035784 rank 7
2023-02-22 20:27:49,078 DEBUG TRAIN Batch 23/3400 loss 9.901750 loss_att 15.785559 loss_ctc 16.692234 loss_rnnt 7.775384 hw_loss 0.082886 lr 0.00035787 rank 4
2023-02-22 20:27:49,079 DEBUG TRAIN Batch 23/3400 loss 6.166493 loss_att 10.917528 loss_ctc 9.228760 loss_rnnt 4.803048 hw_loss 0.009255 lr 0.00035787 rank 0
2023-02-22 20:27:49,079 DEBUG TRAIN Batch 23/3400 loss 13.044454 loss_att 14.183146 loss_ctc 11.144710 loss_rnnt 13.041597 hw_loss 0.053279 lr 0.00035782 rank 2
2023-02-22 20:27:49,083 DEBUG TRAIN Batch 23/3400 loss 5.552103 loss_att 7.725278 loss_ctc 7.035554 loss_rnnt 4.904589 hw_loss 0.028286 lr 0.00035789 rank 6
2023-02-22 20:27:49,085 DEBUG TRAIN Batch 23/3400 loss 10.467965 loss_att 11.249185 loss_ctc 12.618979 loss_rnnt 9.994970 hw_loss 0.056156 lr 0.00035784 rank 3
2023-02-22 20:29:05,073 DEBUG TRAIN Batch 23/3500 loss 12.177523 loss_att 13.951977 loss_ctc 16.750137 loss_rnnt 11.189972 hw_loss 0.043086 lr 0.00035775 rank 7
2023-02-22 20:29:05,077 DEBUG TRAIN Batch 23/3500 loss 7.656163 loss_att 9.259382 loss_ctc 13.400560 loss_rnnt 6.526460 hw_loss 0.080886 lr 0.00035778 rank 5
2023-02-22 20:29:05,078 DEBUG TRAIN Batch 23/3500 loss 10.598922 loss_att 13.036633 loss_ctc 15.134805 loss_rnnt 9.474106 hw_loss 0.060918 lr 0.00035777 rank 0
2023-02-22 20:29:05,085 DEBUG TRAIN Batch 23/3500 loss 5.666867 loss_att 10.170796 loss_ctc 9.490290 loss_rnnt 4.193253 hw_loss 0.118198 lr 0.00035778 rank 4
2023-02-22 20:29:05,084 DEBUG TRAIN Batch 23/3500 loss 7.727926 loss_att 11.092754 loss_ctc 11.875777 loss_rnnt 6.448028 hw_loss 0.101036 lr 0.00035778 rank 1
2023-02-22 20:29:05,086 DEBUG TRAIN Batch 23/3500 loss 11.758965 loss_att 13.916336 loss_ctc 15.126173 loss_rnnt 10.840670 hw_loss 0.070990 lr 0.00035775 rank 3
2023-02-22 20:29:05,087 DEBUG TRAIN Batch 23/3500 loss 16.605389 loss_att 19.615608 loss_ctc 23.831631 loss_rnnt 14.993322 hw_loss 0.087232 lr 0.00035773 rank 2
2023-02-22 20:29:05,088 DEBUG TRAIN Batch 23/3500 loss 9.868696 loss_att 12.267924 loss_ctc 13.639087 loss_rnnt 8.840788 hw_loss 0.085019 lr 0.00035780 rank 6
2023-02-22 20:30:22,255 DEBUG TRAIN Batch 23/3600 loss 6.131725 loss_att 8.239485 loss_ctc 7.468754 loss_rnnt 5.499516 hw_loss 0.060725 lr 0.00035768 rank 0
2023-02-22 20:30:22,259 DEBUG TRAIN Batch 23/3600 loss 11.306994 loss_att 13.971612 loss_ctc 17.034441 loss_rnnt 9.976816 hw_loss 0.062990 lr 0.00035766 rank 7
2023-02-22 20:30:22,263 DEBUG TRAIN Batch 23/3600 loss 8.568601 loss_att 10.381629 loss_ctc 13.419308 loss_rnnt 7.515121 hw_loss 0.082712 lr 0.00035769 rank 1
2023-02-22 20:30:22,265 DEBUG TRAIN Batch 23/3600 loss 10.104824 loss_att 13.269476 loss_ctc 15.711723 loss_rnnt 8.705020 hw_loss 0.036164 lr 0.00035768 rank 5
2023-02-22 20:30:22,266 DEBUG TRAIN Batch 23/3600 loss 9.595840 loss_att 10.529554 loss_ctc 10.576323 loss_rnnt 9.223639 hw_loss 0.102616 lr 0.00035769 rank 4
2023-02-22 20:30:22,266 DEBUG TRAIN Batch 23/3600 loss 10.735713 loss_att 14.897591 loss_ctc 19.128403 loss_rnnt 8.716742 hw_loss 0.126693 lr 0.00035763 rank 2
2023-02-22 20:30:22,267 DEBUG TRAIN Batch 23/3600 loss 8.787668 loss_att 11.693020 loss_ctc 13.619385 loss_rnnt 7.513986 hw_loss 0.090718 lr 0.00035771 rank 6
2023-02-22 20:30:22,313 DEBUG TRAIN Batch 23/3600 loss 10.408908 loss_att 12.883919 loss_ctc 20.291632 loss_rnnt 8.551599 hw_loss 0.083645 lr 0.00035766 rank 3
2023-02-22 20:31:36,874 DEBUG TRAIN Batch 23/3700 loss 5.335605 loss_att 7.451881 loss_ctc 6.497684 loss_rnnt 4.664052 hw_loss 0.175040 lr 0.00035759 rank 0
2023-02-22 20:31:36,875 DEBUG TRAIN Batch 23/3700 loss 21.015545 loss_att 23.254875 loss_ctc 26.934059 loss_rnnt 19.755898 hw_loss 0.042461 lr 0.00035757 rank 7
2023-02-22 20:31:36,878 DEBUG TRAIN Batch 23/3700 loss 13.885971 loss_att 13.755636 loss_ctc 19.514505 loss_rnnt 13.104259 hw_loss 0.107451 lr 0.00035760 rank 4
2023-02-22 20:31:36,878 DEBUG TRAIN Batch 23/3700 loss 9.229518 loss_att 11.663034 loss_ctc 15.298182 loss_rnnt 7.876680 hw_loss 0.106839 lr 0.00035759 rank 5
2023-02-22 20:31:36,879 DEBUG TRAIN Batch 23/3700 loss 6.927820 loss_att 8.711372 loss_ctc 10.061828 loss_rnnt 6.086443 hw_loss 0.125249 lr 0.00035761 rank 6
2023-02-22 20:31:36,881 DEBUG TRAIN Batch 23/3700 loss 6.970524 loss_att 7.275994 loss_ctc 7.682498 loss_rnnt 6.765196 hw_loss 0.092444 lr 0.00035760 rank 1
2023-02-22 20:31:36,883 DEBUG TRAIN Batch 23/3700 loss 8.588392 loss_att 11.817370 loss_ctc 10.825161 loss_rnnt 7.608379 hw_loss 0.067464 lr 0.00035754 rank 2
2023-02-22 20:31:36,885 DEBUG TRAIN Batch 23/3700 loss 9.221901 loss_att 11.366136 loss_ctc 13.757935 loss_rnnt 8.135947 hw_loss 0.098067 lr 0.00035756 rank 3
2023-02-22 20:32:51,348 DEBUG TRAIN Batch 23/3800 loss 3.766455 loss_att 6.014235 loss_ctc 5.508909 loss_rnnt 3.039030 hw_loss 0.085391 lr 0.00035751 rank 4
2023-02-22 20:32:51,355 DEBUG TRAIN Batch 23/3800 loss 8.322707 loss_att 11.167340 loss_ctc 13.793737 loss_rnnt 6.947349 hw_loss 0.144304 lr 0.00035750 rank 0
2023-02-22 20:32:51,357 DEBUG TRAIN Batch 23/3800 loss 7.169518 loss_att 13.588886 loss_ctc 10.225218 loss_rnnt 5.453464 hw_loss 0.046412 lr 0.00035750 rank 5
2023-02-22 20:32:51,357 DEBUG TRAIN Batch 23/3800 loss 10.218866 loss_att 9.595059 loss_ctc 13.298816 loss_rnnt 9.869539 hw_loss 0.118930 lr 0.00035748 rank 7
2023-02-22 20:32:51,357 DEBUG TRAIN Batch 23/3800 loss 7.189560 loss_att 8.370159 loss_ctc 12.100494 loss_rnnt 6.231009 hw_loss 0.126824 lr 0.00035745 rank 2
2023-02-22 20:32:51,357 DEBUG TRAIN Batch 23/3800 loss 5.622653 loss_att 9.268878 loss_ctc 10.708685 loss_rnnt 4.170978 hw_loss 0.083048 lr 0.00035751 rank 1
2023-02-22 20:32:51,359 DEBUG TRAIN Batch 23/3800 loss 7.919329 loss_att 9.398789 loss_ctc 11.298774 loss_rnnt 7.092368 hw_loss 0.150893 lr 0.00035752 rank 6
2023-02-22 20:32:51,360 DEBUG TRAIN Batch 23/3800 loss 6.251970 loss_att 8.137783 loss_ctc 9.389516 loss_rnnt 5.380615 hw_loss 0.142225 lr 0.00035747 rank 3
2023-02-22 20:34:10,568 DEBUG TRAIN Batch 23/3900 loss 10.117167 loss_att 10.937963 loss_ctc 15.639026 loss_rnnt 9.162615 hw_loss 0.101522 lr 0.00035741 rank 5
2023-02-22 20:34:10,572 DEBUG TRAIN Batch 23/3900 loss 6.607508 loss_att 8.214703 loss_ctc 7.664361 loss_rnnt 6.125049 hw_loss 0.037701 lr 0.00035741 rank 4
2023-02-22 20:34:10,575 DEBUG TRAIN Batch 23/3900 loss 7.620711 loss_att 9.033579 loss_ctc 9.395545 loss_rnnt 7.074090 hw_loss 0.051379 lr 0.00035738 rank 3
2023-02-22 20:34:10,582 DEBUG TRAIN Batch 23/3900 loss 10.622519 loss_att 13.779613 loss_ctc 18.354351 loss_rnnt 8.938646 hw_loss 0.040391 lr 0.00035741 rank 0
2023-02-22 20:34:10,585 DEBUG TRAIN Batch 23/3900 loss 13.407246 loss_att 18.556877 loss_ctc 21.826397 loss_rnnt 11.208595 hw_loss 0.086569 lr 0.00035738 rank 7
2023-02-22 20:34:10,586 DEBUG TRAIN Batch 23/3900 loss 12.295066 loss_att 14.298969 loss_ctc 16.072405 loss_rnnt 11.331180 hw_loss 0.111487 lr 0.00035742 rank 1
2023-02-22 20:34:10,609 DEBUG TRAIN Batch 23/3900 loss 12.338282 loss_att 17.869101 loss_ctc 16.367643 loss_rnnt 10.636736 hw_loss 0.108999 lr 0.00035743 rank 6
2023-02-22 20:34:10,641 DEBUG TRAIN Batch 23/3900 loss 10.173662 loss_att 11.318142 loss_ctc 17.428944 loss_rnnt 8.922224 hw_loss 0.103445 lr 0.00035736 rank 2
2023-02-22 20:35:26,686 DEBUG TRAIN Batch 23/4000 loss 3.536897 loss_att 6.191341 loss_ctc 4.841697 loss_rnnt 2.772525 hw_loss 0.111582 lr 0.00035732 rank 4
2023-02-22 20:35:26,686 DEBUG TRAIN Batch 23/4000 loss 8.650761 loss_att 9.928593 loss_ctc 14.306637 loss_rnnt 7.639163 hw_loss 0.003590 lr 0.00035732 rank 5
2023-02-22 20:35:26,691 DEBUG TRAIN Batch 23/4000 loss 14.683931 loss_att 18.412807 loss_ctc 20.136669 loss_rnnt 13.191696 hw_loss 0.036429 lr 0.00035727 rank 2
2023-02-22 20:35:26,691 DEBUG TRAIN Batch 23/4000 loss 3.868446 loss_att 5.928798 loss_ctc 6.742693 loss_rnnt 3.064454 hw_loss 0.016291 lr 0.00035729 rank 7
2023-02-22 20:35:26,694 DEBUG TRAIN Batch 23/4000 loss 12.919178 loss_att 14.785952 loss_ctc 20.798859 loss_rnnt 11.463808 hw_loss 0.058860 lr 0.00035732 rank 0
2023-02-22 20:35:26,697 DEBUG TRAIN Batch 23/4000 loss 1.651580 loss_att 4.350910 loss_ctc 2.493960 loss_rnnt 0.999321 hw_loss 0.000142 lr 0.00035734 rank 6
2023-02-22 20:35:26,696 DEBUG TRAIN Batch 23/4000 loss 9.334999 loss_att 14.258490 loss_ctc 14.497324 loss_rnnt 7.613911 hw_loss 0.090151 lr 0.00035729 rank 3
2023-02-22 20:35:26,743 DEBUG TRAIN Batch 23/4000 loss 6.665032 loss_att 8.778177 loss_ctc 10.728704 loss_rnnt 5.700368 hw_loss 0.000397 lr 0.00035733 rank 1
2023-02-22 20:36:42,106 DEBUG TRAIN Batch 23/4100 loss 14.478379 loss_att 17.655413 loss_ctc 22.040384 loss_rnnt 12.783689 hw_loss 0.095655 lr 0.00035720 rank 7
2023-02-22 20:36:42,107 DEBUG TRAIN Batch 23/4100 loss 5.696381 loss_att 8.641497 loss_ctc 8.574885 loss_rnnt 4.695818 hw_loss 0.052011 lr 0.00035724 rank 1
2023-02-22 20:36:42,108 DEBUG TRAIN Batch 23/4100 loss 4.734509 loss_att 6.075079 loss_ctc 7.301015 loss_rnnt 4.095828 hw_loss 0.053185 lr 0.00035720 rank 3
2023-02-22 20:36:42,109 DEBUG TRAIN Batch 23/4100 loss 3.385460 loss_att 6.208378 loss_ctc 3.953332 loss_rnnt 2.716027 hw_loss 0.054623 lr 0.00035723 rank 4
2023-02-22 20:36:42,111 DEBUG TRAIN Batch 23/4100 loss 11.971351 loss_att 17.012228 loss_ctc 20.677792 loss_rnnt 9.709166 hw_loss 0.174658 lr 0.00035723 rank 0
2023-02-22 20:36:42,112 DEBUG TRAIN Batch 23/4100 loss 8.042343 loss_att 10.022747 loss_ctc 10.654804 loss_rnnt 7.271240 hw_loss 0.050050 lr 0.00035725 rank 6
2023-02-22 20:36:42,112 DEBUG TRAIN Batch 23/4100 loss 2.973415 loss_att 5.857606 loss_ctc 3.848976 loss_rnnt 2.235996 hw_loss 0.082199 lr 0.00035723 rank 5
2023-02-22 20:36:42,116 DEBUG TRAIN Batch 23/4100 loss 5.344005 loss_att 8.781380 loss_ctc 10.189865 loss_rnnt 3.985057 hw_loss 0.047545 lr 0.00035718 rank 2
2023-02-22 20:37:57,991 DEBUG TRAIN Batch 23/4200 loss 13.311653 loss_att 16.903158 loss_ctc 17.711937 loss_rnnt 11.996601 hw_loss 0.018837 lr 0.00035714 rank 4
2023-02-22 20:37:57,993 DEBUG TRAIN Batch 23/4200 loss 13.548199 loss_att 16.828709 loss_ctc 18.805847 loss_rnnt 12.174221 hw_loss 0.031605 lr 0.00035711 rank 7
2023-02-22 20:37:57,996 DEBUG TRAIN Batch 23/4200 loss 11.732045 loss_att 13.780594 loss_ctc 15.437733 loss_rnnt 10.790424 hw_loss 0.070909 lr 0.00035714 rank 1
2023-02-22 20:37:57,996 DEBUG TRAIN Batch 23/4200 loss 4.143530 loss_att 7.757003 loss_ctc 6.687108 loss_rnnt 3.048766 hw_loss 0.061735 lr 0.00035714 rank 5
2023-02-22 20:37:57,999 DEBUG TRAIN Batch 23/4200 loss 5.909859 loss_att 10.265993 loss_ctc 8.352118 loss_rnnt 4.652482 hw_loss 0.113466 lr 0.00035714 rank 0
2023-02-22 20:37:58,000 DEBUG TRAIN Batch 23/4200 loss 4.133296 loss_att 5.776101 loss_ctc 6.345819 loss_rnnt 3.447607 hw_loss 0.116484 lr 0.00035716 rank 6
2023-02-22 20:37:57,999 DEBUG TRAIN Batch 23/4200 loss 10.612062 loss_att 14.540539 loss_ctc 15.178110 loss_rnnt 9.147804 hw_loss 0.130793 lr 0.00035711 rank 3
2023-02-22 20:37:58,002 DEBUG TRAIN Batch 23/4200 loss 7.417539 loss_att 9.337550 loss_ctc 10.695084 loss_rnnt 6.566331 hw_loss 0.056622 lr 0.00035709 rank 2
2023-02-22 20:39:16,204 DEBUG TRAIN Batch 23/4300 loss 12.189159 loss_att 14.912469 loss_ctc 12.830482 loss_rnnt 11.513172 hw_loss 0.085905 lr 0.00035704 rank 0
2023-02-22 20:39:16,204 DEBUG TRAIN Batch 23/4300 loss 16.472902 loss_att 22.635010 loss_ctc 25.002785 loss_rnnt 14.085133 hw_loss 0.033808 lr 0.00035705 rank 4
2023-02-22 20:39:16,208 DEBUG TRAIN Batch 23/4300 loss 11.838656 loss_att 10.514186 loss_ctc 17.690952 loss_rnnt 11.209291 hw_loss 0.213664 lr 0.00035705 rank 5
2023-02-22 20:39:16,210 DEBUG TRAIN Batch 23/4300 loss 6.415326 loss_att 8.684574 loss_ctc 10.635274 loss_rnnt 5.398531 hw_loss 0.000534 lr 0.00035702 rank 7
2023-02-22 20:39:16,213 DEBUG TRAIN Batch 23/4300 loss 13.673823 loss_att 17.211252 loss_ctc 25.387777 loss_rnnt 11.312127 hw_loss 0.173156 lr 0.00035707 rank 6
2023-02-22 20:39:16,213 DEBUG TRAIN Batch 23/4300 loss 9.430428 loss_att 10.639437 loss_ctc 12.625619 loss_rnnt 8.733610 hw_loss 0.054358 lr 0.00035700 rank 2
2023-02-22 20:39:16,224 DEBUG TRAIN Batch 23/4300 loss 7.272928 loss_att 9.736567 loss_ctc 10.742146 loss_rnnt 6.269768 hw_loss 0.089757 lr 0.00035702 rank 3
2023-02-22 20:39:16,255 DEBUG TRAIN Batch 23/4300 loss 6.949435 loss_att 8.677237 loss_ctc 8.053479 loss_rnnt 6.370769 hw_loss 0.161063 lr 0.00035705 rank 1
2023-02-22 20:40:31,230 DEBUG TRAIN Batch 23/4400 loss 13.398011 loss_att 15.290855 loss_ctc 22.016300 loss_rnnt 11.853512 hw_loss 0.031545 lr 0.00035696 rank 4
2023-02-22 20:40:31,230 DEBUG TRAIN Batch 23/4400 loss 10.156910 loss_att 11.205183 loss_ctc 14.060606 loss_rnnt 9.347655 hw_loss 0.148328 lr 0.00035695 rank 5
2023-02-22 20:40:31,232 DEBUG TRAIN Batch 23/4400 loss 10.556201 loss_att 13.309861 loss_ctc 18.367605 loss_rnnt 8.925517 hw_loss 0.072059 lr 0.00035693 rank 7
2023-02-22 20:40:31,233 DEBUG TRAIN Batch 23/4400 loss 9.032858 loss_att 11.605880 loss_ctc 13.425525 loss_rnnt 7.903487 hw_loss 0.054520 lr 0.00035696 rank 1
2023-02-22 20:40:31,233 DEBUG TRAIN Batch 23/4400 loss 8.802913 loss_att 11.701799 loss_ctc 16.001114 loss_rnnt 7.248012 hw_loss 0.028806 lr 0.00035695 rank 0
2023-02-22 20:40:31,234 DEBUG TRAIN Batch 23/4400 loss 1.993024 loss_att 4.331475 loss_ctc 4.180996 loss_rnnt 1.191055 hw_loss 0.079778 lr 0.00035690 rank 2
2023-02-22 20:40:31,235 DEBUG TRAIN Batch 23/4400 loss 5.702023 loss_att 5.614037 loss_ctc 7.614230 loss_rnnt 5.388514 hw_loss 0.142772 lr 0.00035693 rank 3
2023-02-22 20:40:31,278 DEBUG TRAIN Batch 23/4400 loss 11.200253 loss_att 11.149295 loss_ctc 15.521494 loss_rnnt 10.587999 hw_loss 0.086776 lr 0.00035698 rank 6
2023-02-22 20:41:46,649 DEBUG TRAIN Batch 23/4500 loss 9.330318 loss_att 13.495515 loss_ctc 11.876888 loss_rnnt 8.101313 hw_loss 0.105795 lr 0.00035687 rank 4
2023-02-22 20:41:46,651 DEBUG TRAIN Batch 23/4500 loss 3.771324 loss_att 8.662828 loss_ctc 8.555531 loss_rnnt 2.137788 hw_loss 0.032514 lr 0.00035684 rank 7
2023-02-22 20:41:46,653 DEBUG TRAIN Batch 23/4500 loss 7.101040 loss_att 9.860354 loss_ctc 12.935892 loss_rnnt 5.748685 hw_loss 0.042210 lr 0.00035686 rank 5
2023-02-22 20:41:46,656 DEBUG TRAIN Batch 23/4500 loss 9.134857 loss_att 11.475081 loss_ctc 19.174923 loss_rnnt 7.303379 hw_loss 0.046421 lr 0.00035686 rank 0
2023-02-22 20:41:46,658 DEBUG TRAIN Batch 23/4500 loss 7.382022 loss_att 9.804819 loss_ctc 10.571612 loss_rnnt 6.468451 hw_loss 0.006998 lr 0.00035688 rank 6
2023-02-22 20:41:46,660 DEBUG TRAIN Batch 23/4500 loss 8.996266 loss_att 11.590755 loss_ctc 12.896660 loss_rnnt 7.916602 hw_loss 0.076338 lr 0.00035687 rank 1
2023-02-22 20:41:46,661 DEBUG TRAIN Batch 23/4500 loss 11.618252 loss_att 14.773143 loss_ctc 19.844761 loss_rnnt 9.822054 hw_loss 0.128159 lr 0.00035684 rank 3
2023-02-22 20:41:46,664 DEBUG TRAIN Batch 23/4500 loss 10.945491 loss_att 13.871179 loss_ctc 10.997375 loss_rnnt 10.298331 hw_loss 0.103321 lr 0.00035681 rank 2
2023-02-22 20:43:04,359 DEBUG TRAIN Batch 23/4600 loss 8.485168 loss_att 13.179323 loss_ctc 12.392727 loss_rnnt 7.002243 hw_loss 0.043288 lr 0.00035675 rank 7
2023-02-22 20:43:04,359 DEBUG TRAIN Batch 23/4600 loss 5.780631 loss_att 7.478476 loss_ctc 6.413249 loss_rnnt 5.312381 hw_loss 0.083122 lr 0.00035679 rank 6
2023-02-22 20:43:04,361 DEBUG TRAIN Batch 23/4600 loss 6.797136 loss_att 10.675754 loss_ctc 10.404524 loss_rnnt 5.487820 hw_loss 0.098639 lr 0.00035678 rank 4
2023-02-22 20:43:04,362 DEBUG TRAIN Batch 23/4600 loss 5.810226 loss_att 8.718704 loss_ctc 9.775551 loss_rnnt 4.666072 hw_loss 0.063277 lr 0.00035677 rank 0
2023-02-22 20:43:04,363 DEBUG TRAIN Batch 23/4600 loss 10.303493 loss_att 10.302841 loss_ctc 14.401958 loss_rnnt 9.698340 hw_loss 0.110290 lr 0.00035678 rank 1
2023-02-22 20:43:04,363 DEBUG TRAIN Batch 23/4600 loss 6.677874 loss_att 8.647921 loss_ctc 8.609958 loss_rnnt 5.978334 hw_loss 0.089848 lr 0.00035674 rank 3
2023-02-22 20:43:04,366 DEBUG TRAIN Batch 23/4600 loss 9.851781 loss_att 11.891907 loss_ctc 13.031710 loss_rnnt 9.005157 hw_loss 0.027390 lr 0.00035677 rank 5
2023-02-22 20:43:04,416 DEBUG TRAIN Batch 23/4600 loss 11.776541 loss_att 18.482574 loss_ctc 22.367115 loss_rnnt 8.976276 hw_loss 0.088087 lr 0.00035672 rank 2
2023-02-22 20:44:20,774 DEBUG TRAIN Batch 23/4700 loss 3.652156 loss_att 6.293406 loss_ctc 5.637361 loss_rnnt 2.841119 hw_loss 0.033923 lr 0.00035668 rank 0
2023-02-22 20:44:20,778 DEBUG TRAIN Batch 23/4700 loss 6.559291 loss_att 9.260325 loss_ctc 10.268332 loss_rnnt 5.484886 hw_loss 0.074360 lr 0.00035666 rank 7
2023-02-22 20:44:20,782 DEBUG TRAIN Batch 23/4700 loss 9.153829 loss_att 8.757366 loss_ctc 11.480697 loss_rnnt 8.846699 hw_loss 0.142826 lr 0.00035663 rank 2
2023-02-22 20:44:20,783 DEBUG TRAIN Batch 23/4700 loss 11.920185 loss_att 15.254293 loss_ctc 20.323704 loss_rnnt 10.088076 hw_loss 0.084036 lr 0.00035669 rank 4
2023-02-22 20:44:20,785 DEBUG TRAIN Batch 23/4700 loss 10.480966 loss_att 13.333975 loss_ctc 17.151390 loss_rnnt 8.961794 hw_loss 0.110961 lr 0.00035670 rank 6
2023-02-22 20:44:20,785 DEBUG TRAIN Batch 23/4700 loss 5.616375 loss_att 8.839281 loss_ctc 10.119804 loss_rnnt 4.301769 hw_loss 0.130441 lr 0.00035668 rank 5
2023-02-22 20:44:20,787 DEBUG TRAIN Batch 23/4700 loss 6.741371 loss_att 9.026962 loss_ctc 8.004172 loss_rnnt 6.078025 hw_loss 0.070976 lr 0.00035669 rank 1
2023-02-22 20:44:20,837 DEBUG TRAIN Batch 23/4700 loss 13.075538 loss_att 13.392734 loss_ctc 18.221893 loss_rnnt 12.252278 hw_loss 0.138074 lr 0.00035665 rank 3
2023-02-22 20:45:36,204 DEBUG TRAIN Batch 23/4800 loss 9.938185 loss_att 14.022688 loss_ctc 14.602463 loss_rnnt 8.414861 hw_loss 0.158473 lr 0.00035657 rank 7
2023-02-22 20:45:36,211 DEBUG TRAIN Batch 23/4800 loss 17.861612 loss_att 15.815367 loss_ctc 21.704647 loss_rnnt 17.662167 hw_loss 0.180545 lr 0.00035659 rank 5
2023-02-22 20:45:36,211 DEBUG TRAIN Batch 23/4800 loss 10.509117 loss_att 13.189510 loss_ctc 16.815203 loss_rnnt 9.059572 hw_loss 0.136228 lr 0.00035659 rank 0
2023-02-22 20:45:36,212 DEBUG TRAIN Batch 23/4800 loss 12.187653 loss_att 15.088979 loss_ctc 18.712688 loss_rnnt 10.664779 hw_loss 0.136133 lr 0.00035656 rank 3
2023-02-22 20:45:36,215 DEBUG TRAIN Batch 23/4800 loss 20.095592 loss_att 21.463133 loss_ctc 26.402853 loss_rnnt 18.970510 hw_loss 0.019885 lr 0.00035654 rank 2
2023-02-22 20:45:36,216 DEBUG TRAIN Batch 23/4800 loss 10.533589 loss_att 13.985497 loss_ctc 21.240402 loss_rnnt 8.392449 hw_loss 0.043466 lr 0.00035660 rank 1
2023-02-22 20:45:36,219 DEBUG TRAIN Batch 23/4800 loss 8.806736 loss_att 12.539256 loss_ctc 12.430428 loss_rnnt 7.546355 hw_loss 0.057597 lr 0.00035660 rank 4
2023-02-22 20:45:36,221 DEBUG TRAIN Batch 23/4800 loss 13.845333 loss_att 16.071980 loss_ctc 25.168663 loss_rnnt 11.834805 hw_loss 0.103914 lr 0.00035661 rank 6
2023-02-22 20:46:51,383 DEBUG TRAIN Batch 23/4900 loss 6.433175 loss_att 9.776318 loss_ctc 9.877996 loss_rnnt 5.287713 hw_loss 0.032856 lr 0.00035648 rank 7
2023-02-22 20:46:51,384 DEBUG TRAIN Batch 23/4900 loss 7.609239 loss_att 12.492941 loss_ctc 10.556418 loss_rnnt 6.216805 hw_loss 0.042630 lr 0.00035650 rank 0
2023-02-22 20:46:51,384 DEBUG TRAIN Batch 23/4900 loss 8.325381 loss_att 9.732828 loss_ctc 13.130449 loss_rnnt 7.372703 hw_loss 0.057214 lr 0.00035650 rank 5
2023-02-22 20:46:51,388 DEBUG TRAIN Batch 23/4900 loss 8.824421 loss_att 13.655491 loss_ctc 10.525946 loss_rnnt 7.575508 hw_loss 0.104679 lr 0.00035650 rank 4
2023-02-22 20:46:51,393 DEBUG TRAIN Batch 23/4900 loss 8.626088 loss_att 9.949397 loss_ctc 11.076571 loss_rnnt 7.983316 hw_loss 0.096335 lr 0.00035647 rank 3
2023-02-22 20:46:51,394 DEBUG TRAIN Batch 23/4900 loss 12.474458 loss_att 14.248587 loss_ctc 20.594982 loss_rnnt 11.002460 hw_loss 0.064568 lr 0.00035645 rank 2
2023-02-22 20:46:51,395 DEBUG TRAIN Batch 23/4900 loss 7.091400 loss_att 10.427551 loss_ctc 14.864552 loss_rnnt 5.364507 hw_loss 0.043580 lr 0.00035652 rank 6
2023-02-22 20:46:51,432 DEBUG TRAIN Batch 23/4900 loss 9.585272 loss_att 11.160480 loss_ctc 12.883702 loss_rnnt 8.810676 hw_loss 0.037057 lr 0.00035651 rank 1
2023-02-22 20:48:09,560 DEBUG TRAIN Batch 23/5000 loss 8.016112 loss_att 9.650747 loss_ctc 13.719025 loss_rnnt 6.893233 hw_loss 0.066682 lr 0.00035641 rank 0
2023-02-22 20:48:09,567 DEBUG TRAIN Batch 23/5000 loss 11.235712 loss_att 15.388077 loss_ctc 18.444464 loss_rnnt 9.368898 hw_loss 0.140952 lr 0.00035638 rank 7
2023-02-22 20:48:09,568 DEBUG TRAIN Batch 23/5000 loss 10.485991 loss_att 13.375279 loss_ctc 14.518141 loss_rnnt 9.349500 hw_loss 0.039398 lr 0.00035642 rank 1
2023-02-22 20:48:09,569 DEBUG TRAIN Batch 23/5000 loss 7.691745 loss_att 9.030265 loss_ctc 12.084675 loss_rnnt 6.773973 hw_loss 0.120646 lr 0.00035641 rank 5
2023-02-22 20:48:09,571 DEBUG TRAIN Batch 23/5000 loss 7.740503 loss_att 10.107798 loss_ctc 11.661893 loss_rnnt 6.690597 hw_loss 0.100491 lr 0.00035641 rank 4
2023-02-22 20:48:09,573 DEBUG TRAIN Batch 23/5000 loss 9.589551 loss_att 12.553569 loss_ctc 14.621246 loss_rnnt 8.273666 hw_loss 0.097851 lr 0.00035643 rank 6
2023-02-22 20:48:09,601 DEBUG TRAIN Batch 23/5000 loss 14.796866 loss_att 16.057190 loss_ctc 20.789732 loss_rnnt 13.685994 hw_loss 0.112046 lr 0.00035636 rank 2
2023-02-22 20:48:09,609 DEBUG TRAIN Batch 23/5000 loss 9.610371 loss_att 9.969406 loss_ctc 13.832792 loss_rnnt 8.903639 hw_loss 0.134877 lr 0.00035638 rank 3
2023-02-22 20:49:23,204 DEBUG TRAIN Batch 23/5100 loss 8.939789 loss_att 9.289887 loss_ctc 10.278738 loss_rnnt 8.584702 hw_loss 0.199764 lr 0.00035632 rank 4
2023-02-22 20:49:23,208 DEBUG TRAIN Batch 23/5100 loss 4.664165 loss_att 7.416144 loss_ctc 8.870130 loss_rnnt 3.483886 hw_loss 0.129540 lr 0.00035629 rank 7
2023-02-22 20:49:23,210 DEBUG TRAIN Batch 23/5100 loss 15.186020 loss_att 16.912771 loss_ctc 23.428085 loss_rnnt 13.729628 hw_loss 0.022688 lr 0.00035632 rank 0
2023-02-22 20:49:23,210 DEBUG TRAIN Batch 23/5100 loss 5.869039 loss_att 9.452723 loss_ctc 10.069732 loss_rnnt 4.560399 hw_loss 0.059647 lr 0.00035627 rank 2
2023-02-22 20:49:23,212 DEBUG TRAIN Batch 23/5100 loss 8.084477 loss_att 13.157235 loss_ctc 9.713571 loss_rnnt 6.768332 hw_loss 0.158216 lr 0.00035633 rank 1
2023-02-22 20:49:23,214 DEBUG TRAIN Batch 23/5100 loss 3.038517 loss_att 7.172211 loss_ctc 2.065109 loss_rnnt 2.327771 hw_loss 0.025866 lr 0.00035632 rank 5
2023-02-22 20:49:23,214 DEBUG TRAIN Batch 23/5100 loss 8.297030 loss_att 8.146804 loss_ctc 10.809910 loss_rnnt 7.925656 hw_loss 0.124442 lr 0.00035634 rank 6
2023-02-22 20:49:23,216 DEBUG TRAIN Batch 23/5100 loss 5.708464 loss_att 6.503392 loss_ctc 7.022890 loss_rnnt 5.359948 hw_loss 0.026761 lr 0.00035629 rank 3
2023-02-22 20:50:38,730 DEBUG TRAIN Batch 23/5200 loss 6.929809 loss_att 10.366302 loss_ctc 11.626952 loss_rnnt 5.558078 hw_loss 0.109026 lr 0.00035623 rank 5
2023-02-22 20:50:38,731 DEBUG TRAIN Batch 23/5200 loss 11.549326 loss_att 15.442614 loss_ctc 15.929197 loss_rnnt 10.186661 hw_loss 0.000049 lr 0.00035623 rank 0
2023-02-22 20:50:38,732 DEBUG TRAIN Batch 23/5200 loss 6.513154 loss_att 8.483401 loss_ctc 7.585901 loss_rnnt 5.930150 hw_loss 0.086101 lr 0.00035620 rank 7
2023-02-22 20:50:38,733 DEBUG TRAIN Batch 23/5200 loss 3.337315 loss_att 6.619828 loss_ctc 5.909906 loss_rnnt 2.320377 hw_loss 0.032669 lr 0.00035620 rank 3
2023-02-22 20:50:38,734 DEBUG TRAIN Batch 23/5200 loss 2.765537 loss_att 5.532116 loss_ctc 3.309509 loss_rnnt 2.107376 hw_loss 0.060592 lr 0.00035623 rank 4
2023-02-22 20:50:38,736 DEBUG TRAIN Batch 23/5200 loss 7.044266 loss_att 8.727515 loss_ctc 9.506750 loss_rnnt 6.331293 hw_loss 0.089983 lr 0.00035625 rank 6
2023-02-22 20:50:38,738 DEBUG TRAIN Batch 23/5200 loss 17.450422 loss_att 19.369362 loss_ctc 22.308594 loss_rnnt 16.316191 hw_loss 0.192539 lr 0.00035624 rank 1
2023-02-22 20:50:38,784 DEBUG TRAIN Batch 23/5200 loss 6.271891 loss_att 10.703668 loss_ctc 15.188210 loss_rnnt 4.157817 hw_loss 0.072892 lr 0.00035618 rank 2
2023-02-22 20:51:55,946 DEBUG TRAIN Batch 23/5300 loss 9.118365 loss_att 11.779812 loss_ctc 13.960091 loss_rnnt 7.917233 hw_loss 0.043647 lr 0.00035614 rank 0
2023-02-22 20:51:55,948 DEBUG TRAIN Batch 23/5300 loss 7.820548 loss_att 9.764398 loss_ctc 12.584686 loss_rnnt 6.771441 hw_loss 0.047099 lr 0.00035609 rank 2
2023-02-22 20:51:55,950 DEBUG TRAIN Batch 23/5300 loss 16.057768 loss_att 18.478487 loss_ctc 21.945745 loss_rnnt 14.733315 hw_loss 0.103588 lr 0.00035611 rank 7
2023-02-22 20:51:55,952 DEBUG TRAIN Batch 23/5300 loss 11.333220 loss_att 15.855240 loss_ctc 18.235138 loss_rnnt 9.474041 hw_loss 0.064722 lr 0.00035616 rank 6
2023-02-22 20:51:55,954 DEBUG TRAIN Batch 23/5300 loss 7.336079 loss_att 9.757504 loss_ctc 11.261019 loss_rnnt 6.289838 hw_loss 0.072433 lr 0.00035614 rank 4
2023-02-22 20:51:55,954 DEBUG TRAIN Batch 23/5300 loss 6.598654 loss_att 8.427188 loss_ctc 8.931400 loss_rnnt 5.883987 hw_loss 0.071113 lr 0.00035614 rank 5
2023-02-22 20:51:55,957 DEBUG TRAIN Batch 23/5300 loss 18.372381 loss_att 20.714018 loss_ctc 21.344410 loss_rnnt 17.446579 hw_loss 0.114755 lr 0.00035615 rank 1
2023-02-22 20:51:55,996 DEBUG TRAIN Batch 23/5300 loss 3.028221 loss_att 4.816588 loss_ctc 5.020898 loss_rnnt 2.374089 hw_loss 0.057689 lr 0.00035611 rank 3
2023-02-22 20:53:12,968 DEBUG TRAIN Batch 23/5400 loss 6.757609 loss_att 9.355780 loss_ctc 11.106438 loss_rnnt 5.615836 hw_loss 0.079303 lr 0.00035602 rank 7
2023-02-22 20:53:12,974 DEBUG TRAIN Batch 23/5400 loss 6.315629 loss_att 9.770233 loss_ctc 7.998344 loss_rnnt 5.373258 hw_loss 0.050790 lr 0.00035605 rank 0
2023-02-22 20:53:12,976 DEBUG TRAIN Batch 23/5400 loss 5.612686 loss_att 10.335771 loss_ctc 9.440887 loss_rnnt 4.138666 hw_loss 0.035581 lr 0.00035605 rank 4
2023-02-22 20:53:12,978 DEBUG TRAIN Batch 23/5400 loss 5.851341 loss_att 8.643529 loss_ctc 11.775740 loss_rnnt 4.480145 hw_loss 0.042821 lr 0.00035606 rank 1
2023-02-22 20:53:12,979 DEBUG TRAIN Batch 23/5400 loss 6.670156 loss_att 10.143009 loss_ctc 12.114968 loss_rnnt 5.204001 hw_loss 0.085517 lr 0.00035605 rank 5
2023-02-22 20:53:12,982 DEBUG TRAIN Batch 23/5400 loss 4.230283 loss_att 8.408123 loss_ctc 4.187962 loss_rnnt 3.381654 hw_loss 0.035069 lr 0.00035600 rank 2
2023-02-22 20:53:12,982 DEBUG TRAIN Batch 23/5400 loss 11.018343 loss_att 13.288078 loss_ctc 20.995266 loss_rnnt 9.194006 hw_loss 0.075249 lr 0.00035602 rank 3
2023-02-22 20:53:13,021 DEBUG TRAIN Batch 23/5400 loss 8.283873 loss_att 11.559215 loss_ctc 11.414809 loss_rnnt 7.145768 hw_loss 0.122959 lr 0.00035607 rank 6
2023-02-22 20:54:27,882 DEBUG TRAIN Batch 23/5500 loss 10.403790 loss_att 13.635826 loss_ctc 19.561516 loss_rnnt 8.516068 hw_loss 0.038033 lr 0.00035596 rank 0
2023-02-22 20:54:27,882 DEBUG TRAIN Batch 23/5500 loss 5.424227 loss_att 8.106406 loss_ctc 9.138439 loss_rnnt 4.365941 hw_loss 0.049916 lr 0.00035596 rank 5
2023-02-22 20:54:27,882 DEBUG TRAIN Batch 23/5500 loss 15.115209 loss_att 18.340879 loss_ctc 18.776943 loss_rnnt 13.919718 hw_loss 0.116484 lr 0.00035596 rank 4
2023-02-22 20:54:27,885 DEBUG TRAIN Batch 23/5500 loss 5.260361 loss_att 9.176838 loss_ctc 10.734675 loss_rnnt 3.692611 hw_loss 0.102273 lr 0.00035597 rank 1
2023-02-22 20:54:27,887 DEBUG TRAIN Batch 23/5500 loss 8.094937 loss_att 10.670684 loss_ctc 10.132849 loss_rnnt 7.251183 hw_loss 0.106657 lr 0.00035593 rank 3
2023-02-22 20:54:27,889 DEBUG TRAIN Batch 23/5500 loss 12.822410 loss_att 15.432514 loss_ctc 15.725250 loss_rnnt 11.872545 hw_loss 0.076494 lr 0.00035598 rank 6
2023-02-22 20:54:27,889 DEBUG TRAIN Batch 23/5500 loss 15.765841 loss_att 18.520985 loss_ctc 19.049068 loss_rnnt 14.725924 hw_loss 0.095859 lr 0.00035593 rank 7
2023-02-22 20:54:27,891 DEBUG TRAIN Batch 23/5500 loss 9.181727 loss_att 12.132656 loss_ctc 13.797277 loss_rnnt 7.936609 hw_loss 0.074110 lr 0.00035591 rank 2
2023-02-22 20:55:43,020 DEBUG TRAIN Batch 23/5600 loss 8.503876 loss_att 12.602463 loss_ctc 16.156973 loss_rnnt 6.639630 hw_loss 0.045214 lr 0.00035587 rank 4
2023-02-22 20:55:43,026 DEBUG TRAIN Batch 23/5600 loss 10.444415 loss_att 12.847603 loss_ctc 17.871967 loss_rnnt 8.924552 hw_loss 0.091661 lr 0.00035584 rank 3
2023-02-22 20:55:43,027 DEBUG TRAIN Batch 23/5600 loss 8.861089 loss_att 12.604890 loss_ctc 13.384155 loss_rnnt 7.487827 hw_loss 0.040174 lr 0.00035587 rank 5
2023-02-22 20:55:43,030 DEBUG TRAIN Batch 23/5600 loss 4.967671 loss_att 7.669411 loss_ctc 8.338247 loss_rnnt 3.922084 hw_loss 0.104680 lr 0.00035589 rank 6
2023-02-22 20:55:43,031 DEBUG TRAIN Batch 23/5600 loss 9.774842 loss_att 12.211550 loss_ctc 15.471156 loss_rnnt 8.465321 hw_loss 0.117510 lr 0.00035588 rank 1
2023-02-22 20:55:43,034 DEBUG TRAIN Batch 23/5600 loss 7.281123 loss_att 8.972444 loss_ctc 10.593418 loss_rnnt 6.470411 hw_loss 0.057764 lr 0.00035582 rank 2
2023-02-22 20:55:43,047 DEBUG TRAIN Batch 23/5600 loss 13.270106 loss_att 15.322761 loss_ctc 18.013515 loss_rnnt 12.186638 hw_loss 0.075906 lr 0.00035584 rank 7
2023-02-22 20:55:43,057 DEBUG TRAIN Batch 23/5600 loss 13.336929 loss_att 15.722211 loss_ctc 17.885578 loss_rnnt 12.199247 hw_loss 0.101512 lr 0.00035587 rank 0
2023-02-22 20:57:01,663 DEBUG TRAIN Batch 23/5700 loss 9.041307 loss_att 11.377192 loss_ctc 10.611371 loss_rnnt 8.288397 hw_loss 0.143236 lr 0.00035580 rank 6
2023-02-22 20:57:01,667 DEBUG TRAIN Batch 23/5700 loss 6.458695 loss_att 8.545207 loss_ctc 10.956116 loss_rnnt 5.334648 hw_loss 0.200791 lr 0.00035578 rank 0
2023-02-22 20:57:01,667 DEBUG TRAIN Batch 23/5700 loss 8.118640 loss_att 12.774328 loss_ctc 12.512902 loss_rnnt 6.581232 hw_loss 0.038190 lr 0.00035579 rank 1
2023-02-22 20:57:01,668 DEBUG TRAIN Batch 23/5700 loss 11.263196 loss_att 12.223090 loss_ctc 16.378321 loss_rnnt 10.315693 hw_loss 0.137828 lr 0.00035578 rank 5
2023-02-22 20:57:01,669 DEBUG TRAIN Batch 23/5700 loss 11.557556 loss_att 11.387506 loss_ctc 15.301485 loss_rnnt 11.008357 hw_loss 0.157536 lr 0.00035575 rank 7
2023-02-22 20:57:01,670 DEBUG TRAIN Batch 23/5700 loss 6.349825 loss_att 8.063232 loss_ctc 7.255540 loss_rnnt 5.813122 hw_loss 0.137362 lr 0.00035573 rank 2
2023-02-22 20:57:01,671 DEBUG TRAIN Batch 23/5700 loss 3.911649 loss_att 4.933952 loss_ctc 5.256971 loss_rnnt 3.454567 hw_loss 0.137337 lr 0.00035578 rank 4
2023-02-22 20:57:01,673 DEBUG TRAIN Batch 23/5700 loss 5.340152 loss_att 8.244358 loss_ctc 7.189279 loss_rnnt 4.485667 hw_loss 0.050799 lr 0.00035575 rank 3
2023-02-22 20:58:15,982 DEBUG TRAIN Batch 23/5800 loss 4.397250 loss_att 7.910398 loss_ctc 5.174330 loss_rnnt 3.580527 hw_loss 0.019655 lr 0.00035569 rank 4
2023-02-22 20:58:15,983 DEBUG TRAIN Batch 23/5800 loss 7.974741 loss_att 13.051469 loss_ctc 10.721263 loss_rnnt 6.545269 hw_loss 0.089856 lr 0.00035566 rank 7
2023-02-22 20:58:15,985 DEBUG TRAIN Batch 23/5800 loss 3.807639 loss_att 8.436537 loss_ctc 8.281901 loss_rnnt 2.252100 hw_loss 0.062234 lr 0.00035569 rank 5
2023-02-22 20:58:15,985 DEBUG TRAIN Batch 23/5800 loss 13.610198 loss_att 16.250713 loss_ctc 26.547026 loss_rnnt 11.322166 hw_loss 0.065659 lr 0.00035569 rank 0
2023-02-22 20:58:15,986 DEBUG TRAIN Batch 23/5800 loss 8.084298 loss_att 12.218985 loss_ctc 12.521250 loss_rnnt 6.640232 hw_loss 0.047879 lr 0.00035571 rank 6
2023-02-22 20:58:15,989 DEBUG TRAIN Batch 23/5800 loss 5.044652 loss_att 7.868444 loss_ctc 7.063362 loss_rnnt 4.183208 hw_loss 0.051609 lr 0.00035570 rank 1
2023-02-22 20:58:15,992 DEBUG TRAIN Batch 23/5800 loss 3.507590 loss_att 6.410216 loss_ctc 6.985177 loss_rnnt 2.419094 hw_loss 0.083050 lr 0.00035566 rank 3
2023-02-22 20:58:16,033 DEBUG TRAIN Batch 23/5800 loss 5.133691 loss_att 9.222449 loss_ctc 8.561504 loss_rnnt 3.828367 hw_loss 0.057245 lr 0.00035564 rank 2
2023-02-22 20:59:32,144 DEBUG TRAIN Batch 23/5900 loss 8.454918 loss_att 13.197645 loss_ctc 13.241359 loss_rnnt 6.844467 hw_loss 0.044463 lr 0.00035560 rank 0
2023-02-22 20:59:32,147 DEBUG TRAIN Batch 23/5900 loss 6.960747 loss_att 10.095222 loss_ctc 9.518402 loss_rnnt 5.985978 hw_loss 0.012848 lr 0.00035557 rank 3
2023-02-22 20:59:32,148 DEBUG TRAIN Batch 23/5900 loss 3.912338 loss_att 7.152524 loss_ctc 8.728100 loss_rnnt 2.507500 hw_loss 0.215062 lr 0.00035557 rank 7
2023-02-22 20:59:32,149 DEBUG TRAIN Batch 23/5900 loss 2.475753 loss_att 4.682425 loss_ctc 4.618379 loss_rnnt 1.722095 hw_loss 0.049951 lr 0.00035560 rank 5
2023-02-22 20:59:32,150 DEBUG TRAIN Batch 23/5900 loss 6.917539 loss_att 9.021477 loss_ctc 11.480743 loss_rnnt 5.870557 hw_loss 0.033314 lr 0.00035560 rank 4
2023-02-22 20:59:32,151 DEBUG TRAIN Batch 23/5900 loss 7.659804 loss_att 10.980545 loss_ctc 11.099681 loss_rnnt 6.421493 hw_loss 0.216587 lr 0.00035562 rank 6
2023-02-22 20:59:32,152 DEBUG TRAIN Batch 23/5900 loss 9.458009 loss_att 14.759298 loss_ctc 13.098130 loss_rnnt 7.912259 hw_loss 0.000266 lr 0.00035561 rank 1
2023-02-22 20:59:32,197 DEBUG TRAIN Batch 23/5900 loss 7.516416 loss_att 13.596981 loss_ctc 14.176990 loss_rnnt 5.356213 hw_loss 0.105026 lr 0.00035555 rank 2
2023-02-22 21:00:48,285 DEBUG TRAIN Batch 23/6000 loss 7.038548 loss_att 11.439897 loss_ctc 12.715969 loss_rnnt 5.369216 hw_loss 0.060139 lr 0.00035551 rank 0
2023-02-22 21:00:48,284 DEBUG TRAIN Batch 23/6000 loss 14.870955 loss_att 14.562464 loss_ctc 16.749290 loss_rnnt 14.653163 hw_loss 0.054462 lr 0.00035551 rank 4
2023-02-22 21:00:48,285 DEBUG TRAIN Batch 23/6000 loss 10.192924 loss_att 14.395721 loss_ctc 15.267109 loss_rnnt 8.572814 hw_loss 0.193109 lr 0.00035548 rank 7
2023-02-22 21:00:48,288 DEBUG TRAIN Batch 23/6000 loss 11.949639 loss_att 13.701359 loss_ctc 18.435066 loss_rnnt 10.695253 hw_loss 0.073722 lr 0.00035551 rank 5
2023-02-22 21:00:48,288 DEBUG TRAIN Batch 23/6000 loss 3.835505 loss_att 6.973580 loss_ctc 8.191731 loss_rnnt 2.603115 hw_loss 0.044898 lr 0.00035553 rank 6
2023-02-22 21:00:48,289 DEBUG TRAIN Batch 23/6000 loss 13.698913 loss_att 15.965509 loss_ctc 19.718857 loss_rnnt 12.381495 hw_loss 0.115197 lr 0.00035546 rank 2
2023-02-22 21:00:48,293 DEBUG TRAIN Batch 23/6000 loss 10.008658 loss_att 10.761104 loss_ctc 12.711088 loss_rnnt 9.441614 hw_loss 0.105433 lr 0.00035552 rank 1
2023-02-22 21:00:48,294 DEBUG TRAIN Batch 23/6000 loss 9.247489 loss_att 12.658112 loss_ctc 12.592015 loss_rnnt 8.073713 hw_loss 0.085713 lr 0.00035548 rank 3
2023-02-22 21:02:05,736 DEBUG TRAIN Batch 23/6100 loss 11.758646 loss_att 16.106541 loss_ctc 20.717821 loss_rnnt 9.658778 hw_loss 0.066998 lr 0.00035539 rank 7
2023-02-22 21:02:05,737 DEBUG TRAIN Batch 23/6100 loss 9.068671 loss_att 11.778557 loss_ctc 15.097942 loss_rnnt 7.656407 hw_loss 0.124470 lr 0.00035543 rank 1
2023-02-22 21:02:05,741 DEBUG TRAIN Batch 23/6100 loss 6.277764 loss_att 9.926003 loss_ctc 8.274509 loss_rnnt 5.260377 hw_loss 0.040325 lr 0.00035542 rank 5
2023-02-22 21:02:05,741 DEBUG TRAIN Batch 23/6100 loss 6.675343 loss_att 9.591578 loss_ctc 8.225870 loss_rnnt 5.847571 hw_loss 0.070852 lr 0.00035542 rank 0
2023-02-22 21:02:05,742 DEBUG TRAIN Batch 23/6100 loss 3.017914 loss_att 5.407369 loss_ctc 5.113209 loss_rnnt 2.210730 hw_loss 0.093600 lr 0.00035542 rank 4
2023-02-22 21:02:05,744 DEBUG TRAIN Batch 23/6100 loss 3.427373 loss_att 5.364833 loss_ctc 5.866512 loss_rnnt 2.693568 hw_loss 0.039551 lr 0.00035539 rank 3
2023-02-22 21:02:05,746 DEBUG TRAIN Batch 23/6100 loss 14.804184 loss_att 18.250702 loss_ctc 18.577549 loss_rnnt 13.581669 hw_loss 0.056432 lr 0.00035537 rank 2
2023-02-22 21:02:05,792 DEBUG TRAIN Batch 23/6100 loss 2.605898 loss_att 5.596982 loss_ctc 4.216172 loss_rnnt 1.759162 hw_loss 0.063405 lr 0.00035544 rank 6
2023-02-22 21:03:21,015 DEBUG TRAIN Batch 23/6200 loss 7.416643 loss_att 9.347928 loss_ctc 9.037338 loss_rnnt 6.801787 hw_loss 0.023449 lr 0.00035533 rank 5
2023-02-22 21:03:21,019 DEBUG TRAIN Batch 23/6200 loss 4.538537 loss_att 6.803984 loss_ctc 5.561875 loss_rnnt 3.899094 hw_loss 0.093578 lr 0.00035535 rank 6
2023-02-22 21:03:21,022 DEBUG TRAIN Batch 23/6200 loss 9.174419 loss_att 11.772741 loss_ctc 12.949297 loss_rnnt 8.116176 hw_loss 0.066119 lr 0.00035530 rank 7
2023-02-22 21:03:21,023 DEBUG TRAIN Batch 23/6200 loss 11.362970 loss_att 12.253077 loss_ctc 13.997591 loss_rnnt 10.795593 hw_loss 0.071387 lr 0.00035533 rank 4
2023-02-22 21:03:21,023 DEBUG TRAIN Batch 23/6200 loss 2.644223 loss_att 5.291583 loss_ctc 5.197577 loss_rnnt 1.745503 hw_loss 0.054003 lr 0.00035533 rank 0
2023-02-22 21:03:21,024 DEBUG TRAIN Batch 23/6200 loss 4.970377 loss_att 8.856350 loss_ctc 7.864730 loss_rnnt 3.713514 hw_loss 0.175791 lr 0.00035528 rank 2
2023-02-22 21:03:21,025 DEBUG TRAIN Batch 23/6200 loss 8.923050 loss_att 11.678260 loss_ctc 16.329941 loss_rnnt 7.339126 hw_loss 0.084930 lr 0.00035530 rank 3
2023-02-22 21:03:21,027 DEBUG TRAIN Batch 23/6200 loss 12.997712 loss_att 12.615609 loss_ctc 13.617986 loss_rnnt 12.942562 hw_loss 0.091625 lr 0.00035534 rank 1
2023-02-22 21:04:36,826 DEBUG TRAIN Batch 23/6300 loss 10.510625 loss_att 11.390541 loss_ctc 14.276099 loss_rnnt 9.771385 hw_loss 0.114738 lr 0.00035521 rank 7
2023-02-22 21:04:36,831 DEBUG TRAIN Batch 23/6300 loss 5.655799 loss_att 7.273619 loss_ctc 9.697071 loss_rnnt 4.737340 hw_loss 0.105110 lr 0.00035526 rank 6
2023-02-22 21:04:36,833 DEBUG TRAIN Batch 23/6300 loss 14.505521 loss_att 15.193569 loss_ctc 18.994892 loss_rnnt 13.720291 hw_loss 0.091944 lr 0.00035524 rank 4
2023-02-22 21:04:36,831 DEBUG TRAIN Batch 23/6300 loss 13.664227 loss_att 18.730591 loss_ctc 21.457556 loss_rnnt 11.596403 hw_loss 0.028953 lr 0.00035521 rank 3
2023-02-22 21:04:36,833 DEBUG TRAIN Batch 23/6300 loss 3.277715 loss_att 5.189921 loss_ctc 5.484813 loss_rnnt 2.551777 hw_loss 0.092282 lr 0.00035524 rank 5
2023-02-22 21:04:36,834 DEBUG TRAIN Batch 23/6300 loss 12.438799 loss_att 15.428103 loss_ctc 18.673780 loss_rnnt 10.988751 hw_loss 0.039102 lr 0.00035524 rank 0
2023-02-22 21:04:36,840 DEBUG TRAIN Batch 23/6300 loss 8.980334 loss_att 12.360059 loss_ctc 12.322378 loss_rnnt 7.812401 hw_loss 0.086969 lr 0.00035525 rank 1
2023-02-22 21:04:36,886 DEBUG TRAIN Batch 23/6300 loss 15.024138 loss_att 16.547970 loss_ctc 18.558813 loss_rnnt 14.198877 hw_loss 0.092256 lr 0.00035519 rank 2
2023-02-22 21:05:55,431 DEBUG TRAIN Batch 23/6400 loss 5.749959 loss_att 11.199253 loss_ctc 10.614058 loss_rnnt 3.952951 hw_loss 0.109881 lr 0.00035515 rank 4
2023-02-22 21:05:55,433 DEBUG TRAIN Batch 23/6400 loss 6.757893 loss_att 8.713347 loss_ctc 11.504103 loss_rnnt 5.685572 hw_loss 0.090754 lr 0.00035515 rank 0
2023-02-22 21:05:55,436 DEBUG TRAIN Batch 23/6400 loss 6.164657 loss_att 6.403085 loss_ctc 7.775362 loss_rnnt 5.838831 hw_loss 0.118838 lr 0.00035510 rank 2
2023-02-22 21:05:55,437 DEBUG TRAIN Batch 23/6400 loss 6.956300 loss_att 9.374830 loss_ctc 11.302535 loss_rnnt 5.851251 hw_loss 0.078459 lr 0.00035516 rank 1
2023-02-22 21:05:55,440 DEBUG TRAIN Batch 23/6400 loss 8.494352 loss_att 10.373895 loss_ctc 11.174242 loss_rnnt 7.739362 hw_loss 0.040805 lr 0.00035512 rank 3
2023-02-22 21:05:55,443 DEBUG TRAIN Batch 23/6400 loss 4.938311 loss_att 6.494135 loss_ctc 8.687748 loss_rnnt 4.033596 hw_loss 0.175547 lr 0.00035517 rank 6
2023-02-22 21:05:55,457 DEBUG TRAIN Batch 23/6400 loss 7.452389 loss_att 10.740915 loss_ctc 14.426570 loss_rnnt 5.818556 hw_loss 0.086694 lr 0.00035512 rank 7
2023-02-22 21:05:55,463 DEBUG TRAIN Batch 23/6400 loss 9.311139 loss_att 13.835987 loss_ctc 16.738762 loss_rnnt 7.393008 hw_loss 0.042772 lr 0.00035515 rank 5
2023-02-22 21:07:11,055 DEBUG TRAIN Batch 23/6500 loss 9.230240 loss_att 12.977472 loss_ctc 22.116972 loss_rnnt 6.733351 hw_loss 0.054772 lr 0.00035506 rank 4
2023-02-22 21:07:11,056 DEBUG TRAIN Batch 23/6500 loss 5.979280 loss_att 9.826651 loss_ctc 9.319525 loss_rnnt 4.736578 hw_loss 0.052244 lr 0.00035503 rank 7
2023-02-22 21:07:11,057 DEBUG TRAIN Batch 23/6500 loss 3.286194 loss_att 6.818382 loss_ctc 4.492728 loss_rnnt 2.366599 hw_loss 0.098037 lr 0.00035506 rank 0
2023-02-22 21:07:11,058 DEBUG TRAIN Batch 23/6500 loss 4.750669 loss_att 9.777740 loss_ctc 10.255245 loss_rnnt 2.987143 hw_loss 0.045316 lr 0.00035506 rank 5
2023-02-22 21:07:11,059 DEBUG TRAIN Batch 23/6500 loss 6.668869 loss_att 7.305904 loss_ctc 8.917079 loss_rnnt 6.193054 hw_loss 0.091213 lr 0.00035507 rank 1
2023-02-22 21:07:11,061 DEBUG TRAIN Batch 23/6500 loss 4.944418 loss_att 7.555223 loss_ctc 6.388933 loss_rnnt 4.182701 hw_loss 0.088039 lr 0.00035508 rank 6
2023-02-22 21:07:11,064 DEBUG TRAIN Batch 23/6500 loss 6.679065 loss_att 8.954081 loss_ctc 10.226489 loss_rnnt 5.711750 hw_loss 0.073729 lr 0.00035503 rank 3
2023-02-22 21:07:11,110 DEBUG TRAIN Batch 23/6500 loss 11.909749 loss_att 16.607719 loss_ctc 18.490984 loss_rnnt 10.041981 hw_loss 0.095017 lr 0.00035501 rank 2
2023-02-22 21:08:26,426 DEBUG TRAIN Batch 23/6600 loss 11.804849 loss_att 13.213892 loss_ctc 19.690838 loss_rnnt 10.365669 hw_loss 0.198573 lr 0.00035497 rank 4
2023-02-22 21:08:26,427 DEBUG TRAIN Batch 23/6600 loss 5.774773 loss_att 7.489802 loss_ctc 7.321136 loss_rnnt 5.213211 hw_loss 0.023202 lr 0.00035498 rank 1
2023-02-22 21:08:26,430 DEBUG TRAIN Batch 23/6600 loss 11.559866 loss_att 12.659884 loss_ctc 16.258881 loss_rnnt 10.702612 hw_loss 0.020092 lr 0.00035497 rank 5
2023-02-22 21:08:26,431 DEBUG TRAIN Batch 23/6600 loss 4.216642 loss_att 8.338976 loss_ctc 5.885681 loss_rnnt 3.127501 hw_loss 0.079004 lr 0.00035492 rank 2
2023-02-22 21:08:26,431 DEBUG TRAIN Batch 23/6600 loss 12.062463 loss_att 15.404001 loss_ctc 18.444296 loss_rnnt 10.538767 hw_loss 0.008395 lr 0.00035497 rank 0
2023-02-22 21:08:26,431 DEBUG TRAIN Batch 23/6600 loss 4.356262 loss_att 5.715536 loss_ctc 6.752269 loss_rnnt 3.723804 hw_loss 0.077130 lr 0.00035494 rank 7
2023-02-22 21:08:26,439 DEBUG TRAIN Batch 23/6600 loss 8.569659 loss_att 13.615013 loss_ctc 9.987793 loss_rnnt 7.339989 hw_loss 0.059093 lr 0.00035499 rank 6
2023-02-22 21:08:26,477 DEBUG TRAIN Batch 23/6600 loss 8.663383 loss_att 11.009016 loss_ctc 11.375510 loss_rnnt 7.831224 hw_loss 0.002650 lr 0.00035494 rank 3
2023-02-22 21:09:43,063 DEBUG TRAIN Batch 23/6700 loss 7.261656 loss_att 8.043590 loss_ctc 8.383904 loss_rnnt 6.954773 hw_loss 0.001618 lr 0.00035488 rank 4
2023-02-22 21:09:43,066 DEBUG TRAIN Batch 23/6700 loss 15.468572 loss_att 19.045326 loss_ctc 25.709322 loss_rnnt 13.371907 hw_loss 0.029773 lr 0.00035486 rank 7
2023-02-22 21:09:43,066 DEBUG TRAIN Batch 23/6700 loss 8.886333 loss_att 12.158459 loss_ctc 10.919376 loss_rnnt 7.945854 hw_loss 0.028091 lr 0.00035485 rank 3
2023-02-22 21:09:43,067 DEBUG TRAIN Batch 23/6700 loss 6.118883 loss_att 7.692640 loss_ctc 8.538393 loss_rnnt 5.438147 hw_loss 0.081344 lr 0.00035489 rank 1
2023-02-22 21:09:43,068 DEBUG TRAIN Batch 23/6700 loss 10.159267 loss_att 12.571012 loss_ctc 11.777294 loss_rnnt 9.407331 hw_loss 0.100970 lr 0.00035488 rank 0
2023-02-22 21:09:43,068 DEBUG TRAIN Batch 23/6700 loss 9.600533 loss_att 11.644608 loss_ctc 12.372872 loss_rnnt 8.764854 hw_loss 0.107283 lr 0.00035490 rank 6
2023-02-22 21:09:43,072 DEBUG TRAIN Batch 23/6700 loss 2.476429 loss_att 5.442503 loss_ctc 3.395252 loss_rnnt 1.712383 hw_loss 0.090603 lr 0.00035488 rank 5
2023-02-22 21:09:43,074 DEBUG TRAIN Batch 23/6700 loss 4.574054 loss_att 6.084751 loss_ctc 6.729937 loss_rnnt 3.948709 hw_loss 0.067039 lr 0.00035483 rank 2
2023-02-22 21:11:00,384 DEBUG TRAIN Batch 23/6800 loss 4.859211 loss_att 7.029508 loss_ctc 8.250201 loss_rnnt 3.892919 hw_loss 0.150190 lr 0.00035479 rank 0
2023-02-22 21:11:00,385 DEBUG TRAIN Batch 23/6800 loss 3.473757 loss_att 5.222361 loss_ctc 3.750896 loss_rnnt 3.032547 hw_loss 0.102258 lr 0.00035480 rank 4
2023-02-22 21:11:00,387 DEBUG TRAIN Batch 23/6800 loss 8.782176 loss_att 9.988113 loss_ctc 11.085482 loss_rnnt 8.178760 hw_loss 0.103352 lr 0.00035477 rank 7
2023-02-22 21:11:00,388 DEBUG TRAIN Batch 23/6800 loss 7.245780 loss_att 9.399881 loss_ctc 9.315681 loss_rnnt 6.500236 hw_loss 0.072632 lr 0.00035480 rank 1
2023-02-22 21:11:00,388 DEBUG TRAIN Batch 23/6800 loss 7.822312 loss_att 10.609484 loss_ctc 12.734185 loss_rnnt 6.603636 hw_loss 0.011860 lr 0.00035479 rank 5
2023-02-22 21:11:00,391 DEBUG TRAIN Batch 23/6800 loss 6.114881 loss_att 9.700530 loss_ctc 8.311180 loss_rnnt 5.085081 hw_loss 0.037181 lr 0.00035474 rank 2
2023-02-22 21:11:00,392 DEBUG TRAIN Batch 23/6800 loss 6.481851 loss_att 8.724634 loss_ctc 9.769755 loss_rnnt 5.546840 hw_loss 0.090126 lr 0.00035481 rank 6
2023-02-22 21:11:00,392 DEBUG TRAIN Batch 23/6800 loss 7.417650 loss_att 9.381062 loss_ctc 9.230455 loss_rnnt 6.744216 hw_loss 0.073206 lr 0.00035476 rank 3
2023-02-22 21:12:15,079 DEBUG TRAIN Batch 23/6900 loss 11.946335 loss_att 15.383093 loss_ctc 15.430466 loss_rnnt 10.741347 hw_loss 0.099536 lr 0.00035471 rank 4
2023-02-22 21:12:15,080 DEBUG TRAIN Batch 23/6900 loss 10.462196 loss_att 12.943261 loss_ctc 15.312510 loss_rnnt 9.286559 hw_loss 0.061343 lr 0.00035468 rank 7
2023-02-22 21:12:15,080 DEBUG TRAIN Batch 23/6900 loss 10.168718 loss_att 12.271646 loss_ctc 14.083599 loss_rnnt 9.178083 hw_loss 0.090122 lr 0.00035472 rank 6
2023-02-22 21:12:15,082 DEBUG TRAIN Batch 23/6900 loss 9.907681 loss_att 14.077650 loss_ctc 14.065155 loss_rnnt 8.519266 hw_loss 0.000171 lr 0.00035471 rank 1
2023-02-22 21:12:15,083 DEBUG TRAIN Batch 23/6900 loss 8.104687 loss_att 9.459821 loss_ctc 11.252431 loss_rnnt 7.358254 hw_loss 0.104450 lr 0.00035470 rank 5
2023-02-22 21:12:15,085 DEBUG TRAIN Batch 23/6900 loss 2.531319 loss_att 4.198780 loss_ctc 3.361147 loss_rnnt 2.067777 hw_loss 0.036387 lr 0.00035470 rank 0
2023-02-22 21:12:15,087 DEBUG TRAIN Batch 23/6900 loss 7.085711 loss_att 8.494630 loss_ctc 9.620383 loss_rnnt 6.456365 hw_loss 0.018013 lr 0.00035467 rank 3
2023-02-22 21:12:15,089 DEBUG TRAIN Batch 23/6900 loss 7.729711 loss_att 8.886128 loss_ctc 13.258736 loss_rnnt 6.721863 hw_loss 0.073804 lr 0.00035465 rank 2
2023-02-22 21:13:30,640 DEBUG TRAIN Batch 23/7000 loss 13.833097 loss_att 17.501720 loss_ctc 23.946901 loss_rnnt 11.635352 hw_loss 0.216585 lr 0.00035461 rank 0
2023-02-22 21:13:30,642 DEBUG TRAIN Batch 23/7000 loss 11.851191 loss_att 14.401180 loss_ctc 14.407825 loss_rnnt 10.919558 hw_loss 0.151406 lr 0.00035459 rank 7
2023-02-22 21:13:30,645 DEBUG TRAIN Batch 23/7000 loss 10.776599 loss_att 14.049769 loss_ctc 15.011195 loss_rnnt 9.507494 hw_loss 0.093483 lr 0.00035463 rank 6
2023-02-22 21:13:30,647 DEBUG TRAIN Batch 23/7000 loss 9.659444 loss_att 11.696151 loss_ctc 13.184614 loss_rnnt 8.740995 hw_loss 0.077032 lr 0.00035462 rank 1
2023-02-22 21:13:30,648 DEBUG TRAIN Batch 23/7000 loss 6.314692 loss_att 10.630014 loss_ctc 10.175439 loss_rnnt 4.936808 hw_loss 0.000100 lr 0.00035462 rank 4
2023-02-22 21:13:30,649 DEBUG TRAIN Batch 23/7000 loss 2.614621 loss_att 4.898637 loss_ctc 5.172695 loss_rnnt 1.713892 hw_loss 0.192841 lr 0.00035461 rank 5
2023-02-22 21:13:30,651 DEBUG TRAIN Batch 23/7000 loss 10.111523 loss_att 11.279020 loss_ctc 14.473692 loss_rnnt 9.250733 hw_loss 0.085622 lr 0.00035456 rank 2
2023-02-22 21:13:30,670 DEBUG TRAIN Batch 23/7000 loss 9.300644 loss_att 9.616713 loss_ctc 13.300995 loss_rnnt 8.616104 hw_loss 0.164897 lr 0.00035458 rank 3
2023-02-22 21:14:49,493 DEBUG TRAIN Batch 23/7100 loss 5.708274 loss_att 8.212498 loss_ctc 9.794388 loss_rnnt 4.624484 hw_loss 0.071496 lr 0.00035452 rank 0
2023-02-22 21:14:49,494 DEBUG TRAIN Batch 23/7100 loss 3.570124 loss_att 6.255291 loss_ctc 4.971975 loss_rnnt 2.784513 hw_loss 0.115621 lr 0.00035452 rank 5
2023-02-22 21:14:49,496 DEBUG TRAIN Batch 23/7100 loss 9.998247 loss_att 10.631389 loss_ctc 12.600703 loss_rnnt 9.451442 hw_loss 0.137216 lr 0.00035453 rank 1
2023-02-22 21:14:49,497 DEBUG TRAIN Batch 23/7100 loss 8.988544 loss_att 13.188641 loss_ctc 12.668491 loss_rnnt 7.590369 hw_loss 0.126554 lr 0.00035450 rank 7
2023-02-22 21:14:49,500 DEBUG TRAIN Batch 23/7100 loss 9.538931 loss_att 11.028826 loss_ctc 11.425120 loss_rnnt 8.918900 hw_loss 0.132302 lr 0.00035454 rank 6
2023-02-22 21:14:49,500 DEBUG TRAIN Batch 23/7100 loss 6.563269 loss_att 11.189485 loss_ctc 11.616866 loss_rnnt 4.930652 hw_loss 0.062926 lr 0.00035453 rank 4
2023-02-22 21:14:49,502 DEBUG TRAIN Batch 23/7100 loss 11.259287 loss_att 14.336031 loss_ctc 16.575218 loss_rnnt 9.889534 hw_loss 0.085522 lr 0.00035447 rank 2
2023-02-22 21:14:49,508 DEBUG TRAIN Batch 23/7100 loss 3.014754 loss_att 7.098122 loss_ctc 5.775747 loss_rnnt 1.792140 hw_loss 0.070890 lr 0.00035450 rank 3
2023-02-22 21:16:04,493 DEBUG TRAIN Batch 23/7200 loss 8.210899 loss_att 10.248616 loss_ctc 12.555319 loss_rnnt 7.174341 hw_loss 0.093298 lr 0.00035444 rank 4
2023-02-22 21:16:04,493 DEBUG TRAIN Batch 23/7200 loss 17.954241 loss_att 22.178276 loss_ctc 23.245312 loss_rnnt 16.331999 hw_loss 0.134921 lr 0.00035443 rank 0
2023-02-22 21:16:04,493 DEBUG TRAIN Batch 23/7200 loss 5.039400 loss_att 9.045227 loss_ctc 9.662635 loss_rnnt 3.592896 hw_loss 0.054201 lr 0.00035443 rank 5
2023-02-22 21:16:04,494 DEBUG TRAIN Batch 23/7200 loss 10.742163 loss_att 16.050917 loss_ctc 16.517002 loss_rnnt 8.882563 hw_loss 0.052257 lr 0.00035445 rank 6
2023-02-22 21:16:04,496 DEBUG TRAIN Batch 23/7200 loss 9.551608 loss_att 14.175581 loss_ctc 14.737909 loss_rnnt 7.861938 hw_loss 0.137565 lr 0.00035444 rank 1
2023-02-22 21:16:04,496 DEBUG TRAIN Batch 23/7200 loss 10.122156 loss_att 13.763363 loss_ctc 15.589377 loss_rnnt 8.634811 hw_loss 0.056511 lr 0.00035441 rank 7
2023-02-22 21:16:04,499 DEBUG TRAIN Batch 23/7200 loss 4.333735 loss_att 7.975043 loss_ctc 8.192896 loss_rnnt 3.057806 hw_loss 0.062084 lr 0.00035441 rank 3
2023-02-22 21:16:04,499 DEBUG TRAIN Batch 23/7200 loss 2.188154 loss_att 4.791001 loss_ctc 2.310211 loss_rnnt 1.566348 hw_loss 0.159305 lr 0.00035439 rank 2
2023-02-22 21:17:19,629 DEBUG TRAIN Batch 23/7300 loss 5.188824 loss_att 8.518337 loss_ctc 10.509462 loss_rnnt 3.775106 hw_loss 0.071995 lr 0.00035434 rank 0
2023-02-22 21:17:19,633 DEBUG TRAIN Batch 23/7300 loss 6.122746 loss_att 9.405765 loss_ctc 9.403617 loss_rnnt 4.980213 hw_loss 0.090899 lr 0.00035435 rank 1
2023-02-22 21:17:19,634 DEBUG TRAIN Batch 23/7300 loss 9.591075 loss_att 12.452669 loss_ctc 12.311127 loss_rnnt 8.597695 hw_loss 0.109476 lr 0.00035435 rank 4
2023-02-22 21:17:19,634 DEBUG TRAIN Batch 23/7300 loss 3.297538 loss_att 6.750487 loss_ctc 4.625250 loss_rnnt 2.393615 hw_loss 0.068070 lr 0.00035430 rank 2
2023-02-22 21:17:19,635 DEBUG TRAIN Batch 23/7300 loss 8.044538 loss_att 10.811193 loss_ctc 16.659622 loss_rnnt 6.331905 hw_loss 0.019918 lr 0.00035435 rank 5
2023-02-22 21:17:19,635 DEBUG TRAIN Batch 23/7300 loss 6.174757 loss_att 9.685415 loss_ctc 7.752404 loss_rnnt 5.186867 hw_loss 0.141386 lr 0.00035432 rank 7
2023-02-22 21:17:19,638 DEBUG TRAIN Batch 23/7300 loss 8.246634 loss_att 12.154094 loss_ctc 11.104602 loss_rnnt 7.034515 hw_loss 0.092930 lr 0.00035437 rank 6
2023-02-22 21:17:19,682 DEBUG TRAIN Batch 23/7300 loss 15.294776 loss_att 19.254711 loss_ctc 22.828259 loss_rnnt 13.430799 hw_loss 0.126612 lr 0.00035432 rank 3
2023-02-22 21:18:36,720 DEBUG TRAIN Batch 23/7400 loss 6.246081 loss_att 9.663610 loss_ctc 9.713828 loss_rnnt 5.047021 hw_loss 0.099728 lr 0.00035426 rank 0
2023-02-22 21:18:36,722 DEBUG TRAIN Batch 23/7400 loss 11.484676 loss_att 13.784761 loss_ctc 19.201107 loss_rnnt 9.939804 hw_loss 0.104994 lr 0.00035428 rank 6
2023-02-22 21:18:36,723 DEBUG TRAIN Batch 23/7400 loss 3.844666 loss_att 8.315423 loss_ctc 6.847337 loss_rnnt 2.496455 hw_loss 0.100693 lr 0.00035426 rank 5
2023-02-22 21:18:36,723 DEBUG TRAIN Batch 23/7400 loss 11.621028 loss_att 14.874084 loss_ctc 15.919228 loss_rnnt 10.307480 hw_loss 0.168457 lr 0.00035423 rank 7
2023-02-22 21:18:36,725 DEBUG TRAIN Batch 23/7400 loss 3.258716 loss_att 7.638906 loss_ctc 7.334254 loss_rnnt 1.779746 hw_loss 0.111614 lr 0.00035421 rank 2
2023-02-22 21:18:36,727 DEBUG TRAIN Batch 23/7400 loss 4.112648 loss_att 5.743100 loss_ctc 6.614777 loss_rnnt 3.430044 hw_loss 0.042932 lr 0.00035426 rank 4
2023-02-22 21:18:36,729 DEBUG TRAIN Batch 23/7400 loss 6.239450 loss_att 9.790809 loss_ctc 11.189273 loss_rnnt 4.835728 hw_loss 0.062762 lr 0.00035426 rank 1
2023-02-22 21:18:36,745 DEBUG TRAIN Batch 23/7400 loss 8.292172 loss_att 11.422648 loss_ctc 12.769290 loss_rnnt 7.023500 hw_loss 0.085555 lr 0.00035423 rank 3
2023-02-22 21:19:53,761 DEBUG TRAIN Batch 23/7500 loss 7.627468 loss_att 9.971416 loss_ctc 10.889979 loss_rnnt 6.628285 hw_loss 0.178858 lr 0.00035417 rank 5
2023-02-22 21:19:53,763 DEBUG TRAIN Batch 23/7500 loss 7.077027 loss_att 8.992290 loss_ctc 10.856695 loss_rnnt 6.174472 hw_loss 0.029150 lr 0.00035417 rank 0
2023-02-22 21:19:53,767 DEBUG TRAIN Batch 23/7500 loss 13.578872 loss_att 16.089174 loss_ctc 16.380713 loss_rnnt 12.684321 hw_loss 0.035460 lr 0.00035418 rank 1
2023-02-22 21:19:53,767 DEBUG TRAIN Batch 23/7500 loss 7.943962 loss_att 11.639181 loss_ctc 9.326938 loss_rnnt 7.012254 hw_loss 0.015501 lr 0.00035414 rank 7
2023-02-22 21:19:53,767 DEBUG TRAIN Batch 23/7500 loss 7.463378 loss_att 9.402973 loss_ctc 15.548502 loss_rnnt 5.955517 hw_loss 0.078611 lr 0.00035417 rank 4
2023-02-22 21:19:53,770 DEBUG TRAIN Batch 23/7500 loss 6.757295 loss_att 8.958507 loss_ctc 9.510203 loss_rnnt 5.903910 hw_loss 0.086415 lr 0.00035414 rank 3
2023-02-22 21:19:53,770 DEBUG TRAIN Batch 23/7500 loss 7.742651 loss_att 8.666521 loss_ctc 11.244057 loss_rnnt 7.056042 hw_loss 0.065588 lr 0.00035419 rank 6
2023-02-22 21:19:53,772 DEBUG TRAIN Batch 23/7500 loss 7.140033 loss_att 11.653081 loss_ctc 12.114561 loss_rnnt 5.533926 hw_loss 0.075427 lr 0.00035412 rank 2
2023-02-22 21:21:07,717 DEBUG TRAIN Batch 23/7600 loss 14.175525 loss_att 12.938700 loss_ctc 19.575422 loss_rnnt 13.627134 hw_loss 0.142067 lr 0.00035408 rank 5
2023-02-22 21:21:07,721 DEBUG TRAIN Batch 23/7600 loss 7.758811 loss_att 7.978541 loss_ctc 12.026772 loss_rnnt 7.093103 hw_loss 0.098811 lr 0.00035408 rank 4
2023-02-22 21:21:07,723 DEBUG TRAIN Batch 23/7600 loss 17.040962 loss_att 17.475174 loss_ctc 22.308540 loss_rnnt 16.188137 hw_loss 0.119326 lr 0.00035405 rank 3
2023-02-22 21:21:07,724 DEBUG TRAIN Batch 23/7600 loss 3.910179 loss_att 7.788543 loss_ctc 7.565912 loss_rnnt 2.584534 hw_loss 0.117265 lr 0.00035410 rank 6
2023-02-22 21:21:07,725 DEBUG TRAIN Batch 23/7600 loss 7.791977 loss_att 11.174948 loss_ctc 10.197081 loss_rnnt 6.701585 hw_loss 0.174594 lr 0.00035408 rank 0
2023-02-22 21:21:07,725 DEBUG TRAIN Batch 23/7600 loss 4.309161 loss_att 8.232500 loss_ctc 9.129597 loss_rnnt 2.844849 hw_loss 0.069224 lr 0.00035405 rank 7
2023-02-22 21:21:07,729 DEBUG TRAIN Batch 23/7600 loss 8.630000 loss_att 8.137165 loss_ctc 10.490306 loss_rnnt 8.387164 hw_loss 0.175053 lr 0.00035403 rank 2
2023-02-22 21:21:07,732 DEBUG TRAIN Batch 23/7600 loss 11.647143 loss_att 13.857578 loss_ctc 17.095570 loss_rnnt 10.466626 hw_loss 0.022449 lr 0.00035409 rank 1
2023-02-22 21:22:22,899 DEBUG TRAIN Batch 23/7700 loss 9.085866 loss_att 10.034268 loss_ctc 12.304477 loss_rnnt 8.431439 hw_loss 0.066745 lr 0.00035396 rank 3
2023-02-22 21:22:22,900 DEBUG TRAIN Batch 23/7700 loss 6.562771 loss_att 7.054944 loss_ctc 9.003737 loss_rnnt 6.007662 hw_loss 0.246022 lr 0.00035399 rank 0
2023-02-22 21:22:22,902 DEBUG TRAIN Batch 23/7700 loss 6.403574 loss_att 7.256480 loss_ctc 9.980939 loss_rnnt 5.736820 hw_loss 0.035983 lr 0.00035399 rank 5
2023-02-22 21:22:22,904 DEBUG TRAIN Batch 23/7700 loss 5.748211 loss_att 8.711732 loss_ctc 7.637519 loss_rnnt 4.856702 hw_loss 0.087931 lr 0.00035397 rank 7
2023-02-22 21:22:22,906 DEBUG TRAIN Batch 23/7700 loss 12.344657 loss_att 13.547164 loss_ctc 19.546822 loss_rnnt 11.127844 hw_loss 0.030042 lr 0.00035399 rank 4
2023-02-22 21:22:22,909 DEBUG TRAIN Batch 23/7700 loss 9.137042 loss_att 9.718306 loss_ctc 11.216233 loss_rnnt 8.693791 hw_loss 0.093323 lr 0.00035400 rank 1
2023-02-22 21:22:22,915 DEBUG TRAIN Batch 23/7700 loss 7.554751 loss_att 10.113943 loss_ctc 10.866893 loss_rnnt 6.585857 hw_loss 0.028944 lr 0.00035394 rank 2
2023-02-22 21:22:22,925 DEBUG TRAIN Batch 23/7700 loss 6.624244 loss_att 7.733630 loss_ctc 10.844377 loss_rnnt 5.744950 hw_loss 0.177621 lr 0.00035401 rank 6
2023-02-22 21:23:39,771 DEBUG TRAIN Batch 23/7800 loss 7.984651 loss_att 9.682909 loss_ctc 9.412194 loss_rnnt 7.409378 hw_loss 0.084903 lr 0.00035391 rank 4
2023-02-22 21:23:39,771 DEBUG TRAIN Batch 23/7800 loss 3.594331 loss_att 6.791767 loss_ctc 9.543724 loss_rnnt 2.139024 hw_loss 0.042314 lr 0.00035390 rank 0
2023-02-22 21:23:39,774 DEBUG TRAIN Batch 23/7800 loss 7.362474 loss_att 10.628328 loss_ctc 10.185855 loss_rnnt 6.278811 hw_loss 0.101326 lr 0.00035388 rank 7
2023-02-22 21:23:39,774 DEBUG TRAIN Batch 23/7800 loss 6.116600 loss_att 9.974682 loss_ctc 10.521263 loss_rnnt 4.743480 hw_loss 0.026651 lr 0.00035387 rank 3
2023-02-22 21:23:39,780 DEBUG TRAIN Batch 23/7800 loss 5.504354 loss_att 7.433940 loss_ctc 7.041736 loss_rnnt 4.837812 hw_loss 0.141823 lr 0.00035390 rank 5
2023-02-22 21:23:39,784 DEBUG TRAIN Batch 23/7800 loss 12.119174 loss_att 14.344505 loss_ctc 17.367231 loss_rnnt 10.901942 hw_loss 0.135797 lr 0.00035385 rank 2
2023-02-22 21:23:39,808 DEBUG TRAIN Batch 23/7800 loss 4.626579 loss_att 11.212043 loss_ctc 8.347288 loss_rnnt 2.807763 hw_loss 0.010554 lr 0.00035392 rank 6
2023-02-22 21:23:39,811 DEBUG TRAIN Batch 23/7800 loss 17.016321 loss_att 26.293900 loss_ctc 26.779140 loss_rnnt 13.827763 hw_loss 0.058751 lr 0.00035391 rank 1
2023-02-22 21:24:56,175 DEBUG TRAIN Batch 23/7900 loss 25.151735 loss_att 26.886698 loss_ctc 37.693962 loss_rnnt 23.132126 hw_loss 0.000601 lr 0.00035382 rank 1
2023-02-22 21:24:56,176 DEBUG TRAIN Batch 23/7900 loss 9.751809 loss_att 13.505370 loss_ctc 17.707523 loss_rnnt 7.906038 hw_loss 0.064307 lr 0.00035381 rank 0
2023-02-22 21:24:56,178 DEBUG TRAIN Batch 23/7900 loss 3.259682 loss_att 5.085665 loss_ctc 3.597866 loss_rnnt 2.812701 hw_loss 0.068801 lr 0.00035379 rank 7
2023-02-22 21:24:56,178 DEBUG TRAIN Batch 23/7900 loss 8.313435 loss_att 9.973123 loss_ctc 13.941073 loss_rnnt 7.187237 hw_loss 0.082328 lr 0.00035381 rank 5
2023-02-22 21:24:56,178 DEBUG TRAIN Batch 23/7900 loss 11.771871 loss_att 14.330786 loss_ctc 20.766062 loss_rnnt 10.011350 hw_loss 0.092833 lr 0.00035376 rank 2
2023-02-22 21:24:56,179 DEBUG TRAIN Batch 23/7900 loss 6.058892 loss_att 8.767962 loss_ctc 5.540888 loss_rnnt 5.515248 hw_loss 0.132933 lr 0.00035382 rank 4
2023-02-22 21:24:56,184 DEBUG TRAIN Batch 23/7900 loss 9.352041 loss_att 12.406944 loss_ctc 12.658767 loss_rnnt 8.297647 hw_loss 0.004718 lr 0.00035379 rank 3
2023-02-22 21:24:56,185 DEBUG TRAIN Batch 23/7900 loss 5.286206 loss_att 8.203086 loss_ctc 8.638143 loss_rnnt 4.197813 hw_loss 0.108921 lr 0.00035383 rank 6
2023-02-22 21:26:11,608 DEBUG TRAIN Batch 23/8000 loss 4.739489 loss_att 8.170124 loss_ctc 5.799487 loss_rnnt 3.886867 hw_loss 0.047177 lr 0.00035372 rank 0
2023-02-22 21:26:11,610 DEBUG TRAIN Batch 23/8000 loss 9.333879 loss_att 14.634281 loss_ctc 13.918990 loss_rnnt 7.563898 hw_loss 0.184783 lr 0.00035370 rank 3
2023-02-22 21:26:11,611 DEBUG TRAIN Batch 23/8000 loss 12.570849 loss_att 15.041153 loss_ctc 18.169142 loss_rnnt 11.271904 hw_loss 0.109585 lr 0.00035373 rank 4
2023-02-22 21:26:11,612 DEBUG TRAIN Batch 23/8000 loss 15.855005 loss_att 18.879347 loss_ctc 22.093580 loss_rnnt 14.392006 hw_loss 0.049354 lr 0.00035373 rank 1
2023-02-22 21:26:11,616 DEBUG TRAIN Batch 23/8000 loss 9.549685 loss_att 12.969318 loss_ctc 11.951750 loss_rnnt 8.494669 hw_loss 0.095274 lr 0.00035368 rank 2
2023-02-22 21:26:11,617 DEBUG TRAIN Batch 23/8000 loss 15.428130 loss_att 18.965158 loss_ctc 25.274662 loss_rnnt 13.389927 hw_loss 0.033610 lr 0.00035372 rank 5
2023-02-22 21:26:11,619 DEBUG TRAIN Batch 23/8000 loss 9.637624 loss_att 12.851681 loss_ctc 11.524150 loss_rnnt 8.714798 hw_loss 0.053394 lr 0.00035374 rank 6
2023-02-22 21:26:11,626 DEBUG TRAIN Batch 23/8000 loss 10.153066 loss_att 13.889024 loss_ctc 13.632811 loss_rnnt 8.941866 hw_loss 0.000079 lr 0.00035370 rank 7
2023-02-22 21:27:26,898 DEBUG TRAIN Batch 23/8100 loss 8.145712 loss_att 9.485344 loss_ctc 11.051342 loss_rnnt 7.452796 hw_loss 0.070446 lr 0.00035363 rank 0
2023-02-22 21:27:26,901 DEBUG TRAIN Batch 23/8100 loss 12.229077 loss_att 15.305672 loss_ctc 18.389009 loss_rnnt 10.751806 hw_loss 0.076178 lr 0.00035364 rank 5
2023-02-22 21:27:26,903 DEBUG TRAIN Batch 23/8100 loss 8.517711 loss_att 15.640963 loss_ctc 15.713480 loss_rnnt 6.088070 hw_loss 0.085413 lr 0.00035364 rank 4
2023-02-22 21:27:26,902 DEBUG TRAIN Batch 23/8100 loss 6.583178 loss_att 8.763194 loss_ctc 9.656633 loss_rnnt 5.711539 hw_loss 0.048453 lr 0.00035361 rank 7
2023-02-22 21:27:26,902 DEBUG TRAIN Batch 23/8100 loss 8.784145 loss_att 10.343178 loss_ctc 9.991673 loss_rnnt 8.292616 hw_loss 0.035097 lr 0.00035364 rank 1
2023-02-22 21:27:26,902 DEBUG TRAIN Batch 23/8100 loss 8.277980 loss_att 10.860494 loss_ctc 11.787189 loss_rnnt 7.265937 hw_loss 0.051835 lr 0.00035366 rank 6
2023-02-22 21:27:26,903 DEBUG TRAIN Batch 23/8100 loss 5.760327 loss_att 8.927633 loss_ctc 10.150892 loss_rnnt 4.524745 hw_loss 0.031334 lr 0.00035361 rank 3
2023-02-22 21:27:26,906 DEBUG TRAIN Batch 23/8100 loss 14.651940 loss_att 18.337914 loss_ctc 18.537235 loss_rnnt 13.376070 hw_loss 0.038693 lr 0.00035359 rank 2
2023-02-22 21:28:43,511 DEBUG TRAIN Batch 23/8200 loss 9.087934 loss_att 9.086710 loss_ctc 13.781733 loss_rnnt 8.387716 hw_loss 0.139917 lr 0.00035355 rank 5
2023-02-22 21:28:43,512 DEBUG TRAIN Batch 23/8200 loss 13.693399 loss_att 17.871578 loss_ctc 17.374950 loss_rnnt 12.353486 hw_loss 0.025131 lr 0.00035355 rank 0
2023-02-22 21:28:43,512 DEBUG TRAIN Batch 23/8200 loss 4.136521 loss_att 6.075594 loss_ctc 7.421974 loss_rnnt 3.283906 hw_loss 0.050136 lr 0.00035355 rank 4
2023-02-22 21:28:43,519 DEBUG TRAIN Batch 23/8200 loss 10.847444 loss_att 10.344654 loss_ctc 13.774617 loss_rnnt 10.439499 hw_loss 0.221650 lr 0.00035352 rank 7
2023-02-22 21:28:43,520 DEBUG TRAIN Batch 23/8200 loss 8.690432 loss_att 11.683816 loss_ctc 10.637434 loss_rnnt 7.767247 hw_loss 0.121701 lr 0.00035356 rank 1
2023-02-22 21:28:43,522 DEBUG TRAIN Batch 23/8200 loss 11.606607 loss_att 14.399634 loss_ctc 16.989044 loss_rnnt 10.282072 hw_loss 0.090509 lr 0.00035352 rank 3
2023-02-22 21:28:43,522 DEBUG TRAIN Batch 23/8200 loss 11.960797 loss_att 15.751935 loss_ctc 16.075600 loss_rnnt 10.582234 hw_loss 0.134427 lr 0.00035357 rank 6
2023-02-22 21:28:43,525 DEBUG TRAIN Batch 23/8200 loss 6.201833 loss_att 7.971960 loss_ctc 8.309839 loss_rnnt 5.555856 hw_loss 0.020408 lr 0.00035350 rank 2
2023-02-22 21:29:57,136 DEBUG TRAIN Batch 23/8300 loss 13.019626 loss_att 13.022923 loss_ctc 15.847007 loss_rnnt 12.608211 hw_loss 0.063322 lr 0.00035346 rank 4
2023-02-22 21:29:57,136 DEBUG TRAIN Batch 23/8300 loss 13.878033 loss_att 16.811897 loss_ctc 21.783733 loss_rnnt 12.230052 hw_loss 0.013341 lr 0.00035346 rank 5
2023-02-22 21:29:57,137 DEBUG TRAIN Batch 23/8300 loss 4.112453 loss_att 8.867992 loss_ctc 7.879755 loss_rnnt 2.579842 hw_loss 0.148493 lr 0.00035347 rank 1
2023-02-22 21:29:57,138 DEBUG TRAIN Batch 23/8300 loss 7.231483 loss_att 9.361763 loss_ctc 10.193128 loss_rnnt 6.363777 hw_loss 0.087683 lr 0.00035346 rank 0
2023-02-22 21:29:57,138 DEBUG TRAIN Batch 23/8300 loss 8.064278 loss_att 10.924764 loss_ctc 11.283099 loss_rnnt 7.031030 hw_loss 0.059951 lr 0.00035343 rank 7
2023-02-22 21:29:57,142 DEBUG TRAIN Batch 23/8300 loss 7.504841 loss_att 8.098300 loss_ctc 9.531946 loss_rnnt 7.073305 hw_loss 0.079807 lr 0.00035343 rank 3
2023-02-22 21:29:57,143 DEBUG TRAIN Batch 23/8300 loss 7.580468 loss_att 8.939127 loss_ctc 11.640720 loss_rnnt 6.713825 hw_loss 0.100396 lr 0.00035348 rank 6
2023-02-22 21:29:57,149 DEBUG TRAIN Batch 23/8300 loss 7.199466 loss_att 8.372145 loss_ctc 6.407047 loss_rnnt 7.040562 hw_loss 0.056297 lr 0.00035341 rank 2
2023-02-22 21:30:40,519 DEBUG CV Batch 23/0 loss 1.576231 loss_att 1.690946 loss_ctc 2.135497 loss_rnnt 1.389438 hw_loss 0.167403 history loss 1.517852 rank 2
2023-02-22 21:30:40,522 DEBUG CV Batch 23/0 loss 1.576231 loss_att 1.690946 loss_ctc 2.135497 loss_rnnt 1.389438 hw_loss 0.167403 history loss 1.517852 rank 7
2023-02-22 21:30:40,524 DEBUG CV Batch 23/0 loss 1.576231 loss_att 1.690946 loss_ctc 2.135497 loss_rnnt 1.389438 hw_loss 0.167403 history loss 1.517852 rank 1
2023-02-22 21:30:40,525 DEBUG CV Batch 23/0 loss 1.576231 loss_att 1.690946 loss_ctc 2.135497 loss_rnnt 1.389438 hw_loss 0.167403 history loss 1.517852 rank 5
2023-02-22 21:30:40,529 DEBUG CV Batch 23/0 loss 1.576231 loss_att 1.690946 loss_ctc 2.135497 loss_rnnt 1.389438 hw_loss 0.167403 history loss 1.517852 rank 6
2023-02-22 21:30:40,536 DEBUG CV Batch 23/0 loss 1.576231 loss_att 1.690946 loss_ctc 2.135497 loss_rnnt 1.389438 hw_loss 0.167403 history loss 1.517852 rank 3
2023-02-22 21:30:40,538 DEBUG CV Batch 23/0 loss 1.576231 loss_att 1.690946 loss_ctc 2.135497 loss_rnnt 1.389438 hw_loss 0.167403 history loss 1.517852 rank 4
2023-02-22 21:30:40,550 DEBUG CV Batch 23/0 loss 1.576231 loss_att 1.690946 loss_ctc 2.135497 loss_rnnt 1.389438 hw_loss 0.167403 history loss 1.517852 rank 0
2023-02-22 21:30:51,644 DEBUG CV Batch 23/100 loss 6.534327 loss_att 6.529660 loss_ctc 8.733244 loss_rnnt 6.191442 hw_loss 0.094930 history loss 3.220378 rank 7
2023-02-22 21:30:51,697 DEBUG CV Batch 23/100 loss 6.534327 loss_att 6.529660 loss_ctc 8.733244 loss_rnnt 6.191442 hw_loss 0.094930 history loss 3.220377 rank 4
2023-02-22 21:30:51,709 DEBUG CV Batch 23/100 loss 6.534327 loss_att 6.529660 loss_ctc 8.733244 loss_rnnt 6.191442 hw_loss 0.094930 history loss 3.220378 rank 5
2023-02-22 21:30:51,712 DEBUG CV Batch 23/100 loss 6.534327 loss_att 6.529660 loss_ctc 8.733244 loss_rnnt 6.191442 hw_loss 0.094930 history loss 3.220378 rank 0
2023-02-22 21:30:51,754 DEBUG CV Batch 23/100 loss 6.534327 loss_att 6.529660 loss_ctc 8.733244 loss_rnnt 6.191442 hw_loss 0.094930 history loss 3.220377 rank 2
2023-02-22 21:30:51,807 DEBUG CV Batch 23/100 loss 6.534327 loss_att 6.529660 loss_ctc 8.733244 loss_rnnt 6.191442 hw_loss 0.094930 history loss 3.220377 rank 1
2023-02-22 21:30:51,831 DEBUG CV Batch 23/100 loss 6.534327 loss_att 6.529660 loss_ctc 8.733244 loss_rnnt 6.191442 hw_loss 0.094930 history loss 3.220378 rank 6
2023-02-22 21:30:51,860 DEBUG CV Batch 23/100 loss 6.534327 loss_att 6.529660 loss_ctc 8.733244 loss_rnnt 6.191442 hw_loss 0.094930 history loss 3.220377 rank 3
2023-02-22 21:31:04,984 DEBUG CV Batch 23/200 loss 5.558708 loss_att 12.099717 loss_ctc 6.176025 loss_rnnt 4.168016 hw_loss 0.000340 history loss 3.860155 rank 7
2023-02-22 21:31:05,069 DEBUG CV Batch 23/200 loss 5.558708 loss_att 12.099717 loss_ctc 6.176025 loss_rnnt 4.168016 hw_loss 0.000340 history loss 3.860155 rank 4
2023-02-22 21:31:05,089 DEBUG CV Batch 23/200 loss 5.558708 loss_att 12.099717 loss_ctc 6.176025 loss_rnnt 4.168016 hw_loss 0.000340 history loss 3.860155 rank 0
2023-02-22 21:31:05,094 DEBUG CV Batch 23/200 loss 5.558708 loss_att 12.099717 loss_ctc 6.176025 loss_rnnt 4.168016 hw_loss 0.000340 history loss 3.860155 rank 5
2023-02-22 21:31:05,223 DEBUG CV Batch 23/200 loss 5.558708 loss_att 12.099717 loss_ctc 6.176025 loss_rnnt 4.168016 hw_loss 0.000340 history loss 3.860155 rank 1
2023-02-22 21:31:05,333 DEBUG CV Batch 23/200 loss 5.558708 loss_att 12.099717 loss_ctc 6.176025 loss_rnnt 4.168016 hw_loss 0.000340 history loss 3.860155 rank 6
2023-02-22 21:31:05,348 DEBUG CV Batch 23/200 loss 5.558708 loss_att 12.099717 loss_ctc 6.176025 loss_rnnt 4.168016 hw_loss 0.000340 history loss 3.860155 rank 2
2023-02-22 21:31:05,507 DEBUG CV Batch 23/200 loss 5.558708 loss_att 12.099717 loss_ctc 6.176025 loss_rnnt 4.168016 hw_loss 0.000340 history loss 3.860155 rank 3
2023-02-22 21:31:17,018 DEBUG CV Batch 23/300 loss 5.499834 loss_att 5.517698 loss_ctc 8.198942 loss_rnnt 5.073335 hw_loss 0.118209 history loss 4.085198 rank 7
2023-02-22 21:31:17,071 DEBUG CV Batch 23/300 loss 5.499834 loss_att 5.517698 loss_ctc 8.198942 loss_rnnt 5.073335 hw_loss 0.118209 history loss 4.085198 rank 4
2023-02-22 21:31:17,162 DEBUG CV Batch 23/300 loss 5.499834 loss_att 5.517698 loss_ctc 8.198942 loss_rnnt 5.073335 hw_loss 0.118209 history loss 4.085198 rank 5
2023-02-22 21:31:17,210 DEBUG CV Batch 23/300 loss 5.499834 loss_att 5.517698 loss_ctc 8.198942 loss_rnnt 5.073335 hw_loss 0.118209 history loss 4.085198 rank 0
2023-02-22 21:31:17,380 DEBUG CV Batch 23/300 loss 5.499834 loss_att 5.517698 loss_ctc 8.198942 loss_rnnt 5.073335 hw_loss 0.118209 history loss 4.085198 rank 1
2023-02-22 21:31:17,445 DEBUG CV Batch 23/300 loss 5.499834 loss_att 5.517698 loss_ctc 8.198942 loss_rnnt 5.073335 hw_loss 0.118209 history loss 4.085198 rank 6
2023-02-22 21:31:17,716 DEBUG CV Batch 23/300 loss 5.499834 loss_att 5.517698 loss_ctc 8.198942 loss_rnnt 5.073335 hw_loss 0.118209 history loss 4.085198 rank 3
2023-02-22 21:31:18,114 DEBUG CV Batch 23/300 loss 5.499834 loss_att 5.517698 loss_ctc 8.198942 loss_rnnt 5.073335 hw_loss 0.118209 history loss 4.085198 rank 2
2023-02-22 21:31:29,145 DEBUG CV Batch 23/400 loss 24.298532 loss_att 98.732491 loss_ctc 17.174643 loss_rnnt 10.361048 hw_loss 0.001020 history loss 5.024710 rank 4
2023-02-22 21:31:29,154 DEBUG CV Batch 23/400 loss 24.298532 loss_att 98.732491 loss_ctc 17.174643 loss_rnnt 10.361048 hw_loss 0.001020 history loss 5.024710 rank 7
2023-02-22 21:31:29,265 DEBUG CV Batch 23/400 loss 24.298532 loss_att 98.732491 loss_ctc 17.174643 loss_rnnt 10.361048 hw_loss 0.001020 history loss 5.024710 rank 5
2023-02-22 21:31:29,317 DEBUG CV Batch 23/400 loss 24.298532 loss_att 98.732491 loss_ctc 17.174643 loss_rnnt 10.361048 hw_loss 0.001020 history loss 5.024710 rank 0
2023-02-22 21:31:29,573 DEBUG CV Batch 23/400 loss 24.298532 loss_att 98.732491 loss_ctc 17.174643 loss_rnnt 10.361048 hw_loss 0.001020 history loss 5.024710 rank 1
2023-02-22 21:31:29,804 DEBUG CV Batch 23/400 loss 24.298532 loss_att 98.732491 loss_ctc 17.174643 loss_rnnt 10.361048 hw_loss 0.001020 history loss 5.024710 rank 6
2023-02-22 21:31:30,046 DEBUG CV Batch 23/400 loss 24.298532 loss_att 98.732491 loss_ctc 17.174643 loss_rnnt 10.361048 hw_loss 0.001020 history loss 5.024710 rank 3
2023-02-22 21:31:31,012 DEBUG CV Batch 23/400 loss 24.298532 loss_att 98.732491 loss_ctc 17.174643 loss_rnnt 10.361048 hw_loss 0.001020 history loss 5.024710 rank 2
2023-02-22 21:31:39,645 DEBUG CV Batch 23/500 loss 5.002725 loss_att 5.213560 loss_ctc 5.966385 loss_rnnt 4.766371 hw_loss 0.123185 history loss 5.813109 rank 7
2023-02-22 21:31:39,675 DEBUG CV Batch 23/500 loss 5.002725 loss_att 5.213560 loss_ctc 5.966385 loss_rnnt 4.766371 hw_loss 0.123185 history loss 5.813109 rank 4
2023-02-22 21:31:39,785 DEBUG CV Batch 23/500 loss 5.002725 loss_att 5.213560 loss_ctc 5.966385 loss_rnnt 4.766371 hw_loss 0.123185 history loss 5.813109 rank 0
2023-02-22 21:31:39,834 DEBUG CV Batch 23/500 loss 5.002725 loss_att 5.213560 loss_ctc 5.966385 loss_rnnt 4.766371 hw_loss 0.123185 history loss 5.813109 rank 5
2023-02-22 21:31:40,128 DEBUG CV Batch 23/500 loss 5.002725 loss_att 5.213560 loss_ctc 5.966385 loss_rnnt 4.766371 hw_loss 0.123185 history loss 5.813109 rank 1
2023-02-22 21:31:40,675 DEBUG CV Batch 23/500 loss 5.002725 loss_att 5.213560 loss_ctc 5.966385 loss_rnnt 4.766371 hw_loss 0.123185 history loss 5.813109 rank 6
2023-02-22 21:31:40,773 DEBUG CV Batch 23/500 loss 5.002725 loss_att 5.213560 loss_ctc 5.966385 loss_rnnt 4.766371 hw_loss 0.123185 history loss 5.813109 rank 3
2023-02-22 21:31:41,809 DEBUG CV Batch 23/500 loss 5.002725 loss_att 5.213560 loss_ctc 5.966385 loss_rnnt 4.766371 hw_loss 0.123185 history loss 5.813109 rank 2
2023-02-22 21:31:51,681 DEBUG CV Batch 23/600 loss 7.113123 loss_att 7.283006 loss_ctc 9.885968 loss_rnnt 6.600307 hw_loss 0.204615 history loss 6.754110 rank 7
2023-02-22 21:31:51,755 DEBUG CV Batch 23/600 loss 7.113123 loss_att 7.283006 loss_ctc 9.885968 loss_rnnt 6.600307 hw_loss 0.204615 history loss 6.754110 rank 4
2023-02-22 21:31:51,889 DEBUG CV Batch 23/600 loss 7.113123 loss_att 7.283006 loss_ctc 9.885968 loss_rnnt 6.600307 hw_loss 0.204615 history loss 6.754110 rank 0
2023-02-22 21:31:51,903 DEBUG CV Batch 23/600 loss 7.113123 loss_att 7.283006 loss_ctc 9.885968 loss_rnnt 6.600307 hw_loss 0.204615 history loss 6.754110 rank 5
2023-02-22 21:31:52,456 DEBUG CV Batch 23/600 loss 7.113123 loss_att 7.283006 loss_ctc 9.885968 loss_rnnt 6.600307 hw_loss 0.204615 history loss 6.754110 rank 1
2023-02-22 21:31:52,934 DEBUG CV Batch 23/600 loss 7.113123 loss_att 7.283006 loss_ctc 9.885968 loss_rnnt 6.600307 hw_loss 0.204615 history loss 6.754110 rank 6
2023-02-22 21:31:52,968 DEBUG CV Batch 23/600 loss 7.113123 loss_att 7.283006 loss_ctc 9.885968 loss_rnnt 6.600307 hw_loss 0.204615 history loss 6.754110 rank 3
2023-02-22 21:31:54,142 DEBUG CV Batch 23/600 loss 7.113123 loss_att 7.283006 loss_ctc 9.885968 loss_rnnt 6.600307 hw_loss 0.204615 history loss 6.754110 rank 2
2023-02-22 21:32:03,046 DEBUG CV Batch 23/700 loss 19.430748 loss_att 44.380844 loss_ctc 20.899403 loss_rnnt 14.222373 hw_loss 0.042252 history loss 7.360378 rank 7
2023-02-22 21:32:03,133 DEBUG CV Batch 23/700 loss 19.430748 loss_att 44.380844 loss_ctc 20.899403 loss_rnnt 14.222373 hw_loss 0.042252 history loss 7.360378 rank 4
2023-02-22 21:32:03,285 DEBUG CV Batch 23/700 loss 19.430748 loss_att 44.380844 loss_ctc 20.899403 loss_rnnt 14.222373 hw_loss 0.042252 history loss 7.360378 rank 0
2023-02-22 21:32:03,378 DEBUG CV Batch 23/700 loss 19.430748 loss_att 44.380844 loss_ctc 20.899403 loss_rnnt 14.222373 hw_loss 0.042252 history loss 7.360378 rank 5
2023-02-22 21:32:03,944 DEBUG CV Batch 23/700 loss 19.430748 loss_att 44.380844 loss_ctc 20.899403 loss_rnnt 14.222373 hw_loss 0.042252 history loss 7.360378 rank 1
2023-02-22 21:32:04,577 DEBUG CV Batch 23/700 loss 19.430748 loss_att 44.380844 loss_ctc 20.899403 loss_rnnt 14.222373 hw_loss 0.042252 history loss 7.360378 rank 3
2023-02-22 21:32:05,727 DEBUG CV Batch 23/700 loss 19.430748 loss_att 44.380844 loss_ctc 20.899403 loss_rnnt 14.222373 hw_loss 0.042252 history loss 7.360378 rank 2
2023-02-22 21:32:05,733 DEBUG CV Batch 23/700 loss 19.430748 loss_att 44.380844 loss_ctc 20.899403 loss_rnnt 14.222373 hw_loss 0.042252 history loss 7.360378 rank 6
2023-02-22 21:32:14,246 DEBUG CV Batch 23/800 loss 11.397367 loss_att 10.204622 loss_ctc 15.833258 loss_rnnt 11.002177 hw_loss 0.079288 history loss 6.806495 rank 7
2023-02-22 21:32:14,324 DEBUG CV Batch 23/800 loss 11.397367 loss_att 10.204622 loss_ctc 15.833258 loss_rnnt 11.002177 hw_loss 0.079288 history loss 6.806495 rank 4
2023-02-22 21:32:14,460 DEBUG CV Batch 23/800 loss 11.397367 loss_att 10.204622 loss_ctc 15.833258 loss_rnnt 11.002177 hw_loss 0.079288 history loss 6.806495 rank 0
2023-02-22 21:32:14,600 DEBUG CV Batch 23/800 loss 11.397367 loss_att 10.204622 loss_ctc 15.833258 loss_rnnt 11.002177 hw_loss 0.079288 history loss 6.806495 rank 5
2023-02-22 21:32:15,149 DEBUG CV Batch 23/800 loss 11.397367 loss_att 10.204622 loss_ctc 15.833258 loss_rnnt 11.002177 hw_loss 0.079288 history loss 6.806495 rank 1
2023-02-22 21:32:16,037 DEBUG CV Batch 23/800 loss 11.397367 loss_att 10.204622 loss_ctc 15.833258 loss_rnnt 11.002177 hw_loss 0.079288 history loss 6.806495 rank 3
2023-02-22 21:32:17,028 DEBUG CV Batch 23/800 loss 11.397367 loss_att 10.204622 loss_ctc 15.833258 loss_rnnt 11.002177 hw_loss 0.079288 history loss 6.806495 rank 2
2023-02-22 21:32:18,253 DEBUG CV Batch 23/800 loss 11.397367 loss_att 10.204622 loss_ctc 15.833258 loss_rnnt 11.002177 hw_loss 0.079288 history loss 6.806495 rank 6
2023-02-22 21:32:27,410 DEBUG CV Batch 23/900 loss 11.400030 loss_att 14.246973 loss_ctc 22.342518 loss_rnnt 9.356475 hw_loss 0.028441 history loss 6.607609 rank 7
2023-02-22 21:32:27,649 DEBUG CV Batch 23/900 loss 11.400030 loss_att 14.246973 loss_ctc 22.342518 loss_rnnt 9.356475 hw_loss 0.028441 history loss 6.607609 rank 4
2023-02-22 21:32:27,690 DEBUG CV Batch 23/900 loss 11.400030 loss_att 14.246973 loss_ctc 22.342518 loss_rnnt 9.356475 hw_loss 0.028441 history loss 6.607609 rank 0
2023-02-22 21:32:27,823 DEBUG CV Batch 23/900 loss 11.400030 loss_att 14.246973 loss_ctc 22.342518 loss_rnnt 9.356475 hw_loss 0.028441 history loss 6.607609 rank 5
2023-02-22 21:32:28,516 DEBUG CV Batch 23/900 loss 11.400030 loss_att 14.246973 loss_ctc 22.342518 loss_rnnt 9.356475 hw_loss 0.028441 history loss 6.607609 rank 1
2023-02-22 21:32:29,455 DEBUG CV Batch 23/900 loss 11.400030 loss_att 14.246973 loss_ctc 22.342518 loss_rnnt 9.356475 hw_loss 0.028441 history loss 6.607609 rank 3
2023-02-22 21:32:30,701 DEBUG CV Batch 23/900 loss 11.400030 loss_att 14.246973 loss_ctc 22.342518 loss_rnnt 9.356475 hw_loss 0.028441 history loss 6.607609 rank 2
2023-02-22 21:32:31,750 DEBUG CV Batch 23/900 loss 11.400030 loss_att 14.246973 loss_ctc 22.342518 loss_rnnt 9.356475 hw_loss 0.028441 history loss 6.607609 rank 6
2023-02-22 21:32:39,544 DEBUG CV Batch 23/1000 loss 4.612441 loss_att 4.592342 loss_ctc 4.913299 loss_rnnt 4.526738 hw_loss 0.093016 history loss 6.393805 rank 7
2023-02-22 21:32:39,741 DEBUG CV Batch 23/1000 loss 4.612441 loss_att 4.592342 loss_ctc 4.913299 loss_rnnt 4.526738 hw_loss 0.093016 history loss 6.393805 rank 0
2023-02-22 21:32:39,792 DEBUG CV Batch 23/1000 loss 4.612441 loss_att 4.592342 loss_ctc 4.913299 loss_rnnt 4.526738 hw_loss 0.093016 history loss 6.393805 rank 4
2023-02-22 21:32:39,978 DEBUG CV Batch 23/1000 loss 4.612441 loss_att 4.592342 loss_ctc 4.913299 loss_rnnt 4.526738 hw_loss 0.093016 history loss 6.393805 rank 5
2023-02-22 21:32:40,849 DEBUG CV Batch 23/1000 loss 4.612441 loss_att 4.592342 loss_ctc 4.913299 loss_rnnt 4.526738 hw_loss 0.093016 history loss 6.393805 rank 1
2023-02-22 21:32:42,648 DEBUG CV Batch 23/1000 loss 4.612441 loss_att 4.592342 loss_ctc 4.913299 loss_rnnt 4.526738 hw_loss 0.093016 history loss 6.393805 rank 3
2023-02-22 21:32:43,053 DEBUG CV Batch 23/1000 loss 4.612441 loss_att 4.592342 loss_ctc 4.913299 loss_rnnt 4.526738 hw_loss 0.093016 history loss 6.393805 rank 2
2023-02-22 21:32:44,143 DEBUG CV Batch 23/1000 loss 4.612441 loss_att 4.592342 loss_ctc 4.913299 loss_rnnt 4.526738 hw_loss 0.093016 history loss 6.393805 rank 6
2023-02-22 21:32:51,420 DEBUG CV Batch 23/1100 loss 5.939360 loss_att 5.720566 loss_ctc 8.124244 loss_rnnt 5.574397 hw_loss 0.220133 history loss 6.377300 rank 7
2023-02-22 21:32:51,599 DEBUG CV Batch 23/1100 loss 5.939360 loss_att 5.720566 loss_ctc 8.124244 loss_rnnt 5.574397 hw_loss 0.220133 history loss 6.377300 rank 0
2023-02-22 21:32:51,732 DEBUG CV Batch 23/1100 loss 5.939360 loss_att 5.720566 loss_ctc 8.124244 loss_rnnt 5.574397 hw_loss 0.220133 history loss 6.377300 rank 4
2023-02-22 21:32:51,952 DEBUG CV Batch 23/1100 loss 5.939360 loss_att 5.720566 loss_ctc 8.124244 loss_rnnt 5.574397 hw_loss 0.220133 history loss 6.377300 rank 5
2023-02-22 21:32:52,743 DEBUG CV Batch 23/1100 loss 5.939360 loss_att 5.720566 loss_ctc 8.124244 loss_rnnt 5.574397 hw_loss 0.220133 history loss 6.377300 rank 1
2023-02-22 21:32:54,712 DEBUG CV Batch 23/1100 loss 5.939360 loss_att 5.720566 loss_ctc 8.124244 loss_rnnt 5.574397 hw_loss 0.220133 history loss 6.377300 rank 3
2023-02-22 21:32:55,057 DEBUG CV Batch 23/1100 loss 5.939360 loss_att 5.720566 loss_ctc 8.124244 loss_rnnt 5.574397 hw_loss 0.220133 history loss 6.377300 rank 2
2023-02-22 21:32:56,152 DEBUG CV Batch 23/1100 loss 5.939360 loss_att 5.720566 loss_ctc 8.124244 loss_rnnt 5.574397 hw_loss 0.220133 history loss 6.377300 rank 6
2023-02-22 21:33:02,012 DEBUG CV Batch 23/1200 loss 9.596800 loss_att 8.321899 loss_ctc 10.783459 loss_rnnt 9.621037 hw_loss 0.135976 history loss 6.714041 rank 7
2023-02-22 21:33:02,121 DEBUG CV Batch 23/1200 loss 9.596800 loss_att 8.321899 loss_ctc 10.783459 loss_rnnt 9.621037 hw_loss 0.135976 history loss 6.714041 rank 0
2023-02-22 21:33:02,281 DEBUG CV Batch 23/1200 loss 9.596800 loss_att 8.321899 loss_ctc 10.783459 loss_rnnt 9.621037 hw_loss 0.135976 history loss 6.714041 rank 4
2023-02-22 21:33:02,513 DEBUG CV Batch 23/1200 loss 9.596800 loss_att 8.321899 loss_ctc 10.783459 loss_rnnt 9.621037 hw_loss 0.135976 history loss 6.714041 rank 5
2023-02-22 21:33:03,523 DEBUG CV Batch 23/1200 loss 9.596800 loss_att 8.321899 loss_ctc 10.783459 loss_rnnt 9.621037 hw_loss 0.135976 history loss 6.714041 rank 1
2023-02-22 21:33:05,451 DEBUG CV Batch 23/1200 loss 9.596800 loss_att 8.321899 loss_ctc 10.783459 loss_rnnt 9.621037 hw_loss 0.135976 history loss 6.714041 rank 3
2023-02-22 21:33:06,547 DEBUG CV Batch 23/1200 loss 9.596800 loss_att 8.321899 loss_ctc 10.783459 loss_rnnt 9.621037 hw_loss 0.135976 history loss 6.714041 rank 2
2023-02-22 21:33:06,914 DEBUG CV Batch 23/1200 loss 9.596800 loss_att 8.321899 loss_ctc 10.783459 loss_rnnt 9.621037 hw_loss 0.135976 history loss 6.714041 rank 6
2023-02-22 21:33:14,001 DEBUG CV Batch 23/1300 loss 5.932897 loss_att 5.814539 loss_ctc 7.948804 loss_rnnt 5.631250 hw_loss 0.105995 history loss 7.028512 rank 7
2023-02-22 21:33:14,077 DEBUG CV Batch 23/1300 loss 5.932897 loss_att 5.814539 loss_ctc 7.948804 loss_rnnt 5.631250 hw_loss 0.105995 history loss 7.028512 rank 0
2023-02-22 21:33:14,258 DEBUG CV Batch 23/1300 loss 5.932897 loss_att 5.814539 loss_ctc 7.948804 loss_rnnt 5.631250 hw_loss 0.105995 history loss 7.028512 rank 4
2023-02-22 21:33:14,458 DEBUG CV Batch 23/1300 loss 5.932897 loss_att 5.814539 loss_ctc 7.948804 loss_rnnt 5.631250 hw_loss 0.105995 history loss 7.028512 rank 5
2023-02-22 21:33:15,491 DEBUG CV Batch 23/1300 loss 5.932897 loss_att 5.814539 loss_ctc 7.948804 loss_rnnt 5.631250 hw_loss 0.105995 history loss 7.028512 rank 1
2023-02-22 21:33:17,547 DEBUG CV Batch 23/1300 loss 5.932897 loss_att 5.814539 loss_ctc 7.948804 loss_rnnt 5.631250 hw_loss 0.105995 history loss 7.028512 rank 3
2023-02-22 21:33:18,639 DEBUG CV Batch 23/1300 loss 5.932897 loss_att 5.814539 loss_ctc 7.948804 loss_rnnt 5.631250 hw_loss 0.105995 history loss 7.028512 rank 2
2023-02-22 21:33:19,115 DEBUG CV Batch 23/1300 loss 5.932897 loss_att 5.814539 loss_ctc 7.948804 loss_rnnt 5.631250 hw_loss 0.105995 history loss 7.028512 rank 6
2023-02-22 21:33:25,210 DEBUG CV Batch 23/1400 loss 7.469379 loss_att 22.733011 loss_ctc 4.117762 loss_rnnt 4.820385 hw_loss 0.080906 history loss 7.325895 rank 7
2023-02-22 21:33:25,315 DEBUG CV Batch 23/1400 loss 7.469379 loss_att 22.733011 loss_ctc 4.117762 loss_rnnt 4.820385 hw_loss 0.080906 history loss 7.325895 rank 0
2023-02-22 21:33:25,423 DEBUG CV Batch 23/1400 loss 7.469379 loss_att 22.733011 loss_ctc 4.117762 loss_rnnt 4.820385 hw_loss 0.080906 history loss 7.325895 rank 4
2023-02-22 21:33:25,679 DEBUG CV Batch 23/1400 loss 7.469379 loss_att 22.733011 loss_ctc 4.117762 loss_rnnt 4.820385 hw_loss 0.080906 history loss 7.325895 rank 5
2023-02-22 21:33:27,476 DEBUG CV Batch 23/1400 loss 7.469379 loss_att 22.733011 loss_ctc 4.117762 loss_rnnt 4.820385 hw_loss 0.080906 history loss 7.325895 rank 1
2023-02-22 21:33:28,856 DEBUG CV Batch 23/1400 loss 7.469379 loss_att 22.733011 loss_ctc 4.117762 loss_rnnt 4.820385 hw_loss 0.080906 history loss 7.325895 rank 3
2023-02-22 21:33:29,970 DEBUG CV Batch 23/1400 loss 7.469379 loss_att 22.733011 loss_ctc 4.117762 loss_rnnt 4.820385 hw_loss 0.080906 history loss 7.325895 rank 2
2023-02-22 21:33:30,460 DEBUG CV Batch 23/1400 loss 7.469379 loss_att 22.733011 loss_ctc 4.117762 loss_rnnt 4.820385 hw_loss 0.080906 history loss 7.325895 rank 6
2023-02-22 21:33:36,643 DEBUG CV Batch 23/1500 loss 7.169060 loss_att 7.191135 loss_ctc 7.923044 loss_rnnt 7.023559 hw_loss 0.076041 history loss 7.152179 rank 7
2023-02-22 21:33:36,769 DEBUG CV Batch 23/1500 loss 7.169060 loss_att 7.191135 loss_ctc 7.923044 loss_rnnt 7.023559 hw_loss 0.076041 history loss 7.152179 rank 0
2023-02-22 21:33:36,811 DEBUG CV Batch 23/1500 loss 7.169060 loss_att 7.191135 loss_ctc 7.923044 loss_rnnt 7.023559 hw_loss 0.076041 history loss 7.152179 rank 4
2023-02-22 21:33:37,106 DEBUG CV Batch 23/1500 loss 7.169060 loss_att 7.191135 loss_ctc 7.923044 loss_rnnt 7.023559 hw_loss 0.076041 history loss 7.152179 rank 5
2023-02-22 21:33:40,284 DEBUG CV Batch 23/1500 loss 7.169060 loss_att 7.191135 loss_ctc 7.923044 loss_rnnt 7.023559 hw_loss 0.076041 history loss 7.152179 rank 1
2023-02-22 21:33:40,631 DEBUG CV Batch 23/1500 loss 7.169060 loss_att 7.191135 loss_ctc 7.923044 loss_rnnt 7.023559 hw_loss 0.076041 history loss 7.152179 rank 3
2023-02-22 21:33:41,505 DEBUG CV Batch 23/1500 loss 7.169060 loss_att 7.191135 loss_ctc 7.923044 loss_rnnt 7.023559 hw_loss 0.076041 history loss 7.152179 rank 2
2023-02-22 21:33:41,988 DEBUG CV Batch 23/1500 loss 7.169060 loss_att 7.191135 loss_ctc 7.923044 loss_rnnt 7.023559 hw_loss 0.076041 history loss 7.152179 rank 6
2023-02-22 21:33:49,579 DEBUG CV Batch 23/1600 loss 7.141543 loss_att 10.624029 loss_ctc 10.445292 loss_rnnt 5.954768 hw_loss 0.093333 history loss 7.083832 rank 7
2023-02-22 21:33:49,719 DEBUG CV Batch 23/1600 loss 7.141543 loss_att 10.624029 loss_ctc 10.445292 loss_rnnt 5.954768 hw_loss 0.093333 history loss 7.083832 rank 0
2023-02-22 21:33:49,754 DEBUG CV Batch 23/1600 loss 7.141543 loss_att 10.624029 loss_ctc 10.445292 loss_rnnt 5.954768 hw_loss 0.093333 history loss 7.083832 rank 4
2023-02-22 21:33:50,040 DEBUG CV Batch 23/1600 loss 7.141543 loss_att 10.624029 loss_ctc 10.445292 loss_rnnt 5.954768 hw_loss 0.093333 history loss 7.083832 rank 5
2023-02-22 21:33:53,324 DEBUG CV Batch 23/1600 loss 7.141543 loss_att 10.624029 loss_ctc 10.445292 loss_rnnt 5.954768 hw_loss 0.093333 history loss 7.083832 rank 1
2023-02-22 21:33:53,751 DEBUG CV Batch 23/1600 loss 7.141543 loss_att 10.624029 loss_ctc 10.445292 loss_rnnt 5.954768 hw_loss 0.093333 history loss 7.083832 rank 3
2023-02-22 21:33:54,540 DEBUG CV Batch 23/1600 loss 7.141543 loss_att 10.624029 loss_ctc 10.445292 loss_rnnt 5.954768 hw_loss 0.093333 history loss 7.083832 rank 2
2023-02-22 21:33:55,206 DEBUG CV Batch 23/1600 loss 7.141543 loss_att 10.624029 loss_ctc 10.445292 loss_rnnt 5.954768 hw_loss 0.093333 history loss 7.083832 rank 6
2023-02-22 21:34:01,777 DEBUG CV Batch 23/1700 loss 11.505154 loss_att 9.397462 loss_ctc 16.108727 loss_rnnt 11.271755 hw_loss 0.077113 history loss 7.005654 rank 7
2023-02-22 21:34:01,957 DEBUG CV Batch 23/1700 loss 11.505154 loss_att 9.397462 loss_ctc 16.108727 loss_rnnt 11.271755 hw_loss 0.077113 history loss 7.005654 rank 0
2023-02-22 21:34:02,050 DEBUG CV Batch 23/1700 loss 11.505154 loss_att 9.397462 loss_ctc 16.108727 loss_rnnt 11.271755 hw_loss 0.077113 history loss 7.005654 rank 4
2023-02-22 21:34:02,315 DEBUG CV Batch 23/1700 loss 11.505154 loss_att 9.397462 loss_ctc 16.108727 loss_rnnt 11.271755 hw_loss 0.077113 history loss 7.005654 rank 5
2023-02-22 21:34:05,675 DEBUG CV Batch 23/1700 loss 11.505154 loss_att 9.397462 loss_ctc 16.108727 loss_rnnt 11.271755 hw_loss 0.077113 history loss 7.005654 rank 1
2023-02-22 21:34:06,040 DEBUG CV Batch 23/1700 loss 11.505154 loss_att 9.397462 loss_ctc 16.108727 loss_rnnt 11.271755 hw_loss 0.077113 history loss 7.005654 rank 3
2023-02-22 21:34:06,912 DEBUG CV Batch 23/1700 loss 11.505154 loss_att 9.397462 loss_ctc 16.108727 loss_rnnt 11.271755 hw_loss 0.077113 history loss 7.005654 rank 2
2023-02-22 21:34:07,411 DEBUG CV Batch 23/1700 loss 11.505154 loss_att 9.397462 loss_ctc 16.108727 loss_rnnt 11.271755 hw_loss 0.077113 history loss 7.005654 rank 6
2023-02-22 21:34:10,756 INFO Epoch 23 CV info cv_loss 6.972591503957117
2023-02-22 21:34:10,757 INFO Epoch 24 TRAIN info lr 0.00035339086816548257
2023-02-22 21:34:10,760 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 21:34:10,966 INFO Epoch 23 CV info cv_loss 6.972591505290232
2023-02-22 21:34:10,967 INFO Checkpoint: save to checkpoint exp/2_21_rnnt_bias_loss_2_class_1word_finetune/23.pt
2023-02-22 21:34:11,007 INFO Epoch 23 CV info cv_loss 6.972591504891805
2023-02-22 21:34:11,007 INFO Epoch 24 TRAIN info lr 0.00035342706299527617
2023-02-22 21:34:11,010 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 21:34:11,379 INFO Epoch 23 CV info cv_loss 6.972591503892508
2023-02-22 21:34:11,380 INFO Epoch 24 TRAIN info lr 0.00035341646823540147
2023-02-22 21:34:11,384 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 21:34:11,955 INFO Epoch 24 TRAIN info lr 0.0003534279459349428
2023-02-22 21:34:11,959 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 21:34:14,709 INFO Epoch 23 CV info cv_loss 6.972591503535001
2023-02-22 21:34:14,710 INFO Epoch 24 TRAIN info lr 0.00035345620349870024
2023-02-22 21:34:14,713 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 21:34:15,126 INFO Epoch 23 CV info cv_loss 6.972591504827196
2023-02-22 21:34:15,127 INFO Epoch 24 TRAIN info lr 0.0003533996951473765
2023-02-22 21:34:15,130 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 21:34:16,516 INFO Epoch 23 CV info cv_loss 6.972591505660661
2023-02-22 21:34:16,517 INFO Epoch 24 TRAIN info lr 0.00035345620349870024
2023-02-22 21:34:16,520 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 21:34:16,987 INFO Epoch 23 CV info cv_loss 6.972591505787727
2023-02-22 21:34:16,988 INFO Epoch 24 TRAIN info lr 0.0003533723336562322
2023-02-22 21:34:16,992 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-22 21:35:30,454 DEBUG TRAIN Batch 24/0 loss 8.512318 loss_att 8.036493 loss_ctc 10.979348 loss_rnnt 8.170484 hw_loss 0.202614 lr 0.00035343 rank 4
2023-02-22 21:35:30,459 DEBUG TRAIN Batch 24/0 loss 9.463552 loss_att 9.060591 loss_ctc 12.134723 loss_rnnt 9.081453 hw_loss 0.199751 lr 0.00035343 rank 0
2023-02-22 21:35:30,462 DEBUG TRAIN Batch 24/0 loss 8.193557 loss_att 8.395294 loss_ctc 11.719666 loss_rnnt 7.587957 hw_loss 0.178320 lr 0.00035339 rank 7
2023-02-22 21:35:30,469 DEBUG TRAIN Batch 24/0 loss 7.585752 loss_att 8.001040 loss_ctc 10.666708 loss_rnnt 7.006053 hw_loss 0.160966 lr 0.00035340 rank 3
2023-02-22 21:35:30,485 DEBUG TRAIN Batch 24/0 loss 8.881802 loss_att 8.695309 loss_ctc 11.806246 loss_rnnt 8.440107 hw_loss 0.167000 lr 0.00035346 rank 1
2023-02-22 21:35:30,485 DEBUG TRAIN Batch 24/0 loss 12.779791 loss_att 12.008857 loss_ctc 15.496594 loss_rnnt 12.500740 hw_loss 0.133119 lr 0.00035342 rank 5
2023-02-22 21:35:30,510 DEBUG TRAIN Batch 24/0 loss 4.788630 loss_att 4.836944 loss_ctc 6.998704 loss_rnnt 4.343781 hw_loss 0.263454 lr 0.00035346 rank 6
2023-02-22 21:35:30,550 DEBUG TRAIN Batch 24/0 loss 10.312709 loss_att 10.793798 loss_ctc 12.958053 loss_rnnt 9.761003 hw_loss 0.192703 lr 0.00035337 rank 2
2023-02-22 21:36:45,409 DEBUG TRAIN Batch 24/100 loss 16.012180 loss_att 18.753061 loss_ctc 22.115316 loss_rnnt 14.590683 hw_loss 0.111693 lr 0.00035337 rank 1
2023-02-22 21:36:45,412 DEBUG TRAIN Batch 24/100 loss 2.474648 loss_att 6.087557 loss_ctc 4.983007 loss_rnnt 1.388160 hw_loss 0.055232 lr 0.00035334 rank 0
2023-02-22 21:36:45,413 DEBUG TRAIN Batch 24/100 loss 3.597867 loss_att 7.649906 loss_ctc 5.317009 loss_rnnt 2.523174 hw_loss 0.065749 lr 0.00035330 rank 7
2023-02-22 21:36:45,413 DEBUG TRAIN Batch 24/100 loss 9.642395 loss_att 13.062553 loss_ctc 15.064274 loss_rnnt 8.226637 hw_loss 0.016517 lr 0.00035333 rank 5
2023-02-22 21:36:45,414 DEBUG TRAIN Batch 24/100 loss 5.705918 loss_att 11.024931 loss_ctc 8.693771 loss_rnnt 4.222995 hw_loss 0.038889 lr 0.00035334 rank 4
2023-02-22 21:36:45,415 DEBUG TRAIN Batch 24/100 loss 4.643559 loss_att 7.991453 loss_ctc 8.473930 loss_rnnt 3.445033 hw_loss 0.034185 lr 0.00035328 rank 2
2023-02-22 21:36:45,416 DEBUG TRAIN Batch 24/100 loss 6.399164 loss_att 11.341341 loss_ctc 10.920081 loss_rnnt 4.790401 hw_loss 0.032884 lr 0.00035337 rank 6
2023-02-22 21:36:45,418 DEBUG TRAIN Batch 24/100 loss 7.467069 loss_att 13.219197 loss_ctc 11.791380 loss_rnnt 5.669976 hw_loss 0.131422 lr 0.00035331 rank 3
2023-02-22 21:38:00,203 DEBUG TRAIN Batch 24/200 loss 10.663277 loss_att 13.363301 loss_ctc 12.526787 loss_rnnt 9.818687 hw_loss 0.105217 lr 0.00035325 rank 4
2023-02-22 21:38:00,207 DEBUG TRAIN Batch 24/200 loss 2.050319 loss_att 4.333678 loss_ctc 6.183372 loss_rnnt 1.021681 hw_loss 0.039174 lr 0.00035321 rank 7
2023-02-22 21:38:00,208 DEBUG TRAIN Batch 24/200 loss 3.476062 loss_att 8.012392 loss_ctc 3.456364 loss_rnnt 2.459162 hw_loss 0.210488 lr 0.00035325 rank 0
2023-02-22 21:38:00,212 DEBUG TRAIN Batch 24/200 loss 2.160530 loss_att 6.013081 loss_ctc 4.391428 loss_rnnt 1.059504 hw_loss 0.061994 lr 0.00035324 rank 5
2023-02-22 21:38:00,213 DEBUG TRAIN Batch 24/200 loss 4.607968 loss_att 7.103076 loss_ctc 7.912244 loss_rnnt 3.587860 hw_loss 0.150969 lr 0.00035328 rank 6
2023-02-22 21:38:00,214 DEBUG TRAIN Batch 24/200 loss 9.267366 loss_att 10.732580 loss_ctc 13.167614 loss_rnnt 8.424990 hw_loss 0.054939 lr 0.00035320 rank 2
2023-02-22 21:38:00,217 DEBUG TRAIN Batch 24/200 loss 8.137670 loss_att 9.909370 loss_ctc 11.003032 loss_rnnt 7.369026 hw_loss 0.060479 lr 0.00035322 rank 3
2023-02-22 21:38:00,258 DEBUG TRAIN Batch 24/200 loss 6.169523 loss_att 9.630889 loss_ctc 11.742722 loss_rnnt 4.694994 hw_loss 0.073430 lr 0.00035328 rank 1
2023-02-22 21:39:17,331 DEBUG TRAIN Batch 24/300 loss 10.425694 loss_att 13.502981 loss_ctc 16.203928 loss_rnnt 9.016064 hw_loss 0.044515 lr 0.00035313 rank 7
2023-02-22 21:39:17,335 DEBUG TRAIN Batch 24/300 loss 11.306279 loss_att 12.033849 loss_ctc 18.241692 loss_rnnt 10.205171 hw_loss 0.057886 lr 0.00035316 rank 4
2023-02-22 21:39:17,335 DEBUG TRAIN Batch 24/300 loss 14.731181 loss_att 16.342339 loss_ctc 19.891758 loss_rnnt 13.678705 hw_loss 0.079061 lr 0.00035315 rank 5
2023-02-22 21:39:17,338 DEBUG TRAIN Batch 24/300 loss 12.477998 loss_att 13.796882 loss_ctc 16.444052 loss_rnnt 11.657795 hw_loss 0.051786 lr 0.00035316 rank 0
2023-02-22 21:39:17,340 DEBUG TRAIN Batch 24/300 loss 15.377398 loss_att 19.672285 loss_ctc 22.170475 loss_rnnt 13.587951 hw_loss 0.046360 lr 0.00035311 rank 2
2023-02-22 21:39:17,340 DEBUG TRAIN Batch 24/300 loss 18.773401 loss_att 21.142006 loss_ctc 26.435434 loss_rnnt 17.213329 hw_loss 0.121400 lr 0.00035319 rank 6
2023-02-22 21:39:17,343 DEBUG TRAIN Batch 24/300 loss 6.913304 loss_att 9.825029 loss_ctc 13.557554 loss_rnnt 5.385273 hw_loss 0.112100 lr 0.00035313 rank 3
2023-02-22 21:39:17,383 DEBUG TRAIN Batch 24/300 loss 10.340801 loss_att 11.786552 loss_ctc 11.833308 loss_rnnt 9.818892 hw_loss 0.063294 lr 0.00035319 rank 1
2023-02-22 21:40:33,890 DEBUG TRAIN Batch 24/400 loss 10.492007 loss_att 12.455622 loss_ctc 13.806421 loss_rnnt 9.631443 hw_loss 0.048599 lr 0.00035304 rank 7
2023-02-22 21:40:33,893 DEBUG TRAIN Batch 24/400 loss 2.124068 loss_att 4.393166 loss_ctc 4.841926 loss_rnnt 1.292729 hw_loss 0.028383 lr 0.00035306 rank 5
2023-02-22 21:40:33,895 DEBUG TRAIN Batch 24/400 loss 4.006314 loss_att 9.169601 loss_ctc 7.610865 loss_rnnt 2.481759 hw_loss 0.021172 lr 0.00035305 rank 3
2023-02-22 21:40:33,896 DEBUG TRAIN Batch 24/400 loss 11.007675 loss_att 12.992020 loss_ctc 17.017324 loss_rnnt 9.776971 hw_loss 0.061027 lr 0.00035307 rank 0
2023-02-22 21:40:33,898 DEBUG TRAIN Batch 24/400 loss 8.668803 loss_att 10.169981 loss_ctc 16.513515 loss_rnnt 7.297507 hw_loss 0.047061 lr 0.00035302 rank 2
2023-02-22 21:40:33,899 DEBUG TRAIN Batch 24/400 loss 8.468945 loss_att 11.163316 loss_ctc 9.941116 loss_rnnt 7.713100 hw_loss 0.038776 lr 0.00035307 rank 4
2023-02-22 21:40:33,901 DEBUG TRAIN Batch 24/400 loss 4.335092 loss_att 7.372138 loss_ctc 7.178415 loss_rnnt 3.297107 hw_loss 0.096499 lr 0.00035310 rank 6
2023-02-22 21:40:33,902 DEBUG TRAIN Batch 24/400 loss 12.497716 loss_att 12.785372 loss_ctc 19.358749 loss_rnnt 11.502658 hw_loss 0.042606 lr 0.00035310 rank 1
2023-02-22 21:41:49,640 DEBUG TRAIN Batch 24/500 loss 7.931339 loss_att 10.488663 loss_ctc 12.226109 loss_rnnt 6.742468 hw_loss 0.196444 lr 0.00035299 rank 0
2023-02-22 21:41:49,646 DEBUG TRAIN Batch 24/500 loss 8.425801 loss_att 11.013082 loss_ctc 10.410278 loss_rnnt 7.602598 hw_loss 0.077156 lr 0.00035299 rank 4
2023-02-22 21:41:49,646 DEBUG TRAIN Batch 24/500 loss 9.118649 loss_att 10.318953 loss_ctc 11.774504 loss_rnnt 8.481941 hw_loss 0.079750 lr 0.00035295 rank 7
2023-02-22 21:41:49,648 DEBUG TRAIN Batch 24/500 loss 12.002906 loss_att 14.188238 loss_ctc 16.248779 loss_rnnt 10.915440 hw_loss 0.158032 lr 0.00035297 rank 5
2023-02-22 21:41:49,649 DEBUG TRAIN Batch 24/500 loss 13.113896 loss_att 13.819491 loss_ctc 18.570507 loss_rnnt 12.189438 hw_loss 0.104608 lr 0.00035301 rank 6
2023-02-22 21:41:49,650 DEBUG TRAIN Batch 24/500 loss 13.355030 loss_att 16.830166 loss_ctc 21.069874 loss_rnnt 11.588032 hw_loss 0.081233 lr 0.00035301 rank 1
2023-02-22 21:41:49,652 DEBUG TRAIN Batch 24/500 loss 12.821818 loss_att 14.054180 loss_ctc 16.544283 loss_rnnt 12.044280 hw_loss 0.065132 lr 0.00035293 rank 2
2023-02-22 21:41:49,694 DEBUG TRAIN Batch 24/500 loss 7.653881 loss_att 11.917162 loss_ctc 12.769176 loss_rnnt 6.071347 hw_loss 0.089695 lr 0.00035296 rank 3
2023-02-22 21:43:05,875 DEBUG TRAIN Batch 24/600 loss 9.115767 loss_att 9.105818 loss_ctc 11.050949 loss_rnnt 8.795073 hw_loss 0.121238 lr 0.00035286 rank 7
2023-02-22 21:43:05,875 DEBUG TRAIN Batch 24/600 loss 9.709936 loss_att 11.775720 loss_ctc 13.214550 loss_rnnt 8.797553 hw_loss 0.059895 lr 0.00035289 rank 5
2023-02-22 21:43:05,878 DEBUG TRAIN Batch 24/600 loss 11.032985 loss_att 11.951407 loss_ctc 13.920628 loss_rnnt 10.438212 hw_loss 0.048879 lr 0.00035290 rank 0
2023-02-22 21:43:05,877 DEBUG TRAIN Batch 24/600 loss 12.203443 loss_att 15.079391 loss_ctc 18.707752 loss_rnnt 10.693728 hw_loss 0.126156 lr 0.00035290 rank 4
2023-02-22 21:43:05,880 DEBUG TRAIN Batch 24/600 loss 3.821965 loss_att 5.196730 loss_ctc 5.125289 loss_rnnt 3.294744 hw_loss 0.147172 lr 0.00035293 rank 1
2023-02-22 21:43:05,882 DEBUG TRAIN Batch 24/600 loss 6.731426 loss_att 6.991625 loss_ctc 10.001356 loss_rnnt 6.138938 hw_loss 0.195857 lr 0.00035293 rank 6
2023-02-22 21:43:05,882 DEBUG TRAIN Batch 24/600 loss 9.346671 loss_att 10.117716 loss_ctc 13.467959 loss_rnnt 8.585320 hw_loss 0.108067 lr 0.00035287 rank 3
2023-02-22 21:43:05,887 DEBUG TRAIN Batch 24/600 loss 6.080402 loss_att 7.147160 loss_ctc 8.292676 loss_rnnt 5.540976 hw_loss 0.058323 lr 0.00035284 rank 2
2023-02-22 21:44:24,186 DEBUG TRAIN Batch 24/700 loss 7.334556 loss_att 7.374063 loss_ctc 9.694207 loss_rnnt 6.889299 hw_loss 0.230127 lr 0.00035281 rank 4
2023-02-22 21:44:24,188 DEBUG TRAIN Batch 24/700 loss 8.711590 loss_att 13.173009 loss_ctc 12.066959 loss_rnnt 7.343907 hw_loss 0.052527 lr 0.00035277 rank 7
2023-02-22 21:44:24,189 DEBUG TRAIN Batch 24/700 loss 6.322597 loss_att 9.906296 loss_ctc 11.081077 loss_rnnt 4.913173 hw_loss 0.109164 lr 0.00035280 rank 5
2023-02-22 21:44:24,194 DEBUG TRAIN Batch 24/700 loss 4.388597 loss_att 6.597114 loss_ctc 6.681131 loss_rnnt 3.593916 hw_loss 0.088700 lr 0.00035276 rank 2
2023-02-22 21:44:24,196 DEBUG TRAIN Batch 24/700 loss 3.500863 loss_att 5.773108 loss_ctc 3.828157 loss_rnnt 2.969657 hw_loss 0.062096 lr 0.00035284 rank 1
2023-02-22 21:44:24,217 DEBUG TRAIN Batch 24/700 loss 4.493570 loss_att 8.168390 loss_ctc 5.494664 loss_rnnt 3.625049 hw_loss 0.000145 lr 0.00035284 rank 6
2023-02-22 21:44:24,241 DEBUG TRAIN Batch 24/700 loss 8.492221 loss_att 9.679451 loss_ctc 8.204308 loss_rnnt 8.235790 hw_loss 0.107574 lr 0.00035281 rank 0
2023-02-22 21:44:24,260 DEBUG TRAIN Batch 24/700 loss 3.409879 loss_att 6.693164 loss_ctc 4.987052 loss_rnnt 2.488928 hw_loss 0.101259 lr 0.00035278 rank 3
2023-02-22 21:45:39,264 DEBUG TRAIN Batch 24/800 loss 1.374393 loss_att 5.163338 loss_ctc 1.606094 loss_rnnt 0.576802 hw_loss 0.016703 lr 0.00035272 rank 4
2023-02-22 21:45:39,267 DEBUG TRAIN Batch 24/800 loss 5.819245 loss_att 7.731024 loss_ctc 7.554725 loss_rnnt 5.169936 hw_loss 0.066667 lr 0.00035269 rank 7
2023-02-22 21:45:39,270 DEBUG TRAIN Batch 24/800 loss 11.538115 loss_att 13.372925 loss_ctc 14.356020 loss_rnnt 10.750376 hw_loss 0.084480 lr 0.00035271 rank 5
2023-02-22 21:45:39,271 DEBUG TRAIN Batch 24/800 loss 3.939091 loss_att 7.296353 loss_ctc 7.622245 loss_rnnt 2.776303 hw_loss 0.000466 lr 0.00035272 rank 0
2023-02-22 21:45:39,274 DEBUG TRAIN Batch 24/800 loss 3.715431 loss_att 6.147401 loss_ctc 8.875452 loss_rnnt 2.463082 hw_loss 0.146159 lr 0.00035269 rank 3
2023-02-22 21:45:39,276 DEBUG TRAIN Batch 24/800 loss 3.622039 loss_att 7.847070 loss_ctc 7.024746 loss_rnnt 2.287592 hw_loss 0.067024 lr 0.00035267 rank 2
2023-02-22 21:45:39,279 DEBUG TRAIN Batch 24/800 loss 6.004094 loss_att 11.919196 loss_ctc 7.090095 loss_rnnt 4.673621 hw_loss 0.004973 lr 0.00035275 rank 6
2023-02-22 21:45:39,316 DEBUG TRAIN Batch 24/800 loss 6.466775 loss_att 12.965071 loss_ctc 10.758159 loss_rnnt 4.566549 hw_loss 0.053218 lr 0.00035275 rank 1
2023-02-22 21:46:53,570 DEBUG TRAIN Batch 24/900 loss 7.214664 loss_att 9.343273 loss_ctc 9.950899 loss_rnnt 6.403157 hw_loss 0.039288 lr 0.00035262 rank 5
2023-02-22 21:46:53,574 DEBUG TRAIN Batch 24/900 loss 9.816571 loss_att 11.804703 loss_ctc 15.550014 loss_rnnt 8.645317 hw_loss 0.017191 lr 0.00035263 rank 4
2023-02-22 21:46:53,577 DEBUG TRAIN Batch 24/900 loss 6.286590 loss_att 9.630946 loss_ctc 9.666039 loss_rnnt 5.126050 hw_loss 0.077016 lr 0.00035264 rank 0
2023-02-22 21:46:53,578 DEBUG TRAIN Batch 24/900 loss 4.062149 loss_att 7.216930 loss_ctc 6.123332 loss_rnnt 3.114894 hw_loss 0.077763 lr 0.00035260 rank 7
2023-02-22 21:46:53,580 DEBUG TRAIN Batch 24/900 loss 10.378439 loss_att 12.096830 loss_ctc 16.416824 loss_rnnt 9.172791 hw_loss 0.106598 lr 0.00035266 rank 6
2023-02-22 21:46:53,581 DEBUG TRAIN Batch 24/900 loss 10.982957 loss_att 14.738472 loss_ctc 15.631638 loss_rnnt 9.605367 hw_loss 0.012493 lr 0.00035261 rank 3
2023-02-22 21:46:53,584 DEBUG TRAIN Batch 24/900 loss 5.154312 loss_att 7.325319 loss_ctc 9.934903 loss_rnnt 4.027355 hw_loss 0.103771 lr 0.00035266 rank 1
2023-02-22 21:46:53,585 DEBUG TRAIN Batch 24/900 loss 4.287653 loss_att 7.092184 loss_ctc 5.478712 loss_rnnt 3.517100 hw_loss 0.095324 lr 0.00035258 rank 2
2023-02-22 21:48:09,543 DEBUG TRAIN Batch 24/1000 loss 3.853667 loss_att 6.700477 loss_ctc 6.949602 loss_rnnt 2.851706 hw_loss 0.037140 lr 0.00035252 rank 3
2023-02-22 21:48:09,545 DEBUG TRAIN Batch 24/1000 loss 6.112974 loss_att 6.769248 loss_ctc 7.371715 loss_rnnt 5.793096 hw_loss 0.038984 lr 0.00035251 rank 7
2023-02-22 21:48:09,544 DEBUG TRAIN Batch 24/1000 loss 10.366441 loss_att 12.188675 loss_ctc 15.584191 loss_rnnt 9.270379 hw_loss 0.067339 lr 0.00035255 rank 4
2023-02-22 21:48:09,546 DEBUG TRAIN Batch 24/1000 loss 10.536770 loss_att 12.548138 loss_ctc 11.313596 loss_rnnt 9.986591 hw_loss 0.083112 lr 0.00035254 rank 5
2023-02-22 21:48:09,549 DEBUG TRAIN Batch 24/1000 loss 13.753003 loss_att 16.955070 loss_ctc 21.113508 loss_rnnt 12.087371 hw_loss 0.082160 lr 0.00035255 rank 0
2023-02-22 21:48:09,553 DEBUG TRAIN Batch 24/1000 loss 6.858615 loss_att 9.068136 loss_ctc 9.331347 loss_rnnt 6.050384 hw_loss 0.068681 lr 0.00035249 rank 2
2023-02-22 21:48:09,554 DEBUG TRAIN Batch 24/1000 loss 6.835702 loss_att 9.170694 loss_ctc 9.997313 loss_rnnt 5.893334 hw_loss 0.100915 lr 0.00035258 rank 1
2023-02-22 21:48:09,603 DEBUG TRAIN Batch 24/1000 loss 8.635016 loss_att 10.770983 loss_ctc 9.211658 loss_rnnt 8.095160 hw_loss 0.067083 lr 0.00035258 rank 6
2023-02-22 21:49:25,825 DEBUG TRAIN Batch 24/1100 loss 11.067809 loss_att 14.760268 loss_ctc 18.743372 loss_rnnt 9.258719 hw_loss 0.088479 lr 0.00035246 rank 0
2023-02-22 21:49:25,825 DEBUG TRAIN Batch 24/1100 loss 6.366975 loss_att 10.109414 loss_ctc 9.832903 loss_rnnt 5.140030 hw_loss 0.030625 lr 0.00035242 rank 7
2023-02-22 21:49:25,826 DEBUG TRAIN Batch 24/1100 loss 4.734364 loss_att 7.344663 loss_ctc 7.040982 loss_rnnt 3.853025 hw_loss 0.096994 lr 0.00035245 rank 5
2023-02-22 21:49:25,826 DEBUG TRAIN Batch 24/1100 loss 8.416921 loss_att 11.449978 loss_ctc 12.207998 loss_rnnt 7.258083 hw_loss 0.087655 lr 0.00035246 rank 4
2023-02-22 21:49:25,830 DEBUG TRAIN Batch 24/1100 loss 12.416003 loss_att 14.073729 loss_ctc 15.785907 loss_rnnt 11.590368 hw_loss 0.083944 lr 0.00035249 rank 6
2023-02-22 21:49:25,831 DEBUG TRAIN Batch 24/1100 loss 10.904847 loss_att 12.845158 loss_ctc 15.280702 loss_rnnt 9.925637 hw_loss 0.014437 lr 0.00035243 rank 3
2023-02-22 21:49:25,831 DEBUG TRAIN Batch 24/1100 loss 7.998201 loss_att 9.397130 loss_ctc 11.565872 loss_rnnt 7.171492 hw_loss 0.133565 lr 0.00035240 rank 2
2023-02-22 21:49:25,832 DEBUG TRAIN Batch 24/1100 loss 9.120863 loss_att 11.116270 loss_ctc 15.361310 loss_rnnt 7.821555 hw_loss 0.127814 lr 0.00035249 rank 1
2023-02-22 21:50:40,594 DEBUG TRAIN Batch 24/1200 loss 6.556214 loss_att 9.331501 loss_ctc 10.191633 loss_rnnt 5.428127 hw_loss 0.165576 lr 0.00035237 rank 4
2023-02-22 21:50:40,596 DEBUG TRAIN Batch 24/1200 loss 7.631883 loss_att 11.631243 loss_ctc 12.596619 loss_rnnt 6.077075 hw_loss 0.174318 lr 0.00035234 rank 3
2023-02-22 21:50:40,596 DEBUG TRAIN Batch 24/1200 loss 4.644688 loss_att 6.372540 loss_ctc 6.281517 loss_rnnt 4.023010 hw_loss 0.108496 lr 0.00035237 rank 0
2023-02-22 21:50:40,598 DEBUG TRAIN Batch 24/1200 loss 7.285154 loss_att 9.612368 loss_ctc 10.846575 loss_rnnt 6.283050 hw_loss 0.115885 lr 0.00035234 rank 7
2023-02-22 21:50:40,598 DEBUG TRAIN Batch 24/1200 loss 6.812159 loss_att 10.569069 loss_ctc 10.347788 loss_rnnt 5.531664 hw_loss 0.108178 lr 0.00035236 rank 5
2023-02-22 21:50:40,600 DEBUG TRAIN Batch 24/1200 loss 5.232186 loss_att 6.656452 loss_ctc 7.624960 loss_rnnt 4.570975 hw_loss 0.107478 lr 0.00035240 rank 6
2023-02-22 21:50:40,609 DEBUG TRAIN Batch 24/1200 loss 11.971130 loss_att 12.147997 loss_ctc 16.483397 loss_rnnt 11.273218 hw_loss 0.114194 lr 0.00035240 rank 1
2023-02-22 21:50:40,637 DEBUG TRAIN Batch 24/1200 loss 3.276452 loss_att 6.151397 loss_ctc 5.209771 loss_rnnt 2.438944 hw_loss 0.008892 lr 0.00035232 rank 2
2023-02-22 21:51:56,133 DEBUG TRAIN Batch 24/1300 loss 9.262105 loss_att 9.593790 loss_ctc 12.561691 loss_rnnt 8.674103 hw_loss 0.153223 lr 0.00035228 rank 4
2023-02-22 21:51:56,137 DEBUG TRAIN Batch 24/1300 loss 2.146690 loss_att 4.646056 loss_ctc 2.725752 loss_rnnt 1.531524 hw_loss 0.071409 lr 0.00035231 rank 1
2023-02-22 21:51:56,139 DEBUG TRAIN Batch 24/1300 loss 8.084042 loss_att 13.680429 loss_ctc 10.173239 loss_rnnt 6.585632 hw_loss 0.188574 lr 0.00035225 rank 7
2023-02-22 21:51:56,141 DEBUG TRAIN Batch 24/1300 loss 8.523592 loss_att 13.302010 loss_ctc 11.770575 loss_rnnt 7.099420 hw_loss 0.066672 lr 0.00035226 rank 3
2023-02-22 21:51:56,143 DEBUG TRAIN Batch 24/1300 loss 1.468320 loss_att 4.321678 loss_ctc 3.338268 loss_rnnt 0.626132 hw_loss 0.041605 lr 0.00035223 rank 2
2023-02-22 21:51:56,143 DEBUG TRAIN Batch 24/1300 loss 24.186691 loss_att 23.754599 loss_ctc 32.801567 loss_rnnt 23.122814 hw_loss 0.003085 lr 0.00035231 rank 6
2023-02-22 21:51:56,144 DEBUG TRAIN Batch 24/1300 loss 7.652709 loss_att 11.546388 loss_ctc 9.372956 loss_rnnt 6.616567 hw_loss 0.052575 lr 0.00035227 rank 5
2023-02-22 21:51:56,148 DEBUG TRAIN Batch 24/1300 loss 6.285763 loss_att 6.325254 loss_ctc 8.198095 loss_rnnt 5.955799 hw_loss 0.125792 lr 0.00035228 rank 0
2023-02-22 21:53:13,685 DEBUG TRAIN Batch 24/1400 loss 4.810200 loss_att 8.080408 loss_ctc 8.655411 loss_rnnt 3.595996 hw_loss 0.089002 lr 0.00035219 rank 5
2023-02-22 21:53:13,689 DEBUG TRAIN Batch 24/1400 loss 5.862386 loss_att 10.005711 loss_ctc 12.674736 loss_rnnt 4.099499 hw_loss 0.048579 lr 0.00035216 rank 7
2023-02-22 21:53:13,690 DEBUG TRAIN Batch 24/1400 loss 3.126438 loss_att 6.968777 loss_ctc 4.957446 loss_rnnt 2.074409 hw_loss 0.073925 lr 0.00035220 rank 4
2023-02-22 21:53:13,694 DEBUG TRAIN Batch 24/1400 loss 3.474727 loss_att 5.612844 loss_ctc 3.734640 loss_rnnt 2.974005 hw_loss 0.072083 lr 0.00035220 rank 0
2023-02-22 21:53:13,694 DEBUG TRAIN Batch 24/1400 loss 9.462726 loss_att 11.407796 loss_ctc 13.934555 loss_rnnt 8.429986 hw_loss 0.089028 lr 0.00035223 rank 1
2023-02-22 21:53:13,694 DEBUG TRAIN Batch 24/1400 loss 9.392483 loss_att 13.632528 loss_ctc 14.272924 loss_rnnt 7.893088 hw_loss 0.001238 lr 0.00035217 rank 3
2023-02-22 21:53:13,700 DEBUG TRAIN Batch 24/1400 loss 15.037456 loss_att 14.481483 loss_ctc 21.121933 loss_rnnt 14.290213 hw_loss 0.088453 lr 0.00035223 rank 6
2023-02-22 21:53:13,702 DEBUG TRAIN Batch 24/1400 loss 4.681550 loss_att 5.646295 loss_ctc 4.494907 loss_rnnt 4.493196 hw_loss 0.038045 lr 0.00035214 rank 2
2023-02-22 21:54:29,960 DEBUG TRAIN Batch 24/1500 loss 8.009459 loss_att 10.094981 loss_ctc 9.830949 loss_rnnt 7.283113 hw_loss 0.124456 lr 0.00035211 rank 0
2023-02-22 21:54:29,964 DEBUG TRAIN Batch 24/1500 loss 2.751022 loss_att 6.081664 loss_ctc 4.919165 loss_rnnt 1.768267 hw_loss 0.051640 lr 0.00035211 rank 4
2023-02-22 21:54:29,965 DEBUG TRAIN Batch 24/1500 loss 6.495905 loss_att 7.610518 loss_ctc 6.868807 loss_rnnt 6.164760 hw_loss 0.109693 lr 0.00035207 rank 7
2023-02-22 21:54:29,966 DEBUG TRAIN Batch 24/1500 loss 11.797875 loss_att 14.443337 loss_ctc 13.748686 loss_rnnt 11.002266 hw_loss 0.012016 lr 0.00035208 rank 3
2023-02-22 21:54:29,967 DEBUG TRAIN Batch 24/1500 loss 12.422411 loss_att 16.381300 loss_ctc 19.905684 loss_rnnt 10.527945 hw_loss 0.196722 lr 0.00035214 rank 1
2023-02-22 21:54:29,969 DEBUG TRAIN Batch 24/1500 loss 8.617047 loss_att 11.853191 loss_ctc 13.521565 loss_rnnt 7.249551 hw_loss 0.124371 lr 0.00035214 rank 6
2023-02-22 21:54:29,971 DEBUG TRAIN Batch 24/1500 loss 5.461832 loss_att 11.215264 loss_ctc 8.934315 loss_rnnt 3.808372 hw_loss 0.074579 lr 0.00035210 rank 5
2023-02-22 21:54:29,973 DEBUG TRAIN Batch 24/1500 loss 4.792063 loss_att 9.636242 loss_ctc 7.455789 loss_rnnt 3.403887 hw_loss 0.120332 lr 0.00035206 rank 2
2023-02-22 21:55:43,045 DEBUG TRAIN Batch 24/1600 loss 6.988921 loss_att 9.307834 loss_ctc 10.829522 loss_rnnt 5.976369 hw_loss 0.068791 lr 0.00035202 rank 0
2023-02-22 21:55:43,050 DEBUG TRAIN Batch 24/1600 loss 9.846173 loss_att 10.570074 loss_ctc 13.259035 loss_rnnt 9.229305 hw_loss 0.031948 lr 0.00035201 rank 5
2023-02-22 21:55:43,051 DEBUG TRAIN Batch 24/1600 loss 6.932962 loss_att 9.926689 loss_ctc 9.534187 loss_rnnt 5.938573 hw_loss 0.091527 lr 0.00035202 rank 4
2023-02-22 21:55:43,052 DEBUG TRAIN Batch 24/1600 loss 11.982562 loss_att 18.097660 loss_ctc 18.082005 loss_rnnt 9.898014 hw_loss 0.090503 lr 0.00035199 rank 7
2023-02-22 21:55:43,054 DEBUG TRAIN Batch 24/1600 loss 12.135122 loss_att 14.488863 loss_ctc 15.049726 loss_rnnt 11.255297 hw_loss 0.038368 lr 0.00035205 rank 1
2023-02-22 21:55:43,054 DEBUG TRAIN Batch 24/1600 loss 6.980877 loss_att 12.078376 loss_ctc 9.809453 loss_rnnt 5.542344 hw_loss 0.078544 lr 0.00035205 rank 6
2023-02-22 21:55:43,057 DEBUG TRAIN Batch 24/1600 loss 13.042562 loss_att 14.522929 loss_ctc 17.656620 loss_rnnt 12.098577 hw_loss 0.061319 lr 0.00035199 rank 3
2023-02-22 21:55:43,057 DEBUG TRAIN Batch 24/1600 loss 11.359690 loss_att 14.010190 loss_ctc 18.349125 loss_rnnt 9.875994 hw_loss 0.040631 lr 0.00035197 rank 2
2023-02-22 21:56:58,979 DEBUG TRAIN Batch 24/1700 loss 9.343504 loss_att 10.924496 loss_ctc 11.850222 loss_rnnt 8.662505 hw_loss 0.057319 lr 0.00035192 rank 5
2023-02-22 21:56:58,980 DEBUG TRAIN Batch 24/1700 loss 5.436267 loss_att 10.057777 loss_ctc 6.857848 loss_rnnt 4.313206 hw_loss 0.017277 lr 0.00035196 rank 1
2023-02-22 21:56:58,980 DEBUG TRAIN Batch 24/1700 loss 9.682612 loss_att 12.435834 loss_ctc 13.569421 loss_rnnt 8.563079 hw_loss 0.094963 lr 0.00035194 rank 0
2023-02-22 21:56:58,982 DEBUG TRAIN Batch 24/1700 loss 10.153272 loss_att 13.216719 loss_ctc 13.146143 loss_rnnt 9.138122 hw_loss 0.006396 lr 0.00035190 rank 7
2023-02-22 21:56:58,982 DEBUG TRAIN Batch 24/1700 loss 5.356278 loss_att 8.439823 loss_ctc 9.393555 loss_rnnt 4.175467 hw_loss 0.048372 lr 0.00035191 rank 3
2023-02-22 21:56:58,984 DEBUG TRAIN Batch 24/1700 loss 8.212283 loss_att 11.815604 loss_ctc 11.856592 loss_rnnt 6.964142 hw_loss 0.077942 lr 0.00035188 rank 2
2023-02-22 21:56:58,987 DEBUG TRAIN Batch 24/1700 loss 10.871856 loss_att 12.982049 loss_ctc 12.832300 loss_rnnt 10.107744 hw_loss 0.151273 lr 0.00035193 rank 4
2023-02-22 21:56:59,032 DEBUG TRAIN Batch 24/1700 loss 1.166294 loss_att 3.205403 loss_ctc 2.897162 loss_rnnt 0.487092 hw_loss 0.076121 lr 0.00035196 rank 6
2023-02-22 21:58:16,665 DEBUG TRAIN Batch 24/1800 loss 8.318167 loss_att 10.784677 loss_ctc 12.386015 loss_rnnt 7.235292 hw_loss 0.088486 lr 0.00035184 rank 5
2023-02-22 21:58:16,667 DEBUG TRAIN Batch 24/1800 loss 5.089414 loss_att 9.751067 loss_ctc 6.964389 loss_rnnt 3.883025 hw_loss 0.045115 lr 0.00035185 rank 4
2023-02-22 21:58:16,667 DEBUG TRAIN Batch 24/1800 loss 9.491274 loss_att 12.439309 loss_ctc 12.406108 loss_rnnt 8.477364 hw_loss 0.066859 lr 0.00035185 rank 0
2023-02-22 21:58:16,667 DEBUG TRAIN Batch 24/1800 loss 11.691504 loss_att 15.129698 loss_ctc 18.029087 loss_rnnt 10.070747 hw_loss 0.165198 lr 0.00035179 rank 2
2023-02-22 21:58:16,670 DEBUG TRAIN Batch 24/1800 loss 10.980520 loss_att 12.946358 loss_ctc 14.825239 loss_rnnt 10.050985 hw_loss 0.044507 lr 0.00035182 rank 3
2023-02-22 21:58:16,670 DEBUG TRAIN Batch 24/1800 loss 8.120759 loss_att 10.465730 loss_ctc 12.186260 loss_rnnt 7.040901 hw_loss 0.128995 lr 0.00035181 rank 7
2023-02-22 21:58:16,671 DEBUG TRAIN Batch 24/1800 loss 14.149581 loss_att 14.232359 loss_ctc 19.527491 loss_rnnt 13.342142 hw_loss 0.138428 lr 0.00035188 rank 6
2023-02-22 21:58:16,673 DEBUG TRAIN Batch 24/1800 loss 5.300065 loss_att 9.548864 loss_ctc 6.088607 loss_rnnt 4.309225 hw_loss 0.067392 lr 0.00035188 rank 1
2023-02-22 21:59:31,452 DEBUG TRAIN Batch 24/1900 loss 7.465030 loss_att 7.646151 loss_ctc 10.704771 loss_rnnt 6.890983 hw_loss 0.198482 lr 0.00035175 rank 5
2023-02-22 21:59:31,457 DEBUG TRAIN Batch 24/1900 loss 11.845264 loss_att 12.675575 loss_ctc 16.011009 loss_rnnt 11.024240 hw_loss 0.186616 lr 0.00035173 rank 3
2023-02-22 21:59:31,458 DEBUG TRAIN Batch 24/1900 loss 8.748505 loss_att 9.995976 loss_ctc 12.123358 loss_rnnt 7.971848 hw_loss 0.144716 lr 0.00035176 rank 4
2023-02-22 21:59:31,458 DEBUG TRAIN Batch 24/1900 loss 9.644891 loss_att 12.935413 loss_ctc 17.348648 loss_rnnt 7.900541 hw_loss 0.110770 lr 0.00035172 rank 7
2023-02-22 21:59:31,458 DEBUG TRAIN Batch 24/1900 loss 7.976932 loss_att 10.850348 loss_ctc 12.748462 loss_rnnt 6.755479 hw_loss 0.019810 lr 0.00035171 rank 2
2023-02-22 21:59:31,459 DEBUG TRAIN Batch 24/1900 loss 4.815159 loss_att 8.727822 loss_ctc 6.869960 loss_rnnt 3.740799 hw_loss 0.033476 lr 0.00035176 rank 0
2023-02-22 21:59:31,461 DEBUG TRAIN Batch 24/1900 loss 10.032971 loss_att 12.798499 loss_ctc 16.234165 loss_rnnt 8.586623 hw_loss 0.124532 lr 0.00035179 rank 6
2023-02-22 21:59:31,509 DEBUG TRAIN Batch 24/1900 loss 12.956736 loss_att 12.266050 loss_ctc 18.326872 loss_rnnt 12.286730 hw_loss 0.172732 lr 0.00035179 rank 1
2023-02-22 22:00:45,846 DEBUG TRAIN Batch 24/2000 loss 7.782106 loss_att 11.673653 loss_ctc 14.398932 loss_rnnt 6.087313 hw_loss 0.064201 lr 0.00035166 rank 5
2023-02-22 22:00:45,846 DEBUG TRAIN Batch 24/2000 loss 8.689036 loss_att 12.519539 loss_ctc 14.356471 loss_rnnt 7.134571 hw_loss 0.061326 lr 0.00035170 rank 1
2023-02-22 22:00:45,846 DEBUG TRAIN Batch 24/2000 loss 8.083812 loss_att 8.926838 loss_ctc 11.022025 loss_rnnt 7.479201 hw_loss 0.082958 lr 0.00035167 rank 0
2023-02-22 22:00:45,849 DEBUG TRAIN Batch 24/2000 loss 4.773462 loss_att 6.879269 loss_ctc 7.283249 loss_rnnt 3.936126 hw_loss 0.152881 lr 0.00035167 rank 4
2023-02-22 22:00:45,850 DEBUG TRAIN Batch 24/2000 loss 9.115026 loss_att 11.286870 loss_ctc 9.861426 loss_rnnt 8.529295 hw_loss 0.097204 lr 0.00035164 rank 7
2023-02-22 22:00:45,851 DEBUG TRAIN Batch 24/2000 loss 7.491963 loss_att 11.345445 loss_ctc 14.477523 loss_rnnt 5.770187 hw_loss 0.036884 lr 0.00035162 rank 2
2023-02-22 22:00:45,853 DEBUG TRAIN Batch 24/2000 loss 7.280044 loss_att 9.808418 loss_ctc 14.708766 loss_rnnt 5.740972 hw_loss 0.080439 lr 0.00035170 rank 6
2023-02-22 22:00:45,855 DEBUG TRAIN Batch 24/2000 loss 3.373534 loss_att 6.508223 loss_ctc 6.134582 loss_rnnt 2.370446 hw_loss 0.015020 lr 0.00035165 rank 3
2023-02-22 22:02:02,789 DEBUG TRAIN Batch 24/2100 loss 3.944418 loss_att 6.403769 loss_ctc 7.090948 loss_rnnt 2.976884 hw_loss 0.105238 lr 0.00035155 rank 7
2023-02-22 22:02:02,789 DEBUG TRAIN Batch 24/2100 loss 12.835482 loss_att 14.089780 loss_ctc 18.330729 loss_rnnt 11.733099 hw_loss 0.222795 lr 0.00035159 rank 4
2023-02-22 22:02:02,792 DEBUG TRAIN Batch 24/2100 loss 8.912796 loss_att 11.146080 loss_ctc 8.786602 loss_rnnt 8.434587 hw_loss 0.090709 lr 0.00035162 rank 1
2023-02-22 22:02:02,793 DEBUG TRAIN Batch 24/2100 loss 6.235563 loss_att 8.523252 loss_ctc 8.330727 loss_rnnt 5.438759 hw_loss 0.112334 lr 0.00035159 rank 0
2023-02-22 22:02:02,795 DEBUG TRAIN Batch 24/2100 loss 6.237291 loss_att 9.790266 loss_ctc 9.438366 loss_rnnt 5.094464 hw_loss 0.010166 lr 0.00035156 rank 3
2023-02-22 22:02:02,796 DEBUG TRAIN Batch 24/2100 loss 3.224123 loss_att 5.453279 loss_ctc 4.538552 loss_rnnt 2.593406 hw_loss 0.018054 lr 0.00035158 rank 5
2023-02-22 22:02:02,796 DEBUG TRAIN Batch 24/2100 loss 5.272505 loss_att 10.198571 loss_ctc 8.479576 loss_rnnt 3.836241 hw_loss 0.043952 lr 0.00035162 rank 6
2023-02-22 22:02:02,845 DEBUG TRAIN Batch 24/2100 loss 10.857187 loss_att 13.625312 loss_ctc 18.062374 loss_rnnt 9.318071 hw_loss 0.046500 lr 0.00035153 rank 2
2023-02-22 22:03:18,590 DEBUG TRAIN Batch 24/2200 loss 5.872439 loss_att 9.149093 loss_ctc 8.746655 loss_rnnt 4.728920 hw_loss 0.196800 lr 0.00035150 rank 0
2023-02-22 22:03:18,591 DEBUG TRAIN Batch 24/2200 loss 11.690912 loss_att 15.896510 loss_ctc 16.864084 loss_rnnt 10.126671 hw_loss 0.062560 lr 0.00035147 rank 3
2023-02-22 22:03:18,594 DEBUG TRAIN Batch 24/2200 loss 6.186879 loss_att 9.224636 loss_ctc 7.594629 loss_rnnt 5.346068 hw_loss 0.085424 lr 0.00035149 rank 5
2023-02-22 22:03:18,595 DEBUG TRAIN Batch 24/2200 loss 5.494969 loss_att 9.769684 loss_ctc 9.773567 loss_rnnt 3.991014 hw_loss 0.147247 lr 0.00035153 rank 6
2023-02-22 22:03:18,594 DEBUG TRAIN Batch 24/2200 loss 7.692955 loss_att 12.328457 loss_ctc 11.253538 loss_rnnt 6.159619 hw_loss 0.246547 lr 0.00035146 rank 7
2023-02-22 22:03:18,594 DEBUG TRAIN Batch 24/2200 loss 4.356265 loss_att 9.101648 loss_ctc 7.969926 loss_rnnt 2.879256 hw_loss 0.086458 lr 0.00035150 rank 4
2023-02-22 22:03:18,595 DEBUG TRAIN Batch 24/2200 loss 8.089091 loss_att 11.273772 loss_ctc 14.160183 loss_rnnt 6.584834 hw_loss 0.108454 lr 0.00035145 rank 2
2023-02-22 22:03:18,596 DEBUG TRAIN Batch 24/2200 loss 10.981226 loss_att 12.743972 loss_ctc 17.808731 loss_rnnt 9.696175 hw_loss 0.041565 lr 0.00035153 rank 1
2023-02-22 22:04:33,790 DEBUG TRAIN Batch 24/2300 loss 14.378010 loss_att 15.707798 loss_ctc 16.386923 loss_rnnt 13.807945 hw_loss 0.067974 lr 0.00035141 rank 0
2023-02-22 22:04:33,796 DEBUG TRAIN Batch 24/2300 loss 8.284806 loss_att 12.238539 loss_ctc 12.248607 loss_rnnt 6.882400 hw_loss 0.155913 lr 0.00035140 rank 5
2023-02-22 22:04:33,798 DEBUG TRAIN Batch 24/2300 loss 6.814940 loss_att 10.010739 loss_ctc 8.592299 loss_rnnt 5.902332 hw_loss 0.068376 lr 0.00035141 rank 4
2023-02-22 22:04:33,798 DEBUG TRAIN Batch 24/2300 loss 8.672341 loss_att 12.721451 loss_ctc 12.328508 loss_rnnt 7.343317 hw_loss 0.059463 lr 0.00035138 rank 7
2023-02-22 22:04:33,803 DEBUG TRAIN Batch 24/2300 loss 9.326699 loss_att 12.921421 loss_ctc 13.502769 loss_rnnt 7.979034 hw_loss 0.134833 lr 0.00035144 rank 6
2023-02-22 22:04:33,802 DEBUG TRAIN Batch 24/2300 loss 10.948585 loss_att 15.280325 loss_ctc 17.688169 loss_rnnt 9.127922 hw_loss 0.104444 lr 0.00035136 rank 2
2023-02-22 22:04:33,807 DEBUG TRAIN Batch 24/2300 loss 5.070676 loss_att 7.858632 loss_ctc 6.657470 loss_rnnt 4.282108 hw_loss 0.036383 lr 0.00035144 rank 1
2023-02-22 22:04:33,848 DEBUG TRAIN Batch 24/2300 loss 4.849153 loss_att 8.974282 loss_ctc 7.506992 loss_rnnt 3.631487 hw_loss 0.071741 lr 0.00035139 rank 3
2023-02-22 22:05:49,981 DEBUG TRAIN Batch 24/2400 loss 6.874113 loss_att 8.793732 loss_ctc 10.448557 loss_rnnt 5.937072 hw_loss 0.143483 lr 0.00035129 rank 7
2023-02-22 22:05:49,987 DEBUG TRAIN Batch 24/2400 loss 6.891032 loss_att 7.957063 loss_ctc 9.076385 loss_rnnt 6.341753 hw_loss 0.083800 lr 0.00035135 rank 6
2023-02-22 22:05:49,988 DEBUG TRAIN Batch 24/2400 loss 15.533256 loss_att 18.211897 loss_ctc 23.528961 loss_rnnt 13.871967 hw_loss 0.111496 lr 0.00035132 rank 5
2023-02-22 22:05:49,995 DEBUG TRAIN Batch 24/2400 loss 4.290518 loss_att 7.012455 loss_ctc 9.151829 loss_rnnt 3.053157 hw_loss 0.083999 lr 0.00035130 rank 3
2023-02-22 22:05:49,997 DEBUG TRAIN Batch 24/2400 loss 10.814013 loss_att 13.011370 loss_ctc 18.337667 loss_rnnt 9.330992 hw_loss 0.075744 lr 0.00035127 rank 2
2023-02-22 22:05:50,017 DEBUG TRAIN Batch 24/2400 loss 11.358130 loss_att 11.966069 loss_ctc 16.081648 loss_rnnt 10.588744 hw_loss 0.033740 lr 0.00035133 rank 4
2023-02-22 22:05:50,026 DEBUG TRAIN Batch 24/2400 loss 5.541172 loss_att 9.016038 loss_ctc 10.856753 loss_rnnt 4.103613 hw_loss 0.063451 lr 0.00035133 rank 0
2023-02-22 22:05:50,036 DEBUG TRAIN Batch 24/2400 loss 16.115271 loss_att 19.090210 loss_ctc 24.613684 loss_rnnt 14.318840 hw_loss 0.128100 lr 0.00035135 rank 1
2023-02-22 22:07:08,851 DEBUG TRAIN Batch 24/2500 loss 10.928412 loss_att 14.499565 loss_ctc 16.175270 loss_rnnt 9.475777 hw_loss 0.072795 lr 0.00035123 rank 5
2023-02-22 22:07:08,852 DEBUG TRAIN Batch 24/2500 loss 11.953539 loss_att 15.288600 loss_ctc 15.187389 loss_rnnt 10.830853 hw_loss 0.045927 lr 0.00035124 rank 0
2023-02-22 22:07:08,853 DEBUG TRAIN Batch 24/2500 loss 3.348214 loss_att 8.601995 loss_ctc 4.065501 loss_rnnt 2.153182 hw_loss 0.091195 lr 0.00035120 rank 7
2023-02-22 22:07:08,854 DEBUG TRAIN Batch 24/2500 loss 6.687816 loss_att 9.243624 loss_ctc 10.676123 loss_rnnt 5.617939 hw_loss 0.050515 lr 0.00035124 rank 4
2023-02-22 22:07:08,854 DEBUG TRAIN Batch 24/2500 loss 15.570690 loss_att 18.171448 loss_ctc 27.920847 loss_rnnt 13.349231 hw_loss 0.102414 lr 0.00035127 rank 1
2023-02-22 22:07:08,854 DEBUG TRAIN Batch 24/2500 loss 8.729883 loss_att 11.383703 loss_ctc 12.819687 loss_rnnt 7.653768 hw_loss 0.000083 lr 0.00035127 rank 6
2023-02-22 22:07:08,855 DEBUG TRAIN Batch 24/2500 loss 5.948036 loss_att 7.218742 loss_ctc 9.620684 loss_rnnt 5.154714 hw_loss 0.092803 lr 0.00035121 rank 3
2023-02-22 22:07:08,909 DEBUG TRAIN Batch 24/2500 loss 4.631158 loss_att 5.645073 loss_ctc 6.779604 loss_rnnt 4.080055 hw_loss 0.115990 lr 0.00035119 rank 2
2023-02-22 22:08:23,650 DEBUG TRAIN Batch 24/2600 loss 8.091935 loss_att 11.923290 loss_ctc 11.840149 loss_rnnt 6.806383 hw_loss 0.036599 lr 0.00035114 rank 5
2023-02-22 22:08:23,651 DEBUG TRAIN Batch 24/2600 loss 13.664031 loss_att 16.703085 loss_ctc 20.931675 loss_rnnt 12.087161 hw_loss 0.000077 lr 0.00035115 rank 4
2023-02-22 22:08:23,651 DEBUG TRAIN Batch 24/2600 loss 7.539627 loss_att 9.950441 loss_ctc 12.790634 loss_rnnt 6.285058 hw_loss 0.135508 lr 0.00035118 rank 1
2023-02-22 22:08:23,653 DEBUG TRAIN Batch 24/2600 loss 8.431314 loss_att 12.845866 loss_ctc 17.915066 loss_rnnt 6.259263 hw_loss 0.046199 lr 0.00035112 rank 7
2023-02-22 22:08:23,654 DEBUG TRAIN Batch 24/2600 loss 5.041158 loss_att 6.189488 loss_ctc 7.763411 loss_rnnt 4.371984 hw_loss 0.143514 lr 0.00035115 rank 0
2023-02-22 22:08:23,656 DEBUG TRAIN Batch 24/2600 loss 5.132033 loss_att 7.913764 loss_ctc 6.871431 loss_rnnt 4.329846 hw_loss 0.026101 lr 0.00035113 rank 3
2023-02-22 22:08:23,659 DEBUG TRAIN Batch 24/2600 loss 11.876691 loss_att 14.460159 loss_ctc 19.820393 loss_rnnt 10.286633 hw_loss 0.026634 lr 0.00035110 rank 2
2023-02-22 22:08:23,660 DEBUG TRAIN Batch 24/2600 loss 16.380022 loss_att 22.008675 loss_ctc 23.681408 loss_rnnt 14.279990 hw_loss 0.001467 lr 0.00035118 rank 6
2023-02-22 22:09:39,628 DEBUG TRAIN Batch 24/2700 loss 2.167396 loss_att 6.277832 loss_ctc 5.750171 loss_rnnt 0.867563 hw_loss 0.000081 lr 0.00035107 rank 4
2023-02-22 22:09:39,629 DEBUG TRAIN Batch 24/2700 loss 6.039284 loss_att 9.423507 loss_ctc 8.839219 loss_rnnt 4.966525 hw_loss 0.042355 lr 0.00035103 rank 7
2023-02-22 22:09:39,630 DEBUG TRAIN Batch 24/2700 loss 6.261954 loss_att 10.681980 loss_ctc 10.803248 loss_rnnt 4.726298 hw_loss 0.086521 lr 0.00035106 rank 5
2023-02-22 22:09:39,629 DEBUG TRAIN Batch 24/2700 loss 9.072346 loss_att 11.448418 loss_ctc 13.654949 loss_rnnt 7.973201 hw_loss 0.024219 lr 0.00035107 rank 0
2023-02-22 22:09:39,631 DEBUG TRAIN Batch 24/2700 loss 14.855391 loss_att 20.459034 loss_ctc 19.907017 loss_rnnt 13.031329 hw_loss 0.055841 lr 0.00035109 rank 1
2023-02-22 22:09:39,632 DEBUG TRAIN Batch 24/2700 loss 4.507381 loss_att 7.889918 loss_ctc 6.715878 loss_rnnt 3.498955 hw_loss 0.070223 lr 0.00035104 rank 3
2023-02-22 22:09:39,637 DEBUG TRAIN Batch 24/2700 loss 6.538306 loss_att 9.096620 loss_ctc 7.437332 loss_rnnt 5.899787 hw_loss 0.013099 lr 0.00035101 rank 2
2023-02-22 22:09:39,640 DEBUG TRAIN Batch 24/2700 loss 3.012688 loss_att 6.088455 loss_ctc 6.054953 loss_rnnt 1.944657 hw_loss 0.088580 lr 0.00035109 rank 6
2023-02-22 22:10:55,984 DEBUG TRAIN Batch 24/2800 loss 5.634765 loss_att 7.895319 loss_ctc 8.750314 loss_rnnt 4.713377 hw_loss 0.101007 lr 0.00035098 rank 0
2023-02-22 22:10:55,988 DEBUG TRAIN Batch 24/2800 loss 5.506147 loss_att 8.835010 loss_ctc 9.489037 loss_rnnt 4.246151 hw_loss 0.118446 lr 0.00035097 rank 5
2023-02-22 22:10:55,988 DEBUG TRAIN Batch 24/2800 loss 20.751467 loss_att 24.087641 loss_ctc 28.058853 loss_rnnt 19.072926 hw_loss 0.069353 lr 0.00035098 rank 4
2023-02-22 22:10:55,990 DEBUG TRAIN Batch 24/2800 loss 7.069828 loss_att 10.350519 loss_ctc 13.847965 loss_rnnt 5.480324 hw_loss 0.055525 lr 0.00035093 rank 2
2023-02-22 22:10:55,989 DEBUG TRAIN Batch 24/2800 loss 3.424454 loss_att 5.636005 loss_ctc 4.547264 loss_rnnt 2.734337 hw_loss 0.183935 lr 0.00035094 rank 7
2023-02-22 22:10:55,993 DEBUG TRAIN Batch 24/2800 loss 10.940085 loss_att 13.663572 loss_ctc 19.105419 loss_rnnt 9.268080 hw_loss 0.072368 lr 0.00035101 rank 6
2023-02-22 22:10:55,993 DEBUG TRAIN Batch 24/2800 loss 7.239076 loss_att 8.571012 loss_ctc 10.123687 loss_rnnt 6.546879 hw_loss 0.077241 lr 0.00035101 rank 1
2023-02-22 22:10:55,994 DEBUG TRAIN Batch 24/2800 loss 12.874217 loss_att 15.144234 loss_ctc 18.641512 loss_rnnt 11.608478 hw_loss 0.080183 lr 0.00035095 rank 3
2023-02-22 22:12:12,956 DEBUG TRAIN Batch 24/2900 loss 11.882164 loss_att 14.103378 loss_ctc 15.017469 loss_rnnt 10.979561 hw_loss 0.075598 lr 0.00035089 rank 0
2023-02-22 22:12:12,961 DEBUG TRAIN Batch 24/2900 loss 3.270775 loss_att 6.879110 loss_ctc 5.495914 loss_rnnt 2.218800 hw_loss 0.063042 lr 0.00035089 rank 4
2023-02-22 22:12:12,963 DEBUG TRAIN Batch 24/2900 loss 12.671208 loss_att 12.496099 loss_ctc 15.348452 loss_rnnt 12.306194 hw_loss 0.080758 lr 0.00035086 rank 7
2023-02-22 22:12:12,964 DEBUG TRAIN Batch 24/2900 loss 17.012623 loss_att 18.836357 loss_ctc 26.102100 loss_rnnt 15.435842 hw_loss 0.000193 lr 0.00035087 rank 3
2023-02-22 22:12:12,965 DEBUG TRAIN Batch 24/2900 loss 6.450155 loss_att 10.267160 loss_ctc 7.675033 loss_rnnt 5.483907 hw_loss 0.074119 lr 0.00035088 rank 5
2023-02-22 22:12:12,965 DEBUG TRAIN Batch 24/2900 loss 9.856459 loss_att 12.507728 loss_ctc 14.572014 loss_rnnt 8.628006 hw_loss 0.130234 lr 0.00035092 rank 1
2023-02-22 22:12:12,966 DEBUG TRAIN Batch 24/2900 loss 10.588374 loss_att 12.981366 loss_ctc 15.430359 loss_rnnt 9.427769 hw_loss 0.068268 lr 0.00035084 rank 2
2023-02-22 22:12:13,016 DEBUG TRAIN Batch 24/2900 loss 7.935565 loss_att 10.389381 loss_ctc 9.855762 loss_rnnt 7.169679 hw_loss 0.035807 lr 0.00035092 rank 6
2023-02-22 22:13:27,613 DEBUG TRAIN Batch 24/3000 loss 10.159111 loss_att 12.285439 loss_ctc 14.352165 loss_rnnt 9.127604 hw_loss 0.088440 lr 0.00035081 rank 4
2023-02-22 22:13:27,614 DEBUG TRAIN Batch 24/3000 loss 5.181123 loss_att 8.917013 loss_ctc 11.617305 loss_rnnt 3.565366 hw_loss 0.019539 lr 0.00035080 rank 5
2023-02-22 22:13:27,618 DEBUG TRAIN Batch 24/3000 loss 4.582441 loss_att 8.342880 loss_ctc 9.998899 loss_rnnt 3.076089 hw_loss 0.060131 lr 0.00035084 rank 1
2023-02-22 22:13:27,618 DEBUG TRAIN Batch 24/3000 loss 5.779813 loss_att 8.592649 loss_ctc 8.828544 loss_rnnt 4.769115 hw_loss 0.078064 lr 0.00035077 rank 7
2023-02-22 22:13:27,620 DEBUG TRAIN Batch 24/3000 loss 10.863593 loss_att 14.928864 loss_ctc 16.484009 loss_rnnt 9.206750 hw_loss 0.176999 lr 0.00035081 rank 0
2023-02-22 22:13:27,621 DEBUG TRAIN Batch 24/3000 loss 6.256734 loss_att 7.347268 loss_ctc 7.009005 loss_rnnt 5.926080 hw_loss 0.022957 lr 0.00035084 rank 6
2023-02-22 22:13:27,622 DEBUG TRAIN Batch 24/3000 loss 14.749626 loss_att 19.708910 loss_ctc 22.453508 loss_rnnt 12.677293 hw_loss 0.099921 lr 0.00035078 rank 3
2023-02-22 22:13:27,628 DEBUG TRAIN Batch 24/3000 loss 6.178074 loss_att 8.679075 loss_ctc 10.026657 loss_rnnt 5.132279 hw_loss 0.060845 lr 0.00035075 rank 2
2023-02-22 22:14:42,885 DEBUG TRAIN Batch 24/3100 loss 8.829600 loss_att 11.435567 loss_ctc 12.155358 loss_rnnt 7.838604 hw_loss 0.049442 lr 0.00035071 rank 5
2023-02-22 22:14:42,886 DEBUG TRAIN Batch 24/3100 loss 5.553834 loss_att 7.806800 loss_ctc 9.828036 loss_rnnt 4.441422 hw_loss 0.172360 lr 0.00035067 rank 2
2023-02-22 22:14:42,887 DEBUG TRAIN Batch 24/3100 loss 10.656614 loss_att 11.277390 loss_ctc 13.853873 loss_rnnt 10.066404 hw_loss 0.074538 lr 0.00035069 rank 7
2023-02-22 22:14:42,886 DEBUG TRAIN Batch 24/3100 loss 10.988533 loss_att 11.496458 loss_ctc 11.216991 loss_rnnt 10.818661 hw_loss 0.070922 lr 0.00035072 rank 4
2023-02-22 22:14:42,890 DEBUG TRAIN Batch 24/3100 loss 9.707193 loss_att 10.819695 loss_ctc 10.171420 loss_rnnt 9.364549 hw_loss 0.109213 lr 0.00035072 rank 0
2023-02-22 22:14:42,890 DEBUG TRAIN Batch 24/3100 loss 7.855397 loss_att 11.505130 loss_ctc 11.971619 loss_rnnt 6.543585 hw_loss 0.061942 lr 0.00035075 rank 1
2023-02-22 22:14:42,892 DEBUG TRAIN Batch 24/3100 loss 6.945433 loss_att 7.921191 loss_ctc 9.545221 loss_rnnt 6.275866 hw_loss 0.239582 lr 0.00035075 rank 6
2023-02-22 22:14:42,938 DEBUG TRAIN Batch 24/3100 loss 16.563065 loss_att 17.759991 loss_ctc 20.580338 loss_rnnt 15.689632 hw_loss 0.184516 lr 0.00035069 rank 3
2023-02-22 22:16:00,740 DEBUG TRAIN Batch 24/3200 loss 4.052527 loss_att 7.947824 loss_ctc 8.484172 loss_rnnt 2.630046 hw_loss 0.098507 lr 0.00035060 rank 7
2023-02-22 22:16:00,741 DEBUG TRAIN Batch 24/3200 loss 9.429858 loss_att 10.679884 loss_ctc 14.408649 loss_rnnt 8.466272 hw_loss 0.093265 lr 0.00035064 rank 0
2023-02-22 22:16:00,743 DEBUG TRAIN Batch 24/3200 loss 5.334325 loss_att 7.607174 loss_ctc 8.609987 loss_rnnt 4.373637 hw_loss 0.130055 lr 0.00035062 rank 5
2023-02-22 22:16:00,745 DEBUG TRAIN Batch 24/3200 loss 8.761157 loss_att 9.558453 loss_ctc 11.126922 loss_rnnt 8.230497 hw_loss 0.104558 lr 0.00035063 rank 4
2023-02-22 22:16:00,746 DEBUG TRAIN Batch 24/3200 loss 13.435978 loss_att 18.093046 loss_ctc 25.167013 loss_rnnt 10.921568 hw_loss 0.035360 lr 0.00035066 rank 6
2023-02-22 22:16:00,747 DEBUG TRAIN Batch 24/3200 loss 10.523211 loss_att 11.210142 loss_ctc 16.435598 loss_rnnt 9.550740 hw_loss 0.087685 lr 0.00035066 rank 1
2023-02-22 22:16:00,748 DEBUG TRAIN Batch 24/3200 loss 2.123085 loss_att 6.157372 loss_ctc 5.369994 loss_rnnt 0.859964 hw_loss 0.043768 lr 0.00035061 rank 3
2023-02-22 22:16:00,792 DEBUG TRAIN Batch 24/3200 loss 7.777755 loss_att 12.785314 loss_ctc 11.247017 loss_rnnt 6.291263 hw_loss 0.042025 lr 0.00035058 rank 2
2023-02-22 22:17:18,022 DEBUG TRAIN Batch 24/3300 loss 4.011056 loss_att 9.076958 loss_ctc 5.758295 loss_rnnt 2.721087 hw_loss 0.082170 lr 0.00035055 rank 0
2023-02-22 22:17:18,025 DEBUG TRAIN Batch 24/3300 loss 3.247478 loss_att 5.684715 loss_ctc 4.460743 loss_rnnt 2.547821 hw_loss 0.094576 lr 0.00035051 rank 7
2023-02-22 22:17:18,028 DEBUG TRAIN Batch 24/3300 loss 12.045765 loss_att 16.235430 loss_ctc 24.019249 loss_rnnt 9.544890 hw_loss 0.124645 lr 0.00035054 rank 5
2023-02-22 22:17:18,028 DEBUG TRAIN Batch 24/3300 loss 2.509266 loss_att 5.931715 loss_ctc 4.551080 loss_rnnt 1.524407 hw_loss 0.052739 lr 0.00035055 rank 4
2023-02-22 22:17:18,031 DEBUG TRAIN Batch 24/3300 loss 5.574611 loss_att 8.244354 loss_ctc 11.073866 loss_rnnt 4.273060 hw_loss 0.064439 lr 0.00035058 rank 1
2023-02-22 22:17:18,032 DEBUG TRAIN Batch 24/3300 loss 12.395000 loss_att 17.913103 loss_ctc 16.693680 loss_rnnt 10.688026 hw_loss 0.056620 lr 0.00035052 rank 3
2023-02-22 22:17:18,034 DEBUG TRAIN Batch 24/3300 loss 7.680582 loss_att 10.931414 loss_ctc 9.072908 loss_rnnt 6.771145 hw_loss 0.138050 lr 0.00035049 rank 2
2023-02-22 22:17:18,035 DEBUG TRAIN Batch 24/3300 loss 14.859346 loss_att 18.504232 loss_ctc 21.321501 loss_rnnt 13.253528 hw_loss 0.028540 lr 0.00035058 rank 6
2023-02-22 22:18:34,012 DEBUG TRAIN Batch 24/3400 loss 5.042654 loss_att 6.720881 loss_ctc 7.093706 loss_rnnt 4.426680 hw_loss 0.012854 lr 0.00035046 rank 0
2023-02-22 22:18:34,014 DEBUG TRAIN Batch 24/3400 loss 6.351102 loss_att 6.764130 loss_ctc 6.222725 loss_rnnt 6.262563 hw_loss 0.043219 lr 0.00035045 rank 5
2023-02-22 22:18:34,015 DEBUG TRAIN Batch 24/3400 loss 4.563796 loss_att 8.297653 loss_ctc 7.699637 loss_rnnt 3.298550 hw_loss 0.188180 lr 0.00035043 rank 7
2023-02-22 22:18:34,018 DEBUG TRAIN Batch 24/3400 loss 8.604845 loss_att 10.990883 loss_ctc 12.731004 loss_rnnt 7.552019 hw_loss 0.047746 lr 0.00035049 rank 6
2023-02-22 22:18:34,019 DEBUG TRAIN Batch 24/3400 loss 8.789784 loss_att 12.653518 loss_ctc 13.673133 loss_rnnt 7.303274 hw_loss 0.117470 lr 0.00035041 rank 2
2023-02-22 22:18:34,020 DEBUG TRAIN Batch 24/3400 loss 8.578314 loss_att 11.043920 loss_ctc 10.435126 loss_rnnt 7.784784 hw_loss 0.099062 lr 0.00035049 rank 1
2023-02-22 22:18:34,022 DEBUG TRAIN Batch 24/3400 loss 7.471531 loss_att 8.315985 loss_ctc 10.323627 loss_rnnt 6.864094 hw_loss 0.109251 lr 0.00035046 rank 4
2023-02-22 22:18:34,023 DEBUG TRAIN Batch 24/3400 loss 2.896807 loss_att 5.423864 loss_ctc 4.151467 loss_rnnt 2.215490 hw_loss 0.016157 lr 0.00035044 rank 3
2023-02-22 22:19:51,536 DEBUG TRAIN Batch 24/3500 loss 12.764341 loss_att 14.407171 loss_ctc 16.528778 loss_rnnt 11.904236 hw_loss 0.055529 lr 0.00035040 rank 6
2023-02-22 22:19:51,536 DEBUG TRAIN Batch 24/3500 loss 4.521666 loss_att 7.024958 loss_ctc 6.657457 loss_rnnt 3.661746 hw_loss 0.139667 lr 0.00035032 rank 2
2023-02-22 22:19:51,537 DEBUG TRAIN Batch 24/3500 loss 10.835222 loss_att 14.730579 loss_ctc 12.323874 loss_rnnt 9.826506 hw_loss 0.058423 lr 0.00035038 rank 4
2023-02-22 22:19:51,537 DEBUG TRAIN Batch 24/3500 loss 6.584363 loss_att 8.471810 loss_ctc 9.590258 loss_rnnt 5.782871 hw_loss 0.043530 lr 0.00035034 rank 7
2023-02-22 22:19:51,538 DEBUG TRAIN Batch 24/3500 loss 10.217271 loss_att 12.351185 loss_ctc 17.149200 loss_rnnt 8.823418 hw_loss 0.080274 lr 0.00035038 rank 0
2023-02-22 22:19:51,539 DEBUG TRAIN Batch 24/3500 loss 14.240896 loss_att 15.643806 loss_ctc 21.268103 loss_rnnt 12.981502 hw_loss 0.078474 lr 0.00035037 rank 5
2023-02-22 22:19:51,543 DEBUG TRAIN Batch 24/3500 loss 3.790544 loss_att 7.976092 loss_ctc 4.289103 loss_rnnt 2.872029 hw_loss 0.027995 lr 0.00035040 rank 1
2023-02-22 22:19:51,585 DEBUG TRAIN Batch 24/3500 loss 4.607042 loss_att 6.900945 loss_ctc 6.928035 loss_rnnt 3.825538 hw_loss 0.024858 lr 0.00035035 rank 3
2023-02-22 22:21:08,196 DEBUG TRAIN Batch 24/3600 loss 5.014831 loss_att 7.301388 loss_ctc 8.170409 loss_rnnt 4.079843 hw_loss 0.106750 lr 0.00035025 rank 7
2023-02-22 22:21:08,201 DEBUG TRAIN Batch 24/3600 loss 2.174312 loss_att 4.485229 loss_ctc 3.123862 loss_rnnt 1.535320 hw_loss 0.094130 lr 0.00035029 rank 0
2023-02-22 22:21:08,201 DEBUG TRAIN Batch 24/3600 loss 11.862713 loss_att 16.885807 loss_ctc 19.810738 loss_rnnt 9.771106 hw_loss 0.051098 lr 0.00035028 rank 5
2023-02-22 22:21:08,203 DEBUG TRAIN Batch 24/3600 loss 7.889527 loss_att 11.327606 loss_ctc 8.827159 loss_rnnt 7.006048 hw_loss 0.132836 lr 0.00035029 rank 4
2023-02-22 22:21:08,205 DEBUG TRAIN Batch 24/3600 loss 9.121132 loss_att 13.287987 loss_ctc 13.021105 loss_rnnt 7.742861 hw_loss 0.046695 lr 0.00035032 rank 1
2023-02-22 22:21:08,206 DEBUG TRAIN Batch 24/3600 loss 7.261331 loss_att 9.034260 loss_ctc 8.699636 loss_rnnt 6.657175 hw_loss 0.108369 lr 0.00035024 rank 2
2023-02-22 22:21:08,208 DEBUG TRAIN Batch 24/3600 loss 9.456337 loss_att 10.399144 loss_ctc 9.238647 loss_rnnt 9.274635 hw_loss 0.041562 lr 0.00035026 rank 3
2023-02-22 22:21:08,209 DEBUG TRAIN Batch 24/3600 loss 9.392328 loss_att 10.854445 loss_ctc 15.267657 loss_rnnt 8.300200 hw_loss 0.030616 lr 0.00035032 rank 6
2023-02-22 22:22:22,770 DEBUG TRAIN Batch 24/3700 loss 7.766512 loss_att 8.923704 loss_ctc 8.130304 loss_rnnt 7.472601 hw_loss 0.026186 lr 0.00035019 rank 5
2023-02-22 22:22:22,770 DEBUG TRAIN Batch 24/3700 loss 16.102209 loss_att 17.742022 loss_ctc 25.593988 loss_rnnt 14.455573 hw_loss 0.099569 lr 0.00035020 rank 0
2023-02-22 22:22:22,772 DEBUG TRAIN Batch 24/3700 loss 7.406047 loss_att 8.160306 loss_ctc 11.337757 loss_rnnt 6.667820 hw_loss 0.118401 lr 0.00035017 rank 7
2023-02-22 22:22:22,776 DEBUG TRAIN Batch 24/3700 loss 6.469300 loss_att 8.806494 loss_ctc 9.096539 loss_rnnt 5.606605 hw_loss 0.084296 lr 0.00035023 rank 1
2023-02-22 22:22:22,778 DEBUG TRAIN Batch 24/3700 loss 11.950339 loss_att 15.232035 loss_ctc 18.848732 loss_rnnt 10.350049 hw_loss 0.045309 lr 0.00035023 rank 6
2023-02-22 22:22:22,779 DEBUG TRAIN Batch 24/3700 loss 9.463409 loss_att 11.644332 loss_ctc 15.727867 loss_rnnt 8.148808 hw_loss 0.080918 lr 0.00035020 rank 4
2023-02-22 22:22:22,778 DEBUG TRAIN Batch 24/3700 loss 7.231323 loss_att 7.729818 loss_ctc 9.762064 loss_rnnt 6.734333 hw_loss 0.112235 lr 0.00035018 rank 3
2023-02-22 22:22:22,781 DEBUG TRAIN Batch 24/3700 loss 8.351181 loss_att 10.550976 loss_ctc 13.457338 loss_rnnt 7.171810 hw_loss 0.109859 lr 0.00035015 rank 2
2023-02-22 22:23:37,921 DEBUG TRAIN Batch 24/3800 loss 6.291893 loss_att 8.809048 loss_ctc 10.285129 loss_rnnt 5.223733 hw_loss 0.060558 lr 0.00035009 rank 3
2023-02-22 22:23:37,921 DEBUG TRAIN Batch 24/3800 loss 6.987436 loss_att 8.649188 loss_ctc 11.715818 loss_rnnt 5.988512 hw_loss 0.067730 lr 0.00035012 rank 4
2023-02-22 22:23:37,922 DEBUG TRAIN Batch 24/3800 loss 6.908449 loss_att 7.495925 loss_ctc 10.254271 loss_rnnt 6.230805 hw_loss 0.213822 lr 0.00035006 rank 2
2023-02-22 22:23:37,923 DEBUG TRAIN Batch 24/3800 loss 5.574492 loss_att 8.071259 loss_ctc 11.451593 loss_rnnt 4.275801 hw_loss 0.029481 lr 0.00035015 rank 6
2023-02-22 22:23:37,922 DEBUG TRAIN Batch 24/3800 loss 6.092695 loss_att 7.385492 loss_ctc 8.999518 loss_rnnt 5.423697 hw_loss 0.042865 lr 0.00035012 rank 0
2023-02-22 22:23:37,927 DEBUG TRAIN Batch 24/3800 loss 4.199538 loss_att 5.734322 loss_ctc 6.260373 loss_rnnt 3.569851 hw_loss 0.089910 lr 0.00035011 rank 5
2023-02-22 22:23:37,928 DEBUG TRAIN Batch 24/3800 loss 9.190413 loss_att 11.627398 loss_ctc 13.927580 loss_rnnt 8.048962 hw_loss 0.042061 lr 0.00035008 rank 7
2023-02-22 22:23:37,928 DEBUG TRAIN Batch 24/3800 loss 4.898989 loss_att 6.900784 loss_ctc 6.993582 loss_rnnt 4.166674 hw_loss 0.098768 lr 0.00035015 rank 1
2023-02-22 22:24:55,300 DEBUG TRAIN Batch 24/3900 loss 2.664114 loss_att 6.654284 loss_ctc 4.913661 loss_rnnt 1.547342 hw_loss 0.035247 lr 0.00035003 rank 0
2023-02-22 22:24:55,301 DEBUG TRAIN Batch 24/3900 loss 13.976837 loss_att 18.181675 loss_ctc 22.261808 loss_rnnt 12.030621 hw_loss 0.001100 lr 0.00034998 rank 2
2023-02-22 22:24:55,303 DEBUG TRAIN Batch 24/3900 loss 6.608768 loss_att 9.621428 loss_ctc 10.120543 loss_rnnt 5.447847 hw_loss 0.169036 lr 0.00035000 rank 7
2023-02-22 22:24:55,304 DEBUG TRAIN Batch 24/3900 loss 8.282714 loss_att 11.765081 loss_ctc 11.870687 loss_rnnt 7.107784 hw_loss 0.000113 lr 0.00035006 rank 1
2023-02-22 22:24:55,306 DEBUG TRAIN Batch 24/3900 loss 8.188020 loss_att 11.798246 loss_ctc 13.370544 loss_rnnt 6.734193 hw_loss 0.076459 lr 0.00035006 rank 6
2023-02-22 22:24:55,307 DEBUG TRAIN Batch 24/3900 loss 4.686325 loss_att 7.955259 loss_ctc 8.525434 loss_rnnt 3.462780 hw_loss 0.108519 lr 0.00035003 rank 4
2023-02-22 22:24:55,308 DEBUG TRAIN Batch 24/3900 loss 2.750187 loss_att 6.205991 loss_ctc 5.107647 loss_rnnt 1.691639 hw_loss 0.099486 lr 0.00035001 rank 3
2023-02-22 22:24:55,323 DEBUG TRAIN Batch 24/3900 loss 7.721989 loss_att 11.038218 loss_ctc 12.265545 loss_rnnt 6.428149 hw_loss 0.046475 lr 0.00035002 rank 5
2023-02-22 22:26:10,891 DEBUG TRAIN Batch 24/4000 loss 13.020250 loss_att 15.721561 loss_ctc 23.879375 loss_rnnt 11.019518 hw_loss 0.023599 lr 0.00034995 rank 4
2023-02-22 22:26:10,890 DEBUG TRAIN Batch 24/4000 loss 9.168396 loss_att 12.076107 loss_ctc 11.217995 loss_rnnt 8.267086 hw_loss 0.087166 lr 0.00034991 rank 7
2023-02-22 22:26:10,891 DEBUG TRAIN Batch 24/4000 loss 3.422532 loss_att 5.421304 loss_ctc 5.238068 loss_rnnt 2.761470 hw_loss 0.036068 lr 0.00034995 rank 0
2023-02-22 22:26:10,893 DEBUG TRAIN Batch 24/4000 loss 14.612183 loss_att 18.309113 loss_ctc 16.603367 loss_rnnt 13.562767 hw_loss 0.083508 lr 0.00034997 rank 1
2023-02-22 22:26:10,893 DEBUG TRAIN Batch 24/4000 loss 9.882149 loss_att 12.027946 loss_ctc 11.549860 loss_rnnt 9.220594 hw_loss 0.018811 lr 0.00034994 rank 5
2023-02-22 22:26:10,898 DEBUG TRAIN Batch 24/4000 loss 22.920168 loss_att 28.905138 loss_ctc 37.377670 loss_rnnt 19.740887 hw_loss 0.102408 lr 0.00034989 rank 2
2023-02-22 22:26:10,900 DEBUG TRAIN Batch 24/4000 loss 12.258965 loss_att 17.293003 loss_ctc 16.811508 loss_rnnt 10.601275 hw_loss 0.082270 lr 0.00034992 rank 3
2023-02-22 22:26:10,946 DEBUG TRAIN Batch 24/4000 loss 5.001801 loss_att 7.072936 loss_ctc 5.765441 loss_rnnt 4.450669 hw_loss 0.065787 lr 0.00034997 rank 6
2023-02-22 22:27:26,119 DEBUG TRAIN Batch 24/4100 loss 9.914002 loss_att 14.292208 loss_ctc 12.009413 loss_rnnt 8.745502 hw_loss 0.025261 lr 0.00034985 rank 5
2023-02-22 22:27:26,124 DEBUG TRAIN Batch 24/4100 loss 14.732646 loss_att 17.643280 loss_ctc 20.428051 loss_rnnt 13.339584 hw_loss 0.096652 lr 0.00034986 rank 4
2023-02-22 22:27:26,124 DEBUG TRAIN Batch 24/4100 loss 7.559802 loss_att 9.902002 loss_ctc 10.133547 loss_rnnt 6.719132 hw_loss 0.054492 lr 0.00034983 rank 7
2023-02-22 22:27:26,125 DEBUG TRAIN Batch 24/4100 loss 5.203618 loss_att 7.955934 loss_ctc 8.296183 loss_rnnt 4.135734 hw_loss 0.197023 lr 0.00034981 rank 2
2023-02-22 22:27:26,127 DEBUG TRAIN Batch 24/4100 loss 9.122924 loss_att 13.024510 loss_ctc 13.953050 loss_rnnt 7.652298 hw_loss 0.086796 lr 0.00034989 rank 6
2023-02-22 22:27:26,127 DEBUG TRAIN Batch 24/4100 loss 9.735744 loss_att 14.468060 loss_ctc 21.402920 loss_rnnt 7.215158 hw_loss 0.034685 lr 0.00034986 rank 0
2023-02-22 22:27:26,128 DEBUG TRAIN Batch 24/4100 loss 11.071589 loss_att 12.833385 loss_ctc 17.575094 loss_rnnt 9.831135 hw_loss 0.039304 lr 0.00034983 rank 3
2023-02-22 22:27:26,129 DEBUG TRAIN Batch 24/4100 loss 15.713236 loss_att 16.762791 loss_ctc 17.707296 loss_rnnt 15.225977 hw_loss 0.021510 lr 0.00034989 rank 1
2023-02-22 22:28:41,480 DEBUG TRAIN Batch 24/4200 loss 4.106552 loss_att 6.602983 loss_ctc 4.465180 loss_rnnt 3.524760 hw_loss 0.065042 lr 0.00034974 rank 7
2023-02-22 22:28:41,484 DEBUG TRAIN Batch 24/4200 loss 6.757632 loss_att 13.831686 loss_ctc 10.283266 loss_rnnt 4.864997 hw_loss 0.014512 lr 0.00034978 rank 0
2023-02-22 22:28:41,486 DEBUG TRAIN Batch 24/4200 loss 4.954068 loss_att 8.512657 loss_ctc 9.904362 loss_rnnt 3.535697 hw_loss 0.087400 lr 0.00034972 rank 2
2023-02-22 22:28:41,486 DEBUG TRAIN Batch 24/4200 loss 7.004239 loss_att 10.572541 loss_ctc 9.050554 loss_rnnt 5.933337 hw_loss 0.158249 lr 0.00034976 rank 5
2023-02-22 22:28:41,488 DEBUG TRAIN Batch 24/4200 loss 10.378932 loss_att 13.887001 loss_ctc 15.646079 loss_rnnt 8.956205 hw_loss 0.035298 lr 0.00034980 rank 6
2023-02-22 22:28:41,488 DEBUG TRAIN Batch 24/4200 loss 6.074080 loss_att 8.599461 loss_ctc 7.412955 loss_rnnt 5.377699 hw_loss 0.023976 lr 0.00034978 rank 4
2023-02-22 22:28:41,506 DEBUG TRAIN Batch 24/4200 loss 13.572918 loss_att 18.041071 loss_ctc 19.684444 loss_rnnt 11.815516 hw_loss 0.091689 lr 0.00034975 rank 3
2023-02-22 22:28:41,514 DEBUG TRAIN Batch 24/4200 loss 12.458962 loss_att 14.132416 loss_ctc 18.809433 loss_rnnt 11.263452 hw_loss 0.026418 lr 0.00034980 rank 1
2023-02-22 22:29:59,181 DEBUG TRAIN Batch 24/4300 loss 6.141831 loss_att 8.661127 loss_ctc 8.783470 loss_rnnt 5.260811 hw_loss 0.046768 lr 0.00034965 rank 7
2023-02-22 22:29:59,181 DEBUG TRAIN Batch 24/4300 loss 5.915446 loss_att 8.608332 loss_ctc 11.867508 loss_rnnt 4.557532 hw_loss 0.048240 lr 0.00034969 rank 4
2023-02-22 22:29:59,181 DEBUG TRAIN Batch 24/4300 loss 9.911439 loss_att 13.151890 loss_ctc 12.547323 loss_rnnt 8.871445 hw_loss 0.075847 lr 0.00034969 rank 0
2023-02-22 22:29:59,182 DEBUG TRAIN Batch 24/4300 loss 11.196975 loss_att 14.134198 loss_ctc 14.359149 loss_rnnt 10.160402 hw_loss 0.051573 lr 0.00034968 rank 5
2023-02-22 22:29:59,186 DEBUG TRAIN Batch 24/4300 loss 9.984801 loss_att 12.731687 loss_ctc 10.842366 loss_rnnt 9.309721 hw_loss 0.021303 lr 0.00034966 rank 3
2023-02-22 22:29:59,188 DEBUG TRAIN Batch 24/4300 loss 9.844097 loss_att 14.567009 loss_ctc 18.061100 loss_rnnt 7.781240 hw_loss 0.042516 lr 0.00034972 rank 1
2023-02-22 22:29:59,188 DEBUG TRAIN Batch 24/4300 loss 8.065491 loss_att 10.377392 loss_ctc 9.675426 loss_rnnt 7.333755 hw_loss 0.102558 lr 0.00034972 rank 6
2023-02-22 22:29:59,190 DEBUG TRAIN Batch 24/4300 loss 11.187539 loss_att 13.735602 loss_ctc 13.560337 loss_rnnt 10.295456 hw_loss 0.123931 lr 0.00034964 rank 2
2023-02-22 22:31:14,310 DEBUG TRAIN Batch 24/4400 loss 6.332940 loss_att 11.793770 loss_ctc 14.742891 loss_rnnt 4.045158 hw_loss 0.139291 lr 0.00034957 rank 7
2023-02-22 22:31:14,311 DEBUG TRAIN Batch 24/4400 loss 7.775518 loss_att 7.641246 loss_ctc 8.399445 loss_rnnt 7.620860 hw_loss 0.184355 lr 0.00034955 rank 2
2023-02-22 22:31:14,313 DEBUG TRAIN Batch 24/4400 loss 15.571347 loss_att 17.523705 loss_ctc 20.026028 loss_rnnt 14.545771 hw_loss 0.077149 lr 0.00034961 rank 0
2023-02-22 22:31:14,314 DEBUG TRAIN Batch 24/4400 loss 12.612925 loss_att 16.024752 loss_ctc 18.556755 loss_rnnt 11.093651 hw_loss 0.083247 lr 0.00034959 rank 5
2023-02-22 22:31:14,316 DEBUG TRAIN Batch 24/4400 loss 8.792966 loss_att 9.889594 loss_ctc 10.945473 loss_rnnt 8.235575 hw_loss 0.095747 lr 0.00034963 rank 6
2023-02-22 22:31:14,316 DEBUG TRAIN Batch 24/4400 loss 5.173234 loss_att 6.686122 loss_ctc 8.777346 loss_rnnt 4.389710 hw_loss 0.000746 lr 0.00034963 rank 1
2023-02-22 22:31:14,316 DEBUG TRAIN Batch 24/4400 loss 7.997011 loss_att 9.834057 loss_ctc 12.731616 loss_rnnt 6.946002 hw_loss 0.098098 lr 0.00034960 rank 4
2023-02-22 22:31:14,365 DEBUG TRAIN Batch 24/4400 loss 6.075216 loss_att 8.295801 loss_ctc 8.967883 loss_rnnt 5.234221 hw_loss 0.020980 lr 0.00034958 rank 3
2023-02-22 22:32:31,279 DEBUG TRAIN Batch 24/4500 loss 10.626812 loss_att 13.515123 loss_ctc 12.702201 loss_rnnt 9.685472 hw_loss 0.163051 lr 0.00034952 rank 4
2023-02-22 22:32:31,279 DEBUG TRAIN Batch 24/4500 loss 10.109733 loss_att 11.604727 loss_ctc 13.174316 loss_rnnt 9.348964 hw_loss 0.099674 lr 0.00034952 rank 0
2023-02-22 22:32:31,279 DEBUG TRAIN Batch 24/4500 loss 5.461532 loss_att 10.496994 loss_ctc 8.186708 loss_rnnt 4.091035 hw_loss 0.000089 lr 0.00034948 rank 7
2023-02-22 22:32:31,281 DEBUG TRAIN Batch 24/4500 loss 12.049303 loss_att 11.386568 loss_ctc 15.608892 loss_rnnt 11.656099 hw_loss 0.095885 lr 0.00034951 rank 5
2023-02-22 22:32:31,283 DEBUG TRAIN Batch 24/4500 loss 10.009976 loss_att 12.085299 loss_ctc 15.234026 loss_rnnt 8.863533 hw_loss 0.065325 lr 0.00034949 rank 3
2023-02-22 22:32:31,284 DEBUG TRAIN Batch 24/4500 loss 8.682135 loss_att 9.284200 loss_ctc 15.777628 loss_rnnt 7.610389 hw_loss 0.009879 lr 0.00034947 rank 2
2023-02-22 22:32:31,285 DEBUG TRAIN Batch 24/4500 loss 6.758002 loss_att 10.854390 loss_ctc 11.141352 loss_rnnt 5.322301 hw_loss 0.059956 lr 0.00034955 rank 6
2023-02-22 22:32:31,326 DEBUG TRAIN Batch 24/4500 loss 11.504787 loss_att 12.906392 loss_ctc 14.774455 loss_rnnt 10.726308 hw_loss 0.116629 lr 0.00034955 rank 1
2023-02-22 22:33:48,781 DEBUG TRAIN Batch 24/4600 loss 9.662928 loss_att 12.001300 loss_ctc 13.985260 loss_rnnt 8.603191 hw_loss 0.029534 lr 0.00034940 rank 7
2023-02-22 22:33:48,783 DEBUG TRAIN Batch 24/4600 loss 8.947502 loss_att 12.241495 loss_ctc 11.590860 loss_rnnt 7.872969 hw_loss 0.118663 lr 0.00034946 rank 1
2023-02-22 22:33:48,785 DEBUG TRAIN Batch 24/4600 loss 12.399322 loss_att 17.486618 loss_ctc 20.853502 loss_rnnt 10.169487 hw_loss 0.159659 lr 0.00034946 rank 6
2023-02-22 22:33:48,786 DEBUG TRAIN Batch 24/4600 loss 7.208874 loss_att 9.006285 loss_ctc 10.212804 loss_rnnt 6.380161 hw_loss 0.128825 lr 0.00034942 rank 5
2023-02-22 22:33:48,786 DEBUG TRAIN Batch 24/4600 loss 1.930721 loss_att 6.121885 loss_ctc 3.255032 loss_rnnt 0.831829 hw_loss 0.157659 lr 0.00034943 rank 4
2023-02-22 22:33:48,788 DEBUG TRAIN Batch 24/4600 loss 3.756980 loss_att 7.831543 loss_ctc 7.365018 loss_rnnt 2.421462 hw_loss 0.074126 lr 0.00034938 rank 2
2023-02-22 22:33:48,790 DEBUG TRAIN Batch 24/4600 loss 7.013082 loss_att 11.592460 loss_ctc 12.042564 loss_rnnt 5.422469 hw_loss 0.007760 lr 0.00034943 rank 0
2023-02-22 22:33:48,790 DEBUG TRAIN Batch 24/4600 loss 9.205928 loss_att 12.002418 loss_ctc 16.373711 loss_rnnt 7.622276 hw_loss 0.128718 lr 0.00034941 rank 3
2023-02-22 22:35:03,284 DEBUG TRAIN Batch 24/4700 loss 8.210895 loss_att 12.632939 loss_ctc 9.809198 loss_rnnt 7.091444 hw_loss 0.041127 lr 0.00034935 rank 4
2023-02-22 22:35:03,285 DEBUG TRAIN Batch 24/4700 loss 3.040933 loss_att 6.922649 loss_ctc 4.454116 loss_rnnt 2.026936 hw_loss 0.092304 lr 0.00034935 rank 0
2023-02-22 22:35:03,287 DEBUG TRAIN Batch 24/4700 loss 12.901395 loss_att 17.364544 loss_ctc 14.859365 loss_rnnt 11.687751 hw_loss 0.112409 lr 0.00034931 rank 7
2023-02-22 22:35:03,287 DEBUG TRAIN Batch 24/4700 loss 10.033089 loss_att 10.591711 loss_ctc 12.163760 loss_rnnt 9.601402 hw_loss 0.067261 lr 0.00034934 rank 5
2023-02-22 22:35:03,290 DEBUG TRAIN Batch 24/4700 loss 4.926764 loss_att 8.680411 loss_ctc 8.431047 loss_rnnt 3.698823 hw_loss 0.018699 lr 0.00034938 rank 1
2023-02-22 22:35:03,292 DEBUG TRAIN Batch 24/4700 loss 9.225343 loss_att 11.875850 loss_ctc 16.027096 loss_rnnt 7.778340 hw_loss 0.018749 lr 0.00034932 rank 3
2023-02-22 22:35:03,295 DEBUG TRAIN Batch 24/4700 loss 3.659223 loss_att 6.163987 loss_ctc 5.786397 loss_rnnt 2.833747 hw_loss 0.076687 lr 0.00034930 rank 2
2023-02-22 22:35:03,295 DEBUG TRAIN Batch 24/4700 loss 6.100601 loss_att 8.259370 loss_ctc 10.554416 loss_rnnt 5.050178 hw_loss 0.046551 lr 0.00034938 rank 6
2023-02-22 22:36:16,906 DEBUG TRAIN Batch 24/4800 loss 15.062000 loss_att 17.719170 loss_ctc 19.268366 loss_rnnt 13.860306 hw_loss 0.205146 lr 0.00034926 rank 4
2023-02-22 22:36:16,906 DEBUG TRAIN Batch 24/4800 loss 8.164177 loss_att 10.805282 loss_ctc 10.056982 loss_rnnt 7.299565 hw_loss 0.157532 lr 0.00034924 rank 3
2023-02-22 22:36:16,908 DEBUG TRAIN Batch 24/4800 loss 20.655355 loss_att 27.121618 loss_ctc 28.943466 loss_rnnt 18.209362 hw_loss 0.089360 lr 0.00034929 rank 1
2023-02-22 22:36:16,908 DEBUG TRAIN Batch 24/4800 loss 9.330032 loss_att 12.197073 loss_ctc 13.455892 loss_rnnt 8.149120 hw_loss 0.107605 lr 0.00034925 rank 5
2023-02-22 22:36:16,910 DEBUG TRAIN Batch 24/4800 loss 12.678567 loss_att 16.491663 loss_ctc 23.086033 loss_rnnt 10.474856 hw_loss 0.100181 lr 0.00034926 rank 0
2023-02-22 22:36:16,910 DEBUG TRAIN Batch 24/4800 loss 3.647091 loss_att 7.179634 loss_ctc 4.999941 loss_rnnt 2.729908 hw_loss 0.056802 lr 0.00034923 rank 7
2023-02-22 22:36:16,911 DEBUG TRAIN Batch 24/4800 loss 7.162390 loss_att 10.910826 loss_ctc 8.068398 loss_rnnt 6.256437 hw_loss 0.066496 lr 0.00034929 rank 6
2023-02-22 22:36:16,917 DEBUG TRAIN Batch 24/4800 loss 13.043490 loss_att 16.248009 loss_ctc 17.016611 loss_rnnt 11.842806 hw_loss 0.056308 lr 0.00034921 rank 2
run_2_21_rnnt_bias_0-3word_finetune.sh: line 167: 22264 Terminated              python wenet/bin/train.py --gpu $gpu_id --config $train_config --data_type raw --symbol_table $dict --bpe_model ${bpemodel}.model --train_data $wave_data/$train_set/data.list --cv_data $wave_data/$dev_set/data.list ${checkpoint:+--checkpoint $checkpoint} --model_dir $dir --ddp.init_method $init_method --ddp.world_size $num_gpus --ddp.rank $i --ddp.dist_backend $dist_backend --num_workers 1 $cmvn_opts --pin_memory
Traceback (most recent call last):
  File "wenet/bin/train.py", line 297, in <module>
    main()
  File "wenet/bin/train.py", line 269, in main
    executor.train(model, optimizer, scheduler, train_data_loader, device,
  File "/home/work_nfs6/tyxu/workspace/wenet-bias-celoss/wenet/utils/executor.py", line 97, in train
    loss_dict = model(feats, feats_lengths, target,
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 878, in forward
    self._sync_params()
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1370, in _sync_params
    authoritative_rank = self._find_common_rank(
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1352, in _find_common_rank
    dist.all_reduce(rank_to_use, op=ReduceOp.MAX, group=self.process_group)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 1292, in all_reduce
    work.wait()
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272172048/work/third_party/gloo/gloo/transport/tcp/pair.cc:589] Read error [127.0.0.1]:17574: Connection reset by peer
Traceback (most recent call last):
  File "wenet/bin/train.py", line 297, in <module>
    main()
  File "wenet/bin/train.py", line 269, in main
    executor.train(model, optimizer, scheduler, train_data_loader, device,
  File "/home/work_nfs6/tyxu/workspace/wenet-bias-celoss/wenet/utils/executor.py", line 97, in train
    loss_dict = model(feats, feats_lengths, target,
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 878, in forward
    self._sync_params()
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1370, in _sync_params
    authoritative_rank = self._find_common_rank(
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1352, in _find_common_rank
    dist.all_reduce(rank_to_use, op=ReduceOp.MAX, group=self.process_group)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 1292, in all_reduce
    work.wait()
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272172048/work/third_party/gloo/gloo/transport/tcp/pair.cc:589] Read error [127.0.0.1]:59618: Connection reset by peer
Traceback (most recent call last):
  File "wenet/bin/train.py", line 297, in <module>
    main()
  File "wenet/bin/train.py", line 269, in main
    executor.train(model, optimizer, scheduler, train_data_loader, device,
  File "/home/work_nfs6/tyxu/workspace/wenet-bias-celoss/wenet/utils/executor.py", line 97, in train
    loss_dict = model(feats, feats_lengths, target,
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 878, in forward
    self._sync_params()
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1370, in _sync_params
    authoritative_rank = self._find_common_rank(
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1352, in _find_common_rank
    dist.all_reduce(rank_to_use, op=ReduceOp.MAX, group=self.process_group)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 1292, in all_reduce
    work.wait()
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272172048/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [127.0.1.1]:25519
Traceback (most recent call last):
  File "wenet/bin/train.py", line 297, in <module>
    main()
  File "wenet/bin/train.py", line 269, in main
    executor.train(model, optimizer, scheduler, train_data_loader, device,
  File "/home/work_nfs6/tyxu/workspace/wenet-bias-celoss/wenet/utils/executor.py", line 97, in train
    loss_dict = model(feats, feats_lengths, target,
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 878, in forward
    self._sync_params()
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1370, in _sync_params
    authoritative_rank = self._find_common_rank(
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1352, in _find_common_rank
    dist.all_reduce(rank_to_use, op=ReduceOp.MAX, group=self.process_group)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 1292, in all_reduce
    work.wait()
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272172048/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [127.0.0.1]:26296
Traceback (most recent call last):
  File "wenet/bin/train.py", line 297, in <module>
    main()
  File "wenet/bin/train.py", line 269, in main
    executor.train(model, optimizer, scheduler, train_data_loader, device,
  File "/home/work_nfs6/tyxu/workspace/wenet-bias-celoss/wenet/utils/executor.py", line 97, in train
    loss_dict = model(feats, feats_lengths, target,
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 878, in forward
    self._sync_params()
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1370, in _sync_params
    authoritative_rank = self._find_common_rank(
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1352, in _find_common_rank
    dist.all_reduce(rank_to_use, op=ReduceOp.MAX, group=self.process_group)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 1292, in all_reduce
    work.wait()
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272172048/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [127.0.1.1]:9603
Traceback (most recent call last):
  File "wenet/bin/train.py", line 297, in <module>
    main()
  File "wenet/bin/train.py", line 269, in main
    executor.train(model, optimizer, scheduler, train_data_loader, device,
  File "/home/work_nfs6/tyxu/workspace/wenet-bias-celoss/wenet/utils/executor.py", line 97, in train
    loss_dict = model(feats, feats_lengths, target,
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 878, in forward
    self._sync_params()
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1370, in _sync_params
    authoritative_rank = self._find_common_rank(
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1352, in _find_common_rank
    dist.all_reduce(rank_to_use, op=ReduceOp.MAX, group=self.process_group)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 1292, in all_reduce
    work.wait()
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272172048/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [127.0.0.1]:9426
Traceback (most recent call last):
  File "wenet/bin/train.py", line 297, in <module>
    main()
  File "wenet/bin/train.py", line 269, in main
    executor.train(model, optimizer, scheduler, train_data_loader, device,
  File "/home/work_nfs6/tyxu/workspace/wenet-bias-celoss/wenet/utils/executor.py", line 97, in train
    loss_dict = model(feats, feats_lengths, target,
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 878, in forward
    self._sync_params()
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1370, in _sync_params
    authoritative_rank = self._find_common_rank(
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1352, in _find_common_rank
    dist.all_reduce(rank_to_use, op=ReduceOp.MAX, group=self.process_group)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 1292, in all_reduce
    work.wait()
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272172048/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [127.0.1.1]:19346
