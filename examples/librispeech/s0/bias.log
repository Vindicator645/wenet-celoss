/home/work_nfs5_ssd/kxhuang/wenet-encoder_decoder_bias/examples/librispeech/s0/data/lang_char/train_960_unigram5000
dictionary: /home/work_nfs5_ssd/kxhuang/wenet-encoder_decoder_bias/examples/librispeech/s0/data/lang_char/train_960_unigram5000_units.txt
run_encoder_decoder_bias.sh: init method is file:///home/work_nfs6/tyxu/workspace/wenet-rnnt-runtime/examples/librispeech/s0/exp/1202_encoder_bias_30_0.1/ddp_init
2022-12-03 11:23:30,818 INFO training on multiple gpus, this gpu 1
2022-12-03 11:23:30,819 INFO training on multiple gpus, this gpu 7
2022-12-03 11:23:30,819 INFO training on multiple gpus, this gpu 6
2022-12-03 11:23:30,820 INFO training on multiple gpus, this gpu 5
2022-12-03 11:23:30,820 INFO training on multiple gpus, this gpu 3
2022-12-03 11:23:30,821 INFO training on multiple gpus, this gpu 0
2022-12-03 11:23:30,824 INFO training on multiple gpus, this gpu 2
2022-12-03 11:23:30,824 INFO training on multiple gpus, this gpu 4
2022-12-03 11:24:06,325 INFO Added key: store_based_barrier_key:1 to store for rank: 0
2022-12-03 11:24:06,336 INFO Added key: store_based_barrier_key:1 to store for rank: 1
2022-12-03 11:24:06,346 INFO Added key: store_based_barrier_key:1 to store for rank: 2
2022-12-03 11:24:07,335 INFO Added key: store_based_barrier_key:1 to store for rank: 4
2022-12-03 11:24:07,401 INFO Added key: store_based_barrier_key:1 to store for rank: 7
2022-12-03 11:24:08,423 INFO Added key: store_based_barrier_key:1 to store for rank: 5
2022-12-03 11:24:09,354 INFO Added key: store_based_barrier_key:1 to store for rank: 6
2022-12-03 11:24:16,337 INFO Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=8, worker_count=7, timeout=0:30:00)
2022-12-03 11:24:16,340 INFO Waiting in store based barrier to initialize process group for rank: 1, key: store_based_barrier_key:1 (world_size=8, worker_count=7, timeout=0:30:00)
2022-12-03 11:24:17,295 INFO Waiting in store based barrier to initialize process group for rank: 2, key: store_based_barrier_key:1 (world_size=8, worker_count=7, timeout=0:30:00)
2022-12-03 11:24:18,308 INFO Waiting in store based barrier to initialize process group for rank: 7, key: store_based_barrier_key:1 (world_size=8, worker_count=7, timeout=0:30:00)
2022-12-03 11:24:18,367 INFO Waiting in store based barrier to initialize process group for rank: 4, key: store_based_barrier_key:1 (world_size=8, worker_count=7, timeout=0:30:00)
2022-12-03 11:24:19,076 INFO Waiting in store based barrier to initialize process group for rank: 5, key: store_based_barrier_key:1 (world_size=8, worker_count=7, timeout=0:30:00)
2022-12-03 11:24:20,452 INFO Waiting in store based barrier to initialize process group for rank: 6, key: store_based_barrier_key:1 (world_size=8, worker_count=7, timeout=0:30:00)
2022-12-03 11:24:21,710 INFO Added key: store_based_barrier_key:1 to store for rank: 3
2022-12-03 11:24:21,711 INFO Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2022-12-03 11:24:21,711 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2022-12-03 11:24:22,050 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2022-12-03 11:24:22,401 INFO Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2022-12-03 11:24:22,497 INFO Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2022-12-03 11:24:23,650 INFO Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2022-12-03 11:24:24,737 INFO Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2022-12-03 11:24:28,867 INFO Waiting in store based barrier to initialize process group for rank: 1, key: store_based_barrier_key:1 (world_size=8, worker_count=8, timeout=0:30:00)
2022-12-03 11:24:28,867 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2022-12-03 11:24:54,388 INFO Epoch 0 TRAIN info lr 4e-08
2022-12-03 11:24:54,389 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, num_layers=2, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 59680552
2022-12-03 11:24:54,513 INFO Checkpoint: save to checkpoint exp/1202_encoder_bias_30_0.1/init.pt
2022-12-03 11:24:54,542 INFO Epoch 0 TRAIN info lr 4e-08
2022-12-03 11:24:54,545 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, num_layers=2, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 59680552
2022-12-03 11:24:54,632 INFO Epoch 0 TRAIN info lr 4e-08
2022-12-03 11:24:54,634 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, num_layers=2, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 59680552
2022-12-03 11:24:54,654 INFO Epoch 0 TRAIN info lr 4e-08
2022-12-03 11:24:54,656 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 11:24:54,661 INFO Epoch 0 TRAIN info lr 4e-08
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, num_layers=2, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 59680552
2022-12-03 11:24:54,663 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, num_layers=2, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 59680552
2022-12-03 11:24:54,675 INFO Epoch 0 TRAIN info lr 4e-08
2022-12-03 11:24:54,678 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, num_layers=2, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 59680552
2022-12-03 11:24:54,717 INFO Epoch 0 TRAIN info lr 4e-08
2022-12-03 11:24:54,719 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, num_layers=2, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 59680552
2022-12-03 11:24:55,204 INFO Epoch 0 TRAIN info lr 4e-08
2022-12-03 11:24:55,208 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, num_layers=2, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 59680552
2022-12-03 11:27:00,198 DEBUG TRAIN Batch 0/0 loss 507.976257 loss_att 71.040054 loss_ctc 489.222351 loss_rnnt 597.864014 lr 0.00000004 rank 0
2022-12-03 11:27:00,205 DEBUG TRAIN Batch 0/0 loss 580.521851 loss_att 73.008698 loss_ctc 557.380432 loss_rnnt 685.110046 lr 0.00000004 rank 6
2022-12-03 11:27:00,213 DEBUG TRAIN Batch 0/0 loss 543.945435 loss_att 77.232712 loss_ctc 520.921204 loss_rnnt 640.357910 lr 0.00000004 rank 7
2022-12-03 11:27:00,218 DEBUG TRAIN Batch 0/0 loss 507.487640 loss_att 71.244873 loss_ctc 481.963013 loss_rnnt 598.139465 lr 0.00000004 rank 5
2022-12-03 11:27:00,224 DEBUG TRAIN Batch 0/0 loss 538.047424 loss_att 69.197868 loss_ctc 515.765625 loss_rnnt 634.788208 lr 0.00000004 rank 4
2022-12-03 11:27:00,229 DEBUG TRAIN Batch 0/0 loss 525.388000 loss_att 74.099602 loss_ctc 500.325104 loss_rnnt 618.987427 lr 0.00000004 rank 3
2022-12-03 11:27:00,275 DEBUG TRAIN Batch 0/0 loss 532.819641 loss_att 72.744553 loss_ctc 500.616974 loss_rnnt 629.128357 lr 0.00000004 rank 2
2022-12-03 11:27:00,290 DEBUG TRAIN Batch 0/0 loss 629.014160 loss_att 82.445015 loss_ctc 604.190918 loss_rnnt 741.637756 lr 0.00000004 rank 1
2022-12-03 11:28:15,319 DEBUG TRAIN Batch 0/100 loss 2000.048584 loss_att 366.113464 loss_ctc 3021.726318 loss_rnnt 2190.612061 lr 0.00000404 rank 6
2022-12-03 11:28:15,320 DEBUG TRAIN Batch 0/100 loss 2020.944336 loss_att 355.974762 loss_ctc 3124.770996 loss_rnnt 2206.761475 lr 0.00000404 rank 0
2022-12-03 11:28:15,323 DEBUG TRAIN Batch 0/100 loss 2021.243652 loss_att 435.874451 loss_ctc 3050.189453 loss_rnnt 2201.124756 lr 0.00000404 rank 5
2022-12-03 11:28:15,324 DEBUG TRAIN Batch 0/100 loss 2055.080078 loss_att 373.677826 loss_ctc 3082.115234 loss_rnnt 2254.422607 lr 0.00000404 rank 7
2022-12-03 11:28:15,325 DEBUG TRAIN Batch 0/100 loss 1957.651245 loss_att 313.197266 loss_ctc 3141.115723 loss_rnnt 2128.746826 lr 0.00000404 rank 2
2022-12-03 11:28:15,328 DEBUG TRAIN Batch 0/100 loss 2019.104858 loss_att 386.985901 loss_ctc 3055.276123 loss_rnnt 2207.372559 lr 0.00000404 rank 4
2022-12-03 11:28:15,329 DEBUG TRAIN Batch 0/100 loss 2002.029297 loss_att 409.424774 loss_ctc 3064.962891 loss_rnnt 2178.825684 lr 0.00000404 rank 1
2022-12-03 11:28:15,374 DEBUG TRAIN Batch 0/100 loss 2106.954346 loss_att 424.080231 loss_ctc 3175.472656 loss_rnnt 2301.060303 lr 0.00000404 rank 3
2022-12-03 11:29:28,055 DEBUG TRAIN Batch 0/200 loss 779.264038 loss_att 364.154297 loss_ctc 2805.574219 loss_rnnt 592.111267 lr 0.00000804 rank 1
2022-12-03 11:29:28,061 DEBUG TRAIN Batch 0/200 loss 769.271973 loss_att 348.962219 loss_ctc 2757.513672 loss_rnnt 588.235046 lr 0.00000804 rank 6
2022-12-03 11:29:28,064 DEBUG TRAIN Batch 0/200 loss 772.726929 loss_att 323.297180 loss_ctc 2850.552246 loss_rnnt 585.569519 lr 0.00000804 rank 7
2022-12-03 11:29:28,069 DEBUG TRAIN Batch 0/200 loss 753.611328 loss_att 348.045624 loss_ctc 2684.461670 loss_rnnt 577.277771 lr 0.00000804 rank 5
2022-12-03 11:29:28,069 DEBUG TRAIN Batch 0/200 loss 785.607178 loss_att 384.516602 loss_ctc 2705.351807 loss_rnnt 609.859375 lr 0.00000804 rank 3
2022-12-03 11:29:28,073 DEBUG TRAIN Batch 0/200 loss 754.500793 loss_att 366.439087 loss_ctc 2468.079834 loss_rnnt 603.635925 lr 0.00000804 rank 2
2022-12-03 11:29:28,074 DEBUG TRAIN Batch 0/200 loss 805.793762 loss_att 384.801849 loss_ctc 2766.186279 loss_rnnt 628.606445 lr 0.00000804 rank 4
2022-12-03 11:29:28,077 DEBUG TRAIN Batch 0/200 loss 795.019043 loss_att 376.223999 loss_ctc 2776.784912 loss_rnnt 614.542603 lr 0.00000804 rank 0
2022-12-03 11:30:41,504 DEBUG TRAIN Batch 0/300 loss 381.112671 loss_att 331.772247 loss_ctc 600.445312 loss_rnnt 361.736420 lr 0.00001204 rank 6
2022-12-03 11:30:41,515 DEBUG TRAIN Batch 0/300 loss 400.786530 loss_att 355.693604 loss_ctc 616.030762 loss_rnnt 381.105865 lr 0.00001204 rank 1
2022-12-03 11:30:41,517 DEBUG TRAIN Batch 0/300 loss 391.507568 loss_att 345.725159 loss_ctc 624.121826 loss_rnnt 369.648834 lr 0.00001204 rank 0
2022-12-03 11:30:41,518 DEBUG TRAIN Batch 0/300 loss 419.403168 loss_att 375.504456 loss_ctc 638.391724 loss_rnnt 398.984406 lr 0.00001204 rank 2
2022-12-03 11:30:41,520 DEBUG TRAIN Batch 0/300 loss 359.156067 loss_att 310.486115 loss_ctc 592.168823 loss_rnnt 337.821716 lr 0.00001204 rank 5
2022-12-03 11:30:41,521 DEBUG TRAIN Batch 0/300 loss 394.008301 loss_att 348.176941 loss_ctc 606.221191 loss_rnnt 374.879517 lr 0.00001204 rank 3
2022-12-03 11:30:41,554 DEBUG TRAIN Batch 0/300 loss 437.683411 loss_att 389.144043 loss_ctc 639.839355 loss_rnnt 420.437134 lr 0.00001204 rank 4
2022-12-03 11:30:41,563 DEBUG TRAIN Batch 0/300 loss 431.566193 loss_att 384.453888 loss_ctc 642.539307 loss_rnnt 412.858887 lr 0.00001204 rank 7
2022-12-03 11:32:48,787 DEBUG TRAIN Batch 0/400 loss 309.130737 loss_att 282.867371 loss_ctc 347.638611 loss_rnnt 309.249023 lr 0.00001604 rank 0
2022-12-03 11:32:48,789 DEBUG TRAIN Batch 0/400 loss 317.783630 loss_att 299.225098 loss_ctc 355.339935 loss_rnnt 316.487854 lr 0.00001604 rank 1
2022-12-03 11:32:48,792 DEBUG TRAIN Batch 0/400 loss 318.108398 loss_att 293.766418 loss_ctc 357.590332 loss_rnnt 317.712524 lr 0.00001604 rank 2
2022-12-03 11:32:48,793 DEBUG TRAIN Batch 0/400 loss 315.014069 loss_att 293.434174 loss_ctc 349.578308 loss_rnnt 314.721466 lr 0.00001604 rank 5
2022-12-03 11:32:48,793 DEBUG TRAIN Batch 0/400 loss 315.827515 loss_att 291.486511 loss_ctc 355.005524 loss_rnnt 315.471954 lr 0.00001604 rank 6
2022-12-03 11:32:48,798 DEBUG TRAIN Batch 0/400 loss 328.951904 loss_att 301.425629 loss_ctc 367.889008 loss_rnnt 329.265564 lr 0.00001604 rank 7
2022-12-03 11:32:48,798 DEBUG TRAIN Batch 0/400 loss 322.205627 loss_att 299.008881 loss_ctc 359.855438 loss_rnnt 321.825043 lr 0.00001604 rank 3
2022-12-03 11:32:48,801 DEBUG TRAIN Batch 0/400 loss 308.851624 loss_att 284.638977 loss_ctc 346.099640 loss_rnnt 308.727783 lr 0.00001604 rank 4
2022-12-03 11:34:01,837 DEBUG TRAIN Batch 0/500 loss 265.637054 loss_att 239.368912 loss_ctc 279.795227 loss_rnnt 269.002930 lr 0.00002004 rank 1
2022-12-03 11:34:01,839 DEBUG TRAIN Batch 0/500 loss 252.561768 loss_att 226.355545 loss_ctc 270.523926 loss_rnnt 255.408035 lr 0.00002004 rank 5
2022-12-03 11:34:01,842 DEBUG TRAIN Batch 0/500 loss 265.800385 loss_att 235.913513 loss_ctc 282.125549 loss_rnnt 269.601074 lr 0.00002004 rank 6
2022-12-03 11:34:01,848 DEBUG TRAIN Batch 0/500 loss 301.225952 loss_att 269.434998 loss_ctc 325.689026 loss_rnnt 304.322388 lr 0.00002004 rank 0
2022-12-03 11:34:01,850 DEBUG TRAIN Batch 0/500 loss 298.283630 loss_att 266.821381 loss_ctc 317.294128 loss_rnnt 302.041321 lr 0.00002004 rank 2
2022-12-03 11:34:01,850 DEBUG TRAIN Batch 0/500 loss 254.362747 loss_att 228.921112 loss_ctc 272.099762 loss_rnnt 257.086151 lr 0.00002004 rank 3
2022-12-03 11:34:01,854 DEBUG TRAIN Batch 0/500 loss 271.276367 loss_att 243.657364 loss_ctc 287.378967 loss_rnnt 274.653137 lr 0.00002004 rank 7
2022-12-03 11:34:01,898 DEBUG TRAIN Batch 0/500 loss 255.212524 loss_att 226.260223 loss_ctc 270.403046 loss_rnnt 258.977600 lr 0.00002004 rank 4
2022-12-03 11:35:14,881 DEBUG TRAIN Batch 0/600 loss 222.083984 loss_att 197.664139 loss_ctc 229.492432 loss_rnnt 225.980133 lr 0.00002404 rank 6
2022-12-03 11:35:14,883 DEBUG TRAIN Batch 0/600 loss 116.117943 loss_att 103.384377 loss_ctc 120.185539 loss_rnnt 118.122307 lr 0.00002404 rank 0
2022-12-03 11:35:14,884 DEBUG TRAIN Batch 0/600 loss 91.351753 loss_att 81.884796 loss_ctc 94.207207 loss_rnnt 92.864410 lr 0.00002404 rank 2
2022-12-03 11:35:14,886 DEBUG TRAIN Batch 0/600 loss 273.612732 loss_att 241.805496 loss_ctc 281.935791 loss_rnnt 278.864471 lr 0.00002404 rank 3
2022-12-03 11:35:14,888 DEBUG TRAIN Batch 0/600 loss 181.585953 loss_att 162.665222 loss_ctc 190.484406 loss_rnnt 184.183640 lr 0.00002404 rank 5
2022-12-03 11:35:14,889 DEBUG TRAIN Batch 0/600 loss 86.717247 loss_att 78.389412 loss_ctc 89.022209 loss_rnnt 88.075478 lr 0.00002404 rank 1
2022-12-03 11:35:14,891 DEBUG TRAIN Batch 0/600 loss 401.523743 loss_att 357.996582 loss_ctc 416.540833 loss_rnnt 408.226898 lr 0.00002404 rank 4
2022-12-03 11:35:14,937 DEBUG TRAIN Batch 0/600 loss 133.859497 loss_att 119.745163 loss_ctc 138.070175 loss_rnnt 136.120956 lr 0.00002404 rank 7
2022-12-03 11:36:28,666 DEBUG TRAIN Batch 0/700 loss 327.128967 loss_att 290.161682 loss_ctc 336.013214 loss_rnnt 333.337860 lr 0.00002804 rank 5
2022-12-03 11:36:28,678 DEBUG TRAIN Batch 0/700 loss 336.142151 loss_att 300.122070 loss_ctc 346.337585 loss_rnnt 341.986786 lr 0.00002804 rank 6
2022-12-03 11:36:28,681 DEBUG TRAIN Batch 0/700 loss 322.180359 loss_att 287.427643 loss_ctc 333.841125 loss_rnnt 327.576141 lr 0.00002804 rank 1
2022-12-03 11:36:28,688 DEBUG TRAIN Batch 0/700 loss 284.327026 loss_att 253.442688 loss_ctc 295.402588 loss_rnnt 289.027161 lr 0.00002804 rank 7
2022-12-03 11:36:28,691 DEBUG TRAIN Batch 0/700 loss 317.201050 loss_att 281.765228 loss_ctc 325.978455 loss_rnnt 323.117859 lr 0.00002804 rank 0
2022-12-03 11:36:28,691 DEBUG TRAIN Batch 0/700 loss 300.242218 loss_att 267.971863 loss_ctc 311.378845 loss_rnnt 305.211426 lr 0.00002804 rank 2
2022-12-03 11:36:28,695 DEBUG TRAIN Batch 0/700 loss 347.678894 loss_att 310.069336 loss_ctc 357.101013 loss_rnnt 353.944519 lr 0.00002804 rank 4
2022-12-03 11:36:28,732 DEBUG TRAIN Batch 0/700 loss 352.956573 loss_att 315.263794 loss_ctc 364.836304 loss_rnnt 358.911133 lr 0.00002804 rank 3
2022-12-03 11:38:34,100 DEBUG TRAIN Batch 0/800 loss 335.700195 loss_att 298.664978 loss_ctc 345.309326 loss_rnnt 341.825989 lr 0.00003204 rank 5
2022-12-03 11:38:34,103 DEBUG TRAIN Batch 0/800 loss 333.329590 loss_att 297.472321 loss_ctc 343.727631 loss_rnnt 339.114624 lr 0.00003204 rank 6
2022-12-03 11:38:34,104 DEBUG TRAIN Batch 0/800 loss 318.517578 loss_att 283.668945 loss_ctc 327.422424 loss_rnnt 324.299988 lr 0.00003204 rank 1
2022-12-03 11:38:34,105 DEBUG TRAIN Batch 0/800 loss 316.206177 loss_att 283.977234 loss_ctc 328.479553 loss_rnnt 321.015503 lr 0.00003204 rank 0
2022-12-03 11:38:34,105 DEBUG TRAIN Batch 0/800 loss 277.316010 loss_att 246.863373 loss_ctc 285.148804 loss_rnnt 282.362183 lr 0.00003204 rank 2
2022-12-03 11:38:34,106 DEBUG TRAIN Batch 0/800 loss 331.822662 loss_att 297.528107 loss_ctc 343.892029 loss_rnnt 337.072327 lr 0.00003204 rank 7
2022-12-03 11:38:34,106 DEBUG TRAIN Batch 0/800 loss 253.802322 loss_att 225.111053 loss_ctc 262.151703 loss_rnnt 258.427338 lr 0.00003204 rank 3
2022-12-03 11:38:34,109 DEBUG TRAIN Batch 0/800 loss 262.043396 loss_att 231.601700 loss_ctc 269.380157 loss_rnnt 267.153503 lr 0.00003204 rank 4
2022-12-03 11:39:45,008 DEBUG TRAIN Batch 0/900 loss 293.407074 loss_att 261.081177 loss_ctc 305.560577 loss_rnnt 298.251770 lr 0.00003604 rank 6
2022-12-03 11:39:45,010 DEBUG TRAIN Batch 0/900 loss 286.056976 loss_att 255.048172 loss_ctc 295.789917 loss_rnnt 290.960999 lr 0.00003604 rank 5
2022-12-03 11:39:45,015 DEBUG TRAIN Batch 0/900 loss 321.572052 loss_att 287.730469 loss_ctc 334.676270 loss_rnnt 326.593140 lr 0.00003604 rank 3
2022-12-03 11:39:45,015 DEBUG TRAIN Batch 0/900 loss 308.120605 loss_att 273.236389 loss_ctc 318.595123 loss_rnnt 313.700867 lr 0.00003604 rank 1
2022-12-03 11:39:45,017 DEBUG TRAIN Batch 0/900 loss 286.915100 loss_att 256.644897 loss_ctc 296.208282 loss_rnnt 291.730011 lr 0.00003604 rank 2
2022-12-03 11:39:45,018 DEBUG TRAIN Batch 0/900 loss 322.843842 loss_att 288.292877 loss_ctc 333.483398 loss_rnnt 328.335449 lr 0.00003604 rank 7
2022-12-03 11:39:45,019 DEBUG TRAIN Batch 0/900 loss 345.859436 loss_att 307.871582 loss_ctc 358.156281 loss_rnnt 351.817413 lr 0.00003604 rank 0
2022-12-03 11:39:45,028 DEBUG TRAIN Batch 0/900 loss 333.741425 loss_att 296.594482 loss_ctc 345.764954 loss_rnnt 339.567688 lr 0.00003604 rank 4
2022-12-03 11:40:57,571 DEBUG TRAIN Batch 0/1000 loss 304.424988 loss_att 273.722900 loss_ctc 316.587463 loss_rnnt 308.943726 lr 0.00004004 rank 3
2022-12-03 11:40:57,580 DEBUG TRAIN Batch 0/1000 loss 306.524719 loss_att 272.440552 loss_ctc 317.520782 loss_rnnt 311.875397 lr 0.00004004 rank 2
2022-12-03 11:40:57,583 DEBUG TRAIN Batch 0/1000 loss 290.574219 loss_att 259.289124 loss_ctc 302.312622 loss_rnnt 295.266113 lr 0.00004004 rank 6
2022-12-03 11:40:57,583 DEBUG TRAIN Batch 0/1000 loss 323.229889 loss_att 287.588043 loss_ctc 335.709991 loss_rnnt 328.694214 lr 0.00004004 rank 0
2022-12-03 11:40:57,596 DEBUG TRAIN Batch 0/1000 loss 303.629456 loss_att 272.028412 loss_ctc 316.489502 loss_rnnt 308.234985 lr 0.00004004 rank 5
2022-12-03 11:40:57,598 DEBUG TRAIN Batch 0/1000 loss 372.209320 loss_att 329.625061 loss_ctc 387.289337 loss_rnnt 378.715485 lr 0.00004004 rank 7
2022-12-03 11:40:57,608 DEBUG TRAIN Batch 0/1000 loss 272.858673 loss_att 243.685059 loss_ctc 282.718689 loss_rnnt 277.378723 lr 0.00004004 rank 4
2022-12-03 11:40:57,624 DEBUG TRAIN Batch 0/1000 loss 318.877472 loss_att 284.276184 loss_ctc 329.108978 loss_rnnt 324.433533 lr 0.00004004 rank 1
2022-12-03 11:43:03,293 DEBUG TRAIN Batch 0/1100 loss 327.287079 loss_att 289.939331 loss_ctc 340.318573 loss_rnnt 333.019104 lr 0.00004404 rank 3
2022-12-03 11:43:03,295 DEBUG TRAIN Batch 0/1100 loss 320.485840 loss_att 286.474335 loss_ctc 335.949524 loss_rnnt 325.226318 lr 0.00004404 rank 0
2022-12-03 11:43:03,295 DEBUG TRAIN Batch 0/1100 loss 282.703461 loss_att 250.502869 loss_ctc 291.856659 loss_rnnt 287.923157 lr 0.00004404 rank 6
2022-12-03 11:43:03,297 DEBUG TRAIN Batch 0/1100 loss 325.781250 loss_att 290.657654 loss_ctc 341.752441 loss_rnnt 330.676453 lr 0.00004404 rank 5
2022-12-03 11:43:03,300 DEBUG TRAIN Batch 0/1100 loss 253.405380 loss_att 226.732162 loss_ctc 264.765472 loss_rnnt 257.225342 lr 0.00004404 rank 7
2022-12-03 11:43:03,310 DEBUG TRAIN Batch 0/1100 loss 258.893494 loss_att 230.942429 loss_ctc 266.198181 loss_rnnt 263.509766 lr 0.00004404 rank 2
2022-12-03 11:43:03,333 DEBUG TRAIN Batch 0/1100 loss 261.644714 loss_att 231.997543 loss_ctc 273.262573 loss_rnnt 266.025116 lr 0.00004404 rank 4
2022-12-03 11:43:03,335 DEBUG TRAIN Batch 0/1100 loss 299.865875 loss_att 267.978577 loss_ctc 313.555817 loss_rnnt 304.418030 lr 0.00004404 rank 1
2022-12-03 11:44:15,444 DEBUG TRAIN Batch 0/1200 loss 154.458786 loss_att 137.493317 loss_ctc 161.771027 loss_rnnt 156.876923 lr 0.00004804 rank 1
2022-12-03 11:44:15,445 DEBUG TRAIN Batch 0/1200 loss 209.620255 loss_att 186.153229 loss_ctc 219.797684 loss_rnnt 212.956665 lr 0.00004804 rank 0
2022-12-03 11:44:15,447 DEBUG TRAIN Batch 0/1200 loss 167.861725 loss_att 150.182709 loss_ctc 174.430847 loss_rnnt 170.521652 lr 0.00004804 rank 2
2022-12-03 11:44:15,448 DEBUG TRAIN Batch 0/1200 loss 270.560120 loss_att 241.032532 loss_ctc 283.261108 loss_rnnt 274.772156 lr 0.00004804 rank 5
2022-12-03 11:44:15,450 DEBUG TRAIN Batch 0/1200 loss 224.430405 loss_att 200.734940 loss_ctc 232.777176 loss_rnnt 228.056595 lr 0.00004804 rank 6
2022-12-03 11:44:15,451 DEBUG TRAIN Batch 0/1200 loss 251.352264 loss_att 224.479431 loss_ctc 263.602997 loss_rnnt 255.093384 lr 0.00004804 rank 3
2022-12-03 11:44:15,455 DEBUG TRAIN Batch 0/1200 loss 237.516800 loss_att 211.859268 loss_ctc 249.820633 loss_rnnt 241.007812 lr 0.00004804 rank 7
2022-12-03 11:44:15,456 DEBUG TRAIN Batch 0/1200 loss 208.162735 loss_att 185.416977 loss_ctc 219.204346 loss_rnnt 211.239670 lr 0.00004804 rank 4
2022-12-03 11:45:27,513 DEBUG TRAIN Batch 0/1300 loss 433.171021 loss_att 388.346527 loss_ctc 457.049927 loss_rnnt 438.952057 lr 0.00005204 rank 6
2022-12-03 11:45:27,513 DEBUG TRAIN Batch 0/1300 loss 59.115768 loss_att 53.381481 loss_ctc 61.696426 loss_rnnt 59.918537 lr 0.00005204 rank 3
2022-12-03 11:45:27,518 DEBUG TRAIN Batch 0/1300 loss 375.756287 loss_att 335.140747 loss_ctc 393.227509 loss_rnnt 381.549866 lr 0.00005204 rank 0
2022-12-03 11:45:27,518 DEBUG TRAIN Batch 0/1300 loss 309.846802 loss_att 273.972382 loss_ctc 328.340698 loss_rnnt 314.555847 lr 0.00005204 rank 1
2022-12-03 11:45:27,520 DEBUG TRAIN Batch 0/1300 loss 295.903290 loss_att 260.668579 loss_ctc 307.581604 loss_rnnt 301.393158 lr 0.00005204 rank 7
2022-12-03 11:45:27,521 DEBUG TRAIN Batch 0/1300 loss 314.672668 loss_att 280.706848 loss_ctc 333.955322 loss_rnnt 318.894836 lr 0.00005204 rank 2
2022-12-03 11:45:27,525 DEBUG TRAIN Batch 0/1300 loss 171.476471 loss_att 152.596741 loss_ctc 183.210312 loss_rnnt 173.687897 lr 0.00005204 rank 5
2022-12-03 11:45:27,525 DEBUG TRAIN Batch 0/1300 loss 353.109283 loss_att 318.008881 loss_ctc 372.505432 loss_rnnt 357.543213 lr 0.00005204 rank 4
2022-12-03 11:46:40,932 DEBUG TRAIN Batch 0/1400 loss 306.088623 loss_att 273.141785 loss_ctc 325.342834 loss_rnnt 310.110779 lr 0.00005604 rank 0
2022-12-03 11:46:40,933 DEBUG TRAIN Batch 0/1400 loss 297.059174 loss_att 266.564270 loss_ctc 316.566650 loss_rnnt 300.557129 lr 0.00005604 rank 7
2022-12-03 11:46:40,934 DEBUG TRAIN Batch 0/1400 loss 261.019958 loss_att 234.905045 loss_ctc 280.683411 loss_rnnt 263.621155 lr 0.00005604 rank 6
2022-12-03 11:46:40,935 DEBUG TRAIN Batch 0/1400 loss 316.350464 loss_att 280.616150 loss_ctc 333.121338 loss_rnnt 321.261230 lr 0.00005604 rank 2
2022-12-03 11:46:40,937 DEBUG TRAIN Batch 0/1400 loss 266.887146 loss_att 239.533081 loss_ctc 283.394592 loss_rnnt 270.156952 lr 0.00005604 rank 1
2022-12-03 11:46:40,939 DEBUG TRAIN Batch 0/1400 loss 295.604919 loss_att 266.994263 loss_ctc 317.347809 loss_rnnt 298.427979 lr 0.00005604 rank 3
2022-12-03 11:46:40,942 DEBUG TRAIN Batch 0/1400 loss 300.853210 loss_att 272.794983 loss_ctc 323.390961 loss_rnnt 303.459839 lr 0.00005604 rank 5
2022-12-03 11:46:40,943 DEBUG TRAIN Batch 0/1400 loss 333.139282 loss_att 298.760254 loss_ctc 351.269958 loss_rnnt 337.597656 lr 0.00005604 rank 4
2022-12-03 11:48:47,129 DEBUG TRAIN Batch 0/1500 loss 390.546112 loss_att 347.544617 loss_ctc 420.838074 loss_rnnt 395.107513 lr 0.00006004 rank 6
2022-12-03 11:48:47,132 DEBUG TRAIN Batch 0/1500 loss 321.587494 loss_att 286.468872 loss_ctc 341.527191 loss_rnnt 325.952606 lr 0.00006004 rank 3
2022-12-03 11:48:47,134 DEBUG TRAIN Batch 0/1500 loss 273.100037 loss_att 246.909119 loss_ctc 291.290863 loss_rnnt 275.912781 lr 0.00006004 rank 5
2022-12-03 11:48:47,135 DEBUG TRAIN Batch 0/1500 loss 261.205872 loss_att 233.555603 loss_ctc 276.168549 loss_rnnt 264.740875 lr 0.00006004 rank 7
2022-12-03 11:48:47,137 DEBUG TRAIN Batch 0/1500 loss 296.295410 loss_att 263.606934 loss_ctc 314.997925 loss_rnnt 300.339417 lr 0.00006004 rank 1
2022-12-03 11:48:47,138 DEBUG TRAIN Batch 0/1500 loss 313.020691 loss_att 276.990845 loss_ctc 331.359314 loss_rnnt 317.781525 lr 0.00006004 rank 2
2022-12-03 11:48:47,140 DEBUG TRAIN Batch 0/1500 loss 286.235718 loss_att 253.006042 loss_ctc 305.210419 loss_rnnt 290.351685 lr 0.00006004 rank 0
2022-12-03 11:48:47,142 DEBUG TRAIN Batch 0/1500 loss 329.045044 loss_att 294.535522 loss_ctc 351.112640 loss_rnnt 333.004608 lr 0.00006004 rank 4
2022-12-03 11:49:59,014 DEBUG TRAIN Batch 0/1600 loss 311.328186 loss_att 279.099365 loss_ctc 329.618286 loss_rnnt 315.335297 lr 0.00006404 rank 5
2022-12-03 11:49:59,016 DEBUG TRAIN Batch 0/1600 loss 276.143066 loss_att 246.607651 loss_ctc 293.620392 loss_rnnt 279.719818 lr 0.00006404 rank 3
2022-12-03 11:49:59,016 DEBUG TRAIN Batch 0/1600 loss 294.028137 loss_att 264.984009 loss_ctc 313.301361 loss_rnnt 297.267181 lr 0.00006404 rank 7
2022-12-03 11:49:59,016 DEBUG TRAIN Batch 0/1600 loss 315.025269 loss_att 282.485596 loss_ctc 334.870819 loss_rnnt 318.887146 lr 0.00006404 rank 6
2022-12-03 11:49:59,018 DEBUG TRAIN Batch 0/1600 loss 318.087006 loss_att 286.451477 loss_ctc 335.523193 loss_rnnt 322.089294 lr 0.00006404 rank 4
2022-12-03 11:49:59,018 DEBUG TRAIN Batch 0/1600 loss 376.046356 loss_att 338.950653 loss_ctc 400.004150 loss_rnnt 380.271118 lr 0.00006404 rank 0
2022-12-03 11:49:59,019 DEBUG TRAIN Batch 0/1600 loss 308.980774 loss_att 272.418091 loss_ctc 324.489868 loss_rnnt 314.225464 lr 0.00006404 rank 1
2022-12-03 11:49:59,069 DEBUG TRAIN Batch 0/1600 loss 286.234680 loss_att 258.815247 loss_ctc 307.572296 loss_rnnt 288.873535 lr 0.00006404 rank 2
2022-12-03 11:51:10,869 DEBUG TRAIN Batch 0/1700 loss 265.891388 loss_att 240.250000 loss_ctc 284.010132 loss_rnnt 268.603821 lr 0.00006804 rank 6
2022-12-03 11:51:10,869 DEBUG TRAIN Batch 0/1700 loss 244.181458 loss_att 219.851456 loss_ctc 256.729736 loss_rnnt 247.374344 lr 0.00006804 rank 3
2022-12-03 11:51:10,875 DEBUG TRAIN Batch 0/1700 loss 269.842194 loss_att 241.537506 loss_ctc 288.347046 loss_rnnt 273.035797 lr 0.00006804 rank 0
2022-12-03 11:51:10,877 DEBUG TRAIN Batch 0/1700 loss 329.951141 loss_att 298.093384 loss_ctc 359.078613 loss_rnnt 332.439026 lr 0.00006804 rank 5
2022-12-03 11:51:10,881 DEBUG TRAIN Batch 0/1700 loss 268.143005 loss_att 239.492889 loss_ctc 283.621582 loss_rnnt 271.809235 lr 0.00006804 rank 4
2022-12-03 11:51:10,881 DEBUG TRAIN Batch 0/1700 loss 252.965454 loss_att 227.917145 loss_ctc 269.746399 loss_rnnt 255.737656 lr 0.00006804 rank 7
2022-12-03 11:51:10,902 DEBUG TRAIN Batch 0/1700 loss 298.063110 loss_att 266.384918 loss_ctc 319.193604 loss_rnnt 301.581360 lr 0.00006804 rank 2
2022-12-03 11:51:10,908 DEBUG TRAIN Batch 0/1700 loss 271.180664 loss_att 244.184357 loss_ctc 292.899780 loss_rnnt 273.684021 lr 0.00006804 rank 1
2022-12-03 11:53:16,274 DEBUG TRAIN Batch 0/1800 loss 276.964600 loss_att 249.258774 loss_ctc 297.526978 loss_rnnt 279.764099 lr 0.00007204 rank 6
2022-12-03 11:53:16,275 DEBUG TRAIN Batch 0/1800 loss 242.849060 loss_att 220.352615 loss_ctc 263.031189 loss_rnnt 244.657379 lr 0.00007204 rank 0
2022-12-03 11:53:16,276 DEBUG TRAIN Batch 0/1800 loss 293.809479 loss_att 262.645630 loss_ctc 310.593048 loss_rnnt 297.804443 lr 0.00007204 rank 3
2022-12-03 11:53:16,278 DEBUG TRAIN Batch 0/1800 loss 179.462860 loss_att 162.360016 loss_ctc 194.274704 loss_rnnt 180.908508 lr 0.00007204 rank 1
2022-12-03 11:53:16,278 DEBUG TRAIN Batch 0/1800 loss 259.338013 loss_att 234.005341 loss_ctc 279.992432 loss_rnnt 261.650635 lr 0.00007204 rank 5
2022-12-03 11:53:16,282 DEBUG TRAIN Batch 0/1800 loss 278.127136 loss_att 250.745956 loss_ctc 301.894775 loss_rnnt 280.434326 lr 0.00007204 rank 2
2022-12-03 11:53:16,288 DEBUG TRAIN Batch 0/1800 loss 260.453186 loss_att 233.706177 loss_ctc 279.734619 loss_rnnt 263.231720 lr 0.00007204 rank 4
2022-12-03 11:53:16,327 DEBUG TRAIN Batch 0/1800 loss 282.154388 loss_att 251.017120 loss_ctc 306.560974 loss_rnnt 285.127625 lr 0.00007204 rank 7
2022-12-03 11:54:28,892 DEBUG TRAIN Batch 0/1900 loss 245.277344 loss_att 217.639313 loss_ctc 265.712250 loss_rnnt 248.080307 lr 0.00007604 rank 5
2022-12-03 11:54:28,892 DEBUG TRAIN Batch 0/1900 loss 207.430115 loss_att 187.687317 loss_ctc 223.061646 loss_rnnt 209.294464 lr 0.00007604 rank 6
2022-12-03 11:54:28,896 DEBUG TRAIN Batch 0/1900 loss 190.736099 loss_att 172.773499 loss_ctc 204.678879 loss_rnnt 192.469574 lr 0.00007604 rank 3
2022-12-03 11:54:28,897 DEBUG TRAIN Batch 0/1900 loss 171.823853 loss_att 154.649933 loss_ctc 185.227234 loss_rnnt 173.471512 lr 0.00007604 rank 0
2022-12-03 11:54:28,897 DEBUG TRAIN Batch 0/1900 loss 193.768967 loss_att 174.206406 loss_ctc 210.821716 loss_rnnt 195.407776 lr 0.00007604 rank 7
2022-12-03 11:54:28,898 DEBUG TRAIN Batch 0/1900 loss 311.474182 loss_att 280.022461 loss_ctc 334.959717 loss_rnnt 314.633118 lr 0.00007604 rank 1
2022-12-03 11:54:28,902 DEBUG TRAIN Batch 0/1900 loss 103.991440 loss_att 94.655708 loss_ctc 111.719032 loss_rnnt 104.828239 lr 0.00007604 rank 4
2022-12-03 11:54:28,902 DEBUG TRAIN Batch 0/1900 loss 149.291870 loss_att 136.104172 loss_ctc 162.734543 loss_rnnt 150.137070 lr 0.00007604 rank 2
2022-12-03 11:55:39,899 DEBUG TRAIN Batch 0/2000 loss 258.597290 loss_att 234.182098 loss_ctc 279.355286 loss_rnnt 260.712616 lr 0.00008004 rank 3
2022-12-03 11:55:39,914 DEBUG TRAIN Batch 0/2000 loss 301.585602 loss_att 273.825928 loss_ctc 325.725525 loss_rnnt 303.918884 lr 0.00008004 rank 0
2022-12-03 11:55:39,916 DEBUG TRAIN Batch 0/2000 loss 231.938019 loss_att 211.104462 loss_ctc 249.680878 loss_rnnt 233.739014 lr 0.00008004 rank 5
2022-12-03 11:55:39,915 DEBUG TRAIN Batch 0/2000 loss 279.079132 loss_att 252.177063 loss_ctc 303.432983 loss_rnnt 281.212372 lr 0.00008004 rank 6
2022-12-03 11:55:39,916 DEBUG TRAIN Batch 0/2000 loss 321.861542 loss_att 292.447357 loss_ctc 350.081268 loss_rnnt 323.981750 lr 0.00008004 rank 1
2022-12-03 11:55:39,921 DEBUG TRAIN Batch 0/2000 loss 322.145264 loss_att 291.204529 loss_ctc 351.401917 loss_rnnt 324.432556 lr 0.00008004 rank 2
2022-12-03 11:55:39,922 DEBUG TRAIN Batch 0/2000 loss 317.909180 loss_att 283.794098 loss_ctc 345.233490 loss_rnnt 321.088959 lr 0.00008004 rank 4
2022-12-03 11:55:39,925 DEBUG TRAIN Batch 0/2000 loss 298.586578 loss_att 270.138336 loss_ctc 326.289246 loss_rnnt 300.582520 lr 0.00008004 rank 7
2022-12-03 11:56:52,914 DEBUG TRAIN Batch 0/2100 loss 286.506104 loss_att 259.920319 loss_ctc 314.544647 loss_rnnt 288.084778 lr 0.00008404 rank 3
2022-12-03 11:56:52,914 DEBUG TRAIN Batch 0/2100 loss 294.180145 loss_att 268.081299 loss_ctc 322.655090 loss_rnnt 295.603271 lr 0.00008404 rank 0
2022-12-03 11:56:52,915 DEBUG TRAIN Batch 0/2100 loss 275.724548 loss_att 249.396683 loss_ctc 295.779175 loss_rnnt 278.316162 lr 0.00008404 rank 7
2022-12-03 11:56:52,915 DEBUG TRAIN Batch 0/2100 loss 320.785370 loss_att 290.681274 loss_ctc 350.258118 loss_rnnt 322.876465 lr 0.00008404 rank 5
2022-12-03 11:56:52,916 DEBUG TRAIN Batch 0/2100 loss 268.743896 loss_att 244.537537 loss_ctc 292.218018 loss_rnnt 270.455261 lr 0.00008404 rank 6
2022-12-03 11:56:52,921 DEBUG TRAIN Batch 0/2100 loss 296.180450 loss_att 268.633606 loss_ctc 318.701416 loss_rnnt 298.687012 lr 0.00008404 rank 1
2022-12-03 11:56:52,925 DEBUG TRAIN Batch 0/2100 loss 294.820251 loss_att 260.975616 loss_ctc 322.685791 loss_rnnt 297.873779 lr 0.00008404 rank 2
2022-12-03 11:56:52,927 DEBUG TRAIN Batch 0/2100 loss 273.446472 loss_att 246.328308 loss_ctc 295.588501 loss_rnnt 275.917847 lr 0.00008404 rank 4
2022-12-03 11:58:59,295 DEBUG TRAIN Batch 0/2200 loss 272.270447 loss_att 247.056412 loss_ctc 295.233978 loss_rnnt 274.251465 lr 0.00008804 rank 6
2022-12-03 11:58:59,298 DEBUG TRAIN Batch 0/2200 loss 282.363678 loss_att 255.579285 loss_ctc 303.406982 loss_rnnt 284.914795 lr 0.00008804 rank 3
2022-12-03 11:58:59,300 DEBUG TRAIN Batch 0/2200 loss 299.023834 loss_att 267.965363 loss_ctc 323.023193 loss_rnnt 302.035645 lr 0.00008804 rank 0
2022-12-03 11:58:59,300 DEBUG TRAIN Batch 0/2200 loss 247.747543 loss_att 226.787537 loss_ctc 274.263123 loss_rnnt 248.404144 lr 0.00008804 rank 4
2022-12-03 11:58:59,302 DEBUG TRAIN Batch 0/2200 loss 304.664124 loss_att 272.555573 loss_ctc 325.076477 loss_rnnt 308.364197 lr 0.00008804 rank 7
2022-12-03 11:58:59,303 DEBUG TRAIN Batch 0/2200 loss 309.820557 loss_att 279.482727 loss_ctc 331.228577 loss_rnnt 313.033691 lr 0.00008804 rank 2
2022-12-03 11:58:59,304 DEBUG TRAIN Batch 0/2200 loss 253.067657 loss_att 231.735321 loss_ctc 269.974335 loss_rnnt 255.079895 lr 0.00008804 rank 1
2022-12-03 11:58:59,343 DEBUG TRAIN Batch 0/2200 loss 312.855225 loss_att 287.432129 loss_ctc 337.158386 loss_rnnt 314.699432 lr 0.00008804 rank 5
2022-12-03 12:00:10,758 DEBUG TRAIN Batch 0/2300 loss 293.787872 loss_att 266.969971 loss_ctc 321.507629 loss_rnnt 295.455475 lr 0.00009204 rank 4
2022-12-03 12:00:10,759 DEBUG TRAIN Batch 0/2300 loss 299.273773 loss_att 269.987030 loss_ctc 319.268738 loss_rnnt 302.465149 lr 0.00009204 rank 0
2022-12-03 12:00:10,760 DEBUG TRAIN Batch 0/2300 loss 274.949707 loss_att 249.336029 loss_ctc 295.853668 loss_rnnt 277.285217 lr 0.00009204 rank 3
2022-12-03 12:00:10,762 DEBUG TRAIN Batch 0/2300 loss 326.039673 loss_att 294.599182 loss_ctc 354.160950 loss_rnnt 328.578247 lr 0.00009204 rank 5
2022-12-03 12:00:10,766 DEBUG TRAIN Batch 0/2300 loss 278.368347 loss_att 255.734222 loss_ctc 299.410278 loss_rnnt 280.089600 lr 0.00009204 rank 2
2022-12-03 12:00:10,768 DEBUG TRAIN Batch 0/2300 loss 306.735077 loss_att 279.457794 loss_ctc 331.042480 loss_rnnt 308.949524 lr 0.00009204 rank 6
2022-12-03 12:00:10,771 DEBUG TRAIN Batch 0/2300 loss 259.662964 loss_att 238.910431 loss_ctc 275.590332 loss_rnnt 261.689819 lr 0.00009204 rank 7
2022-12-03 12:00:10,809 DEBUG TRAIN Batch 0/2300 loss 287.247314 loss_att 262.359253 loss_ctc 316.347015 loss_rnnt 288.344971 lr 0.00009204 rank 1
2022-12-03 12:01:22,636 DEBUG TRAIN Batch 0/2400 loss 253.064240 loss_att 232.538116 loss_ctc 273.574402 loss_rnnt 254.434784 lr 0.00009604 rank 6
2022-12-03 12:01:22,637 DEBUG TRAIN Batch 0/2400 loss 227.233246 loss_att 206.624344 loss_ctc 242.876007 loss_rnnt 229.269318 lr 0.00009604 rank 3
2022-12-03 12:01:22,641 DEBUG TRAIN Batch 0/2400 loss 233.234039 loss_att 212.036438 loss_ctc 248.098785 loss_rnnt 235.491592 lr 0.00009604 rank 5
2022-12-03 12:01:22,641 DEBUG TRAIN Batch 0/2400 loss 195.926468 loss_att 179.156693 loss_ctc 212.993607 loss_rnnt 197.004791 lr 0.00009604 rank 1
2022-12-03 12:01:22,644 DEBUG TRAIN Batch 0/2400 loss 309.587830 loss_att 280.589325 loss_ctc 329.373871 loss_rnnt 312.749390 lr 0.00009604 rank 0
2022-12-03 12:01:22,648 DEBUG TRAIN Batch 0/2400 loss 252.869202 loss_att 230.055176 loss_ctc 276.269409 loss_rnnt 254.311996 lr 0.00009604 rank 7
2022-12-03 12:01:22,648 DEBUG TRAIN Batch 0/2400 loss 269.481232 loss_att 250.322388 loss_ctc 293.377289 loss_rnnt 270.126862 lr 0.00009604 rank 2
2022-12-03 12:01:22,648 DEBUG TRAIN Batch 0/2400 loss 263.687622 loss_att 241.325317 loss_ctc 285.995270 loss_rnnt 265.185730 lr 0.00009604 rank 4
2022-12-03 12:03:28,320 DEBUG TRAIN Batch 0/2500 loss 193.547913 loss_att 181.014038 loss_ctc 207.043121 loss_rnnt 194.255325 lr 0.00010004 rank 3
2022-12-03 12:03:28,321 DEBUG TRAIN Batch 0/2500 loss 189.908783 loss_att 176.518646 loss_ctc 201.636688 loss_rnnt 191.023087 lr 0.00010004 rank 0
2022-12-03 12:03:28,322 DEBUG TRAIN Batch 0/2500 loss 210.343307 loss_att 195.036346 loss_ctc 229.155228 loss_rnnt 210.896439 lr 0.00010004 rank 6
2022-12-03 12:03:28,324 DEBUG TRAIN Batch 0/2500 loss 322.998993 loss_att 296.419891 loss_ctc 358.949036 loss_rnnt 323.521484 lr 0.00010004 rank 1
2022-12-03 12:03:28,326 DEBUG TRAIN Batch 0/2500 loss 258.310730 loss_att 238.839294 loss_ctc 271.950195 loss_rnnt 260.386414 lr 0.00010004 rank 5
2022-12-03 12:03:28,331 DEBUG TRAIN Batch 0/2500 loss 191.442230 loss_att 175.740891 loss_ctc 211.223251 loss_rnnt 191.945023 lr 0.00010004 rank 2
2022-12-03 12:03:28,332 DEBUG TRAIN Batch 0/2500 loss 235.121292 loss_att 216.245239 loss_ctc 253.929764 loss_rnnt 236.388702 lr 0.00010004 rank 7
2022-12-03 12:03:28,338 DEBUG TRAIN Batch 0/2500 loss 255.871750 loss_att 235.571091 loss_ctc 278.648651 loss_rnnt 256.894958 lr 0.00010004 rank 4
2022-12-03 12:04:40,392 DEBUG TRAIN Batch 0/2600 loss 287.088074 loss_att 269.641113 loss_ctc 307.485107 loss_rnnt 287.857880 lr 0.00010404 rank 4
2022-12-03 12:04:40,406 DEBUG TRAIN Batch 0/2600 loss 347.821381 loss_att 319.816956 loss_ctc 375.138123 loss_rnnt 349.780029 lr 0.00010404 rank 3
2022-12-03 12:04:40,408 DEBUG TRAIN Batch 0/2600 loss 111.349121 loss_att 106.674408 loss_ctc 118.835381 loss_rnnt 111.285896 lr 0.00010404 rank 5
2022-12-03 12:04:40,410 DEBUG TRAIN Batch 0/2600 loss 303.711975 loss_att 285.705078 loss_ctc 323.123077 loss_rnnt 304.725189 lr 0.00010404 rank 6
2022-12-03 12:04:40,410 DEBUG TRAIN Batch 0/2600 loss 257.985962 loss_att 243.220062 loss_ctc 284.962891 loss_rnnt 257.342224 lr 0.00010404 rank 0
2022-12-03 12:04:40,414 DEBUG TRAIN Batch 0/2600 loss 149.913986 loss_att 139.935486 loss_ctc 161.337234 loss_rnnt 150.386581 lr 0.00010404 rank 7
2022-12-03 12:04:40,417 DEBUG TRAIN Batch 0/2600 loss 250.774323 loss_att 236.195572 loss_ctc 267.734955 loss_rnnt 251.428650 lr 0.00010404 rank 2
2022-12-03 12:04:40,459 DEBUG TRAIN Batch 0/2600 loss 341.234436 loss_att 309.699677 loss_ctc 370.095795 loss_rnnt 343.693207 lr 0.00010404 rank 1
2022-12-03 12:05:52,058 DEBUG TRAIN Batch 0/2700 loss 285.315338 loss_att 267.777222 loss_ctc 297.105469 loss_rnnt 287.250946 lr 0.00010804 rank 3
2022-12-03 12:05:52,059 DEBUG TRAIN Batch 0/2700 loss 294.217804 loss_att 273.426208 loss_ctc 312.956421 loss_rnnt 295.877655 lr 0.00010804 rank 6
2022-12-03 12:05:52,062 DEBUG TRAIN Batch 0/2700 loss 331.606689 loss_att 315.390656 loss_ctc 357.505829 loss_rnnt 331.396667 lr 0.00010804 rank 1
2022-12-03 12:05:52,063 DEBUG TRAIN Batch 0/2700 loss 246.747787 loss_att 234.703979 loss_ctc 264.577148 loss_rnnt 246.779297 lr 0.00010804 rank 2
2022-12-03 12:05:52,063 DEBUG TRAIN Batch 0/2700 loss 283.328339 loss_att 266.759766 loss_ctc 302.783752 loss_rnnt 284.047974 lr 0.00010804 rank 5
2022-12-03 12:05:52,066 DEBUG TRAIN Batch 0/2700 loss 277.970306 loss_att 264.409760 loss_ctc 292.470947 loss_rnnt 278.748993 lr 0.00010804 rank 0
2022-12-03 12:05:52,067 DEBUG TRAIN Batch 0/2700 loss 322.942139 loss_att 301.626556 loss_ctc 348.662781 loss_rnnt 323.775818 lr 0.00010804 rank 4
2022-12-03 12:05:52,068 DEBUG TRAIN Batch 0/2700 loss 287.570892 loss_att 279.853424 loss_ctc 301.371399 loss_rnnt 287.274292 lr 0.00010804 rank 7
2022-12-03 12:07:05,457 DEBUG TRAIN Batch 0/2800 loss 249.843277 loss_att 237.764206 loss_ctc 264.764648 loss_rnnt 250.269577 lr 0.00011204 rank 6
2022-12-03 12:07:05,461 DEBUG TRAIN Batch 0/2800 loss 302.957001 loss_att 282.685760 loss_ctc 324.408142 loss_rnnt 304.151093 lr 0.00011204 rank 5
2022-12-03 12:07:05,462 DEBUG TRAIN Batch 0/2800 loss 295.116547 loss_att 284.339478 loss_ctc 318.615784 loss_rnnt 294.138733 lr 0.00011204 rank 4
2022-12-03 12:07:05,462 DEBUG TRAIN Batch 0/2800 loss 225.408646 loss_att 218.378555 loss_ctc 240.704987 loss_rnnt 224.775146 lr 0.00011204 rank 0
2022-12-03 12:07:05,462 DEBUG TRAIN Batch 0/2800 loss 306.369873 loss_att 292.151459 loss_ctc 338.730072 loss_rnnt 304.898865 lr 0.00011204 rank 7
2022-12-03 12:07:05,462 DEBUG TRAIN Batch 0/2800 loss 260.750122 loss_att 252.732239 loss_ctc 290.290222 loss_rnnt 258.415009 lr 0.00011204 rank 3
2022-12-03 12:07:05,463 DEBUG TRAIN Batch 0/2800 loss 255.536697 loss_att 239.139008 loss_ctc 273.576294 loss_rnnt 256.410950 lr 0.00011204 rank 1
2022-12-03 12:07:05,510 DEBUG TRAIN Batch 0/2800 loss 290.062073 loss_att 279.587738 loss_ctc 317.473541 loss_rnnt 288.502075 lr 0.00011204 rank 2
2022-12-03 12:09:11,779 DEBUG TRAIN Batch 0/2900 loss 218.155090 loss_att 216.757095 loss_ctc 231.117340 loss_rnnt 216.706390 lr 0.00011604 rank 0
2022-12-03 12:09:11,780 DEBUG TRAIN Batch 0/2900 loss 292.541962 loss_att 281.087891 loss_ctc 310.628876 loss_rnnt 292.421204 lr 0.00011604 rank 1
2022-12-03 12:09:11,780 DEBUG TRAIN Batch 0/2900 loss 257.053558 loss_att 252.845490 loss_ctc 271.339722 loss_rnnt 255.990341 lr 0.00011604 rank 6
2022-12-03 12:09:11,782 DEBUG TRAIN Batch 0/2900 loss 262.315125 loss_att 257.269775 loss_ctc 279.081055 loss_rnnt 261.088745 lr 0.00011604 rank 2
2022-12-03 12:09:11,785 DEBUG TRAIN Batch 0/2900 loss 242.097488 loss_att 242.338120 loss_ctc 257.204407 loss_rnnt 240.035095 lr 0.00011604 rank 5
2022-12-03 12:09:11,787 DEBUG TRAIN Batch 0/2900 loss 258.990112 loss_att 253.532104 loss_ctc 269.790527 loss_rnnt 258.641663 lr 0.00011604 rank 7
2022-12-03 12:09:11,787 DEBUG TRAIN Batch 0/2900 loss 249.881912 loss_att 241.134705 loss_ctc 258.886230 loss_rnnt 250.430771 lr 0.00011604 rank 4
2022-12-03 12:09:11,788 DEBUG TRAIN Batch 0/2900 loss 252.228973 loss_att 243.371246 loss_ctc 269.091064 loss_rnnt 251.752243 lr 0.00011604 rank 3
2022-12-03 12:10:22,940 DEBUG TRAIN Batch 0/3000 loss 222.649857 loss_att 215.871796 loss_ctc 232.210480 loss_rnnt 222.730713 lr 0.00012004 rank 1
2022-12-03 12:10:22,949 DEBUG TRAIN Batch 0/3000 loss 260.060242 loss_att 259.813721 loss_ctc 276.367798 loss_rnnt 257.935211 lr 0.00012004 rank 6
2022-12-03 12:10:22,954 DEBUG TRAIN Batch 0/3000 loss 258.079712 loss_att 255.207687 loss_ctc 273.232971 loss_rnnt 256.633667 lr 0.00012004 rank 7
2022-12-03 12:10:22,954 DEBUG TRAIN Batch 0/3000 loss 280.803040 loss_att 275.445557 loss_ctc 298.822388 loss_rnnt 279.471954 lr 0.00012004 rank 5
2022-12-03 12:10:22,956 DEBUG TRAIN Batch 0/3000 loss 258.828918 loss_att 260.738007 loss_ctc 272.793884 loss_rnnt 256.585083 lr 0.00012004 rank 2
2022-12-03 12:10:22,956 DEBUG TRAIN Batch 0/3000 loss 284.704651 loss_att 281.705200 loss_ctc 299.953064 loss_rnnt 283.271393 lr 0.00012004 rank 0
2022-12-03 12:10:22,956 DEBUG TRAIN Batch 0/3000 loss 244.997482 loss_att 246.873535 loss_ctc 255.054657 loss_rnnt 243.281311 lr 0.00012004 rank 3
2022-12-03 12:10:22,956 DEBUG TRAIN Batch 0/3000 loss 259.198761 loss_att 261.077515 loss_ctc 265.635742 loss_rnnt 257.964752 lr 0.00012004 rank 4
2022-12-03 12:11:34,577 DEBUG TRAIN Batch 0/3100 loss 247.877014 loss_att 254.826187 loss_ctc 258.134369 loss_rnnt 245.119553 lr 0.00012404 rank 5
2022-12-03 12:11:34,578 DEBUG TRAIN Batch 0/3100 loss 228.544388 loss_att 233.936035 loss_ctc 242.003525 loss_rnnt 225.671509 lr 0.00012404 rank 3
2022-12-03 12:11:34,579 DEBUG TRAIN Batch 0/3100 loss 198.713120 loss_att 195.672791 loss_ctc 207.333618 loss_rnnt 198.171768 lr 0.00012404 rank 6
2022-12-03 12:11:34,579 DEBUG TRAIN Batch 0/3100 loss 218.337479 loss_att 216.065338 loss_ctc 234.099396 loss_rnnt 216.690308 lr 0.00012404 rank 0
2022-12-03 12:11:34,582 DEBUG TRAIN Batch 0/3100 loss 218.978302 loss_att 223.649323 loss_ctc 228.702881 loss_rnnt 216.747482 lr 0.00012404 rank 2
2022-12-03 12:11:34,584 DEBUG TRAIN Batch 0/3100 loss 99.172668 loss_att 97.640572 loss_ctc 105.808716 loss_rnnt 98.594284 lr 0.00012404 rank 1
2022-12-03 12:11:34,592 DEBUG TRAIN Batch 0/3100 loss 212.699829 loss_att 220.022949 loss_ctc 221.271393 loss_rnnt 210.092316 lr 0.00012404 rank 4
2022-12-03 12:11:34,635 DEBUG TRAIN Batch 0/3100 loss 220.641617 loss_att 226.800201 loss_ctc 228.842117 loss_rnnt 218.316483 lr 0.00012404 rank 7
2022-12-03 12:13:44,326 DEBUG TRAIN Batch 0/3200 loss 263.690460 loss_att 267.334625 loss_ctc 283.772247 loss_rnnt 260.284058 lr 0.00012804 rank 6
2022-12-03 12:13:44,327 DEBUG TRAIN Batch 0/3200 loss 234.146362 loss_att 239.091934 loss_ctc 243.744965 loss_rnnt 231.877441 lr 0.00012804 rank 1
2022-12-03 12:13:44,332 DEBUG TRAIN Batch 0/3200 loss 111.377365 loss_att 112.896683 loss_ctc 115.205139 loss_rnnt 110.563133 lr 0.00012804 rank 2
2022-12-03 12:13:44,334 DEBUG TRAIN Batch 0/3200 loss 80.748199 loss_att 82.287643 loss_ctc 86.221481 loss_rnnt 79.710541 lr 0.00012804 rank 0
2022-12-03 12:13:44,334 DEBUG TRAIN Batch 0/3200 loss 123.601723 loss_att 125.172729 loss_ctc 129.687225 loss_rnnt 122.476128 lr 0.00012804 rank 3
2022-12-03 12:13:44,334 DEBUG TRAIN Batch 0/3200 loss 197.051102 loss_att 199.127975 loss_ctc 205.897583 loss_rnnt 195.456192 lr 0.00012804 rank 7
2022-12-03 12:13:44,337 DEBUG TRAIN Batch 0/3200 loss 94.452126 loss_att 98.166458 loss_ctc 100.304123 loss_rnnt 92.928993 lr 0.00012804 rank 4
2022-12-03 12:13:44,390 DEBUG TRAIN Batch 0/3200 loss 149.579407 loss_att 156.039215 loss_ctc 156.720383 loss_rnnt 147.335327 lr 0.00012804 rank 5
2022-12-03 12:14:56,953 DEBUG TRAIN Batch 0/3300 loss 250.338821 loss_att 254.280609 loss_ctc 246.289520 loss_rnnt 250.090378 lr 0.00013204 rank 0
2022-12-03 12:14:56,955 DEBUG TRAIN Batch 0/3300 loss 246.568726 loss_att 269.784119 loss_ctc 245.779099 loss_rnnt 242.030930 lr 0.00013204 rank 2
2022-12-03 12:14:56,957 DEBUG TRAIN Batch 0/3300 loss 269.942535 loss_att 280.854858 loss_ctc 273.520020 loss_rnnt 267.283081 lr 0.00013204 rank 3
2022-12-03 12:14:56,956 DEBUG TRAIN Batch 0/3300 loss 244.700729 loss_att 264.182434 loss_ctc 244.026459 loss_rnnt 240.894287 lr 0.00013204 rank 6
2022-12-03 12:14:56,957 DEBUG TRAIN Batch 0/3300 loss 236.146881 loss_att 247.599518 loss_ctc 234.583679 loss_rnnt 234.064758 lr 0.00013204 rank 5
2022-12-03 12:14:56,960 DEBUG TRAIN Batch 0/3300 loss 263.811554 loss_att 270.899902 loss_ctc 276.141907 loss_rnnt 260.749817 lr 0.00013204 rank 4
2022-12-03 12:14:56,962 DEBUG TRAIN Batch 0/3300 loss 269.000488 loss_att 281.948914 loss_ctc 271.099487 loss_rnnt 266.130951 lr 0.00013204 rank 7
2022-12-03 12:14:57,002 DEBUG TRAIN Batch 0/3300 loss 201.471603 loss_att 226.174316 loss_ctc 202.148285 loss_rnnt 196.440826 lr 0.00013204 rank 1
2022-12-03 12:16:08,454 DEBUG TRAIN Batch 0/3400 loss 298.621460 loss_att 309.309570 loss_ctc 297.648743 loss_rnnt 296.613525 lr 0.00013604 rank 5
2022-12-03 12:16:08,455 DEBUG TRAIN Batch 0/3400 loss 193.773117 loss_att 226.194366 loss_ctc 188.838196 loss_rnnt 187.946869 lr 0.00013604 rank 3
2022-12-03 12:16:08,456 DEBUG TRAIN Batch 0/3400 loss 260.524170 loss_att 280.098145 loss_ctc 261.664551 loss_rnnt 256.457336 lr 0.00013604 rank 6
2022-12-03 12:16:08,459 DEBUG TRAIN Batch 0/3400 loss 213.484039 loss_att 241.115540 loss_ctc 219.337692 loss_rnnt 207.177246 lr 0.00013604 rank 0
2022-12-03 12:16:08,460 DEBUG TRAIN Batch 0/3400 loss 222.749435 loss_att 242.173584 loss_ctc 227.121399 loss_rnnt 218.281677 lr 0.00013604 rank 2
2022-12-03 12:16:08,462 DEBUG TRAIN Batch 0/3400 loss 247.737350 loss_att 267.618225 loss_ctc 264.011169 loss_rnnt 241.591324 lr 0.00013604 rank 1
2022-12-03 12:16:08,465 DEBUG TRAIN Batch 0/3400 loss 169.250580 loss_att 189.608002 loss_ctc 167.682343 loss_rnnt 165.388184 lr 0.00013604 rank 7
2022-12-03 12:16:08,466 DEBUG TRAIN Batch 0/3400 loss 199.284760 loss_att 229.117859 loss_ctc 190.264755 loss_rnnt 194.520813 lr 0.00013604 rank 4
2022-12-03 12:17:21,979 DEBUG TRAIN Batch 0/3500 loss 273.140564 loss_att 297.205811 loss_ctc 276.095123 loss_rnnt 267.933594 lr 0.00014004 rank 1
2022-12-03 12:17:21,994 DEBUG TRAIN Batch 0/3500 loss 246.707855 loss_att 270.265961 loss_ctc 244.963867 loss_rnnt 242.228760 lr 0.00014004 rank 6
2022-12-03 12:17:21,994 DEBUG TRAIN Batch 0/3500 loss 242.307770 loss_att 264.870453 loss_ctc 245.580551 loss_rnnt 237.358871 lr 0.00014004 rank 5
2022-12-03 12:17:21,997 DEBUG TRAIN Batch 0/3500 loss 259.455688 loss_att 280.136871 loss_ctc 256.954651 loss_rnnt 255.652939 lr 0.00014004 rank 3
2022-12-03 12:17:22,002 DEBUG TRAIN Batch 0/3500 loss 198.779755 loss_att 232.923431 loss_ctc 200.542603 loss_rnnt 191.715973 lr 0.00014004 rank 0
2022-12-03 12:17:22,038 DEBUG TRAIN Batch 0/3500 loss 231.597961 loss_att 261.194000 loss_ctc 230.490814 loss_rnnt 225.826385 lr 0.00014004 rank 2
2022-12-03 12:17:22,044 DEBUG TRAIN Batch 0/3500 loss 217.902924 loss_att 243.101440 loss_ctc 217.912842 loss_rnnt 212.861877 lr 0.00014004 rank 7
2022-12-03 12:17:22,047 DEBUG TRAIN Batch 0/3500 loss 220.801361 loss_att 247.872955 loss_ctc 218.262665 loss_rnnt 215.725525 lr 0.00014004 rank 4
2022-12-03 12:19:24,825 DEBUG TRAIN Batch 0/3600 loss 229.470947 loss_att 250.428955 loss_ctc 245.022430 loss_rnnt 223.205811 lr 0.00014404 rank 6
2022-12-03 12:19:24,827 DEBUG TRAIN Batch 0/3600 loss 245.837921 loss_att 278.444214 loss_ctc 244.449158 loss_rnnt 239.501831 lr 0.00014404 rank 5
2022-12-03 12:19:24,829 DEBUG TRAIN Batch 0/3600 loss 232.113281 loss_att 255.257965 loss_ctc 234.876953 loss_rnnt 227.115845 lr 0.00014404 rank 3
2022-12-03 12:19:24,832 DEBUG TRAIN Batch 0/3600 loss 241.626892 loss_att 271.340942 loss_ctc 249.472122 loss_rnnt 234.638046 lr 0.00014404 rank 4
2022-12-03 12:19:24,833 DEBUG TRAIN Batch 0/3600 loss 229.835114 loss_att 251.765259 loss_ctc 237.848816 loss_rnnt 224.380600 lr 0.00014404 rank 0
2022-12-03 12:19:24,836 DEBUG TRAIN Batch 0/3600 loss 205.839279 loss_att 234.565613 loss_ctc 214.578430 loss_rnnt 198.928802 lr 0.00014404 rank 1
2022-12-03 12:19:24,837 DEBUG TRAIN Batch 0/3600 loss 209.353973 loss_att 254.189468 loss_ctc 203.120117 loss_rnnt 201.218063 lr 0.00014404 rank 2
2022-12-03 12:19:24,839 DEBUG TRAIN Batch 0/3600 loss 220.686218 loss_att 259.885895 loss_ctc 218.823486 loss_rnnt 213.094635 lr 0.00014404 rank 7
2022-12-03 12:20:36,523 DEBUG TRAIN Batch 0/3700 loss 220.624985 loss_att 254.634888 loss_ctc 221.214935 loss_rnnt 213.744339 lr 0.00014804 rank 5
2022-12-03 12:20:36,524 DEBUG TRAIN Batch 0/3700 loss 139.733734 loss_att 162.865967 loss_ctc 144.504196 loss_rnnt 134.471237 lr 0.00014804 rank 1
2022-12-03 12:20:36,525 DEBUG TRAIN Batch 0/3700 loss 216.529099 loss_att 253.183807 loss_ctc 228.007095 loss_rnnt 207.667755 lr 0.00014804 rank 3
2022-12-03 12:20:36,526 DEBUG TRAIN Batch 0/3700 loss 185.000885 loss_att 217.071411 loss_ctc 184.862823 loss_rnnt 178.605194 lr 0.00014804 rank 6
2022-12-03 12:20:36,527 DEBUG TRAIN Batch 0/3700 loss 174.700516 loss_att 221.126984 loss_ctc 173.308350 loss_rnnt 165.600830 lr 0.00014804 rank 0
2022-12-03 12:20:36,527 DEBUG TRAIN Batch 0/3700 loss 189.122620 loss_att 229.012238 loss_ctc 190.488403 loss_rnnt 180.962585 lr 0.00014804 rank 2
2022-12-03 12:20:36,534 DEBUG TRAIN Batch 0/3700 loss 214.630661 loss_att 244.715393 loss_ctc 210.734467 loss_rnnt 209.133209 lr 0.00014804 rank 4
2022-12-03 12:20:36,575 DEBUG TRAIN Batch 0/3700 loss 164.177948 loss_att 208.569138 loss_ctc 167.196884 loss_rnnt 154.897171 lr 0.00014804 rank 7
2022-12-03 12:21:49,005 DEBUG TRAIN Batch 0/3800 loss 150.186600 loss_att 176.523468 loss_ctc 152.170609 loss_rnnt 144.654678 lr 0.00015204 rank 3
2022-12-03 12:21:49,009 DEBUG TRAIN Batch 0/3800 loss 64.757988 loss_att 74.176125 loss_ctc 68.199509 loss_rnnt 62.415493 lr 0.00015204 rank 1
2022-12-03 12:21:49,010 DEBUG TRAIN Batch 0/3800 loss 223.805695 loss_att 252.674530 loss_ctc 225.390869 loss_rnnt 217.820557 lr 0.00015204 rank 7
2022-12-03 12:21:49,012 DEBUG TRAIN Batch 0/3800 loss 62.525131 loss_att 70.564438 loss_ctc 65.716751 loss_rnnt 60.491722 lr 0.00015204 rank 2
2022-12-03 12:21:49,012 DEBUG TRAIN Batch 0/3800 loss 148.374756 loss_att 165.011749 loss_ctc 151.073837 loss_rnnt 144.687469 lr 0.00015204 rank 6
2022-12-03 12:21:49,014 DEBUG TRAIN Batch 0/3800 loss 136.898361 loss_att 162.802917 loss_ctc 136.781204 loss_rnnt 131.733063 lr 0.00015204 rank 0
2022-12-03 12:21:49,014 DEBUG TRAIN Batch 0/3800 loss 116.741257 loss_att 137.722382 loss_ctc 116.673416 loss_rnnt 112.554077 lr 0.00015204 rank 5
2022-12-03 12:21:49,016 DEBUG TRAIN Batch 0/3800 loss 141.678848 loss_att 173.765778 loss_ctc 148.323837 loss_rnnt 134.375458 lr 0.00015204 rank 4
2022-12-03 12:23:51,740 DEBUG TRAIN Batch 0/3900 loss 171.881454 loss_att 233.778564 loss_ctc 164.269577 loss_rnnt 160.516937 lr 0.00015604 rank 6
2022-12-03 12:23:51,741 DEBUG TRAIN Batch 0/3900 loss 247.428101 loss_att 294.270050 loss_ctc 251.749069 loss_rnnt 237.483551 lr 0.00015604 rank 5
2022-12-03 12:23:51,744 DEBUG TRAIN Batch 0/3900 loss 82.406708 loss_att 96.139397 loss_ctc 83.989441 loss_rnnt 79.449150 lr 0.00015604 rank 7
2022-12-03 12:23:51,753 DEBUG TRAIN Batch 0/3900 loss 204.379761 loss_att 250.751053 loss_ctc 195.528931 loss_rnnt 196.285629 lr 0.00015604 rank 2
2022-12-03 12:23:51,767 DEBUG TRAIN Batch 0/3900 loss 173.056702 loss_att 228.260620 loss_ctc 175.640930 loss_rnnt 161.671371 lr 0.00015604 rank 0
2022-12-03 12:23:51,773 DEBUG TRAIN Batch 0/3900 loss 224.225967 loss_att 275.807312 loss_ctc 210.694977 loss_rnnt 215.713837 lr 0.00015604 rank 3
2022-12-03 12:23:51,776 DEBUG TRAIN Batch 0/3900 loss 204.448242 loss_att 250.154877 loss_ctc 193.043304 loss_rnnt 196.827560 lr 0.00015604 rank 4
2022-12-03 12:23:51,796 DEBUG TRAIN Batch 0/3900 loss 176.374557 loss_att 233.879883 loss_ctc 173.083191 loss_rnnt 165.312347 lr 0.00015604 rank 1
2022-12-03 12:25:07,249 DEBUG TRAIN Batch 0/4000 loss 204.989685 loss_att 252.993408 loss_ctc 208.727295 loss_rnnt 194.890610 lr 0.00016004 rank 1
2022-12-03 12:25:07,251 DEBUG TRAIN Batch 0/4000 loss 200.084076 loss_att 269.692047 loss_ctc 199.067566 loss_rnnt 186.298004 lr 0.00016004 rank 5
2022-12-03 12:25:07,252 DEBUG TRAIN Batch 0/4000 loss 224.868835 loss_att 275.681763 loss_ctc 221.261963 loss_rnnt 215.187164 lr 0.00016004 rank 0
2022-12-03 12:25:07,252 DEBUG TRAIN Batch 0/4000 loss 172.658783 loss_att 227.101608 loss_ctc 170.693390 loss_rnnt 162.032257 lr 0.00016004 rank 3
2022-12-03 12:25:07,255 DEBUG TRAIN Batch 0/4000 loss 159.642609 loss_att 219.838089 loss_ctc 151.781967 loss_rnnt 148.651581 lr 0.00016004 rank 6
2022-12-03 12:25:07,255 DEBUG TRAIN Batch 0/4000 loss 233.583801 loss_att 277.475494 loss_ctc 237.439850 loss_rnnt 224.291321 lr 0.00016004 rank 4
2022-12-03 12:25:07,256 DEBUG TRAIN Batch 0/4000 loss 202.137665 loss_att 245.418060 loss_ctc 199.285004 loss_rnnt 193.861938 lr 0.00016004 rank 7
2022-12-03 12:25:07,301 DEBUG TRAIN Batch 0/4000 loss 212.034592 loss_att 264.086182 loss_ctc 212.807922 loss_rnnt 201.521164 lr 0.00016004 rank 2
2022-12-03 12:26:19,490 DEBUG TRAIN Batch 0/4100 loss 214.083359 loss_att 269.885040 loss_ctc 208.364166 loss_rnnt 203.685577 lr 0.00016404 rank 6
2022-12-03 12:26:19,492 DEBUG TRAIN Batch 0/4100 loss 212.766144 loss_att 289.746826 loss_ctc 220.972504 loss_rnnt 196.275848 lr 0.00016404 rank 0
2022-12-03 12:26:19,494 DEBUG TRAIN Batch 0/4100 loss 188.951340 loss_att 249.201843 loss_ctc 191.343506 loss_rnnt 176.582275 lr 0.00016404 rank 3
2022-12-03 12:26:19,497 DEBUG TRAIN Batch 0/4100 loss 146.363602 loss_att 197.426804 loss_ctc 142.439514 loss_rnnt 136.674179 lr 0.00016404 rank 5
2022-12-03 12:26:19,498 DEBUG TRAIN Batch 0/4100 loss 238.024826 loss_att 306.300568 loss_ctc 239.682434 loss_rnnt 224.148666 lr 0.00016404 rank 7
2022-12-03 12:26:19,498 DEBUG TRAIN Batch 0/4100 loss 184.728088 loss_att 227.420242 loss_ctc 184.195129 loss_rnnt 176.260727 lr 0.00016404 rank 4
2022-12-03 12:26:19,500 DEBUG TRAIN Batch 0/4100 loss 174.391998 loss_att 234.303741 loss_ctc 174.566711 loss_rnnt 162.386353 lr 0.00016404 rank 2
2022-12-03 12:26:19,537 DEBUG TRAIN Batch 0/4100 loss 193.987473 loss_att 245.087601 loss_ctc 189.643250 loss_rnnt 184.346680 lr 0.00016404 rank 1
2022-12-03 12:27:32,231 DEBUG TRAIN Batch 0/4200 loss 194.762909 loss_att 247.006714 loss_ctc 195.344742 loss_rnnt 184.236572 lr 0.00016804 rank 1
2022-12-03 12:27:32,232 DEBUG TRAIN Batch 0/4200 loss 202.511673 loss_att 254.801331 loss_ctc 208.918350 loss_rnnt 191.199524 lr 0.00016804 rank 5
2022-12-03 12:27:32,233 DEBUG TRAIN Batch 0/4200 loss 199.060837 loss_att 254.925201 loss_ctc 199.349030 loss_rnnt 187.849533 lr 0.00016804 rank 0
2022-12-03 12:27:32,234 DEBUG TRAIN Batch 0/4200 loss 180.845825 loss_att 246.747070 loss_ctc 178.664551 loss_rnnt 167.956406 lr 0.00016804 rank 3
2022-12-03 12:27:32,234 DEBUG TRAIN Batch 0/4200 loss 186.922913 loss_att 230.983185 loss_ctc 181.921295 loss_rnnt 178.777756 lr 0.00016804 rank 6
2022-12-03 12:27:32,235 DEBUG TRAIN Batch 0/4200 loss 208.415176 loss_att 279.525848 loss_ctc 200.376892 loss_rnnt 195.264816 lr 0.00016804 rank 7
2022-12-03 12:27:32,236 DEBUG TRAIN Batch 0/4200 loss 166.669632 loss_att 234.142639 loss_ctc 154.913055 loss_rnnt 154.742569 lr 0.00016804 rank 4
2022-12-03 12:27:32,241 DEBUG TRAIN Batch 0/4200 loss 218.687500 loss_att 283.297058 loss_ctc 224.409943 loss_rnnt 205.002609 lr 0.00016804 rank 2
2022-12-03 12:29:37,965 DEBUG TRAIN Batch 0/4300 loss 161.367035 loss_att 234.343597 loss_ctc 153.581543 loss_rnnt 147.809784 lr 0.00017204 rank 3
2022-12-03 12:29:37,965 DEBUG TRAIN Batch 0/4300 loss 199.537354 loss_att 254.002533 loss_ctc 209.329788 loss_rnnt 187.338638 lr 0.00017204 rank 6
2022-12-03 12:29:37,966 DEBUG TRAIN Batch 0/4300 loss 200.619659 loss_att 265.960175 loss_ctc 202.993423 loss_rnnt 187.235046 lr 0.00017204 rank 0
2022-12-03 12:29:37,968 DEBUG TRAIN Batch 0/4300 loss 156.402664 loss_att 215.321320 loss_ctc 152.972534 loss_rnnt 145.076279 lr 0.00017204 rank 5
2022-12-03 12:29:37,968 DEBUG TRAIN Batch 0/4300 loss 136.936691 loss_att 191.563873 loss_ctc 131.239563 loss_rnnt 126.770866 lr 0.00017204 rank 2
2022-12-03 12:29:37,969 DEBUG TRAIN Batch 0/4300 loss 139.761139 loss_att 189.380463 loss_ctc 138.039581 loss_rnnt 130.066818 lr 0.00017204 rank 1
2022-12-03 12:29:37,971 DEBUG TRAIN Batch 0/4300 loss 163.950439 loss_att 222.391495 loss_ctc 160.477295 loss_rnnt 152.725296 lr 0.00017204 rank 7
2022-12-03 12:29:37,978 DEBUG TRAIN Batch 0/4300 loss 159.215607 loss_att 225.389297 loss_ctc 155.365723 loss_rnnt 146.494171 lr 0.00017204 rank 4
2022-12-03 12:30:50,522 DEBUG TRAIN Batch 0/4400 loss 140.716660 loss_att 179.443665 loss_ctc 146.844330 loss_rnnt 132.154236 lr 0.00017604 rank 6
2022-12-03 12:30:50,524 DEBUG TRAIN Batch 0/4400 loss 165.714264 loss_att 211.523254 loss_ctc 169.710983 loss_rnnt 156.019577 lr 0.00017604 rank 0
2022-12-03 12:30:50,526 DEBUG TRAIN Batch 0/4400 loss 106.007530 loss_att 144.726395 loss_ctc 106.581360 loss_rnnt 98.187248 lr 0.00017604 rank 5
2022-12-03 12:30:50,527 DEBUG TRAIN Batch 0/4400 loss 74.094383 loss_att 100.598114 loss_ctc 74.415916 loss_rnnt 68.750763 lr 0.00017604 rank 1
2022-12-03 12:30:50,528 DEBUG TRAIN Batch 0/4400 loss 183.588425 loss_att 236.485046 loss_ctc 188.437134 loss_rnnt 172.362579 lr 0.00017604 rank 3
2022-12-03 12:30:50,531 DEBUG TRAIN Batch 0/4400 loss 95.951660 loss_att 135.472916 loss_ctc 97.283699 loss_rnnt 87.869804 lr 0.00017604 rank 2
2022-12-03 12:30:50,531 DEBUG TRAIN Batch 0/4400 loss 177.753601 loss_att 236.435287 loss_ctc 175.150360 loss_rnnt 166.364380 lr 0.00017604 rank 7
2022-12-03 12:30:50,538 DEBUG TRAIN Batch 0/4400 loss 172.788483 loss_att 225.181885 loss_ctc 175.348053 loss_rnnt 161.968521 lr 0.00017604 rank 4
2022-12-03 12:32:03,036 DEBUG TRAIN Batch 0/4500 loss 222.487808 loss_att 290.952881 loss_ctc 217.556396 loss_rnnt 209.452301 lr 0.00018004 rank 6
2022-12-03 12:32:03,037 DEBUG TRAIN Batch 0/4500 loss 172.680588 loss_att 253.404099 loss_ctc 177.930328 loss_rnnt 155.835907 lr 0.00018004 rank 5
2022-12-03 12:32:03,037 DEBUG TRAIN Batch 0/4500 loss 147.380524 loss_att 226.940552 loss_ctc 137.260544 loss_rnnt 132.817841 lr 0.00018004 rank 2
2022-12-03 12:32:03,041 DEBUG TRAIN Batch 0/4500 loss 100.759346 loss_att 132.043518 loss_ctc 96.767464 loss_rnnt 95.034760 lr 0.00018004 rank 3
2022-12-03 12:32:03,041 DEBUG TRAIN Batch 0/4500 loss 59.182674 loss_att 86.243919 loss_ctc 57.560635 loss_rnnt 53.986694 lr 0.00018004 rank 0
2022-12-03 12:32:03,044 DEBUG TRAIN Batch 0/4500 loss 177.487335 loss_att 252.884552 loss_ctc 181.641907 loss_rnnt 161.853943 lr 0.00018004 rank 1
2022-12-03 12:32:03,055 DEBUG TRAIN Batch 0/4500 loss 67.465225 loss_att 94.484116 loss_ctc 66.116173 loss_rnnt 62.241322 lr 0.00018004 rank 4
2022-12-03 12:32:03,085 DEBUG TRAIN Batch 0/4500 loss 110.788376 loss_att 149.207916 loss_ctc 107.828568 loss_rnnt 103.499100 lr 0.00018004 rank 7
2022-12-03 12:33:16,339 DEBUG TRAIN Batch 0/4600 loss 189.335236 loss_att 258.485565 loss_ctc 184.113983 loss_rnnt 176.201340 lr 0.00018404 rank 6
2022-12-03 12:33:16,342 DEBUG TRAIN Batch 0/4600 loss 204.118698 loss_att 279.698059 loss_ctc 202.089111 loss_rnnt 189.273438 lr 0.00018404 rank 1
2022-12-03 12:33:16,345 DEBUG TRAIN Batch 0/4600 loss 169.967255 loss_att 258.700714 loss_ctc 164.248016 loss_rnnt 152.983139 lr 0.00018404 rank 0
2022-12-03 12:33:16,346 DEBUG TRAIN Batch 0/4600 loss 179.284470 loss_att 267.930420 loss_ctc 168.812073 loss_rnnt 162.951599 lr 0.00018404 rank 3
2022-12-03 12:33:16,348 DEBUG TRAIN Batch 0/4600 loss 184.538055 loss_att 265.564331 loss_ctc 178.192749 loss_rnnt 169.178833 lr 0.00018404 rank 7
2022-12-03 12:33:16,353 DEBUG TRAIN Batch 0/4600 loss 137.533401 loss_att 219.473175 loss_ctc 138.392380 loss_rnnt 121.030914 lr 0.00018404 rank 2
2022-12-03 12:33:16,354 DEBUG TRAIN Batch 0/4600 loss 168.087463 loss_att 297.398163 loss_ctc 165.390991 loss_rnnt 142.584839 lr 0.00018404 rank 4
2022-12-03 12:33:16,358 DEBUG TRAIN Batch 0/4600 loss 169.286530 loss_att 256.099487 loss_ctc 162.339722 loss_rnnt 152.850174 lr 0.00018404 rank 5
2022-12-03 12:35:19,644 DEBUG TRAIN Batch 0/4700 loss 138.011383 loss_att 223.584259 loss_ctc 127.863747 loss_rnnt 122.249825 lr 0.00018804 rank 6
2022-12-03 12:35:19,645 DEBUG TRAIN Batch 0/4700 loss 177.887436 loss_att 256.446930 loss_ctc 173.405090 loss_rnnt 162.773178 lr 0.00018804 rank 5
2022-12-03 12:35:19,646 DEBUG TRAIN Batch 0/4700 loss 136.057861 loss_att 213.502106 loss_ctc 128.947784 loss_rnnt 121.517029 lr 0.00018804 rank 3
2022-12-03 12:35:19,648 DEBUG TRAIN Batch 0/4700 loss 176.257751 loss_att 247.918884 loss_ctc 176.171860 loss_rnnt 161.936981 lr 0.00018804 rank 1
2022-12-03 12:35:19,654 DEBUG TRAIN Batch 0/4700 loss 163.488312 loss_att 253.558563 loss_ctc 160.923431 loss_rnnt 145.816238 lr 0.00018804 rank 0
2022-12-03 12:35:19,657 DEBUG TRAIN Batch 0/4700 loss 139.966675 loss_att 214.588470 loss_ctc 136.116394 loss_rnnt 125.555687 lr 0.00018804 rank 7
2022-12-03 12:35:19,658 DEBUG TRAIN Batch 0/4700 loss 206.233643 loss_att 310.922913 loss_ctc 207.367447 loss_rnnt 185.144623 lr 0.00018804 rank 2
2022-12-03 12:35:19,659 DEBUG TRAIN Batch 0/4700 loss 149.421265 loss_att 224.579620 loss_ctc 145.652573 loss_rnnt 134.892090 lr 0.00018804 rank 4
2022-12-03 12:36:31,241 DEBUG TRAIN Batch 0/4800 loss 145.241837 loss_att 236.073837 loss_ctc 136.416183 loss_rnnt 128.252197 lr 0.00019204 rank 0
2022-12-03 12:36:31,241 DEBUG TRAIN Batch 0/4800 loss 150.774292 loss_att 233.282104 loss_ctc 142.861755 loss_rnnt 135.327728 lr 0.00019204 rank 5
2022-12-03 12:36:31,242 DEBUG TRAIN Batch 0/4800 loss 209.085342 loss_att 299.019958 loss_ctc 211.662079 loss_rnnt 190.754852 lr 0.00019204 rank 3
2022-12-03 12:36:31,242 DEBUG TRAIN Batch 0/4800 loss 190.468964 loss_att 269.626312 loss_ctc 199.672821 loss_rnnt 173.410324 lr 0.00019204 rank 1
2022-12-03 12:36:31,244 DEBUG TRAIN Batch 0/4800 loss 127.545937 loss_att 197.795059 loss_ctc 124.261147 loss_rnnt 113.934082 lr 0.00019204 rank 6
2022-12-03 12:36:31,245 DEBUG TRAIN Batch 0/4800 loss 129.068237 loss_att 194.407013 loss_ctc 122.192734 loss_rnnt 116.917206 lr 0.00019204 rank 2
2022-12-03 12:36:31,246 DEBUG TRAIN Batch 0/4800 loss 136.802460 loss_att 204.352310 loss_ctc 131.922775 loss_rnnt 123.943115 lr 0.00019204 rank 7
2022-12-03 12:36:31,258 DEBUG TRAIN Batch 0/4800 loss 195.305695 loss_att 278.117584 loss_ctc 206.666473 loss_rnnt 177.228561 lr 0.00019204 rank 4
2022-12-03 12:37:43,645 DEBUG TRAIN Batch 0/4900 loss 170.566315 loss_att 257.232941 loss_ctc 172.867935 loss_rnnt 152.926102 lr 0.00019604 rank 0
2022-12-03 12:37:43,648 DEBUG TRAIN Batch 0/4900 loss 152.267990 loss_att 225.479248 loss_ctc 150.363342 loss_rnnt 137.879700 lr 0.00019604 rank 3
2022-12-03 12:37:43,647 DEBUG TRAIN Batch 0/4900 loss 154.160248 loss_att 220.295746 loss_ctc 148.128296 loss_rnnt 141.737396 lr 0.00019604 rank 2
2022-12-03 12:37:43,648 DEBUG TRAIN Batch 0/4900 loss 145.214478 loss_att 207.813507 loss_ctc 144.554749 loss_rnnt 132.782623 lr 0.00019604 rank 5
2022-12-03 12:37:43,649 DEBUG TRAIN Batch 0/4900 loss 152.471390 loss_att 234.019684 loss_ctc 150.188568 loss_rnnt 136.466095 lr 0.00019604 rank 6
2022-12-03 12:37:43,650 DEBUG TRAIN Batch 0/4900 loss 115.064354 loss_att 191.214172 loss_ctc 113.292747 loss_rnnt 100.070602 lr 0.00019604 rank 1
2022-12-03 12:37:43,654 DEBUG TRAIN Batch 0/4900 loss 166.784454 loss_att 247.088348 loss_ctc 166.651550 loss_rnnt 150.741394 lr 0.00019604 rank 7
2022-12-03 12:37:43,654 DEBUG TRAIN Batch 0/4900 loss 181.953430 loss_att 271.997528 loss_ctc 184.467438 loss_rnnt 163.609406 lr 0.00019604 rank 4
2022-12-03 12:39:49,897 DEBUG TRAIN Batch 0/5000 loss 103.064880 loss_att 157.426971 loss_ctc 101.647156 loss_rnnt 92.381493 lr 0.00020004 rank 5
2022-12-03 12:39:49,898 DEBUG TRAIN Batch 0/5000 loss 112.681557 loss_att 194.764008 loss_ctc 107.052238 loss_rnnt 97.015640 lr 0.00020004 rank 6
2022-12-03 12:39:49,898 DEBUG TRAIN Batch 0/5000 loss 88.577637 loss_att 135.222244 loss_ctc 89.836082 loss_rnnt 79.080917 lr 0.00020004 rank 1
2022-12-03 12:39:49,899 DEBUG TRAIN Batch 0/5000 loss 173.890839 loss_att 229.709717 loss_ctc 181.419556 loss_rnnt 161.723221 lr 0.00020004 rank 3
2022-12-03 12:39:49,901 DEBUG TRAIN Batch 0/5000 loss 158.929672 loss_att 260.936188 loss_ctc 160.156311 loss_rnnt 138.364807 lr 0.00020004 rank 7
2022-12-03 12:39:49,902 DEBUG TRAIN Batch 0/5000 loss 173.159653 loss_att 262.775177 loss_ctc 171.532562 loss_rnnt 155.453491 lr 0.00020004 rank 4
2022-12-03 12:39:49,905 DEBUG TRAIN Batch 0/5000 loss 154.410950 loss_att 225.902252 loss_ctc 150.156281 loss_rnnt 140.679993 lr 0.00020004 rank 0
2022-12-03 12:39:49,953 DEBUG TRAIN Batch 0/5000 loss 120.868050 loss_att 199.572830 loss_ctc 112.987877 loss_rnnt 106.177773 lr 0.00020004 rank 2
2022-12-03 12:41:01,608 DEBUG TRAIN Batch 0/5100 loss 136.925308 loss_att 241.146057 loss_ctc 133.915009 loss_rnnt 116.482529 lr 0.00020404 rank 2
2022-12-03 12:41:01,619 DEBUG TRAIN Batch 0/5100 loss 126.791634 loss_att 184.359512 loss_ctc 127.781471 loss_rnnt 115.146072 lr 0.00020404 rank 3
2022-12-03 12:41:01,621 DEBUG TRAIN Batch 0/5100 loss 115.481911 loss_att 180.159546 loss_ctc 111.331963 loss_rnnt 103.099709 lr 0.00020404 rank 0
2022-12-03 12:41:01,622 DEBUG TRAIN Batch 0/5100 loss 147.832474 loss_att 247.776291 loss_ctc 152.354767 loss_rnnt 127.240746 lr 0.00020404 rank 5
2022-12-03 12:41:01,621 DEBUG TRAIN Batch 0/5100 loss 46.552998 loss_att 61.525639 loss_ctc 47.568153 loss_rnnt 43.423111 lr 0.00020404 rank 6
2022-12-03 12:41:01,623 DEBUG TRAIN Batch 0/5100 loss 84.834595 loss_att 124.772865 loss_ctc 89.039726 loss_rnnt 76.286255 lr 0.00020404 rank 4
2022-12-03 12:41:01,624 DEBUG TRAIN Batch 0/5100 loss 92.582413 loss_att 156.592636 loss_ctc 89.735924 loss_rnnt 80.159897 lr 0.00020404 rank 7
2022-12-03 12:41:01,666 DEBUG TRAIN Batch 0/5100 loss 221.499634 loss_att 308.336334 loss_ctc 242.904694 loss_rnnt 201.278290 lr 0.00020404 rank 1
2022-12-03 12:42:13,528 DEBUG TRAIN Batch 0/5200 loss 124.291962 loss_att 231.342026 loss_ctc 113.597427 loss_rnnt 104.307884 lr 0.00020804 rank 1
2022-12-03 12:42:13,540 DEBUG TRAIN Batch 0/5200 loss 127.811783 loss_att 210.713165 loss_ctc 129.558746 loss_rnnt 110.998581 lr 0.00020804 rank 6
2022-12-03 12:42:13,540 DEBUG TRAIN Batch 0/5200 loss 158.680878 loss_att 251.389847 loss_ctc 151.905823 loss_rnnt 141.042419 lr 0.00020804 rank 3
2022-12-03 12:42:13,543 DEBUG TRAIN Batch 0/5200 loss 54.186131 loss_att 83.846870 loss_ctc 54.808670 loss_rnnt 48.170979 lr 0.00020804 rank 0
2022-12-03 12:42:13,545 DEBUG TRAIN Batch 0/5200 loss 177.110733 loss_att 276.089294 loss_ctc 177.228149 loss_rnnt 157.299377 lr 0.00020804 rank 2
2022-12-03 12:42:13,544 DEBUG TRAIN Batch 0/5200 loss 170.735077 loss_att 276.152557 loss_ctc 170.017303 loss_rnnt 149.747284 lr 0.00020804 rank 7
2022-12-03 12:42:13,545 DEBUG TRAIN Batch 0/5200 loss 132.508057 loss_att 223.201294 loss_ctc 128.824875 loss_rnnt 114.860519 lr 0.00020804 rank 5
2022-12-03 12:42:13,554 DEBUG TRAIN Batch 0/5200 loss 134.003723 loss_att 201.651657 loss_ctc 130.450470 loss_rnnt 120.947899 lr 0.00020804 rank 4
2022-12-03 12:43:27,053 DEBUG TRAIN Batch 0/5300 loss 165.261917 loss_att 261.649902 loss_ctc 167.926239 loss_rnnt 145.629074 lr 0.00021204 rank 5
2022-12-03 12:43:27,059 DEBUG TRAIN Batch 0/5300 loss 119.190628 loss_att 241.064331 loss_ctc 109.751793 loss_rnnt 96.074394 lr 0.00021204 rank 7
2022-12-03 12:43:27,065 DEBUG TRAIN Batch 0/5300 loss 133.515350 loss_att 226.520477 loss_ctc 131.887817 loss_rnnt 115.131332 lr 0.00021204 rank 6
2022-12-03 12:43:27,066 DEBUG TRAIN Batch 0/5300 loss 130.971512 loss_att 251.313553 loss_ctc 124.588913 loss_rnnt 107.754112 lr 0.00021204 rank 0
2022-12-03 12:43:27,067 DEBUG TRAIN Batch 0/5300 loss 160.431473 loss_att 275.779175 loss_ctc 159.931747 loss_rnnt 137.428558 lr 0.00021204 rank 3
2022-12-03 12:43:27,077 DEBUG TRAIN Batch 0/5300 loss 133.026230 loss_att 226.332047 loss_ctc 130.405807 loss_rnnt 114.714462 lr 0.00021204 rank 4
2022-12-03 12:43:27,080 DEBUG TRAIN Batch 0/5300 loss 199.651505 loss_att 288.878876 loss_ctc 204.815399 loss_rnnt 181.117523 lr 0.00021204 rank 1
2022-12-03 12:43:27,085 DEBUG TRAIN Batch 0/5300 loss 129.923126 loss_att 225.046799 loss_ctc 124.881653 loss_rnnt 111.570587 lr 0.00021204 rank 2
2022-12-03 12:45:32,033 DEBUG TRAIN Batch 0/5400 loss 97.645020 loss_att 199.126892 loss_ctc 93.121811 loss_rnnt 77.951736 lr 0.00021604 rank 6
2022-12-03 12:45:32,036 DEBUG TRAIN Batch 0/5400 loss 172.151062 loss_att 264.300323 loss_ctc 165.349030 loss_rnnt 154.628159 lr 0.00021604 rank 0
2022-12-03 12:45:32,038 DEBUG TRAIN Batch 0/5400 loss 153.505249 loss_att 247.545593 loss_ctc 152.850311 loss_rnnt 134.784500 lr 0.00021604 rank 5
2022-12-03 12:45:32,042 DEBUG TRAIN Batch 0/5400 loss 167.220016 loss_att 255.504837 loss_ctc 174.660706 loss_rnnt 148.570953 lr 0.00021604 rank 3
2022-12-03 12:45:32,042 DEBUG TRAIN Batch 0/5400 loss 138.022568 loss_att 228.402008 loss_ctc 132.444092 loss_rnnt 120.690475 lr 0.00021604 rank 1
2022-12-03 12:45:32,043 DEBUG TRAIN Batch 0/5400 loss 156.305511 loss_att 276.459259 loss_ctc 150.018951 loss_rnnt 133.112976 lr 0.00021604 rank 4
2022-12-03 12:45:32,043 DEBUG TRAIN Batch 0/5400 loss 134.700241 loss_att 232.620941 loss_ctc 132.530884 loss_rnnt 115.405342 lr 0.00021604 rank 7
2022-12-03 12:45:32,056 DEBUG TRAIN Batch 0/5400 loss 128.087555 loss_att 229.107605 loss_ctc 121.627731 loss_rnnt 108.744843 lr 0.00021604 rank 2
2022-12-03 12:46:43,962 DEBUG TRAIN Batch 0/5500 loss 142.659515 loss_att 242.435501 loss_ctc 140.005753 loss_rnnt 123.058151 lr 0.00022004 rank 3
2022-12-03 12:46:43,963 DEBUG TRAIN Batch 0/5500 loss 132.087021 loss_att 223.772812 loss_ctc 126.433609 loss_rnnt 114.503639 lr 0.00022004 rank 0
2022-12-03 12:46:43,964 DEBUG TRAIN Batch 0/5500 loss 113.917908 loss_att 220.555038 loss_ctc 111.195244 loss_rnnt 92.953514 lr 0.00022004 rank 1
2022-12-03 12:46:43,965 DEBUG TRAIN Batch 0/5500 loss 80.659805 loss_att 178.549438 loss_ctc 71.491356 loss_rnnt 62.304344 lr 0.00022004 rank 5
2022-12-03 12:46:43,969 DEBUG TRAIN Batch 0/5500 loss 152.905853 loss_att 256.872437 loss_ctc 147.170502 loss_rnnt 132.877243 lr 0.00022004 rank 6
2022-12-03 12:46:43,971 DEBUG TRAIN Batch 0/5500 loss 138.942322 loss_att 245.230042 loss_ctc 145.615479 loss_rnnt 116.795013 lr 0.00022004 rank 2
2022-12-03 12:46:43,984 DEBUG TRAIN Batch 0/5500 loss 145.380463 loss_att 232.378174 loss_ctc 143.323959 loss_rnnt 128.255127 lr 0.00022004 rank 4
2022-12-03 12:46:44,012 DEBUG TRAIN Batch 0/5500 loss 113.402351 loss_att 225.085175 loss_ctc 98.701416 loss_rnnt 93.025909 lr 0.00022004 rank 7
2022-12-03 12:47:56,752 DEBUG TRAIN Batch 0/5600 loss 95.418335 loss_att 187.971420 loss_ctc 88.389938 loss_rnnt 77.844833 lr 0.00022404 rank 6
2022-12-03 12:47:56,753 DEBUG TRAIN Batch 0/5600 loss 113.788925 loss_att 201.534882 loss_ctc 106.323303 loss_rnnt 97.235153 lr 0.00022404 rank 4
2022-12-03 12:47:56,754 DEBUG TRAIN Batch 0/5600 loss 129.542297 loss_att 221.765717 loss_ctc 130.189133 loss_rnnt 111.011375 lr 0.00022404 rank 5
2022-12-03 12:47:56,754 DEBUG TRAIN Batch 0/5600 loss 131.804840 loss_att 235.875977 loss_ctc 137.253326 loss_rnnt 110.264145 lr 0.00022404 rank 0
2022-12-03 12:47:56,759 DEBUG TRAIN Batch 0/5600 loss 99.751381 loss_att 188.714096 loss_ctc 92.507004 loss_rnnt 82.924759 lr 0.00022404 rank 3
2022-12-03 12:47:56,775 DEBUG TRAIN Batch 0/5600 loss 85.899460 loss_att 150.130310 loss_ctc 82.191818 loss_rnnt 73.547646 lr 0.00022404 rank 1
2022-12-03 12:47:56,776 DEBUG TRAIN Batch 0/5600 loss 85.146263 loss_att 176.268524 loss_ctc 86.033981 loss_rnnt 66.803452 lr 0.00022404 rank 7
2022-12-03 12:47:56,799 DEBUG TRAIN Batch 0/5600 loss 133.196060 loss_att 215.244415 loss_ctc 141.896423 loss_rnnt 115.626343 lr 0.00022404 rank 2
2022-12-03 12:50:04,741 DEBUG TRAIN Batch 0/5700 loss 51.103058 loss_att 93.127029 loss_ctc 50.823833 loss_rnnt 42.735493 lr 0.00022804 rank 6
2022-12-03 12:50:04,744 DEBUG TRAIN Batch 0/5700 loss 148.304169 loss_att 228.381165 loss_ctc 154.151169 loss_rnnt 131.509171 lr 0.00022804 rank 3
2022-12-03 12:50:04,745 DEBUG TRAIN Batch 0/5700 loss 154.015656 loss_att 241.298904 loss_ctc 160.752625 loss_rnnt 135.660736 lr 0.00022804 rank 0
2022-12-03 12:50:04,746 DEBUG TRAIN Batch 0/5700 loss 117.942131 loss_att 205.361313 loss_ctc 116.968239 loss_rnnt 100.588142 lr 0.00022804 rank 7
2022-12-03 12:50:04,753 DEBUG TRAIN Batch 0/5700 loss 76.806442 loss_att 158.250412 loss_ctc 73.350067 loss_rnnt 60.978493 lr 0.00022804 rank 4
2022-12-03 12:50:04,770 DEBUG TRAIN Batch 0/5700 loss 133.995590 loss_att 257.263153 loss_ctc 126.667725 loss_rnnt 110.319138 lr 0.00022804 rank 1
2022-12-03 12:50:04,774 DEBUG TRAIN Batch 0/5700 loss 39.735588 loss_att 59.873253 loss_ctc 40.246059 loss_rnnt 35.639992 lr 0.00022804 rank 5
2022-12-03 12:50:04,794 DEBUG TRAIN Batch 0/5700 loss 61.703506 loss_att 115.506012 loss_ctc 59.108280 loss_rnnt 51.289036 lr 0.00022804 rank 2
2022-12-03 12:51:16,876 DEBUG TRAIN Batch 0/5800 loss 56.739235 loss_att 101.884445 loss_ctc 54.546013 loss_rnnt 48.002621 lr 0.00023204 rank 3
2022-12-03 12:51:16,878 DEBUG TRAIN Batch 0/5800 loss 98.542198 loss_att 204.843979 loss_ctc 90.398155 loss_rnnt 78.367706 lr 0.00023204 rank 5
2022-12-03 12:51:16,879 DEBUG TRAIN Batch 0/5800 loss 33.245682 loss_att 45.345623 loss_ctc 34.644684 loss_rnnt 30.639160 lr 0.00023204 rank 4
2022-12-03 12:51:16,880 DEBUG TRAIN Batch 0/5800 loss 139.082733 loss_att 258.332092 loss_ctc 135.028976 loss_rnnt 115.773369 lr 0.00023204 rank 6
2022-12-03 12:51:16,880 DEBUG TRAIN Batch 0/5800 loss 64.932709 loss_att 93.577782 loss_ctc 66.511955 loss_rnnt 58.993122 lr 0.00023204 rank 7
2022-12-03 12:51:16,883 DEBUG TRAIN Batch 0/5800 loss 84.605476 loss_att 125.215286 loss_ctc 86.542519 loss_rnnt 76.225235 lr 0.00023204 rank 0
2022-12-03 12:51:16,883 DEBUG TRAIN Batch 0/5800 loss 108.598984 loss_att 221.171844 loss_ctc 93.795303 loss_rnnt 88.058228 lr 0.00023204 rank 1
2022-12-03 12:51:16,889 DEBUG TRAIN Batch 0/5800 loss 134.521515 loss_att 254.652435 loss_ctc 131.046356 loss_rnnt 110.958679 lr 0.00023204 rank 2
2022-12-03 12:52:28,242 DEBUG TRAIN Batch 0/5900 loss 166.492065 loss_att 293.871948 loss_ctc 165.025665 loss_rnnt 141.211609 lr 0.00023604 rank 6
2022-12-03 12:52:28,247 DEBUG TRAIN Batch 0/5900 loss 123.910172 loss_att 243.454346 loss_ctc 113.028702 loss_rnnt 101.452194 lr 0.00023604 rank 7
2022-12-03 12:52:28,248 DEBUG TRAIN Batch 0/5900 loss 124.434845 loss_att 236.838531 loss_ctc 118.466370 loss_rnnt 102.749908 lr 0.00023604 rank 5
2022-12-03 12:52:28,251 DEBUG TRAIN Batch 0/5900 loss 104.281418 loss_att 202.004761 loss_ctc 94.663803 loss_rnnt 86.019104 lr 0.00023604 rank 0
2022-12-03 12:52:28,252 DEBUG TRAIN Batch 0/5900 loss 139.772354 loss_att 257.202179 loss_ctc 135.680115 loss_rnnt 116.832024 lr 0.00023604 rank 3
2022-12-03 12:52:28,253 DEBUG TRAIN Batch 0/5900 loss 131.878922 loss_att 254.696411 loss_ctc 133.308212 loss_rnnt 107.124863 lr 0.00023604 rank 1
2022-12-03 12:52:28,279 DEBUG TRAIN Batch 0/5900 loss 151.583679 loss_att 258.956909 loss_ctc 149.866150 loss_rnnt 130.338043 lr 0.00023604 rank 2
2022-12-03 12:52:28,295 DEBUG TRAIN Batch 0/5900 loss 133.325043 loss_att 252.421021 loss_ctc 138.597290 loss_rnnt 108.802879 lr 0.00023604 rank 4
2022-12-03 12:53:41,080 DEBUG TRAIN Batch 0/6000 loss 113.575874 loss_att 230.887146 loss_ctc 114.167252 loss_rnnt 90.034775 lr 0.00024004 rank 1
2022-12-03 12:53:41,086 DEBUG TRAIN Batch 0/6000 loss 79.234261 loss_att 192.844910 loss_ctc 74.294815 loss_rnnt 57.170723 lr 0.00024004 rank 0
2022-12-03 12:53:41,086 DEBUG TRAIN Batch 0/6000 loss 93.173149 loss_att 213.934692 loss_ctc 82.830612 loss_rnnt 70.399841 lr 0.00024004 rank 3
2022-12-03 12:53:41,087 DEBUG TRAIN Batch 0/6000 loss 116.165932 loss_att 215.361511 loss_ctc 110.399384 loss_rnnt 97.095688 lr 0.00024004 rank 6
2022-12-03 12:53:41,088 DEBUG TRAIN Batch 0/6000 loss 146.816559 loss_att 240.767639 loss_ctc 144.679245 loss_rnnt 128.311310 lr 0.00024004 rank 2
2022-12-03 12:53:41,089 DEBUG TRAIN Batch 0/6000 loss 127.172501 loss_att 229.129486 loss_ctc 132.651733 loss_rnnt 106.050537 lr 0.00024004 rank 7
2022-12-03 12:53:41,090 DEBUG TRAIN Batch 0/6000 loss 103.199692 loss_att 221.796326 loss_ctc 99.486359 loss_rnnt 79.975479 lr 0.00024004 rank 5
2022-12-03 12:53:41,092 DEBUG TRAIN Batch 0/6000 loss 90.670013 loss_att 213.122604 loss_ctc 78.957085 loss_rnnt 67.741211 lr 0.00024004 rank 4
2022-12-03 12:55:46,149 DEBUG TRAIN Batch 0/6100 loss 110.545235 loss_att 217.377258 loss_ctc 108.706932 loss_rnnt 89.423943 lr 0.00024404 rank 3
2022-12-03 12:55:46,150 DEBUG TRAIN Batch 0/6100 loss 115.981583 loss_att 232.875763 loss_ctc 104.973892 loss_rnnt 94.070435 lr 0.00024404 rank 1
2022-12-03 12:55:46,151 DEBUG TRAIN Batch 0/6100 loss 132.251465 loss_att 251.705780 loss_ctc 131.309357 loss_rnnt 108.486221 lr 0.00024404 rank 5
2022-12-03 12:55:46,152 DEBUG TRAIN Batch 0/6100 loss 114.170135 loss_att 233.767517 loss_ctc 111.545990 loss_rnnt 90.600540 lr 0.00024404 rank 0
2022-12-03 12:55:46,152 DEBUG TRAIN Batch 0/6100 loss 132.011612 loss_att 254.400101 loss_ctc 136.199661 loss_rnnt 106.975510 lr 0.00024404 rank 7
2022-12-03 12:55:46,153 DEBUG TRAIN Batch 0/6100 loss 127.270126 loss_att 221.630310 loss_ctc 124.389313 loss_rnnt 108.782181 lr 0.00024404 rank 6
2022-12-03 12:55:46,163 DEBUG TRAIN Batch 0/6100 loss 109.145264 loss_att 231.884125 loss_ctc 105.209564 loss_rnnt 85.122246 lr 0.00024404 rank 4
2022-12-03 12:55:46,198 DEBUG TRAIN Batch 0/6100 loss 97.132973 loss_att 216.605835 loss_ctc 94.489273 loss_rnnt 73.590897 lr 0.00024404 rank 2
2022-12-03 12:56:58,182 DEBUG TRAIN Batch 0/6200 loss 86.152634 loss_att 198.036728 loss_ctc 83.559036 loss_rnnt 64.121628 lr 0.00024804 rank 0
2022-12-03 12:56:58,184 DEBUG TRAIN Batch 0/6200 loss 116.470215 loss_att 209.972610 loss_ctc 117.778900 loss_rnnt 97.595238 lr 0.00024804 rank 5
2022-12-03 12:56:58,185 DEBUG TRAIN Batch 0/6200 loss 115.258766 loss_att 205.653214 loss_ctc 115.647705 loss_rnnt 97.128014 lr 0.00024804 rank 6
2022-12-03 12:56:58,186 DEBUG TRAIN Batch 0/6200 loss 120.238365 loss_att 230.568085 loss_ctc 114.065125 loss_rnnt 98.995522 lr 0.00024804 rank 3
2022-12-03 12:56:58,189 DEBUG TRAIN Batch 0/6200 loss 96.574020 loss_att 198.967056 loss_ctc 93.522736 loss_rnnt 76.502251 lr 0.00024804 rank 1
2022-12-03 12:56:58,193 DEBUG TRAIN Batch 0/6200 loss 143.588043 loss_att 220.452301 loss_ctc 149.194855 loss_rnnt 127.467606 lr 0.00024804 rank 7
2022-12-03 12:56:58,226 DEBUG TRAIN Batch 0/6200 loss 131.582367 loss_att 231.335327 loss_ctc 142.305252 loss_rnnt 110.202057 lr 0.00024804 rank 4
2022-12-03 12:56:58,229 DEBUG TRAIN Batch 0/6200 loss 101.930923 loss_att 212.368668 loss_ctc 92.092102 loss_rnnt 81.155212 lr 0.00024804 rank 2
2022-12-03 12:58:10,638 DEBUG TRAIN Batch 0/6300 loss 69.786652 loss_att 140.713760 loss_ctc 68.497101 loss_rnnt 55.773174 lr 0.00025204 rank 6
2022-12-03 12:58:10,639 DEBUG TRAIN Batch 0/6300 loss 83.476959 loss_att 154.038254 loss_ctc 87.127975 loss_rnnt 68.877892 lr 0.00025204 rank 5
2022-12-03 12:58:10,639 DEBUG TRAIN Batch 0/6300 loss 85.397476 loss_att 175.770248 loss_ctc 83.686813 loss_rnnt 67.551010 lr 0.00025204 rank 3
2022-12-03 12:58:10,639 DEBUG TRAIN Batch 0/6300 loss 168.833603 loss_att 262.020325 loss_ctc 173.057739 loss_rnnt 149.633026 lr 0.00025204 rank 0
2022-12-03 12:58:10,640 DEBUG TRAIN Batch 0/6300 loss 56.580841 loss_att 90.669250 loss_ctc 56.443108 loss_rnnt 49.781525 lr 0.00025204 rank 1
2022-12-03 12:58:10,640 DEBUG TRAIN Batch 0/6300 loss 83.340065 loss_att 168.956100 loss_ctc 83.706383 loss_rnnt 66.168015 lr 0.00025204 rank 2
2022-12-03 12:58:10,646 DEBUG TRAIN Batch 0/6300 loss 87.734169 loss_att 181.529633 loss_ctc 85.103752 loss_rnnt 69.325798 lr 0.00025204 rank 4
2022-12-03 12:58:10,697 DEBUG TRAIN Batch 0/6300 loss 129.025391 loss_att 226.635895 loss_ctc 135.110626 loss_rnnt 108.691940 lr 0.00025204 rank 7
2022-12-03 13:00:17,552 DEBUG TRAIN Batch 0/6400 loss 62.547638 loss_att 110.900284 loss_ctc 61.493729 loss_rnnt 53.017632 lr 0.00025604 rank 3
2022-12-03 13:00:17,553 DEBUG TRAIN Batch 0/6400 loss 136.425797 loss_att 261.724182 loss_ctc 123.415710 loss_rnnt 113.100800 lr 0.00025604 rank 6
2022-12-03 13:00:17,556 DEBUG TRAIN Batch 0/6400 loss 89.598328 loss_att 171.355499 loss_ctc 86.505768 loss_rnnt 73.659233 lr 0.00025604 rank 0
2022-12-03 13:00:17,559 DEBUG TRAIN Batch 0/6400 loss 67.690247 loss_att 124.707870 loss_ctc 65.535980 loss_rnnt 56.573967 lr 0.00025604 rank 4
2022-12-03 13:00:17,558 DEBUG TRAIN Batch 0/6400 loss 109.407532 loss_att 222.657806 loss_ctc 105.107773 loss_rnnt 87.330772 lr 0.00025604 rank 1
2022-12-03 13:00:17,564 DEBUG TRAIN Batch 0/6400 loss 101.675430 loss_att 172.478149 loss_ctc 102.168884 loss_rnnt 87.449089 lr 0.00025604 rank 7
2022-12-03 13:00:17,563 DEBUG TRAIN Batch 0/6400 loss 42.484383 loss_att 72.113182 loss_ctc 43.348534 loss_rnnt 36.443401 lr 0.00025604 rank 2
2022-12-03 13:00:17,614 DEBUG TRAIN Batch 0/6400 loss 156.666016 loss_att 293.280670 loss_ctc 158.676285 loss_rnnt 129.075043 lr 0.00025604 rank 5
2022-12-03 13:01:29,400 DEBUG TRAIN Batch 0/6500 loss 142.467422 loss_att 241.723618 loss_ctc 138.957077 loss_rnnt 123.084229 lr 0.00026004 rank 3
2022-12-03 13:01:29,403 DEBUG TRAIN Batch 0/6500 loss 100.339821 loss_att 196.247162 loss_ctc 89.971611 loss_rnnt 82.540779 lr 0.00026004 rank 1
2022-12-03 13:01:29,402 DEBUG TRAIN Batch 0/6500 loss 104.985107 loss_att 211.575745 loss_ctc 91.858078 loss_rnnt 85.417259 lr 0.00026004 rank 2
2022-12-03 13:01:29,402 DEBUG TRAIN Batch 0/6500 loss 89.667969 loss_att 207.308975 loss_ctc 89.146164 loss_rnnt 66.209335 lr 0.00026004 rank 6
2022-12-03 13:01:29,405 DEBUG TRAIN Batch 0/6500 loss 119.152718 loss_att 247.251282 loss_ctc 117.188614 loss_rnnt 93.794876 lr 0.00026004 rank 0
2022-12-03 13:01:29,407 DEBUG TRAIN Batch 0/6500 loss 108.192215 loss_att 211.287628 loss_ctc 111.679398 loss_rnnt 87.108170 lr 0.00026004 rank 5
2022-12-03 13:01:29,409 DEBUG TRAIN Batch 0/6500 loss 126.445282 loss_att 230.377853 loss_ctc 124.587639 loss_rnnt 105.906456 lr 0.00026004 rank 7
2022-12-03 13:01:29,415 DEBUG TRAIN Batch 0/6500 loss 111.586327 loss_att 232.237137 loss_ctc 97.699150 loss_rnnt 89.307793 lr 0.00026004 rank 4
2022-12-03 13:02:40,763 DEBUG TRAIN Batch 0/6600 loss 93.175613 loss_att 209.790771 loss_ctc 85.904747 loss_rnnt 70.822021 lr 0.00026404 rank 6
2022-12-03 13:02:40,779 DEBUG TRAIN Batch 0/6600 loss 92.927780 loss_att 205.843781 loss_ctc 90.472656 loss_rnnt 70.671928 lr 0.00026404 rank 2
2022-12-03 13:02:40,780 DEBUG TRAIN Batch 0/6600 loss 102.008347 loss_att 213.109955 loss_ctc 98.403725 loss_rnnt 80.268646 lr 0.00026404 rank 1
2022-12-03 13:02:40,783 DEBUG TRAIN Batch 0/6600 loss 131.600555 loss_att 232.328796 loss_ctc 137.957062 loss_rnnt 110.607361 lr 0.00026404 rank 0
2022-12-03 13:02:40,785 DEBUG TRAIN Batch 0/6600 loss 103.068115 loss_att 228.992111 loss_ctc 104.469994 loss_rnnt 77.696388 lr 0.00026404 rank 7
2022-12-03 13:02:40,785 DEBUG TRAIN Batch 0/6600 loss 120.418655 loss_att 236.549286 loss_ctc 121.513390 loss_rnnt 97.046570 lr 0.00026404 rank 4
2022-12-03 13:02:40,785 DEBUG TRAIN Batch 0/6600 loss 106.837746 loss_att 213.162292 loss_ctc 100.776848 loss_rnnt 86.380966 lr 0.00026404 rank 3
2022-12-03 13:02:40,786 DEBUG TRAIN Batch 0/6600 loss 99.428513 loss_att 196.144882 loss_ctc 94.735191 loss_rnnt 80.711014 lr 0.00026404 rank 5
2022-12-03 13:03:52,904 DEBUG TRAIN Batch 0/6700 loss 98.203506 loss_att 202.454102 loss_ctc 97.581253 loss_rnnt 77.436356 lr 0.00026804 rank 5
2022-12-03 13:03:52,904 DEBUG TRAIN Batch 0/6700 loss 144.982483 loss_att 261.587341 loss_ctc 136.716095 loss_rnnt 122.763695 lr 0.00026804 rank 2
2022-12-03 13:03:52,906 DEBUG TRAIN Batch 0/6700 loss 110.642365 loss_att 218.628632 loss_ctc 115.001030 loss_rnnt 88.463943 lr 0.00026804 rank 6
2022-12-03 13:03:52,911 DEBUG TRAIN Batch 0/6700 loss 85.302155 loss_att 184.393066 loss_ctc 80.274887 loss_rnnt 66.154274 lr 0.00026804 rank 1
2022-12-03 13:03:52,911 DEBUG TRAIN Batch 0/6700 loss 90.515396 loss_att 203.422363 loss_ctc 83.608940 loss_rnnt 68.854858 lr 0.00026804 rank 0
2022-12-03 13:03:52,912 DEBUG TRAIN Batch 0/6700 loss 90.666397 loss_att 199.135193 loss_ctc 82.515625 loss_rnnt 70.059402 lr 0.00026804 rank 3
2022-12-03 13:03:52,917 DEBUG TRAIN Batch 0/6700 loss 81.320229 loss_att 195.448715 loss_ctc 71.435173 loss_rnnt 59.812542 lr 0.00026804 rank 4
2022-12-03 13:03:52,918 DEBUG TRAIN Batch 0/6700 loss 98.562202 loss_att 220.956818 loss_ctc 91.026672 loss_rnnt 75.088013 lr 0.00026804 rank 7
2022-12-03 13:06:05,843 DEBUG TRAIN Batch 0/6800 loss 92.205544 loss_att 200.706177 loss_ctc 91.105072 loss_rnnt 70.652145 lr 0.00027204 rank 6
2022-12-03 13:06:05,843 DEBUG TRAIN Batch 0/6800 loss 112.558929 loss_att 223.726257 loss_ctc 111.734253 loss_rnnt 90.435425 lr 0.00027204 rank 0
2022-12-03 13:06:05,846 DEBUG TRAIN Batch 0/6800 loss 101.574615 loss_att 197.876648 loss_ctc 102.436508 loss_rnnt 82.199295 lr 0.00027204 rank 5
2022-12-03 13:06:05,848 DEBUG TRAIN Batch 0/6800 loss 113.676590 loss_att 237.130264 loss_ctc 117.837708 loss_rnnt 88.431038 lr 0.00027204 rank 7
2022-12-03 13:06:05,848 DEBUG TRAIN Batch 0/6800 loss 75.855019 loss_att 178.619568 loss_ctc 74.145760 loss_rnnt 55.530003 lr 0.00027204 rank 3
2022-12-03 13:06:05,848 DEBUG TRAIN Batch 0/6800 loss 108.529076 loss_att 242.130157 loss_ctc 110.226913 loss_rnnt 81.582474 lr 0.00027204 rank 2
2022-12-03 13:06:05,850 DEBUG TRAIN Batch 0/6800 loss 83.177925 loss_att 170.251099 loss_ctc 80.399323 loss_rnnt 66.133766 lr 0.00027204 rank 4
2022-12-03 13:06:05,852 DEBUG TRAIN Batch 0/6800 loss 103.036835 loss_att 205.635773 loss_ctc 112.302170 loss_rnnt 81.281670 lr 0.00027204 rank 1
2022-12-03 13:07:18,173 DEBUG TRAIN Batch 0/6900 loss 63.192581 loss_att 117.629959 loss_ctc 63.667107 loss_rnnt 52.241829 lr 0.00027604 rank 1
2022-12-03 13:07:18,174 DEBUG TRAIN Batch 0/6900 loss 100.066299 loss_att 219.543320 loss_ctc 100.993256 loss_rnnt 76.047302 lr 0.00027604 rank 0
2022-12-03 13:07:18,178 DEBUG TRAIN Batch 0/6900 loss 89.611282 loss_att 199.118164 loss_ctc 83.925720 loss_rnnt 68.467972 lr 0.00027604 rank 3
2022-12-03 13:07:18,178 DEBUG TRAIN Batch 0/6900 loss 73.515884 loss_att 179.245483 loss_ctc 72.351875 loss_rnnt 52.525166 lr 0.00027604 rank 5
2022-12-03 13:07:18,179 DEBUG TRAIN Batch 0/6900 loss 95.245239 loss_att 172.301193 loss_ctc 96.967072 loss_rnnt 79.604469 lr 0.00027604 rank 6
2022-12-03 13:07:18,180 DEBUG TRAIN Batch 0/6900 loss 106.056969 loss_att 204.605896 loss_ctc 110.277847 loss_rnnt 85.784393 lr 0.00027604 rank 7
2022-12-03 13:07:18,183 DEBUG TRAIN Batch 0/6900 loss 101.044876 loss_att 196.706024 loss_ctc 99.501274 loss_rnnt 82.118462 lr 0.00027604 rank 2
2022-12-03 13:07:18,186 DEBUG TRAIN Batch 0/6900 loss 108.198257 loss_att 219.116104 loss_ctc 101.522659 loss_rnnt 86.904770 lr 0.00027604 rank 4
2022-12-03 13:08:30,412 DEBUG TRAIN Batch 0/7000 loss 81.392311 loss_att 140.474503 loss_ctc 86.527977 loss_rnnt 68.891113 lr 0.00028004 rank 5
2022-12-03 13:08:30,414 DEBUG TRAIN Batch 0/7000 loss 39.285889 loss_att 55.258141 loss_ctc 42.700893 loss_rnnt 35.636105 lr 0.00028004 rank 6
2022-12-03 13:08:30,415 DEBUG TRAIN Batch 0/7000 loss 77.276100 loss_att 169.587036 loss_ctc 72.994942 loss_rnnt 59.384731 lr 0.00028004 rank 3
2022-12-03 13:08:30,418 DEBUG TRAIN Batch 0/7000 loss 45.432312 loss_att 84.353111 loss_ctc 44.865524 loss_rnnt 37.723724 lr 0.00028004 rank 2
2022-12-03 13:08:30,420 DEBUG TRAIN Batch 0/7000 loss 64.757156 loss_att 156.157806 loss_ctc 65.880798 loss_rnnt 46.327206 lr 0.00028004 rank 7
2022-12-03 13:08:30,422 DEBUG TRAIN Batch 0/7000 loss 101.911209 loss_att 179.590424 loss_ctc 106.003700 loss_rnnt 85.829697 lr 0.00028004 rank 4
2022-12-03 13:08:30,422 DEBUG TRAIN Batch 0/7000 loss 111.701775 loss_att 198.837875 loss_ctc 113.628860 loss_rnnt 94.017609 lr 0.00028004 rank 0
2022-12-03 13:08:30,453 DEBUG TRAIN Batch 0/7000 loss 98.296143 loss_att 229.926025 loss_ctc 96.508240 loss_rnnt 72.208549 lr 0.00028004 rank 1
2022-12-03 13:10:38,520 DEBUG TRAIN Batch 0/7100 loss 58.698082 loss_att 128.220322 loss_ctc 55.518791 loss_rnnt 45.217541 lr 0.00028404 rank 0
2022-12-03 13:10:38,521 DEBUG TRAIN Batch 0/7100 loss 114.437714 loss_att 216.864136 loss_ctc 121.155518 loss_rnnt 93.056717 lr 0.00028404 rank 3
2022-12-03 13:10:38,525 DEBUG TRAIN Batch 0/7100 loss 106.704117 loss_att 213.864258 loss_ctc 102.104904 loss_rnnt 85.885315 lr 0.00028404 rank 6
2022-12-03 13:10:38,526 DEBUG TRAIN Batch 0/7100 loss 105.467957 loss_att 225.533112 loss_ctc 101.990440 loss_rnnt 81.918594 lr 0.00028404 rank 5
2022-12-03 13:10:38,526 DEBUG TRAIN Batch 0/7100 loss 96.728386 loss_att 206.372360 loss_ctc 104.542534 loss_rnnt 73.757698 lr 0.00028404 rank 1
2022-12-03 13:10:38,539 DEBUG TRAIN Batch 0/7100 loss 94.252289 loss_att 233.102844 loss_ctc 87.197571 loss_rnnt 67.422806 lr 0.00028404 rank 2
2022-12-03 13:10:38,543 DEBUG TRAIN Batch 0/7100 loss 176.470016 loss_att 347.393372 loss_ctc 178.096680 loss_rnnt 142.068451 lr 0.00028404 rank 4
2022-12-03 13:10:38,586 DEBUG TRAIN Batch 0/7100 loss 40.052490 loss_att 61.174728 loss_ctc 40.137768 loss_rnnt 35.816673 lr 0.00028404 rank 7
2022-12-03 13:11:50,801 DEBUG TRAIN Batch 0/7200 loss 76.707199 loss_att 179.926727 loss_ctc 67.077362 loss_rnnt 57.347271 lr 0.00028804 rank 3
2022-12-03 13:11:50,802 DEBUG TRAIN Batch 0/7200 loss 101.930267 loss_att 202.290817 loss_ctc 99.347244 loss_rnnt 82.202553 lr 0.00028804 rank 5
2022-12-03 13:11:50,803 DEBUG TRAIN Batch 0/7200 loss 118.343315 loss_att 250.262848 loss_ctc 111.723831 loss_rnnt 92.841995 lr 0.00028804 rank 0
2022-12-03 13:11:50,807 DEBUG TRAIN Batch 0/7200 loss 123.056427 loss_att 256.407104 loss_ctc 123.879089 loss_rnnt 96.276604 lr 0.00028804 rank 6
2022-12-03 13:11:50,809 DEBUG TRAIN Batch 0/7200 loss 65.074867 loss_att 141.779739 loss_ctc 66.120094 loss_rnnt 49.594524 lr 0.00028804 rank 1
2022-12-03 13:11:50,809 DEBUG TRAIN Batch 0/7200 loss 94.837135 loss_att 191.316467 loss_ctc 92.660324 loss_rnnt 75.831512 lr 0.00028804 rank 2
2022-12-03 13:11:50,809 DEBUG TRAIN Batch 0/7200 loss 106.652954 loss_att 241.669495 loss_ctc 105.376549 loss_rnnt 79.819824 lr 0.00028804 rank 4
2022-12-03 13:11:50,811 DEBUG TRAIN Batch 0/7200 loss 95.012535 loss_att 225.463852 loss_ctc 96.021538 loss_rnnt 68.787735 lr 0.00028804 rank 7
2022-12-03 13:13:03,256 DEBUG TRAIN Batch 0/7300 loss 93.105644 loss_att 213.904419 loss_ctc 84.997482 loss_rnnt 70.026978 lr 0.00029204 rank 0
2022-12-03 13:13:03,260 DEBUG TRAIN Batch 0/7300 loss 89.593842 loss_att 179.578156 loss_ctc 82.201508 loss_rnnt 72.582626 lr 0.00029204 rank 2
2022-12-03 13:13:03,262 DEBUG TRAIN Batch 0/7300 loss 99.356438 loss_att 198.370392 loss_ctc 98.511368 loss_rnnt 79.666321 lr 0.00029204 rank 7
2022-12-03 13:13:03,263 DEBUG TRAIN Batch 0/7300 loss 101.510681 loss_att 217.213364 loss_ctc 105.757629 loss_rnnt 77.803894 lr 0.00029204 rank 5
2022-12-03 13:13:03,263 DEBUG TRAIN Batch 0/7300 loss 92.474213 loss_att 212.267090 loss_ctc 96.473587 loss_rnnt 67.982384 lr 0.00029204 rank 3
2022-12-03 13:13:03,264 DEBUG TRAIN Batch 0/7300 loss 89.375679 loss_att 205.050537 loss_ctc 89.466904 loss_rnnt 66.228546 lr 0.00029204 rank 6
2022-12-03 13:13:03,266 DEBUG TRAIN Batch 0/7300 loss 99.534607 loss_att 222.822784 loss_ctc 105.492966 loss_rnnt 74.082520 lr 0.00029204 rank 1
2022-12-03 13:13:03,275 DEBUG TRAIN Batch 0/7300 loss 93.163010 loss_att 218.509094 loss_ctc 84.060295 loss_rnnt 69.307487 lr 0.00029204 rank 4
2022-12-03 13:14:15,507 DEBUG TRAIN Batch 0/7400 loss 75.582848 loss_att 182.096359 loss_ctc 69.427826 loss_rnnt 55.100807 lr 0.00029604 rank 5
2022-12-03 13:14:15,509 DEBUG TRAIN Batch 0/7400 loss 108.265617 loss_att 211.429794 loss_ctc 106.869843 loss_rnnt 87.818893 lr 0.00029604 rank 3
2022-12-03 13:14:15,514 DEBUG TRAIN Batch 0/7400 loss 115.863716 loss_att 212.307495 loss_ctc 126.097694 loss_rnnt 95.210426 lr 0.00029604 rank 6
2022-12-03 13:14:15,514 DEBUG TRAIN Batch 0/7400 loss 84.000237 loss_att 194.141235 loss_ctc 83.930634 loss_rnnt 61.981312 lr 0.00029604 rank 0
2022-12-03 13:14:15,520 DEBUG TRAIN Batch 0/7400 loss 89.157669 loss_att 211.045837 loss_ctc 87.083176 loss_rnnt 65.056633 lr 0.00029604 rank 7
2022-12-03 13:14:15,521 DEBUG TRAIN Batch 0/7400 loss 76.392624 loss_att 182.885468 loss_ctc 74.169075 loss_rnnt 55.390522 lr 0.00029604 rank 1
2022-12-03 13:14:15,521 DEBUG TRAIN Batch 0/7400 loss 112.062805 loss_att 246.134125 loss_ctc 110.437149 loss_rnnt 85.465286 lr 0.00029604 rank 4
2022-12-03 13:14:15,563 DEBUG TRAIN Batch 0/7400 loss 107.590057 loss_att 192.586029 loss_ctc 105.996803 loss_rnnt 90.803299 lr 0.00029604 rank 2
2022-12-03 13:16:17,674 DEBUG TRAIN Batch 0/7500 loss 76.062592 loss_att 159.281830 loss_ctc 73.745987 loss_rnnt 59.727623 lr 0.00030004 rank 6
2022-12-03 13:16:17,676 DEBUG TRAIN Batch 0/7500 loss 97.465759 loss_att 191.011017 loss_ctc 102.215195 loss_rnnt 78.123444 lr 0.00030004 rank 5
2022-12-03 13:16:17,676 DEBUG TRAIN Batch 0/7500 loss 87.770020 loss_att 181.072510 loss_ctc 92.745407 loss_rnnt 68.446136 lr 0.00030004 rank 0
2022-12-03 13:16:17,677 DEBUG TRAIN Batch 0/7500 loss 97.236252 loss_att 199.458313 loss_ctc 99.507370 loss_rnnt 76.489029 lr 0.00030004 rank 2
2022-12-03 13:16:17,682 DEBUG TRAIN Batch 0/7500 loss 107.044724 loss_att 225.419083 loss_ctc 117.789482 loss_rnnt 81.937225 lr 0.00030004 rank 4
2022-12-03 13:16:17,683 DEBUG TRAIN Batch 0/7500 loss 99.060989 loss_att 185.775238 loss_ctc 106.821518 loss_rnnt 80.683395 lr 0.00030004 rank 3
2022-12-03 13:16:17,689 DEBUG TRAIN Batch 0/7500 loss 74.400497 loss_att 144.265366 loss_ctc 79.650497 loss_rnnt 59.727531 lr 0.00030004 rank 7
2022-12-03 13:16:17,720 DEBUG TRAIN Batch 0/7500 loss 68.358368 loss_att 140.405090 loss_ctc 66.182892 loss_rnnt 54.239082 lr 0.00030004 rank 1
2022-12-03 13:17:29,434 DEBUG TRAIN Batch 0/7600 loss 101.968201 loss_att 209.731262 loss_ctc 97.765503 loss_rnnt 80.975952 lr 0.00030404 rank 1
2022-12-03 13:17:29,436 DEBUG TRAIN Batch 0/7600 loss 104.966599 loss_att 204.895218 loss_ctc 107.010536 loss_rnnt 84.708344 lr 0.00030404 rank 0
2022-12-03 13:17:29,437 DEBUG TRAIN Batch 0/7600 loss 66.008751 loss_att 144.734680 loss_ctc 62.214222 loss_rnnt 50.769497 lr 0.00030404 rank 3
2022-12-03 13:17:29,438 DEBUG TRAIN Batch 0/7600 loss 72.500801 loss_att 150.878326 loss_ctc 71.917297 loss_rnnt 56.903095 lr 0.00030404 rank 5
2022-12-03 13:17:29,437 DEBUG TRAIN Batch 0/7600 loss 69.484894 loss_att 139.544266 loss_ctc 72.282791 loss_rnnt 55.099968 lr 0.00030404 rank 6
2022-12-03 13:17:29,438 DEBUG TRAIN Batch 0/7600 loss 74.646851 loss_att 169.244812 loss_ctc 72.381714 loss_rnnt 56.029282 lr 0.00030404 rank 7
2022-12-03 13:17:29,440 DEBUG TRAIN Batch 0/7600 loss 67.320557 loss_att 128.485077 loss_ctc 70.584274 loss_rnnt 54.652489 lr 0.00030404 rank 2
2022-12-03 13:17:29,443 DEBUG TRAIN Batch 0/7600 loss 68.011490 loss_att 171.470703 loss_ctc 67.425995 loss_rnnt 47.397717 lr 0.00030404 rank 4
2022-12-03 13:18:42,030 DEBUG TRAIN Batch 0/7700 loss 107.097198 loss_att 206.516602 loss_ctc 105.189507 loss_rnnt 87.467674 lr 0.00030804 rank 6
2022-12-03 13:18:42,031 DEBUG TRAIN Batch 0/7700 loss 27.017056 loss_att 37.720684 loss_ctc 29.119633 loss_rnnt 24.595989 lr 0.00030804 rank 3
2022-12-03 13:18:42,033 DEBUG TRAIN Batch 0/7700 loss 50.740211 loss_att 86.421432 loss_ctc 51.183933 loss_rnnt 43.544804 lr 0.00030804 rank 7
2022-12-03 13:18:42,038 DEBUG TRAIN Batch 0/7700 loss 90.490463 loss_att 186.302383 loss_ctc 97.989441 loss_rnnt 70.328217 lr 0.00030804 rank 5
2022-12-03 13:18:42,039 DEBUG TRAIN Batch 0/7700 loss 85.684410 loss_att 194.259399 loss_ctc 83.756432 loss_rnnt 64.226471 lr 0.00030804 rank 2
2022-12-03 13:18:42,042 DEBUG TRAIN Batch 0/7700 loss 103.159805 loss_att 208.146042 loss_ctc 101.438828 loss_rnnt 82.392021 lr 0.00030804 rank 1
2022-12-03 13:18:42,084 DEBUG TRAIN Batch 0/7700 loss 46.429520 loss_att 79.365486 loss_ctc 49.127502 loss_rnnt 39.482597 lr 0.00030804 rank 4
2022-12-03 13:18:42,375 DEBUG TRAIN Batch 0/7700 loss 59.147526 loss_att 105.563248 loss_ctc 59.761467 loss_rnnt 49.782524 lr 0.00030804 rank 0
2022-12-03 13:19:56,238 DEBUG TRAIN Batch 0/7800 loss 71.812439 loss_att 171.956940 loss_ctc 70.517387 loss_rnnt 51.956207 lr 0.00031204 rank 6
2022-12-03 13:19:56,240 DEBUG TRAIN Batch 0/7800 loss 130.553757 loss_att 226.111816 loss_ctc 145.154648 loss_rnnt 109.495361 lr 0.00031204 rank 3
2022-12-03 13:19:56,241 DEBUG TRAIN Batch 0/7800 loss 77.151360 loss_att 175.961136 loss_ctc 76.824493 loss_rnnt 57.432983 lr 0.00031204 rank 1
2022-12-03 13:19:56,243 DEBUG TRAIN Batch 0/7800 loss 78.340775 loss_att 188.152496 loss_ctc 83.687103 loss_rnnt 55.665585 lr 0.00031204 rank 2
2022-12-03 13:19:56,243 DEBUG TRAIN Batch 0/7800 loss 75.880417 loss_att 182.092865 loss_ctc 72.173248 loss_rnnt 55.132217 lr 0.00031204 rank 7
2022-12-03 13:19:56,245 DEBUG TRAIN Batch 0/7800 loss 66.699631 loss_att 164.734726 loss_ctc 65.573563 loss_rnnt 47.242748 lr 0.00031204 rank 0
2022-12-03 13:19:56,248 DEBUG TRAIN Batch 0/7800 loss 77.126556 loss_att 179.932236 loss_ctc 71.069473 loss_rnnt 57.373032 lr 0.00031204 rank 4
2022-12-03 13:19:56,248 DEBUG TRAIN Batch 0/7800 loss 125.180191 loss_att 259.065735 loss_ctc 123.656738 loss_rnnt 98.606201 lr 0.00031204 rank 5
2022-12-03 13:22:00,477 DEBUG TRAIN Batch 0/7900 loss 78.232414 loss_att 192.093155 loss_ctc 79.152794 loss_rnnt 55.337551 lr 0.00031604 rank 2
2022-12-03 13:22:00,478 DEBUG TRAIN Batch 0/7900 loss 124.554199 loss_att 236.124115 loss_ctc 118.675713 loss_rnnt 103.024017 lr 0.00031604 rank 1
2022-12-03 13:22:00,480 DEBUG TRAIN Batch 0/7900 loss 107.531700 loss_att 249.992523 loss_ctc 104.929070 loss_rnnt 79.386559 lr 0.00031604 rank 3
2022-12-03 13:22:00,481 DEBUG TRAIN Batch 0/7900 loss 102.708206 loss_att 219.161072 loss_ctc 104.195084 loss_rnnt 79.219383 lr 0.00031604 rank 5
2022-12-03 13:22:00,482 DEBUG TRAIN Batch 0/7900 loss 102.167992 loss_att 202.851929 loss_ctc 101.900330 loss_rnnt 82.066895 lr 0.00031604 rank 6
2022-12-03 13:22:00,484 DEBUG TRAIN Batch 0/7900 loss 88.116035 loss_att 203.506470 loss_ctc 89.044144 loss_rnnt 64.914200 lr 0.00031604 rank 4
2022-12-03 13:22:00,484 DEBUG TRAIN Batch 0/7900 loss 83.427902 loss_att 173.887436 loss_ctc 89.299194 loss_rnnt 64.553154 lr 0.00031604 rank 7
2022-12-03 13:22:00,491 DEBUG TRAIN Batch 0/7900 loss 75.623039 loss_att 192.104385 loss_ctc 75.156052 loss_rnnt 52.389034 lr 0.00031604 rank 0
2022-12-03 13:23:13,590 DEBUG TRAIN Batch 0/8000 loss 68.068420 loss_att 160.466736 loss_ctc 66.569199 loss_rnnt 49.788651 lr 0.00032004 rank 2
2022-12-03 13:23:13,594 DEBUG TRAIN Batch 0/8000 loss 105.935394 loss_att 222.429260 loss_ctc 108.095665 loss_rnnt 82.348572 lr 0.00032004 rank 6
2022-12-03 13:23:13,594 DEBUG TRAIN Batch 0/8000 loss 89.645638 loss_att 203.170761 loss_ctc 82.353226 loss_rnnt 67.912933 lr 0.00032004 rank 0
2022-12-03 13:23:13,598 DEBUG TRAIN Batch 0/8000 loss 91.562469 loss_att 203.524658 loss_ctc 99.875069 loss_rnnt 68.061684 lr 0.00032004 rank 3
2022-12-03 13:23:13,599 DEBUG TRAIN Batch 0/8000 loss 129.829086 loss_att 233.469955 loss_ctc 144.941254 loss_rnnt 107.085953 lr 0.00032004 rank 1
2022-12-03 13:23:13,601 DEBUG TRAIN Batch 0/8000 loss 86.697739 loss_att 185.681442 loss_ctc 84.052399 loss_rnnt 67.253708 lr 0.00032004 rank 7
2022-12-03 13:23:13,604 DEBUG TRAIN Batch 0/8000 loss 74.608932 loss_att 180.571838 loss_ctc 68.641151 loss_rnnt 54.212059 lr 0.00032004 rank 4
2022-12-03 13:23:13,640 DEBUG TRAIN Batch 0/8000 loss 80.236763 loss_att 182.760574 loss_ctc 82.809471 loss_rnnt 59.388969 lr 0.00032004 rank 5
2022-12-03 13:24:27,723 DEBUG TRAIN Batch 0/8100 loss 73.735085 loss_att 171.016693 loss_ctc 76.892410 loss_rnnt 53.857788 lr 0.00032404 rank 6
2022-12-03 13:24:27,723 DEBUG TRAIN Batch 0/8100 loss 90.477745 loss_att 180.022766 loss_ctc 87.043549 loss_rnnt 73.026627 lr 0.00032404 rank 0
2022-12-03 13:24:27,726 DEBUG TRAIN Batch 0/8100 loss 87.732513 loss_att 186.014801 loss_ctc 92.571640 loss_rnnt 67.430832 lr 0.00032404 rank 3
2022-12-03 13:24:27,727 DEBUG TRAIN Batch 0/8100 loss 74.364014 loss_att 173.693634 loss_ctc 77.594620 loss_rnnt 54.067345 lr 0.00032404 rank 7
2022-12-03 13:24:27,729 DEBUG TRAIN Batch 0/8100 loss 56.989521 loss_att 128.260208 loss_ctc 55.541180 loss_rnnt 42.928493 lr 0.00032404 rank 1
2022-12-03 13:24:27,728 DEBUG TRAIN Batch 0/8100 loss 92.045731 loss_att 175.211456 loss_ctc 92.999474 loss_rnnt 75.285423 lr 0.00032404 rank 2
2022-12-03 13:24:27,730 DEBUG TRAIN Batch 0/8100 loss 80.798332 loss_att 172.271240 loss_ctc 80.942261 loss_rnnt 62.484558 lr 0.00032404 rank 5
2022-12-03 13:24:27,786 DEBUG TRAIN Batch 0/8100 loss 86.776230 loss_att 186.413742 loss_ctc 86.481415 loss_rnnt 66.888031 lr 0.00032404 rank 4
2022-12-03 13:25:40,335 DEBUG TRAIN Batch 0/8200 loss 97.777184 loss_att 211.563721 loss_ctc 99.281128 loss_rnnt 74.819351 lr 0.00032804 rank 1
2022-12-03 13:25:40,337 DEBUG TRAIN Batch 0/8200 loss 105.052979 loss_att 190.042099 loss_ctc 119.718620 loss_rnnt 86.099731 lr 0.00032804 rank 0
2022-12-03 13:25:40,339 DEBUG TRAIN Batch 0/8200 loss 69.294106 loss_att 158.598816 loss_ctc 74.701775 loss_rnnt 50.712143 lr 0.00032804 rank 6
2022-12-03 13:25:40,341 DEBUG TRAIN Batch 0/8200 loss 49.450798 loss_att 130.184036 loss_ctc 50.041645 loss_rnnt 33.225368 lr 0.00032804 rank 3
2022-12-03 13:25:40,342 DEBUG TRAIN Batch 0/8200 loss 104.591736 loss_att 191.809814 loss_ctc 110.552971 loss_rnnt 86.353287 lr 0.00032804 rank 5
2022-12-03 13:25:40,344 DEBUG TRAIN Batch 0/8200 loss 56.523144 loss_att 109.419189 loss_ctc 59.399235 loss_rnnt 45.560455 lr 0.00032804 rank 7
2022-12-03 13:25:40,348 DEBUG TRAIN Batch 0/8200 loss 59.600494 loss_att 143.579315 loss_ctc 58.680927 loss_rnnt 42.927338 lr 0.00032804 rank 4
2022-12-03 13:25:40,352 DEBUG TRAIN Batch 0/8200 loss 63.408672 loss_att 138.558121 loss_ctc 61.912708 loss_rnnt 48.578247 lr 0.00032804 rank 2
2022-12-03 13:26:52,600 DEBUG TRAIN Batch 0/8300 loss 70.184479 loss_att 134.300659 loss_ctc 73.446777 loss_rnnt 56.926270 lr 0.00033204 rank 3
2022-12-03 13:26:52,617 DEBUG TRAIN Batch 0/8300 loss 86.504089 loss_att 201.178940 loss_ctc 89.552048 loss_rnnt 63.162727 lr 0.00033204 rank 1
2022-12-03 13:26:52,618 DEBUG TRAIN Batch 0/8300 loss 59.074062 loss_att 131.710052 loss_ctc 65.123825 loss_rnnt 43.740231 lr 0.00033204 rank 0
2022-12-03 13:26:52,619 DEBUG TRAIN Batch 0/8300 loss 75.510849 loss_att 163.059174 loss_ctc 76.932060 loss_rnnt 57.811684 lr 0.00033204 rank 5
2022-12-03 13:26:52,621 DEBUG TRAIN Batch 0/8300 loss 54.965157 loss_att 109.775070 loss_ctc 58.246319 loss_rnnt 43.565685 lr 0.00033204 rank 6
2022-12-03 13:26:52,631 DEBUG TRAIN Batch 0/8300 loss 80.242661 loss_att 168.351135 loss_ctc 84.145599 loss_rnnt 62.100571 lr 0.00033204 rank 4
2022-12-03 13:26:52,636 DEBUG TRAIN Batch 0/8300 loss 110.236374 loss_att 214.049179 loss_ctc 122.527550 loss_rnnt 87.834976 lr 0.00033204 rank 2
2022-12-03 13:26:52,643 DEBUG TRAIN Batch 0/8300 loss 75.957367 loss_att 165.429932 loss_ctc 78.291275 loss_rnnt 57.751671 lr 0.00033204 rank 7
2022-12-03 13:27:43,636 DEBUG CV Batch 0/0 loss 14.645320 loss_att 22.072971 loss_ctc 16.289690 loss_rnnt 12.940540 history loss 14.102901 rank 7
2022-12-03 13:27:43,643 DEBUG CV Batch 0/0 loss 14.645320 loss_att 22.072971 loss_ctc 16.289690 loss_rnnt 12.940540 history loss 14.102901 rank 6
2022-12-03 13:27:43,646 DEBUG CV Batch 0/0 loss 14.645320 loss_att 22.072971 loss_ctc 16.289690 loss_rnnt 12.940540 history loss 14.102901 rank 0
2022-12-03 13:27:43,646 DEBUG CV Batch 0/0 loss 14.645320 loss_att 22.072971 loss_ctc 16.289690 loss_rnnt 12.940540 history loss 14.102901 rank 4
2022-12-03 13:27:43,654 DEBUG CV Batch 0/0 loss 14.645320 loss_att 22.072971 loss_ctc 16.289690 loss_rnnt 12.940540 history loss 14.102901 rank 3
2022-12-03 13:27:43,654 DEBUG CV Batch 0/0 loss 14.645320 loss_att 22.072971 loss_ctc 16.289690 loss_rnnt 12.940540 history loss 14.102901 rank 1
2022-12-03 13:27:43,662 DEBUG CV Batch 0/0 loss 14.645320 loss_att 22.072971 loss_ctc 16.289690 loss_rnnt 12.940540 history loss 14.102901 rank 2
2022-12-03 13:27:43,669 DEBUG CV Batch 0/0 loss 14.645320 loss_att 22.072971 loss_ctc 16.289690 loss_rnnt 12.940540 history loss 14.102901 rank 5
2022-12-03 13:27:57,565 DEBUG CV Batch 0/100 loss 61.158432 loss_att 117.992996 loss_ctc 67.743500 loss_rnnt 48.913513 history loss 37.523914 rank 3
2022-12-03 13:27:57,605 DEBUG CV Batch 0/100 loss 61.158432 loss_att 117.992996 loss_ctc 67.743500 loss_rnnt 48.913513 history loss 37.523914 rank 5
2022-12-03 13:27:57,620 DEBUG CV Batch 0/100 loss 61.158432 loss_att 117.992996 loss_ctc 67.743500 loss_rnnt 48.913513 history loss 37.523914 rank 1
2022-12-03 13:27:57,672 DEBUG CV Batch 0/100 loss 61.158432 loss_att 117.992996 loss_ctc 67.743500 loss_rnnt 48.913513 history loss 37.523914 rank 2
2022-12-03 13:27:57,694 DEBUG CV Batch 0/100 loss 61.158432 loss_att 117.992996 loss_ctc 67.743500 loss_rnnt 48.913513 history loss 37.523914 rank 4
2022-12-03 13:27:57,944 DEBUG CV Batch 0/100 loss 61.158432 loss_att 117.992996 loss_ctc 67.743500 loss_rnnt 48.913513 history loss 37.523914 rank 0
2022-12-03 13:27:57,946 DEBUG CV Batch 0/100 loss 61.158432 loss_att 117.992996 loss_ctc 67.743500 loss_rnnt 48.913513 history loss 37.523914 rank 6
2022-12-03 13:27:58,279 DEBUG CV Batch 0/100 loss 61.158432 loss_att 117.992996 loss_ctc 67.743500 loss_rnnt 48.913513 history loss 37.523914 rank 7
2022-12-03 13:28:14,046 DEBUG CV Batch 0/200 loss 122.509003 loss_att 314.270844 loss_ctc 116.454620 loss_rnnt 84.963882 history loss 42.246249 rank 6
2022-12-03 13:28:14,092 DEBUG CV Batch 0/200 loss 122.509003 loss_att 314.270844 loss_ctc 116.454620 loss_rnnt 84.963882 history loss 42.246249 rank 3
2022-12-03 13:28:14,161 DEBUG CV Batch 0/200 loss 122.509003 loss_att 314.270844 loss_ctc 116.454620 loss_rnnt 84.963882 history loss 42.246249 rank 0
2022-12-03 13:28:14,272 DEBUG CV Batch 0/200 loss 122.509003 loss_att 314.270844 loss_ctc 116.454620 loss_rnnt 84.963882 history loss 42.246249 rank 1
2022-12-03 13:28:14,281 DEBUG CV Batch 0/200 loss 122.509003 loss_att 314.270844 loss_ctc 116.454620 loss_rnnt 84.963882 history loss 42.246249 rank 7
2022-12-03 13:28:14,311 DEBUG CV Batch 0/200 loss 122.509003 loss_att 314.270844 loss_ctc 116.454620 loss_rnnt 84.963882 history loss 42.246249 rank 5
2022-12-03 13:28:14,445 DEBUG CV Batch 0/200 loss 122.509003 loss_att 314.270844 loss_ctc 116.454620 loss_rnnt 84.963882 history loss 42.246249 rank 2
2022-12-03 13:28:14,461 DEBUG CV Batch 0/200 loss 122.509003 loss_att 314.270844 loss_ctc 116.454620 loss_rnnt 84.963882 history loss 42.246249 rank 4
2022-12-03 13:28:29,064 DEBUG CV Batch 0/300 loss 46.409016 loss_att 84.025246 loss_ctc 51.188950 loss_rnnt 38.248444 history loss 41.499036 rank 3
2022-12-03 13:28:29,065 DEBUG CV Batch 0/300 loss 46.409016 loss_att 84.025246 loss_ctc 51.188950 loss_rnnt 38.248444 history loss 41.499036 rank 6
2022-12-03 13:28:29,072 DEBUG CV Batch 0/300 loss 46.409016 loss_att 84.025246 loss_ctc 51.188950 loss_rnnt 38.248444 history loss 41.499036 rank 0
2022-12-03 13:28:29,143 DEBUG CV Batch 0/300 loss 46.409016 loss_att 84.025246 loss_ctc 51.188950 loss_rnnt 38.248444 history loss 41.499036 rank 1
2022-12-03 13:28:29,214 DEBUG CV Batch 0/300 loss 46.409016 loss_att 84.025246 loss_ctc 51.188950 loss_rnnt 38.248444 history loss 41.499036 rank 5
2022-12-03 13:28:29,221 DEBUG CV Batch 0/300 loss 46.409016 loss_att 84.025246 loss_ctc 51.188950 loss_rnnt 38.248444 history loss 41.499036 rank 7
2022-12-03 13:28:29,236 DEBUG CV Batch 0/300 loss 46.409016 loss_att 84.025246 loss_ctc 51.188950 loss_rnnt 38.248444 history loss 41.499036 rank 4
2022-12-03 13:28:29,281 DEBUG CV Batch 0/300 loss 46.409016 loss_att 84.025246 loss_ctc 51.188950 loss_rnnt 38.248444 history loss 41.499036 rank 2
2022-12-03 13:28:48,067 DEBUG CV Batch 0/400 loss 182.094543 loss_att 444.806458 loss_ctc 169.241699 loss_rnnt 131.265869 history loss 44.494914 rank 7
2022-12-03 13:28:48,071 DEBUG CV Batch 0/400 loss 182.094543 loss_att 444.806458 loss_ctc 169.241699 loss_rnnt 131.265869 history loss 44.494914 rank 0
2022-12-03 13:28:48,075 DEBUG CV Batch 0/400 loss 182.094543 loss_att 444.806458 loss_ctc 169.241699 loss_rnnt 131.265869 history loss 44.494914 rank 3
2022-12-03 13:28:48,076 DEBUG CV Batch 0/400 loss 182.094543 loss_att 444.806458 loss_ctc 169.241699 loss_rnnt 131.265869 history loss 44.494914 rank 5
2022-12-03 13:28:48,082 DEBUG CV Batch 0/400 loss 182.094543 loss_att 444.806458 loss_ctc 169.241699 loss_rnnt 131.265869 history loss 44.494914 rank 2
2022-12-03 13:28:48,085 DEBUG CV Batch 0/400 loss 182.094543 loss_att 444.806458 loss_ctc 169.241699 loss_rnnt 131.265869 history loss 44.494914 rank 4
2022-12-03 13:28:48,088 DEBUG CV Batch 0/400 loss 182.094543 loss_att 444.806458 loss_ctc 169.241699 loss_rnnt 131.265869 history loss 44.494914 rank 6
2022-12-03 13:28:48,099 DEBUG CV Batch 0/400 loss 182.094543 loss_att 444.806458 loss_ctc 169.241699 loss_rnnt 131.265869 history loss 44.494914 rank 1
2022-12-03 13:29:01,628 DEBUG CV Batch 0/500 loss 58.130707 loss_att 115.942093 loss_ctc 62.186916 loss_rnnt 46.027596 history loss 44.709539 rank 6
2022-12-03 13:29:01,667 DEBUG CV Batch 0/500 loss 58.130707 loss_att 115.942093 loss_ctc 62.186916 loss_rnnt 46.027596 history loss 44.709539 rank 3
2022-12-03 13:29:01,696 DEBUG CV Batch 0/500 loss 58.130707 loss_att 115.942093 loss_ctc 62.186916 loss_rnnt 46.027596 history loss 44.709539 rank 0
2022-12-03 13:29:01,701 DEBUG CV Batch 0/500 loss 58.130707 loss_att 115.942093 loss_ctc 62.186916 loss_rnnt 46.027596 history loss 44.709539 rank 1
2022-12-03 13:29:01,722 DEBUG CV Batch 0/500 loss 58.130707 loss_att 115.942093 loss_ctc 62.186916 loss_rnnt 46.027596 history loss 44.709539 rank 7
2022-12-03 13:29:01,738 DEBUG CV Batch 0/500 loss 58.130707 loss_att 115.942093 loss_ctc 62.186916 loss_rnnt 46.027596 history loss 44.709539 rank 2
2022-12-03 13:29:01,783 DEBUG CV Batch 0/500 loss 58.130707 loss_att 115.942093 loss_ctc 62.186916 loss_rnnt 46.027596 history loss 44.709539 rank 4
2022-12-03 13:29:01,916 DEBUG CV Batch 0/500 loss 58.130707 loss_att 115.942093 loss_ctc 62.186916 loss_rnnt 46.027596 history loss 44.709539 rank 5
2022-12-03 13:29:19,105 DEBUG CV Batch 0/600 loss 32.898293 loss_att 50.282494 loss_ctc 36.822735 loss_rnnt 28.898191 history loss 46.420542 rank 1
2022-12-03 13:29:19,120 DEBUG CV Batch 0/600 loss 32.898293 loss_att 50.282494 loss_ctc 36.822735 loss_rnnt 28.898191 history loss 46.420542 rank 4
2022-12-03 13:29:19,125 DEBUG CV Batch 0/600 loss 32.898293 loss_att 50.282494 loss_ctc 36.822735 loss_rnnt 28.898191 history loss 46.420542 rank 7
2022-12-03 13:29:19,130 DEBUG CV Batch 0/600 loss 32.898293 loss_att 50.282494 loss_ctc 36.822735 loss_rnnt 28.898191 history loss 46.420542 rank 6
2022-12-03 13:29:19,136 DEBUG CV Batch 0/600 loss 32.898293 loss_att 50.282494 loss_ctc 36.822735 loss_rnnt 28.898191 history loss 46.420542 rank 3
2022-12-03 13:29:19,156 DEBUG CV Batch 0/600 loss 32.898293 loss_att 50.282494 loss_ctc 36.822735 loss_rnnt 28.898191 history loss 46.420542 rank 0
2022-12-03 13:29:19,199 DEBUG CV Batch 0/600 loss 32.898293 loss_att 50.282494 loss_ctc 36.822735 loss_rnnt 28.898191 history loss 46.420542 rank 2
2022-12-03 13:29:19,214 DEBUG CV Batch 0/600 loss 32.898293 loss_att 50.282494 loss_ctc 36.822735 loss_rnnt 28.898191 history loss 46.420542 rank 5
2022-12-03 13:29:35,325 DEBUG CV Batch 0/700 loss 180.695267 loss_att 392.374786 loss_ctc 182.929794 loss_rnnt 138.061417 history loss 47.649047 rank 6
2022-12-03 13:29:35,382 DEBUG CV Batch 0/700 loss 180.695267 loss_att 392.374786 loss_ctc 182.929794 loss_rnnt 138.061417 history loss 47.649047 rank 3
2022-12-03 13:29:35,412 DEBUG CV Batch 0/700 loss 180.695267 loss_att 392.374786 loss_ctc 182.929794 loss_rnnt 138.061417 history loss 47.649047 rank 0
2022-12-03 13:29:35,472 DEBUG CV Batch 0/700 loss 180.695267 loss_att 392.374786 loss_ctc 182.929794 loss_rnnt 138.061417 history loss 47.649047 rank 1
2022-12-03 13:29:35,518 DEBUG CV Batch 0/700 loss 180.695267 loss_att 392.374786 loss_ctc 182.929794 loss_rnnt 138.061417 history loss 47.649047 rank 7
2022-12-03 13:29:35,604 DEBUG CV Batch 0/700 loss 180.695267 loss_att 392.374786 loss_ctc 182.929794 loss_rnnt 138.061417 history loss 47.649047 rank 2
2022-12-03 13:29:35,652 DEBUG CV Batch 0/700 loss 180.695267 loss_att 392.374786 loss_ctc 182.929794 loss_rnnt 138.061417 history loss 47.649047 rank 4
2022-12-03 13:29:35,684 DEBUG CV Batch 0/700 loss 180.695267 loss_att 392.374786 loss_ctc 182.929794 loss_rnnt 138.061417 history loss 47.649047 rank 5
2022-12-03 13:29:47,171 DEBUG CV Batch 0/800 loss 62.627857 loss_att 119.007286 loss_ctc 68.899895 loss_rnnt 50.515701 history loss 46.192334 rank 6
2022-12-03 13:29:47,333 DEBUG CV Batch 0/800 loss 62.627857 loss_att 119.007286 loss_ctc 68.899895 loss_rnnt 50.515701 history loss 46.192334 rank 3
2022-12-03 13:29:47,448 DEBUG CV Batch 0/800 loss 62.627857 loss_att 119.007286 loss_ctc 68.899895 loss_rnnt 50.515701 history loss 46.192334 rank 0
2022-12-03 13:29:48,061 DEBUG CV Batch 0/800 loss 62.627857 loss_att 119.007286 loss_ctc 68.899895 loss_rnnt 50.515701 history loss 46.192334 rank 2
2022-12-03 13:29:48,104 DEBUG CV Batch 0/800 loss 62.627857 loss_att 119.007286 loss_ctc 68.899895 loss_rnnt 50.515701 history loss 46.192334 rank 5
2022-12-03 13:29:48,148 DEBUG CV Batch 0/800 loss 62.627857 loss_att 119.007286 loss_ctc 68.899895 loss_rnnt 50.515701 history loss 46.192334 rank 1
2022-12-03 13:29:48,165 DEBUG CV Batch 0/800 loss 62.627857 loss_att 119.007286 loss_ctc 68.899895 loss_rnnt 50.515701 history loss 46.192334 rank 7
2022-12-03 13:29:48,250 DEBUG CV Batch 0/800 loss 62.627857 loss_att 119.007286 loss_ctc 68.899895 loss_rnnt 50.515701 history loss 46.192334 rank 4
2022-12-03 13:30:00,409 DEBUG CV Batch 0/900 loss 109.215858 loss_att 281.743622 loss_ctc 106.438721 loss_rnnt 75.080589 history loss 46.391688 rank 6
2022-12-03 13:30:00,762 DEBUG CV Batch 0/900 loss 109.215858 loss_att 281.743622 loss_ctc 106.438721 loss_rnnt 75.080589 history loss 46.391688 rank 3
2022-12-03 13:30:00,920 DEBUG CV Batch 0/900 loss 109.215858 loss_att 281.743622 loss_ctc 106.438721 loss_rnnt 75.080589 history loss 46.391688 rank 0
2022-12-03 13:30:02,153 DEBUG CV Batch 0/900 loss 109.215858 loss_att 281.743622 loss_ctc 106.438721 loss_rnnt 75.080589 history loss 46.391688 rank 1
2022-12-03 13:30:02,276 DEBUG CV Batch 0/900 loss 109.215858 loss_att 281.743622 loss_ctc 106.438721 loss_rnnt 75.080589 history loss 46.391688 rank 5
2022-12-03 13:30:02,294 DEBUG CV Batch 0/900 loss 109.215858 loss_att 281.743622 loss_ctc 106.438721 loss_rnnt 75.080589 history loss 46.391688 rank 2
2022-12-03 13:30:02,386 DEBUG CV Batch 0/900 loss 109.215858 loss_att 281.743622 loss_ctc 106.438721 loss_rnnt 75.080589 history loss 46.391688 rank 7
2022-12-03 13:30:02,428 DEBUG CV Batch 0/900 loss 109.215858 loss_att 281.743622 loss_ctc 106.438721 loss_rnnt 75.080589 history loss 46.391688 rank 4
2022-12-03 13:30:12,446 DEBUG CV Batch 0/1000 loss 35.346405 loss_att 71.347992 loss_ctc 38.380051 loss_rnnt 27.741604 history loss 45.837696 rank 6
2022-12-03 13:30:12,974 DEBUG CV Batch 0/1000 loss 35.346405 loss_att 71.347992 loss_ctc 38.380051 loss_rnnt 27.741604 history loss 45.837696 rank 3
2022-12-03 13:30:13,131 DEBUG CV Batch 0/1000 loss 35.346405 loss_att 71.347992 loss_ctc 38.380051 loss_rnnt 27.741604 history loss 45.837696 rank 0
2022-12-03 13:30:14,404 DEBUG CV Batch 0/1000 loss 35.346405 loss_att 71.347992 loss_ctc 38.380051 loss_rnnt 27.741604 history loss 45.837696 rank 1
2022-12-03 13:30:14,617 DEBUG CV Batch 0/1000 loss 35.346405 loss_att 71.347992 loss_ctc 38.380051 loss_rnnt 27.741604 history loss 45.837696 rank 5
2022-12-03 13:30:14,761 DEBUG CV Batch 0/1000 loss 35.346405 loss_att 71.347992 loss_ctc 38.380051 loss_rnnt 27.741604 history loss 45.837696 rank 2
2022-12-03 13:30:14,906 DEBUG CV Batch 0/1000 loss 35.346405 loss_att 71.347992 loss_ctc 38.380051 loss_rnnt 27.741604 history loss 45.837696 rank 4
2022-12-03 13:30:15,017 DEBUG CV Batch 0/1000 loss 35.346405 loss_att 71.347992 loss_ctc 38.380051 loss_rnnt 27.741604 history loss 45.837696 rank 7
2022-12-03 13:30:24,344 DEBUG CV Batch 0/1100 loss 19.208645 loss_att 26.188766 loss_ctc 22.317633 loss_rnnt 17.398090 history loss 46.047535 rank 6
2022-12-03 13:30:25,030 DEBUG CV Batch 0/1100 loss 19.208645 loss_att 26.188766 loss_ctc 22.317633 loss_rnnt 17.398090 history loss 46.047535 rank 3
2022-12-03 13:30:25,104 DEBUG CV Batch 0/1100 loss 19.208645 loss_att 26.188766 loss_ctc 22.317633 loss_rnnt 17.398090 history loss 46.047535 rank 0
2022-12-03 13:30:26,465 DEBUG CV Batch 0/1100 loss 19.208645 loss_att 26.188766 loss_ctc 22.317633 loss_rnnt 17.398090 history loss 46.047535 rank 1
2022-12-03 13:30:26,733 DEBUG CV Batch 0/1100 loss 19.208645 loss_att 26.188766 loss_ctc 22.317633 loss_rnnt 17.398090 history loss 46.047535 rank 5
2022-12-03 13:30:27,018 DEBUG CV Batch 0/1100 loss 19.208645 loss_att 26.188766 loss_ctc 22.317633 loss_rnnt 17.398090 history loss 46.047535 rank 2
2022-12-03 13:30:27,279 DEBUG CV Batch 0/1100 loss 19.208645 loss_att 26.188766 loss_ctc 22.317633 loss_rnnt 17.398090 history loss 46.047535 rank 7
2022-12-03 13:30:27,436 DEBUG CV Batch 0/1100 loss 19.208645 loss_att 26.188766 loss_ctc 22.317633 loss_rnnt 17.398090 history loss 46.047535 rank 4
2022-12-03 13:30:34,805 DEBUG CV Batch 0/1200 loss 73.068535 loss_att 131.165146 loss_ctc 79.813637 loss_rnnt 60.549862 history loss 46.404204 rank 6
2022-12-03 13:30:35,488 DEBUG CV Batch 0/1200 loss 73.068535 loss_att 131.165146 loss_ctc 79.813637 loss_rnnt 60.549862 history loss 46.404204 rank 3
2022-12-03 13:30:35,667 DEBUG CV Batch 0/1200 loss 73.068535 loss_att 131.165146 loss_ctc 79.813637 loss_rnnt 60.549862 history loss 46.404204 rank 0
2022-12-03 13:30:37,279 DEBUG CV Batch 0/1200 loss 73.068535 loss_att 131.165146 loss_ctc 79.813637 loss_rnnt 60.549862 history loss 46.404204 rank 1
2022-12-03 13:30:37,655 DEBUG CV Batch 0/1200 loss 73.068535 loss_att 131.165146 loss_ctc 79.813637 loss_rnnt 60.549862 history loss 46.404204 rank 5
2022-12-03 13:30:37,870 DEBUG CV Batch 0/1200 loss 73.068535 loss_att 131.165146 loss_ctc 79.813637 loss_rnnt 60.549862 history loss 46.404204 rank 2
2022-12-03 13:30:38,096 DEBUG CV Batch 0/1200 loss 73.068535 loss_att 131.165146 loss_ctc 79.813637 loss_rnnt 60.549862 history loss 46.404204 rank 7
2022-12-03 13:30:38,305 DEBUG CV Batch 0/1200 loss 73.068535 loss_att 131.165146 loss_ctc 79.813637 loss_rnnt 60.549862 history loss 46.404204 rank 4
2022-12-03 13:30:46,718 DEBUG CV Batch 0/1300 loss 34.496216 loss_att 47.916775 loss_ctc 39.386063 loss_rnnt 31.160124 history loss 46.855560 rank 6
2022-12-03 13:30:47,561 DEBUG CV Batch 0/1300 loss 34.496216 loss_att 47.916775 loss_ctc 39.386063 loss_rnnt 31.160124 history loss 46.855560 rank 3
2022-12-03 13:30:47,834 DEBUG CV Batch 0/1300 loss 34.496216 loss_att 47.916775 loss_ctc 39.386063 loss_rnnt 31.160124 history loss 46.855560 rank 0
2022-12-03 13:30:49,460 DEBUG CV Batch 0/1300 loss 34.496216 loss_att 47.916775 loss_ctc 39.386063 loss_rnnt 31.160124 history loss 46.855560 rank 1
2022-12-03 13:30:50,044 DEBUG CV Batch 0/1300 loss 34.496216 loss_att 47.916775 loss_ctc 39.386063 loss_rnnt 31.160124 history loss 46.855560 rank 5
2022-12-03 13:30:50,135 DEBUG CV Batch 0/1300 loss 34.496216 loss_att 47.916775 loss_ctc 39.386063 loss_rnnt 31.160124 history loss 46.855560 rank 2
2022-12-03 13:30:50,443 DEBUG CV Batch 0/1300 loss 34.496216 loss_att 47.916775 loss_ctc 39.386063 loss_rnnt 31.160124 history loss 46.855560 rank 7
2022-12-03 13:30:50,762 DEBUG CV Batch 0/1300 loss 34.496216 loss_att 47.916775 loss_ctc 39.386063 loss_rnnt 31.160124 history loss 46.855560 rank 4
2022-12-03 13:30:57,888 DEBUG CV Batch 0/1400 loss 127.706917 loss_att 309.984314 loss_ctc 116.805122 loss_rnnt 92.705009 history loss 47.522593 rank 6
2022-12-03 13:30:58,990 DEBUG CV Batch 0/1400 loss 127.706917 loss_att 309.984314 loss_ctc 116.805122 loss_rnnt 92.705009 history loss 47.522593 rank 3
2022-12-03 13:30:59,237 DEBUG CV Batch 0/1400 loss 127.706917 loss_att 309.984314 loss_ctc 116.805122 loss_rnnt 92.705009 history loss 47.522593 rank 0
2022-12-03 13:31:01,000 DEBUG CV Batch 0/1400 loss 127.706917 loss_att 309.984314 loss_ctc 116.805122 loss_rnnt 92.705009 history loss 47.522593 rank 1
2022-12-03 13:31:01,746 DEBUG CV Batch 0/1400 loss 127.706917 loss_att 309.984314 loss_ctc 116.805122 loss_rnnt 92.705009 history loss 47.522593 rank 2
2022-12-03 13:31:02,147 DEBUG CV Batch 0/1400 loss 127.706917 loss_att 309.984314 loss_ctc 116.805122 loss_rnnt 92.705009 history loss 47.522593 rank 7
2022-12-03 13:31:02,244 DEBUG CV Batch 0/1400 loss 127.706917 loss_att 309.984314 loss_ctc 116.805122 loss_rnnt 92.705009 history loss 47.522593 rank 5
2022-12-03 13:31:02,456 DEBUG CV Batch 0/1400 loss 127.706917 loss_att 309.984314 loss_ctc 116.805122 loss_rnnt 92.705009 history loss 47.522593 rank 4
2022-12-03 13:31:09,183 DEBUG CV Batch 0/1500 loss 60.293354 loss_att 122.659599 loss_ctc 59.964775 loss_rnnt 47.863914 history loss 46.846302 rank 6
2022-12-03 13:31:10,368 DEBUG CV Batch 0/1500 loss 60.293354 loss_att 122.659599 loss_ctc 59.964775 loss_rnnt 47.863914 history loss 46.846302 rank 3
2022-12-03 13:31:10,704 DEBUG CV Batch 0/1500 loss 60.293354 loss_att 122.659599 loss_ctc 59.964775 loss_rnnt 47.863914 history loss 46.846302 rank 0
2022-12-03 13:31:13,914 DEBUG CV Batch 0/1500 loss 60.293354 loss_att 122.659599 loss_ctc 59.964775 loss_rnnt 47.863914 history loss 46.846302 rank 7
2022-12-03 13:31:13,953 DEBUG CV Batch 0/1500 loss 60.293354 loss_att 122.659599 loss_ctc 59.964775 loss_rnnt 47.863914 history loss 46.846302 rank 2
2022-12-03 13:31:13,989 DEBUG CV Batch 0/1500 loss 60.293354 loss_att 122.659599 loss_ctc 59.964775 loss_rnnt 47.863914 history loss 46.846302 rank 1
2022-12-03 13:31:14,243 DEBUG CV Batch 0/1500 loss 60.293354 loss_att 122.659599 loss_ctc 59.964775 loss_rnnt 47.863914 history loss 46.846302 rank 4
2022-12-03 13:31:15,090 DEBUG CV Batch 0/1500 loss 60.293354 loss_att 122.659599 loss_ctc 59.964775 loss_rnnt 47.863914 history loss 46.846302 rank 5
2022-12-03 13:31:22,323 DEBUG CV Batch 0/1600 loss 122.034561 loss_att 306.215179 loss_ctc 108.597992 loss_rnnt 86.989975 history loss 46.985549 rank 6
2022-12-03 13:31:23,604 DEBUG CV Batch 0/1600 loss 122.034561 loss_att 306.215179 loss_ctc 108.597992 loss_rnnt 86.989975 history loss 46.985549 rank 3
2022-12-03 13:31:23,982 DEBUG CV Batch 0/1600 loss 122.034561 loss_att 306.215179 loss_ctc 108.597992 loss_rnnt 86.989975 history loss 46.985549 rank 0
2022-12-03 13:31:27,857 DEBUG CV Batch 0/1600 loss 122.034561 loss_att 306.215179 loss_ctc 108.597992 loss_rnnt 86.989975 history loss 46.985549 rank 1
2022-12-03 13:31:27,876 DEBUG CV Batch 0/1600 loss 122.034561 loss_att 306.215179 loss_ctc 108.597992 loss_rnnt 86.989975 history loss 46.985549 rank 7
2022-12-03 13:31:27,947 DEBUG CV Batch 0/1600 loss 122.034561 loss_att 306.215179 loss_ctc 108.597992 loss_rnnt 86.989975 history loss 46.985549 rank 2
2022-12-03 13:31:28,166 DEBUG CV Batch 0/1600 loss 122.034561 loss_att 306.215179 loss_ctc 108.597992 loss_rnnt 86.989975 history loss 46.985549 rank 4
2022-12-03 13:31:29,058 DEBUG CV Batch 0/1600 loss 122.034561 loss_att 306.215179 loss_ctc 108.597992 loss_rnnt 86.989975 history loss 46.985549 rank 5
2022-12-03 13:31:34,696 DEBUG CV Batch 0/1700 loss 57.236382 loss_att 96.113800 loss_ctc 63.550865 loss_rnnt 48.618965 history loss 46.651073 rank 6
2022-12-03 13:31:36,254 DEBUG CV Batch 0/1700 loss 57.236382 loss_att 96.113800 loss_ctc 63.550865 loss_rnnt 48.618965 history loss 46.651073 rank 3
2022-12-03 13:31:36,576 DEBUG CV Batch 0/1700 loss 57.236382 loss_att 96.113800 loss_ctc 63.550865 loss_rnnt 48.618965 history loss 46.651073 rank 0
2022-12-03 13:31:40,510 DEBUG CV Batch 0/1700 loss 57.236382 loss_att 96.113800 loss_ctc 63.550865 loss_rnnt 48.618965 history loss 46.651073 rank 1
2022-12-03 13:31:40,767 DEBUG CV Batch 0/1700 loss 57.236382 loss_att 96.113800 loss_ctc 63.550865 loss_rnnt 48.618965 history loss 46.651073 rank 2
2022-12-03 13:31:40,847 DEBUG CV Batch 0/1700 loss 57.236382 loss_att 96.113800 loss_ctc 63.550865 loss_rnnt 48.618965 history loss 46.651073 rank 4
2022-12-03 13:31:40,899 DEBUG CV Batch 0/1700 loss 57.236382 loss_att 96.113800 loss_ctc 63.550865 loss_rnnt 48.618965 history loss 46.651073 rank 7
2022-12-03 13:31:41,859 DEBUG CV Batch 0/1700 loss 57.236382 loss_att 96.113800 loss_ctc 63.550865 loss_rnnt 48.618965 history loss 46.651073 rank 5
2022-12-03 13:31:43,882 INFO Epoch 0 CV info cv_loss 46.80984417154087
2022-12-03 13:31:43,883 INFO Epoch 1 TRAIN info lr 0.00033344
2022-12-03 13:31:43,887 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 13:31:45,600 INFO Epoch 0 CV info cv_loss 46.80984417154087
2022-12-03 13:31:45,600 INFO Epoch 1 TRAIN info lr 0.00033336
2022-12-03 13:31:45,602 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 13:31:45,883 INFO Epoch 0 CV info cv_loss 46.80984417154087
2022-12-03 13:31:45,883 INFO Checkpoint: save to checkpoint exp/1202_encoder_bias_30_0.1/0.pt
2022-12-03 13:31:46,456 INFO Epoch 1 TRAIN info lr 0.00033276000000000003
2022-12-03 13:31:46,459 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 13:31:49,620 INFO Epoch 0 CV info cv_loss 46.80984417154087
2022-12-03 13:31:49,620 INFO Epoch 1 TRAIN info lr 0.0003344
2022-12-03 13:31:49,622 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 13:31:50,126 INFO Epoch 0 CV info cv_loss 46.80984417154087
2022-12-03 13:31:50,126 INFO Epoch 1 TRAIN info lr 0.00033316
2022-12-03 13:31:50,131 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 13:31:50,180 INFO Epoch 0 CV info cv_loss 46.80984417154087
2022-12-03 13:31:50,180 INFO Epoch 1 TRAIN info lr 0.0003336
2022-12-03 13:31:50,182 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 13:31:50,501 INFO Epoch 0 CV info cv_loss 46.80984417154087
2022-12-03 13:31:50,502 INFO Epoch 1 TRAIN info lr 0.00033324
2022-12-03 13:31:50,507 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 13:31:51,037 INFO Epoch 0 CV info cv_loss 46.80984417154087
2022-12-03 13:31:51,037 INFO Epoch 1 TRAIN info lr 0.00033332
2022-12-03 13:31:51,039 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 13:32:56,565 DEBUG TRAIN Batch 1/0 loss 25.237120 loss_att 33.781929 loss_ctc 27.267252 loss_rnnt 23.257475 lr 0.00033280 rank 0
2022-12-03 13:32:56,569 DEBUG TRAIN Batch 1/0 loss 40.391258 loss_att 49.333393 loss_ctc 43.482338 loss_rnnt 38.190689 lr 0.00033348 rank 6
2022-12-03 13:32:56,570 DEBUG TRAIN Batch 1/0 loss 33.185070 loss_att 42.100761 loss_ctc 38.140057 loss_rnnt 30.741268 lr 0.00033444 rank 1
2022-12-03 13:32:56,575 DEBUG TRAIN Batch 1/0 loss 31.822449 loss_att 36.077911 loss_ctc 37.744968 loss_rnnt 30.181688 lr 0.00033328 rank 7
2022-12-03 13:32:56,575 DEBUG TRAIN Batch 1/0 loss 31.335140 loss_att 36.987556 loss_ctc 35.320549 loss_rnnt 29.673269 lr 0.00033320 rank 4
2022-12-03 13:32:56,576 DEBUG TRAIN Batch 1/0 loss 34.342854 loss_att 40.951641 loss_ctc 38.453575 loss_rnnt 32.472996 lr 0.00033340 rank 3
2022-12-03 13:32:56,589 DEBUG TRAIN Batch 1/0 loss 22.235695 loss_att 31.436172 loss_ctc 23.369997 loss_rnnt 20.244360 lr 0.00033364 rank 2
2022-12-03 13:32:56,639 DEBUG TRAIN Batch 1/0 loss 33.914978 loss_att 42.223705 loss_ctc 38.673386 loss_rnnt 31.618780 lr 0.00033336 rank 5
2022-12-03 13:34:07,605 DEBUG TRAIN Batch 1/100 loss 112.297226 loss_att 207.253021 loss_ctc 115.333275 loss_rnnt 92.901260 lr 0.00033736 rank 5
2022-12-03 13:34:07,608 DEBUG TRAIN Batch 1/100 loss 123.484024 loss_att 208.704132 loss_ctc 139.810913 loss_rnnt 104.263084 lr 0.00033844 rank 1
2022-12-03 13:34:07,608 DEBUG TRAIN Batch 1/100 loss 88.760399 loss_att 191.328415 loss_ctc 96.976913 loss_rnnt 67.151253 lr 0.00033728 rank 7
2022-12-03 13:34:07,609 DEBUG TRAIN Batch 1/100 loss 92.363808 loss_att 198.142990 loss_ctc 98.816216 loss_rnnt 70.347649 lr 0.00033740 rank 3
2022-12-03 13:34:07,610 DEBUG TRAIN Batch 1/100 loss 74.252113 loss_att 172.952881 loss_ctc 70.134888 loss_rnnt 55.060925 lr 0.00033748 rank 6
2022-12-03 13:34:07,611 DEBUG TRAIN Batch 1/100 loss 108.836151 loss_att 218.711304 loss_ctc 103.315109 loss_rnnt 87.597244 lr 0.00033680 rank 0
2022-12-03 13:34:07,614 DEBUG TRAIN Batch 1/100 loss 105.089691 loss_att 204.906982 loss_ctc 107.703735 loss_rnnt 84.777695 lr 0.00033764 rank 2
2022-12-03 13:34:07,618 DEBUG TRAIN Batch 1/100 loss 84.277962 loss_att 174.112274 loss_ctc 94.039673 loss_rnnt 65.009537 lr 0.00033720 rank 4
2022-12-03 13:35:18,755 DEBUG TRAIN Batch 1/200 loss 72.870117 loss_att 189.735535 loss_ctc 66.450020 loss_rnnt 50.353054 lr 0.00034140 rank 3
2022-12-03 13:35:18,769 DEBUG TRAIN Batch 1/200 loss 75.580772 loss_att 171.091156 loss_ctc 77.668381 loss_rnnt 56.200348 lr 0.00034148 rank 6
2022-12-03 13:35:18,769 DEBUG TRAIN Batch 1/200 loss 111.397903 loss_att 210.768555 loss_ctc 125.863121 loss_rnnt 89.595078 lr 0.00034136 rank 5
2022-12-03 13:35:18,773 DEBUG TRAIN Batch 1/200 loss 82.195633 loss_att 186.021637 loss_ctc 83.072510 loss_rnnt 61.313515 lr 0.00034244 rank 1
2022-12-03 13:35:18,773 DEBUG TRAIN Batch 1/200 loss 112.056870 loss_att 221.691406 loss_ctc 113.970245 loss_rnnt 89.874840 lr 0.00034128 rank 7
2022-12-03 13:35:18,774 DEBUG TRAIN Batch 1/200 loss 100.864449 loss_att 190.073761 loss_ctc 102.456802 loss_rnnt 82.810272 lr 0.00034120 rank 4
2022-12-03 13:35:18,775 DEBUG TRAIN Batch 1/200 loss 83.070557 loss_att 189.841370 loss_ctc 75.812233 loss_rnnt 62.684174 lr 0.00034080 rank 0
2022-12-03 13:35:18,777 DEBUG TRAIN Batch 1/200 loss 80.180489 loss_att 164.279312 loss_ctc 84.249908 loss_rnnt 62.818138 lr 0.00034164 rank 2
2022-12-03 13:36:30,949 DEBUG TRAIN Batch 1/300 loss 87.611473 loss_att 188.434052 loss_ctc 89.208122 loss_rnnt 67.234070 lr 0.00034536 rank 5
2022-12-03 13:36:30,960 DEBUG TRAIN Batch 1/300 loss 74.604446 loss_att 180.732773 loss_ctc 75.303268 loss_rnnt 53.285606 lr 0.00034644 rank 1
2022-12-03 13:36:30,962 DEBUG TRAIN Batch 1/300 loss 88.118118 loss_att 168.574158 loss_ctc 92.857887 loss_rnnt 71.394943 lr 0.00034480 rank 0
2022-12-03 13:36:30,962 DEBUG TRAIN Batch 1/300 loss 59.481514 loss_att 146.399185 loss_ctc 65.969307 loss_rnnt 41.232937 lr 0.00034528 rank 7
2022-12-03 13:36:30,965 DEBUG TRAIN Batch 1/300 loss 98.367096 loss_att 209.456177 loss_ctc 104.541092 loss_rnnt 75.326080 lr 0.00034564 rank 2
2022-12-03 13:36:30,969 DEBUG TRAIN Batch 1/300 loss 89.280365 loss_att 209.087158 loss_ctc 94.344299 loss_rnnt 64.643822 lr 0.00034520 rank 4
2022-12-03 13:36:30,980 DEBUG TRAIN Batch 1/300 loss 107.390671 loss_att 224.295853 loss_ctc 112.001053 loss_rnnt 83.394920 lr 0.00034548 rank 6
2022-12-03 13:36:30,982 DEBUG TRAIN Batch 1/300 loss 79.166000 loss_att 169.158417 loss_ctc 87.062683 loss_rnnt 60.114628 lr 0.00034540 rank 3
2022-12-03 13:37:44,041 DEBUG TRAIN Batch 1/400 loss 83.132561 loss_att 169.847916 loss_ctc 82.847229 loss_rnnt 65.827538 lr 0.00034940 rank 3
2022-12-03 13:37:44,043 DEBUG TRAIN Batch 1/400 loss 54.920979 loss_att 136.949768 loss_ctc 55.793144 loss_rnnt 38.398933 lr 0.00034880 rank 0
2022-12-03 13:37:44,044 DEBUG TRAIN Batch 1/400 loss 124.473564 loss_att 212.936646 loss_ctc 137.734222 loss_rnnt 105.012863 lr 0.00034948 rank 6
2022-12-03 13:37:44,045 DEBUG TRAIN Batch 1/400 loss 101.509827 loss_att 196.504837 loss_ctc 100.739899 loss_rnnt 82.613472 lr 0.00035044 rank 1
2022-12-03 13:37:44,048 DEBUG TRAIN Batch 1/400 loss 96.561234 loss_att 199.386261 loss_ctc 99.132065 loss_rnnt 75.653450 lr 0.00034936 rank 5
2022-12-03 13:37:44,050 DEBUG TRAIN Batch 1/400 loss 77.591820 loss_att 174.678802 loss_ctc 78.000137 loss_rnnt 58.119972 lr 0.00034928 rank 7
2022-12-03 13:37:44,085 DEBUG TRAIN Batch 1/400 loss 89.247795 loss_att 190.137283 loss_ctc 97.444229 loss_rnnt 67.977043 lr 0.00034920 rank 4
2022-12-03 13:37:44,111 DEBUG TRAIN Batch 1/400 loss 97.073883 loss_att 194.881012 loss_ctc 97.290344 loss_rnnt 77.483589 lr 0.00034964 rank 2
2022-12-03 13:38:55,559 DEBUG TRAIN Batch 1/500 loss 52.152588 loss_att 130.525101 loss_ctc 54.987770 loss_rnnt 36.100063 lr 0.00035348 rank 6
2022-12-03 13:38:55,562 DEBUG TRAIN Batch 1/500 loss 63.883888 loss_att 141.727661 loss_ctc 69.634911 loss_rnnt 47.548332 lr 0.00035280 rank 0
2022-12-03 13:38:55,563 DEBUG TRAIN Batch 1/500 loss 73.780243 loss_att 159.619766 loss_ctc 77.047722 loss_rnnt 56.176666 lr 0.00035336 rank 5
2022-12-03 13:38:55,563 DEBUG TRAIN Batch 1/500 loss 66.423859 loss_att 137.447800 loss_ctc 71.632759 loss_rnnt 51.524544 lr 0.00035364 rank 2
2022-12-03 13:38:55,564 DEBUG TRAIN Batch 1/500 loss 69.137413 loss_att 141.938171 loss_ctc 71.502243 loss_rnnt 54.261951 lr 0.00035340 rank 3
2022-12-03 13:38:55,566 DEBUG TRAIN Batch 1/500 loss 80.746277 loss_att 155.482162 loss_ctc 84.616531 loss_rnnt 65.283066 lr 0.00035444 rank 1
2022-12-03 13:38:55,572 DEBUG TRAIN Batch 1/500 loss 59.354557 loss_att 121.014267 loss_ctc 59.125244 loss_rnnt 47.053188 lr 0.00035320 rank 4
2022-12-03 13:38:55,610 DEBUG TRAIN Batch 1/500 loss 90.056885 loss_att 176.131577 loss_ctc 97.387459 loss_rnnt 71.864532 lr 0.00035328 rank 7
2022-12-03 13:40:06,772 DEBUG TRAIN Batch 1/600 loss 43.166725 loss_att 89.578735 loss_ctc 48.764294 loss_rnnt 33.137981 lr 0.00035736 rank 5
2022-12-03 13:40:06,772 DEBUG TRAIN Batch 1/600 loss 41.520859 loss_att 62.173882 loss_ctc 45.707569 loss_rnnt 36.832027 lr 0.00035748 rank 6
2022-12-03 13:40:06,773 DEBUG TRAIN Batch 1/600 loss 49.388714 loss_att 99.391586 loss_ctc 55.357086 loss_rnnt 38.592358 lr 0.00035728 rank 7
2022-12-03 13:40:06,775 DEBUG TRAIN Batch 1/600 loss 32.132088 loss_att 62.097847 loss_ctc 37.664688 loss_rnnt 25.401258 lr 0.00035740 rank 3
2022-12-03 13:40:06,779 DEBUG TRAIN Batch 1/600 loss 83.143242 loss_att 143.134827 loss_ctc 86.250900 loss_rnnt 70.730568 lr 0.00035844 rank 1
2022-12-03 13:40:06,779 DEBUG TRAIN Batch 1/600 loss 45.216267 loss_att 70.100578 loss_ctc 52.109589 loss_rnnt 39.320293 lr 0.00035764 rank 2
2022-12-03 13:40:06,780 DEBUG TRAIN Batch 1/600 loss 35.376595 loss_att 60.788105 loss_ctc 37.403591 loss_rnnt 30.024025 lr 0.00035720 rank 4
2022-12-03 13:40:06,782 DEBUG TRAIN Batch 1/600 loss 32.345470 loss_att 52.612026 loss_ctc 36.316235 loss_rnnt 27.762722 lr 0.00035680 rank 0
2022-12-03 13:41:20,562 DEBUG TRAIN Batch 1/700 loss 95.707855 loss_att 182.152267 loss_ctc 96.057762 loss_rnnt 78.372314 lr 0.00036136 rank 5
2022-12-03 13:41:20,564 DEBUG TRAIN Batch 1/700 loss 106.957191 loss_att 181.921265 loss_ctc 124.118546 loss_rnnt 89.676193 lr 0.00036244 rank 1
2022-12-03 13:41:20,564 DEBUG TRAIN Batch 1/700 loss 89.475937 loss_att 175.757141 loss_ctc 96.544144 loss_rnnt 71.277267 lr 0.00036148 rank 6
2022-12-03 13:41:20,567 DEBUG TRAIN Batch 1/700 loss 90.987900 loss_att 185.367935 loss_ctc 99.009079 loss_rnnt 71.042404 lr 0.00036080 rank 0
2022-12-03 13:41:20,568 DEBUG TRAIN Batch 1/700 loss 126.578415 loss_att 219.959381 loss_ctc 133.287628 loss_rnnt 107.007652 lr 0.00036120 rank 4
2022-12-03 13:41:20,571 DEBUG TRAIN Batch 1/700 loss 95.443474 loss_att 205.939423 loss_ctc 101.493164 loss_rnnt 72.537659 lr 0.00036128 rank 7
2022-12-03 13:41:20,607 DEBUG TRAIN Batch 1/700 loss 96.418915 loss_att 188.042908 loss_ctc 108.530060 loss_rnnt 76.479294 lr 0.00036140 rank 3
2022-12-03 13:41:20,609 DEBUG TRAIN Batch 1/700 loss 83.740295 loss_att 175.575592 loss_ctc 82.787491 loss_rnnt 65.500275 lr 0.00036164 rank 2
2022-12-03 13:42:33,323 DEBUG TRAIN Batch 1/800 loss 79.295876 loss_att 157.112305 loss_ctc 89.033073 loss_rnnt 62.434292 lr 0.00036480 rank 0
2022-12-03 13:42:33,325 DEBUG TRAIN Batch 1/800 loss 94.001053 loss_att 172.106903 loss_ctc 94.401169 loss_rnnt 78.326530 lr 0.00036536 rank 5
2022-12-03 13:42:33,328 DEBUG TRAIN Batch 1/800 loss 65.534065 loss_att 148.350784 loss_ctc 66.834625 loss_rnnt 48.797314 lr 0.00036548 rank 6
2022-12-03 13:42:33,330 DEBUG TRAIN Batch 1/800 loss 92.611031 loss_att 186.859177 loss_ctc 94.931671 loss_rnnt 73.451988 lr 0.00036644 rank 1
2022-12-03 13:42:33,337 DEBUG TRAIN Batch 1/800 loss 70.833344 loss_att 152.574432 loss_ctc 79.487595 loss_rnnt 53.331219 lr 0.00036540 rank 3
2022-12-03 13:42:33,338 DEBUG TRAIN Batch 1/800 loss 67.613289 loss_att 182.222092 loss_ctc 68.398804 loss_rnnt 44.586792 lr 0.00036528 rank 7
2022-12-03 13:42:33,339 DEBUG TRAIN Batch 1/800 loss 95.867218 loss_att 194.171524 loss_ctc 98.772781 loss_rnnt 75.818939 lr 0.00036520 rank 4
2022-12-03 13:42:33,381 DEBUG TRAIN Batch 1/800 loss 74.106339 loss_att 152.712799 loss_ctc 80.201134 loss_rnnt 57.572399 lr 0.00036564 rank 2
2022-12-03 13:43:44,914 DEBUG TRAIN Batch 1/900 loss 84.417221 loss_att 158.021851 loss_ctc 97.287590 loss_rnnt 67.980240 lr 0.00037044 rank 1
2022-12-03 13:43:44,915 DEBUG TRAIN Batch 1/900 loss 69.570572 loss_att 159.638077 loss_ctc 69.019081 loss_rnnt 51.630592 lr 0.00036948 rank 6
2022-12-03 13:43:44,915 DEBUG TRAIN Batch 1/900 loss 87.541519 loss_att 161.638321 loss_ctc 92.364235 loss_rnnt 72.079132 lr 0.00036880 rank 0
2022-12-03 13:43:44,916 DEBUG TRAIN Batch 1/900 loss 87.252129 loss_att 171.024017 loss_ctc 94.207329 loss_rnnt 69.570389 lr 0.00036964 rank 2
2022-12-03 13:43:44,916 DEBUG TRAIN Batch 1/900 loss 69.580627 loss_att 148.202148 loss_ctc 71.803825 loss_rnnt 53.559902 lr 0.00036936 rank 5
2022-12-03 13:43:44,920 DEBUG TRAIN Batch 1/900 loss 70.662170 loss_att 139.503311 loss_ctc 78.909248 loss_rnnt 55.794327 lr 0.00036940 rank 3
2022-12-03 13:43:44,921 DEBUG TRAIN Batch 1/900 loss 102.211563 loss_att 221.290863 loss_ctc 103.103607 loss_rnnt 78.276764 lr 0.00036928 rank 7
2022-12-03 13:43:44,967 DEBUG TRAIN Batch 1/900 loss 77.970901 loss_att 185.665009 loss_ctc 81.144096 loss_rnnt 56.008980 lr 0.00036920 rank 4
2022-12-03 13:44:57,037 DEBUG TRAIN Batch 1/1000 loss 78.585991 loss_att 146.635895 loss_ctc 86.458801 loss_rnnt 63.926300 lr 0.00037348 rank 6
2022-12-03 13:44:57,038 DEBUG TRAIN Batch 1/1000 loss 76.235565 loss_att 161.970978 loss_ctc 79.262810 loss_rnnt 58.684845 lr 0.00037328 rank 7
2022-12-03 13:44:57,037 DEBUG TRAIN Batch 1/1000 loss 75.012848 loss_att 163.750259 loss_ctc 78.966827 loss_rnnt 56.738163 lr 0.00037444 rank 1
2022-12-03 13:44:57,038 DEBUG TRAIN Batch 1/1000 loss 57.764748 loss_att 127.403168 loss_ctc 56.666641 loss_rnnt 43.983475 lr 0.00037280 rank 0
2022-12-03 13:44:57,040 DEBUG TRAIN Batch 1/1000 loss 69.573166 loss_att 155.532608 loss_ctc 74.067062 loss_rnnt 51.782085 lr 0.00037364 rank 2
2022-12-03 13:44:57,040 DEBUG TRAIN Batch 1/1000 loss 76.486191 loss_att 149.193878 loss_ctc 82.450821 loss_rnnt 61.149376 lr 0.00037320 rank 4
2022-12-03 13:44:57,041 DEBUG TRAIN Batch 1/1000 loss 96.728577 loss_att 183.557846 loss_ctc 110.418762 loss_rnnt 77.537369 lr 0.00037340 rank 3
2022-12-03 13:44:57,061 DEBUG TRAIN Batch 1/1000 loss 95.757362 loss_att 173.643845 loss_ctc 106.220184 loss_rnnt 78.785019 lr 0.00037336 rank 5
2022-12-03 13:46:10,705 DEBUG TRAIN Batch 1/1100 loss 65.061630 loss_att 128.968445 loss_ctc 70.485779 loss_rnnt 51.557045 lr 0.00037736 rank 5
2022-12-03 13:46:10,706 DEBUG TRAIN Batch 1/1100 loss 62.921600 loss_att 128.125427 loss_ctc 72.196487 loss_rnnt 48.644180 lr 0.00037740 rank 3
2022-12-03 13:46:10,706 DEBUG TRAIN Batch 1/1100 loss 54.356567 loss_att 127.216156 loss_ctc 53.692986 loss_rnnt 39.873127 lr 0.00037748 rank 6
2022-12-03 13:46:10,710 DEBUG TRAIN Batch 1/1100 loss 52.592216 loss_att 120.204224 loss_ctc 60.596962 loss_rnnt 38.002518 lr 0.00037680 rank 0
2022-12-03 13:46:10,715 DEBUG TRAIN Batch 1/1100 loss 64.444901 loss_att 121.431297 loss_ctc 78.585739 loss_rnnt 51.162170 lr 0.00037720 rank 4
2022-12-03 13:46:10,714 DEBUG TRAIN Batch 1/1100 loss 65.795670 loss_att 139.905762 loss_ctc 70.587936 loss_rnnt 50.334686 lr 0.00037728 rank 7
2022-12-03 13:46:10,727 DEBUG TRAIN Batch 1/1100 loss 63.309723 loss_att 146.123001 loss_ctc 65.898590 loss_rnnt 46.401886 lr 0.00037844 rank 1
2022-12-03 13:46:10,760 DEBUG TRAIN Batch 1/1100 loss 56.777966 loss_att 124.055984 loss_ctc 62.304665 loss_rnnt 42.585468 lr 0.00037764 rank 2
2022-12-03 13:47:22,873 DEBUG TRAIN Batch 1/1200 loss 82.426636 loss_att 130.441483 loss_ctc 97.106216 loss_rnnt 70.866386 lr 0.00038148 rank 6
2022-12-03 13:47:22,874 DEBUG TRAIN Batch 1/1200 loss 53.914642 loss_att 96.810577 loss_ctc 58.767811 loss_rnnt 44.688362 lr 0.00038140 rank 3
2022-12-03 13:47:22,876 DEBUG TRAIN Batch 1/1200 loss 72.274597 loss_att 126.659569 loss_ctc 75.972282 loss_rnnt 60.904579 lr 0.00038244 rank 1
2022-12-03 13:47:22,876 DEBUG TRAIN Batch 1/1200 loss 37.328514 loss_att 78.666359 loss_ctc 39.666779 loss_rnnt 28.749176 lr 0.00038136 rank 5
2022-12-03 13:47:22,879 DEBUG TRAIN Batch 1/1200 loss 32.561966 loss_att 50.206169 loss_ctc 39.799580 loss_rnnt 28.068113 lr 0.00038164 rank 2
2022-12-03 13:47:22,881 DEBUG TRAIN Batch 1/1200 loss 51.038483 loss_att 85.676270 loss_ctc 58.194538 loss_rnnt 43.156784 lr 0.00038080 rank 0
2022-12-03 13:47:22,890 DEBUG TRAIN Batch 1/1200 loss 54.218147 loss_att 109.137222 loss_ctc 59.557922 loss_rnnt 42.522362 lr 0.00038128 rank 7
2022-12-03 13:47:22,892 DEBUG TRAIN Batch 1/1200 loss 39.778793 loss_att 82.803276 loss_ctc 46.534988 loss_rnnt 30.273071 lr 0.00038120 rank 4
2022-12-03 13:48:34,066 DEBUG TRAIN Batch 1/1300 loss 76.371025 loss_att 168.176117 loss_ctc 82.353683 loss_rnnt 57.212318 lr 0.00038548 rank 6
2022-12-03 13:48:34,068 DEBUG TRAIN Batch 1/1300 loss 81.612167 loss_att 174.975540 loss_ctc 90.693298 loss_rnnt 61.728680 lr 0.00038540 rank 3
2022-12-03 13:48:34,072 DEBUG TRAIN Batch 1/1300 loss 105.095764 loss_att 186.742203 loss_ctc 116.375534 loss_rnnt 87.262512 lr 0.00038480 rank 0
2022-12-03 13:48:34,072 DEBUG TRAIN Batch 1/1300 loss 90.571915 loss_att 182.466507 loss_ctc 101.860741 loss_rnnt 70.687820 lr 0.00038536 rank 5
2022-12-03 13:48:34,075 DEBUG TRAIN Batch 1/1300 loss 73.775253 loss_att 146.827637 loss_ctc 82.419937 loss_rnnt 58.012146 lr 0.00038564 rank 2
2022-12-03 13:48:34,077 DEBUG TRAIN Batch 1/1300 loss 86.981110 loss_att 188.282471 loss_ctc 97.623405 loss_rnnt 65.301865 lr 0.00038528 rank 7
2022-12-03 13:48:34,081 DEBUG TRAIN Batch 1/1300 loss 67.868805 loss_att 166.305450 loss_ctc 80.953751 loss_rnnt 46.436821 lr 0.00038520 rank 4
2022-12-03 13:48:34,118 DEBUG TRAIN Batch 1/1300 loss 45.536144 loss_att 71.553986 loss_ctc 51.085426 loss_rnnt 39.592670 lr 0.00038644 rank 1
2022-12-03 13:49:47,907 DEBUG TRAIN Batch 1/1400 loss 88.759636 loss_att 169.745316 loss_ctc 92.925629 loss_rnnt 72.007027 lr 0.00038928 rank 7
2022-12-03 13:49:47,918 DEBUG TRAIN Batch 1/1400 loss 63.458664 loss_att 134.646561 loss_ctc 69.685623 loss_rnnt 48.390820 lr 0.00038920 rank 4
2022-12-03 13:49:47,925 DEBUG TRAIN Batch 1/1400 loss 58.111664 loss_att 146.859406 loss_ctc 59.193871 loss_rnnt 40.217819 lr 0.00038940 rank 3
2022-12-03 13:49:47,926 DEBUG TRAIN Batch 1/1400 loss 71.499527 loss_att 165.685745 loss_ctc 79.926559 loss_rnnt 51.538681 lr 0.00039044 rank 1
2022-12-03 13:49:47,928 DEBUG TRAIN Batch 1/1400 loss 54.729172 loss_att 123.454857 loss_ctc 60.472206 loss_rnnt 40.218292 lr 0.00038948 rank 6
2022-12-03 13:49:47,928 DEBUG TRAIN Batch 1/1400 loss 82.010254 loss_att 166.171799 loss_ctc 88.039398 loss_rnnt 64.374054 lr 0.00038880 rank 0
2022-12-03 13:49:47,929 DEBUG TRAIN Batch 1/1400 loss 96.750435 loss_att 184.063049 loss_ctc 105.107727 loss_rnnt 78.173599 lr 0.00038964 rank 2
2022-12-03 13:49:47,929 DEBUG TRAIN Batch 1/1400 loss 78.097488 loss_att 176.599792 loss_ctc 86.681107 loss_rnnt 57.252541 lr 0.00038936 rank 5
2022-12-03 13:51:00,813 DEBUG TRAIN Batch 1/1500 loss 58.256653 loss_att 132.007935 loss_ctc 64.781410 loss_rnnt 42.636425 lr 0.00039280 rank 0
2022-12-03 13:51:00,813 DEBUG TRAIN Batch 1/1500 loss 66.787727 loss_att 166.117157 loss_ctc 73.324852 loss_rnnt 46.050224 lr 0.00039348 rank 6
2022-12-03 13:51:00,815 DEBUG TRAIN Batch 1/1500 loss 91.600830 loss_att 176.427826 loss_ctc 103.702621 loss_rnnt 73.021866 lr 0.00039364 rank 2
2022-12-03 13:51:00,816 DEBUG TRAIN Batch 1/1500 loss 30.538013 loss_att 108.348419 loss_ctc 23.965179 loss_rnnt 15.852310 lr 0.00039444 rank 1
2022-12-03 13:51:00,820 DEBUG TRAIN Batch 1/1500 loss 67.491913 loss_att 155.266693 loss_ctc 75.585083 loss_rnnt 48.857864 lr 0.00039328 rank 7
2022-12-03 13:51:00,823 DEBUG TRAIN Batch 1/1500 loss 107.927040 loss_att 190.153503 loss_ctc 127.902428 loss_rnnt 88.818359 lr 0.00039340 rank 3
2022-12-03 13:51:00,827 DEBUG TRAIN Batch 1/1500 loss 61.134933 loss_att 135.484863 loss_ctc 63.617596 loss_rnnt 45.933926 lr 0.00039320 rank 4
2022-12-03 13:51:00,860 DEBUG TRAIN Batch 1/1500 loss 79.012634 loss_att 155.935440 loss_ctc 84.531090 loss_rnnt 62.892273 lr 0.00039336 rank 5
2022-12-03 13:52:12,110 DEBUG TRAIN Batch 1/1600 loss 56.016060 loss_att 132.813416 loss_ctc 63.555267 loss_rnnt 39.651363 lr 0.00039680 rank 0
2022-12-03 13:52:12,129 DEBUG TRAIN Batch 1/1600 loss 61.429855 loss_att 134.620636 loss_ctc 66.276230 loss_rnnt 46.145512 lr 0.00039736 rank 5
2022-12-03 13:52:12,131 DEBUG TRAIN Batch 1/1600 loss 41.282059 loss_att 120.871399 loss_ctc 42.042747 loss_rnnt 25.262766 lr 0.00039740 rank 3
2022-12-03 13:52:12,132 DEBUG TRAIN Batch 1/1600 loss 67.185684 loss_att 137.931137 loss_ctc 72.591400 loss_rnnt 52.315834 lr 0.00039748 rank 6
2022-12-03 13:52:12,133 DEBUG TRAIN Batch 1/1600 loss 87.142700 loss_att 168.389465 loss_ctc 102.506470 loss_rnnt 68.844841 lr 0.00039844 rank 1
2022-12-03 13:52:12,137 DEBUG TRAIN Batch 1/1600 loss 77.259750 loss_att 153.640274 loss_ctc 87.544945 loss_rnnt 60.612286 lr 0.00039764 rank 2
2022-12-03 13:52:12,142 DEBUG TRAIN Batch 1/1600 loss 66.221756 loss_att 129.445969 loss_ctc 76.428978 loss_rnnt 52.215942 lr 0.00039728 rank 7
2022-12-03 13:52:12,143 DEBUG TRAIN Batch 1/1600 loss 61.180531 loss_att 136.887070 loss_ctc 69.285179 loss_rnnt 44.958603 lr 0.00039720 rank 4
2022-12-03 13:53:25,150 DEBUG TRAIN Batch 1/1700 loss 78.716087 loss_att 147.529694 loss_ctc 87.703476 loss_rnnt 63.755043 lr 0.00040148 rank 6
2022-12-03 13:53:25,151 DEBUG TRAIN Batch 1/1700 loss 77.308800 loss_att 148.242477 loss_ctc 89.069656 loss_rnnt 61.553951 lr 0.00040140 rank 3
2022-12-03 13:53:25,153 DEBUG TRAIN Batch 1/1700 loss 77.166870 loss_att 144.638351 loss_ctc 76.189133 loss_rnnt 63.802940 lr 0.00040164 rank 2
2022-12-03 13:53:25,154 DEBUG TRAIN Batch 1/1700 loss 65.695580 loss_att 141.301254 loss_ctc 69.320915 loss_rnnt 50.091064 lr 0.00040080 rank 0
2022-12-03 13:53:25,157 DEBUG TRAIN Batch 1/1700 loss 108.105881 loss_att 195.183212 loss_ctc 129.047943 loss_rnnt 87.898140 lr 0.00040244 rank 1
2022-12-03 13:53:25,159 DEBUG TRAIN Batch 1/1700 loss 77.661797 loss_att 158.796677 loss_ctc 82.180862 loss_rnnt 60.832275 lr 0.00040120 rank 4
2022-12-03 13:53:25,162 DEBUG TRAIN Batch 1/1700 loss 79.674156 loss_att 151.599442 loss_ctc 92.862091 loss_rnnt 63.530704 lr 0.00040128 rank 7
2022-12-03 13:53:25,169 DEBUG TRAIN Batch 1/1700 loss 51.692940 loss_att 119.428696 loss_ctc 61.942795 loss_rnnt 36.779137 lr 0.00040136 rank 5
2022-12-03 13:54:39,307 DEBUG TRAIN Batch 1/1800 loss 73.316536 loss_att 122.238762 loss_ctc 83.979362 loss_rnnt 62.110378 lr 0.00040548 rank 6
2022-12-03 13:54:39,308 DEBUG TRAIN Batch 1/1800 loss 38.877937 loss_att 65.845917 loss_ctc 43.772125 loss_rnnt 32.831783 lr 0.00040480 rank 0
2022-12-03 13:54:39,310 DEBUG TRAIN Batch 1/1800 loss 60.239136 loss_att 114.728561 loss_ctc 63.153351 loss_rnnt 48.952690 lr 0.00040536 rank 5
2022-12-03 13:54:39,312 DEBUG TRAIN Batch 1/1800 loss 59.304382 loss_att 103.094200 loss_ctc 71.495010 loss_rnnt 48.921001 lr 0.00040564 rank 2
2022-12-03 13:54:39,317 DEBUG TRAIN Batch 1/1800 loss 68.321465 loss_att 130.222961 loss_ctc 82.873451 loss_rnnt 54.000893 lr 0.00040540 rank 3
2022-12-03 13:54:39,318 DEBUG TRAIN Batch 1/1800 loss 91.119408 loss_att 161.172821 loss_ctc 108.046234 loss_rnnt 74.851807 lr 0.00040644 rank 1
2022-12-03 13:54:39,321 DEBUG TRAIN Batch 1/1800 loss 43.410233 loss_att 105.291862 loss_ctc 48.295769 loss_rnnt 30.382500 lr 0.00040528 rank 7
2022-12-03 13:54:39,320 DEBUG TRAIN Batch 1/1800 loss 55.155743 loss_att 117.832642 loss_ctc 67.076736 loss_rnnt 41.030899 lr 0.00040520 rank 4
2022-12-03 13:55:50,836 DEBUG TRAIN Batch 1/1900 loss 21.700281 loss_att 27.618187 loss_ctc 24.189564 loss_rnnt 20.184795 lr 0.00040948 rank 6
2022-12-03 13:55:50,839 DEBUG TRAIN Batch 1/1900 loss 106.022751 loss_att 175.159546 loss_ctc 132.608673 loss_rnnt 88.650604 lr 0.00040880 rank 0
2022-12-03 13:55:50,842 DEBUG TRAIN Batch 1/1900 loss 78.397865 loss_att 157.216705 loss_ctc 89.599487 loss_rnnt 61.140549 lr 0.00040964 rank 2
2022-12-03 13:55:50,842 DEBUG TRAIN Batch 1/1900 loss 25.671963 loss_att 33.692657 loss_ctc 31.531792 loss_rnnt 23.286514 lr 0.00040940 rank 3
2022-12-03 13:55:50,843 DEBUG TRAIN Batch 1/1900 loss 43.188171 loss_att 76.641655 loss_ctc 49.505199 loss_rnnt 35.655205 lr 0.00041044 rank 1
2022-12-03 13:55:50,847 DEBUG TRAIN Batch 1/1900 loss 46.440208 loss_att 80.020180 loss_ctc 58.108532 loss_rnnt 38.168438 lr 0.00040936 rank 5
2022-12-03 13:55:50,848 DEBUG TRAIN Batch 1/1900 loss 44.922039 loss_att 81.609665 loss_ctc 54.677547 loss_rnnt 36.283779 lr 0.00040928 rank 7
2022-12-03 13:55:50,901 DEBUG TRAIN Batch 1/1900 loss 36.170238 loss_att 56.866299 loss_ctc 39.434280 loss_rnnt 31.595821 lr 0.00040920 rank 4
2022-12-03 13:57:02,675 DEBUG TRAIN Batch 1/2000 loss 73.862946 loss_att 156.690277 loss_ctc 88.158752 loss_rnnt 55.391365 lr 0.00041444 rank 1
2022-12-03 13:57:02,683 DEBUG TRAIN Batch 1/2000 loss 100.530624 loss_att 180.769104 loss_ctc 111.253555 loss_rnnt 83.053207 lr 0.00041320 rank 4
2022-12-03 13:57:02,686 DEBUG TRAIN Batch 1/2000 loss 81.199280 loss_att 137.067642 loss_ctc 89.253174 loss_rnnt 68.951759 lr 0.00041348 rank 6
2022-12-03 13:57:02,689 DEBUG TRAIN Batch 1/2000 loss 79.258072 loss_att 165.477936 loss_ctc 91.598267 loss_rnnt 60.368736 lr 0.00041340 rank 3
2022-12-03 13:57:02,691 DEBUG TRAIN Batch 1/2000 loss 74.654160 loss_att 149.335876 loss_ctc 79.783020 loss_rnnt 59.033962 lr 0.00041280 rank 0
2022-12-03 13:57:02,696 DEBUG TRAIN Batch 1/2000 loss 78.589935 loss_att 148.900162 loss_ctc 91.331451 loss_rnnt 62.829025 lr 0.00041328 rank 7
2022-12-03 13:57:02,697 DEBUG TRAIN Batch 1/2000 loss 47.666885 loss_att 127.049240 loss_ctc 55.199535 loss_rnnt 30.786064 lr 0.00041364 rank 2
2022-12-03 13:57:02,740 DEBUG TRAIN Batch 1/2000 loss 63.924358 loss_att 137.385956 loss_ctc 66.904053 loss_rnnt 48.834743 lr 0.00041336 rank 5
2022-12-03 13:58:16,302 DEBUG TRAIN Batch 1/2100 loss 61.725235 loss_att 140.482849 loss_ctc 66.226440 loss_rnnt 45.373550 lr 0.00041844 rank 1
2022-12-03 13:58:16,304 DEBUG TRAIN Batch 1/2100 loss 75.998650 loss_att 153.145035 loss_ctc 93.420166 loss_rnnt 58.246502 lr 0.00041728 rank 7
2022-12-03 13:58:16,305 DEBUG TRAIN Batch 1/2100 loss 65.497757 loss_att 131.583344 loss_ctc 66.310577 loss_rnnt 52.172264 lr 0.00041740 rank 3
2022-12-03 13:58:16,305 DEBUG TRAIN Batch 1/2100 loss 71.510986 loss_att 130.456390 loss_ctc 85.251770 loss_rnnt 57.889801 lr 0.00041764 rank 2
2022-12-03 13:58:16,307 DEBUG TRAIN Batch 1/2100 loss 50.421753 loss_att 111.976852 loss_ctc 58.339981 loss_rnnt 37.054970 lr 0.00041748 rank 6
2022-12-03 13:58:16,307 DEBUG TRAIN Batch 1/2100 loss 52.602005 loss_att 118.840004 loss_ctc 54.533474 loss_rnnt 39.096870 lr 0.00041736 rank 5
2022-12-03 13:58:16,308 DEBUG TRAIN Batch 1/2100 loss 50.580418 loss_att 112.990692 loss_ctc 54.910778 loss_rnnt 37.520981 lr 0.00041680 rank 0
2022-12-03 13:58:16,310 DEBUG TRAIN Batch 1/2100 loss 58.208092 loss_att 123.812836 loss_ctc 65.090385 loss_rnnt 44.169506 lr 0.00041720 rank 4
2022-12-03 13:59:29,095 DEBUG TRAIN Batch 1/2200 loss 74.090218 loss_att 133.888733 loss_ctc 80.692535 loss_rnnt 61.250206 lr 0.00042136 rank 5
2022-12-03 13:59:29,116 DEBUG TRAIN Batch 1/2200 loss 73.573364 loss_att 142.348984 loss_ctc 84.146622 loss_rnnt 58.408478 lr 0.00042140 rank 3
2022-12-03 13:59:29,116 DEBUG TRAIN Batch 1/2200 loss 69.953369 loss_att 140.454742 loss_ctc 86.697174 loss_rnnt 53.620583 lr 0.00042148 rank 6
2022-12-03 13:59:29,122 DEBUG TRAIN Batch 1/2200 loss 81.874397 loss_att 156.527603 loss_ctc 92.476044 loss_rnnt 65.530205 lr 0.00042080 rank 0
2022-12-03 13:59:29,125 DEBUG TRAIN Batch 1/2200 loss 75.061546 loss_att 130.840332 loss_ctc 89.910263 loss_rnnt 61.925961 lr 0.00042164 rank 2
2022-12-03 13:59:29,126 DEBUG TRAIN Batch 1/2200 loss 55.975906 loss_att 112.034958 loss_ctc 60.852898 loss_rnnt 44.113831 lr 0.00042120 rank 4
2022-12-03 13:59:29,127 DEBUG TRAIN Batch 1/2200 loss 76.299683 loss_att 136.726807 loss_ctc 82.980484 loss_rnnt 63.323479 lr 0.00042244 rank 1
2022-12-03 13:59:29,163 DEBUG TRAIN Batch 1/2200 loss 84.509315 loss_att 135.140442 loss_ctc 102.376633 loss_rnnt 72.000778 lr 0.00042128 rank 7
2022-12-03 14:00:40,762 DEBUG TRAIN Batch 1/2300 loss 74.202019 loss_att 146.678070 loss_ctc 90.091370 loss_rnnt 57.588226 lr 0.00042548 rank 6
2022-12-03 14:00:40,769 DEBUG TRAIN Batch 1/2300 loss 44.835068 loss_att 98.420502 loss_ctc 47.720566 loss_rnnt 33.733246 lr 0.00042480 rank 0
2022-12-03 14:00:40,769 DEBUG TRAIN Batch 1/2300 loss 56.505287 loss_att 110.656128 loss_ctc 67.038177 loss_rnnt 44.270733 lr 0.00042536 rank 5
2022-12-03 14:00:40,771 DEBUG TRAIN Batch 1/2300 loss 55.284470 loss_att 131.191010 loss_ctc 57.850410 loss_rnnt 39.761040 lr 0.00042564 rank 2
2022-12-03 14:00:40,772 DEBUG TRAIN Batch 1/2300 loss 75.213013 loss_att 124.701126 loss_ctc 89.751022 loss_rnnt 63.376984 lr 0.00042540 rank 3
2022-12-03 14:00:40,772 DEBUG TRAIN Batch 1/2300 loss 55.752129 loss_att 108.426498 loss_ctc 62.428436 loss_rnnt 44.327084 lr 0.00042644 rank 1
2022-12-03 14:00:40,773 DEBUG TRAIN Batch 1/2300 loss 93.300613 loss_att 164.218216 loss_ctc 104.479065 loss_rnnt 77.626633 lr 0.00042528 rank 7
2022-12-03 14:00:40,773 DEBUG TRAIN Batch 1/2300 loss 64.609383 loss_att 114.999161 loss_ctc 81.352600 loss_rnnt 52.298996 lr 0.00042520 rank 4
2022-12-03 14:01:53,001 DEBUG TRAIN Batch 1/2400 loss 55.197449 loss_att 104.838287 loss_ctc 68.432114 loss_rnnt 43.504658 lr 0.00042948 rank 6
2022-12-03 14:01:53,006 DEBUG TRAIN Batch 1/2400 loss 52.614742 loss_att 96.854225 loss_ctc 57.552162 loss_rnnt 43.108524 lr 0.00042880 rank 0
2022-12-03 14:01:53,008 DEBUG TRAIN Batch 1/2400 loss 59.087654 loss_att 109.515923 loss_ctc 66.966553 loss_rnnt 47.951477 lr 0.00043044 rank 1
2022-12-03 14:01:53,008 DEBUG TRAIN Batch 1/2400 loss 49.101204 loss_att 87.083954 loss_ctc 58.797352 loss_rnnt 40.211834 lr 0.00042940 rank 3
2022-12-03 14:01:53,014 DEBUG TRAIN Batch 1/2400 loss 52.801395 loss_att 102.463730 loss_ctc 64.237297 loss_rnnt 41.344143 lr 0.00042920 rank 4
2022-12-03 14:01:53,015 DEBUG TRAIN Batch 1/2400 loss 80.299065 loss_att 140.208603 loss_ctc 93.161545 loss_rnnt 66.602158 lr 0.00042964 rank 2
2022-12-03 14:01:53,019 DEBUG TRAIN Batch 1/2400 loss 45.094612 loss_att 94.043526 loss_ctc 57.914825 loss_rnnt 33.595467 lr 0.00042936 rank 5
2022-12-03 14:01:53,033 DEBUG TRAIN Batch 1/2400 loss 61.294979 loss_att 121.090866 loss_ctc 63.587234 loss_rnnt 49.030167 lr 0.00042928 rank 7
2022-12-03 14:03:07,572 DEBUG TRAIN Batch 1/2500 loss 93.313354 loss_att 193.676910 loss_ctc 115.496513 loss_rnnt 70.282890 lr 0.00043280 rank 0
2022-12-03 14:03:07,575 DEBUG TRAIN Batch 1/2500 loss 46.453426 loss_att 92.303543 loss_ctc 49.580463 loss_rnnt 36.866467 lr 0.00043444 rank 1
2022-12-03 14:03:07,577 DEBUG TRAIN Batch 1/2500 loss 35.486160 loss_att 57.744957 loss_ctc 43.830849 loss_rnnt 29.921776 lr 0.00043348 rank 6
2022-12-03 14:03:07,578 DEBUG TRAIN Batch 1/2500 loss 32.170773 loss_att 44.465225 loss_ctc 37.271069 loss_rnnt 29.031845 lr 0.00043340 rank 3
2022-12-03 14:03:07,577 DEBUG TRAIN Batch 1/2500 loss 46.565243 loss_att 77.257637 loss_ctc 58.845360 loss_rnnt 38.789413 lr 0.00043336 rank 5
2022-12-03 14:03:07,579 DEBUG TRAIN Batch 1/2500 loss 53.992325 loss_att 94.897209 loss_ctc 62.794827 loss_rnnt 44.637680 lr 0.00043328 rank 7
2022-12-03 14:03:07,582 DEBUG TRAIN Batch 1/2500 loss 41.342751 loss_att 67.979385 loss_ctc 51.515087 loss_rnnt 34.659111 lr 0.00043364 rank 2
2022-12-03 14:03:07,630 DEBUG TRAIN Batch 1/2500 loss 64.781586 loss_att 105.509216 loss_ctc 83.562157 loss_rnnt 54.131977 lr 0.00043320 rank 4
2022-12-03 14:04:19,513 DEBUG TRAIN Batch 1/2600 loss 34.845192 loss_att 67.727531 loss_ctc 36.603477 loss_rnnt 28.034286 lr 0.00043680 rank 0
2022-12-03 14:04:19,517 DEBUG TRAIN Batch 1/2600 loss 85.286522 loss_att 145.086075 loss_ctc 102.703697 loss_rnnt 71.004318 lr 0.00043748 rank 6
2022-12-03 14:04:19,521 DEBUG TRAIN Batch 1/2600 loss 80.181503 loss_att 149.998276 loss_ctc 106.083855 loss_rnnt 62.764496 lr 0.00043736 rank 5
2022-12-03 14:04:19,521 DEBUG TRAIN Batch 1/2600 loss 20.526970 loss_att 33.121086 loss_ctc 24.713026 loss_rnnt 17.450005 lr 0.00043728 rank 7
2022-12-03 14:04:19,523 DEBUG TRAIN Batch 1/2600 loss 39.889294 loss_att 108.021591 loss_ctc 46.387161 loss_rnnt 25.396452 lr 0.00043844 rank 1
2022-12-03 14:04:19,524 DEBUG TRAIN Batch 1/2600 loss 73.996582 loss_att 138.546249 loss_ctc 82.043755 loss_rnnt 60.013695 lr 0.00043740 rank 3
2022-12-03 14:04:19,525 DEBUG TRAIN Batch 1/2600 loss 76.847298 loss_att 147.490723 loss_ctc 94.299866 loss_rnnt 60.391602 lr 0.00043764 rank 2
2022-12-03 14:04:19,535 DEBUG TRAIN Batch 1/2600 loss 81.935417 loss_att 145.769836 loss_ctc 92.127243 loss_rnnt 67.809624 lr 0.00043720 rank 4
2022-12-03 14:05:31,177 DEBUG TRAIN Batch 1/2700 loss 91.905067 loss_att 145.557434 loss_ctc 102.044983 loss_rnnt 79.822601 lr 0.00044080 rank 0
2022-12-03 14:05:31,183 DEBUG TRAIN Batch 1/2700 loss 55.616718 loss_att 111.461578 loss_ctc 57.038769 loss_rnnt 44.258141 lr 0.00044140 rank 3
2022-12-03 14:05:31,183 DEBUG TRAIN Batch 1/2700 loss 46.950653 loss_att 104.429901 loss_ctc 49.283443 loss_rnnt 35.143761 lr 0.00044148 rank 6
2022-12-03 14:05:31,186 DEBUG TRAIN Batch 1/2700 loss 68.164032 loss_att 116.960693 loss_ctc 79.201538 loss_rnnt 56.933037 lr 0.00044136 rank 5
2022-12-03 14:05:31,186 DEBUG TRAIN Batch 1/2700 loss 49.750641 loss_att 114.393127 loss_ctc 57.767120 loss_rnnt 35.753281 lr 0.00044244 rank 1
2022-12-03 14:05:31,187 DEBUG TRAIN Batch 1/2700 loss 54.910473 loss_att 100.110802 loss_ctc 67.821823 loss_rnnt 44.148895 lr 0.00044164 rank 2
2022-12-03 14:05:31,190 DEBUG TRAIN Batch 1/2700 loss 79.302048 loss_att 133.600311 loss_ctc 99.856186 loss_rnnt 65.701843 lr 0.00044120 rank 4
2022-12-03 14:05:31,196 DEBUG TRAIN Batch 1/2700 loss 57.391823 loss_att 107.820404 loss_ctc 63.191277 loss_rnnt 46.532848 lr 0.00044128 rank 7
2022-12-03 14:06:43,615 DEBUG TRAIN Batch 1/2800 loss 56.124577 loss_att 113.338768 loss_ctc 74.062660 loss_rnnt 42.289993 lr 0.00044536 rank 5
2022-12-03 14:06:43,616 DEBUG TRAIN Batch 1/2800 loss 48.009659 loss_att 101.242218 loss_ctc 61.424858 loss_rnnt 35.574451 lr 0.00044644 rank 1
2022-12-03 14:06:43,621 DEBUG TRAIN Batch 1/2800 loss 44.219715 loss_att 91.178268 loss_ctc 54.262718 loss_rnnt 33.488937 lr 0.00044548 rank 6
2022-12-03 14:06:43,623 DEBUG TRAIN Batch 1/2800 loss 49.911442 loss_att 101.857681 loss_ctc 61.501114 loss_rnnt 37.976906 lr 0.00044480 rank 0
2022-12-03 14:06:43,624 DEBUG TRAIN Batch 1/2800 loss 59.134720 loss_att 122.851486 loss_ctc 84.785942 loss_rnnt 42.971203 lr 0.00044520 rank 4
2022-12-03 14:06:43,626 DEBUG TRAIN Batch 1/2800 loss 40.665516 loss_att 82.308159 loss_ctc 50.968033 loss_rnnt 30.963316 lr 0.00044540 rank 3
2022-12-03 14:06:43,633 DEBUG TRAIN Batch 1/2800 loss 43.434845 loss_att 100.781998 loss_ctc 47.521313 loss_rnnt 31.420547 lr 0.00044528 rank 7
2022-12-03 14:06:43,674 DEBUG TRAIN Batch 1/2800 loss 70.562210 loss_att 122.958664 loss_ctc 88.211182 loss_rnnt 57.729725 lr 0.00044564 rank 2
2022-12-03 14:07:56,481 DEBUG TRAIN Batch 1/2900 loss 88.485222 loss_att 143.588776 loss_ctc 95.153702 loss_rnnt 76.575378 lr 0.00044948 rank 6
2022-12-03 14:07:56,487 DEBUG TRAIN Batch 1/2900 loss 60.125935 loss_att 103.136543 loss_ctc 74.341095 loss_rnnt 49.628460 lr 0.00044964 rank 2
2022-12-03 14:07:56,487 DEBUG TRAIN Batch 1/2900 loss 60.059944 loss_att 120.442276 loss_ctc 65.422195 loss_rnnt 47.268509 lr 0.00044880 rank 0
2022-12-03 14:07:56,489 DEBUG TRAIN Batch 1/2900 loss 57.244392 loss_att 108.950150 loss_ctc 71.728317 loss_rnnt 44.972046 lr 0.00044936 rank 5
2022-12-03 14:07:56,489 DEBUG TRAIN Batch 1/2900 loss 60.071640 loss_att 107.433052 loss_ctc 70.719269 loss_rnnt 49.179672 lr 0.00045044 rank 1
2022-12-03 14:07:56,491 DEBUG TRAIN Batch 1/2900 loss 77.131813 loss_att 137.038223 loss_ctc 92.866837 loss_rnnt 63.052528 lr 0.00044920 rank 4
2022-12-03 14:07:56,493 DEBUG TRAIN Batch 1/2900 loss 67.844894 loss_att 109.937149 loss_ctc 81.405670 loss_rnnt 57.618340 lr 0.00044940 rank 3
2022-12-03 14:07:56,550 DEBUG TRAIN Batch 1/2900 loss 68.002419 loss_att 121.186615 loss_ctc 83.595596 loss_rnnt 55.286491 lr 0.00044928 rank 7
2022-12-03 14:09:07,377 DEBUG TRAIN Batch 1/3000 loss 46.883434 loss_att 81.272934 loss_ctc 57.725796 loss_rnnt 38.559883 lr 0.00045348 rank 6
2022-12-03 14:09:07,392 DEBUG TRAIN Batch 1/3000 loss 74.527367 loss_att 129.061005 loss_ctc 95.664780 loss_rnnt 60.802319 lr 0.00045336 rank 5
2022-12-03 14:09:07,394 DEBUG TRAIN Batch 1/3000 loss 39.158955 loss_att 75.685341 loss_ctc 48.079529 loss_rnnt 30.664268 lr 0.00045340 rank 3
2022-12-03 14:09:07,395 DEBUG TRAIN Batch 1/3000 loss 55.375427 loss_att 102.859268 loss_ctc 71.435196 loss_rnnt 43.737358 lr 0.00045328 rank 7
2022-12-03 14:09:07,396 DEBUG TRAIN Batch 1/3000 loss 48.616669 loss_att 84.007927 loss_ctc 60.531933 loss_rnnt 39.949718 lr 0.00045280 rank 0
2022-12-03 14:09:07,398 DEBUG TRAIN Batch 1/3000 loss 59.830181 loss_att 104.542213 loss_ctc 75.970451 loss_rnnt 48.735741 lr 0.00045444 rank 1
2022-12-03 14:09:07,403 DEBUG TRAIN Batch 1/3000 loss 57.187981 loss_att 103.693680 loss_ctc 70.133919 loss_rnnt 46.160713 lr 0.00045320 rank 4
2022-12-03 14:09:07,437 DEBUG TRAIN Batch 1/3000 loss 33.350441 loss_att 65.778770 loss_ctc 34.131554 loss_rnnt 26.760632 lr 0.00045364 rank 2
2022-12-03 14:10:19,472 DEBUG TRAIN Batch 1/3100 loss 50.282139 loss_att 75.125877 loss_ctc 60.053295 loss_rnnt 44.010567 lr 0.00045764 rank 2
2022-12-03 14:10:19,484 DEBUG TRAIN Batch 1/3100 loss 68.561150 loss_att 97.100044 loss_ctc 81.019745 loss_rnnt 61.192226 lr 0.00045844 rank 1
2022-12-03 14:10:19,492 DEBUG TRAIN Batch 1/3100 loss 45.538006 loss_att 65.907028 loss_ctc 54.527248 loss_rnnt 40.265633 lr 0.00045748 rank 6
2022-12-03 14:10:19,493 DEBUG TRAIN Batch 1/3100 loss 29.147762 loss_att 41.348724 loss_ctc 33.449604 loss_rnnt 26.133989 lr 0.00045680 rank 0
2022-12-03 14:10:19,495 DEBUG TRAIN Batch 1/3100 loss 48.096458 loss_att 71.776321 loss_ctc 58.649033 loss_rnnt 41.953476 lr 0.00045740 rank 3
2022-12-03 14:10:19,498 DEBUG TRAIN Batch 1/3100 loss 63.987953 loss_att 104.643616 loss_ctc 72.371910 loss_rnnt 54.738960 lr 0.00045728 rank 7
2022-12-03 14:10:19,498 DEBUG TRAIN Batch 1/3100 loss 55.796032 loss_att 92.213287 loss_ctc 64.194527 loss_rnnt 47.392784 lr 0.00045736 rank 5
2022-12-03 14:10:19,544 DEBUG TRAIN Batch 1/3100 loss 57.485207 loss_att 93.731674 loss_ctc 72.269562 loss_rnnt 48.264671 lr 0.00045720 rank 4
2022-12-03 14:11:33,967 DEBUG TRAIN Batch 1/3200 loss 45.643959 loss_att 73.949219 loss_ctc 50.874611 loss_rnnt 39.285484 lr 0.00046136 rank 5
2022-12-03 14:11:33,967 DEBUG TRAIN Batch 1/3200 loss 72.736832 loss_att 113.605980 loss_ctc 92.474266 loss_rnnt 61.931343 lr 0.00046164 rank 2
2022-12-03 14:11:33,968 DEBUG TRAIN Batch 1/3200 loss 54.029808 loss_att 104.089127 loss_ctc 68.276459 loss_rnnt 42.118393 lr 0.00046148 rank 6
2022-12-03 14:11:33,974 DEBUG TRAIN Batch 1/3200 loss 40.400364 loss_att 63.004303 loss_ctc 50.374855 loss_rnnt 34.549644 lr 0.00046128 rank 7
2022-12-03 14:11:33,981 DEBUG TRAIN Batch 1/3200 loss 56.524368 loss_att 74.323486 loss_ctc 65.174004 loss_rnnt 51.811256 lr 0.00046120 rank 4
2022-12-03 14:11:33,984 DEBUG TRAIN Batch 1/3200 loss 39.135002 loss_att 65.460587 loss_ctc 46.811733 loss_rnnt 32.846321 lr 0.00046244 rank 1
2022-12-03 14:11:33,999 DEBUG TRAIN Batch 1/3200 loss 76.078773 loss_att 128.504898 loss_ctc 93.449944 loss_rnnt 63.277397 lr 0.00046080 rank 0
2022-12-03 14:11:34,011 DEBUG TRAIN Batch 1/3200 loss 41.997028 loss_att 86.085762 loss_ctc 50.880272 loss_rnnt 31.994846 lr 0.00046140 rank 3
2022-12-03 14:12:46,038 DEBUG TRAIN Batch 1/3300 loss 59.584736 loss_att 102.189072 loss_ctc 70.990196 loss_rnnt 49.543144 lr 0.00046536 rank 5
2022-12-03 14:12:46,044 DEBUG TRAIN Batch 1/3300 loss 50.827541 loss_att 101.438728 loss_ctc 60.914040 loss_rnnt 39.360439 lr 0.00046528 rank 7
2022-12-03 14:12:46,044 DEBUG TRAIN Batch 1/3300 loss 74.124229 loss_att 130.787949 loss_ctc 82.091385 loss_rnnt 61.729198 lr 0.00046548 rank 6
2022-12-03 14:12:46,045 DEBUG TRAIN Batch 1/3300 loss 41.793854 loss_att 79.034897 loss_ctc 50.342186 loss_rnnt 33.205864 lr 0.00046564 rank 2
2022-12-03 14:12:46,047 DEBUG TRAIN Batch 1/3300 loss 62.423737 loss_att 112.817703 loss_ctc 79.829681 loss_rnnt 50.024151 lr 0.00046540 rank 3
2022-12-03 14:12:46,048 DEBUG TRAIN Batch 1/3300 loss 49.609207 loss_att 99.481880 loss_ctc 63.885880 loss_rnnt 37.731113 lr 0.00046644 rank 1
2022-12-03 14:12:46,048 DEBUG TRAIN Batch 1/3300 loss 73.123032 loss_att 112.887634 loss_ctc 91.745590 loss_rnnt 62.687099 lr 0.00046480 rank 0
2022-12-03 14:12:46,053 DEBUG TRAIN Batch 1/3300 loss 76.210159 loss_att 130.439529 loss_ctc 92.855438 loss_rnnt 63.144920 lr 0.00046520 rank 4
2022-12-03 14:13:58,537 DEBUG TRAIN Batch 1/3400 loss 47.034267 loss_att 86.143188 loss_ctc 56.050087 loss_rnnt 38.010376 lr 0.00046928 rank 7
2022-12-03 14:13:58,538 DEBUG TRAIN Batch 1/3400 loss 42.148342 loss_att 76.034477 loss_ctc 57.729057 loss_rnnt 33.293686 lr 0.00046940 rank 3
2022-12-03 14:13:58,539 DEBUG TRAIN Batch 1/3400 loss 70.134537 loss_att 114.075241 loss_ctc 78.385887 loss_rnnt 60.246212 lr 0.00047044 rank 1
2022-12-03 14:13:58,540 DEBUG TRAIN Batch 1/3400 loss 42.212666 loss_att 86.697861 loss_ctc 55.577007 loss_rnnt 31.533710 lr 0.00046948 rank 6
2022-12-03 14:13:58,541 DEBUG TRAIN Batch 1/3400 loss 54.884087 loss_att 98.372726 loss_ctc 65.573761 loss_rnnt 44.761070 lr 0.00046936 rank 5
2022-12-03 14:13:58,541 DEBUG TRAIN Batch 1/3400 loss 39.100452 loss_att 81.730347 loss_ctc 51.044868 loss_rnnt 28.981882 lr 0.00046880 rank 0
2022-12-03 14:13:58,544 DEBUG TRAIN Batch 1/3400 loss 53.084343 loss_att 87.912720 loss_ctc 68.784561 loss_rnnt 44.025303 lr 0.00046964 rank 2
2022-12-03 14:13:58,545 DEBUG TRAIN Batch 1/3400 loss 55.905403 loss_att 100.382980 loss_ctc 73.144249 loss_rnnt 44.711376 lr 0.00046920 rank 4
2022-12-03 14:15:11,554 DEBUG TRAIN Batch 1/3500 loss 40.365643 loss_att 73.247215 loss_ctc 51.664360 loss_rnnt 32.282829 lr 0.00047444 rank 1
2022-12-03 14:15:11,570 DEBUG TRAIN Batch 1/3500 loss 38.983585 loss_att 66.434944 loss_ctc 50.416233 loss_rnnt 31.968958 lr 0.00047280 rank 0
2022-12-03 14:15:11,572 DEBUG TRAIN Batch 1/3500 loss 53.272709 loss_att 94.141434 loss_ctc 69.346634 loss_rnnt 42.955776 lr 0.00047336 rank 5
2022-12-03 14:15:11,573 DEBUG TRAIN Batch 1/3500 loss 67.958733 loss_att 113.774376 loss_ctc 86.825195 loss_rnnt 56.280075 lr 0.00047340 rank 3
2022-12-03 14:15:11,573 DEBUG TRAIN Batch 1/3500 loss 42.930969 loss_att 74.408134 loss_ctc 54.452614 loss_rnnt 35.099316 lr 0.00047328 rank 7
2022-12-03 14:15:11,574 DEBUG TRAIN Batch 1/3500 loss 73.096878 loss_att 116.670380 loss_ctc 94.861420 loss_rnnt 61.480232 lr 0.00047320 rank 4
2022-12-03 14:15:11,575 DEBUG TRAIN Batch 1/3500 loss 60.124203 loss_att 105.274612 loss_ctc 85.106377 loss_rnnt 47.763161 lr 0.00047348 rank 6
2022-12-03 14:15:11,575 DEBUG TRAIN Batch 1/3500 loss 35.145287 loss_att 73.324562 loss_ctc 47.312485 loss_rnnt 25.887136 lr 0.00047364 rank 2
2022-12-03 14:16:25,330 DEBUG TRAIN Batch 1/3600 loss 76.607086 loss_att 112.719040 loss_ctc 100.034973 loss_rnnt 66.260971 lr 0.00047736 rank 5
2022-12-03 14:16:25,330 DEBUG TRAIN Batch 1/3600 loss 53.746239 loss_att 83.481323 loss_ctc 73.621445 loss_rnnt 45.149197 lr 0.00047748 rank 6
2022-12-03 14:16:25,333 DEBUG TRAIN Batch 1/3600 loss 47.806339 loss_att 78.905197 loss_ctc 60.665096 loss_rnnt 39.872066 lr 0.00047680 rank 0
2022-12-03 14:16:25,336 DEBUG TRAIN Batch 1/3600 loss 60.036026 loss_att 89.003311 loss_ctc 73.164795 loss_rnnt 52.492065 lr 0.00047740 rank 3
2022-12-03 14:16:25,339 DEBUG TRAIN Batch 1/3600 loss 37.409241 loss_att 60.988556 loss_ctc 51.294090 loss_rnnt 30.842062 lr 0.00047764 rank 2
2022-12-03 14:16:25,339 DEBUG TRAIN Batch 1/3600 loss 56.578358 loss_att 93.269234 loss_ctc 70.939346 loss_rnnt 47.325382 lr 0.00047844 rank 1
2022-12-03 14:16:25,342 DEBUG TRAIN Batch 1/3600 loss 60.682007 loss_att 99.749207 loss_ctc 68.594574 loss_rnnt 51.813553 lr 0.00047728 rank 7
2022-12-03 14:16:25,342 DEBUG TRAIN Batch 1/3600 loss 61.770927 loss_att 97.007416 loss_ctc 78.428848 loss_rnnt 52.502575 lr 0.00047720 rank 4
2022-12-03 14:17:36,583 DEBUG TRAIN Batch 1/3700 loss 29.222034 loss_att 42.297539 loss_ctc 39.887619 loss_rnnt 25.184855 lr 0.00048148 rank 6
2022-12-03 14:17:36,586 DEBUG TRAIN Batch 1/3700 loss 41.793274 loss_att 78.081726 loss_ctc 59.444260 loss_rnnt 32.182117 lr 0.00048136 rank 5
2022-12-03 14:17:36,587 DEBUG TRAIN Batch 1/3700 loss 50.492916 loss_att 77.225342 loss_ctc 61.407455 loss_rnnt 43.691158 lr 0.00048244 rank 1
2022-12-03 14:17:36,588 DEBUG TRAIN Batch 1/3700 loss 31.533802 loss_att 43.763931 loss_ctc 41.021526 loss_rnnt 27.822746 lr 0.00048080 rank 0
2022-12-03 14:17:36,590 DEBUG TRAIN Batch 1/3700 loss 84.463181 loss_att 121.489487 loss_ctc 94.381958 loss_rnnt 75.735420 lr 0.00048120 rank 4
2022-12-03 14:17:36,592 DEBUG TRAIN Batch 1/3700 loss 35.537891 loss_att 63.659668 loss_ctc 43.766640 loss_rnnt 28.816370 lr 0.00048164 rank 2
2022-12-03 14:17:36,594 DEBUG TRAIN Batch 1/3700 loss 41.309742 loss_att 65.723305 loss_ctc 51.973267 loss_rnnt 35.005226 lr 0.00048140 rank 3
2022-12-03 14:17:36,596 DEBUG TRAIN Batch 1/3700 loss 63.913834 loss_att 95.968262 loss_ctc 83.203560 loss_rnnt 54.930977 lr 0.00048128 rank 7
2022-12-03 14:18:50,203 DEBUG TRAIN Batch 1/3800 loss 87.853027 loss_att 126.737045 loss_ctc 107.474564 loss_rnnt 77.460014 lr 0.00048548 rank 6
2022-12-03 14:18:50,207 DEBUG TRAIN Batch 1/3800 loss 66.195122 loss_att 122.270004 loss_ctc 83.697914 loss_rnnt 52.646435 lr 0.00048480 rank 0
2022-12-03 14:18:50,208 DEBUG TRAIN Batch 1/3800 loss 63.794838 loss_att 91.676476 loss_ctc 86.882538 loss_rnnt 55.140148 lr 0.00048520 rank 4
2022-12-03 14:18:50,208 DEBUG TRAIN Batch 1/3800 loss 74.538971 loss_att 124.287910 loss_ctc 97.431625 loss_rnnt 61.536827 lr 0.00048540 rank 3
2022-12-03 14:18:50,212 DEBUG TRAIN Batch 1/3800 loss 61.566143 loss_att 81.043472 loss_ctc 71.886154 loss_rnnt 56.294678 lr 0.00048536 rank 5
2022-12-03 14:18:50,213 DEBUG TRAIN Batch 1/3800 loss 41.885406 loss_att 71.438736 loss_ctc 56.136616 loss_rnnt 34.074581 lr 0.00048528 rank 7
2022-12-03 14:18:50,216 DEBUG TRAIN Batch 1/3800 loss 19.230354 loss_att 25.944649 loss_ctc 23.748652 loss_rnnt 17.285055 lr 0.00048564 rank 2
2022-12-03 14:18:50,217 DEBUG TRAIN Batch 1/3800 loss 56.344532 loss_att 84.833290 loss_ctc 70.351784 loss_rnnt 48.779144 lr 0.00048644 rank 1
2022-12-03 14:20:05,837 DEBUG TRAIN Batch 1/3900 loss 51.642029 loss_att 99.383278 loss_ctc 59.441986 loss_rnnt 41.053780 lr 0.00048936 rank 5
2022-12-03 14:20:05,842 DEBUG TRAIN Batch 1/3900 loss 51.149796 loss_att 85.984093 loss_ctc 64.670219 loss_rnnt 42.380215 lr 0.00048948 rank 6
2022-12-03 14:20:05,845 DEBUG TRAIN Batch 1/3900 loss 29.977072 loss_att 61.416023 loss_ctc 40.618977 loss_rnnt 22.270361 lr 0.00048880 rank 0
2022-12-03 14:20:05,845 DEBUG TRAIN Batch 1/3900 loss 23.082825 loss_att 30.625351 loss_ctc 27.769466 loss_rnnt 20.949432 lr 0.00048920 rank 4
2022-12-03 14:20:05,846 DEBUG TRAIN Batch 1/3900 loss 38.411827 loss_att 53.718918 loss_ctc 48.075451 loss_rnnt 34.061924 lr 0.00048928 rank 7
2022-12-03 14:20:05,869 DEBUG TRAIN Batch 1/3900 loss 77.473862 loss_att 112.518066 loss_ctc 92.333984 loss_rnnt 68.483673 lr 0.00049044 rank 1
2022-12-03 14:20:05,874 DEBUG TRAIN Batch 1/3900 loss 44.110569 loss_att 82.342377 loss_ctc 54.432980 loss_rnnt 35.087883 lr 0.00048940 rank 3
2022-12-03 14:20:05,887 DEBUG TRAIN Batch 1/3900 loss 40.863220 loss_att 79.765533 loss_ctc 54.574657 loss_rnnt 31.254568 lr 0.00048964 rank 2
2022-12-03 14:21:18,066 DEBUG TRAIN Batch 1/4000 loss 90.089912 loss_att 149.469635 loss_ctc 119.482620 loss_rnnt 74.294937 lr 0.00049328 rank 7
2022-12-03 14:21:18,075 DEBUG TRAIN Batch 1/4000 loss 35.873230 loss_att 60.846344 loss_ctc 45.214527 loss_rnnt 29.633101 lr 0.00049348 rank 6
2022-12-03 14:21:18,077 DEBUG TRAIN Batch 1/4000 loss 46.083069 loss_att 81.809822 loss_ctc 63.979248 loss_rnnt 36.551559 lr 0.00049340 rank 3
2022-12-03 14:21:18,078 DEBUG TRAIN Batch 1/4000 loss 52.544334 loss_att 79.950958 loss_ctc 70.131790 loss_rnnt 44.718014 lr 0.00049280 rank 0
2022-12-03 14:21:18,081 DEBUG TRAIN Batch 1/4000 loss 57.363186 loss_att 93.831482 loss_ctc 73.408226 loss_rnnt 47.930187 lr 0.00049364 rank 2
2022-12-03 14:21:18,086 DEBUG TRAIN Batch 1/4000 loss 66.726311 loss_att 110.343971 loss_ctc 81.736053 loss_rnnt 56.001472 lr 0.00049336 rank 5
2022-12-03 14:21:18,098 DEBUG TRAIN Batch 1/4000 loss 55.323807 loss_att 82.322914 loss_ctc 72.476402 loss_rnnt 47.636971 lr 0.00049444 rank 1
2022-12-03 14:21:18,134 DEBUG TRAIN Batch 1/4000 loss 47.112877 loss_att 70.663055 loss_ctc 61.377834 loss_rnnt 40.500851 lr 0.00049320 rank 4
2022-12-03 14:22:30,510 DEBUG TRAIN Batch 1/4100 loss 43.394394 loss_att 76.457230 loss_ctc 56.419170 loss_rnnt 35.045189 lr 0.00049844 rank 1
2022-12-03 14:22:30,521 DEBUG TRAIN Batch 1/4100 loss 55.410175 loss_att 96.141846 loss_ctc 77.408279 loss_rnnt 44.330757 lr 0.00049748 rank 6
2022-12-03 14:22:30,524 DEBUG TRAIN Batch 1/4100 loss 46.298470 loss_att 80.017555 loss_ctc 61.200912 loss_rnnt 37.567657 lr 0.00049740 rank 3
2022-12-03 14:22:30,527 DEBUG TRAIN Batch 1/4100 loss 69.208725 loss_att 96.768394 loss_ctc 88.142517 loss_rnnt 61.172283 lr 0.00049680 rank 0
2022-12-03 14:22:30,531 DEBUG TRAIN Batch 1/4100 loss 80.792900 loss_att 124.853195 loss_ctc 92.344955 loss_rnnt 70.440559 lr 0.00049720 rank 4
2022-12-03 14:22:30,533 DEBUG TRAIN Batch 1/4100 loss 44.396103 loss_att 72.506844 loss_ctc 52.486206 loss_rnnt 37.695278 lr 0.00049728 rank 7
2022-12-03 14:22:30,533 DEBUG TRAIN Batch 1/4100 loss 33.235893 loss_att 63.807690 loss_ctc 48.040821 loss_rnnt 25.147541 lr 0.00049764 rank 2
2022-12-03 14:22:30,575 DEBUG TRAIN Batch 1/4100 loss 39.141861 loss_att 68.276718 loss_ctc 40.067322 loss_rnnt 33.191494 lr 0.00049736 rank 5
2022-12-03 14:23:42,740 DEBUG TRAIN Batch 1/4200 loss 45.334846 loss_att 76.535172 loss_ctc 61.337662 loss_rnnt 36.961075 lr 0.00050136 rank 5
2022-12-03 14:23:42,749 DEBUG TRAIN Batch 1/4200 loss 46.161819 loss_att 78.339752 loss_ctc 56.139088 loss_rnnt 38.395935 lr 0.00050120 rank 4
2022-12-03 14:23:42,758 DEBUG TRAIN Batch 1/4200 loss 42.805019 loss_att 68.831360 loss_ctc 55.795727 loss_rnnt 35.867657 lr 0.00050148 rank 6
2022-12-03 14:23:42,759 DEBUG TRAIN Batch 1/4200 loss 34.491268 loss_att 58.528027 loss_ctc 43.169849 loss_rnnt 28.526772 lr 0.00050140 rank 3
2022-12-03 14:23:42,760 DEBUG TRAIN Batch 1/4200 loss 36.740490 loss_att 60.476799 loss_ctc 52.613850 loss_rnnt 29.876780 lr 0.00050244 rank 1
2022-12-03 14:23:42,764 DEBUG TRAIN Batch 1/4200 loss 52.612892 loss_att 76.197617 loss_ctc 67.507942 loss_rnnt 45.909943 lr 0.00050080 rank 0
2022-12-03 14:23:42,776 DEBUG TRAIN Batch 1/4200 loss 50.826252 loss_att 78.950928 loss_ctc 64.860374 loss_rnnt 43.330097 lr 0.00050164 rank 2
2022-12-03 14:23:42,778 DEBUG TRAIN Batch 1/4200 loss 72.301430 loss_att 117.446503 loss_ctc 93.615150 loss_rnnt 60.430580 lr 0.00050128 rank 7
2022-12-03 14:24:56,938 DEBUG TRAIN Batch 1/4300 loss 40.709457 loss_att 64.138115 loss_ctc 54.930519 loss_rnnt 34.127583 lr 0.00050548 rank 6
2022-12-03 14:24:56,942 DEBUG TRAIN Batch 1/4300 loss 37.079857 loss_att 56.129349 loss_ctc 45.638802 loss_rnnt 32.128765 lr 0.00050480 rank 0
2022-12-03 14:24:56,942 DEBUG TRAIN Batch 1/4300 loss 63.770134 loss_att 95.791290 loss_ctc 82.186172 loss_rnnt 54.910431 lr 0.00050644 rank 1
2022-12-03 14:24:56,942 DEBUG TRAIN Batch 1/4300 loss 66.547348 loss_att 100.818840 loss_ctc 86.904755 loss_rnnt 56.978729 lr 0.00050540 rank 3
2022-12-03 14:24:56,947 DEBUG TRAIN Batch 1/4300 loss 51.791893 loss_att 90.569336 loss_ctc 65.617432 loss_rnnt 42.193001 lr 0.00050536 rank 5
2022-12-03 14:24:56,950 DEBUG TRAIN Batch 1/4300 loss 46.877289 loss_att 68.267273 loss_ctc 62.986794 loss_rnnt 40.451355 lr 0.00050564 rank 2
2022-12-03 14:24:56,954 DEBUG TRAIN Batch 1/4300 loss 75.050911 loss_att 105.926788 loss_ctc 95.364532 loss_rnnt 66.167252 lr 0.00050528 rank 7
2022-12-03 14:24:56,954 DEBUG TRAIN Batch 1/4300 loss 53.944870 loss_att 93.725067 loss_ctc 78.697144 loss_rnnt 42.688530 lr 0.00050520 rank 4
2022-12-03 14:26:08,826 DEBUG TRAIN Batch 1/4400 loss 55.669899 loss_att 95.765213 loss_ctc 77.639244 loss_rnnt 44.721588 lr 0.00050948 rank 6
2022-12-03 14:26:08,833 DEBUG TRAIN Batch 1/4400 loss 55.099480 loss_att 90.931305 loss_ctc 83.398056 loss_rnnt 44.159969 lr 0.00050880 rank 0
2022-12-03 14:26:08,833 DEBUG TRAIN Batch 1/4400 loss 29.831371 loss_att 45.870411 loss_ctc 42.818249 loss_rnnt 24.891977 lr 0.00050964 rank 2
2022-12-03 14:26:08,836 DEBUG TRAIN Batch 1/4400 loss 51.220360 loss_att 66.752335 loss_ctc 66.819519 loss_rnnt 46.034073 lr 0.00050940 rank 3
2022-12-03 14:26:08,836 DEBUG TRAIN Batch 1/4400 loss 62.718178 loss_att 85.891861 loss_ctc 73.715210 loss_rnnt 56.617172 lr 0.00050936 rank 5
2022-12-03 14:26:08,837 DEBUG TRAIN Batch 1/4400 loss 38.281017 loss_att 73.837036 loss_ctc 59.338875 loss_rnnt 28.362099 lr 0.00050928 rank 7
2022-12-03 14:26:08,837 DEBUG TRAIN Batch 1/4400 loss 62.149010 loss_att 95.037941 loss_ctc 87.599083 loss_rnnt 52.177883 lr 0.00051044 rank 1
2022-12-03 14:26:08,841 DEBUG TRAIN Batch 1/4400 loss 62.800392 loss_att 82.339035 loss_ctc 79.204277 loss_rnnt 56.705475 lr 0.00050920 rank 4
2022-12-03 14:27:20,612 DEBUG TRAIN Batch 1/4500 loss 61.307972 loss_att 98.232986 loss_ctc 76.347702 loss_rnnt 51.917671 lr 0.00051348 rank 6
2022-12-03 14:27:20,613 DEBUG TRAIN Batch 1/4500 loss 61.062935 loss_att 79.584846 loss_ctc 74.250366 loss_rnnt 55.600231 lr 0.00051328 rank 7
2022-12-03 14:27:20,614 DEBUG TRAIN Batch 1/4500 loss 32.733746 loss_att 38.648251 loss_ctc 39.188858 loss_rnnt 30.690161 lr 0.00051336 rank 5
2022-12-03 14:27:20,615 DEBUG TRAIN Batch 1/4500 loss 58.103210 loss_att 88.125732 loss_ctc 75.566429 loss_rnnt 49.770275 lr 0.00051364 rank 2
2022-12-03 14:27:20,617 DEBUG TRAIN Batch 1/4500 loss 40.521381 loss_att 56.541618 loss_ctc 52.521584 loss_rnnt 35.717308 lr 0.00051444 rank 1
2022-12-03 14:27:20,617 DEBUG TRAIN Batch 1/4500 loss 46.846130 loss_att 85.877335 loss_ctc 67.794380 loss_rnnt 36.246792 lr 0.00051340 rank 3
2022-12-03 14:27:20,618 DEBUG TRAIN Batch 1/4500 loss 48.263874 loss_att 76.563843 loss_ctc 66.926918 loss_rnnt 40.115475 lr 0.00051280 rank 0
2022-12-03 14:27:20,620 DEBUG TRAIN Batch 1/4500 loss 25.018597 loss_att 34.240238 loss_ctc 31.731140 loss_rnnt 22.279261 lr 0.00051320 rank 4
2022-12-03 14:28:34,667 DEBUG TRAIN Batch 1/4600 loss 52.939362 loss_att 86.818863 loss_ctc 71.260178 loss_rnnt 43.720680 lr 0.00051680 rank 0
2022-12-03 14:28:34,674 DEBUG TRAIN Batch 1/4600 loss 30.324989 loss_att 56.979668 loss_ctc 34.216553 loss_rnnt 24.475180 lr 0.00051764 rank 2
2022-12-03 14:28:34,676 DEBUG TRAIN Batch 1/4600 loss 61.053215 loss_att 95.331528 loss_ctc 88.315781 loss_rnnt 50.562546 lr 0.00051736 rank 5
2022-12-03 14:28:34,680 DEBUG TRAIN Batch 1/4600 loss 62.264755 loss_att 92.569870 loss_ctc 82.136841 loss_rnnt 53.554115 lr 0.00051748 rank 6
2022-12-03 14:28:34,683 DEBUG TRAIN Batch 1/4600 loss 107.412064 loss_att 165.389404 loss_ctc 144.341110 loss_rnnt 90.892715 lr 0.00051728 rank 7
2022-12-03 14:28:34,685 DEBUG TRAIN Batch 1/4600 loss 57.356750 loss_att 84.310501 loss_ctc 76.083679 loss_rnnt 49.469078 lr 0.00051740 rank 3
2022-12-03 14:28:34,685 DEBUG TRAIN Batch 1/4600 loss 22.423252 loss_att 46.942322 loss_ctc 38.086445 loss_rnnt 15.431014 lr 0.00051720 rank 4
2022-12-03 14:28:34,695 DEBUG TRAIN Batch 1/4600 loss 79.647034 loss_att 116.002884 loss_ctc 101.768356 loss_rnnt 69.426361 lr 0.00051844 rank 1
2022-12-03 14:29:47,678 DEBUG TRAIN Batch 1/4700 loss 57.537941 loss_att 88.450912 loss_ctc 64.683044 loss_rnnt 50.402672 lr 0.00052140 rank 3
2022-12-03 14:29:47,679 DEBUG TRAIN Batch 1/4700 loss 42.239433 loss_att 72.286217 loss_ctc 52.123878 loss_rnnt 34.912148 lr 0.00052080 rank 0
2022-12-03 14:29:47,679 DEBUG TRAIN Batch 1/4700 loss 41.068115 loss_att 74.903694 loss_ctc 50.645191 loss_rnnt 33.024055 lr 0.00052148 rank 6
2022-12-03 14:29:47,680 DEBUG TRAIN Batch 1/4700 loss 72.458389 loss_att 109.023857 loss_ctc 96.561180 loss_rnnt 61.931591 lr 0.00052136 rank 5
2022-12-03 14:29:47,681 DEBUG TRAIN Batch 1/4700 loss 56.494091 loss_att 89.327644 loss_ctc 73.694916 loss_rnnt 47.633938 lr 0.00052244 rank 1
2022-12-03 14:29:47,684 DEBUG TRAIN Batch 1/4700 loss 37.289127 loss_att 61.708469 loss_ctc 45.783260 loss_rnnt 31.272705 lr 0.00052128 rank 7
2022-12-03 14:29:47,684 DEBUG TRAIN Batch 1/4700 loss 48.328419 loss_att 73.393776 loss_ctc 64.097481 loss_rnnt 41.212803 lr 0.00052164 rank 2
2022-12-03 14:29:47,688 DEBUG TRAIN Batch 1/4700 loss 49.480141 loss_att 78.488647 loss_ctc 68.188911 loss_rnnt 41.183941 lr 0.00052120 rank 4
2022-12-03 14:30:59,181 DEBUG TRAIN Batch 1/4800 loss 48.555885 loss_att 72.517921 loss_ctc 60.889843 loss_rnnt 42.118946 lr 0.00052548 rank 6
2022-12-03 14:30:59,193 DEBUG TRAIN Batch 1/4800 loss 36.403503 loss_att 60.589035 loss_ctc 51.876896 loss_rnnt 29.503277 lr 0.00052480 rank 0
2022-12-03 14:30:59,194 DEBUG TRAIN Batch 1/4800 loss 55.895420 loss_att 89.637177 loss_ctc 79.279755 loss_rnnt 46.029160 lr 0.00052540 rank 3
2022-12-03 14:30:59,194 DEBUG TRAIN Batch 1/4800 loss 51.853889 loss_att 81.044838 loss_ctc 68.001480 loss_rnnt 43.862686 lr 0.00052536 rank 5
2022-12-03 14:30:59,195 DEBUG TRAIN Batch 1/4800 loss 66.066612 loss_att 96.829727 loss_ctc 90.452957 loss_rnnt 56.662476 lr 0.00052520 rank 4
2022-12-03 14:30:59,196 DEBUG TRAIN Batch 1/4800 loss 70.903374 loss_att 112.097458 loss_ctc 101.265594 loss_rnnt 58.616264 lr 0.00052644 rank 1
2022-12-03 14:30:59,196 DEBUG TRAIN Batch 1/4800 loss 49.622257 loss_att 79.524895 loss_ctc 66.501671 loss_rnnt 41.391144 lr 0.00052528 rank 7
2022-12-03 14:30:59,199 DEBUG TRAIN Batch 1/4800 loss 44.749603 loss_att 69.660843 loss_ctc 57.006332 loss_rnnt 38.133125 lr 0.00052564 rank 2
2022-12-03 14:32:11,079 DEBUG TRAIN Batch 1/4900 loss 36.244560 loss_att 52.771202 loss_ctc 45.896275 loss_rnnt 31.652336 lr 0.00052964 rank 2
2022-12-03 14:32:11,090 DEBUG TRAIN Batch 1/4900 loss 52.388355 loss_att 74.296112 loss_ctc 67.159798 loss_rnnt 46.037277 lr 0.00052940 rank 3
2022-12-03 14:32:11,093 DEBUG TRAIN Batch 1/4900 loss 44.853401 loss_att 63.834366 loss_ctc 57.051342 loss_rnnt 39.430817 lr 0.00052948 rank 6
2022-12-03 14:32:11,096 DEBUG TRAIN Batch 1/4900 loss 44.725513 loss_att 65.022865 loss_ctc 59.788662 loss_rnnt 38.657623 lr 0.00052880 rank 0
2022-12-03 14:32:11,104 DEBUG TRAIN Batch 1/4900 loss 60.841145 loss_att 86.654121 loss_ctc 75.312820 loss_rnnt 53.748993 lr 0.00053044 rank 1
2022-12-03 14:32:11,118 DEBUG TRAIN Batch 1/4900 loss 46.787914 loss_att 74.817047 loss_ctc 64.637711 loss_rnnt 38.802116 lr 0.00052936 rank 5
2022-12-03 14:32:11,126 DEBUG TRAIN Batch 1/4900 loss 41.227280 loss_att 77.765221 loss_ctc 53.269302 loss_rnnt 32.314087 lr 0.00052928 rank 7
2022-12-03 14:32:11,159 DEBUG TRAIN Batch 1/4900 loss 51.704041 loss_att 80.982880 loss_ctc 70.103607 loss_rnnt 43.394997 lr 0.00052920 rank 4
2022-12-03 14:33:25,247 DEBUG TRAIN Batch 1/5000 loss 31.729622 loss_att 36.546646 loss_ctc 41.503540 loss_rnnt 29.463028 lr 0.00053348 rank 6
2022-12-03 14:33:25,250 DEBUG TRAIN Batch 1/5000 loss 31.081179 loss_att 54.123711 loss_ctc 40.145065 loss_rnnt 25.264153 lr 0.00053444 rank 1
2022-12-03 14:33:25,254 DEBUG TRAIN Batch 1/5000 loss 48.109634 loss_att 61.538681 loss_ctc 61.001934 loss_rnnt 43.704853 lr 0.00053340 rank 3
2022-12-03 14:33:25,254 DEBUG TRAIN Batch 1/5000 loss 49.063885 loss_att 78.464027 loss_ctc 67.029518 loss_rnnt 40.788437 lr 0.00053336 rank 5
2022-12-03 14:33:25,254 DEBUG TRAIN Batch 1/5000 loss 20.603710 loss_att 37.154064 loss_ctc 29.217346 loss_rnnt 16.145153 lr 0.00053280 rank 0
2022-12-03 14:33:25,260 DEBUG TRAIN Batch 1/5000 loss 39.833294 loss_att 60.216805 loss_ctc 51.794998 loss_rnnt 34.161697 lr 0.00053328 rank 7
2022-12-03 14:33:25,261 DEBUG TRAIN Batch 1/5000 loss 40.053699 loss_att 54.250416 loss_ctc 49.621376 loss_rnnt 35.938667 lr 0.00053364 rank 2
2022-12-03 14:33:25,265 DEBUG TRAIN Batch 1/5000 loss 33.235497 loss_att 65.341019 loss_ctc 45.177162 loss_rnnt 25.222174 lr 0.00053320 rank 4
2022-12-03 14:34:37,092 DEBUG TRAIN Batch 1/5100 loss 46.720078 loss_att 66.365097 loss_ctc 61.028767 loss_rnnt 40.883247 lr 0.00053844 rank 1
2022-12-03 14:34:37,092 DEBUG TRAIN Batch 1/5100 loss 49.401222 loss_att 76.845078 loss_ctc 68.469528 loss_rnnt 41.370007 lr 0.00053748 rank 6
2022-12-03 14:34:37,092 DEBUG TRAIN Batch 1/5100 loss 35.560913 loss_att 53.056156 loss_ctc 49.401733 loss_rnnt 30.216421 lr 0.00053736 rank 5
2022-12-03 14:34:37,098 DEBUG TRAIN Batch 1/5100 loss 44.449287 loss_att 77.855560 loss_ctc 55.359692 loss_rnnt 36.313313 lr 0.00053680 rank 0
2022-12-03 14:34:37,098 DEBUG TRAIN Batch 1/5100 loss 48.760429 loss_att 85.529831 loss_ctc 66.585861 loss_rnnt 39.029827 lr 0.00053740 rank 3
2022-12-03 14:34:37,103 DEBUG TRAIN Batch 1/5100 loss 57.650475 loss_att 76.623047 loss_ctc 69.552605 loss_rnnt 52.269009 lr 0.00053720 rank 4
2022-12-03 14:34:37,120 DEBUG TRAIN Batch 1/5100 loss 44.451519 loss_att 76.841827 loss_ctc 65.388916 loss_rnnt 35.181805 lr 0.00053764 rank 2
2022-12-03 14:34:37,126 DEBUG TRAIN Batch 1/5100 loss 41.316708 loss_att 57.425514 loss_ctc 58.110394 loss_rnnt 35.855789 lr 0.00053728 rank 7
2022-12-03 14:35:48,651 DEBUG TRAIN Batch 1/5200 loss 58.926563 loss_att 90.976028 loss_ctc 85.745148 loss_rnnt 48.940857 lr 0.00054148 rank 6
2022-12-03 14:35:48,655 DEBUG TRAIN Batch 1/5200 loss 48.752930 loss_att 83.604111 loss_ctc 71.954170 loss_rnnt 38.689194 lr 0.00054120 rank 4
2022-12-03 14:35:48,658 DEBUG TRAIN Batch 1/5200 loss 57.714386 loss_att 89.470131 loss_ctc 74.718521 loss_rnnt 49.096020 lr 0.00054140 rank 3
2022-12-03 14:35:48,661 DEBUG TRAIN Batch 1/5200 loss 48.786175 loss_att 82.095161 loss_ctc 60.333435 loss_rnnt 40.584743 lr 0.00054080 rank 0
2022-12-03 14:35:48,662 DEBUG TRAIN Batch 1/5200 loss 64.638405 loss_att 98.975052 loss_ctc 87.904541 loss_rnnt 54.668926 lr 0.00054164 rank 2
2022-12-03 14:35:48,666 DEBUG TRAIN Batch 1/5200 loss 32.867115 loss_att 64.901939 loss_ctc 39.126175 loss_rnnt 25.625610 lr 0.00054136 rank 5
2022-12-03 14:35:48,668 DEBUG TRAIN Batch 1/5200 loss 69.220505 loss_att 97.518051 loss_ctc 92.371689 loss_rnnt 60.474167 lr 0.00054244 rank 1
2022-12-03 14:35:48,669 DEBUG TRAIN Batch 1/5200 loss 42.616272 loss_att 78.250961 loss_ctc 58.274742 loss_rnnt 33.401535 lr 0.00054128 rank 7
2022-12-03 14:37:02,178 DEBUG TRAIN Batch 1/5300 loss 52.333714 loss_att 76.535820 loss_ctc 60.965576 loss_rnnt 46.342377 lr 0.00054540 rank 3
2022-12-03 14:37:02,179 DEBUG TRAIN Batch 1/5300 loss 49.376366 loss_att 74.901260 loss_ctc 65.523087 loss_rnnt 42.118496 lr 0.00054564 rank 2
2022-12-03 14:37:02,179 DEBUG TRAIN Batch 1/5300 loss 46.625519 loss_att 77.132729 loss_ctc 64.281021 loss_rnnt 38.170013 lr 0.00054528 rank 7
2022-12-03 14:37:02,180 DEBUG TRAIN Batch 1/5300 loss 48.068935 loss_att 84.538589 loss_ctc 58.784698 loss_rnnt 39.346233 lr 0.00054536 rank 5
2022-12-03 14:37:02,180 DEBUG TRAIN Batch 1/5300 loss 43.483715 loss_att 65.907059 loss_ctc 56.952087 loss_rnnt 37.203262 lr 0.00054548 rank 6
2022-12-03 14:37:02,184 DEBUG TRAIN Batch 1/5300 loss 26.158512 loss_att 53.793938 loss_ctc 35.820747 loss_rnnt 19.343130 lr 0.00054520 rank 4
2022-12-03 14:37:02,184 DEBUG TRAIN Batch 1/5300 loss 60.551022 loss_att 95.488968 loss_ctc 82.617775 loss_rnnt 50.621193 lr 0.00054480 rank 0
2022-12-03 14:37:02,231 DEBUG TRAIN Batch 1/5300 loss 27.977562 loss_att 54.262115 loss_ctc 32.581245 loss_rnnt 22.106825 lr 0.00054644 rank 1
2022-12-03 14:38:14,532 DEBUG TRAIN Batch 1/5400 loss 27.296038 loss_att 53.090866 loss_ctc 38.129181 loss_rnnt 20.692652 lr 0.00054880 rank 0
2022-12-03 14:38:14,533 DEBUG TRAIN Batch 1/5400 loss 67.518707 loss_att 99.492912 loss_ctc 81.673782 loss_rnnt 59.236526 lr 0.00054948 rank 6
2022-12-03 14:38:14,533 DEBUG TRAIN Batch 1/5400 loss 31.541584 loss_att 54.610481 loss_ctc 45.776611 loss_rnnt 25.029800 lr 0.00054936 rank 5
2022-12-03 14:38:14,536 DEBUG TRAIN Batch 1/5400 loss 37.867130 loss_att 54.926224 loss_ctc 51.554230 loss_rnnt 32.630363 lr 0.00055044 rank 1
2022-12-03 14:38:14,541 DEBUG TRAIN Batch 1/5400 loss 53.841446 loss_att 71.869133 loss_ctc 70.974785 loss_rnnt 47.951462 lr 0.00054940 rank 3
2022-12-03 14:38:14,543 DEBUG TRAIN Batch 1/5400 loss 58.009483 loss_att 91.877869 loss_ctc 69.936935 loss_rnnt 49.645477 lr 0.00054928 rank 7
2022-12-03 14:38:14,543 DEBUG TRAIN Batch 1/5400 loss 34.200832 loss_att 68.659195 loss_ctc 39.286324 loss_rnnt 26.631092 lr 0.00054964 rank 2
2022-12-03 14:38:14,546 DEBUG TRAIN Batch 1/5400 loss 64.613464 loss_att 92.879761 loss_ctc 86.149826 loss_rnnt 56.088684 lr 0.00054920 rank 4
2022-12-03 14:39:26,733 DEBUG TRAIN Batch 1/5500 loss 28.446657 loss_att 42.763111 loss_ctc 45.343029 loss_rnnt 23.330517 lr 0.00055348 rank 6
2022-12-03 14:39:26,736 DEBUG TRAIN Batch 1/5500 loss 45.419678 loss_att 58.974026 loss_ctc 58.498653 loss_rnnt 40.964947 lr 0.00055340 rank 3
2022-12-03 14:39:26,737 DEBUG TRAIN Batch 1/5500 loss 43.002708 loss_att 57.684422 loss_ctc 55.948708 loss_rnnt 38.340233 lr 0.00055280 rank 0
2022-12-03 14:39:26,738 DEBUG TRAIN Batch 1/5500 loss 29.263437 loss_att 48.474869 loss_ctc 36.262466 loss_rnnt 24.487946 lr 0.00055336 rank 5
2022-12-03 14:39:26,739 DEBUG TRAIN Batch 1/5500 loss 61.434383 loss_att 90.566017 loss_ctc 89.994904 loss_rnnt 51.799988 lr 0.00055444 rank 1
2022-12-03 14:39:26,746 DEBUG TRAIN Batch 1/5500 loss 56.028194 loss_att 80.886559 loss_ctc 68.975334 loss_rnnt 49.330235 lr 0.00055320 rank 4
2022-12-03 14:39:26,783 DEBUG TRAIN Batch 1/5500 loss 40.555923 loss_att 58.947845 loss_ctc 57.661091 loss_rnnt 34.596848 lr 0.00055364 rank 2
2022-12-03 14:39:26,786 DEBUG TRAIN Batch 1/5500 loss 40.071762 loss_att 60.569237 loss_ctc 52.629608 loss_rnnt 34.297886 lr 0.00055328 rank 7
2022-12-03 14:40:39,302 DEBUG TRAIN Batch 1/5600 loss 34.341946 loss_att 46.131359 loss_ctc 45.269417 loss_rnnt 30.527067 lr 0.00055764 rank 2
2022-12-03 14:40:39,303 DEBUG TRAIN Batch 1/5600 loss 64.402069 loss_att 93.915741 loss_ctc 89.662308 loss_rnnt 55.131298 lr 0.00055736 rank 5
2022-12-03 14:40:39,312 DEBUG TRAIN Batch 1/5600 loss 47.852631 loss_att 60.285595 loss_ctc 63.218349 loss_rnnt 43.317276 lr 0.00055748 rank 6
2022-12-03 14:40:39,316 DEBUG TRAIN Batch 1/5600 loss 41.439926 loss_att 46.042084 loss_ctc 55.010307 loss_rnnt 38.710114 lr 0.00055680 rank 0
2022-12-03 14:40:39,319 DEBUG TRAIN Batch 1/5600 loss 57.008560 loss_att 90.191147 loss_ctc 83.851112 loss_rnnt 46.793034 lr 0.00055844 rank 1
2022-12-03 14:40:39,319 DEBUG TRAIN Batch 1/5600 loss 48.894577 loss_att 67.765617 loss_ctc 66.849602 loss_rnnt 42.726372 lr 0.00055740 rank 3
2022-12-03 14:40:39,325 DEBUG TRAIN Batch 1/5600 loss 48.726742 loss_att 83.401291 loss_ctc 64.470390 loss_rnnt 39.692680 lr 0.00055728 rank 7
2022-12-03 14:40:39,332 DEBUG TRAIN Batch 1/5600 loss 35.177292 loss_att 55.903801 loss_ctc 52.146008 loss_rnnt 28.769495 lr 0.00055720 rank 4
2022-12-03 14:41:53,771 DEBUG TRAIN Batch 1/5700 loss 47.295059 loss_att 71.512627 loss_ctc 56.875748 loss_rnnt 41.174118 lr 0.00056148 rank 6
2022-12-03 14:41:53,773 DEBUG TRAIN Batch 1/5700 loss 38.080753 loss_att 59.322746 loss_ctc 50.326118 loss_rnnt 32.199638 lr 0.00056080 rank 0
2022-12-03 14:41:53,777 DEBUG TRAIN Batch 1/5700 loss 58.290764 loss_att 79.536133 loss_ctc 78.385620 loss_rnnt 51.362373 lr 0.00056136 rank 5
2022-12-03 14:41:53,780 DEBUG TRAIN Batch 1/5700 loss 16.199615 loss_att 18.659859 loss_ctc 21.342806 loss_rnnt 15.021809 lr 0.00056140 rank 3
2022-12-03 14:41:53,779 DEBUG TRAIN Batch 1/5700 loss 49.165390 loss_att 69.127853 loss_ctc 64.995361 loss_rnnt 43.062237 lr 0.00056244 rank 1
2022-12-03 14:41:53,779 DEBUG TRAIN Batch 1/5700 loss 41.172413 loss_att 70.032722 loss_ctc 57.382519 loss_rnnt 33.239002 lr 0.00056164 rank 2
2022-12-03 14:41:53,783 DEBUG TRAIN Batch 1/5700 loss 31.948267 loss_att 51.930855 loss_ctc 41.110687 loss_rnnt 26.730091 lr 0.00056128 rank 7
2022-12-03 14:41:53,791 DEBUG TRAIN Batch 1/5700 loss 45.116688 loss_att 66.283432 loss_ctc 64.058830 loss_rnnt 38.357716 lr 0.00056120 rank 4
2022-12-03 14:43:05,823 DEBUG TRAIN Batch 1/5800 loss 38.723541 loss_att 69.819931 loss_ctc 54.566612 loss_rnnt 30.391851 lr 0.00056548 rank 6
2022-12-03 14:43:05,826 DEBUG TRAIN Batch 1/5800 loss 43.944473 loss_att 60.534492 loss_ctc 60.909332 loss_rnnt 38.364487 lr 0.00056480 rank 0
2022-12-03 14:43:05,827 DEBUG TRAIN Batch 1/5800 loss 26.061378 loss_att 31.295368 loss_ctc 34.786804 loss_rnnt 23.851191 lr 0.00056644 rank 1
2022-12-03 14:43:05,830 DEBUG TRAIN Batch 1/5800 loss 52.951576 loss_att 86.169014 loss_ctc 75.786316 loss_rnnt 43.263454 lr 0.00056528 rank 7
2022-12-03 14:43:05,831 DEBUG TRAIN Batch 1/5800 loss 26.100632 loss_att 38.813278 loss_ctc 35.815437 loss_rnnt 22.262794 lr 0.00056536 rank 5
2022-12-03 14:43:05,833 DEBUG TRAIN Batch 1/5800 loss 29.168545 loss_att 50.699097 loss_ctc 38.759350 loss_rnnt 23.583662 lr 0.00056540 rank 3
2022-12-03 14:43:05,832 DEBUG TRAIN Batch 1/5800 loss 40.992825 loss_att 68.110855 loss_ctc 53.951733 loss_rnnt 33.841362 lr 0.00056564 rank 2
2022-12-03 14:43:05,843 DEBUG TRAIN Batch 1/5800 loss 30.469162 loss_att 38.217846 loss_ctc 44.791649 loss_rnnt 27.009758 lr 0.00056520 rank 4
2022-12-03 14:44:18,066 DEBUG TRAIN Batch 1/5900 loss 50.550266 loss_att 75.936409 loss_ctc 64.540726 loss_rnnt 43.607643 lr 0.00056880 rank 0
2022-12-03 14:44:18,068 DEBUG TRAIN Batch 1/5900 loss 74.045349 loss_att 103.589027 loss_ctc 106.137779 loss_rnnt 63.857628 lr 0.00056948 rank 6
2022-12-03 14:44:18,071 DEBUG TRAIN Batch 1/5900 loss 67.935158 loss_att 100.246170 loss_ctc 87.315475 loss_rnnt 58.888912 lr 0.00057044 rank 1
2022-12-03 14:44:18,072 DEBUG TRAIN Batch 1/5900 loss 60.900772 loss_att 77.156540 loss_ctc 83.044456 loss_rnnt 54.697121 lr 0.00056928 rank 7
2022-12-03 14:44:18,072 DEBUG TRAIN Batch 1/5900 loss 72.264290 loss_att 97.658882 loss_ctc 104.778793 loss_rnnt 62.850109 lr 0.00056940 rank 3
2022-12-03 14:44:18,075 DEBUG TRAIN Batch 1/5900 loss 31.586033 loss_att 58.965294 loss_ctc 45.835419 loss_rnnt 24.210262 lr 0.00056936 rank 5
2022-12-03 14:44:18,076 DEBUG TRAIN Batch 1/5900 loss 44.463409 loss_att 75.675621 loss_ctc 66.282104 loss_rnnt 35.311806 lr 0.00056964 rank 2
2022-12-03 14:44:18,081 DEBUG TRAIN Batch 1/5900 loss 58.812462 loss_att 95.765236 loss_ctc 73.751495 loss_rnnt 49.430038 lr 0.00056920 rank 4
2022-12-03 14:45:31,337 DEBUG TRAIN Batch 1/6000 loss 87.805237 loss_att 126.977768 loss_ctc 119.926559 loss_rnnt 75.687897 lr 0.00057340 rank 3
2022-12-03 14:45:31,350 DEBUG TRAIN Batch 1/6000 loss 72.462311 loss_att 97.571335 loss_ctc 99.817398 loss_rnnt 63.793163 lr 0.00057280 rank 0
2022-12-03 14:45:31,352 DEBUG TRAIN Batch 1/6000 loss 50.154991 loss_att 75.518936 loss_ctc 71.695221 loss_rnnt 42.210171 lr 0.00057444 rank 1
2022-12-03 14:45:31,353 DEBUG TRAIN Batch 1/6000 loss 91.605179 loss_att 116.304092 loss_ctc 119.973114 loss_rnnt 82.883011 lr 0.00057348 rank 6
2022-12-03 14:45:31,355 DEBUG TRAIN Batch 1/6000 loss 42.065201 loss_att 64.798630 loss_ctc 57.176781 loss_rnnt 35.503639 lr 0.00057336 rank 5
2022-12-03 14:45:31,356 DEBUG TRAIN Batch 1/6000 loss 36.696220 loss_att 58.682068 loss_ctc 53.146202 loss_rnnt 30.105719 lr 0.00057320 rank 4
2022-12-03 14:45:31,362 DEBUG TRAIN Batch 1/6000 loss 46.877922 loss_att 72.090721 loss_ctc 62.049767 loss_rnnt 39.812447 lr 0.00057328 rank 7
2022-12-03 14:45:31,364 DEBUG TRAIN Batch 1/6000 loss 56.091492 loss_att 81.045998 loss_ctc 78.713287 loss_rnnt 48.084347 lr 0.00057364 rank 2
2022-12-03 14:46:44,834 DEBUG TRAIN Batch 1/6100 loss 56.937729 loss_att 95.652832 loss_ctc 84.261688 loss_rnnt 45.551514 lr 0.00057680 rank 0
2022-12-03 14:46:44,837 DEBUG TRAIN Batch 1/6100 loss 50.755447 loss_att 63.902843 loss_ctc 64.158096 loss_rnnt 46.338947 lr 0.00057740 rank 3
2022-12-03 14:46:44,837 DEBUG TRAIN Batch 1/6100 loss 42.973190 loss_att 62.749588 loss_ctc 59.632645 loss_rnnt 36.796650 lr 0.00057844 rank 1
2022-12-03 14:46:44,837 DEBUG TRAIN Batch 1/6100 loss 55.003105 loss_att 73.494049 loss_ctc 73.636589 loss_rnnt 48.820450 lr 0.00057764 rank 2
2022-12-03 14:46:44,839 DEBUG TRAIN Batch 1/6100 loss 47.568237 loss_att 67.199966 loss_ctc 62.638363 loss_rnnt 41.632542 lr 0.00057748 rank 6
2022-12-03 14:46:44,844 DEBUG TRAIN Batch 1/6100 loss 60.376465 loss_att 87.434364 loss_ctc 90.249741 loss_rnnt 50.981781 lr 0.00057728 rank 7
2022-12-03 14:46:44,845 DEBUG TRAIN Batch 1/6100 loss 55.545639 loss_att 75.701202 loss_ctc 77.701675 loss_rnnt 48.560387 lr 0.00057720 rank 4
2022-12-03 14:46:44,890 DEBUG TRAIN Batch 1/6100 loss 27.558729 loss_att 45.634399 loss_ctc 40.194221 loss_rnnt 22.258863 lr 0.00057736 rank 5
2022-12-03 14:47:56,092 DEBUG TRAIN Batch 1/6200 loss 45.318283 loss_att 68.343697 loss_ctc 69.155937 loss_rnnt 37.534847 lr 0.00058244 rank 1
2022-12-03 14:47:56,093 DEBUG TRAIN Batch 1/6200 loss 46.899063 loss_att 69.257507 loss_ctc 67.394211 loss_rnnt 39.694687 lr 0.00058148 rank 6
2022-12-03 14:47:56,093 DEBUG TRAIN Batch 1/6200 loss 74.308914 loss_att 93.121231 loss_ctc 92.385986 loss_rnnt 68.136169 lr 0.00058136 rank 5
2022-12-03 14:47:56,095 DEBUG TRAIN Batch 1/6200 loss 29.502659 loss_att 46.146107 loss_ctc 43.576038 loss_rnnt 24.297516 lr 0.00058080 rank 0
2022-12-03 14:47:56,097 DEBUG TRAIN Batch 1/6200 loss 43.899063 loss_att 72.063850 loss_ctc 58.988945 loss_rnnt 36.254120 lr 0.00058128 rank 7
2022-12-03 14:47:56,098 DEBUG TRAIN Batch 1/6200 loss 26.411467 loss_att 41.434189 loss_ctc 40.446609 loss_rnnt 21.535570 lr 0.00058140 rank 3
2022-12-03 14:47:56,099 DEBUG TRAIN Batch 1/6200 loss 62.671566 loss_att 80.514580 loss_ctc 75.337929 loss_rnnt 57.414112 lr 0.00058164 rank 2
2022-12-03 14:47:56,152 DEBUG TRAIN Batch 1/6200 loss 35.457939 loss_att 56.756905 loss_ctc 51.430809 loss_rnnt 29.068428 lr 0.00058120 rank 4
2022-12-03 14:49:07,937 DEBUG TRAIN Batch 1/6300 loss 18.209341 loss_att 23.346910 loss_ctc 24.023388 loss_rnnt 16.406622 lr 0.00058540 rank 3
2022-12-03 14:49:07,938 DEBUG TRAIN Batch 1/6300 loss 39.793144 loss_att 60.785488 loss_ctc 51.583622 loss_rnnt 34.022610 lr 0.00058644 rank 1
2022-12-03 14:49:07,940 DEBUG TRAIN Batch 1/6300 loss 19.089069 loss_att 20.708836 loss_ctc 25.014530 loss_rnnt 17.975054 lr 0.00058548 rank 6
2022-12-03 14:49:07,942 DEBUG TRAIN Batch 1/6300 loss 14.687786 loss_att 16.582588 loss_ctc 17.869276 loss_rnnt 13.884627 lr 0.00058480 rank 0
2022-12-03 14:49:07,949 DEBUG TRAIN Batch 1/6300 loss 39.608212 loss_att 53.756741 loss_ctc 50.470669 loss_rnnt 35.330177 lr 0.00058520 rank 4
2022-12-03 14:49:07,950 DEBUG TRAIN Batch 1/6300 loss 28.261013 loss_att 40.430634 loss_ctc 37.359917 loss_rnnt 24.613901 lr 0.00058528 rank 7
2022-12-03 14:49:07,967 DEBUG TRAIN Batch 1/6300 loss 53.011478 loss_att 77.785217 loss_ctc 72.886292 loss_rnnt 45.406761 lr 0.00058536 rank 5
2022-12-03 14:49:07,971 DEBUG TRAIN Batch 1/6300 loss 29.440210 loss_att 35.720203 loss_ctc 40.101650 loss_rnnt 26.762684 lr 0.00058564 rank 2
2022-12-03 14:50:22,581 DEBUG TRAIN Batch 1/6400 loss 52.843204 loss_att 76.046616 loss_ctc 68.761459 loss_rnnt 46.080086 lr 0.00058948 rank 6
2022-12-03 14:50:22,586 DEBUG TRAIN Batch 1/6400 loss 36.242790 loss_att 47.946236 loss_ctc 46.910351 loss_rnnt 32.479755 lr 0.00059044 rank 1
2022-12-03 14:50:22,588 DEBUG TRAIN Batch 1/6400 loss 41.123901 loss_att 77.226692 loss_ctc 57.520927 loss_rnnt 31.717072 lr 0.00058880 rank 0
2022-12-03 14:50:22,589 DEBUG TRAIN Batch 1/6400 loss 33.121819 loss_att 39.067066 loss_ctc 42.043827 loss_rnnt 30.743164 lr 0.00058936 rank 5
2022-12-03 14:50:22,589 DEBUG TRAIN Batch 1/6400 loss 56.726112 loss_att 76.819931 loss_ctc 67.893417 loss_rnnt 51.218376 lr 0.00058964 rank 2
2022-12-03 14:50:22,595 DEBUG TRAIN Batch 1/6400 loss 18.001940 loss_att 23.550058 loss_ctc 24.415739 loss_rnnt 16.037142 lr 0.00058920 rank 4
2022-12-03 14:50:22,596 DEBUG TRAIN Batch 1/6400 loss 22.989872 loss_att 28.918629 loss_ctc 28.188574 loss_rnnt 21.110958 lr 0.00058928 rank 7
2022-12-03 14:50:22,600 DEBUG TRAIN Batch 1/6400 loss 87.622841 loss_att 119.346802 loss_ctc 113.773865 loss_rnnt 77.791245 lr 0.00058940 rank 3
2022-12-03 14:51:34,628 DEBUG TRAIN Batch 1/6500 loss 33.904160 loss_att 55.274857 loss_ctc 49.890896 loss_rnnt 27.498455 lr 0.00059348 rank 6
2022-12-03 14:51:34,629 DEBUG TRAIN Batch 1/6500 loss 31.535822 loss_att 54.552128 loss_ctc 45.685131 loss_rnnt 25.045986 lr 0.00059340 rank 3
2022-12-03 14:51:34,633 DEBUG TRAIN Batch 1/6500 loss 38.353882 loss_att 56.990211 loss_ctc 50.390835 loss_rnnt 33.021690 lr 0.00059336 rank 5
2022-12-03 14:51:34,634 DEBUG TRAIN Batch 1/6500 loss 56.860882 loss_att 80.580345 loss_ctc 86.450394 loss_rnnt 48.171722 lr 0.00059280 rank 0
2022-12-03 14:51:34,637 DEBUG TRAIN Batch 1/6500 loss 65.973434 loss_att 89.956337 loss_ctc 93.947784 loss_rnnt 57.446941 lr 0.00059364 rank 2
2022-12-03 14:51:34,638 DEBUG TRAIN Batch 1/6500 loss 55.911087 loss_att 84.599915 loss_ctc 74.837563 loss_rnnt 47.649792 lr 0.00059328 rank 7
2022-12-03 14:51:34,644 DEBUG TRAIN Batch 1/6500 loss 45.134285 loss_att 63.277218 loss_ctc 50.899132 loss_rnnt 40.737057 lr 0.00059320 rank 4
2022-12-03 14:51:34,685 DEBUG TRAIN Batch 1/6500 loss 53.735924 loss_att 86.537270 loss_ctc 71.645874 loss_rnnt 44.787659 lr 0.00059444 rank 1
2022-12-03 14:52:46,689 DEBUG TRAIN Batch 1/6600 loss 48.414173 loss_att 76.288193 loss_ctc 72.333847 loss_rnnt 39.650078 lr 0.00059740 rank 3
2022-12-03 14:52:46,702 DEBUG TRAIN Batch 1/6600 loss 41.927097 loss_att 64.816055 loss_ctc 58.274597 loss_rnnt 35.169640 lr 0.00059680 rank 0
2022-12-03 14:52:46,703 DEBUG TRAIN Batch 1/6600 loss 48.246964 loss_att 69.151932 loss_ctc 67.942245 loss_rnnt 41.439930 lr 0.00059764 rank 2
2022-12-03 14:52:46,703 DEBUG TRAIN Batch 1/6600 loss 54.578072 loss_att 80.512932 loss_ctc 65.997162 loss_rnnt 47.868553 lr 0.00059736 rank 5
2022-12-03 14:52:46,705 DEBUG TRAIN Batch 1/6600 loss 27.763531 loss_att 46.628807 loss_ctc 39.919704 loss_rnnt 22.369652 lr 0.00059728 rank 7
2022-12-03 14:52:46,706 DEBUG TRAIN Batch 1/6600 loss 40.324894 loss_att 64.364166 loss_ctc 57.247360 loss_rnnt 33.260712 lr 0.00059720 rank 4
2022-12-03 14:52:46,712 DEBUG TRAIN Batch 1/6600 loss 43.364395 loss_att 68.063835 loss_ctc 64.248444 loss_rnnt 35.639969 lr 0.00059748 rank 6
2022-12-03 14:52:46,750 DEBUG TRAIN Batch 1/6600 loss 35.623951 loss_att 56.762634 loss_ctc 50.230713 loss_rnnt 29.448643 lr 0.00059844 rank 1
2022-12-03 14:53:59,975 DEBUG TRAIN Batch 1/6700 loss 36.381966 loss_att 56.086403 loss_ctc 50.059517 loss_rnnt 30.617403 lr 0.00060136 rank 5
2022-12-03 14:53:59,983 DEBUG TRAIN Batch 1/6700 loss 53.616196 loss_att 77.528557 loss_ctc 69.256577 loss_rnnt 46.748337 lr 0.00060140 rank 3
2022-12-03 14:53:59,987 DEBUG TRAIN Batch 1/6700 loss 36.019878 loss_att 49.937355 loss_ctc 48.196335 loss_rnnt 31.612854 lr 0.00060164 rank 2
2022-12-03 14:53:59,987 DEBUG TRAIN Batch 1/6700 loss 48.250839 loss_att 58.992802 loss_ctc 66.481079 loss_rnnt 43.671749 lr 0.00060080 rank 0
2022-12-03 14:53:59,988 DEBUG TRAIN Batch 1/6700 loss 44.652023 loss_att 65.778244 loss_ctc 66.601624 loss_rnnt 37.500164 lr 0.00060148 rank 6
2022-12-03 14:53:59,996 DEBUG TRAIN Batch 1/6700 loss 34.120880 loss_att 47.450691 loss_ctc 43.935654 loss_rnnt 30.146278 lr 0.00060128 rank 7
2022-12-03 14:53:59,998 DEBUG TRAIN Batch 1/6700 loss 73.322289 loss_att 93.961288 loss_ctc 99.457962 loss_rnnt 65.709724 lr 0.00060120 rank 4
2022-12-03 14:54:00,039 DEBUG TRAIN Batch 1/6700 loss 32.956341 loss_att 55.043854 loss_ctc 47.489719 loss_rnnt 26.601053 lr 0.00060244 rank 1
2022-12-03 14:55:12,877 DEBUG TRAIN Batch 1/6800 loss 33.257133 loss_att 47.709507 loss_ctc 41.985672 loss_rnnt 29.202854 lr 0.00060536 rank 5
2022-12-03 14:55:12,878 DEBUG TRAIN Batch 1/6800 loss 31.729939 loss_att 45.763325 loss_ctc 44.329895 loss_rnnt 27.243267 lr 0.00060548 rank 6
2022-12-03 14:55:12,879 DEBUG TRAIN Batch 1/6800 loss 51.715855 loss_att 83.920609 loss_ctc 59.202194 loss_rnnt 44.276726 lr 0.00060540 rank 3
2022-12-03 14:55:12,881 DEBUG TRAIN Batch 1/6800 loss 43.846661 loss_att 56.856071 loss_ctc 58.294960 loss_rnnt 39.318340 lr 0.00060480 rank 0
2022-12-03 14:55:12,883 DEBUG TRAIN Batch 1/6800 loss 39.854492 loss_att 56.242165 loss_ctc 51.646912 loss_rnnt 35.004631 lr 0.00060528 rank 7
2022-12-03 14:55:12,884 DEBUG TRAIN Batch 1/6800 loss 41.424812 loss_att 61.521187 loss_ctc 60.998981 loss_rnnt 34.795647 lr 0.00060644 rank 1
2022-12-03 14:55:12,885 DEBUG TRAIN Batch 1/6800 loss 25.613930 loss_att 43.504246 loss_ctc 37.458023 loss_rnnt 20.456656 lr 0.00060564 rank 2
2022-12-03 14:55:12,891 DEBUG TRAIN Batch 1/6800 loss 33.774940 loss_att 51.002411 loss_ctc 46.652359 loss_rnnt 28.612457 lr 0.00060520 rank 4
2022-12-03 14:56:24,723 DEBUG TRAIN Batch 1/6900 loss 45.445576 loss_att 53.808666 loss_ctc 59.616547 loss_rnnt 41.883492 lr 0.00060948 rank 6
2022-12-03 14:56:24,729 DEBUG TRAIN Batch 1/6900 loss 60.159580 loss_att 73.056770 loss_ctc 83.228912 loss_rnnt 54.504234 lr 0.00060936 rank 5
2022-12-03 14:56:24,730 DEBUG TRAIN Batch 1/6900 loss 32.130745 loss_att 38.233696 loss_ctc 42.587822 loss_rnnt 29.515879 lr 0.00060940 rank 3
2022-12-03 14:56:24,731 DEBUG TRAIN Batch 1/6900 loss 34.944763 loss_att 42.931953 loss_ctc 45.942047 loss_rnnt 31.881023 lr 0.00060880 rank 0
2022-12-03 14:56:24,732 DEBUG TRAIN Batch 1/6900 loss 37.083633 loss_att 53.805305 loss_ctc 49.332005 loss_rnnt 32.106182 lr 0.00060964 rank 2
2022-12-03 14:56:24,736 DEBUG TRAIN Batch 1/6900 loss 30.929392 loss_att 45.067425 loss_ctc 43.689812 loss_rnnt 26.400394 lr 0.00060920 rank 4
2022-12-03 14:56:24,736 DEBUG TRAIN Batch 1/6900 loss 39.563648 loss_att 60.940224 loss_ctc 54.616829 loss_rnnt 33.281242 lr 0.00061044 rank 1
2022-12-03 14:56:24,788 DEBUG TRAIN Batch 1/6900 loss 41.441765 loss_att 60.441010 loss_ctc 58.311058 loss_rnnt 35.392677 lr 0.00060928 rank 7
2022-12-03 14:57:36,410 DEBUG TRAIN Batch 1/7000 loss 63.707848 loss_att 95.213684 loss_ctc 86.553284 loss_rnnt 54.360622 lr 0.00061348 rank 6
2022-12-03 14:57:36,411 DEBUG TRAIN Batch 1/7000 loss 37.487923 loss_att 63.259804 loss_ctc 50.766659 loss_rnnt 30.563049 lr 0.00061280 rank 0
2022-12-03 14:57:36,413 DEBUG TRAIN Batch 1/7000 loss 38.213917 loss_att 48.317810 loss_ctc 48.792320 loss_rnnt 34.782684 lr 0.00061336 rank 5
2022-12-03 14:57:36,416 DEBUG TRAIN Batch 1/7000 loss 32.182808 loss_att 40.913418 loss_ctc 43.081963 loss_rnnt 28.983465 lr 0.00061444 rank 1
2022-12-03 14:57:36,416 DEBUG TRAIN Batch 1/7000 loss 61.902187 loss_att 98.739441 loss_ctc 86.168732 loss_rnnt 51.299194 lr 0.00061364 rank 2
2022-12-03 14:57:36,419 DEBUG TRAIN Batch 1/7000 loss 33.412067 loss_att 51.683136 loss_ctc 46.533855 loss_rnnt 28.008284 lr 0.00061340 rank 3
2022-12-03 14:57:36,423 DEBUG TRAIN Batch 1/7000 loss 30.568302 loss_att 42.366150 loss_ctc 41.406139 loss_rnnt 26.763687 lr 0.00061320 rank 4
2022-12-03 14:57:36,428 DEBUG TRAIN Batch 1/7000 loss 52.236046 loss_att 69.984970 loss_ctc 72.217621 loss_rnnt 46.022049 lr 0.00061328 rank 7
2022-12-03 14:58:49,902 DEBUG TRAIN Batch 1/7100 loss 42.493782 loss_att 76.464691 loss_ctc 54.158318 loss_rnnt 34.144325 lr 0.00061680 rank 0
2022-12-03 14:58:49,918 DEBUG TRAIN Batch 1/7100 loss 37.913857 loss_att 57.323883 loss_ctc 54.656261 loss_rnnt 31.799528 lr 0.00061740 rank 3
2022-12-03 14:58:49,919 DEBUG TRAIN Batch 1/7100 loss 37.184433 loss_att 64.508492 loss_ctc 51.862453 loss_rnnt 29.762550 lr 0.00061748 rank 6
2022-12-03 14:58:49,918 DEBUG TRAIN Batch 1/7100 loss 57.297344 loss_att 76.596237 loss_ctc 65.162262 loss_rnnt 52.388908 lr 0.00061844 rank 1
2022-12-03 14:58:49,930 DEBUG TRAIN Batch 1/7100 loss 41.153053 loss_att 55.499275 loss_ctc 56.043819 loss_rnnt 36.298370 lr 0.00061764 rank 2
2022-12-03 14:58:49,936 DEBUG TRAIN Batch 1/7100 loss 58.512512 loss_att 84.000603 loss_ctc 81.586899 loss_rnnt 50.338310 lr 0.00061720 rank 4
2022-12-03 14:58:49,949 DEBUG TRAIN Batch 1/7100 loss 53.506153 loss_att 80.417885 loss_ctc 62.500790 loss_rnnt 46.924522 lr 0.00061736 rank 5
2022-12-03 14:58:49,959 DEBUG TRAIN Batch 1/7100 loss 17.796659 loss_att 19.948645 loss_ctc 21.567663 loss_rnnt 16.863462 lr 0.00061728 rank 7
2022-12-03 15:00:02,152 DEBUG TRAIN Batch 1/7200 loss 55.608849 loss_att 73.350914 loss_ctc 80.404999 loss_rnnt 48.754280 lr 0.00062080 rank 0
2022-12-03 15:00:02,153 DEBUG TRAIN Batch 1/7200 loss 57.472244 loss_att 79.995865 loss_ctc 81.053589 loss_rnnt 49.823341 lr 0.00062128 rank 7
2022-12-03 15:00:02,154 DEBUG TRAIN Batch 1/7200 loss 51.538605 loss_att 69.512596 loss_ctc 74.616096 loss_rnnt 44.866814 lr 0.00062148 rank 6
2022-12-03 15:00:02,155 DEBUG TRAIN Batch 1/7200 loss 35.926094 loss_att 59.918251 loss_ctc 55.444328 loss_rnnt 28.525234 lr 0.00062136 rank 5
2022-12-03 15:00:02,156 DEBUG TRAIN Batch 1/7200 loss 61.754902 loss_att 90.959740 loss_ctc 98.135208 loss_rnnt 51.063225 lr 0.00062140 rank 3
2022-12-03 15:00:02,157 DEBUG TRAIN Batch 1/7200 loss 53.069725 loss_att 77.264206 loss_ctc 77.762268 loss_rnnt 44.938492 lr 0.00062164 rank 2
2022-12-03 15:00:02,160 DEBUG TRAIN Batch 1/7200 loss 49.288567 loss_att 72.855057 loss_ctc 69.339035 loss_rnnt 41.901875 lr 0.00062244 rank 1
2022-12-03 15:00:02,214 DEBUG TRAIN Batch 1/7200 loss 40.141247 loss_att 64.620438 loss_ctc 52.906731 loss_rnnt 33.543346 lr 0.00062120 rank 4
2022-12-03 15:01:13,265 DEBUG TRAIN Batch 1/7300 loss 56.658394 loss_att 73.912491 loss_ctc 80.730301 loss_rnnt 49.997982 lr 0.00062536 rank 5
2022-12-03 15:01:13,268 DEBUG TRAIN Batch 1/7300 loss 51.303711 loss_att 71.665024 loss_ctc 75.051521 loss_rnnt 44.065071 lr 0.00062520 rank 4
2022-12-03 15:01:13,277 DEBUG TRAIN Batch 1/7300 loss 36.816788 loss_att 59.008080 loss_ctc 51.968189 loss_rnnt 30.358339 lr 0.00062548 rank 6
2022-12-03 15:01:13,283 DEBUG TRAIN Batch 1/7300 loss 58.570259 loss_att 73.706383 loss_ctc 77.832870 loss_rnnt 52.974686 lr 0.00062540 rank 3
2022-12-03 15:01:13,285 DEBUG TRAIN Batch 1/7300 loss 39.875221 loss_att 56.472366 loss_ctc 60.243942 loss_rnnt 33.839958 lr 0.00062644 rank 1
2022-12-03 15:01:13,287 DEBUG TRAIN Batch 1/7300 loss 35.421860 loss_att 59.270153 loss_ctc 41.204506 loss_rnnt 29.881180 lr 0.00062480 rank 0
2022-12-03 15:01:13,298 DEBUG TRAIN Batch 1/7300 loss 43.478680 loss_att 63.334015 loss_ctc 57.154640 loss_rnnt 37.684151 lr 0.00062564 rank 2
2022-12-03 15:01:13,336 DEBUG TRAIN Batch 1/7300 loss 32.241360 loss_att 54.091583 loss_ctc 48.725262 loss_rnnt 25.673462 lr 0.00062528 rank 7
2022-12-03 15:02:25,005 DEBUG TRAIN Batch 1/7400 loss 37.068962 loss_att 53.133373 loss_ctc 49.704052 loss_rnnt 32.171402 lr 0.00062936 rank 5
2022-12-03 15:02:25,010 DEBUG TRAIN Batch 1/7400 loss 36.449402 loss_att 56.105148 loss_ctc 55.413513 loss_rnnt 29.989706 lr 0.00062928 rank 7
2022-12-03 15:02:25,010 DEBUG TRAIN Batch 1/7400 loss 46.411758 loss_att 58.190922 loss_ctc 64.407288 loss_rnnt 41.656525 lr 0.00062948 rank 6
2022-12-03 15:02:25,010 DEBUG TRAIN Batch 1/7400 loss 30.083908 loss_att 41.118542 loss_ctc 50.942429 loss_rnnt 25.095844 lr 0.00062940 rank 3
2022-12-03 15:02:25,010 DEBUG TRAIN Batch 1/7400 loss 61.473972 loss_att 78.953979 loss_ctc 80.665817 loss_rnnt 55.419056 lr 0.00062880 rank 0
2022-12-03 15:02:25,013 DEBUG TRAIN Batch 1/7400 loss 35.927235 loss_att 55.440186 loss_ctc 50.233879 loss_rnnt 30.117092 lr 0.00062964 rank 2
2022-12-03 15:02:25,013 DEBUG TRAIN Batch 1/7400 loss 50.063370 loss_att 66.940460 loss_ctc 71.093155 loss_rnnt 43.883980 lr 0.00063044 rank 1
2022-12-03 15:02:25,061 DEBUG TRAIN Batch 1/7400 loss 34.007191 loss_att 51.412918 loss_ctc 50.910446 loss_rnnt 28.272276 lr 0.00062920 rank 4
2022-12-03 15:03:39,276 DEBUG TRAIN Batch 1/7500 loss 37.608952 loss_att 41.728062 loss_ctc 49.898399 loss_rnnt 35.146538 lr 0.00063280 rank 0
2022-12-03 15:03:39,276 DEBUG TRAIN Batch 1/7500 loss 34.494087 loss_att 50.356277 loss_ctc 46.608788 loss_rnnt 29.706356 lr 0.00063336 rank 5
2022-12-03 15:03:39,280 DEBUG TRAIN Batch 1/7500 loss 38.099693 loss_att 52.920898 loss_ctc 55.629078 loss_rnnt 32.798203 lr 0.00063348 rank 6
2022-12-03 15:03:39,281 DEBUG TRAIN Batch 1/7500 loss 53.045425 loss_att 73.440460 loss_ctc 72.126419 loss_rnnt 46.422283 lr 0.00063328 rank 7
2022-12-03 15:03:39,281 DEBUG TRAIN Batch 1/7500 loss 52.069496 loss_att 66.359398 loss_ctc 71.427246 loss_rnnt 46.630486 lr 0.00063364 rank 2
2022-12-03 15:03:39,282 DEBUG TRAIN Batch 1/7500 loss 53.370979 loss_att 67.196411 loss_ctc 70.989662 loss_rnnt 48.256737 lr 0.00063320 rank 4
2022-12-03 15:03:39,283 DEBUG TRAIN Batch 1/7500 loss 50.001877 loss_att 61.447792 loss_ctc 69.939194 loss_rnnt 45.054382 lr 0.00063340 rank 3
2022-12-03 15:03:39,331 DEBUG TRAIN Batch 1/7500 loss 38.521988 loss_att 55.518211 loss_ctc 58.026825 loss_rnnt 32.522099 lr 0.00063444 rank 1
2022-12-03 15:04:50,686 DEBUG TRAIN Batch 1/7600 loss 42.368893 loss_att 61.908081 loss_ctc 55.819908 loss_rnnt 36.667587 lr 0.00063748 rank 6
2022-12-03 15:04:50,688 DEBUG TRAIN Batch 1/7600 loss 26.033018 loss_att 43.075081 loss_ctc 42.832214 loss_rnnt 20.384712 lr 0.00063740 rank 3
2022-12-03 15:04:50,690 DEBUG TRAIN Batch 1/7600 loss 43.729240 loss_att 65.434769 loss_ctc 67.091728 loss_rnnt 36.273136 lr 0.00063736 rank 5
2022-12-03 15:04:50,690 DEBUG TRAIN Batch 1/7600 loss 45.042873 loss_att 73.549606 loss_ctc 52.744789 loss_rnnt 38.314606 lr 0.00063680 rank 0
2022-12-03 15:04:50,691 DEBUG TRAIN Batch 1/7600 loss 40.853252 loss_att 67.026016 loss_ctc 65.575508 loss_rnnt 32.322399 lr 0.00063764 rank 2
2022-12-03 15:04:50,691 DEBUG TRAIN Batch 1/7600 loss 41.862812 loss_att 58.526028 loss_ctc 57.643032 loss_rnnt 36.426144 lr 0.00063720 rank 4
2022-12-03 15:04:50,692 DEBUG TRAIN Batch 1/7600 loss 44.970821 loss_att 55.969006 loss_ctc 54.840015 loss_rnnt 41.455292 lr 0.00063844 rank 1
2022-12-03 15:04:50,695 DEBUG TRAIN Batch 1/7600 loss 26.613728 loss_att 36.678890 loss_ctc 36.875332 loss_rnnt 23.232481 lr 0.00063728 rank 7
2022-12-03 15:06:02,614 DEBUG TRAIN Batch 1/7700 loss 69.008430 loss_att 100.732468 loss_ctc 96.814140 loss_rnnt 58.956192 lr 0.00064128 rank 7
2022-12-03 15:06:02,621 DEBUG TRAIN Batch 1/7700 loss 51.034775 loss_att 69.614517 loss_ctc 67.413475 loss_rnnt 45.135002 lr 0.00064244 rank 1
2022-12-03 15:06:02,624 DEBUG TRAIN Batch 1/7700 loss 52.290001 loss_att 77.277557 loss_ctc 63.925072 loss_rnnt 45.741150 lr 0.00064164 rank 2
2022-12-03 15:06:02,626 DEBUG TRAIN Batch 1/7700 loss 33.145687 loss_att 40.650787 loss_ctc 42.307766 loss_rnnt 30.423054 lr 0.00064136 rank 5
2022-12-03 15:06:02,627 DEBUG TRAIN Batch 1/7700 loss 39.860027 loss_att 55.846870 loss_ctc 58.041977 loss_rnnt 34.238400 lr 0.00064140 rank 3
2022-12-03 15:06:02,627 DEBUG TRAIN Batch 1/7700 loss 42.336193 loss_att 67.359009 loss_ctc 61.390884 loss_rnnt 34.791004 lr 0.00064148 rank 6
2022-12-03 15:06:02,630 DEBUG TRAIN Batch 1/7700 loss 97.238113 loss_att 120.791779 loss_ctc 128.834885 loss_rnnt 88.314476 lr 0.00064080 rank 0
2022-12-03 15:06:02,678 DEBUG TRAIN Batch 1/7700 loss 22.397018 loss_att 25.935280 loss_ctc 29.283741 loss_rnnt 20.771135 lr 0.00064120 rank 4
2022-12-03 15:07:16,195 DEBUG TRAIN Batch 1/7800 loss 40.630070 loss_att 55.547661 loss_ctc 60.595398 loss_rnnt 34.984505 lr 0.00064548 rank 6
2022-12-03 15:07:16,204 DEBUG TRAIN Batch 1/7800 loss 50.802505 loss_att 73.138428 loss_ctc 68.326721 loss_rnnt 43.998760 lr 0.00064644 rank 1
2022-12-03 15:07:16,209 DEBUG TRAIN Batch 1/7800 loss 21.827362 loss_att 43.688232 loss_ctc 30.258743 loss_rnnt 16.331005 lr 0.00064540 rank 3
2022-12-03 15:07:16,211 DEBUG TRAIN Batch 1/7800 loss 72.920837 loss_att 107.541397 loss_ctc 100.584442 loss_rnnt 62.308250 lr 0.00064520 rank 4
2022-12-03 15:07:16,212 DEBUG TRAIN Batch 1/7800 loss 41.551052 loss_att 61.085999 loss_ctc 58.273922 loss_rnnt 35.414349 lr 0.00064564 rank 2
2022-12-03 15:07:16,212 DEBUG TRAIN Batch 1/7800 loss 37.700768 loss_att 52.844109 loss_ctc 58.352104 loss_rnnt 31.918587 lr 0.00064480 rank 0
2022-12-03 15:07:16,215 DEBUG TRAIN Batch 1/7800 loss 42.683304 loss_att 67.144768 loss_ctc 63.354431 loss_rnnt 35.034863 lr 0.00064528 rank 7
2022-12-03 15:07:16,231 DEBUG TRAIN Batch 1/7800 loss 42.028034 loss_att 61.567703 loss_ctc 54.465904 loss_rnnt 36.461716 lr 0.00064536 rank 5
2022-12-03 15:08:30,574 DEBUG TRAIN Batch 1/7900 loss 38.928406 loss_att 57.620140 loss_ctc 52.883518 loss_rnnt 33.329376 lr 0.00064880 rank 0
2022-12-03 15:08:30,574 DEBUG TRAIN Batch 1/7900 loss 47.705082 loss_att 66.651131 loss_ctc 57.958138 loss_rnnt 42.548798 lr 0.00064936 rank 5
2022-12-03 15:08:30,578 DEBUG TRAIN Batch 1/7900 loss 45.918453 loss_att 63.124634 loss_ctc 62.599205 loss_rnnt 40.253113 lr 0.00064940 rank 3
2022-12-03 15:08:30,579 DEBUG TRAIN Batch 1/7900 loss 60.439552 loss_att 81.270386 loss_ctc 85.224426 loss_rnnt 52.968735 lr 0.00064948 rank 6
2022-12-03 15:08:30,579 DEBUG TRAIN Batch 1/7900 loss 41.695568 loss_att 65.611366 loss_ctc 53.408474 loss_rnnt 35.350689 lr 0.00065044 rank 1
2022-12-03 15:08:30,579 DEBUG TRAIN Batch 1/7900 loss 35.295845 loss_att 58.052010 loss_ctc 53.666794 loss_rnnt 28.295149 lr 0.00064928 rank 7
2022-12-03 15:08:30,580 DEBUG TRAIN Batch 1/7900 loss 33.545341 loss_att 50.147888 loss_ctc 46.489540 loss_rnnt 28.498936 lr 0.00064964 rank 2
2022-12-03 15:08:30,581 DEBUG TRAIN Batch 1/7900 loss 50.498081 loss_att 80.557434 loss_ctc 68.035782 loss_rnnt 42.147850 lr 0.00064920 rank 4
2022-12-03 15:09:42,227 DEBUG TRAIN Batch 1/8000 loss 49.184647 loss_att 68.659424 loss_ctc 70.850128 loss_rnnt 42.400955 lr 0.00065336 rank 5
2022-12-03 15:09:42,230 DEBUG TRAIN Batch 1/8000 loss 55.211906 loss_att 77.282715 loss_ctc 71.934250 loss_rnnt 48.568100 lr 0.00065340 rank 3
2022-12-03 15:09:42,231 DEBUG TRAIN Batch 1/8000 loss 38.298264 loss_att 52.740433 loss_ctc 55.306702 loss_rnnt 33.142040 lr 0.00065280 rank 0
2022-12-03 15:09:42,235 DEBUG TRAIN Batch 1/8000 loss 46.278488 loss_att 60.806599 loss_ctc 73.688995 loss_rnnt 39.718132 lr 0.00065348 rank 6
2022-12-03 15:09:42,239 DEBUG TRAIN Batch 1/8000 loss 43.206955 loss_att 59.283062 loss_ctc 53.945671 loss_rnnt 38.559906 lr 0.00065320 rank 4
2022-12-03 15:09:42,239 DEBUG TRAIN Batch 1/8000 loss 36.638470 loss_att 54.910278 loss_ctc 48.528610 loss_rnnt 31.398756 lr 0.00065444 rank 1
2022-12-03 15:09:42,239 DEBUG TRAIN Batch 1/8000 loss 49.868210 loss_att 69.554230 loss_ctc 63.008400 loss_rnnt 44.178982 lr 0.00065328 rank 7
2022-12-03 15:09:42,241 DEBUG TRAIN Batch 1/8000 loss 44.493553 loss_att 64.164070 loss_ctc 64.609863 loss_rnnt 37.877274 lr 0.00065364 rank 2
2022-12-03 15:10:54,058 DEBUG TRAIN Batch 1/8100 loss 40.439899 loss_att 52.944614 loss_ctc 51.394989 loss_rnnt 36.478275 lr 0.00065764 rank 2
2022-12-03 15:10:54,064 DEBUG TRAIN Batch 1/8100 loss 52.798130 loss_att 66.443527 loss_ctc 74.460350 loss_rnnt 47.180756 lr 0.00065748 rank 6
2022-12-03 15:10:54,065 DEBUG TRAIN Batch 1/8100 loss 26.302811 loss_att 37.438881 loss_ctc 40.263794 loss_rnnt 22.214132 lr 0.00065740 rank 3
2022-12-03 15:10:54,066 DEBUG TRAIN Batch 1/8100 loss 50.031227 loss_att 68.214081 loss_ctc 64.638947 loss_rnnt 44.446960 lr 0.00065844 rank 1
2022-12-03 15:10:54,066 DEBUG TRAIN Batch 1/8100 loss 47.774815 loss_att 57.882874 loss_ctc 62.054424 loss_rnnt 43.849251 lr 0.00065680 rank 0
2022-12-03 15:10:54,068 DEBUG TRAIN Batch 1/8100 loss 47.331848 loss_att 66.242157 loss_ctc 59.662308 loss_rnnt 41.905724 lr 0.00065736 rank 5
2022-12-03 15:10:54,068 DEBUG TRAIN Batch 1/8100 loss 37.284004 loss_att 49.024036 loss_ctc 48.426487 loss_rnnt 33.450333 lr 0.00065728 rank 7
2022-12-03 15:10:54,073 DEBUG TRAIN Batch 1/8100 loss 28.175831 loss_att 43.184456 loss_ctc 36.683533 loss_rnnt 24.039745 lr 0.00065720 rank 4
2022-12-03 15:12:06,130 DEBUG TRAIN Batch 1/8200 loss 21.388060 loss_att 25.934238 loss_ctc 28.395144 loss_rnnt 19.544544 lr 0.00066148 rank 6
2022-12-03 15:12:06,131 DEBUG TRAIN Batch 1/8200 loss 40.491146 loss_att 54.599274 loss_ctc 52.172985 loss_rnnt 36.111938 lr 0.00066136 rank 5
2022-12-03 15:12:06,136 DEBUG TRAIN Batch 1/8200 loss 45.784210 loss_att 57.365578 loss_ctc 60.481483 loss_rnnt 41.508301 lr 0.00066244 rank 1
2022-12-03 15:12:06,137 DEBUG TRAIN Batch 1/8200 loss 42.225010 loss_att 60.281174 loss_ctc 62.455524 loss_rnnt 35.916378 lr 0.00066128 rank 7
2022-12-03 15:12:06,137 DEBUG TRAIN Batch 1/8200 loss 46.039249 loss_att 68.789948 loss_ctc 59.285378 loss_rnnt 39.722958 lr 0.00066080 rank 0
2022-12-03 15:12:06,139 DEBUG TRAIN Batch 1/8200 loss 35.641037 loss_att 56.012886 loss_ctc 54.686913 loss_rnnt 29.027214 lr 0.00066120 rank 4
2022-12-03 15:12:06,140 DEBUG TRAIN Batch 1/8200 loss 24.078270 loss_att 29.952259 loss_ctc 34.026245 loss_rnnt 21.577074 lr 0.00066140 rank 3
2022-12-03 15:12:06,141 DEBUG TRAIN Batch 1/8200 loss 57.106865 loss_att 80.507782 loss_ctc 90.629051 loss_rnnt 47.957058 lr 0.00066164 rank 2
2022-12-03 15:13:17,391 DEBUG TRAIN Batch 1/8300 loss 34.467964 loss_att 51.875793 loss_ctc 54.093365 loss_rnnt 28.369680 lr 0.00066480 rank 0
2022-12-03 15:13:17,395 DEBUG TRAIN Batch 1/8300 loss 39.777634 loss_att 55.273594 loss_ctc 55.245689 loss_rnnt 34.616032 lr 0.00066536 rank 5
2022-12-03 15:13:17,398 DEBUG TRAIN Batch 1/8300 loss 42.223450 loss_att 61.018932 loss_ctc 62.920315 loss_rnnt 35.704773 lr 0.00066540 rank 3
2022-12-03 15:13:17,399 DEBUG TRAIN Batch 1/8300 loss 42.815781 loss_att 60.364014 loss_ctc 59.887493 loss_rnnt 37.029903 lr 0.00066548 rank 6
2022-12-03 15:13:17,401 DEBUG TRAIN Batch 1/8300 loss 39.612335 loss_att 52.463806 loss_ctc 53.842571 loss_rnnt 35.144676 lr 0.00066520 rank 4
2022-12-03 15:13:17,402 DEBUG TRAIN Batch 1/8300 loss 45.818527 loss_att 66.791290 loss_ctc 78.976494 loss_rnnt 37.202915 lr 0.00066564 rank 2
2022-12-03 15:13:17,404 DEBUG TRAIN Batch 1/8300 loss 51.285263 loss_att 65.900009 loss_ctc 71.579445 loss_rnnt 45.656425 lr 0.00066528 rank 7
2022-12-03 15:13:17,446 DEBUG TRAIN Batch 1/8300 loss 27.170572 loss_att 32.819061 loss_ctc 30.497717 loss_rnnt 25.597256 lr 0.00066644 rank 1
2022-12-03 15:14:07,071 DEBUG CV Batch 1/0 loss 7.998265 loss_att 8.651558 loss_ctc 11.034649 loss_rnnt 7.462755 history loss 7.702033 rank 0
2022-12-03 15:14:07,076 DEBUG CV Batch 1/0 loss 7.998265 loss_att 8.651558 loss_ctc 11.034649 loss_rnnt 7.462755 history loss 7.702033 rank 1
2022-12-03 15:14:07,076 DEBUG CV Batch 1/0 loss 7.998265 loss_att 8.651558 loss_ctc 11.034649 loss_rnnt 7.462755 history loss 7.702033 rank 5
2022-12-03 15:14:07,080 DEBUG CV Batch 1/0 loss 7.998265 loss_att 8.651558 loss_ctc 11.034649 loss_rnnt 7.462755 history loss 7.702033 rank 3
2022-12-03 15:14:07,083 DEBUG CV Batch 1/0 loss 7.998265 loss_att 8.651558 loss_ctc 11.034649 loss_rnnt 7.462755 history loss 7.702033 rank 6
2022-12-03 15:14:07,103 DEBUG CV Batch 1/0 loss 7.998265 loss_att 8.651558 loss_ctc 11.034649 loss_rnnt 7.462755 history loss 7.702033 rank 2
2022-12-03 15:14:07,115 DEBUG CV Batch 1/0 loss 7.998265 loss_att 8.651558 loss_ctc 11.034649 loss_rnnt 7.462755 history loss 7.702033 rank 4
2022-12-03 15:14:07,118 DEBUG CV Batch 1/0 loss 7.998265 loss_att 8.651558 loss_ctc 11.034649 loss_rnnt 7.462755 history loss 7.702033 rank 7
2022-12-03 15:14:18,337 DEBUG CV Batch 1/100 loss 30.060110 loss_att 43.079086 loss_ctc 45.265495 loss_rnnt 25.428928 history loss 16.044285 rank 5
2022-12-03 15:14:18,447 DEBUG CV Batch 1/100 loss 30.060110 loss_att 43.079086 loss_ctc 45.265495 loss_rnnt 25.428928 history loss 16.044285 rank 7
2022-12-03 15:14:18,463 DEBUG CV Batch 1/100 loss 30.060110 loss_att 43.079086 loss_ctc 45.265495 loss_rnnt 25.428928 history loss 16.044285 rank 1
2022-12-03 15:14:18,507 DEBUG CV Batch 1/100 loss 30.060110 loss_att 43.079086 loss_ctc 45.265495 loss_rnnt 25.428928 history loss 16.044285 rank 0
2022-12-03 15:14:18,585 DEBUG CV Batch 1/100 loss 30.060110 loss_att 43.079086 loss_ctc 45.265495 loss_rnnt 25.428928 history loss 16.044285 rank 4
2022-12-03 15:14:18,662 DEBUG CV Batch 1/100 loss 30.060110 loss_att 43.079086 loss_ctc 45.265495 loss_rnnt 25.428928 history loss 16.044285 rank 6
2022-12-03 15:14:18,814 DEBUG CV Batch 1/100 loss 30.060110 loss_att 43.079086 loss_ctc 45.265495 loss_rnnt 25.428928 history loss 16.044285 rank 3
2022-12-03 15:14:18,981 DEBUG CV Batch 1/100 loss 30.060110 loss_att 43.079086 loss_ctc 45.265495 loss_rnnt 25.428928 history loss 16.044285 rank 2
2022-12-03 15:14:31,931 DEBUG CV Batch 1/200 loss 49.754333 loss_att 88.766098 loss_ctc 69.255661 loss_rnnt 39.351803 history loss 17.800948 rank 1
2022-12-03 15:14:32,100 DEBUG CV Batch 1/200 loss 49.754333 loss_att 88.766098 loss_ctc 69.255661 loss_rnnt 39.351803 history loss 17.800948 rank 4
2022-12-03 15:14:32,185 DEBUG CV Batch 1/200 loss 49.754333 loss_att 88.766098 loss_ctc 69.255661 loss_rnnt 39.351803 history loss 17.800948 rank 7
2022-12-03 15:14:32,192 DEBUG CV Batch 1/200 loss 49.754333 loss_att 88.766098 loss_ctc 69.255661 loss_rnnt 39.351803 history loss 17.800948 rank 0
2022-12-03 15:14:32,326 DEBUG CV Batch 1/200 loss 49.754333 loss_att 88.766098 loss_ctc 69.255661 loss_rnnt 39.351803 history loss 17.800948 rank 6
2022-12-03 15:14:32,329 DEBUG CV Batch 1/200 loss 49.754333 loss_att 88.766098 loss_ctc 69.255661 loss_rnnt 39.351803 history loss 17.800948 rank 5
2022-12-03 15:14:32,531 DEBUG CV Batch 1/200 loss 49.754333 loss_att 88.766098 loss_ctc 69.255661 loss_rnnt 39.351803 history loss 17.800948 rank 3
2022-12-03 15:14:32,962 DEBUG CV Batch 1/200 loss 49.754333 loss_att 88.766098 loss_ctc 69.255661 loss_rnnt 39.351803 history loss 17.800948 rank 2
2022-12-03 15:14:43,861 DEBUG CV Batch 1/300 loss 22.126091 loss_att 39.883709 loss_ctc 32.933704 loss_rnnt 17.133553 history loss 17.821749 rank 1
2022-12-03 15:14:44,141 DEBUG CV Batch 1/300 loss 22.126091 loss_att 39.883709 loss_ctc 32.933704 loss_rnnt 17.133553 history loss 17.821749 rank 7
2022-12-03 15:14:44,161 DEBUG CV Batch 1/300 loss 22.126091 loss_att 39.883709 loss_ctc 32.933704 loss_rnnt 17.133553 history loss 17.821749 rank 4
2022-12-03 15:14:44,258 DEBUG CV Batch 1/300 loss 22.126091 loss_att 39.883709 loss_ctc 32.933704 loss_rnnt 17.133553 history loss 17.821749 rank 5
2022-12-03 15:14:44,526 DEBUG CV Batch 1/300 loss 22.126091 loss_att 39.883709 loss_ctc 32.933704 loss_rnnt 17.133553 history loss 17.821749 rank 0
2022-12-03 15:14:44,741 DEBUG CV Batch 1/300 loss 22.126091 loss_att 39.883709 loss_ctc 32.933704 loss_rnnt 17.133553 history loss 17.821749 rank 6
2022-12-03 15:14:44,862 DEBUG CV Batch 1/300 loss 22.126091 loss_att 39.883709 loss_ctc 32.933704 loss_rnnt 17.133553 history loss 17.821749 rank 3
2022-12-03 15:14:45,322 DEBUG CV Batch 1/300 loss 22.126091 loss_att 39.883709 loss_ctc 32.933704 loss_rnnt 17.133553 history loss 17.821749 rank 2
2022-12-03 15:14:55,732 DEBUG CV Batch 1/400 loss 80.801308 loss_att 246.591675 loss_ctc 81.305008 loss_rnnt 47.576069 history loss 19.646358 rank 1
2022-12-03 15:14:56,074 DEBUG CV Batch 1/400 loss 80.801308 loss_att 246.591675 loss_ctc 81.305008 loss_rnnt 47.576069 history loss 19.646358 rank 7
2022-12-03 15:14:56,138 DEBUG CV Batch 1/400 loss 80.801308 loss_att 246.591675 loss_ctc 81.305008 loss_rnnt 47.576069 history loss 19.646358 rank 5
2022-12-03 15:14:56,146 DEBUG CV Batch 1/400 loss 80.801308 loss_att 246.591675 loss_ctc 81.305008 loss_rnnt 47.576069 history loss 19.646358 rank 4
2022-12-03 15:14:56,873 DEBUG CV Batch 1/400 loss 80.801308 loss_att 246.591675 loss_ctc 81.305008 loss_rnnt 47.576069 history loss 19.646358 rank 0
2022-12-03 15:14:57,012 DEBUG CV Batch 1/400 loss 80.801308 loss_att 246.591675 loss_ctc 81.305008 loss_rnnt 47.576069 history loss 19.646358 rank 6
2022-12-03 15:14:57,102 DEBUG CV Batch 1/400 loss 80.801308 loss_att 246.591675 loss_ctc 81.305008 loss_rnnt 47.576069 history loss 19.646358 rank 3
2022-12-03 15:14:57,766 DEBUG CV Batch 1/400 loss 80.801308 loss_att 246.591675 loss_ctc 81.305008 loss_rnnt 47.576069 history loss 19.646358 rank 2
2022-12-03 15:15:05,929 DEBUG CV Batch 1/500 loss 31.909290 loss_att 47.294624 loss_ctc 44.845070 loss_rnnt 27.107452 history loss 21.062817 rank 1
2022-12-03 15:15:06,466 DEBUG CV Batch 1/500 loss 31.909290 loss_att 47.294624 loss_ctc 44.845070 loss_rnnt 27.107452 history loss 21.062817 rank 4
2022-12-03 15:15:06,625 DEBUG CV Batch 1/500 loss 31.909290 loss_att 47.294624 loss_ctc 44.845070 loss_rnnt 27.107452 history loss 21.062817 rank 5
2022-12-03 15:15:06,635 DEBUG CV Batch 1/500 loss 31.909290 loss_att 47.294624 loss_ctc 44.845070 loss_rnnt 27.107452 history loss 21.062817 rank 7
2022-12-03 15:15:07,604 DEBUG CV Batch 1/500 loss 31.909290 loss_att 47.294624 loss_ctc 44.845070 loss_rnnt 27.107452 history loss 21.062817 rank 6
2022-12-03 15:15:07,635 DEBUG CV Batch 1/500 loss 31.909290 loss_att 47.294624 loss_ctc 44.845070 loss_rnnt 27.107452 history loss 21.062817 rank 0
2022-12-03 15:15:07,825 DEBUG CV Batch 1/500 loss 31.909290 loss_att 47.294624 loss_ctc 44.845070 loss_rnnt 27.107452 history loss 21.062817 rank 3
2022-12-03 15:15:08,391 DEBUG CV Batch 1/500 loss 31.909290 loss_att 47.294624 loss_ctc 44.845070 loss_rnnt 27.107452 history loss 21.062817 rank 2
2022-12-03 15:15:17,904 DEBUG CV Batch 1/600 loss 19.890987 loss_att 31.118679 loss_ctc 26.200409 loss_rnnt 16.804192 history loss 22.486523 rank 1
2022-12-03 15:15:18,556 DEBUG CV Batch 1/600 loss 19.890987 loss_att 31.118679 loss_ctc 26.200409 loss_rnnt 16.804192 history loss 22.486523 rank 4
2022-12-03 15:15:18,682 DEBUG CV Batch 1/600 loss 19.890987 loss_att 31.118679 loss_ctc 26.200409 loss_rnnt 16.804192 history loss 22.486523 rank 5
2022-12-03 15:15:18,826 DEBUG CV Batch 1/600 loss 19.890987 loss_att 31.118679 loss_ctc 26.200409 loss_rnnt 16.804192 history loss 22.486523 rank 7
2022-12-03 15:15:19,851 DEBUG CV Batch 1/600 loss 19.890987 loss_att 31.118679 loss_ctc 26.200409 loss_rnnt 16.804192 history loss 22.486523 rank 6
2022-12-03 15:15:19,998 DEBUG CV Batch 1/600 loss 19.890987 loss_att 31.118679 loss_ctc 26.200409 loss_rnnt 16.804192 history loss 22.486523 rank 0
2022-12-03 15:15:20,155 DEBUG CV Batch 1/600 loss 19.890987 loss_att 31.118679 loss_ctc 26.200409 loss_rnnt 16.804192 history loss 22.486523 rank 3
2022-12-03 15:15:20,708 DEBUG CV Batch 1/600 loss 19.890987 loss_att 31.118679 loss_ctc 26.200409 loss_rnnt 16.804192 history loss 22.486523 rank 2
2022-12-03 15:15:29,125 DEBUG CV Batch 1/700 loss 76.445076 loss_att 176.169586 loss_ctc 92.954559 loss_rnnt 54.298904 history loss 23.799343 rank 1
2022-12-03 15:15:29,801 DEBUG CV Batch 1/700 loss 76.445076 loss_att 176.169586 loss_ctc 92.954559 loss_rnnt 54.298904 history loss 23.799343 rank 4
2022-12-03 15:15:30,768 DEBUG CV Batch 1/700 loss 76.445076 loss_att 176.169586 loss_ctc 92.954559 loss_rnnt 54.298904 history loss 23.799343 rank 5
2022-12-03 15:15:31,288 DEBUG CV Batch 1/700 loss 76.445076 loss_att 176.169586 loss_ctc 92.954559 loss_rnnt 54.298904 history loss 23.799343 rank 7
2022-12-03 15:15:31,381 DEBUG CV Batch 1/700 loss 76.445076 loss_att 176.169586 loss_ctc 92.954559 loss_rnnt 54.298904 history loss 23.799343 rank 6
2022-12-03 15:15:31,683 DEBUG CV Batch 1/700 loss 76.445076 loss_att 176.169586 loss_ctc 92.954559 loss_rnnt 54.298904 history loss 23.799343 rank 0
2022-12-03 15:15:31,857 DEBUG CV Batch 1/700 loss 76.445076 loss_att 176.169586 loss_ctc 92.954559 loss_rnnt 54.298904 history loss 23.799343 rank 3
2022-12-03 15:15:32,588 DEBUG CV Batch 1/700 loss 76.445076 loss_att 176.169586 loss_ctc 92.954559 loss_rnnt 54.298904 history loss 23.799343 rank 2
2022-12-03 15:15:40,563 DEBUG CV Batch 1/800 loss 31.193415 loss_att 43.026360 loss_ctc 48.415188 loss_rnnt 26.530590 history loss 22.744514 rank 1
2022-12-03 15:15:41,132 DEBUG CV Batch 1/800 loss 31.193415 loss_att 43.026360 loss_ctc 48.415188 loss_rnnt 26.530590 history loss 22.744514 rank 4
2022-12-03 15:15:42,743 DEBUG CV Batch 1/800 loss 31.193415 loss_att 43.026360 loss_ctc 48.415188 loss_rnnt 26.530590 history loss 22.744514 rank 5
2022-12-03 15:15:43,280 DEBUG CV Batch 1/800 loss 31.193415 loss_att 43.026360 loss_ctc 48.415188 loss_rnnt 26.530590 history loss 22.744514 rank 0
2022-12-03 15:15:43,405 DEBUG CV Batch 1/800 loss 31.193415 loss_att 43.026360 loss_ctc 48.415188 loss_rnnt 26.530590 history loss 22.744514 rank 3
2022-12-03 15:15:43,451 DEBUG CV Batch 1/800 loss 31.193415 loss_att 43.026360 loss_ctc 48.415188 loss_rnnt 26.530590 history loss 22.744514 rank 7
2022-12-03 15:15:43,496 DEBUG CV Batch 1/800 loss 31.193415 loss_att 43.026360 loss_ctc 48.415188 loss_rnnt 26.530590 history loss 22.744514 rank 6
2022-12-03 15:15:43,726 DEBUG CV Batch 1/800 loss 31.193415 loss_att 43.026360 loss_ctc 48.415188 loss_rnnt 26.530590 history loss 22.744514 rank 2
2022-12-03 15:15:53,970 DEBUG CV Batch 1/900 loss 42.303009 loss_att 79.881516 loss_ctc 65.331108 loss_rnnt 31.716896 history loss 22.488137 rank 1
2022-12-03 15:15:54,455 DEBUG CV Batch 1/900 loss 42.303009 loss_att 79.881516 loss_ctc 65.331108 loss_rnnt 31.716896 history loss 22.488137 rank 4
2022-12-03 15:15:57,014 DEBUG CV Batch 1/900 loss 42.303009 loss_att 79.881516 loss_ctc 65.331108 loss_rnnt 31.716896 history loss 22.488137 rank 0
2022-12-03 15:15:57,185 DEBUG CV Batch 1/900 loss 42.303009 loss_att 79.881516 loss_ctc 65.331108 loss_rnnt 31.716896 history loss 22.488137 rank 3
2022-12-03 15:15:57,210 DEBUG CV Batch 1/900 loss 42.303009 loss_att 79.881516 loss_ctc 65.331108 loss_rnnt 31.716896 history loss 22.488137 rank 6
2022-12-03 15:15:57,289 DEBUG CV Batch 1/900 loss 42.303009 loss_att 79.881516 loss_ctc 65.331108 loss_rnnt 31.716896 history loss 22.488137 rank 5
2022-12-03 15:15:57,313 DEBUG CV Batch 1/900 loss 42.303009 loss_att 79.881516 loss_ctc 65.331108 loss_rnnt 31.716896 history loss 22.488137 rank 2
2022-12-03 15:15:57,501 DEBUG CV Batch 1/900 loss 42.303009 loss_att 79.881516 loss_ctc 65.331108 loss_rnnt 31.716896 history loss 22.488137 rank 7
2022-12-03 15:16:05,985 DEBUG CV Batch 1/1000 loss 18.238728 loss_att 32.551949 loss_ctc 24.590174 loss_rnnt 14.529222 history loss 22.047573 rank 1
2022-12-03 15:16:06,840 DEBUG CV Batch 1/1000 loss 18.238728 loss_att 32.551949 loss_ctc 24.590174 loss_rnnt 14.529222 history loss 22.047573 rank 4
2022-12-03 15:16:09,447 DEBUG CV Batch 1/1000 loss 18.238728 loss_att 32.551949 loss_ctc 24.590174 loss_rnnt 14.529222 history loss 22.047573 rank 5
2022-12-03 15:16:09,472 DEBUG CV Batch 1/1000 loss 18.238728 loss_att 32.551949 loss_ctc 24.590174 loss_rnnt 14.529222 history loss 22.047573 rank 6
2022-12-03 15:16:09,689 DEBUG CV Batch 1/1000 loss 18.238728 loss_att 32.551949 loss_ctc 24.590174 loss_rnnt 14.529222 history loss 22.047573 rank 0
2022-12-03 15:16:09,769 DEBUG CV Batch 1/1000 loss 18.238728 loss_att 32.551949 loss_ctc 24.590174 loss_rnnt 14.529222 history loss 22.047573 rank 3
2022-12-03 15:16:09,806 DEBUG CV Batch 1/1000 loss 18.238728 loss_att 32.551949 loss_ctc 24.590174 loss_rnnt 14.529222 history loss 22.047573 rank 7
2022-12-03 15:16:10,045 DEBUG CV Batch 1/1000 loss 18.238728 loss_att 32.551949 loss_ctc 24.590174 loss_rnnt 14.529222 history loss 22.047573 rank 2
2022-12-03 15:16:17,904 DEBUG CV Batch 1/1100 loss 11.442109 loss_att 13.744781 loss_ctc 14.656650 loss_rnnt 10.552970 history loss 22.035755 rank 1
2022-12-03 15:16:18,823 DEBUG CV Batch 1/1100 loss 11.442109 loss_att 13.744781 loss_ctc 14.656650 loss_rnnt 10.552970 history loss 22.035755 rank 4
2022-12-03 15:16:21,190 DEBUG CV Batch 1/1100 loss 11.442109 loss_att 13.744781 loss_ctc 14.656650 loss_rnnt 10.552970 history loss 22.035755 rank 5
2022-12-03 15:16:21,668 DEBUG CV Batch 1/1100 loss 11.442109 loss_att 13.744781 loss_ctc 14.656650 loss_rnnt 10.552970 history loss 22.035755 rank 6
2022-12-03 15:16:21,965 DEBUG CV Batch 1/1100 loss 11.442109 loss_att 13.744781 loss_ctc 14.656650 loss_rnnt 10.552970 history loss 22.035755 rank 7
2022-12-03 15:16:22,058 DEBUG CV Batch 1/1100 loss 11.442109 loss_att 13.744781 loss_ctc 14.656650 loss_rnnt 10.552970 history loss 22.035755 rank 0
2022-12-03 15:16:22,181 DEBUG CV Batch 1/1100 loss 11.442109 loss_att 13.744781 loss_ctc 14.656650 loss_rnnt 10.552970 history loss 22.035755 rank 3
2022-12-03 15:16:22,255 DEBUG CV Batch 1/1100 loss 11.442109 loss_att 13.744781 loss_ctc 14.656650 loss_rnnt 10.552970 history loss 22.035755 rank 2
2022-12-03 15:16:28,219 DEBUG CV Batch 1/1200 loss 34.885742 loss_att 53.694904 loss_ctc 50.499340 loss_rnnt 29.042097 history loss 22.645803 rank 1
2022-12-03 15:16:29,223 DEBUG CV Batch 1/1200 loss 34.885742 loss_att 53.694904 loss_ctc 50.499340 loss_rnnt 29.042097 history loss 22.645803 rank 4
2022-12-03 15:16:31,633 DEBUG CV Batch 1/1200 loss 34.885742 loss_att 53.694904 loss_ctc 50.499340 loss_rnnt 29.042097 history loss 22.645803 rank 5
2022-12-03 15:16:32,215 DEBUG CV Batch 1/1200 loss 34.885742 loss_att 53.694904 loss_ctc 50.499340 loss_rnnt 29.042097 history loss 22.645803 rank 6
2022-12-03 15:16:32,519 DEBUG CV Batch 1/1200 loss 34.885742 loss_att 53.694904 loss_ctc 50.499340 loss_rnnt 29.042097 history loss 22.645803 rank 7
2022-12-03 15:16:32,950 DEBUG CV Batch 1/1200 loss 34.885742 loss_att 53.694904 loss_ctc 50.499340 loss_rnnt 29.042097 history loss 22.645803 rank 0
2022-12-03 15:16:33,111 DEBUG CV Batch 1/1200 loss 34.885742 loss_att 53.694904 loss_ctc 50.499340 loss_rnnt 29.042097 history loss 22.645803 rank 3
2022-12-03 15:16:33,442 DEBUG CV Batch 1/1200 loss 34.885742 loss_att 53.694904 loss_ctc 50.499340 loss_rnnt 29.042097 history loss 22.645803 rank 2
2022-12-03 15:16:40,023 DEBUG CV Batch 1/1300 loss 20.400602 loss_att 29.946846 loss_ctc 25.756556 loss_rnnt 17.777225 history loss 23.072429 rank 1
2022-12-03 15:16:41,384 DEBUG CV Batch 1/1300 loss 20.400602 loss_att 29.946846 loss_ctc 25.756556 loss_rnnt 17.777225 history loss 23.072429 rank 4
2022-12-03 15:16:43,752 DEBUG CV Batch 1/1300 loss 20.400602 loss_att 29.946846 loss_ctc 25.756556 loss_rnnt 17.777225 history loss 23.072429 rank 5
2022-12-03 15:16:44,332 DEBUG CV Batch 1/1300 loss 20.400602 loss_att 29.946846 loss_ctc 25.756556 loss_rnnt 17.777225 history loss 23.072429 rank 6
2022-12-03 15:16:44,619 DEBUG CV Batch 1/1300 loss 20.400602 loss_att 29.946846 loss_ctc 25.756556 loss_rnnt 17.777225 history loss 23.072429 rank 7
2022-12-03 15:16:45,314 DEBUG CV Batch 1/1300 loss 20.400602 loss_att 29.946846 loss_ctc 25.756556 loss_rnnt 17.777225 history loss 23.072429 rank 0
2022-12-03 15:16:45,497 DEBUG CV Batch 1/1300 loss 20.400602 loss_att 29.946846 loss_ctc 25.756556 loss_rnnt 17.777225 history loss 23.072429 rank 3
2022-12-03 15:16:45,839 DEBUG CV Batch 1/1300 loss 20.400602 loss_att 29.946846 loss_ctc 25.756556 loss_rnnt 17.777225 history loss 23.072429 rank 2
2022-12-03 15:16:51,048 DEBUG CV Batch 1/1400 loss 54.640739 loss_att 124.075592 loss_ctc 78.797485 loss_rnnt 37.532867 history loss 23.717321 rank 1
2022-12-03 15:16:52,647 DEBUG CV Batch 1/1400 loss 54.640739 loss_att 124.075592 loss_ctc 78.797485 loss_rnnt 37.532867 history loss 23.717321 rank 4
2022-12-03 15:16:55,147 DEBUG CV Batch 1/1400 loss 54.640739 loss_att 124.075592 loss_ctc 78.797485 loss_rnnt 37.532867 history loss 23.717321 rank 5
2022-12-03 15:16:55,687 DEBUG CV Batch 1/1400 loss 54.640739 loss_att 124.075592 loss_ctc 78.797485 loss_rnnt 37.532867 history loss 23.717321 rank 6
2022-12-03 15:16:55,879 DEBUG CV Batch 1/1400 loss 54.640739 loss_att 124.075592 loss_ctc 78.797485 loss_rnnt 37.532867 history loss 23.717321 rank 7
2022-12-03 15:16:56,866 DEBUG CV Batch 1/1400 loss 54.640739 loss_att 124.075592 loss_ctc 78.797485 loss_rnnt 37.532867 history loss 23.717321 rank 0
2022-12-03 15:16:57,101 DEBUG CV Batch 1/1400 loss 54.640739 loss_att 124.075592 loss_ctc 78.797485 loss_rnnt 37.532867 history loss 23.717321 rank 3
2022-12-03 15:16:57,363 DEBUG CV Batch 1/1400 loss 54.640739 loss_att 124.075592 loss_ctc 78.797485 loss_rnnt 37.532867 history loss 23.717321 rank 2
2022-12-03 15:17:02,935 DEBUG CV Batch 1/1500 loss 27.292458 loss_att 40.096535 loss_ctc 34.897034 loss_rnnt 23.717697 history loss 23.281960 rank 1
2022-12-03 15:17:03,930 DEBUG CV Batch 1/1500 loss 27.292458 loss_att 40.096535 loss_ctc 34.897034 loss_rnnt 23.717697 history loss 23.281960 rank 4
2022-12-03 15:17:07,783 DEBUG CV Batch 1/1500 loss 27.292458 loss_att 40.096535 loss_ctc 34.897034 loss_rnnt 23.717697 history loss 23.281960 rank 5
2022-12-03 15:17:08,432 DEBUG CV Batch 1/1500 loss 27.292458 loss_att 40.096535 loss_ctc 34.897034 loss_rnnt 23.717697 history loss 23.281960 rank 6
2022-12-03 15:17:08,488 DEBUG CV Batch 1/1500 loss 27.292458 loss_att 40.096535 loss_ctc 34.897034 loss_rnnt 23.717697 history loss 23.281960 rank 7
2022-12-03 15:17:08,812 DEBUG CV Batch 1/1500 loss 27.292458 loss_att 40.096535 loss_ctc 34.897034 loss_rnnt 23.717697 history loss 23.281960 rank 0
2022-12-03 15:17:08,925 DEBUG CV Batch 1/1500 loss 27.292458 loss_att 40.096535 loss_ctc 34.897034 loss_rnnt 23.717697 history loss 23.281960 rank 3
2022-12-03 15:17:09,342 DEBUG CV Batch 1/1500 loss 27.292458 loss_att 40.096535 loss_ctc 34.897034 loss_rnnt 23.717697 history loss 23.281960 rank 2
2022-12-03 15:17:16,281 DEBUG CV Batch 1/1600 loss 34.364326 loss_att 71.846176 loss_ctc 51.053917 loss_rnnt 24.642675 history loss 23.155573 rank 1
2022-12-03 15:17:17,068 DEBUG CV Batch 1/1600 loss 34.364326 loss_att 71.846176 loss_ctc 51.053917 loss_rnnt 24.642675 history loss 23.155573 rank 4
2022-12-03 15:17:21,619 DEBUG CV Batch 1/1600 loss 34.364326 loss_att 71.846176 loss_ctc 51.053917 loss_rnnt 24.642675 history loss 23.155573 rank 5
2022-12-03 15:17:22,092 DEBUG CV Batch 1/1600 loss 34.364326 loss_att 71.846176 loss_ctc 51.053917 loss_rnnt 24.642675 history loss 23.155573 rank 6
2022-12-03 15:17:22,149 DEBUG CV Batch 1/1600 loss 34.364326 loss_att 71.846176 loss_ctc 51.053917 loss_rnnt 24.642675 history loss 23.155573 rank 7
2022-12-03 15:17:22,264 DEBUG CV Batch 1/1600 loss 34.364326 loss_att 71.846176 loss_ctc 51.053917 loss_rnnt 24.642675 history loss 23.155573 rank 0
2022-12-03 15:17:22,345 DEBUG CV Batch 1/1600 loss 34.364326 loss_att 71.846176 loss_ctc 51.053917 loss_rnnt 24.642675 history loss 23.155573 rank 3
2022-12-03 15:17:23,171 DEBUG CV Batch 1/1600 loss 34.364326 loss_att 71.846176 loss_ctc 51.053917 loss_rnnt 24.642675 history loss 23.155573 rank 2
2022-12-03 15:17:28,878 DEBUG CV Batch 1/1700 loss 32.349182 loss_att 51.006969 loss_ctc 43.981651 loss_rnnt 27.066628 history loss 22.894633 rank 1
2022-12-03 15:17:29,877 DEBUG CV Batch 1/1700 loss 32.349182 loss_att 51.006969 loss_ctc 43.981651 loss_rnnt 27.066628 history loss 22.894633 rank 4
2022-12-03 15:17:34,083 DEBUG CV Batch 1/1700 loss 32.349182 loss_att 51.006969 loss_ctc 43.981651 loss_rnnt 27.066628 history loss 22.894633 rank 5
2022-12-03 15:17:34,521 DEBUG CV Batch 1/1700 loss 32.349182 loss_att 51.006969 loss_ctc 43.981651 loss_rnnt 27.066628 history loss 22.894633 rank 6
2022-12-03 15:17:34,652 DEBUG CV Batch 1/1700 loss 32.349182 loss_att 51.006969 loss_ctc 43.981651 loss_rnnt 27.066628 history loss 22.894633 rank 7
2022-12-03 15:17:34,921 DEBUG CV Batch 1/1700 loss 32.349182 loss_att 51.006969 loss_ctc 43.981651 loss_rnnt 27.066628 history loss 22.894633 rank 0
2022-12-03 15:17:35,022 DEBUG CV Batch 1/1700 loss 32.349182 loss_att 51.006969 loss_ctc 43.981651 loss_rnnt 27.066628 history loss 22.894633 rank 3
2022-12-03 15:17:36,221 DEBUG CV Batch 1/1700 loss 32.349182 loss_att 51.006969 loss_ctc 43.981651 loss_rnnt 27.066628 history loss 22.894633 rank 2
2022-12-03 15:17:38,187 INFO Epoch 1 CV info cv_loss 22.846707009393917
2022-12-03 15:17:38,187 INFO Epoch 2 TRAIN info lr 0.0006679199999999999
2022-12-03 15:17:38,192 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 15:17:39,455 INFO Epoch 1 CV info cv_loss 22.846707009393917
2022-12-03 15:17:39,456 INFO Epoch 2 TRAIN info lr 0.00066632
2022-12-03 15:17:39,461 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 15:17:43,338 INFO Epoch 1 CV info cv_loss 22.846707009393917
2022-12-03 15:17:43,339 INFO Epoch 2 TRAIN info lr 0.00066636
2022-12-03 15:17:43,340 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 15:17:43,807 INFO Epoch 1 CV info cv_loss 22.846707009393917
2022-12-03 15:17:43,808 INFO Epoch 2 TRAIN info lr 0.0006674
2022-12-03 15:17:43,810 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 15:17:44,010 INFO Epoch 1 CV info cv_loss 22.846707009393917
2022-12-03 15:17:44,010 INFO Epoch 2 TRAIN info lr 0.00066632
2022-12-03 15:17:44,012 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 15:17:44,199 INFO Epoch 1 CV info cv_loss 22.846707009393917
2022-12-03 15:17:44,200 INFO Checkpoint: save to checkpoint exp/1202_encoder_bias_30_0.1/1.pt
2022-12-03 15:17:44,300 INFO Epoch 1 CV info cv_loss 22.846707009393917
2022-12-03 15:17:44,300 INFO Epoch 2 TRAIN info lr 0.0006674399999999999
2022-12-03 15:17:44,302 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 15:17:45,261 INFO Epoch 2 TRAIN info lr 0.00066724
2022-12-03 15:17:45,266 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 15:17:45,800 INFO Epoch 1 CV info cv_loss 22.846707009393917
2022-12-03 15:17:45,801 INFO Epoch 2 TRAIN info lr 0.00066796
2022-12-03 15:17:45,806 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 15:18:49,399 DEBUG TRAIN Batch 2/0 loss 15.249324 loss_att 16.792057 loss_ctc 17.539103 loss_rnnt 14.635474 lr 0.00066748 rank 3
2022-12-03 15:18:49,399 DEBUG TRAIN Batch 2/0 loss 19.247692 loss_att 20.640238 loss_ctc 22.919493 loss_rnnt 18.479610 lr 0.00066744 rank 6
2022-12-03 15:18:49,404 DEBUG TRAIN Batch 2/0 loss 17.496744 loss_att 19.210281 loss_ctc 20.978262 loss_rnnt 16.689835 lr 0.00066728 rank 0
2022-12-03 15:18:49,406 DEBUG TRAIN Batch 2/0 loss 18.296358 loss_att 20.328306 loss_ctc 23.169846 loss_rnnt 17.240170 lr 0.00066640 rank 5
2022-12-03 15:18:49,406 DEBUG TRAIN Batch 2/0 loss 17.459139 loss_att 20.863356 loss_ctc 22.308439 loss_rnnt 16.131721 lr 0.00066796 rank 1
2022-12-03 15:18:49,407 DEBUG TRAIN Batch 2/0 loss 18.432438 loss_att 20.017210 loss_ctc 22.012272 loss_rnnt 17.638174 lr 0.00066636 rank 4
2022-12-03 15:18:49,410 DEBUG TRAIN Batch 2/0 loss 16.927746 loss_att 19.975922 loss_ctc 20.065145 loss_rnnt 15.899791 lr 0.00066636 rank 7
2022-12-03 15:18:49,420 DEBUG TRAIN Batch 2/0 loss 18.093010 loss_att 19.812119 loss_ctc 19.926245 loss_rnnt 17.504755 lr 0.00066800 rank 2
2022-12-03 15:20:00,401 DEBUG TRAIN Batch 2/100 loss 42.491577 loss_att 64.573196 loss_ctc 56.928062 loss_rnnt 36.150383 lr 0.00067144 rank 6
2022-12-03 15:20:00,402 DEBUG TRAIN Batch 2/100 loss 51.756615 loss_att 72.617844 loss_ctc 74.120018 loss_rnnt 44.602577 lr 0.00067196 rank 1
2022-12-03 15:20:00,402 DEBUG TRAIN Batch 2/100 loss 24.468935 loss_att 42.173134 loss_ctc 35.424503 loss_rnnt 19.467354 lr 0.00067040 rank 5
2022-12-03 15:20:00,402 DEBUG TRAIN Batch 2/100 loss 74.223701 loss_att 93.288635 loss_ctc 101.566254 loss_rnnt 66.765045 lr 0.00067128 rank 0
2022-12-03 15:20:00,406 DEBUG TRAIN Batch 2/100 loss 62.730537 loss_att 96.314438 loss_ctc 86.769775 loss_rnnt 52.808525 lr 0.00067148 rank 3
2022-12-03 15:20:00,409 DEBUG TRAIN Batch 2/100 loss 47.803757 loss_att 59.989017 loss_ctc 62.568401 loss_rnnt 43.398087 lr 0.00067200 rank 2
2022-12-03 15:20:00,409 DEBUG TRAIN Batch 2/100 loss 54.174286 loss_att 73.670410 loss_ctc 80.834976 loss_rnnt 46.720303 lr 0.00067036 rank 7
2022-12-03 15:20:00,410 DEBUG TRAIN Batch 2/100 loss 39.569698 loss_att 62.794106 loss_ctc 61.724579 loss_rnnt 31.970831 lr 0.00067036 rank 4
2022-12-03 15:21:12,048 DEBUG TRAIN Batch 2/200 loss 47.686596 loss_att 67.960304 loss_ctc 67.679947 loss_rnnt 40.966076 lr 0.00067544 rank 6
2022-12-03 15:21:12,048 DEBUG TRAIN Batch 2/200 loss 42.159218 loss_att 59.808365 loss_ctc 66.300171 loss_rnnt 35.410595 lr 0.00067440 rank 5
2022-12-03 15:21:12,055 DEBUG TRAIN Batch 2/200 loss 53.609695 loss_att 78.291840 loss_ctc 74.953384 loss_rnnt 45.827446 lr 0.00067436 rank 7
2022-12-03 15:21:12,056 DEBUG TRAIN Batch 2/200 loss 38.783806 loss_att 52.898914 loss_ctc 55.387955 loss_rnnt 33.746895 lr 0.00067596 rank 1
2022-12-03 15:21:12,057 DEBUG TRAIN Batch 2/200 loss 93.932648 loss_att 120.505035 loss_ctc 129.098877 loss_rnnt 83.929344 lr 0.00067436 rank 4
2022-12-03 15:21:12,058 DEBUG TRAIN Batch 2/200 loss 43.577736 loss_att 67.765556 loss_ctc 59.312218 loss_rnnt 36.642242 lr 0.00067600 rank 2
2022-12-03 15:21:12,060 DEBUG TRAIN Batch 2/200 loss 52.936768 loss_att 77.495399 loss_ctc 70.629120 loss_rnnt 45.666061 lr 0.00067548 rank 3
2022-12-03 15:21:12,061 DEBUG TRAIN Batch 2/200 loss 59.016853 loss_att 85.903458 loss_ctc 79.298248 loss_rnnt 50.935345 lr 0.00067528 rank 0
2022-12-03 15:22:24,080 DEBUG TRAIN Batch 2/300 loss 29.129618 loss_att 49.286781 loss_ctc 45.095612 loss_rnnt 22.969387 lr 0.00067944 rank 6
2022-12-03 15:22:24,079 DEBUG TRAIN Batch 2/300 loss 21.735497 loss_att 33.141804 loss_ctc 31.449867 loss_rnnt 18.158985 lr 0.00067836 rank 4
2022-12-03 15:22:24,081 DEBUG TRAIN Batch 2/300 loss 40.780594 loss_att 59.702492 loss_ctc 51.903725 loss_rnnt 35.513130 lr 0.00068000 rank 2
2022-12-03 15:22:24,084 DEBUG TRAIN Batch 2/300 loss 57.591232 loss_att 78.220551 loss_ctc 76.078430 loss_rnnt 51.000412 lr 0.00067836 rank 7
2022-12-03 15:22:24,087 DEBUG TRAIN Batch 2/300 loss 46.688206 loss_att 59.246624 loss_ctc 59.864487 loss_rnnt 42.419682 lr 0.00067840 rank 5
2022-12-03 15:22:24,089 DEBUG TRAIN Batch 2/300 loss 31.618484 loss_att 51.705109 loss_ctc 51.872864 loss_rnnt 24.900576 lr 0.00067928 rank 0
2022-12-03 15:22:24,096 DEBUG TRAIN Batch 2/300 loss 29.117247 loss_att 52.479816 loss_ctc 46.481091 loss_rnnt 22.129551 lr 0.00067996 rank 1
2022-12-03 15:22:24,107 DEBUG TRAIN Batch 2/300 loss 50.713558 loss_att 74.281784 loss_ctc 71.399261 loss_rnnt 43.241817 lr 0.00067948 rank 3
2022-12-03 15:23:36,779 DEBUG TRAIN Batch 2/400 loss 66.762482 loss_att 82.747093 loss_ctc 88.262558 loss_rnnt 60.698883 lr 0.00068396 rank 1
2022-12-03 15:23:36,781 DEBUG TRAIN Batch 2/400 loss 62.505314 loss_att 80.659958 loss_ctc 77.257912 loss_rnnt 56.907368 lr 0.00068344 rank 6
2022-12-03 15:23:36,782 DEBUG TRAIN Batch 2/400 loss 42.034973 loss_att 58.754124 loss_ctc 58.691864 loss_rnnt 36.470222 lr 0.00068328 rank 0
2022-12-03 15:23:36,784 DEBUG TRAIN Batch 2/400 loss 34.797363 loss_att 45.999748 loss_ctc 52.826134 loss_rnnt 30.153048 lr 0.00068240 rank 5
2022-12-03 15:23:36,786 DEBUG TRAIN Batch 2/400 loss 56.851624 loss_att 71.915756 loss_ctc 80.102386 loss_rnnt 50.738693 lr 0.00068400 rank 2
2022-12-03 15:23:36,787 DEBUG TRAIN Batch 2/400 loss 60.887280 loss_att 77.394791 loss_ctc 82.084900 loss_rnnt 54.759430 lr 0.00068348 rank 3
2022-12-03 15:23:36,791 DEBUG TRAIN Batch 2/400 loss 23.627619 loss_att 40.708275 loss_ctc 35.385475 loss_rnnt 18.643772 lr 0.00068236 rank 7
2022-12-03 15:23:36,791 DEBUG TRAIN Batch 2/400 loss 81.920372 loss_att 98.250481 loss_ctc 112.156891 loss_rnnt 74.622810 lr 0.00068236 rank 4
2022-12-03 15:24:47,957 DEBUG TRAIN Batch 2/500 loss 49.129829 loss_att 59.798771 loss_ctc 64.448669 loss_rnnt 44.953533 lr 0.00068800 rank 2
2022-12-03 15:24:47,958 DEBUG TRAIN Batch 2/500 loss 33.989342 loss_att 45.175354 loss_ctc 49.626190 loss_rnnt 29.667227 lr 0.00068728 rank 0
2022-12-03 15:24:47,959 DEBUG TRAIN Batch 2/500 loss 50.932446 loss_att 77.272842 loss_ctc 75.026512 loss_rnnt 42.451824 lr 0.00068748 rank 3
2022-12-03 15:24:47,964 DEBUG TRAIN Batch 2/500 loss 69.167259 loss_att 90.292892 loss_ctc 97.158440 loss_rnnt 61.209969 lr 0.00068744 rank 6
2022-12-03 15:24:47,966 DEBUG TRAIN Batch 2/500 loss 37.172146 loss_att 54.211945 loss_ctc 47.393456 loss_rnnt 32.401344 lr 0.00068796 rank 1
2022-12-03 15:24:47,965 DEBUG TRAIN Batch 2/500 loss 65.175064 loss_att 78.293030 loss_ctc 81.966026 loss_rnnt 60.312672 lr 0.00068640 rank 5
2022-12-03 15:24:47,967 DEBUG TRAIN Batch 2/500 loss 37.292934 loss_att 51.811329 loss_ctc 56.680969 loss_rnnt 31.804184 lr 0.00068636 rank 4
2022-12-03 15:24:48,012 DEBUG TRAIN Batch 2/500 loss 41.351112 loss_att 55.009861 loss_ctc 53.680595 loss_rnnt 36.975430 lr 0.00068636 rank 7
2022-12-03 15:26:00,012 DEBUG TRAIN Batch 2/600 loss 32.302261 loss_att 38.507866 loss_ctc 45.038082 loss_rnnt 29.363031 lr 0.00069200 rank 2
2022-12-03 15:26:00,013 DEBUG TRAIN Batch 2/600 loss 39.815552 loss_att 50.102455 loss_ctc 57.096508 loss_rnnt 35.454041 lr 0.00069144 rank 6
2022-12-03 15:26:00,014 DEBUG TRAIN Batch 2/600 loss 29.644026 loss_att 35.369644 loss_ctc 35.030895 loss_rnnt 27.780653 lr 0.00069196 rank 1
2022-12-03 15:26:00,017 DEBUG TRAIN Batch 2/600 loss 20.693697 loss_att 21.235970 loss_ctc 28.231684 loss_rnnt 19.580177 lr 0.00069128 rank 0
2022-12-03 15:26:00,017 DEBUG TRAIN Batch 2/600 loss 17.577051 loss_att 21.679516 loss_ctc 24.430012 loss_rnnt 15.842829 lr 0.00069040 rank 5
2022-12-03 15:26:00,018 DEBUG TRAIN Batch 2/600 loss 37.529938 loss_att 50.692860 loss_ctc 49.036449 loss_rnnt 33.363155 lr 0.00069148 rank 3
2022-12-03 15:26:00,023 DEBUG TRAIN Batch 2/600 loss 38.437820 loss_att 51.136189 loss_ctc 46.734184 loss_rnnt 34.791965 lr 0.00069036 rank 4
2022-12-03 15:26:00,062 DEBUG TRAIN Batch 2/600 loss 28.521671 loss_att 34.746502 loss_ctc 35.728157 loss_rnnt 26.315842 lr 0.00069036 rank 7
2022-12-03 15:27:14,465 DEBUG TRAIN Batch 2/700 loss 49.580868 loss_att 72.978821 loss_ctc 71.051750 loss_rnnt 42.038494 lr 0.00069528 rank 0
2022-12-03 15:27:14,466 DEBUG TRAIN Batch 2/700 loss 77.852814 loss_att 101.406509 loss_ctc 98.379379 loss_rnnt 70.405197 lr 0.00069544 rank 6
2022-12-03 15:27:14,470 DEBUG TRAIN Batch 2/700 loss 45.375114 loss_att 71.198746 loss_ctc 64.327652 loss_rnnt 37.683380 lr 0.00069548 rank 3
2022-12-03 15:27:14,471 DEBUG TRAIN Batch 2/700 loss 48.467091 loss_att 70.591766 loss_ctc 70.641830 loss_rnnt 41.085526 lr 0.00069596 rank 1
2022-12-03 15:27:14,477 DEBUG TRAIN Batch 2/700 loss 71.890396 loss_att 97.261612 loss_ctc 104.613907 loss_rnnt 62.453011 lr 0.00069436 rank 7
2022-12-03 15:27:14,493 DEBUG TRAIN Batch 2/700 loss 79.720604 loss_att 96.071915 loss_ctc 109.457359 loss_rnnt 72.485443 lr 0.00069436 rank 4
2022-12-03 15:27:14,494 DEBUG TRAIN Batch 2/700 loss 72.745804 loss_att 93.894791 loss_ctc 92.613159 loss_rnnt 65.867020 lr 0.00069440 rank 5
2022-12-03 15:27:14,514 DEBUG TRAIN Batch 2/700 loss 43.517422 loss_att 64.776604 loss_ctc 69.684258 loss_rnnt 35.776672 lr 0.00069600 rank 2
2022-12-03 15:28:26,622 DEBUG TRAIN Batch 2/800 loss 37.240421 loss_att 58.545357 loss_ctc 58.271034 loss_rnnt 30.175354 lr 0.00069948 rank 3
2022-12-03 15:28:26,632 DEBUG TRAIN Batch 2/800 loss 47.083710 loss_att 63.615749 loss_ctc 66.489212 loss_rnnt 41.189903 lr 0.00069944 rank 6
2022-12-03 15:28:26,635 DEBUG TRAIN Batch 2/800 loss 47.419846 loss_att 59.857609 loss_ctc 71.931396 loss_rnnt 41.664089 lr 0.00069928 rank 0
2022-12-03 15:28:26,638 DEBUG TRAIN Batch 2/800 loss 34.163097 loss_att 44.559406 loss_ctc 53.445446 loss_rnnt 29.512854 lr 0.00070000 rank 2
2022-12-03 15:28:26,639 DEBUG TRAIN Batch 2/800 loss 34.034077 loss_att 55.767174 loss_ctc 54.520000 loss_rnnt 26.956001 lr 0.00069996 rank 1
2022-12-03 15:28:26,642 DEBUG TRAIN Batch 2/800 loss 26.564095 loss_att 45.829807 loss_ctc 36.279926 loss_rnnt 21.415508 lr 0.00069840 rank 5
2022-12-03 15:28:26,649 DEBUG TRAIN Batch 2/800 loss 47.917892 loss_att 74.206253 loss_ctc 63.077267 loss_rnnt 40.638969 lr 0.00069836 rank 4
2022-12-03 15:28:26,689 DEBUG TRAIN Batch 2/800 loss 51.887577 loss_att 67.973206 loss_ctc 83.117676 loss_rnnt 44.506439 lr 0.00069836 rank 7
2022-12-03 15:29:37,097 DEBUG TRAIN Batch 2/900 loss 28.903431 loss_att 43.743958 loss_ctc 40.762096 loss_rnnt 24.354170 lr 0.00070328 rank 0
2022-12-03 15:29:37,100 DEBUG TRAIN Batch 2/900 loss 33.168995 loss_att 57.116882 loss_ctc 46.503918 loss_rnnt 26.601425 lr 0.00070344 rank 6
2022-12-03 15:29:37,100 DEBUG TRAIN Batch 2/900 loss 39.942360 loss_att 57.821243 loss_ctc 52.889946 loss_rnnt 34.640236 lr 0.00070240 rank 5
2022-12-03 15:29:37,101 DEBUG TRAIN Batch 2/900 loss 46.879387 loss_att 62.674896 loss_ctc 70.263176 loss_rnnt 40.602448 lr 0.00070348 rank 3
2022-12-03 15:29:37,101 DEBUG TRAIN Batch 2/900 loss 75.855446 loss_att 99.844109 loss_ctc 110.495277 loss_rnnt 66.439072 lr 0.00070236 rank 7
2022-12-03 15:29:37,102 DEBUG TRAIN Batch 2/900 loss 47.299721 loss_att 61.455284 loss_ctc 70.897141 loss_rnnt 41.322289 lr 0.00070400 rank 2
2022-12-03 15:29:37,107 DEBUG TRAIN Batch 2/900 loss 43.392159 loss_att 60.864845 loss_ctc 62.239334 loss_rnnt 37.384663 lr 0.00070236 rank 4
2022-12-03 15:29:37,118 DEBUG TRAIN Batch 2/900 loss 20.019064 loss_att 36.108501 loss_ctc 31.399025 loss_rnnt 15.283848 lr 0.00070396 rank 1
2022-12-03 15:30:49,130 DEBUG TRAIN Batch 2/1000 loss 27.894476 loss_att 43.277267 loss_ctc 41.512363 loss_rnnt 23.002197 lr 0.00070640 rank 5
2022-12-03 15:30:49,139 DEBUG TRAIN Batch 2/1000 loss 46.807037 loss_att 67.749130 loss_ctc 62.302956 loss_rnnt 40.552494 lr 0.00070744 rank 6
2022-12-03 15:30:49,140 DEBUG TRAIN Batch 2/1000 loss 33.194988 loss_att 50.365086 loss_ctc 46.679321 loss_rnnt 27.963057 lr 0.00070748 rank 3
2022-12-03 15:30:49,140 DEBUG TRAIN Batch 2/1000 loss 39.881050 loss_att 59.258980 loss_ctc 60.633026 loss_rnnt 33.238533 lr 0.00070636 rank 7
2022-12-03 15:30:49,143 DEBUG TRAIN Batch 2/1000 loss 35.065304 loss_att 49.690426 loss_ctc 50.279888 loss_rnnt 30.111668 lr 0.00070728 rank 0
2022-12-03 15:30:49,150 DEBUG TRAIN Batch 2/1000 loss 41.079117 loss_att 63.707848 loss_ctc 61.646091 loss_rnnt 33.811108 lr 0.00070796 rank 1
2022-12-03 15:30:49,151 DEBUG TRAIN Batch 2/1000 loss 40.874298 loss_att 58.049049 loss_ctc 62.055191 loss_rnnt 34.615231 lr 0.00070636 rank 4
2022-12-03 15:30:49,154 DEBUG TRAIN Batch 2/1000 loss 49.367832 loss_att 65.098679 loss_ctc 63.037533 loss_rnnt 44.399036 lr 0.00070800 rank 2
2022-12-03 15:32:02,061 DEBUG TRAIN Batch 2/1100 loss 41.674271 loss_att 57.977745 loss_ctc 60.009480 loss_rnnt 35.968880 lr 0.00071148 rank 3
2022-12-03 15:32:02,061 DEBUG TRAIN Batch 2/1100 loss 41.769524 loss_att 59.180565 loss_ctc 61.085083 loss_rnnt 35.711906 lr 0.00071196 rank 1
2022-12-03 15:32:02,062 DEBUG TRAIN Batch 2/1100 loss 59.279766 loss_att 68.262344 loss_ctc 84.265762 loss_rnnt 54.151779 lr 0.00071144 rank 6
2022-12-03 15:32:02,063 DEBUG TRAIN Batch 2/1100 loss 40.652142 loss_att 58.053017 loss_ctc 54.544865 loss_rnnt 35.319603 lr 0.00071200 rank 2
2022-12-03 15:32:02,064 DEBUG TRAIN Batch 2/1100 loss 28.500326 loss_att 41.509743 loss_ctc 39.097980 loss_rnnt 24.485424 lr 0.00071128 rank 0
2022-12-03 15:32:02,066 DEBUG TRAIN Batch 2/1100 loss 27.634594 loss_att 39.889988 loss_ctc 38.817081 loss_rnnt 23.692516 lr 0.00071036 rank 7
2022-12-03 15:32:02,066 DEBUG TRAIN Batch 2/1100 loss 29.345001 loss_att 41.812054 loss_ctc 41.977711 loss_rnnt 25.167229 lr 0.00071040 rank 5
2022-12-03 15:32:02,067 DEBUG TRAIN Batch 2/1100 loss 45.181602 loss_att 56.165676 loss_ctc 60.803894 loss_rnnt 40.901814 lr 0.00071036 rank 4
2022-12-03 15:33:13,743 DEBUG TRAIN Batch 2/1200 loss 44.709446 loss_att 53.478474 loss_ctc 61.284191 loss_rnnt 40.745678 lr 0.00071544 rank 6
2022-12-03 15:33:13,745 DEBUG TRAIN Batch 2/1200 loss 29.921982 loss_att 41.554237 loss_ctc 37.865181 loss_rnnt 26.536438 lr 0.00071548 rank 3
2022-12-03 15:33:13,750 DEBUG TRAIN Batch 2/1200 loss 28.995468 loss_att 37.519783 loss_ctc 41.156693 loss_rnnt 25.669109 lr 0.00071440 rank 5
2022-12-03 15:33:13,750 DEBUG TRAIN Batch 2/1200 loss 52.601765 loss_att 59.881851 loss_ctc 68.846153 loss_rnnt 48.979828 lr 0.00071596 rank 1
2022-12-03 15:33:13,751 DEBUG TRAIN Batch 2/1200 loss 35.051033 loss_att 41.108913 loss_ctc 45.565048 loss_rnnt 32.437588 lr 0.00071436 rank 4
2022-12-03 15:33:13,752 DEBUG TRAIN Batch 2/1200 loss 29.243761 loss_att 36.760757 loss_ctc 44.272846 loss_rnnt 25.736483 lr 0.00071528 rank 0
2022-12-03 15:33:13,752 DEBUG TRAIN Batch 2/1200 loss 38.842289 loss_att 48.961067 loss_ctc 51.851765 loss_rnnt 35.083935 lr 0.00071436 rank 7
2022-12-03 15:33:13,799 DEBUG TRAIN Batch 2/1200 loss 59.692928 loss_att 75.210213 loss_ctc 75.559502 loss_rnnt 54.473927 lr 0.00071600 rank 2
2022-12-03 15:34:25,304 DEBUG TRAIN Batch 2/1300 loss 71.013214 loss_att 82.473236 loss_ctc 102.076134 loss_rnnt 64.579483 lr 0.00071840 rank 5
2022-12-03 15:34:25,306 DEBUG TRAIN Batch 2/1300 loss 67.001404 loss_att 85.645401 loss_ctc 85.615440 loss_rnnt 60.790733 lr 0.00071996 rank 1
2022-12-03 15:34:25,308 DEBUG TRAIN Batch 2/1300 loss 29.348019 loss_att 53.093063 loss_ctc 43.597820 loss_rnnt 22.699036 lr 0.00071944 rank 6
2022-12-03 15:34:25,308 DEBUG TRAIN Batch 2/1300 loss 37.962658 loss_att 60.360748 loss_ctc 54.803555 loss_rnnt 31.237587 lr 0.00071836 rank 7
2022-12-03 15:34:25,309 DEBUG TRAIN Batch 2/1300 loss 63.536980 loss_att 84.487564 loss_ctc 83.906647 loss_rnnt 56.630913 lr 0.00071948 rank 3
2022-12-03 15:34:25,312 DEBUG TRAIN Batch 2/1300 loss 35.179226 loss_att 54.004684 loss_ctc 53.807877 loss_rnnt 28.930313 lr 0.00071928 rank 0
2022-12-03 15:34:25,313 DEBUG TRAIN Batch 2/1300 loss 56.470009 loss_att 74.954025 loss_ctc 76.791534 loss_rnnt 50.063671 lr 0.00072000 rank 2
2022-12-03 15:34:25,360 DEBUG TRAIN Batch 2/1300 loss 54.617599 loss_att 85.460655 loss_ctc 76.456230 loss_rnnt 45.537170 lr 0.00071836 rank 4
2022-12-03 15:35:38,854 DEBUG TRAIN Batch 2/1400 loss 28.255720 loss_att 48.096935 loss_ctc 39.451061 loss_rnnt 22.794765 lr 0.00072396 rank 1
2022-12-03 15:35:38,859 DEBUG TRAIN Batch 2/1400 loss 34.573849 loss_att 50.055283 loss_ctc 48.010315 loss_rnnt 29.686035 lr 0.00072236 rank 7
2022-12-03 15:35:38,868 DEBUG TRAIN Batch 2/1400 loss 27.742044 loss_att 45.719616 loss_ctc 38.121521 loss_rnnt 22.762600 lr 0.00072344 rank 6
2022-12-03 15:35:38,869 DEBUG TRAIN Batch 2/1400 loss 41.423901 loss_att 67.926971 loss_ctc 54.624508 loss_rnnt 34.363205 lr 0.00072328 rank 0
2022-12-03 15:35:38,872 DEBUG TRAIN Batch 2/1400 loss 30.918339 loss_att 49.473446 loss_ctc 45.275803 loss_rnnt 25.292990 lr 0.00072348 rank 3
2022-12-03 15:35:38,881 DEBUG TRAIN Batch 2/1400 loss 25.539951 loss_att 37.783249 loss_ctc 42.441933 loss_rnnt 20.837692 lr 0.00072236 rank 4
2022-12-03 15:35:38,898 DEBUG TRAIN Batch 2/1400 loss 24.175297 loss_att 47.174797 loss_ctc 38.811939 loss_rnnt 17.623844 lr 0.00072400 rank 2
2022-12-03 15:35:38,902 DEBUG TRAIN Batch 2/1400 loss 42.042080 loss_att 57.446243 loss_ctc 68.097282 loss_rnnt 35.487225 lr 0.00072240 rank 5
2022-12-03 15:36:51,047 DEBUG TRAIN Batch 2/1500 loss 43.313889 loss_att 60.805241 loss_ctc 59.218647 loss_rnnt 37.694988 lr 0.00072640 rank 5
2022-12-03 15:36:51,064 DEBUG TRAIN Batch 2/1500 loss 30.677418 loss_att 47.361694 loss_ctc 50.441570 loss_rnnt 24.705343 lr 0.00072796 rank 1
2022-12-03 15:36:51,064 DEBUG TRAIN Batch 2/1500 loss 37.810501 loss_att 57.949600 loss_ctc 55.808575 loss_rnnt 31.382940 lr 0.00072744 rank 6
2022-12-03 15:36:51,066 DEBUG TRAIN Batch 2/1500 loss 27.725346 loss_att 38.012695 loss_ctc 40.964695 loss_rnnt 23.902630 lr 0.00072728 rank 0
2022-12-03 15:36:51,068 DEBUG TRAIN Batch 2/1500 loss 44.416374 loss_att 63.478413 loss_ctc 56.536221 loss_rnnt 38.987988 lr 0.00072748 rank 3
2022-12-03 15:36:51,067 DEBUG TRAIN Batch 2/1500 loss 14.841570 loss_att 27.122818 loss_ctc 25.807308 loss_rnnt 10.923222 lr 0.00072636 rank 4
2022-12-03 15:36:51,070 DEBUG TRAIN Batch 2/1500 loss 39.615700 loss_att 61.872719 loss_ctc 49.619743 loss_rnnt 33.830425 lr 0.00072636 rank 7
2022-12-03 15:36:51,112 DEBUG TRAIN Batch 2/1500 loss 40.051582 loss_att 50.053883 loss_ctc 55.839539 loss_rnnt 35.946060 lr 0.00072800 rank 2
2022-12-03 15:38:02,545 DEBUG TRAIN Batch 2/1600 loss 29.750835 loss_att 45.368111 loss_ctc 44.635784 loss_rnnt 24.642721 lr 0.00073144 rank 6
2022-12-03 15:38:02,563 DEBUG TRAIN Batch 2/1600 loss 51.322159 loss_att 68.516891 loss_ctc 71.836334 loss_rnnt 45.147987 lr 0.00073196 rank 1
2022-12-03 15:38:02,563 DEBUG TRAIN Batch 2/1600 loss 65.983223 loss_att 81.220642 loss_ctc 90.116913 loss_rnnt 59.717918 lr 0.00073040 rank 5
2022-12-03 15:38:02,564 DEBUG TRAIN Batch 2/1600 loss 30.875019 loss_att 46.482300 loss_ctc 45.948997 loss_rnnt 25.743698 lr 0.00073128 rank 0
2022-12-03 15:38:02,572 DEBUG TRAIN Batch 2/1600 loss 39.407036 loss_att 60.962788 loss_ctc 59.097980 loss_rnnt 32.470428 lr 0.00073148 rank 3
2022-12-03 15:38:02,575 DEBUG TRAIN Batch 2/1600 loss 37.704338 loss_att 48.387894 loss_ctc 47.944939 loss_rnnt 34.202209 lr 0.00073036 rank 4
2022-12-03 15:38:02,593 DEBUG TRAIN Batch 2/1600 loss 49.032463 loss_att 64.543434 loss_ctc 74.543243 loss_rnnt 42.528831 lr 0.00073200 rank 2
2022-12-03 15:38:02,632 DEBUG TRAIN Batch 2/1600 loss 41.598003 loss_att 57.158920 loss_ctc 54.430538 loss_rnnt 36.774815 lr 0.00073036 rank 7
2022-12-03 15:39:14,452 DEBUG TRAIN Batch 2/1700 loss 26.968933 loss_att 39.206055 loss_ctc 39.942101 loss_rnnt 22.791754 lr 0.00073436 rank 4
2022-12-03 15:39:14,454 DEBUG TRAIN Batch 2/1700 loss 32.482094 loss_att 47.785053 loss_ctc 51.470924 loss_rnnt 26.889660 lr 0.00073544 rank 6
2022-12-03 15:39:14,456 DEBUG TRAIN Batch 2/1700 loss 36.673985 loss_att 52.928223 loss_ctc 54.983257 loss_rnnt 30.981901 lr 0.00073528 rank 0
2022-12-03 15:39:14,459 DEBUG TRAIN Batch 2/1700 loss 52.934021 loss_att 74.921471 loss_ctc 68.213058 loss_rnnt 46.499329 lr 0.00073548 rank 3
2022-12-03 15:39:14,461 DEBUG TRAIN Batch 2/1700 loss 42.007339 loss_att 58.429604 loss_ctc 57.238918 loss_rnnt 36.692013 lr 0.00073596 rank 1
2022-12-03 15:39:14,463 DEBUG TRAIN Batch 2/1700 loss 26.259123 loss_att 45.130943 loss_ctc 40.578552 loss_rnnt 20.575500 lr 0.00073600 rank 2
2022-12-03 15:39:14,463 DEBUG TRAIN Batch 2/1700 loss 53.503284 loss_att 63.919098 loss_ctc 71.543510 loss_rnnt 49.014763 lr 0.00073436 rank 7
2022-12-03 15:39:14,481 DEBUG TRAIN Batch 2/1700 loss 42.466240 loss_att 51.671967 loss_ctc 51.913567 loss_rnnt 39.365452 lr 0.00073440 rank 5
2022-12-03 15:40:28,158 DEBUG TRAIN Batch 2/1800 loss 37.157928 loss_att 50.357841 loss_ctc 56.264359 loss_rnnt 31.970421 lr 0.00073948 rank 3
2022-12-03 15:40:28,161 DEBUG TRAIN Batch 2/1800 loss 51.502354 loss_att 64.208595 loss_ctc 82.027641 loss_rnnt 44.891060 lr 0.00073836 rank 7
2022-12-03 15:40:28,162 DEBUG TRAIN Batch 2/1800 loss 47.438213 loss_att 58.391525 loss_ctc 66.041832 loss_rnnt 42.767071 lr 0.00073928 rank 0
2022-12-03 15:40:28,165 DEBUG TRAIN Batch 2/1800 loss 53.641144 loss_att 59.342285 loss_ctc 71.334389 loss_rnnt 50.141815 lr 0.00073840 rank 5
2022-12-03 15:40:28,164 DEBUG TRAIN Batch 2/1800 loss 38.873390 loss_att 48.760696 loss_ctc 55.222836 loss_rnnt 34.716003 lr 0.00073944 rank 6
2022-12-03 15:40:28,165 DEBUG TRAIN Batch 2/1800 loss 28.112663 loss_att 36.834148 loss_ctc 35.705444 loss_rnnt 25.355993 lr 0.00074000 rank 2
2022-12-03 15:40:28,175 DEBUG TRAIN Batch 2/1800 loss 44.784531 loss_att 60.668167 loss_ctc 63.577480 loss_rnnt 39.102077 lr 0.00073836 rank 4
2022-12-03 15:40:28,219 DEBUG TRAIN Batch 2/1800 loss 37.378380 loss_att 53.261173 loss_ctc 50.707844 loss_rnnt 32.424557 lr 0.00073996 rank 1
2022-12-03 15:41:40,171 DEBUG TRAIN Batch 2/1900 loss 14.592539 loss_att 14.994688 loss_ctc 18.082907 loss_rnnt 14.046726 lr 0.00074328 rank 0
2022-12-03 15:41:40,172 DEBUG TRAIN Batch 2/1900 loss 21.975315 loss_att 25.244064 loss_ctc 27.727379 loss_rnnt 20.554623 lr 0.00074348 rank 3
2022-12-03 15:41:40,173 DEBUG TRAIN Batch 2/1900 loss 27.438339 loss_att 33.323673 loss_ctc 31.959738 loss_rnnt 25.658417 lr 0.00074344 rank 6
2022-12-03 15:41:40,174 DEBUG TRAIN Batch 2/1900 loss 44.219360 loss_att 63.718952 loss_ctc 64.058884 loss_rnnt 37.674171 lr 0.00074240 rank 5
2022-12-03 15:41:40,175 DEBUG TRAIN Batch 2/1900 loss 26.181698 loss_att 37.673283 loss_ctc 35.797218 loss_rnnt 22.601315 lr 0.00074236 rank 7
2022-12-03 15:41:40,178 DEBUG TRAIN Batch 2/1900 loss 43.037472 loss_att 66.997368 loss_ctc 55.800934 loss_rnnt 36.543697 lr 0.00074400 rank 2
2022-12-03 15:41:40,179 DEBUG TRAIN Batch 2/1900 loss 24.756590 loss_att 27.840055 loss_ctc 33.594101 loss_rnnt 22.961563 lr 0.00074396 rank 1
2022-12-03 15:41:40,182 DEBUG TRAIN Batch 2/1900 loss 24.703564 loss_att 30.638336 loss_ctc 30.398382 loss_rnnt 22.757299 lr 0.00074236 rank 4
2022-12-03 15:42:51,020 DEBUG TRAIN Batch 2/2000 loss 30.440092 loss_att 44.290016 loss_ctc 45.747982 loss_rnnt 25.629055 lr 0.00074800 rank 2
2022-12-03 15:42:51,020 DEBUG TRAIN Batch 2/2000 loss 51.583508 loss_att 72.419052 loss_ctc 77.078171 loss_rnnt 44.017113 lr 0.00074744 rank 6
2022-12-03 15:42:51,021 DEBUG TRAIN Batch 2/2000 loss 31.377548 loss_att 41.240105 loss_ctc 43.515747 loss_rnnt 27.786612 lr 0.00074796 rank 1
2022-12-03 15:42:51,026 DEBUG TRAIN Batch 2/2000 loss 24.642561 loss_att 37.748180 loss_ctc 38.950985 loss_rnnt 20.113647 lr 0.00074640 rank 5
2022-12-03 15:42:51,027 DEBUG TRAIN Batch 2/2000 loss 31.437172 loss_att 54.572899 loss_ctc 46.807571 loss_rnnt 24.760641 lr 0.00074728 rank 0
2022-12-03 15:42:51,029 DEBUG TRAIN Batch 2/2000 loss 30.046244 loss_att 50.343609 loss_ctc 43.044807 loss_rnnt 24.253628 lr 0.00074748 rank 3
2022-12-03 15:42:51,031 DEBUG TRAIN Batch 2/2000 loss 34.447598 loss_att 47.523792 loss_ctc 49.074871 loss_rnnt 29.882055 lr 0.00074636 rank 7
2022-12-03 15:42:51,041 DEBUG TRAIN Batch 2/2000 loss 56.034393 loss_att 79.585220 loss_ctc 81.774521 loss_rnnt 47.892212 lr 0.00074636 rank 4
2022-12-03 15:44:04,014 DEBUG TRAIN Batch 2/2100 loss 49.701855 loss_att 67.762299 loss_ctc 77.572556 loss_rnnt 42.373672 lr 0.00075144 rank 6
2022-12-03 15:44:04,021 DEBUG TRAIN Batch 2/2100 loss 50.112434 loss_att 61.246643 loss_ctc 73.017822 loss_rnnt 44.831543 lr 0.00075196 rank 1
2022-12-03 15:44:04,031 DEBUG TRAIN Batch 2/2100 loss 65.456070 loss_att 75.520813 loss_ctc 87.598511 loss_rnnt 60.490795 lr 0.00075128 rank 0
2022-12-03 15:44:04,037 DEBUG TRAIN Batch 2/2100 loss 60.689674 loss_att 70.056885 loss_ctc 83.063606 loss_rnnt 55.833038 lr 0.00075036 rank 7
2022-12-03 15:44:04,039 DEBUG TRAIN Batch 2/2100 loss 39.309097 loss_att 56.675659 loss_ctc 66.887169 loss_rnnt 32.158707 lr 0.00075040 rank 5
2022-12-03 15:44:04,039 DEBUG TRAIN Batch 2/2100 loss 43.767445 loss_att 58.008694 loss_ctc 58.837379 loss_rnnt 38.909866 lr 0.00075148 rank 3
2022-12-03 15:44:04,041 DEBUG TRAIN Batch 2/2100 loss 23.869701 loss_att 32.743179 loss_ctc 38.800484 loss_rnnt 20.104237 lr 0.00075036 rank 4
2022-12-03 15:44:04,063 DEBUG TRAIN Batch 2/2100 loss 27.740250 loss_att 37.415661 loss_ctc 45.319107 loss_rnnt 23.461319 lr 0.00075200 rank 2
2022-12-03 15:45:16,680 DEBUG TRAIN Batch 2/2200 loss 49.052494 loss_att 61.547867 loss_ctc 66.544426 loss_rnnt 44.221161 lr 0.00075544 rank 6
2022-12-03 15:45:16,683 DEBUG TRAIN Batch 2/2200 loss 24.789795 loss_att 40.135506 loss_ctc 39.262901 loss_rnnt 19.790905 lr 0.00075528 rank 0
2022-12-03 15:45:16,687 DEBUG TRAIN Batch 2/2200 loss 29.310734 loss_att 40.060829 loss_ctc 35.158897 loss_rnnt 26.380959 lr 0.00075548 rank 3
2022-12-03 15:45:16,688 DEBUG TRAIN Batch 2/2200 loss 53.422096 loss_att 59.172142 loss_ctc 78.420464 loss_rnnt 48.938969 lr 0.00075440 rank 5
2022-12-03 15:45:16,691 DEBUG TRAIN Batch 2/2200 loss 38.506668 loss_att 52.587921 loss_ctc 55.164852 loss_rnnt 33.469326 lr 0.00075600 rank 2
2022-12-03 15:45:16,692 DEBUG TRAIN Batch 2/2200 loss 46.082600 loss_att 60.367920 loss_ctc 69.105431 loss_rnnt 40.155827 lr 0.00075436 rank 7
2022-12-03 15:45:16,693 DEBUG TRAIN Batch 2/2200 loss 37.587727 loss_att 52.682541 loss_ctc 54.413910 loss_rnnt 32.325272 lr 0.00075436 rank 4
2022-12-03 15:45:16,693 DEBUG TRAIN Batch 2/2200 loss 55.461319 loss_att 76.492493 loss_ctc 83.361778 loss_rnnt 47.535027 lr 0.00075596 rank 1
2022-12-03 15:46:27,457 DEBUG TRAIN Batch 2/2300 loss 26.281507 loss_att 33.416222 loss_ctc 40.705345 loss_rnnt 22.931385 lr 0.00075944 rank 6
2022-12-03 15:46:27,462 DEBUG TRAIN Batch 2/2300 loss 28.041689 loss_att 39.839485 loss_ctc 46.992348 loss_rnnt 23.155373 lr 0.00075928 rank 0
2022-12-03 15:46:27,465 DEBUG TRAIN Batch 2/2300 loss 41.249004 loss_att 66.238190 loss_ctc 57.349064 loss_rnnt 34.104492 lr 0.00075840 rank 5
2022-12-03 15:46:27,467 DEBUG TRAIN Batch 2/2300 loss 46.662323 loss_att 65.631218 loss_ctc 72.672653 loss_rnnt 39.400501 lr 0.00075836 rank 7
2022-12-03 15:46:27,468 DEBUG TRAIN Batch 2/2300 loss 40.523247 loss_att 56.228371 loss_ctc 57.690132 loss_rnnt 35.093304 lr 0.00075996 rank 1
2022-12-03 15:46:27,470 DEBUG TRAIN Batch 2/2300 loss 31.563135 loss_att 44.382027 loss_ctc 43.082272 loss_rnnt 27.463470 lr 0.00075948 rank 3
2022-12-03 15:46:27,472 DEBUG TRAIN Batch 2/2300 loss 50.926105 loss_att 62.390800 loss_ctc 70.395058 loss_rnnt 46.037308 lr 0.00076000 rank 2
2022-12-03 15:46:27,473 DEBUG TRAIN Batch 2/2300 loss 41.231895 loss_att 59.619560 loss_ctc 59.329102 loss_rnnt 35.141399 lr 0.00075836 rank 4
2022-12-03 15:47:39,518 DEBUG TRAIN Batch 2/2400 loss 30.576714 loss_att 37.597992 loss_ctc 44.249634 loss_rnnt 27.349401 lr 0.00076328 rank 0
2022-12-03 15:47:39,520 DEBUG TRAIN Batch 2/2400 loss 38.701935 loss_att 49.024090 loss_ctc 61.399548 loss_rnnt 33.611153 lr 0.00076240 rank 5
2022-12-03 15:47:39,532 DEBUG TRAIN Batch 2/2400 loss 70.151291 loss_att 87.737244 loss_ctc 92.944397 loss_rnnt 63.595016 lr 0.00076344 rank 6
2022-12-03 15:47:39,534 DEBUG TRAIN Batch 2/2400 loss 33.130447 loss_att 43.643047 loss_ctc 44.626434 loss_rnnt 29.495132 lr 0.00076396 rank 1
2022-12-03 15:47:39,539 DEBUG TRAIN Batch 2/2400 loss 32.725494 loss_att 43.724350 loss_ctc 52.109821 loss_rnnt 27.941145 lr 0.00076348 rank 3
2022-12-03 15:47:39,540 DEBUG TRAIN Batch 2/2400 loss 29.409084 loss_att 38.168213 loss_ctc 48.270657 loss_rnnt 25.142380 lr 0.00076400 rank 2
2022-12-03 15:47:39,542 DEBUG TRAIN Batch 2/2400 loss 41.503048 loss_att 57.649887 loss_ctc 54.812767 loss_rnnt 36.499050 lr 0.00076236 rank 7
2022-12-03 15:47:39,542 DEBUG TRAIN Batch 2/2400 loss 25.146660 loss_att 35.949524 loss_ctc 38.194275 loss_rnnt 21.246403 lr 0.00076236 rank 4
2022-12-03 15:48:53,876 DEBUG TRAIN Batch 2/2500 loss 33.256599 loss_att 42.427887 loss_ctc 45.541405 loss_rnnt 29.784369 lr 0.00076728 rank 0
2022-12-03 15:48:53,878 DEBUG TRAIN Batch 2/2500 loss 23.570034 loss_att 31.168056 loss_ctc 32.154003 loss_rnnt 20.905899 lr 0.00076744 rank 6
2022-12-03 15:48:53,880 DEBUG TRAIN Batch 2/2500 loss 29.074953 loss_att 34.049400 loss_ctc 45.002644 loss_rnnt 25.956369 lr 0.00076640 rank 5
2022-12-03 15:48:53,880 DEBUG TRAIN Batch 2/2500 loss 15.108590 loss_att 18.990978 loss_ctc 22.356525 loss_rnnt 13.365721 lr 0.00076800 rank 2
2022-12-03 15:48:53,882 DEBUG TRAIN Batch 2/2500 loss 28.298342 loss_att 38.282166 loss_ctc 39.458221 loss_rnnt 24.813595 lr 0.00076636 rank 7
2022-12-03 15:48:53,883 DEBUG TRAIN Batch 2/2500 loss 32.377644 loss_att 48.336704 loss_ctc 40.964954 loss_rnnt 28.040854 lr 0.00076796 rank 1
2022-12-03 15:48:53,886 DEBUG TRAIN Batch 2/2500 loss 30.872465 loss_att 35.635868 loss_ctc 41.062317 loss_rnnt 28.561138 lr 0.00076748 rank 3
2022-12-03 15:48:53,890 DEBUG TRAIN Batch 2/2500 loss 23.465031 loss_att 33.991539 loss_ctc 35.647526 loss_rnnt 19.735397 lr 0.00076636 rank 4
2022-12-03 15:50:05,948 DEBUG TRAIN Batch 2/2600 loss 29.614079 loss_att 45.355564 loss_ctc 40.333588 loss_rnnt 25.036512 lr 0.00077144 rank 6
2022-12-03 15:50:05,949 DEBUG TRAIN Batch 2/2600 loss 59.751465 loss_att 84.108093 loss_ctc 76.512711 loss_rnnt 52.645302 lr 0.00077128 rank 0
2022-12-03 15:50:05,952 DEBUG TRAIN Batch 2/2600 loss 34.203953 loss_att 50.009628 loss_ctc 53.878674 loss_rnnt 28.419523 lr 0.00077148 rank 3
2022-12-03 15:50:05,952 DEBUG TRAIN Batch 2/2600 loss 47.901176 loss_att 57.876022 loss_ctc 69.918121 loss_rnnt 42.970612 lr 0.00077040 rank 5
2022-12-03 15:50:05,959 DEBUG TRAIN Batch 2/2600 loss 36.294979 loss_att 46.910515 loss_ctc 48.615108 loss_rnnt 32.529186 lr 0.00077036 rank 7
2022-12-03 15:50:05,960 DEBUG TRAIN Batch 2/2600 loss 38.548008 loss_att 52.216721 loss_ctc 51.803490 loss_rnnt 34.046867 lr 0.00077196 rank 1
2022-12-03 15:50:05,962 DEBUG TRAIN Batch 2/2600 loss 41.231461 loss_att 56.811829 loss_ctc 59.697536 loss_rnnt 35.653244 lr 0.00077200 rank 2
2022-12-03 15:50:05,970 DEBUG TRAIN Batch 2/2600 loss 39.378662 loss_att 53.345284 loss_ctc 64.911957 loss_rnnt 33.180897 lr 0.00077036 rank 4
2022-12-03 15:51:17,845 DEBUG TRAIN Batch 2/2700 loss 39.650330 loss_att 49.528290 loss_ctc 62.923702 loss_rnnt 34.571621 lr 0.00077544 rank 6
2022-12-03 15:51:17,848 DEBUG TRAIN Batch 2/2700 loss 36.105782 loss_att 52.277336 loss_ctc 48.969666 loss_rnnt 31.156286 lr 0.00077548 rank 3
2022-12-03 15:51:17,849 DEBUG TRAIN Batch 2/2700 loss 36.434750 loss_att 42.620293 loss_ctc 51.251415 loss_rnnt 33.222084 lr 0.00077436 rank 7
2022-12-03 15:51:17,851 DEBUG TRAIN Batch 2/2700 loss 22.301805 loss_att 34.652695 loss_ctc 35.563641 loss_rnnt 18.063381 lr 0.00077528 rank 0
2022-12-03 15:51:17,852 DEBUG TRAIN Batch 2/2700 loss 44.189983 loss_att 64.618195 loss_ctc 67.489319 loss_rnnt 36.997761 lr 0.00077596 rank 1
2022-12-03 15:51:17,852 DEBUG TRAIN Batch 2/2700 loss 53.887527 loss_att 69.754242 loss_ctc 74.557999 loss_rnnt 47.958122 lr 0.00077600 rank 2
2022-12-03 15:51:17,858 DEBUG TRAIN Batch 2/2700 loss 43.518730 loss_att 57.999428 loss_ctc 60.801525 loss_rnnt 38.318222 lr 0.00077436 rank 4
2022-12-03 15:51:17,893 DEBUG TRAIN Batch 2/2700 loss 35.990005 loss_att 60.175640 loss_ctc 53.851715 loss_rnnt 28.771317 lr 0.00077440 rank 5
2022-12-03 15:52:30,736 DEBUG TRAIN Batch 2/2800 loss 46.670742 loss_att 62.937462 loss_ctc 75.065849 loss_rnnt 39.631382 lr 0.00077928 rank 0
2022-12-03 15:52:30,737 DEBUG TRAIN Batch 2/2800 loss 44.608158 loss_att 57.985958 loss_ctc 59.047279 loss_rnnt 40.007378 lr 0.00077836 rank 7
2022-12-03 15:52:30,738 DEBUG TRAIN Batch 2/2800 loss 29.266171 loss_att 40.279892 loss_ctc 45.633736 loss_rnnt 24.881084 lr 0.00078000 rank 2
2022-12-03 15:52:30,741 DEBUG TRAIN Batch 2/2800 loss 36.198368 loss_att 53.196556 loss_ctc 57.049805 loss_rnnt 30.018539 lr 0.00077944 rank 6
2022-12-03 15:52:30,749 DEBUG TRAIN Batch 2/2800 loss 38.528416 loss_att 52.985325 loss_ctc 56.492924 loss_rnnt 33.241768 lr 0.00077948 rank 3
2022-12-03 15:52:30,753 DEBUG TRAIN Batch 2/2800 loss 22.616777 loss_att 33.627193 loss_ctc 39.133820 loss_rnnt 18.212421 lr 0.00077996 rank 1
2022-12-03 15:52:30,769 DEBUG TRAIN Batch 2/2800 loss 44.064724 loss_att 59.358543 loss_ctc 60.819256 loss_rnnt 38.772022 lr 0.00077840 rank 5
2022-12-03 15:52:30,788 DEBUG TRAIN Batch 2/2800 loss 35.624844 loss_att 46.350517 loss_ctc 45.367149 loss_rnnt 32.180733 lr 0.00077836 rank 4
2022-12-03 15:53:43,134 DEBUG TRAIN Batch 2/2900 loss 45.080448 loss_att 58.230862 loss_ctc 68.633133 loss_rnnt 39.310005 lr 0.00078344 rank 6
2022-12-03 15:53:43,134 DEBUG TRAIN Batch 2/2900 loss 22.845184 loss_att 41.225922 loss_ctc 35.183449 loss_rnnt 17.523933 lr 0.00078240 rank 5
2022-12-03 15:53:43,135 DEBUG TRAIN Batch 2/2900 loss 44.828606 loss_att 56.343826 loss_ctc 59.006386 loss_rnnt 40.635193 lr 0.00078236 rank 7
2022-12-03 15:53:43,140 DEBUG TRAIN Batch 2/2900 loss 38.809334 loss_att 56.707802 loss_ctc 65.080307 loss_rnnt 31.726849 lr 0.00078328 rank 0
2022-12-03 15:53:43,143 DEBUG TRAIN Batch 2/2900 loss 39.224869 loss_att 60.785843 loss_ctc 55.680382 loss_rnnt 32.718605 lr 0.00078348 rank 3
2022-12-03 15:53:43,144 DEBUG TRAIN Batch 2/2900 loss 36.404991 loss_att 54.538010 loss_ctc 51.492825 loss_rnnt 30.766678 lr 0.00078400 rank 2
2022-12-03 15:53:43,144 DEBUG TRAIN Batch 2/2900 loss 47.582790 loss_att 65.553009 loss_ctc 71.688965 loss_rnnt 40.774590 lr 0.00078236 rank 4
2022-12-03 15:53:43,184 DEBUG TRAIN Batch 2/2900 loss 45.060837 loss_att 53.684601 loss_ctc 63.622684 loss_rnnt 40.861168 lr 0.00078396 rank 1
2022-12-03 15:54:53,750 DEBUG TRAIN Batch 2/3000 loss 29.335678 loss_att 46.708786 loss_ctc 43.274685 loss_rnnt 24.002522 lr 0.00078728 rank 0
2022-12-03 15:54:53,756 DEBUG TRAIN Batch 2/3000 loss 20.416843 loss_att 33.667336 loss_ctc 29.516647 loss_rnnt 16.553436 lr 0.00078744 rank 6
2022-12-03 15:54:53,760 DEBUG TRAIN Batch 2/3000 loss 42.888287 loss_att 52.284519 loss_ctc 57.336330 loss_rnnt 39.082634 lr 0.00078748 rank 3
2022-12-03 15:54:53,760 DEBUG TRAIN Batch 2/3000 loss 23.916084 loss_att 34.382687 loss_ctc 31.299820 loss_rnnt 20.838264 lr 0.00078800 rank 2
2022-12-03 15:54:53,767 DEBUG TRAIN Batch 2/3000 loss 39.506454 loss_att 51.243408 loss_ctc 55.497715 loss_rnnt 35.026894 lr 0.00078636 rank 4
2022-12-03 15:54:53,769 DEBUG TRAIN Batch 2/3000 loss 41.454659 loss_att 54.159134 loss_ctc 57.774040 loss_rnnt 36.737846 lr 0.00078636 rank 7
2022-12-03 15:54:53,769 DEBUG TRAIN Batch 2/3000 loss 38.591091 loss_att 45.883186 loss_ctc 63.934231 loss_rnnt 33.753586 lr 0.00078640 rank 5
2022-12-03 15:54:53,769 DEBUG TRAIN Batch 2/3000 loss 26.265528 loss_att 42.434540 loss_ctc 41.910843 loss_rnnt 20.945684 lr 0.00078796 rank 1
2022-12-03 15:56:06,337 DEBUG TRAIN Batch 2/3100 loss 26.388166 loss_att 36.727379 loss_ctc 40.189247 loss_rnnt 22.480179 lr 0.00079036 rank 7
2022-12-03 15:56:06,337 DEBUG TRAIN Batch 2/3100 loss 53.551743 loss_att 64.774025 loss_ctc 69.674561 loss_rnnt 49.157570 lr 0.00079144 rank 6
2022-12-03 15:56:06,341 DEBUG TRAIN Batch 2/3100 loss 30.369915 loss_att 41.899303 loss_ctc 43.867393 loss_rnnt 26.264374 lr 0.00079128 rank 0
2022-12-03 15:56:06,341 DEBUG TRAIN Batch 2/3100 loss 20.423296 loss_att 26.401669 loss_ctc 28.524380 loss_rnnt 18.147476 lr 0.00079148 rank 3
2022-12-03 15:56:06,341 DEBUG TRAIN Batch 2/3100 loss 28.457901 loss_att 36.078903 loss_ctc 38.905392 loss_rnnt 25.540701 lr 0.00079040 rank 5
2022-12-03 15:56:06,368 DEBUG TRAIN Batch 2/3100 loss 25.154329 loss_att 29.059633 loss_ctc 34.395481 loss_rnnt 23.141113 lr 0.00079200 rank 2
2022-12-03 15:56:06,374 DEBUG TRAIN Batch 2/3100 loss 29.515633 loss_att 43.489834 loss_ctc 41.833862 loss_rnnt 25.078362 lr 0.00079036 rank 4
2022-12-03 15:56:06,387 DEBUG TRAIN Batch 2/3100 loss 28.102846 loss_att 35.239510 loss_ctc 39.949429 loss_rnnt 25.095968 lr 0.00079196 rank 1
2022-12-03 15:57:21,163 DEBUG TRAIN Batch 2/3200 loss 54.839619 loss_att 75.519432 loss_ctc 86.920074 loss_rnnt 46.426262 lr 0.00079548 rank 3
2022-12-03 15:57:21,163 DEBUG TRAIN Batch 2/3200 loss 22.455090 loss_att 30.012421 loss_ctc 30.881504 loss_rnnt 19.820101 lr 0.00079544 rank 6
2022-12-03 15:57:21,168 DEBUG TRAIN Batch 2/3200 loss 35.115891 loss_att 56.398994 loss_ctc 53.871502 loss_rnnt 28.358521 lr 0.00079528 rank 0
2022-12-03 15:57:21,171 DEBUG TRAIN Batch 2/3200 loss 49.061100 loss_att 63.671181 loss_ctc 71.350029 loss_rnnt 43.167229 lr 0.00079600 rank 2
2022-12-03 15:57:21,172 DEBUG TRAIN Batch 2/3200 loss 20.788609 loss_att 25.273506 loss_ctc 27.886036 loss_rnnt 18.945305 lr 0.00079596 rank 1
2022-12-03 15:57:21,186 DEBUG TRAIN Batch 2/3200 loss 27.454479 loss_att 43.978367 loss_ctc 38.329742 loss_rnnt 22.699665 lr 0.00079436 rank 7
2022-12-03 15:57:21,203 DEBUG TRAIN Batch 2/3200 loss 19.601290 loss_att 34.564320 loss_ctc 31.758863 loss_rnnt 14.987674 lr 0.00079436 rank 4
2022-12-03 15:57:21,207 DEBUG TRAIN Batch 2/3200 loss 49.799751 loss_att 69.457840 loss_ctc 65.267929 loss_rnnt 43.805706 lr 0.00079440 rank 5
2022-12-03 15:58:32,661 DEBUG TRAIN Batch 2/3300 loss 46.827148 loss_att 61.974087 loss_ctc 71.483612 loss_rnnt 40.510235 lr 0.00079948 rank 3
2022-12-03 15:58:32,662 DEBUG TRAIN Batch 2/3300 loss 46.645527 loss_att 64.981079 loss_ctc 59.217720 loss_rnnt 41.302124 lr 0.00079840 rank 5
2022-12-03 15:58:32,664 DEBUG TRAIN Batch 2/3300 loss 42.460640 loss_att 63.188065 loss_ctc 58.577728 loss_rnnt 36.166210 lr 0.00079944 rank 6
2022-12-03 15:58:32,665 DEBUG TRAIN Batch 2/3300 loss 38.182705 loss_att 55.179672 loss_ctc 59.364727 loss_rnnt 31.959044 lr 0.00079836 rank 7
2022-12-03 15:58:32,666 DEBUG TRAIN Batch 2/3300 loss 70.278755 loss_att 85.734085 loss_ctc 91.161522 loss_rnnt 64.403320 lr 0.00079928 rank 0
2022-12-03 15:58:32,667 DEBUG TRAIN Batch 2/3300 loss 45.627270 loss_att 55.204281 loss_ctc 66.681641 loss_rnnt 40.904617 lr 0.00079996 rank 1
2022-12-03 15:58:32,668 DEBUG TRAIN Batch 2/3300 loss 38.730732 loss_att 54.408104 loss_ctc 56.283249 loss_rnnt 33.254921 lr 0.00079836 rank 4
2022-12-03 15:58:32,677 DEBUG TRAIN Batch 2/3300 loss 36.355282 loss_att 47.870430 loss_ctc 47.930901 loss_rnnt 32.508835 lr 0.00080000 rank 2
2022-12-03 15:59:43,603 DEBUG TRAIN Batch 2/3400 loss 54.063957 loss_att 64.267944 loss_ctc 68.809509 loss_rnnt 50.057083 lr 0.00080240 rank 5
2022-12-03 15:59:43,604 DEBUG TRAIN Batch 2/3400 loss 57.973778 loss_att 81.396164 loss_ctc 84.481590 loss_rnnt 49.754929 lr 0.00080396 rank 1
2022-12-03 15:59:43,606 DEBUG TRAIN Batch 2/3400 loss 43.848209 loss_att 59.935863 loss_ctc 60.521240 loss_rnnt 38.407608 lr 0.00080328 rank 0
2022-12-03 15:59:43,606 DEBUG TRAIN Batch 2/3400 loss 44.338387 loss_att 53.792278 loss_ctc 58.360516 loss_rnnt 40.577995 lr 0.00080344 rank 6
2022-12-03 15:59:43,607 DEBUG TRAIN Batch 2/3400 loss 25.143660 loss_att 39.184799 loss_ctc 43.151115 loss_rnnt 19.934439 lr 0.00080236 rank 7
2022-12-03 15:59:43,610 DEBUG TRAIN Batch 2/3400 loss 48.505058 loss_att 60.192383 loss_ctc 72.703674 loss_rnnt 42.941109 lr 0.00080400 rank 2
2022-12-03 15:59:43,613 DEBUG TRAIN Batch 2/3400 loss 63.319878 loss_att 81.873741 loss_ctc 80.455826 loss_rnnt 57.324310 lr 0.00080348 rank 3
2022-12-03 15:59:43,618 DEBUG TRAIN Batch 2/3400 loss 35.312553 loss_att 53.491745 loss_ctc 60.195873 loss_rnnt 28.358936 lr 0.00080236 rank 4
2022-12-03 16:00:58,207 DEBUG TRAIN Batch 2/3500 loss 53.935936 loss_att 63.733093 loss_ctc 73.588104 loss_rnnt 49.356216 lr 0.00080636 rank 4
2022-12-03 16:00:58,218 DEBUG TRAIN Batch 2/3500 loss 37.080070 loss_att 48.603310 loss_ctc 50.829784 loss_rnnt 32.942127 lr 0.00080728 rank 0
2022-12-03 16:00:58,219 DEBUG TRAIN Batch 2/3500 loss 43.563522 loss_att 51.901978 loss_ctc 65.352333 loss_rnnt 38.990654 lr 0.00080640 rank 5
2022-12-03 16:00:58,221 DEBUG TRAIN Batch 2/3500 loss 40.796940 loss_att 49.986012 loss_ctc 59.513145 loss_rnnt 36.463634 lr 0.00080800 rank 2
2022-12-03 16:00:58,222 DEBUG TRAIN Batch 2/3500 loss 41.030487 loss_att 59.772556 loss_ctc 61.592907 loss_rnnt 34.540413 lr 0.00080744 rank 6
2022-12-03 16:00:58,223 DEBUG TRAIN Batch 2/3500 loss 44.940132 loss_att 63.245949 loss_ctc 61.938313 loss_rnnt 39.012543 lr 0.00080636 rank 7
2022-12-03 16:00:58,229 DEBUG TRAIN Batch 2/3500 loss 33.087585 loss_att 47.545704 loss_ctc 46.631313 loss_rnnt 28.390129 lr 0.00080796 rank 1
2022-12-03 16:00:58,245 DEBUG TRAIN Batch 2/3500 loss 36.666359 loss_att 52.428520 loss_ctc 50.597546 loss_rnnt 31.656435 lr 0.00080748 rank 3
2022-12-03 16:02:11,839 DEBUG TRAIN Batch 2/3600 loss 47.310123 loss_att 56.190994 loss_ctc 65.033340 loss_rnnt 43.170853 lr 0.00081196 rank 1
2022-12-03 16:02:11,841 DEBUG TRAIN Batch 2/3600 loss 46.733341 loss_att 55.213730 loss_ctc 66.487091 loss_rnnt 42.403431 lr 0.00081144 rank 6
2022-12-03 16:02:11,841 DEBUG TRAIN Batch 2/3600 loss 42.533745 loss_att 52.833282 loss_ctc 56.552170 loss_rnnt 38.604713 lr 0.00081128 rank 0
2022-12-03 16:02:11,841 DEBUG TRAIN Batch 2/3600 loss 31.198534 loss_att 41.436806 loss_ctc 46.245049 loss_rnnt 27.144678 lr 0.00081200 rank 2
2022-12-03 16:02:11,843 DEBUG TRAIN Batch 2/3600 loss 41.478104 loss_att 48.604004 loss_ctc 60.825821 loss_rnnt 37.473228 lr 0.00081040 rank 5
2022-12-03 16:02:11,853 DEBUG TRAIN Batch 2/3600 loss 43.406097 loss_att 59.692802 loss_ctc 66.345306 loss_rnnt 37.090199 lr 0.00081148 rank 3
2022-12-03 16:02:11,854 DEBUG TRAIN Batch 2/3600 loss 44.024948 loss_att 61.563866 loss_ctc 68.698135 loss_rnnt 37.227406 lr 0.00081036 rank 7
2022-12-03 16:02:11,857 DEBUG TRAIN Batch 2/3600 loss 38.372215 loss_att 59.461655 loss_ctc 59.068863 loss_rnnt 31.394775 lr 0.00081036 rank 4
2022-12-03 16:03:23,972 DEBUG TRAIN Batch 2/3700 loss 47.277725 loss_att 55.208134 loss_ctc 68.654678 loss_rnnt 42.841385 lr 0.00081596 rank 1
2022-12-03 16:03:23,972 DEBUG TRAIN Batch 2/3700 loss 28.884026 loss_att 41.872635 loss_ctc 44.094543 loss_rnnt 24.258236 lr 0.00081544 rank 6
2022-12-03 16:03:23,974 DEBUG TRAIN Batch 2/3700 loss 39.976471 loss_att 47.666702 loss_ctc 60.775917 loss_rnnt 35.665165 lr 0.00081600 rank 2
2022-12-03 16:03:23,975 DEBUG TRAIN Batch 2/3700 loss 38.048649 loss_att 49.691692 loss_ctc 57.120846 loss_rnnt 33.177078 lr 0.00081528 rank 0
2022-12-03 16:03:23,976 DEBUG TRAIN Batch 2/3700 loss 48.444878 loss_att 59.476051 loss_ctc 70.697060 loss_rnnt 43.271683 lr 0.00081440 rank 5
2022-12-03 16:03:23,976 DEBUG TRAIN Batch 2/3700 loss 25.259924 loss_att 36.506256 loss_ctc 38.148201 loss_rnnt 21.292221 lr 0.00081436 rank 7
2022-12-03 16:03:23,981 DEBUG TRAIN Batch 2/3700 loss 33.622040 loss_att 41.256363 loss_ctc 46.394238 loss_rnnt 30.392218 lr 0.00081548 rank 3
2022-12-03 16:03:23,984 DEBUG TRAIN Batch 2/3700 loss 34.450813 loss_att 43.708466 loss_ctc 49.619850 loss_rnnt 30.576744 lr 0.00081436 rank 4
2022-12-03 16:04:35,948 DEBUG TRAIN Batch 2/3800 loss 30.977512 loss_att 33.726048 loss_ctc 40.284740 loss_rnnt 29.186838 lr 0.00081944 rank 6
2022-12-03 16:04:35,952 DEBUG TRAIN Batch 2/3800 loss 37.354366 loss_att 55.629391 loss_ctc 56.275078 loss_rnnt 31.176598 lr 0.00082000 rank 2
2022-12-03 16:04:35,952 DEBUG TRAIN Batch 2/3800 loss 69.628548 loss_att 84.704483 loss_ctc 84.410637 loss_rnnt 64.642418 lr 0.00081928 rank 0
2022-12-03 16:04:35,953 DEBUG TRAIN Batch 2/3800 loss 28.777515 loss_att 34.501465 loss_ctc 36.157681 loss_rnnt 26.648701 lr 0.00081836 rank 7
2022-12-03 16:04:35,954 DEBUG TRAIN Batch 2/3800 loss 14.015923 loss_att 14.283749 loss_ctc 18.882299 loss_rnnt 13.313507 lr 0.00081948 rank 3
2022-12-03 16:04:35,954 DEBUG TRAIN Batch 2/3800 loss 21.547697 loss_att 23.719122 loss_ctc 28.780571 loss_rnnt 20.149027 lr 0.00081840 rank 5
2022-12-03 16:04:35,987 DEBUG TRAIN Batch 2/3800 loss 28.974327 loss_att 32.044704 loss_ctc 41.498081 loss_rnnt 26.690416 lr 0.00081996 rank 1
2022-12-03 16:04:35,992 DEBUG TRAIN Batch 2/3800 loss 19.646400 loss_att 24.793037 loss_ctc 30.269531 loss_rnnt 17.200655 lr 0.00081836 rank 4
2022-12-03 16:05:49,588 DEBUG TRAIN Batch 2/3900 loss 74.408295 loss_att 93.681526 loss_ctc 108.675522 loss_rnnt 65.984680 lr 0.00082328 rank 0
2022-12-03 16:05:49,588 DEBUG TRAIN Batch 2/3900 loss 29.892916 loss_att 43.446274 loss_ctc 48.135921 loss_rnnt 24.749844 lr 0.00082236 rank 7
2022-12-03 16:05:49,589 DEBUG TRAIN Batch 2/3900 loss 35.098854 loss_att 47.867134 loss_ctc 53.046349 loss_rnnt 30.152199 lr 0.00082348 rank 3
2022-12-03 16:05:49,589 DEBUG TRAIN Batch 2/3900 loss 43.013817 loss_att 60.705742 loss_ctc 65.043045 loss_rnnt 36.538200 lr 0.00082400 rank 2
2022-12-03 16:05:49,596 DEBUG TRAIN Batch 2/3900 loss 36.909245 loss_att 63.140629 loss_ctc 53.552410 loss_rnnt 29.443878 lr 0.00082344 rank 6
2022-12-03 16:05:49,602 DEBUG TRAIN Batch 2/3900 loss 48.827377 loss_att 68.197220 loss_ctc 67.161453 loss_rnnt 42.508865 lr 0.00082240 rank 5
2022-12-03 16:05:49,607 DEBUG TRAIN Batch 2/3900 loss 24.327122 loss_att 39.702816 loss_ctc 31.917686 loss_rnnt 20.239908 lr 0.00082236 rank 4
2022-12-03 16:05:49,619 DEBUG TRAIN Batch 2/3900 loss 53.853138 loss_att 67.369568 loss_ctc 88.755127 loss_rnnt 46.496254 lr 0.00082396 rank 1
2022-12-03 16:07:01,842 DEBUG TRAIN Batch 2/4000 loss 58.122124 loss_att 70.186981 loss_ctc 89.907585 loss_rnnt 51.471092 lr 0.00082636 rank 4
2022-12-03 16:07:01,851 DEBUG TRAIN Batch 2/4000 loss 17.372557 loss_att 26.521839 loss_ctc 32.598286 loss_rnnt 13.512603 lr 0.00082640 rank 5
2022-12-03 16:07:01,851 DEBUG TRAIN Batch 2/4000 loss 36.621193 loss_att 41.746735 loss_ctc 51.106171 loss_rnnt 33.664757 lr 0.00082748 rank 3
2022-12-03 16:07:01,853 DEBUG TRAIN Batch 2/4000 loss 39.528267 loss_att 48.426365 loss_ctc 54.629456 loss_rnnt 35.735157 lr 0.00082636 rank 7
2022-12-03 16:07:01,853 DEBUG TRAIN Batch 2/4000 loss 46.060295 loss_att 66.573547 loss_ctc 64.940964 loss_rnnt 39.440228 lr 0.00082744 rank 6
2022-12-03 16:07:01,853 DEBUG TRAIN Batch 2/4000 loss 25.808292 loss_att 34.925770 loss_ctc 43.904736 loss_rnnt 21.571938 lr 0.00082728 rank 0
2022-12-03 16:07:01,856 DEBUG TRAIN Batch 2/4000 loss 25.377878 loss_att 36.780029 loss_ctc 36.986839 loss_rnnt 21.549587 lr 0.00082796 rank 1
2022-12-03 16:07:01,858 DEBUG TRAIN Batch 2/4000 loss 41.058594 loss_att 56.428768 loss_ctc 62.515720 loss_rnnt 35.123604 lr 0.00082800 rank 2
2022-12-03 16:08:13,063 DEBUG TRAIN Batch 2/4100 loss 27.518444 loss_att 40.904175 loss_ctc 41.378651 loss_rnnt 22.993271 lr 0.00083144 rank 6
2022-12-03 16:08:13,066 DEBUG TRAIN Batch 2/4100 loss 39.946415 loss_att 51.731709 loss_ctc 63.051018 loss_rnnt 34.508739 lr 0.00083128 rank 0
2022-12-03 16:08:13,067 DEBUG TRAIN Batch 2/4100 loss 34.900520 loss_att 44.701195 loss_ctc 57.677914 loss_rnnt 29.903399 lr 0.00083148 rank 3
2022-12-03 16:08:13,067 DEBUG TRAIN Batch 2/4100 loss 37.957436 loss_att 58.036598 loss_ctc 63.538918 loss_rnnt 30.530743 lr 0.00083196 rank 1
2022-12-03 16:08:13,070 DEBUG TRAIN Batch 2/4100 loss 31.697336 loss_att 46.279202 loss_ctc 53.453629 loss_rnnt 25.880123 lr 0.00083040 rank 5
2022-12-03 16:08:13,072 DEBUG TRAIN Batch 2/4100 loss 41.181110 loss_att 53.155296 loss_ctc 61.953556 loss_rnnt 36.016617 lr 0.00083036 rank 7
2022-12-03 16:08:13,076 DEBUG TRAIN Batch 2/4100 loss 46.791862 loss_att 58.682861 loss_ctc 71.966415 loss_rnnt 41.057056 lr 0.00083036 rank 4
2022-12-03 16:08:13,084 DEBUG TRAIN Batch 2/4100 loss 63.105686 loss_att 81.316925 loss_ctc 92.856934 loss_rnnt 55.496601 lr 0.00083200 rank 2
2022-12-03 16:09:24,873 DEBUG TRAIN Batch 2/4200 loss 42.068741 loss_att 47.945694 loss_ctc 60.305870 loss_rnnt 38.461735 lr 0.00083440 rank 5
2022-12-03 16:09:24,876 DEBUG TRAIN Batch 2/4200 loss 24.364271 loss_att 38.526218 loss_ctc 41.436073 loss_rnnt 19.255642 lr 0.00083436 rank 7
2022-12-03 16:09:24,883 DEBUG TRAIN Batch 2/4200 loss 48.067577 loss_att 59.941700 loss_ctc 60.557739 loss_rnnt 44.027397 lr 0.00083548 rank 3
2022-12-03 16:09:24,884 DEBUG TRAIN Batch 2/4200 loss 40.302025 loss_att 51.484795 loss_ctc 58.466377 loss_rnnt 35.643555 lr 0.00083528 rank 0
2022-12-03 16:09:24,885 DEBUG TRAIN Batch 2/4200 loss 59.560513 loss_att 71.859756 loss_ctc 80.244293 loss_rnnt 54.342823 lr 0.00083544 rank 6
2022-12-03 16:09:24,890 DEBUG TRAIN Batch 2/4200 loss 31.808975 loss_att 41.912254 loss_ctc 50.037685 loss_rnnt 27.357822 lr 0.00083596 rank 1
2022-12-03 16:09:24,893 DEBUG TRAIN Batch 2/4200 loss 56.009895 loss_att 66.157791 loss_ctc 78.859192 loss_rnnt 50.933746 lr 0.00083600 rank 2
2022-12-03 16:09:24,898 DEBUG TRAIN Batch 2/4200 loss 56.958164 loss_att 75.046875 loss_ctc 85.449684 loss_rnnt 49.541557 lr 0.00083436 rank 4
2022-12-03 16:10:38,657 DEBUG TRAIN Batch 2/4300 loss 27.209885 loss_att 41.349087 loss_ctc 42.799934 loss_rnnt 22.303370 lr 0.00083928 rank 0
2022-12-03 16:10:38,657 DEBUG TRAIN Batch 2/4300 loss 32.704506 loss_att 43.940334 loss_ctc 44.331364 loss_rnnt 28.907093 lr 0.00083944 rank 6
2022-12-03 16:10:38,662 DEBUG TRAIN Batch 2/4300 loss 20.682138 loss_att 36.028446 loss_ctc 33.879040 loss_rnnt 15.853289 lr 0.00083996 rank 1
2022-12-03 16:10:38,663 DEBUG TRAIN Batch 2/4300 loss 50.060520 loss_att 59.920826 loss_ctc 73.032837 loss_rnnt 45.025482 lr 0.00083840 rank 5
2022-12-03 16:10:38,669 DEBUG TRAIN Batch 2/4300 loss 25.238480 loss_att 30.347239 loss_ctc 33.406826 loss_rnnt 23.127615 lr 0.00084000 rank 2
2022-12-03 16:10:38,671 DEBUG TRAIN Batch 2/4300 loss 39.087463 loss_att 49.095642 loss_ctc 66.135597 loss_rnnt 33.479412 lr 0.00083836 rank 7
2022-12-03 16:10:38,670 DEBUG TRAIN Batch 2/4300 loss 45.344246 loss_att 53.028358 loss_ctc 62.706593 loss_rnnt 41.492443 lr 0.00083948 rank 3
2022-12-03 16:10:38,717 DEBUG TRAIN Batch 2/4300 loss 32.937664 loss_att 45.292046 loss_ctc 55.563431 loss_rnnt 27.450018 lr 0.00083836 rank 4
2022-12-03 16:11:51,084 DEBUG TRAIN Batch 2/4400 loss 24.467373 loss_att 32.485573 loss_ctc 30.185993 loss_rnnt 22.101254 lr 0.00084396 rank 1
2022-12-03 16:11:51,084 DEBUG TRAIN Batch 2/4400 loss 34.413101 loss_att 39.861759 loss_ctc 46.377457 loss_rnnt 31.728125 lr 0.00084328 rank 0
2022-12-03 16:11:51,085 DEBUG TRAIN Batch 2/4400 loss 28.112961 loss_att 33.780281 loss_ctc 42.871082 loss_rnnt 25.011745 lr 0.00084240 rank 5
2022-12-03 16:11:51,086 DEBUG TRAIN Batch 2/4400 loss 14.277575 loss_att 16.841293 loss_ctc 19.059589 loss_rnnt 13.127229 lr 0.00084400 rank 2
2022-12-03 16:11:51,087 DEBUG TRAIN Batch 2/4400 loss 40.545261 loss_att 48.704994 loss_ctc 57.413055 loss_rnnt 36.664276 lr 0.00084236 rank 7
2022-12-03 16:11:51,090 DEBUG TRAIN Batch 2/4400 loss 19.627613 loss_att 24.865398 loss_ctc 27.437143 loss_rnnt 17.538784 lr 0.00084348 rank 3
2022-12-03 16:11:51,090 DEBUG TRAIN Batch 2/4400 loss 43.621784 loss_att 49.330154 loss_ctc 62.587963 loss_rnnt 39.951286 lr 0.00084344 rank 6
2022-12-03 16:11:51,091 DEBUG TRAIN Batch 2/4400 loss 23.766224 loss_att 30.972767 loss_ctc 33.536018 loss_rnnt 21.022274 lr 0.00084236 rank 4
2022-12-03 16:13:02,792 DEBUG TRAIN Batch 2/4500 loss 42.849770 loss_att 63.799461 loss_ctc 60.985485 loss_rnnt 36.241737 lr 0.00084640 rank 5
2022-12-03 16:13:02,792 DEBUG TRAIN Batch 2/4500 loss 26.691526 loss_att 40.850227 loss_ctc 47.195343 loss_rnnt 21.125944 lr 0.00084728 rank 0
2022-12-03 16:13:02,793 DEBUG TRAIN Batch 2/4500 loss 43.314987 loss_att 53.345375 loss_ctc 62.034019 loss_rnnt 38.813034 lr 0.00084744 rank 6
2022-12-03 16:13:02,793 DEBUG TRAIN Batch 2/4500 loss 40.085434 loss_att 56.749458 loss_ctc 65.640305 loss_rnnt 33.345318 lr 0.00084800 rank 2
2022-12-03 16:13:02,796 DEBUG TRAIN Batch 2/4500 loss 45.735474 loss_att 53.505692 loss_ctc 69.344940 loss_rnnt 41.033497 lr 0.00084796 rank 1
2022-12-03 16:13:02,797 DEBUG TRAIN Batch 2/4500 loss 37.525551 loss_att 47.319336 loss_ctc 49.873016 loss_rnnt 33.920467 lr 0.00084748 rank 3
2022-12-03 16:13:02,798 DEBUG TRAIN Batch 2/4500 loss 48.550175 loss_att 60.677208 loss_ctc 74.368706 loss_rnnt 42.682297 lr 0.00084636 rank 7
2022-12-03 16:13:02,804 DEBUG TRAIN Batch 2/4500 loss 26.794327 loss_att 40.674938 loss_ctc 41.370689 loss_rnnt 22.074688 lr 0.00084636 rank 4
2022-12-03 16:14:16,745 DEBUG TRAIN Batch 2/4600 loss 30.041368 loss_att 45.249210 loss_ctc 49.014050 loss_rnnt 24.470108 lr 0.00085036 rank 7
2022-12-03 16:14:16,752 DEBUG TRAIN Batch 2/4600 loss 43.151810 loss_att 54.911236 loss_ctc 60.920559 loss_rnnt 38.430756 lr 0.00085196 rank 1
2022-12-03 16:14:16,753 DEBUG TRAIN Batch 2/4600 loss 54.737251 loss_att 60.836700 loss_ctc 74.953690 loss_rnnt 50.821835 lr 0.00085144 rank 6
2022-12-03 16:14:16,754 DEBUG TRAIN Batch 2/4600 loss 33.356018 loss_att 44.254761 loss_ctc 47.910046 loss_rnnt 29.235733 lr 0.00085148 rank 3
2022-12-03 16:14:16,755 DEBUG TRAIN Batch 2/4600 loss 35.820969 loss_att 43.655972 loss_ctc 53.137005 loss_rnnt 31.945160 lr 0.00085040 rank 5
2022-12-03 16:14:16,755 DEBUG TRAIN Batch 2/4600 loss 44.269554 loss_att 58.780643 loss_ctc 54.489708 loss_rnnt 40.004650 lr 0.00085128 rank 0
2022-12-03 16:14:16,760 DEBUG TRAIN Batch 2/4600 loss 31.290798 loss_att 38.308372 loss_ctc 40.704361 loss_rnnt 28.632141 lr 0.00085036 rank 4
2022-12-03 16:14:16,783 DEBUG TRAIN Batch 2/4600 loss 37.879192 loss_att 65.028717 loss_ctc 53.967587 loss_rnnt 30.304169 lr 0.00085200 rank 2
2022-12-03 16:15:29,616 DEBUG TRAIN Batch 2/4700 loss 38.226234 loss_att 48.263306 loss_ctc 56.293488 loss_rnnt 33.809856 lr 0.00085544 rank 6
2022-12-03 16:15:29,617 DEBUG TRAIN Batch 2/4700 loss 35.826454 loss_att 45.062809 loss_ctc 57.474823 loss_rnnt 31.092731 lr 0.00085528 rank 0
2022-12-03 16:15:29,622 DEBUG TRAIN Batch 2/4700 loss 31.138985 loss_att 41.859581 loss_ctc 46.262444 loss_rnnt 26.978401 lr 0.00085436 rank 7
2022-12-03 16:15:29,624 DEBUG TRAIN Batch 2/4700 loss 37.511406 loss_att 57.581749 loss_ctc 63.005993 loss_rnnt 30.098057 lr 0.00085596 rank 1
2022-12-03 16:15:29,627 DEBUG TRAIN Batch 2/4700 loss 40.659931 loss_att 50.124222 loss_ctc 55.265591 loss_rnnt 36.819653 lr 0.00085548 rank 3
2022-12-03 16:15:29,633 DEBUG TRAIN Batch 2/4700 loss 31.538315 loss_att 41.398079 loss_ctc 51.637936 loss_rnnt 26.886414 lr 0.00085436 rank 4
2022-12-03 16:15:29,645 DEBUG TRAIN Batch 2/4700 loss 40.896767 loss_att 58.812523 loss_ctc 59.691849 loss_rnnt 34.807610 lr 0.00085600 rank 2
2022-12-03 16:15:29,654 DEBUG TRAIN Batch 2/4700 loss 41.641247 loss_att 52.788246 loss_ctc 70.724915 loss_rnnt 35.534027 lr 0.00085440 rank 5
2022-12-03 16:16:40,624 DEBUG TRAIN Batch 2/4800 loss 59.982117 loss_att 66.967140 loss_ctc 78.584839 loss_rnnt 56.104752 lr 0.00085836 rank 4
2022-12-03 16:16:40,639 DEBUG TRAIN Batch 2/4800 loss 28.290615 loss_att 44.179806 loss_ctc 43.275471 loss_rnnt 23.114794 lr 0.00085928 rank 0
2022-12-03 16:16:40,639 DEBUG TRAIN Batch 2/4800 loss 33.250690 loss_att 41.955795 loss_ctc 52.215492 loss_rnnt 28.981030 lr 0.00085948 rank 3
2022-12-03 16:16:40,640 DEBUG TRAIN Batch 2/4800 loss 33.372314 loss_att 43.981148 loss_ctc 50.026402 loss_rnnt 29.030001 lr 0.00085944 rank 6
2022-12-03 16:16:40,642 DEBUG TRAIN Batch 2/4800 loss 32.351868 loss_att 47.546349 loss_ctc 52.385155 loss_rnnt 26.641867 lr 0.00085996 rank 1
2022-12-03 16:16:40,647 DEBUG TRAIN Batch 2/4800 loss 35.504459 loss_att 46.157776 loss_ctc 57.977936 loss_rnnt 30.377331 lr 0.00085836 rank 7
2022-12-03 16:16:40,648 DEBUG TRAIN Batch 2/4800 loss 36.392086 loss_att 45.431820 loss_ctc 52.060001 loss_rnnt 32.495083 lr 0.00086000 rank 2
2022-12-03 16:16:40,652 DEBUG TRAIN Batch 2/4800 loss 34.821869 loss_att 46.828236 loss_ctc 53.640800 loss_rnnt 29.911404 lr 0.00085840 rank 5
2022-12-03 16:17:52,361 DEBUG TRAIN Batch 2/4900 loss 72.299789 loss_att 85.247894 loss_ctc 97.329109 loss_rnnt 66.372925 lr 0.00086396 rank 1
2022-12-03 16:17:52,372 DEBUG TRAIN Batch 2/4900 loss 32.704960 loss_att 41.411339 loss_ctc 49.887280 loss_rnnt 28.672710 lr 0.00086240 rank 5
2022-12-03 16:17:52,372 DEBUG TRAIN Batch 2/4900 loss 53.308311 loss_att 61.955048 loss_ctc 71.257477 loss_rnnt 49.185738 lr 0.00086344 rank 6
2022-12-03 16:17:52,373 DEBUG TRAIN Batch 2/4900 loss 26.828398 loss_att 34.309666 loss_ctc 37.640053 loss_rnnt 23.890591 lr 0.00086348 rank 3
2022-12-03 16:17:52,376 DEBUG TRAIN Batch 2/4900 loss 31.000254 loss_att 40.037994 loss_ctc 48.125244 loss_rnnt 26.909372 lr 0.00086236 rank 7
2022-12-03 16:17:52,377 DEBUG TRAIN Batch 2/4900 loss 37.244984 loss_att 41.141178 loss_ctc 51.850571 loss_rnnt 34.518333 lr 0.00086328 rank 0
2022-12-03 16:17:52,380 DEBUG TRAIN Batch 2/4900 loss 29.989788 loss_att 38.490654 loss_ctc 47.722855 loss_rnnt 25.925205 lr 0.00086400 rank 2
2022-12-03 16:17:52,391 DEBUG TRAIN Batch 2/4900 loss 32.715504 loss_att 43.385693 loss_ctc 52.840210 loss_rnnt 27.898172 lr 0.00086236 rank 4
2022-12-03 16:19:06,409 DEBUG TRAIN Batch 2/5000 loss 21.149715 loss_att 29.472179 loss_ctc 32.658169 loss_rnnt 17.950764 lr 0.00086744 rank 6
2022-12-03 16:19:06,410 DEBUG TRAIN Batch 2/5000 loss 18.565655 loss_att 24.104153 loss_ctc 24.962368 loss_rnnt 16.605061 lr 0.00086748 rank 3
2022-12-03 16:19:06,412 DEBUG TRAIN Batch 2/5000 loss 33.075989 loss_att 40.832428 loss_ctc 47.582298 loss_rnnt 29.590527 lr 0.00086800 rank 2
2022-12-03 16:19:06,415 DEBUG TRAIN Batch 2/5000 loss 26.387360 loss_att 30.747597 loss_ctc 33.699078 loss_rnnt 24.540417 lr 0.00086640 rank 5
2022-12-03 16:19:06,417 DEBUG TRAIN Batch 2/5000 loss 30.352293 loss_att 39.392250 loss_ctc 39.634445 loss_rnnt 27.306681 lr 0.00086796 rank 1
2022-12-03 16:19:06,416 DEBUG TRAIN Batch 2/5000 loss 35.860855 loss_att 42.981613 loss_ctc 48.885754 loss_rnnt 32.700050 lr 0.00086728 rank 0
2022-12-03 16:19:06,418 DEBUG TRAIN Batch 2/5000 loss 48.357262 loss_att 58.744972 loss_ctc 67.781067 loss_rnnt 43.689877 lr 0.00086636 rank 7
2022-12-03 16:19:06,421 DEBUG TRAIN Batch 2/5000 loss 32.299545 loss_att 45.262283 loss_ctc 44.383888 loss_rnnt 28.095749 lr 0.00086636 rank 4
2022-12-03 16:20:18,325 DEBUG TRAIN Batch 2/5100 loss 21.931734 loss_att 36.380615 loss_ctc 34.820244 loss_rnnt 17.323490 lr 0.00087040 rank 5
2022-12-03 16:20:18,326 DEBUG TRAIN Batch 2/5100 loss 40.740868 loss_att 52.900749 loss_ctc 61.340134 loss_rnnt 35.562325 lr 0.00087144 rank 6
2022-12-03 16:20:18,326 DEBUG TRAIN Batch 2/5100 loss 43.694061 loss_att 50.858139 loss_ctc 54.165375 loss_rnnt 40.865074 lr 0.00087200 rank 2
2022-12-03 16:20:18,327 DEBUG TRAIN Batch 2/5100 loss 48.320255 loss_att 53.678001 loss_ctc 64.281830 loss_rnnt 45.120495 lr 0.00087148 rank 3
2022-12-03 16:20:18,328 DEBUG TRAIN Batch 2/5100 loss 54.096046 loss_att 64.523987 loss_ctc 77.428307 loss_rnnt 48.899487 lr 0.00087128 rank 0
2022-12-03 16:20:18,330 DEBUG TRAIN Batch 2/5100 loss 16.959694 loss_att 18.208012 loss_ctc 23.869207 loss_rnnt 15.788762 lr 0.00087196 rank 1
2022-12-03 16:20:18,340 DEBUG TRAIN Batch 2/5100 loss 34.159512 loss_att 37.887947 loss_ctc 45.048149 loss_rnnt 31.962006 lr 0.00087036 rank 4
2022-12-03 16:20:18,346 DEBUG TRAIN Batch 2/5100 loss 32.676983 loss_att 47.968922 loss_ctc 53.403759 loss_rnnt 26.855026 lr 0.00087036 rank 7
2022-12-03 16:21:29,780 DEBUG TRAIN Batch 2/5200 loss 33.308392 loss_att 50.064892 loss_ctc 49.602287 loss_rnnt 27.784573 lr 0.00087440 rank 5
2022-12-03 16:21:29,785 DEBUG TRAIN Batch 2/5200 loss 42.239883 loss_att 54.812279 loss_ctc 63.059006 loss_rnnt 36.949524 lr 0.00087544 rank 6
2022-12-03 16:21:29,788 DEBUG TRAIN Batch 2/5200 loss 32.992802 loss_att 42.481495 loss_ctc 42.873123 loss_rnnt 29.777691 lr 0.00087548 rank 3
2022-12-03 16:21:29,788 DEBUG TRAIN Batch 2/5200 loss 40.353291 loss_att 51.264118 loss_ctc 61.346191 loss_rnnt 35.372070 lr 0.00087528 rank 0
2022-12-03 16:21:29,791 DEBUG TRAIN Batch 2/5200 loss 40.496559 loss_att 52.181129 loss_ctc 71.489853 loss_rnnt 34.027203 lr 0.00087436 rank 4
2022-12-03 16:21:29,792 DEBUG TRAIN Batch 2/5200 loss 29.070724 loss_att 38.181572 loss_ctc 41.727825 loss_rnnt 25.560942 lr 0.00087600 rank 2
2022-12-03 16:21:29,818 DEBUG TRAIN Batch 2/5200 loss 30.830280 loss_att 37.743576 loss_ctc 43.942898 loss_rnnt 27.699270 lr 0.00087596 rank 1
2022-12-03 16:21:29,859 DEBUG TRAIN Batch 2/5200 loss 40.882839 loss_att 51.626541 loss_ctc 63.719479 loss_rnnt 35.689213 lr 0.00087436 rank 7
2022-12-03 16:22:43,222 DEBUG TRAIN Batch 2/5300 loss 31.802818 loss_att 46.510048 loss_ctc 52.837776 loss_rnnt 26.056713 lr 0.00087944 rank 6
2022-12-03 16:22:43,228 DEBUG TRAIN Batch 2/5300 loss 39.356808 loss_att 50.800549 loss_ctc 52.634182 loss_rnnt 35.297745 lr 0.00088000 rank 2
2022-12-03 16:22:43,228 DEBUG TRAIN Batch 2/5300 loss 33.947350 loss_att 48.002464 loss_ctc 50.208267 loss_rnnt 28.968204 lr 0.00087928 rank 0
2022-12-03 16:22:43,228 DEBUG TRAIN Batch 2/5300 loss 55.549648 loss_att 71.553772 loss_ctc 89.170891 loss_rnnt 47.865990 lr 0.00087948 rank 3
2022-12-03 16:22:43,233 DEBUG TRAIN Batch 2/5300 loss 29.881145 loss_att 49.371548 loss_ctc 45.751175 loss_rnnt 23.867062 lr 0.00087836 rank 7
2022-12-03 16:22:43,233 DEBUG TRAIN Batch 2/5300 loss 22.466135 loss_att 29.962490 loss_ctc 35.139046 loss_rnnt 19.277143 lr 0.00087996 rank 1
2022-12-03 16:22:43,239 DEBUG TRAIN Batch 2/5300 loss 26.176865 loss_att 30.392029 loss_ctc 38.275299 loss_rnnt 23.720707 lr 0.00087836 rank 4
2022-12-03 16:22:43,275 DEBUG TRAIN Batch 2/5300 loss 40.399567 loss_att 50.048931 loss_ctc 65.187149 loss_rnnt 35.164684 lr 0.00087840 rank 5
2022-12-03 16:23:55,692 DEBUG TRAIN Batch 2/5400 loss 28.536379 loss_att 41.476906 loss_ctc 48.063725 loss_rnnt 23.344625 lr 0.00088328 rank 0
2022-12-03 16:23:55,699 DEBUG TRAIN Batch 2/5400 loss 18.658760 loss_att 26.065184 loss_ctc 29.314045 loss_rnnt 15.756773 lr 0.00088236 rank 7
2022-12-03 16:23:55,700 DEBUG TRAIN Batch 2/5400 loss 26.227179 loss_att 35.764435 loss_ctc 35.559261 loss_rnnt 23.075451 lr 0.00088344 rank 6
2022-12-03 16:23:55,700 DEBUG TRAIN Batch 2/5400 loss 40.773018 loss_att 54.899643 loss_ctc 62.291637 loss_rnnt 35.078545 lr 0.00088348 rank 3
2022-12-03 16:23:55,701 DEBUG TRAIN Batch 2/5400 loss 30.674980 loss_att 39.454987 loss_ctc 45.729527 loss_rnnt 26.911705 lr 0.00088240 rank 5
2022-12-03 16:23:55,704 DEBUG TRAIN Batch 2/5400 loss 39.286846 loss_att 50.616623 loss_ctc 58.730366 loss_rnnt 34.428421 lr 0.00088396 rank 1
2022-12-03 16:23:55,706 DEBUG TRAIN Batch 2/5400 loss 25.276905 loss_att 36.841728 loss_ctc 35.467453 loss_rnnt 21.605198 lr 0.00088400 rank 2
2022-12-03 16:23:55,712 DEBUG TRAIN Batch 2/5400 loss 32.316132 loss_att 47.929901 loss_ctc 58.004364 loss_rnnt 25.768280 lr 0.00088236 rank 4
2022-12-03 16:25:07,497 DEBUG TRAIN Batch 2/5500 loss 36.849426 loss_att 45.095467 loss_ctc 52.448616 loss_rnnt 33.120323 lr 0.00088744 rank 6
2022-12-03 16:25:07,498 DEBUG TRAIN Batch 2/5500 loss 21.128784 loss_att 28.944977 loss_ctc 33.019691 loss_rnnt 17.980089 lr 0.00088728 rank 0
2022-12-03 16:25:07,503 DEBUG TRAIN Batch 2/5500 loss 41.645115 loss_att 56.368660 loss_ctc 67.053421 loss_rnnt 35.312634 lr 0.00088640 rank 5
2022-12-03 16:25:07,505 DEBUG TRAIN Batch 2/5500 loss 47.776672 loss_att 60.633835 loss_ctc 65.373734 loss_rnnt 42.858967 lr 0.00088748 rank 3
2022-12-03 16:25:07,506 DEBUG TRAIN Batch 2/5500 loss 23.094006 loss_att 35.406399 loss_ctc 42.107872 loss_rnnt 18.096344 lr 0.00088796 rank 1
2022-12-03 16:25:07,509 DEBUG TRAIN Batch 2/5500 loss 24.859425 loss_att 34.344143 loss_ctc 36.786861 loss_rnnt 21.372158 lr 0.00088636 rank 7
2022-12-03 16:25:07,512 DEBUG TRAIN Batch 2/5500 loss 51.694195 loss_att 63.561340 loss_ctc 72.960205 loss_rnnt 46.485294 lr 0.00088800 rank 2
2022-12-03 16:25:07,513 DEBUG TRAIN Batch 2/5500 loss 68.093956 loss_att 97.677689 loss_ctc 98.460876 loss_rnnt 58.128281 lr 0.00088636 rank 4
2022-12-03 16:26:19,411 DEBUG TRAIN Batch 2/5600 loss 21.329102 loss_att 24.949284 loss_ctc 29.359615 loss_rnnt 19.534330 lr 0.00089144 rank 6
2022-12-03 16:26:19,422 DEBUG TRAIN Batch 2/5600 loss 22.172358 loss_att 27.464405 loss_ctc 35.947151 loss_rnnt 19.277309 lr 0.00089036 rank 4
2022-12-03 16:26:19,430 DEBUG TRAIN Batch 2/5600 loss 26.515560 loss_att 35.767433 loss_ctc 42.578163 loss_rnnt 22.523504 lr 0.00089196 rank 1
2022-12-03 16:26:19,432 DEBUG TRAIN Batch 2/5600 loss 43.698421 loss_att 53.809574 loss_ctc 62.817860 loss_rnnt 39.126934 lr 0.00089148 rank 3
2022-12-03 16:26:19,434 DEBUG TRAIN Batch 2/5600 loss 39.680717 loss_att 46.793137 loss_ctc 56.478584 loss_rnnt 36.018520 lr 0.00089200 rank 2
2022-12-03 16:26:19,434 DEBUG TRAIN Batch 2/5600 loss 30.914112 loss_att 40.660656 loss_ctc 57.090324 loss_rnnt 25.474642 lr 0.00089036 rank 7
2022-12-03 16:26:19,441 DEBUG TRAIN Batch 2/5600 loss 47.149879 loss_att 53.733009 loss_ctc 68.489281 loss_rnnt 42.988003 lr 0.00089128 rank 0
2022-12-03 16:26:19,449 DEBUG TRAIN Batch 2/5600 loss 33.697628 loss_att 42.089149 loss_ctc 50.084419 loss_rnnt 29.834417 lr 0.00089040 rank 5
2022-12-03 16:27:34,017 DEBUG TRAIN Batch 2/5700 loss 30.016556 loss_att 31.808380 loss_ctc 35.580952 loss_rnnt 28.916269 lr 0.00089528 rank 0
2022-12-03 16:27:34,020 DEBUG TRAIN Batch 2/5700 loss 29.290405 loss_att 45.898014 loss_ctc 46.114498 loss_rnnt 23.725670 lr 0.00089436 rank 7
2022-12-03 16:27:34,020 DEBUG TRAIN Batch 2/5700 loss 29.063070 loss_att 38.146587 loss_ctc 47.319664 loss_rnnt 24.812155 lr 0.00089596 rank 1
2022-12-03 16:27:34,022 DEBUG TRAIN Batch 2/5700 loss 32.858997 loss_att 41.931835 loss_ctc 46.326378 loss_rnnt 29.248779 lr 0.00089544 rank 6
2022-12-03 16:27:34,025 DEBUG TRAIN Batch 2/5700 loss 23.701534 loss_att 26.125607 loss_ctc 30.191196 loss_rnnt 22.351433 lr 0.00089548 rank 3
2022-12-03 16:27:34,027 DEBUG TRAIN Batch 2/5700 loss 42.790962 loss_att 54.579212 loss_ctc 69.820534 loss_rnnt 36.829372 lr 0.00089436 rank 4
2022-12-03 16:27:34,043 DEBUG TRAIN Batch 2/5700 loss 40.011459 loss_att 55.816948 loss_ctc 61.368301 loss_rnnt 34.002781 lr 0.00089600 rank 2
2022-12-03 16:27:34,064 DEBUG TRAIN Batch 2/5700 loss 48.805714 loss_att 65.426323 loss_ctc 78.427483 loss_rnnt 41.532024 lr 0.00089440 rank 5
2022-12-03 16:28:46,164 DEBUG TRAIN Batch 2/5800 loss 31.748913 loss_att 40.668118 loss_ctc 43.266602 loss_rnnt 28.429380 lr 0.00089944 rank 6
2022-12-03 16:28:46,170 DEBUG TRAIN Batch 2/5800 loss 42.649910 loss_att 65.076401 loss_ctc 63.729839 loss_rnnt 35.353954 lr 0.00089928 rank 0
2022-12-03 16:28:46,170 DEBUG TRAIN Batch 2/5800 loss 28.798325 loss_att 40.238831 loss_ctc 42.200214 loss_rnnt 24.723303 lr 0.00089948 rank 3
2022-12-03 16:28:46,171 DEBUG TRAIN Batch 2/5800 loss 34.069504 loss_att 41.924789 loss_ctc 51.348877 loss_rnnt 30.194532 lr 0.00089836 rank 7
2022-12-03 16:28:46,175 DEBUG TRAIN Batch 2/5800 loss 37.366707 loss_att 44.679871 loss_ctc 59.944042 loss_rnnt 32.893761 lr 0.00090000 rank 2
2022-12-03 16:28:46,176 DEBUG TRAIN Batch 2/5800 loss 44.803612 loss_att 55.185883 loss_ctc 63.448959 loss_rnnt 40.241116 lr 0.00089840 rank 5
2022-12-03 16:28:46,177 DEBUG TRAIN Batch 2/5800 loss 28.137850 loss_att 42.289108 loss_ctc 42.874203 loss_rnnt 23.342751 lr 0.00089996 rank 1
2022-12-03 16:28:46,180 DEBUG TRAIN Batch 2/5800 loss 26.704081 loss_att 30.259041 loss_ctc 35.083405 loss_rnnt 24.875845 lr 0.00089836 rank 4
2022-12-03 16:29:57,451 DEBUG TRAIN Batch 2/5900 loss 47.915688 loss_att 60.682289 loss_ctc 67.095306 loss_rnnt 42.805084 lr 0.00090240 rank 5
2022-12-03 16:29:57,452 DEBUG TRAIN Batch 2/5900 loss 57.762917 loss_att 74.851776 loss_ctc 74.699547 loss_rnnt 52.086926 lr 0.00090344 rank 6
2022-12-03 16:29:57,453 DEBUG TRAIN Batch 2/5900 loss 32.330959 loss_att 45.404068 loss_ctc 46.118774 loss_rnnt 27.877960 lr 0.00090328 rank 0
2022-12-03 16:29:57,458 DEBUG TRAIN Batch 2/5900 loss 43.116936 loss_att 57.002377 loss_ctc 67.869720 loss_rnnt 37.039474 lr 0.00090396 rank 1
2022-12-03 16:29:57,459 DEBUG TRAIN Batch 2/5900 loss 40.572083 loss_att 58.729492 loss_ctc 58.457497 loss_rnnt 34.555878 lr 0.00090236 rank 7
2022-12-03 16:29:57,461 DEBUG TRAIN Batch 2/5900 loss 24.347813 loss_att 31.974619 loss_ctc 33.784302 loss_rnnt 21.564253 lr 0.00090400 rank 2
2022-12-03 16:29:57,465 DEBUG TRAIN Batch 2/5900 loss 19.724972 loss_att 30.285505 loss_ctc 29.701523 loss_rnnt 16.282658 lr 0.00090348 rank 3
2022-12-03 16:29:57,466 DEBUG TRAIN Batch 2/5900 loss 30.357407 loss_att 36.018745 loss_ctc 47.022903 loss_rnnt 27.003073 lr 0.00090236 rank 4
2022-12-03 16:31:10,299 DEBUG TRAIN Batch 2/6000 loss 35.461449 loss_att 49.126728 loss_ctc 53.384724 loss_rnnt 30.338623 lr 0.00090800 rank 2
2022-12-03 16:31:10,303 DEBUG TRAIN Batch 2/6000 loss 21.969040 loss_att 31.650459 loss_ctc 33.418869 loss_rnnt 18.506111 lr 0.00090744 rank 6
2022-12-03 16:31:10,306 DEBUG TRAIN Batch 2/6000 loss 45.149689 loss_att 56.965008 loss_ctc 65.173683 loss_rnnt 40.116760 lr 0.00090640 rank 5
2022-12-03 16:31:10,310 DEBUG TRAIN Batch 2/6000 loss 45.025024 loss_att 59.562218 loss_ctc 65.883247 loss_rnnt 39.336487 lr 0.00090748 rank 3
2022-12-03 16:31:10,311 DEBUG TRAIN Batch 2/6000 loss 51.437958 loss_att 61.368263 loss_ctc 63.978310 loss_rnnt 47.779850 lr 0.00090728 rank 0
2022-12-03 16:31:10,311 DEBUG TRAIN Batch 2/6000 loss 26.337563 loss_att 34.267227 loss_ctc 39.999180 loss_rnnt 22.930082 lr 0.00090636 rank 7
2022-12-03 16:31:10,319 DEBUG TRAIN Batch 2/6000 loss 51.719212 loss_att 68.835876 loss_ctc 81.834717 loss_rnnt 44.280479 lr 0.00090636 rank 4
2022-12-03 16:31:10,322 DEBUG TRAIN Batch 2/6000 loss 52.698696 loss_att 65.419891 loss_ctc 75.546967 loss_rnnt 47.108025 lr 0.00090796 rank 1
2022-12-03 16:32:23,578 DEBUG TRAIN Batch 2/6100 loss 36.806847 loss_att 42.375744 loss_ctc 45.691399 loss_rnnt 34.508461 lr 0.00091036 rank 7
2022-12-03 16:32:23,599 DEBUG TRAIN Batch 2/6100 loss 38.401905 loss_att 51.245972 loss_ctc 62.953003 loss_rnnt 32.559608 lr 0.00091144 rank 6
2022-12-03 16:32:23,601 DEBUG TRAIN Batch 2/6100 loss 26.627544 loss_att 37.566574 loss_ctc 41.156879 loss_rnnt 22.502491 lr 0.00091128 rank 0
2022-12-03 16:32:23,604 DEBUG TRAIN Batch 2/6100 loss 57.148811 loss_att 66.660469 loss_ctc 81.106918 loss_rnnt 52.052063 lr 0.00091200 rank 2
2022-12-03 16:32:23,604 DEBUG TRAIN Batch 2/6100 loss 55.600285 loss_att 65.054947 loss_ctc 71.180206 loss_rnnt 51.632030 lr 0.00091196 rank 1
2022-12-03 16:32:23,608 DEBUG TRAIN Batch 2/6100 loss 26.846195 loss_att 36.899002 loss_ctc 42.844513 loss_rnnt 22.702526 lr 0.00091148 rank 3
2022-12-03 16:32:23,612 DEBUG TRAIN Batch 2/6100 loss 44.218513 loss_att 57.321404 loss_ctc 69.796867 loss_rnnt 38.187485 lr 0.00091036 rank 4
2022-12-03 16:32:23,666 DEBUG TRAIN Batch 2/6100 loss 31.702694 loss_att 45.343994 loss_ctc 48.763668 loss_rnnt 26.699635 lr 0.00091040 rank 5
2022-12-03 16:33:35,861 DEBUG TRAIN Batch 2/6200 loss 47.091187 loss_att 61.894035 loss_ctc 69.374855 loss_rnnt 41.159458 lr 0.00091548 rank 3
2022-12-03 16:33:35,884 DEBUG TRAIN Batch 2/6200 loss 33.812160 loss_att 41.392044 loss_ctc 50.172897 loss_rnnt 30.114750 lr 0.00091544 rank 6
2022-12-03 16:33:35,885 DEBUG TRAIN Batch 2/6200 loss 21.703955 loss_att 29.056915 loss_ctc 38.693249 loss_rnnt 17.968122 lr 0.00091596 rank 1
2022-12-03 16:33:35,886 DEBUG TRAIN Batch 2/6200 loss 38.943359 loss_att 53.325546 loss_ctc 62.665802 loss_rnnt 32.903931 lr 0.00091528 rank 0
2022-12-03 16:33:35,886 DEBUG TRAIN Batch 2/6200 loss 55.093193 loss_att 68.680061 loss_ctc 73.387787 loss_rnnt 49.936539 lr 0.00091436 rank 4
2022-12-03 16:33:35,887 DEBUG TRAIN Batch 2/6200 loss 33.716358 loss_att 44.112328 loss_ctc 52.083176 loss_rnnt 29.188255 lr 0.00091440 rank 5
2022-12-03 16:33:35,888 DEBUG TRAIN Batch 2/6200 loss 21.661804 loss_att 29.767700 loss_ctc 36.761246 loss_rnnt 18.027367 lr 0.00091436 rank 7
2022-12-03 16:33:35,933 DEBUG TRAIN Batch 2/6200 loss 36.770649 loss_att 42.136055 loss_ctc 51.547619 loss_rnnt 33.727303 lr 0.00091600 rank 2
2022-12-03 16:34:47,908 DEBUG TRAIN Batch 2/6300 loss 28.464361 loss_att 36.114006 loss_ctc 34.457138 loss_rnnt 26.135395 lr 0.00091996 rank 1
2022-12-03 16:34:47,912 DEBUG TRAIN Batch 2/6300 loss 64.552505 loss_att 78.305344 loss_ctc 99.306297 loss_rnnt 57.168098 lr 0.00092000 rank 2
2022-12-03 16:34:47,921 DEBUG TRAIN Batch 2/6300 loss 20.616924 loss_att 25.381996 loss_ctc 32.035107 loss_rnnt 18.141483 lr 0.00091948 rank 3
2022-12-03 16:34:47,925 DEBUG TRAIN Batch 2/6300 loss 36.269623 loss_att 53.361359 loss_ctc 56.007835 loss_rnnt 30.219513 lr 0.00091840 rank 5
2022-12-03 16:34:47,926 DEBUG TRAIN Batch 2/6300 loss 39.519646 loss_att 43.773102 loss_ctc 51.361328 loss_rnnt 37.090065 lr 0.00091928 rank 0
2022-12-03 16:34:47,926 DEBUG TRAIN Batch 2/6300 loss 40.238781 loss_att 50.750889 loss_ctc 61.681923 loss_rnnt 35.277275 lr 0.00091944 rank 6
2022-12-03 16:34:47,929 DEBUG TRAIN Batch 2/6300 loss 26.490662 loss_att 34.700626 loss_ctc 38.826561 loss_rnnt 23.203880 lr 0.00091836 rank 4
2022-12-03 16:34:47,976 DEBUG TRAIN Batch 2/6300 loss 19.873615 loss_att 25.654514 loss_ctc 30.368231 loss_rnnt 17.318153 lr 0.00091836 rank 7
2022-12-03 16:36:02,239 DEBUG TRAIN Batch 2/6400 loss 17.219593 loss_att 18.283741 loss_ctc 20.888062 loss_rnnt 16.517635 lr 0.00092396 rank 1
2022-12-03 16:36:02,239 DEBUG TRAIN Batch 2/6400 loss 32.680187 loss_att 45.841881 loss_ctc 40.314781 loss_rnnt 29.029903 lr 0.00092348 rank 3
2022-12-03 16:36:02,239 DEBUG TRAIN Batch 2/6400 loss 24.392246 loss_att 33.833851 loss_ctc 44.081978 loss_rnnt 19.878626 lr 0.00092400 rank 2
2022-12-03 16:36:02,240 DEBUG TRAIN Batch 2/6400 loss 59.043781 loss_att 71.194580 loss_ctc 79.120407 loss_rnnt 53.936737 lr 0.00092240 rank 5
2022-12-03 16:36:02,248 DEBUG TRAIN Batch 2/6400 loss 24.428991 loss_att 31.360050 loss_ctc 40.348476 loss_rnnt 20.920181 lr 0.00092236 rank 4
2022-12-03 16:36:02,260 DEBUG TRAIN Batch 2/6400 loss 19.725866 loss_att 21.941154 loss_ctc 24.424391 loss_rnnt 18.656338 lr 0.00092344 rank 6
2022-12-03 16:36:02,266 DEBUG TRAIN Batch 2/6400 loss 17.985489 loss_att 19.478569 loss_ctc 23.762451 loss_rnnt 16.916611 lr 0.00092328 rank 0
2022-12-03 16:36:02,303 DEBUG TRAIN Batch 2/6400 loss 35.503117 loss_att 52.756805 loss_ctc 52.152283 loss_rnnt 29.832489 lr 0.00092236 rank 7
2022-12-03 16:37:13,894 DEBUG TRAIN Batch 2/6500 loss 30.526865 loss_att 43.617413 loss_ctc 45.287655 loss_rnnt 25.940647 lr 0.00092636 rank 4
2022-12-03 16:37:13,897 DEBUG TRAIN Batch 2/6500 loss 25.548237 loss_att 33.551018 loss_ctc 39.689983 loss_rnnt 22.062115 lr 0.00092640 rank 5
2022-12-03 16:37:13,900 DEBUG TRAIN Batch 2/6500 loss 21.564262 loss_att 36.036953 loss_ctc 36.825638 loss_rnnt 16.634872 lr 0.00092744 rank 6
2022-12-03 16:37:13,901 DEBUG TRAIN Batch 2/6500 loss 37.001228 loss_att 46.242165 loss_ctc 57.115700 loss_rnnt 32.471111 lr 0.00092728 rank 0
2022-12-03 16:37:13,902 DEBUG TRAIN Batch 2/6500 loss 32.151791 loss_att 39.130188 loss_ctc 47.935253 loss_rnnt 28.651646 lr 0.00092748 rank 3
2022-12-03 16:37:13,903 DEBUG TRAIN Batch 2/6500 loss 48.016499 loss_att 59.074383 loss_ctc 64.470673 loss_rnnt 43.611031 lr 0.00092636 rank 7
2022-12-03 16:37:13,907 DEBUG TRAIN Batch 2/6500 loss 24.717232 loss_att 36.400063 loss_ctc 39.600998 loss_rnnt 20.396164 lr 0.00092800 rank 2
2022-12-03 16:37:13,945 DEBUG TRAIN Batch 2/6500 loss 40.347336 loss_att 56.555401 loss_ctc 60.286095 loss_rnnt 34.447220 lr 0.00092796 rank 1
2022-12-03 16:38:25,414 DEBUG TRAIN Batch 2/6600 loss 22.145927 loss_att 34.884064 loss_ctc 34.825470 loss_rnnt 17.907696 lr 0.00093200 rank 2
2022-12-03 16:38:25,426 DEBUG TRAIN Batch 2/6600 loss 39.023972 loss_att 53.567287 loss_ctc 63.567509 loss_rnnt 32.842834 lr 0.00093040 rank 5
2022-12-03 16:38:25,427 DEBUG TRAIN Batch 2/6600 loss 26.779751 loss_att 36.135273 loss_ctc 38.601017 loss_rnnt 23.332478 lr 0.00093148 rank 3
2022-12-03 16:38:25,427 DEBUG TRAIN Batch 2/6600 loss 28.877110 loss_att 37.570553 loss_ctc 51.526882 loss_rnnt 24.118452 lr 0.00093144 rank 6
2022-12-03 16:38:25,429 DEBUG TRAIN Batch 2/6600 loss 29.520884 loss_att 36.676033 loss_ctc 45.862015 loss_rnnt 25.911037 lr 0.00093128 rank 0
2022-12-03 16:38:25,430 DEBUG TRAIN Batch 2/6600 loss 51.138973 loss_att 63.374046 loss_ctc 72.770699 loss_rnnt 45.807732 lr 0.00093196 rank 1
2022-12-03 16:38:25,431 DEBUG TRAIN Batch 2/6600 loss 24.890413 loss_att 35.540096 loss_ctc 36.267731 loss_rnnt 21.243500 lr 0.00093036 rank 7
2022-12-03 16:38:25,436 DEBUG TRAIN Batch 2/6600 loss 42.855362 loss_att 56.002853 loss_ctc 67.726303 loss_rnnt 36.909740 lr 0.00093036 rank 4
2022-12-03 16:39:37,850 DEBUG TRAIN Batch 2/6700 loss 48.404083 loss_att 59.627899 loss_ctc 66.856308 loss_rnnt 43.699020 lr 0.00093544 rank 6
2022-12-03 16:39:37,857 DEBUG TRAIN Batch 2/6700 loss 34.408012 loss_att 41.341297 loss_ctc 44.676628 loss_rnnt 31.652206 lr 0.00093436 rank 7
2022-12-03 16:39:37,859 DEBUG TRAIN Batch 2/6700 loss 34.146152 loss_att 46.188255 loss_ctc 47.977409 loss_rnnt 29.893566 lr 0.00093528 rank 0
2022-12-03 16:39:37,859 DEBUG TRAIN Batch 2/6700 loss 58.030800 loss_att 67.319962 loss_ctc 77.498596 loss_rnnt 53.577263 lr 0.00093548 rank 3
2022-12-03 16:39:37,859 DEBUG TRAIN Batch 2/6700 loss 32.527538 loss_att 42.365410 loss_ctc 50.027664 loss_rnnt 28.226612 lr 0.00093440 rank 5
2022-12-03 16:39:37,861 DEBUG TRAIN Batch 2/6700 loss 28.749523 loss_att 39.937286 loss_ctc 39.180824 loss_rnnt 25.121130 lr 0.00093596 rank 1
2022-12-03 16:39:37,862 DEBUG TRAIN Batch 2/6700 loss 50.047707 loss_att 61.228340 loss_ctc 78.253166 loss_rnnt 44.050854 lr 0.00093436 rank 4
2022-12-03 16:39:37,870 DEBUG TRAIN Batch 2/6700 loss 32.081367 loss_att 38.763920 loss_ctc 51.771164 loss_rnnt 28.119551 lr 0.00093600 rank 2
2022-12-03 16:40:50,723 DEBUG TRAIN Batch 2/6800 loss 42.690239 loss_att 60.403732 loss_ctc 68.465614 loss_rnnt 35.710819 lr 0.00093944 rank 6
2022-12-03 16:40:50,741 DEBUG TRAIN Batch 2/6800 loss 29.329252 loss_att 38.110619 loss_ctc 45.474800 loss_rnnt 25.420240 lr 0.00094000 rank 2
2022-12-03 16:40:50,742 DEBUG TRAIN Batch 2/6800 loss 32.356937 loss_att 41.032654 loss_ctc 49.006264 loss_rnnt 28.401882 lr 0.00093928 rank 0
2022-12-03 16:40:50,744 DEBUG TRAIN Batch 2/6800 loss 36.327179 loss_att 44.755867 loss_ctc 57.102356 loss_rnnt 31.871416 lr 0.00093840 rank 5
2022-12-03 16:40:50,745 DEBUG TRAIN Batch 2/6800 loss 55.630699 loss_att 63.036137 loss_ctc 72.822891 loss_rnnt 51.857319 lr 0.00093836 rank 4
2022-12-03 16:40:50,746 DEBUG TRAIN Batch 2/6800 loss 18.471428 loss_att 27.874783 loss_ctc 33.714512 loss_rnnt 14.558344 lr 0.00093836 rank 7
2022-12-03 16:40:50,748 DEBUG TRAIN Batch 2/6800 loss 35.593807 loss_att 43.423054 loss_ctc 55.082195 loss_rnnt 31.429504 lr 0.00093948 rank 3
2022-12-03 16:40:50,787 DEBUG TRAIN Batch 2/6800 loss 47.327469 loss_att 55.734558 loss_ctc 65.604889 loss_rnnt 43.209061 lr 0.00093996 rank 1
2022-12-03 16:42:02,415 DEBUG TRAIN Batch 2/6900 loss 38.697010 loss_att 45.266827 loss_ctc 52.997169 loss_rnnt 35.476357 lr 0.00094348 rank 3
2022-12-03 16:42:02,419 DEBUG TRAIN Batch 2/6900 loss 38.639709 loss_att 44.540176 loss_ctc 55.675495 loss_rnnt 35.188175 lr 0.00094328 rank 0
2022-12-03 16:42:02,425 DEBUG TRAIN Batch 2/6900 loss 26.125961 loss_att 35.230392 loss_ctc 35.620773 loss_rnnt 23.039101 lr 0.00094236 rank 4
2022-12-03 16:42:02,426 DEBUG TRAIN Batch 2/6900 loss 26.146658 loss_att 28.258980 loss_ctc 35.859142 loss_rnnt 24.429195 lr 0.00094240 rank 5
2022-12-03 16:42:02,428 DEBUG TRAIN Batch 2/6900 loss 43.951111 loss_att 62.405350 loss_ctc 62.808838 loss_rnnt 37.745903 lr 0.00094400 rank 2
2022-12-03 16:42:02,430 DEBUG TRAIN Batch 2/6900 loss 49.724960 loss_att 54.110256 loss_ctc 69.301064 loss_rnnt 46.237755 lr 0.00094236 rank 7
2022-12-03 16:42:02,446 DEBUG TRAIN Batch 2/6900 loss 43.943634 loss_att 55.586700 loss_ctc 69.713837 loss_rnnt 38.178993 lr 0.00094344 rank 6
2022-12-03 16:42:02,456 DEBUG TRAIN Batch 2/6900 loss 25.845768 loss_att 32.435120 loss_ctc 31.939058 loss_rnnt 23.715458 lr 0.00094396 rank 1
2022-12-03 16:43:13,813 DEBUG TRAIN Batch 2/7000 loss 25.731514 loss_att 30.097458 loss_ctc 39.831139 loss_rnnt 22.978376 lr 0.00094744 rank 6
2022-12-03 16:43:13,818 DEBUG TRAIN Batch 2/7000 loss 28.524998 loss_att 37.134476 loss_ctc 40.506165 loss_rnnt 25.205612 lr 0.00094640 rank 5
2022-12-03 16:43:13,821 DEBUG TRAIN Batch 2/7000 loss 29.409706 loss_att 32.256180 loss_ctc 36.806541 loss_rnnt 27.854168 lr 0.00094728 rank 0
2022-12-03 16:43:13,822 DEBUG TRAIN Batch 2/7000 loss 27.884125 loss_att 38.369503 loss_ctc 42.361946 loss_rnnt 23.856674 lr 0.00094748 rank 3
2022-12-03 16:43:13,826 DEBUG TRAIN Batch 2/7000 loss 31.296579 loss_att 36.746014 loss_ctc 43.844482 loss_rnnt 28.533638 lr 0.00094796 rank 1
2022-12-03 16:43:13,828 DEBUG TRAIN Batch 2/7000 loss 49.192444 loss_att 57.306633 loss_ctc 65.195724 loss_rnnt 45.435829 lr 0.00094800 rank 2
2022-12-03 16:43:13,831 DEBUG TRAIN Batch 2/7000 loss 31.542896 loss_att 39.453979 loss_ctc 44.794907 loss_rnnt 28.193745 lr 0.00094636 rank 4
2022-12-03 16:43:13,867 DEBUG TRAIN Batch 2/7000 loss 27.946381 loss_att 32.448959 loss_ctc 39.018829 loss_rnnt 25.569540 lr 0.00094636 rank 7
2022-12-03 16:44:27,988 DEBUG TRAIN Batch 2/7100 loss 40.656757 loss_att 53.933636 loss_ctc 68.276947 loss_rnnt 34.318691 lr 0.00095036 rank 7
2022-12-03 16:44:27,994 DEBUG TRAIN Batch 2/7100 loss 36.444386 loss_att 51.553543 loss_ctc 54.548515 loss_rnnt 31.008673 lr 0.00095200 rank 2
2022-12-03 16:44:27,998 DEBUG TRAIN Batch 2/7100 loss 19.842426 loss_att 33.564430 loss_ctc 35.229786 loss_rnnt 15.046378 lr 0.00095144 rank 6
2022-12-03 16:44:27,999 DEBUG TRAIN Batch 2/7100 loss 36.748074 loss_att 46.628700 loss_ctc 52.063580 loss_rnnt 32.729881 lr 0.00095128 rank 0
2022-12-03 16:44:28,001 DEBUG TRAIN Batch 2/7100 loss 53.679443 loss_att 72.388428 loss_ctc 73.283745 loss_rnnt 47.323738 lr 0.00095040 rank 5
2022-12-03 16:44:28,003 DEBUG TRAIN Batch 2/7100 loss 29.784317 loss_att 48.849937 loss_ctc 41.585449 loss_rnnt 24.397711 lr 0.00095196 rank 1
2022-12-03 16:44:28,004 DEBUG TRAIN Batch 2/7100 loss 29.427063 loss_att 41.117416 loss_ctc 36.483486 loss_rnnt 26.148136 lr 0.00095148 rank 3
2022-12-03 16:44:28,009 DEBUG TRAIN Batch 2/7100 loss 16.409945 loss_att 19.811539 loss_ctc 24.269951 loss_rnnt 14.681625 lr 0.00095036 rank 4
2022-12-03 16:45:40,371 DEBUG TRAIN Batch 2/7200 loss 56.857185 loss_att 68.034576 loss_ctc 82.348991 loss_rnnt 51.222801 lr 0.00095436 rank 7
2022-12-03 16:45:40,371 DEBUG TRAIN Batch 2/7200 loss 23.750214 loss_att 36.908512 loss_ctc 33.066059 loss_rnnt 19.876442 lr 0.00095544 rank 6
2022-12-03 16:45:40,371 DEBUG TRAIN Batch 2/7200 loss 24.681395 loss_att 32.166389 loss_ctc 41.148560 loss_rnnt 20.988773 lr 0.00095548 rank 3
2022-12-03 16:45:40,373 DEBUG TRAIN Batch 2/7200 loss 29.821207 loss_att 45.019863 loss_ctc 43.444885 loss_rnnt 24.964985 lr 0.00095528 rank 0
2022-12-03 16:45:40,376 DEBUG TRAIN Batch 2/7200 loss 25.707172 loss_att 38.068848 loss_ctc 37.169640 loss_rnnt 21.706509 lr 0.00095600 rank 2
2022-12-03 16:45:40,376 DEBUG TRAIN Batch 2/7200 loss 31.162874 loss_att 47.707008 loss_ctc 53.645947 loss_rnnt 24.856304 lr 0.00095440 rank 5
2022-12-03 16:45:40,376 DEBUG TRAIN Batch 2/7200 loss 37.985653 loss_att 44.044586 loss_ctc 58.985989 loss_rnnt 33.973820 lr 0.00095596 rank 1
2022-12-03 16:45:40,382 DEBUG TRAIN Batch 2/7200 loss 28.132149 loss_att 36.764023 loss_ctc 45.751709 loss_rnnt 24.056501 lr 0.00095436 rank 4
2022-12-03 16:46:52,140 DEBUG TRAIN Batch 2/7300 loss 23.997578 loss_att 31.814440 loss_ctc 35.374359 loss_rnnt 20.917301 lr 0.00095996 rank 1
2022-12-03 16:46:52,155 DEBUG TRAIN Batch 2/7300 loss 57.044357 loss_att 69.819412 loss_ctc 81.539413 loss_rnnt 51.223335 lr 0.00095944 rank 6
2022-12-03 16:46:52,155 DEBUG TRAIN Batch 2/7300 loss 32.146992 loss_att 37.174614 loss_ctc 52.391243 loss_rnnt 28.442232 lr 0.00095840 rank 5
2022-12-03 16:46:52,156 DEBUG TRAIN Batch 2/7300 loss 26.934315 loss_att 40.578220 loss_ctc 44.180851 loss_rnnt 21.905994 lr 0.00095928 rank 0
2022-12-03 16:46:52,158 DEBUG TRAIN Batch 2/7300 loss 17.993952 loss_att 26.496105 loss_ctc 25.114666 loss_rnnt 15.344090 lr 0.00096000 rank 2
2022-12-03 16:46:52,162 DEBUG TRAIN Batch 2/7300 loss 43.760735 loss_att 55.644295 loss_ctc 67.803879 loss_rnnt 38.178268 lr 0.00095948 rank 3
2022-12-03 16:46:52,168 DEBUG TRAIN Batch 2/7300 loss 52.453873 loss_att 69.414658 loss_ctc 84.276627 loss_rnnt 44.818687 lr 0.00095836 rank 4
2022-12-03 16:46:52,212 DEBUG TRAIN Batch 2/7300 loss 47.323097 loss_att 62.173637 loss_ctc 77.628830 loss_rnnt 40.312225 lr 0.00095836 rank 7
2022-12-03 16:48:04,226 DEBUG TRAIN Batch 2/7400 loss 22.200563 loss_att 28.370420 loss_ctc 31.863623 loss_rnnt 19.678185 lr 0.00096240 rank 5
2022-12-03 16:48:04,231 DEBUG TRAIN Batch 2/7400 loss 56.247612 loss_att 67.621696 loss_ctc 77.956581 loss_rnnt 51.078270 lr 0.00096344 rank 6
2022-12-03 16:48:04,241 DEBUG TRAIN Batch 2/7400 loss 28.592712 loss_att 37.373032 loss_ctc 46.081642 loss_rnnt 24.504791 lr 0.00096328 rank 0
2022-12-03 16:48:04,244 DEBUG TRAIN Batch 2/7400 loss 20.957991 loss_att 31.827515 loss_ctc 34.643097 loss_rnnt 16.959404 lr 0.00096236 rank 7
2022-12-03 16:48:04,245 DEBUG TRAIN Batch 2/7400 loss 24.036835 loss_att 32.998779 loss_ctc 39.645279 loss_rnnt 20.163321 lr 0.00096236 rank 4
2022-12-03 16:48:04,246 DEBUG TRAIN Batch 2/7400 loss 26.137405 loss_att 31.844311 loss_ctc 36.387821 loss_rnnt 23.629303 lr 0.00096348 rank 3
2022-12-03 16:48:04,247 DEBUG TRAIN Batch 2/7400 loss 36.083504 loss_att 49.689114 loss_ctc 50.940002 loss_rnnt 31.381516 lr 0.00096400 rank 2
2022-12-03 16:48:04,265 DEBUG TRAIN Batch 2/7400 loss 27.306631 loss_att 40.906891 loss_ctc 44.226345 loss_rnnt 22.330616 lr 0.00096396 rank 1
2022-12-03 16:49:18,337 DEBUG TRAIN Batch 2/7500 loss 35.661541 loss_att 42.856163 loss_ctc 47.481903 loss_rnnt 32.646568 lr 0.00096744 rank 6
2022-12-03 16:49:18,339 DEBUG TRAIN Batch 2/7500 loss 25.793972 loss_att 29.569290 loss_ctc 39.789597 loss_rnnt 23.172823 lr 0.00096640 rank 5
2022-12-03 16:49:18,345 DEBUG TRAIN Batch 2/7500 loss 44.161133 loss_att 56.543133 loss_ctc 67.300888 loss_rnnt 38.599430 lr 0.00096636 rank 4
2022-12-03 16:49:18,346 DEBUG TRAIN Batch 2/7500 loss 23.944574 loss_att 31.100204 loss_ctc 36.140057 loss_rnnt 20.887383 lr 0.00096796 rank 1
2022-12-03 16:49:18,346 DEBUG TRAIN Batch 2/7500 loss 35.593269 loss_att 40.767857 loss_ctc 49.729843 loss_rnnt 32.673477 lr 0.00096728 rank 0
2022-12-03 16:49:18,350 DEBUG TRAIN Batch 2/7500 loss 45.711399 loss_att 51.446716 loss_ctc 65.386353 loss_rnnt 41.941010 lr 0.00096636 rank 7
2022-12-03 16:49:18,352 DEBUG TRAIN Batch 2/7500 loss 32.335541 loss_att 38.106777 loss_ctc 42.776192 loss_rnnt 29.789206 lr 0.00096800 rank 2
2022-12-03 16:49:18,352 DEBUG TRAIN Batch 2/7500 loss 22.814222 loss_att 29.003448 loss_ctc 30.761049 loss_rnnt 20.516800 lr 0.00096748 rank 3
2022-12-03 16:50:31,037 DEBUG TRAIN Batch 2/7600 loss 29.145065 loss_att 37.853233 loss_ctc 45.332527 loss_rnnt 25.245102 lr 0.00097144 rank 6
2022-12-03 16:50:31,039 DEBUG TRAIN Batch 2/7600 loss 19.657421 loss_att 26.731720 loss_ctc 23.379852 loss_rnnt 17.746239 lr 0.00097040 rank 5
2022-12-03 16:50:31,041 DEBUG TRAIN Batch 2/7600 loss 17.332390 loss_att 22.559671 loss_ctc 26.927212 loss_rnnt 15.007625 lr 0.00097128 rank 0
2022-12-03 16:50:31,043 DEBUG TRAIN Batch 2/7600 loss 26.806435 loss_att 29.479614 loss_ctc 40.781307 loss_rnnt 24.408482 lr 0.00097148 rank 3
2022-12-03 16:50:31,045 DEBUG TRAIN Batch 2/7600 loss 27.241230 loss_att 31.840336 loss_ctc 38.769089 loss_rnnt 24.784361 lr 0.00097036 rank 7
2022-12-03 16:50:31,046 DEBUG TRAIN Batch 2/7600 loss 32.484287 loss_att 40.583908 loss_ctc 52.026806 loss_rnnt 28.258694 lr 0.00097200 rank 2
2022-12-03 16:50:31,054 DEBUG TRAIN Batch 2/7600 loss 24.014259 loss_att 36.362701 loss_ctc 40.757221 loss_rnnt 19.312176 lr 0.00097036 rank 4
2022-12-03 16:50:31,097 DEBUG TRAIN Batch 2/7600 loss 48.010254 loss_att 50.470669 loss_ctc 66.776512 loss_rnnt 45.016003 lr 0.00097196 rank 1
2022-12-03 16:51:43,768 DEBUG TRAIN Batch 2/7700 loss 28.453005 loss_att 36.019135 loss_ctc 42.104420 loss_rnnt 25.119591 lr 0.00097528 rank 0
2022-12-03 16:51:43,771 DEBUG TRAIN Batch 2/7700 loss 24.526285 loss_att 37.698219 loss_ctc 33.976997 loss_rnnt 20.631802 lr 0.00097544 rank 6
2022-12-03 16:51:43,773 DEBUG TRAIN Batch 2/7700 loss 41.917416 loss_att 56.758110 loss_ctc 69.139801 loss_rnnt 35.319626 lr 0.00097436 rank 7
2022-12-03 16:51:43,774 DEBUG TRAIN Batch 2/7700 loss 15.998629 loss_att 26.789726 loss_ctc 27.340950 loss_rnnt 12.328098 lr 0.00097548 rank 3
2022-12-03 16:51:43,775 DEBUG TRAIN Batch 2/7700 loss 24.971052 loss_att 36.817024 loss_ctc 34.996071 loss_rnnt 21.265188 lr 0.00097440 rank 5
2022-12-03 16:51:43,779 DEBUG TRAIN Batch 2/7700 loss 33.094604 loss_att 47.518879 loss_ctc 48.880901 loss_rnnt 28.104910 lr 0.00097600 rank 2
2022-12-03 16:51:43,780 DEBUG TRAIN Batch 2/7700 loss 44.431034 loss_att 54.313248 loss_ctc 75.277664 loss_rnnt 38.341705 lr 0.00097596 rank 1
2022-12-03 16:51:43,781 DEBUG TRAIN Batch 2/7700 loss 27.001335 loss_att 34.289413 loss_ctc 39.829952 loss_rnnt 23.833237 lr 0.00097436 rank 4
2022-12-03 16:52:57,540 DEBUG TRAIN Batch 2/7800 loss 13.442211 loss_att 14.890377 loss_ctc 19.300222 loss_rnnt 12.371510 lr 0.00097836 rank 4
2022-12-03 16:52:57,543 DEBUG TRAIN Batch 2/7800 loss 35.385559 loss_att 44.978760 loss_ctc 47.239281 loss_rnnt 31.886425 lr 0.00097944 rank 6
2022-12-03 16:52:57,543 DEBUG TRAIN Batch 2/7800 loss 37.258224 loss_att 50.924583 loss_ctc 52.940090 loss_rnnt 32.434036 lr 0.00097928 rank 0
2022-12-03 16:52:57,544 DEBUG TRAIN Batch 2/7800 loss 49.270653 loss_att 62.796623 loss_ctc 73.089806 loss_rnnt 43.389572 lr 0.00097840 rank 5
2022-12-03 16:52:57,548 DEBUG TRAIN Batch 2/7800 loss 31.825621 loss_att 43.037083 loss_ctc 47.736526 loss_rnnt 27.461874 lr 0.00098000 rank 2
2022-12-03 16:52:57,548 DEBUG TRAIN Batch 2/7800 loss 14.951632 loss_att 26.204201 loss_ctc 24.957916 loss_rnnt 11.366947 lr 0.00097948 rank 3
2022-12-03 16:52:57,554 DEBUG TRAIN Batch 2/7800 loss 30.022861 loss_att 35.777184 loss_ctc 38.623299 loss_rnnt 27.725273 lr 0.00097836 rank 7
2022-12-03 16:52:57,591 DEBUG TRAIN Batch 2/7800 loss 31.809872 loss_att 43.463726 loss_ctc 48.095451 loss_rnnt 27.307690 lr 0.00097996 rank 1
2022-12-03 16:54:09,615 DEBUG TRAIN Batch 2/7900 loss 32.544891 loss_att 42.296581 loss_ctc 43.567745 loss_rnnt 29.124840 lr 0.00098328 rank 0
2022-12-03 16:54:09,617 DEBUG TRAIN Batch 2/7900 loss 34.247288 loss_att 39.741623 loss_ctc 53.627579 loss_rnnt 30.564383 lr 0.00098348 rank 3
2022-12-03 16:54:09,617 DEBUG TRAIN Batch 2/7900 loss 21.651306 loss_att 27.164680 loss_ctc 29.473450 loss_rnnt 19.505676 lr 0.00098396 rank 1
2022-12-03 16:54:09,619 DEBUG TRAIN Batch 2/7900 loss 35.306046 loss_att 50.986496 loss_ctc 54.734650 loss_rnnt 29.579472 lr 0.00098240 rank 5
2022-12-03 16:54:09,621 DEBUG TRAIN Batch 2/7900 loss 32.539665 loss_att 47.198673 loss_ctc 48.507431 loss_rnnt 27.478832 lr 0.00098400 rank 2
2022-12-03 16:54:09,623 DEBUG TRAIN Batch 2/7900 loss 31.771870 loss_att 36.711044 loss_ctc 45.163300 loss_rnnt 28.998508 lr 0.00098344 rank 6
2022-12-03 16:54:09,629 DEBUG TRAIN Batch 2/7900 loss 13.727022 loss_att 22.603199 loss_ctc 25.161064 loss_rnnt 10.427248 lr 0.00098236 rank 7
2022-12-03 16:54:09,673 DEBUG TRAIN Batch 2/7900 loss 58.528709 loss_att 74.359802 loss_ctc 92.139816 loss_rnnt 50.881012 lr 0.00098236 rank 4
2022-12-03 16:55:21,669 DEBUG TRAIN Batch 2/8000 loss 43.191147 loss_att 60.128059 loss_ctc 70.753601 loss_rnnt 36.128769 lr 0.00098796 rank 1
2022-12-03 16:55:21,669 DEBUG TRAIN Batch 2/8000 loss 36.368782 loss_att 47.523720 loss_ctc 54.426640 loss_rnnt 31.730076 lr 0.00098640 rank 5
2022-12-03 16:55:21,672 DEBUG TRAIN Batch 2/8000 loss 28.958658 loss_att 32.907295 loss_ctc 42.424984 loss_rnnt 26.373421 lr 0.00098728 rank 0
2022-12-03 16:55:21,674 DEBUG TRAIN Batch 2/8000 loss 38.791920 loss_att 48.972054 loss_ctc 58.924721 loss_rnnt 34.071518 lr 0.00098744 rank 6
2022-12-03 16:55:21,675 DEBUG TRAIN Batch 2/8000 loss 33.056244 loss_att 41.060341 loss_ctc 48.068569 loss_rnnt 29.453781 lr 0.00098636 rank 7
2022-12-03 16:55:21,675 DEBUG TRAIN Batch 2/8000 loss 36.882744 loss_att 43.992908 loss_ctc 57.538754 loss_rnnt 32.706573 lr 0.00098748 rank 3
2022-12-03 16:55:21,678 DEBUG TRAIN Batch 2/8000 loss 36.548626 loss_att 47.421032 loss_ctc 63.020363 loss_rnnt 30.844578 lr 0.00098636 rank 4
2022-12-03 16:55:21,681 DEBUG TRAIN Batch 2/8000 loss 31.484097 loss_att 40.884125 loss_ctc 46.987091 loss_rnnt 27.537025 lr 0.00098800 rank 2
2022-12-03 16:56:33,769 DEBUG TRAIN Batch 2/8100 loss 32.171211 loss_att 36.598618 loss_ctc 45.106369 loss_rnnt 29.561043 lr 0.00099196 rank 1
2022-12-03 16:56:33,781 DEBUG TRAIN Batch 2/8100 loss 25.457134 loss_att 30.813993 loss_ctc 37.304787 loss_rnnt 22.806076 lr 0.00099200 rank 2
2022-12-03 16:56:33,787 DEBUG TRAIN Batch 2/8100 loss 32.652370 loss_att 37.284035 loss_ctc 41.705128 loss_rnnt 30.519001 lr 0.00099128 rank 0
2022-12-03 16:56:33,788 DEBUG TRAIN Batch 2/8100 loss 36.679234 loss_att 37.284115 loss_ctc 56.346119 loss_rnnt 33.936005 lr 0.00099040 rank 5
2022-12-03 16:56:33,790 DEBUG TRAIN Batch 2/8100 loss 25.489988 loss_att 38.485119 loss_ctc 42.702480 loss_rnnt 20.595963 lr 0.00099036 rank 4
2022-12-03 16:56:33,797 DEBUG TRAIN Batch 2/8100 loss 33.379787 loss_att 43.168774 loss_ctc 48.468605 loss_rnnt 29.410147 lr 0.00099144 rank 6
2022-12-03 16:56:33,803 DEBUG TRAIN Batch 2/8100 loss 21.394884 loss_att 28.980328 loss_ctc 35.756508 loss_rnnt 17.962912 lr 0.00099036 rank 7
2022-12-03 16:56:33,803 DEBUG TRAIN Batch 2/8100 loss 18.522152 loss_att 25.533863 loss_ctc 26.493246 loss_rnnt 16.056997 lr 0.00099148 rank 3
2022-12-03 16:57:46,642 DEBUG TRAIN Batch 2/8200 loss 26.154644 loss_att 31.642159 loss_ctc 36.615231 loss_rnnt 23.662395 lr 0.00099548 rank 3
2022-12-03 16:57:46,644 DEBUG TRAIN Batch 2/8200 loss 20.554634 loss_att 28.692497 loss_ctc 31.250544 loss_rnnt 17.500938 lr 0.00099596 rank 1
2022-12-03 16:57:46,645 DEBUG TRAIN Batch 2/8200 loss 31.955042 loss_att 40.561966 loss_ctc 42.864571 loss_rnnt 28.779053 lr 0.00099544 rank 6
2022-12-03 16:57:46,646 DEBUG TRAIN Batch 2/8200 loss 41.888420 loss_att 43.713264 loss_ctc 56.331924 loss_rnnt 39.597649 lr 0.00099600 rank 2
2022-12-03 16:57:46,648 DEBUG TRAIN Batch 2/8200 loss 60.058861 loss_att 79.652367 loss_ctc 73.007195 loss_rnnt 54.413719 lr 0.00099440 rank 5
2022-12-03 16:57:46,650 DEBUG TRAIN Batch 2/8200 loss 49.754074 loss_att 59.574791 loss_ctc 75.512688 loss_rnnt 44.355446 lr 0.00099436 rank 4
2022-12-03 16:57:46,651 DEBUG TRAIN Batch 2/8200 loss 21.656515 loss_att 27.434776 loss_ctc 31.910986 loss_rnnt 19.133598 lr 0.00099528 rank 0
2022-12-03 16:57:46,704 DEBUG TRAIN Batch 2/8200 loss 24.223728 loss_att 33.214691 loss_ctc 36.122326 loss_rnnt 20.839054 lr 0.00099436 rank 7
2022-12-03 16:58:58,910 DEBUG TRAIN Batch 2/8300 loss 26.494963 loss_att 43.389950 loss_ctc 53.591000 loss_rnnt 19.503159 lr 0.00099948 rank 3
2022-12-03 16:58:58,923 DEBUG TRAIN Batch 2/8300 loss 26.942146 loss_att 35.733738 loss_ctc 40.883636 loss_rnnt 23.324963 lr 0.00099996 rank 1
2022-12-03 16:58:58,924 DEBUG TRAIN Batch 2/8300 loss 40.392544 loss_att 59.791222 loss_ctc 64.262863 loss_rnnt 33.330097 lr 0.00099944 rank 6
2022-12-03 16:58:58,925 DEBUG TRAIN Batch 2/8300 loss 22.177137 loss_att 28.835127 loss_ctc 30.326847 loss_rnnt 19.758911 lr 0.00099836 rank 7
2022-12-03 16:58:58,926 DEBUG TRAIN Batch 2/8300 loss 29.188047 loss_att 37.942635 loss_ctc 35.058563 loss_rnnt 26.654396 lr 0.00099836 rank 4
2022-12-03 16:58:58,927 DEBUG TRAIN Batch 2/8300 loss 36.929092 loss_att 55.728260 loss_ctc 56.995354 loss_rnnt 30.493755 lr 0.00100000 rank 2
2022-12-03 16:58:58,927 DEBUG TRAIN Batch 2/8300 loss 21.667107 loss_att 30.697983 loss_ctc 29.202717 loss_rnnt 18.856182 lr 0.00099928 rank 0
2022-12-03 16:58:58,928 DEBUG TRAIN Batch 2/8300 loss 37.961235 loss_att 49.970924 loss_ctc 57.416634 loss_rnnt 32.965244 lr 0.00099840 rank 5
2022-12-03 16:59:49,612 DEBUG CV Batch 2/0 loss 6.565379 loss_att 6.355950 loss_ctc 10.298202 loss_rnnt 6.109555 history loss 6.322216 rank 7
2022-12-03 16:59:49,617 DEBUG CV Batch 2/0 loss 6.565379 loss_att 6.355950 loss_ctc 10.298202 loss_rnnt 6.109555 history loss 6.322216 rank 3
2022-12-03 16:59:49,618 DEBUG CV Batch 2/0 loss 6.565379 loss_att 6.355950 loss_ctc 10.298202 loss_rnnt 6.109555 history loss 6.322216 rank 1
2022-12-03 16:59:49,640 DEBUG CV Batch 2/0 loss 6.565379 loss_att 6.355950 loss_ctc 10.298202 loss_rnnt 6.109555 history loss 6.322216 rank 2
2022-12-03 16:59:49,641 DEBUG CV Batch 2/0 loss 6.565379 loss_att 6.355950 loss_ctc 10.298202 loss_rnnt 6.109555 history loss 6.322216 rank 5
2022-12-03 16:59:49,642 DEBUG CV Batch 2/0 loss 6.565379 loss_att 6.355950 loss_ctc 10.298202 loss_rnnt 6.109555 history loss 6.322216 rank 4
2022-12-03 16:59:49,644 DEBUG CV Batch 2/0 loss 6.565379 loss_att 6.355950 loss_ctc 10.298202 loss_rnnt 6.109555 history loss 6.322216 rank 0
2022-12-03 16:59:49,649 DEBUG CV Batch 2/0 loss 6.565379 loss_att 6.355950 loss_ctc 10.298202 loss_rnnt 6.109555 history loss 6.322216 rank 6
2022-12-03 17:00:00,846 DEBUG CV Batch 2/100 loss 27.608017 loss_att 25.828941 loss_ctc 39.355591 loss_rnnt 26.397490 history loss 13.015580 rank 1
2022-12-03 17:00:01,041 DEBUG CV Batch 2/100 loss 27.608017 loss_att 25.828941 loss_ctc 39.355591 loss_rnnt 26.397490 history loss 13.015580 rank 7
2022-12-03 17:00:01,061 DEBUG CV Batch 2/100 loss 27.608017 loss_att 25.828941 loss_ctc 39.355591 loss_rnnt 26.397490 history loss 13.015580 rank 2
2022-12-03 17:00:01,170 DEBUG CV Batch 2/100 loss 27.608017 loss_att 25.828941 loss_ctc 39.355591 loss_rnnt 26.397490 history loss 13.015580 rank 0
2022-12-03 17:00:01,241 DEBUG CV Batch 2/100 loss 27.608017 loss_att 25.828941 loss_ctc 39.355591 loss_rnnt 26.397490 history loss 13.015580 rank 4
2022-12-03 17:00:01,270 DEBUG CV Batch 2/100 loss 27.608017 loss_att 25.828941 loss_ctc 39.355591 loss_rnnt 26.397490 history loss 13.015580 rank 3
2022-12-03 17:00:01,272 DEBUG CV Batch 2/100 loss 27.608017 loss_att 25.828941 loss_ctc 39.355591 loss_rnnt 26.397490 history loss 13.015580 rank 6
2022-12-03 17:00:01,420 DEBUG CV Batch 2/100 loss 27.608017 loss_att 25.828941 loss_ctc 39.355591 loss_rnnt 26.397490 history loss 13.015580 rank 5
2022-12-03 17:00:14,718 DEBUG CV Batch 2/200 loss 40.344692 loss_att 70.388329 loss_ctc 50.419861 loss_rnnt 32.992607 history loss 14.315011 rank 4
2022-12-03 17:00:14,795 DEBUG CV Batch 2/200 loss 40.344692 loss_att 70.388329 loss_ctc 50.419861 loss_rnnt 32.992607 history loss 14.315011 rank 1
2022-12-03 17:00:14,796 DEBUG CV Batch 2/200 loss 40.344692 loss_att 70.388329 loss_ctc 50.419861 loss_rnnt 32.992607 history loss 14.315011 rank 7
2022-12-03 17:00:14,867 DEBUG CV Batch 2/200 loss 40.344692 loss_att 70.388329 loss_ctc 50.419861 loss_rnnt 32.992607 history loss 14.315011 rank 2
2022-12-03 17:00:14,903 DEBUG CV Batch 2/200 loss 40.344692 loss_att 70.388329 loss_ctc 50.419861 loss_rnnt 32.992607 history loss 14.315011 rank 6
2022-12-03 17:00:14,927 DEBUG CV Batch 2/200 loss 40.344692 loss_att 70.388329 loss_ctc 50.419861 loss_rnnt 32.992607 history loss 14.315011 rank 0
2022-12-03 17:00:15,064 DEBUG CV Batch 2/200 loss 40.344692 loss_att 70.388329 loss_ctc 50.419861 loss_rnnt 32.992607 history loss 14.315011 rank 3
2022-12-03 17:00:15,274 DEBUG CV Batch 2/200 loss 40.344692 loss_att 70.388329 loss_ctc 50.419861 loss_rnnt 32.992607 history loss 14.315011 rank 5
2022-12-03 17:00:26,657 DEBUG CV Batch 2/300 loss 15.241081 loss_att 17.614714 loss_ctc 25.684921 loss_rnnt 13.373842 history loss 14.411574 rank 1
2022-12-03 17:00:26,752 DEBUG CV Batch 2/300 loss 15.241081 loss_att 17.614714 loss_ctc 25.684921 loss_rnnt 13.373842 history loss 14.411574 rank 4
2022-12-03 17:00:26,817 DEBUG CV Batch 2/300 loss 15.241081 loss_att 17.614714 loss_ctc 25.684921 loss_rnnt 13.373842 history loss 14.411574 rank 7
2022-12-03 17:00:26,955 DEBUG CV Batch 2/300 loss 15.241081 loss_att 17.614714 loss_ctc 25.684921 loss_rnnt 13.373842 history loss 14.411574 rank 2
2022-12-03 17:00:27,165 DEBUG CV Batch 2/300 loss 15.241081 loss_att 17.614714 loss_ctc 25.684921 loss_rnnt 13.373842 history loss 14.411574 rank 6
2022-12-03 17:00:27,338 DEBUG CV Batch 2/300 loss 15.241081 loss_att 17.614714 loss_ctc 25.684921 loss_rnnt 13.373842 history loss 14.411574 rank 0
2022-12-03 17:00:27,398 DEBUG CV Batch 2/300 loss 15.241081 loss_att 17.614714 loss_ctc 25.684921 loss_rnnt 13.373842 history loss 14.411574 rank 3
2022-12-03 17:00:27,835 DEBUG CV Batch 2/300 loss 15.241081 loss_att 17.614714 loss_ctc 25.684921 loss_rnnt 13.373842 history loss 14.411574 rank 5
2022-12-03 17:00:38,529 DEBUG CV Batch 2/400 loss 53.907585 loss_att 153.537170 loss_ctc 62.862236 loss_rnnt 32.787712 history loss 16.119065 rank 1
2022-12-03 17:00:38,863 DEBUG CV Batch 2/400 loss 53.907585 loss_att 153.537170 loss_ctc 62.862236 loss_rnnt 32.787712 history loss 16.119065 rank 7
2022-12-03 17:00:38,896 DEBUG CV Batch 2/400 loss 53.907585 loss_att 153.537170 loss_ctc 62.862236 loss_rnnt 32.787712 history loss 16.119065 rank 4
2022-12-03 17:00:39,156 DEBUG CV Batch 2/400 loss 53.907585 loss_att 153.537170 loss_ctc 62.862236 loss_rnnt 32.787712 history loss 16.119065 rank 2
2022-12-03 17:00:39,290 DEBUG CV Batch 2/400 loss 53.907585 loss_att 153.537170 loss_ctc 62.862236 loss_rnnt 32.787712 history loss 16.119065 rank 6
2022-12-03 17:00:39,723 DEBUG CV Batch 2/400 loss 53.907585 loss_att 153.537170 loss_ctc 62.862236 loss_rnnt 32.787712 history loss 16.119065 rank 0
2022-12-03 17:00:39,729 DEBUG CV Batch 2/400 loss 53.907585 loss_att 153.537170 loss_ctc 62.862236 loss_rnnt 32.787712 history loss 16.119065 rank 3
2022-12-03 17:00:40,123 DEBUG CV Batch 2/400 loss 53.907585 loss_att 153.537170 loss_ctc 62.862236 loss_rnnt 32.787712 history loss 16.119065 rank 5
2022-12-03 17:00:48,946 DEBUG CV Batch 2/500 loss 23.853756 loss_att 28.763344 loss_ctc 39.166622 loss_rnnt 20.830122 history loss 17.416355 rank 1
2022-12-03 17:00:49,307 DEBUG CV Batch 2/500 loss 23.853756 loss_att 28.763344 loss_ctc 39.166622 loss_rnnt 20.830122 history loss 17.416355 rank 7
2022-12-03 17:00:49,319 DEBUG CV Batch 2/500 loss 23.853756 loss_att 28.763344 loss_ctc 39.166622 loss_rnnt 20.830122 history loss 17.416355 rank 4
2022-12-03 17:00:49,766 DEBUG CV Batch 2/500 loss 23.853756 loss_att 28.763344 loss_ctc 39.166622 loss_rnnt 20.830122 history loss 17.416355 rank 2
2022-12-03 17:00:49,854 DEBUG CV Batch 2/500 loss 23.853756 loss_att 28.763344 loss_ctc 39.166622 loss_rnnt 20.830122 history loss 17.416355 rank 6
2022-12-03 17:00:50,457 DEBUG CV Batch 2/500 loss 23.853756 loss_att 28.763344 loss_ctc 39.166622 loss_rnnt 20.830122 history loss 17.416355 rank 3
2022-12-03 17:00:50,462 DEBUG CV Batch 2/500 loss 23.853756 loss_att 28.763344 loss_ctc 39.166622 loss_rnnt 20.830122 history loss 17.416355 rank 0
2022-12-03 17:00:50,699 DEBUG CV Batch 2/500 loss 23.853756 loss_att 28.763344 loss_ctc 39.166622 loss_rnnt 20.830122 history loss 17.416355 rank 5
2022-12-03 17:01:00,872 DEBUG CV Batch 2/600 loss 16.645714 loss_att 15.568373 loss_ctc 23.674187 loss_rnnt 15.924051 history loss 18.931737 rank 1
2022-12-03 17:01:01,411 DEBUG CV Batch 2/600 loss 16.645714 loss_att 15.568373 loss_ctc 23.674187 loss_rnnt 15.924051 history loss 18.931737 rank 7
2022-12-03 17:01:01,518 DEBUG CV Batch 2/600 loss 16.645714 loss_att 15.568373 loss_ctc 23.674187 loss_rnnt 15.924051 history loss 18.931737 rank 4
2022-12-03 17:01:02,025 DEBUG CV Batch 2/600 loss 16.645714 loss_att 15.568373 loss_ctc 23.674187 loss_rnnt 15.924051 history loss 18.931737 rank 2
2022-12-03 17:01:02,027 DEBUG CV Batch 2/600 loss 16.645714 loss_att 15.568373 loss_ctc 23.674187 loss_rnnt 15.924051 history loss 18.931737 rank 6
2022-12-03 17:01:02,754 DEBUG CV Batch 2/600 loss 16.645714 loss_att 15.568373 loss_ctc 23.674187 loss_rnnt 15.924051 history loss 18.931737 rank 5
2022-12-03 17:01:02,860 DEBUG CV Batch 2/600 loss 16.645714 loss_att 15.568373 loss_ctc 23.674187 loss_rnnt 15.924051 history loss 18.931737 rank 3
2022-12-03 17:01:02,900 DEBUG CV Batch 2/600 loss 16.645714 loss_att 15.568373 loss_ctc 23.674187 loss_rnnt 15.924051 history loss 18.931737 rank 0
2022-12-03 17:01:13,254 DEBUG CV Batch 2/700 loss 66.018425 loss_att 116.730331 loss_ctc 82.331924 loss_rnnt 53.700905 history loss 20.204972 rank 4
2022-12-03 17:01:13,367 DEBUG CV Batch 2/700 loss 66.018425 loss_att 116.730331 loss_ctc 82.331924 loss_rnnt 53.700905 history loss 20.204972 rank 7
2022-12-03 17:01:13,375 DEBUG CV Batch 2/700 loss 66.018425 loss_att 116.730331 loss_ctc 82.331924 loss_rnnt 53.700905 history loss 20.204972 rank 2
2022-12-03 17:01:13,379 DEBUG CV Batch 2/700 loss 66.018425 loss_att 116.730331 loss_ctc 82.331924 loss_rnnt 53.700905 history loss 20.204972 rank 1
2022-12-03 17:01:13,543 DEBUG CV Batch 2/700 loss 66.018425 loss_att 116.730331 loss_ctc 82.331924 loss_rnnt 53.700905 history loss 20.204972 rank 6
2022-12-03 17:01:13,934 DEBUG CV Batch 2/700 loss 66.018425 loss_att 116.730331 loss_ctc 82.331924 loss_rnnt 53.700905 history loss 20.204972 rank 5
2022-12-03 17:01:14,502 DEBUG CV Batch 2/700 loss 66.018425 loss_att 116.730331 loss_ctc 82.331924 loss_rnnt 53.700905 history loss 20.204972 rank 3
2022-12-03 17:01:14,636 DEBUG CV Batch 2/700 loss 66.018425 loss_att 116.730331 loss_ctc 82.331924 loss_rnnt 53.700905 history loss 20.204972 rank 0
2022-12-03 17:01:24,222 DEBUG CV Batch 2/800 loss 29.448593 loss_att 25.906124 loss_ctc 42.928024 loss_rnnt 28.359829 history loss 19.232323 rank 4
2022-12-03 17:01:24,916 DEBUG CV Batch 2/800 loss 29.448593 loss_att 25.906124 loss_ctc 42.928024 loss_rnnt 28.359829 history loss 19.232323 rank 6
2022-12-03 17:01:24,928 DEBUG CV Batch 2/800 loss 29.448593 loss_att 25.906124 loss_ctc 42.928024 loss_rnnt 28.359829 history loss 19.232323 rank 2
2022-12-03 17:01:25,111 DEBUG CV Batch 2/800 loss 29.448593 loss_att 25.906124 loss_ctc 42.928024 loss_rnnt 28.359829 history loss 19.232323 rank 1
2022-12-03 17:01:25,123 DEBUG CV Batch 2/800 loss 29.448593 loss_att 25.906124 loss_ctc 42.928024 loss_rnnt 28.359829 history loss 19.232323 rank 5
2022-12-03 17:01:25,558 DEBUG CV Batch 2/800 loss 29.448593 loss_att 25.906124 loss_ctc 42.928024 loss_rnnt 28.359829 history loss 19.232323 rank 7
2022-12-03 17:01:26,082 DEBUG CV Batch 2/800 loss 29.448593 loss_att 25.906124 loss_ctc 42.928024 loss_rnnt 28.359829 history loss 19.232323 rank 3
2022-12-03 17:01:26,298 DEBUG CV Batch 2/800 loss 29.448593 loss_att 25.906124 loss_ctc 42.928024 loss_rnnt 28.359829 history loss 19.232323 rank 0
2022-12-03 17:01:37,666 DEBUG CV Batch 2/900 loss 41.880653 loss_att 58.937489 loss_ctc 61.635071 loss_rnnt 35.835365 history loss 18.928361 rank 4
2022-12-03 17:01:38,480 DEBUG CV Batch 2/900 loss 41.880653 loss_att 58.937489 loss_ctc 61.635071 loss_rnnt 35.835365 history loss 18.928361 rank 6
2022-12-03 17:01:38,704 DEBUG CV Batch 2/900 loss 41.880653 loss_att 58.937489 loss_ctc 61.635071 loss_rnnt 35.835365 history loss 18.928361 rank 5
2022-12-03 17:01:38,740 DEBUG CV Batch 2/900 loss 41.880653 loss_att 58.937489 loss_ctc 61.635071 loss_rnnt 35.835365 history loss 18.928361 rank 2
2022-12-03 17:01:39,014 DEBUG CV Batch 2/900 loss 41.880653 loss_att 58.937489 loss_ctc 61.635071 loss_rnnt 35.835365 history loss 18.928361 rank 1
2022-12-03 17:01:39,231 DEBUG CV Batch 2/900 loss 41.880653 loss_att 58.937489 loss_ctc 61.635071 loss_rnnt 35.835365 history loss 18.928361 rank 7
2022-12-03 17:01:39,821 DEBUG CV Batch 2/900 loss 41.880653 loss_att 58.937489 loss_ctc 61.635071 loss_rnnt 35.835365 history loss 18.928361 rank 3
2022-12-03 17:01:40,142 DEBUG CV Batch 2/900 loss 41.880653 loss_att 58.937489 loss_ctc 61.635071 loss_rnnt 35.835365 history loss 18.928361 rank 0
2022-12-03 17:01:49,868 DEBUG CV Batch 2/1000 loss 11.233021 loss_att 14.131643 loss_ctc 16.243660 loss_rnnt 9.985210 history loss 18.504680 rank 4
2022-12-03 17:01:50,776 DEBUG CV Batch 2/1000 loss 11.233021 loss_att 14.131643 loss_ctc 16.243660 loss_rnnt 9.985210 history loss 18.504680 rank 5
2022-12-03 17:01:51,027 DEBUG CV Batch 2/1000 loss 11.233021 loss_att 14.131643 loss_ctc 16.243660 loss_rnnt 9.985210 history loss 18.504680 rank 6
2022-12-03 17:01:51,032 DEBUG CV Batch 2/1000 loss 11.233021 loss_att 14.131643 loss_ctc 16.243660 loss_rnnt 9.985210 history loss 18.504680 rank 1
2022-12-03 17:01:51,525 DEBUG CV Batch 2/1000 loss 11.233021 loss_att 14.131643 loss_ctc 16.243660 loss_rnnt 9.985210 history loss 18.504680 rank 2
2022-12-03 17:01:51,578 DEBUG CV Batch 2/1000 loss 11.233021 loss_att 14.131643 loss_ctc 16.243660 loss_rnnt 9.985210 history loss 18.504680 rank 7
2022-12-03 17:01:52,487 DEBUG CV Batch 2/1000 loss 11.233021 loss_att 14.131643 loss_ctc 16.243660 loss_rnnt 9.985210 history loss 18.504680 rank 3
2022-12-03 17:01:52,954 DEBUG CV Batch 2/1000 loss 11.233021 loss_att 14.131643 loss_ctc 16.243660 loss_rnnt 9.985210 history loss 18.504680 rank 0
2022-12-03 17:02:02,049 DEBUG CV Batch 2/1100 loss 9.635210 loss_att 9.324726 loss_ctc 15.136378 loss_rnnt 8.963818 history loss 18.467283 rank 4
2022-12-03 17:02:02,609 DEBUG CV Batch 2/1100 loss 9.635210 loss_att 9.324726 loss_ctc 15.136378 loss_rnnt 8.963818 history loss 18.467283 rank 5
2022-12-03 17:02:02,975 DEBUG CV Batch 2/1100 loss 9.635210 loss_att 9.324726 loss_ctc 15.136378 loss_rnnt 8.963818 history loss 18.467283 rank 1
2022-12-03 17:02:03,203 DEBUG CV Batch 2/1100 loss 9.635210 loss_att 9.324726 loss_ctc 15.136378 loss_rnnt 8.963818 history loss 18.467283 rank 6
2022-12-03 17:02:03,582 DEBUG CV Batch 2/1100 loss 9.635210 loss_att 9.324726 loss_ctc 15.136378 loss_rnnt 8.963818 history loss 18.467283 rank 7
2022-12-03 17:02:03,713 DEBUG CV Batch 2/1100 loss 9.635210 loss_att 9.324726 loss_ctc 15.136378 loss_rnnt 8.963818 history loss 18.467283 rank 2
2022-12-03 17:02:04,806 DEBUG CV Batch 2/1100 loss 9.635210 loss_att 9.324726 loss_ctc 15.136378 loss_rnnt 8.963818 history loss 18.467283 rank 3
2022-12-03 17:02:05,446 DEBUG CV Batch 2/1100 loss 9.635210 loss_att 9.324726 loss_ctc 15.136378 loss_rnnt 8.963818 history loss 18.467283 rank 0
2022-12-03 17:02:12,764 DEBUG CV Batch 2/1200 loss 23.862841 loss_att 33.107765 loss_ctc 40.543793 loss_rnnt 19.789726 history loss 19.030094 rank 4
2022-12-03 17:02:13,083 DEBUG CV Batch 2/1200 loss 23.862841 loss_att 33.107765 loss_ctc 40.543793 loss_rnnt 19.789726 history loss 19.030094 rank 5
2022-12-03 17:02:13,516 DEBUG CV Batch 2/1200 loss 23.862841 loss_att 33.107765 loss_ctc 40.543793 loss_rnnt 19.789726 history loss 19.030094 rank 1
2022-12-03 17:02:13,968 DEBUG CV Batch 2/1200 loss 23.862841 loss_att 33.107765 loss_ctc 40.543793 loss_rnnt 19.789726 history loss 19.030094 rank 7
2022-12-03 17:02:14,011 DEBUG CV Batch 2/1200 loss 23.862841 loss_att 33.107765 loss_ctc 40.543793 loss_rnnt 19.789726 history loss 19.030094 rank 6
2022-12-03 17:02:14,734 DEBUG CV Batch 2/1200 loss 23.862841 loss_att 33.107765 loss_ctc 40.543793 loss_rnnt 19.789726 history loss 19.030094 rank 2
2022-12-03 17:02:15,873 DEBUG CV Batch 2/1200 loss 23.862841 loss_att 33.107765 loss_ctc 40.543793 loss_rnnt 19.789726 history loss 19.030094 rank 3
2022-12-03 17:02:16,582 DEBUG CV Batch 2/1200 loss 23.862841 loss_att 33.107765 loss_ctc 40.543793 loss_rnnt 19.789726 history loss 19.030094 rank 0
2022-12-03 17:02:24,756 DEBUG CV Batch 2/1300 loss 18.012115 loss_att 16.505207 loss_ctc 25.655285 loss_rnnt 17.294407 history loss 19.493913 rank 4
2022-12-03 17:02:24,998 DEBUG CV Batch 2/1300 loss 18.012115 loss_att 16.505207 loss_ctc 25.655285 loss_rnnt 17.294407 history loss 19.493913 rank 5
2022-12-03 17:02:25,449 DEBUG CV Batch 2/1300 loss 18.012115 loss_att 16.505207 loss_ctc 25.655285 loss_rnnt 17.294407 history loss 19.493913 rank 1
2022-12-03 17:02:26,069 DEBUG CV Batch 2/1300 loss 18.012115 loss_att 16.505207 loss_ctc 25.655285 loss_rnnt 17.294407 history loss 19.493913 rank 7
2022-12-03 17:02:26,297 DEBUG CV Batch 2/1300 loss 18.012115 loss_att 16.505207 loss_ctc 25.655285 loss_rnnt 17.294407 history loss 19.493913 rank 6
2022-12-03 17:02:27,150 DEBUG CV Batch 2/1300 loss 18.012115 loss_att 16.505207 loss_ctc 25.655285 loss_rnnt 17.294407 history loss 19.493913 rank 2
2022-12-03 17:02:28,319 DEBUG CV Batch 2/1300 loss 18.012115 loss_att 16.505207 loss_ctc 25.655285 loss_rnnt 17.294407 history loss 19.493913 rank 3
2022-12-03 17:02:28,938 DEBUG CV Batch 2/1300 loss 18.012115 loss_att 16.505207 loss_ctc 25.655285 loss_rnnt 17.294407 history loss 19.493913 rank 0
2022-12-03 17:02:36,149 DEBUG CV Batch 2/1400 loss 53.088345 loss_att 97.189743 loss_ctc 59.263435 loss_rnnt 43.444721 history loss 20.117995 rank 4
2022-12-03 17:02:36,565 DEBUG CV Batch 2/1400 loss 53.088345 loss_att 97.189743 loss_ctc 59.263435 loss_rnnt 43.444721 history loss 20.117995 rank 5
2022-12-03 17:02:37,377 DEBUG CV Batch 2/1400 loss 53.088345 loss_att 97.189743 loss_ctc 59.263435 loss_rnnt 43.444721 history loss 20.117995 rank 1
2022-12-03 17:02:37,413 DEBUG CV Batch 2/1400 loss 53.088345 loss_att 97.189743 loss_ctc 59.263435 loss_rnnt 43.444721 history loss 20.117995 rank 7
2022-12-03 17:02:37,728 DEBUG CV Batch 2/1400 loss 53.088345 loss_att 97.189743 loss_ctc 59.263435 loss_rnnt 43.444721 history loss 20.117995 rank 6
2022-12-03 17:02:39,051 DEBUG CV Batch 2/1400 loss 53.088345 loss_att 97.189743 loss_ctc 59.263435 loss_rnnt 43.444721 history loss 20.117995 rank 2
2022-12-03 17:02:40,025 DEBUG CV Batch 2/1400 loss 53.088345 loss_att 97.189743 loss_ctc 59.263435 loss_rnnt 43.444721 history loss 20.117995 rank 3
2022-12-03 17:02:40,700 DEBUG CV Batch 2/1400 loss 53.088345 loss_att 97.189743 loss_ctc 59.263435 loss_rnnt 43.444721 history loss 20.117995 rank 0
2022-12-03 17:02:47,382 DEBUG CV Batch 2/1500 loss 21.769630 loss_att 26.550411 loss_ctc 29.889317 loss_rnnt 19.730850 history loss 19.725368 rank 4
2022-12-03 17:02:49,104 DEBUG CV Batch 2/1500 loss 21.769630 loss_att 26.550411 loss_ctc 29.889317 loss_rnnt 19.730850 history loss 19.725368 rank 5
2022-12-03 17:02:49,509 DEBUG CV Batch 2/1500 loss 21.769630 loss_att 26.550411 loss_ctc 29.889317 loss_rnnt 19.730850 history loss 19.725368 rank 7
2022-12-03 17:02:49,564 DEBUG CV Batch 2/1500 loss 21.769630 loss_att 26.550411 loss_ctc 29.889317 loss_rnnt 19.730850 history loss 19.725368 rank 6
2022-12-03 17:02:50,172 DEBUG CV Batch 2/1500 loss 21.769630 loss_att 26.550411 loss_ctc 29.889317 loss_rnnt 19.730850 history loss 19.725368 rank 1
2022-12-03 17:02:50,705 DEBUG CV Batch 2/1500 loss 21.769630 loss_att 26.550411 loss_ctc 29.889317 loss_rnnt 19.730850 history loss 19.725368 rank 2
2022-12-03 17:02:51,825 DEBUG CV Batch 2/1500 loss 21.769630 loss_att 26.550411 loss_ctc 29.889317 loss_rnnt 19.730850 history loss 19.725368 rank 3
2022-12-03 17:02:52,674 DEBUG CV Batch 2/1500 loss 21.769630 loss_att 26.550411 loss_ctc 29.889317 loss_rnnt 19.730850 history loss 19.725368 rank 0
2022-12-03 17:03:00,647 DEBUG CV Batch 2/1600 loss 31.544182 loss_att 63.580788 loss_ctc 43.490005 loss_rnnt 23.544083 history loss 19.582915 rank 4
2022-12-03 17:03:02,814 DEBUG CV Batch 2/1600 loss 31.544182 loss_att 63.580788 loss_ctc 43.490005 loss_rnnt 23.544083 history loss 19.582915 rank 5
2022-12-03 17:03:02,822 DEBUG CV Batch 2/1600 loss 31.544182 loss_att 63.580788 loss_ctc 43.490005 loss_rnnt 23.544083 history loss 19.582915 rank 6
2022-12-03 17:03:03,113 DEBUG CV Batch 2/1600 loss 31.544182 loss_att 63.580788 loss_ctc 43.490005 loss_rnnt 23.544083 history loss 19.582915 rank 7
2022-12-03 17:03:03,696 DEBUG CV Batch 2/1600 loss 31.544182 loss_att 63.580788 loss_ctc 43.490005 loss_rnnt 23.544083 history loss 19.582915 rank 1
2022-12-03 17:03:04,157 DEBUG CV Batch 2/1600 loss 31.544182 loss_att 63.580788 loss_ctc 43.490005 loss_rnnt 23.544083 history loss 19.582915 rank 2
2022-12-03 17:03:05,285 DEBUG CV Batch 2/1600 loss 31.544182 loss_att 63.580788 loss_ctc 43.490005 loss_rnnt 23.544083 history loss 19.582915 rank 3
2022-12-03 17:03:06,194 DEBUG CV Batch 2/1600 loss 31.544182 loss_att 63.580788 loss_ctc 43.490005 loss_rnnt 23.544083 history loss 19.582915 rank 0
2022-12-03 17:03:13,292 DEBUG CV Batch 2/1700 loss 20.996429 loss_att 21.615368 loss_ctc 32.293541 loss_rnnt 19.366358 history loss 19.338997 rank 4
2022-12-03 17:03:15,340 DEBUG CV Batch 2/1700 loss 20.996429 loss_att 21.615368 loss_ctc 32.293541 loss_rnnt 19.366358 history loss 19.338997 rank 6
2022-12-03 17:03:15,671 DEBUG CV Batch 2/1700 loss 20.996429 loss_att 21.615368 loss_ctc 32.293541 loss_rnnt 19.366358 history loss 19.338997 rank 7
2022-12-03 17:03:15,720 DEBUG CV Batch 2/1700 loss 20.996429 loss_att 21.615368 loss_ctc 32.293541 loss_rnnt 19.366358 history loss 19.338997 rank 5
2022-12-03 17:03:16,041 DEBUG CV Batch 2/1700 loss 20.996429 loss_att 21.615368 loss_ctc 32.293541 loss_rnnt 19.366358 history loss 19.338997 rank 1
2022-12-03 17:03:16,945 DEBUG CV Batch 2/1700 loss 20.996429 loss_att 21.615368 loss_ctc 32.293541 loss_rnnt 19.366358 history loss 19.338997 rank 2
2022-12-03 17:03:17,976 DEBUG CV Batch 2/1700 loss 20.996429 loss_att 21.615368 loss_ctc 32.293541 loss_rnnt 19.366358 history loss 19.338997 rank 3
2022-12-03 17:03:18,840 DEBUG CV Batch 2/1700 loss 20.996429 loss_att 21.615368 loss_ctc 32.293541 loss_rnnt 19.366358 history loss 19.338997 rank 0
2022-12-03 17:03:22,556 INFO Epoch 2 CV info cv_loss 19.260678711921635
2022-12-03 17:03:22,557 INFO Epoch 3 TRAIN info lr 0.0009990399999999999
2022-12-03 17:03:22,561 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 17:03:24,308 INFO Epoch 2 CV info cv_loss 19.260678711921635
2022-12-03 17:03:24,308 INFO Epoch 3 TRAIN info lr 0.0009998200485854245
2022-12-03 17:03:24,310 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 17:03:24,988 INFO Epoch 2 CV info cv_loss 19.260678711921635
2022-12-03 17:03:24,988 INFO Epoch 3 TRAIN info lr 0.0009995403171568558
2022-12-03 17:03:24,993 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 17:03:25,057 INFO Epoch 2 CV info cv_loss 19.260678711921635
2022-12-03 17:03:25,057 INFO Epoch 3 TRAIN info lr 0.0009994399999999999
2022-12-03 17:03:25,059 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 17:03:25,100 INFO Epoch 2 CV info cv_loss 19.260678711921635
2022-12-03 17:03:25,100 INFO Epoch 3 TRAIN info lr 0.0009994205041127147
2022-12-03 17:03:25,102 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 17:03:26,189 INFO Epoch 2 CV info cv_loss 19.260678711921635
2022-12-03 17:03:26,190 INFO Epoch 3 TRAIN info lr 0.0009989616195929486
2022-12-03 17:03:26,195 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 17:03:27,173 INFO Epoch 2 CV info cv_loss 19.260678711921635
2022-12-03 17:03:27,174 INFO Epoch 3 TRAIN info lr 0.0009993606137453732
2022-12-03 17:03:27,175 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 17:03:28,136 INFO Epoch 2 CV info cv_loss 19.260678711921635
2022-12-03 17:03:28,137 INFO Checkpoint: save to checkpoint exp/1202_encoder_bias_30_0.1/2.pt
2022-12-03 17:03:28,789 INFO Epoch 3 TRAIN info lr 0.000999600239840112
2022-12-03 17:03:28,794 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 17:04:29,480 DEBUG TRAIN Batch 3/0 loss 15.320262 loss_att 15.797157 loss_ctc 20.674793 loss_rnnt 14.510945 lr 0.00099940 rank 1
2022-12-03 17:04:29,483 DEBUG TRAIN Batch 3/0 loss 15.330679 loss_att 15.848690 loss_ctc 20.317257 loss_rnnt 14.562200 lr 0.00099980 rank 6
2022-12-03 17:04:29,486 DEBUG TRAIN Batch 3/0 loss 14.937706 loss_att 15.970518 loss_ctc 18.282969 loss_rnnt 14.285109 lr 0.00099934 rank 3
2022-12-03 17:04:29,487 DEBUG TRAIN Batch 3/0 loss 17.952263 loss_att 18.988035 loss_ctc 23.472708 loss_rnnt 17.009048 lr 0.00099952 rank 5
2022-12-03 17:04:29,491 DEBUG TRAIN Batch 3/0 loss 23.407501 loss_att 20.817953 loss_ctc 28.776474 loss_rnnt 23.209547 lr 0.00099948 rank 7
2022-12-03 17:04:29,524 DEBUG TRAIN Batch 3/0 loss 17.913126 loss_att 19.761238 loss_ctc 24.626579 loss_rnnt 16.648376 lr 0.00099958 rank 0
2022-12-03 17:04:29,527 DEBUG TRAIN Batch 3/0 loss 18.719383 loss_att 18.015396 loss_ctc 23.656025 loss_rnnt 18.201962 lr 0.00099894 rank 2
2022-12-03 17:04:29,541 DEBUG TRAIN Batch 3/0 loss 20.903606 loss_att 21.136446 loss_ctc 28.202236 loss_rnnt 19.883888 lr 0.00099908 rank 4
2022-12-03 17:05:40,476 DEBUG TRAIN Batch 3/100 loss 27.771219 loss_att 36.755932 loss_ctc 51.642754 loss_rnnt 22.791405 lr 0.00099759 rank 0
2022-12-03 17:05:40,477 DEBUG TRAIN Batch 3/100 loss 23.621302 loss_att 29.157114 loss_ctc 40.216698 loss_rnnt 20.301418 lr 0.00099735 rank 3
2022-12-03 17:05:40,479 DEBUG TRAIN Batch 3/100 loss 65.454475 loss_att 75.529076 loss_ctc 87.146866 loss_rnnt 60.547234 lr 0.00099781 rank 6
2022-12-03 17:05:40,481 DEBUG TRAIN Batch 3/100 loss 41.458656 loss_att 50.862190 loss_ctc 55.024193 loss_rnnt 37.769211 lr 0.00099753 rank 5
2022-12-03 17:05:40,489 DEBUG TRAIN Batch 3/100 loss 43.913368 loss_att 54.342010 loss_ctc 67.669823 loss_rnnt 38.660110 lr 0.00099695 rank 2
2022-12-03 17:05:40,509 DEBUG TRAIN Batch 3/100 loss 46.823631 loss_att 64.840637 loss_ctc 73.200455 loss_rnnt 39.703316 lr 0.00099826 rank 7
2022-12-03 17:05:40,518 DEBUG TRAIN Batch 3/100 loss 56.319225 loss_att 69.044617 loss_ctc 81.142578 loss_rnnt 50.464363 lr 0.00099846 rank 4
2022-12-03 17:05:40,543 DEBUG TRAIN Batch 3/100 loss 39.492004 loss_att 54.731682 loss_ctc 70.106071 loss_rnnt 32.362190 lr 0.00099741 rank 1
2022-12-03 17:06:52,037 DEBUG TRAIN Batch 3/200 loss 20.909361 loss_att 28.902382 loss_ctc 31.535934 loss_rnnt 17.893879 lr 0.00099561 rank 0
2022-12-03 17:06:52,037 DEBUG TRAIN Batch 3/200 loss 33.671219 loss_att 42.943680 loss_ctc 58.120556 loss_rnnt 28.556814 lr 0.00099543 rank 1
2022-12-03 17:06:52,040 DEBUG TRAIN Batch 3/200 loss 39.867275 loss_att 48.935658 loss_ctc 63.969219 loss_rnnt 34.840008 lr 0.00099498 rank 2
2022-12-03 17:06:52,040 DEBUG TRAIN Batch 3/200 loss 44.966873 loss_att 52.318653 loss_ctc 65.608505 loss_rnnt 40.744297 lr 0.00099555 rank 5
2022-12-03 17:06:52,044 DEBUG TRAIN Batch 3/200 loss 21.589447 loss_att 32.071156 loss_ctc 33.567711 loss_rnnt 17.896002 lr 0.00099537 rank 3
2022-12-03 17:06:52,044 DEBUG TRAIN Batch 3/200 loss 37.008389 loss_att 52.056164 loss_ctc 57.974297 loss_rnnt 31.203381 lr 0.00099583 rank 6
2022-12-03 17:06:52,047 DEBUG TRAIN Batch 3/200 loss 23.965183 loss_att 38.169777 loss_ctc 38.489338 loss_rnnt 19.187712 lr 0.00099648 rank 4
2022-12-03 17:06:52,087 DEBUG TRAIN Batch 3/200 loss 25.771395 loss_att 35.713360 loss_ctc 42.676311 loss_rnnt 21.529013 lr 0.00099628 rank 7
2022-12-03 17:08:04,558 DEBUG TRAIN Batch 3/300 loss 28.750603 loss_att 38.746391 loss_ctc 38.736073 loss_rnnt 25.420048 lr 0.00099451 rank 4
2022-12-03 17:08:04,563 DEBUG TRAIN Batch 3/300 loss 30.099260 loss_att 37.012215 loss_ctc 44.333633 loss_rnnt 26.818754 lr 0.00099431 rank 7
2022-12-03 17:08:04,569 DEBUG TRAIN Batch 3/300 loss 46.909683 loss_att 61.656807 loss_ctc 70.841232 loss_rnnt 40.769386 lr 0.00099346 rank 1
2022-12-03 17:08:04,569 DEBUG TRAIN Batch 3/300 loss 65.771942 loss_att 81.105850 loss_ctc 89.829483 loss_rnnt 59.497482 lr 0.00099386 rank 6
2022-12-03 17:08:04,571 DEBUG TRAIN Batch 3/300 loss 30.416506 loss_att 46.692474 loss_ctc 43.922691 loss_rnnt 25.360487 lr 0.00099358 rank 5
2022-12-03 17:08:04,572 DEBUG TRAIN Batch 3/300 loss 52.687649 loss_att 68.610718 loss_ctc 73.711510 loss_rnnt 46.699856 lr 0.00099341 rank 3
2022-12-03 17:08:04,573 DEBUG TRAIN Batch 3/300 loss 26.993490 loss_att 37.077011 loss_ctc 41.551987 loss_rnnt 23.035652 lr 0.00099364 rank 0
2022-12-03 17:08:04,590 DEBUG TRAIN Batch 3/300 loss 28.432148 loss_att 38.050621 loss_ctc 43.499355 loss_rnnt 24.499491 lr 0.00099301 rank 2
2022-12-03 17:09:17,912 DEBUG TRAIN Batch 3/400 loss 27.292431 loss_att 38.539654 loss_ctc 38.367367 loss_rnnt 23.566328 lr 0.00099190 rank 6
2022-12-03 17:09:17,924 DEBUG TRAIN Batch 3/400 loss 58.067188 loss_att 69.081207 loss_ctc 80.813110 loss_rnnt 52.831596 lr 0.00099235 rank 7
2022-12-03 17:09:17,925 DEBUG TRAIN Batch 3/400 loss 33.020866 loss_att 40.827988 loss_ctc 48.018089 loss_rnnt 29.459810 lr 0.00099145 rank 3
2022-12-03 17:09:17,926 DEBUG TRAIN Batch 3/400 loss 42.794289 loss_att 51.110413 loss_ctc 68.579422 loss_rnnt 37.693047 lr 0.00099168 rank 0
2022-12-03 17:09:17,927 DEBUG TRAIN Batch 3/400 loss 30.245796 loss_att 39.903610 loss_ctc 48.776546 loss_rnnt 25.843464 lr 0.00099163 rank 5
2022-12-03 17:09:17,926 DEBUG TRAIN Batch 3/400 loss 64.739151 loss_att 75.835480 loss_ctc 87.857651 loss_rnnt 59.437416 lr 0.00099151 rank 1
2022-12-03 17:09:17,928 DEBUG TRAIN Batch 3/400 loss 26.510792 loss_att 31.652813 loss_ctc 36.008762 loss_rnnt 24.215994 lr 0.00099106 rank 2
2022-12-03 17:09:17,933 DEBUG TRAIN Batch 3/400 loss 41.906166 loss_att 48.319843 loss_ctc 62.033371 loss_rnnt 37.939800 lr 0.00099254 rank 4
2022-12-03 17:10:29,142 DEBUG TRAIN Batch 3/500 loss 54.567116 loss_att 59.792442 loss_ctc 73.166168 loss_rnnt 51.042175 lr 0.00098951 rank 3
2022-12-03 17:10:29,143 DEBUG TRAIN Batch 3/500 loss 37.653889 loss_att 45.703384 loss_ctc 58.396870 loss_rnnt 33.278259 lr 0.00098995 rank 6
2022-12-03 17:10:29,146 DEBUG TRAIN Batch 3/500 loss 45.750908 loss_att 51.649445 loss_ctc 60.429684 loss_rnnt 42.614029 lr 0.00098957 rank 1
2022-12-03 17:10:29,150 DEBUG TRAIN Batch 3/500 loss 23.187637 loss_att 32.302734 loss_ctc 36.431297 loss_rnnt 19.598797 lr 0.00099040 rank 7
2022-12-03 17:10:29,151 DEBUG TRAIN Batch 3/500 loss 28.935638 loss_att 41.195045 loss_ctc 45.248539 loss_rnnt 24.308702 lr 0.00098912 rank 2
2022-12-03 17:10:29,153 DEBUG TRAIN Batch 3/500 loss 26.682190 loss_att 38.473618 loss_ctc 40.190292 loss_rnnt 22.522823 lr 0.00098974 rank 0
2022-12-03 17:10:29,156 DEBUG TRAIN Batch 3/500 loss 28.716726 loss_att 33.250526 loss_ctc 41.438107 loss_rnnt 26.113783 lr 0.00099059 rank 4
2022-12-03 17:10:29,193 DEBUG TRAIN Batch 3/500 loss 27.161850 loss_att 36.582462 loss_ctc 39.409973 loss_rnnt 23.644644 lr 0.00098968 rank 5
2022-12-03 17:11:40,943 DEBUG TRAIN Batch 3/600 loss 19.924187 loss_att 25.634348 loss_ctc 32.549431 loss_rnnt 17.098789 lr 0.00098781 rank 0
2022-12-03 17:11:40,944 DEBUG TRAIN Batch 3/600 loss 28.300417 loss_att 32.860973 loss_ctc 43.750191 loss_rnnt 25.328337 lr 0.00098775 rank 5
2022-12-03 17:11:40,945 DEBUG TRAIN Batch 3/600 loss 22.990980 loss_att 27.541969 loss_ctc 38.398960 loss_rnnt 20.026384 lr 0.00098763 rank 1
2022-12-03 17:11:40,946 DEBUG TRAIN Batch 3/600 loss 34.299843 loss_att 37.128563 loss_ctc 43.246662 loss_rnnt 32.541187 lr 0.00098758 rank 3
2022-12-03 17:11:40,947 DEBUG TRAIN Batch 3/600 loss 31.950443 loss_att 35.298676 loss_ctc 51.705315 loss_rnnt 28.646812 lr 0.00098802 rank 6
2022-12-03 17:11:40,948 DEBUG TRAIN Batch 3/600 loss 37.128670 loss_att 41.501801 loss_ctc 48.951744 loss_rnnt 34.677631 lr 0.00098846 rank 7
2022-12-03 17:11:40,951 DEBUG TRAIN Batch 3/600 loss 22.455383 loss_att 27.307770 loss_ctc 32.314724 loss_rnnt 20.170328 lr 0.00098866 rank 4
2022-12-03 17:11:40,953 DEBUG TRAIN Batch 3/600 loss 23.909952 loss_att 24.189877 loss_ctc 33.819996 loss_rnnt 22.532629 lr 0.00098719 rank 2
2022-12-03 17:12:54,458 DEBUG TRAIN Batch 3/700 loss 25.724628 loss_att 33.994476 loss_ctc 35.181343 loss_rnnt 22.809761 lr 0.00098610 rank 6
2022-12-03 17:12:54,463 DEBUG TRAIN Batch 3/700 loss 29.947874 loss_att 40.078087 loss_ctc 44.767982 loss_rnnt 25.945816 lr 0.00098571 rank 1
2022-12-03 17:12:54,465 DEBUG TRAIN Batch 3/700 loss 33.104385 loss_att 46.898865 loss_ctc 53.573616 loss_rnnt 27.616255 lr 0.00098565 rank 3
2022-12-03 17:12:54,465 DEBUG TRAIN Batch 3/700 loss 31.683561 loss_att 38.943253 loss_ctc 44.899124 loss_rnnt 28.469547 lr 0.00098527 rank 2
2022-12-03 17:12:54,469 DEBUG TRAIN Batch 3/700 loss 35.697163 loss_att 56.585594 loss_ctc 55.938400 loss_rnnt 28.820644 lr 0.00098654 rank 7
2022-12-03 17:12:54,492 DEBUG TRAIN Batch 3/700 loss 26.437479 loss_att 35.667542 loss_ctc 39.390083 loss_rnnt 22.864452 lr 0.00098583 rank 5
2022-12-03 17:12:54,517 DEBUG TRAIN Batch 3/700 loss 75.542946 loss_att 90.127136 loss_ctc 104.532127 loss_rnnt 68.760887 lr 0.00098673 rank 4
2022-12-03 17:12:54,525 DEBUG TRAIN Batch 3/700 loss 43.417267 loss_att 55.964188 loss_ctc 62.894161 loss_rnnt 38.310966 lr 0.00098588 rank 0
2022-12-03 17:14:06,056 DEBUG TRAIN Batch 3/800 loss 28.208477 loss_att 37.840782 loss_ctc 43.447598 loss_rnnt 24.250134 lr 0.00098418 rank 6
2022-12-03 17:14:06,059 DEBUG TRAIN Batch 3/800 loss 20.081245 loss_att 26.459114 loss_ctc 29.380280 loss_rnnt 17.565802 lr 0.00098380 rank 1
2022-12-03 17:14:06,060 DEBUG TRAIN Batch 3/800 loss 35.648708 loss_att 47.859604 loss_ctc 55.035698 loss_rnnt 30.621597 lr 0.00098392 rank 5
2022-12-03 17:14:06,066 DEBUG TRAIN Batch 3/800 loss 36.990887 loss_att 47.483219 loss_ctc 50.422546 loss_rnnt 33.101532 lr 0.00098375 rank 3
2022-12-03 17:14:06,066 DEBUG TRAIN Batch 3/800 loss 25.410511 loss_att 37.577412 loss_ctc 39.165009 loss_rnnt 21.143198 lr 0.00098397 rank 0
2022-12-03 17:14:06,067 DEBUG TRAIN Batch 3/800 loss 39.663681 loss_att 51.091080 loss_ctc 64.838867 loss_rnnt 34.021511 lr 0.00098481 rank 4
2022-12-03 17:14:06,067 DEBUG TRAIN Batch 3/800 loss 46.184593 loss_att 48.401730 loss_ctc 74.875206 loss_rnnt 41.915752 lr 0.00098336 rank 2
2022-12-03 17:14:06,070 DEBUG TRAIN Batch 3/800 loss 42.172813 loss_att 49.000851 loss_ctc 68.105179 loss_rnnt 37.349556 lr 0.00098462 rank 7
2022-12-03 17:15:17,435 DEBUG TRAIN Batch 3/900 loss 39.192886 loss_att 46.401192 loss_ctc 53.747505 loss_rnnt 35.810608 lr 0.00098228 rank 6
2022-12-03 17:15:17,435 DEBUG TRAIN Batch 3/900 loss 46.929882 loss_att 60.632965 loss_ctc 64.550446 loss_rnnt 41.839859 lr 0.00098190 rank 1
2022-12-03 17:15:17,436 DEBUG TRAIN Batch 3/900 loss 33.396229 loss_att 43.391712 loss_ctc 54.985836 loss_rnnt 28.518513 lr 0.00098272 rank 7
2022-12-03 17:15:17,438 DEBUG TRAIN Batch 3/900 loss 28.585518 loss_att 42.434483 loss_ctc 46.206890 loss_rnnt 23.466206 lr 0.00098185 rank 3
2022-12-03 17:15:17,439 DEBUG TRAIN Batch 3/900 loss 39.392990 loss_att 52.898228 loss_ctc 62.899940 loss_rnnt 33.557682 lr 0.00098291 rank 4
2022-12-03 17:15:17,441 DEBUG TRAIN Batch 3/900 loss 23.936785 loss_att 35.752396 loss_ctc 43.217758 loss_rnnt 19.002867 lr 0.00098202 rank 5
2022-12-03 17:15:17,445 DEBUG TRAIN Batch 3/900 loss 32.810047 loss_att 34.304077 loss_ctc 45.085220 loss_rnnt 30.874550 lr 0.00098207 rank 0
2022-12-03 17:15:17,448 DEBUG TRAIN Batch 3/900 loss 24.835426 loss_att 36.324268 loss_ctc 45.690350 loss_rnnt 19.757000 lr 0.00098147 rank 2
2022-12-03 17:16:29,707 DEBUG TRAIN Batch 3/1000 loss 26.134544 loss_att 38.381363 loss_ctc 31.350910 loss_rnnt 22.989664 lr 0.00097958 rank 2
2022-12-03 17:16:29,720 DEBUG TRAIN Batch 3/1000 loss 22.298672 loss_att 31.053181 loss_ctc 34.771145 loss_rnnt 18.884773 lr 0.00098039 rank 6
2022-12-03 17:16:29,720 DEBUG TRAIN Batch 3/1000 loss 32.280140 loss_att 42.156765 loss_ctc 47.048649 loss_rnnt 28.335680 lr 0.00098083 rank 7
2022-12-03 17:16:29,729 DEBUG TRAIN Batch 3/1000 loss 42.585953 loss_att 50.370403 loss_ctc 68.536591 loss_rnnt 37.568974 lr 0.00098101 rank 4
2022-12-03 17:16:29,743 DEBUG TRAIN Batch 3/1000 loss 46.282120 loss_att 63.570023 loss_ctc 63.842964 loss_rnnt 40.483093 lr 0.00098018 rank 0
2022-12-03 17:16:29,747 DEBUG TRAIN Batch 3/1000 loss 33.838390 loss_att 42.621552 loss_ctc 48.074928 loss_rnnt 30.183552 lr 0.00097996 rank 3
2022-12-03 17:16:29,753 DEBUG TRAIN Batch 3/1000 loss 25.642946 loss_att 35.210407 loss_ctc 36.106522 loss_rnnt 22.334311 lr 0.00098002 rank 1
2022-12-03 17:16:29,793 DEBUG TRAIN Batch 3/1000 loss 27.625580 loss_att 36.109451 loss_ctc 40.184631 loss_rnnt 24.254265 lr 0.00098013 rank 5
2022-12-03 17:17:42,867 DEBUG TRAIN Batch 3/1100 loss 20.756098 loss_att 28.473536 loss_ctc 31.654684 loss_rnnt 17.759464 lr 0.00097851 rank 6
2022-12-03 17:17:42,867 DEBUG TRAIN Batch 3/1100 loss 27.978947 loss_att 33.744888 loss_ctc 45.697758 loss_rnnt 24.463249 lr 0.00097825 rank 5
2022-12-03 17:17:42,867 DEBUG TRAIN Batch 3/1100 loss 30.591991 loss_att 36.699318 loss_ctc 45.593918 loss_rnnt 27.370270 lr 0.00097808 rank 3
2022-12-03 17:17:42,870 DEBUG TRAIN Batch 3/1100 loss 41.565071 loss_att 48.397865 loss_ctc 57.414291 loss_rnnt 38.085281 lr 0.00097831 rank 0
2022-12-03 17:17:42,873 DEBUG TRAIN Batch 3/1100 loss 43.254173 loss_att 49.544880 loss_ctc 62.403572 loss_rnnt 39.442780 lr 0.00097894 rank 7
2022-12-03 17:17:42,877 DEBUG TRAIN Batch 3/1100 loss 37.081558 loss_att 47.094505 loss_ctc 56.399372 loss_rnnt 32.503262 lr 0.00097771 rank 2
2022-12-03 17:17:42,880 DEBUG TRAIN Batch 3/1100 loss 25.907568 loss_att 33.281639 loss_ctc 42.135422 loss_rnnt 22.269039 lr 0.00097814 rank 1
2022-12-03 17:17:42,937 DEBUG TRAIN Batch 3/1100 loss 30.021730 loss_att 39.642738 loss_ctc 47.723469 loss_rnnt 25.737297 lr 0.00097913 rank 4
2022-12-03 17:18:55,190 DEBUG TRAIN Batch 3/1200 loss 29.582767 loss_att 32.643711 loss_ctc 46.985847 loss_rnnt 26.650166 lr 0.00097638 rank 5
2022-12-03 17:18:55,207 DEBUG TRAIN Batch 3/1200 loss 32.076378 loss_att 39.628197 loss_ctc 49.527676 loss_rnnt 28.239170 lr 0.00097644 rank 0
2022-12-03 17:18:55,208 DEBUG TRAIN Batch 3/1200 loss 40.154076 loss_att 48.054863 loss_ctc 59.693249 loss_rnnt 35.968693 lr 0.00097622 rank 3
2022-12-03 17:18:55,209 DEBUG TRAIN Batch 3/1200 loss 32.649109 loss_att 37.767654 loss_ctc 54.629036 loss_rnnt 28.694742 lr 0.00097707 rank 7
2022-12-03 17:18:55,211 DEBUG TRAIN Batch 3/1200 loss 16.349607 loss_att 22.178001 loss_ctc 24.338947 loss_rnnt 14.118683 lr 0.00097664 rank 6
2022-12-03 17:18:55,215 DEBUG TRAIN Batch 3/1200 loss 41.570751 loss_att 49.132500 loss_ctc 56.721779 loss_rnnt 38.038261 lr 0.00097584 rank 2
2022-12-03 17:18:55,240 DEBUG TRAIN Batch 3/1200 loss 22.014666 loss_att 29.988680 loss_ctc 35.472267 loss_rnnt 18.625517 lr 0.00097627 rank 1
2022-12-03 17:18:55,245 DEBUG TRAIN Batch 3/1200 loss 23.405146 loss_att 28.292130 loss_ctc 34.065037 loss_rnnt 21.006430 lr 0.00097726 rank 4
2022-12-03 17:20:08,321 DEBUG TRAIN Batch 3/1300 loss 41.384068 loss_att 53.720108 loss_ctc 62.103802 loss_rnnt 36.154228 lr 0.00097458 rank 0
2022-12-03 17:20:08,321 DEBUG TRAIN Batch 3/1300 loss 46.686852 loss_att 53.412510 loss_ctc 59.132439 loss_rnnt 43.682308 lr 0.00097436 rank 3
2022-12-03 17:20:08,324 DEBUG TRAIN Batch 3/1300 loss 50.864357 loss_att 56.502262 loss_ctc 67.810303 loss_rnnt 47.477318 lr 0.00097453 rank 5
2022-12-03 17:20:08,324 DEBUG TRAIN Batch 3/1300 loss 46.503853 loss_att 55.106621 loss_ctc 67.169693 loss_rnnt 42.027851 lr 0.00097399 rank 2
2022-12-03 17:20:08,326 DEBUG TRAIN Batch 3/1300 loss 22.468716 loss_att 36.889225 loss_ctc 39.165115 loss_rnnt 17.358427 lr 0.00097479 rank 6
2022-12-03 17:20:08,329 DEBUG TRAIN Batch 3/1300 loss 50.003376 loss_att 61.201771 loss_ctc 77.816956 loss_rnnt 44.055214 lr 0.00097540 rank 4
2022-12-03 17:20:08,331 DEBUG TRAIN Batch 3/1300 loss 24.563267 loss_att 37.809135 loss_ctc 37.527187 loss_rnnt 20.185570 lr 0.00097442 rank 1
2022-12-03 17:20:08,333 DEBUG TRAIN Batch 3/1300 loss 18.343914 loss_att 18.685188 loss_ctc 21.705477 loss_rnnt 17.827452 lr 0.00097521 rank 7
2022-12-03 17:21:22,048 DEBUG TRAIN Batch 3/1400 loss 47.739544 loss_att 54.995419 loss_ctc 70.108139 loss_rnnt 43.305889 lr 0.00097215 rank 2
2022-12-03 17:21:22,053 DEBUG TRAIN Batch 3/1400 loss 32.711609 loss_att 47.280018 loss_ctc 47.466339 loss_rnnt 27.830631 lr 0.00097252 rank 3
2022-12-03 17:21:22,056 DEBUG TRAIN Batch 3/1400 loss 40.357643 loss_att 46.581493 loss_ctc 54.745281 loss_rnnt 37.194519 lr 0.00097274 rank 0
2022-12-03 17:21:22,058 DEBUG TRAIN Batch 3/1400 loss 30.027382 loss_att 37.449772 loss_ctc 37.383999 loss_rnnt 27.562023 lr 0.00097294 rank 6
2022-12-03 17:21:22,062 DEBUG TRAIN Batch 3/1400 loss 14.557756 loss_att 21.160639 loss_ctc 23.418552 loss_rnnt 12.055740 lr 0.00097336 rank 7
2022-12-03 17:21:22,063 DEBUG TRAIN Batch 3/1400 loss 29.656622 loss_att 40.283203 loss_ctc 42.288647 loss_rnnt 25.847036 lr 0.00097355 rank 4
2022-12-03 17:21:22,073 DEBUG TRAIN Batch 3/1400 loss 19.485445 loss_att 29.558872 loss_ctc 33.628628 loss_rnnt 15.585002 lr 0.00097257 rank 1
2022-12-03 17:21:22,112 DEBUG TRAIN Batch 3/1400 loss 37.181763 loss_att 43.558937 loss_ctc 58.832191 loss_rnnt 33.019604 lr 0.00097268 rank 5
2022-12-03 17:22:34,449 DEBUG TRAIN Batch 3/1500 loss 26.434927 loss_att 33.648632 loss_ctc 48.950676 loss_rnnt 21.990088 lr 0.00097110 rank 6
2022-12-03 17:22:34,450 DEBUG TRAIN Batch 3/1500 loss 46.149086 loss_att 58.959152 loss_ctc 60.616131 loss_rnnt 41.658134 lr 0.00097085 rank 5
2022-12-03 17:22:34,452 DEBUG TRAIN Batch 3/1500 loss 33.679203 loss_att 40.092804 loss_ctc 48.914246 loss_rnnt 30.365143 lr 0.00097068 rank 3
2022-12-03 17:22:34,455 DEBUG TRAIN Batch 3/1500 loss 39.462841 loss_att 50.045021 loss_ctc 66.209702 loss_rnnt 33.780159 lr 0.00097090 rank 0
2022-12-03 17:22:34,458 DEBUG TRAIN Batch 3/1500 loss 29.784416 loss_att 40.902668 loss_ctc 38.634892 loss_rnnt 26.380703 lr 0.00097032 rank 2
2022-12-03 17:22:34,459 DEBUG TRAIN Batch 3/1500 loss 35.055523 loss_att 38.016068 loss_ctc 53.894833 loss_rnnt 31.951504 lr 0.00097074 rank 1
2022-12-03 17:22:34,459 DEBUG TRAIN Batch 3/1500 loss 32.441574 loss_att 47.267567 loss_ctc 57.879189 loss_rnnt 26.084698 lr 0.00097171 rank 4
2022-12-03 17:22:34,513 DEBUG TRAIN Batch 3/1500 loss 46.610321 loss_att 59.182938 loss_ctc 78.787926 loss_rnnt 39.805450 lr 0.00097152 rank 7
2022-12-03 17:23:45,131 DEBUG TRAIN Batch 3/1600 loss 29.344692 loss_att 40.798874 loss_ctc 45.061222 loss_rnnt 24.958317 lr 0.00096908 rank 0
2022-12-03 17:23:45,133 DEBUG TRAIN Batch 3/1600 loss 33.165112 loss_att 41.179054 loss_ctc 52.968964 loss_rnnt 28.921808 lr 0.00096891 rank 1
2022-12-03 17:23:45,134 DEBUG TRAIN Batch 3/1600 loss 30.512394 loss_att 39.403111 loss_ctc 48.014046 loss_rnnt 26.400696 lr 0.00096902 rank 5
2022-12-03 17:23:45,134 DEBUG TRAIN Batch 3/1600 loss 29.899981 loss_att 39.525639 loss_ctc 49.763763 loss_rnnt 25.326344 lr 0.00096886 rank 3
2022-12-03 17:23:45,135 DEBUG TRAIN Batch 3/1600 loss 31.081089 loss_att 37.366089 loss_ctc 48.629513 loss_rnnt 27.484299 lr 0.00096928 rank 6
2022-12-03 17:23:45,140 DEBUG TRAIN Batch 3/1600 loss 37.876072 loss_att 43.519112 loss_ctc 57.612003 loss_rnnt 34.116005 lr 0.00096970 rank 7
2022-12-03 17:23:45,140 DEBUG TRAIN Batch 3/1600 loss 24.401348 loss_att 30.502567 loss_ctc 37.583168 loss_rnnt 21.423531 lr 0.00096849 rank 2
2022-12-03 17:23:45,141 DEBUG TRAIN Batch 3/1600 loss 51.127647 loss_att 60.694561 loss_ctc 75.373032 loss_rnnt 45.981548 lr 0.00096988 rank 4
2022-12-03 17:24:56,862 DEBUG TRAIN Batch 3/1700 loss 36.149281 loss_att 41.029552 loss_ctc 52.748699 loss_rnnt 32.959969 lr 0.00096721 rank 5
2022-12-03 17:24:56,861 DEBUG TRAIN Batch 3/1700 loss 43.086102 loss_att 50.296650 loss_ctc 59.614986 loss_rnnt 39.440140 lr 0.00096668 rank 2
2022-12-03 17:24:56,862 DEBUG TRAIN Batch 3/1700 loss 32.734482 loss_att 43.267296 loss_ctc 46.778835 loss_rnnt 28.755341 lr 0.00096746 rank 6
2022-12-03 17:24:56,863 DEBUG TRAIN Batch 3/1700 loss 28.442741 loss_att 33.119713 loss_ctc 39.473473 loss_rnnt 26.036583 lr 0.00096704 rank 3
2022-12-03 17:24:56,864 DEBUG TRAIN Batch 3/1700 loss 20.027458 loss_att 29.616680 loss_ctc 36.209415 loss_rnnt 15.952022 lr 0.00096788 rank 7
2022-12-03 17:24:56,864 DEBUG TRAIN Batch 3/1700 loss 28.333729 loss_att 38.990280 loss_ctc 51.267586 loss_rnnt 23.144571 lr 0.00096710 rank 1
2022-12-03 17:24:56,868 DEBUG TRAIN Batch 3/1700 loss 19.688557 loss_att 29.223389 loss_ctc 37.760658 loss_rnnt 15.371977 lr 0.00096726 rank 0
2022-12-03 17:24:56,877 DEBUG TRAIN Batch 3/1700 loss 27.482792 loss_att 35.301441 loss_ctc 36.174469 loss_rnnt 24.760174 lr 0.00096806 rank 4
2022-12-03 17:26:11,305 DEBUG TRAIN Batch 3/1800 loss 28.629169 loss_att 33.776962 loss_ctc 52.226654 loss_rnnt 24.453279 lr 0.00096565 rank 6
2022-12-03 17:26:11,305 DEBUG TRAIN Batch 3/1800 loss 16.665886 loss_att 26.537582 loss_ctc 32.100262 loss_rnnt 12.633628 lr 0.00096488 rank 2
2022-12-03 17:26:11,306 DEBUG TRAIN Batch 3/1800 loss 27.128813 loss_att 32.085300 loss_ctc 39.914539 loss_rnnt 24.432753 lr 0.00096546 rank 0
2022-12-03 17:26:11,305 DEBUG TRAIN Batch 3/1800 loss 29.852217 loss_att 36.539536 loss_ctc 43.752903 loss_rnnt 26.661329 lr 0.00096529 rank 1
2022-12-03 17:26:11,306 DEBUG TRAIN Batch 3/1800 loss 27.525681 loss_att 28.943741 loss_ctc 38.046383 loss_rnnt 25.839308 lr 0.00096524 rank 3
2022-12-03 17:26:11,306 DEBUG TRAIN Batch 3/1800 loss 46.834354 loss_att 53.887241 loss_ctc 64.306175 loss_rnnt 43.094196 lr 0.00096607 rank 7
2022-12-03 17:26:11,310 DEBUG TRAIN Batch 3/1800 loss 16.719694 loss_att 24.167469 loss_ctc 22.992521 loss_rnnt 14.393761 lr 0.00096625 rank 4
2022-12-03 17:26:11,353 DEBUG TRAIN Batch 3/1800 loss 39.049427 loss_att 43.585476 loss_ctc 57.724895 loss_rnnt 35.652157 lr 0.00096540 rank 5
2022-12-03 17:27:23,484 DEBUG TRAIN Batch 3/1900 loss 37.470009 loss_att 46.573238 loss_ctc 58.508148 loss_rnnt 32.844276 lr 0.00096361 rank 5
2022-12-03 17:27:23,483 DEBUG TRAIN Batch 3/1900 loss 20.236368 loss_att 25.169554 loss_ctc 34.428326 loss_rnnt 17.357471 lr 0.00096427 rank 7
2022-12-03 17:27:23,485 DEBUG TRAIN Batch 3/1900 loss 22.495646 loss_att 23.338076 loss_ctc 28.223680 loss_rnnt 21.563421 lr 0.00096345 rank 3
2022-12-03 17:27:23,486 DEBUG TRAIN Batch 3/1900 loss 21.121414 loss_att 23.217804 loss_ctc 29.593775 loss_rnnt 19.572487 lr 0.00096366 rank 0
2022-12-03 17:27:23,486 DEBUG TRAIN Batch 3/1900 loss 39.086193 loss_att 51.945045 loss_ctc 45.711929 loss_rnnt 35.630989 lr 0.00096350 rank 1
2022-12-03 17:27:23,489 DEBUG TRAIN Batch 3/1900 loss 26.979952 loss_att 33.112385 loss_ctc 38.557568 loss_rnnt 24.209784 lr 0.00096386 rank 6
2022-12-03 17:27:23,490 DEBUG TRAIN Batch 3/1900 loss 40.800339 loss_att 55.957836 loss_ctc 67.761513 loss_rnnt 34.174015 lr 0.00096309 rank 2
2022-12-03 17:27:23,500 DEBUG TRAIN Batch 3/1900 loss 20.267431 loss_att 20.954327 loss_ctc 27.548304 loss_rnnt 19.159269 lr 0.00096445 rank 4
2022-12-03 17:28:35,065 DEBUG TRAIN Batch 3/2000 loss 45.797401 loss_att 55.296764 loss_ctc 69.935059 loss_rnnt 40.679176 lr 0.00096207 rank 6
2022-12-03 17:28:35,064 DEBUG TRAIN Batch 3/2000 loss 60.877060 loss_att 75.719330 loss_ctc 90.944565 loss_rnnt 53.899605 lr 0.00096188 rank 0
2022-12-03 17:28:35,067 DEBUG TRAIN Batch 3/2000 loss 9.067829 loss_att 21.490406 loss_ctc 23.087881 loss_rnnt 4.713973 lr 0.00096248 rank 7
2022-12-03 17:28:35,069 DEBUG TRAIN Batch 3/2000 loss 16.416239 loss_att 25.217052 loss_ctc 28.881878 loss_rnnt 12.993991 lr 0.00096166 rank 3
2022-12-03 17:28:35,070 DEBUG TRAIN Batch 3/2000 loss 33.918724 loss_att 43.956779 loss_ctc 45.947781 loss_rnnt 30.307241 lr 0.00096182 rank 5
2022-12-03 17:28:35,071 DEBUG TRAIN Batch 3/2000 loss 27.744770 loss_att 38.029484 loss_ctc 43.085152 loss_rnnt 23.642441 lr 0.00096131 rank 2
2022-12-03 17:28:35,073 DEBUG TRAIN Batch 3/2000 loss 40.909771 loss_att 47.455338 loss_ctc 62.305706 loss_rnnt 36.747864 lr 0.00096172 rank 1
2022-12-03 17:28:35,073 DEBUG TRAIN Batch 3/2000 loss 46.882706 loss_att 57.527321 loss_ctc 61.280602 loss_rnnt 42.834068 lr 0.00096266 rank 4
2022-12-03 17:29:48,619 DEBUG TRAIN Batch 3/2100 loss 35.988995 loss_att 45.292301 loss_ctc 51.567352 loss_rnnt 32.051220 lr 0.00095994 rank 1
2022-12-03 17:29:48,620 DEBUG TRAIN Batch 3/2100 loss 33.774353 loss_att 39.884357 loss_ctc 48.293819 loss_rnnt 30.616425 lr 0.00096030 rank 6
2022-12-03 17:29:48,622 DEBUG TRAIN Batch 3/2100 loss 30.686522 loss_att 38.976334 loss_ctc 51.641354 loss_rnnt 26.234581 lr 0.00096010 rank 0
2022-12-03 17:29:48,622 DEBUG TRAIN Batch 3/2100 loss 23.464802 loss_att 35.459175 loss_ctc 33.861935 loss_rnnt 19.679642 lr 0.00095989 rank 3
2022-12-03 17:29:48,623 DEBUG TRAIN Batch 3/2100 loss 51.094604 loss_att 57.174629 loss_ctc 83.935257 loss_rnnt 45.499847 lr 0.00096005 rank 5
2022-12-03 17:29:48,624 DEBUG TRAIN Batch 3/2100 loss 23.453617 loss_att 31.380466 loss_ctc 38.183899 loss_rnnt 19.904211 lr 0.00095954 rank 2
2022-12-03 17:29:48,631 DEBUG TRAIN Batch 3/2100 loss 42.746010 loss_att 47.350086 loss_ctc 51.152374 loss_rnnt 40.704346 lr 0.00096088 rank 4
2022-12-03 17:29:48,646 DEBUG TRAIN Batch 3/2100 loss 28.303003 loss_att 44.519878 loss_ctc 40.364639 loss_rnnt 23.451408 lr 0.00096070 rank 7
2022-12-03 17:31:01,179 DEBUG TRAIN Batch 3/2200 loss 38.031574 loss_att 49.488544 loss_ctc 58.492107 loss_rnnt 33.012108 lr 0.00095834 rank 0
2022-12-03 17:31:01,181 DEBUG TRAIN Batch 3/2200 loss 34.181545 loss_att 38.100471 loss_ctc 53.409248 loss_rnnt 30.834064 lr 0.00095818 rank 1
2022-12-03 17:31:01,183 DEBUG TRAIN Batch 3/2200 loss 37.767292 loss_att 47.398216 loss_ctc 54.238022 loss_rnnt 33.645008 lr 0.00095853 rank 6
2022-12-03 17:31:01,183 DEBUG TRAIN Batch 3/2200 loss 18.968155 loss_att 27.754585 loss_ctc 26.633558 loss_rnnt 16.188814 lr 0.00095894 rank 7
2022-12-03 17:31:01,185 DEBUG TRAIN Batch 3/2200 loss 32.465939 loss_att 40.620808 loss_ctc 60.002052 loss_rnnt 27.163483 lr 0.00095813 rank 3
2022-12-03 17:31:01,186 DEBUG TRAIN Batch 3/2200 loss 46.813137 loss_att 54.046928 loss_ctc 55.094322 loss_rnnt 44.262215 lr 0.00095777 rank 2
2022-12-03 17:31:01,188 DEBUG TRAIN Batch 3/2200 loss 37.934181 loss_att 43.168228 loss_ctc 49.658966 loss_rnnt 35.324066 lr 0.00095828 rank 5
2022-12-03 17:31:01,198 DEBUG TRAIN Batch 3/2200 loss 36.723625 loss_att 49.495476 loss_ctc 60.593407 loss_rnnt 30.986616 lr 0.00095911 rank 4
2022-12-03 17:32:12,857 DEBUG TRAIN Batch 3/2300 loss 31.330521 loss_att 41.074829 loss_ctc 51.498955 loss_rnnt 26.692535 lr 0.00095677 rank 6
2022-12-03 17:32:12,858 DEBUG TRAIN Batch 3/2300 loss 24.415483 loss_att 29.094616 loss_ctc 35.117245 loss_rnnt 22.052755 lr 0.00095642 rank 1
2022-12-03 17:32:12,860 DEBUG TRAIN Batch 3/2300 loss 19.703434 loss_att 26.456215 loss_ctc 28.536797 loss_rnnt 17.175095 lr 0.00095653 rank 5
2022-12-03 17:32:12,861 DEBUG TRAIN Batch 3/2300 loss 31.359098 loss_att 44.564705 loss_ctc 54.876583 loss_rnnt 25.582314 lr 0.00095718 rank 7
2022-12-03 17:32:12,862 DEBUG TRAIN Batch 3/2300 loss 26.727411 loss_att 30.572182 loss_ctc 39.344185 loss_rnnt 24.276222 lr 0.00095658 rank 0
2022-12-03 17:32:12,866 DEBUG TRAIN Batch 3/2300 loss 83.343735 loss_att 86.165161 loss_ctc 106.431381 loss_rnnt 79.701103 lr 0.00095637 rank 3
2022-12-03 17:32:12,868 DEBUG TRAIN Batch 3/2300 loss 40.381367 loss_att 45.673031 loss_ctc 56.313690 loss_rnnt 37.198719 lr 0.00095602 rank 2
2022-12-03 17:32:12,869 DEBUG TRAIN Batch 3/2300 loss 42.228897 loss_att 53.600296 loss_ctc 54.973499 loss_rnnt 38.255333 lr 0.00095735 rank 4
2022-12-03 17:33:24,818 DEBUG TRAIN Batch 3/2400 loss 25.347969 loss_att 36.759220 loss_ctc 42.397625 loss_rnnt 20.792431 lr 0.00095478 rank 5
2022-12-03 17:33:24,818 DEBUG TRAIN Batch 3/2400 loss 33.944870 loss_att 42.567112 loss_ctc 50.597321 loss_rnnt 30.000097 lr 0.00095503 rank 6
2022-12-03 17:33:24,822 DEBUG TRAIN Batch 3/2400 loss 40.026024 loss_att 49.318283 loss_ctc 59.631466 loss_rnnt 35.553513 lr 0.00095463 rank 3
2022-12-03 17:33:24,822 DEBUG TRAIN Batch 3/2400 loss 47.193974 loss_att 49.838795 loss_ctc 66.981804 loss_rnnt 44.026634 lr 0.00095484 rank 0
2022-12-03 17:33:24,829 DEBUG TRAIN Batch 3/2400 loss 31.643045 loss_att 39.494080 loss_ctc 49.937660 loss_rnnt 27.633554 lr 0.00095468 rank 1
2022-12-03 17:33:24,838 DEBUG TRAIN Batch 3/2400 loss 26.846554 loss_att 40.434372 loss_ctc 41.292778 loss_rnnt 22.202824 lr 0.00095543 rank 7
2022-12-03 17:33:24,855 DEBUG TRAIN Batch 3/2400 loss 37.541679 loss_att 45.375736 loss_ctc 62.030231 loss_rnnt 32.709724 lr 0.00095428 rank 2
2022-12-03 17:33:24,863 DEBUG TRAIN Batch 3/2400 loss 57.141335 loss_att 63.060162 loss_ctc 77.957436 loss_rnnt 53.182087 lr 0.00095560 rank 4
2022-12-03 17:34:39,634 DEBUG TRAIN Batch 3/2500 loss 48.975510 loss_att 52.724121 loss_ctc 68.905052 loss_rnnt 45.568512 lr 0.00095329 rank 6
2022-12-03 17:34:39,635 DEBUG TRAIN Batch 3/2500 loss 15.301906 loss_att 20.192694 loss_ctc 27.548855 loss_rnnt 12.690822 lr 0.00095310 rank 0
2022-12-03 17:34:39,635 DEBUG TRAIN Batch 3/2500 loss 21.581337 loss_att 26.327600 loss_ctc 31.359444 loss_rnnt 19.328337 lr 0.00095305 rank 5
2022-12-03 17:34:39,638 DEBUG TRAIN Batch 3/2500 loss 35.013733 loss_att 43.021740 loss_ctc 53.131054 loss_rnnt 30.996485 lr 0.00095369 rank 7
2022-12-03 17:34:39,643 DEBUG TRAIN Batch 3/2500 loss 21.933420 loss_att 27.110950 loss_ctc 33.958527 loss_rnnt 19.294565 lr 0.00095289 rank 3
2022-12-03 17:34:39,644 DEBUG TRAIN Batch 3/2500 loss 19.489325 loss_att 20.753872 loss_ctc 30.397833 loss_rnnt 17.781948 lr 0.00095294 rank 1
2022-12-03 17:34:39,649 DEBUG TRAIN Batch 3/2500 loss 29.070961 loss_att 33.096218 loss_ctc 47.218742 loss_rnnt 25.846205 lr 0.00095386 rank 4
2022-12-03 17:34:39,696 DEBUG TRAIN Batch 3/2500 loss 44.456127 loss_att 52.977089 loss_ctc 61.282543 loss_rnnt 40.508411 lr 0.00095255 rank 2
2022-12-03 17:35:51,411 DEBUG TRAIN Batch 3/2600 loss 18.353409 loss_att 26.051815 loss_ctc 29.253071 loss_rnnt 15.360439 lr 0.00095117 rank 3
2022-12-03 17:35:51,414 DEBUG TRAIN Batch 3/2600 loss 29.340025 loss_att 38.348282 loss_ctc 43.213402 loss_rnnt 25.688589 lr 0.00095122 rank 1
2022-12-03 17:35:51,415 DEBUG TRAIN Batch 3/2600 loss 18.777828 loss_att 20.631535 loss_ctc 25.091864 loss_rnnt 17.565214 lr 0.00095156 rank 6
2022-12-03 17:35:51,419 DEBUG TRAIN Batch 3/2600 loss 32.112019 loss_att 41.190987 loss_ctc 46.046326 loss_rnnt 28.438314 lr 0.00095213 rank 4
2022-12-03 17:35:51,423 DEBUG TRAIN Batch 3/2600 loss 51.857502 loss_att 65.778122 loss_ctc 73.282669 loss_rnnt 46.216690 lr 0.00095137 rank 0
2022-12-03 17:35:51,425 DEBUG TRAIN Batch 3/2600 loss 19.486856 loss_att 25.582645 loss_ctc 37.884171 loss_rnnt 15.814724 lr 0.00095196 rank 7
2022-12-03 17:35:51,438 DEBUG TRAIN Batch 3/2600 loss 44.228695 loss_att 50.943985 loss_ctc 64.816208 loss_rnnt 40.140633 lr 0.00095082 rank 2
2022-12-03 17:35:51,447 DEBUG TRAIN Batch 3/2600 loss 40.259003 loss_att 47.443390 loss_ctc 59.306023 loss_rnnt 36.282524 lr 0.00095132 rank 5
2022-12-03 17:37:04,028 DEBUG TRAIN Batch 3/2700 loss 69.809998 loss_att 75.769981 loss_ctc 89.080948 loss_rnnt 66.048538 lr 0.00094965 rank 0
2022-12-03 17:37:04,030 DEBUG TRAIN Batch 3/2700 loss 18.716953 loss_att 31.975216 loss_ctc 30.910145 loss_rnnt 14.439543 lr 0.00095024 rank 7
2022-12-03 17:37:04,031 DEBUG TRAIN Batch 3/2700 loss 24.218849 loss_att 36.361687 loss_ctc 41.331955 loss_rnnt 19.508532 lr 0.00094984 rank 6
2022-12-03 17:37:04,031 DEBUG TRAIN Batch 3/2700 loss 30.818392 loss_att 37.850510 loss_ctc 45.614174 loss_rnnt 27.439198 lr 0.00094950 rank 1
2022-12-03 17:37:04,033 DEBUG TRAIN Batch 3/2700 loss 41.591991 loss_att 45.620399 loss_ctc 55.033791 loss_rnnt 38.994068 lr 0.00094960 rank 5
2022-12-03 17:37:04,035 DEBUG TRAIN Batch 3/2700 loss 28.385485 loss_att 33.111874 loss_ctc 36.272247 loss_rnnt 26.388639 lr 0.00094911 rank 2
2022-12-03 17:37:04,038 DEBUG TRAIN Batch 3/2700 loss 26.844284 loss_att 37.829506 loss_ctc 49.023438 loss_rnnt 21.690018 lr 0.00094945 rank 3
2022-12-03 17:37:04,079 DEBUG TRAIN Batch 3/2700 loss 79.803078 loss_att 87.178986 loss_ctc 111.319504 loss_rnnt 74.125702 lr 0.00095041 rank 4
2022-12-03 17:38:17,441 DEBUG TRAIN Batch 3/2800 loss 27.731609 loss_att 35.682678 loss_ctc 39.809677 loss_rnnt 24.530987 lr 0.00094870 rank 4
2022-12-03 17:38:17,443 DEBUG TRAIN Batch 3/2800 loss 43.610527 loss_att 54.646305 loss_ctc 68.938736 loss_rnnt 38.026276 lr 0.00094813 rank 6
2022-12-03 17:38:17,444 DEBUG TRAIN Batch 3/2800 loss 26.228617 loss_att 32.778484 loss_ctc 43.028286 loss_rnnt 22.678686 lr 0.00094795 rank 0
2022-12-03 17:38:17,445 DEBUG TRAIN Batch 3/2800 loss 38.417366 loss_att 44.763687 loss_ctc 51.671867 loss_rnnt 35.380836 lr 0.00094779 rank 1
2022-12-03 17:38:17,451 DEBUG TRAIN Batch 3/2800 loss 25.757828 loss_att 32.535557 loss_ctc 46.140678 loss_rnnt 21.684568 lr 0.00094774 rank 3
2022-12-03 17:38:17,463 DEBUG TRAIN Batch 3/2800 loss 38.848454 loss_att 41.636234 loss_ctc 54.954453 loss_rnnt 36.143433 lr 0.00094740 rank 2
2022-12-03 17:38:17,477 DEBUG TRAIN Batch 3/2800 loss 19.565493 loss_att 33.559868 loss_ctc 35.887695 loss_rnnt 14.590323 lr 0.00094789 rank 5
2022-12-03 17:38:17,486 DEBUG TRAIN Batch 3/2800 loss 17.586693 loss_att 25.692883 loss_ctc 28.424307 loss_rnnt 14.520439 lr 0.00094853 rank 7
2022-12-03 17:39:30,606 DEBUG TRAIN Batch 3/2900 loss 32.007706 loss_att 38.802959 loss_ctc 48.414955 loss_rnnt 28.461023 lr 0.00094625 rank 0
2022-12-03 17:39:30,608 DEBUG TRAIN Batch 3/2900 loss 29.125080 loss_att 40.474190 loss_ctc 48.492851 loss_rnnt 24.272888 lr 0.00094604 rank 3
2022-12-03 17:39:30,609 DEBUG TRAIN Batch 3/2900 loss 38.895996 loss_att 46.341194 loss_ctc 55.127350 loss_rnnt 35.242779 lr 0.00094643 rank 6
2022-12-03 17:39:30,612 DEBUG TRAIN Batch 3/2900 loss 42.760456 loss_att 45.695541 loss_ctc 62.923798 loss_rnnt 39.484989 lr 0.00094571 rank 2
2022-12-03 17:39:30,612 DEBUG TRAIN Batch 3/2900 loss 48.727459 loss_att 52.081097 loss_ctc 68.618301 loss_rnnt 45.404617 lr 0.00094609 rank 1
2022-12-03 17:39:30,613 DEBUG TRAIN Batch 3/2900 loss 29.861521 loss_att 36.957348 loss_ctc 48.394569 loss_rnnt 25.971283 lr 0.00094620 rank 5
2022-12-03 17:39:30,614 DEBUG TRAIN Batch 3/2900 loss 21.364571 loss_att 28.543016 loss_ctc 32.285255 loss_rnnt 18.472790 lr 0.00094699 rank 4
2022-12-03 17:39:30,664 DEBUG TRAIN Batch 3/2900 loss 46.275875 loss_att 50.601650 loss_ctc 61.857407 loss_rnnt 43.333183 lr 0.00094682 rank 7
2022-12-03 17:40:41,954 DEBUG TRAIN Batch 3/3000 loss 37.964966 loss_att 47.615185 loss_ctc 58.263573 loss_rnnt 33.328442 lr 0.00094474 rank 6
2022-12-03 17:40:41,956 DEBUG TRAIN Batch 3/3000 loss 35.104584 loss_att 41.556118 loss_ctc 50.455666 loss_rnnt 31.767466 lr 0.00094456 rank 0
2022-12-03 17:40:41,957 DEBUG TRAIN Batch 3/3000 loss 44.267662 loss_att 48.452805 loss_ctc 63.236740 loss_rnnt 40.901421 lr 0.00094402 rank 2
2022-12-03 17:40:41,957 DEBUG TRAIN Batch 3/3000 loss 27.952501 loss_att 34.538826 loss_ctc 45.599205 loss_rnnt 24.282341 lr 0.00094441 rank 1
2022-12-03 17:40:41,957 DEBUG TRAIN Batch 3/3000 loss 19.555498 loss_att 26.053934 loss_ctc 33.099945 loss_rnnt 16.449884 lr 0.00094435 rank 3
2022-12-03 17:40:41,962 DEBUG TRAIN Batch 3/3000 loss 20.931402 loss_att 27.042957 loss_ctc 33.569221 loss_rnnt 18.024048 lr 0.00094513 rank 7
2022-12-03 17:40:41,963 DEBUG TRAIN Batch 3/3000 loss 39.264713 loss_att 44.683167 loss_ctc 50.793121 loss_rnnt 36.643898 lr 0.00094451 rank 5
2022-12-03 17:40:41,964 DEBUG TRAIN Batch 3/3000 loss 35.009781 loss_att 41.744518 loss_ctc 52.509872 loss_rnnt 31.329485 lr 0.00094530 rank 4
2022-12-03 17:41:53,917 DEBUG TRAIN Batch 3/3100 loss 20.546429 loss_att 25.520660 loss_ctc 38.376595 loss_rnnt 17.174229 lr 0.00094273 rank 1
2022-12-03 17:41:53,918 DEBUG TRAIN Batch 3/3100 loss 20.131769 loss_att 26.701836 loss_ctc 31.502340 loss_rnnt 17.301680 lr 0.00094288 rank 0
2022-12-03 17:41:53,920 DEBUG TRAIN Batch 3/3100 loss 29.592381 loss_att 34.629547 loss_ctc 48.516273 loss_rnnt 26.061762 lr 0.00094283 rank 5
2022-12-03 17:41:53,923 DEBUG TRAIN Batch 3/3100 loss 20.324030 loss_att 28.290989 loss_ctc 33.702129 loss_rnnt 16.946892 lr 0.00094267 rank 3
2022-12-03 17:41:53,924 DEBUG TRAIN Batch 3/3100 loss 32.394989 loss_att 35.528961 loss_ctc 40.152309 loss_rnnt 30.733883 lr 0.00094306 rank 6
2022-12-03 17:41:53,928 DEBUG TRAIN Batch 3/3100 loss 39.827995 loss_att 46.181290 loss_ctc 62.969826 loss_rnnt 35.471760 lr 0.00094345 rank 7
2022-12-03 17:41:53,931 DEBUG TRAIN Batch 3/3100 loss 23.937138 loss_att 33.044006 loss_ctc 39.131863 loss_rnnt 20.089802 lr 0.00094361 rank 4
2022-12-03 17:41:53,977 DEBUG TRAIN Batch 3/3100 loss 22.550869 loss_att 23.606459 loss_ctc 32.193340 loss_rnnt 21.054087 lr 0.00094234 rank 2
2022-12-03 17:43:08,821 DEBUG TRAIN Batch 3/3200 loss 34.200233 loss_att 36.632317 loss_ctc 49.658215 loss_rnnt 31.652754 lr 0.00094139 rank 6
2022-12-03 17:43:08,823 DEBUG TRAIN Batch 3/3200 loss 40.262951 loss_att 54.048988 loss_ctc 59.183407 loss_rnnt 34.983017 lr 0.00094120 rank 0
2022-12-03 17:43:08,824 DEBUG TRAIN Batch 3/3200 loss 29.092606 loss_att 37.337257 loss_ctc 47.293442 loss_rnnt 25.016897 lr 0.00094100 rank 3
2022-12-03 17:43:08,825 DEBUG TRAIN Batch 3/3200 loss 18.800110 loss_att 22.595070 loss_ctc 30.940626 loss_rnnt 16.422380 lr 0.00094115 rank 5
2022-12-03 17:43:08,831 DEBUG TRAIN Batch 3/3200 loss 46.316963 loss_att 49.702763 loss_ctc 63.627380 loss_rnnt 43.331749 lr 0.00094105 rank 1
2022-12-03 17:43:08,833 DEBUG TRAIN Batch 3/3200 loss 35.770672 loss_att 41.095226 loss_ctc 53.498791 loss_rnnt 32.342010 lr 0.00094067 rank 2
2022-12-03 17:43:08,862 DEBUG TRAIN Batch 3/3200 loss 28.733431 loss_att 36.513515 loss_ctc 45.018658 loss_rnnt 25.006050 lr 0.00094194 rank 4
2022-12-03 17:43:08,880 DEBUG TRAIN Batch 3/3200 loss 14.102589 loss_att 16.304819 loss_ctc 18.915577 loss_rnnt 13.020410 lr 0.00094177 rank 7
2022-12-03 17:44:22,007 DEBUG TRAIN Batch 3/3300 loss 24.281094 loss_att 33.117374 loss_ctc 34.095352 loss_rnnt 21.205269 lr 0.00093954 rank 0
2022-12-03 17:44:22,007 DEBUG TRAIN Batch 3/3300 loss 38.482185 loss_att 48.777767 loss_ctc 61.255672 loss_rnnt 33.386604 lr 0.00093901 rank 2
2022-12-03 17:44:22,009 DEBUG TRAIN Batch 3/3300 loss 33.404194 loss_att 38.904350 loss_ctc 48.705360 loss_rnnt 30.264008 lr 0.00093972 rank 6
2022-12-03 17:44:22,010 DEBUG TRAIN Batch 3/3300 loss 17.709064 loss_att 25.345654 loss_ctc 27.807217 loss_rnnt 14.835327 lr 0.00093934 rank 3
2022-12-03 17:44:22,010 DEBUG TRAIN Batch 3/3300 loss 78.939896 loss_att 84.296051 loss_ctc 105.562462 loss_rnnt 74.318993 lr 0.00093939 rank 1
2022-12-03 17:44:22,013 DEBUG TRAIN Batch 3/3300 loss 42.220631 loss_att 45.814262 loss_ctc 66.926460 loss_rnnt 38.207794 lr 0.00094011 rank 7
2022-12-03 17:44:22,014 DEBUG TRAIN Batch 3/3300 loss 53.667721 loss_att 69.548065 loss_ctc 68.793549 loss_rnnt 48.474876 lr 0.00093949 rank 5
2022-12-03 17:44:22,062 DEBUG TRAIN Batch 3/3300 loss 41.963242 loss_att 52.355232 loss_ctc 67.004684 loss_rnnt 36.545979 lr 0.00094027 rank 4
2022-12-03 17:45:34,736 DEBUG TRAIN Batch 3/3400 loss 25.247772 loss_att 34.510696 loss_ctc 41.103584 loss_rnnt 21.281076 lr 0.00093769 rank 3
2022-12-03 17:45:34,739 DEBUG TRAIN Batch 3/3400 loss 32.571938 loss_att 38.818359 loss_ctc 50.237942 loss_rnnt 28.967186 lr 0.00093807 rank 6
2022-12-03 17:45:34,740 DEBUG TRAIN Batch 3/3400 loss 26.856319 loss_att 33.728043 loss_ctc 41.842052 loss_rnnt 23.483877 lr 0.00093789 rank 0
2022-12-03 17:45:34,744 DEBUG TRAIN Batch 3/3400 loss 23.337677 loss_att 37.853600 loss_ctc 33.286385 loss_rnnt 19.107998 lr 0.00093784 rank 5
2022-12-03 17:45:34,748 DEBUG TRAIN Batch 3/3400 loss 40.032642 loss_att 46.992367 loss_ctc 57.454021 loss_rnnt 36.317848 lr 0.00093736 rank 2
2022-12-03 17:45:34,749 DEBUG TRAIN Batch 3/3400 loss 42.793087 loss_att 49.804058 loss_ctc 65.246414 loss_rnnt 38.397118 lr 0.00093845 rank 7
2022-12-03 17:45:34,751 DEBUG TRAIN Batch 3/3400 loss 31.568493 loss_att 42.776512 loss_ctc 47.371471 loss_rnnt 27.219826 lr 0.00093774 rank 1
2022-12-03 17:45:34,798 DEBUG TRAIN Batch 3/3400 loss 41.403610 loss_att 53.184875 loss_ctc 57.195583 loss_rnnt 36.941765 lr 0.00093861 rank 4
2022-12-03 17:46:47,670 DEBUG TRAIN Batch 3/3500 loss 27.443476 loss_att 36.717461 loss_ctc 48.901627 loss_rnnt 22.727589 lr 0.00093572 rank 2
2022-12-03 17:46:47,681 DEBUG TRAIN Batch 3/3500 loss 32.292938 loss_att 38.211861 loss_ctc 51.892406 loss_rnnt 28.495890 lr 0.00093609 rank 1
2022-12-03 17:46:47,681 DEBUG TRAIN Batch 3/3500 loss 19.798965 loss_att 30.089544 loss_ctc 33.865181 loss_rnnt 15.865355 lr 0.00093604 rank 3
2022-12-03 17:46:47,686 DEBUG TRAIN Batch 3/3500 loss 15.174818 loss_att 21.312386 loss_ctc 23.163116 loss_rnnt 12.882198 lr 0.00093624 rank 0
2022-12-03 17:46:47,686 DEBUG TRAIN Batch 3/3500 loss 37.739727 loss_att 55.201641 loss_ctc 59.564495 loss_rnnt 31.337374 lr 0.00093619 rank 5
2022-12-03 17:46:47,686 DEBUG TRAIN Batch 3/3500 loss 38.715000 loss_att 47.829926 loss_ctc 58.868347 loss_rnnt 34.204903 lr 0.00093642 rank 6
2022-12-03 17:46:47,689 DEBUG TRAIN Batch 3/3500 loss 34.004261 loss_att 43.419323 loss_ctc 60.889442 loss_rnnt 28.536558 lr 0.00093680 rank 7
2022-12-03 17:46:48,103 DEBUG TRAIN Batch 3/3500 loss 42.455898 loss_att 44.198166 loss_ctc 58.734970 loss_rnnt 39.936897 lr 0.00093696 rank 4
2022-12-03 17:48:01,255 DEBUG TRAIN Batch 3/3600 loss 28.788643 loss_att 36.101566 loss_ctc 44.445374 loss_rnnt 25.238493 lr 0.00093446 rank 1
2022-12-03 17:48:01,264 DEBUG TRAIN Batch 3/3600 loss 28.673271 loss_att 37.465584 loss_ctc 46.871429 loss_rnnt 24.488388 lr 0.00093408 rank 2
2022-12-03 17:48:01,272 DEBUG TRAIN Batch 3/3600 loss 33.264595 loss_att 41.463158 loss_ctc 62.725212 loss_rnnt 27.696798 lr 0.00093516 rank 7
2022-12-03 17:48:01,273 DEBUG TRAIN Batch 3/3600 loss 41.602661 loss_att 49.895912 loss_ctc 62.066177 loss_rnnt 37.215542 lr 0.00093478 rank 6
2022-12-03 17:48:01,277 DEBUG TRAIN Batch 3/3600 loss 23.160587 loss_att 30.701462 loss_ctc 36.051296 loss_rnnt 19.933651 lr 0.00093460 rank 0
2022-12-03 17:48:01,277 DEBUG TRAIN Batch 3/3600 loss 20.890347 loss_att 29.866631 loss_ctc 32.891655 loss_rnnt 17.494915 lr 0.00093441 rank 3
2022-12-03 17:48:01,284 DEBUG TRAIN Batch 3/3600 loss 17.197851 loss_att 20.982548 loss_ctc 24.222282 loss_rnnt 15.504319 lr 0.00093532 rank 4
2022-12-03 17:48:01,298 DEBUG TRAIN Batch 3/3600 loss 32.959953 loss_att 42.580597 loss_ctc 50.595032 loss_rnnt 28.684479 lr 0.00093455 rank 5
2022-12-03 17:49:12,553 DEBUG TRAIN Batch 3/3700 loss 21.544729 loss_att 31.301361 loss_ctc 36.138233 loss_rnnt 17.647602 lr 0.00093278 rank 3
2022-12-03 17:49:12,553 DEBUG TRAIN Batch 3/3700 loss 38.493721 loss_att 41.406952 loss_ctc 48.716812 loss_rnnt 36.547997 lr 0.00093315 rank 6
2022-12-03 17:49:12,555 DEBUG TRAIN Batch 3/3700 loss 19.299721 loss_att 25.095928 loss_ctc 35.839840 loss_rnnt 15.935128 lr 0.00093353 rank 7
2022-12-03 17:49:12,555 DEBUG TRAIN Batch 3/3700 loss 15.440280 loss_att 21.094372 loss_ctc 21.242779 loss_rnnt 13.535795 lr 0.00093293 rank 5
2022-12-03 17:49:12,555 DEBUG TRAIN Batch 3/3700 loss 24.988487 loss_att 28.226749 loss_ctc 36.004646 loss_rnnt 22.872013 lr 0.00093298 rank 0
2022-12-03 17:49:12,557 DEBUG TRAIN Batch 3/3700 loss 28.549290 loss_att 32.269039 loss_ctc 41.568867 loss_rnnt 26.069397 lr 0.00093283 rank 1
2022-12-03 17:49:12,562 DEBUG TRAIN Batch 3/3700 loss 32.021694 loss_att 34.838135 loss_ctc 47.262794 loss_rnnt 29.426260 lr 0.00093246 rank 2
2022-12-03 17:49:12,566 DEBUG TRAIN Batch 3/3700 loss 27.476360 loss_att 34.291435 loss_ctc 40.583088 loss_rnnt 24.365782 lr 0.00093369 rank 4
2022-12-03 17:50:24,837 DEBUG TRAIN Batch 3/3800 loss 33.735085 loss_att 37.334366 loss_ctc 45.119244 loss_rnnt 31.497343 lr 0.00093191 rank 7
2022-12-03 17:50:24,838 DEBUG TRAIN Batch 3/3800 loss 12.271037 loss_att 18.063753 loss_ctc 21.130987 loss_rnnt 9.931167 lr 0.00093153 rank 6
2022-12-03 17:50:24,837 DEBUG TRAIN Batch 3/3800 loss 21.352772 loss_att 28.364948 loss_ctc 29.714367 loss_rnnt 18.835457 lr 0.00093121 rank 1
2022-12-03 17:50:24,839 DEBUG TRAIN Batch 3/3800 loss 26.893196 loss_att 27.412121 loss_ctc 32.589050 loss_rnnt 26.029963 lr 0.00093136 rank 0
2022-12-03 17:50:24,843 DEBUG TRAIN Batch 3/3800 loss 18.635454 loss_att 21.188520 loss_ctc 28.124744 loss_rnnt 16.859602 lr 0.00093131 rank 5
2022-12-03 17:50:24,843 DEBUG TRAIN Batch 3/3800 loss 19.507923 loss_att 21.881210 loss_ctc 27.286499 loss_rnnt 17.996122 lr 0.00093084 rank 2
2022-12-03 17:50:24,846 DEBUG TRAIN Batch 3/3800 loss 26.757782 loss_att 39.266304 loss_ctc 51.034660 loss_rnnt 21.019159 lr 0.00093207 rank 4
2022-12-03 17:50:24,848 DEBUG TRAIN Batch 3/3800 loss 27.361544 loss_att 43.304356 loss_ctc 44.596375 loss_rnnt 21.875006 lr 0.00093116 rank 3
2022-12-03 17:51:38,904 DEBUG TRAIN Batch 3/3900 loss 33.670330 loss_att 42.655010 loss_ctc 51.567169 loss_rnnt 29.487148 lr 0.00092960 rank 1
2022-12-03 17:51:38,905 DEBUG TRAIN Batch 3/3900 loss 37.100239 loss_att 48.816597 loss_ctc 49.521324 loss_rnnt 33.100822 lr 0.00092992 rank 6
2022-12-03 17:51:38,916 DEBUG TRAIN Batch 3/3900 loss 46.124046 loss_att 50.541397 loss_ctc 55.669128 loss_rnnt 43.967896 lr 0.00092955 rank 3
2022-12-03 17:51:38,919 DEBUG TRAIN Batch 3/3900 loss 19.058151 loss_att 32.338295 loss_ctc 37.046040 loss_rnnt 14.003738 lr 0.00092974 rank 0
2022-12-03 17:51:38,919 DEBUG TRAIN Batch 3/3900 loss 27.810410 loss_att 35.236359 loss_ctc 43.268612 loss_rnnt 24.264128 lr 0.00092970 rank 5
2022-12-03 17:51:38,921 DEBUG TRAIN Batch 3/3900 loss 18.354542 loss_att 25.439159 loss_ctc 27.896893 loss_rnnt 15.665306 lr 0.00093029 rank 7
2022-12-03 17:51:38,921 DEBUG TRAIN Batch 3/3900 loss 45.739517 loss_att 58.484543 loss_ctc 74.617142 loss_rnnt 39.340160 lr 0.00092923 rank 2
2022-12-03 17:51:38,924 DEBUG TRAIN Batch 3/3900 loss 32.519463 loss_att 41.737179 loss_ctc 52.098873 loss_rnnt 28.065327 lr 0.00093045 rank 4
2022-12-03 17:52:50,731 DEBUG TRAIN Batch 3/4000 loss 23.755445 loss_att 32.816402 loss_ctc 31.900043 loss_rnnt 20.857307 lr 0.00092832 rank 6
2022-12-03 17:52:50,737 DEBUG TRAIN Batch 3/4000 loss 26.719732 loss_att 35.565807 loss_ctc 43.475044 loss_rnnt 22.716475 lr 0.00092868 rank 7
2022-12-03 17:52:50,738 DEBUG TRAIN Batch 3/4000 loss 33.819164 loss_att 40.377766 loss_ctc 49.326263 loss_rnnt 30.439833 lr 0.00092814 rank 0
2022-12-03 17:52:50,738 DEBUG TRAIN Batch 3/4000 loss 23.654089 loss_att 30.570915 loss_ctc 41.317932 loss_rnnt 19.915543 lr 0.00092763 rank 2
2022-12-03 17:52:50,739 DEBUG TRAIN Batch 3/4000 loss 21.786974 loss_att 27.583212 loss_ctc 26.269247 loss_rnnt 20.030090 lr 0.00092800 rank 1
2022-12-03 17:52:50,739 DEBUG TRAIN Batch 3/4000 loss 26.820845 loss_att 30.872366 loss_ctc 47.538464 loss_rnnt 23.248190 lr 0.00092795 rank 3
2022-12-03 17:52:50,740 DEBUG TRAIN Batch 3/4000 loss 42.208153 loss_att 50.909103 loss_ctc 60.603882 loss_rnnt 38.015198 lr 0.00092885 rank 4
2022-12-03 17:52:50,746 DEBUG TRAIN Batch 3/4000 loss 27.137444 loss_att 37.247459 loss_ctc 42.526039 loss_rnnt 23.063629 lr 0.00092809 rank 5
2022-12-03 17:54:01,633 DEBUG TRAIN Batch 3/4100 loss 28.529209 loss_att 36.913162 loss_ctc 48.356346 loss_rnnt 24.208801 lr 0.00092650 rank 5
2022-12-03 17:54:01,634 DEBUG TRAIN Batch 3/4100 loss 14.055228 loss_att 26.095226 loss_ctc 27.114447 loss_rnnt 9.906000 lr 0.00092672 rank 6
2022-12-03 17:54:01,635 DEBUG TRAIN Batch 3/4100 loss 46.117958 loss_att 49.314629 loss_ctc 63.773949 loss_rnnt 43.124493 lr 0.00092655 rank 0
2022-12-03 17:54:01,635 DEBUG TRAIN Batch 3/4100 loss 49.776428 loss_att 59.070980 loss_ctc 75.885910 loss_rnnt 44.436249 lr 0.00092640 rank 1
2022-12-03 17:54:01,637 DEBUG TRAIN Batch 3/4100 loss 39.526691 loss_att 44.815777 loss_ctc 54.348309 loss_rnnt 36.492661 lr 0.00092635 rank 3
2022-12-03 17:54:01,638 DEBUG TRAIN Batch 3/4100 loss 38.422157 loss_att 47.591969 loss_ctc 60.959534 loss_rnnt 33.583214 lr 0.00092709 rank 7
2022-12-03 17:54:01,640 DEBUG TRAIN Batch 3/4100 loss 24.524532 loss_att 31.443438 loss_ctc 36.116013 loss_rnnt 21.595221 lr 0.00092604 rank 2
2022-12-03 17:54:01,646 DEBUG TRAIN Batch 3/4100 loss 23.326460 loss_att 32.653831 loss_ctc 41.778351 loss_rnnt 19.000732 lr 0.00092725 rank 4
2022-12-03 17:55:14,320 DEBUG TRAIN Batch 3/4200 loss 27.318321 loss_att 33.954174 loss_ctc 43.260246 loss_rnnt 23.865559 lr 0.00092491 rank 5
2022-12-03 17:55:14,326 DEBUG TRAIN Batch 3/4200 loss 28.752220 loss_att 38.717098 loss_ctc 45.009697 loss_rnnt 24.591581 lr 0.00092513 rank 6
2022-12-03 17:55:14,329 DEBUG TRAIN Batch 3/4200 loss 33.965992 loss_att 42.532879 loss_ctc 49.731071 loss_rnnt 30.150604 lr 0.00092496 rank 0
2022-12-03 17:55:14,329 DEBUG TRAIN Batch 3/4200 loss 15.931160 loss_att 25.093552 loss_ctc 27.867290 loss_rnnt 12.507196 lr 0.00092477 rank 3
2022-12-03 17:55:14,333 DEBUG TRAIN Batch 3/4200 loss 36.989216 loss_att 46.124069 loss_ctc 59.748676 loss_rnnt 32.127651 lr 0.00092445 rank 2
2022-12-03 17:55:14,334 DEBUG TRAIN Batch 3/4200 loss 35.265663 loss_att 42.056797 loss_ctc 59.713654 loss_rnnt 30.647705 lr 0.00092550 rank 7
2022-12-03 17:55:14,341 DEBUG TRAIN Batch 3/4200 loss 18.746428 loss_att 28.066326 loss_ctc 31.240095 loss_rnnt 15.216623 lr 0.00092566 rank 4
2022-12-03 17:55:14,344 DEBUG TRAIN Batch 3/4200 loss 31.699539 loss_att 38.357941 loss_ctc 49.433922 loss_rnnt 28.003277 lr 0.00092482 rank 1
2022-12-03 17:56:27,943 DEBUG TRAIN Batch 3/4300 loss 44.097618 loss_att 45.304909 loss_ctc 78.010330 loss_rnnt 39.334461 lr 0.00092355 rank 6
2022-12-03 17:56:27,954 DEBUG TRAIN Batch 3/4300 loss 41.866360 loss_att 48.419369 loss_ctc 61.837128 loss_rnnt 37.892990 lr 0.00092338 rank 0
2022-12-03 17:56:27,959 DEBUG TRAIN Batch 3/4300 loss 27.013840 loss_att 28.200258 loss_ctc 36.900837 loss_rnnt 25.458286 lr 0.00092324 rank 1
2022-12-03 17:56:27,960 DEBUG TRAIN Batch 3/4300 loss 18.738031 loss_att 25.168924 loss_ctc 30.688103 loss_rnnt 15.858509 lr 0.00092288 rank 2
2022-12-03 17:56:27,963 DEBUG TRAIN Batch 3/4300 loss 32.411385 loss_att 41.404022 loss_ctc 52.479946 loss_rnnt 27.937048 lr 0.00092319 rank 3
2022-12-03 17:56:27,964 DEBUG TRAIN Batch 3/4300 loss 40.382439 loss_att 44.971809 loss_ctc 50.337990 loss_rnnt 38.137157 lr 0.00092392 rank 7
2022-12-03 17:56:27,971 DEBUG TRAIN Batch 3/4300 loss 37.539772 loss_att 44.143848 loss_ctc 51.574692 loss_rnnt 34.347633 lr 0.00092407 rank 4
2022-12-03 17:56:28,001 DEBUG TRAIN Batch 3/4300 loss 44.525478 loss_att 53.437378 loss_ctc 73.557671 loss_rnnt 38.872143 lr 0.00092333 rank 5
2022-12-03 17:57:40,353 DEBUG TRAIN Batch 3/4400 loss 18.921715 loss_att 25.008284 loss_ctc 32.623695 loss_rnnt 15.877472 lr 0.00092198 rank 6
2022-12-03 17:57:40,354 DEBUG TRAIN Batch 3/4400 loss 36.060356 loss_att 36.339760 loss_ctc 53.022259 loss_rnnt 33.742889 lr 0.00092162 rank 3
2022-12-03 17:57:40,356 DEBUG TRAIN Batch 3/4400 loss 33.438923 loss_att 36.438854 loss_ctc 47.317966 loss_rnnt 30.988398 lr 0.00092176 rank 5
2022-12-03 17:57:40,357 DEBUG TRAIN Batch 3/4400 loss 26.491856 loss_att 34.718048 loss_ctc 42.638325 loss_rnnt 22.693754 lr 0.00092234 rank 7
2022-12-03 17:57:40,357 DEBUG TRAIN Batch 3/4400 loss 25.472216 loss_att 25.513296 loss_ctc 36.657951 loss_rnnt 23.972569 lr 0.00092181 rank 0
2022-12-03 17:57:40,359 DEBUG TRAIN Batch 3/4400 loss 10.561357 loss_att 11.730355 loss_ctc 16.012426 loss_rnnt 9.600748 lr 0.00092167 rank 1
2022-12-03 17:57:40,359 DEBUG TRAIN Batch 3/4400 loss 28.117048 loss_att 30.117020 loss_ctc 40.036243 loss_rnnt 26.127827 lr 0.00092131 rank 2
2022-12-03 17:57:40,371 DEBUG TRAIN Batch 3/4400 loss 17.955011 loss_att 23.052912 loss_ctc 29.015411 loss_rnnt 15.460711 lr 0.00092250 rank 4
2022-12-03 17:58:52,050 DEBUG TRAIN Batch 3/4500 loss 42.349899 loss_att 47.831841 loss_ctc 58.111336 loss_rnnt 39.151981 lr 0.00092006 rank 3
2022-12-03 17:58:52,067 DEBUG TRAIN Batch 3/4500 loss 26.383471 loss_att 29.410755 loss_ctc 33.716019 loss_rnnt 24.800341 lr 0.00092042 rank 6
2022-12-03 17:58:52,076 DEBUG TRAIN Batch 3/4500 loss 14.847953 loss_att 25.382364 loss_ctc 22.589813 loss_rnnt 11.708822 lr 0.00092020 rank 5
2022-12-03 17:58:52,077 DEBUG TRAIN Batch 3/4500 loss 20.800381 loss_att 28.493652 loss_ctc 33.563137 loss_rnnt 17.560024 lr 0.00092025 rank 0
2022-12-03 17:58:52,077 DEBUG TRAIN Batch 3/4500 loss 27.943703 loss_att 40.311615 loss_ctc 45.830475 loss_rnnt 23.085218 lr 0.00091975 rank 2
2022-12-03 17:58:52,078 DEBUG TRAIN Batch 3/4500 loss 15.875322 loss_att 22.487036 loss_ctc 25.548717 loss_rnnt 13.263194 lr 0.00092078 rank 7
2022-12-03 17:58:52,078 DEBUG TRAIN Batch 3/4500 loss 20.753691 loss_att 29.741545 loss_ctc 31.642189 loss_rnnt 17.504320 lr 0.00092093 rank 4
2022-12-03 17:58:52,128 DEBUG TRAIN Batch 3/4500 loss 41.115070 loss_att 50.477787 loss_ctc 56.002335 loss_rnnt 37.257561 lr 0.00092011 rank 1
2022-12-03 18:00:05,362 DEBUG TRAIN Batch 3/4600 loss 20.231415 loss_att 30.631990 loss_ctc 36.256065 loss_rnnt 16.014679 lr 0.00091922 rank 7
2022-12-03 18:00:05,369 DEBUG TRAIN Batch 3/4600 loss 45.087669 loss_att 56.902905 loss_ctc 72.196838 loss_rnnt 39.110065 lr 0.00091820 rank 2
2022-12-03 18:00:05,375 DEBUG TRAIN Batch 3/4600 loss 26.530508 loss_att 39.335579 loss_ctc 40.570389 loss_rnnt 22.097507 lr 0.00091855 rank 1
2022-12-03 18:00:05,377 DEBUG TRAIN Batch 3/4600 loss 26.915228 loss_att 35.927338 loss_ctc 42.178886 loss_rnnt 23.077652 lr 0.00091865 rank 5
2022-12-03 18:00:05,378 DEBUG TRAIN Batch 3/4600 loss 32.357719 loss_att 41.354473 loss_ctc 49.537613 loss_rnnt 28.267715 lr 0.00091869 rank 0
2022-12-03 18:00:05,378 DEBUG TRAIN Batch 3/4600 loss 19.110081 loss_att 19.373619 loss_ctc 28.776434 loss_rnnt 17.768524 lr 0.00091851 rank 3
2022-12-03 18:00:05,381 DEBUG TRAIN Batch 3/4600 loss 19.057987 loss_att 34.198502 loss_ctc 35.769463 loss_rnnt 13.801687 lr 0.00091938 rank 4
2022-12-03 18:00:05,433 DEBUG TRAIN Batch 3/4600 loss 33.925819 loss_att 40.261913 loss_ctc 50.352962 loss_rnnt 30.468315 lr 0.00091886 rank 6
2022-12-03 18:01:18,659 DEBUG TRAIN Batch 3/4700 loss 38.237041 loss_att 50.565422 loss_ctc 51.734070 loss_rnnt 33.971764 lr 0.00091732 rank 6
2022-12-03 18:01:18,665 DEBUG TRAIN Batch 3/4700 loss 27.468571 loss_att 35.467155 loss_ctc 40.895054 loss_rnnt 24.078655 lr 0.00091767 rank 7
2022-12-03 18:01:18,666 DEBUG TRAIN Batch 3/4700 loss 24.269569 loss_att 32.782425 loss_ctc 44.774700 loss_rnnt 19.832981 lr 0.00091715 rank 0
2022-12-03 18:01:18,669 DEBUG TRAIN Batch 3/4700 loss 20.304192 loss_att 27.038057 loss_ctc 28.857605 loss_rnnt 17.816961 lr 0.00091696 rank 3
2022-12-03 18:01:18,669 DEBUG TRAIN Batch 3/4700 loss 51.610111 loss_att 56.692379 loss_ctc 70.748230 loss_rnnt 48.041908 lr 0.00091783 rank 4
2022-12-03 18:01:18,703 DEBUG TRAIN Batch 3/4700 loss 20.633156 loss_att 30.371754 loss_ctc 36.610241 loss_rnnt 16.555157 lr 0.00091665 rank 2
2022-12-03 18:01:18,709 DEBUG TRAIN Batch 3/4700 loss 20.796669 loss_att 26.777744 loss_ctc 34.251289 loss_rnnt 17.806503 lr 0.00091710 rank 5
2022-12-03 18:01:18,716 DEBUG TRAIN Batch 3/4700 loss 25.127041 loss_att 31.720184 loss_ctc 34.827190 loss_rnnt 22.515059 lr 0.00091701 rank 1
2022-12-03 18:02:30,391 DEBUG TRAIN Batch 3/4800 loss 33.799782 loss_att 36.446709 loss_ctc 50.892361 loss_rnnt 30.991383 lr 0.00091578 rank 6
2022-12-03 18:02:30,391 DEBUG TRAIN Batch 3/4800 loss 17.164608 loss_att 24.064934 loss_ctc 27.553593 loss_rnnt 14.399345 lr 0.00091547 rank 1
2022-12-03 18:02:30,395 DEBUG TRAIN Batch 3/4800 loss 14.730087 loss_att 24.363472 loss_ctc 22.664137 loss_rnnt 11.745537 lr 0.00091561 rank 0
2022-12-03 18:02:30,396 DEBUG TRAIN Batch 3/4800 loss 24.873363 loss_att 34.742538 loss_ctc 44.903717 loss_rnnt 20.228817 lr 0.00091613 rank 7
2022-12-03 18:02:30,397 DEBUG TRAIN Batch 3/4800 loss 32.479145 loss_att 41.135941 loss_ctc 46.064148 loss_rnnt 28.936453 lr 0.00091556 rank 5
2022-12-03 18:02:30,398 DEBUG TRAIN Batch 3/4800 loss 49.407501 loss_att 56.586040 loss_ctc 72.110733 loss_rnnt 44.944695 lr 0.00091542 rank 3
2022-12-03 18:02:30,399 DEBUG TRAIN Batch 3/4800 loss 48.891541 loss_att 57.948360 loss_ctc 69.278198 loss_rnnt 44.361961 lr 0.00091512 rank 2
2022-12-03 18:02:30,404 DEBUG TRAIN Batch 3/4800 loss 19.454988 loss_att 22.453260 loss_ctc 28.561329 loss_rnnt 17.641155 lr 0.00091628 rank 4
2022-12-03 18:03:41,818 DEBUG TRAIN Batch 3/4900 loss 21.338169 loss_att 28.152161 loss_ctc 37.121929 loss_rnnt 17.870871 lr 0.00091359 rank 2
2022-12-03 18:03:41,827 DEBUG TRAIN Batch 3/4900 loss 30.634605 loss_att 32.018192 loss_ctc 40.377331 loss_rnnt 29.058859 lr 0.00091408 rank 0
2022-12-03 18:03:41,829 DEBUG TRAIN Batch 3/4900 loss 25.519861 loss_att 33.025318 loss_ctc 39.384377 loss_rnnt 22.170166 lr 0.00091424 rank 6
2022-12-03 18:03:41,828 DEBUG TRAIN Batch 3/4900 loss 29.314281 loss_att 42.111198 loss_ctc 56.952065 loss_rnnt 23.069859 lr 0.00091460 rank 7
2022-12-03 18:03:41,829 DEBUG TRAIN Batch 3/4900 loss 15.969547 loss_att 23.342976 loss_ctc 28.251455 loss_rnnt 12.857273 lr 0.00091394 rank 1
2022-12-03 18:03:41,832 DEBUG TRAIN Batch 3/4900 loss 24.805788 loss_att 30.072144 loss_ctc 40.752605 loss_rnnt 21.626274 lr 0.00091389 rank 3
2022-12-03 18:03:41,832 DEBUG TRAIN Batch 3/4900 loss 26.311853 loss_att 31.703669 loss_ctc 40.609966 loss_rnnt 23.327074 lr 0.00091403 rank 5
2022-12-03 18:03:41,833 DEBUG TRAIN Batch 3/4900 loss 14.465267 loss_att 19.370462 loss_ctc 20.610783 loss_rnnt 12.664825 lr 0.00091475 rank 4
2022-12-03 18:04:55,886 DEBUG TRAIN Batch 3/5000 loss 27.970913 loss_att 31.759624 loss_ctc 36.265270 loss_rnnt 26.107254 lr 0.00091237 rank 3
2022-12-03 18:04:55,887 DEBUG TRAIN Batch 3/5000 loss 18.682732 loss_att 25.370548 loss_ctc 38.642513 loss_rnnt 14.683864 lr 0.00091241 rank 1
2022-12-03 18:04:55,887 DEBUG TRAIN Batch 3/5000 loss 12.958003 loss_att 20.334326 loss_ctc 20.938848 loss_rnnt 10.418625 lr 0.00091272 rank 6
2022-12-03 18:04:55,888 DEBUG TRAIN Batch 3/5000 loss 35.310020 loss_att 37.439117 loss_ctc 48.810669 loss_rnnt 33.084114 lr 0.00091207 rank 2
2022-12-03 18:04:55,889 DEBUG TRAIN Batch 3/5000 loss 18.093998 loss_att 21.387793 loss_ctc 26.684841 loss_rnnt 16.289795 lr 0.00091251 rank 5
2022-12-03 18:04:55,890 DEBUG TRAIN Batch 3/5000 loss 22.852562 loss_att 29.310062 loss_ctc 37.385357 loss_rnnt 19.623358 lr 0.00091255 rank 0
2022-12-03 18:04:55,895 DEBUG TRAIN Batch 3/5000 loss 31.032076 loss_att 35.030174 loss_ctc 42.085236 loss_rnnt 28.758703 lr 0.00091307 rank 7
2022-12-03 18:04:55,896 DEBUG TRAIN Batch 3/5000 loss 16.845026 loss_att 21.782158 loss_ctc 25.596670 loss_rnnt 14.690712 lr 0.00091322 rank 4
2022-12-03 18:06:07,419 DEBUG TRAIN Batch 3/5100 loss 19.882362 loss_att 26.419079 loss_ctc 30.752134 loss_rnnt 17.125715 lr 0.00091099 rank 5
2022-12-03 18:06:07,422 DEBUG TRAIN Batch 3/5100 loss 32.429844 loss_att 34.639389 loss_ctc 50.152023 loss_rnnt 29.624977 lr 0.00091104 rank 0
2022-12-03 18:06:07,422 DEBUG TRAIN Batch 3/5100 loss 50.990486 loss_att 62.933506 loss_ctc 78.673569 loss_rnnt 44.910809 lr 0.00091090 rank 1
2022-12-03 18:06:07,426 DEBUG TRAIN Batch 3/5100 loss 44.399460 loss_att 52.422371 loss_ctc 57.306499 loss_rnnt 41.073936 lr 0.00091085 rank 3
2022-12-03 18:06:07,426 DEBUG TRAIN Batch 3/5100 loss 25.683859 loss_att 32.110306 loss_ctc 34.837963 loss_rnnt 23.178022 lr 0.00091120 rank 6
2022-12-03 18:06:07,427 DEBUG TRAIN Batch 3/5100 loss 8.523538 loss_att 8.870316 loss_ctc 12.639844 loss_rnnt 7.905341 lr 0.00091155 rank 7
2022-12-03 18:06:07,431 DEBUG TRAIN Batch 3/5100 loss 35.467522 loss_att 50.107353 loss_ctc 57.605415 loss_rnnt 29.587837 lr 0.00091055 rank 2
2022-12-03 18:06:07,433 DEBUG TRAIN Batch 3/5100 loss 24.126198 loss_att 30.393482 loss_ctc 32.674606 loss_rnnt 21.732954 lr 0.00091170 rank 4
2022-12-03 18:07:18,886 DEBUG TRAIN Batch 3/5200 loss 26.642490 loss_att 36.555576 loss_ctc 49.592571 loss_rnnt 21.599861 lr 0.00090953 rank 0
2022-12-03 18:07:18,886 DEBUG TRAIN Batch 3/5200 loss 36.950588 loss_att 42.204155 loss_ctc 49.191154 loss_rnnt 34.267799 lr 0.00090935 rank 3
2022-12-03 18:07:18,887 DEBUG TRAIN Batch 3/5200 loss 48.454407 loss_att 62.370132 loss_ctc 67.695145 loss_rnnt 43.105827 lr 0.00090948 rank 5
2022-12-03 18:07:18,888 DEBUG TRAIN Batch 3/5200 loss 36.859219 loss_att 43.366447 loss_ctc 55.540844 loss_rnnt 33.066887 lr 0.00090969 rank 6
2022-12-03 18:07:18,888 DEBUG TRAIN Batch 3/5200 loss 31.339554 loss_att 45.204571 loss_ctc 54.846626 loss_rnnt 25.432274 lr 0.00090939 rank 1
2022-12-03 18:07:18,890 DEBUG TRAIN Batch 3/5200 loss 27.346842 loss_att 36.082588 loss_ctc 42.591072 loss_rnnt 23.567129 lr 0.00091004 rank 7
2022-12-03 18:07:18,895 DEBUG TRAIN Batch 3/5200 loss 24.822084 loss_att 32.218929 loss_ctc 43.167839 loss_rnnt 20.896614 lr 0.00090905 rank 2
2022-12-03 18:07:18,897 DEBUG TRAIN Batch 3/5200 loss 27.920135 loss_att 36.879341 loss_ctc 44.177746 loss_rnnt 23.960615 lr 0.00091019 rank 4
2022-12-03 18:08:32,014 DEBUG TRAIN Batch 3/5300 loss 12.667667 loss_att 16.745455 loss_ctc 23.358389 loss_rnnt 10.426680 lr 0.00090819 rank 6
2022-12-03 18:08:32,014 DEBUG TRAIN Batch 3/5300 loss 37.158413 loss_att 43.948982 loss_ctc 55.072460 loss_rnnt 33.411758 lr 0.00090785 rank 3
2022-12-03 18:08:32,017 DEBUG TRAIN Batch 3/5300 loss 33.273872 loss_att 39.868958 loss_ctc 42.168209 loss_rnnt 30.768942 lr 0.00090803 rank 0
2022-12-03 18:08:32,017 DEBUG TRAIN Batch 3/5300 loss 28.521276 loss_att 34.091431 loss_ctc 43.370056 loss_rnnt 25.427410 lr 0.00090798 rank 5
2022-12-03 18:08:32,017 DEBUG TRAIN Batch 3/5300 loss 15.161564 loss_att 21.070648 loss_ctc 20.458105 loss_rnnt 13.273540 lr 0.00090755 rank 2
2022-12-03 18:08:32,018 DEBUG TRAIN Batch 3/5300 loss 25.707569 loss_att 37.482132 loss_ctc 39.498775 loss_rnnt 21.513828 lr 0.00090869 rank 4
2022-12-03 18:08:32,019 DEBUG TRAIN Batch 3/5300 loss 34.387005 loss_att 44.645554 loss_ctc 52.373848 loss_rnnt 29.937046 lr 0.00090854 rank 7
2022-12-03 18:08:32,022 DEBUG TRAIN Batch 3/5300 loss 24.158730 loss_att 34.862015 loss_ctc 37.040718 loss_rnnt 20.300472 lr 0.00090789 rank 1
2022-12-03 18:09:44,957 DEBUG TRAIN Batch 3/5400 loss 27.322380 loss_att 36.488068 loss_ctc 46.657173 loss_rnnt 22.911270 lr 0.00090670 rank 6
2022-12-03 18:09:44,957 DEBUG TRAIN Batch 3/5400 loss 25.048996 loss_att 29.757866 loss_ctc 43.578102 loss_rnnt 21.636673 lr 0.00090635 rank 3
2022-12-03 18:09:44,958 DEBUG TRAIN Batch 3/5400 loss 21.827896 loss_att 28.310312 loss_ctc 35.429665 loss_rnnt 18.717842 lr 0.00090640 rank 1
2022-12-03 18:09:44,959 DEBUG TRAIN Batch 3/5400 loss 28.072765 loss_att 33.380486 loss_ctc 41.741165 loss_rnnt 25.188768 lr 0.00090606 rank 2
2022-12-03 18:09:44,963 DEBUG TRAIN Batch 3/5400 loss 45.107933 loss_att 55.801491 loss_ctc 65.679260 loss_rnnt 40.226379 lr 0.00090653 rank 0
2022-12-03 18:09:44,966 DEBUG TRAIN Batch 3/5400 loss 18.422192 loss_att 24.881668 loss_ctc 31.625277 loss_rnnt 15.369884 lr 0.00090704 rank 7
2022-12-03 18:09:44,967 DEBUG TRAIN Batch 3/5400 loss 32.905155 loss_att 38.848804 loss_ctc 48.625793 loss_rnnt 29.620338 lr 0.00090649 rank 5
2022-12-03 18:09:44,970 DEBUG TRAIN Batch 3/5400 loss 23.186249 loss_att 27.456352 loss_ctc 42.010178 loss_rnnt 19.822369 lr 0.00090719 rank 4
2022-12-03 18:10:56,140 DEBUG TRAIN Batch 3/5500 loss 29.063919 loss_att 37.204926 loss_ctc 47.091080 loss_rnnt 25.032095 lr 0.00090570 rank 4
2022-12-03 18:10:56,141 DEBUG TRAIN Batch 3/5500 loss 35.764507 loss_att 39.716789 loss_ctc 53.484974 loss_rnnt 32.611324 lr 0.00090500 rank 5
2022-12-03 18:10:56,144 DEBUG TRAIN Batch 3/5500 loss 26.493160 loss_att 29.976753 loss_ctc 35.889896 loss_rnnt 24.543545 lr 0.00090487 rank 3
2022-12-03 18:10:56,146 DEBUG TRAIN Batch 3/5500 loss 26.146109 loss_att 30.150620 loss_ctc 32.885620 loss_rnnt 24.446606 lr 0.00090505 rank 0
2022-12-03 18:10:56,147 DEBUG TRAIN Batch 3/5500 loss 36.233452 loss_att 45.777630 loss_ctc 44.461769 loss_rnnt 33.227509 lr 0.00090521 rank 6
2022-12-03 18:10:56,149 DEBUG TRAIN Batch 3/5500 loss 15.656641 loss_att 17.472944 loss_ctc 19.123413 loss_rnnt 14.831143 lr 0.00090491 rank 1
2022-12-03 18:10:56,151 DEBUG TRAIN Batch 3/5500 loss 56.070251 loss_att 64.657516 loss_ctc 79.130508 loss_rnnt 51.278099 lr 0.00090457 rank 2
2022-12-03 18:10:56,157 DEBUG TRAIN Batch 3/5500 loss 28.224474 loss_att 37.428371 loss_ctc 43.991589 loss_rnnt 24.281412 lr 0.00090555 rank 7
2022-12-03 18:12:08,883 DEBUG TRAIN Batch 3/5600 loss 23.056093 loss_att 29.915348 loss_ctc 34.551872 loss_rnnt 20.151470 lr 0.00090339 rank 3
2022-12-03 18:12:08,884 DEBUG TRAIN Batch 3/5600 loss 23.006943 loss_att 24.871059 loss_ctc 36.327614 loss_rnnt 20.858028 lr 0.00090343 rank 1
2022-12-03 18:12:08,885 DEBUG TRAIN Batch 3/5600 loss 25.115215 loss_att 32.068016 loss_ctc 40.661957 loss_rnnt 21.651756 lr 0.00090373 rank 6
2022-12-03 18:12:08,885 DEBUG TRAIN Batch 3/5600 loss 11.185203 loss_att 18.900999 loss_ctc 22.546869 loss_rnnt 8.127154 lr 0.00090357 rank 0
2022-12-03 18:12:08,891 DEBUG TRAIN Batch 3/5600 loss 17.738449 loss_att 22.348007 loss_ctc 29.247564 loss_rnnt 15.281989 lr 0.00090422 rank 4
2022-12-03 18:12:08,901 DEBUG TRAIN Batch 3/5600 loss 42.392757 loss_att 48.103054 loss_ctc 58.677689 loss_rnnt 39.079376 lr 0.00090407 rank 7
2022-12-03 18:12:08,904 DEBUG TRAIN Batch 3/5600 loss 36.376122 loss_att 42.646542 loss_ctc 47.827621 loss_rnnt 33.595169 lr 0.00090352 rank 5
2022-12-03 18:12:08,906 DEBUG TRAIN Batch 3/5600 loss 30.115179 loss_att 34.822166 loss_ctc 46.780479 loss_rnnt 26.951740 lr 0.00090310 rank 2
2022-12-03 18:13:23,220 DEBUG TRAIN Batch 3/5700 loss 26.590847 loss_att 33.240303 loss_ctc 39.698971 loss_rnnt 23.513206 lr 0.00090226 rank 6
2022-12-03 18:13:23,223 DEBUG TRAIN Batch 3/5700 loss 31.357620 loss_att 38.291889 loss_ctc 47.355923 loss_rnnt 27.837660 lr 0.00090205 rank 5
2022-12-03 18:13:23,226 DEBUG TRAIN Batch 3/5700 loss 25.883184 loss_att 31.582510 loss_ctc 35.906075 loss_rnnt 23.406935 lr 0.00090210 rank 0
2022-12-03 18:13:23,230 DEBUG TRAIN Batch 3/5700 loss 13.667084 loss_att 15.282437 loss_ctc 20.629028 loss_rnnt 12.415753 lr 0.00090192 rank 3
2022-12-03 18:13:23,230 DEBUG TRAIN Batch 3/5700 loss 39.207272 loss_att 51.511002 loss_ctc 60.138824 loss_rnnt 33.955654 lr 0.00090163 rank 2
2022-12-03 18:13:23,234 DEBUG TRAIN Batch 3/5700 loss 14.609687 loss_att 14.629408 loss_ctc 20.521852 loss_rnnt 13.817453 lr 0.00090274 rank 4
2022-12-03 18:13:23,234 DEBUG TRAIN Batch 3/5700 loss 20.015978 loss_att 20.860437 loss_ctc 32.268593 loss_rnnt 18.213402 lr 0.00090259 rank 7
2022-12-03 18:13:23,275 DEBUG TRAIN Batch 3/5700 loss 14.918871 loss_att 18.282099 loss_ctc 23.953979 loss_rnnt 13.041545 lr 0.00090196 rank 1
2022-12-03 18:14:35,549 DEBUG TRAIN Batch 3/5800 loss 19.723345 loss_att 26.578510 loss_ctc 28.324499 loss_rnnt 17.205490 lr 0.00090046 rank 3
2022-12-03 18:14:35,551 DEBUG TRAIN Batch 3/5800 loss 14.140599 loss_att 14.298038 loss_ctc 17.784843 loss_rnnt 13.623212 lr 0.00090079 rank 6
2022-12-03 18:14:35,553 DEBUG TRAIN Batch 3/5800 loss 56.924980 loss_att 58.409817 loss_ctc 85.919792 loss_rnnt 52.762035 lr 0.00090063 rank 0
2022-12-03 18:14:35,553 DEBUG TRAIN Batch 3/5800 loss 29.953411 loss_att 36.657001 loss_ctc 49.599541 loss_rnnt 25.993208 lr 0.00090059 rank 5
2022-12-03 18:14:35,555 DEBUG TRAIN Batch 3/5800 loss 43.133865 loss_att 48.439766 loss_ctc 54.355145 loss_rnnt 40.576515 lr 0.00090050 rank 1
2022-12-03 18:14:35,559 DEBUG TRAIN Batch 3/5800 loss 21.577576 loss_att 30.619205 loss_ctc 33.396191 loss_rnnt 18.193436 lr 0.00090016 rank 2
2022-12-03 18:14:35,561 DEBUG TRAIN Batch 3/5800 loss 29.952908 loss_att 39.162785 loss_ctc 49.015221 loss_rnnt 25.569290 lr 0.00090113 rank 7
2022-12-03 18:14:35,564 DEBUG TRAIN Batch 3/5800 loss 32.685570 loss_att 37.661045 loss_ctc 50.988323 loss_rnnt 29.250107 lr 0.00090127 rank 4
2022-12-03 18:15:46,488 DEBUG TRAIN Batch 3/5900 loss 29.377892 loss_att 37.083973 loss_ctc 44.934517 loss_rnnt 25.762459 lr 0.00089933 rank 6
2022-12-03 18:15:46,488 DEBUG TRAIN Batch 3/5900 loss 14.987066 loss_att 20.997210 loss_ctc 27.420406 loss_rnnt 12.127258 lr 0.00089904 rank 1
2022-12-03 18:15:46,490 DEBUG TRAIN Batch 3/5900 loss 37.739662 loss_att 43.025570 loss_ctc 55.449997 loss_rnnt 34.321102 lr 0.00089900 rank 3
2022-12-03 18:15:46,492 DEBUG TRAIN Batch 3/5900 loss 38.801071 loss_att 46.128716 loss_ctc 52.825909 loss_rnnt 35.465561 lr 0.00089913 rank 5
2022-12-03 18:15:46,493 DEBUG TRAIN Batch 3/5900 loss 27.845522 loss_att 30.758499 loss_ctc 42.397682 loss_rnnt 25.322636 lr 0.00089917 rank 0
2022-12-03 18:15:46,494 DEBUG TRAIN Batch 3/5900 loss 19.382553 loss_att 27.433308 loss_ctc 32.772614 loss_rnnt 15.987061 lr 0.00089871 rank 2
2022-12-03 18:15:46,497 DEBUG TRAIN Batch 3/5900 loss 40.360359 loss_att 50.931133 loss_ctc 61.981323 loss_rnnt 35.363407 lr 0.00089967 rank 7
2022-12-03 18:15:46,539 DEBUG TRAIN Batch 3/5900 loss 38.276115 loss_att 46.369438 loss_ctc 64.424149 loss_rnnt 33.171043 lr 0.00089981 rank 4
2022-12-03 18:16:59,905 DEBUG TRAIN Batch 3/6000 loss 54.783649 loss_att 60.266846 loss_ctc 88.901077 loss_rnnt 49.138023 lr 0.00089759 rank 1
2022-12-03 18:16:59,907 DEBUG TRAIN Batch 3/6000 loss 25.613693 loss_att 30.966625 loss_ctc 38.481995 loss_rnnt 22.827332 lr 0.00089836 rank 4
2022-12-03 18:16:59,914 DEBUG TRAIN Batch 3/6000 loss 49.418751 loss_att 52.629036 loss_ctc 61.106903 loss_rnnt 47.218273 lr 0.00089788 rank 6
2022-12-03 18:16:59,919 DEBUG TRAIN Batch 3/6000 loss 14.590687 loss_att 23.527348 loss_ctc 28.653320 loss_rnnt 10.928336 lr 0.00089726 rank 2
2022-12-03 18:16:59,919 DEBUG TRAIN Batch 3/6000 loss 22.709501 loss_att 31.009127 loss_ctc 34.019890 loss_rnnt 19.541525 lr 0.00089772 rank 0
2022-12-03 18:16:59,920 DEBUG TRAIN Batch 3/6000 loss 39.278454 loss_att 43.048695 loss_ctc 55.607224 loss_rnnt 36.347233 lr 0.00089755 rank 3
2022-12-03 18:16:59,923 DEBUG TRAIN Batch 3/6000 loss 62.974102 loss_att 64.117279 loss_ctc 86.504547 loss_rnnt 59.608070 lr 0.00089768 rank 5
2022-12-03 18:16:59,944 DEBUG TRAIN Batch 3/6000 loss 19.524326 loss_att 23.838209 loss_ctc 34.252930 loss_rnnt 16.697735 lr 0.00089821 rank 7
2022-12-03 18:18:12,822 DEBUG TRAIN Batch 3/6100 loss 31.067146 loss_att 31.489319 loss_ctc 54.092247 loss_rnnt 27.912697 lr 0.00089644 rank 6
2022-12-03 18:18:12,828 DEBUG TRAIN Batch 3/6100 loss 44.083698 loss_att 50.136894 loss_ctc 72.903999 loss_rnnt 39.030350 lr 0.00089628 rank 0
2022-12-03 18:18:12,829 DEBUG TRAIN Batch 3/6100 loss 19.319637 loss_att 24.285149 loss_ctc 33.046982 loss_rnnt 16.496223 lr 0.00089677 rank 7
2022-12-03 18:18:12,833 DEBUG TRAIN Batch 3/6100 loss 40.293552 loss_att 48.393761 loss_ctc 60.953320 loss_rnnt 35.918873 lr 0.00089611 rank 3
2022-12-03 18:18:12,834 DEBUG TRAIN Batch 3/6100 loss 12.647160 loss_att 20.625822 loss_ctc 29.291214 loss_rnnt 8.832218 lr 0.00089691 rank 4
2022-12-03 18:18:12,835 DEBUG TRAIN Batch 3/6100 loss 23.904320 loss_att 27.395203 loss_ctc 43.744396 loss_rnnt 20.560801 lr 0.00089582 rank 2
2022-12-03 18:18:12,836 DEBUG TRAIN Batch 3/6100 loss 16.971214 loss_att 22.175358 loss_ctc 30.203249 loss_rnnt 14.166114 lr 0.00089615 rank 1
2022-12-03 18:18:12,874 DEBUG TRAIN Batch 3/6100 loss 15.925356 loss_att 23.651911 loss_ctc 27.012400 loss_rnnt 12.901772 lr 0.00089624 rank 5
2022-12-03 18:19:25,009 DEBUG TRAIN Batch 3/6200 loss 27.784557 loss_att 32.884663 loss_ctc 40.381721 loss_rnnt 25.084915 lr 0.00089471 rank 1
2022-12-03 18:19:25,011 DEBUG TRAIN Batch 3/6200 loss 45.011951 loss_att 48.253090 loss_ctc 68.822449 loss_rnnt 41.188992 lr 0.00089467 rank 3
2022-12-03 18:19:25,012 DEBUG TRAIN Batch 3/6200 loss 19.603868 loss_att 21.714132 loss_ctc 32.197117 loss_rnnt 17.502716 lr 0.00089484 rank 0
2022-12-03 18:19:25,015 DEBUG TRAIN Batch 3/6200 loss 32.570118 loss_att 35.175129 loss_ctc 45.282207 loss_rnnt 30.354170 lr 0.00089500 rank 6
2022-12-03 18:19:25,015 DEBUG TRAIN Batch 3/6200 loss 38.856457 loss_att 46.983284 loss_ctc 55.935524 loss_rnnt 34.953880 lr 0.00089547 rank 4
2022-12-03 18:19:25,020 DEBUG TRAIN Batch 3/6200 loss 31.107233 loss_att 39.650459 loss_ctc 47.367290 loss_rnnt 27.230579 lr 0.00089480 rank 5
2022-12-03 18:19:25,020 DEBUG TRAIN Batch 3/6200 loss 23.464840 loss_att 30.228762 loss_ctc 40.769485 loss_rnnt 19.804768 lr 0.00089438 rank 2
2022-12-03 18:19:25,021 DEBUG TRAIN Batch 3/6200 loss 24.571117 loss_att 28.497850 loss_ctc 36.700584 loss_rnnt 22.168507 lr 0.00089533 rank 7
2022-12-03 18:20:36,978 DEBUG TRAIN Batch 3/6300 loss 37.736214 loss_att 41.016228 loss_ctc 56.852654 loss_rnnt 34.531353 lr 0.00089357 rank 6
2022-12-03 18:20:36,982 DEBUG TRAIN Batch 3/6300 loss 14.906850 loss_att 23.192608 loss_ctc 28.078547 loss_rnnt 11.493472 lr 0.00089337 rank 5
2022-12-03 18:20:36,982 DEBUG TRAIN Batch 3/6300 loss 20.286480 loss_att 23.723646 loss_ctc 28.833054 loss_rnnt 18.459503 lr 0.00089390 rank 7
2022-12-03 18:20:36,983 DEBUG TRAIN Batch 3/6300 loss 36.489357 loss_att 44.471397 loss_ctc 58.834450 loss_rnnt 31.913599 lr 0.00089328 rank 1
2022-12-03 18:20:36,988 DEBUG TRAIN Batch 3/6300 loss 30.465572 loss_att 35.441280 loss_ctc 50.851208 loss_rnnt 26.752344 lr 0.00089324 rank 3
2022-12-03 18:20:36,989 DEBUG TRAIN Batch 3/6300 loss 20.101013 loss_att 20.541317 loss_ctc 28.380590 loss_rnnt 18.909008 lr 0.00089296 rank 2
2022-12-03 18:20:36,991 DEBUG TRAIN Batch 3/6300 loss 27.688353 loss_att 36.121735 loss_ctc 46.729946 loss_rnnt 23.462797 lr 0.00089404 rank 4
2022-12-03 18:20:36,995 DEBUG TRAIN Batch 3/6300 loss 29.911734 loss_att 30.123909 loss_ctc 42.421028 loss_rnnt 28.201389 lr 0.00089341 rank 0
2022-12-03 18:21:51,494 DEBUG TRAIN Batch 3/6400 loss 29.977587 loss_att 29.080132 loss_ctc 45.060745 loss_rnnt 28.145988 lr 0.00089215 rank 6
2022-12-03 18:21:51,494 DEBUG TRAIN Batch 3/6400 loss 48.525688 loss_att 54.035397 loss_ctc 65.293716 loss_rnnt 45.188011 lr 0.00089199 rank 0
2022-12-03 18:21:51,497 DEBUG TRAIN Batch 3/6400 loss 26.295370 loss_att 35.680061 loss_ctc 44.246792 loss_rnnt 22.024910 lr 0.00089182 rank 3
2022-12-03 18:21:51,499 DEBUG TRAIN Batch 3/6400 loss 23.723776 loss_att 33.026463 loss_ctc 37.552425 loss_rnnt 20.019417 lr 0.00089154 rank 2
2022-12-03 18:21:51,506 DEBUG TRAIN Batch 3/6400 loss 19.940388 loss_att 21.745043 loss_ctc 30.723978 loss_rnnt 18.141645 lr 0.00089186 rank 1
2022-12-03 18:21:51,508 DEBUG TRAIN Batch 3/6400 loss 13.398654 loss_att 13.025618 loss_ctc 16.955976 loss_rnnt 12.998951 lr 0.00089262 rank 4
2022-12-03 18:21:51,526 DEBUG TRAIN Batch 3/6400 loss 25.918430 loss_att 39.735214 loss_ctc 38.879578 loss_rnnt 21.426918 lr 0.00089247 rank 7
2022-12-03 18:21:51,543 DEBUG TRAIN Batch 3/6400 loss 24.761324 loss_att 27.617451 loss_ctc 35.762871 loss_rnnt 22.723227 lr 0.00089195 rank 5
2022-12-03 18:23:03,420 DEBUG TRAIN Batch 3/6500 loss 38.409687 loss_att 49.986221 loss_ctc 54.659477 loss_rnnt 33.927742 lr 0.00089012 rank 2
2022-12-03 18:23:03,421 DEBUG TRAIN Batch 3/6500 loss 37.148975 loss_att 48.609241 loss_ctc 51.832863 loss_rnnt 32.899071 lr 0.00089045 rank 1
2022-12-03 18:23:03,422 DEBUG TRAIN Batch 3/6500 loss 21.470201 loss_att 34.082237 loss_ctc 36.259884 loss_rnnt 16.975838 lr 0.00089073 rank 6
2022-12-03 18:23:03,422 DEBUG TRAIN Batch 3/6500 loss 25.238241 loss_att 35.070503 loss_ctc 42.865963 loss_rnnt 20.921425 lr 0.00089057 rank 0
2022-12-03 18:23:03,422 DEBUG TRAIN Batch 3/6500 loss 26.227749 loss_att 33.992073 loss_ctc 37.293934 loss_rnnt 23.199392 lr 0.00089105 rank 7
2022-12-03 18:23:03,423 DEBUG TRAIN Batch 3/6500 loss 29.399689 loss_att 39.936279 loss_ctc 45.529949 loss_rnnt 25.141668 lr 0.00089040 rank 3
2022-12-03 18:23:03,428 DEBUG TRAIN Batch 3/6500 loss 25.106493 loss_att 39.801346 loss_ctc 37.080906 loss_rnnt 20.570936 lr 0.00089120 rank 4
2022-12-03 18:23:03,470 DEBUG TRAIN Batch 3/6500 loss 42.382687 loss_att 50.740318 loss_ctc 70.681183 loss_rnnt 36.938026 lr 0.00089053 rank 5
2022-12-03 18:24:15,670 DEBUG TRAIN Batch 3/6600 loss 16.809147 loss_att 21.209875 loss_ctc 27.569199 loss_rnnt 14.494327 lr 0.00088932 rank 6
2022-12-03 18:24:15,672 DEBUG TRAIN Batch 3/6600 loss 31.242153 loss_att 39.358540 loss_ctc 48.093559 loss_rnnt 27.372019 lr 0.00088872 rank 2
2022-12-03 18:24:15,672 DEBUG TRAIN Batch 3/6600 loss 26.459560 loss_att 32.750244 loss_ctc 42.978878 loss_rnnt 22.998848 lr 0.00088916 rank 0
2022-12-03 18:24:15,674 DEBUG TRAIN Batch 3/6600 loss 31.631433 loss_att 39.234455 loss_ctc 44.652161 loss_rnnt 28.374733 lr 0.00088964 rank 7
2022-12-03 18:24:15,675 DEBUG TRAIN Batch 3/6600 loss 26.559952 loss_att 36.576797 loss_ctc 43.449596 loss_rnnt 22.304632 lr 0.00088912 rank 5
2022-12-03 18:24:15,676 DEBUG TRAIN Batch 3/6600 loss 23.402559 loss_att 32.949547 loss_ctc 38.367424 loss_rnnt 19.497847 lr 0.00088900 rank 3
2022-12-03 18:24:15,676 DEBUG TRAIN Batch 3/6600 loss 31.669594 loss_att 36.321854 loss_ctc 53.724728 loss_rnnt 27.798458 lr 0.00088904 rank 1
2022-12-03 18:24:15,682 DEBUG TRAIN Batch 3/6600 loss 22.221388 loss_att 31.164726 loss_ctc 37.151283 loss_rnnt 18.442068 lr 0.00088978 rank 4
2022-12-03 18:25:28,759 DEBUG TRAIN Batch 3/6700 loss 39.604088 loss_att 39.934345 loss_ctc 55.462032 loss_rnnt 37.423645 lr 0.00088731 rank 2
2022-12-03 18:25:28,759 DEBUG TRAIN Batch 3/6700 loss 27.212372 loss_att 37.043488 loss_ctc 45.937805 loss_rnnt 22.749424 lr 0.00088772 rank 5
2022-12-03 18:25:28,766 DEBUG TRAIN Batch 3/6700 loss 35.268356 loss_att 43.090771 loss_ctc 53.082851 loss_rnnt 31.328606 lr 0.00088838 rank 4
2022-12-03 18:25:28,773 DEBUG TRAIN Batch 3/6700 loss 24.793905 loss_att 30.323000 loss_ctc 35.600441 loss_rnnt 22.247215 lr 0.00088776 rank 0
2022-12-03 18:25:28,776 DEBUG TRAIN Batch 3/6700 loss 17.539352 loss_att 22.381363 loss_ctc 26.593510 loss_rnnt 15.363728 lr 0.00088792 rank 6
2022-12-03 18:25:28,777 DEBUG TRAIN Batch 3/6700 loss 32.663906 loss_att 40.537636 loss_ctc 50.613983 loss_rnnt 28.695814 lr 0.00088759 rank 3
2022-12-03 18:25:28,782 DEBUG TRAIN Batch 3/6700 loss 24.638269 loss_att 29.682976 loss_ctc 42.780258 loss_rnnt 21.210396 lr 0.00088764 rank 1
2022-12-03 18:25:28,799 DEBUG TRAIN Batch 3/6700 loss 30.195240 loss_att 37.849030 loss_ctc 45.234463 loss_rnnt 26.659252 lr 0.00088824 rank 7
2022-12-03 18:26:41,913 DEBUG TRAIN Batch 3/6800 loss 24.589785 loss_att 28.275230 loss_ctc 37.411644 loss_rnnt 22.143112 lr 0.00088684 rank 7
2022-12-03 18:26:41,922 DEBUG TRAIN Batch 3/6800 loss 41.276859 loss_att 50.619606 loss_ctc 65.094116 loss_rnnt 36.232674 lr 0.00088698 rank 4
2022-12-03 18:26:41,923 DEBUG TRAIN Batch 3/6800 loss 31.041185 loss_att 37.248875 loss_ctc 46.517475 loss_rnnt 27.736139 lr 0.00088652 rank 6
2022-12-03 18:26:41,924 DEBUG TRAIN Batch 3/6800 loss 17.561420 loss_att 23.912868 loss_ctc 30.102570 loss_rnnt 14.618979 lr 0.00088637 rank 0
2022-12-03 18:26:41,929 DEBUG TRAIN Batch 3/6800 loss 26.370520 loss_att 34.795403 loss_ctc 48.233524 loss_rnnt 21.770475 lr 0.00088632 rank 5
2022-12-03 18:26:41,930 DEBUG TRAIN Batch 3/6800 loss 28.654360 loss_att 34.102398 loss_ctc 51.302837 loss_rnnt 24.544954 lr 0.00088620 rank 3
2022-12-03 18:26:41,935 DEBUG TRAIN Batch 3/6800 loss 15.112963 loss_att 23.677551 loss_ctc 26.650600 loss_rnnt 11.861693 lr 0.00088592 rank 2
2022-12-03 18:26:41,980 DEBUG TRAIN Batch 3/6800 loss 27.608456 loss_att 34.600117 loss_ctc 40.869766 loss_rnnt 24.441948 lr 0.00088624 rank 1
2022-12-03 18:27:54,215 DEBUG TRAIN Batch 3/6900 loss 19.022774 loss_att 22.276775 loss_ctc 29.472935 loss_rnnt 16.978621 lr 0.00088513 rank 6
2022-12-03 18:27:54,222 DEBUG TRAIN Batch 3/6900 loss 29.853569 loss_att 36.764595 loss_ctc 35.598816 loss_rnnt 27.705334 lr 0.00088485 rank 1
2022-12-03 18:27:54,222 DEBUG TRAIN Batch 3/6900 loss 22.398857 loss_att 27.325089 loss_ctc 37.500648 loss_rnnt 19.400038 lr 0.00088481 rank 3
2022-12-03 18:27:54,225 DEBUG TRAIN Batch 3/6900 loss 27.954271 loss_att 32.181877 loss_ctc 43.068977 loss_rnnt 25.093454 lr 0.00088498 rank 0
2022-12-03 18:27:54,225 DEBUG TRAIN Batch 3/6900 loss 27.233755 loss_att 34.533039 loss_ctc 48.962463 loss_rnnt 22.876738 lr 0.00088493 rank 5
2022-12-03 18:27:54,226 DEBUG TRAIN Batch 3/6900 loss 24.499735 loss_att 27.331963 loss_ctc 38.533138 loss_rnnt 22.062170 lr 0.00088453 rank 2
2022-12-03 18:27:54,232 DEBUG TRAIN Batch 3/6900 loss 42.739128 loss_att 47.591843 loss_ctc 76.670433 loss_rnnt 37.244415 lr 0.00088545 rank 7
2022-12-03 18:27:54,281 DEBUG TRAIN Batch 3/6900 loss 61.396484 loss_att 67.037773 loss_ctc 86.249443 loss_rnnt 56.954498 lr 0.00088559 rank 4
2022-12-03 18:29:06,408 DEBUG TRAIN Batch 3/7000 loss 46.415112 loss_att 47.680927 loss_ctc 65.378975 loss_rnnt 43.633434 lr 0.00088375 rank 6
2022-12-03 18:29:06,410 DEBUG TRAIN Batch 3/7000 loss 20.960262 loss_att 20.755793 loss_ctc 30.405056 loss_rnnt 19.741850 lr 0.00088343 rank 3
2022-12-03 18:29:06,410 DEBUG TRAIN Batch 3/7000 loss 14.893739 loss_att 15.402302 loss_ctc 21.094851 loss_rnnt 13.965210 lr 0.00088406 rank 7
2022-12-03 18:29:06,412 DEBUG TRAIN Batch 3/7000 loss 16.903597 loss_att 19.010954 loss_ctc 24.739933 loss_rnnt 15.437281 lr 0.00088420 rank 4
2022-12-03 18:29:06,413 DEBUG TRAIN Batch 3/7000 loss 28.352707 loss_att 29.155548 loss_ctc 38.955315 loss_rnnt 26.778458 lr 0.00088359 rank 0
2022-12-03 18:29:06,413 DEBUG TRAIN Batch 3/7000 loss 30.669987 loss_att 36.464417 loss_ctc 46.479324 loss_rnnt 27.403191 lr 0.00088315 rank 2
2022-12-03 18:29:06,423 DEBUG TRAIN Batch 3/7000 loss 22.177137 loss_att 24.127544 loss_ctc 30.628693 loss_rnnt 20.660181 lr 0.00088347 rank 1
2022-12-03 18:29:06,456 DEBUG TRAIN Batch 3/7000 loss 51.096096 loss_att 57.120258 loss_ctc 72.839348 loss_rnnt 46.992161 lr 0.00088355 rank 5
2022-12-03 18:30:20,375 DEBUG TRAIN Batch 3/7100 loss 30.945801 loss_att 34.759842 loss_ctc 44.196560 loss_rnnt 28.416225 lr 0.00088268 rank 7
2022-12-03 18:30:20,376 DEBUG TRAIN Batch 3/7100 loss 31.382521 loss_att 38.867012 loss_ctc 41.802608 loss_rnnt 28.496277 lr 0.00088282 rank 4
2022-12-03 18:30:20,380 DEBUG TRAIN Batch 3/7100 loss 27.539448 loss_att 36.776764 loss_ctc 40.468590 loss_rnnt 23.968100 lr 0.00088205 rank 3
2022-12-03 18:30:20,383 DEBUG TRAIN Batch 3/7100 loss 33.509224 loss_att 45.214161 loss_ctc 46.694042 loss_rnnt 29.410259 lr 0.00088237 rank 6
2022-12-03 18:30:20,390 DEBUG TRAIN Batch 3/7100 loss 24.674713 loss_att 33.215843 loss_ctc 50.464867 loss_rnnt 19.527800 lr 0.00088209 rank 1
2022-12-03 18:30:20,404 DEBUG TRAIN Batch 3/7100 loss 23.804440 loss_att 29.474609 loss_ctc 35.536114 loss_rnnt 21.106182 lr 0.00088222 rank 0
2022-12-03 18:30:20,419 DEBUG TRAIN Batch 3/7100 loss 26.312664 loss_att 29.649384 loss_ctc 34.374168 loss_rnnt 24.570456 lr 0.00088218 rank 5
2022-12-03 18:30:20,439 DEBUG TRAIN Batch 3/7100 loss 17.734041 loss_att 23.499556 loss_ctc 24.707680 loss_rnnt 15.651119 lr 0.00088178 rank 2
2022-12-03 18:31:32,466 DEBUG TRAIN Batch 3/7200 loss 30.839861 loss_att 35.662979 loss_ctc 45.976837 loss_rnnt 27.856976 lr 0.00088100 rank 6
2022-12-03 18:31:32,469 DEBUG TRAIN Batch 3/7200 loss 24.491436 loss_att 28.468466 loss_ctc 39.731773 loss_rnnt 21.663986 lr 0.00088041 rank 2
2022-12-03 18:31:32,469 DEBUG TRAIN Batch 3/7200 loss 30.164513 loss_att 40.220657 loss_ctc 45.074478 loss_rnnt 26.165287 lr 0.00088085 rank 0
2022-12-03 18:31:32,471 DEBUG TRAIN Batch 3/7200 loss 27.863041 loss_att 37.542767 loss_ctc 48.566193 loss_rnnt 23.166677 lr 0.00088068 rank 3
2022-12-03 18:31:32,471 DEBUG TRAIN Batch 3/7200 loss 61.992523 loss_att 68.019569 loss_ctc 84.933411 loss_rnnt 57.728333 lr 0.00088081 rank 5
2022-12-03 18:31:32,472 DEBUG TRAIN Batch 3/7200 loss 26.950260 loss_att 39.103844 loss_ctc 36.071442 loss_rnnt 23.303389 lr 0.00088072 rank 1
2022-12-03 18:31:32,473 DEBUG TRAIN Batch 3/7200 loss 23.921198 loss_att 32.356880 loss_ctc 39.150993 loss_rnnt 20.203421 lr 0.00088131 rank 7
2022-12-03 18:31:32,479 DEBUG TRAIN Batch 3/7200 loss 20.936020 loss_att 27.278881 loss_ctc 35.824780 loss_rnnt 17.682280 lr 0.00088145 rank 4
2022-12-03 18:32:45,030 DEBUG TRAIN Batch 3/7300 loss 21.058792 loss_att 25.995781 loss_ctc 35.343887 loss_rnnt 18.166714 lr 0.00087963 rank 6
2022-12-03 18:32:45,031 DEBUG TRAIN Batch 3/7300 loss 38.497456 loss_att 41.542862 loss_ctc 48.805725 loss_rnnt 36.513939 lr 0.00087944 rank 5
2022-12-03 18:32:45,036 DEBUG TRAIN Batch 3/7300 loss 22.828362 loss_att 28.751064 loss_ctc 42.020866 loss_rnnt 19.084818 lr 0.00087905 rank 2
2022-12-03 18:32:45,038 DEBUG TRAIN Batch 3/7300 loss 22.999979 loss_att 30.424946 loss_ctc 42.842751 loss_rnnt 18.869284 lr 0.00087995 rank 7
2022-12-03 18:32:45,040 DEBUG TRAIN Batch 3/7300 loss 27.016691 loss_att 35.018822 loss_ctc 45.056908 loss_rnnt 23.010902 lr 0.00088008 rank 4
2022-12-03 18:32:45,040 DEBUG TRAIN Batch 3/7300 loss 25.551876 loss_att 30.390858 loss_ctc 42.680344 loss_rnnt 22.300282 lr 0.00087948 rank 0
2022-12-03 18:32:45,045 DEBUG TRAIN Batch 3/7300 loss 24.325195 loss_att 30.559168 loss_ctc 36.623215 loss_rnnt 21.438663 lr 0.00087932 rank 3
2022-12-03 18:32:45,089 DEBUG TRAIN Batch 3/7300 loss 36.490997 loss_att 39.080948 loss_ctc 54.666992 loss_rnnt 33.549538 lr 0.00087936 rank 1
2022-12-03 18:33:57,936 DEBUG TRAIN Batch 3/7400 loss 18.320217 loss_att 29.648556 loss_ctc 31.322281 loss_rnnt 14.320941 lr 0.00087800 rank 1
2022-12-03 18:33:57,940 DEBUG TRAIN Batch 3/7400 loss 39.348694 loss_att 47.054596 loss_ctc 55.193932 loss_rnnt 35.694817 lr 0.00087809 rank 5
2022-12-03 18:33:57,953 DEBUG TRAIN Batch 3/7400 loss 24.639963 loss_att 32.542786 loss_ctc 36.635117 loss_rnnt 21.460045 lr 0.00087769 rank 2
2022-12-03 18:33:57,954 DEBUG TRAIN Batch 3/7400 loss 26.338390 loss_att 33.160851 loss_ctc 44.097424 loss_rnnt 22.606026 lr 0.00087827 rank 6
2022-12-03 18:33:57,956 DEBUG TRAIN Batch 3/7400 loss 11.291952 loss_att 16.663202 loss_ctc 19.789480 loss_rnnt 9.084699 lr 0.00087813 rank 0
2022-12-03 18:33:57,957 DEBUG TRAIN Batch 3/7400 loss 14.800264 loss_att 21.767559 loss_ctc 23.817995 loss_rnnt 12.204441 lr 0.00087872 rank 4
2022-12-03 18:33:57,959 DEBUG TRAIN Batch 3/7400 loss 28.944191 loss_att 41.166672 loss_ctc 48.149170 loss_rnnt 23.939032 lr 0.00087859 rank 7
2022-12-03 18:33:57,963 DEBUG TRAIN Batch 3/7400 loss 19.043783 loss_att 23.567856 loss_ctc 33.174850 loss_rnnt 16.254826 lr 0.00087796 rank 3
2022-12-03 18:35:11,789 DEBUG TRAIN Batch 3/7500 loss 21.284704 loss_att 24.773325 loss_ctc 34.317715 loss_rnnt 18.849243 lr 0.00087661 rank 3
2022-12-03 18:35:11,791 DEBUG TRAIN Batch 3/7500 loss 30.701811 loss_att 38.495369 loss_ctc 40.503227 loss_rnnt 27.836243 lr 0.00087692 rank 6
2022-12-03 18:35:11,793 DEBUG TRAIN Batch 3/7500 loss 33.933640 loss_att 41.279289 loss_ctc 53.357166 loss_rnnt 29.874706 lr 0.00087665 rank 1
2022-12-03 18:35:11,793 DEBUG TRAIN Batch 3/7500 loss 14.769787 loss_att 21.459106 loss_ctc 21.661438 loss_rnnt 12.513036 lr 0.00087673 rank 5
2022-12-03 18:35:11,797 DEBUG TRAIN Batch 3/7500 loss 19.476433 loss_att 26.643377 loss_ctc 32.295616 loss_rnnt 16.333820 lr 0.00087677 rank 0
2022-12-03 18:35:11,798 DEBUG TRAIN Batch 3/7500 loss 16.839664 loss_att 21.057037 loss_ctc 24.431530 loss_rnnt 14.983940 lr 0.00087634 rank 2
2022-12-03 18:35:11,800 DEBUG TRAIN Batch 3/7500 loss 17.391106 loss_att 22.902790 loss_ctc 30.598209 loss_rnnt 14.527822 lr 0.00087723 rank 7
2022-12-03 18:35:11,801 DEBUG TRAIN Batch 3/7500 loss 29.429344 loss_att 35.054382 loss_ctc 48.590492 loss_rnnt 25.749516 lr 0.00087737 rank 4
2022-12-03 18:36:24,820 DEBUG TRAIN Batch 3/7600 loss 18.167997 loss_att 24.460415 loss_ctc 36.769619 loss_rnnt 14.429298 lr 0.00087539 rank 5
2022-12-03 18:36:24,819 DEBUG TRAIN Batch 3/7600 loss 38.495659 loss_att 45.232231 loss_ctc 55.870571 loss_rnnt 34.831692 lr 0.00087531 rank 1
2022-12-03 18:36:24,821 DEBUG TRAIN Batch 3/7600 loss 13.805594 loss_att 15.667782 loss_ctc 21.018639 loss_rnnt 12.471417 lr 0.00087527 rank 3
2022-12-03 18:36:24,823 DEBUG TRAIN Batch 3/7600 loss 32.746655 loss_att 41.278263 loss_ctc 52.588020 loss_rnnt 28.394819 lr 0.00087558 rank 6
2022-12-03 18:36:24,824 DEBUG TRAIN Batch 3/7600 loss 23.651316 loss_att 29.695953 loss_ctc 36.005051 loss_rnnt 20.795221 lr 0.00087543 rank 0
2022-12-03 18:36:24,828 DEBUG TRAIN Batch 3/7600 loss 21.435841 loss_att 22.057150 loss_ctc 34.076206 loss_rnnt 19.626196 lr 0.00087602 rank 4
2022-12-03 18:36:24,830 DEBUG TRAIN Batch 3/7600 loss 30.272074 loss_att 32.263832 loss_ctc 42.999016 loss_rnnt 28.176796 lr 0.00087589 rank 7
2022-12-03 18:36:24,832 DEBUG TRAIN Batch 3/7600 loss 48.797165 loss_att 59.371632 loss_ctc 72.102341 loss_rnnt 43.574913 lr 0.00087500 rank 2
2022-12-03 18:37:36,970 DEBUG TRAIN Batch 3/7700 loss 13.264645 loss_att 20.600142 loss_ctc 27.305687 loss_rnnt 9.925406 lr 0.00087393 rank 3
2022-12-03 18:37:36,982 DEBUG TRAIN Batch 3/7700 loss 29.603394 loss_att 38.743767 loss_ctc 40.259598 loss_rnnt 26.354492 lr 0.00087397 rank 1
2022-12-03 18:37:36,984 DEBUG TRAIN Batch 3/7700 loss 23.755215 loss_att 24.528599 loss_ctc 32.853539 loss_rnnt 22.387426 lr 0.00087424 rank 6
2022-12-03 18:37:36,987 DEBUG TRAIN Batch 3/7700 loss 27.487673 loss_att 34.235649 loss_ctc 51.995972 loss_rnnt 22.870304 lr 0.00087366 rank 2
2022-12-03 18:37:36,987 DEBUG TRAIN Batch 3/7700 loss 24.334700 loss_att 33.077171 loss_ctc 35.906258 loss_rnnt 21.043331 lr 0.00087468 rank 4
2022-12-03 18:37:36,989 DEBUG TRAIN Batch 3/7700 loss 36.322250 loss_att 40.997223 loss_ctc 61.793743 loss_rnnt 31.991055 lr 0.00087409 rank 0
2022-12-03 18:37:36,990 DEBUG TRAIN Batch 3/7700 loss 18.731361 loss_att 27.821974 loss_ctc 29.376240 loss_rnnt 15.493922 lr 0.00087455 rank 7
2022-12-03 18:37:36,991 DEBUG TRAIN Batch 3/7700 loss 21.582542 loss_att 25.600115 loss_ctc 33.368881 loss_rnnt 19.207518 lr 0.00087405 rank 5
2022-12-03 18:38:51,226 DEBUG TRAIN Batch 3/7800 loss 17.367706 loss_att 21.965477 loss_ctc 27.913601 loss_rnnt 15.042033 lr 0.00087264 rank 1
2022-12-03 18:38:51,233 DEBUG TRAIN Batch 3/7800 loss 26.513411 loss_att 34.917282 loss_ctc 39.013805 loss_rnnt 23.165916 lr 0.00087233 rank 2
2022-12-03 18:38:51,246 DEBUG TRAIN Batch 3/7800 loss 37.031147 loss_att 48.340042 loss_ctc 65.653023 loss_rnnt 30.953121 lr 0.00087272 rank 5
2022-12-03 18:38:51,247 DEBUG TRAIN Batch 3/7800 loss 12.167690 loss_att 18.204227 loss_ctc 20.223074 loss_rnnt 9.886332 lr 0.00087260 rank 3
2022-12-03 18:38:51,252 DEBUG TRAIN Batch 3/7800 loss 30.640903 loss_att 40.284622 loss_ctc 55.412746 loss_rnnt 25.409246 lr 0.00087276 rank 0
2022-12-03 18:38:51,253 DEBUG TRAIN Batch 3/7800 loss 20.264431 loss_att 28.666935 loss_ctc 38.848412 loss_rnnt 16.106068 lr 0.00087321 rank 7
2022-12-03 18:38:51,256 DEBUG TRAIN Batch 3/7800 loss 22.017618 loss_att 27.759361 loss_ctc 34.994209 loss_rnnt 19.139057 lr 0.00087334 rank 4
2022-12-03 18:38:51,255 DEBUG TRAIN Batch 3/7800 loss 18.583536 loss_att 25.119171 loss_ctc 27.854712 loss_rnnt 16.040253 lr 0.00087290 rank 6
2022-12-03 18:40:04,123 DEBUG TRAIN Batch 3/7900 loss 39.362480 loss_att 48.142265 loss_ctc 61.842033 loss_rnnt 34.609249 lr 0.00087201 rank 4
2022-12-03 18:40:04,134 DEBUG TRAIN Batch 3/7900 loss 23.353146 loss_att 29.556557 loss_ctc 40.890617 loss_rnnt 19.774134 lr 0.00087143 rank 0
2022-12-03 18:40:04,134 DEBUG TRAIN Batch 3/7900 loss 33.187237 loss_att 42.041481 loss_ctc 45.149269 loss_rnnt 29.821449 lr 0.00087188 rank 7
2022-12-03 18:40:04,134 DEBUG TRAIN Batch 3/7900 loss 18.335331 loss_att 23.736145 loss_ctc 25.419323 loss_rnnt 16.310635 lr 0.00087158 rank 6
2022-12-03 18:40:04,135 DEBUG TRAIN Batch 3/7900 loss 17.804043 loss_att 26.395555 loss_ctc 29.708530 loss_rnnt 14.498476 lr 0.00087127 rank 3
2022-12-03 18:40:04,135 DEBUG TRAIN Batch 3/7900 loss 32.922951 loss_att 41.805878 loss_ctc 41.949730 loss_rnnt 29.942793 lr 0.00087139 rank 5
2022-12-03 18:40:04,143 DEBUG TRAIN Batch 3/7900 loss 24.601870 loss_att 32.077255 loss_ctc 30.099157 loss_rnnt 22.373819 lr 0.00087101 rank 2
2022-12-03 18:40:04,178 DEBUG TRAIN Batch 3/7900 loss 16.790951 loss_att 20.866510 loss_ctc 30.624578 loss_rnnt 14.131355 lr 0.00087131 rank 1
2022-12-03 18:41:15,443 DEBUG TRAIN Batch 3/8000 loss 41.369568 loss_att 44.571136 loss_ctc 58.770844 loss_rnnt 38.409088 lr 0.00086999 rank 1
2022-12-03 18:41:15,448 DEBUG TRAIN Batch 3/8000 loss 27.221729 loss_att 38.742466 loss_ctc 48.810463 loss_rnnt 22.039085 lr 0.00086995 rank 3
2022-12-03 18:41:15,452 DEBUG TRAIN Batch 3/8000 loss 28.051628 loss_att 38.140842 loss_ctc 47.998276 loss_rnnt 23.374231 lr 0.00086969 rank 2
2022-12-03 18:41:15,452 DEBUG TRAIN Batch 3/8000 loss 26.712769 loss_att 27.820141 loss_ctc 41.902157 loss_rnnt 24.466042 lr 0.00087011 rank 0
2022-12-03 18:41:15,453 DEBUG TRAIN Batch 3/8000 loss 23.984436 loss_att 35.013763 loss_ctc 38.040787 loss_rnnt 19.904388 lr 0.00087026 rank 6
2022-12-03 18:41:15,456 DEBUG TRAIN Batch 3/8000 loss 24.027412 loss_att 28.354641 loss_ctc 33.359756 loss_rnnt 21.917652 lr 0.00087069 rank 4
2022-12-03 18:41:15,457 DEBUG TRAIN Batch 3/8000 loss 21.526814 loss_att 30.467306 loss_ctc 36.487083 loss_rnnt 17.744011 lr 0.00087056 rank 7
2022-12-03 18:41:15,503 DEBUG TRAIN Batch 3/8000 loss 19.687630 loss_att 24.958635 loss_ctc 30.810806 loss_rnnt 17.150339 lr 0.00087007 rank 5
2022-12-03 18:42:27,462 DEBUG TRAIN Batch 3/8100 loss 22.780384 loss_att 26.947712 loss_ctc 31.913170 loss_rnnt 20.729214 lr 0.00086937 rank 4
2022-12-03 18:42:27,468 DEBUG TRAIN Batch 3/8100 loss 17.277716 loss_att 21.928917 loss_ctc 28.480600 loss_rnnt 14.853759 lr 0.00086838 rank 2
2022-12-03 18:42:27,468 DEBUG TRAIN Batch 3/8100 loss 13.244771 loss_att 17.106850 loss_ctc 21.841679 loss_rnnt 11.326101 lr 0.00086894 rank 6
2022-12-03 18:42:27,471 DEBUG TRAIN Batch 3/8100 loss 28.606489 loss_att 30.680893 loss_ctc 40.134907 loss_rnnt 26.654486 lr 0.00086880 rank 0
2022-12-03 18:42:27,472 DEBUG TRAIN Batch 3/8100 loss 32.691162 loss_att 40.675991 loss_ctc 53.186741 loss_rnnt 28.361450 lr 0.00086864 rank 3
2022-12-03 18:42:27,473 DEBUG TRAIN Batch 3/8100 loss 24.555119 loss_att 32.040779 loss_ctc 43.494514 loss_rnnt 20.532736 lr 0.00086876 rank 5
2022-12-03 18:42:27,479 DEBUG TRAIN Batch 3/8100 loss 33.500977 loss_att 35.310387 loss_ctc 49.594704 loss_rnnt 30.993263 lr 0.00086924 rank 7
2022-12-03 18:42:27,513 DEBUG TRAIN Batch 3/8100 loss 24.181416 loss_att 30.433672 loss_ctc 42.379761 loss_rnnt 20.504517 lr 0.00086868 rank 1
2022-12-03 18:43:40,184 DEBUG TRAIN Batch 3/8200 loss 17.964031 loss_att 20.188997 loss_ctc 26.520800 loss_rnnt 16.378136 lr 0.00086707 rank 2
2022-12-03 18:43:40,192 DEBUG TRAIN Batch 3/8200 loss 18.146889 loss_att 20.260017 loss_ctc 25.506691 loss_rnnt 16.742954 lr 0.00086749 rank 0
2022-12-03 18:43:40,194 DEBUG TRAIN Batch 3/8200 loss 15.862958 loss_att 20.240906 loss_ctc 26.408978 loss_rnnt 13.581232 lr 0.00086733 rank 3
2022-12-03 18:43:40,196 DEBUG TRAIN Batch 3/8200 loss 28.295385 loss_att 33.921623 loss_ctc 34.348560 loss_rnnt 26.363049 lr 0.00086745 rank 5
2022-12-03 18:43:40,196 DEBUG TRAIN Batch 3/8200 loss 24.920212 loss_att 29.998684 loss_ctc 38.068970 loss_rnnt 22.151352 lr 0.00086763 rank 6
2022-12-03 18:43:40,198 DEBUG TRAIN Batch 3/8200 loss 25.076963 loss_att 26.784210 loss_ctc 31.323605 loss_rnnt 23.902630 lr 0.00086806 rank 4
2022-12-03 18:43:40,199 DEBUG TRAIN Batch 3/8200 loss 34.020454 loss_att 38.156685 loss_ctc 47.829365 loss_rnnt 31.352018 lr 0.00086793 rank 7
2022-12-03 18:43:40,249 DEBUG TRAIN Batch 3/8200 loss 22.551422 loss_att 27.865265 loss_ctc 37.526817 loss_rnnt 19.491934 lr 0.00086737 rank 1
2022-12-03 18:44:51,667 DEBUG TRAIN Batch 3/8300 loss 32.295918 loss_att 38.024300 loss_ctc 45.290192 loss_rnnt 29.417675 lr 0.00086615 rank 5
2022-12-03 18:44:51,676 DEBUG TRAIN Batch 3/8300 loss 38.388092 loss_att 44.995132 loss_ctc 70.494095 loss_rnnt 32.785881 lr 0.00086663 rank 7
2022-12-03 18:44:51,684 DEBUG TRAIN Batch 3/8300 loss 27.388531 loss_att 30.666540 loss_ctc 40.782417 loss_rnnt 24.947077 lr 0.00086633 rank 6
2022-12-03 18:44:51,685 DEBUG TRAIN Batch 3/8300 loss 19.756029 loss_att 31.136204 loss_ctc 35.333275 loss_rnnt 15.403027 lr 0.00086619 rank 0
2022-12-03 18:44:51,686 DEBUG TRAIN Batch 3/8300 loss 33.968197 loss_att 39.228672 loss_ctc 54.505859 loss_rnnt 30.177748 lr 0.00086603 rank 3
2022-12-03 18:44:51,690 DEBUG TRAIN Batch 3/8300 loss 17.709591 loss_att 25.425461 loss_ctc 31.022141 loss_rnnt 14.391411 lr 0.00086676 rank 4
2022-12-03 18:44:51,692 DEBUG TRAIN Batch 3/8300 loss 29.324959 loss_att 40.419502 loss_ctc 44.563698 loss_rnnt 25.074219 lr 0.00086577 rank 2
2022-12-03 18:44:51,731 DEBUG TRAIN Batch 3/8300 loss 26.314877 loss_att 28.680538 loss_ctc 41.556770 loss_rnnt 23.809490 lr 0.00086607 rank 1
2022-12-03 18:45:39,675 DEBUG CV Batch 3/0 loss 4.306388 loss_att 3.935734 loss_ctc 7.329944 loss_rnnt 3.977378 history loss 4.146893 rank 7
2022-12-03 18:45:39,676 DEBUG CV Batch 3/0 loss 4.306388 loss_att 3.935734 loss_ctc 7.329944 loss_rnnt 3.977378 history loss 4.146893 rank 1
2022-12-03 18:45:39,678 DEBUG CV Batch 3/0 loss 4.306388 loss_att 3.935734 loss_ctc 7.329944 loss_rnnt 3.977378 history loss 4.146893 rank 2
2022-12-03 18:45:39,680 DEBUG CV Batch 3/0 loss 4.306388 loss_att 3.935734 loss_ctc 7.329944 loss_rnnt 3.977378 history loss 4.146893 rank 5
2022-12-03 18:45:39,686 DEBUG CV Batch 3/0 loss 4.306388 loss_att 3.935734 loss_ctc 7.329944 loss_rnnt 3.977378 history loss 4.146893 rank 6
2022-12-03 18:45:39,691 DEBUG CV Batch 3/0 loss 4.306388 loss_att 3.935734 loss_ctc 7.329944 loss_rnnt 3.977378 history loss 4.146893 rank 3
2022-12-03 18:45:39,695 DEBUG CV Batch 3/0 loss 4.306388 loss_att 3.935734 loss_ctc 7.329944 loss_rnnt 3.977378 history loss 4.146893 rank 0
2022-12-03 18:45:39,705 DEBUG CV Batch 3/0 loss 4.306388 loss_att 3.935734 loss_ctc 7.329944 loss_rnnt 3.977378 history loss 4.146893 rank 4
2022-12-03 18:45:50,970 DEBUG CV Batch 3/100 loss 19.284513 loss_att 19.948586 loss_ctc 31.135763 loss_rnnt 17.571531 history loss 8.618691 rank 1
2022-12-03 18:45:51,023 DEBUG CV Batch 3/100 loss 19.284513 loss_att 19.948586 loss_ctc 31.135763 loss_rnnt 17.571531 history loss 8.618691 rank 7
2022-12-03 18:45:51,064 DEBUG CV Batch 3/100 loss 19.284513 loss_att 19.948586 loss_ctc 31.135763 loss_rnnt 17.571531 history loss 8.618691 rank 2
2022-12-03 18:45:51,271 DEBUG CV Batch 3/100 loss 19.284513 loss_att 19.948586 loss_ctc 31.135763 loss_rnnt 17.571531 history loss 8.618691 rank 4
2022-12-03 18:45:51,315 DEBUG CV Batch 3/100 loss 19.284513 loss_att 19.948586 loss_ctc 31.135763 loss_rnnt 17.571531 history loss 8.618691 rank 6
2022-12-03 18:45:51,346 DEBUG CV Batch 3/100 loss 19.284513 loss_att 19.948586 loss_ctc 31.135763 loss_rnnt 17.571531 history loss 8.618691 rank 5
2022-12-03 18:45:51,468 DEBUG CV Batch 3/100 loss 19.284513 loss_att 19.948586 loss_ctc 31.135763 loss_rnnt 17.571531 history loss 8.618691 rank 0
2022-12-03 18:45:51,571 DEBUG CV Batch 3/100 loss 19.284513 loss_att 19.948586 loss_ctc 31.135763 loss_rnnt 17.571531 history loss 8.618691 rank 3
2022-12-03 18:46:04,611 DEBUG CV Batch 3/200 loss 24.684084 loss_att 40.647099 loss_ctc 31.612675 loss_rnnt 20.567669 history loss 9.577637 rank 2
2022-12-03 18:46:04,612 DEBUG CV Batch 3/200 loss 24.684084 loss_att 40.647099 loss_ctc 31.612675 loss_rnnt 20.567669 history loss 9.577637 rank 5
2022-12-03 18:46:04,621 DEBUG CV Batch 3/200 loss 24.684084 loss_att 40.647099 loss_ctc 31.612675 loss_rnnt 20.567669 history loss 9.577637 rank 1
2022-12-03 18:46:04,725 DEBUG CV Batch 3/200 loss 24.684084 loss_att 40.647099 loss_ctc 31.612675 loss_rnnt 20.567669 history loss 9.577637 rank 7
2022-12-03 18:46:05,198 DEBUG CV Batch 3/200 loss 24.684084 loss_att 40.647099 loss_ctc 31.612675 loss_rnnt 20.567669 history loss 9.577637 rank 6
2022-12-03 18:46:05,335 DEBUG CV Batch 3/200 loss 24.684084 loss_att 40.647099 loss_ctc 31.612675 loss_rnnt 20.567669 history loss 9.577637 rank 4
2022-12-03 18:46:05,520 DEBUG CV Batch 3/200 loss 24.684084 loss_att 40.647099 loss_ctc 31.612675 loss_rnnt 20.567669 history loss 9.577637 rank 0
2022-12-03 18:46:05,553 DEBUG CV Batch 3/200 loss 24.684084 loss_att 40.647099 loss_ctc 31.612675 loss_rnnt 20.567669 history loss 9.577637 rank 3
2022-12-03 18:46:16,513 DEBUG CV Batch 3/300 loss 8.735467 loss_att 11.583538 loss_ctc 17.739986 loss_rnnt 6.965250 history loss 9.594336 rank 2
2022-12-03 18:46:16,522 DEBUG CV Batch 3/300 loss 8.735467 loss_att 11.583538 loss_ctc 17.739986 loss_rnnt 6.965250 history loss 9.594336 rank 1
2022-12-03 18:46:16,607 DEBUG CV Batch 3/300 loss 8.735467 loss_att 11.583538 loss_ctc 17.739986 loss_rnnt 6.965250 history loss 9.594336 rank 5
2022-12-03 18:46:16,667 DEBUG CV Batch 3/300 loss 8.735467 loss_att 11.583538 loss_ctc 17.739986 loss_rnnt 6.965250 history loss 9.594336 rank 7
2022-12-03 18:46:17,233 DEBUG CV Batch 3/300 loss 8.735467 loss_att 11.583538 loss_ctc 17.739986 loss_rnnt 6.965250 history loss 9.594336 rank 4
2022-12-03 18:46:17,631 DEBUG CV Batch 3/300 loss 8.735467 loss_att 11.583538 loss_ctc 17.739986 loss_rnnt 6.965250 history loss 9.594336 rank 6
2022-12-03 18:46:18,193 DEBUG CV Batch 3/300 loss 8.735467 loss_att 11.583538 loss_ctc 17.739986 loss_rnnt 6.965250 history loss 9.594336 rank 3
2022-12-03 18:46:18,214 DEBUG CV Batch 3/300 loss 8.735467 loss_att 11.583538 loss_ctc 17.739986 loss_rnnt 6.965250 history loss 9.594336 rank 0
2022-12-03 18:46:28,367 DEBUG CV Batch 3/400 loss 36.917431 loss_att 79.694366 loss_ctc 55.206123 loss_rnnt 25.923552 history loss 10.960863 rank 1
2022-12-03 18:46:28,391 DEBUG CV Batch 3/400 loss 36.917431 loss_att 79.694366 loss_ctc 55.206123 loss_rnnt 25.923552 history loss 10.960863 rank 5
2022-12-03 18:46:28,588 DEBUG CV Batch 3/400 loss 36.917431 loss_att 79.694366 loss_ctc 55.206123 loss_rnnt 25.923552 history loss 10.960863 rank 2
2022-12-03 18:46:28,646 DEBUG CV Batch 3/400 loss 36.917431 loss_att 79.694366 loss_ctc 55.206123 loss_rnnt 25.923552 history loss 10.960863 rank 7
2022-12-03 18:46:29,358 DEBUG CV Batch 3/400 loss 36.917431 loss_att 79.694366 loss_ctc 55.206123 loss_rnnt 25.923552 history loss 10.960863 rank 4
2022-12-03 18:46:30,080 DEBUG CV Batch 3/400 loss 36.917431 loss_att 79.694366 loss_ctc 55.206123 loss_rnnt 25.923552 history loss 10.960863 rank 6
2022-12-03 18:46:30,819 DEBUG CV Batch 3/400 loss 36.917431 loss_att 79.694366 loss_ctc 55.206123 loss_rnnt 25.923552 history loss 10.960863 rank 3
2022-12-03 18:46:30,928 DEBUG CV Batch 3/400 loss 36.917431 loss_att 79.694366 loss_ctc 55.206123 loss_rnnt 25.923552 history loss 10.960863 rank 0
2022-12-03 18:46:38,578 DEBUG CV Batch 3/500 loss 15.255761 loss_att 17.802036 loss_ctc 24.399044 loss_rnnt 13.527402 history loss 12.020499 rank 1
2022-12-03 18:46:38,594 DEBUG CV Batch 3/500 loss 15.255761 loss_att 17.802036 loss_ctc 24.399044 loss_rnnt 13.527402 history loss 12.020499 rank 5
2022-12-03 18:46:38,972 DEBUG CV Batch 3/500 loss 15.255761 loss_att 17.802036 loss_ctc 24.399044 loss_rnnt 13.527402 history loss 12.020499 rank 2
2022-12-03 18:46:39,044 DEBUG CV Batch 3/500 loss 15.255761 loss_att 17.802036 loss_ctc 24.399044 loss_rnnt 13.527402 history loss 12.020499 rank 7
2022-12-03 18:46:40,061 DEBUG CV Batch 3/500 loss 15.255761 loss_att 17.802036 loss_ctc 24.399044 loss_rnnt 13.527402 history loss 12.020499 rank 4
2022-12-03 18:46:40,934 DEBUG CV Batch 3/500 loss 15.255761 loss_att 17.802036 loss_ctc 24.399044 loss_rnnt 13.527402 history loss 12.020499 rank 6
2022-12-03 18:46:41,922 DEBUG CV Batch 3/500 loss 15.255761 loss_att 17.802036 loss_ctc 24.399044 loss_rnnt 13.527402 history loss 12.020499 rank 3
2022-12-03 18:46:42,039 DEBUG CV Batch 3/500 loss 15.255761 loss_att 17.802036 loss_ctc 24.399044 loss_rnnt 13.527402 history loss 12.020499 rank 0
2022-12-03 18:46:50,633 DEBUG CV Batch 3/600 loss 11.584510 loss_att 13.889821 loss_ctc 16.721657 loss_rnnt 10.438495 history loss 13.277887 rank 1
2022-12-03 18:46:50,741 DEBUG CV Batch 3/600 loss 11.584510 loss_att 13.889821 loss_ctc 16.721657 loss_rnnt 10.438495 history loss 13.277887 rank 5
2022-12-03 18:46:51,071 DEBUG CV Batch 3/600 loss 11.584510 loss_att 13.889821 loss_ctc 16.721657 loss_rnnt 10.438495 history loss 13.277887 rank 7
2022-12-03 18:46:51,168 DEBUG CV Batch 3/600 loss 11.584510 loss_att 13.889821 loss_ctc 16.721657 loss_rnnt 10.438495 history loss 13.277887 rank 2
2022-12-03 18:46:52,105 DEBUG CV Batch 3/600 loss 11.584510 loss_att 13.889821 loss_ctc 16.721657 loss_rnnt 10.438495 history loss 13.277887 rank 4
2022-12-03 18:46:53,498 DEBUG CV Batch 3/600 loss 11.584510 loss_att 13.889821 loss_ctc 16.721657 loss_rnnt 10.438495 history loss 13.277887 rank 6
2022-12-03 18:46:54,587 DEBUG CV Batch 3/600 loss 11.584510 loss_att 13.889821 loss_ctc 16.721657 loss_rnnt 10.438495 history loss 13.277887 rank 3
2022-12-03 18:46:54,837 DEBUG CV Batch 3/600 loss 11.584510 loss_att 13.889821 loss_ctc 16.721657 loss_rnnt 10.438495 history loss 13.277887 rank 0
2022-12-03 18:47:01,908 DEBUG CV Batch 3/700 loss 39.888699 loss_att 97.167221 loss_ctc 60.191605 loss_rnnt 25.725939 history loss 14.212447 rank 5
2022-12-03 18:47:02,096 DEBUG CV Batch 3/700 loss 39.888699 loss_att 97.167221 loss_ctc 60.191605 loss_rnnt 25.725939 history loss 14.212447 rank 1
2022-12-03 18:47:02,310 DEBUG CV Batch 3/700 loss 39.888699 loss_att 97.167221 loss_ctc 60.191605 loss_rnnt 25.725939 history loss 14.212447 rank 7
2022-12-03 18:47:02,480 DEBUG CV Batch 3/700 loss 39.888699 loss_att 97.167221 loss_ctc 60.191605 loss_rnnt 25.725939 history loss 14.212447 rank 2
2022-12-03 18:47:03,316 DEBUG CV Batch 3/700 loss 39.888699 loss_att 97.167221 loss_ctc 60.191605 loss_rnnt 25.725939 history loss 14.212447 rank 4
2022-12-03 18:47:05,365 DEBUG CV Batch 3/700 loss 39.888699 loss_att 97.167221 loss_ctc 60.191605 loss_rnnt 25.725939 history loss 14.212447 rank 6
2022-12-03 18:47:06,669 DEBUG CV Batch 3/700 loss 39.888699 loss_att 97.167221 loss_ctc 60.191605 loss_rnnt 25.725939 history loss 14.212447 rank 3
2022-12-03 18:47:06,760 DEBUG CV Batch 3/700 loss 39.888699 loss_att 97.167221 loss_ctc 60.191605 loss_rnnt 25.725939 history loss 14.212447 rank 0
2022-12-03 18:47:14,010 DEBUG CV Batch 3/800 loss 21.219135 loss_att 20.686419 loss_ctc 33.238678 loss_rnnt 19.723072 history loss 13.452303 rank 5
2022-12-03 18:47:14,172 DEBUG CV Batch 3/800 loss 21.219135 loss_att 20.686419 loss_ctc 33.238678 loss_rnnt 19.723072 history loss 13.452303 rank 7
2022-12-03 18:47:14,320 DEBUG CV Batch 3/800 loss 21.219135 loss_att 20.686419 loss_ctc 33.238678 loss_rnnt 19.723072 history loss 13.452303 rank 1
2022-12-03 18:47:14,749 DEBUG CV Batch 3/800 loss 21.219135 loss_att 20.686419 loss_ctc 33.238678 loss_rnnt 19.723072 history loss 13.452303 rank 2
2022-12-03 18:47:15,183 DEBUG CV Batch 3/800 loss 21.219135 loss_att 20.686419 loss_ctc 33.238678 loss_rnnt 19.723072 history loss 13.452303 rank 4
2022-12-03 18:47:16,973 DEBUG CV Batch 3/800 loss 21.219135 loss_att 20.686419 loss_ctc 33.238678 loss_rnnt 19.723072 history loss 13.452303 rank 6
2022-12-03 18:47:18,520 DEBUG CV Batch 3/800 loss 21.219135 loss_att 20.686419 loss_ctc 33.238678 loss_rnnt 19.723072 history loss 13.452303 rank 3
2022-12-03 18:47:18,544 DEBUG CV Batch 3/800 loss 21.219135 loss_att 20.686419 loss_ctc 33.238678 loss_rnnt 19.723072 history loss 13.452303 rank 0
2022-12-03 18:47:27,789 DEBUG CV Batch 3/900 loss 24.852713 loss_att 42.580162 loss_ctc 40.203156 loss_rnnt 19.260498 history loss 13.203786 rank 1
2022-12-03 18:47:27,789 DEBUG CV Batch 3/900 loss 24.852713 loss_att 42.580162 loss_ctc 40.203156 loss_rnnt 19.260498 history loss 13.203786 rank 5
2022-12-03 18:47:27,927 DEBUG CV Batch 3/900 loss 24.852713 loss_att 42.580162 loss_ctc 40.203156 loss_rnnt 19.260498 history loss 13.203786 rank 7
2022-12-03 18:47:28,223 DEBUG CV Batch 3/900 loss 24.852713 loss_att 42.580162 loss_ctc 40.203156 loss_rnnt 19.260498 history loss 13.203786 rank 2
2022-12-03 18:47:28,967 DEBUG CV Batch 3/900 loss 24.852713 loss_att 42.580162 loss_ctc 40.203156 loss_rnnt 19.260498 history loss 13.203786 rank 4
2022-12-03 18:47:30,875 DEBUG CV Batch 3/900 loss 24.852713 loss_att 42.580162 loss_ctc 40.203156 loss_rnnt 19.260498 history loss 13.203786 rank 6
2022-12-03 18:47:32,580 DEBUG CV Batch 3/900 loss 24.852713 loss_att 42.580162 loss_ctc 40.203156 loss_rnnt 19.260498 history loss 13.203786 rank 3
2022-12-03 18:47:32,671 DEBUG CV Batch 3/900 loss 24.852713 loss_att 42.580162 loss_ctc 40.203156 loss_rnnt 19.260498 history loss 13.203786 rank 0
2022-12-03 18:47:39,768 DEBUG CV Batch 3/1000 loss 10.774855 loss_att 11.625460 loss_ctc 15.359175 loss_rnnt 9.993490 history loss 12.861701 rank 1
2022-12-03 18:47:39,894 DEBUG CV Batch 3/1000 loss 10.774855 loss_att 11.625460 loss_ctc 15.359175 loss_rnnt 9.993490 history loss 12.861701 rank 5
2022-12-03 18:47:40,134 DEBUG CV Batch 3/1000 loss 10.774855 loss_att 11.625460 loss_ctc 15.359175 loss_rnnt 9.993490 history loss 12.861701 rank 7
2022-12-03 18:47:40,478 DEBUG CV Batch 3/1000 loss 10.774855 loss_att 11.625460 loss_ctc 15.359175 loss_rnnt 9.993490 history loss 12.861701 rank 2
2022-12-03 18:47:41,652 DEBUG CV Batch 3/1000 loss 10.774855 loss_att 11.625460 loss_ctc 15.359175 loss_rnnt 9.993490 history loss 12.861701 rank 4
2022-12-03 18:47:43,620 DEBUG CV Batch 3/1000 loss 10.774855 loss_att 11.625460 loss_ctc 15.359175 loss_rnnt 9.993490 history loss 12.861701 rank 6
2022-12-03 18:47:45,458 DEBUG CV Batch 3/1000 loss 10.774855 loss_att 11.625460 loss_ctc 15.359175 loss_rnnt 9.993490 history loss 12.861701 rank 0
2022-12-03 18:47:45,477 DEBUG CV Batch 3/1000 loss 10.774855 loss_att 11.625460 loss_ctc 15.359175 loss_rnnt 9.993490 history loss 12.861701 rank 3
2022-12-03 18:47:51,484 DEBUG CV Batch 3/1100 loss 9.066309 loss_att 8.647867 loss_ctc 15.038357 loss_rnnt 8.353724 history loss 12.839057 rank 1
2022-12-03 18:47:52,045 DEBUG CV Batch 3/1100 loss 9.066309 loss_att 8.647867 loss_ctc 15.038357 loss_rnnt 8.353724 history loss 12.839057 rank 7
2022-12-03 18:47:52,160 DEBUG CV Batch 3/1100 loss 9.066309 loss_att 8.647867 loss_ctc 15.038357 loss_rnnt 8.353724 history loss 12.839057 rank 5
2022-12-03 18:47:52,378 DEBUG CV Batch 3/1100 loss 9.066309 loss_att 8.647867 loss_ctc 15.038357 loss_rnnt 8.353724 history loss 12.839057 rank 2
2022-12-03 18:47:53,521 DEBUG CV Batch 3/1100 loss 9.066309 loss_att 8.647867 loss_ctc 15.038357 loss_rnnt 8.353724 history loss 12.839057 rank 4
2022-12-03 18:47:56,049 DEBUG CV Batch 3/1100 loss 9.066309 loss_att 8.647867 loss_ctc 15.038357 loss_rnnt 8.353724 history loss 12.839057 rank 6
2022-12-03 18:47:58,027 DEBUG CV Batch 3/1100 loss 9.066309 loss_att 8.647867 loss_ctc 15.038357 loss_rnnt 8.353724 history loss 12.839057 rank 0
2022-12-03 18:47:58,175 DEBUG CV Batch 3/1100 loss 9.066309 loss_att 8.647867 loss_ctc 15.038357 loss_rnnt 8.353724 history loss 12.839057 rank 3
2022-12-03 18:48:02,020 DEBUG CV Batch 3/1200 loss 15.120886 loss_att 18.486013 loss_ctc 21.377028 loss_rnnt 13.613708 history loss 13.288690 rank 1
2022-12-03 18:48:02,438 DEBUG CV Batch 3/1200 loss 15.120886 loss_att 18.486013 loss_ctc 21.377028 loss_rnnt 13.613708 history loss 13.288690 rank 7
2022-12-03 18:48:02,576 DEBUG CV Batch 3/1200 loss 15.120886 loss_att 18.486013 loss_ctc 21.377028 loss_rnnt 13.613708 history loss 13.288690 rank 5
2022-12-03 18:48:02,859 DEBUG CV Batch 3/1200 loss 15.120886 loss_att 18.486013 loss_ctc 21.377028 loss_rnnt 13.613708 history loss 13.288690 rank 2
2022-12-03 18:48:04,181 DEBUG CV Batch 3/1200 loss 15.120886 loss_att 18.486013 loss_ctc 21.377028 loss_rnnt 13.613708 history loss 13.288690 rank 4
2022-12-03 18:48:07,167 DEBUG CV Batch 3/1200 loss 15.120886 loss_att 18.486013 loss_ctc 21.377028 loss_rnnt 13.613708 history loss 13.288690 rank 6
2022-12-03 18:48:09,395 DEBUG CV Batch 3/1200 loss 15.120886 loss_att 18.486013 loss_ctc 21.377028 loss_rnnt 13.613708 history loss 13.288690 rank 0
2022-12-03 18:48:09,479 DEBUG CV Batch 3/1200 loss 15.120886 loss_att 18.486013 loss_ctc 21.377028 loss_rnnt 13.613708 history loss 13.288690 rank 3
2022-12-03 18:48:14,320 DEBUG CV Batch 3/1300 loss 10.690219 loss_att 11.628766 loss_ctc 16.587563 loss_rnnt 9.716197 history loss 13.691557 rank 1
2022-12-03 18:48:14,390 DEBUG CV Batch 3/1300 loss 10.690219 loss_att 11.628766 loss_ctc 16.587563 loss_rnnt 9.716197 history loss 13.691557 rank 5
2022-12-03 18:48:14,495 DEBUG CV Batch 3/1300 loss 10.690219 loss_att 11.628766 loss_ctc 16.587563 loss_rnnt 9.716197 history loss 13.691557 rank 7
2022-12-03 18:48:14,858 DEBUG CV Batch 3/1300 loss 10.690219 loss_att 11.628766 loss_ctc 16.587563 loss_rnnt 9.716197 history loss 13.691557 rank 2
2022-12-03 18:48:16,139 DEBUG CV Batch 3/1300 loss 10.690219 loss_att 11.628766 loss_ctc 16.587563 loss_rnnt 9.716197 history loss 13.691557 rank 4
2022-12-03 18:48:19,703 DEBUG CV Batch 3/1300 loss 10.690219 loss_att 11.628766 loss_ctc 16.587563 loss_rnnt 9.716197 history loss 13.691557 rank 6
2022-12-03 18:48:22,003 DEBUG CV Batch 3/1300 loss 10.690219 loss_att 11.628766 loss_ctc 16.587563 loss_rnnt 9.716197 history loss 13.691557 rank 0
2022-12-03 18:48:22,159 DEBUG CV Batch 3/1300 loss 10.690219 loss_att 11.628766 loss_ctc 16.587563 loss_rnnt 9.716197 history loss 13.691557 rank 3
2022-12-03 18:48:25,277 DEBUG CV Batch 3/1400 loss 25.510796 loss_att 52.282913 loss_ctc 37.583450 loss_rnnt 18.546684 history loss 14.151542 rank 1
2022-12-03 18:48:25,497 DEBUG CV Batch 3/1400 loss 25.510796 loss_att 52.282913 loss_ctc 37.583450 loss_rnnt 18.546684 history loss 14.151542 rank 5
2022-12-03 18:48:25,687 DEBUG CV Batch 3/1400 loss 25.510796 loss_att 52.282913 loss_ctc 37.583450 loss_rnnt 18.546684 history loss 14.151542 rank 7
2022-12-03 18:48:26,097 DEBUG CV Batch 3/1400 loss 25.510796 loss_att 52.282913 loss_ctc 37.583450 loss_rnnt 18.546684 history loss 14.151542 rank 2
2022-12-03 18:48:27,137 DEBUG CV Batch 3/1400 loss 25.510796 loss_att 52.282913 loss_ctc 37.583450 loss_rnnt 18.546684 history loss 14.151542 rank 4
2022-12-03 18:48:31,384 DEBUG CV Batch 3/1400 loss 25.510796 loss_att 52.282913 loss_ctc 37.583450 loss_rnnt 18.546684 history loss 14.151542 rank 6
2022-12-03 18:48:33,986 DEBUG CV Batch 3/1400 loss 25.510796 loss_att 52.282913 loss_ctc 37.583450 loss_rnnt 18.546684 history loss 14.151542 rank 0
2022-12-03 18:48:34,146 DEBUG CV Batch 3/1400 loss 25.510796 loss_att 52.282913 loss_ctc 37.583450 loss_rnnt 18.546684 history loss 14.151542 rank 3
2022-12-03 18:48:37,276 DEBUG CV Batch 3/1500 loss 16.675575 loss_att 18.918406 loss_ctc 21.163685 loss_rnnt 15.628593 history loss 13.860563 rank 5
2022-12-03 18:48:37,537 DEBUG CV Batch 3/1500 loss 16.675575 loss_att 18.918406 loss_ctc 21.163685 loss_rnnt 15.628593 history loss 13.860563 rank 1
2022-12-03 18:48:37,537 DEBUG CV Batch 3/1500 loss 16.675575 loss_att 18.918406 loss_ctc 21.163685 loss_rnnt 15.628593 history loss 13.860563 rank 7
2022-12-03 18:48:38,483 DEBUG CV Batch 3/1500 loss 16.675575 loss_att 18.918406 loss_ctc 21.163685 loss_rnnt 15.628593 history loss 13.860563 rank 2
2022-12-03 18:48:38,646 DEBUG CV Batch 3/1500 loss 16.675575 loss_att 18.918406 loss_ctc 21.163685 loss_rnnt 15.628593 history loss 13.860563 rank 4
2022-12-03 18:48:43,430 DEBUG CV Batch 3/1500 loss 16.675575 loss_att 18.918406 loss_ctc 21.163685 loss_rnnt 15.628593 history loss 13.860563 rank 6
2022-12-03 18:48:46,285 DEBUG CV Batch 3/1500 loss 16.675575 loss_att 18.918406 loss_ctc 21.163685 loss_rnnt 15.628593 history loss 13.860563 rank 3
2022-12-03 18:48:46,352 DEBUG CV Batch 3/1500 loss 16.675575 loss_att 18.918406 loss_ctc 21.163685 loss_rnnt 15.628593 history loss 13.860563 rank 0
2022-12-03 18:48:50,787 DEBUG CV Batch 3/1600 loss 14.237356 loss_att 33.342945 loss_ctc 26.846994 loss_rnnt 8.734953 history loss 13.737851 rank 7
2022-12-03 18:48:50,859 DEBUG CV Batch 3/1600 loss 14.237356 loss_att 33.342945 loss_ctc 26.846994 loss_rnnt 8.734953 history loss 13.737851 rank 1
2022-12-03 18:48:51,046 DEBUG CV Batch 3/1600 loss 14.237356 loss_att 33.342945 loss_ctc 26.846994 loss_rnnt 8.734953 history loss 13.737851 rank 5
2022-12-03 18:48:51,904 DEBUG CV Batch 3/1600 loss 14.237356 loss_att 33.342945 loss_ctc 26.846994 loss_rnnt 8.734953 history loss 13.737851 rank 2
2022-12-03 18:48:52,237 DEBUG CV Batch 3/1600 loss 14.237356 loss_att 33.342945 loss_ctc 26.846994 loss_rnnt 8.734953 history loss 13.737851 rank 4
2022-12-03 18:48:57,026 DEBUG CV Batch 3/1600 loss 14.237356 loss_att 33.342945 loss_ctc 26.846994 loss_rnnt 8.734953 history loss 13.737851 rank 6
2022-12-03 18:48:59,907 DEBUG CV Batch 3/1600 loss 14.237356 loss_att 33.342945 loss_ctc 26.846994 loss_rnnt 8.734953 history loss 13.737851 rank 3
2022-12-03 18:48:59,996 DEBUG CV Batch 3/1600 loss 14.237356 loss_att 33.342945 loss_ctc 26.846994 loss_rnnt 8.734953 history loss 13.737851 rank 0
2022-12-03 18:49:03,043 DEBUG CV Batch 3/1700 loss 16.773457 loss_att 19.184843 loss_ctc 27.957310 loss_rnnt 14.799999 history loss 13.555162 rank 1
2022-12-03 18:49:03,339 DEBUG CV Batch 3/1700 loss 16.773457 loss_att 19.184843 loss_ctc 27.957310 loss_rnnt 14.799999 history loss 13.555162 rank 7
2022-12-03 18:49:03,713 DEBUG CV Batch 3/1700 loss 16.773457 loss_att 19.184843 loss_ctc 27.957310 loss_rnnt 14.799999 history loss 13.555162 rank 5
2022-12-03 18:49:04,540 DEBUG CV Batch 3/1700 loss 16.773457 loss_att 19.184843 loss_ctc 27.957310 loss_rnnt 14.799999 history loss 13.555162 rank 2
2022-12-03 18:49:04,874 DEBUG CV Batch 3/1700 loss 16.773457 loss_att 19.184843 loss_ctc 27.957310 loss_rnnt 14.799999 history loss 13.555162 rank 4
2022-12-03 18:49:09,734 DEBUG CV Batch 3/1700 loss 16.773457 loss_att 19.184843 loss_ctc 27.957310 loss_rnnt 14.799999 history loss 13.555162 rank 6
2022-12-03 18:49:12,249 INFO Epoch 3 CV info cv_loss 13.504969487827385
2022-12-03 18:49:12,249 INFO Epoch 4 TRAIN info lr 0.0008656402795311361
2022-12-03 18:49:12,251 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 18:49:12,437 DEBUG CV Batch 3/1700 loss 16.773457 loss_att 19.184843 loss_ctc 27.957310 loss_rnnt 14.799999 history loss 13.555162 rank 3
2022-12-03 18:49:12,593 DEBUG CV Batch 3/1700 loss 16.773457 loss_att 19.184843 loss_ctc 27.957310 loss_rnnt 14.799999 history loss 13.555162 rank 0
2022-12-03 18:49:12,832 INFO Epoch 3 CV info cv_loss 13.504969487827385
2022-12-03 18:49:12,833 INFO Epoch 4 TRAIN info lr 0.0008660037539612091
2022-12-03 18:49:12,835 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 18:49:13,301 INFO Epoch 3 CV info cv_loss 13.504969487827385
2022-12-03 18:49:13,302 INFO Epoch 4 TRAIN info lr 0.0008658219595258424
2022-12-03 18:49:13,306 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 18:49:13,993 INFO Epoch 3 CV info cv_loss 13.504969487827385
2022-12-03 18:49:13,993 INFO Epoch 4 TRAIN info lr 0.0008650182438596602
2022-12-03 18:49:13,998 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 18:49:14,158 INFO Epoch 3 CV info cv_loss 13.504969487827385
2022-12-03 18:49:14,158 INFO Epoch 4 TRAIN info lr 0.0008662246583727777
2022-12-03 18:49:14,160 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 18:49:18,920 INFO Epoch 3 CV info cv_loss 13.504969487827385
2022-12-03 18:49:18,920 INFO Epoch 4 TRAIN info lr 0.0008659258280394903
2022-12-03 18:49:18,922 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 18:49:21,817 INFO Epoch 3 CV info cv_loss 13.504969487827385
2022-12-03 18:49:21,818 INFO Epoch 4 TRAIN info lr 0.0008654457492517003
2022-12-03 18:49:21,822 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 18:49:22,078 INFO Epoch 3 CV info cv_loss 13.504969487827385
2022-12-03 18:49:22,078 INFO Checkpoint: save to checkpoint exp/1202_encoder_bias_30_0.1/3.pt
2022-12-03 18:49:23,227 INFO Epoch 4 TRAIN info lr 0.0008655494824115181
2022-12-03 18:49:23,231 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 18:50:21,821 DEBUG TRAIN Batch 4/0 loss 10.655022 loss_att 10.918561 loss_ctc 12.966658 loss_rnnt 10.294096 lr 0.00086563 rank 1
2022-12-03 18:50:21,826 DEBUG TRAIN Batch 4/0 loss 13.864994 loss_att 14.843967 loss_ctc 18.064754 loss_rnnt 13.109231 lr 0.00086501 rank 2
2022-12-03 18:50:21,827 DEBUG TRAIN Batch 4/0 loss 9.850791 loss_att 10.823808 loss_ctc 13.711637 loss_rnnt 9.141408 lr 0.00086591 rank 6
2022-12-03 18:50:21,831 DEBUG TRAIN Batch 4/0 loss 9.807928 loss_att 10.154957 loss_ctc 13.304866 loss_rnnt 9.272264 lr 0.00086599 rank 7
2022-12-03 18:50:21,841 DEBUG TRAIN Batch 4/0 loss 16.317652 loss_att 16.655396 loss_ctc 22.485590 loss_rnnt 15.427711 lr 0.00086581 rank 5
2022-12-03 18:50:21,855 DEBUG TRAIN Batch 4/0 loss 15.363461 loss_att 15.473222 loss_ctc 21.356737 loss_rnnt 14.542405 lr 0.00086621 rank 4
2022-12-03 18:50:21,856 DEBUG TRAIN Batch 4/0 loss 12.731549 loss_att 11.894975 loss_ctc 16.231075 loss_rnnt 12.432260 lr 0.00086554 rank 0
2022-12-03 18:50:21,868 DEBUG TRAIN Batch 4/0 loss 15.544659 loss_att 16.136438 loss_ctc 20.199146 loss_rnnt 14.805703 lr 0.00086543 rank 3
2022-12-03 18:51:33,114 DEBUG TRAIN Batch 4/100 loss 23.659437 loss_att 27.588192 loss_ctc 38.274605 loss_rnnt 20.924995 lr 0.00086414 rank 3
2022-12-03 18:51:33,122 DEBUG TRAIN Batch 4/100 loss 32.888039 loss_att 40.497059 loss_ctc 48.369133 loss_rnnt 29.302090 lr 0.00086424 rank 0
2022-12-03 18:51:33,129 DEBUG TRAIN Batch 4/100 loss 25.810276 loss_att 27.701298 loss_ctc 37.345757 loss_rnnt 23.894009 lr 0.00086451 rank 5
2022-12-03 18:51:33,129 DEBUG TRAIN Batch 4/100 loss 31.842461 loss_att 37.370903 loss_ctc 43.638458 loss_rnnt 29.163971 lr 0.00086433 rank 1
2022-12-03 18:51:33,132 DEBUG TRAIN Batch 4/100 loss 17.670313 loss_att 19.916243 loss_ctc 28.463524 loss_rnnt 15.782032 lr 0.00086462 rank 6
2022-12-03 18:51:33,134 DEBUG TRAIN Batch 4/100 loss 29.286800 loss_att 36.011707 loss_ctc 47.371262 loss_rnnt 25.530560 lr 0.00086491 rank 4
2022-12-03 18:51:33,134 DEBUG TRAIN Batch 4/100 loss 22.229076 loss_att 30.391104 loss_ctc 43.478783 loss_rnnt 17.763374 lr 0.00086469 rank 7
2022-12-03 18:51:33,169 DEBUG TRAIN Batch 4/100 loss 20.884001 loss_att 28.053919 loss_ctc 32.788811 loss_rnnt 17.862709 lr 0.00086371 rank 2
2022-12-03 18:52:44,673 DEBUG TRAIN Batch 4/200 loss 27.652502 loss_att 31.845177 loss_ctc 41.377342 loss_rnnt 24.983990 lr 0.00086304 rank 1
2022-12-03 18:52:44,679 DEBUG TRAIN Batch 4/200 loss 26.335629 loss_att 31.348061 loss_ctc 39.906147 loss_rnnt 23.523741 lr 0.00086362 rank 4
2022-12-03 18:52:44,683 DEBUG TRAIN Batch 4/200 loss 21.873165 loss_att 34.281734 loss_ctc 44.232498 loss_rnnt 16.410206 lr 0.00086322 rank 5
2022-12-03 18:52:44,688 DEBUG TRAIN Batch 4/200 loss 39.752590 loss_att 50.311913 loss_ctc 65.539154 loss_rnnt 34.202515 lr 0.00086295 rank 0
2022-12-03 18:52:44,688 DEBUG TRAIN Batch 4/200 loss 19.241333 loss_att 23.603680 loss_ctc 30.340628 loss_rnnt 16.888956 lr 0.00086333 rank 6
2022-12-03 18:52:44,693 DEBUG TRAIN Batch 4/200 loss 16.822882 loss_att 24.635612 loss_ctc 23.329840 loss_rnnt 14.392740 lr 0.00086340 rank 7
2022-12-03 18:52:44,694 DEBUG TRAIN Batch 4/200 loss 30.409483 loss_att 36.901142 loss_ctc 48.207764 loss_rnnt 26.738049 lr 0.00086285 rank 3
2022-12-03 18:52:44,737 DEBUG TRAIN Batch 4/200 loss 20.561966 loss_att 25.369675 loss_ctc 34.527863 loss_rnnt 17.738306 lr 0.00086243 rank 2
2022-12-03 18:53:57,641 DEBUG TRAIN Batch 4/300 loss 39.173950 loss_att 46.140987 loss_ctc 58.191952 loss_rnnt 35.244804 lr 0.00086204 rank 6
2022-12-03 18:53:57,644 DEBUG TRAIN Batch 4/300 loss 19.688511 loss_att 26.348885 loss_ctc 34.292301 loss_rnnt 16.409264 lr 0.00086157 rank 3
2022-12-03 18:53:57,644 DEBUG TRAIN Batch 4/300 loss 40.354649 loss_att 48.723572 loss_ctc 63.988052 loss_rnnt 35.529743 lr 0.00086194 rank 5
2022-12-03 18:53:57,646 DEBUG TRAIN Batch 4/300 loss 31.419914 loss_att 40.892063 loss_ctc 50.471779 loss_rnnt 26.985233 lr 0.00086167 rank 0
2022-12-03 18:53:57,646 DEBUG TRAIN Batch 4/300 loss 35.497063 loss_att 38.301441 loss_ctc 51.971130 loss_rnnt 32.739647 lr 0.00086212 rank 7
2022-12-03 18:53:57,649 DEBUG TRAIN Batch 4/300 loss 22.016239 loss_att 29.011562 loss_ctc 33.463959 loss_rnnt 19.090813 lr 0.00086234 rank 4
2022-12-03 18:53:57,652 DEBUG TRAIN Batch 4/300 loss 17.061296 loss_att 25.795221 loss_ctc 29.217377 loss_rnnt 13.693701 lr 0.00086176 rank 1
2022-12-03 18:53:57,657 DEBUG TRAIN Batch 4/300 loss 30.531845 loss_att 37.142338 loss_ctc 46.275414 loss_rnnt 27.110603 lr 0.00086115 rank 2
2022-12-03 18:55:10,858 DEBUG TRAIN Batch 4/400 loss 18.951902 loss_att 21.407478 loss_ctc 27.128403 loss_rnnt 17.370586 lr 0.00086076 rank 6
2022-12-03 18:55:10,860 DEBUG TRAIN Batch 4/400 loss 31.137489 loss_att 36.663734 loss_ctc 52.145218 loss_rnnt 27.231213 lr 0.00086040 rank 0
2022-12-03 18:55:10,864 DEBUG TRAIN Batch 4/400 loss 22.442652 loss_att 28.171307 loss_ctc 37.026085 loss_rnnt 19.352463 lr 0.00086029 rank 3
2022-12-03 18:55:10,867 DEBUG TRAIN Batch 4/400 loss 24.579393 loss_att 31.412468 loss_ctc 41.301003 loss_rnnt 20.983231 lr 0.00086066 rank 5
2022-12-03 18:55:10,868 DEBUG TRAIN Batch 4/400 loss 20.182476 loss_att 31.345322 loss_ctc 35.811127 loss_rnnt 15.866087 lr 0.00086106 rank 4
2022-12-03 18:55:10,869 DEBUG TRAIN Batch 4/400 loss 23.793194 loss_att 29.337658 loss_ctc 38.704163 loss_rnnt 20.696171 lr 0.00086084 rank 7
2022-12-03 18:55:10,873 DEBUG TRAIN Batch 4/400 loss 35.415043 loss_att 40.184303 loss_ctc 58.581894 loss_rnnt 31.372280 lr 0.00085987 rank 2
2022-12-03 18:55:10,911 DEBUG TRAIN Batch 4/400 loss 16.317516 loss_att 23.271646 loss_ctc 29.793259 loss_rnnt 13.129925 lr 0.00086048 rank 1
2022-12-03 18:56:22,441 DEBUG TRAIN Batch 4/500 loss 19.445509 loss_att 22.134274 loss_ctc 29.219677 loss_rnnt 17.604534 lr 0.00085949 rank 6
2022-12-03 18:56:22,443 DEBUG TRAIN Batch 4/500 loss 22.824450 loss_att 26.891718 loss_ctc 31.466290 loss_rnnt 20.858749 lr 0.00085912 rank 0
2022-12-03 18:56:22,446 DEBUG TRAIN Batch 4/500 loss 38.393154 loss_att 45.477646 loss_ctc 60.966785 loss_rnnt 33.966438 lr 0.00085902 rank 3
2022-12-03 18:56:22,448 DEBUG TRAIN Batch 4/500 loss 21.919668 loss_att 26.011299 loss_ctc 37.031471 loss_rnnt 19.086433 lr 0.00085939 rank 5
2022-12-03 18:56:22,448 DEBUG TRAIN Batch 4/500 loss 21.360950 loss_att 27.053455 loss_ctc 35.245453 loss_rnnt 18.371181 lr 0.00085957 rank 7
2022-12-03 18:56:22,450 DEBUG TRAIN Batch 4/500 loss 31.659836 loss_att 32.101276 loss_ctc 53.752113 loss_rnnt 28.625910 lr 0.00085921 rank 1
2022-12-03 18:56:22,453 DEBUG TRAIN Batch 4/500 loss 26.316669 loss_att 29.469078 loss_ctc 40.021191 loss_rnnt 23.858917 lr 0.00085860 rank 2
2022-12-03 18:56:22,459 DEBUG TRAIN Batch 4/500 loss 26.739328 loss_att 30.535088 loss_ctc 39.630333 loss_rnnt 24.261375 lr 0.00085978 rank 4
2022-12-03 18:57:34,898 DEBUG TRAIN Batch 4/600 loss 20.714710 loss_att 22.470940 loss_ctc 29.792025 loss_rnnt 19.153154 lr 0.00085786 rank 0
2022-12-03 18:57:34,901 DEBUG TRAIN Batch 4/600 loss 23.556423 loss_att 26.355814 loss_ctc 38.099159 loss_rnnt 21.057512 lr 0.00085823 rank 6
2022-12-03 18:57:34,907 DEBUG TRAIN Batch 4/600 loss 12.397578 loss_att 14.896690 loss_ctc 20.182541 loss_rnnt 10.859760 lr 0.00085812 rank 5
2022-12-03 18:57:34,908 DEBUG TRAIN Batch 4/600 loss 13.995071 loss_att 18.315092 loss_ctc 21.716063 loss_rnnt 12.101602 lr 0.00085852 rank 4
2022-12-03 18:57:34,909 DEBUG TRAIN Batch 4/600 loss 30.420605 loss_att 32.019913 loss_ctc 46.411343 loss_rnnt 27.968643 lr 0.00085830 rank 7
2022-12-03 18:57:34,910 DEBUG TRAIN Batch 4/600 loss 12.890974 loss_att 14.632576 loss_ctc 19.715107 loss_rnnt 11.632769 lr 0.00085734 rank 2
2022-12-03 18:57:34,911 DEBUG TRAIN Batch 4/600 loss 14.473364 loss_att 16.846813 loss_ctc 22.069691 loss_rnnt 12.985830 lr 0.00085776 rank 3
2022-12-03 18:57:34,953 DEBUG TRAIN Batch 4/600 loss 17.463764 loss_att 24.224977 loss_ctc 29.009092 loss_rnnt 14.572144 lr 0.00085795 rank 1
2022-12-03 18:58:48,751 DEBUG TRAIN Batch 4/700 loss 35.221172 loss_att 47.836823 loss_ctc 53.448540 loss_rnnt 30.267727 lr 0.00085696 rank 6
2022-12-03 18:58:48,753 DEBUG TRAIN Batch 4/700 loss 24.577820 loss_att 33.061031 loss_ctc 38.616730 loss_rnnt 21.009323 lr 0.00085660 rank 0
2022-12-03 18:58:48,754 DEBUG TRAIN Batch 4/700 loss 33.983185 loss_att 44.467701 loss_ctc 45.382183 loss_rnnt 30.366413 lr 0.00085650 rank 3
2022-12-03 18:58:48,755 DEBUG TRAIN Batch 4/700 loss 30.276945 loss_att 40.242191 loss_ctc 52.818878 loss_rnnt 25.278303 lr 0.00085725 rank 4
2022-12-03 18:58:48,759 DEBUG TRAIN Batch 4/700 loss 15.761801 loss_att 22.559875 loss_ctc 26.490692 loss_rnnt 12.971667 lr 0.00085704 rank 7
2022-12-03 18:58:48,763 DEBUG TRAIN Batch 4/700 loss 26.412048 loss_att 36.821014 loss_ctc 40.497509 loss_rnnt 22.452194 lr 0.00085669 rank 1
2022-12-03 18:58:48,764 DEBUG TRAIN Batch 4/700 loss 24.777031 loss_att 30.181145 loss_ctc 41.951523 loss_rnnt 21.406277 lr 0.00085608 rank 2
2022-12-03 18:58:48,773 DEBUG TRAIN Batch 4/700 loss 34.233582 loss_att 52.564224 loss_ctc 61.379074 loss_rnnt 26.948051 lr 0.00085686 rank 5
2022-12-03 19:00:00,800 DEBUG TRAIN Batch 4/800 loss 26.540817 loss_att 32.138504 loss_ctc 48.956432 loss_rnnt 22.432531 lr 0.00085534 rank 0
2022-12-03 19:00:00,812 DEBUG TRAIN Batch 4/800 loss 25.381062 loss_att 28.531754 loss_ctc 38.028618 loss_rnnt 23.064581 lr 0.00085524 rank 3
2022-12-03 19:00:00,819 DEBUG TRAIN Batch 4/800 loss 31.292238 loss_att 38.209122 loss_ctc 61.151085 loss_rnnt 25.927681 lr 0.00085543 rank 1
2022-12-03 19:00:00,821 DEBUG TRAIN Batch 4/800 loss 26.642834 loss_att 30.724325 loss_ctc 37.468971 loss_rnnt 24.383053 lr 0.00085483 rank 2
2022-12-03 19:00:00,820 DEBUG TRAIN Batch 4/800 loss 22.342743 loss_att 30.466076 loss_ctc 40.939816 loss_rnnt 18.238464 lr 0.00085571 rank 6
2022-12-03 19:00:00,824 DEBUG TRAIN Batch 4/800 loss 27.578682 loss_att 35.381172 loss_ctc 48.004700 loss_rnnt 23.294714 lr 0.00085600 rank 4
2022-12-03 19:00:00,826 DEBUG TRAIN Batch 4/800 loss 19.417057 loss_att 26.730289 loss_ctc 39.162674 loss_rnnt 15.321661 lr 0.00085578 rank 7
2022-12-03 19:00:00,864 DEBUG TRAIN Batch 4/800 loss 29.828098 loss_att 39.464863 loss_ctc 40.226624 loss_rnnt 26.514275 lr 0.00085561 rank 5
2022-12-03 19:01:13,147 DEBUG TRAIN Batch 4/900 loss 23.494389 loss_att 28.679594 loss_ctc 44.941620 loss_rnnt 19.597717 lr 0.00085446 rank 6
2022-12-03 19:01:13,148 DEBUG TRAIN Batch 4/900 loss 17.223396 loss_att 22.758966 loss_ctc 28.159569 loss_rnnt 14.658127 lr 0.00085400 rank 3
2022-12-03 19:01:13,149 DEBUG TRAIN Batch 4/900 loss 23.078238 loss_att 27.190361 loss_ctc 34.334866 loss_rnnt 20.754929 lr 0.00085436 rank 5
2022-12-03 19:01:13,150 DEBUG TRAIN Batch 4/900 loss 13.321365 loss_att 22.737709 loss_ctc 24.740940 loss_rnnt 9.915485 lr 0.00085410 rank 0
2022-12-03 19:01:13,151 DEBUG TRAIN Batch 4/900 loss 31.942629 loss_att 35.673241 loss_ctc 42.598766 loss_rnnt 29.775688 lr 0.00085418 rank 1
2022-12-03 19:01:13,156 DEBUG TRAIN Batch 4/900 loss 24.549747 loss_att 31.720655 loss_ctc 37.242767 loss_rnnt 21.423161 lr 0.00085453 rank 7
2022-12-03 19:01:13,157 DEBUG TRAIN Batch 4/900 loss 19.466713 loss_att 23.417601 loss_ctc 30.280773 loss_rnnt 17.234661 lr 0.00085359 rank 2
2022-12-03 19:01:13,210 DEBUG TRAIN Batch 4/900 loss 27.136383 loss_att 36.224049 loss_ctc 47.828754 loss_rnnt 22.559868 lr 0.00085474 rank 4
2022-12-03 19:02:25,205 DEBUG TRAIN Batch 4/1000 loss 19.347902 loss_att 24.368391 loss_ctc 30.930389 loss_rnnt 16.799473 lr 0.00085321 rank 6
2022-12-03 19:02:25,207 DEBUG TRAIN Batch 4/1000 loss 17.951782 loss_att 24.494987 loss_ctc 31.343979 loss_rnnt 14.857516 lr 0.00085350 rank 4
2022-12-03 19:02:25,211 DEBUG TRAIN Batch 4/1000 loss 23.780399 loss_att 28.203579 loss_ctc 40.946114 loss_rnnt 20.607000 lr 0.00085329 rank 7
2022-12-03 19:02:25,211 DEBUG TRAIN Batch 4/1000 loss 41.726768 loss_att 41.089634 loss_ctc 54.720909 loss_rnnt 40.121643 lr 0.00085294 rank 1
2022-12-03 19:02:25,212 DEBUG TRAIN Batch 4/1000 loss 22.928570 loss_att 28.507114 loss_ctc 39.029984 loss_rnnt 19.666006 lr 0.00085285 rank 0
2022-12-03 19:02:25,212 DEBUG TRAIN Batch 4/1000 loss 31.863094 loss_att 40.832539 loss_ctc 56.029247 loss_rnnt 26.847050 lr 0.00085275 rank 3
2022-12-03 19:02:25,213 DEBUG TRAIN Batch 4/1000 loss 19.472099 loss_att 28.547508 loss_ctc 43.034008 loss_rnnt 14.515428 lr 0.00085234 rank 2
2022-12-03 19:02:25,214 DEBUG TRAIN Batch 4/1000 loss 31.069532 loss_att 43.464561 loss_ctc 53.246784 loss_rnnt 25.633560 lr 0.00085311 rank 5
2022-12-03 19:03:38,306 DEBUG TRAIN Batch 4/1100 loss 20.693838 loss_att 26.870955 loss_ctc 38.755882 loss_rnnt 17.050142 lr 0.00085152 rank 3
2022-12-03 19:03:38,307 DEBUG TRAIN Batch 4/1100 loss 20.235073 loss_att 25.652712 loss_ctc 35.228889 loss_rnnt 17.152370 lr 0.00085170 rank 1
2022-12-03 19:03:38,309 DEBUG TRAIN Batch 4/1100 loss 33.023548 loss_att 34.098553 loss_ctc 40.990845 loss_rnnt 31.746239 lr 0.00085197 rank 6
2022-12-03 19:03:38,312 DEBUG TRAIN Batch 4/1100 loss 41.584824 loss_att 43.597507 loss_ctc 50.953178 loss_rnnt 39.933174 lr 0.00085161 rank 0
2022-12-03 19:03:38,313 DEBUG TRAIN Batch 4/1100 loss 19.677656 loss_att 26.109987 loss_ctc 33.258961 loss_rnnt 16.580349 lr 0.00085187 rank 5
2022-12-03 19:03:38,318 DEBUG TRAIN Batch 4/1100 loss 12.575119 loss_att 22.281700 loss_ctc 26.231239 loss_rnnt 8.812986 lr 0.00085205 rank 7
2022-12-03 19:03:38,346 DEBUG TRAIN Batch 4/1100 loss 27.597218 loss_att 34.478867 loss_ctc 36.517056 loss_rnnt 25.031576 lr 0.00085111 rank 2
2022-12-03 19:03:38,358 DEBUG TRAIN Batch 4/1100 loss 25.614422 loss_att 34.731274 loss_ctc 47.083755 loss_rnnt 20.928474 lr 0.00085226 rank 4
2022-12-03 19:04:49,302 DEBUG TRAIN Batch 4/1200 loss 23.823359 loss_att 26.525246 loss_ctc 37.814869 loss_rnnt 21.417448 lr 0.00085028 rank 3
2022-12-03 19:04:49,318 DEBUG TRAIN Batch 4/1200 loss 30.307096 loss_att 32.315910 loss_ctc 43.733761 loss_rnnt 28.115110 lr 0.00085047 rank 1
2022-12-03 19:04:49,322 DEBUG TRAIN Batch 4/1200 loss 36.039513 loss_att 41.157314 loss_ctc 56.082020 loss_rnnt 32.343616 lr 0.00085038 rank 0
2022-12-03 19:04:49,326 DEBUG TRAIN Batch 4/1200 loss 19.625875 loss_att 23.887560 loss_ctc 31.228338 loss_rnnt 17.226545 lr 0.00085074 rank 6
2022-12-03 19:04:49,327 DEBUG TRAIN Batch 4/1200 loss 23.367123 loss_att 27.322557 loss_ctc 37.043468 loss_rnnt 20.752522 lr 0.00084988 rank 2
2022-12-03 19:04:49,327 DEBUG TRAIN Batch 4/1200 loss 23.647190 loss_att 27.917782 loss_ctc 34.833092 loss_rnnt 21.301617 lr 0.00085064 rank 5
2022-12-03 19:04:49,327 DEBUG TRAIN Batch 4/1200 loss 23.069290 loss_att 27.951601 loss_ctc 35.509979 loss_rnnt 20.434071 lr 0.00085081 rank 7
2022-12-03 19:04:49,327 DEBUG TRAIN Batch 4/1200 loss 21.678949 loss_att 26.534336 loss_ctc 33.964455 loss_rnnt 19.069803 lr 0.00085102 rank 4
2022-12-03 19:06:01,530 DEBUG TRAIN Batch 4/1300 loss 14.213963 loss_att 13.032719 loss_ctc 19.172535 loss_rnnt 13.789069 lr 0.00084951 rank 6
2022-12-03 19:06:01,536 DEBUG TRAIN Batch 4/1300 loss 26.454838 loss_att 36.867973 loss_ctc 40.520851 loss_rnnt 22.496740 lr 0.00084915 rank 0
2022-12-03 19:06:01,537 DEBUG TRAIN Batch 4/1300 loss 20.934151 loss_att 28.060833 loss_ctc 31.859116 loss_rnnt 18.052151 lr 0.00084941 rank 5
2022-12-03 19:06:01,539 DEBUG TRAIN Batch 4/1300 loss 30.986967 loss_att 41.628529 loss_ctc 46.119980 loss_rnnt 26.840919 lr 0.00084906 rank 3
2022-12-03 19:06:01,541 DEBUG TRAIN Batch 4/1300 loss 27.351002 loss_att 33.284561 loss_ctc 40.096798 loss_rnnt 24.464851 lr 0.00084924 rank 1
2022-12-03 19:06:01,541 DEBUG TRAIN Batch 4/1300 loss 22.595772 loss_att 27.850761 loss_ctc 34.387020 loss_rnnt 19.972609 lr 0.00084979 rank 4
2022-12-03 19:06:01,541 DEBUG TRAIN Batch 4/1300 loss 9.171781 loss_att 9.463085 loss_ctc 12.169245 loss_rnnt 8.713858 lr 0.00084865 rank 2
2022-12-03 19:06:01,586 DEBUG TRAIN Batch 4/1300 loss 15.079559 loss_att 16.719255 loss_ctc 20.772766 loss_rnnt 13.992525 lr 0.00084958 rank 7
2022-12-03 19:07:14,974 DEBUG TRAIN Batch 4/1400 loss 20.444706 loss_att 29.594578 loss_ctc 29.746395 loss_rnnt 17.374506 lr 0.00084784 rank 3
2022-12-03 19:07:14,979 DEBUG TRAIN Batch 4/1400 loss 30.474756 loss_att 36.423683 loss_ctc 42.870068 loss_rnnt 27.632263 lr 0.00084819 rank 5
2022-12-03 19:07:14,979 DEBUG TRAIN Batch 4/1400 loss 14.314593 loss_att 20.907173 loss_ctc 25.824024 loss_rnnt 11.461487 lr 0.00084793 rank 0
2022-12-03 19:07:14,980 DEBUG TRAIN Batch 4/1400 loss 27.405787 loss_att 37.109360 loss_ctc 45.552559 loss_rnnt 23.045502 lr 0.00084829 rank 6
2022-12-03 19:07:14,986 DEBUG TRAIN Batch 4/1400 loss 45.494038 loss_att 52.023502 loss_ctc 66.252365 loss_rnnt 41.420372 lr 0.00084857 rank 4
2022-12-03 19:07:15,001 DEBUG TRAIN Batch 4/1400 loss 14.744375 loss_att 22.088900 loss_ctc 25.000389 loss_rnnt 11.908001 lr 0.00084802 rank 1
2022-12-03 19:07:15,016 DEBUG TRAIN Batch 4/1400 loss 25.256514 loss_att 29.488382 loss_ctc 37.195686 loss_rnnt 22.818251 lr 0.00084836 rank 7
2022-12-03 19:07:15,017 DEBUG TRAIN Batch 4/1400 loss 23.541615 loss_att 31.437395 loss_ctc 37.583328 loss_rnnt 20.090231 lr 0.00084743 rank 2
2022-12-03 19:08:27,722 DEBUG TRAIN Batch 4/1500 loss 18.404282 loss_att 23.212337 loss_ctc 33.799187 loss_rnnt 15.390015 lr 0.00084672 rank 0
2022-12-03 19:08:27,724 DEBUG TRAIN Batch 4/1500 loss 23.284451 loss_att 33.457214 loss_ctc 48.850380 loss_rnnt 17.841106 lr 0.00084707 rank 6
2022-12-03 19:08:27,724 DEBUG TRAIN Batch 4/1500 loss 40.143951 loss_att 46.480495 loss_ctc 61.999313 loss_rnnt 35.962589 lr 0.00084680 rank 1
2022-12-03 19:08:27,725 DEBUG TRAIN Batch 4/1500 loss 28.257978 loss_att 35.561882 loss_ctc 42.415783 loss_rnnt 24.909489 lr 0.00084697 rank 5
2022-12-03 19:08:27,728 DEBUG TRAIN Batch 4/1500 loss 25.710945 loss_att 32.574417 loss_ctc 45.316437 loss_rnnt 21.724186 lr 0.00084714 rank 7
2022-12-03 19:08:27,728 DEBUG TRAIN Batch 4/1500 loss 32.845833 loss_att 31.296852 loss_ctc 53.305321 loss_rnnt 30.427700 lr 0.00084622 rank 2
2022-12-03 19:08:27,735 DEBUG TRAIN Batch 4/1500 loss 47.490166 loss_att 52.525471 loss_ctc 69.697098 loss_rnnt 43.522179 lr 0.00084662 rank 3
2022-12-03 19:08:27,781 DEBUG TRAIN Batch 4/1500 loss 32.014011 loss_att 37.059372 loss_ctc 47.610855 loss_rnnt 28.925360 lr 0.00084735 rank 4
2022-12-03 19:09:39,077 DEBUG TRAIN Batch 4/1600 loss 28.154419 loss_att 36.122887 loss_ctc 46.960690 loss_rnnt 24.053223 lr 0.00084541 rank 3
2022-12-03 19:09:39,080 DEBUG TRAIN Batch 4/1600 loss 20.935287 loss_att 28.254002 loss_ctc 34.066223 loss_rnnt 17.720753 lr 0.00084501 rank 2
2022-12-03 19:09:39,080 DEBUG TRAIN Batch 4/1600 loss 30.746078 loss_att 37.140076 loss_ctc 52.010410 loss_rnnt 26.632034 lr 0.00084586 rank 6
2022-12-03 19:09:39,084 DEBUG TRAIN Batch 4/1600 loss 29.022675 loss_att 37.102512 loss_ctc 52.900009 loss_rnnt 24.223061 lr 0.00084576 rank 5
2022-12-03 19:09:39,082 DEBUG TRAIN Batch 4/1600 loss 31.091644 loss_att 33.411850 loss_ctc 46.461983 loss_rnnt 28.578224 lr 0.00084559 rank 1
2022-12-03 19:09:39,083 DEBUG TRAIN Batch 4/1600 loss 30.965824 loss_att 34.318115 loss_ctc 44.564480 loss_rnnt 28.482212 lr 0.00084550 rank 0
2022-12-03 19:09:39,084 DEBUG TRAIN Batch 4/1600 loss 21.906851 loss_att 31.967356 loss_ctc 29.970457 loss_rnnt 18.819603 lr 0.00084593 rank 7
2022-12-03 19:09:39,088 DEBUG TRAIN Batch 4/1600 loss 34.141476 loss_att 39.796947 loss_ctc 47.066418 loss_rnnt 31.287052 lr 0.00084613 rank 4
2022-12-03 19:10:51,391 DEBUG TRAIN Batch 4/1700 loss 16.200449 loss_att 21.222347 loss_ctc 25.052145 loss_rnnt 14.015842 lr 0.00084430 rank 0
2022-12-03 19:10:51,402 DEBUG TRAIN Batch 4/1700 loss 41.647919 loss_att 45.055840 loss_ctc 57.772652 loss_rnnt 38.816368 lr 0.00084420 rank 3
2022-12-03 19:10:51,402 DEBUG TRAIN Batch 4/1700 loss 29.550966 loss_att 40.105221 loss_ctc 47.501595 loss_rnnt 25.046696 lr 0.00084465 rank 6
2022-12-03 19:10:51,408 DEBUG TRAIN Batch 4/1700 loss 32.808163 loss_att 44.212635 loss_ctc 52.529877 loss_rnnt 27.897705 lr 0.00084455 rank 5
2022-12-03 19:10:51,411 DEBUG TRAIN Batch 4/1700 loss 20.526087 loss_att 24.882931 loss_ctc 33.180206 loss_rnnt 17.967505 lr 0.00084492 rank 4
2022-12-03 19:10:51,429 DEBUG TRAIN Batch 4/1700 loss 30.606361 loss_att 37.463497 loss_ctc 45.942760 loss_rnnt 27.190079 lr 0.00084472 rank 7
2022-12-03 19:10:51,439 DEBUG TRAIN Batch 4/1700 loss 25.832729 loss_att 30.247322 loss_ctc 36.917614 loss_rnnt 23.471828 lr 0.00084381 rank 2
2022-12-03 19:10:51,451 DEBUG TRAIN Batch 4/1700 loss 31.103085 loss_att 32.318752 loss_ctc 57.462605 loss_rnnt 27.345350 lr 0.00084438 rank 1
2022-12-03 19:12:05,516 DEBUG TRAIN Batch 4/1800 loss 19.279217 loss_att 24.207350 loss_ctc 36.186234 loss_rnnt 16.039322 lr 0.00084335 rank 5
2022-12-03 19:12:05,517 DEBUG TRAIN Batch 4/1800 loss 36.053696 loss_att 40.270893 loss_ctc 71.074425 loss_rnnt 30.540821 lr 0.00084344 rank 6
2022-12-03 19:12:05,520 DEBUG TRAIN Batch 4/1800 loss 22.454021 loss_att 22.880726 loss_ctc 33.564381 loss_rnnt 20.887299 lr 0.00084310 rank 0
2022-12-03 19:12:05,521 DEBUG TRAIN Batch 4/1800 loss 13.761302 loss_att 16.793255 loss_ctc 21.418930 loss_rnnt 12.133894 lr 0.00084300 rank 3
2022-12-03 19:12:05,522 DEBUG TRAIN Batch 4/1800 loss 23.132256 loss_att 31.242212 loss_ctc 38.269421 loss_rnnt 19.491974 lr 0.00084318 rank 1
2022-12-03 19:12:05,526 DEBUG TRAIN Batch 4/1800 loss 32.400829 loss_att 36.715477 loss_ctc 44.450562 loss_rnnt 29.931269 lr 0.00084261 rank 2
2022-12-03 19:12:05,526 DEBUG TRAIN Batch 4/1800 loss 20.553877 loss_att 30.267876 loss_ctc 36.420387 loss_rnnt 16.495543 lr 0.00084352 rank 7
2022-12-03 19:12:05,527 DEBUG TRAIN Batch 4/1800 loss 17.014299 loss_att 20.745195 loss_ctc 27.990650 loss_rnnt 14.804606 lr 0.00084372 rank 4
2022-12-03 19:13:17,423 DEBUG TRAIN Batch 4/1900 loss 11.288670 loss_att 14.105543 loss_ctc 18.057053 loss_rnnt 9.822844 lr 0.00084198 rank 1
2022-12-03 19:13:17,424 DEBUG TRAIN Batch 4/1900 loss 23.696877 loss_att 27.032219 loss_ctc 32.098583 loss_rnnt 21.909580 lr 0.00084225 rank 6
2022-12-03 19:13:17,425 DEBUG TRAIN Batch 4/1900 loss 24.491133 loss_att 26.123236 loss_ctc 34.710926 loss_rnnt 22.802073 lr 0.00084190 rank 0
2022-12-03 19:13:17,426 DEBUG TRAIN Batch 4/1900 loss 20.750139 loss_att 23.813404 loss_ctc 29.228308 loss_rnnt 19.007065 lr 0.00084141 rank 2
2022-12-03 19:13:17,427 DEBUG TRAIN Batch 4/1900 loss 26.486298 loss_att 34.079254 loss_ctc 40.812454 loss_rnnt 23.057552 lr 0.00084181 rank 3
2022-12-03 19:13:17,427 DEBUG TRAIN Batch 4/1900 loss 29.278763 loss_att 32.088806 loss_ctc 49.954132 loss_rnnt 25.960037 lr 0.00084232 rank 7
2022-12-03 19:13:17,433 DEBUG TRAIN Batch 4/1900 loss 31.530422 loss_att 35.728043 loss_ctc 47.432507 loss_rnnt 28.570618 lr 0.00084252 rank 4
2022-12-03 19:13:17,466 DEBUG TRAIN Batch 4/1900 loss 21.133175 loss_att 28.143820 loss_ctc 35.122681 loss_rnnt 17.865780 lr 0.00084215 rank 5
2022-12-03 19:14:29,426 DEBUG TRAIN Batch 4/2000 loss 20.805851 loss_att 28.704073 loss_ctc 36.993034 loss_rnnt 17.067917 lr 0.00084096 rank 5
2022-12-03 19:14:29,440 DEBUG TRAIN Batch 4/2000 loss 7.616573 loss_att 14.992310 loss_ctc 16.202457 loss_rnnt 4.996641 lr 0.00084079 rank 1
2022-12-03 19:14:29,442 DEBUG TRAIN Batch 4/2000 loss 31.997829 loss_att 41.434891 loss_ctc 56.609802 loss_rnnt 26.828823 lr 0.00084071 rank 0
2022-12-03 19:14:29,443 DEBUG TRAIN Batch 4/2000 loss 18.724062 loss_att 27.061590 loss_ctc 27.490738 loss_rnnt 15.887665 lr 0.00084106 rank 6
2022-12-03 19:14:29,444 DEBUG TRAIN Batch 4/2000 loss 27.771385 loss_att 31.822247 loss_ctc 49.379555 loss_rnnt 24.080122 lr 0.00084113 rank 7
2022-12-03 19:14:29,445 DEBUG TRAIN Batch 4/2000 loss 19.273285 loss_att 27.195347 loss_ctc 29.545746 loss_rnnt 16.319210 lr 0.00084062 rank 3
2022-12-03 19:14:29,448 DEBUG TRAIN Batch 4/2000 loss 29.581476 loss_att 44.936275 loss_ctc 41.463741 loss_rnnt 24.926212 lr 0.00084133 rank 4
2022-12-03 19:14:29,449 DEBUG TRAIN Batch 4/2000 loss 30.448151 loss_att 38.999912 loss_ctc 54.277115 loss_rnnt 25.560604 lr 0.00084022 rank 2
2022-12-03 19:15:42,873 DEBUG TRAIN Batch 4/2100 loss 37.143013 loss_att 41.085785 loss_ctc 58.031792 loss_rnnt 33.569290 lr 0.00083943 rank 3
2022-12-03 19:15:42,883 DEBUG TRAIN Batch 4/2100 loss 38.668140 loss_att 45.025997 loss_ctc 54.773811 loss_rnnt 35.249146 lr 0.00083977 rank 5
2022-12-03 19:15:42,887 DEBUG TRAIN Batch 4/2100 loss 35.549381 loss_att 41.532841 loss_ctc 56.302429 loss_rnnt 31.585615 lr 0.00083952 rank 0
2022-12-03 19:15:42,889 DEBUG TRAIN Batch 4/2100 loss 32.614410 loss_att 42.867432 loss_ctc 49.953194 loss_rnnt 28.251968 lr 0.00083987 rank 6
2022-12-03 19:15:42,890 DEBUG TRAIN Batch 4/2100 loss 16.557779 loss_att 24.692314 loss_ctc 28.121639 loss_rnnt 13.389023 lr 0.00083994 rank 7
2022-12-03 19:15:42,892 DEBUG TRAIN Batch 4/2100 loss 23.482424 loss_att 28.633234 loss_ctc 37.212326 loss_rnnt 20.621609 lr 0.00083961 rank 1
2022-12-03 19:15:42,896 DEBUG TRAIN Batch 4/2100 loss 43.305740 loss_att 45.393684 loss_ctc 59.582481 loss_rnnt 40.717922 lr 0.00083904 rank 2
2022-12-03 19:15:42,918 DEBUG TRAIN Batch 4/2100 loss 25.109436 loss_att 30.376354 loss_ctc 39.933517 loss_rnnt 22.079510 lr 0.00084014 rank 4
2022-12-03 19:16:55,662 DEBUG TRAIN Batch 4/2200 loss 16.081949 loss_att 23.235031 loss_ctc 34.552414 loss_rnnt 12.188605 lr 0.00083859 rank 5
2022-12-03 19:16:55,672 DEBUG TRAIN Batch 4/2200 loss 30.747608 loss_att 36.626648 loss_ctc 48.906883 loss_rnnt 27.150562 lr 0.00083843 rank 1
2022-12-03 19:16:55,673 DEBUG TRAIN Batch 4/2200 loss 28.493507 loss_att 34.092232 loss_ctc 40.872849 loss_rnnt 25.723186 lr 0.00083834 rank 0
2022-12-03 19:16:55,676 DEBUG TRAIN Batch 4/2200 loss 22.413435 loss_att 27.325117 loss_ctc 37.371277 loss_rnnt 19.436718 lr 0.00083869 rank 6
2022-12-03 19:16:55,677 DEBUG TRAIN Batch 4/2200 loss 27.768253 loss_att 38.108768 loss_ctc 44.189053 loss_rnnt 23.510712 lr 0.00083786 rank 2
2022-12-03 19:16:55,680 DEBUG TRAIN Batch 4/2200 loss 16.807686 loss_att 25.018188 loss_ctc 30.754883 loss_rnnt 13.305958 lr 0.00083876 rank 7
2022-12-03 19:16:55,681 DEBUG TRAIN Batch 4/2200 loss 14.748093 loss_att 20.958061 loss_ctc 26.976376 loss_rnnt 11.875662 lr 0.00083825 rank 3
2022-12-03 19:16:55,683 DEBUG TRAIN Batch 4/2200 loss 14.281488 loss_att 20.638523 loss_ctc 25.671625 loss_rnnt 11.491396 lr 0.00083896 rank 4
2022-12-03 19:18:06,603 DEBUG TRAIN Batch 4/2300 loss 20.937712 loss_att 23.267567 loss_ctc 36.810493 loss_rnnt 18.355370 lr 0.00083717 rank 0
2022-12-03 19:18:06,604 DEBUG TRAIN Batch 4/2300 loss 17.773865 loss_att 19.002903 loss_ctc 27.045572 loss_rnnt 16.291828 lr 0.00083751 rank 6
2022-12-03 19:18:06,605 DEBUG TRAIN Batch 4/2300 loss 21.861217 loss_att 26.982231 loss_ctc 34.768764 loss_rnnt 19.116009 lr 0.00083707 rank 3
2022-12-03 19:18:06,608 DEBUG TRAIN Batch 4/2300 loss 20.026146 loss_att 26.955673 loss_ctc 39.453697 loss_rnnt 16.049900 lr 0.00083778 rank 4
2022-12-03 19:18:06,608 DEBUG TRAIN Batch 4/2300 loss 29.030342 loss_att 33.851135 loss_ctc 43.290119 loss_rnnt 26.164879 lr 0.00083725 rank 1
2022-12-03 19:18:06,609 DEBUG TRAIN Batch 4/2300 loss 31.688080 loss_att 39.750423 loss_ctc 50.634033 loss_rnnt 27.549484 lr 0.00083741 rank 5
2022-12-03 19:18:06,609 DEBUG TRAIN Batch 4/2300 loss 36.555305 loss_att 43.785152 loss_ctc 53.058723 loss_rnnt 32.908882 lr 0.00083758 rank 7
2022-12-03 19:18:06,614 DEBUG TRAIN Batch 4/2300 loss 40.420601 loss_att 42.779984 loss_ctc 58.382195 loss_rnnt 37.553848 lr 0.00083669 rank 2
2022-12-03 19:19:19,289 DEBUG TRAIN Batch 4/2400 loss 13.791243 loss_att 19.698683 loss_ctc 23.283337 loss_rnnt 11.344141 lr 0.00083552 rank 2
2022-12-03 19:19:19,293 DEBUG TRAIN Batch 4/2400 loss 41.469933 loss_att 44.921116 loss_ctc 64.283905 loss_rnnt 37.737831 lr 0.00083634 rank 6
2022-12-03 19:19:19,294 DEBUG TRAIN Batch 4/2400 loss 29.429396 loss_att 36.930130 loss_ctc 48.385788 loss_rnnt 25.401728 lr 0.00083600 rank 0
2022-12-03 19:19:19,299 DEBUG TRAIN Batch 4/2400 loss 24.279881 loss_att 31.263161 loss_ctc 44.256119 loss_rnnt 20.219727 lr 0.00083641 rank 7
2022-12-03 19:19:19,301 DEBUG TRAIN Batch 4/2400 loss 22.477352 loss_att 27.451420 loss_ctc 32.011086 loss_rnnt 20.211374 lr 0.00083608 rank 1
2022-12-03 19:19:19,302 DEBUG TRAIN Batch 4/2400 loss 17.875124 loss_att 24.617195 loss_ctc 32.837574 loss_rnnt 14.531715 lr 0.00083624 rank 5
2022-12-03 19:19:19,301 DEBUG TRAIN Batch 4/2400 loss 21.084469 loss_att 24.618252 loss_ctc 30.844799 loss_rnnt 19.076334 lr 0.00083660 rank 4
2022-12-03 19:19:19,302 DEBUG TRAIN Batch 4/2400 loss 24.879654 loss_att 28.871210 loss_ctc 38.448238 loss_rnnt 22.272196 lr 0.00083590 rank 3
2022-12-03 19:20:34,477 DEBUG TRAIN Batch 4/2500 loss 20.548410 loss_att 24.544510 loss_ctc 27.966536 loss_rnnt 18.760107 lr 0.00083483 rank 0
2022-12-03 19:20:34,483 DEBUG TRAIN Batch 4/2500 loss 12.539810 loss_att 16.910967 loss_ctc 24.649969 loss_rnnt 10.050891 lr 0.00083474 rank 3
2022-12-03 19:20:34,484 DEBUG TRAIN Batch 4/2500 loss 19.456795 loss_att 24.731976 loss_ctc 35.055347 loss_rnnt 16.321951 lr 0.00083507 rank 5
2022-12-03 19:20:34,484 DEBUG TRAIN Batch 4/2500 loss 17.562799 loss_att 19.866568 loss_ctc 25.875090 loss_rnnt 15.993740 lr 0.00083544 rank 4
2022-12-03 19:20:34,484 DEBUG TRAIN Batch 4/2500 loss 13.612680 loss_att 14.813962 loss_ctc 21.643780 loss_rnnt 12.301611 lr 0.00083517 rank 6
2022-12-03 19:20:34,485 DEBUG TRAIN Batch 4/2500 loss 16.863853 loss_att 19.822239 loss_ctc 32.159782 loss_rnnt 14.232719 lr 0.00083524 rank 7
2022-12-03 19:20:34,488 DEBUG TRAIN Batch 4/2500 loss 25.896708 loss_att 30.698410 loss_ctc 41.196255 loss_rnnt 22.896429 lr 0.00083491 rank 1
2022-12-03 19:20:34,489 DEBUG TRAIN Batch 4/2500 loss 20.760693 loss_att 22.617191 loss_ctc 32.891785 loss_rnnt 18.771915 lr 0.00083435 rank 2
2022-12-03 19:21:46,024 DEBUG TRAIN Batch 4/2600 loss 20.554523 loss_att 26.464581 loss_ctc 32.279411 loss_rnnt 17.809195 lr 0.00083401 rank 6
2022-12-03 19:21:46,029 DEBUG TRAIN Batch 4/2600 loss 33.531822 loss_att 40.560452 loss_ctc 44.785961 loss_rnnt 30.625546 lr 0.00083367 rank 0
2022-12-03 19:21:46,031 DEBUG TRAIN Batch 4/2600 loss 16.475409 loss_att 19.246729 loss_ctc 22.495167 loss_rnnt 15.118509 lr 0.00083408 rank 7
2022-12-03 19:21:46,034 DEBUG TRAIN Batch 4/2600 loss 29.628689 loss_att 34.513252 loss_ctc 46.069012 loss_rnnt 26.459732 lr 0.00083319 rank 2
2022-12-03 19:21:46,034 DEBUG TRAIN Batch 4/2600 loss 32.823654 loss_att 47.285713 loss_ctc 52.525276 loss_rnnt 27.304359 lr 0.00083391 rank 5
2022-12-03 19:21:46,035 DEBUG TRAIN Batch 4/2600 loss 21.571800 loss_att 30.173191 loss_ctc 37.656143 loss_rnnt 17.706945 lr 0.00083358 rank 3
2022-12-03 19:21:46,035 DEBUG TRAIN Batch 4/2600 loss 39.560764 loss_att 42.038193 loss_ctc 49.148678 loss_rnnt 37.786892 lr 0.00083375 rank 1
2022-12-03 19:21:46,045 DEBUG TRAIN Batch 4/2600 loss 10.351438 loss_att 19.193314 loss_ctc 20.373907 loss_rnnt 7.246733 lr 0.00083427 rank 4
2022-12-03 19:22:57,871 DEBUG TRAIN Batch 4/2700 loss 47.780949 loss_att 58.624058 loss_ctc 76.210602 loss_rnnt 41.821705 lr 0.00083204 rank 2
2022-12-03 19:22:57,872 DEBUG TRAIN Batch 4/2700 loss 22.202721 loss_att 30.106297 loss_ctc 35.919250 loss_rnnt 18.793135 lr 0.00083242 rank 3
2022-12-03 19:22:57,875 DEBUG TRAIN Batch 4/2700 loss 30.484840 loss_att 35.892300 loss_ctc 53.632000 loss_rnnt 26.317060 lr 0.00083285 rank 6
2022-12-03 19:22:57,876 DEBUG TRAIN Batch 4/2700 loss 34.169228 loss_att 45.958111 loss_ctc 58.695724 loss_rnnt 28.541252 lr 0.00083259 rank 1
2022-12-03 19:22:57,876 DEBUG TRAIN Batch 4/2700 loss 24.550785 loss_att 32.269657 loss_ctc 38.960094 loss_rnnt 21.085770 lr 0.00083276 rank 5
2022-12-03 19:22:57,879 DEBUG TRAIN Batch 4/2700 loss 22.341751 loss_att 28.424204 loss_ctc 34.660679 loss_rnnt 19.482735 lr 0.00083311 rank 4
2022-12-03 19:22:57,879 DEBUG TRAIN Batch 4/2700 loss 31.657459 loss_att 35.600845 loss_ctc 47.743553 loss_rnnt 28.723969 lr 0.00083292 rank 7
2022-12-03 19:22:57,881 DEBUG TRAIN Batch 4/2700 loss 37.708244 loss_att 45.278992 loss_ctc 56.642487 loss_rnnt 33.669525 lr 0.00083251 rank 0
2022-12-03 19:24:11,242 DEBUG TRAIN Batch 4/2800 loss 17.372860 loss_att 24.030430 loss_ctc 27.751415 loss_rnnt 14.657539 lr 0.00083144 rank 1
2022-12-03 19:24:11,248 DEBUG TRAIN Batch 4/2800 loss 18.682598 loss_att 21.606495 loss_ctc 25.745296 loss_rnnt 17.156124 lr 0.00083176 rank 7
2022-12-03 19:24:11,255 DEBUG TRAIN Batch 4/2800 loss 17.394888 loss_att 24.699751 loss_ctc 26.680296 loss_rnnt 14.695861 lr 0.00083136 rank 0
2022-12-03 19:24:11,255 DEBUG TRAIN Batch 4/2800 loss 48.429752 loss_att 57.329891 loss_ctc 74.186218 loss_rnnt 43.215530 lr 0.00083169 rank 6
2022-12-03 19:24:11,257 DEBUG TRAIN Batch 4/2800 loss 31.834980 loss_att 37.405647 loss_ctc 51.766777 loss_rnnt 28.063274 lr 0.00083089 rank 2
2022-12-03 19:24:11,260 DEBUG TRAIN Batch 4/2800 loss 35.538074 loss_att 38.774433 loss_ctc 55.101845 loss_rnnt 32.282299 lr 0.00083160 rank 5
2022-12-03 19:24:11,284 DEBUG TRAIN Batch 4/2800 loss 64.485855 loss_att 72.463608 loss_ctc 103.933739 loss_rnnt 57.630585 lr 0.00083127 rank 3
2022-12-03 19:24:11,288 DEBUG TRAIN Batch 4/2800 loss 20.701336 loss_att 25.575464 loss_ctc 31.775927 loss_rnnt 18.249899 lr 0.00083196 rank 4
2022-12-03 19:25:24,046 DEBUG TRAIN Batch 4/2900 loss 26.289753 loss_att 31.175451 loss_ctc 39.489555 loss_rnnt 23.552641 lr 0.00083081 rank 4
2022-12-03 19:25:24,066 DEBUG TRAIN Batch 4/2900 loss 21.820093 loss_att 27.835886 loss_ctc 33.167931 loss_rnnt 19.103889 lr 0.00083045 rank 5
2022-12-03 19:25:24,066 DEBUG TRAIN Batch 4/2900 loss 29.636351 loss_att 33.319790 loss_ctc 45.430084 loss_rnnt 26.793831 lr 0.00082975 rank 2
2022-12-03 19:25:24,067 DEBUG TRAIN Batch 4/2900 loss 31.972084 loss_att 33.438961 loss_ctc 38.747356 loss_rnnt 30.775339 lr 0.00083029 rank 1
2022-12-03 19:25:24,067 DEBUG TRAIN Batch 4/2900 loss 23.431780 loss_att 26.005669 loss_ctc 40.103653 loss_rnnt 20.694086 lr 0.00083021 rank 0
2022-12-03 19:25:24,073 DEBUG TRAIN Batch 4/2900 loss 11.623195 loss_att 15.832263 loss_ctc 17.134850 loss_rnnt 10.046494 lr 0.00083062 rank 7
2022-12-03 19:25:24,074 DEBUG TRAIN Batch 4/2900 loss 21.790825 loss_att 24.283304 loss_ctc 37.878571 loss_rnnt 19.147295 lr 0.00083055 rank 6
2022-12-03 19:25:24,455 DEBUG TRAIN Batch 4/2900 loss 27.573618 loss_att 32.869835 loss_ctc 43.627655 loss_rnnt 24.373837 lr 0.00083012 rank 3
2022-12-03 19:26:36,621 DEBUG TRAIN Batch 4/3000 loss 30.472630 loss_att 34.560654 loss_ctc 40.555542 loss_rnnt 28.310638 lr 0.00082907 rank 0
2022-12-03 19:26:36,623 DEBUG TRAIN Batch 4/3000 loss 17.134314 loss_att 21.889452 loss_ctc 30.220486 loss_rnnt 14.438461 lr 0.00082861 rank 2
2022-12-03 19:26:36,624 DEBUG TRAIN Batch 4/3000 loss 20.107754 loss_att 26.771217 loss_ctc 33.151405 loss_rnnt 17.035908 lr 0.00082940 rank 6
2022-12-03 19:26:36,631 DEBUG TRAIN Batch 4/3000 loss 11.884333 loss_att 16.130116 loss_ctc 14.905623 loss_rnnt 10.632337 lr 0.00082931 rank 5
2022-12-03 19:26:36,631 DEBUG TRAIN Batch 4/3000 loss 25.429029 loss_att 26.033810 loss_ctc 39.080948 loss_rnnt 23.487820 lr 0.00082967 rank 4
2022-12-03 19:26:36,631 DEBUG TRAIN Batch 4/3000 loss 17.415407 loss_att 23.053978 loss_ctc 33.432137 loss_rnnt 14.152128 lr 0.00082898 rank 3
2022-12-03 19:26:36,631 DEBUG TRAIN Batch 4/3000 loss 25.341284 loss_att 29.906706 loss_ctc 39.717445 loss_rnnt 22.511377 lr 0.00082915 rank 1
2022-12-03 19:26:36,633 DEBUG TRAIN Batch 4/3000 loss 21.920170 loss_att 28.255434 loss_ctc 40.764172 loss_rnnt 18.140583 lr 0.00082947 rank 7
2022-12-03 19:27:49,025 DEBUG TRAIN Batch 4/3100 loss 24.425821 loss_att 26.031261 loss_ctc 39.273438 loss_rnnt 22.125051 lr 0.00082747 rank 2
2022-12-03 19:27:49,027 DEBUG TRAIN Batch 4/3100 loss 20.413149 loss_att 25.803471 loss_ctc 32.691631 loss_rnnt 17.697952 lr 0.00082793 rank 0
2022-12-03 19:27:49,027 DEBUG TRAIN Batch 4/3100 loss 18.282846 loss_att 22.122101 loss_ctc 32.387142 loss_rnnt 15.634422 lr 0.00082801 rank 1
2022-12-03 19:27:49,027 DEBUG TRAIN Batch 4/3100 loss 18.002192 loss_att 22.234638 loss_ctc 29.486115 loss_rnnt 15.624512 lr 0.00082826 rank 6
2022-12-03 19:27:49,027 DEBUG TRAIN Batch 4/3100 loss 10.256104 loss_att 14.976793 loss_ctc 20.183508 loss_rnnt 7.988313 lr 0.00082817 rank 5
2022-12-03 19:27:49,028 DEBUG TRAIN Batch 4/3100 loss 15.236510 loss_att 18.407524 loss_ctc 26.625874 loss_rnnt 13.083726 lr 0.00082784 rank 3
2022-12-03 19:27:49,030 DEBUG TRAIN Batch 4/3100 loss 19.226439 loss_att 27.434181 loss_ctc 26.848557 loss_rnnt 16.568607 lr 0.00082833 rank 7
2022-12-03 19:27:49,033 DEBUG TRAIN Batch 4/3100 loss 32.781502 loss_att 35.740101 loss_ctc 44.335033 loss_rnnt 30.649307 lr 0.00082853 rank 4
2022-12-03 19:29:03,480 DEBUG TRAIN Batch 4/3200 loss 22.991653 loss_att 30.761511 loss_ctc 41.184013 loss_rnnt 19.012032 lr 0.00082713 rank 6
2022-12-03 19:29:03,482 DEBUG TRAIN Batch 4/3200 loss 38.817829 loss_att 47.392677 loss_ctc 60.331116 loss_rnnt 34.234421 lr 0.00082680 rank 0
2022-12-03 19:29:03,484 DEBUG TRAIN Batch 4/3200 loss 12.464496 loss_att 12.831291 loss_ctc 18.326681 loss_rnnt 11.609511 lr 0.00082671 rank 3
2022-12-03 19:29:03,489 DEBUG TRAIN Batch 4/3200 loss 16.745798 loss_att 19.877056 loss_ctc 24.162443 loss_rnnt 15.130660 lr 0.00082720 rank 7
2022-12-03 19:29:03,501 DEBUG TRAIN Batch 4/3200 loss 15.725184 loss_att 20.117130 loss_ctc 23.433298 loss_rnnt 13.819046 lr 0.00082634 rank 2
2022-12-03 19:29:03,506 DEBUG TRAIN Batch 4/3200 loss 18.463089 loss_att 26.934116 loss_ctc 31.507309 loss_rnnt 15.029654 lr 0.00082688 rank 1
2022-12-03 19:29:03,513 DEBUG TRAIN Batch 4/3200 loss 12.226983 loss_att 17.850348 loss_ctc 22.021704 loss_rnnt 9.796347 lr 0.00082739 rank 4
2022-12-03 19:29:03,535 DEBUG TRAIN Batch 4/3200 loss 16.937473 loss_att 21.407875 loss_ctc 26.913582 loss_rnnt 14.713245 lr 0.00082704 rank 5
2022-12-03 19:30:15,507 DEBUG TRAIN Batch 4/3300 loss 26.110519 loss_att 35.412163 loss_ctc 49.751457 loss_rnnt 21.098064 lr 0.00082600 rank 6
2022-12-03 19:30:15,516 DEBUG TRAIN Batch 4/3300 loss 42.936771 loss_att 45.644508 loss_ctc 70.609398 loss_rnnt 38.705544 lr 0.00082567 rank 0
2022-12-03 19:30:15,524 DEBUG TRAIN Batch 4/3300 loss 16.371853 loss_att 24.929468 loss_ctc 32.099571 loss_rnnt 12.563301 lr 0.00082607 rank 7
2022-12-03 19:30:15,525 DEBUG TRAIN Batch 4/3300 loss 24.378868 loss_att 28.529406 loss_ctc 39.120647 loss_rnnt 21.583189 lr 0.00082591 rank 5
2022-12-03 19:30:15,528 DEBUG TRAIN Batch 4/3300 loss 15.674766 loss_att 21.860359 loss_ctc 29.573301 loss_rnnt 12.584509 lr 0.00082575 rank 1
2022-12-03 19:30:15,528 DEBUG TRAIN Batch 4/3300 loss 16.958672 loss_att 25.000305 loss_ctc 30.138479 loss_rnnt 13.593036 lr 0.00082521 rank 2
2022-12-03 19:30:15,531 DEBUG TRAIN Batch 4/3300 loss 20.200773 loss_att 29.630278 loss_ctc 31.741901 loss_rnnt 16.776054 lr 0.00082558 rank 3
2022-12-03 19:30:15,575 DEBUG TRAIN Batch 4/3300 loss 24.845396 loss_att 33.145077 loss_ctc 38.060303 loss_rnnt 21.423473 lr 0.00082626 rank 4
2022-12-03 19:31:27,915 DEBUG TRAIN Batch 4/3400 loss 25.258099 loss_att 30.666706 loss_ctc 36.816551 loss_rnnt 22.635250 lr 0.00082455 rank 0
2022-12-03 19:31:27,916 DEBUG TRAIN Batch 4/3400 loss 4.996988 loss_att 9.833136 loss_ctc 10.615483 loss_rnnt 3.280625 lr 0.00082488 rank 6
2022-12-03 19:31:27,916 DEBUG TRAIN Batch 4/3400 loss 21.344181 loss_att 29.398453 loss_ctc 39.302502 loss_rnnt 17.338886 lr 0.00082494 rank 7
2022-12-03 19:31:27,917 DEBUG TRAIN Batch 4/3400 loss 16.185223 loss_att 23.362789 loss_ctc 36.047684 loss_rnnt 12.101379 lr 0.00082463 rank 1
2022-12-03 19:31:27,918 DEBUG TRAIN Batch 4/3400 loss 27.815735 loss_att 32.669357 loss_ctc 35.916500 loss_rnnt 25.764908 lr 0.00082479 rank 5
2022-12-03 19:31:27,921 DEBUG TRAIN Batch 4/3400 loss 15.308319 loss_att 22.723373 loss_ctc 34.065922 loss_rnnt 11.324294 lr 0.00082409 rank 2
2022-12-03 19:31:27,921 DEBUG TRAIN Batch 4/3400 loss 21.411581 loss_att 23.799282 loss_ctc 36.363338 loss_rnnt 18.940472 lr 0.00082446 rank 3
2022-12-03 19:31:27,926 DEBUG TRAIN Batch 4/3400 loss 11.810799 loss_att 16.704550 loss_ctc 18.977484 loss_rnnt 9.876492 lr 0.00082513 rank 4
2022-12-03 19:32:41,441 DEBUG TRAIN Batch 4/3500 loss 36.083649 loss_att 45.024052 loss_ctc 52.155125 loss_rnnt 32.152706 lr 0.00082297 rank 2
2022-12-03 19:32:41,442 DEBUG TRAIN Batch 4/3500 loss 15.377942 loss_att 22.093079 loss_ctc 23.232327 loss_rnnt 12.987663 lr 0.00082376 rank 6
2022-12-03 19:32:41,442 DEBUG TRAIN Batch 4/3500 loss 20.277428 loss_att 23.022200 loss_ctc 34.679062 loss_rnnt 17.808254 lr 0.00082382 rank 7
2022-12-03 19:32:41,444 DEBUG TRAIN Batch 4/3500 loss 28.859989 loss_att 39.237049 loss_ctc 49.669975 loss_rnnt 24.009914 lr 0.00082351 rank 1
2022-12-03 19:32:41,446 DEBUG TRAIN Batch 4/3500 loss 30.842850 loss_att 39.256546 loss_ctc 50.328079 loss_rnnt 26.562080 lr 0.00082334 rank 3
2022-12-03 19:32:41,446 DEBUG TRAIN Batch 4/3500 loss 38.532375 loss_att 48.788197 loss_ctc 58.193504 loss_rnnt 33.859726 lr 0.00082343 rank 0
2022-12-03 19:32:41,448 DEBUG TRAIN Batch 4/3500 loss 39.302094 loss_att 42.435516 loss_ctc 55.850864 loss_rnnt 36.468906 lr 0.00082401 rank 4
2022-12-03 19:32:41,471 DEBUG TRAIN Batch 4/3500 loss 14.331890 loss_att 21.410969 loss_ctc 22.222927 loss_rnnt 11.863936 lr 0.00082367 rank 5
2022-12-03 19:33:54,467 DEBUG TRAIN Batch 4/3600 loss 22.027519 loss_att 31.304451 loss_ctc 36.506943 loss_rnnt 18.241543 lr 0.00082255 rank 5
2022-12-03 19:33:54,481 DEBUG TRAIN Batch 4/3600 loss 28.725288 loss_att 33.334694 loss_ctc 46.380608 loss_rnnt 25.449364 lr 0.00082264 rank 6
2022-12-03 19:33:54,483 DEBUG TRAIN Batch 4/3600 loss 17.988956 loss_att 22.570196 loss_ctc 29.030144 loss_rnnt 15.600552 lr 0.00082232 rank 0
2022-12-03 19:33:54,486 DEBUG TRAIN Batch 4/3600 loss 17.272385 loss_att 21.583111 loss_ctc 30.446112 loss_rnnt 14.653743 lr 0.00082271 rank 7
2022-12-03 19:33:54,489 DEBUG TRAIN Batch 4/3600 loss 10.875023 loss_att 17.467590 loss_ctc 22.562641 loss_rnnt 7.998159 lr 0.00082240 rank 1
2022-12-03 19:33:54,491 DEBUG TRAIN Batch 4/3600 loss 32.148579 loss_att 36.628357 loss_ctc 55.004723 loss_rnnt 28.205135 lr 0.00082290 rank 4
2022-12-03 19:33:54,492 DEBUG TRAIN Batch 4/3600 loss 20.543814 loss_att 28.782387 loss_ctc 39.952938 loss_rnnt 16.308216 lr 0.00082223 rank 3
2022-12-03 19:33:54,536 DEBUG TRAIN Batch 4/3600 loss 29.473373 loss_att 36.468857 loss_ctc 49.960831 loss_rnnt 25.342613 lr 0.00082186 rank 2
2022-12-03 19:35:06,209 DEBUG TRAIN Batch 4/3700 loss 22.014645 loss_att 31.352812 loss_ctc 38.076271 loss_rnnt 18.005461 lr 0.00082153 rank 6
2022-12-03 19:35:06,211 DEBUG TRAIN Batch 4/3700 loss 10.780913 loss_att 15.014027 loss_ctc 17.674885 loss_rnnt 9.015095 lr 0.00082144 rank 5
2022-12-03 19:35:06,212 DEBUG TRAIN Batch 4/3700 loss 9.867331 loss_att 15.412155 loss_ctc 22.196840 loss_rnnt 7.114430 lr 0.00082075 rank 2
2022-12-03 19:35:06,214 DEBUG TRAIN Batch 4/3700 loss 12.698175 loss_att 16.981743 loss_ctc 23.958494 loss_rnnt 10.340087 lr 0.00082160 rank 7
2022-12-03 19:35:06,215 DEBUG TRAIN Batch 4/3700 loss 26.050415 loss_att 28.463083 loss_ctc 42.924873 loss_rnnt 23.317953 lr 0.00082128 rank 1
2022-12-03 19:35:06,217 DEBUG TRAIN Batch 4/3700 loss 25.359022 loss_att 26.487131 loss_ctc 37.436218 loss_rnnt 23.523106 lr 0.00082112 rank 3
2022-12-03 19:35:06,221 DEBUG TRAIN Batch 4/3700 loss 23.149836 loss_att 24.190262 loss_ctc 30.971552 loss_rnnt 21.898853 lr 0.00082121 rank 0
2022-12-03 19:35:06,223 DEBUG TRAIN Batch 4/3700 loss 21.014095 loss_att 23.563293 loss_ctc 31.521427 loss_rnnt 19.103277 lr 0.00082178 rank 4
2022-12-03 19:36:18,527 DEBUG TRAIN Batch 4/3800 loss 10.181911 loss_att 13.547923 loss_ctc 17.782867 loss_rnnt 8.495247 lr 0.00082033 rank 5
2022-12-03 19:36:18,529 DEBUG TRAIN Batch 4/3800 loss 34.649246 loss_att 44.861412 loss_ctc 49.687729 loss_rnnt 30.601683 lr 0.00082018 rank 1
2022-12-03 19:36:18,531 DEBUG TRAIN Batch 4/3800 loss 12.503110 loss_att 16.064686 loss_ctc 21.012478 loss_rnnt 10.656212 lr 0.00082042 rank 6
2022-12-03 19:36:18,532 DEBUG TRAIN Batch 4/3800 loss 18.126884 loss_att 20.685434 loss_ctc 27.563211 loss_rnnt 16.356997 lr 0.00082001 rank 3
2022-12-03 19:36:18,535 DEBUG TRAIN Batch 4/3800 loss 17.358442 loss_att 18.291157 loss_ctc 26.210672 loss_rnnt 15.991601 lr 0.00082068 rank 4
2022-12-03 19:36:18,536 DEBUG TRAIN Batch 4/3800 loss 18.450270 loss_att 22.321194 loss_ctc 27.766567 loss_rnnt 16.433910 lr 0.00081965 rank 2
2022-12-03 19:36:18,536 DEBUG TRAIN Batch 4/3800 loss 28.797665 loss_att 33.823929 loss_ctc 47.273293 loss_rnnt 25.328995 lr 0.00082049 rank 7
2022-12-03 19:36:18,538 DEBUG TRAIN Batch 4/3800 loss 13.542208 loss_att 15.118649 loss_ctc 20.089401 loss_rnnt 12.353960 lr 0.00082010 rank 0
2022-12-03 19:37:32,370 DEBUG TRAIN Batch 4/3900 loss 25.363287 loss_att 33.061241 loss_ctc 42.926537 loss_rnnt 21.481930 lr 0.00081932 rank 6
2022-12-03 19:37:32,373 DEBUG TRAIN Batch 4/3900 loss 31.876396 loss_att 39.269848 loss_ctc 49.185833 loss_rnnt 28.089783 lr 0.00081900 rank 0
2022-12-03 19:37:32,376 DEBUG TRAIN Batch 4/3900 loss 20.228849 loss_att 34.552612 loss_ctc 42.119774 loss_rnnt 14.445308 lr 0.00081908 rank 1
2022-12-03 19:37:32,378 DEBUG TRAIN Batch 4/3900 loss 42.069351 loss_att 47.229313 loss_ctc 59.495571 loss_rnnt 38.713863 lr 0.00081891 rank 3
2022-12-03 19:37:32,377 DEBUG TRAIN Batch 4/3900 loss 17.862457 loss_att 27.857775 loss_ctc 29.862257 loss_rnnt 14.263420 lr 0.00081855 rank 2
2022-12-03 19:37:32,378 DEBUG TRAIN Batch 4/3900 loss 25.511990 loss_att 25.863388 loss_ctc 36.686806 loss_rnnt 23.951735 lr 0.00081939 rank 7
2022-12-03 19:37:32,382 DEBUG TRAIN Batch 4/3900 loss 15.262432 loss_att 15.299294 loss_ctc 18.547461 loss_rnnt 14.817056 lr 0.00081923 rank 5
2022-12-03 19:37:32,428 DEBUG TRAIN Batch 4/3900 loss 40.547134 loss_att 48.434155 loss_ctc 65.740646 loss_rnnt 35.610596 lr 0.00081957 rank 4
2022-12-03 19:38:44,411 DEBUG TRAIN Batch 4/4000 loss 27.107380 loss_att 30.400185 loss_ctc 38.819653 loss_rnnt 24.887182 lr 0.00081822 rank 6
2022-12-03 19:38:44,415 DEBUG TRAIN Batch 4/4000 loss 19.516861 loss_att 26.065338 loss_ctc 39.731071 loss_rnnt 15.511938 lr 0.00081782 rank 3
2022-12-03 19:38:44,415 DEBUG TRAIN Batch 4/4000 loss 11.256296 loss_att 18.208710 loss_ctc 20.186745 loss_rnnt 8.675086 lr 0.00081813 rank 5
2022-12-03 19:38:44,417 DEBUG TRAIN Batch 4/4000 loss 26.526300 loss_att 33.152252 loss_ctc 39.231037 loss_rnnt 23.507147 lr 0.00081746 rank 2
2022-12-03 19:38:44,420 DEBUG TRAIN Batch 4/4000 loss 46.219402 loss_att 51.524231 loss_ctc 72.832497 loss_rnnt 41.610023 lr 0.00081798 rank 1
2022-12-03 19:38:44,423 DEBUG TRAIN Batch 4/4000 loss 25.610523 loss_att 36.901463 loss_ctc 47.105515 loss_rnnt 20.486336 lr 0.00081829 rank 7
2022-12-03 19:38:44,422 DEBUG TRAIN Batch 4/4000 loss 16.092037 loss_att 21.022621 loss_ctc 26.206381 loss_rnnt 13.757342 lr 0.00081790 rank 0
2022-12-03 19:38:44,427 DEBUG TRAIN Batch 4/4000 loss 27.797249 loss_att 32.297104 loss_ctc 46.045784 loss_rnnt 24.464140 lr 0.00081847 rank 4
2022-12-03 19:39:55,543 DEBUG TRAIN Batch 4/4100 loss 16.749426 loss_att 20.031843 loss_ctc 30.154026 loss_rnnt 14.305661 lr 0.00081713 rank 6
2022-12-03 19:39:55,543 DEBUG TRAIN Batch 4/4100 loss 30.807867 loss_att 41.130428 loss_ctc 54.036064 loss_rnnt 25.646259 lr 0.00081704 rank 5
2022-12-03 19:39:55,548 DEBUG TRAIN Batch 4/4100 loss 22.353367 loss_att 23.351665 loss_ctc 31.847229 loss_rnnt 20.887859 lr 0.00081681 rank 0
2022-12-03 19:39:55,550 DEBUG TRAIN Batch 4/4100 loss 34.953938 loss_att 40.747391 loss_ctc 49.877163 loss_rnnt 31.805481 lr 0.00081689 rank 1
2022-12-03 19:39:55,549 DEBUG TRAIN Batch 4/4100 loss 33.091919 loss_att 46.240223 loss_ctc 60.566761 loss_rnnt 26.798943 lr 0.00081738 rank 4
2022-12-03 19:39:55,551 DEBUG TRAIN Batch 4/4100 loss 15.733327 loss_att 24.158134 loss_ctc 21.021067 loss_rnnt 13.343332 lr 0.00081719 rank 7
2022-12-03 19:39:55,551 DEBUG TRAIN Batch 4/4100 loss 25.186079 loss_att 34.092346 loss_ctc 46.397732 loss_rnnt 20.576607 lr 0.00081673 rank 3
2022-12-03 19:39:55,557 DEBUG TRAIN Batch 4/4100 loss 33.046593 loss_att 40.464249 loss_ctc 49.992912 loss_rnnt 29.303553 lr 0.00081637 rank 2
2022-12-03 19:41:07,994 DEBUG TRAIN Batch 4/4200 loss 19.811329 loss_att 26.696198 loss_ctc 34.026360 loss_rnnt 16.539017 lr 0.00081572 rank 0
2022-12-03 19:41:08,006 DEBUG TRAIN Batch 4/4200 loss 25.904133 loss_att 31.813450 loss_ctc 46.823742 loss_rnnt 21.932987 lr 0.00081604 rank 6
2022-12-03 19:41:08,009 DEBUG TRAIN Batch 4/4200 loss 24.038395 loss_att 34.356083 loss_ctc 46.574829 loss_rnnt 18.969997 lr 0.00081564 rank 3
2022-12-03 19:41:08,013 DEBUG TRAIN Batch 4/4200 loss 32.636211 loss_att 34.937256 loss_ctc 48.759354 loss_rnnt 30.026249 lr 0.00081595 rank 5
2022-12-03 19:41:08,013 DEBUG TRAIN Batch 4/4200 loss 11.283827 loss_att 17.480598 loss_ctc 17.909698 loss_rnnt 9.161024 lr 0.00081610 rank 7
2022-12-03 19:41:08,017 DEBUG TRAIN Batch 4/4200 loss 21.953297 loss_att 25.246347 loss_ctc 32.982449 loss_rnnt 19.824133 lr 0.00081629 rank 4
2022-12-03 19:41:08,035 DEBUG TRAIN Batch 4/4200 loss 32.966732 loss_att 35.661293 loss_ctc 52.549049 loss_rnnt 29.816843 lr 0.00081528 rank 2
2022-12-03 19:41:08,039 DEBUG TRAIN Batch 4/4200 loss 18.350817 loss_att 21.681280 loss_ctc 27.787903 loss_rnnt 16.426445 lr 0.00081580 rank 1
2022-12-03 19:42:21,070 DEBUG TRAIN Batch 4/4300 loss 28.820215 loss_att 31.823666 loss_ctc 38.835976 loss_rnnt 26.884089 lr 0.00081487 rank 5
2022-12-03 19:42:21,074 DEBUG TRAIN Batch 4/4300 loss 21.416891 loss_att 24.769348 loss_ctc 33.197384 loss_rnnt 19.175667 lr 0.00081455 rank 3
2022-12-03 19:42:21,077 DEBUG TRAIN Batch 4/4300 loss 12.824633 loss_att 18.197924 loss_ctc 26.420321 loss_rnnt 9.937215 lr 0.00081496 rank 6
2022-12-03 19:42:21,083 DEBUG TRAIN Batch 4/4300 loss 30.571650 loss_att 36.574081 loss_ctc 47.718468 loss_rnnt 27.084919 lr 0.00081502 rank 7
2022-12-03 19:42:21,085 DEBUG TRAIN Batch 4/4300 loss 17.206612 loss_att 22.844437 loss_ctc 26.642904 loss_rnnt 14.820875 lr 0.00081420 rank 2
2022-12-03 19:42:21,086 DEBUG TRAIN Batch 4/4300 loss 16.400478 loss_att 21.279011 loss_ctc 28.093369 loss_rnnt 13.865720 lr 0.00081464 rank 0
2022-12-03 19:42:21,088 DEBUG TRAIN Batch 4/4300 loss 25.022060 loss_att 31.840664 loss_ctc 37.723202 loss_rnnt 21.964855 lr 0.00081520 rank 4
2022-12-03 19:42:21,122 DEBUG TRAIN Batch 4/4300 loss 15.816010 loss_att 18.901306 loss_ctc 26.254000 loss_rnnt 13.807219 lr 0.00081472 rank 1
2022-12-03 19:43:32,806 DEBUG TRAIN Batch 4/4400 loss 20.945879 loss_att 22.807287 loss_ctc 34.809654 loss_rnnt 18.725096 lr 0.00081356 rank 0
2022-12-03 19:43:32,807 DEBUG TRAIN Batch 4/4400 loss 14.033088 loss_att 18.038948 loss_ctc 24.183441 loss_rnnt 11.878535 lr 0.00081348 rank 3
2022-12-03 19:43:32,810 DEBUG TRAIN Batch 4/4400 loss 24.736206 loss_att 30.531158 loss_ctc 43.066162 loss_rnnt 21.133223 lr 0.00081387 rank 6
2022-12-03 19:43:32,811 DEBUG TRAIN Batch 4/4400 loss 16.695566 loss_att 19.613546 loss_ctc 25.918123 loss_rnnt 14.882296 lr 0.00081394 rank 7
2022-12-03 19:43:32,812 DEBUG TRAIN Batch 4/4400 loss 22.385368 loss_att 27.837547 loss_ctc 30.361660 loss_rnnt 20.231428 lr 0.00081379 rank 5
2022-12-03 19:43:32,813 DEBUG TRAIN Batch 4/4400 loss 23.704088 loss_att 27.893515 loss_ctc 37.067867 loss_rnnt 21.084366 lr 0.00081364 rank 1
2022-12-03 19:43:32,819 DEBUG TRAIN Batch 4/4400 loss 20.929342 loss_att 24.415668 loss_ctc 34.554237 loss_rnnt 18.415424 lr 0.00081312 rank 2
2022-12-03 19:43:32,820 DEBUG TRAIN Batch 4/4400 loss 19.841187 loss_att 21.226355 loss_ctc 31.073544 loss_rnnt 18.066505 lr 0.00081412 rank 4
2022-12-03 19:44:43,968 DEBUG TRAIN Batch 4/4500 loss 14.150496 loss_att 14.239622 loss_ctc 18.942442 loss_rnnt 13.493744 lr 0.00081280 rank 6
2022-12-03 19:44:43,972 DEBUG TRAIN Batch 4/4500 loss 18.057264 loss_att 22.646111 loss_ctc 30.891859 loss_rnnt 15.428215 lr 0.00081271 rank 5
2022-12-03 19:44:43,972 DEBUG TRAIN Batch 4/4500 loss 19.127733 loss_att 24.073599 loss_ctc 33.515560 loss_rnnt 16.220184 lr 0.00081240 rank 3
2022-12-03 19:44:43,974 DEBUG TRAIN Batch 4/4500 loss 17.199121 loss_att 19.510902 loss_ctc 27.793354 loss_rnnt 15.324202 lr 0.00081249 rank 0
2022-12-03 19:44:43,975 DEBUG TRAIN Batch 4/4500 loss 12.705332 loss_att 15.145184 loss_ctc 20.268972 loss_rnnt 11.208877 lr 0.00081286 rank 7
2022-12-03 19:44:43,978 DEBUG TRAIN Batch 4/4500 loss 24.806158 loss_att 32.936695 loss_ctc 36.941299 loss_rnnt 21.562031 lr 0.00081305 rank 4
2022-12-03 19:44:43,979 DEBUG TRAIN Batch 4/4500 loss 26.820877 loss_att 30.700426 loss_ctc 40.970810 loss_rnnt 24.158310 lr 0.00081205 rank 2
2022-12-03 19:44:43,982 DEBUG TRAIN Batch 4/4500 loss 28.265266 loss_att 36.931053 loss_ctc 51.666866 loss_rnnt 23.411896 lr 0.00081256 rank 1
2022-12-03 19:45:57,448 DEBUG TRAIN Batch 4/4600 loss 18.846502 loss_att 23.800114 loss_ctc 26.642639 loss_rnnt 16.816296 lr 0.00081133 rank 3
2022-12-03 19:45:57,450 DEBUG TRAIN Batch 4/4600 loss 17.500942 loss_att 25.509060 loss_ctc 30.248013 loss_rnnt 14.199710 lr 0.00081098 rank 2
2022-12-03 19:45:57,457 DEBUG TRAIN Batch 4/4600 loss 20.968029 loss_att 31.536402 loss_ctc 34.080822 loss_rnnt 17.105980 lr 0.00081149 rank 1
2022-12-03 19:45:57,463 DEBUG TRAIN Batch 4/4600 loss 20.446712 loss_att 24.661184 loss_ctc 39.732777 loss_rnnt 17.032345 lr 0.00081142 rank 0
2022-12-03 19:45:57,464 DEBUG TRAIN Batch 4/4600 loss 27.787668 loss_att 37.482849 loss_ctc 44.400146 loss_rnnt 23.633635 lr 0.00081164 rank 5
2022-12-03 19:45:57,485 DEBUG TRAIN Batch 4/4600 loss 21.112459 loss_att 30.787493 loss_ctc 33.477310 loss_rnnt 17.528805 lr 0.00081197 rank 4
2022-12-03 19:45:57,503 DEBUG TRAIN Batch 4/4600 loss 39.005257 loss_att 47.174629 loss_ctc 66.233665 loss_rnnt 33.740929 lr 0.00081179 rank 7
2022-12-03 19:45:57,504 DEBUG TRAIN Batch 4/4600 loss 23.429722 loss_att 29.260895 loss_ctc 38.920246 loss_rnnt 20.198082 lr 0.00081173 rank 6
2022-12-03 19:47:09,204 DEBUG TRAIN Batch 4/4700 loss 29.540947 loss_att 38.524677 loss_ctc 44.977524 loss_rnnt 25.685989 lr 0.00081066 rank 6
2022-12-03 19:47:09,208 DEBUG TRAIN Batch 4/4700 loss 17.794542 loss_att 21.573893 loss_ctc 32.278114 loss_rnnt 15.107529 lr 0.00081072 rank 7
2022-12-03 19:47:09,209 DEBUG TRAIN Batch 4/4700 loss 15.651924 loss_att 22.698532 loss_ctc 31.067604 loss_rnnt 12.187179 lr 0.00081035 rank 0
2022-12-03 19:47:09,212 DEBUG TRAIN Batch 4/4700 loss 19.584549 loss_att 26.669603 loss_ctc 37.969086 loss_rnnt 15.716267 lr 0.00081027 rank 3
2022-12-03 19:47:09,214 DEBUG TRAIN Batch 4/4700 loss 36.244339 loss_att 40.873840 loss_ctc 49.529129 loss_rnnt 33.547134 lr 0.00081042 rank 1
2022-12-03 19:47:09,216 DEBUG TRAIN Batch 4/4700 loss 33.099487 loss_att 45.485947 loss_ctc 58.563259 loss_rnnt 27.227026 lr 0.00081057 rank 5
2022-12-03 19:47:09,218 DEBUG TRAIN Batch 4/4700 loss 15.714439 loss_att 22.335455 loss_ctc 25.967010 loss_rnnt 13.023226 lr 0.00081090 rank 4
2022-12-03 19:47:09,257 DEBUG TRAIN Batch 4/4700 loss 20.982452 loss_att 30.307438 loss_ctc 38.779938 loss_rnnt 16.744457 lr 0.00080991 rank 2
2022-12-03 19:48:20,570 DEBUG TRAIN Batch 4/4800 loss 19.010231 loss_att 26.288948 loss_ctc 31.799856 loss_rnnt 15.849204 lr 0.00080960 rank 6
2022-12-03 19:48:20,575 DEBUG TRAIN Batch 4/4800 loss 48.385071 loss_att 62.842121 loss_ctc 73.866257 loss_rnnt 42.096169 lr 0.00080951 rank 5
2022-12-03 19:48:20,581 DEBUG TRAIN Batch 4/4800 loss 30.114933 loss_att 35.464733 loss_ctc 50.757854 loss_rnnt 26.292583 lr 0.00080966 rank 7
2022-12-03 19:48:20,584 DEBUG TRAIN Batch 4/4800 loss 32.609371 loss_att 40.606911 loss_ctc 52.193588 loss_rnnt 28.398636 lr 0.00080929 rank 0
2022-12-03 19:48:20,584 DEBUG TRAIN Batch 4/4800 loss 17.215702 loss_att 22.037636 loss_ctc 29.472128 loss_rnnt 14.617126 lr 0.00080920 rank 3
2022-12-03 19:48:20,586 DEBUG TRAIN Batch 4/4800 loss 29.400181 loss_att 31.831099 loss_ctc 46.249458 loss_rnnt 26.667423 lr 0.00080936 rank 1
2022-12-03 19:48:20,587 DEBUG TRAIN Batch 4/4800 loss 20.170475 loss_att 29.763809 loss_ctc 33.354641 loss_rnnt 16.493919 lr 0.00080885 rank 2
2022-12-03 19:48:20,589 DEBUG TRAIN Batch 4/4800 loss 32.390892 loss_att 35.244659 loss_ctc 52.251667 loss_rnnt 29.172031 lr 0.00080984 rank 4
2022-12-03 19:49:32,150 DEBUG TRAIN Batch 4/4900 loss 22.405687 loss_att 22.695181 loss_ctc 36.566513 loss_rnnt 20.459679 lr 0.00080780 rank 2
2022-12-03 19:49:32,151 DEBUG TRAIN Batch 4/4900 loss 28.930235 loss_att 33.604485 loss_ctc 46.932167 loss_rnnt 25.595129 lr 0.00080830 rank 1
2022-12-03 19:49:32,161 DEBUG TRAIN Batch 4/4900 loss 21.291237 loss_att 26.083920 loss_ctc 31.538174 loss_rnnt 18.966442 lr 0.00080854 rank 6
2022-12-03 19:49:32,162 DEBUG TRAIN Batch 4/4900 loss 29.603561 loss_att 42.786537 loss_ctc 50.130653 loss_rnnt 24.230022 lr 0.00080860 rank 7
2022-12-03 19:49:32,164 DEBUG TRAIN Batch 4/4900 loss 27.875877 loss_att 35.073166 loss_ctc 52.454414 loss_rnnt 23.159283 lr 0.00080815 rank 3
2022-12-03 19:49:32,164 DEBUG TRAIN Batch 4/4900 loss 28.712976 loss_att 35.200485 loss_ctc 47.415398 loss_rnnt 24.921818 lr 0.00080878 rank 4
2022-12-03 19:49:32,164 DEBUG TRAIN Batch 4/4900 loss 21.044334 loss_att 30.075481 loss_ctc 36.157074 loss_rnnt 17.223072 lr 0.00080845 rank 5
2022-12-03 19:49:32,168 DEBUG TRAIN Batch 4/4900 loss 31.293385 loss_att 34.976624 loss_ctc 42.496933 loss_rnnt 29.062929 lr 0.00080823 rank 0
2022-12-03 19:50:45,821 DEBUG TRAIN Batch 4/5000 loss 21.941841 loss_att 28.237133 loss_ctc 31.681885 loss_rnnt 19.384109 lr 0.00080725 rank 1
2022-12-03 19:50:45,821 DEBUG TRAIN Batch 4/5000 loss 26.041498 loss_att 30.772779 loss_ctc 45.618267 loss_rnnt 22.485006 lr 0.00080740 rank 5
2022-12-03 19:50:45,824 DEBUG TRAIN Batch 4/5000 loss 17.462191 loss_att 25.023418 loss_ctc 27.131222 loss_rnnt 14.660740 lr 0.00080718 rank 0
2022-12-03 19:50:45,826 DEBUG TRAIN Batch 4/5000 loss 20.523506 loss_att 23.888054 loss_ctc 31.658045 loss_rnnt 18.365992 lr 0.00080675 rank 2
2022-12-03 19:50:45,828 DEBUG TRAIN Batch 4/5000 loss 14.402247 loss_att 20.158125 loss_ctc 26.990513 loss_rnnt 11.572637 lr 0.00080709 rank 3
2022-12-03 19:50:45,828 DEBUG TRAIN Batch 4/5000 loss 23.890032 loss_att 22.318033 loss_ctc 32.583900 loss_rnnt 23.045248 lr 0.00080772 rank 4
2022-12-03 19:50:45,829 DEBUG TRAIN Batch 4/5000 loss 24.633352 loss_att 30.626516 loss_ctc 43.028896 loss_rnnt 20.981979 lr 0.00080754 rank 7
2022-12-03 19:50:45,830 DEBUG TRAIN Batch 4/5000 loss 29.030149 loss_att 34.993942 loss_ctc 47.525330 loss_rnnt 25.371367 lr 0.00080748 rank 6
2022-12-03 19:51:58,807 DEBUG TRAIN Batch 4/5100 loss 23.198053 loss_att 22.004520 loss_ctc 31.187267 loss_rnnt 22.371532 lr 0.00080643 rank 6
2022-12-03 19:51:58,811 DEBUG TRAIN Batch 4/5100 loss 10.975015 loss_att 11.304809 loss_ctc 14.483870 loss_rnnt 10.441208 lr 0.00080620 rank 1
2022-12-03 19:51:58,813 DEBUG TRAIN Batch 4/5100 loss 7.470017 loss_att 9.430847 loss_ctc 10.299849 loss_rnnt 6.700540 lr 0.00080570 rank 2
2022-12-03 19:51:58,814 DEBUG TRAIN Batch 4/5100 loss 28.911903 loss_att 33.219315 loss_ctc 45.085430 loss_rnnt 25.893951 lr 0.00080635 rank 5
2022-12-03 19:51:58,813 DEBUG TRAIN Batch 4/5100 loss 13.854237 loss_att 14.965246 loss_ctc 21.208473 loss_rnnt 12.651469 lr 0.00080613 rank 0
2022-12-03 19:51:58,814 DEBUG TRAIN Batch 4/5100 loss 17.230955 loss_att 19.316389 loss_ctc 25.638702 loss_rnnt 15.692836 lr 0.00080604 rank 3
2022-12-03 19:51:58,816 DEBUG TRAIN Batch 4/5100 loss 12.000561 loss_att 18.276917 loss_ctc 19.950773 loss_rnnt 9.685262 lr 0.00080649 rank 7
2022-12-03 19:51:58,817 DEBUG TRAIN Batch 4/5100 loss 10.226726 loss_att 10.679253 loss_ctc 12.688395 loss_rnnt 9.807998 lr 0.00080667 rank 4
2022-12-03 19:53:10,632 DEBUG TRAIN Batch 4/5200 loss 28.163782 loss_att 28.652382 loss_ctc 40.135635 loss_rnnt 26.469816 lr 0.00080530 rank 5
2022-12-03 19:53:10,632 DEBUG TRAIN Batch 4/5200 loss 32.410606 loss_att 38.965149 loss_ctc 47.358562 loss_rnnt 29.106640 lr 0.00080500 rank 3
2022-12-03 19:53:10,634 DEBUG TRAIN Batch 4/5200 loss 20.646694 loss_att 26.737930 loss_ctc 30.259285 loss_rnnt 18.146767 lr 0.00080545 rank 7
2022-12-03 19:53:10,636 DEBUG TRAIN Batch 4/5200 loss 25.281954 loss_att 32.026833 loss_ctc 46.512321 loss_rnnt 21.102261 lr 0.00080508 rank 0
2022-12-03 19:53:10,635 DEBUG TRAIN Batch 4/5200 loss 29.308954 loss_att 39.327599 loss_ctc 46.721184 loss_rnnt 24.983595 lr 0.00080538 rank 6
2022-12-03 19:53:10,637 DEBUG TRAIN Batch 4/5200 loss 12.977087 loss_att 22.606503 loss_ctc 25.800589 loss_rnnt 9.341404 lr 0.00080562 rank 4
2022-12-03 19:53:10,637 DEBUG TRAIN Batch 4/5200 loss 17.923061 loss_att 26.080139 loss_ctc 30.548141 loss_rnnt 14.608301 lr 0.00080465 rank 2
2022-12-03 19:53:10,641 DEBUG TRAIN Batch 4/5200 loss 11.873230 loss_att 17.460100 loss_ctc 25.131462 loss_rnnt 8.988091 lr 0.00080515 rank 1
2022-12-03 19:54:23,773 DEBUG TRAIN Batch 4/5300 loss 17.272383 loss_att 23.977411 loss_ctc 23.277981 loss_rnnt 15.130630 lr 0.00080434 rank 6
2022-12-03 19:54:23,777 DEBUG TRAIN Batch 4/5300 loss 26.989607 loss_att 33.743309 loss_ctc 44.866806 loss_rnnt 23.255239 lr 0.00080426 rank 5
2022-12-03 19:54:23,777 DEBUG TRAIN Batch 4/5300 loss 25.372160 loss_att 27.597122 loss_ctc 37.267372 loss_rnnt 23.341139 lr 0.00080396 rank 3
2022-12-03 19:54:23,778 DEBUG TRAIN Batch 4/5300 loss 10.397153 loss_att 16.502226 loss_ctc 20.549871 loss_rnnt 7.822443 lr 0.00080411 rank 1
2022-12-03 19:54:23,780 DEBUG TRAIN Batch 4/5300 loss 16.307665 loss_att 19.427311 loss_ctc 31.790920 loss_rnnt 13.619301 lr 0.00080404 rank 0
2022-12-03 19:54:23,792 DEBUG TRAIN Batch 4/5300 loss 34.912716 loss_att 41.395180 loss_ctc 61.019577 loss_rnnt 30.135307 lr 0.00080440 rank 7
2022-12-03 19:54:23,800 DEBUG TRAIN Batch 4/5300 loss 16.569040 loss_att 22.301994 loss_ctc 26.406269 loss_rnnt 14.110820 lr 0.00080458 rank 4
2022-12-03 19:54:23,823 DEBUG TRAIN Batch 4/5300 loss 30.728678 loss_att 34.847446 loss_ctc 51.673504 loss_rnnt 27.112278 lr 0.00080361 rank 2
2022-12-03 19:55:36,228 DEBUG TRAIN Batch 4/5400 loss 22.596132 loss_att 28.954504 loss_ctc 36.292572 loss_rnnt 19.498266 lr 0.00080307 rank 1
2022-12-03 19:55:36,230 DEBUG TRAIN Batch 4/5400 loss 15.302545 loss_att 21.440041 loss_ctc 22.808544 loss_rnnt 13.074245 lr 0.00080322 rank 5
2022-12-03 19:55:36,231 DEBUG TRAIN Batch 4/5400 loss 25.533447 loss_att 30.203876 loss_ctc 39.918591 loss_rnnt 22.681339 lr 0.00080292 rank 3
2022-12-03 19:55:36,231 DEBUG TRAIN Batch 4/5400 loss 25.128643 loss_att 27.060843 loss_ctc 35.085972 loss_rnnt 23.414562 lr 0.00080330 rank 6
2022-12-03 19:55:36,233 DEBUG TRAIN Batch 4/5400 loss 17.067631 loss_att 22.283073 loss_ctc 34.518471 loss_rnnt 13.697762 lr 0.00080300 rank 0
2022-12-03 19:55:36,235 DEBUG TRAIN Batch 4/5400 loss 14.950335 loss_att 19.261990 loss_ctc 25.692112 loss_rnnt 12.655766 lr 0.00080258 rank 2
2022-12-03 19:55:36,237 DEBUG TRAIN Batch 4/5400 loss 12.091582 loss_att 24.181126 loss_ctc 23.414343 loss_rnnt 8.163973 lr 0.00080336 rank 7
2022-12-03 19:55:36,242 DEBUG TRAIN Batch 4/5400 loss 17.719517 loss_att 22.528433 loss_ctc 29.291348 loss_rnnt 15.214823 lr 0.00080354 rank 4
2022-12-03 19:56:48,045 DEBUG TRAIN Batch 4/5500 loss 32.278130 loss_att 37.022633 loss_ctc 46.446381 loss_rnnt 29.440126 lr 0.00080227 rank 6
2022-12-03 19:56:48,047 DEBUG TRAIN Batch 4/5500 loss 24.587099 loss_att 32.114552 loss_ctc 41.562904 loss_rnnt 20.818169 lr 0.00080218 rank 5
2022-12-03 19:56:48,056 DEBUG TRAIN Batch 4/5500 loss 31.836727 loss_att 39.575733 loss_ctc 59.958019 loss_rnnt 26.539419 lr 0.00080197 rank 0
2022-12-03 19:56:48,056 DEBUG TRAIN Batch 4/5500 loss 26.143417 loss_att 32.907345 loss_ctc 40.652954 loss_rnnt 22.856026 lr 0.00080233 rank 7
2022-12-03 19:56:48,058 DEBUG TRAIN Batch 4/5500 loss 27.630093 loss_att 36.262653 loss_ctc 41.295692 loss_rnnt 24.081499 lr 0.00080155 rank 2
2022-12-03 19:56:48,059 DEBUG TRAIN Batch 4/5500 loss 22.384846 loss_att 27.603254 loss_ctc 36.219723 loss_rnnt 19.496513 lr 0.00080189 rank 3
2022-12-03 19:56:48,059 DEBUG TRAIN Batch 4/5500 loss 35.681770 loss_att 43.604546 loss_ctc 50.442970 loss_rnnt 32.129051 lr 0.00080251 rank 4
2022-12-03 19:56:48,097 DEBUG TRAIN Batch 4/5500 loss 20.713846 loss_att 23.376429 loss_ctc 34.290108 loss_rnnt 18.371162 lr 0.00080204 rank 1
2022-12-03 19:57:59,478 DEBUG TRAIN Batch 4/5600 loss 17.721964 loss_att 21.786888 loss_ctc 34.216461 loss_rnnt 14.709711 lr 0.00080147 rank 4
2022-12-03 19:57:59,483 DEBUG TRAIN Batch 4/5600 loss 34.578873 loss_att 39.512608 loss_ctc 55.167542 loss_rnnt 30.846970 lr 0.00080101 rank 1
2022-12-03 19:57:59,485 DEBUG TRAIN Batch 4/5600 loss 21.202181 loss_att 25.249416 loss_ctc 33.099339 loss_rnnt 18.806444 lr 0.00080124 rank 6
2022-12-03 19:57:59,490 DEBUG TRAIN Batch 4/5600 loss 12.983383 loss_att 18.627691 loss_ctc 24.255936 loss_rnnt 10.351515 lr 0.00080115 rank 5
2022-12-03 19:57:59,490 DEBUG TRAIN Batch 4/5600 loss 34.554356 loss_att 37.290695 loss_ctc 50.840687 loss_rnnt 31.835577 lr 0.00080086 rank 3
2022-12-03 19:57:59,491 DEBUG TRAIN Batch 4/5600 loss 26.999111 loss_att 31.676544 loss_ctc 39.493923 loss_rnnt 24.397648 lr 0.00080052 rank 2
2022-12-03 19:57:59,491 DEBUG TRAIN Batch 4/5600 loss 28.772997 loss_att 33.695145 loss_ctc 44.659370 loss_rnnt 25.670385 lr 0.00080094 rank 0
2022-12-03 19:57:59,506 DEBUG TRAIN Batch 4/5600 loss 28.588411 loss_att 35.944420 loss_ctc 40.505005 loss_rnnt 25.528332 lr 0.00080130 rank 7
2022-12-03 19:59:13,612 DEBUG TRAIN Batch 4/5700 loss 31.252153 loss_att 36.420029 loss_ctc 45.044113 loss_rnnt 28.379648 lr 0.00080021 rank 6
2022-12-03 19:59:13,615 DEBUG TRAIN Batch 4/5700 loss 16.234194 loss_att 16.792046 loss_ctc 20.811495 loss_rnnt 15.512317 lr 0.00079991 rank 0
2022-12-03 19:59:13,615 DEBUG TRAIN Batch 4/5700 loss 12.806915 loss_att 18.097137 loss_ctc 24.846251 loss_rnnt 10.143626 lr 0.00079983 rank 3
2022-12-03 19:59:13,619 DEBUG TRAIN Batch 4/5700 loss 14.666864 loss_att 19.228331 loss_ctc 29.508732 loss_rnnt 11.775655 lr 0.00080013 rank 5
2022-12-03 19:59:13,621 DEBUG TRAIN Batch 4/5700 loss 29.836720 loss_att 33.912361 loss_ctc 48.186012 loss_rnnt 26.575016 lr 0.00080027 rank 7
2022-12-03 19:59:13,624 DEBUG TRAIN Batch 4/5700 loss 16.594086 loss_att 16.483662 loss_ctc 24.137722 loss_rnnt 15.610352 lr 0.00079949 rank 2
2022-12-03 19:59:13,630 DEBUG TRAIN Batch 4/5700 loss 21.559601 loss_att 23.320366 loss_ctc 30.302519 loss_rnnt 20.041725 lr 0.00080045 rank 4
2022-12-03 19:59:13,661 DEBUG TRAIN Batch 4/5700 loss 16.269220 loss_att 15.940529 loss_ctc 21.182766 loss_rnnt 15.679818 lr 0.00079998 rank 1
2022-12-03 20:00:25,907 DEBUG TRAIN Batch 4/5800 loss 17.458714 loss_att 30.791475 loss_ctc 30.308365 loss_rnnt 13.078876 lr 0.00079896 rank 1
2022-12-03 20:00:25,915 DEBUG TRAIN Batch 4/5800 loss 16.549408 loss_att 18.076622 loss_ctc 21.911905 loss_rnnt 15.528967 lr 0.00079919 rank 6
2022-12-03 20:00:25,916 DEBUG TRAIN Batch 4/5800 loss 22.045124 loss_att 25.674665 loss_ctc 28.581236 loss_rnnt 20.447735 lr 0.00079881 rank 3
2022-12-03 20:00:25,917 DEBUG TRAIN Batch 4/5800 loss 32.738804 loss_att 42.571316 loss_ctc 48.927155 loss_rnnt 28.613857 lr 0.00079847 rank 2
2022-12-03 20:00:25,917 DEBUG TRAIN Batch 4/5800 loss 20.742611 loss_att 23.525660 loss_ctc 36.397964 loss_rnnt 18.098619 lr 0.00079911 rank 5
2022-12-03 20:00:25,920 DEBUG TRAIN Batch 4/5800 loss 39.931297 loss_att 40.425797 loss_ctc 62.690536 loss_rnnt 36.797832 lr 0.00079889 rank 0
2022-12-03 20:00:25,925 DEBUG TRAIN Batch 4/5800 loss 25.150043 loss_att 29.483887 loss_ctc 38.427940 loss_rnnt 22.512890 lr 0.00079942 rank 4
2022-12-03 20:00:25,963 DEBUG TRAIN Batch 4/5800 loss 15.574956 loss_att 17.944382 loss_ctc 23.447475 loss_rnnt 14.051401 lr 0.00079925 rank 7
2022-12-03 20:01:38,915 DEBUG TRAIN Batch 4/5900 loss 26.681501 loss_att 32.611729 loss_ctc 43.843945 loss_rnnt 23.207129 lr 0.00079809 rank 5
2022-12-03 20:01:38,932 DEBUG TRAIN Batch 4/5900 loss 20.709719 loss_att 27.653429 loss_ctc 33.110912 loss_rnnt 17.667486 lr 0.00079823 rank 7
2022-12-03 20:01:38,933 DEBUG TRAIN Batch 4/5900 loss 27.591309 loss_att 31.196682 loss_ctc 44.154705 loss_rnnt 24.661781 lr 0.00079794 rank 1
2022-12-03 20:01:38,936 DEBUG TRAIN Batch 4/5900 loss 27.237997 loss_att 31.539597 loss_ctc 47.117870 loss_rnnt 23.727026 lr 0.00079817 rank 6
2022-12-03 20:01:38,939 DEBUG TRAIN Batch 4/5900 loss 31.360588 loss_att 35.571251 loss_ctc 45.813229 loss_rnnt 28.591436 lr 0.00079840 rank 4
2022-12-03 20:01:38,940 DEBUG TRAIN Batch 4/5900 loss 26.913115 loss_att 41.521996 loss_ctc 48.479015 loss_rnnt 21.115883 lr 0.00079779 rank 3
2022-12-03 20:01:38,946 DEBUG TRAIN Batch 4/5900 loss 21.079435 loss_att 24.595346 loss_ctc 39.944195 loss_rnnt 17.860952 lr 0.00079787 rank 0
2022-12-03 20:01:38,987 DEBUG TRAIN Batch 4/5900 loss 14.308893 loss_att 18.994867 loss_ctc 22.909168 loss_rnnt 12.224997 lr 0.00079746 rank 2
2022-12-03 20:02:52,274 DEBUG TRAIN Batch 4/6000 loss 31.477448 loss_att 32.480816 loss_ctc 46.140442 loss_rnnt 29.321709 lr 0.00079686 rank 0
2022-12-03 20:02:52,278 DEBUG TRAIN Batch 4/6000 loss 11.844667 loss_att 19.078789 loss_ctc 21.074715 loss_rnnt 9.167170 lr 0.00079721 rank 7
2022-12-03 20:02:52,280 DEBUG TRAIN Batch 4/6000 loss 11.720608 loss_att 17.142241 loss_ctc 20.594082 loss_rnnt 9.453152 lr 0.00079678 rank 3
2022-12-03 20:02:52,282 DEBUG TRAIN Batch 4/6000 loss 24.783154 loss_att 33.054878 loss_ctc 39.372696 loss_rnnt 21.183538 lr 0.00079693 rank 1
2022-12-03 20:02:52,283 DEBUG TRAIN Batch 4/6000 loss 34.672615 loss_att 37.327141 loss_ctc 49.516243 loss_rnnt 32.162560 lr 0.00079715 rank 6
2022-12-03 20:02:52,286 DEBUG TRAIN Batch 4/6000 loss 14.741846 loss_att 23.238073 loss_ctc 23.809864 loss_rnnt 11.833532 lr 0.00079707 rank 5
2022-12-03 20:02:52,288 DEBUG TRAIN Batch 4/6000 loss 31.596106 loss_att 37.423325 loss_ctc 48.699589 loss_rnnt 28.150198 lr 0.00079644 rank 2
2022-12-03 20:02:52,293 DEBUG TRAIN Batch 4/6000 loss 25.743095 loss_att 39.593018 loss_ctc 50.623283 loss_rnnt 19.655750 lr 0.00079739 rank 4
2022-12-03 20:04:05,226 DEBUG TRAIN Batch 4/6100 loss 20.073101 loss_att 22.061701 loss_ctc 26.917473 loss_rnnt 18.762798 lr 0.00079614 rank 6
2022-12-03 20:04:05,231 DEBUG TRAIN Batch 4/6100 loss 27.225468 loss_att 29.388523 loss_ctc 41.654526 loss_rnnt 24.868980 lr 0.00079606 rank 5
2022-12-03 20:04:05,232 DEBUG TRAIN Batch 4/6100 loss 26.973557 loss_att 35.474396 loss_ctc 43.660675 loss_rnnt 23.048439 lr 0.00079544 rank 2
2022-12-03 20:04:05,234 DEBUG TRAIN Batch 4/6100 loss 19.554722 loss_att 28.621502 loss_ctc 30.135063 loss_rnnt 16.330654 lr 0.00079577 rank 3
2022-12-03 20:04:05,235 DEBUG TRAIN Batch 4/6100 loss 26.828182 loss_att 35.620522 loss_ctc 51.943192 loss_rnnt 21.721046 lr 0.00079585 rank 0
2022-12-03 20:04:05,237 DEBUG TRAIN Batch 4/6100 loss 11.841673 loss_att 16.413939 loss_ctc 21.138371 loss_rnnt 9.687659 lr 0.00079592 rank 1
2022-12-03 20:04:05,238 DEBUG TRAIN Batch 4/6100 loss 27.934883 loss_att 31.923531 loss_ctc 43.857399 loss_rnnt 25.014149 lr 0.00079620 rank 7
2022-12-03 20:04:05,244 DEBUG TRAIN Batch 4/6100 loss 21.846453 loss_att 27.001472 loss_ctc 32.253998 loss_rnnt 19.427776 lr 0.00079637 rank 4
2022-12-03 20:05:17,839 DEBUG TRAIN Batch 4/6200 loss 14.064116 loss_att 21.410152 loss_ctc 26.505732 loss_rnnt 10.936026 lr 0.00079513 rank 6
2022-12-03 20:05:17,842 DEBUG TRAIN Batch 4/6200 loss 16.465164 loss_att 19.330088 loss_ctc 24.512808 loss_rnnt 14.819160 lr 0.00079484 rank 0
2022-12-03 20:05:17,843 DEBUG TRAIN Batch 4/6200 loss 15.718445 loss_att 18.824947 loss_ctc 25.784771 loss_rnnt 13.754968 lr 0.00079505 rank 5
2022-12-03 20:05:17,843 DEBUG TRAIN Batch 4/6200 loss 27.570314 loss_att 30.968945 loss_ctc 43.958370 loss_rnnt 24.705513 lr 0.00079491 rank 1
2022-12-03 20:05:17,844 DEBUG TRAIN Batch 4/6200 loss 30.749088 loss_att 30.846846 loss_ctc 41.303173 loss_rnnt 29.322325 lr 0.00079476 rank 3
2022-12-03 20:05:17,845 DEBUG TRAIN Batch 4/6200 loss 19.310356 loss_att 23.733624 loss_ctc 34.897964 loss_rnnt 16.347353 lr 0.00079443 rank 2
2022-12-03 20:05:17,846 DEBUG TRAIN Batch 4/6200 loss 30.564434 loss_att 36.187920 loss_ctc 46.033127 loss_rnnt 27.377243 lr 0.00079519 rank 7
2022-12-03 20:05:17,863 DEBUG TRAIN Batch 4/6200 loss 24.713215 loss_att 33.713112 loss_ctc 36.029083 loss_rnnt 21.404451 lr 0.00079537 rank 4
2022-12-03 20:06:30,179 DEBUG TRAIN Batch 4/6300 loss 31.519176 loss_att 34.520329 loss_ctc 43.218132 loss_rnnt 29.359085 lr 0.00079405 rank 5
2022-12-03 20:06:30,182 DEBUG TRAIN Batch 4/6300 loss 18.971279 loss_att 23.423212 loss_ctc 33.645531 loss_rnnt 16.124325 lr 0.00079376 rank 3
2022-12-03 20:06:30,183 DEBUG TRAIN Batch 4/6300 loss 18.201962 loss_att 20.415251 loss_ctc 31.970325 loss_rnnt 15.923522 lr 0.00079343 rank 2
2022-12-03 20:06:30,184 DEBUG TRAIN Batch 4/6300 loss 20.703226 loss_att 28.812675 loss_ctc 35.823578 loss_rnnt 17.065290 lr 0.00079391 rank 1
2022-12-03 20:06:30,184 DEBUG TRAIN Batch 4/6300 loss 12.511728 loss_att 16.725348 loss_ctc 20.994934 loss_rnnt 10.537910 lr 0.00079419 rank 7
2022-12-03 20:06:30,185 DEBUG TRAIN Batch 4/6300 loss 27.516737 loss_att 30.444553 loss_ctc 40.409374 loss_rnnt 25.212156 lr 0.00079413 rank 6
2022-12-03 20:06:30,187 DEBUG TRAIN Batch 4/6300 loss 12.021896 loss_att 13.547320 loss_ctc 20.852539 loss_rnnt 10.539392 lr 0.00079384 rank 0
2022-12-03 20:06:30,232 DEBUG TRAIN Batch 4/6300 loss 26.352413 loss_att 30.207062 loss_ctc 42.568619 loss_rnnt 23.419323 lr 0.00079436 rank 4
2022-12-03 20:07:45,356 DEBUG TRAIN Batch 4/6400 loss 13.651929 loss_att 17.438839 loss_ctc 23.518131 loss_rnnt 11.579054 lr 0.00079284 rank 0
2022-12-03 20:07:45,361 DEBUG TRAIN Batch 4/6400 loss 9.833937 loss_att 12.859749 loss_ctc 14.955363 loss_rnnt 8.545918 lr 0.00079319 rank 7
2022-12-03 20:07:45,362 DEBUG TRAIN Batch 4/6400 loss 27.078503 loss_att 31.264797 loss_ctc 40.209709 loss_rnnt 24.490416 lr 0.00079313 rank 6
2022-12-03 20:07:45,362 DEBUG TRAIN Batch 4/6400 loss 20.389275 loss_att 17.831448 loss_ctc 26.744928 loss_rnnt 20.053421 lr 0.00079276 rank 3
2022-12-03 20:07:45,367 DEBUG TRAIN Batch 4/6400 loss 25.373547 loss_att 38.761848 loss_ctc 42.037514 loss_rnnt 20.474022 lr 0.00079336 rank 4
2022-12-03 20:07:45,372 DEBUG TRAIN Batch 4/6400 loss 29.885614 loss_att 35.841175 loss_ctc 44.384148 loss_rnnt 26.761364 lr 0.00079243 rank 2
2022-12-03 20:07:45,385 DEBUG TRAIN Batch 4/6400 loss 18.409313 loss_att 26.379272 loss_ctc 30.478842 loss_rnnt 15.206053 lr 0.00079291 rank 1
2022-12-03 20:07:45,393 DEBUG TRAIN Batch 4/6400 loss 21.079376 loss_att 23.429070 loss_ctc 32.722572 loss_rnnt 19.057011 lr 0.00079305 rank 5
2022-12-03 20:08:57,299 DEBUG TRAIN Batch 4/6500 loss 42.813000 loss_att 47.663403 loss_ctc 65.882202 loss_rnnt 38.767029 lr 0.00079177 rank 3
2022-12-03 20:08:57,300 DEBUG TRAIN Batch 4/6500 loss 20.787195 loss_att 26.258816 loss_ctc 37.538631 loss_rnnt 17.459349 lr 0.00079185 rank 0
2022-12-03 20:08:57,301 DEBUG TRAIN Batch 4/6500 loss 10.789708 loss_att 20.673670 loss_ctc 19.423588 loss_rnnt 7.661731 lr 0.00079206 rank 5
2022-12-03 20:08:57,302 DEBUG TRAIN Batch 4/6500 loss 17.222233 loss_att 21.786535 loss_ctc 26.916653 loss_rnnt 15.016783 lr 0.00079144 rank 2
2022-12-03 20:08:57,303 DEBUG TRAIN Batch 4/6500 loss 24.073969 loss_att 33.759865 loss_ctc 39.894329 loss_rnnt 20.027409 lr 0.00079220 rank 7
2022-12-03 20:08:57,306 DEBUG TRAIN Batch 4/6500 loss 23.503275 loss_att 28.740204 loss_ctc 36.443169 loss_rnnt 20.730568 lr 0.00079192 rank 1
2022-12-03 20:08:57,306 DEBUG TRAIN Batch 4/6500 loss 47.679325 loss_att 53.347958 loss_ctc 76.575462 loss_rnnt 42.692780 lr 0.00079236 rank 4
2022-12-03 20:08:57,307 DEBUG TRAIN Batch 4/6500 loss 19.274363 loss_att 28.385746 loss_ctc 38.053337 loss_rnnt 14.948222 lr 0.00079214 rank 6
2022-12-03 20:10:08,775 DEBUG TRAIN Batch 4/6600 loss 33.137051 loss_att 36.598465 loss_ctc 51.314728 loss_rnnt 30.021078 lr 0.00079086 rank 0
2022-12-03 20:10:08,776 DEBUG TRAIN Batch 4/6600 loss 24.139933 loss_att 27.371605 loss_ctc 43.631462 loss_rnnt 20.894726 lr 0.00079114 rank 6
2022-12-03 20:10:08,779 DEBUG TRAIN Batch 4/6600 loss 6.203802 loss_att 10.366104 loss_ctc 9.633170 loss_rnnt 4.914093 lr 0.00079106 rank 5
2022-12-03 20:10:08,784 DEBUG TRAIN Batch 4/6600 loss 21.764679 loss_att 29.944412 loss_ctc 40.614845 loss_rnnt 17.615376 lr 0.00079078 rank 3
2022-12-03 20:10:08,786 DEBUG TRAIN Batch 4/6600 loss 15.919734 loss_att 23.902859 loss_ctc 22.522352 loss_rnnt 13.442760 lr 0.00079045 rank 2
2022-12-03 20:10:08,786 DEBUG TRAIN Batch 4/6600 loss 12.192366 loss_att 16.317606 loss_ctc 22.200247 loss_rnnt 10.032932 lr 0.00079120 rank 7
2022-12-03 20:10:08,788 DEBUG TRAIN Batch 4/6600 loss 19.651762 loss_att 26.156446 loss_ctc 43.468910 loss_rnnt 15.175204 lr 0.00079093 rank 1
2022-12-03 20:10:08,833 DEBUG TRAIN Batch 4/6600 loss 23.106224 loss_att 29.931965 loss_ctc 41.364452 loss_rnnt 19.306646 lr 0.00079137 rank 4
2022-12-03 20:11:21,513 DEBUG TRAIN Batch 4/6700 loss 27.530170 loss_att 33.199654 loss_ctc 37.967422 loss_rnnt 25.004641 lr 0.00078979 rank 3
2022-12-03 20:11:21,525 DEBUG TRAIN Batch 4/6700 loss 22.085815 loss_att 27.577351 loss_ctc 41.117512 loss_rnnt 18.449949 lr 0.00079015 rank 6
2022-12-03 20:11:21,533 DEBUG TRAIN Batch 4/6700 loss 20.885389 loss_att 24.632959 loss_ctc 31.054195 loss_rnnt 18.780033 lr 0.00078987 rank 0
2022-12-03 20:11:21,535 DEBUG TRAIN Batch 4/6700 loss 16.144958 loss_att 23.725746 loss_ctc 32.343189 loss_rnnt 12.469036 lr 0.00078946 rank 2
2022-12-03 20:11:21,535 DEBUG TRAIN Batch 4/6700 loss 11.422575 loss_att 15.252827 loss_ctc 18.570639 loss_rnnt 9.703449 lr 0.00079038 rank 4
2022-12-03 20:11:21,538 DEBUG TRAIN Batch 4/6700 loss 19.942665 loss_att 21.341782 loss_ctc 32.727779 loss_rnnt 17.958160 lr 0.00079021 rank 7
2022-12-03 20:11:21,553 DEBUG TRAIN Batch 4/6700 loss 15.800918 loss_att 21.132393 loss_ctc 28.168465 loss_rnnt 13.085616 lr 0.00078994 rank 1
2022-12-03 20:11:21,553 DEBUG TRAIN Batch 4/6700 loss 25.495262 loss_att 33.695671 loss_ctc 46.545208 loss_rnnt 21.048517 lr 0.00079008 rank 5
2022-12-03 20:12:34,640 DEBUG TRAIN Batch 4/6800 loss 13.592658 loss_att 17.816601 loss_ctc 23.894056 loss_rnnt 11.374349 lr 0.00078888 rank 0
2022-12-03 20:12:34,640 DEBUG TRAIN Batch 4/6800 loss 27.209520 loss_att 30.745152 loss_ctc 40.673752 loss_rnnt 24.707165 lr 0.00078917 rank 6
2022-12-03 20:12:34,641 DEBUG TRAIN Batch 4/6800 loss 17.618187 loss_att 24.582043 loss_ctc 26.231413 loss_rnnt 15.076984 lr 0.00078923 rank 7
2022-12-03 20:12:34,643 DEBUG TRAIN Batch 4/6800 loss 22.958391 loss_att 25.507607 loss_ctc 35.712063 loss_rnnt 20.748058 lr 0.00078881 rank 3
2022-12-03 20:12:34,649 DEBUG TRAIN Batch 4/6800 loss 31.211487 loss_att 34.634537 loss_ctc 52.223740 loss_rnnt 27.725243 lr 0.00078909 rank 5
2022-12-03 20:12:34,652 DEBUG TRAIN Batch 4/6800 loss 22.754910 loss_att 29.318136 loss_ctc 36.411430 loss_rnnt 19.621395 lr 0.00078940 rank 4
2022-12-03 20:12:34,654 DEBUG TRAIN Batch 4/6800 loss 21.945030 loss_att 24.621216 loss_ctc 34.412682 loss_rnnt 19.747440 lr 0.00078848 rank 2
2022-12-03 20:12:34,657 DEBUG TRAIN Batch 4/6800 loss 25.016859 loss_att 29.187967 loss_ctc 41.799469 loss_rnnt 21.944956 lr 0.00078895 rank 1
2022-12-03 20:13:46,289 DEBUG TRAIN Batch 4/6900 loss 13.835349 loss_att 13.977169 loss_ctc 19.816633 loss_rnnt 13.009480 lr 0.00078790 rank 0
2022-12-03 20:13:46,289 DEBUG TRAIN Batch 4/6900 loss 31.218613 loss_att 35.962292 loss_ctc 51.349464 loss_rnnt 27.585762 lr 0.00078819 rank 6
2022-12-03 20:13:46,293 DEBUG TRAIN Batch 4/6900 loss 20.464428 loss_att 21.241537 loss_ctc 32.683636 loss_rnnt 18.679779 lr 0.00078750 rank 2
2022-12-03 20:13:46,293 DEBUG TRAIN Batch 4/6900 loss 12.135978 loss_att 17.014397 loss_ctc 29.385965 loss_rnnt 8.860296 lr 0.00078783 rank 3
2022-12-03 20:13:46,294 DEBUG TRAIN Batch 4/6900 loss 14.902933 loss_att 19.292831 loss_ctc 26.523005 loss_rnnt 12.475610 lr 0.00078797 rank 1
2022-12-03 20:13:46,296 DEBUG TRAIN Batch 4/6900 loss 32.209900 loss_att 37.930595 loss_ctc 48.515865 loss_rnnt 28.891632 lr 0.00078811 rank 5
2022-12-03 20:13:46,300 DEBUG TRAIN Batch 4/6900 loss 15.450351 loss_att 19.912859 loss_ctc 28.026123 loss_rnnt 12.881080 lr 0.00078825 rank 7
2022-12-03 20:13:46,305 DEBUG TRAIN Batch 4/6900 loss 26.160774 loss_att 30.223713 loss_ctc 42.162422 loss_rnnt 23.214636 lr 0.00078841 rank 4
2022-12-03 20:15:00,090 DEBUG TRAIN Batch 4/7000 loss 16.637062 loss_att 22.221497 loss_ctc 30.911818 loss_rnnt 13.616875 lr 0.00078700 rank 1
2022-12-03 20:15:00,099 DEBUG TRAIN Batch 4/7000 loss 14.682144 loss_att 19.011658 loss_ctc 26.679880 loss_rnnt 12.216544 lr 0.00078713 rank 5
2022-12-03 20:15:00,103 DEBUG TRAIN Batch 4/7000 loss 33.444942 loss_att 41.952324 loss_ctc 59.015503 loss_rnnt 28.334057 lr 0.00078693 rank 0
2022-12-03 20:15:00,106 DEBUG TRAIN Batch 4/7000 loss 17.670609 loss_att 21.304388 loss_ctc 26.052382 loss_rnnt 15.826283 lr 0.00078721 rank 6
2022-12-03 20:15:00,108 DEBUG TRAIN Batch 4/7000 loss 13.375104 loss_att 15.336819 loss_ctc 21.467773 loss_rnnt 11.903739 lr 0.00078653 rank 2
2022-12-03 20:15:00,109 DEBUG TRAIN Batch 4/7000 loss 22.629753 loss_att 24.289284 loss_ctc 30.856817 loss_rnnt 21.200905 lr 0.00078685 rank 3
2022-12-03 20:15:00,110 DEBUG TRAIN Batch 4/7000 loss 20.906166 loss_att 23.772615 loss_ctc 30.370066 loss_rnnt 19.071022 lr 0.00078744 rank 4
2022-12-03 20:15:00,156 DEBUG TRAIN Batch 4/7000 loss 26.424587 loss_att 25.841084 loss_ctc 40.456379 loss_rnnt 24.670382 lr 0.00078727 rank 7
2022-12-03 20:16:14,677 DEBUG TRAIN Batch 4/7100 loss 10.848779 loss_att 12.540882 loss_ctc 16.322611 loss_rnnt 9.780514 lr 0.00078630 rank 7
2022-12-03 20:16:14,678 DEBUG TRAIN Batch 4/7100 loss 22.880007 loss_att 31.389156 loss_ctc 39.992393 loss_rnnt 18.896524 lr 0.00078624 rank 6
2022-12-03 20:16:14,683 DEBUG TRAIN Batch 4/7100 loss 19.483435 loss_att 25.635576 loss_ctc 39.246040 loss_rnnt 15.617991 lr 0.00078596 rank 0
2022-12-03 20:16:14,686 DEBUG TRAIN Batch 4/7100 loss 27.994446 loss_att 37.725403 loss_ctc 48.942657 loss_rnnt 23.255157 lr 0.00078616 rank 5
2022-12-03 20:16:14,688 DEBUG TRAIN Batch 4/7100 loss 41.804028 loss_att 45.929756 loss_ctc 58.797783 loss_rnnt 38.713043 lr 0.00078602 rank 1
2022-12-03 20:16:14,690 DEBUG TRAIN Batch 4/7100 loss 20.546492 loss_att 25.587101 loss_ctc 33.333862 loss_rnnt 17.833387 lr 0.00078556 rank 2
2022-12-03 20:16:14,693 DEBUG TRAIN Batch 4/7100 loss 24.457066 loss_att 34.826160 loss_ctc 51.513134 loss_rnnt 18.775770 lr 0.00078646 rank 4
2022-12-03 20:16:14,702 DEBUG TRAIN Batch 4/7100 loss 24.766273 loss_att 29.639603 loss_ctc 41.514240 loss_rnnt 21.558546 lr 0.00078588 rank 3
2022-12-03 20:17:27,445 DEBUG TRAIN Batch 4/7200 loss 21.642735 loss_att 26.518883 loss_ctc 43.749092 loss_rnnt 17.719988 lr 0.00078527 rank 6
2022-12-03 20:17:27,445 DEBUG TRAIN Batch 4/7200 loss 20.724070 loss_att 23.226112 loss_ctc 29.269402 loss_rnnt 19.084282 lr 0.00078505 rank 1
2022-12-03 20:17:27,446 DEBUG TRAIN Batch 4/7200 loss 49.951885 loss_att 42.849003 loss_ctc 74.794952 loss_rnnt 48.060055 lr 0.00078519 rank 5
2022-12-03 20:17:27,447 DEBUG TRAIN Batch 4/7200 loss 35.959385 loss_att 46.614422 loss_ctc 56.882469 loss_rnnt 31.038631 lr 0.00078499 rank 0
2022-12-03 20:17:27,448 DEBUG TRAIN Batch 4/7200 loss 30.491398 loss_att 34.492943 loss_ctc 54.300529 loss_rnnt 26.516537 lr 0.00078459 rank 2
2022-12-03 20:17:27,450 DEBUG TRAIN Batch 4/7200 loss 33.603489 loss_att 46.061039 loss_ctc 53.803814 loss_rnnt 28.418600 lr 0.00078491 rank 3
2022-12-03 20:17:27,450 DEBUG TRAIN Batch 4/7200 loss 21.196890 loss_att 32.801132 loss_ctc 38.082275 loss_rnnt 16.624657 lr 0.00078533 rank 7
2022-12-03 20:17:27,460 DEBUG TRAIN Batch 4/7200 loss 21.749825 loss_att 24.739256 loss_ctc 33.197762 loss_rnnt 19.625547 lr 0.00078549 rank 4
2022-12-03 20:18:39,450 DEBUG TRAIN Batch 4/7300 loss 22.558064 loss_att 25.659805 loss_ctc 38.092117 loss_rnnt 19.866508 lr 0.00078394 rank 3
2022-12-03 20:18:39,452 DEBUG TRAIN Batch 4/7300 loss 14.143824 loss_att 21.923843 loss_ctc 23.347404 loss_rnnt 11.360674 lr 0.00078430 rank 6
2022-12-03 20:18:39,454 DEBUG TRAIN Batch 4/7300 loss 25.556246 loss_att 32.381886 loss_ctc 42.583729 loss_rnnt 21.920788 lr 0.00078402 rank 0
2022-12-03 20:18:39,455 DEBUG TRAIN Batch 4/7300 loss 10.974577 loss_att 14.045870 loss_ctc 17.659214 loss_rnnt 9.469032 lr 0.00078409 rank 1
2022-12-03 20:18:39,456 DEBUG TRAIN Batch 4/7300 loss 23.242392 loss_att 27.144911 loss_ctc 35.256157 loss_rnnt 20.860052 lr 0.00078363 rank 2
2022-12-03 20:18:39,456 DEBUG TRAIN Batch 4/7300 loss 27.397022 loss_att 32.941017 loss_ctc 54.392433 loss_rnnt 22.688835 lr 0.00078422 rank 5
2022-12-03 20:18:39,463 DEBUG TRAIN Batch 4/7300 loss 10.912959 loss_att 18.037727 loss_ctc 19.197403 loss_rnnt 8.383413 lr 0.00078452 rank 4
2022-12-03 20:18:39,470 DEBUG TRAIN Batch 4/7300 loss 25.026209 loss_att 27.438406 loss_ctc 33.078598 loss_rnnt 23.470119 lr 0.00078436 rank 7
2022-12-03 20:19:52,033 DEBUG TRAIN Batch 4/7400 loss 27.361713 loss_att 33.072968 loss_ctc 48.901630 loss_rnnt 23.347473 lr 0.00078334 rank 6
2022-12-03 20:19:52,037 DEBUG TRAIN Batch 4/7400 loss 27.882664 loss_att 30.351873 loss_ctc 49.121712 loss_rnnt 24.556952 lr 0.00078306 rank 0
2022-12-03 20:19:52,038 DEBUG TRAIN Batch 4/7400 loss 13.234582 loss_att 21.701530 loss_ctc 22.270687 loss_rnnt 10.336378 lr 0.00078313 rank 1
2022-12-03 20:19:52,042 DEBUG TRAIN Batch 4/7400 loss 28.318455 loss_att 33.342373 loss_ctc 47.998562 loss_rnnt 24.689655 lr 0.00078298 rank 3
2022-12-03 20:19:52,059 DEBUG TRAIN Batch 4/7400 loss 33.204571 loss_att 38.051380 loss_ctc 47.667053 loss_rnnt 30.306881 lr 0.00078267 rank 2
2022-12-03 20:19:52,074 DEBUG TRAIN Batch 4/7400 loss 19.368160 loss_att 26.763712 loss_ctc 32.481525 loss_rnnt 16.140602 lr 0.00078326 rank 5
2022-12-03 20:19:52,079 DEBUG TRAIN Batch 4/7400 loss 22.200100 loss_att 25.408150 loss_ctc 35.532433 loss_rnnt 19.780846 lr 0.00078340 rank 7
2022-12-03 20:19:52,091 DEBUG TRAIN Batch 4/7400 loss 11.753850 loss_att 17.892864 loss_ctc 19.035801 loss_rnnt 9.555120 lr 0.00078356 rank 4
2022-12-03 20:21:06,244 DEBUG TRAIN Batch 4/7500 loss 25.122875 loss_att 30.736202 loss_ctc 42.326862 loss_rnnt 21.706343 lr 0.00078238 rank 6
2022-12-03 20:21:06,247 DEBUG TRAIN Batch 4/7500 loss 11.974172 loss_att 16.201004 loss_ctc 20.507391 loss_rnnt 9.991042 lr 0.00078210 rank 0
2022-12-03 20:21:06,247 DEBUG TRAIN Batch 4/7500 loss 14.284912 loss_att 18.587978 loss_ctc 28.678928 loss_rnnt 11.505096 lr 0.00078244 rank 7
2022-12-03 20:21:06,247 DEBUG TRAIN Batch 4/7500 loss 12.594645 loss_att 18.716719 loss_ctc 20.683676 loss_rnnt 10.291692 lr 0.00078217 rank 1
2022-12-03 20:21:06,251 DEBUG TRAIN Batch 4/7500 loss 22.976641 loss_att 23.947794 loss_ctc 35.785786 loss_rnnt 21.074524 lr 0.00078202 rank 3
2022-12-03 20:21:06,252 DEBUG TRAIN Batch 4/7500 loss 25.002979 loss_att 27.540844 loss_ctc 39.543388 loss_rnnt 22.556686 lr 0.00078171 rank 2
2022-12-03 20:21:06,261 DEBUG TRAIN Batch 4/7500 loss 23.749269 loss_att 27.436188 loss_ctc 42.101196 loss_rnnt 20.564960 lr 0.00078260 rank 4
2022-12-03 20:21:06,310 DEBUG TRAIN Batch 4/7500 loss 33.180393 loss_att 41.035557 loss_ctc 51.152054 loss_rnnt 29.213139 lr 0.00078230 rank 5
2022-12-03 20:22:18,724 DEBUG TRAIN Batch 4/7600 loss 16.597239 loss_att 19.593431 loss_ctc 27.292128 loss_rnnt 14.572014 lr 0.00078142 rank 6
2022-12-03 20:22:18,727 DEBUG TRAIN Batch 4/7600 loss 18.539455 loss_att 19.892168 loss_ctc 27.541958 loss_rnnt 17.068579 lr 0.00078075 rank 2
2022-12-03 20:22:18,727 DEBUG TRAIN Batch 4/7600 loss 19.974682 loss_att 21.619091 loss_ctc 29.323181 loss_rnnt 18.399332 lr 0.00078164 rank 4
2022-12-03 20:22:18,727 DEBUG TRAIN Batch 4/7600 loss 25.553762 loss_att 29.965836 loss_ctc 41.773354 loss_rnnt 22.508736 lr 0.00078107 rank 3
2022-12-03 20:22:18,728 DEBUG TRAIN Batch 4/7600 loss 8.955706 loss_att 13.057301 loss_ctc 14.045699 loss_rnnt 7.456721 lr 0.00078115 rank 0
2022-12-03 20:22:18,738 DEBUG TRAIN Batch 4/7600 loss 30.687799 loss_att 33.817337 loss_ctc 45.022987 loss_rnnt 28.150532 lr 0.00078135 rank 5
2022-12-03 20:22:18,738 DEBUG TRAIN Batch 4/7600 loss 11.805668 loss_att 15.935124 loss_ctc 21.576542 loss_rnnt 9.676993 lr 0.00078148 rank 7
2022-12-03 20:22:18,770 DEBUG TRAIN Batch 4/7600 loss 14.380501 loss_att 13.927680 loss_ctc 19.401621 loss_rnnt 13.801582 lr 0.00078121 rank 1
2022-12-03 20:23:30,657 DEBUG TRAIN Batch 4/7700 loss 12.421111 loss_att 15.326123 loss_ctc 18.264145 loss_rnnt 11.061037 lr 0.00078047 rank 6
2022-12-03 20:23:30,657 DEBUG TRAIN Batch 4/7700 loss 10.917199 loss_att 11.703115 loss_ctc 15.335676 loss_rnnt 10.170885 lr 0.00078039 rank 5
2022-12-03 20:23:30,658 DEBUG TRAIN Batch 4/7700 loss 24.984087 loss_att 30.183014 loss_ctc 42.809502 loss_rnnt 21.567579 lr 0.00078026 rank 1
2022-12-03 20:23:30,661 DEBUG TRAIN Batch 4/7700 loss 35.111801 loss_att 37.202526 loss_ctc 54.401566 loss_rnnt 32.121689 lr 0.00077980 rank 2
2022-12-03 20:23:30,660 DEBUG TRAIN Batch 4/7700 loss 18.049524 loss_att 21.199612 loss_ctc 32.334332 loss_rnnt 15.514866 lr 0.00078053 rank 7
2022-12-03 20:23:30,662 DEBUG TRAIN Batch 4/7700 loss 26.314667 loss_att 31.742378 loss_ctc 40.148540 loss_rnnt 23.384609 lr 0.00078019 rank 0
2022-12-03 20:23:30,667 DEBUG TRAIN Batch 4/7700 loss 29.872768 loss_att 32.779278 loss_ctc 43.593853 loss_rnnt 27.461987 lr 0.00078012 rank 3
2022-12-03 20:23:30,671 DEBUG TRAIN Batch 4/7700 loss 13.612899 loss_att 18.024601 loss_ctc 19.381598 loss_rnnt 11.961398 lr 0.00078069 rank 4
2022-12-03 20:24:44,544 DEBUG TRAIN Batch 4/7800 loss 16.089397 loss_att 25.047892 loss_ctc 20.209227 loss_rnnt 13.748388 lr 0.00077931 rank 1
2022-12-03 20:24:44,553 DEBUG TRAIN Batch 4/7800 loss 18.920544 loss_att 25.574450 loss_ctc 27.341589 loss_rnnt 16.466955 lr 0.00077944 rank 5
2022-12-03 20:24:44,553 DEBUG TRAIN Batch 4/7800 loss 22.930523 loss_att 30.566162 loss_ctc 44.371895 loss_rnnt 18.544544 lr 0.00077925 rank 0
2022-12-03 20:24:44,556 DEBUG TRAIN Batch 4/7800 loss 11.077744 loss_att 17.767763 loss_ctc 24.869452 loss_rnnt 7.900846 lr 0.00077958 rank 7
2022-12-03 20:24:44,557 DEBUG TRAIN Batch 4/7800 loss 14.104307 loss_att 23.486824 loss_ctc 25.425299 loss_rnnt 10.718338 lr 0.00077952 rank 6
2022-12-03 20:24:44,562 DEBUG TRAIN Batch 4/7800 loss 23.569565 loss_att 25.218376 loss_ctc 33.831219 loss_rnnt 21.871582 lr 0.00077917 rank 3
2022-12-03 20:24:44,564 DEBUG TRAIN Batch 4/7800 loss 20.809137 loss_att 24.746181 loss_ctc 38.715736 loss_rnnt 17.634182 lr 0.00077886 rank 2
2022-12-03 20:24:44,565 DEBUG TRAIN Batch 4/7800 loss 49.619545 loss_att 59.747765 loss_ctc 72.622314 loss_rnnt 44.526867 lr 0.00077974 rank 4
2022-12-03 20:25:56,786 DEBUG TRAIN Batch 4/7900 loss 27.821041 loss_att 32.648422 loss_ctc 42.105728 loss_rnnt 24.950939 lr 0.00077857 rank 6
2022-12-03 20:25:56,790 DEBUG TRAIN Batch 4/7900 loss 16.747740 loss_att 21.609962 loss_ctc 30.398428 loss_rnnt 13.955204 lr 0.00077850 rank 5
2022-12-03 20:25:56,794 DEBUG TRAIN Batch 4/7900 loss 37.084064 loss_att 43.122887 loss_ctc 60.845264 loss_rnnt 32.708141 lr 0.00077879 rank 4
2022-12-03 20:25:56,797 DEBUG TRAIN Batch 4/7900 loss 9.351094 loss_att 14.943308 loss_ctc 14.344154 loss_rnnt 7.566910 lr 0.00077791 rank 2
2022-12-03 20:25:56,797 DEBUG TRAIN Batch 4/7900 loss 16.677895 loss_att 22.015482 loss_ctc 26.228577 loss_rnnt 14.336951 lr 0.00077837 rank 1
2022-12-03 20:25:56,798 DEBUG TRAIN Batch 4/7900 loss 27.389721 loss_att 34.999619 loss_ctc 51.014034 loss_rnnt 22.717833 lr 0.00077823 rank 3
2022-12-03 20:25:56,799 DEBUG TRAIN Batch 4/7900 loss 28.402988 loss_att 36.357643 loss_ctc 42.592484 loss_rnnt 24.920124 lr 0.00077830 rank 0
2022-12-03 20:25:56,845 DEBUG TRAIN Batch 4/7900 loss 5.505211 loss_att 7.941456 loss_ctc 10.063495 loss_rnnt 4.410191 lr 0.00077863 rank 7
2022-12-03 20:27:08,430 DEBUG TRAIN Batch 4/8000 loss 16.928186 loss_att 21.737652 loss_ctc 31.829115 loss_rnnt 13.979502 lr 0.00077763 rank 6
2022-12-03 20:27:08,437 DEBUG TRAIN Batch 4/8000 loss 22.251707 loss_att 25.338577 loss_ctc 39.621346 loss_rnnt 19.318380 lr 0.00077756 rank 5
2022-12-03 20:27:08,438 DEBUG TRAIN Batch 4/8000 loss 65.827568 loss_att 71.844391 loss_ctc 98.922806 loss_rnnt 60.211510 lr 0.00077743 rank 1
2022-12-03 20:27:08,440 DEBUG TRAIN Batch 4/8000 loss 18.929470 loss_att 25.253670 loss_ctc 36.306160 loss_rnnt 15.347736 lr 0.00077736 rank 0
2022-12-03 20:27:08,442 DEBUG TRAIN Batch 4/8000 loss 20.525669 loss_att 25.396353 loss_ctc 31.965109 loss_rnnt 18.026272 lr 0.00077697 rank 2
2022-12-03 20:27:08,443 DEBUG TRAIN Batch 4/8000 loss 15.393754 loss_att 23.750706 loss_ctc 24.972252 loss_rnnt 12.445231 lr 0.00077769 rank 7
2022-12-03 20:27:08,443 DEBUG TRAIN Batch 4/8000 loss 34.679943 loss_att 39.571938 loss_ctc 49.976547 loss_rnnt 31.661995 lr 0.00077728 rank 3
2022-12-03 20:27:08,449 DEBUG TRAIN Batch 4/8000 loss 27.149708 loss_att 34.284317 loss_ctc 42.618786 loss_rnnt 23.660244 lr 0.00077785 rank 4
2022-12-03 20:28:21,272 DEBUG TRAIN Batch 4/8100 loss 53.352364 loss_att 55.161041 loss_ctc 69.374756 loss_rnnt 50.854309 lr 0.00077649 rank 1
2022-12-03 20:28:21,275 DEBUG TRAIN Batch 4/8100 loss 45.082211 loss_att 47.545345 loss_ctc 78.897682 loss_rnnt 40.080856 lr 0.00077604 rank 2
2022-12-03 20:28:21,277 DEBUG TRAIN Batch 4/8100 loss 23.448513 loss_att 26.664425 loss_ctc 44.822208 loss_rnnt 19.955503 lr 0.00077691 rank 4
2022-12-03 20:28:21,280 DEBUG TRAIN Batch 4/8100 loss 28.734194 loss_att 32.208458 loss_ctc 41.641754 loss_rnnt 26.318333 lr 0.00077662 rank 5
2022-12-03 20:28:21,288 DEBUG TRAIN Batch 4/8100 loss 37.330929 loss_att 45.060745 loss_ctc 55.299614 loss_rnnt 33.389141 lr 0.00077675 rank 7
2022-12-03 20:28:21,290 DEBUG TRAIN Batch 4/8100 loss 23.876472 loss_att 25.862354 loss_ctc 38.108746 loss_rnnt 21.581661 lr 0.00077642 rank 0
2022-12-03 20:28:21,290 DEBUG TRAIN Batch 4/8100 loss 18.499704 loss_att 21.616463 loss_ctc 26.536356 loss_rnnt 16.804798 lr 0.00077669 rank 6
2022-12-03 20:28:21,294 DEBUG TRAIN Batch 4/8100 loss 20.435305 loss_att 23.029076 loss_ctc 30.681553 loss_rnnt 18.550385 lr 0.00077635 rank 3
2022-12-03 20:29:34,097 DEBUG TRAIN Batch 4/8200 loss 21.728205 loss_att 23.426559 loss_ctc 32.505775 loss_rnnt 19.951523 lr 0.00077581 rank 7
2022-12-03 20:29:34,110 DEBUG TRAIN Batch 4/8200 loss 26.855818 loss_att 33.763069 loss_ctc 39.925198 loss_rnnt 23.731783 lr 0.00077576 rank 6
2022-12-03 20:29:34,112 DEBUG TRAIN Batch 4/8200 loss 15.814620 loss_att 14.880118 loss_ctc 20.961903 loss_rnnt 15.315216 lr 0.00077549 rank 0
2022-12-03 20:29:34,116 DEBUG TRAIN Batch 4/8200 loss 16.698965 loss_att 21.870686 loss_ctc 25.547268 loss_rnnt 14.484847 lr 0.00077511 rank 2
2022-12-03 20:29:34,121 DEBUG TRAIN Batch 4/8200 loss 16.752663 loss_att 21.764929 loss_ctc 31.999397 loss_rnnt 13.717312 lr 0.00077541 rank 3
2022-12-03 20:29:34,122 DEBUG TRAIN Batch 4/8200 loss 17.591179 loss_att 19.992031 loss_ctc 26.433353 loss_rnnt 15.932053 lr 0.00077568 rank 5
2022-12-03 20:29:34,123 DEBUG TRAIN Batch 4/8200 loss 23.634991 loss_att 26.517593 loss_ctc 35.408073 loss_rnnt 21.488724 lr 0.00077597 rank 4
2022-12-03 20:29:34,167 DEBUG TRAIN Batch 4/8200 loss 18.065912 loss_att 25.657322 loss_ctc 32.060066 loss_rnnt 14.681743 lr 0.00077555 rank 1
2022-12-03 20:30:46,110 DEBUG TRAIN Batch 4/8300 loss 7.822638 loss_att 10.641507 loss_ctc 12.683622 loss_rnnt 6.610733 lr 0.00077475 rank 5
2022-12-03 20:30:46,112 DEBUG TRAIN Batch 4/8300 loss 14.887218 loss_att 17.634789 loss_ctc 22.723278 loss_rnnt 13.292896 lr 0.00077483 rank 6
2022-12-03 20:30:46,113 DEBUG TRAIN Batch 4/8300 loss 17.729555 loss_att 22.297152 loss_ctc 23.678305 loss_rnnt 16.022871 lr 0.00077456 rank 0
2022-12-03 20:30:46,115 DEBUG TRAIN Batch 4/8300 loss 21.760513 loss_att 23.299078 loss_ctc 32.082386 loss_rnnt 20.076551 lr 0.00077488 rank 7
2022-12-03 20:30:46,116 DEBUG TRAIN Batch 4/8300 loss 13.802752 loss_att 20.004017 loss_ctc 25.883533 loss_rnnt 10.951728 lr 0.00077418 rank 2
2022-12-03 20:30:46,117 DEBUG TRAIN Batch 4/8300 loss 25.391935 loss_att 30.263760 loss_ctc 36.211647 loss_rnnt 22.974943 lr 0.00077448 rank 3
2022-12-03 20:30:46,118 DEBUG TRAIN Batch 4/8300 loss 13.121367 loss_att 13.834227 loss_ctc 18.537167 loss_rnnt 12.256689 lr 0.00077462 rank 1
2022-12-03 20:30:46,127 DEBUG TRAIN Batch 4/8300 loss 12.983718 loss_att 17.674768 loss_ctc 22.709862 loss_rnnt 10.748688 lr 0.00077504 rank 4
2022-12-03 20:31:28,727 DEBUG CV Batch 4/0 loss 3.338066 loss_att 3.555976 loss_ctc 6.321056 loss_rnnt 2.896752 history loss 3.214434 rank 2
2022-12-03 20:31:28,729 DEBUG CV Batch 4/0 loss 3.338066 loss_att 3.555976 loss_ctc 6.321056 loss_rnnt 2.896752 history loss 3.214434 rank 4
2022-12-03 20:31:28,731 DEBUG CV Batch 4/0 loss 3.338066 loss_att 3.555976 loss_ctc 6.321056 loss_rnnt 2.896752 history loss 3.214434 rank 6
2022-12-03 20:31:28,733 DEBUG CV Batch 4/0 loss 3.338066 loss_att 3.555976 loss_ctc 6.321056 loss_rnnt 2.896752 history loss 3.214434 rank 5
2022-12-03 20:31:28,738 DEBUG CV Batch 4/0 loss 3.338066 loss_att 3.555976 loss_ctc 6.321056 loss_rnnt 2.896752 history loss 3.214434 rank 3
2022-12-03 20:31:28,738 DEBUG CV Batch 4/0 loss 3.338066 loss_att 3.555976 loss_ctc 6.321056 loss_rnnt 2.896752 history loss 3.214434 rank 1
2022-12-03 20:31:28,739 DEBUG CV Batch 4/0 loss 3.338066 loss_att 3.555976 loss_ctc 6.321056 loss_rnnt 2.896752 history loss 3.214434 rank 7
2022-12-03 20:31:28,752 DEBUG CV Batch 4/0 loss 3.338066 loss_att 3.555976 loss_ctc 6.321056 loss_rnnt 2.896752 history loss 3.214434 rank 0
2022-12-03 20:31:40,032 DEBUG CV Batch 4/100 loss 13.993678 loss_att 13.198488 loss_ctc 23.388838 loss_rnnt 12.900027 history loss 6.522558 rank 5
2022-12-03 20:31:40,066 DEBUG CV Batch 4/100 loss 13.993678 loss_att 13.198488 loss_ctc 23.388838 loss_rnnt 12.900027 history loss 6.522558 rank 1
2022-12-03 20:31:40,137 DEBUG CV Batch 4/100 loss 13.993678 loss_att 13.198488 loss_ctc 23.388838 loss_rnnt 12.900027 history loss 6.522558 rank 4
2022-12-03 20:31:40,276 DEBUG CV Batch 4/100 loss 13.993678 loss_att 13.198488 loss_ctc 23.388838 loss_rnnt 12.900027 history loss 6.522558 rank 7
2022-12-03 20:31:40,394 DEBUG CV Batch 4/100 loss 13.993678 loss_att 13.198488 loss_ctc 23.388838 loss_rnnt 12.900027 history loss 6.522558 rank 0
2022-12-03 20:31:40,442 DEBUG CV Batch 4/100 loss 13.993678 loss_att 13.198488 loss_ctc 23.388838 loss_rnnt 12.900027 history loss 6.522558 rank 6
2022-12-03 20:31:40,443 DEBUG CV Batch 4/100 loss 13.993678 loss_att 13.198488 loss_ctc 23.388838 loss_rnnt 12.900027 history loss 6.522558 rank 3
2022-12-03 20:31:40,474 DEBUG CV Batch 4/100 loss 13.993678 loss_att 13.198488 loss_ctc 23.388838 loss_rnnt 12.900027 history loss 6.522558 rank 2
2022-12-03 20:31:53,310 DEBUG CV Batch 4/200 loss 17.513355 loss_att 22.466431 loss_ctc 27.681154 loss_rnnt 15.167032 history loss 7.234361 rank 1
2022-12-03 20:31:53,488 DEBUG CV Batch 4/200 loss 17.513355 loss_att 22.466431 loss_ctc 27.681154 loss_rnnt 15.167032 history loss 7.234361 rank 5
2022-12-03 20:31:53,852 DEBUG CV Batch 4/200 loss 17.513355 loss_att 22.466431 loss_ctc 27.681154 loss_rnnt 15.167032 history loss 7.234361 rank 7
2022-12-03 20:31:53,955 DEBUG CV Batch 4/200 loss 17.513355 loss_att 22.466431 loss_ctc 27.681154 loss_rnnt 15.167032 history loss 7.234361 rank 2
2022-12-03 20:31:54,259 DEBUG CV Batch 4/200 loss 17.513355 loss_att 22.466431 loss_ctc 27.681154 loss_rnnt 15.167032 history loss 7.234361 rank 3
2022-12-03 20:31:54,263 DEBUG CV Batch 4/200 loss 17.513355 loss_att 22.466431 loss_ctc 27.681154 loss_rnnt 15.167032 history loss 7.234361 rank 0
2022-12-03 20:31:54,406 DEBUG CV Batch 4/200 loss 17.513355 loss_att 22.466431 loss_ctc 27.681154 loss_rnnt 15.167032 history loss 7.234361 rank 6
2022-12-03 20:31:54,511 DEBUG CV Batch 4/200 loss 17.513355 loss_att 22.466431 loss_ctc 27.681154 loss_rnnt 15.167032 history loss 7.234361 rank 4
2022-12-03 20:32:05,166 DEBUG CV Batch 4/300 loss 8.617378 loss_att 10.222727 loss_ctc 16.558723 loss_rnnt 7.237462 history loss 7.343517 rank 1
2022-12-03 20:32:05,451 DEBUG CV Batch 4/300 loss 8.617378 loss_att 10.222727 loss_ctc 16.558723 loss_rnnt 7.237462 history loss 7.343517 rank 5
2022-12-03 20:32:05,937 DEBUG CV Batch 4/300 loss 8.617378 loss_att 10.222727 loss_ctc 16.558723 loss_rnnt 7.237462 history loss 7.343517 rank 7
2022-12-03 20:32:06,088 DEBUG CV Batch 4/300 loss 8.617378 loss_att 10.222727 loss_ctc 16.558723 loss_rnnt 7.237462 history loss 7.343517 rank 2
2022-12-03 20:32:06,714 DEBUG CV Batch 4/300 loss 8.617378 loss_att 10.222727 loss_ctc 16.558723 loss_rnnt 7.237462 history loss 7.343517 rank 3
2022-12-03 20:32:06,842 DEBUG CV Batch 4/300 loss 8.617378 loss_att 10.222727 loss_ctc 16.558723 loss_rnnt 7.237462 history loss 7.343517 rank 6
2022-12-03 20:32:06,857 DEBUG CV Batch 4/300 loss 8.617378 loss_att 10.222727 loss_ctc 16.558723 loss_rnnt 7.237462 history loss 7.343517 rank 0
2022-12-03 20:32:07,153 DEBUG CV Batch 4/300 loss 8.617378 loss_att 10.222727 loss_ctc 16.558723 loss_rnnt 7.237462 history loss 7.343517 rank 4
2022-12-03 20:32:17,105 DEBUG CV Batch 4/400 loss 26.766409 loss_att 72.605270 loss_ctc 30.100468 loss_rnnt 17.154095 history loss 8.471008 rank 1
2022-12-03 20:32:17,867 DEBUG CV Batch 4/400 loss 26.766409 loss_att 72.605270 loss_ctc 30.100468 loss_rnnt 17.154095 history loss 8.471008 rank 5
2022-12-03 20:32:18,129 DEBUG CV Batch 4/400 loss 26.766409 loss_att 72.605270 loss_ctc 30.100468 loss_rnnt 17.154095 history loss 8.471008 rank 2
2022-12-03 20:32:18,137 DEBUG CV Batch 4/400 loss 26.766409 loss_att 72.605270 loss_ctc 30.100468 loss_rnnt 17.154095 history loss 8.471008 rank 7
2022-12-03 20:32:19,050 DEBUG CV Batch 4/400 loss 26.766409 loss_att 72.605270 loss_ctc 30.100468 loss_rnnt 17.154095 history loss 8.471008 rank 6
2022-12-03 20:32:19,111 DEBUG CV Batch 4/400 loss 26.766409 loss_att 72.605270 loss_ctc 30.100468 loss_rnnt 17.154095 history loss 8.471008 rank 3
2022-12-03 20:32:19,175 DEBUG CV Batch 4/400 loss 26.766409 loss_att 72.605270 loss_ctc 30.100468 loss_rnnt 17.154095 history loss 8.471008 rank 4
2022-12-03 20:32:19,452 DEBUG CV Batch 4/400 loss 26.766409 loss_att 72.605270 loss_ctc 30.100468 loss_rnnt 17.154095 history loss 8.471008 rank 0
2022-12-03 20:32:27,233 DEBUG CV Batch 4/500 loss 11.484842 loss_att 11.501471 loss_ctc 18.549292 loss_rnnt 10.539590 history loss 9.414766 rank 1
2022-12-03 20:32:28,350 DEBUG CV Batch 4/500 loss 11.484842 loss_att 11.501471 loss_ctc 18.549292 loss_rnnt 10.539590 history loss 9.414766 rank 5
2022-12-03 20:32:28,618 DEBUG CV Batch 4/500 loss 11.484842 loss_att 11.501471 loss_ctc 18.549292 loss_rnnt 10.539590 history loss 9.414766 rank 2
2022-12-03 20:32:28,675 DEBUG CV Batch 4/500 loss 11.484842 loss_att 11.501471 loss_ctc 18.549292 loss_rnnt 10.539590 history loss 9.414766 rank 7
2022-12-03 20:32:29,631 DEBUG CV Batch 4/500 loss 11.484842 loss_att 11.501471 loss_ctc 18.549292 loss_rnnt 10.539590 history loss 9.414766 rank 6
2022-12-03 20:32:29,979 DEBUG CV Batch 4/500 loss 11.484842 loss_att 11.501471 loss_ctc 18.549292 loss_rnnt 10.539590 history loss 9.414766 rank 3
2022-12-03 20:32:29,991 DEBUG CV Batch 4/500 loss 11.484842 loss_att 11.501471 loss_ctc 18.549292 loss_rnnt 10.539590 history loss 9.414766 rank 4
2022-12-03 20:32:30,445 DEBUG CV Batch 4/500 loss 11.484842 loss_att 11.501471 loss_ctc 18.549292 loss_rnnt 10.539590 history loss 9.414766 rank 0
2022-12-03 20:32:39,254 DEBUG CV Batch 4/600 loss 9.305560 loss_att 10.471647 loss_ctc 14.682521 loss_rnnt 8.355414 history loss 10.511941 rank 1
2022-12-03 20:32:40,465 DEBUG CV Batch 4/600 loss 9.305560 loss_att 10.471647 loss_ctc 14.682521 loss_rnnt 8.355414 history loss 10.511941 rank 5
2022-12-03 20:32:40,872 DEBUG CV Batch 4/600 loss 9.305560 loss_att 10.471647 loss_ctc 14.682521 loss_rnnt 8.355414 history loss 10.511941 rank 2
2022-12-03 20:32:41,320 DEBUG CV Batch 4/600 loss 9.305560 loss_att 10.471647 loss_ctc 14.682521 loss_rnnt 8.355414 history loss 10.511941 rank 7
2022-12-03 20:32:41,989 DEBUG CV Batch 4/600 loss 9.305560 loss_att 10.471647 loss_ctc 14.682521 loss_rnnt 8.355414 history loss 10.511941 rank 4
2022-12-03 20:32:42,069 DEBUG CV Batch 4/600 loss 9.305560 loss_att 10.471647 loss_ctc 14.682521 loss_rnnt 8.355414 history loss 10.511941 rank 6
2022-12-03 20:32:42,550 DEBUG CV Batch 4/600 loss 9.305560 loss_att 10.471647 loss_ctc 14.682521 loss_rnnt 8.355414 history loss 10.511941 rank 3
2022-12-03 20:32:43,032 DEBUG CV Batch 4/600 loss 9.305560 loss_att 10.471647 loss_ctc 14.682521 loss_rnnt 8.355414 history loss 10.511941 rank 0
2022-12-03 20:32:50,421 DEBUG CV Batch 4/700 loss 33.162670 loss_att 68.916214 loss_ctc 46.429008 loss_rnnt 24.243116 history loss 11.332705 rank 1
2022-12-03 20:32:51,702 DEBUG CV Batch 4/700 loss 33.162670 loss_att 68.916214 loss_ctc 46.429008 loss_rnnt 24.243116 history loss 11.332705 rank 5
2022-12-03 20:32:52,811 DEBUG CV Batch 4/700 loss 33.162670 loss_att 68.916214 loss_ctc 46.429008 loss_rnnt 24.243116 history loss 11.332705 rank 2
2022-12-03 20:32:53,307 DEBUG CV Batch 4/700 loss 33.162670 loss_att 68.916214 loss_ctc 46.429008 loss_rnnt 24.243116 history loss 11.332705 rank 4
2022-12-03 20:32:53,407 DEBUG CV Batch 4/700 loss 33.162670 loss_att 68.916214 loss_ctc 46.429008 loss_rnnt 24.243116 history loss 11.332705 rank 7
2022-12-03 20:32:53,590 DEBUG CV Batch 4/700 loss 33.162670 loss_att 68.916214 loss_ctc 46.429008 loss_rnnt 24.243116 history loss 11.332705 rank 6
2022-12-03 20:32:54,351 DEBUG CV Batch 4/700 loss 33.162670 loss_att 68.916214 loss_ctc 46.429008 loss_rnnt 24.243116 history loss 11.332705 rank 3
2022-12-03 20:32:54,862 DEBUG CV Batch 4/700 loss 33.162670 loss_att 68.916214 loss_ctc 46.429008 loss_rnnt 24.243116 history loss 11.332705 rank 0
2022-12-03 20:33:01,823 DEBUG CV Batch 4/800 loss 15.172294 loss_att 14.328799 loss_ctc 25.645048 loss_rnnt 13.944626 history loss 10.678225 rank 1
2022-12-03 20:33:02,740 DEBUG CV Batch 4/800 loss 15.172294 loss_att 14.328799 loss_ctc 25.645048 loss_rnnt 13.944626 history loss 10.678225 rank 5
2022-12-03 20:33:04,655 DEBUG CV Batch 4/800 loss 15.172294 loss_att 14.328799 loss_ctc 25.645048 loss_rnnt 13.944626 history loss 10.678225 rank 7
2022-12-03 20:33:04,847 DEBUG CV Batch 4/800 loss 15.172294 loss_att 14.328799 loss_ctc 25.645048 loss_rnnt 13.944626 history loss 10.678225 rank 4
2022-12-03 20:33:04,963 DEBUG CV Batch 4/800 loss 15.172294 loss_att 14.328799 loss_ctc 25.645048 loss_rnnt 13.944626 history loss 10.678225 rank 2
2022-12-03 20:33:05,354 DEBUG CV Batch 4/800 loss 15.172294 loss_att 14.328799 loss_ctc 25.645048 loss_rnnt 13.944626 history loss 10.678225 rank 6
2022-12-03 20:33:06,062 DEBUG CV Batch 4/800 loss 15.172294 loss_att 14.328799 loss_ctc 25.645048 loss_rnnt 13.944626 history loss 10.678225 rank 3
2022-12-03 20:33:06,615 DEBUG CV Batch 4/800 loss 15.172294 loss_att 14.328799 loss_ctc 25.645048 loss_rnnt 13.944626 history loss 10.678225 rank 0
2022-12-03 20:33:15,307 DEBUG CV Batch 4/900 loss 20.438324 loss_att 28.837593 loss_ctc 30.317303 loss_rnnt 17.441273 history loss 10.452064 rank 1
2022-12-03 20:33:16,251 DEBUG CV Batch 4/900 loss 20.438324 loss_att 28.837593 loss_ctc 30.317303 loss_rnnt 17.441273 history loss 10.452064 rank 5
2022-12-03 20:33:18,230 DEBUG CV Batch 4/900 loss 20.438324 loss_att 28.837593 loss_ctc 30.317303 loss_rnnt 17.441273 history loss 10.452064 rank 7
2022-12-03 20:33:18,498 DEBUG CV Batch 4/900 loss 20.438324 loss_att 28.837593 loss_ctc 30.317303 loss_rnnt 17.441273 history loss 10.452064 rank 4
2022-12-03 20:33:18,984 DEBUG CV Batch 4/900 loss 20.438324 loss_att 28.837593 loss_ctc 30.317303 loss_rnnt 17.441273 history loss 10.452064 rank 2
2022-12-03 20:33:19,057 DEBUG CV Batch 4/900 loss 20.438324 loss_att 28.837593 loss_ctc 30.317303 loss_rnnt 17.441273 history loss 10.452064 rank 6
2022-12-03 20:33:19,813 DEBUG CV Batch 4/900 loss 20.438324 loss_att 28.837593 loss_ctc 30.317303 loss_rnnt 17.441273 history loss 10.452064 rank 3
2022-12-03 20:33:20,458 DEBUG CV Batch 4/900 loss 20.438324 loss_att 28.837593 loss_ctc 30.317303 loss_rnnt 17.441273 history loss 10.452064 rank 0
2022-12-03 20:33:27,267 DEBUG CV Batch 4/1000 loss 7.813470 loss_att 7.986260 loss_ctc 12.262318 loss_rnnt 7.185733 history loss 10.161067 rank 1
2022-12-03 20:33:28,578 DEBUG CV Batch 4/1000 loss 7.813470 loss_att 7.986260 loss_ctc 12.262318 loss_rnnt 7.185733 history loss 10.161067 rank 5
2022-12-03 20:33:30,816 DEBUG CV Batch 4/1000 loss 7.813470 loss_att 7.986260 loss_ctc 12.262318 loss_rnnt 7.185733 history loss 10.161067 rank 7
2022-12-03 20:33:31,053 DEBUG CV Batch 4/1000 loss 7.813470 loss_att 7.986260 loss_ctc 12.262318 loss_rnnt 7.185733 history loss 10.161067 rank 4
2022-12-03 20:33:31,259 DEBUG CV Batch 4/1000 loss 7.813470 loss_att 7.986260 loss_ctc 12.262318 loss_rnnt 7.185733 history loss 10.161067 rank 2
2022-12-03 20:33:31,364 DEBUG CV Batch 4/1000 loss 7.813470 loss_att 7.986260 loss_ctc 12.262318 loss_rnnt 7.185733 history loss 10.161067 rank 6
2022-12-03 20:33:32,468 DEBUG CV Batch 4/1000 loss 7.813470 loss_att 7.986260 loss_ctc 12.262318 loss_rnnt 7.185733 history loss 10.161067 rank 3
2022-12-03 20:33:33,284 DEBUG CV Batch 4/1000 loss 7.813470 loss_att 7.986260 loss_ctc 12.262318 loss_rnnt 7.185733 history loss 10.161067 rank 0
2022-12-03 20:33:39,561 DEBUG CV Batch 4/1100 loss 7.638451 loss_att 7.604986 loss_ctc 12.322371 loss_rnnt 7.020620 history loss 10.139417 rank 1
2022-12-03 20:33:40,763 DEBUG CV Batch 4/1100 loss 7.638451 loss_att 7.604986 loss_ctc 12.322371 loss_rnnt 7.020620 history loss 10.139417 rank 5
2022-12-03 20:33:42,919 DEBUG CV Batch 4/1100 loss 7.638451 loss_att 7.604986 loss_ctc 12.322371 loss_rnnt 7.020620 history loss 10.139417 rank 4
2022-12-03 20:33:42,971 DEBUG CV Batch 4/1100 loss 7.638451 loss_att 7.604986 loss_ctc 12.322371 loss_rnnt 7.020620 history loss 10.139417 rank 7
2022-12-03 20:33:43,418 DEBUG CV Batch 4/1100 loss 7.638451 loss_att 7.604986 loss_ctc 12.322371 loss_rnnt 7.020620 history loss 10.139417 rank 2
2022-12-03 20:33:43,712 DEBUG CV Batch 4/1100 loss 7.638451 loss_att 7.604986 loss_ctc 12.322371 loss_rnnt 7.020620 history loss 10.139417 rank 6
2022-12-03 20:33:44,961 DEBUG CV Batch 4/1100 loss 7.638451 loss_att 7.604986 loss_ctc 12.322371 loss_rnnt 7.020620 history loss 10.139417 rank 3
2022-12-03 20:33:45,791 DEBUG CV Batch 4/1100 loss 7.638451 loss_att 7.604986 loss_ctc 12.322371 loss_rnnt 7.020620 history loss 10.139417 rank 0
2022-12-03 20:33:49,987 DEBUG CV Batch 4/1200 loss 14.146730 loss_att 13.955973 loss_ctc 16.920862 loss_rnnt 13.814997 history loss 10.534024 rank 1
2022-12-03 20:33:51,247 DEBUG CV Batch 4/1200 loss 14.146730 loss_att 13.955973 loss_ctc 16.920862 loss_rnnt 13.814997 history loss 10.534024 rank 5
2022-12-03 20:33:53,381 DEBUG CV Batch 4/1200 loss 14.146730 loss_att 13.955973 loss_ctc 16.920862 loss_rnnt 13.814997 history loss 10.534024 rank 4
2022-12-03 20:33:53,993 DEBUG CV Batch 4/1200 loss 14.146730 loss_att 13.955973 loss_ctc 16.920862 loss_rnnt 13.814997 history loss 10.534024 rank 7
2022-12-03 20:33:54,002 DEBUG CV Batch 4/1200 loss 14.146730 loss_att 13.955973 loss_ctc 16.920862 loss_rnnt 13.814997 history loss 10.534024 rank 2
2022-12-03 20:33:54,405 DEBUG CV Batch 4/1200 loss 14.146730 loss_att 13.955973 loss_ctc 16.920862 loss_rnnt 13.814997 history loss 10.534024 rank 6
2022-12-03 20:33:56,096 DEBUG CV Batch 4/1200 loss 14.146730 loss_att 13.955973 loss_ctc 16.920862 loss_rnnt 13.814997 history loss 10.534024 rank 3
2022-12-03 20:33:57,149 DEBUG CV Batch 4/1200 loss 14.146730 loss_att 13.955973 loss_ctc 16.920862 loss_rnnt 13.814997 history loss 10.534024 rank 0
2022-12-03 20:34:01,856 DEBUG CV Batch 4/1300 loss 7.796264 loss_att 8.297584 loss_ctc 13.136814 loss_rnnt 6.983927 history loss 10.880546 rank 1
2022-12-03 20:34:03,457 DEBUG CV Batch 4/1300 loss 7.796264 loss_att 8.297584 loss_ctc 13.136814 loss_rnnt 6.983927 history loss 10.880546 rank 5
2022-12-03 20:34:05,511 DEBUG CV Batch 4/1300 loss 7.796264 loss_att 8.297584 loss_ctc 13.136814 loss_rnnt 6.983927 history loss 10.880546 rank 4
2022-12-03 20:34:06,159 DEBUG CV Batch 4/1300 loss 7.796264 loss_att 8.297584 loss_ctc 13.136814 loss_rnnt 6.983927 history loss 10.880546 rank 7
2022-12-03 20:34:06,194 DEBUG CV Batch 4/1300 loss 7.796264 loss_att 8.297584 loss_ctc 13.136814 loss_rnnt 6.983927 history loss 10.880546 rank 2
2022-12-03 20:34:06,645 DEBUG CV Batch 4/1300 loss 7.796264 loss_att 8.297584 loss_ctc 13.136814 loss_rnnt 6.983927 history loss 10.880546 rank 6
2022-12-03 20:34:08,600 DEBUG CV Batch 4/1300 loss 7.796264 loss_att 8.297584 loss_ctc 13.136814 loss_rnnt 6.983927 history loss 10.880546 rank 3
2022-12-03 20:34:09,701 DEBUG CV Batch 4/1300 loss 7.796264 loss_att 8.297584 loss_ctc 13.136814 loss_rnnt 6.983927 history loss 10.880546 rank 0
2022-12-03 20:34:12,926 DEBUG CV Batch 4/1400 loss 12.035082 loss_att 29.904884 loss_ctc 23.007177 loss_rnnt 6.998174 history loss 11.287253 rank 1
2022-12-03 20:34:14,993 DEBUG CV Batch 4/1400 loss 12.035082 loss_att 29.904884 loss_ctc 23.007177 loss_rnnt 6.998174 history loss 11.287253 rank 5
2022-12-03 20:34:17,102 DEBUG CV Batch 4/1400 loss 12.035082 loss_att 29.904884 loss_ctc 23.007177 loss_rnnt 6.998174 history loss 11.287253 rank 4
2022-12-03 20:34:17,452 DEBUG CV Batch 4/1400 loss 12.035082 loss_att 29.904884 loss_ctc 23.007177 loss_rnnt 6.998174 history loss 11.287253 rank 2
2022-12-03 20:34:18,115 DEBUG CV Batch 4/1400 loss 12.035082 loss_att 29.904884 loss_ctc 23.007177 loss_rnnt 6.998174 history loss 11.287253 rank 7
2022-12-03 20:34:18,123 DEBUG CV Batch 4/1400 loss 12.035082 loss_att 29.904884 loss_ctc 23.007177 loss_rnnt 6.998174 history loss 11.287253 rank 6
2022-12-03 20:34:20,442 DEBUG CV Batch 4/1400 loss 12.035082 loss_att 29.904884 loss_ctc 23.007177 loss_rnnt 6.998174 history loss 11.287253 rank 3
2022-12-03 20:34:21,537 DEBUG CV Batch 4/1400 loss 12.035082 loss_att 29.904884 loss_ctc 23.007177 loss_rnnt 6.998174 history loss 11.287253 rank 0
2022-12-03 20:34:24,425 DEBUG CV Batch 4/1500 loss 13.144400 loss_att 14.907242 loss_ctc 18.478682 loss_rnnt 12.080595 history loss 11.053952 rank 1
2022-12-03 20:34:26,221 DEBUG CV Batch 4/1500 loss 13.144400 loss_att 14.907242 loss_ctc 18.478682 loss_rnnt 12.080595 history loss 11.053952 rank 5
2022-12-03 20:34:29,253 DEBUG CV Batch 4/1500 loss 13.144400 loss_att 14.907242 loss_ctc 18.478682 loss_rnnt 12.080595 history loss 11.053952 rank 2
2022-12-03 20:34:29,503 DEBUG CV Batch 4/1500 loss 13.144400 loss_att 14.907242 loss_ctc 18.478682 loss_rnnt 12.080595 history loss 11.053952 rank 4
2022-12-03 20:34:29,992 DEBUG CV Batch 4/1500 loss 13.144400 loss_att 14.907242 loss_ctc 18.478682 loss_rnnt 12.080595 history loss 11.053952 rank 7
2022-12-03 20:34:30,088 DEBUG CV Batch 4/1500 loss 13.144400 loss_att 14.907242 loss_ctc 18.478682 loss_rnnt 12.080595 history loss 11.053952 rank 6
2022-12-03 20:34:32,667 DEBUG CV Batch 4/1500 loss 13.144400 loss_att 14.907242 loss_ctc 18.478682 loss_rnnt 12.080595 history loss 11.053952 rank 3
2022-12-03 20:34:33,664 DEBUG CV Batch 4/1500 loss 13.144400 loss_att 14.907242 loss_ctc 18.478682 loss_rnnt 12.080595 history loss 11.053952 rank 0
2022-12-03 20:34:37,606 DEBUG CV Batch 4/1600 loss 11.716647 loss_att 18.860844 loss_ctc 23.153625 loss_rnnt 8.762877 history loss 10.958448 rank 1
2022-12-03 20:34:39,392 DEBUG CV Batch 4/1600 loss 11.716647 loss_att 18.860844 loss_ctc 23.153625 loss_rnnt 8.762877 history loss 10.958448 rank 5
2022-12-03 20:34:42,679 DEBUG CV Batch 4/1600 loss 11.716647 loss_att 18.860844 loss_ctc 23.153625 loss_rnnt 8.762877 history loss 10.958448 rank 2
2022-12-03 20:34:43,288 DEBUG CV Batch 4/1600 loss 11.716647 loss_att 18.860844 loss_ctc 23.153625 loss_rnnt 8.762877 history loss 10.958448 rank 4
2022-12-03 20:34:43,429 DEBUG CV Batch 4/1600 loss 11.716647 loss_att 18.860844 loss_ctc 23.153625 loss_rnnt 8.762877 history loss 10.958448 rank 7
2022-12-03 20:34:43,592 DEBUG CV Batch 4/1600 loss 11.716647 loss_att 18.860844 loss_ctc 23.153625 loss_rnnt 8.762877 history loss 10.958448 rank 6
2022-12-03 20:34:46,270 DEBUG CV Batch 4/1600 loss 11.716647 loss_att 18.860844 loss_ctc 23.153625 loss_rnnt 8.762877 history loss 10.958448 rank 3
2022-12-03 20:34:47,241 DEBUG CV Batch 4/1600 loss 11.716647 loss_att 18.860844 loss_ctc 23.153625 loss_rnnt 8.762877 history loss 10.958448 rank 0
2022-12-03 20:34:50,136 DEBUG CV Batch 4/1700 loss 15.417319 loss_att 14.979236 loss_ctc 25.062199 loss_rnnt 14.218952 history loss 10.815788 rank 1
2022-12-03 20:34:52,002 DEBUG CV Batch 4/1700 loss 15.417319 loss_att 14.979236 loss_ctc 25.062199 loss_rnnt 14.218952 history loss 10.815788 rank 5
2022-12-03 20:34:55,378 DEBUG CV Batch 4/1700 loss 15.417319 loss_att 14.979236 loss_ctc 25.062199 loss_rnnt 14.218952 history loss 10.815788 rank 2
2022-12-03 20:34:56,077 DEBUG CV Batch 4/1700 loss 15.417319 loss_att 14.979236 loss_ctc 25.062199 loss_rnnt 14.218952 history loss 10.815788 rank 4
2022-12-03 20:34:56,153 DEBUG CV Batch 4/1700 loss 15.417319 loss_att 14.979236 loss_ctc 25.062199 loss_rnnt 14.218952 history loss 10.815788 rank 6
2022-12-03 20:34:56,669 DEBUG CV Batch 4/1700 loss 15.417319 loss_att 14.979236 loss_ctc 25.062199 loss_rnnt 14.218952 history loss 10.815788 rank 7
2022-12-03 20:34:58,814 DEBUG CV Batch 4/1700 loss 15.417319 loss_att 14.979236 loss_ctc 25.062199 loss_rnnt 14.218952 history loss 10.815788 rank 3
2022-12-03 20:34:59,521 INFO Epoch 4 CV info cv_loss 10.771700637958043
2022-12-03 20:34:59,522 INFO Epoch 5 TRAIN info lr 0.0007742777325031314
2022-12-03 20:34:59,526 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 20:34:59,795 DEBUG CV Batch 4/1700 loss 15.417319 loss_att 14.979236 loss_ctc 25.062199 loss_rnnt 14.218952 history loss 10.815788 rank 0
2022-12-03 20:35:01,414 INFO Epoch 4 CV info cv_loss 10.771700637958043
2022-12-03 20:35:01,415 INFO Epoch 5 TRAIN info lr 0.0007744541827794007
2022-12-03 20:35:01,420 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 20:35:04,872 INFO Epoch 4 CV info cv_loss 10.771700637958043
2022-12-03 20:35:04,872 INFO Epoch 5 TRAIN info lr 0.0007737861658211832
2022-12-03 20:35:04,874 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 20:35:05,249 INFO Epoch 4 CV info cv_loss 10.771700637958043
2022-12-03 20:35:05,250 INFO Epoch 5 TRAIN info lr 0.0007745842759922126
2022-12-03 20:35:05,251 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 20:35:05,480 INFO Epoch 4 CV info cv_loss 10.771700637958043
2022-12-03 20:35:05,481 INFO Epoch 5 TRAIN info lr 0.0007746400502990038
2022-12-03 20:35:05,483 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 20:35:05,845 INFO Epoch 4 CV info cv_loss 10.771700637958043
2022-12-03 20:35:05,845 INFO Epoch 5 TRAIN info lr 0.0007746493471882033
2022-12-03 20:35:05,850 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 20:35:08,155 INFO Epoch 4 CV info cv_loss 10.771700637958043
2022-12-03 20:35:08,155 INFO Epoch 5 TRAIN info lr 0.0007742034737231392
2022-12-03 20:35:08,157 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 20:35:09,216 INFO Epoch 4 CV info cv_loss 10.771700637958043
2022-12-03 20:35:09,217 INFO Checkpoint: save to checkpoint exp/1202_encoder_bias_30_0.1/4.pt
2022-12-03 20:35:09,811 INFO Epoch 5 TRAIN info lr 0.0007740828487617071
2022-12-03 20:35:09,815 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 20:36:08,708 DEBUG TRAIN Batch 5/0 loss 14.716103 loss_att 14.896062 loss_ctc 20.849548 loss_rnnt 13.862318 lr 0.00077463 rank 6
2022-12-03 20:36:08,711 DEBUG TRAIN Batch 5/0 loss 10.184484 loss_att 10.146880 loss_ctc 13.936935 loss_rnnt 9.691678 lr 0.00077427 rank 1
2022-12-03 20:36:08,712 DEBUG TRAIN Batch 5/0 loss 11.739149 loss_att 11.682470 loss_ctc 16.059498 loss_rnnt 11.174438 lr 0.00077464 rank 7
2022-12-03 20:36:08,718 DEBUG TRAIN Batch 5/0 loss 12.360323 loss_att 12.334051 loss_ctc 17.110722 loss_rnnt 11.732190 lr 0.00077457 rank 4
2022-12-03 20:36:08,720 DEBUG TRAIN Batch 5/0 loss 10.852507 loss_att 10.545185 loss_ctc 16.292269 loss_rnnt 10.188670 lr 0.00077444 rank 5
2022-12-03 20:36:08,727 DEBUG TRAIN Batch 5/0 loss 11.162825 loss_att 10.885130 loss_ctc 13.515824 loss_rnnt 10.904630 lr 0.00077378 rank 2
2022-12-03 20:36:08,739 DEBUG TRAIN Batch 5/0 loss 11.402730 loss_att 12.233107 loss_ctc 16.336756 loss_rnnt 10.578785 lr 0.00077407 rank 0
2022-12-03 20:36:08,764 DEBUG TRAIN Batch 5/0 loss 12.649883 loss_att 13.770076 loss_ctc 18.972691 loss_rnnt 11.582803 lr 0.00077419 rank 3
2022-12-03 20:37:19,521 DEBUG TRAIN Batch 5/100 loss 5.442352 loss_att 8.596678 loss_ctc 10.534578 loss_rnnt 4.132524 lr 0.00077370 rank 6
2022-12-03 20:37:19,522 DEBUG TRAIN Batch 5/100 loss 28.885864 loss_att 39.179005 loss_ctc 49.185600 loss_rnnt 24.120605 lr 0.00077352 rank 5
2022-12-03 20:37:19,526 DEBUG TRAIN Batch 5/100 loss 31.000834 loss_att 39.776295 loss_ctc 59.150879 loss_rnnt 25.492401 lr 0.00077327 rank 3
2022-12-03 20:37:19,528 DEBUG TRAIN Batch 5/100 loss 23.374296 loss_att 31.829479 loss_ctc 32.028549 loss_rnnt 20.529360 lr 0.00077315 rank 0
2022-12-03 20:37:19,529 DEBUG TRAIN Batch 5/100 loss 19.949532 loss_att 29.279339 loss_ctc 32.313107 loss_rnnt 16.435093 lr 0.00077334 rank 1
2022-12-03 20:37:19,531 DEBUG TRAIN Batch 5/100 loss 20.285278 loss_att 26.763617 loss_ctc 44.086559 loss_rnnt 15.816107 lr 0.00077285 rank 2
2022-12-03 20:37:19,533 DEBUG TRAIN Batch 5/100 loss 18.280590 loss_att 26.149513 loss_ctc 34.923309 loss_rnnt 14.487774 lr 0.00077371 rank 7
2022-12-03 20:37:19,538 DEBUG TRAIN Batch 5/100 loss 12.204374 loss_att 16.947012 loss_ctc 15.107738 loss_rnnt 10.868731 lr 0.00077365 rank 4
2022-12-03 20:38:31,378 DEBUG TRAIN Batch 5/200 loss 7.488676 loss_att 12.215330 loss_ctc 13.729956 loss_rnnt 5.711174 lr 0.00077278 rank 6
2022-12-03 20:38:31,380 DEBUG TRAIN Batch 5/200 loss 19.801649 loss_att 25.032906 loss_ctc 37.817993 loss_rnnt 16.353218 lr 0.00077222 rank 0
2022-12-03 20:38:31,380 DEBUG TRAIN Batch 5/200 loss 37.003853 loss_att 40.174606 loss_ctc 49.098110 loss_rnnt 34.757137 lr 0.00077259 rank 5
2022-12-03 20:38:31,381 DEBUG TRAIN Batch 5/200 loss 19.886581 loss_att 30.379013 loss_ctc 39.665676 loss_rnnt 15.150883 lr 0.00077242 rank 1
2022-12-03 20:38:31,382 DEBUG TRAIN Batch 5/200 loss 26.123835 loss_att 34.713184 loss_ctc 42.554657 loss_rnnt 22.215187 lr 0.00077234 rank 3
2022-12-03 20:38:31,383 DEBUG TRAIN Batch 5/200 loss 17.503031 loss_att 24.014624 loss_ctc 30.151510 loss_rnnt 14.514250 lr 0.00077279 rank 7
2022-12-03 20:38:31,388 DEBUG TRAIN Batch 5/200 loss 7.609721 loss_att 14.064083 loss_ctc 11.691572 loss_rnnt 5.774602 lr 0.00077193 rank 2
2022-12-03 20:38:31,395 DEBUG TRAIN Batch 5/200 loss 12.111578 loss_att 15.665350 loss_ctc 22.009491 loss_rnnt 10.081101 lr 0.00077272 rank 4
2022-12-03 20:39:43,874 DEBUG TRAIN Batch 5/300 loss 25.956121 loss_att 33.061398 loss_ctc 42.265987 loss_rnnt 22.360416 lr 0.00077180 rank 4
2022-12-03 20:39:43,885 DEBUG TRAIN Batch 5/300 loss 26.983747 loss_att 32.844936 loss_ctc 38.973251 loss_rnnt 24.212908 lr 0.00077142 rank 3
2022-12-03 20:39:43,888 DEBUG TRAIN Batch 5/300 loss 22.376221 loss_att 30.233185 loss_ctc 42.672661 loss_rnnt 18.098639 lr 0.00077187 rank 7
2022-12-03 20:39:43,889 DEBUG TRAIN Batch 5/300 loss 16.322071 loss_att 24.475994 loss_ctc 35.295441 loss_rnnt 12.161504 lr 0.00077131 rank 0
2022-12-03 20:39:43,890 DEBUG TRAIN Batch 5/300 loss 12.590694 loss_att 17.608639 loss_ctc 25.723179 loss_rnnt 9.836106 lr 0.00077167 rank 5
2022-12-03 20:39:43,890 DEBUG TRAIN Batch 5/300 loss 16.634323 loss_att 24.785627 loss_ctc 31.183533 loss_rnnt 13.064169 lr 0.00077186 rank 6
2022-12-03 20:39:43,892 DEBUG TRAIN Batch 5/300 loss 26.169189 loss_att 35.720978 loss_ctc 43.516891 loss_rnnt 21.945807 lr 0.00077101 rank 2
2022-12-03 20:39:43,896 DEBUG TRAIN Batch 5/300 loss 31.803425 loss_att 38.275188 loss_ctc 44.632793 loss_rnnt 28.798489 lr 0.00077150 rank 1
2022-12-03 20:40:56,622 DEBUG TRAIN Batch 5/400 loss 21.400536 loss_att 24.674257 loss_ctc 30.398115 loss_rnnt 19.546112 lr 0.00077094 rank 6
2022-12-03 20:40:56,624 DEBUG TRAIN Batch 5/400 loss 31.164494 loss_att 42.514343 loss_ctc 61.741856 loss_rnnt 24.817539 lr 0.00077039 rank 0
2022-12-03 20:40:56,627 DEBUG TRAIN Batch 5/400 loss 16.699032 loss_att 22.797626 loss_ctc 26.365036 loss_rnnt 14.190514 lr 0.00077051 rank 3
2022-12-03 20:40:56,627 DEBUG TRAIN Batch 5/400 loss 22.442303 loss_att 26.067114 loss_ctc 39.274323 loss_rnnt 19.473072 lr 0.00077058 rank 1
2022-12-03 20:40:56,628 DEBUG TRAIN Batch 5/400 loss 17.605103 loss_att 24.145287 loss_ctc 34.670876 loss_rnnt 14.021629 lr 0.00077076 rank 5
2022-12-03 20:40:56,630 DEBUG TRAIN Batch 5/400 loss 24.165737 loss_att 35.057480 loss_ctc 46.565613 loss_rnnt 19.000738 lr 0.00077088 rank 4
2022-12-03 20:40:56,631 DEBUG TRAIN Batch 5/400 loss 21.533136 loss_att 28.524235 loss_ctc 33.715466 loss_rnnt 18.510607 lr 0.00077010 rank 2
2022-12-03 20:40:56,679 DEBUG TRAIN Batch 5/400 loss 17.461494 loss_att 25.791594 loss_ctc 30.745228 loss_rnnt 14.024310 lr 0.00077095 rank 7
2022-12-03 20:42:08,575 DEBUG TRAIN Batch 5/500 loss 28.909214 loss_att 29.891827 loss_ctc 49.409981 loss_rnnt 25.979256 lr 0.00076948 rank 0
2022-12-03 20:42:08,575 DEBUG TRAIN Batch 5/500 loss 27.426071 loss_att 32.272156 loss_ctc 45.896152 loss_rnnt 23.994177 lr 0.00076984 rank 5
2022-12-03 20:42:08,575 DEBUG TRAIN Batch 5/500 loss 17.857327 loss_att 21.626253 loss_ctc 26.722843 loss_rnnt 15.921474 lr 0.00076960 rank 3
2022-12-03 20:42:08,575 DEBUG TRAIN Batch 5/500 loss 22.092598 loss_att 28.748150 loss_ctc 39.336899 loss_rnnt 18.462246 lr 0.00077002 rank 6
2022-12-03 20:42:08,577 DEBUG TRAIN Batch 5/500 loss 18.694851 loss_att 25.696709 loss_ctc 32.275082 loss_rnnt 15.483783 lr 0.00076967 rank 1
2022-12-03 20:42:08,580 DEBUG TRAIN Batch 5/500 loss 18.412983 loss_att 23.410114 loss_ctc 31.957716 loss_rnnt 15.607594 lr 0.00076919 rank 2
2022-12-03 20:42:08,582 DEBUG TRAIN Batch 5/500 loss 24.161764 loss_att 27.345999 loss_ctc 34.484661 loss_rnnt 22.148531 lr 0.00076997 rank 4
2022-12-03 20:42:08,585 DEBUG TRAIN Batch 5/500 loss 9.674573 loss_att 14.722507 loss_ctc 22.318796 loss_rnnt 6.979089 lr 0.00077003 rank 7
2022-12-03 20:43:20,533 DEBUG TRAIN Batch 5/600 loss 24.882328 loss_att 25.487152 loss_ctc 35.957058 loss_rnnt 23.284735 lr 0.00076893 rank 5
2022-12-03 20:43:20,547 DEBUG TRAIN Batch 5/600 loss 17.857346 loss_att 22.227100 loss_ctc 29.299765 loss_rnnt 15.457740 lr 0.00076911 rank 6
2022-12-03 20:43:20,547 DEBUG TRAIN Batch 5/600 loss 18.673473 loss_att 21.473269 loss_ctc 27.539013 loss_rnnt 16.931442 lr 0.00076857 rank 0
2022-12-03 20:43:20,547 DEBUG TRAIN Batch 5/600 loss 27.293026 loss_att 28.710135 loss_ctc 42.229534 loss_rnnt 25.018068 lr 0.00076876 rank 1
2022-12-03 20:43:20,549 DEBUG TRAIN Batch 5/600 loss 10.992694 loss_att 11.978087 loss_ctc 17.277327 loss_rnnt 9.957664 lr 0.00076912 rank 7
2022-12-03 20:43:20,550 DEBUG TRAIN Batch 5/600 loss 20.085201 loss_att 22.452419 loss_ctc 26.497564 loss_rnnt 18.756775 lr 0.00076869 rank 3
2022-12-03 20:43:20,553 DEBUG TRAIN Batch 5/600 loss 25.427166 loss_att 28.028675 loss_ctc 39.698288 loss_rnnt 23.004045 lr 0.00076828 rank 2
2022-12-03 20:43:20,563 DEBUG TRAIN Batch 5/600 loss 14.170687 loss_att 16.770229 loss_ctc 27.643900 loss_rnnt 11.854350 lr 0.00076906 rank 4
2022-12-03 20:44:34,644 DEBUG TRAIN Batch 5/700 loss 24.222372 loss_att 30.426174 loss_ctc 35.580582 loss_rnnt 21.467184 lr 0.00076766 rank 0
2022-12-03 20:44:34,645 DEBUG TRAIN Batch 5/700 loss 25.555889 loss_att 32.863670 loss_ctc 44.662331 loss_rnnt 21.546806 lr 0.00076820 rank 6
2022-12-03 20:44:34,646 DEBUG TRAIN Batch 5/700 loss 21.201881 loss_att 33.018162 loss_ctc 32.270958 loss_rnnt 17.362747 lr 0.00076778 rank 3
2022-12-03 20:44:34,649 DEBUG TRAIN Batch 5/700 loss 14.468758 loss_att 20.408571 loss_ctc 24.752241 loss_rnnt 11.909662 lr 0.00076785 rank 1
2022-12-03 20:44:34,652 DEBUG TRAIN Batch 5/700 loss 12.406383 loss_att 19.568314 loss_ctc 25.475521 loss_rnnt 9.231444 lr 0.00076737 rank 2
2022-12-03 20:44:34,655 DEBUG TRAIN Batch 5/700 loss 10.921665 loss_att 14.366449 loss_ctc 23.938118 loss_rnnt 8.497181 lr 0.00076821 rank 7
2022-12-03 20:44:34,658 DEBUG TRAIN Batch 5/700 loss 16.181967 loss_att 18.956503 loss_ctc 23.966457 loss_rnnt 14.589127 lr 0.00076815 rank 4
2022-12-03 20:44:34,688 DEBUG TRAIN Batch 5/700 loss 55.270351 loss_att 52.849083 loss_ctc 74.283829 loss_rnnt 53.219475 lr 0.00076802 rank 5
2022-12-03 20:45:46,524 DEBUG TRAIN Batch 5/800 loss 25.033268 loss_att 26.618275 loss_ctc 37.755241 loss_rnnt 23.020004 lr 0.00076676 rank 0
2022-12-03 20:45:46,525 DEBUG TRAIN Batch 5/800 loss 30.996103 loss_att 37.950378 loss_ctc 44.689087 loss_rnnt 27.779518 lr 0.00076730 rank 6
2022-12-03 20:45:46,526 DEBUG TRAIN Batch 5/800 loss 36.813499 loss_att 42.098354 loss_ctc 57.395531 loss_rnnt 33.012257 lr 0.00076687 rank 3
2022-12-03 20:45:46,527 DEBUG TRAIN Batch 5/800 loss 21.088837 loss_att 29.938900 loss_ctc 34.561333 loss_rnnt 17.522491 lr 0.00076647 rank 2
2022-12-03 20:45:46,530 DEBUG TRAIN Batch 5/800 loss 18.553991 loss_att 22.694990 loss_ctc 28.592161 loss_rnnt 16.387367 lr 0.00076712 rank 5
2022-12-03 20:45:46,532 DEBUG TRAIN Batch 5/800 loss 18.259518 loss_att 23.715588 loss_ctc 26.146002 loss_rnnt 16.116772 lr 0.00076695 rank 1
2022-12-03 20:45:46,535 DEBUG TRAIN Batch 5/800 loss 24.747011 loss_att 31.221378 loss_ctc 42.544964 loss_rnnt 21.079079 lr 0.00076724 rank 4
2022-12-03 20:45:46,587 DEBUG TRAIN Batch 5/800 loss 21.486811 loss_att 31.123871 loss_ctc 36.761345 loss_rnnt 17.522795 lr 0.00076731 rank 7
2022-12-03 20:46:58,599 DEBUG TRAIN Batch 5/900 loss 15.753786 loss_att 23.768656 loss_ctc 34.227325 loss_rnnt 11.687674 lr 0.00076622 rank 5
2022-12-03 20:46:58,601 DEBUG TRAIN Batch 5/900 loss 6.749488 loss_att 11.494715 loss_ctc 16.151302 loss_rnnt 4.546867 lr 0.00076605 rank 1
2022-12-03 20:46:58,602 DEBUG TRAIN Batch 5/900 loss 31.924833 loss_att 43.101120 loss_ctc 51.865932 loss_rnnt 27.030762 lr 0.00076640 rank 6
2022-12-03 20:46:58,605 DEBUG TRAIN Batch 5/900 loss 21.111607 loss_att 25.041119 loss_ctc 32.044842 loss_rnnt 18.867939 lr 0.00076586 rank 0
2022-12-03 20:46:58,606 DEBUG TRAIN Batch 5/900 loss 20.788269 loss_att 27.174492 loss_ctc 41.817276 loss_rnnt 16.707157 lr 0.00076641 rank 7
2022-12-03 20:46:58,607 DEBUG TRAIN Batch 5/900 loss 21.542458 loss_att 26.266705 loss_ctc 39.461796 loss_rnnt 18.208363 lr 0.00076597 rank 3
2022-12-03 20:46:58,615 DEBUG TRAIN Batch 5/900 loss 14.424288 loss_att 20.449526 loss_ctc 22.519398 loss_rnnt 12.139893 lr 0.00076557 rank 2
2022-12-03 20:46:58,619 DEBUG TRAIN Batch 5/900 loss 21.005459 loss_att 27.985958 loss_ctc 32.579391 loss_rnnt 18.066170 lr 0.00076634 rank 4
2022-12-03 20:48:11,278 DEBUG TRAIN Batch 5/1000 loss 20.492674 loss_att 25.388760 loss_ctc 35.970680 loss_rnnt 17.449722 lr 0.00076496 rank 0
2022-12-03 20:48:11,284 DEBUG TRAIN Batch 5/1000 loss 25.565050 loss_att 30.798429 loss_ctc 38.537098 loss_rnnt 22.788767 lr 0.00076508 rank 3
2022-12-03 20:48:11,288 DEBUG TRAIN Batch 5/1000 loss 16.026777 loss_att 22.986988 loss_ctc 27.930408 loss_rnnt 13.047584 lr 0.00076550 rank 6
2022-12-03 20:48:11,291 DEBUG TRAIN Batch 5/1000 loss 28.075710 loss_att 27.103085 loss_ctc 40.973564 loss_rnnt 26.550522 lr 0.00076544 rank 4
2022-12-03 20:48:11,295 DEBUG TRAIN Batch 5/1000 loss 19.639353 loss_att 24.802216 loss_ctc 33.889217 loss_rnnt 16.706799 lr 0.00076467 rank 2
2022-12-03 20:48:11,295 DEBUG TRAIN Batch 5/1000 loss 30.834530 loss_att 37.795506 loss_ctc 52.153282 loss_rnnt 26.599834 lr 0.00076515 rank 1
2022-12-03 20:48:11,300 DEBUG TRAIN Batch 5/1000 loss 19.976755 loss_att 24.833691 loss_ctc 25.285461 loss_rnnt 18.297541 lr 0.00076532 rank 5
2022-12-03 20:48:11,320 DEBUG TRAIN Batch 5/1000 loss 17.457699 loss_att 21.042549 loss_ctc 35.333996 loss_rnnt 14.357223 lr 0.00076551 rank 7
2022-12-03 20:49:24,534 DEBUG TRAIN Batch 5/1100 loss 22.463799 loss_att 28.288025 loss_ctc 40.544739 loss_rnnt 18.888161 lr 0.00076407 rank 0
2022-12-03 20:49:24,536 DEBUG TRAIN Batch 5/1100 loss 44.542114 loss_att 50.261818 loss_ctc 69.752563 loss_rnnt 40.036781 lr 0.00076461 rank 7
2022-12-03 20:49:24,537 DEBUG TRAIN Batch 5/1100 loss 28.447731 loss_att 32.237469 loss_ctc 44.474457 loss_rnnt 25.552887 lr 0.00076442 rank 5
2022-12-03 20:49:24,537 DEBUG TRAIN Batch 5/1100 loss 12.190631 loss_att 16.830090 loss_ctc 16.622438 loss_rnnt 10.671832 lr 0.00076418 rank 3
2022-12-03 20:49:24,537 DEBUG TRAIN Batch 5/1100 loss 31.095348 loss_att 36.559265 loss_ctc 44.653946 loss_rnnt 28.194750 lr 0.00076460 rank 6
2022-12-03 20:49:24,540 DEBUG TRAIN Batch 5/1100 loss 33.818474 loss_att 37.496437 loss_ctc 56.995670 loss_rnnt 29.992588 lr 0.00076378 rank 2
2022-12-03 20:49:24,540 DEBUG TRAIN Batch 5/1100 loss 12.330793 loss_att 13.309015 loss_ctc 20.438171 loss_rnnt 11.054165 lr 0.00076425 rank 1
2022-12-03 20:49:24,542 DEBUG TRAIN Batch 5/1100 loss 17.376923 loss_att 21.783894 loss_ctc 31.453064 loss_rnnt 14.618710 lr 0.00076455 rank 4
2022-12-03 20:50:36,561 DEBUG TRAIN Batch 5/1200 loss 25.876060 loss_att 28.912493 loss_ctc 38.704880 loss_rnnt 23.558266 lr 0.00076336 rank 1
2022-12-03 20:50:36,582 DEBUG TRAIN Batch 5/1200 loss 21.819555 loss_att 25.271317 loss_ctc 41.769073 loss_rnnt 18.469269 lr 0.00076329 rank 3
2022-12-03 20:50:36,586 DEBUG TRAIN Batch 5/1200 loss 29.792320 loss_att 32.033348 loss_ctc 47.578899 loss_rnnt 26.972569 lr 0.00076371 rank 6
2022-12-03 20:50:36,586 DEBUG TRAIN Batch 5/1200 loss 19.970940 loss_att 24.358658 loss_ctc 37.403309 loss_rnnt 16.769079 lr 0.00076353 rank 5
2022-12-03 20:50:36,589 DEBUG TRAIN Batch 5/1200 loss 27.156300 loss_att 31.909628 loss_ctc 39.389996 loss_rnnt 24.574476 lr 0.00076318 rank 0
2022-12-03 20:50:36,589 DEBUG TRAIN Batch 5/1200 loss 18.167782 loss_att 20.184433 loss_ctc 25.686689 loss_rnnt 16.761930 lr 0.00076366 rank 4
2022-12-03 20:50:36,593 DEBUG TRAIN Batch 5/1200 loss 16.946762 loss_att 20.065023 loss_ctc 28.208160 loss_rnnt 14.821589 lr 0.00076289 rank 2
2022-12-03 20:50:36,631 DEBUG TRAIN Batch 5/1200 loss 21.857660 loss_att 23.759117 loss_ctc 32.222927 loss_rnnt 20.095333 lr 0.00076372 rank 7
2022-12-03 20:51:48,505 DEBUG TRAIN Batch 5/1300 loss 15.662608 loss_att 14.455585 loss_ctc 21.902252 loss_rnnt 15.072060 lr 0.00076264 rank 5
2022-12-03 20:51:48,505 DEBUG TRAIN Batch 5/1300 loss 20.591570 loss_att 19.783749 loss_ctc 27.056396 loss_rnnt 19.891159 lr 0.00076229 rank 0
2022-12-03 20:51:48,505 DEBUG TRAIN Batch 5/1300 loss 22.381462 loss_att 29.773415 loss_ctc 38.998901 loss_rnnt 18.687412 lr 0.00076201 rank 2
2022-12-03 20:51:48,507 DEBUG TRAIN Batch 5/1300 loss 15.441309 loss_att 16.578190 loss_ctc 19.431084 loss_rnnt 14.681962 lr 0.00076248 rank 1
2022-12-03 20:51:48,508 DEBUG TRAIN Batch 5/1300 loss 15.664870 loss_att 18.503330 loss_ctc 26.470539 loss_rnnt 13.656423 lr 0.00076282 rank 6
2022-12-03 20:51:48,510 DEBUG TRAIN Batch 5/1300 loss 30.845467 loss_att 38.484116 loss_ctc 43.866425 loss_rnnt 27.581610 lr 0.00076240 rank 3
2022-12-03 20:51:48,511 DEBUG TRAIN Batch 5/1300 loss 15.801454 loss_att 17.747440 loss_ctc 24.301374 loss_rnnt 14.278934 lr 0.00076277 rank 4
2022-12-03 20:51:48,516 DEBUG TRAIN Batch 5/1300 loss 23.248707 loss_att 32.594975 loss_ctc 39.554207 loss_rnnt 19.205387 lr 0.00076283 rank 7
2022-12-03 20:53:01,324 DEBUG TRAIN Batch 5/1400 loss 20.775694 loss_att 23.671320 loss_ctc 24.547810 loss_rnnt 19.693621 lr 0.00076140 rank 0
2022-12-03 20:53:01,325 DEBUG TRAIN Batch 5/1400 loss 26.894415 loss_att 31.605656 loss_ctc 43.257309 loss_rnnt 23.770447 lr 0.00076188 rank 4
2022-12-03 20:53:01,325 DEBUG TRAIN Batch 5/1400 loss 17.004570 loss_att 21.744911 loss_ctc 24.312361 loss_rnnt 15.082129 lr 0.00076159 rank 1
2022-12-03 20:53:01,338 DEBUG TRAIN Batch 5/1400 loss 10.670912 loss_att 17.226612 loss_ctc 22.381550 loss_rnnt 7.798353 lr 0.00076193 rank 6
2022-12-03 20:53:01,341 DEBUG TRAIN Batch 5/1400 loss 36.119110 loss_att 37.291481 loss_ctc 53.358807 loss_rnnt 33.586010 lr 0.00076176 rank 5
2022-12-03 20:53:01,341 DEBUG TRAIN Batch 5/1400 loss 25.504459 loss_att 30.386646 loss_ctc 48.083023 loss_rnnt 21.517548 lr 0.00076112 rank 2
2022-12-03 20:53:01,340 DEBUG TRAIN Batch 5/1400 loss 25.040207 loss_att 25.566742 loss_ctc 34.192070 loss_rnnt 23.714649 lr 0.00076194 rank 7
2022-12-03 20:53:01,342 DEBUG TRAIN Batch 5/1400 loss 24.351665 loss_att 26.352684 loss_ctc 32.749191 loss_rnnt 22.831793 lr 0.00076152 rank 3
2022-12-03 20:54:13,649 DEBUG TRAIN Batch 5/1500 loss 16.719669 loss_att 22.538582 loss_ctc 26.777664 loss_rnnt 14.214820 lr 0.00076071 rank 1
2022-12-03 20:54:13,650 DEBUG TRAIN Batch 5/1500 loss 45.234428 loss_att 47.958252 loss_ctc 69.132477 loss_rnnt 41.503262 lr 0.00076105 rank 6
2022-12-03 20:54:13,654 DEBUG TRAIN Batch 5/1500 loss 21.875776 loss_att 26.124800 loss_ctc 34.311169 loss_rnnt 19.367920 lr 0.00076064 rank 3
2022-12-03 20:54:13,656 DEBUG TRAIN Batch 5/1500 loss 31.056202 loss_att 32.223503 loss_ctc 45.153942 loss_rnnt 28.943043 lr 0.00076052 rank 0
2022-12-03 20:54:13,657 DEBUG TRAIN Batch 5/1500 loss 20.778799 loss_att 25.727222 loss_ctc 32.546104 loss_rnnt 18.220140 lr 0.00076088 rank 5
2022-12-03 20:54:13,658 DEBUG TRAIN Batch 5/1500 loss 12.381585 loss_att 16.320766 loss_ctc 19.240936 loss_rnnt 10.679169 lr 0.00076024 rank 2
2022-12-03 20:54:13,662 DEBUG TRAIN Batch 5/1500 loss 26.722017 loss_att 39.474960 loss_ctc 46.113243 loss_rnnt 21.585934 lr 0.00076106 rank 7
2022-12-03 20:54:13,664 DEBUG TRAIN Batch 5/1500 loss 20.419172 loss_att 25.785686 loss_ctc 41.030746 loss_rnnt 16.597660 lr 0.00076100 rank 4
2022-12-03 20:55:25,011 DEBUG TRAIN Batch 5/1600 loss 14.629290 loss_att 19.221884 loss_ctc 27.636425 loss_rnnt 11.976486 lr 0.00075965 rank 0
2022-12-03 20:55:25,013 DEBUG TRAIN Batch 5/1600 loss 15.247410 loss_att 19.428534 loss_ctc 24.337864 loss_rnnt 13.199124 lr 0.00075976 rank 3
2022-12-03 20:55:25,016 DEBUG TRAIN Batch 5/1600 loss 25.191280 loss_att 29.443125 loss_ctc 44.440613 loss_rnnt 21.774334 lr 0.00076017 rank 6
2022-12-03 20:55:25,019 DEBUG TRAIN Batch 5/1600 loss 14.116953 loss_att 19.169945 loss_ctc 24.810123 loss_rnnt 11.680598 lr 0.00075983 rank 1
2022-12-03 20:55:25,020 DEBUG TRAIN Batch 5/1600 loss 47.748802 loss_att 48.845764 loss_ctc 67.556717 loss_rnnt 44.888351 lr 0.00075936 rank 2
2022-12-03 20:55:25,021 DEBUG TRAIN Batch 5/1600 loss 23.217743 loss_att 33.125988 loss_ctc 46.123142 loss_rnnt 18.182041 lr 0.00076018 rank 7
2022-12-03 20:55:25,022 DEBUG TRAIN Batch 5/1600 loss 35.328453 loss_att 39.852989 loss_ctc 54.572777 loss_rnnt 31.857635 lr 0.00076012 rank 4
2022-12-03 20:55:25,066 DEBUG TRAIN Batch 5/1600 loss 28.446848 loss_att 33.244873 loss_ctc 47.414711 loss_rnnt 24.958193 lr 0.00076000 rank 5
2022-12-03 20:56:37,568 DEBUG TRAIN Batch 5/1700 loss 13.395225 loss_att 17.202484 loss_ctc 21.131269 loss_rnnt 11.602301 lr 0.00075929 rank 6
2022-12-03 20:56:37,568 DEBUG TRAIN Batch 5/1700 loss 13.915638 loss_att 17.831333 loss_ctc 21.829264 loss_rnnt 12.077349 lr 0.00075888 rank 3
2022-12-03 20:56:37,569 DEBUG TRAIN Batch 5/1700 loss 18.051195 loss_att 21.104279 loss_ctc 23.262537 loss_rnnt 16.745731 lr 0.00075924 rank 4
2022-12-03 20:56:37,569 DEBUG TRAIN Batch 5/1700 loss 17.353174 loss_att 22.941290 loss_ctc 25.211971 loss_rnnt 15.187712 lr 0.00075877 rank 0
2022-12-03 20:56:37,571 DEBUG TRAIN Batch 5/1700 loss 12.969500 loss_att 17.652184 loss_ctc 26.822136 loss_rnnt 10.185944 lr 0.00075930 rank 7
2022-12-03 20:56:37,573 DEBUG TRAIN Batch 5/1700 loss 16.604744 loss_att 24.600668 loss_ctc 25.978535 loss_rnnt 13.755720 lr 0.00075912 rank 5
2022-12-03 20:56:37,584 DEBUG TRAIN Batch 5/1700 loss 22.673536 loss_att 27.298622 loss_ctc 37.447811 loss_rnnt 19.778616 lr 0.00075895 rank 1
2022-12-03 20:56:37,596 DEBUG TRAIN Batch 5/1700 loss 27.044449 loss_att 31.755859 loss_ctc 42.734978 loss_rnnt 24.010094 lr 0.00075849 rank 2
2022-12-03 20:57:51,575 DEBUG TRAIN Batch 5/1800 loss 17.511436 loss_att 23.156813 loss_ctc 28.135118 loss_rnnt 14.965872 lr 0.00075801 rank 3
2022-12-03 20:57:51,592 DEBUG TRAIN Batch 5/1800 loss 25.837175 loss_att 29.524004 loss_ctc 40.147472 loss_rnnt 23.191771 lr 0.00075790 rank 0
2022-12-03 20:57:51,593 DEBUG TRAIN Batch 5/1800 loss 19.884842 loss_att 21.344065 loss_ctc 28.164858 loss_rnnt 18.488995 lr 0.00075843 rank 7
2022-12-03 20:57:51,595 DEBUG TRAIN Batch 5/1800 loss 17.718964 loss_att 18.806854 loss_ctc 25.346981 loss_rnnt 16.484316 lr 0.00075842 rank 6
2022-12-03 20:57:51,596 DEBUG TRAIN Batch 5/1800 loss 42.412125 loss_att 43.890709 loss_ctc 55.156891 loss_rnnt 40.417103 lr 0.00075808 rank 1
2022-12-03 20:57:51,596 DEBUG TRAIN Batch 5/1800 loss 16.261492 loss_att 19.206362 loss_ctc 26.548664 loss_rnnt 14.300895 lr 0.00075762 rank 2
2022-12-03 20:57:51,605 DEBUG TRAIN Batch 5/1800 loss 30.089153 loss_att 33.066788 loss_ctc 50.279167 loss_rnnt 26.801624 lr 0.00075837 rank 4
2022-12-03 20:57:51,642 DEBUG TRAIN Batch 5/1800 loss 16.071810 loss_att 17.583910 loss_ctc 28.822426 loss_rnnt 14.069306 lr 0.00075825 rank 5
2022-12-03 20:59:03,741 DEBUG TRAIN Batch 5/1900 loss 16.084286 loss_att 18.808376 loss_ctc 25.967871 loss_rnnt 14.221657 lr 0.00075755 rank 6
2022-12-03 20:59:03,750 DEBUG TRAIN Batch 5/1900 loss 17.577911 loss_att 21.105629 loss_ctc 25.258739 loss_rnnt 15.848258 lr 0.00075714 rank 3
2022-12-03 20:59:03,751 DEBUG TRAIN Batch 5/1900 loss 16.849468 loss_att 19.450455 loss_ctc 28.475561 loss_rnnt 14.779127 lr 0.00075738 rank 5
2022-12-03 20:59:03,751 DEBUG TRAIN Batch 5/1900 loss 9.264376 loss_att 10.066378 loss_ctc 15.953494 loss_rnnt 8.212093 lr 0.00075675 rank 2
2022-12-03 20:59:03,750 DEBUG TRAIN Batch 5/1900 loss 23.925419 loss_att 30.052612 loss_ctc 39.687088 loss_rnnt 20.598423 lr 0.00075721 rank 1
2022-12-03 20:59:03,751 DEBUG TRAIN Batch 5/1900 loss 14.831277 loss_att 22.244890 loss_ctc 23.852806 loss_rnnt 12.145683 lr 0.00075756 rank 7
2022-12-03 20:59:03,756 DEBUG TRAIN Batch 5/1900 loss 17.068319 loss_att 18.154007 loss_ctc 23.994019 loss_rnnt 15.927756 lr 0.00075703 rank 0
2022-12-03 20:59:03,798 DEBUG TRAIN Batch 5/1900 loss 22.158806 loss_att 26.755753 loss_ctc 28.664669 loss_rnnt 20.371967 lr 0.00075750 rank 4
2022-12-03 21:00:15,780 DEBUG TRAIN Batch 5/2000 loss 12.993145 loss_att 20.254330 loss_ctc 24.716879 loss_rnnt 9.977743 lr 0.00075668 rank 6
2022-12-03 21:00:15,782 DEBUG TRAIN Batch 5/2000 loss 20.953545 loss_att 32.611485 loss_ctc 40.125957 loss_rnnt 16.065636 lr 0.00075651 rank 5
2022-12-03 21:00:15,782 DEBUG TRAIN Batch 5/2000 loss 20.692383 loss_att 28.822882 loss_ctc 36.136456 loss_rnnt 17.007072 lr 0.00075634 rank 1
2022-12-03 21:00:15,787 DEBUG TRAIN Batch 5/2000 loss 19.189693 loss_att 23.140701 loss_ctc 35.139458 loss_rnnt 16.272858 lr 0.00075669 rank 7
2022-12-03 21:00:15,789 DEBUG TRAIN Batch 5/2000 loss 18.238083 loss_att 27.429337 loss_ctc 28.468475 loss_rnnt 15.035778 lr 0.00075663 rank 4
2022-12-03 21:00:15,790 DEBUG TRAIN Batch 5/2000 loss 20.402250 loss_att 25.357447 loss_ctc 29.054600 loss_rnnt 18.257565 lr 0.00075616 rank 0
2022-12-03 21:00:15,792 DEBUG TRAIN Batch 5/2000 loss 16.857910 loss_att 28.101543 loss_ctc 24.167715 loss_rnnt 13.634541 lr 0.00075627 rank 3
2022-12-03 21:00:15,796 DEBUG TRAIN Batch 5/2000 loss 19.357674 loss_att 24.549078 loss_ctc 35.489994 loss_rnnt 16.168415 lr 0.00075589 rank 2
2022-12-03 21:01:29,803 DEBUG TRAIN Batch 5/2100 loss 11.685278 loss_att 18.130671 loss_ctc 19.916763 loss_rnnt 9.298668 lr 0.00075502 rank 2
2022-12-03 21:01:29,810 DEBUG TRAIN Batch 5/2100 loss 21.488230 loss_att 26.692528 loss_ctc 32.284286 loss_rnnt 19.007896 lr 0.00075582 rank 6
2022-12-03 21:01:29,810 DEBUG TRAIN Batch 5/2100 loss 18.477999 loss_att 22.490421 loss_ctc 29.282333 loss_rnnt 16.234936 lr 0.00075530 rank 0
2022-12-03 21:01:29,813 DEBUG TRAIN Batch 5/2100 loss 17.150068 loss_att 24.662884 loss_ctc 32.806801 loss_rnnt 13.559942 lr 0.00075564 rank 5
2022-12-03 21:01:29,812 DEBUG TRAIN Batch 5/2100 loss 14.433614 loss_att 18.847931 loss_ctc 23.601669 loss_rnnt 12.328344 lr 0.00075541 rank 3
2022-12-03 21:01:29,815 DEBUG TRAIN Batch 5/2100 loss 38.378220 loss_att 45.290314 loss_ctc 67.112068 loss_rnnt 33.164623 lr 0.00075583 rank 7
2022-12-03 21:01:29,816 DEBUG TRAIN Batch 5/2100 loss 21.219101 loss_att 28.122322 loss_ctc 38.155128 loss_rnnt 17.580320 lr 0.00075548 rank 1
2022-12-03 21:01:29,821 DEBUG TRAIN Batch 5/2100 loss 19.297699 loss_att 29.644846 loss_ctc 37.769600 loss_rnnt 14.765348 lr 0.00075576 rank 4
2022-12-03 21:02:41,847 DEBUG TRAIN Batch 5/2200 loss 17.496908 loss_att 22.615099 loss_ctc 27.371372 loss_rnnt 15.156673 lr 0.00075455 rank 3
2022-12-03 21:02:41,851 DEBUG TRAIN Batch 5/2200 loss 24.065937 loss_att 30.817581 loss_ctc 35.775238 loss_rnnt 21.154369 lr 0.00075462 rank 1
2022-12-03 21:02:41,851 DEBUG TRAIN Batch 5/2200 loss 25.282124 loss_att 31.792219 loss_ctc 27.235178 loss_rnnt 23.719696 lr 0.00075495 rank 6
2022-12-03 21:02:41,851 DEBUG TRAIN Batch 5/2200 loss 16.901306 loss_att 23.889599 loss_ctc 27.815739 loss_rnnt 14.048388 lr 0.00075416 rank 2
2022-12-03 21:02:41,853 DEBUG TRAIN Batch 5/2200 loss 18.202770 loss_att 19.682438 loss_ctc 25.304386 loss_rnnt 16.959953 lr 0.00075478 rank 5
2022-12-03 21:02:41,853 DEBUG TRAIN Batch 5/2200 loss 18.981110 loss_att 25.851683 loss_ctc 35.211895 loss_rnnt 15.442888 lr 0.00075490 rank 4
2022-12-03 21:02:41,854 DEBUG TRAIN Batch 5/2200 loss 17.585920 loss_att 21.033701 loss_ctc 31.987509 loss_rnnt 14.976151 lr 0.00075444 rank 0
2022-12-03 21:02:41,899 DEBUG TRAIN Batch 5/2200 loss 49.273399 loss_att 54.576118 loss_ctc 78.461136 loss_rnnt 44.321159 lr 0.00075496 rank 7
2022-12-03 21:03:53,719 DEBUG TRAIN Batch 5/2300 loss 15.906467 loss_att 20.258551 loss_ctc 23.379395 loss_rnnt 14.039660 lr 0.00075404 rank 4
2022-12-03 21:03:53,726 DEBUG TRAIN Batch 5/2300 loss 24.834393 loss_att 28.993956 loss_ctc 40.315395 loss_rnnt 21.938343 lr 0.00075410 rank 6
2022-12-03 21:03:53,727 DEBUG TRAIN Batch 5/2300 loss 23.978577 loss_att 25.153152 loss_ctc 39.172615 loss_rnnt 21.717789 lr 0.00075358 rank 0
2022-12-03 21:03:53,730 DEBUG TRAIN Batch 5/2300 loss 20.948973 loss_att 24.291012 loss_ctc 38.131065 loss_rnnt 17.989620 lr 0.00075331 rank 2
2022-12-03 21:03:53,732 DEBUG TRAIN Batch 5/2300 loss 25.901749 loss_att 32.015400 loss_ctc 41.356422 loss_rnnt 22.618395 lr 0.00075392 rank 5
2022-12-03 21:03:53,733 DEBUG TRAIN Batch 5/2300 loss 26.513941 loss_att 35.074017 loss_ctc 46.190224 loss_rnnt 22.178421 lr 0.00075369 rank 3
2022-12-03 21:03:53,736 DEBUG TRAIN Batch 5/2300 loss 18.928223 loss_att 22.353830 loss_ctc 37.882805 loss_rnnt 15.715823 lr 0.00075410 rank 7
2022-12-03 21:03:53,746 DEBUG TRAIN Batch 5/2300 loss 22.565323 loss_att 24.707878 loss_ctc 35.705727 loss_rnnt 20.384758 lr 0.00075376 rank 1
2022-12-03 21:05:05,345 DEBUG TRAIN Batch 5/2400 loss 31.524414 loss_att 33.921490 loss_ctc 44.917618 loss_rnnt 29.259237 lr 0.00075307 rank 5
2022-12-03 21:05:05,349 DEBUG TRAIN Batch 5/2400 loss 21.558105 loss_att 25.622419 loss_ctc 34.209141 loss_rnnt 19.058437 lr 0.00075319 rank 4
2022-12-03 21:05:05,355 DEBUG TRAIN Batch 5/2400 loss 16.962261 loss_att 21.013317 loss_ctc 35.546852 loss_rnnt 13.674103 lr 0.00075325 rank 7
2022-12-03 21:05:05,355 DEBUG TRAIN Batch 5/2400 loss 33.661011 loss_att 38.267330 loss_ctc 48.984200 loss_rnnt 30.696655 lr 0.00075324 rank 6
2022-12-03 21:05:05,361 DEBUG TRAIN Batch 5/2400 loss 14.258945 loss_att 22.094185 loss_ctc 27.365860 loss_rnnt 10.944306 lr 0.00075245 rank 2
2022-12-03 21:05:05,361 DEBUG TRAIN Batch 5/2400 loss 23.745394 loss_att 28.695324 loss_ctc 39.455864 loss_rnnt 20.660679 lr 0.00075273 rank 0
2022-12-03 21:05:05,366 DEBUG TRAIN Batch 5/2400 loss 19.723454 loss_att 24.513096 loss_ctc 32.885677 loss_rnnt 17.010561 lr 0.00075284 rank 3
2022-12-03 21:05:05,402 DEBUG TRAIN Batch 5/2400 loss 21.605993 loss_att 30.040476 loss_ctc 36.273285 loss_rnnt 17.963459 lr 0.00075291 rank 1
2022-12-03 21:06:19,851 DEBUG TRAIN Batch 5/2500 loss 16.052683 loss_att 18.515543 loss_ctc 26.633575 loss_rnnt 14.149325 lr 0.00075239 rank 6
2022-12-03 21:06:19,852 DEBUG TRAIN Batch 5/2500 loss 15.954700 loss_att 21.187508 loss_ctc 26.016235 loss_rnnt 13.566600 lr 0.00075222 rank 5
2022-12-03 21:06:19,854 DEBUG TRAIN Batch 5/2500 loss 25.564503 loss_att 26.102467 loss_ctc 39.944363 loss_rnnt 23.539595 lr 0.00075188 rank 0
2022-12-03 21:06:19,856 DEBUG TRAIN Batch 5/2500 loss 16.692802 loss_att 18.655659 loss_ctc 22.326002 loss_rnnt 15.549139 lr 0.00075199 rank 3
2022-12-03 21:06:19,857 DEBUG TRAIN Batch 5/2500 loss 51.103809 loss_att 48.901932 loss_ctc 70.569206 loss_rnnt 48.948803 lr 0.00075205 rank 1
2022-12-03 21:06:19,861 DEBUG TRAIN Batch 5/2500 loss 17.417868 loss_att 17.230902 loss_ctc 24.005909 loss_rnnt 16.576855 lr 0.00075160 rank 2
2022-12-03 21:06:19,870 DEBUG TRAIN Batch 5/2500 loss 20.236103 loss_att 30.369190 loss_ctc 23.943426 loss_rnnt 17.715176 lr 0.00075239 rank 7
2022-12-03 21:06:19,912 DEBUG TRAIN Batch 5/2500 loss 29.505798 loss_att 31.972992 loss_ctc 36.883694 loss_rnnt 28.028641 lr 0.00075233 rank 4
2022-12-03 21:07:31,438 DEBUG TRAIN Batch 5/2600 loss 33.968090 loss_att 38.208828 loss_ctc 62.259712 loss_rnnt 29.347725 lr 0.00075103 rank 0
2022-12-03 21:07:31,453 DEBUG TRAIN Batch 5/2600 loss 27.293642 loss_att 31.033627 loss_ctc 35.526642 loss_rnnt 25.447912 lr 0.00075114 rank 3
2022-12-03 21:07:31,454 DEBUG TRAIN Batch 5/2600 loss 26.255112 loss_att 45.845490 loss_ctc 48.475220 loss_rnnt 19.374355 lr 0.00075154 rank 6
2022-12-03 21:07:31,455 DEBUG TRAIN Batch 5/2600 loss 17.634768 loss_att 18.691128 loss_ctc 24.687563 loss_rnnt 16.483122 lr 0.00075137 rank 5
2022-12-03 21:07:31,454 DEBUG TRAIN Batch 5/2600 loss 32.184410 loss_att 37.050014 loss_ctc 50.137718 loss_rnnt 28.817516 lr 0.00075154 rank 7
2022-12-03 21:07:31,459 DEBUG TRAIN Batch 5/2600 loss 12.377514 loss_att 13.799520 loss_ctc 18.395315 loss_rnnt 11.290739 lr 0.00075120 rank 1
2022-12-03 21:07:31,460 DEBUG TRAIN Batch 5/2600 loss 26.932850 loss_att 34.036942 loss_ctc 40.833542 loss_rnnt 23.658604 lr 0.00075076 rank 2
2022-12-03 21:07:31,462 DEBUG TRAIN Batch 5/2600 loss 16.834284 loss_att 16.860041 loss_ctc 22.673538 loss_rnnt 16.050564 lr 0.00075148 rank 4
2022-12-03 21:08:44,306 DEBUG TRAIN Batch 5/2700 loss 19.256887 loss_att 25.365772 loss_ctc 35.537254 loss_rnnt 15.864394 lr 0.00075018 rank 0
2022-12-03 21:08:44,319 DEBUG TRAIN Batch 5/2700 loss 14.580325 loss_att 17.449549 loss_ctc 21.958288 loss_rnnt 13.022751 lr 0.00075069 rank 6
2022-12-03 21:08:44,321 DEBUG TRAIN Batch 5/2700 loss 11.209531 loss_att 14.526577 loss_ctc 18.593229 loss_rnnt 9.561629 lr 0.00074991 rank 2
2022-12-03 21:08:44,322 DEBUG TRAIN Batch 5/2700 loss 15.910561 loss_att 23.206608 loss_ctc 26.929554 loss_rnnt 12.982153 lr 0.00075036 rank 1
2022-12-03 21:08:44,324 DEBUG TRAIN Batch 5/2700 loss 11.604958 loss_att 19.479919 loss_ctc 21.619986 loss_rnnt 8.694628 lr 0.00075029 rank 3
2022-12-03 21:08:44,326 DEBUG TRAIN Batch 5/2700 loss 26.056805 loss_att 34.479401 loss_ctc 47.192291 loss_rnnt 21.554220 lr 0.00075070 rank 7
2022-12-03 21:08:44,330 DEBUG TRAIN Batch 5/2700 loss 20.617018 loss_att 24.536110 loss_ctc 37.437004 loss_rnnt 17.590534 lr 0.00075064 rank 4
2022-12-03 21:08:44,372 DEBUG TRAIN Batch 5/2700 loss 22.035975 loss_att 32.089550 loss_ctc 38.528652 loss_rnnt 17.826237 lr 0.00075052 rank 5
2022-12-03 21:09:57,822 DEBUG TRAIN Batch 5/2800 loss 9.314088 loss_att 14.640106 loss_ctc 16.578285 loss_rnnt 7.280324 lr 0.00074979 rank 4
2022-12-03 21:09:57,823 DEBUG TRAIN Batch 5/2800 loss 26.679901 loss_att 33.128807 loss_ctc 43.631165 loss_rnnt 23.129948 lr 0.00074984 rank 6
2022-12-03 21:09:57,827 DEBUG TRAIN Batch 5/2800 loss 29.274700 loss_att 35.676556 loss_ctc 36.856544 loss_rnnt 26.983418 lr 0.00074985 rank 7
2022-12-03 21:09:57,828 DEBUG TRAIN Batch 5/2800 loss 15.651125 loss_att 19.323168 loss_ctc 33.326706 loss_rnnt 12.559973 lr 0.00074967 rank 5
2022-12-03 21:09:57,830 DEBUG TRAIN Batch 5/2800 loss 17.898203 loss_att 27.345482 loss_ctc 34.637802 loss_rnnt 13.776801 lr 0.00074934 rank 0
2022-12-03 21:09:57,831 DEBUG TRAIN Batch 5/2800 loss 16.109825 loss_att 25.006647 loss_ctc 27.530926 loss_rnnt 12.807648 lr 0.00074951 rank 1
2022-12-03 21:09:57,837 DEBUG TRAIN Batch 5/2800 loss 29.429657 loss_att 36.305561 loss_ctc 53.395092 loss_rnnt 24.859085 lr 0.00074907 rank 2
2022-12-03 21:09:57,844 DEBUG TRAIN Batch 5/2800 loss 15.636188 loss_att 20.274290 loss_ctc 25.064461 loss_rnnt 13.451465 lr 0.00074945 rank 3
2022-12-03 21:11:11,230 DEBUG TRAIN Batch 5/2900 loss 19.432177 loss_att 18.337826 loss_ctc 23.770721 loss_rnnt 19.072575 lr 0.00074900 rank 6
2022-12-03 21:11:11,232 DEBUG TRAIN Batch 5/2900 loss 23.785877 loss_att 31.468334 loss_ctc 34.403690 loss_rnnt 20.833675 lr 0.00074861 rank 3
2022-12-03 21:11:11,238 DEBUG TRAIN Batch 5/2900 loss 13.937958 loss_att 18.438526 loss_ctc 21.145826 loss_rnnt 12.076794 lr 0.00074850 rank 0
2022-12-03 21:11:11,240 DEBUG TRAIN Batch 5/2900 loss 15.902852 loss_att 18.335756 loss_ctc 26.548939 loss_rnnt 13.996793 lr 0.00074823 rank 2
2022-12-03 21:11:11,239 DEBUG TRAIN Batch 5/2900 loss 17.987249 loss_att 20.546501 loss_ctc 31.045042 loss_rnnt 15.734360 lr 0.00074867 rank 1
2022-12-03 21:11:11,239 DEBUG TRAIN Batch 5/2900 loss 13.167540 loss_att 17.776867 loss_ctc 25.728718 loss_rnnt 10.570850 lr 0.00074895 rank 4
2022-12-03 21:11:11,241 DEBUG TRAIN Batch 5/2900 loss 19.591991 loss_att 22.651716 loss_ctc 36.279236 loss_rnnt 16.755081 lr 0.00074883 rank 5
2022-12-03 21:11:11,244 DEBUG TRAIN Batch 5/2900 loss 25.768105 loss_att 30.755619 loss_ctc 41.019218 loss_rnnt 22.737122 lr 0.00074901 rank 7
2022-12-03 21:12:23,052 DEBUG TRAIN Batch 5/3000 loss 27.993849 loss_att 30.352093 loss_ctc 41.704536 loss_rnnt 25.694107 lr 0.00074739 rank 2
2022-12-03 21:12:23,055 DEBUG TRAIN Batch 5/3000 loss 17.225351 loss_att 20.673130 loss_ctc 29.763397 loss_rnnt 14.864058 lr 0.00074816 rank 6
2022-12-03 21:12:23,057 DEBUG TRAIN Batch 5/3000 loss 25.551136 loss_att 30.366585 loss_ctc 35.972977 loss_rnnt 23.198469 lr 0.00074766 rank 0
2022-12-03 21:12:23,058 DEBUG TRAIN Batch 5/3000 loss 22.230326 loss_att 32.212608 loss_ctc 34.607182 loss_rnnt 18.583622 lr 0.00074777 rank 3
2022-12-03 21:12:23,058 DEBUG TRAIN Batch 5/3000 loss 32.621807 loss_att 36.504116 loss_ctc 60.276569 loss_rnnt 28.158045 lr 0.00074784 rank 1
2022-12-03 21:12:23,059 DEBUG TRAIN Batch 5/3000 loss 25.138426 loss_att 28.441162 loss_ctc 41.770050 loss_rnnt 22.260328 lr 0.00074817 rank 7
2022-12-03 21:12:23,061 DEBUG TRAIN Batch 5/3000 loss 19.055729 loss_att 22.904627 loss_ctc 29.095339 loss_rnnt 16.947334 lr 0.00074800 rank 5
2022-12-03 21:12:23,064 DEBUG TRAIN Batch 5/3000 loss 27.715603 loss_att 32.670292 loss_ctc 44.918915 loss_rnnt 24.430891 lr 0.00074811 rank 4
2022-12-03 21:13:35,677 DEBUG TRAIN Batch 5/3100 loss 19.656229 loss_att 21.065510 loss_ctc 27.162893 loss_rnnt 18.373486 lr 0.00074733 rank 6
2022-12-03 21:13:35,681 DEBUG TRAIN Batch 5/3100 loss 15.072407 loss_att 19.337019 loss_ctc 23.996235 loss_rnnt 13.029640 lr 0.00074683 rank 0
2022-12-03 21:13:35,689 DEBUG TRAIN Batch 5/3100 loss 17.552742 loss_att 20.347315 loss_ctc 27.769012 loss_rnnt 15.631659 lr 0.00074700 rank 1
2022-12-03 21:13:35,691 DEBUG TRAIN Batch 5/3100 loss 20.753004 loss_att 24.722170 loss_ctc 35.696289 loss_rnnt 17.966732 lr 0.00074733 rank 7
2022-12-03 21:13:35,691 DEBUG TRAIN Batch 5/3100 loss 17.396738 loss_att 23.515560 loss_ctc 31.670650 loss_rnnt 14.269785 lr 0.00074728 rank 4
2022-12-03 21:13:35,701 DEBUG TRAIN Batch 5/3100 loss 19.991196 loss_att 20.550129 loss_ctc 28.431143 loss_rnnt 18.754082 lr 0.00074656 rank 2
2022-12-03 21:13:35,713 DEBUG TRAIN Batch 5/3100 loss 12.188541 loss_att 16.809847 loss_ctc 16.596134 loss_rnnt 10.676601 lr 0.00074693 rank 3
2022-12-03 21:13:35,714 DEBUG TRAIN Batch 5/3100 loss 17.379345 loss_att 22.670635 loss_ctc 30.756710 loss_rnnt 14.537437 lr 0.00074716 rank 5
2022-12-03 21:14:50,640 DEBUG TRAIN Batch 5/3200 loss 14.874247 loss_att 21.724594 loss_ctc 26.289183 loss_rnnt 11.982185 lr 0.00074649 rank 6
2022-12-03 21:14:50,640 DEBUG TRAIN Batch 5/3200 loss 13.366128 loss_att 18.403671 loss_ctc 21.005243 loss_rnnt 11.340070 lr 0.00074599 rank 0
2022-12-03 21:14:50,640 DEBUG TRAIN Batch 5/3200 loss 17.535601 loss_att 18.518938 loss_ctc 29.255941 loss_rnnt 15.776221 lr 0.00074610 rank 3
2022-12-03 21:14:50,648 DEBUG TRAIN Batch 5/3200 loss 19.367472 loss_att 21.530098 loss_ctc 26.316319 loss_rnnt 18.008432 lr 0.00074617 rank 1
2022-12-03 21:14:50,660 DEBUG TRAIN Batch 5/3200 loss 18.167618 loss_att 24.193176 loss_ctc 36.259594 loss_rnnt 14.550243 lr 0.00074573 rank 2
2022-12-03 21:14:50,686 DEBUG TRAIN Batch 5/3200 loss 15.712775 loss_att 20.882271 loss_ctc 34.740711 loss_rnnt 12.141818 lr 0.00074650 rank 7
2022-12-03 21:14:50,686 DEBUG TRAIN Batch 5/3200 loss 19.029570 loss_att 23.414289 loss_ctc 32.440380 loss_rnnt 16.364517 lr 0.00074644 rank 4
2022-12-03 21:14:50,692 DEBUG TRAIN Batch 5/3200 loss 12.470476 loss_att 14.736684 loss_ctc 19.260904 loss_rnnt 11.111844 lr 0.00074633 rank 5
2022-12-03 21:16:02,431 DEBUG TRAIN Batch 5/3300 loss 17.496321 loss_att 22.483122 loss_ctc 36.506676 loss_rnnt 13.964245 lr 0.00074517 rank 0
2022-12-03 21:16:02,440 DEBUG TRAIN Batch 5/3300 loss 16.293907 loss_att 18.819256 loss_ctc 21.236496 loss_rnnt 15.129825 lr 0.00074527 rank 3
2022-12-03 21:16:02,441 DEBUG TRAIN Batch 5/3300 loss 33.978611 loss_att 39.080429 loss_ctc 55.412170 loss_rnnt 30.100437 lr 0.00074566 rank 6
2022-12-03 21:16:02,445 DEBUG TRAIN Batch 5/3300 loss 27.780140 loss_att 34.951633 loss_ctc 44.043148 loss_rnnt 24.177441 lr 0.00074567 rank 7
2022-12-03 21:16:02,447 DEBUG TRAIN Batch 5/3300 loss 16.795757 loss_att 25.231897 loss_ctc 31.722530 loss_rnnt 13.118294 lr 0.00074550 rank 5
2022-12-03 21:16:02,449 DEBUG TRAIN Batch 5/3300 loss 33.571365 loss_att 36.814922 loss_ctc 50.851486 loss_rnnt 30.618635 lr 0.00074490 rank 2
2022-12-03 21:16:02,469 DEBUG TRAIN Batch 5/3300 loss 22.851780 loss_att 24.736773 loss_ctc 40.023148 loss_rnnt 20.185265 lr 0.00074534 rank 1
2022-12-03 21:16:02,495 DEBUG TRAIN Batch 5/3300 loss 14.034125 loss_att 12.673510 loss_ctc 18.282967 loss_rnnt 13.739737 lr 0.00074561 rank 4
2022-12-03 21:17:14,177 DEBUG TRAIN Batch 5/3400 loss 12.901633 loss_att 21.559328 loss_ctc 24.998837 loss_rnnt 9.557135 lr 0.00074451 rank 1
2022-12-03 21:17:14,178 DEBUG TRAIN Batch 5/3400 loss 28.167080 loss_att 34.732933 loss_ctc 41.383232 loss_rnnt 25.091757 lr 0.00074434 rank 0
2022-12-03 21:17:14,179 DEBUG TRAIN Batch 5/3400 loss 22.522903 loss_att 28.852139 loss_ctc 42.619797 loss_rnnt 18.577473 lr 0.00074484 rank 7
2022-12-03 21:17:14,179 DEBUG TRAIN Batch 5/3400 loss 13.075430 loss_att 19.835140 loss_ctc 31.385361 loss_rnnt 9.282163 lr 0.00074483 rank 6
2022-12-03 21:17:14,181 DEBUG TRAIN Batch 5/3400 loss 10.647375 loss_att 23.301743 loss_ctc 14.144549 loss_rnnt 7.650211 lr 0.00074467 rank 5
2022-12-03 21:17:14,182 DEBUG TRAIN Batch 5/3400 loss 21.853943 loss_att 26.388901 loss_ctc 42.457195 loss_rnnt 18.199850 lr 0.00074445 rank 3
2022-12-03 21:17:14,184 DEBUG TRAIN Batch 5/3400 loss 21.180382 loss_att 28.531834 loss_ctc 34.987572 loss_rnnt 17.869133 lr 0.00074479 rank 4
2022-12-03 21:17:14,225 DEBUG TRAIN Batch 5/3400 loss 25.018700 loss_att 33.211151 loss_ctc 38.909317 loss_rnnt 21.528128 lr 0.00074408 rank 2
2022-12-03 21:18:26,366 DEBUG TRAIN Batch 5/3500 loss 11.239855 loss_att 16.815742 loss_ctc 18.435635 loss_rnnt 9.165239 lr 0.00074396 rank 4
2022-12-03 21:18:26,368 DEBUG TRAIN Batch 5/3500 loss 16.506351 loss_att 24.290665 loss_ctc 25.308294 loss_rnnt 13.775897 lr 0.00074369 rank 1
2022-12-03 21:18:26,377 DEBUG TRAIN Batch 5/3500 loss 28.490192 loss_att 34.877575 loss_ctc 45.294647 loss_rnnt 24.972122 lr 0.00074401 rank 6
2022-12-03 21:18:26,377 DEBUG TRAIN Batch 5/3500 loss 21.787624 loss_att 24.838564 loss_ctc 41.593060 loss_rnnt 18.536713 lr 0.00074362 rank 3
2022-12-03 21:18:26,380 DEBUG TRAIN Batch 5/3500 loss 21.963217 loss_att 27.276314 loss_ctc 31.652925 loss_rnnt 19.608635 lr 0.00074352 rank 0
2022-12-03 21:18:26,383 DEBUG TRAIN Batch 5/3500 loss 20.330236 loss_att 25.207047 loss_ctc 33.299217 loss_rnnt 17.625677 lr 0.00074402 rank 7
2022-12-03 21:18:26,390 DEBUG TRAIN Batch 5/3500 loss 15.331887 loss_att 21.476040 loss_ctc 24.967312 loss_rnnt 12.818335 lr 0.00074325 rank 2
2022-12-03 21:18:26,399 DEBUG TRAIN Batch 5/3500 loss 15.845362 loss_att 22.365515 loss_ctc 26.553085 loss_rnnt 13.113633 lr 0.00074385 rank 5
2022-12-03 21:19:38,887 DEBUG TRAIN Batch 5/3600 loss 24.505173 loss_att 31.632784 loss_ctc 44.221928 loss_rnnt 20.450747 lr 0.00074319 rank 6
2022-12-03 21:19:38,891 DEBUG TRAIN Batch 5/3600 loss 25.338558 loss_att 30.111210 loss_ctc 46.063049 loss_rnnt 21.620760 lr 0.00074302 rank 5
2022-12-03 21:19:38,892 DEBUG TRAIN Batch 5/3600 loss 24.413490 loss_att 25.869823 loss_ctc 38.208820 loss_rnnt 22.282845 lr 0.00074280 rank 3
2022-12-03 21:19:38,892 DEBUG TRAIN Batch 5/3600 loss 12.771082 loss_att 17.225349 loss_ctc 22.208998 loss_rnnt 10.621840 lr 0.00074243 rank 2
2022-12-03 21:19:38,893 DEBUG TRAIN Batch 5/3600 loss 13.891191 loss_att 19.703068 loss_ctc 22.947098 loss_rnnt 11.521361 lr 0.00074314 rank 4
2022-12-03 21:19:38,894 DEBUG TRAIN Batch 5/3600 loss 20.337366 loss_att 22.148973 loss_ctc 33.467125 loss_rnnt 18.224411 lr 0.00074270 rank 0
2022-12-03 21:19:38,897 DEBUG TRAIN Batch 5/3600 loss 18.509672 loss_att 24.685110 loss_ctc 28.071259 loss_rnnt 15.999706 lr 0.00074287 rank 1
2022-12-03 21:19:38,898 DEBUG TRAIN Batch 5/3600 loss 11.957682 loss_att 13.665834 loss_ctc 16.089386 loss_rnnt 11.065157 lr 0.00074320 rank 7
2022-12-03 21:20:51,372 DEBUG TRAIN Batch 5/3700 loss 18.932709 loss_att 21.539680 loss_ctc 30.032515 loss_rnnt 16.931339 lr 0.00074188 rank 0
2022-12-03 21:20:51,377 DEBUG TRAIN Batch 5/3700 loss 21.492100 loss_att 21.221584 loss_ctc 27.279449 loss_rnnt 20.774557 lr 0.00074238 rank 7
2022-12-03 21:20:51,377 DEBUG TRAIN Batch 5/3700 loss 20.095856 loss_att 28.093727 loss_ctc 32.359051 loss_rnnt 16.861189 lr 0.00074237 rank 6
2022-12-03 21:20:51,379 DEBUG TRAIN Batch 5/3700 loss 33.768536 loss_att 42.280670 loss_ctc 56.999107 loss_rnnt 28.968697 lr 0.00074220 rank 5
2022-12-03 21:20:51,379 DEBUG TRAIN Batch 5/3700 loss 23.758125 loss_att 29.988224 loss_ctc 35.543766 loss_rnnt 20.940687 lr 0.00074198 rank 3
2022-12-03 21:20:51,382 DEBUG TRAIN Batch 5/3700 loss 15.756603 loss_att 20.263523 loss_ctc 28.807629 loss_rnnt 13.115082 lr 0.00074205 rank 1
2022-12-03 21:20:51,383 DEBUG TRAIN Batch 5/3700 loss 18.737053 loss_att 22.118786 loss_ctc 25.071445 loss_rnnt 17.216120 lr 0.00074162 rank 2
2022-12-03 21:20:51,389 DEBUG TRAIN Batch 5/3700 loss 18.612310 loss_att 22.238945 loss_ctc 26.467607 loss_rnnt 16.839611 lr 0.00074232 rank 4
2022-12-03 21:22:03,514 DEBUG TRAIN Batch 5/3800 loss 12.591768 loss_att 14.031868 loss_ctc 19.670483 loss_rnnt 11.359919 lr 0.00074155 rank 6
2022-12-03 21:22:03,518 DEBUG TRAIN Batch 5/3800 loss 20.902485 loss_att 20.699774 loss_ctc 30.511108 loss_rnnt 19.661877 lr 0.00074139 rank 5
2022-12-03 21:22:03,518 DEBUG TRAIN Batch 5/3800 loss 12.419893 loss_att 16.422836 loss_ctc 17.400665 loss_rnnt 10.955201 lr 0.00074117 rank 3
2022-12-03 21:22:03,519 DEBUG TRAIN Batch 5/3800 loss 25.699608 loss_att 28.934250 loss_ctc 38.694225 loss_rnnt 23.320065 lr 0.00074123 rank 1
2022-12-03 21:22:03,524 DEBUG TRAIN Batch 5/3800 loss 8.668669 loss_att 10.832203 loss_ctc 14.476008 loss_rnnt 7.461650 lr 0.00074080 rank 2
2022-12-03 21:22:03,524 DEBUG TRAIN Batch 5/3800 loss 15.751386 loss_att 18.322626 loss_ctc 25.105246 loss_rnnt 13.989956 lr 0.00074156 rank 7
2022-12-03 21:22:03,529 DEBUG TRAIN Batch 5/3800 loss 16.729527 loss_att 21.693123 loss_ctc 26.005157 loss_rnnt 14.500055 lr 0.00074106 rank 0
2022-12-03 21:22:03,532 DEBUG TRAIN Batch 5/3800 loss 16.558060 loss_att 18.925869 loss_ctc 20.708115 loss_rnnt 15.531157 lr 0.00074150 rank 4
2022-12-03 21:23:17,307 DEBUG TRAIN Batch 5/3900 loss 21.864153 loss_att 21.551958 loss_ctc 37.827782 loss_rnnt 19.798109 lr 0.00074057 rank 5
2022-12-03 21:23:17,318 DEBUG TRAIN Batch 5/3900 loss 17.831959 loss_att 25.844843 loss_ctc 31.553997 loss_rnnt 14.399778 lr 0.00074074 rank 6
2022-12-03 21:23:17,319 DEBUG TRAIN Batch 5/3900 loss 26.595987 loss_att 32.422333 loss_ctc 49.643433 loss_rnnt 22.357725 lr 0.00074025 rank 0
2022-12-03 21:23:17,320 DEBUG TRAIN Batch 5/3900 loss 24.089413 loss_att 28.529320 loss_ctc 38.152847 loss_rnnt 21.326307 lr 0.00073999 rank 2
2022-12-03 21:23:17,322 DEBUG TRAIN Batch 5/3900 loss 22.893915 loss_att 29.385405 loss_ctc 34.917358 loss_rnnt 19.992493 lr 0.00074035 rank 3
2022-12-03 21:23:17,321 DEBUG TRAIN Batch 5/3900 loss 29.217358 loss_att 34.163338 loss_ctc 43.368542 loss_rnnt 26.341337 lr 0.00074042 rank 1
2022-12-03 21:23:17,325 DEBUG TRAIN Batch 5/3900 loss 31.935095 loss_att 30.766235 loss_ctc 48.941223 loss_rnnt 29.901382 lr 0.00074074 rank 7
2022-12-03 21:23:17,326 DEBUG TRAIN Batch 5/3900 loss 19.998646 loss_att 21.048876 loss_ctc 32.709911 loss_rnnt 18.093765 lr 0.00074069 rank 4
2022-12-03 21:24:29,509 DEBUG TRAIN Batch 5/4000 loss 7.578676 loss_att 10.912339 loss_ctc 14.670024 loss_rnnt 5.966431 lr 0.00073954 rank 3
2022-12-03 21:24:29,511 DEBUG TRAIN Batch 5/4000 loss 19.653318 loss_att 24.317894 loss_ctc 30.799591 loss_rnnt 17.234234 lr 0.00073944 rank 0
2022-12-03 21:24:29,512 DEBUG TRAIN Batch 5/4000 loss 40.830265 loss_att 42.516598 loss_ctc 57.008972 loss_rnnt 38.335835 lr 0.00073993 rank 6
2022-12-03 21:24:29,513 DEBUG TRAIN Batch 5/4000 loss 11.845547 loss_att 19.009157 loss_ctc 27.983191 loss_rnnt 8.261139 lr 0.00073988 rank 4
2022-12-03 21:24:29,514 DEBUG TRAIN Batch 5/4000 loss 26.422276 loss_att 31.154078 loss_ctc 38.992504 loss_rnnt 23.799887 lr 0.00073961 rank 1
2022-12-03 21:24:29,516 DEBUG TRAIN Batch 5/4000 loss 27.576027 loss_att 33.770641 loss_ctc 36.814384 loss_rnnt 25.105322 lr 0.00073976 rank 5
2022-12-03 21:24:29,518 DEBUG TRAIN Batch 5/4000 loss 27.051607 loss_att 33.544106 loss_ctc 39.664364 loss_rnnt 24.071407 lr 0.00073993 rank 7
2022-12-03 21:24:29,563 DEBUG TRAIN Batch 5/4000 loss 27.993284 loss_att 35.101574 loss_ctc 45.468163 loss_rnnt 24.241644 lr 0.00073918 rank 2
2022-12-03 21:25:41,421 DEBUG TRAIN Batch 5/4100 loss 10.980763 loss_att 22.408899 loss_ctc 25.870739 loss_rnnt 6.709806 lr 0.00073895 rank 5
2022-12-03 21:25:41,421 DEBUG TRAIN Batch 5/4100 loss 28.196314 loss_att 35.083195 loss_ctc 45.707741 loss_rnnt 24.484079 lr 0.00073880 rank 1
2022-12-03 21:25:41,428 DEBUG TRAIN Batch 5/4100 loss 27.155293 loss_att 27.642414 loss_ctc 43.708389 loss_rnnt 24.850790 lr 0.00073912 rank 6
2022-12-03 21:25:41,428 DEBUG TRAIN Batch 5/4100 loss 9.138727 loss_att 17.507549 loss_ctc 16.539068 loss_rnnt 6.478250 lr 0.00073863 rank 0
2022-12-03 21:25:41,431 DEBUG TRAIN Batch 5/4100 loss 22.062496 loss_att 25.284077 loss_ctc 42.768642 loss_rnnt 18.657360 lr 0.00073874 rank 3
2022-12-03 21:25:41,439 DEBUG TRAIN Batch 5/4100 loss 18.182430 loss_att 23.148716 loss_ctc 28.127867 loss_rnnt 15.863113 lr 0.00073907 rank 4
2022-12-03 21:25:41,439 DEBUG TRAIN Batch 5/4100 loss 12.724369 loss_att 21.926044 loss_ctc 24.117954 loss_rnnt 9.364888 lr 0.00073837 rank 2
2022-12-03 21:25:41,442 DEBUG TRAIN Batch 5/4100 loss 23.953539 loss_att 30.679981 loss_ctc 37.544266 loss_rnnt 20.796154 lr 0.00073912 rank 7
2022-12-03 21:26:53,927 DEBUG TRAIN Batch 5/4200 loss 23.574989 loss_att 30.213249 loss_ctc 35.010036 loss_rnnt 20.722664 lr 0.00073793 rank 3
2022-12-03 21:26:53,928 DEBUG TRAIN Batch 5/4200 loss 23.088272 loss_att 29.193520 loss_ctc 34.430424 loss_rnnt 20.354935 lr 0.00073831 rank 6
2022-12-03 21:26:53,928 DEBUG TRAIN Batch 5/4200 loss 25.459658 loss_att 28.736038 loss_ctc 36.936085 loss_rnnt 23.274191 lr 0.00073783 rank 0
2022-12-03 21:26:53,930 DEBUG TRAIN Batch 5/4200 loss 28.740393 loss_att 30.500046 loss_ctc 45.842426 loss_rnnt 26.108189 lr 0.00073832 rank 7
2022-12-03 21:26:53,931 DEBUG TRAIN Batch 5/4200 loss 30.599874 loss_att 36.765018 loss_ctc 51.149803 loss_rnnt 26.626854 lr 0.00073815 rank 5
2022-12-03 21:26:53,933 DEBUG TRAIN Batch 5/4200 loss 20.467072 loss_att 22.184504 loss_ctc 27.188469 loss_rnnt 19.227400 lr 0.00073800 rank 1
2022-12-03 21:26:53,935 DEBUG TRAIN Batch 5/4200 loss 26.140305 loss_att 32.321301 loss_ctc 39.146713 loss_rnnt 23.169918 lr 0.00073826 rank 4
2022-12-03 21:26:53,946 DEBUG TRAIN Batch 5/4200 loss 21.380375 loss_att 27.677441 loss_ctc 35.238411 loss_rnnt 18.273222 lr 0.00073757 rank 2
2022-12-03 21:28:07,395 DEBUG TRAIN Batch 5/4300 loss 17.664047 loss_att 19.489441 loss_ctc 25.356724 loss_rnnt 16.273277 lr 0.00073735 rank 5
2022-12-03 21:28:07,396 DEBUG TRAIN Batch 5/4300 loss 22.031696 loss_att 25.314106 loss_ctc 29.978275 loss_rnnt 20.315672 lr 0.00073713 rank 3
2022-12-03 21:28:07,396 DEBUG TRAIN Batch 5/4300 loss 22.257675 loss_att 27.331486 loss_ctc 39.323624 loss_rnnt 18.967455 lr 0.00073751 rank 7
2022-12-03 21:28:07,397 DEBUG TRAIN Batch 5/4300 loss 17.266836 loss_att 24.760166 loss_ctc 31.857582 loss_rnnt 13.822737 lr 0.00073751 rank 6
2022-12-03 21:28:07,397 DEBUG TRAIN Batch 5/4300 loss 17.384035 loss_att 25.116615 loss_ctc 30.834019 loss_rnnt 14.044188 lr 0.00073719 rank 1
2022-12-03 21:28:07,402 DEBUG TRAIN Batch 5/4300 loss 21.314003 loss_att 24.952156 loss_ctc 29.702412 loss_rnnt 19.467918 lr 0.00073746 rank 4
2022-12-03 21:28:07,415 DEBUG TRAIN Batch 5/4300 loss 15.184837 loss_att 17.272831 loss_ctc 25.221525 loss_rnnt 13.429013 lr 0.00073703 rank 0
2022-12-03 21:28:07,450 DEBUG TRAIN Batch 5/4300 loss 11.455967 loss_att 16.597588 loss_ctc 18.153276 loss_rnnt 9.534668 lr 0.00073677 rank 2
2022-12-03 21:29:19,861 DEBUG TRAIN Batch 5/4400 loss 28.194429 loss_att 29.100796 loss_ctc 41.502743 loss_rnnt 26.238712 lr 0.00073633 rank 3
2022-12-03 21:29:19,862 DEBUG TRAIN Batch 5/4400 loss 18.004610 loss_att 19.338198 loss_ctc 23.107325 loss_rnnt 17.057529 lr 0.00073671 rank 6
2022-12-03 21:29:19,866 DEBUG TRAIN Batch 5/4400 loss 15.922957 loss_att 17.259287 loss_ctc 26.529770 loss_rnnt 14.241450 lr 0.00073597 rank 2
2022-12-03 21:29:19,867 DEBUG TRAIN Batch 5/4400 loss 14.404638 loss_att 15.710183 loss_ctc 19.163742 loss_rnnt 13.508982 lr 0.00073671 rank 7
2022-12-03 21:29:19,867 DEBUG TRAIN Batch 5/4400 loss 13.801191 loss_att 15.976971 loss_ctc 24.645866 loss_rnnt 11.920079 lr 0.00073639 rank 1
2022-12-03 21:29:19,868 DEBUG TRAIN Batch 5/4400 loss 13.243272 loss_att 16.384968 loss_ctc 19.047562 loss_rnnt 11.841026 lr 0.00073623 rank 0
2022-12-03 21:29:19,871 DEBUG TRAIN Batch 5/4400 loss 27.796446 loss_att 29.971195 loss_ctc 49.005821 loss_rnnt 24.533581 lr 0.00073666 rank 4
2022-12-03 21:29:19,917 DEBUG TRAIN Batch 5/4400 loss 8.168253 loss_att 14.085048 loss_ctc 17.081551 loss_rnnt 5.796454 lr 0.00073655 rank 5
2022-12-03 21:30:32,446 DEBUG TRAIN Batch 5/4500 loss 11.646828 loss_att 11.374401 loss_ctc 15.432780 loss_rnnt 11.196519 lr 0.00073591 rank 6
2022-12-03 21:30:32,449 DEBUG TRAIN Batch 5/4500 loss 14.327893 loss_att 17.025234 loss_ctc 22.507631 loss_rnnt 12.697793 lr 0.00073543 rank 0
2022-12-03 21:30:32,455 DEBUG TRAIN Batch 5/4500 loss 15.665012 loss_att 16.242069 loss_ctc 21.530087 loss_rnnt 14.767591 lr 0.00073553 rank 3
2022-12-03 21:30:32,457 DEBUG TRAIN Batch 5/4500 loss 16.153753 loss_att 22.472023 loss_ctc 23.762854 loss_rnnt 13.875553 lr 0.00073592 rank 7
2022-12-03 21:30:32,458 DEBUG TRAIN Batch 5/4500 loss 9.363759 loss_att 10.176889 loss_ctc 12.388040 loss_rnnt 8.797896 lr 0.00073560 rank 1
2022-12-03 21:30:32,457 DEBUG TRAIN Batch 5/4500 loss 8.941160 loss_att 18.031384 loss_ctc 22.158997 loss_rnnt 5.360737 lr 0.00073517 rank 2
2022-12-03 21:30:32,466 DEBUG TRAIN Batch 5/4500 loss 9.283358 loss_att 12.075649 loss_ctc 13.917336 loss_rnnt 8.107036 lr 0.00073586 rank 4
2022-12-03 21:30:32,502 DEBUG TRAIN Batch 5/4500 loss 14.525587 loss_att 15.486708 loss_ctc 22.947384 loss_rnnt 13.210457 lr 0.00073575 rank 5
2022-12-03 21:31:45,729 DEBUG TRAIN Batch 5/4600 loss 30.247440 loss_att 32.147678 loss_ctc 48.427635 loss_rnnt 27.443365 lr 0.00073511 rank 6
2022-12-03 21:31:45,732 DEBUG TRAIN Batch 5/4600 loss 16.835543 loss_att 19.387909 loss_ctc 27.256100 loss_rnnt 14.935661 lr 0.00073495 rank 5
2022-12-03 21:31:45,731 DEBUG TRAIN Batch 5/4600 loss 23.367222 loss_att 31.217167 loss_ctc 41.423439 loss_rnnt 19.389736 lr 0.00073474 rank 3
2022-12-03 21:31:45,736 DEBUG TRAIN Batch 5/4600 loss 19.307249 loss_att 25.239330 loss_ctc 30.401602 loss_rnnt 16.641586 lr 0.00073464 rank 0
2022-12-03 21:31:45,737 DEBUG TRAIN Batch 5/4600 loss 14.722126 loss_att 22.312721 loss_ctc 23.991070 loss_rnnt 11.968147 lr 0.00073438 rank 2
2022-12-03 21:31:45,738 DEBUG TRAIN Batch 5/4600 loss 14.442362 loss_att 18.202988 loss_ctc 27.062466 loss_rnnt 12.007556 lr 0.00073512 rank 7
2022-12-03 21:31:45,768 DEBUG TRAIN Batch 5/4600 loss 8.594557 loss_att 14.081757 loss_ctc 16.169746 loss_rnnt 6.487091 lr 0.00073506 rank 4
2022-12-03 21:31:45,776 DEBUG TRAIN Batch 5/4600 loss 18.587543 loss_att 20.631100 loss_ctc 29.007915 loss_rnnt 16.789448 lr 0.00073480 rank 1
2022-12-03 21:32:58,254 DEBUG TRAIN Batch 5/4700 loss 13.896396 loss_att 22.855724 loss_ctc 23.060089 loss_rnnt 10.882704 lr 0.00073416 rank 5
2022-12-03 21:32:58,254 DEBUG TRAIN Batch 5/4700 loss 27.117929 loss_att 32.206429 loss_ctc 44.135979 loss_rnnt 23.831158 lr 0.00073432 rank 6
2022-12-03 21:32:58,257 DEBUG TRAIN Batch 5/4700 loss 16.098938 loss_att 21.970856 loss_ctc 25.116087 loss_rnnt 13.722267 lr 0.00073359 rank 2
2022-12-03 21:32:58,258 DEBUG TRAIN Batch 5/4700 loss 29.891850 loss_att 35.361942 loss_ctc 47.351097 loss_rnnt 26.469929 lr 0.00073384 rank 0
2022-12-03 21:32:58,261 DEBUG TRAIN Batch 5/4700 loss 19.067799 loss_att 21.606401 loss_ctc 30.943142 loss_rnnt 16.976698 lr 0.00073395 rank 3
2022-12-03 21:32:58,262 DEBUG TRAIN Batch 5/4700 loss 36.769062 loss_att 45.033321 loss_ctc 61.099144 loss_rnnt 31.872200 lr 0.00073427 rank 4
2022-12-03 21:32:58,264 DEBUG TRAIN Batch 5/4700 loss 18.961853 loss_att 26.763126 loss_ctc 32.638348 loss_rnnt 15.578065 lr 0.00073433 rank 7
2022-12-03 21:32:58,308 DEBUG TRAIN Batch 5/4700 loss 16.311390 loss_att 21.804556 loss_ctc 24.034597 loss_rnnt 14.182995 lr 0.00073401 rank 1
2022-12-03 21:34:10,206 DEBUG TRAIN Batch 5/4800 loss 28.223122 loss_att 32.650898 loss_ctc 37.774872 loss_rnnt 26.063999 lr 0.00073305 rank 0
2022-12-03 21:34:10,214 DEBUG TRAIN Batch 5/4800 loss 28.741467 loss_att 33.855648 loss_ctc 48.540741 loss_rnnt 25.078724 lr 0.00073322 rank 1
2022-12-03 21:34:10,216 DEBUG TRAIN Batch 5/4800 loss 21.311314 loss_att 22.208767 loss_ctc 29.204990 loss_rnnt 20.079330 lr 0.00073337 rank 5
2022-12-03 21:34:10,217 DEBUG TRAIN Batch 5/4800 loss 34.431980 loss_att 37.936577 loss_ctc 48.079536 loss_rnnt 31.911388 lr 0.00073316 rank 3
2022-12-03 21:34:10,218 DEBUG TRAIN Batch 5/4800 loss 16.307568 loss_att 20.744030 loss_ctc 30.778511 loss_rnnt 13.490814 lr 0.00073353 rank 6
2022-12-03 21:34:10,219 DEBUG TRAIN Batch 5/4800 loss 19.016163 loss_att 19.878553 loss_ctc 27.285706 loss_rnnt 17.741079 lr 0.00073354 rank 7
2022-12-03 21:34:10,219 DEBUG TRAIN Batch 5/4800 loss 14.351621 loss_att 18.015017 loss_ctc 24.659229 loss_rnnt 12.244593 lr 0.00073280 rank 2
2022-12-03 21:34:10,223 DEBUG TRAIN Batch 5/4800 loss 33.216053 loss_att 35.919186 loss_ctc 51.242126 loss_rnnt 30.271954 lr 0.00073348 rank 4
2022-12-03 21:35:22,938 DEBUG TRAIN Batch 5/4900 loss 16.737350 loss_att 19.992523 loss_ctc 25.079748 loss_rnnt 14.973995 lr 0.00073202 rank 2
2022-12-03 21:35:22,944 DEBUG TRAIN Batch 5/4900 loss 25.961231 loss_att 28.448662 loss_ctc 37.994518 loss_rnnt 23.859306 lr 0.00073274 rank 6
2022-12-03 21:35:22,945 DEBUG TRAIN Batch 5/4900 loss 18.589247 loss_att 22.411657 loss_ctc 27.200294 loss_rnnt 16.676624 lr 0.00073243 rank 1
2022-12-03 21:35:22,946 DEBUG TRAIN Batch 5/4900 loss 22.466307 loss_att 27.838308 loss_ctc 43.556007 loss_rnnt 18.579945 lr 0.00073227 rank 0
2022-12-03 21:35:22,951 DEBUG TRAIN Batch 5/4900 loss 24.744530 loss_att 31.054947 loss_ctc 34.501610 loss_rnnt 22.181503 lr 0.00073237 rank 3
2022-12-03 21:35:22,952 DEBUG TRAIN Batch 5/4900 loss 20.788723 loss_att 25.915537 loss_ctc 33.232101 loss_rnnt 18.104242 lr 0.00073275 rank 7
2022-12-03 21:35:22,954 DEBUG TRAIN Batch 5/4900 loss 23.934711 loss_att 25.112507 loss_ctc 40.853119 loss_rnnt 21.443363 lr 0.00073269 rank 4
2022-12-03 21:35:22,966 DEBUG TRAIN Batch 5/4900 loss 32.386482 loss_att 34.407856 loss_ctc 50.590607 loss_rnnt 29.554993 lr 0.00073258 rank 5
2022-12-03 21:36:36,301 DEBUG TRAIN Batch 5/5000 loss 15.659111 loss_att 21.598368 loss_ctc 25.346432 loss_rnnt 13.179617 lr 0.00073180 rank 5
2022-12-03 21:36:36,301 DEBUG TRAIN Batch 5/5000 loss 18.502113 loss_att 20.569382 loss_ctc 28.480576 loss_rnnt 16.758198 lr 0.00073165 rank 1
2022-12-03 21:36:36,302 DEBUG TRAIN Batch 5/5000 loss 24.645172 loss_att 25.287910 loss_ctc 37.153069 loss_rnnt 22.848906 lr 0.00073195 rank 6
2022-12-03 21:36:36,306 DEBUG TRAIN Batch 5/5000 loss 13.347713 loss_att 19.213663 loss_ctc 24.017168 loss_rnnt 10.751929 lr 0.00073148 rank 0
2022-12-03 21:36:36,306 DEBUG TRAIN Batch 5/5000 loss 23.161270 loss_att 28.682177 loss_ctc 38.600281 loss_rnnt 19.998554 lr 0.00073123 rank 2
2022-12-03 21:36:36,307 DEBUG TRAIN Batch 5/5000 loss 19.423166 loss_att 27.896793 loss_ctc 33.558376 loss_rnnt 15.843746 lr 0.00073191 rank 4
2022-12-03 21:36:36,311 DEBUG TRAIN Batch 5/5000 loss 27.462803 loss_att 28.793213 loss_ctc 40.530678 loss_rnnt 25.454338 lr 0.00073159 rank 3
2022-12-03 21:36:36,314 DEBUG TRAIN Batch 5/5000 loss 25.795736 loss_att 27.677557 loss_ctc 39.234940 loss_rnnt 23.627478 lr 0.00073196 rank 7
2022-12-03 21:37:48,503 DEBUG TRAIN Batch 5/5100 loss 14.207483 loss_att 17.070374 loss_ctc 20.332066 loss_rnnt 12.818294 lr 0.00073070 rank 0
2022-12-03 21:37:48,507 DEBUG TRAIN Batch 5/5100 loss 18.800386 loss_att 24.633083 loss_ctc 30.000546 loss_rnnt 16.140493 lr 0.00073118 rank 7
2022-12-03 21:37:48,508 DEBUG TRAIN Batch 5/5100 loss 17.011036 loss_att 21.661892 loss_ctc 28.979498 loss_rnnt 14.485068 lr 0.00073117 rank 6
2022-12-03 21:37:48,508 DEBUG TRAIN Batch 5/5100 loss 12.110013 loss_att 12.812140 loss_ctc 17.401331 loss_rnnt 11.264079 lr 0.00073045 rank 2
2022-12-03 21:37:48,511 DEBUG TRAIN Batch 5/5100 loss 21.598261 loss_att 21.297106 loss_ctc 26.951685 loss_rnnt 20.944702 lr 0.00073080 rank 3
2022-12-03 21:37:48,511 DEBUG TRAIN Batch 5/5100 loss 12.538001 loss_att 13.864826 loss_ctc 20.944036 loss_rnnt 11.151830 lr 0.00073087 rank 1
2022-12-03 21:37:48,517 DEBUG TRAIN Batch 5/5100 loss 11.071901 loss_att 13.883714 loss_ctc 19.833326 loss_rnnt 9.341349 lr 0.00073101 rank 5
2022-12-03 21:37:48,517 DEBUG TRAIN Batch 5/5100 loss 21.900118 loss_att 24.403154 loss_ctc 29.233318 loss_rnnt 20.421751 lr 0.00073112 rank 4
2022-12-03 21:38:59,907 DEBUG TRAIN Batch 5/5200 loss 18.198048 loss_att 22.824720 loss_ctc 29.916119 loss_rnnt 15.710304 lr 0.00073039 rank 6
2022-12-03 21:38:59,910 DEBUG TRAIN Batch 5/5200 loss 33.053581 loss_att 33.111412 loss_ctc 49.530556 loss_rnnt 30.845081 lr 0.00072992 rank 0
2022-12-03 21:38:59,910 DEBUG TRAIN Batch 5/5200 loss 22.155113 loss_att 25.230049 loss_ctc 31.721306 loss_rnnt 20.264633 lr 0.00073023 rank 5
2022-12-03 21:38:59,918 DEBUG TRAIN Batch 5/5200 loss 30.888597 loss_att 36.161507 loss_ctc 48.808331 loss_rnnt 27.444717 lr 0.00073002 rank 3
2022-12-03 21:38:59,918 DEBUG TRAIN Batch 5/5200 loss 19.610727 loss_att 20.636911 loss_ctc 34.400600 loss_rnnt 17.433506 lr 0.00073009 rank 1
2022-12-03 21:38:59,918 DEBUG TRAIN Batch 5/5200 loss 21.396194 loss_att 22.377209 loss_ctc 35.292110 loss_rnnt 19.347204 lr 0.00073034 rank 4
2022-12-03 21:38:59,920 DEBUG TRAIN Batch 5/5200 loss 33.444374 loss_att 36.519287 loss_ctc 47.081566 loss_rnnt 31.011099 lr 0.00073040 rank 7
2022-12-03 21:38:59,921 DEBUG TRAIN Batch 5/5200 loss 7.223500 loss_att 11.947096 loss_ctc 16.712721 loss_rnnt 5.013552 lr 0.00072967 rank 2
2022-12-03 21:40:13,493 DEBUG TRAIN Batch 5/5300 loss 13.067847 loss_att 15.779779 loss_ctc 19.645987 loss_rnnt 11.648376 lr 0.00072946 rank 5
2022-12-03 21:40:13,506 DEBUG TRAIN Batch 5/5300 loss 15.310895 loss_att 22.957272 loss_ctc 29.750484 loss_rnnt 11.856340 lr 0.00072961 rank 6
2022-12-03 21:40:13,507 DEBUG TRAIN Batch 5/5300 loss 27.569088 loss_att 36.377571 loss_ctc 44.520378 loss_rnnt 23.547218 lr 0.00072915 rank 0
2022-12-03 21:40:13,511 DEBUG TRAIN Batch 5/5300 loss 12.568864 loss_att 17.725914 loss_ctc 21.117741 loss_rnnt 10.397604 lr 0.00072925 rank 3
2022-12-03 21:40:13,512 DEBUG TRAIN Batch 5/5300 loss 25.201468 loss_att 27.546097 loss_ctc 41.995125 loss_rnnt 22.493389 lr 0.00072962 rank 7
2022-12-03 21:40:13,514 DEBUG TRAIN Batch 5/5300 loss 15.624359 loss_att 22.127491 loss_ctc 34.991760 loss_rnnt 11.741412 lr 0.00072957 rank 4
2022-12-03 21:40:13,514 DEBUG TRAIN Batch 5/5300 loss 25.152580 loss_att 32.777100 loss_ctc 45.231640 loss_rnnt 20.950468 lr 0.00072931 rank 1
2022-12-03 21:40:13,534 DEBUG TRAIN Batch 5/5300 loss 33.543488 loss_att 39.235985 loss_ctc 57.248680 loss_rnnt 29.244293 lr 0.00072890 rank 2
2022-12-03 21:41:25,788 DEBUG TRAIN Batch 5/5400 loss 19.673779 loss_att 23.269547 loss_ctc 35.699802 loss_rnnt 16.817822 lr 0.00072884 rank 6
2022-12-03 21:41:25,807 DEBUG TRAIN Batch 5/5400 loss 18.265680 loss_att 24.611748 loss_ctc 32.013233 loss_rnnt 15.163459 lr 0.00072847 rank 3
2022-12-03 21:41:25,809 DEBUG TRAIN Batch 5/5400 loss 18.590401 loss_att 24.008415 loss_ctc 36.969070 loss_rnnt 15.056309 lr 0.00072837 rank 0
2022-12-03 21:41:25,811 DEBUG TRAIN Batch 5/5400 loss 16.241049 loss_att 22.101206 loss_ctc 27.130276 loss_rnnt 13.617120 lr 0.00072868 rank 5
2022-12-03 21:41:25,812 DEBUG TRAIN Batch 5/5400 loss 11.842975 loss_att 20.034451 loss_ctc 20.238232 loss_rnnt 9.085312 lr 0.00072853 rank 1
2022-12-03 21:41:25,813 DEBUG TRAIN Batch 5/5400 loss 17.079062 loss_att 21.661995 loss_ctc 33.841003 loss_rnnt 13.927547 lr 0.00072884 rank 7
2022-12-03 21:41:25,818 DEBUG TRAIN Batch 5/5400 loss 20.982254 loss_att 24.535215 loss_ctc 31.192703 loss_rnnt 18.910267 lr 0.00072879 rank 4
2022-12-03 21:41:25,862 DEBUG TRAIN Batch 5/5400 loss 19.430475 loss_att 25.777094 loss_ctc 35.970154 loss_rnnt 15.955862 lr 0.00072813 rank 2
2022-12-03 21:42:36,975 DEBUG TRAIN Batch 5/5500 loss 30.722782 loss_att 32.675392 loss_ctc 52.681847 loss_rnnt 27.404385 lr 0.00072760 rank 0
2022-12-03 21:42:36,988 DEBUG TRAIN Batch 5/5500 loss 12.978380 loss_att 17.133217 loss_ctc 20.220953 loss_rnnt 11.181736 lr 0.00072806 rank 6
2022-12-03 21:42:36,996 DEBUG TRAIN Batch 5/5500 loss 28.068529 loss_att 31.734703 loss_ctc 45.340073 loss_rnnt 25.032421 lr 0.00072776 rank 1
2022-12-03 21:42:36,997 DEBUG TRAIN Batch 5/5500 loss 19.624393 loss_att 26.848850 loss_ctc 27.851980 loss_rnnt 17.082489 lr 0.00072770 rank 3
2022-12-03 21:42:36,998 DEBUG TRAIN Batch 5/5500 loss 13.628683 loss_att 17.868927 loss_ctc 22.704762 loss_rnnt 11.570490 lr 0.00072791 rank 5
2022-12-03 21:42:36,998 DEBUG TRAIN Batch 5/5500 loss 19.904036 loss_att 25.090557 loss_ctc 35.105003 loss_rnnt 16.839935 lr 0.00072807 rank 7
2022-12-03 21:42:37,003 DEBUG TRAIN Batch 5/5500 loss 14.211716 loss_att 21.816542 loss_ctc 24.859726 loss_rnnt 11.271015 lr 0.00072802 rank 4
2022-12-03 21:42:37,003 DEBUG TRAIN Batch 5/5500 loss 24.233730 loss_att 26.103788 loss_ctc 35.467804 loss_rnnt 22.361843 lr 0.00072735 rank 2
2022-12-03 21:43:48,695 DEBUG TRAIN Batch 5/5600 loss 23.727482 loss_att 28.024982 loss_ctc 37.947388 loss_rnnt 20.971996 lr 0.00072693 rank 3
2022-12-03 21:43:48,699 DEBUG TRAIN Batch 5/5600 loss 27.504854 loss_att 29.197662 loss_ctc 43.722343 loss_rnnt 25.003960 lr 0.00072714 rank 5
2022-12-03 21:43:48,700 DEBUG TRAIN Batch 5/5600 loss 19.391996 loss_att 30.086342 loss_ctc 25.437382 loss_rnnt 16.447075 lr 0.00072699 rank 1
2022-12-03 21:43:48,702 DEBUG TRAIN Batch 5/5600 loss 19.788879 loss_att 22.666164 loss_ctc 32.206749 loss_rnnt 17.557705 lr 0.00072725 rank 4
2022-12-03 21:43:48,703 DEBUG TRAIN Batch 5/5600 loss 18.483608 loss_att 21.957462 loss_ctc 36.809948 loss_rnnt 15.345324 lr 0.00072730 rank 7
2022-12-03 21:43:48,703 DEBUG TRAIN Batch 5/5600 loss 26.160618 loss_att 31.082314 loss_ctc 41.974823 loss_rnnt 23.067717 lr 0.00072729 rank 6
2022-12-03 21:43:48,705 DEBUG TRAIN Batch 5/5600 loss 17.995569 loss_att 21.715544 loss_ctc 28.307667 loss_rnnt 15.876629 lr 0.00072683 rank 0
2022-12-03 21:43:48,750 DEBUG TRAIN Batch 5/5600 loss 13.083741 loss_att 18.833389 loss_ctc 24.873720 loss_rnnt 10.361814 lr 0.00072659 rank 2
2022-12-03 21:45:03,258 DEBUG TRAIN Batch 5/5700 loss 17.137455 loss_att 19.379885 loss_ctc 29.829285 loss_rnnt 14.996726 lr 0.00072616 rank 3
2022-12-03 21:45:03,261 DEBUG TRAIN Batch 5/5700 loss 17.041460 loss_att 24.686831 loss_ctc 27.595392 loss_rnnt 14.105194 lr 0.00072606 rank 0
2022-12-03 21:45:03,268 DEBUG TRAIN Batch 5/5700 loss 26.238369 loss_att 30.891500 loss_ctc 35.480202 loss_rnnt 24.075500 lr 0.00072648 rank 4
2022-12-03 21:45:03,270 DEBUG TRAIN Batch 5/5700 loss 16.619205 loss_att 22.979473 loss_ctc 32.561043 loss_rnnt 13.221573 lr 0.00072652 rank 6
2022-12-03 21:45:03,271 DEBUG TRAIN Batch 5/5700 loss 9.768998 loss_att 10.763141 loss_ctc 15.232783 loss_rnnt 8.841664 lr 0.00072653 rank 7
2022-12-03 21:45:03,271 DEBUG TRAIN Batch 5/5700 loss 17.105289 loss_att 18.767056 loss_ctc 24.527279 loss_rnnt 15.783337 lr 0.00072623 rank 1
2022-12-03 21:45:03,272 DEBUG TRAIN Batch 5/5700 loss 20.343273 loss_att 23.062122 loss_ctc 30.132965 loss_rnnt 18.494211 lr 0.00072582 rank 2
2022-12-03 21:45:03,312 DEBUG TRAIN Batch 5/5700 loss 24.753281 loss_att 32.482002 loss_ctc 42.310890 loss_rnnt 20.866520 lr 0.00072637 rank 5
2022-12-03 21:46:15,746 DEBUG TRAIN Batch 5/5800 loss 10.973303 loss_att 17.156954 loss_ctc 18.513466 loss_rnnt 8.731217 lr 0.00072561 rank 5
2022-12-03 21:46:15,747 DEBUG TRAIN Batch 5/5800 loss 14.615516 loss_att 16.314606 loss_ctc 20.487755 loss_rnnt 13.492732 lr 0.00072576 rank 6
2022-12-03 21:46:15,749 DEBUG TRAIN Batch 5/5800 loss 17.536116 loss_att 28.429613 loss_ctc 26.895849 loss_rnnt 14.109451 lr 0.00072530 rank 0
2022-12-03 21:46:15,748 DEBUG TRAIN Batch 5/5800 loss 34.204514 loss_att 39.401802 loss_ctc 49.654400 loss_rnnt 31.105068 lr 0.00072546 rank 1
2022-12-03 21:46:15,753 DEBUG TRAIN Batch 5/5800 loss 30.481640 loss_att 33.165272 loss_ctc 37.231750 loss_rnnt 29.044899 lr 0.00072540 rank 3
2022-12-03 21:46:15,753 DEBUG TRAIN Batch 5/5800 loss 17.563971 loss_att 22.650948 loss_ctc 33.338333 loss_rnnt 14.443325 lr 0.00072577 rank 7
2022-12-03 21:46:15,754 DEBUG TRAIN Batch 5/5800 loss 17.493481 loss_att 21.534052 loss_ctc 30.748056 loss_rnnt 14.918088 lr 0.00072571 rank 4
2022-12-03 21:46:15,756 DEBUG TRAIN Batch 5/5800 loss 20.806353 loss_att 23.739614 loss_ctc 31.464834 loss_rnnt 18.798571 lr 0.00072506 rank 2
2022-12-03 21:47:26,811 DEBUG TRAIN Batch 5/5900 loss 30.994667 loss_att 31.044334 loss_ctc 46.626015 loss_rnnt 28.900555 lr 0.00072454 rank 0
2022-12-03 21:47:26,813 DEBUG TRAIN Batch 5/5900 loss 14.597464 loss_att 23.254103 loss_ctc 29.938637 loss_rnnt 10.820646 lr 0.00072500 rank 6
2022-12-03 21:47:26,814 DEBUG TRAIN Batch 5/5900 loss 25.599968 loss_att 27.389078 loss_ctc 43.994156 loss_rnnt 22.789587 lr 0.00072464 rank 3
2022-12-03 21:47:26,814 DEBUG TRAIN Batch 5/5900 loss 19.232540 loss_att 24.293924 loss_ctc 29.995235 loss_rnnt 16.785236 lr 0.00072470 rank 1
2022-12-03 21:47:26,815 DEBUG TRAIN Batch 5/5900 loss 15.464380 loss_att 22.411909 loss_ctc 33.531601 loss_rnnt 11.665911 lr 0.00072430 rank 2
2022-12-03 21:47:26,827 DEBUG TRAIN Batch 5/5900 loss 19.123337 loss_att 24.200451 loss_ctc 34.117207 loss_rnnt 16.108732 lr 0.00072495 rank 4
2022-12-03 21:47:26,832 DEBUG TRAIN Batch 5/5900 loss 17.804155 loss_att 25.696699 loss_ctc 29.997021 loss_rnnt 14.599930 lr 0.00072500 rank 7
2022-12-03 21:47:26,851 DEBUG TRAIN Batch 5/5900 loss 26.911781 loss_att 26.841381 loss_ctc 42.879341 loss_rnnt 24.796856 lr 0.00072484 rank 5
2022-12-03 21:48:40,315 DEBUG TRAIN Batch 5/6000 loss 22.694361 loss_att 23.170052 loss_ctc 31.667484 loss_rnnt 21.402807 lr 0.00072408 rank 5
2022-12-03 21:48:40,321 DEBUG TRAIN Batch 5/6000 loss 20.130564 loss_att 27.698130 loss_ctc 32.831161 loss_rnnt 16.923637 lr 0.00072423 rank 6
2022-12-03 21:48:40,328 DEBUG TRAIN Batch 5/6000 loss 27.087185 loss_att 37.305676 loss_ctc 47.164543 loss_rnnt 22.366505 lr 0.00072378 rank 0
2022-12-03 21:48:40,330 DEBUG TRAIN Batch 5/6000 loss 6.685824 loss_att 10.276783 loss_ctc 9.215529 loss_rnnt 5.630339 lr 0.00072394 rank 1
2022-12-03 21:48:40,329 DEBUG TRAIN Batch 5/6000 loss 25.242558 loss_att 31.632710 loss_ctc 45.243675 loss_rnnt 21.297712 lr 0.00072419 rank 4
2022-12-03 21:48:40,332 DEBUG TRAIN Batch 5/6000 loss 10.559036 loss_att 13.440190 loss_ctc 24.770597 loss_rnnt 8.087931 lr 0.00072388 rank 3
2022-12-03 21:48:40,347 DEBUG TRAIN Batch 5/6000 loss 22.012531 loss_att 29.048836 loss_ctc 34.351521 loss_rnnt 18.960070 lr 0.00072424 rank 7
2022-12-03 21:48:40,350 DEBUG TRAIN Batch 5/6000 loss 22.890266 loss_att 25.912935 loss_ctc 39.126251 loss_rnnt 20.120935 lr 0.00072354 rank 2
2022-12-03 21:49:53,461 DEBUG TRAIN Batch 5/6100 loss 22.262533 loss_att 27.045834 loss_ctc 33.746407 loss_rnnt 19.774689 lr 0.00072348 rank 6
2022-12-03 21:49:53,463 DEBUG TRAIN Batch 5/6100 loss 14.229973 loss_att 18.315186 loss_ctc 23.969845 loss_rnnt 12.114281 lr 0.00072278 rank 2
2022-12-03 21:49:53,463 DEBUG TRAIN Batch 5/6100 loss 30.484123 loss_att 35.750038 loss_ctc 44.771248 loss_rnnt 27.525990 lr 0.00072302 rank 0
2022-12-03 21:49:53,464 DEBUG TRAIN Batch 5/6100 loss 14.750751 loss_att 20.306831 loss_ctc 23.790615 loss_rnnt 12.434219 lr 0.00072312 rank 3
2022-12-03 21:49:53,464 DEBUG TRAIN Batch 5/6100 loss 11.780361 loss_att 15.212634 loss_ctc 20.923523 loss_rnnt 9.874818 lr 0.00072332 rank 5
2022-12-03 21:49:53,464 DEBUG TRAIN Batch 5/6100 loss 28.617052 loss_att 35.501072 loss_ctc 44.559540 loss_rnnt 25.114582 lr 0.00072343 rank 4
2022-12-03 21:49:53,468 DEBUG TRAIN Batch 5/6100 loss 24.063639 loss_att 24.800045 loss_ctc 29.757074 loss_rnnt 23.157230 lr 0.00072348 rank 7
2022-12-03 21:49:53,514 DEBUG TRAIN Batch 5/6100 loss 21.794249 loss_att 23.506163 loss_ctc 37.303226 loss_rnnt 19.384003 lr 0.00072318 rank 1
2022-12-03 21:51:06,160 DEBUG TRAIN Batch 5/6200 loss 18.958452 loss_att 22.862410 loss_ctc 35.018970 loss_rnnt 16.036259 lr 0.00072257 rank 5
2022-12-03 21:51:06,164 DEBUG TRAIN Batch 5/6200 loss 13.126640 loss_att 20.603058 loss_ctc 28.116882 loss_rnnt 9.632658 lr 0.00072227 rank 0
2022-12-03 21:51:06,165 DEBUG TRAIN Batch 5/6200 loss 18.135731 loss_att 19.650639 loss_ctc 24.707745 loss_rnnt 16.956480 lr 0.00072203 rank 2
2022-12-03 21:51:06,165 DEBUG TRAIN Batch 5/6200 loss 8.566052 loss_att 11.742881 loss_ctc 14.067034 loss_rnnt 7.197222 lr 0.00072243 rank 1
2022-12-03 21:51:06,166 DEBUG TRAIN Batch 5/6200 loss 13.117271 loss_att 17.946272 loss_ctc 23.255487 loss_rnnt 10.799708 lr 0.00072272 rank 6
2022-12-03 21:51:06,168 DEBUG TRAIN Batch 5/6200 loss 12.849452 loss_att 13.952914 loss_ctc 21.039917 loss_rnnt 11.536697 lr 0.00072237 rank 3
2022-12-03 21:51:06,168 DEBUG TRAIN Batch 5/6200 loss 17.638477 loss_att 21.631950 loss_ctc 30.630306 loss_rnnt 15.107538 lr 0.00072273 rank 7
2022-12-03 21:51:06,172 DEBUG TRAIN Batch 5/6200 loss 10.250921 loss_att 15.426967 loss_ctc 19.889887 loss_rnnt 7.930516 lr 0.00072267 rank 4
2022-12-03 21:52:18,354 DEBUG TRAIN Batch 5/6300 loss 16.177158 loss_att 20.544125 loss_ctc 26.876892 loss_rnnt 13.877132 lr 0.00072167 rank 1
2022-12-03 21:52:18,356 DEBUG TRAIN Batch 5/6300 loss 32.729370 loss_att 32.581261 loss_ctc 46.196449 loss_rnnt 30.963385 lr 0.00072182 rank 5
2022-12-03 21:52:18,360 DEBUG TRAIN Batch 5/6300 loss 14.521146 loss_att 17.666937 loss_ctc 27.312353 loss_rnnt 12.186493 lr 0.00072192 rank 4
2022-12-03 21:52:18,360 DEBUG TRAIN Batch 5/6300 loss 13.044147 loss_att 17.925196 loss_ctc 23.887226 loss_rnnt 10.622195 lr 0.00072197 rank 6
2022-12-03 21:52:18,365 DEBUG TRAIN Batch 5/6300 loss 27.734543 loss_att 30.609619 loss_ctc 39.883324 loss_rnnt 25.539688 lr 0.00072151 rank 0
2022-12-03 21:52:18,366 DEBUG TRAIN Batch 5/6300 loss 28.766809 loss_att 32.299191 loss_ctc 42.171570 loss_rnnt 26.273029 lr 0.00072161 rank 3
2022-12-03 21:52:18,378 DEBUG TRAIN Batch 5/6300 loss 17.852182 loss_att 22.253340 loss_ctc 35.404045 loss_rnnt 14.631702 lr 0.00072197 rank 7
2022-12-03 21:52:18,379 DEBUG TRAIN Batch 5/6300 loss 13.931380 loss_att 15.907572 loss_ctc 20.815166 loss_rnnt 12.618304 lr 0.00072127 rank 2
2022-12-03 21:53:32,729 DEBUG TRAIN Batch 5/6400 loss 13.796310 loss_att 19.185192 loss_ctc 23.260681 loss_rnnt 11.456618 lr 0.00072053 rank 2
2022-12-03 21:53:32,734 DEBUG TRAIN Batch 5/6400 loss 12.487563 loss_att 14.125748 loss_ctc 19.740202 loss_rnnt 11.192908 lr 0.00072106 rank 5
2022-12-03 21:53:32,740 DEBUG TRAIN Batch 5/6400 loss 10.861091 loss_att 12.961338 loss_ctc 16.212057 loss_rnnt 9.727580 lr 0.00072076 rank 0
2022-12-03 21:53:32,741 DEBUG TRAIN Batch 5/6400 loss 12.975781 loss_att 13.231900 loss_ctc 18.880848 loss_rnnt 12.137216 lr 0.00072086 rank 3
2022-12-03 21:53:32,746 DEBUG TRAIN Batch 5/6400 loss 20.671896 loss_att 24.358494 loss_ctc 30.705429 loss_rnnt 18.596771 lr 0.00072121 rank 6
2022-12-03 21:53:32,747 DEBUG TRAIN Batch 5/6400 loss 20.659588 loss_att 27.954605 loss_ctc 39.524971 loss_rnnt 16.685200 lr 0.00072122 rank 7
2022-12-03 21:53:32,756 DEBUG TRAIN Batch 5/6400 loss 24.185322 loss_att 30.127155 loss_ctc 42.221813 loss_rnnt 20.592089 lr 0.00072117 rank 4
2022-12-03 21:53:32,785 DEBUG TRAIN Batch 5/6400 loss 25.566673 loss_att 32.053719 loss_ctc 52.683067 loss_rnnt 20.653746 lr 0.00072092 rank 1
2022-12-03 21:54:44,782 DEBUG TRAIN Batch 5/6500 loss 20.526878 loss_att 29.083158 loss_ctc 44.760815 loss_rnnt 15.584430 lr 0.00072047 rank 7
2022-12-03 21:54:44,782 DEBUG TRAIN Batch 5/6500 loss 16.609102 loss_att 20.095844 loss_ctc 30.875265 loss_rnnt 14.009598 lr 0.00072011 rank 3
2022-12-03 21:54:44,783 DEBUG TRAIN Batch 5/6500 loss 14.396326 loss_att 19.339005 loss_ctc 24.954174 loss_rnnt 12.000076 lr 0.00072047 rank 6
2022-12-03 21:54:44,784 DEBUG TRAIN Batch 5/6500 loss 9.430871 loss_att 13.712378 loss_ctc 13.889013 loss_rnnt 7.980151 lr 0.00072042 rank 4
2022-12-03 21:54:44,784 DEBUG TRAIN Batch 5/6500 loss 11.421050 loss_att 19.852339 loss_ctc 15.269400 loss_rnnt 9.221679 lr 0.00072017 rank 1
2022-12-03 21:54:44,787 DEBUG TRAIN Batch 5/6500 loss 20.957012 loss_att 29.573788 loss_ctc 33.073166 loss_rnnt 17.618168 lr 0.00072002 rank 0
2022-12-03 21:54:44,785 DEBUG TRAIN Batch 5/6500 loss 25.913036 loss_att 30.689281 loss_ctc 38.268150 loss_rnnt 23.310440 lr 0.00072032 rank 5
2022-12-03 21:54:44,830 DEBUG TRAIN Batch 5/6500 loss 25.966999 loss_att 29.581789 loss_ctc 50.499481 loss_rnnt 21.973043 lr 0.00071978 rank 2
2022-12-03 21:55:57,071 DEBUG TRAIN Batch 5/6600 loss 19.164919 loss_att 21.560877 loss_ctc 35.194950 loss_rnnt 16.548391 lr 0.00071957 rank 5
2022-12-03 21:55:57,072 DEBUG TRAIN Batch 5/6600 loss 24.230297 loss_att 31.995277 loss_ctc 43.096794 loss_rnnt 20.161768 lr 0.00071943 rank 1
2022-12-03 21:55:57,075 DEBUG TRAIN Batch 5/6600 loss 20.057777 loss_att 26.916977 loss_ctc 30.031460 loss_rnnt 17.356113 lr 0.00071972 rank 6
2022-12-03 21:55:57,076 DEBUG TRAIN Batch 5/6600 loss 14.009599 loss_att 21.791832 loss_ctc 26.401943 loss_rnnt 10.800840 lr 0.00071927 rank 0
2022-12-03 21:55:57,077 DEBUG TRAIN Batch 5/6600 loss 28.945236 loss_att 30.795113 loss_ctc 43.749084 loss_rnnt 26.601416 lr 0.00071973 rank 7
2022-12-03 21:55:57,079 DEBUG TRAIN Batch 5/6600 loss 9.848916 loss_att 14.771002 loss_ctc 22.065994 loss_rnnt 7.235555 lr 0.00071937 rank 3
2022-12-03 21:55:57,087 DEBUG TRAIN Batch 5/6600 loss 27.531155 loss_att 30.358675 loss_ctc 41.356270 loss_rnnt 25.122301 lr 0.00071903 rank 2
2022-12-03 21:55:57,131 DEBUG TRAIN Batch 5/6600 loss 10.199645 loss_att 12.767863 loss_ctc 17.729671 loss_rnnt 8.681998 lr 0.00071967 rank 4
2022-12-03 21:57:10,485 DEBUG TRAIN Batch 5/6700 loss 34.868935 loss_att 35.570206 loss_ctc 54.541870 loss_rnnt 32.105621 lr 0.00071883 rank 5
2022-12-03 21:57:10,493 DEBUG TRAIN Batch 5/6700 loss 14.475555 loss_att 20.303961 loss_ctc 24.612501 loss_rnnt 11.958282 lr 0.00071868 rank 1
2022-12-03 21:57:10,497 DEBUG TRAIN Batch 5/6700 loss 21.270357 loss_att 24.705709 loss_ctc 31.607069 loss_rnnt 19.205059 lr 0.00071863 rank 3
2022-12-03 21:57:10,497 DEBUG TRAIN Batch 5/6700 loss 18.314274 loss_att 17.551218 loss_ctc 23.597996 loss_rnnt 17.762390 lr 0.00071829 rank 2
2022-12-03 21:57:10,497 DEBUG TRAIN Batch 5/6700 loss 25.103607 loss_att 27.419920 loss_ctc 44.106030 loss_rnnt 22.106689 lr 0.00071898 rank 7
2022-12-03 21:57:10,498 DEBUG TRAIN Batch 5/6700 loss 12.142155 loss_att 15.539917 loss_ctc 16.227119 loss_rnnt 10.917939 lr 0.00071897 rank 6
2022-12-03 21:57:10,499 DEBUG TRAIN Batch 5/6700 loss 15.162831 loss_att 18.518867 loss_ctc 27.772873 loss_rnnt 12.810286 lr 0.00071853 rank 0
2022-12-03 21:57:10,510 DEBUG TRAIN Batch 5/6700 loss 26.266293 loss_att 28.379395 loss_ctc 36.579403 loss_rnnt 24.468590 lr 0.00071893 rank 4
2022-12-03 21:58:24,259 DEBUG TRAIN Batch 5/6800 loss 17.195065 loss_att 22.430370 loss_ctc 29.094900 loss_rnnt 14.561358 lr 0.00071779 rank 0
2022-12-03 21:58:24,263 DEBUG TRAIN Batch 5/6800 loss 11.364136 loss_att 18.917221 loss_ctc 22.572025 loss_rnnt 8.359133 lr 0.00071794 rank 1
2022-12-03 21:58:24,266 DEBUG TRAIN Batch 5/6800 loss 13.938416 loss_att 21.552258 loss_ctc 26.223942 loss_rnnt 10.777578 lr 0.00071808 rank 5
2022-12-03 21:58:24,265 DEBUG TRAIN Batch 5/6800 loss 19.306309 loss_att 25.273691 loss_ctc 38.366287 loss_rnnt 15.571502 lr 0.00071755 rank 2
2022-12-03 21:58:24,266 DEBUG TRAIN Batch 5/6800 loss 26.376026 loss_att 34.433876 loss_ctc 47.169540 loss_rnnt 21.991989 lr 0.00071823 rank 6
2022-12-03 21:58:24,270 DEBUG TRAIN Batch 5/6800 loss 24.043104 loss_att 26.870056 loss_ctc 36.017952 loss_rnnt 21.881067 lr 0.00071824 rank 7
2022-12-03 21:58:24,272 DEBUG TRAIN Batch 5/6800 loss 15.435048 loss_att 20.631428 loss_ctc 28.849863 loss_rnnt 12.607131 lr 0.00071788 rank 3
2022-12-03 21:58:24,273 DEBUG TRAIN Batch 5/6800 loss 21.342710 loss_att 23.427662 loss_ctc 34.922714 loss_rnnt 19.115053 lr 0.00071819 rank 4
2022-12-03 21:59:36,817 DEBUG TRAIN Batch 5/6900 loss 18.526413 loss_att 21.083458 loss_ctc 30.213154 loss_rnnt 16.456772 lr 0.00071720 rank 1
2022-12-03 21:59:36,822 DEBUG TRAIN Batch 5/6900 loss 11.356972 loss_att 16.118811 loss_ctc 19.290951 loss_rnnt 9.346740 lr 0.00071749 rank 6
2022-12-03 21:59:36,822 DEBUG TRAIN Batch 5/6900 loss 21.954617 loss_att 25.037569 loss_ctc 31.652170 loss_rnnt 20.045017 lr 0.00071681 rank 2
2022-12-03 21:59:36,823 DEBUG TRAIN Batch 5/6900 loss 24.840422 loss_att 31.451862 loss_ctc 40.489044 loss_rnnt 21.431652 lr 0.00071705 rank 0
2022-12-03 21:59:36,828 DEBUG TRAIN Batch 5/6900 loss 17.492508 loss_att 22.410315 loss_ctc 27.693243 loss_rnnt 15.148849 lr 0.00071750 rank 7
2022-12-03 21:59:36,828 DEBUG TRAIN Batch 5/6900 loss 17.990992 loss_att 22.607096 loss_ctc 27.701593 loss_rnnt 15.773023 lr 0.00071715 rank 3
2022-12-03 21:59:36,831 DEBUG TRAIN Batch 5/6900 loss 23.788555 loss_att 29.680332 loss_ctc 42.553905 loss_rnnt 20.108150 lr 0.00071734 rank 5
2022-12-03 21:59:36,881 DEBUG TRAIN Batch 5/6900 loss 28.447489 loss_att 33.329170 loss_ctc 44.147137 loss_rnnt 25.377867 lr 0.00071745 rank 4
2022-12-03 22:00:50,092 DEBUG TRAIN Batch 5/7000 loss 12.125336 loss_att 14.914749 loss_ctc 18.611275 loss_rnnt 10.702661 lr 0.00071647 rank 1
2022-12-03 22:00:50,092 DEBUG TRAIN Batch 5/7000 loss 19.662258 loss_att 23.695797 loss_ctc 35.826126 loss_rnnt 16.700369 lr 0.00071676 rank 7
2022-12-03 22:00:50,095 DEBUG TRAIN Batch 5/7000 loss 16.015535 loss_att 19.761280 loss_ctc 22.781921 loss_rnnt 14.364202 lr 0.00071661 rank 5
2022-12-03 22:00:50,097 DEBUG TRAIN Batch 5/7000 loss 17.122400 loss_att 20.368828 loss_ctc 23.869818 loss_rnnt 15.573458 lr 0.00071631 rank 0
2022-12-03 22:00:50,098 DEBUG TRAIN Batch 5/7000 loss 24.987907 loss_att 34.905857 loss_ctc 45.891476 loss_rnnt 20.217173 lr 0.00071675 rank 6
2022-12-03 22:00:50,098 DEBUG TRAIN Batch 5/7000 loss 20.619640 loss_att 24.030905 loss_ctc 33.825306 loss_rnnt 18.176632 lr 0.00071671 rank 4
2022-12-03 22:00:50,100 DEBUG TRAIN Batch 5/7000 loss 14.026741 loss_att 14.646614 loss_ctc 21.284405 loss_rnnt 12.935078 lr 0.00071641 rank 3
2022-12-03 22:00:50,122 DEBUG TRAIN Batch 5/7000 loss 21.899147 loss_att 29.620594 loss_ctc 33.651604 loss_rnnt 18.787865 lr 0.00071608 rank 2
2022-12-03 22:02:04,145 DEBUG TRAIN Batch 5/7100 loss 9.862190 loss_att 14.510834 loss_ctc 16.789883 loss_rnnt 8.008768 lr 0.00071573 rank 1
2022-12-03 22:02:04,161 DEBUG TRAIN Batch 5/7100 loss 10.823161 loss_att 17.645481 loss_ctc 13.431880 loss_rnnt 9.110868 lr 0.00071558 rank 0
2022-12-03 22:02:04,164 DEBUG TRAIN Batch 5/7100 loss 12.774284 loss_att 12.863810 loss_ctc 22.189259 loss_rnnt 11.501051 lr 0.00071602 rank 6
2022-12-03 22:02:04,166 DEBUG TRAIN Batch 5/7100 loss 22.399227 loss_att 21.747635 loss_ctc 34.304718 loss_rnnt 20.942146 lr 0.00071598 rank 4
2022-12-03 22:02:04,168 DEBUG TRAIN Batch 5/7100 loss 14.972315 loss_att 19.654976 loss_ctc 22.848333 loss_rnnt 12.985647 lr 0.00071603 rank 7
2022-12-03 22:02:04,169 DEBUG TRAIN Batch 5/7100 loss 15.416676 loss_att 17.706551 loss_ctc 26.903854 loss_rnnt 13.427075 lr 0.00071587 rank 5
2022-12-03 22:02:04,168 DEBUG TRAIN Batch 5/7100 loss 23.625576 loss_att 32.199127 loss_ctc 30.952389 loss_rnnt 20.933958 lr 0.00071534 rank 2
2022-12-03 22:02:04,204 DEBUG TRAIN Batch 5/7100 loss 14.272631 loss_att 21.188131 loss_ctc 34.151932 loss_rnnt 10.238956 lr 0.00071567 rank 3
2022-12-03 22:03:16,992 DEBUG TRAIN Batch 5/7200 loss 27.089409 loss_att 29.907663 loss_ctc 38.719566 loss_rnnt 24.975073 lr 0.00071529 rank 6
2022-12-03 22:03:16,992 DEBUG TRAIN Batch 5/7200 loss 21.503849 loss_att 29.718544 loss_ctc 33.231197 loss_rnnt 18.297262 lr 0.00071485 rank 0
2022-12-03 22:03:16,993 DEBUG TRAIN Batch 5/7200 loss 23.294207 loss_att 27.900391 loss_ctc 34.102257 loss_rnnt 20.931898 lr 0.00071461 rank 2
2022-12-03 22:03:16,995 DEBUG TRAIN Batch 5/7200 loss 23.266453 loss_att 27.375568 loss_ctc 32.481956 loss_rnnt 21.215897 lr 0.00071494 rank 3
2022-12-03 22:03:16,997 DEBUG TRAIN Batch 5/7200 loss 19.207804 loss_att 22.313337 loss_ctc 31.139212 loss_rnnt 16.995842 lr 0.00071514 rank 5
2022-12-03 22:03:16,998 DEBUG TRAIN Batch 5/7200 loss 19.328953 loss_att 28.298140 loss_ctc 35.061012 loss_rnnt 15.437508 lr 0.00071529 rank 7
2022-12-03 22:03:17,003 DEBUG TRAIN Batch 5/7200 loss 19.534683 loss_att 26.185913 loss_ctc 33.915386 loss_rnnt 16.287010 lr 0.00071500 rank 1
2022-12-03 22:03:17,008 DEBUG TRAIN Batch 5/7200 loss 15.975932 loss_att 22.526577 loss_ctc 27.623547 loss_rnnt 13.112788 lr 0.00071524 rank 4
2022-12-03 22:04:29,822 DEBUG TRAIN Batch 5/7300 loss 30.599316 loss_att 35.679955 loss_ctc 47.309902 loss_rnnt 27.355108 lr 0.00071456 rank 6
2022-12-03 22:04:29,824 DEBUG TRAIN Batch 5/7300 loss 14.353410 loss_att 23.904819 loss_ctc 33.149841 loss_rnnt 9.936937 lr 0.00071412 rank 0
2022-12-03 22:04:29,824 DEBUG TRAIN Batch 5/7300 loss 20.619041 loss_att 24.657738 loss_ctc 32.435661 loss_rnnt 18.235754 lr 0.00071421 rank 3
2022-12-03 22:04:29,825 DEBUG TRAIN Batch 5/7300 loss 35.294075 loss_att 39.930038 loss_ctc 54.576813 loss_rnnt 31.795851 lr 0.00071441 rank 5
2022-12-03 22:04:29,826 DEBUG TRAIN Batch 5/7300 loss 16.097263 loss_att 22.406147 loss_ctc 30.627337 loss_rnnt 12.898144 lr 0.00071427 rank 1
2022-12-03 22:04:29,830 DEBUG TRAIN Batch 5/7300 loss 18.177750 loss_att 25.520584 loss_ctc 28.787365 loss_rnnt 15.294565 lr 0.00071451 rank 4
2022-12-03 22:04:29,835 DEBUG TRAIN Batch 5/7300 loss 18.974585 loss_att 23.577190 loss_ctc 34.201275 loss_rnnt 16.023838 lr 0.00071456 rank 7
2022-12-03 22:04:29,839 DEBUG TRAIN Batch 5/7300 loss 19.133060 loss_att 26.036171 loss_ctc 29.198652 loss_rnnt 16.410358 lr 0.00071389 rank 2
2022-12-03 22:05:42,673 DEBUG TRAIN Batch 5/7400 loss 18.247892 loss_att 24.300653 loss_ctc 34.395897 loss_rnnt 14.884272 lr 0.00071383 rank 6
2022-12-03 22:05:42,674 DEBUG TRAIN Batch 5/7400 loss 23.109764 loss_att 24.322426 loss_ctc 39.468231 loss_rnnt 20.686104 lr 0.00071339 rank 0
2022-12-03 22:05:42,675 DEBUG TRAIN Batch 5/7400 loss 18.493856 loss_att 21.914392 loss_ctc 32.304886 loss_rnnt 15.968278 lr 0.00071383 rank 7
2022-12-03 22:05:42,676 DEBUG TRAIN Batch 5/7400 loss 36.994930 loss_att 41.190617 loss_ctc 62.802856 loss_rnnt 32.714737 lr 0.00071316 rank 2
2022-12-03 22:05:42,678 DEBUG TRAIN Batch 5/7400 loss 13.242825 loss_att 21.458567 loss_ctc 31.489174 loss_rnnt 9.166829 lr 0.00071349 rank 3
2022-12-03 22:05:42,681 DEBUG TRAIN Batch 5/7400 loss 18.250097 loss_att 22.847111 loss_ctc 27.360380 loss_rnnt 16.115990 lr 0.00071368 rank 5
2022-12-03 22:05:42,686 DEBUG TRAIN Batch 5/7400 loss 10.128042 loss_att 14.344759 loss_ctc 17.893200 loss_rnnt 8.249345 lr 0.00071378 rank 4
2022-12-03 22:05:42,696 DEBUG TRAIN Batch 5/7400 loss 10.026929 loss_att 14.631594 loss_ctc 18.656796 loss_rnnt 7.955347 lr 0.00071354 rank 1
2022-12-03 22:06:57,017 DEBUG TRAIN Batch 5/7500 loss 15.246544 loss_att 20.818390 loss_ctc 38.174992 loss_rnnt 11.075047 lr 0.00071296 rank 5
2022-12-03 22:06:57,029 DEBUG TRAIN Batch 5/7500 loss 18.583506 loss_att 23.352184 loss_ctc 33.163628 loss_rnnt 15.685752 lr 0.00071310 rank 6
2022-12-03 22:06:57,033 DEBUG TRAIN Batch 5/7500 loss 11.421906 loss_att 14.289886 loss_ctc 20.003704 loss_rnnt 9.704070 lr 0.00071282 rank 1
2022-12-03 22:06:57,034 DEBUG TRAIN Batch 5/7500 loss 28.147968 loss_att 32.562435 loss_ctc 42.937553 loss_rnnt 25.293129 lr 0.00071267 rank 0
2022-12-03 22:06:57,034 DEBUG TRAIN Batch 5/7500 loss 25.189447 loss_att 31.946953 loss_ctc 35.373039 loss_rnnt 22.480133 lr 0.00071243 rank 2
2022-12-03 22:06:57,039 DEBUG TRAIN Batch 5/7500 loss 26.108109 loss_att 25.810692 loss_ctc 36.995659 loss_rnnt 24.715918 lr 0.00071311 rank 7
2022-12-03 22:06:57,041 DEBUG TRAIN Batch 5/7500 loss 31.560911 loss_att 37.558220 loss_ctc 47.486042 loss_rnnt 28.238098 lr 0.00071276 rank 3
2022-12-03 22:06:57,093 DEBUG TRAIN Batch 5/7500 loss 9.167793 loss_att 12.692480 loss_ctc 17.682295 loss_rnnt 7.327589 lr 0.00071306 rank 4
2022-12-03 22:08:08,333 DEBUG TRAIN Batch 5/7600 loss 20.849426 loss_att 24.223358 loss_ctc 37.702347 loss_rnnt 17.927582 lr 0.00071238 rank 6
2022-12-03 22:08:08,334 DEBUG TRAIN Batch 5/7600 loss 16.777435 loss_att 23.595589 loss_ctc 26.635220 loss_rnnt 14.099434 lr 0.00071223 rank 5
2022-12-03 22:08:08,334 DEBUG TRAIN Batch 5/7600 loss 17.523613 loss_att 17.924463 loss_ctc 27.884253 loss_rnnt 16.062025 lr 0.00071171 rank 2
2022-12-03 22:08:08,337 DEBUG TRAIN Batch 5/7600 loss 22.254736 loss_att 29.188078 loss_ctc 36.592426 loss_rnnt 18.956375 lr 0.00071194 rank 0
2022-12-03 22:08:08,338 DEBUG TRAIN Batch 5/7600 loss 36.697773 loss_att 37.765224 loss_ctc 53.852638 loss_rnnt 34.196964 lr 0.00071209 rank 1
2022-12-03 22:08:08,340 DEBUG TRAIN Batch 5/7600 loss 28.381145 loss_att 37.665989 loss_ctc 46.003521 loss_rnnt 24.174526 lr 0.00071238 rank 7
2022-12-03 22:08:08,343 DEBUG TRAIN Batch 5/7600 loss 12.269489 loss_att 15.496388 loss_ctc 22.913448 loss_rnnt 10.204915 lr 0.00071204 rank 3
2022-12-03 22:08:08,390 DEBUG TRAIN Batch 5/7600 loss 14.226161 loss_att 19.277000 loss_ctc 22.427679 loss_rnnt 12.122458 lr 0.00071233 rank 4
2022-12-03 22:09:19,712 DEBUG TRAIN Batch 5/7700 loss 17.542606 loss_att 25.160116 loss_ctc 24.610989 loss_rnnt 15.076653 lr 0.00071137 rank 1
2022-12-03 22:09:19,713 DEBUG TRAIN Batch 5/7700 loss 20.958420 loss_att 22.772461 loss_ctc 33.412758 loss_rnnt 18.935034 lr 0.00071151 rank 5
2022-12-03 22:09:19,714 DEBUG TRAIN Batch 5/7700 loss 23.673386 loss_att 28.827749 loss_ctc 40.759502 loss_rnnt 20.364363 lr 0.00071122 rank 0
2022-12-03 22:09:19,714 DEBUG TRAIN Batch 5/7700 loss 8.029982 loss_att 9.472551 loss_ctc 12.049109 loss_rnnt 7.205583 lr 0.00071165 rank 6
2022-12-03 22:09:19,716 DEBUG TRAIN Batch 5/7700 loss 30.513823 loss_att 36.237743 loss_ctc 51.132988 loss_rnnt 26.619816 lr 0.00071099 rank 2
2022-12-03 22:09:19,716 DEBUG TRAIN Batch 5/7700 loss 18.689913 loss_att 23.947456 loss_ctc 30.117514 loss_rnnt 16.114723 lr 0.00071132 rank 3
2022-12-03 22:09:19,721 DEBUG TRAIN Batch 5/7700 loss 7.019180 loss_att 12.350636 loss_ctc 14.695831 loss_rnnt 4.929336 lr 0.00071166 rank 7
2022-12-03 22:09:19,722 DEBUG TRAIN Batch 5/7700 loss 28.827148 loss_att 29.888233 loss_ctc 49.352734 loss_rnnt 25.878187 lr 0.00071161 rank 4
2022-12-03 22:10:32,908 DEBUG TRAIN Batch 5/7800 loss 14.832315 loss_att 19.026348 loss_ctc 34.573673 loss_rnnt 11.361327 lr 0.00071094 rank 7
2022-12-03 22:10:32,914 DEBUG TRAIN Batch 5/7800 loss 5.675972 loss_att 9.849589 loss_ctc 12.006676 loss_rnnt 3.997154 lr 0.00071050 rank 0
2022-12-03 22:10:32,919 DEBUG TRAIN Batch 5/7800 loss 13.587269 loss_att 17.991556 loss_ctc 29.736797 loss_rnnt 10.553142 lr 0.00071065 rank 1
2022-12-03 22:10:32,922 DEBUG TRAIN Batch 5/7800 loss 15.911922 loss_att 21.246866 loss_ctc 23.735699 loss_rnnt 13.801764 lr 0.00071060 rank 3
2022-12-03 22:10:32,925 DEBUG TRAIN Batch 5/7800 loss 28.633541 loss_att 34.355225 loss_ctc 41.729301 loss_rnnt 25.743103 lr 0.00071079 rank 5
2022-12-03 22:10:32,926 DEBUG TRAIN Batch 5/7800 loss 32.513039 loss_att 37.376778 loss_ctc 52.961388 loss_rnnt 28.813843 lr 0.00071027 rank 2
2022-12-03 22:10:32,938 DEBUG TRAIN Batch 5/7800 loss 16.150936 loss_att 26.150581 loss_ctc 35.250183 loss_rnnt 11.604439 lr 0.00071093 rank 6
2022-12-03 22:10:32,959 DEBUG TRAIN Batch 5/7800 loss 22.509466 loss_att 25.689148 loss_ctc 26.873150 loss_rnnt 21.291704 lr 0.00071089 rank 4
2022-12-03 22:11:45,229 DEBUG TRAIN Batch 5/7900 loss 16.533640 loss_att 19.735214 loss_ctc 29.860273 loss_rnnt 14.116440 lr 0.00071022 rank 6
2022-12-03 22:11:45,231 DEBUG TRAIN Batch 5/7900 loss 36.682556 loss_att 39.219460 loss_ctc 53.315777 loss_rnnt 33.957413 lr 0.00071007 rank 5
2022-12-03 22:11:45,232 DEBUG TRAIN Batch 5/7900 loss 26.809111 loss_att 34.097450 loss_ctc 44.620445 loss_rnnt 22.976599 lr 0.00070994 rank 1
2022-12-03 22:11:45,232 DEBUG TRAIN Batch 5/7900 loss 18.709608 loss_att 25.132780 loss_ctc 36.786411 loss_rnnt 15.014733 lr 0.00070988 rank 3
2022-12-03 22:11:45,237 DEBUG TRAIN Batch 5/7900 loss 18.858250 loss_att 26.372059 loss_ctc 40.857338 loss_rnnt 14.422276 lr 0.00070956 rank 2
2022-12-03 22:11:45,240 DEBUG TRAIN Batch 5/7900 loss 20.324526 loss_att 24.873661 loss_ctc 27.422649 loss_rnnt 18.468283 lr 0.00070979 rank 0
2022-12-03 22:11:45,240 DEBUG TRAIN Batch 5/7900 loss 20.195372 loss_att 27.567404 loss_ctc 28.777628 loss_rnnt 17.576664 lr 0.00071022 rank 7
2022-12-03 22:11:45,246 DEBUG TRAIN Batch 5/7900 loss 16.163387 loss_att 19.423847 loss_ctc 24.870167 loss_rnnt 14.350389 lr 0.00071017 rank 4
2022-12-03 22:12:55,527 DEBUG TRAIN Batch 5/8000 loss 18.782005 loss_att 22.720438 loss_ctc 32.052971 loss_rnnt 16.224857 lr 0.00070907 rank 0
2022-12-03 22:12:55,531 DEBUG TRAIN Batch 5/8000 loss 29.328014 loss_att 35.676720 loss_ctc 47.334278 loss_rnnt 25.657438 lr 0.00070950 rank 6
2022-12-03 22:12:55,532 DEBUG TRAIN Batch 5/8000 loss 13.317002 loss_att 18.371284 loss_ctc 29.206982 loss_rnnt 10.187483 lr 0.00070922 rank 1
2022-12-03 22:12:55,533 DEBUG TRAIN Batch 5/8000 loss 30.767912 loss_att 33.516960 loss_ctc 48.855343 loss_rnnt 27.806444 lr 0.00070917 rank 3
2022-12-03 22:12:55,534 DEBUG TRAIN Batch 5/8000 loss 12.894245 loss_att 19.443779 loss_ctc 21.910498 loss_rnnt 10.382172 lr 0.00070885 rank 2
2022-12-03 22:12:55,535 DEBUG TRAIN Batch 5/8000 loss 16.892262 loss_att 21.937954 loss_ctc 25.761963 loss_rnnt 14.700497 lr 0.00070936 rank 5
2022-12-03 22:12:55,536 DEBUG TRAIN Batch 5/8000 loss 19.769205 loss_att 24.863901 loss_ctc 24.978794 loss_rnnt 18.055655 lr 0.00070946 rank 4
2022-12-03 22:12:55,537 DEBUG TRAIN Batch 5/8000 loss 29.066444 loss_att 29.183666 loss_ctc 42.469826 loss_rnnt 27.255882 lr 0.00070951 rank 7
2022-12-03 22:14:07,670 DEBUG TRAIN Batch 5/8100 loss 32.104607 loss_att 32.099854 loss_ctc 38.217430 loss_rnnt 31.290512 lr 0.00070880 rank 7
2022-12-03 22:14:07,685 DEBUG TRAIN Batch 5/8100 loss 26.163292 loss_att 31.156517 loss_ctc 39.482407 loss_rnnt 23.388765 lr 0.00070879 rank 6
2022-12-03 22:14:07,688 DEBUG TRAIN Batch 5/8100 loss 23.795382 loss_att 31.530910 loss_ctc 46.553833 loss_rnnt 19.213814 lr 0.00070865 rank 5
2022-12-03 22:14:07,689 DEBUG TRAIN Batch 5/8100 loss 19.491497 loss_att 21.557814 loss_ctc 30.511465 loss_rnnt 17.608906 lr 0.00070836 rank 0
2022-12-03 22:14:07,690 DEBUG TRAIN Batch 5/8100 loss 15.802057 loss_att 21.271168 loss_ctc 37.250267 loss_rnnt 11.848473 lr 0.00070851 rank 1
2022-12-03 22:14:07,692 DEBUG TRAIN Batch 5/8100 loss 13.220698 loss_att 16.934555 loss_ctc 21.175598 loss_rnnt 11.417274 lr 0.00070845 rank 3
2022-12-03 22:14:07,695 DEBUG TRAIN Batch 5/8100 loss 16.851076 loss_att 19.529228 loss_ctc 24.131491 loss_rnnt 15.344725 lr 0.00070875 rank 4
2022-12-03 22:14:07,711 DEBUG TRAIN Batch 5/8100 loss 25.801577 loss_att 31.034275 loss_ctc 47.657940 loss_rnnt 21.840853 lr 0.00070813 rank 2
2022-12-03 22:15:19,667 DEBUG TRAIN Batch 5/8200 loss 22.068848 loss_att 25.102093 loss_ctc 35.694649 loss_rnnt 19.645424 lr 0.00070808 rank 6
2022-12-03 22:15:19,672 DEBUG TRAIN Batch 5/8200 loss 27.995323 loss_att 33.371925 loss_ctc 47.101883 loss_rnnt 24.372463 lr 0.00070794 rank 5
2022-12-03 22:15:19,674 DEBUG TRAIN Batch 5/8200 loss 22.976707 loss_att 24.450600 loss_ctc 39.590378 loss_rnnt 20.466774 lr 0.00070780 rank 1
2022-12-03 22:15:19,675 DEBUG TRAIN Batch 5/8200 loss 17.324274 loss_att 23.405806 loss_ctc 30.409786 loss_rnnt 14.363234 lr 0.00070808 rank 7
2022-12-03 22:15:19,676 DEBUG TRAIN Batch 5/8200 loss 24.056965 loss_att 30.436108 loss_ctc 40.819508 loss_rnnt 20.546131 lr 0.00070774 rank 3
2022-12-03 22:15:19,676 DEBUG TRAIN Batch 5/8200 loss 16.389883 loss_att 21.410732 loss_ctc 27.930140 loss_rnnt 13.847010 lr 0.00070743 rank 2
2022-12-03 22:15:19,676 DEBUG TRAIN Batch 5/8200 loss 14.790901 loss_att 18.264023 loss_ctc 17.845387 loss_rnnt 13.689012 lr 0.00070765 rank 0
2022-12-03 22:15:19,685 DEBUG TRAIN Batch 5/8200 loss 45.138317 loss_att 47.620872 loss_ctc 75.317230 loss_rnnt 40.617950 lr 0.00070803 rank 4
2022-12-03 22:16:30,652 DEBUG TRAIN Batch 5/8300 loss 34.363949 loss_att 38.122414 loss_ctc 47.073269 loss_rnnt 31.917679 lr 0.00070737 rank 6
2022-12-03 22:16:30,653 DEBUG TRAIN Batch 5/8300 loss 10.736708 loss_att 13.240427 loss_ctc 16.851624 loss_rnnt 9.420642 lr 0.00070694 rank 0
2022-12-03 22:16:30,653 DEBUG TRAIN Batch 5/8300 loss 14.934270 loss_att 21.691330 loss_ctc 25.262478 loss_rnnt 12.205764 lr 0.00070723 rank 5
2022-12-03 22:16:30,655 DEBUG TRAIN Batch 5/8300 loss 17.946354 loss_att 26.024483 loss_ctc 38.324299 loss_rnnt 13.613669 lr 0.00070704 rank 3
2022-12-03 22:16:30,655 DEBUG TRAIN Batch 5/8300 loss 18.584724 loss_att 17.091890 loss_ctc 28.883667 loss_rnnt 17.510099 lr 0.00070709 rank 1
2022-12-03 22:16:30,657 DEBUG TRAIN Batch 5/8300 loss 9.086658 loss_att 17.127056 loss_ctc 21.404171 loss_rnnt 5.836245 lr 0.00070738 rank 7
2022-12-03 22:16:30,662 DEBUG TRAIN Batch 5/8300 loss 32.188820 loss_att 40.525562 loss_ctc 62.778500 loss_rnnt 26.442846 lr 0.00070672 rank 2
2022-12-03 22:16:30,662 DEBUG TRAIN Batch 5/8300 loss 20.925692 loss_att 25.879429 loss_ctc 35.856514 loss_rnnt 17.944168 lr 0.00070733 rank 4
2022-12-03 22:17:17,093 DEBUG CV Batch 5/0 loss 2.816203 loss_att 2.843783 loss_ctc 5.487638 loss_rnnt 2.454495 history loss 2.711899 rank 4
2022-12-03 22:17:17,099 DEBUG CV Batch 5/0 loss 2.816203 loss_att 2.843783 loss_ctc 5.487638 loss_rnnt 2.454495 history loss 2.711899 rank 6
2022-12-03 22:17:17,106 DEBUG CV Batch 5/0 loss 2.816203 loss_att 2.843783 loss_ctc 5.487638 loss_rnnt 2.454495 history loss 2.711899 rank 5
2022-12-03 22:17:17,107 DEBUG CV Batch 5/0 loss 2.816203 loss_att 2.843783 loss_ctc 5.487638 loss_rnnt 2.454495 history loss 2.711899 rank 1
2022-12-03 22:17:17,107 DEBUG CV Batch 5/0 loss 2.816203 loss_att 2.843783 loss_ctc 5.487638 loss_rnnt 2.454495 history loss 2.711899 rank 2
2022-12-03 22:17:17,109 DEBUG CV Batch 5/0 loss 2.816203 loss_att 2.843783 loss_ctc 5.487638 loss_rnnt 2.454495 history loss 2.711899 rank 0
2022-12-03 22:17:17,110 DEBUG CV Batch 5/0 loss 2.816203 loss_att 2.843783 loss_ctc 5.487638 loss_rnnt 2.454495 history loss 2.711899 rank 7
2022-12-03 22:17:17,110 DEBUG CV Batch 5/0 loss 2.816203 loss_att 2.843783 loss_ctc 5.487638 loss_rnnt 2.454495 history loss 2.711899 rank 3
2022-12-03 22:17:28,311 DEBUG CV Batch 5/100 loss 11.281563 loss_att 13.575175 loss_ctc 18.782635 loss_rnnt 9.822697 history loss 5.569568 rank 1
2022-12-03 22:17:28,442 DEBUG CV Batch 5/100 loss 11.281563 loss_att 13.575175 loss_ctc 18.782635 loss_rnnt 9.822697 history loss 5.569568 rank 2
2022-12-03 22:17:28,511 DEBUG CV Batch 5/100 loss 11.281563 loss_att 13.575175 loss_ctc 18.782635 loss_rnnt 9.822697 history loss 5.569568 rank 7
2022-12-03 22:17:28,511 DEBUG CV Batch 5/100 loss 11.281563 loss_att 13.575175 loss_ctc 18.782635 loss_rnnt 9.822697 history loss 5.569568 rank 4
2022-12-03 22:17:28,804 DEBUG CV Batch 5/100 loss 11.281563 loss_att 13.575175 loss_ctc 18.782635 loss_rnnt 9.822697 history loss 5.569568 rank 0
2022-12-03 22:17:28,904 DEBUG CV Batch 5/100 loss 11.281563 loss_att 13.575175 loss_ctc 18.782635 loss_rnnt 9.822697 history loss 5.569568 rank 3
2022-12-03 22:17:28,971 DEBUG CV Batch 5/100 loss 11.281563 loss_att 13.575175 loss_ctc 18.782635 loss_rnnt 9.822697 history loss 5.569568 rank 6
2022-12-03 22:17:29,051 DEBUG CV Batch 5/100 loss 11.281563 loss_att 13.575175 loss_ctc 18.782635 loss_rnnt 9.822697 history loss 5.569568 rank 5
2022-12-03 22:17:41,980 DEBUG CV Batch 5/200 loss 11.432966 loss_att 20.846210 loss_ctc 16.369547 loss_rnnt 8.892108 history loss 6.273377 rank 4
2022-12-03 22:17:42,209 DEBUG CV Batch 5/200 loss 11.432966 loss_att 20.846210 loss_ctc 16.369547 loss_rnnt 8.892108 history loss 6.273377 rank 1
2022-12-03 22:17:42,537 DEBUG CV Batch 5/200 loss 11.432966 loss_att 20.846210 loss_ctc 16.369547 loss_rnnt 8.892108 history loss 6.273377 rank 7
2022-12-03 22:17:42,599 DEBUG CV Batch 5/200 loss 11.432966 loss_att 20.846210 loss_ctc 16.369547 loss_rnnt 8.892108 history loss 6.273377 rank 2
2022-12-03 22:17:42,890 DEBUG CV Batch 5/200 loss 11.432966 loss_att 20.846210 loss_ctc 16.369547 loss_rnnt 8.892108 history loss 6.273377 rank 0
2022-12-03 22:17:42,898 DEBUG CV Batch 5/200 loss 11.432966 loss_att 20.846210 loss_ctc 16.369547 loss_rnnt 8.892108 history loss 6.273377 rank 3
2022-12-03 22:17:42,947 DEBUG CV Batch 5/200 loss 11.432966 loss_att 20.846210 loss_ctc 16.369547 loss_rnnt 8.892108 history loss 6.273377 rank 6
2022-12-03 22:17:43,164 DEBUG CV Batch 5/200 loss 11.432966 loss_att 20.846210 loss_ctc 16.369547 loss_rnnt 8.892108 history loss 6.273377 rank 5
2022-12-03 22:17:53,828 DEBUG CV Batch 5/300 loss 8.347868 loss_att 9.880951 loss_ctc 15.569936 loss_rnnt 7.078310 history loss 6.398759 rank 4
2022-12-03 22:17:54,269 DEBUG CV Batch 5/300 loss 8.347868 loss_att 9.880951 loss_ctc 15.569936 loss_rnnt 7.078310 history loss 6.398759 rank 1
2022-12-03 22:17:54,449 DEBUG CV Batch 5/300 loss 8.347868 loss_att 9.880951 loss_ctc 15.569936 loss_rnnt 7.078310 history loss 6.398759 rank 2
2022-12-03 22:17:54,516 DEBUG CV Batch 5/300 loss 8.347868 loss_att 9.880951 loss_ctc 15.569936 loss_rnnt 7.078310 history loss 6.398759 rank 7
2022-12-03 22:17:55,420 DEBUG CV Batch 5/300 loss 8.347868 loss_att 9.880951 loss_ctc 15.569936 loss_rnnt 7.078310 history loss 6.398759 rank 6
2022-12-03 22:17:55,524 DEBUG CV Batch 5/300 loss 8.347868 loss_att 9.880951 loss_ctc 15.569936 loss_rnnt 7.078310 history loss 6.398759 rank 3
2022-12-03 22:17:55,547 DEBUG CV Batch 5/300 loss 8.347868 loss_att 9.880951 loss_ctc 15.569936 loss_rnnt 7.078310 history loss 6.398759 rank 0
2022-12-03 22:17:55,766 DEBUG CV Batch 5/300 loss 8.347868 loss_att 9.880951 loss_ctc 15.569936 loss_rnnt 7.078310 history loss 6.398759 rank 5
2022-12-03 22:18:06,180 DEBUG CV Batch 5/400 loss 28.321896 loss_att 102.652260 loss_ctc 32.944305 loss_rnnt 12.839499 history loss 7.491355 rank 4
2022-12-03 22:18:06,291 DEBUG CV Batch 5/400 loss 28.321896 loss_att 102.652260 loss_ctc 32.944305 loss_rnnt 12.839499 history loss 7.491355 rank 1
2022-12-03 22:18:06,362 DEBUG CV Batch 5/400 loss 28.321896 loss_att 102.652260 loss_ctc 32.944305 loss_rnnt 12.839499 history loss 7.491355 rank 2
2022-12-03 22:18:06,489 DEBUG CV Batch 5/400 loss 28.321896 loss_att 102.652260 loss_ctc 32.944305 loss_rnnt 12.839499 history loss 7.491355 rank 7
2022-12-03 22:18:07,911 DEBUG CV Batch 5/400 loss 28.321896 loss_att 102.652260 loss_ctc 32.944305 loss_rnnt 12.839499 history loss 7.491355 rank 6
2022-12-03 22:18:08,086 DEBUG CV Batch 5/400 loss 28.321896 loss_att 102.652260 loss_ctc 32.944305 loss_rnnt 12.839499 history loss 7.491355 rank 0
2022-12-03 22:18:08,117 DEBUG CV Batch 5/400 loss 28.321896 loss_att 102.652260 loss_ctc 32.944305 loss_rnnt 12.839499 history loss 7.491355 rank 3
2022-12-03 22:18:08,251 DEBUG CV Batch 5/400 loss 28.321896 loss_att 102.652260 loss_ctc 32.944305 loss_rnnt 12.839499 history loss 7.491355 rank 5
2022-12-03 22:18:16,360 DEBUG CV Batch 5/500 loss 8.503110 loss_att 8.840042 loss_ctc 15.291646 loss_rnnt 7.530585 history loss 8.370426 rank 1
2022-12-03 22:18:16,362 DEBUG CV Batch 5/500 loss 8.503110 loss_att 8.840042 loss_ctc 15.291646 loss_rnnt 7.530585 history loss 8.370426 rank 4
2022-12-03 22:18:16,604 DEBUG CV Batch 5/500 loss 8.503110 loss_att 8.840042 loss_ctc 15.291646 loss_rnnt 7.530585 history loss 8.370426 rank 2
2022-12-03 22:18:16,778 DEBUG CV Batch 5/500 loss 8.503110 loss_att 8.840042 loss_ctc 15.291646 loss_rnnt 7.530585 history loss 8.370426 rank 7
2022-12-03 22:18:18,855 DEBUG CV Batch 5/500 loss 8.503110 loss_att 8.840042 loss_ctc 15.291646 loss_rnnt 7.530585 history loss 8.370426 rank 6
2022-12-03 22:18:19,074 DEBUG CV Batch 5/500 loss 8.503110 loss_att 8.840042 loss_ctc 15.291646 loss_rnnt 7.530585 history loss 8.370426 rank 0
2022-12-03 22:18:19,166 DEBUG CV Batch 5/500 loss 8.503110 loss_att 8.840042 loss_ctc 15.291646 loss_rnnt 7.530585 history loss 8.370426 rank 3
2022-12-03 22:18:19,319 DEBUG CV Batch 5/500 loss 8.503110 loss_att 8.840042 loss_ctc 15.291646 loss_rnnt 7.530585 history loss 8.370426 rank 5
2022-12-03 22:18:28,165 DEBUG CV Batch 5/600 loss 9.830131 loss_att 10.343531 loss_ctc 14.138868 loss_rnnt 9.152952 history loss 9.325110 rank 1
2022-12-03 22:18:28,357 DEBUG CV Batch 5/600 loss 9.830131 loss_att 10.343531 loss_ctc 14.138868 loss_rnnt 9.152952 history loss 9.325110 rank 4
2022-12-03 22:18:28,844 DEBUG CV Batch 5/600 loss 9.830131 loss_att 10.343531 loss_ctc 14.138868 loss_rnnt 9.152952 history loss 9.325110 rank 7
2022-12-03 22:18:28,850 DEBUG CV Batch 5/600 loss 9.830131 loss_att 10.343531 loss_ctc 14.138868 loss_rnnt 9.152952 history loss 9.325110 rank 2
2022-12-03 22:18:31,537 DEBUG CV Batch 5/600 loss 9.830131 loss_att 10.343531 loss_ctc 14.138868 loss_rnnt 9.152952 history loss 9.325110 rank 6
2022-12-03 22:18:31,785 DEBUG CV Batch 5/600 loss 9.830131 loss_att 10.343531 loss_ctc 14.138868 loss_rnnt 9.152952 history loss 9.325110 rank 5
2022-12-03 22:18:31,789 DEBUG CV Batch 5/600 loss 9.830131 loss_att 10.343531 loss_ctc 14.138868 loss_rnnt 9.152952 history loss 9.325110 rank 0
2022-12-03 22:18:31,847 DEBUG CV Batch 5/600 loss 9.830131 loss_att 10.343531 loss_ctc 14.138868 loss_rnnt 9.152952 history loss 9.325110 rank 3
2022-12-03 22:18:39,890 DEBUG CV Batch 5/700 loss 23.956512 loss_att 52.742470 loss_ctc 43.404663 loss_rnnt 15.606233 history loss 10.099794 rank 1
2022-12-03 22:18:39,909 DEBUG CV Batch 5/700 loss 23.956512 loss_att 52.742470 loss_ctc 43.404663 loss_rnnt 15.606233 history loss 10.099794 rank 4
2022-12-03 22:18:40,217 DEBUG CV Batch 5/700 loss 23.956512 loss_att 52.742470 loss_ctc 43.404663 loss_rnnt 15.606233 history loss 10.099794 rank 7
2022-12-03 22:18:40,285 DEBUG CV Batch 5/700 loss 23.956512 loss_att 52.742470 loss_ctc 43.404663 loss_rnnt 15.606233 history loss 10.099794 rank 2
2022-12-03 22:18:43,413 DEBUG CV Batch 5/700 loss 23.956512 loss_att 52.742470 loss_ctc 43.404663 loss_rnnt 15.606233 history loss 10.099794 rank 6
2022-12-03 22:18:43,704 DEBUG CV Batch 5/700 loss 23.956512 loss_att 52.742470 loss_ctc 43.404663 loss_rnnt 15.606233 history loss 10.099794 rank 5
2022-12-03 22:18:43,837 DEBUG CV Batch 5/700 loss 23.956512 loss_att 52.742470 loss_ctc 43.404663 loss_rnnt 15.606233 history loss 10.099794 rank 0
2022-12-03 22:18:43,928 DEBUG CV Batch 5/700 loss 23.956512 loss_att 52.742470 loss_ctc 43.404663 loss_rnnt 15.606233 history loss 10.099794 rank 3
2022-12-03 22:18:51,602 DEBUG CV Batch 5/800 loss 13.734030 loss_att 14.705174 loss_ctc 20.975243 loss_rnnt 12.574306 history loss 9.488635 rank 1
2022-12-03 22:18:51,811 DEBUG CV Batch 5/800 loss 13.734030 loss_att 14.705174 loss_ctc 20.975243 loss_rnnt 12.574306 history loss 9.488635 rank 2
2022-12-03 22:18:52,005 DEBUG CV Batch 5/800 loss 13.734030 loss_att 14.705174 loss_ctc 20.975243 loss_rnnt 12.574306 history loss 9.488635 rank 7
2022-12-03 22:18:52,081 DEBUG CV Batch 5/800 loss 13.734030 loss_att 14.705174 loss_ctc 20.975243 loss_rnnt 12.574306 history loss 9.488635 rank 4
2022-12-03 22:18:55,037 DEBUG CV Batch 5/800 loss 13.734030 loss_att 14.705174 loss_ctc 20.975243 loss_rnnt 12.574306 history loss 9.488635 rank 6
2022-12-03 22:18:55,303 DEBUG CV Batch 5/800 loss 13.734030 loss_att 14.705174 loss_ctc 20.975243 loss_rnnt 12.574306 history loss 9.488635 rank 5
2022-12-03 22:18:55,516 DEBUG CV Batch 5/800 loss 13.734030 loss_att 14.705174 loss_ctc 20.975243 loss_rnnt 12.574306 history loss 9.488635 rank 0
2022-12-03 22:18:55,579 DEBUG CV Batch 5/800 loss 13.734030 loss_att 14.705174 loss_ctc 20.975243 loss_rnnt 12.574306 history loss 9.488635 rank 3
2022-12-03 22:19:05,327 DEBUG CV Batch 5/900 loss 16.702347 loss_att 26.738266 loss_ctc 28.752731 loss_rnnt 13.088446 history loss 9.279377 rank 1
2022-12-03 22:19:05,368 DEBUG CV Batch 5/900 loss 16.702347 loss_att 26.738266 loss_ctc 28.752731 loss_rnnt 13.088446 history loss 9.279377 rank 2
2022-12-03 22:19:05,587 DEBUG CV Batch 5/900 loss 16.702347 loss_att 26.738266 loss_ctc 28.752731 loss_rnnt 13.088446 history loss 9.279377 rank 7
2022-12-03 22:19:05,735 DEBUG CV Batch 5/900 loss 16.702347 loss_att 26.738266 loss_ctc 28.752731 loss_rnnt 13.088446 history loss 9.279377 rank 4
2022-12-03 22:19:08,845 DEBUG CV Batch 5/900 loss 16.702347 loss_att 26.738266 loss_ctc 28.752731 loss_rnnt 13.088446 history loss 9.279377 rank 6
2022-12-03 22:19:09,139 DEBUG CV Batch 5/900 loss 16.702347 loss_att 26.738266 loss_ctc 28.752731 loss_rnnt 13.088446 history loss 9.279377 rank 5
2022-12-03 22:19:09,615 DEBUG CV Batch 5/900 loss 16.702347 loss_att 26.738266 loss_ctc 28.752731 loss_rnnt 13.088446 history loss 9.279377 rank 3
2022-12-03 22:19:09,659 DEBUG CV Batch 5/900 loss 16.702347 loss_att 26.738266 loss_ctc 28.752731 loss_rnnt 13.088446 history loss 9.279377 rank 0
2022-12-03 22:19:17,371 DEBUG CV Batch 5/1000 loss 6.025938 loss_att 5.907652 loss_ctc 8.118898 loss_rnnt 5.770534 history loss 9.013440 rank 1
2022-12-03 22:19:17,488 DEBUG CV Batch 5/1000 loss 6.025938 loss_att 5.907652 loss_ctc 8.118898 loss_rnnt 5.770534 history loss 9.013440 rank 2
2022-12-03 22:19:17,819 DEBUG CV Batch 5/1000 loss 6.025938 loss_att 5.907652 loss_ctc 8.118898 loss_rnnt 5.770534 history loss 9.013440 rank 7
2022-12-03 22:19:18,120 DEBUG CV Batch 5/1000 loss 6.025938 loss_att 5.907652 loss_ctc 8.118898 loss_rnnt 5.770534 history loss 9.013440 rank 4
2022-12-03 22:19:21,543 DEBUG CV Batch 5/1000 loss 6.025938 loss_att 5.907652 loss_ctc 8.118898 loss_rnnt 5.770534 history loss 9.013440 rank 6
2022-12-03 22:19:21,919 DEBUG CV Batch 5/1000 loss 6.025938 loss_att 5.907652 loss_ctc 8.118898 loss_rnnt 5.770534 history loss 9.013440 rank 5
2022-12-03 22:19:22,516 DEBUG CV Batch 5/1000 loss 6.025938 loss_att 5.907652 loss_ctc 8.118898 loss_rnnt 5.770534 history loss 9.013440 rank 0
2022-12-03 22:19:22,522 DEBUG CV Batch 5/1000 loss 6.025938 loss_att 5.907652 loss_ctc 8.118898 loss_rnnt 5.770534 history loss 9.013440 rank 3
2022-12-03 22:19:28,968 DEBUG CV Batch 5/1100 loss 6.289340 loss_att 6.677439 loss_ctc 11.172581 loss_rnnt 5.560621 history loss 8.986710 rank 1
2022-12-03 22:19:29,875 DEBUG CV Batch 5/1100 loss 6.289340 loss_att 6.677439 loss_ctc 11.172581 loss_rnnt 5.560621 history loss 8.986710 rank 7
2022-12-03 22:19:30,027 DEBUG CV Batch 5/1100 loss 6.289340 loss_att 6.677439 loss_ctc 11.172581 loss_rnnt 5.560621 history loss 8.986710 rank 2
2022-12-03 22:19:30,110 DEBUG CV Batch 5/1100 loss 6.289340 loss_att 6.677439 loss_ctc 11.172581 loss_rnnt 5.560621 history loss 8.986710 rank 4
2022-12-03 22:19:33,999 DEBUG CV Batch 5/1100 loss 6.289340 loss_att 6.677439 loss_ctc 11.172581 loss_rnnt 5.560621 history loss 8.986710 rank 6
2022-12-03 22:19:34,569 DEBUG CV Batch 5/1100 loss 6.289340 loss_att 6.677439 loss_ctc 11.172581 loss_rnnt 5.560621 history loss 8.986710 rank 5
2022-12-03 22:19:35,103 DEBUG CV Batch 5/1100 loss 6.289340 loss_att 6.677439 loss_ctc 11.172581 loss_rnnt 5.560621 history loss 8.986710 rank 0
2022-12-03 22:19:35,199 DEBUG CV Batch 5/1100 loss 6.289340 loss_att 6.677439 loss_ctc 11.172581 loss_rnnt 5.560621 history loss 8.986710 rank 3
2022-12-03 22:19:39,413 DEBUG CV Batch 5/1200 loss 10.368897 loss_att 11.391427 loss_ctc 16.984058 loss_rnnt 9.282370 history loss 9.372735 rank 1
2022-12-03 22:19:40,441 DEBUG CV Batch 5/1200 loss 10.368897 loss_att 11.391427 loss_ctc 16.984058 loss_rnnt 9.282370 history loss 9.372735 rank 7
2022-12-03 22:19:40,506 DEBUG CV Batch 5/1200 loss 10.368897 loss_att 11.391427 loss_ctc 16.984058 loss_rnnt 9.282370 history loss 9.372735 rank 4
2022-12-03 22:19:40,699 DEBUG CV Batch 5/1200 loss 10.368897 loss_att 11.391427 loss_ctc 16.984058 loss_rnnt 9.282370 history loss 9.372735 rank 2
2022-12-03 22:19:45,194 DEBUG CV Batch 5/1200 loss 10.368897 loss_att 11.391427 loss_ctc 16.984058 loss_rnnt 9.282370 history loss 9.372735 rank 6
2022-12-03 22:19:45,721 DEBUG CV Batch 5/1200 loss 10.368897 loss_att 11.391427 loss_ctc 16.984058 loss_rnnt 9.282370 history loss 9.372735 rank 5
2022-12-03 22:19:46,469 DEBUG CV Batch 5/1200 loss 10.368897 loss_att 11.391427 loss_ctc 16.984058 loss_rnnt 9.282370 history loss 9.372735 rank 0
2022-12-03 22:19:46,513 DEBUG CV Batch 5/1200 loss 10.368897 loss_att 11.391427 loss_ctc 16.984058 loss_rnnt 9.282370 history loss 9.372735 rank 3
2022-12-03 22:19:51,219 DEBUG CV Batch 5/1300 loss 8.460548 loss_att 8.231970 loss_ctc 14.058165 loss_rnnt 7.759915 history loss 9.668838 rank 1
2022-12-03 22:19:52,380 DEBUG CV Batch 5/1300 loss 8.460548 loss_att 8.231970 loss_ctc 14.058165 loss_rnnt 7.759915 history loss 9.668838 rank 4
2022-12-03 22:19:52,422 DEBUG CV Batch 5/1300 loss 8.460548 loss_att 8.231970 loss_ctc 14.058165 loss_rnnt 7.759915 history loss 9.668838 rank 7
2022-12-03 22:19:52,730 DEBUG CV Batch 5/1300 loss 8.460548 loss_att 8.231970 loss_ctc 14.058165 loss_rnnt 7.759915 history loss 9.668838 rank 2
2022-12-03 22:19:57,584 DEBUG CV Batch 5/1300 loss 8.460548 loss_att 8.231970 loss_ctc 14.058165 loss_rnnt 7.759915 history loss 9.668838 rank 6
2022-12-03 22:19:58,252 DEBUG CV Batch 5/1300 loss 8.460548 loss_att 8.231970 loss_ctc 14.058165 loss_rnnt 7.759915 history loss 9.668838 rank 5
2022-12-03 22:19:59,109 DEBUG CV Batch 5/1300 loss 8.460548 loss_att 8.231970 loss_ctc 14.058165 loss_rnnt 7.759915 history loss 9.668838 rank 3
2022-12-03 22:19:59,160 DEBUG CV Batch 5/1300 loss 8.460548 loss_att 8.231970 loss_ctc 14.058165 loss_rnnt 7.759915 history loss 9.668838 rank 0
2022-12-03 22:20:03,291 DEBUG CV Batch 5/1400 loss 12.134394 loss_att 38.318192 loss_ctc 18.449980 loss_rnnt 6.055556 history loss 10.052883 rank 1
2022-12-03 22:20:03,371 DEBUG CV Batch 5/1400 loss 12.134394 loss_att 38.318192 loss_ctc 18.449980 loss_rnnt 6.055556 history loss 10.052883 rank 4
2022-12-03 22:20:03,883 DEBUG CV Batch 5/1400 loss 12.134394 loss_att 38.318192 loss_ctc 18.449980 loss_rnnt 6.055556 history loss 10.052883 rank 7
2022-12-03 22:20:03,920 DEBUG CV Batch 5/1400 loss 12.134394 loss_att 38.318192 loss_ctc 18.449980 loss_rnnt 6.055556 history loss 10.052883 rank 2
2022-12-03 22:20:09,326 DEBUG CV Batch 5/1400 loss 12.134394 loss_att 38.318192 loss_ctc 18.449980 loss_rnnt 6.055556 history loss 10.052883 rank 6
2022-12-03 22:20:10,045 DEBUG CV Batch 5/1400 loss 12.134394 loss_att 38.318192 loss_ctc 18.449980 loss_rnnt 6.055556 history loss 10.052883 rank 5
2022-12-03 22:20:11,185 DEBUG CV Batch 5/1400 loss 12.134394 loss_att 38.318192 loss_ctc 18.449980 loss_rnnt 6.055556 history loss 10.052883 rank 3
2022-12-03 22:20:11,332 DEBUG CV Batch 5/1400 loss 12.134394 loss_att 38.318192 loss_ctc 18.449980 loss_rnnt 6.055556 history loss 10.052883 rank 0
2022-12-03 22:20:15,012 DEBUG CV Batch 5/1500 loss 11.208736 loss_att 13.757529 loss_ctc 14.764002 loss_rnnt 10.224943 history loss 9.840914 rank 4
2022-12-03 22:20:15,408 DEBUG CV Batch 5/1500 loss 11.208736 loss_att 13.757529 loss_ctc 14.764002 loss_rnnt 10.224943 history loss 9.840914 rank 2
2022-12-03 22:20:15,566 DEBUG CV Batch 5/1500 loss 11.208736 loss_att 13.757529 loss_ctc 14.764002 loss_rnnt 10.224943 history loss 9.840914 rank 7
2022-12-03 22:20:15,762 DEBUG CV Batch 5/1500 loss 11.208736 loss_att 13.757529 loss_ctc 14.764002 loss_rnnt 10.224943 history loss 9.840914 rank 1
2022-12-03 22:20:21,484 DEBUG CV Batch 5/1500 loss 11.208736 loss_att 13.757529 loss_ctc 14.764002 loss_rnnt 10.224943 history loss 9.840914 rank 6
2022-12-03 22:20:22,192 DEBUG CV Batch 5/1500 loss 11.208736 loss_att 13.757529 loss_ctc 14.764002 loss_rnnt 10.224943 history loss 9.840914 rank 5
2022-12-03 22:20:23,400 DEBUG CV Batch 5/1500 loss 11.208736 loss_att 13.757529 loss_ctc 14.764002 loss_rnnt 10.224943 history loss 9.840914 rank 3
2022-12-03 22:20:23,540 DEBUG CV Batch 5/1500 loss 11.208736 loss_att 13.757529 loss_ctc 14.764002 loss_rnnt 10.224943 history loss 9.840914 rank 0
2022-12-03 22:20:28,414 DEBUG CV Batch 5/1600 loss 11.123190 loss_att 22.732594 loss_ctc 18.252224 loss_rnnt 7.850770 history loss 9.753844 rank 4
2022-12-03 22:20:28,694 DEBUG CV Batch 5/1600 loss 11.123190 loss_att 22.732594 loss_ctc 18.252224 loss_rnnt 7.850770 history loss 9.753844 rank 2
2022-12-03 22:20:28,985 DEBUG CV Batch 5/1600 loss 11.123190 loss_att 22.732594 loss_ctc 18.252224 loss_rnnt 7.850770 history loss 9.753844 rank 7
2022-12-03 22:20:29,550 DEBUG CV Batch 5/1600 loss 11.123190 loss_att 22.732594 loss_ctc 18.252224 loss_rnnt 7.850770 history loss 9.753844 rank 1
2022-12-03 22:20:35,109 DEBUG CV Batch 5/1600 loss 11.123190 loss_att 22.732594 loss_ctc 18.252224 loss_rnnt 7.850770 history loss 9.753844 rank 6
2022-12-03 22:20:35,851 DEBUG CV Batch 5/1600 loss 11.123190 loss_att 22.732594 loss_ctc 18.252224 loss_rnnt 7.850770 history loss 9.753844 rank 5
2022-12-03 22:20:37,083 DEBUG CV Batch 5/1600 loss 11.123190 loss_att 22.732594 loss_ctc 18.252224 loss_rnnt 7.850770 history loss 9.753844 rank 3
2022-12-03 22:20:37,234 DEBUG CV Batch 5/1600 loss 11.123190 loss_att 22.732594 loss_ctc 18.252224 loss_rnnt 7.850770 history loss 9.753844 rank 0
2022-12-03 22:20:40,879 DEBUG CV Batch 5/1700 loss 12.373685 loss_att 12.732397 loss_ctc 22.422657 loss_rnnt 10.962079 history loss 9.630913 rank 4
2022-12-03 22:20:41,191 DEBUG CV Batch 5/1700 loss 12.373685 loss_att 12.732397 loss_ctc 22.422657 loss_rnnt 10.962079 history loss 9.630913 rank 2
2022-12-03 22:20:41,494 DEBUG CV Batch 5/1700 loss 12.373685 loss_att 12.732397 loss_ctc 22.422657 loss_rnnt 10.962079 history loss 9.630913 rank 7
2022-12-03 22:20:41,731 DEBUG CV Batch 5/1700 loss 12.373685 loss_att 12.732397 loss_ctc 22.422657 loss_rnnt 10.962079 history loss 9.630913 rank 1
2022-12-03 22:20:47,851 DEBUG CV Batch 5/1700 loss 12.373685 loss_att 12.732397 loss_ctc 22.422657 loss_rnnt 10.962079 history loss 9.630913 rank 6
2022-12-03 22:20:48,616 DEBUG CV Batch 5/1700 loss 12.373685 loss_att 12.732397 loss_ctc 22.422657 loss_rnnt 10.962079 history loss 9.630913 rank 5
2022-12-03 22:20:49,748 DEBUG CV Batch 5/1700 loss 12.373685 loss_att 12.732397 loss_ctc 22.422657 loss_rnnt 10.962079 history loss 9.630913 rank 3
2022-12-03 22:20:50,089 DEBUG CV Batch 5/1700 loss 12.373685 loss_att 12.732397 loss_ctc 22.422657 loss_rnnt 10.962079 history loss 9.630913 rank 0
2022-12-03 22:20:50,129 INFO Epoch 5 CV info cv_loss 9.588191622822146
2022-12-03 22:20:50,129 INFO Epoch 6 TRAIN info lr 0.000707205796929705
2022-12-03 22:20:50,132 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 22:20:50,580 INFO Epoch 5 CV info cv_loss 9.588191622822146
2022-12-03 22:20:50,581 INFO Epoch 6 TRAIN info lr 0.000706457139316299
2022-12-03 22:20:50,582 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 22:20:50,816 INFO Epoch 5 CV info cv_loss 9.588191622822146
2022-12-03 22:20:50,817 INFO Epoch 6 TRAIN info lr 0.0007068594236682566
2022-12-03 22:20:50,821 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 22:20:50,912 INFO Epoch 5 CV info cv_loss 9.588191622822146
2022-12-03 22:20:50,913 INFO Epoch 6 TRAIN info lr 0.0007069795363210172
2022-12-03 22:20:50,917 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 22:20:57,005 INFO Epoch 5 CV info cv_loss 9.588191622822146
2022-12-03 22:20:57,006 INFO Epoch 6 TRAIN info lr 0.0007071704293894907
2022-12-03 22:20:57,008 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 22:20:57,861 INFO Epoch 5 CV info cv_loss 9.588191622822146
2022-12-03 22:20:57,861 INFO Epoch 6 TRAIN info lr 0.0007070926394751738
2022-12-03 22:20:57,863 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 22:20:59,065 INFO Epoch 5 CV info cv_loss 9.588191622822146
2022-12-03 22:20:59,066 INFO Epoch 6 TRAIN info lr 0.0007067464323715661
2022-12-03 22:20:59,067 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 22:20:59,450 INFO Epoch 5 CV info cv_loss 9.588191622822146
2022-12-03 22:20:59,450 INFO Checkpoint: save to checkpoint exp/1202_encoder_bias_30_0.1/5.pt
2022-12-03 22:21:00,182 INFO Epoch 6 TRAIN info lr 0.0007067181930127675
2022-12-03 22:21:00,186 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-03 22:22:00,278 DEBUG TRAIN Batch 6/0 loss 17.057455 loss_att 16.895203 loss_ctc 23.234978 loss_rnnt 16.266235 lr 0.00070674 rank 3
2022-12-03 22:22:00,294 DEBUG TRAIN Batch 6/0 loss 9.027321 loss_att 9.951816 loss_ctc 13.187476 loss_rnnt 8.287735 lr 0.00070716 rank 6
2022-12-03 22:22:00,298 DEBUG TRAIN Batch 6/0 loss 15.590342 loss_att 16.158588 loss_ctc 20.963142 loss_rnnt 14.760319 lr 0.00070697 rank 7
2022-12-03 22:22:00,298 DEBUG TRAIN Batch 6/0 loss 13.122640 loss_att 12.431063 loss_ctc 15.418484 loss_rnnt 12.954843 lr 0.00070645 rank 2
2022-12-03 22:22:00,300 DEBUG TRAIN Batch 6/0 loss 13.093575 loss_att 13.576048 loss_ctc 18.843822 loss_rnnt 12.230379 lr 0.00070685 rank 1
2022-12-03 22:22:00,307 DEBUG TRAIN Batch 6/0 loss 12.341549 loss_att 12.933271 loss_ctc 18.909374 loss_rnnt 11.347494 lr 0.00070720 rank 4
2022-12-03 22:22:00,330 DEBUG TRAIN Batch 6/0 loss 12.924615 loss_att 12.505704 loss_ctc 16.702955 loss_rnnt 12.504619 lr 0.00070709 rank 5
2022-12-03 22:22:00,331 DEBUG TRAIN Batch 6/0 loss 15.535393 loss_att 15.066950 loss_ctc 21.259686 loss_rnnt 14.865843 lr 0.00070671 rank 0
2022-12-03 22:23:10,904 DEBUG TRAIN Batch 6/100 loss 17.641659 loss_att 32.923790 loss_ctc 34.707134 loss_rnnt 12.309836 lr 0.00070638 rank 5
2022-12-03 22:23:10,904 DEBUG TRAIN Batch 6/100 loss 34.025185 loss_att 35.058830 loss_ctc 43.214077 loss_rnnt 32.593269 lr 0.00070627 rank 7
2022-12-03 22:23:10,905 DEBUG TRAIN Batch 6/100 loss 16.481632 loss_att 21.365108 loss_ctc 31.980446 loss_rnnt 13.438429 lr 0.00070646 rank 6
2022-12-03 22:23:10,905 DEBUG TRAIN Batch 6/100 loss 28.057617 loss_att 35.418568 loss_ctc 50.344433 loss_rnnt 23.613850 lr 0.00070575 rank 2
2022-12-03 22:23:10,907 DEBUG TRAIN Batch 6/100 loss 21.472069 loss_att 23.645603 loss_ctc 35.345036 loss_rnnt 19.187632 lr 0.00070601 rank 0
2022-12-03 22:23:10,907 DEBUG TRAIN Batch 6/100 loss 13.562149 loss_att 22.150131 loss_ctc 25.559065 loss_rnnt 10.244964 lr 0.00070615 rank 1
2022-12-03 22:23:10,908 DEBUG TRAIN Batch 6/100 loss 21.691536 loss_att 28.035589 loss_ctc 40.095875 loss_rnnt 17.968811 lr 0.00070603 rank 3
2022-12-03 22:23:10,914 DEBUG TRAIN Batch 6/100 loss 12.521275 loss_att 17.538300 loss_ctc 28.850788 loss_rnnt 9.340601 lr 0.00070649 rank 4
2022-12-03 22:24:21,335 DEBUG TRAIN Batch 6/200 loss 6.609683 loss_att 11.272335 loss_ctc 12.001422 loss_rnnt 4.958254 lr 0.00070575 rank 6
2022-12-03 22:24:21,337 DEBUG TRAIN Batch 6/200 loss 18.955658 loss_att 21.763369 loss_ctc 35.461338 loss_rnnt 16.193359 lr 0.00070530 rank 0
2022-12-03 22:24:21,338 DEBUG TRAIN Batch 6/200 loss 15.239288 loss_att 20.471685 loss_ctc 25.859564 loss_rnnt 12.776772 lr 0.00070504 rank 2
2022-12-03 22:24:21,341 DEBUG TRAIN Batch 6/200 loss 12.161852 loss_att 18.597172 loss_ctc 22.038885 loss_rnnt 9.557850 lr 0.00070568 rank 5
2022-12-03 22:24:21,342 DEBUG TRAIN Batch 6/200 loss 13.230658 loss_att 19.804724 loss_ctc 30.131660 loss_rnnt 9.662376 lr 0.00070533 rank 3
2022-12-03 22:24:21,345 DEBUG TRAIN Batch 6/200 loss 25.187502 loss_att 25.424994 loss_ctc 37.283905 loss_rnnt 23.527149 lr 0.00070544 rank 1
2022-12-03 22:24:21,347 DEBUG TRAIN Batch 6/200 loss 6.659724 loss_att 12.059922 loss_ctc 12.428665 loss_rnnt 4.810492 lr 0.00070556 rank 7
2022-12-03 22:24:21,352 DEBUG TRAIN Batch 6/200 loss 11.045796 loss_att 18.170605 loss_ctc 20.219709 loss_rnnt 8.397646 lr 0.00070579 rank 4
2022-12-03 22:25:32,800 DEBUG TRAIN Batch 6/300 loss 18.215982 loss_att 24.637865 loss_ctc 27.562056 loss_rnnt 15.685463 lr 0.00070509 rank 4
2022-12-03 22:25:32,802 DEBUG TRAIN Batch 6/300 loss 19.214430 loss_att 24.450024 loss_ctc 29.818377 loss_rnnt 16.753452 lr 0.00070497 rank 5
2022-12-03 22:25:32,804 DEBUG TRAIN Batch 6/300 loss 20.170135 loss_att 27.421988 loss_ctc 32.989845 loss_rnnt 17.010469 lr 0.00070505 rank 6
2022-12-03 22:25:32,805 DEBUG TRAIN Batch 6/300 loss 12.571396 loss_att 17.996857 loss_ctc 21.925081 loss_rnnt 10.239145 lr 0.00070463 rank 3
2022-12-03 22:25:32,804 DEBUG TRAIN Batch 6/300 loss 22.068495 loss_att 24.867985 loss_ctc 31.301226 loss_rnnt 20.277565 lr 0.00070474 rank 1
2022-12-03 22:25:32,807 DEBUG TRAIN Batch 6/300 loss 17.015289 loss_att 20.639097 loss_ctc 27.802698 loss_rnnt 14.852205 lr 0.00070486 rank 7
2022-12-03 22:25:32,813 DEBUG TRAIN Batch 6/300 loss 27.126625 loss_att 29.031254 loss_ctc 41.244301 loss_rnnt 24.863342 lr 0.00070434 rank 2
2022-12-03 22:25:32,817 DEBUG TRAIN Batch 6/300 loss 18.267082 loss_att 27.794809 loss_ctc 32.125118 loss_rnnt 14.513798 lr 0.00070460 rank 0
2022-12-03 22:26:46,082 DEBUG TRAIN Batch 6/400 loss 20.660748 loss_att 23.138945 loss_ctc 27.934242 loss_rnnt 19.195309 lr 0.00070365 rank 2
2022-12-03 22:26:46,082 DEBUG TRAIN Batch 6/400 loss 17.633034 loss_att 22.826542 loss_ctc 26.181324 loss_rnnt 15.454559 lr 0.00070393 rank 3
2022-12-03 22:26:46,082 DEBUG TRAIN Batch 6/400 loss 11.138713 loss_att 19.385212 loss_ctc 17.985828 loss_rnnt 8.576465 lr 0.00070390 rank 0
2022-12-03 22:26:46,083 DEBUG TRAIN Batch 6/400 loss 33.279739 loss_att 34.166363 loss_ctc 49.358795 loss_rnnt 30.958540 lr 0.00070404 rank 1
2022-12-03 22:26:46,086 DEBUG TRAIN Batch 6/400 loss 11.229154 loss_att 16.862965 loss_ctc 24.352760 loss_rnnt 8.352577 lr 0.00070416 rank 7
2022-12-03 22:26:46,094 DEBUG TRAIN Batch 6/400 loss 21.778748 loss_att 24.441877 loss_ctc 32.271839 loss_rnnt 19.847042 lr 0.00070439 rank 4
2022-12-03 22:26:46,113 DEBUG TRAIN Batch 6/400 loss 18.649141 loss_att 27.719074 loss_ctc 31.611084 loss_rnnt 15.106895 lr 0.00070427 rank 5
2022-12-03 22:26:46,120 DEBUG TRAIN Batch 6/400 loss 24.068813 loss_att 25.750694 loss_ctc 48.481613 loss_rnnt 20.477398 lr 0.00070435 rank 6
2022-12-03 22:27:57,583 DEBUG TRAIN Batch 6/500 loss 14.271930 loss_att 16.332363 loss_ctc 23.774124 loss_rnnt 12.592883 lr 0.00070321 rank 0
2022-12-03 22:27:57,586 DEBUG TRAIN Batch 6/500 loss 23.064697 loss_att 26.236074 loss_ctc 36.136013 loss_rnnt 20.687580 lr 0.00070365 rank 6
2022-12-03 22:27:57,588 DEBUG TRAIN Batch 6/500 loss 21.984320 loss_att 25.209885 loss_ctc 33.254368 loss_rnnt 19.836533 lr 0.00070295 rank 2
2022-12-03 22:27:57,590 DEBUG TRAIN Batch 6/500 loss 16.788811 loss_att 18.931250 loss_ctc 19.369019 loss_rnnt 16.016294 lr 0.00070324 rank 3
2022-12-03 22:27:57,592 DEBUG TRAIN Batch 6/500 loss 18.465590 loss_att 22.027048 loss_ctc 30.644835 loss_rnnt 16.129398 lr 0.00070358 rank 5
2022-12-03 22:27:57,596 DEBUG TRAIN Batch 6/500 loss 19.711348 loss_att 24.567476 loss_ctc 32.072254 loss_rnnt 17.092001 lr 0.00070369 rank 4
2022-12-03 22:27:57,609 DEBUG TRAIN Batch 6/500 loss 24.869783 loss_att 28.904148 loss_ctc 39.285671 loss_rnnt 22.140791 lr 0.00070335 rank 1
2022-12-03 22:27:57,611 DEBUG TRAIN Batch 6/500 loss 20.952826 loss_att 25.589899 loss_ctc 37.156116 loss_rnnt 17.864971 lr 0.00070347 rank 7
2022-12-03 22:29:09,666 DEBUG TRAIN Batch 6/600 loss 21.605415 loss_att 29.426933 loss_ctc 41.590042 loss_rnnt 17.376495 lr 0.00070299 rank 4
2022-12-03 22:29:09,681 DEBUG TRAIN Batch 6/600 loss 10.020905 loss_att 13.966293 loss_ctc 15.557138 loss_rnnt 8.493663 lr 0.00070288 rank 5
2022-12-03 22:29:09,682 DEBUG TRAIN Batch 6/600 loss 17.776855 loss_att 19.632961 loss_ctc 26.828148 loss_rnnt 16.198793 lr 0.00070254 rank 3
2022-12-03 22:29:09,683 DEBUG TRAIN Batch 6/600 loss 18.742188 loss_att 20.213190 loss_ctc 25.291945 loss_rnnt 17.574684 lr 0.00070277 rank 7
2022-12-03 22:29:09,684 DEBUG TRAIN Batch 6/600 loss 15.652799 loss_att 18.069036 loss_ctc 27.839844 loss_rnnt 13.544611 lr 0.00070296 rank 6
2022-12-03 22:29:09,685 DEBUG TRAIN Batch 6/600 loss 15.979685 loss_att 16.920004 loss_ctc 21.665051 loss_rnnt 15.033571 lr 0.00070251 rank 0
2022-12-03 22:29:09,692 DEBUG TRAIN Batch 6/600 loss 14.201480 loss_att 15.821710 loss_ctc 22.015316 loss_rnnt 12.835588 lr 0.00070226 rank 2
2022-12-03 22:29:09,734 DEBUG TRAIN Batch 6/600 loss 13.082947 loss_att 14.562187 loss_ctc 20.804277 loss_rnnt 11.757587 lr 0.00070265 rank 1
2022-12-03 22:30:23,164 DEBUG TRAIN Batch 6/700 loss 12.645136 loss_att 19.028732 loss_ctc 26.012394 loss_rnnt 9.586115 lr 0.00070219 rank 5
2022-12-03 22:30:23,164 DEBUG TRAIN Batch 6/700 loss 15.531606 loss_att 21.251429 loss_ctc 24.136923 loss_rnnt 13.240265 lr 0.00070226 rank 6
2022-12-03 22:30:23,166 DEBUG TRAIN Batch 6/700 loss 18.190947 loss_att 24.251883 loss_ctc 34.303078 loss_rnnt 14.830475 lr 0.00070157 rank 2
2022-12-03 22:30:23,168 DEBUG TRAIN Batch 6/700 loss 8.756981 loss_att 13.498011 loss_ctc 22.322487 loss_rnnt 6.000041 lr 0.00070196 rank 1
2022-12-03 22:30:23,172 DEBUG TRAIN Batch 6/700 loss 19.712734 loss_att 24.681751 loss_ctc 34.602024 loss_rnnt 16.733692 lr 0.00070208 rank 7
2022-12-03 22:30:23,180 DEBUG TRAIN Batch 6/700 loss 15.654949 loss_att 22.357809 loss_ctc 30.735561 loss_rnnt 12.303629 lr 0.00070182 rank 0
2022-12-03 22:30:23,194 DEBUG TRAIN Batch 6/700 loss 24.832701 loss_att 31.207031 loss_ctc 37.576683 loss_rnnt 21.858639 lr 0.00070230 rank 4
2022-12-03 22:30:23,205 DEBUG TRAIN Batch 6/700 loss 10.294451 loss_att 15.296904 loss_ctc 19.005180 loss_rnnt 8.132529 lr 0.00070185 rank 3
2022-12-03 22:31:34,491 DEBUG TRAIN Batch 6/800 loss 14.441582 loss_att 19.953609 loss_ctc 26.477026 loss_rnnt 11.734449 lr 0.00070157 rank 6
2022-12-03 22:31:34,490 DEBUG TRAIN Batch 6/800 loss 20.421246 loss_att 32.641125 loss_ctc 37.194851 loss_rnnt 15.740790 lr 0.00070113 rank 0
2022-12-03 22:31:34,492 DEBUG TRAIN Batch 6/800 loss 15.097075 loss_att 22.249067 loss_ctc 23.757261 loss_rnnt 12.511984 lr 0.00070088 rank 2
2022-12-03 22:31:34,492 DEBUG TRAIN Batch 6/800 loss 9.091410 loss_att 14.333580 loss_ctc 20.287460 loss_rnnt 6.550169 lr 0.00070150 rank 5
2022-12-03 22:31:34,493 DEBUG TRAIN Batch 6/800 loss 20.779190 loss_att 22.239069 loss_ctc 33.109482 loss_rnnt 18.843176 lr 0.00070127 rank 1
2022-12-03 22:31:34,496 DEBUG TRAIN Batch 6/800 loss 16.554068 loss_att 17.320351 loss_ctc 20.008389 loss_rnnt 15.940235 lr 0.00070116 rank 3
2022-12-03 22:31:34,501 DEBUG TRAIN Batch 6/800 loss 15.056873 loss_att 19.482597 loss_ctc 31.533026 loss_rnnt 11.974907 lr 0.00070139 rank 7
2022-12-03 22:31:34,504 DEBUG TRAIN Batch 6/800 loss 7.204304 loss_att 12.590487 loss_ctc 11.229289 loss_rnnt 5.590402 lr 0.00070161 rank 4
2022-12-03 22:32:45,698 DEBUG TRAIN Batch 6/900 loss 17.678089 loss_att 19.432394 loss_ctc 31.664658 loss_rnnt 15.462352 lr 0.00070081 rank 5
2022-12-03 22:32:45,700 DEBUG TRAIN Batch 6/900 loss 29.165194 loss_att 32.239967 loss_ctc 41.882061 loss_rnnt 26.854658 lr 0.00070047 rank 3
2022-12-03 22:32:45,701 DEBUG TRAIN Batch 6/900 loss 17.768166 loss_att 23.267986 loss_ctc 31.816948 loss_rnnt 14.795029 lr 0.00070044 rank 0
2022-12-03 22:32:45,701 DEBUG TRAIN Batch 6/900 loss 20.428736 loss_att 27.532284 loss_ctc 36.359917 loss_rnnt 16.883869 lr 0.00070058 rank 1
2022-12-03 22:32:45,705 DEBUG TRAIN Batch 6/900 loss 17.723370 loss_att 22.640034 loss_ctc 29.987127 loss_rnnt 15.104869 lr 0.00070088 rank 6
2022-12-03 22:32:45,712 DEBUG TRAIN Batch 6/900 loss 16.954483 loss_att 24.202473 loss_ctc 32.173874 loss_rnnt 13.475634 lr 0.00070019 rank 2
2022-12-03 22:32:45,713 DEBUG TRAIN Batch 6/900 loss 24.897537 loss_att 31.942146 loss_ctc 45.621086 loss_rnnt 20.725475 lr 0.00070092 rank 4
2022-12-03 22:32:45,757 DEBUG TRAIN Batch 6/900 loss 22.073023 loss_att 27.098650 loss_ctc 34.657822 loss_rnnt 19.389923 lr 0.00070070 rank 7
2022-12-03 22:33:57,000 DEBUG TRAIN Batch 6/1000 loss 13.555323 loss_att 21.605095 loss_ctc 24.571003 loss_rnnt 10.476611 lr 0.00070019 rank 6
2022-12-03 22:33:57,001 DEBUG TRAIN Batch 6/1000 loss 17.214828 loss_att 25.475151 loss_ctc 35.734516 loss_rnnt 13.093473 lr 0.00070001 rank 7
2022-12-03 22:33:57,002 DEBUG TRAIN Batch 6/1000 loss 23.347260 loss_att 27.219742 loss_ctc 33.129967 loss_rnnt 21.268402 lr 0.00070012 rank 5
2022-12-03 22:33:57,003 DEBUG TRAIN Batch 6/1000 loss 11.738512 loss_att 17.090551 loss_ctc 21.232586 loss_rnnt 9.402227 lr 0.00069978 rank 3
2022-12-03 22:33:57,005 DEBUG TRAIN Batch 6/1000 loss 16.804901 loss_att 24.736130 loss_ctc 30.016708 loss_rnnt 13.457081 lr 0.00069989 rank 1
2022-12-03 22:33:57,006 DEBUG TRAIN Batch 6/1000 loss 10.631294 loss_att 13.688147 loss_ctc 16.575985 loss_rnnt 9.227299 lr 0.00069950 rank 2
2022-12-03 22:33:57,009 DEBUG TRAIN Batch 6/1000 loss 15.108688 loss_att 17.675377 loss_ctc 23.458874 loss_rnnt 13.481993 lr 0.00070023 rank 4
2022-12-03 22:33:57,014 DEBUG TRAIN Batch 6/1000 loss 22.427971 loss_att 29.897884 loss_ctc 35.648708 loss_rnnt 19.171223 lr 0.00069976 rank 0
2022-12-03 22:35:10,144 DEBUG TRAIN Batch 6/1100 loss 18.102175 loss_att 23.342701 loss_ctc 35.236008 loss_rnnt 14.769558 lr 0.00069921 rank 1
2022-12-03 22:35:10,145 DEBUG TRAIN Batch 6/1100 loss 12.519176 loss_att 17.221508 loss_ctc 24.564651 loss_rnnt 9.972647 lr 0.00069907 rank 0
2022-12-03 22:35:10,145 DEBUG TRAIN Batch 6/1100 loss 14.040539 loss_att 17.755823 loss_ctc 25.679340 loss_rnnt 11.745642 lr 0.00069943 rank 5
2022-12-03 22:35:10,147 DEBUG TRAIN Batch 6/1100 loss 8.467537 loss_att 13.061373 loss_ctc 16.610855 loss_rnnt 6.462994 lr 0.00069951 rank 6
2022-12-03 22:35:10,151 DEBUG TRAIN Batch 6/1100 loss 14.814607 loss_att 19.374893 loss_ctc 26.260925 loss_rnnt 12.376373 lr 0.00069882 rank 2
2022-12-03 22:35:10,153 DEBUG TRAIN Batch 6/1100 loss 17.297247 loss_att 22.617119 loss_ctc 28.411114 loss_rnnt 14.751423 lr 0.00069910 rank 3
2022-12-03 22:35:10,154 DEBUG TRAIN Batch 6/1100 loss 14.781148 loss_att 18.854256 loss_ctc 21.833288 loss_rnnt 13.026241 lr 0.00069954 rank 4
2022-12-03 22:35:10,162 DEBUG TRAIN Batch 6/1100 loss 27.261242 loss_att 30.414240 loss_ctc 46.017780 loss_rnnt 24.129772 lr 0.00069932 rank 7
2022-12-03 22:36:20,922 DEBUG TRAIN Batch 6/1200 loss 25.996002 loss_att 25.472494 loss_ctc 45.583523 loss_rnnt 23.489033 lr 0.00069839 rank 0
2022-12-03 22:36:20,924 DEBUG TRAIN Batch 6/1200 loss 17.807465 loss_att 19.742558 loss_ctc 25.239105 loss_rnnt 16.429562 lr 0.00069853 rank 1
2022-12-03 22:36:20,927 DEBUG TRAIN Batch 6/1200 loss 14.297894 loss_att 15.640069 loss_ctc 20.592514 loss_rnnt 13.190177 lr 0.00069842 rank 3
2022-12-03 22:36:20,927 DEBUG TRAIN Batch 6/1200 loss 14.938990 loss_att 18.210463 loss_ctc 22.272894 loss_rnnt 13.306841 lr 0.00069875 rank 5
2022-12-03 22:36:20,929 DEBUG TRAIN Batch 6/1200 loss 18.428413 loss_att 22.641781 loss_ctc 30.178104 loss_rnnt 16.019114 lr 0.00069883 rank 6
2022-12-03 22:36:20,929 DEBUG TRAIN Batch 6/1200 loss 25.251455 loss_att 28.875824 loss_ctc 33.251564 loss_rnnt 23.459900 lr 0.00069864 rank 7
2022-12-03 22:36:20,929 DEBUG TRAIN Batch 6/1200 loss 23.940485 loss_att 23.701294 loss_ctc 37.893841 loss_rnnt 22.127874 lr 0.00069814 rank 2
2022-12-03 22:36:20,937 DEBUG TRAIN Batch 6/1200 loss 9.671738 loss_att 11.155651 loss_ctc 14.754984 loss_rnnt 8.697189 lr 0.00069886 rank 4
2022-12-03 22:37:31,664 DEBUG TRAIN Batch 6/1300 loss 12.175800 loss_att 19.747419 loss_ctc 26.004192 loss_rnnt 8.817690 lr 0.00069814 rank 6
2022-12-03 22:37:31,668 DEBUG TRAIN Batch 6/1300 loss 14.888165 loss_att 14.918768 loss_ctc 25.006393 loss_rnnt 13.532946 lr 0.00069785 rank 1
2022-12-03 22:37:31,671 DEBUG TRAIN Batch 6/1300 loss 20.227257 loss_att 29.753925 loss_ctc 36.017159 loss_rnnt 16.216604 lr 0.00069771 rank 0
2022-12-03 22:37:31,672 DEBUG TRAIN Batch 6/1300 loss 28.585796 loss_att 32.289005 loss_ctc 40.917908 loss_rnnt 26.200872 lr 0.00069796 rank 7
2022-12-03 22:37:31,673 DEBUG TRAIN Batch 6/1300 loss 17.231047 loss_att 25.933323 loss_ctc 32.128647 loss_rnnt 13.504245 lr 0.00069774 rank 3
2022-12-03 22:37:31,675 DEBUG TRAIN Batch 6/1300 loss 16.166035 loss_att 21.977068 loss_ctc 25.710361 loss_rnnt 13.731249 lr 0.00069818 rank 4
2022-12-03 22:37:31,675 DEBUG TRAIN Batch 6/1300 loss 21.798359 loss_att 25.614557 loss_ctc 28.033768 loss_rnnt 20.203732 lr 0.00069807 rank 5
2022-12-03 22:37:31,678 DEBUG TRAIN Batch 6/1300 loss 27.998508 loss_att 34.292953 loss_ctc 33.947174 loss_rnnt 25.946463 lr 0.00069746 rank 2
2022-12-03 22:38:44,695 DEBUG TRAIN Batch 6/1400 loss 19.305305 loss_att 23.974192 loss_ctc 27.845892 loss_rnnt 17.232784 lr 0.00069703 rank 0
2022-12-03 22:38:44,711 DEBUG TRAIN Batch 6/1400 loss 36.079075 loss_att 40.693836 loss_ctc 50.821312 loss_rnnt 33.190491 lr 0.00069717 rank 1
2022-12-03 22:38:44,710 DEBUG TRAIN Batch 6/1400 loss 41.528732 loss_att 50.344711 loss_ctc 64.428818 loss_rnnt 36.712189 lr 0.00069706 rank 3
2022-12-03 22:38:44,711 DEBUG TRAIN Batch 6/1400 loss 27.226923 loss_att 32.839905 loss_ctc 48.784630 loss_rnnt 23.229965 lr 0.00069746 rank 6
2022-12-03 22:38:44,711 DEBUG TRAIN Batch 6/1400 loss 20.252300 loss_att 25.348888 loss_ctc 32.322292 loss_rnnt 17.623650 lr 0.00069728 rank 7
2022-12-03 22:38:44,711 DEBUG TRAIN Batch 6/1400 loss 22.822559 loss_att 30.826328 loss_ctc 38.420464 loss_rnnt 19.142086 lr 0.00069678 rank 2
2022-12-03 22:38:44,713 DEBUG TRAIN Batch 6/1400 loss 31.138321 loss_att 38.681507 loss_ctc 56.804379 loss_rnnt 26.207539 lr 0.00069739 rank 5
2022-12-03 22:38:44,764 DEBUG TRAIN Batch 6/1400 loss 31.458284 loss_att 29.590569 loss_ctc 35.801426 loss_rnnt 31.252743 lr 0.00069750 rank 4
2022-12-03 22:39:56,331 DEBUG TRAIN Batch 6/1500 loss 55.014774 loss_att 57.416077 loss_ctc 76.645386 loss_rnnt 51.650433 lr 0.00069671 rank 5
2022-12-03 22:39:56,332 DEBUG TRAIN Batch 6/1500 loss 23.620285 loss_att 25.989847 loss_ctc 39.394661 loss_rnnt 21.043121 lr 0.00069679 rank 6
2022-12-03 22:39:56,336 DEBUG TRAIN Batch 6/1500 loss 15.228025 loss_att 19.569395 loss_ctc 24.171101 loss_rnnt 13.167341 lr 0.00069610 rank 2
2022-12-03 22:39:56,338 DEBUG TRAIN Batch 6/1500 loss 20.120775 loss_att 25.729586 loss_ctc 36.133121 loss_rnnt 16.864033 lr 0.00069649 rank 1
2022-12-03 22:39:56,339 DEBUG TRAIN Batch 6/1500 loss 19.860674 loss_att 25.623293 loss_ctc 37.444901 loss_rnnt 16.363586 lr 0.00069635 rank 0
2022-12-03 22:39:56,341 DEBUG TRAIN Batch 6/1500 loss 19.196165 loss_att 22.456032 loss_ctc 30.398657 loss_rnnt 17.050528 lr 0.00069638 rank 3
2022-12-03 22:39:56,344 DEBUG TRAIN Batch 6/1500 loss 13.731840 loss_att 19.462442 loss_ctc 25.159904 loss_rnnt 11.061978 lr 0.00069682 rank 4
2022-12-03 22:39:56,345 DEBUG TRAIN Batch 6/1500 loss 23.593914 loss_att 27.943268 loss_ctc 35.674480 loss_rnnt 21.113300 lr 0.00069660 rank 7
2022-12-03 22:41:06,872 DEBUG TRAIN Batch 6/1600 loss 24.112116 loss_att 30.459846 loss_ctc 40.868423 loss_rnnt 20.608395 lr 0.00069611 rank 6
2022-12-03 22:41:06,876 DEBUG TRAIN Batch 6/1600 loss 7.547377 loss_att 14.036692 loss_ctc 16.138737 loss_rnnt 5.103999 lr 0.00069568 rank 0
2022-12-03 22:41:06,879 DEBUG TRAIN Batch 6/1600 loss 30.038895 loss_att 39.461170 loss_ctc 52.506546 loss_rnnt 25.158752 lr 0.00069581 rank 1
2022-12-03 22:41:06,880 DEBUG TRAIN Batch 6/1600 loss 14.438765 loss_att 20.155199 loss_ctc 27.661312 loss_rnnt 11.532471 lr 0.00069543 rank 2
2022-12-03 22:41:06,879 DEBUG TRAIN Batch 6/1600 loss 15.884529 loss_att 21.299257 loss_ctc 24.837349 loss_rnnt 13.607873 lr 0.00069571 rank 3
2022-12-03 22:41:06,879 DEBUG TRAIN Batch 6/1600 loss 11.314306 loss_att 18.741508 loss_ctc 20.976486 loss_rnnt 8.540575 lr 0.00069604 rank 5
2022-12-03 22:41:06,883 DEBUG TRAIN Batch 6/1600 loss 15.759215 loss_att 19.968243 loss_ctc 21.966909 loss_rnnt 14.089718 lr 0.00069615 rank 4
2022-12-03 22:41:06,889 DEBUG TRAIN Batch 6/1600 loss 11.396184 loss_att 16.870468 loss_ctc 20.197884 loss_rnnt 9.127768 lr 0.00069593 rank 7
2022-12-03 22:42:19,296 DEBUG TRAIN Batch 6/1700 loss 19.078030 loss_att 20.954884 loss_ctc 37.411026 loss_rnnt 16.258259 lr 0.00069503 rank 3
2022-12-03 22:42:19,296 DEBUG TRAIN Batch 6/1700 loss 24.174206 loss_att 28.339153 loss_ctc 35.009403 loss_rnnt 21.896523 lr 0.00069536 rank 5
2022-12-03 22:42:19,299 DEBUG TRAIN Batch 6/1700 loss 18.820341 loss_att 22.769840 loss_ctc 30.997971 loss_rnnt 16.406757 lr 0.00069501 rank 0
2022-12-03 22:42:19,299 DEBUG TRAIN Batch 6/1700 loss 16.251650 loss_att 16.702404 loss_ctc 27.313248 loss_rnnt 14.686619 lr 0.00069476 rank 2
2022-12-03 22:42:19,301 DEBUG TRAIN Batch 6/1700 loss 13.655612 loss_att 18.496517 loss_ctc 21.226994 loss_rnnt 11.677912 lr 0.00069544 rank 6
2022-12-03 22:42:19,304 DEBUG TRAIN Batch 6/1700 loss 22.915432 loss_att 29.176605 loss_ctc 41.916679 loss_rnnt 19.129696 lr 0.00069526 rank 7
2022-12-03 22:42:19,316 DEBUG TRAIN Batch 6/1700 loss 27.785120 loss_att 34.368042 loss_ctc 48.145912 loss_rnnt 23.753765 lr 0.00069514 rank 1
2022-12-03 22:42:19,320 DEBUG TRAIN Batch 6/1700 loss 26.107410 loss_att 31.228180 loss_ctc 40.662315 loss_rnnt 23.142605 lr 0.00069547 rank 4
2022-12-03 22:43:33,442 DEBUG TRAIN Batch 6/1800 loss 20.321928 loss_att 22.665606 loss_ctc 34.268658 loss_rnnt 17.993628 lr 0.00069477 rank 6
2022-12-03 22:43:33,445 DEBUG TRAIN Batch 6/1800 loss 32.844269 loss_att 36.584667 loss_ctc 56.748947 loss_rnnt 28.908901 lr 0.00069469 rank 5
2022-12-03 22:43:33,446 DEBUG TRAIN Batch 6/1800 loss 19.683128 loss_att 19.847988 loss_ctc 33.628098 loss_rnnt 17.790829 lr 0.00069447 rank 1
2022-12-03 22:43:33,447 DEBUG TRAIN Batch 6/1800 loss 19.310707 loss_att 20.745321 loss_ctc 31.269180 loss_rnnt 17.429321 lr 0.00069409 rank 2
2022-12-03 22:43:33,450 DEBUG TRAIN Batch 6/1800 loss 11.920804 loss_att 17.640022 loss_ctc 21.268738 loss_rnnt 9.530569 lr 0.00069434 rank 0
2022-12-03 22:43:33,455 DEBUG TRAIN Batch 6/1800 loss 19.357288 loss_att 25.111492 loss_ctc 36.326996 loss_rnnt 15.943820 lr 0.00069436 rank 3
2022-12-03 22:43:33,459 DEBUG TRAIN Batch 6/1800 loss 20.323259 loss_att 21.863712 loss_ctc 35.716408 loss_rnnt 17.962751 lr 0.00069480 rank 4
2022-12-03 22:43:33,493 DEBUG TRAIN Batch 6/1800 loss 14.874146 loss_att 18.901110 loss_ctc 28.574623 loss_rnnt 12.242023 lr 0.00069459 rank 7
2022-12-03 22:44:45,064 DEBUG TRAIN Batch 6/1900 loss 10.567287 loss_att 11.714294 loss_ctc 16.701151 loss_rnnt 9.520038 lr 0.00069410 rank 6
2022-12-03 22:44:45,067 DEBUG TRAIN Batch 6/1900 loss 22.534367 loss_att 24.202810 loss_ctc 33.905827 loss_rnnt 20.684483 lr 0.00069402 rank 5
2022-12-03 22:44:45,073 DEBUG TRAIN Batch 6/1900 loss 16.238647 loss_att 16.330084 loss_ctc 23.224213 loss_rnnt 15.288951 lr 0.00069370 rank 3
2022-12-03 22:44:45,073 DEBUG TRAIN Batch 6/1900 loss 15.260008 loss_att 17.845413 loss_ctc 22.635967 loss_rnnt 13.759466 lr 0.00069367 rank 0
2022-12-03 22:44:45,074 DEBUG TRAIN Batch 6/1900 loss 12.709092 loss_att 12.216135 loss_ctc 17.179090 loss_rnnt 12.211684 lr 0.00069392 rank 7
2022-12-03 22:44:45,074 DEBUG TRAIN Batch 6/1900 loss 23.359045 loss_att 25.514847 loss_ctc 33.078434 loss_rnnt 21.631966 lr 0.00069380 rank 1
2022-12-03 22:44:45,083 DEBUG TRAIN Batch 6/1900 loss 27.977646 loss_att 35.042717 loss_ctc 49.430416 loss_rnnt 23.704260 lr 0.00069413 rank 4
2022-12-03 22:44:45,121 DEBUG TRAIN Batch 6/1900 loss 10.429092 loss_att 20.060360 loss_ctc 25.730721 loss_rnnt 6.462621 lr 0.00069342 rank 2
2022-12-03 22:45:55,840 DEBUG TRAIN Batch 6/2000 loss 19.927769 loss_att 25.219284 loss_ctc 32.267021 loss_rnnt 17.224234 lr 0.00069343 rank 6
2022-12-03 22:45:55,842 DEBUG TRAIN Batch 6/2000 loss 16.847223 loss_att 23.662781 loss_ctc 26.495850 loss_rnnt 14.197630 lr 0.00069336 rank 5
2022-12-03 22:45:55,842 DEBUG TRAIN Batch 6/2000 loss 20.744705 loss_att 37.389984 loss_ctc 40.868652 loss_rnnt 14.732456 lr 0.00069314 rank 1
2022-12-03 22:45:55,842 DEBUG TRAIN Batch 6/2000 loss 9.705156 loss_att 17.353140 loss_ctc 16.600283 loss_rnnt 7.256210 lr 0.00069303 rank 3
2022-12-03 22:45:55,844 DEBUG TRAIN Batch 6/2000 loss 20.528938 loss_att 25.315413 loss_ctc 32.868385 loss_rnnt 17.926384 lr 0.00069276 rank 2
2022-12-03 22:45:55,844 DEBUG TRAIN Batch 6/2000 loss 20.194086 loss_att 23.457340 loss_ctc 30.689444 loss_rnnt 18.142056 lr 0.00069325 rank 7
2022-12-03 22:45:55,847 DEBUG TRAIN Batch 6/2000 loss 14.566891 loss_att 19.062647 loss_ctc 30.163509 loss_rnnt 11.588191 lr 0.00069300 rank 0
2022-12-03 22:45:55,891 DEBUG TRAIN Batch 6/2000 loss 18.949526 loss_att 22.370779 loss_ctc 32.178963 loss_rnnt 16.501350 lr 0.00069346 rank 4
2022-12-03 22:47:08,342 DEBUG TRAIN Batch 6/2100 loss 8.705740 loss_att 15.346269 loss_ctc 19.914618 loss_rnnt 5.883117 lr 0.00069247 rank 1
2022-12-03 22:47:08,349 DEBUG TRAIN Batch 6/2100 loss 31.467098 loss_att 35.977066 loss_ctc 51.048382 loss_rnnt 27.954266 lr 0.00069234 rank 0
2022-12-03 22:47:08,349 DEBUG TRAIN Batch 6/2100 loss 16.593990 loss_att 18.460657 loss_ctc 23.126837 loss_rnnt 15.349609 lr 0.00069236 rank 3
2022-12-03 22:47:08,350 DEBUG TRAIN Batch 6/2100 loss 10.267695 loss_att 15.166862 loss_ctc 17.830027 loss_rnnt 8.279552 lr 0.00069276 rank 6
2022-12-03 22:47:08,355 DEBUG TRAIN Batch 6/2100 loss 18.700823 loss_att 26.363750 loss_ctc 42.720806 loss_rnnt 13.965570 lr 0.00069280 rank 4
2022-12-03 22:47:08,354 DEBUG TRAIN Batch 6/2100 loss 15.537513 loss_att 21.693338 loss_ctc 27.760155 loss_rnnt 12.676662 lr 0.00069269 rank 5
2022-12-03 22:47:08,354 DEBUG TRAIN Batch 6/2100 loss 20.559452 loss_att 28.443151 loss_ctc 36.052017 loss_rnnt 16.917038 lr 0.00069209 rank 2
2022-12-03 22:47:08,357 DEBUG TRAIN Batch 6/2100 loss 31.209095 loss_att 37.119438 loss_ctc 54.373161 loss_rnnt 26.938484 lr 0.00069258 rank 7
2022-12-03 22:48:20,594 DEBUG TRAIN Batch 6/2200 loss 15.542381 loss_att 20.880793 loss_ctc 24.253780 loss_rnnt 13.313179 lr 0.00069210 rank 6
2022-12-03 22:48:20,597 DEBUG TRAIN Batch 6/2200 loss 14.183709 loss_att 19.116331 loss_ctc 27.518385 loss_rnnt 11.419228 lr 0.00069203 rank 5
2022-12-03 22:48:20,597 DEBUG TRAIN Batch 6/2200 loss 13.757022 loss_att 18.212700 loss_ctc 26.177683 loss_rnnt 11.209799 lr 0.00069181 rank 1
2022-12-03 22:48:20,600 DEBUG TRAIN Batch 6/2200 loss 15.773214 loss_att 20.215187 loss_ctc 23.817926 loss_rnnt 13.812191 lr 0.00069170 rank 3
2022-12-03 22:48:20,602 DEBUG TRAIN Batch 6/2200 loss 28.284214 loss_att 34.908268 loss_ctc 48.632114 loss_rnnt 24.246347 lr 0.00069143 rank 2
2022-12-03 22:48:20,604 DEBUG TRAIN Batch 6/2200 loss 21.864521 loss_att 24.663914 loss_ctc 34.715408 loss_rnnt 19.591190 lr 0.00069167 rank 0
2022-12-03 22:48:20,606 DEBUG TRAIN Batch 6/2200 loss 19.798544 loss_att 22.619143 loss_ctc 28.442005 loss_rnnt 18.081963 lr 0.00069213 rank 4
2022-12-03 22:48:20,613 DEBUG TRAIN Batch 6/2200 loss 17.208443 loss_att 23.621439 loss_ctc 28.678726 loss_rnnt 14.396471 lr 0.00069192 rank 7
2022-12-03 22:49:30,826 DEBUG TRAIN Batch 6/2300 loss 22.314377 loss_att 24.278732 loss_ctc 38.685326 loss_rnnt 19.738712 lr 0.00069101 rank 0
2022-12-03 22:49:30,827 DEBUG TRAIN Batch 6/2300 loss 31.914658 loss_att 41.405575 loss_ctc 46.869453 loss_rnnt 28.022503 lr 0.00069136 rank 5
2022-12-03 22:49:30,827 DEBUG TRAIN Batch 6/2300 loss 19.579353 loss_att 22.895533 loss_ctc 33.263050 loss_rnnt 17.091625 lr 0.00069104 rank 3
2022-12-03 22:49:30,830 DEBUG TRAIN Batch 6/2300 loss 22.075689 loss_att 27.945705 loss_ctc 33.909241 loss_rnnt 19.323877 lr 0.00069077 rank 2
2022-12-03 22:49:30,830 DEBUG TRAIN Batch 6/2300 loss 16.530811 loss_att 20.280674 loss_ctc 23.981308 loss_rnnt 14.787440 lr 0.00069144 rank 6
2022-12-03 22:49:30,832 DEBUG TRAIN Batch 6/2300 loss 30.446138 loss_att 35.906525 loss_ctc 47.084061 loss_rnnt 27.135672 lr 0.00069115 rank 1
2022-12-03 22:49:30,835 DEBUG TRAIN Batch 6/2300 loss 17.876144 loss_att 19.438986 loss_ctc 23.419346 loss_rnnt 16.824484 lr 0.00069126 rank 7
2022-12-03 22:49:30,844 DEBUG TRAIN Batch 6/2300 loss 12.074806 loss_att 16.310015 loss_ctc 23.007404 loss_rnnt 9.770084 lr 0.00069147 rank 4
2022-12-03 22:50:42,746 DEBUG TRAIN Batch 6/2400 loss 23.268810 loss_att 24.410696 loss_ctc 33.128971 loss_rnnt 21.725746 lr 0.00069078 rank 6
2022-12-03 22:50:42,767 DEBUG TRAIN Batch 6/2400 loss 28.726633 loss_att 35.715279 loss_ctc 44.204288 loss_rnnt 25.265215 lr 0.00069060 rank 7
2022-12-03 22:50:42,768 DEBUG TRAIN Batch 6/2400 loss 19.396383 loss_att 25.643410 loss_ctc 28.348045 loss_rnnt 16.953423 lr 0.00069038 rank 3
2022-12-03 22:50:42,769 DEBUG TRAIN Batch 6/2400 loss 25.826694 loss_att 28.476038 loss_ctc 40.507759 loss_rnnt 23.339352 lr 0.00069049 rank 1
2022-12-03 22:50:42,769 DEBUG TRAIN Batch 6/2400 loss 16.713005 loss_att 24.095465 loss_ctc 32.838226 loss_rnnt 13.086483 lr 0.00069035 rank 0
2022-12-03 22:50:42,771 DEBUG TRAIN Batch 6/2400 loss 10.078036 loss_att 19.081539 loss_ctc 25.282606 loss_rnnt 6.250060 lr 0.00069070 rank 5
2022-12-03 22:50:42,773 DEBUG TRAIN Batch 6/2400 loss 28.041424 loss_att 29.400471 loss_ctc 36.580395 loss_rnnt 26.631086 lr 0.00069081 rank 4
2022-12-03 22:50:42,779 DEBUG TRAIN Batch 6/2400 loss 23.820192 loss_att 27.948490 loss_ctc 38.883556 loss_rnnt 20.986084 lr 0.00069011 rank 2
2022-12-03 22:51:56,846 DEBUG TRAIN Batch 6/2500 loss 13.853787 loss_att 16.128796 loss_ctc 20.881550 loss_rnnt 12.461751 lr 0.00069012 rank 6
2022-12-03 22:51:56,859 DEBUG TRAIN Batch 6/2500 loss 14.315805 loss_att 17.441315 loss_ctc 24.422262 loss_rnnt 12.343175 lr 0.00068970 rank 0
2022-12-03 22:51:56,859 DEBUG TRAIN Batch 6/2500 loss 8.113824 loss_att 12.580504 loss_ctc 16.372885 loss_rnnt 6.119279 lr 0.00068972 rank 3
2022-12-03 22:51:56,861 DEBUG TRAIN Batch 6/2500 loss 19.541590 loss_att 22.976204 loss_ctc 33.631935 loss_rnnt 16.975954 lr 0.00069005 rank 5
2022-12-03 22:51:56,863 DEBUG TRAIN Batch 6/2500 loss 17.273233 loss_att 17.839579 loss_ctc 23.119543 loss_rnnt 16.380455 lr 0.00068983 rank 1
2022-12-03 22:51:56,864 DEBUG TRAIN Batch 6/2500 loss 8.027179 loss_att 15.981100 loss_ctc 15.997419 loss_rnnt 5.373695 lr 0.00068946 rank 2
2022-12-03 22:51:56,868 DEBUG TRAIN Batch 6/2500 loss 16.743122 loss_att 18.973179 loss_ctc 26.784790 loss_rnnt 14.958220 lr 0.00068994 rank 7
2022-12-03 22:51:56,868 DEBUG TRAIN Batch 6/2500 loss 15.833479 loss_att 15.451762 loss_ctc 21.852356 loss_rnnt 15.107306 lr 0.00069015 rank 4
2022-12-03 22:53:09,230 DEBUG TRAIN Batch 6/2600 loss 7.247972 loss_att 13.964417 loss_ctc 16.396471 loss_rnnt 4.684883 lr 0.00068946 rank 6
2022-12-03 22:53:09,231 DEBUG TRAIN Batch 6/2600 loss 28.541012 loss_att 30.894890 loss_ctc 41.120831 loss_rnnt 26.392927 lr 0.00068939 rank 5
2022-12-03 22:53:09,234 DEBUG TRAIN Batch 6/2600 loss 14.212251 loss_att 14.692949 loss_ctc 18.769314 loss_rnnt 13.508503 lr 0.00068904 rank 0
2022-12-03 22:53:09,237 DEBUG TRAIN Batch 6/2600 loss 18.574768 loss_att 31.629639 loss_ctc 32.583977 loss_rnnt 14.095901 lr 0.00068917 rank 1
2022-12-03 22:53:09,237 DEBUG TRAIN Batch 6/2600 loss 31.327894 loss_att 33.864609 loss_ctc 50.905071 loss_rnnt 28.210262 lr 0.00068928 rank 7
2022-12-03 22:53:09,238 DEBUG TRAIN Batch 6/2600 loss 12.801491 loss_att 12.029449 loss_ctc 16.057257 loss_rnnt 12.521797 lr 0.00068907 rank 3
2022-12-03 22:53:09,242 DEBUG TRAIN Batch 6/2600 loss 16.279619 loss_att 22.762646 loss_ctc 29.976650 loss_rnnt 13.156742 lr 0.00068880 rank 2
2022-12-03 22:53:09,243 DEBUG TRAIN Batch 6/2600 loss 9.733078 loss_att 15.397299 loss_ctc 16.823143 loss_rnnt 7.654892 lr 0.00068949 rank 4
2022-12-03 22:54:21,365 DEBUG TRAIN Batch 6/2700 loss 21.121458 loss_att 29.442293 loss_ctc 33.683743 loss_rnnt 17.782320 lr 0.00068874 rank 5
2022-12-03 22:54:21,368 DEBUG TRAIN Batch 6/2700 loss 22.191126 loss_att 24.006687 loss_ctc 31.910206 loss_rnnt 20.532135 lr 0.00068881 rank 6
2022-12-03 22:54:21,369 DEBUG TRAIN Batch 6/2700 loss 13.949369 loss_att 21.431246 loss_ctc 22.257637 loss_rnnt 11.345225 lr 0.00068842 rank 3
2022-12-03 22:54:21,370 DEBUG TRAIN Batch 6/2700 loss 19.683619 loss_att 25.102863 loss_ctc 37.481285 loss_rnnt 16.226746 lr 0.00068863 rank 7
2022-12-03 22:54:21,369 DEBUG TRAIN Batch 6/2700 loss 8.668983 loss_att 13.853742 loss_ctc 19.796627 loss_rnnt 6.148346 lr 0.00068852 rank 1
2022-12-03 22:54:21,373 DEBUG TRAIN Batch 6/2700 loss 6.716793 loss_att 10.309690 loss_ctc 11.679678 loss_rnnt 5.336495 lr 0.00068815 rank 2
2022-12-03 22:54:21,372 DEBUG TRAIN Batch 6/2700 loss 14.962104 loss_att 20.521896 loss_ctc 23.653828 loss_rnnt 12.691249 lr 0.00068884 rank 4
2022-12-03 22:54:21,378 DEBUG TRAIN Batch 6/2700 loss 19.815409 loss_att 25.612534 loss_ctc 36.412720 loss_rnnt 16.443008 lr 0.00068839 rank 0
2022-12-03 22:55:34,278 DEBUG TRAIN Batch 6/2800 loss 26.311659 loss_att 35.362061 loss_ctc 41.738190 loss_rnnt 22.444708 lr 0.00068774 rank 0
2022-12-03 22:55:34,279 DEBUG TRAIN Batch 6/2800 loss 13.154400 loss_att 17.740788 loss_ctc 19.083357 loss_rnnt 11.446594 lr 0.00068750 rank 2
2022-12-03 22:55:34,279 DEBUG TRAIN Batch 6/2800 loss 24.948414 loss_att 35.201103 loss_ctc 48.906837 loss_rnnt 19.703421 lr 0.00068815 rank 6
2022-12-03 22:55:34,282 DEBUG TRAIN Batch 6/2800 loss 12.123670 loss_att 18.003000 loss_ctc 23.828655 loss_rnnt 9.387138 lr 0.00068776 rank 3
2022-12-03 22:55:34,283 DEBUG TRAIN Batch 6/2800 loss 30.450790 loss_att 39.173843 loss_ctc 65.534424 loss_rnnt 24.028364 lr 0.00068808 rank 5
2022-12-03 22:55:34,288 DEBUG TRAIN Batch 6/2800 loss 8.256836 loss_att 15.705687 loss_ctc 15.208988 loss_rnnt 5.840112 lr 0.00068819 rank 4
2022-12-03 22:55:34,294 DEBUG TRAIN Batch 6/2800 loss 37.564560 loss_att 40.726326 loss_ctc 63.552395 loss_rnnt 33.467163 lr 0.00068798 rank 7
2022-12-03 22:55:34,328 DEBUG TRAIN Batch 6/2800 loss 41.071575 loss_att 40.438965 loss_ctc 73.675827 loss_rnnt 36.850861 lr 0.00068787 rank 1
2022-12-03 22:56:48,235 DEBUG TRAIN Batch 6/2900 loss 13.018103 loss_att 17.385979 loss_ctc 21.865726 loss_rnnt 10.964844 lr 0.00068750 rank 6
2022-12-03 22:56:48,238 DEBUG TRAIN Batch 6/2900 loss 10.290773 loss_att 15.329773 loss_ctc 18.582024 loss_rnnt 8.177473 lr 0.00068709 rank 0
2022-12-03 22:56:48,239 DEBUG TRAIN Batch 6/2900 loss 8.547817 loss_att 14.653000 loss_ctc 18.111458 loss_rnnt 6.051628 lr 0.00068685 rank 2
2022-12-03 22:56:48,239 DEBUG TRAIN Batch 6/2900 loss 13.596600 loss_att 19.883875 loss_ctc 26.259987 loss_rnnt 10.650693 lr 0.00068722 rank 1
2022-12-03 22:56:48,240 DEBUG TRAIN Batch 6/2900 loss 28.515903 loss_att 33.530281 loss_ctc 38.547089 loss_rnnt 26.175535 lr 0.00068743 rank 5
2022-12-03 22:56:48,243 DEBUG TRAIN Batch 6/2900 loss 30.776134 loss_att 33.818851 loss_ctc 50.061089 loss_rnnt 27.596262 lr 0.00068733 rank 7
2022-12-03 22:56:48,243 DEBUG TRAIN Batch 6/2900 loss 13.579542 loss_att 18.967295 loss_ctc 26.335381 loss_rnnt 10.801214 lr 0.00068711 rank 3
2022-12-03 22:56:48,248 DEBUG TRAIN Batch 6/2900 loss 7.773849 loss_att 14.250813 loss_ctc 16.549522 loss_rnnt 5.308367 lr 0.00068754 rank 4
2022-12-03 22:58:00,107 DEBUG TRAIN Batch 6/3000 loss 27.437298 loss_att 33.030628 loss_ctc 42.551109 loss_rnnt 24.303453 lr 0.00068647 rank 3
2022-12-03 22:58:00,109 DEBUG TRAIN Batch 6/3000 loss 10.381473 loss_att 16.650574 loss_ctc 17.680302 loss_rnnt 8.154475 lr 0.00068668 rank 7
2022-12-03 22:58:00,109 DEBUG TRAIN Batch 6/3000 loss 17.256416 loss_att 23.197250 loss_ctc 36.718216 loss_rnnt 13.473342 lr 0.00068685 rank 6
2022-12-03 22:58:00,110 DEBUG TRAIN Batch 6/3000 loss 12.644792 loss_att 16.013731 loss_ctc 19.994413 loss_rnnt 10.991055 lr 0.00068644 rank 0
2022-12-03 22:58:00,116 DEBUG TRAIN Batch 6/3000 loss 19.374777 loss_att 23.658913 loss_ctc 31.385191 loss_rnnt 16.916559 lr 0.00068620 rank 2
2022-12-03 22:58:00,118 DEBUG TRAIN Batch 6/3000 loss 33.785488 loss_att 39.906254 loss_ctc 59.479092 loss_rnnt 29.135521 lr 0.00068678 rank 5
2022-12-03 22:58:00,122 DEBUG TRAIN Batch 6/3000 loss 13.643487 loss_att 18.146763 loss_ctc 24.091995 loss_rnnt 11.349697 lr 0.00068689 rank 4
2022-12-03 22:58:00,157 DEBUG TRAIN Batch 6/3000 loss 11.984045 loss_att 14.762524 loss_ctc 16.651989 loss_rnnt 10.805957 lr 0.00068657 rank 1
2022-12-03 22:59:13,244 DEBUG TRAIN Batch 6/3100 loss 15.281505 loss_att 18.981556 loss_ctc 28.979971 loss_rnnt 12.715033 lr 0.00068614 rank 5
2022-12-03 22:59:13,247 DEBUG TRAIN Batch 6/3100 loss 15.915676 loss_att 19.936857 loss_ctc 26.267172 loss_rnnt 13.731239 lr 0.00068603 rank 7
2022-12-03 22:59:13,248 DEBUG TRAIN Batch 6/3100 loss 20.878471 loss_att 24.792660 loss_ctc 39.500599 loss_rnnt 17.612684 lr 0.00068579 rank 0
2022-12-03 22:59:13,249 DEBUG TRAIN Batch 6/3100 loss 20.948467 loss_att 27.616825 loss_ctc 31.902252 loss_rnnt 18.154289 lr 0.00068621 rank 6
2022-12-03 22:59:13,250 DEBUG TRAIN Batch 6/3100 loss 14.761230 loss_att 19.216900 loss_ctc 28.895222 loss_rnnt 11.985563 lr 0.00068582 rank 3
2022-12-03 22:59:13,251 DEBUG TRAIN Batch 6/3100 loss 18.807758 loss_att 27.999916 loss_ctc 29.287008 loss_rnnt 15.572093 lr 0.00068556 rank 2
2022-12-03 22:59:13,254 DEBUG TRAIN Batch 6/3100 loss 20.383293 loss_att 25.449879 loss_ctc 37.381996 loss_rnnt 17.103481 lr 0.00068624 rank 4
2022-12-03 22:59:13,296 DEBUG TRAIN Batch 6/3100 loss 14.877640 loss_att 14.773315 loss_ctc 25.080700 loss_rnnt 13.538095 lr 0.00068592 rank 1
2022-12-03 23:00:27,511 DEBUG TRAIN Batch 6/3200 loss 25.816650 loss_att 26.700270 loss_ctc 35.033562 loss_rnnt 24.411003 lr 0.00068539 rank 7
2022-12-03 23:00:27,523 DEBUG TRAIN Batch 6/3200 loss 12.550393 loss_att 12.460577 loss_ctc 20.082733 loss_rnnt 11.564045 lr 0.00068556 rank 6
2022-12-03 23:00:27,524 DEBUG TRAIN Batch 6/3200 loss 15.166466 loss_att 18.160574 loss_ctc 27.229229 loss_rnnt 12.959274 lr 0.00068549 rank 5
2022-12-03 23:00:27,527 DEBUG TRAIN Batch 6/3200 loss 11.099117 loss_att 14.252220 loss_ctc 17.115042 loss_rnnt 9.666373 lr 0.00068518 rank 3
2022-12-03 23:00:27,529 DEBUG TRAIN Batch 6/3200 loss 15.472738 loss_att 14.841101 loss_ctc 20.017241 loss_rnnt 14.993132 lr 0.00068515 rank 0
2022-12-03 23:00:27,532 DEBUG TRAIN Batch 6/3200 loss 16.054688 loss_att 25.063034 loss_ctc 34.497551 loss_rnnt 11.793971 lr 0.00068491 rank 2
2022-12-03 23:00:27,540 DEBUG TRAIN Batch 6/3200 loss 23.265442 loss_att 26.276131 loss_ctc 38.844551 loss_rnnt 20.586090 lr 0.00068528 rank 1
2022-12-03 23:00:27,557 DEBUG TRAIN Batch 6/3200 loss 21.541866 loss_att 29.431152 loss_ctc 37.791046 loss_rnnt 17.797451 lr 0.00068559 rank 4
2022-12-03 23:01:39,424 DEBUG TRAIN Batch 6/3300 loss 17.392727 loss_att 22.906616 loss_ctc 34.641403 loss_rnnt 13.990124 lr 0.00068451 rank 0
2022-12-03 23:01:39,427 DEBUG TRAIN Batch 6/3300 loss 43.080112 loss_att 49.800545 loss_ctc 68.858635 loss_rnnt 38.298889 lr 0.00068492 rank 6
2022-12-03 23:01:39,428 DEBUG TRAIN Batch 6/3300 loss 12.527079 loss_att 20.601768 loss_ctc 24.352131 loss_rnnt 9.335467 lr 0.00068485 rank 5
2022-12-03 23:01:39,428 DEBUG TRAIN Batch 6/3300 loss 32.668221 loss_att 41.626793 loss_ctc 65.738701 loss_rnnt 26.467108 lr 0.00068475 rank 7
2022-12-03 23:01:39,430 DEBUG TRAIN Batch 6/3300 loss 17.792385 loss_att 23.652882 loss_ctc 24.046652 loss_rnnt 15.786384 lr 0.00068453 rank 3
2022-12-03 23:01:39,430 DEBUG TRAIN Batch 6/3300 loss 10.323061 loss_att 15.844164 loss_ctc 17.781780 loss_rnnt 8.224344 lr 0.00068464 rank 1
2022-12-03 23:01:39,431 DEBUG TRAIN Batch 6/3300 loss 12.448344 loss_att 17.187664 loss_ctc 23.328197 loss_rnnt 10.049833 lr 0.00068495 rank 4
2022-12-03 23:01:39,475 DEBUG TRAIN Batch 6/3300 loss 10.077684 loss_att 18.512064 loss_ctc 19.743864 loss_rnnt 7.101984 lr 0.00068427 rank 2
2022-12-03 23:02:50,868 DEBUG TRAIN Batch 6/3400 loss 7.546467 loss_att 15.775001 loss_ctc 15.743858 loss_rnnt 4.807774 lr 0.00068389 rank 3
2022-12-03 23:02:50,871 DEBUG TRAIN Batch 6/3400 loss 22.887951 loss_att 23.377457 loss_ctc 39.896427 loss_rnnt 20.522253 lr 0.00068410 rank 7
2022-12-03 23:02:50,870 DEBUG TRAIN Batch 6/3400 loss 23.483690 loss_att 26.679092 loss_ctc 39.021988 loss_rnnt 20.772839 lr 0.00068428 rank 6
2022-12-03 23:02:50,871 DEBUG TRAIN Batch 6/3400 loss 4.228951 loss_att 7.618843 loss_ctc 6.401145 loss_rnnt 3.261347 lr 0.00068387 rank 0
2022-12-03 23:02:50,872 DEBUG TRAIN Batch 6/3400 loss 41.773506 loss_att 40.086758 loss_ctc 63.429745 loss_rnnt 39.223354 lr 0.00068421 rank 5
2022-12-03 23:02:50,873 DEBUG TRAIN Batch 6/3400 loss 19.400589 loss_att 26.522738 loss_ctc 32.473328 loss_rnnt 16.233128 lr 0.00068400 rank 1
2022-12-03 23:02:50,875 DEBUG TRAIN Batch 6/3400 loss 27.308899 loss_att 28.337622 loss_ctc 41.302940 loss_rnnt 25.237282 lr 0.00068363 rank 2
2022-12-03 23:02:50,876 DEBUG TRAIN Batch 6/3400 loss 37.212646 loss_att 42.324718 loss_ctc 50.484295 loss_rnnt 34.420681 lr 0.00068431 rank 4
2022-12-03 23:04:03,720 DEBUG TRAIN Batch 6/3500 loss 16.581301 loss_att 20.400024 loss_ctc 28.363457 loss_rnnt 14.246601 lr 0.00068336 rank 1
2022-12-03 23:04:03,724 DEBUG TRAIN Batch 6/3500 loss 15.910023 loss_att 22.243864 loss_ctc 23.229191 loss_rnnt 13.667366 lr 0.00068357 rank 5
2022-12-03 23:04:03,732 DEBUG TRAIN Batch 6/3500 loss 19.707756 loss_att 24.366673 loss_ctc 29.970987 loss_rnnt 17.407543 lr 0.00068367 rank 4
2022-12-03 23:04:03,736 DEBUG TRAIN Batch 6/3500 loss 13.484892 loss_att 18.458910 loss_ctc 22.169781 loss_rnnt 11.332104 lr 0.00068364 rank 6
2022-12-03 23:04:03,737 DEBUG TRAIN Batch 6/3500 loss 20.887379 loss_att 23.541365 loss_ctc 31.827789 loss_rnnt 18.897860 lr 0.00068299 rank 2
2022-12-03 23:04:03,737 DEBUG TRAIN Batch 6/3500 loss 30.063894 loss_att 32.225929 loss_ctc 43.392651 loss_rnnt 27.854321 lr 0.00068325 rank 3
2022-12-03 23:04:03,738 DEBUG TRAIN Batch 6/3500 loss 23.614162 loss_att 28.706469 loss_ctc 36.906418 loss_rnnt 20.823399 lr 0.00068323 rank 0
2022-12-03 23:04:03,756 DEBUG TRAIN Batch 6/3500 loss 12.672470 loss_att 19.737928 loss_ctc 23.602692 loss_rnnt 9.802015 lr 0.00068346 rank 7
2022-12-03 23:05:16,539 DEBUG TRAIN Batch 6/3600 loss 18.894262 loss_att 23.922857 loss_ctc 29.105030 loss_rnnt 16.527107 lr 0.00068236 rank 2
2022-12-03 23:05:16,541 DEBUG TRAIN Batch 6/3600 loss 25.886995 loss_att 32.162300 loss_ctc 44.238388 loss_rnnt 22.185081 lr 0.00068300 rank 6
2022-12-03 23:05:16,543 DEBUG TRAIN Batch 6/3600 loss 18.022112 loss_att 19.476276 loss_ctc 29.122570 loss_rnnt 16.251217 lr 0.00068259 rank 0
2022-12-03 23:05:16,544 DEBUG TRAIN Batch 6/3600 loss 13.400863 loss_att 19.283478 loss_ctc 25.285057 loss_rnnt 10.639780 lr 0.00068293 rank 5
2022-12-03 23:05:16,545 DEBUG TRAIN Batch 6/3600 loss 16.834154 loss_att 20.110157 loss_ctc 24.808296 loss_rnnt 15.115736 lr 0.00068283 rank 7
2022-12-03 23:05:16,546 DEBUG TRAIN Batch 6/3600 loss 12.325072 loss_att 17.658295 loss_ctc 19.213430 loss_rnnt 10.339980 lr 0.00068262 rank 3
2022-12-03 23:05:16,547 DEBUG TRAIN Batch 6/3600 loss 9.777738 loss_att 12.463819 loss_ctc 18.515766 loss_rnnt 8.075451 lr 0.00068272 rank 1
2022-12-03 23:05:16,550 DEBUG TRAIN Batch 6/3600 loss 15.364391 loss_att 19.962715 loss_ctc 27.410416 loss_rnnt 12.838590 lr 0.00068303 rank 4
2022-12-03 23:06:28,278 DEBUG TRAIN Batch 6/3700 loss 14.650168 loss_att 18.282183 loss_ctc 22.865156 loss_rnnt 12.828432 lr 0.00068219 rank 7
2022-12-03 23:06:28,280 DEBUG TRAIN Batch 6/3700 loss 24.511114 loss_att 27.725706 loss_ctc 44.954704 loss_rnnt 21.142385 lr 0.00068236 rank 6
2022-12-03 23:06:28,281 DEBUG TRAIN Batch 6/3700 loss 17.345322 loss_att 21.402397 loss_ctc 28.430614 loss_rnnt 15.055866 lr 0.00068196 rank 0
2022-12-03 23:06:28,282 DEBUG TRAIN Batch 6/3700 loss 20.457739 loss_att 24.875362 loss_ctc 39.519913 loss_rnnt 17.032591 lr 0.00068229 rank 5
2022-12-03 23:06:28,282 DEBUG TRAIN Batch 6/3700 loss 18.608841 loss_att 25.368361 loss_ctc 26.413853 loss_rnnt 16.216269 lr 0.00068172 rank 2
2022-12-03 23:06:28,283 DEBUG TRAIN Batch 6/3700 loss 11.813383 loss_att 14.854306 loss_ctc 23.416542 loss_rnnt 9.658110 lr 0.00068208 rank 1
2022-12-03 23:06:28,289 DEBUG TRAIN Batch 6/3700 loss 11.874514 loss_att 15.658146 loss_ctc 15.842033 loss_rnnt 10.588783 lr 0.00068198 rank 3
2022-12-03 23:06:28,292 DEBUG TRAIN Batch 6/3700 loss 17.029881 loss_att 21.185352 loss_ctc 28.109592 loss_rnnt 14.721492 lr 0.00068239 rank 4
2022-12-03 23:07:40,795 DEBUG TRAIN Batch 6/3800 loss 20.482475 loss_att 28.391487 loss_ctc 33.252556 loss_rnnt 17.197996 lr 0.00068166 rank 5
2022-12-03 23:07:40,795 DEBUG TRAIN Batch 6/3800 loss 24.802515 loss_att 26.419464 loss_ctc 38.049908 loss_rnnt 22.712807 lr 0.00068132 rank 0
2022-12-03 23:07:40,795 DEBUG TRAIN Batch 6/3800 loss 11.071424 loss_att 13.447439 loss_ctc 18.193373 loss_rnnt 9.646628 lr 0.00068135 rank 3
2022-12-03 23:07:40,795 DEBUG TRAIN Batch 6/3800 loss 10.817259 loss_att 13.817102 loss_ctc 15.189644 loss_rnnt 9.634306 lr 0.00068145 rank 1
2022-12-03 23:07:40,796 DEBUG TRAIN Batch 6/3800 loss 10.717924 loss_att 14.530622 loss_ctc 16.425756 loss_rnnt 9.194341 lr 0.00068173 rank 6
2022-12-03 23:07:40,797 DEBUG TRAIN Batch 6/3800 loss 18.770863 loss_att 18.128166 loss_ctc 27.632025 loss_rnnt 17.717915 lr 0.00068156 rank 7
2022-12-03 23:07:40,800 DEBUG TRAIN Batch 6/3800 loss 11.204816 loss_att 11.976193 loss_ctc 15.203256 loss_rnnt 10.517415 lr 0.00068176 rank 4
2022-12-03 23:07:40,846 DEBUG TRAIN Batch 6/3800 loss 17.608086 loss_att 18.492970 loss_ctc 23.165237 loss_rnnt 16.690155 lr 0.00068109 rank 2
2022-12-03 23:08:54,984 DEBUG TRAIN Batch 6/3900 loss 13.479002 loss_att 19.263905 loss_ctc 24.302969 loss_rnnt 10.878826 lr 0.00068069 rank 0
2022-12-03 23:08:54,984 DEBUG TRAIN Batch 6/3900 loss 10.850931 loss_att 12.297953 loss_ctc 18.509670 loss_rnnt 9.540361 lr 0.00068072 rank 3
2022-12-03 23:08:54,987 DEBUG TRAIN Batch 6/3900 loss 5.498750 loss_att 10.401569 loss_ctc 11.735374 loss_rnnt 3.686636 lr 0.00068110 rank 6
2022-12-03 23:08:54,989 DEBUG TRAIN Batch 6/3900 loss 26.893373 loss_att 32.913933 loss_ctc 45.114441 loss_rnnt 23.259787 lr 0.00068046 rank 2
2022-12-03 23:08:54,992 DEBUG TRAIN Batch 6/3900 loss 19.013334 loss_att 25.172783 loss_ctc 30.156361 loss_rnnt 16.295708 lr 0.00068082 rank 1
2022-12-03 23:08:54,994 DEBUG TRAIN Batch 6/3900 loss 13.740536 loss_att 18.929262 loss_ctc 20.650585 loss_rnnt 11.781451 lr 0.00068103 rank 5
2022-12-03 23:08:55,001 DEBUG TRAIN Batch 6/3900 loss 24.564444 loss_att 28.187857 loss_ctc 35.048950 loss_rnnt 22.441830 lr 0.00068113 rank 4
2022-12-03 23:08:55,018 DEBUG TRAIN Batch 6/3900 loss 27.620573 loss_att 31.054434 loss_ctc 38.091766 loss_rnnt 25.537642 lr 0.00068092 rank 7
2022-12-03 23:10:06,987 DEBUG TRAIN Batch 6/4000 loss 15.187335 loss_att 19.741446 loss_ctc 22.992691 loss_rnnt 13.235800 lr 0.00068009 rank 3
2022-12-03 23:10:07,004 DEBUG TRAIN Batch 6/4000 loss 31.443748 loss_att 35.565895 loss_ctc 48.786568 loss_rnnt 28.306944 lr 0.00068039 rank 5
2022-12-03 23:10:07,008 DEBUG TRAIN Batch 6/4000 loss 13.155820 loss_att 17.256552 loss_ctc 21.688168 loss_rnnt 11.198028 lr 0.00068046 rank 6
2022-12-03 23:10:07,009 DEBUG TRAIN Batch 6/4000 loss 30.854219 loss_att 31.337685 loss_ctc 56.328560 loss_rnnt 27.360947 lr 0.00068006 rank 0
2022-12-03 23:10:07,012 DEBUG TRAIN Batch 6/4000 loss 13.437974 loss_att 17.992968 loss_ctc 27.232578 loss_rnnt 10.687695 lr 0.00068029 rank 7
2022-12-03 23:10:07,018 DEBUG TRAIN Batch 6/4000 loss 34.848679 loss_att 38.569157 loss_ctc 49.372643 loss_rnnt 32.168056 lr 0.00068050 rank 4
2022-12-03 23:10:07,023 DEBUG TRAIN Batch 6/4000 loss 26.550285 loss_att 31.591854 loss_ctc 38.457481 loss_rnnt 23.954346 lr 0.00067983 rank 2
2022-12-03 23:10:07,056 DEBUG TRAIN Batch 6/4000 loss 12.413004 loss_att 20.942951 loss_ctc 30.127193 loss_rnnt 8.345123 lr 0.00068019 rank 1
2022-12-03 23:11:18,264 DEBUG TRAIN Batch 6/4100 loss 25.687590 loss_att 36.152695 loss_ctc 46.663719 loss_rnnt 20.797750 lr 0.00067987 rank 4
2022-12-03 23:11:18,265 DEBUG TRAIN Batch 6/4100 loss 18.569300 loss_att 21.244421 loss_ctc 30.251608 loss_rnnt 16.476633 lr 0.00067983 rank 6
2022-12-03 23:11:18,266 DEBUG TRAIN Batch 6/4100 loss 10.495190 loss_att 15.137056 loss_ctc 20.353615 loss_rnnt 8.252359 lr 0.00067956 rank 1
2022-12-03 23:11:18,270 DEBUG TRAIN Batch 6/4100 loss 12.838549 loss_att 16.332657 loss_ctc 19.331236 loss_rnnt 11.274035 lr 0.00067946 rank 3
2022-12-03 23:11:18,271 DEBUG TRAIN Batch 6/4100 loss 27.436718 loss_att 27.011703 loss_ctc 39.616573 loss_rnnt 25.897741 lr 0.00067943 rank 0
2022-12-03 23:11:18,275 DEBUG TRAIN Batch 6/4100 loss 27.038254 loss_att 31.303356 loss_ctc 46.254963 loss_rnnt 23.623007 lr 0.00067920 rank 2
2022-12-03 23:11:18,276 DEBUG TRAIN Batch 6/4100 loss 12.702713 loss_att 15.804763 loss_ctc 23.408646 loss_rnnt 10.654846 lr 0.00067977 rank 5
2022-12-03 23:11:18,289 DEBUG TRAIN Batch 6/4100 loss 12.147578 loss_att 18.920511 loss_ctc 21.667706 loss_rnnt 9.523642 lr 0.00067967 rank 7
2022-12-03 23:12:30,685 DEBUG TRAIN Batch 6/4200 loss 31.200588 loss_att 31.792112 loss_ctc 42.780796 loss_rnnt 29.538254 lr 0.00067858 rank 2
2022-12-03 23:12:30,685 DEBUG TRAIN Batch 6/4200 loss 34.839966 loss_att 41.516762 loss_ctc 60.662899 loss_rnnt 30.061546 lr 0.00067904 rank 7
2022-12-03 23:12:30,688 DEBUG TRAIN Batch 6/4200 loss 24.190247 loss_att 29.304855 loss_ctc 45.496418 loss_rnnt 20.326500 lr 0.00067914 rank 5
2022-12-03 23:12:30,688 DEBUG TRAIN Batch 6/4200 loss 29.333227 loss_att 32.361740 loss_ctc 47.707314 loss_rnnt 26.277647 lr 0.00067881 rank 0
2022-12-03 23:12:30,688 DEBUG TRAIN Batch 6/4200 loss 23.975441 loss_att 25.560442 loss_ctc 37.474518 loss_rnnt 21.858564 lr 0.00067883 rank 3
2022-12-03 23:12:30,689 DEBUG TRAIN Batch 6/4200 loss 6.903400 loss_att 12.640376 loss_ctc 13.133717 loss_rnnt 4.925295 lr 0.00067921 rank 6
2022-12-03 23:12:30,698 DEBUG TRAIN Batch 6/4200 loss 17.960640 loss_att 24.355181 loss_ctc 32.083061 loss_rnnt 14.798743 lr 0.00067924 rank 4
2022-12-03 23:12:30,734 DEBUG TRAIN Batch 6/4200 loss 20.386114 loss_att 25.976191 loss_ctc 36.777699 loss_rnnt 17.082554 lr 0.00067893 rank 1
2022-12-03 23:13:44,535 DEBUG TRAIN Batch 6/4300 loss 19.613342 loss_att 25.000778 loss_ctc 30.485363 loss_rnnt 17.086252 lr 0.00067858 rank 6
2022-12-03 23:13:44,537 DEBUG TRAIN Batch 6/4300 loss 19.589937 loss_att 23.453041 loss_ctc 30.565264 loss_rnnt 17.353939 lr 0.00067821 rank 3
2022-12-03 23:13:44,538 DEBUG TRAIN Batch 6/4300 loss 16.835556 loss_att 18.560638 loss_ctc 28.070423 loss_rnnt 14.992559 lr 0.00067841 rank 7
2022-12-03 23:13:44,542 DEBUG TRAIN Batch 6/4300 loss 8.934402 loss_att 13.442616 loss_ctc 16.024837 loss_rnnt 7.087368 lr 0.00067851 rank 5
2022-12-03 23:13:44,542 DEBUG TRAIN Batch 6/4300 loss 23.997358 loss_att 28.273922 loss_ctc 38.303543 loss_rnnt 21.234554 lr 0.00067861 rank 4
2022-12-03 23:13:44,542 DEBUG TRAIN Batch 6/4300 loss 13.853271 loss_att 21.219053 loss_ctc 22.038486 loss_rnnt 11.288753 lr 0.00067818 rank 0
2022-12-03 23:13:44,544 DEBUG TRAIN Batch 6/4300 loss 17.397833 loss_att 18.355616 loss_ctc 27.662445 loss_rnnt 15.837661 lr 0.00067795 rank 2
2022-12-03 23:13:44,544 DEBUG TRAIN Batch 6/4300 loss 19.695951 loss_att 24.828632 loss_ctc 42.165329 loss_rnnt 15.673498 lr 0.00067831 rank 1
2022-12-03 23:14:57,113 DEBUG TRAIN Batch 6/4400 loss 17.248747 loss_att 24.468451 loss_ctc 35.234982 loss_rnnt 13.406641 lr 0.00067789 rank 5
2022-12-03 23:14:57,118 DEBUG TRAIN Batch 6/4400 loss 9.081516 loss_att 12.529653 loss_ctc 15.350600 loss_rnnt 7.556011 lr 0.00067756 rank 0
2022-12-03 23:14:57,118 DEBUG TRAIN Batch 6/4400 loss 11.345192 loss_att 14.053306 loss_ctc 14.784401 loss_rnnt 10.345008 lr 0.00067768 rank 1
2022-12-03 23:14:57,120 DEBUG TRAIN Batch 6/4400 loss 18.336452 loss_att 20.923779 loss_ctc 26.766638 loss_rnnt 16.694962 lr 0.00067779 rank 7
2022-12-03 23:14:57,121 DEBUG TRAIN Batch 6/4400 loss 20.422697 loss_att 24.857227 loss_ctc 30.866089 loss_rnnt 18.143339 lr 0.00067796 rank 6
2022-12-03 23:14:57,124 DEBUG TRAIN Batch 6/4400 loss 16.050472 loss_att 20.546028 loss_ctc 32.605492 loss_rnnt 12.944025 lr 0.00067758 rank 3
2022-12-03 23:14:57,126 DEBUG TRAIN Batch 6/4400 loss 15.170492 loss_att 15.781907 loss_ctc 24.601889 loss_rnnt 13.790690 lr 0.00067799 rank 4
2022-12-03 23:14:57,169 DEBUG TRAIN Batch 6/4400 loss 12.925381 loss_att 17.093250 loss_ctc 25.163403 loss_rnnt 10.460071 lr 0.00067733 rank 2
2022-12-03 23:16:08,415 DEBUG TRAIN Batch 6/4500 loss 21.429972 loss_att 27.140301 loss_ctc 37.705097 loss_rnnt 18.117889 lr 0.00067727 rank 5
2022-12-03 23:16:08,417 DEBUG TRAIN Batch 6/4500 loss 11.635784 loss_att 13.963094 loss_ctc 17.820866 loss_rnnt 10.345645 lr 0.00067696 rank 3
2022-12-03 23:16:08,420 DEBUG TRAIN Batch 6/4500 loss 17.853928 loss_att 22.381800 loss_ctc 34.750397 loss_rnnt 14.695490 lr 0.00067694 rank 0
2022-12-03 23:16:08,420 DEBUG TRAIN Batch 6/4500 loss 16.669636 loss_att 18.241182 loss_ctc 20.513073 loss_rnnt 15.842868 lr 0.00067706 rank 1
2022-12-03 23:16:08,421 DEBUG TRAIN Batch 6/4500 loss 14.799232 loss_att 18.298485 loss_ctc 23.732508 loss_rnnt 12.908278 lr 0.00067734 rank 6
2022-12-03 23:16:08,424 DEBUG TRAIN Batch 6/4500 loss 25.858025 loss_att 28.439716 loss_ctc 34.130791 loss_rnnt 24.238653 lr 0.00067671 rank 2
2022-12-03 23:16:08,427 DEBUG TRAIN Batch 6/4500 loss 10.918922 loss_att 17.320953 loss_ctc 18.442965 loss_rnnt 8.635311 lr 0.00067737 rank 4
2022-12-03 23:16:08,432 DEBUG TRAIN Batch 6/4500 loss 12.151408 loss_att 19.932930 loss_ctc 22.966160 loss_rnnt 9.153137 lr 0.00067717 rank 7
2022-12-03 23:17:21,892 DEBUG TRAIN Batch 6/4600 loss 19.209648 loss_att 21.559723 loss_ctc 35.837727 loss_rnnt 16.522556 lr 0.00067655 rank 7
2022-12-03 23:17:21,895 DEBUG TRAIN Batch 6/4600 loss 23.862877 loss_att 26.985151 loss_ctc 41.514835 loss_rnnt 20.884827 lr 0.00067675 rank 4
2022-12-03 23:17:21,898 DEBUG TRAIN Batch 6/4600 loss 14.305266 loss_att 18.180059 loss_ctc 21.025360 loss_rnnt 12.634295 lr 0.00067632 rank 0
2022-12-03 23:17:21,899 DEBUG TRAIN Batch 6/4600 loss 20.235306 loss_att 25.914410 loss_ctc 34.177803 loss_rnnt 17.240486 lr 0.00067634 rank 3
2022-12-03 23:17:21,899 DEBUG TRAIN Batch 6/4600 loss 22.671715 loss_att 28.028362 loss_ctc 38.843941 loss_rnnt 19.444088 lr 0.00067644 rank 1
2022-12-03 23:17:21,903 DEBUG TRAIN Batch 6/4600 loss 36.970543 loss_att 43.181824 loss_ctc 62.623070 loss_rnnt 32.307945 lr 0.00067609 rank 2
2022-12-03 23:17:21,917 DEBUG TRAIN Batch 6/4600 loss 19.812738 loss_att 23.834164 loss_ctc 27.939240 loss_rnnt 17.924919 lr 0.00067671 rank 6
2022-12-03 23:17:21,942 DEBUG TRAIN Batch 6/4600 loss 21.621107 loss_att 30.595776 loss_ctc 40.242367 loss_rnnt 17.343338 lr 0.00067665 rank 5
2022-12-03 23:18:34,695 DEBUG TRAIN Batch 6/4700 loss 17.959717 loss_att 20.890469 loss_ctc 26.840252 loss_rnnt 16.189495 lr 0.00067603 rank 5
2022-12-03 23:18:34,697 DEBUG TRAIN Batch 6/4700 loss 31.043652 loss_att 32.605698 loss_ctc 55.225292 loss_rnnt 27.507025 lr 0.00067570 rank 0
2022-12-03 23:18:34,699 DEBUG TRAIN Batch 6/4700 loss 25.005133 loss_att 31.719219 loss_ctc 36.803547 loss_rnnt 22.089191 lr 0.00067610 rank 6
2022-12-03 23:18:34,700 DEBUG TRAIN Batch 6/4700 loss 24.509945 loss_att 28.328732 loss_ctc 38.392380 loss_rnnt 21.895199 lr 0.00067582 rank 1
2022-12-03 23:18:34,702 DEBUG TRAIN Batch 6/4700 loss 15.070739 loss_att 19.591358 loss_ctc 29.830368 loss_rnnt 12.198664 lr 0.00067573 rank 3
2022-12-03 23:18:34,704 DEBUG TRAIN Batch 6/4700 loss 21.271765 loss_att 26.901688 loss_ctc 30.209160 loss_rnnt 18.954128 lr 0.00067547 rank 2
2022-12-03 23:18:34,707 DEBUG TRAIN Batch 6/4700 loss 18.488739 loss_att 29.509613 loss_ctc 33.075516 loss_rnnt 14.339661 lr 0.00067593 rank 7
2022-12-03 23:18:34,710 DEBUG TRAIN Batch 6/4700 loss 7.776979 loss_att 13.950384 loss_ctc 14.293510 loss_rnnt 5.673428 lr 0.00067613 rank 4
2022-12-03 23:19:46,181 DEBUG TRAIN Batch 6/4800 loss 14.496132 loss_att 20.688807 loss_ctc 28.921350 loss_rnnt 11.334234 lr 0.00067531 rank 7
2022-12-03 23:19:46,184 DEBUG TRAIN Batch 6/4800 loss 19.418938 loss_att 21.707081 loss_ctc 37.918472 loss_rnnt 16.494705 lr 0.00067541 rank 5
2022-12-03 23:19:46,184 DEBUG TRAIN Batch 6/4800 loss 20.913738 loss_att 24.251612 loss_ctc 37.662201 loss_rnnt 18.013035 lr 0.00067508 rank 0
2022-12-03 23:19:46,185 DEBUG TRAIN Batch 6/4800 loss 14.574606 loss_att 19.321552 loss_ctc 20.719090 loss_rnnt 12.805952 lr 0.00067511 rank 3
2022-12-03 23:19:46,185 DEBUG TRAIN Batch 6/4800 loss 23.230545 loss_att 29.648722 loss_ctc 37.642193 loss_rnnt 20.025356 lr 0.00067548 rank 6
2022-12-03 23:19:46,186 DEBUG TRAIN Batch 6/4800 loss 28.987944 loss_att 33.886734 loss_ctc 57.391705 loss_rnnt 24.221020 lr 0.00067521 rank 1
2022-12-03 23:19:46,190 DEBUG TRAIN Batch 6/4800 loss 8.303732 loss_att 12.004181 loss_ctc 14.689671 loss_rnnt 6.712183 lr 0.00067551 rank 4
2022-12-03 23:19:46,194 DEBUG TRAIN Batch 6/4800 loss 7.192552 loss_att 10.932127 loss_ctc 13.306993 loss_rnnt 5.629377 lr 0.00067486 rank 2
2022-12-03 23:20:57,397 DEBUG TRAIN Batch 6/4900 loss 14.042865 loss_att 16.659216 loss_ctc 21.221058 loss_rnnt 12.562503 lr 0.00067486 rank 6
2022-12-03 23:20:57,398 DEBUG TRAIN Batch 6/4900 loss 36.319778 loss_att 38.591877 loss_ctc 52.444084 loss_rnnt 33.715454 lr 0.00067459 rank 1
2022-12-03 23:20:57,398 DEBUG TRAIN Batch 6/4900 loss 19.778454 loss_att 26.953829 loss_ctc 35.004044 loss_rnnt 16.313301 lr 0.00067480 rank 5
2022-12-03 23:20:57,402 DEBUG TRAIN Batch 6/4900 loss 21.401794 loss_att 24.605652 loss_ctc 28.842018 loss_rnnt 19.768993 lr 0.00067447 rank 0
2022-12-03 23:20:57,402 DEBUG TRAIN Batch 6/4900 loss 16.878357 loss_att 23.915825 loss_ctc 26.329632 loss_rnnt 14.210693 lr 0.00067449 rank 3
2022-12-03 23:20:57,403 DEBUG TRAIN Batch 6/4900 loss 13.498714 loss_att 19.460217 loss_ctc 24.464478 loss_rnnt 10.844312 lr 0.00067470 rank 7
2022-12-03 23:20:57,406 DEBUG TRAIN Batch 6/4900 loss 23.663755 loss_att 25.687887 loss_ctc 35.443100 loss_rnnt 21.688351 lr 0.00067489 rank 4
2022-12-03 23:20:57,408 DEBUG TRAIN Batch 6/4900 loss 12.063499 loss_att 16.927746 loss_ctc 21.732784 loss_rnnt 9.801413 lr 0.00067424 rank 2
2022-12-03 23:22:11,816 DEBUG TRAIN Batch 6/5000 loss 21.787224 loss_att 27.980989 loss_ctc 36.031574 loss_rnnt 18.649223 lr 0.00067425 rank 6
2022-12-03 23:22:11,817 DEBUG TRAIN Batch 6/5000 loss 13.959778 loss_att 18.187134 loss_ctc 23.343723 loss_rnnt 11.863113 lr 0.00067386 rank 0
2022-12-03 23:22:11,817 DEBUG TRAIN Batch 6/5000 loss 15.230766 loss_att 21.603733 loss_ctc 25.477360 loss_rnnt 12.589961 lr 0.00067418 rank 5
2022-12-03 23:22:11,818 DEBUG TRAIN Batch 6/5000 loss 14.484788 loss_att 17.112698 loss_ctc 23.530357 loss_rnnt 12.753129 lr 0.00067363 rank 2
2022-12-03 23:22:11,819 DEBUG TRAIN Batch 6/5000 loss 12.554060 loss_att 17.615232 loss_ctc 22.905088 loss_rnnt 10.161689 lr 0.00067398 rank 1
2022-12-03 23:22:11,821 DEBUG TRAIN Batch 6/5000 loss 15.370593 loss_att 21.197025 loss_ctc 27.136353 loss_rnnt 12.636538 lr 0.00067388 rank 3
2022-12-03 23:22:11,822 DEBUG TRAIN Batch 6/5000 loss 9.486658 loss_att 13.074028 loss_ctc 13.827311 loss_rnnt 8.190431 lr 0.00067428 rank 4
2022-12-03 23:22:11,826 DEBUG TRAIN Batch 6/5000 loss 28.367853 loss_att 33.101509 loss_ctc 45.521080 loss_rnnt 25.134024 lr 0.00067408 rank 7
2022-12-03 23:23:23,686 DEBUG TRAIN Batch 6/5100 loss 12.223495 loss_att 12.480970 loss_ctc 17.089964 loss_rnnt 11.523136 lr 0.00067357 rank 5
2022-12-03 23:23:23,687 DEBUG TRAIN Batch 6/5100 loss 13.734770 loss_att 19.035873 loss_ctc 25.157291 loss_rnnt 11.151546 lr 0.00067364 rank 6
2022-12-03 23:23:23,688 DEBUG TRAIN Batch 6/5100 loss 15.064175 loss_att 14.318878 loss_ctc 19.048395 loss_rnnt 14.682004 lr 0.00067337 rank 1
2022-12-03 23:23:23,689 DEBUG TRAIN Batch 6/5100 loss 25.087734 loss_att 30.249365 loss_ctc 38.174240 loss_rnnt 22.310539 lr 0.00067302 rank 2
2022-12-03 23:23:23,691 DEBUG TRAIN Batch 6/5100 loss 5.353901 loss_att 10.065113 loss_ctc 10.947004 loss_rnnt 3.665912 lr 0.00067327 rank 3
2022-12-03 23:23:23,695 DEBUG TRAIN Batch 6/5100 loss 23.594313 loss_att 34.241982 loss_ctc 35.909336 loss_rnnt 19.822777 lr 0.00067367 rank 4
2022-12-03 23:23:23,699 DEBUG TRAIN Batch 6/5100 loss 12.506256 loss_att 13.141139 loss_ctc 17.475805 loss_rnnt 11.716674 lr 0.00067347 rank 7
2022-12-03 23:23:23,702 DEBUG TRAIN Batch 6/5100 loss 14.072433 loss_att 13.159389 loss_ctc 18.113909 loss_rnnt 13.716178 lr 0.00067325 rank 0
2022-12-03 23:24:35,028 DEBUG TRAIN Batch 6/5200 loss 15.066914 loss_att 21.122730 loss_ctc 26.592749 loss_rnnt 12.318973 lr 0.00067264 rank 0
2022-12-03 23:24:35,029 DEBUG TRAIN Batch 6/5200 loss 14.200680 loss_att 15.152790 loss_ctc 17.469217 loss_rnnt 13.574453 lr 0.00067241 rank 2
2022-12-03 23:24:35,030 DEBUG TRAIN Batch 6/5200 loss 21.478134 loss_att 23.200384 loss_ctc 34.655933 loss_rnnt 19.376644 lr 0.00067303 rank 6
2022-12-03 23:24:35,030 DEBUG TRAIN Batch 6/5200 loss 19.769531 loss_att 25.493561 loss_ctc 30.659872 loss_rnnt 17.172678 lr 0.00067296 rank 5
2022-12-03 23:24:35,030 DEBUG TRAIN Batch 6/5200 loss 15.281898 loss_att 16.016262 loss_ctc 21.813681 loss_rnnt 14.264122 lr 0.00067266 rank 3
2022-12-03 23:24:35,035 DEBUG TRAIN Batch 6/5200 loss 44.361061 loss_att 46.483963 loss_ctc 69.837051 loss_rnnt 40.539680 lr 0.00067276 rank 1
2022-12-03 23:24:35,038 DEBUG TRAIN Batch 6/5200 loss 13.153399 loss_att 14.293922 loss_ctc 19.853590 loss_rnnt 12.031936 lr 0.00067286 rank 7
2022-12-03 23:24:35,039 DEBUG TRAIN Batch 6/5200 loss 9.580177 loss_att 14.206385 loss_ctc 15.544040 loss_rnnt 7.859755 lr 0.00067306 rank 4
2022-12-03 23:25:48,019 DEBUG TRAIN Batch 6/5300 loss 20.973892 loss_att 29.592010 loss_ctc 31.592779 loss_rnnt 17.834415 lr 0.00067242 rank 6
2022-12-03 23:25:48,019 DEBUG TRAIN Batch 6/5300 loss 13.754757 loss_att 21.252281 loss_ctc 26.599991 loss_rnnt 10.542554 lr 0.00067235 rank 5
2022-12-03 23:25:48,022 DEBUG TRAIN Batch 6/5300 loss 11.731776 loss_att 18.489977 loss_ctc 23.859386 loss_rnnt 8.763122 lr 0.00067180 rank 2
2022-12-03 23:25:48,034 DEBUG TRAIN Batch 6/5300 loss 14.654351 loss_att 21.413391 loss_ctc 24.541311 loss_rnnt 11.984282 lr 0.00067205 rank 3
2022-12-03 23:25:48,035 DEBUG TRAIN Batch 6/5300 loss 16.500111 loss_att 18.877722 loss_ctc 24.275085 loss_rnnt 14.987926 lr 0.00067225 rank 7
2022-12-03 23:25:48,035 DEBUG TRAIN Batch 6/5300 loss 23.438541 loss_att 29.750610 loss_ctc 41.869331 loss_rnnt 19.718689 lr 0.00067203 rank 0
2022-12-03 23:25:48,036 DEBUG TRAIN Batch 6/5300 loss 37.882282 loss_att 36.639202 loss_ctc 55.498749 loss_rnnt 35.782036 lr 0.00067245 rank 4
2022-12-03 23:25:48,048 DEBUG TRAIN Batch 6/5300 loss 11.069332 loss_att 19.094559 loss_ctc 21.111494 loss_rnnt 8.125331 lr 0.00067215 rank 1
2022-12-03 23:27:00,878 DEBUG TRAIN Batch 6/5400 loss 15.438953 loss_att 16.494328 loss_ctc 23.655479 loss_rnnt 14.132340 lr 0.00067174 rank 5
2022-12-03 23:27:00,878 DEBUG TRAIN Batch 6/5400 loss 31.241680 loss_att 34.501324 loss_ctc 44.243145 loss_rnnt 28.856220 lr 0.00067120 rank 2
2022-12-03 23:27:00,880 DEBUG TRAIN Batch 6/5400 loss 10.140156 loss_att 15.821968 loss_ctc 20.068962 loss_rnnt 7.679953 lr 0.00067154 rank 1
2022-12-03 23:27:00,880 DEBUG TRAIN Batch 6/5400 loss 26.309101 loss_att 33.331875 loss_ctc 42.407845 loss_rnnt 22.758047 lr 0.00067165 rank 7
2022-12-03 23:27:00,884 DEBUG TRAIN Batch 6/5400 loss 15.134361 loss_att 22.681963 loss_ctc 32.127453 loss_rnnt 11.359095 lr 0.00067142 rank 0
2022-12-03 23:27:00,886 DEBUG TRAIN Batch 6/5400 loss 19.793926 loss_att 25.061775 loss_ctc 34.221062 loss_rnnt 16.816738 lr 0.00067184 rank 4
2022-12-03 23:27:00,904 DEBUG TRAIN Batch 6/5400 loss 16.254320 loss_att 19.393581 loss_ctc 29.930925 loss_rnnt 13.802919 lr 0.00067181 rank 6
2022-12-03 23:27:00,912 DEBUG TRAIN Batch 6/5400 loss 15.117607 loss_att 17.975327 loss_ctc 24.258650 loss_rnnt 13.327258 lr 0.00067145 rank 3
2022-12-03 23:28:12,328 DEBUG TRAIN Batch 6/5500 loss 24.210594 loss_att 27.234859 loss_ctc 36.243698 loss_rnnt 22.001328 lr 0.00067120 rank 6
2022-12-03 23:28:12,330 DEBUG TRAIN Batch 6/5500 loss 28.693369 loss_att 30.009514 loss_ctc 34.230625 loss_rnnt 27.691839 lr 0.00067082 rank 0
2022-12-03 23:28:12,333 DEBUG TRAIN Batch 6/5500 loss 19.468813 loss_att 24.718412 loss_ctc 30.176319 loss_rnnt 16.991226 lr 0.00067094 rank 1
2022-12-03 23:28:12,333 DEBUG TRAIN Batch 6/5500 loss 19.988367 loss_att 25.067692 loss_ctc 31.360201 loss_rnnt 17.456255 lr 0.00067104 rank 7
2022-12-03 23:28:12,335 DEBUG TRAIN Batch 6/5500 loss 34.075706 loss_att 37.137619 loss_ctc 50.654816 loss_rnnt 31.252777 lr 0.00067084 rank 3
2022-12-03 23:28:12,338 DEBUG TRAIN Batch 6/5500 loss 13.513665 loss_att 18.834883 loss_ctc 28.080225 loss_rnnt 10.507214 lr 0.00067123 rank 4
2022-12-03 23:28:12,362 DEBUG TRAIN Batch 6/5500 loss 14.906096 loss_att 22.074017 loss_ctc 28.065754 loss_rnnt 11.717889 lr 0.00067114 rank 5
2022-12-03 23:28:12,392 DEBUG TRAIN Batch 6/5500 loss 21.658442 loss_att 20.652489 loss_ctc 43.093983 loss_rnnt 19.001558 lr 0.00067059 rank 2
2022-12-03 23:29:23,649 DEBUG TRAIN Batch 6/5600 loss 14.067587 loss_att 19.517069 loss_ctc 25.411091 loss_rnnt 11.465223 lr 0.00067060 rank 6
2022-12-03 23:29:23,660 DEBUG TRAIN Batch 6/5600 loss 15.496258 loss_att 23.043365 loss_ctc 30.340111 loss_rnnt 12.007656 lr 0.00067063 rank 4
2022-12-03 23:29:23,664 DEBUG TRAIN Batch 6/5600 loss 13.985552 loss_att 17.417397 loss_ctc 28.872999 loss_rnnt 11.314189 lr 0.00067053 rank 5
2022-12-03 23:29:23,664 DEBUG TRAIN Batch 6/5600 loss 13.831897 loss_att 19.096382 loss_ctc 25.562424 loss_rnnt 11.214929 lr 0.00067024 rank 3
2022-12-03 23:29:23,665 DEBUG TRAIN Batch 6/5600 loss 25.228630 loss_att 30.484489 loss_ctc 41.344116 loss_rnnt 22.028725 lr 0.00067044 rank 7
2022-12-03 23:29:23,666 DEBUG TRAIN Batch 6/5600 loss 11.712485 loss_att 17.268175 loss_ctc 24.161892 loss_rnnt 8.941427 lr 0.00067021 rank 0
2022-12-03 23:29:23,666 DEBUG TRAIN Batch 6/5600 loss 19.449341 loss_att 21.046648 loss_ctc 24.680428 loss_rnnt 18.432402 lr 0.00067034 rank 1
2022-12-03 23:29:23,669 DEBUG TRAIN Batch 6/5600 loss 18.637581 loss_att 19.342968 loss_ctc 30.850576 loss_rnnt 16.868103 lr 0.00066999 rank 2
2022-12-03 23:30:37,793 DEBUG TRAIN Batch 6/5700 loss 22.252844 loss_att 22.966316 loss_ctc 35.505718 loss_rnnt 20.343100 lr 0.00067000 rank 6
2022-12-03 23:30:37,795 DEBUG TRAIN Batch 6/5700 loss 39.334633 loss_att 46.431934 loss_ctc 61.370762 loss_rnnt 34.977020 lr 0.00066964 rank 3
2022-12-03 23:30:37,800 DEBUG TRAIN Batch 6/5700 loss 22.634954 loss_att 25.368397 loss_ctc 34.530437 loss_rnnt 20.502203 lr 0.00066993 rank 5
2022-12-03 23:30:37,801 DEBUG TRAIN Batch 6/5700 loss 12.872311 loss_att 16.323563 loss_ctc 23.378561 loss_rnnt 10.781226 lr 0.00066961 rank 0
2022-12-03 23:30:37,806 DEBUG TRAIN Batch 6/5700 loss 12.575031 loss_att 15.314960 loss_ctc 23.395397 loss_rnnt 10.584331 lr 0.00066973 rank 1
2022-12-03 23:30:37,808 DEBUG TRAIN Batch 6/5700 loss 13.890240 loss_att 15.456778 loss_ctc 19.026974 loss_rnnt 12.892034 lr 0.00067003 rank 4
2022-12-03 23:30:37,808 DEBUG TRAIN Batch 6/5700 loss 16.269297 loss_att 25.030743 loss_ctc 28.572767 loss_rnnt 12.876543 lr 0.00066939 rank 2
2022-12-03 23:30:37,824 DEBUG TRAIN Batch 6/5700 loss 10.930703 loss_att 13.033911 loss_ctc 17.635851 loss_rnnt 9.616042 lr 0.00066984 rank 7
2022-12-03 23:31:49,982 DEBUG TRAIN Batch 6/5800 loss 18.778835 loss_att 27.998623 loss_ctc 29.677008 loss_rnnt 15.481788 lr 0.00066901 rank 0
2022-12-03 23:31:50,002 DEBUG TRAIN Batch 6/5800 loss 14.476070 loss_att 20.679150 loss_ctc 24.897289 loss_rnnt 11.845959 lr 0.00066940 rank 6
2022-12-03 23:31:50,004 DEBUG TRAIN Batch 6/5800 loss 14.170253 loss_att 15.994248 loss_ctc 21.026964 loss_rnnt 12.891225 lr 0.00066904 rank 3
2022-12-03 23:31:50,005 DEBUG TRAIN Batch 6/5800 loss 63.530407 loss_att 69.145508 loss_ctc 92.439537 loss_rnnt 58.552837 lr 0.00066913 rank 1
2022-12-03 23:31:50,007 DEBUG TRAIN Batch 6/5800 loss 23.266785 loss_att 31.799770 loss_ctc 42.693932 loss_rnnt 18.969900 lr 0.00066924 rank 7
2022-12-03 23:31:50,008 DEBUG TRAIN Batch 6/5800 loss 15.046789 loss_att 21.077311 loss_ctc 33.715515 loss_rnnt 11.351522 lr 0.00066943 rank 4
2022-12-03 23:31:50,009 DEBUG TRAIN Batch 6/5800 loss 13.434374 loss_att 16.705585 loss_ctc 26.265503 loss_rnnt 11.069313 lr 0.00066879 rank 2
2022-12-03 23:31:50,048 DEBUG TRAIN Batch 6/5800 loss 9.357091 loss_att 12.740088 loss_ctc 16.127693 loss_rnnt 7.777744 lr 0.00066933 rank 5
2022-12-03 23:33:01,648 DEBUG TRAIN Batch 6/5900 loss 26.358789 loss_att 36.254974 loss_ctc 44.723076 loss_rnnt 21.930983 lr 0.00066880 rank 6
2022-12-03 23:33:01,651 DEBUG TRAIN Batch 6/5900 loss 18.895895 loss_att 25.736046 loss_ctc 39.084698 loss_rnnt 14.836024 lr 0.00066873 rank 5
2022-12-03 23:33:01,652 DEBUG TRAIN Batch 6/5900 loss 16.823788 loss_att 18.905745 loss_ctc 31.863043 loss_rnnt 14.402163 lr 0.00066842 rank 0
2022-12-03 23:33:01,655 DEBUG TRAIN Batch 6/5900 loss 26.326412 loss_att 29.911282 loss_ctc 34.615582 loss_rnnt 24.504217 lr 0.00066854 rank 1
2022-12-03 23:33:01,654 DEBUG TRAIN Batch 6/5900 loss 24.743900 loss_att 30.421186 loss_ctc 43.352184 loss_rnnt 21.127340 lr 0.00066864 rank 7
2022-12-03 23:33:01,658 DEBUG TRAIN Batch 6/5900 loss 28.059557 loss_att 32.449177 loss_ctc 51.195648 loss_rnnt 24.096823 lr 0.00066844 rank 3
2022-12-03 23:33:01,659 DEBUG TRAIN Batch 6/5900 loss 12.473563 loss_att 19.104889 loss_ctc 35.686852 loss_rnnt 8.052193 lr 0.00066883 rank 4
2022-12-03 23:33:01,660 DEBUG TRAIN Batch 6/5900 loss 10.173503 loss_att 15.586973 loss_ctc 21.796362 loss_rnnt 7.541095 lr 0.00066819 rank 2
2022-12-03 23:34:14,987 DEBUG TRAIN Batch 6/6000 loss 17.267591 loss_att 20.911163 loss_ctc 31.307556 loss_rnnt 14.666883 lr 0.00066820 rank 6
2022-12-03 23:34:14,994 DEBUG TRAIN Batch 6/6000 loss 16.120556 loss_att 19.730089 loss_ctc 28.527435 loss_rnnt 13.744400 lr 0.00066794 rank 1
2022-12-03 23:34:14,997 DEBUG TRAIN Batch 6/6000 loss 25.987480 loss_att 28.086853 loss_ctc 40.717178 loss_rnnt 23.603645 lr 0.00066823 rank 4
2022-12-03 23:34:15,001 DEBUG TRAIN Batch 6/6000 loss 33.305370 loss_att 32.782104 loss_ctc 45.233292 loss_rnnt 31.819637 lr 0.00066814 rank 5
2022-12-03 23:34:15,003 DEBUG TRAIN Batch 6/6000 loss 9.008149 loss_att 14.973321 loss_ctc 15.827538 loss_rnnt 6.905864 lr 0.00066760 rank 2
2022-12-03 23:34:15,007 DEBUG TRAIN Batch 6/6000 loss 18.324467 loss_att 20.332027 loss_ctc 30.062609 loss_rnnt 16.357868 lr 0.00066804 rank 7
2022-12-03 23:34:15,008 DEBUG TRAIN Batch 6/6000 loss 10.377850 loss_att 16.010296 loss_ctc 22.379189 loss_rnnt 7.651182 lr 0.00066782 rank 0
2022-12-03 23:34:15,011 DEBUG TRAIN Batch 6/6000 loss 11.300946 loss_att 16.284752 loss_ctc 25.113842 loss_rnnt 8.462466 lr 0.00066784 rank 3
2022-12-03 23:35:27,803 DEBUG TRAIN Batch 6/6100 loss 29.814152 loss_att 31.955420 loss_ctc 45.460129 loss_rnnt 27.299767 lr 0.00066760 rank 6
2022-12-03 23:35:27,804 DEBUG TRAIN Batch 6/6100 loss 21.187832 loss_att 28.403084 loss_ctc 38.515110 loss_rnnt 17.434475 lr 0.00066725 rank 3
2022-12-03 23:35:27,809 DEBUG TRAIN Batch 6/6100 loss 27.856424 loss_att 34.000946 loss_ctc 46.781013 loss_rnnt 24.104244 lr 0.00066754 rank 5
2022-12-03 23:35:27,809 DEBUG TRAIN Batch 6/6100 loss 46.929810 loss_att 41.484501 loss_ctc 59.256500 loss_rnnt 46.375309 lr 0.00066744 rank 7
2022-12-03 23:35:27,810 DEBUG TRAIN Batch 6/6100 loss 14.513676 loss_att 19.590765 loss_ctc 26.958454 loss_rnnt 11.838954 lr 0.00066700 rank 2
2022-12-03 23:35:27,812 DEBUG TRAIN Batch 6/6100 loss 13.137277 loss_att 20.024712 loss_ctc 26.370663 loss_rnnt 9.995338 lr 0.00066722 rank 0
2022-12-03 23:35:27,815 DEBUG TRAIN Batch 6/6100 loss 24.849676 loss_att 32.772381 loss_ctc 39.347404 loss_rnnt 21.332106 lr 0.00066734 rank 1
2022-12-03 23:35:27,816 DEBUG TRAIN Batch 6/6100 loss 26.197134 loss_att 31.707853 loss_ctc 43.229218 loss_rnnt 22.824047 lr 0.00066763 rank 4
2022-12-03 23:36:39,415 DEBUG TRAIN Batch 6/6200 loss 32.222507 loss_att 36.411655 loss_ctc 49.157341 loss_rnnt 29.126696 lr 0.00066701 rank 6
2022-12-03 23:36:39,416 DEBUG TRAIN Batch 6/6200 loss 5.653986 loss_att 10.222714 loss_ctc 11.025476 loss_rnnt 4.024041 lr 0.00066675 rank 1
2022-12-03 23:36:39,418 DEBUG TRAIN Batch 6/6200 loss 20.732027 loss_att 25.494209 loss_ctc 36.612003 loss_rnnt 17.662262 lr 0.00066641 rank 2
2022-12-03 23:36:39,419 DEBUG TRAIN Batch 6/6200 loss 21.685726 loss_att 26.566715 loss_ctc 31.434870 loss_rnnt 19.409641 lr 0.00066665 rank 3
2022-12-03 23:36:39,420 DEBUG TRAIN Batch 6/6200 loss 22.292458 loss_att 25.547640 loss_ctc 39.071156 loss_rnnt 19.404261 lr 0.00066663 rank 0
2022-12-03 23:36:39,427 DEBUG TRAIN Batch 6/6200 loss 21.035769 loss_att 26.663555 loss_ctc 33.141548 loss_rnnt 18.296108 lr 0.00066704 rank 4
2022-12-03 23:36:39,445 DEBUG TRAIN Batch 6/6200 loss 18.010427 loss_att 22.303877 loss_ctc 32.650803 loss_rnnt 15.199686 lr 0.00066685 rank 7
2022-12-03 23:36:39,459 DEBUG TRAIN Batch 6/6200 loss 14.203229 loss_att 20.038254 loss_ctc 24.275238 loss_rnnt 11.693290 lr 0.00066695 rank 5
2022-12-03 23:37:51,091 DEBUG TRAIN Batch 6/6300 loss 11.944685 loss_att 14.768664 loss_ctc 16.102160 loss_rnnt 10.825560 lr 0.00066604 rank 0
2022-12-03 23:37:51,093 DEBUG TRAIN Batch 6/6300 loss 17.238716 loss_att 20.106619 loss_ctc 27.916737 loss_rnnt 15.241401 lr 0.00066642 rank 6
2022-12-03 23:37:51,094 DEBUG TRAIN Batch 6/6300 loss 22.644648 loss_att 24.737812 loss_ctc 38.718994 loss_rnnt 20.082769 lr 0.00066606 rank 3
2022-12-03 23:37:51,096 DEBUG TRAIN Batch 6/6300 loss 21.923262 loss_att 27.943130 loss_ctc 43.452797 loss_rnnt 17.848684 lr 0.00066616 rank 1
2022-12-03 23:37:51,098 DEBUG TRAIN Batch 6/6300 loss 15.678983 loss_att 17.210590 loss_ctc 23.915255 loss_rnnt 14.274491 lr 0.00066626 rank 7
2022-12-03 23:37:51,100 DEBUG TRAIN Batch 6/6300 loss 12.559561 loss_att 16.962902 loss_ctc 19.675726 loss_rnnt 10.730071 lr 0.00066635 rank 5
2022-12-03 23:37:51,100 DEBUG TRAIN Batch 6/6300 loss 19.852055 loss_att 23.733219 loss_ctc 31.518177 loss_rnnt 17.520340 lr 0.00066645 rank 4
2022-12-03 23:37:51,103 DEBUG TRAIN Batch 6/6300 loss 9.418095 loss_att 10.051768 loss_ctc 16.026651 loss_rnnt 8.410219 lr 0.00066582 rank 2
2022-12-03 23:39:05,556 DEBUG TRAIN Batch 6/6400 loss 21.514219 loss_att 22.464825 loss_ctc 30.248894 loss_rnnt 20.159475 lr 0.00066545 rank 0
2022-12-03 23:39:05,556 DEBUG TRAIN Batch 6/6400 loss 6.832774 loss_att 12.871693 loss_ctc 16.416824 loss_rnnt 4.347116 lr 0.00066576 rank 5
2022-12-03 23:39:05,558 DEBUG TRAIN Batch 6/6400 loss 17.611509 loss_att 17.666571 loss_ctc 22.595503 loss_rnnt 16.935965 lr 0.00066583 rank 6
2022-12-03 23:39:05,561 DEBUG TRAIN Batch 6/6400 loss 15.556386 loss_att 19.034180 loss_ctc 21.597967 loss_rnnt 14.055283 lr 0.00066547 rank 3
2022-12-03 23:39:05,563 DEBUG TRAIN Batch 6/6400 loss 10.255787 loss_att 11.153539 loss_ctc 13.289825 loss_rnnt 9.671699 lr 0.00066567 rank 7
2022-12-03 23:39:05,588 DEBUG TRAIN Batch 6/6400 loss 13.756087 loss_att 16.219524 loss_ctc 23.087103 loss_rnnt 12.019264 lr 0.00066523 rank 2
2022-12-03 23:39:05,595 DEBUG TRAIN Batch 6/6400 loss 21.996984 loss_att 25.820543 loss_ctc 41.212421 loss_rnnt 18.670214 lr 0.00066586 rank 4
2022-12-03 23:39:05,607 DEBUG TRAIN Batch 6/6400 loss 11.115602 loss_att 10.925987 loss_ctc 15.172987 loss_rnnt 10.612541 lr 0.00066557 rank 1
2022-12-03 23:40:17,965 DEBUG TRAIN Batch 6/6500 loss 22.408237 loss_att 26.746296 loss_ctc 31.876434 loss_rnnt 20.278200 lr 0.00066517 rank 5
2022-12-03 23:40:17,966 DEBUG TRAIN Batch 6/6500 loss 13.768688 loss_att 18.790478 loss_ctc 27.401917 loss_rnnt 10.946567 lr 0.00066524 rank 6
2022-12-03 23:40:17,967 DEBUG TRAIN Batch 6/6500 loss 13.799226 loss_att 14.479534 loss_ctc 18.837868 loss_rnnt 12.991344 lr 0.00066464 rank 2
2022-12-03 23:40:17,972 DEBUG TRAIN Batch 6/6500 loss 13.204486 loss_att 17.745522 loss_ctc 18.407063 loss_rnnt 11.602603 lr 0.00066498 rank 1
2022-12-03 23:40:17,973 DEBUG TRAIN Batch 6/6500 loss 26.383301 loss_att 33.926804 loss_ctc 49.072506 loss_rnnt 21.849373 lr 0.00066508 rank 7
2022-12-03 23:40:17,974 DEBUG TRAIN Batch 6/6500 loss 14.862845 loss_att 20.666241 loss_ctc 28.757557 loss_rnnt 11.849539 lr 0.00066527 rank 4
2022-12-03 23:40:17,985 DEBUG TRAIN Batch 6/6500 loss 18.161325 loss_att 25.812834 loss_ctc 37.379967 loss_rnnt 14.068538 lr 0.00066486 rank 0
2022-12-03 23:40:17,994 DEBUG TRAIN Batch 6/6500 loss 24.634012 loss_att 34.011650 loss_ctc 46.304138 loss_rnnt 19.869133 lr 0.00066488 rank 3
2022-12-03 23:41:30,933 DEBUG TRAIN Batch 6/6600 loss 21.774818 loss_att 26.260410 loss_ctc 31.825775 loss_rnnt 19.537571 lr 0.00066458 rank 5
2022-12-03 23:41:30,934 DEBUG TRAIN Batch 6/6600 loss 12.270602 loss_att 17.461044 loss_ctc 18.451824 loss_rnnt 10.408351 lr 0.00066439 rank 1
2022-12-03 23:41:30,938 DEBUG TRAIN Batch 6/6600 loss 8.886191 loss_att 16.179287 loss_ctc 19.832575 loss_rnnt 5.968055 lr 0.00066427 rank 0
2022-12-03 23:41:30,939 DEBUG TRAIN Batch 6/6600 loss 17.509012 loss_att 23.389343 loss_ctc 25.826607 loss_rnnt 15.223932 lr 0.00066430 rank 3
2022-12-03 23:41:30,940 DEBUG TRAIN Batch 6/6600 loss 12.675040 loss_att 17.072189 loss_ctc 20.289669 loss_rnnt 10.780327 lr 0.00066406 rank 2
2022-12-03 23:41:30,941 DEBUG TRAIN Batch 6/6600 loss 10.352515 loss_att 14.682738 loss_ctc 26.333250 loss_rnnt 7.355707 lr 0.00066465 rank 6
2022-12-03 23:41:30,944 DEBUG TRAIN Batch 6/6600 loss 16.987795 loss_att 21.331751 loss_ctc 25.621534 loss_rnnt 14.967837 lr 0.00066468 rank 4
2022-12-03 23:41:30,989 DEBUG TRAIN Batch 6/6600 loss 19.630566 loss_att 25.630257 loss_ctc 32.078270 loss_rnnt 16.770935 lr 0.00066449 rank 7
2022-12-03 23:42:43,807 DEBUG TRAIN Batch 6/6700 loss 22.367844 loss_att 27.049583 loss_ctc 36.673378 loss_rnnt 19.524090 lr 0.00066406 rank 6
2022-12-03 23:42:43,810 DEBUG TRAIN Batch 6/6700 loss 14.222445 loss_att 20.057955 loss_ctc 24.704870 loss_rnnt 11.657685 lr 0.00066390 rank 7
2022-12-03 23:42:43,811 DEBUG TRAIN Batch 6/6700 loss 16.529951 loss_att 18.950781 loss_ctc 25.843750 loss_rnnt 14.803944 lr 0.00066371 rank 3
2022-12-03 23:42:43,811 DEBUG TRAIN Batch 6/6700 loss 10.437160 loss_att 15.551121 loss_ctc 19.615707 loss_rnnt 8.190561 lr 0.00066369 rank 0
2022-12-03 23:42:43,812 DEBUG TRAIN Batch 6/6700 loss 26.198988 loss_att 32.475594 loss_ctc 47.916153 loss_rnnt 22.048042 lr 0.00066347 rank 2
2022-12-03 23:42:43,813 DEBUG TRAIN Batch 6/6700 loss 11.621202 loss_att 14.509192 loss_ctc 15.370528 loss_rnnt 10.543694 lr 0.00066400 rank 5
2022-12-03 23:42:43,837 DEBUG TRAIN Batch 6/6700 loss 16.020716 loss_att 15.979454 loss_ctc 25.450897 loss_rnnt 14.771610 lr 0.00066381 rank 1
2022-12-03 23:42:43,837 DEBUG TRAIN Batch 6/6700 loss 21.718437 loss_att 27.138525 loss_ctc 33.826572 loss_rnnt 19.019999 lr 0.00066409 rank 4
2022-12-03 23:43:57,334 DEBUG TRAIN Batch 6/6800 loss 12.105772 loss_att 14.857290 loss_ctc 18.796879 loss_rnnt 10.663321 lr 0.00066348 rank 6
2022-12-03 23:43:57,354 DEBUG TRAIN Batch 6/6800 loss 11.272917 loss_att 15.685362 loss_ctc 17.225971 loss_rnnt 9.596687 lr 0.00066310 rank 0
2022-12-03 23:43:57,356 DEBUG TRAIN Batch 6/6800 loss 21.583651 loss_att 21.923967 loss_ctc 28.236820 loss_rnnt 20.628498 lr 0.00066322 rank 1
2022-12-03 23:43:57,357 DEBUG TRAIN Batch 6/6800 loss 22.598103 loss_att 24.413958 loss_ctc 38.015617 loss_rnnt 20.179262 lr 0.00066313 rank 3
2022-12-03 23:43:57,359 DEBUG TRAIN Batch 6/6800 loss 16.627262 loss_att 23.149254 loss_ctc 30.145214 loss_rnnt 13.520471 lr 0.00066341 rank 5
2022-12-03 23:43:57,361 DEBUG TRAIN Batch 6/6800 loss 17.033918 loss_att 22.696798 loss_ctc 31.132425 loss_rnnt 14.021540 lr 0.00066351 rank 4
2022-12-03 23:43:57,362 DEBUG TRAIN Batch 6/6800 loss 20.073990 loss_att 20.218479 loss_ctc 27.427383 loss_rnnt 19.064638 lr 0.00066332 rank 7
2022-12-03 23:43:57,364 DEBUG TRAIN Batch 6/6800 loss 22.176968 loss_att 23.203426 loss_ctc 34.260925 loss_rnnt 20.360481 lr 0.00066289 rank 2
2022-12-03 23:45:09,410 DEBUG TRAIN Batch 6/6900 loss 26.230011 loss_att 31.009712 loss_ctc 39.549900 loss_rnnt 23.498085 lr 0.00066289 rank 6
2022-12-03 23:45:09,415 DEBUG TRAIN Batch 6/6900 loss 34.701904 loss_att 40.264496 loss_ctc 47.987877 loss_rnnt 31.817921 lr 0.00066283 rank 5
2022-12-03 23:45:09,415 DEBUG TRAIN Batch 6/6900 loss 23.489273 loss_att 26.056206 loss_ctc 44.579239 loss_rnnt 20.163891 lr 0.00066264 rank 1
2022-12-03 23:45:09,418 DEBUG TRAIN Batch 6/6900 loss 15.762954 loss_att 22.812012 loss_ctc 26.373579 loss_rnnt 12.938393 lr 0.00066255 rank 3
2022-12-03 23:45:09,419 DEBUG TRAIN Batch 6/6900 loss 11.921805 loss_att 12.931825 loss_ctc 18.761469 loss_rnnt 10.807846 lr 0.00066231 rank 2
2022-12-03 23:45:09,420 DEBUG TRAIN Batch 6/6900 loss 17.683380 loss_att 19.332924 loss_ctc 27.267479 loss_rnnt 16.075592 lr 0.00066252 rank 0
2022-12-03 23:45:09,420 DEBUG TRAIN Batch 6/6900 loss 30.272217 loss_att 31.921612 loss_ctc 43.505020 loss_rnnt 28.177963 lr 0.00066274 rank 7
2022-12-03 23:45:09,421 DEBUG TRAIN Batch 6/6900 loss 19.335833 loss_att 23.980701 loss_ctc 33.178204 loss_rnnt 16.561209 lr 0.00066292 rank 4
2022-12-03 23:46:21,783 DEBUG TRAIN Batch 6/7000 loss 10.394530 loss_att 13.215988 loss_ctc 15.683551 loss_rnnt 9.125037 lr 0.00066173 rank 2
2022-12-03 23:46:21,783 DEBUG TRAIN Batch 6/7000 loss 23.046993 loss_att 25.386889 loss_ctc 31.214762 loss_rnnt 21.489981 lr 0.00066196 rank 3
2022-12-03 23:46:21,788 DEBUG TRAIN Batch 6/7000 loss 17.990953 loss_att 19.756878 loss_ctc 27.902029 loss_rnnt 16.316292 lr 0.00066194 rank 0
2022-12-03 23:46:21,788 DEBUG TRAIN Batch 6/7000 loss 9.364694 loss_att 11.945385 loss_ctc 13.981661 loss_rnnt 8.232960 lr 0.00066231 rank 6
2022-12-03 23:46:21,790 DEBUG TRAIN Batch 6/7000 loss 12.600548 loss_att 13.418486 loss_ctc 18.709618 loss_rnnt 11.622417 lr 0.00066225 rank 5
2022-12-03 23:46:21,800 DEBUG TRAIN Batch 6/7000 loss 9.487441 loss_att 11.870216 loss_ctc 15.663475 loss_rnnt 8.187415 lr 0.00066216 rank 7
2022-12-03 23:46:21,808 DEBUG TRAIN Batch 6/7000 loss 12.462187 loss_att 14.536764 loss_ctc 20.437092 loss_rnnt 10.983950 lr 0.00066206 rank 1
2022-12-03 23:46:21,823 DEBUG TRAIN Batch 6/7000 loss 12.302010 loss_att 20.875374 loss_ctc 20.210228 loss_rnnt 9.532907 lr 0.00066234 rank 4
2022-12-03 23:47:36,375 DEBUG TRAIN Batch 6/7100 loss 21.452911 loss_att 22.448357 loss_ctc 39.138458 loss_rnnt 18.895748 lr 0.00066148 rank 1
2022-12-03 23:47:36,380 DEBUG TRAIN Batch 6/7100 loss 30.367079 loss_att 42.354542 loss_ctc 53.257317 loss_rnnt 24.917555 lr 0.00066158 rank 7
2022-12-03 23:47:36,386 DEBUG TRAIN Batch 6/7100 loss 8.262892 loss_att 7.884687 loss_ctc 10.759741 loss_rnnt 8.005619 lr 0.00066138 rank 3
2022-12-03 23:47:36,394 DEBUG TRAIN Batch 6/7100 loss 11.492146 loss_att 14.495364 loss_ctc 16.617290 loss_rnnt 10.208149 lr 0.00066115 rank 2
2022-12-03 23:47:36,395 DEBUG TRAIN Batch 6/7100 loss 22.969673 loss_att 28.884651 loss_ctc 43.133862 loss_rnnt 19.098116 lr 0.00066167 rank 5
2022-12-03 23:47:36,399 DEBUG TRAIN Batch 6/7100 loss 25.404110 loss_att 29.488216 loss_ctc 46.233101 loss_rnnt 21.810089 lr 0.00066173 rank 6
2022-12-03 23:47:36,411 DEBUG TRAIN Batch 6/7100 loss 8.915725 loss_att 13.394181 loss_ctc 18.132904 loss_rnnt 6.791076 lr 0.00066136 rank 0
2022-12-03 23:47:36,440 DEBUG TRAIN Batch 6/7100 loss 13.640168 loss_att 18.258356 loss_ctc 26.949123 loss_rnnt 10.942003 lr 0.00066176 rank 4
2022-12-03 23:48:48,596 DEBUG TRAIN Batch 6/7200 loss 12.470089 loss_att 18.118919 loss_ctc 19.353456 loss_rnnt 10.422541 lr 0.00066057 rank 2
2022-12-03 23:48:48,606 DEBUG TRAIN Batch 6/7200 loss 9.485075 loss_att 13.303357 loss_ctc 15.994478 loss_rnnt 7.853498 lr 0.00066081 rank 3
2022-12-03 23:48:48,609 DEBUG TRAIN Batch 6/7200 loss 32.910301 loss_att 38.040615 loss_ctc 48.026306 loss_rnnt 29.868773 lr 0.00066118 rank 4
2022-12-03 23:48:48,610 DEBUG TRAIN Batch 6/7200 loss 17.212059 loss_att 24.148232 loss_ctc 36.160110 loss_rnnt 13.298419 lr 0.00066109 rank 5
2022-12-03 23:48:48,612 DEBUG TRAIN Batch 6/7200 loss 16.297066 loss_att 18.938663 loss_ctc 28.688568 loss_rnnt 14.116546 lr 0.00066078 rank 0
2022-12-03 23:48:48,612 DEBUG TRAIN Batch 6/7200 loss 13.046297 loss_att 17.605324 loss_ctc 23.107342 loss_rnnt 10.793020 lr 0.00066115 rank 6
2022-12-03 23:48:48,613 DEBUG TRAIN Batch 6/7200 loss 17.200945 loss_att 19.173349 loss_ctc 25.766602 loss_rnnt 15.664375 lr 0.00066100 rank 7
2022-12-03 23:48:48,614 DEBUG TRAIN Batch 6/7200 loss 8.259121 loss_att 9.817474 loss_ctc 15.088997 loss_rnnt 7.036800 lr 0.00066090 rank 1
2022-12-03 23:49:59,777 DEBUG TRAIN Batch 6/7300 loss 18.638678 loss_att 22.127247 loss_ctc 25.858410 loss_rnnt 16.978333 lr 0.00066058 rank 6
2022-12-03 23:49:59,778 DEBUG TRAIN Batch 6/7300 loss 10.368010 loss_att 14.120785 loss_ctc 24.179462 loss_rnnt 7.775926 lr 0.00066021 rank 0
2022-12-03 23:49:59,779 DEBUG TRAIN Batch 6/7300 loss 22.860157 loss_att 28.469860 loss_ctc 36.334473 loss_rnnt 19.941641 lr 0.00066042 rank 7
2022-12-03 23:49:59,778 DEBUG TRAIN Batch 6/7300 loss 19.029692 loss_att 24.167400 loss_ctc 27.821106 loss_rnnt 16.829960 lr 0.00066023 rank 3
2022-12-03 23:49:59,781 DEBUG TRAIN Batch 6/7300 loss 19.164248 loss_att 22.107323 loss_ctc 32.215862 loss_rnnt 16.835417 lr 0.00065999 rank 2
2022-12-03 23:49:59,781 DEBUG TRAIN Batch 6/7300 loss 8.891162 loss_att 12.077568 loss_ctc 17.082731 loss_rnnt 7.161672 lr 0.00066032 rank 1
2022-12-03 23:49:59,784 DEBUG TRAIN Batch 6/7300 loss 9.883124 loss_att 13.118317 loss_ctc 17.025846 loss_rnnt 8.283723 lr 0.00066051 rank 5
2022-12-03 23:49:59,788 DEBUG TRAIN Batch 6/7300 loss 17.917019 loss_att 24.251369 loss_ctc 25.564613 loss_rnnt 15.630470 lr 0.00066061 rank 4
2022-12-03 23:51:11,700 DEBUG TRAIN Batch 6/7400 loss 32.352772 loss_att 34.723541 loss_ctc 56.242901 loss_rnnt 28.693268 lr 0.00065966 rank 3
2022-12-03 23:51:11,708 DEBUG TRAIN Batch 6/7400 loss 19.208332 loss_att 24.372765 loss_ctc 22.213375 loss_rnnt 17.774773 lr 0.00066000 rank 6
2022-12-03 23:51:11,710 DEBUG TRAIN Batch 6/7400 loss 21.624428 loss_att 22.620884 loss_ctc 29.901413 loss_rnnt 20.321537 lr 0.00065963 rank 0
2022-12-03 23:51:11,712 DEBUG TRAIN Batch 6/7400 loss 18.876556 loss_att 21.082705 loss_ctc 26.064308 loss_rnnt 17.476959 lr 0.00065985 rank 7
2022-12-03 23:51:11,712 DEBUG TRAIN Batch 6/7400 loss 24.431084 loss_att 28.481529 loss_ctc 41.029007 loss_rnnt 21.407936 lr 0.00065975 rank 1
2022-12-03 23:51:11,716 DEBUG TRAIN Batch 6/7400 loss 14.161293 loss_att 17.473440 loss_ctc 20.642357 loss_rnnt 12.634722 lr 0.00065994 rank 5
2022-12-03 23:51:11,729 DEBUG TRAIN Batch 6/7400 loss 13.291366 loss_att 16.655922 loss_ctc 20.241405 loss_rnnt 11.691782 lr 0.00065942 rank 2
2022-12-03 23:51:11,746 DEBUG TRAIN Batch 6/7400 loss 21.300636 loss_att 23.611731 loss_ctc 38.712685 loss_rnnt 18.516809 lr 0.00066003 rank 4
2022-12-03 23:52:25,187 DEBUG TRAIN Batch 6/7500 loss 12.877750 loss_att 15.330305 loss_ctc 19.935118 loss_rnnt 11.446258 lr 0.00065885 rank 2
2022-12-03 23:52:25,190 DEBUG TRAIN Batch 6/7500 loss 23.623812 loss_att 27.038582 loss_ctc 36.950989 loss_rnnt 21.163898 lr 0.00065906 rank 0
2022-12-03 23:52:25,192 DEBUG TRAIN Batch 6/7500 loss 25.616610 loss_att 25.649069 loss_ctc 40.759686 loss_rnnt 23.591038 lr 0.00065908 rank 3
2022-12-03 23:52:25,193 DEBUG TRAIN Batch 6/7500 loss 23.368803 loss_att 28.301083 loss_ctc 39.997803 loss_rnnt 20.165146 lr 0.00065917 rank 1
2022-12-03 23:52:25,194 DEBUG TRAIN Batch 6/7500 loss 14.844416 loss_att 20.660383 loss_ctc 25.872501 loss_rnnt 12.210810 lr 0.00065943 rank 6
2022-12-03 23:52:25,196 DEBUG TRAIN Batch 6/7500 loss 26.546759 loss_att 29.456758 loss_ctc 39.696510 loss_rnnt 24.211458 lr 0.00065936 rank 5
2022-12-03 23:52:25,199 DEBUG TRAIN Batch 6/7500 loss 18.194754 loss_att 22.503284 loss_ctc 31.073854 loss_rnnt 15.615835 lr 0.00065946 rank 4
2022-12-03 23:52:25,250 DEBUG TRAIN Batch 6/7500 loss 24.854671 loss_att 28.315994 loss_ctc 35.266617 loss_rnnt 22.774149 lr 0.00065927 rank 7
2022-12-03 23:53:37,318 DEBUG TRAIN Batch 6/7600 loss 10.001431 loss_att 12.721096 loss_ctc 19.471146 loss_rnnt 8.194869 lr 0.00065870 rank 7
2022-12-03 23:53:37,320 DEBUG TRAIN Batch 6/7600 loss 19.326941 loss_att 22.109783 loss_ctc 29.365143 loss_rnnt 17.431946 lr 0.00065851 rank 3
2022-12-03 23:53:37,322 DEBUG TRAIN Batch 6/7600 loss 13.909366 loss_att 15.760256 loss_ctc 22.673841 loss_rnnt 12.370590 lr 0.00065885 rank 6
2022-12-03 23:53:37,324 DEBUG TRAIN Batch 6/7600 loss 9.951894 loss_att 12.790897 loss_ctc 16.430702 loss_rnnt 8.520252 lr 0.00065860 rank 1
2022-12-03 23:53:37,325 DEBUG TRAIN Batch 6/7600 loss 16.470493 loss_att 24.730061 loss_ctc 24.041058 loss_rnnt 13.809172 lr 0.00065828 rank 2
2022-12-03 23:53:37,326 DEBUG TRAIN Batch 6/7600 loss 12.148304 loss_att 15.819900 loss_ctc 22.264563 loss_rnnt 10.065150 lr 0.00065849 rank 0
2022-12-03 23:53:37,326 DEBUG TRAIN Batch 6/7600 loss 26.891613 loss_att 26.366901 loss_ctc 35.017593 loss_rnnt 25.913092 lr 0.00065888 rank 4
2022-12-03 23:53:37,326 DEBUG TRAIN Batch 6/7600 loss 9.377449 loss_att 11.788038 loss_ctc 18.781584 loss_rnnt 7.641446 lr 0.00065879 rank 5
2022-12-03 23:54:48,895 DEBUG TRAIN Batch 6/7700 loss 13.004692 loss_att 17.848261 loss_ctc 22.366133 loss_rnnt 10.787786 lr 0.00065822 rank 5
2022-12-03 23:54:48,896 DEBUG TRAIN Batch 6/7700 loss 31.651878 loss_att 39.432186 loss_ctc 53.729057 loss_rnnt 27.152191 lr 0.00065803 rank 1
2022-12-03 23:54:48,897 DEBUG TRAIN Batch 6/7700 loss 22.253483 loss_att 27.544703 loss_ctc 36.331581 loss_rnnt 19.318159 lr 0.00065813 rank 7
2022-12-03 23:54:48,899 DEBUG TRAIN Batch 6/7700 loss 11.551346 loss_att 16.573851 loss_ctc 21.038336 loss_rnnt 9.281913 lr 0.00065828 rank 6
2022-12-03 23:54:48,899 DEBUG TRAIN Batch 6/7700 loss 32.714516 loss_att 37.410519 loss_ctc 49.252541 loss_rnnt 29.570242 lr 0.00065792 rank 0
2022-12-03 23:54:48,906 DEBUG TRAIN Batch 6/7700 loss 26.042099 loss_att 31.211058 loss_ctc 47.689693 loss_rnnt 22.121960 lr 0.00065831 rank 4
2022-12-03 23:54:48,920 DEBUG TRAIN Batch 6/7700 loss 9.186952 loss_att 9.957561 loss_ctc 13.610084 loss_rnnt 8.443079 lr 0.00065794 rank 3
2022-12-03 23:54:48,920 DEBUG TRAIN Batch 6/7700 loss 34.600323 loss_att 35.011814 loss_ctc 57.303173 loss_rnnt 31.490978 lr 0.00065771 rank 2
2022-12-03 23:56:02,973 DEBUG TRAIN Batch 6/7800 loss 26.918839 loss_att 33.486156 loss_ctc 42.730301 loss_rnnt 23.497183 lr 0.00065771 rank 6
2022-12-03 23:56:02,980 DEBUG TRAIN Batch 6/7800 loss 29.945616 loss_att 36.843109 loss_ctc 46.518875 loss_rnnt 26.356350 lr 0.00065746 rank 1
2022-12-03 23:56:02,980 DEBUG TRAIN Batch 6/7800 loss 27.200001 loss_att 34.303707 loss_ctc 41.521683 loss_rnnt 23.869701 lr 0.00065714 rank 2
2022-12-03 23:56:02,982 DEBUG TRAIN Batch 6/7800 loss 15.286842 loss_att 19.556078 loss_ctc 19.232832 loss_rnnt 13.906862 lr 0.00065735 rank 0
2022-12-03 23:56:02,984 DEBUG TRAIN Batch 6/7800 loss 9.147491 loss_att 13.178432 loss_ctc 20.005621 loss_rnnt 6.893553 lr 0.00065765 rank 5
2022-12-03 23:56:02,984 DEBUG TRAIN Batch 6/7800 loss 26.832897 loss_att 30.227604 loss_ctc 44.887447 loss_rnnt 23.746685 lr 0.00065756 rank 7
2022-12-03 23:56:02,992 DEBUG TRAIN Batch 6/7800 loss 8.206171 loss_att 14.064733 loss_ctc 17.939650 loss_rnnt 5.736661 lr 0.00065774 rank 4
2022-12-03 23:56:03,000 DEBUG TRAIN Batch 6/7800 loss 17.242769 loss_att 22.027365 loss_ctc 35.451920 loss_rnnt 13.857964 lr 0.00065737 rank 3
2022-12-03 23:57:15,949 DEBUG TRAIN Batch 6/7900 loss 11.851439 loss_att 14.220773 loss_ctc 16.773129 loss_rnnt 10.721347 lr 0.00065714 rank 6
2022-12-03 23:57:15,963 DEBUG TRAIN Batch 6/7900 loss 11.424844 loss_att 15.796032 loss_ctc 22.331356 loss_rnnt 9.096405 lr 0.00065678 rank 0
2022-12-03 23:57:15,968 DEBUG TRAIN Batch 6/7900 loss 17.507719 loss_att 20.886089 loss_ctc 33.280243 loss_rnnt 14.729041 lr 0.00065680 rank 3
2022-12-03 23:57:15,969 DEBUG TRAIN Batch 6/7900 loss 15.795597 loss_att 23.440014 loss_ctc 37.574699 loss_rnnt 11.362833 lr 0.00065689 rank 1
2022-12-03 23:57:15,969 DEBUG TRAIN Batch 6/7900 loss 14.342152 loss_att 17.340815 loss_ctc 26.103855 loss_rnnt 12.174191 lr 0.00065657 rank 2
2022-12-03 23:57:15,973 DEBUG TRAIN Batch 6/7900 loss 10.734236 loss_att 14.133251 loss_ctc 22.080444 loss_rnnt 8.541606 lr 0.00065717 rank 4
2022-12-03 23:57:16,000 DEBUG TRAIN Batch 6/7900 loss 23.172398 loss_att 26.715363 loss_ctc 39.679424 loss_rnnt 20.262865 lr 0.00065699 rank 7
2022-12-03 23:57:16,005 DEBUG TRAIN Batch 6/7900 loss 12.154324 loss_att 17.119423 loss_ctc 23.191277 loss_rnnt 9.689711 lr 0.00065708 rank 5
2022-12-03 23:58:28,118 DEBUG TRAIN Batch 6/8000 loss 21.372538 loss_att 24.927380 loss_ctc 35.824982 loss_rnnt 18.734577 lr 0.00065622 rank 0
2022-12-03 23:58:28,121 DEBUG TRAIN Batch 6/8000 loss 11.048920 loss_att 13.590288 loss_ctc 21.947208 loss_rnnt 9.087540 lr 0.00065601 rank 2
2022-12-03 23:58:28,123 DEBUG TRAIN Batch 6/8000 loss 24.270805 loss_att 33.390884 loss_ctc 37.190742 loss_rnnt 20.724133 lr 0.00065633 rank 1
2022-12-03 23:58:28,125 DEBUG TRAIN Batch 6/8000 loss 15.670908 loss_att 21.689566 loss_ctc 27.540344 loss_rnnt 12.884583 lr 0.00065661 rank 4
2022-12-03 23:58:28,126 DEBUG TRAIN Batch 6/8000 loss 24.458881 loss_att 27.015894 loss_ctc 34.031479 loss_rnnt 22.671129 lr 0.00065652 rank 5
2022-12-03 23:58:28,149 DEBUG TRAIN Batch 6/8000 loss 15.948196 loss_att 19.194517 loss_ctc 27.514668 loss_rnnt 13.756737 lr 0.00065658 rank 6
2022-12-03 23:58:28,162 DEBUG TRAIN Batch 6/8000 loss 22.424381 loss_att 26.701603 loss_ctc 33.720291 loss_rnnt 20.062819 lr 0.00065624 rank 3
2022-12-03 23:58:28,171 DEBUG TRAIN Batch 6/8000 loss 18.241264 loss_att 22.118628 loss_ctc 27.183889 loss_rnnt 16.273441 lr 0.00065642 rank 7
2022-12-03 23:59:39,843 DEBUG TRAIN Batch 6/8100 loss 21.204105 loss_att 24.641048 loss_ctc 33.015133 loss_rnnt 18.941914 lr 0.00065544 rank 2
2022-12-03 23:59:39,845 DEBUG TRAIN Batch 6/8100 loss 22.034681 loss_att 24.463703 loss_ctc 36.701164 loss_rnnt 19.593346 lr 0.00065604 rank 4
2022-12-03 23:59:39,850 DEBUG TRAIN Batch 6/8100 loss 24.243038 loss_att 27.122358 loss_ctc 34.417404 loss_rnnt 22.310593 lr 0.00065567 rank 3
2022-12-03 23:59:39,851 DEBUG TRAIN Batch 6/8100 loss 18.844831 loss_att 19.333065 loss_ctc 27.513580 loss_rnnt 17.591351 lr 0.00065601 rank 6
2022-12-03 23:59:39,853 DEBUG TRAIN Batch 6/8100 loss 18.103243 loss_att 21.632010 loss_ctc 26.674568 loss_rnnt 16.254646 lr 0.00065565 rank 0
2022-12-03 23:59:39,855 DEBUG TRAIN Batch 6/8100 loss 17.195107 loss_att 23.726957 loss_ctc 41.249359 loss_rnnt 12.681502 lr 0.00065576 rank 1
2022-12-03 23:59:39,857 DEBUG TRAIN Batch 6/8100 loss 23.354330 loss_att 27.500492 loss_ctc 34.132111 loss_rnnt 21.088058 lr 0.00065586 rank 7
2022-12-03 23:59:39,875 DEBUG TRAIN Batch 6/8100 loss 24.753180 loss_att 30.339161 loss_ctc 43.682842 loss_rnnt 21.112026 lr 0.00065595 rank 5
2022-12-04 00:00:51,700 DEBUG TRAIN Batch 6/8200 loss 25.367416 loss_att 27.935947 loss_ctc 40.535057 loss_rnnt 22.831358 lr 0.00065545 rank 6
2022-12-04 00:00:51,701 DEBUG TRAIN Batch 6/8200 loss 23.529766 loss_att 26.239248 loss_ctc 34.716732 loss_rnnt 21.496275 lr 0.00065539 rank 5
2022-12-04 00:00:51,703 DEBUG TRAIN Batch 6/8200 loss 14.551384 loss_att 17.330238 loss_ctc 28.048794 loss_rnnt 12.195959 lr 0.00065509 rank 0
2022-12-04 00:00:51,704 DEBUG TRAIN Batch 6/8200 loss 16.958647 loss_att 22.549606 loss_ctc 26.587261 loss_rnnt 14.556641 lr 0.00065511 rank 3
2022-12-04 00:00:51,706 DEBUG TRAIN Batch 6/8200 loss 17.981709 loss_att 23.212774 loss_ctc 29.289265 loss_rnnt 15.427822 lr 0.00065520 rank 1
2022-12-04 00:00:51,708 DEBUG TRAIN Batch 6/8200 loss 11.725950 loss_att 13.974140 loss_ctc 17.315037 loss_rnnt 10.531101 lr 0.00065548 rank 4
2022-12-04 00:00:51,714 DEBUG TRAIN Batch 6/8200 loss 16.939941 loss_att 21.570923 loss_ctc 28.466892 loss_rnnt 14.476817 lr 0.00065530 rank 7
2022-12-04 00:00:51,763 DEBUG TRAIN Batch 6/8200 loss 17.988014 loss_att 18.839432 loss_ctc 26.689545 loss_rnnt 16.657526 lr 0.00065488 rank 2
2022-12-04 00:02:03,587 DEBUG TRAIN Batch 6/8300 loss 24.907841 loss_att 33.333244 loss_ctc 37.755787 loss_rnnt 21.509701 lr 0.00065453 rank 0
2022-12-04 00:02:03,589 DEBUG TRAIN Batch 6/8300 loss 15.779682 loss_att 20.526403 loss_ctc 28.924753 loss_rnnt 13.077662 lr 0.00065455 rank 3
2022-12-04 00:02:03,591 DEBUG TRAIN Batch 6/8300 loss 14.992630 loss_att 15.858900 loss_ctc 24.945700 loss_rnnt 13.492300 lr 0.00065489 rank 6
2022-12-04 00:02:03,592 DEBUG TRAIN Batch 6/8300 loss 13.081406 loss_att 19.602959 loss_ctc 21.850128 loss_rnnt 10.607932 lr 0.00065482 rank 5
2022-12-04 00:02:03,593 DEBUG TRAIN Batch 6/8300 loss 13.230810 loss_att 16.473495 loss_ctc 25.470886 loss_rnnt 10.950263 lr 0.00065432 rank 2
2022-12-04 00:02:03,594 DEBUG TRAIN Batch 6/8300 loss 17.455759 loss_att 21.386517 loss_ctc 32.015594 loss_rnnt 14.728296 lr 0.00065473 rank 7
2022-12-04 00:02:03,594 DEBUG TRAIN Batch 6/8300 loss 11.194960 loss_att 15.903286 loss_ctc 17.436859 loss_rnnt 9.421041 lr 0.00065464 rank 1
2022-12-04 00:02:03,599 DEBUG TRAIN Batch 6/8300 loss 19.894474 loss_att 24.628681 loss_ctc 36.832741 loss_rnnt 16.689198 lr 0.00065491 rank 4
2022-12-04 00:02:45,141 DEBUG CV Batch 6/0 loss 2.623687 loss_att 2.923095 loss_ctc 4.841672 loss_rnnt 2.268074 history loss 2.526514 rank 2
2022-12-04 00:02:45,149 DEBUG CV Batch 6/0 loss 2.623687 loss_att 2.923095 loss_ctc 4.841672 loss_rnnt 2.268074 history loss 2.526514 rank 7
2022-12-04 00:02:45,151 DEBUG CV Batch 6/0 loss 2.623687 loss_att 2.923095 loss_ctc 4.841672 loss_rnnt 2.268074 history loss 2.526514 rank 5
2022-12-04 00:02:45,151 DEBUG CV Batch 6/0 loss 2.623687 loss_att 2.923095 loss_ctc 4.841672 loss_rnnt 2.268074 history loss 2.526514 rank 4
2022-12-04 00:02:45,156 DEBUG CV Batch 6/0 loss 2.623687 loss_att 2.923095 loss_ctc 4.841672 loss_rnnt 2.268074 history loss 2.526514 rank 3
2022-12-04 00:02:45,159 DEBUG CV Batch 6/0 loss 2.623687 loss_att 2.923095 loss_ctc 4.841672 loss_rnnt 2.268074 history loss 2.526514 rank 0
2022-12-04 00:02:45,160 DEBUG CV Batch 6/0 loss 2.623687 loss_att 2.923095 loss_ctc 4.841672 loss_rnnt 2.268074 history loss 2.526514 rank 6
2022-12-04 00:02:45,166 DEBUG CV Batch 6/0 loss 2.623687 loss_att 2.923095 loss_ctc 4.841672 loss_rnnt 2.268074 history loss 2.526514 rank 1
2022-12-04 00:02:56,479 DEBUG CV Batch 6/100 loss 10.125655 loss_att 10.731963 loss_ctc 17.717369 loss_rnnt 8.992165 history loss 4.858914 rank 6
2022-12-04 00:02:56,552 DEBUG CV Batch 6/100 loss 10.125655 loss_att 10.731963 loss_ctc 17.717369 loss_rnnt 8.992165 history loss 4.858914 rank 0
2022-12-04 00:02:56,572 DEBUG CV Batch 6/100 loss 10.125655 loss_att 10.731963 loss_ctc 17.717369 loss_rnnt 8.992165 history loss 4.858914 rank 1
2022-12-04 00:02:56,599 DEBUG CV Batch 6/100 loss 10.125655 loss_att 10.731963 loss_ctc 17.717369 loss_rnnt 8.992165 history loss 4.858914 rank 7
2022-12-04 00:02:56,651 DEBUG CV Batch 6/100 loss 10.125655 loss_att 10.731963 loss_ctc 17.717369 loss_rnnt 8.992165 history loss 4.858914 rank 2
2022-12-04 00:02:56,740 DEBUG CV Batch 6/100 loss 10.125655 loss_att 10.731963 loss_ctc 17.717369 loss_rnnt 8.992165 history loss 4.858914 rank 4
2022-12-04 00:02:56,801 DEBUG CV Batch 6/100 loss 10.125655 loss_att 10.731963 loss_ctc 17.717369 loss_rnnt 8.992165 history loss 4.858914 rank 3
2022-12-04 00:02:56,836 DEBUG CV Batch 6/100 loss 10.125655 loss_att 10.731963 loss_ctc 17.717369 loss_rnnt 8.992165 history loss 4.858914 rank 5
2022-12-04 00:03:09,932 DEBUG CV Batch 6/200 loss 11.841715 loss_att 18.245909 loss_ctc 18.865480 loss_rnnt 9.624373 history loss 5.435058 rank 6
2022-12-04 00:03:10,040 DEBUG CV Batch 6/200 loss 11.841715 loss_att 18.245909 loss_ctc 18.865480 loss_rnnt 9.624373 history loss 5.435058 rank 0
2022-12-04 00:03:10,378 DEBUG CV Batch 6/200 loss 11.841715 loss_att 18.245909 loss_ctc 18.865480 loss_rnnt 9.624373 history loss 5.435058 rank 1
2022-12-04 00:03:10,412 DEBUG CV Batch 6/200 loss 11.841715 loss_att 18.245909 loss_ctc 18.865480 loss_rnnt 9.624373 history loss 5.435058 rank 3
2022-12-04 00:03:10,419 DEBUG CV Batch 6/200 loss 11.841715 loss_att 18.245909 loss_ctc 18.865480 loss_rnnt 9.624373 history loss 5.435058 rank 2
2022-12-04 00:03:10,495 DEBUG CV Batch 6/200 loss 11.841715 loss_att 18.245909 loss_ctc 18.865480 loss_rnnt 9.624373 history loss 5.435058 rank 4
2022-12-04 00:03:10,619 DEBUG CV Batch 6/200 loss 11.841715 loss_att 18.245909 loss_ctc 18.865480 loss_rnnt 9.624373 history loss 5.435058 rank 7
2022-12-04 00:03:10,886 DEBUG CV Batch 6/200 loss 11.841715 loss_att 18.245909 loss_ctc 18.865480 loss_rnnt 9.624373 history loss 5.435058 rank 5
2022-12-04 00:03:21,990 DEBUG CV Batch 6/300 loss 6.767327 loss_att 7.906425 loss_ctc 11.718438 loss_rnnt 5.879359 history loss 5.575426 rank 6
2022-12-04 00:03:22,263 DEBUG CV Batch 6/300 loss 6.767327 loss_att 7.906425 loss_ctc 11.718438 loss_rnnt 5.879359 history loss 5.575426 rank 0
2022-12-04 00:03:22,511 DEBUG CV Batch 6/300 loss 6.767327 loss_att 7.906425 loss_ctc 11.718438 loss_rnnt 5.879359 history loss 5.575426 rank 1
2022-12-04 00:03:22,581 DEBUG CV Batch 6/300 loss 6.767327 loss_att 7.906425 loss_ctc 11.718438 loss_rnnt 5.879359 history loss 5.575426 rank 2
2022-12-04 00:03:22,654 DEBUG CV Batch 6/300 loss 6.767327 loss_att 7.906425 loss_ctc 11.718438 loss_rnnt 5.879359 history loss 5.575426 rank 3
2022-12-04 00:03:22,687 DEBUG CV Batch 6/300 loss 6.767327 loss_att 7.906425 loss_ctc 11.718438 loss_rnnt 5.879359 history loss 5.575426 rank 4
2022-12-04 00:03:23,280 DEBUG CV Batch 6/300 loss 6.767327 loss_att 7.906425 loss_ctc 11.718438 loss_rnnt 5.879359 history loss 5.575426 rank 5
2022-12-04 00:03:23,323 DEBUG CV Batch 6/300 loss 6.767327 loss_att 7.906425 loss_ctc 11.718438 loss_rnnt 5.879359 history loss 5.575426 rank 7
2022-12-04 00:03:34,131 DEBUG CV Batch 6/400 loss 17.544506 loss_att 65.906570 loss_ctc 17.940058 loss_rnnt 7.819352 history loss 6.592035 rank 6
2022-12-04 00:03:34,564 DEBUG CV Batch 6/400 loss 17.544506 loss_att 65.906570 loss_ctc 17.940058 loss_rnnt 7.819352 history loss 6.592035 rank 0
2022-12-04 00:03:34,767 DEBUG CV Batch 6/400 loss 17.544506 loss_att 65.906570 loss_ctc 17.940058 loss_rnnt 7.819352 history loss 6.592035 rank 4
2022-12-04 00:03:34,774 DEBUG CV Batch 6/400 loss 17.544506 loss_att 65.906570 loss_ctc 17.940058 loss_rnnt 7.819352 history loss 6.592035 rank 2
2022-12-04 00:03:34,892 DEBUG CV Batch 6/400 loss 17.544506 loss_att 65.906570 loss_ctc 17.940058 loss_rnnt 7.819352 history loss 6.592035 rank 3
2022-12-04 00:03:35,065 DEBUG CV Batch 6/400 loss 17.544506 loss_att 65.906570 loss_ctc 17.940058 loss_rnnt 7.819352 history loss 6.592035 rank 1
2022-12-04 00:03:35,415 DEBUG CV Batch 6/400 loss 17.544506 loss_att 65.906570 loss_ctc 17.940058 loss_rnnt 7.819352 history loss 6.592035 rank 5
2022-12-04 00:03:35,619 DEBUG CV Batch 6/400 loss 17.544506 loss_att 65.906570 loss_ctc 17.940058 loss_rnnt 7.819352 history loss 6.592035 rank 7
2022-12-04 00:03:44,640 DEBUG CV Batch 6/500 loss 8.394697 loss_att 8.923662 loss_ctc 12.927463 loss_rnnt 7.684535 history loss 7.364583 rank 6
2022-12-04 00:03:45,292 DEBUG CV Batch 6/500 loss 8.394697 loss_att 8.923662 loss_ctc 12.927463 loss_rnnt 7.684535 history loss 7.364583 rank 0
2022-12-04 00:03:45,333 DEBUG CV Batch 6/500 loss 8.394697 loss_att 8.923662 loss_ctc 12.927463 loss_rnnt 7.684535 history loss 7.364583 rank 4
2022-12-04 00:03:45,361 DEBUG CV Batch 6/500 loss 8.394697 loss_att 8.923662 loss_ctc 12.927463 loss_rnnt 7.684535 history loss 7.364583 rank 2
2022-12-04 00:03:45,414 DEBUG CV Batch 6/500 loss 8.394697 loss_att 8.923662 loss_ctc 12.927463 loss_rnnt 7.684535 history loss 7.364583 rank 3
2022-12-04 00:03:45,812 DEBUG CV Batch 6/500 loss 8.394697 loss_att 8.923662 loss_ctc 12.927463 loss_rnnt 7.684535 history loss 7.364583 rank 1
2022-12-04 00:03:46,053 DEBUG CV Batch 6/500 loss 8.394697 loss_att 8.923662 loss_ctc 12.927463 loss_rnnt 7.684535 history loss 7.364583 rank 5
2022-12-04 00:03:46,294 DEBUG CV Batch 6/500 loss 8.394697 loss_att 8.923662 loss_ctc 12.927463 loss_rnnt 7.684535 history loss 7.364583 rank 7
2022-12-04 00:03:56,764 DEBUG CV Batch 6/600 loss 7.623654 loss_att 7.764103 loss_ctc 12.168728 loss_rnnt 6.989554 history loss 8.300786 rank 6
2022-12-04 00:03:57,595 DEBUG CV Batch 6/600 loss 7.623654 loss_att 7.764103 loss_ctc 12.168728 loss_rnnt 6.989554 history loss 8.300786 rank 0
2022-12-04 00:03:57,660 DEBUG CV Batch 6/600 loss 7.623654 loss_att 7.764103 loss_ctc 12.168728 loss_rnnt 6.989554 history loss 8.300786 rank 2
2022-12-04 00:03:57,661 DEBUG CV Batch 6/600 loss 7.623654 loss_att 7.764103 loss_ctc 12.168728 loss_rnnt 6.989554 history loss 8.300786 rank 3
2022-12-04 00:03:57,664 DEBUG CV Batch 6/600 loss 7.623654 loss_att 7.764103 loss_ctc 12.168728 loss_rnnt 6.989554 history loss 8.300786 rank 4
2022-12-04 00:03:58,225 DEBUG CV Batch 6/600 loss 7.623654 loss_att 7.764103 loss_ctc 12.168728 loss_rnnt 6.989554 history loss 8.300786 rank 5
2022-12-04 00:03:58,248 DEBUG CV Batch 6/600 loss 7.623654 loss_att 7.764103 loss_ctc 12.168728 loss_rnnt 6.989554 history loss 8.300786 rank 1
2022-12-04 00:03:59,020 DEBUG CV Batch 6/600 loss 7.623654 loss_att 7.764103 loss_ctc 12.168728 loss_rnnt 6.989554 history loss 8.300786 rank 7
2022-12-04 00:04:08,252 DEBUG CV Batch 6/700 loss 29.110241 loss_att 39.535717 loss_ctc 45.630661 loss_rnnt 24.822420 history loss 8.987120 rank 6
2022-12-04 00:04:09,114 DEBUG CV Batch 6/700 loss 29.110241 loss_att 39.535717 loss_ctc 45.630661 loss_rnnt 24.822420 history loss 8.987120 rank 2
2022-12-04 00:04:09,179 DEBUG CV Batch 6/700 loss 29.110241 loss_att 39.535717 loss_ctc 45.630661 loss_rnnt 24.822420 history loss 8.987120 rank 3
2022-12-04 00:04:09,273 DEBUG CV Batch 6/700 loss 29.110241 loss_att 39.535717 loss_ctc 45.630661 loss_rnnt 24.822420 history loss 8.987120 rank 0
2022-12-04 00:04:09,546 DEBUG CV Batch 6/700 loss 29.110241 loss_att 39.535717 loss_ctc 45.630661 loss_rnnt 24.822420 history loss 8.987120 rank 4
2022-12-04 00:04:09,918 DEBUG CV Batch 6/700 loss 29.110241 loss_att 39.535717 loss_ctc 45.630661 loss_rnnt 24.822420 history loss 8.987120 rank 5
2022-12-04 00:04:10,197 DEBUG CV Batch 6/700 loss 29.110241 loss_att 39.535717 loss_ctc 45.630661 loss_rnnt 24.822420 history loss 8.987120 rank 1
2022-12-04 00:04:10,891 DEBUG CV Batch 6/700 loss 29.110241 loss_att 39.535717 loss_ctc 45.630661 loss_rnnt 24.822420 history loss 8.987120 rank 7
2022-12-04 00:04:19,437 DEBUG CV Batch 6/800 loss 12.395864 loss_att 12.200130 loss_ctc 21.921566 loss_rnnt 11.164917 history loss 8.424674 rank 6
2022-12-04 00:04:20,411 DEBUG CV Batch 6/800 loss 12.395864 loss_att 12.200130 loss_ctc 21.921566 loss_rnnt 11.164917 history loss 8.424674 rank 3
2022-12-04 00:04:20,741 DEBUG CV Batch 6/800 loss 12.395864 loss_att 12.200130 loss_ctc 21.921566 loss_rnnt 11.164917 history loss 8.424674 rank 0
2022-12-04 00:04:21,201 DEBUG CV Batch 6/800 loss 12.395864 loss_att 12.200130 loss_ctc 21.921566 loss_rnnt 11.164917 history loss 8.424674 rank 2
2022-12-04 00:04:21,594 DEBUG CV Batch 6/800 loss 12.395864 loss_att 12.200130 loss_ctc 21.921566 loss_rnnt 11.164917 history loss 8.424674 rank 1
2022-12-04 00:04:21,613 DEBUG CV Batch 6/800 loss 12.395864 loss_att 12.200130 loss_ctc 21.921566 loss_rnnt 11.164917 history loss 8.424674 rank 4
2022-12-04 00:04:21,616 DEBUG CV Batch 6/800 loss 12.395864 loss_att 12.200130 loss_ctc 21.921566 loss_rnnt 11.164917 history loss 8.424674 rank 5
2022-12-04 00:04:22,407 DEBUG CV Batch 6/800 loss 12.395864 loss_att 12.200130 loss_ctc 21.921566 loss_rnnt 11.164917 history loss 8.424674 rank 7
2022-12-04 00:04:33,037 DEBUG CV Batch 6/900 loss 16.588881 loss_att 22.224033 loss_ctc 27.745991 loss_rnnt 13.974236 history loss 8.218962 rank 6
2022-12-04 00:04:34,103 DEBUG CV Batch 6/900 loss 16.588881 loss_att 22.224033 loss_ctc 27.745991 loss_rnnt 13.974236 history loss 8.218962 rank 3
2022-12-04 00:04:34,385 DEBUG CV Batch 6/900 loss 16.588881 loss_att 22.224033 loss_ctc 27.745991 loss_rnnt 13.974236 history loss 8.218962 rank 0
2022-12-04 00:04:34,909 DEBUG CV Batch 6/900 loss 16.588881 loss_att 22.224033 loss_ctc 27.745991 loss_rnnt 13.974236 history loss 8.218962 rank 2
2022-12-04 00:04:35,269 DEBUG CV Batch 6/900 loss 16.588881 loss_att 22.224033 loss_ctc 27.745991 loss_rnnt 13.974236 history loss 8.218962 rank 1
2022-12-04 00:04:35,732 DEBUG CV Batch 6/900 loss 16.588881 loss_att 22.224033 loss_ctc 27.745991 loss_rnnt 13.974236 history loss 8.218962 rank 4
2022-12-04 00:04:35,735 DEBUG CV Batch 6/900 loss 16.588881 loss_att 22.224033 loss_ctc 27.745991 loss_rnnt 13.974236 history loss 8.218962 rank 5
2022-12-04 00:04:36,142 DEBUG CV Batch 6/900 loss 16.588881 loss_att 22.224033 loss_ctc 27.745991 loss_rnnt 13.974236 history loss 8.218962 rank 7
2022-12-04 00:04:45,440 DEBUG CV Batch 6/1000 loss 4.797318 loss_att 6.114408 loss_ctc 7.651844 loss_rnnt 4.153296 history loss 7.980523 rank 6
2022-12-04 00:04:46,545 DEBUG CV Batch 6/1000 loss 4.797318 loss_att 6.114408 loss_ctc 7.651844 loss_rnnt 4.153296 history loss 7.980523 rank 3
2022-12-04 00:04:46,899 DEBUG CV Batch 6/1000 loss 4.797318 loss_att 6.114408 loss_ctc 7.651844 loss_rnnt 4.153296 history loss 7.980523 rank 0
2022-12-04 00:04:47,203 DEBUG CV Batch 6/1000 loss 4.797318 loss_att 6.114408 loss_ctc 7.651844 loss_rnnt 4.153296 history loss 7.980523 rank 2
2022-12-04 00:04:47,998 DEBUG CV Batch 6/1000 loss 4.797318 loss_att 6.114408 loss_ctc 7.651844 loss_rnnt 4.153296 history loss 7.980523 rank 5
2022-12-04 00:04:48,057 DEBUG CV Batch 6/1000 loss 4.797318 loss_att 6.114408 loss_ctc 7.651844 loss_rnnt 4.153296 history loss 7.980523 rank 4
2022-12-04 00:04:48,131 DEBUG CV Batch 6/1000 loss 4.797318 loss_att 6.114408 loss_ctc 7.651844 loss_rnnt 4.153296 history loss 7.980523 rank 1
2022-12-04 00:04:48,838 DEBUG CV Batch 6/1000 loss 4.797318 loss_att 6.114408 loss_ctc 7.651844 loss_rnnt 4.153296 history loss 7.980523 rank 7
2022-12-04 00:04:57,452 DEBUG CV Batch 6/1100 loss 6.084839 loss_att 6.014991 loss_ctc 10.784835 loss_rnnt 5.472143 history loss 7.965318 rank 6
2022-12-04 00:04:58,670 DEBUG CV Batch 6/1100 loss 6.084839 loss_att 6.014991 loss_ctc 10.784835 loss_rnnt 5.472143 history loss 7.965318 rank 3
2022-12-04 00:04:59,101 DEBUG CV Batch 6/1100 loss 6.084839 loss_att 6.014991 loss_ctc 10.784835 loss_rnnt 5.472143 history loss 7.965318 rank 0
2022-12-04 00:04:59,545 DEBUG CV Batch 6/1100 loss 6.084839 loss_att 6.014991 loss_ctc 10.784835 loss_rnnt 5.472143 history loss 7.965318 rank 2
2022-12-04 00:05:00,005 DEBUG CV Batch 6/1100 loss 6.084839 loss_att 6.014991 loss_ctc 10.784835 loss_rnnt 5.472143 history loss 7.965318 rank 4
2022-12-04 00:05:00,155 DEBUG CV Batch 6/1100 loss 6.084839 loss_att 6.014991 loss_ctc 10.784835 loss_rnnt 5.472143 history loss 7.965318 rank 5
2022-12-04 00:05:00,575 DEBUG CV Batch 6/1100 loss 6.084839 loss_att 6.014991 loss_ctc 10.784835 loss_rnnt 5.472143 history loss 7.965318 rank 1
2022-12-04 00:05:01,011 DEBUG CV Batch 6/1100 loss 6.084839 loss_att 6.014991 loss_ctc 10.784835 loss_rnnt 5.472143 history loss 7.965318 rank 7
2022-12-04 00:05:08,314 DEBUG CV Batch 6/1200 loss 14.218235 loss_att 14.042062 loss_ctc 18.520445 loss_rnnt 13.679843 history loss 8.296690 rank 6
2022-12-04 00:05:09,603 DEBUG CV Batch 6/1200 loss 14.218235 loss_att 14.042062 loss_ctc 18.520445 loss_rnnt 13.679843 history loss 8.296690 rank 3
2022-12-04 00:05:09,904 DEBUG CV Batch 6/1200 loss 14.218235 loss_att 14.042062 loss_ctc 18.520445 loss_rnnt 13.679843 history loss 8.296690 rank 0
2022-12-04 00:05:10,542 DEBUG CV Batch 6/1200 loss 14.218235 loss_att 14.042062 loss_ctc 18.520445 loss_rnnt 13.679843 history loss 8.296690 rank 4
2022-12-04 00:05:10,710 DEBUG CV Batch 6/1200 loss 14.218235 loss_att 14.042062 loss_ctc 18.520445 loss_rnnt 13.679843 history loss 8.296690 rank 5
2022-12-04 00:05:10,794 DEBUG CV Batch 6/1200 loss 14.218235 loss_att 14.042062 loss_ctc 18.520445 loss_rnnt 13.679843 history loss 8.296690 rank 2
2022-12-04 00:05:11,761 DEBUG CV Batch 6/1200 loss 14.218235 loss_att 14.042062 loss_ctc 18.520445 loss_rnnt 13.679843 history loss 8.296690 rank 7
2022-12-04 00:05:11,818 DEBUG CV Batch 6/1200 loss 14.218235 loss_att 14.042062 loss_ctc 18.520445 loss_rnnt 13.679843 history loss 8.296690 rank 1
2022-12-04 00:05:20,438 DEBUG CV Batch 6/1300 loss 6.565792 loss_att 6.912959 loss_ctc 10.629984 loss_rnnt 5.954467 history loss 8.606822 rank 6
2022-12-04 00:05:21,843 DEBUG CV Batch 6/1300 loss 6.565792 loss_att 6.912959 loss_ctc 10.629984 loss_rnnt 5.954467 history loss 8.606822 rank 3
2022-12-04 00:05:22,273 DEBUG CV Batch 6/1300 loss 6.565792 loss_att 6.912959 loss_ctc 10.629984 loss_rnnt 5.954467 history loss 8.606822 rank 0
2022-12-04 00:05:22,929 DEBUG CV Batch 6/1300 loss 6.565792 loss_att 6.912959 loss_ctc 10.629984 loss_rnnt 5.954467 history loss 8.606822 rank 5
2022-12-04 00:05:22,949 DEBUG CV Batch 6/1300 loss 6.565792 loss_att 6.912959 loss_ctc 10.629984 loss_rnnt 5.954467 history loss 8.606822 rank 2
2022-12-04 00:05:22,959 DEBUG CV Batch 6/1300 loss 6.565792 loss_att 6.912959 loss_ctc 10.629984 loss_rnnt 5.954467 history loss 8.606822 rank 4
2022-12-04 00:05:23,886 DEBUG CV Batch 6/1300 loss 6.565792 loss_att 6.912959 loss_ctc 10.629984 loss_rnnt 5.954467 history loss 8.606822 rank 7
2022-12-04 00:05:24,215 DEBUG CV Batch 6/1300 loss 6.565792 loss_att 6.912959 loss_ctc 10.629984 loss_rnnt 5.954467 history loss 8.606822 rank 1
2022-12-04 00:05:31,902 DEBUG CV Batch 6/1400 loss 10.630803 loss_att 31.628366 loss_ctc 16.308582 loss_rnnt 5.674253 history loss 8.944105 rank 6
2022-12-04 00:05:33,455 DEBUG CV Batch 6/1400 loss 10.630803 loss_att 31.628366 loss_ctc 16.308582 loss_rnnt 5.674253 history loss 8.944105 rank 3
2022-12-04 00:05:33,883 DEBUG CV Batch 6/1400 loss 10.630803 loss_att 31.628366 loss_ctc 16.308582 loss_rnnt 5.674253 history loss 8.944105 rank 0
2022-12-04 00:05:34,311 DEBUG CV Batch 6/1400 loss 10.630803 loss_att 31.628366 loss_ctc 16.308582 loss_rnnt 5.674253 history loss 8.944105 rank 5
2022-12-04 00:05:34,481 DEBUG CV Batch 6/1400 loss 10.630803 loss_att 31.628366 loss_ctc 16.308582 loss_rnnt 5.674253 history loss 8.944105 rank 2
2022-12-04 00:05:34,731 DEBUG CV Batch 6/1400 loss 10.630803 loss_att 31.628366 loss_ctc 16.308582 loss_rnnt 5.674253 history loss 8.944105 rank 4
2022-12-04 00:05:35,271 DEBUG CV Batch 6/1400 loss 10.630803 loss_att 31.628366 loss_ctc 16.308582 loss_rnnt 5.674253 history loss 8.944105 rank 7
2022-12-04 00:05:35,803 DEBUG CV Batch 6/1400 loss 10.630803 loss_att 31.628366 loss_ctc 16.308582 loss_rnnt 5.674253 history loss 8.944105 rank 1
2022-12-04 00:05:43,569 DEBUG CV Batch 6/1500 loss 9.976319 loss_att 11.282385 loss_ctc 12.315730 loss_rnnt 9.403184 history loss 8.750438 rank 6
2022-12-04 00:05:45,213 DEBUG CV Batch 6/1500 loss 9.976319 loss_att 11.282385 loss_ctc 12.315730 loss_rnnt 9.403184 history loss 8.750438 rank 3
2022-12-04 00:05:45,627 DEBUG CV Batch 6/1500 loss 9.976319 loss_att 11.282385 loss_ctc 12.315730 loss_rnnt 9.403184 history loss 8.750438 rank 0
2022-12-04 00:05:46,093 DEBUG CV Batch 6/1500 loss 9.976319 loss_att 11.282385 loss_ctc 12.315730 loss_rnnt 9.403184 history loss 8.750438 rank 5
2022-12-04 00:05:46,231 DEBUG CV Batch 6/1500 loss 9.976319 loss_att 11.282385 loss_ctc 12.315730 loss_rnnt 9.403184 history loss 8.750438 rank 2
2022-12-04 00:05:46,591 DEBUG CV Batch 6/1500 loss 9.976319 loss_att 11.282385 loss_ctc 12.315730 loss_rnnt 9.403184 history loss 8.750438 rank 4
2022-12-04 00:05:47,042 DEBUG CV Batch 6/1500 loss 9.976319 loss_att 11.282385 loss_ctc 12.315730 loss_rnnt 9.403184 history loss 8.750438 rank 7
2022-12-04 00:05:47,905 DEBUG CV Batch 6/1500 loss 9.976319 loss_att 11.282385 loss_ctc 12.315730 loss_rnnt 9.403184 history loss 8.750438 rank 1
2022-12-04 00:05:56,664 DEBUG CV Batch 6/1600 loss 8.394018 loss_att 16.534519 loss_ctc 22.489275 loss_rnnt 4.886550 history loss 8.667506 rank 6
2022-12-04 00:05:58,605 DEBUG CV Batch 6/1600 loss 8.394018 loss_att 16.534519 loss_ctc 22.489275 loss_rnnt 4.886550 history loss 8.667506 rank 3
2022-12-04 00:05:58,893 DEBUG CV Batch 6/1600 loss 8.394018 loss_att 16.534519 loss_ctc 22.489275 loss_rnnt 4.886550 history loss 8.667506 rank 0
2022-12-04 00:05:59,582 DEBUG CV Batch 6/1600 loss 8.394018 loss_att 16.534519 loss_ctc 22.489275 loss_rnnt 4.886550 history loss 8.667506 rank 5
2022-12-04 00:05:59,812 DEBUG CV Batch 6/1600 loss 8.394018 loss_att 16.534519 loss_ctc 22.489275 loss_rnnt 4.886550 history loss 8.667506 rank 2
2022-12-04 00:06:00,268 DEBUG CV Batch 6/1600 loss 8.394018 loss_att 16.534519 loss_ctc 22.489275 loss_rnnt 4.886550 history loss 8.667506 rank 4
2022-12-04 00:06:00,767 DEBUG CV Batch 6/1600 loss 8.394018 loss_att 16.534519 loss_ctc 22.489275 loss_rnnt 4.886550 history loss 8.667506 rank 7
2022-12-04 00:06:01,390 DEBUG CV Batch 6/1600 loss 8.394018 loss_att 16.534519 loss_ctc 22.489275 loss_rnnt 4.886550 history loss 8.667506 rank 1
2022-12-04 00:06:09,244 DEBUG CV Batch 6/1700 loss 12.233388 loss_att 12.192874 loss_ctc 21.259991 loss_rnnt 11.037943 history loss 8.559061 rank 6
2022-12-04 00:06:11,228 DEBUG CV Batch 6/1700 loss 12.233388 loss_att 12.192874 loss_ctc 21.259991 loss_rnnt 11.037943 history loss 8.559061 rank 3
2022-12-04 00:06:11,535 DEBUG CV Batch 6/1700 loss 12.233388 loss_att 12.192874 loss_ctc 21.259991 loss_rnnt 11.037943 history loss 8.559061 rank 0
2022-12-04 00:06:12,154 DEBUG CV Batch 6/1700 loss 12.233388 loss_att 12.192874 loss_ctc 21.259991 loss_rnnt 11.037943 history loss 8.559061 rank 5
2022-12-04 00:06:12,514 DEBUG CV Batch 6/1700 loss 12.233388 loss_att 12.192874 loss_ctc 21.259991 loss_rnnt 11.037943 history loss 8.559061 rank 2
2022-12-04 00:06:12,951 DEBUG CV Batch 6/1700 loss 12.233388 loss_att 12.192874 loss_ctc 21.259991 loss_rnnt 11.037943 history loss 8.559061 rank 4
2022-12-04 00:06:13,805 DEBUG CV Batch 6/1700 loss 12.233388 loss_att 12.192874 loss_ctc 21.259991 loss_rnnt 11.037943 history loss 8.559061 rank 7
2022-12-04 00:06:14,251 DEBUG CV Batch 6/1700 loss 12.233388 loss_att 12.192874 loss_ctc 21.259991 loss_rnnt 11.037943 history loss 8.559061 rank 1
2022-12-04 00:06:18,393 INFO Epoch 6 CV info cv_loss 8.520733891625438
2022-12-04 00:06:18,393 INFO Epoch 7 TRAIN info lr 0.0006547116620234855
2022-12-04 00:06:18,398 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 00:06:20,428 INFO Epoch 6 CV info cv_loss 8.520733891625438
2022-12-04 00:06:20,428 INFO Epoch 7 TRAIN info lr 0.0006544087806709167
2022-12-04 00:06:20,430 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 00:06:20,725 INFO Epoch 6 CV info cv_loss 8.520733891625438
2022-12-04 00:06:20,726 INFO Checkpoint: save to checkpoint exp/1202_encoder_bias_30_0.1/6.pt
2022-12-04 00:06:21,314 INFO Epoch 7 TRAIN info lr 0.000654296709019754
2022-12-04 00:06:21,319 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 00:06:21,501 INFO Epoch 6 CV info cv_loss 8.520733891625438
2022-12-04 00:06:21,502 INFO Epoch 7 TRAIN info lr 0.0006546050447106971
2022-12-04 00:06:21,507 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 00:06:21,952 INFO Epoch 6 CV info cv_loss 8.520733891625438
2022-12-04 00:06:21,953 INFO Epoch 7 TRAIN info lr 0.0006540447581805335
2022-12-04 00:06:21,957 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 00:06:22,163 INFO Epoch 6 CV info cv_loss 8.520733891625438
2022-12-04 00:06:22,163 INFO Epoch 7 TRAIN info lr 0.000654638707708519
2022-12-04 00:06:22,165 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 00:06:23,067 INFO Epoch 6 CV info cv_loss 8.520733891625438
2022-12-04 00:06:23,068 INFO Epoch 7 TRAIN info lr 0.0006545994347159273
2022-12-04 00:06:23,072 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 00:06:23,452 INFO Epoch 6 CV info cv_loss 8.520733891625438
2022-12-04 00:06:23,453 INFO Epoch 7 TRAIN info lr 0.0006544143857652888
2022-12-04 00:06:23,458 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 00:07:25,088 DEBUG TRAIN Batch 7/0 loss 9.110839 loss_att 9.004425 loss_ctc 13.922852 loss_rnnt 8.490520 lr 0.00065471 rank 6
2022-12-04 00:07:25,091 DEBUG TRAIN Batch 7/0 loss 9.778118 loss_att 9.732216 loss_ctc 13.393107 loss_rnnt 9.305300 lr 0.00065429 rank 0
2022-12-04 00:07:25,093 DEBUG TRAIN Batch 7/0 loss 10.727977 loss_att 9.820322 loss_ctc 13.766217 loss_rnnt 10.504410 lr 0.00065460 rank 5
2022-12-04 00:07:25,097 DEBUG TRAIN Batch 7/0 loss 12.833200 loss_att 12.351985 loss_ctc 17.400686 loss_rnnt 12.320445 lr 0.00065459 rank 7
2022-12-04 00:07:25,102 DEBUG TRAIN Batch 7/0 loss 9.965268 loss_att 9.845497 loss_ctc 13.475633 loss_rnnt 9.521174 lr 0.00065463 rank 4
2022-12-04 00:07:25,108 DEBUG TRAIN Batch 7/0 loss 10.918319 loss_att 11.178503 loss_ctc 15.858431 loss_rnnt 10.207600 lr 0.00065404 rank 2
2022-12-04 00:07:25,121 DEBUG TRAIN Batch 7/0 loss 12.557392 loss_att 12.751804 loss_ctc 18.683008 loss_rnnt 11.701762 lr 0.00065441 rank 1
2022-12-04 00:07:25,135 DEBUG TRAIN Batch 7/0 loss 10.230803 loss_att 10.129683 loss_ctc 14.427594 loss_rnnt 9.691455 lr 0.00065440 rank 3
2022-12-04 00:08:36,494 DEBUG TRAIN Batch 7/100 loss 10.912903 loss_att 14.930423 loss_ctc 17.204632 loss_rnnt 9.270502 lr 0.00065373 rank 0
2022-12-04 00:08:36,497 DEBUG TRAIN Batch 7/100 loss 20.979519 loss_att 22.635704 loss_ctc 29.617605 loss_rnnt 19.496536 lr 0.00065384 rank 3
2022-12-04 00:08:36,498 DEBUG TRAIN Batch 7/100 loss 12.489883 loss_att 18.642693 loss_ctc 20.692892 loss_rnnt 10.165586 lr 0.00065415 rank 6
2022-12-04 00:08:36,498 DEBUG TRAIN Batch 7/100 loss 24.624081 loss_att 33.783691 loss_ctc 40.827675 loss_rnnt 20.631680 lr 0.00065404 rank 5
2022-12-04 00:08:36,500 DEBUG TRAIN Batch 7/100 loss 18.897251 loss_att 27.915184 loss_ctc 36.847317 loss_rnnt 14.700323 lr 0.00065385 rank 1
2022-12-04 00:08:36,504 DEBUG TRAIN Batch 7/100 loss 19.282772 loss_att 28.692341 loss_ctc 30.885595 loss_rnnt 15.853816 lr 0.00065407 rank 4
2022-12-04 00:08:36,506 DEBUG TRAIN Batch 7/100 loss 17.139381 loss_att 25.656155 loss_ctc 32.910671 loss_rnnt 13.333189 lr 0.00065348 rank 2
2022-12-04 00:08:36,537 DEBUG TRAIN Batch 7/100 loss 11.541664 loss_att 14.519096 loss_ctc 19.010811 loss_rnnt 9.950293 lr 0.00065403 rank 7
2022-12-04 00:09:47,511 DEBUG TRAIN Batch 7/200 loss 34.415997 loss_att 33.533382 loss_ctc 49.867851 loss_rnnt 32.532272 lr 0.00065359 rank 6
2022-12-04 00:09:47,513 DEBUG TRAIN Batch 7/200 loss 9.036784 loss_att 13.697230 loss_ctc 21.534346 loss_rnnt 6.438354 lr 0.00065329 rank 1
2022-12-04 00:09:47,514 DEBUG TRAIN Batch 7/200 loss 10.521102 loss_att 13.569486 loss_ctc 20.930222 loss_rnnt 8.523542 lr 0.00065347 rank 7
2022-12-04 00:09:47,514 DEBUG TRAIN Batch 7/200 loss 11.361550 loss_att 15.732531 loss_ctc 21.426605 loss_rnnt 9.145347 lr 0.00065317 rank 0
2022-12-04 00:09:47,515 DEBUG TRAIN Batch 7/200 loss 19.136013 loss_att 23.861919 loss_ctc 36.880993 loss_rnnt 15.824835 lr 0.00065292 rank 2
2022-12-04 00:09:47,516 DEBUG TRAIN Batch 7/200 loss 14.128757 loss_att 20.453398 loss_ctc 23.218147 loss_rnnt 11.651912 lr 0.00065348 rank 5
2022-12-04 00:09:47,516 DEBUG TRAIN Batch 7/200 loss 14.517830 loss_att 21.962263 loss_ctc 28.080976 loss_rnnt 11.220523 lr 0.00065329 rank 3
2022-12-04 00:09:47,522 DEBUG TRAIN Batch 7/200 loss 16.509916 loss_att 21.781155 loss_ctc 22.233961 loss_rnnt 14.692462 lr 0.00065351 rank 4
2022-12-04 00:10:59,257 DEBUG TRAIN Batch 7/300 loss 17.696680 loss_att 23.090073 loss_ctc 27.479328 loss_rnnt 15.313650 lr 0.00065296 rank 4
2022-12-04 00:10:59,266 DEBUG TRAIN Batch 7/300 loss 21.864029 loss_att 26.809734 loss_ctc 42.650688 loss_rnnt 18.103331 lr 0.00065303 rank 6
2022-12-04 00:10:59,267 DEBUG TRAIN Batch 7/300 loss 25.278141 loss_att 26.948864 loss_ctc 34.406597 loss_rnnt 23.726868 lr 0.00065273 rank 3
2022-12-04 00:10:59,268 DEBUG TRAIN Batch 7/300 loss 7.426615 loss_att 13.831874 loss_ctc 18.430977 loss_rnnt 4.678314 lr 0.00065292 rank 7
2022-12-04 00:10:59,267 DEBUG TRAIN Batch 7/300 loss 28.191380 loss_att 33.477486 loss_ctc 33.523468 loss_rnnt 26.423214 lr 0.00065273 rank 1
2022-12-04 00:10:59,273 DEBUG TRAIN Batch 7/300 loss 10.825150 loss_att 16.027020 loss_ctc 20.820522 loss_rnnt 8.452061 lr 0.00065262 rank 0
2022-12-04 00:10:59,293 DEBUG TRAIN Batch 7/300 loss 19.026972 loss_att 23.036564 loss_ctc 33.227047 loss_rnnt 16.331711 lr 0.00065237 rank 2
2022-12-04 00:10:59,311 DEBUG TRAIN Batch 7/300 loss 27.066753 loss_att 31.166279 loss_ctc 43.651855 loss_rnnt 24.035500 lr 0.00065292 rank 5
2022-12-04 00:12:12,345 DEBUG TRAIN Batch 7/400 loss 13.177198 loss_att 16.266148 loss_ctc 21.503643 loss_rnnt 11.449217 lr 0.00065237 rank 5
2022-12-04 00:12:12,349 DEBUG TRAIN Batch 7/400 loss 11.751646 loss_att 16.357548 loss_ctc 18.294819 loss_rnnt 9.958042 lr 0.00065247 rank 6
2022-12-04 00:12:12,348 DEBUG TRAIN Batch 7/400 loss 16.572693 loss_att 19.345270 loss_ctc 25.433264 loss_rnnt 14.836767 lr 0.00065218 rank 1
2022-12-04 00:12:12,349 DEBUG TRAIN Batch 7/400 loss 32.610115 loss_att 34.007515 loss_ctc 51.281013 loss_rnnt 29.841185 lr 0.00065206 rank 0
2022-12-04 00:12:12,352 DEBUG TRAIN Batch 7/400 loss 20.047382 loss_att 25.702560 loss_ctc 35.020248 loss_rnnt 16.919964 lr 0.00065217 rank 3
2022-12-04 00:12:12,353 DEBUG TRAIN Batch 7/400 loss 19.587992 loss_att 21.975201 loss_ctc 25.118382 loss_rnnt 18.373163 lr 0.00065236 rank 7
2022-12-04 00:12:12,359 DEBUG TRAIN Batch 7/400 loss 16.831680 loss_att 19.802876 loss_ctc 19.641197 loss_rnnt 15.862840 lr 0.00065181 rank 2
2022-12-04 00:12:12,360 DEBUG TRAIN Batch 7/400 loss 13.218745 loss_att 18.559959 loss_ctc 18.458000 loss_rnnt 11.451935 lr 0.00065240 rank 4
2022-12-04 00:13:24,192 DEBUG TRAIN Batch 7/500 loss 5.625376 loss_att 10.527534 loss_ctc 10.571445 loss_rnnt 3.985468 lr 0.00065192 rank 6
2022-12-04 00:13:24,194 DEBUG TRAIN Batch 7/500 loss 13.269302 loss_att 16.555840 loss_ctc 22.034584 loss_rnnt 11.443290 lr 0.00065151 rank 0
2022-12-04 00:13:24,197 DEBUG TRAIN Batch 7/500 loss 13.943789 loss_att 17.524988 loss_ctc 21.337118 loss_rnnt 12.241771 lr 0.00065181 rank 5
2022-12-04 00:13:24,197 DEBUG TRAIN Batch 7/500 loss 22.073015 loss_att 26.157400 loss_ctc 34.256836 loss_rnnt 19.631628 lr 0.00065126 rank 2
2022-12-04 00:13:24,199 DEBUG TRAIN Batch 7/500 loss 20.168692 loss_att 23.530888 loss_ctc 31.314941 loss_rnnt 18.010086 lr 0.00065181 rank 7
2022-12-04 00:13:24,202 DEBUG TRAIN Batch 7/500 loss 16.276669 loss_att 18.917801 loss_ctc 24.001001 loss_rnnt 14.718531 lr 0.00065162 rank 3
2022-12-04 00:13:24,208 DEBUG TRAIN Batch 7/500 loss 27.434698 loss_att 27.438328 loss_ctc 41.614239 loss_rnnt 25.543365 lr 0.00065185 rank 4
2022-12-04 00:13:24,246 DEBUG TRAIN Batch 7/500 loss 12.380237 loss_att 17.379620 loss_ctc 22.365858 loss_rnnt 10.048944 lr 0.00065162 rank 1
2022-12-04 00:14:37,198 DEBUG TRAIN Batch 7/600 loss 19.015560 loss_att 20.395931 loss_ctc 31.756645 loss_rnnt 17.040674 lr 0.00065096 rank 0
2022-12-04 00:14:37,200 DEBUG TRAIN Batch 7/600 loss 13.078514 loss_att 14.763160 loss_ctc 15.966102 loss_rnnt 12.356574 lr 0.00065107 rank 3
2022-12-04 00:14:37,200 DEBUG TRAIN Batch 7/600 loss 9.037515 loss_att 10.601285 loss_ctc 15.099756 loss_rnnt 7.916461 lr 0.00065107 rank 1
2022-12-04 00:14:37,201 DEBUG TRAIN Batch 7/600 loss 19.200766 loss_att 20.034086 loss_ctc 31.097876 loss_rnnt 17.447819 lr 0.00065071 rank 2
2022-12-04 00:14:37,205 DEBUG TRAIN Batch 7/600 loss 19.899374 loss_att 22.563904 loss_ctc 34.049942 loss_rnnt 17.479725 lr 0.00065126 rank 5
2022-12-04 00:14:37,205 DEBUG TRAIN Batch 7/600 loss 9.093592 loss_att 11.250759 loss_ctc 12.492719 loss_rnnt 8.208941 lr 0.00065136 rank 6
2022-12-04 00:14:37,209 DEBUG TRAIN Batch 7/600 loss 6.526732 loss_att 8.396752 loss_ctc 10.252900 loss_rnnt 5.655905 lr 0.00065129 rank 4
2022-12-04 00:14:37,253 DEBUG TRAIN Batch 7/600 loss 13.088661 loss_att 17.001902 loss_ctc 22.439997 loss_rnnt 11.059169 lr 0.00065125 rank 7
2022-12-04 00:15:51,210 DEBUG TRAIN Batch 7/700 loss 8.633535 loss_att 13.183084 loss_ctc 16.793579 loss_rnnt 6.635619 lr 0.00065040 rank 0
2022-12-04 00:15:51,219 DEBUG TRAIN Batch 7/700 loss 23.207821 loss_att 29.347788 loss_ctc 33.155750 loss_rnnt 20.653437 lr 0.00065051 rank 3
2022-12-04 00:15:51,219 DEBUG TRAIN Batch 7/700 loss 12.100332 loss_att 16.960487 loss_ctc 21.778570 loss_rnnt 9.837869 lr 0.00065071 rank 5
2022-12-04 00:15:51,222 DEBUG TRAIN Batch 7/700 loss 16.788282 loss_att 22.865128 loss_ctc 27.633823 loss_rnnt 14.126842 lr 0.00065052 rank 1
2022-12-04 00:15:51,239 DEBUG TRAIN Batch 7/700 loss 14.232605 loss_att 21.108871 loss_ctc 30.605968 loss_rnnt 10.674236 lr 0.00065074 rank 4
2022-12-04 00:15:51,248 DEBUG TRAIN Batch 7/700 loss 17.901474 loss_att 18.791565 loss_ctc 29.468536 loss_rnnt 16.181181 lr 0.00065070 rank 7
2022-12-04 00:15:51,253 DEBUG TRAIN Batch 7/700 loss 10.897307 loss_att 12.986789 loss_ctc 14.556627 loss_rnnt 9.991503 lr 0.00065081 rank 6
2022-12-04 00:15:51,257 DEBUG TRAIN Batch 7/700 loss 10.359315 loss_att 16.962143 loss_ctc 21.600164 loss_rnnt 7.539969 lr 0.00065016 rank 2
2022-12-04 00:17:03,098 DEBUG TRAIN Batch 7/800 loss 18.061518 loss_att 21.928165 loss_ctc 36.480263 loss_rnnt 14.832355 lr 0.00064986 rank 0
2022-12-04 00:17:03,099 DEBUG TRAIN Batch 7/800 loss 15.385400 loss_att 19.228510 loss_ctc 32.514206 loss_rnnt 12.332937 lr 0.00065016 rank 5
2022-12-04 00:17:03,106 DEBUG TRAIN Batch 7/800 loss 9.670980 loss_att 16.726543 loss_ctc 23.610357 loss_rnnt 6.401283 lr 0.00065026 rank 6
2022-12-04 00:17:03,105 DEBUG TRAIN Batch 7/800 loss 15.448339 loss_att 17.661669 loss_ctc 27.674414 loss_rnnt 13.375529 lr 0.00064997 rank 1
2022-12-04 00:17:03,105 DEBUG TRAIN Batch 7/800 loss 15.733678 loss_att 19.046082 loss_ctc 29.723499 loss_rnnt 13.205887 lr 0.00065015 rank 7
2022-12-04 00:17:03,106 DEBUG TRAIN Batch 7/800 loss 9.328253 loss_att 15.313023 loss_ctc 16.500874 loss_rnnt 7.174949 lr 0.00064996 rank 3
2022-12-04 00:17:03,113 DEBUG TRAIN Batch 7/800 loss 15.030060 loss_att 20.114464 loss_ctc 24.239735 loss_rnnt 12.785223 lr 0.00065019 rank 4
2022-12-04 00:17:03,155 DEBUG TRAIN Batch 7/800 loss 8.485992 loss_att 12.829280 loss_ctc 13.259181 loss_rnnt 6.980910 lr 0.00064961 rank 2
2022-12-04 00:18:14,650 DEBUG TRAIN Batch 7/900 loss 10.419760 loss_att 15.539422 loss_ctc 16.253365 loss_rnnt 8.618013 lr 0.00064971 rank 6
2022-12-04 00:18:14,654 DEBUG TRAIN Batch 7/900 loss 30.298332 loss_att 29.631596 loss_ctc 41.480145 loss_rnnt 28.940769 lr 0.00064942 rank 1
2022-12-04 00:18:14,654 DEBUG TRAIN Batch 7/900 loss 19.722569 loss_att 22.948565 loss_ctc 32.228645 loss_rnnt 17.409891 lr 0.00064931 rank 0
2022-12-04 00:18:14,655 DEBUG TRAIN Batch 7/900 loss 16.530869 loss_att 20.688404 loss_ctc 28.189383 loss_rnnt 14.144892 lr 0.00064961 rank 5
2022-12-04 00:18:14,658 DEBUG TRAIN Batch 7/900 loss 12.577508 loss_att 16.739241 loss_ctc 19.499134 loss_rnnt 10.822279 lr 0.00064964 rank 4
2022-12-04 00:18:14,658 DEBUG TRAIN Batch 7/900 loss 14.744123 loss_att 19.286787 loss_ctc 21.014097 loss_rnnt 12.999594 lr 0.00064942 rank 3
2022-12-04 00:18:14,663 DEBUG TRAIN Batch 7/900 loss 15.754434 loss_att 20.102005 loss_ctc 25.842487 loss_rnnt 13.539845 lr 0.00064906 rank 2
2022-12-04 00:18:14,662 DEBUG TRAIN Batch 7/900 loss 17.439106 loss_att 19.253353 loss_ctc 25.219315 loss_rnnt 16.038895 lr 0.00064960 rank 7
2022-12-04 00:19:26,483 DEBUG TRAIN Batch 7/1000 loss 21.547171 loss_att 27.550255 loss_ctc 39.095943 loss_rnnt 18.006718 lr 0.00064916 rank 6
2022-12-04 00:19:26,495 DEBUG TRAIN Batch 7/1000 loss 10.443830 loss_att 14.378649 loss_ctc 20.872169 loss_rnnt 8.266419 lr 0.00064887 rank 3
2022-12-04 00:19:26,496 DEBUG TRAIN Batch 7/1000 loss 18.934479 loss_att 23.473118 loss_ctc 33.217014 loss_rnnt 16.122414 lr 0.00064876 rank 0
2022-12-04 00:19:26,498 DEBUG TRAIN Batch 7/1000 loss 10.672617 loss_att 13.442526 loss_ctc 21.210041 loss_rnnt 8.713645 lr 0.00064887 rank 1
2022-12-04 00:19:26,508 DEBUG TRAIN Batch 7/1000 loss 15.128834 loss_att 19.651859 loss_ctc 23.856411 loss_rnnt 13.060552 lr 0.00064909 rank 4
2022-12-04 00:19:26,527 DEBUG TRAIN Batch 7/1000 loss 10.764611 loss_att 16.497778 loss_ctc 18.805458 loss_rnnt 8.545865 lr 0.00064851 rank 2
2022-12-04 00:19:26,536 DEBUG TRAIN Batch 7/1000 loss 9.218098 loss_att 14.460976 loss_ctc 17.315517 loss_rnnt 7.089867 lr 0.00064906 rank 7
2022-12-04 00:19:26,538 DEBUG TRAIN Batch 7/1000 loss 16.033930 loss_att 16.914413 loss_ctc 20.169285 loss_rnnt 15.306451 lr 0.00064906 rank 5
2022-12-04 00:20:40,499 DEBUG TRAIN Batch 7/1100 loss 15.095445 loss_att 20.507750 loss_ctc 26.964884 loss_rnnt 12.430391 lr 0.00064797 rank 2
2022-12-04 00:20:40,502 DEBUG TRAIN Batch 7/1100 loss 8.827504 loss_att 11.167572 loss_ctc 13.078630 loss_rnnt 7.792674 lr 0.00064833 rank 1
2022-12-04 00:20:40,501 DEBUG TRAIN Batch 7/1100 loss 19.751158 loss_att 25.461189 loss_ctc 33.191502 loss_rnnt 16.817106 lr 0.00064821 rank 0
2022-12-04 00:20:40,502 DEBUG TRAIN Batch 7/1100 loss 17.088753 loss_att 20.266804 loss_ctc 33.713799 loss_rnnt 14.236471 lr 0.00064851 rank 7
2022-12-04 00:20:40,503 DEBUG TRAIN Batch 7/1100 loss 18.289064 loss_att 22.972555 loss_ctc 28.872746 loss_rnnt 15.941208 lr 0.00064832 rank 3
2022-12-04 00:20:40,504 DEBUG TRAIN Batch 7/1100 loss 15.797597 loss_att 21.988302 loss_ctc 25.889935 loss_rnnt 13.213810 lr 0.00064862 rank 6
2022-12-04 00:20:40,504 DEBUG TRAIN Batch 7/1100 loss 33.911270 loss_att 37.848862 loss_ctc 55.448456 loss_rnnt 30.252125 lr 0.00064851 rank 5
2022-12-04 00:20:40,512 DEBUG TRAIN Batch 7/1100 loss 26.333914 loss_att 27.567823 loss_ctc 37.354633 loss_rnnt 24.617701 lr 0.00064855 rank 4
2022-12-04 00:21:52,132 DEBUG TRAIN Batch 7/1200 loss 24.233158 loss_att 29.196928 loss_ctc 42.712372 loss_rnnt 20.776510 lr 0.00064778 rank 3
2022-12-04 00:21:52,132 DEBUG TRAIN Batch 7/1200 loss 7.909347 loss_att 10.661775 loss_ctc 13.496748 loss_rnnt 6.613873 lr 0.00064797 rank 5
2022-12-04 00:21:52,133 DEBUG TRAIN Batch 7/1200 loss 13.414276 loss_att 14.730265 loss_ctc 19.533642 loss_rnnt 12.335162 lr 0.00064807 rank 6
2022-12-04 00:21:52,134 DEBUG TRAIN Batch 7/1200 loss 16.286129 loss_att 21.728075 loss_ctc 26.484934 loss_rnnt 13.837898 lr 0.00064743 rank 2
2022-12-04 00:21:52,134 DEBUG TRAIN Batch 7/1200 loss 19.174454 loss_att 21.794924 loss_ctc 27.483624 loss_rnnt 17.542469 lr 0.00064778 rank 1
2022-12-04 00:21:52,136 DEBUG TRAIN Batch 7/1200 loss 18.817402 loss_att 22.260214 loss_ctc 27.621607 loss_rnnt 16.954945 lr 0.00064767 rank 0
2022-12-04 00:21:52,138 DEBUG TRAIN Batch 7/1200 loss 22.436148 loss_att 21.678093 loss_ctc 28.043646 loss_rnnt 21.840090 lr 0.00064796 rank 7
2022-12-04 00:21:52,150 DEBUG TRAIN Batch 7/1200 loss 10.064608 loss_att 13.808825 loss_ctc 15.480545 loss_rnnt 8.593638 lr 0.00064800 rank 4
2022-12-04 00:23:04,485 DEBUG TRAIN Batch 7/1300 loss 20.519793 loss_att 26.428593 loss_ctc 34.216473 loss_rnnt 17.511808 lr 0.00064713 rank 0
2022-12-04 00:23:04,485 DEBUG TRAIN Batch 7/1300 loss 16.165129 loss_att 20.290174 loss_ctc 33.685562 loss_rnnt 13.004061 lr 0.00064724 rank 1
2022-12-04 00:23:04,486 DEBUG TRAIN Batch 7/1300 loss 28.692184 loss_att 28.751921 loss_ctc 40.174641 loss_rnnt 27.149244 lr 0.00064743 rank 5
2022-12-04 00:23:04,486 DEBUG TRAIN Batch 7/1300 loss 9.251720 loss_att 16.392963 loss_ctc 20.008360 loss_rnnt 6.389253 lr 0.00064753 rank 6
2022-12-04 00:23:04,486 DEBUG TRAIN Batch 7/1300 loss 10.003035 loss_att 9.559638 loss_ctc 13.605648 loss_rnnt 9.611365 lr 0.00064742 rank 7
2022-12-04 00:23:04,489 DEBUG TRAIN Batch 7/1300 loss 14.923136 loss_att 23.825468 loss_ctc 29.233440 loss_rnnt 11.234630 lr 0.00064724 rank 3
2022-12-04 00:23:04,491 DEBUG TRAIN Batch 7/1300 loss 16.601519 loss_att 19.758965 loss_ctc 27.427511 loss_rnnt 14.526564 lr 0.00064746 rank 4
2022-12-04 00:23:04,500 DEBUG TRAIN Batch 7/1300 loss 9.271893 loss_att 16.207720 loss_ctc 18.314009 loss_rnnt 6.679111 lr 0.00064688 rank 2
2022-12-04 00:24:18,285 DEBUG TRAIN Batch 7/1400 loss 21.053013 loss_att 23.844601 loss_ctc 28.776600 loss_rnnt 19.464882 lr 0.00064688 rank 5
2022-12-04 00:24:18,292 DEBUG TRAIN Batch 7/1400 loss 22.070400 loss_att 27.774475 loss_ctc 41.687740 loss_rnnt 18.313940 lr 0.00064692 rank 4
2022-12-04 00:24:18,292 DEBUG TRAIN Batch 7/1400 loss 5.953324 loss_att 8.807904 loss_ctc 11.900192 loss_rnnt 4.589492 lr 0.00064659 rank 0
2022-12-04 00:24:18,293 DEBUG TRAIN Batch 7/1400 loss 16.342644 loss_att 22.099392 loss_ctc 29.309338 loss_rnnt 13.462400 lr 0.00064670 rank 1
2022-12-04 00:24:18,296 DEBUG TRAIN Batch 7/1400 loss 12.986166 loss_att 18.758713 loss_ctc 22.793102 loss_rnnt 10.524064 lr 0.00064634 rank 2
2022-12-04 00:24:18,298 DEBUG TRAIN Batch 7/1400 loss 30.023556 loss_att 33.778210 loss_ctc 47.360870 loss_rnnt 26.960983 lr 0.00064688 rank 7
2022-12-04 00:24:18,300 DEBUG TRAIN Batch 7/1400 loss 15.828304 loss_att 21.855947 loss_ctc 28.661245 loss_rnnt 12.911716 lr 0.00064699 rank 6
2022-12-04 00:24:18,300 DEBUG TRAIN Batch 7/1400 loss 16.672279 loss_att 21.906963 loss_ctc 33.526363 loss_rnnt 13.378132 lr 0.00064669 rank 3
2022-12-04 00:25:31,241 DEBUG TRAIN Batch 7/1500 loss 18.551159 loss_att 22.583241 loss_ctc 28.712967 loss_rnnt 16.389835 lr 0.00064645 rank 6
2022-12-04 00:25:31,242 DEBUG TRAIN Batch 7/1500 loss 10.603650 loss_att 12.738131 loss_ctc 18.496572 loss_rnnt 9.124364 lr 0.00064605 rank 0
2022-12-04 00:25:31,242 DEBUG TRAIN Batch 7/1500 loss 22.965260 loss_att 28.180305 loss_ctc 45.791992 loss_rnnt 18.878687 lr 0.00064616 rank 1
2022-12-04 00:25:31,244 DEBUG TRAIN Batch 7/1500 loss 10.284710 loss_att 16.094231 loss_ctc 17.367176 loss_rnnt 8.178477 lr 0.00064634 rank 5
2022-12-04 00:25:31,243 DEBUG TRAIN Batch 7/1500 loss 10.277171 loss_att 14.217794 loss_ctc 21.507788 loss_rnnt 7.991631 lr 0.00064615 rank 3
2022-12-04 00:25:31,246 DEBUG TRAIN Batch 7/1500 loss 21.050396 loss_att 29.826981 loss_ctc 33.490795 loss_rnnt 17.636360 lr 0.00064580 rank 2
2022-12-04 00:25:31,249 DEBUG TRAIN Batch 7/1500 loss 19.361181 loss_att 23.227453 loss_ctc 30.848486 loss_rnnt 17.056288 lr 0.00064634 rank 7
2022-12-04 00:25:31,250 DEBUG TRAIN Batch 7/1500 loss 6.689060 loss_att 11.591435 loss_ctc 12.775878 loss_rnnt 4.897009 lr 0.00064638 rank 4
2022-12-04 00:26:42,931 DEBUG TRAIN Batch 7/1600 loss 11.222385 loss_att 16.896296 loss_ctc 19.813175 loss_rnnt 8.942164 lr 0.00064562 rank 1
2022-12-04 00:26:42,932 DEBUG TRAIN Batch 7/1600 loss 14.504875 loss_att 18.954178 loss_ctc 21.614218 loss_rnnt 12.667101 lr 0.00064591 rank 6
2022-12-04 00:26:42,933 DEBUG TRAIN Batch 7/1600 loss 12.839497 loss_att 16.209349 loss_ctc 27.316471 loss_rnnt 10.235263 lr 0.00064551 rank 0
2022-12-04 00:26:42,933 DEBUG TRAIN Batch 7/1600 loss 18.358500 loss_att 22.835407 loss_ctc 33.007557 loss_rnnt 15.509911 lr 0.00064580 rank 7
2022-12-04 00:26:42,936 DEBUG TRAIN Batch 7/1600 loss 23.414392 loss_att 24.773134 loss_ctc 35.358036 loss_rnnt 21.550158 lr 0.00064580 rank 5
2022-12-04 00:26:42,936 DEBUG TRAIN Batch 7/1600 loss 6.649566 loss_att 11.234509 loss_ctc 14.035744 loss_rnnt 4.747753 lr 0.00064562 rank 3
2022-12-04 00:26:42,939 DEBUG TRAIN Batch 7/1600 loss 18.474993 loss_att 24.219959 loss_ctc 25.742771 loss_rnnt 16.356962 lr 0.00064527 rank 2
2022-12-04 00:26:42,944 DEBUG TRAIN Batch 7/1600 loss 19.536564 loss_att 23.266783 loss_ctc 31.482237 loss_rnnt 17.197765 lr 0.00064584 rank 4
2022-12-04 00:27:54,806 DEBUG TRAIN Batch 7/1700 loss 23.420010 loss_att 28.291096 loss_ctc 39.905617 loss_rnnt 20.247709 lr 0.00064497 rank 0
2022-12-04 00:27:54,808 DEBUG TRAIN Batch 7/1700 loss 20.129902 loss_att 26.712465 loss_ctc 38.527683 loss_rnnt 16.360352 lr 0.00064473 rank 2
2022-12-04 00:27:54,811 DEBUG TRAIN Batch 7/1700 loss 18.388708 loss_att 21.443829 loss_ctc 28.114307 loss_rnnt 16.480936 lr 0.00064508 rank 1
2022-12-04 00:27:54,821 DEBUG TRAIN Batch 7/1700 loss 17.126904 loss_att 25.020840 loss_ctc 35.966682 loss_rnnt 13.036144 lr 0.00064537 rank 6
2022-12-04 00:27:54,826 DEBUG TRAIN Batch 7/1700 loss 14.623093 loss_att 16.468216 loss_ctc 19.573915 loss_rnnt 13.593957 lr 0.00064508 rank 3
2022-12-04 00:27:54,835 DEBUG TRAIN Batch 7/1700 loss 24.739540 loss_att 27.656771 loss_ctc 41.860195 loss_rnnt 21.873339 lr 0.00064530 rank 4
2022-12-04 00:27:54,839 DEBUG TRAIN Batch 7/1700 loss 8.510723 loss_att 14.739031 loss_ctc 14.636333 loss_rnnt 6.448314 lr 0.00064527 rank 5
2022-12-04 00:27:54,852 DEBUG TRAIN Batch 7/1700 loss 19.740088 loss_att 24.443640 loss_ctc 29.887905 loss_rnnt 17.446335 lr 0.00064526 rank 7
2022-12-04 00:29:08,599 DEBUG TRAIN Batch 7/1800 loss 18.830353 loss_att 20.985365 loss_ctc 27.233027 loss_rnnt 17.278994 lr 0.00064483 rank 6
2022-12-04 00:29:08,601 DEBUG TRAIN Batch 7/1800 loss 21.935116 loss_att 27.049324 loss_ctc 37.303905 loss_rnnt 18.863104 lr 0.00064455 rank 1
2022-12-04 00:29:08,605 DEBUG TRAIN Batch 7/1800 loss 18.037916 loss_att 20.937801 loss_ctc 35.521339 loss_rnnt 15.126815 lr 0.00064419 rank 2
2022-12-04 00:29:08,606 DEBUG TRAIN Batch 7/1800 loss 15.742721 loss_att 18.285362 loss_ctc 22.149099 loss_rnnt 14.380008 lr 0.00064443 rank 0
2022-12-04 00:29:08,607 DEBUG TRAIN Batch 7/1800 loss 7.198472 loss_att 11.972876 loss_ctc 9.833907 loss_rnnt 5.892200 lr 0.00064454 rank 3
2022-12-04 00:29:08,607 DEBUG TRAIN Batch 7/1800 loss 25.379330 loss_att 28.927275 loss_ctc 42.744579 loss_rnnt 22.354372 lr 0.00064473 rank 5
2022-12-04 00:29:08,608 DEBUG TRAIN Batch 7/1800 loss 17.136202 loss_att 20.273632 loss_ctc 26.532490 loss_rnnt 15.255877 lr 0.00064476 rank 4
2022-12-04 00:29:08,610 DEBUG TRAIN Batch 7/1800 loss 25.990429 loss_att 29.990891 loss_ctc 40.810383 loss_rnnt 23.214342 lr 0.00064472 rank 7
2022-12-04 00:30:20,348 DEBUG TRAIN Batch 7/1900 loss 11.095791 loss_att 15.441118 loss_ctc 18.463833 loss_rnnt 9.244320 lr 0.00064401 rank 1
2022-12-04 00:30:20,358 DEBUG TRAIN Batch 7/1900 loss 11.245419 loss_att 14.972861 loss_ctc 23.972790 loss_rnnt 8.802946 lr 0.00064390 rank 0
2022-12-04 00:30:20,360 DEBUG TRAIN Batch 7/1900 loss 19.000042 loss_att 20.856522 loss_ctc 27.868038 loss_rnnt 17.446346 lr 0.00064430 rank 6
2022-12-04 00:30:20,360 DEBUG TRAIN Batch 7/1900 loss 19.766474 loss_att 21.570648 loss_ctc 28.175674 loss_rnnt 18.284410 lr 0.00064419 rank 7
2022-12-04 00:30:20,360 DEBUG TRAIN Batch 7/1900 loss 11.225163 loss_att 12.395096 loss_ctc 17.342127 loss_rnnt 10.175580 lr 0.00064401 rank 3
2022-12-04 00:30:20,364 DEBUG TRAIN Batch 7/1900 loss 25.193029 loss_att 27.371918 loss_ctc 38.935760 loss_rnnt 22.924889 lr 0.00064419 rank 5
2022-12-04 00:30:20,364 DEBUG TRAIN Batch 7/1900 loss 10.139388 loss_att 11.452819 loss_ctc 15.892581 loss_rnnt 9.109609 lr 0.00064423 rank 4
2022-12-04 00:30:20,402 DEBUG TRAIN Batch 7/1900 loss 14.020750 loss_att 15.383823 loss_ctc 20.818502 loss_rnnt 12.841769 lr 0.00064366 rank 2
2022-12-04 00:31:31,862 DEBUG TRAIN Batch 7/2000 loss 10.397035 loss_att 14.622705 loss_ctc 17.115654 loss_rnnt 8.656085 lr 0.00064337 rank 0
2022-12-04 00:31:31,862 DEBUG TRAIN Batch 7/2000 loss 20.548681 loss_att 23.320011 loss_ctc 40.265232 loss_rnnt 17.365543 lr 0.00064376 rank 6
2022-12-04 00:31:31,869 DEBUG TRAIN Batch 7/2000 loss 10.496205 loss_att 12.720422 loss_ctc 17.504215 loss_rnnt 9.116961 lr 0.00064366 rank 5
2022-12-04 00:31:31,869 DEBUG TRAIN Batch 7/2000 loss 23.277246 loss_att 25.000216 loss_ctc 41.340996 loss_rnnt 20.524153 lr 0.00064348 rank 1
2022-12-04 00:31:31,870 DEBUG TRAIN Batch 7/2000 loss 15.126177 loss_att 20.814545 loss_ctc 25.902298 loss_rnnt 12.551687 lr 0.00064369 rank 4
2022-12-04 00:31:31,871 DEBUG TRAIN Batch 7/2000 loss 16.878851 loss_att 22.116114 loss_ctc 34.821613 loss_rnnt 13.439030 lr 0.00064347 rank 3
2022-12-04 00:31:31,873 DEBUG TRAIN Batch 7/2000 loss 6.441704 loss_att 13.182610 loss_ctc 10.169456 loss_rnnt 4.596489 lr 0.00064313 rank 2
2022-12-04 00:31:31,918 DEBUG TRAIN Batch 7/2000 loss 17.893173 loss_att 25.331337 loss_ctc 29.867208 loss_rnnt 14.809001 lr 0.00064365 rank 7
2022-12-04 00:32:44,704 DEBUG TRAIN Batch 7/2100 loss 17.441252 loss_att 19.095531 loss_ctc 22.779869 loss_rnnt 16.398581 lr 0.00064295 rank 1
2022-12-04 00:32:44,709 DEBUG TRAIN Batch 7/2100 loss 19.178783 loss_att 22.733013 loss_ctc 31.375153 loss_rnnt 16.841755 lr 0.00064313 rank 5
2022-12-04 00:32:44,713 DEBUG TRAIN Batch 7/2100 loss 15.685362 loss_att 20.990677 loss_ctc 23.657898 loss_rnnt 13.561294 lr 0.00064323 rank 6
2022-12-04 00:32:44,717 DEBUG TRAIN Batch 7/2100 loss 22.347696 loss_att 27.441460 loss_ctc 34.188828 loss_rnnt 19.750126 lr 0.00064283 rank 0
2022-12-04 00:32:44,717 DEBUG TRAIN Batch 7/2100 loss 11.663327 loss_att 17.604294 loss_ctc 19.712124 loss_rnnt 9.401961 lr 0.00064312 rank 7
2022-12-04 00:32:44,718 DEBUG TRAIN Batch 7/2100 loss 24.625519 loss_att 31.395611 loss_ctc 44.288357 loss_rnnt 20.649788 lr 0.00064294 rank 3
2022-12-04 00:32:44,728 DEBUG TRAIN Batch 7/2100 loss 7.567587 loss_att 12.020846 loss_ctc 18.557051 loss_rnnt 5.211673 lr 0.00064260 rank 2
2022-12-04 00:32:44,753 DEBUG TRAIN Batch 7/2100 loss 16.277426 loss_att 20.798386 loss_ctc 20.396545 loss_rnnt 14.824017 lr 0.00064316 rank 4
2022-12-04 00:33:57,781 DEBUG TRAIN Batch 7/2200 loss 14.641022 loss_att 20.249807 loss_ctc 23.144835 loss_rnnt 12.385422 lr 0.00064259 rank 7
2022-12-04 00:33:57,781 DEBUG TRAIN Batch 7/2200 loss 15.190582 loss_att 21.846754 loss_ctc 27.666653 loss_rnnt 12.195871 lr 0.00064241 rank 3
2022-12-04 00:33:57,782 DEBUG TRAIN Batch 7/2200 loss 7.824938 loss_att 13.600204 loss_ctc 15.904509 loss_rnnt 5.592609 lr 0.00064270 rank 6
2022-12-04 00:33:57,783 DEBUG TRAIN Batch 7/2200 loss 18.135887 loss_att 23.788187 loss_ctc 37.651581 loss_rnnt 14.403336 lr 0.00064260 rank 5
2022-12-04 00:33:57,790 DEBUG TRAIN Batch 7/2200 loss 11.383374 loss_att 15.648420 loss_ctc 24.457245 loss_rnnt 8.787182 lr 0.00064230 rank 0
2022-12-04 00:33:57,791 DEBUG TRAIN Batch 7/2200 loss 15.113321 loss_att 17.633696 loss_ctc 28.840319 loss_rnnt 12.778980 lr 0.00064207 rank 2
2022-12-04 00:33:57,794 DEBUG TRAIN Batch 7/2200 loss 16.177980 loss_att 19.281246 loss_ctc 27.014482 loss_rnnt 14.112459 lr 0.00064242 rank 1
2022-12-04 00:33:57,797 DEBUG TRAIN Batch 7/2200 loss 8.385002 loss_att 15.158119 loss_ctc 18.557907 loss_rnnt 5.673991 lr 0.00064263 rank 4
2022-12-04 00:35:10,128 DEBUG TRAIN Batch 7/2300 loss 22.335793 loss_att 28.048080 loss_ctc 40.163643 loss_rnnt 18.816288 lr 0.00064188 rank 3
2022-12-04 00:35:10,128 DEBUG TRAIN Batch 7/2300 loss 32.909698 loss_att 34.880413 loss_ctc 48.927734 loss_rnnt 30.379814 lr 0.00064217 rank 6
2022-12-04 00:35:10,130 DEBUG TRAIN Batch 7/2300 loss 6.615645 loss_att 10.181482 loss_ctc 14.351387 loss_rnnt 4.871045 lr 0.00064207 rank 5
2022-12-04 00:35:10,130 DEBUG TRAIN Batch 7/2300 loss 29.176886 loss_att 32.264084 loss_ctc 44.759216 loss_rnnt 26.481802 lr 0.00064178 rank 0
2022-12-04 00:35:10,131 DEBUG TRAIN Batch 7/2300 loss 14.812994 loss_att 19.471058 loss_ctc 26.803619 loss_rnnt 12.282631 lr 0.00064189 rank 1
2022-12-04 00:35:10,133 DEBUG TRAIN Batch 7/2300 loss 14.929319 loss_att 21.500647 loss_ctc 26.629059 loss_rnnt 12.055090 lr 0.00064206 rank 7
2022-12-04 00:35:10,134 DEBUG TRAIN Batch 7/2300 loss 25.666323 loss_att 29.221983 loss_ctc 36.624374 loss_rnnt 23.494118 lr 0.00064154 rank 2
2022-12-04 00:35:10,139 DEBUG TRAIN Batch 7/2300 loss 16.555708 loss_att 20.217289 loss_ctc 29.188828 loss_rnnt 14.138977 lr 0.00064210 rank 4
2022-12-04 00:36:21,160 DEBUG TRAIN Batch 7/2400 loss 21.482101 loss_att 25.879208 loss_ctc 30.111628 loss_rnnt 19.452078 lr 0.00064101 rank 2
2022-12-04 00:36:21,162 DEBUG TRAIN Batch 7/2400 loss 8.446603 loss_att 13.193119 loss_ctc 11.406231 loss_rnnt 7.102683 lr 0.00064135 rank 3
2022-12-04 00:36:21,166 DEBUG TRAIN Batch 7/2400 loss 12.441451 loss_att 15.995151 loss_ctc 21.754740 loss_rnnt 10.488939 lr 0.00064136 rank 1
2022-12-04 00:36:21,171 DEBUG TRAIN Batch 7/2400 loss 13.077861 loss_att 19.541212 loss_ctc 25.207462 loss_rnnt 10.167911 lr 0.00064164 rank 6
2022-12-04 00:36:21,171 DEBUG TRAIN Batch 7/2400 loss 29.118547 loss_att 31.417084 loss_ctc 49.871937 loss_rnnt 25.891722 lr 0.00064154 rank 5
2022-12-04 00:36:21,175 DEBUG TRAIN Batch 7/2400 loss 25.703783 loss_att 33.389469 loss_ctc 52.453152 loss_rnnt 20.600063 lr 0.00064153 rank 7
2022-12-04 00:36:21,179 DEBUG TRAIN Batch 7/2400 loss 14.327097 loss_att 17.269920 loss_ctc 28.284552 loss_rnnt 11.877539 lr 0.00064125 rank 0
2022-12-04 00:36:21,191 DEBUG TRAIN Batch 7/2400 loss 14.626932 loss_att 18.323189 loss_ctc 25.181440 loss_rnnt 12.480413 lr 0.00064157 rank 4
2022-12-04 00:37:36,667 DEBUG TRAIN Batch 7/2500 loss 14.158893 loss_att 16.185888 loss_ctc 21.513569 loss_rnnt 12.772871 lr 0.00064101 rank 5
2022-12-04 00:37:36,667 DEBUG TRAIN Batch 7/2500 loss 50.054028 loss_att 51.738350 loss_ctc 69.283211 loss_rnnt 47.153271 lr 0.00064111 rank 6
2022-12-04 00:37:36,669 DEBUG TRAIN Batch 7/2500 loss 10.259205 loss_att 11.954158 loss_ctc 16.065708 loss_rnnt 9.146014 lr 0.00064083 rank 1
2022-12-04 00:37:36,670 DEBUG TRAIN Batch 7/2500 loss 32.525116 loss_att 35.398926 loss_ctc 53.814415 loss_rnnt 29.111784 lr 0.00064083 rank 3
2022-12-04 00:37:36,674 DEBUG TRAIN Batch 7/2500 loss 17.298746 loss_att 17.201082 loss_ctc 21.249863 loss_rnnt 16.791464 lr 0.00064072 rank 0
2022-12-04 00:37:36,678 DEBUG TRAIN Batch 7/2500 loss 19.529091 loss_att 18.489290 loss_ctc 27.676910 loss_rnnt 18.650675 lr 0.00064104 rank 4
2022-12-04 00:37:36,680 DEBUG TRAIN Batch 7/2500 loss 12.261589 loss_att 13.977250 loss_ctc 18.643976 loss_rnnt 11.067472 lr 0.00064048 rank 2
2022-12-04 00:37:36,680 DEBUG TRAIN Batch 7/2500 loss 19.744593 loss_att 25.476513 loss_ctc 26.333149 loss_rnnt 17.719734 lr 0.00064100 rank 7
2022-12-04 00:38:48,752 DEBUG TRAIN Batch 7/2600 loss 12.895286 loss_att 17.084087 loss_ctc 29.032883 loss_rnnt 9.905846 lr 0.00064031 rank 1
2022-12-04 00:38:48,755 DEBUG TRAIN Batch 7/2600 loss 12.140908 loss_att 18.597622 loss_ctc 25.477652 loss_rnnt 9.071334 lr 0.00064058 rank 6
2022-12-04 00:38:48,755 DEBUG TRAIN Batch 7/2600 loss 16.696924 loss_att 20.151430 loss_ctc 34.487900 loss_rnnt 13.633892 lr 0.00064019 rank 0
2022-12-04 00:38:48,755 DEBUG TRAIN Batch 7/2600 loss 15.936363 loss_att 18.295374 loss_ctc 26.166958 loss_rnnt 14.100482 lr 0.00064048 rank 7
2022-12-04 00:38:48,755 DEBUG TRAIN Batch 7/2600 loss 34.327507 loss_att 40.671436 loss_ctc 50.047573 loss_rnnt 30.962711 lr 0.00063996 rank 2
2022-12-04 00:38:48,757 DEBUG TRAIN Batch 7/2600 loss 16.993828 loss_att 21.771259 loss_ctc 22.173241 loss_rnnt 15.347754 lr 0.00064048 rank 5
2022-12-04 00:38:48,756 DEBUG TRAIN Batch 7/2600 loss 13.235937 loss_att 17.990025 loss_ctc 21.244244 loss_rnnt 11.217346 lr 0.00064030 rank 3
2022-12-04 00:38:48,757 DEBUG TRAIN Batch 7/2600 loss 8.061934 loss_att 11.905517 loss_ctc 16.051083 loss_rnnt 6.227999 lr 0.00064052 rank 4
2022-12-04 00:40:01,325 DEBUG TRAIN Batch 7/2700 loss 25.186956 loss_att 26.283314 loss_ctc 41.702003 loss_rnnt 22.765678 lr 0.00064006 rank 6
2022-12-04 00:40:01,328 DEBUG TRAIN Batch 7/2700 loss 16.571321 loss_att 20.125679 loss_ctc 25.884380 loss_rnnt 14.618709 lr 0.00063978 rank 3
2022-12-04 00:40:01,332 DEBUG TRAIN Batch 7/2700 loss 11.709651 loss_att 18.018970 loss_ctc 29.275780 loss_rnnt 8.105637 lr 0.00063996 rank 5
2022-12-04 00:40:01,333 DEBUG TRAIN Batch 7/2700 loss 5.525609 loss_att 10.152288 loss_ctc 8.393286 loss_rnnt 4.217916 lr 0.00063967 rank 0
2022-12-04 00:40:01,333 DEBUG TRAIN Batch 7/2700 loss 28.384983 loss_att 28.636400 loss_ctc 46.613991 loss_rnnt 25.904163 lr 0.00063995 rank 7
2022-12-04 00:40:01,353 DEBUG TRAIN Batch 7/2700 loss 16.298458 loss_att 20.607862 loss_ctc 25.552862 loss_rnnt 14.202656 lr 0.00063978 rank 1
2022-12-04 00:40:01,357 DEBUG TRAIN Batch 7/2700 loss 12.815416 loss_att 17.765064 loss_ctc 26.272720 loss_rnnt 10.031179 lr 0.00063999 rank 4
2022-12-04 00:40:01,372 DEBUG TRAIN Batch 7/2700 loss 11.439510 loss_att 16.875837 loss_ctc 20.271378 loss_rnnt 9.174663 lr 0.00063944 rank 2
2022-12-04 00:41:14,773 DEBUG TRAIN Batch 7/2800 loss 16.601847 loss_att 19.935062 loss_ctc 25.696959 loss_rnnt 14.722521 lr 0.00063944 rank 5
2022-12-04 00:41:14,780 DEBUG TRAIN Batch 7/2800 loss 17.422375 loss_att 23.262909 loss_ctc 28.422516 loss_rnnt 14.787581 lr 0.00063953 rank 6
2022-12-04 00:41:14,781 DEBUG TRAIN Batch 7/2800 loss 28.800602 loss_att 37.032295 loss_ctc 51.859665 loss_rnnt 24.079721 lr 0.00063915 rank 0
2022-12-04 00:41:14,784 DEBUG TRAIN Batch 7/2800 loss 14.777939 loss_att 16.653872 loss_ctc 26.068859 loss_rnnt 12.897295 lr 0.00063925 rank 3
2022-12-04 00:41:14,785 DEBUG TRAIN Batch 7/2800 loss 24.727865 loss_att 28.191006 loss_ctc 37.517746 loss_rnnt 22.329922 lr 0.00063943 rank 7
2022-12-04 00:41:14,811 DEBUG TRAIN Batch 7/2800 loss 16.807949 loss_att 19.342503 loss_ctc 26.695221 loss_rnnt 14.982735 lr 0.00063947 rank 4
2022-12-04 00:41:14,814 DEBUG TRAIN Batch 7/2800 loss 11.999919 loss_att 15.697725 loss_ctc 21.314165 loss_rnnt 10.018458 lr 0.00063891 rank 2
2022-12-04 00:41:14,815 DEBUG TRAIN Batch 7/2800 loss 28.503204 loss_att 33.730640 loss_ctc 49.051662 loss_rnnt 24.717922 lr 0.00063926 rank 1
2022-12-04 00:42:27,773 DEBUG TRAIN Batch 7/2900 loss 8.928876 loss_att 11.540483 loss_ctc 16.884216 loss_rnnt 7.345842 lr 0.00063874 rank 1
2022-12-04 00:42:27,776 DEBUG TRAIN Batch 7/2900 loss 26.411278 loss_att 30.662804 loss_ctc 36.715794 loss_rnnt 24.187038 lr 0.00063901 rank 6
2022-12-04 00:42:27,777 DEBUG TRAIN Batch 7/2900 loss 17.935179 loss_att 25.959242 loss_ctc 30.503267 loss_rnnt 14.654619 lr 0.00063839 rank 2
2022-12-04 00:42:27,777 DEBUG TRAIN Batch 7/2900 loss 19.759676 loss_att 27.388474 loss_ctc 39.802517 loss_rnnt 15.561538 lr 0.00063863 rank 0
2022-12-04 00:42:27,777 DEBUG TRAIN Batch 7/2900 loss 15.879009 loss_att 20.431141 loss_ctc 26.345398 loss_rnnt 13.573065 lr 0.00063873 rank 3
2022-12-04 00:42:27,780 DEBUG TRAIN Batch 7/2900 loss 10.707493 loss_att 13.886347 loss_ctc 17.714317 loss_rnnt 9.137478 lr 0.00063891 rank 7
2022-12-04 00:42:27,786 DEBUG TRAIN Batch 7/2900 loss 17.319567 loss_att 23.093075 loss_ctc 29.660610 loss_rnnt 14.519394 lr 0.00063894 rank 4
2022-12-04 00:42:27,828 DEBUG TRAIN Batch 7/2900 loss 12.409857 loss_att 15.155947 loss_ctc 18.462915 loss_rnnt 11.053563 lr 0.00063891 rank 5
2022-12-04 00:43:40,376 DEBUG TRAIN Batch 7/3000 loss 19.264576 loss_att 19.990595 loss_ctc 29.431168 loss_rnnt 17.763828 lr 0.00063821 rank 3
2022-12-04 00:43:40,379 DEBUG TRAIN Batch 7/3000 loss 6.934690 loss_att 9.979661 loss_ctc 12.585390 loss_rnnt 5.572268 lr 0.00063839 rank 5
2022-12-04 00:43:40,380 DEBUG TRAIN Batch 7/3000 loss 19.217274 loss_att 23.553371 loss_ctc 32.264671 loss_rnnt 16.610401 lr 0.00063811 rank 0
2022-12-04 00:43:40,380 DEBUG TRAIN Batch 7/3000 loss 41.823402 loss_att 47.531788 loss_ctc 63.797428 loss_rnnt 37.751854 lr 0.00063839 rank 7
2022-12-04 00:43:40,382 DEBUG TRAIN Batch 7/3000 loss 7.532286 loss_att 10.748821 loss_ctc 12.873071 loss_rnnt 6.176874 lr 0.00063787 rank 2
2022-12-04 00:43:40,383 DEBUG TRAIN Batch 7/3000 loss 17.929583 loss_att 20.963142 loss_ctc 28.593126 loss_rnnt 15.901064 lr 0.00063822 rank 1
2022-12-04 00:43:40,384 DEBUG TRAIN Batch 7/3000 loss 18.039177 loss_att 22.384817 loss_ctc 28.773451 loss_rnnt 15.738811 lr 0.00063849 rank 6
2022-12-04 00:43:40,391 DEBUG TRAIN Batch 7/3000 loss 14.410925 loss_att 21.370165 loss_ctc 36.683044 loss_rnnt 10.049461 lr 0.00063842 rank 4
2022-12-04 00:44:52,260 DEBUG TRAIN Batch 7/3100 loss 17.381392 loss_att 19.647482 loss_ctc 25.755026 loss_rnnt 15.811690 lr 0.00063797 rank 6
2022-12-04 00:44:52,263 DEBUG TRAIN Batch 7/3100 loss 20.881542 loss_att 26.222044 loss_ctc 36.110538 loss_rnnt 17.782911 lr 0.00063769 rank 3
2022-12-04 00:44:52,265 DEBUG TRAIN Batch 7/3100 loss 13.158232 loss_att 14.639376 loss_ctc 23.356606 loss_rnnt 11.502219 lr 0.00063759 rank 0
2022-12-04 00:44:52,266 DEBUG TRAIN Batch 7/3100 loss 30.004513 loss_att 32.252121 loss_ctc 42.425030 loss_rnnt 27.898920 lr 0.00063787 rank 5
2022-12-04 00:44:52,268 DEBUG TRAIN Batch 7/3100 loss 17.691916 loss_att 17.853722 loss_ctc 25.716553 loss_rnnt 16.589603 lr 0.00063790 rank 4
2022-12-04 00:44:52,267 DEBUG TRAIN Batch 7/3100 loss 13.097412 loss_att 18.887289 loss_ctc 24.851521 loss_rnnt 10.372222 lr 0.00063787 rank 7
2022-12-04 00:44:52,297 DEBUG TRAIN Batch 7/3100 loss 9.555739 loss_att 11.367660 loss_ctc 17.138947 loss_rnnt 8.182261 lr 0.00063735 rank 2
2022-12-04 00:44:52,331 DEBUG TRAIN Batch 7/3100 loss 8.826745 loss_att 10.007676 loss_ctc 15.748181 loss_rnnt 7.667701 lr 0.00063770 rank 1
2022-12-04 00:46:06,698 DEBUG TRAIN Batch 7/3200 loss 20.240421 loss_att 28.128069 loss_ctc 42.439186 loss_rnnt 15.703056 lr 0.00063707 rank 0
2022-12-04 00:46:06,698 DEBUG TRAIN Batch 7/3200 loss 15.829689 loss_att 17.244362 loss_ctc 22.740934 loss_rnnt 14.625254 lr 0.00063735 rank 7
2022-12-04 00:46:06,701 DEBUG TRAIN Batch 7/3200 loss 13.914394 loss_att 20.989567 loss_ctc 21.088480 loss_rnnt 11.542815 lr 0.00063684 rank 2
2022-12-04 00:46:06,703 DEBUG TRAIN Batch 7/3200 loss 20.495605 loss_att 24.535736 loss_ctc 32.219753 loss_rnnt 18.124359 lr 0.00063717 rank 3
2022-12-04 00:46:06,726 DEBUG TRAIN Batch 7/3200 loss 7.278140 loss_att 12.646037 loss_ctc 20.090899 loss_rnnt 4.496192 lr 0.00063745 rank 6
2022-12-04 00:46:06,738 DEBUG TRAIN Batch 7/3200 loss 16.582790 loss_att 24.051590 loss_ctc 23.965725 loss_rnnt 14.104640 lr 0.00063718 rank 1
2022-12-04 00:46:06,764 DEBUG TRAIN Batch 7/3200 loss 15.309059 loss_att 16.912487 loss_ctc 25.116192 loss_rnnt 13.680756 lr 0.00063739 rank 4
2022-12-04 00:46:06,765 DEBUG TRAIN Batch 7/3200 loss 15.559574 loss_att 25.862507 loss_ctc 31.440346 loss_rnnt 11.381552 lr 0.00063735 rank 5
2022-12-04 00:47:19,026 DEBUG TRAIN Batch 7/3300 loss 26.784037 loss_att 31.093790 loss_ctc 47.661301 loss_rnnt 23.138451 lr 0.00063693 rank 6
2022-12-04 00:47:19,030 DEBUG TRAIN Batch 7/3300 loss 12.665704 loss_att 20.930937 loss_ctc 30.223461 loss_rnnt 8.671622 lr 0.00063655 rank 0
2022-12-04 00:47:19,031 DEBUG TRAIN Batch 7/3300 loss 14.249620 loss_att 21.627008 loss_ctc 27.916481 loss_rnnt 10.951895 lr 0.00063666 rank 1
2022-12-04 00:47:19,032 DEBUG TRAIN Batch 7/3300 loss 6.340264 loss_att 11.696394 loss_ctc 12.473959 loss_rnnt 4.451212 lr 0.00063666 rank 3
2022-12-04 00:47:19,033 DEBUG TRAIN Batch 7/3300 loss 8.966787 loss_att 14.464402 loss_ctc 19.938343 loss_rnnt 6.404389 lr 0.00063683 rank 7
2022-12-04 00:47:19,036 DEBUG TRAIN Batch 7/3300 loss 13.697164 loss_att 15.613957 loss_ctc 19.158607 loss_rnnt 12.585611 lr 0.00063632 rank 2
2022-12-04 00:47:19,047 DEBUG TRAIN Batch 7/3300 loss 20.087263 loss_att 23.001934 loss_ctc 40.551117 loss_rnnt 16.775814 lr 0.00063687 rank 4
2022-12-04 00:47:19,082 DEBUG TRAIN Batch 7/3300 loss 12.990061 loss_att 15.872111 loss_ctc 15.129234 loss_rnnt 12.128428 lr 0.00063684 rank 5
2022-12-04 00:48:31,209 DEBUG TRAIN Batch 7/3400 loss 12.547996 loss_att 16.950703 loss_ctc 19.735453 loss_rnnt 10.709127 lr 0.00063642 rank 6
2022-12-04 00:48:31,213 DEBUG TRAIN Batch 7/3400 loss 19.689178 loss_att 23.555195 loss_ctc 29.068808 loss_rnnt 17.665358 lr 0.00063632 rank 5
2022-12-04 00:48:31,214 DEBUG TRAIN Batch 7/3400 loss 12.976120 loss_att 17.285034 loss_ctc 24.880331 loss_rnnt 10.527109 lr 0.00063614 rank 3
2022-12-04 00:48:31,214 DEBUG TRAIN Batch 7/3400 loss 7.643115 loss_att 10.376803 loss_ctc 13.270868 loss_rnnt 6.346010 lr 0.00063581 rank 2
2022-12-04 00:48:31,215 DEBUG TRAIN Batch 7/3400 loss 14.277378 loss_att 19.253063 loss_ctc 17.177227 loss_rnnt 12.895595 lr 0.00063615 rank 1
2022-12-04 00:48:31,216 DEBUG TRAIN Batch 7/3400 loss 19.343502 loss_att 24.884157 loss_ctc 31.109463 loss_rnnt 16.666574 lr 0.00063604 rank 0
2022-12-04 00:48:31,222 DEBUG TRAIN Batch 7/3400 loss 16.364275 loss_att 19.539183 loss_ctc 25.108368 loss_rnnt 14.563415 lr 0.00063632 rank 7
2022-12-04 00:48:31,225 DEBUG TRAIN Batch 7/3400 loss 13.036828 loss_att 15.285624 loss_ctc 21.570618 loss_rnnt 11.449230 lr 0.00063635 rank 4
2022-12-04 00:49:43,223 DEBUG TRAIN Batch 7/3500 loss 14.962292 loss_att 20.421326 loss_ctc 23.862522 loss_rnnt 12.683786 lr 0.00063580 rank 7
2022-12-04 00:49:43,234 DEBUG TRAIN Batch 7/3500 loss 24.519493 loss_att 26.413361 loss_ctc 39.295834 loss_rnnt 22.170544 lr 0.00063563 rank 1
2022-12-04 00:49:43,235 DEBUG TRAIN Batch 7/3500 loss 14.895779 loss_att 20.119928 loss_ctc 22.772800 loss_rnnt 12.800679 lr 0.00063590 rank 6
2022-12-04 00:49:43,242 DEBUG TRAIN Batch 7/3500 loss 20.031298 loss_att 24.765652 loss_ctc 32.629536 loss_rnnt 17.404663 lr 0.00063581 rank 5
2022-12-04 00:49:43,248 DEBUG TRAIN Batch 7/3500 loss 37.900108 loss_att 43.366890 loss_ctc 68.890198 loss_rnnt 32.674740 lr 0.00063584 rank 4
2022-12-04 00:49:43,252 DEBUG TRAIN Batch 7/3500 loss 31.842447 loss_att 31.484369 loss_ctc 46.944260 loss_rnnt 29.900486 lr 0.00063563 rank 3
2022-12-04 00:49:43,256 DEBUG TRAIN Batch 7/3500 loss 10.135427 loss_att 16.436985 loss_ctc 22.174633 loss_rnnt 7.269887 lr 0.00063552 rank 0
2022-12-04 00:49:43,278 DEBUG TRAIN Batch 7/3500 loss 14.961901 loss_att 17.544500 loss_ctc 22.278349 loss_rnnt 13.469854 lr 0.00063529 rank 2
2022-12-04 00:50:55,817 DEBUG TRAIN Batch 7/3600 loss 9.028217 loss_att 11.617198 loss_ctc 13.592911 loss_rnnt 7.901795 lr 0.00063501 rank 0
2022-12-04 00:50:55,820 DEBUG TRAIN Batch 7/3600 loss 14.990464 loss_att 16.568573 loss_ctc 26.948980 loss_rnnt 13.080374 lr 0.00063539 rank 6
2022-12-04 00:50:55,823 DEBUG TRAIN Batch 7/3600 loss 18.111713 loss_att 23.517355 loss_ctc 30.186872 loss_rnnt 15.420564 lr 0.00063511 rank 3
2022-12-04 00:50:55,827 DEBUG TRAIN Batch 7/3600 loss 20.181240 loss_att 23.887537 loss_ctc 32.233494 loss_rnnt 17.833015 lr 0.00063512 rank 1
2022-12-04 00:50:55,830 DEBUG TRAIN Batch 7/3600 loss 21.370878 loss_att 24.857861 loss_ctc 30.928299 loss_rnnt 19.399158 lr 0.00063478 rank 2
2022-12-04 00:50:55,831 DEBUG TRAIN Batch 7/3600 loss 16.038851 loss_att 18.175169 loss_ctc 22.994251 loss_rnnt 14.684200 lr 0.00063529 rank 7
2022-12-04 00:50:55,831 DEBUG TRAIN Batch 7/3600 loss 18.126930 loss_att 21.468351 loss_ctc 36.048622 loss_rnnt 15.069086 lr 0.00063529 rank 5
2022-12-04 00:50:55,834 DEBUG TRAIN Batch 7/3600 loss 10.900772 loss_att 12.887331 loss_ctc 14.195371 loss_rnnt 10.064180 lr 0.00063532 rank 4
2022-12-04 00:52:07,181 DEBUG TRAIN Batch 7/3700 loss 9.366054 loss_att 11.682757 loss_ctc 16.604645 loss_rnnt 7.937567 lr 0.00063450 rank 0
2022-12-04 00:52:07,182 DEBUG TRAIN Batch 7/3700 loss 10.075874 loss_att 12.869932 loss_ctc 16.705017 loss_rnnt 8.633178 lr 0.00063488 rank 6
2022-12-04 00:52:07,185 DEBUG TRAIN Batch 7/3700 loss 14.160853 loss_att 19.808140 loss_ctc 26.340071 loss_rnnt 11.407500 lr 0.00063461 rank 1
2022-12-04 00:52:07,186 DEBUG TRAIN Batch 7/3700 loss 15.085503 loss_att 19.288754 loss_ctc 26.514589 loss_rnnt 12.720974 lr 0.00063478 rank 7
2022-12-04 00:52:07,186 DEBUG TRAIN Batch 7/3700 loss 19.190311 loss_att 20.607548 loss_ctc 25.480471 loss_rnnt 18.068174 lr 0.00063427 rank 2
2022-12-04 00:52:07,187 DEBUG TRAIN Batch 7/3700 loss 11.934596 loss_att 15.175741 loss_ctc 26.273458 loss_rnnt 9.374518 lr 0.00063460 rank 3
2022-12-04 00:52:07,191 DEBUG TRAIN Batch 7/3700 loss 20.694475 loss_att 24.029324 loss_ctc 35.681229 loss_rnnt 18.029270 lr 0.00063478 rank 5
2022-12-04 00:52:07,192 DEBUG TRAIN Batch 7/3700 loss 17.176285 loss_att 20.529467 loss_ctc 25.373325 loss_rnnt 15.412711 lr 0.00063481 rank 4
2022-12-04 00:53:19,365 DEBUG TRAIN Batch 7/3800 loss 12.406981 loss_att 12.791221 loss_ctc 15.072270 loss_rnnt 11.974761 lr 0.00063399 rank 0
2022-12-04 00:53:19,370 DEBUG TRAIN Batch 7/3800 loss 20.217178 loss_att 28.325073 loss_ctc 33.096699 loss_rnnt 16.878330 lr 0.00063376 rank 2
2022-12-04 00:53:19,372 DEBUG TRAIN Batch 7/3800 loss 14.010928 loss_att 14.300074 loss_ctc 19.984985 loss_rnnt 13.156558 lr 0.00063410 rank 1
2022-12-04 00:53:19,375 DEBUG TRAIN Batch 7/3800 loss 15.244916 loss_att 23.603262 loss_ctc 25.732948 loss_rnnt 12.174843 lr 0.00063437 rank 6
2022-12-04 00:53:19,376 DEBUG TRAIN Batch 7/3800 loss 18.336943 loss_att 26.349476 loss_ctc 29.938293 loss_rnnt 15.187589 lr 0.00063426 rank 7
2022-12-04 00:53:19,377 DEBUG TRAIN Batch 7/3800 loss 8.182120 loss_att 8.541622 loss_ctc 11.954457 loss_rnnt 7.607242 lr 0.00063409 rank 3
2022-12-04 00:53:19,380 DEBUG TRAIN Batch 7/3800 loss 11.088221 loss_att 11.365393 loss_ctc 19.861795 loss_rnnt 9.862976 lr 0.00063427 rank 5
2022-12-04 00:53:19,386 DEBUG TRAIN Batch 7/3800 loss 10.652946 loss_att 12.641363 loss_ctc 16.838850 loss_rnnt 9.430475 lr 0.00063430 rank 4
2022-12-04 00:54:32,291 DEBUG TRAIN Batch 7/3900 loss 15.636936 loss_att 19.847656 loss_ctc 26.800961 loss_rnnt 13.306257 lr 0.00063376 rank 5
2022-12-04 00:54:32,293 DEBUG TRAIN Batch 7/3900 loss 10.919827 loss_att 13.883184 loss_ctc 16.447079 loss_rnnt 9.590189 lr 0.00063386 rank 6
2022-12-04 00:54:32,297 DEBUG TRAIN Batch 7/3900 loss 10.991971 loss_att 15.534374 loss_ctc 15.228397 loss_rnnt 9.518633 lr 0.00063325 rank 2
2022-12-04 00:54:32,301 DEBUG TRAIN Batch 7/3900 loss 21.638067 loss_att 24.302937 loss_ctc 34.052376 loss_rnnt 19.449852 lr 0.00063375 rank 7
2022-12-04 00:54:32,301 DEBUG TRAIN Batch 7/3900 loss 9.808987 loss_att 14.269815 loss_ctc 16.747288 loss_rnnt 7.991714 lr 0.00063348 rank 0
2022-12-04 00:54:32,301 DEBUG TRAIN Batch 7/3900 loss 15.302613 loss_att 22.525818 loss_ctc 27.416891 loss_rnnt 12.242736 lr 0.00063358 rank 3
2022-12-04 00:54:32,304 DEBUG TRAIN Batch 7/3900 loss 15.522635 loss_att 18.087626 loss_ctc 22.228603 loss_rnnt 14.115508 lr 0.00063379 rank 4
2022-12-04 00:54:32,311 DEBUG TRAIN Batch 7/3900 loss 23.326580 loss_att 28.115519 loss_ctc 40.393414 loss_rnnt 20.093212 lr 0.00063359 rank 1
2022-12-04 00:55:44,568 DEBUG TRAIN Batch 7/4000 loss 11.646270 loss_att 15.202415 loss_ctc 17.766306 loss_rnnt 10.119036 lr 0.00063325 rank 5
2022-12-04 00:55:44,569 DEBUG TRAIN Batch 7/4000 loss 18.609573 loss_att 22.152924 loss_ctc 33.754887 loss_rnnt 15.881529 lr 0.00063297 rank 0
2022-12-04 00:55:44,570 DEBUG TRAIN Batch 7/4000 loss 11.597404 loss_att 19.993105 loss_ctc 18.134258 loss_rnnt 9.046684 lr 0.00063274 rank 2
2022-12-04 00:55:44,572 DEBUG TRAIN Batch 7/4000 loss 6.728916 loss_att 11.531534 loss_ctc 10.826842 loss_rnnt 5.222002 lr 0.00063335 rank 6
2022-12-04 00:55:44,573 DEBUG TRAIN Batch 7/4000 loss 21.495045 loss_att 24.479427 loss_ctc 33.934483 loss_rnnt 19.239576 lr 0.00063307 rank 3
2022-12-04 00:55:44,578 DEBUG TRAIN Batch 7/4000 loss 22.693659 loss_att 26.897102 loss_ctc 39.900490 loss_rnnt 19.558725 lr 0.00063325 rank 7
2022-12-04 00:55:44,587 DEBUG TRAIN Batch 7/4000 loss 9.253059 loss_att 14.026298 loss_ctc 18.135313 loss_rnnt 7.114112 lr 0.00063328 rank 4
2022-12-04 00:55:44,624 DEBUG TRAIN Batch 7/4000 loss 14.118923 loss_att 16.658173 loss_ctc 22.194921 loss_rnnt 12.534274 lr 0.00063308 rank 1
2022-12-04 00:56:56,829 DEBUG TRAIN Batch 7/4100 loss 12.503841 loss_att 18.094326 loss_ctc 22.012550 loss_rnnt 10.117916 lr 0.00063257 rank 1
2022-12-04 00:56:56,831 DEBUG TRAIN Batch 7/4100 loss 11.852398 loss_att 17.085361 loss_ctc 19.422220 loss_rnnt 9.796495 lr 0.00063274 rank 5
2022-12-04 00:56:56,831 DEBUG TRAIN Batch 7/4100 loss 13.038905 loss_att 19.132576 loss_ctc 24.246170 loss_rnnt 10.325870 lr 0.00063257 rank 3
2022-12-04 00:56:56,832 DEBUG TRAIN Batch 7/4100 loss 14.206244 loss_att 16.345448 loss_ctc 29.902479 loss_rnnt 11.685572 lr 0.00063274 rank 7
2022-12-04 00:56:56,833 DEBUG TRAIN Batch 7/4100 loss 22.088425 loss_att 27.145302 loss_ctc 37.883141 loss_rnnt 18.971085 lr 0.00063224 rank 2
2022-12-04 00:56:56,836 DEBUG TRAIN Batch 7/4100 loss 15.607197 loss_att 19.037107 loss_ctc 27.239206 loss_rnnt 13.370279 lr 0.00063247 rank 0
2022-12-04 00:56:56,838 DEBUG TRAIN Batch 7/4100 loss 22.291031 loss_att 26.316505 loss_ctc 33.423733 loss_rnnt 20.001575 lr 0.00063284 rank 6
2022-12-04 00:56:56,840 DEBUG TRAIN Batch 7/4100 loss 6.800264 loss_att 10.109693 loss_ctc 16.195024 loss_rnnt 4.885744 lr 0.00063277 rank 4
2022-12-04 00:58:08,681 DEBUG TRAIN Batch 7/4200 loss 15.717409 loss_att 20.177114 loss_ctc 24.351028 loss_rnnt 13.674318 lr 0.00063233 rank 6
2022-12-04 00:58:08,683 DEBUG TRAIN Batch 7/4200 loss 8.678450 loss_att 14.037542 loss_ctc 17.885658 loss_rnnt 6.379003 lr 0.00063206 rank 3
2022-12-04 00:58:08,683 DEBUG TRAIN Batch 7/4200 loss 22.733112 loss_att 26.705059 loss_ctc 35.469582 loss_rnnt 20.240524 lr 0.00063173 rank 2
2022-12-04 00:58:08,684 DEBUG TRAIN Batch 7/4200 loss 12.488069 loss_att 17.147552 loss_ctc 19.870407 loss_rnnt 10.571859 lr 0.00063196 rank 0
2022-12-04 00:58:08,687 DEBUG TRAIN Batch 7/4200 loss 17.702087 loss_att 22.632948 loss_ctc 26.288933 loss_rnnt 15.571004 lr 0.00063227 rank 4
2022-12-04 00:58:08,689 DEBUG TRAIN Batch 7/4200 loss 9.742909 loss_att 13.020890 loss_ctc 16.349585 loss_rnnt 8.206423 lr 0.00063207 rank 1
2022-12-04 00:58:08,689 DEBUG TRAIN Batch 7/4200 loss 19.782337 loss_att 23.585165 loss_ctc 32.311432 loss_rnnt 17.351225 lr 0.00063224 rank 5
2022-12-04 00:58:08,689 DEBUG TRAIN Batch 7/4200 loss 12.010738 loss_att 16.507927 loss_ctc 23.439608 loss_rnnt 9.587451 lr 0.00063223 rank 7
2022-12-04 00:59:22,441 DEBUG TRAIN Batch 7/4300 loss 21.683950 loss_att 22.924915 loss_ctc 38.552662 loss_rnnt 19.186596 lr 0.00063183 rank 6
2022-12-04 00:59:22,457 DEBUG TRAIN Batch 7/4300 loss 17.614330 loss_att 19.595385 loss_ctc 23.847610 loss_rnnt 16.387016 lr 0.00063146 rank 0
2022-12-04 00:59:22,458 DEBUG TRAIN Batch 7/4300 loss 10.014441 loss_att 12.674446 loss_ctc 17.686428 loss_rnnt 8.459509 lr 0.00063173 rank 5
2022-12-04 00:59:22,459 DEBUG TRAIN Batch 7/4300 loss 18.734085 loss_att 24.533625 loss_ctc 34.316021 loss_rnnt 15.496585 lr 0.00063156 rank 1
2022-12-04 00:59:22,461 DEBUG TRAIN Batch 7/4300 loss 12.045859 loss_att 16.483656 loss_ctc 20.781267 loss_rnnt 9.993579 lr 0.00063156 rank 3
2022-12-04 00:59:22,465 DEBUG TRAIN Batch 7/4300 loss 10.521552 loss_att 15.561184 loss_ctc 21.553448 loss_rnnt 8.042706 lr 0.00063173 rank 7
2022-12-04 00:59:22,470 DEBUG TRAIN Batch 7/4300 loss 13.707355 loss_att 17.672318 loss_ctc 25.811049 loss_rnnt 11.300537 lr 0.00063176 rank 4
2022-12-04 00:59:22,510 DEBUG TRAIN Batch 7/4300 loss 10.701038 loss_att 15.415514 loss_ctc 17.781696 loss_rnnt 8.814055 lr 0.00063123 rank 2
2022-12-04 01:00:34,509 DEBUG TRAIN Batch 7/4400 loss 18.674715 loss_att 19.470078 loss_ctc 21.752394 loss_rnnt 18.105286 lr 0.00063105 rank 3
2022-12-04 01:00:34,525 DEBUG TRAIN Batch 7/4400 loss 5.207607 loss_att 10.067845 loss_ctc 10.713161 loss_rnnt 3.501486 lr 0.00063133 rank 6
2022-12-04 01:00:34,529 DEBUG TRAIN Batch 7/4400 loss 10.853751 loss_att 12.044310 loss_ctc 18.922678 loss_rnnt 9.539783 lr 0.00063123 rank 5
2022-12-04 01:00:34,529 DEBUG TRAIN Batch 7/4400 loss 16.219152 loss_att 17.181452 loss_ctc 23.989117 loss_rnnt 14.990697 lr 0.00063095 rank 0
2022-12-04 01:00:34,532 DEBUG TRAIN Batch 7/4400 loss 18.255829 loss_att 20.625523 loss_ctc 27.098463 loss_rnnt 16.602871 lr 0.00063106 rank 1
2022-12-04 01:00:34,533 DEBUG TRAIN Batch 7/4400 loss 11.949097 loss_att 15.507502 loss_ctc 20.084875 loss_rnnt 10.152645 lr 0.00063126 rank 4
2022-12-04 01:00:34,534 DEBUG TRAIN Batch 7/4400 loss 13.467324 loss_att 20.240524 loss_ctc 24.942083 loss_rnnt 10.582717 lr 0.00063122 rank 7
2022-12-04 01:00:34,539 DEBUG TRAIN Batch 7/4400 loss 17.992476 loss_att 18.959051 loss_ctc 28.724173 loss_rnnt 16.368267 lr 0.00063073 rank 2
2022-12-04 01:01:46,433 DEBUG TRAIN Batch 7/4500 loss 10.141783 loss_att 15.621388 loss_ctc 14.372432 loss_rnnt 8.481775 lr 0.00063045 rank 0
2022-12-04 01:01:46,433 DEBUG TRAIN Batch 7/4500 loss 14.570079 loss_att 18.325232 loss_ctc 21.359846 loss_rnnt 12.913746 lr 0.00063056 rank 1
2022-12-04 01:01:46,434 DEBUG TRAIN Batch 7/4500 loss 10.727080 loss_att 15.400242 loss_ctc 20.479717 loss_rnnt 8.492096 lr 0.00063055 rank 3
2022-12-04 01:01:46,438 DEBUG TRAIN Batch 7/4500 loss 13.396191 loss_att 18.364357 loss_ctc 21.914822 loss_rnnt 11.266739 lr 0.00063023 rank 2
2022-12-04 01:01:46,438 DEBUG TRAIN Batch 7/4500 loss 18.056005 loss_att 22.982958 loss_ctc 33.913082 loss_rnnt 14.956340 lr 0.00063082 rank 6
2022-12-04 01:01:46,441 DEBUG TRAIN Batch 7/4500 loss 9.648893 loss_att 15.812105 loss_ctc 21.158627 loss_rnnt 6.881619 lr 0.00063073 rank 5
2022-12-04 01:01:46,446 DEBUG TRAIN Batch 7/4500 loss 11.654012 loss_att 10.897309 loss_ctc 15.530353 loss_rnnt 11.288507 lr 0.00063072 rank 7
2022-12-04 01:01:46,491 DEBUG TRAIN Batch 7/4500 loss 17.639338 loss_att 22.987661 loss_ctc 28.730993 loss_rnnt 15.090785 lr 0.00063076 rank 4
2022-12-04 01:02:59,862 DEBUG TRAIN Batch 7/4600 loss 25.849590 loss_att 28.909332 loss_ctc 52.289948 loss_rnnt 21.712263 lr 0.00063023 rank 5
2022-12-04 01:02:59,865 DEBUG TRAIN Batch 7/4600 loss 14.241547 loss_att 18.597719 loss_ctc 23.457310 loss_rnnt 12.141543 lr 0.00063005 rank 3
2022-12-04 01:02:59,865 DEBUG TRAIN Batch 7/4600 loss 19.228092 loss_att 28.233013 loss_ctc 41.901546 loss_rnnt 14.403979 lr 0.00063032 rank 6
2022-12-04 01:02:59,866 DEBUG TRAIN Batch 7/4600 loss 11.928287 loss_att 16.923262 loss_ctc 20.337309 loss_rnnt 9.808089 lr 0.00063006 rank 1
2022-12-04 01:02:59,868 DEBUG TRAIN Batch 7/4600 loss 33.118561 loss_att 39.719719 loss_ctc 45.542755 loss_rnnt 30.141769 lr 0.00062995 rank 0
2022-12-04 01:02:59,871 DEBUG TRAIN Batch 7/4600 loss 16.724771 loss_att 23.460148 loss_ctc 31.531616 loss_rnnt 13.403449 lr 0.00062973 rank 2
2022-12-04 01:02:59,892 DEBUG TRAIN Batch 7/4600 loss 25.079945 loss_att 35.716705 loss_ctc 43.275742 loss_rnnt 20.526485 lr 0.00063022 rank 7
2022-12-04 01:02:59,900 DEBUG TRAIN Batch 7/4600 loss 5.409683 loss_att 12.918395 loss_ctc 10.899505 loss_rnnt 3.175964 lr 0.00063026 rank 4
2022-12-04 01:04:12,924 DEBUG TRAIN Batch 7/4700 loss 14.404730 loss_att 17.995518 loss_ctc 18.489445 loss_rnnt 13.141944 lr 0.00062972 rank 7
2022-12-04 01:04:12,934 DEBUG TRAIN Batch 7/4700 loss 12.556614 loss_att 20.384924 loss_ctc 27.108234 loss_rnnt 9.050735 lr 0.00062956 rank 1
2022-12-04 01:04:12,940 DEBUG TRAIN Batch 7/4700 loss 4.527884 loss_att 6.393125 loss_ctc 6.354198 loss_rnnt 3.911327 lr 0.00062973 rank 5
2022-12-04 01:04:12,941 DEBUG TRAIN Batch 7/4700 loss 19.367521 loss_att 25.870523 loss_ctc 30.798702 loss_rnnt 16.542763 lr 0.00062982 rank 6
2022-12-04 01:04:12,943 DEBUG TRAIN Batch 7/4700 loss 27.320267 loss_att 31.673416 loss_ctc 43.428604 loss_rnnt 24.301857 lr 0.00062923 rank 2
2022-12-04 01:04:12,957 DEBUG TRAIN Batch 7/4700 loss 9.319706 loss_att 14.171493 loss_ctc 12.498222 loss_rnnt 7.925547 lr 0.00062945 rank 0
2022-12-04 01:04:12,958 DEBUG TRAIN Batch 7/4700 loss 7.307803 loss_att 9.085589 loss_ctc 13.126750 loss_rnnt 6.176386 lr 0.00062955 rank 3
2022-12-04 01:04:12,987 DEBUG TRAIN Batch 7/4700 loss 16.385668 loss_att 21.739429 loss_ctc 26.335400 loss_rnnt 13.988284 lr 0.00062976 rank 4
2022-12-04 01:05:24,143 DEBUG TRAIN Batch 7/4800 loss 15.088386 loss_att 19.910086 loss_ctc 27.345209 loss_rnnt 12.489802 lr 0.00062932 rank 6
2022-12-04 01:05:24,146 DEBUG TRAIN Batch 7/4800 loss 16.288754 loss_att 21.999695 loss_ctc 26.408604 loss_rnnt 13.797253 lr 0.00062922 rank 7
2022-12-04 01:05:24,148 DEBUG TRAIN Batch 7/4800 loss 21.765976 loss_att 20.536659 loss_ctc 28.315365 loss_rnnt 21.138586 lr 0.00062905 rank 3
2022-12-04 01:05:24,151 DEBUG TRAIN Batch 7/4800 loss 12.043339 loss_att 16.762930 loss_ctc 31.137377 loss_rnnt 8.553548 lr 0.00062906 rank 1
2022-12-04 01:05:24,153 DEBUG TRAIN Batch 7/4800 loss 10.750010 loss_att 17.979019 loss_ctc 16.441635 loss_rnnt 8.545324 lr 0.00062923 rank 5
2022-12-04 01:05:24,155 DEBUG TRAIN Batch 7/4800 loss 28.826042 loss_att 31.448784 loss_ctc 38.388279 loss_rnnt 27.026531 lr 0.00062895 rank 0
2022-12-04 01:05:24,156 DEBUG TRAIN Batch 7/4800 loss 16.650215 loss_att 23.400099 loss_ctc 27.172129 loss_rnnt 13.897316 lr 0.00062873 rank 2
2022-12-04 01:05:24,158 DEBUG TRAIN Batch 7/4800 loss 28.793430 loss_att 33.782810 loss_ctc 49.327789 loss_rnnt 25.057636 lr 0.00062926 rank 4
2022-12-04 01:06:35,778 DEBUG TRAIN Batch 7/4900 loss 27.362869 loss_att 33.243553 loss_ctc 46.351669 loss_rnnt 23.654890 lr 0.00062856 rank 1
2022-12-04 01:06:35,791 DEBUG TRAIN Batch 7/4900 loss 9.680525 loss_att 13.394857 loss_ctc 14.373026 loss_rnnt 8.311991 lr 0.00062846 rank 0
2022-12-04 01:06:35,792 DEBUG TRAIN Batch 7/4900 loss 14.087973 loss_att 17.565304 loss_ctc 18.638607 loss_rnnt 12.785754 lr 0.00062882 rank 6
2022-12-04 01:06:35,797 DEBUG TRAIN Batch 7/4900 loss 12.370918 loss_att 19.056158 loss_ctc 24.667490 loss_rnnt 9.394327 lr 0.00062856 rank 3
2022-12-04 01:06:35,802 DEBUG TRAIN Batch 7/4900 loss 15.942045 loss_att 19.513056 loss_ctc 26.755106 loss_rnnt 13.786102 lr 0.00062872 rank 7
2022-12-04 01:06:35,803 DEBUG TRAIN Batch 7/4900 loss 17.427252 loss_att 20.997637 loss_ctc 21.196201 loss_rnnt 16.210648 lr 0.00062876 rank 4
2022-12-04 01:06:35,803 DEBUG TRAIN Batch 7/4900 loss 23.191830 loss_att 24.722202 loss_ctc 34.798332 loss_rnnt 21.338223 lr 0.00062873 rank 5
2022-12-04 01:06:35,805 DEBUG TRAIN Batch 7/4900 loss 20.665998 loss_att 21.534565 loss_ctc 35.706703 loss_rnnt 18.486858 lr 0.00062823 rank 2
2022-12-04 01:07:49,681 DEBUG TRAIN Batch 7/5000 loss 10.257137 loss_att 11.470247 loss_ctc 15.106646 loss_rnnt 9.367914 lr 0.00062833 rank 6
2022-12-04 01:07:49,681 DEBUG TRAIN Batch 7/5000 loss 18.517637 loss_att 21.156996 loss_ctc 25.765753 loss_rnnt 17.023352 lr 0.00062796 rank 0
2022-12-04 01:07:49,683 DEBUG TRAIN Batch 7/5000 loss 16.205618 loss_att 21.940134 loss_ctc 25.009249 loss_rnnt 13.884898 lr 0.00062823 rank 7
2022-12-04 01:07:49,688 DEBUG TRAIN Batch 7/5000 loss 18.508795 loss_att 20.578739 loss_ctc 28.118191 loss_rnnt 16.813553 lr 0.00062806 rank 3
2022-12-04 01:07:49,689 DEBUG TRAIN Batch 7/5000 loss 13.433548 loss_att 17.073702 loss_ctc 27.828753 loss_rnnt 10.786157 lr 0.00062823 rank 5
2022-12-04 01:07:49,690 DEBUG TRAIN Batch 7/5000 loss 13.346478 loss_att 15.141270 loss_ctc 21.162527 loss_rnnt 11.945378 lr 0.00062806 rank 1
2022-12-04 01:07:49,692 DEBUG TRAIN Batch 7/5000 loss 24.298964 loss_att 26.613935 loss_ctc 32.922344 loss_rnnt 22.686186 lr 0.00062774 rank 2
2022-12-04 01:07:49,737 DEBUG TRAIN Batch 7/5000 loss 16.749701 loss_att 18.393297 loss_ctc 24.016066 loss_rnnt 15.452133 lr 0.00062826 rank 4
2022-12-04 01:08:59,680 DEBUG TRAIN Batch 7/5100 loss 25.389879 loss_att 30.626160 loss_ctc 41.843674 loss_rnnt 22.148785 lr 0.00062777 rank 4
2022-12-04 01:08:59,687 DEBUG TRAIN Batch 7/5100 loss 17.707626 loss_att 19.922226 loss_ctc 27.965914 loss_rnnt 15.896935 lr 0.00062756 rank 3
2022-12-04 01:08:59,690 DEBUG TRAIN Batch 7/5100 loss 18.089977 loss_att 20.015467 loss_ctc 28.119032 loss_rnnt 16.367674 lr 0.00062774 rank 5
2022-12-04 01:08:59,691 DEBUG TRAIN Batch 7/5100 loss 14.934595 loss_att 15.618997 loss_ctc 20.381170 loss_rnnt 14.071504 lr 0.00062773 rank 7
2022-12-04 01:08:59,692 DEBUG TRAIN Batch 7/5100 loss 20.896381 loss_att 23.954960 loss_ctc 36.622417 loss_rnnt 18.187860 lr 0.00062783 rank 6
2022-12-04 01:08:59,694 DEBUG TRAIN Batch 7/5100 loss 13.628216 loss_att 17.496260 loss_ctc 26.282553 loss_rnnt 11.167361 lr 0.00062757 rank 1
2022-12-04 01:08:59,697 DEBUG TRAIN Batch 7/5100 loss 20.758802 loss_att 25.356892 loss_ctc 33.777748 loss_rnnt 18.103325 lr 0.00062747 rank 0
2022-12-04 01:08:59,697 DEBUG TRAIN Batch 7/5100 loss 21.714895 loss_att 26.265245 loss_ctc 33.971016 loss_rnnt 19.170675 lr 0.00062724 rank 2
2022-12-04 01:10:09,509 DEBUG TRAIN Batch 7/5200 loss 12.186401 loss_att 19.021706 loss_ctc 21.572830 loss_rnnt 9.567817 lr 0.00062734 rank 6
2022-12-04 01:10:09,514 DEBUG TRAIN Batch 7/5200 loss 10.143326 loss_att 15.117237 loss_ctc 22.103344 loss_rnnt 7.553874 lr 0.00062724 rank 7
2022-12-04 01:10:09,515 DEBUG TRAIN Batch 7/5200 loss 30.099689 loss_att 33.644836 loss_ctc 52.309654 loss_rnnt 26.429333 lr 0.00062707 rank 3
2022-12-04 01:10:09,517 DEBUG TRAIN Batch 7/5200 loss 23.028736 loss_att 28.481903 loss_ctc 34.211590 loss_rnnt 20.447056 lr 0.00062697 rank 0
2022-12-04 01:10:09,520 DEBUG TRAIN Batch 7/5200 loss 6.192655 loss_att 11.279903 loss_ctc 9.444460 loss_rnnt 4.741631 lr 0.00062708 rank 1
2022-12-04 01:10:09,523 DEBUG TRAIN Batch 7/5200 loss 25.546152 loss_att 29.090664 loss_ctc 39.858597 loss_rnnt 22.928925 lr 0.00062724 rank 5
2022-12-04 01:10:09,527 DEBUG TRAIN Batch 7/5200 loss 20.709997 loss_att 25.274864 loss_ctc 34.755280 loss_rnnt 17.924320 lr 0.00062675 rank 2
2022-12-04 01:10:09,528 DEBUG TRAIN Batch 7/5200 loss 9.244787 loss_att 13.043215 loss_ctc 20.228174 loss_rnnt 7.020650 lr 0.00062727 rank 4
2022-12-04 01:11:21,348 DEBUG TRAIN Batch 7/5300 loss 7.940502 loss_att 11.558247 loss_ctc 13.504726 loss_rnnt 6.475057 lr 0.00062626 rank 2
2022-12-04 01:11:21,352 DEBUG TRAIN Batch 7/5300 loss 9.999679 loss_att 15.687283 loss_ctc 21.729559 loss_rnnt 7.298173 lr 0.00062658 rank 1
2022-12-04 01:11:21,361 DEBUG TRAIN Batch 7/5300 loss 16.420433 loss_att 19.079798 loss_ctc 21.828403 loss_rnnt 15.167499 lr 0.00062675 rank 7
2022-12-04 01:11:21,362 DEBUG TRAIN Batch 7/5300 loss 27.551617 loss_att 33.805679 loss_ctc 54.068909 loss_rnnt 22.765165 lr 0.00062648 rank 0
2022-12-04 01:11:21,362 DEBUG TRAIN Batch 7/5300 loss 13.351737 loss_att 17.373661 loss_ctc 24.102720 loss_rnnt 11.113887 lr 0.00062675 rank 5
2022-12-04 01:11:21,368 DEBUG TRAIN Batch 7/5300 loss 13.883928 loss_att 17.222643 loss_ctc 26.336815 loss_rnnt 11.555800 lr 0.00062658 rank 3
2022-12-04 01:11:21,368 DEBUG TRAIN Batch 7/5300 loss 24.448996 loss_att 28.091045 loss_ctc 36.855942 loss_rnnt 22.066326 lr 0.00062684 rank 6
2022-12-04 01:11:21,379 DEBUG TRAIN Batch 7/5300 loss 16.124809 loss_att 17.835833 loss_ctc 24.814137 loss_rnnt 14.624029 lr 0.00062678 rank 4
2022-12-04 01:12:32,338 DEBUG TRAIN Batch 7/5400 loss 12.688063 loss_att 16.808165 loss_ctc 23.166588 loss_rnnt 10.466905 lr 0.00062609 rank 1
2022-12-04 01:12:32,340 DEBUG TRAIN Batch 7/5400 loss 9.535857 loss_att 17.595951 loss_ctc 13.549192 loss_rnnt 7.388726 lr 0.00062626 rank 5
2022-12-04 01:12:32,344 DEBUG TRAIN Batch 7/5400 loss 14.447392 loss_att 17.394505 loss_ctc 22.485958 loss_rnnt 12.786161 lr 0.00062635 rank 6
2022-12-04 01:12:32,344 DEBUG TRAIN Batch 7/5400 loss 10.583632 loss_att 13.388337 loss_ctc 15.528046 loss_rnnt 9.363436 lr 0.00062599 rank 0
2022-12-04 01:12:32,344 DEBUG TRAIN Batch 7/5400 loss 13.074842 loss_att 21.938400 loss_ctc 24.420223 loss_rnnt 9.789413 lr 0.00062625 rank 7
2022-12-04 01:12:32,350 DEBUG TRAIN Batch 7/5400 loss 18.799561 loss_att 26.042555 loss_ctc 34.822838 loss_rnnt 15.214525 lr 0.00062609 rank 3
2022-12-04 01:12:32,356 DEBUG TRAIN Batch 7/5400 loss 30.332788 loss_att 34.689331 loss_ctc 43.947945 loss_rnnt 27.646126 lr 0.00062577 rank 2
2022-12-04 01:12:32,358 DEBUG TRAIN Batch 7/5400 loss 22.548569 loss_att 27.852962 loss_ctc 37.702110 loss_rnnt 19.467218 lr 0.00062629 rank 4
2022-12-04 01:13:42,030 DEBUG TRAIN Batch 7/5500 loss 22.546524 loss_att 24.884563 loss_ctc 36.108837 loss_rnnt 20.270607 lr 0.00062586 rank 6
2022-12-04 01:13:42,033 DEBUG TRAIN Batch 7/5500 loss 19.502243 loss_att 22.520126 loss_ctc 33.382057 loss_rnnt 17.048023 lr 0.00062550 rank 0
2022-12-04 01:13:42,037 DEBUG TRAIN Batch 7/5500 loss 20.840164 loss_att 21.612144 loss_ctc 32.933430 loss_rnnt 19.073334 lr 0.00062577 rank 5
2022-12-04 01:13:42,036 DEBUG TRAIN Batch 7/5500 loss 6.387360 loss_att 9.145508 loss_ctc 12.744319 loss_rnnt 4.988135 lr 0.00062560 rank 1
2022-12-04 01:13:42,037 DEBUG TRAIN Batch 7/5500 loss 14.129260 loss_att 19.662214 loss_ctc 26.022753 loss_rnnt 11.436871 lr 0.00062576 rank 7
2022-12-04 01:13:42,039 DEBUG TRAIN Batch 7/5500 loss 7.170794 loss_att 9.594449 loss_ctc 11.477337 loss_rnnt 6.111857 lr 0.00062528 rank 2
2022-12-04 01:13:42,040 DEBUG TRAIN Batch 7/5500 loss 12.692943 loss_att 16.381458 loss_ctc 20.013994 loss_rnnt 10.979097 lr 0.00062560 rank 3
2022-12-04 01:13:42,040 DEBUG TRAIN Batch 7/5500 loss 10.350355 loss_att 15.844818 loss_ctc 15.966189 loss_rnnt 8.502684 lr 0.00062580 rank 4
2022-12-04 01:14:52,883 DEBUG TRAIN Batch 7/5600 loss 19.664440 loss_att 23.033041 loss_ctc 38.883991 loss_rnnt 16.428112 lr 0.00062479 rank 2
2022-12-04 01:14:52,886 DEBUG TRAIN Batch 7/5600 loss 23.414658 loss_att 25.914801 loss_ctc 35.407478 loss_rnnt 21.315586 lr 0.00062531 rank 4
2022-12-04 01:14:52,889 DEBUG TRAIN Batch 7/5600 loss 9.149150 loss_att 11.387291 loss_ctc 12.752070 loss_rnnt 8.221132 lr 0.00062537 rank 6
2022-12-04 01:14:52,890 DEBUG TRAIN Batch 7/5600 loss 14.332521 loss_att 17.123219 loss_ctc 19.175167 loss_rnnt 13.128695 lr 0.00062527 rank 7
2022-12-04 01:14:52,892 DEBUG TRAIN Batch 7/5600 loss 22.686623 loss_att 26.522768 loss_ctc 38.879578 loss_rnnt 19.760334 lr 0.00062511 rank 3
2022-12-04 01:14:52,894 DEBUG TRAIN Batch 7/5600 loss 22.863930 loss_att 25.886627 loss_ctc 38.739754 loss_rnnt 20.142614 lr 0.00062511 rank 1
2022-12-04 01:14:52,895 DEBUG TRAIN Batch 7/5600 loss 18.799372 loss_att 21.142727 loss_ctc 26.267561 loss_rnnt 17.334940 lr 0.00062501 rank 0
2022-12-04 01:14:52,923 DEBUG TRAIN Batch 7/5600 loss 17.360489 loss_att 22.538334 loss_ctc 34.310593 loss_rnnt 14.064905 lr 0.00062528 rank 5
2022-12-04 01:16:06,531 DEBUG TRAIN Batch 7/5700 loss 15.028903 loss_att 14.685535 loss_ctc 19.059582 loss_rnnt 14.560153 lr 0.00062452 rank 0
2022-12-04 01:16:06,532 DEBUG TRAIN Batch 7/5700 loss 22.629623 loss_att 22.859776 loss_ctc 30.311592 loss_rnnt 21.559332 lr 0.00062462 rank 1
2022-12-04 01:16:06,534 DEBUG TRAIN Batch 7/5700 loss 17.982189 loss_att 18.202915 loss_ctc 30.324295 loss_rnnt 16.292429 lr 0.00062479 rank 5
2022-12-04 01:16:06,536 DEBUG TRAIN Batch 7/5700 loss 17.776342 loss_att 21.100922 loss_ctc 32.006641 loss_rnnt 15.214053 lr 0.00062462 rank 3
2022-12-04 01:16:06,536 DEBUG TRAIN Batch 7/5700 loss 14.538017 loss_att 16.401733 loss_ctc 21.615490 loss_rnnt 13.221611 lr 0.00062479 rank 7
2022-12-04 01:16:06,538 DEBUG TRAIN Batch 7/5700 loss 20.388002 loss_att 21.943850 loss_ctc 29.918783 loss_rnnt 18.806061 lr 0.00062430 rank 2
2022-12-04 01:16:06,540 DEBUG TRAIN Batch 7/5700 loss 9.418729 loss_att 11.934364 loss_ctc 14.787585 loss_rnnt 8.199755 lr 0.00062482 rank 4
2022-12-04 01:16:06,539 DEBUG TRAIN Batch 7/5700 loss 17.013306 loss_att 19.116734 loss_ctc 24.478470 loss_rnnt 15.597265 lr 0.00062488 rank 6
2022-12-04 01:17:15,999 DEBUG TRAIN Batch 7/5800 loss 27.380081 loss_att 31.195303 loss_ctc 44.505142 loss_rnnt 24.333694 lr 0.00062430 rank 7
2022-12-04 01:17:16,002 DEBUG TRAIN Batch 7/5800 loss 10.798897 loss_att 10.673335 loss_ctc 15.673767 loss_rnnt 10.174026 lr 0.00062413 rank 3
2022-12-04 01:17:16,002 DEBUG TRAIN Batch 7/5800 loss 18.923731 loss_att 20.808903 loss_ctc 31.681890 loss_rnnt 16.845608 lr 0.00062440 rank 6
2022-12-04 01:17:16,009 DEBUG TRAIN Batch 7/5800 loss 13.666813 loss_att 17.753361 loss_ctc 24.162907 loss_rnnt 11.450026 lr 0.00062430 rank 5
2022-12-04 01:17:16,010 DEBUG TRAIN Batch 7/5800 loss 17.329893 loss_att 21.040363 loss_ctc 24.010273 loss_rnnt 15.697082 lr 0.00062414 rank 1
2022-12-04 01:17:16,012 DEBUG TRAIN Batch 7/5800 loss 15.945012 loss_att 21.742834 loss_ctc 29.403250 loss_rnnt 12.991016 lr 0.00062404 rank 0
2022-12-04 01:17:16,014 DEBUG TRAIN Batch 7/5800 loss 11.467539 loss_att 15.589716 loss_ctc 18.928970 loss_rnnt 9.648245 lr 0.00062382 rank 2
2022-12-04 01:17:16,018 DEBUG TRAIN Batch 7/5800 loss 16.651554 loss_att 22.491661 loss_ctc 27.248762 loss_rnnt 14.070572 lr 0.00062433 rank 4
2022-12-04 01:18:25,232 DEBUG TRAIN Batch 7/5900 loss 16.576111 loss_att 19.865519 loss_ctc 24.944267 loss_rnnt 14.802474 lr 0.00062381 rank 7
2022-12-04 01:18:25,233 DEBUG TRAIN Batch 7/5900 loss 17.859093 loss_att 18.766703 loss_ctc 26.578867 loss_rnnt 16.514933 lr 0.00062391 rank 6
2022-12-04 01:18:25,236 DEBUG TRAIN Batch 7/5900 loss 26.337608 loss_att 30.847267 loss_ctc 42.162975 loss_rnnt 23.325628 lr 0.00062355 rank 0
2022-12-04 01:18:25,238 DEBUG TRAIN Batch 7/5900 loss 19.322987 loss_att 27.105675 loss_ctc 39.194820 loss_rnnt 15.116870 lr 0.00062365 rank 1
2022-12-04 01:18:25,239 DEBUG TRAIN Batch 7/5900 loss 13.607583 loss_att 18.718077 loss_ctc 25.948578 loss_rnnt 10.940018 lr 0.00062382 rank 5
2022-12-04 01:18:25,239 DEBUG TRAIN Batch 7/5900 loss 6.592772 loss_att 10.015588 loss_ctc 11.609427 loss_rnnt 5.239321 lr 0.00062333 rank 2
2022-12-04 01:18:25,240 DEBUG TRAIN Batch 7/5900 loss 10.489646 loss_att 14.005681 loss_ctc 18.519300 loss_rnnt 8.715818 lr 0.00062365 rank 3
2022-12-04 01:18:25,243 DEBUG TRAIN Batch 7/5900 loss 13.274916 loss_att 19.373272 loss_ctc 25.862202 loss_rnnt 10.376939 lr 0.00062385 rank 4
2022-12-04 01:19:37,250 DEBUG TRAIN Batch 7/6000 loss 18.739386 loss_att 25.860506 loss_ctc 35.630959 loss_rnnt 15.062951 lr 0.00062285 rank 2
2022-12-04 01:19:37,255 DEBUG TRAIN Batch 7/6000 loss 9.253696 loss_att 14.777192 loss_ctc 18.702080 loss_rnnt 6.889213 lr 0.00062333 rank 5
2022-12-04 01:19:37,262 DEBUG TRAIN Batch 7/6000 loss 11.942955 loss_att 18.462841 loss_ctc 19.643763 loss_rnnt 9.612204 lr 0.00062333 rank 7
2022-12-04 01:19:37,263 DEBUG TRAIN Batch 7/6000 loss 16.335695 loss_att 20.862167 loss_ctc 27.446819 loss_rnnt 13.948917 lr 0.00062316 rank 3
2022-12-04 01:19:37,264 DEBUG TRAIN Batch 7/6000 loss 17.271967 loss_att 23.875557 loss_ctc 25.871689 loss_rnnt 14.804619 lr 0.00062307 rank 0
2022-12-04 01:19:37,265 DEBUG TRAIN Batch 7/6000 loss 21.602201 loss_att 31.702507 loss_ctc 35.312206 loss_rnnt 17.754139 lr 0.00062342 rank 6
2022-12-04 01:19:37,279 DEBUG TRAIN Batch 7/6000 loss 23.927383 loss_att 25.449038 loss_ctc 40.165512 loss_rnnt 21.457966 lr 0.00062336 rank 4
2022-12-04 01:19:37,287 DEBUG TRAIN Batch 7/6000 loss 25.600557 loss_att 29.731136 loss_ctc 40.091679 loss_rnnt 22.842289 lr 0.00062317 rank 1
2022-12-04 01:20:48,701 DEBUG TRAIN Batch 7/6100 loss 10.500612 loss_att 14.895794 loss_ctc 16.631529 loss_rnnt 8.804120 lr 0.00062284 rank 7
2022-12-04 01:20:48,702 DEBUG TRAIN Batch 7/6100 loss 21.586693 loss_att 27.056675 loss_ctc 36.870686 loss_rnnt 18.454830 lr 0.00062258 rank 0
2022-12-04 01:20:48,705 DEBUG TRAIN Batch 7/6100 loss 18.158195 loss_att 21.595512 loss_ctc 29.648960 loss_rnnt 15.938629 lr 0.00062294 rank 6
2022-12-04 01:20:48,708 DEBUG TRAIN Batch 7/6100 loss 15.875643 loss_att 18.663603 loss_ctc 24.672667 loss_rnnt 14.145113 lr 0.00062285 rank 5
2022-12-04 01:20:48,708 DEBUG TRAIN Batch 7/6100 loss 10.595181 loss_att 14.660799 loss_ctc 21.507830 loss_rnnt 8.327037 lr 0.00062268 rank 3
2022-12-04 01:20:48,709 DEBUG TRAIN Batch 7/6100 loss 12.454840 loss_att 16.875578 loss_ctc 23.058659 loss_rnnt 10.156849 lr 0.00062268 rank 1
2022-12-04 01:20:48,714 DEBUG TRAIN Batch 7/6100 loss 15.750801 loss_att 20.594994 loss_ctc 23.535500 loss_rnnt 13.744003 lr 0.00062237 rank 2
2022-12-04 01:20:48,717 DEBUG TRAIN Batch 7/6100 loss 15.045124 loss_att 21.249563 loss_ctc 27.503571 loss_rnnt 12.143108 lr 0.00062288 rank 4
2022-12-04 01:21:59,425 DEBUG TRAIN Batch 7/6200 loss 16.276745 loss_att 17.856125 loss_ctc 21.230469 loss_rnnt 15.300371 lr 0.00062246 rank 6
2022-12-04 01:21:59,426 DEBUG TRAIN Batch 7/6200 loss 14.838446 loss_att 17.439600 loss_ctc 26.130259 loss_rnnt 12.812640 lr 0.00062236 rank 7
2022-12-04 01:21:59,431 DEBUG TRAIN Batch 7/6200 loss 26.325056 loss_att 29.290234 loss_ctc 39.539333 loss_rnnt 23.970116 lr 0.00062237 rank 5
2022-12-04 01:21:59,433 DEBUG TRAIN Batch 7/6200 loss 17.659529 loss_att 21.446461 loss_ctc 29.220518 loss_rnnt 15.360678 lr 0.00062210 rank 0
2022-12-04 01:21:59,435 DEBUG TRAIN Batch 7/6200 loss 8.954788 loss_att 11.821999 loss_ctc 13.779214 loss_rnnt 7.738089 lr 0.00062188 rank 2
2022-12-04 01:21:59,435 DEBUG TRAIN Batch 7/6200 loss 22.040066 loss_att 25.377106 loss_ctc 27.044548 loss_rnnt 20.705393 lr 0.00062220 rank 1
2022-12-04 01:21:59,436 DEBUG TRAIN Batch 7/6200 loss 21.625351 loss_att 27.398254 loss_ctc 36.077877 loss_rnnt 18.543766 lr 0.00062220 rank 3
2022-12-04 01:21:59,437 DEBUG TRAIN Batch 7/6200 loss 17.080076 loss_att 22.517883 loss_ctc 32.004234 loss_rnnt 14.002627 lr 0.00062239 rank 4
2022-12-04 01:23:11,038 DEBUG TRAIN Batch 7/6300 loss 20.889299 loss_att 21.463717 loss_ctc 33.486187 loss_rnnt 19.094831 lr 0.00062188 rank 5
2022-12-04 01:23:11,045 DEBUG TRAIN Batch 7/6300 loss 14.366018 loss_att 17.953495 loss_ctc 23.377964 loss_rnnt 12.446930 lr 0.00062198 rank 6
2022-12-04 01:23:11,046 DEBUG TRAIN Batch 7/6300 loss 9.577876 loss_att 14.653116 loss_ctc 18.706940 loss_rnnt 7.345619 lr 0.00062172 rank 1
2022-12-04 01:23:11,047 DEBUG TRAIN Batch 7/6300 loss 13.488252 loss_att 15.466745 loss_ctc 20.357107 loss_rnnt 12.176705 lr 0.00062162 rank 0
2022-12-04 01:23:11,048 DEBUG TRAIN Batch 7/6300 loss 12.720107 loss_att 16.210741 loss_ctc 23.207640 loss_rnnt 10.623643 lr 0.00062188 rank 7
2022-12-04 01:23:11,049 DEBUG TRAIN Batch 7/6300 loss 19.560709 loss_att 19.657076 loss_ctc 27.389265 loss_rnnt 18.497629 lr 0.00062172 rank 3
2022-12-04 01:23:11,053 DEBUG TRAIN Batch 7/6300 loss 14.569081 loss_att 16.710213 loss_ctc 23.427519 loss_rnnt 12.959730 lr 0.00062140 rank 2
2022-12-04 01:23:11,058 DEBUG TRAIN Batch 7/6300 loss 15.231226 loss_att 17.832312 loss_ctc 25.666958 loss_rnnt 13.319578 lr 0.00062191 rank 4
2022-12-04 01:24:23,867 DEBUG TRAIN Batch 7/6400 loss 13.410138 loss_att 19.233326 loss_ctc 21.810202 loss_rnnt 11.125490 lr 0.00062124 rank 1
2022-12-04 01:24:23,869 DEBUG TRAIN Batch 7/6400 loss 18.630665 loss_att 17.762405 loss_ctc 30.813198 loss_rnnt 17.179977 lr 0.00062149 rank 6
2022-12-04 01:24:23,872 DEBUG TRAIN Batch 7/6400 loss 19.229088 loss_att 23.382702 loss_ctc 24.514019 loss_rnnt 17.693707 lr 0.00062114 rank 0
2022-12-04 01:24:23,876 DEBUG TRAIN Batch 7/6400 loss 14.789265 loss_att 16.513714 loss_ctc 22.343489 loss_rnnt 13.437143 lr 0.00062124 rank 3
2022-12-04 01:24:23,888 DEBUG TRAIN Batch 7/6400 loss 16.087055 loss_att 20.705498 loss_ctc 36.622017 loss_rnnt 12.425371 lr 0.00062143 rank 4
2022-12-04 01:24:23,911 DEBUG TRAIN Batch 7/6400 loss 11.909586 loss_att 19.780142 loss_ctc 21.751537 loss_rnnt 9.023215 lr 0.00062140 rank 7
2022-12-04 01:24:23,933 DEBUG TRAIN Batch 7/6400 loss 11.818051 loss_att 16.848186 loss_ctc 23.148642 loss_rnnt 9.301279 lr 0.00062092 rank 2
2022-12-04 01:24:23,954 DEBUG TRAIN Batch 7/6400 loss 8.686127 loss_att 13.487920 loss_ctc 10.807129 loss_rnnt 7.442967 lr 0.00062140 rank 5
2022-12-04 01:25:35,024 DEBUG TRAIN Batch 7/6500 loss 25.657001 loss_att 32.632805 loss_ctc 47.109634 loss_rnnt 21.401489 lr 0.00062092 rank 5
2022-12-04 01:25:35,025 DEBUG TRAIN Batch 7/6500 loss 25.983044 loss_att 27.027807 loss_ctc 40.128399 loss_rnnt 23.888044 lr 0.00062076 rank 3
2022-12-04 01:25:35,029 DEBUG TRAIN Batch 7/6500 loss 9.617340 loss_att 15.395528 loss_ctc 19.359678 loss_rnnt 7.162724 lr 0.00062092 rank 7
2022-12-04 01:25:35,035 DEBUG TRAIN Batch 7/6500 loss 15.887678 loss_att 17.821293 loss_ctc 23.379662 loss_rnnt 14.502024 lr 0.00062102 rank 6
2022-12-04 01:25:35,035 DEBUG TRAIN Batch 7/6500 loss 17.707644 loss_att 21.205093 loss_ctc 29.599960 loss_rnnt 15.422511 lr 0.00062066 rank 0
2022-12-04 01:25:35,035 DEBUG TRAIN Batch 7/6500 loss 5.384168 loss_att 9.255222 loss_ctc 9.212406 loss_rnnt 4.099525 lr 0.00062095 rank 4
2022-12-04 01:25:35,035 DEBUG TRAIN Batch 7/6500 loss 16.900200 loss_att 18.812569 loss_ctc 30.707708 loss_rnnt 14.676723 lr 0.00062045 rank 2
2022-12-04 01:25:35,071 DEBUG TRAIN Batch 7/6500 loss 6.300845 loss_att 9.954848 loss_ctc 12.203995 loss_rnnt 4.782959 lr 0.00062076 rank 1
2022-12-04 01:26:46,798 DEBUG TRAIN Batch 7/6600 loss 17.062180 loss_att 23.265533 loss_ctc 27.890106 loss_rnnt 14.377784 lr 0.00062045 rank 5
2022-12-04 01:26:46,802 DEBUG TRAIN Batch 7/6600 loss 23.013731 loss_att 25.912653 loss_ctc 38.931473 loss_rnnt 20.311581 lr 0.00062054 rank 6
2022-12-04 01:26:46,802 DEBUG TRAIN Batch 7/6600 loss 21.241425 loss_att 18.359234 loss_ctc 32.341103 loss_rnnt 20.337906 lr 0.00062028 rank 3
2022-12-04 01:26:46,802 DEBUG TRAIN Batch 7/6600 loss 13.290694 loss_att 17.850941 loss_ctc 25.463087 loss_rnnt 10.755660 lr 0.00062018 rank 0
2022-12-04 01:26:46,803 DEBUG TRAIN Batch 7/6600 loss 7.789684 loss_att 11.783045 loss_ctc 11.972659 loss_rnnt 6.433282 lr 0.00061997 rank 2
2022-12-04 01:26:46,804 DEBUG TRAIN Batch 7/6600 loss 10.017433 loss_att 14.660124 loss_ctc 12.545940 loss_rnnt 8.751760 lr 0.00062044 rank 7
2022-12-04 01:26:46,811 DEBUG TRAIN Batch 7/6600 loss 9.264184 loss_att 12.990236 loss_ctc 19.664265 loss_rnnt 7.132297 lr 0.00062047 rank 4
2022-12-04 01:26:46,849 DEBUG TRAIN Batch 7/6600 loss 13.870373 loss_att 19.425903 loss_ctc 24.099815 loss_rnnt 11.395340 lr 0.00062028 rank 1
2022-12-04 01:27:59,315 DEBUG TRAIN Batch 7/6700 loss 22.809275 loss_att 26.408596 loss_ctc 31.714006 loss_rnnt 20.902113 lr 0.00061949 rank 2
2022-12-04 01:27:59,321 DEBUG TRAIN Batch 7/6700 loss 8.230434 loss_att 10.313362 loss_ctc 15.363146 loss_rnnt 6.862820 lr 0.00062006 rank 6
2022-12-04 01:27:59,324 DEBUG TRAIN Batch 7/6700 loss 9.183242 loss_att 15.657851 loss_ctc 20.947933 loss_rnnt 6.319695 lr 0.00061971 rank 0
2022-12-04 01:27:59,326 DEBUG TRAIN Batch 7/6700 loss 12.486459 loss_att 13.424594 loss_ctc 22.720879 loss_rnnt 10.934242 lr 0.00061981 rank 1
2022-12-04 01:27:59,327 DEBUG TRAIN Batch 7/6700 loss 17.191347 loss_att 22.621502 loss_ctc 27.736288 loss_rnnt 14.699324 lr 0.00061996 rank 7
2022-12-04 01:27:59,328 DEBUG TRAIN Batch 7/6700 loss 13.855060 loss_att 18.002979 loss_ctc 19.876659 loss_rnnt 12.222595 lr 0.00061997 rank 5
2022-12-04 01:27:59,344 DEBUG TRAIN Batch 7/6700 loss 11.995371 loss_att 18.324944 loss_ctc 25.087399 loss_rnnt 8.983852 lr 0.00061980 rank 3
2022-12-04 01:27:59,347 DEBUG TRAIN Batch 7/6700 loss 14.220008 loss_att 20.422710 loss_ctc 22.390055 loss_rnnt 11.890127 lr 0.00062000 rank 4
2022-12-04 01:29:12,443 DEBUG TRAIN Batch 7/6800 loss 19.975937 loss_att 21.717064 loss_ctc 31.273069 loss_rnnt 18.121428 lr 0.00061958 rank 6
2022-12-04 01:29:12,443 DEBUG TRAIN Batch 7/6800 loss 8.389502 loss_att 13.551141 loss_ctc 14.195869 loss_rnnt 6.582992 lr 0.00061933 rank 3
2022-12-04 01:29:12,444 DEBUG TRAIN Batch 7/6800 loss 13.763829 loss_att 22.727961 loss_ctc 27.056250 loss_rnnt 10.198681 lr 0.00061949 rank 7
2022-12-04 01:29:12,446 DEBUG TRAIN Batch 7/6800 loss 13.485613 loss_att 20.048138 loss_ctc 20.407097 loss_rnnt 11.250244 lr 0.00061902 rank 2
2022-12-04 01:29:12,449 DEBUG TRAIN Batch 7/6800 loss 23.925827 loss_att 30.530144 loss_ctc 36.285698 loss_rnnt 20.956982 lr 0.00061933 rank 1
2022-12-04 01:29:12,452 DEBUG TRAIN Batch 7/6800 loss 25.520824 loss_att 28.657097 loss_ctc 38.959496 loss_rnnt 23.101746 lr 0.00061923 rank 0
2022-12-04 01:29:12,456 DEBUG TRAIN Batch 7/6800 loss 12.485619 loss_att 18.464502 loss_ctc 22.768431 loss_rnnt 9.918800 lr 0.00061952 rank 4
2022-12-04 01:29:12,457 DEBUG TRAIN Batch 7/6800 loss 14.952497 loss_att 17.193134 loss_ctc 22.617952 loss_rnnt 13.482310 lr 0.00061949 rank 5
2022-12-04 01:30:24,400 DEBUG TRAIN Batch 7/6900 loss 19.706488 loss_att 23.315891 loss_ctc 36.047672 loss_rnnt 16.805784 lr 0.00061885 rank 3
2022-12-04 01:30:24,400 DEBUG TRAIN Batch 7/6900 loss 16.827213 loss_att 21.031734 loss_ctc 27.164503 loss_rnnt 14.608004 lr 0.00061901 rank 7
2022-12-04 01:30:24,401 DEBUG TRAIN Batch 7/6900 loss 21.444750 loss_att 24.439835 loss_ctc 31.651808 loss_rnnt 19.484793 lr 0.00061876 rank 0
2022-12-04 01:30:24,402 DEBUG TRAIN Batch 7/6900 loss 35.668892 loss_att 36.589218 loss_ctc 48.799496 loss_rnnt 33.734081 lr 0.00061854 rank 2
2022-12-04 01:30:24,402 DEBUG TRAIN Batch 7/6900 loss 15.697421 loss_att 19.610283 loss_ctc 28.282776 loss_rnnt 13.236801 lr 0.00061886 rank 1
2022-12-04 01:30:24,407 DEBUG TRAIN Batch 7/6900 loss 17.726923 loss_att 21.647543 loss_ctc 29.318844 loss_rnnt 15.397209 lr 0.00061902 rank 5
2022-12-04 01:30:24,406 DEBUG TRAIN Batch 7/6900 loss 7.224187 loss_att 14.753290 loss_ctc 14.918556 loss_rnnt 4.692451 lr 0.00061911 rank 6
2022-12-04 01:30:24,413 DEBUG TRAIN Batch 7/6900 loss 19.850136 loss_att 22.374195 loss_ctc 30.473343 loss_rnnt 17.928898 lr 0.00061905 rank 4
2022-12-04 01:31:36,912 DEBUG TRAIN Batch 7/7000 loss 9.356394 loss_att 14.848510 loss_ctc 19.042675 loss_rnnt 6.966466 lr 0.00061863 rank 6
2022-12-04 01:31:36,914 DEBUG TRAIN Batch 7/7000 loss 12.328407 loss_att 17.445869 loss_ctc 23.312765 loss_rnnt 9.840333 lr 0.00061828 rank 0
2022-12-04 01:31:36,917 DEBUG TRAIN Batch 7/7000 loss 13.441690 loss_att 14.769493 loss_ctc 21.056219 loss_rnnt 12.160858 lr 0.00061807 rank 2
2022-12-04 01:31:36,918 DEBUG TRAIN Batch 7/7000 loss 10.607332 loss_att 11.163690 loss_ctc 16.816746 loss_rnnt 9.668139 lr 0.00061838 rank 1
2022-12-04 01:31:36,921 DEBUG TRAIN Batch 7/7000 loss 8.283061 loss_att 10.543352 loss_ctc 13.032722 loss_rnnt 7.197714 lr 0.00061838 rank 3
2022-12-04 01:31:36,923 DEBUG TRAIN Batch 7/7000 loss 17.272476 loss_att 18.209990 loss_ctc 24.040911 loss_rnnt 16.182516 lr 0.00061857 rank 4
2022-12-04 01:31:36,926 DEBUG TRAIN Batch 7/7000 loss 6.517068 loss_att 11.462129 loss_ctc 18.452707 loss_rnnt 3.936637 lr 0.00061854 rank 7
2022-12-04 01:31:36,959 DEBUG TRAIN Batch 7/7000 loss 18.120674 loss_att 19.008312 loss_ctc 31.547756 loss_rnnt 16.152870 lr 0.00061854 rank 5
2022-12-04 01:32:50,766 DEBUG TRAIN Batch 7/7100 loss 12.561693 loss_att 17.066435 loss_ctc 16.316145 loss_rnnt 11.160151 lr 0.00061807 rank 7
2022-12-04 01:32:50,771 DEBUG TRAIN Batch 7/7100 loss 14.675923 loss_att 25.253525 loss_ctc 20.657106 loss_rnnt 11.762912 lr 0.00061807 rank 5
2022-12-04 01:32:50,777 DEBUG TRAIN Batch 7/7100 loss 9.897678 loss_att 13.960948 loss_ctc 20.919462 loss_rnnt 7.615453 lr 0.00061816 rank 6
2022-12-04 01:32:50,778 DEBUG TRAIN Batch 7/7100 loss 14.020069 loss_att 16.349827 loss_ctc 20.050631 loss_rnnt 12.750044 lr 0.00061810 rank 4
2022-12-04 01:32:50,780 DEBUG TRAIN Batch 7/7100 loss 15.016701 loss_att 18.807732 loss_ctc 26.553299 loss_rnnt 12.720283 lr 0.00061791 rank 1
2022-12-04 01:32:50,785 DEBUG TRAIN Batch 7/7100 loss 14.164466 loss_att 20.175976 loss_ctc 29.036251 loss_rnnt 10.979258 lr 0.00061781 rank 0
2022-12-04 01:32:50,786 DEBUG TRAIN Batch 7/7100 loss 19.064489 loss_att 21.111866 loss_ctc 25.032604 loss_rnnt 17.859264 lr 0.00061791 rank 3
2022-12-04 01:32:50,789 DEBUG TRAIN Batch 7/7100 loss 12.851162 loss_att 20.105881 loss_ctc 22.779943 loss_rnnt 10.076380 lr 0.00061760 rank 2
2022-12-04 01:34:02,807 DEBUG TRAIN Batch 7/7200 loss 14.566855 loss_att 21.503658 loss_ctc 21.938854 loss_rnnt 12.196562 lr 0.00061744 rank 1
2022-12-04 01:34:02,808 DEBUG TRAIN Batch 7/7200 loss 27.026745 loss_att 26.903145 loss_ctc 39.643780 loss_rnnt 25.369192 lr 0.00061734 rank 0
2022-12-04 01:34:02,812 DEBUG TRAIN Batch 7/7200 loss 21.245308 loss_att 27.408224 loss_ctc 34.878895 loss_rnnt 18.194912 lr 0.00061760 rank 5
2022-12-04 01:34:02,812 DEBUG TRAIN Batch 7/7200 loss 10.719510 loss_att 15.582096 loss_ctc 12.385357 loss_rnnt 9.524879 lr 0.00061713 rank 2
2022-12-04 01:34:02,814 DEBUG TRAIN Batch 7/7200 loss 19.754549 loss_att 24.821682 loss_ctc 34.924774 loss_rnnt 16.718426 lr 0.00061769 rank 6
2022-12-04 01:34:02,816 DEBUG TRAIN Batch 7/7200 loss 18.960871 loss_att 26.046335 loss_ctc 27.836889 loss_rnnt 16.360308 lr 0.00061743 rank 3
2022-12-04 01:34:02,818 DEBUG TRAIN Batch 7/7200 loss 17.489796 loss_att 17.232414 loss_ctc 26.505482 loss_rnnt 16.339180 lr 0.00061759 rank 7
2022-12-04 01:34:02,819 DEBUG TRAIN Batch 7/7200 loss 5.141565 loss_att 7.692370 loss_ctc 9.677226 loss_rnnt 4.026649 lr 0.00061763 rank 4
2022-12-04 01:35:14,885 DEBUG TRAIN Batch 7/7300 loss 17.746941 loss_att 26.266623 loss_ctc 31.117706 loss_rnnt 14.260237 lr 0.00061722 rank 6
2022-12-04 01:35:14,885 DEBUG TRAIN Batch 7/7300 loss 21.913193 loss_att 27.533871 loss_ctc 46.180351 loss_rnnt 17.553434 lr 0.00061687 rank 0
2022-12-04 01:35:14,889 DEBUG TRAIN Batch 7/7300 loss 10.555012 loss_att 14.863335 loss_ctc 19.076572 loss_rnnt 8.557137 lr 0.00061712 rank 7
2022-12-04 01:35:14,889 DEBUG TRAIN Batch 7/7300 loss 13.321679 loss_att 17.385635 loss_ctc 22.506195 loss_rnnt 11.284286 lr 0.00061696 rank 3
2022-12-04 01:35:14,893 DEBUG TRAIN Batch 7/7300 loss 21.059292 loss_att 24.361750 loss_ctc 38.049030 loss_rnnt 18.133501 lr 0.00061713 rank 5
2022-12-04 01:35:14,894 DEBUG TRAIN Batch 7/7300 loss 9.335918 loss_att 13.793304 loss_ctc 16.137039 loss_rnnt 7.537626 lr 0.00061666 rank 2
2022-12-04 01:35:14,896 DEBUG TRAIN Batch 7/7300 loss 26.521420 loss_att 30.894623 loss_ctc 44.768505 loss_rnnt 23.213835 lr 0.00061697 rank 1
2022-12-04 01:35:14,903 DEBUG TRAIN Batch 7/7300 loss 5.536524 loss_att 9.595276 loss_ctc 9.521132 loss_rnnt 4.193492 lr 0.00061716 rank 4
2022-12-04 01:36:27,227 DEBUG TRAIN Batch 7/7400 loss 25.184910 loss_att 27.332680 loss_ctc 35.742031 loss_rnnt 23.347740 lr 0.00061675 rank 6
2022-12-04 01:36:27,236 DEBUG TRAIN Batch 7/7400 loss 10.460854 loss_att 16.442047 loss_ctc 17.036999 loss_rnnt 8.387794 lr 0.00061619 rank 2
2022-12-04 01:36:27,240 DEBUG TRAIN Batch 7/7400 loss 17.441502 loss_att 22.054811 loss_ctc 23.571751 loss_rnnt 15.701471 lr 0.00061666 rank 5
2022-12-04 01:36:27,242 DEBUG TRAIN Batch 7/7400 loss 10.472595 loss_att 16.477600 loss_ctc 24.972855 loss_rnnt 7.338226 lr 0.00061650 rank 3
2022-12-04 01:36:27,243 DEBUG TRAIN Batch 7/7400 loss 13.359297 loss_att 15.695759 loss_ctc 23.960058 loss_rnnt 11.478570 lr 0.00061640 rank 0
2022-12-04 01:36:27,243 DEBUG TRAIN Batch 7/7400 loss 16.842720 loss_att 23.419313 loss_ctc 34.440304 loss_rnnt 13.181057 lr 0.00061650 rank 1
2022-12-04 01:36:27,245 DEBUG TRAIN Batch 7/7400 loss 29.299128 loss_att 31.466253 loss_ctc 48.371880 loss_rnnt 26.322666 lr 0.00061669 rank 4
2022-12-04 01:36:27,274 DEBUG TRAIN Batch 7/7400 loss 14.583605 loss_att 20.454020 loss_ctc 26.140268 loss_rnnt 11.868633 lr 0.00061665 rank 7
2022-12-04 01:37:40,900 DEBUG TRAIN Batch 7/7500 loss 12.180486 loss_att 12.964510 loss_ctc 18.538748 loss_rnnt 11.175912 lr 0.00061628 rank 6
2022-12-04 01:37:40,901 DEBUG TRAIN Batch 7/7500 loss 20.656681 loss_att 26.035152 loss_ctc 33.696465 loss_rnnt 17.842348 lr 0.00061593 rank 0
2022-12-04 01:37:40,902 DEBUG TRAIN Batch 7/7500 loss 28.843555 loss_att 36.847382 loss_ctc 49.096519 loss_rnnt 24.542395 lr 0.00061603 rank 1
2022-12-04 01:37:40,904 DEBUG TRAIN Batch 7/7500 loss 17.342712 loss_att 19.346077 loss_ctc 27.003494 loss_rnnt 15.653934 lr 0.00061603 rank 3
2022-12-04 01:37:40,904 DEBUG TRAIN Batch 7/7500 loss 23.333580 loss_att 26.169725 loss_ctc 36.288895 loss_rnnt 21.038977 lr 0.00061619 rank 7
2022-12-04 01:37:40,908 DEBUG TRAIN Batch 7/7500 loss 11.678530 loss_att 19.380373 loss_ctc 22.754173 loss_rnnt 8.661408 lr 0.00061572 rank 2
2022-12-04 01:37:40,908 DEBUG TRAIN Batch 7/7500 loss 15.136531 loss_att 16.785526 loss_ctc 23.246948 loss_rnnt 13.725343 lr 0.00061619 rank 5
2022-12-04 01:37:40,912 DEBUG TRAIN Batch 7/7500 loss 15.758128 loss_att 19.952950 loss_ctc 32.829330 loss_rnnt 12.643003 lr 0.00061622 rank 4
2022-12-04 01:38:53,499 DEBUG TRAIN Batch 7/7600 loss 16.350416 loss_att 20.446785 loss_ctc 26.046827 loss_rnnt 14.238288 lr 0.00061526 rank 2
2022-12-04 01:38:53,510 DEBUG TRAIN Batch 7/7600 loss 8.681884 loss_att 11.466099 loss_ctc 16.015089 loss_rnnt 7.147280 lr 0.00061547 rank 0
2022-12-04 01:38:53,512 DEBUG TRAIN Batch 7/7600 loss 17.479982 loss_att 21.388788 loss_ctc 27.495182 loss_rnnt 15.362861 lr 0.00061556 rank 3
2022-12-04 01:38:53,515 DEBUG TRAIN Batch 7/7600 loss 23.120464 loss_att 23.966515 loss_ctc 35.229275 loss_rnnt 21.336746 lr 0.00061581 rank 6
2022-12-04 01:38:53,515 DEBUG TRAIN Batch 7/7600 loss 12.027978 loss_att 15.563234 loss_ctc 19.432171 loss_rnnt 10.333701 lr 0.00061572 rank 5
2022-12-04 01:38:53,517 DEBUG TRAIN Batch 7/7600 loss 9.940803 loss_att 10.218931 loss_ctc 15.162690 loss_rnnt 9.188926 lr 0.00061556 rank 1
2022-12-04 01:38:53,519 DEBUG TRAIN Batch 7/7600 loss 22.487045 loss_att 22.176264 loss_ctc 34.194416 loss_rnnt 20.988220 lr 0.00061572 rank 7
2022-12-04 01:38:53,524 DEBUG TRAIN Batch 7/7600 loss 10.906432 loss_att 13.455696 loss_ctc 19.225945 loss_rnnt 9.287312 lr 0.00061575 rank 4
2022-12-04 01:40:05,711 DEBUG TRAIN Batch 7/7700 loss 12.925145 loss_att 18.229927 loss_ctc 20.638395 loss_rnnt 10.835754 lr 0.00061535 rank 6
2022-12-04 01:40:05,714 DEBUG TRAIN Batch 7/7700 loss 16.085945 loss_att 21.336655 loss_ctc 30.146961 loss_rnnt 13.161001 lr 0.00061510 rank 1
2022-12-04 01:40:05,714 DEBUG TRAIN Batch 7/7700 loss 13.275101 loss_att 17.179068 loss_ctc 23.997900 loss_rnnt 11.064600 lr 0.00061526 rank 5
2022-12-04 01:40:05,714 DEBUG TRAIN Batch 7/7700 loss 19.065063 loss_att 16.527390 loss_ctc 26.485479 loss_rnnt 18.583210 lr 0.00061479 rank 2
2022-12-04 01:40:05,716 DEBUG TRAIN Batch 7/7700 loss 13.315225 loss_att 14.627272 loss_ctc 21.531582 loss_rnnt 11.957301 lr 0.00061509 rank 3
2022-12-04 01:40:05,717 DEBUG TRAIN Batch 7/7700 loss 6.220968 loss_att 10.856293 loss_ctc 11.840914 loss_rnnt 4.544578 lr 0.00061525 rank 7
2022-12-04 01:40:05,719 DEBUG TRAIN Batch 7/7700 loss 22.706257 loss_att 27.699457 loss_ctc 34.300915 loss_rnnt 20.161663 lr 0.00061500 rank 0
2022-12-04 01:40:05,719 DEBUG TRAIN Batch 7/7700 loss 13.071845 loss_att 18.983746 loss_ctc 17.425995 loss_rnnt 11.308912 lr 0.00061529 rank 4
2022-12-04 01:41:18,762 DEBUG TRAIN Batch 7/7800 loss 18.146284 loss_att 21.218262 loss_ctc 33.687099 loss_rnnt 15.459781 lr 0.00061463 rank 1
2022-12-04 01:41:18,764 DEBUG TRAIN Batch 7/7800 loss 8.204725 loss_att 13.708892 loss_ctc 11.306701 loss_rnnt 6.690296 lr 0.00061433 rank 2
2022-12-04 01:41:18,766 DEBUG TRAIN Batch 7/7800 loss 15.604105 loss_att 18.187778 loss_ctc 22.758232 loss_rnnt 14.133487 lr 0.00061488 rank 6
2022-12-04 01:41:18,767 DEBUG TRAIN Batch 7/7800 loss 16.901840 loss_att 18.299215 loss_ctc 27.924454 loss_rnnt 15.152685 lr 0.00061482 rank 4
2022-12-04 01:41:18,773 DEBUG TRAIN Batch 7/7800 loss 15.901593 loss_att 18.340414 loss_ctc 34.897167 loss_rnnt 12.881086 lr 0.00061479 rank 7
2022-12-04 01:41:18,781 DEBUG TRAIN Batch 7/7800 loss 7.843005 loss_att 9.987165 loss_ctc 9.104012 loss_rnnt 7.246038 lr 0.00061479 rank 5
2022-12-04 01:41:18,781 DEBUG TRAIN Batch 7/7800 loss 23.383232 loss_att 27.336296 loss_ctc 42.204292 loss_rnnt 20.083145 lr 0.00061454 rank 0
2022-12-04 01:41:18,796 DEBUG TRAIN Batch 7/7800 loss 12.288239 loss_att 14.142676 loss_ctc 17.573643 loss_rnnt 11.212631 lr 0.00061463 rank 3
2022-12-04 01:42:31,573 DEBUG TRAIN Batch 7/7900 loss 7.369497 loss_att 9.813637 loss_ctc 10.588089 loss_rnnt 6.451524 lr 0.00061407 rank 0
2022-12-04 01:42:31,578 DEBUG TRAIN Batch 7/7900 loss 13.973155 loss_att 16.950714 loss_ctc 24.405067 loss_rnnt 11.986721 lr 0.00061442 rank 6
2022-12-04 01:42:31,580 DEBUG TRAIN Batch 7/7900 loss 19.331083 loss_att 30.760143 loss_ctc 33.649498 loss_rnnt 15.136149 lr 0.00061433 rank 5
2022-12-04 01:42:31,579 DEBUG TRAIN Batch 7/7900 loss 30.912018 loss_att 38.961617 loss_ctc 50.741959 loss_rnnt 26.658108 lr 0.00061386 rank 2
2022-12-04 01:42:31,579 DEBUG TRAIN Batch 7/7900 loss 19.195131 loss_att 22.525274 loss_ctc 22.745495 loss_rnnt 18.055721 lr 0.00061417 rank 3
2022-12-04 01:42:31,580 DEBUG TRAIN Batch 7/7900 loss 17.405252 loss_att 18.917589 loss_ctc 25.907585 loss_rnnt 15.969141 lr 0.00061417 rank 1
2022-12-04 01:42:31,584 DEBUG TRAIN Batch 7/7900 loss 20.285221 loss_att 22.514643 loss_ctc 35.328957 loss_rnnt 17.833504 lr 0.00061436 rank 4
2022-12-04 01:42:31,586 DEBUG TRAIN Batch 7/7900 loss 14.662159 loss_att 18.273033 loss_ctc 22.924999 loss_rnnt 12.838272 lr 0.00061432 rank 7
2022-12-04 01:43:42,956 DEBUG TRAIN Batch 7/8000 loss 18.739796 loss_att 24.857086 loss_ctc 37.126968 loss_rnnt 15.064714 lr 0.00061395 rank 6
2022-12-04 01:43:42,959 DEBUG TRAIN Batch 7/8000 loss 13.118177 loss_att 18.677799 loss_ctc 26.665142 loss_rnnt 10.199991 lr 0.00061386 rank 5
2022-12-04 01:43:42,961 DEBUG TRAIN Batch 7/8000 loss 14.607395 loss_att 19.396749 loss_ctc 27.432755 loss_rnnt 11.939476 lr 0.00061371 rank 1
2022-12-04 01:43:42,966 DEBUG TRAIN Batch 7/8000 loss 12.112674 loss_att 15.167586 loss_ctc 17.750706 loss_rnnt 10.749954 lr 0.00061370 rank 3
2022-12-04 01:43:42,966 DEBUG TRAIN Batch 7/8000 loss 12.247810 loss_att 14.427107 loss_ctc 18.133488 loss_rnnt 11.027193 lr 0.00061361 rank 0
2022-12-04 01:43:42,967 DEBUG TRAIN Batch 7/8000 loss 23.967512 loss_att 27.060938 loss_ctc 38.891872 loss_rnnt 21.358912 lr 0.00061386 rank 7
2022-12-04 01:43:42,968 DEBUG TRAIN Batch 7/8000 loss 12.174356 loss_att 16.455408 loss_ctc 20.416012 loss_rnnt 10.219259 lr 0.00061389 rank 4
2022-12-04 01:43:42,970 DEBUG TRAIN Batch 7/8000 loss 19.345873 loss_att 22.951637 loss_ctc 32.916328 loss_rnnt 16.815325 lr 0.00061340 rank 2
2022-12-04 01:44:54,440 DEBUG TRAIN Batch 7/8100 loss 9.620201 loss_att 12.651030 loss_ctc 14.639194 loss_rnnt 8.344835 lr 0.00061325 rank 1
2022-12-04 01:44:54,450 DEBUG TRAIN Batch 7/8100 loss 12.050993 loss_att 14.988050 loss_ctc 19.543655 loss_rnnt 10.464561 lr 0.00061349 rank 6
2022-12-04 01:44:54,456 DEBUG TRAIN Batch 7/8100 loss 22.864586 loss_att 29.195299 loss_ctc 35.215649 loss_rnnt 19.951635 lr 0.00061315 rank 0
2022-12-04 01:44:54,456 DEBUG TRAIN Batch 7/8100 loss 14.911366 loss_att 17.520573 loss_ctc 22.320396 loss_rnnt 13.401653 lr 0.00061294 rank 2
2022-12-04 01:44:54,458 DEBUG TRAIN Batch 7/8100 loss 21.057407 loss_att 24.962475 loss_ctc 33.009289 loss_rnnt 18.682810 lr 0.00061324 rank 3
2022-12-04 01:44:54,460 DEBUG TRAIN Batch 7/8100 loss 10.761938 loss_att 13.702128 loss_ctc 18.407625 loss_rnnt 9.154476 lr 0.00061343 rank 4
2022-12-04 01:44:54,461 DEBUG TRAIN Batch 7/8100 loss 13.278299 loss_att 17.118622 loss_ctc 22.794464 loss_rnnt 11.241413 lr 0.00061340 rank 7
2022-12-04 01:44:54,488 DEBUG TRAIN Batch 7/8100 loss 27.424160 loss_att 29.965466 loss_ctc 38.967499 loss_rnnt 25.376787 lr 0.00061340 rank 5
2022-12-04 01:46:06,759 DEBUG TRAIN Batch 7/8200 loss 20.052834 loss_att 23.697403 loss_ctc 31.973360 loss_rnnt 17.734514 lr 0.00061294 rank 5
2022-12-04 01:46:06,759 DEBUG TRAIN Batch 7/8200 loss 12.684485 loss_att 17.220146 loss_ctc 26.592316 loss_rnnt 9.922976 lr 0.00061278 rank 3
2022-12-04 01:46:06,759 DEBUG TRAIN Batch 7/8200 loss 14.900146 loss_att 16.856108 loss_ctc 23.864361 loss_rnnt 13.313726 lr 0.00061269 rank 0
2022-12-04 01:46:06,762 DEBUG TRAIN Batch 7/8200 loss 8.908147 loss_att 13.204103 loss_ctc 11.191151 loss_rnnt 7.744555 lr 0.00061278 rank 1
2022-12-04 01:46:06,762 DEBUG TRAIN Batch 7/8200 loss 7.993662 loss_att 11.333219 loss_ctc 12.380355 loss_rnnt 6.740858 lr 0.00061303 rank 6
2022-12-04 01:46:06,763 DEBUG TRAIN Batch 7/8200 loss 12.017139 loss_att 14.021957 loss_ctc 18.590855 loss_rnnt 10.739681 lr 0.00061248 rank 2
2022-12-04 01:46:06,768 DEBUG TRAIN Batch 7/8200 loss 12.072073 loss_att 12.206630 loss_ctc 19.932966 loss_rnnt 10.997042 lr 0.00061297 rank 4
2022-12-04 01:46:06,813 DEBUG TRAIN Batch 7/8200 loss 14.139252 loss_att 14.758059 loss_ctc 21.474327 loss_rnnt 13.037480 lr 0.00061294 rank 7
2022-12-04 01:47:18,101 DEBUG TRAIN Batch 7/8300 loss 15.054085 loss_att 24.884340 loss_ctc 28.518909 loss_rnnt 11.292724 lr 0.00061248 rank 7
2022-12-04 01:47:18,111 DEBUG TRAIN Batch 7/8300 loss 12.153473 loss_att 15.668240 loss_ctc 13.721949 loss_rnnt 11.241389 lr 0.00061257 rank 6
2022-12-04 01:47:18,112 DEBUG TRAIN Batch 7/8300 loss 20.446407 loss_att 26.642422 loss_ctc 34.267342 loss_rnnt 17.364414 lr 0.00061223 rank 0
2022-12-04 01:47:18,114 DEBUG TRAIN Batch 7/8300 loss 19.762177 loss_att 22.697912 loss_ctc 32.561520 loss_rnnt 17.468451 lr 0.00061232 rank 1
2022-12-04 01:47:18,116 DEBUG TRAIN Batch 7/8300 loss 19.807806 loss_att 22.122049 loss_ctc 23.946758 loss_rnnt 18.793097 lr 0.00061232 rank 3
2022-12-04 01:47:18,117 DEBUG TRAIN Batch 7/8300 loss 17.771099 loss_att 21.443371 loss_ctc 27.756237 loss_rnnt 15.705293 lr 0.00061202 rank 2
2022-12-04 01:47:18,118 DEBUG TRAIN Batch 7/8300 loss 17.871714 loss_att 22.603264 loss_ctc 34.431656 loss_rnnt 14.717409 lr 0.00061251 rank 4
2022-12-04 01:47:18,131 DEBUG TRAIN Batch 7/8300 loss 18.748098 loss_att 23.956871 loss_ctc 28.400616 loss_rnnt 16.419342 lr 0.00061248 rank 5
2022-12-04 01:48:09,976 DEBUG CV Batch 7/0 loss 2.397721 loss_att 2.391394 loss_ctc 4.230130 loss_rnnt 2.154665 history loss 2.308916 rank 4
2022-12-04 01:48:09,979 DEBUG CV Batch 7/0 loss 2.397721 loss_att 2.391394 loss_ctc 4.230130 loss_rnnt 2.154665 history loss 2.308916 rank 6
2022-12-04 01:48:09,980 DEBUG CV Batch 7/0 loss 2.397721 loss_att 2.391394 loss_ctc 4.230130 loss_rnnt 2.154665 history loss 2.308916 rank 3
2022-12-04 01:48:09,985 DEBUG CV Batch 7/0 loss 2.397721 loss_att 2.391394 loss_ctc 4.230130 loss_rnnt 2.154665 history loss 2.308916 rank 7
2022-12-04 01:48:09,986 DEBUG CV Batch 7/0 loss 2.397721 loss_att 2.391394 loss_ctc 4.230130 loss_rnnt 2.154665 history loss 2.308916 rank 1
2022-12-04 01:48:09,997 DEBUG CV Batch 7/0 loss 2.397721 loss_att 2.391394 loss_ctc 4.230130 loss_rnnt 2.154665 history loss 2.308916 rank 0
2022-12-04 01:48:10,007 DEBUG CV Batch 7/0 loss 2.397721 loss_att 2.391394 loss_ctc 4.230130 loss_rnnt 2.154665 history loss 2.308916 rank 5
2022-12-04 01:48:10,013 DEBUG CV Batch 7/0 loss 2.397721 loss_att 2.391394 loss_ctc 4.230130 loss_rnnt 2.154665 history loss 2.308916 rank 2
2022-12-04 01:48:21,290 DEBUG CV Batch 7/100 loss 11.241348 loss_att 10.960158 loss_ctc 18.564873 loss_rnnt 10.321115 history loss 4.754380 rank 6
2022-12-04 01:48:21,390 DEBUG CV Batch 7/100 loss 11.241348 loss_att 10.960158 loss_ctc 18.564873 loss_rnnt 10.321115 history loss 4.754380 rank 4
2022-12-04 01:48:21,415 DEBUG CV Batch 7/100 loss 11.241348 loss_att 10.960158 loss_ctc 18.564873 loss_rnnt 10.321115 history loss 4.754380 rank 1
2022-12-04 01:48:21,465 DEBUG CV Batch 7/100 loss 11.241348 loss_att 10.960158 loss_ctc 18.564873 loss_rnnt 10.321115 history loss 4.754380 rank 0
2022-12-04 01:48:21,471 DEBUG CV Batch 7/100 loss 11.241348 loss_att 10.960158 loss_ctc 18.564873 loss_rnnt 10.321115 history loss 4.754380 rank 7
2022-12-04 01:48:21,474 DEBUG CV Batch 7/100 loss 11.241348 loss_att 10.960158 loss_ctc 18.564873 loss_rnnt 10.321115 history loss 4.754380 rank 2
2022-12-04 01:48:21,480 DEBUG CV Batch 7/100 loss 11.241348 loss_att 10.960158 loss_ctc 18.564873 loss_rnnt 10.321115 history loss 4.754380 rank 3
2022-12-04 01:48:21,483 DEBUG CV Batch 7/100 loss 11.241348 loss_att 10.960158 loss_ctc 18.564873 loss_rnnt 10.321115 history loss 4.754380 rank 5
2022-12-04 01:48:34,794 DEBUG CV Batch 7/200 loss 13.717214 loss_att 16.339067 loss_ctc 19.049911 loss_rnnt 12.481816 history loss 5.370728 rank 6
2022-12-04 01:48:35,003 DEBUG CV Batch 7/200 loss 13.717214 loss_att 16.339067 loss_ctc 19.049911 loss_rnnt 12.481816 history loss 5.370728 rank 3
2022-12-04 01:48:35,029 DEBUG CV Batch 7/200 loss 13.717214 loss_att 16.339067 loss_ctc 19.049911 loss_rnnt 12.481816 history loss 5.370728 rank 0
2022-12-04 01:48:35,293 DEBUG CV Batch 7/200 loss 13.717214 loss_att 16.339067 loss_ctc 19.049911 loss_rnnt 12.481816 history loss 5.370728 rank 5
2022-12-04 01:48:35,436 DEBUG CV Batch 7/200 loss 13.717214 loss_att 16.339067 loss_ctc 19.049911 loss_rnnt 12.481816 history loss 5.370728 rank 2
2022-12-04 01:48:35,444 DEBUG CV Batch 7/200 loss 13.717214 loss_att 16.339067 loss_ctc 19.049911 loss_rnnt 12.481816 history loss 5.370728 rank 7
2022-12-04 01:48:35,611 DEBUG CV Batch 7/200 loss 13.717214 loss_att 16.339067 loss_ctc 19.049911 loss_rnnt 12.481816 history loss 5.370728 rank 4
2022-12-04 01:48:35,616 DEBUG CV Batch 7/200 loss 13.717214 loss_att 16.339067 loss_ctc 19.049911 loss_rnnt 12.481816 history loss 5.370728 rank 1
2022-12-04 01:48:46,905 DEBUG CV Batch 7/300 loss 5.365363 loss_att 7.094703 loss_ctc 10.986928 loss_rnnt 4.269954 history loss 5.528738 rank 6
2022-12-04 01:48:47,136 DEBUG CV Batch 7/300 loss 5.365363 loss_att 7.094703 loss_ctc 10.986928 loss_rnnt 4.269954 history loss 5.528738 rank 3
2022-12-04 01:48:47,277 DEBUG CV Batch 7/300 loss 5.365363 loss_att 7.094703 loss_ctc 10.986928 loss_rnnt 4.269954 history loss 5.528738 rank 0
2022-12-04 01:48:47,635 DEBUG CV Batch 7/300 loss 5.365363 loss_att 7.094703 loss_ctc 10.986928 loss_rnnt 4.269954 history loss 5.528738 rank 2
2022-12-04 01:48:47,719 DEBUG CV Batch 7/300 loss 5.365363 loss_att 7.094703 loss_ctc 10.986928 loss_rnnt 4.269954 history loss 5.528738 rank 1
2022-12-04 01:48:47,821 DEBUG CV Batch 7/300 loss 5.365363 loss_att 7.094703 loss_ctc 10.986928 loss_rnnt 4.269954 history loss 5.528738 rank 7
2022-12-04 01:48:47,823 DEBUG CV Batch 7/300 loss 5.365363 loss_att 7.094703 loss_ctc 10.986928 loss_rnnt 4.269954 history loss 5.528738 rank 4
2022-12-04 01:48:47,924 DEBUG CV Batch 7/300 loss 5.365363 loss_att 7.094703 loss_ctc 10.986928 loss_rnnt 4.269954 history loss 5.528738 rank 5
2022-12-04 01:48:59,070 DEBUG CV Batch 7/400 loss 21.658497 loss_att 128.755661 loss_ctc 9.346744 loss_rnnt 1.880630 history loss 6.497332 rank 6
2022-12-04 01:48:59,395 DEBUG CV Batch 7/400 loss 21.658497 loss_att 128.755661 loss_ctc 9.346744 loss_rnnt 1.880630 history loss 6.497332 rank 3
2022-12-04 01:48:59,628 DEBUG CV Batch 7/400 loss 21.658497 loss_att 128.755661 loss_ctc 9.346744 loss_rnnt 1.880630 history loss 6.497332 rank 0
2022-12-04 01:48:59,890 DEBUG CV Batch 7/400 loss 21.658497 loss_att 128.755661 loss_ctc 9.346744 loss_rnnt 1.880630 history loss 6.497332 rank 7
2022-12-04 01:48:59,925 DEBUG CV Batch 7/400 loss 21.658497 loss_att 128.755661 loss_ctc 9.346744 loss_rnnt 1.880630 history loss 6.497332 rank 4
2022-12-04 01:48:59,964 DEBUG CV Batch 7/400 loss 21.658497 loss_att 128.755661 loss_ctc 9.346744 loss_rnnt 1.880630 history loss 6.497332 rank 1
2022-12-04 01:48:59,965 DEBUG CV Batch 7/400 loss 21.658497 loss_att 128.755661 loss_ctc 9.346744 loss_rnnt 1.880630 history loss 6.497332 rank 2
2022-12-04 01:49:00,446 DEBUG CV Batch 7/400 loss 21.658497 loss_att 128.755661 loss_ctc 9.346744 loss_rnnt 1.880630 history loss 6.497332 rank 5
2022-12-04 01:49:09,582 DEBUG CV Batch 7/500 loss 8.775473 loss_att 8.821266 loss_ctc 11.694608 loss_rnnt 8.377095 history loss 7.290536 rank 6
2022-12-04 01:49:09,997 DEBUG CV Batch 7/500 loss 8.775473 loss_att 8.821266 loss_ctc 11.694608 loss_rnnt 8.377095 history loss 7.290536 rank 3
2022-12-04 01:49:10,257 DEBUG CV Batch 7/500 loss 8.775473 loss_att 8.821266 loss_ctc 11.694608 loss_rnnt 8.377095 history loss 7.290536 rank 0
2022-12-04 01:49:10,355 DEBUG CV Batch 7/500 loss 8.775473 loss_att 8.821266 loss_ctc 11.694608 loss_rnnt 8.377095 history loss 7.290536 rank 1
2022-12-04 01:49:10,495 DEBUG CV Batch 7/500 loss 8.775473 loss_att 8.821266 loss_ctc 11.694608 loss_rnnt 8.377095 history loss 7.290536 rank 7
2022-12-04 01:49:10,561 DEBUG CV Batch 7/500 loss 8.775473 loss_att 8.821266 loss_ctc 11.694608 loss_rnnt 8.377095 history loss 7.290536 rank 4
2022-12-04 01:49:10,839 DEBUG CV Batch 7/500 loss 8.775473 loss_att 8.821266 loss_ctc 11.694608 loss_rnnt 8.377095 history loss 7.290536 rank 2
2022-12-04 01:49:11,768 DEBUG CV Batch 7/500 loss 8.775473 loss_att 8.821266 loss_ctc 11.694608 loss_rnnt 8.377095 history loss 7.290536 rank 5
2022-12-04 01:49:21,859 DEBUG CV Batch 7/600 loss 6.887005 loss_att 7.647296 loss_ctc 10.378171 loss_rnnt 6.269458 history loss 8.261244 rank 6
2022-12-04 01:49:22,212 DEBUG CV Batch 7/600 loss 6.887005 loss_att 7.647296 loss_ctc 10.378171 loss_rnnt 6.269458 history loss 8.261244 rank 3
2022-12-04 01:49:22,608 DEBUG CV Batch 7/600 loss 6.887005 loss_att 7.647296 loss_ctc 10.378171 loss_rnnt 6.269458 history loss 8.261244 rank 0
2022-12-04 01:49:22,785 DEBUG CV Batch 7/600 loss 6.887005 loss_att 7.647296 loss_ctc 10.378171 loss_rnnt 6.269458 history loss 8.261244 rank 1
2022-12-04 01:49:22,799 DEBUG CV Batch 7/600 loss 6.887005 loss_att 7.647296 loss_ctc 10.378171 loss_rnnt 6.269458 history loss 8.261244 rank 7
2022-12-04 01:49:22,804 DEBUG CV Batch 7/600 loss 6.887005 loss_att 7.647296 loss_ctc 10.378171 loss_rnnt 6.269458 history loss 8.261244 rank 4
2022-12-04 01:49:22,936 DEBUG CV Batch 7/600 loss 6.887005 loss_att 7.647296 loss_ctc 10.378171 loss_rnnt 6.269458 history loss 8.261244 rank 2
2022-12-04 01:49:24,252 DEBUG CV Batch 7/600 loss 6.887005 loss_att 7.647296 loss_ctc 10.378171 loss_rnnt 6.269458 history loss 8.261244 rank 5
2022-12-04 01:49:33,379 DEBUG CV Batch 7/700 loss 24.026340 loss_att 73.518105 loss_ctc 35.659000 loss_rnnt 12.576965 history loss 8.956289 rank 6
2022-12-04 01:49:33,874 DEBUG CV Batch 7/700 loss 24.026340 loss_att 73.518105 loss_ctc 35.659000 loss_rnnt 12.576965 history loss 8.956289 rank 3
2022-12-04 01:49:34,097 DEBUG CV Batch 7/700 loss 24.026340 loss_att 73.518105 loss_ctc 35.659000 loss_rnnt 12.576965 history loss 8.956289 rank 1
2022-12-04 01:49:34,193 DEBUG CV Batch 7/700 loss 24.026340 loss_att 73.518105 loss_ctc 35.659000 loss_rnnt 12.576965 history loss 8.956289 rank 0
2022-12-04 01:49:34,402 DEBUG CV Batch 7/700 loss 24.026340 loss_att 73.518105 loss_ctc 35.659000 loss_rnnt 12.576965 history loss 8.956289 rank 4
2022-12-04 01:49:34,452 DEBUG CV Batch 7/700 loss 24.026340 loss_att 73.518105 loss_ctc 35.659000 loss_rnnt 12.576965 history loss 8.956289 rank 2
2022-12-04 01:49:34,537 DEBUG CV Batch 7/700 loss 24.026340 loss_att 73.518105 loss_ctc 35.659000 loss_rnnt 12.576965 history loss 8.956289 rank 7
2022-12-04 01:49:36,092 DEBUG CV Batch 7/700 loss 24.026340 loss_att 73.518105 loss_ctc 35.659000 loss_rnnt 12.576965 history loss 8.956289 rank 5
2022-12-04 01:49:44,659 DEBUG CV Batch 7/800 loss 12.251601 loss_att 12.134550 loss_ctc 21.143656 loss_rnnt 11.089403 history loss 8.395263 rank 6
2022-12-04 01:49:45,183 DEBUG CV Batch 7/800 loss 12.251601 loss_att 12.134550 loss_ctc 21.143656 loss_rnnt 11.089403 history loss 8.395263 rank 3
2022-12-04 01:49:45,562 DEBUG CV Batch 7/800 loss 12.251601 loss_att 12.134550 loss_ctc 21.143656 loss_rnnt 11.089403 history loss 8.395263 rank 0
2022-12-04 01:49:46,012 DEBUG CV Batch 7/800 loss 12.251601 loss_att 12.134550 loss_ctc 21.143656 loss_rnnt 11.089403 history loss 8.395263 rank 2
2022-12-04 01:49:46,031 DEBUG CV Batch 7/800 loss 12.251601 loss_att 12.134550 loss_ctc 21.143656 loss_rnnt 11.089403 history loss 8.395263 rank 1
2022-12-04 01:49:46,505 DEBUG CV Batch 7/800 loss 12.251601 loss_att 12.134550 loss_ctc 21.143656 loss_rnnt 11.089403 history loss 8.395263 rank 7
2022-12-04 01:49:46,679 DEBUG CV Batch 7/800 loss 12.251601 loss_att 12.134550 loss_ctc 21.143656 loss_rnnt 11.089403 history loss 8.395263 rank 4
2022-12-04 01:49:47,993 DEBUG CV Batch 7/800 loss 12.251601 loss_att 12.134550 loss_ctc 21.143656 loss_rnnt 11.089403 history loss 8.395263 rank 5
2022-12-04 01:49:58,185 DEBUG CV Batch 7/900 loss 19.031342 loss_att 24.453735 loss_ctc 34.066433 loss_rnnt 15.942184 history loss 8.186827 rank 6
2022-12-04 01:49:58,850 DEBUG CV Batch 7/900 loss 19.031342 loss_att 24.453735 loss_ctc 34.066433 loss_rnnt 15.942184 history loss 8.186827 rank 3
2022-12-04 01:49:59,145 DEBUG CV Batch 7/900 loss 19.031342 loss_att 24.453735 loss_ctc 34.066433 loss_rnnt 15.942184 history loss 8.186827 rank 0
2022-12-04 01:49:59,639 DEBUG CV Batch 7/900 loss 19.031342 loss_att 24.453735 loss_ctc 34.066433 loss_rnnt 15.942184 history loss 8.186827 rank 2
2022-12-04 01:50:00,154 DEBUG CV Batch 7/900 loss 19.031342 loss_att 24.453735 loss_ctc 34.066433 loss_rnnt 15.942184 history loss 8.186827 rank 1
2022-12-04 01:50:00,394 DEBUG CV Batch 7/900 loss 19.031342 loss_att 24.453735 loss_ctc 34.066433 loss_rnnt 15.942184 history loss 8.186827 rank 4
2022-12-04 01:50:00,521 DEBUG CV Batch 7/900 loss 19.031342 loss_att 24.453735 loss_ctc 34.066433 loss_rnnt 15.942184 history loss 8.186827 rank 7
2022-12-04 01:50:01,788 DEBUG CV Batch 7/900 loss 19.031342 loss_att 24.453735 loss_ctc 34.066433 loss_rnnt 15.942184 history loss 8.186827 rank 5
2022-12-04 01:50:10,575 DEBUG CV Batch 7/1000 loss 4.552751 loss_att 5.514190 loss_ctc 6.995584 loss_rnnt 4.034752 history loss 7.954106 rank 6
2022-12-04 01:50:11,284 DEBUG CV Batch 7/1000 loss 4.552751 loss_att 5.514190 loss_ctc 6.995584 loss_rnnt 4.034752 history loss 7.954106 rank 3
2022-12-04 01:50:11,640 DEBUG CV Batch 7/1000 loss 4.552751 loss_att 5.514190 loss_ctc 6.995584 loss_rnnt 4.034752 history loss 7.954106 rank 0
2022-12-04 01:50:12,241 DEBUG CV Batch 7/1000 loss 4.552751 loss_att 5.514190 loss_ctc 6.995584 loss_rnnt 4.034752 history loss 7.954106 rank 1
2022-12-04 01:50:12,606 DEBUG CV Batch 7/1000 loss 4.552751 loss_att 5.514190 loss_ctc 6.995584 loss_rnnt 4.034752 history loss 7.954106 rank 2
2022-12-04 01:50:12,710 DEBUG CV Batch 7/1000 loss 4.552751 loss_att 5.514190 loss_ctc 6.995584 loss_rnnt 4.034752 history loss 7.954106 rank 4
2022-12-04 01:50:12,937 DEBUG CV Batch 7/1000 loss 4.552751 loss_att 5.514190 loss_ctc 6.995584 loss_rnnt 4.034752 history loss 7.954106 rank 7
2022-12-04 01:50:14,613 DEBUG CV Batch 7/1000 loss 4.552751 loss_att 5.514190 loss_ctc 6.995584 loss_rnnt 4.034752 history loss 7.954106 rank 5
2022-12-04 01:50:22,712 DEBUG CV Batch 7/1100 loss 5.185415 loss_att 5.182956 loss_ctc 9.003321 loss_rnnt 4.676853 history loss 7.915758 rank 6
2022-12-04 01:50:23,409 DEBUG CV Batch 7/1100 loss 5.185415 loss_att 5.182956 loss_ctc 9.003321 loss_rnnt 4.676853 history loss 7.915758 rank 3
2022-12-04 01:50:23,846 DEBUG CV Batch 7/1100 loss 5.185415 loss_att 5.182956 loss_ctc 9.003321 loss_rnnt 4.676853 history loss 7.915758 rank 0
2022-12-04 01:50:24,100 DEBUG CV Batch 7/1100 loss 5.185415 loss_att 5.182956 loss_ctc 9.003321 loss_rnnt 4.676853 history loss 7.915758 rank 1
2022-12-04 01:50:24,952 DEBUG CV Batch 7/1100 loss 5.185415 loss_att 5.182956 loss_ctc 9.003321 loss_rnnt 4.676853 history loss 7.915758 rank 2
2022-12-04 01:50:25,125 DEBUG CV Batch 7/1100 loss 5.185415 loss_att 5.182956 loss_ctc 9.003321 loss_rnnt 4.676853 history loss 7.915758 rank 7
2022-12-04 01:50:25,313 DEBUG CV Batch 7/1100 loss 5.185415 loss_att 5.182956 loss_ctc 9.003321 loss_rnnt 4.676853 history loss 7.915758 rank 4
2022-12-04 01:50:27,000 DEBUG CV Batch 7/1100 loss 5.185415 loss_att 5.182956 loss_ctc 9.003321 loss_rnnt 4.676853 history loss 7.915758 rank 5
2022-12-04 01:50:33,549 DEBUG CV Batch 7/1200 loss 10.248213 loss_att 10.121699 loss_ctc 12.655089 loss_rnnt 9.952599 history loss 8.261631 rank 6
2022-12-04 01:50:34,347 DEBUG CV Batch 7/1200 loss 10.248213 loss_att 10.121699 loss_ctc 12.655089 loss_rnnt 9.952599 history loss 8.261631 rank 3
2022-12-04 01:50:34,662 DEBUG CV Batch 7/1200 loss 10.248213 loss_att 10.121699 loss_ctc 12.655089 loss_rnnt 9.952599 history loss 8.261631 rank 1
2022-12-04 01:50:34,760 DEBUG CV Batch 7/1200 loss 10.248213 loss_att 10.121699 loss_ctc 12.655089 loss_rnnt 9.952599 history loss 8.261631 rank 0
2022-12-04 01:50:35,621 DEBUG CV Batch 7/1200 loss 10.248213 loss_att 10.121699 loss_ctc 12.655089 loss_rnnt 9.952599 history loss 8.261631 rank 2
2022-12-04 01:50:35,819 DEBUG CV Batch 7/1200 loss 10.248213 loss_att 10.121699 loss_ctc 12.655089 loss_rnnt 9.952599 history loss 8.261631 rank 7
2022-12-04 01:50:35,825 DEBUG CV Batch 7/1200 loss 10.248213 loss_att 10.121699 loss_ctc 12.655089 loss_rnnt 9.952599 history loss 8.261631 rank 4
2022-12-04 01:50:38,359 DEBUG CV Batch 7/1200 loss 10.248213 loss_att 10.121699 loss_ctc 12.655089 loss_rnnt 9.952599 history loss 8.261631 rank 5
2022-12-04 01:50:45,733 DEBUG CV Batch 7/1300 loss 5.940602 loss_att 6.143426 loss_ctc 10.504302 loss_rnnt 5.291543 history loss 8.583256 rank 6
2022-12-04 01:50:46,576 DEBUG CV Batch 7/1300 loss 5.940602 loss_att 6.143426 loss_ctc 10.504302 loss_rnnt 5.291543 history loss 8.583256 rank 3
2022-12-04 01:50:46,922 DEBUG CV Batch 7/1300 loss 5.940602 loss_att 6.143426 loss_ctc 10.504302 loss_rnnt 5.291543 history loss 8.583256 rank 1
2022-12-04 01:50:47,046 DEBUG CV Batch 7/1300 loss 5.940602 loss_att 6.143426 loss_ctc 10.504302 loss_rnnt 5.291543 history loss 8.583256 rank 0
2022-12-04 01:50:47,753 DEBUG CV Batch 7/1300 loss 5.940602 loss_att 6.143426 loss_ctc 10.504302 loss_rnnt 5.291543 history loss 8.583256 rank 2
2022-12-04 01:50:47,962 DEBUG CV Batch 7/1300 loss 5.940602 loss_att 6.143426 loss_ctc 10.504302 loss_rnnt 5.291543 history loss 8.583256 rank 7
2022-12-04 01:50:48,176 DEBUG CV Batch 7/1300 loss 5.940602 loss_att 6.143426 loss_ctc 10.504302 loss_rnnt 5.291543 history loss 8.583256 rank 4
2022-12-04 01:50:50,890 DEBUG CV Batch 7/1300 loss 5.940602 loss_att 6.143426 loss_ctc 10.504302 loss_rnnt 5.291543 history loss 8.583256 rank 5
2022-12-04 01:50:57,142 DEBUG CV Batch 7/1400 loss 12.019746 loss_att 44.110950 loss_ctc 15.102397 loss_rnnt 5.190485 history loss 8.923314 rank 6
2022-12-04 01:50:58,173 DEBUG CV Batch 7/1400 loss 12.019746 loss_att 44.110950 loss_ctc 15.102397 loss_rnnt 5.190485 history loss 8.923314 rank 3
2022-12-04 01:50:58,540 DEBUG CV Batch 7/1400 loss 12.019746 loss_att 44.110950 loss_ctc 15.102397 loss_rnnt 5.190485 history loss 8.923314 rank 1
2022-12-04 01:50:58,737 DEBUG CV Batch 7/1400 loss 12.019746 loss_att 44.110950 loss_ctc 15.102397 loss_rnnt 5.190485 history loss 8.923314 rank 0
2022-12-04 01:50:59,146 DEBUG CV Batch 7/1400 loss 12.019746 loss_att 44.110950 loss_ctc 15.102397 loss_rnnt 5.190485 history loss 8.923314 rank 2
2022-12-04 01:50:59,535 DEBUG CV Batch 7/1400 loss 12.019746 loss_att 44.110950 loss_ctc 15.102397 loss_rnnt 5.190485 history loss 8.923314 rank 7
2022-12-04 01:50:59,797 DEBUG CV Batch 7/1400 loss 12.019746 loss_att 44.110950 loss_ctc 15.102397 loss_rnnt 5.190485 history loss 8.923314 rank 4
2022-12-04 01:51:02,762 DEBUG CV Batch 7/1400 loss 12.019746 loss_att 44.110950 loss_ctc 15.102397 loss_rnnt 5.190485 history loss 8.923314 rank 5
2022-12-04 01:51:08,768 DEBUG CV Batch 7/1500 loss 9.691914 loss_att 10.607328 loss_ctc 12.965836 loss_rnnt 9.072308 history loss 8.731029 rank 6
2022-12-04 01:51:09,948 DEBUG CV Batch 7/1500 loss 9.691914 loss_att 10.607328 loss_ctc 12.965836 loss_rnnt 9.072308 history loss 8.731029 rank 3
2022-12-04 01:51:10,450 DEBUG CV Batch 7/1500 loss 9.691914 loss_att 10.607328 loss_ctc 12.965836 loss_rnnt 9.072308 history loss 8.731029 rank 0
2022-12-04 01:51:10,849 DEBUG CV Batch 7/1500 loss 9.691914 loss_att 10.607328 loss_ctc 12.965836 loss_rnnt 9.072308 history loss 8.731029 rank 2
2022-12-04 01:51:11,419 DEBUG CV Batch 7/1500 loss 9.691914 loss_att 10.607328 loss_ctc 12.965836 loss_rnnt 9.072308 history loss 8.731029 rank 1
2022-12-04 01:51:11,461 DEBUG CV Batch 7/1500 loss 9.691914 loss_att 10.607328 loss_ctc 12.965836 loss_rnnt 9.072308 history loss 8.731029 rank 4
2022-12-04 01:51:11,464 DEBUG CV Batch 7/1500 loss 9.691914 loss_att 10.607328 loss_ctc 12.965836 loss_rnnt 9.072308 history loss 8.731029 rank 7
2022-12-04 01:51:15,003 DEBUG CV Batch 7/1500 loss 9.691914 loss_att 10.607328 loss_ctc 12.965836 loss_rnnt 9.072308 history loss 8.731029 rank 5
2022-12-04 01:51:21,901 DEBUG CV Batch 7/1600 loss 6.469186 loss_att 15.085058 loss_ctc 12.451687 loss_rnnt 3.948344 history loss 8.640861 rank 6
2022-12-04 01:51:23,235 DEBUG CV Batch 7/1600 loss 6.469186 loss_att 15.085058 loss_ctc 12.451687 loss_rnnt 3.948344 history loss 8.640861 rank 3
2022-12-04 01:51:23,766 DEBUG CV Batch 7/1600 loss 6.469186 loss_att 15.085058 loss_ctc 12.451687 loss_rnnt 3.948344 history loss 8.640861 rank 0
2022-12-04 01:51:24,239 DEBUG CV Batch 7/1600 loss 6.469186 loss_att 15.085058 loss_ctc 12.451687 loss_rnnt 3.948344 history loss 8.640861 rank 2
2022-12-04 01:51:24,776 DEBUG CV Batch 7/1600 loss 6.469186 loss_att 15.085058 loss_ctc 12.451687 loss_rnnt 3.948344 history loss 8.640861 rank 4
2022-12-04 01:51:25,124 DEBUG CV Batch 7/1600 loss 6.469186 loss_att 15.085058 loss_ctc 12.451687 loss_rnnt 3.948344 history loss 8.640861 rank 1
2022-12-04 01:51:25,231 DEBUG CV Batch 7/1600 loss 6.469186 loss_att 15.085058 loss_ctc 12.451687 loss_rnnt 3.948344 history loss 8.640861 rank 7
2022-12-04 01:51:28,573 DEBUG CV Batch 7/1600 loss 6.469186 loss_att 15.085058 loss_ctc 12.451687 loss_rnnt 3.948344 history loss 8.640861 rank 5
2022-12-04 01:51:34,479 DEBUG CV Batch 7/1700 loss 11.741204 loss_att 11.197537 loss_ctc 19.996666 loss_rnnt 10.749210 history loss 8.536559 rank 6
2022-12-04 01:51:35,958 DEBUG CV Batch 7/1700 loss 11.741204 loss_att 11.197537 loss_ctc 19.996666 loss_rnnt 10.749210 history loss 8.536559 rank 3
2022-12-04 01:51:36,485 DEBUG CV Batch 7/1700 loss 11.741204 loss_att 11.197537 loss_ctc 19.996666 loss_rnnt 10.749210 history loss 8.536559 rank 0
2022-12-04 01:51:36,973 DEBUG CV Batch 7/1700 loss 11.741204 loss_att 11.197537 loss_ctc 19.996666 loss_rnnt 10.749210 history loss 8.536559 rank 2
2022-12-04 01:51:37,433 DEBUG CV Batch 7/1700 loss 11.741204 loss_att 11.197537 loss_ctc 19.996666 loss_rnnt 10.749210 history loss 8.536559 rank 4
2022-12-04 01:51:37,459 DEBUG CV Batch 7/1700 loss 11.741204 loss_att 11.197537 loss_ctc 19.996666 loss_rnnt 10.749210 history loss 8.536559 rank 1
2022-12-04 01:51:38,024 DEBUG CV Batch 7/1700 loss 11.741204 loss_att 11.197537 loss_ctc 19.996666 loss_rnnt 10.749210 history loss 8.536559 rank 7
2022-12-04 01:51:41,250 DEBUG CV Batch 7/1700 loss 11.741204 loss_att 11.197537 loss_ctc 19.996666 loss_rnnt 10.749210 history loss 8.536559 rank 5
2022-12-04 01:51:43,701 INFO Epoch 7 CV info cv_loss 8.49045031304855
2022-12-04 01:51:43,702 INFO Epoch 8 TRAIN info lr 0.0006122652986422042
2022-12-04 01:51:43,706 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 01:51:45,156 INFO Epoch 7 CV info cv_loss 8.49045031304855
2022-12-04 01:51:45,156 INFO Epoch 8 TRAIN info lr 0.0006122285788809476
2022-12-04 01:51:45,158 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 01:51:45,761 INFO Epoch 7 CV info cv_loss 8.49045031304855
2022-12-04 01:51:45,762 INFO Checkpoint: save to checkpoint exp/1202_encoder_bias_30_0.1/7.pt
2022-12-04 01:51:46,345 INFO Epoch 7 CV info cv_loss 8.49045031304855
2022-12-04 01:51:46,346 INFO Epoch 8 TRAIN info lr 0.0006119075625329945
2022-12-04 01:51:46,350 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 01:51:46,388 INFO Epoch 8 TRAIN info lr 0.0006120129836259613
2022-12-04 01:51:46,392 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 01:51:46,593 INFO Epoch 7 CV info cv_loss 8.49045031304855
2022-12-04 01:51:46,594 INFO Epoch 8 TRAIN info lr 0.0006121872770454996
2022-12-04 01:51:46,595 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 01:51:46,719 INFO Epoch 7 CV info cv_loss 8.49045031304855
2022-12-04 01:51:46,719 INFO Epoch 8 TRAIN info lr 0.0006123203906744066
2022-12-04 01:51:46,721 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 01:51:47,433 INFO Epoch 7 CV info cv_loss 8.49045031304855
2022-12-04 01:51:47,434 INFO Epoch 8 TRAIN info lr 0.0006122652986422042
2022-12-04 01:51:47,437 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 01:51:50,647 INFO Epoch 7 CV info cv_loss 8.49045031304855
2022-12-04 01:51:50,648 INFO Epoch 8 TRAIN info lr 0.0006122974338537289
2022-12-04 01:51:50,653 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 01:52:51,736 DEBUG TRAIN Batch 8/0 loss 13.742234 loss_att 13.369710 loss_ctc 17.993576 loss_rnnt 13.249893 lr 0.00061201 rank 0
2022-12-04 01:52:51,737 DEBUG TRAIN Batch 8/0 loss 12.092440 loss_att 11.386495 loss_ctc 16.158804 loss_rnnt 11.691447 lr 0.00061226 rank 6
2022-12-04 01:52:51,738 DEBUG TRAIN Batch 8/0 loss 10.117603 loss_att 10.618653 loss_ctc 15.726132 loss_rnnt 9.269589 lr 0.00061222 rank 3
2022-12-04 01:52:51,741 DEBUG TRAIN Batch 8/0 loss 11.640985 loss_att 12.535727 loss_ctc 15.644526 loss_rnnt 10.928233 lr 0.00061218 rank 1
2022-12-04 01:52:51,745 DEBUG TRAIN Batch 8/0 loss 12.930651 loss_att 12.267697 loss_ctc 18.472368 loss_rnnt 12.324346 lr 0.00061226 rank 7
2022-12-04 01:52:51,751 DEBUG TRAIN Batch 8/0 loss 9.500982 loss_att 9.439054 loss_ctc 11.768819 loss_rnnt 9.210989 lr 0.00061232 rank 4
2022-12-04 01:52:51,758 DEBUG TRAIN Batch 8/0 loss 11.751069 loss_att 12.550188 loss_ctc 17.133968 loss_rnnt 10.873525 lr 0.00061190 rank 2
2022-12-04 01:52:51,802 DEBUG TRAIN Batch 8/0 loss 12.843598 loss_att 12.265209 loss_ctc 18.071083 loss_rnnt 12.262279 lr 0.00061229 rank 5
2022-12-04 01:54:03,553 DEBUG TRAIN Batch 8/100 loss 23.650589 loss_att 29.794388 loss_ctc 45.786003 loss_rnnt 19.470440 lr 0.00061155 rank 0
2022-12-04 01:54:03,553 DEBUG TRAIN Batch 8/100 loss 16.874001 loss_att 19.186378 loss_ctc 26.702557 loss_rnnt 15.101051 lr 0.00061180 rank 6
2022-12-04 01:54:03,555 DEBUG TRAIN Batch 8/100 loss 7.762720 loss_att 15.014812 loss_ctc 17.077906 loss_rnnt 5.070277 lr 0.00061183 rank 5
2022-12-04 01:54:03,556 DEBUG TRAIN Batch 8/100 loss 13.376150 loss_att 20.086996 loss_ctc 23.817261 loss_rnnt 10.641832 lr 0.00061145 rank 2
2022-12-04 01:54:03,559 DEBUG TRAIN Batch 8/100 loss 18.239248 loss_att 28.771358 loss_ctc 32.752995 loss_rnnt 14.197660 lr 0.00061180 rank 7
2022-12-04 01:54:03,562 DEBUG TRAIN Batch 8/100 loss 8.426016 loss_att 12.588661 loss_ctc 15.961841 loss_rnnt 6.588710 lr 0.00061186 rank 4
2022-12-04 01:54:03,586 DEBUG TRAIN Batch 8/100 loss 10.534744 loss_att 14.649599 loss_ctc 15.193184 loss_rnnt 9.090648 lr 0.00061177 rank 3
2022-12-04 01:54:03,611 DEBUG TRAIN Batch 8/100 loss 7.648630 loss_att 12.399450 loss_ctc 10.568731 loss_rnnt 6.309119 lr 0.00061172 rank 1
2022-12-04 01:55:15,282 DEBUG TRAIN Batch 8/200 loss 22.922972 loss_att 30.537361 loss_ctc 36.334679 loss_rnnt 19.611866 lr 0.00061134 rank 6
2022-12-04 01:55:15,285 DEBUG TRAIN Batch 8/200 loss 11.298346 loss_att 15.996718 loss_ctc 17.541069 loss_rnnt 9.526309 lr 0.00061138 rank 5
2022-12-04 01:55:15,285 DEBUG TRAIN Batch 8/200 loss 30.473867 loss_att 35.530228 loss_ctc 46.188187 loss_rnnt 27.367353 lr 0.00061109 rank 0
2022-12-04 01:55:15,289 DEBUG TRAIN Batch 8/200 loss 21.353914 loss_att 24.683939 loss_ctc 39.146942 loss_rnnt 18.315506 lr 0.00061131 rank 3
2022-12-04 01:55:15,292 DEBUG TRAIN Batch 8/200 loss 13.816738 loss_att 18.692078 loss_ctc 28.025650 loss_rnnt 10.947147 lr 0.00061127 rank 1
2022-12-04 01:55:15,292 DEBUG TRAIN Batch 8/200 loss 12.695039 loss_att 18.004969 loss_ctc 24.800827 loss_rnnt 10.018948 lr 0.00061099 rank 2
2022-12-04 01:55:15,296 DEBUG TRAIN Batch 8/200 loss 12.950506 loss_att 17.615383 loss_ctc 23.216589 loss_rnnt 10.648720 lr 0.00061134 rank 7
2022-12-04 01:55:15,300 DEBUG TRAIN Batch 8/200 loss 10.615053 loss_att 15.272362 loss_ctc 17.972160 loss_rnnt 8.702643 lr 0.00061140 rank 4
2022-12-04 01:56:27,429 DEBUG TRAIN Batch 8/300 loss 10.830313 loss_att 13.519705 loss_ctc 14.425959 loss_rnnt 9.813015 lr 0.00061092 rank 5
2022-12-04 01:56:27,443 DEBUG TRAIN Batch 8/300 loss 12.188082 loss_att 16.392584 loss_ctc 15.008957 loss_rnnt 10.971064 lr 0.00061094 rank 4
2022-12-04 01:56:27,445 DEBUG TRAIN Batch 8/300 loss 9.306290 loss_att 13.783180 loss_ctc 16.727654 loss_rnnt 7.421396 lr 0.00061081 rank 1
2022-12-04 01:56:27,449 DEBUG TRAIN Batch 8/300 loss 15.714417 loss_att 23.051706 loss_ctc 28.922943 loss_rnnt 12.485821 lr 0.00061053 rank 2
2022-12-04 01:56:27,450 DEBUG TRAIN Batch 8/300 loss 11.676147 loss_att 14.229673 loss_ctc 15.546308 loss_rnnt 10.649421 lr 0.00061064 rank 0
2022-12-04 01:56:27,453 DEBUG TRAIN Batch 8/300 loss 14.549937 loss_att 15.657114 loss_ctc 18.561028 loss_rnnt 13.793690 lr 0.00061085 rank 3
2022-12-04 01:56:27,453 DEBUG TRAIN Batch 8/300 loss 20.065550 loss_att 24.580101 loss_ctc 33.866264 loss_rnnt 17.322542 lr 0.00061089 rank 6
2022-12-04 01:56:27,473 DEBUG TRAIN Batch 8/300 loss 26.299026 loss_att 30.558884 loss_ctc 42.568985 loss_rnnt 23.277725 lr 0.00061089 rank 7
2022-12-04 01:57:40,684 DEBUG TRAIN Batch 8/400 loss 25.666920 loss_att 35.868164 loss_ctc 36.604080 loss_rnnt 22.168383 lr 0.00061018 rank 0
2022-12-04 01:57:40,685 DEBUG TRAIN Batch 8/400 loss 11.359580 loss_att 13.850941 loss_ctc 19.071482 loss_rnnt 9.833054 lr 0.00061043 rank 6
2022-12-04 01:57:40,685 DEBUG TRAIN Batch 8/400 loss 26.446451 loss_att 31.460230 loss_ctc 44.343781 loss_rnnt 23.057386 lr 0.00061036 rank 1
2022-12-04 01:57:40,687 DEBUG TRAIN Batch 8/400 loss 16.170719 loss_att 18.041826 loss_ctc 27.833630 loss_rnnt 14.241442 lr 0.00061040 rank 3
2022-12-04 01:57:40,688 DEBUG TRAIN Batch 8/400 loss 35.708347 loss_att 37.502296 loss_ctc 57.452194 loss_rnnt 32.450378 lr 0.00061008 rank 2
2022-12-04 01:57:40,689 DEBUG TRAIN Batch 8/400 loss 21.413933 loss_att 24.972469 loss_ctc 33.132565 loss_rnnt 19.139740 lr 0.00061043 rank 7
2022-12-04 01:57:40,693 DEBUG TRAIN Batch 8/400 loss 22.507792 loss_att 24.516768 loss_ctc 44.119225 loss_rnnt 19.224472 lr 0.00061046 rank 5
2022-12-04 01:57:40,698 DEBUG TRAIN Batch 8/400 loss 17.139862 loss_att 23.157505 loss_ctc 29.773907 loss_rnnt 14.251796 lr 0.00061049 rank 4
2022-12-04 01:58:52,338 DEBUG TRAIN Batch 8/500 loss 17.707754 loss_att 21.229956 loss_ctc 28.054596 loss_rnnt 15.623734 lr 0.00060998 rank 7
2022-12-04 01:58:52,346 DEBUG TRAIN Batch 8/500 loss 9.424189 loss_att 14.896332 loss_ctc 18.778193 loss_rnnt 7.082559 lr 0.00061001 rank 5
2022-12-04 01:58:52,349 DEBUG TRAIN Batch 8/500 loss 9.457487 loss_att 12.260406 loss_ctc 18.474545 loss_rnnt 7.694629 lr 0.00060994 rank 3
2022-12-04 01:58:52,352 DEBUG TRAIN Batch 8/500 loss 15.686364 loss_att 21.943205 loss_ctc 23.957939 loss_rnnt 13.332119 lr 0.00060973 rank 0
2022-12-04 01:58:52,352 DEBUG TRAIN Batch 8/500 loss 15.758978 loss_att 19.336048 loss_ctc 28.106739 loss_rnnt 13.397195 lr 0.00060998 rank 6
2022-12-04 01:58:52,353 DEBUG TRAIN Batch 8/500 loss 12.645263 loss_att 15.553835 loss_ctc 20.773426 loss_rnnt 10.979792 lr 0.00061003 rank 4
2022-12-04 01:58:52,353 DEBUG TRAIN Batch 8/500 loss 13.409200 loss_att 17.114550 loss_ctc 18.291237 loss_rnnt 12.017191 lr 0.00060990 rank 1
2022-12-04 01:58:52,353 DEBUG TRAIN Batch 8/500 loss 8.667206 loss_att 12.462143 loss_ctc 16.979191 loss_rnnt 6.799953 lr 0.00060962 rank 2
2022-12-04 02:00:04,137 DEBUG TRAIN Batch 8/600 loss 23.377865 loss_att 26.585693 loss_ctc 39.862839 loss_rnnt 20.538303 lr 0.00060952 rank 6
2022-12-04 02:00:04,138 DEBUG TRAIN Batch 8/600 loss 8.855486 loss_att 11.423497 loss_ctc 17.604271 loss_rnnt 7.175380 lr 0.00060945 rank 1
2022-12-04 02:00:04,139 DEBUG TRAIN Batch 8/600 loss 10.200050 loss_att 11.221647 loss_ctc 15.573899 loss_rnnt 9.279217 lr 0.00060956 rank 5
2022-12-04 02:00:04,141 DEBUG TRAIN Batch 8/600 loss 18.518942 loss_att 20.586849 loss_ctc 32.889755 loss_rnnt 16.189251 lr 0.00060949 rank 3
2022-12-04 02:00:04,142 DEBUG TRAIN Batch 8/600 loss 12.678629 loss_att 14.224122 loss_ctc 16.480381 loss_rnnt 11.862630 lr 0.00060958 rank 4
2022-12-04 02:00:04,143 DEBUG TRAIN Batch 8/600 loss 12.034595 loss_att 17.434364 loss_ctc 22.752882 loss_rnnt 9.525537 lr 0.00060928 rank 0
2022-12-04 02:00:04,143 DEBUG TRAIN Batch 8/600 loss 35.235420 loss_att 36.839867 loss_ctc 52.012417 loss_rnnt 32.677597 lr 0.00060917 rank 2
2022-12-04 02:00:04,188 DEBUG TRAIN Batch 8/600 loss 9.739902 loss_att 12.045281 loss_ctc 16.371189 loss_rnnt 8.394655 lr 0.00060952 rank 7
2022-12-04 02:01:18,296 DEBUG TRAIN Batch 8/700 loss 16.498436 loss_att 20.589905 loss_ctc 27.897703 loss_rnnt 14.160240 lr 0.00060904 rank 3
2022-12-04 02:01:18,298 DEBUG TRAIN Batch 8/700 loss 19.571674 loss_att 26.988285 loss_ctc 30.190611 loss_rnnt 16.672493 lr 0.00060907 rank 6
2022-12-04 02:01:18,300 DEBUG TRAIN Batch 8/700 loss 7.313605 loss_att 12.802115 loss_ctc 16.080635 loss_rnnt 5.046966 lr 0.00060900 rank 1
2022-12-04 02:01:18,304 DEBUG TRAIN Batch 8/700 loss 15.349186 loss_att 14.964144 loss_ctc 22.547705 loss_rnnt 14.466393 lr 0.00060882 rank 0
2022-12-04 02:01:18,305 DEBUG TRAIN Batch 8/700 loss 20.676838 loss_att 24.895187 loss_ctc 31.875748 loss_rnnt 18.339981 lr 0.00060907 rank 7
2022-12-04 02:01:18,320 DEBUG TRAIN Batch 8/700 loss 5.479469 loss_att 12.496948 loss_ctc 9.618379 loss_rnnt 3.524119 lr 0.00060872 rank 2
2022-12-04 02:01:18,322 DEBUG TRAIN Batch 8/700 loss 4.006251 loss_att 8.672412 loss_ctc 7.930610 loss_rnnt 2.549771 lr 0.00060913 rank 4
2022-12-04 02:01:18,330 DEBUG TRAIN Batch 8/700 loss 13.892704 loss_att 20.164282 loss_ctc 24.543324 loss_rnnt 11.218306 lr 0.00060910 rank 5
2022-12-04 02:02:29,176 DEBUG TRAIN Batch 8/800 loss 5.442733 loss_att 10.828875 loss_ctc 13.423247 loss_rnnt 3.301436 lr 0.00060862 rank 6
2022-12-04 02:02:29,180 DEBUG TRAIN Batch 8/800 loss 9.627706 loss_att 13.100019 loss_ctc 18.333647 loss_rnnt 7.772451 lr 0.00060859 rank 3
2022-12-04 02:02:29,180 DEBUG TRAIN Batch 8/800 loss 12.557068 loss_att 15.679261 loss_ctc 18.173002 loss_rnnt 11.183838 lr 0.00060827 rank 2
2022-12-04 02:02:29,180 DEBUG TRAIN Batch 8/800 loss 9.190634 loss_att 15.876102 loss_ctc 20.559605 loss_rnnt 6.337677 lr 0.00060862 rank 7
2022-12-04 02:02:29,182 DEBUG TRAIN Batch 8/800 loss 13.665751 loss_att 23.612429 loss_ctc 32.501053 loss_rnnt 9.165041 lr 0.00060837 rank 0
2022-12-04 02:02:29,183 DEBUG TRAIN Batch 8/800 loss 34.453201 loss_att 36.768913 loss_ctc 48.606293 loss_rnnt 32.102978 lr 0.00060854 rank 1
2022-12-04 02:02:29,186 DEBUG TRAIN Batch 8/800 loss 17.330139 loss_att 22.232616 loss_ctc 35.033176 loss_rnnt 13.989238 lr 0.00060865 rank 5
2022-12-04 02:02:29,191 DEBUG TRAIN Batch 8/800 loss 6.756163 loss_att 12.234670 loss_ctc 12.648947 loss_rnnt 4.874757 lr 0.00060868 rank 4
2022-12-04 02:03:40,824 DEBUG TRAIN Batch 8/900 loss 11.000489 loss_att 12.661470 loss_ctc 17.715897 loss_rnnt 9.772905 lr 0.00060817 rank 7
2022-12-04 02:03:40,831 DEBUG TRAIN Batch 8/900 loss 13.092737 loss_att 20.957447 loss_ctc 20.296391 loss_rnnt 10.559309 lr 0.00060809 rank 1
2022-12-04 02:03:40,833 DEBUG TRAIN Batch 8/900 loss 14.430624 loss_att 18.047297 loss_ctc 30.802420 loss_rnnt 11.524383 lr 0.00060792 rank 0
2022-12-04 02:03:40,839 DEBUG TRAIN Batch 8/900 loss 15.116896 loss_att 21.305201 loss_ctc 23.233114 loss_rnnt 12.797071 lr 0.00060820 rank 5
2022-12-04 02:03:40,839 DEBUG TRAIN Batch 8/900 loss 20.230312 loss_att 24.874205 loss_ctc 29.103464 loss_rnnt 18.118446 lr 0.00060813 rank 3
2022-12-04 02:03:40,840 DEBUG TRAIN Batch 8/900 loss 12.803871 loss_att 18.770344 loss_ctc 21.588871 loss_rnnt 10.439243 lr 0.00060782 rank 2
2022-12-04 02:03:40,842 DEBUG TRAIN Batch 8/900 loss 13.906556 loss_att 16.956547 loss_ctc 23.654327 loss_rnnt 11.996856 lr 0.00060817 rank 6
2022-12-04 02:03:40,851 DEBUG TRAIN Batch 8/900 loss 29.356768 loss_att 33.360580 loss_ctc 43.292480 loss_rnnt 26.697908 lr 0.00060822 rank 4
2022-12-04 02:04:52,342 DEBUG TRAIN Batch 8/1000 loss 10.006144 loss_att 15.525810 loss_ctc 17.240229 loss_rnnt 7.937665 lr 0.00060747 rank 0
2022-12-04 02:04:52,342 DEBUG TRAIN Batch 8/1000 loss 6.579031 loss_att 10.565763 loss_ctc 16.196314 loss_rnnt 4.499379 lr 0.00060775 rank 5
2022-12-04 02:04:52,345 DEBUG TRAIN Batch 8/1000 loss 17.100348 loss_att 20.743156 loss_ctc 33.529625 loss_rnnt 14.181215 lr 0.00060772 rank 6
2022-12-04 02:04:52,349 DEBUG TRAIN Batch 8/1000 loss 11.780495 loss_att 14.588755 loss_ctc 21.395138 loss_rnnt 9.936890 lr 0.00060769 rank 3
2022-12-04 02:04:52,349 DEBUG TRAIN Batch 8/1000 loss 8.424648 loss_att 10.496818 loss_ctc 13.142837 loss_rnnt 7.381122 lr 0.00060765 rank 1
2022-12-04 02:04:52,351 DEBUG TRAIN Batch 8/1000 loss 19.999041 loss_att 21.225271 loss_ctc 28.329140 loss_rnnt 18.643114 lr 0.00060778 rank 4
2022-12-04 02:04:52,354 DEBUG TRAIN Batch 8/1000 loss 17.088367 loss_att 21.290804 loss_ctc 23.017609 loss_rnnt 15.457314 lr 0.00060737 rank 2
2022-12-04 02:04:52,391 DEBUG TRAIN Batch 8/1000 loss 11.497846 loss_att 15.109581 loss_ctc 16.337910 loss_rnnt 10.130157 lr 0.00060772 rank 7
2022-12-04 02:06:06,373 DEBUG TRAIN Batch 8/1100 loss 13.510851 loss_att 18.784811 loss_ctc 20.834476 loss_rnnt 11.479575 lr 0.00060720 rank 1
2022-12-04 02:06:06,392 DEBUG TRAIN Batch 8/1100 loss 18.054514 loss_att 20.935974 loss_ctc 30.758476 loss_rnnt 15.784359 lr 0.00060727 rank 6
2022-12-04 02:06:06,393 DEBUG TRAIN Batch 8/1100 loss 22.533909 loss_att 23.753246 loss_ctc 34.612747 loss_rnnt 20.679531 lr 0.00060730 rank 5
2022-12-04 02:06:06,394 DEBUG TRAIN Batch 8/1100 loss 9.888962 loss_att 14.170083 loss_ctc 14.515182 loss_rnnt 8.415907 lr 0.00060733 rank 4
2022-12-04 02:06:06,395 DEBUG TRAIN Batch 8/1100 loss 18.178396 loss_att 22.449394 loss_ctc 33.283283 loss_rnnt 15.310211 lr 0.00060703 rank 0
2022-12-04 02:06:06,396 DEBUG TRAIN Batch 8/1100 loss 41.177166 loss_att 47.775444 loss_ctc 63.236954 loss_rnnt 36.916206 lr 0.00060727 rank 7
2022-12-04 02:06:06,401 DEBUG TRAIN Batch 8/1100 loss 17.885429 loss_att 24.594830 loss_ctc 36.019615 loss_rnnt 14.125659 lr 0.00060724 rank 3
2022-12-04 02:06:06,442 DEBUG TRAIN Batch 8/1100 loss 20.883745 loss_att 23.783024 loss_ctc 34.009628 loss_rnnt 18.553772 lr 0.00060692 rank 2
2022-12-04 02:07:17,711 DEBUG TRAIN Batch 8/1200 loss 20.047050 loss_att 23.488617 loss_ctc 26.793013 loss_rnnt 18.459274 lr 0.00060683 rank 6
2022-12-04 02:07:17,715 DEBUG TRAIN Batch 8/1200 loss 13.136204 loss_att 19.043531 loss_ctc 23.650276 loss_rnnt 10.552861 lr 0.00060658 rank 0
2022-12-04 02:07:17,717 DEBUG TRAIN Batch 8/1200 loss 8.603508 loss_att 11.048238 loss_ctc 15.812920 loss_rnnt 7.153306 lr 0.00060679 rank 3
2022-12-04 02:07:17,721 DEBUG TRAIN Batch 8/1200 loss 16.236258 loss_att 18.445171 loss_ctc 24.312773 loss_rnnt 14.717606 lr 0.00060686 rank 5
2022-12-04 02:07:17,720 DEBUG TRAIN Batch 8/1200 loss 17.079733 loss_att 18.379925 loss_ctc 23.539434 loss_rnnt 15.958401 lr 0.00060675 rank 1
2022-12-04 02:07:17,721 DEBUG TRAIN Batch 8/1200 loss 14.859478 loss_att 18.511450 loss_ctc 21.864811 loss_rnnt 13.195038 lr 0.00060648 rank 2
2022-12-04 02:07:17,721 DEBUG TRAIN Batch 8/1200 loss 11.032468 loss_att 13.072094 loss_ctc 20.339304 loss_rnnt 9.383631 lr 0.00060683 rank 7
2022-12-04 02:07:17,725 DEBUG TRAIN Batch 8/1200 loss 16.576494 loss_att 20.471300 loss_ctc 29.955866 loss_rnnt 14.013618 lr 0.00060688 rank 4
2022-12-04 02:08:29,818 DEBUG TRAIN Batch 8/1300 loss 16.574369 loss_att 23.894085 loss_ctc 29.034180 loss_rnnt 13.449120 lr 0.00060638 rank 7
2022-12-04 02:08:29,824 DEBUG TRAIN Batch 8/1300 loss 8.431911 loss_att 7.972176 loss_ctc 12.963799 loss_rnnt 7.919607 lr 0.00060638 rank 6
2022-12-04 02:08:29,825 DEBUG TRAIN Batch 8/1300 loss 22.391256 loss_att 25.334682 loss_ctc 33.006458 loss_rnnt 20.387211 lr 0.00060613 rank 0
2022-12-04 02:08:29,828 DEBUG TRAIN Batch 8/1300 loss 13.879239 loss_att 20.996544 loss_ctc 25.113752 loss_rnnt 10.957842 lr 0.00060634 rank 3
2022-12-04 02:08:29,830 DEBUG TRAIN Batch 8/1300 loss 12.198085 loss_att 21.754784 loss_ctc 15.345634 loss_rnnt 9.867072 lr 0.00060630 rank 1
2022-12-04 02:08:29,835 DEBUG TRAIN Batch 8/1300 loss 14.467573 loss_att 15.434719 loss_ctc 21.822046 loss_rnnt 13.293547 lr 0.00060641 rank 5
2022-12-04 02:08:29,838 DEBUG TRAIN Batch 8/1300 loss 14.619187 loss_att 13.855061 loss_ctc 26.370113 loss_rnnt 13.205222 lr 0.00060603 rank 2
2022-12-04 02:08:29,838 DEBUG TRAIN Batch 8/1300 loss 22.053497 loss_att 25.302456 loss_ctc 39.248413 loss_rnnt 19.111052 lr 0.00060643 rank 4
2022-12-04 02:09:43,048 DEBUG TRAIN Batch 8/1400 loss 4.390223 loss_att 8.081293 loss_ctc 8.027430 loss_rnnt 3.167048 lr 0.00060586 rank 1
2022-12-04 02:09:43,057 DEBUG TRAIN Batch 8/1400 loss 9.488561 loss_att 12.580394 loss_ctc 11.373775 loss_rnnt 8.618832 lr 0.00060596 rank 5
2022-12-04 02:09:43,060 DEBUG TRAIN Batch 8/1400 loss 10.107843 loss_att 13.594906 loss_ctc 16.707544 loss_rnnt 8.530471 lr 0.00060569 rank 0
2022-12-04 02:09:43,061 DEBUG TRAIN Batch 8/1400 loss 30.799635 loss_att 35.342319 loss_ctc 44.398846 loss_rnnt 28.077869 lr 0.00060593 rank 6
2022-12-04 02:09:43,070 DEBUG TRAIN Batch 8/1400 loss 3.832296 loss_att 9.060738 loss_ctc 6.875526 loss_rnnt 2.380843 lr 0.00060593 rank 7
2022-12-04 02:09:43,073 DEBUG TRAIN Batch 8/1400 loss 4.570024 loss_att 9.618549 loss_ctc 10.778895 loss_rnnt 2.732469 lr 0.00060559 rank 2
2022-12-04 02:09:43,073 DEBUG TRAIN Batch 8/1400 loss 17.329700 loss_att 24.001255 loss_ctc 32.523918 loss_rnnt 13.969492 lr 0.00060590 rank 3
2022-12-04 02:09:43,112 DEBUG TRAIN Batch 8/1400 loss 12.739250 loss_att 18.196926 loss_ctc 17.403290 loss_rnnt 11.025844 lr 0.00060599 rank 4
2022-12-04 02:10:55,082 DEBUG TRAIN Batch 8/1500 loss 8.488138 loss_att 12.252659 loss_ctc 15.111747 loss_rnnt 6.852087 lr 0.00060549 rank 6
2022-12-04 02:10:55,083 DEBUG TRAIN Batch 8/1500 loss 14.008024 loss_att 19.043079 loss_ctc 22.565201 loss_rnnt 11.860056 lr 0.00060545 rank 3
2022-12-04 02:10:55,086 DEBUG TRAIN Batch 8/1500 loss 16.706442 loss_att 22.409445 loss_ctc 27.886206 loss_rnnt 14.075206 lr 0.00060525 rank 0
2022-12-04 02:10:55,086 DEBUG TRAIN Batch 8/1500 loss 14.272518 loss_att 18.139557 loss_ctc 26.354202 loss_rnnt 11.888220 lr 0.00060514 rank 2
2022-12-04 02:10:55,087 DEBUG TRAIN Batch 8/1500 loss 14.019358 loss_att 17.353020 loss_ctc 22.602310 loss_rnnt 12.208232 lr 0.00060552 rank 5
2022-12-04 02:10:55,088 DEBUG TRAIN Batch 8/1500 loss 8.678508 loss_att 11.365175 loss_ctc 14.591209 loss_rnnt 7.352814 lr 0.00060554 rank 4
2022-12-04 02:10:55,088 DEBUG TRAIN Batch 8/1500 loss 9.416881 loss_att 13.047678 loss_ctc 19.000883 loss_rnnt 7.412855 lr 0.00060549 rank 7
2022-12-04 02:10:55,093 DEBUG TRAIN Batch 8/1500 loss 14.942182 loss_att 17.448666 loss_ctc 23.688400 loss_rnnt 13.274722 lr 0.00060541 rank 1
2022-12-04 02:12:06,445 DEBUG TRAIN Batch 8/1600 loss 5.835402 loss_att 9.193613 loss_ctc 11.159373 loss_rnnt 4.453897 lr 0.00060480 rank 0
2022-12-04 02:12:06,447 DEBUG TRAIN Batch 8/1600 loss 16.717171 loss_att 20.719610 loss_ctc 30.551378 loss_rnnt 14.072121 lr 0.00060505 rank 6
2022-12-04 02:12:06,447 DEBUG TRAIN Batch 8/1600 loss 20.225309 loss_att 23.397366 loss_ctc 38.880508 loss_rnnt 17.103539 lr 0.00060505 rank 7
2022-12-04 02:12:06,448 DEBUG TRAIN Batch 8/1600 loss 13.515016 loss_att 16.736439 loss_ctc 20.447260 loss_rnnt 11.946432 lr 0.00060470 rank 2
2022-12-04 02:12:06,450 DEBUG TRAIN Batch 8/1600 loss 9.088562 loss_att 14.791701 loss_ctc 19.619148 loss_rnnt 6.543855 lr 0.00060508 rank 5
2022-12-04 02:12:06,450 DEBUG TRAIN Batch 8/1600 loss 12.978689 loss_att 17.204313 loss_ctc 18.830818 loss_rnnt 11.353282 lr 0.00060497 rank 1
2022-12-04 02:12:06,453 DEBUG TRAIN Batch 8/1600 loss 15.657345 loss_att 20.662819 loss_ctc 26.622820 loss_rnnt 13.194186 lr 0.00060501 rank 3
2022-12-04 02:12:06,456 DEBUG TRAIN Batch 8/1600 loss 16.362146 loss_att 18.386976 loss_ctc 20.989174 loss_rnnt 15.340242 lr 0.00060510 rank 4
2022-12-04 02:13:18,768 DEBUG TRAIN Batch 8/1700 loss 23.675091 loss_att 33.262192 loss_ctc 36.932934 loss_rnnt 19.989960 lr 0.00060426 rank 2
2022-12-04 02:13:18,776 DEBUG TRAIN Batch 8/1700 loss 13.723494 loss_att 18.160505 loss_ctc 22.546404 loss_rnnt 11.659703 lr 0.00060466 rank 4
2022-12-04 02:13:18,780 DEBUG TRAIN Batch 8/1700 loss 39.599545 loss_att 43.946991 loss_ctc 61.584892 loss_rnnt 35.798676 lr 0.00060463 rank 5
2022-12-04 02:13:18,784 DEBUG TRAIN Batch 8/1700 loss 8.370743 loss_att 12.891779 loss_ctc 14.970291 loss_rnnt 6.586595 lr 0.00060460 rank 7
2022-12-04 02:13:18,785 DEBUG TRAIN Batch 8/1700 loss 21.312555 loss_att 28.443060 loss_ctc 35.673981 loss_rnnt 17.971600 lr 0.00060436 rank 0
2022-12-04 02:13:18,785 DEBUG TRAIN Batch 8/1700 loss 17.133760 loss_att 20.286697 loss_ctc 26.955730 loss_rnnt 15.193578 lr 0.00060453 rank 1
2022-12-04 02:13:18,786 DEBUG TRAIN Batch 8/1700 loss 13.014505 loss_att 19.014118 loss_ctc 20.643627 loss_rnnt 10.797367 lr 0.00060457 rank 3
2022-12-04 02:13:18,790 DEBUG TRAIN Batch 8/1700 loss 18.924248 loss_att 22.456125 loss_ctc 24.301956 loss_rnnt 17.500843 lr 0.00060460 rank 6
2022-12-04 02:14:32,597 DEBUG TRAIN Batch 8/1800 loss 18.333847 loss_att 22.042850 loss_ctc 31.210449 loss_rnnt 15.875165 lr 0.00060413 rank 3
2022-12-04 02:14:32,597 DEBUG TRAIN Batch 8/1800 loss 7.816851 loss_att 8.672762 loss_ctc 10.894876 loss_rnnt 7.235265 lr 0.00060409 rank 1
2022-12-04 02:14:32,597 DEBUG TRAIN Batch 8/1800 loss 11.184301 loss_att 15.128761 loss_ctc 25.617630 loss_rnnt 8.470966 lr 0.00060416 rank 6
2022-12-04 02:14:32,598 DEBUG TRAIN Batch 8/1800 loss 30.401381 loss_att 33.671947 loss_ctc 54.769592 loss_rnnt 26.498171 lr 0.00060392 rank 0
2022-12-04 02:14:32,603 DEBUG TRAIN Batch 8/1800 loss 23.172800 loss_att 26.752533 loss_ctc 35.307758 loss_rnnt 20.838860 lr 0.00060419 rank 5
2022-12-04 02:14:32,604 DEBUG TRAIN Batch 8/1800 loss 13.991530 loss_att 17.925352 loss_ctc 23.540009 loss_rnnt 11.931635 lr 0.00060421 rank 4
2022-12-04 02:14:32,604 DEBUG TRAIN Batch 8/1800 loss 23.707874 loss_att 27.848797 loss_ctc 47.581104 loss_rnnt 19.696590 lr 0.00060382 rank 2
2022-12-04 02:14:32,605 DEBUG TRAIN Batch 8/1800 loss 13.077464 loss_att 16.052698 loss_ctc 18.763977 loss_rnnt 11.724216 lr 0.00060416 rank 7
2022-12-04 02:15:44,207 DEBUG TRAIN Batch 8/1900 loss 9.138031 loss_att 11.058753 loss_ctc 16.985628 loss_rnnt 7.707541 lr 0.00060377 rank 4
2022-12-04 02:15:44,214 DEBUG TRAIN Batch 8/1900 loss 25.472195 loss_att 27.260763 loss_ctc 38.505219 loss_rnnt 23.376745 lr 0.00060372 rank 6
2022-12-04 02:15:44,214 DEBUG TRAIN Batch 8/1900 loss 17.699280 loss_att 19.636839 loss_ctc 28.068525 loss_rnnt 15.929202 lr 0.00060348 rank 0
2022-12-04 02:15:44,215 DEBUG TRAIN Batch 8/1900 loss 22.620640 loss_att 28.496824 loss_ctc 33.747032 loss_rnnt 19.961884 lr 0.00060365 rank 1
2022-12-04 02:15:44,215 DEBUG TRAIN Batch 8/1900 loss 16.310858 loss_att 16.252359 loss_ctc 24.819294 loss_rnnt 15.188098 lr 0.00060375 rank 5
2022-12-04 02:15:44,223 DEBUG TRAIN Batch 8/1900 loss 6.522787 loss_att 8.803785 loss_ctc 9.828121 loss_rnnt 5.625876 lr 0.00060338 rank 2
2022-12-04 02:15:44,223 DEBUG TRAIN Batch 8/1900 loss 20.484102 loss_att 23.230824 loss_ctc 36.152580 loss_rnnt 17.845629 lr 0.00060369 rank 3
2022-12-04 02:15:44,224 DEBUG TRAIN Batch 8/1900 loss 16.579868 loss_att 22.912643 loss_ctc 31.715019 loss_rnnt 13.295294 lr 0.00060372 rank 7
2022-12-04 02:16:57,567 DEBUG TRAIN Batch 8/2000 loss 18.736969 loss_att 21.746965 loss_ctc 26.547094 loss_rnnt 17.093620 lr 0.00060294 rank 2
2022-12-04 02:16:57,580 DEBUG TRAIN Batch 8/2000 loss 20.981346 loss_att 27.758198 loss_ctc 42.730373 loss_rnnt 16.726105 lr 0.00060325 rank 3
2022-12-04 02:16:57,581 DEBUG TRAIN Batch 8/2000 loss 18.065380 loss_att 20.269394 loss_ctc 37.112122 loss_rnnt 15.085012 lr 0.00060328 rank 6
2022-12-04 02:16:57,581 DEBUG TRAIN Batch 8/2000 loss 20.481359 loss_att 23.985357 loss_ctc 32.712078 loss_rnnt 18.149797 lr 0.00060328 rank 7
2022-12-04 02:16:57,587 DEBUG TRAIN Batch 8/2000 loss 10.906281 loss_att 14.623293 loss_ctc 22.574005 loss_rnnt 8.607183 lr 0.00060331 rank 5
2022-12-04 02:16:57,587 DEBUG TRAIN Batch 8/2000 loss 11.489117 loss_att 16.776279 loss_ctc 23.262533 loss_rnnt 8.861895 lr 0.00060321 rank 1
2022-12-04 02:16:57,587 DEBUG TRAIN Batch 8/2000 loss 8.650247 loss_att 12.875240 loss_ctc 13.514685 loss_rnnt 7.156656 lr 0.00060304 rank 0
2022-12-04 02:16:57,595 DEBUG TRAIN Batch 8/2000 loss 19.634508 loss_att 23.644316 loss_ctc 35.347122 loss_rnnt 16.737532 lr 0.00060333 rank 4
2022-12-04 02:18:10,436 DEBUG TRAIN Batch 8/2100 loss 17.411350 loss_att 19.276236 loss_ctc 30.020260 loss_rnnt 15.357184 lr 0.00060287 rank 5
2022-12-04 02:18:10,442 DEBUG TRAIN Batch 8/2100 loss 7.761196 loss_att 10.332479 loss_ctc 11.199586 loss_rnnt 6.788487 lr 0.00060284 rank 7
2022-12-04 02:18:10,454 DEBUG TRAIN Batch 8/2100 loss 17.559061 loss_att 29.834011 loss_ctc 29.449196 loss_rnnt 13.518719 lr 0.00060277 rank 1
2022-12-04 02:18:10,454 DEBUG TRAIN Batch 8/2100 loss 10.584188 loss_att 16.268866 loss_ctc 22.366936 loss_rnnt 7.876219 lr 0.00060281 rank 3
2022-12-04 02:18:10,455 DEBUG TRAIN Batch 8/2100 loss 18.213667 loss_att 18.860958 loss_ctc 25.801598 loss_rnnt 17.072485 lr 0.00060284 rank 6
2022-12-04 02:18:10,460 DEBUG TRAIN Batch 8/2100 loss 17.833479 loss_att 25.307405 loss_ctc 34.488964 loss_rnnt 14.117962 lr 0.00060250 rank 2
2022-12-04 02:18:10,460 DEBUG TRAIN Batch 8/2100 loss 8.557575 loss_att 13.516918 loss_ctc 19.962677 loss_rnnt 6.045026 lr 0.00060260 rank 0
2022-12-04 02:18:10,462 DEBUG TRAIN Batch 8/2100 loss 19.493389 loss_att 27.964622 loss_ctc 32.597237 loss_rnnt 16.051964 lr 0.00060290 rank 4
2022-12-04 02:19:22,653 DEBUG TRAIN Batch 8/2200 loss 13.949739 loss_att 19.731016 loss_ctc 23.608961 loss_rnnt 11.505588 lr 0.00060206 rank 2
2022-12-04 02:19:22,654 DEBUG TRAIN Batch 8/2200 loss 11.497597 loss_att 17.827250 loss_ctc 19.318039 loss_rnnt 9.188940 lr 0.00060216 rank 0
2022-12-04 02:19:22,654 DEBUG TRAIN Batch 8/2200 loss 11.175111 loss_att 15.491333 loss_ctc 17.965117 loss_rnnt 9.406532 lr 0.00060233 rank 1
2022-12-04 02:19:22,655 DEBUG TRAIN Batch 8/2200 loss 13.349040 loss_att 19.677620 loss_ctc 19.453917 loss_rnnt 11.269341 lr 0.00060241 rank 6
2022-12-04 02:19:22,655 DEBUG TRAIN Batch 8/2200 loss 16.411489 loss_att 21.233574 loss_ctc 26.606499 loss_rnnt 14.087738 lr 0.00060244 rank 5
2022-12-04 02:19:22,658 DEBUG TRAIN Batch 8/2200 loss 20.512335 loss_att 24.947176 loss_ctc 33.330200 loss_rnnt 17.916317 lr 0.00060237 rank 3
2022-12-04 02:19:22,665 DEBUG TRAIN Batch 8/2200 loss 28.790009 loss_att 31.558153 loss_ctc 54.000252 loss_rnnt 24.875015 lr 0.00060246 rank 4
2022-12-04 02:19:23,051 DEBUG TRAIN Batch 8/2200 loss 16.079885 loss_att 16.771221 loss_ctc 23.734299 loss_rnnt 14.921029 lr 0.00060241 rank 7
2022-12-04 02:20:34,958 DEBUG TRAIN Batch 8/2300 loss 10.718511 loss_att 19.386812 loss_ctc 18.470943 loss_rnnt 7.951192 lr 0.00060202 rank 4
2022-12-04 02:20:34,964 DEBUG TRAIN Batch 8/2300 loss 26.241201 loss_att 31.789795 loss_ctc 41.887398 loss_rnnt 23.045322 lr 0.00060197 rank 6
2022-12-04 02:20:34,969 DEBUG TRAIN Batch 8/2300 loss 22.128790 loss_att 26.435154 loss_ctc 35.890060 loss_rnnt 19.432680 lr 0.00060200 rank 5
2022-12-04 02:20:34,969 DEBUG TRAIN Batch 8/2300 loss 18.877110 loss_att 22.121864 loss_ctc 28.578487 loss_rnnt 16.934641 lr 0.00060193 rank 3
2022-12-04 02:20:34,971 DEBUG TRAIN Batch 8/2300 loss 22.065224 loss_att 27.643362 loss_ctc 40.076523 loss_rnnt 18.548092 lr 0.00060173 rank 0
2022-12-04 02:20:34,986 DEBUG TRAIN Batch 8/2300 loss 11.943652 loss_att 17.269611 loss_ctc 25.706179 loss_rnnt 9.043457 lr 0.00060197 rank 7
2022-12-04 02:20:34,994 DEBUG TRAIN Batch 8/2300 loss 11.763111 loss_att 18.027363 loss_ctc 25.668013 loss_rnnt 8.656274 lr 0.00060163 rank 2
2022-12-04 02:20:35,020 DEBUG TRAIN Batch 8/2300 loss 31.776447 loss_att 35.629345 loss_ctc 52.893513 loss_rnnt 28.190258 lr 0.00060189 rank 1
2022-12-04 02:21:46,706 DEBUG TRAIN Batch 8/2400 loss 14.146484 loss_att 17.905447 loss_ctc 23.035145 loss_rnnt 12.209536 lr 0.00060146 rank 1
2022-12-04 02:21:46,713 DEBUG TRAIN Batch 8/2400 loss 7.235444 loss_att 12.128667 loss_ctc 14.428332 loss_rnnt 5.297748 lr 0.00060119 rank 2
2022-12-04 02:21:46,719 DEBUG TRAIN Batch 8/2400 loss 6.595675 loss_att 13.214598 loss_ctc 15.372755 loss_rnnt 4.101613 lr 0.00060153 rank 6
2022-12-04 02:21:46,722 DEBUG TRAIN Batch 8/2400 loss 12.291500 loss_att 15.476051 loss_ctc 25.806133 loss_rnnt 9.852638 lr 0.00060156 rank 5
2022-12-04 02:21:46,725 DEBUG TRAIN Batch 8/2400 loss 23.585218 loss_att 27.930649 loss_ctc 39.442703 loss_rnnt 20.601799 lr 0.00060129 rank 0
2022-12-04 02:21:46,724 DEBUG TRAIN Batch 8/2400 loss 19.553017 loss_att 22.740927 loss_ctc 32.586658 loss_rnnt 17.177618 lr 0.00060150 rank 3
2022-12-04 02:21:46,736 DEBUG TRAIN Batch 8/2400 loss 17.097803 loss_att 20.356701 loss_ctc 27.496521 loss_rnnt 15.059526 lr 0.00060158 rank 4
2022-12-04 02:21:46,768 DEBUG TRAIN Batch 8/2400 loss 12.982897 loss_att 15.580873 loss_ctc 20.124983 loss_rnnt 11.511022 lr 0.00060153 rank 7
2022-12-04 02:23:02,014 DEBUG TRAIN Batch 8/2500 loss 5.476949 loss_att 8.474362 loss_ctc 12.379905 loss_rnnt 3.957072 lr 0.00060110 rank 6
2022-12-04 02:23:02,015 DEBUG TRAIN Batch 8/2500 loss 17.446135 loss_att 20.382008 loss_ctc 29.365149 loss_rnnt 15.269759 lr 0.00060086 rank 0
2022-12-04 02:23:02,021 DEBUG TRAIN Batch 8/2500 loss 22.715889 loss_att 25.067032 loss_ctc 42.314377 loss_rnnt 19.632526 lr 0.00060076 rank 2
2022-12-04 02:23:02,021 DEBUG TRAIN Batch 8/2500 loss 17.391363 loss_att 16.011000 loss_ctc 24.664062 loss_rnnt 16.697744 lr 0.00060106 rank 3
2022-12-04 02:23:02,023 DEBUG TRAIN Batch 8/2500 loss 22.264755 loss_att 27.271793 loss_ctc 30.933136 loss_rnnt 20.107563 lr 0.00060113 rank 5
2022-12-04 02:23:02,023 DEBUG TRAIN Batch 8/2500 loss 15.818735 loss_att 16.837387 loss_ctc 20.420984 loss_rnnt 15.001371 lr 0.00060102 rank 1
2022-12-04 02:23:02,032 DEBUG TRAIN Batch 8/2500 loss 26.125134 loss_att 29.937214 loss_ctc 39.051170 loss_rnnt 23.639248 lr 0.00060115 rank 4
2022-12-04 02:23:02,073 DEBUG TRAIN Batch 8/2500 loss 5.766867 loss_att 8.466209 loss_ctc 12.961142 loss_rnnt 4.267762 lr 0.00060110 rank 7
2022-12-04 02:24:13,251 DEBUG TRAIN Batch 8/2600 loss 12.358530 loss_att 16.389507 loss_ctc 17.890905 loss_rnnt 10.814684 lr 0.00060066 rank 6
2022-12-04 02:24:13,253 DEBUG TRAIN Batch 8/2600 loss 13.135981 loss_att 19.250643 loss_ctc 22.570389 loss_rnnt 10.655127 lr 0.00060069 rank 5
2022-12-04 02:24:13,257 DEBUG TRAIN Batch 8/2600 loss 8.834175 loss_att 14.795380 loss_ctc 14.734553 loss_rnnt 6.855217 lr 0.00060063 rank 3
2022-12-04 02:24:13,258 DEBUG TRAIN Batch 8/2600 loss 20.053537 loss_att 20.594652 loss_ctc 27.292187 loss_rnnt 18.980162 lr 0.00060059 rank 1
2022-12-04 02:24:13,259 DEBUG TRAIN Batch 8/2600 loss 11.327047 loss_att 16.489449 loss_ctc 20.830082 loss_rnnt 9.027495 lr 0.00060066 rank 7
2022-12-04 02:24:13,261 DEBUG TRAIN Batch 8/2600 loss 7.794665 loss_att 12.396606 loss_ctc 16.129425 loss_rnnt 5.762975 lr 0.00060033 rank 2
2022-12-04 02:24:13,263 DEBUG TRAIN Batch 8/2600 loss 11.170450 loss_att 13.725604 loss_ctc 16.877682 loss_rnnt 9.898455 lr 0.00060043 rank 0
2022-12-04 02:24:13,269 DEBUG TRAIN Batch 8/2600 loss 8.988954 loss_att 8.650732 loss_ctc 11.715888 loss_rnnt 8.693007 lr 0.00060072 rank 4
2022-12-04 02:25:24,607 DEBUG TRAIN Batch 8/2700 loss 19.177944 loss_att 22.656635 loss_ctc 33.080574 loss_rnnt 16.628523 lr 0.00059999 rank 0
2022-12-04 02:25:24,615 DEBUG TRAIN Batch 8/2700 loss 12.676251 loss_att 17.327091 loss_ctc 22.338314 loss_rnnt 10.457808 lr 0.00060020 rank 3
2022-12-04 02:25:24,616 DEBUG TRAIN Batch 8/2700 loss 19.322229 loss_att 21.904909 loss_ctc 29.329514 loss_rnnt 17.471390 lr 0.00060016 rank 1
2022-12-04 02:25:24,620 DEBUG TRAIN Batch 8/2700 loss 34.254425 loss_att 39.535187 loss_ctc 55.768669 loss_rnnt 30.329708 lr 0.00059989 rank 2
2022-12-04 02:25:24,622 DEBUG TRAIN Batch 8/2700 loss 9.441167 loss_att 14.835754 loss_ctc 20.973152 loss_rnnt 6.824651 lr 0.00060023 rank 6
2022-12-04 02:25:24,623 DEBUG TRAIN Batch 8/2700 loss 16.906849 loss_att 22.783222 loss_ctc 27.179180 loss_rnnt 14.361929 lr 0.00060026 rank 5
2022-12-04 02:25:24,623 DEBUG TRAIN Batch 8/2700 loss 7.035373 loss_att 12.274395 loss_ctc 17.211294 loss_rnnt 4.630779 lr 0.00060023 rank 7
2022-12-04 02:25:24,627 DEBUG TRAIN Batch 8/2700 loss 17.692921 loss_att 29.883879 loss_ctc 22.781301 loss_rnnt 14.576278 lr 0.00060028 rank 4
2022-12-04 02:26:37,224 DEBUG TRAIN Batch 8/2800 loss 29.473499 loss_att 34.031837 loss_ctc 41.138081 loss_rnnt 27.006554 lr 0.00059983 rank 5
2022-12-04 02:26:37,227 DEBUG TRAIN Batch 8/2800 loss 26.614845 loss_att 31.658691 loss_ctc 46.443840 loss_rnnt 22.962210 lr 0.00059946 rank 2
2022-12-04 02:26:37,227 DEBUG TRAIN Batch 8/2800 loss 31.055492 loss_att 38.223183 loss_ctc 59.554485 loss_rnnt 25.822088 lr 0.00059980 rank 6
2022-12-04 02:26:37,231 DEBUG TRAIN Batch 8/2800 loss 8.702161 loss_att 10.437356 loss_ctc 14.782721 loss_rnnt 7.544380 lr 0.00059956 rank 0
2022-12-04 02:26:37,233 DEBUG TRAIN Batch 8/2800 loss 17.147484 loss_att 20.727468 loss_ctc 28.968113 loss_rnnt 14.855402 lr 0.00059976 rank 3
2022-12-04 02:26:37,239 DEBUG TRAIN Batch 8/2800 loss 5.612937 loss_att 9.504614 loss_ctc 14.369963 loss_rnnt 3.666998 lr 0.00059985 rank 4
2022-12-04 02:26:37,251 DEBUG TRAIN Batch 8/2800 loss 23.532011 loss_att 28.174706 loss_ctc 36.052254 loss_rnnt 20.934107 lr 0.00059980 rank 7
2022-12-04 02:26:37,273 DEBUG TRAIN Batch 8/2800 loss 10.817799 loss_att 15.703946 loss_ctc 23.974247 loss_rnnt 8.086376 lr 0.00059973 rank 1
2022-12-04 02:27:49,842 DEBUG TRAIN Batch 8/2900 loss 11.361635 loss_att 14.939701 loss_ctc 18.960209 loss_rnnt 9.632879 lr 0.00059937 rank 6
2022-12-04 02:27:49,846 DEBUG TRAIN Batch 8/2900 loss 9.294734 loss_att 11.967768 loss_ctc 14.811010 loss_rnnt 8.024624 lr 0.00059929 rank 1
2022-12-04 02:27:49,846 DEBUG TRAIN Batch 8/2900 loss 12.264318 loss_att 17.928934 loss_ctc 25.673826 loss_rnnt 9.343462 lr 0.00059913 rank 0
2022-12-04 02:27:49,847 DEBUG TRAIN Batch 8/2900 loss 18.727654 loss_att 20.731098 loss_ctc 35.996292 loss_rnnt 16.024479 lr 0.00059940 rank 5
2022-12-04 02:27:49,849 DEBUG TRAIN Batch 8/2900 loss 19.746265 loss_att 22.808025 loss_ctc 35.674812 loss_rnnt 17.010107 lr 0.00059933 rank 3
2022-12-04 02:27:49,850 DEBUG TRAIN Batch 8/2900 loss 10.552361 loss_att 13.251578 loss_ctc 17.781303 loss_rnnt 9.048658 lr 0.00059903 rank 2
2022-12-04 02:27:49,851 DEBUG TRAIN Batch 8/2900 loss 17.409887 loss_att 22.438967 loss_ctc 31.808563 loss_rnnt 14.484247 lr 0.00059937 rank 7
2022-12-04 02:27:49,855 DEBUG TRAIN Batch 8/2900 loss 6.356606 loss_att 11.056379 loss_ctc 9.923338 loss_rnnt 4.941088 lr 0.00059942 rank 4
2022-12-04 02:29:01,339 DEBUG TRAIN Batch 8/3000 loss 18.017477 loss_att 18.715017 loss_ctc 27.268085 loss_rnnt 16.644554 lr 0.00059890 rank 3
2022-12-04 02:29:01,341 DEBUG TRAIN Batch 8/3000 loss 20.651609 loss_att 25.804546 loss_ctc 30.866337 loss_rnnt 18.259058 lr 0.00059894 rank 6
2022-12-04 02:29:01,342 DEBUG TRAIN Batch 8/3000 loss 13.532191 loss_att 17.720024 loss_ctc 26.489090 loss_rnnt 10.967039 lr 0.00059870 rank 0
2022-12-04 02:29:01,346 DEBUG TRAIN Batch 8/3000 loss 11.728579 loss_att 18.834511 loss_ctc 19.641960 loss_rnnt 9.252274 lr 0.00059886 rank 1
2022-12-04 02:29:01,346 DEBUG TRAIN Batch 8/3000 loss 13.949769 loss_att 19.912739 loss_ctc 23.468060 loss_rnnt 11.488070 lr 0.00059894 rank 7
2022-12-04 02:29:01,347 DEBUG TRAIN Batch 8/3000 loss 19.755203 loss_att 21.601131 loss_ctc 27.438009 loss_rnnt 18.361645 lr 0.00059899 rank 4
2022-12-04 02:29:01,349 DEBUG TRAIN Batch 8/3000 loss 18.378252 loss_att 21.338047 loss_ctc 28.162287 loss_rnnt 16.481756 lr 0.00059897 rank 5
2022-12-04 02:29:01,392 DEBUG TRAIN Batch 8/3000 loss 20.834305 loss_att 30.475254 loss_ctc 35.552238 loss_rnnt 16.943722 lr 0.00059860 rank 2
2022-12-04 02:30:13,582 DEBUG TRAIN Batch 8/3100 loss 6.568804 loss_att 6.910684 loss_ctc 10.856965 loss_rnnt 5.928673 lr 0.00059847 rank 3
2022-12-04 02:30:13,584 DEBUG TRAIN Batch 8/3100 loss 15.149633 loss_att 19.227024 loss_ctc 30.271835 loss_rnnt 12.317861 lr 0.00059851 rank 6
2022-12-04 02:30:13,584 DEBUG TRAIN Batch 8/3100 loss 9.319804 loss_att 10.437844 loss_ctc 14.671306 loss_rnnt 8.382663 lr 0.00059844 rank 1
2022-12-04 02:30:13,585 DEBUG TRAIN Batch 8/3100 loss 15.033378 loss_att 18.456224 loss_ctc 23.368855 loss_rnnt 13.237411 lr 0.00059827 rank 0
2022-12-04 02:30:13,587 DEBUG TRAIN Batch 8/3100 loss 13.244748 loss_att 16.129517 loss_ctc 20.658474 loss_rnnt 11.679297 lr 0.00059854 rank 5
2022-12-04 02:30:13,588 DEBUG TRAIN Batch 8/3100 loss 11.386805 loss_att 14.461334 loss_ctc 22.440428 loss_rnnt 9.298082 lr 0.00059851 rank 7
2022-12-04 02:30:13,589 DEBUG TRAIN Batch 8/3100 loss 12.087518 loss_att 17.626408 loss_ctc 21.341629 loss_rnnt 9.745858 lr 0.00059817 rank 2
2022-12-04 02:30:13,626 DEBUG TRAIN Batch 8/3100 loss 10.649864 loss_att 14.748192 loss_ctc 19.304834 loss_rnnt 8.676202 lr 0.00059856 rank 4
2022-12-04 02:31:27,970 DEBUG TRAIN Batch 8/3200 loss 11.928349 loss_att 15.319711 loss_ctc 23.997519 loss_rnnt 9.640855 lr 0.00059805 rank 3
2022-12-04 02:31:27,975 DEBUG TRAIN Batch 8/3200 loss 13.134610 loss_att 14.828745 loss_ctc 17.522894 loss_rnnt 12.210678 lr 0.00059784 rank 0
2022-12-04 02:31:27,975 DEBUG TRAIN Batch 8/3200 loss 8.056962 loss_att 11.449408 loss_ctc 14.280382 loss_rnnt 6.548684 lr 0.00059813 rank 4
2022-12-04 02:31:27,976 DEBUG TRAIN Batch 8/3200 loss 14.734345 loss_att 19.360193 loss_ctc 28.061033 loss_rnnt 12.032284 lr 0.00059811 rank 5
2022-12-04 02:31:27,976 DEBUG TRAIN Batch 8/3200 loss 23.498039 loss_att 29.276142 loss_ctc 44.570648 loss_rnnt 19.532736 lr 0.00059808 rank 6
2022-12-04 02:31:27,978 DEBUG TRAIN Batch 8/3200 loss 15.381866 loss_att 19.557789 loss_ctc 25.917940 loss_rnnt 13.141872 lr 0.00059775 rank 2
2022-12-04 02:31:28,003 DEBUG TRAIN Batch 8/3200 loss 8.215378 loss_att 11.334181 loss_ctc 15.201017 loss_rnnt 6.660198 lr 0.00059808 rank 7
2022-12-04 02:31:28,019 DEBUG TRAIN Batch 8/3200 loss 6.699554 loss_att 11.372198 loss_ctc 17.313398 loss_rnnt 4.349846 lr 0.00059801 rank 1
2022-12-04 02:32:40,429 DEBUG TRAIN Batch 8/3300 loss 13.409531 loss_att 14.288014 loss_ctc 15.560217 loss_rnnt 12.947075 lr 0.00059758 rank 1
2022-12-04 02:32:40,438 DEBUG TRAIN Batch 8/3300 loss 43.712357 loss_att 46.566181 loss_ctc 63.807552 loss_rnnt 40.462231 lr 0.00059742 rank 0
2022-12-04 02:32:40,447 DEBUG TRAIN Batch 8/3300 loss 20.904385 loss_att 23.669947 loss_ctc 31.132231 loss_rnnt 18.987562 lr 0.00059762 rank 3
2022-12-04 02:32:40,447 DEBUG TRAIN Batch 8/3300 loss 11.511786 loss_att 16.511063 loss_ctc 17.939499 loss_rnnt 9.654902 lr 0.00059765 rank 7
2022-12-04 02:32:40,448 DEBUG TRAIN Batch 8/3300 loss 10.488172 loss_att 14.851183 loss_ctc 22.093475 loss_rnnt 8.068195 lr 0.00059765 rank 6
2022-12-04 02:32:40,449 DEBUG TRAIN Batch 8/3300 loss 12.360910 loss_att 14.007856 loss_ctc 18.125540 loss_rnnt 11.262903 lr 0.00059732 rank 2
2022-12-04 02:32:40,449 DEBUG TRAIN Batch 8/3300 loss 15.494553 loss_att 20.657761 loss_ctc 14.145569 loss_rnnt 14.641776 lr 0.00059770 rank 4
2022-12-04 02:32:40,454 DEBUG TRAIN Batch 8/3300 loss 17.560596 loss_att 20.149864 loss_ctc 25.572250 loss_rnnt 15.974522 lr 0.00059768 rank 5
2022-12-04 02:33:51,832 DEBUG TRAIN Batch 8/3400 loss 18.591108 loss_att 21.116226 loss_ctc 31.071133 loss_rnnt 16.422081 lr 0.00059723 rank 6
2022-12-04 02:33:51,834 DEBUG TRAIN Batch 8/3400 loss 22.523067 loss_att 26.622171 loss_ctc 30.716084 loss_rnnt 20.610844 lr 0.00059719 rank 3
2022-12-04 02:33:51,835 DEBUG TRAIN Batch 8/3400 loss 13.822610 loss_att 19.671558 loss_ctc 20.003162 loss_rnnt 11.828745 lr 0.00059726 rank 5
2022-12-04 02:33:51,835 DEBUG TRAIN Batch 8/3400 loss 16.158861 loss_att 25.365540 loss_ctc 22.987806 loss_rnnt 13.407000 lr 0.00059699 rank 0
2022-12-04 02:33:51,839 DEBUG TRAIN Batch 8/3400 loss 29.386734 loss_att 34.698608 loss_ctc 52.063034 loss_rnnt 25.300850 lr 0.00059715 rank 1
2022-12-04 02:33:51,841 DEBUG TRAIN Batch 8/3400 loss 18.242523 loss_att 21.396847 loss_ctc 32.317177 loss_rnnt 15.735037 lr 0.00059723 rank 7
2022-12-04 02:33:51,842 DEBUG TRAIN Batch 8/3400 loss 12.127232 loss_att 17.969536 loss_ctc 23.658546 loss_rnnt 9.421262 lr 0.00059728 rank 4
2022-12-04 02:33:51,843 DEBUG TRAIN Batch 8/3400 loss 16.016890 loss_att 17.677895 loss_ctc 29.484388 loss_rnnt 13.889023 lr 0.00059689 rank 2
2022-12-04 02:35:03,935 DEBUG TRAIN Batch 8/3500 loss 9.623105 loss_att 15.943884 loss_ctc 18.483698 loss_rnnt 7.177537 lr 0.00059680 rank 6
2022-12-04 02:35:03,936 DEBUG TRAIN Batch 8/3500 loss 7.535488 loss_att 10.714006 loss_ctc 14.387512 loss_rnnt 5.986181 lr 0.00059657 rank 0
2022-12-04 02:35:03,936 DEBUG TRAIN Batch 8/3500 loss 19.543468 loss_att 22.424871 loss_ctc 31.776548 loss_rnnt 17.336109 lr 0.00059673 rank 1
2022-12-04 02:35:03,938 DEBUG TRAIN Batch 8/3500 loss 9.266840 loss_att 14.416048 loss_ctc 13.623655 loss_rnnt 7.656088 lr 0.00059677 rank 3
2022-12-04 02:35:03,944 DEBUG TRAIN Batch 8/3500 loss 11.439962 loss_att 16.142651 loss_ctc 21.321655 loss_rnnt 9.181866 lr 0.00059647 rank 2
2022-12-04 02:35:03,949 DEBUG TRAIN Batch 8/3500 loss 25.627119 loss_att 27.253555 loss_ctc 32.272881 loss_rnnt 24.415730 lr 0.00059685 rank 4
2022-12-04 02:35:03,967 DEBUG TRAIN Batch 8/3500 loss 13.317894 loss_att 17.069534 loss_ctc 22.915998 loss_rnnt 11.287818 lr 0.00059683 rank 5
2022-12-04 02:35:03,967 DEBUG TRAIN Batch 8/3500 loss 18.399130 loss_att 25.902998 loss_ctc 35.344086 loss_rnnt 14.639028 lr 0.00059680 rank 7
2022-12-04 02:36:17,470 DEBUG TRAIN Batch 8/3600 loss 13.054869 loss_att 17.463606 loss_ctc 21.428026 loss_rnnt 11.056701 lr 0.00059634 rank 3
2022-12-04 02:36:17,471 DEBUG TRAIN Batch 8/3600 loss 19.887794 loss_att 25.994305 loss_ctc 34.631874 loss_rnnt 16.700615 lr 0.00059641 rank 5
2022-12-04 02:36:17,472 DEBUG TRAIN Batch 8/3600 loss 22.089495 loss_att 26.097464 loss_ctc 30.052679 loss_rnnt 20.226143 lr 0.00059614 rank 0
2022-12-04 02:36:17,472 DEBUG TRAIN Batch 8/3600 loss 16.595051 loss_att 21.312292 loss_ctc 31.151386 loss_rnnt 13.710756 lr 0.00059638 rank 6
2022-12-04 02:36:17,474 DEBUG TRAIN Batch 8/3600 loss 26.615450 loss_att 29.108418 loss_ctc 40.565495 loss_rnnt 24.256851 lr 0.00059630 rank 1
2022-12-04 02:36:17,476 DEBUG TRAIN Batch 8/3600 loss 13.226843 loss_att 16.820446 loss_ctc 23.013510 loss_rnnt 11.203232 lr 0.00059605 rank 2
2022-12-04 02:36:17,483 DEBUG TRAIN Batch 8/3600 loss 18.025124 loss_att 20.549007 loss_ctc 26.112484 loss_rnnt 16.442032 lr 0.00059643 rank 4
2022-12-04 02:36:17,483 DEBUG TRAIN Batch 8/3600 loss 14.502220 loss_att 20.154789 loss_ctc 27.085323 loss_rnnt 11.693960 lr 0.00059638 rank 7
2022-12-04 02:37:29,796 DEBUG TRAIN Batch 8/3700 loss 11.656068 loss_att 14.636722 loss_ctc 17.848053 loss_rnnt 10.234339 lr 0.00059572 rank 0
2022-12-04 02:37:29,797 DEBUG TRAIN Batch 8/3700 loss 15.802777 loss_att 17.868469 loss_ctc 24.666859 loss_rnnt 14.207762 lr 0.00059592 rank 3
2022-12-04 02:37:29,800 DEBUG TRAIN Batch 8/3700 loss 10.109046 loss_att 15.002253 loss_ctc 19.347878 loss_rnnt 7.898560 lr 0.00059595 rank 7
2022-12-04 02:37:29,800 DEBUG TRAIN Batch 8/3700 loss 15.075084 loss_att 16.353601 loss_ctc 24.933834 loss_rnnt 13.504880 lr 0.00059595 rank 6
2022-12-04 02:37:29,802 DEBUG TRAIN Batch 8/3700 loss 12.365486 loss_att 14.849901 loss_ctc 22.001762 loss_rnnt 10.583765 lr 0.00059588 rank 1
2022-12-04 02:37:29,803 DEBUG TRAIN Batch 8/3700 loss 10.847230 loss_att 13.488840 loss_ctc 17.346649 loss_rnnt 9.452318 lr 0.00059562 rank 2
2022-12-04 02:37:29,809 DEBUG TRAIN Batch 8/3700 loss 16.969105 loss_att 19.923117 loss_ctc 26.916306 loss_rnnt 15.052010 lr 0.00059600 rank 4
2022-12-04 02:37:29,843 DEBUG TRAIN Batch 8/3700 loss 17.146988 loss_att 21.125029 loss_ctc 25.888067 loss_rnnt 15.185903 lr 0.00059598 rank 5
2022-12-04 02:38:41,685 DEBUG TRAIN Batch 8/3800 loss 11.813240 loss_att 14.940235 loss_ctc 16.857561 loss_rnnt 10.515265 lr 0.00059556 rank 5
2022-12-04 02:38:41,687 DEBUG TRAIN Batch 8/3800 loss 10.884475 loss_att 13.873226 loss_ctc 17.576237 loss_rnnt 9.394489 lr 0.00059520 rank 2
2022-12-04 02:38:41,687 DEBUG TRAIN Batch 8/3800 loss 27.971600 loss_att 33.264797 loss_ctc 38.302925 loss_rnnt 25.535450 lr 0.00059550 rank 3
2022-12-04 02:38:41,688 DEBUG TRAIN Batch 8/3800 loss 15.787289 loss_att 17.127607 loss_ctc 20.725258 loss_rnnt 14.860828 lr 0.00059553 rank 6
2022-12-04 02:38:41,689 DEBUG TRAIN Batch 8/3800 loss 11.281419 loss_att 11.548136 loss_ctc 16.317560 loss_rnnt 10.556589 lr 0.00059553 rank 7
2022-12-04 02:38:41,692 DEBUG TRAIN Batch 8/3800 loss 11.153229 loss_att 15.330588 loss_ctc 20.071466 loss_rnnt 9.128658 lr 0.00059530 rank 0
2022-12-04 02:38:41,693 DEBUG TRAIN Batch 8/3800 loss 11.411583 loss_att 15.466425 loss_ctc 21.456150 loss_rnnt 9.261338 lr 0.00059558 rank 4
2022-12-04 02:38:41,740 DEBUG TRAIN Batch 8/3800 loss 6.102092 loss_att 13.603465 loss_ctc 13.418567 loss_rnnt 3.626287 lr 0.00059546 rank 1
2022-12-04 02:39:56,083 DEBUG TRAIN Batch 8/3900 loss 8.733486 loss_att 13.963107 loss_ctc 19.287682 loss_rnnt 6.280336 lr 0.00059514 rank 5
2022-12-04 02:39:56,086 DEBUG TRAIN Batch 8/3900 loss 15.358271 loss_att 18.979761 loss_ctc 27.451538 loss_rnnt 13.021537 lr 0.00059507 rank 3
2022-12-04 02:39:56,090 DEBUG TRAIN Batch 8/3900 loss 24.225487 loss_att 25.607662 loss_ctc 37.004326 loss_rnnt 22.245207 lr 0.00059478 rank 2
2022-12-04 02:39:56,089 DEBUG TRAIN Batch 8/3900 loss 7.929580 loss_att 14.371435 loss_ctc 13.770563 loss_rnnt 5.862411 lr 0.00059504 rank 1
2022-12-04 02:39:56,090 DEBUG TRAIN Batch 8/3900 loss 7.310980 loss_att 10.193089 loss_ctc 14.350891 loss_rnnt 5.795903 lr 0.00059488 rank 0
2022-12-04 02:39:56,091 DEBUG TRAIN Batch 8/3900 loss 20.304268 loss_att 22.009703 loss_ctc 28.582670 loss_rnnt 18.859392 lr 0.00059511 rank 7
2022-12-04 02:39:56,094 DEBUG TRAIN Batch 8/3900 loss 10.619299 loss_att 16.736786 loss_ctc 17.316320 loss_rnnt 8.502865 lr 0.00059516 rank 4
2022-12-04 02:39:56,103 DEBUG TRAIN Batch 8/3900 loss 14.216825 loss_att 19.044033 loss_ctc 22.338699 loss_rnnt 12.168468 lr 0.00059511 rank 6
2022-12-04 02:41:08,078 DEBUG TRAIN Batch 8/4000 loss 12.847578 loss_att 23.029987 loss_ctc 18.193981 loss_rnnt 10.098242 lr 0.00059469 rank 6
2022-12-04 02:41:08,078 DEBUG TRAIN Batch 8/4000 loss 13.425550 loss_att 20.207014 loss_ctc 28.971825 loss_rnnt 9.996420 lr 0.00059446 rank 0
2022-12-04 02:41:08,081 DEBUG TRAIN Batch 8/4000 loss 8.634531 loss_att 11.438112 loss_ctc 15.158687 loss_rnnt 7.203928 lr 0.00059465 rank 3
2022-12-04 02:41:08,082 DEBUG TRAIN Batch 8/4000 loss 20.102804 loss_att 24.800911 loss_ctc 27.693169 loss_rnnt 18.151134 lr 0.00059469 rank 7
2022-12-04 02:41:08,085 DEBUG TRAIN Batch 8/4000 loss 10.928781 loss_att 12.557614 loss_ctc 19.451878 loss_rnnt 9.466601 lr 0.00059461 rank 1
2022-12-04 02:41:08,085 DEBUG TRAIN Batch 8/4000 loss 19.225195 loss_att 25.470522 loss_ctc 36.214348 loss_rnnt 15.710910 lr 0.00059472 rank 5
2022-12-04 02:41:08,088 DEBUG TRAIN Batch 8/4000 loss 13.730081 loss_att 17.855961 loss_ctc 19.586914 loss_rnnt 12.123993 lr 0.00059436 rank 2
2022-12-04 02:41:08,091 DEBUG TRAIN Batch 8/4000 loss 17.572071 loss_att 27.175667 loss_ctc 30.541332 loss_rnnt 13.922117 lr 0.00059474 rank 4
2022-12-04 02:42:20,824 DEBUG TRAIN Batch 8/4100 loss 15.539063 loss_att 19.242630 loss_ctc 23.627522 loss_rnnt 13.719889 lr 0.00059423 rank 3
2022-12-04 02:42:20,823 DEBUG TRAIN Batch 8/4100 loss 16.942205 loss_att 21.347857 loss_ctc 25.399925 loss_rnnt 14.933379 lr 0.00059427 rank 7
2022-12-04 02:42:20,824 DEBUG TRAIN Batch 8/4100 loss 23.150658 loss_att 25.695107 loss_ctc 40.870228 loss_rnnt 20.279156 lr 0.00059427 rank 6
2022-12-04 02:42:20,825 DEBUG TRAIN Batch 8/4100 loss 16.147192 loss_att 23.029413 loss_ctc 34.902348 loss_rnnt 12.270060 lr 0.00059430 rank 5
2022-12-04 02:42:20,829 DEBUG TRAIN Batch 8/4100 loss 36.696255 loss_att 37.791473 loss_ctc 60.581158 loss_rnnt 33.292557 lr 0.00059404 rank 0
2022-12-04 02:42:20,831 DEBUG TRAIN Batch 8/4100 loss 14.577673 loss_att 18.587395 loss_ctc 22.439344 loss_rnnt 12.727507 lr 0.00059419 rank 1
2022-12-04 02:42:20,834 DEBUG TRAIN Batch 8/4100 loss 13.369229 loss_att 17.824993 loss_ctc 21.509361 loss_rnnt 11.392725 lr 0.00059394 rank 2
2022-12-04 02:42:20,875 DEBUG TRAIN Batch 8/4100 loss 14.568677 loss_att 19.295952 loss_ctc 28.781792 loss_rnnt 11.728140 lr 0.00059432 rank 4
2022-12-04 02:43:33,171 DEBUG TRAIN Batch 8/4200 loss 15.714122 loss_att 15.388348 loss_ctc 23.993441 loss_rnnt 14.675367 lr 0.00059388 rank 5
2022-12-04 02:43:33,176 DEBUG TRAIN Batch 8/4200 loss 8.990705 loss_att 12.739311 loss_ctc 15.360611 loss_rnnt 7.391664 lr 0.00059385 rank 6
2022-12-04 02:43:33,178 DEBUG TRAIN Batch 8/4200 loss 6.357771 loss_att 11.752731 loss_ctc 13.380510 loss_rnnt 4.342413 lr 0.00059352 rank 2
2022-12-04 02:43:33,187 DEBUG TRAIN Batch 8/4200 loss 23.654926 loss_att 24.956940 loss_ctc 33.068047 loss_rnnt 22.139439 lr 0.00059378 rank 1
2022-12-04 02:43:33,188 DEBUG TRAIN Batch 8/4200 loss 23.995590 loss_att 28.968893 loss_ctc 44.819908 loss_rnnt 20.224354 lr 0.00059362 rank 0
2022-12-04 02:43:33,193 DEBUG TRAIN Batch 8/4200 loss 16.161076 loss_att 24.725372 loss_ctc 33.903366 loss_rnnt 12.082575 lr 0.00059385 rank 7
2022-12-04 02:43:33,194 DEBUG TRAIN Batch 8/4200 loss 11.477875 loss_att 15.177563 loss_ctc 18.254875 loss_rnnt 9.834337 lr 0.00059381 rank 3
2022-12-04 02:43:33,212 DEBUG TRAIN Batch 8/4200 loss 12.793762 loss_att 17.908266 loss_ctc 23.125439 loss_rnnt 10.393304 lr 0.00059390 rank 4
2022-12-04 02:44:47,769 DEBUG TRAIN Batch 8/4300 loss 21.830061 loss_att 22.089325 loss_ctc 31.117966 loss_rnnt 20.539822 lr 0.00059340 rank 3
2022-12-04 02:44:47,769 DEBUG TRAIN Batch 8/4300 loss 13.114886 loss_att 15.869877 loss_ctc 21.979906 loss_rnnt 11.381886 lr 0.00059336 rank 1
2022-12-04 02:44:47,769 DEBUG TRAIN Batch 8/4300 loss 19.158773 loss_att 22.546516 loss_ctc 33.330517 loss_rnnt 16.591660 lr 0.00059346 rank 5
2022-12-04 02:44:47,769 DEBUG TRAIN Batch 8/4300 loss 7.676335 loss_att 11.662019 loss_ctc 17.310801 loss_rnnt 5.594603 lr 0.00059348 rank 4
2022-12-04 02:44:47,770 DEBUG TRAIN Batch 8/4300 loss 21.506432 loss_att 24.943563 loss_ctc 28.090561 loss_rnnt 19.941122 lr 0.00059343 rank 6
2022-12-04 02:44:47,770 DEBUG TRAIN Batch 8/4300 loss 23.332550 loss_att 26.026682 loss_ctc 37.695747 loss_rnnt 20.878630 lr 0.00059343 rank 7
2022-12-04 02:44:47,771 DEBUG TRAIN Batch 8/4300 loss 12.736135 loss_att 17.307289 loss_ctc 21.015985 loss_rnnt 10.717924 lr 0.00059320 rank 0
2022-12-04 02:44:47,776 DEBUG TRAIN Batch 8/4300 loss 14.488078 loss_att 19.217686 loss_ctc 22.727894 loss_rnnt 12.443514 lr 0.00059310 rank 2
2022-12-04 02:46:00,130 DEBUG TRAIN Batch 8/4400 loss 6.630755 loss_att 12.726217 loss_ctc 14.834051 loss_rnnt 4.317890 lr 0.00059298 rank 3
2022-12-04 02:46:00,141 DEBUG TRAIN Batch 8/4400 loss 25.459152 loss_att 27.314278 loss_ctc 34.395844 loss_rnnt 23.896568 lr 0.00059278 rank 0
2022-12-04 02:46:00,144 DEBUG TRAIN Batch 8/4400 loss 8.561783 loss_att 11.163754 loss_ctc 14.391437 loss_rnnt 7.264101 lr 0.00059294 rank 1
2022-12-04 02:46:00,147 DEBUG TRAIN Batch 8/4400 loss 15.213651 loss_att 15.379532 loss_ctc 23.244823 loss_rnnt 14.109653 lr 0.00059304 rank 5
2022-12-04 02:46:00,147 DEBUG TRAIN Batch 8/4400 loss 11.393867 loss_att 15.099350 loss_ctc 16.506018 loss_rnnt 9.971152 lr 0.00059301 rank 6
2022-12-04 02:46:00,151 DEBUG TRAIN Batch 8/4400 loss 16.768307 loss_att 20.498333 loss_ctc 25.909256 loss_rnnt 14.803507 lr 0.00059269 rank 2
2022-12-04 02:46:00,155 DEBUG TRAIN Batch 8/4400 loss 11.684017 loss_att 15.655413 loss_ctc 21.607836 loss_rnnt 9.566562 lr 0.00059306 rank 4
2022-12-04 02:46:00,156 DEBUG TRAIN Batch 8/4400 loss 14.864923 loss_att 15.254358 loss_ctc 26.065388 loss_rnnt 13.293641 lr 0.00059301 rank 7
2022-12-04 02:47:11,973 DEBUG TRAIN Batch 8/4500 loss 10.673204 loss_att 17.767668 loss_ctc 27.484161 loss_rnnt 7.012852 lr 0.00059262 rank 5
2022-12-04 02:47:11,979 DEBUG TRAIN Batch 8/4500 loss 13.531425 loss_att 22.269684 loss_ctc 23.060944 loss_rnnt 10.513170 lr 0.00059259 rank 6
2022-12-04 02:47:11,980 DEBUG TRAIN Batch 8/4500 loss 16.060749 loss_att 18.316805 loss_ctc 24.584373 loss_rnnt 14.473056 lr 0.00059256 rank 3
2022-12-04 02:47:11,980 DEBUG TRAIN Batch 8/4500 loss 11.436872 loss_att 15.244736 loss_ctc 14.355696 loss_rnnt 10.286121 lr 0.00059252 rank 1
2022-12-04 02:47:11,981 DEBUG TRAIN Batch 8/4500 loss 18.232471 loss_att 20.162228 loss_ctc 26.221268 loss_rnnt 16.781347 lr 0.00059237 rank 0
2022-12-04 02:47:11,982 DEBUG TRAIN Batch 8/4500 loss 10.789036 loss_att 14.068523 loss_ctc 15.693034 loss_rnnt 9.479271 lr 0.00059259 rank 7
2022-12-04 02:47:11,986 DEBUG TRAIN Batch 8/4500 loss 19.030149 loss_att 20.897921 loss_ctc 29.479048 loss_rnnt 17.263411 lr 0.00059227 rank 2
2022-12-04 02:47:11,987 DEBUG TRAIN Batch 8/4500 loss 9.257565 loss_att 17.684053 loss_ctc 14.148111 loss_rnnt 6.920196 lr 0.00059264 rank 4
2022-12-04 02:48:25,368 DEBUG TRAIN Batch 8/4600 loss 22.801647 loss_att 28.003176 loss_ctc 40.151428 loss_rnnt 19.448036 lr 0.00059185 rank 2
2022-12-04 02:48:25,374 DEBUG TRAIN Batch 8/4600 loss 18.810532 loss_att 20.269758 loss_ctc 30.755688 loss_rnnt 16.925999 lr 0.00059218 rank 6
2022-12-04 02:48:25,375 DEBUG TRAIN Batch 8/4600 loss 12.414110 loss_att 13.526070 loss_ctc 19.981886 loss_rnnt 11.182681 lr 0.00059221 rank 5
2022-12-04 02:48:25,375 DEBUG TRAIN Batch 8/4600 loss 15.112720 loss_att 18.316845 loss_ctc 31.345085 loss_rnnt 12.307578 lr 0.00059215 rank 3
2022-12-04 02:48:25,379 DEBUG TRAIN Batch 8/4600 loss 11.828153 loss_att 15.963873 loss_ctc 18.478054 loss_rnnt 10.114355 lr 0.00059195 rank 0
2022-12-04 02:48:25,397 DEBUG TRAIN Batch 8/4600 loss 17.374683 loss_att 19.437643 loss_ctc 24.972591 loss_rnnt 15.949036 lr 0.00059218 rank 7
2022-12-04 02:48:25,402 DEBUG TRAIN Batch 8/4600 loss 10.886353 loss_att 15.072833 loss_ctc 19.470978 loss_rnnt 8.904440 lr 0.00059211 rank 1
2022-12-04 02:48:25,415 DEBUG TRAIN Batch 8/4600 loss 12.837507 loss_att 18.595156 loss_ctc 23.709518 loss_rnnt 10.236377 lr 0.00059223 rank 4
2022-12-04 02:49:38,059 DEBUG TRAIN Batch 8/4700 loss 35.167755 loss_att 37.326626 loss_ctc 54.324688 loss_rnnt 32.181725 lr 0.00059176 rank 7
2022-12-04 02:49:38,061 DEBUG TRAIN Batch 8/4700 loss 24.055429 loss_att 30.231133 loss_ctc 44.039215 loss_rnnt 20.155785 lr 0.00059169 rank 1
2022-12-04 02:49:38,063 DEBUG TRAIN Batch 8/4700 loss 17.925268 loss_att 19.635242 loss_ctc 22.020035 loss_rnnt 17.037304 lr 0.00059176 rank 6
2022-12-04 02:49:38,066 DEBUG TRAIN Batch 8/4700 loss 22.559759 loss_att 25.772457 loss_ctc 36.710381 loss_rnnt 20.030468 lr 0.00059179 rank 5
2022-12-04 02:49:38,068 DEBUG TRAIN Batch 8/4700 loss 11.982890 loss_att 18.847240 loss_ctc 24.094582 loss_rnnt 8.995127 lr 0.00059154 rank 0
2022-12-04 02:49:38,069 DEBUG TRAIN Batch 8/4700 loss 18.540375 loss_att 20.284037 loss_ctc 31.539259 loss_rnnt 16.458458 lr 0.00059144 rank 2
2022-12-04 02:49:38,070 DEBUG TRAIN Batch 8/4700 loss 14.038475 loss_att 19.833311 loss_ctc 27.382715 loss_rnnt 11.100276 lr 0.00059173 rank 3
2022-12-04 02:49:38,077 DEBUG TRAIN Batch 8/4700 loss 19.114738 loss_att 22.722416 loss_ctc 32.234348 loss_rnnt 16.643921 lr 0.00059181 rank 4
2022-12-04 02:50:49,286 DEBUG TRAIN Batch 8/4800 loss 32.423668 loss_att 34.237076 loss_ctc 50.393456 loss_rnnt 29.665012 lr 0.00059135 rank 6
2022-12-04 02:50:49,290 DEBUG TRAIN Batch 8/4800 loss 18.123755 loss_att 23.279514 loss_ctc 26.591282 loss_rnnt 15.963598 lr 0.00059112 rank 0
2022-12-04 02:50:49,291 DEBUG TRAIN Batch 8/4800 loss 9.531164 loss_att 14.566183 loss_ctc 17.122335 loss_rnnt 7.512005 lr 0.00059132 rank 3
2022-12-04 02:50:49,292 DEBUG TRAIN Batch 8/4800 loss 12.087454 loss_att 16.890079 loss_ctc 25.218946 loss_rnnt 9.376062 lr 0.00059128 rank 1
2022-12-04 02:50:49,294 DEBUG TRAIN Batch 8/4800 loss 29.671738 loss_att 35.141640 loss_ctc 45.780716 loss_rnnt 26.429893 lr 0.00059103 rank 2
2022-12-04 02:50:49,294 DEBUG TRAIN Batch 8/4800 loss 25.219984 loss_att 30.433308 loss_ctc 33.903236 loss_rnnt 23.019550 lr 0.00059138 rank 5
2022-12-04 02:50:49,296 DEBUG TRAIN Batch 8/4800 loss 17.435345 loss_att 19.873602 loss_ctc 29.759148 loss_rnnt 15.304519 lr 0.00059135 rank 7
2022-12-04 02:50:49,302 DEBUG TRAIN Batch 8/4800 loss 21.073080 loss_att 25.920361 loss_ctc 34.432068 loss_rnnt 18.322426 lr 0.00059140 rank 4
2022-12-04 02:52:01,154 DEBUG TRAIN Batch 8/4900 loss 13.527784 loss_att 14.883335 loss_ctc 20.594725 loss_rnnt 12.314416 lr 0.00059094 rank 6
2022-12-04 02:52:01,157 DEBUG TRAIN Batch 8/4900 loss 15.017361 loss_att 16.048326 loss_ctc 22.306358 loss_rnnt 13.839301 lr 0.00059087 rank 1
2022-12-04 02:52:01,159 DEBUG TRAIN Batch 8/4900 loss 19.674322 loss_att 27.676804 loss_ctc 35.560417 loss_rnnt 15.955680 lr 0.00059061 rank 2
2022-12-04 02:52:01,158 DEBUG TRAIN Batch 8/4900 loss 16.371336 loss_att 17.010899 loss_ctc 21.592056 loss_rnnt 15.547328 lr 0.00059071 rank 0
2022-12-04 02:52:01,159 DEBUG TRAIN Batch 8/4900 loss 6.972019 loss_att 11.831316 loss_ctc 12.273361 loss_rnnt 5.293314 lr 0.00059097 rank 5
2022-12-04 02:52:01,160 DEBUG TRAIN Batch 8/4900 loss 16.557997 loss_att 17.415051 loss_ctc 22.259512 loss_rnnt 15.626383 lr 0.00059090 rank 3
2022-12-04 02:52:01,181 DEBUG TRAIN Batch 8/4900 loss 26.547844 loss_att 29.165089 loss_ctc 38.398018 loss_rnnt 24.444370 lr 0.00059099 rank 4
2022-12-04 02:52:01,187 DEBUG TRAIN Batch 8/4900 loss 18.119608 loss_att 21.244864 loss_ctc 28.088833 loss_rnnt 16.165325 lr 0.00059094 rank 7
2022-12-04 02:53:16,069 DEBUG TRAIN Batch 8/5000 loss 25.603477 loss_att 31.948223 loss_ctc 47.498779 loss_rnnt 21.415157 lr 0.00059049 rank 3
2022-12-04 02:53:16,088 DEBUG TRAIN Batch 8/5000 loss 12.921387 loss_att 14.154623 loss_ctc 20.201548 loss_rnnt 11.704050 lr 0.00059055 rank 5
2022-12-04 02:53:16,088 DEBUG TRAIN Batch 8/5000 loss 10.105152 loss_att 12.135594 loss_ctc 20.314894 loss_rnnt 8.337765 lr 0.00059045 rank 1
2022-12-04 02:53:16,092 DEBUG TRAIN Batch 8/5000 loss 12.524849 loss_att 16.200541 loss_ctc 21.666208 loss_rnnt 10.570862 lr 0.00059052 rank 6
2022-12-04 02:53:16,091 DEBUG TRAIN Batch 8/5000 loss 14.353190 loss_att 18.368530 loss_ctc 26.505997 loss_rnnt 11.929749 lr 0.00059020 rank 2
2022-12-04 02:53:16,094 DEBUG TRAIN Batch 8/5000 loss 22.825195 loss_att 28.176924 loss_ctc 35.123882 loss_rnnt 20.115025 lr 0.00059030 rank 0
2022-12-04 02:53:16,098 DEBUG TRAIN Batch 8/5000 loss 5.992195 loss_att 8.925746 loss_ctc 10.600760 loss_rnnt 4.791009 lr 0.00059052 rank 7
2022-12-04 02:53:16,099 DEBUG TRAIN Batch 8/5000 loss 19.896513 loss_att 21.099360 loss_ctc 28.649502 loss_rnnt 18.488880 lr 0.00059057 rank 4
2022-12-04 02:54:28,055 DEBUG TRAIN Batch 8/5100 loss 13.466025 loss_att 24.405575 loss_ctc 19.635672 loss_rnnt 10.455496 lr 0.00059008 rank 3
2022-12-04 02:54:28,073 DEBUG TRAIN Batch 8/5100 loss 13.676967 loss_att 13.560846 loss_ctc 18.545456 loss_rnnt 13.051059 lr 0.00059011 rank 6
2022-12-04 02:54:28,075 DEBUG TRAIN Batch 8/5100 loss 16.966507 loss_att 19.541456 loss_ctc 24.503035 loss_rnnt 15.446647 lr 0.00058989 rank 0
2022-12-04 02:54:28,079 DEBUG TRAIN Batch 8/5100 loss 15.881665 loss_att 18.974483 loss_ctc 26.464417 loss_rnnt 13.852068 lr 0.00059014 rank 5
2022-12-04 02:54:28,079 DEBUG TRAIN Batch 8/5100 loss 11.347898 loss_att 11.296515 loss_ctc 16.906416 loss_rnnt 10.617040 lr 0.00059011 rank 7
2022-12-04 02:54:28,089 DEBUG TRAIN Batch 8/5100 loss 12.500892 loss_att 13.231335 loss_ctc 18.337971 loss_rnnt 11.576526 lr 0.00059016 rank 4
2022-12-04 02:54:28,091 DEBUG TRAIN Batch 8/5100 loss 16.270399 loss_att 17.224506 loss_ctc 23.506153 loss_rnnt 15.114810 lr 0.00058979 rank 2
2022-12-04 02:54:28,124 DEBUG TRAIN Batch 8/5100 loss 10.849968 loss_att 16.946934 loss_ctc 21.089836 loss_rnnt 8.265259 lr 0.00059004 rank 1
2022-12-04 02:55:40,654 DEBUG TRAIN Batch 8/5200 loss 21.390732 loss_att 29.620901 loss_ctc 41.284084 loss_rnnt 17.092253 lr 0.00058973 rank 5
2022-12-04 02:55:40,654 DEBUG TRAIN Batch 8/5200 loss 10.886663 loss_att 13.985186 loss_ctc 23.292583 loss_rnnt 8.612837 lr 0.00058967 rank 3
2022-12-04 02:55:40,655 DEBUG TRAIN Batch 8/5200 loss 18.651510 loss_att 23.761261 loss_ctc 31.426878 loss_rnnt 15.926177 lr 0.00058970 rank 6
2022-12-04 02:55:40,656 DEBUG TRAIN Batch 8/5200 loss 14.903304 loss_att 14.775899 loss_ctc 19.870422 loss_rnnt 14.266502 lr 0.00058938 rank 2
2022-12-04 02:55:40,657 DEBUG TRAIN Batch 8/5200 loss 7.006302 loss_att 12.942895 loss_ctc 16.051682 loss_rnnt 4.612933 lr 0.00058970 rank 7
2022-12-04 02:55:40,657 DEBUG TRAIN Batch 8/5200 loss 11.133101 loss_att 14.355758 loss_ctc 22.973860 loss_rnnt 8.909801 lr 0.00058948 rank 0
2022-12-04 02:55:40,666 DEBUG TRAIN Batch 8/5200 loss 9.078388 loss_att 12.848269 loss_ctc 14.320450 loss_rnnt 7.625471 lr 0.00058975 rank 4
2022-12-04 02:55:40,666 DEBUG TRAIN Batch 8/5200 loss 9.353971 loss_att 13.568499 loss_ctc 19.992926 loss_rnnt 7.092540 lr 0.00058963 rank 1
2022-12-04 02:56:53,159 DEBUG TRAIN Batch 8/5300 loss 11.748555 loss_att 14.595080 loss_ctc 12.728909 loss_rnnt 11.048536 lr 0.00058922 rank 1
2022-12-04 02:56:53,166 DEBUG TRAIN Batch 8/5300 loss 17.904884 loss_att 25.717741 loss_ctc 39.569313 loss_rnnt 13.453724 lr 0.00058897 rank 2
2022-12-04 02:56:53,174 DEBUG TRAIN Batch 8/5300 loss 6.790872 loss_att 16.450272 loss_ctc 13.421791 loss_rnnt 3.974869 lr 0.00058929 rank 6
2022-12-04 02:56:53,174 DEBUG TRAIN Batch 8/5300 loss 14.533331 loss_att 20.087717 loss_ctc 32.676422 loss_rnnt 11.003375 lr 0.00058934 rank 4
2022-12-04 02:56:53,177 DEBUG TRAIN Batch 8/5300 loss 15.823608 loss_att 21.028481 loss_ctc 23.828199 loss_rnnt 13.715355 lr 0.00058907 rank 0
2022-12-04 02:56:53,178 DEBUG TRAIN Batch 8/5300 loss 17.029428 loss_att 21.186466 loss_ctc 28.623283 loss_rnnt 14.652174 lr 0.00058926 rank 3
2022-12-04 02:56:53,178 DEBUG TRAIN Batch 8/5300 loss 12.916677 loss_att 15.621502 loss_ctc 21.649445 loss_rnnt 11.211343 lr 0.00058932 rank 5
2022-12-04 02:56:53,202 DEBUG TRAIN Batch 8/5300 loss 8.275679 loss_att 14.285183 loss_ctc 19.312984 loss_rnnt 5.602137 lr 0.00058929 rank 7
2022-12-04 02:58:06,272 DEBUG TRAIN Batch 8/5400 loss 20.502981 loss_att 21.763454 loss_ctc 30.367615 loss_rnnt 18.935600 lr 0.00058891 rank 5
2022-12-04 02:58:06,282 DEBUG TRAIN Batch 8/5400 loss 20.822536 loss_att 27.196083 loss_ctc 29.143036 loss_rnnt 18.438429 lr 0.00058888 rank 6
2022-12-04 02:58:06,284 DEBUG TRAIN Batch 8/5400 loss 25.455883 loss_att 28.172237 loss_ctc 44.753914 loss_rnnt 22.339540 lr 0.00058888 rank 7
2022-12-04 02:58:06,289 DEBUG TRAIN Batch 8/5400 loss 13.705907 loss_att 15.056622 loss_ctc 18.838284 loss_rnnt 12.751448 lr 0.00058866 rank 0
2022-12-04 02:58:06,290 DEBUG TRAIN Batch 8/5400 loss 6.927710 loss_att 10.389560 loss_ctc 12.482479 loss_rnnt 5.494703 lr 0.00058885 rank 3
2022-12-04 02:58:06,290 DEBUG TRAIN Batch 8/5400 loss 19.589439 loss_att 22.739887 loss_ctc 31.364460 loss_rnnt 17.389347 lr 0.00058893 rank 4
2022-12-04 02:58:06,292 DEBUG TRAIN Batch 8/5400 loss 9.315112 loss_att 11.673405 loss_ctc 15.802406 loss_rnnt 7.978481 lr 0.00058881 rank 1
2022-12-04 02:58:06,295 DEBUG TRAIN Batch 8/5400 loss 14.584004 loss_att 19.329281 loss_ctc 20.831249 loss_rnnt 12.801983 lr 0.00058857 rank 2
2022-12-04 02:59:17,187 DEBUG TRAIN Batch 8/5500 loss 20.900288 loss_att 20.111385 loss_ctc 30.095654 loss_rnnt 19.832018 lr 0.00058841 rank 1
2022-12-04 02:59:17,199 DEBUG TRAIN Batch 8/5500 loss 15.301280 loss_att 19.555567 loss_ctc 26.348629 loss_rnnt 12.977442 lr 0.00058850 rank 5
2022-12-04 02:59:17,201 DEBUG TRAIN Batch 8/5500 loss 8.543946 loss_att 11.202631 loss_ctc 11.972345 loss_rnnt 7.555089 lr 0.00058848 rank 6
2022-12-04 02:59:17,201 DEBUG TRAIN Batch 8/5500 loss 14.489646 loss_att 17.642620 loss_ctc 29.336784 loss_rnnt 11.879433 lr 0.00058816 rank 2
2022-12-04 02:59:17,202 DEBUG TRAIN Batch 8/5500 loss 30.907309 loss_att 34.306190 loss_ctc 40.188625 loss_rnnt 28.990023 lr 0.00058825 rank 0
2022-12-04 02:59:17,203 DEBUG TRAIN Batch 8/5500 loss 11.087078 loss_att 15.710197 loss_ctc 23.260284 loss_rnnt 8.539359 lr 0.00058844 rank 3
2022-12-04 02:59:17,206 DEBUG TRAIN Batch 8/5500 loss 13.205923 loss_att 19.508402 loss_ctc 27.699184 loss_rnnt 10.012993 lr 0.00058848 rank 7
2022-12-04 02:59:17,212 DEBUG TRAIN Batch 8/5500 loss 38.222271 loss_att 43.985088 loss_ctc 53.036079 loss_rnnt 35.094532 lr 0.00058852 rank 4
2022-12-04 03:00:29,440 DEBUG TRAIN Batch 8/5600 loss 16.456619 loss_att 20.792912 loss_ctc 30.419058 loss_rnnt 13.727703 lr 0.00058784 rank 0
2022-12-04 03:00:29,441 DEBUG TRAIN Batch 8/5600 loss 18.573404 loss_att 20.318197 loss_ctc 24.984463 loss_rnnt 17.369637 lr 0.00058800 rank 1
2022-12-04 03:00:29,445 DEBUG TRAIN Batch 8/5600 loss 11.350878 loss_att 12.066539 loss_ctc 19.620222 loss_rnnt 10.105165 lr 0.00058804 rank 3
2022-12-04 03:00:29,445 DEBUG TRAIN Batch 8/5600 loss 11.791569 loss_att 14.538512 loss_ctc 20.439148 loss_rnnt 10.089170 lr 0.00058807 rank 6
2022-12-04 03:00:29,448 DEBUG TRAIN Batch 8/5600 loss 17.729042 loss_att 25.920931 loss_ctc 34.378738 loss_rnnt 13.870706 lr 0.00058807 rank 7
2022-12-04 03:00:29,479 DEBUG TRAIN Batch 8/5600 loss 16.458992 loss_att 17.490185 loss_ctc 17.714371 loss_rnnt 16.085369 lr 0.00058775 rank 2
2022-12-04 03:00:29,488 DEBUG TRAIN Batch 8/5600 loss 17.571404 loss_att 16.013968 loss_ctc 24.420671 loss_rnnt 16.969656 lr 0.00058810 rank 5
2022-12-04 03:00:29,496 DEBUG TRAIN Batch 8/5600 loss 12.913960 loss_att 18.177406 loss_ctc 24.517157 loss_rnnt 10.314177 lr 0.00058812 rank 4
2022-12-04 03:01:45,353 DEBUG TRAIN Batch 8/5700 loss 31.940746 loss_att 37.565598 loss_ctc 57.404510 loss_rnnt 27.420607 lr 0.00058759 rank 1
2022-12-04 03:01:45,354 DEBUG TRAIN Batch 8/5700 loss 10.523191 loss_att 14.911266 loss_ctc 20.241570 loss_rnnt 8.349792 lr 0.00058766 rank 6
2022-12-04 03:01:45,354 DEBUG TRAIN Batch 8/5700 loss 7.527153 loss_att 12.156879 loss_ctc 19.255196 loss_rnnt 5.037469 lr 0.00058769 rank 5
2022-12-04 03:01:45,357 DEBUG TRAIN Batch 8/5700 loss 21.601128 loss_att 26.538210 loss_ctc 36.424534 loss_rnnt 18.637257 lr 0.00058744 rank 0
2022-12-04 03:01:45,358 DEBUG TRAIN Batch 8/5700 loss 14.355364 loss_att 23.586323 loss_ctc 28.004112 loss_rnnt 10.689339 lr 0.00058763 rank 3
2022-12-04 03:01:45,359 DEBUG TRAIN Batch 8/5700 loss 11.119182 loss_att 13.411659 loss_ctc 20.863363 loss_rnnt 9.361462 lr 0.00058766 rank 7
2022-12-04 03:01:45,368 DEBUG TRAIN Batch 8/5700 loss 16.215570 loss_att 18.607132 loss_ctc 23.786461 loss_rnnt 14.727806 lr 0.00058735 rank 2
2022-12-04 03:01:45,375 DEBUG TRAIN Batch 8/5700 loss 8.022597 loss_att 10.467935 loss_ctc 12.083648 loss_rnnt 6.992056 lr 0.00058771 rank 4
2022-12-04 03:02:57,165 DEBUG TRAIN Batch 8/5800 loss 17.377800 loss_att 21.785881 loss_ctc 30.665279 loss_rnnt 14.724518 lr 0.00058719 rank 1
2022-12-04 03:02:57,165 DEBUG TRAIN Batch 8/5800 loss 14.777637 loss_att 16.293243 loss_ctc 22.478191 loss_rnnt 13.447776 lr 0.00058694 rank 2
2022-12-04 03:02:57,166 DEBUG TRAIN Batch 8/5800 loss 11.516517 loss_att 15.943029 loss_ctc 20.303070 loss_rnnt 9.459673 lr 0.00058726 rank 6
2022-12-04 03:02:57,167 DEBUG TRAIN Batch 8/5800 loss 19.798679 loss_att 22.229073 loss_ctc 30.131664 loss_rnnt 17.934868 lr 0.00058726 rank 7
2022-12-04 03:02:57,169 DEBUG TRAIN Batch 8/5800 loss 26.028355 loss_att 27.844748 loss_ctc 41.114185 loss_rnnt 23.653633 lr 0.00058729 rank 5
2022-12-04 03:02:57,170 DEBUG TRAIN Batch 8/5800 loss 12.145848 loss_att 13.150642 loss_ctc 19.518171 loss_rnnt 10.961913 lr 0.00058703 rank 0
2022-12-04 03:02:57,171 DEBUG TRAIN Batch 8/5800 loss 11.782530 loss_att 15.302182 loss_ctc 24.821785 loss_rnnt 9.340033 lr 0.00058722 rank 3
2022-12-04 03:02:57,176 DEBUG TRAIN Batch 8/5800 loss 7.805078 loss_att 14.161680 loss_ctc 16.539392 loss_rnnt 5.369182 lr 0.00058731 rank 4
2022-12-04 03:04:08,896 DEBUG TRAIN Batch 8/5900 loss 20.391232 loss_att 25.240725 loss_ctc 36.590897 loss_rnnt 17.261379 lr 0.00058685 rank 6
2022-12-04 03:04:08,914 DEBUG TRAIN Batch 8/5900 loss 8.693694 loss_att 12.362089 loss_ctc 16.605894 loss_rnnt 6.905055 lr 0.00058682 rank 3
2022-12-04 03:04:08,916 DEBUG TRAIN Batch 8/5900 loss 14.060635 loss_att 16.893105 loss_ctc 19.969879 loss_rnnt 12.706241 lr 0.00058663 rank 0
2022-12-04 03:04:08,917 DEBUG TRAIN Batch 8/5900 loss 12.513705 loss_att 14.654061 loss_ctc 27.466702 loss_rnnt 10.091900 lr 0.00058678 rank 1
2022-12-04 03:04:08,918 DEBUG TRAIN Batch 8/5900 loss 10.332455 loss_att 13.214434 loss_ctc 17.992355 loss_rnnt 8.734738 lr 0.00058688 rank 5
2022-12-04 03:04:08,922 DEBUG TRAIN Batch 8/5900 loss 5.911944 loss_att 10.885544 loss_ctc 16.031443 loss_rnnt 3.567958 lr 0.00058654 rank 2
2022-12-04 03:04:08,922 DEBUG TRAIN Batch 8/5900 loss 23.781944 loss_att 27.665443 loss_ctc 39.049679 loss_rnnt 20.969545 lr 0.00058685 rank 7
2022-12-04 03:04:08,964 DEBUG TRAIN Batch 8/5900 loss 17.076460 loss_att 18.296974 loss_ctc 32.852798 loss_rnnt 14.728844 lr 0.00058690 rank 4
2022-12-04 03:05:21,563 DEBUG TRAIN Batch 8/6000 loss 18.067263 loss_att 24.076572 loss_ctc 29.958298 loss_rnnt 15.279930 lr 0.00058648 rank 5
2022-12-04 03:05:21,564 DEBUG TRAIN Batch 8/6000 loss 24.778564 loss_att 25.954895 loss_ctc 41.281601 loss_rnnt 22.342894 lr 0.00058645 rank 7
2022-12-04 03:05:21,566 DEBUG TRAIN Batch 8/6000 loss 29.837126 loss_att 32.242775 loss_ctc 43.134621 loss_rnnt 27.582996 lr 0.00058613 rank 2
2022-12-04 03:05:21,566 DEBUG TRAIN Batch 8/6000 loss 10.343759 loss_att 12.587810 loss_ctc 16.279747 loss_rnnt 9.103483 lr 0.00058645 rank 6
2022-12-04 03:05:21,568 DEBUG TRAIN Batch 8/6000 loss 17.554768 loss_att 21.576998 loss_ctc 28.037298 loss_rnnt 15.352652 lr 0.00058642 rank 3
2022-12-04 03:05:21,571 DEBUG TRAIN Batch 8/6000 loss 14.486330 loss_att 20.063549 loss_ctc 24.923931 loss_rnnt 11.979206 lr 0.00058623 rank 0
2022-12-04 03:05:21,579 DEBUG TRAIN Batch 8/6000 loss 16.833582 loss_att 20.838108 loss_ctc 31.753666 loss_rnnt 14.043332 lr 0.00058638 rank 1
2022-12-04 03:05:21,625 DEBUG TRAIN Batch 8/6000 loss 10.498625 loss_att 15.448112 loss_ctc 18.151665 loss_rnnt 8.488321 lr 0.00058650 rank 4
2022-12-04 03:06:38,390 DEBUG TRAIN Batch 8/6100 loss 20.605206 loss_att 23.419409 loss_ctc 32.107738 loss_rnnt 18.508694 lr 0.00058582 rank 0
2022-12-04 03:06:38,409 DEBUG TRAIN Batch 8/6100 loss 17.561424 loss_att 20.493307 loss_ctc 25.961699 loss_rnnt 15.855011 lr 0.00058605 rank 6
2022-12-04 03:06:38,411 DEBUG TRAIN Batch 8/6100 loss 16.077862 loss_att 18.652660 loss_ctc 27.395546 loss_rnnt 14.053877 lr 0.00058607 rank 5
2022-12-04 03:06:38,411 DEBUG TRAIN Batch 8/6100 loss 16.483826 loss_att 25.443924 loss_ctc 28.972538 loss_rnnt 13.026644 lr 0.00058601 rank 3
2022-12-04 03:06:38,411 DEBUG TRAIN Batch 8/6100 loss 16.106928 loss_att 21.365376 loss_ctc 27.201908 loss_rnnt 13.575907 lr 0.00058598 rank 1
2022-12-04 03:06:38,411 DEBUG TRAIN Batch 8/6100 loss 18.783659 loss_att 21.657639 loss_ctc 32.830887 loss_rnnt 16.335899 lr 0.00058609 rank 4
2022-12-04 03:06:38,412 DEBUG TRAIN Batch 8/6100 loss 12.802795 loss_att 16.634518 loss_ctc 23.882252 loss_rnnt 10.559189 lr 0.00058573 rank 2
2022-12-04 03:06:38,416 DEBUG TRAIN Batch 8/6100 loss 16.410082 loss_att 17.637224 loss_ctc 23.188522 loss_rnnt 15.260860 lr 0.00058605 rank 7
2022-12-04 03:07:50,741 DEBUG TRAIN Batch 8/6200 loss 16.546186 loss_att 17.765305 loss_ctc 25.908649 loss_rnnt 15.054034 lr 0.00058567 rank 5
2022-12-04 03:07:50,743 DEBUG TRAIN Batch 8/6200 loss 19.695274 loss_att 22.243038 loss_ctc 33.429024 loss_rnnt 17.354553 lr 0.00058542 rank 0
2022-12-04 03:07:50,750 DEBUG TRAIN Batch 8/6200 loss 7.492145 loss_att 10.651099 loss_ctc 13.968897 loss_rnnt 5.996787 lr 0.00058561 rank 3
2022-12-04 03:07:50,750 DEBUG TRAIN Batch 8/6200 loss 12.241398 loss_att 12.693467 loss_ctc 17.271614 loss_rnnt 11.480288 lr 0.00058557 rank 1
2022-12-04 03:07:50,752 DEBUG TRAIN Batch 8/6200 loss 11.206760 loss_att 13.814967 loss_ctc 20.642015 loss_rnnt 9.427085 lr 0.00058533 rank 2
2022-12-04 03:07:50,753 DEBUG TRAIN Batch 8/6200 loss 15.692764 loss_att 18.894081 loss_ctc 29.733452 loss_rnnt 13.180408 lr 0.00058564 rank 6
2022-12-04 03:07:50,755 DEBUG TRAIN Batch 8/6200 loss 19.625145 loss_att 24.456373 loss_ctc 31.547211 loss_rnnt 17.069290 lr 0.00058569 rank 4
2022-12-04 03:07:50,800 DEBUG TRAIN Batch 8/6200 loss 16.251156 loss_att 19.603144 loss_ctc 27.173100 loss_rnnt 14.124500 lr 0.00058564 rank 7
2022-12-04 03:09:02,845 DEBUG TRAIN Batch 8/6300 loss 10.608151 loss_att 14.071928 loss_ctc 19.636936 loss_rnnt 8.711558 lr 0.00058502 rank 0
2022-12-04 03:09:02,846 DEBUG TRAIN Batch 8/6300 loss 29.759771 loss_att 35.452866 loss_ctc 50.776215 loss_rnnt 25.818958 lr 0.00058521 rank 3
2022-12-04 03:09:02,847 DEBUG TRAIN Batch 8/6300 loss 11.143751 loss_att 16.288067 loss_ctc 20.184158 loss_rnnt 8.909500 lr 0.00058527 rank 5
2022-12-04 03:09:02,847 DEBUG TRAIN Batch 8/6300 loss 12.047342 loss_att 17.240692 loss_ctc 22.776258 loss_rnnt 9.578150 lr 0.00058529 rank 4
2022-12-04 03:09:02,848 DEBUG TRAIN Batch 8/6300 loss 8.966184 loss_att 12.441736 loss_ctc 17.096664 loss_rnnt 7.187009 lr 0.00058524 rank 6
2022-12-04 03:09:02,851 DEBUG TRAIN Batch 8/6300 loss 16.665348 loss_att 18.279284 loss_ctc 23.741005 loss_rnnt 15.399139 lr 0.00058493 rank 2
2022-12-04 03:09:02,850 DEBUG TRAIN Batch 8/6300 loss 7.201404 loss_att 7.941716 loss_ctc 11.212620 loss_rnnt 6.518513 lr 0.00058517 rank 1
2022-12-04 03:09:02,873 DEBUG TRAIN Batch 8/6300 loss 24.138710 loss_att 26.070229 loss_ctc 39.326294 loss_rnnt 21.727398 lr 0.00058524 rank 7
2022-12-04 03:10:24,181 DEBUG TRAIN Batch 8/6400 loss 10.353238 loss_att 12.295270 loss_ctc 15.564971 loss_rnnt 9.269935 lr 0.00058453 rank 2
2022-12-04 03:10:24,192 DEBUG TRAIN Batch 8/6400 loss 17.308340 loss_att 22.386089 loss_ctc 35.077858 loss_rnnt 13.923521 lr 0.00058477 rank 1
2022-12-04 03:10:24,193 DEBUG TRAIN Batch 8/6400 loss 19.369438 loss_att 19.637091 loss_ctc 30.584173 loss_rnnt 17.820610 lr 0.00058462 rank 0
2022-12-04 03:10:24,193 DEBUG TRAIN Batch 8/6400 loss 22.087490 loss_att 26.814831 loss_ctc 32.280045 loss_rnnt 19.783014 lr 0.00058487 rank 5
2022-12-04 03:10:24,195 DEBUG TRAIN Batch 8/6400 loss 23.555065 loss_att 33.394958 loss_ctc 35.559685 loss_rnnt 19.986471 lr 0.00058484 rank 6
2022-12-04 03:10:24,197 DEBUG TRAIN Batch 8/6400 loss 10.645580 loss_att 11.134336 loss_ctc 13.967146 loss_rnnt 10.104954 lr 0.00058484 rank 7
2022-12-04 03:10:24,222 DEBUG TRAIN Batch 8/6400 loss 17.749941 loss_att 22.181303 loss_ctc 27.498663 loss_rnnt 15.563839 lr 0.00058481 rank 3
2022-12-04 03:10:24,243 DEBUG TRAIN Batch 8/6400 loss 8.695212 loss_att 9.271508 loss_ctc 11.506557 loss_rnnt 8.205108 lr 0.00058489 rank 4
2022-12-04 03:11:36,717 DEBUG TRAIN Batch 8/6500 loss 4.643424 loss_att 9.284691 loss_ctc 11.322638 loss_rnnt 2.824609 lr 0.00058447 rank 5
2022-12-04 03:11:36,719 DEBUG TRAIN Batch 8/6500 loss 9.296082 loss_att 12.479332 loss_ctc 13.487062 loss_rnnt 8.100635 lr 0.00058444 rank 6
2022-12-04 03:11:36,722 DEBUG TRAIN Batch 8/6500 loss 13.158962 loss_att 15.861033 loss_ctc 22.698812 loss_rnnt 11.346567 lr 0.00058437 rank 1
2022-12-04 03:11:36,727 DEBUG TRAIN Batch 8/6500 loss 12.307751 loss_att 17.248266 loss_ctc 23.053886 loss_rnnt 9.886829 lr 0.00058444 rank 7
2022-12-04 03:11:36,731 DEBUG TRAIN Batch 8/6500 loss 8.379608 loss_att 12.485174 loss_ctc 13.753139 loss_rnnt 6.842025 lr 0.00058422 rank 0
2022-12-04 03:11:36,731 DEBUG TRAIN Batch 8/6500 loss 18.782438 loss_att 21.402411 loss_ctc 33.824184 loss_rnnt 16.252876 lr 0.00058441 rank 3
2022-12-04 03:11:36,734 DEBUG TRAIN Batch 8/6500 loss 24.713850 loss_att 27.440437 loss_ctc 34.567230 loss_rnnt 22.854750 lr 0.00058449 rank 4
2022-12-04 03:11:36,775 DEBUG TRAIN Batch 8/6500 loss 8.554981 loss_att 12.413342 loss_ctc 18.887001 loss_rnnt 6.405706 lr 0.00058413 rank 2
2022-12-04 03:12:48,917 DEBUG TRAIN Batch 8/6600 loss 6.713450 loss_att 11.031166 loss_ctc 11.649258 loss_rnnt 5.191799 lr 0.00058404 rank 6
2022-12-04 03:12:48,917 DEBUG TRAIN Batch 8/6600 loss 13.653850 loss_att 20.782669 loss_ctc 25.523003 loss_rnnt 10.645533 lr 0.00058398 rank 1
2022-12-04 03:12:48,917 DEBUG TRAIN Batch 8/6600 loss 10.087481 loss_att 15.806084 loss_ctc 18.653732 loss_rnnt 7.801593 lr 0.00058401 rank 3
2022-12-04 03:12:48,918 DEBUG TRAIN Batch 8/6600 loss 11.260183 loss_att 15.011725 loss_ctc 21.050583 loss_rnnt 9.204489 lr 0.00058382 rank 0
2022-12-04 03:12:48,919 DEBUG TRAIN Batch 8/6600 loss 20.067167 loss_att 23.599455 loss_ctc 34.880257 loss_rnnt 17.385630 lr 0.00058407 rank 5
2022-12-04 03:12:48,919 DEBUG TRAIN Batch 8/6600 loss 10.703444 loss_att 14.265646 loss_ctc 20.095768 loss_rnnt 8.738693 lr 0.00058404 rank 7
2022-12-04 03:12:48,922 DEBUG TRAIN Batch 8/6600 loss 15.616356 loss_att 19.013239 loss_ctc 26.547125 loss_rnnt 13.479544 lr 0.00058373 rank 2
2022-12-04 03:12:48,925 DEBUG TRAIN Batch 8/6600 loss 10.601948 loss_att 15.693912 loss_ctc 23.416182 loss_rnnt 7.874990 lr 0.00058409 rank 4
2022-12-04 03:14:01,699 DEBUG TRAIN Batch 8/6700 loss 11.077263 loss_att 16.099792 loss_ctc 21.145729 loss_rnnt 8.730295 lr 0.00058364 rank 7
2022-12-04 03:14:01,702 DEBUG TRAIN Batch 8/6700 loss 16.133368 loss_att 20.119328 loss_ctc 24.422539 loss_rnnt 14.230952 lr 0.00058333 rank 2
2022-12-04 03:14:01,702 DEBUG TRAIN Batch 8/6700 loss 39.184593 loss_att 41.182640 loss_ctc 60.122292 loss_rnnt 35.993290 lr 0.00058361 rank 3
2022-12-04 03:14:01,711 DEBUG TRAIN Batch 8/6700 loss 18.436466 loss_att 27.192034 loss_ctc 32.441109 loss_rnnt 14.818068 lr 0.00058364 rank 6
2022-12-04 03:14:01,716 DEBUG TRAIN Batch 8/6700 loss 15.388227 loss_att 17.888954 loss_ctc 28.114422 loss_rnnt 13.191256 lr 0.00058343 rank 0
2022-12-04 03:14:01,716 DEBUG TRAIN Batch 8/6700 loss 24.014141 loss_att 26.248463 loss_ctc 37.160645 loss_rnnt 21.814409 lr 0.00058358 rank 1
2022-12-04 03:14:01,718 DEBUG TRAIN Batch 8/6700 loss 10.950365 loss_att 15.570118 loss_ctc 19.822771 loss_rnnt 8.843427 lr 0.00058367 rank 5
2022-12-04 03:14:01,741 DEBUG TRAIN Batch 8/6700 loss 20.947035 loss_att 26.101816 loss_ctc 28.814472 loss_rnnt 18.867088 lr 0.00058369 rank 4
2022-12-04 03:15:23,448 DEBUG TRAIN Batch 8/6800 loss 21.658833 loss_att 24.106108 loss_ctc 30.871277 loss_rnnt 19.941051 lr 0.00058318 rank 1
2022-12-04 03:15:23,450 DEBUG TRAIN Batch 8/6800 loss 16.129959 loss_att 18.067165 loss_ctc 22.652754 loss_rnnt 14.872810 lr 0.00058303 rank 0
2022-12-04 03:15:23,454 DEBUG TRAIN Batch 8/6800 loss 19.883528 loss_att 22.173727 loss_ctc 29.318087 loss_rnnt 18.167545 lr 0.00058325 rank 6
2022-12-04 03:15:23,455 DEBUG TRAIN Batch 8/6800 loss 8.420910 loss_att 13.887512 loss_ctc 13.510627 loss_rnnt 6.648960 lr 0.00058322 rank 3
2022-12-04 03:15:23,456 DEBUG TRAIN Batch 8/6800 loss 22.702171 loss_att 27.904516 loss_ctc 44.793018 loss_rnnt 18.716255 lr 0.00058330 rank 4
2022-12-04 03:15:23,458 DEBUG TRAIN Batch 8/6800 loss 20.587523 loss_att 23.689308 loss_ctc 27.029610 loss_rnnt 19.108221 lr 0.00058325 rank 7
2022-12-04 03:15:23,460 DEBUG TRAIN Batch 8/6800 loss 17.924448 loss_att 20.682928 loss_ctc 32.904854 loss_rnnt 15.375364 lr 0.00058294 rank 2
2022-12-04 03:15:23,505 DEBUG TRAIN Batch 8/6800 loss 11.834122 loss_att 13.593453 loss_ctc 20.779163 loss_rnnt 10.289583 lr 0.00058328 rank 5
2022-12-04 03:16:35,136 DEBUG TRAIN Batch 8/6900 loss 18.805643 loss_att 19.702358 loss_ctc 26.633053 loss_rnnt 17.582645 lr 0.00058282 rank 3
2022-12-04 03:16:35,136 DEBUG TRAIN Batch 8/6900 loss 13.834351 loss_att 15.317843 loss_ctc 22.254786 loss_rnnt 12.414928 lr 0.00058263 rank 0
2022-12-04 03:16:35,137 DEBUG TRAIN Batch 8/6900 loss 20.490067 loss_att 19.607536 loss_ctc 26.386024 loss_rnnt 19.880445 lr 0.00058285 rank 6
2022-12-04 03:16:35,140 DEBUG TRAIN Batch 8/6900 loss 10.860373 loss_att 11.196002 loss_ctc 15.310330 loss_rnnt 10.199921 lr 0.00058288 rank 5
2022-12-04 03:16:35,142 DEBUG TRAIN Batch 8/6900 loss 15.712440 loss_att 15.956419 loss_ctc 25.080702 loss_rnnt 14.414542 lr 0.00058278 rank 1
2022-12-04 03:16:35,142 DEBUG TRAIN Batch 8/6900 loss 23.823910 loss_att 32.580154 loss_ctc 37.867302 loss_rnnt 20.200207 lr 0.00058254 rank 2
2022-12-04 03:16:35,146 DEBUG TRAIN Batch 8/6900 loss 18.493723 loss_att 24.818481 loss_ctc 28.382183 loss_rnnt 15.910309 lr 0.00058285 rank 7
2022-12-04 03:16:35,201 DEBUG TRAIN Batch 8/6900 loss 20.720842 loss_att 19.667793 loss_ctc 34.887123 loss_rnnt 19.042616 lr 0.00058290 rank 4
2022-12-04 03:17:47,573 DEBUG TRAIN Batch 8/7000 loss 17.427046 loss_att 17.774704 loss_ctc 24.883568 loss_rnnt 16.363312 lr 0.00058246 rank 6
2022-12-04 03:17:47,575 DEBUG TRAIN Batch 8/7000 loss 20.167685 loss_att 25.093182 loss_ctc 35.627625 loss_rnnt 17.121260 lr 0.00058242 rank 3
2022-12-04 03:17:47,576 DEBUG TRAIN Batch 8/7000 loss 14.605438 loss_att 20.036179 loss_ctc 25.472488 loss_rnnt 12.070350 lr 0.00058248 rank 5
2022-12-04 03:17:47,580 DEBUG TRAIN Batch 8/7000 loss 12.679140 loss_att 16.332582 loss_ctc 20.473421 loss_rnnt 10.909214 lr 0.00058224 rank 0
2022-12-04 03:17:47,582 DEBUG TRAIN Batch 8/7000 loss 11.122068 loss_att 13.634921 loss_ctc 15.187513 loss_rnnt 10.077438 lr 0.00058215 rank 2
2022-12-04 03:17:47,582 DEBUG TRAIN Batch 8/7000 loss 18.971584 loss_att 23.804873 loss_ctc 27.257532 loss_rnnt 16.900135 lr 0.00058246 rank 7
2022-12-04 03:17:47,589 DEBUG TRAIN Batch 8/7000 loss 22.289799 loss_att 22.541317 loss_ctc 28.309746 loss_rnnt 21.436836 lr 0.00058250 rank 4
2022-12-04 03:17:47,620 DEBUG TRAIN Batch 8/7000 loss 8.570080 loss_att 12.339390 loss_ctc 15.498332 loss_rnnt 6.892450 lr 0.00058239 rank 1
2022-12-04 03:19:08,672 DEBUG TRAIN Batch 8/7100 loss 19.510807 loss_att 23.605356 loss_ctc 36.007538 loss_rnnt 16.492332 lr 0.00058206 rank 6
2022-12-04 03:19:08,673 DEBUG TRAIN Batch 8/7100 loss 18.644398 loss_att 22.297401 loss_ctc 33.350822 loss_rnnt 15.952939 lr 0.00058184 rank 0
2022-12-04 03:19:08,675 DEBUG TRAIN Batch 8/7100 loss 11.007907 loss_att 15.999521 loss_ctc 17.748873 loss_rnnt 9.110789 lr 0.00058203 rank 3
2022-12-04 03:19:08,675 DEBUG TRAIN Batch 8/7100 loss 7.872360 loss_att 12.924493 loss_ctc 15.209201 loss_rnnt 5.883688 lr 0.00058199 rank 1
2022-12-04 03:19:08,678 DEBUG TRAIN Batch 8/7100 loss 10.240821 loss_att 11.079997 loss_ctc 14.377894 loss_rnnt 9.521377 lr 0.00058175 rank 2
2022-12-04 03:19:08,678 DEBUG TRAIN Batch 8/7100 loss 14.248183 loss_att 17.991684 loss_ctc 23.482565 loss_rnnt 12.268232 lr 0.00058211 rank 4
2022-12-04 03:19:08,679 DEBUG TRAIN Batch 8/7100 loss 17.762562 loss_att 21.117044 loss_ctc 29.690056 loss_rnnt 15.501334 lr 0.00058209 rank 5
2022-12-04 03:19:08,748 DEBUG TRAIN Batch 8/7100 loss 16.868830 loss_att 20.419382 loss_ctc 27.564911 loss_rnnt 14.732574 lr 0.00058206 rank 7
2022-12-04 03:20:20,935 DEBUG TRAIN Batch 8/7200 loss 3.774499 loss_att 6.708082 loss_ctc 6.905504 loss_rnnt 2.770315 lr 0.00058167 rank 6
2022-12-04 03:20:20,936 DEBUG TRAIN Batch 8/7200 loss 12.750241 loss_att 17.836693 loss_ctc 19.447441 loss_rnnt 10.839991 lr 0.00058164 rank 3
2022-12-04 03:20:20,938 DEBUG TRAIN Batch 8/7200 loss 16.959475 loss_att 20.276196 loss_ctc 28.550817 loss_rnnt 14.750618 lr 0.00058145 rank 0
2022-12-04 03:20:20,941 DEBUG TRAIN Batch 8/7200 loss 10.958877 loss_att 14.898222 loss_ctc 16.492178 loss_rnnt 9.433233 lr 0.00058169 rank 5
2022-12-04 03:20:20,942 DEBUG TRAIN Batch 8/7200 loss 15.073703 loss_att 19.226717 loss_ctc 22.189276 loss_rnnt 13.294357 lr 0.00058171 rank 4
2022-12-04 03:20:20,943 DEBUG TRAIN Batch 8/7200 loss 19.590410 loss_att 22.838535 loss_ctc 29.632200 loss_rnnt 17.601879 lr 0.00058160 rank 1
2022-12-04 03:20:20,948 DEBUG TRAIN Batch 8/7200 loss 20.713966 loss_att 24.764969 loss_ctc 33.891899 loss_rnnt 18.146706 lr 0.00058136 rank 2
2022-12-04 03:20:21,002 DEBUG TRAIN Batch 8/7200 loss 9.518045 loss_att 15.397129 loss_ctc 19.878347 loss_rnnt 6.960855 lr 0.00058167 rank 7
2022-12-04 03:21:31,909 DEBUG TRAIN Batch 8/7300 loss 23.510380 loss_att 26.762218 loss_ctc 30.970634 loss_rnnt 21.865311 lr 0.00058127 rank 6
2022-12-04 03:21:31,909 DEBUG TRAIN Batch 8/7300 loss 16.141382 loss_att 20.339001 loss_ctc 30.023102 loss_rnnt 13.450963 lr 0.00058124 rank 3
2022-12-04 03:21:31,918 DEBUG TRAIN Batch 8/7300 loss 9.210082 loss_att 15.718470 loss_ctc 19.664589 loss_rnnt 6.514471 lr 0.00058106 rank 0
2022-12-04 03:21:31,918 DEBUG TRAIN Batch 8/7300 loss 22.603163 loss_att 28.114315 loss_ctc 45.465622 loss_rnnt 18.452604 lr 0.00058097 rank 2
2022-12-04 03:21:31,918 DEBUG TRAIN Batch 8/7300 loss 17.872953 loss_att 24.134834 loss_ctc 34.255142 loss_rnnt 14.436286 lr 0.00058121 rank 1
2022-12-04 03:21:31,919 DEBUG TRAIN Batch 8/7300 loss 10.084354 loss_att 14.955121 loss_ctc 18.371967 loss_rnnt 8.005186 lr 0.00058127 rank 7
2022-12-04 03:21:31,924 DEBUG TRAIN Batch 8/7300 loss 9.458709 loss_att 13.067142 loss_ctc 13.828908 loss_rnnt 8.154329 lr 0.00058132 rank 4
2022-12-04 03:21:31,964 DEBUG TRAIN Batch 8/7300 loss 13.729405 loss_att 20.616297 loss_ctc 32.762283 loss_rnnt 9.814311 lr 0.00058130 rank 5
2022-12-04 03:22:43,909 DEBUG TRAIN Batch 8/7400 loss 16.309170 loss_att 19.165243 loss_ctc 24.056992 loss_rnnt 14.704912 lr 0.00058091 rank 5
2022-12-04 03:22:43,912 DEBUG TRAIN Batch 8/7400 loss 11.887123 loss_att 15.002171 loss_ctc 15.349419 loss_rnnt 10.802475 lr 0.00058085 rank 3
2022-12-04 03:22:43,916 DEBUG TRAIN Batch 8/7400 loss 19.775381 loss_att 28.770977 loss_ctc 31.634945 loss_rnnt 16.394985 lr 0.00058088 rank 7
2022-12-04 03:22:43,917 DEBUG TRAIN Batch 8/7400 loss 19.621387 loss_att 26.499138 loss_ctc 32.081966 loss_rnnt 16.584427 lr 0.00058088 rank 6
2022-12-04 03:22:43,919 DEBUG TRAIN Batch 8/7400 loss 12.500153 loss_att 18.166946 loss_ctc 21.756165 loss_rnnt 10.132658 lr 0.00058058 rank 2
2022-12-04 03:22:43,919 DEBUG TRAIN Batch 8/7400 loss 16.015198 loss_att 21.171030 loss_ctc 30.039959 loss_rnnt 13.114061 lr 0.00058067 rank 0
2022-12-04 03:22:43,922 DEBUG TRAIN Batch 8/7400 loss 12.202902 loss_att 14.459797 loss_ctc 19.818089 loss_rnnt 10.736164 lr 0.00058093 rank 4
2022-12-04 03:22:43,959 DEBUG TRAIN Batch 8/7400 loss 13.304258 loss_att 16.755854 loss_ctc 19.562731 loss_rnnt 11.779476 lr 0.00058081 rank 1
2022-12-04 03:24:11,513 DEBUG TRAIN Batch 8/7500 loss 22.993101 loss_att 29.454983 loss_ctc 38.847492 loss_rnnt 19.586807 lr 0.00058049 rank 6
2022-12-04 03:24:11,513 DEBUG TRAIN Batch 8/7500 loss 14.722429 loss_att 16.797258 loss_ctc 27.723038 loss_rnnt 12.574048 lr 0.00058046 rank 3
2022-12-04 03:24:11,514 DEBUG TRAIN Batch 8/7500 loss 17.895905 loss_att 22.997856 loss_ctc 33.907986 loss_rnnt 14.740570 lr 0.00058042 rank 1
2022-12-04 03:24:11,517 DEBUG TRAIN Batch 8/7500 loss 13.663164 loss_att 15.654619 loss_ctc 18.906721 loss_rnnt 12.565733 lr 0.00058052 rank 5
2022-12-04 03:24:11,519 DEBUG TRAIN Batch 8/7500 loss 19.803185 loss_att 22.497974 loss_ctc 30.228043 loss_rnnt 17.874245 lr 0.00058027 rank 0
2022-12-04 03:24:11,518 DEBUG TRAIN Batch 8/7500 loss 20.342817 loss_att 23.841238 loss_ctc 38.852272 loss_rnnt 17.175205 lr 0.00058018 rank 2
2022-12-04 03:24:11,518 DEBUG TRAIN Batch 8/7500 loss 26.912991 loss_att 27.169424 loss_ctc 37.834526 loss_rnnt 25.405497 lr 0.00058054 rank 4
2022-12-04 03:24:11,519 DEBUG TRAIN Batch 8/7500 loss 17.290689 loss_att 20.836058 loss_ctc 28.276459 loss_rnnt 15.116847 lr 0.00058049 rank 7
2022-12-04 03:25:23,254 DEBUG TRAIN Batch 8/7600 loss 9.373061 loss_att 13.777002 loss_ctc 15.779887 loss_rnnt 7.638030 lr 0.00057988 rank 0
2022-12-04 03:25:23,258 DEBUG TRAIN Batch 8/7600 loss 15.582563 loss_att 18.472115 loss_ctc 23.863573 loss_rnnt 13.900517 lr 0.00058010 rank 6
2022-12-04 03:25:23,259 DEBUG TRAIN Batch 8/7600 loss 9.240898 loss_att 13.630476 loss_ctc 16.729202 loss_rnnt 7.364543 lr 0.00058013 rank 5
2022-12-04 03:25:23,259 DEBUG TRAIN Batch 8/7600 loss 9.423491 loss_att 11.904203 loss_ctc 12.726858 loss_rnnt 8.486900 lr 0.00058010 rank 7
2022-12-04 03:25:23,262 DEBUG TRAIN Batch 8/7600 loss 3.846625 loss_att 8.313310 loss_ctc 8.576529 loss_rnnt 2.322634 lr 0.00058003 rank 1
2022-12-04 03:25:23,263 DEBUG TRAIN Batch 8/7600 loss 8.044096 loss_att 10.125546 loss_ctc 15.787968 loss_rnnt 6.595289 lr 0.00057979 rank 2
2022-12-04 03:25:23,266 DEBUG TRAIN Batch 8/7600 loss 10.860147 loss_att 13.164316 loss_ctc 19.797173 loss_rnnt 9.207709 lr 0.00058015 rank 4
2022-12-04 03:25:23,268 DEBUG TRAIN Batch 8/7600 loss 23.484343 loss_att 29.563356 loss_ctc 36.060009 loss_rnnt 20.591785 lr 0.00058007 rank 3
2022-12-04 03:26:35,260 DEBUG TRAIN Batch 8/7700 loss 32.998959 loss_att 34.793285 loss_ctc 54.485962 loss_rnnt 29.775160 lr 0.00057974 rank 5
2022-12-04 03:26:35,259 DEBUG TRAIN Batch 8/7700 loss 33.032097 loss_att 37.952213 loss_ctc 49.999077 loss_rnnt 29.785810 lr 0.00057968 rank 3
2022-12-04 03:26:35,261 DEBUG TRAIN Batch 8/7700 loss 18.404112 loss_att 20.885494 loss_ctc 30.314327 loss_rnnt 16.319807 lr 0.00057949 rank 0
2022-12-04 03:26:35,264 DEBUG TRAIN Batch 8/7700 loss 7.334031 loss_att 14.311697 loss_ctc 12.596252 loss_rnnt 5.236868 lr 0.00057964 rank 1
2022-12-04 03:26:35,265 DEBUG TRAIN Batch 8/7700 loss 19.868416 loss_att 19.683777 loss_ctc 32.381294 loss_rnnt 18.236961 lr 0.00057971 rank 7
2022-12-04 03:26:35,268 DEBUG TRAIN Batch 8/7700 loss 13.873411 loss_att 15.996438 loss_ctc 19.854948 loss_rnnt 12.651268 lr 0.00057941 rank 2
2022-12-04 03:26:35,269 DEBUG TRAIN Batch 8/7700 loss 23.818016 loss_att 31.972498 loss_ctc 31.627686 loss_rnnt 21.145828 lr 0.00057971 rank 6
2022-12-04 03:26:35,278 DEBUG TRAIN Batch 8/7700 loss 21.425686 loss_att 25.276253 loss_ctc 34.234436 loss_rnnt 18.947739 lr 0.00057976 rank 4
2022-12-04 03:27:48,843 DEBUG TRAIN Batch 8/7800 loss 19.260061 loss_att 23.267784 loss_ctc 32.262096 loss_rnnt 16.724911 lr 0.00057935 rank 5
2022-12-04 03:27:48,844 DEBUG TRAIN Batch 8/7800 loss 18.662266 loss_att 26.397751 loss_ctc 39.881447 loss_rnnt 14.285943 lr 0.00057929 rank 3
2022-12-04 03:27:48,846 DEBUG TRAIN Batch 8/7800 loss 14.432575 loss_att 20.497402 loss_ctc 27.409201 loss_rnnt 11.489393 lr 0.00057932 rank 7
2022-12-04 03:27:48,853 DEBUG TRAIN Batch 8/7800 loss 17.285673 loss_att 18.087027 loss_ctc 30.615725 loss_rnnt 15.348061 lr 0.00057925 rank 1
2022-12-04 03:27:48,856 DEBUG TRAIN Batch 8/7800 loss 6.345491 loss_att 9.143447 loss_ctc 13.673022 loss_rnnt 4.808895 lr 0.00057932 rank 6
2022-12-04 03:27:48,858 DEBUG TRAIN Batch 8/7800 loss 9.298745 loss_att 17.749346 loss_ctc 13.720957 loss_rnnt 7.018997 lr 0.00057911 rank 0
2022-12-04 03:27:48,870 DEBUG TRAIN Batch 8/7800 loss 13.873403 loss_att 18.542448 loss_ctc 21.610153 loss_rnnt 11.908027 lr 0.00057902 rank 2
2022-12-04 03:27:48,873 DEBUG TRAIN Batch 8/7800 loss 23.294531 loss_att 30.457115 loss_ctc 34.470184 loss_rnnt 20.371927 lr 0.00057937 rank 4
2022-12-04 03:29:16,622 DEBUG TRAIN Batch 8/7900 loss 17.448301 loss_att 25.160879 loss_ctc 30.595139 loss_rnnt 14.152873 lr 0.00057887 rank 1
2022-12-04 03:29:16,626 DEBUG TRAIN Batch 8/7900 loss 18.565800 loss_att 21.288988 loss_ctc 32.451851 loss_rnnt 16.169689 lr 0.00057896 rank 5
2022-12-04 03:29:16,626 DEBUG TRAIN Batch 8/7900 loss 14.217929 loss_att 19.800497 loss_ctc 23.511284 loss_rnnt 11.862301 lr 0.00057890 rank 3
2022-12-04 03:29:16,626 DEBUG TRAIN Batch 8/7900 loss 5.136041 loss_att 10.361104 loss_ctc 11.257564 loss_rnnt 3.274826 lr 0.00057893 rank 6
2022-12-04 03:29:16,631 DEBUG TRAIN Batch 8/7900 loss 12.904375 loss_att 16.760141 loss_ctc 24.858231 loss_rnnt 10.539373 lr 0.00057893 rank 7
2022-12-04 03:29:16,632 DEBUG TRAIN Batch 8/7900 loss 18.873381 loss_att 20.730640 loss_ctc 31.629601 loss_rnnt 16.801100 lr 0.00057863 rank 2
2022-12-04 03:29:16,633 DEBUG TRAIN Batch 8/7900 loss 22.254705 loss_att 29.788054 loss_ctc 37.301762 loss_rnnt 18.741760 lr 0.00057872 rank 0
2022-12-04 03:29:16,636 DEBUG TRAIN Batch 8/7900 loss 28.295856 loss_att 29.810183 loss_ctc 37.937534 loss_rnnt 26.707436 lr 0.00057898 rank 4
2022-12-04 03:30:27,533 DEBUG TRAIN Batch 8/8000 loss 15.623213 loss_att 19.947273 loss_ctc 26.699764 loss_rnnt 13.281527 lr 0.00057854 rank 6
2022-12-04 03:30:27,534 DEBUG TRAIN Batch 8/8000 loss 28.132307 loss_att 40.347080 loss_ctc 50.980011 loss_rnnt 22.642990 lr 0.00057833 rank 0
2022-12-04 03:30:27,536 DEBUG TRAIN Batch 8/8000 loss 16.201426 loss_att 20.938984 loss_ctc 26.154737 loss_rnnt 13.926806 lr 0.00057851 rank 3
2022-12-04 03:30:27,537 DEBUG TRAIN Batch 8/8000 loss 12.614855 loss_att 15.363087 loss_ctc 17.680439 loss_rnnt 11.389797 lr 0.00057854 rank 7
2022-12-04 03:30:27,539 DEBUG TRAIN Batch 8/8000 loss 7.780284 loss_att 10.993402 loss_ctc 15.303370 loss_rnnt 6.134582 lr 0.00057824 rank 2
2022-12-04 03:30:27,541 DEBUG TRAIN Batch 8/8000 loss 29.113655 loss_att 32.300232 loss_ctc 48.961262 loss_rnnt 25.829990 lr 0.00057848 rank 1
2022-12-04 03:30:27,547 DEBUG TRAIN Batch 8/8000 loss 12.504318 loss_att 16.210331 loss_ctc 18.015024 loss_rnnt 11.028355 lr 0.00057859 rank 4
2022-12-04 03:30:27,585 DEBUG TRAIN Batch 8/8000 loss 21.892054 loss_att 25.838825 loss_ctc 30.513283 loss_rnnt 19.953201 lr 0.00057857 rank 5
2022-12-04 03:31:40,070 DEBUG TRAIN Batch 8/8100 loss 15.417644 loss_att 17.759064 loss_ctc 22.714682 loss_rnnt 13.976421 lr 0.00057813 rank 3
2022-12-04 03:31:40,075 DEBUG TRAIN Batch 8/8100 loss 11.655247 loss_att 15.083717 loss_ctc 19.353859 loss_rnnt 9.943070 lr 0.00057794 rank 0
2022-12-04 03:31:40,075 DEBUG TRAIN Batch 8/8100 loss 17.076443 loss_att 18.106361 loss_ctc 20.744610 loss_rnnt 16.381371 lr 0.00057816 rank 6
2022-12-04 03:31:40,077 DEBUG TRAIN Batch 8/8100 loss 13.322513 loss_att 16.966591 loss_ctc 19.919270 loss_rnnt 11.714129 lr 0.00057809 rank 1
2022-12-04 03:31:40,083 DEBUG TRAIN Batch 8/8100 loss 16.182144 loss_att 17.145149 loss_ctc 22.016550 loss_rnnt 15.211622 lr 0.00057818 rank 5
2022-12-04 03:31:40,084 DEBUG TRAIN Batch 8/8100 loss 18.805052 loss_att 21.428747 loss_ctc 27.524145 loss_rnnt 17.117767 lr 0.00057786 rank 2
2022-12-04 03:31:40,099 DEBUG TRAIN Batch 8/8100 loss 19.961351 loss_att 24.669735 loss_ctc 30.859055 loss_rnnt 17.566648 lr 0.00057820 rank 4
2022-12-04 03:31:40,132 DEBUG TRAIN Batch 8/8100 loss 7.053792 loss_att 12.218298 loss_ctc 14.832298 loss_rnnt 4.983757 lr 0.00057816 rank 7
2022-12-04 03:32:53,678 DEBUG TRAIN Batch 8/8200 loss 23.334223 loss_att 34.646412 loss_ctc 34.511059 loss_rnnt 19.581539 lr 0.00057770 rank 1
2022-12-04 03:32:53,680 DEBUG TRAIN Batch 8/8200 loss 17.014183 loss_att 20.255465 loss_ctc 25.298958 loss_rnnt 15.261290 lr 0.00057756 rank 0
2022-12-04 03:32:53,683 DEBUG TRAIN Batch 8/8200 loss 16.134031 loss_att 19.374971 loss_ctc 29.074074 loss_rnnt 13.760504 lr 0.00057747 rank 2
2022-12-04 03:32:53,684 DEBUG TRAIN Batch 8/8200 loss 18.870161 loss_att 20.956383 loss_ctc 34.733528 loss_rnnt 16.337801 lr 0.00057777 rank 6
2022-12-04 03:32:53,684 DEBUG TRAIN Batch 8/8200 loss 9.714664 loss_att 11.160741 loss_ctc 14.809379 loss_rnnt 8.746154 lr 0.00057780 rank 5
2022-12-04 03:32:53,685 DEBUG TRAIN Batch 8/8200 loss 9.763902 loss_att 17.008890 loss_ctc 20.283159 loss_rnnt 6.912335 lr 0.00057774 rank 3
2022-12-04 03:32:53,688 DEBUG TRAIN Batch 8/8200 loss 12.784897 loss_att 16.937023 loss_ctc 19.725060 loss_rnnt 11.029116 lr 0.00057777 rank 7
2022-12-04 03:32:53,689 DEBUG TRAIN Batch 8/8200 loss 7.943748 loss_att 9.088987 loss_ctc 10.932171 loss_rnnt 7.316243 lr 0.00057782 rank 4
2022-12-04 03:34:04,980 DEBUG TRAIN Batch 8/8300 loss 13.610014 loss_att 17.705584 loss_ctc 22.142279 loss_rnnt 11.653265 lr 0.00057732 rank 1
2022-12-04 03:34:05,001 DEBUG TRAIN Batch 8/8300 loss 15.700727 loss_att 17.779776 loss_ctc 23.819418 loss_rnnt 14.202425 lr 0.00057708 rank 2
2022-12-04 03:34:05,002 DEBUG TRAIN Batch 8/8300 loss 16.273487 loss_att 20.525991 loss_ctc 28.327297 loss_rnnt 13.815811 lr 0.00057741 rank 5
2022-12-04 03:34:05,002 DEBUG TRAIN Batch 8/8300 loss 9.563334 loss_att 12.161871 loss_ctc 16.280031 loss_rnnt 8.148066 lr 0.00057738 rank 6
2022-12-04 03:34:05,002 DEBUG TRAIN Batch 8/8300 loss 7.870288 loss_att 12.955724 loss_ctc 10.798417 loss_rnnt 6.462784 lr 0.00057717 rank 0
2022-12-04 03:34:05,002 DEBUG TRAIN Batch 8/8300 loss 12.896168 loss_att 17.235645 loss_ctc 22.962242 loss_rnnt 10.686128 lr 0.00057738 rank 7
2022-12-04 03:34:05,003 DEBUG TRAIN Batch 8/8300 loss 14.308016 loss_att 20.804811 loss_ctc 25.184959 loss_rnnt 11.558397 lr 0.00057735 rank 3
2022-12-04 03:34:05,011 DEBUG TRAIN Batch 8/8300 loss 28.862553 loss_att 29.784584 loss_ctc 36.241711 loss_rnnt 27.694260 lr 0.00057743 rank 4
2022-12-04 03:34:57,447 DEBUG CV Batch 8/0 loss 2.129161 loss_att 2.374060 loss_ctc 4.428423 loss_rnnt 1.773613 history loss 2.050304 rank 4
2022-12-04 03:34:57,448 DEBUG CV Batch 8/0 loss 2.129161 loss_att 2.374060 loss_ctc 4.428423 loss_rnnt 1.773613 history loss 2.050304 rank 7
2022-12-04 03:34:57,449 DEBUG CV Batch 8/0 loss 2.129161 loss_att 2.374060 loss_ctc 4.428423 loss_rnnt 1.773613 history loss 2.050304 rank 0
2022-12-04 03:34:57,456 DEBUG CV Batch 8/0 loss 2.129161 loss_att 2.374060 loss_ctc 4.428423 loss_rnnt 1.773613 history loss 2.050304 rank 1
2022-12-04 03:34:57,457 DEBUG CV Batch 8/0 loss 2.129161 loss_att 2.374060 loss_ctc 4.428423 loss_rnnt 1.773613 history loss 2.050304 rank 3
2022-12-04 03:34:57,460 DEBUG CV Batch 8/0 loss 2.129161 loss_att 2.374060 loss_ctc 4.428423 loss_rnnt 1.773613 history loss 2.050304 rank 6
2022-12-04 03:34:57,470 DEBUG CV Batch 8/0 loss 2.129161 loss_att 2.374060 loss_ctc 4.428423 loss_rnnt 1.773613 history loss 2.050304 rank 2
2022-12-04 03:34:57,475 DEBUG CV Batch 8/0 loss 2.129161 loss_att 2.374060 loss_ctc 4.428423 loss_rnnt 1.773613 history loss 2.050304 rank 5
2022-12-04 03:35:08,786 DEBUG CV Batch 8/100 loss 8.021418 loss_att 9.102507 loss_ctc 13.873474 loss_rnnt 7.024925 history loss 4.363476 rank 5
2022-12-04 03:35:08,841 DEBUG CV Batch 8/100 loss 8.021418 loss_att 9.102507 loss_ctc 13.873474 loss_rnnt 7.024925 history loss 4.363476 rank 4
2022-12-04 03:35:08,867 DEBUG CV Batch 8/100 loss 8.021418 loss_att 9.102507 loss_ctc 13.873474 loss_rnnt 7.024925 history loss 4.363476 rank 2
2022-12-04 03:35:08,891 DEBUG CV Batch 8/100 loss 8.021418 loss_att 9.102507 loss_ctc 13.873474 loss_rnnt 7.024925 history loss 4.363476 rank 7
2022-12-04 03:35:09,084 DEBUG CV Batch 8/100 loss 8.021418 loss_att 9.102507 loss_ctc 13.873474 loss_rnnt 7.024925 history loss 4.363476 rank 0
2022-12-04 03:35:09,181 DEBUG CV Batch 8/100 loss 8.021418 loss_att 9.102507 loss_ctc 13.873474 loss_rnnt 7.024925 history loss 4.363476 rank 3
2022-12-04 03:35:09,191 DEBUG CV Batch 8/100 loss 8.021418 loss_att 9.102507 loss_ctc 13.873474 loss_rnnt 7.024925 history loss 4.363476 rank 6
2022-12-04 03:35:09,216 DEBUG CV Batch 8/100 loss 8.021418 loss_att 9.102507 loss_ctc 13.873474 loss_rnnt 7.024925 history loss 4.363476 rank 1
2022-12-04 03:35:22,370 DEBUG CV Batch 8/200 loss 11.810458 loss_att 19.492529 loss_ctc 15.139840 loss_rnnt 9.830127 history loss 5.061228 rank 5
2022-12-04 03:35:22,598 DEBUG CV Batch 8/200 loss 11.810458 loss_att 19.492529 loss_ctc 15.139840 loss_rnnt 9.830127 history loss 5.061228 rank 1
2022-12-04 03:35:22,666 DEBUG CV Batch 8/200 loss 11.810458 loss_att 19.492529 loss_ctc 15.139840 loss_rnnt 9.830127 history loss 5.061228 rank 0
2022-12-04 03:35:22,814 DEBUG CV Batch 8/200 loss 11.810458 loss_att 19.492529 loss_ctc 15.139840 loss_rnnt 9.830127 history loss 5.061228 rank 2
2022-12-04 03:35:22,848 DEBUG CV Batch 8/200 loss 11.810458 loss_att 19.492529 loss_ctc 15.139840 loss_rnnt 9.830127 history loss 5.061228 rank 4
2022-12-04 03:35:22,903 DEBUG CV Batch 8/200 loss 11.810458 loss_att 19.492529 loss_ctc 15.139840 loss_rnnt 9.830127 history loss 5.061228 rank 6
2022-12-04 03:35:22,952 DEBUG CV Batch 8/200 loss 11.810458 loss_att 19.492529 loss_ctc 15.139840 loss_rnnt 9.830127 history loss 5.061228 rank 3
2022-12-04 03:35:22,994 DEBUG CV Batch 8/200 loss 11.810458 loss_att 19.492529 loss_ctc 15.139840 loss_rnnt 9.830127 history loss 5.061228 rank 7
2022-12-04 03:35:34,410 DEBUG CV Batch 8/300 loss 4.565643 loss_att 6.296929 loss_ctc 9.780754 loss_rnnt 3.524038 history loss 5.165233 rank 5
2022-12-04 03:35:34,580 DEBUG CV Batch 8/300 loss 4.565643 loss_att 6.296929 loss_ctc 9.780754 loss_rnnt 3.524038 history loss 5.165233 rank 1
2022-12-04 03:35:34,755 DEBUG CV Batch 8/300 loss 4.565643 loss_att 6.296929 loss_ctc 9.780754 loss_rnnt 3.524038 history loss 5.165233 rank 4
2022-12-04 03:35:34,911 DEBUG CV Batch 8/300 loss 4.565643 loss_att 6.296929 loss_ctc 9.780754 loss_rnnt 3.524038 history loss 5.165233 rank 0
2022-12-04 03:35:35,003 DEBUG CV Batch 8/300 loss 4.565643 loss_att 6.296929 loss_ctc 9.780754 loss_rnnt 3.524038 history loss 5.165233 rank 7
2022-12-04 03:35:35,171 DEBUG CV Batch 8/300 loss 4.565643 loss_att 6.296929 loss_ctc 9.780754 loss_rnnt 3.524038 history loss 5.165233 rank 6
2022-12-04 03:35:35,221 DEBUG CV Batch 8/300 loss 4.565643 loss_att 6.296929 loss_ctc 9.780754 loss_rnnt 3.524038 history loss 5.165233 rank 2
2022-12-04 03:35:35,250 DEBUG CV Batch 8/300 loss 4.565643 loss_att 6.296929 loss_ctc 9.780754 loss_rnnt 3.524038 history loss 5.165233 rank 3
2022-12-04 03:35:46,508 DEBUG CV Batch 8/400 loss 18.084049 loss_att 83.101807 loss_ctc 18.133801 loss_rnnt 5.073862 history loss 6.157426 rank 5
2022-12-04 03:35:46,600 DEBUG CV Batch 8/400 loss 18.084049 loss_att 83.101807 loss_ctc 18.133801 loss_rnnt 5.073862 history loss 6.157426 rank 1
2022-12-04 03:35:46,626 DEBUG CV Batch 8/400 loss 18.084049 loss_att 83.101807 loss_ctc 18.133801 loss_rnnt 5.073862 history loss 6.157426 rank 4
2022-12-04 03:35:46,896 DEBUG CV Batch 8/400 loss 18.084049 loss_att 83.101807 loss_ctc 18.133801 loss_rnnt 5.073862 history loss 6.157426 rank 7
2022-12-04 03:35:47,199 DEBUG CV Batch 8/400 loss 18.084049 loss_att 83.101807 loss_ctc 18.133801 loss_rnnt 5.073862 history loss 6.157426 rank 0
2022-12-04 03:35:47,236 DEBUG CV Batch 8/400 loss 18.084049 loss_att 83.101807 loss_ctc 18.133801 loss_rnnt 5.073862 history loss 6.157426 rank 2
2022-12-04 03:35:47,535 DEBUG CV Batch 8/400 loss 18.084049 loss_att 83.101807 loss_ctc 18.133801 loss_rnnt 5.073862 history loss 6.157426 rank 6
2022-12-04 03:35:47,806 DEBUG CV Batch 8/400 loss 18.084049 loss_att 83.101807 loss_ctc 18.133801 loss_rnnt 5.073862 history loss 6.157426 rank 3
2022-12-04 03:35:56,829 DEBUG CV Batch 8/500 loss 9.475021 loss_att 9.722778 loss_ctc 12.863762 loss_rnnt 8.973638 history loss 6.979393 rank 1
2022-12-04 03:35:56,894 DEBUG CV Batch 8/500 loss 9.475021 loss_att 9.722778 loss_ctc 12.863762 loss_rnnt 8.973638 history loss 6.979393 rank 5
2022-12-04 03:35:57,401 DEBUG CV Batch 8/500 loss 9.475021 loss_att 9.722778 loss_ctc 12.863762 loss_rnnt 8.973638 history loss 6.979393 rank 7
2022-12-04 03:35:57,448 DEBUG CV Batch 8/500 loss 9.475021 loss_att 9.722778 loss_ctc 12.863762 loss_rnnt 8.973638 history loss 6.979393 rank 4
2022-12-04 03:35:57,637 DEBUG CV Batch 8/500 loss 9.475021 loss_att 9.722778 loss_ctc 12.863762 loss_rnnt 8.973638 history loss 6.979393 rank 2
2022-12-04 03:35:58,066 DEBUG CV Batch 8/500 loss 9.475021 loss_att 9.722778 loss_ctc 12.863762 loss_rnnt 8.973638 history loss 6.979393 rank 0
2022-12-04 03:35:58,193 DEBUG CV Batch 8/500 loss 9.475021 loss_att 9.722778 loss_ctc 12.863762 loss_rnnt 8.973638 history loss 6.979393 rank 6
2022-12-04 03:35:58,620 DEBUG CV Batch 8/500 loss 9.475021 loss_att 9.722778 loss_ctc 12.863762 loss_rnnt 8.973638 history loss 6.979393 rank 3
2022-12-04 03:36:08,817 DEBUG CV Batch 8/600 loss 7.018384 loss_att 7.925945 loss_ctc 11.210370 loss_rnnt 6.277940 history loss 7.838741 rank 1
2022-12-04 03:36:08,971 DEBUG CV Batch 8/600 loss 7.018384 loss_att 7.925945 loss_ctc 11.210370 loss_rnnt 6.277940 history loss 7.838741 rank 5
2022-12-04 03:36:09,569 DEBUG CV Batch 8/600 loss 7.018384 loss_att 7.925945 loss_ctc 11.210370 loss_rnnt 6.277940 history loss 7.838741 rank 4
2022-12-04 03:36:09,791 DEBUG CV Batch 8/600 loss 7.018384 loss_att 7.925945 loss_ctc 11.210370 loss_rnnt 6.277940 history loss 7.838741 rank 7
2022-12-04 03:36:09,877 DEBUG CV Batch 8/600 loss 7.018384 loss_att 7.925945 loss_ctc 11.210370 loss_rnnt 6.277940 history loss 7.838741 rank 2
2022-12-04 03:36:10,324 DEBUG CV Batch 8/600 loss 7.018384 loss_att 7.925945 loss_ctc 11.210370 loss_rnnt 6.277940 history loss 7.838741 rank 6
2022-12-04 03:36:10,502 DEBUG CV Batch 8/600 loss 7.018384 loss_att 7.925945 loss_ctc 11.210370 loss_rnnt 6.277940 history loss 7.838741 rank 0
2022-12-04 03:36:11,019 DEBUG CV Batch 8/600 loss 7.018384 loss_att 7.925945 loss_ctc 11.210370 loss_rnnt 6.277940 history loss 7.838741 rank 3
2022-12-04 03:36:20,045 DEBUG CV Batch 8/700 loss 15.005463 loss_att 45.856701 loss_ctc 24.812553 loss_rnnt 7.527604 history loss 8.497946 rank 1
2022-12-04 03:36:20,290 DEBUG CV Batch 8/700 loss 15.005463 loss_att 45.856701 loss_ctc 24.812553 loss_rnnt 7.527604 history loss 8.497946 rank 5
2022-12-04 03:36:21,323 DEBUG CV Batch 8/700 loss 15.005463 loss_att 45.856701 loss_ctc 24.812553 loss_rnnt 7.527604 history loss 8.497946 rank 2
2022-12-04 03:36:21,572 DEBUG CV Batch 8/700 loss 15.005463 loss_att 45.856701 loss_ctc 24.812553 loss_rnnt 7.527604 history loss 8.497946 rank 4
2022-12-04 03:36:21,627 DEBUG CV Batch 8/700 loss 15.005463 loss_att 45.856701 loss_ctc 24.812553 loss_rnnt 7.527604 history loss 8.497946 rank 7
2022-12-04 03:36:21,815 DEBUG CV Batch 8/700 loss 15.005463 loss_att 45.856701 loss_ctc 24.812553 loss_rnnt 7.527604 history loss 8.497946 rank 6
2022-12-04 03:36:22,258 DEBUG CV Batch 8/700 loss 15.005463 loss_att 45.856701 loss_ctc 24.812553 loss_rnnt 7.527604 history loss 8.497946 rank 0
2022-12-04 03:36:22,712 DEBUG CV Batch 8/700 loss 15.005463 loss_att 45.856701 loss_ctc 24.812553 loss_rnnt 7.527604 history loss 8.497946 rank 3
2022-12-04 03:36:31,364 DEBUG CV Batch 8/800 loss 11.091062 loss_att 11.401598 loss_ctc 18.133347 loss_rnnt 10.089983 history loss 7.938540 rank 1
2022-12-04 03:36:31,816 DEBUG CV Batch 8/800 loss 11.091062 loss_att 11.401598 loss_ctc 18.133347 loss_rnnt 10.089983 history loss 7.938540 rank 5
2022-12-04 03:36:33,226 DEBUG CV Batch 8/800 loss 11.091062 loss_att 11.401598 loss_ctc 18.133347 loss_rnnt 10.089983 history loss 7.938540 rank 6
2022-12-04 03:36:33,481 DEBUG CV Batch 8/800 loss 11.091062 loss_att 11.401598 loss_ctc 18.133347 loss_rnnt 10.089983 history loss 7.938540 rank 2
2022-12-04 03:36:33,641 DEBUG CV Batch 8/800 loss 11.091062 loss_att 11.401598 loss_ctc 18.133347 loss_rnnt 10.089983 history loss 7.938540 rank 4
2022-12-04 03:36:33,674 DEBUG CV Batch 8/800 loss 11.091062 loss_att 11.401598 loss_ctc 18.133347 loss_rnnt 10.089983 history loss 7.938540 rank 7
2022-12-04 03:36:33,758 DEBUG CV Batch 8/800 loss 11.091062 loss_att 11.401598 loss_ctc 18.133347 loss_rnnt 10.089983 history loss 7.938540 rank 0
2022-12-04 03:36:34,277 DEBUG CV Batch 8/800 loss 11.091062 loss_att 11.401598 loss_ctc 18.133347 loss_rnnt 10.089983 history loss 7.938540 rank 3
2022-12-04 03:36:44,751 DEBUG CV Batch 8/900 loss 13.340179 loss_att 19.588478 loss_ctc 21.344231 loss_rnnt 11.023314 history loss 7.752054 rank 1
2022-12-04 03:36:45,215 DEBUG CV Batch 8/900 loss 13.340179 loss_att 19.588478 loss_ctc 21.344231 loss_rnnt 11.023314 history loss 7.752054 rank 5
2022-12-04 03:36:46,809 DEBUG CV Batch 8/900 loss 13.340179 loss_att 19.588478 loss_ctc 21.344231 loss_rnnt 11.023314 history loss 7.752054 rank 6
2022-12-04 03:36:47,278 DEBUG CV Batch 8/900 loss 13.340179 loss_att 19.588478 loss_ctc 21.344231 loss_rnnt 11.023314 history loss 7.752054 rank 7
2022-12-04 03:36:47,335 DEBUG CV Batch 8/900 loss 13.340179 loss_att 19.588478 loss_ctc 21.344231 loss_rnnt 11.023314 history loss 7.752054 rank 2
2022-12-04 03:36:47,370 DEBUG CV Batch 8/900 loss 13.340179 loss_att 19.588478 loss_ctc 21.344231 loss_rnnt 11.023314 history loss 7.752054 rank 4
2022-12-04 03:36:47,576 DEBUG CV Batch 8/900 loss 13.340179 loss_att 19.588478 loss_ctc 21.344231 loss_rnnt 11.023314 history loss 7.752054 rank 0
2022-12-04 03:36:48,042 DEBUG CV Batch 8/900 loss 13.340179 loss_att 19.588478 loss_ctc 21.344231 loss_rnnt 11.023314 history loss 7.752054 rank 3
2022-12-04 03:36:56,810 DEBUG CV Batch 8/1000 loss 6.809222 loss_att 6.639695 loss_ctc 7.799917 loss_rnnt 6.711035 history loss 7.511137 rank 1
2022-12-04 03:36:57,294 DEBUG CV Batch 8/1000 loss 6.809222 loss_att 6.639695 loss_ctc 7.799917 loss_rnnt 6.711035 history loss 7.511137 rank 5
2022-12-04 03:36:59,365 DEBUG CV Batch 8/1000 loss 6.809222 loss_att 6.639695 loss_ctc 7.799917 loss_rnnt 6.711035 history loss 7.511137 rank 6
2022-12-04 03:36:59,528 DEBUG CV Batch 8/1000 loss 6.809222 loss_att 6.639695 loss_ctc 7.799917 loss_rnnt 6.711035 history loss 7.511137 rank 4
2022-12-04 03:36:59,592 DEBUG CV Batch 8/1000 loss 6.809222 loss_att 6.639695 loss_ctc 7.799917 loss_rnnt 6.711035 history loss 7.511137 rank 2
2022-12-04 03:36:59,604 DEBUG CV Batch 8/1000 loss 6.809222 loss_att 6.639695 loss_ctc 7.799917 loss_rnnt 6.711035 history loss 7.511137 rank 7
2022-12-04 03:37:00,245 DEBUG CV Batch 8/1000 loss 6.809222 loss_att 6.639695 loss_ctc 7.799917 loss_rnnt 6.711035 history loss 7.511137 rank 0
2022-12-04 03:37:00,797 DEBUG CV Batch 8/1000 loss 6.809222 loss_att 6.639695 loss_ctc 7.799917 loss_rnnt 6.711035 history loss 7.511137 rank 3
2022-12-04 03:37:08,769 DEBUG CV Batch 8/1100 loss 5.429296 loss_att 5.424388 loss_ctc 9.636748 loss_rnnt 4.869284 history loss 7.494827 rank 1
2022-12-04 03:37:09,421 DEBUG CV Batch 8/1100 loss 5.429296 loss_att 5.424388 loss_ctc 9.636748 loss_rnnt 4.869284 history loss 7.494827 rank 5
2022-12-04 03:37:11,354 DEBUG CV Batch 8/1100 loss 5.429296 loss_att 5.424388 loss_ctc 9.636748 loss_rnnt 4.869284 history loss 7.494827 rank 4
2022-12-04 03:37:11,568 DEBUG CV Batch 8/1100 loss 5.429296 loss_att 5.424388 loss_ctc 9.636748 loss_rnnt 4.869284 history loss 7.494827 rank 7
2022-12-04 03:37:11,579 DEBUG CV Batch 8/1100 loss 5.429296 loss_att 5.424388 loss_ctc 9.636748 loss_rnnt 4.869284 history loss 7.494827 rank 6
2022-12-04 03:37:11,830 DEBUG CV Batch 8/1100 loss 5.429296 loss_att 5.424388 loss_ctc 9.636748 loss_rnnt 4.869284 history loss 7.494827 rank 2
2022-12-04 03:37:12,697 DEBUG CV Batch 8/1100 loss 5.429296 loss_att 5.424388 loss_ctc 9.636748 loss_rnnt 4.869284 history loss 7.494827 rank 0
2022-12-04 03:37:13,288 DEBUG CV Batch 8/1100 loss 5.429296 loss_att 5.424388 loss_ctc 9.636748 loss_rnnt 4.869284 history loss 7.494827 rank 3
2022-12-04 03:37:18,884 DEBUG CV Batch 8/1200 loss 11.777835 loss_att 11.766212 loss_ctc 13.816025 loss_rnnt 11.508401 history loss 7.857107 rank 1
2022-12-04 03:37:19,746 DEBUG CV Batch 8/1200 loss 11.777835 loss_att 11.766212 loss_ctc 13.816025 loss_rnnt 11.508401 history loss 7.857107 rank 5
2022-12-04 03:37:21,971 DEBUG CV Batch 8/1200 loss 11.777835 loss_att 11.766212 loss_ctc 13.816025 loss_rnnt 11.508401 history loss 7.857107 rank 4
2022-12-04 03:37:22,220 DEBUG CV Batch 8/1200 loss 11.777835 loss_att 11.766212 loss_ctc 13.816025 loss_rnnt 11.508401 history loss 7.857107 rank 7
2022-12-04 03:37:22,343 DEBUG CV Batch 8/1200 loss 11.777835 loss_att 11.766212 loss_ctc 13.816025 loss_rnnt 11.508401 history loss 7.857107 rank 2
2022-12-04 03:37:22,556 DEBUG CV Batch 8/1200 loss 11.777835 loss_att 11.766212 loss_ctc 13.816025 loss_rnnt 11.508401 history loss 7.857107 rank 6
2022-12-04 03:37:23,862 DEBUG CV Batch 8/1200 loss 11.777835 loss_att 11.766212 loss_ctc 13.816025 loss_rnnt 11.508401 history loss 7.857107 rank 0
2022-12-04 03:37:24,406 DEBUG CV Batch 8/1200 loss 11.777835 loss_att 11.766212 loss_ctc 13.816025 loss_rnnt 11.508401 history loss 7.857107 rank 3
2022-12-04 03:37:31,277 DEBUG CV Batch 8/1300 loss 6.176580 loss_att 6.442161 loss_ctc 10.321760 loss_rnnt 5.570773 history loss 8.132228 rank 1
2022-12-04 03:37:31,751 DEBUG CV Batch 8/1300 loss 6.176580 loss_att 6.442161 loss_ctc 10.321760 loss_rnnt 5.570773 history loss 8.132228 rank 5
2022-12-04 03:37:34,005 DEBUG CV Batch 8/1300 loss 6.176580 loss_att 6.442161 loss_ctc 10.321760 loss_rnnt 5.570773 history loss 8.132228 rank 4
2022-12-04 03:37:34,338 DEBUG CV Batch 8/1300 loss 6.176580 loss_att 6.442161 loss_ctc 10.321760 loss_rnnt 5.570773 history loss 8.132228 rank 7
2022-12-04 03:37:34,360 DEBUG CV Batch 8/1300 loss 6.176580 loss_att 6.442161 loss_ctc 10.321760 loss_rnnt 5.570773 history loss 8.132228 rank 2
2022-12-04 03:37:34,814 DEBUG CV Batch 8/1300 loss 6.176580 loss_att 6.442161 loss_ctc 10.321760 loss_rnnt 5.570773 history loss 8.132228 rank 6
2022-12-04 03:37:36,197 DEBUG CV Batch 8/1300 loss 6.176580 loss_att 6.442161 loss_ctc 10.321760 loss_rnnt 5.570773 history loss 8.132228 rank 0
2022-12-04 03:37:36,890 DEBUG CV Batch 8/1300 loss 6.176580 loss_att 6.442161 loss_ctc 10.321760 loss_rnnt 5.570773 history loss 8.132228 rank 3
2022-12-04 03:37:42,305 DEBUG CV Batch 8/1400 loss 8.982368 loss_att 24.133215 loss_ctc 14.520573 loss_rnnt 5.213770 history loss 8.458389 rank 1
2022-12-04 03:37:42,961 DEBUG CV Batch 8/1400 loss 8.982368 loss_att 24.133215 loss_ctc 14.520573 loss_rnnt 5.213770 history loss 8.458389 rank 5
2022-12-04 03:37:45,609 DEBUG CV Batch 8/1400 loss 8.982368 loss_att 24.133215 loss_ctc 14.520573 loss_rnnt 5.213770 history loss 8.458389 rank 4
2022-12-04 03:37:45,636 DEBUG CV Batch 8/1400 loss 8.982368 loss_att 24.133215 loss_ctc 14.520573 loss_rnnt 5.213770 history loss 8.458389 rank 2
2022-12-04 03:37:45,715 DEBUG CV Batch 8/1400 loss 8.982368 loss_att 24.133215 loss_ctc 14.520573 loss_rnnt 5.213770 history loss 8.458389 rank 7
2022-12-04 03:37:46,336 DEBUG CV Batch 8/1400 loss 8.982368 loss_att 24.133215 loss_ctc 14.520573 loss_rnnt 5.213770 history loss 8.458389 rank 6
2022-12-04 03:37:47,942 DEBUG CV Batch 8/1400 loss 8.982368 loss_att 24.133215 loss_ctc 14.520573 loss_rnnt 5.213770 history loss 8.458389 rank 0
2022-12-04 03:37:48,764 DEBUG CV Batch 8/1400 loss 8.982368 loss_att 24.133215 loss_ctc 14.520573 loss_rnnt 5.213770 history loss 8.458389 rank 3
2022-12-04 03:37:53,918 DEBUG CV Batch 8/1500 loss 10.186268 loss_att 10.633658 loss_ctc 13.521585 loss_rnnt 9.652081 history loss 8.274382 rank 1
2022-12-04 03:37:54,364 DEBUG CV Batch 8/1500 loss 10.186268 loss_att 10.633658 loss_ctc 13.521585 loss_rnnt 9.652081 history loss 8.274382 rank 5
2022-12-04 03:37:57,740 DEBUG CV Batch 8/1500 loss 10.186268 loss_att 10.633658 loss_ctc 13.521585 loss_rnnt 9.652081 history loss 8.274382 rank 7
2022-12-04 03:37:58,006 DEBUG CV Batch 8/1500 loss 10.186268 loss_att 10.633658 loss_ctc 13.521585 loss_rnnt 9.652081 history loss 8.274382 rank 2
2022-12-04 03:37:58,211 DEBUG CV Batch 8/1500 loss 10.186268 loss_att 10.633658 loss_ctc 13.521585 loss_rnnt 9.652081 history loss 8.274382 rank 6
2022-12-04 03:37:58,292 DEBUG CV Batch 8/1500 loss 10.186268 loss_att 10.633658 loss_ctc 13.521585 loss_rnnt 9.652081 history loss 8.274382 rank 4
2022-12-04 03:37:59,871 DEBUG CV Batch 8/1500 loss 10.186268 loss_att 10.633658 loss_ctc 13.521585 loss_rnnt 9.652081 history loss 8.274382 rank 0
2022-12-04 03:38:00,673 DEBUG CV Batch 8/1500 loss 10.186268 loss_att 10.633658 loss_ctc 13.521585 loss_rnnt 9.652081 history loss 8.274382 rank 3
2022-12-04 03:38:07,063 DEBUG CV Batch 8/1600 loss 5.668087 loss_att 13.222135 loss_ctc 15.155579 loss_rnnt 2.892279 history loss 8.202611 rank 1
2022-12-04 03:38:07,473 DEBUG CV Batch 8/1600 loss 5.668087 loss_att 13.222135 loss_ctc 15.155579 loss_rnnt 2.892279 history loss 8.202611 rank 5
2022-12-04 03:38:11,409 DEBUG CV Batch 8/1600 loss 5.668087 loss_att 13.222135 loss_ctc 15.155579 loss_rnnt 2.892279 history loss 8.202611 rank 7
2022-12-04 03:38:11,613 DEBUG CV Batch 8/1600 loss 5.668087 loss_att 13.222135 loss_ctc 15.155579 loss_rnnt 2.892279 history loss 8.202611 rank 6
2022-12-04 03:38:11,905 DEBUG CV Batch 8/1600 loss 5.668087 loss_att 13.222135 loss_ctc 15.155579 loss_rnnt 2.892279 history loss 8.202611 rank 4
2022-12-04 03:38:11,937 DEBUG CV Batch 8/1600 loss 5.668087 loss_att 13.222135 loss_ctc 15.155579 loss_rnnt 2.892279 history loss 8.202611 rank 2
2022-12-04 03:38:13,354 DEBUG CV Batch 8/1600 loss 5.668087 loss_att 13.222135 loss_ctc 15.155579 loss_rnnt 2.892279 history loss 8.202611 rank 0
2022-12-04 03:38:14,239 DEBUG CV Batch 8/1600 loss 5.668087 loss_att 13.222135 loss_ctc 15.155579 loss_rnnt 2.892279 history loss 8.202611 rank 3
2022-12-04 03:38:19,498 DEBUG CV Batch 8/1700 loss 11.290660 loss_att 10.862396 loss_ctc 18.197365 loss_rnnt 10.455420 history loss 8.091748 rank 1
2022-12-04 03:38:20,174 DEBUG CV Batch 8/1700 loss 11.290660 loss_att 10.862396 loss_ctc 18.197365 loss_rnnt 10.455420 history loss 8.091748 rank 5
2022-12-04 03:38:24,149 DEBUG CV Batch 8/1700 loss 11.290660 loss_att 10.862396 loss_ctc 18.197365 loss_rnnt 10.455420 history loss 8.091748 rank 6
2022-12-04 03:38:24,245 DEBUG CV Batch 8/1700 loss 11.290660 loss_att 10.862396 loss_ctc 18.197365 loss_rnnt 10.455420 history loss 8.091748 rank 7
2022-12-04 03:38:24,362 DEBUG CV Batch 8/1700 loss 11.290660 loss_att 10.862396 loss_ctc 18.197365 loss_rnnt 10.455420 history loss 8.091748 rank 4
2022-12-04 03:38:25,098 DEBUG CV Batch 8/1700 loss 11.290660 loss_att 10.862396 loss_ctc 18.197365 loss_rnnt 10.455420 history loss 8.091748 rank 2
2022-12-04 03:38:26,002 DEBUG CV Batch 8/1700 loss 11.290660 loss_att 10.862396 loss_ctc 18.197365 loss_rnnt 10.455420 history loss 8.091748 rank 0
2022-12-04 03:38:26,977 DEBUG CV Batch 8/1700 loss 11.290660 loss_att 10.862396 loss_ctc 18.197365 loss_rnnt 10.455420 history loss 8.091748 rank 3
2022-12-04 03:38:28,902 INFO Epoch 8 CV info cv_loss 8.057522663212628
2022-12-04 03:38:28,903 INFO Epoch 9 TRAIN info lr 0.0005770694970056977
2022-12-04 03:38:28,908 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 03:38:29,582 INFO Epoch 8 CV info cv_loss 8.057522663212628
2022-12-04 03:38:29,582 INFO Epoch 9 TRAIN info lr 0.0005772117549881386
2022-12-04 03:38:29,587 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 03:38:33,271 INFO Epoch 8 CV info cv_loss 8.057522663212628
2022-12-04 03:38:33,272 INFO Epoch 9 TRAIN info lr 0.0005772656097747607
2022-12-04 03:38:33,277 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 03:38:33,673 INFO Epoch 8 CV info cv_loss 8.057522663212628
2022-12-04 03:38:33,674 INFO Epoch 9 TRAIN info lr 0.0005772156012587581
2022-12-04 03:38:33,678 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 03:38:33,716 INFO Epoch 8 CV info cv_loss 8.057522663212628
2022-12-04 03:38:33,716 INFO Epoch 9 TRAIN info lr 0.0005773079348266083
2022-12-04 03:38:33,718 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 03:38:34,400 INFO Epoch 8 CV info cv_loss 8.057522663212628
2022-12-04 03:38:34,401 INFO Epoch 9 TRAIN info lr 0.0005770195394357156
2022-12-04 03:38:34,406 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 03:38:35,160 INFO Epoch 8 CV info cv_loss 8.057522663212628
2022-12-04 03:38:35,160 INFO Checkpoint: save to checkpoint exp/1202_encoder_bias_30_0.1/8.pt
2022-12-04 03:38:36,166 INFO Epoch 9 TRAIN info lr 0.0005770887149110706
2022-12-04 03:38:36,170 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 03:38:36,194 INFO Epoch 8 CV info cv_loss 8.057522663212628
2022-12-04 03:38:36,195 INFO Epoch 9 TRAIN info lr 0.0005771194675537031
2022-12-04 03:38:36,199 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 03:39:50,078 DEBUG TRAIN Batch 9/0 loss 7.529833 loss_att 8.573796 loss_ctc 13.086125 loss_rnnt 6.580201 lr 0.00057712 rank 3
2022-12-04 03:39:50,080 DEBUG TRAIN Batch 9/0 loss 9.733207 loss_att 9.670310 loss_ctc 13.898395 loss_rnnt 9.190428 lr 0.00057726 rank 6
2022-12-04 03:39:50,080 DEBUG TRAIN Batch 9/0 loss 11.248366 loss_att 10.910277 loss_ctc 15.248330 loss_rnnt 10.782656 lr 0.00057708 rank 0
2022-12-04 03:39:50,082 DEBUG TRAIN Batch 9/0 loss 10.275895 loss_att 9.246776 loss_ctc 13.530157 loss_rnnt 10.047817 lr 0.00057730 rank 7
2022-12-04 03:39:50,083 DEBUG TRAIN Batch 9/0 loss 12.385705 loss_att 12.352535 loss_ctc 15.831414 loss_rnnt 11.932911 lr 0.00057702 rank 2
2022-12-04 03:39:50,090 DEBUG TRAIN Batch 9/0 loss 11.631006 loss_att 11.283465 loss_ctc 18.006460 loss_rnnt 10.850453 lr 0.00057721 rank 4
2022-12-04 03:39:50,094 DEBUG TRAIN Batch 9/0 loss 7.480913 loss_att 7.779272 loss_ctc 10.851241 loss_rnnt 6.971864 lr 0.00057707 rank 1
2022-12-04 03:39:50,096 DEBUG TRAIN Batch 9/0 loss 8.554516 loss_att 8.898266 loss_ctc 13.326013 loss_rnnt 7.849567 lr 0.00057721 rank 5
2022-12-04 03:41:00,912 DEBUG TRAIN Batch 9/100 loss 17.260569 loss_att 22.939569 loss_ctc 31.694809 loss_rnnt 14.200203 lr 0.00057673 rank 3
2022-12-04 03:41:00,915 DEBUG TRAIN Batch 9/100 loss 24.683748 loss_att 29.902725 loss_ctc 54.229637 loss_rnnt 19.700500 lr 0.00057670 rank 0
2022-12-04 03:41:00,916 DEBUG TRAIN Batch 9/100 loss 11.931313 loss_att 19.790312 loss_ctc 17.461128 loss_rnnt 9.622204 lr 0.00057688 rank 6
2022-12-04 03:41:00,918 DEBUG TRAIN Batch 9/100 loss 18.139082 loss_att 21.295250 loss_ctc 26.639069 loss_rnnt 16.374516 lr 0.00057663 rank 2
2022-12-04 03:41:00,918 DEBUG TRAIN Batch 9/100 loss 12.316427 loss_att 15.153080 loss_ctc 22.201231 loss_rnnt 10.431123 lr 0.00057682 rank 5
2022-12-04 03:41:00,929 DEBUG TRAIN Batch 9/100 loss 13.626941 loss_att 20.506142 loss_ctc 26.289169 loss_rnnt 10.562803 lr 0.00057668 rank 1
2022-12-04 03:41:00,948 DEBUG TRAIN Batch 9/100 loss 10.378579 loss_att 14.460310 loss_ctc 16.568245 loss_rnnt 8.736945 lr 0.00057683 rank 4
2022-12-04 03:41:00,950 DEBUG TRAIN Batch 9/100 loss 11.757158 loss_att 19.710117 loss_ctc 21.473743 loss_rnnt 8.871021 lr 0.00057692 rank 7
2022-12-04 03:42:11,559 DEBUG TRAIN Batch 9/200 loss 30.061432 loss_att 31.405022 loss_ctc 38.983551 loss_rnnt 28.603096 lr 0.00057649 rank 6
2022-12-04 03:42:11,561 DEBUG TRAIN Batch 9/200 loss 19.007244 loss_att 23.307144 loss_ctc 39.827862 loss_rnnt 15.371181 lr 0.00057644 rank 5
2022-12-04 03:42:11,561 DEBUG TRAIN Batch 9/200 loss 16.346687 loss_att 24.607357 loss_ctc 30.891190 loss_rnnt 12.755287 lr 0.00057635 rank 3
2022-12-04 03:42:11,562 DEBUG TRAIN Batch 9/200 loss 12.239744 loss_att 21.246845 loss_ctc 20.307068 loss_rnnt 9.362681 lr 0.00057625 rank 2
2022-12-04 03:42:11,563 DEBUG TRAIN Batch 9/200 loss 20.485394 loss_att 29.742706 loss_ctc 32.449432 loss_rnnt 17.038725 lr 0.00057630 rank 1
2022-12-04 03:42:11,565 DEBUG TRAIN Batch 9/200 loss 22.720203 loss_att 28.080450 loss_ctc 42.968193 loss_rnnt 18.948421 lr 0.00057632 rank 0
2022-12-04 03:42:11,567 DEBUG TRAIN Batch 9/200 loss 25.653172 loss_att 25.605446 loss_ctc 37.309212 loss_rnnt 24.108580 lr 0.00057654 rank 7
2022-12-04 03:42:11,571 DEBUG TRAIN Batch 9/200 loss 13.213460 loss_att 17.693857 loss_ctc 23.702740 loss_rnnt 10.918811 lr 0.00057644 rank 4
2022-12-04 03:43:23,751 DEBUG TRAIN Batch 9/300 loss 11.137564 loss_att 16.836573 loss_ctc 14.884648 loss_rnnt 9.498150 lr 0.00057606 rank 4
2022-12-04 03:43:23,761 DEBUG TRAIN Batch 9/300 loss 21.425455 loss_att 27.527405 loss_ctc 36.598824 loss_rnnt 18.181952 lr 0.00057606 rank 5
2022-12-04 03:43:23,762 DEBUG TRAIN Batch 9/300 loss 14.542889 loss_att 20.353531 loss_ctc 27.535915 loss_rnnt 11.648355 lr 0.00057594 rank 0
2022-12-04 03:43:23,764 DEBUG TRAIN Batch 9/300 loss 14.767671 loss_att 18.529133 loss_ctc 23.995552 loss_rnnt 12.784994 lr 0.00057597 rank 3
2022-12-04 03:43:23,765 DEBUG TRAIN Batch 9/300 loss 14.426795 loss_att 16.593378 loss_ctc 22.384876 loss_rnnt 12.932402 lr 0.00057611 rank 6
2022-12-04 03:43:23,766 DEBUG TRAIN Batch 9/300 loss 23.040703 loss_att 27.696918 loss_ctc 34.806252 loss_rnnt 20.540718 lr 0.00057615 rank 7
2022-12-04 03:43:23,782 DEBUG TRAIN Batch 9/300 loss 5.682254 loss_att 9.372656 loss_ctc 9.774626 loss_rnnt 4.398524 lr 0.00057592 rank 1
2022-12-04 03:43:23,787 DEBUG TRAIN Batch 9/300 loss 15.838414 loss_att 21.246189 loss_ctc 28.221725 loss_rnnt 13.105751 lr 0.00057587 rank 2
2022-12-04 03:44:36,918 DEBUG TRAIN Batch 9/400 loss 19.340694 loss_att 21.723721 loss_ctc 26.884781 loss_rnnt 17.858210 lr 0.00057558 rank 3
2022-12-04 03:44:36,921 DEBUG TRAIN Batch 9/400 loss 11.694140 loss_att 15.735224 loss_ctc 17.249886 loss_rnnt 10.145157 lr 0.00057553 rank 1
2022-12-04 03:44:36,922 DEBUG TRAIN Batch 9/400 loss 26.350855 loss_att 29.044827 loss_ctc 39.262833 loss_rnnt 24.090466 lr 0.00057573 rank 6
2022-12-04 03:44:36,923 DEBUG TRAIN Batch 9/400 loss 18.353500 loss_att 19.382063 loss_ctc 24.965471 loss_rnnt 17.266190 lr 0.00057555 rank 0
2022-12-04 03:44:36,923 DEBUG TRAIN Batch 9/400 loss 10.240676 loss_att 14.954794 loss_ctc 18.381817 loss_rnnt 8.212366 lr 0.00057548 rank 2
2022-12-04 03:44:36,929 DEBUG TRAIN Batch 9/400 loss 17.347319 loss_att 19.814049 loss_ctc 23.034344 loss_rnnt 16.095703 lr 0.00057577 rank 7
2022-12-04 03:44:36,930 DEBUG TRAIN Batch 9/400 loss 12.801960 loss_att 21.155033 loss_ctc 19.031948 loss_rnnt 10.300680 lr 0.00057568 rank 4
2022-12-04 03:44:36,970 DEBUG TRAIN Batch 9/400 loss 14.957159 loss_att 17.987930 loss_ctc 24.608952 loss_rnnt 13.064098 lr 0.00057568 rank 5
2022-12-04 03:45:48,191 DEBUG TRAIN Batch 9/500 loss 11.468318 loss_att 13.182816 loss_ctc 17.805819 loss_rnnt 10.280418 lr 0.00057530 rank 4
2022-12-04 03:45:48,202 DEBUG TRAIN Batch 9/500 loss 9.588081 loss_att 10.171632 loss_ctc 16.742174 loss_rnnt 8.517493 lr 0.00057529 rank 5
2022-12-04 03:45:48,202 DEBUG TRAIN Batch 9/500 loss 11.651275 loss_att 15.452799 loss_ctc 22.694603 loss_rnnt 9.418526 lr 0.00057535 rank 6
2022-12-04 03:45:48,207 DEBUG TRAIN Batch 9/500 loss 8.974202 loss_att 12.762571 loss_ctc 13.843824 loss_rnnt 7.567245 lr 0.00057515 rank 1
2022-12-04 03:45:48,207 DEBUG TRAIN Batch 9/500 loss 17.124008 loss_att 18.208248 loss_ctc 27.572205 loss_rnnt 15.514066 lr 0.00057539 rank 7
2022-12-04 03:45:48,208 DEBUG TRAIN Batch 9/500 loss 19.867653 loss_att 23.321276 loss_ctc 35.306629 loss_rnnt 17.118399 lr 0.00057520 rank 3
2022-12-04 03:45:48,208 DEBUG TRAIN Batch 9/500 loss 14.667630 loss_att 16.443340 loss_ctc 21.121609 loss_rnnt 13.451958 lr 0.00057517 rank 0
2022-12-04 03:45:48,213 DEBUG TRAIN Batch 9/500 loss 22.437571 loss_att 25.309885 loss_ctc 34.244125 loss_rnnt 20.288902 lr 0.00057510 rank 2
2022-12-04 03:47:00,032 DEBUG TRAIN Batch 9/600 loss 10.233810 loss_att 12.513208 loss_ctc 15.874521 loss_rnnt 9.025836 lr 0.00057492 rank 4
2022-12-04 03:47:00,039 DEBUG TRAIN Batch 9/600 loss 10.754319 loss_att 12.564631 loss_ctc 17.812868 loss_rnnt 9.451116 lr 0.00057497 rank 6
2022-12-04 03:47:00,043 DEBUG TRAIN Batch 9/600 loss 9.206898 loss_att 9.867208 loss_ctc 13.742246 loss_rnnt 8.470122 lr 0.00057501 rank 7
2022-12-04 03:47:00,043 DEBUG TRAIN Batch 9/600 loss 9.402420 loss_att 11.003524 loss_ctc 16.781544 loss_rnnt 8.098316 lr 0.00057479 rank 0
2022-12-04 03:47:00,044 DEBUG TRAIN Batch 9/600 loss 11.325794 loss_att 13.854752 loss_ctc 16.158684 loss_rnnt 10.175617 lr 0.00057477 rank 1
2022-12-04 03:47:00,046 DEBUG TRAIN Batch 9/600 loss 18.845839 loss_att 20.081705 loss_ctc 33.508644 loss_rnnt 16.643623 lr 0.00057472 rank 2
2022-12-04 03:47:00,047 DEBUG TRAIN Batch 9/600 loss 11.497972 loss_att 12.563477 loss_ctc 17.793818 loss_rnnt 10.445424 lr 0.00057482 rank 3
2022-12-04 03:47:00,092 DEBUG TRAIN Batch 9/600 loss 11.257049 loss_att 11.839074 loss_ctc 19.613323 loss_rnnt 10.026474 lr 0.00057491 rank 5
2022-12-04 03:48:13,953 DEBUG TRAIN Batch 9/700 loss 19.216131 loss_att 22.782021 loss_ctc 32.801224 loss_rnnt 16.691607 lr 0.00057453 rank 5
2022-12-04 03:48:13,960 DEBUG TRAIN Batch 9/700 loss 15.730281 loss_att 21.116665 loss_ctc 29.753845 loss_rnnt 12.783195 lr 0.00057439 rank 1
2022-12-04 03:48:13,973 DEBUG TRAIN Batch 9/700 loss 10.217192 loss_att 16.022995 loss_ctc 26.386307 loss_rnnt 6.900149 lr 0.00057441 rank 0
2022-12-04 03:48:13,977 DEBUG TRAIN Batch 9/700 loss 14.044970 loss_att 20.711847 loss_ctc 23.181570 loss_rnnt 11.493380 lr 0.00057434 rank 2
2022-12-04 03:48:13,979 DEBUG TRAIN Batch 9/700 loss 7.593489 loss_att 11.678846 loss_ctc 15.499855 loss_rnnt 5.722235 lr 0.00057463 rank 7
2022-12-04 03:48:13,984 DEBUG TRAIN Batch 9/700 loss 13.941217 loss_att 20.155203 loss_ctc 22.187252 loss_rnnt 11.598948 lr 0.00057459 rank 6
2022-12-04 03:48:13,995 DEBUG TRAIN Batch 9/700 loss 14.852198 loss_att 17.753050 loss_ctc 25.278152 loss_rnnt 12.881900 lr 0.00057454 rank 4
2022-12-04 03:48:14,010 DEBUG TRAIN Batch 9/700 loss 22.309742 loss_att 25.330315 loss_ctc 35.018318 loss_rnnt 20.011150 lr 0.00057444 rank 3
2022-12-04 03:49:26,364 DEBUG TRAIN Batch 9/800 loss 7.738942 loss_att 13.433622 loss_ctc 12.561552 loss_rnnt 5.956991 lr 0.00057406 rank 3
2022-12-04 03:49:26,364 DEBUG TRAIN Batch 9/800 loss 4.804831 loss_att 7.971601 loss_ctc 8.840705 loss_rnnt 3.633360 lr 0.00057397 rank 2
2022-12-04 03:49:26,364 DEBUG TRAIN Batch 9/800 loss 6.280859 loss_att 10.055017 loss_ctc 11.955890 loss_rnnt 4.769356 lr 0.00057403 rank 0
2022-12-04 03:49:26,367 DEBUG TRAIN Batch 9/800 loss 8.477946 loss_att 10.062954 loss_ctc 13.434361 loss_rnnt 7.500089 lr 0.00057421 rank 6
2022-12-04 03:49:26,366 DEBUG TRAIN Batch 9/800 loss 10.425032 loss_att 16.143631 loss_ctc 20.218309 loss_rnnt 7.975542 lr 0.00057402 rank 1
2022-12-04 03:49:26,371 DEBUG TRAIN Batch 9/800 loss 39.465324 loss_att 45.248692 loss_ctc 53.617443 loss_rnnt 36.421700 lr 0.00057416 rank 4
2022-12-04 03:49:26,371 DEBUG TRAIN Batch 9/800 loss 7.831943 loss_att 11.549047 loss_ctc 12.690611 loss_rnnt 6.440700 lr 0.00057416 rank 5
2022-12-04 03:49:26,378 DEBUG TRAIN Batch 9/800 loss 9.021753 loss_att 12.316290 loss_ctc 15.853542 loss_rnnt 7.451940 lr 0.00057425 rank 7
2022-12-04 03:50:37,689 DEBUG TRAIN Batch 9/900 loss 10.178733 loss_att 14.352193 loss_ctc 21.307705 loss_rnnt 7.860178 lr 0.00057366 rank 0
2022-12-04 03:50:37,692 DEBUG TRAIN Batch 9/900 loss 14.511394 loss_att 18.623941 loss_ctc 20.549000 loss_rnnt 12.883869 lr 0.00057378 rank 5
2022-12-04 03:50:37,693 DEBUG TRAIN Batch 9/900 loss 22.853886 loss_att 30.008438 loss_ctc 37.735214 loss_rnnt 19.438797 lr 0.00057364 rank 1
2022-12-04 03:50:37,694 DEBUG TRAIN Batch 9/900 loss 11.577766 loss_att 17.853685 loss_ctc 21.291012 loss_rnnt 9.027483 lr 0.00057383 rank 6
2022-12-04 03:50:37,696 DEBUG TRAIN Batch 9/900 loss 20.892834 loss_att 24.733406 loss_ctc 34.058056 loss_rnnt 18.369358 lr 0.00057369 rank 3
2022-12-04 03:50:37,703 DEBUG TRAIN Batch 9/900 loss 7.746590 loss_att 10.906034 loss_ctc 9.548747 loss_rnnt 6.874414 lr 0.00057387 rank 7
2022-12-04 03:50:37,703 DEBUG TRAIN Batch 9/900 loss 16.451122 loss_att 22.325939 loss_ctc 30.528198 loss_rnnt 13.399216 lr 0.00057378 rank 4
2022-12-04 03:50:37,739 DEBUG TRAIN Batch 9/900 loss 10.440148 loss_att 14.321218 loss_ctc 18.939373 loss_rnnt 8.530704 lr 0.00057359 rank 2
2022-12-04 03:51:49,656 DEBUG TRAIN Batch 9/1000 loss 13.006881 loss_att 20.609613 loss_ctc 29.527838 loss_rnnt 9.283540 lr 0.00057340 rank 5
2022-12-04 03:51:49,668 DEBUG TRAIN Batch 9/1000 loss 26.761692 loss_att 29.226433 loss_ctc 39.542198 loss_rnnt 24.564678 lr 0.00057331 rank 3
2022-12-04 03:51:49,674 DEBUG TRAIN Batch 9/1000 loss 21.694843 loss_att 24.790531 loss_ctc 31.640469 loss_rnnt 19.749620 lr 0.00057345 rank 6
2022-12-04 03:51:49,674 DEBUG TRAIN Batch 9/1000 loss 9.654729 loss_att 13.971661 loss_ctc 14.615211 loss_rnnt 8.129945 lr 0.00057321 rank 2
2022-12-04 03:51:49,674 DEBUG TRAIN Batch 9/1000 loss 12.288579 loss_att 18.419945 loss_ctc 20.190111 loss_rnnt 10.008767 lr 0.00057326 rank 1
2022-12-04 03:51:49,680 DEBUG TRAIN Batch 9/1000 loss 17.272282 loss_att 24.332361 loss_ctc 26.693640 loss_rnnt 14.604085 lr 0.00057340 rank 4
2022-12-04 03:51:49,681 DEBUG TRAIN Batch 9/1000 loss 6.634552 loss_att 11.918946 loss_ctc 14.988873 loss_rnnt 4.463764 lr 0.00057349 rank 7
2022-12-04 03:51:49,686 DEBUG TRAIN Batch 9/1000 loss 13.148493 loss_att 15.830828 loss_ctc 18.387508 loss_rnnt 11.913490 lr 0.00057328 rank 0
2022-12-04 03:53:10,887 DEBUG TRAIN Batch 9/1100 loss 22.379517 loss_att 26.824356 loss_ctc 43.973873 loss_rnnt 18.611301 lr 0.00057290 rank 0
2022-12-04 03:53:10,887 DEBUG TRAIN Batch 9/1100 loss 15.856764 loss_att 17.705477 loss_ctc 28.433695 loss_rnnt 13.810097 lr 0.00057308 rank 6
2022-12-04 03:53:10,889 DEBUG TRAIN Batch 9/1100 loss 14.712982 loss_att 17.415245 loss_ctc 25.988403 loss_rnnt 12.669140 lr 0.00057288 rank 1
2022-12-04 03:53:10,890 DEBUG TRAIN Batch 9/1100 loss 16.116976 loss_att 19.258324 loss_ctc 23.874104 loss_rnnt 14.454423 lr 0.00057312 rank 7
2022-12-04 03:53:10,890 DEBUG TRAIN Batch 9/1100 loss 15.944387 loss_att 20.921452 loss_ctc 33.546005 loss_rnnt 12.602091 lr 0.00057284 rank 2
2022-12-04 03:53:10,893 DEBUG TRAIN Batch 9/1100 loss 16.170731 loss_att 19.929371 loss_ctc 26.637085 loss_rnnt 14.023488 lr 0.00057302 rank 5
2022-12-04 03:53:10,893 DEBUG TRAIN Batch 9/1100 loss 13.877289 loss_att 19.051624 loss_ctc 26.103132 loss_rnnt 11.212309 lr 0.00057293 rank 3
2022-12-04 03:53:10,894 DEBUG TRAIN Batch 9/1100 loss 17.645973 loss_att 20.232208 loss_ctc 24.239674 loss_rnnt 16.249565 lr 0.00057303 rank 4
2022-12-04 03:54:22,530 DEBUG TRAIN Batch 9/1200 loss 20.604218 loss_att 20.247570 loss_ctc 30.250198 loss_rnnt 19.389414 lr 0.00057253 rank 0
2022-12-04 03:54:22,532 DEBUG TRAIN Batch 9/1200 loss 8.875487 loss_att 12.363562 loss_ctc 16.698206 loss_rnnt 7.134843 lr 0.00057270 rank 6
2022-12-04 03:54:22,534 DEBUG TRAIN Batch 9/1200 loss 13.577042 loss_att 15.668371 loss_ctc 23.305096 loss_rnnt 11.861701 lr 0.00057265 rank 5
2022-12-04 03:54:22,536 DEBUG TRAIN Batch 9/1200 loss 19.151352 loss_att 20.570786 loss_ctc 28.824097 loss_rnnt 17.577765 lr 0.00057251 rank 1
2022-12-04 03:54:22,537 DEBUG TRAIN Batch 9/1200 loss 12.387030 loss_att 14.537152 loss_ctc 19.332792 loss_rnnt 11.030903 lr 0.00057256 rank 3
2022-12-04 03:54:22,538 DEBUG TRAIN Batch 9/1200 loss 6.780553 loss_att 10.509292 loss_ctc 12.367213 loss_rnnt 5.289917 lr 0.00057246 rank 2
2022-12-04 03:54:22,536 DEBUG TRAIN Batch 9/1200 loss 11.289520 loss_att 12.835420 loss_ctc 14.577759 loss_rnnt 10.541908 lr 0.00057274 rank 7
2022-12-04 03:54:22,549 DEBUG TRAIN Batch 9/1200 loss 15.610352 loss_att 18.354649 loss_ctc 24.336720 loss_rnnt 13.897976 lr 0.00057265 rank 4
2022-12-04 03:55:34,266 DEBUG TRAIN Batch 9/1300 loss 8.426341 loss_att 10.171480 loss_ctc 12.779834 loss_rnnt 7.496847 lr 0.00057227 rank 5
2022-12-04 03:55:34,267 DEBUG TRAIN Batch 9/1300 loss 15.804028 loss_att 20.600372 loss_ctc 32.155380 loss_rnnt 12.664577 lr 0.00057232 rank 6
2022-12-04 03:55:34,271 DEBUG TRAIN Batch 9/1300 loss 10.311561 loss_att 15.309156 loss_ctc 18.330181 loss_rnnt 8.242892 lr 0.00057215 rank 0
2022-12-04 03:55:34,271 DEBUG TRAIN Batch 9/1300 loss 14.005774 loss_att 18.855936 loss_ctc 33.033051 loss_rnnt 10.498772 lr 0.00057237 rank 7
2022-12-04 03:55:34,272 DEBUG TRAIN Batch 9/1300 loss 16.665182 loss_att 23.794954 loss_ctc 25.883978 loss_rnnt 14.010056 lr 0.00057218 rank 3
2022-12-04 03:55:34,277 DEBUG TRAIN Batch 9/1300 loss 35.457554 loss_att 36.096909 loss_ctc 55.994152 loss_rnnt 32.591473 lr 0.00057228 rank 4
2022-12-04 03:55:34,291 DEBUG TRAIN Batch 9/1300 loss 5.688807 loss_att 8.531969 loss_ctc 10.610665 loss_rnnt 4.463926 lr 0.00057213 rank 1
2022-12-04 03:55:34,294 DEBUG TRAIN Batch 9/1300 loss 23.673117 loss_att 27.062607 loss_ctc 36.161221 loss_rnnt 21.330139 lr 0.00057208 rank 2
2022-12-04 03:56:48,008 DEBUG TRAIN Batch 9/1400 loss 29.176453 loss_att 32.619385 loss_ctc 47.967922 loss_rnnt 25.982336 lr 0.00057171 rank 2
2022-12-04 03:56:48,011 DEBUG TRAIN Batch 9/1400 loss 5.260382 loss_att 13.713316 loss_ctc 17.351547 loss_rnnt 1.957639 lr 0.00057190 rank 4
2022-12-04 03:56:48,015 DEBUG TRAIN Batch 9/1400 loss 21.492750 loss_att 24.260952 loss_ctc 32.784149 loss_rnnt 19.433590 lr 0.00057195 rank 6
2022-12-04 03:56:48,018 DEBUG TRAIN Batch 9/1400 loss 9.828714 loss_att 15.584353 loss_ctc 20.669884 loss_rnnt 7.232097 lr 0.00057181 rank 3
2022-12-04 03:56:48,019 DEBUG TRAIN Batch 9/1400 loss 13.954327 loss_att 16.027918 loss_ctc 20.001820 loss_rnnt 12.733275 lr 0.00057178 rank 0
2022-12-04 03:56:48,033 DEBUG TRAIN Batch 9/1400 loss 10.795373 loss_att 14.838135 loss_ctc 27.910194 loss_rnnt 7.704845 lr 0.00057190 rank 5
2022-12-04 03:56:48,041 DEBUG TRAIN Batch 9/1400 loss 9.505339 loss_att 13.897444 loss_ctc 10.976822 loss_rnnt 8.430719 lr 0.00057176 rank 1
2022-12-04 03:56:48,042 DEBUG TRAIN Batch 9/1400 loss 9.237760 loss_att 12.064983 loss_ctc 15.504904 loss_rnnt 7.836696 lr 0.00057199 rank 7
2022-12-04 03:58:11,048 DEBUG TRAIN Batch 9/1500 loss 15.239052 loss_att 21.406927 loss_ctc 31.090832 loss_rnnt 11.891906 lr 0.00057140 rank 0
2022-12-04 03:58:11,049 DEBUG TRAIN Batch 9/1500 loss 12.068329 loss_att 16.260366 loss_ctc 18.944817 loss_rnnt 10.313057 lr 0.00057162 rank 7
2022-12-04 03:58:11,050 DEBUG TRAIN Batch 9/1500 loss 17.150295 loss_att 20.402431 loss_ctc 28.225784 loss_rnnt 15.023135 lr 0.00057158 rank 6
2022-12-04 03:58:11,050 DEBUG TRAIN Batch 9/1500 loss 12.675440 loss_att 12.940851 loss_ctc 16.101532 loss_rnnt 12.165545 lr 0.00057139 rank 1
2022-12-04 03:58:11,053 DEBUG TRAIN Batch 9/1500 loss 10.167862 loss_att 13.809124 loss_ctc 11.420207 loss_rnnt 9.272631 lr 0.00057134 rank 2
2022-12-04 03:58:11,052 DEBUG TRAIN Batch 9/1500 loss 17.403542 loss_att 24.384230 loss_ctc 22.125374 loss_rnnt 15.377825 lr 0.00057152 rank 5
2022-12-04 03:58:11,053 DEBUG TRAIN Batch 9/1500 loss 7.393218 loss_att 9.406731 loss_ctc 12.745418 loss_rnnt 6.276889 lr 0.00057143 rank 3
2022-12-04 03:58:11,099 DEBUG TRAIN Batch 9/1500 loss 10.345206 loss_att 16.931665 loss_ctc 23.453796 loss_rnnt 7.280102 lr 0.00057153 rank 4
2022-12-04 03:59:21,883 DEBUG TRAIN Batch 9/1600 loss 18.743856 loss_att 19.601139 loss_ctc 29.227514 loss_rnnt 17.174580 lr 0.00057120 rank 6
2022-12-04 03:59:21,885 DEBUG TRAIN Batch 9/1600 loss 22.487022 loss_att 26.959686 loss_ctc 34.985970 loss_rnnt 19.925964 lr 0.00057101 rank 1
2022-12-04 03:59:21,889 DEBUG TRAIN Batch 9/1600 loss 10.044398 loss_att 14.266430 loss_ctc 19.283104 loss_rnnt 7.968164 lr 0.00057124 rank 7
2022-12-04 03:59:21,891 DEBUG TRAIN Batch 9/1600 loss 9.604477 loss_att 14.443207 loss_ctc 17.876553 loss_rnnt 7.533787 lr 0.00057106 rank 3
2022-12-04 03:59:21,891 DEBUG TRAIN Batch 9/1600 loss 7.651804 loss_att 14.463959 loss_ctc 16.319328 loss_rnnt 5.133703 lr 0.00057103 rank 0
2022-12-04 03:59:21,892 DEBUG TRAIN Batch 9/1600 loss 15.931802 loss_att 22.960606 loss_ctc 38.237534 loss_rnnt 11.551943 lr 0.00057096 rank 2
2022-12-04 03:59:21,896 DEBUG TRAIN Batch 9/1600 loss 12.282721 loss_att 17.865896 loss_ctc 23.090521 loss_rnnt 9.725044 lr 0.00057115 rank 4
2022-12-04 03:59:21,940 DEBUG TRAIN Batch 9/1600 loss 9.196114 loss_att 14.457598 loss_ctc 15.477322 loss_rnnt 7.306322 lr 0.00057115 rank 5
2022-12-04 04:00:34,986 DEBUG TRAIN Batch 9/1700 loss 23.271431 loss_att 24.434708 loss_ctc 33.627968 loss_rnnt 21.657904 lr 0.00057083 rank 6
2022-12-04 04:00:34,995 DEBUG TRAIN Batch 9/1700 loss 9.394709 loss_att 11.790565 loss_ctc 13.689842 loss_rnnt 8.342854 lr 0.00057069 rank 3
2022-12-04 04:00:34,998 DEBUG TRAIN Batch 9/1700 loss 12.666893 loss_att 15.857660 loss_ctc 21.941332 loss_rnnt 10.792148 lr 0.00057066 rank 0
2022-12-04 04:00:34,998 DEBUG TRAIN Batch 9/1700 loss 14.748572 loss_att 19.076450 loss_ctc 22.846766 loss_rnnt 12.803238 lr 0.00057059 rank 2
2022-12-04 04:00:35,000 DEBUG TRAIN Batch 9/1700 loss 21.757753 loss_att 24.817417 loss_ctc 36.218376 loss_rnnt 19.217737 lr 0.00057078 rank 5
2022-12-04 04:00:35,001 DEBUG TRAIN Batch 9/1700 loss 4.312216 loss_att 7.537387 loss_ctc 12.603441 loss_rnnt 2.561685 lr 0.00057087 rank 7
2022-12-04 04:00:35,002 DEBUG TRAIN Batch 9/1700 loss 9.463149 loss_att 13.834030 loss_ctc 15.246271 loss_rnnt 7.817890 lr 0.00057064 rank 1
2022-12-04 04:00:35,052 DEBUG TRAIN Batch 9/1700 loss 20.439451 loss_att 23.302107 loss_ctc 40.552990 loss_rnnt 17.185114 lr 0.00057078 rank 4
2022-12-04 04:01:58,644 DEBUG TRAIN Batch 9/1800 loss 11.799473 loss_att 14.028933 loss_ctc 19.081053 loss_rnnt 10.382704 lr 0.00057046 rank 6
2022-12-04 04:01:58,645 DEBUG TRAIN Batch 9/1800 loss 12.971740 loss_att 15.563057 loss_ctc 23.293985 loss_rnnt 11.077178 lr 0.00057041 rank 5
2022-12-04 04:01:58,647 DEBUG TRAIN Batch 9/1800 loss 10.661328 loss_att 13.375994 loss_ctc 20.248768 loss_rnnt 8.840070 lr 0.00057032 rank 3
2022-12-04 04:01:58,649 DEBUG TRAIN Batch 9/1800 loss 25.040483 loss_att 28.450497 loss_ctc 41.229378 loss_rnnt 22.199961 lr 0.00057029 rank 0
2022-12-04 04:01:58,649 DEBUG TRAIN Batch 9/1800 loss 15.197260 loss_att 17.657988 loss_ctc 20.715586 loss_rnnt 13.969337 lr 0.00057027 rank 1
2022-12-04 04:01:58,649 DEBUG TRAIN Batch 9/1800 loss 12.602775 loss_att 15.150936 loss_ctc 21.391647 loss_rnnt 10.921293 lr 0.00057041 rank 4
2022-12-04 04:01:58,650 DEBUG TRAIN Batch 9/1800 loss 14.877777 loss_att 17.579670 loss_ctc 26.637833 loss_rnnt 12.769391 lr 0.00057022 rank 2
2022-12-04 04:01:58,655 DEBUG TRAIN Batch 9/1800 loss 9.906473 loss_att 13.405542 loss_ctc 16.488314 loss_rnnt 8.329082 lr 0.00057050 rank 7
2022-12-04 04:03:10,199 DEBUG TRAIN Batch 9/1900 loss 7.973322 loss_att 10.242373 loss_ctc 11.394222 loss_rnnt 7.063392 lr 0.00057009 rank 6
2022-12-04 04:03:10,201 DEBUG TRAIN Batch 9/1900 loss 17.594652 loss_att 18.620665 loss_ctc 27.421566 loss_rnnt 16.079193 lr 0.00057004 rank 5
2022-12-04 04:03:10,204 DEBUG TRAIN Batch 9/1900 loss 18.797970 loss_att 20.839201 loss_ctc 29.846945 loss_rnnt 16.916527 lr 0.00057013 rank 7
2022-12-04 04:03:10,205 DEBUG TRAIN Batch 9/1900 loss 26.915586 loss_att 27.260437 loss_ctc 39.129234 loss_rnnt 25.218130 lr 0.00056990 rank 1
2022-12-04 04:03:10,206 DEBUG TRAIN Batch 9/1900 loss 13.076107 loss_att 13.111097 loss_ctc 16.676218 loss_rnnt 12.589095 lr 0.00056995 rank 3
2022-12-04 04:03:10,207 DEBUG TRAIN Batch 9/1900 loss 14.791904 loss_att 14.392010 loss_ctc 17.614817 loss_rnnt 14.495495 lr 0.00056992 rank 0
2022-12-04 04:03:10,208 DEBUG TRAIN Batch 9/1900 loss 13.487254 loss_att 16.821726 loss_ctc 20.187321 loss_rnnt 11.927017 lr 0.00057004 rank 4
2022-12-04 04:03:10,212 DEBUG TRAIN Batch 9/1900 loss 9.328178 loss_att 10.894013 loss_ctc 11.588287 loss_rnnt 8.713663 lr 0.00056985 rank 2
2022-12-04 04:04:22,129 DEBUG TRAIN Batch 9/2000 loss 9.688749 loss_att 12.423542 loss_ctc 14.671428 loss_rnnt 8.477434 lr 0.00056955 rank 0
2022-12-04 04:04:22,131 DEBUG TRAIN Batch 9/2000 loss 7.449137 loss_att 13.876390 loss_ctc 13.687084 loss_rnnt 5.331960 lr 0.00056948 rank 2
2022-12-04 04:04:22,132 DEBUG TRAIN Batch 9/2000 loss 13.496208 loss_att 16.103065 loss_ctc 18.339205 loss_rnnt 12.329103 lr 0.00056976 rank 7
2022-12-04 04:04:22,132 DEBUG TRAIN Batch 9/2000 loss 9.554710 loss_att 16.083599 loss_ctc 15.755481 loss_rnnt 7.422164 lr 0.00056972 rank 6
2022-12-04 04:04:22,133 DEBUG TRAIN Batch 9/2000 loss 14.323919 loss_att 17.998743 loss_ctc 19.389626 loss_rnnt 12.913527 lr 0.00056958 rank 3
2022-12-04 04:04:22,135 DEBUG TRAIN Batch 9/2000 loss 22.828629 loss_att 28.827457 loss_ctc 38.222565 loss_rnnt 19.576336 lr 0.00056953 rank 1
2022-12-04 04:04:22,138 DEBUG TRAIN Batch 9/2000 loss 9.382043 loss_att 14.857865 loss_ctc 16.319532 loss_rnnt 7.361879 lr 0.00056967 rank 5
2022-12-04 04:04:22,140 DEBUG TRAIN Batch 9/2000 loss 9.710383 loss_att 11.183467 loss_ctc 14.941170 loss_rnnt 8.718329 lr 0.00056967 rank 4
2022-12-04 04:05:36,183 DEBUG TRAIN Batch 9/2100 loss 3.673569 loss_att 7.976202 loss_ctc 7.205368 loss_rnnt 2.342136 lr 0.00056918 rank 0
2022-12-04 04:05:36,184 DEBUG TRAIN Batch 9/2100 loss 12.011645 loss_att 17.691460 loss_ctc 21.499731 loss_rnnt 9.610604 lr 0.00056935 rank 6
2022-12-04 04:05:36,184 DEBUG TRAIN Batch 9/2100 loss 17.406471 loss_att 24.635080 loss_ctc 31.524254 loss_rnnt 14.078377 lr 0.00056939 rank 7
2022-12-04 04:05:36,184 DEBUG TRAIN Batch 9/2100 loss 16.843790 loss_att 20.834034 loss_ctc 35.124306 loss_rnnt 13.608340 lr 0.00056916 rank 1
2022-12-04 04:05:36,187 DEBUG TRAIN Batch 9/2100 loss 25.213274 loss_att 32.615952 loss_ctc 52.504852 loss_rnnt 20.093859 lr 0.00056930 rank 4
2022-12-04 04:05:36,187 DEBUG TRAIN Batch 9/2100 loss 16.155313 loss_att 19.155268 loss_ctc 18.996696 loss_rnnt 15.176472 lr 0.00056930 rank 5
2022-12-04 04:05:36,189 DEBUG TRAIN Batch 9/2100 loss 11.597834 loss_att 16.737442 loss_ctc 23.075546 loss_rnnt 9.039551 lr 0.00056911 rank 2
2022-12-04 04:05:36,189 DEBUG TRAIN Batch 9/2100 loss 11.563771 loss_att 19.245142 loss_ctc 16.459625 loss_rnnt 9.374717 lr 0.00056921 rank 3
2022-12-04 04:06:59,363 DEBUG TRAIN Batch 9/2200 loss 17.497108 loss_att 21.098936 loss_ctc 29.310583 loss_rnnt 15.201613 lr 0.00056898 rank 6
2022-12-04 04:06:59,365 DEBUG TRAIN Batch 9/2200 loss 15.306774 loss_att 19.042767 loss_ctc 30.460295 loss_rnnt 12.539106 lr 0.00056884 rank 3
2022-12-04 04:06:59,369 DEBUG TRAIN Batch 9/2200 loss 22.876699 loss_att 33.262608 loss_ctc 40.631447 loss_rnnt 18.432219 lr 0.00056879 rank 1
2022-12-04 04:06:59,371 DEBUG TRAIN Batch 9/2200 loss 10.932327 loss_att 15.162336 loss_ctc 18.601250 loss_rnnt 9.063804 lr 0.00056881 rank 0
2022-12-04 04:06:59,372 DEBUG TRAIN Batch 9/2200 loss 9.554273 loss_att 11.025423 loss_ctc 12.185215 loss_rnnt 8.909250 lr 0.00056893 rank 5
2022-12-04 04:06:59,374 DEBUG TRAIN Batch 9/2200 loss 10.349789 loss_att 16.542814 loss_ctc 17.908279 loss_rnnt 8.103385 lr 0.00056874 rank 2
2022-12-04 04:06:59,375 DEBUG TRAIN Batch 9/2200 loss 19.396698 loss_att 21.141460 loss_ctc 30.841404 loss_rnnt 17.521784 lr 0.00056902 rank 7
2022-12-04 04:06:59,376 DEBUG TRAIN Batch 9/2200 loss 25.538311 loss_att 30.630186 loss_ctc 50.083553 loss_rnnt 21.247236 lr 0.00056893 rank 4
2022-12-04 04:08:12,157 DEBUG TRAIN Batch 9/2300 loss 14.090240 loss_att 16.198406 loss_ctc 21.621601 loss_rnnt 12.664426 lr 0.00056847 rank 3
2022-12-04 04:08:12,157 DEBUG TRAIN Batch 9/2300 loss 19.930943 loss_att 24.563942 loss_ctc 33.932251 loss_rnnt 17.137501 lr 0.00056861 rank 6
2022-12-04 04:08:12,158 DEBUG TRAIN Batch 9/2300 loss 18.631948 loss_att 20.205193 loss_ctc 25.782055 loss_rnnt 17.363953 lr 0.00056856 rank 5
2022-12-04 04:08:12,158 DEBUG TRAIN Batch 9/2300 loss 15.633537 loss_att 21.091057 loss_ctc 27.775291 loss_rnnt 12.923134 lr 0.00056842 rank 1
2022-12-04 04:08:12,162 DEBUG TRAIN Batch 9/2300 loss 16.917933 loss_att 21.931061 loss_ctc 25.246696 loss_rnnt 14.804806 lr 0.00056838 rank 2
2022-12-04 04:08:12,162 DEBUG TRAIN Batch 9/2300 loss 23.291199 loss_att 30.768253 loss_ctc 47.591530 loss_rnnt 18.555744 lr 0.00056844 rank 0
2022-12-04 04:08:12,163 DEBUG TRAIN Batch 9/2300 loss 11.981621 loss_att 15.565135 loss_ctc 16.347298 loss_rnnt 10.682828 lr 0.00056856 rank 4
2022-12-04 04:08:12,167 DEBUG TRAIN Batch 9/2300 loss 13.788351 loss_att 19.431625 loss_ctc 25.699581 loss_rnnt 11.071533 lr 0.00056865 rank 7
2022-12-04 04:09:24,215 DEBUG TRAIN Batch 9/2400 loss 19.912876 loss_att 23.824673 loss_ctc 26.363800 loss_rnnt 18.270393 lr 0.00056824 rank 6
2022-12-04 04:09:24,222 DEBUG TRAIN Batch 9/2400 loss 11.638473 loss_att 14.391521 loss_ctc 18.682518 loss_rnnt 10.148657 lr 0.00056810 rank 3
2022-12-04 04:09:24,224 DEBUG TRAIN Batch 9/2400 loss 19.849205 loss_att 25.589952 loss_ctc 29.355011 loss_rnnt 17.433613 lr 0.00056808 rank 0
2022-12-04 04:09:24,225 DEBUG TRAIN Batch 9/2400 loss 21.173019 loss_att 25.209263 loss_ctc 35.662498 loss_rnnt 18.433840 lr 0.00056806 rank 1
2022-12-04 04:09:24,226 DEBUG TRAIN Batch 9/2400 loss 25.426052 loss_att 28.045628 loss_ctc 40.719864 loss_rnnt 22.862961 lr 0.00056801 rank 2
2022-12-04 04:09:24,230 DEBUG TRAIN Batch 9/2400 loss 13.396330 loss_att 16.343870 loss_ctc 26.324457 loss_rnnt 11.083072 lr 0.00056828 rank 7
2022-12-04 04:09:24,235 DEBUG TRAIN Batch 9/2400 loss 18.129026 loss_att 22.044281 loss_ctc 27.284052 loss_rnnt 16.125305 lr 0.00056820 rank 4
2022-12-04 04:09:24,241 DEBUG TRAIN Batch 9/2400 loss 20.328268 loss_att 23.744141 loss_ctc 31.972370 loss_rnnt 18.092546 lr 0.00056819 rank 5
2022-12-04 04:10:47,625 DEBUG TRAIN Batch 9/2500 loss 21.944763 loss_att 23.528662 loss_ctc 34.693867 loss_rnnt 19.928102 lr 0.00056771 rank 0
2022-12-04 04:10:47,627 DEBUG TRAIN Batch 9/2500 loss 42.736012 loss_att 52.741821 loss_ctc 60.807201 loss_rnnt 38.325356 lr 0.00056792 rank 7
2022-12-04 04:10:47,627 DEBUG TRAIN Batch 9/2500 loss 20.895544 loss_att 19.089321 loss_ctc 28.943972 loss_rnnt 20.183666 lr 0.00056783 rank 4
2022-12-04 04:10:47,628 DEBUG TRAIN Batch 9/2500 loss 19.594063 loss_att 23.128550 loss_ctc 36.052532 loss_rnnt 16.692703 lr 0.00056769 rank 1
2022-12-04 04:10:47,630 DEBUG TRAIN Batch 9/2500 loss 11.177076 loss_att 12.763579 loss_ctc 17.861786 loss_rnnt 9.968481 lr 0.00056788 rank 6
2022-12-04 04:10:47,631 DEBUG TRAIN Batch 9/2500 loss 15.647380 loss_att 16.147047 loss_ctc 26.206570 loss_rnnt 14.139555 lr 0.00056774 rank 3
2022-12-04 04:10:47,632 DEBUG TRAIN Batch 9/2500 loss 30.512848 loss_att 32.109875 loss_ctc 50.407284 loss_rnnt 27.540848 lr 0.00056764 rank 2
2022-12-04 04:10:47,678 DEBUG TRAIN Batch 9/2500 loss 11.386525 loss_att 14.445648 loss_ctc 21.818321 loss_rnnt 9.383794 lr 0.00056783 rank 5
2022-12-04 04:12:00,148 DEBUG TRAIN Batch 9/2600 loss 10.654858 loss_att 12.441650 loss_ctc 12.463054 loss_rnnt 10.056405 lr 0.00056737 rank 3
2022-12-04 04:12:00,150 DEBUG TRAIN Batch 9/2600 loss 15.009192 loss_att 17.428743 loss_ctc 25.583500 loss_rnnt 13.115375 lr 0.00056733 rank 1
2022-12-04 04:12:00,150 DEBUG TRAIN Batch 9/2600 loss 20.597647 loss_att 21.270578 loss_ctc 27.418739 loss_rnnt 19.553581 lr 0.00056751 rank 6
2022-12-04 04:12:00,153 DEBUG TRAIN Batch 9/2600 loss 10.524096 loss_att 17.901365 loss_ctc 21.972563 loss_rnnt 7.522179 lr 0.00056746 rank 5
2022-12-04 04:12:00,154 DEBUG TRAIN Batch 9/2600 loss 14.716709 loss_att 17.326159 loss_ctc 20.964430 loss_rnnt 13.361790 lr 0.00056734 rank 0
2022-12-04 04:12:00,156 DEBUG TRAIN Batch 9/2600 loss 14.317906 loss_att 16.548088 loss_ctc 20.947182 loss_rnnt 12.987967 lr 0.00056746 rank 4
2022-12-04 04:12:00,157 DEBUG TRAIN Batch 9/2600 loss 32.035275 loss_att 44.205441 loss_ctc 49.601891 loss_rnnt 27.259026 lr 0.00056728 rank 2
2022-12-04 04:12:00,161 DEBUG TRAIN Batch 9/2600 loss 12.786842 loss_att 15.167366 loss_ctc 23.083294 loss_rnnt 10.937876 lr 0.00056755 rank 7
2022-12-04 04:13:11,960 DEBUG TRAIN Batch 9/2700 loss 14.418971 loss_att 20.249094 loss_ctc 31.124172 loss_rnnt 11.025587 lr 0.00056691 rank 2
2022-12-04 04:13:11,962 DEBUG TRAIN Batch 9/2700 loss 12.045320 loss_att 18.847584 loss_ctc 22.430748 loss_rnnt 9.300142 lr 0.00056710 rank 4
2022-12-04 04:13:11,969 DEBUG TRAIN Batch 9/2700 loss 15.781087 loss_att 22.225143 loss_ctc 26.734356 loss_rnnt 13.031840 lr 0.00056715 rank 6
2022-12-04 04:13:11,970 DEBUG TRAIN Batch 9/2700 loss 11.236196 loss_att 13.137007 loss_ctc 20.307936 loss_rnnt 9.646467 lr 0.00056696 rank 1
2022-12-04 04:13:11,974 DEBUG TRAIN Batch 9/2700 loss 10.668946 loss_att 14.901693 loss_ctc 17.452337 loss_rnnt 8.917945 lr 0.00056701 rank 3
2022-12-04 04:13:11,974 DEBUG TRAIN Batch 9/2700 loss 10.398990 loss_att 15.087742 loss_ctc 24.185034 loss_rnnt 7.623099 lr 0.00056698 rank 0
2022-12-04 04:13:11,974 DEBUG TRAIN Batch 9/2700 loss 24.221582 loss_att 27.980850 loss_ctc 40.076958 loss_rnnt 21.355679 lr 0.00056719 rank 7
2022-12-04 04:13:11,976 DEBUG TRAIN Batch 9/2700 loss 21.909645 loss_att 29.656441 loss_ctc 36.662941 loss_rnnt 18.393179 lr 0.00056710 rank 5
2022-12-04 04:14:24,886 DEBUG TRAIN Batch 9/2800 loss 8.362522 loss_att 15.788672 loss_ctc 12.075656 loss_rnnt 6.382208 lr 0.00056660 rank 1
2022-12-04 04:14:24,888 DEBUG TRAIN Batch 9/2800 loss 11.954833 loss_att 16.150574 loss_ctc 21.039238 loss_rnnt 9.904430 lr 0.00056673 rank 4
2022-12-04 04:14:24,888 DEBUG TRAIN Batch 9/2800 loss 24.479017 loss_att 27.928139 loss_ctc 32.980747 loss_rnnt 22.655628 lr 0.00056655 rank 2
2022-12-04 04:14:24,891 DEBUG TRAIN Batch 9/2800 loss 23.344110 loss_att 24.723827 loss_ctc 37.356026 loss_rnnt 21.199911 lr 0.00056673 rank 5
2022-12-04 04:14:24,894 DEBUG TRAIN Batch 9/2800 loss 13.457377 loss_att 13.575521 loss_ctc 19.705496 loss_rnnt 12.600666 lr 0.00056664 rank 3
2022-12-04 04:14:24,897 DEBUG TRAIN Batch 9/2800 loss 20.253017 loss_att 23.305298 loss_ctc 27.788425 loss_rnnt 18.637840 lr 0.00056682 rank 7
2022-12-04 04:14:24,914 DEBUG TRAIN Batch 9/2800 loss 12.770035 loss_att 14.878695 loss_ctc 19.524828 loss_rnnt 11.447662 lr 0.00056678 rank 6
2022-12-04 04:14:24,921 DEBUG TRAIN Batch 9/2800 loss 13.566257 loss_att 20.154167 loss_ctc 24.952652 loss_rnnt 10.730491 lr 0.00056661 rank 0
2022-12-04 04:15:41,398 DEBUG TRAIN Batch 9/2900 loss 15.943035 loss_att 21.025352 loss_ctc 26.506981 loss_rnnt 13.518046 lr 0.00056642 rank 6
2022-12-04 04:15:41,401 DEBUG TRAIN Batch 9/2900 loss 10.288675 loss_att 14.423320 loss_ctc 18.520744 loss_rnnt 8.364138 lr 0.00056623 rank 1
2022-12-04 04:15:41,403 DEBUG TRAIN Batch 9/2900 loss 11.961358 loss_att 16.355232 loss_ctc 18.946907 loss_rnnt 10.151176 lr 0.00056619 rank 2
2022-12-04 04:15:41,405 DEBUG TRAIN Batch 9/2900 loss 18.166405 loss_att 21.847790 loss_ctc 31.878651 loss_rnnt 15.601828 lr 0.00056637 rank 5
2022-12-04 04:15:41,405 DEBUG TRAIN Batch 9/2900 loss 10.814602 loss_att 15.451086 loss_ctc 20.183224 loss_rnnt 8.638156 lr 0.00056625 rank 0
2022-12-04 04:15:41,406 DEBUG TRAIN Batch 9/2900 loss 15.504537 loss_att 20.593233 loss_ctc 28.387600 loss_rnnt 12.769054 lr 0.00056628 rank 3
2022-12-04 04:15:41,410 DEBUG TRAIN Batch 9/2900 loss 16.200123 loss_att 19.339336 loss_ctc 25.461397 loss_rnnt 14.337444 lr 0.00056646 rank 7
2022-12-04 04:15:41,411 DEBUG TRAIN Batch 9/2900 loss 15.643591 loss_att 17.923325 loss_ctc 21.161510 loss_rnnt 14.451922 lr 0.00056637 rank 4
2022-12-04 04:16:52,933 DEBUG TRAIN Batch 9/3000 loss 19.455881 loss_att 24.080362 loss_ctc 35.347275 loss_rnnt 16.412132 lr 0.00056587 rank 1
2022-12-04 04:16:52,937 DEBUG TRAIN Batch 9/3000 loss 12.464031 loss_att 16.257730 loss_ctc 20.693798 loss_rnnt 10.607988 lr 0.00056609 rank 7
2022-12-04 04:16:52,937 DEBUG TRAIN Batch 9/3000 loss 10.943307 loss_att 13.407377 loss_ctc 22.303028 loss_rnnt 8.935863 lr 0.00056600 rank 5
2022-12-04 04:16:52,938 DEBUG TRAIN Batch 9/3000 loss 17.293749 loss_att 23.488739 loss_ctc 24.295502 loss_rnnt 15.121183 lr 0.00056589 rank 0
2022-12-04 04:16:52,940 DEBUG TRAIN Batch 9/3000 loss 15.789353 loss_att 19.243896 loss_ctc 25.510223 loss_rnnt 13.802329 lr 0.00056592 rank 3
2022-12-04 04:16:52,941 DEBUG TRAIN Batch 9/3000 loss 14.013170 loss_att 16.960745 loss_ctc 26.149845 loss_rnnt 11.805433 lr 0.00056606 rank 6
2022-12-04 04:16:52,943 DEBUG TRAIN Batch 9/3000 loss 9.139922 loss_att 12.223672 loss_ctc 13.668749 loss_rnnt 7.919329 lr 0.00056582 rank 2
2022-12-04 04:16:52,955 DEBUG TRAIN Batch 9/3000 loss 8.994838 loss_att 12.927095 loss_ctc 16.987074 loss_rnnt 7.142755 lr 0.00056601 rank 4
2022-12-04 04:18:04,931 DEBUG TRAIN Batch 9/3100 loss 13.440969 loss_att 21.169567 loss_ctc 29.046329 loss_rnnt 9.814534 lr 0.00056553 rank 0
2022-12-04 04:18:04,933 DEBUG TRAIN Batch 9/3100 loss 18.668997 loss_att 19.444174 loss_ctc 31.775410 loss_rnnt 16.766439 lr 0.00056569 rank 6
2022-12-04 04:18:04,935 DEBUG TRAIN Batch 9/3100 loss 9.624116 loss_att 13.194271 loss_ctc 18.427465 loss_rnnt 7.736305 lr 0.00056564 rank 5
2022-12-04 04:18:04,937 DEBUG TRAIN Batch 9/3100 loss 12.701897 loss_att 15.444308 loss_ctc 21.757818 loss_rnnt 10.945957 lr 0.00056573 rank 7
2022-12-04 04:18:04,941 DEBUG TRAIN Batch 9/3100 loss 10.892722 loss_att 13.390928 loss_ctc 19.279545 loss_rnnt 9.274837 lr 0.00056565 rank 4
2022-12-04 04:18:04,944 DEBUG TRAIN Batch 9/3100 loss 13.742383 loss_att 16.150478 loss_ctc 23.377514 loss_rnnt 11.976080 lr 0.00056556 rank 3
2022-12-04 04:18:04,965 DEBUG TRAIN Batch 9/3100 loss 12.489864 loss_att 15.073048 loss_ctc 18.775494 loss_rnnt 11.135145 lr 0.00056546 rank 2
2022-12-04 04:18:04,988 DEBUG TRAIN Batch 9/3100 loss 24.300282 loss_att 29.874437 loss_ctc 38.128185 loss_rnnt 21.341728 lr 0.00056551 rank 1
2022-12-04 04:19:28,313 DEBUG TRAIN Batch 9/3200 loss 11.831267 loss_att 14.434057 loss_ctc 17.063900 loss_rnnt 10.613025 lr 0.00056519 rank 3
2022-12-04 04:19:28,315 DEBUG TRAIN Batch 9/3200 loss 16.582430 loss_att 18.330336 loss_ctc 23.366413 loss_rnnt 15.328319 lr 0.00056516 rank 0
2022-12-04 04:19:28,320 DEBUG TRAIN Batch 9/3200 loss 13.268600 loss_att 19.714563 loss_ctc 27.281935 loss_rnnt 10.110962 lr 0.00056528 rank 5
2022-12-04 04:19:28,321 DEBUG TRAIN Batch 9/3200 loss 14.465515 loss_att 21.353516 loss_ctc 28.665222 loss_rnnt 11.194620 lr 0.00056533 rank 6
2022-12-04 04:19:28,322 DEBUG TRAIN Batch 9/3200 loss 22.714224 loss_att 25.419392 loss_ctc 37.979267 loss_rnnt 20.137852 lr 0.00056515 rank 1
2022-12-04 04:19:28,325 DEBUG TRAIN Batch 9/3200 loss 13.348342 loss_att 20.115749 loss_ctc 24.445665 loss_rnnt 10.515217 lr 0.00056510 rank 2
2022-12-04 04:19:28,328 DEBUG TRAIN Batch 9/3200 loss 19.327745 loss_att 23.380722 loss_ctc 28.376429 loss_rnnt 17.310659 lr 0.00056528 rank 4
2022-12-04 04:19:28,359 DEBUG TRAIN Batch 9/3200 loss 18.399912 loss_att 19.552029 loss_ctc 32.664196 loss_rnnt 16.267584 lr 0.00056537 rank 7
2022-12-04 04:20:40,207 DEBUG TRAIN Batch 9/3300 loss 18.481010 loss_att 26.387617 loss_ctc 37.665813 loss_rnnt 14.341716 lr 0.00056497 rank 6
2022-12-04 04:20:40,207 DEBUG TRAIN Batch 9/3300 loss 21.305086 loss_att 22.621883 loss_ctc 32.040398 loss_rnnt 19.610352 lr 0.00056483 rank 3
2022-12-04 04:20:40,210 DEBUG TRAIN Batch 9/3300 loss 15.761955 loss_att 21.073874 loss_ctc 31.395239 loss_rnnt 12.615133 lr 0.00056492 rank 5
2022-12-04 04:20:40,212 DEBUG TRAIN Batch 9/3300 loss 11.799598 loss_att 11.792631 loss_ctc 15.211464 loss_rnnt 11.346075 lr 0.00056474 rank 2
2022-12-04 04:20:40,212 DEBUG TRAIN Batch 9/3300 loss 6.655165 loss_att 11.953840 loss_ctc 19.866722 loss_rnnt 3.833889 lr 0.00056480 rank 0
2022-12-04 04:20:40,212 DEBUG TRAIN Batch 9/3300 loss 9.621498 loss_att 15.701660 loss_ctc 23.068302 loss_rnnt 6.612558 lr 0.00056479 rank 1
2022-12-04 04:20:40,218 DEBUG TRAIN Batch 9/3300 loss 10.566084 loss_att 12.868345 loss_ctc 15.791519 loss_rnnt 9.408906 lr 0.00056501 rank 7
2022-12-04 04:20:40,263 DEBUG TRAIN Batch 9/3300 loss 12.145784 loss_att 17.857557 loss_ctc 21.832424 loss_rnnt 9.711878 lr 0.00056492 rank 4
2022-12-04 04:21:51,980 DEBUG TRAIN Batch 9/3400 loss 19.722202 loss_att 24.470913 loss_ctc 29.594509 loss_rnnt 17.456152 lr 0.00056461 rank 6
2022-12-04 04:21:51,991 DEBUG TRAIN Batch 9/3400 loss 7.914174 loss_att 14.305245 loss_ctc 15.483424 loss_rnnt 5.626726 lr 0.00056447 rank 3
2022-12-04 04:21:51,997 DEBUG TRAIN Batch 9/3400 loss 7.544556 loss_att 15.237451 loss_ctc 13.376266 loss_rnnt 5.228415 lr 0.00056438 rank 2
2022-12-04 04:21:51,997 DEBUG TRAIN Batch 9/3400 loss 17.851440 loss_att 21.002943 loss_ctc 26.293148 loss_rnnt 16.095579 lr 0.00056444 rank 0
2022-12-04 04:21:51,998 DEBUG TRAIN Batch 9/3400 loss 20.147974 loss_att 24.489178 loss_ctc 36.374855 loss_rnnt 17.116150 lr 0.00056443 rank 1
2022-12-04 04:21:52,000 DEBUG TRAIN Batch 9/3400 loss 9.607716 loss_att 14.039345 loss_ctc 16.514799 loss_rnnt 7.800446 lr 0.00056465 rank 7
2022-12-04 04:21:52,005 DEBUG TRAIN Batch 9/3400 loss 13.865974 loss_att 18.841576 loss_ctc 20.813633 loss_rnnt 11.944499 lr 0.00056456 rank 4
2022-12-04 04:21:52,049 DEBUG TRAIN Batch 9/3400 loss 17.934710 loss_att 23.627621 loss_ctc 27.771557 loss_rnnt 15.484549 lr 0.00056456 rank 5
2022-12-04 04:23:04,682 DEBUG TRAIN Batch 9/3500 loss 13.639372 loss_att 15.925150 loss_ctc 18.670612 loss_rnnt 12.511383 lr 0.00056407 rank 1
2022-12-04 04:23:04,685 DEBUG TRAIN Batch 9/3500 loss 19.591835 loss_att 22.472481 loss_ctc 29.870914 loss_rnnt 17.645161 lr 0.00056425 rank 6
2022-12-04 04:23:04,687 DEBUG TRAIN Batch 9/3500 loss 12.099517 loss_att 15.539512 loss_ctc 20.076912 loss_rnnt 10.347865 lr 0.00056420 rank 5
2022-12-04 04:23:04,687 DEBUG TRAIN Batch 9/3500 loss 23.550421 loss_att 28.928669 loss_ctc 35.869003 loss_rnnt 20.832293 lr 0.00056402 rank 2
2022-12-04 04:23:04,692 DEBUG TRAIN Batch 9/3500 loss 20.404917 loss_att 23.780771 loss_ctc 32.433872 loss_rnnt 18.125885 lr 0.00056411 rank 3
2022-12-04 04:23:04,692 DEBUG TRAIN Batch 9/3500 loss 15.584598 loss_att 19.926479 loss_ctc 22.361151 loss_rnnt 13.812681 lr 0.00056408 rank 0
2022-12-04 04:23:04,693 DEBUG TRAIN Batch 9/3500 loss 23.501041 loss_att 24.610369 loss_ctc 31.879213 loss_rnnt 22.162086 lr 0.00056429 rank 7
2022-12-04 04:23:04,701 DEBUG TRAIN Batch 9/3500 loss 23.891581 loss_att 26.758635 loss_ctc 40.401443 loss_rnnt 21.116854 lr 0.00056420 rank 4
2022-12-04 04:24:21,005 DEBUG TRAIN Batch 9/3600 loss 10.851514 loss_att 14.931679 loss_ctc 22.984070 loss_rnnt 8.417807 lr 0.00056384 rank 5
2022-12-04 04:24:21,007 DEBUG TRAIN Batch 9/3600 loss 7.351028 loss_att 10.222652 loss_ctc 16.523497 loss_rnnt 5.553709 lr 0.00056375 rank 3
2022-12-04 04:24:21,010 DEBUG TRAIN Batch 9/3600 loss 17.109503 loss_att 18.688032 loss_ctc 28.375202 loss_rnnt 15.291702 lr 0.00056366 rank 2
2022-12-04 04:24:21,010 DEBUG TRAIN Batch 9/3600 loss 15.063820 loss_att 19.240055 loss_ctc 19.511696 loss_rnnt 13.635522 lr 0.00056389 rank 6
2022-12-04 04:24:21,011 DEBUG TRAIN Batch 9/3600 loss 22.127583 loss_att 28.593140 loss_ctc 34.406013 loss_rnnt 19.197346 lr 0.00056373 rank 0
2022-12-04 04:24:21,011 DEBUG TRAIN Batch 9/3600 loss 25.909021 loss_att 31.538849 loss_ctc 37.053734 loss_rnnt 23.297094 lr 0.00056371 rank 1
2022-12-04 04:24:21,012 DEBUG TRAIN Batch 9/3600 loss 24.985260 loss_att 31.339781 loss_ctc 43.870766 loss_rnnt 21.196287 lr 0.00056393 rank 7
2022-12-04 04:24:21,016 DEBUG TRAIN Batch 9/3600 loss 27.229813 loss_att 36.094326 loss_ctc 45.613777 loss_rnnt 23.005711 lr 0.00056384 rank 4
2022-12-04 04:25:33,552 DEBUG TRAIN Batch 9/3700 loss 11.040832 loss_att 15.244062 loss_ctc 19.521358 loss_rnnt 9.069448 lr 0.00056337 rank 0
2022-12-04 04:25:33,556 DEBUG TRAIN Batch 9/3700 loss 16.122755 loss_att 19.173340 loss_ctc 25.851383 loss_rnnt 14.215487 lr 0.00056353 rank 6
2022-12-04 04:25:33,557 DEBUG TRAIN Batch 9/3700 loss 13.697630 loss_att 17.541134 loss_ctc 28.182203 loss_rnnt 10.997652 lr 0.00056348 rank 5
2022-12-04 04:25:33,560 DEBUG TRAIN Batch 9/3700 loss 12.677296 loss_att 14.760553 loss_ctc 21.640522 loss_rnnt 11.065548 lr 0.00056335 rank 1
2022-12-04 04:25:33,561 DEBUG TRAIN Batch 9/3700 loss 18.337317 loss_att 23.389149 loss_ctc 29.824764 loss_rnnt 15.795291 lr 0.00056340 rank 3
2022-12-04 04:25:33,563 DEBUG TRAIN Batch 9/3700 loss 13.535652 loss_att 17.434942 loss_ctc 23.251347 loss_rnnt 11.460366 lr 0.00056330 rank 2
2022-12-04 04:25:33,570 DEBUG TRAIN Batch 9/3700 loss 16.419340 loss_att 18.855659 loss_ctc 22.899637 loss_rnnt 15.068036 lr 0.00056357 rank 7
2022-12-04 04:25:33,574 DEBUG TRAIN Batch 9/3700 loss 19.917423 loss_att 24.136307 loss_ctc 32.427784 loss_rnnt 17.405598 lr 0.00056349 rank 4
2022-12-04 04:26:45,689 DEBUG TRAIN Batch 9/3800 loss 12.007570 loss_att 13.932737 loss_ctc 19.353554 loss_rnnt 10.643072 lr 0.00056313 rank 5
2022-12-04 04:26:45,692 DEBUG TRAIN Batch 9/3800 loss 15.537645 loss_att 17.154474 loss_ctc 22.717112 loss_rnnt 14.257016 lr 0.00056304 rank 3
2022-12-04 04:26:45,692 DEBUG TRAIN Batch 9/3800 loss 21.826725 loss_att 24.810585 loss_ctc 39.454689 loss_rnnt 18.879559 lr 0.00056318 rank 6
2022-12-04 04:26:45,692 DEBUG TRAIN Batch 9/3800 loss 12.206959 loss_att 14.594780 loss_ctc 19.277090 loss_rnnt 10.786712 lr 0.00056301 rank 0
2022-12-04 04:26:45,693 DEBUG TRAIN Batch 9/3800 loss 8.976693 loss_att 16.154041 loss_ctc 20.428646 loss_rnnt 6.014297 lr 0.00056321 rank 7
2022-12-04 04:26:45,693 DEBUG TRAIN Batch 9/3800 loss 12.224361 loss_att 14.176675 loss_ctc 23.742611 loss_rnnt 10.298133 lr 0.00056299 rank 1
2022-12-04 04:26:45,695 DEBUG TRAIN Batch 9/3800 loss 7.329237 loss_att 12.838072 loss_ctc 12.550278 loss_rnnt 5.531331 lr 0.00056313 rank 4
2022-12-04 04:26:45,700 DEBUG TRAIN Batch 9/3800 loss 15.556044 loss_att 18.021523 loss_ctc 29.671886 loss_rnnt 13.180835 lr 0.00056295 rank 2
2022-12-04 04:28:01,614 DEBUG TRAIN Batch 9/3900 loss 5.993981 loss_att 9.240513 loss_ctc 10.860271 loss_rnnt 4.695836 lr 0.00056282 rank 6
2022-12-04 04:28:01,617 DEBUG TRAIN Batch 9/3900 loss 11.033539 loss_att 11.054067 loss_ctc 13.691467 loss_rnnt 10.675043 lr 0.00056265 rank 0
2022-12-04 04:28:01,617 DEBUG TRAIN Batch 9/3900 loss 16.151407 loss_att 24.295689 loss_ctc 30.404980 loss_rnnt 12.622076 lr 0.00056268 rank 3
2022-12-04 04:28:01,618 DEBUG TRAIN Batch 9/3900 loss 13.432948 loss_att 19.311140 loss_ctc 24.926916 loss_rnnt 10.724779 lr 0.00056286 rank 7
2022-12-04 04:28:01,619 DEBUG TRAIN Batch 9/3900 loss 14.357965 loss_att 20.948570 loss_ctc 22.906752 loss_rnnt 11.900007 lr 0.00056277 rank 5
2022-12-04 04:28:01,621 DEBUG TRAIN Batch 9/3900 loss 11.087831 loss_att 13.945646 loss_ctc 23.294060 loss_rnnt 8.888771 lr 0.00056277 rank 4
2022-12-04 04:28:01,622 DEBUG TRAIN Batch 9/3900 loss 11.628570 loss_att 12.590323 loss_ctc 17.035488 loss_rnnt 10.715296 lr 0.00056264 rank 1
2022-12-04 04:28:01,640 DEBUG TRAIN Batch 9/3900 loss 9.798816 loss_att 14.732151 loss_ctc 17.247723 loss_rnnt 7.818961 lr 0.00056259 rank 2
2022-12-04 04:29:13,903 DEBUG TRAIN Batch 9/4000 loss 9.466082 loss_att 15.718820 loss_ctc 18.389744 loss_rnnt 7.025712 lr 0.00056228 rank 1
2022-12-04 04:29:13,917 DEBUG TRAIN Batch 9/4000 loss 27.918442 loss_att 30.380623 loss_ctc 45.606934 loss_rnnt 25.067541 lr 0.00056246 rank 6
2022-12-04 04:29:13,918 DEBUG TRAIN Batch 9/4000 loss 24.253365 loss_att 31.482470 loss_ctc 40.048817 loss_rnnt 20.701485 lr 0.00056230 rank 0
2022-12-04 04:29:13,919 DEBUG TRAIN Batch 9/4000 loss 17.713730 loss_att 17.364185 loss_ctc 23.887691 loss_rnnt 16.960443 lr 0.00056233 rank 3
2022-12-04 04:29:13,921 DEBUG TRAIN Batch 9/4000 loss 13.382630 loss_att 20.786772 loss_ctc 27.071651 loss_rnnt 10.076598 lr 0.00056250 rank 7
2022-12-04 04:29:13,923 DEBUG TRAIN Batch 9/4000 loss 21.163795 loss_att 25.114513 loss_ctc 34.679703 loss_rnnt 18.571529 lr 0.00056241 rank 5
2022-12-04 04:29:13,925 DEBUG TRAIN Batch 9/4000 loss 10.532372 loss_att 16.221508 loss_ctc 23.404562 loss_rnnt 7.678253 lr 0.00056242 rank 4
2022-12-04 04:29:13,926 DEBUG TRAIN Batch 9/4000 loss 11.106588 loss_att 13.963474 loss_ctc 15.038095 loss_rnnt 10.011009 lr 0.00056223 rank 2
2022-12-04 04:30:25,928 DEBUG TRAIN Batch 9/4100 loss 6.405904 loss_att 10.329242 loss_ctc 15.556946 loss_rnnt 4.401097 lr 0.00056194 rank 0
2022-12-04 04:30:25,929 DEBUG TRAIN Batch 9/4100 loss 10.773580 loss_att 16.203638 loss_ctc 24.034327 loss_rnnt 7.919468 lr 0.00056197 rank 3
2022-12-04 04:30:25,930 DEBUG TRAIN Batch 9/4100 loss 14.654890 loss_att 16.811018 loss_ctc 20.720367 loss_rnnt 13.414934 lr 0.00056215 rank 7
2022-12-04 04:30:25,930 DEBUG TRAIN Batch 9/4100 loss 9.226582 loss_att 11.084795 loss_ctc 11.812363 loss_rnnt 8.510167 lr 0.00056193 rank 1
2022-12-04 04:30:25,931 DEBUG TRAIN Batch 9/4100 loss 22.055460 loss_att 25.570431 loss_ctc 29.728365 loss_rnnt 20.329411 lr 0.00056211 rank 6
2022-12-04 04:30:25,932 DEBUG TRAIN Batch 9/4100 loss 8.507869 loss_att 13.216202 loss_ctc 15.426060 loss_rnnt 6.643776 lr 0.00056206 rank 5
2022-12-04 04:30:25,934 DEBUG TRAIN Batch 9/4100 loss 18.011047 loss_att 20.434357 loss_ctc 22.366341 loss_rnnt 16.945679 lr 0.00056188 rank 2
2022-12-04 04:30:25,942 DEBUG TRAIN Batch 9/4100 loss 12.741001 loss_att 16.938786 loss_ctc 25.441639 loss_rnnt 10.208026 lr 0.00056206 rank 4
2022-12-04 04:31:38,966 DEBUG TRAIN Batch 9/4200 loss 18.839716 loss_att 22.615738 loss_ctc 29.383606 loss_rnnt 16.678659 lr 0.00056170 rank 5
2022-12-04 04:31:38,969 DEBUG TRAIN Batch 9/4200 loss 13.670031 loss_att 17.808699 loss_ctc 25.715912 loss_rnnt 11.236179 lr 0.00056175 rank 6
2022-12-04 04:31:38,969 DEBUG TRAIN Batch 9/4200 loss 16.509939 loss_att 19.561581 loss_ctc 29.618690 loss_rnnt 14.151777 lr 0.00056152 rank 2
2022-12-04 04:31:38,972 DEBUG TRAIN Batch 9/4200 loss 2.395483 loss_att 6.485353 loss_ctc 5.205860 loss_rnnt 1.202791 lr 0.00056162 rank 3
2022-12-04 04:31:38,976 DEBUG TRAIN Batch 9/4200 loss 7.687898 loss_att 12.883512 loss_ctc 13.711639 loss_rnnt 5.845609 lr 0.00056157 rank 1
2022-12-04 04:31:38,976 DEBUG TRAIN Batch 9/4200 loss 8.725718 loss_att 13.098140 loss_ctc 20.325222 loss_rnnt 6.304633 lr 0.00056171 rank 4
2022-12-04 04:31:38,979 DEBUG TRAIN Batch 9/4200 loss 13.809007 loss_att 21.028198 loss_ctc 22.209866 loss_rnnt 11.245054 lr 0.00056159 rank 0
2022-12-04 04:31:39,007 DEBUG TRAIN Batch 9/4200 loss 14.270349 loss_att 18.190174 loss_ctc 23.637653 loss_rnnt 12.237410 lr 0.00056179 rank 7
2022-12-04 04:32:54,808 DEBUG TRAIN Batch 9/4300 loss 15.082246 loss_att 17.798901 loss_ctc 28.118155 loss_rnnt 12.800795 lr 0.00056122 rank 1
2022-12-04 04:32:54,807 DEBUG TRAIN Batch 9/4300 loss 16.628548 loss_att 20.763746 loss_ctc 32.343300 loss_rnnt 13.706207 lr 0.00056123 rank 0
2022-12-04 04:32:54,807 DEBUG TRAIN Batch 9/4300 loss 13.208186 loss_att 16.657072 loss_ctc 23.267399 loss_rnnt 11.177179 lr 0.00056117 rank 2
2022-12-04 04:32:54,810 DEBUG TRAIN Batch 9/4300 loss 14.830967 loss_att 16.878843 loss_ctc 20.675104 loss_rnnt 13.642174 lr 0.00056140 rank 6
2022-12-04 04:32:54,811 DEBUG TRAIN Batch 9/4300 loss 16.163939 loss_att 19.771629 loss_ctc 28.978298 loss_rnnt 13.733818 lr 0.00056135 rank 5
2022-12-04 04:32:54,815 DEBUG TRAIN Batch 9/4300 loss 14.475741 loss_att 17.153543 loss_ctc 24.527252 loss_rnnt 12.599979 lr 0.00056144 rank 7
2022-12-04 04:32:54,816 DEBUG TRAIN Batch 9/4300 loss 11.073371 loss_att 12.587536 loss_ctc 17.011497 loss_rnnt 9.978788 lr 0.00056126 rank 3
2022-12-04 04:32:54,820 DEBUG TRAIN Batch 9/4300 loss 8.926453 loss_att 12.169785 loss_ctc 12.753268 loss_rnnt 7.767544 lr 0.00056135 rank 4
2022-12-04 04:34:06,738 DEBUG TRAIN Batch 9/4400 loss 20.219776 loss_att 19.937534 loss_ctc 31.258625 loss_rnnt 18.804380 lr 0.00056088 rank 0
2022-12-04 04:34:06,740 DEBUG TRAIN Batch 9/4400 loss 9.170050 loss_att 8.753858 loss_ctc 13.121816 loss_rnnt 8.726386 lr 0.00056104 rank 6
2022-12-04 04:34:06,742 DEBUG TRAIN Batch 9/4400 loss 12.596027 loss_att 15.227921 loss_ctc 25.257683 loss_rnnt 10.381428 lr 0.00056086 rank 1
2022-12-04 04:34:06,743 DEBUG TRAIN Batch 9/4400 loss 13.409532 loss_att 13.115178 loss_ctc 19.015032 loss_rnnt 12.721002 lr 0.00056082 rank 2
2022-12-04 04:34:06,744 DEBUG TRAIN Batch 9/4400 loss 18.726030 loss_att 19.532417 loss_ctc 30.135201 loss_rnnt 17.043531 lr 0.00056099 rank 5
2022-12-04 04:34:06,746 DEBUG TRAIN Batch 9/4400 loss 14.133043 loss_att 17.558205 loss_ctc 24.135868 loss_rnnt 12.114301 lr 0.00056091 rank 3
2022-12-04 04:34:06,751 DEBUG TRAIN Batch 9/4400 loss 13.537445 loss_att 14.486252 loss_ctc 16.269604 loss_rnnt 12.983397 lr 0.00056100 rank 4
2022-12-04 04:34:06,788 DEBUG TRAIN Batch 9/4400 loss 8.780643 loss_att 10.138381 loss_ctc 14.405521 loss_rnnt 7.759113 lr 0.00056108 rank 7
2022-12-04 04:35:18,636 DEBUG TRAIN Batch 9/4500 loss 17.792736 loss_att 22.811722 loss_ctc 36.044910 loss_rnnt 14.355316 lr 0.00056069 rank 6
2022-12-04 04:35:18,636 DEBUG TRAIN Batch 9/4500 loss 15.139779 loss_att 21.368132 loss_ctc 23.415924 loss_rnnt 12.790622 lr 0.00056047 rank 2
2022-12-04 04:35:18,637 DEBUG TRAIN Batch 9/4500 loss 6.263663 loss_att 10.223188 loss_ctc 12.724597 loss_rnnt 4.610300 lr 0.00056056 rank 3
2022-12-04 04:35:18,638 DEBUG TRAIN Batch 9/4500 loss 6.974524 loss_att 11.133844 loss_ctc 16.502241 loss_rnnt 4.872297 lr 0.00056051 rank 1
2022-12-04 04:35:18,639 DEBUG TRAIN Batch 9/4500 loss 29.460777 loss_att 30.401264 loss_ctc 45.903152 loss_rnnt 27.080362 lr 0.00056053 rank 0
2022-12-04 04:35:18,640 DEBUG TRAIN Batch 9/4500 loss 9.992421 loss_att 22.152126 loss_ctc 14.850673 loss_rnnt 6.912713 lr 0.00056073 rank 7
2022-12-04 04:35:18,641 DEBUG TRAIN Batch 9/4500 loss 7.436969 loss_att 15.228060 loss_ctc 12.565519 loss_rnnt 5.194943 lr 0.00056064 rank 5
2022-12-04 04:35:18,643 DEBUG TRAIN Batch 9/4500 loss 18.824156 loss_att 23.037466 loss_ctc 26.146418 loss_rnnt 17.005192 lr 0.00056065 rank 4
2022-12-04 04:36:31,803 DEBUG TRAIN Batch 9/4600 loss 12.160887 loss_att 14.733349 loss_ctc 13.898638 loss_rnnt 11.414694 lr 0.00056038 rank 7
2022-12-04 04:36:31,816 DEBUG TRAIN Batch 9/4600 loss 11.052554 loss_att 13.860291 loss_ctc 17.504215 loss_rnnt 9.630785 lr 0.00056018 rank 0
2022-12-04 04:36:31,817 DEBUG TRAIN Batch 9/4600 loss 15.370310 loss_att 21.264198 loss_ctc 27.352478 loss_rnnt 12.593910 lr 0.00056021 rank 3
2022-12-04 04:36:31,818 DEBUG TRAIN Batch 9/4600 loss 26.139601 loss_att 30.555199 loss_ctc 44.670788 loss_rnnt 22.785656 lr 0.00056034 rank 6
2022-12-04 04:36:31,824 DEBUG TRAIN Batch 9/4600 loss 18.463766 loss_att 18.890507 loss_ctc 31.750378 loss_rnnt 16.606871 lr 0.00056029 rank 4
2022-12-04 04:36:31,826 DEBUG TRAIN Batch 9/4600 loss 18.358475 loss_att 27.078045 loss_ctc 36.702011 loss_rnnt 14.168755 lr 0.00056011 rank 2
2022-12-04 04:36:31,839 DEBUG TRAIN Batch 9/4600 loss 21.358694 loss_att 23.258823 loss_ctc 34.185474 loss_rnnt 19.268433 lr 0.00056029 rank 5
2022-12-04 04:36:31,841 DEBUG TRAIN Batch 9/4600 loss 10.623124 loss_att 18.757872 loss_ctc 24.905857 loss_rnnt 7.091810 lr 0.00056016 rank 1
2022-12-04 04:37:55,782 DEBUG TRAIN Batch 9/4700 loss 12.458467 loss_att 17.637888 loss_ctc 23.022446 loss_rnnt 10.014052 lr 0.00055999 rank 6
2022-12-04 04:37:55,801 DEBUG TRAIN Batch 9/4700 loss 13.408116 loss_att 18.984074 loss_ctc 29.762253 loss_rnnt 10.112372 lr 0.00055983 rank 0
2022-12-04 04:37:55,801 DEBUG TRAIN Batch 9/4700 loss 9.172092 loss_att 12.837063 loss_ctc 15.124018 loss_rnnt 7.645509 lr 0.00055994 rank 5
2022-12-04 04:37:55,804 DEBUG TRAIN Batch 9/4700 loss 11.722734 loss_att 17.075989 loss_ctc 22.647041 loss_rnnt 9.195509 lr 0.00055976 rank 2
2022-12-04 04:37:55,805 DEBUG TRAIN Batch 9/4700 loss 12.585900 loss_att 15.961871 loss_ctc 21.071566 loss_rnnt 10.779284 lr 0.00056003 rank 7
2022-12-04 04:37:55,809 DEBUG TRAIN Batch 9/4700 loss 13.381743 loss_att 19.256973 loss_ctc 21.347340 loss_rnnt 11.144618 lr 0.00055985 rank 3
2022-12-04 04:37:55,809 DEBUG TRAIN Batch 9/4700 loss 6.248190 loss_att 13.839343 loss_ctc 10.925738 loss_rnnt 4.106287 lr 0.00055981 rank 1
2022-12-04 04:37:55,862 DEBUG TRAIN Batch 9/4700 loss 9.153355 loss_att 13.736975 loss_ctc 17.328890 loss_rnnt 7.146558 lr 0.00055994 rank 4
2022-12-04 04:39:07,239 DEBUG TRAIN Batch 9/4800 loss 10.769062 loss_att 14.933323 loss_ctc 19.888319 loss_rnnt 8.720309 lr 0.00055964 rank 6
2022-12-04 04:39:07,241 DEBUG TRAIN Batch 9/4800 loss 21.511549 loss_att 28.499804 loss_ctc 33.078102 loss_rnnt 18.571690 lr 0.00055959 rank 5
2022-12-04 04:39:07,242 DEBUG TRAIN Batch 9/4800 loss 13.090112 loss_att 17.227661 loss_ctc 23.161160 loss_rnnt 10.919794 lr 0.00055946 rank 1
2022-12-04 04:39:07,241 DEBUG TRAIN Batch 9/4800 loss 5.837153 loss_att 9.212067 loss_ctc 9.402090 loss_rnnt 4.686845 lr 0.00055950 rank 3
2022-12-04 04:39:07,243 DEBUG TRAIN Batch 9/4800 loss 15.066851 loss_att 19.464277 loss_ctc 24.591957 loss_rnnt 12.917351 lr 0.00055941 rank 2
2022-12-04 04:39:07,245 DEBUG TRAIN Batch 9/4800 loss 7.574319 loss_att 10.340037 loss_ctc 12.428741 loss_rnnt 6.373919 lr 0.00055967 rank 7
2022-12-04 04:39:07,246 DEBUG TRAIN Batch 9/4800 loss 16.518242 loss_att 23.425522 loss_ctc 26.721579 loss_rnnt 13.776339 lr 0.00055959 rank 4
2022-12-04 04:39:07,246 DEBUG TRAIN Batch 9/4800 loss 18.390320 loss_att 21.605940 loss_ctc 29.692585 loss_rnnt 16.240227 lr 0.00055948 rank 0
2022-12-04 04:40:19,416 DEBUG TRAIN Batch 9/4900 loss 7.906111 loss_att 11.916001 loss_ctc 13.594244 loss_rnnt 6.345715 lr 0.00055924 rank 5
2022-12-04 04:40:19,416 DEBUG TRAIN Batch 9/4900 loss 13.447550 loss_att 17.072460 loss_ctc 21.801052 loss_rnnt 11.608767 lr 0.00055915 rank 3
2022-12-04 04:40:19,420 DEBUG TRAIN Batch 9/4900 loss 6.567744 loss_att 9.767492 loss_ctc 11.856274 loss_rnnt 5.222657 lr 0.00055929 rank 6
2022-12-04 04:40:19,421 DEBUG TRAIN Batch 9/4900 loss 21.674549 loss_att 23.177374 loss_ctc 30.471186 loss_rnnt 20.201097 lr 0.00055911 rank 1
2022-12-04 04:40:19,422 DEBUG TRAIN Batch 9/4900 loss 26.069246 loss_att 27.182245 loss_ctc 36.251556 loss_rnnt 24.489002 lr 0.00055913 rank 0
2022-12-04 04:40:19,423 DEBUG TRAIN Batch 9/4900 loss 17.603060 loss_att 22.940529 loss_ctc 31.996811 loss_rnnt 14.616398 lr 0.00055906 rank 2
2022-12-04 04:40:19,438 DEBUG TRAIN Batch 9/4900 loss 10.976171 loss_att 14.857391 loss_ctc 24.033634 loss_rnnt 8.458931 lr 0.00055932 rank 7
2022-12-04 04:40:19,471 DEBUG TRAIN Batch 9/4900 loss 18.456516 loss_att 22.460041 loss_ctc 34.291836 loss_rnnt 15.544435 lr 0.00055924 rank 4
2022-12-04 04:41:40,705 DEBUG TRAIN Batch 9/5000 loss 14.204288 loss_att 19.967739 loss_ctc 29.641094 loss_rnnt 10.993357 lr 0.00055894 rank 6
2022-12-04 04:41:40,706 DEBUG TRAIN Batch 9/5000 loss 8.785301 loss_att 13.310756 loss_ctc 17.442501 loss_rnnt 6.725917 lr 0.00055878 rank 0
2022-12-04 04:41:40,719 DEBUG TRAIN Batch 9/5000 loss 17.543425 loss_att 18.352798 loss_ctc 26.036417 loss_rnnt 16.249151 lr 0.00055889 rank 5
2022-12-04 04:41:40,723 DEBUG TRAIN Batch 9/5000 loss 12.398063 loss_att 12.827625 loss_ctc 19.422352 loss_rnnt 11.375579 lr 0.00055898 rank 7
2022-12-04 04:41:40,724 DEBUG TRAIN Batch 9/5000 loss 21.167818 loss_att 23.893528 loss_ctc 33.746979 loss_rnnt 18.945454 lr 0.00055871 rank 2
2022-12-04 04:41:40,725 DEBUG TRAIN Batch 9/5000 loss 13.003036 loss_att 15.671258 loss_ctc 22.425236 loss_rnnt 11.213099 lr 0.00055880 rank 3
2022-12-04 04:41:40,729 DEBUG TRAIN Batch 9/5000 loss 18.347986 loss_att 25.191265 loss_ctc 39.459530 loss_rnnt 14.164457 lr 0.00055889 rank 4
2022-12-04 04:41:40,771 DEBUG TRAIN Batch 9/5000 loss 21.556402 loss_att 24.395123 loss_ctc 41.087616 loss_rnnt 18.384497 lr 0.00055876 rank 1
2022-12-04 04:42:52,449 DEBUG TRAIN Batch 9/5100 loss 9.485363 loss_att 16.332199 loss_ctc 16.053143 loss_rnnt 7.240291 lr 0.00055859 rank 6
2022-12-04 04:42:52,463 DEBUG TRAIN Batch 9/5100 loss 16.318985 loss_att 19.793915 loss_ctc 23.758724 loss_rnnt 14.632034 lr 0.00055843 rank 0
2022-12-04 04:42:52,467 DEBUG TRAIN Batch 9/5100 loss 12.600128 loss_att 16.124344 loss_ctc 19.597031 loss_rnnt 10.962364 lr 0.00055841 rank 1
2022-12-04 04:42:52,468 DEBUG TRAIN Batch 9/5100 loss 9.711583 loss_att 9.645285 loss_ctc 13.737294 loss_rnnt 9.188082 lr 0.00055846 rank 3
2022-12-04 04:42:52,470 DEBUG TRAIN Batch 9/5100 loss 11.368511 loss_att 15.745058 loss_ctc 18.051910 loss_rnnt 9.602081 lr 0.00055854 rank 5
2022-12-04 04:42:52,471 DEBUG TRAIN Batch 9/5100 loss 30.836067 loss_att 39.558708 loss_ctc 60.120232 loss_rnnt 25.186981 lr 0.00055836 rank 2
2022-12-04 04:42:52,472 DEBUG TRAIN Batch 9/5100 loss 15.463097 loss_att 20.976501 loss_ctc 20.405090 loss_rnnt 13.701483 lr 0.00055863 rank 7
2022-12-04 04:42:52,479 DEBUG TRAIN Batch 9/5100 loss 13.762545 loss_att 15.283738 loss_ctc 21.697878 loss_rnnt 12.400261 lr 0.00055854 rank 4
2022-12-04 04:44:04,658 DEBUG TRAIN Batch 9/5200 loss 15.909185 loss_att 23.811348 loss_ctc 26.582081 loss_rnnt 12.905701 lr 0.00055811 rank 3
2022-12-04 04:44:04,661 DEBUG TRAIN Batch 9/5200 loss 8.927836 loss_att 9.770012 loss_ctc 13.226727 loss_rnnt 8.186215 lr 0.00055806 rank 1
2022-12-04 04:44:04,661 DEBUG TRAIN Batch 9/5200 loss 14.107994 loss_att 16.431543 loss_ctc 23.342989 loss_rnnt 12.411951 lr 0.00055808 rank 0
2022-12-04 04:44:04,662 DEBUG TRAIN Batch 9/5200 loss 17.637203 loss_att 23.644875 loss_ctc 28.749176 loss_rnnt 14.954071 lr 0.00055824 rank 6
2022-12-04 04:44:04,663 DEBUG TRAIN Batch 9/5200 loss 11.188587 loss_att 17.083937 loss_ctc 22.939177 loss_rnnt 8.442772 lr 0.00055828 rank 7
2022-12-04 04:44:04,666 DEBUG TRAIN Batch 9/5200 loss 29.625257 loss_att 29.427170 loss_ctc 43.671356 loss_rnnt 27.792061 lr 0.00055819 rank 5
2022-12-04 04:44:04,668 DEBUG TRAIN Batch 9/5200 loss 8.538319 loss_att 13.488234 loss_ctc 17.249260 loss_rnnt 6.386877 lr 0.00055802 rank 2
2022-12-04 04:44:04,676 DEBUG TRAIN Batch 9/5200 loss 12.423090 loss_att 13.748190 loss_ctc 20.206837 loss_rnnt 11.120235 lr 0.00055819 rank 4
2022-12-04 04:45:18,078 DEBUG TRAIN Batch 9/5300 loss 8.552351 loss_att 11.848474 loss_ctc 15.917860 loss_rnnt 6.911059 lr 0.00055767 rank 2
2022-12-04 04:45:18,085 DEBUG TRAIN Batch 9/5300 loss 23.393322 loss_att 27.585543 loss_ctc 39.016655 loss_rnnt 20.471766 lr 0.00055789 rank 6
2022-12-04 04:45:18,090 DEBUG TRAIN Batch 9/5300 loss 22.018490 loss_att 26.595566 loss_ctc 38.251846 loss_rnnt 18.938625 lr 0.00055773 rank 0
2022-12-04 04:45:18,091 DEBUG TRAIN Batch 9/5300 loss 18.155724 loss_att 25.217131 loss_ctc 35.591881 loss_rnnt 14.418623 lr 0.00055771 rank 1
2022-12-04 04:45:18,091 DEBUG TRAIN Batch 9/5300 loss 12.779214 loss_att 17.276081 loss_ctc 22.959339 loss_rnnt 10.522491 lr 0.00055793 rank 7
2022-12-04 04:45:18,095 DEBUG TRAIN Batch 9/5300 loss 11.645767 loss_att 13.411354 loss_ctc 20.232481 loss_rnnt 10.147754 lr 0.00055776 rank 3
2022-12-04 04:45:18,095 DEBUG TRAIN Batch 9/5300 loss 4.526704 loss_att 7.457345 loss_ctc 8.102148 loss_rnnt 3.463850 lr 0.00055785 rank 4
2022-12-04 04:45:18,111 DEBUG TRAIN Batch 9/5300 loss 9.060028 loss_att 15.955102 loss_ctc 19.146961 loss_rnnt 6.336089 lr 0.00055784 rank 5
2022-12-04 04:46:41,667 DEBUG TRAIN Batch 9/5400 loss 21.555000 loss_att 27.092571 loss_ctc 37.273544 loss_rnnt 18.351683 lr 0.00055754 rank 6
2022-12-04 04:46:41,668 DEBUG TRAIN Batch 9/5400 loss 23.572851 loss_att 29.401508 loss_ctc 49.782818 loss_rnnt 18.912457 lr 0.00055739 rank 0
2022-12-04 04:46:41,669 DEBUG TRAIN Batch 9/5400 loss 18.682064 loss_att 22.952158 loss_ctc 31.003016 loss_rnnt 16.185251 lr 0.00055758 rank 7
2022-12-04 04:46:41,672 DEBUG TRAIN Batch 9/5400 loss 9.935572 loss_att 14.640503 loss_ctc 17.071213 loss_rnnt 8.043167 lr 0.00055732 rank 2
2022-12-04 04:46:41,674 DEBUG TRAIN Batch 9/5400 loss 12.229720 loss_att 15.352310 loss_ctc 26.369675 loss_rnnt 9.719874 lr 0.00055750 rank 5
2022-12-04 04:46:41,675 DEBUG TRAIN Batch 9/5400 loss 27.974886 loss_att 34.276768 loss_ctc 50.016521 loss_rnnt 23.775625 lr 0.00055750 rank 4
2022-12-04 04:46:41,675 DEBUG TRAIN Batch 9/5400 loss 8.068018 loss_att 14.385597 loss_ctc 18.074646 loss_rnnt 5.470285 lr 0.00055737 rank 1
2022-12-04 04:46:41,679 DEBUG TRAIN Batch 9/5400 loss 23.372559 loss_att 25.175829 loss_ctc 31.424831 loss_rnnt 21.938267 lr 0.00055741 rank 3
2022-12-04 04:47:53,330 DEBUG TRAIN Batch 9/5500 loss 8.552853 loss_att 12.939903 loss_ctc 14.779261 loss_rnnt 6.845254 lr 0.00055720 rank 6
2022-12-04 04:47:53,335 DEBUG TRAIN Batch 9/5500 loss 8.101535 loss_att 12.451709 loss_ctc 13.527509 loss_rnnt 6.508037 lr 0.00055704 rank 0
2022-12-04 04:47:53,335 DEBUG TRAIN Batch 9/5500 loss 4.842295 loss_att 7.106291 loss_ctc 9.769829 loss_rnnt 3.732491 lr 0.00055715 rank 5
2022-12-04 04:47:53,338 DEBUG TRAIN Batch 9/5500 loss 15.564233 loss_att 19.083561 loss_ctc 28.770451 loss_rnnt 13.099539 lr 0.00055715 rank 4
2022-12-04 04:47:53,339 DEBUG TRAIN Batch 9/5500 loss 10.014747 loss_att 11.314431 loss_ctc 16.532244 loss_rnnt 8.885811 lr 0.00055724 rank 7
2022-12-04 04:47:53,339 DEBUG TRAIN Batch 9/5500 loss 10.429536 loss_att 14.671825 loss_ctc 17.480450 loss_rnnt 8.640955 lr 0.00055707 rank 3
2022-12-04 04:47:53,341 DEBUG TRAIN Batch 9/5500 loss 12.044485 loss_att 16.386030 loss_ctc 23.122128 loss_rnnt 9.699157 lr 0.00055698 rank 2
2022-12-04 04:47:53,381 DEBUG TRAIN Batch 9/5500 loss 7.110538 loss_att 12.055628 loss_ctc 18.383215 loss_rnnt 4.618496 lr 0.00055702 rank 1
2022-12-04 04:49:05,440 DEBUG TRAIN Batch 9/5600 loss 9.525659 loss_att 13.225401 loss_ctc 16.783438 loss_rnnt 7.818006 lr 0.00055669 rank 0
2022-12-04 04:49:05,455 DEBUG TRAIN Batch 9/5600 loss 15.268098 loss_att 19.763081 loss_ctc 25.550467 loss_rnnt 12.998117 lr 0.00055685 rank 6
2022-12-04 04:49:05,456 DEBUG TRAIN Batch 9/5600 loss 19.114647 loss_att 19.585449 loss_ctc 26.883316 loss_rnnt 17.984665 lr 0.00055680 rank 5
2022-12-04 04:49:05,457 DEBUG TRAIN Batch 9/5600 loss 9.265749 loss_att 13.506450 loss_ctc 15.478002 loss_rnnt 7.589309 lr 0.00055672 rank 3
2022-12-04 04:49:05,462 DEBUG TRAIN Batch 9/5600 loss 15.493780 loss_att 27.136696 loss_ctc 37.025871 loss_rnnt 10.294250 lr 0.00055668 rank 1
2022-12-04 04:49:05,464 DEBUG TRAIN Batch 9/5600 loss 18.140768 loss_att 23.087772 loss_ctc 31.216003 loss_rnnt 15.408004 lr 0.00055689 rank 7
2022-12-04 04:49:05,465 DEBUG TRAIN Batch 9/5600 loss 16.770840 loss_att 17.507055 loss_ctc 20.586983 loss_rnnt 16.114777 lr 0.00055663 rank 2
2022-12-04 04:49:05,468 DEBUG TRAIN Batch 9/5600 loss 20.305981 loss_att 26.175461 loss_ctc 35.033512 loss_rnnt 17.168415 lr 0.00055681 rank 4
2022-12-04 04:50:32,943 DEBUG TRAIN Batch 9/5700 loss 19.523817 loss_att 22.750748 loss_ctc 32.524544 loss_rnnt 17.144999 lr 0.00055635 rank 0
2022-12-04 04:50:32,944 DEBUG TRAIN Batch 9/5700 loss 18.768770 loss_att 21.267088 loss_ctc 25.082867 loss_rnnt 17.427227 lr 0.00055633 rank 1
2022-12-04 04:50:32,944 DEBUG TRAIN Batch 9/5700 loss 7.272699 loss_att 13.925911 loss_ctc 15.452686 loss_rnnt 4.851392 lr 0.00055646 rank 5
2022-12-04 04:50:32,948 DEBUG TRAIN Batch 9/5700 loss 32.692329 loss_att 40.049152 loss_ctc 58.910259 loss_rnnt 27.725241 lr 0.00055655 rank 7
2022-12-04 04:50:32,949 DEBUG TRAIN Batch 9/5700 loss 13.003906 loss_att 23.373257 loss_ctc 28.220961 loss_rnnt 8.901094 lr 0.00055629 rank 2
2022-12-04 04:50:32,950 DEBUG TRAIN Batch 9/5700 loss 13.438665 loss_att 16.503885 loss_ctc 32.932072 loss_rnnt 10.226501 lr 0.00055646 rank 4
2022-12-04 04:50:32,950 DEBUG TRAIN Batch 9/5700 loss 18.427814 loss_att 20.658119 loss_ctc 31.310154 loss_rnnt 16.264107 lr 0.00055651 rank 6
2022-12-04 04:50:32,955 DEBUG TRAIN Batch 9/5700 loss 8.802989 loss_att 11.560505 loss_ctc 14.361819 loss_rnnt 7.510308 lr 0.00055638 rank 3
2022-12-04 04:51:44,561 DEBUG TRAIN Batch 9/5800 loss 15.293119 loss_att 24.946863 loss_ctc 22.833197 loss_rnnt 12.357028 lr 0.00055616 rank 6
2022-12-04 04:51:44,563 DEBUG TRAIN Batch 9/5800 loss 8.254258 loss_att 10.526112 loss_ctc 12.261621 loss_rnnt 7.265573 lr 0.00055601 rank 0
2022-12-04 04:51:44,566 DEBUG TRAIN Batch 9/5800 loss 10.870912 loss_att 13.425787 loss_ctc 17.341074 loss_rnnt 9.497248 lr 0.00055599 rank 1
2022-12-04 04:51:44,566 DEBUG TRAIN Batch 9/5800 loss 15.661513 loss_att 20.389175 loss_ctc 22.349407 loss_rnnt 13.824263 lr 0.00055612 rank 5
2022-12-04 04:51:44,570 DEBUG TRAIN Batch 9/5800 loss 18.036821 loss_att 21.214725 loss_ctc 21.416264 loss_rnnt 16.950647 lr 0.00055594 rank 2
2022-12-04 04:51:44,571 DEBUG TRAIN Batch 9/5800 loss 12.877131 loss_att 15.787751 loss_ctc 23.387878 loss_rnnt 10.893574 lr 0.00055603 rank 3
2022-12-04 04:51:44,574 DEBUG TRAIN Batch 9/5800 loss 11.534632 loss_att 15.685593 loss_ctc 18.648071 loss_rnnt 9.755981 lr 0.00055620 rank 7
2022-12-04 04:51:44,575 DEBUG TRAIN Batch 9/5800 loss 14.231893 loss_att 16.673607 loss_ctc 21.088970 loss_rnnt 12.829271 lr 0.00055612 rank 4
2022-12-04 04:52:56,884 DEBUG TRAIN Batch 9/5900 loss 21.928186 loss_att 24.311703 loss_ctc 28.989574 loss_rnnt 20.509964 lr 0.00055566 rank 0
2022-12-04 04:52:56,884 DEBUG TRAIN Batch 9/5900 loss 10.455200 loss_att 15.618160 loss_ctc 15.839422 loss_rnnt 8.704712 lr 0.00055582 rank 6
2022-12-04 04:52:56,887 DEBUG TRAIN Batch 9/5900 loss 6.421445 loss_att 10.455363 loss_ctc 13.146686 loss_rnnt 4.717963 lr 0.00055577 rank 5
2022-12-04 04:52:56,887 DEBUG TRAIN Batch 9/5900 loss 4.655030 loss_att 7.771453 loss_ctc 11.406248 loss_rnnt 3.131582 lr 0.00055586 rank 7
2022-12-04 04:52:56,890 DEBUG TRAIN Batch 9/5900 loss 8.196367 loss_att 10.946670 loss_ctc 15.911041 loss_rnnt 6.617683 lr 0.00055560 rank 2
2022-12-04 04:52:56,891 DEBUG TRAIN Batch 9/5900 loss 5.643193 loss_att 8.823375 loss_ctc 8.505028 loss_rnnt 4.625579 lr 0.00055564 rank 1
2022-12-04 04:52:56,895 DEBUG TRAIN Batch 9/5900 loss 14.408788 loss_att 18.597553 loss_ctc 22.692366 loss_rnnt 12.466558 lr 0.00055569 rank 3
2022-12-04 04:52:56,898 DEBUG TRAIN Batch 9/5900 loss 10.353767 loss_att 15.360855 loss_ctc 23.875641 loss_rnnt 7.549432 lr 0.00055578 rank 4
2022-12-04 04:54:09,647 DEBUG TRAIN Batch 9/6000 loss 5.827229 loss_att 11.800262 loss_ctc 9.654972 loss_rnnt 4.122257 lr 0.00055543 rank 4
2022-12-04 04:54:09,656 DEBUG TRAIN Batch 9/6000 loss 11.220782 loss_att 17.492651 loss_ctc 24.760275 loss_rnnt 8.161143 lr 0.00055532 rank 0
2022-12-04 04:54:09,656 DEBUG TRAIN Batch 9/6000 loss 15.248997 loss_att 17.575005 loss_ctc 20.154339 loss_rnnt 14.129749 lr 0.00055548 rank 6
2022-12-04 04:54:09,657 DEBUG TRAIN Batch 9/6000 loss 18.184345 loss_att 20.320229 loss_ctc 30.179359 loss_rnnt 16.157833 lr 0.00055551 rank 7
2022-12-04 04:54:09,659 DEBUG TRAIN Batch 9/6000 loss 12.118616 loss_att 16.842274 loss_ctc 20.992802 loss_rnnt 9.990659 lr 0.00055526 rank 2
2022-12-04 04:54:09,659 DEBUG TRAIN Batch 9/6000 loss 53.227142 loss_att 54.093876 loss_ctc 76.112991 loss_rnnt 50.002350 lr 0.00055535 rank 3
2022-12-04 04:54:09,674 DEBUG TRAIN Batch 9/6000 loss 26.797361 loss_att 27.005440 loss_ctc 38.129646 loss_rnnt 25.244774 lr 0.00055543 rank 5
2022-12-04 04:54:09,693 DEBUG TRAIN Batch 9/6000 loss 10.550402 loss_att 14.427678 loss_ctc 22.453718 loss_rnnt 8.187838 lr 0.00055530 rank 1
2022-12-04 04:55:27,137 DEBUG TRAIN Batch 9/6100 loss 11.975778 loss_att 14.787939 loss_ctc 22.275816 loss_rnnt 10.040007 lr 0.00055500 rank 3
2022-12-04 04:55:27,137 DEBUG TRAIN Batch 9/6100 loss 22.664867 loss_att 23.513739 loss_ctc 31.575146 loss_rnnt 21.307056 lr 0.00055509 rank 5
2022-12-04 04:55:27,138 DEBUG TRAIN Batch 9/6100 loss 13.932069 loss_att 18.691437 loss_ctc 20.008299 loss_rnnt 12.170031 lr 0.00055513 rank 6
2022-12-04 04:55:27,138 DEBUG TRAIN Batch 9/6100 loss 6.305439 loss_att 11.833550 loss_ctc 11.538790 loss_rnnt 4.502037 lr 0.00055498 rank 0
2022-12-04 04:55:27,142 DEBUG TRAIN Batch 9/6100 loss 16.272640 loss_att 21.312954 loss_ctc 32.468109 loss_rnnt 13.105182 lr 0.00055496 rank 1
2022-12-04 04:55:27,144 DEBUG TRAIN Batch 9/6100 loss 13.889565 loss_att 20.085615 loss_ctc 24.167667 loss_rnnt 11.279942 lr 0.00055517 rank 7
2022-12-04 04:55:27,148 DEBUG TRAIN Batch 9/6100 loss 10.548635 loss_att 13.109806 loss_ctc 17.652905 loss_rnnt 9.089166 lr 0.00055492 rank 2
2022-12-04 04:55:27,151 DEBUG TRAIN Batch 9/6100 loss 52.361404 loss_att 54.078583 loss_ctc 83.297401 loss_rnnt 47.893166 lr 0.00055509 rank 4
2022-12-04 04:56:39,416 DEBUG TRAIN Batch 9/6200 loss 12.370975 loss_att 16.846539 loss_ctc 22.292772 loss_rnnt 10.152956 lr 0.00055462 rank 1
2022-12-04 04:56:39,428 DEBUG TRAIN Batch 9/6200 loss 9.641308 loss_att 13.495567 loss_ctc 18.991423 loss_rnnt 7.623775 lr 0.00055466 rank 3
2022-12-04 04:56:39,429 DEBUG TRAIN Batch 9/6200 loss 13.015034 loss_att 17.457779 loss_ctc 22.194412 loss_rnnt 10.902567 lr 0.00055464 rank 0
2022-12-04 04:56:39,432 DEBUG TRAIN Batch 9/6200 loss 23.104500 loss_att 23.481138 loss_ctc 37.957775 loss_rnnt 21.048735 lr 0.00055474 rank 5
2022-12-04 04:56:39,433 DEBUG TRAIN Batch 9/6200 loss 20.538958 loss_att 25.459530 loss_ctc 39.434570 loss_rnnt 17.035427 lr 0.00055475 rank 4
2022-12-04 04:56:39,436 DEBUG TRAIN Batch 9/6200 loss 22.642120 loss_att 26.974785 loss_ctc 38.113148 loss_rnnt 19.712784 lr 0.00055479 rank 6
2022-12-04 04:56:39,437 DEBUG TRAIN Batch 9/6200 loss 7.946631 loss_att 12.373625 loss_ctc 18.723608 loss_rnnt 5.624302 lr 0.00055457 rank 2
2022-12-04 04:56:39,438 DEBUG TRAIN Batch 9/6200 loss 10.350191 loss_att 14.552723 loss_ctc 18.068296 loss_rnnt 8.480603 lr 0.00055483 rank 7
2022-12-04 04:57:51,313 DEBUG TRAIN Batch 9/6300 loss 11.574229 loss_att 12.250115 loss_ctc 18.635527 loss_rnnt 10.497545 lr 0.00055445 rank 6
2022-12-04 04:57:51,328 DEBUG TRAIN Batch 9/6300 loss 6.480558 loss_att 10.711698 loss_ctc 12.353989 loss_rnnt 4.851206 lr 0.00055432 rank 3
2022-12-04 04:57:51,329 DEBUG TRAIN Batch 9/6300 loss 16.183500 loss_att 16.810406 loss_ctc 26.280073 loss_rnnt 14.711908 lr 0.00055423 rank 2
2022-12-04 04:57:51,333 DEBUG TRAIN Batch 9/6300 loss 14.062733 loss_att 15.860455 loss_ctc 25.912739 loss_rnnt 12.123187 lr 0.00055440 rank 5
2022-12-04 04:57:51,334 DEBUG TRAIN Batch 9/6300 loss 12.171857 loss_att 11.850328 loss_ctc 16.003164 loss_rnnt 11.725321 lr 0.00055449 rank 7
2022-12-04 04:57:51,336 DEBUG TRAIN Batch 9/6300 loss 20.287172 loss_att 20.400482 loss_ctc 28.213434 loss_rnnt 19.207674 lr 0.00055429 rank 0
2022-12-04 04:57:51,338 DEBUG TRAIN Batch 9/6300 loss 15.652631 loss_att 19.331062 loss_ctc 24.615589 loss_rnnt 13.721884 lr 0.00055441 rank 4
2022-12-04 04:57:51,340 DEBUG TRAIN Batch 9/6300 loss 21.888599 loss_att 23.776413 loss_ctc 31.401371 loss_rnnt 20.242668 lr 0.00055428 rank 1
2022-12-04 04:59:05,639 DEBUG TRAIN Batch 9/6400 loss 17.725368 loss_att 19.052618 loss_ctc 27.974987 loss_rnnt 16.093304 lr 0.00055407 rank 4
2022-12-04 04:59:05,646 DEBUG TRAIN Batch 9/6400 loss 10.412882 loss_att 13.658309 loss_ctc 16.196701 loss_rnnt 8.992621 lr 0.00055415 rank 7
2022-12-04 04:59:05,648 DEBUG TRAIN Batch 9/6400 loss 14.042407 loss_att 16.803848 loss_ctc 16.934797 loss_rnnt 13.104467 lr 0.00055389 rank 2
2022-12-04 04:59:05,649 DEBUG TRAIN Batch 9/6400 loss 10.013232 loss_att 16.012875 loss_ctc 19.272226 loss_rnnt 7.578771 lr 0.00055394 rank 1
2022-12-04 04:59:05,649 DEBUG TRAIN Batch 9/6400 loss 10.740021 loss_att 11.766422 loss_ctc 15.268703 loss_rnnt 9.930916 lr 0.00055411 rank 6
2022-12-04 04:59:05,653 DEBUG TRAIN Batch 9/6400 loss 15.431964 loss_att 18.651764 loss_ctc 25.946831 loss_rnnt 13.386022 lr 0.00055398 rank 3
2022-12-04 04:59:05,654 DEBUG TRAIN Batch 9/6400 loss 18.346546 loss_att 19.102285 loss_ctc 27.450134 loss_rnnt 16.981586 lr 0.00055395 rank 0
2022-12-04 04:59:05,690 DEBUG TRAIN Batch 9/6400 loss 7.668622 loss_att 14.997992 loss_ctc 15.109703 loss_rnnt 5.210604 lr 0.00055406 rank 5
2022-12-04 05:00:17,543 DEBUG TRAIN Batch 9/6500 loss 17.171862 loss_att 24.894222 loss_ctc 33.485382 loss_rnnt 13.452253 lr 0.00055377 rank 6
2022-12-04 05:00:17,545 DEBUG TRAIN Batch 9/6500 loss 15.368932 loss_att 17.800434 loss_ctc 24.918392 loss_rnnt 13.609369 lr 0.00055381 rank 7
2022-12-04 05:00:17,546 DEBUG TRAIN Batch 9/6500 loss 13.077950 loss_att 20.831955 loss_ctc 18.706442 loss_rnnt 10.776683 lr 0.00055364 rank 3
2022-12-04 05:00:17,550 DEBUG TRAIN Batch 9/6500 loss 10.801262 loss_att 12.335602 loss_ctc 15.399593 loss_rnnt 9.881283 lr 0.00055360 rank 1
2022-12-04 05:00:17,553 DEBUG TRAIN Batch 9/6500 loss 15.375996 loss_att 22.867193 loss_ctc 33.895271 loss_rnnt 11.408519 lr 0.00055361 rank 0
2022-12-04 05:00:17,553 DEBUG TRAIN Batch 9/6500 loss 6.611222 loss_att 11.198120 loss_ctc 18.377060 loss_rnnt 4.125063 lr 0.00055372 rank 5
2022-12-04 05:00:17,554 DEBUG TRAIN Batch 9/6500 loss 10.141541 loss_att 13.787962 loss_ctc 18.715996 loss_rnnt 8.268995 lr 0.00055355 rank 2
2022-12-04 05:00:17,556 DEBUG TRAIN Batch 9/6500 loss 17.739429 loss_att 27.822176 loss_ctc 31.434986 loss_rnnt 13.896805 lr 0.00055373 rank 4
2022-12-04 05:01:29,566 DEBUG TRAIN Batch 9/6600 loss 13.345209 loss_att 17.951706 loss_ctc 23.585327 loss_rnnt 11.058561 lr 0.00055321 rank 2
2022-12-04 05:01:29,568 DEBUG TRAIN Batch 9/6600 loss 15.253518 loss_att 18.337133 loss_ctc 25.832703 loss_rnnt 13.226236 lr 0.00055343 rank 6
2022-12-04 05:01:29,568 DEBUG TRAIN Batch 9/6600 loss 11.412087 loss_att 17.003975 loss_ctc 19.886320 loss_rnnt 9.163813 lr 0.00055330 rank 3
2022-12-04 05:01:29,570 DEBUG TRAIN Batch 9/6600 loss 4.603158 loss_att 8.330474 loss_ctc 9.304620 loss_rnnt 3.230834 lr 0.00055338 rank 5
2022-12-04 05:01:29,570 DEBUG TRAIN Batch 9/6600 loss 11.243465 loss_att 16.437120 loss_ctc 19.514832 loss_rnnt 9.101887 lr 0.00055328 rank 0
2022-12-04 05:01:29,571 DEBUG TRAIN Batch 9/6600 loss 10.016895 loss_att 15.174131 loss_ctc 15.183661 loss_rnnt 8.296546 lr 0.00055326 rank 1
2022-12-04 05:01:29,572 DEBUG TRAIN Batch 9/6600 loss 16.505016 loss_att 21.002026 loss_ctc 24.689730 loss_rnnt 14.514318 lr 0.00055347 rank 7
2022-12-04 05:01:29,575 DEBUG TRAIN Batch 9/6600 loss 14.588755 loss_att 17.841949 loss_ctc 17.742109 loss_rnnt 13.517669 lr 0.00055339 rank 4
2022-12-04 05:02:43,103 DEBUG TRAIN Batch 9/6700 loss 6.746136 loss_att 12.046832 loss_ctc 14.725746 loss_rnnt 4.622048 lr 0.00055305 rank 5
2022-12-04 05:02:43,118 DEBUG TRAIN Batch 9/6700 loss 18.314632 loss_att 22.294064 loss_ctc 27.176018 loss_rnnt 16.337227 lr 0.00055309 rank 6
2022-12-04 05:02:43,122 DEBUG TRAIN Batch 9/6700 loss 25.243282 loss_att 27.474554 loss_ctc 38.218636 loss_rnnt 23.066982 lr 0.00055313 rank 7
2022-12-04 05:02:43,124 DEBUG TRAIN Batch 9/6700 loss 17.773386 loss_att 19.855469 loss_ctc 26.655033 loss_rnnt 16.172749 lr 0.00055296 rank 3
2022-12-04 05:02:43,127 DEBUG TRAIN Batch 9/6700 loss 13.870411 loss_att 16.027184 loss_ctc 19.230803 loss_rnnt 12.724338 lr 0.00055305 rank 4
2022-12-04 05:02:43,130 DEBUG TRAIN Batch 9/6700 loss 6.555202 loss_att 12.240757 loss_ctc 15.848890 loss_rnnt 4.178934 lr 0.00055294 rank 0
2022-12-04 05:02:43,149 DEBUG TRAIN Batch 9/6700 loss 8.146582 loss_att 13.369449 loss_ctc 17.113449 loss_rnnt 5.906425 lr 0.00055292 rank 1
2022-12-04 05:02:43,190 DEBUG TRAIN Batch 9/6700 loss 10.877847 loss_att 11.902642 loss_ctc 17.380556 loss_rnnt 9.805860 lr 0.00055288 rank 2
2022-12-04 05:03:55,825 DEBUG TRAIN Batch 9/6800 loss 27.922016 loss_att 30.140356 loss_ctc 42.149307 loss_rnnt 25.581375 lr 0.00055260 rank 0
2022-12-04 05:03:55,827 DEBUG TRAIN Batch 9/6800 loss 14.145597 loss_att 17.974163 loss_ctc 25.525860 loss_rnnt 11.862516 lr 0.00055271 rank 5
2022-12-04 05:03:55,827 DEBUG TRAIN Batch 9/6800 loss 8.825327 loss_att 13.038275 loss_ctc 16.390366 loss_rnnt 6.974066 lr 0.00055258 rank 1
2022-12-04 05:03:55,827 DEBUG TRAIN Batch 9/6800 loss 15.594615 loss_att 18.570410 loss_ctc 27.183588 loss_rnnt 13.454259 lr 0.00055263 rank 3
2022-12-04 05:03:55,832 DEBUG TRAIN Batch 9/6800 loss 20.373451 loss_att 23.192516 loss_ctc 35.986706 loss_rnnt 17.727871 lr 0.00055275 rank 6
2022-12-04 05:03:55,836 DEBUG TRAIN Batch 9/6800 loss 15.375480 loss_att 19.294376 loss_ctc 28.315353 loss_rnnt 12.866384 lr 0.00055271 rank 4
2022-12-04 05:03:55,838 DEBUG TRAIN Batch 9/6800 loss 7.751170 loss_att 11.087506 loss_ctc 13.933397 loss_rnnt 6.259605 lr 0.00055279 rank 7
2022-12-04 05:03:55,878 DEBUG TRAIN Batch 9/6800 loss 25.473469 loss_att 31.646019 loss_ctc 50.594757 loss_rnnt 20.889452 lr 0.00055254 rank 2
2022-12-04 05:05:07,122 DEBUG TRAIN Batch 9/6900 loss 14.096624 loss_att 16.254555 loss_ctc 18.888929 loss_rnnt 13.026064 lr 0.00055242 rank 6
2022-12-04 05:05:07,123 DEBUG TRAIN Batch 9/6900 loss 7.773089 loss_att 11.394630 loss_ctc 13.596663 loss_rnnt 6.272305 lr 0.00055226 rank 0
2022-12-04 05:05:07,126 DEBUG TRAIN Batch 9/6900 loss 6.887043 loss_att 10.288704 loss_ctc 16.827852 loss_rnnt 4.881270 lr 0.00055225 rank 1
2022-12-04 05:05:07,132 DEBUG TRAIN Batch 9/6900 loss 15.703366 loss_att 17.740490 loss_ctc 23.943464 loss_rnnt 14.197262 lr 0.00055245 rank 7
2022-12-04 05:05:07,133 DEBUG TRAIN Batch 9/6900 loss 18.410685 loss_att 21.672489 loss_ctc 35.482014 loss_rnnt 15.482146 lr 0.00055229 rank 3
2022-12-04 05:05:07,134 DEBUG TRAIN Batch 9/6900 loss 17.954674 loss_att 19.855267 loss_ctc 26.689100 loss_rnnt 16.409966 lr 0.00055220 rank 2
2022-12-04 05:05:07,137 DEBUG TRAIN Batch 9/6900 loss 19.946274 loss_att 22.442221 loss_ctc 31.601294 loss_rnnt 17.893082 lr 0.00055237 rank 4
2022-12-04 05:05:07,175 DEBUG TRAIN Batch 9/6900 loss 16.468199 loss_att 21.666771 loss_ctc 36.991760 loss_rnnt 12.692009 lr 0.00055237 rank 5
2022-12-04 05:06:19,862 DEBUG TRAIN Batch 9/7000 loss 9.641992 loss_att 10.139971 loss_ctc 14.777159 loss_rnnt 8.857707 lr 0.00055208 rank 6
2022-12-04 05:06:19,862 DEBUG TRAIN Batch 9/7000 loss 18.483704 loss_att 19.612858 loss_ctc 21.830225 loss_rnnt 17.811670 lr 0.00055191 rank 1
2022-12-04 05:06:19,863 DEBUG TRAIN Batch 9/7000 loss 24.355759 loss_att 25.439651 loss_ctc 42.456276 loss_rnnt 21.725574 lr 0.00055195 rank 3
2022-12-04 05:06:19,867 DEBUG TRAIN Batch 9/7000 loss 14.242602 loss_att 17.869610 loss_ctc 25.559254 loss_rnnt 12.008314 lr 0.00055193 rank 0
2022-12-04 05:06:19,870 DEBUG TRAIN Batch 9/7000 loss 8.215779 loss_att 8.527843 loss_ctc 11.498141 loss_rnnt 7.715718 lr 0.00055203 rank 5
2022-12-04 05:06:19,873 DEBUG TRAIN Batch 9/7000 loss 20.821026 loss_att 24.107061 loss_ctc 35.208946 loss_rnnt 18.245428 lr 0.00055212 rank 7
2022-12-04 05:06:19,891 DEBUG TRAIN Batch 9/7000 loss 9.670172 loss_att 12.224493 loss_ctc 11.132926 loss_rnnt 8.964273 lr 0.00055186 rank 2
2022-12-04 05:06:19,926 DEBUG TRAIN Batch 9/7000 loss 7.709601 loss_att 10.135118 loss_ctc 12.334246 loss_rnnt 6.607878 lr 0.00055204 rank 4
2022-12-04 05:07:37,023 DEBUG TRAIN Batch 9/7100 loss 14.902670 loss_att 14.555878 loss_ctc 20.401665 loss_rnnt 14.238829 lr 0.00055162 rank 3
2022-12-04 05:07:37,024 DEBUG TRAIN Batch 9/7100 loss 16.122910 loss_att 17.112072 loss_ctc 21.733501 loss_rnnt 15.176996 lr 0.00055170 rank 5
2022-12-04 05:07:37,027 DEBUG TRAIN Batch 9/7100 loss 5.787022 loss_att 7.992579 loss_ctc 9.991268 loss_rnnt 4.785345 lr 0.00055178 rank 7
2022-12-04 05:07:37,029 DEBUG TRAIN Batch 9/7100 loss 19.257069 loss_att 22.230236 loss_ctc 26.738842 loss_rnnt 17.664864 lr 0.00055159 rank 0
2022-12-04 05:07:37,033 DEBUG TRAIN Batch 9/7100 loss 31.244179 loss_att 29.876617 loss_ctc 40.126587 loss_rnnt 30.333368 lr 0.00055157 rank 1
2022-12-04 05:07:37,061 DEBUG TRAIN Batch 9/7100 loss 12.168503 loss_att 15.759800 loss_ctc 17.308292 loss_rnnt 10.764938 lr 0.00055174 rank 6
2022-12-04 05:07:37,064 DEBUG TRAIN Batch 9/7100 loss 11.492564 loss_att 16.502201 loss_ctc 21.581379 loss_rnnt 9.145461 lr 0.00055153 rank 2
2022-12-04 05:07:37,089 DEBUG TRAIN Batch 9/7100 loss 12.948851 loss_att 18.492495 loss_ctc 25.872616 loss_rnnt 10.116953 lr 0.00055170 rank 4
2022-12-04 05:08:49,008 DEBUG TRAIN Batch 9/7200 loss 7.734165 loss_att 12.174149 loss_ctc 13.111948 loss_rnnt 6.129130 lr 0.00055124 rank 1
2022-12-04 05:08:49,014 DEBUG TRAIN Batch 9/7200 loss 11.587519 loss_att 15.930475 loss_ctc 17.167595 loss_rnnt 9.974917 lr 0.00055141 rank 6
2022-12-04 05:08:49,016 DEBUG TRAIN Batch 9/7200 loss 9.887599 loss_att 16.318577 loss_ctc 17.930931 loss_rnnt 7.528958 lr 0.00055119 rank 2
2022-12-04 05:08:49,018 DEBUG TRAIN Batch 9/7200 loss 9.590941 loss_att 12.151489 loss_ctc 12.911334 loss_rnnt 8.636112 lr 0.00055128 rank 3
2022-12-04 05:08:49,019 DEBUG TRAIN Batch 9/7200 loss 18.577404 loss_att 21.459204 loss_ctc 27.778175 loss_rnnt 16.774275 lr 0.00055125 rank 0
2022-12-04 05:08:49,021 DEBUG TRAIN Batch 9/7200 loss 15.807405 loss_att 25.408707 loss_ctc 28.967163 loss_rnnt 12.132510 lr 0.00055136 rank 5
2022-12-04 05:08:49,028 DEBUG TRAIN Batch 9/7200 loss 18.312845 loss_att 23.294926 loss_ctc 31.677391 loss_rnnt 15.534489 lr 0.00055136 rank 4
2022-12-04 05:08:49,038 DEBUG TRAIN Batch 9/7200 loss 19.742779 loss_att 25.063101 loss_ctc 33.552147 loss_rnnt 16.837463 lr 0.00055145 rank 7
2022-12-04 05:10:00,026 DEBUG TRAIN Batch 9/7300 loss 15.039335 loss_att 20.779989 loss_ctc 28.269852 loss_rnnt 12.127135 lr 0.00055086 rank 2
2022-12-04 05:10:00,028 DEBUG TRAIN Batch 9/7300 loss 14.983921 loss_att 18.066813 loss_ctc 26.053871 loss_rnnt 12.891350 lr 0.00055107 rank 6
2022-12-04 05:10:00,029 DEBUG TRAIN Batch 9/7300 loss 9.994118 loss_att 14.969500 loss_ctc 18.563595 loss_rnnt 7.856444 lr 0.00055092 rank 0
2022-12-04 05:10:00,029 DEBUG TRAIN Batch 9/7300 loss 14.384661 loss_att 17.299948 loss_ctc 26.523771 loss_rnnt 12.183055 lr 0.00055090 rank 1
2022-12-04 05:10:00,031 DEBUG TRAIN Batch 9/7300 loss 16.841707 loss_att 18.768137 loss_ctc 27.575651 loss_rnnt 15.025229 lr 0.00055095 rank 3
2022-12-04 05:10:00,034 DEBUG TRAIN Batch 9/7300 loss 15.254704 loss_att 19.385536 loss_ctc 22.888474 loss_rnnt 13.410702 lr 0.00055111 rank 7
2022-12-04 05:10:00,039 DEBUG TRAIN Batch 9/7300 loss 47.696182 loss_att 51.127396 loss_ctc 63.345917 loss_rnnt 44.923309 lr 0.00055103 rank 4
2022-12-04 05:10:00,073 DEBUG TRAIN Batch 9/7300 loss 14.409315 loss_att 19.555096 loss_ctc 28.374643 loss_rnnt 11.518115 lr 0.00055103 rank 5
2022-12-04 05:11:12,693 DEBUG TRAIN Batch 9/7400 loss 10.943975 loss_att 14.821435 loss_ctc 21.001114 loss_rnnt 8.827533 lr 0.00055078 rank 7
2022-12-04 05:11:12,699 DEBUG TRAIN Batch 9/7400 loss 24.538670 loss_att 24.272936 loss_ctc 37.770828 loss_rnnt 22.827530 lr 0.00055061 rank 3
2022-12-04 05:11:12,707 DEBUG TRAIN Batch 9/7400 loss 14.074840 loss_att 17.940432 loss_ctc 22.950375 loss_rnnt 12.118317 lr 0.00055069 rank 5
2022-12-04 05:11:12,709 DEBUG TRAIN Batch 9/7400 loss 8.058678 loss_att 12.087856 loss_ctc 14.293729 loss_rnnt 6.421502 lr 0.00055059 rank 0
2022-12-04 05:11:12,710 DEBUG TRAIN Batch 9/7400 loss 17.268129 loss_att 20.561365 loss_ctc 28.673124 loss_rnnt 15.088815 lr 0.00055074 rank 6
2022-12-04 05:11:12,712 DEBUG TRAIN Batch 9/7400 loss 9.725706 loss_att 13.260982 loss_ctc 24.845383 loss_rnnt 7.002694 lr 0.00055070 rank 4
2022-12-04 05:11:12,727 DEBUG TRAIN Batch 9/7400 loss 16.877926 loss_att 18.840202 loss_ctc 30.656517 loss_rnnt 14.648325 lr 0.00055057 rank 1
2022-12-04 05:11:12,729 DEBUG TRAIN Batch 9/7400 loss 10.511563 loss_att 15.427798 loss_ctc 23.626673 loss_rnnt 7.779634 lr 0.00055053 rank 2
2022-12-04 05:12:26,522 DEBUG TRAIN Batch 9/7500 loss 19.742687 loss_att 22.701111 loss_ctc 36.158207 loss_rnnt 16.962267 lr 0.00055028 rank 3
2022-12-04 05:12:26,522 DEBUG TRAIN Batch 9/7500 loss 12.802609 loss_att 15.159389 loss_ctc 23.062943 loss_rnnt 10.963209 lr 0.00055041 rank 6
2022-12-04 05:12:26,529 DEBUG TRAIN Batch 9/7500 loss 12.630448 loss_att 17.991060 loss_ctc 24.367722 loss_rnnt 9.993357 lr 0.00055025 rank 0
2022-12-04 05:12:26,530 DEBUG TRAIN Batch 9/7500 loss 5.519843 loss_att 8.270086 loss_ctc 8.640442 loss_rnnt 4.553715 lr 0.00055036 rank 5
2022-12-04 05:12:26,532 DEBUG TRAIN Batch 9/7500 loss 12.793749 loss_att 15.503703 loss_ctc 20.400711 loss_rnnt 11.237495 lr 0.00055024 rank 1
2022-12-04 05:12:26,534 DEBUG TRAIN Batch 9/7500 loss 9.510160 loss_att 12.840706 loss_ctc 19.049088 loss_rnnt 7.572194 lr 0.00055019 rank 2
2022-12-04 05:12:26,536 DEBUG TRAIN Batch 9/7500 loss 13.815341 loss_att 15.915628 loss_ctc 24.595287 loss_rnnt 11.957957 lr 0.00055044 rank 7
2022-12-04 05:12:26,537 DEBUG TRAIN Batch 9/7500 loss 14.911960 loss_att 18.094093 loss_ctc 24.754681 loss_rnnt 12.963169 lr 0.00055036 rank 4
2022-12-04 05:13:38,294 DEBUG TRAIN Batch 9/7600 loss 9.162271 loss_att 11.771497 loss_ctc 14.745070 loss_rnnt 7.896052 lr 0.00055011 rank 7
2022-12-04 05:13:38,296 DEBUG TRAIN Batch 9/7600 loss 17.725845 loss_att 25.756165 loss_ctc 26.484104 loss_rnnt 14.952013 lr 0.00054986 rank 2
2022-12-04 05:13:38,303 DEBUG TRAIN Batch 9/7600 loss 8.339024 loss_att 8.177847 loss_ctc 13.102854 loss_rnnt 7.736082 lr 0.00055003 rank 5
2022-12-04 05:13:38,307 DEBUG TRAIN Batch 9/7600 loss 19.358393 loss_att 19.137539 loss_ctc 30.650375 loss_rnnt 17.896967 lr 0.00054992 rank 0
2022-12-04 05:13:38,308 DEBUG TRAIN Batch 9/7600 loss 12.897276 loss_att 17.701181 loss_ctc 21.734838 loss_rnnt 10.758154 lr 0.00054995 rank 3
2022-12-04 05:13:38,309 DEBUG TRAIN Batch 9/7600 loss 9.580537 loss_att 12.140211 loss_ctc 15.840897 loss_rnnt 8.233887 lr 0.00055007 rank 6
2022-12-04 05:13:38,309 DEBUG TRAIN Batch 9/7600 loss 16.626350 loss_att 20.333229 loss_ctc 28.608377 loss_rnnt 14.287372 lr 0.00055003 rank 4
2022-12-04 05:13:38,355 DEBUG TRAIN Batch 9/7600 loss 10.126789 loss_att 14.458642 loss_ctc 17.568396 loss_rnnt 8.268204 lr 0.00054990 rank 1
2022-12-04 05:14:50,040 DEBUG TRAIN Batch 9/7700 loss 12.045115 loss_att 14.495625 loss_ctc 24.120846 loss_rnnt 9.944915 lr 0.00054957 rank 1
2022-12-04 05:14:50,044 DEBUG TRAIN Batch 9/7700 loss 11.863315 loss_att 15.287055 loss_ctc 21.399565 loss_rnnt 9.907066 lr 0.00054974 rank 6
2022-12-04 05:14:50,047 DEBUG TRAIN Batch 9/7700 loss 8.733417 loss_att 12.973244 loss_ctc 19.225330 loss_rnnt 6.486529 lr 0.00054959 rank 0
2022-12-04 05:14:50,049 DEBUG TRAIN Batch 9/7700 loss 13.420819 loss_att 17.499622 loss_ctc 28.543921 loss_rnnt 10.588644 lr 0.00054969 rank 5
2022-12-04 05:14:50,052 DEBUG TRAIN Batch 9/7700 loss 14.703465 loss_att 16.938141 loss_ctc 23.830112 loss_rnnt 13.039644 lr 0.00054961 rank 3
2022-12-04 05:14:50,057 DEBUG TRAIN Batch 9/7700 loss 14.871929 loss_att 17.598156 loss_ctc 27.476965 loss_rnnt 12.646011 lr 0.00054953 rank 2
2022-12-04 05:14:50,060 DEBUG TRAIN Batch 9/7700 loss 10.779864 loss_att 11.605477 loss_ctc 17.134140 loss_rnnt 9.767505 lr 0.00054970 rank 4
2022-12-04 05:14:50,099 DEBUG TRAIN Batch 9/7700 loss 6.835524 loss_att 11.317560 loss_ctc 12.761309 loss_rnnt 5.149012 lr 0.00054978 rank 7
2022-12-04 05:16:03,723 DEBUG TRAIN Batch 9/7800 loss 13.716188 loss_att 21.206394 loss_ctc 31.211945 loss_rnnt 9.885380 lr 0.00054928 rank 3
2022-12-04 05:16:03,723 DEBUG TRAIN Batch 9/7800 loss 15.208079 loss_att 18.685970 loss_ctc 20.462326 loss_rnnt 13.811934 lr 0.00054925 rank 0
2022-12-04 05:16:03,726 DEBUG TRAIN Batch 9/7800 loss 11.506472 loss_att 16.891064 loss_ctc 20.148537 loss_rnnt 9.277277 lr 0.00054920 rank 2
2022-12-04 05:16:03,726 DEBUG TRAIN Batch 9/7800 loss 9.411185 loss_att 12.480530 loss_ctc 10.030337 loss_rnnt 8.714763 lr 0.00054941 rank 6
2022-12-04 05:16:03,729 DEBUG TRAIN Batch 9/7800 loss 10.381265 loss_att 11.705029 loss_ctc 16.346500 loss_rnnt 9.321147 lr 0.00054924 rank 1
2022-12-04 05:16:03,729 DEBUG TRAIN Batch 9/7800 loss 18.107210 loss_att 19.004009 loss_ctc 34.109661 loss_rnnt 15.794189 lr 0.00054944 rank 7
2022-12-04 05:16:03,731 DEBUG TRAIN Batch 9/7800 loss 19.355282 loss_att 23.462828 loss_ctc 32.739155 loss_rnnt 16.749258 lr 0.00054936 rank 5
2022-12-04 05:16:03,733 DEBUG TRAIN Batch 9/7800 loss 11.101295 loss_att 17.196386 loss_ctc 21.089676 loss_rnnt 8.550491 lr 0.00054936 rank 4
2022-12-04 05:17:16,614 DEBUG TRAIN Batch 9/7900 loss 11.830923 loss_att 15.637501 loss_ctc 23.279331 loss_rnnt 9.543154 lr 0.00054891 rank 1
2022-12-04 05:17:16,618 DEBUG TRAIN Batch 9/7900 loss 8.434074 loss_att 15.036294 loss_ctc 19.117077 loss_rnnt 5.689229 lr 0.00054886 rank 2
2022-12-04 05:17:16,618 DEBUG TRAIN Batch 9/7900 loss 7.635531 loss_att 11.658743 loss_ctc 11.362117 loss_rnnt 6.334011 lr 0.00054908 rank 6
2022-12-04 05:17:16,621 DEBUG TRAIN Batch 9/7900 loss 10.480377 loss_att 12.356091 loss_ctc 17.653580 loss_rnnt 9.148808 lr 0.00054911 rank 7
2022-12-04 05:17:16,624 DEBUG TRAIN Batch 9/7900 loss 17.812469 loss_att 20.422798 loss_ctc 26.612898 loss_rnnt 16.117012 lr 0.00054892 rank 0
2022-12-04 05:17:16,623 DEBUG TRAIN Batch 9/7900 loss 5.385337 loss_att 7.780474 loss_ctc 8.766392 loss_rnnt 4.455503 lr 0.00054903 rank 5
2022-12-04 05:17:16,623 DEBUG TRAIN Batch 9/7900 loss 8.764013 loss_att 15.012957 loss_ctc 17.749111 loss_rnnt 6.316212 lr 0.00054903 rank 4
2022-12-04 05:17:16,632 DEBUG TRAIN Batch 9/7900 loss 15.490399 loss_att 21.373672 loss_ctc 25.964138 loss_rnnt 12.917246 lr 0.00054895 rank 3
2022-12-04 05:18:29,226 DEBUG TRAIN Batch 9/8000 loss 23.292322 loss_att 28.016712 loss_ctc 49.450966 loss_rnnt 18.859625 lr 0.00054858 rank 1
2022-12-04 05:18:29,229 DEBUG TRAIN Batch 9/8000 loss 18.206741 loss_att 21.493595 loss_ctc 30.186453 loss_rnnt 15.952075 lr 0.00054870 rank 4
2022-12-04 05:18:29,229 DEBUG TRAIN Batch 9/8000 loss 27.637659 loss_att 30.019161 loss_ctc 44.315117 loss_rnnt 24.937696 lr 0.00054870 rank 5
2022-12-04 05:18:29,243 DEBUG TRAIN Batch 9/8000 loss 11.066800 loss_att 15.468227 loss_ctc 18.237577 loss_rnnt 9.230411 lr 0.00054875 rank 6
2022-12-04 05:18:29,244 DEBUG TRAIN Batch 9/8000 loss 41.814674 loss_att 44.714638 loss_ctc 56.447563 loss_rnnt 39.283630 lr 0.00054859 rank 0
2022-12-04 05:18:29,246 DEBUG TRAIN Batch 9/8000 loss 12.523005 loss_att 13.235022 loss_ctc 25.226246 loss_rnnt 10.686836 lr 0.00054862 rank 3
2022-12-04 05:18:29,248 DEBUG TRAIN Batch 9/8000 loss 13.111752 loss_att 16.295164 loss_ctc 20.298883 loss_rnnt 11.516785 lr 0.00054878 rank 7
2022-12-04 05:18:29,294 DEBUG TRAIN Batch 9/8000 loss 16.923468 loss_att 21.301609 loss_ctc 30.707020 loss_rnnt 14.210031 lr 0.00054853 rank 2
2022-12-04 05:19:41,100 DEBUG TRAIN Batch 9/8100 loss 27.840620 loss_att 30.470352 loss_ctc 47.607395 loss_rnnt 24.679104 lr 0.00054826 rank 0
2022-12-04 05:19:41,100 DEBUG TRAIN Batch 9/8100 loss 14.864207 loss_att 16.490337 loss_ctc 25.431414 loss_rnnt 13.130020 lr 0.00054845 rank 7
2022-12-04 05:19:41,101 DEBUG TRAIN Batch 9/8100 loss 20.115469 loss_att 22.981396 loss_ctc 31.452080 loss_rnnt 18.030733 lr 0.00054842 rank 6
2022-12-04 05:19:41,102 DEBUG TRAIN Batch 9/8100 loss 17.141304 loss_att 20.047249 loss_ctc 31.964079 loss_rnnt 14.583744 lr 0.00054825 rank 1
2022-12-04 05:19:41,104 DEBUG TRAIN Batch 9/8100 loss 5.424392 loss_att 8.227555 loss_ctc 10.067596 loss_rnnt 4.244666 lr 0.00054837 rank 5
2022-12-04 05:19:41,108 DEBUG TRAIN Batch 9/8100 loss 7.773988 loss_att 11.734167 loss_ctc 21.466423 loss_rnnt 5.156293 lr 0.00054837 rank 4
2022-12-04 05:19:41,108 DEBUG TRAIN Batch 9/8100 loss 13.629087 loss_att 18.325535 loss_ctc 25.494627 loss_rnnt 11.107726 lr 0.00054820 rank 2
2022-12-04 05:19:41,112 DEBUG TRAIN Batch 9/8100 loss 18.722757 loss_att 20.832291 loss_ctc 31.746384 loss_rnnt 16.564367 lr 0.00054829 rank 3
2022-12-04 05:20:53,726 DEBUG TRAIN Batch 9/8200 loss 11.876448 loss_att 16.323690 loss_ctc 24.591782 loss_rnnt 9.291622 lr 0.00054809 rank 6
2022-12-04 05:20:53,730 DEBUG TRAIN Batch 9/8200 loss 9.398305 loss_att 11.768393 loss_ctc 22.075310 loss_rnnt 7.234020 lr 0.00054793 rank 0
2022-12-04 05:20:53,731 DEBUG TRAIN Batch 9/8200 loss 9.135242 loss_att 12.187057 loss_ctc 14.993282 loss_rnnt 7.743807 lr 0.00054792 rank 1
2022-12-04 05:20:53,734 DEBUG TRAIN Batch 9/8200 loss 11.328526 loss_att 14.501677 loss_ctc 14.733887 loss_rnnt 10.239848 lr 0.00054804 rank 5
2022-12-04 05:20:53,735 DEBUG TRAIN Batch 9/8200 loss 12.902293 loss_att 17.391581 loss_ctc 22.406115 loss_rnnt 10.737259 lr 0.00054804 rank 4
2022-12-04 05:20:53,737 DEBUG TRAIN Batch 9/8200 loss 13.950254 loss_att 16.326868 loss_ctc 25.422615 loss_rnnt 11.945285 lr 0.00054796 rank 3
2022-12-04 05:20:53,742 DEBUG TRAIN Batch 9/8200 loss 12.610068 loss_att 14.728653 loss_ctc 15.563732 loss_rnnt 11.792529 lr 0.00054812 rank 7
2022-12-04 05:20:53,782 DEBUG TRAIN Batch 9/8200 loss 14.816004 loss_att 19.471342 loss_ctc 25.902678 loss_rnnt 12.406713 lr 0.00054787 rank 2
2022-12-04 05:22:05,433 DEBUG TRAIN Batch 9/8300 loss 18.257278 loss_att 22.057571 loss_ctc 27.788740 loss_rnnt 16.226357 lr 0.00054761 rank 0
2022-12-04 05:22:05,436 DEBUG TRAIN Batch 9/8300 loss 10.326330 loss_att 13.619919 loss_ctc 17.240936 loss_rnnt 8.745666 lr 0.00054763 rank 3
2022-12-04 05:22:05,438 DEBUG TRAIN Batch 9/8300 loss 8.324097 loss_att 11.868109 loss_ctc 12.703703 loss_rnnt 7.031347 lr 0.00054755 rank 2
2022-12-04 05:22:05,439 DEBUG TRAIN Batch 9/8300 loss 8.207912 loss_att 10.129667 loss_ctc 15.474901 loss_rnnt 6.854629 lr 0.00054776 rank 6
2022-12-04 05:22:05,439 DEBUG TRAIN Batch 9/8300 loss 12.367497 loss_att 15.289031 loss_ctc 12.454570 loss_rnnt 11.771582 lr 0.00054759 rank 1
2022-12-04 05:22:05,442 DEBUG TRAIN Batch 9/8300 loss 10.333783 loss_att 13.694500 loss_ctc 20.199512 loss_rnnt 8.346209 lr 0.00054771 rank 4
2022-12-04 05:22:05,447 DEBUG TRAIN Batch 9/8300 loss 19.002800 loss_att 23.375713 loss_ctc 30.197128 loss_rnnt 16.635639 lr 0.00054779 rank 7
2022-12-04 05:22:05,485 DEBUG TRAIN Batch 9/8300 loss 13.437178 loss_att 16.139076 loss_ctc 23.678656 loss_rnnt 11.531267 lr 0.00054771 rank 5
2022-12-04 05:22:53,289 DEBUG CV Batch 9/0 loss 2.550298 loss_att 2.476349 loss_ctc 3.919713 loss_rnnt 2.382499 history loss 2.455843 rank 5
2022-12-04 05:22:53,300 DEBUG CV Batch 9/0 loss 2.550298 loss_att 2.476349 loss_ctc 3.919713 loss_rnnt 2.382499 history loss 2.455843 rank 2
2022-12-04 05:22:53,302 DEBUG CV Batch 9/0 loss 2.550298 loss_att 2.476349 loss_ctc 3.919713 loss_rnnt 2.382499 history loss 2.455843 rank 4
2022-12-04 05:22:53,303 DEBUG CV Batch 9/0 loss 2.550298 loss_att 2.476349 loss_ctc 3.919713 loss_rnnt 2.382499 history loss 2.455843 rank 0
2022-12-04 05:22:53,303 DEBUG CV Batch 9/0 loss 2.550298 loss_att 2.476349 loss_ctc 3.919713 loss_rnnt 2.382499 history loss 2.455843 rank 7
2022-12-04 05:22:53,308 DEBUG CV Batch 9/0 loss 2.550298 loss_att 2.476349 loss_ctc 3.919713 loss_rnnt 2.382499 history loss 2.455843 rank 6
2022-12-04 05:22:53,308 DEBUG CV Batch 9/0 loss 2.550298 loss_att 2.476349 loss_ctc 3.919713 loss_rnnt 2.382499 history loss 2.455843 rank 1
2022-12-04 05:22:53,310 DEBUG CV Batch 9/0 loss 2.550298 loss_att 2.476349 loss_ctc 3.919713 loss_rnnt 2.382499 history loss 2.455843 rank 3
2022-12-04 05:23:04,470 DEBUG CV Batch 9/100 loss 7.464782 loss_att 9.324932 loss_ctc 12.860968 loss_rnnt 6.373260 history loss 4.056505 rank 5
2022-12-04 05:23:04,482 DEBUG CV Batch 9/100 loss 7.464782 loss_att 9.324932 loss_ctc 12.860968 loss_rnnt 6.373260 history loss 4.056505 rank 1
2022-12-04 05:23:04,569 DEBUG CV Batch 9/100 loss 7.464782 loss_att 9.324932 loss_ctc 12.860968 loss_rnnt 6.373260 history loss 4.056505 rank 7
2022-12-04 05:23:04,709 DEBUG CV Batch 9/100 loss 7.464782 loss_att 9.324932 loss_ctc 12.860968 loss_rnnt 6.373260 history loss 4.056505 rank 2
2022-12-04 05:23:04,736 DEBUG CV Batch 9/100 loss 7.464782 loss_att 9.324932 loss_ctc 12.860968 loss_rnnt 6.373260 history loss 4.056505 rank 4
2022-12-04 05:23:04,946 DEBUG CV Batch 9/100 loss 7.464782 loss_att 9.324932 loss_ctc 12.860968 loss_rnnt 6.373260 history loss 4.056505 rank 0
2022-12-04 05:23:05,056 DEBUG CV Batch 9/100 loss 7.464782 loss_att 9.324932 loss_ctc 12.860968 loss_rnnt 6.373260 history loss 4.056505 rank 6
2022-12-04 05:23:05,217 DEBUG CV Batch 9/100 loss 7.464782 loss_att 9.324932 loss_ctc 12.860968 loss_rnnt 6.373260 history loss 4.056505 rank 3
2022-12-04 05:23:18,036 DEBUG CV Batch 9/200 loss 10.835838 loss_att 16.568325 loss_ctc 17.935093 loss_rnnt 8.742774 history loss 4.724800 rank 5
2022-12-04 05:23:18,383 DEBUG CV Batch 9/200 loss 10.835838 loss_att 16.568325 loss_ctc 17.935093 loss_rnnt 8.742774 history loss 4.724800 rank 1
2022-12-04 05:23:18,422 DEBUG CV Batch 9/200 loss 10.835838 loss_att 16.568325 loss_ctc 17.935093 loss_rnnt 8.742774 history loss 4.724800 rank 2
2022-12-04 05:23:18,527 DEBUG CV Batch 9/200 loss 10.835838 loss_att 16.568325 loss_ctc 17.935093 loss_rnnt 8.742774 history loss 4.724800 rank 7
2022-12-04 05:23:18,657 DEBUG CV Batch 9/200 loss 10.835838 loss_att 16.568325 loss_ctc 17.935093 loss_rnnt 8.742774 history loss 4.724800 rank 4
2022-12-04 05:23:18,853 DEBUG CV Batch 9/200 loss 10.835838 loss_att 16.568325 loss_ctc 17.935093 loss_rnnt 8.742774 history loss 4.724800 rank 0
2022-12-04 05:23:18,985 DEBUG CV Batch 9/200 loss 10.835838 loss_att 16.568325 loss_ctc 17.935093 loss_rnnt 8.742774 history loss 4.724800 rank 6
2022-12-04 05:23:19,361 DEBUG CV Batch 9/200 loss 10.835838 loss_att 16.568325 loss_ctc 17.935093 loss_rnnt 8.742774 history loss 4.724800 rank 3
2022-12-04 05:23:29,892 DEBUG CV Batch 9/300 loss 3.758197 loss_att 5.691708 loss_ctc 8.834228 loss_rnnt 2.694690 history loss 4.806332 rank 5
2022-12-04 05:23:30,091 DEBUG CV Batch 9/300 loss 3.758197 loss_att 5.691708 loss_ctc 8.834228 loss_rnnt 2.694690 history loss 4.806332 rank 1
2022-12-04 05:23:30,491 DEBUG CV Batch 9/300 loss 3.758197 loss_att 5.691708 loss_ctc 8.834228 loss_rnnt 2.694690 history loss 4.806332 rank 7
2022-12-04 05:23:30,520 DEBUG CV Batch 9/300 loss 3.758197 loss_att 5.691708 loss_ctc 8.834228 loss_rnnt 2.694690 history loss 4.806332 rank 2
2022-12-04 05:23:30,577 DEBUG CV Batch 9/300 loss 3.758197 loss_att 5.691708 loss_ctc 8.834228 loss_rnnt 2.694690 history loss 4.806332 rank 4
2022-12-04 05:23:31,362 DEBUG CV Batch 9/300 loss 3.758197 loss_att 5.691708 loss_ctc 8.834228 loss_rnnt 2.694690 history loss 4.806332 rank 0
2022-12-04 05:23:31,544 DEBUG CV Batch 9/300 loss 3.758197 loss_att 5.691708 loss_ctc 8.834228 loss_rnnt 2.694690 history loss 4.806332 rank 6
2022-12-04 05:23:31,974 DEBUG CV Batch 9/300 loss 3.758197 loss_att 5.691708 loss_ctc 8.834228 loss_rnnt 2.694690 history loss 4.806332 rank 3
2022-12-04 05:23:41,733 DEBUG CV Batch 9/400 loss 14.772072 loss_att 66.353256 loss_ctc 17.863106 loss_rnnt 4.043697 history loss 5.799307 rank 1
2022-12-04 05:23:41,772 DEBUG CV Batch 9/400 loss 14.772072 loss_att 66.353256 loss_ctc 17.863106 loss_rnnt 4.043697 history loss 5.799307 rank 5
2022-12-04 05:23:42,409 DEBUG CV Batch 9/400 loss 14.772072 loss_att 66.353256 loss_ctc 17.863106 loss_rnnt 4.043697 history loss 5.799307 rank 7
2022-12-04 05:23:42,440 DEBUG CV Batch 9/400 loss 14.772072 loss_att 66.353256 loss_ctc 17.863106 loss_rnnt 4.043697 history loss 5.799307 rank 2
2022-12-04 05:23:42,478 DEBUG CV Batch 9/400 loss 14.772072 loss_att 66.353256 loss_ctc 17.863106 loss_rnnt 4.043697 history loss 5.799307 rank 4
2022-12-04 05:23:43,852 DEBUG CV Batch 9/400 loss 14.772072 loss_att 66.353256 loss_ctc 17.863106 loss_rnnt 4.043697 history loss 5.799307 rank 0
2022-12-04 05:23:43,978 DEBUG CV Batch 9/400 loss 14.772072 loss_att 66.353256 loss_ctc 17.863106 loss_rnnt 4.043697 history loss 5.799307 rank 6
2022-12-04 05:23:44,559 DEBUG CV Batch 9/400 loss 14.772072 loss_att 66.353256 loss_ctc 17.863106 loss_rnnt 4.043697 history loss 5.799307 rank 3
2022-12-04 05:23:51,890 DEBUG CV Batch 9/500 loss 8.716551 loss_att 9.458097 loss_ctc 11.119330 loss_rnnt 8.247870 history loss 6.554302 rank 1
2022-12-04 05:23:52,064 DEBUG CV Batch 9/500 loss 8.716551 loss_att 9.458097 loss_ctc 11.119330 loss_rnnt 8.247870 history loss 6.554302 rank 5
2022-12-04 05:23:52,652 DEBUG CV Batch 9/500 loss 8.716551 loss_att 9.458097 loss_ctc 11.119330 loss_rnnt 8.247870 history loss 6.554302 rank 4
2022-12-04 05:23:52,715 DEBUG CV Batch 9/500 loss 8.716551 loss_att 9.458097 loss_ctc 11.119330 loss_rnnt 8.247870 history loss 6.554302 rank 2
2022-12-04 05:23:53,257 DEBUG CV Batch 9/500 loss 8.716551 loss_att 9.458097 loss_ctc 11.119330 loss_rnnt 8.247870 history loss 6.554302 rank 7
2022-12-04 05:23:54,842 DEBUG CV Batch 9/500 loss 8.716551 loss_att 9.458097 loss_ctc 11.119330 loss_rnnt 8.247870 history loss 6.554302 rank 0
2022-12-04 05:23:54,845 DEBUG CV Batch 9/500 loss 8.716551 loss_att 9.458097 loss_ctc 11.119330 loss_rnnt 8.247870 history loss 6.554302 rank 6
2022-12-04 05:23:55,530 DEBUG CV Batch 9/500 loss 8.716551 loss_att 9.458097 loss_ctc 11.119330 loss_rnnt 8.247870 history loss 6.554302 rank 3
2022-12-04 05:24:04,281 DEBUG CV Batch 9/600 loss 8.432575 loss_att 8.805628 loss_ctc 11.901049 loss_rnnt 7.895502 history loss 7.468513 rank 5
2022-12-04 05:24:04,315 DEBUG CV Batch 9/600 loss 8.432575 loss_att 8.805628 loss_ctc 11.901049 loss_rnnt 7.895502 history loss 7.468513 rank 1
2022-12-04 05:24:04,735 DEBUG CV Batch 9/600 loss 8.432575 loss_att 8.805628 loss_ctc 11.901049 loss_rnnt 7.895502 history loss 7.468513 rank 4
2022-12-04 05:24:04,846 DEBUG CV Batch 9/600 loss 8.432575 loss_att 8.805628 loss_ctc 11.901049 loss_rnnt 7.895502 history loss 7.468513 rank 2
2022-12-04 05:24:05,322 DEBUG CV Batch 9/600 loss 8.432575 loss_att 8.805628 loss_ctc 11.901049 loss_rnnt 7.895502 history loss 7.468513 rank 7
2022-12-04 05:24:07,244 DEBUG CV Batch 9/600 loss 8.432575 loss_att 8.805628 loss_ctc 11.901049 loss_rnnt 7.895502 history loss 7.468513 rank 6
2022-12-04 05:24:07,470 DEBUG CV Batch 9/600 loss 8.432575 loss_att 8.805628 loss_ctc 11.901049 loss_rnnt 7.895502 history loss 7.468513 rank 0
2022-12-04 05:24:08,055 DEBUG CV Batch 9/600 loss 8.432575 loss_att 8.805628 loss_ctc 11.901049 loss_rnnt 7.895502 history loss 7.468513 rank 3
2022-12-04 05:24:15,975 DEBUG CV Batch 9/700 loss 12.277737 loss_att 30.632820 loss_ctc 22.925413 loss_rnnt 7.187030 history loss 8.042215 rank 4
2022-12-04 05:24:16,014 DEBUG CV Batch 9/700 loss 12.277737 loss_att 30.632820 loss_ctc 22.925413 loss_rnnt 7.187030 history loss 8.042215 rank 5
2022-12-04 05:24:16,074 DEBUG CV Batch 9/700 loss 12.277737 loss_att 30.632820 loss_ctc 22.925413 loss_rnnt 7.187030 history loss 8.042215 rank 2
2022-12-04 05:24:16,557 DEBUG CV Batch 9/700 loss 12.277737 loss_att 30.632820 loss_ctc 22.925413 loss_rnnt 7.187030 history loss 8.042215 rank 1
2022-12-04 05:24:16,572 DEBUG CV Batch 9/700 loss 12.277737 loss_att 30.632820 loss_ctc 22.925413 loss_rnnt 7.187030 history loss 8.042215 rank 7
2022-12-04 05:24:19,007 DEBUG CV Batch 9/700 loss 12.277737 loss_att 30.632820 loss_ctc 22.925413 loss_rnnt 7.187030 history loss 8.042215 rank 6
2022-12-04 05:24:19,380 DEBUG CV Batch 9/700 loss 12.277737 loss_att 30.632820 loss_ctc 22.925413 loss_rnnt 7.187030 history loss 8.042215 rank 0
2022-12-04 05:24:20,001 DEBUG CV Batch 9/700 loss 12.277737 loss_att 30.632820 loss_ctc 22.925413 loss_rnnt 7.187030 history loss 8.042215 rank 3
2022-12-04 05:24:27,805 DEBUG CV Batch 9/800 loss 10.204578 loss_att 11.362004 loss_ctc 16.986107 loss_rnnt 9.068890 history loss 7.509548 rank 5
2022-12-04 05:24:27,946 DEBUG CV Batch 9/800 loss 10.204578 loss_att 11.362004 loss_ctc 16.986107 loss_rnnt 9.068890 history loss 7.509548 rank 7
2022-12-04 05:24:28,144 DEBUG CV Batch 9/800 loss 10.204578 loss_att 11.362004 loss_ctc 16.986107 loss_rnnt 9.068890 history loss 7.509548 rank 2
2022-12-04 05:24:28,309 DEBUG CV Batch 9/800 loss 10.204578 loss_att 11.362004 loss_ctc 16.986107 loss_rnnt 9.068890 history loss 7.509548 rank 4
2022-12-04 05:24:28,699 DEBUG CV Batch 9/800 loss 10.204578 loss_att 11.362004 loss_ctc 16.986107 loss_rnnt 9.068890 history loss 7.509548 rank 1
2022-12-04 05:24:30,586 DEBUG CV Batch 9/800 loss 10.204578 loss_att 11.362004 loss_ctc 16.986107 loss_rnnt 9.068890 history loss 7.509548 rank 6
2022-12-04 05:24:31,017 DEBUG CV Batch 9/800 loss 10.204578 loss_att 11.362004 loss_ctc 16.986107 loss_rnnt 9.068890 history loss 7.509548 rank 0
2022-12-04 05:24:31,672 DEBUG CV Batch 9/800 loss 10.204578 loss_att 11.362004 loss_ctc 16.986107 loss_rnnt 9.068890 history loss 7.509548 rank 3
2022-12-04 05:24:41,531 DEBUG CV Batch 9/900 loss 12.698516 loss_att 16.255100 loss_ctc 22.185801 loss_rnnt 10.722228 history loss 7.330590 rank 5
2022-12-04 05:24:41,571 DEBUG CV Batch 9/900 loss 12.698516 loss_att 16.255100 loss_ctc 22.185801 loss_rnnt 10.722228 history loss 7.330590 rank 2
2022-12-04 05:24:41,572 DEBUG CV Batch 9/900 loss 12.698516 loss_att 16.255100 loss_ctc 22.185801 loss_rnnt 10.722228 history loss 7.330590 rank 7
2022-12-04 05:24:42,196 DEBUG CV Batch 9/900 loss 12.698516 loss_att 16.255100 loss_ctc 22.185801 loss_rnnt 10.722228 history loss 7.330590 rank 4
2022-12-04 05:24:42,263 DEBUG CV Batch 9/900 loss 12.698516 loss_att 16.255100 loss_ctc 22.185801 loss_rnnt 10.722228 history loss 7.330590 rank 1
2022-12-04 05:24:44,399 DEBUG CV Batch 9/900 loss 12.698516 loss_att 16.255100 loss_ctc 22.185801 loss_rnnt 10.722228 history loss 7.330590 rank 6
2022-12-04 05:24:45,007 DEBUG CV Batch 9/900 loss 12.698516 loss_att 16.255100 loss_ctc 22.185801 loss_rnnt 10.722228 history loss 7.330590 rank 0
2022-12-04 05:24:45,640 DEBUG CV Batch 9/900 loss 12.698516 loss_att 16.255100 loss_ctc 22.185801 loss_rnnt 10.722228 history loss 7.330590 rank 3
2022-12-04 05:24:53,431 DEBUG CV Batch 9/1000 loss 4.597394 loss_att 5.285859 loss_ctc 7.012841 loss_rnnt 4.137640 history loss 7.094409 rank 5
2022-12-04 05:24:53,683 DEBUG CV Batch 9/1000 loss 4.597394 loss_att 5.285859 loss_ctc 7.012841 loss_rnnt 4.137640 history loss 7.094409 rank 2
2022-12-04 05:24:53,780 DEBUG CV Batch 9/1000 loss 4.597394 loss_att 5.285859 loss_ctc 7.012841 loss_rnnt 4.137640 history loss 7.094409 rank 7
2022-12-04 05:24:54,179 DEBUG CV Batch 9/1000 loss 4.597394 loss_att 5.285859 loss_ctc 7.012841 loss_rnnt 4.137640 history loss 7.094409 rank 1
2022-12-04 05:24:54,338 DEBUG CV Batch 9/1000 loss 4.597394 loss_att 5.285859 loss_ctc 7.012841 loss_rnnt 4.137640 history loss 7.094409 rank 4
2022-12-04 05:24:57,094 DEBUG CV Batch 9/1000 loss 4.597394 loss_att 5.285859 loss_ctc 7.012841 loss_rnnt 4.137640 history loss 7.094409 rank 6
2022-12-04 05:24:57,826 DEBUG CV Batch 9/1000 loss 4.597394 loss_att 5.285859 loss_ctc 7.012841 loss_rnnt 4.137640 history loss 7.094409 rank 0
2022-12-04 05:24:58,609 DEBUG CV Batch 9/1000 loss 4.597394 loss_att 5.285859 loss_ctc 7.012841 loss_rnnt 4.137640 history loss 7.094409 rank 3
2022-12-04 05:25:05,257 DEBUG CV Batch 9/1100 loss 5.024785 loss_att 5.230403 loss_ctc 8.554128 loss_rnnt 4.513082 history loss 7.085698 rank 5
2022-12-04 05:25:05,635 DEBUG CV Batch 9/1100 loss 5.024785 loss_att 5.230403 loss_ctc 8.554128 loss_rnnt 4.513082 history loss 7.085698 rank 2
2022-12-04 05:25:05,740 DEBUG CV Batch 9/1100 loss 5.024785 loss_att 5.230403 loss_ctc 8.554128 loss_rnnt 4.513082 history loss 7.085698 rank 1
2022-12-04 05:25:05,744 DEBUG CV Batch 9/1100 loss 5.024785 loss_att 5.230403 loss_ctc 8.554128 loss_rnnt 4.513082 history loss 7.085698 rank 7
2022-12-04 05:25:06,214 DEBUG CV Batch 9/1100 loss 5.024785 loss_att 5.230403 loss_ctc 8.554128 loss_rnnt 4.513082 history loss 7.085698 rank 4
2022-12-04 05:25:09,458 DEBUG CV Batch 9/1100 loss 5.024785 loss_att 5.230403 loss_ctc 8.554128 loss_rnnt 4.513082 history loss 7.085698 rank 6
2022-12-04 05:25:10,276 DEBUG CV Batch 9/1100 loss 5.024785 loss_att 5.230403 loss_ctc 8.554128 loss_rnnt 4.513082 history loss 7.085698 rank 0
2022-12-04 05:25:11,220 DEBUG CV Batch 9/1100 loss 5.024785 loss_att 5.230403 loss_ctc 8.554128 loss_rnnt 4.513082 history loss 7.085698 rank 3
2022-12-04 05:25:15,510 DEBUG CV Batch 9/1200 loss 11.561073 loss_att 11.735878 loss_ctc 13.230397 loss_rnnt 11.303535 history loss 7.418437 rank 5
2022-12-04 05:25:16,118 DEBUG CV Batch 9/1200 loss 11.561073 loss_att 11.735878 loss_ctc 13.230397 loss_rnnt 11.303535 history loss 7.418437 rank 7
2022-12-04 05:25:16,375 DEBUG CV Batch 9/1200 loss 11.561073 loss_att 11.735878 loss_ctc 13.230397 loss_rnnt 11.303535 history loss 7.418437 rank 1
2022-12-04 05:25:16,472 DEBUG CV Batch 9/1200 loss 11.561073 loss_att 11.735878 loss_ctc 13.230397 loss_rnnt 11.303535 history loss 7.418437 rank 4
2022-12-04 05:25:16,524 DEBUG CV Batch 9/1200 loss 11.561073 loss_att 11.735878 loss_ctc 13.230397 loss_rnnt 11.303535 history loss 7.418437 rank 2
2022-12-04 05:25:20,402 DEBUG CV Batch 9/1200 loss 11.561073 loss_att 11.735878 loss_ctc 13.230397 loss_rnnt 11.303535 history loss 7.418437 rank 6
2022-12-04 05:25:21,412 DEBUG CV Batch 9/1200 loss 11.561073 loss_att 11.735878 loss_ctc 13.230397 loss_rnnt 11.303535 history loss 7.418437 rank 0
2022-12-04 05:25:22,497 DEBUG CV Batch 9/1200 loss 11.561073 loss_att 11.735878 loss_ctc 13.230397 loss_rnnt 11.303535 history loss 7.418437 rank 3
2022-12-04 05:25:27,304 DEBUG CV Batch 9/1300 loss 6.872438 loss_att 5.890564 loss_ctc 10.636154 loss_rnnt 6.566985 history loss 7.716332 rank 5
2022-12-04 05:25:28,145 DEBUG CV Batch 9/1300 loss 6.872438 loss_att 5.890564 loss_ctc 10.636154 loss_rnnt 6.566985 history loss 7.716332 rank 1
2022-12-04 05:25:28,287 DEBUG CV Batch 9/1300 loss 6.872438 loss_att 5.890564 loss_ctc 10.636154 loss_rnnt 6.566985 history loss 7.716332 rank 7
2022-12-04 05:25:28,461 DEBUG CV Batch 9/1300 loss 6.872438 loss_att 5.890564 loss_ctc 10.636154 loss_rnnt 6.566985 history loss 7.716332 rank 4
2022-12-04 05:25:28,604 DEBUG CV Batch 9/1300 loss 6.872438 loss_att 5.890564 loss_ctc 10.636154 loss_rnnt 6.566985 history loss 7.716332 rank 2
2022-12-04 05:25:32,771 DEBUG CV Batch 9/1300 loss 6.872438 loss_att 5.890564 loss_ctc 10.636154 loss_rnnt 6.566985 history loss 7.716332 rank 6
2022-12-04 05:25:34,108 DEBUG CV Batch 9/1300 loss 6.872438 loss_att 5.890564 loss_ctc 10.636154 loss_rnnt 6.566985 history loss 7.716332 rank 0
2022-12-04 05:25:35,135 DEBUG CV Batch 9/1300 loss 6.872438 loss_att 5.890564 loss_ctc 10.636154 loss_rnnt 6.566985 history loss 7.716332 rank 3
2022-12-04 05:25:38,743 DEBUG CV Batch 9/1400 loss 6.641721 loss_att 21.088543 loss_ctc 9.419619 loss_rnnt 3.381970 history loss 8.008342 rank 5
2022-12-04 05:25:39,382 DEBUG CV Batch 9/1400 loss 6.641721 loss_att 21.088543 loss_ctc 9.419619 loss_rnnt 3.381970 history loss 8.008342 rank 7
2022-12-04 05:25:39,555 DEBUG CV Batch 9/1400 loss 6.641721 loss_att 21.088543 loss_ctc 9.419619 loss_rnnt 3.381970 history loss 8.008342 rank 4
2022-12-04 05:25:39,728 DEBUG CV Batch 9/1400 loss 6.641721 loss_att 21.088543 loss_ctc 9.419619 loss_rnnt 3.381970 history loss 8.008342 rank 2
2022-12-04 05:25:39,964 DEBUG CV Batch 9/1400 loss 6.641721 loss_att 21.088543 loss_ctc 9.419619 loss_rnnt 3.381970 history loss 8.008342 rank 1
2022-12-04 05:25:44,315 DEBUG CV Batch 9/1400 loss 6.641721 loss_att 21.088543 loss_ctc 9.419619 loss_rnnt 3.381970 history loss 8.008342 rank 6
2022-12-04 05:25:45,941 DEBUG CV Batch 9/1400 loss 6.641721 loss_att 21.088543 loss_ctc 9.419619 loss_rnnt 3.381970 history loss 8.008342 rank 0
2022-12-04 05:25:47,099 DEBUG CV Batch 9/1400 loss 6.641721 loss_att 21.088543 loss_ctc 9.419619 loss_rnnt 3.381970 history loss 8.008342 rank 3
2022-12-04 05:25:50,724 DEBUG CV Batch 9/1500 loss 7.661223 loss_att 9.775554 loss_ctc 8.568455 loss_rnnt 7.117393 history loss 7.828428 rank 5
2022-12-04 05:25:50,996 DEBUG CV Batch 9/1500 loss 7.661223 loss_att 9.775554 loss_ctc 8.568455 loss_rnnt 7.117393 history loss 7.828428 rank 7
2022-12-04 05:25:51,156 DEBUG CV Batch 9/1500 loss 7.661223 loss_att 9.775554 loss_ctc 8.568455 loss_rnnt 7.117393 history loss 7.828428 rank 2
2022-12-04 05:25:51,200 DEBUG CV Batch 9/1500 loss 7.661223 loss_att 9.775554 loss_ctc 8.568455 loss_rnnt 7.117393 history loss 7.828428 rank 4
2022-12-04 05:25:52,208 DEBUG CV Batch 9/1500 loss 7.661223 loss_att 9.775554 loss_ctc 8.568455 loss_rnnt 7.117393 history loss 7.828428 rank 1
2022-12-04 05:25:56,277 DEBUG CV Batch 9/1500 loss 7.661223 loss_att 9.775554 loss_ctc 8.568455 loss_rnnt 7.117393 history loss 7.828428 rank 6
2022-12-04 05:25:57,998 DEBUG CV Batch 9/1500 loss 7.661223 loss_att 9.775554 loss_ctc 8.568455 loss_rnnt 7.117393 history loss 7.828428 rank 0
2022-12-04 05:25:59,120 DEBUG CV Batch 9/1500 loss 7.661223 loss_att 9.775554 loss_ctc 8.568455 loss_rnnt 7.117393 history loss 7.828428 rank 3
2022-12-04 05:26:04,054 DEBUG CV Batch 9/1600 loss 7.130192 loss_att 15.584965 loss_ctc 13.184748 loss_rnnt 4.631963 history loss 7.761851 rank 5
2022-12-04 05:26:04,182 DEBUG CV Batch 9/1600 loss 7.130192 loss_att 15.584965 loss_ctc 13.184748 loss_rnnt 4.631963 history loss 7.761851 rank 7
2022-12-04 05:26:04,814 DEBUG CV Batch 9/1600 loss 7.130192 loss_att 15.584965 loss_ctc 13.184748 loss_rnnt 4.631963 history loss 7.761851 rank 2
2022-12-04 05:26:05,196 DEBUG CV Batch 9/1600 loss 7.130192 loss_att 15.584965 loss_ctc 13.184748 loss_rnnt 4.631963 history loss 7.761851 rank 4
2022-12-04 05:26:05,405 DEBUG CV Batch 9/1600 loss 7.130192 loss_att 15.584965 loss_ctc 13.184748 loss_rnnt 4.631963 history loss 7.761851 rank 1
2022-12-04 05:26:09,727 DEBUG CV Batch 9/1600 loss 7.130192 loss_att 15.584965 loss_ctc 13.184748 loss_rnnt 4.631963 history loss 7.761851 rank 6
2022-12-04 05:26:11,627 DEBUG CV Batch 9/1600 loss 7.130192 loss_att 15.584965 loss_ctc 13.184748 loss_rnnt 4.631963 history loss 7.761851 rank 0
2022-12-04 05:26:12,787 DEBUG CV Batch 9/1600 loss 7.130192 loss_att 15.584965 loss_ctc 13.184748 loss_rnnt 4.631963 history loss 7.761851 rank 3
2022-12-04 05:26:16,448 DEBUG CV Batch 9/1700 loss 9.696867 loss_att 9.499880 loss_ctc 17.488110 loss_rnnt 8.697432 history loss 7.659079 rank 5
2022-12-04 05:26:16,691 DEBUG CV Batch 9/1700 loss 9.696867 loss_att 9.499880 loss_ctc 17.488110 loss_rnnt 8.697432 history loss 7.659079 rank 7
2022-12-04 05:26:17,710 DEBUG CV Batch 9/1700 loss 9.696867 loss_att 9.499880 loss_ctc 17.488110 loss_rnnt 8.697432 history loss 7.659079 rank 2
2022-12-04 05:26:17,778 DEBUG CV Batch 9/1700 loss 9.696867 loss_att 9.499880 loss_ctc 17.488110 loss_rnnt 8.697432 history loss 7.659079 rank 4
2022-12-04 05:26:17,828 DEBUG CV Batch 9/1700 loss 9.696867 loss_att 9.499880 loss_ctc 17.488110 loss_rnnt 8.697432 history loss 7.659079 rank 1
2022-12-04 05:26:22,342 DEBUG CV Batch 9/1700 loss 9.696867 loss_att 9.499880 loss_ctc 17.488110 loss_rnnt 8.697432 history loss 7.659079 rank 6
2022-12-04 05:26:24,316 DEBUG CV Batch 9/1700 loss 9.696867 loss_att 9.499880 loss_ctc 17.488110 loss_rnnt 8.697432 history loss 7.659079 rank 0
2022-12-04 05:26:25,380 DEBUG CV Batch 9/1700 loss 9.696867 loss_att 9.499880 loss_ctc 17.488110 loss_rnnt 8.697432 history loss 7.659079 rank 3
2022-12-04 05:26:25,804 INFO Epoch 9 CV info cv_loss 7.62756943344329
2022-12-04 05:26:25,805 INFO Epoch 10 TRAIN info lr 0.000547588962095067
2022-12-04 05:26:25,807 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 05:26:26,105 INFO Epoch 9 CV info cv_loss 7.62756943344329
2022-12-04 05:26:26,106 INFO Epoch 10 TRAIN info lr 0.0005476020982925979
2022-12-04 05:26:26,110 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 05:26:26,956 INFO Epoch 9 CV info cv_loss 7.62756943344329
2022-12-04 05:26:26,957 INFO Epoch 10 TRAIN info lr 0.0005473526720778872
2022-12-04 05:26:26,959 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 05:26:27,024 INFO Epoch 9 CV info cv_loss 7.62756943344329
2022-12-04 05:26:27,025 INFO Epoch 10 TRAIN info lr 0.0005476447974644971
2022-12-04 05:26:27,029 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 05:26:27,384 INFO Epoch 9 CV info cv_loss 7.62756943344329
2022-12-04 05:26:27,385 INFO Epoch 10 TRAIN info lr 0.0005475594091067427
2022-12-04 05:26:27,390 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 05:26:31,566 INFO Epoch 9 CV info cv_loss 7.62756943344329
2022-12-04 05:26:31,567 INFO Epoch 10 TRAIN info lr 0.0005476480824299165
2022-12-04 05:26:31,572 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 05:26:33,597 INFO Epoch 9 CV info cv_loss 7.62756943344329
2022-12-04 05:26:33,598 INFO Checkpoint: save to checkpoint exp/1202_encoder_bias_30_0.1/9.pt
2022-12-04 05:26:34,164 INFO Epoch 10 TRAIN info lr 0.0005474937529266094
2022-12-04 05:26:34,168 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 05:26:34,815 INFO Epoch 9 CV info cv_loss 7.62756943344329
2022-12-04 05:26:34,816 INFO Epoch 10 TRAIN info lr 0.0005475791105672853
2022-12-04 05:26:34,818 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 05:27:34,565 DEBUG TRAIN Batch 10/0 loss 9.326225 loss_att 9.398891 loss_ctc 14.049884 loss_rnnt 8.681870 lr 0.00054756 rank 1
2022-12-04 05:27:34,568 DEBUG TRAIN Batch 10/0 loss 13.562309 loss_att 14.259918 loss_ctc 18.626488 loss_rnnt 12.747564 lr 0.00054760 rank 7
2022-12-04 05:27:34,570 DEBUG TRAIN Batch 10/0 loss 12.376822 loss_att 11.902947 loss_ctc 16.379221 loss_rnnt 11.937943 lr 0.00054764 rank 4
2022-12-04 05:27:34,572 DEBUG TRAIN Batch 10/0 loss 10.298472 loss_att 10.638616 loss_ctc 14.273065 loss_rnnt 9.700498 lr 0.00054764 rank 6
2022-12-04 05:27:34,573 DEBUG TRAIN Batch 10/0 loss 11.544699 loss_att 10.408902 loss_ctc 14.562886 loss_rnnt 11.369432 lr 0.00054735 rank 2
2022-12-04 05:27:34,599 DEBUG TRAIN Batch 10/0 loss 10.594341 loss_att 10.550240 loss_ctc 16.315462 loss_rnnt 9.840345 lr 0.00054758 rank 3
2022-12-04 05:27:34,603 DEBUG TRAIN Batch 10/0 loss 11.127756 loss_att 11.537114 loss_ctc 15.935433 loss_rnnt 10.404861 lr 0.00054749 rank 0
2022-12-04 05:27:34,618 DEBUG TRAIN Batch 10/0 loss 9.628481 loss_att 9.645494 loss_ctc 14.036477 loss_rnnt 9.037346 lr 0.00054759 rank 5
2022-12-04 05:28:45,517 DEBUG TRAIN Batch 10/100 loss 16.573450 loss_att 23.371147 loss_ctc 24.955381 loss_rnnt 14.096319 lr 0.00054726 rank 5
2022-12-04 05:28:45,523 DEBUG TRAIN Batch 10/100 loss 4.828714 loss_att 7.874385 loss_ctc 9.562733 loss_rnnt 3.588377 lr 0.00054732 rank 6
2022-12-04 05:28:45,526 DEBUG TRAIN Batch 10/100 loss 18.282555 loss_att 23.224110 loss_ctc 30.410391 loss_rnnt 15.677198 lr 0.00054723 rank 1
2022-12-04 05:28:45,527 DEBUG TRAIN Batch 10/100 loss 19.001541 loss_att 19.482084 loss_ctc 36.872673 loss_rnnt 16.522614 lr 0.00054725 rank 3
2022-12-04 05:28:45,533 DEBUG TRAIN Batch 10/100 loss 8.703555 loss_att 11.419762 loss_ctc 13.225115 loss_rnnt 7.557439 lr 0.00054727 rank 7
2022-12-04 05:28:45,534 DEBUG TRAIN Batch 10/100 loss 9.334888 loss_att 17.293324 loss_ctc 22.689276 loss_rnnt 5.962616 lr 0.00054716 rank 0
2022-12-04 05:28:45,537 DEBUG TRAIN Batch 10/100 loss 15.103843 loss_att 20.899237 loss_ctc 18.665854 loss_rnnt 13.469828 lr 0.00054702 rank 2
2022-12-04 05:28:45,539 DEBUG TRAIN Batch 10/100 loss 15.738140 loss_att 22.009457 loss_ctc 24.387138 loss_rnnt 13.330677 lr 0.00054731 rank 4
2022-12-04 05:29:56,396 DEBUG TRAIN Batch 10/200 loss 12.815527 loss_att 18.235909 loss_ctc 36.780022 loss_rnnt 8.536185 lr 0.00054699 rank 6
2022-12-04 05:29:56,399 DEBUG TRAIN Batch 10/200 loss 13.800725 loss_att 15.025757 loss_ctc 23.769207 loss_rnnt 12.226588 lr 0.00054684 rank 0
2022-12-04 05:29:56,402 DEBUG TRAIN Batch 10/200 loss 12.230375 loss_att 21.824944 loss_ctc 22.114271 loss_rnnt 8.993608 lr 0.00054692 rank 3
2022-12-04 05:29:56,402 DEBUG TRAIN Batch 10/200 loss 19.150833 loss_att 22.470308 loss_ctc 29.864141 loss_rnnt 17.058498 lr 0.00054694 rank 7
2022-12-04 05:29:56,404 DEBUG TRAIN Batch 10/200 loss 5.987871 loss_att 10.821992 loss_ctc 13.209328 loss_rnnt 4.058187 lr 0.00054699 rank 4
2022-12-04 05:29:56,407 DEBUG TRAIN Batch 10/200 loss 6.554245 loss_att 8.793730 loss_ctc 12.320217 loss_rnnt 5.337553 lr 0.00054690 rank 1
2022-12-04 05:29:56,406 DEBUG TRAIN Batch 10/200 loss 12.801985 loss_att 18.888300 loss_ctc 22.398373 loss_rnnt 10.305202 lr 0.00054669 rank 2
2022-12-04 05:29:56,448 DEBUG TRAIN Batch 10/200 loss 6.417131 loss_att 12.437703 loss_ctc 16.366634 loss_rnnt 3.886417 lr 0.00054693 rank 5
2022-12-04 05:31:09,227 DEBUG TRAIN Batch 10/300 loss 19.366894 loss_att 24.637732 loss_ctc 36.978722 loss_rnnt 15.964481 lr 0.00054662 rank 7
2022-12-04 05:31:09,234 DEBUG TRAIN Batch 10/300 loss 23.960407 loss_att 28.133614 loss_ctc 35.639935 loss_rnnt 21.568497 lr 0.00054660 rank 5
2022-12-04 05:31:09,234 DEBUG TRAIN Batch 10/300 loss 10.965130 loss_att 16.400303 loss_ctc 16.058916 loss_rnnt 9.198923 lr 0.00054666 rank 6
2022-12-04 05:31:09,235 DEBUG TRAIN Batch 10/300 loss 21.614122 loss_att 24.160240 loss_ctc 36.368969 loss_rnnt 19.137585 lr 0.00054666 rank 4
2022-12-04 05:31:09,236 DEBUG TRAIN Batch 10/300 loss 13.647606 loss_att 18.458387 loss_ctc 22.944290 loss_rnnt 11.445892 lr 0.00054651 rank 0
2022-12-04 05:31:09,238 DEBUG TRAIN Batch 10/300 loss 15.981889 loss_att 18.953341 loss_ctc 29.708603 loss_rnnt 13.557369 lr 0.00054659 rank 3
2022-12-04 05:31:09,239 DEBUG TRAIN Batch 10/300 loss 10.791659 loss_att 15.007217 loss_ctc 18.164188 loss_rnnt 8.965544 lr 0.00054637 rank 2
2022-12-04 05:31:09,261 DEBUG TRAIN Batch 10/300 loss 18.373129 loss_att 22.373276 loss_ctc 28.908455 loss_rnnt 16.168388 lr 0.00054657 rank 1
2022-12-04 05:32:22,825 DEBUG TRAIN Batch 10/400 loss 13.232285 loss_att 17.624514 loss_ctc 22.594450 loss_rnnt 11.105549 lr 0.00054618 rank 0
2022-12-04 05:32:22,827 DEBUG TRAIN Batch 10/400 loss 12.893296 loss_att 15.817617 loss_ctc 19.887400 loss_rnnt 11.375885 lr 0.00054628 rank 5
2022-12-04 05:32:22,830 DEBUG TRAIN Batch 10/400 loss 8.392344 loss_att 11.959826 loss_ctc 15.868636 loss_rnnt 6.682008 lr 0.00054604 rank 2
2022-12-04 05:32:22,831 DEBUG TRAIN Batch 10/400 loss 13.045835 loss_att 15.123336 loss_ctc 19.198669 loss_rnnt 11.809958 lr 0.00054629 rank 7
2022-12-04 05:32:22,833 DEBUG TRAIN Batch 10/400 loss 10.853222 loss_att 16.015463 loss_ctc 26.373554 loss_rnnt 7.751395 lr 0.00054634 rank 6
2022-12-04 05:32:22,835 DEBUG TRAIN Batch 10/400 loss 12.348576 loss_att 16.645809 loss_ctc 24.282349 loss_rnnt 9.897960 lr 0.00054625 rank 1
2022-12-04 05:32:22,835 DEBUG TRAIN Batch 10/400 loss 26.453690 loss_att 29.344208 loss_ctc 44.982166 loss_rnnt 23.405121 lr 0.00054633 rank 4
2022-12-04 05:32:22,836 DEBUG TRAIN Batch 10/400 loss 22.421835 loss_att 28.975674 loss_ctc 35.513428 loss_rnnt 19.365520 lr 0.00054627 rank 3
2022-12-04 05:33:34,860 DEBUG TRAIN Batch 10/500 loss 6.092202 loss_att 7.940229 loss_ctc 8.003520 loss_rnnt 5.467754 lr 0.00054601 rank 6
2022-12-04 05:33:34,866 DEBUG TRAIN Batch 10/500 loss 19.100027 loss_att 20.806747 loss_ctc 28.017653 loss_rnnt 17.569666 lr 0.00054586 rank 0
2022-12-04 05:33:34,866 DEBUG TRAIN Batch 10/500 loss 11.862564 loss_att 12.977156 loss_ctc 19.609755 loss_rnnt 10.606687 lr 0.00054572 rank 2
2022-12-04 05:33:34,865 DEBUG TRAIN Batch 10/500 loss 8.514946 loss_att 12.865012 loss_ctc 13.792532 loss_rnnt 6.941254 lr 0.00054592 rank 1
2022-12-04 05:33:34,868 DEBUG TRAIN Batch 10/500 loss 14.608654 loss_att 16.602085 loss_ctc 24.272446 loss_rnnt 12.921463 lr 0.00054594 rank 3
2022-12-04 05:33:34,870 DEBUG TRAIN Batch 10/500 loss 16.284822 loss_att 20.926903 loss_ctc 29.151060 loss_rnnt 13.640907 lr 0.00054595 rank 5
2022-12-04 05:33:34,874 DEBUG TRAIN Batch 10/500 loss 5.706244 loss_att 8.907629 loss_ctc 9.879416 loss_rnnt 4.509544 lr 0.00054601 rank 4
2022-12-04 05:33:34,878 DEBUG TRAIN Batch 10/500 loss 26.207954 loss_att 28.790871 loss_ctc 49.159199 loss_rnnt 22.631205 lr 0.00054596 rank 7
2022-12-04 05:34:47,499 DEBUG TRAIN Batch 10/600 loss 9.571157 loss_att 10.577869 loss_ctc 14.847477 loss_rnnt 8.666306 lr 0.00054568 rank 4
2022-12-04 05:34:47,509 DEBUG TRAIN Batch 10/600 loss 9.652852 loss_att 11.069670 loss_ctc 16.004623 loss_rnnt 8.522585 lr 0.00054568 rank 6
2022-12-04 05:34:47,510 DEBUG TRAIN Batch 10/600 loss 16.282957 loss_att 19.815073 loss_ctc 22.917616 loss_rnnt 14.691912 lr 0.00054553 rank 0
2022-12-04 05:34:47,512 DEBUG TRAIN Batch 10/600 loss 9.103374 loss_att 11.999382 loss_ctc 16.514685 loss_rnnt 7.535998 lr 0.00054563 rank 5
2022-12-04 05:34:47,513 DEBUG TRAIN Batch 10/600 loss 15.250107 loss_att 16.638046 loss_ctc 22.197567 loss_rnnt 14.046189 lr 0.00054562 rank 3
2022-12-04 05:34:47,515 DEBUG TRAIN Batch 10/600 loss 13.376376 loss_att 14.543081 loss_ctc 18.644215 loss_rnnt 12.440657 lr 0.00054560 rank 1
2022-12-04 05:34:47,525 DEBUG TRAIN Batch 10/600 loss 9.085505 loss_att 11.453238 loss_ctc 15.428868 loss_rnnt 7.766177 lr 0.00054539 rank 2
2022-12-04 05:34:47,525 DEBUG TRAIN Batch 10/600 loss 7.126765 loss_att 8.533169 loss_ctc 10.601644 loss_rnnt 6.382167 lr 0.00054564 rank 7
2022-12-04 05:36:00,698 DEBUG TRAIN Batch 10/700 loss 12.251369 loss_att 18.271046 loss_ctc 18.911327 loss_rnnt 10.159439 lr 0.00054531 rank 7
2022-12-04 05:36:00,706 DEBUG TRAIN Batch 10/700 loss 9.221243 loss_att 12.718862 loss_ctc 20.615601 loss_rnnt 7.002472 lr 0.00054527 rank 1
2022-12-04 05:36:00,707 DEBUG TRAIN Batch 10/700 loss 3.064097 loss_att 8.285946 loss_ctc 5.325482 loss_rnnt 1.718210 lr 0.00054530 rank 5
2022-12-04 05:36:00,708 DEBUG TRAIN Batch 10/700 loss 13.939393 loss_att 19.191492 loss_ctc 15.715231 loss_rnnt 12.652195 lr 0.00054536 rank 6
2022-12-04 05:36:00,709 DEBUG TRAIN Batch 10/700 loss 12.921800 loss_att 15.478371 loss_ctc 22.694647 loss_rnnt 11.107440 lr 0.00054521 rank 0
2022-12-04 05:36:00,711 DEBUG TRAIN Batch 10/700 loss 9.645720 loss_att 16.112680 loss_ctc 28.862373 loss_rnnt 5.790107 lr 0.00054529 rank 3
2022-12-04 05:36:00,714 DEBUG TRAIN Batch 10/700 loss 7.927062 loss_att 11.237989 loss_ctc 14.187445 loss_rnnt 6.430158 lr 0.00054536 rank 4
2022-12-04 05:36:00,757 DEBUG TRAIN Batch 10/700 loss 13.917594 loss_att 20.674236 loss_ctc 23.583572 loss_rnnt 11.277469 lr 0.00054507 rank 2
2022-12-04 05:37:15,908 DEBUG TRAIN Batch 10/800 loss 21.543848 loss_att 23.311663 loss_ctc 38.544186 loss_rnnt 18.923574 lr 0.00054497 rank 3
2022-12-04 05:37:15,908 DEBUG TRAIN Batch 10/800 loss 18.728756 loss_att 22.989826 loss_ctc 31.705357 loss_rnnt 16.146326 lr 0.00054504 rank 6
2022-12-04 05:37:15,909 DEBUG TRAIN Batch 10/800 loss 9.659616 loss_att 15.471066 loss_ctc 13.446739 loss_rnnt 7.992376 lr 0.00054498 rank 5
2022-12-04 05:37:15,914 DEBUG TRAIN Batch 10/800 loss 26.979105 loss_att 31.634710 loss_ctc 55.340893 loss_rnnt 22.266411 lr 0.00054495 rank 1
2022-12-04 05:37:15,915 DEBUG TRAIN Batch 10/800 loss 10.339140 loss_att 13.621838 loss_ctc 16.684462 loss_rnnt 8.836557 lr 0.00054488 rank 0
2022-12-04 05:37:15,914 DEBUG TRAIN Batch 10/800 loss 9.356667 loss_att 13.200844 loss_ctc 14.687607 loss_rnnt 7.877039 lr 0.00054499 rank 7
2022-12-04 05:37:15,916 DEBUG TRAIN Batch 10/800 loss 11.884291 loss_att 16.974756 loss_ctc 22.234732 loss_rnnt 9.486137 lr 0.00054474 rank 2
2022-12-04 05:37:15,920 DEBUG TRAIN Batch 10/800 loss 13.389013 loss_att 17.418339 loss_ctc 21.563673 loss_rnnt 11.493194 lr 0.00054503 rank 4
2022-12-04 05:38:27,322 DEBUG TRAIN Batch 10/900 loss 20.078156 loss_att 24.026688 loss_ctc 34.414604 loss_rnnt 17.376923 lr 0.00054456 rank 0
2022-12-04 05:38:27,322 DEBUG TRAIN Batch 10/900 loss 11.454030 loss_att 15.158703 loss_ctc 21.330421 loss_rnnt 9.396243 lr 0.00054465 rank 5
2022-12-04 05:38:27,322 DEBUG TRAIN Batch 10/900 loss 12.419324 loss_att 12.745260 loss_ctc 18.746714 loss_rnnt 11.510485 lr 0.00054471 rank 6
2022-12-04 05:38:27,329 DEBUG TRAIN Batch 10/900 loss 5.462969 loss_att 10.380409 loss_ctc 10.517153 loss_rnnt 3.805589 lr 0.00054467 rank 7
2022-12-04 05:38:27,330 DEBUG TRAIN Batch 10/900 loss 8.463636 loss_att 13.545608 loss_ctc 17.361362 loss_rnnt 6.260879 lr 0.00054462 rank 1
2022-12-04 05:38:27,333 DEBUG TRAIN Batch 10/900 loss 22.963341 loss_att 28.297636 loss_ctc 43.948570 loss_rnnt 19.098450 lr 0.00054442 rank 2
2022-12-04 05:38:27,333 DEBUG TRAIN Batch 10/900 loss 8.871431 loss_att 15.011000 loss_ctc 20.006092 loss_rnnt 6.158896 lr 0.00054464 rank 3
2022-12-04 05:38:27,334 DEBUG TRAIN Batch 10/900 loss 12.357768 loss_att 15.944589 loss_ctc 21.107445 loss_rnnt 10.473780 lr 0.00054471 rank 4
2022-12-04 05:39:39,682 DEBUG TRAIN Batch 10/1000 loss 5.649273 loss_att 8.108381 loss_ctc 9.210162 loss_rnnt 4.682666 lr 0.00054424 rank 0
2022-12-04 05:39:39,693 DEBUG TRAIN Batch 10/1000 loss 5.430114 loss_att 10.353373 loss_ctc 9.521025 loss_rnnt 3.900007 lr 0.00054434 rank 7
2022-12-04 05:39:39,701 DEBUG TRAIN Batch 10/1000 loss 17.265724 loss_att 22.250145 loss_ctc 27.577518 loss_rnnt 14.893934 lr 0.00054430 rank 1
2022-12-04 05:39:39,701 DEBUG TRAIN Batch 10/1000 loss 6.983092 loss_att 9.432500 loss_ctc 12.584871 loss_rnnt 5.746306 lr 0.00054439 rank 6
2022-12-04 05:39:39,702 DEBUG TRAIN Batch 10/1000 loss 24.098475 loss_att 25.732006 loss_ctc 34.406830 loss_rnnt 22.397322 lr 0.00054432 rank 3
2022-12-04 05:39:39,703 DEBUG TRAIN Batch 10/1000 loss 9.895657 loss_att 12.894188 loss_ctc 20.990534 loss_rnnt 7.816634 lr 0.00054439 rank 4
2022-12-04 05:39:39,705 DEBUG TRAIN Batch 10/1000 loss 8.595181 loss_att 11.495707 loss_ctc 16.721170 loss_rnnt 6.931611 lr 0.00054410 rank 2
2022-12-04 05:39:39,750 DEBUG TRAIN Batch 10/1000 loss 21.726820 loss_att 26.192532 loss_ctc 35.361172 loss_rnnt 19.015762 lr 0.00054433 rank 5
2022-12-04 05:40:54,109 DEBUG TRAIN Batch 10/1100 loss 10.639215 loss_att 13.615278 loss_ctc 16.019724 loss_rnnt 9.326602 lr 0.00054407 rank 6
2022-12-04 05:40:54,118 DEBUG TRAIN Batch 10/1100 loss 13.852800 loss_att 19.114168 loss_ctc 27.154095 loss_rnnt 11.027021 lr 0.00054392 rank 0
2022-12-04 05:40:54,117 DEBUG TRAIN Batch 10/1100 loss 14.405861 loss_att 19.664976 loss_ctc 21.651659 loss_rnnt 12.387931 lr 0.00054378 rank 2
2022-12-04 05:40:54,118 DEBUG TRAIN Batch 10/1100 loss 14.282110 loss_att 18.551579 loss_ctc 24.728981 loss_rnnt 12.035300 lr 0.00054402 rank 7
2022-12-04 05:40:54,119 DEBUG TRAIN Batch 10/1100 loss 15.219293 loss_att 21.857426 loss_ctc 25.206825 loss_rnnt 12.559995 lr 0.00054400 rank 3
2022-12-04 05:40:54,119 DEBUG TRAIN Batch 10/1100 loss 16.551048 loss_att 20.360752 loss_ctc 25.555439 loss_rnnt 14.588522 lr 0.00054398 rank 1
2022-12-04 05:40:54,120 DEBUG TRAIN Batch 10/1100 loss 19.653095 loss_att 25.255447 loss_ctc 39.098999 loss_rnnt 15.939838 lr 0.00054406 rank 4
2022-12-04 05:40:54,163 DEBUG TRAIN Batch 10/1100 loss 10.289881 loss_att 13.923727 loss_ctc 13.709961 loss_rnnt 9.107100 lr 0.00054401 rank 5
2022-12-04 05:42:06,012 DEBUG TRAIN Batch 10/1200 loss 10.843903 loss_att 13.851550 loss_ctc 19.904259 loss_rnnt 9.034326 lr 0.00054374 rank 6
2022-12-04 05:42:06,016 DEBUG TRAIN Batch 10/1200 loss 8.609609 loss_att 11.112856 loss_ctc 14.412101 loss_rnnt 7.335293 lr 0.00054346 rank 2
2022-12-04 05:42:06,016 DEBUG TRAIN Batch 10/1200 loss 11.082753 loss_att 14.246210 loss_ctc 23.219633 loss_rnnt 8.831812 lr 0.00054366 rank 1
2022-12-04 05:42:06,016 DEBUG TRAIN Batch 10/1200 loss 14.727022 loss_att 18.150387 loss_ctc 25.968468 loss_rnnt 12.543490 lr 0.00054359 rank 0
2022-12-04 05:42:06,020 DEBUG TRAIN Batch 10/1200 loss 7.960286 loss_att 9.342108 loss_ctc 13.257152 loss_rnnt 6.977673 lr 0.00054374 rank 4
2022-12-04 05:42:06,020 DEBUG TRAIN Batch 10/1200 loss 11.166208 loss_att 12.176914 loss_ctc 20.316133 loss_rnnt 9.744077 lr 0.00054368 rank 3
2022-12-04 05:42:06,023 DEBUG TRAIN Batch 10/1200 loss 9.749970 loss_att 10.617439 loss_ctc 13.335552 loss_rnnt 9.098399 lr 0.00054370 rank 7
2022-12-04 05:42:06,068 DEBUG TRAIN Batch 10/1200 loss 13.511132 loss_att 16.053871 loss_ctc 20.107796 loss_rnnt 12.123030 lr 0.00054369 rank 5
2022-12-04 05:43:17,337 DEBUG TRAIN Batch 10/1300 loss 16.829241 loss_att 20.890179 loss_ctc 33.875771 loss_rnnt 13.744182 lr 0.00054327 rank 0
2022-12-04 05:43:17,349 DEBUG TRAIN Batch 10/1300 loss 18.959110 loss_att 21.399536 loss_ctc 34.718033 loss_rnnt 16.369835 lr 0.00054342 rank 6
2022-12-04 05:43:17,349 DEBUG TRAIN Batch 10/1300 loss 10.820023 loss_att 18.745092 loss_ctc 24.399632 loss_rnnt 7.424394 lr 0.00054336 rank 3
2022-12-04 05:43:17,351 DEBUG TRAIN Batch 10/1300 loss 16.295116 loss_att 16.576599 loss_ctc 22.399462 loss_rnnt 15.424908 lr 0.00054337 rank 5
2022-12-04 05:43:17,354 DEBUG TRAIN Batch 10/1300 loss 11.452077 loss_att 13.842666 loss_ctc 21.786489 loss_rnnt 9.596038 lr 0.00054342 rank 4
2022-12-04 05:43:17,354 DEBUG TRAIN Batch 10/1300 loss 17.048500 loss_att 21.717583 loss_ctc 31.767807 loss_rnnt 14.152109 lr 0.00054338 rank 7
2022-12-04 05:43:17,361 DEBUG TRAIN Batch 10/1300 loss 40.861740 loss_att 49.765240 loss_ctc 72.393524 loss_rnnt 34.876801 lr 0.00054334 rank 1
2022-12-04 05:43:17,375 DEBUG TRAIN Batch 10/1300 loss 14.910880 loss_att 19.129620 loss_ctc 26.721272 loss_rnnt 12.492414 lr 0.00054314 rank 2
2022-12-04 05:44:30,259 DEBUG TRAIN Batch 10/1400 loss 20.198565 loss_att 24.482393 loss_ctc 33.773071 loss_rnnt 17.531862 lr 0.00054304 rank 3
2022-12-04 05:44:30,261 DEBUG TRAIN Batch 10/1400 loss 8.175176 loss_att 13.180801 loss_ctc 21.744797 loss_rnnt 5.364767 lr 0.00054310 rank 6
2022-12-04 05:44:30,261 DEBUG TRAIN Batch 10/1400 loss 21.768879 loss_att 25.529949 loss_ctc 37.319763 loss_rnnt 18.943214 lr 0.00054295 rank 0
2022-12-04 05:44:30,263 DEBUG TRAIN Batch 10/1400 loss 8.854364 loss_att 12.139718 loss_ctc 13.728231 loss_rnnt 7.547445 lr 0.00054310 rank 4
2022-12-04 05:44:30,262 DEBUG TRAIN Batch 10/1400 loss 13.896629 loss_att 18.625898 loss_ctc 20.665241 loss_rnnt 12.048293 lr 0.00054302 rank 1
2022-12-04 05:44:30,263 DEBUG TRAIN Batch 10/1400 loss 8.866446 loss_att 12.286515 loss_ctc 14.294912 loss_rnnt 7.458636 lr 0.00054306 rank 7
2022-12-04 05:44:30,262 DEBUG TRAIN Batch 10/1400 loss 6.526923 loss_att 12.175859 loss_ctc 17.998531 loss_rnnt 3.867588 lr 0.00054281 rank 2
2022-12-04 05:44:30,266 DEBUG TRAIN Batch 10/1400 loss 12.628031 loss_att 16.934303 loss_ctc 29.131474 loss_rnnt 9.566317 lr 0.00054305 rank 5
2022-12-04 05:45:49,267 DEBUG TRAIN Batch 10/1500 loss 10.368000 loss_att 11.318095 loss_ctc 18.044174 loss_rnnt 9.154491 lr 0.00054272 rank 3
2022-12-04 05:45:49,268 DEBUG TRAIN Batch 10/1500 loss 10.210687 loss_att 14.191269 loss_ctc 15.657356 loss_rnnt 8.688347 lr 0.00054273 rank 5
2022-12-04 05:45:49,268 DEBUG TRAIN Batch 10/1500 loss 15.845330 loss_att 23.243397 loss_ctc 24.951050 loss_rnnt 13.151622 lr 0.00054274 rank 7
2022-12-04 05:45:49,269 DEBUG TRAIN Batch 10/1500 loss 15.280955 loss_att 23.381508 loss_ctc 27.356237 loss_rnnt 12.050808 lr 0.00054278 rank 4
2022-12-04 05:45:49,270 DEBUG TRAIN Batch 10/1500 loss 7.858889 loss_att 12.816140 loss_ctc 15.250384 loss_rnnt 5.881906 lr 0.00054270 rank 1
2022-12-04 05:45:49,273 DEBUG TRAIN Batch 10/1500 loss 11.492788 loss_att 16.298592 loss_ctc 17.569368 loss_rnnt 9.721416 lr 0.00054278 rank 6
2022-12-04 05:45:49,274 DEBUG TRAIN Batch 10/1500 loss 15.458961 loss_att 18.702011 loss_ctc 21.299210 loss_rnnt 14.031652 lr 0.00054263 rank 0
2022-12-04 05:45:49,276 DEBUG TRAIN Batch 10/1500 loss 16.936111 loss_att 22.016203 loss_ctc 26.762558 loss_rnnt 14.609900 lr 0.00054250 rank 2
2022-12-04 05:47:00,747 DEBUG TRAIN Batch 10/1600 loss 9.984970 loss_att 15.269034 loss_ctc 18.301134 loss_rnnt 7.819336 lr 0.00054238 rank 1
2022-12-04 05:47:00,748 DEBUG TRAIN Batch 10/1600 loss 21.771246 loss_att 23.183449 loss_ctc 34.450581 loss_rnnt 19.798225 lr 0.00054231 rank 0
2022-12-04 05:47:00,753 DEBUG TRAIN Batch 10/1600 loss 20.910585 loss_att 21.881927 loss_ctc 30.752113 loss_rnnt 19.404114 lr 0.00054240 rank 3
2022-12-04 05:47:00,753 DEBUG TRAIN Batch 10/1600 loss 21.291107 loss_att 27.946611 loss_ctc 28.308653 loss_rnnt 19.024334 lr 0.00054246 rank 6
2022-12-04 05:47:00,755 DEBUG TRAIN Batch 10/1600 loss 7.836345 loss_att 12.061714 loss_ctc 19.810513 loss_rnnt 5.394715 lr 0.00054241 rank 5
2022-12-04 05:47:00,758 DEBUG TRAIN Batch 10/1600 loss 12.669734 loss_att 17.005280 loss_ctc 22.124369 loss_rnnt 10.542007 lr 0.00054218 rank 2
2022-12-04 05:47:00,758 DEBUG TRAIN Batch 10/1600 loss 16.142460 loss_att 16.899879 loss_ctc 27.194180 loss_rnnt 14.517411 lr 0.00054246 rank 4
2022-12-04 05:47:00,759 DEBUG TRAIN Batch 10/1600 loss 12.077399 loss_att 16.746445 loss_ctc 24.680910 loss_rnnt 9.463122 lr 0.00054242 rank 7
2022-12-04 05:48:12,503 DEBUG TRAIN Batch 10/1700 loss 3.648621 loss_att 7.518948 loss_ctc 7.254532 loss_rnnt 2.393767 lr 0.00054208 rank 3
2022-12-04 05:48:12,503 DEBUG TRAIN Batch 10/1700 loss 14.810216 loss_att 14.094339 loss_ctc 19.856701 loss_rnnt 14.280526 lr 0.00054206 rank 1
2022-12-04 05:48:12,505 DEBUG TRAIN Batch 10/1700 loss 17.471201 loss_att 18.338949 loss_ctc 20.734606 loss_rnnt 16.862530 lr 0.00054209 rank 5
2022-12-04 05:48:12,506 DEBUG TRAIN Batch 10/1700 loss 13.666063 loss_att 18.856712 loss_ctc 21.130947 loss_rnnt 11.632616 lr 0.00054214 rank 6
2022-12-04 05:48:12,506 DEBUG TRAIN Batch 10/1700 loss 12.279952 loss_att 15.194776 loss_ctc 17.481699 loss_rnnt 11.003420 lr 0.00054186 rank 2
2022-12-04 05:48:12,508 DEBUG TRAIN Batch 10/1700 loss 14.330378 loss_att 17.922165 loss_ctc 23.690334 loss_rnnt 12.364025 lr 0.00054199 rank 0
2022-12-04 05:48:12,509 DEBUG TRAIN Batch 10/1700 loss 20.207092 loss_att 22.779831 loss_ctc 26.402815 loss_rnnt 18.866447 lr 0.00054214 rank 4
2022-12-04 05:48:12,511 DEBUG TRAIN Batch 10/1700 loss 4.597883 loss_att 9.273851 loss_ctc 12.285917 loss_rnnt 2.637618 lr 0.00054210 rank 7
2022-12-04 05:49:27,599 DEBUG TRAIN Batch 10/1800 loss 13.398465 loss_att 14.370829 loss_ctc 18.701756 loss_rnnt 12.496887 lr 0.00054183 rank 6
2022-12-04 05:49:27,600 DEBUG TRAIN Batch 10/1800 loss 15.332027 loss_att 15.888260 loss_ctc 29.955173 loss_rnnt 13.271028 lr 0.00054168 rank 0
2022-12-04 05:49:27,600 DEBUG TRAIN Batch 10/1800 loss 13.922963 loss_att 18.820408 loss_ctc 31.335724 loss_rnnt 10.621773 lr 0.00054177 rank 5
2022-12-04 05:49:27,603 DEBUG TRAIN Batch 10/1800 loss 14.567839 loss_att 14.055941 loss_ctc 19.362576 loss_rnnt 14.030919 lr 0.00054174 rank 1
2022-12-04 05:49:27,603 DEBUG TRAIN Batch 10/1800 loss 14.832018 loss_att 16.382614 loss_ctc 26.534664 loss_rnnt 12.961546 lr 0.00054176 rank 3
2022-12-04 05:49:27,606 DEBUG TRAIN Batch 10/1800 loss 11.881966 loss_att 14.065222 loss_ctc 21.016333 loss_rnnt 10.227399 lr 0.00054182 rank 4
2022-12-04 05:49:27,607 DEBUG TRAIN Batch 10/1800 loss 5.409586 loss_att 7.410897 loss_ctc 8.689810 loss_rnnt 4.571960 lr 0.00054178 rank 7
2022-12-04 05:49:27,610 DEBUG TRAIN Batch 10/1800 loss 13.567748 loss_att 13.608589 loss_ctc 22.382843 loss_rnnt 12.384233 lr 0.00054154 rank 2
2022-12-04 05:50:39,942 DEBUG TRAIN Batch 10/1900 loss 8.199637 loss_att 9.032471 loss_ctc 14.657667 loss_rnnt 7.171999 lr 0.00054151 rank 6
2022-12-04 05:50:39,945 DEBUG TRAIN Batch 10/1900 loss 8.215233 loss_att 12.032351 loss_ctc 11.454311 loss_rnnt 7.019932 lr 0.00054144 rank 3
2022-12-04 05:50:39,946 DEBUG TRAIN Batch 10/1900 loss 19.857054 loss_att 21.538952 loss_ctc 31.061146 loss_rnnt 18.026794 lr 0.00054145 rank 5
2022-12-04 05:50:39,948 DEBUG TRAIN Batch 10/1900 loss 6.693424 loss_att 12.845192 loss_ctc 16.234758 loss_rnnt 4.190892 lr 0.00054146 rank 7
2022-12-04 05:50:39,948 DEBUG TRAIN Batch 10/1900 loss 5.362755 loss_att 7.743659 loss_ctc 9.951116 loss_rnnt 4.274793 lr 0.00054136 rank 0
2022-12-04 05:50:39,949 DEBUG TRAIN Batch 10/1900 loss 16.475359 loss_att 18.021471 loss_ctc 22.449230 loss_rnnt 15.369621 lr 0.00054142 rank 1
2022-12-04 05:50:39,949 DEBUG TRAIN Batch 10/1900 loss 5.809052 loss_att 10.820158 loss_ctc 9.512420 loss_rnnt 4.313049 lr 0.00054150 rank 4
2022-12-04 05:50:39,953 DEBUG TRAIN Batch 10/1900 loss 10.812720 loss_att 17.885025 loss_ctc 15.866224 loss_rnnt 8.724460 lr 0.00054122 rank 2
2022-12-04 05:51:51,328 DEBUG TRAIN Batch 10/2000 loss 10.762353 loss_att 16.100204 loss_ctc 19.042240 loss_rnnt 8.590797 lr 0.00054119 rank 4
2022-12-04 05:51:51,342 DEBUG TRAIN Batch 10/2000 loss 4.327223 loss_att 7.992629 loss_ctc 6.959221 loss_rnnt 3.243209 lr 0.00054112 rank 3
2022-12-04 05:51:51,343 DEBUG TRAIN Batch 10/2000 loss 13.568537 loss_att 19.257822 loss_ctc 19.644745 loss_rnnt 11.620520 lr 0.00054111 rank 1
2022-12-04 05:51:51,343 DEBUG TRAIN Batch 10/2000 loss 9.296257 loss_att 14.503363 loss_ctc 15.990291 loss_rnnt 7.362298 lr 0.00054104 rank 0
2022-12-04 05:51:51,343 DEBUG TRAIN Batch 10/2000 loss 8.377723 loss_att 14.175528 loss_ctc 11.911633 loss_rnnt 6.746973 lr 0.00054113 rank 5
2022-12-04 05:51:51,345 DEBUG TRAIN Batch 10/2000 loss 7.203373 loss_att 10.487182 loss_ctc 14.744609 loss_rnnt 5.541114 lr 0.00054119 rank 6
2022-12-04 05:51:51,346 DEBUG TRAIN Batch 10/2000 loss 3.585396 loss_att 7.193915 loss_ctc 5.702728 loss_rnnt 2.581381 lr 0.00054115 rank 7
2022-12-04 05:51:51,387 DEBUG TRAIN Batch 10/2000 loss 9.114442 loss_att 12.888960 loss_ctc 12.941981 loss_rnnt 7.849200 lr 0.00054091 rank 2
2022-12-04 05:53:04,960 DEBUG TRAIN Batch 10/2100 loss 24.913589 loss_att 24.485662 loss_ctc 37.119015 loss_rnnt 23.371786 lr 0.00054059 rank 2
2022-12-04 05:53:04,963 DEBUG TRAIN Batch 10/2100 loss 27.219271 loss_att 30.533487 loss_ctc 48.836281 loss_rnnt 23.674160 lr 0.00054082 rank 5
2022-12-04 05:53:04,971 DEBUG TRAIN Batch 10/2100 loss 12.634518 loss_att 14.850147 loss_ctc 26.693090 loss_rnnt 10.316916 lr 0.00054087 rank 6
2022-12-04 05:53:04,973 DEBUG TRAIN Batch 10/2100 loss 9.806395 loss_att 13.363735 loss_ctc 20.997623 loss_rnnt 7.602761 lr 0.00054079 rank 1
2022-12-04 05:53:04,974 DEBUG TRAIN Batch 10/2100 loss 16.028069 loss_att 16.692976 loss_ctc 21.276295 loss_rnnt 15.195322 lr 0.00054083 rank 7
2022-12-04 05:53:04,976 DEBUG TRAIN Batch 10/2100 loss 10.568078 loss_att 13.613821 loss_ctc 23.716328 loss_rnnt 8.205830 lr 0.00054073 rank 0
2022-12-04 05:53:04,975 DEBUG TRAIN Batch 10/2100 loss 19.993498 loss_att 23.515583 loss_ctc 35.997593 loss_rnnt 17.155201 lr 0.00054081 rank 3
2022-12-04 05:53:04,980 DEBUG TRAIN Batch 10/2100 loss 15.416161 loss_att 20.149475 loss_ctc 22.057636 loss_rnnt 13.583968 lr 0.00054087 rank 4
2022-12-04 05:54:17,822 DEBUG TRAIN Batch 10/2200 loss 24.903355 loss_att 31.463268 loss_ctc 40.987617 loss_rnnt 21.446804 lr 0.00054056 rank 6
2022-12-04 05:54:17,823 DEBUG TRAIN Batch 10/2200 loss 18.415316 loss_att 21.342306 loss_ctc 28.932636 loss_rnnt 16.427608 lr 0.00054027 rank 2
2022-12-04 05:54:17,823 DEBUG TRAIN Batch 10/2200 loss 12.003168 loss_att 15.011795 loss_ctc 20.475023 loss_rnnt 10.271862 lr 0.00054047 rank 1
2022-12-04 05:54:17,825 DEBUG TRAIN Batch 10/2200 loss 9.342002 loss_att 12.105551 loss_ctc 16.843161 loss_rnnt 7.789138 lr 0.00054050 rank 5
2022-12-04 05:54:17,826 DEBUG TRAIN Batch 10/2200 loss 9.713336 loss_att 17.460497 loss_ctc 21.204224 loss_rnnt 6.631785 lr 0.00054041 rank 0
2022-12-04 05:54:17,826 DEBUG TRAIN Batch 10/2200 loss 15.648993 loss_att 20.790543 loss_ctc 21.988359 loss_rnnt 13.775433 lr 0.00054055 rank 4
2022-12-04 05:54:17,830 DEBUG TRAIN Batch 10/2200 loss 11.114877 loss_att 12.644258 loss_ctc 21.461597 loss_rnnt 9.429438 lr 0.00054051 rank 7
2022-12-04 05:54:17,831 DEBUG TRAIN Batch 10/2200 loss 17.167692 loss_att 22.745581 loss_ctc 35.242397 loss_rnnt 13.642153 lr 0.00054049 rank 3
2022-12-04 05:55:29,006 DEBUG TRAIN Batch 10/2300 loss 6.909490 loss_att 10.197295 loss_ctc 9.768177 loss_rnnt 5.870770 lr 0.00054018 rank 3
2022-12-04 05:55:29,009 DEBUG TRAIN Batch 10/2300 loss 4.691205 loss_att 8.443466 loss_ctc 9.155596 loss_rnnt 3.345500 lr 0.00054019 rank 5
2022-12-04 05:55:29,010 DEBUG TRAIN Batch 10/2300 loss 10.642985 loss_att 14.327174 loss_ctc 14.391730 loss_rnnt 9.406315 lr 0.00054009 rank 0
2022-12-04 05:55:29,010 DEBUG TRAIN Batch 10/2300 loss 10.484539 loss_att 14.563815 loss_ctc 17.492916 loss_rnnt 8.734234 lr 0.00054024 rank 6
2022-12-04 05:55:29,015 DEBUG TRAIN Batch 10/2300 loss 16.205608 loss_att 19.562765 loss_ctc 24.042164 loss_rnnt 14.489304 lr 0.00054016 rank 1
2022-12-04 05:55:29,015 DEBUG TRAIN Batch 10/2300 loss 15.639160 loss_att 23.108582 loss_ctc 37.739029 loss_rnnt 11.198626 lr 0.00053996 rank 2
2022-12-04 05:55:29,016 DEBUG TRAIN Batch 10/2300 loss 32.067028 loss_att 37.088581 loss_ctc 51.053921 loss_rnnt 28.531134 lr 0.00054020 rank 7
2022-12-04 05:55:29,020 DEBUG TRAIN Batch 10/2300 loss 15.641716 loss_att 21.181183 loss_ctc 27.500963 loss_rnnt 12.952590 lr 0.00054024 rank 4
2022-12-04 05:56:40,983 DEBUG TRAIN Batch 10/2400 loss 12.175311 loss_att 14.611191 loss_ctc 22.743784 loss_rnnt 10.279005 lr 0.00053988 rank 7
2022-12-04 05:56:41,000 DEBUG TRAIN Batch 10/2400 loss 20.804827 loss_att 20.946543 loss_ctc 29.078537 loss_rnnt 19.673323 lr 0.00053978 rank 0
2022-12-04 05:56:41,001 DEBUG TRAIN Batch 10/2400 loss 25.337307 loss_att 27.310909 loss_ctc 41.590191 loss_rnnt 22.775536 lr 0.00053964 rank 2
2022-12-04 05:56:41,001 DEBUG TRAIN Batch 10/2400 loss 14.859639 loss_att 22.385073 loss_ctc 26.474028 loss_rnnt 11.805967 lr 0.00053986 rank 3
2022-12-04 05:56:41,002 DEBUG TRAIN Batch 10/2400 loss 24.878704 loss_att 28.804089 loss_ctc 33.413525 loss_rnnt 22.955650 lr 0.00053984 rank 1
2022-12-04 05:56:41,002 DEBUG TRAIN Batch 10/2400 loss 7.930074 loss_att 10.877284 loss_ctc 16.153608 loss_rnnt 6.244161 lr 0.00053987 rank 5
2022-12-04 05:56:41,004 DEBUG TRAIN Batch 10/2400 loss 9.062186 loss_att 13.173035 loss_ctc 18.196182 loss_rnnt 7.022150 lr 0.00053993 rank 6
2022-12-04 05:56:41,006 DEBUG TRAIN Batch 10/2400 loss 18.068916 loss_att 22.686153 loss_ctc 24.963791 loss_rnnt 16.226152 lr 0.00053992 rank 4
2022-12-04 05:57:57,950 DEBUG TRAIN Batch 10/2500 loss 8.245954 loss_att 10.115110 loss_ctc 14.105718 loss_rnnt 7.090821 lr 0.00053961 rank 6
2022-12-04 05:57:57,956 DEBUG TRAIN Batch 10/2500 loss 9.276086 loss_att 11.543871 loss_ctc 16.198658 loss_rnnt 7.899519 lr 0.00053955 rank 3
2022-12-04 05:57:57,957 DEBUG TRAIN Batch 10/2500 loss 14.322865 loss_att 17.173027 loss_ctc 21.967749 loss_rnnt 12.733513 lr 0.00053956 rank 5
2022-12-04 05:57:57,957 DEBUG TRAIN Batch 10/2500 loss 11.088591 loss_att 10.709298 loss_ctc 14.153259 loss_rnnt 10.755827 lr 0.00053961 rank 4
2022-12-04 05:57:57,958 DEBUG TRAIN Batch 10/2500 loss 15.663654 loss_att 13.985170 loss_ctc 23.754681 loss_rnnt 14.920547 lr 0.00053957 rank 7
2022-12-04 05:57:57,959 DEBUG TRAIN Batch 10/2500 loss 6.817717 loss_att 8.511309 loss_ctc 9.796881 loss_rnnt 6.081777 lr 0.00053933 rank 2
2022-12-04 05:57:57,963 DEBUG TRAIN Batch 10/2500 loss 23.569195 loss_att 26.258207 loss_ctc 40.919689 loss_rnnt 20.717991 lr 0.00053947 rank 0
2022-12-04 05:57:57,964 DEBUG TRAIN Batch 10/2500 loss 12.049058 loss_att 10.746262 loss_ctc 17.146112 loss_rnnt 11.630010 lr 0.00053953 rank 1
2022-12-04 05:59:09,199 DEBUG TRAIN Batch 10/2600 loss 16.129595 loss_att 23.267485 loss_ctc 28.157087 loss_rnnt 13.098351 lr 0.00053915 rank 0
2022-12-04 05:59:09,200 DEBUG TRAIN Batch 10/2600 loss 16.977137 loss_att 19.629530 loss_ctc 36.830284 loss_rnnt 13.799571 lr 0.00053930 rank 6
2022-12-04 05:59:09,203 DEBUG TRAIN Batch 10/2600 loss 16.019478 loss_att 19.411556 loss_ctc 25.248726 loss_rnnt 14.110497 lr 0.00053923 rank 3
2022-12-04 05:59:09,209 DEBUG TRAIN Batch 10/2600 loss 10.290214 loss_att 11.466122 loss_ctc 16.436253 loss_rnnt 9.235559 lr 0.00053924 rank 5
2022-12-04 05:59:09,211 DEBUG TRAIN Batch 10/2600 loss 15.618266 loss_att 20.949167 loss_ctc 25.482565 loss_rnnt 13.236846 lr 0.00053921 rank 1
2022-12-04 05:59:09,214 DEBUG TRAIN Batch 10/2600 loss 10.830594 loss_att 15.174147 loss_ctc 17.355679 loss_rnnt 9.091872 lr 0.00053902 rank 2
2022-12-04 05:59:09,217 DEBUG TRAIN Batch 10/2600 loss 8.243181 loss_att 14.086372 loss_ctc 15.824224 loss_rnnt 6.063737 lr 0.00053930 rank 4
2022-12-04 05:59:09,218 DEBUG TRAIN Batch 10/2600 loss 15.052261 loss_att 19.376081 loss_ctc 24.770370 loss_rnnt 12.891748 lr 0.00053925 rank 7
2022-12-04 06:00:20,177 DEBUG TRAIN Batch 10/2700 loss 7.669321 loss_att 11.101103 loss_ctc 14.967880 loss_rnnt 6.009823 lr 0.00053884 rank 0
2022-12-04 06:00:20,178 DEBUG TRAIN Batch 10/2700 loss 14.800306 loss_att 16.594336 loss_ctc 21.838675 loss_rnnt 13.503051 lr 0.00053899 rank 6
2022-12-04 06:00:20,181 DEBUG TRAIN Batch 10/2700 loss 11.840226 loss_att 13.757343 loss_ctc 16.484898 loss_rnnt 10.837513 lr 0.00053892 rank 3
2022-12-04 06:00:20,183 DEBUG TRAIN Batch 10/2700 loss 4.694494 loss_att 8.050714 loss_ctc 8.928214 loss_rnnt 3.458755 lr 0.00053893 rank 5
2022-12-04 06:00:20,186 DEBUG TRAIN Batch 10/2700 loss 7.428957 loss_att 10.050097 loss_ctc 10.326389 loss_rnnt 6.518404 lr 0.00053898 rank 4
2022-12-04 06:00:20,190 DEBUG TRAIN Batch 10/2700 loss 21.035633 loss_att 26.308575 loss_ctc 29.825338 loss_rnnt 18.809082 lr 0.00053894 rank 7
2022-12-04 06:00:20,217 DEBUG TRAIN Batch 10/2700 loss 8.775878 loss_att 11.586231 loss_ctc 13.224020 loss_rnnt 7.620721 lr 0.00053870 rank 2
2022-12-04 06:00:20,223 DEBUG TRAIN Batch 10/2700 loss 7.530560 loss_att 11.102036 loss_ctc 12.112240 loss_rnnt 6.205373 lr 0.00053890 rank 1
2022-12-04 06:01:33,040 DEBUG TRAIN Batch 10/2800 loss 8.913707 loss_att 12.097380 loss_ctc 15.470485 loss_rnnt 7.402735 lr 0.00053859 rank 1
2022-12-04 06:01:33,049 DEBUG TRAIN Batch 10/2800 loss 18.510134 loss_att 26.331013 loss_ctc 34.118576 loss_rnnt 14.864832 lr 0.00053861 rank 3
2022-12-04 06:01:33,054 DEBUG TRAIN Batch 10/2800 loss 12.102808 loss_att 16.950096 loss_ctc 17.166286 loss_rnnt 10.458220 lr 0.00053853 rank 0
2022-12-04 06:01:33,055 DEBUG TRAIN Batch 10/2800 loss 13.179636 loss_att 16.302263 loss_ctc 19.764507 loss_rnnt 11.677128 lr 0.00053867 rank 4
2022-12-04 06:01:33,056 DEBUG TRAIN Batch 10/2800 loss 9.320349 loss_att 13.577940 loss_ctc 16.077579 loss_rnnt 7.567867 lr 0.00053867 rank 6
2022-12-04 06:01:33,057 DEBUG TRAIN Batch 10/2800 loss 15.656545 loss_att 21.209806 loss_ctc 22.564421 loss_rnnt 13.624843 lr 0.00053862 rank 5
2022-12-04 06:01:33,082 DEBUG TRAIN Batch 10/2800 loss 20.592524 loss_att 27.376581 loss_ctc 40.264675 loss_rnnt 16.612759 lr 0.00053839 rank 2
2022-12-04 06:01:33,090 DEBUG TRAIN Batch 10/2800 loss 10.115644 loss_att 12.819564 loss_ctc 19.689747 loss_rnnt 8.298312 lr 0.00053863 rank 7
2022-12-04 06:02:45,572 DEBUG TRAIN Batch 10/2900 loss 8.935241 loss_att 15.469956 loss_ctc 12.299945 loss_rnnt 7.179670 lr 0.00053821 rank 0
2022-12-04 06:02:45,573 DEBUG TRAIN Batch 10/2900 loss 7.916345 loss_att 11.850345 loss_ctc 13.095785 loss_rnnt 6.438953 lr 0.00053836 rank 6
2022-12-04 06:02:45,576 DEBUG TRAIN Batch 10/2900 loss 5.571651 loss_att 8.288387 loss_ctc 11.038845 loss_rnnt 4.299345 lr 0.00053829 rank 3
2022-12-04 06:02:45,577 DEBUG TRAIN Batch 10/2900 loss 9.970505 loss_att 18.182652 loss_ctc 19.695110 loss_rnnt 7.031461 lr 0.00053808 rank 2
2022-12-04 06:02:45,578 DEBUG TRAIN Batch 10/2900 loss 13.599034 loss_att 16.158981 loss_ctc 19.307621 loss_rnnt 12.325899 lr 0.00053830 rank 5
2022-12-04 06:02:45,582 DEBUG TRAIN Batch 10/2900 loss 16.022848 loss_att 20.634056 loss_ctc 28.434143 loss_rnnt 13.445766 lr 0.00053832 rank 7
2022-12-04 06:02:45,605 DEBUG TRAIN Batch 10/2900 loss 11.972136 loss_att 14.924858 loss_ctc 18.511944 loss_rnnt 10.509618 lr 0.00053836 rank 4
2022-12-04 06:02:45,607 DEBUG TRAIN Batch 10/2900 loss 15.966623 loss_att 20.404345 loss_ctc 27.753967 loss_rnnt 13.507433 lr 0.00053828 rank 1
2022-12-04 06:03:56,965 DEBUG TRAIN Batch 10/3000 loss 21.552032 loss_att 25.286451 loss_ctc 39.402283 loss_rnnt 18.425114 lr 0.00053790 rank 0
2022-12-04 06:03:56,986 DEBUG TRAIN Batch 10/3000 loss 15.118453 loss_att 17.548458 loss_ctc 25.515301 loss_rnnt 13.246206 lr 0.00053805 rank 6
2022-12-04 06:03:56,989 DEBUG TRAIN Batch 10/3000 loss 17.385178 loss_att 23.366835 loss_ctc 36.300716 loss_rnnt 13.666775 lr 0.00053796 rank 1
2022-12-04 06:03:56,989 DEBUG TRAIN Batch 10/3000 loss 7.274078 loss_att 10.728868 loss_ctc 12.554453 loss_rnnt 5.879070 lr 0.00053799 rank 5
2022-12-04 06:03:56,991 DEBUG TRAIN Batch 10/3000 loss 7.988354 loss_att 11.307403 loss_ctc 13.070783 loss_rnnt 6.646886 lr 0.00053798 rank 3
2022-12-04 06:03:56,992 DEBUG TRAIN Batch 10/3000 loss 5.742896 loss_att 8.701703 loss_ctc 9.437453 loss_rnnt 4.658526 lr 0.00053800 rank 7
2022-12-04 06:03:56,994 DEBUG TRAIN Batch 10/3000 loss 15.390708 loss_att 18.873449 loss_ctc 23.401852 loss_rnnt 13.626007 lr 0.00053777 rank 2
2022-12-04 06:03:57,002 DEBUG TRAIN Batch 10/3000 loss 16.538172 loss_att 18.601366 loss_ctc 29.919033 loss_rnnt 14.341417 lr 0.00053805 rank 4
2022-12-04 06:05:08,883 DEBUG TRAIN Batch 10/3100 loss 11.711374 loss_att 15.636841 loss_ctc 21.229137 loss_rnnt 9.657247 lr 0.00053768 rank 5
2022-12-04 06:05:08,883 DEBUG TRAIN Batch 10/3100 loss 12.208990 loss_att 14.535232 loss_ctc 20.435156 loss_rnnt 10.646919 lr 0.00053765 rank 1
2022-12-04 06:05:08,886 DEBUG TRAIN Batch 10/3100 loss 24.772593 loss_att 26.425606 loss_ctc 31.874166 loss_rnnt 23.495115 lr 0.00053769 rank 7
2022-12-04 06:05:08,887 DEBUG TRAIN Batch 10/3100 loss 14.431700 loss_att 19.081919 loss_ctc 23.150253 loss_rnnt 12.339183 lr 0.00053759 rank 0
2022-12-04 06:05:08,887 DEBUG TRAIN Batch 10/3100 loss 11.202610 loss_att 13.876621 loss_ctc 22.457077 loss_rnnt 9.167212 lr 0.00053774 rank 6
2022-12-04 06:05:08,888 DEBUG TRAIN Batch 10/3100 loss 9.219139 loss_att 11.220354 loss_ctc 16.057686 loss_rnnt 7.907089 lr 0.00053767 rank 3
2022-12-04 06:05:08,894 DEBUG TRAIN Batch 10/3100 loss 10.777633 loss_att 13.811405 loss_ctc 18.158033 loss_rnnt 9.186825 lr 0.00053773 rank 4
2022-12-04 06:05:08,939 DEBUG TRAIN Batch 10/3100 loss 12.045086 loss_att 17.115032 loss_ctc 16.665836 loss_rnnt 10.414996 lr 0.00053746 rank 2
2022-12-04 06:06:24,483 DEBUG TRAIN Batch 10/3200 loss 15.411265 loss_att 18.644058 loss_ctc 22.097420 loss_rnnt 13.873220 lr 0.00053738 rank 7
2022-12-04 06:06:24,484 DEBUG TRAIN Batch 10/3200 loss 10.818069 loss_att 17.346201 loss_ctc 24.637304 loss_rnnt 7.669878 lr 0.00053736 rank 3
2022-12-04 06:06:24,485 DEBUG TRAIN Batch 10/3200 loss 18.157074 loss_att 19.263969 loss_ctc 26.679090 loss_rnnt 16.799427 lr 0.00053737 rank 5
2022-12-04 06:06:24,485 DEBUG TRAIN Batch 10/3200 loss 11.737474 loss_att 12.970311 loss_ctc 19.683657 loss_rnnt 10.431416 lr 0.00053734 rank 1
2022-12-04 06:06:24,486 DEBUG TRAIN Batch 10/3200 loss 7.935591 loss_att 7.841525 loss_ctc 11.401145 loss_rnnt 7.492330 lr 0.00053728 rank 0
2022-12-04 06:06:24,488 DEBUG TRAIN Batch 10/3200 loss 15.486652 loss_att 19.947601 loss_ctc 25.628010 loss_rnnt 13.242282 lr 0.00053715 rank 2
2022-12-04 06:06:24,492 DEBUG TRAIN Batch 10/3200 loss 7.278368 loss_att 15.100784 loss_ctc 16.401794 loss_rnnt 4.497428 lr 0.00053742 rank 4
2022-12-04 06:06:24,529 DEBUG TRAIN Batch 10/3200 loss 13.908396 loss_att 21.903915 loss_ctc 27.292900 loss_rnnt 10.524692 lr 0.00053743 rank 6
2022-12-04 06:07:37,505 DEBUG TRAIN Batch 10/3300 loss 28.807516 loss_att 34.104904 loss_ctc 46.154404 loss_rnnt 25.435120 lr 0.00053712 rank 6
2022-12-04 06:07:37,510 DEBUG TRAIN Batch 10/3300 loss 14.135760 loss_att 17.561117 loss_ctc 26.393749 loss_rnnt 11.816291 lr 0.00053707 rank 7
2022-12-04 06:07:37,510 DEBUG TRAIN Batch 10/3300 loss 11.761965 loss_att 15.104925 loss_ctc 26.267132 loss_rnnt 9.159348 lr 0.00053705 rank 3
2022-12-04 06:07:37,512 DEBUG TRAIN Batch 10/3300 loss 13.267081 loss_att 17.007248 loss_ctc 24.834576 loss_rnnt 10.976715 lr 0.00053697 rank 0
2022-12-04 06:07:37,514 DEBUG TRAIN Batch 10/3300 loss 18.538589 loss_att 26.761753 loss_ctc 37.541664 loss_rnnt 14.360212 lr 0.00053706 rank 5
2022-12-04 06:07:37,515 DEBUG TRAIN Batch 10/3300 loss 12.230099 loss_att 17.610743 loss_ctc 27.351986 loss_rnnt 9.137717 lr 0.00053703 rank 1
2022-12-04 06:07:37,515 DEBUG TRAIN Batch 10/3300 loss 26.055321 loss_att 26.832981 loss_ctc 42.236691 loss_rnnt 23.742275 lr 0.00053684 rank 2
2022-12-04 06:07:37,525 DEBUG TRAIN Batch 10/3300 loss 13.687653 loss_att 16.124023 loss_ctc 23.307182 loss_rnnt 11.917774 lr 0.00053711 rank 4
2022-12-04 06:08:49,231 DEBUG TRAIN Batch 10/3400 loss 30.215408 loss_att 31.531580 loss_ctc 38.807522 loss_rnnt 28.806561 lr 0.00053681 rank 6
2022-12-04 06:08:49,232 DEBUG TRAIN Batch 10/3400 loss 9.437839 loss_att 12.365872 loss_ctc 14.865225 loss_rnnt 8.128580 lr 0.00053675 rank 5
2022-12-04 06:08:49,233 DEBUG TRAIN Batch 10/3400 loss 13.644676 loss_att 21.995237 loss_ctc 26.781693 loss_rnnt 10.222961 lr 0.00053666 rank 0
2022-12-04 06:08:49,239 DEBUG TRAIN Batch 10/3400 loss 10.471884 loss_att 14.045053 loss_ctc 21.037516 loss_rnnt 8.348499 lr 0.00053676 rank 7
2022-12-04 06:08:49,243 DEBUG TRAIN Batch 10/3400 loss 10.797995 loss_att 14.671564 loss_ctc 20.843922 loss_rnnt 8.683825 lr 0.00053674 rank 3
2022-12-04 06:08:49,244 DEBUG TRAIN Batch 10/3400 loss 15.468674 loss_att 19.580584 loss_ctc 25.478239 loss_rnnt 13.311684 lr 0.00053680 rank 4
2022-12-04 06:08:49,243 DEBUG TRAIN Batch 10/3400 loss 18.126368 loss_att 21.771339 loss_ctc 24.087158 loss_rnnt 16.602600 lr 0.00053672 rank 1
2022-12-04 06:08:49,248 DEBUG TRAIN Batch 10/3400 loss 20.260521 loss_att 25.944826 loss_ctc 32.196709 loss_rnnt 17.532169 lr 0.00053653 rank 2
2022-12-04 06:10:02,222 DEBUG TRAIN Batch 10/3500 loss 8.900970 loss_att 11.684311 loss_ctc 10.363815 loss_rnnt 8.149256 lr 0.00053635 rank 0
2022-12-04 06:10:02,227 DEBUG TRAIN Batch 10/3500 loss 15.307364 loss_att 21.800051 loss_ctc 26.148933 loss_rnnt 12.563284 lr 0.00053649 rank 4
2022-12-04 06:10:02,232 DEBUG TRAIN Batch 10/3500 loss 22.225006 loss_att 21.710001 loss_ctc 27.310261 loss_rnnt 21.649975 lr 0.00053641 rank 1
2022-12-04 06:10:02,237 DEBUG TRAIN Batch 10/3500 loss 15.350969 loss_att 21.585693 loss_ctc 27.980322 loss_rnnt 12.420112 lr 0.00053622 rank 2
2022-12-04 06:10:02,239 DEBUG TRAIN Batch 10/3500 loss 15.607367 loss_att 21.076084 loss_ctc 32.126915 loss_rnnt 12.311016 lr 0.00053650 rank 6
2022-12-04 06:10:02,239 DEBUG TRAIN Batch 10/3500 loss 7.033463 loss_att 9.396775 loss_ctc 12.585365 loss_rnnt 5.820547 lr 0.00053643 rank 3
2022-12-04 06:10:02,261 DEBUG TRAIN Batch 10/3500 loss 11.050693 loss_att 13.327358 loss_ctc 19.722878 loss_rnnt 9.439068 lr 0.00053645 rank 7
2022-12-04 06:10:02,287 DEBUG TRAIN Batch 10/3500 loss 7.249572 loss_att 10.255733 loss_ctc 17.139217 loss_rnnt 5.329721 lr 0.00053644 rank 5
2022-12-04 06:11:18,082 DEBUG TRAIN Batch 10/3600 loss 12.112380 loss_att 13.966024 loss_ctc 15.440901 loss_rnnt 11.297848 lr 0.00053619 rank 6
2022-12-04 06:11:18,083 DEBUG TRAIN Batch 10/3600 loss 13.977164 loss_att 19.231972 loss_ctc 21.240011 loss_rnnt 11.957823 lr 0.00053604 rank 0
2022-12-04 06:11:18,084 DEBUG TRAIN Batch 10/3600 loss 10.263101 loss_att 15.094183 loss_ctc 25.606133 loss_rnnt 7.251145 lr 0.00053612 rank 3
2022-12-04 06:11:18,084 DEBUG TRAIN Batch 10/3600 loss 27.186443 loss_att 27.823757 loss_ctc 37.319679 loss_rnnt 25.707882 lr 0.00053611 rank 1
2022-12-04 06:11:18,089 DEBUG TRAIN Batch 10/3600 loss 16.412333 loss_att 16.833714 loss_ctc 22.969952 loss_rnnt 15.453707 lr 0.00053591 rank 2
2022-12-04 06:11:18,094 DEBUG TRAIN Batch 10/3600 loss 14.103051 loss_att 17.782789 loss_ctc 24.031744 loss_rnnt 12.043278 lr 0.00053615 rank 7
2022-12-04 06:11:18,094 DEBUG TRAIN Batch 10/3600 loss 16.055851 loss_att 19.352642 loss_ctc 27.216522 loss_rnnt 13.908404 lr 0.00053619 rank 4
2022-12-04 06:11:18,134 DEBUG TRAIN Batch 10/3600 loss 10.121732 loss_att 14.935463 loss_ctc 18.152071 loss_rnnt 8.088273 lr 0.00053613 rank 5
2022-12-04 06:12:29,292 DEBUG TRAIN Batch 10/3700 loss 17.428160 loss_att 15.661172 loss_ctc 27.258724 loss_rnnt 16.470814 lr 0.00053582 rank 3
2022-12-04 06:12:29,295 DEBUG TRAIN Batch 10/3700 loss 14.330032 loss_att 16.103626 loss_ctc 23.504850 loss_rnnt 12.752004 lr 0.00053588 rank 6
2022-12-04 06:12:29,296 DEBUG TRAIN Batch 10/3700 loss 15.597759 loss_att 21.025009 loss_ctc 24.968174 loss_rnnt 13.262920 lr 0.00053574 rank 0
2022-12-04 06:12:29,299 DEBUG TRAIN Batch 10/3700 loss 22.375282 loss_att 25.258261 loss_ctc 34.777878 loss_rnnt 20.145010 lr 0.00053584 rank 7
2022-12-04 06:12:29,300 DEBUG TRAIN Batch 10/3700 loss 27.049374 loss_att 28.798420 loss_ctc 40.014183 loss_rnnt 24.970921 lr 0.00053588 rank 4
2022-12-04 06:12:29,301 DEBUG TRAIN Batch 10/3700 loss 13.817186 loss_att 16.220877 loss_ctc 19.609636 loss_rnnt 12.564123 lr 0.00053560 rank 2
2022-12-04 06:12:29,302 DEBUG TRAIN Batch 10/3700 loss 10.498079 loss_att 13.362526 loss_ctc 16.823145 loss_rnnt 9.081847 lr 0.00053580 rank 1
2022-12-04 06:12:29,304 DEBUG TRAIN Batch 10/3700 loss 10.111338 loss_att 11.941217 loss_ctc 18.413902 loss_rnnt 8.638353 lr 0.00053583 rank 5
2022-12-04 06:13:41,405 DEBUG TRAIN Batch 10/3800 loss 6.886597 loss_att 7.817702 loss_ctc 11.523851 loss_rnnt 6.082074 lr 0.00053530 rank 2
2022-12-04 06:13:41,406 DEBUG TRAIN Batch 10/3800 loss 32.740192 loss_att 41.697655 loss_ctc 55.924164 loss_rnnt 27.857504 lr 0.00053557 rank 6
2022-12-04 06:13:41,406 DEBUG TRAIN Batch 10/3800 loss 9.492389 loss_att 15.936952 loss_ctc 19.116894 loss_rnnt 6.920209 lr 0.00053553 rank 7
2022-12-04 06:13:41,409 DEBUG TRAIN Batch 10/3800 loss 7.362364 loss_att 11.675669 loss_ctc 14.711550 loss_rnnt 5.519811 lr 0.00053551 rank 3
2022-12-04 06:13:41,409 DEBUG TRAIN Batch 10/3800 loss 13.800179 loss_att 14.183174 loss_ctc 21.801855 loss_rnnt 12.656690 lr 0.00053557 rank 4
2022-12-04 06:13:41,411 DEBUG TRAIN Batch 10/3800 loss 10.974873 loss_att 14.417961 loss_ctc 17.336546 loss_rnnt 9.438031 lr 0.00053543 rank 0
2022-12-04 06:13:41,435 DEBUG TRAIN Batch 10/3800 loss 17.923662 loss_att 24.681498 loss_ctc 24.371502 loss_rnnt 15.712383 lr 0.00053552 rank 5
2022-12-04 06:13:41,444 DEBUG TRAIN Batch 10/3800 loss 7.653817 loss_att 13.219646 loss_ctc 12.932175 loss_rnnt 5.836870 lr 0.00053549 rank 1
2022-12-04 06:14:58,182 DEBUG TRAIN Batch 10/3900 loss 14.464395 loss_att 19.234066 loss_ctc 23.850760 loss_rnnt 12.258945 lr 0.00053527 rank 6
2022-12-04 06:14:58,185 DEBUG TRAIN Batch 10/3900 loss 16.428341 loss_att 16.597754 loss_ctc 25.131592 loss_rnnt 15.234024 lr 0.00053518 rank 1
2022-12-04 06:14:58,186 DEBUG TRAIN Batch 10/3900 loss 8.109386 loss_att 11.380733 loss_ctc 15.914313 loss_rnnt 6.414461 lr 0.00053512 rank 0
2022-12-04 06:14:58,190 DEBUG TRAIN Batch 10/3900 loss 8.258915 loss_att 11.708770 loss_ctc 15.229929 loss_rnnt 6.639475 lr 0.00053520 rank 3
2022-12-04 06:14:58,190 DEBUG TRAIN Batch 10/3900 loss 23.221329 loss_att 24.270325 loss_ctc 31.133314 loss_rnnt 21.956600 lr 0.00053521 rank 5
2022-12-04 06:14:58,192 DEBUG TRAIN Batch 10/3900 loss 14.240562 loss_att 15.704533 loss_ctc 18.061882 loss_rnnt 13.438259 lr 0.00053522 rank 7
2022-12-04 06:14:58,193 DEBUG TRAIN Batch 10/3900 loss 12.754564 loss_att 15.941707 loss_ctc 28.866074 loss_rnnt 9.968934 lr 0.00053499 rank 2
2022-12-04 06:14:58,197 DEBUG TRAIN Batch 10/3900 loss 3.530474 loss_att 6.920200 loss_ctc 6.012866 loss_rnnt 2.521543 lr 0.00053526 rank 4
2022-12-04 06:16:12,850 DEBUG TRAIN Batch 10/4000 loss 12.384189 loss_att 15.480633 loss_ctc 19.966639 loss_rnnt 10.753906 lr 0.00053482 rank 0
2022-12-04 06:16:12,852 DEBUG TRAIN Batch 10/4000 loss 22.733122 loss_att 25.045258 loss_ctc 33.231514 loss_rnnt 20.870911 lr 0.00053490 rank 5
2022-12-04 06:16:12,854 DEBUG TRAIN Batch 10/4000 loss 13.592779 loss_att 20.107374 loss_ctc 31.050720 loss_rnnt 9.962134 lr 0.00053492 rank 7
2022-12-04 06:16:12,856 DEBUG TRAIN Batch 10/4000 loss 16.018129 loss_att 20.207123 loss_ctc 28.788139 loss_rnnt 13.477664 lr 0.00053496 rank 6
2022-12-04 06:16:12,857 DEBUG TRAIN Batch 10/4000 loss 10.016305 loss_att 15.231293 loss_ctc 23.062725 loss_rnnt 7.233785 lr 0.00053490 rank 3
2022-12-04 06:16:12,858 DEBUG TRAIN Batch 10/4000 loss 9.415784 loss_att 12.703146 loss_ctc 17.515877 loss_rnnt 7.678298 lr 0.00053468 rank 2
2022-12-04 06:16:12,863 DEBUG TRAIN Batch 10/4000 loss 12.477546 loss_att 17.004116 loss_ctc 20.974270 loss_rnnt 10.439335 lr 0.00053496 rank 4
2022-12-04 06:16:12,866 DEBUG TRAIN Batch 10/4000 loss 21.048080 loss_att 24.884108 loss_ctc 38.667068 loss_rnnt 17.931675 lr 0.00053488 rank 1
2022-12-04 06:17:24,748 DEBUG TRAIN Batch 10/4100 loss 15.333881 loss_att 20.154270 loss_ctc 26.520016 loss_rnnt 12.878319 lr 0.00053451 rank 0
2022-12-04 06:17:24,751 DEBUG TRAIN Batch 10/4100 loss 7.322694 loss_att 12.159760 loss_ctc 14.805324 loss_rnnt 5.357596 lr 0.00053460 rank 5
2022-12-04 06:17:24,753 DEBUG TRAIN Batch 10/4100 loss 17.839325 loss_att 20.245455 loss_ctc 26.044985 loss_rnnt 16.264011 lr 0.00053465 rank 6
2022-12-04 06:17:24,752 DEBUG TRAIN Batch 10/4100 loss 13.312040 loss_att 16.985157 loss_ctc 21.073692 loss_rnnt 11.542530 lr 0.00053459 rank 3
2022-12-04 06:17:24,753 DEBUG TRAIN Batch 10/4100 loss 19.811203 loss_att 24.904881 loss_ctc 28.351507 loss_rnnt 17.653761 lr 0.00053438 rank 2
2022-12-04 06:17:24,754 DEBUG TRAIN Batch 10/4100 loss 13.526102 loss_att 14.710264 loss_ctc 20.570646 loss_rnnt 12.349998 lr 0.00053461 rank 7
2022-12-04 06:17:24,754 DEBUG TRAIN Batch 10/4100 loss 10.754188 loss_att 17.400957 loss_ctc 22.133305 loss_rnnt 7.907618 lr 0.00053457 rank 1
2022-12-04 06:17:24,761 DEBUG TRAIN Batch 10/4100 loss 9.948103 loss_att 13.423424 loss_ctc 18.220774 loss_rnnt 8.150016 lr 0.00053465 rank 4
2022-12-04 06:18:37,559 DEBUG TRAIN Batch 10/4200 loss 11.573027 loss_att 14.426775 loss_ctc 22.690683 loss_rnnt 9.519921 lr 0.00053429 rank 5
2022-12-04 06:18:37,559 DEBUG TRAIN Batch 10/4200 loss 16.295359 loss_att 22.734396 loss_ctc 33.627327 loss_rnnt 12.696621 lr 0.00053421 rank 0
2022-12-04 06:18:37,562 DEBUG TRAIN Batch 10/4200 loss 10.767175 loss_att 11.876238 loss_ctc 19.126499 loss_rnnt 9.430785 lr 0.00053427 rank 1
2022-12-04 06:18:37,563 DEBUG TRAIN Batch 10/4200 loss 13.116955 loss_att 16.130342 loss_ctc 21.929817 loss_rnnt 11.339230 lr 0.00053407 rank 2
2022-12-04 06:18:37,564 DEBUG TRAIN Batch 10/4200 loss 25.038591 loss_att 29.171703 loss_ctc 42.928406 loss_rnnt 21.826660 lr 0.00053435 rank 4
2022-12-04 06:18:37,565 DEBUG TRAIN Batch 10/4200 loss 12.694203 loss_att 11.908463 loss_ctc 17.839233 loss_rnnt 12.165348 lr 0.00053431 rank 7
2022-12-04 06:18:37,585 DEBUG TRAIN Batch 10/4200 loss 15.580122 loss_att 16.367393 loss_ctc 23.856041 loss_rnnt 14.319213 lr 0.00053435 rank 6
2022-12-04 06:18:37,592 DEBUG TRAIN Batch 10/4200 loss 18.175512 loss_att 20.536270 loss_ctc 33.855446 loss_rnnt 15.612701 lr 0.00053428 rank 3
2022-12-04 06:19:54,223 DEBUG TRAIN Batch 10/4300 loss 12.706329 loss_att 18.263477 loss_ctc 26.839539 loss_rnnt 9.710471 lr 0.00053399 rank 5
2022-12-04 06:19:54,225 DEBUG TRAIN Batch 10/4300 loss 10.690234 loss_att 12.263418 loss_ctc 17.240593 loss_rnnt 9.502216 lr 0.00053404 rank 6
2022-12-04 06:19:54,229 DEBUG TRAIN Batch 10/4300 loss 11.233125 loss_att 13.886592 loss_ctc 21.054226 loss_rnnt 9.392951 lr 0.00053398 rank 3
2022-12-04 06:19:54,230 DEBUG TRAIN Batch 10/4300 loss 10.901382 loss_att 17.023808 loss_ctc 20.643833 loss_rnnt 8.377904 lr 0.00053377 rank 2
2022-12-04 06:19:54,234 DEBUG TRAIN Batch 10/4300 loss 17.342722 loss_att 20.467514 loss_ctc 36.482285 loss_rnnt 14.165821 lr 0.00053390 rank 0
2022-12-04 06:19:54,236 DEBUG TRAIN Batch 10/4300 loss 10.390519 loss_att 12.702059 loss_ctc 17.179892 loss_rnnt 9.022962 lr 0.00053400 rank 7
2022-12-04 06:19:54,239 DEBUG TRAIN Batch 10/4300 loss 11.150982 loss_att 12.425304 loss_ctc 17.049137 loss_rnnt 10.109697 lr 0.00053396 rank 1
2022-12-04 06:19:54,240 DEBUG TRAIN Batch 10/4300 loss 6.618684 loss_att 9.668481 loss_ctc 9.177806 loss_rnnt 5.667509 lr 0.00053404 rank 4
2022-12-04 06:21:05,885 DEBUG TRAIN Batch 10/4400 loss 16.194504 loss_att 24.783791 loss_ctc 30.763739 loss_rnnt 12.534081 lr 0.00053368 rank 3
2022-12-04 06:21:05,888 DEBUG TRAIN Batch 10/4400 loss 13.178007 loss_att 21.698059 loss_ctc 23.227291 loss_rnnt 10.134091 lr 0.00053374 rank 6
2022-12-04 06:21:05,890 DEBUG TRAIN Batch 10/4400 loss 16.182928 loss_att 19.868368 loss_ctc 32.976772 loss_rnnt 13.206659 lr 0.00053368 rank 5
2022-12-04 06:21:05,892 DEBUG TRAIN Batch 10/4400 loss 7.734433 loss_att 10.983556 loss_ctc 14.118293 loss_rnnt 6.233427 lr 0.00053347 rank 2
2022-12-04 06:21:05,892 DEBUG TRAIN Batch 10/4400 loss 36.915962 loss_att 38.493069 loss_ctc 66.376816 loss_rnnt 32.672424 lr 0.00053370 rank 7
2022-12-04 06:21:05,893 DEBUG TRAIN Batch 10/4400 loss 5.140462 loss_att 7.860690 loss_ctc 12.015195 loss_rnnt 3.679785 lr 0.00053360 rank 0
2022-12-04 06:21:05,895 DEBUG TRAIN Batch 10/4400 loss 7.717335 loss_att 10.078074 loss_ctc 14.173190 loss_rnnt 6.384406 lr 0.00053374 rank 4
2022-12-04 06:21:05,935 DEBUG TRAIN Batch 10/4400 loss 11.214014 loss_att 11.098714 loss_ctc 14.670074 loss_rnnt 10.776266 lr 0.00053366 rank 1
2022-12-04 06:22:17,897 DEBUG TRAIN Batch 10/4500 loss 11.114021 loss_att 10.366199 loss_ctc 14.805056 loss_rnnt 10.771447 lr 0.00053329 rank 0
2022-12-04 06:22:17,899 DEBUG TRAIN Batch 10/4500 loss 18.290398 loss_att 23.121260 loss_ctc 29.776457 loss_rnnt 15.792750 lr 0.00053344 rank 6
2022-12-04 06:22:17,901 DEBUG TRAIN Batch 10/4500 loss 17.152895 loss_att 22.565207 loss_ctc 29.039474 loss_rnnt 14.485554 lr 0.00053316 rank 2
2022-12-04 06:22:17,902 DEBUG TRAIN Batch 10/4500 loss 6.361404 loss_att 11.808411 loss_ctc 14.327148 loss_rnnt 4.209904 lr 0.00053337 rank 3
2022-12-04 06:22:17,905 DEBUG TRAIN Batch 10/4500 loss 21.027351 loss_att 22.092422 loss_ctc 35.964352 loss_rnnt 18.822737 lr 0.00053338 rank 5
2022-12-04 06:22:17,906 DEBUG TRAIN Batch 10/4500 loss 16.744303 loss_att 20.935995 loss_ctc 23.379141 loss_rnnt 15.021319 lr 0.00053343 rank 4
2022-12-04 06:22:17,908 DEBUG TRAIN Batch 10/4500 loss 8.512119 loss_att 14.275953 loss_ctc 16.281279 loss_rnnt 6.323465 lr 0.00053339 rank 7
2022-12-04 06:22:17,908 DEBUG TRAIN Batch 10/4500 loss 13.358813 loss_att 18.400465 loss_ctc 23.216217 loss_rnnt 11.036162 lr 0.00053335 rank 1
2022-12-04 06:23:37,280 DEBUG TRAIN Batch 10/4600 loss 13.886929 loss_att 17.243357 loss_ctc 26.271702 loss_rnnt 11.564339 lr 0.00053299 rank 0
2022-12-04 06:23:37,283 DEBUG TRAIN Batch 10/4600 loss 11.009958 loss_att 14.166599 loss_ctc 19.222111 loss_rnnt 9.283677 lr 0.00053307 rank 3
2022-12-04 06:23:37,295 DEBUG TRAIN Batch 10/4600 loss 11.875215 loss_att 14.645199 loss_ctc 18.230150 loss_rnnt 10.473892 lr 0.00053313 rank 6
2022-12-04 06:23:37,298 DEBUG TRAIN Batch 10/4600 loss 8.690426 loss_att 12.788518 loss_ctc 15.486464 loss_rnnt 6.964670 lr 0.00053309 rank 7
2022-12-04 06:23:37,300 DEBUG TRAIN Batch 10/4600 loss 12.519881 loss_att 12.656772 loss_ctc 17.719931 loss_rnnt 11.799164 lr 0.00053308 rank 5
2022-12-04 06:23:37,300 DEBUG TRAIN Batch 10/4600 loss 6.849241 loss_att 11.431689 loss_ctc 10.653193 loss_rnnt 5.425557 lr 0.00053313 rank 4
2022-12-04 06:23:37,300 DEBUG TRAIN Batch 10/4600 loss 21.943205 loss_att 24.235270 loss_ctc 28.642151 loss_rnnt 20.591599 lr 0.00053305 rank 1
2022-12-04 06:23:37,319 DEBUG TRAIN Batch 10/4600 loss 8.252251 loss_att 12.437984 loss_ctc 16.552353 loss_rnnt 6.308424 lr 0.00053286 rank 2
2022-12-04 06:24:50,446 DEBUG TRAIN Batch 10/4700 loss 23.859608 loss_att 31.414835 loss_ctc 39.616997 loss_rnnt 20.247578 lr 0.00053269 rank 0
2022-12-04 06:24:50,458 DEBUG TRAIN Batch 10/4700 loss 12.248349 loss_att 15.467562 loss_ctc 15.198805 loss_rnnt 11.211113 lr 0.00053277 rank 3
2022-12-04 06:24:50,459 DEBUG TRAIN Batch 10/4700 loss 6.223609 loss_att 11.847909 loss_ctc 12.124400 loss_rnnt 4.311976 lr 0.00053277 rank 5
2022-12-04 06:24:50,460 DEBUG TRAIN Batch 10/4700 loss 11.633234 loss_att 15.214084 loss_ctc 24.822752 loss_rnnt 9.158463 lr 0.00053275 rank 1
2022-12-04 06:24:50,461 DEBUG TRAIN Batch 10/4700 loss 9.092957 loss_att 13.664419 loss_ctc 16.395390 loss_rnnt 7.205006 lr 0.00053283 rank 6
2022-12-04 06:24:50,464 DEBUG TRAIN Batch 10/4700 loss 20.852009 loss_att 21.748629 loss_ctc 28.271496 loss_rnnt 19.683418 lr 0.00053283 rank 4
2022-12-04 06:24:50,466 DEBUG TRAIN Batch 10/4700 loss 9.928356 loss_att 13.924835 loss_ctc 15.958701 loss_rnnt 8.325014 lr 0.00053256 rank 2
2022-12-04 06:24:50,469 DEBUG TRAIN Batch 10/4700 loss 17.521708 loss_att 21.771132 loss_ctc 29.854023 loss_rnnt 15.027514 lr 0.00053279 rank 7
2022-12-04 06:26:02,418 DEBUG TRAIN Batch 10/4800 loss 10.566200 loss_att 13.545147 loss_ctc 20.579369 loss_rnnt 8.635322 lr 0.00053253 rank 6
2022-12-04 06:26:02,421 DEBUG TRAIN Batch 10/4800 loss 16.822298 loss_att 23.080395 loss_ctc 33.189541 loss_rnnt 13.388380 lr 0.00053247 rank 5
2022-12-04 06:26:02,425 DEBUG TRAIN Batch 10/4800 loss 13.579012 loss_att 19.787632 loss_ctc 20.547928 loss_rnnt 11.408098 lr 0.00053246 rank 3
2022-12-04 06:26:02,425 DEBUG TRAIN Batch 10/4800 loss 17.444715 loss_att 21.272209 loss_ctc 33.958694 loss_rnnt 14.477354 lr 0.00053252 rank 4
2022-12-04 06:26:02,426 DEBUG TRAIN Batch 10/4800 loss 13.062677 loss_att 15.643179 loss_ctc 25.149294 loss_rnnt 10.935028 lr 0.00053239 rank 0
2022-12-04 06:26:02,431 DEBUG TRAIN Batch 10/4800 loss 14.026765 loss_att 17.199219 loss_ctc 25.097992 loss_rnnt 11.916111 lr 0.00053245 rank 1
2022-12-04 06:26:02,437 DEBUG TRAIN Batch 10/4800 loss 11.053933 loss_att 15.244186 loss_ctc 16.324703 loss_rnnt 9.513113 lr 0.00053248 rank 7
2022-12-04 06:26:02,482 DEBUG TRAIN Batch 10/4800 loss 11.165608 loss_att 13.998045 loss_ctc 18.152252 loss_rnnt 9.667568 lr 0.00053226 rank 2
2022-12-04 06:27:14,830 DEBUG TRAIN Batch 10/4900 loss 20.197094 loss_att 21.281187 loss_ctc 34.804241 loss_rnnt 18.032654 lr 0.00053217 rank 5
2022-12-04 06:27:14,831 DEBUG TRAIN Batch 10/4900 loss 8.207068 loss_att 12.687462 loss_ctc 14.780008 loss_rnnt 6.434598 lr 0.00053218 rank 7
2022-12-04 06:27:14,833 DEBUG TRAIN Batch 10/4900 loss 10.707739 loss_att 15.512874 loss_ctc 26.851952 loss_rnnt 7.594151 lr 0.00053195 rank 2
2022-12-04 06:27:14,833 DEBUG TRAIN Batch 10/4900 loss 18.998051 loss_att 20.465405 loss_ctc 31.172445 loss_rnnt 17.081327 lr 0.00053216 rank 3
2022-12-04 06:27:14,833 DEBUG TRAIN Batch 10/4900 loss 18.310171 loss_att 18.931656 loss_ctc 30.239056 loss_rnnt 16.595356 lr 0.00053223 rank 6
2022-12-04 06:27:14,836 DEBUG TRAIN Batch 10/4900 loss 8.831702 loss_att 13.775166 loss_ctc 14.637436 loss_rnnt 7.068912 lr 0.00053208 rank 0
2022-12-04 06:27:14,836 DEBUG TRAIN Batch 10/4900 loss 11.398796 loss_att 17.118441 loss_ctc 22.802414 loss_rnnt 8.734385 lr 0.00053214 rank 1
2022-12-04 06:27:14,842 DEBUG TRAIN Batch 10/4900 loss 12.418460 loss_att 16.377914 loss_ctc 26.562271 loss_rnnt 9.740728 lr 0.00053222 rank 4
2022-12-04 06:28:33,748 DEBUG TRAIN Batch 10/5000 loss 7.173327 loss_att 9.063765 loss_ctc 11.496616 loss_rnnt 6.218801 lr 0.00053188 rank 7
2022-12-04 06:28:33,754 DEBUG TRAIN Batch 10/5000 loss 9.412307 loss_att 11.532228 loss_ctc 13.310079 loss_rnnt 8.468619 lr 0.00053192 rank 6
2022-12-04 06:28:33,756 DEBUG TRAIN Batch 10/5000 loss 12.115878 loss_att 14.195289 loss_ctc 15.768508 loss_rnnt 11.212978 lr 0.00053187 rank 5
2022-12-04 06:28:33,756 DEBUG TRAIN Batch 10/5000 loss 15.172821 loss_att 18.637068 loss_ctc 24.012569 loss_rnnt 13.301338 lr 0.00053178 rank 0
2022-12-04 06:28:33,757 DEBUG TRAIN Batch 10/5000 loss 13.590752 loss_att 13.720350 loss_ctc 20.214073 loss_rnnt 12.681723 lr 0.00053186 rank 3
2022-12-04 06:28:33,758 DEBUG TRAIN Batch 10/5000 loss 10.066153 loss_att 13.232922 loss_ctc 19.536152 loss_rnnt 8.170132 lr 0.00053184 rank 1
2022-12-04 06:28:33,766 DEBUG TRAIN Batch 10/5000 loss 12.446614 loss_att 15.821049 loss_ctc 22.509563 loss_rnnt 10.430000 lr 0.00053165 rank 2
2022-12-04 06:28:33,806 DEBUG TRAIN Batch 10/5000 loss 11.307505 loss_att 12.575469 loss_ctc 14.177625 loss_rnnt 10.671228 lr 0.00053192 rank 4
2022-12-04 06:29:45,871 DEBUG TRAIN Batch 10/5100 loss 11.392923 loss_att 13.181095 loss_ctc 18.114992 loss_rnnt 10.139012 lr 0.00053148 rank 0
2022-12-04 06:29:45,877 DEBUG TRAIN Batch 10/5100 loss 13.521555 loss_att 16.536205 loss_ctc 16.195608 loss_rnnt 12.562084 lr 0.00053162 rank 6
2022-12-04 06:29:45,878 DEBUG TRAIN Batch 10/5100 loss 29.835545 loss_att 31.239899 loss_ctc 45.437859 loss_rnnt 27.474365 lr 0.00053157 rank 5
2022-12-04 06:29:45,879 DEBUG TRAIN Batch 10/5100 loss 14.518313 loss_att 19.381021 loss_ctc 28.385984 loss_rnnt 11.696749 lr 0.00053156 rank 3
2022-12-04 06:29:45,881 DEBUG TRAIN Batch 10/5100 loss 9.679834 loss_att 10.095554 loss_ctc 12.449405 loss_rnnt 9.227415 lr 0.00053162 rank 4
2022-12-04 06:29:45,884 DEBUG TRAIN Batch 10/5100 loss 10.884748 loss_att 16.172407 loss_ctc 21.678854 loss_rnnt 8.388000 lr 0.00053158 rank 7
2022-12-04 06:29:45,885 DEBUG TRAIN Batch 10/5100 loss 8.399946 loss_att 12.209600 loss_ctc 12.636535 loss_rnnt 7.073137 lr 0.00053135 rank 2
2022-12-04 06:29:45,927 DEBUG TRAIN Batch 10/5100 loss 26.369144 loss_att 29.778433 loss_ctc 41.203209 loss_rnnt 23.709412 lr 0.00053154 rank 1
2022-12-04 06:30:57,992 DEBUG TRAIN Batch 10/5200 loss 8.462418 loss_att 12.611232 loss_ctc 13.303513 loss_rnnt 6.987175 lr 0.00053132 rank 6
2022-12-04 06:30:57,998 DEBUG TRAIN Batch 10/5200 loss 6.053720 loss_att 8.425728 loss_ctc 10.925816 loss_rnnt 4.929705 lr 0.00053127 rank 5
2022-12-04 06:30:57,998 DEBUG TRAIN Batch 10/5200 loss 7.365487 loss_att 9.850750 loss_ctc 11.974463 loss_rnnt 6.253904 lr 0.00053126 rank 3
2022-12-04 06:30:57,998 DEBUG TRAIN Batch 10/5200 loss 20.061708 loss_att 24.684830 loss_ctc 38.883751 loss_rnnt 16.627480 lr 0.00053118 rank 0
2022-12-04 06:30:58,001 DEBUG TRAIN Batch 10/5200 loss 13.994339 loss_att 16.691509 loss_ctc 31.738087 loss_rnnt 11.089071 lr 0.00053105 rank 2
2022-12-04 06:30:58,001 DEBUG TRAIN Batch 10/5200 loss 13.955902 loss_att 14.774956 loss_ctc 21.268751 loss_rnnt 12.817045 lr 0.00053132 rank 4
2022-12-04 06:30:58,001 DEBUG TRAIN Batch 10/5200 loss 14.542053 loss_att 18.613293 loss_ctc 27.412352 loss_rnnt 12.011765 lr 0.00053128 rank 7
2022-12-04 06:30:58,004 DEBUG TRAIN Batch 10/5200 loss 7.816400 loss_att 14.807770 loss_ctc 16.138275 loss_rnnt 5.308542 lr 0.00053124 rank 1
2022-12-04 06:32:11,593 DEBUG TRAIN Batch 10/5300 loss 13.330809 loss_att 16.594048 loss_ctc 24.043911 loss_rnnt 11.249747 lr 0.00053097 rank 5
2022-12-04 06:32:11,594 DEBUG TRAIN Batch 10/5300 loss 8.094275 loss_att 13.800742 loss_ctc 17.816189 loss_rnnt 5.656725 lr 0.00053102 rank 6
2022-12-04 06:32:11,596 DEBUG TRAIN Batch 10/5300 loss 10.917005 loss_att 15.310523 loss_ctc 21.761856 loss_rnnt 8.592321 lr 0.00053075 rank 2
2022-12-04 06:32:11,598 DEBUG TRAIN Batch 10/5300 loss 23.901876 loss_att 25.235804 loss_ctc 37.360428 loss_rnnt 21.840620 lr 0.00053088 rank 0
2022-12-04 06:32:11,599 DEBUG TRAIN Batch 10/5300 loss 21.483135 loss_att 23.547827 loss_ctc 33.919647 loss_rnnt 19.411997 lr 0.00053096 rank 3
2022-12-04 06:32:11,606 DEBUG TRAIN Batch 10/5300 loss 32.856789 loss_att 43.679356 loss_ctc 57.184479 loss_rnnt 27.448584 lr 0.00053094 rank 1
2022-12-04 06:32:11,622 DEBUG TRAIN Batch 10/5300 loss 23.875916 loss_att 33.629227 loss_ctc 39.956818 loss_rnnt 19.781134 lr 0.00053098 rank 7
2022-12-04 06:32:11,639 DEBUG TRAIN Batch 10/5300 loss 4.406468 loss_att 7.789084 loss_ctc 10.578600 loss_rnnt 2.906994 lr 0.00053102 rank 4
2022-12-04 06:33:28,787 DEBUG TRAIN Batch 10/5400 loss 15.756086 loss_att 20.224840 loss_ctc 20.753050 loss_rnnt 14.196073 lr 0.00053072 rank 6
2022-12-04 06:33:28,788 DEBUG TRAIN Batch 10/5400 loss 9.246886 loss_att 16.717350 loss_ctc 17.580032 loss_rnnt 6.641707 lr 0.00053066 rank 3
2022-12-04 06:33:28,788 DEBUG TRAIN Batch 10/5400 loss 17.396149 loss_att 25.296532 loss_ctc 27.898352 loss_rnnt 14.415779 lr 0.00053058 rank 0
2022-12-04 06:33:28,790 DEBUG TRAIN Batch 10/5400 loss 14.944807 loss_att 18.247456 loss_ctc 24.108765 loss_rnnt 13.062416 lr 0.00053067 rank 5
2022-12-04 06:33:28,795 DEBUG TRAIN Batch 10/5400 loss 23.443562 loss_att 27.212173 loss_ctc 33.925255 loss_rnnt 21.292282 lr 0.00053068 rank 7
2022-12-04 06:33:28,796 DEBUG TRAIN Batch 10/5400 loss 11.676333 loss_att 14.011038 loss_ctc 19.752121 loss_rnnt 10.132621 lr 0.00053046 rank 2
2022-12-04 06:33:28,797 DEBUG TRAIN Batch 10/5400 loss 13.620375 loss_att 15.916200 loss_ctc 23.707642 loss_rnnt 11.816240 lr 0.00053064 rank 1
2022-12-04 06:33:28,801 DEBUG TRAIN Batch 10/5400 loss 19.342636 loss_att 26.558830 loss_ctc 35.472015 loss_rnnt 15.748811 lr 0.00053072 rank 4
2022-12-04 06:34:40,664 DEBUG TRAIN Batch 10/5500 loss 11.540469 loss_att 15.999380 loss_ctc 20.173550 loss_rnnt 9.497610 lr 0.00053043 rank 6
2022-12-04 06:34:40,669 DEBUG TRAIN Batch 10/5500 loss 18.433613 loss_att 20.385054 loss_ctc 29.676504 loss_rnnt 16.544273 lr 0.00053036 rank 3
2022-12-04 06:34:40,671 DEBUG TRAIN Batch 10/5500 loss 15.736966 loss_att 19.128689 loss_ctc 27.169783 loss_rnnt 13.534246 lr 0.00053034 rank 1
2022-12-04 06:34:40,672 DEBUG TRAIN Batch 10/5500 loss 11.790605 loss_att 16.293530 loss_ctc 21.855202 loss_rnnt 9.548073 lr 0.00053029 rank 0
2022-12-04 06:34:40,674 DEBUG TRAIN Batch 10/5500 loss 10.790141 loss_att 15.191337 loss_ctc 21.387274 loss_rnnt 8.496950 lr 0.00053016 rank 2
2022-12-04 06:34:40,674 DEBUG TRAIN Batch 10/5500 loss 12.184526 loss_att 14.600182 loss_ctc 21.507448 loss_rnnt 10.458340 lr 0.00053037 rank 5
2022-12-04 06:34:40,681 DEBUG TRAIN Batch 10/5500 loss 15.834764 loss_att 18.546181 loss_ctc 23.563847 loss_rnnt 14.261938 lr 0.00053042 rank 4
2022-12-04 06:34:40,681 DEBUG TRAIN Batch 10/5500 loss 18.742683 loss_att 20.662573 loss_ctc 25.728090 loss_rnnt 17.427319 lr 0.00053038 rank 7
2022-12-04 06:35:54,134 DEBUG TRAIN Batch 10/5600 loss 9.802235 loss_att 13.279490 loss_ctc 20.379841 loss_rnnt 7.696436 lr 0.00053013 rank 6
2022-12-04 06:35:54,139 DEBUG TRAIN Batch 10/5600 loss 12.382309 loss_att 16.912106 loss_ctc 20.137230 loss_rnnt 10.442360 lr 0.00053007 rank 5
2022-12-04 06:35:54,139 DEBUG TRAIN Batch 10/5600 loss 13.591107 loss_att 16.058151 loss_ctc 20.735151 loss_rnnt 12.145160 lr 0.00052986 rank 2
2022-12-04 06:35:54,141 DEBUG TRAIN Batch 10/5600 loss 15.128267 loss_att 18.897963 loss_ctc 23.023611 loss_rnnt 13.321615 lr 0.00053009 rank 7
2022-12-04 06:35:54,142 DEBUG TRAIN Batch 10/5600 loss 8.009935 loss_att 8.794327 loss_ctc 13.102775 loss_rnnt 7.174011 lr 0.00053006 rank 3
2022-12-04 06:35:54,144 DEBUG TRAIN Batch 10/5600 loss 10.467474 loss_att 13.034416 loss_ctc 20.735233 loss_rnnt 8.585052 lr 0.00052999 rank 0
2022-12-04 06:35:54,174 DEBUG TRAIN Batch 10/5600 loss 12.327237 loss_att 16.559971 loss_ctc 20.240013 loss_rnnt 10.425653 lr 0.00053012 rank 4
2022-12-04 06:35:54,176 DEBUG TRAIN Batch 10/5600 loss 10.152836 loss_att 14.486083 loss_ctc 15.829004 loss_rnnt 8.529364 lr 0.00053005 rank 1
2022-12-04 06:37:10,335 DEBUG TRAIN Batch 10/5700 loss 11.892351 loss_att 12.000264 loss_ctc 17.823696 loss_rnnt 11.079923 lr 0.00052983 rank 6
2022-12-04 06:37:10,337 DEBUG TRAIN Batch 10/5700 loss 12.090805 loss_att 13.028787 loss_ctc 18.897135 loss_rnnt 10.995698 lr 0.00052969 rank 0
2022-12-04 06:37:10,340 DEBUG TRAIN Batch 10/5700 loss 12.578172 loss_att 15.847370 loss_ctc 25.403076 loss_rnnt 10.214344 lr 0.00052977 rank 3
2022-12-04 06:37:10,340 DEBUG TRAIN Batch 10/5700 loss 13.962328 loss_att 18.113775 loss_ctc 25.305176 loss_rnnt 11.619658 lr 0.00052975 rank 1
2022-12-04 06:37:10,342 DEBUG TRAIN Batch 10/5700 loss 8.699374 loss_att 13.734511 loss_ctc 14.000670 loss_rnnt 6.985507 lr 0.00052979 rank 7
2022-12-04 06:37:10,344 DEBUG TRAIN Batch 10/5700 loss 12.227531 loss_att 13.195618 loss_ctc 17.097706 loss_rnnt 11.384559 lr 0.00052956 rank 2
2022-12-04 06:37:10,367 DEBUG TRAIN Batch 10/5700 loss 19.373560 loss_att 25.379791 loss_ctc 29.128273 loss_rnnt 16.871685 lr 0.00052978 rank 5
2022-12-04 06:37:10,370 DEBUG TRAIN Batch 10/5700 loss 14.129195 loss_att 16.621178 loss_ctc 23.648228 loss_rnnt 12.361595 lr 0.00052983 rank 4
2022-12-04 06:38:22,605 DEBUG TRAIN Batch 10/5800 loss 19.873358 loss_att 24.830832 loss_ctc 35.999626 loss_rnnt 16.731693 lr 0.00052939 rank 0
2022-12-04 06:38:22,606 DEBUG TRAIN Batch 10/5800 loss 19.045866 loss_att 21.793114 loss_ctc 30.106731 loss_rnnt 17.021633 lr 0.00052945 rank 1
2022-12-04 06:38:22,608 DEBUG TRAIN Batch 10/5800 loss 14.635540 loss_att 19.602015 loss_ctc 24.645817 loss_rnnt 12.307541 lr 0.00052927 rank 2
2022-12-04 06:38:22,611 DEBUG TRAIN Batch 10/5800 loss 12.464076 loss_att 16.660759 loss_ctc 21.327019 loss_rnnt 10.443013 lr 0.00052953 rank 6
2022-12-04 06:38:22,612 DEBUG TRAIN Batch 10/5800 loss 7.773911 loss_att 12.828791 loss_ctc 12.969999 loss_rnnt 6.070123 lr 0.00052947 rank 3
2022-12-04 06:38:22,613 DEBUG TRAIN Batch 10/5800 loss 6.049676 loss_att 10.116711 loss_ctc 12.330454 loss_rnnt 4.398832 lr 0.00052953 rank 4
2022-12-04 06:38:22,617 DEBUG TRAIN Batch 10/5800 loss 13.455349 loss_att 14.780657 loss_ctc 22.528198 loss_rnnt 11.980574 lr 0.00052949 rank 7
2022-12-04 06:38:22,662 DEBUG TRAIN Batch 10/5800 loss 13.832066 loss_att 17.079769 loss_ctc 21.816864 loss_rnnt 12.117884 lr 0.00052948 rank 5
2022-12-04 06:39:36,041 DEBUG TRAIN Batch 10/5900 loss 7.371022 loss_att 9.671390 loss_ctc 13.418698 loss_rnnt 6.104592 lr 0.00052919 rank 7
2022-12-04 06:39:36,050 DEBUG TRAIN Batch 10/5900 loss 6.463822 loss_att 8.550793 loss_ctc 12.330633 loss_rnnt 5.264187 lr 0.00052917 rank 3
2022-12-04 06:39:36,052 DEBUG TRAIN Batch 10/5900 loss 16.369850 loss_att 29.020042 loss_ctc 28.225090 loss_rnnt 12.259112 lr 0.00052924 rank 6
2022-12-04 06:39:36,053 DEBUG TRAIN Batch 10/5900 loss 12.668762 loss_att 13.354430 loss_ctc 19.184492 loss_rnnt 11.662865 lr 0.00052918 rank 5
2022-12-04 06:39:36,056 DEBUG TRAIN Batch 10/5900 loss 11.919750 loss_att 15.293919 loss_ctc 22.694235 loss_rnnt 9.808319 lr 0.00052910 rank 0
2022-12-04 06:39:36,058 DEBUG TRAIN Batch 10/5900 loss 2.812709 loss_att 5.953209 loss_ctc 3.798921 loss_rnnt 2.053114 lr 0.00052916 rank 1
2022-12-04 06:39:36,064 DEBUG TRAIN Batch 10/5900 loss 15.190878 loss_att 17.435539 loss_ctc 28.967121 loss_rnnt 12.905113 lr 0.00052923 rank 4
2022-12-04 06:39:36,094 DEBUG TRAIN Batch 10/5900 loss 24.516117 loss_att 29.869808 loss_ctc 42.000854 loss_rnnt 21.114079 lr 0.00052897 rank 2
2022-12-04 06:40:49,031 DEBUG TRAIN Batch 10/6000 loss 14.015781 loss_att 19.610369 loss_ctc 27.350470 loss_rnnt 11.118904 lr 0.00052889 rank 5
2022-12-04 06:40:49,032 DEBUG TRAIN Batch 10/6000 loss 11.038677 loss_att 15.795508 loss_ctc 13.985156 loss_rnnt 9.694447 lr 0.00052880 rank 0
2022-12-04 06:40:49,035 DEBUG TRAIN Batch 10/6000 loss 22.206028 loss_att 28.282833 loss_ctc 34.183033 loss_rnnt 19.393734 lr 0.00052894 rank 6
2022-12-04 06:40:49,037 DEBUG TRAIN Batch 10/6000 loss 20.203043 loss_att 20.993706 loss_ctc 37.667263 loss_rnnt 17.716349 lr 0.00052890 rank 7
2022-12-04 06:40:49,041 DEBUG TRAIN Batch 10/6000 loss 14.159187 loss_att 17.727827 loss_ctc 26.739193 loss_rnnt 11.768126 lr 0.00052888 rank 3
2022-12-04 06:40:49,040 DEBUG TRAIN Batch 10/6000 loss 11.286862 loss_att 17.153269 loss_ctc 20.679871 loss_rnnt 8.861179 lr 0.00052894 rank 4
2022-12-04 06:40:49,047 DEBUG TRAIN Batch 10/6000 loss 15.789302 loss_att 21.358383 loss_ctc 26.220284 loss_rnnt 13.284689 lr 0.00052867 rank 2
2022-12-04 06:40:49,087 DEBUG TRAIN Batch 10/6000 loss 13.667436 loss_att 17.060856 loss_ctc 22.822380 loss_rnnt 11.768092 lr 0.00052886 rank 1
2022-12-04 06:42:06,197 DEBUG TRAIN Batch 10/6100 loss 9.259857 loss_att 13.643656 loss_ctc 13.771124 loss_rnnt 7.781596 lr 0.00052850 rank 0
2022-12-04 06:42:06,199 DEBUG TRAIN Batch 10/6100 loss 18.607021 loss_att 21.059887 loss_ctc 33.791489 loss_rnnt 16.091852 lr 0.00052864 rank 6
2022-12-04 06:42:06,200 DEBUG TRAIN Batch 10/6100 loss 14.165762 loss_att 20.655762 loss_ctc 29.049599 loss_rnnt 10.883251 lr 0.00052856 rank 1
2022-12-04 06:42:06,201 DEBUG TRAIN Batch 10/6100 loss 10.408022 loss_att 13.706726 loss_ctc 14.779191 loss_rnnt 9.165458 lr 0.00052860 rank 7
2022-12-04 06:42:06,202 DEBUG TRAIN Batch 10/6100 loss 7.817711 loss_att 9.182384 loss_ctc 12.566643 loss_rnnt 6.911585 lr 0.00052858 rank 3
2022-12-04 06:42:06,207 DEBUG TRAIN Batch 10/6100 loss 22.496359 loss_att 27.406654 loss_ctc 35.647045 loss_rnnt 19.760876 lr 0.00052838 rank 2
2022-12-04 06:42:06,208 DEBUG TRAIN Batch 10/6100 loss 10.818380 loss_att 16.135014 loss_ctc 18.490200 loss_rnnt 8.732145 lr 0.00052859 rank 5
2022-12-04 06:42:06,212 DEBUG TRAIN Batch 10/6100 loss 10.434374 loss_att 16.349857 loss_ctc 20.467566 loss_rnnt 7.913519 lr 0.00052864 rank 4
2022-12-04 06:43:18,402 DEBUG TRAIN Batch 10/6200 loss 11.569424 loss_att 13.915630 loss_ctc 21.162334 loss_rnnt 9.821128 lr 0.00052821 rank 0
2022-12-04 06:43:18,406 DEBUG TRAIN Batch 10/6200 loss 12.632651 loss_att 13.685291 loss_ctc 16.241816 loss_rnnt 11.940902 lr 0.00052808 rank 2
2022-12-04 06:43:18,406 DEBUG TRAIN Batch 10/6200 loss 14.044343 loss_att 19.619686 loss_ctc 27.010048 loss_rnnt 11.200513 lr 0.00052835 rank 6
2022-12-04 06:43:18,406 DEBUG TRAIN Batch 10/6200 loss 10.889982 loss_att 15.202093 loss_ctc 18.653086 loss_rnnt 8.992480 lr 0.00052829 rank 3
2022-12-04 06:43:18,407 DEBUG TRAIN Batch 10/6200 loss 19.657204 loss_att 24.980185 loss_ctc 36.552757 loss_rnnt 16.339867 lr 0.00052830 rank 5
2022-12-04 06:43:18,413 DEBUG TRAIN Batch 10/6200 loss 7.638420 loss_att 10.952128 loss_ctc 14.294394 loss_rnnt 6.088214 lr 0.00052831 rank 7
2022-12-04 06:43:18,424 DEBUG TRAIN Batch 10/6200 loss 16.722979 loss_att 20.133156 loss_ctc 26.762646 loss_rnnt 14.702321 lr 0.00052835 rank 4
2022-12-04 06:43:18,453 DEBUG TRAIN Batch 10/6200 loss 9.307385 loss_att 11.921690 loss_ctc 14.239795 loss_rnnt 8.126869 lr 0.00052827 rank 1
2022-12-04 06:44:30,817 DEBUG TRAIN Batch 10/6300 loss 16.850418 loss_att 17.854733 loss_ctc 22.428448 loss_rnnt 15.905817 lr 0.00052800 rank 5
2022-12-04 06:44:30,832 DEBUG TRAIN Batch 10/6300 loss 9.080571 loss_att 16.496605 loss_ctc 20.419830 loss_rnnt 6.085463 lr 0.00052797 rank 1
2022-12-04 06:44:30,835 DEBUG TRAIN Batch 10/6300 loss 15.773804 loss_att 19.574257 loss_ctc 29.296703 loss_rnnt 13.210659 lr 0.00052805 rank 6
2022-12-04 06:44:30,835 DEBUG TRAIN Batch 10/6300 loss 25.435690 loss_att 30.129862 loss_ctc 42.240948 loss_rnnt 22.256155 lr 0.00052799 rank 3
2022-12-04 06:44:30,835 DEBUG TRAIN Batch 10/6300 loss 11.908517 loss_att 13.272392 loss_ctc 18.223955 loss_rnnt 10.793683 lr 0.00052792 rank 0
2022-12-04 06:44:30,837 DEBUG TRAIN Batch 10/6300 loss 16.826847 loss_att 20.625765 loss_ctc 26.104635 loss_rnnt 14.830025 lr 0.00052779 rank 2
2022-12-04 06:44:30,842 DEBUG TRAIN Batch 10/6300 loss 15.136326 loss_att 18.639177 loss_ctc 26.015388 loss_rnnt 12.985214 lr 0.00052801 rank 7
2022-12-04 06:44:30,848 DEBUG TRAIN Batch 10/6300 loss 22.710230 loss_att 23.859568 loss_ctc 42.483807 loss_rnnt 19.843885 lr 0.00052805 rank 4
2022-12-04 06:45:47,390 DEBUG TRAIN Batch 10/6400 loss 10.178404 loss_att 14.764553 loss_ctc 23.566093 loss_rnnt 7.476148 lr 0.00052768 rank 1
2022-12-04 06:45:47,394 DEBUG TRAIN Batch 10/6400 loss 14.864071 loss_att 17.996359 loss_ctc 28.608036 loss_rnnt 12.405084 lr 0.00052771 rank 5
2022-12-04 06:45:47,393 DEBUG TRAIN Batch 10/6400 loss 14.598082 loss_att 18.546473 loss_ctc 28.741188 loss_rnnt 11.922656 lr 0.00052770 rank 3
2022-12-04 06:45:47,395 DEBUG TRAIN Batch 10/6400 loss 8.633018 loss_att 15.387703 loss_ctc 15.716506 loss_rnnt 6.337616 lr 0.00052762 rank 0
2022-12-04 06:45:47,396 DEBUG TRAIN Batch 10/6400 loss 13.047676 loss_att 18.799072 loss_ctc 20.193195 loss_rnnt 10.944660 lr 0.00052749 rank 2
2022-12-04 06:45:47,402 DEBUG TRAIN Batch 10/6400 loss 17.936378 loss_att 22.735004 loss_ctc 25.360350 loss_rnnt 15.986788 lr 0.00052776 rank 6
2022-12-04 06:45:47,403 DEBUG TRAIN Batch 10/6400 loss 13.927777 loss_att 17.426472 loss_ctc 24.475439 loss_rnnt 11.821684 lr 0.00052772 rank 7
2022-12-04 06:45:47,425 DEBUG TRAIN Batch 10/6400 loss 15.076101 loss_att 18.992559 loss_ctc 22.155090 loss_rnnt 13.348944 lr 0.00052776 rank 4
2022-12-04 06:47:00,315 DEBUG TRAIN Batch 10/6500 loss 24.498470 loss_att 26.261198 loss_ctc 36.447853 loss_rnnt 22.552673 lr 0.00052747 rank 6
2022-12-04 06:47:00,317 DEBUG TRAIN Batch 10/6500 loss 10.466813 loss_att 12.844207 loss_ctc 16.797857 loss_rnnt 9.147196 lr 0.00052741 rank 5
2022-12-04 06:47:00,321 DEBUG TRAIN Batch 10/6500 loss 19.070965 loss_att 22.522188 loss_ctc 32.051529 loss_rnnt 16.649979 lr 0.00052733 rank 0
2022-12-04 06:47:00,322 DEBUG TRAIN Batch 10/6500 loss 9.061256 loss_att 10.743597 loss_ctc 12.849850 loss_rnnt 8.219643 lr 0.00052739 rank 1
2022-12-04 06:47:00,322 DEBUG TRAIN Batch 10/6500 loss 19.683794 loss_att 21.604305 loss_ctc 28.126884 loss_rnnt 18.173946 lr 0.00052720 rank 2
2022-12-04 06:47:00,328 DEBUG TRAIN Batch 10/6500 loss 20.441763 loss_att 22.270197 loss_ctc 29.326580 loss_rnnt 18.891434 lr 0.00052740 rank 3
2022-12-04 06:47:00,332 DEBUG TRAIN Batch 10/6500 loss 3.839477 loss_att 7.682151 loss_ctc 5.794488 loss_rnnt 2.810274 lr 0.00052742 rank 7
2022-12-04 06:47:00,372 DEBUG TRAIN Batch 10/6500 loss 14.394862 loss_att 17.005978 loss_ctc 26.290955 loss_rnnt 12.286494 lr 0.00052746 rank 4
2022-12-04 06:48:11,806 DEBUG TRAIN Batch 10/6600 loss 7.441986 loss_att 12.150832 loss_ctc 13.730445 loss_rnnt 5.661756 lr 0.00052717 rank 4
2022-12-04 06:48:11,819 DEBUG TRAIN Batch 10/6600 loss 11.541953 loss_att 16.727009 loss_ctc 21.038239 loss_rnnt 9.238770 lr 0.00052691 rank 2
2022-12-04 06:48:11,819 DEBUG TRAIN Batch 10/6600 loss 16.163059 loss_att 23.371311 loss_ctc 26.846157 loss_rnnt 13.296996 lr 0.00052711 rank 3
2022-12-04 06:48:11,822 DEBUG TRAIN Batch 10/6600 loss 20.944746 loss_att 24.968643 loss_ctc 33.717907 loss_rnnt 18.436880 lr 0.00052709 rank 1
2022-12-04 06:48:11,824 DEBUG TRAIN Batch 10/6600 loss 14.203962 loss_att 17.528145 loss_ctc 25.657608 loss_rnnt 12.011973 lr 0.00052703 rank 0
2022-12-04 06:48:11,826 DEBUG TRAIN Batch 10/6600 loss 12.692169 loss_att 16.852715 loss_ctc 22.029007 loss_rnnt 10.615149 lr 0.00052712 rank 5
2022-12-04 06:48:11,827 DEBUG TRAIN Batch 10/6600 loss 12.270711 loss_att 15.157032 loss_ctc 21.536705 loss_rnnt 10.457981 lr 0.00052713 rank 7
2022-12-04 06:48:11,828 DEBUG TRAIN Batch 10/6600 loss 9.850948 loss_att 14.925158 loss_ctc 17.073860 loss_rnnt 7.873051 lr 0.00052717 rank 6
2022-12-04 06:49:24,288 DEBUG TRAIN Batch 10/6700 loss 8.244671 loss_att 14.506784 loss_ctc 15.504638 loss_rnnt 6.024252 lr 0.00052662 rank 2
2022-12-04 06:49:24,297 DEBUG TRAIN Batch 10/6700 loss 12.942448 loss_att 14.636093 loss_ctc 17.662811 loss_rnnt 11.974337 lr 0.00052684 rank 7
2022-12-04 06:49:24,299 DEBUG TRAIN Batch 10/6700 loss 20.823324 loss_att 19.759445 loss_ctc 23.612110 loss_rnnt 20.664261 lr 0.00052683 rank 5
2022-12-04 06:49:24,298 DEBUG TRAIN Batch 10/6700 loss 10.966883 loss_att 12.865119 loss_ctc 16.490200 loss_rnnt 9.850793 lr 0.00052680 rank 1
2022-12-04 06:49:24,303 DEBUG TRAIN Batch 10/6700 loss 17.722446 loss_att 19.702446 loss_ctc 27.345568 loss_rnnt 16.043364 lr 0.00052688 rank 4
2022-12-04 06:49:24,304 DEBUG TRAIN Batch 10/6700 loss 18.319914 loss_att 22.938990 loss_ctc 31.201244 loss_rnnt 15.678586 lr 0.00052688 rank 6
2022-12-04 06:49:24,312 DEBUG TRAIN Batch 10/6700 loss 10.619585 loss_att 15.037954 loss_ctc 23.284199 loss_rnnt 8.047296 lr 0.00052682 rank 3
2022-12-04 06:49:24,326 DEBUG TRAIN Batch 10/6700 loss 26.019007 loss_att 25.959476 loss_ctc 41.530136 loss_rnnt 23.962765 lr 0.00052674 rank 0
2022-12-04 06:50:38,174 DEBUG TRAIN Batch 10/6800 loss 12.104319 loss_att 18.142839 loss_ctc 21.079998 loss_rnnt 9.699857 lr 0.00052659 rank 6
2022-12-04 06:50:38,175 DEBUG TRAIN Batch 10/6800 loss 5.751038 loss_att 8.192087 loss_ctc 10.440651 loss_rnnt 4.637547 lr 0.00052645 rank 0
2022-12-04 06:50:38,176 DEBUG TRAIN Batch 10/6800 loss 18.172607 loss_att 18.636217 loss_ctc 28.132797 loss_rnnt 16.751860 lr 0.00052653 rank 3
2022-12-04 06:50:38,177 DEBUG TRAIN Batch 10/6800 loss 14.614209 loss_att 19.225344 loss_ctc 21.272577 loss_rnnt 12.804200 lr 0.00052653 rank 5
2022-12-04 06:50:38,177 DEBUG TRAIN Batch 10/6800 loss 18.136080 loss_att 22.854643 loss_ctc 31.733793 loss_rnnt 15.379340 lr 0.00052651 rank 1
2022-12-04 06:50:38,185 DEBUG TRAIN Batch 10/6800 loss 12.130023 loss_att 16.864594 loss_ctc 23.894447 loss_rnnt 9.614518 lr 0.00052632 rank 2
2022-12-04 06:50:38,187 DEBUG TRAIN Batch 10/6800 loss 6.628567 loss_att 10.870138 loss_ctc 11.947797 loss_rnnt 5.071022 lr 0.00052658 rank 4
2022-12-04 06:50:38,248 DEBUG TRAIN Batch 10/6800 loss 11.246383 loss_att 13.449173 loss_ctc 16.839354 loss_rnnt 10.060095 lr 0.00052655 rank 7
2022-12-04 06:51:50,610 DEBUG TRAIN Batch 10/6900 loss 16.002350 loss_att 17.082130 loss_ctc 28.049688 loss_rnnt 14.180083 lr 0.00052630 rank 6
2022-12-04 06:51:50,611 DEBUG TRAIN Batch 10/6900 loss 6.197574 loss_att 7.313240 loss_ctc 9.371922 loss_rnnt 5.551194 lr 0.00052622 rank 1
2022-12-04 06:51:50,612 DEBUG TRAIN Batch 10/6900 loss 14.496834 loss_att 21.568390 loss_ctc 28.573294 loss_rnnt 11.205662 lr 0.00052624 rank 5
2022-12-04 06:51:50,613 DEBUG TRAIN Batch 10/6900 loss 23.694740 loss_att 26.930534 loss_ctc 38.668602 loss_rnnt 21.051069 lr 0.00052616 rank 0
2022-12-04 06:51:50,614 DEBUG TRAIN Batch 10/6900 loss 11.892327 loss_att 15.942820 loss_ctc 24.136623 loss_rnnt 9.449656 lr 0.00052625 rank 7
2022-12-04 06:51:50,614 DEBUG TRAIN Batch 10/6900 loss 11.736718 loss_att 15.354269 loss_ctc 20.845562 loss_rnnt 9.798695 lr 0.00052623 rank 3
2022-12-04 06:51:50,616 DEBUG TRAIN Batch 10/6900 loss 10.682890 loss_att 11.728344 loss_ctc 17.317705 loss_rnnt 9.589157 lr 0.00052603 rank 2
2022-12-04 06:51:50,622 DEBUG TRAIN Batch 10/6900 loss 13.452312 loss_att 17.560041 loss_ctc 20.690306 loss_rnnt 11.665700 lr 0.00052629 rank 4
2022-12-04 06:53:02,146 DEBUG TRAIN Batch 10/7000 loss 18.801035 loss_att 17.967377 loss_ctc 25.005619 loss_rnnt 18.140488 lr 0.00052600 rank 6
2022-12-04 06:53:02,149 DEBUG TRAIN Batch 10/7000 loss 22.111298 loss_att 23.874222 loss_ctc 32.056278 loss_rnnt 20.432716 lr 0.00052595 rank 5
2022-12-04 06:53:02,150 DEBUG TRAIN Batch 10/7000 loss 18.701015 loss_att 21.755424 loss_ctc 24.656385 loss_rnnt 17.296085 lr 0.00052587 rank 0
2022-12-04 06:53:02,151 DEBUG TRAIN Batch 10/7000 loss 20.618876 loss_att 25.503559 loss_ctc 39.327053 loss_rnnt 17.147514 lr 0.00052594 rank 3
2022-12-04 06:53:02,156 DEBUG TRAIN Batch 10/7000 loss 10.829386 loss_att 13.236354 loss_ctc 16.170444 loss_rnnt 9.635850 lr 0.00052596 rank 7
2022-12-04 06:53:02,156 DEBUG TRAIN Batch 10/7000 loss 12.330066 loss_att 14.284012 loss_ctc 21.473808 loss_rnnt 10.720110 lr 0.00052593 rank 1
2022-12-04 06:53:02,158 DEBUG TRAIN Batch 10/7000 loss 12.635723 loss_att 14.241911 loss_ctc 18.871311 loss_rnnt 11.483074 lr 0.00052600 rank 4
2022-12-04 06:53:02,197 DEBUG TRAIN Batch 10/7000 loss 10.315223 loss_att 14.666780 loss_ctc 17.437513 loss_rnnt 8.495273 lr 0.00052574 rank 2
2022-12-04 06:54:17,763 DEBUG TRAIN Batch 10/7100 loss 12.961660 loss_att 16.741028 loss_ctc 20.464493 loss_rnnt 11.205409 lr 0.00052571 rank 6
2022-12-04 06:54:17,765 DEBUG TRAIN Batch 10/7100 loss 26.333374 loss_att 35.132938 loss_ctc 38.166710 loss_rnnt 22.995682 lr 0.00052571 rank 4
2022-12-04 06:54:17,766 DEBUG TRAIN Batch 10/7100 loss 32.723824 loss_att 32.271313 loss_ctc 45.730927 loss_rnnt 31.080044 lr 0.00052565 rank 3
2022-12-04 06:54:17,781 DEBUG TRAIN Batch 10/7100 loss 6.330027 loss_att 11.411781 loss_ctc 9.956005 loss_rnnt 4.830213 lr 0.00052567 rank 7
2022-12-04 06:54:17,784 DEBUG TRAIN Batch 10/7100 loss 12.121297 loss_att 16.334423 loss_ctc 22.191250 loss_rnnt 9.936010 lr 0.00052545 rank 2
2022-12-04 06:54:17,790 DEBUG TRAIN Batch 10/7100 loss 3.818331 loss_att 7.970754 loss_ctc 9.346092 loss_rnnt 2.250812 lr 0.00052558 rank 0
2022-12-04 06:54:17,797 DEBUG TRAIN Batch 10/7100 loss 9.257723 loss_att 12.477336 loss_ctc 17.298605 loss_rnnt 7.541683 lr 0.00052566 rank 5
2022-12-04 06:54:17,809 DEBUG TRAIN Batch 10/7100 loss 11.931839 loss_att 14.618259 loss_ctc 18.675640 loss_rnnt 10.495380 lr 0.00052563 rank 1
2022-12-04 06:55:30,817 DEBUG TRAIN Batch 10/7200 loss 22.745743 loss_att 25.806919 loss_ctc 39.249512 loss_rnnt 19.933004 lr 0.00052537 rank 5
2022-12-04 06:55:30,819 DEBUG TRAIN Batch 10/7200 loss 18.141207 loss_att 20.272633 loss_ctc 31.158894 loss_rnnt 15.979229 lr 0.00052536 rank 3
2022-12-04 06:55:30,820 DEBUG TRAIN Batch 10/7200 loss 16.815144 loss_att 20.510340 loss_ctc 32.687691 loss_rnnt 13.959765 lr 0.00052542 rank 6
2022-12-04 06:55:30,821 DEBUG TRAIN Batch 10/7200 loss 4.458945 loss_att 7.199904 loss_ctc 6.897573 loss_rnnt 3.585603 lr 0.00052516 rank 2
2022-12-04 06:55:30,821 DEBUG TRAIN Batch 10/7200 loss 14.838791 loss_att 17.166859 loss_ctc 23.625324 loss_rnnt 13.201639 lr 0.00052534 rank 1
2022-12-04 06:55:30,822 DEBUG TRAIN Batch 10/7200 loss 24.888260 loss_att 28.853012 loss_ctc 40.109226 loss_rnnt 22.065845 lr 0.00052529 rank 0
2022-12-04 06:55:30,825 DEBUG TRAIN Batch 10/7200 loss 12.980023 loss_att 15.079002 loss_ctc 20.048149 loss_rnnt 11.617810 lr 0.00052538 rank 7
2022-12-04 06:55:30,828 DEBUG TRAIN Batch 10/7200 loss 10.192000 loss_att 13.118979 loss_ctc 22.209038 loss_rnnt 8.004333 lr 0.00052542 rank 4
2022-12-04 06:56:42,543 DEBUG TRAIN Batch 10/7300 loss 19.388103 loss_att 24.893518 loss_ctc 28.805286 loss_rnnt 17.031397 lr 0.00052505 rank 1
2022-12-04 06:56:42,550 DEBUG TRAIN Batch 10/7300 loss 12.717072 loss_att 16.964489 loss_ctc 26.046822 loss_rnnt 10.090289 lr 0.00052508 rank 5
2022-12-04 06:56:42,552 DEBUG TRAIN Batch 10/7300 loss 19.246017 loss_att 21.884205 loss_ctc 29.350307 loss_rnnt 17.371141 lr 0.00052513 rank 6
2022-12-04 06:56:42,556 DEBUG TRAIN Batch 10/7300 loss 20.828527 loss_att 22.287851 loss_ctc 33.341808 loss_rnnt 18.868225 lr 0.00052509 rank 7
2022-12-04 06:56:42,556 DEBUG TRAIN Batch 10/7300 loss 9.218776 loss_att 12.898126 loss_ctc 16.002642 loss_rnnt 7.578391 lr 0.00052500 rank 0
2022-12-04 06:56:42,558 DEBUG TRAIN Batch 10/7300 loss 31.569498 loss_att 33.311497 loss_ctc 42.029106 loss_rnnt 29.826481 lr 0.00052507 rank 3
2022-12-04 06:56:42,563 DEBUG TRAIN Batch 10/7300 loss 25.076862 loss_att 28.937855 loss_ctc 40.407673 loss_rnnt 22.260553 lr 0.00052487 rank 2
2022-12-04 06:56:42,563 DEBUG TRAIN Batch 10/7300 loss 20.482523 loss_att 22.459772 loss_ctc 29.842546 loss_rnnt 18.839071 lr 0.00052513 rank 4
2022-12-04 06:57:55,121 DEBUG TRAIN Batch 10/7400 loss 6.242588 loss_att 11.477138 loss_ctc 15.473048 loss_rnnt 3.964950 lr 0.00052480 rank 7
2022-12-04 06:57:55,121 DEBUG TRAIN Batch 10/7400 loss 18.985424 loss_att 21.948357 loss_ctc 27.636898 loss_rnnt 17.239307 lr 0.00052479 rank 5
2022-12-04 06:57:55,122 DEBUG TRAIN Batch 10/7400 loss 12.213134 loss_att 17.501549 loss_ctc 19.014809 loss_rnnt 10.248560 lr 0.00052484 rank 6
2022-12-04 06:57:55,127 DEBUG TRAIN Batch 10/7400 loss 14.702997 loss_att 16.055820 loss_ctc 21.953308 loss_rnnt 13.465725 lr 0.00052478 rank 3
2022-12-04 06:57:55,128 DEBUG TRAIN Batch 10/7400 loss 15.592360 loss_att 20.128162 loss_ctc 29.961397 loss_rnnt 12.769329 lr 0.00052471 rank 0
2022-12-04 06:57:55,131 DEBUG TRAIN Batch 10/7400 loss 11.444108 loss_att 11.896756 loss_ctc 16.787134 loss_rnnt 10.641174 lr 0.00052477 rank 1
2022-12-04 06:57:55,164 DEBUG TRAIN Batch 10/7400 loss 15.940911 loss_att 19.499569 loss_ctc 27.704021 loss_rnnt 13.660766 lr 0.00052458 rank 2
2022-12-04 06:57:55,169 DEBUG TRAIN Batch 10/7400 loss 18.229624 loss_att 19.948332 loss_ctc 28.167620 loss_rnnt 16.560816 lr 0.00052484 rank 4
2022-12-04 06:59:11,432 DEBUG TRAIN Batch 10/7500 loss 9.626028 loss_att 14.019208 loss_ctc 12.681969 loss_rnnt 8.339932 lr 0.00052455 rank 6
2022-12-04 06:59:11,433 DEBUG TRAIN Batch 10/7500 loss 14.420954 loss_att 13.689845 loss_ctc 23.652111 loss_rnnt 13.336353 lr 0.00052450 rank 5
2022-12-04 06:59:11,434 DEBUG TRAIN Batch 10/7500 loss 14.358334 loss_att 15.296982 loss_ctc 20.502701 loss_rnnt 13.351356 lr 0.00052448 rank 1
2022-12-04 06:59:11,437 DEBUG TRAIN Batch 10/7500 loss 9.450531 loss_att 10.919852 loss_ctc 15.344744 loss_rnnt 8.370772 lr 0.00052451 rank 7
2022-12-04 06:59:11,438 DEBUG TRAIN Batch 10/7500 loss 12.464354 loss_att 18.288773 loss_ctc 23.321957 loss_rnnt 9.851789 lr 0.00052442 rank 0
2022-12-04 06:59:11,437 DEBUG TRAIN Batch 10/7500 loss 16.412104 loss_att 19.372639 loss_ctc 31.894344 loss_rnnt 13.755699 lr 0.00052430 rank 2
2022-12-04 06:59:11,439 DEBUG TRAIN Batch 10/7500 loss 6.622005 loss_att 7.473458 loss_ctc 11.292613 loss_rnnt 5.828965 lr 0.00052449 rank 3
2022-12-04 06:59:11,441 DEBUG TRAIN Batch 10/7500 loss 10.377444 loss_att 12.571652 loss_ctc 17.388716 loss_rnnt 9.003766 lr 0.00052455 rank 4
2022-12-04 07:00:23,739 DEBUG TRAIN Batch 10/7600 loss 10.019070 loss_att 12.435702 loss_ctc 16.460989 loss_rnnt 8.676821 lr 0.00052413 rank 0
2022-12-04 07:00:23,739 DEBUG TRAIN Batch 10/7600 loss 11.349360 loss_att 12.353445 loss_ctc 20.265965 loss_rnnt 9.959663 lr 0.00052419 rank 1
2022-12-04 07:00:23,742 DEBUG TRAIN Batch 10/7600 loss 5.849680 loss_att 11.709776 loss_ctc 16.599400 loss_rnnt 3.244365 lr 0.00052421 rank 3
2022-12-04 07:00:23,742 DEBUG TRAIN Batch 10/7600 loss 9.813748 loss_att 11.678911 loss_ctc 16.739023 loss_rnnt 8.517345 lr 0.00052401 rank 2
2022-12-04 07:00:23,745 DEBUG TRAIN Batch 10/7600 loss 14.982084 loss_att 15.787517 loss_ctc 23.652605 loss_rnnt 13.664928 lr 0.00052427 rank 6
2022-12-04 07:00:23,745 DEBUG TRAIN Batch 10/7600 loss 14.039250 loss_att 20.650398 loss_ctc 22.593117 loss_rnnt 11.576506 lr 0.00052423 rank 7
2022-12-04 07:00:23,746 DEBUG TRAIN Batch 10/7600 loss 8.879443 loss_att 10.151344 loss_ctc 13.792308 loss_rnnt 7.970014 lr 0.00052421 rank 5
2022-12-04 07:00:23,757 DEBUG TRAIN Batch 10/7600 loss 12.298053 loss_att 15.110068 loss_ctc 21.522877 loss_rnnt 10.505673 lr 0.00052426 rank 4
2022-12-04 07:01:35,739 DEBUG TRAIN Batch 10/7700 loss 9.713041 loss_att 15.432635 loss_ctc 19.008810 loss_rnnt 7.329687 lr 0.00052398 rank 6
2022-12-04 07:01:35,739 DEBUG TRAIN Batch 10/7700 loss 9.502228 loss_att 10.391761 loss_ctc 16.520529 loss_rnnt 8.388548 lr 0.00052384 rank 0
2022-12-04 07:01:35,741 DEBUG TRAIN Batch 10/7700 loss 14.502018 loss_att 18.515970 loss_ctc 19.290325 loss_rnnt 13.060786 lr 0.00052390 rank 1
2022-12-04 07:01:35,741 DEBUG TRAIN Batch 10/7700 loss 14.383096 loss_att 17.398256 loss_ctc 23.748337 loss_rnnt 12.531364 lr 0.00052392 rank 3
2022-12-04 07:01:35,741 DEBUG TRAIN Batch 10/7700 loss 32.246037 loss_att 34.012138 loss_ctc 49.708099 loss_rnnt 29.564543 lr 0.00052372 rank 2
2022-12-04 07:01:35,744 DEBUG TRAIN Batch 10/7700 loss 6.738267 loss_att 12.849458 loss_ctc 9.977824 loss_rnnt 5.084088 lr 0.00052398 rank 4
2022-12-04 07:01:35,746 DEBUG TRAIN Batch 10/7700 loss 10.710894 loss_att 14.067327 loss_ctc 17.893650 loss_rnnt 9.081906 lr 0.00052394 rank 7
2022-12-04 07:01:35,791 DEBUG TRAIN Batch 10/7700 loss 7.360075 loss_att 10.983594 loss_ctc 16.841648 loss_rnnt 5.371161 lr 0.00052393 rank 5
2022-12-04 07:02:49,462 DEBUG TRAIN Batch 10/7800 loss 15.454170 loss_att 17.898979 loss_ctc 27.173630 loss_rnnt 13.402613 lr 0.00052361 rank 1
2022-12-04 07:02:49,465 DEBUG TRAIN Batch 10/7800 loss 10.057740 loss_att 12.085737 loss_ctc 14.080492 loss_rnnt 9.115773 lr 0.00052364 rank 5
2022-12-04 07:02:49,475 DEBUG TRAIN Batch 10/7800 loss 7.403326 loss_att 13.779776 loss_ctc 14.112165 loss_rnnt 5.233524 lr 0.00052369 rank 6
2022-12-04 07:02:49,479 DEBUG TRAIN Batch 10/7800 loss 8.614037 loss_att 12.396763 loss_ctc 17.709835 loss_rnnt 6.644718 lr 0.00052356 rank 0
2022-12-04 07:02:49,478 DEBUG TRAIN Batch 10/7800 loss 16.217861 loss_att 22.875732 loss_ctc 29.825272 loss_rnnt 13.071965 lr 0.00052363 rank 3
2022-12-04 07:02:49,480 DEBUG TRAIN Batch 10/7800 loss 10.754108 loss_att 15.779856 loss_ctc 22.668911 loss_rnnt 8.160318 lr 0.00052365 rank 7
2022-12-04 07:02:49,486 DEBUG TRAIN Batch 10/7800 loss 22.893812 loss_att 23.700430 loss_ctc 32.720329 loss_rnnt 21.422285 lr 0.00052343 rank 2
2022-12-04 07:02:49,487 DEBUG TRAIN Batch 10/7800 loss 6.348103 loss_att 11.264553 loss_ctc 10.229403 loss_rnnt 4.847305 lr 0.00052369 rank 4
2022-12-04 07:04:01,888 DEBUG TRAIN Batch 10/7900 loss 19.689837 loss_att 21.212938 loss_ctc 31.515392 loss_rnnt 17.808477 lr 0.00052327 rank 0
2022-12-04 07:04:01,891 DEBUG TRAIN Batch 10/7900 loss 13.764389 loss_att 16.325050 loss_ctc 16.655872 loss_rnnt 12.866726 lr 0.00052336 rank 7
2022-12-04 07:04:01,892 DEBUG TRAIN Batch 10/7900 loss 15.976919 loss_att 16.517908 loss_ctc 21.179699 loss_rnnt 15.175018 lr 0.00052334 rank 3
2022-12-04 07:04:01,892 DEBUG TRAIN Batch 10/7900 loss 10.766191 loss_att 15.641703 loss_ctc 15.393992 loss_rnnt 9.174047 lr 0.00052335 rank 5
2022-12-04 07:04:01,896 DEBUG TRAIN Batch 10/7900 loss 9.899370 loss_att 11.830064 loss_ctc 14.613853 loss_rnnt 8.884633 lr 0.00052340 rank 6
2022-12-04 07:04:01,896 DEBUG TRAIN Batch 10/7900 loss 5.041725 loss_att 11.057891 loss_ctc 13.415474 loss_rnnt 2.721992 lr 0.00052340 rank 4
2022-12-04 07:04:01,896 DEBUG TRAIN Batch 10/7900 loss 8.918159 loss_att 10.149433 loss_ctc 16.192804 loss_rnnt 7.701953 lr 0.00052333 rank 1
2022-12-04 07:04:01,902 DEBUG TRAIN Batch 10/7900 loss 7.316438 loss_att 9.862906 loss_ctc 9.818907 loss_rnnt 6.473482 lr 0.00052315 rank 2
2022-12-04 07:05:13,173 DEBUG TRAIN Batch 10/8000 loss 13.299860 loss_att 15.818581 loss_ctc 24.967188 loss_rnnt 11.240471 lr 0.00052311 rank 4
2022-12-04 07:05:13,184 DEBUG TRAIN Batch 10/8000 loss 8.807605 loss_att 11.709749 loss_ctc 11.737764 loss_rnnt 7.836488 lr 0.00052304 rank 1
2022-12-04 07:05:13,189 DEBUG TRAIN Batch 10/8000 loss 27.078365 loss_att 30.275288 loss_ctc 43.225365 loss_rnnt 24.286049 lr 0.00052312 rank 6
2022-12-04 07:05:13,190 DEBUG TRAIN Batch 10/8000 loss 12.853734 loss_att 16.658161 loss_ctc 19.746119 loss_rnnt 11.173864 lr 0.00052298 rank 0
2022-12-04 07:05:13,192 DEBUG TRAIN Batch 10/8000 loss 11.083621 loss_att 14.629105 loss_ctc 19.150705 loss_rnnt 9.298913 lr 0.00052306 rank 3
2022-12-04 07:05:13,193 DEBUG TRAIN Batch 10/8000 loss 17.771713 loss_att 21.283802 loss_ctc 26.710453 loss_rnnt 15.877463 lr 0.00052286 rank 2
2022-12-04 07:05:13,194 DEBUG TRAIN Batch 10/8000 loss 8.929416 loss_att 12.376606 loss_ctc 12.880923 loss_rnnt 7.713109 lr 0.00052307 rank 5
2022-12-04 07:05:13,196 DEBUG TRAIN Batch 10/8000 loss 17.363541 loss_att 18.301241 loss_ctc 26.343832 loss_rnnt 15.978628 lr 0.00052308 rank 7
2022-12-04 07:06:25,761 DEBUG TRAIN Batch 10/8100 loss 18.753820 loss_att 22.736095 loss_ctc 41.435722 loss_rnnt 14.933113 lr 0.00052283 rank 6
2022-12-04 07:06:25,762 DEBUG TRAIN Batch 10/8100 loss 7.903607 loss_att 10.076943 loss_ctc 12.447657 loss_rnnt 6.863066 lr 0.00052279 rank 7
2022-12-04 07:06:25,764 DEBUG TRAIN Batch 10/8100 loss 11.022095 loss_att 16.084528 loss_ctc 23.977213 loss_rnnt 8.282258 lr 0.00052270 rank 0
2022-12-04 07:06:25,764 DEBUG TRAIN Batch 10/8100 loss 16.010498 loss_att 21.003563 loss_ctc 31.918139 loss_rnnt 12.890867 lr 0.00052257 rank 2
2022-12-04 07:06:25,768 DEBUG TRAIN Batch 10/8100 loss 6.413468 loss_att 8.389701 loss_ctc 11.909465 loss_rnnt 5.285421 lr 0.00052277 rank 3
2022-12-04 07:06:25,776 DEBUG TRAIN Batch 10/8100 loss 14.754552 loss_att 18.592535 loss_ctc 24.641035 loss_rnnt 12.668756 lr 0.00052275 rank 1
2022-12-04 07:06:25,786 DEBUG TRAIN Batch 10/8100 loss 14.777495 loss_att 16.875404 loss_ctc 22.812088 loss_rnnt 13.286634 lr 0.00052283 rank 4
2022-12-04 07:06:25,818 DEBUG TRAIN Batch 10/8100 loss 9.393798 loss_att 11.819100 loss_ctc 18.010519 loss_rnnt 7.759841 lr 0.00052278 rank 5
2022-12-04 07:07:37,883 DEBUG TRAIN Batch 10/8200 loss 10.902063 loss_att 13.459217 loss_ctc 15.750566 loss_rnnt 9.744164 lr 0.00052249 rank 5
2022-12-04 07:07:37,884 DEBUG TRAIN Batch 10/8200 loss 9.217489 loss_att 12.489561 loss_ctc 17.304003 loss_rnnt 7.484874 lr 0.00052241 rank 0
2022-12-04 07:07:37,886 DEBUG TRAIN Batch 10/8200 loss 9.855879 loss_att 12.880962 loss_ctc 23.617119 loss_rnnt 7.416030 lr 0.00052249 rank 3
2022-12-04 07:07:37,887 DEBUG TRAIN Batch 10/8200 loss 8.490266 loss_att 12.292818 loss_ctc 20.167036 loss_rnnt 6.172853 lr 0.00052255 rank 6
2022-12-04 07:07:37,888 DEBUG TRAIN Batch 10/8200 loss 12.603364 loss_att 15.028385 loss_ctc 23.898834 loss_rnnt 10.612297 lr 0.00052229 rank 2
2022-12-04 07:07:37,888 DEBUG TRAIN Batch 10/8200 loss 7.797819 loss_att 10.362616 loss_ctc 14.171872 loss_rnnt 6.434986 lr 0.00052251 rank 7
2022-12-04 07:07:37,889 DEBUG TRAIN Batch 10/8200 loss 5.108484 loss_att 9.236162 loss_ctc 10.381721 loss_rnnt 3.579850 lr 0.00052247 rank 1
2022-12-04 07:07:37,944 DEBUG TRAIN Batch 10/8200 loss 8.663530 loss_att 10.379078 loss_ctc 14.338359 loss_rnnt 7.563777 lr 0.00052254 rank 4
2022-12-04 07:08:49,231 DEBUG TRAIN Batch 10/8300 loss 6.481679 loss_att 10.243629 loss_ctc 10.665014 loss_rnnt 5.171511 lr 0.00052213 rank 0
2022-12-04 07:08:49,231 DEBUG TRAIN Batch 10/8300 loss 8.976652 loss_att 11.187204 loss_ctc 20.968899 loss_rnnt 6.935575 lr 0.00052221 rank 5
2022-12-04 07:08:49,232 DEBUG TRAIN Batch 10/8300 loss 15.081905 loss_att 19.324364 loss_ctc 35.874710 loss_rnnt 11.461040 lr 0.00052226 rank 6
2022-12-04 07:08:49,233 DEBUG TRAIN Batch 10/8300 loss 7.344680 loss_att 14.300520 loss_ctc 14.302222 loss_rnnt 5.025840 lr 0.00052218 rank 1
2022-12-04 07:08:49,233 DEBUG TRAIN Batch 10/8300 loss 13.511724 loss_att 14.710640 loss_ctc 21.617674 loss_rnnt 12.191147 lr 0.00052222 rank 7
2022-12-04 07:08:49,234 DEBUG TRAIN Batch 10/8300 loss 17.435400 loss_att 22.983318 loss_ctc 28.245567 loss_rnnt 14.884460 lr 0.00052220 rank 3
2022-12-04 07:08:49,236 DEBUG TRAIN Batch 10/8300 loss 13.263336 loss_att 18.457235 loss_ctc 27.706341 loss_rnnt 10.298823 lr 0.00052200 rank 2
2022-12-04 07:08:49,241 DEBUG TRAIN Batch 10/8300 loss 19.823927 loss_att 22.498978 loss_ctc 36.194885 loss_rnnt 17.106123 lr 0.00052226 rank 4
2022-12-04 07:09:47,635 DEBUG CV Batch 10/0 loss 2.680704 loss_att 2.169800 loss_ctc 4.144320 loss_rnnt 2.587736 history loss 2.581419 rank 3
2022-12-04 07:09:47,638 DEBUG CV Batch 10/0 loss 2.680704 loss_att 2.169800 loss_ctc 4.144320 loss_rnnt 2.587736 history loss 2.581419 rank 7
2022-12-04 07:09:47,640 DEBUG CV Batch 10/0 loss 2.680704 loss_att 2.169800 loss_ctc 4.144320 loss_rnnt 2.587736 history loss 2.581419 rank 6
2022-12-04 07:09:47,642 DEBUG CV Batch 10/0 loss 2.680704 loss_att 2.169800 loss_ctc 4.144320 loss_rnnt 2.587736 history loss 2.581419 rank 2
2022-12-04 07:09:47,643 DEBUG CV Batch 10/0 loss 2.680704 loss_att 2.169800 loss_ctc 4.144320 loss_rnnt 2.587736 history loss 2.581419 rank 5
2022-12-04 07:09:47,644 DEBUG CV Batch 10/0 loss 2.680704 loss_att 2.169800 loss_ctc 4.144320 loss_rnnt 2.587736 history loss 2.581419 rank 1
2022-12-04 07:09:47,645 DEBUG CV Batch 10/0 loss 2.680704 loss_att 2.169800 loss_ctc 4.144320 loss_rnnt 2.587736 history loss 2.581419 rank 0
2022-12-04 07:09:47,654 DEBUG CV Batch 10/0 loss 2.680704 loss_att 2.169800 loss_ctc 4.144320 loss_rnnt 2.587736 history loss 2.581419 rank 4
2022-12-04 07:09:58,982 DEBUG CV Batch 10/100 loss 8.958514 loss_att 9.183960 loss_ctc 14.740963 loss_rnnt 8.142432 history loss 4.066853 rank 5
2022-12-04 07:09:59,000 DEBUG CV Batch 10/100 loss 8.958514 loss_att 9.183960 loss_ctc 14.740963 loss_rnnt 8.142432 history loss 4.066853 rank 1
2022-12-04 07:09:59,031 DEBUG CV Batch 10/100 loss 8.958514 loss_att 9.183960 loss_ctc 14.740963 loss_rnnt 8.142432 history loss 4.066853 rank 4
2022-12-04 07:09:59,236 DEBUG CV Batch 10/100 loss 8.958514 loss_att 9.183960 loss_ctc 14.740963 loss_rnnt 8.142432 history loss 4.066853 rank 7
2022-12-04 07:09:59,253 DEBUG CV Batch 10/100 loss 8.958514 loss_att 9.183960 loss_ctc 14.740963 loss_rnnt 8.142432 history loss 4.066853 rank 0
2022-12-04 07:09:59,270 DEBUG CV Batch 10/100 loss 8.958514 loss_att 9.183960 loss_ctc 14.740963 loss_rnnt 8.142432 history loss 4.066853 rank 6
2022-12-04 07:09:59,310 DEBUG CV Batch 10/100 loss 8.958514 loss_att 9.183960 loss_ctc 14.740963 loss_rnnt 8.142432 history loss 4.066853 rank 2
2022-12-04 07:09:59,343 DEBUG CV Batch 10/100 loss 8.958514 loss_att 9.183960 loss_ctc 14.740963 loss_rnnt 8.142432 history loss 4.066853 rank 3
2022-12-04 07:10:12,463 DEBUG CV Batch 10/200 loss 13.273260 loss_att 17.048176 loss_ctc 16.461025 loss_rnnt 12.093242 history loss 4.692654 rank 4
2022-12-04 07:10:12,823 DEBUG CV Batch 10/200 loss 13.273260 loss_att 17.048176 loss_ctc 16.461025 loss_rnnt 12.093242 history loss 4.692654 rank 2
2022-12-04 07:10:12,881 DEBUG CV Batch 10/200 loss 13.273260 loss_att 17.048176 loss_ctc 16.461025 loss_rnnt 12.093242 history loss 4.692654 rank 0
2022-12-04 07:10:12,914 DEBUG CV Batch 10/200 loss 13.273260 loss_att 17.048176 loss_ctc 16.461025 loss_rnnt 12.093242 history loss 4.692654 rank 5
2022-12-04 07:10:12,919 DEBUG CV Batch 10/200 loss 13.273260 loss_att 17.048176 loss_ctc 16.461025 loss_rnnt 12.093242 history loss 4.692654 rank 6
2022-12-04 07:10:13,017 DEBUG CV Batch 10/200 loss 13.273260 loss_att 17.048176 loss_ctc 16.461025 loss_rnnt 12.093242 history loss 4.692654 rank 3
2022-12-04 07:10:13,282 DEBUG CV Batch 10/200 loss 13.273260 loss_att 17.048176 loss_ctc 16.461025 loss_rnnt 12.093242 history loss 4.692654 rank 7
2022-12-04 07:10:13,292 DEBUG CV Batch 10/200 loss 13.273260 loss_att 17.048176 loss_ctc 16.461025 loss_rnnt 12.093242 history loss 4.692654 rank 1
2022-12-04 07:10:24,428 DEBUG CV Batch 10/300 loss 5.762118 loss_att 6.706725 loss_ctc 11.058187 loss_rnnt 4.867055 history loss 4.825567 rank 4
2022-12-04 07:10:24,852 DEBUG CV Batch 10/300 loss 5.762118 loss_att 6.706725 loss_ctc 11.058187 loss_rnnt 4.867055 history loss 4.825567 rank 5
2022-12-04 07:10:25,056 DEBUG CV Batch 10/300 loss 5.762118 loss_att 6.706725 loss_ctc 11.058187 loss_rnnt 4.867055 history loss 4.825567 rank 2
2022-12-04 07:10:25,192 DEBUG CV Batch 10/300 loss 5.762118 loss_att 6.706725 loss_ctc 11.058187 loss_rnnt 4.867055 history loss 4.825567 rank 6
2022-12-04 07:10:25,245 DEBUG CV Batch 10/300 loss 5.762118 loss_att 6.706725 loss_ctc 11.058187 loss_rnnt 4.867055 history loss 4.825567 rank 0
2022-12-04 07:10:25,335 DEBUG CV Batch 10/300 loss 5.762118 loss_att 6.706725 loss_ctc 11.058187 loss_rnnt 4.867055 history loss 4.825567 rank 1
2022-12-04 07:10:25,349 DEBUG CV Batch 10/300 loss 5.762118 loss_att 6.706725 loss_ctc 11.058187 loss_rnnt 4.867055 history loss 4.825567 rank 7
2022-12-04 07:10:25,444 DEBUG CV Batch 10/300 loss 5.762118 loss_att 6.706725 loss_ctc 11.058187 loss_rnnt 4.867055 history loss 4.825567 rank 3
2022-12-04 07:10:36,465 DEBUG CV Batch 10/400 loss 19.164885 loss_att 90.118813 loss_ctc 16.216463 loss_rnnt 5.367220 history loss 5.751036 rank 4
2022-12-04 07:10:36,976 DEBUG CV Batch 10/400 loss 19.164885 loss_att 90.118813 loss_ctc 16.216463 loss_rnnt 5.367220 history loss 5.751036 rank 5
2022-12-04 07:10:37,142 DEBUG CV Batch 10/400 loss 19.164885 loss_att 90.118813 loss_ctc 16.216463 loss_rnnt 5.367220 history loss 5.751036 rank 1
2022-12-04 07:10:37,215 DEBUG CV Batch 10/400 loss 19.164885 loss_att 90.118813 loss_ctc 16.216463 loss_rnnt 5.367220 history loss 5.751036 rank 7
2022-12-04 07:10:37,296 DEBUG CV Batch 10/400 loss 19.164885 loss_att 90.118813 loss_ctc 16.216463 loss_rnnt 5.367220 history loss 5.751036 rank 2
2022-12-04 07:10:37,410 DEBUG CV Batch 10/400 loss 19.164885 loss_att 90.118813 loss_ctc 16.216463 loss_rnnt 5.367220 history loss 5.751036 rank 6
2022-12-04 07:10:37,554 DEBUG CV Batch 10/400 loss 19.164885 loss_att 90.118813 loss_ctc 16.216463 loss_rnnt 5.367220 history loss 5.751036 rank 0
2022-12-04 07:10:37,879 DEBUG CV Batch 10/400 loss 19.164885 loss_att 90.118813 loss_ctc 16.216463 loss_rnnt 5.367220 history loss 5.751036 rank 3
2022-12-04 07:10:46,803 DEBUG CV Batch 10/500 loss 10.432472 loss_att 10.153191 loss_ctc 12.914177 loss_rnnt 10.157434 history loss 6.534139 rank 4
2022-12-04 07:10:47,324 DEBUG CV Batch 10/500 loss 10.432472 loss_att 10.153191 loss_ctc 12.914177 loss_rnnt 10.157434 history loss 6.534139 rank 5
2022-12-04 07:10:47,573 DEBUG CV Batch 10/500 loss 10.432472 loss_att 10.153191 loss_ctc 12.914177 loss_rnnt 10.157434 history loss 6.534139 rank 1
2022-12-04 07:10:47,727 DEBUG CV Batch 10/500 loss 10.432472 loss_att 10.153191 loss_ctc 12.914177 loss_rnnt 10.157434 history loss 6.534139 rank 7
2022-12-04 07:10:47,784 DEBUG CV Batch 10/500 loss 10.432472 loss_att 10.153191 loss_ctc 12.914177 loss_rnnt 10.157434 history loss 6.534139 rank 2
2022-12-04 07:10:48,034 DEBUG CV Batch 10/500 loss 10.432472 loss_att 10.153191 loss_ctc 12.914177 loss_rnnt 10.157434 history loss 6.534139 rank 6
2022-12-04 07:10:48,378 DEBUG CV Batch 10/500 loss 10.432472 loss_att 10.153191 loss_ctc 12.914177 loss_rnnt 10.157434 history loss 6.534139 rank 0
2022-12-04 07:10:48,750 DEBUG CV Batch 10/500 loss 10.432472 loss_att 10.153191 loss_ctc 12.914177 loss_rnnt 10.157434 history loss 6.534139 rank 3
2022-12-04 07:10:59,310 DEBUG CV Batch 10/600 loss 7.238427 loss_att 7.560741 loss_ctc 10.871788 loss_rnnt 6.689516 history loss 7.418939 rank 4
2022-12-04 07:10:59,317 DEBUG CV Batch 10/600 loss 7.238427 loss_att 7.560741 loss_ctc 10.871788 loss_rnnt 6.689516 history loss 7.418939 rank 5
2022-12-04 07:10:59,685 DEBUG CV Batch 10/600 loss 7.238427 loss_att 7.560741 loss_ctc 10.871788 loss_rnnt 6.689516 history loss 7.418939 rank 1
2022-12-04 07:10:59,921 DEBUG CV Batch 10/600 loss 7.238427 loss_att 7.560741 loss_ctc 10.871788 loss_rnnt 6.689516 history loss 7.418939 rank 7
2022-12-04 07:11:00,023 DEBUG CV Batch 10/600 loss 7.238427 loss_att 7.560741 loss_ctc 10.871788 loss_rnnt 6.689516 history loss 7.418939 rank 2
2022-12-04 07:11:00,237 DEBUG CV Batch 10/600 loss 7.238427 loss_att 7.560741 loss_ctc 10.871788 loss_rnnt 6.689516 history loss 7.418939 rank 6
2022-12-04 07:11:00,792 DEBUG CV Batch 10/600 loss 7.238427 loss_att 7.560741 loss_ctc 10.871788 loss_rnnt 6.689516 history loss 7.418939 rank 0
2022-12-04 07:11:01,208 DEBUG CV Batch 10/600 loss 7.238427 loss_att 7.560741 loss_ctc 10.871788 loss_rnnt 6.689516 history loss 7.418939 rank 3
2022-12-04 07:11:10,892 DEBUG CV Batch 10/700 loss 17.085554 loss_att 55.178467 loss_ctc 24.446499 loss_rnnt 8.485512 history loss 8.054445 rank 4
2022-12-04 07:11:11,051 DEBUG CV Batch 10/700 loss 17.085554 loss_att 55.178467 loss_ctc 24.446499 loss_rnnt 8.485512 history loss 8.054445 rank 5
2022-12-04 07:11:11,587 DEBUG CV Batch 10/700 loss 17.085554 loss_att 55.178467 loss_ctc 24.446499 loss_rnnt 8.485512 history loss 8.054445 rank 2
2022-12-04 07:11:11,807 DEBUG CV Batch 10/700 loss 17.085554 loss_att 55.178467 loss_ctc 24.446499 loss_rnnt 8.485512 history loss 8.054445 rank 1
2022-12-04 07:11:11,845 DEBUG CV Batch 10/700 loss 17.085554 loss_att 55.178467 loss_ctc 24.446499 loss_rnnt 8.485512 history loss 8.054445 rank 6
2022-12-04 07:11:12,254 DEBUG CV Batch 10/700 loss 17.085554 loss_att 55.178467 loss_ctc 24.446499 loss_rnnt 8.485512 history loss 8.054445 rank 7
2022-12-04 07:11:12,460 DEBUG CV Batch 10/700 loss 17.085554 loss_att 55.178467 loss_ctc 24.446499 loss_rnnt 8.485512 history loss 8.054445 rank 0
2022-12-04 07:11:12,978 DEBUG CV Batch 10/700 loss 17.085554 loss_att 55.178467 loss_ctc 24.446499 loss_rnnt 8.485512 history loss 8.054445 rank 3
2022-12-04 07:11:22,041 DEBUG CV Batch 10/800 loss 11.138503 loss_att 10.307421 loss_ctc 16.497396 loss_rnnt 10.590200 history loss 7.514294 rank 4
2022-12-04 07:11:22,572 DEBUG CV Batch 10/800 loss 11.138503 loss_att 10.307421 loss_ctc 16.497396 loss_rnnt 10.590200 history loss 7.514294 rank 2
2022-12-04 07:11:22,911 DEBUG CV Batch 10/800 loss 11.138503 loss_att 10.307421 loss_ctc 16.497396 loss_rnnt 10.590200 history loss 7.514294 rank 5
2022-12-04 07:11:23,179 DEBUG CV Batch 10/800 loss 11.138503 loss_att 10.307421 loss_ctc 16.497396 loss_rnnt 10.590200 history loss 7.514294 rank 6
2022-12-04 07:11:23,870 DEBUG CV Batch 10/800 loss 11.138503 loss_att 10.307421 loss_ctc 16.497396 loss_rnnt 10.590200 history loss 7.514294 rank 1
2022-12-04 07:11:23,988 DEBUG CV Batch 10/800 loss 11.138503 loss_att 10.307421 loss_ctc 16.497396 loss_rnnt 10.590200 history loss 7.514294 rank 0
2022-12-04 07:11:24,081 DEBUG CV Batch 10/800 loss 11.138503 loss_att 10.307421 loss_ctc 16.497396 loss_rnnt 10.590200 history loss 7.514294 rank 7
2022-12-04 07:11:24,553 DEBUG CV Batch 10/800 loss 11.138503 loss_att 10.307421 loss_ctc 16.497396 loss_rnnt 10.590200 history loss 7.514294 rank 3
2022-12-04 07:11:35,508 DEBUG CV Batch 10/900 loss 14.336310 loss_att 17.560528 loss_ctc 26.383839 loss_rnnt 12.085130 history loss 7.323942 rank 4
2022-12-04 07:11:36,182 DEBUG CV Batch 10/900 loss 14.336310 loss_att 17.560528 loss_ctc 26.383839 loss_rnnt 12.085130 history loss 7.323942 rank 2
2022-12-04 07:11:36,771 DEBUG CV Batch 10/900 loss 14.336310 loss_att 17.560528 loss_ctc 26.383839 loss_rnnt 12.085130 history loss 7.323942 rank 5
2022-12-04 07:11:36,853 DEBUG CV Batch 10/900 loss 14.336310 loss_att 17.560528 loss_ctc 26.383839 loss_rnnt 12.085130 history loss 7.323942 rank 6
2022-12-04 07:11:37,688 DEBUG CV Batch 10/900 loss 14.336310 loss_att 17.560528 loss_ctc 26.383839 loss_rnnt 12.085130 history loss 7.323942 rank 0
2022-12-04 07:11:37,880 DEBUG CV Batch 10/900 loss 14.336310 loss_att 17.560528 loss_ctc 26.383839 loss_rnnt 12.085130 history loss 7.323942 rank 1
2022-12-04 07:11:38,112 DEBUG CV Batch 10/900 loss 14.336310 loss_att 17.560528 loss_ctc 26.383839 loss_rnnt 12.085130 history loss 7.323942 rank 7
2022-12-04 07:11:38,435 DEBUG CV Batch 10/900 loss 14.336310 loss_att 17.560528 loss_ctc 26.383839 loss_rnnt 12.085130 history loss 7.323942 rank 3
2022-12-04 07:11:47,631 DEBUG CV Batch 10/1000 loss 4.991813 loss_att 5.762207 loss_ctc 6.811628 loss_rnnt 4.595091 history loss 7.099917 rank 4
2022-12-04 07:11:48,730 DEBUG CV Batch 10/1000 loss 4.991813 loss_att 5.762207 loss_ctc 6.811628 loss_rnnt 4.595091 history loss 7.099917 rank 2
2022-12-04 07:11:48,870 DEBUG CV Batch 10/1000 loss 4.991813 loss_att 5.762207 loss_ctc 6.811628 loss_rnnt 4.595091 history loss 7.099917 rank 5
2022-12-04 07:11:49,468 DEBUG CV Batch 10/1000 loss 4.991813 loss_att 5.762207 loss_ctc 6.811628 loss_rnnt 4.595091 history loss 7.099917 rank 6
2022-12-04 07:11:50,028 DEBUG CV Batch 10/1000 loss 4.991813 loss_att 5.762207 loss_ctc 6.811628 loss_rnnt 4.595091 history loss 7.099917 rank 1
2022-12-04 07:11:50,404 DEBUG CV Batch 10/1000 loss 4.991813 loss_att 5.762207 loss_ctc 6.811628 loss_rnnt 4.595091 history loss 7.099917 rank 0
2022-12-04 07:11:50,601 DEBUG CV Batch 10/1000 loss 4.991813 loss_att 5.762207 loss_ctc 6.811628 loss_rnnt 4.595091 history loss 7.099917 rank 7
2022-12-04 07:11:51,163 DEBUG CV Batch 10/1000 loss 4.991813 loss_att 5.762207 loss_ctc 6.811628 loss_rnnt 4.595091 history loss 7.099917 rank 3
2022-12-04 07:12:00,029 DEBUG CV Batch 10/1100 loss 5.695454 loss_att 6.042869 loss_ctc 10.139679 loss_rnnt 5.033408 history loss 7.083584 rank 4
2022-12-04 07:12:00,901 DEBUG CV Batch 10/1100 loss 5.695454 loss_att 6.042869 loss_ctc 10.139679 loss_rnnt 5.033408 history loss 7.083584 rank 5
2022-12-04 07:12:00,917 DEBUG CV Batch 10/1100 loss 5.695454 loss_att 6.042869 loss_ctc 10.139679 loss_rnnt 5.033408 history loss 7.083584 rank 2
2022-12-04 07:12:01,692 DEBUG CV Batch 10/1100 loss 5.695454 loss_att 6.042869 loss_ctc 10.139679 loss_rnnt 5.033408 history loss 7.083584 rank 6
2022-12-04 07:12:01,851 DEBUG CV Batch 10/1100 loss 5.695454 loss_att 6.042869 loss_ctc 10.139679 loss_rnnt 5.033408 history loss 7.083584 rank 1
2022-12-04 07:12:02,707 DEBUG CV Batch 10/1100 loss 5.695454 loss_att 6.042869 loss_ctc 10.139679 loss_rnnt 5.033408 history loss 7.083584 rank 7
2022-12-04 07:12:02,788 DEBUG CV Batch 10/1100 loss 5.695454 loss_att 6.042869 loss_ctc 10.139679 loss_rnnt 5.033408 history loss 7.083584 rank 0
2022-12-04 07:12:03,494 DEBUG CV Batch 10/1100 loss 5.695454 loss_att 6.042869 loss_ctc 10.139679 loss_rnnt 5.033408 history loss 7.083584 rank 3
2022-12-04 07:12:10,448 DEBUG CV Batch 10/1200 loss 10.519156 loss_att 10.662235 loss_ctc 12.412161 loss_rnnt 10.238139 history loss 7.412392 rank 4
2022-12-04 07:12:11,395 DEBUG CV Batch 10/1200 loss 10.519156 loss_att 10.662235 loss_ctc 12.412161 loss_rnnt 10.238139 history loss 7.412392 rank 5
2022-12-04 07:12:11,541 DEBUG CV Batch 10/1200 loss 10.519156 loss_att 10.662235 loss_ctc 12.412161 loss_rnnt 10.238139 history loss 7.412392 rank 2
2022-12-04 07:12:12,220 DEBUG CV Batch 10/1200 loss 10.519156 loss_att 10.662235 loss_ctc 12.412161 loss_rnnt 10.238139 history loss 7.412392 rank 1
2022-12-04 07:12:12,684 DEBUG CV Batch 10/1200 loss 10.519156 loss_att 10.662235 loss_ctc 12.412161 loss_rnnt 10.238139 history loss 7.412392 rank 6
2022-12-04 07:12:13,311 DEBUG CV Batch 10/1200 loss 10.519156 loss_att 10.662235 loss_ctc 12.412161 loss_rnnt 10.238139 history loss 7.412392 rank 7
2022-12-04 07:12:13,820 DEBUG CV Batch 10/1200 loss 10.519156 loss_att 10.662235 loss_ctc 12.412161 loss_rnnt 10.238139 history loss 7.412392 rank 0
2022-12-04 07:12:14,624 DEBUG CV Batch 10/1200 loss 10.519156 loss_att 10.662235 loss_ctc 12.412161 loss_rnnt 10.238139 history loss 7.412392 rank 3
2022-12-04 07:12:22,366 DEBUG CV Batch 10/1300 loss 5.505025 loss_att 5.717644 loss_ctc 10.123817 loss_rnnt 4.846663 history loss 7.708044 rank 4
2022-12-04 07:12:23,331 DEBUG CV Batch 10/1300 loss 5.505025 loss_att 5.717644 loss_ctc 10.123817 loss_rnnt 4.846663 history loss 7.708044 rank 5
2022-12-04 07:12:23,963 DEBUG CV Batch 10/1300 loss 5.505025 loss_att 5.717644 loss_ctc 10.123817 loss_rnnt 4.846663 history loss 7.708044 rank 2
2022-12-04 07:12:24,140 DEBUG CV Batch 10/1300 loss 5.505025 loss_att 5.717644 loss_ctc 10.123817 loss_rnnt 4.846663 history loss 7.708044 rank 1
2022-12-04 07:12:25,081 DEBUG CV Batch 10/1300 loss 5.505025 loss_att 5.717644 loss_ctc 10.123817 loss_rnnt 4.846663 history loss 7.708044 rank 6
2022-12-04 07:12:25,465 DEBUG CV Batch 10/1300 loss 5.505025 loss_att 5.717644 loss_ctc 10.123817 loss_rnnt 4.846663 history loss 7.708044 rank 7
2022-12-04 07:12:26,168 DEBUG CV Batch 10/1300 loss 5.505025 loss_att 5.717644 loss_ctc 10.123817 loss_rnnt 4.846663 history loss 7.708044 rank 0
2022-12-04 07:12:27,157 DEBUG CV Batch 10/1300 loss 5.505025 loss_att 5.717644 loss_ctc 10.123817 loss_rnnt 4.846663 history loss 7.708044 rank 3
2022-12-04 07:12:33,477 DEBUG CV Batch 10/1400 loss 7.148890 loss_att 26.050755 loss_ctc 7.581744 loss_rnnt 3.310803 history loss 8.018363 rank 4
2022-12-04 07:12:35,237 DEBUG CV Batch 10/1400 loss 7.148890 loss_att 26.050755 loss_ctc 7.581744 loss_rnnt 3.310803 history loss 8.018363 rank 5
2022-12-04 07:12:35,539 DEBUG CV Batch 10/1400 loss 7.148890 loss_att 26.050755 loss_ctc 7.581744 loss_rnnt 3.310803 history loss 8.018363 rank 2
2022-12-04 07:12:36,681 DEBUG CV Batch 10/1400 loss 7.148890 loss_att 26.050755 loss_ctc 7.581744 loss_rnnt 3.310803 history loss 8.018363 rank 6
2022-12-04 07:12:36,800 DEBUG CV Batch 10/1400 loss 7.148890 loss_att 26.050755 loss_ctc 7.581744 loss_rnnt 3.310803 history loss 8.018363 rank 1
2022-12-04 07:12:37,090 DEBUG CV Batch 10/1400 loss 7.148890 loss_att 26.050755 loss_ctc 7.581744 loss_rnnt 3.310803 history loss 8.018363 rank 7
2022-12-04 07:12:37,931 DEBUG CV Batch 10/1400 loss 7.148890 loss_att 26.050755 loss_ctc 7.581744 loss_rnnt 3.310803 history loss 8.018363 rank 0
2022-12-04 07:12:39,102 DEBUG CV Batch 10/1400 loss 7.148890 loss_att 26.050755 loss_ctc 7.581744 loss_rnnt 3.310803 history loss 8.018363 rank 3
2022-12-04 07:12:44,850 DEBUG CV Batch 10/1500 loss 8.185513 loss_att 10.208192 loss_ctc 10.503628 loss_rnnt 7.471895 history loss 7.843337 rank 4
2022-12-04 07:12:46,923 DEBUG CV Batch 10/1500 loss 8.185513 loss_att 10.208192 loss_ctc 10.503628 loss_rnnt 7.471895 history loss 7.843337 rank 2
2022-12-04 07:12:47,927 DEBUG CV Batch 10/1500 loss 8.185513 loss_att 10.208192 loss_ctc 10.503628 loss_rnnt 7.471895 history loss 7.843337 rank 5
2022-12-04 07:12:48,512 DEBUG CV Batch 10/1500 loss 8.185513 loss_att 10.208192 loss_ctc 10.503628 loss_rnnt 7.471895 history loss 7.843337 rank 6
2022-12-04 07:12:49,157 DEBUG CV Batch 10/1500 loss 8.185513 loss_att 10.208192 loss_ctc 10.503628 loss_rnnt 7.471895 history loss 7.843337 rank 1
2022-12-04 07:12:49,639 DEBUG CV Batch 10/1500 loss 8.185513 loss_att 10.208192 loss_ctc 10.503628 loss_rnnt 7.471895 history loss 7.843337 rank 7
2022-12-04 07:12:49,996 DEBUG CV Batch 10/1500 loss 8.185513 loss_att 10.208192 loss_ctc 10.503628 loss_rnnt 7.471895 history loss 7.843337 rank 0
2022-12-04 07:12:51,165 DEBUG CV Batch 10/1500 loss 8.185513 loss_att 10.208192 loss_ctc 10.503628 loss_rnnt 7.471895 history loss 7.843337 rank 3
2022-12-04 07:12:57,930 DEBUG CV Batch 10/1600 loss 9.024580 loss_att 16.878426 loss_ctc 12.940316 loss_rnnt 6.931713 history loss 7.776464 rank 4
2022-12-04 07:13:00,493 DEBUG CV Batch 10/1600 loss 9.024580 loss_att 16.878426 loss_ctc 12.940316 loss_rnnt 6.931713 history loss 7.776464 rank 2
2022-12-04 07:13:01,593 DEBUG CV Batch 10/1600 loss 9.024580 loss_att 16.878426 loss_ctc 12.940316 loss_rnnt 6.931713 history loss 7.776464 rank 5
2022-12-04 07:13:01,810 DEBUG CV Batch 10/1600 loss 9.024580 loss_att 16.878426 loss_ctc 12.940316 loss_rnnt 6.931713 history loss 7.776464 rank 6
2022-12-04 07:13:02,678 DEBUG CV Batch 10/1600 loss 9.024580 loss_att 16.878426 loss_ctc 12.940316 loss_rnnt 6.931713 history loss 7.776464 rank 1
2022-12-04 07:13:03,288 DEBUG CV Batch 10/1600 loss 9.024580 loss_att 16.878426 loss_ctc 12.940316 loss_rnnt 6.931713 history loss 7.776464 rank 7
2022-12-04 07:13:03,462 DEBUG CV Batch 10/1600 loss 9.024580 loss_att 16.878426 loss_ctc 12.940316 loss_rnnt 6.931713 history loss 7.776464 rank 0
2022-12-04 07:13:04,769 DEBUG CV Batch 10/1600 loss 9.024580 loss_att 16.878426 loss_ctc 12.940316 loss_rnnt 6.931713 history loss 7.776464 rank 3
2022-12-04 07:13:10,641 DEBUG CV Batch 10/1700 loss 11.827505 loss_att 10.907074 loss_ctc 18.809689 loss_rnnt 11.080634 history loss 7.686811 rank 4
2022-12-04 07:13:13,830 DEBUG CV Batch 10/1700 loss 11.827505 loss_att 10.907074 loss_ctc 18.809689 loss_rnnt 11.080634 history loss 7.686811 rank 2
2022-12-04 07:13:13,999 DEBUG CV Batch 10/1700 loss 11.827505 loss_att 10.907074 loss_ctc 18.809689 loss_rnnt 11.080634 history loss 7.686811 rank 5
2022-12-04 07:13:14,439 DEBUG CV Batch 10/1700 loss 11.827505 loss_att 10.907074 loss_ctc 18.809689 loss_rnnt 11.080634 history loss 7.686811 rank 6
2022-12-04 07:13:15,044 DEBUG CV Batch 10/1700 loss 11.827505 loss_att 10.907074 loss_ctc 18.809689 loss_rnnt 11.080634 history loss 7.686811 rank 1
2022-12-04 07:13:15,890 DEBUG CV Batch 10/1700 loss 11.827505 loss_att 10.907074 loss_ctc 18.809689 loss_rnnt 11.080634 history loss 7.686811 rank 7
2022-12-04 07:13:16,145 DEBUG CV Batch 10/1700 loss 11.827505 loss_att 10.907074 loss_ctc 18.809689 loss_rnnt 11.080634 history loss 7.686811 rank 0
2022-12-04 07:13:17,485 DEBUG CV Batch 10/1700 loss 11.827505 loss_att 10.907074 loss_ctc 18.809689 loss_rnnt 11.080634 history loss 7.686811 rank 3
2022-12-04 07:13:20,010 INFO Epoch 10 CV info cv_loss 7.659262217526354
2022-12-04 07:13:20,010 INFO Epoch 11 TRAIN info lr 0.0005221779047366788
2022-12-04 07:13:20,012 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 07:13:23,296 INFO Epoch 10 CV info cv_loss 7.659262217526354
2022-12-04 07:13:23,297 INFO Epoch 11 TRAIN info lr 0.0005218734734203946
2022-12-04 07:13:23,302 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 07:13:23,304 INFO Epoch 10 CV info cv_loss 7.659262217526354
2022-12-04 07:13:23,304 INFO Epoch 11 TRAIN info lr 0.0005221864478738994
2022-12-04 07:13:23,306 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 07:13:23,507 INFO Epoch 10 CV info cv_loss 7.659262217526354
2022-12-04 07:13:23,507 INFO Epoch 11 TRAIN info lr 0.0005221494306406346
2022-12-04 07:13:23,509 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 07:13:24,334 INFO Epoch 10 CV info cv_loss 7.659262217526354
2022-12-04 07:13:24,334 INFO Epoch 11 TRAIN info lr 0.0005220185097681493
2022-12-04 07:13:24,336 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 07:13:25,250 INFO Epoch 10 CV info cv_loss 7.659262217526354
2022-12-04 07:13:25,250 INFO Epoch 11 TRAIN info lr 0.0005220668820958698
2022-12-04 07:13:25,252 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 07:13:25,326 INFO Epoch 10 CV info cv_loss 7.659262217526354
2022-12-04 07:13:25,327 INFO Checkpoint: save to checkpoint exp/1202_encoder_bias_30_0.1/10.pt
2022-12-04 07:13:25,987 INFO Epoch 11 TRAIN info lr 0.0005220554991619313
2022-12-04 07:13:25,991 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 07:13:26,785 INFO Epoch 10 CV info cv_loss 7.659262217526354
2022-12-04 07:13:26,785 INFO Epoch 11 TRAIN info lr 0.0005219872171906762
2022-12-04 07:13:26,787 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 07:14:29,244 DEBUG TRAIN Batch 11/0 loss 7.165220 loss_att 7.896893 loss_ctc 9.894881 loss_rnnt 6.654931 lr 0.00052215 rank 6
2022-12-04 07:14:29,248 DEBUG TRAIN Batch 11/0 loss 10.511904 loss_att 10.487583 loss_ctc 14.266841 loss_rnnt 10.016109 lr 0.00052218 rank 4
2022-12-04 07:14:29,248 DEBUG TRAIN Batch 11/0 loss 12.160517 loss_att 11.081265 loss_ctc 15.345087 loss_rnnt 11.951758 lr 0.00052202 rank 1
2022-12-04 07:14:29,249 DEBUG TRAIN Batch 11/0 loss 9.104056 loss_att 8.744659 loss_ctc 11.737717 loss_rnnt 8.824780 lr 0.00052187 rank 2
2022-12-04 07:14:29,266 DEBUG TRAIN Batch 11/0 loss 13.826070 loss_att 12.924950 loss_ctc 17.712616 loss_rnnt 13.488088 lr 0.00052218 rank 5
2022-12-04 07:14:29,268 DEBUG TRAIN Batch 11/0 loss 9.764584 loss_att 9.826845 loss_ctc 13.436345 loss_rnnt 9.262563 lr 0.00052198 rank 3
2022-12-04 07:14:29,271 DEBUG TRAIN Batch 11/0 loss 6.863645 loss_att 7.262860 loss_ctc 10.760770 loss_rnnt 6.264184 lr 0.00052205 rank 0
2022-12-04 07:14:29,275 DEBUG TRAIN Batch 11/0 loss 8.373884 loss_att 8.257625 loss_ctc 11.428237 loss_rnnt 7.989889 lr 0.00052206 rank 7
2022-12-04 07:15:40,181 DEBUG TRAIN Batch 11/100 loss 14.866748 loss_att 20.464983 loss_ctc 24.030312 loss_rnnt 12.525291 lr 0.00052170 rank 3
2022-12-04 07:15:40,181 DEBUG TRAIN Batch 11/100 loss 8.300738 loss_att 12.177481 loss_ctc 14.824871 loss_rnnt 6.655505 lr 0.00052190 rank 5
2022-12-04 07:15:40,184 DEBUG TRAIN Batch 11/100 loss 10.437716 loss_att 15.140809 loss_ctc 19.526724 loss_rnnt 8.285229 lr 0.00052177 rank 0
2022-12-04 07:15:40,185 DEBUG TRAIN Batch 11/100 loss 6.394439 loss_att 10.011025 loss_ctc 8.650743 loss_rnnt 5.370281 lr 0.00052186 rank 6
2022-12-04 07:15:40,186 DEBUG TRAIN Batch 11/100 loss 9.014995 loss_att 12.523764 loss_ctc 10.291416 loss_rnnt 8.143051 lr 0.00052159 rank 2
2022-12-04 07:15:40,187 DEBUG TRAIN Batch 11/100 loss 3.780913 loss_att 9.320888 loss_ctc 7.422278 loss_rnnt 2.187403 lr 0.00052178 rank 7
2022-12-04 07:15:40,188 DEBUG TRAIN Batch 11/100 loss 11.530634 loss_att 15.102582 loss_ctc 20.094597 loss_rnnt 9.674382 lr 0.00052189 rank 4
2022-12-04 07:15:40,191 DEBUG TRAIN Batch 11/100 loss 23.619871 loss_att 25.351994 loss_ctc 33.469025 loss_rnnt 21.960226 lr 0.00052173 rank 1
2022-12-04 07:16:52,359 DEBUG TRAIN Batch 11/200 loss 14.578064 loss_att 15.011389 loss_ctc 17.653683 loss_rnnt 14.081317 lr 0.00052148 rank 0
2022-12-04 07:16:52,376 DEBUG TRAIN Batch 11/200 loss 7.436152 loss_att 11.986495 loss_ctc 12.730635 loss_rnnt 5.820152 lr 0.00052161 rank 5
2022-12-04 07:16:52,378 DEBUG TRAIN Batch 11/200 loss 10.293223 loss_att 18.018333 loss_ctc 24.079910 loss_rnnt 6.909976 lr 0.00052145 rank 1
2022-12-04 07:16:52,379 DEBUG TRAIN Batch 11/200 loss 13.042719 loss_att 16.332169 loss_ctc 24.392025 loss_rnnt 10.871589 lr 0.00052158 rank 6
2022-12-04 07:16:52,383 DEBUG TRAIN Batch 11/200 loss 17.259468 loss_att 21.215288 loss_ctc 27.230642 loss_rnnt 15.138813 lr 0.00052161 rank 4
2022-12-04 07:16:52,384 DEBUG TRAIN Batch 11/200 loss 5.349958 loss_att 11.121688 loss_ctc 8.438070 loss_rnnt 3.783864 lr 0.00052130 rank 2
2022-12-04 07:16:52,385 DEBUG TRAIN Batch 11/200 loss 15.175865 loss_att 19.406342 loss_ctc 25.682770 loss_rnnt 12.928848 lr 0.00052150 rank 7
2022-12-04 07:16:52,386 DEBUG TRAIN Batch 11/200 loss 2.752872 loss_att 5.960383 loss_ctc 4.980004 loss_rnnt 1.814419 lr 0.00052142 rank 3
2022-12-04 07:18:05,177 DEBUG TRAIN Batch 11/300 loss 24.031033 loss_att 31.357544 loss_ctc 51.009644 loss_rnnt 18.968582 lr 0.00052133 rank 5
2022-12-04 07:18:05,180 DEBUG TRAIN Batch 11/300 loss 13.333835 loss_att 14.990519 loss_ctc 18.838654 loss_rnnt 12.268522 lr 0.00052129 rank 6
2022-12-04 07:18:05,182 DEBUG TRAIN Batch 11/300 loss 12.245622 loss_att 14.341063 loss_ctc 20.593451 loss_rnnt 10.713490 lr 0.00052113 rank 3
2022-12-04 07:18:05,186 DEBUG TRAIN Batch 11/300 loss 18.101763 loss_att 20.951092 loss_ctc 28.344366 loss_rnnt 16.166216 lr 0.00052120 rank 0
2022-12-04 07:18:05,193 DEBUG TRAIN Batch 11/300 loss 11.987272 loss_att 18.357965 loss_ctc 20.531919 loss_rnnt 9.573848 lr 0.00052132 rank 4
2022-12-04 07:18:05,193 DEBUG TRAIN Batch 11/300 loss 13.838674 loss_att 15.908913 loss_ctc 21.167040 loss_rnnt 12.447510 lr 0.00052102 rank 2
2022-12-04 07:18:05,196 DEBUG TRAIN Batch 11/300 loss 6.711913 loss_att 8.798380 loss_ctc 10.830757 loss_rnnt 5.745440 lr 0.00052116 rank 1
2022-12-04 07:18:05,245 DEBUG TRAIN Batch 11/300 loss 7.831426 loss_att 11.665966 loss_ctc 16.447977 loss_rnnt 5.915645 lr 0.00052121 rank 7
2022-12-04 07:19:21,303 DEBUG TRAIN Batch 11/400 loss 8.139835 loss_att 12.752784 loss_ctc 13.997846 loss_rnnt 6.436178 lr 0.00052101 rank 6
2022-12-04 07:19:21,306 DEBUG TRAIN Batch 11/400 loss 12.084063 loss_att 15.662046 loss_ctc 24.530283 loss_rnnt 9.708969 lr 0.00052085 rank 3
2022-12-04 07:19:21,308 DEBUG TRAIN Batch 11/400 loss 12.310895 loss_att 17.513313 loss_ctc 20.188551 loss_rnnt 10.220057 lr 0.00052092 rank 0
2022-12-04 07:19:21,307 DEBUG TRAIN Batch 11/400 loss 20.192333 loss_att 23.258308 loss_ctc 29.925438 loss_rnnt 18.281391 lr 0.00052088 rank 1
2022-12-04 07:19:21,311 DEBUG TRAIN Batch 11/400 loss 16.018238 loss_att 21.388313 loss_ctc 27.063658 loss_rnnt 13.471502 lr 0.00052074 rank 2
2022-12-04 07:19:21,314 DEBUG TRAIN Batch 11/400 loss 14.373962 loss_att 19.928764 loss_ctc 24.335861 loss_rnnt 11.934749 lr 0.00052105 rank 5
2022-12-04 07:19:21,315 DEBUG TRAIN Batch 11/400 loss 14.281830 loss_att 17.326694 loss_ctc 22.671383 loss_rnnt 12.554251 lr 0.00052093 rank 7
2022-12-04 07:19:21,318 DEBUG TRAIN Batch 11/400 loss 13.435454 loss_att 19.607822 loss_ctc 19.481741 loss_rnnt 11.394808 lr 0.00052104 rank 4
2022-12-04 07:20:31,821 DEBUG TRAIN Batch 11/500 loss 15.408816 loss_att 20.763119 loss_ctc 31.321423 loss_rnnt 12.216276 lr 0.00052064 rank 0
2022-12-04 07:20:31,821 DEBUG TRAIN Batch 11/500 loss 20.089500 loss_att 25.349253 loss_ctc 30.867729 loss_rnnt 17.600452 lr 0.00052046 rank 2
2022-12-04 07:20:31,821 DEBUG TRAIN Batch 11/500 loss 14.676721 loss_att 20.484604 loss_ctc 23.218243 loss_rnnt 12.376274 lr 0.00052057 rank 3
2022-12-04 07:20:31,823 DEBUG TRAIN Batch 11/500 loss 9.845230 loss_att 11.263232 loss_ctc 12.813457 loss_rnnt 9.165867 lr 0.00052073 rank 6
2022-12-04 07:20:31,824 DEBUG TRAIN Batch 11/500 loss 8.004456 loss_att 10.543755 loss_ctc 16.847683 loss_rnnt 6.317498 lr 0.00052060 rank 1
2022-12-04 07:20:31,825 DEBUG TRAIN Batch 11/500 loss 13.356324 loss_att 15.048359 loss_ctc 20.352888 loss_rnnt 12.085043 lr 0.00052077 rank 5
2022-12-04 07:20:31,827 DEBUG TRAIN Batch 11/500 loss 17.612919 loss_att 19.685368 loss_ctc 30.916595 loss_rnnt 15.424606 lr 0.00052065 rank 7
2022-12-04 07:20:31,828 DEBUG TRAIN Batch 11/500 loss 11.457007 loss_att 13.185493 loss_ctc 18.516230 loss_rnnt 10.170081 lr 0.00052076 rank 4
2022-12-04 07:21:43,346 DEBUG TRAIN Batch 11/600 loss 10.110783 loss_att 12.741233 loss_ctc 17.401115 loss_rnnt 8.612648 lr 0.00052029 rank 3
2022-12-04 07:21:43,347 DEBUG TRAIN Batch 11/600 loss 19.494061 loss_att 22.317881 loss_ctc 35.743828 loss_rnnt 16.762659 lr 0.00052045 rank 6
2022-12-04 07:21:43,349 DEBUG TRAIN Batch 11/600 loss 13.507360 loss_att 16.078453 loss_ctc 21.412205 loss_rnnt 11.939163 lr 0.00052032 rank 1
2022-12-04 07:21:43,351 DEBUG TRAIN Batch 11/600 loss 16.047800 loss_att 17.184540 loss_ctc 29.978447 loss_rnnt 13.963033 lr 0.00052048 rank 5
2022-12-04 07:21:43,351 DEBUG TRAIN Batch 11/600 loss 11.093981 loss_att 11.569245 loss_ctc 15.680223 loss_rnnt 10.387428 lr 0.00052035 rank 0
2022-12-04 07:21:43,354 DEBUG TRAIN Batch 11/600 loss 17.588148 loss_att 19.136883 loss_ctc 30.263269 loss_rnnt 15.588384 lr 0.00052036 rank 7
2022-12-04 07:21:43,356 DEBUG TRAIN Batch 11/600 loss 8.930280 loss_att 12.824995 loss_ctc 17.286108 loss_rnnt 7.037227 lr 0.00052017 rank 2
2022-12-04 07:21:43,356 DEBUG TRAIN Batch 11/600 loss 15.209343 loss_att 19.483015 loss_ctc 24.357618 loss_rnnt 13.134838 lr 0.00052047 rank 4
2022-12-04 07:22:57,513 DEBUG TRAIN Batch 11/700 loss 12.195797 loss_att 17.579052 loss_ctc 23.460295 loss_rnnt 9.617213 lr 0.00052019 rank 4
2022-12-04 07:22:57,521 DEBUG TRAIN Batch 11/700 loss 16.357035 loss_att 25.853512 loss_ctc 30.969372 loss_rnnt 12.509428 lr 0.00052008 rank 7
2022-12-04 07:22:57,523 DEBUG TRAIN Batch 11/700 loss 14.627693 loss_att 19.483072 loss_ctc 29.258490 loss_rnnt 11.705845 lr 0.00051989 rank 2
2022-12-04 07:22:57,525 DEBUG TRAIN Batch 11/700 loss 19.605675 loss_att 23.225027 loss_ctc 32.254448 loss_rnnt 17.195299 lr 0.00052007 rank 0
2022-12-04 07:22:57,529 DEBUG TRAIN Batch 11/700 loss 12.553234 loss_att 18.688456 loss_ctc 22.152271 loss_rnnt 10.046318 lr 0.00052000 rank 3
2022-12-04 07:22:57,540 DEBUG TRAIN Batch 11/700 loss 29.791706 loss_att 40.606693 loss_ctc 64.159409 loss_rnnt 23.046347 lr 0.00052016 rank 6
2022-12-04 07:22:57,545 DEBUG TRAIN Batch 11/700 loss 11.014999 loss_att 18.910793 loss_ctc 15.638880 loss_rnnt 8.819324 lr 0.00052004 rank 1
2022-12-04 07:22:57,576 DEBUG TRAIN Batch 11/700 loss 7.912615 loss_att 10.026963 loss_ctc 10.401544 loss_rnnt 7.157888 lr 0.00052020 rank 5
2022-12-04 07:24:09,291 DEBUG TRAIN Batch 11/800 loss 11.388901 loss_att 15.503567 loss_ctc 19.122173 loss_rnnt 9.534865 lr 0.00051992 rank 5
2022-12-04 07:24:09,300 DEBUG TRAIN Batch 11/800 loss 12.244020 loss_att 19.186752 loss_ctc 20.491484 loss_rnnt 9.755812 lr 0.00051991 rank 4
2022-12-04 07:24:09,303 DEBUG TRAIN Batch 11/800 loss 10.070842 loss_att 13.965118 loss_ctc 20.448433 loss_rnnt 7.908308 lr 0.00051979 rank 0
2022-12-04 07:24:09,306 DEBUG TRAIN Batch 11/800 loss 5.777340 loss_att 11.793884 loss_ctc 14.651505 loss_rnnt 3.390810 lr 0.00051972 rank 3
2022-12-04 07:24:09,308 DEBUG TRAIN Batch 11/800 loss 18.498638 loss_att 25.060135 loss_ctc 38.662163 loss_rnnt 14.497869 lr 0.00051980 rank 7
2022-12-04 07:24:09,309 DEBUG TRAIN Batch 11/800 loss 6.985536 loss_att 12.358922 loss_ctc 11.015860 loss_rnnt 5.373482 lr 0.00051988 rank 6
2022-12-04 07:24:09,309 DEBUG TRAIN Batch 11/800 loss 14.905201 loss_att 19.830946 loss_ctc 29.496731 loss_rnnt 11.974516 lr 0.00051961 rank 2
2022-12-04 07:24:09,360 DEBUG TRAIN Batch 11/800 loss 9.050303 loss_att 18.542706 loss_ctc 14.461355 loss_rnnt 6.430349 lr 0.00051975 rank 1
2022-12-04 07:25:20,824 DEBUG TRAIN Batch 11/900 loss 7.881448 loss_att 10.166071 loss_ctc 12.563311 loss_rnnt 6.800275 lr 0.00051960 rank 6
2022-12-04 07:25:20,825 DEBUG TRAIN Batch 11/900 loss 9.516775 loss_att 14.526582 loss_ctc 20.244598 loss_rnnt 7.084437 lr 0.00051944 rank 3
2022-12-04 07:25:20,827 DEBUG TRAIN Batch 11/900 loss 14.571838 loss_att 18.123371 loss_ctc 23.416492 loss_rnnt 12.682244 lr 0.00051964 rank 5
2022-12-04 07:25:20,827 DEBUG TRAIN Batch 11/900 loss 9.082614 loss_att 12.791994 loss_ctc 14.804390 loss_rnnt 7.577834 lr 0.00051952 rank 7
2022-12-04 07:25:20,828 DEBUG TRAIN Batch 11/900 loss 15.439567 loss_att 18.258760 loss_ctc 25.930250 loss_rnnt 13.476970 lr 0.00051947 rank 1
2022-12-04 07:25:20,828 DEBUG TRAIN Batch 11/900 loss 9.094639 loss_att 14.088967 loss_ctc 12.223684 loss_rnnt 7.678567 lr 0.00051951 rank 0
2022-12-04 07:25:20,836 DEBUG TRAIN Batch 11/900 loss 19.423399 loss_att 23.905619 loss_ctc 25.793282 loss_rnnt 17.677637 lr 0.00051963 rank 4
2022-12-04 07:25:20,836 DEBUG TRAIN Batch 11/900 loss 14.072193 loss_att 16.245003 loss_ctc 22.161049 loss_rnnt 12.559118 lr 0.00051933 rank 2
2022-12-04 07:26:32,097 DEBUG TRAIN Batch 11/1000 loss 9.831336 loss_att 14.043426 loss_ctc 14.932968 loss_rnnt 8.308701 lr 0.00051916 rank 3
2022-12-04 07:26:32,106 DEBUG TRAIN Batch 11/1000 loss 8.482656 loss_att 12.982834 loss_ctc 23.090475 loss_rnnt 5.634911 lr 0.00051936 rank 5
2022-12-04 07:26:32,107 DEBUG TRAIN Batch 11/1000 loss 9.260636 loss_att 13.067181 loss_ctc 17.362093 loss_rnnt 7.419133 lr 0.00051932 rank 6
2022-12-04 07:26:32,109 DEBUG TRAIN Batch 11/1000 loss 21.463902 loss_att 23.983503 loss_ctc 36.266670 loss_rnnt 18.986279 lr 0.00051924 rank 7
2022-12-04 07:26:32,112 DEBUG TRAIN Batch 11/1000 loss 15.531527 loss_att 18.180120 loss_ctc 24.588280 loss_rnnt 13.794240 lr 0.00051919 rank 1
2022-12-04 07:26:32,113 DEBUG TRAIN Batch 11/1000 loss 18.554628 loss_att 23.631212 loss_ctc 32.264076 loss_rnnt 15.711386 lr 0.00051923 rank 0
2022-12-04 07:26:32,114 DEBUG TRAIN Batch 11/1000 loss 8.452773 loss_att 14.874031 loss_ctc 17.362186 loss_rnnt 5.980599 lr 0.00051935 rank 4
2022-12-04 07:26:32,143 DEBUG TRAIN Batch 11/1000 loss 7.177527 loss_att 10.971101 loss_ctc 11.781656 loss_rnnt 5.804928 lr 0.00051905 rank 2
2022-12-04 07:27:46,532 DEBUG TRAIN Batch 11/1100 loss 18.787201 loss_att 21.311918 loss_ctc 35.794167 loss_rnnt 16.014660 lr 0.00051877 rank 2
2022-12-04 07:27:46,539 DEBUG TRAIN Batch 11/1100 loss 19.745678 loss_att 23.648115 loss_ctc 25.302874 loss_rnnt 18.224232 lr 0.00051904 rank 6
2022-12-04 07:27:46,540 DEBUG TRAIN Batch 11/1100 loss 10.549709 loss_att 14.727884 loss_ctc 20.475607 loss_rnnt 8.390621 lr 0.00051891 rank 1
2022-12-04 07:27:46,544 DEBUG TRAIN Batch 11/1100 loss 9.668548 loss_att 12.322636 loss_ctc 20.374659 loss_rnnt 7.710249 lr 0.00051895 rank 0
2022-12-04 07:27:46,549 DEBUG TRAIN Batch 11/1100 loss 4.185849 loss_att 8.963258 loss_ctc 14.884230 loss_rnnt 1.803916 lr 0.00051907 rank 4
2022-12-04 07:27:46,550 DEBUG TRAIN Batch 11/1100 loss 15.859010 loss_att 20.673056 loss_ctc 22.782860 loss_rnnt 13.973021 lr 0.00051888 rank 3
2022-12-04 07:27:46,552 DEBUG TRAIN Batch 11/1100 loss 9.685208 loss_att 13.658676 loss_ctc 18.498077 loss_rnnt 7.715466 lr 0.00051896 rank 7
2022-12-04 07:27:46,589 DEBUG TRAIN Batch 11/1100 loss 14.340277 loss_att 18.436460 loss_ctc 22.432789 loss_rnnt 12.442039 lr 0.00051908 rank 5
2022-12-04 07:28:57,979 DEBUG TRAIN Batch 11/1200 loss 12.472897 loss_att 16.141468 loss_ctc 24.091932 loss_rnnt 10.189977 lr 0.00051863 rank 1
2022-12-04 07:28:57,992 DEBUG TRAIN Batch 11/1200 loss 11.838352 loss_att 12.867603 loss_ctc 21.453451 loss_rnnt 10.350489 lr 0.00051860 rank 3
2022-12-04 07:28:57,996 DEBUG TRAIN Batch 11/1200 loss 11.520958 loss_att 13.119289 loss_ctc 19.195343 loss_rnnt 10.178040 lr 0.00051876 rank 6
2022-12-04 07:28:57,997 DEBUG TRAIN Batch 11/1200 loss 25.065788 loss_att 27.879784 loss_ctc 40.969246 loss_rnnt 22.382524 lr 0.00051867 rank 0
2022-12-04 07:28:57,999 DEBUG TRAIN Batch 11/1200 loss 10.816107 loss_att 11.820884 loss_ctc 18.105051 loss_rnnt 9.643292 lr 0.00051879 rank 4
2022-12-04 07:28:58,002 DEBUG TRAIN Batch 11/1200 loss 8.153955 loss_att 11.774283 loss_ctc 15.343451 loss_rnnt 6.471289 lr 0.00051880 rank 5
2022-12-04 07:28:58,002 DEBUG TRAIN Batch 11/1200 loss 13.998921 loss_att 15.803819 loss_ctc 19.884954 loss_rnnt 12.853137 lr 0.00051849 rank 2
2022-12-04 07:28:58,019 DEBUG TRAIN Batch 11/1200 loss 13.911685 loss_att 16.853359 loss_ctc 19.294516 loss_rnnt 12.605639 lr 0.00051868 rank 7
2022-12-04 07:30:09,944 DEBUG TRAIN Batch 11/1300 loss 10.455297 loss_att 13.933061 loss_ctc 23.859625 loss_rnnt 7.972500 lr 0.00051839 rank 0
2022-12-04 07:30:09,946 DEBUG TRAIN Batch 11/1300 loss 8.799238 loss_att 9.185270 loss_ctc 13.150091 loss_rnnt 8.141918 lr 0.00051836 rank 1
2022-12-04 07:30:09,947 DEBUG TRAIN Batch 11/1300 loss 12.605731 loss_att 20.284771 loss_ctc 19.585396 loss_rnnt 10.139300 lr 0.00051848 rank 6
2022-12-04 07:30:09,949 DEBUG TRAIN Batch 11/1300 loss 4.808412 loss_att 14.524459 loss_ctc 10.482528 loss_rnnt 2.108653 lr 0.00051852 rank 5
2022-12-04 07:30:09,949 DEBUG TRAIN Batch 11/1300 loss 8.721496 loss_att 12.720422 loss_ctc 17.841967 loss_rnnt 6.705648 lr 0.00051821 rank 2
2022-12-04 07:30:09,949 DEBUG TRAIN Batch 11/1300 loss 6.842059 loss_att 9.665208 loss_ctc 10.753702 loss_rnnt 5.755877 lr 0.00051840 rank 7
2022-12-04 07:30:09,952 DEBUG TRAIN Batch 11/1300 loss 5.826760 loss_att 10.095816 loss_ctc 9.447041 loss_rnnt 4.490244 lr 0.00051833 rank 3
2022-12-04 07:30:09,954 DEBUG TRAIN Batch 11/1300 loss 10.376511 loss_att 14.905640 loss_ctc 20.891548 loss_rnnt 8.068680 lr 0.00051851 rank 4
2022-12-04 07:31:24,379 DEBUG TRAIN Batch 11/1400 loss 8.043467 loss_att 11.884457 loss_ctc 15.326976 loss_rnnt 6.304133 lr 0.00051794 rank 2
2022-12-04 07:31:24,386 DEBUG TRAIN Batch 11/1400 loss 23.698198 loss_att 23.780994 loss_ctc 33.437668 loss_rnnt 22.383041 lr 0.00051811 rank 0
2022-12-04 07:31:24,392 DEBUG TRAIN Batch 11/1400 loss 12.790310 loss_att 15.518588 loss_ctc 17.609581 loss_rnnt 11.602085 lr 0.00051824 rank 5
2022-12-04 07:31:24,393 DEBUG TRAIN Batch 11/1400 loss 14.152695 loss_att 16.183786 loss_ctc 22.526806 loss_rnnt 12.629929 lr 0.00051812 rank 7
2022-12-04 07:31:24,394 DEBUG TRAIN Batch 11/1400 loss 13.992734 loss_att 18.111366 loss_ctc 18.798859 loss_rnnt 12.528191 lr 0.00051821 rank 6
2022-12-04 07:31:24,397 DEBUG TRAIN Batch 11/1400 loss 6.645525 loss_att 13.144992 loss_ctc 9.872315 loss_rnnt 4.915393 lr 0.00051805 rank 3
2022-12-04 07:31:24,403 DEBUG TRAIN Batch 11/1400 loss 8.977559 loss_att 14.075632 loss_ctc 13.345737 loss_rnnt 7.375521 lr 0.00051823 rank 4
2022-12-04 07:31:24,410 DEBUG TRAIN Batch 11/1400 loss 7.970742 loss_att 12.070176 loss_ctc 13.975027 loss_rnnt 6.350284 lr 0.00051808 rank 1
2022-12-04 07:32:37,508 DEBUG TRAIN Batch 11/1500 loss 14.012907 loss_att 17.252764 loss_ctc 26.704636 loss_rnnt 11.672706 lr 0.00051780 rank 1
2022-12-04 07:32:37,509 DEBUG TRAIN Batch 11/1500 loss 3.256946 loss_att 6.712873 loss_ctc 5.514038 loss_rnnt 2.264815 lr 0.00051784 rank 0
2022-12-04 07:32:37,509 DEBUG TRAIN Batch 11/1500 loss 11.149513 loss_att 15.446447 loss_ctc 19.204893 loss_rnnt 9.216076 lr 0.00051793 rank 6
2022-12-04 07:32:37,509 DEBUG TRAIN Batch 11/1500 loss 13.162489 loss_att 22.074396 loss_ctc 24.128134 loss_rnnt 9.918022 lr 0.00051796 rank 5
2022-12-04 07:32:37,509 DEBUG TRAIN Batch 11/1500 loss 16.955435 loss_att 23.872868 loss_ctc 28.434887 loss_rnnt 14.041355 lr 0.00051777 rank 3
2022-12-04 07:32:37,511 DEBUG TRAIN Batch 11/1500 loss 7.449125 loss_att 10.843172 loss_ctc 13.304398 loss_rnnt 5.989613 lr 0.00051766 rank 2
2022-12-04 07:32:37,545 DEBUG TRAIN Batch 11/1500 loss 4.712149 loss_att 10.440231 loss_ctc 6.692745 loss_rnnt 3.302453 lr 0.00051785 rank 7
2022-12-04 07:32:37,556 DEBUG TRAIN Batch 11/1500 loss 8.355471 loss_att 12.050154 loss_ctc 15.386477 loss_rnnt 6.679067 lr 0.00051796 rank 4
2022-12-04 07:33:50,220 DEBUG TRAIN Batch 11/1600 loss 9.040897 loss_att 14.605931 loss_ctc 16.287382 loss_rnnt 6.961693 lr 0.00051765 rank 6
2022-12-04 07:33:50,221 DEBUG TRAIN Batch 11/1600 loss 12.119741 loss_att 15.509108 loss_ctc 16.618652 loss_rnnt 10.842012 lr 0.00051769 rank 5
2022-12-04 07:33:50,222 DEBUG TRAIN Batch 11/1600 loss 21.312624 loss_att 25.254477 loss_ctc 31.900442 loss_rnnt 19.112543 lr 0.00051749 rank 3
2022-12-04 07:33:50,225 DEBUG TRAIN Batch 11/1600 loss 14.262553 loss_att 18.460171 loss_ctc 27.244318 loss_rnnt 11.692127 lr 0.00051756 rank 0
2022-12-04 07:33:50,231 DEBUG TRAIN Batch 11/1600 loss 13.003428 loss_att 14.102945 loss_ctc 17.377975 loss_rnnt 12.200250 lr 0.00051757 rank 7
2022-12-04 07:33:50,234 DEBUG TRAIN Batch 11/1600 loss 7.810871 loss_att 12.682498 loss_ctc 13.650177 loss_rnnt 6.057971 lr 0.00051768 rank 4
2022-12-04 07:33:50,235 DEBUG TRAIN Batch 11/1600 loss 9.019610 loss_att 13.369020 loss_ctc 15.623592 loss_rnnt 7.269197 lr 0.00051738 rank 2
2022-12-04 07:33:50,268 DEBUG TRAIN Batch 11/1600 loss 17.741669 loss_att 21.388899 loss_ctc 27.312960 loss_rnnt 15.736048 lr 0.00051752 rank 1
2022-12-04 07:35:02,227 DEBUG TRAIN Batch 11/1700 loss 12.159355 loss_att 13.696323 loss_ctc 19.421213 loss_rnnt 10.883713 lr 0.00051741 rank 5
2022-12-04 07:35:02,228 DEBUG TRAIN Batch 11/1700 loss 14.837443 loss_att 16.805229 loss_ctc 20.230381 loss_rnnt 13.724828 lr 0.00051737 rank 6
2022-12-04 07:35:02,228 DEBUG TRAIN Batch 11/1700 loss 7.503025 loss_att 9.848620 loss_ctc 13.216081 loss_rnnt 6.272165 lr 0.00051728 rank 0
2022-12-04 07:35:02,231 DEBUG TRAIN Batch 11/1700 loss 7.983328 loss_att 11.931170 loss_ctc 12.943038 loss_rnnt 6.532465 lr 0.00051725 rank 1
2022-12-04 07:35:02,231 DEBUG TRAIN Batch 11/1700 loss 18.799479 loss_att 25.314310 loss_ctc 34.691132 loss_rnnt 15.377625 lr 0.00051740 rank 4
2022-12-04 07:35:02,231 DEBUG TRAIN Batch 11/1700 loss 12.180210 loss_att 15.837647 loss_ctc 23.312532 loss_rnnt 9.964413 lr 0.00051721 rank 3
2022-12-04 07:35:02,235 DEBUG TRAIN Batch 11/1700 loss 10.236399 loss_att 13.710138 loss_ctc 21.372465 loss_rnnt 8.056841 lr 0.00051729 rank 7
2022-12-04 07:35:02,242 DEBUG TRAIN Batch 11/1700 loss 13.610785 loss_att 22.476088 loss_ctc 29.523499 loss_rnnt 9.716030 lr 0.00051710 rank 2
2022-12-04 07:36:18,869 DEBUG TRAIN Batch 11/1800 loss 12.498394 loss_att 17.029522 loss_ctc 21.078560 loss_rnnt 10.448147 lr 0.00051710 rank 6
2022-12-04 07:36:18,870 DEBUG TRAIN Batch 11/1800 loss 17.283976 loss_att 18.197699 loss_ctc 26.617382 loss_rnnt 15.856777 lr 0.00051697 rank 1
2022-12-04 07:36:18,873 DEBUG TRAIN Batch 11/1800 loss 13.131639 loss_att 19.263361 loss_ctc 26.240122 loss_rnnt 10.157496 lr 0.00051694 rank 3
2022-12-04 07:36:18,875 DEBUG TRAIN Batch 11/1800 loss 12.733112 loss_att 19.018970 loss_ctc 23.483562 loss_rnnt 10.042548 lr 0.00051683 rank 2
2022-12-04 07:36:18,878 DEBUG TRAIN Batch 11/1800 loss 24.005741 loss_att 26.343046 loss_ctc 32.674248 loss_rnnt 22.382479 lr 0.00051700 rank 0
2022-12-04 07:36:18,880 DEBUG TRAIN Batch 11/1800 loss 12.024519 loss_att 14.861767 loss_ctc 20.288120 loss_rnnt 10.355255 lr 0.00051712 rank 4
2022-12-04 07:36:18,907 DEBUG TRAIN Batch 11/1800 loss 6.848922 loss_att 9.261589 loss_ctc 12.386724 loss_rnnt 5.628015 lr 0.00051702 rank 7
2022-12-04 07:36:18,913 DEBUG TRAIN Batch 11/1800 loss 24.844532 loss_att 26.833858 loss_ctc 40.429077 loss_rnnt 22.368729 lr 0.00051713 rank 5
2022-12-04 07:37:31,494 DEBUG TRAIN Batch 11/1900 loss 13.224253 loss_att 15.049168 loss_ctc 21.530809 loss_rnnt 11.751729 lr 0.00051673 rank 0
2022-12-04 07:37:31,494 DEBUG TRAIN Batch 11/1900 loss 5.794804 loss_att 6.394179 loss_ctc 9.189528 loss_rnnt 5.222299 lr 0.00051686 rank 5
2022-12-04 07:37:31,494 DEBUG TRAIN Batch 11/1900 loss 8.990118 loss_att 10.359980 loss_ctc 13.426968 loss_rnnt 8.124565 lr 0.00051682 rank 6
2022-12-04 07:37:31,498 DEBUG TRAIN Batch 11/1900 loss 8.975090 loss_att 11.369880 loss_ctc 12.867256 loss_rnnt 7.977177 lr 0.00051655 rank 2
2022-12-04 07:37:31,498 DEBUG TRAIN Batch 11/1900 loss 17.038216 loss_att 22.951241 loss_ctc 23.187740 loss_rnnt 15.035674 lr 0.00051666 rank 3
2022-12-04 07:37:31,498 DEBUG TRAIN Batch 11/1900 loss 19.430712 loss_att 20.176050 loss_ctc 28.082943 loss_rnnt 18.128014 lr 0.00051669 rank 1
2022-12-04 07:37:31,501 DEBUG TRAIN Batch 11/1900 loss 11.044003 loss_att 11.338338 loss_ctc 16.282402 loss_rnnt 10.286684 lr 0.00051685 rank 4
2022-12-04 07:37:31,503 DEBUG TRAIN Batch 11/1900 loss 21.052532 loss_att 23.006161 loss_ctc 29.142981 loss_rnnt 19.583080 lr 0.00051674 rank 7
2022-12-04 07:38:42,085 DEBUG TRAIN Batch 11/2000 loss 14.546602 loss_att 16.050352 loss_ctc 20.420403 loss_rnnt 13.462679 lr 0.00051654 rank 6
2022-12-04 07:38:42,086 DEBUG TRAIN Batch 11/2000 loss 11.289871 loss_att 15.881491 loss_ctc 16.310673 loss_rnnt 9.702106 lr 0.00051628 rank 2
2022-12-04 07:38:42,086 DEBUG TRAIN Batch 11/2000 loss 22.977451 loss_att 36.401699 loss_ctc 40.839157 loss_rnnt 17.911041 lr 0.00051646 rank 7
2022-12-04 07:38:42,086 DEBUG TRAIN Batch 11/2000 loss 7.020064 loss_att 11.380857 loss_ctc 14.710314 loss_rnnt 5.122540 lr 0.00051639 rank 3
2022-12-04 07:38:42,087 DEBUG TRAIN Batch 11/2000 loss 13.483779 loss_att 17.330374 loss_ctc 23.155310 loss_rnnt 11.424923 lr 0.00051645 rank 0
2022-12-04 07:38:42,088 DEBUG TRAIN Batch 11/2000 loss 8.949572 loss_att 12.138992 loss_ctc 14.690145 loss_rnnt 7.546278 lr 0.00051658 rank 5
2022-12-04 07:38:42,095 DEBUG TRAIN Batch 11/2000 loss 14.384586 loss_att 19.797962 loss_ctc 21.909866 loss_rnnt 12.298540 lr 0.00051657 rank 4
2022-12-04 07:38:42,133 DEBUG TRAIN Batch 11/2000 loss 8.802999 loss_att 16.349861 loss_ctc 20.225624 loss_rnnt 5.770611 lr 0.00051642 rank 1
2022-12-04 07:39:54,878 DEBUG TRAIN Batch 11/2100 loss 9.784590 loss_att 13.755623 loss_ctc 18.341215 loss_rnnt 7.849500 lr 0.00051611 rank 3
2022-12-04 07:39:54,882 DEBUG TRAIN Batch 11/2100 loss 12.066084 loss_att 15.349826 loss_ctc 21.008276 loss_rnnt 10.217043 lr 0.00051627 rank 6
2022-12-04 07:39:54,883 DEBUG TRAIN Batch 11/2100 loss 15.589418 loss_att 21.723728 loss_ctc 37.258617 loss_rnnt 11.473330 lr 0.00051618 rank 0
2022-12-04 07:39:54,884 DEBUG TRAIN Batch 11/2100 loss 8.350562 loss_att 10.537151 loss_ctc 16.123562 loss_rnnt 6.876844 lr 0.00051619 rank 7
2022-12-04 07:39:54,886 DEBUG TRAIN Batch 11/2100 loss 13.963890 loss_att 16.630470 loss_ctc 25.934254 loss_rnnt 11.834525 lr 0.00051630 rank 4
2022-12-04 07:39:54,888 DEBUG TRAIN Batch 11/2100 loss 10.398403 loss_att 16.071402 loss_ctc 22.962576 loss_rnnt 7.588580 lr 0.00051600 rank 2
2022-12-04 07:39:54,929 DEBUG TRAIN Batch 11/2100 loss 14.141713 loss_att 16.385136 loss_ctc 21.292418 loss_rnnt 12.739601 lr 0.00051630 rank 5
2022-12-04 07:39:54,956 DEBUG TRAIN Batch 11/2100 loss 14.400526 loss_att 18.724339 loss_ctc 25.807922 loss_rnnt 12.014777 lr 0.00051614 rank 1
2022-12-04 07:41:09,402 DEBUG TRAIN Batch 11/2200 loss 21.782116 loss_att 28.595917 loss_ctc 36.075672 loss_rnnt 18.513546 lr 0.00051599 rank 6
2022-12-04 07:41:09,404 DEBUG TRAIN Batch 11/2200 loss 9.799037 loss_att 12.239988 loss_ctc 20.043036 loss_rnnt 7.944980 lr 0.00051603 rank 5
2022-12-04 07:41:09,405 DEBUG TRAIN Batch 11/2200 loss 23.744896 loss_att 31.193504 loss_ctc 39.033836 loss_rnnt 20.216648 lr 0.00051590 rank 0
2022-12-04 07:41:09,406 DEBUG TRAIN Batch 11/2200 loss 11.795622 loss_att 13.754189 loss_ctc 13.312084 loss_rnnt 11.201714 lr 0.00051591 rank 7
2022-12-04 07:41:09,410 DEBUG TRAIN Batch 11/2200 loss 17.206980 loss_att 21.766186 loss_ctc 24.760229 loss_rnnt 15.288038 lr 0.00051587 rank 1
2022-12-04 07:41:09,411 DEBUG TRAIN Batch 11/2200 loss 13.797789 loss_att 20.762863 loss_ctc 23.420048 loss_rnnt 11.121805 lr 0.00051584 rank 3
2022-12-04 07:41:09,414 DEBUG TRAIN Batch 11/2200 loss 12.304364 loss_att 17.257282 loss_ctc 19.961433 loss_rnnt 10.292838 lr 0.00051573 rank 2
2022-12-04 07:41:09,419 DEBUG TRAIN Batch 11/2200 loss 28.862846 loss_att 29.963905 loss_ctc 54.405361 loss_rnnt 25.236963 lr 0.00051602 rank 4
2022-12-04 07:42:20,475 DEBUG TRAIN Batch 11/2300 loss 18.556589 loss_att 21.210629 loss_ctc 32.030609 loss_rnnt 16.229244 lr 0.00051575 rank 5
2022-12-04 07:42:20,479 DEBUG TRAIN Batch 11/2300 loss 7.226464 loss_att 10.568727 loss_ctc 11.635900 loss_rnnt 5.970086 lr 0.00051556 rank 3
2022-12-04 07:42:20,481 DEBUG TRAIN Batch 11/2300 loss 21.279552 loss_att 25.009861 loss_ctc 33.319962 loss_rnnt 18.928101 lr 0.00051563 rank 0
2022-12-04 07:42:20,482 DEBUG TRAIN Batch 11/2300 loss 13.740914 loss_att 15.480919 loss_ctc 20.526840 loss_rnnt 12.488123 lr 0.00051572 rank 6
2022-12-04 07:42:20,486 DEBUG TRAIN Batch 11/2300 loss 10.900270 loss_att 12.025196 loss_ctc 17.428728 loss_rnnt 9.804822 lr 0.00051545 rank 2
2022-12-04 07:42:20,518 DEBUG TRAIN Batch 11/2300 loss 16.318413 loss_att 18.317120 loss_ctc 23.961254 loss_rnnt 14.899624 lr 0.00051564 rank 7
2022-12-04 07:42:20,518 DEBUG TRAIN Batch 11/2300 loss 15.398928 loss_att 18.462896 loss_ctc 23.347111 loss_rnnt 13.726376 lr 0.00051575 rank 4
2022-12-04 07:42:20,527 DEBUG TRAIN Batch 11/2300 loss 12.708543 loss_att 17.167614 loss_ctc 18.538120 loss_rnnt 11.039452 lr 0.00051559 rank 1
2022-12-04 07:43:32,601 DEBUG TRAIN Batch 11/2400 loss 18.881706 loss_att 20.144855 loss_ctc 28.237209 loss_rnnt 17.381676 lr 0.00051548 rank 5
2022-12-04 07:43:32,605 DEBUG TRAIN Batch 11/2400 loss 10.240437 loss_att 14.435501 loss_ctc 18.640354 loss_rnnt 8.281435 lr 0.00051544 rank 6
2022-12-04 07:43:32,605 DEBUG TRAIN Batch 11/2400 loss 19.704596 loss_att 24.797153 loss_ctc 40.596775 loss_rnnt 15.900459 lr 0.00051532 rank 1
2022-12-04 07:43:32,606 DEBUG TRAIN Batch 11/2400 loss 17.019609 loss_att 18.979319 loss_ctc 24.378525 loss_rnnt 15.646479 lr 0.00051529 rank 3
2022-12-04 07:43:32,613 DEBUG TRAIN Batch 11/2400 loss 13.305342 loss_att 12.031336 loss_ctc 17.717113 loss_rnnt 12.971907 lr 0.00051518 rank 2
2022-12-04 07:43:32,616 DEBUG TRAIN Batch 11/2400 loss 13.331963 loss_att 19.024376 loss_ctc 23.566971 loss_rnnt 10.828812 lr 0.00051535 rank 0
2022-12-04 07:43:32,636 DEBUG TRAIN Batch 11/2400 loss 7.282291 loss_att 9.698904 loss_ctc 12.022842 loss_rnnt 6.166895 lr 0.00051537 rank 7
2022-12-04 07:43:32,650 DEBUG TRAIN Batch 11/2400 loss 15.353222 loss_att 18.441441 loss_ctc 27.487450 loss_rnnt 13.117682 lr 0.00051547 rank 4
2022-12-04 07:44:49,669 DEBUG TRAIN Batch 11/2500 loss 14.336139 loss_att 14.389351 loss_ctc 17.428137 loss_rnnt 13.913230 lr 0.00051508 rank 0
2022-12-04 07:44:49,669 DEBUG TRAIN Batch 11/2500 loss 22.079920 loss_att 21.878002 loss_ctc 30.252356 loss_rnnt 21.030645 lr 0.00051521 rank 5
2022-12-04 07:44:49,670 DEBUG TRAIN Batch 11/2500 loss 11.953030 loss_att 14.009391 loss_ctc 16.919525 loss_rnnt 10.879558 lr 0.00051517 rank 6
2022-12-04 07:44:49,676 DEBUG TRAIN Batch 11/2500 loss 10.066068 loss_att 10.246454 loss_ctc 13.258316 loss_rnnt 9.604357 lr 0.00051491 rank 2
2022-12-04 07:44:49,676 DEBUG TRAIN Batch 11/2500 loss 10.478017 loss_att 12.178983 loss_ctc 16.623260 loss_rnnt 9.318459 lr 0.00051505 rank 1
2022-12-04 07:44:49,678 DEBUG TRAIN Batch 11/2500 loss 8.996334 loss_att 9.610205 loss_ctc 14.487989 loss_rnnt 8.141339 lr 0.00051502 rank 3
2022-12-04 07:44:49,694 DEBUG TRAIN Batch 11/2500 loss 7.872146 loss_att 8.636750 loss_ctc 11.125966 loss_rnnt 7.285382 lr 0.00051509 rank 7
2022-12-04 07:44:49,728 DEBUG TRAIN Batch 11/2500 loss 10.912142 loss_att 16.646561 loss_ctc 23.965761 loss_rnnt 8.024775 lr 0.00051520 rank 4
2022-12-04 07:46:00,924 DEBUG TRAIN Batch 11/2600 loss 13.007781 loss_att 19.572720 loss_ctc 17.124573 loss_rnnt 11.145887 lr 0.00051481 rank 0
2022-12-04 07:46:00,924 DEBUG TRAIN Batch 11/2600 loss 12.581054 loss_att 18.281092 loss_ctc 26.010015 loss_rnnt 9.650518 lr 0.00051474 rank 3
2022-12-04 07:46:00,930 DEBUG TRAIN Batch 11/2600 loss 21.241673 loss_att 22.143230 loss_ctc 33.318733 loss_rnnt 19.451084 lr 0.00051490 rank 6
2022-12-04 07:46:00,932 DEBUG TRAIN Batch 11/2600 loss 10.645361 loss_att 14.973606 loss_ctc 23.100021 loss_rnnt 8.119090 lr 0.00051482 rank 7
2022-12-04 07:46:00,934 DEBUG TRAIN Batch 11/2600 loss 10.497722 loss_att 14.808455 loss_ctc 21.109600 loss_rnnt 8.220657 lr 0.00051463 rank 2
2022-12-04 07:46:00,935 DEBUG TRAIN Batch 11/2600 loss 16.549913 loss_att 21.085184 loss_ctc 27.875565 loss_rnnt 14.132772 lr 0.00051493 rank 5
2022-12-04 07:46:00,959 DEBUG TRAIN Batch 11/2600 loss 11.548407 loss_att 13.467882 loss_ctc 17.936644 loss_rnnt 10.312747 lr 0.00051477 rank 1
2022-12-04 07:46:00,966 DEBUG TRAIN Batch 11/2600 loss 12.731606 loss_att 16.063709 loss_ctc 20.825022 loss_rnnt 10.986064 lr 0.00051493 rank 4
2022-12-04 07:47:12,730 DEBUG TRAIN Batch 11/2700 loss 17.621552 loss_att 19.654621 loss_ctc 27.906813 loss_rnnt 15.843569 lr 0.00051436 rank 2
2022-12-04 07:47:12,747 DEBUG TRAIN Batch 11/2700 loss 8.779541 loss_att 14.474294 loss_ctc 17.136166 loss_rnnt 6.526374 lr 0.00051454 rank 0
2022-12-04 07:47:12,748 DEBUG TRAIN Batch 11/2700 loss 12.793064 loss_att 16.037268 loss_ctc 20.958553 loss_rnnt 11.055491 lr 0.00051455 rank 7
2022-12-04 07:47:12,749 DEBUG TRAIN Batch 11/2700 loss 8.263097 loss_att 11.630032 loss_ctc 14.369377 loss_rnnt 6.775539 lr 0.00051463 rank 6
2022-12-04 07:47:12,750 DEBUG TRAIN Batch 11/2700 loss 19.970867 loss_att 23.036037 loss_ctc 38.637798 loss_rnnt 16.868910 lr 0.00051447 rank 3
2022-12-04 07:47:12,752 DEBUG TRAIN Batch 11/2700 loss 9.741846 loss_att 14.933805 loss_ctc 13.573124 loss_rnnt 8.192617 lr 0.00051465 rank 4
2022-12-04 07:47:12,755 DEBUG TRAIN Batch 11/2700 loss 9.803093 loss_att 13.861839 loss_ctc 14.486194 loss_rnnt 8.366931 lr 0.00051450 rank 1
2022-12-04 07:47:12,796 DEBUG TRAIN Batch 11/2700 loss 16.136499 loss_att 18.964401 loss_ctc 24.479080 loss_rnnt 14.458575 lr 0.00051466 rank 5
2022-12-04 07:48:25,429 DEBUG TRAIN Batch 11/2800 loss 8.773772 loss_att 12.981204 loss_ctc 15.006596 loss_rnnt 7.101243 lr 0.00051423 rank 1
2022-12-04 07:48:25,432 DEBUG TRAIN Batch 11/2800 loss 7.843029 loss_att 12.163464 loss_ctc 12.851097 loss_rnnt 6.311201 lr 0.00051435 rank 6
2022-12-04 07:48:25,435 DEBUG TRAIN Batch 11/2800 loss 13.188425 loss_att 16.158318 loss_ctc 20.140701 loss_rnnt 11.667475 lr 0.00051409 rank 2
2022-12-04 07:48:25,435 DEBUG TRAIN Batch 11/2800 loss 5.555443 loss_att 8.541317 loss_ctc 10.287341 loss_rnnt 4.327348 lr 0.00051426 rank 0
2022-12-04 07:48:25,435 DEBUG TRAIN Batch 11/2800 loss 7.232487 loss_att 10.335734 loss_ctc 10.014854 loss_rnnt 6.240856 lr 0.00051427 rank 7
2022-12-04 07:48:25,437 DEBUG TRAIN Batch 11/2800 loss 14.896671 loss_att 18.522707 loss_ctc 25.697426 loss_rnnt 12.731363 lr 0.00051438 rank 4
2022-12-04 07:48:25,438 DEBUG TRAIN Batch 11/2800 loss 7.813245 loss_att 10.923981 loss_ctc 12.293830 loss_rnnt 6.593687 lr 0.00051420 rank 3
2022-12-04 07:48:25,442 DEBUG TRAIN Batch 11/2800 loss 7.382059 loss_att 10.344327 loss_ctc 14.327824 loss_rnnt 5.863503 lr 0.00051439 rank 5
2022-12-04 07:49:38,826 DEBUG TRAIN Batch 11/2900 loss 13.828439 loss_att 16.383316 loss_ctc 18.883362 loss_rnnt 12.643473 lr 0.00051408 rank 6
2022-12-04 07:49:38,828 DEBUG TRAIN Batch 11/2900 loss 18.822042 loss_att 21.406738 loss_ctc 27.403103 loss_rnnt 17.160961 lr 0.00051393 rank 3
2022-12-04 07:49:38,831 DEBUG TRAIN Batch 11/2900 loss 12.353285 loss_att 18.768473 loss_ctc 21.911274 loss_rnnt 9.795848 lr 0.00051399 rank 0
2022-12-04 07:49:38,832 DEBUG TRAIN Batch 11/2900 loss 14.881664 loss_att 18.473270 loss_ctc 25.453646 loss_rnnt 12.753746 lr 0.00051412 rank 5
2022-12-04 07:49:38,834 DEBUG TRAIN Batch 11/2900 loss 9.516075 loss_att 14.814569 loss_ctc 18.793507 loss_rnnt 7.219385 lr 0.00051411 rank 4
2022-12-04 07:49:38,834 DEBUG TRAIN Batch 11/2900 loss 13.493778 loss_att 19.409256 loss_ctc 23.040691 loss_rnnt 11.037760 lr 0.00051382 rank 2
2022-12-04 07:49:38,837 DEBUG TRAIN Batch 11/2900 loss 18.417086 loss_att 23.909008 loss_ctc 34.923714 loss_rnnt 15.117817 lr 0.00051400 rank 7
2022-12-04 07:49:38,884 DEBUG TRAIN Batch 11/2900 loss 13.095839 loss_att 17.600925 loss_ctc 27.229731 loss_rnnt 10.310303 lr 0.00051396 rank 1
2022-12-04 07:50:50,605 DEBUG TRAIN Batch 11/3000 loss 7.955706 loss_att 11.550043 loss_ctc 14.868746 loss_rnnt 6.315099 lr 0.00051381 rank 6
2022-12-04 07:50:50,613 DEBUG TRAIN Batch 11/3000 loss 5.574115 loss_att 9.345888 loss_ctc 10.750340 loss_rnnt 4.129597 lr 0.00051372 rank 0
2022-12-04 07:50:50,615 DEBUG TRAIN Batch 11/3000 loss 11.595346 loss_att 14.181782 loss_ctc 16.985525 loss_rnnt 10.359370 lr 0.00051373 rank 7
2022-12-04 07:50:50,617 DEBUG TRAIN Batch 11/3000 loss 20.368494 loss_att 21.573738 loss_ctc 34.068253 loss_rnnt 18.300810 lr 0.00051368 rank 1
2022-12-04 07:50:50,617 DEBUG TRAIN Batch 11/3000 loss 15.631909 loss_att 19.689335 loss_ctc 24.862183 loss_rnnt 13.589721 lr 0.00051384 rank 4
2022-12-04 07:50:50,618 DEBUG TRAIN Batch 11/3000 loss 12.039327 loss_att 14.472698 loss_ctc 18.415428 loss_rnnt 10.702504 lr 0.00051365 rank 3
2022-12-04 07:50:50,621 DEBUG TRAIN Batch 11/3000 loss 13.254921 loss_att 17.014280 loss_ctc 24.160791 loss_rnnt 11.048933 lr 0.00051355 rank 2
2022-12-04 07:50:50,659 DEBUG TRAIN Batch 11/3000 loss 6.126806 loss_att 8.997897 loss_ctc 10.703169 loss_rnnt 4.942406 lr 0.00051384 rank 5
2022-12-04 07:52:02,825 DEBUG TRAIN Batch 11/3100 loss 12.864204 loss_att 13.172184 loss_ctc 17.534954 loss_rnnt 12.179842 lr 0.00051346 rank 7
2022-12-04 07:52:02,825 DEBUG TRAIN Batch 11/3100 loss 13.474247 loss_att 16.624052 loss_ctc 21.157633 loss_rnnt 11.819835 lr 0.00051341 rank 1
2022-12-04 07:52:02,828 DEBUG TRAIN Batch 11/3100 loss 7.992223 loss_att 11.830005 loss_ctc 11.775513 loss_rnnt 6.720227 lr 0.00051345 rank 0
2022-12-04 07:52:02,829 DEBUG TRAIN Batch 11/3100 loss 9.715202 loss_att 14.308098 loss_ctc 20.588552 loss_rnnt 7.346844 lr 0.00051328 rank 2
2022-12-04 07:52:02,833 DEBUG TRAIN Batch 11/3100 loss 8.957217 loss_att 10.501504 loss_ctc 16.366207 loss_rnnt 7.660494 lr 0.00051354 rank 6
2022-12-04 07:52:02,833 DEBUG TRAIN Batch 11/3100 loss 14.513328 loss_att 16.654671 loss_ctc 24.114189 loss_rnnt 12.804945 lr 0.00051357 rank 5
2022-12-04 07:52:02,835 DEBUG TRAIN Batch 11/3100 loss 12.171228 loss_att 14.227610 loss_ctc 20.055910 loss_rnnt 10.708661 lr 0.00051338 rank 3
2022-12-04 07:52:02,889 DEBUG TRAIN Batch 11/3100 loss 15.586342 loss_att 19.448187 loss_ctc 21.191786 loss_rnnt 14.066581 lr 0.00051357 rank 4
2022-12-04 07:53:18,027 DEBUG TRAIN Batch 11/3200 loss 11.057096 loss_att 11.844057 loss_ctc 14.978428 loss_rnnt 10.376859 lr 0.00051318 rank 0
2022-12-04 07:53:18,030 DEBUG TRAIN Batch 11/3200 loss 8.253216 loss_att 12.657849 loss_ctc 13.899780 loss_rnnt 6.619414 lr 0.00051314 rank 1
2022-12-04 07:53:18,031 DEBUG TRAIN Batch 11/3200 loss 11.079017 loss_att 16.759605 loss_ctc 22.650810 loss_rnnt 8.399993 lr 0.00051330 rank 5
2022-12-04 07:53:18,032 DEBUG TRAIN Batch 11/3200 loss 15.299314 loss_att 21.219711 loss_ctc 23.340399 loss_rnnt 13.043091 lr 0.00051311 rank 3
2022-12-04 07:53:18,039 DEBUG TRAIN Batch 11/3200 loss 8.100724 loss_att 11.425393 loss_ctc 21.069271 loss_rnnt 5.706651 lr 0.00051301 rank 2
2022-12-04 07:53:18,040 DEBUG TRAIN Batch 11/3200 loss 14.091902 loss_att 17.010078 loss_ctc 22.574362 loss_rnnt 12.377272 lr 0.00051319 rank 7
2022-12-04 07:53:18,044 DEBUG TRAIN Batch 11/3200 loss 18.912745 loss_att 19.211302 loss_ctc 26.086668 loss_rnnt 17.896509 lr 0.00051327 rank 6
2022-12-04 07:53:18,059 DEBUG TRAIN Batch 11/3200 loss 30.997612 loss_att 34.901314 loss_ctc 48.454033 loss_rnnt 27.889349 lr 0.00051329 rank 4
2022-12-04 07:54:31,424 DEBUG TRAIN Batch 11/3300 loss 22.944061 loss_att 31.781216 loss_ctc 44.280575 loss_rnnt 18.331764 lr 0.00051291 rank 0
2022-12-04 07:54:31,425 DEBUG TRAIN Batch 11/3300 loss 5.714974 loss_att 8.786107 loss_ctc 10.756697 loss_rnnt 4.428518 lr 0.00051292 rank 7
2022-12-04 07:54:31,425 DEBUG TRAIN Batch 11/3300 loss 11.397235 loss_att 10.737848 loss_ctc 12.666046 loss_rnnt 11.359938 lr 0.00051303 rank 5
2022-12-04 07:54:31,426 DEBUG TRAIN Batch 11/3300 loss 8.527735 loss_att 13.014963 loss_ctc 16.039347 loss_rnnt 6.628741 lr 0.00051284 rank 3
2022-12-04 07:54:31,426 DEBUG TRAIN Batch 11/3300 loss 16.954960 loss_att 20.547821 loss_ctc 23.103527 loss_rnnt 15.416578 lr 0.00051300 rank 6
2022-12-04 07:54:31,429 DEBUG TRAIN Batch 11/3300 loss 16.134220 loss_att 21.049601 loss_ctc 25.141266 loss_rnnt 13.950205 lr 0.00051274 rank 2
2022-12-04 07:54:31,429 DEBUG TRAIN Batch 11/3300 loss 10.009841 loss_att 15.286739 loss_ctc 16.748707 loss_rnnt 8.055946 lr 0.00051287 rank 1
2022-12-04 07:54:31,478 DEBUG TRAIN Batch 11/3300 loss 5.917536 loss_att 9.691277 loss_ctc 11.934116 loss_rnnt 4.360578 lr 0.00051302 rank 4
2022-12-04 07:55:43,134 DEBUG TRAIN Batch 11/3400 loss 14.388725 loss_att 17.887909 loss_ctc 28.301428 loss_rnnt 11.833861 lr 0.00051257 rank 3
2022-12-04 07:55:43,140 DEBUG TRAIN Batch 11/3400 loss 7.687338 loss_att 10.823807 loss_ctc 15.585218 loss_rnnt 6.006994 lr 0.00051276 rank 5
2022-12-04 07:55:43,149 DEBUG TRAIN Batch 11/3400 loss 13.358547 loss_att 16.055075 loss_ctc 21.065323 loss_rnnt 11.791672 lr 0.00051273 rank 6
2022-12-04 07:55:43,150 DEBUG TRAIN Batch 11/3400 loss 9.897792 loss_att 16.087822 loss_ctc 20.712269 loss_rnnt 7.217855 lr 0.00051264 rank 0
2022-12-04 07:55:43,152 DEBUG TRAIN Batch 11/3400 loss 7.029399 loss_att 8.628489 loss_ctc 7.772896 loss_rnnt 6.610449 lr 0.00051247 rank 2
2022-12-04 07:55:43,156 DEBUG TRAIN Batch 11/3400 loss 13.271595 loss_att 18.531504 loss_ctc 23.860554 loss_rnnt 10.807752 lr 0.00051265 rank 7
2022-12-04 07:55:43,156 DEBUG TRAIN Batch 11/3400 loss 10.544981 loss_att 16.814995 loss_ctc 20.484978 loss_rnnt 7.965645 lr 0.00051275 rank 4
2022-12-04 07:55:43,202 DEBUG TRAIN Batch 11/3400 loss 12.986864 loss_att 21.933115 loss_ctc 26.082808 loss_rnnt 9.451488 lr 0.00051260 rank 1
2022-12-04 07:56:55,434 DEBUG TRAIN Batch 11/3500 loss 5.804376 loss_att 9.640932 loss_ctc 11.161140 loss_rnnt 4.322829 lr 0.00051233 rank 1
2022-12-04 07:56:55,436 DEBUG TRAIN Batch 11/3500 loss 15.390845 loss_att 17.983145 loss_ctc 23.086899 loss_rnnt 13.846245 lr 0.00051249 rank 5
2022-12-04 07:56:55,437 DEBUG TRAIN Batch 11/3500 loss 13.351267 loss_att 17.860973 loss_ctc 18.406956 loss_rnnt 11.775234 lr 0.00051246 rank 6
2022-12-04 07:56:55,439 DEBUG TRAIN Batch 11/3500 loss 9.096911 loss_att 13.782328 loss_ctc 18.143269 loss_rnnt 6.953648 lr 0.00051237 rank 0
2022-12-04 07:56:55,440 DEBUG TRAIN Batch 11/3500 loss 10.794859 loss_att 13.950736 loss_ctc 23.696857 loss_rnnt 8.443417 lr 0.00051238 rank 7
2022-12-04 07:56:55,441 DEBUG TRAIN Batch 11/3500 loss 17.091812 loss_att 19.678820 loss_ctc 24.663162 loss_rnnt 15.564897 lr 0.00051230 rank 3
2022-12-04 07:56:55,485 DEBUG TRAIN Batch 11/3500 loss 22.277737 loss_att 24.712736 loss_ctc 31.400829 loss_rnnt 20.574324 lr 0.00051249 rank 4
2022-12-04 07:56:55,490 DEBUG TRAIN Batch 11/3500 loss 12.600083 loss_att 15.654921 loss_ctc 19.308786 loss_rnnt 11.094622 lr 0.00051220 rank 2
2022-12-04 07:58:11,851 DEBUG TRAIN Batch 11/3600 loss 9.708402 loss_att 11.458855 loss_ctc 12.887892 loss_rnnt 8.934379 lr 0.00051222 rank 5
2022-12-04 07:58:11,852 DEBUG TRAIN Batch 11/3600 loss 11.177873 loss_att 14.394459 loss_ctc 16.003981 loss_rnnt 9.891074 lr 0.00051204 rank 3
2022-12-04 07:58:11,854 DEBUG TRAIN Batch 11/3600 loss 18.585749 loss_att 22.566536 loss_ctc 28.891930 loss_rnnt 16.415432 lr 0.00051207 rank 1
2022-12-04 07:58:11,855 DEBUG TRAIN Batch 11/3600 loss 20.358992 loss_att 23.022198 loss_ctc 34.336781 loss_rnnt 17.962646 lr 0.00051210 rank 0
2022-12-04 07:58:11,859 DEBUG TRAIN Batch 11/3600 loss 17.279633 loss_att 24.286383 loss_ctc 27.795338 loss_rnnt 14.476189 lr 0.00051219 rank 6
2022-12-04 07:58:11,859 DEBUG TRAIN Batch 11/3600 loss 6.936604 loss_att 9.915136 loss_ctc 13.594383 loss_rnnt 5.453194 lr 0.00051211 rank 7
2022-12-04 07:58:11,859 DEBUG TRAIN Batch 11/3600 loss 10.364081 loss_att 11.817996 loss_ctc 15.800480 loss_rnnt 9.348446 lr 0.00051193 rank 2
2022-12-04 07:58:11,867 DEBUG TRAIN Batch 11/3600 loss 14.938341 loss_att 18.892057 loss_ctc 32.491947 loss_rnnt 11.807116 lr 0.00051222 rank 4
2022-12-04 07:59:24,015 DEBUG TRAIN Batch 11/3700 loss 11.719260 loss_att 14.771492 loss_ctc 20.151907 loss_rnnt 9.984461 lr 0.00051177 rank 3
2022-12-04 07:59:24,020 DEBUG TRAIN Batch 11/3700 loss 15.934219 loss_att 21.307854 loss_ctc 30.928064 loss_rnnt 12.860312 lr 0.00051192 rank 6
2022-12-04 07:59:24,021 DEBUG TRAIN Batch 11/3700 loss 16.202003 loss_att 19.357224 loss_ctc 25.139803 loss_rnnt 14.379251 lr 0.00051183 rank 0
2022-12-04 07:59:24,023 DEBUG TRAIN Batch 11/3700 loss 14.829818 loss_att 17.264374 loss_ctc 27.388617 loss_rnnt 12.668400 lr 0.00051180 rank 1
2022-12-04 07:59:24,024 DEBUG TRAIN Batch 11/3700 loss 12.402332 loss_att 16.407013 loss_ctc 21.030804 loss_rnnt 10.450933 lr 0.00051196 rank 5
2022-12-04 07:59:24,026 DEBUG TRAIN Batch 11/3700 loss 13.798349 loss_att 12.252790 loss_ctc 20.482540 loss_rnnt 13.216236 lr 0.00051184 rank 7
2022-12-04 07:59:24,033 DEBUG TRAIN Batch 11/3700 loss 7.893103 loss_att 11.611188 loss_ctc 16.469738 loss_rnnt 6.005935 lr 0.00051195 rank 4
2022-12-04 07:59:24,077 DEBUG TRAIN Batch 11/3700 loss 10.204403 loss_att 13.780652 loss_ctc 18.687998 loss_rnnt 8.358006 lr 0.00051166 rank 2
2022-12-04 08:00:36,340 DEBUG TRAIN Batch 11/3800 loss 18.111126 loss_att 24.389620 loss_ctc 31.278187 loss_rnnt 15.099818 lr 0.00051169 rank 5
2022-12-04 08:00:36,342 DEBUG TRAIN Batch 11/3800 loss 8.758985 loss_att 9.514781 loss_ctc 11.231513 loss_rnnt 8.278155 lr 0.00051139 rank 2
2022-12-04 08:00:36,346 DEBUG TRAIN Batch 11/3800 loss 12.418604 loss_att 13.766825 loss_ctc 18.991249 loss_rnnt 11.272606 lr 0.00051165 rank 6
2022-12-04 08:00:36,346 DEBUG TRAIN Batch 11/3800 loss 5.245257 loss_att 8.235448 loss_ctc 10.383108 loss_rnnt 3.962173 lr 0.00051156 rank 0
2022-12-04 08:00:36,346 DEBUG TRAIN Batch 11/3800 loss 7.437092 loss_att 10.443553 loss_ctc 13.273681 loss_rnnt 6.057588 lr 0.00051150 rank 3
2022-12-04 08:00:36,348 DEBUG TRAIN Batch 11/3800 loss 10.837906 loss_att 12.024359 loss_ctc 16.938074 loss_rnnt 9.787260 lr 0.00051153 rank 1
2022-12-04 08:00:36,349 DEBUG TRAIN Batch 11/3800 loss 10.718630 loss_att 15.041029 loss_ctc 19.662216 loss_rnnt 8.661671 lr 0.00051157 rank 7
2022-12-04 08:00:36,354 DEBUG TRAIN Batch 11/3800 loss 10.100363 loss_att 11.474834 loss_ctc 14.839137 loss_rnnt 9.193633 lr 0.00051168 rank 4
2022-12-04 08:01:50,420 DEBUG TRAIN Batch 11/3900 loss 12.734255 loss_att 17.519718 loss_ctc 21.392841 loss_rnnt 10.622683 lr 0.00051130 rank 0
2022-12-04 08:01:50,425 DEBUG TRAIN Batch 11/3900 loss 16.355574 loss_att 20.081511 loss_ctc 24.335979 loss_rnnt 14.546333 lr 0.00051142 rank 5
2022-12-04 08:01:50,437 DEBUG TRAIN Batch 11/3900 loss 21.240850 loss_att 22.860754 loss_ctc 31.655722 loss_rnnt 19.528221 lr 0.00051138 rank 6
2022-12-04 08:01:50,437 DEBUG TRAIN Batch 11/3900 loss 19.989809 loss_att 23.357025 loss_ctc 32.673546 loss_rnnt 17.625202 lr 0.00051126 rank 1
2022-12-04 08:01:50,464 DEBUG TRAIN Batch 11/3900 loss 18.542459 loss_att 22.933823 loss_ctc 26.229040 loss_rnnt 16.639309 lr 0.00051131 rank 7
2022-12-04 08:01:50,466 DEBUG TRAIN Batch 11/3900 loss 3.950109 loss_att 8.437922 loss_ctc 6.505959 loss_rnnt 2.711766 lr 0.00051123 rank 3
2022-12-04 08:01:50,475 DEBUG TRAIN Batch 11/3900 loss 9.886445 loss_att 11.667841 loss_ctc 19.913158 loss_rnnt 8.193270 lr 0.00051113 rank 2
2022-12-04 08:01:50,481 DEBUG TRAIN Batch 11/3900 loss 5.933095 loss_att 8.224194 loss_ctc 10.967929 loss_rnnt 4.803564 lr 0.00051141 rank 4
2022-12-04 08:03:03,828 DEBUG TRAIN Batch 11/4000 loss 11.306009 loss_att 19.215515 loss_ctc 15.804316 loss_rnnt 9.124334 lr 0.00051112 rank 6
2022-12-04 08:03:03,830 DEBUG TRAIN Batch 11/4000 loss 15.925338 loss_att 18.031652 loss_ctc 22.791626 loss_rnnt 14.588570 lr 0.00051103 rank 0
2022-12-04 08:03:03,833 DEBUG TRAIN Batch 11/4000 loss 4.908533 loss_att 8.452063 loss_ctc 11.222113 loss_rnnt 3.358016 lr 0.00051115 rank 5
2022-12-04 08:03:03,834 DEBUG TRAIN Batch 11/4000 loss 12.082741 loss_att 15.318102 loss_ctc 20.093904 loss_rnnt 10.367514 lr 0.00051086 rank 2
2022-12-04 08:03:03,835 DEBUG TRAIN Batch 11/4000 loss 14.756207 loss_att 15.134699 loss_ctc 19.135187 loss_rnnt 14.096644 lr 0.00051104 rank 7
2022-12-04 08:03:03,836 DEBUG TRAIN Batch 11/4000 loss 14.507423 loss_att 22.738583 loss_ctc 31.174162 loss_rnnt 10.638960 lr 0.00051097 rank 3
2022-12-04 08:03:03,837 DEBUG TRAIN Batch 11/4000 loss 12.909925 loss_att 15.457977 loss_ctc 24.004286 loss_rnnt 10.921066 lr 0.00051099 rank 1
2022-12-04 08:03:03,842 DEBUG TRAIN Batch 11/4000 loss 6.975966 loss_att 10.052550 loss_ctc 11.644363 loss_rnnt 5.738196 lr 0.00051114 rank 4
2022-12-04 08:04:14,519 DEBUG TRAIN Batch 11/4100 loss 14.692639 loss_att 18.640739 loss_ctc 20.638939 loss_rnnt 13.110178 lr 0.00051085 rank 6
2022-12-04 08:04:14,520 DEBUG TRAIN Batch 11/4100 loss 8.686316 loss_att 12.557652 loss_ctc 14.287438 loss_rnnt 7.165232 lr 0.00051076 rank 0
2022-12-04 08:04:14,523 DEBUG TRAIN Batch 11/4100 loss 19.883133 loss_att 27.145939 loss_ctc 33.789352 loss_rnnt 16.576410 lr 0.00051089 rank 5
2022-12-04 08:04:14,525 DEBUG TRAIN Batch 11/4100 loss 20.409824 loss_att 23.973816 loss_ctc 35.314674 loss_rnnt 17.709713 lr 0.00051059 rank 2
2022-12-04 08:04:14,525 DEBUG TRAIN Batch 11/4100 loss 11.866404 loss_att 17.067648 loss_ctc 18.833076 loss_rnnt 9.897264 lr 0.00051073 rank 1
2022-12-04 08:04:14,527 DEBUG TRAIN Batch 11/4100 loss 6.794115 loss_att 9.284479 loss_ctc 15.442955 loss_rnnt 5.142862 lr 0.00051070 rank 3
2022-12-04 08:04:14,532 DEBUG TRAIN Batch 11/4100 loss 14.490849 loss_att 21.407820 loss_ctc 26.583733 loss_rnnt 11.495071 lr 0.00051077 rank 7
2022-12-04 08:04:14,540 DEBUG TRAIN Batch 11/4100 loss 10.030080 loss_att 13.232385 loss_ctc 13.595062 loss_rnnt 8.914288 lr 0.00051088 rank 4
2022-12-04 08:05:26,555 DEBUG TRAIN Batch 11/4200 loss 15.211806 loss_att 19.151920 loss_ctc 28.874706 loss_rnnt 12.602064 lr 0.00051046 rank 1
2022-12-04 08:05:26,558 DEBUG TRAIN Batch 11/4200 loss 9.479408 loss_att 14.606093 loss_ctc 16.374058 loss_rnnt 7.534785 lr 0.00051043 rank 3
2022-12-04 08:05:26,558 DEBUG TRAIN Batch 11/4200 loss 11.355598 loss_att 17.288006 loss_ctc 22.762569 loss_rnnt 8.648189 lr 0.00051050 rank 0
2022-12-04 08:05:26,562 DEBUG TRAIN Batch 11/4200 loss 13.150980 loss_att 16.990494 loss_ctc 25.532459 loss_rnnt 10.732214 lr 0.00051033 rank 2
2022-12-04 08:05:26,566 DEBUG TRAIN Batch 11/4200 loss 16.440918 loss_att 19.166328 loss_ctc 27.606020 loss_rnnt 14.407156 lr 0.00051061 rank 4
2022-12-04 08:05:26,581 DEBUG TRAIN Batch 11/4200 loss 16.284046 loss_att 18.867369 loss_ctc 26.218895 loss_rnnt 14.442736 lr 0.00051058 rank 6
2022-12-04 08:05:26,583 DEBUG TRAIN Batch 11/4200 loss 7.914295 loss_att 10.665520 loss_ctc 10.063726 loss_rnnt 7.077460 lr 0.00051051 rank 7
2022-12-04 08:05:26,606 DEBUG TRAIN Batch 11/4200 loss 14.580484 loss_att 20.383116 loss_ctc 27.972557 loss_rnnt 11.634348 lr 0.00051062 rank 5
2022-12-04 08:06:43,614 DEBUG TRAIN Batch 11/4300 loss 9.321867 loss_att 14.619696 loss_ctc 20.025803 loss_rnnt 6.835109 lr 0.00051032 rank 6
2022-12-04 08:06:43,622 DEBUG TRAIN Batch 11/4300 loss 14.321661 loss_att 16.454613 loss_ctc 23.003914 loss_rnnt 12.737436 lr 0.00051017 rank 3
2022-12-04 08:06:43,622 DEBUG TRAIN Batch 11/4300 loss 6.707936 loss_att 11.700670 loss_ctc 12.840272 loss_rnnt 4.891745 lr 0.00051024 rank 7
2022-12-04 08:06:43,622 DEBUG TRAIN Batch 11/4300 loss 14.822435 loss_att 20.481525 loss_ctc 26.565277 loss_rnnt 12.124907 lr 0.00051035 rank 5
2022-12-04 08:06:43,623 DEBUG TRAIN Batch 11/4300 loss 21.454685 loss_att 23.394875 loss_ctc 30.242817 loss_rnnt 19.894896 lr 0.00051020 rank 1
2022-12-04 08:06:43,623 DEBUG TRAIN Batch 11/4300 loss 5.727016 loss_att 10.195208 loss_ctc 12.374959 loss_rnnt 3.946986 lr 0.00051006 rank 2
2022-12-04 08:06:43,623 DEBUG TRAIN Batch 11/4300 loss 26.060871 loss_att 29.379795 loss_ctc 41.552216 loss_rnnt 23.331573 lr 0.00051023 rank 0
2022-12-04 08:06:43,675 DEBUG TRAIN Batch 11/4300 loss 17.824272 loss_att 19.987192 loss_ctc 24.821743 loss_rnnt 16.458691 lr 0.00051034 rank 4
2022-12-04 08:07:55,082 DEBUG TRAIN Batch 11/4400 loss 13.814379 loss_att 15.647789 loss_ctc 25.066833 loss_rnnt 11.947371 lr 0.00050990 rank 3
2022-12-04 08:07:55,082 DEBUG TRAIN Batch 11/4400 loss 6.085095 loss_att 9.504961 loss_ctc 11.031107 loss_rnnt 4.741654 lr 0.00050997 rank 0
2022-12-04 08:07:55,084 DEBUG TRAIN Batch 11/4400 loss 24.957546 loss_att 26.161953 loss_ctc 33.641869 loss_rnnt 23.558754 lr 0.00051005 rank 6
2022-12-04 08:07:55,084 DEBUG TRAIN Batch 11/4400 loss 14.104313 loss_att 15.266684 loss_ctc 19.108057 loss_rnnt 13.204673 lr 0.00051009 rank 5
2022-12-04 08:07:55,086 DEBUG TRAIN Batch 11/4400 loss 8.968240 loss_att 10.874900 loss_ctc 15.286349 loss_rnnt 7.744493 lr 0.00050993 rank 1
2022-12-04 08:07:55,086 DEBUG TRAIN Batch 11/4400 loss 12.782538 loss_att 15.277227 loss_ctc 22.834360 loss_rnnt 10.943358 lr 0.00050998 rank 7
2022-12-04 08:07:55,089 DEBUG TRAIN Batch 11/4400 loss 10.497520 loss_att 13.629902 loss_ctc 19.313828 loss_rnnt 8.695537 lr 0.00051008 rank 4
2022-12-04 08:07:55,128 DEBUG TRAIN Batch 11/4400 loss 11.594927 loss_att 12.017365 loss_ctc 15.825267 loss_rnnt 10.946395 lr 0.00050980 rank 2
2022-12-04 08:09:07,506 DEBUG TRAIN Batch 11/4500 loss 11.105971 loss_att 16.425457 loss_ctc 29.615929 loss_rnnt 7.574080 lr 0.00050970 rank 0
2022-12-04 08:09:07,507 DEBUG TRAIN Batch 11/4500 loss 21.970810 loss_att 27.465996 loss_ctc 43.290001 loss_rnnt 18.029213 lr 0.00050967 rank 1
2022-12-04 08:09:07,507 DEBUG TRAIN Batch 11/4500 loss 7.367408 loss_att 12.980679 loss_ctc 12.102106 loss_rnnt 5.613461 lr 0.00050982 rank 5
2022-12-04 08:09:07,508 DEBUG TRAIN Batch 11/4500 loss 10.492701 loss_att 13.404398 loss_ctc 16.646616 loss_rnnt 9.089838 lr 0.00050964 rank 3
2022-12-04 08:09:07,512 DEBUG TRAIN Batch 11/4500 loss 12.340460 loss_att 16.116787 loss_ctc 24.572250 loss_rnnt 9.954288 lr 0.00050981 rank 4
2022-12-04 08:09:07,531 DEBUG TRAIN Batch 11/4500 loss 17.238848 loss_att 20.974590 loss_ctc 29.212784 loss_rnnt 14.895174 lr 0.00050979 rank 6
2022-12-04 08:09:07,536 DEBUG TRAIN Batch 11/4500 loss 19.449223 loss_att 21.245525 loss_ctc 27.229519 loss_rnnt 18.052589 lr 0.00050971 rank 7
2022-12-04 08:09:07,544 DEBUG TRAIN Batch 11/4500 loss 24.151958 loss_att 27.703899 loss_ctc 37.986523 loss_rnnt 21.596960 lr 0.00050953 rank 2
2022-12-04 08:10:21,468 DEBUG TRAIN Batch 11/4600 loss 20.025774 loss_att 22.852877 loss_ctc 31.127457 loss_rnnt 17.980129 lr 0.00050952 rank 6
2022-12-04 08:10:21,468 DEBUG TRAIN Batch 11/4600 loss 12.915042 loss_att 14.730641 loss_ctc 25.207870 loss_rnnt 10.912878 lr 0.00050927 rank 2
2022-12-04 08:10:21,472 DEBUG TRAIN Batch 11/4600 loss 12.772773 loss_att 21.382984 loss_ctc 28.849180 loss_rnnt 8.907208 lr 0.00050937 rank 3
2022-12-04 08:10:21,473 DEBUG TRAIN Batch 11/4600 loss 11.630787 loss_att 16.373871 loss_ctc 17.128891 loss_rnnt 9.949090 lr 0.00050955 rank 4
2022-12-04 08:10:21,474 DEBUG TRAIN Batch 11/4600 loss 13.733085 loss_att 18.426233 loss_ctc 23.470579 loss_rnnt 11.496122 lr 0.00050944 rank 0
2022-12-04 08:10:21,480 DEBUG TRAIN Batch 11/4600 loss 12.644403 loss_att 15.580400 loss_ctc 16.929930 loss_rnnt 11.485801 lr 0.00050945 rank 7
2022-12-04 08:10:21,499 DEBUG TRAIN Batch 11/4600 loss 9.584940 loss_att 14.830131 loss_ctc 19.379425 loss_rnnt 7.229970 lr 0.00050956 rank 5
2022-12-04 08:10:21,535 DEBUG TRAIN Batch 11/4600 loss 20.137011 loss_att 29.427288 loss_ctc 37.161530 loss_rnnt 16.009018 lr 0.00050940 rank 1
2022-12-04 08:11:35,986 DEBUG TRAIN Batch 11/4700 loss 7.063460 loss_att 10.219938 loss_ctc 13.569149 loss_rnnt 5.564739 lr 0.00050911 rank 3
2022-12-04 08:11:35,988 DEBUG TRAIN Batch 11/4700 loss 11.553776 loss_att 16.364647 loss_ctc 18.547249 loss_rnnt 9.659140 lr 0.00050900 rank 2
2022-12-04 08:11:35,990 DEBUG TRAIN Batch 11/4700 loss 11.067359 loss_att 17.359465 loss_ctc 19.670162 loss_rnnt 8.661897 lr 0.00050914 rank 1
2022-12-04 08:11:35,991 DEBUG TRAIN Batch 11/4700 loss 12.875162 loss_att 14.813234 loss_ctc 18.331137 loss_rnnt 11.760085 lr 0.00050918 rank 7
2022-12-04 08:11:35,998 DEBUG TRAIN Batch 11/4700 loss 17.737806 loss_att 19.179646 loss_ctc 23.819782 loss_rnnt 16.638508 lr 0.00050928 rank 4
2022-12-04 08:11:36,011 DEBUG TRAIN Batch 11/4700 loss 8.573777 loss_att 12.373554 loss_ctc 19.033436 loss_rnnt 6.419201 lr 0.00050926 rank 6
2022-12-04 08:11:36,018 DEBUG TRAIN Batch 11/4700 loss 12.910482 loss_att 16.768890 loss_ctc 20.567041 loss_rnnt 11.117927 lr 0.00050917 rank 0
2022-12-04 08:11:36,032 DEBUG TRAIN Batch 11/4700 loss 8.906262 loss_att 12.550276 loss_ctc 16.952286 loss_rnnt 7.104656 lr 0.00050929 rank 5
2022-12-04 08:12:47,591 DEBUG TRAIN Batch 11/4800 loss 13.038683 loss_att 16.475193 loss_ctc 21.725077 loss_rnnt 11.193195 lr 0.00050899 rank 6
2022-12-04 08:12:47,593 DEBUG TRAIN Batch 11/4800 loss 7.958894 loss_att 11.834695 loss_ctc 15.211152 loss_rnnt 6.216766 lr 0.00050884 rank 3
2022-12-04 08:12:47,594 DEBUG TRAIN Batch 11/4800 loss 7.276742 loss_att 11.738894 loss_ctc 15.482669 loss_rnnt 5.290188 lr 0.00050891 rank 0
2022-12-04 08:12:47,595 DEBUG TRAIN Batch 11/4800 loss 8.611681 loss_att 11.769489 loss_ctc 14.719957 loss_rnnt 7.165682 lr 0.00050874 rank 2
2022-12-04 08:12:47,595 DEBUG TRAIN Batch 11/4800 loss 17.315557 loss_att 22.258137 loss_ctc 27.997871 loss_rnnt 14.902733 lr 0.00050903 rank 5
2022-12-04 08:12:47,595 DEBUG TRAIN Batch 11/4800 loss 19.026588 loss_att 21.760906 loss_ctc 26.796045 loss_rnnt 17.443798 lr 0.00050887 rank 1
2022-12-04 08:12:47,595 DEBUG TRAIN Batch 11/4800 loss 8.091978 loss_att 12.877165 loss_ctc 16.261305 loss_rnnt 6.045696 lr 0.00050892 rank 7
2022-12-04 08:12:47,644 DEBUG TRAIN Batch 11/4800 loss 20.136921 loss_att 20.562149 loss_ctc 29.992256 loss_rnnt 18.737831 lr 0.00050902 rank 4
2022-12-04 08:13:59,706 DEBUG TRAIN Batch 11/4900 loss 18.932743 loss_att 22.064491 loss_ctc 27.862970 loss_rnnt 17.115696 lr 0.00050877 rank 5
2022-12-04 08:13:59,711 DEBUG TRAIN Batch 11/4900 loss 15.918341 loss_att 17.101002 loss_ctc 30.162086 loss_rnnt 13.782642 lr 0.00050873 rank 6
2022-12-04 08:13:59,712 DEBUG TRAIN Batch 11/4900 loss 12.435081 loss_att 15.632298 loss_ctc 25.038374 loss_rnnt 10.115197 lr 0.00050858 rank 3
2022-12-04 08:13:59,712 DEBUG TRAIN Batch 11/4900 loss 17.169027 loss_att 21.377098 loss_ctc 29.946606 loss_rnnt 14.623735 lr 0.00050864 rank 0
2022-12-04 08:13:59,715 DEBUG TRAIN Batch 11/4900 loss 11.717121 loss_att 16.476074 loss_ctc 24.631262 loss_rnnt 9.043445 lr 0.00050848 rank 2
2022-12-04 08:13:59,717 DEBUG TRAIN Batch 11/4900 loss 19.089994 loss_att 25.559824 loss_ctc 29.856632 loss_rnnt 16.360477 lr 0.00050876 rank 4
2022-12-04 08:13:59,738 DEBUG TRAIN Batch 11/4900 loss 7.646643 loss_att 10.878304 loss_ctc 14.902229 loss_rnnt 6.032899 lr 0.00050865 rank 7
2022-12-04 08:13:59,741 DEBUG TRAIN Batch 11/4900 loss 5.317168 loss_att 8.019192 loss_ctc 8.783195 loss_rnnt 4.314625 lr 0.00050861 rank 1
2022-12-04 08:15:15,417 DEBUG TRAIN Batch 11/5000 loss 19.068811 loss_att 21.710133 loss_ctc 27.180395 loss_rnnt 17.459003 lr 0.00050847 rank 6
2022-12-04 08:15:15,418 DEBUG TRAIN Batch 11/5000 loss 5.724034 loss_att 7.766382 loss_ctc 11.294803 loss_rnnt 4.572795 lr 0.00050835 rank 1
2022-12-04 08:15:15,418 DEBUG TRAIN Batch 11/5000 loss 19.753906 loss_att 21.253105 loss_ctc 23.543926 loss_rnnt 18.948730 lr 0.00050821 rank 2
2022-12-04 08:15:15,419 DEBUG TRAIN Batch 11/5000 loss 14.404104 loss_att 18.725658 loss_ctc 20.331696 loss_rnnt 12.749449 lr 0.00050832 rank 3
2022-12-04 08:15:15,419 DEBUG TRAIN Batch 11/5000 loss 9.156118 loss_att 12.207800 loss_ctc 15.165874 loss_rnnt 7.744482 lr 0.00050839 rank 7
2022-12-04 08:15:15,426 DEBUG TRAIN Batch 11/5000 loss 8.669741 loss_att 10.892278 loss_ctc 12.211215 loss_rnnt 7.753036 lr 0.00050850 rank 5
2022-12-04 08:15:15,430 DEBUG TRAIN Batch 11/5000 loss 14.638008 loss_att 18.716377 loss_ctc 23.114643 loss_rnnt 12.692116 lr 0.00050838 rank 0
2022-12-04 08:15:15,435 DEBUG TRAIN Batch 11/5000 loss 7.035655 loss_att 11.423845 loss_ctc 12.371051 loss_rnnt 5.446631 lr 0.00050849 rank 4
2022-12-04 08:16:28,104 DEBUG TRAIN Batch 11/5100 loss 10.348178 loss_att 13.912285 loss_ctc 18.125393 loss_rnnt 8.598394 lr 0.00050824 rank 5
2022-12-04 08:16:28,105 DEBUG TRAIN Batch 11/5100 loss 14.084396 loss_att 19.811970 loss_ctc 24.759285 loss_rnnt 11.515564 lr 0.00050821 rank 6
2022-12-04 08:16:28,106 DEBUG TRAIN Batch 11/5100 loss 10.851665 loss_att 11.634434 loss_ctc 16.339718 loss_rnnt 9.963371 lr 0.00050808 rank 1
2022-12-04 08:16:28,110 DEBUG TRAIN Batch 11/5100 loss 12.541771 loss_att 13.491238 loss_ctc 17.313719 loss_rnnt 11.715618 lr 0.00050812 rank 0
2022-12-04 08:16:28,113 DEBUG TRAIN Batch 11/5100 loss 18.587200 loss_att 27.935032 loss_ctc 41.554466 loss_rnnt 13.655334 lr 0.00050795 rank 2
2022-12-04 08:16:28,114 DEBUG TRAIN Batch 11/5100 loss 11.935493 loss_att 13.222525 loss_ctc 16.689302 loss_rnnt 11.044245 lr 0.00050806 rank 3
2022-12-04 08:16:28,118 DEBUG TRAIN Batch 11/5100 loss 8.473639 loss_att 7.959332 loss_ctc 10.963918 loss_rnnt 8.244464 lr 0.00050823 rank 4
2022-12-04 08:16:28,159 DEBUG TRAIN Batch 11/5100 loss 11.475850 loss_att 11.110147 loss_ctc 16.450594 loss_rnnt 10.885692 lr 0.00050813 rank 7
2022-12-04 08:17:39,498 DEBUG TRAIN Batch 11/5200 loss 6.746613 loss_att 11.439510 loss_ctc 14.984218 loss_rnnt 4.709685 lr 0.00050782 rank 1
2022-12-04 08:17:39,517 DEBUG TRAIN Batch 11/5200 loss 18.279312 loss_att 19.429981 loss_ctc 24.361403 loss_rnnt 17.238234 lr 0.00050786 rank 0
2022-12-04 08:17:39,519 DEBUG TRAIN Batch 11/5200 loss 19.604216 loss_att 26.329575 loss_ctc 29.559149 loss_rnnt 16.931820 lr 0.00050794 rank 6
2022-12-04 08:17:39,522 DEBUG TRAIN Batch 11/5200 loss 26.390079 loss_att 33.614037 loss_ctc 45.523510 loss_rnnt 22.394163 lr 0.00050798 rank 5
2022-12-04 08:17:39,523 DEBUG TRAIN Batch 11/5200 loss 12.808807 loss_att 16.061314 loss_ctc 25.413145 loss_rnnt 10.477727 lr 0.00050779 rank 3
2022-12-04 08:17:39,524 DEBUG TRAIN Batch 11/5200 loss 9.765546 loss_att 14.695080 loss_ctc 20.184629 loss_rnnt 7.390428 lr 0.00050787 rank 7
2022-12-04 08:17:39,525 DEBUG TRAIN Batch 11/5200 loss 7.595467 loss_att 10.646027 loss_ctc 11.121767 loss_rnnt 6.515181 lr 0.00050769 rank 2
2022-12-04 08:17:39,528 DEBUG TRAIN Batch 11/5200 loss 5.660875 loss_att 11.866791 loss_ctc 10.510469 loss_rnnt 3.773079 lr 0.00050797 rank 4
2022-12-04 08:18:53,590 DEBUG TRAIN Batch 11/5300 loss 10.435243 loss_att 13.661459 loss_ctc 13.716667 loss_rnnt 9.352476 lr 0.00050771 rank 4
2022-12-04 08:18:53,599 DEBUG TRAIN Batch 11/5300 loss 8.776866 loss_att 14.236215 loss_ctc 21.607586 loss_rnnt 5.974233 lr 0.00050759 rank 0
2022-12-04 08:18:53,600 DEBUG TRAIN Batch 11/5300 loss 16.851433 loss_att 22.099232 loss_ctc 31.689409 loss_rnnt 13.823476 lr 0.00050768 rank 6
2022-12-04 08:18:53,600 DEBUG TRAIN Batch 11/5300 loss 18.454182 loss_att 21.055012 loss_ctc 25.192060 loss_rnnt 17.035631 lr 0.00050756 rank 1
2022-12-04 08:18:53,601 DEBUG TRAIN Batch 11/5300 loss 9.956782 loss_att 12.513054 loss_ctc 16.119316 loss_rnnt 8.623857 lr 0.00050771 rank 5
2022-12-04 08:18:53,602 DEBUG TRAIN Batch 11/5300 loss 10.202518 loss_att 11.715641 loss_ctc 15.988444 loss_rnnt 9.128437 lr 0.00050753 rank 3
2022-12-04 08:18:53,602 DEBUG TRAIN Batch 11/5300 loss 27.226204 loss_att 29.342047 loss_ctc 44.267937 loss_rnnt 24.530802 lr 0.00050761 rank 7
2022-12-04 08:18:53,605 DEBUG TRAIN Batch 11/5300 loss 9.817792 loss_att 15.144032 loss_ctc 20.257740 loss_rnnt 7.360551 lr 0.00050743 rank 2
2022-12-04 08:20:09,191 DEBUG TRAIN Batch 11/5400 loss 10.256470 loss_att 13.889328 loss_ctc 22.184179 loss_rnnt 7.939536 lr 0.00050745 rank 5
2022-12-04 08:20:09,192 DEBUG TRAIN Batch 11/5400 loss 7.362431 loss_att 11.300278 loss_ctc 17.166273 loss_rnnt 5.267682 lr 0.00050733 rank 0
2022-12-04 08:20:09,194 DEBUG TRAIN Batch 11/5400 loss 15.251144 loss_att 19.072170 loss_ctc 28.269373 loss_rnnt 12.751175 lr 0.00050742 rank 6
2022-12-04 08:20:09,196 DEBUG TRAIN Batch 11/5400 loss 8.888136 loss_att 13.623129 loss_ctc 18.932833 loss_rnnt 6.601844 lr 0.00050717 rank 2
2022-12-04 08:20:09,198 DEBUG TRAIN Batch 11/5400 loss 17.442389 loss_att 22.149601 loss_ctc 33.115417 loss_rnnt 14.411208 lr 0.00050730 rank 1
2022-12-04 08:20:09,197 DEBUG TRAIN Batch 11/5400 loss 7.689146 loss_att 10.667593 loss_ctc 12.125835 loss_rnnt 6.501897 lr 0.00050734 rank 7
2022-12-04 08:20:09,199 DEBUG TRAIN Batch 11/5400 loss 12.848131 loss_att 17.339451 loss_ctc 19.580318 loss_rnnt 11.052242 lr 0.00050727 rank 3
2022-12-04 08:20:09,206 DEBUG TRAIN Batch 11/5400 loss 13.723841 loss_att 16.103746 loss_ctc 24.639538 loss_rnnt 11.792433 lr 0.00050745 rank 4
2022-12-04 08:21:21,285 DEBUG TRAIN Batch 11/5500 loss 9.293972 loss_att 14.027973 loss_ctc 13.700552 loss_rnnt 7.759627 lr 0.00050701 rank 3
2022-12-04 08:21:21,291 DEBUG TRAIN Batch 11/5500 loss 11.070317 loss_att 13.132833 loss_ctc 19.409302 loss_rnnt 9.545950 lr 0.00050704 rank 1
2022-12-04 08:21:21,300 DEBUG TRAIN Batch 11/5500 loss 16.957792 loss_att 21.858883 loss_ctc 30.773043 loss_rnnt 14.135538 lr 0.00050719 rank 5
2022-12-04 08:21:21,302 DEBUG TRAIN Batch 11/5500 loss 13.637156 loss_att 15.522021 loss_ctc 24.393227 loss_rnnt 11.826040 lr 0.00050707 rank 0
2022-12-04 08:21:21,303 DEBUG TRAIN Batch 11/5500 loss 6.164438 loss_att 8.491268 loss_ctc 8.148619 loss_rnnt 5.434514 lr 0.00050691 rank 2
2022-12-04 08:21:21,305 DEBUG TRAIN Batch 11/5500 loss 12.904395 loss_att 14.294325 loss_ctc 15.502139 loss_rnnt 12.280044 lr 0.00050716 rank 6
2022-12-04 08:21:21,305 DEBUG TRAIN Batch 11/5500 loss 20.539053 loss_att 20.098125 loss_ctc 33.040939 loss_rnnt 18.960320 lr 0.00050708 rank 7
2022-12-04 08:21:21,311 DEBUG TRAIN Batch 11/5500 loss 20.653976 loss_att 25.015760 loss_ctc 36.936104 loss_rnnt 17.610670 lr 0.00050718 rank 4
2022-12-04 08:22:33,629 DEBUG TRAIN Batch 11/5600 loss 12.747908 loss_att 15.069334 loss_ctc 21.361767 loss_rnnt 11.135108 lr 0.00050693 rank 5
2022-12-04 08:22:33,629 DEBUG TRAIN Batch 11/5600 loss 11.562590 loss_att 15.505478 loss_ctc 22.248013 loss_rnnt 9.349289 lr 0.00050681 rank 0
2022-12-04 08:22:33,631 DEBUG TRAIN Batch 11/5600 loss 15.308475 loss_att 18.045067 loss_ctc 28.575064 loss_rnnt 12.992278 lr 0.00050665 rank 2
2022-12-04 08:22:33,632 DEBUG TRAIN Batch 11/5600 loss 21.747272 loss_att 23.797777 loss_ctc 37.787525 loss_rnnt 19.198471 lr 0.00050690 rank 6
2022-12-04 08:22:33,632 DEBUG TRAIN Batch 11/5600 loss 8.830110 loss_att 10.731396 loss_ctc 14.647644 loss_rnnt 7.674180 lr 0.00050682 rank 7
2022-12-04 08:22:33,635 DEBUG TRAIN Batch 11/5600 loss 8.654327 loss_att 13.000769 loss_ctc 16.927135 loss_rnnt 6.681998 lr 0.00050675 rank 3
2022-12-04 08:22:33,635 DEBUG TRAIN Batch 11/5600 loss 11.173109 loss_att 17.538010 loss_ctc 17.463957 loss_rnnt 9.061348 lr 0.00050678 rank 1
2022-12-04 08:22:33,643 DEBUG TRAIN Batch 11/5600 loss 10.308897 loss_att 14.059567 loss_ctc 17.572081 loss_rnnt 8.590338 lr 0.00050692 rank 4
2022-12-04 08:23:49,936 DEBUG TRAIN Batch 11/5700 loss 10.623487 loss_att 13.807420 loss_ctc 19.426840 loss_rnnt 8.812921 lr 0.00050655 rank 0
2022-12-04 08:23:49,937 DEBUG TRAIN Batch 11/5700 loss 10.459504 loss_att 15.273634 loss_ctc 17.892746 loss_rnnt 8.505580 lr 0.00050652 rank 1
2022-12-04 08:23:49,938 DEBUG TRAIN Batch 11/5700 loss 18.277649 loss_att 20.390804 loss_ctc 24.013367 loss_rnnt 17.090256 lr 0.00050664 rank 6
2022-12-04 08:23:49,939 DEBUG TRAIN Batch 11/5700 loss 8.429872 loss_att 12.032195 loss_ctc 15.197825 loss_rnnt 6.807013 lr 0.00050649 rank 3
2022-12-04 08:23:49,942 DEBUG TRAIN Batch 11/5700 loss 13.823940 loss_att 11.965325 loss_ctc 14.913074 loss_rnnt 14.050446 lr 0.00050639 rank 2
2022-12-04 08:23:49,943 DEBUG TRAIN Batch 11/5700 loss 9.037119 loss_att 13.915855 loss_ctc 19.010429 loss_rnnt 6.731597 lr 0.00050656 rank 7
2022-12-04 08:23:49,986 DEBUG TRAIN Batch 11/5700 loss 20.652664 loss_att 26.638296 loss_ctc 33.243225 loss_rnnt 17.776796 lr 0.00050667 rank 5
2022-12-04 08:23:49,992 DEBUG TRAIN Batch 11/5700 loss 11.481902 loss_att 12.662014 loss_ctc 16.721701 loss_rnnt 10.547240 lr 0.00050666 rank 4
2022-12-04 08:25:02,540 DEBUG TRAIN Batch 11/5800 loss 19.735401 loss_att 23.045990 loss_ctc 31.272331 loss_rnnt 17.535027 lr 0.00050638 rank 6
2022-12-04 08:25:02,543 DEBUG TRAIN Batch 11/5800 loss 5.126582 loss_att 9.203645 loss_ctc 10.587276 loss_rnnt 3.583077 lr 0.00050626 rank 1
2022-12-04 08:25:02,545 DEBUG TRAIN Batch 11/5800 loss 12.835214 loss_att 14.849319 loss_ctc 23.278128 loss_rnnt 11.040003 lr 0.00050641 rank 5
2022-12-04 08:25:02,546 DEBUG TRAIN Batch 11/5800 loss 13.891460 loss_att 17.325960 loss_ctc 21.938931 loss_rnnt 12.131564 lr 0.00050629 rank 0
2022-12-04 08:25:02,547 DEBUG TRAIN Batch 11/5800 loss 10.667843 loss_att 11.364176 loss_ctc 19.264603 loss_rnnt 9.382341 lr 0.00050613 rank 2
2022-12-04 08:25:02,549 DEBUG TRAIN Batch 11/5800 loss 16.443905 loss_att 18.369368 loss_ctc 23.567612 loss_rnnt 15.108986 lr 0.00050630 rank 7
2022-12-04 08:25:02,551 DEBUG TRAIN Batch 11/5800 loss 15.358329 loss_att 21.776306 loss_ctc 25.704479 loss_rnnt 12.695247 lr 0.00050640 rank 4
2022-12-04 08:25:02,552 DEBUG TRAIN Batch 11/5800 loss 11.512714 loss_att 18.370510 loss_ctc 24.738274 loss_rnnt 8.377747 lr 0.00050623 rank 3
2022-12-04 08:26:13,495 DEBUG TRAIN Batch 11/5900 loss 18.237434 loss_att 22.495211 loss_ctc 29.576849 loss_rnnt 15.873958 lr 0.00050612 rank 6
2022-12-04 08:26:13,495 DEBUG TRAIN Batch 11/5900 loss 14.116214 loss_att 23.048010 loss_ctc 32.975967 loss_rnnt 9.815220 lr 0.00050597 rank 3
2022-12-04 08:26:13,498 DEBUG TRAIN Batch 11/5900 loss 11.278090 loss_att 16.927670 loss_ctc 15.256174 loss_rnnt 9.617764 lr 0.00050603 rank 0
2022-12-04 08:26:13,499 DEBUG TRAIN Batch 11/5900 loss 9.728994 loss_att 15.255468 loss_ctc 16.660976 loss_rnnt 7.699435 lr 0.00050615 rank 5
2022-12-04 08:26:13,504 DEBUG TRAIN Batch 11/5900 loss 11.493327 loss_att 15.370640 loss_ctc 21.959333 loss_rnnt 9.322397 lr 0.00050600 rank 1
2022-12-04 08:26:13,504 DEBUG TRAIN Batch 11/5900 loss 15.178161 loss_att 19.097841 loss_ctc 24.918322 loss_rnnt 13.095535 lr 0.00050604 rank 7
2022-12-04 08:26:13,505 DEBUG TRAIN Batch 11/5900 loss 15.761959 loss_att 22.197643 loss_ctc 23.278357 loss_rnnt 13.472635 lr 0.00050614 rank 4
2022-12-04 08:26:13,543 DEBUG TRAIN Batch 11/5900 loss 22.815243 loss_att 22.689924 loss_ctc 31.458904 loss_rnnt 21.687819 lr 0.00050587 rank 2
2022-12-04 08:27:27,198 DEBUG TRAIN Batch 11/6000 loss 16.584726 loss_att 15.654711 loss_ctc 23.621891 loss_rnnt 15.832441 lr 0.00050574 rank 1
2022-12-04 08:27:27,203 DEBUG TRAIN Batch 11/6000 loss 21.080030 loss_att 25.480625 loss_ctc 38.287498 loss_rnnt 17.905582 lr 0.00050571 rank 3
2022-12-04 08:27:27,203 DEBUG TRAIN Batch 11/6000 loss 16.301399 loss_att 19.567471 loss_ctc 31.202120 loss_rnnt 13.661420 lr 0.00050561 rank 2
2022-12-04 08:27:27,204 DEBUG TRAIN Batch 11/6000 loss 16.717083 loss_att 18.240877 loss_ctc 22.129255 loss_rnnt 15.690701 lr 0.00050586 rank 6
2022-12-04 08:27:27,204 DEBUG TRAIN Batch 11/6000 loss 24.560350 loss_att 24.823925 loss_ctc 35.665245 loss_rnnt 23.026981 lr 0.00050577 rank 0
2022-12-04 08:27:27,205 DEBUG TRAIN Batch 11/6000 loss 12.133371 loss_att 15.401073 loss_ctc 23.840187 loss_rnnt 9.918922 lr 0.00050578 rank 7
2022-12-04 08:27:27,207 DEBUG TRAIN Batch 11/6000 loss 16.669500 loss_att 17.633421 loss_ctc 25.522665 loss_rnnt 15.296293 lr 0.00050588 rank 4
2022-12-04 08:27:27,250 DEBUG TRAIN Batch 11/6000 loss 8.642632 loss_att 11.706221 loss_ctc 17.445580 loss_rnnt 6.856187 lr 0.00050589 rank 5
2022-12-04 08:28:42,031 DEBUG TRAIN Batch 11/6100 loss 11.559265 loss_att 14.832240 loss_ctc 23.043076 loss_rnnt 9.373495 lr 0.00050545 rank 3
2022-12-04 08:28:42,037 DEBUG TRAIN Batch 11/6100 loss 20.097986 loss_att 22.225822 loss_ctc 25.134264 loss_rnnt 19.000916 lr 0.00050551 rank 0
2022-12-04 08:28:42,038 DEBUG TRAIN Batch 11/6100 loss 17.858845 loss_att 23.170639 loss_ctc 35.114296 loss_rnnt 14.495758 lr 0.00050548 rank 1
2022-12-04 08:28:42,039 DEBUG TRAIN Batch 11/6100 loss 5.500839 loss_att 8.793528 loss_ctc 8.171922 loss_rnnt 4.486156 lr 0.00050535 rank 2
2022-12-04 08:28:42,039 DEBUG TRAIN Batch 11/6100 loss 14.235884 loss_att 18.618921 loss_ctc 25.009037 loss_rnnt 11.922855 lr 0.00050560 rank 6
2022-12-04 08:28:42,042 DEBUG TRAIN Batch 11/6100 loss 6.643613 loss_att 11.115646 loss_ctc 12.635324 loss_rnnt 4.950312 lr 0.00050563 rank 4
2022-12-04 08:28:42,045 DEBUG TRAIN Batch 11/6100 loss 5.999852 loss_att 10.356169 loss_ctc 14.246115 loss_rnnt 4.029087 lr 0.00050553 rank 7
2022-12-04 08:28:42,091 DEBUG TRAIN Batch 11/6100 loss 12.939540 loss_att 16.449751 loss_ctc 20.593746 loss_rnnt 11.216937 lr 0.00050563 rank 5
2022-12-04 08:29:53,249 DEBUG TRAIN Batch 11/6200 loss 6.565823 loss_att 9.454230 loss_ctc 14.129923 loss_rnnt 4.979594 lr 0.00050519 rank 3
2022-12-04 08:29:53,267 DEBUG TRAIN Batch 11/6200 loss 9.127640 loss_att 13.568235 loss_ctc 16.550230 loss_rnnt 7.249841 lr 0.00050509 rank 2
2022-12-04 08:29:53,270 DEBUG TRAIN Batch 11/6200 loss 14.579599 loss_att 15.630218 loss_ctc 22.863457 loss_rnnt 13.264961 lr 0.00050527 rank 7
2022-12-04 08:29:53,270 DEBUG TRAIN Batch 11/6200 loss 10.876612 loss_att 12.452055 loss_ctc 18.109413 loss_rnnt 9.597149 lr 0.00050538 rank 5
2022-12-04 08:29:53,271 DEBUG TRAIN Batch 11/6200 loss 7.476342 loss_att 11.085589 loss_ctc 15.044716 loss_rnnt 5.745376 lr 0.00050522 rank 1
2022-12-04 08:29:53,271 DEBUG TRAIN Batch 11/6200 loss 15.825242 loss_att 17.049286 loss_ctc 29.676046 loss_rnnt 13.733659 lr 0.00050526 rank 0
2022-12-04 08:29:53,275 DEBUG TRAIN Batch 11/6200 loss 4.963501 loss_att 7.129922 loss_ctc 9.854134 loss_rnnt 3.878133 lr 0.00050534 rank 6
2022-12-04 08:29:53,279 DEBUG TRAIN Batch 11/6200 loss 18.793495 loss_att 22.828114 loss_ctc 34.161312 loss_rnnt 15.937529 lr 0.00050537 rank 4
2022-12-04 08:31:05,014 DEBUG TRAIN Batch 11/6300 loss 16.934486 loss_att 18.081499 loss_ctc 25.561741 loss_rnnt 15.554782 lr 0.00050512 rank 5
2022-12-04 08:31:05,015 DEBUG TRAIN Batch 11/6300 loss 18.528130 loss_att 21.658142 loss_ctc 32.212170 loss_rnnt 16.077587 lr 0.00050500 rank 0
2022-12-04 08:31:05,017 DEBUG TRAIN Batch 11/6300 loss 10.836987 loss_att 11.170047 loss_ctc 17.396723 loss_rnnt 9.895743 lr 0.00050508 rank 6
2022-12-04 08:31:05,018 DEBUG TRAIN Batch 11/6300 loss 13.671583 loss_att 18.508913 loss_ctc 15.887651 loss_rnnt 12.408642 lr 0.00050501 rank 7
2022-12-04 08:31:05,022 DEBUG TRAIN Batch 11/6300 loss 22.821720 loss_att 23.269152 loss_ctc 34.705105 loss_rnnt 21.147781 lr 0.00050494 rank 3
2022-12-04 08:31:05,035 DEBUG TRAIN Batch 11/6300 loss 7.573580 loss_att 10.211917 loss_ctc 17.622309 loss_rnnt 5.706082 lr 0.00050511 rank 4
2022-12-04 08:31:05,038 DEBUG TRAIN Batch 11/6300 loss 13.767785 loss_att 17.006130 loss_ctc 22.581228 loss_rnnt 11.944991 lr 0.00050483 rank 2
2022-12-04 08:31:05,070 DEBUG TRAIN Batch 11/6300 loss 14.482882 loss_att 17.659164 loss_ctc 23.605047 loss_rnnt 12.631335 lr 0.00050497 rank 1
2022-12-04 08:32:19,674 DEBUG TRAIN Batch 11/6400 loss 12.191936 loss_att 12.120659 loss_ctc 18.204519 loss_rnnt 11.404513 lr 0.00050468 rank 3
2022-12-04 08:32:19,675 DEBUG TRAIN Batch 11/6400 loss 10.378698 loss_att 9.745480 loss_ctc 14.363576 loss_rnnt 9.974025 lr 0.00050474 rank 0
2022-12-04 08:32:19,676 DEBUG TRAIN Batch 11/6400 loss 4.963356 loss_att 7.749379 loss_ctc 6.995360 loss_rnnt 4.135217 lr 0.00050483 rank 6
2022-12-04 08:32:19,678 DEBUG TRAIN Batch 11/6400 loss 13.189186 loss_att 17.030731 loss_ctc 20.586529 loss_rnnt 11.434566 lr 0.00050486 rank 5
2022-12-04 08:32:19,680 DEBUG TRAIN Batch 11/6400 loss 10.530241 loss_att 10.651722 loss_ctc 12.800775 loss_rnnt 10.203207 lr 0.00050471 rank 1
2022-12-04 08:32:19,681 DEBUG TRAIN Batch 11/6400 loss 11.338019 loss_att 17.098774 loss_ctc 22.096800 loss_rnnt 8.751364 lr 0.00050475 rank 7
2022-12-04 08:32:19,697 DEBUG TRAIN Batch 11/6400 loss 11.837514 loss_att 18.891647 loss_ctc 22.066578 loss_rnnt 9.062813 lr 0.00050485 rank 4
2022-12-04 08:32:19,717 DEBUG TRAIN Batch 11/6400 loss 7.072612 loss_att 13.740238 loss_ctc 15.308814 loss_rnnt 4.640925 lr 0.00050458 rank 2
2022-12-04 08:33:32,121 DEBUG TRAIN Batch 11/6500 loss 6.936949 loss_att 10.448059 loss_ctc 12.069185 loss_rnnt 5.550429 lr 0.00050448 rank 0
2022-12-04 08:33:32,123 DEBUG TRAIN Batch 11/6500 loss 16.726072 loss_att 19.378702 loss_ctc 29.035183 loss_rnnt 14.554332 lr 0.00050445 rank 1
2022-12-04 08:33:32,124 DEBUG TRAIN Batch 11/6500 loss 21.441406 loss_att 24.504667 loss_ctc 36.784302 loss_rnnt 18.783035 lr 0.00050460 rank 5
2022-12-04 08:33:32,127 DEBUG TRAIN Batch 11/6500 loss 10.444500 loss_att 17.357399 loss_ctc 16.898567 loss_rnnt 8.201378 lr 0.00050449 rank 7
2022-12-04 08:33:32,129 DEBUG TRAIN Batch 11/6500 loss 13.761531 loss_att 15.878825 loss_ctc 20.778814 loss_rnnt 12.402434 lr 0.00050457 rank 6
2022-12-04 08:33:32,129 DEBUG TRAIN Batch 11/6500 loss 24.467432 loss_att 27.293711 loss_ctc 38.422894 loss_rnnt 22.041447 lr 0.00050432 rank 2
2022-12-04 08:33:32,141 DEBUG TRAIN Batch 11/6500 loss 10.142252 loss_att 11.758731 loss_ctc 16.831154 loss_rnnt 8.927103 lr 0.00050442 rank 3
2022-12-04 08:33:32,187 DEBUG TRAIN Batch 11/6500 loss 6.579716 loss_att 14.468007 loss_ctc 15.382452 loss_rnnt 3.828359 lr 0.00050460 rank 4
2022-12-04 08:34:43,862 DEBUG TRAIN Batch 11/6600 loss 8.833899 loss_att 11.329239 loss_ctc 18.036934 loss_rnnt 7.107761 lr 0.00050435 rank 5
2022-12-04 08:34:43,864 DEBUG TRAIN Batch 11/6600 loss 12.698411 loss_att 15.172356 loss_ctc 19.372854 loss_rnnt 11.313697 lr 0.00050423 rank 0
2022-12-04 08:34:43,866 DEBUG TRAIN Batch 11/6600 loss 11.190727 loss_att 13.449079 loss_ctc 17.873699 loss_rnnt 9.847995 lr 0.00050424 rank 7
2022-12-04 08:34:43,869 DEBUG TRAIN Batch 11/6600 loss 12.970811 loss_att 15.007519 loss_ctc 21.042103 loss_rnnt 11.487297 lr 0.00050431 rank 6
2022-12-04 08:34:43,871 DEBUG TRAIN Batch 11/6600 loss 19.797264 loss_att 25.486767 loss_ctc 39.060604 loss_rnnt 16.090919 lr 0.00050417 rank 3
2022-12-04 08:34:43,872 DEBUG TRAIN Batch 11/6600 loss 5.230738 loss_att 8.316096 loss_ctc 7.786178 loss_rnnt 4.272941 lr 0.00050406 rank 2
2022-12-04 08:34:43,874 DEBUG TRAIN Batch 11/6600 loss 5.052619 loss_att 8.668695 loss_ctc 9.915224 loss_rnnt 3.681056 lr 0.00050434 rank 4
2022-12-04 08:34:43,912 DEBUG TRAIN Batch 11/6600 loss 15.968714 loss_att 25.727541 loss_ctc 30.456688 loss_rnnt 12.085218 lr 0.00050419 rank 1
2022-12-04 08:35:56,125 DEBUG TRAIN Batch 11/6700 loss 16.148386 loss_att 19.597227 loss_ctc 25.748571 loss_rnnt 14.178592 lr 0.00050397 rank 0
2022-12-04 08:35:56,125 DEBUG TRAIN Batch 11/6700 loss 17.413773 loss_att 16.946087 loss_ctc 25.772058 loss_rnnt 16.392872 lr 0.00050409 rank 5
2022-12-04 08:35:56,127 DEBUG TRAIN Batch 11/6700 loss 14.533646 loss_att 16.738356 loss_ctc 19.283293 loss_rnnt 13.459417 lr 0.00050391 rank 3
2022-12-04 08:35:56,129 DEBUG TRAIN Batch 11/6700 loss 15.407623 loss_att 17.999180 loss_ctc 24.958691 loss_rnnt 13.615836 lr 0.00050406 rank 6
2022-12-04 08:35:56,130 DEBUG TRAIN Batch 11/6700 loss 15.053558 loss_att 18.931625 loss_ctc 24.135714 loss_rnnt 13.066991 lr 0.00050394 rank 1
2022-12-04 08:35:56,134 DEBUG TRAIN Batch 11/6700 loss 23.033249 loss_att 29.329832 loss_ctc 34.180786 loss_rnnt 20.287592 lr 0.00050398 rank 7
2022-12-04 08:35:56,140 DEBUG TRAIN Batch 11/6700 loss 9.465803 loss_att 15.317661 loss_ctc 12.792736 loss_rnnt 7.851840 lr 0.00050408 rank 4
2022-12-04 08:35:56,142 DEBUG TRAIN Batch 11/6700 loss 13.262999 loss_att 16.483231 loss_ctc 21.587616 loss_rnnt 11.509003 lr 0.00050381 rank 2
2022-12-04 08:37:09,001 DEBUG TRAIN Batch 11/6800 loss 13.683992 loss_att 16.161215 loss_ctc 24.410240 loss_rnnt 11.758381 lr 0.00050380 rank 6
2022-12-04 08:37:09,017 DEBUG TRAIN Batch 11/6800 loss 11.943750 loss_att 14.632975 loss_ctc 23.268835 loss_rnnt 9.895894 lr 0.00050372 rank 0
2022-12-04 08:37:09,020 DEBUG TRAIN Batch 11/6800 loss 12.590953 loss_att 19.422129 loss_ctc 27.782536 loss_rnnt 9.199173 lr 0.00050368 rank 1
2022-12-04 08:37:09,022 DEBUG TRAIN Batch 11/6800 loss 14.821638 loss_att 16.664410 loss_ctc 24.993864 loss_rnnt 13.096786 lr 0.00050383 rank 4
2022-12-04 08:37:09,023 DEBUG TRAIN Batch 11/6800 loss 11.093507 loss_att 15.100823 loss_ctc 25.800444 loss_rnnt 8.331119 lr 0.00050355 rank 2
2022-12-04 08:37:09,025 DEBUG TRAIN Batch 11/6800 loss 4.851535 loss_att 8.931393 loss_ctc 10.844180 loss_rnnt 3.236544 lr 0.00050373 rank 7
2022-12-04 08:37:09,025 DEBUG TRAIN Batch 11/6800 loss 10.541046 loss_att 13.291136 loss_ctc 18.462870 loss_rnnt 8.934785 lr 0.00050365 rank 3
2022-12-04 08:37:09,028 DEBUG TRAIN Batch 11/6800 loss 23.452267 loss_att 27.421494 loss_ctc 36.765377 loss_rnnt 20.883339 lr 0.00050383 rank 5
2022-12-04 08:38:20,519 DEBUG TRAIN Batch 11/6900 loss 7.472342 loss_att 9.895422 loss_ctc 13.407195 loss_rnnt 6.196411 lr 0.00050354 rank 6
2022-12-04 08:38:20,522 DEBUG TRAIN Batch 11/6900 loss 19.818420 loss_att 21.631208 loss_ctc 28.523720 loss_rnnt 18.295158 lr 0.00050343 rank 1
2022-12-04 08:38:20,526 DEBUG TRAIN Batch 11/6900 loss 12.313539 loss_att 16.845329 loss_ctc 22.574045 loss_rnnt 10.039113 lr 0.00050330 rank 2
2022-12-04 08:38:20,526 DEBUG TRAIN Batch 11/6900 loss 10.689913 loss_att 12.660430 loss_ctc 17.216999 loss_rnnt 9.425532 lr 0.00050347 rank 7
2022-12-04 08:38:20,528 DEBUG TRAIN Batch 11/6900 loss 9.112733 loss_att 12.518143 loss_ctc 14.408349 loss_rnnt 7.725569 lr 0.00050346 rank 0
2022-12-04 08:38:20,529 DEBUG TRAIN Batch 11/6900 loss 17.543972 loss_att 19.028990 loss_ctc 32.869930 loss_rnnt 15.203506 lr 0.00050358 rank 5
2022-12-04 08:38:20,529 DEBUG TRAIN Batch 11/6900 loss 15.503514 loss_att 17.813744 loss_ctc 20.971437 loss_rnnt 14.312410 lr 0.00050340 rank 3
2022-12-04 08:38:20,531 DEBUG TRAIN Batch 11/6900 loss 13.057385 loss_att 15.124817 loss_ctc 17.476374 loss_rnnt 12.054701 lr 0.00050357 rank 4
2022-12-04 08:39:33,111 DEBUG TRAIN Batch 11/7000 loss 49.140068 loss_att 56.805695 loss_ctc 71.911591 loss_rnnt 44.570740 lr 0.00050332 rank 5
2022-12-04 08:39:33,113 DEBUG TRAIN Batch 11/7000 loss 16.804930 loss_att 16.764238 loss_ctc 27.257635 loss_rnnt 15.419375 lr 0.00050321 rank 0
2022-12-04 08:39:33,115 DEBUG TRAIN Batch 11/7000 loss 8.035265 loss_att 12.273044 loss_ctc 13.513229 loss_rnnt 6.457314 lr 0.00050329 rank 6
2022-12-04 08:39:33,115 DEBUG TRAIN Batch 11/7000 loss 15.791157 loss_att 17.924950 loss_ctc 27.092312 loss_rnnt 13.857577 lr 0.00050314 rank 3
2022-12-04 08:39:33,118 DEBUG TRAIN Batch 11/7000 loss 12.434473 loss_att 16.391159 loss_ctc 26.284737 loss_rnnt 9.796434 lr 0.00050322 rank 7
2022-12-04 08:39:33,119 DEBUG TRAIN Batch 11/7000 loss 16.910889 loss_att 17.719685 loss_ctc 27.898153 loss_rnnt 15.284160 lr 0.00050304 rank 2
2022-12-04 08:39:33,125 DEBUG TRAIN Batch 11/7000 loss 6.582028 loss_att 9.246422 loss_ctc 12.632948 loss_rnnt 5.242361 lr 0.00050332 rank 4
2022-12-04 08:39:33,166 DEBUG TRAIN Batch 11/7000 loss 11.283957 loss_att 13.354078 loss_ctc 19.591919 loss_rnnt 9.762205 lr 0.00050317 rank 1
2022-12-04 08:40:46,779 DEBUG TRAIN Batch 11/7100 loss 5.880581 loss_att 9.873650 loss_ctc 6.649049 loss_rnnt 4.979505 lr 0.00050296 rank 7
2022-12-04 08:40:46,783 DEBUG TRAIN Batch 11/7100 loss 11.177512 loss_att 14.404074 loss_ctc 20.842903 loss_rnnt 9.243481 lr 0.00050306 rank 4
2022-12-04 08:40:46,790 DEBUG TRAIN Batch 11/7100 loss 6.207685 loss_att 10.877972 loss_ctc 15.951071 loss_rnnt 3.974509 lr 0.00050295 rank 0
2022-12-04 08:40:46,793 DEBUG TRAIN Batch 11/7100 loss 8.702532 loss_att 12.057038 loss_ctc 15.752695 loss_rnnt 7.091609 lr 0.00050303 rank 6
2022-12-04 08:40:46,799 DEBUG TRAIN Batch 11/7100 loss 22.159454 loss_att 27.612091 loss_ctc 31.990665 loss_rnnt 19.758099 lr 0.00050279 rank 2
2022-12-04 08:40:46,798 DEBUG TRAIN Batch 11/7100 loss 10.848013 loss_att 13.688055 loss_ctc 16.014427 loss_rnnt 9.591149 lr 0.00050307 rank 5
2022-12-04 08:40:46,800 DEBUG TRAIN Batch 11/7100 loss 7.405714 loss_att 10.075844 loss_ctc 13.514263 loss_rnnt 6.057215 lr 0.00050292 rank 1
2022-12-04 08:40:46,819 DEBUG TRAIN Batch 11/7100 loss 16.349365 loss_att 22.145493 loss_ctc 29.155510 loss_rnnt 13.482654 lr 0.00050289 rank 3
2022-12-04 08:41:58,855 DEBUG TRAIN Batch 11/7200 loss 7.043054 loss_att 10.488659 loss_ctc 14.135254 loss_rnnt 5.408306 lr 0.00050278 rank 6
2022-12-04 08:41:58,861 DEBUG TRAIN Batch 11/7200 loss 9.054212 loss_att 15.789146 loss_ctc 14.316278 loss_rnnt 7.005616 lr 0.00050271 rank 7
2022-12-04 08:41:58,862 DEBUG TRAIN Batch 11/7200 loss 12.396603 loss_att 18.576286 loss_ctc 22.401093 loss_rnnt 9.826735 lr 0.00050270 rank 0
2022-12-04 08:41:58,863 DEBUG TRAIN Batch 11/7200 loss 3.443215 loss_att 9.241138 loss_ctc 4.588774 loss_rnnt 2.130889 lr 0.00050281 rank 5
2022-12-04 08:41:58,864 DEBUG TRAIN Batch 11/7200 loss 8.070368 loss_att 12.288868 loss_ctc 16.308365 loss_rnnt 6.128268 lr 0.00050264 rank 3
2022-12-04 08:41:58,865 DEBUG TRAIN Batch 11/7200 loss 16.612194 loss_att 19.833651 loss_ctc 36.542679 loss_rnnt 13.310504 lr 0.00050266 rank 1
2022-12-04 08:41:58,870 DEBUG TRAIN Batch 11/7200 loss 23.946428 loss_att 34.042107 loss_ctc 43.047314 loss_rnnt 19.380508 lr 0.00050253 rank 2
2022-12-04 08:41:58,871 DEBUG TRAIN Batch 11/7200 loss 17.584213 loss_att 20.233490 loss_ctc 27.019665 loss_rnnt 15.796299 lr 0.00050281 rank 4
2022-12-04 08:43:10,390 DEBUG TRAIN Batch 11/7300 loss 11.095903 loss_att 12.858765 loss_ctc 15.458829 loss_rnnt 10.161608 lr 0.00050256 rank 5
2022-12-04 08:43:10,398 DEBUG TRAIN Batch 11/7300 loss 16.067408 loss_att 19.925829 loss_ctc 26.554970 loss_rnnt 13.897381 lr 0.00050244 rank 0
2022-12-04 08:43:10,399 DEBUG TRAIN Batch 11/7300 loss 6.785125 loss_att 11.203924 loss_ctc 11.255381 loss_rnnt 5.305331 lr 0.00050253 rank 6
2022-12-04 08:43:10,401 DEBUG TRAIN Batch 11/7300 loss 6.972712 loss_att 10.728034 loss_ctc 11.226666 loss_rnnt 5.654453 lr 0.00050245 rank 7
2022-12-04 08:43:10,403 DEBUG TRAIN Batch 11/7300 loss 13.274920 loss_att 18.992912 loss_ctc 26.813992 loss_rnnt 10.326113 lr 0.00050241 rank 1
2022-12-04 08:43:10,404 DEBUG TRAIN Batch 11/7300 loss 9.478785 loss_att 12.999954 loss_ctc 14.529152 loss_rnnt 8.101169 lr 0.00050228 rank 2
2022-12-04 08:43:10,405 DEBUG TRAIN Batch 11/7300 loss 13.794392 loss_att 15.182573 loss_ctc 22.701778 loss_rnnt 12.329103 lr 0.00050238 rank 3
2022-12-04 08:43:10,413 DEBUG TRAIN Batch 11/7300 loss 5.602746 loss_att 8.952134 loss_ctc 10.811272 loss_rnnt 4.238399 lr 0.00050255 rank 4
2022-12-04 08:44:22,350 DEBUG TRAIN Batch 11/7400 loss 5.249123 loss_att 8.383160 loss_ctc 9.817730 loss_rnnt 4.013167 lr 0.00050216 rank 1
2022-12-04 08:44:22,355 DEBUG TRAIN Batch 11/7400 loss 12.471033 loss_att 16.110132 loss_ctc 22.891520 loss_rnnt 10.353814 lr 0.00050227 rank 6
2022-12-04 08:44:22,356 DEBUG TRAIN Batch 11/7400 loss 14.121683 loss_att 16.975908 loss_ctc 23.817875 loss_rnnt 12.258014 lr 0.00050220 rank 7
2022-12-04 08:44:22,359 DEBUG TRAIN Batch 11/7400 loss 8.588675 loss_att 12.050155 loss_ctc 12.528923 loss_rnnt 7.371011 lr 0.00050230 rank 4
2022-12-04 08:44:22,360 DEBUG TRAIN Batch 11/7400 loss 15.832055 loss_att 15.207600 loss_ctc 20.814854 loss_rnnt 15.292572 lr 0.00050213 rank 3
2022-12-04 08:44:22,363 DEBUG TRAIN Batch 11/7400 loss 11.531240 loss_att 13.980059 loss_ctc 19.231937 loss_rnnt 10.014717 lr 0.00050219 rank 0
2022-12-04 08:44:22,365 DEBUG TRAIN Batch 11/7400 loss 9.916064 loss_att 12.783533 loss_ctc 16.906021 loss_rnnt 8.410576 lr 0.00050203 rank 2
2022-12-04 08:44:22,407 DEBUG TRAIN Batch 11/7400 loss 20.640585 loss_att 24.801353 loss_ctc 35.266945 loss_rnnt 17.858248 lr 0.00050231 rank 5
2022-12-04 08:45:36,338 DEBUG TRAIN Batch 11/7500 loss 11.556542 loss_att 15.218409 loss_ctc 16.583931 loss_rnnt 10.153851 lr 0.00050188 rank 3
2022-12-04 08:45:36,342 DEBUG TRAIN Batch 11/7500 loss 8.873783 loss_att 12.942139 loss_ctc 14.993670 loss_rnnt 7.244127 lr 0.00050205 rank 5
2022-12-04 08:45:36,345 DEBUG TRAIN Batch 11/7500 loss 6.651609 loss_att 9.559738 loss_ctc 12.119303 loss_rnnt 5.340958 lr 0.00050202 rank 6
2022-12-04 08:45:36,348 DEBUG TRAIN Batch 11/7500 loss 12.419596 loss_att 17.886574 loss_ctc 24.288670 loss_rnnt 9.743656 lr 0.00050190 rank 1
2022-12-04 08:45:36,348 DEBUG TRAIN Batch 11/7500 loss 5.705975 loss_att 8.726267 loss_ctc 11.628694 loss_rnnt 4.312221 lr 0.00050194 rank 0
2022-12-04 08:45:36,351 DEBUG TRAIN Batch 11/7500 loss 6.880497 loss_att 9.435662 loss_ctc 14.036148 loss_rnnt 5.415378 lr 0.00050195 rank 7
2022-12-04 08:45:36,351 DEBUG TRAIN Batch 11/7500 loss 16.613476 loss_att 17.816330 loss_ctc 22.229252 loss_rnnt 15.624135 lr 0.00050177 rank 2
2022-12-04 08:45:36,359 DEBUG TRAIN Batch 11/7500 loss 14.012023 loss_att 15.869617 loss_ctc 20.927679 loss_rnnt 12.718416 lr 0.00050204 rank 4
2022-12-04 08:46:48,330 DEBUG TRAIN Batch 11/7600 loss 6.851382 loss_att 9.444848 loss_ctc 11.985286 loss_rnnt 5.648168 lr 0.00050168 rank 0
2022-12-04 08:46:48,330 DEBUG TRAIN Batch 11/7600 loss 10.009257 loss_att 14.482881 loss_ctc 18.782087 loss_rnnt 7.944822 lr 0.00050165 rank 1
2022-12-04 08:46:48,330 DEBUG TRAIN Batch 11/7600 loss 11.914772 loss_att 12.170402 loss_ctc 19.158281 loss_rnnt 10.897845 lr 0.00050180 rank 5
2022-12-04 08:46:48,333 DEBUG TRAIN Batch 11/7600 loss 8.426075 loss_att 9.101383 loss_ctc 13.152880 loss_rnnt 7.660773 lr 0.00050177 rank 6
2022-12-04 08:46:48,335 DEBUG TRAIN Batch 11/7600 loss 14.815757 loss_att 17.884590 loss_ctc 24.645079 loss_rnnt 12.891413 lr 0.00050162 rank 3
2022-12-04 08:46:48,340 DEBUG TRAIN Batch 11/7600 loss 13.173418 loss_att 13.311321 loss_ctc 18.820665 loss_rnnt 12.392870 lr 0.00050152 rank 2
2022-12-04 08:46:48,341 DEBUG TRAIN Batch 11/7600 loss 12.512869 loss_att 15.386984 loss_ctc 22.250446 loss_rnnt 10.639701 lr 0.00050179 rank 4
2022-12-04 08:46:48,385 DEBUG TRAIN Batch 11/7600 loss 9.291917 loss_att 15.958343 loss_ctc 19.049664 loss_rnnt 6.657599 lr 0.00050169 rank 7
2022-12-04 08:48:00,208 DEBUG TRAIN Batch 11/7700 loss 13.273051 loss_att 17.989058 loss_ctc 24.412086 loss_rnnt 10.844646 lr 0.00050151 rank 6
2022-12-04 08:48:00,210 DEBUG TRAIN Batch 11/7700 loss 11.440331 loss_att 16.418322 loss_ctc 25.035988 loss_rnnt 8.631979 lr 0.00050155 rank 5
2022-12-04 08:48:00,212 DEBUG TRAIN Batch 11/7700 loss 15.815899 loss_att 20.141254 loss_ctc 30.894712 loss_rnnt 12.940317 lr 0.00050140 rank 1
2022-12-04 08:48:00,213 DEBUG TRAIN Batch 11/7700 loss 18.026186 loss_att 30.911537 loss_ctc 24.315094 loss_rnnt 14.610596 lr 0.00050143 rank 0
2022-12-04 08:48:00,214 DEBUG TRAIN Batch 11/7700 loss 9.526541 loss_att 11.687627 loss_ctc 21.904104 loss_rnnt 7.443981 lr 0.00050144 rank 7
2022-12-04 08:48:00,216 DEBUG TRAIN Batch 11/7700 loss 11.149115 loss_att 14.489206 loss_ctc 19.183987 loss_rnnt 9.409781 lr 0.00050154 rank 4
2022-12-04 08:48:00,219 DEBUG TRAIN Batch 11/7700 loss 12.732840 loss_att 14.818760 loss_ctc 17.611248 loss_rnnt 11.665202 lr 0.00050137 rank 3
2022-12-04 08:48:00,222 DEBUG TRAIN Batch 11/7700 loss 7.797697 loss_att 11.124658 loss_ctc 11.717013 loss_rnnt 6.609729 lr 0.00050127 rank 2
2022-12-04 08:49:13,845 DEBUG TRAIN Batch 11/7800 loss 11.381882 loss_att 16.353819 loss_ctc 19.485605 loss_rnnt 9.306997 lr 0.00050130 rank 5
2022-12-04 08:49:13,858 DEBUG TRAIN Batch 11/7800 loss 12.734539 loss_att 18.678131 loss_ctc 28.759848 loss_rnnt 9.409113 lr 0.00050118 rank 0
2022-12-04 08:49:13,858 DEBUG TRAIN Batch 11/7800 loss 14.215296 loss_att 19.242004 loss_ctc 25.853062 loss_rnnt 11.658252 lr 0.00050126 rank 6
2022-12-04 08:49:13,859 DEBUG TRAIN Batch 11/7800 loss 16.649075 loss_att 19.556620 loss_ctc 24.251333 loss_rnnt 15.053930 lr 0.00050102 rank 2
2022-12-04 08:49:13,860 DEBUG TRAIN Batch 11/7800 loss 14.909203 loss_att 17.286823 loss_ctc 19.078100 loss_rnnt 13.877826 lr 0.00050115 rank 1
2022-12-04 08:49:13,861 DEBUG TRAIN Batch 11/7800 loss 9.827472 loss_att 12.636557 loss_ctc 17.313154 loss_rnnt 8.267563 lr 0.00050112 rank 3
2022-12-04 08:49:13,890 DEBUG TRAIN Batch 11/7800 loss 6.658693 loss_att 9.996224 loss_ctc 10.043165 loss_rnnt 5.539924 lr 0.00050119 rank 7
2022-12-04 08:49:13,911 DEBUG TRAIN Batch 11/7800 loss 21.360874 loss_att 22.806576 loss_ctc 29.034035 loss_rnnt 20.048645 lr 0.00050129 rank 4
2022-12-04 08:50:26,052 DEBUG TRAIN Batch 11/7900 loss 10.514258 loss_att 14.040178 loss_ctc 18.095791 loss_rnnt 8.798203 lr 0.00050101 rank 6
2022-12-04 08:50:26,054 DEBUG TRAIN Batch 11/7900 loss 11.398380 loss_att 16.057896 loss_ctc 17.066238 loss_rnnt 9.710762 lr 0.00050104 rank 5
2022-12-04 08:50:26,060 DEBUG TRAIN Batch 11/7900 loss 17.436325 loss_att 18.395771 loss_ctc 23.364952 loss_rnnt 16.453953 lr 0.00050077 rank 2
2022-12-04 08:50:26,060 DEBUG TRAIN Batch 11/7900 loss 12.899247 loss_att 18.699970 loss_ctc 21.035547 loss_rnnt 10.654263 lr 0.00050104 rank 4
2022-12-04 08:50:26,062 DEBUG TRAIN Batch 11/7900 loss 20.666908 loss_att 25.221786 loss_ctc 43.131058 loss_rnnt 16.760712 lr 0.00050089 rank 1
2022-12-04 08:50:26,062 DEBUG TRAIN Batch 11/7900 loss 16.011936 loss_att 19.346798 loss_ctc 23.146301 loss_rnnt 14.393715 lr 0.00050087 rank 3
2022-12-04 08:50:26,061 DEBUG TRAIN Batch 11/7900 loss 14.631810 loss_att 20.618343 loss_ctc 23.218895 loss_rnnt 12.289558 lr 0.00050094 rank 7
2022-12-04 08:50:26,065 DEBUG TRAIN Batch 11/7900 loss 9.619907 loss_att 15.567519 loss_ctc 18.473495 loss_rnnt 7.249906 lr 0.00050093 rank 0
2022-12-04 08:51:37,285 DEBUG TRAIN Batch 11/8000 loss 10.623061 loss_att 13.147230 loss_ctc 16.538034 loss_rnnt 9.329563 lr 0.00050078 rank 4
2022-12-04 08:51:37,298 DEBUG TRAIN Batch 11/8000 loss 16.295319 loss_att 19.037418 loss_ctc 28.072582 loss_rnnt 14.176598 lr 0.00050068 rank 0
2022-12-04 08:51:37,299 DEBUG TRAIN Batch 11/8000 loss 24.161419 loss_att 26.479141 loss_ctc 35.932865 loss_rnnt 22.128347 lr 0.00050064 rank 1
2022-12-04 08:51:37,300 DEBUG TRAIN Batch 11/8000 loss 9.936680 loss_att 11.982372 loss_ctc 19.895966 loss_rnnt 8.199636 lr 0.00050069 rank 7
2022-12-04 08:51:37,300 DEBUG TRAIN Batch 11/8000 loss 6.283020 loss_att 10.804503 loss_ctc 12.756769 loss_rnnt 4.515557 lr 0.00050079 rank 5
2022-12-04 08:51:37,304 DEBUG TRAIN Batch 11/8000 loss 19.156483 loss_att 26.117477 loss_ctc 37.857719 loss_rnnt 15.270784 lr 0.00050052 rank 2
2022-12-04 08:51:37,329 DEBUG TRAIN Batch 11/8000 loss 15.295326 loss_att 18.824158 loss_ctc 24.432770 loss_rnnt 13.371233 lr 0.00050076 rank 6
2022-12-04 08:51:37,333 DEBUG TRAIN Batch 11/8000 loss 6.554841 loss_att 11.727962 loss_ctc 16.727364 loss_rnnt 4.163880 lr 0.00050062 rank 3
2022-12-04 08:52:49,713 DEBUG TRAIN Batch 11/8100 loss 14.819460 loss_att 15.783856 loss_ctc 22.819370 loss_rnnt 13.559926 lr 0.00050044 rank 7
2022-12-04 08:52:49,715 DEBUG TRAIN Batch 11/8100 loss 20.810658 loss_att 19.910131 loss_ctc 25.251852 loss_rnnt 20.398605 lr 0.00050053 rank 4
2022-12-04 08:52:49,717 DEBUG TRAIN Batch 11/8100 loss 13.236125 loss_att 15.904985 loss_ctc 24.372684 loss_rnnt 11.217478 lr 0.00050054 rank 5
2022-12-04 08:52:49,722 DEBUG TRAIN Batch 11/8100 loss 9.834230 loss_att 14.099371 loss_ctc 21.841211 loss_rnnt 7.380271 lr 0.00050037 rank 3
2022-12-04 08:52:49,723 DEBUG TRAIN Batch 11/8100 loss 13.616497 loss_att 15.030103 loss_ctc 17.290615 loss_rnnt 12.843894 lr 0.00050039 rank 1
2022-12-04 08:52:49,725 DEBUG TRAIN Batch 11/8100 loss 13.547850 loss_att 16.445354 loss_ctc 19.683887 loss_rnnt 12.150209 lr 0.00050043 rank 0
2022-12-04 08:52:49,725 DEBUG TRAIN Batch 11/8100 loss 15.873322 loss_att 23.769367 loss_ctc 28.966246 loss_rnnt 12.548389 lr 0.00050051 rank 6
2022-12-04 08:52:49,751 DEBUG TRAIN Batch 11/8100 loss 14.801622 loss_att 17.690851 loss_ctc 24.490526 loss_rnnt 12.931923 lr 0.00050027 rank 2
2022-12-04 08:54:03,021 DEBUG TRAIN Batch 11/8200 loss 12.016644 loss_att 13.919106 loss_ctc 22.034460 loss_rnnt 10.300442 lr 0.00050029 rank 5
2022-12-04 08:54:03,023 DEBUG TRAIN Batch 11/8200 loss 26.738503 loss_att 22.928663 loss_ctc 37.321625 loss_rnnt 26.089388 lr 0.00050026 rank 6
2022-12-04 08:54:03,023 DEBUG TRAIN Batch 11/8200 loss 11.369914 loss_att 13.021723 loss_ctc 16.069134 loss_rnnt 10.412990 lr 0.00050014 rank 1
2022-12-04 08:54:03,026 DEBUG TRAIN Batch 11/8200 loss 13.767124 loss_att 14.136965 loss_ctc 20.914515 loss_rnnt 12.740170 lr 0.00050002 rank 2
2022-12-04 08:54:03,026 DEBUG TRAIN Batch 11/8200 loss 8.153624 loss_att 10.695903 loss_ctc 14.744435 loss_rnnt 6.766392 lr 0.00050012 rank 3
2022-12-04 08:54:03,030 DEBUG TRAIN Batch 11/8200 loss 11.335447 loss_att 16.655220 loss_ctc 17.988434 loss_rnnt 9.384428 lr 0.00050018 rank 0
2022-12-04 08:54:03,031 DEBUG TRAIN Batch 11/8200 loss 24.672993 loss_att 32.455284 loss_ctc 53.277077 loss_rnnt 19.302654 lr 0.00050019 rank 7
2022-12-04 08:54:03,033 DEBUG TRAIN Batch 11/8200 loss 15.579678 loss_att 19.415947 loss_ctc 23.183811 loss_rnnt 13.798539 lr 0.00050028 rank 4
2022-12-04 08:55:13,990 DEBUG TRAIN Batch 11/8300 loss 9.398445 loss_att 12.493536 loss_ctc 16.758471 loss_rnnt 7.798090 lr 0.00049993 rank 0
2022-12-04 08:55:13,990 DEBUG TRAIN Batch 11/8300 loss 9.567192 loss_att 12.528327 loss_ctc 13.775000 loss_rnnt 8.413924 lr 0.00050001 rank 6
2022-12-04 08:55:13,992 DEBUG TRAIN Batch 11/8300 loss 6.194723 loss_att 11.330408 loss_ctc 14.108019 loss_rnnt 4.112480 lr 0.00049994 rank 7
2022-12-04 08:55:13,992 DEBUG TRAIN Batch 11/8300 loss 4.579436 loss_att 7.930619 loss_ctc 8.637981 loss_rnnt 3.368060 lr 0.00050004 rank 5
2022-12-04 08:55:13,994 DEBUG TRAIN Batch 11/8300 loss 17.641848 loss_att 21.521332 loss_ctc 24.204035 loss_rnnt 15.990992 lr 0.00050003 rank 4
2022-12-04 08:55:13,996 DEBUG TRAIN Batch 11/8300 loss 14.056023 loss_att 17.828270 loss_ctc 22.819683 loss_rnnt 12.133086 lr 0.00049987 rank 3
2022-12-04 08:55:14,000 DEBUG TRAIN Batch 11/8300 loss 16.389559 loss_att 15.950007 loss_ctc 24.815289 loss_rnnt 15.354038 lr 0.00049989 rank 1
2022-12-04 08:55:14,001 DEBUG TRAIN Batch 11/8300 loss 11.852856 loss_att 20.714294 loss_ctc 18.853531 loss_rnnt 9.147144 lr 0.00049977 rank 2
2022-12-04 08:56:03,750 DEBUG CV Batch 11/0 loss 2.369359 loss_att 2.041684 loss_ctc 4.223538 loss_rnnt 2.187670 history loss 2.281605 rank 3
2022-12-04 08:56:03,773 DEBUG CV Batch 11/0 loss 2.369359 loss_att 2.041684 loss_ctc 4.223538 loss_rnnt 2.187670 history loss 2.281605 rank 5
2022-12-04 08:56:03,773 DEBUG CV Batch 11/0 loss 2.369359 loss_att 2.041684 loss_ctc 4.223538 loss_rnnt 2.187670 history loss 2.281605 rank 1
2022-12-04 08:56:03,779 DEBUG CV Batch 11/0 loss 2.369359 loss_att 2.041684 loss_ctc 4.223538 loss_rnnt 2.187670 history loss 2.281605 rank 4
2022-12-04 08:56:03,782 DEBUG CV Batch 11/0 loss 2.369359 loss_att 2.041684 loss_ctc 4.223538 loss_rnnt 2.187670 history loss 2.281605 rank 2
2022-12-04 08:56:03,784 DEBUG CV Batch 11/0 loss 2.369359 loss_att 2.041684 loss_ctc 4.223538 loss_rnnt 2.187670 history loss 2.281605 rank 0
2022-12-04 08:56:03,787 DEBUG CV Batch 11/0 loss 2.369359 loss_att 2.041684 loss_ctc 4.223538 loss_rnnt 2.187670 history loss 2.281605 rank 7
2022-12-04 08:56:03,787 DEBUG CV Batch 11/0 loss 2.369359 loss_att 2.041684 loss_ctc 4.223538 loss_rnnt 2.187670 history loss 2.281605 rank 6
2022-12-04 08:56:15,094 DEBUG CV Batch 11/100 loss 6.750263 loss_att 7.512075 loss_ctc 11.749496 loss_rnnt 5.931335 history loss 3.770649 rank 1
2022-12-04 08:56:15,173 DEBUG CV Batch 11/100 loss 6.750263 loss_att 7.512075 loss_ctc 11.749496 loss_rnnt 5.931335 history loss 3.770649 rank 5
2022-12-04 08:56:15,214 DEBUG CV Batch 11/100 loss 6.750263 loss_att 7.512075 loss_ctc 11.749496 loss_rnnt 5.931335 history loss 3.770649 rank 7
2022-12-04 08:56:15,356 DEBUG CV Batch 11/100 loss 6.750263 loss_att 7.512075 loss_ctc 11.749496 loss_rnnt 5.931335 history loss 3.770649 rank 0
2022-12-04 08:56:15,378 DEBUG CV Batch 11/100 loss 6.750263 loss_att 7.512075 loss_ctc 11.749496 loss_rnnt 5.931335 history loss 3.770649 rank 2
2022-12-04 08:56:15,490 DEBUG CV Batch 11/100 loss 6.750263 loss_att 7.512075 loss_ctc 11.749496 loss_rnnt 5.931335 history loss 3.770649 rank 6
2022-12-04 08:56:15,528 DEBUG CV Batch 11/100 loss 6.750263 loss_att 7.512075 loss_ctc 11.749496 loss_rnnt 5.931335 history loss 3.770649 rank 4
2022-12-04 08:56:15,555 DEBUG CV Batch 11/100 loss 6.750263 loss_att 7.512075 loss_ctc 11.749496 loss_rnnt 5.931335 history loss 3.770649 rank 3
2022-12-04 08:56:28,797 DEBUG CV Batch 11/200 loss 10.747873 loss_att 12.911531 loss_ctc 14.064405 loss_rnnt 9.872937 history loss 4.457296 rank 5
2022-12-04 08:56:28,907 DEBUG CV Batch 11/200 loss 10.747873 loss_att 12.911531 loss_ctc 14.064405 loss_rnnt 9.872937 history loss 4.457296 rank 2
2022-12-04 08:56:28,989 DEBUG CV Batch 11/200 loss 10.747873 loss_att 12.911531 loss_ctc 14.064405 loss_rnnt 9.872937 history loss 4.457296 rank 1
2022-12-04 08:56:29,052 DEBUG CV Batch 11/200 loss 10.747873 loss_att 12.911531 loss_ctc 14.064405 loss_rnnt 9.872937 history loss 4.457296 rank 7
2022-12-04 08:56:29,066 DEBUG CV Batch 11/200 loss 10.747873 loss_att 12.911531 loss_ctc 14.064405 loss_rnnt 9.872937 history loss 4.457296 rank 4
2022-12-04 08:56:29,070 DEBUG CV Batch 11/200 loss 10.747873 loss_att 12.911531 loss_ctc 14.064405 loss_rnnt 9.872937 history loss 4.457296 rank 0
2022-12-04 08:56:29,247 DEBUG CV Batch 11/200 loss 10.747873 loss_att 12.911531 loss_ctc 14.064405 loss_rnnt 9.872937 history loss 4.457296 rank 6
2022-12-04 08:56:29,624 DEBUG CV Batch 11/200 loss 10.747873 loss_att 12.911531 loss_ctc 14.064405 loss_rnnt 9.872937 history loss 4.457296 rank 3
2022-12-04 08:56:40,697 DEBUG CV Batch 11/300 loss 3.534727 loss_att 4.775406 loss_ctc 6.949728 loss_rnnt 2.831257 history loss 4.554234 rank 5
2022-12-04 08:56:40,930 DEBUG CV Batch 11/300 loss 3.534727 loss_att 4.775406 loss_ctc 6.949728 loss_rnnt 2.831257 history loss 4.554234 rank 2
2022-12-04 08:56:40,932 DEBUG CV Batch 11/300 loss 3.534727 loss_att 4.775406 loss_ctc 6.949728 loss_rnnt 2.831257 history loss 4.554234 rank 1
2022-12-04 08:56:41,111 DEBUG CV Batch 11/300 loss 3.534727 loss_att 4.775406 loss_ctc 6.949728 loss_rnnt 2.831257 history loss 4.554234 rank 4
2022-12-04 08:56:41,117 DEBUG CV Batch 11/300 loss 3.534727 loss_att 4.775406 loss_ctc 6.949728 loss_rnnt 2.831257 history loss 4.554234 rank 7
2022-12-04 08:56:41,502 DEBUG CV Batch 11/300 loss 3.534727 loss_att 4.775406 loss_ctc 6.949728 loss_rnnt 2.831257 history loss 4.554234 rank 0
2022-12-04 08:56:41,596 DEBUG CV Batch 11/300 loss 3.534727 loss_att 4.775406 loss_ctc 6.949728 loss_rnnt 2.831257 history loss 4.554234 rank 6
2022-12-04 08:56:42,092 DEBUG CV Batch 11/300 loss 3.534727 loss_att 4.775406 loss_ctc 6.949728 loss_rnnt 2.831257 history loss 4.554234 rank 3
2022-12-04 08:56:52,665 DEBUG CV Batch 11/400 loss 13.335220 loss_att 53.666786 loss_ctc 18.020771 loss_rnnt 4.644166 history loss 5.399888 rank 5
2022-12-04 08:56:53,097 DEBUG CV Batch 11/400 loss 13.335220 loss_att 53.666786 loss_ctc 18.020771 loss_rnnt 4.644166 history loss 5.399888 rank 2
2022-12-04 08:56:53,236 DEBUG CV Batch 11/400 loss 13.335220 loss_att 53.666786 loss_ctc 18.020771 loss_rnnt 4.644166 history loss 5.399888 rank 7
2022-12-04 08:56:53,286 DEBUG CV Batch 11/400 loss 13.335220 loss_att 53.666786 loss_ctc 18.020771 loss_rnnt 4.644166 history loss 5.399888 rank 4
2022-12-04 08:56:53,489 DEBUG CV Batch 11/400 loss 13.335220 loss_att 53.666786 loss_ctc 18.020771 loss_rnnt 4.644166 history loss 5.399888 rank 1
2022-12-04 08:56:53,849 DEBUG CV Batch 11/400 loss 13.335220 loss_att 53.666786 loss_ctc 18.020771 loss_rnnt 4.644166 history loss 5.399888 rank 6
2022-12-04 08:56:53,882 DEBUG CV Batch 11/400 loss 13.335220 loss_att 53.666786 loss_ctc 18.020771 loss_rnnt 4.644166 history loss 5.399888 rank 0
2022-12-04 08:56:54,549 DEBUG CV Batch 11/400 loss 13.335220 loss_att 53.666786 loss_ctc 18.020771 loss_rnnt 4.644166 history loss 5.399888 rank 3
2022-12-04 08:57:03,053 DEBUG CV Batch 11/500 loss 8.240406 loss_att 9.026489 loss_ctc 11.225907 loss_rnnt 7.685123 history loss 6.121345 rank 5
2022-12-04 08:57:03,559 DEBUG CV Batch 11/500 loss 8.240406 loss_att 9.026489 loss_ctc 11.225907 loss_rnnt 7.685123 history loss 6.121345 rank 2
2022-12-04 08:57:03,684 DEBUG CV Batch 11/500 loss 8.240406 loss_att 9.026489 loss_ctc 11.225907 loss_rnnt 7.685123 history loss 6.121345 rank 4
2022-12-04 08:57:03,753 DEBUG CV Batch 11/500 loss 8.240406 loss_att 9.026489 loss_ctc 11.225907 loss_rnnt 7.685123 history loss 6.121345 rank 1
2022-12-04 08:57:04,150 DEBUG CV Batch 11/500 loss 8.240406 loss_att 9.026489 loss_ctc 11.225907 loss_rnnt 7.685123 history loss 6.121345 rank 7
2022-12-04 08:57:04,530 DEBUG CV Batch 11/500 loss 8.240406 loss_att 9.026489 loss_ctc 11.225907 loss_rnnt 7.685123 history loss 6.121345 rank 6
2022-12-04 08:57:04,700 DEBUG CV Batch 11/500 loss 8.240406 loss_att 9.026489 loss_ctc 11.225907 loss_rnnt 7.685123 history loss 6.121345 rank 0
2022-12-04 08:57:05,349 DEBUG CV Batch 11/500 loss 8.240406 loss_att 9.026489 loss_ctc 11.225907 loss_rnnt 7.685123 history loss 6.121345 rank 3
2022-12-04 08:57:15,169 DEBUG CV Batch 11/600 loss 5.710370 loss_att 6.726752 loss_ctc 8.930423 loss_rnnt 5.077753 history loss 7.037876 rank 5
2022-12-04 08:57:15,747 DEBUG CV Batch 11/600 loss 5.710370 loss_att 6.726752 loss_ctc 8.930423 loss_rnnt 5.077753 history loss 7.037876 rank 4
2022-12-04 08:57:15,869 DEBUG CV Batch 11/600 loss 5.710370 loss_att 6.726752 loss_ctc 8.930423 loss_rnnt 5.077753 history loss 7.037876 rank 2
2022-12-04 08:57:16,158 DEBUG CV Batch 11/600 loss 5.710370 loss_att 6.726752 loss_ctc 8.930423 loss_rnnt 5.077753 history loss 7.037876 rank 1
2022-12-04 08:57:16,364 DEBUG CV Batch 11/600 loss 5.710370 loss_att 6.726752 loss_ctc 8.930423 loss_rnnt 5.077753 history loss 7.037876 rank 7
2022-12-04 08:57:16,872 DEBUG CV Batch 11/600 loss 5.710370 loss_att 6.726752 loss_ctc 8.930423 loss_rnnt 5.077753 history loss 7.037876 rank 6
2022-12-04 08:57:17,105 DEBUG CV Batch 11/600 loss 5.710370 loss_att 6.726752 loss_ctc 8.930423 loss_rnnt 5.077753 history loss 7.037876 rank 0
2022-12-04 08:57:18,038 DEBUG CV Batch 11/600 loss 5.710370 loss_att 6.726752 loss_ctc 8.930423 loss_rnnt 5.077753 history loss 7.037876 rank 3
2022-12-04 08:57:26,835 DEBUG CV Batch 11/700 loss 10.126434 loss_att 27.407228 loss_ctc 18.558607 loss_rnnt 5.545985 history loss 7.629527 rank 5
2022-12-04 08:57:27,022 DEBUG CV Batch 11/700 loss 10.126434 loss_att 27.407228 loss_ctc 18.558607 loss_rnnt 5.545985 history loss 7.629527 rank 4
2022-12-04 08:57:27,198 DEBUG CV Batch 11/700 loss 10.126434 loss_att 27.407228 loss_ctc 18.558607 loss_rnnt 5.545985 history loss 7.629527 rank 2
2022-12-04 08:57:27,253 DEBUG CV Batch 11/700 loss 10.126434 loss_att 27.407228 loss_ctc 18.558607 loss_rnnt 5.545985 history loss 7.629527 rank 1
2022-12-04 08:57:27,753 DEBUG CV Batch 11/700 loss 10.126434 loss_att 27.407228 loss_ctc 18.558607 loss_rnnt 5.545985 history loss 7.629527 rank 7
2022-12-04 08:57:28,465 DEBUG CV Batch 11/700 loss 10.126434 loss_att 27.407228 loss_ctc 18.558607 loss_rnnt 5.545985 history loss 7.629527 rank 6
2022-12-04 08:57:28,824 DEBUG CV Batch 11/700 loss 10.126434 loss_att 27.407228 loss_ctc 18.558607 loss_rnnt 5.545985 history loss 7.629527 rank 0
2022-12-04 08:57:29,732 DEBUG CV Batch 11/700 loss 10.126434 loss_att 27.407228 loss_ctc 18.558607 loss_rnnt 5.545985 history loss 7.629527 rank 3
2022-12-04 08:57:38,116 DEBUG CV Batch 11/800 loss 10.153926 loss_att 9.921447 loss_ctc 16.916643 loss_rnnt 9.298725 history loss 7.104766 rank 1
2022-12-04 08:57:38,179 DEBUG CV Batch 11/800 loss 10.153926 loss_att 9.921447 loss_ctc 16.916643 loss_rnnt 9.298725 history loss 7.104766 rank 4
2022-12-04 08:57:38,587 DEBUG CV Batch 11/800 loss 10.153926 loss_att 9.921447 loss_ctc 16.916643 loss_rnnt 9.298725 history loss 7.104766 rank 2
2022-12-04 08:57:38,972 DEBUG CV Batch 11/800 loss 10.153926 loss_att 9.921447 loss_ctc 16.916643 loss_rnnt 9.298725 history loss 7.104766 rank 5
2022-12-04 08:57:39,279 DEBUG CV Batch 11/800 loss 10.153926 loss_att 9.921447 loss_ctc 16.916643 loss_rnnt 9.298725 history loss 7.104766 rank 7
2022-12-04 08:57:39,970 DEBUG CV Batch 11/800 loss 10.153926 loss_att 9.921447 loss_ctc 16.916643 loss_rnnt 9.298725 history loss 7.104766 rank 6
2022-12-04 08:57:40,316 DEBUG CV Batch 11/800 loss 10.153926 loss_att 9.921447 loss_ctc 16.916643 loss_rnnt 9.298725 history loss 7.104766 rank 0
2022-12-04 08:57:41,889 DEBUG CV Batch 11/800 loss 10.153926 loss_att 9.921447 loss_ctc 16.916643 loss_rnnt 9.298725 history loss 7.104766 rank 3
2022-12-04 08:57:51,376 DEBUG CV Batch 11/900 loss 11.820114 loss_att 18.418701 loss_ctc 22.064209 loss_rnnt 9.134518 history loss 6.939071 rank 1
2022-12-04 08:57:51,552 DEBUG CV Batch 11/900 loss 11.820114 loss_att 18.418701 loss_ctc 22.064209 loss_rnnt 9.134518 history loss 6.939071 rank 4
2022-12-04 08:57:52,232 DEBUG CV Batch 11/900 loss 11.820114 loss_att 18.418701 loss_ctc 22.064209 loss_rnnt 9.134518 history loss 6.939071 rank 2
2022-12-04 08:57:52,828 DEBUG CV Batch 11/900 loss 11.820114 loss_att 18.418701 loss_ctc 22.064209 loss_rnnt 9.134518 history loss 6.939071 rank 5
2022-12-04 08:57:53,108 DEBUG CV Batch 11/900 loss 11.820114 loss_att 18.418701 loss_ctc 22.064209 loss_rnnt 9.134518 history loss 6.939071 rank 7
2022-12-04 08:57:53,596 DEBUG CV Batch 11/900 loss 11.820114 loss_att 18.418701 loss_ctc 22.064209 loss_rnnt 9.134518 history loss 6.939071 rank 6
2022-12-04 08:57:54,092 DEBUG CV Batch 11/900 loss 11.820114 loss_att 18.418701 loss_ctc 22.064209 loss_rnnt 9.134518 history loss 6.939071 rank 0
2022-12-04 08:57:56,154 DEBUG CV Batch 11/900 loss 11.820114 loss_att 18.418701 loss_ctc 22.064209 loss_rnnt 9.134518 history loss 6.939071 rank 3
2022-12-04 08:58:03,447 DEBUG CV Batch 11/1000 loss 3.919305 loss_att 5.150342 loss_ctc 5.709843 loss_rnnt 3.434359 history loss 6.720379 rank 1
2022-12-04 08:58:03,772 DEBUG CV Batch 11/1000 loss 3.919305 loss_att 5.150342 loss_ctc 5.709843 loss_rnnt 3.434359 history loss 6.720379 rank 4
2022-12-04 08:58:04,756 DEBUG CV Batch 11/1000 loss 3.919305 loss_att 5.150342 loss_ctc 5.709843 loss_rnnt 3.434359 history loss 6.720379 rank 2
2022-12-04 08:58:04,991 DEBUG CV Batch 11/1000 loss 3.919305 loss_att 5.150342 loss_ctc 5.709843 loss_rnnt 3.434359 history loss 6.720379 rank 5
2022-12-04 08:58:05,608 DEBUG CV Batch 11/1000 loss 3.919305 loss_att 5.150342 loss_ctc 5.709843 loss_rnnt 3.434359 history loss 6.720379 rank 7
2022-12-04 08:58:06,178 DEBUG CV Batch 11/1000 loss 3.919305 loss_att 5.150342 loss_ctc 5.709843 loss_rnnt 3.434359 history loss 6.720379 rank 6
2022-12-04 08:58:06,846 DEBUG CV Batch 11/1000 loss 3.919305 loss_att 5.150342 loss_ctc 5.709843 loss_rnnt 3.434359 history loss 6.720379 rank 0
2022-12-04 08:58:09,040 DEBUG CV Batch 11/1000 loss 3.919305 loss_att 5.150342 loss_ctc 5.709843 loss_rnnt 3.434359 history loss 6.720379 rank 3
2022-12-04 08:58:15,515 DEBUG CV Batch 11/1100 loss 4.956091 loss_att 4.899141 loss_ctc 9.028297 loss_rnnt 4.424520 history loss 6.689400 rank 1
2022-12-04 08:58:15,860 DEBUG CV Batch 11/1100 loss 4.956091 loss_att 4.899141 loss_ctc 9.028297 loss_rnnt 4.424520 history loss 6.689400 rank 4
2022-12-04 08:58:16,948 DEBUG CV Batch 11/1100 loss 4.956091 loss_att 4.899141 loss_ctc 9.028297 loss_rnnt 4.424520 history loss 6.689400 rank 5
2022-12-04 08:58:17,137 DEBUG CV Batch 11/1100 loss 4.956091 loss_att 4.899141 loss_ctc 9.028297 loss_rnnt 4.424520 history loss 6.689400 rank 2
2022-12-04 08:58:17,584 DEBUG CV Batch 11/1100 loss 4.956091 loss_att 4.899141 loss_ctc 9.028297 loss_rnnt 4.424520 history loss 6.689400 rank 7
2022-12-04 08:58:18,441 DEBUG CV Batch 11/1100 loss 4.956091 loss_att 4.899141 loss_ctc 9.028297 loss_rnnt 4.424520 history loss 6.689400 rank 6
2022-12-04 08:58:19,373 DEBUG CV Batch 11/1100 loss 4.956091 loss_att 4.899141 loss_ctc 9.028297 loss_rnnt 4.424520 history loss 6.689400 rank 0
2022-12-04 08:58:21,497 DEBUG CV Batch 11/1100 loss 4.956091 loss_att 4.899141 loss_ctc 9.028297 loss_rnnt 4.424520 history loss 6.689400 rank 3
2022-12-04 08:58:25,803 DEBUG CV Batch 11/1200 loss 9.524830 loss_att 9.674036 loss_ctc 12.255528 loss_rnnt 9.130896 history loss 6.996853 rank 1
2022-12-04 08:58:26,671 DEBUG CV Batch 11/1200 loss 9.524830 loss_att 9.674036 loss_ctc 12.255528 loss_rnnt 9.130896 history loss 6.996853 rank 4
2022-12-04 08:58:27,450 DEBUG CV Batch 11/1200 loss 9.524830 loss_att 9.674036 loss_ctc 12.255528 loss_rnnt 9.130896 history loss 6.996853 rank 5
2022-12-04 08:58:28,129 DEBUG CV Batch 11/1200 loss 9.524830 loss_att 9.674036 loss_ctc 12.255528 loss_rnnt 9.130896 history loss 6.996853 rank 7
2022-12-04 08:58:28,233 DEBUG CV Batch 11/1200 loss 9.524830 loss_att 9.674036 loss_ctc 12.255528 loss_rnnt 9.130896 history loss 6.996853 rank 2
2022-12-04 08:58:29,324 DEBUG CV Batch 11/1200 loss 9.524830 loss_att 9.674036 loss_ctc 12.255528 loss_rnnt 9.130896 history loss 6.996853 rank 6
2022-12-04 08:58:30,419 DEBUG CV Batch 11/1200 loss 9.524830 loss_att 9.674036 loss_ctc 12.255528 loss_rnnt 9.130896 history loss 6.996853 rank 0
2022-12-04 08:58:32,623 DEBUG CV Batch 11/1200 loss 9.524830 loss_att 9.674036 loss_ctc 12.255528 loss_rnnt 9.130896 history loss 6.996853 rank 3
2022-12-04 08:58:37,858 DEBUG CV Batch 11/1300 loss 5.085188 loss_att 5.112446 loss_ctc 9.192228 loss_rnnt 4.532131 history loss 7.306908 rank 1
2022-12-04 08:58:38,685 DEBUG CV Batch 11/1300 loss 5.085188 loss_att 5.112446 loss_ctc 9.192228 loss_rnnt 4.532131 history loss 7.306908 rank 4
2022-12-04 08:58:39,689 DEBUG CV Batch 11/1300 loss 5.085188 loss_att 5.112446 loss_ctc 9.192228 loss_rnnt 4.532131 history loss 7.306908 rank 5
2022-12-04 08:58:40,545 DEBUG CV Batch 11/1300 loss 5.085188 loss_att 5.112446 loss_ctc 9.192228 loss_rnnt 4.532131 history loss 7.306908 rank 7
2022-12-04 08:58:40,617 DEBUG CV Batch 11/1300 loss 5.085188 loss_att 5.112446 loss_ctc 9.192228 loss_rnnt 4.532131 history loss 7.306908 rank 2
2022-12-04 08:58:41,529 DEBUG CV Batch 11/1300 loss 5.085188 loss_att 5.112446 loss_ctc 9.192228 loss_rnnt 4.532131 history loss 7.306908 rank 6
2022-12-04 08:58:42,916 DEBUG CV Batch 11/1300 loss 5.085188 loss_att 5.112446 loss_ctc 9.192228 loss_rnnt 4.532131 history loss 7.306908 rank 0
2022-12-04 08:58:45,042 DEBUG CV Batch 11/1300 loss 5.085188 loss_att 5.112446 loss_ctc 9.192228 loss_rnnt 4.532131 history loss 7.306908 rank 3
2022-12-04 08:58:48,851 DEBUG CV Batch 11/1400 loss 6.390841 loss_att 16.150072 loss_ctc 10.802757 loss_rnnt 3.850739 history loss 7.598337 rank 1
2022-12-04 08:58:49,884 DEBUG CV Batch 11/1400 loss 6.390841 loss_att 16.150072 loss_ctc 10.802757 loss_rnnt 3.850739 history loss 7.598337 rank 4
2022-12-04 08:58:51,473 DEBUG CV Batch 11/1400 loss 6.390841 loss_att 16.150072 loss_ctc 10.802757 loss_rnnt 3.850739 history loss 7.598337 rank 5
2022-12-04 08:58:51,802 DEBUG CV Batch 11/1400 loss 6.390841 loss_att 16.150072 loss_ctc 10.802757 loss_rnnt 3.850739 history loss 7.598337 rank 7
2022-12-04 08:58:52,203 DEBUG CV Batch 11/1400 loss 6.390841 loss_att 16.150072 loss_ctc 10.802757 loss_rnnt 3.850739 history loss 7.598337 rank 2
2022-12-04 08:58:53,086 DEBUG CV Batch 11/1400 loss 6.390841 loss_att 16.150072 loss_ctc 10.802757 loss_rnnt 3.850739 history loss 7.598337 rank 6
2022-12-04 08:58:54,779 DEBUG CV Batch 11/1400 loss 6.390841 loss_att 16.150072 loss_ctc 10.802757 loss_rnnt 3.850739 history loss 7.598337 rank 0
2022-12-04 08:58:56,694 DEBUG CV Batch 11/1400 loss 6.390841 loss_att 16.150072 loss_ctc 10.802757 loss_rnnt 3.850739 history loss 7.598337 rank 3
2022-12-04 08:59:00,235 DEBUG CV Batch 11/1500 loss 7.917075 loss_att 9.788494 loss_ctc 8.867620 loss_rnnt 7.416052 history loss 7.439205 rank 1
2022-12-04 08:59:01,070 DEBUG CV Batch 11/1500 loss 7.917075 loss_att 9.788494 loss_ctc 8.867620 loss_rnnt 7.416052 history loss 7.439205 rank 4
2022-12-04 08:59:03,714 DEBUG CV Batch 11/1500 loss 7.917075 loss_att 9.788494 loss_ctc 8.867620 loss_rnnt 7.416052 history loss 7.439205 rank 2
2022-12-04 08:59:03,974 DEBUG CV Batch 11/1500 loss 7.917075 loss_att 9.788494 loss_ctc 8.867620 loss_rnnt 7.416052 history loss 7.439205 rank 7
2022-12-04 08:59:04,497 DEBUG CV Batch 11/1500 loss 7.917075 loss_att 9.788494 loss_ctc 8.867620 loss_rnnt 7.416052 history loss 7.439205 rank 5
2022-12-04 08:59:04,879 DEBUG CV Batch 11/1500 loss 7.917075 loss_att 9.788494 loss_ctc 8.867620 loss_rnnt 7.416052 history loss 7.439205 rank 6
2022-12-04 08:59:06,629 DEBUG CV Batch 11/1500 loss 7.917075 loss_att 9.788494 loss_ctc 8.867620 loss_rnnt 7.416052 history loss 7.439205 rank 0
2022-12-04 08:59:08,975 DEBUG CV Batch 11/1500 loss 7.917075 loss_att 9.788494 loss_ctc 8.867620 loss_rnnt 7.416052 history loss 7.439205 rank 3
2022-12-04 08:59:13,429 DEBUG CV Batch 11/1600 loss 7.028812 loss_att 11.877132 loss_ctc 12.754997 loss_rnnt 5.295657 history loss 7.383345 rank 1
2022-12-04 08:59:14,354 DEBUG CV Batch 11/1600 loss 7.028812 loss_att 11.877132 loss_ctc 12.754997 loss_rnnt 5.295657 history loss 7.383345 rank 4
2022-12-04 08:59:17,196 DEBUG CV Batch 11/1600 loss 7.028812 loss_att 11.877132 loss_ctc 12.754997 loss_rnnt 5.295657 history loss 7.383345 rank 2
2022-12-04 08:59:17,536 DEBUG CV Batch 11/1600 loss 7.028812 loss_att 11.877132 loss_ctc 12.754997 loss_rnnt 5.295657 history loss 7.383345 rank 7
2022-12-04 08:59:18,253 DEBUG CV Batch 11/1600 loss 7.028812 loss_att 11.877132 loss_ctc 12.754997 loss_rnnt 5.295657 history loss 7.383345 rank 5
2022-12-04 08:59:18,305 DEBUG CV Batch 11/1600 loss 7.028812 loss_att 11.877132 loss_ctc 12.754997 loss_rnnt 5.295657 history loss 7.383345 rank 6
2022-12-04 08:59:20,166 DEBUG CV Batch 11/1600 loss 7.028812 loss_att 11.877132 loss_ctc 12.754997 loss_rnnt 5.295657 history loss 7.383345 rank 0
2022-12-04 08:59:22,832 DEBUG CV Batch 11/1600 loss 7.028812 loss_att 11.877132 loss_ctc 12.754997 loss_rnnt 5.295657 history loss 7.383345 rank 3
2022-12-04 08:59:26,118 DEBUG CV Batch 11/1700 loss 10.300310 loss_att 10.627247 loss_ctc 18.152197 loss_rnnt 9.188005 history loss 7.299857 rank 1
2022-12-04 08:59:27,100 DEBUG CV Batch 11/1700 loss 10.300310 loss_att 10.627247 loss_ctc 18.152197 loss_rnnt 9.188005 history loss 7.299857 rank 4
2022-12-04 08:59:30,308 DEBUG CV Batch 11/1700 loss 10.300310 loss_att 10.627247 loss_ctc 18.152197 loss_rnnt 9.188005 history loss 7.299857 rank 7
2022-12-04 08:59:30,344 DEBUG CV Batch 11/1700 loss 10.300310 loss_att 10.627247 loss_ctc 18.152197 loss_rnnt 9.188005 history loss 7.299857 rank 2
2022-12-04 08:59:30,844 DEBUG CV Batch 11/1700 loss 10.300310 loss_att 10.627247 loss_ctc 18.152197 loss_rnnt 9.188005 history loss 7.299857 rank 6
2022-12-04 08:59:30,878 DEBUG CV Batch 11/1700 loss 10.300310 loss_att 10.627247 loss_ctc 18.152197 loss_rnnt 9.188005 history loss 7.299857 rank 5
2022-12-04 08:59:32,875 DEBUG CV Batch 11/1700 loss 10.300310 loss_att 10.627247 loss_ctc 18.152197 loss_rnnt 9.188005 history loss 7.299857 rank 0
2022-12-04 08:59:35,257 DEBUG CV Batch 11/1700 loss 10.300310 loss_att 10.627247 loss_ctc 18.152197 loss_rnnt 9.188005 history loss 7.299857 rank 3
2022-12-04 08:59:35,546 INFO Epoch 11 CV info cv_loss 7.271049347612051
2022-12-04 08:59:35,546 INFO Epoch 12 TRAIN info lr 0.0004998076110974647
2022-12-04 08:59:35,548 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 08:59:36,462 INFO Epoch 11 CV info cv_loss 7.271049347612051
2022-12-04 08:59:36,463 INFO Epoch 12 TRAIN info lr 0.0004999525067676785
2022-12-04 08:59:36,468 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 08:59:39,680 INFO Epoch 11 CV info cv_loss 7.271049347612051
2022-12-04 08:59:39,680 INFO Epoch 12 TRAIN info lr 0.0004996353991893491
2022-12-04 08:59:39,685 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 08:59:39,785 INFO Epoch 11 CV info cv_loss 7.271049347612051
2022-12-04 08:59:39,786 INFO Epoch 12 TRAIN info lr 0.0004997826418159372
2022-12-04 08:59:39,791 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 08:59:40,024 INFO Epoch 11 CV info cv_loss 7.271049347612051
2022-12-04 08:59:40,025 INFO Epoch 12 TRAIN info lr 0.000499897531507985
2022-12-04 08:59:40,027 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 08:59:40,254 INFO Epoch 11 CV info cv_loss 7.271049347612051
2022-12-04 08:59:40,255 INFO Epoch 12 TRAIN info lr 0.0004999225180140964
2022-12-04 08:59:40,260 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 08:59:42,173 INFO Epoch 11 CV info cv_loss 7.271049347612051
2022-12-04 08:59:42,174 INFO Checkpoint: save to checkpoint exp/1202_encoder_bias_30_0.1/11.pt
2022-12-04 08:59:42,794 INFO Epoch 12 TRAIN info lr 0.0004998600587725735
2022-12-04 08:59:42,799 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 08:59:44,902 INFO Epoch 11 CV info cv_loss 7.271049347612051
2022-12-04 08:59:44,902 INFO Epoch 12 TRAIN info lr 0.0004997377065380372
2022-12-04 08:59:44,904 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-04 09:00:43,611 DEBUG TRAIN Batch 12/0 loss 7.310971 loss_att 8.101341 loss_ctc 12.029437 loss_rnnt 6.523768 lr 0.00049990 rank 6
2022-12-04 09:00:43,616 DEBUG TRAIN Batch 12/0 loss 9.559606 loss_att 10.014125 loss_ctc 13.326483 loss_rnnt 8.966451 lr 0.00049986 rank 0
2022-12-04 09:00:43,617 DEBUG TRAIN Batch 12/0 loss 14.351180 loss_att 12.424652 loss_ctc 19.027174 loss_rnnt 14.113020 lr 0.00049981 rank 1
2022-12-04 09:00:43,617 DEBUG TRAIN Batch 12/0 loss 8.529791 loss_att 8.360711 loss_ctc 12.826700 loss_rnnt 7.990686 lr 0.00049978 rank 7
2022-12-04 09:00:43,648 DEBUG TRAIN Batch 12/0 loss 12.722984 loss_att 12.988049 loss_ctc 17.343803 loss_rnnt 12.053862 lr 0.00049963 rank 2
2022-12-04 09:00:43,657 DEBUG TRAIN Batch 12/0 loss 13.749609 loss_att 13.355391 loss_ctc 18.279953 loss_rnnt 13.224406 lr 0.00049992 rank 5
2022-12-04 09:00:43,657 DEBUG TRAIN Batch 12/0 loss 8.199927 loss_att 8.971354 loss_ctc 11.047229 loss_rnnt 7.666001 lr 0.00049974 rank 3
2022-12-04 09:00:43,657 DEBUG TRAIN Batch 12/0 loss 4.476886 loss_att 4.770232 loss_ctc 5.681902 loss_rnnt 4.257548 lr 0.00049995 rank 4
2022-12-04 09:01:54,593 DEBUG TRAIN Batch 12/100 loss 6.199883 loss_att 8.666802 loss_ctc 11.254612 loss_rnnt 5.032535 lr 0.00049961 rank 0
2022-12-04 09:01:54,593 DEBUG TRAIN Batch 12/100 loss 12.479280 loss_att 18.982918 loss_ctc 26.329578 loss_rnnt 9.331844 lr 0.00049967 rank 5
2022-12-04 09:01:54,594 DEBUG TRAIN Batch 12/100 loss 15.586155 loss_att 19.679205 loss_ctc 22.360241 loss_rnnt 13.864333 lr 0.00049965 rank 6
2022-12-04 09:01:54,596 DEBUG TRAIN Batch 12/100 loss 11.090504 loss_att 16.010708 loss_ctc 16.843491 loss_rnnt 9.339397 lr 0.00049956 rank 1
2022-12-04 09:01:54,597 DEBUG TRAIN Batch 12/100 loss 6.469752 loss_att 10.212543 loss_ctc 13.745219 loss_rnnt 4.751132 lr 0.00049949 rank 3
2022-12-04 09:01:54,603 DEBUG TRAIN Batch 12/100 loss 8.300577 loss_att 13.451387 loss_ctc 17.232769 loss_rnnt 6.079455 lr 0.00049938 rank 2
2022-12-04 09:01:54,606 DEBUG TRAIN Batch 12/100 loss 12.543606 loss_att 14.919203 loss_ctc 16.055836 loss_rnnt 11.600189 lr 0.00049970 rank 4
2022-12-04 09:01:54,608 DEBUG TRAIN Batch 12/100 loss 28.897802 loss_att 32.680321 loss_ctc 50.594208 loss_rnnt 25.248444 lr 0.00049953 rank 7
2022-12-04 09:03:06,331 DEBUG TRAIN Batch 12/200 loss 6.432267 loss_att 8.445510 loss_ctc 9.145760 loss_rnnt 5.667819 lr 0.00049940 rank 6
2022-12-04 09:03:06,333 DEBUG TRAIN Batch 12/200 loss 9.383413 loss_att 12.125925 loss_ctc 15.205409 loss_rnnt 8.058645 lr 0.00049936 rank 0
2022-12-04 09:03:06,338 DEBUG TRAIN Batch 12/200 loss 23.982708 loss_att 29.017876 loss_ctc 39.801273 loss_rnnt 20.866531 lr 0.00049931 rank 1
2022-12-04 09:03:06,339 DEBUG TRAIN Batch 12/200 loss 6.087701 loss_att 9.329829 loss_ctc 10.729167 loss_rnnt 4.820414 lr 0.00049924 rank 3
2022-12-04 09:03:06,339 DEBUG TRAIN Batch 12/200 loss 12.554264 loss_att 15.975098 loss_ctc 17.567429 loss_rnnt 11.201675 lr 0.00049942 rank 5
2022-12-04 09:03:06,341 DEBUG TRAIN Batch 12/200 loss 9.100349 loss_att 15.493685 loss_ctc 14.020676 loss_rnnt 7.165639 lr 0.00049928 rank 7
2022-12-04 09:03:06,348 DEBUG TRAIN Batch 12/200 loss 13.520419 loss_att 15.087845 loss_ctc 21.032156 loss_rnnt 12.205368 lr 0.00049945 rank 4
2022-12-04 09:03:06,387 DEBUG TRAIN Batch 12/200 loss 8.197800 loss_att 10.997303 loss_ctc 13.433677 loss_rnnt 6.939782 lr 0.00049913 rank 2
2022-12-04 09:04:18,871 DEBUG TRAIN Batch 12/300 loss 8.531998 loss_att 9.865759 loss_ctc 12.618057 loss_rnnt 7.720437 lr 0.00049917 rank 5
2022-12-04 09:04:18,880 DEBUG TRAIN Batch 12/300 loss 19.356960 loss_att 22.469877 loss_ctc 33.977463 loss_rnnt 16.784975 lr 0.00049911 rank 0
2022-12-04 09:04:18,885 DEBUG TRAIN Batch 12/300 loss 16.324699 loss_att 19.803946 loss_ctc 22.387342 loss_rnnt 14.820498 lr 0.00049903 rank 7
2022-12-04 09:04:18,886 DEBUG TRAIN Batch 12/300 loss 18.226267 loss_att 25.245356 loss_ctc 33.902786 loss_rnnt 14.732246 lr 0.00049915 rank 6
2022-12-04 09:04:18,891 DEBUG TRAIN Batch 12/300 loss 16.853489 loss_att 17.832886 loss_ctc 23.889517 loss_rnnt 15.719473 lr 0.00049889 rank 2
2022-12-04 09:04:18,893 DEBUG TRAIN Batch 12/300 loss 8.460273 loss_att 10.887412 loss_ctc 14.185292 loss_rnnt 7.211509 lr 0.00049920 rank 4
2022-12-04 09:04:18,899 DEBUG TRAIN Batch 12/300 loss 9.112498 loss_att 13.671419 loss_ctc 17.147270 loss_rnnt 7.129411 lr 0.00049899 rank 3
2022-12-04 09:04:18,933 DEBUG TRAIN Batch 12/300 loss 9.916120 loss_att 14.111429 loss_ctc 17.034721 loss_rnnt 8.127911 lr 0.00049906 rank 1
2022-12-04 09:05:32,091 DEBUG TRAIN Batch 12/400 loss 9.330501 loss_att 13.207190 loss_ctc 15.407322 loss_rnnt 7.744920 lr 0.00049881 rank 1
2022-12-04 09:05:32,094 DEBUG TRAIN Batch 12/400 loss 15.351027 loss_att 19.477320 loss_ctc 22.650660 loss_rnnt 13.552483 lr 0.00049892 rank 5
2022-12-04 09:05:32,095 DEBUG TRAIN Batch 12/400 loss 23.111132 loss_att 24.213711 loss_ctc 30.695183 loss_rnnt 21.879408 lr 0.00049878 rank 7
2022-12-04 09:05:32,096 DEBUG TRAIN Batch 12/400 loss 8.046927 loss_att 10.827888 loss_ctc 13.340708 loss_rnnt 6.784897 lr 0.00049890 rank 6
2022-12-04 09:05:32,096 DEBUG TRAIN Batch 12/400 loss 20.919703 loss_att 24.230816 loss_ctc 31.940649 loss_rnnt 18.788019 lr 0.00049886 rank 0
2022-12-04 09:05:32,097 DEBUG TRAIN Batch 12/400 loss 5.605405 loss_att 9.454840 loss_ctc 12.538301 loss_rnnt 3.911131 lr 0.00049874 rank 3
2022-12-04 09:05:32,101 DEBUG TRAIN Batch 12/400 loss 24.240215 loss_att 26.354212 loss_ctc 37.871887 loss_rnnt 21.999859 lr 0.00049864 rank 2
2022-12-04 09:05:32,106 DEBUG TRAIN Batch 12/400 loss 8.747843 loss_att 14.321439 loss_ctc 14.775032 loss_rnnt 6.829498 lr 0.00049895 rank 4
2022-12-04 09:06:43,487 DEBUG TRAIN Batch 12/500 loss 14.954587 loss_att 18.699383 loss_ctc 24.825420 loss_rnnt 12.889517 lr 0.00049865 rank 6
2022-12-04 09:06:43,487 DEBUG TRAIN Batch 12/500 loss 4.895971 loss_att 8.168963 loss_ctc 10.726904 loss_rnnt 3.463915 lr 0.00049849 rank 3
2022-12-04 09:06:43,490 DEBUG TRAIN Batch 12/500 loss 10.467010 loss_att 12.950371 loss_ctc 18.519566 loss_rnnt 8.896665 lr 0.00049868 rank 5
2022-12-04 09:06:43,491 DEBUG TRAIN Batch 12/500 loss 9.265749 loss_att 12.176899 loss_ctc 18.998573 loss_rnnt 7.385808 lr 0.00049861 rank 0
2022-12-04 09:06:43,494 DEBUG TRAIN Batch 12/500 loss 17.936386 loss_att 19.036276 loss_ctc 31.190962 loss_rnnt 15.949131 lr 0.00049854 rank 7
2022-12-04 09:06:43,494 DEBUG TRAIN Batch 12/500 loss 7.257972 loss_att 8.988277 loss_ctc 9.537918 loss_rnnt 6.607918 lr 0.00049871 rank 4
2022-12-04 09:06:43,494 DEBUG TRAIN Batch 12/500 loss 7.247991 loss_att 9.831911 loss_ctc 11.681026 loss_rnnt 6.140135 lr 0.00049856 rank 1
2022-12-04 09:06:43,499 DEBUG TRAIN Batch 12/500 loss 9.259420 loss_att 12.621552 loss_ctc 16.106428 loss_rnnt 7.674059 lr 0.00049839 rank 2
2022-12-04 09:07:55,442 DEBUG TRAIN Batch 12/600 loss 6.274196 loss_att 13.495781 loss_ctc 9.907721 loss_rnnt 4.345408 lr 0.00049843 rank 5
2022-12-04 09:07:55,453 DEBUG TRAIN Batch 12/600 loss 12.070189 loss_att 12.793854 loss_ctc 16.623823 loss_rnnt 11.318306 lr 0.00049840 rank 6
2022-12-04 09:07:55,454 DEBUG TRAIN Batch 12/600 loss 7.633560 loss_att 11.363922 loss_ctc 13.675880 loss_rnnt 6.081844 lr 0.00049837 rank 0
2022-12-04 09:07:55,455 DEBUG TRAIN Batch 12/600 loss 21.990641 loss_att 20.725048 loss_ctc 32.243027 loss_rnnt 20.876774 lr 0.00049831 rank 1
2022-12-04 09:07:55,458 DEBUG TRAIN Batch 12/600 loss 6.649966 loss_att 8.434273 loss_ctc 12.758198 loss_rnnt 5.478674 lr 0.00049814 rank 2
2022-12-04 09:07:55,458 DEBUG TRAIN Batch 12/600 loss 15.924502 loss_att 17.840574 loss_ctc 23.182722 loss_rnnt 14.573524 lr 0.00049824 rank 3
2022-12-04 09:07:55,460 DEBUG TRAIN Batch 12/600 loss 19.164438 loss_att 20.971897 loss_ctc 30.921253 loss_rnnt 17.235373 lr 0.00049829 rank 7
2022-12-04 09:07:55,464 DEBUG TRAIN Batch 12/600 loss 11.789774 loss_att 11.978281 loss_ctc 19.729057 loss_rnnt 10.693501 lr 0.00049846 rank 4
2022-12-04 09:09:08,900 DEBUG TRAIN Batch 12/700 loss 16.473576 loss_att 20.736107 loss_ctc 20.561497 loss_rnnt 15.076015 lr 0.00049821 rank 4
2022-12-04 09:09:08,904 DEBUG TRAIN Batch 12/700 loss 15.567508 loss_att 20.442846 loss_ctc 32.440197 loss_rnnt 12.342749 lr 0.00049816 rank 6
2022-12-04 09:09:08,905 DEBUG TRAIN Batch 12/700 loss 9.474779 loss_att 14.417702 loss_ctc 17.437222 loss_rnnt 7.424535 lr 0.00049818 rank 5
2022-12-04 09:09:08,907 DEBUG TRAIN Batch 12/700 loss 18.114336 loss_att 24.152483 loss_ctc 34.451843 loss_rnnt 14.728371 lr 0.00049790 rank 2
2022-12-04 09:09:08,910 DEBUG TRAIN Batch 12/700 loss 14.603038 loss_att 22.281330 loss_ctc 36.897953 loss_rnnt 10.094725 lr 0.00049804 rank 7
2022-12-04 09:09:08,911 DEBUG TRAIN Batch 12/700 loss 13.461635 loss_att 15.910046 loss_ctc 22.236244 loss_rnnt 11.802005 lr 0.00049812 rank 0
2022-12-04 09:09:08,915 DEBUG TRAIN Batch 12/700 loss 18.400934 loss_att 22.459202 loss_ctc 26.869736 loss_rnnt 16.460106 lr 0.00049807 rank 1
2022-12-04 09:09:08,931 DEBUG TRAIN Batch 12/700 loss 8.974570 loss_att 12.365615 loss_ctc 14.252910 loss_rnnt 7.592582 lr 0.00049800 rank 3
2022-12-04 09:10:20,459 DEBUG TRAIN Batch 12/800 loss 11.996083 loss_att 14.761577 loss_ctc 22.322378 loss_rnnt 10.066145 lr 0.00049791 rank 6
2022-12-04 09:10:20,460 DEBUG TRAIN Batch 12/800 loss 2.737311 loss_att 5.858855 loss_ctc 7.325770 loss_rnnt 1.501208 lr 0.00049775 rank 3
2022-12-04 09:10:20,461 DEBUG TRAIN Batch 12/800 loss 12.805937 loss_att 15.432141 loss_ctc 22.365011 loss_rnnt 11.006152 lr 0.00049787 rank 0
2022-12-04 09:10:20,464 DEBUG TRAIN Batch 12/800 loss 20.427999 loss_att 25.029713 loss_ctc 34.224354 loss_rnnt 17.668142 lr 0.00049793 rank 5
2022-12-04 09:10:20,464 DEBUG TRAIN Batch 12/800 loss 10.542438 loss_att 13.915773 loss_ctc 13.132177 loss_rnnt 9.522471 lr 0.00049765 rank 2
2022-12-04 09:10:20,466 DEBUG TRAIN Batch 12/800 loss 14.485924 loss_att 20.429193 loss_ctc 28.676430 loss_rnnt 11.405201 lr 0.00049779 rank 7
2022-12-04 09:10:20,471 DEBUG TRAIN Batch 12/800 loss 18.293217 loss_att 22.869286 loss_ctc 33.081249 loss_rnnt 15.406265 lr 0.00049796 rank 4
2022-12-04 09:10:20,507 DEBUG TRAIN Batch 12/800 loss 5.830379 loss_att 10.032680 loss_ctc 11.976919 loss_rnnt 4.170381 lr 0.00049782 rank 1
2022-12-04 09:11:31,850 DEBUG TRAIN Batch 12/900 loss 18.690243 loss_att 22.172211 loss_ctc 35.282013 loss_rnnt 15.781612 lr 0.00049762 rank 0
2022-12-04 09:11:31,853 DEBUG TRAIN Batch 12/900 loss 6.952179 loss_att 11.395065 loss_ctc 12.768902 loss_rnnt 5.288038 lr 0.00049750 rank 3
2022-12-04 09:11:31,854 DEBUG TRAIN Batch 12/900 loss 10.014757 loss_att 15.714139 loss_ctc 18.295040 loss_rnnt 7.770843 lr 0.00049755 rank 7
2022-12-04 09:11:31,856 DEBUG TRAIN Batch 12/900 loss 14.876946 loss_att 18.737093 loss_ctc 25.209242 loss_rnnt 12.727278 lr 0.00049766 rank 6
2022-12-04 09:11:31,858 DEBUG TRAIN Batch 12/900 loss 11.389784 loss_att 18.515303 loss_ctc 28.917801 loss_rnnt 7.627610 lr 0.00049757 rank 1
2022-12-04 09:11:31,856 DEBUG TRAIN Batch 12/900 loss 14.923180 loss_att 15.795803 loss_ctc 27.214233 loss_rnnt 13.109848 lr 0.00049769 rank 5
2022-12-04 09:11:31,859 DEBUG TRAIN Batch 12/900 loss 10.135942 loss_att 16.488817 loss_ctc 21.231594 loss_rnnt 7.385947 lr 0.00049740 rank 2
2022-12-04 09:11:31,866 DEBUG TRAIN Batch 12/900 loss 16.526394 loss_att 21.373678 loss_ctc 24.285707 loss_rnnt 14.522363 lr 0.00049772 rank 4
2022-12-04 09:12:44,903 DEBUG TRAIN Batch 12/1000 loss 14.854075 loss_att 15.766212 loss_ctc 23.910065 loss_rnnt 13.464182 lr 0.00049744 rank 5
2022-12-04 09:12:44,903 DEBUG TRAIN Batch 12/1000 loss 9.766966 loss_att 11.338272 loss_ctc 16.775860 loss_rnnt 8.518186 lr 0.00049742 rank 6
2022-12-04 09:12:44,906 DEBUG TRAIN Batch 12/1000 loss 6.941997 loss_att 9.962758 loss_ctc 10.556939 loss_rnnt 5.855852 lr 0.00049738 rank 0
2022-12-04 09:12:44,907 DEBUG TRAIN Batch 12/1000 loss 13.778589 loss_att 16.832657 loss_ctc 27.239288 loss_rnnt 11.373015 lr 0.00049726 rank 3
2022-12-04 09:12:44,908 DEBUG TRAIN Batch 12/1000 loss 19.700827 loss_att 22.317467 loss_ctc 28.801928 loss_rnnt 17.964020 lr 0.00049733 rank 1
2022-12-04 09:12:44,913 DEBUG TRAIN Batch 12/1000 loss 7.694366 loss_att 9.071783 loss_ctc 10.557171 loss_rnnt 7.037176 lr 0.00049716 rank 2
2022-12-04 09:12:44,915 DEBUG TRAIN Batch 12/1000 loss 14.978870 loss_att 16.842667 loss_ctc 21.953159 loss_rnnt 13.676206 lr 0.00049747 rank 4
2022-12-04 09:12:44,932 DEBUG TRAIN Batch 12/1000 loss 17.266809 loss_att 19.428888 loss_ctc 28.722742 loss_rnnt 15.306935 lr 0.00049730 rank 7
2022-12-04 09:13:58,551 DEBUG TRAIN Batch 12/1100 loss 16.446325 loss_att 20.272919 loss_ctc 29.080463 loss_rnnt 13.996454 lr 0.00049719 rank 5
2022-12-04 09:13:58,551 DEBUG TRAIN Batch 12/1100 loss 15.835505 loss_att 19.181355 loss_ctc 25.305685 loss_rnnt 13.903643 lr 0.00049713 rank 0
2022-12-04 09:13:58,551 DEBUG TRAIN Batch 12/1100 loss 20.528608 loss_att 22.041721 loss_ctc 37.231297 loss_rnnt 17.998959 lr 0.00049717 rank 6
2022-12-04 09:13:58,552 DEBUG TRAIN Batch 12/1100 loss 10.077704 loss_att 12.890348 loss_ctc 14.044481 loss_rnnt 8.986271 lr 0.00049708 rank 1
2022-12-04 09:13:58,553 DEBUG TRAIN Batch 12/1100 loss 9.562365 loss_att 14.324343 loss_ctc 15.603095 loss_rnnt 7.804539 lr 0.00049701 rank 3
2022-12-04 09:13:58,558 DEBUG TRAIN Batch 12/1100 loss 7.977400 loss_att 10.739502 loss_ctc 10.756256 loss_rnnt 7.054466 lr 0.00049691 rank 2
2022-12-04 09:13:58,558 DEBUG TRAIN Batch 12/1100 loss 15.483093 loss_att 19.367073 loss_ctc 18.198740 loss_rnnt 14.344212 lr 0.00049706 rank 7
2022-12-04 09:13:58,563 DEBUG TRAIN Batch 12/1100 loss 11.322466 loss_att 13.703827 loss_ctc 20.011164 loss_rnnt 9.687699 lr 0.00049722 rank 4
2022-12-04 09:15:10,508 DEBUG TRAIN Batch 12/1200 loss 13.701161 loss_att 16.089676 loss_ctc 21.618925 loss_rnnt 12.167756 lr 0.00049692 rank 6
2022-12-04 09:15:10,515 DEBUG TRAIN Batch 12/1200 loss 13.958273 loss_att 15.920410 loss_ctc 20.131712 loss_rnnt 12.742721 lr 0.00049677 rank 3
2022-12-04 09:15:10,516 DEBUG TRAIN Batch 12/1200 loss 3.552867 loss_att 7.296867 loss_ctc 5.882650 loss_rnnt 2.493429 lr 0.00049684 rank 1
2022-12-04 09:15:10,516 DEBUG TRAIN Batch 12/1200 loss 11.562452 loss_att 15.637488 loss_ctc 16.672928 loss_rnnt 10.066049 lr 0.00049698 rank 4
2022-12-04 09:15:10,517 DEBUG TRAIN Batch 12/1200 loss 9.048106 loss_att 13.111038 loss_ctc 15.569825 loss_rnnt 7.365957 lr 0.00049695 rank 5
2022-12-04 09:15:10,518 DEBUG TRAIN Batch 12/1200 loss 24.255817 loss_att 30.343575 loss_ctc 42.176819 loss_rnnt 20.648798 lr 0.00049681 rank 7
2022-12-04 09:15:10,518 DEBUG TRAIN Batch 12/1200 loss 26.502514 loss_att 28.478287 loss_ctc 40.916145 loss_rnnt 24.185539 lr 0.00049689 rank 0
2022-12-04 09:15:10,535 DEBUG TRAIN Batch 12/1200 loss 15.035219 loss_att 18.803883 loss_ctc 22.759254 loss_rnnt 13.251615 lr 0.00049667 rank 2
2022-12-04 09:16:22,250 DEBUG TRAIN Batch 12/1300 loss 7.652970 loss_att 13.422773 loss_ctc 14.866800 loss_rnnt 5.537166 lr 0.00049652 rank 3
2022-12-04 09:16:22,250 DEBUG TRAIN Batch 12/1300 loss 12.008275 loss_att 12.555756 loss_ctc 18.111485 loss_rnnt 11.085017 lr 0.00049657 rank 7
2022-12-04 09:16:22,250 DEBUG TRAIN Batch 12/1300 loss 10.948814 loss_att 12.230185 loss_ctc 18.392572 loss_rnnt 9.700039 lr 0.00049668 rank 6
2022-12-04 09:16:22,253 DEBUG TRAIN Batch 12/1300 loss 7.570989 loss_att 13.648613 loss_ctc 12.153152 loss_rnnt 5.744509 lr 0.00049659 rank 1
2022-12-04 09:16:22,254 DEBUG TRAIN Batch 12/1300 loss 10.361453 loss_att 10.890246 loss_ctc 18.259281 loss_rnnt 9.202650 lr 0.00049664 rank 0
2022-12-04 09:16:22,260 DEBUG TRAIN Batch 12/1300 loss 9.981541 loss_att 18.387407 loss_ctc 23.849335 loss_rnnt 6.451328 lr 0.00049673 rank 4
2022-12-04 09:16:22,260 DEBUG TRAIN Batch 12/1300 loss 10.236342 loss_att 16.318714 loss_ctc 15.825625 loss_rnnt 8.274631 lr 0.00049642 rank 2
2022-12-04 09:16:22,295 DEBUG TRAIN Batch 12/1300 loss 5.751023 loss_att 11.196238 loss_ctc 12.252566 loss_rnnt 3.795108 lr 0.00049670 rank 5
2022-12-04 09:17:36,903 DEBUG TRAIN Batch 12/1400 loss 16.155226 loss_att 19.871416 loss_ctc 31.513052 loss_rnnt 13.364279 lr 0.00049643 rank 6
2022-12-04 09:17:36,905 DEBUG TRAIN Batch 12/1400 loss 13.435295 loss_att 20.880333 loss_ctc 22.144077 loss_rnnt 10.785117 lr 0.00049628 rank 3
2022-12-04 09:17:36,906 DEBUG TRAIN Batch 12/1400 loss 8.819468 loss_att 13.516943 loss_ctc 18.680639 loss_rnnt 6.565149 lr 0.00049635 rank 1
2022-12-04 09:17:36,906 DEBUG TRAIN Batch 12/1400 loss 10.861000 loss_att 15.250916 loss_ctc 25.720625 loss_rnnt 8.001733 lr 0.00049632 rank 7
2022-12-04 09:17:36,908 DEBUG TRAIN Batch 12/1400 loss 6.901059 loss_att 9.208900 loss_ctc 13.332617 loss_rnnt 5.581950 lr 0.00049646 rank 5
2022-12-04 09:17:36,908 DEBUG TRAIN Batch 12/1400 loss 17.190283 loss_att 21.942680 loss_ctc 33.032200 loss_rnnt 14.127548 lr 0.00049640 rank 0
2022-12-04 09:17:36,915 DEBUG TRAIN Batch 12/1400 loss 16.481350 loss_att 19.481665 loss_ctc 24.293312 loss_rnnt 14.839691 lr 0.00049649 rank 4
2022-12-04 09:17:36,924 DEBUG TRAIN Batch 12/1400 loss 8.537716 loss_att 12.463223 loss_ctc 17.637814 loss_rnnt 6.539268 lr 0.00049618 rank 2
2022-12-04 09:18:49,140 DEBUG TRAIN Batch 12/1500 loss 11.215246 loss_att 13.972686 loss_ctc 16.990681 loss_rnnt 9.893701 lr 0.00049619 rank 6
2022-12-04 09:18:49,142 DEBUG TRAIN Batch 12/1500 loss 12.624763 loss_att 14.277575 loss_ctc 19.629395 loss_rnnt 11.360250 lr 0.00049603 rank 3
2022-12-04 09:18:49,145 DEBUG TRAIN Batch 12/1500 loss 12.756079 loss_att 16.543974 loss_ctc 21.776630 loss_rnnt 10.795760 lr 0.00049615 rank 0
2022-12-04 09:18:49,148 DEBUG TRAIN Batch 12/1500 loss 8.075352 loss_att 12.427323 loss_ctc 19.111061 loss_rnnt 5.733529 lr 0.00049621 rank 5
2022-12-04 09:18:49,148 DEBUG TRAIN Batch 12/1500 loss 23.586241 loss_att 26.329121 loss_ctc 42.536903 loss_rnnt 20.510910 lr 0.00049624 rank 4
2022-12-04 09:18:49,156 DEBUG TRAIN Batch 12/1500 loss 6.419822 loss_att 9.919329 loss_ctc 12.401072 loss_rnnt 4.922421 lr 0.00049610 rank 1
2022-12-04 09:18:49,156 DEBUG TRAIN Batch 12/1500 loss 9.013480 loss_att 14.300281 loss_ctc 17.759321 loss_rnnt 6.790008 lr 0.00049608 rank 7
2022-12-04 09:18:49,161 DEBUG TRAIN Batch 12/1500 loss 15.650530 loss_att 20.810905 loss_ctc 26.117825 loss_rnnt 13.222816 lr 0.00049593 rank 2
2022-12-04 09:20:00,861 DEBUG TRAIN Batch 12/1600 loss 10.653500 loss_att 15.075279 loss_ctc 18.718119 loss_rnnt 8.693860 lr 0.00049594 rank 6
2022-12-04 09:20:00,861 DEBUG TRAIN Batch 12/1600 loss 11.628084 loss_att 13.065354 loss_ctc 17.052549 loss_rnnt 10.617368 lr 0.00049591 rank 0
2022-12-04 09:20:00,865 DEBUG TRAIN Batch 12/1600 loss 16.856050 loss_att 22.078114 loss_ctc 29.166668 loss_rnnt 14.170221 lr 0.00049583 rank 7
2022-12-04 09:20:00,866 DEBUG TRAIN Batch 12/1600 loss 5.898051 loss_att 10.373269 loss_ctc 12.113174 loss_rnnt 4.174325 lr 0.00049597 rank 5
2022-12-04 09:20:00,868 DEBUG TRAIN Batch 12/1600 loss 19.171831 loss_att 25.593647 loss_ctc 39.829212 loss_rnnt 15.133149 lr 0.00049569 rank 2
2022-12-04 09:20:00,867 DEBUG TRAIN Batch 12/1600 loss 15.078434 loss_att 19.257732 loss_ctc 30.660236 loss_rnnt 12.165001 lr 0.00049579 rank 3
2022-12-04 09:20:00,878 DEBUG TRAIN Batch 12/1600 loss 7.720391 loss_att 13.342428 loss_ctc 12.957869 loss_rnnt 5.897653 lr 0.00049600 rank 4
2022-12-04 09:20:00,914 DEBUG TRAIN Batch 12/1600 loss 14.297759 loss_att 16.167671 loss_ctc 24.451862 loss_rnnt 12.569895 lr 0.00049586 rank 1
2022-12-04 09:21:13,163 DEBUG TRAIN Batch 12/1700 loss 18.860374 loss_att 24.346874 loss_ctc 36.431374 loss_rnnt 15.420274 lr 0.00049559 rank 7
2022-12-04 09:21:13,172 DEBUG TRAIN Batch 12/1700 loss 10.860926 loss_att 14.979836 loss_ctc 16.203312 loss_rnnt 9.324825 lr 0.00049570 rank 6
2022-12-04 09:21:13,173 DEBUG TRAIN Batch 12/1700 loss 10.720210 loss_att 13.164684 loss_ctc 18.325714 loss_rnnt 9.217248 lr 0.00049566 rank 0
2022-12-04 09:21:13,173 DEBUG TRAIN Batch 12/1700 loss 10.971627 loss_att 11.307615 loss_ctc 14.740088 loss_rnnt 10.401968 lr 0.00049555 rank 3
2022-12-04 09:21:13,177 DEBUG TRAIN Batch 12/1700 loss 6.139111 loss_att 10.785456 loss_ctc 13.227476 loss_rnnt 4.264727 lr 0.00049545 rank 2
2022-12-04 09:21:13,182 DEBUG TRAIN Batch 12/1700 loss 7.430026 loss_att 13.229033 loss_ctc 18.426922 loss_rnnt 4.803972 lr 0.00049575 rank 4
2022-12-04 09:21:13,205 DEBUG TRAIN Batch 12/1700 loss 17.374537 loss_att 21.520420 loss_ctc 29.671534 loss_rnnt 14.905760 lr 0.00049573 rank 5
2022-12-04 09:21:13,227 DEBUG TRAIN Batch 12/1700 loss 14.201819 loss_att 20.473141 loss_ctc 25.678886 loss_rnnt 11.417278 lr 0.00049561 rank 1
2022-12-04 09:22:26,906 DEBUG TRAIN Batch 12/1800 loss 9.979699 loss_att 12.453962 loss_ctc 17.787771 loss_rnnt 8.443770 lr 0.00049548 rank 5
2022-12-04 09:22:26,908 DEBUG TRAIN Batch 12/1800 loss 11.831587 loss_att 13.837996 loss_ctc 22.108255 loss_rnnt 10.060083 lr 0.00049530 rank 3
2022-12-04 09:22:26,908 DEBUG TRAIN Batch 12/1800 loss 9.216695 loss_att 13.489310 loss_ctc 14.612538 loss_rnnt 7.642726 lr 0.00049535 rank 7
2022-12-04 09:22:26,911 DEBUG TRAIN Batch 12/1800 loss 18.952377 loss_att 22.626102 loss_ctc 31.405916 loss_rnnt 16.557159 lr 0.00049537 rank 1
2022-12-04 09:22:26,912 DEBUG TRAIN Batch 12/1800 loss 19.978056 loss_att 24.654362 loss_ctc 33.424721 loss_rnnt 17.249907 lr 0.00049546 rank 6
2022-12-04 09:22:26,918 DEBUG TRAIN Batch 12/1800 loss 11.873538 loss_att 15.526617 loss_ctc 28.837219 loss_rnnt 8.881098 lr 0.00049520 rank 2
2022-12-04 09:22:26,918 DEBUG TRAIN Batch 12/1800 loss 9.637495 loss_att 13.820984 loss_ctc 17.301914 loss_rnnt 7.778874 lr 0.00049542 rank 0
2022-12-04 09:22:26,965 DEBUG TRAIN Batch 12/1800 loss 11.584152 loss_att 14.869584 loss_ctc 16.677032 loss_rnnt 10.248015 lr 0.00049551 rank 4
2022-12-04 09:23:38,387 DEBUG TRAIN Batch 12/1900 loss 11.788232 loss_att 17.437548 loss_ctc 18.633558 loss_rnnt 9.745659 lr 0.00049506 rank 3
2022-12-04 09:23:38,389 DEBUG TRAIN Batch 12/1900 loss 23.165218 loss_att 24.369677 loss_ctc 33.574661 loss_rnnt 21.536402 lr 0.00049496 rank 2
2022-12-04 09:23:38,389 DEBUG TRAIN Batch 12/1900 loss 9.971106 loss_att 13.272793 loss_ctc 15.043753 loss_rnnt 8.634415 lr 0.00049513 rank 1
2022-12-04 09:23:38,390 DEBUG TRAIN Batch 12/1900 loss 4.696095 loss_att 8.257534 loss_ctc 7.173107 loss_rnnt 3.653540 lr 0.00049524 rank 5
2022-12-04 09:23:38,393 DEBUG TRAIN Batch 12/1900 loss 7.220027 loss_att 8.919901 loss_ctc 11.393867 loss_rnnt 6.323541 lr 0.00049518 rank 0
2022-12-04 09:23:38,395 DEBUG TRAIN Batch 12/1900 loss 11.877640 loss_att 14.137932 loss_ctc 19.081490 loss_rnnt 10.465069 lr 0.00049521 rank 6
2022-12-04 09:23:38,400 DEBUG TRAIN Batch 12/1900 loss 8.633260 loss_att 10.639515 loss_ctc 14.242709 loss_rnnt 7.484081 lr 0.00049527 rank 4
2022-12-04 09:23:38,403 DEBUG TRAIN Batch 12/1900 loss 12.338003 loss_att 17.405563 loss_ctc 18.766932 loss_rnnt 10.467300 lr 0.00049510 rank 7
2022-12-04 09:24:49,753 DEBUG TRAIN Batch 12/2000 loss 7.281378 loss_att 10.953816 loss_ctc 16.755651 loss_rnnt 5.283653 lr 0.00049482 rank 3
2022-12-04 09:24:49,758 DEBUG TRAIN Batch 12/2000 loss 29.188442 loss_att 29.868702 loss_ctc 50.331436 loss_rnnt 26.233322 lr 0.00049488 rank 1
2022-12-04 09:24:49,758 DEBUG TRAIN Batch 12/2000 loss 9.983595 loss_att 13.521653 loss_ctc 16.133558 loss_rnnt 8.455988 lr 0.00049472 rank 2
2022-12-04 09:24:49,758 DEBUG TRAIN Batch 12/2000 loss 21.573086 loss_att 26.669275 loss_ctc 34.819641 loss_rnnt 18.787642 lr 0.00049494 rank 0
2022-12-04 09:24:49,758 DEBUG TRAIN Batch 12/2000 loss 5.033377 loss_att 8.391054 loss_ctc 8.942350 loss_rnnt 3.840645 lr 0.00049497 rank 6
2022-12-04 09:24:49,763 DEBUG TRAIN Batch 12/2000 loss 16.974274 loss_att 18.521122 loss_ctc 26.871212 loss_rnnt 15.345313 lr 0.00049500 rank 5
2022-12-04 09:24:49,765 DEBUG TRAIN Batch 12/2000 loss 16.027210 loss_att 23.482857 loss_ctc 37.926239 loss_rnnt 11.616210 lr 0.00049503 rank 4
2022-12-04 09:24:49,766 DEBUG TRAIN Batch 12/2000 loss 8.751358 loss_att 11.274224 loss_ctc 10.976752 loss_rnnt 7.950066 lr 0.00049486 rank 7
2022-12-04 09:26:03,334 DEBUG TRAIN Batch 12/2100 loss 12.744449 loss_att 17.866600 loss_ctc 24.891529 loss_rnnt 10.100409 lr 0.00049475 rank 5
2022-12-04 09:26:03,336 DEBUG TRAIN Batch 12/2100 loss 10.611270 loss_att 13.147299 loss_ctc 23.723965 loss_rnnt 8.355705 lr 0.00049464 rank 1
2022-12-04 09:26:03,338 DEBUG TRAIN Batch 12/2100 loss 12.369818 loss_att 14.218393 loss_ctc 15.583896 loss_rnnt 11.571559 lr 0.00049462 rank 7
2022-12-04 09:26:03,344 DEBUG TRAIN Batch 12/2100 loss 5.356483 loss_att 10.828505 loss_ctc 8.157848 loss_rnnt 3.888562 lr 0.00049457 rank 3
2022-12-04 09:26:03,355 DEBUG TRAIN Batch 12/2100 loss 8.271656 loss_att 11.042513 loss_ctc 11.049560 loss_rnnt 7.347096 lr 0.00049448 rank 2
2022-12-04 09:26:03,373 DEBUG TRAIN Batch 12/2100 loss 7.433448 loss_att 11.473135 loss_ctc 16.364477 loss_rnnt 5.434707 lr 0.00049469 rank 0
2022-12-04 09:26:03,374 DEBUG TRAIN Batch 12/2100 loss 14.267134 loss_att 19.509354 loss_ctc 26.010647 loss_rnnt 11.652887 lr 0.00049473 rank 6
2022-12-04 09:26:03,388 DEBUG TRAIN Batch 12/2100 loss 10.148998 loss_att 17.560650 loss_ctc 19.909134 loss_rnnt 7.365315 lr 0.00049478 rank 4
2022-12-04 09:27:15,730 DEBUG TRAIN Batch 12/2200 loss 11.495354 loss_att 16.395018 loss_ctc 17.826675 loss_rnnt 9.671244 lr 0.00049451 rank 5
2022-12-04 09:27:15,730 DEBUG TRAIN Batch 12/2200 loss 12.408388 loss_att 17.314201 loss_ctc 22.300356 loss_rnnt 10.108296 lr 0.00049449 rank 6
2022-12-04 09:27:15,734 DEBUG TRAIN Batch 12/2200 loss 9.285589 loss_att 13.982420 loss_ctc 20.765072 loss_rnnt 6.815624 lr 0.00049423 rank 2
2022-12-04 09:27:15,737 DEBUG TRAIN Batch 12/2200 loss 12.455194 loss_att 15.464830 loss_ctc 19.119509 loss_rnnt 10.964691 lr 0.00049440 rank 1
2022-12-04 09:27:15,739 DEBUG TRAIN Batch 12/2200 loss 11.511972 loss_att 15.662157 loss_ctc 17.478338 loss_rnnt 9.886420 lr 0.00049445 rank 0
2022-12-04 09:27:15,740 DEBUG TRAIN Batch 12/2200 loss 12.566200 loss_att 15.851189 loss_ctc 22.644192 loss_rnnt 10.565470 lr 0.00049433 rank 3
2022-12-04 09:27:15,740 DEBUG TRAIN Batch 12/2200 loss 10.870976 loss_att 14.186473 loss_ctc 20.838020 loss_rnnt 8.878939 lr 0.00049454 rank 4
2022-12-04 09:27:15,742 DEBUG TRAIN Batch 12/2200 loss 12.778682 loss_att 18.639246 loss_ctc 29.804955 loss_rnnt 9.336399 lr 0.00049438 rank 7
2022-12-04 09:28:26,596 DEBUG TRAIN Batch 12/2300 loss 18.439789 loss_att 19.459103 loss_ctc 30.464832 loss_rnnt 16.632587 lr 0.00049421 rank 0
2022-12-04 09:28:26,599 DEBUG TRAIN Batch 12/2300 loss 13.014854 loss_att 18.111219 loss_ctc 24.042988 loss_rnnt 10.525164 lr 0.00049399 rank 2
2022-12-04 09:28:26,599 DEBUG TRAIN Batch 12/2300 loss 10.924242 loss_att 14.825785 loss_ctc 18.528173 loss_rnnt 9.130076 lr 0.00049425 rank 6
2022-12-04 09:28:26,600 DEBUG TRAIN Batch 12/2300 loss 10.180823 loss_att 12.814057 loss_ctc 19.713320 loss_rnnt 8.383177 lr 0.00049427 rank 5
2022-12-04 09:28:26,601 DEBUG TRAIN Batch 12/2300 loss 15.927530 loss_att 17.479801 loss_ctc 22.166843 loss_rnnt 14.785168 lr 0.00049416 rank 1
2022-12-04 09:28:26,602 DEBUG TRAIN Batch 12/2300 loss 14.105206 loss_att 19.473640 loss_ctc 27.326992 loss_rnnt 11.268614 lr 0.00049409 rank 3
2022-12-04 09:28:26,606 DEBUG TRAIN Batch 12/2300 loss 11.183671 loss_att 15.726371 loss_ctc 24.592501 loss_rnnt 8.487287 lr 0.00049413 rank 7
2022-12-04 09:28:26,611 DEBUG TRAIN Batch 12/2300 loss 12.747765 loss_att 18.894205 loss_ctc 24.441425 loss_rnnt 9.959322 lr 0.00049430 rank 4
2022-12-04 09:29:38,872 DEBUG TRAIN Batch 12/2400 loss 12.072452 loss_att 15.451744 loss_ctc 19.465927 loss_rnnt 10.410797 lr 0.00049375 rank 2
2022-12-04 09:29:38,878 DEBUG TRAIN Batch 12/2400 loss 8.268054 loss_att 12.762114 loss_ctc 12.999931 loss_rnnt 6.738325 lr 0.00049403 rank 5
2022-12-04 09:29:38,879 DEBUG TRAIN Batch 12/2400 loss 13.548151 loss_att 16.697029 loss_ctc 20.266773 loss_rnnt 12.022559 lr 0.00049397 rank 0
2022-12-04 09:29:38,880 DEBUG TRAIN Batch 12/2400 loss 9.970745 loss_att 14.799448 loss_ctc 16.542549 loss_rnnt 8.128763 lr 0.00049400 rank 6
2022-12-04 09:29:38,881 DEBUG TRAIN Batch 12/2400 loss 9.449985 loss_att 12.641417 loss_ctc 16.276220 loss_rnnt 7.901533 lr 0.00049392 rank 1
2022-12-04 09:29:38,881 DEBUG TRAIN Batch 12/2400 loss 15.432877 loss_att 17.809452 loss_ctc 26.934765 loss_rnnt 13.423975 lr 0.00049389 rank 7
2022-12-04 09:29:38,883 DEBUG TRAIN Batch 12/2400 loss 10.082874 loss_att 11.534944 loss_ctc 16.496412 loss_rnnt 8.937322 lr 0.00049385 rank 3
2022-12-04 09:29:38,889 DEBUG TRAIN Batch 12/2400 loss 8.891261 loss_att 12.297532 loss_ctc 13.978345 loss_rnnt 7.531728 lr 0.00049406 rank 4
2022-12-04 09:30:52,911 DEBUG TRAIN Batch 12/2500 loss 13.055080 loss_att 15.800253 loss_ctc 19.565130 loss_rnnt 11.638039 lr 0.00049376 rank 6
2022-12-04 09:30:52,913 DEBUG TRAIN Batch 12/2500 loss 7.061109 loss_att 8.728861 loss_ctc 13.289596 loss_rnnt 5.897094 lr 0.00049379 rank 5
2022-12-04 09:30:52,913 DEBUG TRAIN Batch 12/2500 loss 3.392008 loss_att 7.272830 loss_ctc 7.242485 loss_rnnt 2.102446 lr 0.00049365 rank 7
2022-12-04 09:30:52,915 DEBUG TRAIN Batch 12/2500 loss 8.569659 loss_att 11.966165 loss_ctc 11.578276 loss_rnnt 7.489210 lr 0.00049361 rank 3
2022-12-04 09:30:52,917 DEBUG TRAIN Batch 12/2500 loss 12.055774 loss_att 13.714670 loss_ctc 16.827267 loss_rnnt 11.087795 lr 0.00049351 rank 2
2022-12-04 09:30:52,919 DEBUG TRAIN Batch 12/2500 loss 13.210115 loss_att 16.345722 loss_ctc 19.486712 loss_rnnt 11.746115 lr 0.00049373 rank 0
2022-12-04 09:30:52,930 DEBUG TRAIN Batch 12/2500 loss 10.454785 loss_att 11.342900 loss_ctc 16.352343 loss_rnnt 9.490822 lr 0.00049382 rank 4
2022-12-04 09:30:52,957 DEBUG TRAIN Batch 12/2500 loss 7.969578 loss_att 10.742553 loss_ctc 13.501075 loss_rnnt 6.677450 lr 0.00049368 rank 1
2022-12-04 09:32:05,073 DEBUG TRAIN Batch 12/2600 loss 29.066284 loss_att 34.530281 loss_ctc 47.831600 loss_rnnt 25.471439 lr 0.00049337 rank 3
2022-12-04 09:32:05,077 DEBUG TRAIN Batch 12/2600 loss 16.950361 loss_att 21.399841 loss_ctc 23.258039 loss_rnnt 15.219442 lr 0.00049344 rank 1
2022-12-04 09:32:05,079 DEBUG TRAIN Batch 12/2600 loss 5.399803 loss_att 11.926559 loss_ctc 17.135334 loss_rnnt 2.529714 lr 0.00049352 rank 6
2022-12-04 09:32:05,081 DEBUG TRAIN Batch 12/2600 loss 10.489004 loss_att 10.839237 loss_ctc 12.344136 loss_rnnt 10.171606 lr 0.00049349 rank 0
2022-12-04 09:32:05,080 DEBUG TRAIN Batch 12/2600 loss 6.059429 loss_att 11.626737 loss_ctc 13.325480 loss_rnnt 3.977161 lr 0.00049358 rank 4
2022-12-04 09:32:05,080 DEBUG TRAIN Batch 12/2600 loss 31.589649 loss_att 39.368267 loss_ctc 57.935104 loss_rnnt 26.521200 lr 0.00049355 rank 5
2022-12-04 09:32:05,082 DEBUG TRAIN Batch 12/2600 loss 6.343955 loss_att 10.659409 loss_ctc 9.616690 loss_rnnt 5.044499 lr 0.00049327 rank 2
2022-12-04 09:32:05,085 DEBUG TRAIN Batch 12/2600 loss 14.320481 loss_att 17.903893 loss_ctc 28.715437 loss_rnnt 11.684471 lr 0.00049341 rank 7
2022-12-04 09:33:17,094 DEBUG TRAIN Batch 12/2700 loss 6.376875 loss_att 11.744078 loss_ctc 10.517170 loss_rnnt 4.751395 lr 0.00049328 rank 6
2022-12-04 09:33:17,097 DEBUG TRAIN Batch 12/2700 loss 9.057613 loss_att 14.279272 loss_ctc 14.848811 loss_rnnt 7.241123 lr 0.00049325 rank 0
2022-12-04 09:33:17,098 DEBUG TRAIN Batch 12/2700 loss 10.552176 loss_att 11.805050 loss_ctc 20.654165 loss_rnnt 8.954670 lr 0.00049320 rank 1
2022-12-04 09:33:17,101 DEBUG TRAIN Batch 12/2700 loss 8.445244 loss_att 13.690748 loss_ctc 16.566319 loss_rnnt 6.313333 lr 0.00049331 rank 5
2022-12-04 09:33:17,101 DEBUG TRAIN Batch 12/2700 loss 13.950041 loss_att 15.907421 loss_ctc 20.116568 loss_rnnt 12.736361 lr 0.00049317 rank 7
2022-12-04 09:33:17,102 DEBUG TRAIN Batch 12/2700 loss 11.103743 loss_att 15.244473 loss_ctc 19.809261 loss_rnnt 9.114861 lr 0.00049334 rank 4
2022-12-04 09:33:17,104 DEBUG TRAIN Batch 12/2700 loss 9.076281 loss_att 12.275221 loss_ctc 17.028343 loss_rnnt 7.376217 lr 0.00049313 rank 3
2022-12-04 09:33:17,107 DEBUG TRAIN Batch 12/2700 loss 14.250415 loss_att 15.853559 loss_ctc 20.147297 loss_rnnt 13.143536 lr 0.00049303 rank 2
2022-12-04 09:34:30,338 DEBUG TRAIN Batch 12/2800 loss 13.502254 loss_att 15.366946 loss_ctc 20.606880 loss_rnnt 12.182032 lr 0.00049279 rank 2
2022-12-04 09:34:30,345 DEBUG TRAIN Batch 12/2800 loss 8.723073 loss_att 12.679740 loss_ctc 14.138457 loss_rnnt 7.209688 lr 0.00049307 rank 5
2022-12-04 09:34:30,346 DEBUG TRAIN Batch 12/2800 loss 8.524260 loss_att 11.999985 loss_ctc 16.963423 loss_rnnt 6.703892 lr 0.00049289 rank 3
2022-12-04 09:34:30,348 DEBUG TRAIN Batch 12/2800 loss 14.021516 loss_att 17.859097 loss_ctc 25.843624 loss_rnnt 11.677719 lr 0.00049301 rank 0
2022-12-04 09:34:30,356 DEBUG TRAIN Batch 12/2800 loss 7.933878 loss_att 12.118609 loss_ctc 13.100817 loss_rnnt 6.408007 lr 0.00049310 rank 4
2022-12-04 09:34:30,364 DEBUG TRAIN Batch 12/2800 loss 7.014228 loss_att 15.436118 loss_ctc 15.524513 loss_rnnt 4.195146 lr 0.00049304 rank 6
2022-12-04 09:34:30,367 DEBUG TRAIN Batch 12/2800 loss 13.111259 loss_att 16.721910 loss_ctc 24.005657 loss_rnnt 10.936543 lr 0.00049293 rank 7
2022-12-04 09:34:30,383 DEBUG TRAIN Batch 12/2800 loss 12.310034 loss_att 15.656319 loss_ctc 18.935392 loss_rnnt 10.757395 lr 0.00049296 rank 1
2022-12-04 09:35:42,803 DEBUG TRAIN Batch 12/2900 loss 32.680237 loss_att 43.225983 loss_ctc 47.838993 loss_rnnt 28.549919 lr 0.00049272 rank 1
2022-12-04 09:35:42,803 DEBUG TRAIN Batch 12/2900 loss 11.469283 loss_att 15.556189 loss_ctc 18.677872 loss_rnnt 9.690757 lr 0.00049255 rank 2
2022-12-04 09:35:42,806 DEBUG TRAIN Batch 12/2900 loss 12.132676 loss_att 15.700716 loss_ctc 13.552168 loss_rnnt 11.229802 lr 0.00049277 rank 0
2022-12-04 09:35:42,806 DEBUG TRAIN Batch 12/2900 loss 16.438334 loss_att 19.645922 loss_ctc 31.208708 loss_rnnt 13.827433 lr 0.00049283 rank 5
2022-12-04 09:35:42,807 DEBUG TRAIN Batch 12/2900 loss 12.645639 loss_att 19.135799 loss_ctc 19.312569 loss_rnnt 10.458683 lr 0.00049280 rank 6
2022-12-04 09:35:42,807 DEBUG TRAIN Batch 12/2900 loss 13.601339 loss_att 14.895893 loss_ctc 17.206661 loss_rnnt 12.861720 lr 0.00049286 rank 4
2022-12-04 09:35:42,809 DEBUG TRAIN Batch 12/2900 loss 14.276785 loss_att 17.912247 loss_ctc 19.926924 loss_rnnt 12.796341 lr 0.00049269 rank 7
2022-12-04 09:35:42,810 DEBUG TRAIN Batch 12/2900 loss 18.986635 loss_att 20.047073 loss_ctc 29.445423 loss_rnnt 17.380043 lr 0.00049265 rank 3
2022-12-04 09:36:54,763 DEBUG TRAIN Batch 12/3000 loss 11.178648 loss_att 12.604137 loss_ctc 16.858122 loss_rnnt 10.136286 lr 0.00049241 rank 3
2022-12-04 09:36:54,764 DEBUG TRAIN Batch 12/3000 loss 10.663563 loss_att 14.859488 loss_ctc 19.291895 loss_rnnt 8.673932 lr 0.00049256 rank 6
2022-12-04 09:36:54,765 DEBUG TRAIN Batch 12/3000 loss 12.929537 loss_att 12.695075 loss_ctc 20.125055 loss_rnnt 12.017027 lr 0.00049262 rank 4
2022-12-04 09:36:54,766 DEBUG TRAIN Batch 12/3000 loss 8.443519 loss_att 13.346104 loss_ctc 14.881727 loss_rnnt 6.604573 lr 0.00049253 rank 0
2022-12-04 09:36:54,766 DEBUG TRAIN Batch 12/3000 loss 23.629671 loss_att 29.059076 loss_ctc 33.227543 loss_rnnt 21.264074 lr 0.00049259 rank 5
2022-12-04 09:36:54,766 DEBUG TRAIN Batch 12/3000 loss 8.077474 loss_att 9.858151 loss_ctc 13.859558 loss_rnnt 6.950394 lr 0.00049231 rank 2
2022-12-04 09:36:54,771 DEBUG TRAIN Batch 12/3000 loss 14.280365 loss_att 16.262075 loss_ctc 19.431395 loss_rnnt 13.197220 lr 0.00049248 rank 1
2022-12-04 09:36:54,771 DEBUG TRAIN Batch 12/3000 loss 9.989524 loss_att 15.162905 loss_ctc 16.000776 loss_rnnt 8.153347 lr 0.00049245 rank 7
2022-12-04 09:38:07,291 DEBUG TRAIN Batch 12/3100 loss 15.950853 loss_att 20.725666 loss_ctc 24.267189 loss_rnnt 13.887047 lr 0.00049229 rank 0
2022-12-04 09:38:07,290 DEBUG TRAIN Batch 12/3100 loss 10.476865 loss_att 15.194067 loss_ctc 18.389973 loss_rnnt 8.478344 lr 0.00049217 rank 3
2022-12-04 09:38:07,292 DEBUG TRAIN Batch 12/3100 loss 9.647922 loss_att 11.756332 loss_ctc 18.345158 loss_rnnt 8.066608 lr 0.00049222 rank 7
2022-12-04 09:38:07,294 DEBUG TRAIN Batch 12/3100 loss 13.192785 loss_att 15.483759 loss_ctc 18.581913 loss_rnnt 12.016040 lr 0.00049233 rank 6
2022-12-04 09:38:07,296 DEBUG TRAIN Batch 12/3100 loss 6.131878 loss_att 8.920076 loss_ctc 10.236191 loss_rnnt 5.026997 lr 0.00049235 rank 5
2022-12-04 09:38:07,296 DEBUG TRAIN Batch 12/3100 loss 10.116270 loss_att 12.922095 loss_ctc 17.418249 loss_rnnt 8.581508 lr 0.00049207 rank 2
2022-12-04 09:38:07,299 DEBUG TRAIN Batch 12/3100 loss 17.184029 loss_att 23.196125 loss_ctc 29.152319 loss_rnnt 14.385837 lr 0.00049238 rank 4
2022-12-04 09:38:07,326 DEBUG TRAIN Batch 12/3100 loss 13.789074 loss_att 14.569127 loss_ctc 20.772223 loss_rnnt 12.701976 lr 0.00049224 rank 1
2022-12-04 09:39:21,664 DEBUG TRAIN Batch 12/3200 loss 9.048341 loss_att 10.352727 loss_ctc 14.582511 loss_rnnt 8.049575 lr 0.00049205 rank 0
2022-12-04 09:39:21,668 DEBUG TRAIN Batch 12/3200 loss 12.091220 loss_att 15.554905 loss_ctc 22.240734 loss_rnnt 10.045215 lr 0.00049193 rank 3
2022-12-04 09:39:21,668 DEBUG TRAIN Batch 12/3200 loss 8.395474 loss_att 7.961341 loss_ctc 12.519399 loss_rnnt 7.932445 lr 0.00049200 rank 1
2022-12-04 09:39:21,669 DEBUG TRAIN Batch 12/3200 loss 17.071087 loss_att 21.081852 loss_ctc 30.409142 loss_rnnt 14.490525 lr 0.00049209 rank 6
2022-12-04 09:39:21,670 DEBUG TRAIN Batch 12/3200 loss 7.080793 loss_att 12.795529 loss_ctc 17.520330 loss_rnnt 4.545907 lr 0.00049211 rank 5
2022-12-04 09:39:21,671 DEBUG TRAIN Batch 12/3200 loss 8.633013 loss_att 10.102925 loss_ctc 15.917773 loss_rnnt 7.367729 lr 0.00049198 rank 7
2022-12-04 09:39:21,677 DEBUG TRAIN Batch 12/3200 loss 7.869316 loss_att 7.850117 loss_ctc 11.718349 loss_rnnt 7.359951 lr 0.00049184 rank 2
2022-12-04 09:39:21,691 DEBUG TRAIN Batch 12/3200 loss 9.699179 loss_att 12.857140 loss_ctc 15.306280 loss_rnnt 8.319973 lr 0.00049214 rank 4
2022-12-04 09:40:33,381 DEBUG TRAIN Batch 12/3300 loss 13.082653 loss_att 18.114464 loss_ctc 21.949078 loss_rnnt 10.894100 lr 0.00049185 rank 6
2022-12-04 09:40:33,387 DEBUG TRAIN Batch 12/3300 loss 3.863232 loss_att 7.893789 loss_ctc 7.559482 loss_rnnt 2.564287 lr 0.00049190 rank 4
2022-12-04 09:40:33,387 DEBUG TRAIN Batch 12/3300 loss 13.705678 loss_att 15.971718 loss_ctc 21.341742 loss_rnnt 12.234328 lr 0.00049187 rank 5
2022-12-04 09:40:33,388 DEBUG TRAIN Batch 12/3300 loss 13.584892 loss_att 16.390276 loss_ctc 23.893085 loss_rnnt 11.649388 lr 0.00049170 rank 3
2022-12-04 09:40:33,388 DEBUG TRAIN Batch 12/3300 loss 7.669963 loss_att 13.536327 loss_ctc 13.206435 loss_rnnt 5.758494 lr 0.00049160 rank 2
2022-12-04 09:40:33,390 DEBUG TRAIN Batch 12/3300 loss 9.604310 loss_att 13.523082 loss_ctc 22.628315 loss_rnnt 7.084022 lr 0.00049174 rank 7
2022-12-04 09:40:33,390 DEBUG TRAIN Batch 12/3300 loss 5.178622 loss_att 9.819863 loss_ctc 9.144939 loss_rnnt 3.721531 lr 0.00049181 rank 0
2022-12-04 09:40:33,390 DEBUG TRAIN Batch 12/3300 loss 15.639324 loss_att 23.822897 loss_ctc 35.980267 loss_rnnt 11.290483 lr 0.00049176 rank 1
2022-12-04 09:41:44,395 DEBUG TRAIN Batch 12/3400 loss 21.824703 loss_att 26.748381 loss_ctc 31.426825 loss_rnnt 19.559685 lr 0.00049158 rank 0
2022-12-04 09:41:44,403 DEBUG TRAIN Batch 12/3400 loss 23.260393 loss_att 29.079269 loss_ctc 43.827789 loss_rnnt 19.354298 lr 0.00049153 rank 1
2022-12-04 09:41:44,404 DEBUG TRAIN Batch 12/3400 loss 11.641323 loss_att 16.291393 loss_ctc 14.950999 loss_rnnt 10.270019 lr 0.00049136 rank 2
2022-12-04 09:41:44,405 DEBUG TRAIN Batch 12/3400 loss 8.810957 loss_att 11.872520 loss_ctc 14.282173 loss_rnnt 7.469149 lr 0.00049161 rank 6
2022-12-04 09:41:44,408 DEBUG TRAIN Batch 12/3400 loss 9.285999 loss_att 10.964943 loss_ctc 13.330450 loss_rnnt 8.410950 lr 0.00049166 rank 4
2022-12-04 09:41:44,409 DEBUG TRAIN Batch 12/3400 loss 21.200556 loss_att 30.374577 loss_ctc 39.330490 loss_rnnt 16.948427 lr 0.00049150 rank 7
2022-12-04 09:41:44,410 DEBUG TRAIN Batch 12/3400 loss 16.781002 loss_att 19.068207 loss_ctc 24.588076 loss_rnnt 15.282619 lr 0.00049163 rank 5
2022-12-04 09:41:44,414 DEBUG TRAIN Batch 12/3400 loss 16.057785 loss_att 17.847610 loss_ctc 26.102518 loss_rnnt 14.360523 lr 0.00049146 rank 3
2022-12-04 09:42:56,984 DEBUG TRAIN Batch 12/3500 loss 10.728611 loss_att 14.731062 loss_ctc 19.077692 loss_rnnt 8.814910 lr 0.00049140 rank 5
2022-12-04 09:42:56,995 DEBUG TRAIN Batch 12/3500 loss 18.490963 loss_att 22.264091 loss_ctc 29.760082 loss_rnnt 16.233788 lr 0.00049137 rank 6
2022-12-04 09:42:56,999 DEBUG TRAIN Batch 12/3500 loss 10.110795 loss_att 16.702999 loss_ctc 24.798328 loss_rnnt 6.834016 lr 0.00049134 rank 0
2022-12-04 09:42:57,000 DEBUG TRAIN Batch 12/3500 loss 17.526600 loss_att 25.866463 loss_ctc 28.493324 loss_rnnt 14.396397 lr 0.00049129 rank 1
2022-12-04 09:42:57,001 DEBUG TRAIN Batch 12/3500 loss 17.939362 loss_att 19.218380 loss_ctc 25.590921 loss_rnnt 16.663351 lr 0.00049122 rank 3
2022-12-04 09:42:57,003 DEBUG TRAIN Batch 12/3500 loss 19.145569 loss_att 23.815836 loss_ctc 30.862043 loss_rnnt 16.649319 lr 0.00049112 rank 2
2022-12-04 09:42:57,025 DEBUG TRAIN Batch 12/3500 loss 9.377619 loss_att 14.300366 loss_ctc 19.599384 loss_rnnt 7.030167 lr 0.00049143 rank 4
2022-12-04 09:42:57,043 DEBUG TRAIN Batch 12/3500 loss 21.603743 loss_att 26.089287 loss_ctc 33.219376 loss_rnnt 19.157883 lr 0.00049126 rank 7
2022-12-04 09:44:10,661 DEBUG TRAIN Batch 12/3600 loss 5.174126 loss_att 9.553017 loss_ctc 11.434626 loss_rnnt 3.463614 lr 0.00049110 rank 0
2022-12-04 09:44:10,662 DEBUG TRAIN Batch 12/3600 loss 14.647558 loss_att 16.773245 loss_ctc 20.936653 loss_rnnt 13.383875 lr 0.00049114 rank 6
2022-12-04 09:44:10,664 DEBUG TRAIN Batch 12/3600 loss 12.144232 loss_att 13.752982 loss_ctc 19.900272 loss_rnnt 10.788343 lr 0.00049116 rank 5
2022-12-04 09:44:10,665 DEBUG TRAIN Batch 12/3600 loss 7.482376 loss_att 10.898236 loss_ctc 12.597679 loss_rnnt 6.117163 lr 0.00049105 rank 1
2022-12-04 09:44:10,668 DEBUG TRAIN Batch 12/3600 loss 10.487780 loss_att 12.304797 loss_ctc 15.849281 loss_rnnt 9.409510 lr 0.00049098 rank 3
2022-12-04 09:44:10,670 DEBUG TRAIN Batch 12/3600 loss 11.474903 loss_att 13.761999 loss_ctc 17.917744 loss_rnnt 10.158438 lr 0.00049089 rank 2
2022-12-04 09:44:10,674 DEBUG TRAIN Batch 12/3600 loss 9.269852 loss_att 13.820388 loss_ctc 16.371891 loss_rnnt 7.412806 lr 0.00049103 rank 7
2022-12-04 09:44:10,678 DEBUG TRAIN Batch 12/3600 loss 9.971385 loss_att 16.026196 loss_ctc 18.983906 loss_rnnt 7.558753 lr 0.00049119 rank 4
2022-12-04 09:45:22,745 DEBUG TRAIN Batch 12/3700 loss 14.680412 loss_att 19.017000 loss_ctc 19.175331 loss_rnnt 13.213774 lr 0.00049086 rank 0
2022-12-04 09:45:22,745 DEBUG TRAIN Batch 12/3700 loss 7.095348 loss_att 9.631147 loss_ctc 14.976610 loss_rnnt 5.537354 lr 0.00049081 rank 1
2022-12-04 09:45:22,748 DEBUG TRAIN Batch 12/3700 loss 9.428997 loss_att 12.395637 loss_ctc 16.837461 loss_rnnt 7.847874 lr 0.00049092 rank 5
2022-12-04 09:45:22,748 DEBUG TRAIN Batch 12/3700 loss 17.593681 loss_att 18.607117 loss_ctc 30.285908 loss_rnnt 15.698698 lr 0.00049090 rank 6
2022-12-04 09:45:22,752 DEBUG TRAIN Batch 12/3700 loss 13.055163 loss_att 16.587715 loss_ctc 21.530294 loss_rnnt 11.218636 lr 0.00049095 rank 4
2022-12-04 09:45:22,752 DEBUG TRAIN Batch 12/3700 loss 9.757822 loss_att 11.848473 loss_ctc 15.195744 loss_rnnt 8.614635 lr 0.00049065 rank 2
2022-12-04 09:45:22,753 DEBUG TRAIN Batch 12/3700 loss 9.008235 loss_att 12.668556 loss_ctc 14.861372 loss_rnnt 7.495751 lr 0.00049075 rank 3
2022-12-04 09:45:22,763 DEBUG TRAIN Batch 12/3700 loss 10.607377 loss_att 13.513920 loss_ctc 15.080286 loss_rnnt 9.429680 lr 0.00049079 rank 7
2022-12-04 09:46:33,931 DEBUG TRAIN Batch 12/3800 loss 11.705381 loss_att 14.487726 loss_ctc 21.300083 loss_rnnt 9.869619 lr 0.00049066 rank 6
2022-12-04 09:46:33,937 DEBUG TRAIN Batch 12/3800 loss 20.609785 loss_att 20.718596 loss_ctc 33.202339 loss_rnnt 18.909016 lr 0.00049051 rank 3
2022-12-04 09:46:33,939 DEBUG TRAIN Batch 12/3800 loss 21.034000 loss_att 22.157316 loss_ctc 31.340618 loss_rnnt 19.435123 lr 0.00049063 rank 0
2022-12-04 09:46:33,939 DEBUG TRAIN Batch 12/3800 loss 12.028237 loss_att 11.901440 loss_ctc 16.949886 loss_rnnt 11.397377 lr 0.00049069 rank 5
2022-12-04 09:46:33,941 DEBUG TRAIN Batch 12/3800 loss 19.457687 loss_att 20.826242 loss_ctc 30.300709 loss_rnnt 17.738241 lr 0.00049042 rank 2
2022-12-04 09:46:33,947 DEBUG TRAIN Batch 12/3800 loss 13.325804 loss_att 14.981634 loss_ctc 18.181686 loss_rnnt 12.347187 lr 0.00049058 rank 1
2022-12-04 09:46:33,950 DEBUG TRAIN Batch 12/3800 loss 10.550210 loss_att 10.546446 loss_ctc 15.145605 loss_rnnt 9.938243 lr 0.00049072 rank 4
2022-12-04 09:46:33,953 DEBUG TRAIN Batch 12/3800 loss 10.893996 loss_att 14.303785 loss_ctc 16.012089 loss_rnnt 9.529626 lr 0.00049055 rank 7
2022-12-04 09:47:48,120 DEBUG TRAIN Batch 12/3900 loss 24.210609 loss_att 30.876949 loss_ctc 38.637043 loss_rnnt 20.953817 lr 0.00049039 rank 0
2022-12-04 09:47:48,120 DEBUG TRAIN Batch 12/3900 loss 12.042017 loss_att 12.558281 loss_ctc 17.869532 loss_rnnt 11.161762 lr 0.00049032 rank 7
2022-12-04 09:47:48,121 DEBUG TRAIN Batch 12/3900 loss 9.996035 loss_att 12.871588 loss_ctc 18.543882 loss_rnnt 8.281211 lr 0.00049028 rank 3
2022-12-04 09:47:48,127 DEBUG TRAIN Batch 12/3900 loss 9.456575 loss_att 12.792997 loss_ctc 15.561183 loss_rnnt 7.975343 lr 0.00049043 rank 6
2022-12-04 09:47:48,132 DEBUG TRAIN Batch 12/3900 loss 8.720096 loss_att 14.793718 loss_ctc 19.782600 loss_rnnt 6.030371 lr 0.00049048 rank 4
2022-12-04 09:47:48,148 DEBUG TRAIN Batch 12/3900 loss 9.377033 loss_att 14.590484 loss_ctc 15.897982 loss_rnnt 7.464883 lr 0.00049045 rank 5
2022-12-04 09:47:48,174 DEBUG TRAIN Batch 12/3900 loss 11.532409 loss_att 13.818272 loss_ctc 21.165112 loss_rnnt 9.790876 lr 0.00049018 rank 2
2022-12-04 09:47:48,178 DEBUG TRAIN Batch 12/3900 loss 4.933251 loss_att 8.643262 loss_ctc 11.905140 loss_rnnt 3.261664 lr 0.00049034 rank 1
2022-12-04 09:48:59,379 DEBUG TRAIN Batch 12/4000 loss 21.140404 loss_att 30.740986 loss_ctc 34.836655 loss_rnnt 17.394119 lr 0.00049019 rank 6
2022-12-04 09:48:59,381 DEBUG TRAIN Batch 12/4000 loss 8.696091 loss_att 13.343188 loss_ctc 14.081683 loss_rnnt 7.048592 lr 0.00049004 rank 3
2022-12-04 09:48:59,383 DEBUG TRAIN Batch 12/4000 loss 22.605547 loss_att 28.670841 loss_ctc 29.394146 loss_rnnt 20.487341 lr 0.00049016 rank 0
2022-12-04 09:48:59,387 DEBUG TRAIN Batch 12/4000 loss 11.678706 loss_att 17.009504 loss_ctc 14.202441 loss_rnnt 10.276048 lr 0.00048994 rank 2
2022-12-04 09:48:59,388 DEBUG TRAIN Batch 12/4000 loss 12.352114 loss_att 17.445030 loss_ctc 17.011070 loss_rnnt 10.712336 lr 0.00049021 rank 5
2022-12-04 09:48:59,389 DEBUG TRAIN Batch 12/4000 loss 14.311370 loss_att 19.891466 loss_ctc 18.712749 loss_rnnt 12.608500 lr 0.00049024 rank 4
2022-12-04 09:48:59,390 DEBUG TRAIN Batch 12/4000 loss 15.556765 loss_att 17.420277 loss_ctc 24.683571 loss_rnnt 13.967155 lr 0.00049011 rank 1
2022-12-04 09:48:59,391 DEBUG TRAIN Batch 12/4000 loss 16.211634 loss_att 19.302544 loss_ctc 27.820349 loss_rnnt 14.045624 lr 0.00049008 rank 7
2022-12-04 09:50:11,102 DEBUG TRAIN Batch 12/4100 loss 29.157814 loss_att 38.551399 loss_ctc 49.634792 loss_rnnt 24.548832 lr 0.00048987 rank 1
2022-12-04 09:50:11,105 DEBUG TRAIN Batch 12/4100 loss 16.608770 loss_att 22.036980 loss_ctc 23.114498 loss_rnnt 14.655698 lr 0.00048992 rank 0
2022-12-04 09:50:11,106 DEBUG TRAIN Batch 12/4100 loss 4.408535 loss_att 9.386596 loss_ctc 9.588059 loss_rnnt 2.722319 lr 0.00048985 rank 7
2022-12-04 09:50:11,107 DEBUG TRAIN Batch 12/4100 loss 14.771858 loss_att 16.945246 loss_ctc 23.196499 loss_rnnt 13.213896 lr 0.00048981 rank 3
2022-12-04 09:50:11,109 DEBUG TRAIN Batch 12/4100 loss 17.681414 loss_att 24.959166 loss_ctc 32.579018 loss_rnnt 14.239515 lr 0.00048996 rank 6
2022-12-04 09:50:11,111 DEBUG TRAIN Batch 12/4100 loss 15.983574 loss_att 18.929794 loss_ctc 25.066425 loss_rnnt 14.183283 lr 0.00049001 rank 4
2022-12-04 09:50:11,144 DEBUG TRAIN Batch 12/4100 loss 13.157963 loss_att 19.295927 loss_ctc 26.716778 loss_rnnt 10.122528 lr 0.00048971 rank 2
2022-12-04 09:50:11,177 DEBUG TRAIN Batch 12/4100 loss 4.914196 loss_att 9.187504 loss_ctc 6.850982 loss_rnnt 3.801296 lr 0.00048998 rank 5
2022-12-04 09:51:23,377 DEBUG TRAIN Batch 12/4200 loss 12.022882 loss_att 18.604095 loss_ctc 20.584751 loss_rnnt 9.565058 lr 0.00048961 rank 7
2022-12-04 09:51:23,380 DEBUG TRAIN Batch 12/4200 loss 14.558064 loss_att 19.957642 loss_ctc 24.810184 loss_rnnt 12.111198 lr 0.00048974 rank 5
2022-12-04 09:51:23,380 DEBUG TRAIN Batch 12/4200 loss 21.220158 loss_att 24.594212 loss_ctc 39.746227 loss_rnnt 18.075203 lr 0.00048972 rank 6
2022-12-04 09:51:23,381 DEBUG TRAIN Batch 12/4200 loss 11.873702 loss_att 14.605186 loss_ctc 20.049646 loss_rnnt 10.237279 lr 0.00048957 rank 3
2022-12-04 09:51:23,390 DEBUG TRAIN Batch 12/4200 loss 20.236115 loss_att 21.527359 loss_ctc 32.078659 loss_rnnt 18.398857 lr 0.00048969 rank 0
2022-12-04 09:51:23,393 DEBUG TRAIN Batch 12/4200 loss 9.554081 loss_att 10.954789 loss_ctc 16.403542 loss_rnnt 8.360678 lr 0.00048947 rank 2
2022-12-04 09:51:23,396 DEBUG TRAIN Batch 12/4200 loss 15.248787 loss_att 23.278954 loss_ctc 29.966248 loss_rnnt 11.680425 lr 0.00048964 rank 1
2022-12-04 09:51:23,397 DEBUG TRAIN Batch 12/4200 loss 16.193373 loss_att 19.095760 loss_ctc 24.109650 loss_rnnt 14.557390 lr 0.00048977 rank 4
2022-12-04 09:52:36,488 DEBUG TRAIN Batch 12/4300 loss 9.977821 loss_att 11.872061 loss_ctc 19.497267 loss_rnnt 8.329714 lr 0.00048934 rank 3
2022-12-04 09:52:36,492 DEBUG TRAIN Batch 12/4300 loss 18.121040 loss_att 24.293949 loss_ctc 30.275761 loss_rnnt 15.265827 lr 0.00048945 rank 0
2022-12-04 09:52:36,492 DEBUG TRAIN Batch 12/4300 loss 11.032444 loss_att 13.150782 loss_ctc 13.478872 loss_rnnt 10.282586 lr 0.00048940 rank 1
2022-12-04 09:52:36,495 DEBUG TRAIN Batch 12/4300 loss 6.008534 loss_att 9.450322 loss_ctc 10.295436 loss_rnnt 4.748590 lr 0.00048954 rank 4
2022-12-04 09:52:36,495 DEBUG TRAIN Batch 12/4300 loss 5.903191 loss_att 9.190110 loss_ctc 9.743568 loss_rnnt 4.733757 lr 0.00048949 rank 6
2022-12-04 09:52:36,497 DEBUG TRAIN Batch 12/4300 loss 8.006093 loss_att 10.458303 loss_ctc 12.468796 loss_rnnt 6.920624 lr 0.00048924 rank 2
2022-12-04 09:52:36,503 DEBUG TRAIN Batch 12/4300 loss 11.569604 loss_att 14.625256 loss_ctc 18.557653 loss_rnnt 10.026733 lr 0.00048938 rank 7
2022-12-04 09:52:36,538 DEBUG TRAIN Batch 12/4300 loss 26.188715 loss_att 27.910210 loss_ctc 38.496780 loss_rnnt 24.203341 lr 0.00048951 rank 5
2022-12-04 09:53:47,977 DEBUG TRAIN Batch 12/4400 loss 20.505835 loss_att 25.710981 loss_ctc 33.067093 loss_rnnt 17.789970 lr 0.00048910 rank 3
2022-12-04 09:53:47,982 DEBUG TRAIN Batch 12/4400 loss 9.421391 loss_att 12.376979 loss_ctc 19.102644 loss_rnnt 7.539440 lr 0.00048928 rank 5
2022-12-04 09:53:47,989 DEBUG TRAIN Batch 12/4400 loss 8.742433 loss_att 11.561366 loss_ctc 14.037821 loss_rnnt 7.472594 lr 0.00048914 rank 7
2022-12-04 09:53:47,991 DEBUG TRAIN Batch 12/4400 loss 11.619150 loss_att 15.235865 loss_ctc 19.901674 loss_rnnt 9.791471 lr 0.00048925 rank 6
2022-12-04 09:53:48,002 DEBUG TRAIN Batch 12/4400 loss 8.136232 loss_att 8.848130 loss_ctc 14.549814 loss_rnnt 7.138708 lr 0.00048930 rank 4
2022-12-04 09:53:48,018 DEBUG TRAIN Batch 12/4400 loss 6.534520 loss_att 9.745890 loss_ctc 11.192101 loss_rnnt 5.271235 lr 0.00048922 rank 0
2022-12-04 09:53:48,019 DEBUG TRAIN Batch 12/4400 loss 8.007268 loss_att 10.765541 loss_ctc 13.425226 loss_rnnt 6.733219 lr 0.00048901 rank 2
2022-12-04 09:53:48,037 DEBUG TRAIN Batch 12/4400 loss 15.309298 loss_att 18.312380 loss_ctc 24.519205 loss_rnnt 13.480693 lr 0.00048917 rank 1
2022-12-04 09:54:59,408 DEBUG TRAIN Batch 12/4500 loss 13.791561 loss_att 18.763657 loss_ctc 22.637381 loss_rnnt 11.617699 lr 0.00048907 rank 4
2022-12-04 09:54:59,418 DEBUG TRAIN Batch 12/4500 loss 7.774344 loss_att 13.336122 loss_ctc 15.245563 loss_rnnt 5.665826 lr 0.00048904 rank 5
2022-12-04 09:54:59,418 DEBUG TRAIN Batch 12/4500 loss 13.533358 loss_att 17.788845 loss_ctc 23.447733 loss_rnnt 11.360343 lr 0.00048902 rank 6
2022-12-04 09:54:59,419 DEBUG TRAIN Batch 12/4500 loss 15.204607 loss_att 19.956566 loss_ctc 23.851208 loss_rnnt 13.101336 lr 0.00048887 rank 3
2022-12-04 09:54:59,419 DEBUG TRAIN Batch 12/4500 loss 12.026472 loss_att 13.448069 loss_ctc 19.056210 loss_rnnt 10.804855 lr 0.00048891 rank 7
2022-12-04 09:54:59,418 DEBUG TRAIN Batch 12/4500 loss 7.584350 loss_att 11.632340 loss_ctc 11.458661 loss_rnnt 6.258176 lr 0.00048893 rank 1
2022-12-04 09:54:59,420 DEBUG TRAIN Batch 12/4500 loss 6.751123 loss_att 11.213343 loss_ctc 14.695715 loss_rnnt 4.799400 lr 0.00048898 rank 0
2022-12-04 09:54:59,425 DEBUG TRAIN Batch 12/4500 loss 7.723068 loss_att 12.088017 loss_ctc 14.712387 loss_rnnt 5.918169 lr 0.00048877 rank 2
2022-12-04 09:56:13,053 DEBUG TRAIN Batch 12/4600 loss 20.311743 loss_att 28.217268 loss_ctc 29.728474 loss_rnnt 17.475075 lr 0.00048870 rank 1
2022-12-04 09:56:13,063 DEBUG TRAIN Batch 12/4600 loss 12.492859 loss_att 21.909672 loss_ctc 32.688606 loss_rnnt 7.916730 lr 0.00048881 rank 5
2022-12-04 09:56:13,064 DEBUG TRAIN Batch 12/4600 loss 14.091984 loss_att 15.575739 loss_ctc 24.170761 loss_rnnt 12.451396 lr 0.00048863 rank 3
2022-12-04 09:56:13,067 DEBUG TRAIN Batch 12/4600 loss 11.024812 loss_att 13.986935 loss_ctc 20.335451 loss_rnnt 9.190968 lr 0.00048875 rank 0
2022-12-04 09:56:13,070 DEBUG TRAIN Batch 12/4600 loss 12.574597 loss_att 20.362713 loss_ctc 25.965210 loss_rnnt 9.231559 lr 0.00048868 rank 7
2022-12-04 09:56:13,079 DEBUG TRAIN Batch 12/4600 loss 15.943608 loss_att 21.201265 loss_ctc 26.698278 loss_rnnt 13.458120 lr 0.00048854 rank 2
2022-12-04 09:56:13,087 DEBUG TRAIN Batch 12/4600 loss 8.771991 loss_att 12.054994 loss_ctc 17.111090 loss_rnnt 7.003510 lr 0.00048884 rank 4
2022-12-04 09:56:13,094 DEBUG TRAIN Batch 12/4600 loss 14.478404 loss_att 19.835606 loss_ctc 31.164373 loss_rnnt 11.182167 lr 0.00048878 rank 6
2022-12-04 09:57:25,560 DEBUG TRAIN Batch 12/4700 loss 8.212480 loss_att 12.432418 loss_ctc 18.645628 loss_rnnt 5.977405 lr 0.00048855 rank 6
2022-12-04 09:57:25,566 DEBUG TRAIN Batch 12/4700 loss 13.028298 loss_att 15.950030 loss_ctc 22.468266 loss_rnnt 11.185289 lr 0.00048857 rank 5
2022-12-04 09:57:25,567 DEBUG TRAIN Batch 12/4700 loss 11.169819 loss_att 14.385447 loss_ctc 22.780872 loss_rnnt 8.978553 lr 0.00048852 rank 0
2022-12-04 09:57:25,569 DEBUG TRAIN Batch 12/4700 loss 13.699564 loss_att 16.814812 loss_ctc 24.334805 loss_rnnt 11.658484 lr 0.00048844 rank 7
2022-12-04 09:57:25,571 DEBUG TRAIN Batch 12/4700 loss 19.148594 loss_att 21.817333 loss_ctc 29.332167 loss_rnnt 17.257036 lr 0.00048840 rank 3
2022-12-04 09:57:25,574 DEBUG TRAIN Batch 12/4700 loss 12.211514 loss_att 18.686802 loss_ctc 20.809277 loss_rnnt 9.770087 lr 0.00048847 rank 1
2022-12-04 09:57:25,577 DEBUG TRAIN Batch 12/4700 loss 4.500752 loss_att 10.194374 loss_ctc 15.231781 loss_rnnt 1.931224 lr 0.00048860 rank 4
2022-12-04 09:57:25,578 DEBUG TRAIN Batch 12/4700 loss 9.335537 loss_att 12.335783 loss_ctc 15.182375 loss_rnnt 7.955909 lr 0.00048831 rank 2
2022-12-04 09:58:36,565 DEBUG TRAIN Batch 12/4800 loss 8.388351 loss_att 12.160488 loss_ctc 16.775137 loss_rnnt 6.515687 lr 0.00048817 rank 3
2022-12-04 09:58:36,566 DEBUG TRAIN Batch 12/4800 loss 10.143236 loss_att 12.537579 loss_ctc 16.806641 loss_rnnt 8.775913 lr 0.00048828 rank 0
2022-12-04 09:58:36,569 DEBUG TRAIN Batch 12/4800 loss 9.709927 loss_att 15.108725 loss_ctc 20.360836 loss_rnnt 7.210045 lr 0.00048807 rank 2
2022-12-04 09:58:36,569 DEBUG TRAIN Batch 12/4800 loss 12.946258 loss_att 15.240170 loss_ctc 17.668011 loss_rnnt 11.857907 lr 0.00048834 rank 5
2022-12-04 09:58:36,569 DEBUG TRAIN Batch 12/4800 loss 4.664999 loss_att 8.182639 loss_ctc 10.118429 loss_rnnt 3.234346 lr 0.00048832 rank 6
2022-12-04 09:58:36,573 DEBUG TRAIN Batch 12/4800 loss 11.245683 loss_att 16.382530 loss_ctc 23.115944 loss_rnnt 8.635612 lr 0.00048821 rank 7
2022-12-04 09:58:36,581 DEBUG TRAIN Batch 12/4800 loss 8.091578 loss_att 11.945574 loss_ctc 15.179993 loss_rnnt 6.375657 lr 0.00048837 rank 4
2022-12-04 09:58:36,582 DEBUG TRAIN Batch 12/4800 loss 9.951939 loss_att 12.205595 loss_ctc 12.702997 loss_rnnt 9.134399 lr 0.00048823 rank 1
2022-12-04 09:59:48,965 DEBUG TRAIN Batch 12/4900 loss 6.322284 loss_att 8.457258 loss_ctc 10.564921 loss_rnnt 5.329603 lr 0.00048794 rank 3
2022-12-04 09:59:48,979 DEBUG TRAIN Batch 12/4900 loss 18.979082 loss_att 22.914558 loss_ctc 26.776432 loss_rnnt 17.152340 lr 0.00048811 rank 5
2022-12-04 09:59:48,981 DEBUG TRAIN Batch 12/4900 loss 17.624596 loss_att 21.774681 loss_ctc 38.368626 loss_rnnt 14.028708 lr 0.00048808 rank 6
2022-12-04 09:59:48,987 DEBUG TRAIN Batch 12/4900 loss 11.867936 loss_att 15.971210 loss_ctc 14.918427 loss_rnnt 10.640550 lr 0.00048814 rank 4
2022-12-04 09:59:48,988 DEBUG TRAIN Batch 12/4900 loss 8.181535 loss_att 11.119093 loss_ctc 13.185023 loss_rnnt 6.926891 lr 0.00048798 rank 7
2022-12-04 09:59:48,988 DEBUG TRAIN Batch 12/4900 loss 11.863158 loss_att 13.571947 loss_ctc 18.908443 loss_rnnt 10.582029 lr 0.00048805 rank 0
2022-12-04 09:59:48,994 DEBUG TRAIN Batch 12/4900 loss 8.842273 loss_att 12.243789 loss_ctc 14.907431 loss_rnnt 7.353281 lr 0.00048784 rank 2
2022-12-04 09:59:48,998 DEBUG TRAIN Batch 12/4900 loss 20.847698 loss_att 20.500753 loss_ctc 27.775402 loss_rnnt 19.993393 lr 0.00048800 rank 1
2022-12-04 10:01:03,698 DEBUG TRAIN Batch 12/5000 loss 11.477223 loss_att 15.199179 loss_ctc 22.024504 loss_rnnt 9.326528 lr 0.00048788 rank 5
2022-12-04 10:01:03,701 DEBUG TRAIN Batch 12/5000 loss 13.991212 loss_att 13.411502 loss_ctc 19.698065 loss_rnnt 13.346239 lr 0.00048770 rank 3
2022-12-04 10:01:03,703 DEBUG TRAIN Batch 12/5000 loss 12.422854 loss_att 17.283024 loss_ctc 21.699251 loss_rnnt 10.213967 lr 0.00048782 rank 0
2022-12-04 10:01:03,703 DEBUG TRAIN Batch 12/5000 loss 28.182446 loss_att 28.328249 loss_ctc 44.310791 loss_rnnt 26.002838 lr 0.00048785 rank 6
2022-12-04 10:01:03,707 DEBUG TRAIN Batch 12/5000 loss 9.021579 loss_att 11.828647 loss_ctc 11.670119 loss_rnnt 8.107027 lr 0.00048761 rank 2
2022-12-04 10:01:03,707 DEBUG TRAIN Batch 12/5000 loss 12.047113 loss_att 16.827267 loss_ctc 26.070570 loss_rnnt 9.221288 lr 0.00048777 rank 1
2022-12-04 10:01:03,712 DEBUG TRAIN Batch 12/5000 loss 12.617565 loss_att 19.472645 loss_ctc 22.567982 loss_rnnt 9.919827 lr 0.00048790 rank 4
2022-12-04 10:01:03,713 DEBUG TRAIN Batch 12/5000 loss 8.901886 loss_att 11.680148 loss_ctc 16.144009 loss_rnnt 7.380618 lr 0.00048775 rank 7
2022-12-04 10:02:15,518 DEBUG TRAIN Batch 12/5100 loss 12.914482 loss_att 14.729616 loss_ctc 21.203659 loss_rnnt 11.446230 lr 0.00048762 rank 6
2022-12-04 10:02:15,519 DEBUG TRAIN Batch 12/5100 loss 12.402565 loss_att 14.375126 loss_ctc 17.243229 loss_rnnt 11.362631 lr 0.00048759 rank 0
2022-12-04 10:02:15,520 DEBUG TRAIN Batch 12/5100 loss 5.612500 loss_att 11.447043 loss_ctc 11.297415 loss_rnnt 3.687603 lr 0.00048747 rank 3
2022-12-04 10:02:15,522 DEBUG TRAIN Batch 12/5100 loss 11.472399 loss_att 11.874940 loss_ctc 17.111128 loss_rnnt 10.640059 lr 0.00048764 rank 5
2022-12-04 10:02:15,525 DEBUG TRAIN Batch 12/5100 loss 14.620519 loss_att 20.157623 loss_ctc 32.045181 loss_rnnt 11.189810 lr 0.00048767 rank 4
2022-12-04 10:02:15,526 DEBUG TRAIN Batch 12/5100 loss 15.683480 loss_att 17.599815 loss_ctc 26.652729 loss_rnnt 13.837646 lr 0.00048751 rank 7
2022-12-04 10:02:15,527 DEBUG TRAIN Batch 12/5100 loss 15.656114 loss_att 14.590195 loss_ctc 20.375170 loss_rnnt 15.240090 lr 0.00048754 rank 1
2022-12-04 10:02:15,574 DEBUG TRAIN Batch 12/5100 loss 11.366045 loss_att 13.271219 loss_ctc 16.706171 loss_rnnt 10.272993 lr 0.00048738 rank 2
2022-12-04 10:03:27,936 DEBUG TRAIN Batch 12/5200 loss 10.741698 loss_att 16.897892 loss_ctc 19.784763 loss_rnnt 8.304717 lr 0.00048741 rank 5
2022-12-04 10:03:27,937 DEBUG TRAIN Batch 12/5200 loss 20.337412 loss_att 22.391563 loss_ctc 30.860685 loss_rnnt 18.523479 lr 0.00048731 rank 1
2022-12-04 10:03:27,938 DEBUG TRAIN Batch 12/5200 loss 7.581425 loss_att 11.520636 loss_ctc 13.027266 loss_rnnt 6.067470 lr 0.00048715 rank 2
2022-12-04 10:03:27,939 DEBUG TRAIN Batch 12/5200 loss 10.690158 loss_att 15.212433 loss_ctc 19.569090 loss_rnnt 8.601845 lr 0.00048739 rank 6
2022-12-04 10:03:27,942 DEBUG TRAIN Batch 12/5200 loss 21.578522 loss_att 25.776127 loss_ctc 39.919643 loss_rnnt 18.293518 lr 0.00048724 rank 3
2022-12-04 10:03:27,943 DEBUG TRAIN Batch 12/5200 loss 7.452704 loss_att 11.044783 loss_ctc 12.849211 loss_rnnt 6.014755 lr 0.00048735 rank 0
2022-12-04 10:03:27,945 DEBUG TRAIN Batch 12/5200 loss 6.273952 loss_att 10.583853 loss_ctc 13.779871 loss_rnnt 4.411182 lr 0.00048744 rank 4
2022-12-04 10:03:27,946 DEBUG TRAIN Batch 12/5200 loss 11.228329 loss_att 14.400063 loss_ctc 15.970561 loss_rnnt 9.961684 lr 0.00048728 rank 7
2022-12-04 10:04:41,042 DEBUG TRAIN Batch 12/5300 loss 6.620813 loss_att 10.040106 loss_ctc 11.704631 loss_rnnt 5.259113 lr 0.00048718 rank 5
2022-12-04 10:04:41,048 DEBUG TRAIN Batch 12/5300 loss 6.020596 loss_att 8.353108 loss_ctc 13.031771 loss_rnnt 4.619269 lr 0.00048691 rank 2
2022-12-04 10:04:41,058 DEBUG TRAIN Batch 12/5300 loss 19.788599 loss_att 26.601509 loss_ctc 39.831730 loss_rnnt 15.753599 lr 0.00048712 rank 0
2022-12-04 10:04:41,058 DEBUG TRAIN Batch 12/5300 loss 9.333448 loss_att 11.784976 loss_ctc 16.522377 loss_rnnt 7.884618 lr 0.00048707 rank 1
2022-12-04 10:04:41,061 DEBUG TRAIN Batch 12/5300 loss 11.508118 loss_att 14.655506 loss_ctc 22.829458 loss_rnnt 9.369127 lr 0.00048705 rank 7
2022-12-04 10:04:41,062 DEBUG TRAIN Batch 12/5300 loss 17.476585 loss_att 21.655489 loss_ctc 25.982534 loss_rnnt 15.506678 lr 0.00048721 rank 4
2022-12-04 10:04:41,063 DEBUG TRAIN Batch 12/5300 loss 13.150999 loss_att 19.566372 loss_ctc 20.656034 loss_rnnt 10.867254 lr 0.00048716 rank 6
2022-12-04 10:04:41,066 DEBUG TRAIN Batch 12/5300 loss 14.595068 loss_att 15.947250 loss_ctc 22.247236 loss_rnnt 13.304342 lr 0.00048701 rank 3
2022-12-04 10:05:53,354 DEBUG TRAIN Batch 12/5400 loss 12.397484 loss_att 15.525026 loss_ctc 18.932823 loss_rnnt 10.900597 lr 0.00048693 rank 6
2022-12-04 10:05:53,355 DEBUG TRAIN Batch 12/5400 loss 15.977459 loss_att 18.260704 loss_ctc 21.820831 loss_rnnt 14.741694 lr 0.00048689 rank 0
2022-12-04 10:05:53,356 DEBUG TRAIN Batch 12/5400 loss 13.002460 loss_att 16.550283 loss_ctc 23.063976 loss_rnnt 10.951362 lr 0.00048678 rank 3
2022-12-04 10:05:53,359 DEBUG TRAIN Batch 12/5400 loss 11.416108 loss_att 15.048231 loss_ctc 19.325541 loss_rnnt 9.635093 lr 0.00048684 rank 1
2022-12-04 10:05:53,359 DEBUG TRAIN Batch 12/5400 loss 5.925978 loss_att 10.171408 loss_ctc 11.571002 loss_rnnt 4.324223 lr 0.00048668 rank 2
2022-12-04 10:05:53,361 DEBUG TRAIN Batch 12/5400 loss 13.110945 loss_att 17.252758 loss_ctc 22.868179 loss_rnnt 10.981618 lr 0.00048682 rank 7
2022-12-04 10:05:53,390 DEBUG TRAIN Batch 12/5400 loss 6.604399 loss_att 10.728909 loss_ctc 15.046546 loss_rnnt 4.653878 lr 0.00048695 rank 5
2022-12-04 10:05:53,393 DEBUG TRAIN Batch 12/5400 loss 15.621978 loss_att 21.214466 loss_ctc 25.246403 loss_rnnt 13.220223 lr 0.00048698 rank 4
2022-12-04 10:07:05,085 DEBUG TRAIN Batch 12/5500 loss 13.254734 loss_att 16.779789 loss_ctc 19.459648 loss_rnnt 11.722401 lr 0.00048675 rank 4
2022-12-04 10:07:05,093 DEBUG TRAIN Batch 12/5500 loss 3.863273 loss_att 7.215494 loss_ctc 6.603405 loss_rnnt 2.827478 lr 0.00048670 rank 6
2022-12-04 10:07:05,098 DEBUG TRAIN Batch 12/5500 loss 15.698896 loss_att 17.620419 loss_ctc 28.992407 loss_rnnt 13.542124 lr 0.00048666 rank 0
2022-12-04 10:07:05,099 DEBUG TRAIN Batch 12/5500 loss 13.108285 loss_att 18.559803 loss_ctc 20.034929 loss_rnnt 11.094428 lr 0.00048672 rank 5
2022-12-04 10:07:05,101 DEBUG TRAIN Batch 12/5500 loss 12.909721 loss_att 17.197620 loss_ctc 19.116173 loss_rnnt 11.224615 lr 0.00048655 rank 3
2022-12-04 10:07:05,102 DEBUG TRAIN Batch 12/5500 loss 5.702220 loss_att 10.425419 loss_ctc 12.939139 loss_rnnt 3.792658 lr 0.00048659 rank 7
2022-12-04 10:07:05,110 DEBUG TRAIN Batch 12/5500 loss 19.503241 loss_att 22.380276 loss_ctc 38.528221 loss_rnnt 16.391169 lr 0.00048645 rank 2
2022-12-04 10:07:05,118 DEBUG TRAIN Batch 12/5500 loss 12.102313 loss_att 15.899386 loss_ctc 19.258245 loss_rnnt 10.388775 lr 0.00048661 rank 1
2022-12-04 10:08:16,526 DEBUG TRAIN Batch 12/5600 loss 12.481153 loss_att 18.016155 loss_ctc 18.050283 loss_rnnt 10.631601 lr 0.00048652 rank 4
2022-12-04 10:08:16,537 DEBUG TRAIN Batch 12/5600 loss 13.969369 loss_att 17.866756 loss_ctc 19.409840 loss_rnnt 12.464495 lr 0.00048632 rank 3
2022-12-04 10:08:16,538 DEBUG TRAIN Batch 12/5600 loss 10.765481 loss_att 13.085783 loss_ctc 20.327408 loss_rnnt 9.026497 lr 0.00048647 rank 6
2022-12-04 10:08:16,539 DEBUG TRAIN Batch 12/5600 loss 8.867991 loss_att 14.535564 loss_ctc 20.195107 loss_rnnt 6.224195 lr 0.00048649 rank 5
2022-12-04 10:08:16,540 DEBUG TRAIN Batch 12/5600 loss 23.029240 loss_att 27.035992 loss_ctc 39.223396 loss_rnnt 20.068666 lr 0.00048636 rank 7
2022-12-04 10:08:16,541 DEBUG TRAIN Batch 12/5600 loss 7.705015 loss_att 10.203378 loss_ctc 13.451168 loss_rnnt 6.439188 lr 0.00048643 rank 0
2022-12-04 10:08:16,560 DEBUG TRAIN Batch 12/5600 loss 9.836573 loss_att 13.312188 loss_ctc 15.195886 loss_rnnt 8.426874 lr 0.00048622 rank 2
2022-12-04 10:08:16,580 DEBUG TRAIN Batch 12/5600 loss 11.608610 loss_att 15.738271 loss_ctc 23.465759 loss_rnnt 9.201725 lr 0.00048638 rank 1
2022-12-04 10:09:31,125 DEBUG TRAIN Batch 12/5700 loss 12.185821 loss_att 16.250292 loss_ctc 23.906481 loss_rnnt 9.810171 lr 0.00048624 rank 6
2022-12-04 10:09:31,126 DEBUG TRAIN Batch 12/5700 loss 20.125053 loss_att 22.951742 loss_ctc 32.479568 loss_rnnt 17.912449 lr 0.00048609 rank 3
2022-12-04 10:09:31,128 DEBUG TRAIN Batch 12/5700 loss 12.437259 loss_att 14.341285 loss_ctc 18.731684 loss_rnnt 11.217197 lr 0.00048615 rank 1
2022-12-04 10:09:31,128 DEBUG TRAIN Batch 12/5700 loss 8.316332 loss_att 13.119920 loss_ctc 13.335425 loss_rnnt 6.686401 lr 0.00048626 rank 5
2022-12-04 10:09:31,129 DEBUG TRAIN Batch 12/5700 loss 13.579103 loss_att 13.063079 loss_ctc 18.212944 loss_rnnt 13.064461 lr 0.00048620 rank 0
2022-12-04 10:09:31,132 DEBUG TRAIN Batch 12/5700 loss 10.277782 loss_att 11.777113 loss_ctc 15.613566 loss_rnnt 9.266479 lr 0.00048629 rank 4
2022-12-04 10:09:31,134 DEBUG TRAIN Batch 12/5700 loss 8.969377 loss_att 10.475281 loss_ctc 15.822528 loss_rnnt 7.754442 lr 0.00048599 rank 2
2022-12-04 10:09:31,135 DEBUG TRAIN Batch 12/5700 loss 10.596436 loss_att 12.526224 loss_ctc 16.293579 loss_rnnt 9.450858 lr 0.00048613 rank 7
2022-12-04 10:10:42,622 DEBUG TRAIN Batch 12/5800 loss 9.520044 loss_att 15.279848 loss_ctc 15.838431 loss_rnnt 7.525631 lr 0.00048586 rank 3
2022-12-04 10:10:42,634 DEBUG TRAIN Batch 12/5800 loss 13.232297 loss_att 18.214760 loss_ctc 23.732758 loss_rnnt 10.835743 lr 0.00048601 rank 6
2022-12-04 10:10:42,636 DEBUG TRAIN Batch 12/5800 loss 5.758195 loss_att 11.158609 loss_ctc 8.823232 loss_rnnt 4.269441 lr 0.00048590 rank 7
2022-12-04 10:10:42,638 DEBUG TRAIN Batch 12/5800 loss 3.680719 loss_att 7.190439 loss_ctc 5.942367 loss_rnnt 2.677223 lr 0.00048597 rank 0
2022-12-04 10:10:42,640 DEBUG TRAIN Batch 12/5800 loss 14.598265 loss_att 19.289324 loss_ctc 29.884899 loss_rnnt 11.621834 lr 0.00048592 rank 1
2022-12-04 10:10:42,640 DEBUG TRAIN Batch 12/5800 loss 9.293077 loss_att 11.660402 loss_ctc 16.990604 loss_rnnt 7.793274 lr 0.00048576 rank 2
2022-12-04 10:10:42,643 DEBUG TRAIN Batch 12/5800 loss 10.290883 loss_att 13.800301 loss_ctc 17.514709 loss_rnnt 8.625823 lr 0.00048603 rank 5
2022-12-04 10:10:42,646 DEBUG TRAIN Batch 12/5800 loss 8.529061 loss_att 12.499455 loss_ctc 14.416088 loss_rnnt 6.950046 lr 0.00048606 rank 4
2022-12-04 10:11:54,610 DEBUG TRAIN Batch 12/5900 loss 14.204306 loss_att 17.179039 loss_ctc 26.070745 loss_rnnt 12.027167 lr 0.00048578 rank 6
2022-12-04 10:11:54,615 DEBUG TRAIN Batch 12/5900 loss 8.132496 loss_att 12.515105 loss_ctc 20.733812 loss_rnnt 5.575798 lr 0.00048580 rank 5
2022-12-04 10:11:54,616 DEBUG TRAIN Batch 12/5900 loss 5.120912 loss_att 11.055296 loss_ctc 10.077623 loss_rnnt 3.273140 lr 0.00048554 rank 2
2022-12-04 10:11:54,617 DEBUG TRAIN Batch 12/5900 loss 16.991869 loss_att 19.629921 loss_ctc 26.031929 loss_rnnt 15.258917 lr 0.00048574 rank 0
2022-12-04 10:11:54,621 DEBUG TRAIN Batch 12/5900 loss 8.758590 loss_att 11.653369 loss_ctc 11.196989 loss_rnnt 7.854514 lr 0.00048567 rank 7
2022-12-04 10:11:54,621 DEBUG TRAIN Batch 12/5900 loss 17.872883 loss_att 23.682959 loss_ctc 29.855980 loss_rnnt 15.113121 lr 0.00048563 rank 3
2022-12-04 10:11:54,626 DEBUG TRAIN Batch 12/5900 loss 7.340107 loss_att 10.181343 loss_ctc 13.699760 loss_rnnt 5.923906 lr 0.00048569 rank 1
2022-12-04 10:11:54,642 DEBUG TRAIN Batch 12/5900 loss 4.816589 loss_att 12.556975 loss_ctc 11.248634 loss_rnnt 2.410906 lr 0.00048583 rank 4
2022-12-04 10:13:07,505 DEBUG TRAIN Batch 12/6000 loss 12.500387 loss_att 17.999289 loss_ctc 27.166304 loss_rnnt 9.445150 lr 0.00048544 rank 7
2022-12-04 10:13:07,506 DEBUG TRAIN Batch 12/6000 loss 12.392285 loss_att 15.590865 loss_ctc 19.595778 loss_rnnt 10.792105 lr 0.00048546 rank 1
2022-12-04 10:13:07,519 DEBUG TRAIN Batch 12/6000 loss 5.077110 loss_att 9.453133 loss_ctc 10.674155 loss_rnnt 3.455633 lr 0.00048555 rank 6
2022-12-04 10:13:07,520 DEBUG TRAIN Batch 12/6000 loss 11.722102 loss_att 15.253694 loss_ctc 15.168640 loss_rnnt 10.556245 lr 0.00048540 rank 3
2022-12-04 10:13:07,523 DEBUG TRAIN Batch 12/6000 loss 15.513840 loss_att 16.692759 loss_ctc 24.844687 loss_rnnt 14.033943 lr 0.00048551 rank 0
2022-12-04 10:13:07,523 DEBUG TRAIN Batch 12/6000 loss 9.614788 loss_att 13.780968 loss_ctc 14.751972 loss_rnnt 8.096595 lr 0.00048557 rank 5
2022-12-04 10:13:07,528 DEBUG TRAIN Batch 12/6000 loss 15.879041 loss_att 19.709009 loss_ctc 25.037228 loss_rnnt 13.891955 lr 0.00048560 rank 4
2022-12-04 10:13:07,529 DEBUG TRAIN Batch 12/6000 loss 15.460587 loss_att 18.453360 loss_ctc 24.129438 loss_rnnt 13.706185 lr 0.00048531 rank 2
2022-12-04 10:14:20,554 DEBUG TRAIN Batch 12/6100 loss 11.845111 loss_att 17.093073 loss_ctc 19.728474 loss_rnnt 9.744404 lr 0.00048528 rank 0
2022-12-04 10:14:20,558 DEBUG TRAIN Batch 12/6100 loss 12.473658 loss_att 15.834494 loss_ctc 24.676987 loss_rnnt 10.174379 lr 0.00048521 rank 7
2022-12-04 10:14:20,569 DEBUG TRAIN Batch 12/6100 loss 21.362244 loss_att 28.227684 loss_ctc 35.525238 loss_rnnt 18.100758 lr 0.00048517 rank 3
2022-12-04 10:14:20,569 DEBUG TRAIN Batch 12/6100 loss 14.620214 loss_att 20.163721 loss_ctc 29.964230 loss_rnnt 11.465645 lr 0.00048532 rank 6
2022-12-04 10:14:20,574 DEBUG TRAIN Batch 12/6100 loss 7.089214 loss_att 12.115719 loss_ctc 14.879509 loss_rnnt 5.045207 lr 0.00048508 rank 2
2022-12-04 10:14:20,589 DEBUG TRAIN Batch 12/6100 loss 7.638306 loss_att 11.017217 loss_ctc 12.530761 loss_rnnt 6.310196 lr 0.00048524 rank 1
2022-12-04 10:14:20,595 DEBUG TRAIN Batch 12/6100 loss 14.769374 loss_att 15.715096 loss_ctc 19.689163 loss_rnnt 13.924257 lr 0.00048537 rank 4
2022-12-04 10:14:20,617 DEBUG TRAIN Batch 12/6100 loss 11.927731 loss_att 14.619688 loss_ctc 17.595560 loss_rnnt 10.633629 lr 0.00048534 rank 5
run_encoder_decoder_bias.sh: line 167:  2848 Terminated              python wenet/bin/train.py --gpu $gpu_id --config $train_config --data_type raw --symbol_table $dict --bpe_model ${bpemodel}.model --train_data $wave_data/$train_set/data.list --cv_data $wave_data/$dev_set/data.list ${checkpoint:+--checkpoint $checkpoint} --model_dir $dir --ddp.init_method $init_method --ddp.world_size $num_gpus --ddp.rank $i --ddp.dist_backend $dist_backend --num_workers 1 $cmvn_opts --pin_memory
Traceback (most recent call last):
  File "wenet/bin/train.py", line 297, in <module>
    main()
  File "wenet/bin/train.py", line 269, in main
    executor.train(model, optimizer, scheduler, train_data_loader, device,
  File "/home/work_nfs6/tyxu/workspace/wenet-rnnt-runtime/wenet/utils/executor.py", line 90, in train
    loss.backward()
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/autograd/__init__.py", line 154, in backward
    Variable._execution_engine.run_backward(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272172048/work/third_party/gloo/gloo/transport/tcp/pair.cc:589] Read error [192.168.0.37]:14247: Connection reset by peer
Traceback (most recent call last):
  File "wenet/bin/train.py", line 297, in <module>
    main()
  File "wenet/bin/train.py", line 269, in main
    executor.train(model, optimizer, scheduler, train_data_loader, device,
  File "/home/work_nfs6/tyxu/workspace/wenet-rnnt-runtime/wenet/utils/executor.py", line 90, in train
    loss.backward()
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/autograd/__init__.py", line 154, in backward
    Variable._execution_engine.run_backward(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272172048/work/third_party/gloo/gloo/transport/tcp/pair.cc:589] Read error [192.168.0.37]:46302: Connection reset by peer
Traceback (most recent call last):
  File "wenet/bin/train.py", line 297, in <module>
    main()
  File "wenet/bin/train.py", line 269, in main
    executor.train(model, optimizer, scheduler, train_data_loader, device,
  File "/home/work_nfs6/tyxu/workspace/wenet-rnnt-runtime/wenet/utils/executor.py", line 90, in train
    loss.backward()
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/autograd/__init__.py", line 154, in backward
    Variable._execution_engine.run_backward(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272172048/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [192.168.0.37]:40862
Traceback (most recent call last):
  File "wenet/bin/train.py", line 297, in <module>
    main()
  File "wenet/bin/train.py", line 269, in main
    executor.train(model, optimizer, scheduler, train_data_loader, device,
  File "/home/work_nfs6/tyxu/workspace/wenet-rnnt-runtime/wenet/utils/executor.py", line 90, in train
    loss.backward()
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/autograd/__init__.py", line 154, in backward
    Variable._execution_engine.run_backward(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272172048/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [192.168.0.37]:13719
Traceback (most recent call last):
  File "wenet/bin/train.py", line 297, in <module>
    main()
  File "wenet/bin/train.py", line 269, in main
    executor.train(model, optimizer, scheduler, train_data_loader, device,
  File "/home/work_nfs6/tyxu/workspace/wenet-rnnt-runtime/wenet/utils/executor.py", line 90, in train
    loss.backward()
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/autograd/__init__.py", line 154, in backward
    Variable._execution_engine.run_backward(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272172048/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [192.168.0.37]:2455
Traceback (most recent call last):
  File "wenet/bin/train.py", line 297, in <module>
    main()
  File "wenet/bin/train.py", line 269, in main
    executor.train(model, optimizer, scheduler, train_data_loader, device,
  File "/home/work_nfs6/tyxu/workspace/wenet-rnnt-runtime/wenet/utils/executor.py", line 90, in train
    loss.backward()
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/autograd/__init__.py", line 154, in backward
    Variable._execution_engine.run_backward(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272172048/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [192.168.0.37]:34230
Traceback (most recent call last):
  File "wenet/bin/train.py", line 297, in <module>
    main()
  File "wenet/bin/train.py", line 269, in main
    executor.train(model, optimizer, scheduler, train_data_loader, device,
  File "/home/work_nfs6/tyxu/workspace/wenet-rnnt-runtime/wenet/utils/executor.py", line 90, in train
    loss.backward()
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/environment/tyxu/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/autograd/__init__.py", line 154, in backward
    Variable._execution_engine.run_backward(
RuntimeError: [/opt/conda/conda-bld/pytorch_1634272172048/work/third_party/gloo/gloo/transport/tcp/pair.cc:598] Connection closed by peer [192.168.0.37]:27544
