/home/work_nfs5_ssd/kxhuang/wenet-encoder_decoder_bias/examples/librispeech/s0/data/lang_char/train_960_unigram5000
dictionary: /home/work_nfs5_ssd/kxhuang/wenet-encoder_decoder_bias/examples/librispeech/s0/data/lang_char/train_960_unigram5000_units.txt
run_encoder_decoder_bias_nobi_noatt.sh: init method is file:///home/work_nfs6/tyxu/workspace/wenet-rnnt-runtime/examples/librispeech/s0/exp/1204_encoder_bias_nobi_noatt/ddp_init
2022-12-07 19:33:32,506 INFO training on multiple gpus, this gpu 6
2022-12-07 19:33:32,506 INFO training on multiple gpus, this gpu 0
2022-12-07 19:33:32,506 INFO training on multiple gpus, this gpu 1
2022-12-07 19:33:32,507 INFO training on multiple gpus, this gpu 3
2022-12-07 19:33:32,508 INFO training on multiple gpus, this gpu 7
2022-12-07 19:33:32,508 INFO training on multiple gpus, this gpu 2
2022-12-07 19:33:32,509 INFO training on multiple gpus, this gpu 5
2022-12-07 19:33:32,511 INFO training on multiple gpus, this gpu 4
2022-12-07 19:34:08,075 INFO Added key: store_based_barrier_key:1 to store for rank: 0
2022-12-07 19:34:08,098 INFO Added key: store_based_barrier_key:1 to store for rank: 1
2022-12-07 19:34:08,114 INFO Added key: store_based_barrier_key:1 to store for rank: 3
2022-12-07 19:34:09,111 INFO Added key: store_based_barrier_key:1 to store for rank: 2
2022-12-07 19:34:09,139 INFO Added key: store_based_barrier_key:1 to store for rank: 4
2022-12-07 19:34:14,205 INFO Added key: store_based_barrier_key:1 to store for rank: 5
2022-12-07 19:34:14,212 INFO Added key: store_based_barrier_key:1 to store for rank: 7
2022-12-07 19:34:17,241 INFO Added key: store_based_barrier_key:1 to store for rank: 6
2022-12-07 19:34:17,241 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2022-12-07 19:34:17,242 INFO Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2022-12-07 19:34:17,244 INFO Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2022-12-07 19:34:17,593 INFO Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2022-12-07 19:34:18,003 INFO Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2022-12-07 19:34:18,258 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2022-12-07 19:34:18,356 INFO Waiting in store based barrier to initialize process group for rank: 0, key: store_based_barrier_key:1 (world_size=8, worker_count=8, timeout=0:30:00)
2022-12-07 19:34:18,356 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2022-12-07 19:34:22,426 INFO Waiting in store based barrier to initialize process group for rank: 4, key: store_based_barrier_key:1 (world_size=8, worker_count=8, timeout=0:30:00)
2022-12-07 19:34:22,426 INFO Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2022-12-07 19:34:28,858 INFO Checkpoint: loading from checkpoint exp/1204_encoder_bias_nobi_noatt/20.pt for GPU
2022-12-07 19:34:28,886 INFO Checkpoint: loading from checkpoint exp/1204_encoder_bias_nobi_noatt/20.pt for GPU
2022-12-07 19:34:28,922 INFO Checkpoint: loading from checkpoint exp/1204_encoder_bias_nobi_noatt/20.pt for GPU
2022-12-07 19:34:28,952 INFO Checkpoint: loading from checkpoint exp/1204_encoder_bias_nobi_noatt/20.pt for GPU
2022-12-07 19:34:28,981 INFO Checkpoint: loading from checkpoint exp/1204_encoder_bias_nobi_noatt/20.pt for GPU
2022-12-07 19:34:29,012 INFO Checkpoint: loading from checkpoint exp/1204_encoder_bias_nobi_noatt/20.pt for GPU
2022-12-07 19:34:29,044 INFO Checkpoint: loading from checkpoint exp/1204_encoder_bias_nobi_noatt/20.pt for GPU
2022-12-07 19:34:29,094 INFO Checkpoint: loading from checkpoint exp/1204_encoder_bias_nobi_noatt/20.pt for GPU
2022-12-07 19:34:34,670 INFO Epoch 21 TRAIN info lr 4e-08
2022-12-07 19:34:34,672 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): TransformerDecoder(
    (embed): Sequential(
      (0): Embedding(5002, 256)
      (1): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (output_layer): Linear(in_features=256, out_features=5002, bias=True)
    (decoders): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, num_layers=2, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 52377758
2022-12-07 19:34:34,807 INFO Epoch 21 TRAIN info lr 4e-08
2022-12-07 19:34:34,807 INFO Epoch 21 TRAIN info lr 4e-08
2022-12-07 19:34:34,809 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-07 19:34:34,809 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): TransformerDecoder(
    (embed): Sequential(
      (0): Embedding(5002, 256)
      (1): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (output_layer): Linear(in_features=256, out_features=5002, bias=True)
    (decoders): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, num_layers=2, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 52377758
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): TransformerDecoder(
    (embed): Sequential(
      (0): Embedding(5002, 256)
      (1): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (output_layer): Linear(in_features=256, out_features=5002, bias=True)
    (decoders): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, num_layers=2, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 52377758
2022-12-07 19:34:34,831 INFO Epoch 21 TRAIN info lr 4e-08
2022-12-07 19:34:34,832 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): TransformerDecoder(
    (embed): Sequential(
      (0): Embedding(5002, 256)
      (1): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (output_layer): Linear(in_features=256, out_features=5002, bias=True)
    (decoders): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, num_layers=2, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 52377758
2022-12-07 19:34:34,933 INFO Epoch 21 TRAIN info lr 4e-08
2022-12-07 19:34:34,934 INFO Epoch 21 TRAIN info lr 4e-08
2022-12-07 19:34:34,935 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-07 19:34:34,936 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): TransformerDecoder(
    (embed): Sequential(
      (0): Embedding(5002, 256)
      (1): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (output_layer): Linear(in_features=256, out_features=5002, bias=True)
    (decoders): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, num_layers=2, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 52377758
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): TransformerDecoder(
    (embed): Sequential(
      (0): Embedding(5002, 256)
      (1): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (output_layer): Linear(in_features=256, out_features=5002, bias=True)
    (decoders): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, num_layers=2, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 52377758
2022-12-07 19:34:34,976 INFO Epoch 21 TRAIN info lr 4e-08
2022-12-07 19:34:34,977 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): TransformerDecoder(
    (embed): Sequential(
      (0): Embedding(5002, 256)
      (1): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (output_layer): Linear(in_features=256, out_features=5002, bias=True)
    (decoders): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, num_layers=2, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 52377758
2022-12-07 19:34:34,984 INFO Epoch 21 TRAIN info lr 4e-08
2022-12-07 19:34:34,986 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): TransformerDecoder(
    (embed): Sequential(
      (0): Embedding(5002, 256)
      (1): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (output_layer): Linear(in_features=256, out_features=5002, bias=True)
    (decoders): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear1): Identity()
        (concat_linear2): Identity()
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, num_layers=2, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 52377758
2022-12-07 19:35:38,257 DEBUG TRAIN Batch 21/0 loss 5.780846 loss_att 71.676529 loss_ctc 8.920006 loss_rnnt 5.432050 lr 0.00027380 rank 3
2022-12-07 19:35:38,260 DEBUG TRAIN Batch 21/0 loss 7.496693 loss_att 74.669968 loss_ctc 12.501931 loss_rnnt 6.940556 lr 0.00027380 rank 7
2022-12-07 19:35:38,264 DEBUG TRAIN Batch 21/0 loss 13.091240 loss_att 80.347466 loss_ctc 16.958902 loss_rnnt 12.661500 lr 0.00027380 rank 4
2022-12-07 19:35:38,271 DEBUG TRAIN Batch 21/0 loss 7.776214 loss_att 80.257690 loss_ctc 12.328267 loss_rnnt 7.270430 lr 0.00027380 rank 5
2022-12-07 19:35:38,292 DEBUG TRAIN Batch 21/0 loss 8.151865 loss_att 71.249878 loss_ctc 11.971603 loss_rnnt 7.727450 lr 0.00027380 rank 6
2022-12-07 19:35:38,320 DEBUG TRAIN Batch 21/0 loss 8.383615 loss_att 72.280731 loss_ctc 11.876770 loss_rnnt 7.995486 lr 0.00027380 rank 1
2022-12-07 19:35:38,341 DEBUG TRAIN Batch 21/0 loss 10.739088 loss_att 77.598457 loss_ctc 13.271885 loss_rnnt 10.457666 lr 0.00027380 rank 2
2022-12-07 19:35:38,341 DEBUG TRAIN Batch 21/0 loss 5.334685 loss_att 81.527679 loss_ctc 9.568939 loss_rnnt 4.864212 lr 0.00027380 rank 0
2022-12-07 19:36:44,535 DEBUG TRAIN Batch 21/100 loss 4.704019 loss_att 383.594696 loss_ctc 16.874241 loss_rnnt 3.351772 lr 0.00027376 rank 0
2022-12-07 19:36:44,538 DEBUG TRAIN Batch 21/100 loss 6.328136 loss_att 350.085693 loss_ctc 15.103884 loss_rnnt 5.353053 lr 0.00027376 rank 4
2022-12-07 19:36:44,539 DEBUG TRAIN Batch 21/100 loss 6.675609 loss_att 433.783386 loss_ctc 17.443882 loss_rnnt 5.479135 lr 0.00027376 rank 2
2022-12-07 19:36:44,542 DEBUG TRAIN Batch 21/100 loss 4.488206 loss_att 434.021973 loss_ctc 9.490896 loss_rnnt 3.932352 lr 0.00027376 rank 7
2022-12-07 19:36:44,542 DEBUG TRAIN Batch 21/100 loss 7.542335 loss_att 435.127686 loss_ctc 16.689363 loss_rnnt 6.525998 lr 0.00027376 rank 5
2022-12-07 19:36:44,544 DEBUG TRAIN Batch 21/100 loss 12.832418 loss_att 399.626312 loss_ctc 27.640400 loss_rnnt 11.187087 lr 0.00027376 rank 3
2022-12-07 19:36:44,573 DEBUG TRAIN Batch 21/100 loss 8.204317 loss_att 413.230774 loss_ctc 18.494720 loss_rnnt 7.060939 lr 0.00027376 rank 1
2022-12-07 19:36:44,578 DEBUG TRAIN Batch 21/100 loss 7.245917 loss_att 402.892334 loss_ctc 21.150553 loss_rnnt 5.700958 lr 0.00027376 rank 6
2022-12-07 19:37:48,497 DEBUG TRAIN Batch 21/200 loss 4.528588 loss_att 357.251190 loss_ctc 8.411880 loss_rnnt 4.097111 lr 0.00027372 rank 4
2022-12-07 19:37:48,499 DEBUG TRAIN Batch 21/200 loss 11.102288 loss_att 399.362061 loss_ctc 18.155220 loss_rnnt 10.318629 lr 0.00027372 rank 6
2022-12-07 19:37:48,501 DEBUG TRAIN Batch 21/200 loss 7.377529 loss_att 414.460693 loss_ctc 16.616140 loss_rnnt 6.351017 lr 0.00027372 rank 7
2022-12-07 19:37:48,504 DEBUG TRAIN Batch 21/200 loss 12.322418 loss_att 333.747650 loss_ctc 26.168465 loss_rnnt 10.783969 lr 0.00027372 rank 3
2022-12-07 19:37:48,505 DEBUG TRAIN Batch 21/200 loss 6.556080 loss_att 407.700867 loss_ctc 19.325300 loss_rnnt 5.137278 lr 0.00027372 rank 1
2022-12-07 19:37:48,505 DEBUG TRAIN Batch 21/200 loss 8.931250 loss_att 419.972992 loss_ctc 10.426764 loss_rnnt 8.765081 lr 0.00027372 rank 2
2022-12-07 19:37:48,506 DEBUG TRAIN Batch 21/200 loss 3.871435 loss_att 383.392212 loss_ctc 10.009075 loss_rnnt 3.189475 lr 0.00027372 rank 5
2022-12-07 19:37:48,507 DEBUG TRAIN Batch 21/200 loss 4.131023 loss_att 365.223724 loss_ctc 6.509213 loss_rnnt 3.866780 lr 0.00027372 rank 0
2022-12-07 19:38:52,745 DEBUG TRAIN Batch 21/300 loss 12.810406 loss_att 447.278809 loss_ctc 25.875832 loss_rnnt 11.358691 lr 0.00027368 rank 3
2022-12-07 19:38:52,752 DEBUG TRAIN Batch 21/300 loss 12.555510 loss_att 437.217865 loss_ctc 25.854477 loss_rnnt 11.077847 lr 0.00027368 rank 7
2022-12-07 19:38:52,754 DEBUG TRAIN Batch 21/300 loss 12.326860 loss_att 346.198792 loss_ctc 22.524208 loss_rnnt 11.193821 lr 0.00027368 rank 4
2022-12-07 19:38:52,760 DEBUG TRAIN Batch 21/300 loss 8.930260 loss_att 343.751770 loss_ctc 12.311358 loss_rnnt 8.554583 lr 0.00027368 rank 5
2022-12-07 19:38:52,763 DEBUG TRAIN Batch 21/300 loss 4.116533 loss_att 368.569244 loss_ctc 13.147799 loss_rnnt 3.113059 lr 0.00027368 rank 0
2022-12-07 19:38:52,772 DEBUG TRAIN Batch 21/300 loss 5.975919 loss_att 380.341858 loss_ctc 13.917708 loss_rnnt 5.093498 lr 0.00027368 rank 1
2022-12-07 19:38:52,778 DEBUG TRAIN Batch 21/300 loss 7.089445 loss_att 334.827332 loss_ctc 13.301962 loss_rnnt 6.399165 lr 0.00027368 rank 6
2022-12-07 19:38:52,783 DEBUG TRAIN Batch 21/300 loss 11.154757 loss_att 323.066528 loss_ctc 20.264160 loss_rnnt 10.142601 lr 0.00027368 rank 2
2022-12-07 19:40:25,599 DEBUG TRAIN Batch 21/400 loss 6.393610 loss_att 296.146515 loss_ctc 12.191042 loss_rnnt 5.749451 lr 0.00027364 rank 3
2022-12-07 19:40:25,599 DEBUG TRAIN Batch 21/400 loss 12.391019 loss_att 363.736298 loss_ctc 18.813660 loss_rnnt 11.677393 lr 0.00027364 rank 7
2022-12-07 19:40:25,599 DEBUG TRAIN Batch 21/400 loss 6.095982 loss_att 305.691376 loss_ctc 9.972217 loss_rnnt 5.665290 lr 0.00027364 rank 4
2022-12-07 19:40:25,600 DEBUG TRAIN Batch 21/400 loss 12.007053 loss_att 351.456909 loss_ctc 17.453289 loss_rnnt 11.401917 lr 0.00027364 rank 0
2022-12-07 19:40:25,601 DEBUG TRAIN Batch 21/400 loss 5.562282 loss_att 364.670166 loss_ctc 9.393459 loss_rnnt 5.136596 lr 0.00027364 rank 2
2022-12-07 19:40:25,618 DEBUG TRAIN Batch 21/400 loss 15.534678 loss_att 345.352844 loss_ctc 25.192184 loss_rnnt 14.461621 lr 0.00027364 rank 6
2022-12-07 19:40:25,627 DEBUG TRAIN Batch 21/400 loss 8.227878 loss_att 330.981049 loss_ctc 13.537256 loss_rnnt 7.637947 lr 0.00027364 rank 1
2022-12-07 19:40:25,644 DEBUG TRAIN Batch 21/400 loss 14.286310 loss_att 365.877197 loss_ctc 23.870745 loss_rnnt 13.221374 lr 0.00027364 rank 5
2022-12-07 19:41:30,029 DEBUG TRAIN Batch 21/500 loss 11.647392 loss_att 336.313141 loss_ctc 25.861263 loss_rnnt 10.068073 lr 0.00027360 rank 4
2022-12-07 19:41:30,030 DEBUG TRAIN Batch 21/500 loss 5.067444 loss_att 315.959778 loss_ctc 8.109526 loss_rnnt 4.729435 lr 0.00027360 rank 7
2022-12-07 19:41:30,032 DEBUG TRAIN Batch 21/500 loss 8.516333 loss_att 333.629700 loss_ctc 18.188597 loss_rnnt 7.441637 lr 0.00027360 rank 2
2022-12-07 19:41:30,033 DEBUG TRAIN Batch 21/500 loss 4.745336 loss_att 294.863800 loss_ctc 7.498836 loss_rnnt 4.439392 lr 0.00027360 rank 1
2022-12-07 19:41:30,034 DEBUG TRAIN Batch 21/500 loss 5.949182 loss_att 347.868622 loss_ctc 10.153309 loss_rnnt 5.482057 lr 0.00027360 rank 6
2022-12-07 19:41:30,035 DEBUG TRAIN Batch 21/500 loss 5.943281 loss_att 316.228729 loss_ctc 15.796854 loss_rnnt 4.848440 lr 0.00027360 rank 3
2022-12-07 19:41:30,036 DEBUG TRAIN Batch 21/500 loss 10.597534 loss_att 329.473328 loss_ctc 23.216047 loss_rnnt 9.195477 lr 0.00027360 rank 0
2022-12-07 19:41:30,037 DEBUG TRAIN Batch 21/500 loss 8.105082 loss_att 350.852234 loss_ctc 22.251457 loss_rnnt 6.533262 lr 0.00027360 rank 5
2022-12-07 19:42:34,660 DEBUG TRAIN Batch 21/600 loss 17.285353 loss_att 199.524216 loss_ctc 25.052670 loss_rnnt 16.422318 lr 0.00027356 rank 4
2022-12-07 19:42:34,659 DEBUG TRAIN Batch 21/600 loss 5.831642 loss_att 242.917770 loss_ctc 12.740694 loss_rnnt 5.063970 lr 0.00027356 rank 6
2022-12-07 19:42:34,660 DEBUG TRAIN Batch 21/600 loss 8.211203 loss_att 134.008835 loss_ctc 13.401888 loss_rnnt 7.634460 lr 0.00027356 rank 7
2022-12-07 19:42:34,661 DEBUG TRAIN Batch 21/600 loss 6.172506 loss_att 131.740067 loss_ctc 11.440497 loss_rnnt 5.587173 lr 0.00027356 rank 2
2022-12-07 19:42:34,662 DEBUG TRAIN Batch 21/600 loss 10.098896 loss_att 322.600800 loss_ctc 18.505201 loss_rnnt 9.164863 lr 0.00027356 rank 5
2022-12-07 19:42:34,662 DEBUG TRAIN Batch 21/600 loss 7.097670 loss_att 201.509750 loss_ctc 13.413545 loss_rnnt 6.395906 lr 0.00027356 rank 0
2022-12-07 19:42:34,666 DEBUG TRAIN Batch 21/600 loss 4.347803 loss_att 260.424438 loss_ctc 9.986335 loss_rnnt 3.721300 lr 0.00027356 rank 1
2022-12-07 19:42:34,667 DEBUG TRAIN Batch 21/600 loss 10.555879 loss_att 215.345200 loss_ctc 16.838558 loss_rnnt 9.857803 lr 0.00027356 rank 3
2022-12-07 19:43:40,863 DEBUG TRAIN Batch 21/700 loss 3.022448 loss_att 344.092621 loss_ctc 5.324199 loss_rnnt 2.766698 lr 0.00027352 rank 7
2022-12-07 19:43:40,866 DEBUG TRAIN Batch 21/700 loss 8.847394 loss_att 376.668793 loss_ctc 13.021663 loss_rnnt 8.383587 lr 0.00027352 rank 6
2022-12-07 19:43:40,867 DEBUG TRAIN Batch 21/700 loss 7.339866 loss_att 422.051697 loss_ctc 14.823420 loss_rnnt 6.508360 lr 0.00027352 rank 4
2022-12-07 19:43:40,869 DEBUG TRAIN Batch 21/700 loss 2.757410 loss_att 364.064911 loss_ctc 8.499993 loss_rnnt 2.119345 lr 0.00027352 rank 2
2022-12-07 19:43:40,873 DEBUG TRAIN Batch 21/700 loss 5.494370 loss_att 432.894165 loss_ctc 16.626314 loss_rnnt 4.257488 lr 0.00027352 rank 0
2022-12-07 19:43:40,873 DEBUG TRAIN Batch 21/700 loss 12.307979 loss_att 485.528015 loss_ctc 25.584572 loss_rnnt 10.832802 lr 0.00027352 rank 3
2022-12-07 19:43:40,874 DEBUG TRAIN Batch 21/700 loss 6.527425 loss_att 444.188049 loss_ctc 16.140469 loss_rnnt 5.459309 lr 0.00027352 rank 1
2022-12-07 19:43:40,874 DEBUG TRAIN Batch 21/700 loss 18.270557 loss_att 412.677582 loss_ctc 31.742111 loss_rnnt 16.773718 lr 0.00027352 rank 5
2022-12-07 19:45:32,980 DEBUG TRAIN Batch 21/800 loss 13.937402 loss_att 424.560974 loss_ctc 26.059200 loss_rnnt 12.590536 lr 0.00027348 rank 3
2022-12-07 19:45:32,985 DEBUG TRAIN Batch 21/800 loss 10.905356 loss_att 342.966980 loss_ctc 18.940395 loss_rnnt 10.012575 lr 0.00027348 rank 0
2022-12-07 19:45:32,986 DEBUG TRAIN Batch 21/800 loss 9.687097 loss_att 352.377777 loss_ctc 10.730380 loss_rnnt 9.571177 lr 0.00027348 rank 4
2022-12-07 19:45:32,989 DEBUG TRAIN Batch 21/800 loss 5.980803 loss_att 377.664795 loss_ctc 11.042480 loss_rnnt 5.418394 lr 0.00027348 rank 7
2022-12-07 19:45:32,991 DEBUG TRAIN Batch 21/800 loss 7.463644 loss_att 409.504608 loss_ctc 14.302299 loss_rnnt 6.703794 lr 0.00027348 rank 2
2022-12-07 19:45:32,994 DEBUG TRAIN Batch 21/800 loss 14.078693 loss_att 418.821991 loss_ctc 24.834579 loss_rnnt 12.883595 lr 0.00027348 rank 5
2022-12-07 19:45:32,997 DEBUG TRAIN Batch 21/800 loss 7.378429 loss_att 412.307220 loss_ctc 16.580204 loss_rnnt 6.356010 lr 0.00027348 rank 1
2022-12-07 19:45:33,029 DEBUG TRAIN Batch 21/800 loss 8.988167 loss_att 376.280823 loss_ctc 17.871403 loss_rnnt 8.001141 lr 0.00027348 rank 6
2022-12-07 19:46:36,887 DEBUG TRAIN Batch 21/900 loss 5.896331 loss_att 369.958801 loss_ctc 7.082401 loss_rnnt 5.764546 lr 0.00027344 rank 7
2022-12-07 19:46:36,890 DEBUG TRAIN Batch 21/900 loss 7.055358 loss_att 351.489746 loss_ctc 13.997898 loss_rnnt 6.283965 lr 0.00027344 rank 4
2022-12-07 19:46:36,892 DEBUG TRAIN Batch 21/900 loss 5.744193 loss_att 322.032715 loss_ctc 10.603618 loss_rnnt 5.204257 lr 0.00027344 rank 6
2022-12-07 19:46:36,895 DEBUG TRAIN Batch 21/900 loss 8.519895 loss_att 429.886353 loss_ctc 21.257864 loss_rnnt 7.104565 lr 0.00027344 rank 1
2022-12-07 19:46:36,899 DEBUG TRAIN Batch 21/900 loss 6.446897 loss_att 314.700684 loss_ctc 10.529957 loss_rnnt 5.993223 lr 0.00027344 rank 0
2022-12-07 19:46:36,900 DEBUG TRAIN Batch 21/900 loss 5.275295 loss_att 369.223969 loss_ctc 9.130572 loss_rnnt 4.846931 lr 0.00027344 rank 3
2022-12-07 19:46:36,901 DEBUG TRAIN Batch 21/900 loss 16.423836 loss_att 395.323120 loss_ctc 28.930511 loss_rnnt 15.034205 lr 0.00027344 rank 5
2022-12-07 19:46:36,945 DEBUG TRAIN Batch 21/900 loss 10.186950 loss_att 367.771423 loss_ctc 19.341640 loss_rnnt 9.169762 lr 0.00027344 rank 2
2022-12-07 19:47:41,166 DEBUG TRAIN Batch 21/1000 loss 4.116186 loss_att 387.122986 loss_ctc 7.417163 loss_rnnt 3.749411 lr 0.00027340 rank 7
2022-12-07 19:47:41,167 DEBUG TRAIN Batch 21/1000 loss 2.349583 loss_att 362.218597 loss_ctc 6.239036 loss_rnnt 1.917422 lr 0.00027340 rank 3
2022-12-07 19:47:41,168 DEBUG TRAIN Batch 21/1000 loss 14.330309 loss_att 365.692902 loss_ctc 27.652946 loss_rnnt 12.850016 lr 0.00027340 rank 6
2022-12-07 19:47:41,168 DEBUG TRAIN Batch 21/1000 loss 1.697792 loss_att 337.063538 loss_ctc 5.618975 loss_rnnt 1.262105 lr 0.00027340 rank 4
2022-12-07 19:47:41,168 DEBUG TRAIN Batch 21/1000 loss 5.843743 loss_att 387.498932 loss_ctc 15.032369 loss_rnnt 4.822785 lr 0.00027340 rank 1
2022-12-07 19:47:41,171 DEBUG TRAIN Batch 21/1000 loss 12.458556 loss_att 350.781555 loss_ctc 21.730078 loss_rnnt 11.428387 lr 0.00027340 rank 2
2022-12-07 19:47:41,173 DEBUG TRAIN Batch 21/1000 loss 5.543211 loss_att 339.475555 loss_ctc 12.193711 loss_rnnt 4.804266 lr 0.00027340 rank 0
2022-12-07 19:47:41,195 DEBUG TRAIN Batch 21/1000 loss 13.779999 loss_att 398.148804 loss_ctc 27.328377 loss_rnnt 12.274624 lr 0.00027340 rank 5
2022-12-07 19:49:37,515 DEBUG TRAIN Batch 21/1100 loss 11.929368 loss_att 363.226654 loss_ctc 24.769260 loss_rnnt 10.502714 lr 0.00027335 rank 7
2022-12-07 19:49:37,518 DEBUG TRAIN Batch 21/1100 loss 5.295130 loss_att 296.206970 loss_ctc 8.440593 loss_rnnt 4.945634 lr 0.00027335 rank 4
2022-12-07 19:49:37,519 DEBUG TRAIN Batch 21/1100 loss 10.620021 loss_att 353.871826 loss_ctc 22.231064 loss_rnnt 9.329906 lr 0.00027335 rank 3
2022-12-07 19:49:37,519 DEBUG TRAIN Batch 21/1100 loss 10.717669 loss_att 384.126221 loss_ctc 17.072746 loss_rnnt 10.011550 lr 0.00027335 rank 6
2022-12-07 19:49:37,523 DEBUG TRAIN Batch 21/1100 loss 7.113928 loss_att 322.456940 loss_ctc 13.358187 loss_rnnt 6.420121 lr 0.00027335 rank 1
2022-12-07 19:49:37,525 DEBUG TRAIN Batch 21/1100 loss 3.623851 loss_att 327.984436 loss_ctc 7.927083 loss_rnnt 3.145715 lr 0.00027335 rank 0
2022-12-07 19:49:37,526 DEBUG TRAIN Batch 21/1100 loss 7.499446 loss_att 336.163635 loss_ctc 15.800367 loss_rnnt 6.577122 lr 0.00027335 rank 5
2022-12-07 19:49:37,558 DEBUG TRAIN Batch 21/1100 loss 9.376475 loss_att 384.674286 loss_ctc 16.371162 loss_rnnt 8.599288 lr 0.00027335 rank 2
2022-12-07 19:50:40,815 DEBUG TRAIN Batch 21/1200 loss 8.814581 loss_att 241.334152 loss_ctc 16.317286 loss_rnnt 7.980947 lr 0.00027331 rank 4
2022-12-07 19:50:40,819 DEBUG TRAIN Batch 21/1200 loss 9.225304 loss_att 303.437714 loss_ctc 16.017065 loss_rnnt 8.470664 lr 0.00027331 rank 6
2022-12-07 19:50:40,819 DEBUG TRAIN Batch 21/1200 loss 13.607885 loss_att 351.112701 loss_ctc 26.701832 loss_rnnt 12.153003 lr 0.00027331 rank 3
2022-12-07 19:50:40,821 DEBUG TRAIN Batch 21/1200 loss 6.342791 loss_att 316.925232 loss_ctc 16.000679 loss_rnnt 5.269692 lr 0.00027331 rank 7
2022-12-07 19:50:40,822 DEBUG TRAIN Batch 21/1200 loss 9.340864 loss_att 289.739899 loss_ctc 17.409580 loss_rnnt 8.444341 lr 0.00027331 rank 5
2022-12-07 19:50:40,823 DEBUG TRAIN Batch 21/1200 loss 7.632906 loss_att 260.968140 loss_ctc 14.132870 loss_rnnt 6.910688 lr 0.00027331 rank 2
2022-12-07 19:50:40,825 DEBUG TRAIN Batch 21/1200 loss 12.967376 loss_att 268.821167 loss_ctc 23.513523 loss_rnnt 11.795582 lr 0.00027331 rank 0
2022-12-07 19:50:40,863 DEBUG TRAIN Batch 21/1200 loss 6.002537 loss_att 321.025757 loss_ctc 10.279625 loss_rnnt 5.527305 lr 0.00027331 rank 1
2022-12-07 19:51:43,897 DEBUG TRAIN Batch 21/1300 loss 6.151895 loss_att 295.738434 loss_ctc 13.236883 loss_rnnt 5.364674 lr 0.00027327 rank 4
2022-12-07 19:51:43,915 DEBUG TRAIN Batch 21/1300 loss 16.416552 loss_att 451.987396 loss_ctc 47.568924 loss_rnnt 12.955177 lr 0.00027327 rank 6
2022-12-07 19:51:43,917 DEBUG TRAIN Batch 21/1300 loss 8.840499 loss_att 159.698578 loss_ctc 17.041306 loss_rnnt 7.929298 lr 0.00027327 rank 1
2022-12-07 19:51:43,918 DEBUG TRAIN Batch 21/1300 loss 6.066896 loss_att 367.963867 loss_ctc 11.278628 loss_rnnt 5.487815 lr 0.00027327 rank 2
2022-12-07 19:51:43,920 DEBUG TRAIN Batch 21/1300 loss 18.013855 loss_att 454.265350 loss_ctc 37.714783 loss_rnnt 15.824863 lr 0.00027327 rank 7
2022-12-07 19:51:43,922 DEBUG TRAIN Batch 21/1300 loss 7.816654 loss_att 341.025696 loss_ctc 15.692608 loss_rnnt 6.941549 lr 0.00027327 rank 0
2022-12-07 19:51:43,923 DEBUG TRAIN Batch 21/1300 loss 16.078335 loss_att 619.583557 loss_ctc 26.201508 loss_rnnt 14.953539 lr 0.00027327 rank 5
2022-12-07 19:51:43,964 DEBUG TRAIN Batch 21/1300 loss 6.842407 loss_att 179.099289 loss_ctc 10.672112 loss_rnnt 6.416885 lr 0.00027327 rank 3
2022-12-07 19:52:49,021 DEBUG TRAIN Batch 21/1400 loss 7.362261 loss_att 399.151794 loss_ctc 16.485365 loss_rnnt 6.348583 lr 0.00027323 rank 7
2022-12-07 19:52:49,022 DEBUG TRAIN Batch 21/1400 loss 16.071001 loss_att 414.310852 loss_ctc 26.495445 loss_rnnt 14.912731 lr 0.00027323 rank 4
2022-12-07 19:52:49,024 DEBUG TRAIN Batch 21/1400 loss 4.040977 loss_att 396.534424 loss_ctc 14.544449 loss_rnnt 2.873925 lr 0.00027323 rank 6
2022-12-07 19:52:49,025 DEBUG TRAIN Batch 21/1400 loss 4.446287 loss_att 362.041443 loss_ctc 13.909041 loss_rnnt 3.394870 lr 0.00027323 rank 2
2022-12-07 19:52:49,027 DEBUG TRAIN Batch 21/1400 loss 5.897205 loss_att 375.595886 loss_ctc 22.508314 loss_rnnt 4.051527 lr 0.00027323 rank 1
2022-12-07 19:52:49,028 DEBUG TRAIN Batch 21/1400 loss 6.416250 loss_att 432.668915 loss_ctc 11.081996 loss_rnnt 5.897834 lr 0.00027323 rank 3
2022-12-07 19:52:49,029 DEBUG TRAIN Batch 21/1400 loss 6.248177 loss_att 438.745605 loss_ctc 14.497546 loss_rnnt 5.331581 lr 0.00027323 rank 5
2022-12-07 19:52:49,030 DEBUG TRAIN Batch 21/1400 loss 6.061215 loss_att 371.720184 loss_ctc 9.750423 loss_rnnt 5.651304 lr 0.00027323 rank 0
2022-12-07 19:54:42,445 DEBUG TRAIN Batch 21/1500 loss 4.324240 loss_att 309.763916 loss_ctc 10.878451 loss_rnnt 3.595995 lr 0.00027319 rank 7
2022-12-07 19:54:42,445 DEBUG TRAIN Batch 21/1500 loss 10.929466 loss_att 358.471375 loss_ctc 18.176151 loss_rnnt 10.124279 lr 0.00027319 rank 4
2022-12-07 19:54:42,447 DEBUG TRAIN Batch 21/1500 loss 4.373263 loss_att 360.893494 loss_ctc 12.620615 loss_rnnt 3.456891 lr 0.00027319 rank 3
2022-12-07 19:54:42,447 DEBUG TRAIN Batch 21/1500 loss 4.100565 loss_att 345.083221 loss_ctc 7.686329 loss_rnnt 3.702147 lr 0.00027319 rank 6
2022-12-07 19:54:42,453 DEBUG TRAIN Batch 21/1500 loss 8.282401 loss_att 391.519470 loss_ctc 18.381935 loss_rnnt 7.160230 lr 0.00027319 rank 1
2022-12-07 19:54:42,453 DEBUG TRAIN Batch 21/1500 loss 6.095888 loss_att 407.974945 loss_ctc 13.313927 loss_rnnt 5.293883 lr 0.00027319 rank 0
2022-12-07 19:54:42,456 DEBUG TRAIN Batch 21/1500 loss 11.739850 loss_att 436.872742 loss_ctc 26.757269 loss_rnnt 10.071248 lr 0.00027319 rank 2
2022-12-07 19:54:42,460 DEBUG TRAIN Batch 21/1500 loss 6.367593 loss_att 346.759338 loss_ctc 12.431483 loss_rnnt 5.693828 lr 0.00027319 rank 5
2022-12-07 19:55:45,321 DEBUG TRAIN Batch 21/1600 loss 9.084498 loss_att 357.814789 loss_ctc 14.350120 loss_rnnt 8.499430 lr 0.00027315 rank 4
2022-12-07 19:55:45,323 DEBUG TRAIN Batch 21/1600 loss 6.282928 loss_att 417.153595 loss_ctc 15.051697 loss_rnnt 5.308619 lr 0.00027315 rank 7
2022-12-07 19:55:45,324 DEBUG TRAIN Batch 21/1600 loss 6.133569 loss_att 342.310730 loss_ctc 10.551066 loss_rnnt 5.642736 lr 0.00027315 rank 3
2022-12-07 19:55:45,327 DEBUG TRAIN Batch 21/1600 loss 3.343136 loss_att 331.864288 loss_ctc 7.257979 loss_rnnt 2.908154 lr 0.00027315 rank 6
2022-12-07 19:55:45,329 DEBUG TRAIN Batch 21/1600 loss 16.629946 loss_att 306.823456 loss_ctc 35.391457 loss_rnnt 14.545334 lr 0.00027315 rank 1
2022-12-07 19:55:45,328 DEBUG TRAIN Batch 21/1600 loss 4.681941 loss_att 376.761536 loss_ctc 11.757220 loss_rnnt 3.895799 lr 0.00027315 rank 2
2022-12-07 19:55:45,331 DEBUG TRAIN Batch 21/1600 loss 11.570671 loss_att 400.955261 loss_ctc 26.616322 loss_rnnt 9.898932 lr 0.00027315 rank 0
2022-12-07 19:55:45,372 DEBUG TRAIN Batch 21/1600 loss 6.016099 loss_att 342.673035 loss_ctc 13.479002 loss_rnnt 5.186888 lr 0.00027315 rank 5
2022-12-07 19:56:48,585 DEBUG TRAIN Batch 21/1700 loss 8.924111 loss_att 343.727417 loss_ctc 21.579865 loss_rnnt 7.517917 lr 0.00027311 rank 4
2022-12-07 19:56:48,587 DEBUG TRAIN Batch 21/1700 loss 7.515221 loss_att 334.976624 loss_ctc 14.405788 loss_rnnt 6.749603 lr 0.00027311 rank 7
2022-12-07 19:56:48,588 DEBUG TRAIN Batch 21/1700 loss 9.079432 loss_att 336.887146 loss_ctc 22.827187 loss_rnnt 7.551905 lr 0.00027311 rank 6
2022-12-07 19:56:48,588 DEBUG TRAIN Batch 21/1700 loss 8.055285 loss_att 365.867493 loss_ctc 20.566082 loss_rnnt 6.665196 lr 0.00027311 rank 3
2022-12-07 19:56:48,589 DEBUG TRAIN Batch 21/1700 loss 15.780698 loss_att 335.711670 loss_ctc 25.596052 loss_rnnt 14.690103 lr 0.00027311 rank 0
2022-12-07 19:56:48,590 DEBUG TRAIN Batch 21/1700 loss 5.572192 loss_att 365.359772 loss_ctc 17.773594 loss_rnnt 4.216481 lr 0.00027311 rank 2
2022-12-07 19:56:48,593 DEBUG TRAIN Batch 21/1700 loss 7.892269 loss_att 323.783264 loss_ctc 13.021664 loss_rnnt 7.322337 lr 0.00027311 rank 5
2022-12-07 19:56:48,608 DEBUG TRAIN Batch 21/1700 loss 10.800535 loss_att 392.956299 loss_ctc 21.076122 loss_rnnt 9.658803 lr 0.00027311 rank 1
2022-12-07 19:58:47,908 DEBUG TRAIN Batch 21/1800 loss 13.999047 loss_att 309.043427 loss_ctc 29.342896 loss_rnnt 12.294175 lr 0.00027307 rank 6
2022-12-07 19:58:47,909 DEBUG TRAIN Batch 21/1800 loss 11.298610 loss_att 324.093048 loss_ctc 20.179758 loss_rnnt 10.311815 lr 0.00027307 rank 5
2022-12-07 19:58:47,910 DEBUG TRAIN Batch 21/1800 loss 13.124484 loss_att 404.225525 loss_ctc 31.580124 loss_rnnt 11.073857 lr 0.00027307 rank 1
2022-12-07 19:58:47,911 DEBUG TRAIN Batch 21/1800 loss 6.885534 loss_att 278.494537 loss_ctc 10.409604 loss_rnnt 6.493971 lr 0.00027307 rank 4
2022-12-07 19:58:47,912 DEBUG TRAIN Batch 21/1800 loss 7.024790 loss_att 345.773254 loss_ctc 17.133913 loss_rnnt 5.901554 lr 0.00027307 rank 0
2022-12-07 19:58:47,912 DEBUG TRAIN Batch 21/1800 loss 9.323818 loss_att 331.302124 loss_ctc 15.895769 loss_rnnt 8.593601 lr 0.00027307 rank 3
2022-12-07 19:58:47,912 DEBUG TRAIN Batch 21/1800 loss 9.212363 loss_att 295.121460 loss_ctc 19.297558 loss_rnnt 8.091786 lr 0.00027307 rank 2
2022-12-07 19:58:47,914 DEBUG TRAIN Batch 21/1800 loss 9.897253 loss_att 302.571106 loss_ctc 22.019585 loss_rnnt 8.550327 lr 0.00027307 rank 7
2022-12-07 19:59:52,212 DEBUG TRAIN Batch 21/1900 loss 6.949059 loss_att 406.941620 loss_ctc 17.427143 loss_rnnt 5.784827 lr 0.00027303 rank 4
2022-12-07 19:59:52,216 DEBUG TRAIN Batch 21/1900 loss 5.781194 loss_att 252.203171 loss_ctc 12.157774 loss_rnnt 5.072685 lr 0.00027303 rank 1
2022-12-07 19:59:52,216 DEBUG TRAIN Batch 21/1900 loss 5.421049 loss_att 283.748352 loss_ctc 9.467679 loss_rnnt 4.971424 lr 0.00027303 rank 3
2022-12-07 19:59:52,216 DEBUG TRAIN Batch 21/1900 loss 9.136858 loss_att 159.287094 loss_ctc 21.758520 loss_rnnt 7.734451 lr 0.00027303 rank 7
2022-12-07 19:59:52,217 DEBUG TRAIN Batch 21/1900 loss 5.335567 loss_att 363.945801 loss_ctc 9.822416 loss_rnnt 4.837029 lr 0.00027303 rank 2
2022-12-07 19:59:52,219 DEBUG TRAIN Batch 21/1900 loss 6.205568 loss_att 346.597504 loss_ctc 19.754204 loss_rnnt 4.700164 lr 0.00027303 rank 5
2022-12-07 19:59:52,221 DEBUG TRAIN Batch 21/1900 loss 11.801071 loss_att 392.630798 loss_ctc 22.569693 loss_rnnt 10.604558 lr 0.00027303 rank 6
2022-12-07 19:59:52,223 DEBUG TRAIN Batch 21/1900 loss 6.232571 loss_att 199.853622 loss_ctc 10.557558 loss_rnnt 5.752016 lr 0.00027303 rank 0
2022-12-07 20:00:55,404 DEBUG TRAIN Batch 21/2000 loss 14.464890 loss_att 434.450287 loss_ctc 43.606789 loss_rnnt 11.226901 lr 0.00027299 rank 6
2022-12-07 20:00:55,405 DEBUG TRAIN Batch 21/2000 loss 8.004462 loss_att 390.507996 loss_ctc 20.637730 loss_rnnt 6.600766 lr 0.00027299 rank 2
2022-12-07 20:00:55,406 DEBUG TRAIN Batch 21/2000 loss 8.704023 loss_att 374.767639 loss_ctc 15.660083 loss_rnnt 7.931128 lr 0.00027299 rank 4
2022-12-07 20:00:55,406 DEBUG TRAIN Batch 21/2000 loss 12.369830 loss_att 399.846191 loss_ctc 19.984518 loss_rnnt 11.523753 lr 0.00027299 rank 7
2022-12-07 20:00:55,408 DEBUG TRAIN Batch 21/2000 loss 6.253998 loss_att 361.748627 loss_ctc 13.433440 loss_rnnt 5.456283 lr 0.00027299 rank 5
2022-12-07 20:00:55,411 DEBUG TRAIN Batch 21/2000 loss 11.576509 loss_att 393.497314 loss_ctc 25.891132 loss_rnnt 9.985995 lr 0.00027299 rank 1
2022-12-07 20:00:55,411 DEBUG TRAIN Batch 21/2000 loss 3.969727 loss_att 394.281708 loss_ctc 13.046034 loss_rnnt 2.961248 lr 0.00027299 rank 0
2022-12-07 20:00:55,412 DEBUG TRAIN Batch 21/2000 loss 9.253771 loss_att 76.829659 loss_ctc 14.921704 loss_rnnt 8.624001 lr 0.00027299 rank 3
2022-12-07 20:01:59,624 DEBUG TRAIN Batch 21/2100 loss 11.937717 loss_att 450.182312 loss_ctc 27.283710 loss_rnnt 10.232608 lr 0.00027295 rank 2
2022-12-07 20:01:59,632 DEBUG TRAIN Batch 21/2100 loss 6.732134 loss_att 305.429932 loss_ctc 12.565840 loss_rnnt 6.083944 lr 0.00027295 rank 6
2022-12-07 20:01:59,638 DEBUG TRAIN Batch 21/2100 loss 7.788756 loss_att 384.709198 loss_ctc 16.542847 loss_rnnt 6.816080 lr 0.00027295 rank 4
2022-12-07 20:01:59,640 DEBUG TRAIN Batch 21/2100 loss 10.097652 loss_att 460.732269 loss_ctc 17.587460 loss_rnnt 9.265451 lr 0.00027295 rank 7
2022-12-07 20:01:59,643 DEBUG TRAIN Batch 21/2100 loss 5.274213 loss_att 402.123749 loss_ctc 14.801102 loss_rnnt 4.215670 lr 0.00027295 rank 1
2022-12-07 20:01:59,643 DEBUG TRAIN Batch 21/2100 loss 17.560003 loss_att 381.413574 loss_ctc 33.507339 loss_rnnt 15.788076 lr 0.00027295 rank 5
2022-12-07 20:01:59,656 DEBUG TRAIN Batch 21/2100 loss 18.150871 loss_att 356.398773 loss_ctc 38.245316 loss_rnnt 15.918155 lr 0.00027295 rank 0
2022-12-07 20:01:59,661 DEBUG TRAIN Batch 21/2100 loss 14.408937 loss_att 410.646179 loss_ctc 24.017523 loss_rnnt 13.341316 lr 0.00027295 rank 3
2022-12-07 20:03:53,290 DEBUG TRAIN Batch 21/2200 loss 6.519711 loss_att 343.050354 loss_ctc 12.257326 loss_rnnt 5.882197 lr 0.00027291 rank 1
2022-12-07 20:03:53,300 DEBUG TRAIN Batch 21/2200 loss 6.814532 loss_att 361.564392 loss_ctc 17.776171 loss_rnnt 5.596572 lr 0.00027291 rank 7
2022-12-07 20:03:53,301 DEBUG TRAIN Batch 21/2200 loss 9.876028 loss_att 418.981628 loss_ctc 26.904900 loss_rnnt 7.983931 lr 0.00027291 rank 4
2022-12-07 20:03:53,302 DEBUG TRAIN Batch 21/2200 loss 14.788839 loss_att 371.147522 loss_ctc 34.821362 loss_rnnt 12.563004 lr 0.00027291 rank 6
2022-12-07 20:03:53,305 DEBUG TRAIN Batch 21/2200 loss 8.936193 loss_att 352.190369 loss_ctc 13.099022 loss_rnnt 8.473658 lr 0.00027291 rank 3
2022-12-07 20:03:53,304 DEBUG TRAIN Batch 21/2200 loss 13.386829 loss_att 368.313965 loss_ctc 22.415792 loss_rnnt 12.383612 lr 0.00027291 rank 2
2022-12-07 20:03:53,312 DEBUG TRAIN Batch 21/2200 loss 6.722871 loss_att 365.573212 loss_ctc 11.458727 loss_rnnt 6.196665 lr 0.00027291 rank 0
2022-12-07 20:03:53,343 DEBUG TRAIN Batch 21/2200 loss 7.362116 loss_att 385.703217 loss_ctc 14.009481 loss_rnnt 6.623520 lr 0.00027291 rank 5
2022-12-07 20:04:56,406 DEBUG TRAIN Batch 21/2300 loss 21.795332 loss_att 387.796417 loss_ctc 45.745506 loss_rnnt 19.134201 lr 0.00027287 rank 6
2022-12-07 20:04:56,406 DEBUG TRAIN Batch 21/2300 loss 14.208385 loss_att 425.070251 loss_ctc 25.399654 loss_rnnt 12.964911 lr 0.00027287 rank 7
2022-12-07 20:04:56,409 DEBUG TRAIN Batch 21/2300 loss 7.092302 loss_att 347.859436 loss_ctc 19.587978 loss_rnnt 5.703893 lr 0.00027287 rank 4
2022-12-07 20:04:56,411 DEBUG TRAIN Batch 21/2300 loss 11.599285 loss_att 379.457153 loss_ctc 27.524971 loss_rnnt 9.829765 lr 0.00027287 rank 3
2022-12-07 20:04:56,412 DEBUG TRAIN Batch 21/2300 loss 12.494949 loss_att 348.980408 loss_ctc 28.871445 loss_rnnt 10.675339 lr 0.00027287 rank 2
2022-12-07 20:04:56,414 DEBUG TRAIN Batch 21/2300 loss 4.032308 loss_att 326.554474 loss_ctc 8.503685 loss_rnnt 3.535488 lr 0.00027287 rank 5
2022-12-07 20:04:56,415 DEBUG TRAIN Batch 21/2300 loss 3.324142 loss_att 353.157654 loss_ctc 11.152439 loss_rnnt 2.454331 lr 0.00027287 rank 0
2022-12-07 20:04:56,416 DEBUG TRAIN Batch 21/2300 loss 9.266879 loss_att 323.750122 loss_ctc 15.800494 loss_rnnt 8.540922 lr 0.00027287 rank 1
2022-12-07 20:06:00,522 DEBUG TRAIN Batch 21/2400 loss 7.178890 loss_att 307.558472 loss_ctc 12.731228 loss_rnnt 6.561964 lr 0.00027282 rank 7
2022-12-07 20:06:00,529 DEBUG TRAIN Batch 21/2400 loss 2.652244 loss_att 316.298248 loss_ctc 6.587900 loss_rnnt 2.214949 lr 0.00027282 rank 0
2022-12-07 20:06:00,529 DEBUG TRAIN Batch 21/2400 loss 3.952153 loss_att 341.798401 loss_ctc 11.896463 loss_rnnt 3.069452 lr 0.00027282 rank 3
2022-12-07 20:06:00,530 DEBUG TRAIN Batch 21/2400 loss 9.291593 loss_att 379.280426 loss_ctc 16.829781 loss_rnnt 8.454017 lr 0.00027282 rank 6
2022-12-07 20:06:00,537 DEBUG TRAIN Batch 21/2400 loss 7.368781 loss_att 341.303070 loss_ctc 15.916396 loss_rnnt 6.419046 lr 0.00027282 rank 2
2022-12-07 20:06:00,539 DEBUG TRAIN Batch 21/2400 loss 7.375550 loss_att 360.682922 loss_ctc 19.472702 loss_rnnt 6.031422 lr 0.00027282 rank 5
2022-12-07 20:06:00,544 DEBUG TRAIN Batch 21/2400 loss 14.186840 loss_att 347.714722 loss_ctc 26.385433 loss_rnnt 12.831442 lr 0.00027282 rank 4
2022-12-07 20:06:00,549 DEBUG TRAIN Batch 21/2400 loss 7.373219 loss_att 324.635498 loss_ctc 12.395070 loss_rnnt 6.815236 lr 0.00027282 rank 1
2022-12-07 20:07:56,622 DEBUG TRAIN Batch 21/2500 loss 9.284369 loss_att 192.320663 loss_ctc 15.970193 loss_rnnt 8.541500 lr 0.00027278 rank 4
2022-12-07 20:07:56,624 DEBUG TRAIN Batch 21/2500 loss 7.445165 loss_att 192.931488 loss_ctc 14.304585 loss_rnnt 6.683007 lr 0.00027278 rank 6
2022-12-07 20:07:56,625 DEBUG TRAIN Batch 21/2500 loss 15.599936 loss_att 167.975403 loss_ctc 22.586172 loss_rnnt 14.823688 lr 0.00027278 rank 7
2022-12-07 20:07:56,626 DEBUG TRAIN Batch 21/2500 loss 8.272373 loss_att 339.221832 loss_ctc 12.879596 loss_rnnt 7.760460 lr 0.00027278 rank 1
2022-12-07 20:07:56,629 DEBUG TRAIN Batch 21/2500 loss 16.814840 loss_att 350.753876 loss_ctc 28.308517 loss_rnnt 15.537766 lr 0.00027278 rank 0
2022-12-07 20:07:56,630 DEBUG TRAIN Batch 21/2500 loss 14.136745 loss_att 437.479218 loss_ctc 28.747129 loss_rnnt 12.513370 lr 0.00027278 rank 3
2022-12-07 20:07:56,633 DEBUG TRAIN Batch 21/2500 loss 7.263065 loss_att 139.682037 loss_ctc 12.293454 loss_rnnt 6.704134 lr 0.00027278 rank 2
2022-12-07 20:07:56,633 DEBUG TRAIN Batch 21/2500 loss 4.379874 loss_att 224.929565 loss_ctc 9.254810 loss_rnnt 3.838214 lr 0.00027278 rank 5
2022-12-07 20:08:59,700 DEBUG TRAIN Batch 21/2600 loss 10.721594 loss_att 371.847351 loss_ctc 23.452209 loss_rnnt 9.307082 lr 0.00027274 rank 6
2022-12-07 20:08:59,708 DEBUG TRAIN Batch 21/2600 loss 10.378506 loss_att 459.921844 loss_ctc 19.353800 loss_rnnt 9.381251 lr 0.00027274 rank 4
2022-12-07 20:08:59,709 DEBUG TRAIN Batch 21/2600 loss 2.784107 loss_att 326.764404 loss_ctc 7.884255 loss_rnnt 2.217424 lr 0.00027274 rank 2
2022-12-07 20:08:59,710 DEBUG TRAIN Batch 21/2600 loss 6.945065 loss_att 416.185852 loss_ctc 19.843266 loss_rnnt 5.511932 lr 0.00027274 rank 7
2022-12-07 20:08:59,712 DEBUG TRAIN Batch 21/2600 loss 9.333889 loss_att 413.441772 loss_ctc 22.326025 loss_rnnt 7.890318 lr 0.00027274 rank 5
2022-12-07 20:08:59,713 DEBUG TRAIN Batch 21/2600 loss 10.937728 loss_att 318.049347 loss_ctc 23.023863 loss_rnnt 9.594825 lr 0.00027274 rank 3
2022-12-07 20:08:59,716 DEBUG TRAIN Batch 21/2600 loss 2.930711 loss_att 398.295746 loss_ctc 7.446831 loss_rnnt 2.428920 lr 0.00027274 rank 1
2022-12-07 20:08:59,717 DEBUG TRAIN Batch 21/2600 loss 10.470114 loss_att 155.406845 loss_ctc 17.308790 loss_rnnt 9.710261 lr 0.00027274 rank 0
2022-12-07 20:10:02,014 DEBUG TRAIN Batch 21/2700 loss 4.189074 loss_att 366.994385 loss_ctc 6.741015 loss_rnnt 3.905525 lr 0.00027270 rank 4
2022-12-07 20:10:02,021 DEBUG TRAIN Batch 21/2700 loss 7.988714 loss_att 381.328094 loss_ctc 18.799198 loss_rnnt 6.787549 lr 0.00027270 rank 0
2022-12-07 20:10:02,022 DEBUG TRAIN Batch 21/2700 loss 5.574129 loss_att 381.143402 loss_ctc 12.338226 loss_rnnt 4.822562 lr 0.00027270 rank 3
2022-12-07 20:10:02,024 DEBUG TRAIN Batch 21/2700 loss 6.417931 loss_att 388.346741 loss_ctc 13.955994 loss_rnnt 5.580368 lr 0.00027270 rank 1
2022-12-07 20:10:02,025 DEBUG TRAIN Batch 21/2700 loss 7.970801 loss_att 375.457123 loss_ctc 12.047438 loss_rnnt 7.517841 lr 0.00027270 rank 5
2022-12-07 20:10:02,025 DEBUG TRAIN Batch 21/2700 loss 3.893860 loss_att 384.237061 loss_ctc 12.007801 loss_rnnt 2.992311 lr 0.00027270 rank 7
2022-12-07 20:10:02,026 DEBUG TRAIN Batch 21/2700 loss 5.324536 loss_att 404.947510 loss_ctc 20.802122 loss_rnnt 3.604804 lr 0.00027270 rank 2
2022-12-07 20:10:02,063 DEBUG TRAIN Batch 21/2700 loss 4.389938 loss_att 374.297363 loss_ctc 12.578532 loss_rnnt 3.480095 lr 0.00027270 rank 6
2022-12-07 20:11:07,256 DEBUG TRAIN Batch 21/2800 loss 6.486236 loss_att 345.153076 loss_ctc 10.491926 loss_rnnt 6.041159 lr 0.00027266 rank 7
2022-12-07 20:11:07,257 DEBUG TRAIN Batch 21/2800 loss 4.982096 loss_att 412.452240 loss_ctc 11.122467 loss_rnnt 4.299833 lr 0.00027266 rank 4
2022-12-07 20:11:07,260 DEBUG TRAIN Batch 21/2800 loss 11.719510 loss_att 435.537109 loss_ctc 32.246456 loss_rnnt 9.438739 lr 0.00027266 rank 0
2022-12-07 20:11:07,260 DEBUG TRAIN Batch 21/2800 loss 3.585307 loss_att 382.311798 loss_ctc 7.179312 loss_rnnt 3.185973 lr 0.00027266 rank 2
2022-12-07 20:11:07,264 DEBUG TRAIN Batch 21/2800 loss 2.696526 loss_att 329.402100 loss_ctc 5.315377 loss_rnnt 2.405543 lr 0.00027266 rank 6
2022-12-07 20:11:07,265 DEBUG TRAIN Batch 21/2800 loss 10.266250 loss_att 460.518005 loss_ctc 21.203039 loss_rnnt 9.051051 lr 0.00027266 rank 1
2022-12-07 20:11:07,265 DEBUG TRAIN Batch 21/2800 loss 6.238918 loss_att 345.479065 loss_ctc 15.613420 loss_rnnt 5.197307 lr 0.00027266 rank 5
2022-12-07 20:11:07,270 DEBUG TRAIN Batch 21/2800 loss 7.053964 loss_att 413.801697 loss_ctc 22.804899 loss_rnnt 5.303860 lr 0.00027266 rank 3
2022-12-07 20:13:03,658 DEBUG TRAIN Batch 21/2900 loss 17.405159 loss_att 403.642822 loss_ctc 33.515892 loss_rnnt 15.615078 lr 0.00027262 rank 7
2022-12-07 20:13:03,660 DEBUG TRAIN Batch 21/2900 loss 18.281155 loss_att 401.447937 loss_ctc 26.099195 loss_rnnt 17.412485 lr 0.00027262 rank 4
2022-12-07 20:13:03,666 DEBUG TRAIN Batch 21/2900 loss 7.725200 loss_att 384.770386 loss_ctc 13.663502 loss_rnnt 7.065389 lr 0.00027262 rank 0
2022-12-07 20:13:03,667 DEBUG TRAIN Batch 21/2900 loss 2.814106 loss_att 357.477600 loss_ctc 9.622307 loss_rnnt 2.057639 lr 0.00027262 rank 1
2022-12-07 20:13:03,669 DEBUG TRAIN Batch 21/2900 loss 3.038656 loss_att 331.732178 loss_ctc 6.957365 loss_rnnt 2.603244 lr 0.00027262 rank 5
2022-12-07 20:13:03,672 DEBUG TRAIN Batch 21/2900 loss 4.916762 loss_att 469.922607 loss_ctc 12.546378 loss_rnnt 4.069027 lr 0.00027262 rank 3
2022-12-07 20:13:03,685 DEBUG TRAIN Batch 21/2900 loss 19.190626 loss_att 438.349792 loss_ctc 35.388439 loss_rnnt 17.390869 lr 0.00027262 rank 2
2022-12-07 20:13:03,722 DEBUG TRAIN Batch 21/2900 loss 9.598806 loss_att 391.386353 loss_ctc 16.369112 loss_rnnt 8.846551 lr 0.00027262 rank 6
2022-12-07 20:14:07,941 DEBUG TRAIN Batch 21/3000 loss 4.013934 loss_att 357.129333 loss_ctc 16.725128 loss_rnnt 2.601579 lr 0.00027258 rank 4
2022-12-07 20:14:07,945 DEBUG TRAIN Batch 21/3000 loss 5.159115 loss_att 339.196472 loss_ctc 8.552756 loss_rnnt 4.782044 lr 0.00027258 rank 7
2022-12-07 20:14:07,945 DEBUG TRAIN Batch 21/3000 loss 2.863696 loss_att 355.301208 loss_ctc 4.494599 loss_rnnt 2.682484 lr 0.00027258 rank 3
2022-12-07 20:14:07,947 DEBUG TRAIN Batch 21/3000 loss 14.923864 loss_att 357.147949 loss_ctc 27.042255 loss_rnnt 13.577377 lr 0.00027258 rank 1
2022-12-07 20:14:07,947 DEBUG TRAIN Batch 21/3000 loss 11.805124 loss_att 404.719208 loss_ctc 22.852219 loss_rnnt 10.577669 lr 0.00027258 rank 5
2022-12-07 20:14:07,948 DEBUG TRAIN Batch 21/3000 loss 5.938792 loss_att 335.141479 loss_ctc 13.187564 loss_rnnt 5.133372 lr 0.00027258 rank 2
2022-12-07 20:14:07,949 DEBUG TRAIN Batch 21/3000 loss 6.319981 loss_att 332.481018 loss_ctc 16.634348 loss_rnnt 5.173940 lr 0.00027258 rank 6
2022-12-07 20:14:07,952 DEBUG TRAIN Batch 21/3000 loss 6.509566 loss_att 316.728455 loss_ctc 10.393157 loss_rnnt 6.078056 lr 0.00027258 rank 0
2022-12-07 20:15:11,221 DEBUG TRAIN Batch 21/3100 loss 4.486870 loss_att 257.683136 loss_ctc 12.166512 loss_rnnt 3.633576 lr 0.00027254 rank 4
2022-12-07 20:15:11,222 DEBUG TRAIN Batch 21/3100 loss 5.213463 loss_att 313.960693 loss_ctc 15.153927 loss_rnnt 4.108967 lr 0.00027254 rank 3
2022-12-07 20:15:11,223 DEBUG TRAIN Batch 21/3100 loss 9.378664 loss_att 332.627319 loss_ctc 20.693903 loss_rnnt 8.121415 lr 0.00027254 rank 1
2022-12-07 20:15:11,225 DEBUG TRAIN Batch 21/3100 loss 4.148302 loss_att 285.691223 loss_ctc 8.823870 loss_rnnt 3.628794 lr 0.00027254 rank 6
2022-12-07 20:15:11,226 DEBUG TRAIN Batch 21/3100 loss 13.176753 loss_att 301.075073 loss_ctc 22.600126 loss_rnnt 12.129712 lr 0.00027254 rank 7
2022-12-07 20:15:11,226 DEBUG TRAIN Batch 21/3100 loss 3.286561 loss_att 187.875259 loss_ctc 7.765582 loss_rnnt 2.788892 lr 0.00027254 rank 2
2022-12-07 20:15:11,227 DEBUG TRAIN Batch 21/3100 loss 12.392855 loss_att 285.206299 loss_ctc 30.078955 loss_rnnt 10.427732 lr 0.00027254 rank 5
2022-12-07 20:15:11,227 DEBUG TRAIN Batch 21/3100 loss 10.905860 loss_att 342.074463 loss_ctc 27.963085 loss_rnnt 9.010613 lr 0.00027254 rank 0
2022-12-07 20:17:06,220 DEBUG TRAIN Batch 21/3200 loss 5.718722 loss_att 334.728973 loss_ctc 10.772392 loss_rnnt 5.157203 lr 0.00027250 rank 2
2022-12-07 20:17:06,221 DEBUG TRAIN Batch 21/3200 loss 7.076607 loss_att 264.973877 loss_ctc 11.357501 loss_rnnt 6.600952 lr 0.00027250 rank 3
2022-12-07 20:17:06,222 DEBUG TRAIN Batch 21/3200 loss 17.192379 loss_att 382.522156 loss_ctc 27.988613 loss_rnnt 15.992798 lr 0.00027250 rank 5
2022-12-07 20:17:06,224 DEBUG TRAIN Batch 21/3200 loss 5.670317 loss_att 266.561096 loss_ctc 14.394882 loss_rnnt 4.700921 lr 0.00027250 rank 0
2022-12-07 20:17:06,231 DEBUG TRAIN Batch 21/3200 loss 2.019104 loss_att 409.362640 loss_ctc 6.480125 loss_rnnt 1.523435 lr 0.00027250 rank 6
2022-12-07 20:17:06,236 DEBUG TRAIN Batch 21/3200 loss 17.892826 loss_att 449.590515 loss_ctc 32.515846 loss_rnnt 16.268047 lr 0.00027250 rank 4
2022-12-07 20:17:06,238 DEBUG TRAIN Batch 21/3200 loss 24.003082 loss_att 450.007080 loss_ctc 41.896248 loss_rnnt 22.014954 lr 0.00027250 rank 7
2022-12-07 20:17:06,267 DEBUG TRAIN Batch 21/3200 loss 7.763112 loss_att 135.525009 loss_ctc 15.197217 loss_rnnt 6.937100 lr 0.00027250 rank 1
2022-12-07 20:18:11,856 DEBUG TRAIN Batch 21/3300 loss 11.445408 loss_att 424.959412 loss_ctc 32.910370 loss_rnnt 9.060412 lr 0.00027246 rank 4
2022-12-07 20:18:11,856 DEBUG TRAIN Batch 21/3300 loss 8.931703 loss_att 437.639008 loss_ctc 20.869717 loss_rnnt 7.605257 lr 0.00027246 rank 0
2022-12-07 20:18:11,857 DEBUG TRAIN Batch 21/3300 loss 5.053516 loss_att 382.557129 loss_ctc 10.222974 loss_rnnt 4.479132 lr 0.00027246 rank 1
2022-12-07 20:18:11,858 DEBUG TRAIN Batch 21/3300 loss 7.850336 loss_att 371.083588 loss_ctc 19.022343 loss_rnnt 6.609002 lr 0.00027246 rank 7
2022-12-07 20:18:11,865 DEBUG TRAIN Batch 21/3300 loss 1.459644 loss_att 375.524750 loss_ctc 7.415425 loss_rnnt 0.797891 lr 0.00027246 rank 2
2022-12-07 20:18:11,865 DEBUG TRAIN Batch 21/3300 loss 6.851965 loss_att 358.833344 loss_ctc 17.216898 loss_rnnt 5.700306 lr 0.00027246 rank 3
2022-12-07 20:18:11,886 DEBUG TRAIN Batch 21/3300 loss 11.384771 loss_att 387.948242 loss_ctc 22.560368 loss_rnnt 10.143039 lr 0.00027246 rank 6
2022-12-07 20:18:11,918 DEBUG TRAIN Batch 21/3300 loss 3.700815 loss_att 392.861938 loss_ctc 11.113106 loss_rnnt 2.877228 lr 0.00027246 rank 5
2022-12-07 20:19:15,425 DEBUG TRAIN Batch 21/3400 loss 5.301791 loss_att 423.988220 loss_ctc 12.517214 loss_rnnt 4.500077 lr 0.00027242 rank 7
2022-12-07 20:19:15,426 DEBUG TRAIN Batch 21/3400 loss 10.208027 loss_att 438.070496 loss_ctc 20.104076 loss_rnnt 9.108466 lr 0.00027242 rank 6
2022-12-07 20:19:15,426 DEBUG TRAIN Batch 21/3400 loss 5.901591 loss_att 401.497253 loss_ctc 21.072456 loss_rnnt 4.215940 lr 0.00027242 rank 4
2022-12-07 20:19:15,426 DEBUG TRAIN Batch 21/3400 loss 13.729401 loss_att 430.157471 loss_ctc 25.323347 loss_rnnt 12.441184 lr 0.00027242 rank 3
2022-12-07 20:19:15,429 DEBUG TRAIN Batch 21/3400 loss 10.350854 loss_att 375.756866 loss_ctc 19.444828 loss_rnnt 9.340413 lr 0.00027242 rank 2
2022-12-07 20:19:15,431 DEBUG TRAIN Batch 21/3400 loss 7.470773 loss_att 405.463013 loss_ctc 19.372913 loss_rnnt 6.148313 lr 0.00027242 rank 5
2022-12-07 20:19:15,434 DEBUG TRAIN Batch 21/3400 loss 6.170784 loss_att 338.312622 loss_ctc 16.009636 loss_rnnt 5.077579 lr 0.00027242 rank 1
2022-12-07 20:19:15,438 DEBUG TRAIN Batch 21/3400 loss 10.098672 loss_att 385.804779 loss_ctc 18.670776 loss_rnnt 9.146216 lr 0.00027242 rank 0
2022-12-07 20:20:19,390 DEBUG TRAIN Batch 21/3500 loss 7.328911 loss_att 404.131531 loss_ctc 22.153763 loss_rnnt 5.681705 lr 0.00027238 rank 7
2022-12-07 20:20:19,394 DEBUG TRAIN Batch 21/3500 loss 7.842186 loss_att 364.385712 loss_ctc 12.452017 loss_rnnt 7.329983 lr 0.00027238 rank 1
2022-12-07 20:20:19,396 DEBUG TRAIN Batch 21/3500 loss 10.812009 loss_att 425.776917 loss_ctc 15.995703 loss_rnnt 10.236043 lr 0.00027238 rank 4
2022-12-07 20:20:19,398 DEBUG TRAIN Batch 21/3500 loss 7.379409 loss_att 326.087341 loss_ctc 14.292162 loss_rnnt 6.611326 lr 0.00027238 rank 2
2022-12-07 20:20:19,403 DEBUG TRAIN Batch 21/3500 loss 8.164731 loss_att 390.984222 loss_ctc 14.135158 loss_rnnt 7.501350 lr 0.00027238 rank 5
2022-12-07 20:20:19,404 DEBUG TRAIN Batch 21/3500 loss 7.446485 loss_att 387.102539 loss_ctc 18.193392 loss_rnnt 6.252384 lr 0.00027238 rank 3
2022-12-07 20:20:19,413 DEBUG TRAIN Batch 21/3500 loss 8.257418 loss_att 379.143738 loss_ctc 16.017729 loss_rnnt 7.395161 lr 0.00027238 rank 0
2022-12-07 20:20:19,435 DEBUG TRAIN Batch 21/3500 loss 12.864497 loss_att 384.253662 loss_ctc 22.235065 loss_rnnt 11.823322 lr 0.00027238 rank 6
2022-12-07 20:22:15,636 DEBUG TRAIN Batch 21/3600 loss 4.661510 loss_att 347.222351 loss_ctc 8.442555 loss_rnnt 4.241394 lr 0.00027234 rank 7
2022-12-07 20:22:15,639 DEBUG TRAIN Batch 21/3600 loss 4.632703 loss_att 345.960815 loss_ctc 9.119272 loss_rnnt 4.134195 lr 0.00027234 rank 4
2022-12-07 20:22:15,640 DEBUG TRAIN Batch 21/3600 loss 10.850074 loss_att 384.112305 loss_ctc 19.392376 loss_rnnt 9.900929 lr 0.00027234 rank 3
2022-12-07 20:22:15,641 DEBUG TRAIN Batch 21/3600 loss 6.867479 loss_att 356.677063 loss_ctc 16.697001 loss_rnnt 5.775310 lr 0.00027234 rank 5
2022-12-07 20:22:15,642 DEBUG TRAIN Batch 21/3600 loss 10.290071 loss_att 300.240997 loss_ctc 16.781858 loss_rnnt 9.568762 lr 0.00027234 rank 6
2022-12-07 20:22:15,644 DEBUG TRAIN Batch 21/3600 loss 3.571644 loss_att 303.549896 loss_ctc 6.968063 loss_rnnt 3.194264 lr 0.00027234 rank 2
2022-12-07 20:22:15,645 DEBUG TRAIN Batch 21/3600 loss 16.108435 loss_att 405.936737 loss_ctc 31.021345 loss_rnnt 14.451445 lr 0.00027234 rank 1
2022-12-07 20:22:15,646 DEBUG TRAIN Batch 21/3600 loss 8.566823 loss_att 353.528076 loss_ctc 15.675562 loss_rnnt 7.776964 lr 0.00027234 rank 0
2022-12-07 20:23:18,746 DEBUG TRAIN Batch 21/3700 loss 5.506927 loss_att 312.441162 loss_ctc 9.476817 loss_rnnt 5.065828 lr 0.00027230 rank 7
2022-12-07 20:23:18,746 DEBUG TRAIN Batch 21/3700 loss 5.166239 loss_att 333.042786 loss_ctc 12.312265 loss_rnnt 4.372236 lr 0.00027230 rank 3
2022-12-07 20:23:18,748 DEBUG TRAIN Batch 21/3700 loss 12.290001 loss_att 294.153076 loss_ctc 23.481432 loss_rnnt 11.046509 lr 0.00027230 rank 4
2022-12-07 20:23:18,751 DEBUG TRAIN Batch 21/3700 loss 10.924172 loss_att 262.562958 loss_ctc 18.450047 loss_rnnt 10.087964 lr 0.00027230 rank 6
2022-12-07 20:23:18,753 DEBUG TRAIN Batch 21/3700 loss 6.963016 loss_att 362.577637 loss_ctc 11.352378 loss_rnnt 6.475309 lr 0.00027230 rank 1
2022-12-07 20:23:18,754 DEBUG TRAIN Batch 21/3700 loss 10.245338 loss_att 372.802734 loss_ctc 22.400307 loss_rnnt 8.894786 lr 0.00027230 rank 0
2022-12-07 20:23:18,759 DEBUG TRAIN Batch 21/3700 loss 8.056845 loss_att 319.619690 loss_ctc 13.440628 loss_rnnt 7.458647 lr 0.00027230 rank 5
2022-12-07 20:23:18,767 DEBUG TRAIN Batch 21/3700 loss 7.653265 loss_att 260.319519 loss_ctc 13.391690 loss_rnnt 7.015662 lr 0.00027230 rank 2
2022-12-07 20:24:22,535 DEBUG TRAIN Batch 21/3800 loss 10.504463 loss_att 315.947327 loss_ctc 18.849657 loss_rnnt 9.577219 lr 0.00027226 rank 6
2022-12-07 20:24:22,535 DEBUG TRAIN Batch 21/3800 loss 5.610194 loss_att 253.847168 loss_ctc 10.504518 loss_rnnt 5.066380 lr 0.00027226 rank 7
2022-12-07 20:24:22,536 DEBUG TRAIN Batch 21/3800 loss 10.490713 loss_att 233.580826 loss_ctc 17.983973 loss_rnnt 9.658130 lr 0.00027226 rank 4
2022-12-07 20:24:22,537 DEBUG TRAIN Batch 21/3800 loss 15.099428 loss_att 320.593323 loss_ctc 24.670853 loss_rnnt 14.035937 lr 0.00027226 rank 3
2022-12-07 20:24:22,542 DEBUG TRAIN Batch 21/3800 loss 10.469368 loss_att 292.366028 loss_ctc 18.435949 loss_rnnt 9.584193 lr 0.00027226 rank 1
2022-12-07 20:24:22,544 DEBUG TRAIN Batch 21/3800 loss 8.215722 loss_att 295.583466 loss_ctc 15.064818 loss_rnnt 7.454711 lr 0.00027226 rank 0
2022-12-07 20:24:22,547 DEBUG TRAIN Batch 21/3800 loss 5.190159 loss_att 122.574791 loss_ctc 9.960950 loss_rnnt 4.660071 lr 0.00027226 rank 5
2022-12-07 20:24:22,551 DEBUG TRAIN Batch 21/3800 loss 4.252709 loss_att 389.871338 loss_ctc 9.525105 loss_rnnt 3.666888 lr 0.00027226 rank 2
2022-12-07 20:26:14,632 DEBUG TRAIN Batch 21/3900 loss 8.924200 loss_att 422.582123 loss_ctc 22.506170 loss_rnnt 7.415092 lr 0.00027222 rank 4
2022-12-07 20:26:14,634 DEBUG TRAIN Batch 21/3900 loss 3.693698 loss_att 394.847595 loss_ctc 8.312574 loss_rnnt 3.180489 lr 0.00027222 rank 7
2022-12-07 20:26:14,635 DEBUG TRAIN Batch 21/3900 loss 12.124341 loss_att 349.584229 loss_ctc 23.691750 loss_rnnt 10.839073 lr 0.00027222 rank 6
2022-12-07 20:26:14,636 DEBUG TRAIN Batch 21/3900 loss 6.378901 loss_att 395.651184 loss_ctc 20.109718 loss_rnnt 4.853255 lr 0.00027222 rank 2
2022-12-07 20:26:14,639 DEBUG TRAIN Batch 21/3900 loss 2.378834 loss_att 384.681580 loss_ctc 8.758982 loss_rnnt 1.669928 lr 0.00027222 rank 1
2022-12-07 20:26:14,640 DEBUG TRAIN Batch 21/3900 loss 7.828776 loss_att 416.510681 loss_ctc 15.782848 loss_rnnt 6.944991 lr 0.00027222 rank 5
2022-12-07 20:26:14,641 DEBUG TRAIN Batch 21/3900 loss 7.658504 loss_att 143.018234 loss_ctc 13.086154 loss_rnnt 7.055431 lr 0.00027222 rank 0
2022-12-07 20:26:14,683 DEBUG TRAIN Batch 21/3900 loss 8.683138 loss_att 78.173210 loss_ctc 15.477532 loss_rnnt 7.928206 lr 0.00027222 rank 3
2022-12-07 20:27:21,776 DEBUG TRAIN Batch 21/4000 loss 1.672503 loss_att 329.110352 loss_ctc 5.271038 loss_rnnt 1.272666 lr 0.00027218 rank 2
2022-12-07 20:27:21,781 DEBUG TRAIN Batch 21/4000 loss 9.497709 loss_att 378.167725 loss_ctc 19.647873 loss_rnnt 8.369914 lr 0.00027218 rank 0
2022-12-07 20:27:21,782 DEBUG TRAIN Batch 21/4000 loss 28.328625 loss_att 430.486023 loss_ctc 50.077904 loss_rnnt 25.912037 lr 0.00027218 rank 1
2022-12-07 20:27:21,786 DEBUG TRAIN Batch 21/4000 loss 17.973661 loss_att 340.920258 loss_ctc 39.666592 loss_rnnt 15.563337 lr 0.00027218 rank 3
2022-12-07 20:27:21,786 DEBUG TRAIN Batch 21/4000 loss 7.330312 loss_att 393.470276 loss_ctc 11.141883 loss_rnnt 6.906804 lr 0.00027218 rank 7
2022-12-07 20:27:21,786 DEBUG TRAIN Batch 21/4000 loss 6.424170 loss_att 351.233368 loss_ctc 10.339607 loss_rnnt 5.989122 lr 0.00027218 rank 6
2022-12-07 20:27:21,786 DEBUG TRAIN Batch 21/4000 loss 14.213802 loss_att 386.546143 loss_ctc 28.959249 loss_rnnt 12.575419 lr 0.00027218 rank 4
2022-12-07 20:27:21,800 DEBUG TRAIN Batch 21/4000 loss 3.571109 loss_att 373.515961 loss_ctc 9.852699 loss_rnnt 2.873154 lr 0.00027218 rank 5
2022-12-07 20:28:25,161 DEBUG TRAIN Batch 21/4100 loss 7.347528 loss_att 353.971375 loss_ctc 12.079927 loss_rnnt 6.821706 lr 0.00027214 rank 4
2022-12-07 20:28:25,167 DEBUG TRAIN Batch 21/4100 loss 11.530574 loss_att 406.528564 loss_ctc 25.497671 loss_rnnt 9.978674 lr 0.00027214 rank 2
2022-12-07 20:28:25,168 DEBUG TRAIN Batch 21/4100 loss 3.705947 loss_att 399.830017 loss_ctc 12.017286 loss_rnnt 2.782465 lr 0.00027214 rank 5
2022-12-07 20:28:25,168 DEBUG TRAIN Batch 21/4100 loss 5.864382 loss_att 374.070404 loss_ctc 17.247625 loss_rnnt 4.599577 lr 0.00027214 rank 7
2022-12-07 20:28:25,169 DEBUG TRAIN Batch 21/4100 loss 18.197510 loss_att 390.329224 loss_ctc 36.687859 loss_rnnt 16.143028 lr 0.00027214 rank 1
2022-12-07 20:28:25,170 DEBUG TRAIN Batch 21/4100 loss 6.361987 loss_att 364.964233 loss_ctc 15.350899 loss_rnnt 5.363219 lr 0.00027214 rank 6
2022-12-07 20:28:25,172 DEBUG TRAIN Batch 21/4100 loss 9.006603 loss_att 382.630493 loss_ctc 13.814578 loss_rnnt 8.472384 lr 0.00027214 rank 0
2022-12-07 20:28:25,209 DEBUG TRAIN Batch 21/4100 loss 4.711816 loss_att 379.260498 loss_ctc 12.140110 loss_rnnt 3.886451 lr 0.00027214 rank 3
2022-12-07 20:29:28,731 DEBUG TRAIN Batch 21/4200 loss 5.957785 loss_att 329.399231 loss_ctc 11.054472 loss_rnnt 5.391487 lr 0.00027210 rank 7
2022-12-07 20:29:28,736 DEBUG TRAIN Batch 21/4200 loss 4.760524 loss_att 372.496765 loss_ctc 8.080988 loss_rnnt 4.391584 lr 0.00027210 rank 0
2022-12-07 20:29:28,737 DEBUG TRAIN Batch 21/4200 loss 5.657667 loss_att 321.991760 loss_ctc 8.858477 loss_rnnt 5.302022 lr 0.00027210 rank 4
2022-12-07 20:29:28,738 DEBUG TRAIN Batch 21/4200 loss 14.608908 loss_att 387.232910 loss_ctc 21.520622 loss_rnnt 13.840940 lr 0.00027210 rank 3
2022-12-07 20:29:28,741 DEBUG TRAIN Batch 21/4200 loss 9.611965 loss_att 359.420410 loss_ctc 14.223893 loss_rnnt 9.099529 lr 0.00027210 rank 2
2022-12-07 20:29:28,768 DEBUG TRAIN Batch 21/4200 loss 11.762307 loss_att 413.217682 loss_ctc 18.358356 loss_rnnt 11.029413 lr 0.00027210 rank 1
2022-12-07 20:29:28,778 DEBUG TRAIN Batch 21/4200 loss 5.115665 loss_att 343.707367 loss_ctc 10.219233 loss_rnnt 4.548602 lr 0.00027210 rank 6
2022-12-07 20:29:28,779 DEBUG TRAIN Batch 21/4200 loss 13.665787 loss_att 409.027618 loss_ctc 32.112381 loss_rnnt 11.616166 lr 0.00027210 rank 5
2022-12-07 20:31:24,883 DEBUG TRAIN Batch 21/4300 loss 12.452074 loss_att 358.881348 loss_ctc 22.261990 loss_rnnt 11.362083 lr 0.00027206 rank 7
2022-12-07 20:31:24,883 DEBUG TRAIN Batch 21/4300 loss 7.690106 loss_att 287.750000 loss_ctc 15.782095 loss_rnnt 6.790997 lr 0.00027206 rank 2
2022-12-07 20:31:24,884 DEBUG TRAIN Batch 21/4300 loss 6.676524 loss_att 357.117340 loss_ctc 12.646516 loss_rnnt 6.013191 lr 0.00027206 rank 5
2022-12-07 20:31:24,885 DEBUG TRAIN Batch 21/4300 loss 17.102556 loss_att 338.349670 loss_ctc 27.623241 loss_rnnt 15.933591 lr 0.00027206 rank 4
2022-12-07 20:31:24,888 DEBUG TRAIN Batch 21/4300 loss 13.163614 loss_att 352.305115 loss_ctc 21.317856 loss_rnnt 12.257588 lr 0.00027206 rank 0
2022-12-07 20:31:24,889 DEBUG TRAIN Batch 21/4300 loss 7.397397 loss_att 364.618622 loss_ctc 16.207123 loss_rnnt 6.418538 lr 0.00027206 rank 1
2022-12-07 20:31:24,893 DEBUG TRAIN Batch 21/4300 loss 10.085511 loss_att 299.365082 loss_ctc 15.408699 loss_rnnt 9.494046 lr 0.00027206 rank 6
2022-12-07 20:31:24,896 DEBUG TRAIN Batch 21/4300 loss 8.366697 loss_att 335.033997 loss_ctc 21.346262 loss_rnnt 6.924523 lr 0.00027206 rank 3
2022-12-07 20:32:28,945 DEBUG TRAIN Batch 21/4400 loss 9.560035 loss_att 330.889648 loss_ctc 18.228640 loss_rnnt 8.596857 lr 0.00027202 rank 0
2022-12-07 20:32:28,946 DEBUG TRAIN Batch 21/4400 loss 5.325245 loss_att 321.144409 loss_ctc 11.876180 loss_rnnt 4.597363 lr 0.00027202 rank 3
2022-12-07 20:32:28,947 DEBUG TRAIN Batch 21/4400 loss 21.966148 loss_att 320.218689 loss_ctc 34.519627 loss_rnnt 20.571318 lr 0.00027202 rank 4
2022-12-07 20:32:28,948 DEBUG TRAIN Batch 21/4400 loss 8.936474 loss_att 292.493317 loss_ctc 18.676970 loss_rnnt 7.854197 lr 0.00027202 rank 1
2022-12-07 20:32:28,951 DEBUG TRAIN Batch 21/4400 loss 9.608765 loss_att 282.190796 loss_ctc 16.407419 loss_rnnt 8.853358 lr 0.00027202 rank 7
2022-12-07 20:32:28,953 DEBUG TRAIN Batch 21/4400 loss 9.360985 loss_att 197.600876 loss_ctc 15.300573 loss_rnnt 8.701031 lr 0.00027202 rank 6
2022-12-07 20:32:28,955 DEBUG TRAIN Batch 21/4400 loss 13.697223 loss_att 171.043274 loss_ctc 22.290274 loss_rnnt 12.742439 lr 0.00027202 rank 2
2022-12-07 20:32:28,957 DEBUG TRAIN Batch 21/4400 loss 6.695939 loss_att 194.737335 loss_ctc 10.180626 loss_rnnt 6.308752 lr 0.00027202 rank 5
2022-12-07 20:33:31,777 DEBUG TRAIN Batch 21/4500 loss 6.513349 loss_att 173.912048 loss_ctc 11.580694 loss_rnnt 5.950311 lr 0.00027198 rank 4
2022-12-07 20:33:31,787 DEBUG TRAIN Batch 21/4500 loss 6.781389 loss_att 428.027405 loss_ctc 15.851391 loss_rnnt 5.773611 lr 0.00027198 rank 2
2022-12-07 20:33:31,787 DEBUG TRAIN Batch 21/4500 loss 4.692364 loss_att 454.656494 loss_ctc 9.483511 loss_rnnt 4.160015 lr 0.00027198 rank 7
2022-12-07 20:33:31,791 DEBUG TRAIN Batch 21/4500 loss 13.753249 loss_att 174.858414 loss_ctc 19.171043 loss_rnnt 13.151272 lr 0.00027198 rank 1
2022-12-07 20:33:31,796 DEBUG TRAIN Batch 21/4500 loss 11.772291 loss_att 266.917206 loss_ctc 17.893221 loss_rnnt 11.092189 lr 0.00027198 rank 0
2022-12-07 20:33:31,801 DEBUG TRAIN Batch 21/4500 loss 3.539541 loss_att 452.046143 loss_ctc 9.241781 loss_rnnt 2.905958 lr 0.00027198 rank 5
2022-12-07 20:33:31,803 DEBUG TRAIN Batch 21/4500 loss 5.778798 loss_att 263.493347 loss_ctc 14.744574 loss_rnnt 4.782600 lr 0.00027198 rank 3
2022-12-07 20:33:31,836 DEBUG TRAIN Batch 21/4500 loss 10.560925 loss_att 353.003357 loss_ctc 23.136152 loss_rnnt 9.163676 lr 0.00027198 rank 6
2022-12-07 20:34:36,697 DEBUG TRAIN Batch 21/4600 loss 4.577540 loss_att 344.106445 loss_ctc 8.842861 loss_rnnt 4.103616 lr 0.00027194 rank 7
2022-12-07 20:34:36,698 DEBUG TRAIN Batch 21/4600 loss 6.132303 loss_att 419.542847 loss_ctc 12.480276 loss_rnnt 5.426973 lr 0.00027194 rank 4
2022-12-07 20:34:36,701 DEBUG TRAIN Batch 21/4600 loss 3.972662 loss_att 396.328918 loss_ctc 9.190674 loss_rnnt 3.392883 lr 0.00027194 rank 5
2022-12-07 20:34:36,703 DEBUG TRAIN Batch 21/4600 loss 12.086585 loss_att 366.290161 loss_ctc 21.542959 loss_rnnt 11.035877 lr 0.00027194 rank 2
2022-12-07 20:34:36,705 DEBUG TRAIN Batch 21/4600 loss 7.403066 loss_att 361.212830 loss_ctc 13.867599 loss_rnnt 6.684784 lr 0.00027194 rank 0
2022-12-07 20:34:36,707 DEBUG TRAIN Batch 21/4600 loss 9.854712 loss_att 374.491882 loss_ctc 17.400080 loss_rnnt 9.016338 lr 0.00027194 rank 6
2022-12-07 20:34:36,707 DEBUG TRAIN Batch 21/4600 loss 11.611120 loss_att 398.183350 loss_ctc 27.541199 loss_rnnt 9.841112 lr 0.00027194 rank 1
2022-12-07 20:34:36,717 DEBUG TRAIN Batch 21/4600 loss 11.353237 loss_att 444.526611 loss_ctc 21.701015 loss_rnnt 10.203485 lr 0.00027194 rank 3
2022-12-07 20:36:29,763 DEBUG TRAIN Batch 21/4700 loss 10.107246 loss_att 426.573120 loss_ctc 22.474480 loss_rnnt 8.733109 lr 0.00027190 rank 7
2022-12-07 20:36:29,768 DEBUG TRAIN Batch 21/4700 loss 6.583281 loss_att 356.469116 loss_ctc 14.517843 loss_rnnt 5.701663 lr 0.00027190 rank 5
2022-12-07 20:36:29,769 DEBUG TRAIN Batch 21/4700 loss 12.310545 loss_att 414.127045 loss_ctc 22.665159 loss_rnnt 11.160032 lr 0.00027190 rank 0
2022-12-07 20:36:29,770 DEBUG TRAIN Batch 21/4700 loss 11.079145 loss_att 432.024902 loss_ctc 24.358496 loss_rnnt 9.603662 lr 0.00027190 rank 1
2022-12-07 20:36:29,770 DEBUG TRAIN Batch 21/4700 loss 4.629277 loss_att 378.887726 loss_ctc 13.996344 loss_rnnt 3.588492 lr 0.00027190 rank 6
2022-12-07 20:36:29,771 DEBUG TRAIN Batch 21/4700 loss 11.085503 loss_att 401.719727 loss_ctc 16.579624 loss_rnnt 10.475044 lr 0.00027190 rank 3
2022-12-07 20:36:29,773 DEBUG TRAIN Batch 21/4700 loss 7.064501 loss_att 394.154785 loss_ctc 13.634974 loss_rnnt 6.334448 lr 0.00027190 rank 2
2022-12-07 20:36:29,774 DEBUG TRAIN Batch 21/4700 loss 7.200243 loss_att 373.551270 loss_ctc 17.704725 loss_rnnt 6.033079 lr 0.00027190 rank 4
2022-12-07 20:37:33,115 DEBUG TRAIN Batch 21/4800 loss 5.042820 loss_att 385.604187 loss_ctc 11.288422 loss_rnnt 4.348864 lr 0.00027186 rank 4
2022-12-07 20:37:33,118 DEBUG TRAIN Batch 21/4800 loss 8.589661 loss_att 381.530090 loss_ctc 18.719185 loss_rnnt 7.464159 lr 0.00027186 rank 7
2022-12-07 20:37:33,119 DEBUG TRAIN Batch 21/4800 loss 6.502531 loss_att 376.427460 loss_ctc 14.871129 loss_rnnt 5.572686 lr 0.00027186 rank 6
2022-12-07 20:37:33,119 DEBUG TRAIN Batch 21/4800 loss 2.916858 loss_att 400.888672 loss_ctc 7.590559 loss_rnnt 2.397558 lr 0.00027186 rank 3
2022-12-07 20:37:33,121 DEBUG TRAIN Batch 21/4800 loss 6.068300 loss_att 391.735931 loss_ctc 12.990168 loss_rnnt 5.299203 lr 0.00027186 rank 1
2022-12-07 20:37:33,124 DEBUG TRAIN Batch 21/4800 loss 14.126652 loss_att 392.796356 loss_ctc 25.355156 loss_rnnt 12.879041 lr 0.00027186 rank 2
2022-12-07 20:37:33,127 DEBUG TRAIN Batch 21/4800 loss 20.855406 loss_att 387.644775 loss_ctc 38.740669 loss_rnnt 18.868155 lr 0.00027186 rank 0
2022-12-07 20:37:33,129 DEBUG TRAIN Batch 21/4800 loss 13.129419 loss_att 397.840271 loss_ctc 28.562263 loss_rnnt 11.414660 lr 0.00027186 rank 5
2022-12-07 20:38:37,404 DEBUG TRAIN Batch 21/4900 loss 8.764098 loss_att 316.832886 loss_ctc 17.333057 loss_rnnt 7.811992 lr 0.00027182 rank 4
2022-12-07 20:38:37,404 DEBUG TRAIN Batch 21/4900 loss 11.251814 loss_att 382.220551 loss_ctc 23.397366 loss_rnnt 9.902308 lr 0.00027182 rank 7
2022-12-07 20:38:37,410 DEBUG TRAIN Batch 21/4900 loss 9.097527 loss_att 357.729706 loss_ctc 15.257000 loss_rnnt 8.413141 lr 0.00027182 rank 2
2022-12-07 20:38:37,411 DEBUG TRAIN Batch 21/4900 loss 7.382829 loss_att 340.096069 loss_ctc 11.057552 loss_rnnt 6.974526 lr 0.00027182 rank 6
2022-12-07 20:38:37,412 DEBUG TRAIN Batch 21/4900 loss 9.650008 loss_att 362.519012 loss_ctc 18.019543 loss_rnnt 8.720060 lr 0.00027182 rank 1
2022-12-07 20:38:37,414 DEBUG TRAIN Batch 21/4900 loss 4.048832 loss_att 336.626221 loss_ctc 9.400396 loss_rnnt 3.454214 lr 0.00027182 rank 5
2022-12-07 20:38:37,415 DEBUG TRAIN Batch 21/4900 loss 5.499761 loss_att 310.118195 loss_ctc 8.582458 loss_rnnt 5.157239 lr 0.00027182 rank 0
2022-12-07 20:38:37,415 DEBUG TRAIN Batch 21/4900 loss 8.803684 loss_att 412.913971 loss_ctc 20.061756 loss_rnnt 7.552788 lr 0.00027182 rank 3
2022-12-07 20:40:34,434 DEBUG TRAIN Batch 21/5000 loss 10.449060 loss_att 313.252808 loss_ctc 15.715937 loss_rnnt 9.863853 lr 0.00027177 rank 6
2022-12-07 20:40:34,437 DEBUG TRAIN Batch 21/5000 loss 9.605251 loss_att 119.244835 loss_ctc 14.472232 loss_rnnt 9.064476 lr 0.00027177 rank 2
2022-12-07 20:40:34,438 DEBUG TRAIN Batch 21/5000 loss 12.484271 loss_att 336.999969 loss_ctc 24.038351 loss_rnnt 11.200484 lr 0.00027177 rank 7
2022-12-07 20:40:34,439 DEBUG TRAIN Batch 21/5000 loss 8.709126 loss_att 300.164459 loss_ctc 11.764836 loss_rnnt 8.369602 lr 0.00027177 rank 4
2022-12-07 20:40:34,441 DEBUG TRAIN Batch 21/5000 loss 8.176560 loss_att 336.566650 loss_ctc 14.026321 loss_rnnt 7.526587 lr 0.00027177 rank 1
2022-12-07 20:40:34,442 DEBUG TRAIN Batch 21/5000 loss 18.664072 loss_att 348.283081 loss_ctc 27.635181 loss_rnnt 17.667282 lr 0.00027177 rank 0
2022-12-07 20:40:34,444 DEBUG TRAIN Batch 21/5000 loss 9.791663 loss_att 290.247803 loss_ctc 20.145308 loss_rnnt 8.641258 lr 0.00027177 rank 5
2022-12-07 20:40:34,482 DEBUG TRAIN Batch 21/5000 loss 10.696441 loss_att 303.270386 loss_ctc 13.837904 loss_rnnt 10.347390 lr 0.00027177 rank 3
2022-12-07 20:41:38,283 DEBUG TRAIN Batch 21/5100 loss 9.745221 loss_att 180.731140 loss_ctc 16.412655 loss_rnnt 9.004395 lr 0.00027173 rank 7
2022-12-07 20:41:38,286 DEBUG TRAIN Batch 21/5100 loss 11.670115 loss_att 165.888962 loss_ctc 18.107193 loss_rnnt 10.954884 lr 0.00027173 rank 4
2022-12-07 20:41:38,288 DEBUG TRAIN Batch 21/5100 loss 13.254543 loss_att 300.603119 loss_ctc 22.278675 loss_rnnt 12.251863 lr 0.00027173 rank 3
2022-12-07 20:41:38,291 DEBUG TRAIN Batch 21/5100 loss 6.996316 loss_att 240.368347 loss_ctc 11.938731 loss_rnnt 6.447159 lr 0.00027173 rank 0
2022-12-07 20:41:38,297 DEBUG TRAIN Batch 21/5100 loss 6.922214 loss_att 352.058685 loss_ctc 9.022422 loss_rnnt 6.688858 lr 0.00027173 rank 6
2022-12-07 20:41:38,305 DEBUG TRAIN Batch 21/5100 loss 8.311448 loss_att 369.676117 loss_ctc 17.459333 loss_rnnt 7.295017 lr 0.00027173 rank 2
2022-12-07 20:41:38,314 DEBUG TRAIN Batch 21/5100 loss 12.560737 loss_att 216.504547 loss_ctc 17.938608 loss_rnnt 11.963196 lr 0.00027173 rank 1
2022-12-07 20:41:38,320 DEBUG TRAIN Batch 21/5100 loss 8.187660 loss_att 95.243935 loss_ctc 12.167482 loss_rnnt 7.745459 lr 0.00027173 rank 5
2022-12-07 20:42:42,058 DEBUG TRAIN Batch 21/5200 loss 11.749358 loss_att 406.095459 loss_ctc 29.481915 loss_rnnt 9.779075 lr 0.00027169 rank 4
2022-12-07 20:42:42,059 DEBUG TRAIN Batch 21/5200 loss 8.964257 loss_att 380.907898 loss_ctc 26.448942 loss_rnnt 7.021515 lr 0.00027169 rank 6
2022-12-07 20:42:42,061 DEBUG TRAIN Batch 21/5200 loss 4.988488 loss_att 373.340820 loss_ctc 16.592905 loss_rnnt 3.699109 lr 0.00027169 rank 1
2022-12-07 20:42:42,063 DEBUG TRAIN Batch 21/5200 loss 17.760569 loss_att 526.087097 loss_ctc 36.509518 loss_rnnt 15.677353 lr 0.00027169 rank 3
2022-12-07 20:42:42,064 DEBUG TRAIN Batch 21/5200 loss 5.070012 loss_att 396.786865 loss_ctc 11.044413 loss_rnnt 4.406189 lr 0.00027169 rank 2
2022-12-07 20:42:42,065 DEBUG TRAIN Batch 21/5200 loss 2.125353 loss_att 344.446472 loss_ctc 7.745213 loss_rnnt 1.500924 lr 0.00027169 rank 7
2022-12-07 20:42:42,069 DEBUG TRAIN Batch 21/5200 loss 6.752059 loss_att 427.217773 loss_ctc 12.268615 loss_rnnt 6.139109 lr 0.00027169 rank 0
2022-12-07 20:42:42,109 DEBUG TRAIN Batch 21/5200 loss 12.443769 loss_att 403.755829 loss_ctc 30.152390 loss_rnnt 10.476145 lr 0.00027169 rank 5
2022-12-07 20:43:47,306 DEBUG TRAIN Batch 21/5300 loss 11.352426 loss_att 348.582642 loss_ctc 14.678260 loss_rnnt 10.982889 lr 0.00027165 rank 4
2022-12-07 20:43:47,307 DEBUG TRAIN Batch 21/5300 loss 6.589011 loss_att 326.630524 loss_ctc 13.564026 loss_rnnt 5.814010 lr 0.00027165 rank 2
2022-12-07 20:43:47,308 DEBUG TRAIN Batch 21/5300 loss 9.871085 loss_att 443.539154 loss_ctc 19.807503 loss_rnnt 8.767039 lr 0.00027165 rank 7
2022-12-07 20:43:47,308 DEBUG TRAIN Batch 21/5300 loss 5.913824 loss_att 327.006104 loss_ctc 13.808146 loss_rnnt 5.036677 lr 0.00027165 rank 0
2022-12-07 20:43:47,312 DEBUG TRAIN Batch 21/5300 loss 2.698603 loss_att 336.594696 loss_ctc 10.252439 loss_rnnt 1.859288 lr 0.00027165 rank 5
2022-12-07 20:43:47,315 DEBUG TRAIN Batch 21/5300 loss 6.227988 loss_att 398.601776 loss_ctc 20.530928 loss_rnnt 4.638773 lr 0.00027165 rank 1
2022-12-07 20:43:47,317 DEBUG TRAIN Batch 21/5300 loss 14.976273 loss_att 386.936279 loss_ctc 24.558498 loss_rnnt 13.911581 lr 0.00027165 rank 6
2022-12-07 20:43:47,320 DEBUG TRAIN Batch 21/5300 loss 14.271688 loss_att 393.519043 loss_ctc 23.949604 loss_rnnt 13.196364 lr 0.00027165 rank 3
2022-12-07 20:45:44,754 DEBUG TRAIN Batch 21/5400 loss 4.301729 loss_att 333.012299 loss_ctc 12.710608 loss_rnnt 3.367409 lr 0.00027161 rank 6
2022-12-07 20:45:44,757 DEBUG TRAIN Batch 21/5400 loss 9.388486 loss_att 406.318237 loss_ctc 17.891941 loss_rnnt 8.443658 lr 0.00027161 rank 7
2022-12-07 20:45:44,757 DEBUG TRAIN Batch 21/5400 loss 8.037357 loss_att 380.369873 loss_ctc 13.237893 loss_rnnt 7.459520 lr 0.00027161 rank 4
2022-12-07 20:45:44,759 DEBUG TRAIN Batch 21/5400 loss 3.738096 loss_att 439.166565 loss_ctc 11.597743 loss_rnnt 2.864802 lr 0.00027161 rank 0
2022-12-07 20:45:44,760 DEBUG TRAIN Batch 21/5400 loss 11.319680 loss_att 437.521088 loss_ctc 25.756674 loss_rnnt 9.715570 lr 0.00027161 rank 3
2022-12-07 20:45:44,761 DEBUG TRAIN Batch 21/5400 loss 5.990355 loss_att 371.978241 loss_ctc 9.660244 loss_rnnt 5.582590 lr 0.00027161 rank 1
2022-12-07 20:45:44,763 DEBUG TRAIN Batch 21/5400 loss 12.040568 loss_att 393.394836 loss_ctc 24.121990 loss_rnnt 10.698189 lr 0.00027161 rank 5
2022-12-07 20:45:44,797 DEBUG TRAIN Batch 21/5400 loss 4.657219 loss_att 374.515015 loss_ctc 8.858771 loss_rnnt 4.190380 lr 0.00027161 rank 2
2022-12-07 20:46:48,214 DEBUG TRAIN Batch 21/5500 loss 8.929811 loss_att 338.115967 loss_ctc 15.115541 loss_rnnt 8.242509 lr 0.00027157 rank 0
2022-12-07 20:46:48,219 DEBUG TRAIN Batch 21/5500 loss 16.198818 loss_att 414.645142 loss_ctc 25.906712 loss_rnnt 15.120163 lr 0.00027157 rank 4
2022-12-07 20:46:48,230 DEBUG TRAIN Batch 21/5500 loss 15.396244 loss_att 336.509949 loss_ctc 16.376137 loss_rnnt 15.287368 lr 0.00027157 rank 6
2022-12-07 20:46:48,233 DEBUG TRAIN Batch 21/5500 loss 12.080102 loss_att 372.437012 loss_ctc 19.713642 loss_rnnt 11.231932 lr 0.00027157 rank 1
2022-12-07 20:46:48,234 DEBUG TRAIN Batch 21/5500 loss 13.775179 loss_att 440.611938 loss_ctc 32.312794 loss_rnnt 11.715445 lr 0.00027157 rank 3
2022-12-07 20:46:48,235 DEBUG TRAIN Batch 21/5500 loss 8.606494 loss_att 310.309326 loss_ctc 17.955402 loss_rnnt 7.567727 lr 0.00027157 rank 7
2022-12-07 20:46:48,238 DEBUG TRAIN Batch 21/5500 loss 6.543783 loss_att 299.166168 loss_ctc 13.309753 loss_rnnt 5.792008 lr 0.00027157 rank 2
2022-12-07 20:46:48,274 DEBUG TRAIN Batch 21/5500 loss 6.739616 loss_att 373.868408 loss_ctc 10.268660 loss_rnnt 6.347501 lr 0.00027157 rank 5
2022-12-07 20:47:51,802 DEBUG TRAIN Batch 21/5600 loss 4.406032 loss_att 296.036407 loss_ctc 8.900620 loss_rnnt 3.906633 lr 0.00027153 rank 4
2022-12-07 20:47:51,804 DEBUG TRAIN Batch 21/5600 loss 4.980179 loss_att 336.447601 loss_ctc 15.061015 loss_rnnt 3.860086 lr 0.00027153 rank 3
2022-12-07 20:47:51,805 DEBUG TRAIN Batch 21/5600 loss 14.046743 loss_att 304.562225 loss_ctc 26.252960 loss_rnnt 12.690497 lr 0.00027153 rank 6
2022-12-07 20:47:51,806 DEBUG TRAIN Batch 21/5600 loss 10.677121 loss_att 410.451355 loss_ctc 28.920074 loss_rnnt 8.650126 lr 0.00027153 rank 0
2022-12-07 20:47:51,807 DEBUG TRAIN Batch 21/5600 loss 3.950457 loss_att 307.025818 loss_ctc 8.957535 loss_rnnt 3.394115 lr 0.00027153 rank 7
2022-12-07 20:47:51,811 DEBUG TRAIN Batch 21/5600 loss 7.964997 loss_att 185.811279 loss_ctc 15.643061 loss_rnnt 7.111878 lr 0.00027153 rank 2
2022-12-07 20:47:51,816 DEBUG TRAIN Batch 21/5600 loss 9.972224 loss_att 366.183228 loss_ctc 17.991789 loss_rnnt 9.081161 lr 0.00027153 rank 1
2022-12-07 20:47:51,826 DEBUG TRAIN Batch 21/5600 loss 13.203360 loss_att 379.306793 loss_ctc 21.424879 loss_rnnt 12.289858 lr 0.00027153 rank 5
2022-12-07 20:49:47,790 DEBUG TRAIN Batch 21/5700 loss 7.003236 loss_att 220.064362 loss_ctc 13.171205 loss_rnnt 6.317906 lr 0.00027149 rank 4
2022-12-07 20:49:47,791 DEBUG TRAIN Batch 21/5700 loss 11.216668 loss_att 233.351562 loss_ctc 15.784803 loss_rnnt 10.709097 lr 0.00027149 rank 7
2022-12-07 20:49:47,793 DEBUG TRAIN Batch 21/5700 loss 13.307863 loss_att 291.200531 loss_ctc 22.279922 loss_rnnt 12.310968 lr 0.00027149 rank 1
2022-12-07 20:49:47,797 DEBUG TRAIN Batch 21/5700 loss 7.718396 loss_att 401.722168 loss_ctc 15.733076 loss_rnnt 6.827876 lr 0.00027149 rank 6
2022-12-07 20:49:47,799 DEBUG TRAIN Batch 21/5700 loss 5.202313 loss_att 299.025238 loss_ctc 12.754035 loss_rnnt 4.363233 lr 0.00027149 rank 0
2022-12-07 20:49:47,799 DEBUG TRAIN Batch 21/5700 loss 13.687864 loss_att 389.639465 loss_ctc 30.392775 loss_rnnt 11.831764 lr 0.00027149 rank 3
2022-12-07 20:49:47,809 DEBUG TRAIN Batch 21/5700 loss 13.691212 loss_att 197.577591 loss_ctc 20.942451 loss_rnnt 12.885519 lr 0.00027149 rank 5
2022-12-07 20:49:47,810 DEBUG TRAIN Batch 21/5700 loss 6.057549 loss_att 383.263641 loss_ctc 14.848948 loss_rnnt 5.080727 lr 0.00027149 rank 2
2022-12-07 20:50:51,280 DEBUG TRAIN Batch 21/5800 loss 11.560186 loss_att 368.393799 loss_ctc 29.419865 loss_rnnt 9.575778 lr 0.00027145 rank 2
2022-12-07 20:50:51,282 DEBUG TRAIN Batch 21/5800 loss 10.214981 loss_att 407.036713 loss_ctc 19.465576 loss_rnnt 9.187137 lr 0.00027145 rank 7
2022-12-07 20:50:51,282 DEBUG TRAIN Batch 21/5800 loss 8.428144 loss_att 443.198914 loss_ctc 13.839042 loss_rnnt 7.826932 lr 0.00027145 rank 5
2022-12-07 20:50:51,283 DEBUG TRAIN Batch 21/5800 loss 10.602999 loss_att 313.868866 loss_ctc 19.431349 loss_rnnt 9.622070 lr 0.00027145 rank 3
2022-12-07 20:50:51,285 DEBUG TRAIN Batch 21/5800 loss 8.067410 loss_att 412.769958 loss_ctc 13.755031 loss_rnnt 7.435452 lr 0.00027145 rank 6
2022-12-07 20:50:51,286 DEBUG TRAIN Batch 21/5800 loss 3.814345 loss_att 455.215302 loss_ctc 9.663525 loss_rnnt 3.164436 lr 0.00027145 rank 4
2022-12-07 20:50:51,286 DEBUG TRAIN Batch 21/5800 loss 9.486570 loss_att 126.282890 loss_ctc 16.370590 loss_rnnt 8.721680 lr 0.00027145 rank 0
2022-12-07 20:50:51,286 DEBUG TRAIN Batch 21/5800 loss 1.716231 loss_att 346.514252 loss_ctc 4.783890 loss_rnnt 1.375381 lr 0.00027145 rank 1
2022-12-07 20:51:54,241 DEBUG TRAIN Batch 21/5900 loss 1.958554 loss_att 387.104248 loss_ctc 7.506927 loss_rnnt 1.342068 lr 0.00027141 rank 7
2022-12-07 20:51:54,255 DEBUG TRAIN Batch 21/5900 loss 5.206827 loss_att 343.917694 loss_ctc 12.342093 loss_rnnt 4.414020 lr 0.00027141 rank 4
2022-12-07 20:51:54,257 DEBUG TRAIN Batch 21/5900 loss 10.644573 loss_att 368.221680 loss_ctc 13.556705 loss_rnnt 10.321003 lr 0.00027141 rank 2
2022-12-07 20:51:54,258 DEBUG TRAIN Batch 21/5900 loss 8.208086 loss_att 284.494141 loss_ctc 15.270868 loss_rnnt 7.423332 lr 0.00027141 rank 6
2022-12-07 20:51:54,260 DEBUG TRAIN Batch 21/5900 loss 9.602492 loss_att 375.175049 loss_ctc 15.142958 loss_rnnt 8.986885 lr 0.00027141 rank 0
2022-12-07 20:51:54,260 DEBUG TRAIN Batch 21/5900 loss 14.069695 loss_att 443.138763 loss_ctc 23.081070 loss_rnnt 13.068431 lr 0.00027141 rank 1
2022-12-07 20:51:54,261 DEBUG TRAIN Batch 21/5900 loss 10.744441 loss_att 373.153015 loss_ctc 17.083809 loss_rnnt 10.040068 lr 0.00027141 rank 5
2022-12-07 20:51:54,261 DEBUG TRAIN Batch 21/5900 loss 4.309000 loss_att 417.832764 loss_ctc 12.707056 loss_rnnt 3.375883 lr 0.00027141 rank 3
2022-12-07 20:52:58,647 DEBUG TRAIN Batch 21/6000 loss 12.341976 loss_att 428.577423 loss_ctc 19.915257 loss_rnnt 11.500501 lr 0.00027137 rank 4
2022-12-07 20:52:58,648 DEBUG TRAIN Batch 21/6000 loss 6.731352 loss_att 421.178772 loss_ctc 17.927711 loss_rnnt 5.487312 lr 0.00027137 rank 2
2022-12-07 20:52:58,649 DEBUG TRAIN Batch 21/6000 loss 12.209894 loss_att 395.007263 loss_ctc 26.199173 loss_rnnt 10.655530 lr 0.00027137 rank 6
2022-12-07 20:52:58,649 DEBUG TRAIN Batch 21/6000 loss 8.533653 loss_att 378.628510 loss_ctc 22.015377 loss_rnnt 7.035684 lr 0.00027137 rank 3
2022-12-07 20:52:58,649 DEBUG TRAIN Batch 21/6000 loss 18.945221 loss_att 416.222015 loss_ctc 24.183989 loss_rnnt 18.363136 lr 0.00027137 rank 7
2022-12-07 20:52:58,657 DEBUG TRAIN Batch 21/6000 loss 9.565147 loss_att 382.069672 loss_ctc 18.277515 loss_rnnt 8.597107 lr 0.00027137 rank 1
2022-12-07 20:52:58,659 DEBUG TRAIN Batch 21/6000 loss 7.920312 loss_att 335.345154 loss_ctc 18.821388 loss_rnnt 6.709082 lr 0.00027137 rank 5
2022-12-07 20:52:58,677 DEBUG TRAIN Batch 21/6000 loss 10.282709 loss_att 425.956299 loss_ctc 26.783270 loss_rnnt 8.449313 lr 0.00027137 rank 0
2022-12-07 20:54:54,903 DEBUG TRAIN Batch 21/6100 loss 6.135138 loss_att 352.950165 loss_ctc 10.905874 loss_rnnt 5.605056 lr 0.00027133 rank 4
2022-12-07 20:54:54,908 DEBUG TRAIN Batch 21/6100 loss 7.789619 loss_att 360.090271 loss_ctc 14.767837 loss_rnnt 7.014262 lr 0.00027133 rank 7
2022-12-07 20:54:54,909 DEBUG TRAIN Batch 21/6100 loss 11.355627 loss_att 428.814117 loss_ctc 26.796093 loss_rnnt 9.640020 lr 0.00027133 rank 5
2022-12-07 20:54:54,910 DEBUG TRAIN Batch 21/6100 loss 9.892378 loss_att 386.721161 loss_ctc 30.171665 loss_rnnt 7.639123 lr 0.00027133 rank 3
2022-12-07 20:54:54,910 DEBUG TRAIN Batch 21/6100 loss 7.367718 loss_att 330.931458 loss_ctc 14.064502 loss_rnnt 6.623631 lr 0.00027133 rank 6
2022-12-07 20:54:54,911 DEBUG TRAIN Batch 21/6100 loss 12.607050 loss_att 353.970001 loss_ctc 20.684246 loss_rnnt 11.709584 lr 0.00027133 rank 1
2022-12-07 20:54:54,911 DEBUG TRAIN Batch 21/6100 loss 11.093935 loss_att 312.328156 loss_ctc 19.143688 loss_rnnt 10.199518 lr 0.00027133 rank 0
2022-12-07 20:54:54,914 DEBUG TRAIN Batch 21/6100 loss 7.245862 loss_att 321.154694 loss_ctc 15.425523 loss_rnnt 6.337011 lr 0.00027133 rank 2
2022-12-07 20:55:58,648 DEBUG TRAIN Batch 21/6200 loss 12.875045 loss_att 359.682983 loss_ctc 20.873482 loss_rnnt 11.986330 lr 0.00027129 rank 7
2022-12-07 20:55:58,652 DEBUG TRAIN Batch 21/6200 loss 3.910626 loss_att 245.326950 loss_ctc 15.054214 loss_rnnt 2.672450 lr 0.00027129 rank 2
2022-12-07 20:55:58,652 DEBUG TRAIN Batch 21/6200 loss 8.314631 loss_att 386.177307 loss_ctc 15.559500 loss_rnnt 7.509646 lr 0.00027129 rank 4
2022-12-07 20:55:58,653 DEBUG TRAIN Batch 21/6200 loss 9.589939 loss_att 330.055481 loss_ctc 15.139027 loss_rnnt 8.973374 lr 0.00027129 rank 1
2022-12-07 20:55:58,654 DEBUG TRAIN Batch 21/6200 loss 17.056038 loss_att 422.824280 loss_ctc 26.574268 loss_rnnt 15.998457 lr 0.00027129 rank 3
2022-12-07 20:55:58,656 DEBUG TRAIN Batch 21/6200 loss 9.646409 loss_att 322.875214 loss_ctc 15.425451 loss_rnnt 9.004293 lr 0.00027129 rank 0
2022-12-07 20:55:58,660 DEBUG TRAIN Batch 21/6200 loss 10.853661 loss_att 318.061035 loss_ctc 16.966732 loss_rnnt 10.174431 lr 0.00027129 rank 5
2022-12-07 20:55:58,664 DEBUG TRAIN Batch 21/6200 loss 5.832170 loss_att 232.028976 loss_ctc 11.608843 loss_rnnt 5.190318 lr 0.00027129 rank 6
2022-12-07 20:57:02,139 DEBUG TRAIN Batch 21/6300 loss 3.577210 loss_att 392.364014 loss_ctc 9.046716 loss_rnnt 2.969487 lr 0.00027125 rank 2
2022-12-07 20:57:02,139 DEBUG TRAIN Batch 21/6300 loss 10.661018 loss_att 262.066498 loss_ctc 20.886488 loss_rnnt 9.524856 lr 0.00027125 rank 4
2022-12-07 20:57:02,141 DEBUG TRAIN Batch 21/6300 loss 11.567756 loss_att 361.575317 loss_ctc 24.600533 loss_rnnt 10.119669 lr 0.00027125 rank 7
2022-12-07 20:57:02,143 DEBUG TRAIN Batch 21/6300 loss 4.037996 loss_att 407.237305 loss_ctc 9.717388 loss_rnnt 3.406953 lr 0.00027125 rank 6
2022-12-07 20:57:02,144 DEBUG TRAIN Batch 21/6300 loss 8.491463 loss_att 342.404083 loss_ctc 17.723574 loss_rnnt 7.465673 lr 0.00027125 rank 3
2022-12-07 20:57:02,146 DEBUG TRAIN Batch 21/6300 loss 7.677397 loss_att 221.691513 loss_ctc 13.506794 loss_rnnt 7.029686 lr 0.00027125 rank 5
2022-12-07 20:57:02,148 DEBUG TRAIN Batch 21/6300 loss 8.804090 loss_att 377.198303 loss_ctc 21.351383 loss_rnnt 7.409947 lr 0.00027125 rank 0
2022-12-07 20:57:02,186 DEBUG TRAIN Batch 21/6300 loss 7.839666 loss_att 287.959229 loss_ctc 17.561226 loss_rnnt 6.759493 lr 0.00027125 rank 1
2022-12-07 20:58:57,444 DEBUG TRAIN Batch 21/6400 loss 14.031124 loss_att 385.737000 loss_ctc 24.432922 loss_rnnt 12.875369 lr 0.00027121 rank 2
2022-12-07 20:58:57,447 DEBUG TRAIN Batch 21/6400 loss 12.668906 loss_att 258.359375 loss_ctc 20.544977 loss_rnnt 11.793788 lr 0.00027121 rank 0
2022-12-07 20:58:57,454 DEBUG TRAIN Batch 21/6400 loss 3.102439 loss_att 420.712891 loss_ctc 10.506559 loss_rnnt 2.279759 lr 0.00027121 rank 6
2022-12-07 20:58:57,459 DEBUG TRAIN Batch 21/6400 loss 8.852889 loss_att 423.340576 loss_ctc 23.657928 loss_rnnt 7.207885 lr 0.00027121 rank 4
2022-12-07 20:58:57,461 DEBUG TRAIN Batch 21/6400 loss 12.560217 loss_att 393.807953 loss_ctc 22.426275 loss_rnnt 11.463988 lr 0.00027121 rank 1
2022-12-07 20:58:57,469 DEBUG TRAIN Batch 21/6400 loss 12.823383 loss_att 327.940460 loss_ctc 22.389078 loss_rnnt 11.760529 lr 0.00027121 rank 3
2022-12-07 20:58:57,476 DEBUG TRAIN Batch 21/6400 loss 11.430180 loss_att 242.911072 loss_ctc 18.215321 loss_rnnt 10.676275 lr 0.00027121 rank 7
2022-12-07 20:58:57,488 DEBUG TRAIN Batch 21/6400 loss 7.400637 loss_att 393.600189 loss_ctc 15.475211 loss_rnnt 6.503462 lr 0.00027121 rank 5
2022-12-07 21:00:05,123 DEBUG TRAIN Batch 21/6500 loss 8.391305 loss_att 387.965820 loss_ctc 21.654053 loss_rnnt 6.917666 lr 0.00027117 rank 4
2022-12-07 21:00:05,123 DEBUG TRAIN Batch 21/6500 loss 8.972783 loss_att 411.997742 loss_ctc 11.637802 loss_rnnt 8.676670 lr 0.00027117 rank 7
2022-12-07 21:00:05,126 DEBUG TRAIN Batch 21/6500 loss 8.806282 loss_att 202.015030 loss_ctc 16.529381 loss_rnnt 7.948160 lr 0.00027117 rank 3
2022-12-07 21:00:05,127 DEBUG TRAIN Batch 21/6500 loss 17.363461 loss_att 338.689850 loss_ctc 25.125889 loss_rnnt 16.500969 lr 0.00027117 rank 6
2022-12-07 21:00:05,129 DEBUG TRAIN Batch 21/6500 loss 5.399650 loss_att 404.913513 loss_ctc 11.980646 loss_rnnt 4.668428 lr 0.00027117 rank 2
2022-12-07 21:00:05,131 DEBUG TRAIN Batch 21/6500 loss 11.836578 loss_att 397.656433 loss_ctc 20.050179 loss_rnnt 10.923956 lr 0.00027117 rank 0
2022-12-07 21:00:05,132 DEBUG TRAIN Batch 21/6500 loss 5.781716 loss_att 397.578461 loss_ctc 15.025541 loss_rnnt 4.754625 lr 0.00027117 rank 1
2022-12-07 21:00:05,172 DEBUG TRAIN Batch 21/6500 loss 5.156505 loss_att 387.532715 loss_ctc 11.210597 loss_rnnt 4.483828 lr 0.00027117 rank 5
2022-12-07 21:01:08,594 DEBUG TRAIN Batch 21/6600 loss 5.172618 loss_att 373.919067 loss_ctc 12.454821 loss_rnnt 4.363484 lr 0.00027113 rank 4
2022-12-07 21:01:08,596 DEBUG TRAIN Batch 21/6600 loss 3.283591 loss_att 379.343689 loss_ctc 14.056601 loss_rnnt 2.086590 lr 0.00027113 rank 3
2022-12-07 21:01:08,597 DEBUG TRAIN Batch 21/6600 loss 5.191046 loss_att 436.709900 loss_ctc 18.337200 loss_rnnt 3.730363 lr 0.00027113 rank 1
2022-12-07 21:01:08,597 DEBUG TRAIN Batch 21/6600 loss 7.811332 loss_att 370.019989 loss_ctc 12.535728 loss_rnnt 7.286399 lr 0.00027113 rank 2
2022-12-07 21:01:08,599 DEBUG TRAIN Batch 21/6600 loss 2.708607 loss_att 348.044769 loss_ctc 8.401413 loss_rnnt 2.076073 lr 0.00027113 rank 0
2022-12-07 21:01:08,607 DEBUG TRAIN Batch 21/6600 loss 8.707630 loss_att 348.535980 loss_ctc 17.136847 loss_rnnt 7.771051 lr 0.00027113 rank 7
2022-12-07 21:01:08,608 DEBUG TRAIN Batch 21/6600 loss 12.896758 loss_att 437.438293 loss_ctc 29.157286 loss_rnnt 11.090033 lr 0.00027113 rank 6
2022-12-07 21:01:08,608 DEBUG TRAIN Batch 21/6600 loss 2.213624 loss_att 366.122162 loss_ctc 10.529229 loss_rnnt 1.289668 lr 0.00027113 rank 5
2022-12-07 21:02:12,486 DEBUG TRAIN Batch 21/6700 loss 6.324422 loss_att 349.363068 loss_ctc 16.218801 loss_rnnt 5.225047 lr 0.00027109 rank 7
2022-12-07 21:02:12,488 DEBUG TRAIN Batch 21/6700 loss 15.817100 loss_att 378.204773 loss_ctc 32.523705 loss_rnnt 13.960810 lr 0.00027109 rank 1
2022-12-07 21:02:12,500 DEBUG TRAIN Batch 21/6700 loss 5.050671 loss_att 346.782471 loss_ctc 12.438129 loss_rnnt 4.229843 lr 0.00027109 rank 4
2022-12-07 21:02:12,504 DEBUG TRAIN Batch 21/6700 loss 12.135535 loss_att 450.019440 loss_ctc 22.182190 loss_rnnt 11.019240 lr 0.00027109 rank 2
2022-12-07 21:02:12,504 DEBUG TRAIN Batch 21/6700 loss 15.229155 loss_att 465.973969 loss_ctc 32.857845 loss_rnnt 13.270411 lr 0.00027109 rank 0
2022-12-07 21:02:12,504 DEBUG TRAIN Batch 21/6700 loss 11.061451 loss_att 401.783813 loss_ctc 32.552444 loss_rnnt 8.673563 lr 0.00027109 rank 6
2022-12-07 21:02:12,524 DEBUG TRAIN Batch 21/6700 loss 9.553600 loss_att 393.760376 loss_ctc 18.646225 loss_rnnt 8.543309 lr 0.00027109 rank 5
2022-12-07 21:02:12,531 DEBUG TRAIN Batch 21/6700 loss 10.531074 loss_att 407.492371 loss_ctc 19.868660 loss_rnnt 9.493565 lr 0.00027109 rank 3
2022-12-07 21:04:10,066 DEBUG TRAIN Batch 21/6800 loss 10.857779 loss_att 380.384583 loss_ctc 22.214413 loss_rnnt 9.595930 lr 0.00027106 rank 7
2022-12-07 21:04:10,067 DEBUG TRAIN Batch 21/6800 loss 7.615017 loss_att 364.109772 loss_ctc 18.735294 loss_rnnt 6.379431 lr 0.00027106 rank 4
2022-12-07 21:04:10,071 DEBUG TRAIN Batch 21/6800 loss 9.874156 loss_att 348.537598 loss_ctc 20.827520 loss_rnnt 8.657116 lr 0.00027106 rank 5
2022-12-07 21:04:10,072 DEBUG TRAIN Batch 21/6800 loss 5.751605 loss_att 373.033203 loss_ctc 10.397652 loss_rnnt 5.235378 lr 0.00027106 rank 3
2022-12-07 21:04:10,072 DEBUG TRAIN Batch 21/6800 loss 6.599869 loss_att 373.036591 loss_ctc 15.996351 loss_rnnt 5.555816 lr 0.00027106 rank 6
2022-12-07 21:04:10,074 DEBUG TRAIN Batch 21/6800 loss 13.051119 loss_att 356.409485 loss_ctc 23.423775 loss_rnnt 11.898602 lr 0.00027106 rank 1
2022-12-07 21:04:10,079 DEBUG TRAIN Batch 21/6800 loss 11.451972 loss_att 391.275879 loss_ctc 24.613014 loss_rnnt 9.989634 lr 0.00027106 rank 0
2022-12-07 21:04:10,111 DEBUG TRAIN Batch 21/6800 loss 5.695530 loss_att 319.001312 loss_ctc 15.212519 loss_rnnt 4.638086 lr 0.00027106 rank 2
2022-12-07 21:05:13,513 DEBUG TRAIN Batch 21/6900 loss 5.647154 loss_att 339.436157 loss_ctc 14.213715 loss_rnnt 4.695314 lr 0.00027102 rank 4
2022-12-07 21:05:13,516 DEBUG TRAIN Batch 21/6900 loss 7.204924 loss_att 267.079193 loss_ctc 12.141193 loss_rnnt 6.656450 lr 0.00027102 rank 2
2022-12-07 21:05:13,516 DEBUG TRAIN Batch 21/6900 loss 7.099911 loss_att 342.291351 loss_ctc 13.524925 loss_rnnt 6.386021 lr 0.00027102 rank 3
2022-12-07 21:05:13,524 DEBUG TRAIN Batch 21/6900 loss 8.898681 loss_att 310.919250 loss_ctc 18.047169 loss_rnnt 7.882183 lr 0.00027102 rank 1
2022-12-07 21:05:13,524 DEBUG TRAIN Batch 21/6900 loss 3.918408 loss_att 108.963371 loss_ctc 6.945656 loss_rnnt 3.582047 lr 0.00027102 rank 6
2022-12-07 21:05:13,526 DEBUG TRAIN Batch 21/6900 loss 11.759157 loss_att 310.768250 loss_ctc 22.239601 loss_rnnt 10.594664 lr 0.00027102 rank 0
2022-12-07 21:05:13,527 DEBUG TRAIN Batch 21/6900 loss 15.160265 loss_att 381.340027 loss_ctc 25.996939 loss_rnnt 13.956190 lr 0.00027102 rank 7
2022-12-07 21:05:13,571 DEBUG TRAIN Batch 21/6900 loss 9.950985 loss_att 246.877594 loss_ctc 19.459684 loss_rnnt 8.894463 lr 0.00027102 rank 5
2022-12-07 21:06:17,389 DEBUG TRAIN Batch 21/7000 loss 6.804341 loss_att 166.323013 loss_ctc 13.461736 loss_rnnt 6.064631 lr 0.00027098 rank 4
2022-12-07 21:06:17,392 DEBUG TRAIN Batch 21/7000 loss 5.342964 loss_att 423.655396 loss_ctc 14.104689 loss_rnnt 4.369439 lr 0.00027098 rank 2
2022-12-07 21:06:17,392 DEBUG TRAIN Batch 21/7000 loss 6.080956 loss_att 277.106903 loss_ctc 12.995435 loss_rnnt 5.312680 lr 0.00027098 rank 0
2022-12-07 21:06:17,393 DEBUG TRAIN Batch 21/7000 loss 12.531724 loss_att 426.689911 loss_ctc 25.335279 loss_rnnt 11.109106 lr 0.00027098 rank 6
2022-12-07 21:06:17,395 DEBUG TRAIN Batch 21/7000 loss 12.506662 loss_att 205.924133 loss_ctc 17.785196 loss_rnnt 11.920158 lr 0.00027098 rank 7
2022-12-07 21:06:17,396 DEBUG TRAIN Batch 21/7000 loss 8.448342 loss_att 193.922058 loss_ctc 16.966927 loss_rnnt 7.501833 lr 0.00027098 rank 1
2022-12-07 21:06:17,402 DEBUG TRAIN Batch 21/7000 loss 5.174252 loss_att 291.593964 loss_ctc 11.835867 loss_rnnt 4.434072 lr 0.00027098 rank 3
2022-12-07 21:06:17,403 DEBUG TRAIN Batch 21/7000 loss 14.085907 loss_att 377.667175 loss_ctc 24.729399 loss_rnnt 12.903297 lr 0.00027098 rank 5
2022-12-07 21:08:12,103 DEBUG TRAIN Batch 21/7100 loss 13.235762 loss_att 400.861328 loss_ctc 31.454077 loss_rnnt 11.211505 lr 0.00027094 rank 4
2022-12-07 21:08:12,110 DEBUG TRAIN Batch 21/7100 loss 16.083157 loss_att 319.286255 loss_ctc 29.849106 loss_rnnt 14.553608 lr 0.00027094 rank 6
2022-12-07 21:08:12,115 DEBUG TRAIN Batch 21/7100 loss 4.124762 loss_att 122.109077 loss_ctc 9.052666 loss_rnnt 3.577217 lr 0.00027094 rank 3
2022-12-07 21:08:12,117 DEBUG TRAIN Batch 21/7100 loss 12.704703 loss_att 393.493103 loss_ctc 28.374683 loss_rnnt 10.963595 lr 0.00027094 rank 7
2022-12-07 21:08:12,117 DEBUG TRAIN Batch 21/7100 loss 7.515768 loss_att 340.288452 loss_ctc 20.708912 loss_rnnt 6.049864 lr 0.00027094 rank 2
2022-12-07 21:08:12,119 DEBUG TRAIN Batch 21/7100 loss 4.056744 loss_att 364.980103 loss_ctc 11.006546 loss_rnnt 3.284544 lr 0.00027094 rank 1
2022-12-07 21:08:12,127 DEBUG TRAIN Batch 21/7100 loss 7.369722 loss_att 390.329407 loss_ctc 15.036018 loss_rnnt 6.517911 lr 0.00027094 rank 5
2022-12-07 21:08:12,137 DEBUG TRAIN Batch 21/7100 loss 21.974262 loss_att 391.929382 loss_ctc 54.960510 loss_rnnt 18.309124 lr 0.00027094 rank 0
2022-12-07 21:09:15,961 DEBUG TRAIN Batch 21/7200 loss 4.617143 loss_att 333.299866 loss_ctc 9.262920 loss_rnnt 4.100945 lr 0.00027090 rank 4
2022-12-07 21:09:15,970 DEBUG TRAIN Batch 21/7200 loss 11.315107 loss_att 371.220276 loss_ctc 20.838692 loss_rnnt 10.256931 lr 0.00027090 rank 2
2022-12-07 21:09:15,971 DEBUG TRAIN Batch 21/7200 loss 18.262695 loss_att 419.233948 loss_ctc 33.220406 loss_rnnt 16.600727 lr 0.00027090 rank 0
2022-12-07 21:09:15,976 DEBUG TRAIN Batch 21/7200 loss 2.338927 loss_att 376.895844 loss_ctc 9.303925 loss_rnnt 1.565038 lr 0.00027090 rank 7
2022-12-07 21:09:15,976 DEBUG TRAIN Batch 21/7200 loss 4.201022 loss_att 339.159637 loss_ctc 9.919542 loss_rnnt 3.565631 lr 0.00027090 rank 6
2022-12-07 21:09:15,981 DEBUG TRAIN Batch 21/7200 loss 4.077371 loss_att 402.006439 loss_ctc 9.595200 loss_rnnt 3.464279 lr 0.00027090 rank 5
2022-12-07 21:09:15,986 DEBUG TRAIN Batch 21/7200 loss 9.030197 loss_att 400.807220 loss_ctc 24.898861 loss_rnnt 7.267013 lr 0.00027090 rank 1
2022-12-07 21:09:16,021 DEBUG TRAIN Batch 21/7200 loss 4.925360 loss_att 412.023041 loss_ctc 13.931533 loss_rnnt 3.924674 lr 0.00027090 rank 3
2022-12-07 21:10:19,593 DEBUG TRAIN Batch 21/7300 loss 7.525119 loss_att 383.791107 loss_ctc 18.574762 loss_rnnt 6.297381 lr 0.00027086 rank 7
2022-12-07 21:10:19,596 DEBUG TRAIN Batch 21/7300 loss 7.369036 loss_att 384.616882 loss_ctc 20.170662 loss_rnnt 5.946633 lr 0.00027086 rank 0
2022-12-07 21:10:19,598 DEBUG TRAIN Batch 21/7300 loss 6.119851 loss_att 407.243774 loss_ctc 14.326485 loss_rnnt 5.208002 lr 0.00027086 rank 4
2022-12-07 21:10:19,602 DEBUG TRAIN Batch 21/7300 loss 6.356134 loss_att 341.382812 loss_ctc 9.131418 loss_rnnt 6.047770 lr 0.00027086 rank 5
2022-12-07 21:10:19,603 DEBUG TRAIN Batch 21/7300 loss 8.858549 loss_att 395.660034 loss_ctc 15.519110 loss_rnnt 8.118487 lr 0.00027086 rank 2
2022-12-07 21:10:19,604 DEBUG TRAIN Batch 21/7300 loss 4.782740 loss_att 371.445007 loss_ctc 10.057420 loss_rnnt 4.196665 lr 0.00027086 rank 1
2022-12-07 21:10:19,630 DEBUG TRAIN Batch 21/7300 loss 8.067500 loss_att 408.304382 loss_ctc 13.471560 loss_rnnt 7.467050 lr 0.00027086 rank 3
2022-12-07 21:10:19,640 DEBUG TRAIN Batch 21/7300 loss 8.817885 loss_att 424.653809 loss_ctc 20.511086 loss_rnnt 7.518641 lr 0.00027086 rank 6
2022-12-07 21:11:23,179 DEBUG TRAIN Batch 21/7400 loss 7.242831 loss_att 363.856506 loss_ctc 9.954544 loss_rnnt 6.941530 lr 0.00027082 rank 7
2022-12-07 21:11:23,179 DEBUG TRAIN Batch 21/7400 loss 7.689935 loss_att 346.467285 loss_ctc 14.096087 loss_rnnt 6.978141 lr 0.00027082 rank 4
2022-12-07 21:11:23,180 DEBUG TRAIN Batch 21/7400 loss 4.695971 loss_att 380.731262 loss_ctc 10.229713 loss_rnnt 4.081111 lr 0.00027082 rank 3
2022-12-07 21:11:23,182 DEBUG TRAIN Batch 21/7400 loss 11.994448 loss_att 309.600525 loss_ctc 25.651121 loss_rnnt 10.477039 lr 0.00027082 rank 6
2022-12-07 21:11:23,182 DEBUG TRAIN Batch 21/7400 loss 6.806877 loss_att 362.461609 loss_ctc 17.037304 loss_rnnt 5.670163 lr 0.00027082 rank 1
2022-12-07 21:11:23,184 DEBUG TRAIN Batch 21/7400 loss 4.766696 loss_att 368.008240 loss_ctc 9.201893 loss_rnnt 4.273897 lr 0.00027082 rank 5
2022-12-07 21:11:23,186 DEBUG TRAIN Batch 21/7400 loss 6.982595 loss_att 310.248779 loss_ctc 10.576462 loss_rnnt 6.583277 lr 0.00027082 rank 0
2022-12-07 21:11:23,203 DEBUG TRAIN Batch 21/7400 loss 7.815876 loss_att 347.180847 loss_ctc 12.064810 loss_rnnt 7.343773 lr 0.00027082 rank 2
2022-12-07 21:13:18,429 DEBUG TRAIN Batch 21/7500 loss 15.539106 loss_att 380.252838 loss_ctc 25.073175 loss_rnnt 14.479766 lr 0.00027078 rank 7
2022-12-07 21:13:18,431 DEBUG TRAIN Batch 21/7500 loss 14.877109 loss_att 252.855789 loss_ctc 21.744505 loss_rnnt 14.114064 lr 0.00027078 rank 6
2022-12-07 21:13:18,431 DEBUG TRAIN Batch 21/7500 loss 10.348258 loss_att 332.292633 loss_ctc 16.432541 loss_rnnt 9.672227 lr 0.00027078 rank 0
2022-12-07 21:13:18,434 DEBUG TRAIN Batch 21/7500 loss 5.839446 loss_att 370.169464 loss_ctc 12.494055 loss_rnnt 5.100045 lr 0.00027078 rank 3
2022-12-07 21:13:18,436 DEBUG TRAIN Batch 21/7500 loss 11.600880 loss_att 324.399536 loss_ctc 29.620733 loss_rnnt 9.598674 lr 0.00027078 rank 4
2022-12-07 21:13:18,437 DEBUG TRAIN Batch 21/7500 loss 8.587643 loss_att 327.023926 loss_ctc 12.144917 loss_rnnt 8.192390 lr 0.00027078 rank 2
2022-12-07 21:13:18,437 DEBUG TRAIN Batch 21/7500 loss 8.852591 loss_att 252.134232 loss_ctc 15.625908 loss_rnnt 8.099999 lr 0.00027078 rank 5
2022-12-07 21:13:18,476 DEBUG TRAIN Batch 21/7500 loss 2.751110 loss_att 325.897827 loss_ctc 6.379727 loss_rnnt 2.347930 lr 0.00027078 rank 1
2022-12-07 21:14:22,976 DEBUG TRAIN Batch 21/7600 loss 8.662277 loss_att 217.472046 loss_ctc 18.650269 loss_rnnt 7.552501 lr 0.00027074 rank 4
2022-12-07 21:14:22,979 DEBUG TRAIN Batch 21/7600 loss 3.914573 loss_att 237.344971 loss_ctc 7.683487 loss_rnnt 3.495805 lr 0.00027074 rank 7
2022-12-07 21:14:22,980 DEBUG TRAIN Batch 21/7600 loss 9.421739 loss_att 180.830734 loss_ctc 14.790601 loss_rnnt 8.825199 lr 0.00027074 rank 2
2022-12-07 21:14:22,980 DEBUG TRAIN Batch 21/7600 loss 6.249914 loss_att 77.948639 loss_ctc 10.635345 loss_rnnt 5.762644 lr 0.00027074 rank 5
2022-12-07 21:14:22,981 DEBUG TRAIN Batch 21/7600 loss 12.909581 loss_att 415.366669 loss_ctc 28.044682 loss_rnnt 11.227903 lr 0.00027074 rank 6
2022-12-07 21:14:22,982 DEBUG TRAIN Batch 21/7600 loss 5.801389 loss_att 373.347046 loss_ctc 15.588254 loss_rnnt 4.713960 lr 0.00027074 rank 3
2022-12-07 21:14:22,983 DEBUG TRAIN Batch 21/7600 loss 19.253754 loss_att 318.219452 loss_ctc 33.733490 loss_rnnt 17.644896 lr 0.00027074 rank 1
2022-12-07 21:14:22,984 DEBUG TRAIN Batch 21/7600 loss 4.636287 loss_att 391.840973 loss_ctc 11.015278 loss_rnnt 3.927510 lr 0.00027074 rank 0
2022-12-07 21:15:26,532 DEBUG TRAIN Batch 21/7700 loss 5.084124 loss_att 425.003510 loss_ctc 17.194534 loss_rnnt 3.738523 lr 0.00027070 rank 7
2022-12-07 21:15:26,533 DEBUG TRAIN Batch 21/7700 loss 8.530749 loss_att 177.586044 loss_ctc 14.738867 loss_rnnt 7.840959 lr 0.00027070 rank 3
2022-12-07 21:15:26,537 DEBUG TRAIN Batch 21/7700 loss 7.459932 loss_att 162.510529 loss_ctc 10.010335 loss_rnnt 7.176554 lr 0.00027070 rank 0
2022-12-07 21:15:26,537 DEBUG TRAIN Batch 21/7700 loss 14.691037 loss_att 409.834717 loss_ctc 32.446053 loss_rnnt 12.718258 lr 0.00027070 rank 5
2022-12-07 21:15:26,539 DEBUG TRAIN Batch 21/7700 loss 5.586258 loss_att 377.049011 loss_ctc 15.497517 loss_rnnt 4.485007 lr 0.00027070 rank 4
2022-12-07 21:15:26,545 DEBUG TRAIN Batch 21/7700 loss 10.237664 loss_att 472.487976 loss_ctc 18.425381 loss_rnnt 9.327918 lr 0.00027070 rank 1
2022-12-07 21:15:26,553 DEBUG TRAIN Batch 21/7700 loss 10.440290 loss_att 386.849121 loss_ctc 26.539841 loss_rnnt 8.651452 lr 0.00027070 rank 2
2022-12-07 21:15:26,561 DEBUG TRAIN Batch 21/7700 loss 13.748878 loss_att 423.684418 loss_ctc 27.696674 loss_rnnt 12.199122 lr 0.00027070 rank 6
2022-12-07 21:16:31,243 DEBUG TRAIN Batch 21/7800 loss 8.176722 loss_att 357.054504 loss_ctc 18.595236 loss_rnnt 7.019109 lr 0.00027066 rank 7
2022-12-07 21:16:31,248 DEBUG TRAIN Batch 21/7800 loss 8.438795 loss_att 394.633148 loss_ctc 14.337718 loss_rnnt 7.783360 lr 0.00027066 rank 4
2022-12-07 21:16:31,249 DEBUG TRAIN Batch 21/7800 loss 10.962340 loss_att 390.374237 loss_ctc 22.611837 loss_rnnt 9.667952 lr 0.00027066 rank 0
2022-12-07 21:16:31,249 DEBUG TRAIN Batch 21/7800 loss 11.422166 loss_att 425.270935 loss_ctc 34.926956 loss_rnnt 8.810523 lr 0.00027066 rank 2
2022-12-07 21:16:31,251 DEBUG TRAIN Batch 21/7800 loss 5.037296 loss_att 430.181519 loss_ctc 8.403593 loss_rnnt 4.663263 lr 0.00027066 rank 6
2022-12-07 21:16:31,254 DEBUG TRAIN Batch 21/7800 loss 6.340802 loss_att 399.201111 loss_ctc 19.091232 loss_rnnt 4.924087 lr 0.00027066 rank 1
2022-12-07 21:16:31,255 DEBUG TRAIN Batch 21/7800 loss 2.189993 loss_att 395.129822 loss_ctc 4.855211 loss_rnnt 1.893858 lr 0.00027066 rank 5
2022-12-07 21:16:31,290 DEBUG TRAIN Batch 21/7800 loss 11.641073 loss_att 446.770844 loss_ctc 30.917297 loss_rnnt 9.499270 lr 0.00027066 rank 3
2022-12-07 21:18:23,712 DEBUG TRAIN Batch 21/7900 loss 5.049304 loss_att 362.317963 loss_ctc 12.348001 loss_rnnt 4.238337 lr 0.00027062 rank 7
2022-12-07 21:18:23,725 DEBUG TRAIN Batch 21/7900 loss 5.586411 loss_att 387.882751 loss_ctc 13.987400 loss_rnnt 4.652967 lr 0.00027062 rank 4
2022-12-07 21:18:23,727 DEBUG TRAIN Batch 21/7900 loss 5.135960 loss_att 321.488586 loss_ctc 13.762262 loss_rnnt 4.177482 lr 0.00027062 rank 2
2022-12-07 21:18:23,728 DEBUG TRAIN Batch 21/7900 loss 7.845461 loss_att 400.424072 loss_ctc 18.203524 loss_rnnt 6.694565 lr 0.00027062 rank 6
2022-12-07 21:18:23,728 DEBUG TRAIN Batch 21/7900 loss 7.924178 loss_att 416.946960 loss_ctc 13.846106 loss_rnnt 7.266186 lr 0.00027062 rank 3
2022-12-07 21:18:23,729 DEBUG TRAIN Batch 21/7900 loss 6.685214 loss_att 353.825958 loss_ctc 12.045198 loss_rnnt 6.089661 lr 0.00027062 rank 5
2022-12-07 21:18:23,731 DEBUG TRAIN Batch 21/7900 loss 11.425466 loss_att 386.208130 loss_ctc 21.797125 loss_rnnt 10.273060 lr 0.00027062 rank 0
2022-12-07 21:18:23,735 DEBUG TRAIN Batch 21/7900 loss 24.837280 loss_att 413.083801 loss_ctc 41.881298 loss_rnnt 22.943501 lr 0.00027062 rank 1
2022-12-07 21:19:26,957 DEBUG TRAIN Batch 21/8000 loss 18.350740 loss_att 347.700684 loss_ctc 33.285309 loss_rnnt 16.691345 lr 0.00027058 rank 4
2022-12-07 21:19:26,959 DEBUG TRAIN Batch 21/8000 loss 7.674595 loss_att 320.930847 loss_ctc 16.617386 loss_rnnt 6.680951 lr 0.00027058 rank 2
2022-12-07 21:19:26,962 DEBUG TRAIN Batch 21/8000 loss 5.345468 loss_att 335.181824 loss_ctc 8.887950 loss_rnnt 4.951859 lr 0.00027058 rank 7
2022-12-07 21:19:26,962 DEBUG TRAIN Batch 21/8000 loss 12.242225 loss_att 347.021027 loss_ctc 19.785969 loss_rnnt 11.404032 lr 0.00027058 rank 6
2022-12-07 21:19:26,964 DEBUG TRAIN Batch 21/8000 loss 10.752104 loss_att 387.399902 loss_ctc 32.112991 loss_rnnt 8.378672 lr 0.00027058 rank 3
2022-12-07 21:19:26,966 DEBUG TRAIN Batch 21/8000 loss 5.262491 loss_att 363.831726 loss_ctc 11.160999 loss_rnnt 4.607101 lr 0.00027058 rank 5
2022-12-07 21:19:26,966 DEBUG TRAIN Batch 21/8000 loss 11.187725 loss_att 327.260925 loss_ctc 23.966354 loss_rnnt 9.767878 lr 0.00027058 rank 0
2022-12-07 21:19:26,967 DEBUG TRAIN Batch 21/8000 loss 9.754314 loss_att 376.132202 loss_ctc 21.099476 loss_rnnt 8.493741 lr 0.00027058 rank 1
2022-12-07 21:20:30,871 DEBUG TRAIN Batch 21/8100 loss 15.201603 loss_att 356.818237 loss_ctc 26.866829 loss_rnnt 13.905467 lr 0.00027054 rank 7
2022-12-07 21:20:30,874 DEBUG TRAIN Batch 21/8100 loss 6.325309 loss_att 338.104980 loss_ctc 12.554659 loss_rnnt 5.633159 lr 0.00027054 rank 5
2022-12-07 21:20:30,875 DEBUG TRAIN Batch 21/8100 loss 8.499041 loss_att 326.523773 loss_ctc 17.396280 loss_rnnt 7.510458 lr 0.00027054 rank 6
2022-12-07 21:20:30,877 DEBUG TRAIN Batch 21/8100 loss 7.385873 loss_att 380.263641 loss_ctc 23.001122 loss_rnnt 5.650846 lr 0.00027054 rank 0
2022-12-07 21:20:30,879 DEBUG TRAIN Batch 21/8100 loss 9.884768 loss_att 365.080078 loss_ctc 15.917194 loss_rnnt 9.214499 lr 0.00027054 rank 4
2022-12-07 21:20:30,879 DEBUG TRAIN Batch 21/8100 loss 8.653440 loss_att 390.400696 loss_ctc 18.999762 loss_rnnt 7.503848 lr 0.00027054 rank 1
2022-12-07 21:20:30,880 DEBUG TRAIN Batch 21/8100 loss 14.172076 loss_att 295.869446 loss_ctc 24.985247 loss_rnnt 12.970613 lr 0.00027054 rank 2
2022-12-07 21:20:30,919 DEBUG TRAIN Batch 21/8100 loss 5.278059 loss_att 345.871643 loss_ctc 11.205959 loss_rnnt 4.619403 lr 0.00027054 rank 3
2022-12-07 21:21:36,478 DEBUG TRAIN Batch 21/8200 loss 9.360741 loss_att 277.033936 loss_ctc 14.534622 loss_rnnt 8.785865 lr 0.00027050 rank 2
2022-12-07 21:21:36,480 DEBUG TRAIN Batch 21/8200 loss 10.325104 loss_att 193.341705 loss_ctc 19.616104 loss_rnnt 9.292770 lr 0.00027050 rank 5
2022-12-07 21:21:36,480 DEBUG TRAIN Batch 21/8200 loss 8.587669 loss_att 368.663330 loss_ctc 18.080217 loss_rnnt 7.532942 lr 0.00027050 rank 3
2022-12-07 21:21:36,481 DEBUG TRAIN Batch 21/8200 loss 5.192794 loss_att 313.722656 loss_ctc 9.115801 loss_rnnt 4.756905 lr 0.00027050 rank 1
2022-12-07 21:21:36,481 DEBUG TRAIN Batch 21/8200 loss 9.811260 loss_att 291.051453 loss_ctc 17.718098 loss_rnnt 8.932723 lr 0.00027050 rank 7
2022-12-07 21:21:36,482 DEBUG TRAIN Batch 21/8200 loss 3.892135 loss_att 293.022919 loss_ctc 8.793368 loss_rnnt 3.347554 lr 0.00027050 rank 4
2022-12-07 21:21:36,483 DEBUG TRAIN Batch 21/8200 loss 7.603044 loss_att 352.118256 loss_ctc 17.190851 loss_rnnt 6.537732 lr 0.00027050 rank 0
2022-12-07 21:21:36,521 DEBUG TRAIN Batch 21/8200 loss 12.769499 loss_att 322.329895 loss_ctc 26.678547 loss_rnnt 11.224049 lr 0.00027050 rank 6
2022-12-07 21:22:39,562 DEBUG TRAIN Batch 21/8300 loss 4.244380 loss_att 398.032043 loss_ctc 9.441151 loss_rnnt 3.666962 lr 0.00027046 rank 7
2022-12-07 21:22:39,567 DEBUG TRAIN Batch 21/8300 loss 10.387053 loss_att 182.377960 loss_ctc 20.559126 loss_rnnt 9.256822 lr 0.00027046 rank 4
2022-12-07 21:22:39,567 DEBUG TRAIN Batch 21/8300 loss 5.217769 loss_att 364.721405 loss_ctc 13.309774 loss_rnnt 4.318657 lr 0.00027046 rank 5
2022-12-07 21:22:39,570 DEBUG TRAIN Batch 21/8300 loss 10.314822 loss_att 372.278015 loss_ctc 15.520929 loss_rnnt 9.736366 lr 0.00027046 rank 6
2022-12-07 21:22:39,572 DEBUG TRAIN Batch 21/8300 loss 6.762284 loss_att 315.073303 loss_ctc 12.044075 loss_rnnt 6.175418 lr 0.00027046 rank 3
2022-12-07 21:22:39,574 DEBUG TRAIN Batch 21/8300 loss 5.774007 loss_att 329.098907 loss_ctc 14.538467 loss_rnnt 4.800179 lr 0.00027046 rank 1
2022-12-07 21:22:39,575 DEBUG TRAIN Batch 21/8300 loss 9.204451 loss_att 322.699127 loss_ctc 16.081017 loss_rnnt 8.440388 lr 0.00027046 rank 0
2022-12-07 21:22:39,575 DEBUG TRAIN Batch 21/8300 loss 11.946523 loss_att 407.351898 loss_ctc 24.328924 loss_rnnt 10.570700 lr 0.00027046 rank 2
2022-12-07 21:23:24,122 DEBUG CV Batch 21/0 loss 1.607347 loss_att 48.088093 loss_ctc 3.219462 loss_rnnt 1.428224 history loss 1.547816 rank 4
2022-12-07 21:23:24,124 DEBUG CV Batch 21/0 loss 1.607347 loss_att 48.088093 loss_ctc 3.219462 loss_rnnt 1.428224 history loss 1.547816 rank 2
2022-12-07 21:23:24,126 DEBUG CV Batch 21/0 loss 1.607347 loss_att 48.088093 loss_ctc 3.219462 loss_rnnt 1.428224 history loss 1.547816 rank 7
2022-12-07 21:23:24,129 DEBUG CV Batch 21/0 loss 1.607347 loss_att 48.088093 loss_ctc 3.219462 loss_rnnt 1.428224 history loss 1.547816 rank 0
2022-12-07 21:23:24,132 DEBUG CV Batch 21/0 loss 1.607347 loss_att 48.088093 loss_ctc 3.219462 loss_rnnt 1.428224 history loss 1.547816 rank 5
2022-12-07 21:23:24,144 DEBUG CV Batch 21/0 loss 1.607347 loss_att 48.088093 loss_ctc 3.219462 loss_rnnt 1.428224 history loss 1.547816 rank 3
2022-12-07 21:23:24,147 DEBUG CV Batch 21/0 loss 1.607347 loss_att 48.088093 loss_ctc 3.219462 loss_rnnt 1.428224 history loss 1.547816 rank 1
2022-12-07 21:23:24,154 DEBUG CV Batch 21/0 loss 1.607347 loss_att 48.088093 loss_ctc 3.219462 loss_rnnt 1.428224 history loss 1.547816 rank 6
2022-12-07 21:23:37,560 DEBUG CV Batch 21/100 loss 3.717893 loss_att 266.944214 loss_ctc 11.320933 loss_rnnt 2.873111 history loss 2.873803 rank 4
2022-12-07 21:23:37,630 DEBUG CV Batch 21/100 loss 3.717893 loss_att 266.944214 loss_ctc 11.320933 loss_rnnt 2.873111 history loss 2.873803 rank 6
2022-12-07 21:23:37,631 DEBUG CV Batch 21/100 loss 3.717893 loss_att 266.944214 loss_ctc 11.320933 loss_rnnt 2.873111 history loss 2.873803 rank 2
2022-12-07 21:23:37,674 DEBUG CV Batch 21/100 loss 3.717893 loss_att 266.944214 loss_ctc 11.320933 loss_rnnt 2.873111 history loss 2.873803 rank 0
2022-12-07 21:23:37,716 DEBUG CV Batch 21/100 loss 3.717893 loss_att 266.944214 loss_ctc 11.320933 loss_rnnt 2.873111 history loss 2.873803 rank 5
2022-12-07 21:23:37,999 DEBUG CV Batch 21/100 loss 3.717893 loss_att 266.944214 loss_ctc 11.320933 loss_rnnt 2.873111 history loss 2.873803 rank 3
2022-12-07 21:23:38,037 DEBUG CV Batch 21/100 loss 3.717893 loss_att 266.944214 loss_ctc 11.320933 loss_rnnt 2.873111 history loss 2.873803 rank 7
2022-12-07 21:23:38,173 DEBUG CV Batch 21/100 loss 3.717893 loss_att 266.944214 loss_ctc 11.320933 loss_rnnt 2.873111 history loss 2.873803 rank 1
2022-12-07 21:23:53,778 DEBUG CV Batch 21/200 loss 6.699872 loss_att 641.179016 loss_ctc 8.610416 loss_rnnt 6.487590 history loss 3.442905 rank 7
2022-12-07 21:23:53,799 DEBUG CV Batch 21/200 loss 6.699872 loss_att 641.179016 loss_ctc 8.610416 loss_rnnt 6.487590 history loss 3.442905 rank 4
2022-12-07 21:23:53,877 DEBUG CV Batch 21/200 loss 6.699872 loss_att 641.179016 loss_ctc 8.610416 loss_rnnt 6.487590 history loss 3.442905 rank 0
2022-12-07 21:23:53,882 DEBUG CV Batch 21/200 loss 6.699872 loss_att 641.179016 loss_ctc 8.610416 loss_rnnt 6.487590 history loss 3.442905 rank 1
2022-12-07 21:23:53,977 DEBUG CV Batch 21/200 loss 6.699872 loss_att 641.179016 loss_ctc 8.610416 loss_rnnt 6.487590 history loss 3.442905 rank 2
2022-12-07 21:23:53,983 DEBUG CV Batch 21/200 loss 6.699872 loss_att 641.179016 loss_ctc 8.610416 loss_rnnt 6.487590 history loss 3.442905 rank 3
2022-12-07 21:23:53,990 DEBUG CV Batch 21/200 loss 6.699872 loss_att 641.179016 loss_ctc 8.610416 loss_rnnt 6.487590 history loss 3.442905 rank 6
2022-12-07 21:23:54,165 DEBUG CV Batch 21/200 loss 6.699872 loss_att 641.179016 loss_ctc 8.610416 loss_rnnt 6.487590 history loss 3.442905 rank 5
2022-12-07 21:24:08,299 DEBUG CV Batch 21/300 loss 3.486628 loss_att 190.889587 loss_ctc 8.165094 loss_rnnt 2.966798 history loss 3.584755 rank 4
2022-12-07 21:24:08,340 DEBUG CV Batch 21/300 loss 3.486628 loss_att 190.889587 loss_ctc 8.165094 loss_rnnt 2.966798 history loss 3.584755 rank 2
2022-12-07 21:24:08,348 DEBUG CV Batch 21/300 loss 3.486628 loss_att 190.889587 loss_ctc 8.165094 loss_rnnt 2.966798 history loss 3.584755 rank 0
2022-12-07 21:24:08,351 DEBUG CV Batch 21/300 loss 3.486628 loss_att 190.889587 loss_ctc 8.165094 loss_rnnt 2.966798 history loss 3.584755 rank 7
2022-12-07 21:24:08,377 DEBUG CV Batch 21/300 loss 3.486628 loss_att 190.889587 loss_ctc 8.165094 loss_rnnt 2.966798 history loss 3.584755 rank 3
2022-12-07 21:24:08,389 DEBUG CV Batch 21/300 loss 3.486628 loss_att 190.889587 loss_ctc 8.165094 loss_rnnt 2.966798 history loss 3.584755 rank 6
2022-12-07 21:24:08,392 DEBUG CV Batch 21/300 loss 3.486628 loss_att 190.889587 loss_ctc 8.165094 loss_rnnt 2.966798 history loss 3.584755 rank 1
2022-12-07 21:24:08,393 DEBUG CV Batch 21/300 loss 3.486628 loss_att 190.889587 loss_ctc 8.165094 loss_rnnt 2.966798 history loss 3.584755 rank 5
2022-12-07 21:24:26,280 DEBUG CV Batch 21/400 loss 3.901631 loss_att 826.193787 loss_ctc 8.347112 loss_rnnt 3.407689 history loss 4.420076 rank 4
2022-12-07 21:24:26,284 DEBUG CV Batch 21/400 loss 3.901631 loss_att 826.193787 loss_ctc 8.347112 loss_rnnt 3.407689 history loss 4.420076 rank 7
2022-12-07 21:24:26,290 DEBUG CV Batch 21/400 loss 3.901631 loss_att 826.193787 loss_ctc 8.347112 loss_rnnt 3.407689 history loss 4.420076 rank 2
2022-12-07 21:24:26,291 DEBUG CV Batch 21/400 loss 3.901631 loss_att 826.193787 loss_ctc 8.347112 loss_rnnt 3.407689 history loss 4.420076 rank 0
2022-12-07 21:24:26,293 DEBUG CV Batch 21/400 loss 3.901631 loss_att 826.193787 loss_ctc 8.347112 loss_rnnt 3.407689 history loss 4.420076 rank 1
2022-12-07 21:24:26,297 DEBUG CV Batch 21/400 loss 3.901631 loss_att 826.193787 loss_ctc 8.347112 loss_rnnt 3.407689 history loss 4.420076 rank 5
2022-12-07 21:24:26,304 DEBUG CV Batch 21/400 loss 3.901631 loss_att 826.193787 loss_ctc 8.347112 loss_rnnt 3.407689 history loss 4.420076 rank 6
2022-12-07 21:24:26,310 DEBUG CV Batch 21/400 loss 3.901631 loss_att 826.193787 loss_ctc 8.347112 loss_rnnt 3.407689 history loss 4.420076 rank 3
2022-12-07 21:24:39,662 DEBUG CV Batch 21/500 loss 4.370433 loss_att 266.658447 loss_ctc 7.674605 loss_rnnt 4.003303 history loss 5.037478 rank 7
2022-12-07 21:24:39,670 DEBUG CV Batch 21/500 loss 4.370433 loss_att 266.658447 loss_ctc 7.674605 loss_rnnt 4.003303 history loss 5.037478 rank 0
2022-12-07 21:24:39,709 DEBUG CV Batch 21/500 loss 4.370433 loss_att 266.658447 loss_ctc 7.674605 loss_rnnt 4.003303 history loss 5.037478 rank 3
2022-12-07 21:24:39,715 DEBUG CV Batch 21/500 loss 4.370433 loss_att 266.658447 loss_ctc 7.674605 loss_rnnt 4.003303 history loss 5.037478 rank 4
2022-12-07 21:24:39,747 DEBUG CV Batch 21/500 loss 4.370433 loss_att 266.658447 loss_ctc 7.674605 loss_rnnt 4.003303 history loss 5.037478 rank 2
2022-12-07 21:24:39,761 DEBUG CV Batch 21/500 loss 4.370433 loss_att 266.658447 loss_ctc 7.674605 loss_rnnt 4.003303 history loss 5.037478 rank 5
2022-12-07 21:24:39,777 DEBUG CV Batch 21/500 loss 4.370433 loss_att 266.658447 loss_ctc 7.674605 loss_rnnt 4.003303 history loss 5.037478 rank 1
2022-12-07 21:24:39,806 DEBUG CV Batch 21/500 loss 4.370433 loss_att 266.658447 loss_ctc 7.674605 loss_rnnt 4.003303 history loss 5.037478 rank 6
2022-12-07 21:24:56,907 DEBUG CV Batch 21/600 loss 5.430327 loss_att 104.307205 loss_ctc 9.242605 loss_rnnt 5.006741 history loss 5.879637 rank 4
2022-12-07 21:24:56,929 DEBUG CV Batch 21/600 loss 5.430327 loss_att 104.307205 loss_ctc 9.242605 loss_rnnt 5.006741 history loss 5.879637 rank 0
2022-12-07 21:24:56,934 DEBUG CV Batch 21/600 loss 5.430327 loss_att 104.307205 loss_ctc 9.242605 loss_rnnt 5.006741 history loss 5.879637 rank 6
2022-12-07 21:24:56,941 DEBUG CV Batch 21/600 loss 5.430327 loss_att 104.307205 loss_ctc 9.242605 loss_rnnt 5.006741 history loss 5.879637 rank 7
2022-12-07 21:24:56,941 DEBUG CV Batch 21/600 loss 5.430327 loss_att 104.307205 loss_ctc 9.242605 loss_rnnt 5.006741 history loss 5.879637 rank 1
2022-12-07 21:24:56,955 DEBUG CV Batch 21/600 loss 5.430327 loss_att 104.307205 loss_ctc 9.242605 loss_rnnt 5.006741 history loss 5.879637 rank 3
2022-12-07 21:24:56,967 DEBUG CV Batch 21/600 loss 5.430327 loss_att 104.307205 loss_ctc 9.242605 loss_rnnt 5.006741 history loss 5.879637 rank 5
2022-12-07 21:24:56,990 DEBUG CV Batch 21/600 loss 5.430327 loss_att 104.307205 loss_ctc 9.242605 loss_rnnt 5.006741 history loss 5.879637 rank 2
2022-12-07 21:25:12,178 DEBUG CV Batch 21/700 loss 4.235197 loss_att 707.039429 loss_ctc 14.243545 loss_rnnt 3.123158 history loss 6.407857 rank 4
2022-12-07 21:25:12,182 DEBUG CV Batch 21/700 loss 4.235197 loss_att 707.039429 loss_ctc 14.243545 loss_rnnt 3.123158 history loss 6.407857 rank 6
2022-12-07 21:25:12,198 DEBUG CV Batch 21/700 loss 4.235197 loss_att 707.039429 loss_ctc 14.243545 loss_rnnt 3.123158 history loss 6.407857 rank 1
2022-12-07 21:25:12,222 DEBUG CV Batch 21/700 loss 4.235197 loss_att 707.039429 loss_ctc 14.243545 loss_rnnt 3.123158 history loss 6.407857 rank 7
2022-12-07 21:25:12,225 DEBUG CV Batch 21/700 loss 4.235197 loss_att 707.039429 loss_ctc 14.243545 loss_rnnt 3.123158 history loss 6.407857 rank 2
2022-12-07 21:25:12,243 DEBUG CV Batch 21/700 loss 4.235197 loss_att 707.039429 loss_ctc 14.243545 loss_rnnt 3.123158 history loss 6.407857 rank 0
2022-12-07 21:25:12,306 DEBUG CV Batch 21/700 loss 4.235197 loss_att 707.039429 loss_ctc 14.243545 loss_rnnt 3.123158 history loss 6.407857 rank 3
2022-12-07 21:25:12,359 DEBUG CV Batch 21/700 loss 4.235197 loss_att 707.039429 loss_ctc 14.243545 loss_rnnt 3.123158 history loss 6.407857 rank 5
2022-12-07 21:25:23,737 DEBUG CV Batch 21/800 loss 6.817291 loss_att 263.403381 loss_ctc 17.466835 loss_rnnt 5.634008 history loss 5.935445 rank 4
2022-12-07 21:25:23,790 DEBUG CV Batch 21/800 loss 6.817291 loss_att 263.403381 loss_ctc 17.466835 loss_rnnt 5.634008 history loss 5.935445 rank 7
2022-12-07 21:25:23,885 DEBUG CV Batch 21/800 loss 6.817291 loss_att 263.403381 loss_ctc 17.466835 loss_rnnt 5.634008 history loss 5.935445 rank 0
2022-12-07 21:25:24,053 DEBUG CV Batch 21/800 loss 6.817291 loss_att 263.403381 loss_ctc 17.466835 loss_rnnt 5.634008 history loss 5.935445 rank 5
2022-12-07 21:25:24,498 DEBUG CV Batch 21/800 loss 6.817291 loss_att 263.403381 loss_ctc 17.466835 loss_rnnt 5.634008 history loss 5.935445 rank 3
2022-12-07 21:25:24,550 DEBUG CV Batch 21/800 loss 6.817291 loss_att 263.403381 loss_ctc 17.466835 loss_rnnt 5.634008 history loss 5.935445 rank 2
2022-12-07 21:25:24,556 DEBUG CV Batch 21/800 loss 6.817291 loss_att 263.403381 loss_ctc 17.466835 loss_rnnt 5.634008 history loss 5.935445 rank 1
2022-12-07 21:25:24,789 DEBUG CV Batch 21/800 loss 6.817291 loss_att 263.403381 loss_ctc 17.466835 loss_rnnt 5.634008 history loss 5.935445 rank 6
2022-12-07 21:25:36,923 DEBUG CV Batch 21/900 loss 11.193037 loss_att 550.849243 loss_ctc 19.889845 loss_rnnt 10.226726 history loss 5.770049 rank 4
2022-12-07 21:25:36,980 DEBUG CV Batch 21/900 loss 11.193037 loss_att 550.849243 loss_ctc 19.889845 loss_rnnt 10.226726 history loss 5.770049 rank 7
2022-12-07 21:25:37,100 DEBUG CV Batch 21/900 loss 11.193037 loss_att 550.849243 loss_ctc 19.889845 loss_rnnt 10.226726 history loss 5.770049 rank 0
2022-12-07 21:25:37,486 DEBUG CV Batch 21/900 loss 11.193037 loss_att 550.849243 loss_ctc 19.889845 loss_rnnt 10.226726 history loss 5.770049 rank 5
2022-12-07 21:25:38,158 DEBUG CV Batch 21/900 loss 11.193037 loss_att 550.849243 loss_ctc 19.889845 loss_rnnt 10.226726 history loss 5.770049 rank 3
2022-12-07 21:25:38,169 DEBUG CV Batch 21/900 loss 11.193037 loss_att 550.849243 loss_ctc 19.889845 loss_rnnt 10.226726 history loss 5.770049 rank 1
2022-12-07 21:25:38,459 DEBUG CV Batch 21/900 loss 11.193037 loss_att 550.849243 loss_ctc 19.889845 loss_rnnt 10.226726 history loss 5.770049 rank 2
2022-12-07 21:25:38,623 DEBUG CV Batch 21/900 loss 11.193037 loss_att 550.849243 loss_ctc 19.889845 loss_rnnt 10.226726 history loss 5.770049 rank 6
2022-12-07 21:25:48,409 DEBUG CV Batch 21/1000 loss 2.580183 loss_att 176.484283 loss_ctc 5.004182 loss_rnnt 2.310850 history loss 5.575482 rank 4
2022-12-07 21:25:48,534 DEBUG CV Batch 21/1000 loss 2.580183 loss_att 176.484283 loss_ctc 5.004182 loss_rnnt 2.310850 history loss 5.575482 rank 7
2022-12-07 21:25:48,889 DEBUG CV Batch 21/1000 loss 2.580183 loss_att 176.484283 loss_ctc 5.004182 loss_rnnt 2.310850 history loss 5.575482 rank 0
2022-12-07 21:25:49,523 DEBUG CV Batch 21/1000 loss 2.580183 loss_att 176.484283 loss_ctc 5.004182 loss_rnnt 2.310850 history loss 5.575482 rank 5
2022-12-07 21:25:49,789 DEBUG CV Batch 21/1000 loss 2.580183 loss_att 176.484283 loss_ctc 5.004182 loss_rnnt 2.310850 history loss 5.575482 rank 3
2022-12-07 21:25:49,817 DEBUG CV Batch 21/1000 loss 2.580183 loss_att 176.484283 loss_ctc 5.004182 loss_rnnt 2.310850 history loss 5.575482 rank 1
2022-12-07 21:25:50,343 DEBUG CV Batch 21/1000 loss 2.580183 loss_att 176.484283 loss_ctc 5.004182 loss_rnnt 2.310850 history loss 5.575482 rank 6
2022-12-07 21:25:50,392 DEBUG CV Batch 21/1000 loss 2.580183 loss_att 176.484283 loss_ctc 5.004182 loss_rnnt 2.310850 history loss 5.575482 rank 2
2022-12-07 21:25:59,493 DEBUG CV Batch 21/1100 loss 4.883859 loss_att 60.695236 loss_ctc 8.014876 loss_rnnt 4.535969 history loss 5.557949 rank 4
2022-12-07 21:25:59,808 DEBUG CV Batch 21/1100 loss 4.883859 loss_att 60.695236 loss_ctc 8.014876 loss_rnnt 4.535969 history loss 5.557949 rank 7
2022-12-07 21:26:00,242 DEBUG CV Batch 21/1100 loss 4.883859 loss_att 60.695236 loss_ctc 8.014876 loss_rnnt 4.535969 history loss 5.557949 rank 0
2022-12-07 21:26:00,903 DEBUG CV Batch 21/1100 loss 4.883859 loss_att 60.695236 loss_ctc 8.014876 loss_rnnt 4.535969 history loss 5.557949 rank 5
2022-12-07 21:26:01,178 DEBUG CV Batch 21/1100 loss 4.883859 loss_att 60.695236 loss_ctc 8.014876 loss_rnnt 4.535969 history loss 5.557949 rank 1
2022-12-07 21:26:01,247 DEBUG CV Batch 21/1100 loss 4.883859 loss_att 60.695236 loss_ctc 8.014876 loss_rnnt 4.535969 history loss 5.557949 rank 3
2022-12-07 21:26:01,637 DEBUG CV Batch 21/1100 loss 4.883859 loss_att 60.695236 loss_ctc 8.014876 loss_rnnt 4.535969 history loss 5.557949 rank 6
2022-12-07 21:26:01,862 DEBUG CV Batch 21/1100 loss 4.883859 loss_att 60.695236 loss_ctc 8.014876 loss_rnnt 4.535969 history loss 5.557949 rank 2
2022-12-07 21:26:09,306 DEBUG CV Batch 21/1200 loss 7.885962 loss_att 280.457733 loss_ctc 11.533980 loss_rnnt 7.480626 history loss 5.831251 rank 4
2022-12-07 21:26:09,656 DEBUG CV Batch 21/1200 loss 7.885962 loss_att 280.457733 loss_ctc 11.533980 loss_rnnt 7.480626 history loss 5.831251 rank 7
2022-12-07 21:26:10,238 DEBUG CV Batch 21/1200 loss 7.885962 loss_att 280.457733 loss_ctc 11.533980 loss_rnnt 7.480626 history loss 5.831251 rank 0
2022-12-07 21:26:10,819 DEBUG CV Batch 21/1200 loss 7.885962 loss_att 280.457733 loss_ctc 11.533980 loss_rnnt 7.480626 history loss 5.831251 rank 5
2022-12-07 21:26:11,663 DEBUG CV Batch 21/1200 loss 7.885962 loss_att 280.457733 loss_ctc 11.533980 loss_rnnt 7.480626 history loss 5.831251 rank 3
2022-12-07 21:26:12,159 DEBUG CV Batch 21/1200 loss 7.885962 loss_att 280.457733 loss_ctc 11.533980 loss_rnnt 7.480626 history loss 5.831251 rank 2
2022-12-07 21:26:12,183 DEBUG CV Batch 21/1200 loss 7.885962 loss_att 280.457733 loss_ctc 11.533980 loss_rnnt 7.480626 history loss 5.831251 rank 1
2022-12-07 21:26:12,470 DEBUG CV Batch 21/1200 loss 7.885962 loss_att 280.457733 loss_ctc 11.533980 loss_rnnt 7.480626 history loss 5.831251 rank 6
2022-12-07 21:26:20,539 DEBUG CV Batch 21/1300 loss 5.106210 loss_att 105.976181 loss_ctc 8.957762 loss_rnnt 4.678259 history loss 6.119024 rank 4
2022-12-07 21:26:21,071 DEBUG CV Batch 21/1300 loss 5.106210 loss_att 105.976181 loss_ctc 8.957762 loss_rnnt 4.678259 history loss 6.119024 rank 7
2022-12-07 21:26:21,690 DEBUG CV Batch 21/1300 loss 5.106210 loss_att 105.976181 loss_ctc 8.957762 loss_rnnt 4.678259 history loss 6.119024 rank 0
2022-12-07 21:26:22,424 DEBUG CV Batch 21/1300 loss 5.106210 loss_att 105.976181 loss_ctc 8.957762 loss_rnnt 4.678259 history loss 6.119024 rank 5
2022-12-07 21:26:23,621 DEBUG CV Batch 21/1300 loss 5.106210 loss_att 105.976181 loss_ctc 8.957762 loss_rnnt 4.678259 history loss 6.119024 rank 3
2022-12-07 21:26:24,306 DEBUG CV Batch 21/1300 loss 5.106210 loss_att 105.976181 loss_ctc 8.957762 loss_rnnt 4.678259 history loss 6.119024 rank 1
2022-12-07 21:26:24,375 DEBUG CV Batch 21/1300 loss 5.106210 loss_att 105.976181 loss_ctc 8.957762 loss_rnnt 4.678259 history loss 6.119024 rank 2
2022-12-07 21:26:24,417 DEBUG CV Batch 21/1300 loss 5.106210 loss_att 105.976181 loss_ctc 8.957762 loss_rnnt 4.678259 history loss 6.119024 rank 6
2022-12-07 21:26:31,645 DEBUG CV Batch 21/1400 loss 2.754820 loss_att 562.086182 loss_ctc 5.149650 loss_rnnt 2.488728 history loss 6.377367 rank 7
2022-12-07 21:26:31,769 DEBUG CV Batch 21/1400 loss 2.754820 loss_att 562.086182 loss_ctc 5.149650 loss_rnnt 2.488728 history loss 6.377367 rank 4
2022-12-07 21:26:32,390 DEBUG CV Batch 21/1400 loss 2.754820 loss_att 562.086182 loss_ctc 5.149650 loss_rnnt 2.488728 history loss 6.377367 rank 0
2022-12-07 21:26:33,338 DEBUG CV Batch 21/1400 loss 2.754820 loss_att 562.086182 loss_ctc 5.149650 loss_rnnt 2.488728 history loss 6.377367 rank 5
2022-12-07 21:26:36,251 DEBUG CV Batch 21/1400 loss 2.754820 loss_att 562.086182 loss_ctc 5.149650 loss_rnnt 2.488728 history loss 6.377367 rank 3
2022-12-07 21:26:36,534 DEBUG CV Batch 21/1400 loss 2.754820 loss_att 562.086182 loss_ctc 5.149650 loss_rnnt 2.488728 history loss 6.377367 rank 2
2022-12-07 21:26:36,610 DEBUG CV Batch 21/1400 loss 2.754820 loss_att 562.086182 loss_ctc 5.149650 loss_rnnt 2.488728 history loss 6.377367 rank 6
2022-12-07 21:26:36,926 DEBUG CV Batch 21/1400 loss 2.754820 loss_att 562.086182 loss_ctc 5.149650 loss_rnnt 2.488728 history loss 6.377367 rank 1
2022-12-07 21:26:43,275 DEBUG CV Batch 21/1500 loss 8.237067 loss_att 275.486603 loss_ctc 9.144100 loss_rnnt 8.136286 history loss 6.249358 rank 7
2022-12-07 21:26:43,440 DEBUG CV Batch 21/1500 loss 8.237067 loss_att 275.486603 loss_ctc 9.144100 loss_rnnt 8.136286 history loss 6.249358 rank 0
2022-12-07 21:26:43,466 DEBUG CV Batch 21/1500 loss 8.237067 loss_att 275.486603 loss_ctc 9.144100 loss_rnnt 8.136286 history loss 6.249358 rank 4
2022-12-07 21:26:44,709 DEBUG CV Batch 21/1500 loss 8.237067 loss_att 275.486603 loss_ctc 9.144100 loss_rnnt 8.136286 history loss 6.249358 rank 5
2022-12-07 21:26:48,724 DEBUG CV Batch 21/1500 loss 8.237067 loss_att 275.486603 loss_ctc 9.144100 loss_rnnt 8.136286 history loss 6.249358 rank 3
2022-12-07 21:26:49,099 DEBUG CV Batch 21/1500 loss 8.237067 loss_att 275.486603 loss_ctc 9.144100 loss_rnnt 8.136286 history loss 6.249358 rank 6
2022-12-07 21:26:49,396 DEBUG CV Batch 21/1500 loss 8.237067 loss_att 275.486603 loss_ctc 9.144100 loss_rnnt 8.136286 history loss 6.249358 rank 2
2022-12-07 21:26:49,554 DEBUG CV Batch 21/1500 loss 8.237067 loss_att 275.486603 loss_ctc 9.144100 loss_rnnt 8.136286 history loss 6.249358 rank 1
2022-12-07 21:26:56,180 DEBUG CV Batch 21/1600 loss 5.134741 loss_att 593.911682 loss_ctc 11.476306 loss_rnnt 4.430123 history loss 6.206138 rank 7
2022-12-07 21:26:56,381 DEBUG CV Batch 21/1600 loss 5.134741 loss_att 593.911682 loss_ctc 11.476306 loss_rnnt 4.430123 history loss 6.206138 rank 4
2022-12-07 21:26:56,678 DEBUG CV Batch 21/1600 loss 5.134741 loss_att 593.911682 loss_ctc 11.476306 loss_rnnt 4.430123 history loss 6.206138 rank 0
2022-12-07 21:26:57,667 DEBUG CV Batch 21/1600 loss 5.134741 loss_att 593.911682 loss_ctc 11.476306 loss_rnnt 4.430123 history loss 6.206138 rank 5
2022-12-07 21:27:02,225 DEBUG CV Batch 21/1600 loss 5.134741 loss_att 593.911682 loss_ctc 11.476306 loss_rnnt 4.430123 history loss 6.206138 rank 3
2022-12-07 21:27:02,668 DEBUG CV Batch 21/1600 loss 5.134741 loss_att 593.911682 loss_ctc 11.476306 loss_rnnt 4.430123 history loss 6.206138 rank 6
2022-12-07 21:27:02,787 DEBUG CV Batch 21/1600 loss 5.134741 loss_att 593.911682 loss_ctc 11.476306 loss_rnnt 4.430123 history loss 6.206138 rank 1
2022-12-07 21:27:03,107 DEBUG CV Batch 21/1600 loss 5.134741 loss_att 593.911682 loss_ctc 11.476306 loss_rnnt 4.430123 history loss 6.206138 rank 2
2022-12-07 21:27:08,108 DEBUG CV Batch 21/1700 loss 5.944520 loss_att 210.845306 loss_ctc 13.675451 loss_rnnt 5.085528 history loss 6.139556 rank 7
2022-12-07 21:27:08,139 DEBUG CV Batch 21/1700 loss 5.944520 loss_att 210.845306 loss_ctc 13.675451 loss_rnnt 5.085528 history loss 6.139556 rank 4
2022-12-07 21:27:08,816 DEBUG CV Batch 21/1700 loss 5.944520 loss_att 210.845306 loss_ctc 13.675451 loss_rnnt 5.085528 history loss 6.139556 rank 0
2022-12-07 21:27:10,407 DEBUG CV Batch 21/1700 loss 5.944520 loss_att 210.845306 loss_ctc 13.675451 loss_rnnt 5.085528 history loss 6.139556 rank 5
2022-12-07 21:27:14,303 DEBUG CV Batch 21/1700 loss 5.944520 loss_att 210.845306 loss_ctc 13.675451 loss_rnnt 5.085528 history loss 6.139556 rank 3
2022-12-07 21:27:14,655 DEBUG CV Batch 21/1700 loss 5.944520 loss_att 210.845306 loss_ctc 13.675451 loss_rnnt 5.085528 history loss 6.139556 rank 1
2022-12-07 21:27:14,688 DEBUG CV Batch 21/1700 loss 5.944520 loss_att 210.845306 loss_ctc 13.675451 loss_rnnt 5.085528 history loss 6.139556 rank 6
2022-12-07 21:27:15,055 DEBUG CV Batch 21/1700 loss 5.944520 loss_att 210.845306 loss_ctc 13.675451 loss_rnnt 5.085528 history loss 6.139556 rank 2
2022-12-07 21:27:16,784 INFO Epoch 21 CV info cv_loss 6.118341461232131
2022-12-07 21:27:16,784 INFO Epoch 22 TRAIN info lr 0.0002704457514727885
2022-12-07 21:27:16,786 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-07 21:27:16,921 INFO Epoch 21 CV info cv_loss 6.118341461232131
2022-12-07 21:27:16,922 INFO Epoch 22 TRAIN info lr 0.00027044377342980207
2022-12-07 21:27:16,926 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-07 21:27:17,772 INFO Epoch 21 CV info cv_loss 6.118341461232131
2022-12-07 21:27:17,772 INFO Checkpoint: save to checkpoint exp/1204_encoder_bias_nobi_noatt/21.pt
2022-12-07 21:27:18,542 INFO Epoch 22 TRAIN info lr 0.0002704489164318462
2022-12-07 21:27:18,546 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-07 21:27:19,441 INFO Epoch 21 CV info cv_loss 6.118341461232131
2022-12-07 21:27:19,442 INFO Epoch 22 TRAIN info lr 0.00027044060865129846
2022-12-07 21:27:19,444 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-07 21:27:23,186 INFO Epoch 21 CV info cv_loss 6.118341461232131
2022-12-07 21:27:23,187 INFO Epoch 22 TRAIN info lr 0.0002704508945876844
2022-12-07 21:27:23,191 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-07 21:27:23,298 INFO Epoch 21 CV info cv_loss 6.118341461232131
2022-12-07 21:27:23,299 INFO Epoch 22 TRAIN info lr 0.0002704489164318462
2022-12-07 21:27:23,300 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-07 21:27:23,468 INFO Epoch 21 CV info cv_loss 6.118341461232131
2022-12-07 21:27:23,468 INFO Epoch 22 TRAIN info lr 0.0002704374439838966
2022-12-07 21:27:23,473 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-07 21:27:23,978 INFO Epoch 21 CV info cv_loss 6.118341461232131
2022-12-07 21:27:23,979 INFO Epoch 22 TRAIN info lr 0.00027044258662484307
2022-12-07 21:27:23,980 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-07 21:28:28,693 DEBUG TRAIN Batch 22/0 loss 6.148842 loss_att 78.525261 loss_ctc 11.218019 loss_rnnt 5.585601 lr 0.00027044 rank 7
2022-12-07 21:28:28,694 DEBUG TRAIN Batch 22/0 loss 7.601673 loss_att 72.645859 loss_ctc 12.107051 loss_rnnt 7.101076 lr 0.00027044 rank 2
2022-12-07 21:28:28,696 DEBUG TRAIN Batch 22/0 loss 6.163444 loss_att 64.505692 loss_ctc 10.621595 loss_rnnt 5.668094 lr 0.00027045 rank 4
2022-12-07 21:28:28,700 DEBUG TRAIN Batch 22/0 loss 7.909955 loss_att 71.426109 loss_ctc 11.729611 loss_rnnt 7.485548 lr 0.00027045 rank 0
2022-12-07 21:28:28,700 DEBUG TRAIN Batch 22/0 loss 5.828521 loss_att 65.839050 loss_ctc 6.733503 loss_rnnt 5.727968 lr 0.00027045 rank 3
2022-12-07 21:28:28,724 DEBUG TRAIN Batch 22/0 loss 8.020269 loss_att 82.624481 loss_ctc 13.188439 loss_rnnt 7.446029 lr 0.00027044 rank 6
2022-12-07 21:28:28,727 DEBUG TRAIN Batch 22/0 loss 7.985027 loss_att 72.287369 loss_ctc 12.298160 loss_rnnt 7.505791 lr 0.00027045 rank 1
2022-12-07 21:28:28,750 DEBUG TRAIN Batch 22/0 loss 9.290615 loss_att 65.485413 loss_ctc 13.866022 loss_rnnt 8.782237 lr 0.00027044 rank 5
2022-12-07 21:29:31,198 DEBUG TRAIN Batch 22/100 loss 7.095232 loss_att 432.816589 loss_ctc 15.993061 loss_rnnt 6.106585 lr 0.00027041 rank 0
2022-12-07 21:29:31,205 DEBUG TRAIN Batch 22/100 loss 6.512853 loss_att 287.628906 loss_ctc 9.161669 loss_rnnt 6.218540 lr 0.00027040 rank 2
2022-12-07 21:29:31,209 DEBUG TRAIN Batch 22/100 loss 3.810262 loss_att 340.642700 loss_ctc 11.511589 loss_rnnt 2.954559 lr 0.00027040 rank 5
2022-12-07 21:29:31,210 DEBUG TRAIN Batch 22/100 loss 7.382634 loss_att 373.111420 loss_ctc 12.843010 loss_rnnt 6.775926 lr 0.00027041 rank 4
2022-12-07 21:29:31,210 DEBUG TRAIN Batch 22/100 loss 5.235538 loss_att 381.016937 loss_ctc 11.096069 loss_rnnt 4.584367 lr 0.00027041 rank 1
2022-12-07 21:29:31,212 DEBUG TRAIN Batch 22/100 loss 1.494982 loss_att 432.117126 loss_ctc 3.783343 loss_rnnt 1.240720 lr 0.00027040 rank 7
2022-12-07 21:29:31,280 DEBUG TRAIN Batch 22/100 loss 6.496178 loss_att 397.507660 loss_ctc 14.347101 loss_rnnt 5.623854 lr 0.00027041 rank 3
2022-12-07 21:29:31,288 DEBUG TRAIN Batch 22/100 loss 7.243189 loss_att 422.461273 loss_ctc 18.495636 loss_rnnt 5.992918 lr 0.00027040 rank 6
2022-12-07 21:30:33,779 DEBUG TRAIN Batch 22/200 loss 4.607209 loss_att 372.854187 loss_ctc 8.158651 loss_rnnt 4.212605 lr 0.00027037 rank 1
2022-12-07 21:30:33,779 DEBUG TRAIN Batch 22/200 loss 2.657257 loss_att 344.059204 loss_ctc 4.976227 loss_rnnt 2.399594 lr 0.00027037 rank 4
2022-12-07 21:30:33,782 DEBUG TRAIN Batch 22/200 loss 9.245652 loss_att 292.794861 loss_ctc 17.975954 loss_rnnt 8.275620 lr 0.00027036 rank 6
2022-12-07 21:30:33,781 DEBUG TRAIN Batch 22/200 loss 1.482308 loss_att 395.791748 loss_ctc 5.746089 loss_rnnt 1.008554 lr 0.00027036 rank 5
2022-12-07 21:30:33,782 DEBUG TRAIN Batch 22/200 loss 4.285890 loss_att 352.287109 loss_ctc 8.493209 loss_rnnt 3.818410 lr 0.00027037 rank 3
2022-12-07 21:30:33,782 DEBUG TRAIN Batch 22/200 loss 4.591671 loss_att 385.555420 loss_ctc 10.300774 loss_rnnt 3.957326 lr 0.00027036 rank 7
2022-12-07 21:30:33,783 DEBUG TRAIN Batch 22/200 loss 2.330492 loss_att 363.511963 loss_ctc 6.456724 loss_rnnt 1.872022 lr 0.00027037 rank 0
2022-12-07 21:30:33,825 DEBUG TRAIN Batch 22/200 loss 5.251383 loss_att 409.276550 loss_ctc 10.549650 loss_rnnt 4.662686 lr 0.00027036 rank 2
2022-12-07 21:31:37,670 DEBUG TRAIN Batch 22/300 loss 8.655808 loss_att 401.017120 loss_ctc 19.977203 loss_rnnt 7.397876 lr 0.00027033 rank 1
2022-12-07 21:31:37,679 DEBUG TRAIN Batch 22/300 loss 3.382424 loss_att 366.323914 loss_ctc 7.017821 loss_rnnt 2.978491 lr 0.00027033 rank 4
2022-12-07 21:31:37,680 DEBUG TRAIN Batch 22/300 loss 5.795814 loss_att 383.055908 loss_ctc 13.733628 loss_rnnt 4.913835 lr 0.00027032 rank 6
2022-12-07 21:31:37,680 DEBUG TRAIN Batch 22/300 loss 11.283096 loss_att 400.220490 loss_ctc 29.737028 loss_rnnt 9.232660 lr 0.00027032 rank 2
2022-12-07 21:31:37,681 DEBUG TRAIN Batch 22/300 loss 5.530624 loss_att 311.394409 loss_ctc 13.276533 loss_rnnt 4.669968 lr 0.00027032 rank 7
2022-12-07 21:31:37,683 DEBUG TRAIN Batch 22/300 loss 5.588138 loss_att 335.749023 loss_ctc 13.186281 loss_rnnt 4.743899 lr 0.00027033 rank 3
2022-12-07 21:31:37,687 DEBUG TRAIN Batch 22/300 loss 4.106320 loss_att 382.989380 loss_ctc 13.565438 loss_rnnt 3.055307 lr 0.00027033 rank 0
2022-12-07 21:31:37,711 DEBUG TRAIN Batch 22/300 loss 6.818684 loss_att 379.924622 loss_ctc 15.789330 loss_rnnt 5.821945 lr 0.00027032 rank 5
2022-12-07 21:32:51,198 DEBUG TRAIN Batch 22/400 loss 6.141126 loss_att 344.983826 loss_ctc 14.793749 loss_rnnt 5.179723 lr 0.00027029 rank 4
2022-12-07 21:32:51,201 DEBUG TRAIN Batch 22/400 loss 9.041330 loss_att 401.568054 loss_ctc 19.748074 loss_rnnt 7.851693 lr 0.00027028 rank 6
2022-12-07 21:32:51,204 DEBUG TRAIN Batch 22/400 loss 8.451042 loss_att 337.983337 loss_ctc 16.203081 loss_rnnt 7.589705 lr 0.00027029 rank 1
2022-12-07 21:32:51,206 DEBUG TRAIN Batch 22/400 loss 6.802956 loss_att 381.394257 loss_ctc 11.600796 loss_rnnt 6.269863 lr 0.00027029 rank 0
2022-12-07 21:32:51,205 DEBUG TRAIN Batch 22/400 loss 6.056741 loss_att 365.927155 loss_ctc 11.864965 loss_rnnt 5.411383 lr 0.00027029 rank 7
2022-12-07 21:32:51,208 DEBUG TRAIN Batch 22/400 loss 7.210244 loss_att 340.374084 loss_ctc 15.499926 loss_rnnt 6.289168 lr 0.00027028 rank 2
2022-12-07 21:32:51,209 DEBUG TRAIN Batch 22/400 loss 6.698919 loss_att 376.466736 loss_ctc 14.909224 loss_rnnt 5.786663 lr 0.00027028 rank 5
2022-12-07 21:32:51,209 DEBUG TRAIN Batch 22/400 loss 9.405063 loss_att 422.920868 loss_ctc 21.727722 loss_rnnt 8.035878 lr 0.00027029 rank 3
2022-12-07 21:33:53,506 DEBUG TRAIN Batch 22/500 loss 15.407400 loss_att 310.580200 loss_ctc 23.261522 loss_rnnt 14.534720 lr 0.00027025 rank 4
2022-12-07 21:33:53,509 DEBUG TRAIN Batch 22/500 loss 7.277888 loss_att 347.698822 loss_ctc 13.289539 loss_rnnt 6.609928 lr 0.00027025 rank 7
2022-12-07 21:33:53,511 DEBUG TRAIN Batch 22/500 loss 9.420407 loss_att 325.164062 loss_ctc 16.687462 loss_rnnt 8.612957 lr 0.00027025 rank 1
2022-12-07 21:33:53,511 DEBUG TRAIN Batch 22/500 loss 10.338871 loss_att 299.780945 loss_ctc 16.619963 loss_rnnt 9.640972 lr 0.00027024 rank 2
2022-12-07 21:33:53,516 DEBUG TRAIN Batch 22/500 loss 7.737581 loss_att 270.399323 loss_ctc 12.571749 loss_rnnt 7.200451 lr 0.00027024 rank 6
2022-12-07 21:33:53,521 DEBUG TRAIN Batch 22/500 loss 10.666098 loss_att 306.117004 loss_ctc 18.446817 loss_rnnt 9.801574 lr 0.00027024 rank 5
2022-12-07 21:33:53,525 DEBUG TRAIN Batch 22/500 loss 4.279673 loss_att 320.631042 loss_ctc 11.082256 loss_rnnt 3.523830 lr 0.00027025 rank 0
2022-12-07 21:33:53,572 DEBUG TRAIN Batch 22/500 loss 12.267553 loss_att 369.116852 loss_ctc 25.530109 loss_rnnt 10.793936 lr 0.00027025 rank 3
2022-12-07 21:34:56,657 DEBUG TRAIN Batch 22/600 loss 3.643859 loss_att 452.373840 loss_ctc 13.199152 loss_rnnt 2.582160 lr 0.00027021 rank 4
2022-12-07 21:34:56,678 DEBUG TRAIN Batch 22/600 loss 7.511261 loss_att 248.029770 loss_ctc 18.268717 loss_rnnt 6.315988 lr 0.00027021 rank 2
2022-12-07 21:34:56,682 DEBUG TRAIN Batch 22/600 loss 10.151030 loss_att 233.014694 loss_ctc 20.894905 loss_rnnt 8.957266 lr 0.00027021 rank 3
2022-12-07 21:34:56,683 DEBUG TRAIN Batch 22/600 loss 6.358260 loss_att 68.039223 loss_ctc 10.702625 loss_rnnt 5.875553 lr 0.00027020 rank 6
2022-12-07 21:34:56,684 DEBUG TRAIN Batch 22/600 loss 7.082934 loss_att 399.778870 loss_ctc 20.328571 loss_rnnt 5.611197 lr 0.00027020 rank 5
2022-12-07 21:34:56,685 DEBUG TRAIN Batch 22/600 loss 9.023379 loss_att 188.347260 loss_ctc 17.298239 loss_rnnt 8.103951 lr 0.00027021 rank 0
2022-12-07 21:34:56,689 DEBUG TRAIN Batch 22/600 loss 7.868289 loss_att 139.813324 loss_ctc 14.751354 loss_rnnt 7.103504 lr 0.00027021 rank 7
2022-12-07 21:34:56,689 DEBUG TRAIN Batch 22/600 loss 5.141128 loss_att 186.002899 loss_ctc 9.102400 loss_rnnt 4.700986 lr 0.00027021 rank 1
2022-12-07 21:36:01,876 DEBUG TRAIN Batch 22/700 loss 7.441596 loss_att 426.769714 loss_ctc 21.089474 loss_rnnt 5.925165 lr 0.00027017 rank 2
2022-12-07 21:36:01,888 DEBUG TRAIN Batch 22/700 loss 9.862593 loss_att 370.977600 loss_ctc 23.795212 loss_rnnt 8.314525 lr 0.00027017 rank 7
2022-12-07 21:36:01,888 DEBUG TRAIN Batch 22/700 loss 6.858383 loss_att 342.100281 loss_ctc 21.378881 loss_rnnt 5.244995 lr 0.00027016 rank 6
2022-12-07 21:36:01,888 DEBUG TRAIN Batch 22/700 loss 1.615102 loss_att 385.090271 loss_ctc 8.100265 loss_rnnt 0.894528 lr 0.00027016 rank 5
2022-12-07 21:36:01,889 DEBUG TRAIN Batch 22/700 loss 10.460332 loss_att 386.386688 loss_ctc 20.041353 loss_rnnt 9.395775 lr 0.00027017 rank 4
2022-12-07 21:36:01,911 DEBUG TRAIN Batch 22/700 loss 3.863141 loss_att 395.027161 loss_ctc 8.503538 loss_rnnt 3.347541 lr 0.00027017 rank 1
2022-12-07 21:36:01,911 DEBUG TRAIN Batch 22/700 loss 7.255364 loss_att 433.179291 loss_ctc 15.100626 loss_rnnt 6.383668 lr 0.00027017 rank 3
2022-12-07 21:36:01,912 DEBUG TRAIN Batch 22/700 loss 5.990715 loss_att 437.549500 loss_ctc 11.202904 loss_rnnt 5.411582 lr 0.00027017 rank 0
2022-12-07 21:37:13,274 DEBUG TRAIN Batch 22/800 loss 11.736094 loss_att 445.372406 loss_ctc 21.248266 loss_rnnt 10.679186 lr 0.00027013 rank 0
2022-12-07 21:37:13,275 DEBUG TRAIN Batch 22/800 loss 10.282436 loss_att 412.004822 loss_ctc 13.782799 loss_rnnt 9.893508 lr 0.00027012 rank 6
2022-12-07 21:37:13,276 DEBUG TRAIN Batch 22/800 loss 15.146876 loss_att 417.707489 loss_ctc 23.825901 loss_rnnt 14.182540 lr 0.00027013 rank 7
2022-12-07 21:37:13,279 DEBUG TRAIN Batch 22/800 loss 10.033025 loss_att 392.025879 loss_ctc 28.169830 loss_rnnt 8.017824 lr 0.00027013 rank 4
2022-12-07 21:37:13,279 DEBUG TRAIN Batch 22/800 loss 3.751768 loss_att 366.368500 loss_ctc 9.968000 loss_rnnt 3.061075 lr 0.00027013 rank 3
2022-12-07 21:37:13,280 DEBUG TRAIN Batch 22/800 loss 6.101634 loss_att 390.734985 loss_ctc 14.334351 loss_rnnt 5.186887 lr 0.00027012 rank 5
2022-12-07 21:37:13,284 DEBUG TRAIN Batch 22/800 loss 6.147588 loss_att 369.393646 loss_ctc 12.151462 loss_rnnt 5.480491 lr 0.00027013 rank 1
2022-12-07 21:37:13,288 DEBUG TRAIN Batch 22/800 loss 4.049366 loss_att 351.942841 loss_ctc 14.254539 loss_rnnt 2.915457 lr 0.00027013 rank 2
2022-12-07 21:38:16,192 DEBUG TRAIN Batch 22/900 loss 7.452926 loss_att 389.303162 loss_ctc 14.736722 loss_rnnt 6.643615 lr 0.00027009 rank 7
2022-12-07 21:38:16,196 DEBUG TRAIN Batch 22/900 loss 5.031594 loss_att 342.479431 loss_ctc 9.181366 loss_rnnt 4.570508 lr 0.00027008 rank 6
2022-12-07 21:38:16,197 DEBUG TRAIN Batch 22/900 loss 4.600115 loss_att 338.878906 loss_ctc 9.177457 loss_rnnt 4.091522 lr 0.00027009 rank 4
2022-12-07 21:38:16,200 DEBUG TRAIN Batch 22/900 loss 1.367501 loss_att 386.990601 loss_ctc 4.324327 loss_rnnt 1.038965 lr 0.00027010 rank 3
2022-12-07 21:38:16,201 DEBUG TRAIN Batch 22/900 loss 5.828233 loss_att 370.219696 loss_ctc 13.985387 loss_rnnt 4.921883 lr 0.00027009 rank 0
2022-12-07 21:38:16,203 DEBUG TRAIN Batch 22/900 loss 5.202435 loss_att 395.622559 loss_ctc 14.388536 loss_rnnt 4.181757 lr 0.00027009 rank 2
2022-12-07 21:38:16,203 DEBUG TRAIN Batch 22/900 loss 6.907872 loss_att 346.355530 loss_ctc 14.038534 loss_rnnt 6.115577 lr 0.00027009 rank 1
2022-12-07 21:38:16,203 DEBUG TRAIN Batch 22/900 loss 5.965888 loss_att 371.665405 loss_ctc 14.538908 loss_rnnt 5.013330 lr 0.00027008 rank 5
2022-12-07 21:39:19,846 DEBUG TRAIN Batch 22/1000 loss 4.084873 loss_att 307.416138 loss_ctc 10.533080 loss_rnnt 3.368406 lr 0.00027005 rank 7
2022-12-07 21:39:19,851 DEBUG TRAIN Batch 22/1000 loss 4.895564 loss_att 365.962311 loss_ctc 10.178915 loss_rnnt 4.308525 lr 0.00027005 rank 0
2022-12-07 21:39:19,856 DEBUG TRAIN Batch 22/1000 loss 9.457460 loss_att 367.772827 loss_ctc 15.210144 loss_rnnt 8.818274 lr 0.00027004 rank 6
2022-12-07 21:39:19,857 DEBUG TRAIN Batch 22/1000 loss 14.565446 loss_att 375.015686 loss_ctc 32.759514 loss_rnnt 12.543883 lr 0.00027005 rank 1
2022-12-07 21:39:19,858 DEBUG TRAIN Batch 22/1000 loss 13.742406 loss_att 437.309326 loss_ctc 27.004295 loss_rnnt 12.268863 lr 0.00027006 rank 3
2022-12-07 21:39:19,859 DEBUG TRAIN Batch 22/1000 loss 6.137659 loss_att 335.098846 loss_ctc 12.368448 loss_rnnt 5.445349 lr 0.00027005 rank 4
2022-12-07 21:39:19,860 DEBUG TRAIN Batch 22/1000 loss 8.167307 loss_att 349.296173 loss_ctc 21.531937 loss_rnnt 6.682348 lr 0.00027005 rank 5
2022-12-07 21:39:19,867 DEBUG TRAIN Batch 22/1000 loss 6.598044 loss_att 375.384644 loss_ctc 16.460560 loss_rnnt 5.502209 lr 0.00027005 rank 2
2022-12-07 21:40:33,946 DEBUG TRAIN Batch 22/1100 loss 5.520391 loss_att 304.770660 loss_ctc 8.522392 loss_rnnt 5.186836 lr 0.00027001 rank 4
2022-12-07 21:40:33,950 DEBUG TRAIN Batch 22/1100 loss 4.814471 loss_att 313.446381 loss_ctc 10.614433 loss_rnnt 4.170031 lr 0.00027001 rank 7
2022-12-07 21:40:33,955 DEBUG TRAIN Batch 22/1100 loss 11.266727 loss_att 292.726166 loss_ctc 16.567923 loss_rnnt 10.677706 lr 0.00027001 rank 0
2022-12-07 21:40:33,957 DEBUG TRAIN Batch 22/1100 loss 5.183223 loss_att 317.440735 loss_ctc 13.846609 loss_rnnt 4.220625 lr 0.00027001 rank 1
2022-12-07 21:40:33,957 DEBUG TRAIN Batch 22/1100 loss 3.704482 loss_att 362.369873 loss_ctc 5.750435 loss_rnnt 3.477154 lr 0.00027002 rank 3
2022-12-07 21:40:33,961 DEBUG TRAIN Batch 22/1100 loss 13.376655 loss_att 406.707458 loss_ctc 31.428467 loss_rnnt 11.370897 lr 0.00027001 rank 5
2022-12-07 21:40:33,995 DEBUG TRAIN Batch 22/1100 loss 5.476971 loss_att 294.392456 loss_ctc 12.323737 loss_rnnt 4.716219 lr 0.00027000 rank 6
2022-12-07 21:40:34,009 DEBUG TRAIN Batch 22/1100 loss 9.343758 loss_att 370.548981 loss_ctc 15.339775 loss_rnnt 8.677534 lr 0.00027001 rank 2
2022-12-07 21:41:37,640 DEBUG TRAIN Batch 22/1200 loss 11.942272 loss_att 413.585297 loss_ctc 22.268318 loss_rnnt 10.794933 lr 0.00026997 rank 4
2022-12-07 21:41:37,639 DEBUG TRAIN Batch 22/1200 loss 7.586196 loss_att 280.649506 loss_ctc 15.157251 loss_rnnt 6.744968 lr 0.00026997 rank 7
2022-12-07 21:41:37,642 DEBUG TRAIN Batch 22/1200 loss 8.186374 loss_att 330.025696 loss_ctc 16.997486 loss_rnnt 7.207361 lr 0.00026998 rank 3
2022-12-07 21:41:37,643 DEBUG TRAIN Batch 22/1200 loss 9.507782 loss_att 296.262177 loss_ctc 18.271351 loss_rnnt 8.534053 lr 0.00026998 rank 1
2022-12-07 21:41:37,646 DEBUG TRAIN Batch 22/1200 loss 14.098957 loss_att 275.749573 loss_ctc 22.805563 loss_rnnt 13.131557 lr 0.00026998 rank 0
2022-12-07 21:41:37,647 DEBUG TRAIN Batch 22/1200 loss 7.788180 loss_att 263.356354 loss_ctc 12.489208 loss_rnnt 7.265844 lr 0.00026997 rank 2
2022-12-07 21:41:37,647 DEBUG TRAIN Batch 22/1200 loss 7.234416 loss_att 224.065475 loss_ctc 16.711681 loss_rnnt 6.181387 lr 0.00026997 rank 5
2022-12-07 21:41:37,686 DEBUG TRAIN Batch 22/1200 loss 7.743577 loss_att 268.213043 loss_ctc 13.879383 loss_rnnt 7.061821 lr 0.00026996 rank 6
2022-12-07 21:42:40,189 DEBUG TRAIN Batch 22/1300 loss 3.769191 loss_att 462.312836 loss_ctc 8.961697 loss_rnnt 3.192246 lr 0.00026993 rank 7
2022-12-07 21:42:40,192 DEBUG TRAIN Batch 22/1300 loss 7.936705 loss_att 162.693970 loss_ctc 15.336728 loss_rnnt 7.114480 lr 0.00026994 rank 3
2022-12-07 21:42:40,192 DEBUG TRAIN Batch 22/1300 loss 3.326274 loss_att 358.333984 loss_ctc 10.001727 loss_rnnt 2.584557 lr 0.00026994 rank 0
2022-12-07 21:42:40,192 DEBUG TRAIN Batch 22/1300 loss 2.432363 loss_att 371.315521 loss_ctc 7.342413 loss_rnnt 1.886802 lr 0.00026993 rank 5
2022-12-07 21:42:40,192 DEBUG TRAIN Batch 22/1300 loss 5.455306 loss_att 414.459229 loss_ctc 10.406141 loss_rnnt 4.905213 lr 0.00026993 rank 4
2022-12-07 21:42:40,196 DEBUG TRAIN Batch 22/1300 loss 11.181406 loss_att 482.703369 loss_ctc 22.220760 loss_rnnt 9.954811 lr 0.00026993 rank 2
2022-12-07 21:42:40,197 DEBUG TRAIN Batch 22/1300 loss 5.948252 loss_att 395.239319 loss_ctc 12.620108 loss_rnnt 5.206934 lr 0.00026992 rank 6
2022-12-07 21:42:40,240 DEBUG TRAIN Batch 22/1300 loss 6.741471 loss_att 426.448669 loss_ctc 10.099956 loss_rnnt 6.368307 lr 0.00026994 rank 1
2022-12-07 21:43:44,419 DEBUG TRAIN Batch 22/1400 loss 5.022629 loss_att 352.933441 loss_ctc 8.325906 loss_rnnt 4.655599 lr 0.00026990 rank 1
2022-12-07 21:43:44,426 DEBUG TRAIN Batch 22/1400 loss 4.667268 loss_att 464.145447 loss_ctc 14.745871 loss_rnnt 3.547423 lr 0.00026988 rank 6
2022-12-07 21:43:44,432 DEBUG TRAIN Batch 22/1400 loss 7.566987 loss_att 289.537933 loss_ctc 22.596382 loss_rnnt 5.897054 lr 0.00026990 rank 3
2022-12-07 21:43:44,432 DEBUG TRAIN Batch 22/1400 loss 4.986301 loss_att 383.884125 loss_ctc 17.004807 loss_rnnt 3.650912 lr 0.00026989 rank 7
2022-12-07 21:43:44,448 DEBUG TRAIN Batch 22/1400 loss 10.094405 loss_att 375.316223 loss_ctc 20.877905 loss_rnnt 8.896239 lr 0.00026989 rank 2
2022-12-07 21:43:44,454 DEBUG TRAIN Batch 22/1400 loss 1.781393 loss_att 367.655121 loss_ctc 9.675976 loss_rnnt 0.904217 lr 0.00026989 rank 5
2022-12-07 21:43:44,460 DEBUG TRAIN Batch 22/1400 loss 14.066313 loss_att 376.076172 loss_ctc 24.614998 loss_rnnt 12.894237 lr 0.00026990 rank 0
2022-12-07 21:43:44,467 DEBUG TRAIN Batch 22/1400 loss 14.484844 loss_att 378.800385 loss_ctc 28.526035 loss_rnnt 12.924712 lr 0.00026989 rank 4
2022-12-07 21:44:57,065 DEBUG TRAIN Batch 22/1500 loss 5.771489 loss_att 385.202484 loss_ctc 11.890013 loss_rnnt 5.091653 lr 0.00026985 rank 4
2022-12-07 21:44:57,072 DEBUG TRAIN Batch 22/1500 loss 12.992137 loss_att 437.783081 loss_ctc 30.786068 loss_rnnt 11.015034 lr 0.00026985 rank 2
2022-12-07 21:44:57,072 DEBUG TRAIN Batch 22/1500 loss 6.113581 loss_att 358.642731 loss_ctc 13.258791 loss_rnnt 5.319669 lr 0.00026985 rank 7
2022-12-07 21:44:57,074 DEBUG TRAIN Batch 22/1500 loss 5.987234 loss_att 369.753998 loss_ctc 9.914939 loss_rnnt 5.550822 lr 0.00026986 rank 1
2022-12-07 21:44:57,075 DEBUG TRAIN Batch 22/1500 loss 10.161406 loss_att 363.479736 loss_ctc 14.539377 loss_rnnt 9.674965 lr 0.00026986 rank 0
2022-12-07 21:44:57,077 DEBUG TRAIN Batch 22/1500 loss 2.312481 loss_att 371.805511 loss_ctc 10.903980 loss_rnnt 1.357870 lr 0.00026986 rank 3
2022-12-07 21:44:57,079 DEBUG TRAIN Batch 22/1500 loss 6.692490 loss_att 389.613342 loss_ctc 18.012440 loss_rnnt 5.434717 lr 0.00026985 rank 6
2022-12-07 21:44:57,079 DEBUG TRAIN Batch 22/1500 loss 10.309134 loss_att 387.715088 loss_ctc 25.848175 loss_rnnt 8.582575 lr 0.00026985 rank 5
2022-12-07 21:45:59,520 DEBUG TRAIN Batch 22/1600 loss 9.414872 loss_att 344.472260 loss_ctc 19.769722 loss_rnnt 8.264334 lr 0.00026981 rank 4
2022-12-07 21:45:59,523 DEBUG TRAIN Batch 22/1600 loss 11.286840 loss_att 409.384033 loss_ctc 18.868099 loss_rnnt 10.444478 lr 0.00026981 rank 7
2022-12-07 21:45:59,523 DEBUG TRAIN Batch 22/1600 loss 4.442630 loss_att 339.200378 loss_ctc 11.723599 loss_rnnt 3.633633 lr 0.00026981 rank 2
2022-12-07 21:45:59,524 DEBUG TRAIN Batch 22/1600 loss 2.721685 loss_att 426.351074 loss_ctc 11.381455 loss_rnnt 1.759488 lr 0.00026982 rank 3
2022-12-07 21:45:59,525 DEBUG TRAIN Batch 22/1600 loss 4.122053 loss_att 337.791168 loss_ctc 10.828569 loss_rnnt 3.376884 lr 0.00026982 rank 1
2022-12-07 21:45:59,526 DEBUG TRAIN Batch 22/1600 loss 3.774441 loss_att 310.995514 loss_ctc 9.686639 loss_rnnt 3.117530 lr 0.00026981 rank 6
2022-12-07 21:45:59,528 DEBUG TRAIN Batch 22/1600 loss 13.520147 loss_att 384.708374 loss_ctc 32.507607 loss_rnnt 11.410429 lr 0.00026981 rank 5
2022-12-07 21:45:59,529 DEBUG TRAIN Batch 22/1600 loss 11.480763 loss_att 423.160767 loss_ctc 18.772232 loss_rnnt 10.670601 lr 0.00026982 rank 0
2022-12-07 21:47:02,985 DEBUG TRAIN Batch 22/1700 loss 9.226931 loss_att 345.813293 loss_ctc 14.953268 loss_rnnt 8.590672 lr 0.00026977 rank 2
2022-12-07 21:47:02,994 DEBUG TRAIN Batch 22/1700 loss 9.935980 loss_att 348.357971 loss_ctc 17.734882 loss_rnnt 9.069435 lr 0.00026977 rank 7
2022-12-07 21:47:02,995 DEBUG TRAIN Batch 22/1700 loss 5.157193 loss_att 386.285797 loss_ctc 13.116838 loss_rnnt 4.272788 lr 0.00026978 rank 3
2022-12-07 21:47:02,995 DEBUG TRAIN Batch 22/1700 loss 14.131159 loss_att 314.942139 loss_ctc 30.973534 loss_rnnt 12.259784 lr 0.00026978 rank 1
2022-12-07 21:47:03,000 DEBUG TRAIN Batch 22/1700 loss 13.591902 loss_att 300.148254 loss_ctc 20.644447 loss_rnnt 12.808287 lr 0.00026978 rank 4
2022-12-07 21:47:03,001 DEBUG TRAIN Batch 22/1700 loss 12.317614 loss_att 354.609344 loss_ctc 29.350554 loss_rnnt 10.425064 lr 0.00026978 rank 0
2022-12-07 21:47:03,014 DEBUG TRAIN Batch 22/1700 loss 20.029547 loss_att 335.951050 loss_ctc 33.879860 loss_rnnt 18.490623 lr 0.00026977 rank 5
2022-12-07 21:47:03,028 DEBUG TRAIN Batch 22/1700 loss 10.737206 loss_att 364.317291 loss_ctc 17.642397 loss_rnnt 9.969964 lr 0.00026977 rank 6
2022-12-07 21:48:14,632 DEBUG TRAIN Batch 22/1800 loss 6.201509 loss_att 326.085205 loss_ctc 10.369642 loss_rnnt 5.738384 lr 0.00026974 rank 0
2022-12-07 21:48:14,639 DEBUG TRAIN Batch 22/1800 loss 8.638988 loss_att 312.580383 loss_ctc 16.686903 loss_rnnt 7.744775 lr 0.00026974 rank 1
2022-12-07 21:48:14,640 DEBUG TRAIN Batch 22/1800 loss 9.614058 loss_att 274.994202 loss_ctc 17.027729 loss_rnnt 8.790318 lr 0.00026973 rank 6
2022-12-07 21:48:14,641 DEBUG TRAIN Batch 22/1800 loss 7.154820 loss_att 175.320068 loss_ctc 14.097226 loss_rnnt 6.383441 lr 0.00026974 rank 4
2022-12-07 21:48:14,642 DEBUG TRAIN Batch 22/1800 loss 5.740646 loss_att 248.280960 loss_ctc 10.275599 loss_rnnt 5.236763 lr 0.00026973 rank 7
2022-12-07 21:48:14,645 DEBUG TRAIN Batch 22/1800 loss 5.382535 loss_att 332.409912 loss_ctc 13.167938 loss_rnnt 4.517489 lr 0.00026973 rank 2
2022-12-07 21:48:14,645 DEBUG TRAIN Batch 22/1800 loss 3.941735 loss_att 398.632263 loss_ctc 8.528121 loss_rnnt 3.432137 lr 0.00026974 rank 3
2022-12-07 21:48:14,646 DEBUG TRAIN Batch 22/1800 loss 5.741578 loss_att 269.104218 loss_ctc 10.597831 loss_rnnt 5.201994 lr 0.00026973 rank 5
2022-12-07 21:49:18,230 DEBUG TRAIN Batch 22/1900 loss 6.587906 loss_att 421.218353 loss_ctc 14.898280 loss_rnnt 5.664531 lr 0.00026969 rank 2
2022-12-07 21:49:18,232 DEBUG TRAIN Batch 22/1900 loss 9.758909 loss_att 365.368408 loss_ctc 17.389427 loss_rnnt 8.911074 lr 0.00026970 rank 4
2022-12-07 21:49:18,234 DEBUG TRAIN Batch 22/1900 loss 8.097438 loss_att 213.878586 loss_ctc 14.757739 loss_rnnt 7.357404 lr 0.00026970 rank 3
2022-12-07 21:49:18,234 DEBUG TRAIN Batch 22/1900 loss 4.395112 loss_att 337.400146 loss_ctc 9.977571 loss_rnnt 3.774839 lr 0.00026969 rank 5
2022-12-07 21:49:18,235 DEBUG TRAIN Batch 22/1900 loss 7.191671 loss_att 433.071594 loss_ctc 18.903034 loss_rnnt 5.890409 lr 0.00026969 rank 7
2022-12-07 21:49:18,239 DEBUG TRAIN Batch 22/1900 loss 8.758390 loss_att 216.668472 loss_ctc 14.850140 loss_rnnt 8.081530 lr 0.00026970 rank 0
2022-12-07 21:49:18,239 DEBUG TRAIN Batch 22/1900 loss 9.837072 loss_att 122.568588 loss_ctc 15.583313 loss_rnnt 9.198601 lr 0.00026970 rank 1
2022-12-07 21:49:18,243 DEBUG TRAIN Batch 22/1900 loss 4.703842 loss_att 140.469208 loss_ctc 7.930257 loss_rnnt 4.345352 lr 0.00026969 rank 6
2022-12-07 21:50:21,359 DEBUG TRAIN Batch 22/2000 loss 8.018296 loss_att 460.153442 loss_ctc 17.740576 loss_rnnt 6.938043 lr 0.00026966 rank 7
2022-12-07 21:50:21,359 DEBUG TRAIN Batch 22/2000 loss 4.085714 loss_att 417.395447 loss_ctc 8.312361 loss_rnnt 3.616086 lr 0.00026966 rank 0
2022-12-07 21:50:21,361 DEBUG TRAIN Batch 22/2000 loss 3.693233 loss_att 436.313904 loss_ctc 12.912148 loss_rnnt 2.668909 lr 0.00026966 rank 4
2022-12-07 21:50:21,361 DEBUG TRAIN Batch 22/2000 loss 5.837545 loss_att 337.839355 loss_ctc 11.548828 loss_rnnt 5.202958 lr 0.00026966 rank 1
2022-12-07 21:50:21,363 DEBUG TRAIN Batch 22/2000 loss 2.589413 loss_att 409.939148 loss_ctc 7.677991 loss_rnnt 2.024016 lr 0.00026965 rank 6
2022-12-07 21:50:21,363 DEBUG TRAIN Batch 22/2000 loss 11.222698 loss_att 396.814026 loss_ctc 15.954566 loss_rnnt 10.696936 lr 0.00026966 rank 3
2022-12-07 21:50:21,366 DEBUG TRAIN Batch 22/2000 loss 9.132188 loss_att 420.005463 loss_ctc 17.773685 loss_rnnt 8.172022 lr 0.00026965 rank 2
2022-12-07 21:50:21,368 DEBUG TRAIN Batch 22/2000 loss 1.448068 loss_att 342.524384 loss_ctc 7.703790 loss_rnnt 0.752988 lr 0.00026965 rank 5
2022-12-07 21:51:25,854 DEBUG TRAIN Batch 22/2100 loss 4.334144 loss_att 356.691742 loss_ctc 12.125361 loss_rnnt 3.468453 lr 0.00026962 rank 7
2022-12-07 21:51:25,855 DEBUG TRAIN Batch 22/2100 loss 8.351768 loss_att 360.679047 loss_ctc 17.463455 loss_rnnt 7.339359 lr 0.00026962 rank 3
2022-12-07 21:51:25,857 DEBUG TRAIN Batch 22/2100 loss 1.769840 loss_att 345.295166 loss_ctc 6.832622 loss_rnnt 1.207308 lr 0.00026961 rank 6
2022-12-07 21:51:25,858 DEBUG TRAIN Batch 22/2100 loss 9.666031 loss_att 445.900726 loss_ctc 15.773504 loss_rnnt 8.987423 lr 0.00026961 rank 5
2022-12-07 21:51:25,860 DEBUG TRAIN Batch 22/2100 loss 8.629653 loss_att 379.468201 loss_ctc 17.560417 loss_rnnt 7.637346 lr 0.00026962 rank 2
2022-12-07 21:51:25,864 DEBUG TRAIN Batch 22/2100 loss 2.991507 loss_att 352.599487 loss_ctc 7.136549 loss_rnnt 2.530947 lr 0.00026962 rank 0
2022-12-07 21:51:25,871 DEBUG TRAIN Batch 22/2100 loss 7.901901 loss_att 376.547119 loss_ctc 17.567036 loss_rnnt 6.827998 lr 0.00026962 rank 4
2022-12-07 21:51:25,900 DEBUG TRAIN Batch 22/2100 loss 4.820456 loss_att 328.747101 loss_ctc 7.843957 loss_rnnt 4.484512 lr 0.00026962 rank 1
2022-12-07 21:52:37,017 DEBUG TRAIN Batch 22/2200 loss 10.260099 loss_att 398.516479 loss_ctc 24.779980 loss_rnnt 8.646779 lr 0.00026958 rank 7
2022-12-07 21:52:37,022 DEBUG TRAIN Batch 22/2200 loss 3.809460 loss_att 352.638458 loss_ctc 12.716579 loss_rnnt 2.819780 lr 0.00026958 rank 4
2022-12-07 21:52:37,023 DEBUG TRAIN Batch 22/2200 loss 5.423816 loss_att 375.230164 loss_ctc 10.283869 loss_rnnt 4.883811 lr 0.00026958 rank 0
2022-12-07 21:52:37,024 DEBUG TRAIN Batch 22/2200 loss 7.089309 loss_att 371.049866 loss_ctc 12.720840 loss_rnnt 6.463583 lr 0.00026957 rank 6
2022-12-07 21:52:37,026 DEBUG TRAIN Batch 22/2200 loss 3.319589 loss_att 361.720459 loss_ctc 8.572601 loss_rnnt 2.735920 lr 0.00026958 rank 2
2022-12-07 21:52:37,027 DEBUG TRAIN Batch 22/2200 loss 15.254489 loss_att 337.838440 loss_ctc 34.018478 loss_rnnt 13.169601 lr 0.00026958 rank 1
2022-12-07 21:52:37,028 DEBUG TRAIN Batch 22/2200 loss 7.298547 loss_att 371.048920 loss_ctc 9.079048 loss_rnnt 7.100714 lr 0.00026957 rank 5
2022-12-07 21:52:37,028 DEBUG TRAIN Batch 22/2200 loss 4.058505 loss_att 351.479248 loss_ctc 11.907234 loss_rnnt 3.186424 lr 0.00026958 rank 3
2022-12-07 21:53:40,188 DEBUG TRAIN Batch 22/2300 loss 5.572791 loss_att 384.689697 loss_ctc 13.058342 loss_rnnt 4.741063 lr 0.00026954 rank 1
2022-12-07 21:53:40,188 DEBUG TRAIN Batch 22/2300 loss 9.363637 loss_att 352.471741 loss_ctc 27.936842 loss_rnnt 7.299948 lr 0.00026954 rank 4
2022-12-07 21:53:40,189 DEBUG TRAIN Batch 22/2300 loss 6.518322 loss_att 376.206238 loss_ctc 11.542228 loss_rnnt 5.960111 lr 0.00026953 rank 5
2022-12-07 21:53:40,189 DEBUG TRAIN Batch 22/2300 loss 6.333892 loss_att 374.504486 loss_ctc 12.394951 loss_rnnt 5.660441 lr 0.00026954 rank 7
2022-12-07 21:53:40,189 DEBUG TRAIN Batch 22/2300 loss 8.641697 loss_att 418.983032 loss_ctc 15.842412 loss_rnnt 7.841618 lr 0.00026954 rank 2
2022-12-07 21:53:40,191 DEBUG TRAIN Batch 22/2300 loss 8.621933 loss_att 395.313660 loss_ctc 14.307481 loss_rnnt 7.990206 lr 0.00026955 rank 3
2022-12-07 21:53:40,193 DEBUG TRAIN Batch 22/2300 loss 8.128785 loss_att 363.719482 loss_ctc 17.907284 loss_rnnt 7.042286 lr 0.00026954 rank 0
2022-12-07 21:53:40,231 DEBUG TRAIN Batch 22/2300 loss 3.296644 loss_att 330.318726 loss_ctc 4.782198 loss_rnnt 3.131583 lr 0.00026953 rank 6
2022-12-07 21:54:43,934 DEBUG TRAIN Batch 22/2400 loss 17.358088 loss_att 220.450485 loss_ctc 35.251053 loss_rnnt 15.369982 lr 0.00026950 rank 4
2022-12-07 21:54:43,938 DEBUG TRAIN Batch 22/2400 loss 7.566719 loss_att 317.636932 loss_ctc 16.148369 loss_rnnt 6.613203 lr 0.00026951 rank 3
2022-12-07 21:54:43,939 DEBUG TRAIN Batch 22/2400 loss 12.068224 loss_att 382.478180 loss_ctc 25.161354 loss_rnnt 10.613432 lr 0.00026949 rank 6
2022-12-07 21:54:43,939 DEBUG TRAIN Batch 22/2400 loss 6.057828 loss_att 339.583801 loss_ctc 10.676090 loss_rnnt 5.544687 lr 0.00026950 rank 7
2022-12-07 21:54:43,941 DEBUG TRAIN Batch 22/2400 loss 11.843022 loss_att 306.838440 loss_ctc 19.727758 loss_rnnt 10.966941 lr 0.00026950 rank 2
2022-12-07 21:54:43,943 DEBUG TRAIN Batch 22/2400 loss 6.132992 loss_att 312.261719 loss_ctc 9.861665 loss_rnnt 5.718696 lr 0.00026950 rank 1
2022-12-07 21:54:43,945 DEBUG TRAIN Batch 22/2400 loss 4.392410 loss_att 308.594360 loss_ctc 10.299430 loss_rnnt 3.736074 lr 0.00026950 rank 5
2022-12-07 21:54:43,946 DEBUG TRAIN Batch 22/2400 loss 8.101548 loss_att 360.718567 loss_ctc 15.393427 loss_rnnt 7.291339 lr 0.00026950 rank 0
2022-12-07 21:55:56,844 DEBUG TRAIN Batch 22/2500 loss 9.042581 loss_att 177.572769 loss_ctc 13.281577 loss_rnnt 8.571581 lr 0.00026946 rank 7
2022-12-07 21:55:56,847 DEBUG TRAIN Batch 22/2500 loss 8.660976 loss_att 113.284447 loss_ctc 16.595287 loss_rnnt 7.779387 lr 0.00026946 rank 2
2022-12-07 21:55:56,847 DEBUG TRAIN Batch 22/2500 loss 12.498647 loss_att 226.883148 loss_ctc 19.044518 loss_rnnt 11.771328 lr 0.00026946 rank 1
2022-12-07 21:55:56,849 DEBUG TRAIN Batch 22/2500 loss 13.068951 loss_att 341.883545 loss_ctc 26.827997 loss_rnnt 11.540168 lr 0.00026946 rank 0
2022-12-07 21:55:56,849 DEBUG TRAIN Batch 22/2500 loss 10.860468 loss_att 445.420654 loss_ctc 22.068617 loss_rnnt 9.615118 lr 0.00026946 rank 4
2022-12-07 21:55:56,850 DEBUG TRAIN Batch 22/2500 loss 8.638134 loss_att 74.748390 loss_ctc 14.204402 loss_rnnt 8.019660 lr 0.00026946 rank 5
2022-12-07 21:55:56,851 DEBUG TRAIN Batch 22/2500 loss 2.946560 loss_att 296.338959 loss_ctc 10.244836 loss_rnnt 2.135640 lr 0.00026947 rank 3
2022-12-07 21:55:56,889 DEBUG TRAIN Batch 22/2500 loss 8.745330 loss_att 317.403625 loss_ctc 16.776968 loss_rnnt 7.852925 lr 0.00026945 rank 6
2022-12-07 21:57:00,374 DEBUG TRAIN Batch 22/2600 loss 5.786860 loss_att 457.007996 loss_ctc 15.877623 loss_rnnt 4.665664 lr 0.00026942 rank 7
2022-12-07 21:57:00,378 DEBUG TRAIN Batch 22/2600 loss 11.498021 loss_att 358.812805 loss_ctc 22.048622 loss_rnnt 10.325732 lr 0.00026942 rank 4
2022-12-07 21:57:00,378 DEBUG TRAIN Batch 22/2600 loss 6.733648 loss_att 68.489029 loss_ctc 10.602917 loss_rnnt 6.303729 lr 0.00026943 rank 3
2022-12-07 21:57:00,378 DEBUG TRAIN Batch 22/2600 loss 8.913570 loss_att 410.503754 loss_ctc 16.382940 loss_rnnt 8.083641 lr 0.00026943 rank 1
2022-12-07 21:57:00,379 DEBUG TRAIN Batch 22/2600 loss 9.448015 loss_att 381.685303 loss_ctc 26.043554 loss_rnnt 7.604067 lr 0.00026942 rank 2
2022-12-07 21:57:00,381 DEBUG TRAIN Batch 22/2600 loss 9.880075 loss_att 414.645355 loss_ctc 16.148029 loss_rnnt 9.183636 lr 0.00026941 rank 6
2022-12-07 21:57:00,383 DEBUG TRAIN Batch 22/2600 loss 8.472998 loss_att 346.882019 loss_ctc 16.118378 loss_rnnt 7.623511 lr 0.00026942 rank 5
2022-12-07 21:57:00,385 DEBUG TRAIN Batch 22/2600 loss 4.525364 loss_att 259.493744 loss_ctc 9.847560 loss_rnnt 3.934009 lr 0.00026943 rank 0
2022-12-07 21:58:03,371 DEBUG TRAIN Batch 22/2700 loss 6.136523 loss_att 425.631897 loss_ctc 15.630470 loss_rnnt 5.081640 lr 0.00026939 rank 0
2022-12-07 21:58:03,376 DEBUG TRAIN Batch 22/2700 loss 7.333928 loss_att 364.696136 loss_ctc 22.880028 loss_rnnt 5.606584 lr 0.00026938 rank 7
2022-12-07 21:58:03,377 DEBUG TRAIN Batch 22/2700 loss 6.377308 loss_att 350.781738 loss_ctc 12.511386 loss_rnnt 5.695744 lr 0.00026938 rank 4
2022-12-07 21:58:03,380 DEBUG TRAIN Batch 22/2700 loss 6.819686 loss_att 357.423889 loss_ctc 14.079866 loss_rnnt 6.013000 lr 0.00026938 rank 2
2022-12-07 21:58:03,384 DEBUG TRAIN Batch 22/2700 loss 8.785031 loss_att 356.243866 loss_ctc 20.169903 loss_rnnt 7.520045 lr 0.00026939 rank 3
2022-12-07 21:58:03,386 DEBUG TRAIN Batch 22/2700 loss 7.009410 loss_att 302.423401 loss_ctc 23.144695 loss_rnnt 5.216600 lr 0.00026938 rank 6
2022-12-07 21:58:03,389 DEBUG TRAIN Batch 22/2700 loss 7.159740 loss_att 405.555267 loss_ctc 14.318094 loss_rnnt 6.364367 lr 0.00026938 rank 5
2022-12-07 21:58:03,430 DEBUG TRAIN Batch 22/2700 loss 7.578656 loss_att 378.455750 loss_ctc 16.297131 loss_rnnt 6.609937 lr 0.00026939 rank 1
2022-12-07 21:59:07,703 DEBUG TRAIN Batch 22/2800 loss 4.130916 loss_att 382.627930 loss_ctc 8.024989 loss_rnnt 3.698241 lr 0.00026935 rank 3
2022-12-07 21:59:07,705 DEBUG TRAIN Batch 22/2800 loss 9.182749 loss_att 380.693054 loss_ctc 18.569609 loss_rnnt 8.139765 lr 0.00026935 rank 1
2022-12-07 21:59:07,706 DEBUG TRAIN Batch 22/2800 loss 11.539793 loss_att 416.092773 loss_ctc 15.119105 loss_rnnt 11.142092 lr 0.00026935 rank 0
2022-12-07 21:59:07,708 DEBUG TRAIN Batch 22/2800 loss 15.636467 loss_att 464.333221 loss_ctc 27.754663 loss_rnnt 14.290001 lr 0.00026934 rank 4
2022-12-07 21:59:07,710 DEBUG TRAIN Batch 22/2800 loss 9.350149 loss_att 430.862000 loss_ctc 27.314316 loss_rnnt 7.354131 lr 0.00026934 rank 6
2022-12-07 21:59:07,712 DEBUG TRAIN Batch 22/2800 loss 6.001574 loss_att 444.215515 loss_ctc 15.933168 loss_rnnt 4.898063 lr 0.00026934 rank 7
2022-12-07 21:59:07,735 DEBUG TRAIN Batch 22/2800 loss 8.943538 loss_att 402.785187 loss_ctc 20.080009 loss_rnnt 7.706151 lr 0.00026934 rank 5
2022-12-07 21:59:07,735 DEBUG TRAIN Batch 22/2800 loss 4.196733 loss_att 409.074829 loss_ctc 8.791700 loss_rnnt 3.686181 lr 0.00026934 rank 2
2022-12-07 22:00:20,918 DEBUG TRAIN Batch 22/2900 loss 9.161151 loss_att 377.182251 loss_ctc 16.869568 loss_rnnt 8.304661 lr 0.00026930 rank 6
2022-12-07 22:00:20,925 DEBUG TRAIN Batch 22/2900 loss 9.672833 loss_att 323.761719 loss_ctc 12.643883 loss_rnnt 9.342717 lr 0.00026930 rank 2
2022-12-07 22:00:20,926 DEBUG TRAIN Batch 22/2900 loss 21.171438 loss_att 418.233521 loss_ctc 38.319717 loss_rnnt 19.266073 lr 0.00026931 rank 3
2022-12-07 22:00:20,926 DEBUG TRAIN Batch 22/2900 loss 6.591177 loss_att 327.831146 loss_ctc 10.077052 loss_rnnt 6.203857 lr 0.00026931 rank 4
2022-12-07 22:00:20,927 DEBUG TRAIN Batch 22/2900 loss 7.682397 loss_att 357.410431 loss_ctc 13.067989 loss_rnnt 7.083998 lr 0.00026931 rank 1
2022-12-07 22:00:20,930 DEBUG TRAIN Batch 22/2900 loss 3.652175 loss_att 436.466736 loss_ctc 10.565894 loss_rnnt 2.883985 lr 0.00026930 rank 7
2022-12-07 22:00:20,930 DEBUG TRAIN Batch 22/2900 loss 9.381234 loss_att 334.711517 loss_ctc 16.631538 loss_rnnt 8.575644 lr 0.00026930 rank 5
2022-12-07 22:00:20,932 DEBUG TRAIN Batch 22/2900 loss 16.222048 loss_att 388.768982 loss_ctc 31.302927 loss_rnnt 14.546394 lr 0.00026931 rank 0
2022-12-07 22:01:23,638 DEBUG TRAIN Batch 22/3000 loss 6.120012 loss_att 309.009003 loss_ctc 12.324028 loss_rnnt 5.430677 lr 0.00026927 rank 4
2022-12-07 22:01:23,640 DEBUG TRAIN Batch 22/3000 loss 7.997118 loss_att 323.878265 loss_ctc 13.551624 loss_rnnt 7.379951 lr 0.00026926 rank 7
2022-12-07 22:01:23,642 DEBUG TRAIN Batch 22/3000 loss 5.250114 loss_att 358.639038 loss_ctc 13.290492 loss_rnnt 4.356739 lr 0.00026926 rank 6
2022-12-07 22:01:23,644 DEBUG TRAIN Batch 22/3000 loss 7.319520 loss_att 390.579529 loss_ctc 13.750505 loss_rnnt 6.604966 lr 0.00026926 rank 2
2022-12-07 22:01:23,647 DEBUG TRAIN Batch 22/3000 loss 4.119927 loss_att 337.623230 loss_ctc 10.692089 loss_rnnt 3.389687 lr 0.00026927 rank 0
2022-12-07 22:01:23,649 DEBUG TRAIN Batch 22/3000 loss 1.933970 loss_att 288.581818 loss_ctc 4.898590 loss_rnnt 1.604568 lr 0.00026926 rank 5
2022-12-07 22:01:23,652 DEBUG TRAIN Batch 22/3000 loss 2.188900 loss_att 320.543335 loss_ctc 6.672241 loss_rnnt 1.690751 lr 0.00026927 rank 1
2022-12-07 22:01:23,684 DEBUG TRAIN Batch 22/3000 loss 2.946739 loss_att 276.473877 loss_ctc 8.316094 loss_rnnt 2.350144 lr 0.00026927 rank 3
2022-12-07 22:02:27,717 DEBUG TRAIN Batch 22/3100 loss 8.331232 loss_att 284.767456 loss_ctc 18.404404 loss_rnnt 7.211991 lr 0.00026922 rank 6
2022-12-07 22:02:27,720 DEBUG TRAIN Batch 22/3100 loss 7.935208 loss_att 309.290924 loss_ctc 17.776062 loss_rnnt 6.841780 lr 0.00026923 rank 7
2022-12-07 22:02:27,721 DEBUG TRAIN Batch 22/3100 loss 8.846767 loss_att 332.628387 loss_ctc 21.201420 loss_rnnt 7.474028 lr 0.00026923 rank 0
2022-12-07 22:02:27,721 DEBUG TRAIN Batch 22/3100 loss 10.549464 loss_att 274.589783 loss_ctc 18.881279 loss_rnnt 9.623707 lr 0.00026923 rank 1
2022-12-07 22:02:27,722 DEBUG TRAIN Batch 22/3100 loss 20.943083 loss_att 321.118011 loss_ctc 34.817787 loss_rnnt 19.401449 lr 0.00026923 rank 3
2022-12-07 22:02:27,722 DEBUG TRAIN Batch 22/3100 loss 7.358358 loss_att 105.129013 loss_ctc 12.304126 loss_rnnt 6.808828 lr 0.00026923 rank 4
2022-12-07 22:02:27,724 DEBUG TRAIN Batch 22/3100 loss 7.557429 loss_att 181.649963 loss_ctc 14.766638 loss_rnnt 6.756406 lr 0.00026922 rank 5
2022-12-07 22:02:27,765 DEBUG TRAIN Batch 22/3100 loss 5.668856 loss_att 282.909607 loss_ctc 13.161372 loss_rnnt 4.836354 lr 0.00026922 rank 2
2022-12-07 22:03:33,666 DEBUG TRAIN Batch 22/3200 loss 6.134289 loss_att 373.897797 loss_ctc 16.532598 loss_rnnt 4.978922 lr 0.00026919 rank 2
2022-12-07 22:03:33,671 DEBUG TRAIN Batch 22/3200 loss 6.055139 loss_att 454.221558 loss_ctc 11.508512 loss_rnnt 5.449208 lr 0.00026919 rank 4
2022-12-07 22:03:33,673 DEBUG TRAIN Batch 22/3200 loss 4.352712 loss_att 397.526581 loss_ctc 13.126043 loss_rnnt 3.377898 lr 0.00026919 rank 7
2022-12-07 22:03:33,675 DEBUG TRAIN Batch 22/3200 loss 9.101025 loss_att 124.140465 loss_ctc 13.893764 loss_rnnt 8.568499 lr 0.00026919 rank 3
2022-12-07 22:03:33,676 DEBUG TRAIN Batch 22/3200 loss 3.480015 loss_att 407.772156 loss_ctc 8.339828 loss_rnnt 2.940036 lr 0.00026919 rank 1
2022-12-07 22:03:33,680 DEBUG TRAIN Batch 22/3200 loss 11.209186 loss_att 361.962646 loss_ctc 16.470181 loss_rnnt 10.624630 lr 0.00026918 rank 5
2022-12-07 22:03:33,686 DEBUG TRAIN Batch 22/3200 loss 15.190025 loss_att 141.524017 loss_ctc 26.793766 loss_rnnt 13.900722 lr 0.00026919 rank 0
2022-12-07 22:03:33,720 DEBUG TRAIN Batch 22/3200 loss 6.243634 loss_att 116.637527 loss_ctc 10.293033 loss_rnnt 5.793701 lr 0.00026918 rank 6
2022-12-07 22:04:43,003 DEBUG TRAIN Batch 22/3300 loss 8.732120 loss_att 441.923950 loss_ctc 19.145950 loss_rnnt 7.575027 lr 0.00026915 rank 7
2022-12-07 22:04:43,006 DEBUG TRAIN Batch 22/3300 loss 11.247267 loss_att 451.317322 loss_ctc 28.768429 loss_rnnt 9.300471 lr 0.00026915 rank 4
2022-12-07 22:04:43,010 DEBUG TRAIN Batch 22/3300 loss 6.038103 loss_att 412.733246 loss_ctc 12.280775 loss_rnnt 5.344473 lr 0.00026915 rank 3
2022-12-07 22:04:43,011 DEBUG TRAIN Batch 22/3300 loss 6.950795 loss_att 457.908447 loss_ctc 15.036937 loss_rnnt 6.052335 lr 0.00026915 rank 0
2022-12-07 22:04:43,012 DEBUG TRAIN Batch 22/3300 loss 22.243593 loss_att 469.020508 loss_ctc 37.282608 loss_rnnt 20.572594 lr 0.00026915 rank 2
2022-12-07 22:04:43,012 DEBUG TRAIN Batch 22/3300 loss 11.754071 loss_att 411.660889 loss_ctc 20.156954 loss_rnnt 10.820417 lr 0.00026914 rank 6
2022-12-07 22:04:43,013 DEBUG TRAIN Batch 22/3300 loss 8.220848 loss_att 423.663757 loss_ctc 17.435751 loss_rnnt 7.196970 lr 0.00026915 rank 1
2022-12-07 22:04:43,015 DEBUG TRAIN Batch 22/3300 loss 9.891275 loss_att 353.750732 loss_ctc 15.346366 loss_rnnt 9.285154 lr 0.00026914 rank 5
2022-12-07 22:05:46,475 DEBUG TRAIN Batch 22/3400 loss 9.683644 loss_att 330.209137 loss_ctc 17.914093 loss_rnnt 8.769150 lr 0.00026911 rank 4
2022-12-07 22:05:46,478 DEBUG TRAIN Batch 22/3400 loss 6.281553 loss_att 371.282471 loss_ctc 12.959026 loss_rnnt 5.539611 lr 0.00026911 rank 7
2022-12-07 22:05:46,479 DEBUG TRAIN Batch 22/3400 loss 9.182480 loss_att 402.199402 loss_ctc 24.016277 loss_rnnt 7.534280 lr 0.00026911 rank 2
2022-12-07 22:05:46,480 DEBUG TRAIN Batch 22/3400 loss 4.108421 loss_att 394.048096 loss_ctc 15.658283 loss_rnnt 2.825103 lr 0.00026910 rank 6
2022-12-07 22:05:46,482 DEBUG TRAIN Batch 22/3400 loss 2.959054 loss_att 344.026733 loss_ctc 5.321940 loss_rnnt 2.696511 lr 0.00026911 rank 1
2022-12-07 22:05:46,483 DEBUG TRAIN Batch 22/3400 loss 6.845272 loss_att 336.599945 loss_ctc 18.481510 loss_rnnt 5.552356 lr 0.00026911 rank 0
2022-12-07 22:05:46,485 DEBUG TRAIN Batch 22/3400 loss 3.506078 loss_att 383.456299 loss_ctc 8.774373 loss_rnnt 2.920712 lr 0.00026912 rank 3
2022-12-07 22:05:46,487 DEBUG TRAIN Batch 22/3400 loss 9.776168 loss_att 372.339630 loss_ctc 21.285198 loss_rnnt 8.497387 lr 0.00026911 rank 5
2022-12-07 22:06:51,009 DEBUG TRAIN Batch 22/3500 loss 7.482826 loss_att 368.261414 loss_ctc 16.232704 loss_rnnt 6.510617 lr 0.00026907 rank 5
2022-12-07 22:06:51,020 DEBUG TRAIN Batch 22/3500 loss 5.629220 loss_att 348.780396 loss_ctc 13.994177 loss_rnnt 4.699780 lr 0.00026907 rank 4
2022-12-07 22:06:51,020 DEBUG TRAIN Batch 22/3500 loss 11.176008 loss_att 468.775024 loss_ctc 24.053284 loss_rnnt 9.745200 lr 0.00026908 rank 3
2022-12-07 22:06:51,020 DEBUG TRAIN Batch 22/3500 loss 8.560541 loss_att 385.905640 loss_ctc 26.649111 loss_rnnt 6.550700 lr 0.00026907 rank 7
2022-12-07 22:06:51,022 DEBUG TRAIN Batch 22/3500 loss 4.303800 loss_att 366.911163 loss_ctc 7.885306 loss_rnnt 3.905855 lr 0.00026907 rank 1
2022-12-07 22:06:51,029 DEBUG TRAIN Batch 22/3500 loss 7.962657 loss_att 286.688507 loss_ctc 16.103622 loss_rnnt 7.058105 lr 0.00026907 rank 0
2022-12-07 22:06:51,032 DEBUG TRAIN Batch 22/3500 loss 27.321087 loss_att 395.054932 loss_ctc 48.996971 loss_rnnt 24.912655 lr 0.00026907 rank 2
2022-12-07 22:06:51,062 DEBUG TRAIN Batch 22/3500 loss 13.550406 loss_att 345.115753 loss_ctc 25.043587 loss_rnnt 12.273385 lr 0.00026906 rank 6
2022-12-07 22:08:02,666 DEBUG TRAIN Batch 22/3600 loss 18.897442 loss_att 325.751068 loss_ctc 29.879959 loss_rnnt 17.677162 lr 0.00026903 rank 7
2022-12-07 22:08:02,667 DEBUG TRAIN Batch 22/3600 loss 13.404696 loss_att 326.652802 loss_ctc 23.873632 loss_rnnt 12.241482 lr 0.00026903 rank 4
2022-12-07 22:08:02,667 DEBUG TRAIN Batch 22/3600 loss 5.122137 loss_att 352.821960 loss_ctc 13.111490 loss_rnnt 4.234431 lr 0.00026904 rank 0
2022-12-07 22:08:02,674 DEBUG TRAIN Batch 22/3600 loss 7.042796 loss_att 340.544403 loss_ctc 13.538109 loss_rnnt 6.321095 lr 0.00026904 rank 1
2022-12-07 22:08:02,674 DEBUG TRAIN Batch 22/3600 loss 6.509805 loss_att 365.871552 loss_ctc 12.335592 loss_rnnt 5.862495 lr 0.00026904 rank 3
2022-12-07 22:08:02,675 DEBUG TRAIN Batch 22/3600 loss 15.599091 loss_att 342.351166 loss_ctc 24.013695 loss_rnnt 14.664135 lr 0.00026903 rank 2
2022-12-07 22:08:02,677 DEBUG TRAIN Batch 22/3600 loss 7.083374 loss_att 333.236969 loss_ctc 15.077200 loss_rnnt 6.195171 lr 0.00026903 rank 5
2022-12-07 22:08:02,679 DEBUG TRAIN Batch 22/3600 loss 16.030756 loss_att 371.445801 loss_ctc 38.399986 loss_rnnt 13.545286 lr 0.00026902 rank 6
2022-12-07 22:09:05,766 DEBUG TRAIN Batch 22/3700 loss 5.195569 loss_att 246.778000 loss_ctc 13.401318 loss_rnnt 4.283819 lr 0.00026899 rank 4
2022-12-07 22:09:05,767 DEBUG TRAIN Batch 22/3700 loss 3.419247 loss_att 337.576843 loss_ctc 10.712022 loss_rnnt 2.608938 lr 0.00026899 rank 2
2022-12-07 22:09:05,768 DEBUG TRAIN Batch 22/3700 loss 11.166095 loss_att 324.535950 loss_ctc 20.873497 loss_rnnt 10.087495 lr 0.00026899 rank 7
2022-12-07 22:09:05,772 DEBUG TRAIN Batch 22/3700 loss 4.470268 loss_att 331.890350 loss_ctc 7.016912 loss_rnnt 4.187308 lr 0.00026899 rank 6
2022-12-07 22:09:05,772 DEBUG TRAIN Batch 22/3700 loss 21.257010 loss_att 374.456665 loss_ctc 34.363632 loss_rnnt 19.800718 lr 0.00026900 rank 3
2022-12-07 22:09:05,772 DEBUG TRAIN Batch 22/3700 loss 6.797207 loss_att 388.462311 loss_ctc 9.542608 loss_rnnt 6.492163 lr 0.00026900 rank 0
2022-12-07 22:09:05,772 DEBUG TRAIN Batch 22/3700 loss 4.424726 loss_att 274.090851 loss_ctc 8.014862 loss_rnnt 4.025823 lr 0.00026899 rank 5
2022-12-07 22:09:05,777 DEBUG TRAIN Batch 22/3700 loss 9.180271 loss_att 309.243408 loss_ctc 20.171162 loss_rnnt 7.959061 lr 0.00026900 rank 1
2022-12-07 22:10:09,107 DEBUG TRAIN Batch 22/3800 loss 8.424238 loss_att 498.172607 loss_ctc 20.122694 loss_rnnt 7.124410 lr 0.00026895 rank 4
2022-12-07 22:10:09,127 DEBUG TRAIN Batch 22/3800 loss 10.374239 loss_att 186.285126 loss_ctc 20.160215 loss_rnnt 9.286908 lr 0.00026895 rank 7
2022-12-07 22:10:09,128 DEBUG TRAIN Batch 22/3800 loss 13.606121 loss_att 223.690750 loss_ctc 22.929012 loss_rnnt 12.570245 lr 0.00026895 rank 6
2022-12-07 22:10:09,129 DEBUG TRAIN Batch 22/3800 loss 8.530674 loss_att 107.677101 loss_ctc 14.527449 loss_rnnt 7.864366 lr 0.00026895 rank 2
2022-12-07 22:10:09,130 DEBUG TRAIN Batch 22/3800 loss 8.579628 loss_att 269.756317 loss_ctc 15.003906 loss_rnnt 7.865819 lr 0.00026896 rank 0
2022-12-07 22:10:09,132 DEBUG TRAIN Batch 22/3800 loss 6.730943 loss_att 100.558609 loss_ctc 10.845150 loss_rnnt 6.273808 lr 0.00026896 rank 1
2022-12-07 22:10:09,136 DEBUG TRAIN Batch 22/3800 loss 1.486451 loss_att 443.275146 loss_ctc 5.656534 loss_rnnt 1.023108 lr 0.00026895 rank 5
2022-12-07 22:10:09,174 DEBUG TRAIN Batch 22/3800 loss 10.185269 loss_att 202.033142 loss_ctc 19.523895 loss_rnnt 9.147644 lr 0.00026896 rank 3
2022-12-07 22:11:14,300 DEBUG TRAIN Batch 22/3900 loss 14.006192 loss_att 365.311768 loss_ctc 19.969852 loss_rnnt 13.343563 lr 0.00026891 rank 2
2022-12-07 22:11:14,309 DEBUG TRAIN Batch 22/3900 loss 6.263044 loss_att 388.935547 loss_ctc 7.589323 loss_rnnt 6.115680 lr 0.00026892 rank 1
2022-12-07 22:11:14,309 DEBUG TRAIN Batch 22/3900 loss 5.695651 loss_att 386.719788 loss_ctc 12.583785 loss_rnnt 4.930303 lr 0.00026891 rank 5
2022-12-07 22:11:14,311 DEBUG TRAIN Batch 22/3900 loss 2.878334 loss_att 437.691833 loss_ctc 7.780919 loss_rnnt 2.333602 lr 0.00026892 rank 3
2022-12-07 22:11:14,311 DEBUG TRAIN Batch 22/3900 loss 3.253913 loss_att 334.725037 loss_ctc 6.592152 loss_rnnt 2.882998 lr 0.00026892 rank 4
2022-12-07 22:11:14,312 DEBUG TRAIN Batch 22/3900 loss 9.674221 loss_att 453.661316 loss_ctc 26.998716 loss_rnnt 7.749277 lr 0.00026892 rank 0
2022-12-07 22:11:14,313 DEBUG TRAIN Batch 22/3900 loss 8.934962 loss_att 387.569275 loss_ctc 14.742495 loss_rnnt 8.289680 lr 0.00026891 rank 7
2022-12-07 22:11:14,355 DEBUG TRAIN Batch 22/3900 loss 5.292032 loss_att 404.935425 loss_ctc 11.708461 loss_rnnt 4.579095 lr 0.00026891 rank 6
2022-12-07 22:12:25,594 DEBUG TRAIN Batch 22/4000 loss 0.987407 loss_att 350.237488 loss_ctc 3.588359 loss_rnnt 0.698413 lr 0.00026888 rank 4
2022-12-07 22:12:25,598 DEBUG TRAIN Batch 22/4000 loss 8.615296 loss_att 338.551270 loss_ctc 17.255127 loss_rnnt 7.655315 lr 0.00026888 rank 1
2022-12-07 22:12:25,599 DEBUG TRAIN Batch 22/4000 loss 8.092215 loss_att 365.746918 loss_ctc 18.910387 loss_rnnt 6.890195 lr 0.00026888 rank 3
2022-12-07 22:12:25,599 DEBUG TRAIN Batch 22/4000 loss 7.660227 loss_att 361.207001 loss_ctc 17.263306 loss_rnnt 6.593218 lr 0.00026887 rank 2
2022-12-07 22:12:25,600 DEBUG TRAIN Batch 22/4000 loss 10.112061 loss_att 445.726166 loss_ctc 20.396435 loss_rnnt 8.969353 lr 0.00026887 rank 5
2022-12-07 22:12:25,602 DEBUG TRAIN Batch 22/4000 loss 10.303454 loss_att 328.767090 loss_ctc 18.967047 loss_rnnt 9.340834 lr 0.00026888 rank 0
2022-12-07 22:12:25,603 DEBUG TRAIN Batch 22/4000 loss 9.674932 loss_att 410.881439 loss_ctc 20.909763 loss_rnnt 8.426617 lr 0.00026887 rank 7
2022-12-07 22:12:25,606 DEBUG TRAIN Batch 22/4000 loss 5.878148 loss_att 406.349945 loss_ctc 13.756247 loss_rnnt 5.002804 lr 0.00026887 rank 6
2022-12-07 22:13:28,933 DEBUG TRAIN Batch 22/4100 loss 13.198688 loss_att 456.534973 loss_ctc 28.763313 loss_rnnt 11.469285 lr 0.00026884 rank 4
2022-12-07 22:13:28,947 DEBUG TRAIN Batch 22/4100 loss 7.184811 loss_att 399.390503 loss_ctc 14.630553 loss_rnnt 6.357506 lr 0.00026883 rank 2
2022-12-07 22:13:28,947 DEBUG TRAIN Batch 22/4100 loss 6.443638 loss_att 337.571655 loss_ctc 13.233272 loss_rnnt 5.689235 lr 0.00026883 rank 5
2022-12-07 22:13:28,950 DEBUG TRAIN Batch 22/4100 loss 10.923581 loss_att 400.892212 loss_ctc 17.053585 loss_rnnt 10.242470 lr 0.00026884 rank 0
2022-12-07 22:13:28,950 DEBUG TRAIN Batch 22/4100 loss 2.282267 loss_att 356.197968 loss_ctc 7.553817 loss_rnnt 1.696539 lr 0.00026884 rank 7
2022-12-07 22:13:28,953 DEBUG TRAIN Batch 22/4100 loss 11.369417 loss_att 412.407959 loss_ctc 23.528130 loss_rnnt 10.018450 lr 0.00026884 rank 1
2022-12-07 22:13:28,954 DEBUG TRAIN Batch 22/4100 loss 4.831782 loss_att 411.145325 loss_ctc 13.276951 loss_rnnt 3.893431 lr 0.00026884 rank 3
2022-12-07 22:13:28,995 DEBUG TRAIN Batch 22/4100 loss 17.236233 loss_att 498.655121 loss_ctc 31.611900 loss_rnnt 15.638937 lr 0.00026883 rank 6
2022-12-07 22:14:32,328 DEBUG TRAIN Batch 22/4200 loss 15.447386 loss_att 343.345062 loss_ctc 24.949812 loss_rnnt 14.391562 lr 0.00026880 rank 4
2022-12-07 22:14:32,333 DEBUG TRAIN Batch 22/4200 loss 5.011001 loss_att 342.444122 loss_ctc 10.805144 loss_rnnt 4.367208 lr 0.00026880 rank 0
2022-12-07 22:14:32,337 DEBUG TRAIN Batch 22/4200 loss 14.727839 loss_att 348.487823 loss_ctc 28.140980 loss_rnnt 13.237490 lr 0.00026879 rank 6
2022-12-07 22:14:32,338 DEBUG TRAIN Batch 22/4200 loss 9.476700 loss_att 369.927887 loss_ctc 21.381859 loss_rnnt 8.153904 lr 0.00026880 rank 2
2022-12-07 22:14:32,341 DEBUG TRAIN Batch 22/4200 loss 4.909617 loss_att 372.884277 loss_ctc 8.538975 loss_rnnt 4.506355 lr 0.00026880 rank 7
2022-12-07 22:14:32,346 DEBUG TRAIN Batch 22/4200 loss 9.927189 loss_att 379.456879 loss_ctc 19.702435 loss_rnnt 8.841050 lr 0.00026880 rank 1
2022-12-07 22:14:32,358 DEBUG TRAIN Batch 22/4200 loss 9.375847 loss_att 345.395264 loss_ctc 16.318417 loss_rnnt 8.604451 lr 0.00026880 rank 3
2022-12-07 22:14:32,363 DEBUG TRAIN Batch 22/4200 loss 16.034710 loss_att 363.181183 loss_ctc 27.156820 loss_rnnt 14.798920 lr 0.00026879 rank 5
2022-12-07 22:15:44,693 DEBUG TRAIN Batch 22/4300 loss 11.647486 loss_att 346.583618 loss_ctc 23.190197 loss_rnnt 10.364963 lr 0.00026876 rank 7
2022-12-07 22:15:44,696 DEBUG TRAIN Batch 22/4300 loss 10.266533 loss_att 296.058990 loss_ctc 20.554976 loss_rnnt 9.123373 lr 0.00026876 rank 4
2022-12-07 22:15:44,695 DEBUG TRAIN Batch 22/4300 loss 5.326178 loss_att 348.043823 loss_ctc 15.004437 loss_rnnt 4.250815 lr 0.00026876 rank 0
2022-12-07 22:15:44,697 DEBUG TRAIN Batch 22/4300 loss 8.166790 loss_att 362.993958 loss_ctc 18.183296 loss_rnnt 7.053845 lr 0.00026876 rank 5
2022-12-07 22:15:44,699 DEBUG TRAIN Batch 22/4300 loss 19.947210 loss_att 406.980286 loss_ctc 37.068680 loss_rnnt 18.044827 lr 0.00026877 rank 3
2022-12-07 22:15:44,699 DEBUG TRAIN Batch 22/4300 loss 4.433184 loss_att 320.616577 loss_ctc 8.519784 loss_rnnt 3.979118 lr 0.00026876 rank 1
2022-12-07 22:15:44,701 DEBUG TRAIN Batch 22/4300 loss 6.167315 loss_att 370.201904 loss_ctc 19.755310 loss_rnnt 4.657537 lr 0.00026875 rank 6
2022-12-07 22:15:44,704 DEBUG TRAIN Batch 22/4300 loss 2.687443 loss_att 300.190063 loss_ctc 5.602218 loss_rnnt 2.363579 lr 0.00026876 rank 2
2022-12-07 22:16:48,928 DEBUG TRAIN Batch 22/4400 loss 17.479546 loss_att 249.116028 loss_ctc 27.930717 loss_rnnt 16.318306 lr 0.00026872 rank 7
2022-12-07 22:16:48,929 DEBUG TRAIN Batch 22/4400 loss 7.105800 loss_att 160.228058 loss_ctc 14.934316 loss_rnnt 6.235965 lr 0.00026872 rank 1
2022-12-07 22:16:48,930 DEBUG TRAIN Batch 22/4400 loss 10.926892 loss_att 315.937805 loss_ctc 19.967138 loss_rnnt 9.922421 lr 0.00026873 rank 3
2022-12-07 22:16:48,932 DEBUG TRAIN Batch 22/4400 loss 6.905362 loss_att 226.271423 loss_ctc 13.545724 loss_rnnt 6.167544 lr 0.00026872 rank 5
2022-12-07 22:16:48,932 DEBUG TRAIN Batch 22/4400 loss 7.118154 loss_att 313.327301 loss_ctc 14.047829 loss_rnnt 6.348190 lr 0.00026871 rank 6
2022-12-07 22:16:48,934 DEBUG TRAIN Batch 22/4400 loss 4.821286 loss_att 99.982353 loss_ctc 9.171167 loss_rnnt 4.337966 lr 0.00026872 rank 4
2022-12-07 22:16:48,934 DEBUG TRAIN Batch 22/4400 loss 3.902442 loss_att 318.736115 loss_ctc 9.008537 loss_rnnt 3.335099 lr 0.00026872 rank 0
2022-12-07 22:16:48,975 DEBUG TRAIN Batch 22/4400 loss 5.662451 loss_att 237.949341 loss_ctc 13.392677 loss_rnnt 4.803537 lr 0.00026872 rank 2
2022-12-07 22:17:52,801 DEBUG TRAIN Batch 22/4500 loss 5.372980 loss_att 424.710205 loss_ctc 12.298595 loss_rnnt 4.603467 lr 0.00026868 rank 7
2022-12-07 22:17:52,806 DEBUG TRAIN Batch 22/4500 loss 9.161036 loss_att 388.758667 loss_ctc 21.322498 loss_rnnt 7.809762 lr 0.00026868 rank 2
2022-12-07 22:17:52,807 DEBUG TRAIN Batch 22/4500 loss 4.240098 loss_att 350.181732 loss_ctc 12.171527 loss_rnnt 3.358829 lr 0.00026869 rank 1
2022-12-07 22:17:52,807 DEBUG TRAIN Batch 22/4500 loss 7.284378 loss_att 175.255249 loss_ctc 15.238178 loss_rnnt 6.400622 lr 0.00026869 rank 3
2022-12-07 22:17:52,807 DEBUG TRAIN Batch 22/4500 loss 2.624986 loss_att 423.255371 loss_ctc 7.897136 loss_rnnt 2.039192 lr 0.00026868 rank 5
2022-12-07 22:17:52,811 DEBUG TRAIN Batch 22/4500 loss 5.048985 loss_att 363.555847 loss_ctc 13.833838 loss_rnnt 4.072891 lr 0.00026869 rank 0
2022-12-07 22:17:52,811 DEBUG TRAIN Batch 22/4500 loss 7.361243 loss_att 457.771057 loss_ctc 15.171981 loss_rnnt 6.493383 lr 0.00026868 rank 4
2022-12-07 22:17:52,849 DEBUG TRAIN Batch 22/4500 loss 18.587370 loss_att 202.987885 loss_ctc 28.858856 loss_rnnt 17.446095 lr 0.00026867 rank 6
2022-12-07 22:18:58,186 DEBUG TRAIN Batch 22/4600 loss 4.085235 loss_att 407.353485 loss_ctc 11.192589 loss_rnnt 3.295529 lr 0.00026864 rank 6
2022-12-07 22:18:58,189 DEBUG TRAIN Batch 22/4600 loss 7.475333 loss_att 486.451752 loss_ctc 20.540592 loss_rnnt 6.023638 lr 0.00026864 rank 4
2022-12-07 22:18:58,192 DEBUG TRAIN Batch 22/4600 loss 7.044672 loss_att 421.201965 loss_ctc 16.554270 loss_rnnt 5.988050 lr 0.00026865 rank 3
2022-12-07 22:18:58,197 DEBUG TRAIN Batch 22/4600 loss 4.280653 loss_att 383.684418 loss_ctc 8.911936 loss_rnnt 3.766066 lr 0.00026864 rank 7
2022-12-07 22:18:58,199 DEBUG TRAIN Batch 22/4600 loss 5.895550 loss_att 420.603271 loss_ctc 12.190001 loss_rnnt 5.196166 lr 0.00026864 rank 2
2022-12-07 22:18:58,200 DEBUG TRAIN Batch 22/4600 loss 9.487097 loss_att 422.655090 loss_ctc 17.325638 loss_rnnt 8.616148 lr 0.00026865 rank 0
2022-12-07 22:18:58,201 DEBUG TRAIN Batch 22/4600 loss 4.137935 loss_att 438.520264 loss_ctc 13.420303 loss_rnnt 3.106561 lr 0.00026865 rank 1
2022-12-07 22:18:58,233 DEBUG TRAIN Batch 22/4600 loss 3.549397 loss_att 357.643768 loss_ctc 8.670798 loss_rnnt 2.980352 lr 0.00026864 rank 5
2022-12-07 22:20:09,473 DEBUG TRAIN Batch 22/4700 loss 9.059998 loss_att 419.455322 loss_ctc 23.136507 loss_rnnt 7.495941 lr 0.00026861 rank 1
2022-12-07 22:20:09,474 DEBUG TRAIN Batch 22/4700 loss 7.022202 loss_att 398.125946 loss_ctc 21.114838 loss_rnnt 5.456353 lr 0.00026860 rank 2
2022-12-07 22:20:09,475 DEBUG TRAIN Batch 22/4700 loss 9.022965 loss_att 350.738831 loss_ctc 24.224932 loss_rnnt 7.333858 lr 0.00026860 rank 5
2022-12-07 22:20:09,478 DEBUG TRAIN Batch 22/4700 loss 5.397498 loss_att 403.646484 loss_ctc 11.485826 loss_rnnt 4.721017 lr 0.00026860 rank 4
2022-12-07 22:20:09,478 DEBUG TRAIN Batch 22/4700 loss 4.987797 loss_att 387.033386 loss_ctc 10.819193 loss_rnnt 4.339864 lr 0.00026861 rank 0
2022-12-07 22:20:09,478 DEBUG TRAIN Batch 22/4700 loss 7.314578 loss_att 381.606537 loss_ctc 14.984947 loss_rnnt 6.462315 lr 0.00026860 rank 6
2022-12-07 22:20:09,479 DEBUG TRAIN Batch 22/4700 loss 8.952044 loss_att 408.394104 loss_ctc 12.212870 loss_rnnt 8.589731 lr 0.00026860 rank 7
2022-12-07 22:20:09,481 DEBUG TRAIN Batch 22/4700 loss 12.874595 loss_att 357.674408 loss_ctc 18.605642 loss_rnnt 12.237812 lr 0.00026861 rank 3
2022-12-07 22:21:12,198 DEBUG TRAIN Batch 22/4800 loss 9.732660 loss_att 353.479248 loss_ctc 17.567146 loss_rnnt 8.862162 lr 0.00026857 rank 0
2022-12-07 22:21:12,200 DEBUG TRAIN Batch 22/4800 loss 18.116302 loss_att 416.430420 loss_ctc 36.548084 loss_rnnt 16.068327 lr 0.00026856 rank 2
2022-12-07 22:21:12,205 DEBUG TRAIN Batch 22/4800 loss 8.269815 loss_att 304.436279 loss_ctc 18.179485 loss_rnnt 7.168741 lr 0.00026857 rank 4
2022-12-07 22:21:12,206 DEBUG TRAIN Batch 22/4800 loss 10.296147 loss_att 361.871796 loss_ctc 18.283417 loss_rnnt 9.408673 lr 0.00026857 rank 1
2022-12-07 22:21:12,209 DEBUG TRAIN Batch 22/4800 loss 4.779274 loss_att 352.805023 loss_ctc 14.338792 loss_rnnt 3.717105 lr 0.00026856 rank 6
2022-12-07 22:21:12,210 DEBUG TRAIN Batch 22/4800 loss 7.682447 loss_att 343.817932 loss_ctc 13.758825 loss_rnnt 7.007294 lr 0.00026856 rank 5
2022-12-07 22:21:12,210 DEBUG TRAIN Batch 22/4800 loss 6.266799 loss_att 365.699493 loss_ctc 12.203677 loss_rnnt 5.607146 lr 0.00026857 rank 3
2022-12-07 22:21:12,210 DEBUG TRAIN Batch 22/4800 loss 7.877884 loss_att 383.479279 loss_ctc 17.254515 loss_rnnt 6.836036 lr 0.00026856 rank 7
2022-12-07 22:22:15,030 DEBUG TRAIN Batch 22/4900 loss 7.038679 loss_att 373.736267 loss_ctc 11.412542 loss_rnnt 6.552694 lr 0.00026853 rank 0
2022-12-07 22:22:15,040 DEBUG TRAIN Batch 22/4900 loss 7.042096 loss_att 332.996979 loss_ctc 15.266362 loss_rnnt 6.128289 lr 0.00026853 rank 7
2022-12-07 22:22:15,040 DEBUG TRAIN Batch 22/4900 loss 11.112600 loss_att 325.831512 loss_ctc 23.957733 loss_rnnt 9.685364 lr 0.00026853 rank 4
2022-12-07 22:22:15,041 DEBUG TRAIN Batch 22/4900 loss 8.753429 loss_att 368.075745 loss_ctc 15.967991 loss_rnnt 7.951811 lr 0.00026853 rank 3
2022-12-07 22:22:15,042 DEBUG TRAIN Batch 22/4900 loss 9.104131 loss_att 325.416809 loss_ctc 18.006165 loss_rnnt 8.115016 lr 0.00026852 rank 6
2022-12-07 22:22:15,068 DEBUG TRAIN Batch 22/4900 loss 6.482282 loss_att 343.410156 loss_ctc 12.287994 loss_rnnt 5.837203 lr 0.00026853 rank 1
2022-12-07 22:22:15,070 DEBUG TRAIN Batch 22/4900 loss 10.244905 loss_att 376.851959 loss_ctc 18.164349 loss_rnnt 9.364967 lr 0.00026852 rank 5
2022-12-07 22:22:15,088 DEBUG TRAIN Batch 22/4900 loss 6.837386 loss_att 403.413300 loss_ctc 15.077038 loss_rnnt 5.921869 lr 0.00026852 rank 2
2022-12-07 22:23:27,527 DEBUG TRAIN Batch 22/5000 loss 13.267725 loss_att 251.533905 loss_ctc 22.203957 loss_rnnt 12.274810 lr 0.00026849 rank 7
2022-12-07 22:23:27,530 DEBUG TRAIN Batch 22/5000 loss 10.807899 loss_att 276.473572 loss_ctc 21.894407 loss_rnnt 9.576064 lr 0.00026849 rank 4
2022-12-07 22:23:27,531 DEBUG TRAIN Batch 22/5000 loss 5.971639 loss_att 336.081238 loss_ctc 14.176386 loss_rnnt 5.060000 lr 0.00026848 rank 6
2022-12-07 22:23:27,533 DEBUG TRAIN Batch 22/5000 loss 11.294561 loss_att 325.114777 loss_ctc 25.644547 loss_rnnt 9.700118 lr 0.00026849 rank 2
2022-12-07 22:23:27,536 DEBUG TRAIN Batch 22/5000 loss 11.822027 loss_att 303.520233 loss_ctc 19.737188 loss_rnnt 10.942565 lr 0.00026849 rank 1
2022-12-07 22:23:27,537 DEBUG TRAIN Batch 22/5000 loss 5.641000 loss_att 325.273438 loss_ctc 14.540538 loss_rnnt 4.652163 lr 0.00026849 rank 0
2022-12-07 22:23:27,539 DEBUG TRAIN Batch 22/5000 loss 7.350031 loss_att 265.019989 loss_ctc 14.306348 loss_rnnt 6.577107 lr 0.00026848 rank 5
2022-12-07 22:23:27,572 DEBUG TRAIN Batch 22/5000 loss 9.555009 loss_att 305.773743 loss_ctc 25.620220 loss_rnnt 7.769986 lr 0.00026849 rank 3
2022-12-07 22:24:31,485 DEBUG TRAIN Batch 22/5100 loss 3.440973 loss_att 406.014740 loss_ctc 8.184299 loss_rnnt 2.913937 lr 0.00026845 rank 4
2022-12-07 22:24:31,486 DEBUG TRAIN Batch 22/5100 loss 4.253439 loss_att 410.160248 loss_ctc 13.393593 loss_rnnt 3.237866 lr 0.00026845 rank 7
2022-12-07 22:24:31,486 DEBUG TRAIN Batch 22/5100 loss 10.836915 loss_att 170.622086 loss_ctc 16.531786 loss_rnnt 10.204152 lr 0.00026844 rank 6
2022-12-07 22:24:31,487 DEBUG TRAIN Batch 22/5100 loss 9.044036 loss_att 125.942307 loss_ctc 15.206782 loss_rnnt 8.359286 lr 0.00026845 rank 2
2022-12-07 22:24:31,487 DEBUG TRAIN Batch 22/5100 loss 13.836127 loss_att 173.979584 loss_ctc 24.309116 loss_rnnt 12.672462 lr 0.00026846 rank 3
2022-12-07 22:24:31,489 DEBUG TRAIN Batch 22/5100 loss 5.601434 loss_att 419.679626 loss_ctc 12.714071 loss_rnnt 4.811141 lr 0.00026845 rank 1
2022-12-07 22:24:31,492 DEBUG TRAIN Batch 22/5100 loss 8.398724 loss_att 423.298340 loss_ctc 18.025444 loss_rnnt 7.329088 lr 0.00026845 rank 5
2022-12-07 22:24:31,492 DEBUG TRAIN Batch 22/5100 loss 12.285015 loss_att 144.010483 loss_ctc 17.243620 loss_rnnt 11.734059 lr 0.00026845 rank 0
2022-12-07 22:25:34,469 DEBUG TRAIN Batch 22/5200 loss 4.935151 loss_att 366.562103 loss_ctc 11.941450 loss_rnnt 4.156673 lr 0.00026841 rank 1
2022-12-07 22:25:34,470 DEBUG TRAIN Batch 22/5200 loss 9.946511 loss_att 388.684906 loss_ctc 19.151569 loss_rnnt 8.923727 lr 0.00026841 rank 7
2022-12-07 22:25:34,472 DEBUG TRAIN Batch 22/5200 loss 5.880942 loss_att 366.843964 loss_ctc 12.751534 loss_rnnt 5.117544 lr 0.00026841 rank 0
2022-12-07 22:25:34,473 DEBUG TRAIN Batch 22/5200 loss 6.326142 loss_att 398.939087 loss_ctc 17.267006 loss_rnnt 5.110490 lr 0.00026841 rank 2
2022-12-07 22:25:34,473 DEBUG TRAIN Batch 22/5200 loss 13.147717 loss_att 441.190979 loss_ctc 33.414024 loss_rnnt 10.895905 lr 0.00026841 rank 4
2022-12-07 22:25:34,474 DEBUG TRAIN Batch 22/5200 loss 7.954546 loss_att 405.691650 loss_ctc 18.244621 loss_rnnt 6.811204 lr 0.00026841 rank 5
2022-12-07 22:25:34,476 DEBUG TRAIN Batch 22/5200 loss 3.413045 loss_att 412.393250 loss_ctc 7.435390 loss_rnnt 2.966119 lr 0.00026842 rank 3
2022-12-07 22:25:34,476 DEBUG TRAIN Batch 22/5200 loss 5.927611 loss_att 370.868164 loss_ctc 11.529051 loss_rnnt 5.305229 lr 0.00026840 rank 6
2022-12-07 22:26:38,792 DEBUG TRAIN Batch 22/5300 loss 7.260509 loss_att 336.814575 loss_ctc 13.880222 loss_rnnt 6.524986 lr 0.00026838 rank 1
2022-12-07 22:26:38,792 DEBUG TRAIN Batch 22/5300 loss 5.621529 loss_att 375.897156 loss_ctc 11.703382 loss_rnnt 4.945767 lr 0.00026838 rank 3
2022-12-07 22:26:38,793 DEBUG TRAIN Batch 22/5300 loss 10.690063 loss_att 444.983368 loss_ctc 26.294813 loss_rnnt 8.956203 lr 0.00026836 rank 6
2022-12-07 22:26:38,796 DEBUG TRAIN Batch 22/5300 loss 5.566802 loss_att 437.243835 loss_ctc 12.757151 loss_rnnt 4.767874 lr 0.00026837 rank 7
2022-12-07 22:26:38,799 DEBUG TRAIN Batch 22/5300 loss 15.208284 loss_att 358.646667 loss_ctc 19.381552 loss_rnnt 14.744589 lr 0.00026837 rank 5
2022-12-07 22:26:38,815 DEBUG TRAIN Batch 22/5300 loss 2.133928 loss_att 337.908997 loss_ctc 6.706811 loss_rnnt 1.625830 lr 0.00026837 rank 2
2022-12-07 22:26:38,826 DEBUG TRAIN Batch 22/5300 loss 4.798802 loss_att 422.820770 loss_ctc 12.363384 loss_rnnt 3.958293 lr 0.00026838 rank 0
2022-12-07 22:26:38,834 DEBUG TRAIN Batch 22/5300 loss 4.486673 loss_att 347.420227 loss_ctc 8.623777 loss_rnnt 4.026995 lr 0.00026837 rank 4
2022-12-07 22:27:49,725 DEBUG TRAIN Batch 22/5400 loss 3.415581 loss_att 349.763275 loss_ctc 14.193254 loss_rnnt 2.218061 lr 0.00026833 rank 4
2022-12-07 22:27:49,725 DEBUG TRAIN Batch 22/5400 loss 8.753754 loss_att 368.459076 loss_ctc 18.969975 loss_rnnt 7.618619 lr 0.00026833 rank 7
2022-12-07 22:27:49,728 DEBUG TRAIN Batch 22/5400 loss 12.488770 loss_att 393.229004 loss_ctc 30.347700 loss_rnnt 10.504444 lr 0.00026834 rank 1
2022-12-07 22:27:49,730 DEBUG TRAIN Batch 22/5400 loss 8.202180 loss_att 405.568298 loss_ctc 13.951260 loss_rnnt 7.563394 lr 0.00026833 rank 5
2022-12-07 22:27:49,731 DEBUG TRAIN Batch 22/5400 loss 6.475515 loss_att 365.691376 loss_ctc 16.104507 loss_rnnt 5.405627 lr 0.00026834 rank 0
2022-12-07 22:27:49,732 DEBUG TRAIN Batch 22/5400 loss 5.890250 loss_att 445.588593 loss_ctc 12.087504 loss_rnnt 5.201667 lr 0.00026834 rank 3
2022-12-07 22:27:49,751 DEBUG TRAIN Batch 22/5400 loss 12.034981 loss_att 429.113068 loss_ctc 23.456039 loss_rnnt 10.765974 lr 0.00026833 rank 2
2022-12-07 22:27:49,757 DEBUG TRAIN Batch 22/5400 loss 9.671507 loss_att 379.621094 loss_ctc 22.253494 loss_rnnt 8.273508 lr 0.00026833 rank 6
2022-12-07 22:28:52,427 DEBUG TRAIN Batch 22/5500 loss 6.733344 loss_att 339.070312 loss_ctc 10.173889 loss_rnnt 6.351061 lr 0.00026830 rank 0
2022-12-07 22:28:52,428 DEBUG TRAIN Batch 22/5500 loss 12.970537 loss_att 366.085815 loss_ctc 16.860870 loss_rnnt 12.538279 lr 0.00026829 rank 7
2022-12-07 22:28:52,431 DEBUG TRAIN Batch 22/5500 loss 8.939743 loss_att 300.276215 loss_ctc 18.038551 loss_rnnt 7.928765 lr 0.00026829 rank 5
2022-12-07 22:28:52,432 DEBUG TRAIN Batch 22/5500 loss 2.427892 loss_att 277.895386 loss_ctc 7.504516 loss_rnnt 1.863823 lr 0.00026829 rank 6
2022-12-07 22:28:52,433 DEBUG TRAIN Batch 22/5500 loss 20.893801 loss_att 458.966248 loss_ctc 38.293171 loss_rnnt 18.960537 lr 0.00026830 rank 3
2022-12-07 22:28:52,433 DEBUG TRAIN Batch 22/5500 loss 8.625230 loss_att 370.196045 loss_ctc 19.926798 loss_rnnt 7.369500 lr 0.00026829 rank 2
2022-12-07 22:28:52,434 DEBUG TRAIN Batch 22/5500 loss 8.749640 loss_att 355.297791 loss_ctc 18.215794 loss_rnnt 7.697845 lr 0.00026830 rank 4
2022-12-07 22:28:52,476 DEBUG TRAIN Batch 22/5500 loss 11.964711 loss_att 367.155029 loss_ctc 30.567616 loss_rnnt 9.897722 lr 0.00026830 rank 1
2022-12-07 22:29:56,482 DEBUG TRAIN Batch 22/5600 loss 5.624868 loss_att 263.427704 loss_ctc 12.718226 loss_rnnt 4.836717 lr 0.00026825 rank 7
2022-12-07 22:29:56,484 DEBUG TRAIN Batch 22/5600 loss 8.109397 loss_att 322.974701 loss_ctc 20.097769 loss_rnnt 6.777356 lr 0.00026826 rank 4
2022-12-07 22:29:56,486 DEBUG TRAIN Batch 22/5600 loss 7.872690 loss_att 319.556091 loss_ctc 17.926548 loss_rnnt 6.755594 lr 0.00026826 rank 3
2022-12-07 22:29:56,488 DEBUG TRAIN Batch 22/5600 loss 11.798205 loss_att 380.671783 loss_ctc 24.505825 loss_rnnt 10.386248 lr 0.00026825 rank 6
2022-12-07 22:29:56,490 DEBUG TRAIN Batch 22/5600 loss 8.064482 loss_att 294.094025 loss_ctc 17.154356 loss_rnnt 7.054495 lr 0.00026826 rank 1
2022-12-07 22:29:56,490 DEBUG TRAIN Batch 22/5600 loss 8.613771 loss_att 317.398895 loss_ctc 15.374862 loss_rnnt 7.862539 lr 0.00026826 rank 0
2022-12-07 22:29:56,491 DEBUG TRAIN Batch 22/5600 loss 6.682753 loss_att 304.561737 loss_ctc 17.959270 loss_rnnt 5.429807 lr 0.00026825 rank 2
2022-12-07 22:29:56,495 DEBUG TRAIN Batch 22/5600 loss 7.107094 loss_att 323.869476 loss_ctc 13.785663 loss_rnnt 6.365031 lr 0.00026825 rank 5
2022-12-07 22:31:09,428 DEBUG TRAIN Batch 22/5700 loss 11.342214 loss_att 123.632858 loss_ctc 19.371895 loss_rnnt 10.450027 lr 0.00026822 rank 0
2022-12-07 22:31:09,430 DEBUG TRAIN Batch 22/5700 loss 5.447801 loss_att 439.967865 loss_ctc 12.418074 loss_rnnt 4.673326 lr 0.00026822 rank 4
2022-12-07 22:31:09,432 DEBUG TRAIN Batch 22/5700 loss 10.472419 loss_att 200.101685 loss_ctc 16.395115 loss_rnnt 9.814342 lr 0.00026821 rank 6
2022-12-07 22:31:09,433 DEBUG TRAIN Batch 22/5700 loss 4.819142 loss_att 402.255554 loss_ctc 13.537176 loss_rnnt 3.850471 lr 0.00026822 rank 7
2022-12-07 22:31:09,434 DEBUG TRAIN Batch 22/5700 loss 12.634289 loss_att 223.128036 loss_ctc 19.363026 loss_rnnt 11.886652 lr 0.00026822 rank 2
2022-12-07 22:31:09,438 DEBUG TRAIN Batch 22/5700 loss 10.485327 loss_att 180.817856 loss_ctc 15.528507 loss_rnnt 9.924973 lr 0.00026821 rank 5
2022-12-07 22:31:09,462 DEBUG TRAIN Batch 22/5700 loss 6.032188 loss_att 81.688843 loss_ctc 11.446262 loss_rnnt 5.430625 lr 0.00026822 rank 1
2022-12-07 22:31:09,477 DEBUG TRAIN Batch 22/5700 loss 3.339654 loss_att 298.725739 loss_ctc 9.221268 loss_rnnt 2.686142 lr 0.00026822 rank 3
2022-12-07 22:32:12,569 DEBUG TRAIN Batch 22/5800 loss 2.247088 loss_att 406.400208 loss_ctc 10.291228 loss_rnnt 1.353295 lr 0.00026818 rank 4
2022-12-07 22:32:12,570 DEBUG TRAIN Batch 22/5800 loss 10.105927 loss_att 418.204559 loss_ctc 24.418158 loss_rnnt 8.515678 lr 0.00026818 rank 2
2022-12-07 22:32:12,570 DEBUG TRAIN Batch 22/5800 loss 5.566441 loss_att 396.011597 loss_ctc 15.617262 loss_rnnt 4.449683 lr 0.00026818 rank 7
2022-12-07 22:32:12,570 DEBUG TRAIN Batch 22/5800 loss 5.161302 loss_att 367.444824 loss_ctc 11.356604 loss_rnnt 4.472935 lr 0.00026818 rank 1
2022-12-07 22:32:12,572 DEBUG TRAIN Batch 22/5800 loss 6.038479 loss_att 405.662689 loss_ctc 14.513260 loss_rnnt 5.096837 lr 0.00026817 rank 6
2022-12-07 22:32:12,572 DEBUG TRAIN Batch 22/5800 loss 6.624748 loss_att 441.049133 loss_ctc 16.088385 loss_rnnt 5.573233 lr 0.00026818 rank 3
2022-12-07 22:32:12,579 DEBUG TRAIN Batch 22/5800 loss 8.403623 loss_att 427.701477 loss_ctc 17.284611 loss_rnnt 7.416846 lr 0.00026818 rank 0
2022-12-07 22:32:12,580 DEBUG TRAIN Batch 22/5800 loss 7.652679 loss_att 364.851501 loss_ctc 16.188406 loss_rnnt 6.704266 lr 0.00026817 rank 5
2022-12-07 22:33:15,310 DEBUG TRAIN Batch 22/5900 loss 6.700208 loss_att 302.175842 loss_ctc 14.850238 loss_rnnt 5.794649 lr 0.00026814 rank 2
2022-12-07 22:33:15,310 DEBUG TRAIN Batch 22/5900 loss 4.013619 loss_att 352.774231 loss_ctc 11.132093 loss_rnnt 3.222678 lr 0.00026814 rank 4
2022-12-07 22:33:15,312 DEBUG TRAIN Batch 22/5900 loss 7.925724 loss_att 381.220459 loss_ctc 14.913786 loss_rnnt 7.149273 lr 0.00026814 rank 0
2022-12-07 22:33:15,313 DEBUG TRAIN Batch 22/5900 loss 5.860470 loss_att 395.140930 loss_ctc 13.188716 loss_rnnt 5.046221 lr 0.00026814 rank 1
2022-12-07 22:33:15,313 DEBUG TRAIN Batch 22/5900 loss 10.586118 loss_att 384.880920 loss_ctc 16.641285 loss_rnnt 9.913321 lr 0.00026815 rank 3
2022-12-07 22:33:15,315 DEBUG TRAIN Batch 22/5900 loss 7.154873 loss_att 431.586517 loss_ctc 20.817989 loss_rnnt 5.636749 lr 0.00026814 rank 5
2022-12-07 22:33:15,324 DEBUG TRAIN Batch 22/5900 loss 10.310701 loss_att 410.749481 loss_ctc 11.332614 loss_rnnt 10.197156 lr 0.00026813 rank 6
2022-12-07 22:33:15,332 DEBUG TRAIN Batch 22/5900 loss 12.256808 loss_att 369.224182 loss_ctc 22.338589 loss_rnnt 11.136611 lr 0.00026814 rank 7
2022-12-07 22:34:20,278 DEBUG TRAIN Batch 22/6000 loss 7.147836 loss_att 359.301025 loss_ctc 9.869908 loss_rnnt 6.845384 lr 0.00026809 rank 6
2022-12-07 22:34:20,277 DEBUG TRAIN Batch 22/6000 loss 4.243477 loss_att 329.994141 loss_ctc 10.179382 loss_rnnt 3.583932 lr 0.00026810 rank 7
2022-12-07 22:34:20,279 DEBUG TRAIN Batch 22/6000 loss 1.462251 loss_att 321.553894 loss_ctc 6.389845 loss_rnnt 0.914741 lr 0.00026811 rank 3
2022-12-07 22:34:20,280 DEBUG TRAIN Batch 22/6000 loss 10.328854 loss_att 398.541138 loss_ctc 21.300293 loss_rnnt 9.109804 lr 0.00026810 rank 5
2022-12-07 22:34:20,284 DEBUG TRAIN Batch 22/6000 loss 15.509668 loss_att 393.464050 loss_ctc 30.808327 loss_rnnt 13.809818 lr 0.00026810 rank 4
2022-12-07 22:34:20,288 DEBUG TRAIN Batch 22/6000 loss 11.708342 loss_att 408.063171 loss_ctc 23.525957 loss_rnnt 10.395273 lr 0.00026811 rank 0
2022-12-07 22:34:20,312 DEBUG TRAIN Batch 22/6000 loss 6.577286 loss_att 391.323761 loss_ctc 13.866279 loss_rnnt 5.767398 lr 0.00026811 rank 1
2022-12-07 22:34:20,318 DEBUG TRAIN Batch 22/6000 loss 3.759413 loss_att 382.010590 loss_ctc 10.910097 loss_rnnt 2.964892 lr 0.00026810 rank 2
2022-12-07 22:35:32,254 DEBUG TRAIN Batch 22/6100 loss 13.854662 loss_att 409.797424 loss_ctc 25.332680 loss_rnnt 12.579327 lr 0.00026807 rank 3
2022-12-07 22:35:32,254 DEBUG TRAIN Batch 22/6100 loss 6.329689 loss_att 374.570038 loss_ctc 13.589790 loss_rnnt 5.523011 lr 0.00026806 rank 7
2022-12-07 22:35:32,255 DEBUG TRAIN Batch 22/6100 loss 6.778380 loss_att 339.166412 loss_ctc 15.225939 loss_rnnt 5.839762 lr 0.00026806 rank 4
2022-12-07 22:35:32,256 DEBUG TRAIN Batch 22/6100 loss 13.563923 loss_att 428.781586 loss_ctc 28.360071 loss_rnnt 11.919907 lr 0.00026807 rank 1
2022-12-07 22:35:32,261 DEBUG TRAIN Batch 22/6100 loss 2.463201 loss_att 353.833252 loss_ctc 7.978125 loss_rnnt 1.850432 lr 0.00026806 rank 6
2022-12-07 22:35:32,262 DEBUG TRAIN Batch 22/6100 loss 13.415524 loss_att 369.591003 loss_ctc 27.577034 loss_rnnt 11.842022 lr 0.00026806 rank 5
2022-12-07 22:35:32,263 DEBUG TRAIN Batch 22/6100 loss 16.223551 loss_att 332.768433 loss_ctc 20.806938 loss_rnnt 15.714287 lr 0.00026807 rank 0
2022-12-07 22:35:32,268 DEBUG TRAIN Batch 22/6100 loss 5.245394 loss_att 352.975372 loss_ctc 11.020882 loss_rnnt 4.603673 lr 0.00026806 rank 2
2022-12-07 22:36:36,326 DEBUG TRAIN Batch 22/6200 loss 12.199554 loss_att 322.293182 loss_ctc 24.461462 loss_rnnt 10.837121 lr 0.00026803 rank 4
2022-12-07 22:36:36,330 DEBUG TRAIN Batch 22/6200 loss 9.613741 loss_att 329.788635 loss_ctc 18.918201 loss_rnnt 8.579912 lr 0.00026802 rank 6
2022-12-07 22:36:36,331 DEBUG TRAIN Batch 22/6200 loss 7.879044 loss_att 374.588867 loss_ctc 11.773824 loss_rnnt 7.446290 lr 0.00026802 rank 5
2022-12-07 22:36:36,333 DEBUG TRAIN Batch 22/6200 loss 3.330101 loss_att 336.805573 loss_ctc 7.229647 loss_rnnt 2.896819 lr 0.00026802 rank 2
2022-12-07 22:36:36,333 DEBUG TRAIN Batch 22/6200 loss 4.628489 loss_att 270.544678 loss_ctc 8.283763 loss_rnnt 4.222347 lr 0.00026802 rank 7
2022-12-07 22:36:36,334 DEBUG TRAIN Batch 22/6200 loss 7.097335 loss_att 344.632935 loss_ctc 10.558281 loss_rnnt 6.712785 lr 0.00026803 rank 3
2022-12-07 22:36:36,336 DEBUG TRAIN Batch 22/6200 loss 9.522876 loss_att 340.339294 loss_ctc 24.460491 loss_rnnt 7.863141 lr 0.00026803 rank 0
2022-12-07 22:36:36,377 DEBUG TRAIN Batch 22/6200 loss 4.742462 loss_att 288.883331 loss_ctc 6.132513 loss_rnnt 4.588012 lr 0.00026803 rank 1
2022-12-07 22:37:40,303 DEBUG TRAIN Batch 22/6300 loss 12.794866 loss_att 77.492424 loss_ctc 18.350502 loss_rnnt 12.177572 lr 0.00026799 rank 7
2022-12-07 22:37:40,305 DEBUG TRAIN Batch 22/6300 loss 7.121165 loss_att 67.518402 loss_ctc 11.460572 loss_rnnt 6.639009 lr 0.00026799 rank 4
2022-12-07 22:37:40,305 DEBUG TRAIN Batch 22/6300 loss 7.384184 loss_att 264.026611 loss_ctc 10.787218 loss_rnnt 7.006069 lr 0.00026799 rank 1
2022-12-07 22:37:40,306 DEBUG TRAIN Batch 22/6300 loss 7.693479 loss_att 339.081787 loss_ctc 14.443693 loss_rnnt 6.943456 lr 0.00026799 rank 3
2022-12-07 22:37:40,308 DEBUG TRAIN Batch 22/6300 loss 14.240317 loss_att 320.118866 loss_ctc 21.919109 loss_rnnt 13.387118 lr 0.00026798 rank 2
2022-12-07 22:37:40,309 DEBUG TRAIN Batch 22/6300 loss 12.123560 loss_att 328.485443 loss_ctc 23.942923 loss_rnnt 10.810297 lr 0.00026798 rank 6
2022-12-07 22:37:40,310 DEBUG TRAIN Batch 22/6300 loss 8.852298 loss_att 266.152618 loss_ctc 18.849562 loss_rnnt 7.741491 lr 0.00026798 rank 5
2022-12-07 22:37:40,312 DEBUG TRAIN Batch 22/6300 loss 9.039768 loss_att 314.227783 loss_ctc 17.772655 loss_rnnt 8.069448 lr 0.00026799 rank 0
2022-12-07 22:38:51,623 DEBUG TRAIN Batch 22/6400 loss 6.316475 loss_att 414.266815 loss_ctc 11.018925 loss_rnnt 5.793981 lr 0.00026795 rank 7
2022-12-07 22:38:51,624 DEBUG TRAIN Batch 22/6400 loss 8.114397 loss_att 339.868988 loss_ctc 20.108446 loss_rnnt 6.781724 lr 0.00026794 rank 5
2022-12-07 22:38:51,624 DEBUG TRAIN Batch 22/6400 loss 7.347348 loss_att 72.275513 loss_ctc 10.581594 loss_rnnt 6.987987 lr 0.00026795 rank 3
2022-12-07 22:38:51,624 DEBUG TRAIN Batch 22/6400 loss 6.860320 loss_att 393.610168 loss_ctc 15.344005 loss_rnnt 5.917688 lr 0.00026795 rank 1
2022-12-07 22:38:51,626 DEBUG TRAIN Batch 22/6400 loss 2.130986 loss_att 342.533142 loss_ctc 4.708937 loss_rnnt 1.844547 lr 0.00026795 rank 4
2022-12-07 22:38:51,628 DEBUG TRAIN Batch 22/6400 loss 4.419461 loss_att 68.476181 loss_ctc 7.407908 loss_rnnt 4.087412 lr 0.00026794 rank 6
2022-12-07 22:38:51,638 DEBUG TRAIN Batch 22/6400 loss 7.499021 loss_att 375.614929 loss_ctc 11.355488 loss_rnnt 7.070524 lr 0.00026795 rank 0
2022-12-07 22:38:51,642 DEBUG TRAIN Batch 22/6400 loss 6.302884 loss_att 149.922989 loss_ctc 11.678159 loss_rnnt 5.705631 lr 0.00026795 rank 2
2022-12-07 22:39:56,567 DEBUG TRAIN Batch 22/6500 loss 5.891807 loss_att 353.807343 loss_ctc 9.841202 loss_rnnt 5.452985 lr 0.00026791 rank 7
2022-12-07 22:39:56,571 DEBUG TRAIN Batch 22/6500 loss 13.117298 loss_att 352.447845 loss_ctc 27.615446 loss_rnnt 11.506393 lr 0.00026791 rank 4
2022-12-07 22:39:56,572 DEBUG TRAIN Batch 22/6500 loss 1.967608 loss_att 330.473083 loss_ctc 4.962339 loss_rnnt 1.634861 lr 0.00026790 rank 5
2022-12-07 22:39:56,572 DEBUG TRAIN Batch 22/6500 loss 8.048795 loss_att 435.823425 loss_ctc 15.598048 loss_rnnt 7.209989 lr 0.00026791 rank 3
2022-12-07 22:39:56,574 DEBUG TRAIN Batch 22/6500 loss 9.909283 loss_att 387.710205 loss_ctc 21.986088 loss_rnnt 8.567415 lr 0.00026791 rank 2
2022-12-07 22:39:56,575 DEBUG TRAIN Batch 22/6500 loss 5.285684 loss_att 384.967285 loss_ctc 10.072097 loss_rnnt 4.753860 lr 0.00026791 rank 1
2022-12-07 22:39:56,577 DEBUG TRAIN Batch 22/6500 loss 8.681234 loss_att 407.413422 loss_ctc 24.644751 loss_rnnt 6.907510 lr 0.00026790 rank 6
2022-12-07 22:39:56,578 DEBUG TRAIN Batch 22/6500 loss 8.619814 loss_att 401.127441 loss_ctc 16.834324 loss_rnnt 7.707090 lr 0.00026791 rank 0
2022-12-07 22:40:59,893 DEBUG TRAIN Batch 22/6600 loss 12.395927 loss_att 419.597290 loss_ctc 31.010273 loss_rnnt 10.327667 lr 0.00026787 rank 4
2022-12-07 22:40:59,895 DEBUG TRAIN Batch 22/6600 loss 12.075296 loss_att 327.482269 loss_ctc 23.662643 loss_rnnt 10.787813 lr 0.00026787 rank 7
2022-12-07 22:40:59,896 DEBUG TRAIN Batch 22/6600 loss 22.678900 loss_att 464.293671 loss_ctc 36.974079 loss_rnnt 21.090546 lr 0.00026787 rank 2
2022-12-07 22:40:59,897 DEBUG TRAIN Batch 22/6600 loss 7.861314 loss_att 429.660278 loss_ctc 13.353794 loss_rnnt 7.251039 lr 0.00026787 rank 0
2022-12-07 22:40:59,897 DEBUG TRAIN Batch 22/6600 loss 11.607351 loss_att 434.892517 loss_ctc 19.940968 loss_rnnt 10.681395 lr 0.00026786 rank 6
2022-12-07 22:40:59,899 DEBUG TRAIN Batch 22/6600 loss 7.997704 loss_att 415.746765 loss_ctc 14.941126 loss_rnnt 7.226213 lr 0.00026788 rank 3
2022-12-07 22:40:59,900 DEBUG TRAIN Batch 22/6600 loss 5.575206 loss_att 426.385010 loss_ctc 10.760978 loss_rnnt 4.999009 lr 0.00026787 rank 5
2022-12-07 22:40:59,903 DEBUG TRAIN Batch 22/6600 loss 3.072765 loss_att 304.837860 loss_ctc 9.053648 loss_rnnt 2.408222 lr 0.00026787 rank 1
2022-12-07 22:42:03,958 DEBUG TRAIN Batch 22/6700 loss 1.738624 loss_att 304.399414 loss_ctc 5.676518 loss_rnnt 1.301080 lr 0.00026783 rank 4
2022-12-07 22:42:03,961 DEBUG TRAIN Batch 22/6700 loss 8.702674 loss_att 352.134277 loss_ctc 15.193489 loss_rnnt 7.981472 lr 0.00026784 rank 0
2022-12-07 22:42:03,962 DEBUG TRAIN Batch 22/6700 loss 6.512348 loss_att 379.601624 loss_ctc 13.992271 loss_rnnt 5.681245 lr 0.00026783 rank 6
2022-12-07 22:42:03,963 DEBUG TRAIN Batch 22/6700 loss 3.309020 loss_att 358.036011 loss_ctc 11.042547 loss_rnnt 2.449739 lr 0.00026784 rank 3
2022-12-07 22:42:03,964 DEBUG TRAIN Batch 22/6700 loss 9.102978 loss_att 364.191315 loss_ctc 13.624310 loss_rnnt 8.600608 lr 0.00026783 rank 2
2022-12-07 22:42:03,965 DEBUG TRAIN Batch 22/6700 loss 4.572450 loss_att 383.777466 loss_ctc 7.008927 loss_rnnt 4.301730 lr 0.00026784 rank 1
2022-12-07 22:42:03,970 DEBUG TRAIN Batch 22/6700 loss 9.384482 loss_att 388.335266 loss_ctc 14.322951 loss_rnnt 8.835764 lr 0.00026783 rank 7
2022-12-07 22:42:03,991 DEBUG TRAIN Batch 22/6700 loss 6.173814 loss_att 360.029327 loss_ctc 9.571922 loss_rnnt 5.796246 lr 0.00026783 rank 5
2022-12-07 22:43:15,622 DEBUG TRAIN Batch 22/6800 loss 2.876183 loss_att 334.879547 loss_ctc 10.632455 loss_rnnt 2.014374 lr 0.00026779 rank 4
2022-12-07 22:43:15,623 DEBUG TRAIN Batch 22/6800 loss 15.089138 loss_att 409.565704 loss_ctc 28.836788 loss_rnnt 13.561621 lr 0.00026780 rank 3
2022-12-07 22:43:15,625 DEBUG TRAIN Batch 22/6800 loss 14.849927 loss_att 366.260406 loss_ctc 32.665100 loss_rnnt 12.870463 lr 0.00026779 rank 6
2022-12-07 22:43:15,626 DEBUG TRAIN Batch 22/6800 loss 2.903749 loss_att 357.367065 loss_ctc 10.970339 loss_rnnt 2.007461 lr 0.00026779 rank 5
2022-12-07 22:43:15,627 DEBUG TRAIN Batch 22/6800 loss 7.376338 loss_att 332.735413 loss_ctc 16.329292 loss_rnnt 6.381565 lr 0.00026779 rank 7
2022-12-07 22:43:15,628 DEBUG TRAIN Batch 22/6800 loss 14.062412 loss_att 437.374146 loss_ctc 28.713053 loss_rnnt 12.434564 lr 0.00026779 rank 2
2022-12-07 22:43:15,631 DEBUG TRAIN Batch 22/6800 loss 3.043376 loss_att 334.179443 loss_ctc 9.664357 loss_rnnt 2.307711 lr 0.00026780 rank 0
2022-12-07 22:43:15,635 DEBUG TRAIN Batch 22/6800 loss 8.843292 loss_att 310.057068 loss_ctc 14.274106 loss_rnnt 8.239868 lr 0.00026780 rank 1
2022-12-07 22:44:18,619 DEBUG TRAIN Batch 22/6900 loss 8.371309 loss_att 179.229752 loss_ctc 15.335675 loss_rnnt 7.597491 lr 0.00026776 rank 4
2022-12-07 22:44:18,624 DEBUG TRAIN Batch 22/6900 loss 7.244686 loss_att 354.017456 loss_ctc 15.881859 loss_rnnt 6.285000 lr 0.00026775 rank 2
2022-12-07 22:44:18,624 DEBUG TRAIN Batch 22/6900 loss 5.127800 loss_att 310.991455 loss_ctc 11.036566 loss_rnnt 4.471271 lr 0.00026776 rank 1
2022-12-07 22:44:18,624 DEBUG TRAIN Batch 22/6900 loss 5.451235 loss_att 215.789169 loss_ctc 10.333464 loss_rnnt 4.908765 lr 0.00026775 rank 7
2022-12-07 22:44:18,626 DEBUG TRAIN Batch 22/6900 loss 6.949585 loss_att 245.934738 loss_ctc 12.778181 loss_rnnt 6.301964 lr 0.00026775 rank 5
2022-12-07 22:44:18,627 DEBUG TRAIN Batch 22/6900 loss 13.090253 loss_att 307.386932 loss_ctc 24.890692 loss_rnnt 11.779094 lr 0.00026776 rank 0
2022-12-07 22:44:18,627 DEBUG TRAIN Batch 22/6900 loss 18.038733 loss_att 391.974731 loss_ctc 29.271204 loss_rnnt 16.790680 lr 0.00026776 rank 3
2022-12-07 22:44:18,631 DEBUG TRAIN Batch 22/6900 loss 11.503900 loss_att 299.675385 loss_ctc 19.027901 loss_rnnt 10.667900 lr 0.00026775 rank 6
2022-12-07 22:45:21,758 DEBUG TRAIN Batch 22/7000 loss 10.563360 loss_att 377.017700 loss_ctc 21.299086 loss_rnnt 9.370502 lr 0.00026772 rank 4
2022-12-07 22:45:21,769 DEBUG TRAIN Batch 22/7000 loss 6.659858 loss_att 433.110077 loss_ctc 16.634445 loss_rnnt 5.551571 lr 0.00026772 rank 7
2022-12-07 22:45:21,774 DEBUG TRAIN Batch 22/7000 loss 6.759379 loss_att 420.860229 loss_ctc 12.347490 loss_rnnt 6.138479 lr 0.00026772 rank 0
2022-12-07 22:45:21,774 DEBUG TRAIN Batch 22/7000 loss 6.864252 loss_att 149.332520 loss_ctc 13.216825 loss_rnnt 6.158411 lr 0.00026772 rank 1
2022-12-07 22:45:21,777 DEBUG TRAIN Batch 22/7000 loss 13.997233 loss_att 191.657379 loss_ctc 27.609272 loss_rnnt 12.484785 lr 0.00026771 rank 6
2022-12-07 22:45:21,777 DEBUG TRAIN Batch 22/7000 loss 10.599673 loss_att 229.592453 loss_ctc 17.341511 loss_rnnt 9.850580 lr 0.00026771 rank 2
2022-12-07 22:45:21,778 DEBUG TRAIN Batch 22/7000 loss 1.331165 loss_att 362.529724 loss_ctc 2.886493 loss_rnnt 1.158351 lr 0.00026771 rank 5
2022-12-07 22:45:21,783 DEBUG TRAIN Batch 22/7000 loss 6.823473 loss_att 142.811447 loss_ctc 13.284403 loss_rnnt 6.105593 lr 0.00026772 rank 3
2022-12-07 22:46:26,594 DEBUG TRAIN Batch 22/7100 loss 15.660618 loss_att 464.158630 loss_ctc 30.711454 loss_rnnt 13.988302 lr 0.00026768 rank 3
2022-12-07 22:46:26,595 DEBUG TRAIN Batch 22/7100 loss 8.939443 loss_att 412.002197 loss_ctc 17.285734 loss_rnnt 8.012077 lr 0.00026767 rank 6
2022-12-07 22:46:26,605 DEBUG TRAIN Batch 22/7100 loss 8.572454 loss_att 390.220062 loss_ctc 21.523941 loss_rnnt 7.133401 lr 0.00026768 rank 4
2022-12-07 22:46:26,609 DEBUG TRAIN Batch 22/7100 loss 3.812467 loss_att 441.584320 loss_ctc 8.905345 loss_rnnt 3.246592 lr 0.00026768 rank 7
2022-12-07 22:46:26,611 DEBUG TRAIN Batch 22/7100 loss 4.993211 loss_att 398.814667 loss_ctc 7.701610 loss_rnnt 4.692278 lr 0.00026768 rank 1
2022-12-07 22:46:26,616 DEBUG TRAIN Batch 22/7100 loss 3.792590 loss_att 327.103363 loss_ctc 8.274508 loss_rnnt 3.294599 lr 0.00026768 rank 0
2022-12-07 22:46:26,633 DEBUG TRAIN Batch 22/7100 loss 3.592213 loss_att 442.259003 loss_ctc 14.753840 loss_rnnt 2.352032 lr 0.00026768 rank 2
2022-12-07 22:46:26,642 DEBUG TRAIN Batch 22/7100 loss 1.842915 loss_att 338.727081 loss_ctc 5.279949 loss_rnnt 1.461022 lr 0.00026767 rank 5
2022-12-07 22:47:39,122 DEBUG TRAIN Batch 22/7200 loss 3.731065 loss_att 367.636292 loss_ctc 6.181512 loss_rnnt 3.458794 lr 0.00026764 rank 4
2022-12-07 22:47:39,125 DEBUG TRAIN Batch 22/7200 loss 2.495440 loss_att 368.011353 loss_ctc 9.408359 loss_rnnt 1.727338 lr 0.00026764 rank 2
2022-12-07 22:47:39,128 DEBUG TRAIN Batch 22/7200 loss 10.608385 loss_att 368.079498 loss_ctc 17.565723 loss_rnnt 9.835347 lr 0.00026764 rank 7
2022-12-07 22:47:39,129 DEBUG TRAIN Batch 22/7200 loss 21.176702 loss_att 435.518311 loss_ctc 30.812027 loss_rnnt 20.106110 lr 0.00026765 rank 3
2022-12-07 22:47:39,129 DEBUG TRAIN Batch 22/7200 loss 3.783644 loss_att 300.912964 loss_ctc 4.863274 loss_rnnt 3.663685 lr 0.00026764 rank 5
2022-12-07 22:47:39,129 DEBUG TRAIN Batch 22/7200 loss 5.283926 loss_att 371.159180 loss_ctc 9.727669 loss_rnnt 4.790177 lr 0.00026764 rank 0
2022-12-07 22:47:39,130 DEBUG TRAIN Batch 22/7200 loss 9.531423 loss_att 397.031830 loss_ctc 16.392780 loss_rnnt 8.769050 lr 0.00026763 rank 6
2022-12-07 22:47:39,133 DEBUG TRAIN Batch 22/7200 loss 5.595042 loss_att 381.728088 loss_ctc 8.717644 loss_rnnt 5.248087 lr 0.00026764 rank 1
2022-12-07 22:48:42,352 DEBUG TRAIN Batch 22/7300 loss 7.909427 loss_att 391.674866 loss_ctc 15.709450 loss_rnnt 7.042758 lr 0.00026760 rank 7
2022-12-07 22:48:42,356 DEBUG TRAIN Batch 22/7300 loss 8.740061 loss_att 352.292694 loss_ctc 20.736809 loss_rnnt 7.407089 lr 0.00026760 rank 4
2022-12-07 22:48:42,357 DEBUG TRAIN Batch 22/7300 loss 4.974606 loss_att 366.440948 loss_ctc 9.606172 loss_rnnt 4.459988 lr 0.00026759 rank 6
2022-12-07 22:48:42,357 DEBUG TRAIN Batch 22/7300 loss 7.948822 loss_att 357.494751 loss_ctc 16.563047 loss_rnnt 6.991685 lr 0.00026761 rank 1
2022-12-07 22:48:42,358 DEBUG TRAIN Batch 22/7300 loss 6.855853 loss_att 384.735046 loss_ctc 14.357698 loss_rnnt 6.022314 lr 0.00026761 rank 0
2022-12-07 22:48:42,357 DEBUG TRAIN Batch 22/7300 loss 6.399801 loss_att 394.895721 loss_ctc 13.438213 loss_rnnt 5.617755 lr 0.00026760 rank 2
2022-12-07 22:48:42,363 DEBUG TRAIN Batch 22/7300 loss 4.427534 loss_att 446.940277 loss_ctc 13.398282 loss_rnnt 3.430785 lr 0.00026760 rank 5
2022-12-07 22:48:42,365 DEBUG TRAIN Batch 22/7300 loss 8.159474 loss_att 359.842560 loss_ctc 15.431656 loss_rnnt 7.351455 lr 0.00026761 rank 3
2022-12-07 22:49:46,354 DEBUG TRAIN Batch 22/7400 loss 5.086959 loss_att 296.807739 loss_ctc 10.988882 loss_rnnt 4.431190 lr 0.00026756 rank 5
2022-12-07 22:49:46,358 DEBUG TRAIN Batch 22/7400 loss 2.781735 loss_att 321.233673 loss_ctc 5.615756 loss_rnnt 2.466844 lr 0.00026756 rank 7
2022-12-07 22:49:46,358 DEBUG TRAIN Batch 22/7400 loss 9.863614 loss_att 360.962036 loss_ctc 15.454952 loss_rnnt 9.242354 lr 0.00026757 rank 3
2022-12-07 22:49:46,358 DEBUG TRAIN Batch 22/7400 loss 15.939490 loss_att 379.034943 loss_ctc 28.233202 loss_rnnt 14.573523 lr 0.00026756 rank 6
2022-12-07 22:49:46,362 DEBUG TRAIN Batch 22/7400 loss 6.921970 loss_att 388.363220 loss_ctc 18.837290 loss_rnnt 5.598046 lr 0.00026756 rank 2
2022-12-07 22:49:46,363 DEBUG TRAIN Batch 22/7400 loss 4.635554 loss_att 337.117493 loss_ctc 12.991966 loss_rnnt 3.707064 lr 0.00026757 rank 0
2022-12-07 22:49:46,365 DEBUG TRAIN Batch 22/7400 loss 5.253367 loss_att 349.780640 loss_ctc 16.299984 loss_rnnt 4.025966 lr 0.00026756 rank 4
2022-12-07 22:49:46,365 DEBUG TRAIN Batch 22/7400 loss 10.285448 loss_att 373.985870 loss_ctc 16.305227 loss_rnnt 9.616584 lr 0.00026757 rank 1
2022-12-07 22:50:57,629 DEBUG TRAIN Batch 22/7500 loss 13.026396 loss_att 308.008972 loss_ctc 29.068808 loss_rnnt 11.243905 lr 0.00026753 rank 4
2022-12-07 22:50:57,640 DEBUG TRAIN Batch 22/7500 loss 14.046576 loss_att 376.482544 loss_ctc 24.882599 loss_rnnt 12.842573 lr 0.00026752 rank 6
2022-12-07 22:50:57,641 DEBUG TRAIN Batch 22/7500 loss 8.686136 loss_att 374.450531 loss_ctc 16.941219 loss_rnnt 7.768905 lr 0.00026753 rank 3
2022-12-07 22:50:57,642 DEBUG TRAIN Batch 22/7500 loss 7.833875 loss_att 238.731750 loss_ctc 14.868530 loss_rnnt 7.052247 lr 0.00026752 rank 7
2022-12-07 22:50:57,642 DEBUG TRAIN Batch 22/7500 loss 6.082310 loss_att 350.578613 loss_ctc 18.651957 loss_rnnt 4.685683 lr 0.00026752 rank 2
2022-12-07 22:50:57,642 DEBUG TRAIN Batch 22/7500 loss 5.929163 loss_att 331.517487 loss_ctc 13.403968 loss_rnnt 5.098629 lr 0.00026753 rank 1
2022-12-07 22:50:57,646 DEBUG TRAIN Batch 22/7500 loss 6.600770 loss_att 330.802734 loss_ctc 20.174921 loss_rnnt 5.092531 lr 0.00026753 rank 0
2022-12-07 22:50:57,648 DEBUG TRAIN Batch 22/7500 loss 4.559882 loss_att 310.199646 loss_ctc 7.840477 loss_rnnt 4.195371 lr 0.00026752 rank 5
2022-12-07 22:52:01,450 DEBUG TRAIN Batch 22/7600 loss 8.698940 loss_att 172.815552 loss_ctc 17.604488 loss_rnnt 7.709435 lr 0.00026749 rank 4
2022-12-07 22:52:01,452 DEBUG TRAIN Batch 22/7600 loss 9.548159 loss_att 221.493896 loss_ctc 14.702393 loss_rnnt 8.975466 lr 0.00026748 rank 6
2022-12-07 22:52:01,455 DEBUG TRAIN Batch 22/7600 loss 8.011580 loss_att 378.965179 loss_ctc 16.618088 loss_rnnt 7.055301 lr 0.00026749 rank 7
2022-12-07 22:52:01,455 DEBUG TRAIN Batch 22/7600 loss 10.604853 loss_att 317.861084 loss_ctc 17.677223 loss_rnnt 9.819035 lr 0.00026748 rank 2
2022-12-07 22:52:01,455 DEBUG TRAIN Batch 22/7600 loss 11.295733 loss_att 268.820404 loss_ctc 18.524530 loss_rnnt 10.492534 lr 0.00026749 rank 3
2022-12-07 22:52:01,459 DEBUG TRAIN Batch 22/7600 loss 6.735208 loss_att 100.739403 loss_ctc 8.633273 loss_rnnt 6.524312 lr 0.00026748 rank 5
2022-12-07 22:52:01,461 DEBUG TRAIN Batch 22/7600 loss 8.492580 loss_att 248.241760 loss_ctc 18.252983 loss_rnnt 7.408092 lr 0.00026749 rank 0
2022-12-07 22:52:01,499 DEBUG TRAIN Batch 22/7600 loss 6.140384 loss_att 278.607666 loss_ctc 10.032084 loss_rnnt 5.707973 lr 0.00026749 rank 1
2022-12-07 22:53:05,374 DEBUG TRAIN Batch 22/7700 loss 11.930787 loss_att 380.296570 loss_ctc 16.174654 loss_rnnt 11.459247 lr 0.00026745 rank 7
2022-12-07 22:53:05,374 DEBUG TRAIN Batch 22/7700 loss 6.380125 loss_att 421.538910 loss_ctc 15.425821 loss_rnnt 5.375047 lr 0.00026745 rank 1
2022-12-07 22:53:05,378 DEBUG TRAIN Batch 22/7700 loss 7.999949 loss_att 355.349426 loss_ctc 14.073890 loss_rnnt 7.325067 lr 0.00026744 rank 6
2022-12-07 22:53:05,377 DEBUG TRAIN Batch 22/7700 loss 5.967802 loss_att 406.724060 loss_ctc 10.529724 loss_rnnt 5.460921 lr 0.00026745 rank 0
2022-12-07 22:53:05,378 DEBUG TRAIN Batch 22/7700 loss 6.935009 loss_att 155.018066 loss_ctc 13.441713 loss_rnnt 6.212041 lr 0.00026745 rank 2
2022-12-07 22:53:05,380 DEBUG TRAIN Batch 22/7700 loss 9.379852 loss_att 368.807373 loss_ctc 15.047450 loss_rnnt 8.750120 lr 0.00026745 rank 4
2022-12-07 22:53:05,391 DEBUG TRAIN Batch 22/7700 loss 1.279179 loss_att 407.344360 loss_ctc 4.768666 loss_rnnt 0.891458 lr 0.00026745 rank 3
2022-12-07 22:53:05,422 DEBUG TRAIN Batch 22/7700 loss 3.848883 loss_att 354.217041 loss_ctc 7.700687 loss_rnnt 3.420905 lr 0.00026744 rank 5
2022-12-07 22:54:10,600 DEBUG TRAIN Batch 22/7800 loss 7.222940 loss_att 414.891846 loss_ctc 14.100921 loss_rnnt 6.458721 lr 0.00026740 rank 6
2022-12-07 22:54:10,602 DEBUG TRAIN Batch 22/7800 loss 12.089523 loss_att 402.378052 loss_ctc 24.698654 loss_rnnt 10.688509 lr 0.00026742 rank 3
2022-12-07 22:54:10,611 DEBUG TRAIN Batch 22/7800 loss 10.517318 loss_att 356.950989 loss_ctc 21.930006 loss_rnnt 9.249242 lr 0.00026741 rank 7
2022-12-07 22:54:10,615 DEBUG TRAIN Batch 22/7800 loss 10.364178 loss_att 380.630951 loss_ctc 20.056967 loss_rnnt 9.287202 lr 0.00026741 rank 5
2022-12-07 22:54:10,618 DEBUG TRAIN Batch 22/7800 loss 10.362293 loss_att 412.756195 loss_ctc 15.289168 loss_rnnt 9.814863 lr 0.00026741 rank 0
2022-12-07 22:54:10,618 DEBUG TRAIN Batch 22/7800 loss 15.516699 loss_att 412.736145 loss_ctc 35.627712 loss_rnnt 13.282142 lr 0.00026741 rank 1
2022-12-07 22:54:10,628 DEBUG TRAIN Batch 22/7800 loss 5.628288 loss_att 370.552734 loss_ctc 9.678004 loss_rnnt 5.178319 lr 0.00026741 rank 4
2022-12-07 22:54:10,652 DEBUG TRAIN Batch 22/7800 loss 5.417347 loss_att 441.857849 loss_ctc 12.626272 loss_rnnt 4.616356 lr 0.00026741 rank 2
2022-12-07 22:55:22,502 DEBUG TRAIN Batch 22/7900 loss 4.167969 loss_att 357.235992 loss_ctc 10.730419 loss_rnnt 3.438807 lr 0.00026737 rank 4
2022-12-07 22:55:22,504 DEBUG TRAIN Batch 22/7900 loss 4.230840 loss_att 379.174530 loss_ctc 12.163757 loss_rnnt 3.349405 lr 0.00026737 rank 7
2022-12-07 22:55:22,505 DEBUG TRAIN Batch 22/7900 loss 6.565955 loss_att 392.592407 loss_ctc 15.415604 loss_rnnt 5.582661 lr 0.00026737 rank 6
2022-12-07 22:55:22,508 DEBUG TRAIN Batch 22/7900 loss 5.913190 loss_att 416.513306 loss_ctc 15.211153 loss_rnnt 4.880083 lr 0.00026738 rank 3
2022-12-07 22:55:22,509 DEBUG TRAIN Batch 22/7900 loss 7.606261 loss_att 390.829437 loss_ctc 17.663773 loss_rnnt 6.488760 lr 0.00026737 rank 2
2022-12-07 22:55:22,511 DEBUG TRAIN Batch 22/7900 loss 6.878752 loss_att 384.784241 loss_ctc 14.114700 loss_rnnt 6.074758 lr 0.00026737 rank 5
2022-12-07 22:55:22,511 DEBUG TRAIN Batch 22/7900 loss 9.222680 loss_att 408.583710 loss_ctc 19.873367 loss_rnnt 8.039270 lr 0.00026738 rank 0
2022-12-07 22:55:22,511 DEBUG TRAIN Batch 22/7900 loss 5.504454 loss_att 332.808136 loss_ctc 15.524931 loss_rnnt 4.391068 lr 0.00026738 rank 1
2022-12-07 22:56:25,765 DEBUG TRAIN Batch 22/8000 loss 5.585162 loss_att 376.173615 loss_ctc 12.551159 loss_rnnt 4.811162 lr 0.00026733 rank 4
2022-12-07 22:56:25,766 DEBUG TRAIN Batch 22/8000 loss 9.779857 loss_att 429.249329 loss_ctc 24.315617 loss_rnnt 8.164772 lr 0.00026734 rank 3
2022-12-07 22:56:25,770 DEBUG TRAIN Batch 22/8000 loss 5.917973 loss_att 364.706116 loss_ctc 12.319782 loss_rnnt 5.206660 lr 0.00026733 rank 2
2022-12-07 22:56:25,772 DEBUG TRAIN Batch 22/8000 loss 8.808480 loss_att 374.035400 loss_ctc 15.020599 loss_rnnt 8.118245 lr 0.00026734 rank 0
2022-12-07 22:56:25,775 DEBUG TRAIN Batch 22/8000 loss 5.958205 loss_att 413.732056 loss_ctc 15.604980 loss_rnnt 4.886341 lr 0.00026733 rank 6
2022-12-07 22:56:25,775 DEBUG TRAIN Batch 22/8000 loss 9.251789 loss_att 376.982788 loss_ctc 15.784285 loss_rnnt 8.525956 lr 0.00026733 rank 7
2022-12-07 22:56:25,778 DEBUG TRAIN Batch 22/8000 loss 11.249037 loss_att 428.791992 loss_ctc 26.689171 loss_rnnt 9.533467 lr 0.00026734 rank 1
2022-12-07 22:56:25,779 DEBUG TRAIN Batch 22/8000 loss 8.451499 loss_att 418.429291 loss_ctc 19.078228 loss_rnnt 7.270751 lr 0.00026733 rank 5
2022-12-07 22:57:30,332 DEBUG TRAIN Batch 22/8100 loss 5.511668 loss_att 351.135376 loss_ctc 12.126131 loss_rnnt 4.776728 lr 0.00026729 rank 6
2022-12-07 22:57:30,332 DEBUG TRAIN Batch 22/8100 loss 5.451442 loss_att 359.189026 loss_ctc 11.381836 loss_rnnt 4.792509 lr 0.00026730 rank 3
2022-12-07 22:57:30,333 DEBUG TRAIN Batch 22/8100 loss 6.920366 loss_att 308.165588 loss_ctc 11.263038 loss_rnnt 6.437848 lr 0.00026730 rank 4
2022-12-07 22:57:30,335 DEBUG TRAIN Batch 22/8100 loss 18.083279 loss_att 363.770569 loss_ctc 26.660875 loss_rnnt 17.130213 lr 0.00026729 rank 2
2022-12-07 22:57:30,335 DEBUG TRAIN Batch 22/8100 loss 6.226966 loss_att 322.738586 loss_ctc 13.942065 loss_rnnt 5.369733 lr 0.00026730 rank 1
2022-12-07 22:57:30,336 DEBUG TRAIN Batch 22/8100 loss 4.205073 loss_att 305.951813 loss_ctc 11.972353 loss_rnnt 3.342042 lr 0.00026729 rank 7
2022-12-07 22:57:30,337 DEBUG TRAIN Batch 22/8100 loss 12.247223 loss_att 336.050415 loss_ctc 22.485895 loss_rnnt 11.109593 lr 0.00026730 rank 0
2022-12-07 22:57:30,339 DEBUG TRAIN Batch 22/8100 loss 4.827135 loss_att 336.992004 loss_ctc 9.695494 loss_rnnt 4.286206 lr 0.00026729 rank 5
2022-12-07 22:58:34,892 DEBUG TRAIN Batch 22/8200 loss 14.142152 loss_att 319.707092 loss_ctc 25.472494 loss_rnnt 12.883224 lr 0.00026726 rank 4
2022-12-07 22:58:34,894 DEBUG TRAIN Batch 22/8200 loss 7.488667 loss_att 285.038666 loss_ctc 15.043523 loss_rnnt 6.649240 lr 0.00026726 rank 0
2022-12-07 22:58:34,898 DEBUG TRAIN Batch 22/8200 loss 7.317659 loss_att 321.079437 loss_ctc 13.260177 loss_rnnt 6.657379 lr 0.00026726 rank 3
2022-12-07 22:58:34,898 DEBUG TRAIN Batch 22/8200 loss 7.701305 loss_att 315.398621 loss_ctc 13.592775 loss_rnnt 7.046698 lr 0.00026725 rank 6
2022-12-07 22:58:34,898 DEBUG TRAIN Batch 22/8200 loss 6.361017 loss_att 135.569016 loss_ctc 10.188314 loss_rnnt 5.935762 lr 0.00026726 rank 7
2022-12-07 22:58:34,901 DEBUG TRAIN Batch 22/8200 loss 10.580812 loss_att 313.374481 loss_ctc 20.995903 loss_rnnt 9.423579 lr 0.00026726 rank 1
2022-12-07 22:58:34,902 DEBUG TRAIN Batch 22/8200 loss 9.023991 loss_att 223.658325 loss_ctc 18.031937 loss_rnnt 8.023108 lr 0.00026725 rank 5
2022-12-07 22:58:34,940 DEBUG TRAIN Batch 22/8200 loss 5.002849 loss_att 341.721619 loss_ctc 11.468462 loss_rnnt 4.284448 lr 0.00026726 rank 2
2022-12-07 22:59:37,562 DEBUG TRAIN Batch 22/8300 loss 5.466236 loss_att 366.713623 loss_ctc 9.079494 loss_rnnt 5.064763 lr 0.00026722 rank 7
2022-12-07 22:59:37,576 DEBUG TRAIN Batch 22/8300 loss 8.844470 loss_att 313.326324 loss_ctc 19.977249 loss_rnnt 7.607495 lr 0.00026723 rank 3
2022-12-07 22:59:37,576 DEBUG TRAIN Batch 22/8300 loss 8.831968 loss_att 378.739502 loss_ctc 14.789893 loss_rnnt 8.169977 lr 0.00026722 rank 4
2022-12-07 22:59:37,577 DEBUG TRAIN Batch 22/8300 loss 13.860984 loss_att 413.628601 loss_ctc 35.912163 loss_rnnt 11.410853 lr 0.00026722 rank 0
2022-12-07 22:59:37,577 DEBUG TRAIN Batch 22/8300 loss 8.206628 loss_att 310.167633 loss_ctc 15.436934 loss_rnnt 7.403261 lr 0.00026721 rank 6
2022-12-07 22:59:37,578 DEBUG TRAIN Batch 22/8300 loss 8.092045 loss_att 384.339844 loss_ctc 14.369112 loss_rnnt 7.394593 lr 0.00026722 rank 2
2022-12-07 22:59:37,578 DEBUG TRAIN Batch 22/8300 loss 11.793648 loss_att 206.707596 loss_ctc 18.818327 loss_rnnt 11.013127 lr 0.00026722 rank 1
2022-12-07 22:59:37,619 DEBUG TRAIN Batch 22/8300 loss 6.158169 loss_att 434.438965 loss_ctc 20.671278 loss_rnnt 4.545601 lr 0.00026722 rank 5
2022-12-07 23:00:16,029 DEBUG CV Batch 22/0 loss 1.216694 loss_att 48.087021 loss_ctc 2.595648 loss_rnnt 1.063478 history loss 1.171632 rank 5
2022-12-07 23:00:16,030 DEBUG CV Batch 22/0 loss 1.216694 loss_att 48.087021 loss_ctc 2.595648 loss_rnnt 1.063478 history loss 1.171632 rank 1
2022-12-07 23:00:16,030 DEBUG CV Batch 22/0 loss 1.216694 loss_att 48.087021 loss_ctc 2.595648 loss_rnnt 1.063478 history loss 1.171632 rank 2
2022-12-07 23:00:16,033 DEBUG CV Batch 22/0 loss 1.216694 loss_att 48.087021 loss_ctc 2.595648 loss_rnnt 1.063478 history loss 1.171632 rank 6
2022-12-07 23:00:16,039 DEBUG CV Batch 22/0 loss 1.216694 loss_att 48.087021 loss_ctc 2.595648 loss_rnnt 1.063478 history loss 1.171632 rank 0
2022-12-07 23:00:16,047 DEBUG CV Batch 22/0 loss 1.216694 loss_att 48.087021 loss_ctc 2.595648 loss_rnnt 1.063478 history loss 1.171632 rank 7
2022-12-07 23:00:16,051 DEBUG CV Batch 22/0 loss 1.216694 loss_att 48.087021 loss_ctc 2.595648 loss_rnnt 1.063478 history loss 1.171632 rank 4
2022-12-07 23:00:16,054 DEBUG CV Batch 22/0 loss 1.216694 loss_att 48.087021 loss_ctc 2.595648 loss_rnnt 1.063478 history loss 1.171632 rank 3
2022-12-07 23:00:26,735 DEBUG CV Batch 22/100 loss 4.433777 loss_att 266.943237 loss_ctc 12.430095 loss_rnnt 3.545298 history loss 2.935529 rank 3
2022-12-07 23:00:26,758 DEBUG CV Batch 22/100 loss 4.433777 loss_att 266.943237 loss_ctc 12.430095 loss_rnnt 3.545298 history loss 2.935529 rank 5
2022-12-07 23:00:26,789 DEBUG CV Batch 22/100 loss 4.433777 loss_att 266.943237 loss_ctc 12.430095 loss_rnnt 3.545298 history loss 2.935529 rank 6
2022-12-07 23:00:26,831 DEBUG CV Batch 22/100 loss 4.433777 loss_att 266.943237 loss_ctc 12.430095 loss_rnnt 3.545298 history loss 2.935529 rank 4
2022-12-07 23:00:26,909 DEBUG CV Batch 22/100 loss 4.433777 loss_att 266.943237 loss_ctc 12.430095 loss_rnnt 3.545298 history loss 2.935529 rank 0
2022-12-07 23:00:27,113 DEBUG CV Batch 22/100 loss 4.433777 loss_att 266.943237 loss_ctc 12.430095 loss_rnnt 3.545298 history loss 2.935529 rank 7
2022-12-07 23:00:27,123 DEBUG CV Batch 22/100 loss 4.433777 loss_att 266.943237 loss_ctc 12.430095 loss_rnnt 3.545298 history loss 2.935529 rank 2
2022-12-07 23:00:27,342 DEBUG CV Batch 22/100 loss 4.433777 loss_att 266.943237 loss_ctc 12.430095 loss_rnnt 3.545298 history loss 2.935529 rank 1
2022-12-07 23:00:39,966 DEBUG CV Batch 22/200 loss 6.742981 loss_att 641.176514 loss_ctc 8.229909 loss_rnnt 6.577767 history loss 3.499417 rank 4
2022-12-07 23:00:40,104 DEBUG CV Batch 22/200 loss 6.742981 loss_att 641.176514 loss_ctc 8.229909 loss_rnnt 6.577767 history loss 3.499417 rank 3
2022-12-07 23:00:40,149 DEBUG CV Batch 22/200 loss 6.742981 loss_att 641.176514 loss_ctc 8.229909 loss_rnnt 6.577767 history loss 3.499417 rank 5
2022-12-07 23:00:40,226 DEBUG CV Batch 22/200 loss 6.742981 loss_att 641.176514 loss_ctc 8.229909 loss_rnnt 6.577767 history loss 3.499417 rank 0
2022-12-07 23:00:40,579 DEBUG CV Batch 22/200 loss 6.742981 loss_att 641.176514 loss_ctc 8.229909 loss_rnnt 6.577767 history loss 3.499417 rank 6
2022-12-07 23:00:40,800 DEBUG CV Batch 22/200 loss 6.742981 loss_att 641.176514 loss_ctc 8.229909 loss_rnnt 6.577767 history loss 3.499417 rank 2
2022-12-07 23:00:41,004 DEBUG CV Batch 22/200 loss 6.742981 loss_att 641.176514 loss_ctc 8.229909 loss_rnnt 6.577767 history loss 3.499417 rank 1
2022-12-07 23:00:41,012 DEBUG CV Batch 22/200 loss 6.742981 loss_att 641.176514 loss_ctc 8.229909 loss_rnnt 6.577767 history loss 3.499417 rank 7
2022-12-07 23:00:51,407 DEBUG CV Batch 22/300 loss 3.244131 loss_att 190.886459 loss_ctc 8.061840 loss_rnnt 2.708830 history loss 3.615757 rank 4
2022-12-07 23:00:51,452 DEBUG CV Batch 22/300 loss 3.244131 loss_att 190.886459 loss_ctc 8.061840 loss_rnnt 2.708830 history loss 3.615757 rank 5
2022-12-07 23:00:51,552 DEBUG CV Batch 22/300 loss 3.244131 loss_att 190.886459 loss_ctc 8.061840 loss_rnnt 2.708830 history loss 3.615757 rank 3
2022-12-07 23:00:51,833 DEBUG CV Batch 22/300 loss 3.244131 loss_att 190.886459 loss_ctc 8.061840 loss_rnnt 2.708830 history loss 3.615757 rank 6
2022-12-07 23:00:51,983 DEBUG CV Batch 22/300 loss 3.244131 loss_att 190.886459 loss_ctc 8.061840 loss_rnnt 2.708830 history loss 3.615757 rank 0
2022-12-07 23:00:52,204 DEBUG CV Batch 22/300 loss 3.244131 loss_att 190.886459 loss_ctc 8.061840 loss_rnnt 2.708830 history loss 3.615757 rank 2
2022-12-07 23:00:52,285 DEBUG CV Batch 22/300 loss 3.244131 loss_att 190.886459 loss_ctc 8.061840 loss_rnnt 2.708830 history loss 3.615757 rank 1
2022-12-07 23:00:52,675 DEBUG CV Batch 22/300 loss 3.244131 loss_att 190.886459 loss_ctc 8.061840 loss_rnnt 2.708830 history loss 3.615757 rank 7
2022-12-07 23:01:02,745 DEBUG CV Batch 22/400 loss 4.902333 loss_att 826.186279 loss_ctc 9.440391 loss_rnnt 4.398105 history loss 4.488136 rank 5
2022-12-07 23:01:02,841 DEBUG CV Batch 22/400 loss 4.902333 loss_att 826.186279 loss_ctc 9.440391 loss_rnnt 4.398105 history loss 4.488136 rank 4
2022-12-07 23:01:03,018 DEBUG CV Batch 22/400 loss 4.902333 loss_att 826.186279 loss_ctc 9.440391 loss_rnnt 4.398105 history loss 4.488136 rank 3
2022-12-07 23:01:03,288 DEBUG CV Batch 22/400 loss 4.902333 loss_att 826.186279 loss_ctc 9.440391 loss_rnnt 4.398105 history loss 4.488136 rank 6
2022-12-07 23:01:03,468 DEBUG CV Batch 22/400 loss 4.902333 loss_att 826.186279 loss_ctc 9.440391 loss_rnnt 4.398105 history loss 4.488136 rank 2
2022-12-07 23:01:03,686 DEBUG CV Batch 22/400 loss 4.902333 loss_att 826.186279 loss_ctc 9.440391 loss_rnnt 4.398105 history loss 4.488136 rank 0
2022-12-07 23:01:03,976 DEBUG CV Batch 22/400 loss 4.902333 loss_att 826.186279 loss_ctc 9.440391 loss_rnnt 4.398105 history loss 4.488136 rank 1
2022-12-07 23:01:04,240 DEBUG CV Batch 22/400 loss 4.902333 loss_att 826.186279 loss_ctc 9.440391 loss_rnnt 4.398105 history loss 4.488136 rank 7
2022-12-07 23:01:12,626 DEBUG CV Batch 22/500 loss 5.129855 loss_att 266.655090 loss_ctc 9.558278 loss_rnnt 4.637808 history loss 5.068396 rank 5
2022-12-07 23:01:12,837 DEBUG CV Batch 22/500 loss 5.129855 loss_att 266.655090 loss_ctc 9.558278 loss_rnnt 4.637808 history loss 5.068396 rank 4
2022-12-07 23:01:12,860 DEBUG CV Batch 22/500 loss 5.129855 loss_att 266.655090 loss_ctc 9.558278 loss_rnnt 4.637808 history loss 5.068396 rank 3
2022-12-07 23:01:13,025 DEBUG CV Batch 22/500 loss 5.129855 loss_att 266.655090 loss_ctc 9.558278 loss_rnnt 4.637808 history loss 5.068396 rank 6
2022-12-07 23:01:13,873 DEBUG CV Batch 22/500 loss 5.129855 loss_att 266.655090 loss_ctc 9.558278 loss_rnnt 4.637808 history loss 5.068396 rank 0
2022-12-07 23:01:14,420 DEBUG CV Batch 22/500 loss 5.129855 loss_att 266.655090 loss_ctc 9.558278 loss_rnnt 4.637808 history loss 5.068396 rank 2
2022-12-07 23:01:15,290 DEBUG CV Batch 22/500 loss 5.129855 loss_att 266.655090 loss_ctc 9.558278 loss_rnnt 4.637808 history loss 5.068396 rank 1
2022-12-07 23:01:15,569 DEBUG CV Batch 22/500 loss 5.129855 loss_att 266.655090 loss_ctc 9.558278 loss_rnnt 4.637808 history loss 5.068396 rank 7
2022-12-07 23:01:24,510 DEBUG CV Batch 22/600 loss 5.483942 loss_att 104.307251 loss_ctc 9.448963 loss_rnnt 5.043385 history loss 5.905949 rank 4
2022-12-07 23:01:24,715 DEBUG CV Batch 22/600 loss 5.483942 loss_att 104.307251 loss_ctc 9.448963 loss_rnnt 5.043385 history loss 5.905949 rank 5
2022-12-07 23:01:24,730 DEBUG CV Batch 22/600 loss 5.483942 loss_att 104.307251 loss_ctc 9.448963 loss_rnnt 5.043385 history loss 5.905949 rank 3
2022-12-07 23:01:24,983 DEBUG CV Batch 22/600 loss 5.483942 loss_att 104.307251 loss_ctc 9.448963 loss_rnnt 5.043385 history loss 5.905949 rank 6
2022-12-07 23:01:25,560 DEBUG CV Batch 22/600 loss 5.483942 loss_att 104.307251 loss_ctc 9.448963 loss_rnnt 5.043385 history loss 5.905949 rank 0
2022-12-07 23:01:27,356 DEBUG CV Batch 22/600 loss 5.483942 loss_att 104.307251 loss_ctc 9.448963 loss_rnnt 5.043385 history loss 5.905949 rank 2
2022-12-07 23:01:27,730 DEBUG CV Batch 22/600 loss 5.483942 loss_att 104.307251 loss_ctc 9.448963 loss_rnnt 5.043385 history loss 5.905949 rank 1
2022-12-07 23:01:28,537 DEBUG CV Batch 22/600 loss 5.483942 loss_att 104.307251 loss_ctc 9.448963 loss_rnnt 5.043385 history loss 5.905949 rank 7
2022-12-07 23:01:36,006 DEBUG CV Batch 22/700 loss 4.876993 loss_att 707.029358 loss_ctc 18.177650 loss_rnnt 3.399142 history loss 6.486849 rank 4
2022-12-07 23:01:36,140 DEBUG CV Batch 22/700 loss 4.876993 loss_att 707.029358 loss_ctc 18.177650 loss_rnnt 3.399142 history loss 6.486849 rank 3
2022-12-07 23:01:36,473 DEBUG CV Batch 22/700 loss 4.876993 loss_att 707.029358 loss_ctc 18.177650 loss_rnnt 3.399142 history loss 6.486849 rank 5
2022-12-07 23:01:36,567 DEBUG CV Batch 22/700 loss 4.876993 loss_att 707.029358 loss_ctc 18.177650 loss_rnnt 3.399142 history loss 6.486849 rank 0
2022-12-07 23:01:36,816 DEBUG CV Batch 22/700 loss 4.876993 loss_att 707.029358 loss_ctc 18.177650 loss_rnnt 3.399142 history loss 6.486849 rank 6
2022-12-07 23:01:40,004 DEBUG CV Batch 22/700 loss 4.876993 loss_att 707.029358 loss_ctc 18.177650 loss_rnnt 3.399142 history loss 6.486849 rank 1
2022-12-07 23:01:40,184 DEBUG CV Batch 22/700 loss 4.876993 loss_att 707.029358 loss_ctc 18.177650 loss_rnnt 3.399142 history loss 6.486849 rank 2
2022-12-07 23:01:41,073 DEBUG CV Batch 22/700 loss 4.876993 loss_att 707.029358 loss_ctc 18.177650 loss_rnnt 3.399142 history loss 6.486849 rank 7
2022-12-07 23:01:47,410 DEBUG CV Batch 22/800 loss 6.693853 loss_att 263.401642 loss_ctc 16.521286 loss_rnnt 5.601916 history loss 6.015300 rank 4
2022-12-07 23:01:47,643 DEBUG CV Batch 22/800 loss 6.693853 loss_att 263.401642 loss_ctc 16.521286 loss_rnnt 5.601916 history loss 6.015300 rank 3
2022-12-07 23:01:47,890 DEBUG CV Batch 22/800 loss 6.693853 loss_att 263.401642 loss_ctc 16.521286 loss_rnnt 5.601916 history loss 6.015300 rank 0
2022-12-07 23:01:48,109 DEBUG CV Batch 22/800 loss 6.693853 loss_att 263.401642 loss_ctc 16.521286 loss_rnnt 5.601916 history loss 6.015300 rank 5
2022-12-07 23:01:48,479 DEBUG CV Batch 22/800 loss 6.693853 loss_att 263.401642 loss_ctc 16.521286 loss_rnnt 5.601916 history loss 6.015300 rank 6
2022-12-07 23:01:52,239 DEBUG CV Batch 22/800 loss 6.693853 loss_att 263.401642 loss_ctc 16.521286 loss_rnnt 5.601916 history loss 6.015300 rank 2
2022-12-07 23:01:52,463 DEBUG CV Batch 22/800 loss 6.693853 loss_att 263.401642 loss_ctc 16.521286 loss_rnnt 5.601916 history loss 6.015300 rank 1
2022-12-07 23:01:53,463 DEBUG CV Batch 22/800 loss 6.693853 loss_att 263.401642 loss_ctc 16.521286 loss_rnnt 5.601916 history loss 6.015300 rank 7
2022-12-07 23:02:00,894 DEBUG CV Batch 22/900 loss 9.972939 loss_att 550.843262 loss_ctc 16.702654 loss_rnnt 9.225193 history loss 5.848546 rank 4
2022-12-07 23:02:01,281 DEBUG CV Batch 22/900 loss 9.972939 loss_att 550.843262 loss_ctc 16.702654 loss_rnnt 9.225193 history loss 5.848546 rank 0
2022-12-07 23:02:01,375 DEBUG CV Batch 22/900 loss 9.972939 loss_att 550.843262 loss_ctc 16.702654 loss_rnnt 9.225193 history loss 5.848546 rank 3
2022-12-07 23:02:01,466 DEBUG CV Batch 22/900 loss 9.972939 loss_att 550.843262 loss_ctc 16.702654 loss_rnnt 9.225193 history loss 5.848546 rank 5
2022-12-07 23:02:01,879 DEBUG CV Batch 22/900 loss 9.972939 loss_att 550.843262 loss_ctc 16.702654 loss_rnnt 9.225193 history loss 5.848546 rank 6
2022-12-07 23:02:05,934 DEBUG CV Batch 22/900 loss 9.972939 loss_att 550.843262 loss_ctc 16.702654 loss_rnnt 9.225193 history loss 5.848546 rank 2
2022-12-07 23:02:06,263 DEBUG CV Batch 22/900 loss 9.972939 loss_att 550.843262 loss_ctc 16.702654 loss_rnnt 9.225193 history loss 5.848546 rank 1
2022-12-07 23:02:07,239 DEBUG CV Batch 22/900 loss 9.972939 loss_att 550.843262 loss_ctc 16.702654 loss_rnnt 9.225193 history loss 5.848546 rank 7
2022-12-07 23:02:12,559 DEBUG CV Batch 22/1000 loss 2.057898 loss_att 176.484756 loss_ctc 4.136973 loss_rnnt 1.826890 history loss 5.642455 rank 4
2022-12-07 23:02:12,975 DEBUG CV Batch 22/1000 loss 2.057898 loss_att 176.484756 loss_ctc 4.136973 loss_rnnt 1.826890 history loss 5.642455 rank 5
2022-12-07 23:02:13,079 DEBUG CV Batch 22/1000 loss 2.057898 loss_att 176.484756 loss_ctc 4.136973 loss_rnnt 1.826890 history loss 5.642455 rank 3
2022-12-07 23:02:13,207 DEBUG CV Batch 22/1000 loss 2.057898 loss_att 176.484756 loss_ctc 4.136973 loss_rnnt 1.826890 history loss 5.642455 rank 0
2022-12-07 23:02:13,435 DEBUG CV Batch 22/1000 loss 2.057898 loss_att 176.484756 loss_ctc 4.136973 loss_rnnt 1.826890 history loss 5.642455 rank 6
2022-12-07 23:02:17,890 DEBUG CV Batch 22/1000 loss 2.057898 loss_att 176.484756 loss_ctc 4.136973 loss_rnnt 1.826890 history loss 5.642455 rank 2
2022-12-07 23:02:17,890 DEBUG CV Batch 22/1000 loss 2.057898 loss_att 176.484756 loss_ctc 4.136973 loss_rnnt 1.826890 history loss 5.642455 rank 1
2022-12-07 23:02:19,178 DEBUG CV Batch 22/1000 loss 2.057898 loss_att 176.484756 loss_ctc 4.136973 loss_rnnt 1.826890 history loss 5.642455 rank 7
2022-12-07 23:02:23,896 DEBUG CV Batch 22/1100 loss 4.477835 loss_att 60.694519 loss_ctc 8.735522 loss_rnnt 4.004759 history loss 5.632076 rank 4
2022-12-07 23:02:24,165 DEBUG CV Batch 22/1100 loss 4.477835 loss_att 60.694519 loss_ctc 8.735522 loss_rnnt 4.004759 history loss 5.632076 rank 5
2022-12-07 23:02:24,588 DEBUG CV Batch 22/1100 loss 4.477835 loss_att 60.694519 loss_ctc 8.735522 loss_rnnt 4.004759 history loss 5.632076 rank 3
2022-12-07 23:02:24,716 DEBUG CV Batch 22/1100 loss 4.477835 loss_att 60.694519 loss_ctc 8.735522 loss_rnnt 4.004759 history loss 5.632076 rank 6
2022-12-07 23:02:24,804 DEBUG CV Batch 22/1100 loss 4.477835 loss_att 60.694519 loss_ctc 8.735522 loss_rnnt 4.004759 history loss 5.632076 rank 0
2022-12-07 23:02:29,020 DEBUG CV Batch 22/1100 loss 4.477835 loss_att 60.694519 loss_ctc 8.735522 loss_rnnt 4.004759 history loss 5.632076 rank 1
2022-12-07 23:02:29,235 DEBUG CV Batch 22/1100 loss 4.477835 loss_att 60.694519 loss_ctc 8.735522 loss_rnnt 4.004759 history loss 5.632076 rank 2
2022-12-07 23:02:30,713 DEBUG CV Batch 22/1100 loss 4.477835 loss_att 60.694519 loss_ctc 8.735522 loss_rnnt 4.004759 history loss 5.632076 rank 7
2022-12-07 23:02:33,750 DEBUG CV Batch 22/1200 loss 7.277942 loss_att 280.455078 loss_ctc 11.401728 loss_rnnt 6.819744 history loss 5.892630 rank 4
2022-12-07 23:02:34,231 DEBUG CV Batch 22/1200 loss 7.277942 loss_att 280.455078 loss_ctc 11.401728 loss_rnnt 6.819744 history loss 5.892630 rank 5
2022-12-07 23:02:34,508 DEBUG CV Batch 22/1200 loss 7.277942 loss_att 280.455078 loss_ctc 11.401728 loss_rnnt 6.819744 history loss 5.892630 rank 3
2022-12-07 23:02:34,789 DEBUG CV Batch 22/1200 loss 7.277942 loss_att 280.455078 loss_ctc 11.401728 loss_rnnt 6.819744 history loss 5.892630 rank 6
2022-12-07 23:02:34,973 DEBUG CV Batch 22/1200 loss 7.277942 loss_att 280.455078 loss_ctc 11.401728 loss_rnnt 6.819744 history loss 5.892630 rank 0
2022-12-07 23:02:39,595 DEBUG CV Batch 22/1200 loss 7.277942 loss_att 280.455078 loss_ctc 11.401728 loss_rnnt 6.819744 history loss 5.892630 rank 2
2022-12-07 23:02:39,938 DEBUG CV Batch 22/1200 loss 7.277942 loss_att 280.455078 loss_ctc 11.401728 loss_rnnt 6.819744 history loss 5.892630 rank 1
2022-12-07 23:02:40,986 DEBUG CV Batch 22/1200 loss 7.277942 loss_att 280.455078 loss_ctc 11.401728 loss_rnnt 6.819744 history loss 5.892630 rank 7
2022-12-07 23:02:45,215 DEBUG CV Batch 22/1300 loss 4.929867 loss_att 105.975952 loss_ctc 8.598277 loss_rnnt 4.522266 history loss 6.173776 rank 4
2022-12-07 23:02:45,767 DEBUG CV Batch 22/1300 loss 4.929867 loss_att 105.975952 loss_ctc 8.598277 loss_rnnt 4.522266 history loss 6.173776 rank 5
2022-12-07 23:02:46,023 DEBUG CV Batch 22/1300 loss 4.929867 loss_att 105.975952 loss_ctc 8.598277 loss_rnnt 4.522266 history loss 6.173776 rank 3
2022-12-07 23:02:46,512 DEBUG CV Batch 22/1300 loss 4.929867 loss_att 105.975952 loss_ctc 8.598277 loss_rnnt 4.522266 history loss 6.173776 rank 0
2022-12-07 23:02:46,701 DEBUG CV Batch 22/1300 loss 4.929867 loss_att 105.975952 loss_ctc 8.598277 loss_rnnt 4.522266 history loss 6.173776 rank 6
2022-12-07 23:02:51,531 DEBUG CV Batch 22/1300 loss 4.929867 loss_att 105.975952 loss_ctc 8.598277 loss_rnnt 4.522266 history loss 6.173776 rank 2
2022-12-07 23:02:51,947 DEBUG CV Batch 22/1300 loss 4.929867 loss_att 105.975952 loss_ctc 8.598277 loss_rnnt 4.522266 history loss 6.173776 rank 1
2022-12-07 23:02:53,065 DEBUG CV Batch 22/1300 loss 4.929867 loss_att 105.975952 loss_ctc 8.598277 loss_rnnt 4.522266 history loss 6.173776 rank 7
2022-12-07 23:02:56,144 DEBUG CV Batch 22/1400 loss 2.856349 loss_att 562.085693 loss_ctc 6.734758 loss_rnnt 2.425415 history loss 6.459106 rank 4
2022-12-07 23:02:57,000 DEBUG CV Batch 22/1400 loss 2.856349 loss_att 562.085693 loss_ctc 6.734758 loss_rnnt 2.425415 history loss 6.459106 rank 3
2022-12-07 23:02:57,303 DEBUG CV Batch 22/1400 loss 2.856349 loss_att 562.085693 loss_ctc 6.734758 loss_rnnt 2.425415 history loss 6.459106 rank 0
2022-12-07 23:02:57,890 DEBUG CV Batch 22/1400 loss 2.856349 loss_att 562.085693 loss_ctc 6.734758 loss_rnnt 2.425415 history loss 6.459106 rank 5
2022-12-07 23:02:58,411 DEBUG CV Batch 22/1400 loss 2.856349 loss_att 562.085693 loss_ctc 6.734758 loss_rnnt 2.425415 history loss 6.459106 rank 6
2022-12-07 23:03:04,074 DEBUG CV Batch 22/1400 loss 2.856349 loss_att 562.085693 loss_ctc 6.734758 loss_rnnt 2.425415 history loss 6.459106 rank 2
2022-12-07 23:03:04,483 DEBUG CV Batch 22/1400 loss 2.856349 loss_att 562.085693 loss_ctc 6.734758 loss_rnnt 2.425415 history loss 6.459106 rank 1
2022-12-07 23:03:05,611 DEBUG CV Batch 22/1400 loss 2.856349 loss_att 562.085693 loss_ctc 6.734758 loss_rnnt 2.425415 history loss 6.459106 rank 7
2022-12-07 23:03:08,024 DEBUG CV Batch 22/1500 loss 7.727011 loss_att 275.486298 loss_ctc 8.910055 loss_rnnt 7.595562 history loss 6.332890 rank 4
2022-12-07 23:03:08,296 DEBUG CV Batch 22/1500 loss 7.727011 loss_att 275.486298 loss_ctc 8.910055 loss_rnnt 7.595562 history loss 6.332890 rank 3
2022-12-07 23:03:08,581 DEBUG CV Batch 22/1500 loss 7.727011 loss_att 275.486298 loss_ctc 8.910055 loss_rnnt 7.595562 history loss 6.332890 rank 0
2022-12-07 23:03:09,740 DEBUG CV Batch 22/1500 loss 7.727011 loss_att 275.486298 loss_ctc 8.910055 loss_rnnt 7.595562 history loss 6.332890 rank 5
2022-12-07 23:03:10,413 DEBUG CV Batch 22/1500 loss 7.727011 loss_att 275.486298 loss_ctc 8.910055 loss_rnnt 7.595562 history loss 6.332890 rank 6
2022-12-07 23:03:16,671 DEBUG CV Batch 22/1500 loss 7.727011 loss_att 275.486298 loss_ctc 8.910055 loss_rnnt 7.595562 history loss 6.332890 rank 2
2022-12-07 23:03:17,144 DEBUG CV Batch 22/1500 loss 7.727011 loss_att 275.486298 loss_ctc 8.910055 loss_rnnt 7.595562 history loss 6.332890 rank 1
2022-12-07 23:03:18,272 DEBUG CV Batch 22/1500 loss 7.727011 loss_att 275.486298 loss_ctc 8.910055 loss_rnnt 7.595562 history loss 6.332890 rank 7
2022-12-07 23:03:21,081 DEBUG CV Batch 22/1600 loss 7.026496 loss_att 593.906677 loss_ctc 15.981127 loss_rnnt 6.031537 history loss 6.292834 rank 4
2022-12-07 23:03:21,368 DEBUG CV Batch 22/1600 loss 7.026496 loss_att 593.906677 loss_ctc 15.981127 loss_rnnt 6.031537 history loss 6.292834 rank 3
2022-12-07 23:03:21,673 DEBUG CV Batch 22/1600 loss 7.026496 loss_att 593.906677 loss_ctc 15.981127 loss_rnnt 6.031537 history loss 6.292834 rank 0
2022-12-07 23:03:22,937 DEBUG CV Batch 22/1600 loss 7.026496 loss_att 593.906677 loss_ctc 15.981127 loss_rnnt 6.031537 history loss 6.292834 rank 5
2022-12-07 23:03:23,537 DEBUG CV Batch 22/1600 loss 7.026496 loss_att 593.906677 loss_ctc 15.981127 loss_rnnt 6.031537 history loss 6.292834 rank 6
2022-12-07 23:03:29,984 DEBUG CV Batch 22/1600 loss 7.026496 loss_att 593.906677 loss_ctc 15.981127 loss_rnnt 6.031537 history loss 6.292834 rank 2
2022-12-07 23:03:30,293 DEBUG CV Batch 22/1600 loss 7.026496 loss_att 593.906677 loss_ctc 15.981127 loss_rnnt 6.031537 history loss 6.292834 rank 1
2022-12-07 23:03:31,689 DEBUG CV Batch 22/1600 loss 7.026496 loss_att 593.906677 loss_ctc 15.981127 loss_rnnt 6.031537 history loss 6.292834 rank 7
2022-12-07 23:03:33,001 DEBUG CV Batch 22/1700 loss 7.544925 loss_att 210.843246 loss_ctc 15.008753 loss_rnnt 6.715611 history loss 6.222391 rank 4
2022-12-07 23:03:33,452 DEBUG CV Batch 22/1700 loss 7.544925 loss_att 210.843246 loss_ctc 15.008753 loss_rnnt 6.715611 history loss 6.222391 rank 3
2022-12-07 23:03:33,900 DEBUG CV Batch 22/1700 loss 7.544925 loss_att 210.843246 loss_ctc 15.008753 loss_rnnt 6.715611 history loss 6.222391 rank 0
2022-12-07 23:03:34,910 DEBUG CV Batch 22/1700 loss 7.544925 loss_att 210.843246 loss_ctc 15.008753 loss_rnnt 6.715611 history loss 6.222391 rank 5
2022-12-07 23:03:35,479 DEBUG CV Batch 22/1700 loss 7.544925 loss_att 210.843246 loss_ctc 15.008753 loss_rnnt 6.715611 history loss 6.222391 rank 6
2022-12-07 23:03:41,757 INFO Epoch 22 CV info cv_loss 6.2026403491705775
2022-12-07 23:03:41,757 INFO Epoch 23 TRAIN info lr 0.0002672036084923839
2022-12-07 23:03:41,759 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-07 23:03:41,838 DEBUG CV Batch 22/1700 loss 7.544925 loss_att 210.843246 loss_ctc 15.008753 loss_rnnt 6.715611 history loss 6.222391 rank 2
2022-12-07 23:03:42,044 DEBUG CV Batch 22/1700 loss 7.544925 loss_att 210.843246 loss_ctc 15.008753 loss_rnnt 6.715611 history loss 6.222391 rank 1
2022-12-07 23:03:42,719 INFO Epoch 22 CV info cv_loss 6.2026403491705775
2022-12-07 23:03:42,719 INFO Epoch 23 TRAIN info lr 0.0002672135294703924
2022-12-07 23:03:42,721 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-07 23:03:42,868 INFO Epoch 22 CV info cv_loss 6.2026403491705775
2022-12-07 23:03:42,868 INFO Checkpoint: save to checkpoint exp/1204_encoder_bias_nobi_noatt/22.pt
2022-12-07 23:03:43,407 INFO Epoch 23 TRAIN info lr 0.0002672074241223828
2022-12-07 23:03:43,413 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-07 23:03:43,507 DEBUG CV Batch 22/1700 loss 7.544925 loss_att 210.843246 loss_ctc 15.008753 loss_rnnt 6.715611 history loss 6.222391 rank 7
2022-12-07 23:03:44,023 INFO Epoch 22 CV info cv_loss 6.2026403491705775
2022-12-07 23:03:44,024 INFO Epoch 23 TRAIN info lr 0.0002671990299521421
2022-12-07 23:03:44,028 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-07 23:03:44,511 INFO Epoch 22 CV info cv_loss 6.2026403491705775
2022-12-07 23:03:44,512 INFO Epoch 23 TRAIN info lr 0.0002671997930258379
2022-12-07 23:03:44,516 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-07 23:03:50,762 INFO Epoch 22 CV info cv_loss 6.2026403491705775
2022-12-07 23:03:50,762 INFO Epoch 23 TRAIN info lr 0.0002672078056943731
2022-12-07 23:03:50,763 INFO Epoch 22 CV info cv_loss 6.2026403491705775
2022-12-07 23:03:50,764 INFO Epoch 23 TRAIN info lr 0.0002672097135788445
2022-12-07 23:03:50,766 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-07 23:03:50,769 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-07 23:03:52,533 INFO Epoch 22 CV info cv_loss 6.2026403491705775
2022-12-07 23:03:52,534 INFO Epoch 23 TRAIN info lr 0.0002671990299521421
2022-12-07 23:03:52,537 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-07 23:04:53,100 DEBUG TRAIN Batch 23/0 loss 7.731711 loss_att 75.521988 loss_ctc 10.510297 loss_rnnt 7.422979 lr 0.00026720 rank 4
2022-12-07 23:04:53,101 DEBUG TRAIN Batch 23/0 loss 11.782462 loss_att 77.093002 loss_ctc 17.332571 loss_rnnt 11.165783 lr 0.00026721 rank 3
2022-12-07 23:04:53,108 DEBUG TRAIN Batch 23/0 loss 8.227755 loss_att 73.818520 loss_ctc 12.938194 loss_rnnt 7.704373 lr 0.00026720 rank 6
2022-12-07 23:04:53,109 DEBUG TRAIN Batch 23/0 loss 12.201425 loss_att 83.940315 loss_ctc 19.188440 loss_rnnt 11.425090 lr 0.00026721 rank 0
2022-12-07 23:04:53,112 DEBUG TRAIN Batch 23/0 loss 6.952100 loss_att 64.525871 loss_ctc 10.768031 loss_rnnt 6.528108 lr 0.00026720 rank 5
2022-12-07 23:04:53,123 DEBUG TRAIN Batch 23/0 loss 7.283978 loss_att 73.942581 loss_ctc 10.173923 loss_rnnt 6.962873 lr 0.00026721 rank 1
2022-12-07 23:04:53,141 DEBUG TRAIN Batch 23/0 loss 6.835931 loss_att 74.054077 loss_ctc 10.638079 loss_rnnt 6.413470 lr 0.00026720 rank 7
2022-12-07 23:04:53,144 DEBUG TRAIN Batch 23/0 loss 11.100587 loss_att 73.716309 loss_ctc 16.157431 loss_rnnt 10.538716 lr 0.00026721 rank 2
2022-12-07 23:05:54,874 DEBUG TRAIN Batch 23/100 loss 3.499698 loss_att 388.573975 loss_ctc 9.363007 loss_rnnt 2.848220 lr 0.00026716 rank 6
2022-12-07 23:05:54,874 DEBUG TRAIN Batch 23/100 loss 3.919231 loss_att 437.380798 loss_ctc 12.434835 loss_rnnt 2.973053 lr 0.00026717 rank 4
2022-12-07 23:05:54,876 DEBUG TRAIN Batch 23/100 loss 2.377338 loss_att 424.547058 loss_ctc 6.614672 loss_rnnt 1.906523 lr 0.00026717 rank 3
2022-12-07 23:05:54,877 DEBUG TRAIN Batch 23/100 loss 2.782986 loss_att 383.200623 loss_ctc 6.102768 loss_rnnt 2.414121 lr 0.00026717 rank 2
2022-12-07 23:05:54,877 DEBUG TRAIN Batch 23/100 loss 21.380688 loss_att 464.023254 loss_ctc 41.476917 loss_rnnt 19.147774 lr 0.00026716 rank 7
2022-12-07 23:05:54,881 DEBUG TRAIN Batch 23/100 loss 1.053186 loss_att 401.674500 loss_ctc 3.961390 loss_rnnt 0.730052 lr 0.00026716 rank 5
2022-12-07 23:05:54,881 DEBUG TRAIN Batch 23/100 loss 5.898546 loss_att 402.121887 loss_ctc 9.237708 loss_rnnt 5.527528 lr 0.00026717 rank 1
2022-12-07 23:05:54,886 DEBUG TRAIN Batch 23/100 loss 5.328084 loss_att 354.184906 loss_ctc 9.554064 loss_rnnt 4.858531 lr 0.00026717 rank 0
2022-12-07 23:06:57,713 DEBUG TRAIN Batch 23/200 loss 2.365744 loss_att 450.029266 loss_ctc 7.898717 loss_rnnt 1.750969 lr 0.00026713 rank 4
2022-12-07 23:06:57,715 DEBUG TRAIN Batch 23/200 loss 6.113420 loss_att 385.926514 loss_ctc 19.750509 loss_rnnt 4.598188 lr 0.00026714 rank 3
2022-12-07 23:06:57,717 DEBUG TRAIN Batch 23/200 loss 10.464297 loss_att 376.828949 loss_ctc 33.861824 loss_rnnt 7.864573 lr 0.00026712 rank 6
2022-12-07 23:06:57,717 DEBUG TRAIN Batch 23/200 loss 3.732666 loss_att 409.509827 loss_ctc 9.014820 loss_rnnt 3.145760 lr 0.00026713 rank 2
2022-12-07 23:06:57,721 DEBUG TRAIN Batch 23/200 loss 8.206110 loss_att 396.321472 loss_ctc 14.917463 loss_rnnt 7.460404 lr 0.00026712 rank 5
2022-12-07 23:06:57,742 DEBUG TRAIN Batch 23/200 loss 7.667177 loss_att 409.348145 loss_ctc 22.202957 loss_rnnt 6.052091 lr 0.00026713 rank 0
2022-12-07 23:06:57,752 DEBUG TRAIN Batch 23/200 loss 6.064614 loss_att 356.809814 loss_ctc 12.427177 loss_rnnt 5.357662 lr 0.00026712 rank 7
2022-12-07 23:06:57,761 DEBUG TRAIN Batch 23/200 loss 2.164964 loss_att 326.822632 loss_ctc 7.187782 loss_rnnt 1.606873 lr 0.00026713 rank 1
2022-12-07 23:08:01,526 DEBUG TRAIN Batch 23/300 loss 7.980923 loss_att 391.298218 loss_ctc 17.696369 loss_rnnt 6.901429 lr 0.00026709 rank 4
2022-12-07 23:08:01,540 DEBUG TRAIN Batch 23/300 loss 17.628502 loss_att 373.430786 loss_ctc 38.253716 loss_rnnt 15.336813 lr 0.00026709 rank 2
2022-12-07 23:08:01,540 DEBUG TRAIN Batch 23/300 loss 9.432177 loss_att 372.896301 loss_ctc 20.925640 loss_rnnt 8.155125 lr 0.00026709 rank 6
2022-12-07 23:08:01,540 DEBUG TRAIN Batch 23/300 loss 4.539927 loss_att 380.231262 loss_ctc 17.582876 loss_rnnt 3.090711 lr 0.00026710 rank 3
2022-12-07 23:08:01,544 DEBUG TRAIN Batch 23/300 loss 4.187189 loss_att 375.553833 loss_ctc 14.624697 loss_rnnt 3.027465 lr 0.00026708 rank 7
2022-12-07 23:08:01,547 DEBUG TRAIN Batch 23/300 loss 13.231638 loss_att 328.240631 loss_ctc 15.883775 loss_rnnt 12.936956 lr 0.00026709 rank 1
2022-12-07 23:08:01,570 DEBUG TRAIN Batch 23/300 loss 5.522445 loss_att 334.216217 loss_ctc 13.246605 loss_rnnt 4.664205 lr 0.00026709 rank 0
2022-12-07 23:08:01,585 DEBUG TRAIN Batch 23/300 loss 9.832999 loss_att 377.286865 loss_ctc 22.863583 loss_rnnt 8.385157 lr 0.00026708 rank 5
2022-12-07 23:09:12,197 DEBUG TRAIN Batch 23/400 loss 5.506896 loss_att 302.250946 loss_ctc 11.139852 loss_rnnt 4.881012 lr 0.00026705 rank 7
2022-12-07 23:09:12,213 DEBUG TRAIN Batch 23/400 loss 14.297693 loss_att 390.610870 loss_ctc 25.052330 loss_rnnt 13.102735 lr 0.00026705 rank 2
2022-12-07 23:09:12,215 DEBUG TRAIN Batch 23/400 loss 7.336409 loss_att 348.020111 loss_ctc 16.092035 loss_rnnt 6.363561 lr 0.00026705 rank 4
2022-12-07 23:09:12,216 DEBUG TRAIN Batch 23/400 loss 5.848208 loss_att 412.099091 loss_ctc 16.120283 loss_rnnt 4.706867 lr 0.00026706 rank 1
2022-12-07 23:09:12,217 DEBUG TRAIN Batch 23/400 loss 2.914042 loss_att 314.892303 loss_ctc 9.747568 loss_rnnt 2.154761 lr 0.00026705 rank 6
2022-12-07 23:09:12,219 DEBUG TRAIN Batch 23/400 loss 9.322845 loss_att 305.344879 loss_ctc 17.014591 loss_rnnt 8.468207 lr 0.00026705 rank 5
2022-12-07 23:09:12,219 DEBUG TRAIN Batch 23/400 loss 10.349916 loss_att 386.377228 loss_ctc 26.032383 loss_rnnt 8.607420 lr 0.00026705 rank 0
2022-12-07 23:09:12,265 DEBUG TRAIN Batch 23/400 loss 10.667739 loss_att 364.561707 loss_ctc 25.332790 loss_rnnt 9.038288 lr 0.00026706 rank 3
2022-12-07 23:10:16,207 DEBUG TRAIN Batch 23/500 loss 7.054009 loss_att 374.164551 loss_ctc 17.594318 loss_rnnt 5.882864 lr 0.00026701 rank 7
2022-12-07 23:10:16,208 DEBUG TRAIN Batch 23/500 loss 5.962533 loss_att 319.512207 loss_ctc 13.375414 loss_rnnt 5.138880 lr 0.00026702 rank 2
2022-12-07 23:10:16,209 DEBUG TRAIN Batch 23/500 loss 4.989408 loss_att 355.962494 loss_ctc 11.330645 loss_rnnt 4.284826 lr 0.00026701 rank 6
2022-12-07 23:10:16,209 DEBUG TRAIN Batch 23/500 loss 5.671392 loss_att 325.737885 loss_ctc 13.590386 loss_rnnt 4.791504 lr 0.00026701 rank 4
2022-12-07 23:10:16,210 DEBUG TRAIN Batch 23/500 loss 7.497338 loss_att 367.612854 loss_ctc 14.747383 loss_rnnt 6.691778 lr 0.00026702 rank 3
2022-12-07 23:10:16,213 DEBUG TRAIN Batch 23/500 loss 3.339441 loss_att 281.580414 loss_ctc 7.208720 loss_rnnt 2.909521 lr 0.00026702 rank 0
2022-12-07 23:10:16,214 DEBUG TRAIN Batch 23/500 loss 4.145081 loss_att 261.223877 loss_ctc 8.590569 loss_rnnt 3.651138 lr 0.00026702 rank 1
2022-12-07 23:10:16,214 DEBUG TRAIN Batch 23/500 loss 13.350811 loss_att 312.803040 loss_ctc 21.733555 loss_rnnt 12.419394 lr 0.00026701 rank 5
2022-12-07 23:11:19,866 DEBUG TRAIN Batch 23/600 loss 6.968129 loss_att 104.838959 loss_ctc 12.839103 loss_rnnt 6.315799 lr 0.00026697 rank 4
2022-12-07 23:11:19,866 DEBUG TRAIN Batch 23/600 loss 10.838917 loss_att 240.840302 loss_ctc 14.771875 loss_rnnt 10.401922 lr 0.00026697 rank 7
2022-12-07 23:11:19,866 DEBUG TRAIN Batch 23/600 loss 8.293903 loss_att 291.033203 loss_ctc 16.395691 loss_rnnt 7.393705 lr 0.00026698 rank 3
2022-12-07 23:11:19,868 DEBUG TRAIN Batch 23/600 loss 9.295465 loss_att 107.493523 loss_ctc 16.942566 loss_rnnt 8.445787 lr 0.00026698 rank 0
2022-12-07 23:11:19,870 DEBUG TRAIN Batch 23/600 loss 5.619382 loss_att 271.725708 loss_ctc 11.273142 loss_rnnt 4.991187 lr 0.00026697 rank 6
2022-12-07 23:11:19,871 DEBUG TRAIN Batch 23/600 loss 9.382262 loss_att 223.086838 loss_ctc 15.943367 loss_rnnt 8.653251 lr 0.00026698 rank 1
2022-12-07 23:11:19,873 DEBUG TRAIN Batch 23/600 loss 11.839279 loss_att 205.051056 loss_ctc 19.727009 loss_rnnt 10.962865 lr 0.00026698 rank 2
2022-12-07 23:11:19,917 DEBUG TRAIN Batch 23/600 loss 4.428499 loss_att 157.801956 loss_ctc 9.327002 loss_rnnt 3.884221 lr 0.00026697 rank 5
2022-12-07 23:12:24,482 DEBUG TRAIN Batch 23/700 loss 2.985400 loss_att 451.050629 loss_ctc 8.666201 loss_rnnt 2.354200 lr 0.00026695 rank 3
2022-12-07 23:12:24,494 DEBUG TRAIN Batch 23/700 loss 9.016232 loss_att 373.669037 loss_ctc 21.906300 loss_rnnt 7.584002 lr 0.00026694 rank 4
2022-12-07 23:12:24,496 DEBUG TRAIN Batch 23/700 loss 4.698085 loss_att 356.267426 loss_ctc 12.103493 loss_rnnt 3.875262 lr 0.00026694 rank 0
2022-12-07 23:12:24,497 DEBUG TRAIN Batch 23/700 loss 9.951972 loss_att 418.255554 loss_ctc 18.461670 loss_rnnt 9.006451 lr 0.00026693 rank 7
2022-12-07 23:12:24,498 DEBUG TRAIN Batch 23/700 loss 5.884839 loss_att 394.809753 loss_ctc 12.158934 loss_rnnt 5.187718 lr 0.00026694 rank 1
2022-12-07 23:12:24,500 DEBUG TRAIN Batch 23/700 loss 4.815524 loss_att 414.549652 loss_ctc 13.945564 loss_rnnt 3.801075 lr 0.00026694 rank 2
2022-12-07 23:12:24,510 DEBUG TRAIN Batch 23/700 loss 7.107342 loss_att 392.763611 loss_ctc 15.101553 loss_rnnt 6.219097 lr 0.00026693 rank 5
2022-12-07 23:12:24,539 DEBUG TRAIN Batch 23/700 loss 10.812886 loss_att 376.298309 loss_ctc 21.564680 loss_rnnt 9.618242 lr 0.00026693 rank 6
2022-12-07 23:13:35,076 DEBUG TRAIN Batch 23/800 loss 7.108702 loss_att 458.461060 loss_ctc 19.405331 loss_rnnt 5.742410 lr 0.00026689 rank 7
2022-12-07 23:13:35,078 DEBUG TRAIN Batch 23/800 loss 8.625324 loss_att 361.370361 loss_ctc 13.318718 loss_rnnt 8.103836 lr 0.00026690 rank 4
2022-12-07 23:13:35,079 DEBUG TRAIN Batch 23/800 loss 4.173116 loss_att 361.329163 loss_ctc 9.412795 loss_rnnt 3.590929 lr 0.00026690 rank 0
2022-12-07 23:13:35,079 DEBUG TRAIN Batch 23/800 loss 6.682350 loss_att 371.321899 loss_ctc 10.055376 loss_rnnt 6.307569 lr 0.00026690 rank 1
2022-12-07 23:13:35,080 DEBUG TRAIN Batch 23/800 loss 6.581376 loss_att 384.309540 loss_ctc 16.815720 loss_rnnt 5.444226 lr 0.00026690 rank 2
2022-12-07 23:13:35,082 DEBUG TRAIN Batch 23/800 loss 10.278100 loss_att 421.741821 loss_ctc 19.148144 loss_rnnt 9.292541 lr 0.00026691 rank 3
2022-12-07 23:13:35,082 DEBUG TRAIN Batch 23/800 loss 7.336303 loss_att 392.900482 loss_ctc 14.559509 loss_rnnt 6.533725 lr 0.00026689 rank 5
2022-12-07 23:13:35,085 DEBUG TRAIN Batch 23/800 loss 9.204506 loss_att 357.966522 loss_ctc 20.216215 loss_rnnt 7.980983 lr 0.00026689 rank 6
2022-12-07 23:14:37,692 DEBUG TRAIN Batch 23/900 loss 7.271424 loss_att 422.674316 loss_ctc 13.562785 loss_rnnt 6.572384 lr 0.00026687 rank 3
2022-12-07 23:14:37,693 DEBUG TRAIN Batch 23/900 loss 5.829347 loss_att 371.764404 loss_ctc 11.738910 loss_rnnt 5.172729 lr 0.00026687 rank 1
2022-12-07 23:14:37,694 DEBUG TRAIN Batch 23/900 loss 5.954604 loss_att 327.079346 loss_ctc 13.543910 loss_rnnt 5.111347 lr 0.00026686 rank 7
2022-12-07 23:14:37,694 DEBUG TRAIN Batch 23/900 loss 17.465397 loss_att 459.826477 loss_ctc 30.201263 loss_rnnt 16.050303 lr 0.00026686 rank 4
2022-12-07 23:14:37,695 DEBUG TRAIN Batch 23/900 loss 8.514621 loss_att 363.935364 loss_ctc 21.821438 loss_rnnt 7.036085 lr 0.00026686 rank 2
2022-12-07 23:14:37,696 DEBUG TRAIN Batch 23/900 loss 4.959725 loss_att 387.163879 loss_ctc 8.825331 loss_rnnt 4.530214 lr 0.00026686 rank 6
2022-12-07 23:14:37,696 DEBUG TRAIN Batch 23/900 loss 14.044744 loss_att 380.343628 loss_ctc 26.372837 loss_rnnt 12.674956 lr 0.00026686 rank 5
2022-12-07 23:14:37,701 DEBUG TRAIN Batch 23/900 loss 7.358108 loss_att 404.939117 loss_ctc 16.401226 loss_rnnt 6.353317 lr 0.00026686 rank 0
2022-12-07 23:15:40,714 DEBUG TRAIN Batch 23/1000 loss 8.974287 loss_att 341.534424 loss_ctc 18.437021 loss_rnnt 7.922873 lr 0.00026683 rank 2
2022-12-07 23:15:40,724 DEBUG TRAIN Batch 23/1000 loss 10.860151 loss_att 448.258087 loss_ctc 18.556425 loss_rnnt 10.005011 lr 0.00026682 rank 4
2022-12-07 23:15:40,726 DEBUG TRAIN Batch 23/1000 loss 6.273163 loss_att 334.769257 loss_ctc 15.361917 loss_rnnt 5.263302 lr 0.00026682 rank 6
2022-12-07 23:15:40,728 DEBUG TRAIN Batch 23/1000 loss 9.751033 loss_att 365.816132 loss_ctc 17.675329 loss_rnnt 8.870556 lr 0.00026683 rank 3
2022-12-07 23:15:40,728 DEBUG TRAIN Batch 23/1000 loss 6.738401 loss_att 404.115417 loss_ctc 23.150648 loss_rnnt 4.914818 lr 0.00026682 rank 7
2022-12-07 23:15:40,734 DEBUG TRAIN Batch 23/1000 loss 7.320768 loss_att 299.635620 loss_ctc 17.299856 loss_rnnt 6.211981 lr 0.00026683 rank 0
2022-12-07 23:15:40,741 DEBUG TRAIN Batch 23/1000 loss 4.867863 loss_att 337.488373 loss_ctc 14.911154 loss_rnnt 3.751942 lr 0.00026683 rank 1
2022-12-07 23:15:40,773 DEBUG TRAIN Batch 23/1000 loss 8.427243 loss_att 373.322449 loss_ctc 16.168106 loss_rnnt 7.567148 lr 0.00026682 rank 5
2022-12-07 23:16:52,190 DEBUG TRAIN Batch 23/1100 loss 7.720828 loss_att 331.822266 loss_ctc 18.903711 loss_rnnt 6.478285 lr 0.00026678 rank 7
2022-12-07 23:16:52,209 DEBUG TRAIN Batch 23/1100 loss 7.800925 loss_att 338.581390 loss_ctc 17.518026 loss_rnnt 6.721248 lr 0.00026678 rank 6
2022-12-07 23:16:52,212 DEBUG TRAIN Batch 23/1100 loss 12.007336 loss_att 374.766815 loss_ctc 24.132816 loss_rnnt 10.660061 lr 0.00026679 rank 2
2022-12-07 23:16:52,213 DEBUG TRAIN Batch 23/1100 loss 7.462420 loss_att 310.226807 loss_ctc 18.710186 loss_rnnt 6.212668 lr 0.00026679 rank 0
2022-12-07 23:16:52,214 DEBUG TRAIN Batch 23/1100 loss 3.888294 loss_att 336.697449 loss_ctc 12.770195 loss_rnnt 2.901416 lr 0.00026679 rank 1
2022-12-07 23:16:52,214 DEBUG TRAIN Batch 23/1100 loss 6.718341 loss_att 338.270172 loss_ctc 12.567880 loss_rnnt 6.068393 lr 0.00026678 rank 4
2022-12-07 23:16:52,220 DEBUG TRAIN Batch 23/1100 loss 9.547516 loss_att 358.803375 loss_ctc 19.191540 loss_rnnt 8.475958 lr 0.00026679 rank 3
2022-12-07 23:16:52,224 DEBUG TRAIN Batch 23/1100 loss 13.002016 loss_att 382.723297 loss_ctc 26.127947 loss_rnnt 11.543579 lr 0.00026678 rank 5
2022-12-07 23:17:55,540 DEBUG TRAIN Batch 23/1200 loss 11.324783 loss_att 289.664001 loss_ctc 21.642271 loss_rnnt 10.178395 lr 0.00026674 rank 7
2022-12-07 23:17:55,545 DEBUG TRAIN Batch 23/1200 loss 13.374707 loss_att 155.301071 loss_ctc 19.413544 loss_rnnt 12.703725 lr 0.00026675 rank 0
2022-12-07 23:17:55,547 DEBUG TRAIN Batch 23/1200 loss 7.476476 loss_att 296.939240 loss_ctc 16.194132 loss_rnnt 6.507848 lr 0.00026675 rank 4
2022-12-07 23:17:55,548 DEBUG TRAIN Batch 23/1200 loss 5.911158 loss_att 266.064514 loss_ctc 14.384703 loss_rnnt 4.969653 lr 0.00026675 rank 2
2022-12-07 23:17:55,550 DEBUG TRAIN Batch 23/1200 loss 15.162620 loss_att 311.352142 loss_ctc 30.185705 loss_rnnt 13.493388 lr 0.00026676 rank 3
2022-12-07 23:17:55,552 DEBUG TRAIN Batch 23/1200 loss 10.728636 loss_att 330.488495 loss_ctc 18.183546 loss_rnnt 9.900312 lr 0.00026674 rank 6
2022-12-07 23:17:55,554 DEBUG TRAIN Batch 23/1200 loss 4.265673 loss_att 283.924072 loss_ctc 11.633727 loss_rnnt 3.447001 lr 0.00026675 rank 1
2022-12-07 23:17:55,561 DEBUG TRAIN Batch 23/1200 loss 3.496646 loss_att 223.216904 loss_ctc 6.580672 loss_rnnt 3.153976 lr 0.00026674 rank 5
2022-12-07 23:18:58,251 DEBUG TRAIN Batch 23/1300 loss 5.201360 loss_att 370.935303 loss_ctc 14.888237 loss_rnnt 4.125040 lr 0.00026670 rank 7
2022-12-07 23:18:58,254 DEBUG TRAIN Batch 23/1300 loss 9.945091 loss_att 419.675476 loss_ctc 20.446369 loss_rnnt 8.778283 lr 0.00026671 rank 4
2022-12-07 23:18:58,256 DEBUG TRAIN Batch 23/1300 loss 5.798439 loss_att 130.995056 loss_ctc 11.974141 loss_rnnt 5.112250 lr 0.00026670 rank 6
2022-12-07 23:18:58,259 DEBUG TRAIN Batch 23/1300 loss 13.662028 loss_att 110.978935 loss_ctc 22.596455 loss_rnnt 12.669314 lr 0.00026672 rank 3
2022-12-07 23:18:58,259 DEBUG TRAIN Batch 23/1300 loss 4.515871 loss_att 361.404236 loss_ctc 14.481998 loss_rnnt 3.408524 lr 0.00026671 rank 1
2022-12-07 23:18:58,260 DEBUG TRAIN Batch 23/1300 loss 3.779865 loss_att 376.532440 loss_ctc 12.807833 loss_rnnt 2.776758 lr 0.00026671 rank 0
2022-12-07 23:18:58,261 DEBUG TRAIN Batch 23/1300 loss 6.023034 loss_att 437.516937 loss_ctc 17.032162 loss_rnnt 4.799798 lr 0.00026671 rank 2
2022-12-07 23:18:58,267 DEBUG TRAIN Batch 23/1300 loss 7.784755 loss_att 403.702332 loss_ctc 20.332600 loss_rnnt 6.390550 lr 0.00026670 rank 5
2022-12-07 23:20:02,752 DEBUG TRAIN Batch 23/1400 loss 10.292661 loss_att 402.170746 loss_ctc 17.756784 loss_rnnt 9.463314 lr 0.00026668 rank 3
2022-12-07 23:20:02,754 DEBUG TRAIN Batch 23/1400 loss 9.890051 loss_att 359.214478 loss_ctc 20.896240 loss_rnnt 8.667141 lr 0.00026667 rank 6
2022-12-07 23:20:02,754 DEBUG TRAIN Batch 23/1400 loss 9.397881 loss_att 337.530945 loss_ctc 16.018353 loss_rnnt 8.662273 lr 0.00026668 rank 1
2022-12-07 23:20:02,754 DEBUG TRAIN Batch 23/1400 loss 4.086149 loss_att 408.434906 loss_ctc 12.282047 loss_rnnt 3.175494 lr 0.00026667 rank 4
2022-12-07 23:20:02,755 DEBUG TRAIN Batch 23/1400 loss 7.922077 loss_att 406.716736 loss_ctc 20.516148 loss_rnnt 6.522736 lr 0.00026667 rank 7
2022-12-07 23:20:02,755 DEBUG TRAIN Batch 23/1400 loss 10.159543 loss_att 404.606049 loss_ctc 20.285666 loss_rnnt 9.034419 lr 0.00026667 rank 2
2022-12-07 23:20:02,759 DEBUG TRAIN Batch 23/1400 loss 3.919847 loss_att 381.228027 loss_ctc 8.241638 loss_rnnt 3.439648 lr 0.00026667 rank 0
2022-12-07 23:20:02,802 DEBUG TRAIN Batch 23/1400 loss 6.763919 loss_att 398.301605 loss_ctc 17.096600 loss_rnnt 5.615844 lr 0.00026667 rank 5
2022-12-07 23:21:15,294 DEBUG TRAIN Batch 23/1500 loss 9.033973 loss_att 428.385132 loss_ctc 19.247765 loss_rnnt 7.899107 lr 0.00026664 rank 0
2022-12-07 23:21:15,294 DEBUG TRAIN Batch 23/1500 loss 4.437163 loss_att 375.488159 loss_ctc 8.144424 loss_rnnt 4.025245 lr 0.00026663 rank 4
2022-12-07 23:21:15,296 DEBUG TRAIN Batch 23/1500 loss 1.111406 loss_att 347.672363 loss_ctc 1.951251 loss_rnnt 1.018090 lr 0.00026663 rank 7
2022-12-07 23:21:15,297 DEBUG TRAIN Batch 23/1500 loss 5.933826 loss_att 406.940521 loss_ctc 16.063705 loss_rnnt 4.808285 lr 0.00026663 rank 6
2022-12-07 23:21:15,300 DEBUG TRAIN Batch 23/1500 loss 7.061448 loss_att 419.048676 loss_ctc 13.176989 loss_rnnt 6.381944 lr 0.00026664 rank 2
2022-12-07 23:21:15,304 DEBUG TRAIN Batch 23/1500 loss 7.530891 loss_att 371.040039 loss_ctc 11.995289 loss_rnnt 7.034847 lr 0.00026664 rank 3
2022-12-07 23:21:15,307 DEBUG TRAIN Batch 23/1500 loss 7.674882 loss_att 313.195312 loss_ctc 18.942495 loss_rnnt 6.422925 lr 0.00026663 rank 5
2022-12-07 23:21:15,342 DEBUG TRAIN Batch 23/1500 loss 9.321266 loss_att 426.994232 loss_ctc 23.331030 loss_rnnt 7.764627 lr 0.00026664 rank 1
2022-12-07 23:22:17,700 DEBUG TRAIN Batch 23/1600 loss 3.884387 loss_att 353.078979 loss_ctc 10.443624 loss_rnnt 3.155583 lr 0.00026659 rank 7
2022-12-07 23:22:17,701 DEBUG TRAIN Batch 23/1600 loss 5.506842 loss_att 301.997040 loss_ctc 8.405910 loss_rnnt 5.184723 lr 0.00026660 rank 1
2022-12-07 23:22:17,701 DEBUG TRAIN Batch 23/1600 loss 2.620279 loss_att 303.337372 loss_ctc 4.040723 loss_rnnt 2.462452 lr 0.00026660 rank 3
2022-12-07 23:22:17,703 DEBUG TRAIN Batch 23/1600 loss 7.842242 loss_att 406.045837 loss_ctc 19.287374 loss_rnnt 6.570561 lr 0.00026659 rank 6
2022-12-07 23:22:17,703 DEBUG TRAIN Batch 23/1600 loss 4.163440 loss_att 395.099976 loss_ctc 8.465698 loss_rnnt 3.685412 lr 0.00026659 rank 4
2022-12-07 23:22:17,704 DEBUG TRAIN Batch 23/1600 loss 3.943997 loss_att 369.250763 loss_ctc 9.209682 loss_rnnt 3.358921 lr 0.00026660 rank 0
2022-12-07 23:22:17,706 DEBUG TRAIN Batch 23/1600 loss 9.029839 loss_att 381.836487 loss_ctc 18.747643 loss_rnnt 7.950082 lr 0.00026660 rank 2
2022-12-07 23:22:17,706 DEBUG TRAIN Batch 23/1600 loss 8.228628 loss_att 360.776672 loss_ctc 16.376377 loss_rnnt 7.323323 lr 0.00026659 rank 5
2022-12-07 23:23:21,523 DEBUG TRAIN Batch 23/1700 loss 8.183468 loss_att 338.943665 loss_ctc 17.328930 loss_rnnt 7.167306 lr 0.00026655 rank 5
2022-12-07 23:23:21,523 DEBUG TRAIN Batch 23/1700 loss 6.001142 loss_att 341.993805 loss_ctc 13.887188 loss_rnnt 5.124914 lr 0.00026656 rank 4
2022-12-07 23:23:21,527 DEBUG TRAIN Batch 23/1700 loss 13.427097 loss_att 394.822174 loss_ctc 28.069214 loss_rnnt 11.800196 lr 0.00026656 rank 2
2022-12-07 23:23:21,529 DEBUG TRAIN Batch 23/1700 loss 7.579070 loss_att 356.820557 loss_ctc 15.976799 loss_rnnt 6.645988 lr 0.00026657 rank 3
2022-12-07 23:23:21,534 DEBUG TRAIN Batch 23/1700 loss 4.691896 loss_att 396.620911 loss_ctc 12.325352 loss_rnnt 3.843734 lr 0.00026656 rank 1
2022-12-07 23:23:21,536 DEBUG TRAIN Batch 23/1700 loss 8.647962 loss_att 318.509277 loss_ctc 21.333866 loss_rnnt 7.238417 lr 0.00026655 rank 7
2022-12-07 23:23:21,536 DEBUG TRAIN Batch 23/1700 loss 6.232079 loss_att 308.377838 loss_ctc 10.032425 loss_rnnt 5.809818 lr 0.00026656 rank 0
2022-12-07 23:23:21,575 DEBUG TRAIN Batch 23/1700 loss 6.347422 loss_att 335.626099 loss_ctc 13.505283 loss_rnnt 5.552104 lr 0.00026655 rank 6
2022-12-07 23:24:32,941 DEBUG TRAIN Batch 23/1800 loss 6.668782 loss_att 359.207092 loss_ctc 10.924349 loss_rnnt 6.195942 lr 0.00026652 rank 4
2022-12-07 23:24:32,942 DEBUG TRAIN Batch 23/1800 loss 6.994344 loss_att 302.351044 loss_ctc 11.138327 loss_rnnt 6.533901 lr 0.00026652 rank 6
2022-12-07 23:24:32,945 DEBUG TRAIN Batch 23/1800 loss 20.083651 loss_att 259.294617 loss_ctc 40.292492 loss_rnnt 17.838224 lr 0.00026651 rank 7
2022-12-07 23:24:32,946 DEBUG TRAIN Batch 23/1800 loss 7.669252 loss_att 307.014496 loss_ctc 14.588614 loss_rnnt 6.900434 lr 0.00026653 rank 1
2022-12-07 23:24:32,946 DEBUG TRAIN Batch 23/1800 loss 10.027212 loss_att 293.242798 loss_ctc 18.280197 loss_rnnt 9.110213 lr 0.00026652 rank 0
2022-12-07 23:24:32,947 DEBUG TRAIN Batch 23/1800 loss 8.814510 loss_att 335.001343 loss_ctc 14.863806 loss_rnnt 8.142366 lr 0.00026653 rank 3
2022-12-07 23:24:32,954 DEBUG TRAIN Batch 23/1800 loss 6.368707 loss_att 261.663635 loss_ctc 10.110185 loss_rnnt 5.952987 lr 0.00026651 rank 5
2022-12-07 23:24:32,992 DEBUG TRAIN Batch 23/1800 loss 5.817475 loss_att 360.196259 loss_ctc 17.313929 loss_rnnt 4.540091 lr 0.00026652 rank 2
2022-12-07 23:25:36,038 DEBUG TRAIN Batch 23/1900 loss 12.038104 loss_att 439.207855 loss_ctc 25.976635 loss_rnnt 10.489378 lr 0.00026648 rank 7
2022-12-07 23:25:36,042 DEBUG TRAIN Batch 23/1900 loss 6.769692 loss_att 191.792572 loss_ctc 12.782454 loss_rnnt 6.101608 lr 0.00026649 rank 3
2022-12-07 23:25:36,042 DEBUG TRAIN Batch 23/1900 loss 7.533340 loss_att 163.561157 loss_ctc 14.919248 loss_rnnt 6.712684 lr 0.00026648 rank 4
2022-12-07 23:25:36,043 DEBUG TRAIN Batch 23/1900 loss 7.545097 loss_att 150.904968 loss_ctc 13.234449 loss_rnnt 6.912948 lr 0.00026649 rank 1
2022-12-07 23:25:36,043 DEBUG TRAIN Batch 23/1900 loss 13.955868 loss_att 186.113541 loss_ctc 23.467987 loss_rnnt 12.898966 lr 0.00026648 rank 6
2022-12-07 23:25:36,044 DEBUG TRAIN Batch 23/1900 loss 9.759604 loss_att 335.521851 loss_ctc 20.501276 loss_rnnt 8.566084 lr 0.00026648 rank 5
2022-12-07 23:25:36,048 DEBUG TRAIN Batch 23/1900 loss 6.483241 loss_att 457.329834 loss_ctc 9.578477 loss_rnnt 6.139326 lr 0.00026648 rank 0
2022-12-07 23:25:36,049 DEBUG TRAIN Batch 23/1900 loss 11.660583 loss_att 203.899124 loss_ctc 19.300800 loss_rnnt 10.811670 lr 0.00026649 rank 2
2022-12-07 23:26:39,151 DEBUG TRAIN Batch 23/2000 loss 5.828696 loss_att 356.360046 loss_ctc 9.836699 loss_rnnt 5.383363 lr 0.00026644 rank 7
2022-12-07 23:26:39,152 DEBUG TRAIN Batch 23/2000 loss 8.284492 loss_att 468.108398 loss_ctc 17.933014 loss_rnnt 7.212434 lr 0.00026645 rank 1
2022-12-07 23:26:39,154 DEBUG TRAIN Batch 23/2000 loss 9.430611 loss_att 393.533875 loss_ctc 15.136485 loss_rnnt 8.796624 lr 0.00026645 rank 2
2022-12-07 23:26:39,155 DEBUG TRAIN Batch 23/2000 loss 13.248768 loss_att 354.565918 loss_ctc 30.943121 loss_rnnt 11.282728 lr 0.00026644 rank 5
2022-12-07 23:26:39,155 DEBUG TRAIN Batch 23/2000 loss 5.696394 loss_att 286.950684 loss_ctc 11.742801 loss_rnnt 5.024571 lr 0.00026644 rank 4
2022-12-07 23:26:39,156 DEBUG TRAIN Batch 23/2000 loss 5.316607 loss_att 353.235779 loss_ctc 9.210244 loss_rnnt 4.883981 lr 0.00026645 rank 0
2022-12-07 23:26:39,156 DEBUG TRAIN Batch 23/2000 loss 7.334191 loss_att 392.711426 loss_ctc 10.244751 loss_rnnt 7.010796 lr 0.00026645 rank 3
2022-12-07 23:26:39,157 DEBUG TRAIN Batch 23/2000 loss 11.336336 loss_att 388.974701 loss_ctc 23.923775 loss_rnnt 9.937732 lr 0.00026644 rank 6
2022-12-07 23:27:43,919 DEBUG TRAIN Batch 23/2100 loss 4.545793 loss_att 352.897217 loss_ctc 10.962188 loss_rnnt 3.832860 lr 0.00026641 rank 2
2022-12-07 23:27:43,920 DEBUG TRAIN Batch 23/2100 loss 9.154744 loss_att 409.883545 loss_ctc 24.028479 loss_rnnt 7.502107 lr 0.00026640 rank 6
2022-12-07 23:27:43,923 DEBUG TRAIN Batch 23/2100 loss 16.264845 loss_att 328.770325 loss_ctc 27.805298 loss_rnnt 14.982573 lr 0.00026640 rank 7
2022-12-07 23:27:43,924 DEBUG TRAIN Batch 23/2100 loss 8.835017 loss_att 382.485535 loss_ctc 17.180840 loss_rnnt 7.907703 lr 0.00026642 rank 3
2022-12-07 23:27:43,924 DEBUG TRAIN Batch 23/2100 loss 6.319832 loss_att 412.428406 loss_ctc 13.601954 loss_rnnt 5.510707 lr 0.00026641 rank 0
2022-12-07 23:27:43,929 DEBUG TRAIN Batch 23/2100 loss 13.268286 loss_att 424.206543 loss_ctc 23.827404 loss_rnnt 12.095051 lr 0.00026641 rank 1
2022-12-07 23:27:43,931 DEBUG TRAIN Batch 23/2100 loss 6.140691 loss_att 365.851074 loss_ctc 15.428050 loss_rnnt 5.108762 lr 0.00026641 rank 4
2022-12-07 23:27:43,934 DEBUG TRAIN Batch 23/2100 loss 12.400991 loss_att 367.664276 loss_ctc 18.432856 loss_rnnt 11.730784 lr 0.00026640 rank 5
2022-12-07 23:28:54,834 DEBUG TRAIN Batch 23/2200 loss 9.371088 loss_att 396.345856 loss_ctc 13.513727 loss_rnnt 8.910795 lr 0.00026637 rank 4
2022-12-07 23:28:54,842 DEBUG TRAIN Batch 23/2200 loss 6.184344 loss_att 333.618530 loss_ctc 13.805658 loss_rnnt 5.337532 lr 0.00026636 rank 7
2022-12-07 23:28:54,842 DEBUG TRAIN Batch 23/2200 loss 4.710821 loss_att 369.406708 loss_ctc 9.225907 loss_rnnt 4.209145 lr 0.00026636 rank 5
2022-12-07 23:28:54,850 DEBUG TRAIN Batch 23/2200 loss 8.621331 loss_att 316.375183 loss_ctc 14.498156 loss_rnnt 7.968351 lr 0.00026637 rank 0
2022-12-07 23:28:54,851 DEBUG TRAIN Batch 23/2200 loss 4.273000 loss_att 379.757202 loss_ctc 8.988776 loss_rnnt 3.749025 lr 0.00026637 rank 1
2022-12-07 23:28:54,851 DEBUG TRAIN Batch 23/2200 loss 8.267220 loss_att 426.488159 loss_ctc 23.213928 loss_rnnt 6.606475 lr 0.00026638 rank 3
2022-12-07 23:28:54,852 DEBUG TRAIN Batch 23/2200 loss 3.441913 loss_att 303.151764 loss_ctc 6.362686 loss_rnnt 3.117383 lr 0.00026636 rank 6
2022-12-07 23:28:54,852 DEBUG TRAIN Batch 23/2200 loss 9.032225 loss_att 342.295105 loss_ctc 16.557934 loss_rnnt 8.196035 lr 0.00026637 rank 2
2022-12-07 23:29:57,250 DEBUG TRAIN Batch 23/2300 loss 9.151142 loss_att 304.358704 loss_ctc 20.221539 loss_rnnt 7.921098 lr 0.00026633 rank 6
2022-12-07 23:29:57,252 DEBUG TRAIN Batch 23/2300 loss 8.168117 loss_att 368.648438 loss_ctc 16.486393 loss_rnnt 7.243864 lr 0.00026633 rank 0
2022-12-07 23:29:57,251 DEBUG TRAIN Batch 23/2300 loss 9.104231 loss_att 304.924011 loss_ctc 14.888974 loss_rnnt 8.461482 lr 0.00026633 rank 5
2022-12-07 23:29:57,252 DEBUG TRAIN Batch 23/2300 loss 8.486827 loss_att 353.264252 loss_ctc 13.932289 loss_rnnt 7.881776 lr 0.00026633 rank 4
2022-12-07 23:29:57,252 DEBUG TRAIN Batch 23/2300 loss 11.673496 loss_att 395.430756 loss_ctc 29.026440 loss_rnnt 9.745392 lr 0.00026634 rank 1
2022-12-07 23:29:57,252 DEBUG TRAIN Batch 23/2300 loss 11.042378 loss_att 359.207336 loss_ctc 19.681692 loss_rnnt 10.082455 lr 0.00026634 rank 3
2022-12-07 23:29:57,254 DEBUG TRAIN Batch 23/2300 loss 10.163757 loss_att 374.091675 loss_ctc 18.843311 loss_rnnt 9.199363 lr 0.00026633 rank 7
2022-12-07 23:29:57,254 DEBUG TRAIN Batch 23/2300 loss 7.446914 loss_att 320.068756 loss_ctc 16.665899 loss_rnnt 6.422582 lr 0.00026633 rank 2
2022-12-07 23:31:00,488 DEBUG TRAIN Batch 23/2400 loss 5.294272 loss_att 358.883636 loss_ctc 9.665909 loss_rnnt 4.808535 lr 0.00026630 rank 2
2022-12-07 23:31:00,490 DEBUG TRAIN Batch 23/2400 loss 9.118026 loss_att 313.122375 loss_ctc 16.492023 loss_rnnt 8.298693 lr 0.00026630 rank 0
2022-12-07 23:31:00,491 DEBUG TRAIN Batch 23/2400 loss 5.030680 loss_att 288.762451 loss_ctc 9.097075 loss_rnnt 4.578858 lr 0.00026629 rank 7
2022-12-07 23:31:00,491 DEBUG TRAIN Batch 23/2400 loss 7.191703 loss_att 397.499268 loss_ctc 16.209568 loss_rnnt 6.189718 lr 0.00026629 rank 4
2022-12-07 23:31:00,492 DEBUG TRAIN Batch 23/2400 loss 8.071953 loss_att 363.987183 loss_ctc 15.848660 loss_rnnt 7.207875 lr 0.00026629 rank 6
2022-12-07 23:31:00,494 DEBUG TRAIN Batch 23/2400 loss 3.098295 loss_att 343.061859 loss_ctc 8.713953 loss_rnnt 2.474333 lr 0.00026630 rank 3
2022-12-07 23:31:00,497 DEBUG TRAIN Batch 23/2400 loss 5.079497 loss_att 321.365112 loss_ctc 9.785785 loss_rnnt 4.556576 lr 0.00026629 rank 5
2022-12-07 23:31:00,528 DEBUG TRAIN Batch 23/2400 loss 10.687935 loss_att 327.033752 loss_ctc 20.411777 loss_rnnt 9.607508 lr 0.00026630 rank 1
2022-12-07 23:32:13,761 DEBUG TRAIN Batch 23/2500 loss 6.571559 loss_att 125.207596 loss_ctc 12.327868 loss_rnnt 5.931970 lr 0.00026625 rank 7
2022-12-07 23:32:13,761 DEBUG TRAIN Batch 23/2500 loss 8.249920 loss_att 204.912750 loss_ctc 14.211065 loss_rnnt 7.587570 lr 0.00026625 rank 4
2022-12-07 23:32:13,762 DEBUG TRAIN Batch 23/2500 loss 5.881007 loss_att 288.450165 loss_ctc 12.661255 loss_rnnt 5.127646 lr 0.00026626 rank 3
2022-12-07 23:32:13,763 DEBUG TRAIN Batch 23/2500 loss 12.414150 loss_att 239.356842 loss_ctc 23.464155 loss_rnnt 11.186372 lr 0.00026626 rank 0
2022-12-07 23:32:13,764 DEBUG TRAIN Batch 23/2500 loss 8.686542 loss_att 289.108948 loss_ctc 15.122067 loss_rnnt 7.971484 lr 0.00026626 rank 1
2022-12-07 23:32:13,774 DEBUG TRAIN Batch 23/2500 loss 8.579236 loss_att 95.983040 loss_ctc 13.296387 loss_rnnt 8.055108 lr 0.00026625 rank 5
2022-12-07 23:32:13,775 DEBUG TRAIN Batch 23/2500 loss 5.643221 loss_att 260.533020 loss_ctc 8.571064 loss_rnnt 5.317905 lr 0.00026626 rank 2
2022-12-07 23:32:13,808 DEBUG TRAIN Batch 23/2500 loss 10.895550 loss_att 258.058685 loss_ctc 18.614868 loss_rnnt 10.037848 lr 0.00026625 rank 6
2022-12-07 23:33:17,430 DEBUG TRAIN Batch 23/2600 loss 11.556888 loss_att 431.833191 loss_ctc 24.546825 loss_rnnt 10.113562 lr 0.00026622 rank 4
2022-12-07 23:33:17,446 DEBUG TRAIN Batch 23/2600 loss 3.669101 loss_att 398.715668 loss_ctc 10.060509 loss_rnnt 2.958945 lr 0.00026622 rank 2
2022-12-07 23:33:17,448 DEBUG TRAIN Batch 23/2600 loss 7.114424 loss_att 385.379822 loss_ctc 15.555222 loss_rnnt 6.176557 lr 0.00026621 rank 7
2022-12-07 23:33:17,452 DEBUG TRAIN Batch 23/2600 loss 2.485497 loss_att 402.549255 loss_ctc 6.345207 loss_rnnt 2.056640 lr 0.00026622 rank 1
2022-12-07 23:33:17,452 DEBUG TRAIN Batch 23/2600 loss 5.196218 loss_att 409.087585 loss_ctc 11.406618 loss_rnnt 4.506174 lr 0.00026622 rank 0
2022-12-07 23:33:17,454 DEBUG TRAIN Batch 23/2600 loss 6.450716 loss_att 284.335571 loss_ctc 13.261324 loss_rnnt 5.693982 lr 0.00026621 rank 5
2022-12-07 23:33:17,457 DEBUG TRAIN Batch 23/2600 loss 4.532997 loss_att 383.662292 loss_ctc 12.109478 loss_rnnt 3.691166 lr 0.00026621 rank 6
2022-12-07 23:33:17,460 DEBUG TRAIN Batch 23/2600 loss 6.602601 loss_att 313.087738 loss_ctc 14.999724 loss_rnnt 5.669588 lr 0.00026623 rank 3
2022-12-07 23:34:20,061 DEBUG TRAIN Batch 23/2700 loss 9.713336 loss_att 363.339294 loss_ctc 25.192009 loss_rnnt 7.993484 lr 0.00026618 rank 4
2022-12-07 23:34:20,063 DEBUG TRAIN Batch 23/2700 loss 13.088529 loss_att 399.808563 loss_ctc 17.059792 loss_rnnt 12.647278 lr 0.00026619 rank 3
2022-12-07 23:34:20,064 DEBUG TRAIN Batch 23/2700 loss 4.869881 loss_att 338.389648 loss_ctc 9.509704 loss_rnnt 4.354345 lr 0.00026618 rank 0
2022-12-07 23:34:20,065 DEBUG TRAIN Batch 23/2700 loss 4.346339 loss_att 440.886963 loss_ctc 6.289022 loss_rnnt 4.130486 lr 0.00026617 rank 7
2022-12-07 23:34:20,068 DEBUG TRAIN Batch 23/2700 loss 7.310455 loss_att 360.949799 loss_ctc 14.872675 loss_rnnt 6.470209 lr 0.00026617 rank 5
2022-12-07 23:34:20,070 DEBUG TRAIN Batch 23/2700 loss 5.194800 loss_att 343.445251 loss_ctc 10.426548 loss_rnnt 4.613495 lr 0.00026618 rank 2
2022-12-07 23:34:20,070 DEBUG TRAIN Batch 23/2700 loss 6.969862 loss_att 310.906097 loss_ctc 11.760515 loss_rnnt 6.437568 lr 0.00026618 rank 1
2022-12-07 23:34:20,114 DEBUG TRAIN Batch 23/2700 loss 3.918824 loss_att 409.376068 loss_ctc 13.737099 loss_rnnt 2.827904 lr 0.00026618 rank 6
2022-12-07 23:35:24,596 DEBUG TRAIN Batch 23/2800 loss 2.662700 loss_att 382.983246 loss_ctc 7.762512 loss_rnnt 2.096054 lr 0.00026614 rank 4
2022-12-07 23:35:24,598 DEBUG TRAIN Batch 23/2800 loss 7.719617 loss_att 397.673645 loss_ctc 30.044271 loss_rnnt 5.239100 lr 0.00026614 rank 6
2022-12-07 23:35:24,598 DEBUG TRAIN Batch 23/2800 loss 7.659680 loss_att 390.117798 loss_ctc 15.978862 loss_rnnt 6.735327 lr 0.00026615 rank 3
2022-12-07 23:35:24,599 DEBUG TRAIN Batch 23/2800 loss 4.908224 loss_att 331.487793 loss_ctc 11.178686 loss_rnnt 4.211506 lr 0.00026614 rank 5
2022-12-07 23:35:24,600 DEBUG TRAIN Batch 23/2800 loss 6.749969 loss_att 387.607849 loss_ctc 14.188464 loss_rnnt 5.923469 lr 0.00026615 rank 1
2022-12-07 23:35:24,602 DEBUG TRAIN Batch 23/2800 loss 10.696472 loss_att 392.423553 loss_ctc 21.668051 loss_rnnt 9.477407 lr 0.00026614 rank 7
2022-12-07 23:35:24,607 DEBUG TRAIN Batch 23/2800 loss 5.801906 loss_att 381.195007 loss_ctc 13.274153 loss_rnnt 4.971656 lr 0.00026615 rank 0
2022-12-07 23:35:24,641 DEBUG TRAIN Batch 23/2800 loss 2.757997 loss_att 380.041931 loss_ctc 4.450483 loss_rnnt 2.569942 lr 0.00026615 rank 2
2022-12-07 23:36:35,281 DEBUG TRAIN Batch 23/2900 loss 4.437551 loss_att 300.035828 loss_ctc 7.163442 loss_rnnt 4.134675 lr 0.00026610 rank 6
2022-12-07 23:36:35,281 DEBUG TRAIN Batch 23/2900 loss 16.734350 loss_att 388.745911 loss_ctc 27.360577 loss_rnnt 15.553658 lr 0.00026611 rank 2
2022-12-07 23:36:35,281 DEBUG TRAIN Batch 23/2900 loss 8.284329 loss_att 385.030090 loss_ctc 16.244192 loss_rnnt 7.399900 lr 0.00026610 rank 7
2022-12-07 23:36:35,281 DEBUG TRAIN Batch 23/2900 loss 10.923632 loss_att 439.592255 loss_ctc 21.844864 loss_rnnt 9.710162 lr 0.00026610 rank 4
2022-12-07 23:36:35,282 DEBUG TRAIN Batch 23/2900 loss 9.886431 loss_att 353.049286 loss_ctc 16.892801 loss_rnnt 9.107944 lr 0.00026611 rank 1
2022-12-07 23:36:35,285 DEBUG TRAIN Batch 23/2900 loss 6.515842 loss_att 362.440430 loss_ctc 11.662754 loss_rnnt 5.943963 lr 0.00026611 rank 3
2022-12-07 23:36:35,287 DEBUG TRAIN Batch 23/2900 loss 7.886111 loss_att 350.135773 loss_ctc 13.769186 loss_rnnt 7.232436 lr 0.00026610 rank 5
2022-12-07 23:36:35,290 DEBUG TRAIN Batch 23/2900 loss 8.018096 loss_att 333.753296 loss_ctc 17.088465 loss_rnnt 7.010278 lr 0.00026611 rank 0
2022-12-07 23:37:38,289 DEBUG TRAIN Batch 23/3000 loss 5.357383 loss_att 374.134430 loss_ctc 11.985747 loss_rnnt 4.620898 lr 0.00026606 rank 7
2022-12-07 23:37:38,290 DEBUG TRAIN Batch 23/3000 loss 4.446784 loss_att 333.742798 loss_ctc 6.403216 loss_rnnt 4.229403 lr 0.00026606 rank 6
2022-12-07 23:37:38,290 DEBUG TRAIN Batch 23/3000 loss 15.487990 loss_att 387.728210 loss_ctc 35.659824 loss_rnnt 13.246675 lr 0.00026607 rank 4
2022-12-07 23:37:38,294 DEBUG TRAIN Batch 23/3000 loss 15.325788 loss_att 394.365021 loss_ctc 29.936993 loss_rnnt 13.702321 lr 0.00026607 rank 1
2022-12-07 23:37:38,297 DEBUG TRAIN Batch 23/3000 loss 8.339822 loss_att 305.917725 loss_ctc 16.063257 loss_rnnt 7.481663 lr 0.00026606 rank 5
2022-12-07 23:37:38,298 DEBUG TRAIN Batch 23/3000 loss 7.260277 loss_att 333.206848 loss_ctc 13.507068 loss_rnnt 6.566189 lr 0.00026607 rank 2
2022-12-07 23:37:38,305 DEBUG TRAIN Batch 23/3000 loss 10.693324 loss_att 297.296326 loss_ctc 17.184723 loss_rnnt 9.972057 lr 0.00026607 rank 0
2022-12-07 23:37:38,336 DEBUG TRAIN Batch 23/3000 loss 14.833652 loss_att 372.481628 loss_ctc 23.323965 loss_rnnt 13.890285 lr 0.00026608 rank 3
2022-12-07 23:38:41,825 DEBUG TRAIN Batch 23/3100 loss 8.902068 loss_att 277.145660 loss_ctc 12.963767 loss_rnnt 8.450768 lr 0.00026602 rank 7
2022-12-07 23:38:41,839 DEBUG TRAIN Batch 23/3100 loss 6.290314 loss_att 316.329193 loss_ctc 9.499658 loss_rnnt 5.933720 lr 0.00026602 rank 6
2022-12-07 23:38:41,839 DEBUG TRAIN Batch 23/3100 loss 8.417814 loss_att 173.537231 loss_ctc 15.641704 loss_rnnt 7.615160 lr 0.00026602 rank 5
2022-12-07 23:38:41,839 DEBUG TRAIN Batch 23/3100 loss 7.587072 loss_att 370.036102 loss_ctc 18.856316 loss_rnnt 6.334934 lr 0.00026603 rank 1
2022-12-07 23:38:41,842 DEBUG TRAIN Batch 23/3100 loss 5.926429 loss_att 187.161194 loss_ctc 11.180113 loss_rnnt 5.342687 lr 0.00026603 rank 2
2022-12-07 23:38:41,842 DEBUG TRAIN Batch 23/3100 loss 8.067044 loss_att 267.238739 loss_ctc 14.495931 loss_rnnt 7.352724 lr 0.00026603 rank 0
2022-12-07 23:38:41,844 DEBUG TRAIN Batch 23/3100 loss 8.199245 loss_att 254.850784 loss_ctc 10.502824 loss_rnnt 7.943292 lr 0.00026603 rank 4
2022-12-07 23:38:41,858 DEBUG TRAIN Batch 23/3100 loss 4.647852 loss_att 261.276337 loss_ctc 10.890831 loss_rnnt 3.954188 lr 0.00026604 rank 3
2022-12-07 23:39:53,420 DEBUG TRAIN Batch 23/3200 loss 9.829185 loss_att 126.769096 loss_ctc 16.894573 loss_rnnt 9.044143 lr 0.00026599 rank 4
2022-12-07 23:39:53,421 DEBUG TRAIN Batch 23/3200 loss 2.313560 loss_att 452.078491 loss_ctc 9.107101 loss_rnnt 1.558723 lr 0.00026599 rank 7
2022-12-07 23:39:53,423 DEBUG TRAIN Batch 23/3200 loss 8.915371 loss_att 99.816132 loss_ctc 14.607110 loss_rnnt 8.282955 lr 0.00026600 rank 3
2022-12-07 23:39:53,424 DEBUG TRAIN Batch 23/3200 loss 3.886385 loss_att 465.801880 loss_ctc 10.788231 loss_rnnt 3.119513 lr 0.00026599 rank 0
2022-12-07 23:39:53,423 DEBUG TRAIN Batch 23/3200 loss 14.415675 loss_att 233.134247 loss_ctc 21.236265 loss_rnnt 13.657832 lr 0.00026600 rank 1
2022-12-07 23:39:53,426 DEBUG TRAIN Batch 23/3200 loss 1.908961 loss_att 341.148346 loss_ctc 7.619925 loss_rnnt 1.274410 lr 0.00026599 rank 2
2022-12-07 23:39:53,427 DEBUG TRAIN Batch 23/3200 loss 29.318203 loss_att 478.204315 loss_ctc 48.866226 loss_rnnt 27.146200 lr 0.00026599 rank 6
2022-12-07 23:39:53,433 DEBUG TRAIN Batch 23/3200 loss 7.279689 loss_att 397.252289 loss_ctc 17.324772 loss_rnnt 6.163569 lr 0.00026599 rank 5
2022-12-07 23:40:57,319 DEBUG TRAIN Batch 23/3300 loss 6.760142 loss_att 467.795776 loss_ctc 20.320118 loss_rnnt 5.253479 lr 0.00026595 rank 7
2022-12-07 23:40:57,326 DEBUG TRAIN Batch 23/3300 loss 8.520441 loss_att 388.654144 loss_ctc 21.166487 loss_rnnt 7.115325 lr 0.00026595 rank 4
2022-12-07 23:40:57,327 DEBUG TRAIN Batch 23/3300 loss 4.050415 loss_att 354.909790 loss_ctc 7.285947 loss_rnnt 3.690912 lr 0.00026595 rank 6
2022-12-07 23:40:57,328 DEBUG TRAIN Batch 23/3300 loss 8.528746 loss_att 341.442383 loss_ctc 17.842018 loss_rnnt 7.493938 lr 0.00026596 rank 0
2022-12-07 23:40:57,331 DEBUG TRAIN Batch 23/3300 loss 2.873847 loss_att 345.114807 loss_ctc 11.180870 loss_rnnt 1.950844 lr 0.00026595 rank 5
2022-12-07 23:40:57,331 DEBUG TRAIN Batch 23/3300 loss 4.052152 loss_att 494.799896 loss_ctc 18.919209 loss_rnnt 2.400257 lr 0.00026596 rank 1
2022-12-07 23:40:57,332 DEBUG TRAIN Batch 23/3300 loss 15.502416 loss_att 338.109558 loss_ctc 23.672684 loss_rnnt 14.594608 lr 0.00026596 rank 2
2022-12-07 23:40:57,338 DEBUG TRAIN Batch 23/3300 loss 2.572710 loss_att 401.275391 loss_ctc 6.561042 loss_rnnt 2.129562 lr 0.00026596 rank 3
2022-12-07 23:42:00,032 DEBUG TRAIN Batch 23/3400 loss 10.033492 loss_att 370.475586 loss_ctc 18.619781 loss_rnnt 9.079460 lr 0.00026592 rank 4
2022-12-07 23:42:00,035 DEBUG TRAIN Batch 23/3400 loss 6.300779 loss_att 365.703186 loss_ctc 12.933653 loss_rnnt 5.563793 lr 0.00026591 rank 6
2022-12-07 23:42:00,038 DEBUG TRAIN Batch 23/3400 loss 3.268498 loss_att 383.735474 loss_ctc 15.200496 loss_rnnt 1.942720 lr 0.00026592 rank 1
2022-12-07 23:42:00,038 DEBUG TRAIN Batch 23/3400 loss 10.350973 loss_att 339.742615 loss_ctc 20.538044 loss_rnnt 9.219077 lr 0.00026592 rank 2
2022-12-07 23:42:00,039 DEBUG TRAIN Batch 23/3400 loss 4.612880 loss_att 358.996155 loss_ctc 10.389000 loss_rnnt 3.971089 lr 0.00026592 rank 0
2022-12-07 23:42:00,042 DEBUG TRAIN Batch 23/3400 loss 10.590995 loss_att 415.457001 loss_ctc 18.450451 loss_rnnt 9.717722 lr 0.00026591 rank 7
2022-12-07 23:42:00,042 DEBUG TRAIN Batch 23/3400 loss 7.110452 loss_att 429.716248 loss_ctc 19.438000 loss_rnnt 5.740725 lr 0.00026591 rank 5
2022-12-07 23:42:00,047 DEBUG TRAIN Batch 23/3400 loss 8.684256 loss_att 440.914551 loss_ctc 36.125145 loss_rnnt 5.635268 lr 0.00026593 rank 3
2022-12-07 23:43:03,918 DEBUG TRAIN Batch 23/3500 loss 3.373435 loss_att 373.668762 loss_ctc 6.370949 loss_rnnt 3.040377 lr 0.00026588 rank 4
2022-12-07 23:43:03,920 DEBUG TRAIN Batch 23/3500 loss 5.551559 loss_att 381.528992 loss_ctc 11.776287 loss_rnnt 4.859923 lr 0.00026587 rank 7
2022-12-07 23:43:03,923 DEBUG TRAIN Batch 23/3500 loss 8.282767 loss_att 408.148682 loss_ctc 20.288559 loss_rnnt 6.948790 lr 0.00026588 rank 0
2022-12-07 23:43:03,928 DEBUG TRAIN Batch 23/3500 loss 7.817684 loss_att 372.635254 loss_ctc 15.408561 loss_rnnt 6.974254 lr 0.00026588 rank 1
2022-12-07 23:43:03,932 DEBUG TRAIN Batch 23/3500 loss 6.641732 loss_att 391.455841 loss_ctc 13.699192 loss_rnnt 5.857570 lr 0.00026588 rank 2
2022-12-07 23:43:03,935 DEBUG TRAIN Batch 23/3500 loss 14.137144 loss_att 425.185913 loss_ctc 33.071903 loss_rnnt 12.033281 lr 0.00026587 rank 5
2022-12-07 23:43:03,945 DEBUG TRAIN Batch 23/3500 loss 5.035123 loss_att 309.334015 loss_ctc 11.218710 loss_rnnt 4.348058 lr 0.00026587 rank 6
2022-12-07 23:43:03,960 DEBUG TRAIN Batch 23/3500 loss 5.189251 loss_att 383.523315 loss_ctc 11.391853 loss_rnnt 4.500073 lr 0.00026589 rank 3
2022-12-07 23:44:21,692 DEBUG TRAIN Batch 23/3600 loss 14.697723 loss_att 375.171387 loss_ctc 21.504169 loss_rnnt 13.941452 lr 0.00026584 rank 4
2022-12-07 23:44:21,694 DEBUG TRAIN Batch 23/3600 loss 11.046392 loss_att 328.351562 loss_ctc 25.783592 loss_rnnt 9.408926 lr 0.00026584 rank 0
2022-12-07 23:44:21,695 DEBUG TRAIN Batch 23/3600 loss 3.480694 loss_att 343.794922 loss_ctc 10.134476 loss_rnnt 2.741385 lr 0.00026584 rank 7
2022-12-07 23:44:21,695 DEBUG TRAIN Batch 23/3600 loss 6.135801 loss_att 251.574615 loss_ctc 15.345610 loss_rnnt 5.112489 lr 0.00026584 rank 6
2022-12-07 23:44:21,696 DEBUG TRAIN Batch 23/3600 loss 11.520924 loss_att 333.402710 loss_ctc 25.280075 loss_rnnt 9.992129 lr 0.00026584 rank 5
2022-12-07 23:44:21,698 DEBUG TRAIN Batch 23/3600 loss 10.466134 loss_att 386.603302 loss_ctc 17.970135 loss_rnnt 9.632357 lr 0.00026585 rank 1
2022-12-07 23:44:21,701 DEBUG TRAIN Batch 23/3600 loss 4.178627 loss_att 365.276031 loss_ctc 10.744577 loss_rnnt 3.449078 lr 0.00026584 rank 2
2022-12-07 23:44:21,746 DEBUG TRAIN Batch 23/3600 loss 7.741773 loss_att 379.050964 loss_ctc 17.751633 loss_rnnt 6.629566 lr 0.00026585 rank 3
2022-12-07 23:45:24,540 DEBUG TRAIN Batch 23/3700 loss 2.219141 loss_att 266.826019 loss_ctc 5.106707 loss_rnnt 1.898301 lr 0.00026580 rank 6
2022-12-07 23:45:24,540 DEBUG TRAIN Batch 23/3700 loss 7.215484 loss_att 305.671600 loss_ctc 14.027518 loss_rnnt 6.458591 lr 0.00026580 rank 7
2022-12-07 23:45:24,541 DEBUG TRAIN Batch 23/3700 loss 3.915729 loss_att 293.346802 loss_ctc 6.917473 loss_rnnt 3.582202 lr 0.00026580 rank 4
2022-12-07 23:45:24,542 DEBUG TRAIN Batch 23/3700 loss 9.477591 loss_att 354.112030 loss_ctc 19.695463 loss_rnnt 8.342272 lr 0.00026581 rank 3
2022-12-07 23:45:24,543 DEBUG TRAIN Batch 23/3700 loss 10.501242 loss_att 311.872345 loss_ctc 19.999636 loss_rnnt 9.445865 lr 0.00026581 rank 2
2022-12-07 23:45:24,546 DEBUG TRAIN Batch 23/3700 loss 3.941898 loss_att 308.483032 loss_ctc 11.410758 loss_rnnt 3.112024 lr 0.00026581 rank 1
2022-12-07 23:45:24,546 DEBUG TRAIN Batch 23/3700 loss 12.715702 loss_att 229.604294 loss_ctc 21.656389 loss_rnnt 11.722293 lr 0.00026580 rank 5
2022-12-07 23:45:24,547 DEBUG TRAIN Batch 23/3700 loss 7.062903 loss_att 356.120605 loss_ctc 17.540724 loss_rnnt 5.898701 lr 0.00026581 rank 0
2022-12-07 23:46:28,086 DEBUG TRAIN Batch 23/3800 loss 14.080913 loss_att 298.883606 loss_ctc 26.337812 loss_rnnt 12.719035 lr 0.00026577 rank 4
2022-12-07 23:46:28,091 DEBUG TRAIN Batch 23/3800 loss 4.812669 loss_att 119.834152 loss_ctc 9.621994 loss_rnnt 4.278299 lr 0.00026576 rank 7
2022-12-07 23:46:28,095 DEBUG TRAIN Batch 23/3800 loss 7.767503 loss_att 73.259346 loss_ctc 12.100075 loss_rnnt 7.286106 lr 0.00026577 rank 2
2022-12-07 23:46:28,096 DEBUG TRAIN Batch 23/3800 loss 9.063810 loss_att 97.913040 loss_ctc 12.431236 loss_rnnt 8.689651 lr 0.00026576 rank 6
2022-12-07 23:46:28,098 DEBUG TRAIN Batch 23/3800 loss 7.885562 loss_att 172.136795 loss_ctc 11.845335 loss_rnnt 7.445587 lr 0.00026577 rank 0
2022-12-07 23:46:28,099 DEBUG TRAIN Batch 23/3800 loss 9.981702 loss_att 292.275543 loss_ctc 15.888643 loss_rnnt 9.325376 lr 0.00026577 rank 1
2022-12-07 23:46:28,119 DEBUG TRAIN Batch 23/3800 loss 8.917271 loss_att 216.047592 loss_ctc 17.755404 loss_rnnt 7.935256 lr 0.00026577 rank 3
2022-12-07 23:46:28,122 DEBUG TRAIN Batch 23/3800 loss 8.119987 loss_att 362.835175 loss_ctc 11.612160 loss_rnnt 7.731967 lr 0.00026576 rank 5
2022-12-07 23:47:51,943 DEBUG TRAIN Batch 23/3900 loss 9.373753 loss_att 305.780518 loss_ctc 17.041435 loss_rnnt 8.521788 lr 0.00026574 rank 3
2022-12-07 23:47:51,944 DEBUG TRAIN Batch 23/3900 loss 2.854678 loss_att 431.046143 loss_ctc 10.627059 loss_rnnt 1.991080 lr 0.00026572 rank 7
2022-12-07 23:47:51,955 DEBUG TRAIN Batch 23/3900 loss 3.809924 loss_att 377.102295 loss_ctc 7.571680 loss_rnnt 3.391951 lr 0.00026572 rank 6
2022-12-07 23:47:51,957 DEBUG TRAIN Batch 23/3900 loss 15.521671 loss_att 410.786194 loss_ctc 28.820282 loss_rnnt 14.044047 lr 0.00026573 rank 2
2022-12-07 23:47:51,982 DEBUG TRAIN Batch 23/3900 loss 8.127272 loss_att 298.286011 loss_ctc 18.354792 loss_rnnt 6.990880 lr 0.00026573 rank 1
2022-12-07 23:47:51,993 DEBUG TRAIN Batch 23/3900 loss 13.078084 loss_att 412.974487 loss_ctc 24.440716 loss_rnnt 11.815569 lr 0.00026573 rank 4
2022-12-07 23:47:51,997 DEBUG TRAIN Batch 23/3900 loss 3.635865 loss_att 388.740906 loss_ctc 9.404301 loss_rnnt 2.994928 lr 0.00026572 rank 5
2022-12-07 23:47:52,001 DEBUG TRAIN Batch 23/3900 loss 5.270051 loss_att 340.248291 loss_ctc 15.399673 loss_rnnt 4.144538 lr 0.00026573 rank 0
2022-12-07 23:48:56,106 DEBUG TRAIN Batch 23/4000 loss 3.049360 loss_att 396.139008 loss_ctc 14.352831 loss_rnnt 1.793418 lr 0.00026569 rank 4
2022-12-07 23:48:56,107 DEBUG TRAIN Batch 23/4000 loss 3.788631 loss_att 348.224731 loss_ctc 7.224445 loss_rnnt 3.406874 lr 0.00026569 rank 7
2022-12-07 23:48:56,109 DEBUG TRAIN Batch 23/4000 loss 2.291588 loss_att 361.063324 loss_ctc 5.658145 loss_rnnt 1.917526 lr 0.00026569 rank 0
2022-12-07 23:48:56,111 DEBUG TRAIN Batch 23/4000 loss 7.400761 loss_att 407.151062 loss_ctc 17.764706 loss_rnnt 6.249212 lr 0.00026569 rank 2
2022-12-07 23:48:56,111 DEBUG TRAIN Batch 23/4000 loss 5.342795 loss_att 351.476501 loss_ctc 14.823040 loss_rnnt 4.289435 lr 0.00026569 rank 5
2022-12-07 23:48:56,113 DEBUG TRAIN Batch 23/4000 loss 6.449581 loss_att 328.669159 loss_ctc 9.524332 loss_rnnt 6.107942 lr 0.00026570 rank 3
2022-12-07 23:48:56,113 DEBUG TRAIN Batch 23/4000 loss 2.597682 loss_att 360.175140 loss_ctc 7.974606 loss_rnnt 2.000247 lr 0.00026570 rank 1
2022-12-07 23:48:56,152 DEBUG TRAIN Batch 23/4000 loss 8.783768 loss_att 372.768066 loss_ctc 17.867268 loss_rnnt 7.774490 lr 0.00026569 rank 6
2022-12-07 23:49:59,115 DEBUG TRAIN Batch 23/4100 loss 11.567994 loss_att 353.154236 loss_ctc 19.667763 loss_rnnt 10.668020 lr 0.00026565 rank 4
2022-12-07 23:49:59,116 DEBUG TRAIN Batch 23/4100 loss 15.182401 loss_att 404.877625 loss_ctc 31.080561 loss_rnnt 13.415938 lr 0.00026566 rank 3
2022-12-07 23:49:59,117 DEBUG TRAIN Batch 23/4100 loss 5.053807 loss_att 372.510101 loss_ctc 12.856399 loss_rnnt 4.186852 lr 0.00026566 rank 1
2022-12-07 23:49:59,118 DEBUG TRAIN Batch 23/4100 loss 13.954080 loss_att 408.462769 loss_ctc 21.260269 loss_rnnt 13.142281 lr 0.00026565 rank 7
2022-12-07 23:49:59,118 DEBUG TRAIN Batch 23/4100 loss 9.896502 loss_att 394.810638 loss_ctc 19.157497 loss_rnnt 8.867502 lr 0.00026566 rank 2
2022-12-07 23:49:59,120 DEBUG TRAIN Batch 23/4100 loss 8.415916 loss_att 315.668274 loss_ctc 10.212751 loss_rnnt 8.216269 lr 0.00026565 rank 5
2022-12-07 23:49:59,127 DEBUG TRAIN Batch 23/4100 loss 8.281088 loss_att 353.310150 loss_ctc 18.644833 loss_rnnt 7.129561 lr 0.00026566 rank 0
2022-12-07 23:49:59,128 DEBUG TRAIN Batch 23/4100 loss 9.203881 loss_att 330.682007 loss_ctc 13.083730 loss_rnnt 8.772787 lr 0.00026565 rank 6
2022-12-07 23:51:02,913 DEBUG TRAIN Batch 23/4200 loss 9.053439 loss_att 345.832397 loss_ctc 15.385517 loss_rnnt 8.349875 lr 0.00026562 rank 0
2022-12-07 23:51:02,916 DEBUG TRAIN Batch 23/4200 loss 13.349750 loss_att 345.420471 loss_ctc 29.558279 loss_rnnt 11.548802 lr 0.00026562 rank 3
2022-12-07 23:51:02,915 DEBUG TRAIN Batch 23/4200 loss 9.902961 loss_att 357.515320 loss_ctc 19.695690 loss_rnnt 8.814880 lr 0.00026561 rank 7
2022-12-07 23:51:02,918 DEBUG TRAIN Batch 23/4200 loss 7.827598 loss_att 381.676392 loss_ctc 16.643280 loss_rnnt 6.848078 lr 0.00026561 rank 4
2022-12-07 23:51:02,919 DEBUG TRAIN Batch 23/4200 loss 5.902497 loss_att 309.111511 loss_ctc 11.950928 loss_rnnt 5.230449 lr 0.00026562 rank 2
2022-12-07 23:51:02,919 DEBUG TRAIN Batch 23/4200 loss 7.461222 loss_att 323.058929 loss_ctc 15.753216 loss_rnnt 6.539889 lr 0.00026561 rank 6
2022-12-07 23:51:02,924 DEBUG TRAIN Batch 23/4200 loss 4.983250 loss_att 422.321350 loss_ctc 10.380957 loss_rnnt 4.383505 lr 0.00026562 rank 1
2022-12-07 23:51:02,958 DEBUG TRAIN Batch 23/4200 loss 10.236852 loss_att 329.037170 loss_ctc 19.147766 loss_rnnt 9.246750 lr 0.00026561 rank 5
2022-12-07 23:52:19,242 DEBUG TRAIN Batch 23/4300 loss 6.051735 loss_att 341.167236 loss_ctc 9.391706 loss_rnnt 5.680627 lr 0.00026558 rank 1
2022-12-07 23:52:19,251 DEBUG TRAIN Batch 23/4300 loss 8.003134 loss_att 381.343353 loss_ctc 15.538391 loss_rnnt 7.165883 lr 0.00026558 rank 4
2022-12-07 23:52:19,253 DEBUG TRAIN Batch 23/4300 loss 7.736324 loss_att 380.324219 loss_ctc 13.454545 loss_rnnt 7.100966 lr 0.00026558 rank 2
2022-12-07 23:52:19,253 DEBUG TRAIN Batch 23/4300 loss 7.635103 loss_att 260.082428 loss_ctc 12.200995 loss_rnnt 7.127782 lr 0.00026557 rank 5
2022-12-07 23:52:19,254 DEBUG TRAIN Batch 23/4300 loss 3.855095 loss_att 333.101135 loss_ctc 5.498708 loss_rnnt 3.672472 lr 0.00026559 rank 3
2022-12-07 23:52:19,255 DEBUG TRAIN Batch 23/4300 loss 9.244990 loss_att 288.584717 loss_ctc 16.836554 loss_rnnt 8.401484 lr 0.00026558 rank 0
2022-12-07 23:52:19,256 DEBUG TRAIN Batch 23/4300 loss 22.614496 loss_att 310.084961 loss_ctc 37.704662 loss_rnnt 20.937813 lr 0.00026557 rank 7
2022-12-07 23:52:19,257 DEBUG TRAIN Batch 23/4300 loss 8.954199 loss_att 395.891998 loss_ctc 19.319996 loss_rnnt 7.802444 lr 0.00026557 rank 6
2022-12-07 23:53:22,736 DEBUG TRAIN Batch 23/4400 loss 7.981425 loss_att 275.792480 loss_ctc 20.596563 loss_rnnt 6.579744 lr 0.00026554 rank 4
2022-12-07 23:53:22,736 DEBUG TRAIN Batch 23/4400 loss 9.339439 loss_att 220.903778 loss_ctc 14.506806 loss_rnnt 8.765287 lr 0.00026554 rank 6
2022-12-07 23:53:22,737 DEBUG TRAIN Batch 23/4400 loss 7.900732 loss_att 236.713226 loss_ctc 17.316914 loss_rnnt 6.854489 lr 0.00026554 rank 2
2022-12-07 23:53:22,738 DEBUG TRAIN Batch 23/4400 loss 9.168744 loss_att 276.318604 loss_ctc 20.269781 loss_rnnt 7.935295 lr 0.00026554 rank 0
2022-12-07 23:53:22,738 DEBUG TRAIN Batch 23/4400 loss 6.892418 loss_att 377.418640 loss_ctc 18.487045 loss_rnnt 5.604126 lr 0.00026555 rank 1
2022-12-07 23:53:22,738 DEBUG TRAIN Batch 23/4400 loss 10.604883 loss_att 238.943115 loss_ctc 20.389091 loss_rnnt 9.517750 lr 0.00026554 rank 7
2022-12-07 23:53:22,740 DEBUG TRAIN Batch 23/4400 loss 13.809337 loss_att 256.651489 loss_ctc 21.030800 loss_rnnt 13.006952 lr 0.00026555 rank 3
2022-12-07 23:53:22,743 DEBUG TRAIN Batch 23/4400 loss 9.411319 loss_att 67.922813 loss_ctc 13.597864 loss_rnnt 8.946148 lr 0.00026554 rank 5
2022-12-07 23:54:25,499 DEBUG TRAIN Batch 23/4500 loss 8.334826 loss_att 135.561630 loss_ctc 13.925696 loss_rnnt 7.713618 lr 0.00026550 rank 4
2022-12-07 23:54:25,502 DEBUG TRAIN Batch 23/4500 loss 6.675843 loss_att 341.668304 loss_ctc 16.520870 loss_rnnt 5.581951 lr 0.00026550 rank 6
2022-12-07 23:54:25,504 DEBUG TRAIN Batch 23/4500 loss 7.577493 loss_att 415.433563 loss_ctc 22.854818 loss_rnnt 5.880012 lr 0.00026550 rank 7
2022-12-07 23:54:25,505 DEBUG TRAIN Batch 23/4500 loss 10.149232 loss_att 428.642822 loss_ctc 28.077848 loss_rnnt 8.157164 lr 0.00026551 rank 2
2022-12-07 23:54:25,507 DEBUG TRAIN Batch 23/4500 loss 6.748303 loss_att 429.249359 loss_ctc 17.398321 loss_rnnt 5.564968 lr 0.00026551 rank 0
2022-12-07 23:54:25,510 DEBUG TRAIN Batch 23/4500 loss 9.742679 loss_att 320.044159 loss_ctc 23.805344 loss_rnnt 8.180161 lr 0.00026551 rank 1
2022-12-07 23:54:25,512 DEBUG TRAIN Batch 23/4500 loss 5.870365 loss_att 333.093689 loss_ctc 15.248644 loss_rnnt 4.828334 lr 0.00026550 rank 5
2022-12-07 23:54:25,550 DEBUG TRAIN Batch 23/4500 loss 6.112947 loss_att 466.932922 loss_ctc 11.958042 loss_rnnt 5.463492 lr 0.00026551 rank 3
2022-12-07 23:55:30,318 DEBUG TRAIN Batch 23/4600 loss 12.802880 loss_att 356.927216 loss_ctc 23.612371 loss_rnnt 11.601826 lr 0.00026546 rank 5
2022-12-07 23:55:30,322 DEBUG TRAIN Batch 23/4600 loss 9.203650 loss_att 366.243958 loss_ctc 15.434126 loss_rnnt 8.511374 lr 0.00026546 rank 7
2022-12-07 23:55:30,329 DEBUG TRAIN Batch 23/4600 loss 5.656067 loss_att 277.044739 loss_ctc 13.268085 loss_rnnt 4.810287 lr 0.00026547 rank 4
2022-12-07 23:55:30,329 DEBUG TRAIN Batch 23/4600 loss 6.355712 loss_att 443.512207 loss_ctc 13.134788 loss_rnnt 5.602482 lr 0.00026547 rank 0
2022-12-07 23:55:30,330 DEBUG TRAIN Batch 23/4600 loss 14.943954 loss_att 415.244232 loss_ctc 32.885544 loss_rnnt 12.950445 lr 0.00026547 rank 1
2022-12-07 23:55:30,343 DEBUG TRAIN Batch 23/4600 loss 14.964699 loss_att 413.933777 loss_ctc 31.427097 loss_rnnt 13.135544 lr 0.00026547 rank 2
2022-12-07 23:55:30,350 DEBUG TRAIN Batch 23/4600 loss 12.306274 loss_att 388.690765 loss_ctc 18.946838 loss_rnnt 11.568434 lr 0.00026546 rank 6
2022-12-07 23:55:30,365 DEBUG TRAIN Batch 23/4600 loss 33.032295 loss_att 476.701416 loss_ctc 64.791931 loss_rnnt 29.503447 lr 0.00026547 rank 3
2022-12-07 23:56:43,360 DEBUG TRAIN Batch 23/4700 loss 13.006630 loss_att 350.706635 loss_ctc 23.231636 loss_rnnt 11.870518 lr 0.00026544 rank 3
2022-12-07 23:56:43,363 DEBUG TRAIN Batch 23/4700 loss 5.071869 loss_att 370.551270 loss_ctc 13.438862 loss_rnnt 4.142203 lr 0.00026542 rank 6
2022-12-07 23:56:43,362 DEBUG TRAIN Batch 23/4700 loss 12.206802 loss_att 407.259155 loss_ctc 22.602148 loss_rnnt 11.051764 lr 0.00026543 rank 4
2022-12-07 23:56:43,366 DEBUG TRAIN Batch 23/4700 loss 8.159488 loss_att 430.949158 loss_ctc 14.179100 loss_rnnt 7.490643 lr 0.00026543 rank 1
2022-12-07 23:56:43,367 DEBUG TRAIN Batch 23/4700 loss 5.088640 loss_att 360.469788 loss_ctc 12.114438 loss_rnnt 4.307996 lr 0.00026542 rank 5
2022-12-07 23:56:43,367 DEBUG TRAIN Batch 23/4700 loss 3.993062 loss_att 292.962463 loss_ctc 7.462137 loss_rnnt 3.607609 lr 0.00026543 rank 2
2022-12-07 23:56:43,396 DEBUG TRAIN Batch 23/4700 loss 12.093180 loss_att 437.720703 loss_ctc 16.209408 loss_rnnt 11.635820 lr 0.00026543 rank 0
2022-12-07 23:56:43,403 DEBUG TRAIN Batch 23/4700 loss 3.645835 loss_att 301.681641 loss_ctc 6.993077 loss_rnnt 3.273919 lr 0.00026542 rank 7
2022-12-07 23:57:46,414 DEBUG TRAIN Batch 23/4800 loss 12.854797 loss_att 407.577759 loss_ctc 28.299236 loss_rnnt 11.138749 lr 0.00026539 rank 4
2022-12-07 23:57:46,418 DEBUG TRAIN Batch 23/4800 loss 2.900853 loss_att 315.780273 loss_ctc 9.591999 loss_rnnt 2.157392 lr 0.00026539 rank 7
2022-12-07 23:57:46,422 DEBUG TRAIN Batch 23/4800 loss 2.396822 loss_att 332.404907 loss_ctc 9.592489 loss_rnnt 1.597304 lr 0.00026539 rank 0
2022-12-07 23:57:46,424 DEBUG TRAIN Batch 23/4800 loss 10.691280 loss_att 383.647034 loss_ctc 22.177435 loss_rnnt 9.415041 lr 0.00026539 rank 6
2022-12-07 23:57:46,426 DEBUG TRAIN Batch 23/4800 loss 13.107171 loss_att 406.321472 loss_ctc 27.059834 loss_rnnt 11.556875 lr 0.00026540 rank 3
2022-12-07 23:57:46,429 DEBUG TRAIN Batch 23/4800 loss 5.178896 loss_att 368.934113 loss_ctc 10.787875 loss_rnnt 4.555676 lr 0.00026539 rank 2
2022-12-07 23:57:46,431 DEBUG TRAIN Batch 23/4800 loss 6.971033 loss_att 392.528168 loss_ctc 11.831476 loss_rnnt 6.430984 lr 0.00026540 rank 1
2022-12-07 23:57:46,466 DEBUG TRAIN Batch 23/4800 loss 8.927234 loss_att 410.693726 loss_ctc 18.021162 loss_rnnt 7.916798 lr 0.00026539 rank 5
2022-12-07 23:58:50,039 DEBUG TRAIN Batch 23/4900 loss 8.653061 loss_att 360.129456 loss_ctc 17.087292 loss_rnnt 7.715924 lr 0.00026535 rank 7
2022-12-07 23:58:50,040 DEBUG TRAIN Batch 23/4900 loss 6.084069 loss_att 328.949585 loss_ctc 9.865700 loss_rnnt 5.663888 lr 0.00026536 rank 0
2022-12-07 23:58:50,042 DEBUG TRAIN Batch 23/4900 loss 8.831902 loss_att 337.932190 loss_ctc 17.884998 loss_rnnt 7.826002 lr 0.00026535 rank 6
2022-12-07 23:58:50,042 DEBUG TRAIN Batch 23/4900 loss 3.566846 loss_att 300.376007 loss_ctc 8.974965 loss_rnnt 2.965944 lr 0.00026535 rank 4
2022-12-07 23:58:50,044 DEBUG TRAIN Batch 23/4900 loss 5.826062 loss_att 326.196411 loss_ctc 15.906931 loss_rnnt 4.705966 lr 0.00026535 rank 5
2022-12-07 23:58:50,045 DEBUG TRAIN Batch 23/4900 loss 10.124381 loss_att 389.217041 loss_ctc 21.170752 loss_rnnt 8.897007 lr 0.00026536 rank 2
2022-12-07 23:58:50,047 DEBUG TRAIN Batch 23/4900 loss 9.021185 loss_att 351.236267 loss_ctc 14.168087 loss_rnnt 8.449306 lr 0.00026536 rank 3
2022-12-07 23:58:50,092 DEBUG TRAIN Batch 23/4900 loss 9.451225 loss_att 359.183990 loss_ctc 17.304169 loss_rnnt 8.578676 lr 0.00026536 rank 1
2022-12-08 00:00:04,313 DEBUG TRAIN Batch 23/5000 loss 7.564904 loss_att 328.796783 loss_ctc 10.470796 loss_rnnt 7.242027 lr 0.00026532 rank 4
2022-12-08 00:00:04,315 DEBUG TRAIN Batch 23/5000 loss 9.504564 loss_att 212.757050 loss_ctc 17.735630 loss_rnnt 8.590001 lr 0.00026531 rank 7
2022-12-08 00:00:04,317 DEBUG TRAIN Batch 23/5000 loss 10.953169 loss_att 261.794495 loss_ctc 24.548096 loss_rnnt 9.442622 lr 0.00026531 rank 6
2022-12-08 00:00:04,317 DEBUG TRAIN Batch 23/5000 loss 5.834087 loss_att 340.475952 loss_ctc 10.062926 loss_rnnt 5.364216 lr 0.00026532 rank 1
2022-12-08 00:00:04,319 DEBUG TRAIN Batch 23/5000 loss 6.318144 loss_att 261.283173 loss_ctc 10.732749 loss_rnnt 5.827632 lr 0.00026533 rank 3
2022-12-08 00:00:04,320 DEBUG TRAIN Batch 23/5000 loss 7.669327 loss_att 265.744751 loss_ctc 11.502905 loss_rnnt 7.243374 lr 0.00026532 rank 0
2022-12-08 00:00:04,322 DEBUG TRAIN Batch 23/5000 loss 4.328975 loss_att 233.350754 loss_ctc 11.666438 loss_rnnt 3.513701 lr 0.00026531 rank 5
2022-12-08 00:00:04,323 DEBUG TRAIN Batch 23/5000 loss 10.582841 loss_att 307.455017 loss_ctc 19.204657 loss_rnnt 9.624862 lr 0.00026532 rank 2
2022-12-08 00:01:06,587 DEBUG TRAIN Batch 23/5100 loss 7.290841 loss_att 380.668518 loss_ctc 11.102041 loss_rnnt 6.867374 lr 0.00026528 rank 0
2022-12-08 00:01:06,595 DEBUG TRAIN Batch 23/5100 loss 5.338022 loss_att 360.322205 loss_ctc 9.211002 loss_rnnt 4.907691 lr 0.00026527 rank 7
2022-12-08 00:01:06,596 DEBUG TRAIN Batch 23/5100 loss 7.594358 loss_att 125.579880 loss_ctc 13.627938 loss_rnnt 6.923961 lr 0.00026527 rank 6
2022-12-08 00:01:06,598 DEBUG TRAIN Batch 23/5100 loss 6.921666 loss_att 330.088745 loss_ctc 10.935481 loss_rnnt 6.475687 lr 0.00026528 rank 1
2022-12-08 00:01:06,599 DEBUG TRAIN Batch 23/5100 loss 9.219011 loss_att 469.630219 loss_ctc 30.959677 loss_rnnt 6.803382 lr 0.00026528 rank 2
2022-12-08 00:01:06,599 DEBUG TRAIN Batch 23/5100 loss 16.381233 loss_att 433.366547 loss_ctc 26.409979 loss_rnnt 15.266928 lr 0.00026527 rank 5
2022-12-08 00:01:06,600 DEBUG TRAIN Batch 23/5100 loss 4.493202 loss_att 64.159332 loss_ctc 6.487799 loss_rnnt 4.271580 lr 0.00026529 rank 3
2022-12-08 00:01:06,601 DEBUG TRAIN Batch 23/5100 loss 13.394808 loss_att 207.921448 loss_ctc 24.344685 loss_rnnt 12.178156 lr 0.00026528 rank 4
2022-12-08 00:02:09,919 DEBUG TRAIN Batch 23/5200 loss 6.694142 loss_att 396.722168 loss_ctc 14.337752 loss_rnnt 5.844852 lr 0.00026524 rank 7
2022-12-08 00:02:09,920 DEBUG TRAIN Batch 23/5200 loss 20.776539 loss_att 399.989380 loss_ctc 34.033108 loss_rnnt 19.303587 lr 0.00026525 rank 2
2022-12-08 00:02:09,923 DEBUG TRAIN Batch 23/5200 loss 5.178098 loss_att 387.823853 loss_ctc 11.779071 loss_rnnt 4.444656 lr 0.00026524 rank 0
2022-12-08 00:02:09,924 DEBUG TRAIN Batch 23/5200 loss 3.080743 loss_att 385.300232 loss_ctc 9.917681 loss_rnnt 2.321084 lr 0.00026524 rank 4
2022-12-08 00:02:09,925 DEBUG TRAIN Batch 23/5200 loss 14.504089 loss_att 201.480743 loss_ctc 24.074100 loss_rnnt 13.440756 lr 0.00026525 rank 1
2022-12-08 00:02:09,925 DEBUG TRAIN Batch 23/5200 loss 2.206181 loss_att 420.100677 loss_ctc 4.999806 loss_rnnt 1.895778 lr 0.00026524 rank 6
2022-12-08 00:02:09,926 DEBUG TRAIN Batch 23/5200 loss 9.075094 loss_att 343.077637 loss_ctc 18.690327 loss_rnnt 8.006735 lr 0.00026524 rank 5
2022-12-08 00:02:09,935 DEBUG TRAIN Batch 23/5200 loss 9.639433 loss_att 404.445740 loss_ctc 18.094252 loss_rnnt 8.700008 lr 0.00026525 rank 3
2022-12-08 00:03:15,102 DEBUG TRAIN Batch 23/5300 loss 3.186721 loss_att 421.568115 loss_ctc 11.554771 loss_rnnt 2.256938 lr 0.00026521 rank 3
2022-12-08 00:03:15,114 DEBUG TRAIN Batch 23/5300 loss 10.088931 loss_att 353.099701 loss_ctc 16.748884 loss_rnnt 9.348936 lr 0.00026520 rank 6
2022-12-08 00:03:15,115 DEBUG TRAIN Batch 23/5300 loss 6.560295 loss_att 364.972992 loss_ctc 13.712298 loss_rnnt 5.765628 lr 0.00026520 rank 7
2022-12-08 00:03:15,116 DEBUG TRAIN Batch 23/5300 loss 13.175288 loss_att 429.138031 loss_ctc 30.534954 loss_rnnt 11.246437 lr 0.00026521 rank 2
2022-12-08 00:03:15,119 DEBUG TRAIN Batch 23/5300 loss 6.747619 loss_att 376.879944 loss_ctc 12.197135 loss_rnnt 6.142118 lr 0.00026521 rank 1
2022-12-08 00:03:15,121 DEBUG TRAIN Batch 23/5300 loss 10.222012 loss_att 343.388611 loss_ctc 24.321560 loss_rnnt 8.655395 lr 0.00026520 rank 4
2022-12-08 00:03:15,130 DEBUG TRAIN Batch 23/5300 loss 3.474427 loss_att 348.078705 loss_ctc 8.372938 loss_rnnt 2.930149 lr 0.00026520 rank 5
2022-12-08 00:03:15,141 DEBUG TRAIN Batch 23/5300 loss 9.062417 loss_att 365.022308 loss_ctc 17.006630 loss_rnnt 8.179727 lr 0.00026521 rank 0
2022-12-08 00:04:27,179 DEBUG TRAIN Batch 23/5400 loss 16.292953 loss_att 395.289764 loss_ctc 33.138561 loss_rnnt 14.421219 lr 0.00026517 rank 1
2022-12-08 00:04:27,187 DEBUG TRAIN Batch 23/5400 loss 4.668493 loss_att 374.319946 loss_ctc 8.734616 loss_rnnt 4.216702 lr 0.00026517 rank 4
2022-12-08 00:04:27,190 DEBUG TRAIN Batch 23/5400 loss 2.808131 loss_att 339.518127 loss_ctc 8.189603 loss_rnnt 2.210190 lr 0.00026516 rank 7
2022-12-08 00:04:27,193 DEBUG TRAIN Batch 23/5400 loss 4.792200 loss_att 352.126648 loss_ctc 11.364747 loss_rnnt 4.061917 lr 0.00026516 rank 6
2022-12-08 00:04:27,193 DEBUG TRAIN Batch 23/5400 loss 8.265574 loss_att 384.664612 loss_ctc 16.116001 loss_rnnt 7.393304 lr 0.00026518 rank 3
2022-12-08 00:04:27,193 DEBUG TRAIN Batch 23/5400 loss 6.862978 loss_att 369.962280 loss_ctc 19.523376 loss_rnnt 5.456267 lr 0.00026516 rank 5
2022-12-08 00:04:27,195 DEBUG TRAIN Batch 23/5400 loss 8.981234 loss_att 345.948120 loss_ctc 14.967111 loss_rnnt 8.316136 lr 0.00026517 rank 2
2022-12-08 00:04:27,205 DEBUG TRAIN Batch 23/5400 loss 13.159204 loss_att 425.869781 loss_ctc 29.683538 loss_rnnt 11.323167 lr 0.00026517 rank 0
2022-12-08 00:05:29,939 DEBUG TRAIN Batch 23/5500 loss 6.961325 loss_att 390.290039 loss_ctc 19.623116 loss_rnnt 5.554459 lr 0.00026513 rank 6
2022-12-08 00:05:29,940 DEBUG TRAIN Batch 23/5500 loss 11.416482 loss_att 412.511444 loss_ctc 23.761211 loss_rnnt 10.044846 lr 0.00026513 rank 0
2022-12-08 00:05:29,940 DEBUG TRAIN Batch 23/5500 loss 5.984311 loss_att 341.749451 loss_ctc 9.484118 loss_rnnt 5.595444 lr 0.00026513 rank 4
2022-12-08 00:05:29,944 DEBUG TRAIN Batch 23/5500 loss 7.225468 loss_att 346.565338 loss_ctc 15.406252 loss_rnnt 6.316493 lr 0.00026514 rank 1
2022-12-08 00:05:29,946 DEBUG TRAIN Batch 23/5500 loss 4.685893 loss_att 306.653656 loss_ctc 11.868834 loss_rnnt 3.887788 lr 0.00026513 rank 2
2022-12-08 00:05:29,946 DEBUG TRAIN Batch 23/5500 loss 7.912274 loss_att 347.121155 loss_ctc 17.356941 loss_rnnt 6.862867 lr 0.00026512 rank 7
2022-12-08 00:05:29,951 DEBUG TRAIN Batch 23/5500 loss 13.058720 loss_att 363.707275 loss_ctc 17.721697 loss_rnnt 12.540611 lr 0.00026512 rank 5
2022-12-08 00:05:29,988 DEBUG TRAIN Batch 23/5500 loss 1.300274 loss_att 312.095520 loss_ctc 3.410079 loss_rnnt 1.065851 lr 0.00026514 rank 3
2022-12-08 00:06:33,418 DEBUG TRAIN Batch 23/5600 loss 5.445535 loss_att 355.472473 loss_ctc 17.001392 loss_rnnt 4.161551 lr 0.00026509 rank 4
2022-12-08 00:06:33,418 DEBUG TRAIN Batch 23/5600 loss 3.146711 loss_att 263.565887 loss_ctc 7.294906 loss_rnnt 2.685801 lr 0.00026509 rank 7
2022-12-08 00:06:33,420 DEBUG TRAIN Batch 23/5600 loss 6.097186 loss_att 320.225647 loss_ctc 16.181223 loss_rnnt 4.976738 lr 0.00026510 rank 1
2022-12-08 00:06:33,419 DEBUG TRAIN Batch 23/5600 loss 6.922648 loss_att 377.641693 loss_ctc 16.023743 loss_rnnt 5.911416 lr 0.00026509 rank 6
2022-12-08 00:06:33,420 DEBUG TRAIN Batch 23/5600 loss 4.335436 loss_att 310.917480 loss_ctc 19.198885 loss_rnnt 2.683941 lr 0.00026510 rank 3
2022-12-08 00:06:33,420 DEBUG TRAIN Batch 23/5600 loss 4.114922 loss_att 311.712006 loss_ctc 8.067588 loss_rnnt 3.675737 lr 0.00026509 rank 5
2022-12-08 00:06:33,423 DEBUG TRAIN Batch 23/5600 loss 7.894218 loss_att 326.369110 loss_ctc 15.821734 loss_rnnt 7.013383 lr 0.00026510 rank 0
2022-12-08 00:06:33,429 DEBUG TRAIN Batch 23/5600 loss 8.690187 loss_att 296.192230 loss_ctc 15.728106 loss_rnnt 7.908195 lr 0.00026510 rank 2
2022-12-08 00:07:48,635 DEBUG TRAIN Batch 23/5700 loss 11.665189 loss_att 251.093506 loss_ctc 18.304611 loss_rnnt 10.927475 lr 0.00026505 rank 4
2022-12-08 00:07:48,636 DEBUG TRAIN Batch 23/5700 loss 6.544452 loss_att 175.317261 loss_ctc 9.169287 loss_rnnt 6.252803 lr 0.00026506 rank 2
2022-12-08 00:07:48,637 DEBUG TRAIN Batch 23/5700 loss 1.953280 loss_att 376.920624 loss_ctc 7.349749 loss_rnnt 1.353673 lr 0.00026505 rank 7
2022-12-08 00:07:48,638 DEBUG TRAIN Batch 23/5700 loss 5.759586 loss_att 363.681946 loss_ctc 9.687477 loss_rnnt 5.323154 lr 0.00026506 rank 1
2022-12-08 00:07:48,640 DEBUG TRAIN Batch 23/5700 loss 5.291091 loss_att 274.608459 loss_ctc 13.457774 loss_rnnt 4.383682 lr 0.00026505 rank 6
2022-12-08 00:07:48,642 DEBUG TRAIN Batch 23/5700 loss 5.725687 loss_att 96.925232 loss_ctc 8.979897 loss_rnnt 5.364108 lr 0.00026506 rank 0
2022-12-08 00:07:48,645 DEBUG TRAIN Batch 23/5700 loss 5.157799 loss_att 163.987503 loss_ctc 7.678270 loss_rnnt 4.877747 lr 0.00026505 rank 5
2022-12-08 00:07:48,683 DEBUG TRAIN Batch 23/5700 loss 7.233190 loss_att 210.126022 loss_ctc 12.421618 loss_rnnt 6.656698 lr 0.00026506 rank 3
2022-12-08 00:08:51,412 DEBUG TRAIN Batch 23/5800 loss 18.500263 loss_att 449.385254 loss_ctc 39.081467 loss_rnnt 16.213463 lr 0.00026502 rank 2
2022-12-08 00:08:51,415 DEBUG TRAIN Batch 23/5800 loss 5.765275 loss_att 435.148682 loss_ctc 14.430227 loss_rnnt 4.802503 lr 0.00026501 rank 6
2022-12-08 00:08:51,424 DEBUG TRAIN Batch 23/5800 loss 3.242901 loss_att 442.746155 loss_ctc 9.325881 loss_rnnt 2.567014 lr 0.00026502 rank 4
2022-12-08 00:08:51,423 DEBUG TRAIN Batch 23/5800 loss 4.915887 loss_att 390.624695 loss_ctc 8.386984 loss_rnnt 4.530210 lr 0.00026501 rank 7
2022-12-08 00:08:51,428 DEBUG TRAIN Batch 23/5800 loss 12.009863 loss_att 363.407562 loss_ctc 25.388123 loss_rnnt 10.523390 lr 0.00026501 rank 5
2022-12-08 00:08:51,434 DEBUG TRAIN Batch 23/5800 loss 3.068595 loss_att 318.858978 loss_ctc 5.426195 loss_rnnt 2.806639 lr 0.00026502 rank 0
2022-12-08 00:08:51,435 DEBUG TRAIN Batch 23/5800 loss 6.520998 loss_att 404.795624 loss_ctc 14.293154 loss_rnnt 5.657424 lr 0.00026503 rank 3
2022-12-08 00:08:51,469 DEBUG TRAIN Batch 23/5800 loss 5.995111 loss_att 310.138763 loss_ctc 15.300487 loss_rnnt 4.961180 lr 0.00026502 rank 1
2022-12-08 00:09:54,573 DEBUG TRAIN Batch 23/5900 loss 9.542666 loss_att 306.927002 loss_ctc 14.098732 loss_rnnt 9.036437 lr 0.00026498 rank 7
2022-12-08 00:09:54,577 DEBUG TRAIN Batch 23/5900 loss 8.120932 loss_att 391.083984 loss_ctc 22.513288 loss_rnnt 6.521781 lr 0.00026498 rank 4
2022-12-08 00:09:54,578 DEBUG TRAIN Batch 23/5900 loss 3.990633 loss_att 405.003754 loss_ctc 9.365810 loss_rnnt 3.393391 lr 0.00026499 rank 3
2022-12-08 00:09:54,578 DEBUG TRAIN Batch 23/5900 loss 7.180007 loss_att 369.829681 loss_ctc 11.177759 loss_rnnt 6.735812 lr 0.00026498 rank 0
2022-12-08 00:09:54,579 DEBUG TRAIN Batch 23/5900 loss 4.820295 loss_att 315.373535 loss_ctc 9.877513 loss_rnnt 4.258382 lr 0.00026498 rank 6
2022-12-08 00:09:54,578 DEBUG TRAIN Batch 23/5900 loss 7.255357 loss_att 390.041382 loss_ctc 18.277407 loss_rnnt 6.030685 lr 0.00026498 rank 2
2022-12-08 00:09:54,580 DEBUG TRAIN Batch 23/5900 loss 6.631103 loss_att 391.290375 loss_ctc 14.091959 loss_rnnt 5.802119 lr 0.00026498 rank 5
2022-12-08 00:09:54,581 DEBUG TRAIN Batch 23/5900 loss 10.023829 loss_att 442.964569 loss_ctc 15.882579 loss_rnnt 9.372858 lr 0.00026499 rank 1
2022-12-08 00:10:59,359 DEBUG TRAIN Batch 23/6000 loss 6.327207 loss_att 368.125732 loss_ctc 13.324034 loss_rnnt 5.549781 lr 0.00026495 rank 1
2022-12-08 00:10:59,370 DEBUG TRAIN Batch 23/6000 loss 6.379423 loss_att 334.349854 loss_ctc 11.717211 loss_rnnt 5.786336 lr 0.00026495 rank 2
2022-12-08 00:10:59,371 DEBUG TRAIN Batch 23/6000 loss 4.794118 loss_att 301.075562 loss_ctc 10.507392 loss_rnnt 4.159310 lr 0.00026494 rank 7
2022-12-08 00:10:59,371 DEBUG TRAIN Batch 23/6000 loss 6.504796 loss_att 377.111206 loss_ctc 13.289879 loss_rnnt 5.750897 lr 0.00026494 rank 4
2022-12-08 00:10:59,371 DEBUG TRAIN Batch 23/6000 loss 7.887106 loss_att 368.483246 loss_ctc 15.461639 loss_rnnt 7.045492 lr 0.00026494 rank 6
2022-12-08 00:10:59,375 DEBUG TRAIN Batch 23/6000 loss 6.970026 loss_att 345.333801 loss_ctc 13.066174 loss_rnnt 6.292676 lr 0.00026494 rank 5
2022-12-08 00:10:59,376 DEBUG TRAIN Batch 23/6000 loss 11.504666 loss_att 432.081665 loss_ctc 20.718618 loss_rnnt 10.480894 lr 0.00026495 rank 0
2022-12-08 00:10:59,413 DEBUG TRAIN Batch 23/6000 loss 6.993689 loss_att 380.441010 loss_ctc 12.716220 loss_rnnt 6.357852 lr 0.00026495 rank 3
2022-12-08 00:12:11,976 DEBUG TRAIN Batch 23/6100 loss 14.235626 loss_att 388.112427 loss_ctc 25.964512 loss_rnnt 12.932416 lr 0.00026490 rank 6
2022-12-08 00:12:11,979 DEBUG TRAIN Batch 23/6100 loss 10.337822 loss_att 282.731506 loss_ctc 18.821203 loss_rnnt 9.395225 lr 0.00026491 rank 1
2022-12-08 00:12:11,980 DEBUG TRAIN Batch 23/6100 loss 8.487003 loss_att 320.806244 loss_ctc 15.138826 loss_rnnt 7.747912 lr 0.00026491 rank 2
2022-12-08 00:12:11,980 DEBUG TRAIN Batch 23/6100 loss 6.898582 loss_att 343.075348 loss_ctc 12.519674 loss_rnnt 6.274016 lr 0.00026491 rank 4
2022-12-08 00:12:11,981 DEBUG TRAIN Batch 23/6100 loss 6.978841 loss_att 396.637512 loss_ctc 12.129023 loss_rnnt 6.406599 lr 0.00026490 rank 7
2022-12-08 00:12:11,983 DEBUG TRAIN Batch 23/6100 loss 2.982395 loss_att 355.659760 loss_ctc 8.239512 loss_rnnt 2.398271 lr 0.00026492 rank 3
2022-12-08 00:12:11,983 DEBUG TRAIN Batch 23/6100 loss 2.490894 loss_att 294.188080 loss_ctc 6.550519 loss_rnnt 2.039825 lr 0.00026491 rank 0
2022-12-08 00:12:11,985 DEBUG TRAIN Batch 23/6100 loss 6.545098 loss_att 336.995056 loss_ctc 15.356018 loss_rnnt 5.566108 lr 0.00026490 rank 5
2022-12-08 00:13:14,908 DEBUG TRAIN Batch 23/6200 loss 9.617798 loss_att 314.892975 loss_ctc 24.057621 loss_rnnt 8.013372 lr 0.00026486 rank 7
2022-12-08 00:13:14,909 DEBUG TRAIN Batch 23/6200 loss 7.986091 loss_att 386.165497 loss_ctc 17.223606 loss_rnnt 6.959701 lr 0.00026488 rank 3
2022-12-08 00:13:14,922 DEBUG TRAIN Batch 23/6200 loss 3.445678 loss_att 364.907410 loss_ctc 6.926270 loss_rnnt 3.058946 lr 0.00026487 rank 2
2022-12-08 00:13:14,923 DEBUG TRAIN Batch 23/6200 loss 14.005828 loss_att 355.635651 loss_ctc 29.492748 loss_rnnt 12.285059 lr 0.00026487 rank 4
2022-12-08 00:13:14,924 DEBUG TRAIN Batch 23/6200 loss 12.451216 loss_att 407.380463 loss_ctc 26.689003 loss_rnnt 10.869240 lr 0.00026487 rank 0
2022-12-08 00:13:14,928 DEBUG TRAIN Batch 23/6200 loss 8.146702 loss_att 332.010376 loss_ctc 15.274804 loss_rnnt 7.354691 lr 0.00026486 rank 5
2022-12-08 00:13:14,933 DEBUG TRAIN Batch 23/6200 loss 6.549750 loss_att 373.213440 loss_ctc 18.743156 loss_rnnt 5.194927 lr 0.00026487 rank 1
2022-12-08 00:13:14,939 DEBUG TRAIN Batch 23/6200 loss 14.888426 loss_att 348.941071 loss_ctc 36.229424 loss_rnnt 12.517204 lr 0.00026486 rank 6
2022-12-08 00:14:18,076 DEBUG TRAIN Batch 23/6300 loss 9.890214 loss_att 85.273643 loss_ctc 16.283897 loss_rnnt 9.179806 lr 0.00026483 rank 7
2022-12-08 00:14:18,078 DEBUG TRAIN Batch 23/6300 loss 5.500117 loss_att 305.669281 loss_ctc 10.117720 loss_rnnt 4.987050 lr 0.00026484 rank 3
2022-12-08 00:14:18,081 DEBUG TRAIN Batch 23/6300 loss 8.866379 loss_att 320.441315 loss_ctc 23.427656 loss_rnnt 7.248459 lr 0.00026484 rank 1
2022-12-08 00:14:18,083 DEBUG TRAIN Batch 23/6300 loss 7.386953 loss_att 229.892303 loss_ctc 11.757913 loss_rnnt 6.901291 lr 0.00026484 rank 0
2022-12-08 00:14:18,084 DEBUG TRAIN Batch 23/6300 loss 11.627112 loss_att 362.969238 loss_ctc 22.482710 loss_rnnt 10.420936 lr 0.00026483 rank 4
2022-12-08 00:14:18,084 DEBUG TRAIN Batch 23/6300 loss 8.998676 loss_att 273.628693 loss_ctc 16.501186 loss_rnnt 8.165065 lr 0.00026483 rank 5
2022-12-08 00:14:18,093 DEBUG TRAIN Batch 23/6300 loss 12.527452 loss_att 355.539673 loss_ctc 30.903360 loss_rnnt 10.485685 lr 0.00026483 rank 6
2022-12-08 00:14:18,116 DEBUG TRAIN Batch 23/6300 loss 9.250083 loss_att 223.198654 loss_ctc 15.738281 loss_rnnt 8.529173 lr 0.00026484 rank 2
2022-12-08 00:15:30,906 DEBUG TRAIN Batch 23/6400 loss 11.861366 loss_att 366.172424 loss_ctc 26.909613 loss_rnnt 10.189339 lr 0.00026480 rank 2
2022-12-08 00:15:30,908 DEBUG TRAIN Batch 23/6400 loss 7.801516 loss_att 417.633881 loss_ctc 17.623772 loss_rnnt 6.710155 lr 0.00026479 rank 4
2022-12-08 00:15:30,908 DEBUG TRAIN Batch 23/6400 loss 3.994845 loss_att 310.088715 loss_ctc 14.436241 loss_rnnt 2.834690 lr 0.00026480 rank 1
2022-12-08 00:15:30,910 DEBUG TRAIN Batch 23/6400 loss 6.266901 loss_att 412.806396 loss_ctc 12.563182 loss_rnnt 5.567315 lr 0.00026479 rank 7
2022-12-08 00:15:30,913 DEBUG TRAIN Batch 23/6400 loss 9.198922 loss_att 162.982208 loss_ctc 16.935041 loss_rnnt 8.339354 lr 0.00026479 rank 6
2022-12-08 00:15:30,913 DEBUG TRAIN Batch 23/6400 loss 11.311654 loss_att 199.680634 loss_ctc 16.761194 loss_rnnt 10.706149 lr 0.00026480 rank 3
2022-12-08 00:15:30,914 DEBUG TRAIN Batch 23/6400 loss 9.218605 loss_att 451.163391 loss_ctc 22.724945 loss_rnnt 7.717900 lr 0.00026479 rank 5
2022-12-08 00:15:30,936 DEBUG TRAIN Batch 23/6400 loss 1.750920 loss_att 382.415955 loss_ctc 6.344223 loss_rnnt 1.240553 lr 0.00026480 rank 0
2022-12-08 00:16:35,537 DEBUG TRAIN Batch 23/6500 loss 12.766002 loss_att 358.089050 loss_ctc 22.871086 loss_rnnt 11.643215 lr 0.00026476 rank 2
2022-12-08 00:16:35,537 DEBUG TRAIN Batch 23/6500 loss 13.691496 loss_att 404.648682 loss_ctc 21.369390 loss_rnnt 12.838397 lr 0.00026475 rank 6
2022-12-08 00:16:35,537 DEBUG TRAIN Batch 23/6500 loss 3.848451 loss_att 117.972214 loss_ctc 8.377464 loss_rnnt 3.345227 lr 0.00026476 rank 1
2022-12-08 00:16:35,539 DEBUG TRAIN Batch 23/6500 loss 8.157892 loss_att 413.019470 loss_ctc 18.494535 loss_rnnt 7.009377 lr 0.00026476 rank 4
2022-12-08 00:16:35,540 DEBUG TRAIN Batch 23/6500 loss 9.232625 loss_att 353.411072 loss_ctc 20.389803 loss_rnnt 7.992939 lr 0.00026477 rank 3
2022-12-08 00:16:35,542 DEBUG TRAIN Batch 23/6500 loss 8.436037 loss_att 416.229462 loss_ctc 18.496901 loss_rnnt 7.318164 lr 0.00026476 rank 0
2022-12-08 00:16:35,544 DEBUG TRAIN Batch 23/6500 loss 11.562113 loss_att 374.826477 loss_ctc 23.643414 loss_rnnt 10.219746 lr 0.00026475 rank 7
2022-12-08 00:16:35,548 DEBUG TRAIN Batch 23/6500 loss 14.050602 loss_att 408.611786 loss_ctc 25.163664 loss_rnnt 12.815817 lr 0.00026475 rank 5
2022-12-08 00:17:39,478 DEBUG TRAIN Batch 23/6600 loss 4.898342 loss_att 418.892670 loss_ctc 14.614704 loss_rnnt 3.818746 lr 0.00026473 rank 1
2022-12-08 00:17:39,487 DEBUG TRAIN Batch 23/6600 loss 10.341059 loss_att 361.895447 loss_ctc 25.416695 loss_rnnt 8.665988 lr 0.00026472 rank 6
2022-12-08 00:17:39,488 DEBUG TRAIN Batch 23/6600 loss 5.062514 loss_att 336.800018 loss_ctc 8.772896 loss_rnnt 4.650249 lr 0.00026472 rank 4
2022-12-08 00:17:39,490 DEBUG TRAIN Batch 23/6600 loss 16.607304 loss_att 452.940247 loss_ctc 42.207897 loss_rnnt 13.762794 lr 0.00026472 rank 2
2022-12-08 00:17:39,491 DEBUG TRAIN Batch 23/6600 loss 10.156863 loss_att 396.435242 loss_ctc 21.568249 loss_rnnt 8.888931 lr 0.00026472 rank 7
2022-12-08 00:17:39,490 DEBUG TRAIN Batch 23/6600 loss 12.520603 loss_att 406.933289 loss_ctc 20.261612 loss_rnnt 11.660491 lr 0.00026472 rank 5
2022-12-08 00:17:39,494 DEBUG TRAIN Batch 23/6600 loss 6.558984 loss_att 383.317596 loss_ctc 12.517555 loss_rnnt 5.896921 lr 0.00026472 rank 0
2022-12-08 00:17:39,537 DEBUG TRAIN Batch 23/6600 loss 3.143167 loss_att 381.685486 loss_ctc 9.858816 loss_rnnt 2.396984 lr 0.00026473 rank 3
2022-12-08 00:18:44,287 DEBUG TRAIN Batch 23/6700 loss 7.017080 loss_att 370.843689 loss_ctc 16.798698 loss_rnnt 5.930234 lr 0.00026468 rank 5
2022-12-08 00:18:44,298 DEBUG TRAIN Batch 23/6700 loss 18.989794 loss_att 368.929932 loss_ctc 25.098894 loss_rnnt 18.311005 lr 0.00026469 rank 2
2022-12-08 00:18:44,299 DEBUG TRAIN Batch 23/6700 loss 2.245902 loss_att 387.978882 loss_ctc 6.460027 loss_rnnt 1.777666 lr 0.00026468 rank 7
2022-12-08 00:18:44,300 DEBUG TRAIN Batch 23/6700 loss 12.711813 loss_att 365.977142 loss_ctc 27.584585 loss_rnnt 11.059282 lr 0.00026469 rank 3
2022-12-08 00:18:44,301 DEBUG TRAIN Batch 23/6700 loss 4.366932 loss_att 350.614746 loss_ctc 8.715530 loss_rnnt 3.883755 lr 0.00026468 rank 6
2022-12-08 00:18:44,301 DEBUG TRAIN Batch 23/6700 loss 3.649350 loss_att 405.483765 loss_ctc 7.012399 loss_rnnt 3.275678 lr 0.00026469 rank 1
2022-12-08 00:18:44,302 DEBUG TRAIN Batch 23/6700 loss 9.521991 loss_att 368.802521 loss_ctc 16.942038 loss_rnnt 8.697541 lr 0.00026469 rank 0
2022-12-08 00:18:44,303 DEBUG TRAIN Batch 23/6700 loss 7.593365 loss_att 301.995544 loss_ctc 12.103611 loss_rnnt 7.092227 lr 0.00026468 rank 4
2022-12-08 00:19:56,904 DEBUG TRAIN Batch 23/6800 loss 9.072724 loss_att 365.342255 loss_ctc 14.488342 loss_rnnt 8.470989 lr 0.00026465 rank 4
2022-12-08 00:19:56,907 DEBUG TRAIN Batch 23/6800 loss 14.192732 loss_att 370.349365 loss_ctc 31.651785 loss_rnnt 12.252838 lr 0.00026465 rank 2
2022-12-08 00:19:56,908 DEBUG TRAIN Batch 23/6800 loss 9.866529 loss_att 350.173035 loss_ctc 21.841839 loss_rnnt 8.535938 lr 0.00026464 rank 7
2022-12-08 00:19:56,908 DEBUG TRAIN Batch 23/6800 loss 13.584904 loss_att 371.124847 loss_ctc 27.588388 loss_rnnt 12.028961 lr 0.00026465 rank 0
2022-12-08 00:19:56,910 DEBUG TRAIN Batch 23/6800 loss 7.595160 loss_att 387.165588 loss_ctc 10.925819 loss_rnnt 7.225088 lr 0.00026464 rank 6
2022-12-08 00:19:56,912 DEBUG TRAIN Batch 23/6800 loss 6.910611 loss_att 345.675934 loss_ctc 14.836411 loss_rnnt 6.029966 lr 0.00026464 rank 5
2022-12-08 00:19:56,913 DEBUG TRAIN Batch 23/6800 loss 7.059926 loss_att 378.080627 loss_ctc 20.797485 loss_rnnt 5.533530 lr 0.00026466 rank 3
2022-12-08 00:19:56,951 DEBUG TRAIN Batch 23/6800 loss 10.537890 loss_att 352.559448 loss_ctc 22.479160 loss_rnnt 9.211082 lr 0.00026465 rank 1
2022-12-08 00:21:00,425 DEBUG TRAIN Batch 23/6900 loss 7.808252 loss_att 157.538757 loss_ctc 13.431767 loss_rnnt 7.183417 lr 0.00026460 rank 7
2022-12-08 00:21:00,428 DEBUG TRAIN Batch 23/6900 loss 9.371727 loss_att 317.533997 loss_ctc 14.602118 loss_rnnt 8.790572 lr 0.00026461 rank 0
2022-12-08 00:21:00,429 DEBUG TRAIN Batch 23/6900 loss 15.682564 loss_att 340.736511 loss_ctc 34.850487 loss_rnnt 13.552795 lr 0.00026461 rank 2
2022-12-08 00:21:00,429 DEBUG TRAIN Batch 23/6900 loss 3.087866 loss_att 296.735992 loss_ctc 5.078870 loss_rnnt 2.866643 lr 0.00026461 rank 1
2022-12-08 00:21:00,430 DEBUG TRAIN Batch 23/6900 loss 19.048067 loss_att 354.543396 loss_ctc 36.189342 loss_rnnt 17.143482 lr 0.00026461 rank 6
2022-12-08 00:21:00,430 DEBUG TRAIN Batch 23/6900 loss 10.480542 loss_att 304.398590 loss_ctc 19.595751 loss_rnnt 9.467742 lr 0.00026461 rank 4
2022-12-08 00:21:00,432 DEBUG TRAIN Batch 23/6900 loss 2.633892 loss_att 307.095947 loss_ctc 5.563915 loss_rnnt 2.308333 lr 0.00026462 rank 3
2022-12-08 00:21:00,438 DEBUG TRAIN Batch 23/6900 loss 3.736696 loss_att 305.982635 loss_ctc 9.749907 loss_rnnt 3.068562 lr 0.00026460 rank 5
2022-12-08 00:22:03,728 DEBUG TRAIN Batch 23/7000 loss 4.594839 loss_att 424.930878 loss_ctc 7.374774 loss_rnnt 4.285957 lr 0.00026457 rank 7
2022-12-08 00:22:03,733 DEBUG TRAIN Batch 23/7000 loss 7.523059 loss_att 372.095215 loss_ctc 10.410857 loss_rnnt 7.202193 lr 0.00026458 rank 2
2022-12-08 00:22:03,734 DEBUG TRAIN Batch 23/7000 loss 6.796095 loss_att 79.544518 loss_ctc 9.397951 loss_rnnt 6.507000 lr 0.00026457 rank 4
2022-12-08 00:22:03,734 DEBUG TRAIN Batch 23/7000 loss 4.395050 loss_att 461.325653 loss_ctc 12.044512 loss_rnnt 3.545110 lr 0.00026458 rank 0
2022-12-08 00:22:03,734 DEBUG TRAIN Batch 23/7000 loss 2.541630 loss_att 324.149567 loss_ctc 6.597617 loss_rnnt 2.090964 lr 0.00026458 rank 1
2022-12-08 00:22:03,736 DEBUG TRAIN Batch 23/7000 loss 7.926262 loss_att 384.838074 loss_ctc 16.313641 loss_rnnt 6.994331 lr 0.00026457 rank 5
2022-12-08 00:22:03,737 DEBUG TRAIN Batch 23/7000 loss 12.722954 loss_att 286.936920 loss_ctc 28.400558 loss_rnnt 10.980998 lr 0.00026458 rank 3
2022-12-08 00:22:03,739 DEBUG TRAIN Batch 23/7000 loss 18.699278 loss_att 270.907440 loss_ctc 27.811790 loss_rnnt 17.686777 lr 0.00026457 rank 6
2022-12-08 00:23:15,758 DEBUG TRAIN Batch 23/7100 loss 9.186472 loss_att 437.833130 loss_ctc 24.312866 loss_rnnt 7.505762 lr 0.00026453 rank 6
2022-12-08 00:23:15,758 DEBUG TRAIN Batch 23/7100 loss 1.643171 loss_att 383.542847 loss_ctc 5.054906 loss_rnnt 1.264089 lr 0.00026453 rank 5
2022-12-08 00:23:15,759 DEBUG TRAIN Batch 23/7100 loss 3.965301 loss_att 374.380951 loss_ctc 8.374628 loss_rnnt 3.475376 lr 0.00026453 rank 7
2022-12-08 00:23:15,759 DEBUG TRAIN Batch 23/7100 loss 7.833755 loss_att 430.489258 loss_ctc 21.912174 loss_rnnt 6.269487 lr 0.00026454 rank 2
2022-12-08 00:23:15,762 DEBUG TRAIN Batch 23/7100 loss 8.580700 loss_att 229.398056 loss_ctc 18.018837 loss_rnnt 7.532018 lr 0.00026454 rank 1
2022-12-08 00:23:15,767 DEBUG TRAIN Batch 23/7100 loss 12.877426 loss_att 419.138245 loss_ctc 22.293371 loss_rnnt 11.831210 lr 0.00026454 rank 0
2022-12-08 00:23:15,777 DEBUG TRAIN Batch 23/7100 loss 8.460762 loss_att 378.766327 loss_ctc 16.880833 loss_rnnt 7.525199 lr 0.00026453 rank 4
2022-12-08 00:23:15,803 DEBUG TRAIN Batch 23/7100 loss 1.084835 loss_att 340.316132 loss_ctc 6.637851 loss_rnnt 0.467833 lr 0.00026454 rank 3
2022-12-08 00:24:18,903 DEBUG TRAIN Batch 23/7200 loss 5.273446 loss_att 396.809998 loss_ctc 13.890628 loss_rnnt 4.315981 lr 0.00026450 rank 1
2022-12-08 00:24:18,905 DEBUG TRAIN Batch 23/7200 loss 10.921831 loss_att 368.306732 loss_ctc 21.855431 loss_rnnt 9.706987 lr 0.00026450 rank 2
2022-12-08 00:24:18,905 DEBUG TRAIN Batch 23/7200 loss 4.717564 loss_att 328.889557 loss_ctc 7.973325 loss_rnnt 4.355812 lr 0.00026451 rank 3
2022-12-08 00:24:18,906 DEBUG TRAIN Batch 23/7200 loss 2.951912 loss_att 317.207642 loss_ctc 6.463418 loss_rnnt 2.561745 lr 0.00026449 rank 5
2022-12-08 00:24:18,907 DEBUG TRAIN Batch 23/7200 loss 6.816347 loss_att 373.478638 loss_ctc 16.835920 loss_rnnt 5.703061 lr 0.00026449 rank 7
2022-12-08 00:24:18,910 DEBUG TRAIN Batch 23/7200 loss 4.855585 loss_att 381.714203 loss_ctc 13.647360 loss_rnnt 3.878721 lr 0.00026450 rank 4
2022-12-08 00:24:18,911 DEBUG TRAIN Batch 23/7200 loss 5.385273 loss_att 461.688477 loss_ctc 9.290236 loss_rnnt 4.951387 lr 0.00026449 rank 6
2022-12-08 00:24:18,911 DEBUG TRAIN Batch 23/7200 loss 3.301442 loss_att 352.135345 loss_ctc 8.898345 loss_rnnt 2.679564 lr 0.00026450 rank 0
2022-12-08 00:25:22,044 DEBUG TRAIN Batch 23/7300 loss 2.072869 loss_att 326.726746 loss_ctc 4.893291 loss_rnnt 1.759489 lr 0.00026446 rank 7
2022-12-08 00:25:22,047 DEBUG TRAIN Batch 23/7300 loss 3.905339 loss_att 320.161102 loss_ctc 15.436999 loss_rnnt 2.624044 lr 0.00026446 rank 6
2022-12-08 00:25:22,049 DEBUG TRAIN Batch 23/7300 loss 10.803483 loss_att 379.160858 loss_ctc 24.547958 loss_rnnt 9.276320 lr 0.00026447 rank 3
2022-12-08 00:25:22,050 DEBUG TRAIN Batch 23/7300 loss 11.112470 loss_att 412.945618 loss_ctc 26.366604 loss_rnnt 9.417566 lr 0.00026446 rank 2
2022-12-08 00:25:22,051 DEBUG TRAIN Batch 23/7300 loss 11.496254 loss_att 396.651123 loss_ctc 17.806252 loss_rnnt 10.795143 lr 0.00026446 rank 4
2022-12-08 00:25:22,051 DEBUG TRAIN Batch 23/7300 loss 13.111188 loss_att 394.904907 loss_ctc 30.733625 loss_rnnt 11.153140 lr 0.00026447 rank 1
2022-12-08 00:25:22,052 DEBUG TRAIN Batch 23/7300 loss 13.416689 loss_att 409.964478 loss_ctc 32.175201 loss_rnnt 11.332409 lr 0.00026446 rank 0
2022-12-08 00:25:22,054 DEBUG TRAIN Batch 23/7300 loss 11.997153 loss_att 377.355652 loss_ctc 16.908699 loss_rnnt 11.451426 lr 0.00026446 rank 5
2022-12-08 00:26:25,720 DEBUG TRAIN Batch 23/7400 loss 3.421908 loss_att 361.743286 loss_ctc 6.767815 loss_rnnt 3.050140 lr 0.00026442 rank 6
2022-12-08 00:26:25,722 DEBUG TRAIN Batch 23/7400 loss 11.542006 loss_att 423.038940 loss_ctc 13.496475 loss_rnnt 11.324842 lr 0.00026443 rank 1
2022-12-08 00:26:25,724 DEBUG TRAIN Batch 23/7400 loss 6.914492 loss_att 318.562561 loss_ctc 12.751528 loss_rnnt 6.265933 lr 0.00026442 rank 7
2022-12-08 00:26:25,724 DEBUG TRAIN Batch 23/7400 loss 6.062900 loss_att 355.672791 loss_ctc 14.760468 loss_rnnt 5.096503 lr 0.00026442 rank 4
2022-12-08 00:26:25,728 DEBUG TRAIN Batch 23/7400 loss 5.341209 loss_att 420.884338 loss_ctc 18.832537 loss_rnnt 3.842173 lr 0.00026443 rank 3
2022-12-08 00:26:25,727 DEBUG TRAIN Batch 23/7400 loss 19.863194 loss_att 357.338837 loss_ctc 32.031040 loss_rnnt 18.511211 lr 0.00026443 rank 0
2022-12-08 00:26:25,746 DEBUG TRAIN Batch 23/7400 loss 5.384117 loss_att 296.190979 loss_ctc 8.563343 loss_rnnt 5.030869 lr 0.00026442 rank 5
2022-12-08 00:26:25,749 DEBUG TRAIN Batch 23/7400 loss 17.547083 loss_att 362.738525 loss_ctc 24.466511 loss_rnnt 16.778257 lr 0.00026443 rank 2
2022-12-08 00:27:39,200 DEBUG TRAIN Batch 23/7500 loss 7.688219 loss_att 348.307922 loss_ctc 16.033941 loss_rnnt 6.760916 lr 0.00026438 rank 6
2022-12-08 00:27:39,202 DEBUG TRAIN Batch 23/7500 loss 12.463034 loss_att 349.895233 loss_ctc 23.616043 loss_rnnt 11.223810 lr 0.00026440 rank 3
2022-12-08 00:27:39,202 DEBUG TRAIN Batch 23/7500 loss 7.038084 loss_att 382.947510 loss_ctc 19.059137 loss_rnnt 5.702412 lr 0.00026439 rank 4
2022-12-08 00:27:39,202 DEBUG TRAIN Batch 23/7500 loss 4.829455 loss_att 356.420898 loss_ctc 8.513397 loss_rnnt 4.420128 lr 0.00026439 rank 0
2022-12-08 00:27:39,203 DEBUG TRAIN Batch 23/7500 loss 1.997774 loss_att 272.984894 loss_ctc 5.071720 loss_rnnt 1.656225 lr 0.00026439 rank 2
2022-12-08 00:27:39,206 DEBUG TRAIN Batch 23/7500 loss 7.601604 loss_att 210.863098 loss_ctc 17.998245 loss_rnnt 6.446422 lr 0.00026438 rank 7
2022-12-08 00:27:39,208 DEBUG TRAIN Batch 23/7500 loss 4.940604 loss_att 312.578247 loss_ctc 7.286374 loss_rnnt 4.679963 lr 0.00026438 rank 5
2022-12-08 00:27:39,247 DEBUG TRAIN Batch 23/7500 loss 18.004025 loss_att 367.717560 loss_ctc 33.698586 loss_rnnt 16.260185 lr 0.00026439 rank 1
2022-12-08 00:28:43,263 DEBUG TRAIN Batch 23/7600 loss 8.260143 loss_att 492.140839 loss_ctc 21.571983 loss_rnnt 6.781049 lr 0.00026435 rank 7
2022-12-08 00:28:43,267 DEBUG TRAIN Batch 23/7600 loss 8.038285 loss_att 272.263611 loss_ctc 13.193291 loss_rnnt 7.465508 lr 0.00026436 rank 3
2022-12-08 00:28:43,267 DEBUG TRAIN Batch 23/7600 loss 8.040515 loss_att 172.270081 loss_ctc 14.806668 loss_rnnt 7.288721 lr 0.00026435 rank 5
2022-12-08 00:28:43,269 DEBUG TRAIN Batch 23/7600 loss 5.888181 loss_att 329.438507 loss_ctc 10.307963 loss_rnnt 5.397094 lr 0.00026435 rank 6
2022-12-08 00:28:43,269 DEBUG TRAIN Batch 23/7600 loss 12.947145 loss_att 260.567047 loss_ctc 18.113174 loss_rnnt 12.373141 lr 0.00026435 rank 4
2022-12-08 00:28:43,270 DEBUG TRAIN Batch 23/7600 loss 8.703989 loss_att 416.288055 loss_ctc 17.194111 loss_rnnt 7.760643 lr 0.00026436 rank 1
2022-12-08 00:28:43,271 DEBUG TRAIN Batch 23/7600 loss 9.387033 loss_att 257.122009 loss_ctc 16.817484 loss_rnnt 8.561427 lr 0.00026435 rank 0
2022-12-08 00:28:43,272 DEBUG TRAIN Batch 23/7600 loss 10.596855 loss_att 75.500687 loss_ctc 16.105911 loss_rnnt 9.984738 lr 0.00026435 rank 2
2022-12-08 00:29:47,410 DEBUG TRAIN Batch 23/7700 loss 6.511366 loss_att 408.550476 loss_ctc 17.947044 loss_rnnt 5.240735 lr 0.00026431 rank 7
2022-12-08 00:29:47,414 DEBUG TRAIN Batch 23/7700 loss 4.274606 loss_att 401.941895 loss_ctc 8.352184 loss_rnnt 3.821541 lr 0.00026431 rank 4
2022-12-08 00:29:47,415 DEBUG TRAIN Batch 23/7700 loss 8.895336 loss_att 126.081139 loss_ctc 13.288191 loss_rnnt 8.407242 lr 0.00026431 rank 6
2022-12-08 00:29:47,417 DEBUG TRAIN Batch 23/7700 loss 10.124501 loss_att 366.102112 loss_ctc 16.148760 loss_rnnt 9.455139 lr 0.00026432 rank 0
2022-12-08 00:29:47,417 DEBUG TRAIN Batch 23/7700 loss 11.380376 loss_att 462.698090 loss_ctc 16.164953 loss_rnnt 10.848757 lr 0.00026432 rank 2
2022-12-08 00:29:47,419 DEBUG TRAIN Batch 23/7700 loss 13.134414 loss_att 361.357452 loss_ctc 19.834860 loss_rnnt 12.389920 lr 0.00026432 rank 1
2022-12-08 00:29:47,422 DEBUG TRAIN Batch 23/7700 loss 14.085855 loss_att 406.196747 loss_ctc 32.211941 loss_rnnt 12.071845 lr 0.00026431 rank 5
2022-12-08 00:29:47,457 DEBUG TRAIN Batch 23/7700 loss 7.082418 loss_att 191.821869 loss_ctc 13.481543 loss_rnnt 6.371405 lr 0.00026432 rank 3
2022-12-08 00:31:00,400 DEBUG TRAIN Batch 23/7800 loss 7.061327 loss_att 379.699951 loss_ctc 13.141658 loss_rnnt 6.385735 lr 0.00026428 rank 4
2022-12-08 00:31:00,400 DEBUG TRAIN Batch 23/7800 loss 3.523567 loss_att 411.576263 loss_ctc 9.730389 loss_rnnt 2.833920 lr 0.00026429 rank 3
2022-12-08 00:31:00,401 DEBUG TRAIN Batch 23/7800 loss 6.031851 loss_att 408.775208 loss_ctc 12.397995 loss_rnnt 5.324502 lr 0.00026428 rank 2
2022-12-08 00:31:00,403 DEBUG TRAIN Batch 23/7800 loss 9.577043 loss_att 389.295990 loss_ctc 24.909882 loss_rnnt 7.873394 lr 0.00026427 rank 5
2022-12-08 00:31:00,402 DEBUG TRAIN Batch 23/7800 loss 5.393869 loss_att 474.210541 loss_ctc 18.536251 loss_rnnt 3.933605 lr 0.00026427 rank 6
2022-12-08 00:31:00,403 DEBUG TRAIN Batch 23/7800 loss 10.589435 loss_att 156.917465 loss_ctc 21.407364 loss_rnnt 9.387443 lr 0.00026428 rank 1
2022-12-08 00:31:00,406 DEBUG TRAIN Batch 23/7800 loss 3.514180 loss_att 374.780457 loss_ctc 13.662651 loss_rnnt 2.386572 lr 0.00026428 rank 0
2022-12-08 00:31:00,418 DEBUG TRAIN Batch 23/7800 loss 15.580577 loss_att 367.731934 loss_ctc 33.465233 loss_rnnt 13.593393 lr 0.00026427 rank 7
2022-12-08 00:32:04,638 DEBUG TRAIN Batch 23/7900 loss 8.108039 loss_att 398.062622 loss_ctc 14.673809 loss_rnnt 7.378510 lr 0.00026424 rank 2
2022-12-08 00:32:04,639 DEBUG TRAIN Batch 23/7900 loss 13.255531 loss_att 353.564880 loss_ctc 17.023159 loss_rnnt 12.836905 lr 0.00026425 rank 3
2022-12-08 00:32:04,641 DEBUG TRAIN Batch 23/7900 loss 6.060676 loss_att 407.698334 loss_ctc 18.514378 loss_rnnt 4.676931 lr 0.00026424 rank 4
2022-12-08 00:32:04,642 DEBUG TRAIN Batch 23/7900 loss 3.548861 loss_att 326.000824 loss_ctc 10.984522 loss_rnnt 2.722677 lr 0.00026423 rank 7
2022-12-08 00:32:04,642 DEBUG TRAIN Batch 23/7900 loss 7.734439 loss_att 316.356537 loss_ctc 15.944979 loss_rnnt 6.822157 lr 0.00026423 rank 5
2022-12-08 00:32:04,643 DEBUG TRAIN Batch 23/7900 loss 3.182793 loss_att 386.080017 loss_ctc 8.622122 loss_rnnt 2.578423 lr 0.00026424 rank 1
2022-12-08 00:32:04,644 DEBUG TRAIN Batch 23/7900 loss 8.245491 loss_att 354.149719 loss_ctc 17.563530 loss_rnnt 7.210153 lr 0.00026424 rank 6
2022-12-08 00:32:04,645 DEBUG TRAIN Batch 23/7900 loss 5.142269 loss_att 448.219971 loss_ctc 18.880054 loss_rnnt 3.615848 lr 0.00026424 rank 0
2022-12-08 00:33:08,260 DEBUG TRAIN Batch 23/8000 loss 18.485970 loss_att 371.679016 loss_ctc 36.061344 loss_rnnt 16.533150 lr 0.00026420 rank 7
2022-12-08 00:33:08,266 DEBUG TRAIN Batch 23/8000 loss 10.979642 loss_att 336.643738 loss_ctc 21.114326 loss_rnnt 9.853565 lr 0.00026421 rank 0
2022-12-08 00:33:08,268 DEBUG TRAIN Batch 23/8000 loss 7.332467 loss_att 420.382812 loss_ctc 16.924057 loss_rnnt 6.266735 lr 0.00026421 rank 1
2022-12-08 00:33:08,272 DEBUG TRAIN Batch 23/8000 loss 13.638557 loss_att 474.477478 loss_ctc 25.625523 loss_rnnt 12.306672 lr 0.00026421 rank 3
2022-12-08 00:33:08,273 DEBUG TRAIN Batch 23/8000 loss 11.488412 loss_att 400.855408 loss_ctc 23.260580 loss_rnnt 10.180393 lr 0.00026421 rank 2
2022-12-08 00:33:08,274 DEBUG TRAIN Batch 23/8000 loss 6.757987 loss_att 359.470886 loss_ctc 14.834484 loss_rnnt 5.860598 lr 0.00026420 rank 4
2022-12-08 00:33:08,275 DEBUG TRAIN Batch 23/8000 loss 10.026139 loss_att 410.164795 loss_ctc 23.392879 loss_rnnt 8.540946 lr 0.00026420 rank 6
2022-12-08 00:33:08,282 DEBUG TRAIN Batch 23/8000 loss 8.595166 loss_att 391.740295 loss_ctc 18.360771 loss_rnnt 7.510099 lr 0.00026420 rank 5
2022-12-08 00:34:11,825 DEBUG TRAIN Batch 23/8100 loss 8.430942 loss_att 401.773651 loss_ctc 18.727999 loss_rnnt 7.286824 lr 0.00026417 rank 1
2022-12-08 00:34:11,826 DEBUG TRAIN Batch 23/8100 loss 8.631678 loss_att 319.783722 loss_ctc 14.132537 loss_rnnt 8.020472 lr 0.00026416 rank 5
2022-12-08 00:34:11,827 DEBUG TRAIN Batch 23/8100 loss 12.810004 loss_att 304.694183 loss_ctc 24.472246 loss_rnnt 11.514200 lr 0.00026417 rank 2
2022-12-08 00:34:11,836 DEBUG TRAIN Batch 23/8100 loss 6.211675 loss_att 313.669861 loss_ctc 11.967699 loss_rnnt 5.572116 lr 0.00026417 rank 4
2022-12-08 00:34:11,841 DEBUG TRAIN Batch 23/8100 loss 8.073195 loss_att 231.269943 loss_ctc 13.698009 loss_rnnt 7.448216 lr 0.00026416 rank 7
2022-12-08 00:34:11,843 DEBUG TRAIN Batch 23/8100 loss 5.548413 loss_att 345.703949 loss_ctc 10.725637 loss_rnnt 4.973166 lr 0.00026417 rank 0
2022-12-08 00:34:11,845 DEBUG TRAIN Batch 23/8100 loss 8.439831 loss_att 347.099152 loss_ctc 13.725619 loss_rnnt 7.852522 lr 0.00026416 rank 6
2022-12-08 00:34:11,854 DEBUG TRAIN Batch 23/8100 loss 10.879755 loss_att 436.536865 loss_ctc 24.669651 loss_rnnt 9.347544 lr 0.00026417 rank 3
2022-12-08 00:35:15,310 DEBUG TRAIN Batch 23/8200 loss 6.167083 loss_att 318.892029 loss_ctc 9.832946 loss_rnnt 5.759766 lr 0.00026413 rank 4
2022-12-08 00:35:15,312 DEBUG TRAIN Batch 23/8200 loss 2.384922 loss_att 218.917450 loss_ctc 5.017364 loss_rnnt 2.092428 lr 0.00026412 rank 5
2022-12-08 00:35:15,315 DEBUG TRAIN Batch 23/8200 loss 6.751757 loss_att 348.283142 loss_ctc 12.768310 loss_rnnt 6.083251 lr 0.00026412 rank 6
2022-12-08 00:35:15,316 DEBUG TRAIN Batch 23/8200 loss 12.702578 loss_att 398.580078 loss_ctc 20.853676 loss_rnnt 11.796901 lr 0.00026414 rank 3
2022-12-08 00:35:15,316 DEBUG TRAIN Batch 23/8200 loss 6.458623 loss_att 386.734375 loss_ctc 18.619408 loss_rnnt 5.107425 lr 0.00026412 rank 7
2022-12-08 00:35:15,317 DEBUG TRAIN Batch 23/8200 loss 10.762142 loss_att 258.474365 loss_ctc 17.955322 loss_rnnt 9.962900 lr 0.00026413 rank 0
2022-12-08 00:35:15,317 DEBUG TRAIN Batch 23/8200 loss 16.985842 loss_att 257.994720 loss_ctc 30.496822 loss_rnnt 15.484622 lr 0.00026413 rank 2
2022-12-08 00:35:15,359 DEBUG TRAIN Batch 23/8200 loss 9.247183 loss_att 388.849152 loss_ctc 17.407013 loss_rnnt 8.340535 lr 0.00026413 rank 1
2022-12-08 00:36:18,075 DEBUG TRAIN Batch 23/8300 loss 10.421780 loss_att 394.539795 loss_ctc 15.526443 loss_rnnt 9.854594 lr 0.00026409 rank 7
2022-12-08 00:36:18,078 DEBUG TRAIN Batch 23/8300 loss 12.433809 loss_att 272.122192 loss_ctc 21.079115 loss_rnnt 11.473219 lr 0.00026409 rank 4
2022-12-08 00:36:18,080 DEBUG TRAIN Batch 23/8300 loss 6.361161 loss_att 409.047302 loss_ctc 12.521873 loss_rnnt 5.676638 lr 0.00026410 rank 2
2022-12-08 00:36:18,081 DEBUG TRAIN Batch 23/8300 loss 5.583402 loss_att 286.711761 loss_ctc 12.271902 loss_rnnt 4.840235 lr 0.00026409 rank 6
2022-12-08 00:36:18,081 DEBUG TRAIN Batch 23/8300 loss 2.669730 loss_att 424.088562 loss_ctc 5.302845 loss_rnnt 2.377162 lr 0.00026410 rank 0
2022-12-08 00:36:18,082 DEBUG TRAIN Batch 23/8300 loss 6.962692 loss_att 319.823303 loss_ctc 13.659746 loss_rnnt 6.218575 lr 0.00026410 rank 3
2022-12-08 00:36:18,084 DEBUG TRAIN Batch 23/8300 loss 10.752095 loss_att 376.832336 loss_ctc 16.303160 loss_rnnt 10.135311 lr 0.00026410 rank 1
2022-12-08 00:36:18,086 DEBUG TRAIN Batch 23/8300 loss 5.601040 loss_att 392.174500 loss_ctc 13.647728 loss_rnnt 4.706964 lr 0.00026409 rank 5
2022-12-08 00:37:02,108 DEBUG CV Batch 23/0 loss 1.467866 loss_att 48.088257 loss_ctc 2.941935 loss_rnnt 1.304080 history loss 1.413500 rank 3
2022-12-08 00:37:02,113 DEBUG CV Batch 23/0 loss 1.467866 loss_att 48.088257 loss_ctc 2.941935 loss_rnnt 1.304080 history loss 1.413500 rank 6
2022-12-08 00:37:02,114 DEBUG CV Batch 23/0 loss 1.467866 loss_att 48.088257 loss_ctc 2.941935 loss_rnnt 1.304080 history loss 1.413500 rank 4
2022-12-08 00:37:02,114 DEBUG CV Batch 23/0 loss 1.467866 loss_att 48.088257 loss_ctc 2.941935 loss_rnnt 1.304080 history loss 1.413500 rank 1
2022-12-08 00:37:02,115 DEBUG CV Batch 23/0 loss 1.467866 loss_att 48.088257 loss_ctc 2.941935 loss_rnnt 1.304080 history loss 1.413500 rank 7
2022-12-08 00:37:02,115 DEBUG CV Batch 23/0 loss 1.467866 loss_att 48.088257 loss_ctc 2.941935 loss_rnnt 1.304080 history loss 1.413500 rank 2
2022-12-08 00:37:02,125 DEBUG CV Batch 23/0 loss 1.467866 loss_att 48.088257 loss_ctc 2.941935 loss_rnnt 1.304080 history loss 1.413500 rank 0
2022-12-08 00:37:02,134 DEBUG CV Batch 23/0 loss 1.467866 loss_att 48.088257 loss_ctc 2.941935 loss_rnnt 1.304080 history loss 1.413500 rank 5
2022-12-08 00:37:12,783 DEBUG CV Batch 23/100 loss 3.366070 loss_att 266.947937 loss_ctc 10.373991 loss_rnnt 2.587413 history loss 2.953208 rank 3
2022-12-08 00:37:12,894 DEBUG CV Batch 23/100 loss 3.366070 loss_att 266.947937 loss_ctc 10.373991 loss_rnnt 2.587413 history loss 2.953208 rank 4
2022-12-08 00:37:12,943 DEBUG CV Batch 23/100 loss 3.366070 loss_att 266.947937 loss_ctc 10.373991 loss_rnnt 2.587413 history loss 2.953208 rank 1
2022-12-08 00:37:12,956 DEBUG CV Batch 23/100 loss 3.366070 loss_att 266.947937 loss_ctc 10.373991 loss_rnnt 2.587413 history loss 2.953208 rank 0
2022-12-08 00:37:12,957 DEBUG CV Batch 23/100 loss 3.366070 loss_att 266.947937 loss_ctc 10.373991 loss_rnnt 2.587413 history loss 2.953208 rank 6
2022-12-08 00:37:12,974 DEBUG CV Batch 23/100 loss 3.366070 loss_att 266.947937 loss_ctc 10.373991 loss_rnnt 2.587413 history loss 2.953208 rank 5
2022-12-08 00:37:13,194 DEBUG CV Batch 23/100 loss 3.366070 loss_att 266.947937 loss_ctc 10.373991 loss_rnnt 2.587413 history loss 2.953208 rank 2
2022-12-08 00:37:13,268 DEBUG CV Batch 23/100 loss 3.366070 loss_att 266.947937 loss_ctc 10.373991 loss_rnnt 2.587413 history loss 2.953208 rank 7
2022-12-08 00:37:26,215 DEBUG CV Batch 23/200 loss 7.582274 loss_att 641.185913 loss_ctc 7.285358 loss_rnnt 7.615265 history loss 3.539265 rank 4
2022-12-08 00:37:26,271 DEBUG CV Batch 23/200 loss 7.582274 loss_att 641.185913 loss_ctc 7.285358 loss_rnnt 7.615265 history loss 3.539265 rank 3
2022-12-08 00:37:26,386 DEBUG CV Batch 23/200 loss 7.582274 loss_att 641.185913 loss_ctc 7.285358 loss_rnnt 7.615265 history loss 3.539265 rank 5
2022-12-08 00:37:26,431 DEBUG CV Batch 23/200 loss 7.582274 loss_att 641.185913 loss_ctc 7.285358 loss_rnnt 7.615265 history loss 3.539265 rank 0
2022-12-08 00:37:26,534 DEBUG CV Batch 23/200 loss 7.582274 loss_att 641.185913 loss_ctc 7.285358 loss_rnnt 7.615265 history loss 3.539265 rank 6
2022-12-08 00:37:26,686 DEBUG CV Batch 23/200 loss 7.582274 loss_att 641.185913 loss_ctc 7.285358 loss_rnnt 7.615265 history loss 3.539265 rank 1
2022-12-08 00:37:26,870 DEBUG CV Batch 23/200 loss 7.582274 loss_att 641.185913 loss_ctc 7.285358 loss_rnnt 7.615265 history loss 3.539265 rank 2
2022-12-08 00:37:27,137 DEBUG CV Batch 23/200 loss 7.582274 loss_att 641.185913 loss_ctc 7.285358 loss_rnnt 7.615265 history loss 3.539265 rank 7
2022-12-08 00:37:37,783 DEBUG CV Batch 23/300 loss 2.666293 loss_att 190.889130 loss_ctc 5.732357 loss_rnnt 2.325619 history loss 3.706435 rank 4
2022-12-08 00:37:37,817 DEBUG CV Batch 23/300 loss 2.666293 loss_att 190.889130 loss_ctc 5.732357 loss_rnnt 2.325619 history loss 3.706435 rank 3
2022-12-08 00:37:37,830 DEBUG CV Batch 23/300 loss 2.666293 loss_att 190.889130 loss_ctc 5.732357 loss_rnnt 2.325619 history loss 3.706435 rank 6
2022-12-08 00:37:37,885 DEBUG CV Batch 23/300 loss 2.666293 loss_att 190.889130 loss_ctc 5.732357 loss_rnnt 2.325619 history loss 3.706435 rank 5
2022-12-08 00:37:38,113 DEBUG CV Batch 23/300 loss 2.666293 loss_att 190.889130 loss_ctc 5.732357 loss_rnnt 2.325619 history loss 3.706435 rank 1
2022-12-08 00:37:38,151 DEBUG CV Batch 23/300 loss 2.666293 loss_att 190.889130 loss_ctc 5.732357 loss_rnnt 2.325619 history loss 3.706435 rank 0
2022-12-08 00:37:38,232 DEBUG CV Batch 23/300 loss 2.666293 loss_att 190.889130 loss_ctc 5.732357 loss_rnnt 2.325619 history loss 3.706435 rank 2
2022-12-08 00:37:38,907 DEBUG CV Batch 23/300 loss 2.666293 loss_att 190.889130 loss_ctc 5.732357 loss_rnnt 2.325619 history loss 3.706435 rank 7
2022-12-08 00:37:49,182 DEBUG CV Batch 23/400 loss 2.924549 loss_att 826.198608 loss_ctc 8.550071 loss_rnnt 2.299490 history loss 4.553312 rank 6
2022-12-08 00:37:49,198 DEBUG CV Batch 23/400 loss 2.924549 loss_att 826.198608 loss_ctc 8.550071 loss_rnnt 2.299490 history loss 4.553312 rank 5
2022-12-08 00:37:49,234 DEBUG CV Batch 23/400 loss 2.924549 loss_att 826.198608 loss_ctc 8.550071 loss_rnnt 2.299490 history loss 4.553312 rank 4
2022-12-08 00:37:49,306 DEBUG CV Batch 23/400 loss 2.924549 loss_att 826.198608 loss_ctc 8.550071 loss_rnnt 2.299490 history loss 4.553312 rank 1
2022-12-08 00:37:49,525 DEBUG CV Batch 23/400 loss 2.924549 loss_att 826.198608 loss_ctc 8.550071 loss_rnnt 2.299490 history loss 4.553312 rank 2
2022-12-08 00:37:49,580 DEBUG CV Batch 23/400 loss 2.924549 loss_att 826.198608 loss_ctc 8.550071 loss_rnnt 2.299490 history loss 4.553312 rank 3
2022-12-08 00:37:49,787 DEBUG CV Batch 23/400 loss 2.924549 loss_att 826.198608 loss_ctc 8.550071 loss_rnnt 2.299490 history loss 4.553312 rank 0
2022-12-08 00:37:50,460 DEBUG CV Batch 23/400 loss 2.924549 loss_att 826.198608 loss_ctc 8.550071 loss_rnnt 2.299490 history loss 4.553312 rank 7
2022-12-08 00:37:58,948 DEBUG CV Batch 23/500 loss 5.671729 loss_att 266.660126 loss_ctc 9.294095 loss_rnnt 5.269244 history loss 5.170287 rank 5
2022-12-08 00:37:59,211 DEBUG CV Batch 23/500 loss 5.671729 loss_att 266.660126 loss_ctc 9.294095 loss_rnnt 5.269244 history loss 5.170287 rank 6
2022-12-08 00:37:59,213 DEBUG CV Batch 23/500 loss 5.671729 loss_att 266.660126 loss_ctc 9.294095 loss_rnnt 5.269244 history loss 5.170287 rank 4
2022-12-08 00:37:59,373 DEBUG CV Batch 23/500 loss 5.671729 loss_att 266.660126 loss_ctc 9.294095 loss_rnnt 5.269244 history loss 5.170287 rank 3
2022-12-08 00:37:59,745 DEBUG CV Batch 23/500 loss 5.671729 loss_att 266.660126 loss_ctc 9.294095 loss_rnnt 5.269244 history loss 5.170287 rank 1
2022-12-08 00:37:59,988 DEBUG CV Batch 23/500 loss 5.671729 loss_att 266.660126 loss_ctc 9.294095 loss_rnnt 5.269244 history loss 5.170287 rank 0
2022-12-08 00:38:00,344 DEBUG CV Batch 23/500 loss 5.671729 loss_att 266.660126 loss_ctc 9.294095 loss_rnnt 5.269244 history loss 5.170287 rank 2
2022-12-08 00:38:00,908 DEBUG CV Batch 23/500 loss 5.671729 loss_att 266.660126 loss_ctc 9.294095 loss_rnnt 5.269244 history loss 5.170287 rank 7
2022-12-08 00:38:10,719 DEBUG CV Batch 23/600 loss 5.805947 loss_att 104.309166 loss_ctc 10.263912 loss_rnnt 5.310618 history loss 6.021743 rank 4
2022-12-08 00:38:10,967 DEBUG CV Batch 23/600 loss 5.805947 loss_att 104.309166 loss_ctc 10.263912 loss_rnnt 5.310618 history loss 6.021743 rank 3
2022-12-08 00:38:11,243 DEBUG CV Batch 23/600 loss 5.805947 loss_att 104.309166 loss_ctc 10.263912 loss_rnnt 5.310618 history loss 6.021743 rank 6
2022-12-08 00:38:11,378 DEBUG CV Batch 23/600 loss 5.805947 loss_att 104.309166 loss_ctc 10.263912 loss_rnnt 5.310618 history loss 6.021743 rank 5
2022-12-08 00:38:11,714 DEBUG CV Batch 23/600 loss 5.805947 loss_att 104.309166 loss_ctc 10.263912 loss_rnnt 5.310618 history loss 6.021743 rank 0
2022-12-08 00:38:12,260 DEBUG CV Batch 23/600 loss 5.805947 loss_att 104.309166 loss_ctc 10.263912 loss_rnnt 5.310618 history loss 6.021743 rank 1
2022-12-08 00:38:13,080 DEBUG CV Batch 23/600 loss 5.805947 loss_att 104.309166 loss_ctc 10.263912 loss_rnnt 5.310618 history loss 6.021743 rank 2
2022-12-08 00:38:13,638 DEBUG CV Batch 23/600 loss 5.805947 loss_att 104.309166 loss_ctc 10.263912 loss_rnnt 5.310618 history loss 6.021743 rank 7
2022-12-08 00:38:22,304 DEBUG CV Batch 23/700 loss 6.394023 loss_att 707.034180 loss_ctc 22.849478 loss_rnnt 4.565639 history loss 6.610845 rank 4
2022-12-08 00:38:22,345 DEBUG CV Batch 23/700 loss 6.394023 loss_att 707.034180 loss_ctc 22.849478 loss_rnnt 4.565639 history loss 6.610845 rank 3
2022-12-08 00:38:22,640 DEBUG CV Batch 23/700 loss 6.394023 loss_att 707.034180 loss_ctc 22.849478 loss_rnnt 4.565639 history loss 6.610845 rank 0
2022-12-08 00:38:22,808 DEBUG CV Batch 23/700 loss 6.394023 loss_att 707.034180 loss_ctc 22.849478 loss_rnnt 4.565639 history loss 6.610845 rank 5
2022-12-08 00:38:23,122 DEBUG CV Batch 23/700 loss 6.394023 loss_att 707.034180 loss_ctc 22.849478 loss_rnnt 4.565639 history loss 6.610845 rank 6
2022-12-08 00:38:24,612 DEBUG CV Batch 23/700 loss 6.394023 loss_att 707.034180 loss_ctc 22.849478 loss_rnnt 4.565639 history loss 6.610845 rank 1
2022-12-08 00:38:25,660 DEBUG CV Batch 23/700 loss 6.394023 loss_att 707.034180 loss_ctc 22.849478 loss_rnnt 4.565639 history loss 6.610845 rank 2
2022-12-08 00:38:26,096 DEBUG CV Batch 23/700 loss 6.394023 loss_att 707.034180 loss_ctc 22.849478 loss_rnnt 4.565639 history loss 6.610845 rank 7
2022-12-08 00:38:33,619 DEBUG CV Batch 23/800 loss 5.437192 loss_att 263.407898 loss_ctc 16.316761 loss_rnnt 4.228351 history loss 6.121344 rank 4
2022-12-08 00:38:33,863 DEBUG CV Batch 23/800 loss 5.437192 loss_att 263.407898 loss_ctc 16.316761 loss_rnnt 4.228351 history loss 6.121344 rank 3
2022-12-08 00:38:34,036 DEBUG CV Batch 23/800 loss 5.437192 loss_att 263.407898 loss_ctc 16.316761 loss_rnnt 4.228351 history loss 6.121344 rank 0
2022-12-08 00:38:34,583 DEBUG CV Batch 23/800 loss 5.437192 loss_att 263.407898 loss_ctc 16.316761 loss_rnnt 4.228351 history loss 6.121344 rank 5
2022-12-08 00:38:35,001 DEBUG CV Batch 23/800 loss 5.437192 loss_att 263.407898 loss_ctc 16.316761 loss_rnnt 4.228351 history loss 6.121344 rank 6
2022-12-08 00:38:37,086 DEBUG CV Batch 23/800 loss 5.437192 loss_att 263.407898 loss_ctc 16.316761 loss_rnnt 4.228351 history loss 6.121344 rank 1
2022-12-08 00:38:37,962 DEBUG CV Batch 23/800 loss 5.437192 loss_att 263.407898 loss_ctc 16.316761 loss_rnnt 4.228351 history loss 6.121344 rank 2
2022-12-08 00:38:38,869 DEBUG CV Batch 23/800 loss 5.437192 loss_att 263.407898 loss_ctc 16.316761 loss_rnnt 4.228351 history loss 6.121344 rank 7
2022-12-08 00:38:46,979 DEBUG CV Batch 23/900 loss 11.598954 loss_att 550.851807 loss_ctc 18.938042 loss_rnnt 10.783500 history loss 5.950701 rank 4
2022-12-08 00:38:47,103 DEBUG CV Batch 23/900 loss 11.598954 loss_att 550.851807 loss_ctc 18.938042 loss_rnnt 10.783500 history loss 5.950701 rank 3
2022-12-08 00:38:47,323 DEBUG CV Batch 23/900 loss 11.598954 loss_att 550.851807 loss_ctc 18.938042 loss_rnnt 10.783500 history loss 5.950701 rank 0
2022-12-08 00:38:48,076 DEBUG CV Batch 23/900 loss 11.598954 loss_att 550.851807 loss_ctc 18.938042 loss_rnnt 10.783500 history loss 5.950701 rank 5
2022-12-08 00:38:48,481 DEBUG CV Batch 23/900 loss 11.598954 loss_att 550.851807 loss_ctc 18.938042 loss_rnnt 10.783500 history loss 5.950701 rank 6
2022-12-08 00:38:50,930 DEBUG CV Batch 23/900 loss 11.598954 loss_att 550.851807 loss_ctc 18.938042 loss_rnnt 10.783500 history loss 5.950701 rank 1
2022-12-08 00:38:51,811 DEBUG CV Batch 23/900 loss 11.598954 loss_att 550.851807 loss_ctc 18.938042 loss_rnnt 10.783500 history loss 5.950701 rank 2
2022-12-08 00:38:52,721 DEBUG CV Batch 23/900 loss 11.598954 loss_att 550.851807 loss_ctc 18.938042 loss_rnnt 10.783500 history loss 5.950701 rank 7
2022-12-08 00:38:58,628 DEBUG CV Batch 23/1000 loss 2.641423 loss_att 176.489120 loss_ctc 6.558362 loss_rnnt 2.206207 history loss 5.754939 rank 4
2022-12-08 00:38:58,649 DEBUG CV Batch 23/1000 loss 2.641423 loss_att 176.489120 loss_ctc 6.558362 loss_rnnt 2.206207 history loss 5.754939 rank 3
2022-12-08 00:38:59,180 DEBUG CV Batch 23/1000 loss 2.641423 loss_att 176.489120 loss_ctc 6.558362 loss_rnnt 2.206207 history loss 5.754939 rank 0
2022-12-08 00:38:59,527 DEBUG CV Batch 23/1000 loss 2.641423 loss_att 176.489120 loss_ctc 6.558362 loss_rnnt 2.206207 history loss 5.754939 rank 5
2022-12-08 00:38:59,998 DEBUG CV Batch 23/1000 loss 2.641423 loss_att 176.489120 loss_ctc 6.558362 loss_rnnt 2.206207 history loss 5.754939 rank 6
2022-12-08 00:39:02,365 DEBUG CV Batch 23/1000 loss 2.641423 loss_att 176.489120 loss_ctc 6.558362 loss_rnnt 2.206207 history loss 5.754939 rank 1
2022-12-08 00:39:03,373 DEBUG CV Batch 23/1000 loss 2.641423 loss_att 176.489120 loss_ctc 6.558362 loss_rnnt 2.206207 history loss 5.754939 rank 2
2022-12-08 00:39:04,570 DEBUG CV Batch 23/1000 loss 2.641423 loss_att 176.489120 loss_ctc 6.558362 loss_rnnt 2.206207 history loss 5.754939 rank 7
2022-12-08 00:39:09,961 DEBUG CV Batch 23/1100 loss 4.599620 loss_att 60.695969 loss_ctc 7.807335 loss_rnnt 4.243208 history loss 5.733477 rank 4
2022-12-08 00:39:10,110 DEBUG CV Batch 23/1100 loss 4.599620 loss_att 60.695969 loss_ctc 7.807335 loss_rnnt 4.243208 history loss 5.733477 rank 3
2022-12-08 00:39:10,675 DEBUG CV Batch 23/1100 loss 4.599620 loss_att 60.695969 loss_ctc 7.807335 loss_rnnt 4.243208 history loss 5.733477 rank 5
2022-12-08 00:39:10,716 DEBUG CV Batch 23/1100 loss 4.599620 loss_att 60.695969 loss_ctc 7.807335 loss_rnnt 4.243208 history loss 5.733477 rank 0
2022-12-08 00:39:11,185 DEBUG CV Batch 23/1100 loss 4.599620 loss_att 60.695969 loss_ctc 7.807335 loss_rnnt 4.243208 history loss 5.733477 rank 6
2022-12-08 00:39:13,807 DEBUG CV Batch 23/1100 loss 4.599620 loss_att 60.695969 loss_ctc 7.807335 loss_rnnt 4.243208 history loss 5.733477 rank 1
2022-12-08 00:39:14,965 DEBUG CV Batch 23/1100 loss 4.599620 loss_att 60.695969 loss_ctc 7.807335 loss_rnnt 4.243208 history loss 5.733477 rank 2
2022-12-08 00:39:16,247 DEBUG CV Batch 23/1100 loss 4.599620 loss_att 60.695969 loss_ctc 7.807335 loss_rnnt 4.243208 history loss 5.733477 rank 7
2022-12-08 00:39:19,990 DEBUG CV Batch 23/1200 loss 9.023151 loss_att 280.461761 loss_ctc 12.303569 loss_rnnt 8.658661 history loss 6.005871 rank 4
2022-12-08 00:39:20,187 DEBUG CV Batch 23/1200 loss 9.023151 loss_att 280.461761 loss_ctc 12.303569 loss_rnnt 8.658661 history loss 6.005871 rank 3
2022-12-08 00:39:20,711 DEBUG CV Batch 23/1200 loss 9.023151 loss_att 280.461761 loss_ctc 12.303569 loss_rnnt 8.658661 history loss 6.005871 rank 0
2022-12-08 00:39:20,823 DEBUG CV Batch 23/1200 loss 9.023151 loss_att 280.461761 loss_ctc 12.303569 loss_rnnt 8.658661 history loss 6.005871 rank 5
2022-12-08 00:39:21,325 DEBUG CV Batch 23/1200 loss 9.023151 loss_att 280.461761 loss_ctc 12.303569 loss_rnnt 8.658661 history loss 6.005871 rank 6
2022-12-08 00:39:24,847 DEBUG CV Batch 23/1200 loss 9.023151 loss_att 280.461761 loss_ctc 12.303569 loss_rnnt 8.658661 history loss 6.005871 rank 1
2022-12-08 00:39:26,173 DEBUG CV Batch 23/1200 loss 9.023151 loss_att 280.461761 loss_ctc 12.303569 loss_rnnt 8.658661 history loss 6.005871 rank 2
2022-12-08 00:39:27,353 DEBUG CV Batch 23/1200 loss 9.023151 loss_att 280.461761 loss_ctc 12.303569 loss_rnnt 8.658661 history loss 6.005871 rank 7
2022-12-08 00:39:31,483 DEBUG CV Batch 23/1300 loss 4.912792 loss_att 105.977547 loss_ctc 8.873749 loss_rnnt 4.472686 history loss 6.287294 rank 4
2022-12-08 00:39:31,769 DEBUG CV Batch 23/1300 loss 4.912792 loss_att 105.977547 loss_ctc 8.873749 loss_rnnt 4.472686 history loss 6.287294 rank 3
2022-12-08 00:39:32,264 DEBUG CV Batch 23/1300 loss 4.912792 loss_att 105.977547 loss_ctc 8.873749 loss_rnnt 4.472686 history loss 6.287294 rank 0
2022-12-08 00:39:32,505 DEBUG CV Batch 23/1300 loss 4.912792 loss_att 105.977547 loss_ctc 8.873749 loss_rnnt 4.472686 history loss 6.287294 rank 5
2022-12-08 00:39:32,941 DEBUG CV Batch 23/1300 loss 4.912792 loss_att 105.977547 loss_ctc 8.873749 loss_rnnt 4.472686 history loss 6.287294 rank 6
2022-12-08 00:39:36,707 DEBUG CV Batch 23/1300 loss 4.912792 loss_att 105.977547 loss_ctc 8.873749 loss_rnnt 4.472686 history loss 6.287294 rank 1
2022-12-08 00:39:38,086 DEBUG CV Batch 23/1300 loss 4.912792 loss_att 105.977547 loss_ctc 8.873749 loss_rnnt 4.472686 history loss 6.287294 rank 2
2022-12-08 00:39:39,395 DEBUG CV Batch 23/1300 loss 4.912792 loss_att 105.977547 loss_ctc 8.873749 loss_rnnt 4.472686 history loss 6.287294 rank 7
2022-12-08 00:39:42,563 DEBUG CV Batch 23/1400 loss 2.995608 loss_att 562.102783 loss_ctc 6.373469 loss_rnnt 2.620290 history loss 6.577492 rank 3
2022-12-08 00:39:42,690 DEBUG CV Batch 23/1400 loss 2.995608 loss_att 562.102783 loss_ctc 6.373469 loss_rnnt 2.620290 history loss 6.577492 rank 4
2022-12-08 00:39:43,140 DEBUG CV Batch 23/1400 loss 2.995608 loss_att 562.102783 loss_ctc 6.373469 loss_rnnt 2.620290 history loss 6.577492 rank 0
2022-12-08 00:39:44,428 DEBUG CV Batch 23/1400 loss 2.995608 loss_att 562.102783 loss_ctc 6.373469 loss_rnnt 2.620290 history loss 6.577492 rank 5
2022-12-08 00:39:44,885 DEBUG CV Batch 23/1400 loss 2.995608 loss_att 562.102783 loss_ctc 6.373469 loss_rnnt 2.620290 history loss 6.577492 rank 6
2022-12-08 00:39:49,373 DEBUG CV Batch 23/1400 loss 2.995608 loss_att 562.102783 loss_ctc 6.373469 loss_rnnt 2.620290 history loss 6.577492 rank 1
2022-12-08 00:39:50,695 DEBUG CV Batch 23/1400 loss 2.995608 loss_att 562.102783 loss_ctc 6.373469 loss_rnnt 2.620290 history loss 6.577492 rank 2
2022-12-08 00:39:52,199 DEBUG CV Batch 23/1400 loss 2.995608 loss_att 562.102783 loss_ctc 6.373469 loss_rnnt 2.620290 history loss 6.577492 rank 7
2022-12-08 00:39:54,313 DEBUG CV Batch 23/1500 loss 7.482151 loss_att 275.491730 loss_ctc 6.975890 loss_rnnt 7.538403 history loss 6.455282 rank 3
2022-12-08 00:39:54,421 DEBUG CV Batch 23/1500 loss 7.482151 loss_att 275.491730 loss_ctc 6.975890 loss_rnnt 7.538403 history loss 6.455282 rank 4
2022-12-08 00:39:54,762 DEBUG CV Batch 23/1500 loss 7.482151 loss_att 275.491730 loss_ctc 6.975890 loss_rnnt 7.538403 history loss 6.455282 rank 0
2022-12-08 00:39:56,327 DEBUG CV Batch 23/1500 loss 7.482151 loss_att 275.491730 loss_ctc 6.975890 loss_rnnt 7.538403 history loss 6.455282 rank 5
2022-12-08 00:39:57,180 DEBUG CV Batch 23/1500 loss 7.482151 loss_att 275.491730 loss_ctc 6.975890 loss_rnnt 7.538403 history loss 6.455282 rank 6
2022-12-08 00:40:02,033 DEBUG CV Batch 23/1500 loss 7.482151 loss_att 275.491730 loss_ctc 6.975890 loss_rnnt 7.538403 history loss 6.455282 rank 1
2022-12-08 00:40:03,430 DEBUG CV Batch 23/1500 loss 7.482151 loss_att 275.491730 loss_ctc 6.975890 loss_rnnt 7.538403 history loss 6.455282 rank 2
2022-12-08 00:40:05,415 DEBUG CV Batch 23/1500 loss 7.482151 loss_att 275.491730 loss_ctc 6.975890 loss_rnnt 7.538403 history loss 6.455282 rank 7
2022-12-08 00:40:07,519 DEBUG CV Batch 23/1600 loss 6.227175 loss_att 593.911804 loss_ctc 13.846073 loss_rnnt 5.380630 history loss 6.420856 rank 4
2022-12-08 00:40:07,535 DEBUG CV Batch 23/1600 loss 6.227175 loss_att 593.911804 loss_ctc 13.846073 loss_rnnt 5.380630 history loss 6.420856 rank 3
2022-12-08 00:40:07,853 DEBUG CV Batch 23/1600 loss 6.227175 loss_att 593.911804 loss_ctc 13.846073 loss_rnnt 5.380630 history loss 6.420856 rank 0
2022-12-08 00:40:09,849 DEBUG CV Batch 23/1600 loss 6.227175 loss_att 593.911804 loss_ctc 13.846073 loss_rnnt 5.380630 history loss 6.420856 rank 5
2022-12-08 00:40:10,505 DEBUG CV Batch 23/1600 loss 6.227175 loss_att 593.911804 loss_ctc 13.846073 loss_rnnt 5.380630 history loss 6.420856 rank 6
2022-12-08 00:40:15,652 DEBUG CV Batch 23/1600 loss 6.227175 loss_att 593.911804 loss_ctc 13.846073 loss_rnnt 5.380630 history loss 6.420856 rank 1
2022-12-08 00:40:16,978 DEBUG CV Batch 23/1600 loss 6.227175 loss_att 593.911804 loss_ctc 13.846073 loss_rnnt 5.380630 history loss 6.420856 rank 2
2022-12-08 00:40:19,130 DEBUG CV Batch 23/1600 loss 6.227175 loss_att 593.911804 loss_ctc 13.846073 loss_rnnt 5.380630 history loss 6.420856 rank 7
2022-12-08 00:40:19,348 DEBUG CV Batch 23/1700 loss 8.679495 loss_att 210.847168 loss_ctc 16.824917 loss_rnnt 7.774448 history loss 6.359133 rank 4
2022-12-08 00:40:19,509 DEBUG CV Batch 23/1700 loss 8.679495 loss_att 210.847168 loss_ctc 16.824917 loss_rnnt 7.774448 history loss 6.359133 rank 3
2022-12-08 00:40:19,952 DEBUG CV Batch 23/1700 loss 8.679495 loss_att 210.847168 loss_ctc 16.824917 loss_rnnt 7.774448 history loss 6.359133 rank 0
2022-12-08 00:40:21,795 DEBUG CV Batch 23/1700 loss 8.679495 loss_att 210.847168 loss_ctc 16.824917 loss_rnnt 7.774448 history loss 6.359133 rank 5
2022-12-08 00:40:22,428 DEBUG CV Batch 23/1700 loss 8.679495 loss_att 210.847168 loss_ctc 16.824917 loss_rnnt 7.774448 history loss 6.359133 rank 6
2022-12-08 00:40:27,215 DEBUG CV Batch 23/1700 loss 8.679495 loss_att 210.847168 loss_ctc 16.824917 loss_rnnt 7.774448 history loss 6.359133 rank 1
2022-12-08 00:40:28,151 INFO Epoch 23 CV info cv_loss 6.338654023533371
2022-12-08 00:40:28,152 INFO Epoch 24 TRAIN info lr 0.00026408086456140015
2022-12-08 00:40:28,156 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 00:40:28,797 DEBUG CV Batch 23/1700 loss 8.679495 loss_att 210.847168 loss_ctc 16.824917 loss_rnnt 7.774448 history loss 6.359133 rank 2
2022-12-08 00:40:28,897 INFO Epoch 23 CV info cv_loss 6.338654023533371
2022-12-08 00:40:28,898 INFO Epoch 24 TRAIN info lr 0.00026409265201103875
2022-12-08 00:40:28,899 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 00:40:29,010 INFO Epoch 23 CV info cv_loss 6.338654023533371
2022-12-08 00:40:29,011 INFO Checkpoint: save to checkpoint exp/1204_encoder_bias_nobi_noatt/23.pt
2022-12-08 00:40:29,535 INFO Epoch 24 TRAIN info lr 0.0002640790229149664
2022-12-08 00:40:29,538 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 00:40:30,887 DEBUG CV Batch 23/1700 loss 8.679495 loss_att 210.847168 loss_ctc 16.824917 loss_rnnt 7.774448 history loss 6.359133 rank 7
2022-12-08 00:40:30,918 INFO Epoch 23 CV info cv_loss 6.338654023533371
2022-12-08 00:40:30,918 INFO Epoch 24 TRAIN info lr 0.00026407018354838784
2022-12-08 00:40:30,923 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 00:40:31,601 INFO Epoch 23 CV info cv_loss 6.338654023533371
2022-12-08 00:40:31,602 INFO Epoch 24 TRAIN info lr 0.00026407865459030313
2022-12-08 00:40:31,607 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 00:40:35,987 INFO Epoch 23 CV info cv_loss 6.338654023533371
2022-12-08 00:40:35,987 INFO Epoch 24 TRAIN info lr 0.0002640944939426309
2022-12-08 00:40:35,991 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 00:40:37,654 INFO Epoch 23 CV info cv_loss 6.338654023533371
2022-12-08 00:40:37,654 INFO Epoch 24 TRAIN info lr 0.0002640779179456002
2022-12-08 00:40:37,655 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 00:40:39,872 INFO Epoch 23 CV info cv_loss 6.338654023533371
2022-12-08 00:40:39,872 INFO Epoch 24 TRAIN info lr 0.0002640646593950027
2022-12-08 00:40:39,874 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 00:41:39,395 DEBUG TRAIN Batch 24/0 loss 8.498958 loss_att 61.700874 loss_ctc 12.784648 loss_rnnt 8.022770 lr 0.00026408 rank 4
2022-12-08 00:41:39,398 DEBUG TRAIN Batch 24/0 loss 5.511490 loss_att 76.324982 loss_ctc 10.041116 loss_rnnt 5.008198 lr 0.00026408 rank 0
2022-12-08 00:41:39,398 DEBUG TRAIN Batch 24/0 loss 8.083335 loss_att 66.294975 loss_ctc 11.665872 loss_rnnt 7.685276 lr 0.00026408 rank 6
2022-12-08 00:41:39,404 DEBUG TRAIN Batch 24/0 loss 6.226711 loss_att 60.525227 loss_ctc 9.798333 loss_rnnt 5.829864 lr 0.00026409 rank 3
2022-12-08 00:41:39,405 DEBUG TRAIN Batch 24/0 loss 7.901018 loss_att 68.774963 loss_ctc 12.068187 loss_rnnt 7.438000 lr 0.00026407 rank 5
2022-12-08 00:41:39,406 DEBUG TRAIN Batch 24/0 loss 6.498304 loss_att 77.934822 loss_ctc 8.419822 loss_rnnt 6.284802 lr 0.00026406 rank 7
2022-12-08 00:41:39,430 DEBUG TRAIN Batch 24/0 loss 8.181738 loss_att 69.787689 loss_ctc 11.931598 loss_rnnt 7.765087 lr 0.00026409 rank 1
2022-12-08 00:41:39,456 DEBUG TRAIN Batch 24/0 loss 8.704686 loss_att 76.075127 loss_ctc 14.889343 loss_rnnt 8.017502 lr 0.00026408 rank 2
2022-12-08 00:42:41,884 DEBUG TRAIN Batch 24/100 loss 14.931952 loss_att 430.040039 loss_ctc 25.235134 loss_rnnt 13.787153 lr 0.00026404 rank 0
2022-12-08 00:42:41,894 DEBUG TRAIN Batch 24/100 loss 6.805391 loss_att 373.753265 loss_ctc 12.677780 loss_rnnt 6.152904 lr 0.00026404 rank 4
2022-12-08 00:42:41,894 DEBUG TRAIN Batch 24/100 loss 3.258749 loss_att 360.010498 loss_ctc 6.559307 loss_rnnt 2.892020 lr 0.00026403 rank 7
2022-12-08 00:42:41,897 DEBUG TRAIN Batch 24/100 loss 3.991093 loss_att 376.706543 loss_ctc 13.571676 loss_rnnt 2.926584 lr 0.00026406 rank 1
2022-12-08 00:42:41,902 DEBUG TRAIN Batch 24/100 loss 13.057279 loss_att 472.373047 loss_ctc 41.404350 loss_rnnt 9.907604 lr 0.00026403 rank 5
2022-12-08 00:42:41,902 DEBUG TRAIN Batch 24/100 loss 8.625896 loss_att 391.899597 loss_ctc 11.185355 loss_rnnt 8.341512 lr 0.00026406 rank 3
2022-12-08 00:42:41,902 DEBUG TRAIN Batch 24/100 loss 5.932704 loss_att 380.802979 loss_ctc 14.118290 loss_rnnt 5.023194 lr 0.00026404 rank 2
2022-12-08 00:42:41,902 DEBUG TRAIN Batch 24/100 loss 7.068119 loss_att 367.331512 loss_ctc 18.153866 loss_rnnt 5.836369 lr 0.00026404 rank 6
2022-12-08 00:43:44,487 DEBUG TRAIN Batch 24/200 loss 7.038540 loss_att 386.256348 loss_ctc 19.785851 loss_rnnt 5.622172 lr 0.00026401 rank 4
2022-12-08 00:43:44,490 DEBUG TRAIN Batch 24/200 loss 4.971301 loss_att 444.882263 loss_ctc 15.314548 loss_rnnt 3.822052 lr 0.00026399 rank 7
2022-12-08 00:43:44,490 DEBUG TRAIN Batch 24/200 loss 3.698411 loss_att 391.187561 loss_ctc 7.951987 loss_rnnt 3.225792 lr 0.00026401 rank 0
2022-12-08 00:43:44,494 DEBUG TRAIN Batch 24/200 loss 7.415908 loss_att 355.738007 loss_ctc 14.826668 loss_rnnt 6.592490 lr 0.00026400 rank 5
2022-12-08 00:43:44,494 DEBUG TRAIN Batch 24/200 loss 3.266408 loss_att 388.504883 loss_ctc 8.813933 loss_rnnt 2.650017 lr 0.00026402 rank 1
2022-12-08 00:43:44,496 DEBUG TRAIN Batch 24/200 loss 10.037965 loss_att 432.500427 loss_ctc 18.467045 loss_rnnt 9.101400 lr 0.00026400 rank 2
2022-12-08 00:43:44,496 DEBUG TRAIN Batch 24/200 loss 3.358557 loss_att 394.943726 loss_ctc 8.425535 loss_rnnt 2.795559 lr 0.00026400 rank 6
2022-12-08 00:43:44,499 DEBUG TRAIN Batch 24/200 loss 13.025292 loss_att 443.289368 loss_ctc 18.445969 loss_rnnt 12.422996 lr 0.00026402 rank 3
2022-12-08 00:44:48,563 DEBUG TRAIN Batch 24/300 loss 7.725818 loss_att 345.088684 loss_ctc 22.980820 loss_rnnt 6.030818 lr 0.00026397 rank 4
2022-12-08 00:44:48,567 DEBUG TRAIN Batch 24/300 loss 13.934071 loss_att 421.858643 loss_ctc 29.569384 loss_rnnt 12.196814 lr 0.00026397 rank 0
2022-12-08 00:44:48,567 DEBUG TRAIN Batch 24/300 loss 6.348911 loss_att 384.759735 loss_ctc 17.283886 loss_rnnt 5.133914 lr 0.00026396 rank 5
2022-12-08 00:44:48,569 DEBUG TRAIN Batch 24/300 loss 6.715649 loss_att 369.608398 loss_ctc 14.524225 loss_rnnt 5.848029 lr 0.00026398 rank 1
2022-12-08 00:44:48,569 DEBUG TRAIN Batch 24/300 loss 6.754849 loss_att 406.118286 loss_ctc 13.449577 loss_rnnt 6.010991 lr 0.00026395 rank 7
2022-12-08 00:44:48,575 DEBUG TRAIN Batch 24/300 loss 10.080384 loss_att 409.302155 loss_ctc 13.854206 loss_rnnt 9.661071 lr 0.00026397 rank 6
2022-12-08 00:44:48,589 DEBUG TRAIN Batch 24/300 loss 13.309780 loss_att 380.506958 loss_ctc 31.115337 loss_rnnt 11.331385 lr 0.00026398 rank 3
2022-12-08 00:44:48,592 DEBUG TRAIN Batch 24/300 loss 4.297142 loss_att 398.794617 loss_ctc 12.588095 loss_rnnt 3.375925 lr 0.00026397 rank 2
2022-12-08 00:45:58,477 DEBUG TRAIN Batch 24/400 loss 7.354738 loss_att 348.374573 loss_ctc 12.566150 loss_rnnt 6.775692 lr 0.00026393 rank 4
2022-12-08 00:45:58,479 DEBUG TRAIN Batch 24/400 loss 11.342297 loss_att 356.145721 loss_ctc 15.049562 loss_rnnt 10.930379 lr 0.00026393 rank 6
2022-12-08 00:45:58,480 DEBUG TRAIN Batch 24/400 loss 8.444576 loss_att 346.725952 loss_ctc 18.860680 loss_rnnt 7.287231 lr 0.00026392 rank 7
2022-12-08 00:45:58,480 DEBUG TRAIN Batch 24/400 loss 4.713929 loss_att 376.299072 loss_ctc 7.761810 loss_rnnt 4.375276 lr 0.00026393 rank 2
2022-12-08 00:45:58,481 DEBUG TRAIN Batch 24/400 loss 13.163529 loss_att 337.807861 loss_ctc 29.254086 loss_rnnt 11.375690 lr 0.00026393 rank 0
2022-12-08 00:45:58,485 DEBUG TRAIN Batch 24/400 loss 10.713526 loss_att 395.965912 loss_ctc 17.519239 loss_rnnt 9.957336 lr 0.00026395 rank 3
2022-12-08 00:45:58,486 DEBUG TRAIN Batch 24/400 loss 7.525828 loss_att 363.251648 loss_ctc 13.180717 loss_rnnt 6.897507 lr 0.00026395 rank 1
2022-12-08 00:45:58,491 DEBUG TRAIN Batch 24/400 loss 7.322795 loss_att 353.770996 loss_ctc 14.090801 loss_rnnt 6.570795 lr 0.00026392 rank 5
2022-12-08 00:47:00,912 DEBUG TRAIN Batch 24/500 loss 3.942580 loss_att 368.256348 loss_ctc 10.609480 loss_rnnt 3.201813 lr 0.00026389 rank 0
2022-12-08 00:47:00,923 DEBUG TRAIN Batch 24/500 loss 11.702970 loss_att 400.754395 loss_ctc 18.844246 loss_rnnt 10.909495 lr 0.00026388 rank 7
2022-12-08 00:47:00,923 DEBUG TRAIN Batch 24/500 loss 19.625200 loss_att 335.814972 loss_ctc 32.157520 loss_rnnt 18.232721 lr 0.00026390 rank 4
2022-12-08 00:47:00,924 DEBUG TRAIN Batch 24/500 loss 6.790219 loss_att 350.796478 loss_ctc 19.184746 loss_rnnt 5.413049 lr 0.00026389 rank 6
2022-12-08 00:47:00,925 DEBUG TRAIN Batch 24/500 loss 9.772821 loss_att 321.633423 loss_ctc 16.948990 loss_rnnt 8.975470 lr 0.00026389 rank 2
2022-12-08 00:47:00,927 DEBUG TRAIN Batch 24/500 loss 8.802893 loss_att 318.632202 loss_ctc 15.642672 loss_rnnt 8.042918 lr 0.00026391 rank 3
2022-12-08 00:47:00,928 DEBUG TRAIN Batch 24/500 loss 9.462917 loss_att 308.077850 loss_ctc 23.884966 loss_rnnt 7.860467 lr 0.00026391 rank 1
2022-12-08 00:47:00,929 DEBUG TRAIN Batch 24/500 loss 9.684854 loss_att 309.860107 loss_ctc 22.685841 loss_rnnt 8.240299 lr 0.00026389 rank 5
2022-12-08 00:48:03,456 DEBUG TRAIN Batch 24/600 loss 9.659369 loss_att 185.006836 loss_ctc 18.727011 loss_rnnt 8.651854 lr 0.00026386 rank 6
2022-12-08 00:48:03,459 DEBUG TRAIN Batch 24/600 loss 9.160908 loss_att 240.570892 loss_ctc 17.306965 loss_rnnt 8.255791 lr 0.00026387 rank 3
2022-12-08 00:48:03,461 DEBUG TRAIN Batch 24/600 loss 9.864507 loss_att 178.823883 loss_ctc 15.509344 loss_rnnt 9.237303 lr 0.00026384 rank 7
2022-12-08 00:48:03,461 DEBUG TRAIN Batch 24/600 loss 9.236187 loss_att 161.356491 loss_ctc 14.769243 loss_rnnt 8.621404 lr 0.00026386 rank 2
2022-12-08 00:48:03,461 DEBUG TRAIN Batch 24/600 loss 5.229321 loss_att 194.581482 loss_ctc 8.939876 loss_rnnt 4.817038 lr 0.00026386 rank 0
2022-12-08 00:48:03,462 DEBUG TRAIN Batch 24/600 loss 10.087370 loss_att 171.891815 loss_ctc 16.232798 loss_rnnt 9.404545 lr 0.00026387 rank 1
2022-12-08 00:48:03,464 DEBUG TRAIN Batch 24/600 loss 6.825963 loss_att 350.354797 loss_ctc 19.767576 loss_rnnt 5.388007 lr 0.00026386 rank 4
2022-12-08 00:48:03,465 DEBUG TRAIN Batch 24/600 loss 6.993607 loss_att 225.882324 loss_ctc 12.372709 loss_rnnt 6.395929 lr 0.00026385 rank 5
2022-12-08 00:49:08,894 DEBUG TRAIN Batch 24/700 loss 10.088421 loss_att 382.169128 loss_ctc 21.169041 loss_rnnt 8.857242 lr 0.00026382 rank 4
2022-12-08 00:49:08,894 DEBUG TRAIN Batch 24/700 loss 6.706433 loss_att 404.685150 loss_ctc 16.621506 loss_rnnt 5.604759 lr 0.00026381 rank 7
2022-12-08 00:49:08,897 DEBUG TRAIN Batch 24/700 loss 5.077383 loss_att 437.926331 loss_ctc 9.524588 loss_rnnt 4.583249 lr 0.00026384 rank 1
2022-12-08 00:49:08,900 DEBUG TRAIN Batch 24/700 loss 4.826044 loss_att 348.411194 loss_ctc 8.642416 loss_rnnt 4.402002 lr 0.00026381 rank 5
2022-12-08 00:49:08,901 DEBUG TRAIN Batch 24/700 loss 15.665907 loss_att 377.913513 loss_ctc 28.955244 loss_rnnt 14.189315 lr 0.00026382 rank 2
2022-12-08 00:49:08,901 DEBUG TRAIN Batch 24/700 loss 7.719889 loss_att 311.240051 loss_ctc 11.637098 loss_rnnt 7.284643 lr 0.00026382 rank 0
2022-12-08 00:49:08,918 DEBUG TRAIN Batch 24/700 loss 1.313071 loss_att 402.030273 loss_ctc 3.238083 loss_rnnt 1.099181 lr 0.00026383 rank 3
2022-12-08 00:49:08,936 DEBUG TRAIN Batch 24/700 loss 5.972741 loss_att 443.741272 loss_ctc 15.654319 loss_rnnt 4.897010 lr 0.00026382 rank 6
2022-12-08 00:50:16,466 DEBUG TRAIN Batch 24/800 loss 6.617753 loss_att 395.122253 loss_ctc 15.524534 loss_rnnt 5.628110 lr 0.00026377 rank 7
2022-12-08 00:50:16,469 DEBUG TRAIN Batch 24/800 loss 6.436820 loss_att 368.570648 loss_ctc 15.316912 loss_rnnt 5.450143 lr 0.00026379 rank 4
2022-12-08 00:50:16,472 DEBUG TRAIN Batch 24/800 loss 2.983224 loss_att 376.419983 loss_ctc 7.790572 loss_rnnt 2.449074 lr 0.00026378 rank 0
2022-12-08 00:50:16,473 DEBUG TRAIN Batch 24/800 loss 10.537971 loss_att 370.715302 loss_ctc 16.285355 loss_rnnt 9.899374 lr 0.00026378 rank 5
2022-12-08 00:50:16,474 DEBUG TRAIN Batch 24/800 loss 12.421378 loss_att 407.616150 loss_ctc 35.670673 loss_rnnt 9.838123 lr 0.00026380 rank 1
2022-12-08 00:50:16,477 DEBUG TRAIN Batch 24/800 loss 6.439212 loss_att 455.241425 loss_ctc 18.824852 loss_rnnt 5.063030 lr 0.00026380 rank 3
2022-12-08 00:50:16,478 DEBUG TRAIN Batch 24/800 loss 6.411686 loss_att 335.834900 loss_ctc 11.957222 loss_rnnt 5.795516 lr 0.00026378 rank 2
2022-12-08 00:50:16,516 DEBUG TRAIN Batch 24/800 loss 2.235089 loss_att 336.944946 loss_ctc 6.285515 loss_rnnt 1.785042 lr 0.00026378 rank 6
2022-12-08 00:51:19,727 DEBUG TRAIN Batch 24/900 loss 14.223490 loss_att 366.087402 loss_ctc 34.555264 loss_rnnt 11.964404 lr 0.00026375 rank 4
2022-12-08 00:51:19,730 DEBUG TRAIN Batch 24/900 loss 8.361521 loss_att 428.078613 loss_ctc 26.826378 loss_rnnt 6.309870 lr 0.00026373 rank 7
2022-12-08 00:51:19,733 DEBUG TRAIN Batch 24/900 loss 11.299498 loss_att 349.041870 loss_ctc 15.751356 loss_rnnt 10.804848 lr 0.00026375 rank 6
2022-12-08 00:51:19,733 DEBUG TRAIN Batch 24/900 loss 3.702651 loss_att 322.202850 loss_ctc 8.827160 loss_rnnt 3.133261 lr 0.00026376 rank 1
2022-12-08 00:51:19,735 DEBUG TRAIN Batch 24/900 loss 4.260034 loss_att 339.080750 loss_ctc 11.575657 loss_rnnt 3.447187 lr 0.00026375 rank 0
2022-12-08 00:51:19,735 DEBUG TRAIN Batch 24/900 loss 9.108906 loss_att 337.852081 loss_ctc 15.713653 loss_rnnt 8.375046 lr 0.00026374 rank 5
2022-12-08 00:51:19,736 DEBUG TRAIN Batch 24/900 loss 11.565698 loss_att 338.089294 loss_ctc 21.679989 loss_rnnt 10.441887 lr 0.00026376 rank 3
2022-12-08 00:51:19,737 DEBUG TRAIN Batch 24/900 loss 3.244029 loss_att 450.083862 loss_ctc 7.984257 loss_rnnt 2.717337 lr 0.00026375 rank 2
2022-12-08 00:52:23,176 DEBUG TRAIN Batch 24/1000 loss 4.884727 loss_att 332.718567 loss_ctc 11.655925 loss_rnnt 4.132372 lr 0.00026371 rank 6
2022-12-08 00:52:23,177 DEBUG TRAIN Batch 24/1000 loss 7.997512 loss_att 349.453125 loss_ctc 19.709818 loss_rnnt 6.696145 lr 0.00026370 rank 5
2022-12-08 00:52:23,184 DEBUG TRAIN Batch 24/1000 loss 5.965672 loss_att 386.579041 loss_ctc 11.764774 loss_rnnt 5.321328 lr 0.00026371 rank 0
2022-12-08 00:52:23,184 DEBUG TRAIN Batch 24/1000 loss 11.778397 loss_att 438.590698 loss_ctc 25.935432 loss_rnnt 10.205393 lr 0.00026372 rank 3
2022-12-08 00:52:23,185 DEBUG TRAIN Batch 24/1000 loss 8.193047 loss_att 370.722198 loss_ctc 19.288622 loss_rnnt 6.960205 lr 0.00026371 rank 2
2022-12-08 00:52:23,187 DEBUG TRAIN Batch 24/1000 loss 7.596334 loss_att 436.405975 loss_ctc 19.257557 loss_rnnt 6.300643 lr 0.00026373 rank 1
2022-12-08 00:52:23,190 DEBUG TRAIN Batch 24/1000 loss 3.978985 loss_att 326.174255 loss_ctc 8.730220 loss_rnnt 3.451070 lr 0.00026370 rank 7
2022-12-08 00:52:23,203 DEBUG TRAIN Batch 24/1000 loss 4.613508 loss_att 375.995453 loss_ctc 9.658638 loss_rnnt 4.052938 lr 0.00026371 rank 4
2022-12-08 00:53:32,670 DEBUG TRAIN Batch 24/1100 loss 8.283614 loss_att 342.563141 loss_ctc 17.719788 loss_rnnt 7.235151 lr 0.00026369 rank 1
2022-12-08 00:53:32,673 DEBUG TRAIN Batch 24/1100 loss 5.150038 loss_att 357.109680 loss_ctc 13.586771 loss_rnnt 4.212623 lr 0.00026366 rank 7
2022-12-08 00:53:32,674 DEBUG TRAIN Batch 24/1100 loss 6.119830 loss_att 342.379089 loss_ctc 12.961227 loss_rnnt 5.359675 lr 0.00026367 rank 6
2022-12-08 00:53:32,676 DEBUG TRAIN Batch 24/1100 loss 16.592670 loss_att 342.305389 loss_ctc 33.181042 loss_rnnt 14.749519 lr 0.00026369 rank 3
2022-12-08 00:53:32,675 DEBUG TRAIN Batch 24/1100 loss 2.552283 loss_att 331.341492 loss_ctc 10.621449 loss_rnnt 1.655709 lr 0.00026368 rank 4
2022-12-08 00:53:32,676 DEBUG TRAIN Batch 24/1100 loss 5.140132 loss_att 331.154358 loss_ctc 13.640583 loss_rnnt 4.195638 lr 0.00026367 rank 2
2022-12-08 00:53:32,676 DEBUG TRAIN Batch 24/1100 loss 2.499908 loss_att 311.409637 loss_ctc 7.825828 loss_rnnt 1.908140 lr 0.00026367 rank 0
2022-12-08 00:53:32,719 DEBUG TRAIN Batch 24/1100 loss 9.414690 loss_att 313.091309 loss_ctc 13.394938 loss_rnnt 8.972441 lr 0.00026367 rank 5
2022-12-08 00:54:36,156 DEBUG TRAIN Batch 24/1200 loss 5.509598 loss_att 290.532440 loss_ctc 14.361821 loss_rnnt 4.526018 lr 0.00026364 rank 6
2022-12-08 00:54:36,157 DEBUG TRAIN Batch 24/1200 loss 8.476314 loss_att 308.579559 loss_ctc 17.641815 loss_rnnt 7.457925 lr 0.00026364 rank 2
2022-12-08 00:54:36,158 DEBUG TRAIN Batch 24/1200 loss 17.508045 loss_att 308.050873 loss_ctc 28.271351 loss_rnnt 16.312122 lr 0.00026362 rank 7
2022-12-08 00:54:36,158 DEBUG TRAIN Batch 24/1200 loss 6.786096 loss_att 293.146057 loss_ctc 11.123733 loss_rnnt 6.304137 lr 0.00026364 rank 4
2022-12-08 00:54:36,158 DEBUG TRAIN Batch 24/1200 loss 8.538692 loss_att 297.863403 loss_ctc 19.525267 loss_rnnt 7.317961 lr 0.00026365 rank 1
2022-12-08 00:54:36,165 DEBUG TRAIN Batch 24/1200 loss 8.916081 loss_att 312.398407 loss_ctc 20.969778 loss_rnnt 7.576782 lr 0.00026363 rank 5
2022-12-08 00:54:36,166 DEBUG TRAIN Batch 24/1200 loss 4.434368 loss_att 278.849365 loss_ctc 12.814004 loss_rnnt 3.503298 lr 0.00026364 rank 0
2022-12-08 00:54:36,167 DEBUG TRAIN Batch 24/1200 loss 10.092940 loss_att 281.432037 loss_ctc 21.460939 loss_rnnt 8.829829 lr 0.00026365 rank 3
2022-12-08 00:55:39,242 DEBUG TRAIN Batch 24/1300 loss 10.062928 loss_att 229.806519 loss_ctc 17.872169 loss_rnnt 9.195234 lr 0.00026360 rank 4
2022-12-08 00:55:39,245 DEBUG TRAIN Batch 24/1300 loss 7.232294 loss_att 411.364594 loss_ctc 13.859402 loss_rnnt 6.495948 lr 0.00026359 rank 7
2022-12-08 00:55:39,245 DEBUG TRAIN Batch 24/1300 loss 10.118587 loss_att 427.680847 loss_ctc 17.439869 loss_rnnt 9.305111 lr 0.00026360 rank 6
2022-12-08 00:55:39,246 DEBUG TRAIN Batch 24/1300 loss 10.912946 loss_att 119.292267 loss_ctc 16.998184 loss_rnnt 10.236808 lr 0.00026362 rank 1
2022-12-08 00:55:39,248 DEBUG TRAIN Batch 24/1300 loss 6.242983 loss_att 136.532227 loss_ctc 11.524289 loss_rnnt 5.656171 lr 0.00026360 rank 0
2022-12-08 00:55:39,252 DEBUG TRAIN Batch 24/1300 loss 13.116966 loss_att 194.755066 loss_ctc 23.273273 loss_rnnt 11.988487 lr 0.00026361 rank 3
2022-12-08 00:55:39,253 DEBUG TRAIN Batch 24/1300 loss 2.924397 loss_att 399.226013 loss_ctc 7.753959 loss_rnnt 2.387780 lr 0.00026360 rank 2
2022-12-08 00:55:39,260 DEBUG TRAIN Batch 24/1300 loss 6.828252 loss_att 67.766487 loss_ctc 9.848815 loss_rnnt 6.492634 lr 0.00026359 rank 5
2022-12-08 00:56:43,754 DEBUG TRAIN Batch 24/1400 loss 6.840648 loss_att 337.548981 loss_ctc 16.713257 loss_rnnt 5.743692 lr 0.00026356 rank 2
2022-12-08 00:56:43,759 DEBUG TRAIN Batch 24/1400 loss 9.300734 loss_att 454.823425 loss_ctc 30.038662 loss_rnnt 6.996520 lr 0.00026356 rank 6
2022-12-08 00:56:43,768 DEBUG TRAIN Batch 24/1400 loss 2.557769 loss_att 397.054688 loss_ctc 9.543515 loss_rnnt 1.781575 lr 0.00026357 rank 4
2022-12-08 00:56:43,768 DEBUG TRAIN Batch 24/1400 loss 7.844344 loss_att 434.523438 loss_ctc 14.018008 loss_rnnt 7.158382 lr 0.00026358 rank 3
2022-12-08 00:56:43,770 DEBUG TRAIN Batch 24/1400 loss 5.951715 loss_att 423.763184 loss_ctc 16.684380 loss_rnnt 4.759197 lr 0.00026358 rank 1
2022-12-08 00:56:43,771 DEBUG TRAIN Batch 24/1400 loss 9.361182 loss_att 433.748993 loss_ctc 14.381317 loss_rnnt 8.803390 lr 0.00026355 rank 7
2022-12-08 00:56:43,773 DEBUG TRAIN Batch 24/1400 loss 12.665689 loss_att 399.887695 loss_ctc 17.977943 loss_rnnt 12.075439 lr 0.00026356 rank 5
2022-12-08 00:56:43,776 DEBUG TRAIN Batch 24/1400 loss 2.050680 loss_att 360.479584 loss_ctc 7.287437 loss_rnnt 1.468818 lr 0.00026356 rank 0
2022-12-08 00:57:53,692 DEBUG TRAIN Batch 24/1500 loss 3.383021 loss_att 313.023224 loss_ctc 6.687057 loss_rnnt 3.015906 lr 0.00026351 rank 7
2022-12-08 00:57:53,711 DEBUG TRAIN Batch 24/1500 loss 2.080385 loss_att 402.471436 loss_ctc 5.342491 loss_rnnt 1.717929 lr 0.00026353 rank 2
2022-12-08 00:57:53,712 DEBUG TRAIN Batch 24/1500 loss 11.198922 loss_att 413.282318 loss_ctc 25.486977 loss_rnnt 9.611362 lr 0.00026354 rank 3
2022-12-08 00:57:53,713 DEBUG TRAIN Batch 24/1500 loss 5.362332 loss_att 386.987488 loss_ctc 16.096079 loss_rnnt 4.169694 lr 0.00026353 rank 6
2022-12-08 00:57:53,714 DEBUG TRAIN Batch 24/1500 loss 3.135105 loss_att 315.724884 loss_ctc 5.819175 loss_rnnt 2.836875 lr 0.00026352 rank 5
2022-12-08 00:57:53,714 DEBUG TRAIN Batch 24/1500 loss 6.320820 loss_att 353.879333 loss_ctc 11.364054 loss_rnnt 5.760461 lr 0.00026353 rank 4
2022-12-08 00:57:53,716 DEBUG TRAIN Batch 24/1500 loss 2.151242 loss_att 363.773041 loss_ctc 7.776172 loss_rnnt 1.526250 lr 0.00026354 rank 1
2022-12-08 00:57:53,724 DEBUG TRAIN Batch 24/1500 loss 5.221740 loss_att 376.522705 loss_ctc 8.711055 loss_rnnt 4.834038 lr 0.00026353 rank 0
2022-12-08 00:58:56,687 DEBUG TRAIN Batch 24/1600 loss 5.462153 loss_att 334.792847 loss_ctc 11.941566 loss_rnnt 4.742218 lr 0.00026348 rank 7
2022-12-08 00:58:56,689 DEBUG TRAIN Batch 24/1600 loss 7.133495 loss_att 435.168335 loss_ctc 15.376689 loss_rnnt 6.217586 lr 0.00026349 rank 6
2022-12-08 00:58:56,690 DEBUG TRAIN Batch 24/1600 loss 10.064963 loss_att 419.342590 loss_ctc 18.515259 loss_rnnt 9.126041 lr 0.00026349 rank 4
2022-12-08 00:58:56,690 DEBUG TRAIN Batch 24/1600 loss 9.753853 loss_att 380.712036 loss_ctc 14.861442 loss_rnnt 9.186343 lr 0.00026349 rank 2
2022-12-08 00:58:56,691 DEBUG TRAIN Batch 24/1600 loss 9.363045 loss_att 329.381348 loss_ctc 14.484935 loss_rnnt 8.793946 lr 0.00026349 rank 0
2022-12-08 00:58:56,697 DEBUG TRAIN Batch 24/1600 loss 11.338918 loss_att 357.541443 loss_ctc 19.484583 loss_rnnt 10.433844 lr 0.00026348 rank 5
2022-12-08 00:58:56,703 DEBUG TRAIN Batch 24/1600 loss 7.365425 loss_att 370.782776 loss_ctc 19.445927 loss_rnnt 6.023147 lr 0.00026350 rank 3
2022-12-08 00:58:56,733 DEBUG TRAIN Batch 24/1600 loss 8.049277 loss_att 382.315704 loss_ctc 12.813787 loss_rnnt 7.519887 lr 0.00026351 rank 1
2022-12-08 00:59:59,926 DEBUG TRAIN Batch 24/1700 loss 10.234653 loss_att 411.900452 loss_ctc 18.481174 loss_rnnt 9.318373 lr 0.00026344 rank 7
2022-12-08 00:59:59,926 DEBUG TRAIN Batch 24/1700 loss 7.089329 loss_att 365.002502 loss_ctc 14.115627 loss_rnnt 6.308629 lr 0.00026345 rank 0
2022-12-08 00:59:59,927 DEBUG TRAIN Batch 24/1700 loss 2.121594 loss_att 396.753418 loss_ctc 7.889962 loss_rnnt 1.480664 lr 0.00026346 rank 4
2022-12-08 00:59:59,929 DEBUG TRAIN Batch 24/1700 loss 11.318922 loss_att 344.879639 loss_ctc 26.454533 loss_rnnt 9.637188 lr 0.00026345 rank 2
2022-12-08 00:59:59,929 DEBUG TRAIN Batch 24/1700 loss 15.059026 loss_att 411.345215 loss_ctc 27.036774 loss_rnnt 13.728166 lr 0.00026347 rank 3
2022-12-08 00:59:59,936 DEBUG TRAIN Batch 24/1700 loss 2.023741 loss_att 358.400970 loss_ctc 5.893004 loss_rnnt 1.593823 lr 0.00026345 rank 5
2022-12-08 00:59:59,938 DEBUG TRAIN Batch 24/1700 loss 5.207008 loss_att 366.548615 loss_ctc 11.128191 loss_rnnt 4.549099 lr 0.00026347 rank 1
2022-12-08 00:59:59,953 DEBUG TRAIN Batch 24/1700 loss 5.341425 loss_att 348.809814 loss_ctc 10.105671 loss_rnnt 4.812065 lr 0.00026345 rank 6
2022-12-08 01:01:12,565 DEBUG TRAIN Batch 24/1800 loss 10.241732 loss_att 356.442627 loss_ctc 21.080395 loss_rnnt 9.037436 lr 0.00026342 rank 4
2022-12-08 01:01:12,566 DEBUG TRAIN Batch 24/1800 loss 6.569802 loss_att 341.159241 loss_ctc 10.383345 loss_rnnt 6.146076 lr 0.00026343 rank 3
2022-12-08 01:01:12,566 DEBUG TRAIN Batch 24/1800 loss 12.312551 loss_att 367.153259 loss_ctc 23.105751 loss_rnnt 11.113306 lr 0.00026342 rank 6
2022-12-08 01:01:12,570 DEBUG TRAIN Batch 24/1800 loss 5.591920 loss_att 316.876648 loss_ctc 13.740044 loss_rnnt 4.686573 lr 0.00026343 rank 1
2022-12-08 01:01:12,570 DEBUG TRAIN Batch 24/1800 loss 4.440508 loss_att 277.487885 loss_ctc 8.238177 loss_rnnt 4.018545 lr 0.00026340 rank 7
2022-12-08 01:01:12,575 DEBUG TRAIN Batch 24/1800 loss 8.741806 loss_att 336.907593 loss_ctc 21.883362 loss_rnnt 7.281633 lr 0.00026341 rank 5
2022-12-08 01:01:12,575 DEBUG TRAIN Batch 24/1800 loss 7.534970 loss_att 288.539703 loss_ctc 16.211109 loss_rnnt 6.570955 lr 0.00026342 rank 0
2022-12-08 01:01:12,609 DEBUG TRAIN Batch 24/1800 loss 9.076518 loss_att 385.232727 loss_ctc 18.353674 loss_rnnt 8.045723 lr 0.00026342 rank 2
2022-12-08 01:02:15,887 DEBUG TRAIN Batch 24/1900 loss 12.213727 loss_att 262.562775 loss_ctc 17.723642 loss_rnnt 11.601514 lr 0.00026338 rank 0
2022-12-08 01:02:15,888 DEBUG TRAIN Batch 24/1900 loss 5.364517 loss_att 143.382065 loss_ctc 7.830623 loss_rnnt 5.090505 lr 0.00026338 rank 2
2022-12-08 01:02:15,892 DEBUG TRAIN Batch 24/1900 loss 7.437854 loss_att 257.541229 loss_ctc 14.994858 loss_rnnt 6.598187 lr 0.00026340 rank 1
2022-12-08 01:02:15,892 DEBUG TRAIN Batch 24/1900 loss 6.431135 loss_att 223.521881 loss_ctc 11.735474 loss_rnnt 5.841764 lr 0.00026337 rank 5
2022-12-08 01:02:15,893 DEBUG TRAIN Batch 24/1900 loss 10.836447 loss_att 257.425446 loss_ctc 19.591484 loss_rnnt 9.863665 lr 0.00026340 rank 3
2022-12-08 01:02:15,894 DEBUG TRAIN Batch 24/1900 loss 6.302589 loss_att 188.152939 loss_ctc 9.990774 loss_rnnt 5.892791 lr 0.00026338 rank 6
2022-12-08 01:02:15,909 DEBUG TRAIN Batch 24/1900 loss 10.000568 loss_att 309.122528 loss_ctc 20.006891 loss_rnnt 8.888755 lr 0.00026338 rank 4
2022-12-08 01:02:15,916 DEBUG TRAIN Batch 24/1900 loss 2.194946 loss_att 485.687256 loss_ctc 6.136029 loss_rnnt 1.757048 lr 0.00026337 rank 7
2022-12-08 01:03:19,128 DEBUG TRAIN Batch 24/2000 loss 6.941376 loss_att 81.747330 loss_ctc 11.668816 loss_rnnt 6.416105 lr 0.00026335 rank 4
2022-12-08 01:03:19,133 DEBUG TRAIN Batch 24/2000 loss 7.930148 loss_att 401.986511 loss_ctc 19.007444 loss_rnnt 6.699337 lr 0.00026333 rank 7
2022-12-08 01:03:19,133 DEBUG TRAIN Batch 24/2000 loss 3.604239 loss_att 363.958557 loss_ctc 12.511650 loss_rnnt 2.614526 lr 0.00026334 rank 5
2022-12-08 01:03:19,134 DEBUG TRAIN Batch 24/2000 loss 7.875141 loss_att 329.405975 loss_ctc 13.956955 loss_rnnt 7.199384 lr 0.00026334 rank 6
2022-12-08 01:03:19,135 DEBUG TRAIN Batch 24/2000 loss 7.326718 loss_att 341.585785 loss_ctc 16.387390 loss_rnnt 6.319976 lr 0.00026334 rank 2
2022-12-08 01:03:19,135 DEBUG TRAIN Batch 24/2000 loss 6.028049 loss_att 395.161926 loss_ctc 9.865170 loss_rnnt 5.601703 lr 0.00026335 rank 0
2022-12-08 01:03:19,138 DEBUG TRAIN Batch 24/2000 loss 7.559338 loss_att 356.026337 loss_ctc 11.857139 loss_rnnt 7.081805 lr 0.00026336 rank 1
2022-12-08 01:03:19,175 DEBUG TRAIN Batch 24/2000 loss 3.275597 loss_att 414.565277 loss_ctc 7.754894 loss_rnnt 2.777897 lr 0.00026336 rank 3
2022-12-08 01:04:24,160 DEBUG TRAIN Batch 24/2100 loss 5.538199 loss_att 397.199402 loss_ctc 10.109430 loss_rnnt 5.030284 lr 0.00026332 rank 1
2022-12-08 01:04:24,161 DEBUG TRAIN Batch 24/2100 loss 7.653157 loss_att 346.869263 loss_ctc 15.537799 loss_rnnt 6.777086 lr 0.00026332 rank 3
2022-12-08 01:04:24,167 DEBUG TRAIN Batch 24/2100 loss 8.334160 loss_att 356.112671 loss_ctc 25.848511 loss_rnnt 6.388122 lr 0.00026329 rank 7
2022-12-08 01:04:24,169 DEBUG TRAIN Batch 24/2100 loss 8.552593 loss_att 376.007751 loss_ctc 17.342018 loss_rnnt 7.575991 lr 0.00026331 rank 4
2022-12-08 01:04:24,172 DEBUG TRAIN Batch 24/2100 loss 7.683505 loss_att 392.656586 loss_ctc 12.920566 loss_rnnt 7.101610 lr 0.00026331 rank 6
2022-12-08 01:04:24,197 DEBUG TRAIN Batch 24/2100 loss 8.656778 loss_att 335.586151 loss_ctc 12.000097 loss_rnnt 8.285299 lr 0.00026330 rank 5
2022-12-08 01:04:24,202 DEBUG TRAIN Batch 24/2100 loss 8.872819 loss_att 448.938324 loss_ctc 14.321848 loss_rnnt 8.267371 lr 0.00026331 rank 0
2022-12-08 01:04:24,221 DEBUG TRAIN Batch 24/2100 loss 4.591406 loss_att 331.581909 loss_ctc 10.100267 loss_rnnt 3.979311 lr 0.00026331 rank 2
2022-12-08 01:05:34,515 DEBUG TRAIN Batch 24/2200 loss 6.782415 loss_att 423.631744 loss_ctc 13.112387 loss_rnnt 6.079085 lr 0.00026327 rank 6
2022-12-08 01:05:34,515 DEBUG TRAIN Batch 24/2200 loss 11.719398 loss_att 352.449890 loss_ctc 15.700019 loss_rnnt 11.277107 lr 0.00026327 rank 0
2022-12-08 01:05:34,517 DEBUG TRAIN Batch 24/2200 loss 7.163371 loss_att 375.806885 loss_ctc 13.497715 loss_rnnt 6.459555 lr 0.00026326 rank 7
2022-12-08 01:05:34,519 DEBUG TRAIN Batch 24/2200 loss 1.787491 loss_att 413.115662 loss_ctc 10.188370 loss_rnnt 0.854060 lr 0.00026327 rank 4
2022-12-08 01:05:34,518 DEBUG TRAIN Batch 24/2200 loss 5.896183 loss_att 405.441742 loss_ctc 9.340719 loss_rnnt 5.513457 lr 0.00026329 rank 1
2022-12-08 01:05:34,519 DEBUG TRAIN Batch 24/2200 loss 8.619703 loss_att 379.789032 loss_ctc 13.764246 loss_rnnt 8.048088 lr 0.00026327 rank 2
2022-12-08 01:05:34,520 DEBUG TRAIN Batch 24/2200 loss 11.760336 loss_att 397.207977 loss_ctc 25.209364 loss_rnnt 10.265999 lr 0.00026329 rank 3
2022-12-08 01:05:34,527 DEBUG TRAIN Batch 24/2200 loss 3.249843 loss_att 370.208435 loss_ctc 7.545574 loss_rnnt 2.772540 lr 0.00026326 rank 5
2022-12-08 01:06:37,342 DEBUG TRAIN Batch 24/2300 loss 1.878106 loss_att 308.534943 loss_ctc 5.649189 loss_rnnt 1.459097 lr 0.00026324 rank 4
2022-12-08 01:06:37,345 DEBUG TRAIN Batch 24/2300 loss 4.003205 loss_att 336.066650 loss_ctc 6.973743 loss_rnnt 3.673145 lr 0.00026322 rank 7
2022-12-08 01:06:37,345 DEBUG TRAIN Batch 24/2300 loss 4.550796 loss_att 350.827942 loss_ctc 10.678874 loss_rnnt 3.869898 lr 0.00026323 rank 5
2022-12-08 01:06:37,347 DEBUG TRAIN Batch 24/2300 loss 8.068943 loss_att 361.991272 loss_ctc 11.119671 loss_rnnt 7.729974 lr 0.00026324 rank 6
2022-12-08 01:06:37,347 DEBUG TRAIN Batch 24/2300 loss 4.144615 loss_att 379.062469 loss_ctc 6.870444 loss_rnnt 3.841745 lr 0.00026325 rank 1
2022-12-08 01:06:37,347 DEBUG TRAIN Batch 24/2300 loss 12.304235 loss_att 380.131470 loss_ctc 19.665470 loss_rnnt 11.486320 lr 0.00026324 rank 0
2022-12-08 01:06:37,351 DEBUG TRAIN Batch 24/2300 loss 16.555735 loss_att 406.860107 loss_ctc 30.152798 loss_rnnt 15.044950 lr 0.00026323 rank 2
2022-12-08 01:06:37,353 DEBUG TRAIN Batch 24/2300 loss 7.769175 loss_att 384.251709 loss_ctc 18.886818 loss_rnnt 6.533881 lr 0.00026325 rank 3
2022-12-08 01:07:41,311 DEBUG TRAIN Batch 24/2400 loss 10.763124 loss_att 308.687042 loss_ctc 12.815976 loss_rnnt 10.535030 lr 0.00026320 rank 2
2022-12-08 01:07:41,312 DEBUG TRAIN Batch 24/2400 loss 7.976481 loss_att 296.098175 loss_ctc 15.152251 loss_rnnt 7.179173 lr 0.00026320 rank 6
2022-12-08 01:07:41,314 DEBUG TRAIN Batch 24/2400 loss 6.860400 loss_att 358.481934 loss_ctc 18.775419 loss_rnnt 5.536509 lr 0.00026321 rank 1
2022-12-08 01:07:41,314 DEBUG TRAIN Batch 24/2400 loss 10.841565 loss_att 335.780792 loss_ctc 20.590504 loss_rnnt 9.758349 lr 0.00026320 rank 4
2022-12-08 01:07:41,318 DEBUG TRAIN Batch 24/2400 loss 6.970300 loss_att 271.217834 loss_ctc 8.756338 loss_rnnt 6.771852 lr 0.00026318 rank 7
2022-12-08 01:07:41,319 DEBUG TRAIN Batch 24/2400 loss 11.292839 loss_att 404.865540 loss_ctc 33.148979 loss_rnnt 8.864379 lr 0.00026320 rank 0
2022-12-08 01:07:41,324 DEBUG TRAIN Batch 24/2400 loss 7.334624 loss_att 389.016663 loss_ctc 21.484604 loss_rnnt 5.762404 lr 0.00026319 rank 5
2022-12-08 01:07:41,345 DEBUG TRAIN Batch 24/2400 loss 9.156893 loss_att 324.330353 loss_ctc 17.009363 loss_rnnt 8.284396 lr 0.00026321 rank 3
2022-12-08 01:08:52,483 DEBUG TRAIN Batch 24/2500 loss 5.638723 loss_att 108.771980 loss_ctc 10.916615 loss_rnnt 5.052291 lr 0.00026315 rank 7
2022-12-08 01:08:52,484 DEBUG TRAIN Batch 24/2500 loss 5.126181 loss_att 344.030090 loss_ctc 13.075470 loss_rnnt 4.242927 lr 0.00026316 rank 0
2022-12-08 01:08:52,485 DEBUG TRAIN Batch 24/2500 loss 12.040544 loss_att 390.945007 loss_ctc 24.097385 loss_rnnt 10.700894 lr 0.00026316 rank 4
2022-12-08 01:08:52,485 DEBUG TRAIN Batch 24/2500 loss 13.415505 loss_att 249.914688 loss_ctc 22.763968 loss_rnnt 12.376788 lr 0.00026316 rank 6
2022-12-08 01:08:52,487 DEBUG TRAIN Batch 24/2500 loss 7.606386 loss_att 249.672363 loss_ctc 13.350316 loss_rnnt 6.968172 lr 0.00026318 rank 1
2022-12-08 01:08:52,487 DEBUG TRAIN Batch 24/2500 loss 6.451252 loss_att 289.012939 loss_ctc 11.384527 loss_rnnt 5.903111 lr 0.00026318 rank 3
2022-12-08 01:08:52,489 DEBUG TRAIN Batch 24/2500 loss 10.386230 loss_att 312.501556 loss_ctc 19.933598 loss_rnnt 9.325412 lr 0.00026315 rank 5
2022-12-08 01:08:52,537 DEBUG TRAIN Batch 24/2500 loss 10.424303 loss_att 244.929123 loss_ctc 18.593168 loss_rnnt 9.516651 lr 0.00026316 rank 2
2022-12-08 01:09:55,830 DEBUG TRAIN Batch 24/2600 loss 4.949975 loss_att 200.357742 loss_ctc 11.467535 loss_rnnt 4.225801 lr 0.00026313 rank 4
2022-12-08 01:09:55,831 DEBUG TRAIN Batch 24/2600 loss 9.522790 loss_att 409.830811 loss_ctc 18.237392 loss_rnnt 8.554501 lr 0.00026313 rank 6
2022-12-08 01:09:55,832 DEBUG TRAIN Batch 24/2600 loss 1.686455 loss_att 378.405640 loss_ctc 4.738585 loss_rnnt 1.347329 lr 0.00026312 rank 5
2022-12-08 01:09:55,832 DEBUG TRAIN Batch 24/2600 loss 4.411766 loss_att 412.826355 loss_ctc 10.227903 loss_rnnt 3.765528 lr 0.00026311 rank 7
2022-12-08 01:09:55,833 DEBUG TRAIN Batch 24/2600 loss 13.256632 loss_att 390.128754 loss_ctc 25.791019 loss_rnnt 11.863922 lr 0.00026313 rank 2
2022-12-08 01:09:55,833 DEBUG TRAIN Batch 24/2600 loss 3.674978 loss_att 367.034363 loss_ctc 6.709768 loss_rnnt 3.337779 lr 0.00026314 rank 3
2022-12-08 01:09:55,837 DEBUG TRAIN Batch 24/2600 loss 7.408399 loss_att 135.379807 loss_ctc 14.941100 loss_rnnt 6.571433 lr 0.00026313 rank 0
2022-12-08 01:09:55,839 DEBUG TRAIN Batch 24/2600 loss 7.566416 loss_att 379.981445 loss_ctc 14.257856 loss_rnnt 6.822923 lr 0.00026314 rank 1
2022-12-08 01:10:59,058 DEBUG TRAIN Batch 24/2700 loss 6.535661 loss_att 406.583466 loss_ctc 14.982681 loss_rnnt 5.597103 lr 0.00026309 rank 4
2022-12-08 01:10:59,065 DEBUG TRAIN Batch 24/2700 loss 4.596921 loss_att 429.165527 loss_ctc 13.926382 loss_rnnt 3.560314 lr 0.00026311 rank 1
2022-12-08 01:10:59,066 DEBUG TRAIN Batch 24/2700 loss 7.341461 loss_att 457.331757 loss_ctc 20.465385 loss_rnnt 5.883247 lr 0.00026309 rank 0
2022-12-08 01:10:59,066 DEBUG TRAIN Batch 24/2700 loss 15.131574 loss_att 387.872803 loss_ctc 21.404488 loss_rnnt 14.434584 lr 0.00026308 rank 7
2022-12-08 01:10:59,067 DEBUG TRAIN Batch 24/2700 loss 1.338666 loss_att 364.235046 loss_ctc 3.565876 loss_rnnt 1.091198 lr 0.00026310 rank 3
2022-12-08 01:10:59,067 DEBUG TRAIN Batch 24/2700 loss 5.142599 loss_att 365.632874 loss_ctc 7.499586 loss_rnnt 4.880712 lr 0.00026309 rank 2
2022-12-08 01:10:59,070 DEBUG TRAIN Batch 24/2700 loss 2.756007 loss_att 373.494446 loss_ctc 6.665342 loss_rnnt 2.321636 lr 0.00026309 rank 6
2022-12-08 01:10:59,110 DEBUG TRAIN Batch 24/2700 loss 8.608861 loss_att 409.610840 loss_ctc 14.667122 loss_rnnt 7.935721 lr 0.00026308 rank 5
2022-12-08 01:12:04,241 DEBUG TRAIN Batch 24/2800 loss 4.823965 loss_att 365.900635 loss_ctc 13.623238 loss_rnnt 3.846268 lr 0.00026306 rank 4
2022-12-08 01:12:04,244 DEBUG TRAIN Batch 24/2800 loss 11.775967 loss_att 389.891754 loss_ctc 26.167723 loss_rnnt 10.176883 lr 0.00026305 rank 6
2022-12-08 01:12:04,252 DEBUG TRAIN Batch 24/2800 loss 6.301661 loss_att 356.083862 loss_ctc 17.862654 loss_rnnt 5.017107 lr 0.00026304 rank 7
2022-12-08 01:12:04,254 DEBUG TRAIN Batch 24/2800 loss 5.016469 loss_att 369.334564 loss_ctc 15.077510 loss_rnnt 3.898576 lr 0.00026307 rank 3
2022-12-08 01:12:04,254 DEBUG TRAIN Batch 24/2800 loss 8.371822 loss_att 352.356689 loss_ctc 14.425947 loss_rnnt 7.699142 lr 0.00026307 rank 1
2022-12-08 01:12:04,255 DEBUG TRAIN Batch 24/2800 loss 16.637220 loss_att 413.821777 loss_ctc 41.277458 loss_rnnt 13.899417 lr 0.00026305 rank 0
2022-12-08 01:12:04,258 DEBUG TRAIN Batch 24/2800 loss 11.506934 loss_att 355.593903 loss_ctc 18.971298 loss_rnnt 10.677561 lr 0.00026304 rank 5
2022-12-08 01:12:04,298 DEBUG TRAIN Batch 24/2800 loss 13.154490 loss_att 437.183563 loss_ctc 22.236763 loss_rnnt 12.145349 lr 0.00026305 rank 2
2022-12-08 01:13:15,474 DEBUG TRAIN Batch 24/2900 loss 5.287772 loss_att 339.407898 loss_ctc 7.465415 loss_rnnt 5.045812 lr 0.00026302 rank 4
2022-12-08 01:13:15,474 DEBUG TRAIN Batch 24/2900 loss 3.773116 loss_att 385.412415 loss_ctc 11.411060 loss_rnnt 2.924456 lr 0.00026300 rank 7
2022-12-08 01:13:15,475 DEBUG TRAIN Batch 24/2900 loss 15.375675 loss_att 370.255188 loss_ctc 25.200518 loss_rnnt 14.284026 lr 0.00026302 rank 6
2022-12-08 01:13:15,477 DEBUG TRAIN Batch 24/2900 loss 9.892918 loss_att 327.879730 loss_ctc 17.224262 loss_rnnt 9.078323 lr 0.00026303 rank 3
2022-12-08 01:13:15,478 DEBUG TRAIN Batch 24/2900 loss 10.778134 loss_att 378.419189 loss_ctc 11.577785 loss_rnnt 10.689284 lr 0.00026303 rank 1
2022-12-08 01:13:15,479 DEBUG TRAIN Batch 24/2900 loss 11.791868 loss_att 409.089325 loss_ctc 23.382908 loss_rnnt 10.503975 lr 0.00026302 rank 2
2022-12-08 01:13:15,482 DEBUG TRAIN Batch 24/2900 loss 7.017188 loss_att 382.575195 loss_ctc 9.251137 loss_rnnt 6.768971 lr 0.00026302 rank 0
2022-12-08 01:13:15,482 DEBUG TRAIN Batch 24/2900 loss 6.480916 loss_att 427.585754 loss_ctc 14.812102 loss_rnnt 5.555229 lr 0.00026301 rank 5
2022-12-08 01:14:18,436 DEBUG TRAIN Batch 24/3000 loss 13.121819 loss_att 392.793274 loss_ctc 31.203346 loss_rnnt 11.112761 lr 0.00026298 rank 0
2022-12-08 01:14:18,439 DEBUG TRAIN Batch 24/3000 loss 5.615169 loss_att 304.656982 loss_ctc 8.715129 loss_rnnt 5.270729 lr 0.00026297 rank 7
2022-12-08 01:14:18,440 DEBUG TRAIN Batch 24/3000 loss 13.533909 loss_att 342.020325 loss_ctc 24.720089 loss_rnnt 12.291000 lr 0.00026298 rank 6
2022-12-08 01:14:18,440 DEBUG TRAIN Batch 24/3000 loss 8.999689 loss_att 349.090149 loss_ctc 13.957867 loss_rnnt 8.448781 lr 0.00026298 rank 2
2022-12-08 01:14:18,440 DEBUG TRAIN Batch 24/3000 loss 9.277910 loss_att 383.094360 loss_ctc 19.821213 loss_rnnt 8.106432 lr 0.00026298 rank 4
2022-12-08 01:14:18,446 DEBUG TRAIN Batch 24/3000 loss 6.544835 loss_att 365.551941 loss_ctc 16.991480 loss_rnnt 5.384096 lr 0.00026300 rank 1
2022-12-08 01:14:18,446 DEBUG TRAIN Batch 24/3000 loss 6.421468 loss_att 359.308411 loss_ctc 10.419186 loss_rnnt 5.977277 lr 0.00026299 rank 3
2022-12-08 01:14:18,453 DEBUG TRAIN Batch 24/3000 loss 5.780047 loss_att 316.805634 loss_ctc 12.098713 loss_rnnt 5.077973 lr 0.00026297 rank 5
2022-12-08 01:15:22,736 DEBUG TRAIN Batch 24/3100 loss 9.356762 loss_att 338.593231 loss_ctc 17.136494 loss_rnnt 8.492348 lr 0.00026295 rank 4
2022-12-08 01:15:22,741 DEBUG TRAIN Batch 24/3100 loss 15.157902 loss_att 262.015198 loss_ctc 24.700312 loss_rnnt 14.097635 lr 0.00026294 rank 2
2022-12-08 01:15:22,740 DEBUG TRAIN Batch 24/3100 loss 6.207306 loss_att 180.909424 loss_ctc 10.182288 loss_rnnt 5.765641 lr 0.00026293 rank 7
2022-12-08 01:15:22,741 DEBUG TRAIN Batch 24/3100 loss 9.872642 loss_att 277.455719 loss_ctc 18.555939 loss_rnnt 8.907831 lr 0.00026294 rank 6
2022-12-08 01:15:22,743 DEBUG TRAIN Batch 24/3100 loss 7.348480 loss_att 353.972412 loss_ctc 13.657578 loss_rnnt 6.647470 lr 0.00026296 rank 1
2022-12-08 01:15:22,747 DEBUG TRAIN Batch 24/3100 loss 10.631698 loss_att 324.199097 loss_ctc 15.762921 loss_rnnt 10.061562 lr 0.00026294 rank 5
2022-12-08 01:15:22,747 DEBUG TRAIN Batch 24/3100 loss 12.178491 loss_att 366.321411 loss_ctc 27.811008 loss_rnnt 10.441544 lr 0.00026294 rank 0
2022-12-08 01:15:22,788 DEBUG TRAIN Batch 24/3100 loss 13.269215 loss_att 270.448181 loss_ctc 22.894224 loss_rnnt 12.199770 lr 0.00026296 rank 3
2022-12-08 01:16:35,904 DEBUG TRAIN Batch 24/3200 loss 14.306088 loss_att 478.372437 loss_ctc 31.419439 loss_rnnt 12.404605 lr 0.00026292 rank 3
2022-12-08 01:16:35,903 DEBUG TRAIN Batch 24/3200 loss 10.641457 loss_att 409.925720 loss_ctc 24.848227 loss_rnnt 9.062927 lr 0.00026289 rank 7
2022-12-08 01:16:35,905 DEBUG TRAIN Batch 24/3200 loss 7.647740 loss_att 275.905914 loss_ctc 17.740664 loss_rnnt 6.526305 lr 0.00026291 rank 4
2022-12-08 01:16:35,911 DEBUG TRAIN Batch 24/3200 loss 5.965902 loss_att 179.068604 loss_ctc 11.822996 loss_rnnt 5.315114 lr 0.00026291 rank 0
2022-12-08 01:16:35,910 DEBUG TRAIN Batch 24/3200 loss 7.448026 loss_att 167.369766 loss_ctc 13.777600 loss_rnnt 6.744740 lr 0.00026290 rank 5
2022-12-08 01:16:35,913 DEBUG TRAIN Batch 24/3200 loss 7.038494 loss_att 294.237183 loss_ctc 12.311977 loss_rnnt 6.452552 lr 0.00026291 rank 2
2022-12-08 01:16:35,914 DEBUG TRAIN Batch 24/3200 loss 7.002025 loss_att 261.133545 loss_ctc 16.359165 loss_rnnt 5.962343 lr 0.00026292 rank 1
2022-12-08 01:16:35,924 DEBUG TRAIN Batch 24/3200 loss 3.065511 loss_att 409.683044 loss_ctc 8.941910 loss_rnnt 2.412578 lr 0.00026291 rank 6
2022-12-08 01:17:39,458 DEBUG TRAIN Batch 24/3300 loss 8.494408 loss_att 378.952148 loss_ctc 17.074009 loss_rnnt 7.541119 lr 0.00026287 rank 2
2022-12-08 01:17:39,460 DEBUG TRAIN Batch 24/3300 loss 5.879740 loss_att 378.565186 loss_ctc 10.682112 loss_rnnt 5.346143 lr 0.00026286 rank 7
2022-12-08 01:17:39,463 DEBUG TRAIN Batch 24/3300 loss 8.982042 loss_att 379.955658 loss_ctc 24.094143 loss_rnnt 7.302921 lr 0.00026287 rank 6
2022-12-08 01:17:39,463 DEBUG TRAIN Batch 24/3300 loss 14.085850 loss_att 439.829834 loss_ctc 42.768688 loss_rnnt 10.898868 lr 0.00026288 rank 3
2022-12-08 01:17:39,465 DEBUG TRAIN Batch 24/3300 loss 7.875190 loss_att 467.493744 loss_ctc 13.618999 loss_rnnt 7.236989 lr 0.00026287 rank 0
2022-12-08 01:17:39,467 DEBUG TRAIN Batch 24/3300 loss 5.392881 loss_att 357.950073 loss_ctc 11.574097 loss_rnnt 4.706079 lr 0.00026289 rank 1
2022-12-08 01:17:39,467 DEBUG TRAIN Batch 24/3300 loss 8.989524 loss_att 418.822571 loss_ctc 14.053232 loss_rnnt 8.426889 lr 0.00026287 rank 4
2022-12-08 01:17:39,470 DEBUG TRAIN Batch 24/3300 loss 6.639144 loss_att 430.591003 loss_ctc 12.807087 loss_rnnt 5.953817 lr 0.00026286 rank 5
2022-12-08 01:18:43,105 DEBUG TRAIN Batch 24/3400 loss 11.486332 loss_att 398.025208 loss_ctc 23.300356 loss_rnnt 10.173662 lr 0.00026282 rank 7
2022-12-08 01:18:43,108 DEBUG TRAIN Batch 24/3400 loss 9.571159 loss_att 434.564941 loss_ctc 14.332914 loss_rnnt 9.042076 lr 0.00026285 rank 1
2022-12-08 01:18:43,108 DEBUG TRAIN Batch 24/3400 loss 5.552271 loss_att 367.852875 loss_ctc 13.197982 loss_rnnt 4.702747 lr 0.00026284 rank 4
2022-12-08 01:18:43,111 DEBUG TRAIN Batch 24/3400 loss 5.042743 loss_att 442.452393 loss_ctc 10.040590 loss_rnnt 4.487427 lr 0.00026283 rank 2
2022-12-08 01:18:43,111 DEBUG TRAIN Batch 24/3400 loss 2.714067 loss_att 413.165283 loss_ctc 4.699822 loss_rnnt 2.493427 lr 0.00026284 rank 0
2022-12-08 01:18:43,112 DEBUG TRAIN Batch 24/3400 loss 11.681375 loss_att 363.279724 loss_ctc 17.111313 loss_rnnt 11.078049 lr 0.00026285 rank 3
2022-12-08 01:18:43,113 DEBUG TRAIN Batch 24/3400 loss 8.752411 loss_att 374.153625 loss_ctc 14.643118 loss_rnnt 8.097888 lr 0.00026283 rank 5
2022-12-08 01:18:43,154 DEBUG TRAIN Batch 24/3400 loss 5.057277 loss_att 391.281738 loss_ctc 10.314646 loss_rnnt 4.473125 lr 0.00026283 rank 6
2022-12-08 01:19:47,242 DEBUG TRAIN Batch 24/3500 loss 5.313907 loss_att 361.011658 loss_ctc 11.947386 loss_rnnt 4.576854 lr 0.00026281 rank 3
2022-12-08 01:19:47,252 DEBUG TRAIN Batch 24/3500 loss 2.462567 loss_att 324.783142 loss_ctc 5.353741 loss_rnnt 2.141326 lr 0.00026280 rank 4
2022-12-08 01:19:47,251 DEBUG TRAIN Batch 24/3500 loss 1.671086 loss_att 398.810913 loss_ctc 7.856826 loss_rnnt 0.983782 lr 0.00026278 rank 7
2022-12-08 01:19:47,254 DEBUG TRAIN Batch 24/3500 loss 12.379807 loss_att 434.700745 loss_ctc 18.609159 loss_rnnt 11.687657 lr 0.00026280 rank 6
2022-12-08 01:19:47,255 DEBUG TRAIN Batch 24/3500 loss 13.365323 loss_att 353.875946 loss_ctc 30.064156 loss_rnnt 11.509898 lr 0.00026279 rank 5
2022-12-08 01:19:47,258 DEBUG TRAIN Batch 24/3500 loss 11.279008 loss_att 396.632202 loss_ctc 25.389614 loss_rnnt 9.711163 lr 0.00026280 rank 2
2022-12-08 01:19:47,258 DEBUG TRAIN Batch 24/3500 loss 6.320851 loss_att 360.083069 loss_ctc 13.626277 loss_rnnt 5.509138 lr 0.00026280 rank 0
2022-12-08 01:19:47,259 DEBUG TRAIN Batch 24/3500 loss 13.204033 loss_att 329.667694 loss_ctc 17.983089 loss_rnnt 12.673026 lr 0.00026281 rank 1
2022-12-08 01:20:58,751 DEBUG TRAIN Batch 24/3600 loss 8.635771 loss_att 398.020752 loss_ctc 15.808844 loss_rnnt 7.838763 lr 0.00026276 rank 4
2022-12-08 01:20:58,754 DEBUG TRAIN Batch 24/3600 loss 5.071065 loss_att 323.350342 loss_ctc 14.374546 loss_rnnt 4.037345 lr 0.00026276 rank 6
2022-12-08 01:20:58,755 DEBUG TRAIN Batch 24/3600 loss 6.803656 loss_att 318.518677 loss_ctc 16.820999 loss_rnnt 5.690618 lr 0.00026275 rank 7
2022-12-08 01:20:58,756 DEBUG TRAIN Batch 24/3600 loss 13.666750 loss_att 416.939667 loss_ctc 29.890718 loss_rnnt 11.864087 lr 0.00026278 rank 1
2022-12-08 01:20:58,756 DEBUG TRAIN Batch 24/3600 loss 8.198782 loss_att 326.478271 loss_ctc 16.165024 loss_rnnt 7.313644 lr 0.00026278 rank 3
2022-12-08 01:20:58,757 DEBUG TRAIN Batch 24/3600 loss 1.596927 loss_att 334.074707 loss_ctc 4.422201 loss_rnnt 1.283008 lr 0.00026276 rank 2
2022-12-08 01:20:58,758 DEBUG TRAIN Batch 24/3600 loss 8.941814 loss_att 383.009094 loss_ctc 13.753109 loss_rnnt 8.407227 lr 0.00026276 rank 0
2022-12-08 01:20:58,764 DEBUG TRAIN Batch 24/3600 loss 7.761728 loss_att 389.359009 loss_ctc 13.825426 loss_rnnt 7.087984 lr 0.00026275 rank 5
2022-12-08 01:22:02,378 DEBUG TRAIN Batch 24/3700 loss 13.402977 loss_att 328.903046 loss_ctc 18.272251 loss_rnnt 12.861947 lr 0.00026273 rank 4
2022-12-08 01:22:02,381 DEBUG TRAIN Batch 24/3700 loss 8.855044 loss_att 274.115570 loss_ctc 12.093581 loss_rnnt 8.495207 lr 0.00026274 rank 3
2022-12-08 01:22:02,381 DEBUG TRAIN Batch 24/3700 loss 4.838301 loss_att 409.464386 loss_ctc 9.320105 loss_rnnt 4.340322 lr 0.00026274 rank 1
2022-12-08 01:22:02,382 DEBUG TRAIN Batch 24/3700 loss 12.110743 loss_att 311.037903 loss_ctc 25.364971 loss_rnnt 10.638051 lr 0.00026273 rank 2
2022-12-08 01:22:02,383 DEBUG TRAIN Batch 24/3700 loss 11.607830 loss_att 317.830292 loss_ctc 22.094769 loss_rnnt 10.442616 lr 0.00026272 rank 5
2022-12-08 01:22:02,384 DEBUG TRAIN Batch 24/3700 loss 8.855915 loss_att 320.964844 loss_ctc 15.595160 loss_rnnt 8.107111 lr 0.00026273 rank 0
2022-12-08 01:22:02,387 DEBUG TRAIN Batch 24/3700 loss 6.913284 loss_att 178.270660 loss_ctc 11.126160 loss_rnnt 6.445187 lr 0.00026271 rank 7
2022-12-08 01:22:02,421 DEBUG TRAIN Batch 24/3700 loss 2.282642 loss_att 292.358124 loss_ctc 6.904972 loss_rnnt 1.769049 lr 0.00026273 rank 6
2022-12-08 01:23:05,425 DEBUG TRAIN Batch 24/3800 loss 8.063241 loss_att 334.485443 loss_ctc 14.901248 loss_rnnt 7.303463 lr 0.00026269 rank 4
2022-12-08 01:23:05,424 DEBUG TRAIN Batch 24/3800 loss 5.490263 loss_att 430.840027 loss_ctc 16.202026 loss_rnnt 4.300067 lr 0.00026268 rank 7
2022-12-08 01:23:05,425 DEBUG TRAIN Batch 24/3800 loss 7.921137 loss_att 78.718117 loss_ctc 12.488055 loss_rnnt 7.413702 lr 0.00026270 rank 3
2022-12-08 01:23:05,430 DEBUG TRAIN Batch 24/3800 loss 10.764928 loss_att 260.879517 loss_ctc 21.249401 loss_rnnt 9.599987 lr 0.00026269 rank 0
2022-12-08 01:23:05,432 DEBUG TRAIN Batch 24/3800 loss 12.574689 loss_att 274.729248 loss_ctc 23.974472 loss_rnnt 11.308046 lr 0.00026271 rank 1
2022-12-08 01:23:05,434 DEBUG TRAIN Batch 24/3800 loss 6.469635 loss_att 74.830177 loss_ctc 11.566052 loss_rnnt 5.903367 lr 0.00026269 rank 6
2022-12-08 01:23:05,444 DEBUG TRAIN Batch 24/3800 loss 4.563263 loss_att 275.623444 loss_ctc 8.483621 loss_rnnt 4.127668 lr 0.00026269 rank 2
2022-12-08 01:23:05,453 DEBUG TRAIN Batch 24/3800 loss 6.426236 loss_att 250.174362 loss_ctc 9.817318 loss_rnnt 6.049449 lr 0.00026268 rank 5
2022-12-08 01:24:17,763 DEBUG TRAIN Batch 24/3900 loss 10.658277 loss_att 380.025726 loss_ctc 16.400368 loss_rnnt 10.020267 lr 0.00026264 rank 7
2022-12-08 01:24:17,764 DEBUG TRAIN Batch 24/3900 loss 8.418978 loss_att 105.028496 loss_ctc 13.829528 loss_rnnt 7.817805 lr 0.00026266 rank 4
2022-12-08 01:24:17,768 DEBUG TRAIN Batch 24/3900 loss 14.910341 loss_att 450.399261 loss_ctc 30.785297 loss_rnnt 13.146458 lr 0.00026265 rank 0
2022-12-08 01:24:17,785 DEBUG TRAIN Batch 24/3900 loss 2.839871 loss_att 395.043457 loss_ctc 7.969099 loss_rnnt 2.269957 lr 0.00026265 rank 2
2022-12-08 01:24:17,794 DEBUG TRAIN Batch 24/3900 loss 9.729457 loss_att 137.104279 loss_ctc 17.427588 loss_rnnt 8.874109 lr 0.00026267 rank 1
2022-12-08 01:24:17,797 DEBUG TRAIN Batch 24/3900 loss 7.688646 loss_att 451.729218 loss_ctc 14.976928 loss_rnnt 6.878837 lr 0.00026267 rank 3
2022-12-08 01:24:17,798 DEBUG TRAIN Batch 24/3900 loss 5.610488 loss_att 385.023285 loss_ctc 20.392866 loss_rnnt 3.968002 lr 0.00026265 rank 5
2022-12-08 01:24:17,804 DEBUG TRAIN Batch 24/3900 loss 5.340215 loss_att 379.288086 loss_ctc 13.633644 loss_rnnt 4.418723 lr 0.00026265 rank 6
2022-12-08 01:25:21,183 DEBUG TRAIN Batch 24/4000 loss 7.307913 loss_att 407.921112 loss_ctc 15.553679 loss_rnnt 6.391717 lr 0.00026262 rank 4
2022-12-08 01:25:21,184 DEBUG TRAIN Batch 24/4000 loss 8.266141 loss_att 381.343323 loss_ctc 15.022482 loss_rnnt 7.515437 lr 0.00026260 rank 7
2022-12-08 01:25:21,188 DEBUG TRAIN Batch 24/4000 loss 4.746674 loss_att 394.468750 loss_ctc 8.242367 loss_rnnt 4.358263 lr 0.00026262 rank 0
2022-12-08 01:25:21,189 DEBUG TRAIN Batch 24/4000 loss 6.194866 loss_att 352.583344 loss_ctc 17.870218 loss_rnnt 4.897604 lr 0.00026263 rank 1
2022-12-08 01:25:21,189 DEBUG TRAIN Batch 24/4000 loss 6.862989 loss_att 424.237488 loss_ctc 20.178665 loss_rnnt 5.383470 lr 0.00026261 rank 5
2022-12-08 01:25:21,191 DEBUG TRAIN Batch 24/4000 loss 8.064481 loss_att 376.603149 loss_ctc 19.115492 loss_rnnt 6.836591 lr 0.00026263 rank 3
2022-12-08 01:25:21,192 DEBUG TRAIN Batch 24/4000 loss 3.746181 loss_att 400.613037 loss_ctc 7.938631 loss_rnnt 3.280353 lr 0.00026262 rank 6
2022-12-08 01:25:21,194 DEBUG TRAIN Batch 24/4000 loss 3.217690 loss_att 430.725037 loss_ctc 7.628996 loss_rnnt 2.727544 lr 0.00026262 rank 2
2022-12-08 01:26:24,109 DEBUG TRAIN Batch 24/4100 loss 2.224924 loss_att 367.917969 loss_ctc 9.538078 loss_rnnt 1.412351 lr 0.00026260 rank 1
2022-12-08 01:26:24,123 DEBUG TRAIN Batch 24/4100 loss 4.787704 loss_att 396.476807 loss_ctc 9.722594 loss_rnnt 4.239383 lr 0.00026258 rank 4
2022-12-08 01:26:24,124 DEBUG TRAIN Batch 24/4100 loss 6.982390 loss_att 320.211609 loss_ctc 13.246567 loss_rnnt 6.286371 lr 0.00026257 rank 7
2022-12-08 01:26:24,124 DEBUG TRAIN Batch 24/4100 loss 13.389163 loss_att 432.714111 loss_ctc 26.407812 loss_rnnt 11.942646 lr 0.00026258 rank 6
2022-12-08 01:26:24,125 DEBUG TRAIN Batch 24/4100 loss 7.289678 loss_att 296.468903 loss_ctc 14.348453 loss_rnnt 6.505369 lr 0.00026257 rank 5
2022-12-08 01:26:24,125 DEBUG TRAIN Batch 24/4100 loss 8.781549 loss_att 392.187866 loss_ctc 17.117786 loss_rnnt 7.855301 lr 0.00026258 rank 2
2022-12-08 01:26:24,126 DEBUG TRAIN Batch 24/4100 loss 3.455033 loss_att 366.926117 loss_ctc 11.740400 loss_rnnt 2.534436 lr 0.00026258 rank 0
2022-12-08 01:26:24,175 DEBUG TRAIN Batch 24/4100 loss 3.686928 loss_att 387.621643 loss_ctc 7.184648 loss_rnnt 3.298292 lr 0.00026259 rank 3
2022-12-08 01:27:28,253 DEBUG TRAIN Batch 24/4200 loss 5.121644 loss_att 410.309143 loss_ctc 13.228935 loss_rnnt 4.220834 lr 0.00026255 rank 4
2022-12-08 01:27:28,254 DEBUG TRAIN Batch 24/4200 loss 8.190191 loss_att 359.602417 loss_ctc 17.795891 loss_rnnt 7.122891 lr 0.00026253 rank 7
2022-12-08 01:27:28,254 DEBUG TRAIN Batch 24/4200 loss 4.745647 loss_att 355.382111 loss_ctc 7.656478 loss_rnnt 4.422221 lr 0.00026255 rank 0
2022-12-08 01:27:28,258 DEBUG TRAIN Batch 24/4200 loss 6.002560 loss_att 361.600464 loss_ctc 11.452528 loss_rnnt 5.397008 lr 0.00026254 rank 2
2022-12-08 01:27:28,258 DEBUG TRAIN Batch 24/4200 loss 9.394749 loss_att 394.285706 loss_ctc 18.795677 loss_rnnt 8.350202 lr 0.00026254 rank 5
2022-12-08 01:27:28,265 DEBUG TRAIN Batch 24/4200 loss 8.331931 loss_att 343.692627 loss_ctc 15.969831 loss_rnnt 7.483275 lr 0.00026256 rank 1
2022-12-08 01:27:28,276 DEBUG TRAIN Batch 24/4200 loss 5.723285 loss_att 345.806641 loss_ctc 13.075310 loss_rnnt 4.906394 lr 0.00026254 rank 6
2022-12-08 01:27:28,287 DEBUG TRAIN Batch 24/4200 loss 7.185569 loss_att 344.854980 loss_ctc 15.005494 loss_rnnt 6.316689 lr 0.00026256 rank 3
2022-12-08 01:28:40,096 DEBUG TRAIN Batch 24/4300 loss 18.135090 loss_att 361.921967 loss_ctc 36.022766 loss_rnnt 16.147572 lr 0.00026252 rank 1
2022-12-08 01:28:40,096 DEBUG TRAIN Batch 24/4300 loss 6.190745 loss_att 386.038757 loss_ctc 19.323111 loss_rnnt 4.731593 lr 0.00026251 rank 6
2022-12-08 01:28:40,096 DEBUG TRAIN Batch 24/4300 loss 10.296885 loss_att 281.917999 loss_ctc 16.247461 loss_rnnt 9.635711 lr 0.00026252 rank 3
2022-12-08 01:28:40,097 DEBUG TRAIN Batch 24/4300 loss 8.115172 loss_att 365.258484 loss_ctc 11.646173 loss_rnnt 7.722839 lr 0.00026251 rank 4
2022-12-08 01:28:40,098 DEBUG TRAIN Batch 24/4300 loss 7.189602 loss_att 314.193695 loss_ctc 17.646257 loss_rnnt 6.027751 lr 0.00026249 rank 7
2022-12-08 01:28:40,101 DEBUG TRAIN Batch 24/4300 loss 14.997690 loss_att 358.311981 loss_ctc 28.729088 loss_rnnt 13.471980 lr 0.00026251 rank 0
2022-12-08 01:28:40,103 DEBUG TRAIN Batch 24/4300 loss 7.899792 loss_att 332.652313 loss_ctc 16.799896 loss_rnnt 6.910892 lr 0.00026251 rank 2
2022-12-08 01:28:40,105 DEBUG TRAIN Batch 24/4300 loss 4.038016 loss_att 326.127075 loss_ctc 13.131043 loss_rnnt 3.027680 lr 0.00026250 rank 5
2022-12-08 01:29:43,536 DEBUG TRAIN Batch 24/4400 loss 17.495089 loss_att 351.248199 loss_ctc 30.540573 loss_rnnt 16.045591 lr 0.00026247 rank 4
2022-12-08 01:29:43,537 DEBUG TRAIN Batch 24/4400 loss 9.841995 loss_att 181.648575 loss_ctc 15.466790 loss_rnnt 9.217019 lr 0.00026246 rank 7
2022-12-08 01:29:43,539 DEBUG TRAIN Batch 24/4400 loss 5.405588 loss_att 232.719116 loss_ctc 9.746619 loss_rnnt 4.923251 lr 0.00026247 rank 6
2022-12-08 01:29:43,542 DEBUG TRAIN Batch 24/4400 loss 5.683449 loss_att 246.929184 loss_ctc 10.915915 loss_rnnt 5.102063 lr 0.00026247 rank 2
2022-12-08 01:29:43,544 DEBUG TRAIN Batch 24/4400 loss 8.246983 loss_att 279.741852 loss_ctc 17.231882 loss_rnnt 7.248661 lr 0.00026247 rank 0
2022-12-08 01:29:43,544 DEBUG TRAIN Batch 24/4400 loss 11.572819 loss_att 358.568848 loss_ctc 29.977987 loss_rnnt 9.527801 lr 0.00026249 rank 1
2022-12-08 01:29:43,548 DEBUG TRAIN Batch 24/4400 loss 8.437298 loss_att 317.937561 loss_ctc 15.967664 loss_rnnt 7.600591 lr 0.00026246 rank 5
2022-12-08 01:29:43,548 DEBUG TRAIN Batch 24/4400 loss 15.089747 loss_att 196.156403 loss_ctc 22.966967 loss_rnnt 14.214501 lr 0.00026249 rank 3
2022-12-08 01:30:47,501 DEBUG TRAIN Batch 24/4500 loss 5.776313 loss_att 121.554581 loss_ctc 11.022122 loss_rnnt 5.193446 lr 0.00026244 rank 4
2022-12-08 01:30:47,506 DEBUG TRAIN Batch 24/4500 loss 13.132141 loss_att 358.393402 loss_ctc 27.417511 loss_rnnt 11.544878 lr 0.00026242 rank 7
2022-12-08 01:30:47,510 DEBUG TRAIN Batch 24/4500 loss 2.112346 loss_att 404.045349 loss_ctc 6.732098 loss_rnnt 1.599040 lr 0.00026245 rank 3
2022-12-08 01:30:47,513 DEBUG TRAIN Batch 24/4500 loss 4.907868 loss_att 303.510040 loss_ctc 7.257884 loss_rnnt 4.646755 lr 0.00026243 rank 5
2022-12-08 01:30:47,514 DEBUG TRAIN Batch 24/4500 loss 9.978095 loss_att 186.394897 loss_ctc 14.894863 loss_rnnt 9.431787 lr 0.00026244 rank 0
2022-12-08 01:30:47,531 DEBUG TRAIN Batch 24/4500 loss 12.153885 loss_att 312.966309 loss_ctc 21.263298 loss_rnnt 11.141727 lr 0.00026245 rank 1
2022-12-08 01:30:47,547 DEBUG TRAIN Batch 24/4500 loss 8.675949 loss_att 376.749451 loss_ctc 16.616680 loss_rnnt 7.793646 lr 0.00026244 rank 6
2022-12-08 01:30:47,550 DEBUG TRAIN Batch 24/4500 loss 10.274724 loss_att 370.457489 loss_ctc 21.720821 loss_rnnt 9.002935 lr 0.00026244 rank 2
2022-12-08 01:31:53,067 DEBUG TRAIN Batch 24/4600 loss 2.476351 loss_att 370.694580 loss_ctc 7.075811 loss_rnnt 1.965300 lr 0.00026240 rank 4
2022-12-08 01:31:53,080 DEBUG TRAIN Batch 24/4600 loss 6.668051 loss_att 404.990234 loss_ctc 15.208415 loss_rnnt 5.719121 lr 0.00026240 rank 6
2022-12-08 01:31:53,081 DEBUG TRAIN Batch 24/4600 loss 3.415457 loss_att 403.601624 loss_ctc 11.330282 loss_rnnt 2.536032 lr 0.00026241 rank 3
2022-12-08 01:31:53,083 DEBUG TRAIN Batch 24/4600 loss 6.232253 loss_att 362.664398 loss_ctc 13.793757 loss_rnnt 5.392086 lr 0.00026240 rank 2
2022-12-08 01:31:53,084 DEBUG TRAIN Batch 24/4600 loss 8.124902 loss_att 379.780579 loss_ctc 13.383334 loss_rnnt 7.540631 lr 0.00026239 rank 7
2022-12-08 01:31:53,085 DEBUG TRAIN Batch 24/4600 loss 3.717432 loss_att 408.303070 loss_ctc 8.856992 loss_rnnt 3.146369 lr 0.00026242 rank 1
2022-12-08 01:31:53,087 DEBUG TRAIN Batch 24/4600 loss 3.927956 loss_att 367.966492 loss_ctc 13.449264 loss_rnnt 2.870033 lr 0.00026240 rank 0
2022-12-08 01:31:53,088 DEBUG TRAIN Batch 24/4600 loss 8.772997 loss_att 369.953308 loss_ctc 14.186583 loss_rnnt 8.171487 lr 0.00026239 rank 5
2022-12-08 01:33:06,561 DEBUG TRAIN Batch 24/4700 loss 12.458336 loss_att 378.631958 loss_ctc 27.244326 loss_rnnt 10.815448 lr 0.00026236 rank 6
2022-12-08 01:33:06,562 DEBUG TRAIN Batch 24/4700 loss 9.172057 loss_att 395.808380 loss_ctc 17.372929 loss_rnnt 8.260849 lr 0.00026235 rank 7
2022-12-08 01:33:06,562 DEBUG TRAIN Batch 24/4700 loss 13.971064 loss_att 378.021454 loss_ctc 32.928413 loss_rnnt 11.864692 lr 0.00026237 rank 4
2022-12-08 01:33:06,565 DEBUG TRAIN Batch 24/4700 loss 3.513626 loss_att 437.065521 loss_ctc 8.591068 loss_rnnt 2.949466 lr 0.00026236 rank 2
2022-12-08 01:33:06,565 DEBUG TRAIN Batch 24/4700 loss 7.293970 loss_att 399.753326 loss_ctc 13.691912 loss_rnnt 6.583087 lr 0.00026238 rank 3
2022-12-08 01:33:06,571 DEBUG TRAIN Batch 24/4700 loss 4.221254 loss_att 410.699463 loss_ctc 7.287608 loss_rnnt 3.880548 lr 0.00026236 rank 5
2022-12-08 01:33:06,573 DEBUG TRAIN Batch 24/4700 loss 3.293401 loss_att 439.243744 loss_ctc 6.685263 loss_rnnt 2.916528 lr 0.00026236 rank 0
2022-12-08 01:33:06,580 DEBUG TRAIN Batch 24/4700 loss 2.282787 loss_att 362.139282 loss_ctc 4.021459 loss_rnnt 2.089601 lr 0.00026238 rank 1
2022-12-08 01:34:10,128 DEBUG TRAIN Batch 24/4800 loss 15.482770 loss_att 419.028564 loss_ctc 23.628481 loss_rnnt 14.577691 lr 0.00026231 rank 7
2022-12-08 01:34:10,131 DEBUG TRAIN Batch 24/4800 loss 6.146772 loss_att 405.153381 loss_ctc 14.917899 loss_rnnt 5.172203 lr 0.00026233 rank 0
2022-12-08 01:34:10,133 DEBUG TRAIN Batch 24/4800 loss 6.869460 loss_att 341.537842 loss_ctc 10.498343 loss_rnnt 6.466250 lr 0.00026233 rank 4
2022-12-08 01:34:10,135 DEBUG TRAIN Batch 24/4800 loss 2.617477 loss_att 352.348572 loss_ctc 6.469308 loss_rnnt 2.189496 lr 0.00026234 rank 1
2022-12-08 01:34:10,135 DEBUG TRAIN Batch 24/4800 loss 5.040257 loss_att 328.846954 loss_ctc 10.927291 loss_rnnt 4.386142 lr 0.00026232 rank 5
2022-12-08 01:34:10,136 DEBUG TRAIN Batch 24/4800 loss 9.524834 loss_att 403.462952 loss_ctc 23.330626 loss_rnnt 7.990857 lr 0.00026233 rank 6
2022-12-08 01:34:10,136 DEBUG TRAIN Batch 24/4800 loss 8.209888 loss_att 343.446899 loss_ctc 15.762001 loss_rnnt 7.370763 lr 0.00026233 rank 2
2022-12-08 01:34:10,140 DEBUG TRAIN Batch 24/4800 loss 12.227013 loss_att 405.379150 loss_ctc 22.119854 loss_rnnt 11.127808 lr 0.00026234 rank 3
2022-12-08 01:35:14,883 DEBUG TRAIN Batch 24/4900 loss 8.123672 loss_att 313.985443 loss_ctc 14.814651 loss_rnnt 7.380229 lr 0.00026231 rank 3
2022-12-08 01:35:14,884 DEBUG TRAIN Batch 24/4900 loss 2.144138 loss_att 311.467560 loss_ctc 8.080521 loss_rnnt 1.484540 lr 0.00026229 rank 6
2022-12-08 01:35:14,885 DEBUG TRAIN Batch 24/4900 loss 7.832224 loss_att 338.510101 loss_ctc 16.113014 loss_rnnt 6.912137 lr 0.00026228 rank 5
2022-12-08 01:35:14,885 DEBUG TRAIN Batch 24/4900 loss 6.880139 loss_att 331.118622 loss_ctc 12.420831 loss_rnnt 6.264507 lr 0.00026231 rank 1
2022-12-08 01:35:14,888 DEBUG TRAIN Batch 24/4900 loss 9.082649 loss_att 389.497101 loss_ctc 14.506578 loss_rnnt 8.479990 lr 0.00026229 rank 0
2022-12-08 01:35:14,888 DEBUG TRAIN Batch 24/4900 loss 5.795143 loss_att 322.274597 loss_ctc 12.213877 loss_rnnt 5.081950 lr 0.00026229 rank 2
2022-12-08 01:35:14,900 DEBUG TRAIN Batch 24/4900 loss 8.001670 loss_att 351.996826 loss_ctc 20.671402 loss_rnnt 6.593922 lr 0.00026228 rank 7
2022-12-08 01:35:14,904 DEBUG TRAIN Batch 24/4900 loss 9.231421 loss_att 360.058136 loss_ctc 11.791351 loss_rnnt 8.946985 lr 0.00026229 rank 4
2022-12-08 01:36:25,998 DEBUG TRAIN Batch 24/5000 loss 9.804509 loss_att 112.991043 loss_ctc 15.409163 loss_rnnt 9.181770 lr 0.00026227 rank 3
2022-12-08 01:36:26,010 DEBUG TRAIN Batch 24/5000 loss 6.436030 loss_att 349.011047 loss_ctc 14.685622 loss_rnnt 5.519409 lr 0.00026226 rank 4
2022-12-08 01:36:26,011 DEBUG TRAIN Batch 24/5000 loss 5.531257 loss_att 371.750671 loss_ctc 14.634853 loss_rnnt 4.519746 lr 0.00026225 rank 5
2022-12-08 01:36:26,013 DEBUG TRAIN Batch 24/5000 loss 16.744484 loss_att 346.712036 loss_ctc 24.734434 loss_rnnt 15.856712 lr 0.00026227 rank 1
2022-12-08 01:36:26,013 DEBUG TRAIN Batch 24/5000 loss 12.943213 loss_att 290.485107 loss_ctc 21.613119 loss_rnnt 11.979891 lr 0.00026224 rank 7
2022-12-08 01:36:26,013 DEBUG TRAIN Batch 24/5000 loss 7.600149 loss_att 359.907959 loss_ctc 17.161873 loss_rnnt 6.537735 lr 0.00026226 rank 0
2022-12-08 01:36:26,014 DEBUG TRAIN Batch 24/5000 loss 8.921115 loss_att 293.439545 loss_ctc 20.953032 loss_rnnt 7.584236 lr 0.00026226 rank 6
2022-12-08 01:36:26,015 DEBUG TRAIN Batch 24/5000 loss 8.568144 loss_att 337.814636 loss_ctc 14.778966 loss_rnnt 7.878053 lr 0.00026225 rank 2
2022-12-08 01:37:29,712 DEBUG TRAIN Batch 24/5100 loss 10.966333 loss_att 371.185303 loss_ctc 31.505722 loss_rnnt 8.684179 lr 0.00026221 rank 7
2022-12-08 01:37:29,734 DEBUG TRAIN Batch 24/5100 loss 10.485486 loss_att 255.070770 loss_ctc 19.628796 loss_rnnt 9.469563 lr 0.00026222 rank 4
2022-12-08 01:37:29,735 DEBUG TRAIN Batch 24/5100 loss 5.908339 loss_att 340.404694 loss_ctc 12.023406 loss_rnnt 5.228887 lr 0.00026224 rank 1
2022-12-08 01:37:29,736 DEBUG TRAIN Batch 24/5100 loss 8.405742 loss_att 341.401001 loss_ctc 10.760833 loss_rnnt 8.144065 lr 0.00026223 rank 3
2022-12-08 01:37:29,736 DEBUG TRAIN Batch 24/5100 loss 4.743938 loss_att 382.863861 loss_ctc 8.913515 loss_rnnt 4.280652 lr 0.00026222 rank 6
2022-12-08 01:37:29,736 DEBUG TRAIN Batch 24/5100 loss 4.029967 loss_att 171.751205 loss_ctc 8.806639 loss_rnnt 3.499226 lr 0.00026221 rank 5
2022-12-08 01:37:29,737 DEBUG TRAIN Batch 24/5100 loss 7.455915 loss_att 210.002762 loss_ctc 14.311403 loss_rnnt 6.694194 lr 0.00026222 rank 2
2022-12-08 01:37:29,740 DEBUG TRAIN Batch 24/5100 loss 6.650094 loss_att 142.597397 loss_ctc 14.313878 loss_rnnt 5.798562 lr 0.00026222 rank 0
2022-12-08 01:38:32,949 DEBUG TRAIN Batch 24/5200 loss 1.548362 loss_att 135.646454 loss_ctc 3.193307 loss_rnnt 1.365590 lr 0.00026220 rank 1
2022-12-08 01:38:32,952 DEBUG TRAIN Batch 24/5200 loss 3.019029 loss_att 308.510742 loss_ctc 6.156061 loss_rnnt 2.670470 lr 0.00026218 rank 6
2022-12-08 01:38:32,953 DEBUG TRAIN Batch 24/5200 loss 3.614889 loss_att 330.936523 loss_ctc 9.811253 loss_rnnt 2.926404 lr 0.00026220 rank 3
2022-12-08 01:38:32,955 DEBUG TRAIN Batch 24/5200 loss 13.406387 loss_att 377.923035 loss_ctc 21.443111 loss_rnnt 12.513418 lr 0.00026218 rank 0
2022-12-08 01:38:32,957 DEBUG TRAIN Batch 24/5200 loss 12.140387 loss_att 390.310547 loss_ctc 17.304859 loss_rnnt 11.566557 lr 0.00026218 rank 2
2022-12-08 01:38:32,958 DEBUG TRAIN Batch 24/5200 loss 5.561968 loss_att 446.645447 loss_ctc 16.890511 loss_rnnt 4.303242 lr 0.00026218 rank 5
2022-12-08 01:38:32,964 DEBUG TRAIN Batch 24/5200 loss 4.119460 loss_att 364.109375 loss_ctc 13.748649 loss_rnnt 3.049551 lr 0.00026219 rank 4
2022-12-08 01:38:32,976 DEBUG TRAIN Batch 24/5200 loss 6.054424 loss_att 412.202942 loss_ctc 17.729074 loss_rnnt 4.757241 lr 0.00026217 rank 7
2022-12-08 01:39:38,127 DEBUG TRAIN Batch 24/5300 loss 1.635448 loss_att 300.503235 loss_ctc 4.888340 loss_rnnt 1.274016 lr 0.00026214 rank 5
2022-12-08 01:39:38,134 DEBUG TRAIN Batch 24/5300 loss 8.147944 loss_att 389.159851 loss_ctc 14.822496 loss_rnnt 7.406328 lr 0.00026213 rank 7
2022-12-08 01:39:38,135 DEBUG TRAIN Batch 24/5300 loss 4.147455 loss_att 425.482147 loss_ctc 7.814041 loss_rnnt 3.740057 lr 0.00026215 rank 2
2022-12-08 01:39:38,137 DEBUG TRAIN Batch 24/5300 loss 4.526321 loss_att 332.024414 loss_ctc 12.013835 loss_rnnt 3.694376 lr 0.00026215 rank 4
2022-12-08 01:39:38,138 DEBUG TRAIN Batch 24/5300 loss 12.784739 loss_att 372.769043 loss_ctc 23.730488 loss_rnnt 11.568544 lr 0.00026216 rank 3
2022-12-08 01:39:38,139 DEBUG TRAIN Batch 24/5300 loss 4.494087 loss_att 372.002777 loss_ctc 12.176552 loss_rnnt 3.640480 lr 0.00026216 rank 1
2022-12-08 01:39:38,140 DEBUG TRAIN Batch 24/5300 loss 5.613949 loss_att 324.137360 loss_ctc 9.162407 loss_rnnt 5.219676 lr 0.00026215 rank 0
2022-12-08 01:39:38,140 DEBUG TRAIN Batch 24/5300 loss 7.953873 loss_att 320.822449 loss_ctc 18.822742 loss_rnnt 6.746222 lr 0.00026215 rank 6
2022-12-08 01:40:48,563 DEBUG TRAIN Batch 24/5400 loss 10.651801 loss_att 387.220154 loss_ctc 22.520561 loss_rnnt 9.333050 lr 0.00026211 rank 4
2022-12-08 01:40:48,566 DEBUG TRAIN Batch 24/5400 loss 2.525925 loss_att 376.323242 loss_ctc 6.716825 loss_rnnt 2.060270 lr 0.00026211 rank 6
2022-12-08 01:40:48,566 DEBUG TRAIN Batch 24/5400 loss 12.398510 loss_att 345.342377 loss_ctc 21.625116 loss_rnnt 11.373332 lr 0.00026211 rank 2
2022-12-08 01:40:48,568 DEBUG TRAIN Batch 24/5400 loss 8.768957 loss_att 424.335632 loss_ctc 21.428349 loss_rnnt 7.362359 lr 0.00026211 rank 0
2022-12-08 01:40:48,568 DEBUG TRAIN Batch 24/5400 loss 7.244316 loss_att 371.879059 loss_ctc 12.876181 loss_rnnt 6.618554 lr 0.00026210 rank 7
2022-12-08 01:40:48,570 DEBUG TRAIN Batch 24/5400 loss 18.884972 loss_att 442.758972 loss_ctc 31.973465 loss_rnnt 17.430695 lr 0.00026210 rank 5
2022-12-08 01:40:48,572 DEBUG TRAIN Batch 24/5400 loss 13.294788 loss_att 366.031250 loss_ctc 32.846066 loss_rnnt 11.122424 lr 0.00026213 rank 1
2022-12-08 01:40:48,573 DEBUG TRAIN Batch 24/5400 loss 5.882322 loss_att 321.478119 loss_ctc 22.770081 loss_rnnt 4.005905 lr 0.00026213 rank 3
2022-12-08 01:41:51,362 DEBUG TRAIN Batch 24/5500 loss 12.640908 loss_att 395.649445 loss_ctc 26.706902 loss_rnnt 11.078020 lr 0.00026206 rank 7
2022-12-08 01:41:51,363 DEBUG TRAIN Batch 24/5500 loss 7.291938 loss_att 480.013794 loss_ctc 13.461889 loss_rnnt 6.606388 lr 0.00026208 rank 4
2022-12-08 01:41:51,366 DEBUG TRAIN Batch 24/5500 loss 3.069448 loss_att 370.328827 loss_ctc 6.662492 loss_rnnt 2.670221 lr 0.00026207 rank 5
2022-12-08 01:41:51,368 DEBUG TRAIN Batch 24/5500 loss 5.912942 loss_att 328.109772 loss_ctc 10.082539 loss_rnnt 5.449654 lr 0.00026208 rank 6
2022-12-08 01:41:51,368 DEBUG TRAIN Batch 24/5500 loss 5.891202 loss_att 326.163818 loss_ctc 8.987968 loss_rnnt 5.547117 lr 0.00026209 rank 3
2022-12-08 01:41:51,368 DEBUG TRAIN Batch 24/5500 loss 6.660793 loss_att 365.443573 loss_ctc 15.964075 loss_rnnt 5.627096 lr 0.00026207 rank 2
2022-12-08 01:41:51,369 DEBUG TRAIN Batch 24/5500 loss 7.881775 loss_att 351.141357 loss_ctc 16.375071 loss_rnnt 6.938076 lr 0.00026208 rank 0
2022-12-08 01:41:51,369 DEBUG TRAIN Batch 24/5500 loss 4.550345 loss_att 403.935577 loss_ctc 12.502777 loss_rnnt 3.666742 lr 0.00026209 rank 1
2022-12-08 01:42:54,849 DEBUG TRAIN Batch 24/5600 loss 7.697874 loss_att 288.262451 loss_ctc 9.443448 loss_rnnt 7.503922 lr 0.00026204 rank 6
2022-12-08 01:42:54,850 DEBUG TRAIN Batch 24/5600 loss 8.451278 loss_att 201.261139 loss_ctc 13.178135 loss_rnnt 7.926071 lr 0.00026205 rank 3
2022-12-08 01:42:54,851 DEBUG TRAIN Batch 24/5600 loss 8.036219 loss_att 370.668518 loss_ctc 19.575081 loss_rnnt 6.754122 lr 0.00026204 rank 2
2022-12-08 01:42:54,856 DEBUG TRAIN Batch 24/5600 loss 8.224543 loss_att 287.282806 loss_ctc 18.587980 loss_rnnt 7.073050 lr 0.00026203 rank 7
2022-12-08 01:42:54,858 DEBUG TRAIN Batch 24/5600 loss 15.289474 loss_att 393.407715 loss_ctc 26.673359 loss_rnnt 14.024598 lr 0.00026204 rank 4
2022-12-08 01:42:54,861 DEBUG TRAIN Batch 24/5600 loss 8.534807 loss_att 352.339905 loss_ctc 17.315775 loss_rnnt 7.559144 lr 0.00026206 rank 1
2022-12-08 01:42:54,863 DEBUG TRAIN Batch 24/5600 loss 1.843671 loss_att 311.671417 loss_ctc 4.581987 loss_rnnt 1.539413 lr 0.00026203 rank 5
2022-12-08 01:42:54,870 DEBUG TRAIN Batch 24/5600 loss 8.054719 loss_att 360.348572 loss_ctc 17.353148 loss_rnnt 7.021560 lr 0.00026204 rank 0
2022-12-08 01:44:07,532 DEBUG TRAIN Batch 24/5700 loss 11.590664 loss_att 86.838272 loss_ctc 17.695435 loss_rnnt 10.912356 lr 0.00026199 rank 7
2022-12-08 01:44:07,537 DEBUG TRAIN Batch 24/5700 loss 7.047110 loss_att 287.238953 loss_ctc 13.275527 loss_rnnt 6.355063 lr 0.00026201 rank 4
2022-12-08 01:44:07,537 DEBUG TRAIN Batch 24/5700 loss 8.860834 loss_att 71.372650 loss_ctc 13.853172 loss_rnnt 8.306130 lr 0.00026200 rank 6
2022-12-08 01:44:07,543 DEBUG TRAIN Batch 24/5700 loss 15.693659 loss_att 388.526794 loss_ctc 32.130981 loss_rnnt 13.867290 lr 0.00026202 rank 3
2022-12-08 01:44:07,545 DEBUG TRAIN Batch 24/5700 loss 5.919960 loss_att 312.052734 loss_ctc 12.493152 loss_rnnt 5.189606 lr 0.00026200 rank 2
2022-12-08 01:44:07,546 DEBUG TRAIN Batch 24/5700 loss 4.036633 loss_att 222.372528 loss_ctc 9.127180 loss_rnnt 3.471016 lr 0.00026200 rank 0
2022-12-08 01:44:07,547 DEBUG TRAIN Batch 24/5700 loss 14.444647 loss_att 383.909180 loss_ctc 24.397419 loss_rnnt 13.338783 lr 0.00026202 rank 1
2022-12-08 01:44:07,587 DEBUG TRAIN Batch 24/5700 loss 5.441620 loss_att 287.702209 loss_ctc 14.583072 loss_rnnt 4.425904 lr 0.00026200 rank 5
2022-12-08 01:45:11,246 DEBUG TRAIN Batch 24/5800 loss 6.835747 loss_att 431.348145 loss_ctc 15.333011 loss_rnnt 5.891606 lr 0.00026197 rank 4
2022-12-08 01:45:11,247 DEBUG TRAIN Batch 24/5800 loss 8.892288 loss_att 396.813416 loss_ctc 22.034941 loss_rnnt 7.431993 lr 0.00026197 rank 2
2022-12-08 01:45:11,247 DEBUG TRAIN Batch 24/5800 loss 6.207987 loss_att 388.419037 loss_ctc 15.717624 loss_rnnt 5.151361 lr 0.00026195 rank 7
2022-12-08 01:45:11,250 DEBUG TRAIN Batch 24/5800 loss 5.764936 loss_att 391.693298 loss_ctc 11.365408 loss_rnnt 5.142662 lr 0.00026197 rank 6
2022-12-08 01:45:11,250 DEBUG TRAIN Batch 24/5800 loss 8.955227 loss_att 403.829468 loss_ctc 15.800430 loss_rnnt 8.194649 lr 0.00026198 rank 3
2022-12-08 01:45:11,253 DEBUG TRAIN Batch 24/5800 loss 5.883927 loss_att 416.892517 loss_ctc 18.111563 loss_rnnt 4.525301 lr 0.00026197 rank 0
2022-12-08 01:45:11,259 DEBUG TRAIN Batch 24/5800 loss 12.076427 loss_att 481.326630 loss_ctc 20.259434 loss_rnnt 11.167205 lr 0.00026196 rank 5
2022-12-08 01:45:11,290 DEBUG TRAIN Batch 24/5800 loss 8.136229 loss_att 263.631653 loss_ctc 15.511977 loss_rnnt 7.316701 lr 0.00026198 rank 1
2022-12-08 01:46:14,998 DEBUG TRAIN Batch 24/5900 loss 9.869327 loss_att 383.711517 loss_ctc 17.789959 loss_rnnt 8.989257 lr 0.00026193 rank 0
2022-12-08 01:46:14,999 DEBUG TRAIN Batch 24/5900 loss 5.438265 loss_att 408.740540 loss_ctc 11.539320 loss_rnnt 4.760370 lr 0.00026193 rank 6
2022-12-08 01:46:15,002 DEBUG TRAIN Batch 24/5900 loss 3.490459 loss_att 320.036316 loss_ctc 9.326874 loss_rnnt 2.841969 lr 0.00026195 rank 1
2022-12-08 01:46:15,001 DEBUG TRAIN Batch 24/5900 loss 12.556011 loss_att 312.202393 loss_ctc 23.467886 loss_rnnt 11.343581 lr 0.00026192 rank 5
2022-12-08 01:46:15,004 DEBUG TRAIN Batch 24/5900 loss 9.908974 loss_att 410.585693 loss_ctc 21.353657 loss_rnnt 8.637342 lr 0.00026193 rank 2
2022-12-08 01:46:15,014 DEBUG TRAIN Batch 24/5900 loss 5.310584 loss_att 345.967133 loss_ctc 11.006338 loss_rnnt 4.677722 lr 0.00026192 rank 7
2022-12-08 01:46:15,024 DEBUG TRAIN Batch 24/5900 loss 13.692551 loss_att 392.789520 loss_ctc 28.050945 loss_rnnt 12.097174 lr 0.00026193 rank 4
2022-12-08 01:46:15,036 DEBUG TRAIN Batch 24/5900 loss 5.119308 loss_att 326.777161 loss_ctc 14.000448 loss_rnnt 4.132515 lr 0.00026195 rank 3
2022-12-08 01:47:19,881 DEBUG TRAIN Batch 24/6000 loss 6.970913 loss_att 357.129486 loss_ctc 10.295607 loss_rnnt 6.601503 lr 0.00026190 rank 6
2022-12-08 01:47:19,883 DEBUG TRAIN Batch 24/6000 loss 6.305696 loss_att 389.652283 loss_ctc 16.107838 loss_rnnt 5.216568 lr 0.00026191 rank 3
2022-12-08 01:47:19,886 DEBUG TRAIN Batch 24/6000 loss 6.296783 loss_att 395.304138 loss_ctc 14.464053 loss_rnnt 5.389308 lr 0.00026189 rank 5
2022-12-08 01:47:19,893 DEBUG TRAIN Batch 24/6000 loss 7.907850 loss_att 350.465546 loss_ctc 18.838058 loss_rnnt 6.693383 lr 0.00026188 rank 7
2022-12-08 01:47:19,894 DEBUG TRAIN Batch 24/6000 loss 12.272797 loss_att 447.487885 loss_ctc 21.100697 loss_rnnt 11.291919 lr 0.00026191 rank 1
2022-12-08 01:47:19,896 DEBUG TRAIN Batch 24/6000 loss 7.123796 loss_att 379.780548 loss_ctc 10.499302 loss_rnnt 6.748741 lr 0.00026190 rank 4
2022-12-08 01:47:19,897 DEBUG TRAIN Batch 24/6000 loss 6.068477 loss_att 384.025482 loss_ctc 10.472915 loss_rnnt 5.579094 lr 0.00026190 rank 0
2022-12-08 01:47:19,907 DEBUG TRAIN Batch 24/6000 loss 9.057111 loss_att 376.924988 loss_ctc 18.138277 loss_rnnt 8.048093 lr 0.00026189 rank 2
2022-12-08 01:48:31,045 DEBUG TRAIN Batch 24/6100 loss 4.460668 loss_att 376.104706 loss_ctc 9.271723 loss_rnnt 3.926107 lr 0.00026185 rank 7
2022-12-08 01:48:31,046 DEBUG TRAIN Batch 24/6100 loss 5.904041 loss_att 341.282379 loss_ctc 16.305084 loss_rnnt 4.748369 lr 0.00026186 rank 0
2022-12-08 01:48:31,047 DEBUG TRAIN Batch 24/6100 loss 7.101247 loss_att 356.061035 loss_ctc 17.839281 loss_rnnt 5.908132 lr 0.00026186 rank 6
2022-12-08 01:48:31,049 DEBUG TRAIN Batch 24/6100 loss 14.350680 loss_att 392.491150 loss_ctc 19.228563 loss_rnnt 13.808694 lr 0.00026186 rank 4
2022-12-08 01:48:31,050 DEBUG TRAIN Batch 24/6100 loss 8.999875 loss_att 422.014771 loss_ctc 18.922146 loss_rnnt 7.897400 lr 0.00026185 rank 5
2022-12-08 01:48:31,053 DEBUG TRAIN Batch 24/6100 loss 6.432594 loss_att 401.853210 loss_ctc 12.913100 loss_rnnt 5.712538 lr 0.00026186 rank 2
2022-12-08 01:48:31,055 DEBUG TRAIN Batch 24/6100 loss 4.408410 loss_att 312.214355 loss_ctc 6.869484 loss_rnnt 4.134957 lr 0.00026187 rank 3
2022-12-08 01:48:31,057 DEBUG TRAIN Batch 24/6100 loss 5.583516 loss_att 362.328461 loss_ctc 8.620670 loss_rnnt 5.246054 lr 0.00026188 rank 1
2022-12-08 01:49:34,373 DEBUG TRAIN Batch 24/6200 loss 4.347978 loss_att 272.895264 loss_ctc 10.781872 loss_rnnt 3.633101 lr 0.00026181 rank 7
2022-12-08 01:49:34,377 DEBUG TRAIN Batch 24/6200 loss 6.204808 loss_att 391.925476 loss_ctc 13.282810 loss_rnnt 5.418364 lr 0.00026184 rank 1
2022-12-08 01:49:34,379 DEBUG TRAIN Batch 24/6200 loss 4.273985 loss_att 384.869781 loss_ctc 10.208151 loss_rnnt 3.614633 lr 0.00026182 rank 2
2022-12-08 01:49:34,380 DEBUG TRAIN Batch 24/6200 loss 12.470242 loss_att 355.403381 loss_ctc 24.226494 loss_rnnt 11.163992 lr 0.00026183 rank 4
2022-12-08 01:49:34,383 DEBUG TRAIN Batch 24/6200 loss 7.879192 loss_att 305.802185 loss_ctc 21.633518 loss_rnnt 6.350934 lr 0.00026182 rank 6
2022-12-08 01:49:34,384 DEBUG TRAIN Batch 24/6200 loss 3.029354 loss_att 344.178772 loss_ctc 8.443588 loss_rnnt 2.427773 lr 0.00026182 rank 0
2022-12-08 01:49:34,387 DEBUG TRAIN Batch 24/6200 loss 7.968953 loss_att 343.957428 loss_ctc 22.235641 loss_rnnt 6.383765 lr 0.00026182 rank 5
2022-12-08 01:49:34,425 DEBUG TRAIN Batch 24/6200 loss 12.205614 loss_att 275.946289 loss_ctc 24.079590 loss_rnnt 10.886284 lr 0.00026184 rank 3
2022-12-08 01:50:38,425 DEBUG TRAIN Batch 24/6300 loss 6.163237 loss_att 156.926163 loss_ctc 14.362443 loss_rnnt 5.252213 lr 0.00026177 rank 7
2022-12-08 01:50:38,426 DEBUG TRAIN Batch 24/6300 loss 8.763309 loss_att 333.229858 loss_ctc 21.222282 loss_rnnt 7.378980 lr 0.00026179 rank 2
2022-12-08 01:50:38,427 DEBUG TRAIN Batch 24/6300 loss 7.158032 loss_att 281.746552 loss_ctc 16.751911 loss_rnnt 6.092046 lr 0.00026179 rank 4
2022-12-08 01:50:38,428 DEBUG TRAIN Batch 24/6300 loss 15.064419 loss_att 199.938873 loss_ctc 30.900570 loss_rnnt 13.304847 lr 0.00026179 rank 6
2022-12-08 01:50:38,431 DEBUG TRAIN Batch 24/6300 loss 7.928796 loss_att 331.930359 loss_ctc 16.629900 loss_rnnt 6.962007 lr 0.00026178 rank 5
2022-12-08 01:50:38,431 DEBUG TRAIN Batch 24/6300 loss 10.585178 loss_att 312.010803 loss_ctc 20.084929 loss_rnnt 9.529651 lr 0.00026179 rank 0
2022-12-08 01:50:38,435 DEBUG TRAIN Batch 24/6300 loss 5.945765 loss_att 76.968651 loss_ctc 9.649531 loss_rnnt 5.534235 lr 0.00026180 rank 3
2022-12-08 01:50:38,440 DEBUG TRAIN Batch 24/6300 loss 8.570353 loss_att 410.224060 loss_ctc 16.475204 loss_rnnt 7.692036 lr 0.00026180 rank 1
2022-12-08 01:51:51,497 DEBUG TRAIN Batch 24/6400 loss 7.814219 loss_att 380.145111 loss_ctc 20.621038 loss_rnnt 6.391239 lr 0.00026174 rank 7
2022-12-08 01:51:51,498 DEBUG TRAIN Batch 24/6400 loss 7.700500 loss_att 390.932922 loss_ctc 15.897839 loss_rnnt 6.789684 lr 0.00026175 rank 6
2022-12-08 01:51:51,499 DEBUG TRAIN Batch 24/6400 loss 5.516076 loss_att 429.585571 loss_ctc 12.053837 loss_rnnt 4.789658 lr 0.00026175 rank 0
2022-12-08 01:51:51,501 DEBUG TRAIN Batch 24/6400 loss 9.484901 loss_att 181.478668 loss_ctc 17.261475 loss_rnnt 8.620838 lr 0.00026175 rank 2
2022-12-08 01:51:51,503 DEBUG TRAIN Batch 24/6400 loss 8.242952 loss_att 265.735321 loss_ctc 14.717700 loss_rnnt 7.523536 lr 0.00026177 rank 1
2022-12-08 01:51:51,506 DEBUG TRAIN Batch 24/6400 loss 7.877095 loss_att 391.324585 loss_ctc 12.053568 loss_rnnt 7.413043 lr 0.00026177 rank 3
2022-12-08 01:51:51,508 DEBUG TRAIN Batch 24/6400 loss 7.274281 loss_att 234.375992 loss_ctc 14.755330 loss_rnnt 6.443053 lr 0.00026174 rank 5
2022-12-08 01:51:51,522 DEBUG TRAIN Batch 24/6400 loss 14.738121 loss_att 406.844910 loss_ctc 25.488041 loss_rnnt 13.543686 lr 0.00026175 rank 4
2022-12-08 01:52:55,044 DEBUG TRAIN Batch 24/6500 loss 10.970679 loss_att 412.058716 loss_ctc 25.884285 loss_rnnt 9.313612 lr 0.00026171 rank 5
2022-12-08 01:52:55,050 DEBUG TRAIN Batch 24/6500 loss 17.973694 loss_att 371.610291 loss_ctc 30.554089 loss_rnnt 16.575872 lr 0.00026170 rank 7
2022-12-08 01:52:55,055 DEBUG TRAIN Batch 24/6500 loss 16.947327 loss_att 405.469086 loss_ctc 27.604704 loss_rnnt 15.763175 lr 0.00026173 rank 3
2022-12-08 01:52:55,055 DEBUG TRAIN Batch 24/6500 loss 4.373599 loss_att 373.470032 loss_ctc 9.635542 loss_rnnt 3.788938 lr 0.00026172 rank 4
2022-12-08 01:52:55,057 DEBUG TRAIN Batch 24/6500 loss 3.279824 loss_att 345.676208 loss_ctc 8.809019 loss_rnnt 2.665469 lr 0.00026172 rank 6
2022-12-08 01:52:55,059 DEBUG TRAIN Batch 24/6500 loss 5.037504 loss_att 376.912476 loss_ctc 12.771334 loss_rnnt 4.178189 lr 0.00026172 rank 0
2022-12-08 01:52:55,059 DEBUG TRAIN Batch 24/6500 loss 1.942701 loss_att 391.461761 loss_ctc 6.926225 loss_rnnt 1.388976 lr 0.00026172 rank 2
2022-12-08 01:52:55,061 DEBUG TRAIN Batch 24/6500 loss 11.425291 loss_att 462.491791 loss_ctc 28.419231 loss_rnnt 9.537075 lr 0.00026173 rank 1
2022-12-08 01:53:57,538 DEBUG TRAIN Batch 24/6600 loss 5.879360 loss_att 412.525238 loss_ctc 10.050530 loss_rnnt 5.415897 lr 0.00026167 rank 5
2022-12-08 01:53:57,544 DEBUG TRAIN Batch 24/6600 loss 4.085604 loss_att 344.000092 loss_ctc 7.151660 loss_rnnt 3.744931 lr 0.00026169 rank 3
2022-12-08 01:53:57,544 DEBUG TRAIN Batch 24/6600 loss 1.858637 loss_att 356.358398 loss_ctc 5.944127 loss_rnnt 1.404693 lr 0.00026170 rank 1
2022-12-08 01:53:57,545 DEBUG TRAIN Batch 24/6600 loss 6.101892 loss_att 416.051086 loss_ctc 15.989435 loss_rnnt 5.003276 lr 0.00026168 rank 2
2022-12-08 01:53:57,547 DEBUG TRAIN Batch 24/6600 loss 18.761494 loss_att 349.291382 loss_ctc 32.725494 loss_rnnt 17.209938 lr 0.00026168 rank 4
2022-12-08 01:53:57,549 DEBUG TRAIN Batch 24/6600 loss 8.464056 loss_att 429.992004 loss_ctc 24.308746 loss_rnnt 6.703535 lr 0.00026168 rank 0
2022-12-08 01:53:57,551 DEBUG TRAIN Batch 24/6600 loss 7.839246 loss_att 335.822937 loss_ctc 16.770086 loss_rnnt 6.846931 lr 0.00026167 rank 7
2022-12-08 01:53:57,583 DEBUG TRAIN Batch 24/6600 loss 9.006913 loss_att 368.084076 loss_ctc 16.929668 loss_rnnt 8.126608 lr 0.00026168 rank 6
2022-12-08 01:55:01,576 DEBUG TRAIN Batch 24/6700 loss 11.732637 loss_att 420.255737 loss_ctc 23.258507 loss_rnnt 10.451985 lr 0.00026163 rank 7
2022-12-08 01:55:01,578 DEBUG TRAIN Batch 24/6700 loss 10.215073 loss_att 391.744446 loss_ctc 16.311192 loss_rnnt 9.537726 lr 0.00026164 rank 6
2022-12-08 01:55:01,579 DEBUG TRAIN Batch 24/6700 loss 8.272730 loss_att 338.841309 loss_ctc 16.645895 loss_rnnt 7.342379 lr 0.00026166 rank 3
2022-12-08 01:55:01,582 DEBUG TRAIN Batch 24/6700 loss 9.769412 loss_att 431.310120 loss_ctc 18.016314 loss_rnnt 8.853090 lr 0.00026164 rank 0
2022-12-08 01:55:01,582 DEBUG TRAIN Batch 24/6700 loss 5.657752 loss_att 399.772339 loss_ctc 10.966862 loss_rnnt 5.067850 lr 0.00026164 rank 2
2022-12-08 01:55:01,583 DEBUG TRAIN Batch 24/6700 loss 12.374947 loss_att 377.700867 loss_ctc 28.072205 loss_rnnt 10.630807 lr 0.00026164 rank 5
2022-12-08 01:55:01,585 DEBUG TRAIN Batch 24/6700 loss 6.544729 loss_att 315.546753 loss_ctc 14.380401 loss_rnnt 5.674099 lr 0.00026165 rank 4
2022-12-08 01:55:01,625 DEBUG TRAIN Batch 24/6700 loss 8.677699 loss_att 298.747803 loss_ctc 22.772352 loss_rnnt 7.111627 lr 0.00026166 rank 1
2022-12-08 01:56:14,510 DEBUG TRAIN Batch 24/6800 loss 3.508642 loss_att 342.580750 loss_ctc 10.412721 loss_rnnt 2.741523 lr 0.00026160 rank 7
2022-12-08 01:56:14,514 DEBUG TRAIN Batch 24/6800 loss 9.086576 loss_att 382.390015 loss_ctc 14.477289 loss_rnnt 8.487608 lr 0.00026161 rank 6
2022-12-08 01:56:14,514 DEBUG TRAIN Batch 24/6800 loss 9.310371 loss_att 358.896820 loss_ctc 15.171679 loss_rnnt 8.659115 lr 0.00026161 rank 0
2022-12-08 01:56:14,515 DEBUG TRAIN Batch 24/6800 loss 5.470240 loss_att 315.573669 loss_ctc 14.064121 loss_rnnt 4.515364 lr 0.00026161 rank 4
2022-12-08 01:56:14,518 DEBUG TRAIN Batch 24/6800 loss 7.199299 loss_att 390.718536 loss_ctc 17.221878 loss_rnnt 6.085679 lr 0.00026160 rank 5
2022-12-08 01:56:14,518 DEBUG TRAIN Batch 24/6800 loss 2.568891 loss_att 332.270264 loss_ctc 7.225311 loss_rnnt 2.051511 lr 0.00026161 rank 2
2022-12-08 01:56:14,538 DEBUG TRAIN Batch 24/6800 loss 12.670387 loss_att 391.494019 loss_ctc 28.228748 loss_rnnt 10.941681 lr 0.00026162 rank 1
2022-12-08 01:56:14,539 DEBUG TRAIN Batch 24/6800 loss 11.981273 loss_att 346.631256 loss_ctc 26.465742 loss_rnnt 10.371887 lr 0.00026162 rank 3
2022-12-08 01:57:17,590 DEBUG TRAIN Batch 24/6900 loss 3.976091 loss_att 289.251312 loss_ctc 9.920848 loss_rnnt 3.315563 lr 0.00026156 rank 7
2022-12-08 01:57:17,596 DEBUG TRAIN Batch 24/6900 loss 11.394752 loss_att 307.755829 loss_ctc 18.750532 loss_rnnt 10.577443 lr 0.00026157 rank 6
2022-12-08 01:57:17,599 DEBUG TRAIN Batch 24/6900 loss 6.136650 loss_att 332.620789 loss_ctc 16.972624 loss_rnnt 4.932653 lr 0.00026157 rank 0
2022-12-08 01:57:17,602 DEBUG TRAIN Batch 24/6900 loss 8.259775 loss_att 224.893280 loss_ctc 18.122635 loss_rnnt 7.163901 lr 0.00026159 rank 3
2022-12-08 01:57:17,602 DEBUG TRAIN Batch 24/6900 loss 12.013686 loss_att 324.951874 loss_ctc 24.849091 loss_rnnt 10.587530 lr 0.00026158 rank 4
2022-12-08 01:57:17,604 DEBUG TRAIN Batch 24/6900 loss 9.997412 loss_att 330.988892 loss_ctc 17.362616 loss_rnnt 9.179056 lr 0.00026156 rank 5
2022-12-08 01:57:17,606 DEBUG TRAIN Batch 24/6900 loss 2.584899 loss_att 304.234619 loss_ctc 7.474828 loss_rnnt 2.041574 lr 0.00026157 rank 2
2022-12-08 01:57:17,612 DEBUG TRAIN Batch 24/6900 loss 11.615789 loss_att 373.985901 loss_ctc 23.618416 loss_rnnt 10.282164 lr 0.00026159 rank 1
2022-12-08 01:58:22,096 DEBUG TRAIN Batch 24/7000 loss 8.372217 loss_att 400.735199 loss_ctc 18.438946 loss_rnnt 7.253692 lr 0.00026154 rank 4
2022-12-08 01:58:22,097 DEBUG TRAIN Batch 24/7000 loss 7.936632 loss_att 188.349686 loss_ctc 18.137014 loss_rnnt 6.803256 lr 0.00026154 rank 0
2022-12-08 01:58:22,100 DEBUG TRAIN Batch 24/7000 loss 3.785641 loss_att 355.892914 loss_ctc 12.486534 loss_rnnt 2.818875 lr 0.00026155 rank 3
2022-12-08 01:58:22,101 DEBUG TRAIN Batch 24/7000 loss 8.080383 loss_att 74.727501 loss_ctc 11.977528 loss_rnnt 7.647368 lr 0.00026152 rank 7
2022-12-08 01:58:22,102 DEBUG TRAIN Batch 24/7000 loss 8.438024 loss_att 400.939819 loss_ctc 15.320265 loss_rnnt 7.673330 lr 0.00026154 rank 6
2022-12-08 01:58:22,103 DEBUG TRAIN Batch 24/7000 loss 9.745690 loss_att 359.101990 loss_ctc 22.161285 loss_rnnt 8.366179 lr 0.00026155 rank 1
2022-12-08 01:58:22,105 DEBUG TRAIN Batch 24/7000 loss 13.644151 loss_att 328.066742 loss_ctc 31.103760 loss_rnnt 11.704194 lr 0.00026154 rank 2
2022-12-08 01:58:22,108 DEBUG TRAIN Batch 24/7000 loss 8.229677 loss_att 297.543121 loss_ctc 17.562458 loss_rnnt 7.192702 lr 0.00026153 rank 5
2022-12-08 01:59:34,828 DEBUG TRAIN Batch 24/7100 loss 2.309005 loss_att 363.469208 loss_ctc 5.380632 loss_rnnt 1.967714 lr 0.00026150 rank 2
2022-12-08 01:59:34,832 DEBUG TRAIN Batch 24/7100 loss 10.547684 loss_att 430.427582 loss_ctc 18.684576 loss_rnnt 9.643584 lr 0.00026152 rank 3
2022-12-08 01:59:34,843 DEBUG TRAIN Batch 24/7100 loss 13.807043 loss_att 241.541779 loss_ctc 22.755493 loss_rnnt 12.812771 lr 0.00026152 rank 1
2022-12-08 01:59:34,848 DEBUG TRAIN Batch 24/7100 loss 8.685205 loss_att 437.815765 loss_ctc 15.013002 loss_rnnt 7.982118 lr 0.00026150 rank 4
2022-12-08 01:59:34,850 DEBUG TRAIN Batch 24/7100 loss 1.723113 loss_att 383.420105 loss_ctc 10.033921 loss_rnnt 0.799690 lr 0.00026149 rank 7
2022-12-08 01:59:34,862 DEBUG TRAIN Batch 24/7100 loss 8.947971 loss_att 341.765228 loss_ctc 16.111523 loss_rnnt 8.152021 lr 0.00026150 rank 6
2022-12-08 01:59:34,868 DEBUG TRAIN Batch 24/7100 loss 2.321795 loss_att 405.315674 loss_ctc 5.637967 loss_rnnt 1.953331 lr 0.00026149 rank 5
2022-12-08 01:59:34,877 DEBUG TRAIN Batch 24/7100 loss 4.364712 loss_att 315.965668 loss_ctc 10.306362 loss_rnnt 3.704529 lr 0.00026150 rank 0
2022-12-08 02:00:39,096 DEBUG TRAIN Batch 24/7200 loss 9.057705 loss_att 325.556793 loss_ctc 18.689795 loss_rnnt 7.987473 lr 0.00026145 rank 7
2022-12-08 02:00:39,097 DEBUG TRAIN Batch 24/7200 loss 3.736308 loss_att 408.091125 loss_ctc 7.987766 loss_rnnt 3.263924 lr 0.00026146 rank 2
2022-12-08 02:00:39,098 DEBUG TRAIN Batch 24/7200 loss 8.862881 loss_att 381.151062 loss_ctc 17.331768 loss_rnnt 7.921893 lr 0.00026148 rank 1
2022-12-08 02:00:39,102 DEBUG TRAIN Batch 24/7200 loss 10.607369 loss_att 405.009644 loss_ctc 18.117218 loss_rnnt 9.772942 lr 0.00026147 rank 4
2022-12-08 02:00:39,105 DEBUG TRAIN Batch 24/7200 loss 5.684027 loss_att 408.474121 loss_ctc 18.859299 loss_rnnt 4.220108 lr 0.00026146 rank 5
2022-12-08 02:00:39,106 DEBUG TRAIN Batch 24/7200 loss 4.435392 loss_att 347.165405 loss_ctc 6.599153 loss_rnnt 4.194974 lr 0.00026148 rank 3
2022-12-08 02:00:39,107 DEBUG TRAIN Batch 24/7200 loss 12.241017 loss_att 371.407898 loss_ctc 19.608946 loss_rnnt 11.422359 lr 0.00026147 rank 0
2022-12-08 02:00:39,109 DEBUG TRAIN Batch 24/7200 loss 1.029218 loss_att 407.707245 loss_ctc 3.485703 loss_rnnt 0.756276 lr 0.00026147 rank 6
2022-12-08 02:01:42,341 DEBUG TRAIN Batch 24/7300 loss 4.457356 loss_att 402.062927 loss_ctc 10.566094 loss_rnnt 3.778608 lr 0.00026142 rank 7
2022-12-08 02:01:42,356 DEBUG TRAIN Batch 24/7300 loss 8.976151 loss_att 405.056732 loss_ctc 21.396719 loss_rnnt 7.596087 lr 0.00026144 rank 3
2022-12-08 02:01:42,358 DEBUG TRAIN Batch 24/7300 loss 7.459788 loss_att 388.378662 loss_ctc 15.134169 loss_rnnt 6.607080 lr 0.00026143 rank 4
2022-12-08 02:01:42,358 DEBUG TRAIN Batch 24/7300 loss 3.735002 loss_att 352.040283 loss_ctc 11.266405 loss_rnnt 2.898180 lr 0.00026145 rank 1
2022-12-08 02:01:42,360 DEBUG TRAIN Batch 24/7300 loss 4.428391 loss_att 341.067078 loss_ctc 12.730616 loss_rnnt 3.505922 lr 0.00026143 rank 0
2022-12-08 02:01:42,361 DEBUG TRAIN Batch 24/7300 loss 7.565825 loss_att 401.495667 loss_ctc 23.016010 loss_rnnt 5.849137 lr 0.00026143 rank 6
2022-12-08 02:01:42,385 DEBUG TRAIN Batch 24/7300 loss 2.753678 loss_att 374.879150 loss_ctc 8.581318 loss_rnnt 2.106163 lr 0.00026143 rank 2
2022-12-08 02:01:42,403 DEBUG TRAIN Batch 24/7300 loss 1.438630 loss_att 419.037354 loss_ctc 6.560788 loss_rnnt 0.869501 lr 0.00026142 rank 5
2022-12-08 02:02:46,649 DEBUG TRAIN Batch 24/7400 loss 3.705447 loss_att 402.033875 loss_ctc 14.658497 loss_rnnt 2.488441 lr 0.00026139 rank 2
2022-12-08 02:02:46,653 DEBUG TRAIN Batch 24/7400 loss 5.006557 loss_att 339.580688 loss_ctc 9.934183 loss_rnnt 4.459044 lr 0.00026139 rank 5
2022-12-08 02:02:46,653 DEBUG TRAIN Batch 24/7400 loss 6.233150 loss_att 306.412842 loss_ctc 14.573762 loss_rnnt 5.306415 lr 0.00026139 rank 6
2022-12-08 02:02:46,657 DEBUG TRAIN Batch 24/7400 loss 8.268636 loss_att 363.284882 loss_ctc 22.965080 loss_rnnt 6.635697 lr 0.00026140 rank 4
2022-12-08 02:02:46,657 DEBUG TRAIN Batch 24/7400 loss 8.574856 loss_att 369.317505 loss_ctc 24.772829 loss_rnnt 6.775082 lr 0.00026138 rank 7
2022-12-08 02:02:46,659 DEBUG TRAIN Batch 24/7400 loss 2.122248 loss_att 396.101166 loss_ctc 5.833264 loss_rnnt 1.709913 lr 0.00026141 rank 1
2022-12-08 02:02:46,667 DEBUG TRAIN Batch 24/7400 loss 9.964371 loss_att 387.465454 loss_ctc 22.072062 loss_rnnt 8.619072 lr 0.00026141 rank 3
2022-12-08 02:02:46,684 DEBUG TRAIN Batch 24/7400 loss 7.032069 loss_att 398.429016 loss_ctc 24.813040 loss_rnnt 5.056406 lr 0.00026139 rank 0
2022-12-08 02:04:00,863 DEBUG TRAIN Batch 24/7500 loss 5.495003 loss_att 322.591125 loss_ctc 12.132713 loss_rnnt 4.757479 lr 0.00026136 rank 4
2022-12-08 02:04:00,877 DEBUG TRAIN Batch 24/7500 loss 6.443198 loss_att 314.113770 loss_ctc 15.101253 loss_rnnt 5.481193 lr 0.00026134 rank 7
2022-12-08 02:04:00,879 DEBUG TRAIN Batch 24/7500 loss 5.341516 loss_att 325.165375 loss_ctc 8.773327 loss_rnnt 4.960205 lr 0.00026136 rank 2
2022-12-08 02:04:00,880 DEBUG TRAIN Batch 24/7500 loss 3.987482 loss_att 285.173492 loss_ctc 7.578615 loss_rnnt 3.588467 lr 0.00026136 rank 6
2022-12-08 02:04:00,881 DEBUG TRAIN Batch 24/7500 loss 8.609952 loss_att 353.471069 loss_ctc 13.012208 loss_rnnt 8.120812 lr 0.00026137 rank 1
2022-12-08 02:04:00,884 DEBUG TRAIN Batch 24/7500 loss 4.418374 loss_att 345.525909 loss_ctc 9.459047 loss_rnnt 3.858299 lr 0.00026135 rank 5
2022-12-08 02:04:00,891 DEBUG TRAIN Batch 24/7500 loss 6.587295 loss_att 350.760803 loss_ctc 18.098743 loss_rnnt 5.308245 lr 0.00026136 rank 0
2022-12-08 02:04:00,921 DEBUG TRAIN Batch 24/7500 loss 5.592283 loss_att 271.210480 loss_ctc 8.640346 loss_rnnt 5.253610 lr 0.00026137 rank 3
2022-12-08 02:05:04,729 DEBUG TRAIN Batch 24/7600 loss 24.269499 loss_att 342.367004 loss_ctc 40.021816 loss_rnnt 22.519241 lr 0.00026132 rank 2
2022-12-08 02:05:04,730 DEBUG TRAIN Batch 24/7600 loss 7.234838 loss_att 398.026794 loss_ctc 17.107260 loss_rnnt 6.137902 lr 0.00026134 rank 1
2022-12-08 02:05:04,732 DEBUG TRAIN Batch 24/7600 loss 8.897434 loss_att 191.295090 loss_ctc 12.444844 loss_rnnt 8.503278 lr 0.00026131 rank 7
2022-12-08 02:05:04,732 DEBUG TRAIN Batch 24/7600 loss 4.869453 loss_att 136.712402 loss_ctc 7.883442 loss_rnnt 4.534566 lr 0.00026132 rank 4
2022-12-08 02:05:04,735 DEBUG TRAIN Batch 24/7600 loss 3.828648 loss_att 172.441315 loss_ctc 10.098670 loss_rnnt 3.131979 lr 0.00026132 rank 6
2022-12-08 02:05:04,735 DEBUG TRAIN Batch 24/7600 loss 4.724885 loss_att 263.851776 loss_ctc 16.127512 loss_rnnt 3.457927 lr 0.00026132 rank 0
2022-12-08 02:05:04,735 DEBUG TRAIN Batch 24/7600 loss 4.844593 loss_att 452.849792 loss_ctc 9.322474 loss_rnnt 4.347050 lr 0.00026134 rank 3
2022-12-08 02:05:04,736 DEBUG TRAIN Batch 24/7600 loss 3.856800 loss_att 265.087219 loss_ctc 9.228598 loss_rnnt 3.259933 lr 0.00026131 rank 5
2022-12-08 02:06:07,784 DEBUG TRAIN Batch 24/7700 loss 12.068469 loss_att 411.914886 loss_ctc 19.359272 loss_rnnt 11.258380 lr 0.00026127 rank 7
2022-12-08 02:06:07,785 DEBUG TRAIN Batch 24/7700 loss 4.017146 loss_att 417.978455 loss_ctc 16.859478 loss_rnnt 2.590221 lr 0.00026129 rank 4
2022-12-08 02:06:07,787 DEBUG TRAIN Batch 24/7700 loss 4.720457 loss_att 396.053650 loss_ctc 14.133494 loss_rnnt 3.674564 lr 0.00026129 rank 6
2022-12-08 02:06:07,790 DEBUG TRAIN Batch 24/7700 loss 3.054745 loss_att 322.759735 loss_ctc 11.537272 loss_rnnt 2.112242 lr 0.00026130 rank 1
2022-12-08 02:06:07,792 DEBUG TRAIN Batch 24/7700 loss 3.802638 loss_att 455.688538 loss_ctc 14.012714 loss_rnnt 2.668185 lr 0.00026129 rank 0
2022-12-08 02:06:07,792 DEBUG TRAIN Batch 24/7700 loss 4.950921 loss_att 411.020020 loss_ctc 17.268183 loss_rnnt 3.582336 lr 0.00026130 rank 3
2022-12-08 02:06:07,793 DEBUG TRAIN Batch 24/7700 loss 7.238449 loss_att 66.156357 loss_ctc 12.185966 loss_rnnt 6.688725 lr 0.00026128 rank 5
2022-12-08 02:06:07,833 DEBUG TRAIN Batch 24/7700 loss 7.899904 loss_att 309.057037 loss_ctc 15.224980 loss_rnnt 7.086007 lr 0.00026129 rank 2
2022-12-08 02:07:20,397 DEBUG TRAIN Batch 24/7800 loss 7.194882 loss_att 460.293457 loss_ctc 17.565731 loss_rnnt 6.042566 lr 0.00026125 rank 0
2022-12-08 02:07:20,406 DEBUG TRAIN Batch 24/7800 loss 6.194021 loss_att 435.173096 loss_ctc 11.477848 loss_rnnt 5.606929 lr 0.00026124 rank 7
2022-12-08 02:07:20,406 DEBUG TRAIN Batch 24/7800 loss 6.150959 loss_att 417.631531 loss_ctc 12.300743 loss_rnnt 5.467649 lr 0.00026125 rank 6
2022-12-08 02:07:20,412 DEBUG TRAIN Batch 24/7800 loss 5.431575 loss_att 120.358154 loss_ctc 9.766797 loss_rnnt 4.949884 lr 0.00026127 rank 1
2022-12-08 02:07:20,414 DEBUG TRAIN Batch 24/7800 loss 10.835060 loss_att 451.639008 loss_ctc 33.267914 loss_rnnt 8.342521 lr 0.00026126 rank 3
2022-12-08 02:07:20,424 DEBUG TRAIN Batch 24/7800 loss 6.720146 loss_att 384.445496 loss_ctc 13.123089 loss_rnnt 6.008708 lr 0.00026125 rank 4
2022-12-08 02:07:20,426 DEBUG TRAIN Batch 24/7800 loss 5.905681 loss_att 337.997681 loss_ctc 9.664210 loss_rnnt 5.488067 lr 0.00026124 rank 5
2022-12-08 02:07:20,426 DEBUG TRAIN Batch 24/7800 loss 5.813134 loss_att 447.708221 loss_ctc 11.417892 loss_rnnt 5.190384 lr 0.00026125 rank 2
2022-12-08 02:08:25,147 DEBUG TRAIN Batch 24/7900 loss 20.313263 loss_att 383.113831 loss_ctc 42.413937 loss_rnnt 17.857632 lr 0.00026122 rank 6
2022-12-08 02:08:25,147 DEBUG TRAIN Batch 24/7900 loss 5.025449 loss_att 376.030304 loss_ctc 15.591832 loss_rnnt 3.851407 lr 0.00026120 rank 7
2022-12-08 02:08:25,148 DEBUG TRAIN Batch 24/7900 loss 5.155612 loss_att 377.014526 loss_ctc 11.186963 loss_rnnt 4.485462 lr 0.00026123 rank 3
2022-12-08 02:08:25,152 DEBUG TRAIN Batch 24/7900 loss 12.095567 loss_att 332.270813 loss_ctc 18.953133 loss_rnnt 11.333615 lr 0.00026122 rank 4
2022-12-08 02:08:25,153 DEBUG TRAIN Batch 24/7900 loss 6.649837 loss_att 375.066162 loss_ctc 17.286558 loss_rnnt 5.467979 lr 0.00026123 rank 1
2022-12-08 02:08:25,153 DEBUG TRAIN Batch 24/7900 loss 2.950994 loss_att 397.979950 loss_ctc 11.915564 loss_rnnt 1.954930 lr 0.00026122 rank 0
2022-12-08 02:08:25,154 DEBUG TRAIN Batch 24/7900 loss 9.271014 loss_att 469.428802 loss_ctc 14.991710 loss_rnnt 8.635382 lr 0.00026122 rank 2
2022-12-08 02:08:25,199 DEBUG TRAIN Batch 24/7900 loss 14.555114 loss_att 350.553650 loss_ctc 16.605087 loss_rnnt 14.327339 lr 0.00026121 rank 5
2022-12-08 02:09:28,555 DEBUG TRAIN Batch 24/8000 loss 8.506164 loss_att 376.160431 loss_ctc 16.772108 loss_rnnt 7.587726 lr 0.00026118 rank 4
2022-12-08 02:09:28,556 DEBUG TRAIN Batch 24/8000 loss 11.863361 loss_att 383.121552 loss_ctc 26.772285 loss_rnnt 10.206814 lr 0.00026117 rank 7
2022-12-08 02:09:28,561 DEBUG TRAIN Batch 24/8000 loss 11.510848 loss_att 414.033905 loss_ctc 33.543640 loss_rnnt 9.062759 lr 0.00026118 rank 2
2022-12-08 02:09:28,563 DEBUG TRAIN Batch 24/8000 loss 7.835641 loss_att 360.330048 loss_ctc 19.338005 loss_rnnt 6.557601 lr 0.00026120 rank 1
2022-12-08 02:09:28,563 DEBUG TRAIN Batch 24/8000 loss 7.946522 loss_att 383.189484 loss_ctc 11.937204 loss_rnnt 7.503113 lr 0.00026118 rank 0
2022-12-08 02:09:28,564 DEBUG TRAIN Batch 24/8000 loss 8.252370 loss_att 323.331451 loss_ctc 12.550151 loss_rnnt 7.774839 lr 0.00026118 rank 6
2022-12-08 02:09:28,565 DEBUG TRAIN Batch 24/8000 loss 4.527426 loss_att 371.094635 loss_ctc 11.876043 loss_rnnt 3.710913 lr 0.00026119 rank 3
2022-12-08 02:09:28,606 DEBUG TRAIN Batch 24/8000 loss 4.834656 loss_att 394.253113 loss_ctc 11.211447 loss_rnnt 4.126123 lr 0.00026117 rank 5
2022-12-08 02:10:32,890 DEBUG TRAIN Batch 24/8100 loss 19.499790 loss_att 352.892700 loss_ctc 29.048372 loss_rnnt 18.438837 lr 0.00026114 rank 6
2022-12-08 02:10:32,890 DEBUG TRAIN Batch 24/8100 loss 8.609436 loss_att 349.767944 loss_ctc 13.471368 loss_rnnt 8.069221 lr 0.00026115 rank 4
2022-12-08 02:10:32,891 DEBUG TRAIN Batch 24/8100 loss 14.659784 loss_att 377.523865 loss_ctc 30.179615 loss_rnnt 12.935359 lr 0.00026113 rank 7
2022-12-08 02:10:32,893 DEBUG TRAIN Batch 24/8100 loss 10.098817 loss_att 310.928131 loss_ctc 16.041311 loss_rnnt 9.438540 lr 0.00026116 rank 3
2022-12-08 02:10:32,894 DEBUG TRAIN Batch 24/8100 loss 5.618354 loss_att 373.622192 loss_ctc 13.530416 loss_rnnt 4.739236 lr 0.00026114 rank 5
2022-12-08 02:10:32,894 DEBUG TRAIN Batch 24/8100 loss 11.671795 loss_att 414.603851 loss_ctc 20.832886 loss_rnnt 10.653896 lr 0.00026114 rank 2
2022-12-08 02:10:32,900 DEBUG TRAIN Batch 24/8100 loss 16.560503 loss_att 381.566345 loss_ctc 27.970621 loss_rnnt 15.292711 lr 0.00026114 rank 0
2022-12-08 02:10:32,912 DEBUG TRAIN Batch 24/8100 loss 5.391625 loss_att 384.438232 loss_ctc 14.379802 loss_rnnt 4.392939 lr 0.00026116 rank 1
2022-12-08 02:11:37,415 DEBUG TRAIN Batch 24/8200 loss 3.955790 loss_att 233.919113 loss_ctc 6.514101 loss_rnnt 3.671533 lr 0.00026111 rank 6
2022-12-08 02:11:37,415 DEBUG TRAIN Batch 24/8200 loss 3.292508 loss_att 305.227997 loss_ctc 6.175784 loss_rnnt 2.972144 lr 0.00026111 rank 2
2022-12-08 02:11:37,416 DEBUG TRAIN Batch 24/8200 loss 7.679566 loss_att 265.764740 loss_ctc 17.343542 loss_rnnt 6.605792 lr 0.00026110 rank 7
2022-12-08 02:11:37,416 DEBUG TRAIN Batch 24/8200 loss 7.627891 loss_att 111.662865 loss_ctc 15.169070 loss_rnnt 6.789982 lr 0.00026111 rank 4
2022-12-08 02:11:37,417 DEBUG TRAIN Batch 24/8200 loss 4.849474 loss_att 481.517761 loss_ctc 16.730762 loss_rnnt 3.529331 lr 0.00026112 rank 3
2022-12-08 02:11:37,417 DEBUG TRAIN Batch 24/8200 loss 10.385760 loss_att 416.287628 loss_ctc 22.138859 loss_rnnt 9.079861 lr 0.00026112 rank 1
2022-12-08 02:11:37,422 DEBUG TRAIN Batch 24/8200 loss 4.154872 loss_att 317.815186 loss_ctc 9.121561 loss_rnnt 3.603018 lr 0.00026111 rank 0
2022-12-08 02:11:37,462 DEBUG TRAIN Batch 24/8200 loss 9.250747 loss_att 328.825684 loss_ctc 19.420563 loss_rnnt 8.120768 lr 0.00026110 rank 5
2022-12-08 02:12:40,884 DEBUG TRAIN Batch 24/8300 loss 5.235160 loss_att 398.826721 loss_ctc 8.361746 loss_rnnt 4.887762 lr 0.00026107 rank 2
2022-12-08 02:12:40,901 DEBUG TRAIN Batch 24/8300 loss 10.285773 loss_att 468.313568 loss_ctc 28.619579 loss_rnnt 8.248684 lr 0.00026108 rank 4
2022-12-08 02:12:40,904 DEBUG TRAIN Batch 24/8300 loss 9.293827 loss_att 415.042358 loss_ctc 16.297808 loss_rnnt 8.515608 lr 0.00026109 rank 3
2022-12-08 02:12:40,906 DEBUG TRAIN Batch 24/8300 loss 5.609635 loss_att 414.675049 loss_ctc 15.112726 loss_rnnt 4.553736 lr 0.00026106 rank 7
2022-12-08 02:12:40,910 DEBUG TRAIN Batch 24/8300 loss 5.268770 loss_att 316.773773 loss_ctc 12.585406 loss_rnnt 4.455811 lr 0.00026107 rank 0
2022-12-08 02:12:40,911 DEBUG TRAIN Batch 24/8300 loss 4.964087 loss_att 375.179199 loss_ctc 8.226774 loss_rnnt 4.601565 lr 0.00026107 rank 6
2022-12-08 02:12:40,911 DEBUG TRAIN Batch 24/8300 loss 11.902289 loss_att 276.341553 loss_ctc 23.472334 loss_rnnt 10.616729 lr 0.00026107 rank 5
2022-12-08 02:13:26,734 DEBUG CV Batch 24/0 loss 1.380718 loss_att 48.086578 loss_ctc 3.220507 loss_rnnt 1.176298 history loss 1.329581 rank 1
2022-12-08 02:13:26,739 DEBUG CV Batch 24/0 loss 1.380718 loss_att 48.086578 loss_ctc 3.220507 loss_rnnt 1.176298 history loss 1.329581 rank 2
2022-12-08 02:13:26,742 DEBUG CV Batch 24/0 loss 1.380718 loss_att 48.086578 loss_ctc 3.220507 loss_rnnt 1.176298 history loss 1.329581 rank 4
2022-12-08 02:13:26,744 DEBUG CV Batch 24/0 loss 1.380718 loss_att 48.086578 loss_ctc 3.220507 loss_rnnt 1.176298 history loss 1.329581 rank 3
2022-12-08 02:13:26,745 DEBUG CV Batch 24/0 loss 1.380718 loss_att 48.086578 loss_ctc 3.220507 loss_rnnt 1.176298 history loss 1.329581 rank 6
2022-12-08 02:13:26,748 DEBUG CV Batch 24/0 loss 1.380718 loss_att 48.086578 loss_ctc 3.220507 loss_rnnt 1.176298 history loss 1.329581 rank 0
2022-12-08 02:13:26,751 DEBUG CV Batch 24/0 loss 1.380718 loss_att 48.086578 loss_ctc 3.220507 loss_rnnt 1.176298 history loss 1.329581 rank 7
2022-12-08 02:13:26,753 DEBUG CV Batch 24/0 loss 1.380718 loss_att 48.086578 loss_ctc 3.220507 loss_rnnt 1.176298 history loss 1.329581 rank 5
2022-12-08 02:13:37,422 DEBUG CV Batch 24/100 loss 4.712744 loss_att 266.945282 loss_ctc 12.776211 loss_rnnt 3.816803 history loss 3.044829 rank 6
2022-12-08 02:13:37,471 DEBUG CV Batch 24/100 loss 4.712744 loss_att 266.945282 loss_ctc 12.776211 loss_rnnt 3.816803 history loss 3.044829 rank 4
2022-12-08 02:13:37,490 DEBUG CV Batch 24/100 loss 4.712744 loss_att 266.945282 loss_ctc 12.776211 loss_rnnt 3.816803 history loss 3.044829 rank 7
2022-12-08 02:13:37,600 DEBUG CV Batch 24/100 loss 4.712744 loss_att 266.945282 loss_ctc 12.776211 loss_rnnt 3.816803 history loss 3.044829 rank 2
2022-12-08 02:13:37,659 DEBUG CV Batch 24/100 loss 4.712744 loss_att 266.945282 loss_ctc 12.776211 loss_rnnt 3.816803 history loss 3.044829 rank 0
2022-12-08 02:13:37,702 DEBUG CV Batch 24/100 loss 4.712744 loss_att 266.945282 loss_ctc 12.776211 loss_rnnt 3.816803 history loss 3.044829 rank 5
2022-12-08 02:13:37,940 DEBUG CV Batch 24/100 loss 4.712744 loss_att 266.945282 loss_ctc 12.776211 loss_rnnt 3.816803 history loss 3.044829 rank 1
2022-12-08 02:13:38,053 DEBUG CV Batch 24/100 loss 4.712744 loss_att 266.945282 loss_ctc 12.776211 loss_rnnt 3.816803 history loss 3.044829 rank 3
2022-12-08 02:13:50,876 DEBUG CV Batch 24/200 loss 6.852855 loss_att 641.184692 loss_ctc 6.653431 loss_rnnt 6.875013 history loss 3.547229 rank 7
2022-12-08 02:13:50,896 DEBUG CV Batch 24/200 loss 6.852855 loss_att 641.184692 loss_ctc 6.653431 loss_rnnt 6.875013 history loss 3.547229 rank 4
2022-12-08 02:13:51,069 DEBUG CV Batch 24/200 loss 6.852855 loss_att 641.184692 loss_ctc 6.653431 loss_rnnt 6.875013 history loss 3.547229 rank 6
2022-12-08 02:13:51,083 DEBUG CV Batch 24/200 loss 6.852855 loss_att 641.184692 loss_ctc 6.653431 loss_rnnt 6.875013 history loss 3.547229 rank 0
2022-12-08 02:13:51,291 DEBUG CV Batch 24/200 loss 6.852855 loss_att 641.184692 loss_ctc 6.653431 loss_rnnt 6.875013 history loss 3.547229 rank 2
2022-12-08 02:13:51,342 DEBUG CV Batch 24/200 loss 6.852855 loss_att 641.184692 loss_ctc 6.653431 loss_rnnt 6.875013 history loss 3.547229 rank 5
2022-12-08 02:13:51,581 DEBUG CV Batch 24/200 loss 6.852855 loss_att 641.184692 loss_ctc 6.653431 loss_rnnt 6.875013 history loss 3.547229 rank 3
2022-12-08 02:13:51,702 DEBUG CV Batch 24/200 loss 6.852855 loss_att 641.184692 loss_ctc 6.653431 loss_rnnt 6.875013 history loss 3.547229 rank 1
2022-12-08 02:14:02,358 DEBUG CV Batch 24/300 loss 3.972352 loss_att 190.888260 loss_ctc 7.415055 loss_rnnt 3.589830 history loss 3.613767 rank 6
2022-12-08 02:14:02,384 DEBUG CV Batch 24/300 loss 3.972352 loss_att 190.888260 loss_ctc 7.415055 loss_rnnt 3.589830 history loss 3.613767 rank 7
2022-12-08 02:14:02,437 DEBUG CV Batch 24/300 loss 3.972352 loss_att 190.888260 loss_ctc 7.415055 loss_rnnt 3.589830 history loss 3.613767 rank 4
2022-12-08 02:14:02,633 DEBUG CV Batch 24/300 loss 3.972352 loss_att 190.888260 loss_ctc 7.415055 loss_rnnt 3.589830 history loss 3.613767 rank 2
2022-12-08 02:14:02,709 DEBUG CV Batch 24/300 loss 3.972352 loss_att 190.888260 loss_ctc 7.415055 loss_rnnt 3.589830 history loss 3.613767 rank 5
2022-12-08 02:14:02,739 DEBUG CV Batch 24/300 loss 3.972352 loss_att 190.888260 loss_ctc 7.415055 loss_rnnt 3.589830 history loss 3.613767 rank 0
2022-12-08 02:14:02,883 DEBUG CV Batch 24/300 loss 3.972352 loss_att 190.888260 loss_ctc 7.415055 loss_rnnt 3.589830 history loss 3.613767 rank 3
2022-12-08 02:14:03,277 DEBUG CV Batch 24/300 loss 3.972352 loss_att 190.888260 loss_ctc 7.415055 loss_rnnt 3.589830 history loss 3.613767 rank 1
2022-12-08 02:14:13,583 DEBUG CV Batch 24/400 loss 6.793776 loss_att 826.191467 loss_ctc 16.546406 loss_rnnt 5.710150 history loss 4.408399 rank 6
2022-12-08 02:14:13,834 DEBUG CV Batch 24/400 loss 6.793776 loss_att 826.191467 loss_ctc 16.546406 loss_rnnt 5.710150 history loss 4.408399 rank 4
2022-12-08 02:14:13,862 DEBUG CV Batch 24/400 loss 6.793776 loss_att 826.191467 loss_ctc 16.546406 loss_rnnt 5.710150 history loss 4.408399 rank 7
2022-12-08 02:14:14,012 DEBUG CV Batch 24/400 loss 6.793776 loss_att 826.191467 loss_ctc 16.546406 loss_rnnt 5.710150 history loss 4.408399 rank 5
2022-12-08 02:14:14,159 DEBUG CV Batch 24/400 loss 6.793776 loss_att 826.191467 loss_ctc 16.546406 loss_rnnt 5.710150 history loss 4.408399 rank 3
2022-12-08 02:14:14,370 DEBUG CV Batch 24/400 loss 6.793776 loss_att 826.191467 loss_ctc 16.546406 loss_rnnt 5.710150 history loss 4.408399 rank 0
2022-12-08 02:14:14,524 DEBUG CV Batch 24/400 loss 6.793776 loss_att 826.191467 loss_ctc 16.546406 loss_rnnt 5.710150 history loss 4.408399 rank 2
2022-12-08 02:14:14,571 DEBUG CV Batch 24/400 loss 6.793776 loss_att 826.191467 loss_ctc 16.546406 loss_rnnt 5.710150 history loss 4.408399 rank 1
2022-12-08 02:14:23,806 DEBUG CV Batch 24/500 loss 4.046050 loss_att 266.656586 loss_ctc 7.226422 loss_rnnt 3.692675 history loss 5.047082 rank 4
2022-12-08 02:14:23,825 DEBUG CV Batch 24/500 loss 4.046050 loss_att 266.656586 loss_ctc 7.226422 loss_rnnt 3.692675 history loss 5.047082 rank 5
2022-12-08 02:14:23,869 DEBUG CV Batch 24/500 loss 4.046050 loss_att 266.656586 loss_ctc 7.226422 loss_rnnt 3.692675 history loss 5.047082 rank 7
2022-12-08 02:14:23,875 DEBUG CV Batch 24/500 loss 4.046050 loss_att 266.656586 loss_ctc 7.226422 loss_rnnt 3.692675 history loss 5.047082 rank 6
2022-12-08 02:14:24,099 DEBUG CV Batch 24/500 loss 4.046050 loss_att 266.656586 loss_ctc 7.226422 loss_rnnt 3.692675 history loss 5.047082 rank 3
2022-12-08 02:14:24,514 DEBUG CV Batch 24/500 loss 4.046050 loss_att 266.656586 loss_ctc 7.226422 loss_rnnt 3.692675 history loss 5.047082 rank 2
2022-12-08 02:14:24,519 DEBUG CV Batch 24/500 loss 4.046050 loss_att 266.656586 loss_ctc 7.226422 loss_rnnt 3.692675 history loss 5.047082 rank 1
2022-12-08 02:14:24,551 DEBUG CV Batch 24/500 loss 4.046050 loss_att 266.656586 loss_ctc 7.226422 loss_rnnt 3.692675 history loss 5.047082 rank 0
2022-12-08 02:14:35,377 DEBUG CV Batch 24/600 loss 5.188201 loss_att 104.308113 loss_ctc 8.493876 loss_rnnt 4.820904 history loss 5.911829 rank 4
2022-12-08 02:14:35,445 DEBUG CV Batch 24/600 loss 5.188201 loss_att 104.308113 loss_ctc 8.493876 loss_rnnt 4.820904 history loss 5.911829 rank 7
2022-12-08 02:14:35,563 DEBUG CV Batch 24/600 loss 5.188201 loss_att 104.308113 loss_ctc 8.493876 loss_rnnt 4.820904 history loss 5.911829 rank 6
2022-12-08 02:14:35,895 DEBUG CV Batch 24/600 loss 5.188201 loss_att 104.308113 loss_ctc 8.493876 loss_rnnt 4.820904 history loss 5.911829 rank 5
2022-12-08 02:14:36,279 DEBUG CV Batch 24/600 loss 5.188201 loss_att 104.308113 loss_ctc 8.493876 loss_rnnt 4.820904 history loss 5.911829 rank 0
2022-12-08 02:14:36,867 DEBUG CV Batch 24/600 loss 5.188201 loss_att 104.308113 loss_ctc 8.493876 loss_rnnt 4.820904 history loss 5.911829 rank 3
2022-12-08 02:14:36,948 DEBUG CV Batch 24/600 loss 5.188201 loss_att 104.308113 loss_ctc 8.493876 loss_rnnt 4.820904 history loss 5.911829 rank 1
2022-12-08 02:14:37,058 DEBUG CV Batch 24/600 loss 5.188201 loss_att 104.308113 loss_ctc 8.493876 loss_rnnt 4.820904 history loss 5.911829 rank 2
2022-12-08 02:14:46,870 DEBUG CV Batch 24/700 loss 8.115171 loss_att 707.032837 loss_ctc 19.082270 loss_rnnt 6.896605 history loss 6.453018 rank 4
2022-12-08 02:14:46,903 DEBUG CV Batch 24/700 loss 8.115171 loss_att 707.032837 loss_ctc 19.082270 loss_rnnt 6.896605 history loss 6.453018 rank 7
2022-12-08 02:14:47,199 DEBUG CV Batch 24/700 loss 8.115171 loss_att 707.032837 loss_ctc 19.082270 loss_rnnt 6.896605 history loss 6.453018 rank 0
2022-12-08 02:14:47,394 DEBUG CV Batch 24/700 loss 8.115171 loss_att 707.032837 loss_ctc 19.082270 loss_rnnt 6.896605 history loss 6.453018 rank 6
2022-12-08 02:14:47,603 DEBUG CV Batch 24/700 loss 8.115171 loss_att 707.032837 loss_ctc 19.082270 loss_rnnt 6.896605 history loss 6.453018 rank 5
2022-12-08 02:14:48,980 DEBUG CV Batch 24/700 loss 8.115171 loss_att 707.032837 loss_ctc 19.082270 loss_rnnt 6.896605 history loss 6.453018 rank 3
2022-12-08 02:14:49,160 DEBUG CV Batch 24/700 loss 8.115171 loss_att 707.032837 loss_ctc 19.082270 loss_rnnt 6.896605 history loss 6.453018 rank 2
2022-12-08 02:14:49,272 DEBUG CV Batch 24/700 loss 8.115171 loss_att 707.032837 loss_ctc 19.082270 loss_rnnt 6.896605 history loss 6.453018 rank 1
2022-12-08 02:14:58,191 DEBUG CV Batch 24/800 loss 8.268560 loss_att 263.403503 loss_ctc 18.751823 loss_rnnt 7.103753 history loss 6.000031 rank 4
2022-12-08 02:14:58,262 DEBUG CV Batch 24/800 loss 8.268560 loss_att 263.403503 loss_ctc 18.751823 loss_rnnt 7.103753 history loss 6.000031 rank 7
2022-12-08 02:14:58,623 DEBUG CV Batch 24/800 loss 8.268560 loss_att 263.403503 loss_ctc 18.751823 loss_rnnt 7.103753 history loss 6.000031 rank 0
2022-12-08 02:14:59,127 DEBUG CV Batch 24/800 loss 8.268560 loss_att 263.403503 loss_ctc 18.751823 loss_rnnt 7.103753 history loss 6.000031 rank 6
2022-12-08 02:14:59,525 DEBUG CV Batch 24/800 loss 8.268560 loss_att 263.403503 loss_ctc 18.751823 loss_rnnt 7.103753 history loss 6.000031 rank 5
2022-12-08 02:15:00,986 DEBUG CV Batch 24/800 loss 8.268560 loss_att 263.403503 loss_ctc 18.751823 loss_rnnt 7.103753 history loss 6.000031 rank 3
2022-12-08 02:15:01,269 DEBUG CV Batch 24/800 loss 8.268560 loss_att 263.403503 loss_ctc 18.751823 loss_rnnt 7.103753 history loss 6.000031 rank 2
2022-12-08 02:15:01,338 DEBUG CV Batch 24/800 loss 8.268560 loss_att 263.403503 loss_ctc 18.751823 loss_rnnt 7.103753 history loss 6.000031 rank 1
2022-12-08 02:15:11,455 DEBUG CV Batch 24/900 loss 9.315508 loss_att 550.843018 loss_ctc 17.883535 loss_rnnt 8.363505 history loss 5.831872 rank 4
2022-12-08 02:15:11,607 DEBUG CV Batch 24/900 loss 9.315508 loss_att 550.843018 loss_ctc 17.883535 loss_rnnt 8.363505 history loss 5.831872 rank 7
2022-12-08 02:15:11,797 DEBUG CV Batch 24/900 loss 9.315508 loss_att 550.843018 loss_ctc 17.883535 loss_rnnt 8.363505 history loss 5.831872 rank 0
2022-12-08 02:15:12,508 DEBUG CV Batch 24/900 loss 9.315508 loss_att 550.843018 loss_ctc 17.883535 loss_rnnt 8.363505 history loss 5.831872 rank 6
2022-12-08 02:15:12,708 DEBUG CV Batch 24/900 loss 9.315508 loss_att 550.843018 loss_ctc 17.883535 loss_rnnt 8.363505 history loss 5.831872 rank 5
2022-12-08 02:15:14,462 DEBUG CV Batch 24/900 loss 9.315508 loss_att 550.843018 loss_ctc 17.883535 loss_rnnt 8.363505 history loss 5.831872 rank 3
2022-12-08 02:15:14,715 DEBUG CV Batch 24/900 loss 9.315508 loss_att 550.843018 loss_ctc 17.883535 loss_rnnt 8.363505 history loss 5.831872 rank 2
2022-12-08 02:15:14,746 DEBUG CV Batch 24/900 loss 9.315508 loss_att 550.843018 loss_ctc 17.883535 loss_rnnt 8.363505 history loss 5.831872 rank 1
2022-12-08 02:15:23,158 DEBUG CV Batch 24/1000 loss 2.231833 loss_att 176.486481 loss_ctc 4.124932 loss_rnnt 2.021489 history loss 5.619963 rank 4
2022-12-08 02:15:23,335 DEBUG CV Batch 24/1000 loss 2.231833 loss_att 176.486481 loss_ctc 4.124932 loss_rnnt 2.021489 history loss 5.619963 rank 7
2022-12-08 02:15:23,576 DEBUG CV Batch 24/1000 loss 2.231833 loss_att 176.486481 loss_ctc 4.124932 loss_rnnt 2.021489 history loss 5.619963 rank 0
2022-12-08 02:15:24,182 DEBUG CV Batch 24/1000 loss 2.231833 loss_att 176.486481 loss_ctc 4.124932 loss_rnnt 2.021489 history loss 5.619963 rank 5
2022-12-08 02:15:24,242 DEBUG CV Batch 24/1000 loss 2.231833 loss_att 176.486481 loss_ctc 4.124932 loss_rnnt 2.021489 history loss 5.619963 rank 6
2022-12-08 02:15:26,106 DEBUG CV Batch 24/1000 loss 2.231833 loss_att 176.486481 loss_ctc 4.124932 loss_rnnt 2.021489 history loss 5.619963 rank 3
2022-12-08 02:15:26,255 DEBUG CV Batch 24/1000 loss 2.231833 loss_att 176.486481 loss_ctc 4.124932 loss_rnnt 2.021489 history loss 5.619963 rank 2
2022-12-08 02:15:26,308 DEBUG CV Batch 24/1000 loss 2.231833 loss_att 176.486481 loss_ctc 4.124932 loss_rnnt 2.021489 history loss 5.619963 rank 1
2022-12-08 02:15:34,483 DEBUG CV Batch 24/1100 loss 4.344810 loss_att 60.695389 loss_ctc 7.952199 loss_rnnt 3.943990 history loss 5.592377 rank 4
2022-12-08 02:15:34,804 DEBUG CV Batch 24/1100 loss 4.344810 loss_att 60.695389 loss_ctc 7.952199 loss_rnnt 3.943990 history loss 5.592377 rank 7
2022-12-08 02:15:35,140 DEBUG CV Batch 24/1100 loss 4.344810 loss_att 60.695389 loss_ctc 7.952199 loss_rnnt 3.943990 history loss 5.592377 rank 0
2022-12-08 02:15:35,369 DEBUG CV Batch 24/1100 loss 4.344810 loss_att 60.695389 loss_ctc 7.952199 loss_rnnt 3.943990 history loss 5.592377 rank 5
2022-12-08 02:15:35,788 DEBUG CV Batch 24/1100 loss 4.344810 loss_att 60.695389 loss_ctc 7.952199 loss_rnnt 3.943990 history loss 5.592377 rank 6
2022-12-08 02:15:37,416 DEBUG CV Batch 24/1100 loss 4.344810 loss_att 60.695389 loss_ctc 7.952199 loss_rnnt 3.943990 history loss 5.592377 rank 3
2022-12-08 02:15:37,565 DEBUG CV Batch 24/1100 loss 4.344810 loss_att 60.695389 loss_ctc 7.952199 loss_rnnt 3.943990 history loss 5.592377 rank 1
2022-12-08 02:15:37,796 DEBUG CV Batch 24/1100 loss 4.344810 loss_att 60.695389 loss_ctc 7.952199 loss_rnnt 3.943990 history loss 5.592377 rank 2
2022-12-08 02:15:44,332 DEBUG CV Batch 24/1200 loss 6.724014 loss_att 280.458405 loss_ctc 8.201945 loss_rnnt 6.559799 history loss 5.865308 rank 4
2022-12-08 02:15:44,791 DEBUG CV Batch 24/1200 loss 6.724014 loss_att 280.458405 loss_ctc 8.201945 loss_rnnt 6.559799 history loss 5.865308 rank 7
2022-12-08 02:15:45,221 DEBUG CV Batch 24/1200 loss 6.724014 loss_att 280.458405 loss_ctc 8.201945 loss_rnnt 6.559799 history loss 5.865308 rank 0
2022-12-08 02:15:45,551 DEBUG CV Batch 24/1200 loss 6.724014 loss_att 280.458405 loss_ctc 8.201945 loss_rnnt 6.559799 history loss 5.865308 rank 5
2022-12-08 02:15:45,721 DEBUG CV Batch 24/1200 loss 6.724014 loss_att 280.458405 loss_ctc 8.201945 loss_rnnt 6.559799 history loss 5.865308 rank 6
2022-12-08 02:15:47,831 DEBUG CV Batch 24/1200 loss 6.724014 loss_att 280.458405 loss_ctc 8.201945 loss_rnnt 6.559799 history loss 5.865308 rank 3
2022-12-08 02:15:48,190 DEBUG CV Batch 24/1200 loss 6.724014 loss_att 280.458405 loss_ctc 8.201945 loss_rnnt 6.559799 history loss 5.865308 rank 1
2022-12-08 02:15:48,471 DEBUG CV Batch 24/1200 loss 6.724014 loss_att 280.458405 loss_ctc 8.201945 loss_rnnt 6.559799 history loss 5.865308 rank 2
2022-12-08 02:15:55,774 DEBUG CV Batch 24/1300 loss 4.447290 loss_att 105.976547 loss_ctc 7.457578 loss_rnnt 4.112814 history loss 6.154380 rank 4
2022-12-08 02:15:56,386 DEBUG CV Batch 24/1300 loss 4.447290 loss_att 105.976547 loss_ctc 7.457578 loss_rnnt 4.112814 history loss 6.154380 rank 7
2022-12-08 02:15:56,720 DEBUG CV Batch 24/1300 loss 4.447290 loss_att 105.976547 loss_ctc 7.457578 loss_rnnt 4.112814 history loss 6.154380 rank 0
2022-12-08 02:15:57,149 DEBUG CV Batch 24/1300 loss 4.447290 loss_att 105.976547 loss_ctc 7.457578 loss_rnnt 4.112814 history loss 6.154380 rank 6
2022-12-08 02:15:57,247 DEBUG CV Batch 24/1300 loss 4.447290 loss_att 105.976547 loss_ctc 7.457578 loss_rnnt 4.112814 history loss 6.154380 rank 5
2022-12-08 02:15:59,846 DEBUG CV Batch 24/1300 loss 4.447290 loss_att 105.976547 loss_ctc 7.457578 loss_rnnt 4.112814 history loss 6.154380 rank 3
2022-12-08 02:16:00,259 DEBUG CV Batch 24/1300 loss 4.447290 loss_att 105.976547 loss_ctc 7.457578 loss_rnnt 4.112814 history loss 6.154380 rank 1
2022-12-08 02:16:00,402 DEBUG CV Batch 24/1300 loss 4.447290 loss_att 105.976547 loss_ctc 7.457578 loss_rnnt 4.112814 history loss 6.154380 rank 2
2022-12-08 02:16:06,847 DEBUG CV Batch 24/1400 loss 2.500042 loss_att 562.090210 loss_ctc 4.546349 loss_rnnt 2.272675 history loss 6.423304 rank 4
2022-12-08 02:16:07,113 DEBUG CV Batch 24/1400 loss 2.500042 loss_att 562.090210 loss_ctc 4.546349 loss_rnnt 2.272675 history loss 6.423304 rank 7
2022-12-08 02:16:07,508 DEBUG CV Batch 24/1400 loss 2.500042 loss_att 562.090210 loss_ctc 4.546349 loss_rnnt 2.272675 history loss 6.423304 rank 0
2022-12-08 02:16:08,981 DEBUG CV Batch 24/1400 loss 2.500042 loss_att 562.090210 loss_ctc 4.546349 loss_rnnt 2.272675 history loss 6.423304 rank 6
2022-12-08 02:16:09,296 DEBUG CV Batch 24/1400 loss 2.500042 loss_att 562.090210 loss_ctc 4.546349 loss_rnnt 2.272675 history loss 6.423304 rank 5
2022-12-08 02:16:12,532 DEBUG CV Batch 24/1400 loss 2.500042 loss_att 562.090210 loss_ctc 4.546349 loss_rnnt 2.272675 history loss 6.423304 rank 1
2022-12-08 02:16:12,705 DEBUG CV Batch 24/1400 loss 2.500042 loss_att 562.090210 loss_ctc 4.546349 loss_rnnt 2.272675 history loss 6.423304 rank 3
2022-12-08 02:16:12,783 DEBUG CV Batch 24/1400 loss 2.500042 loss_att 562.090210 loss_ctc 4.546349 loss_rnnt 2.272675 history loss 6.423304 rank 2
2022-12-08 02:16:18,792 DEBUG CV Batch 24/1500 loss 7.453000 loss_att 275.487915 loss_ctc 7.254558 loss_rnnt 7.475049 history loss 6.314683 rank 0
2022-12-08 02:16:18,861 DEBUG CV Batch 24/1500 loss 7.453000 loss_att 275.487915 loss_ctc 7.254558 loss_rnnt 7.475049 history loss 6.314683 rank 4
2022-12-08 02:16:19,227 DEBUG CV Batch 24/1500 loss 7.453000 loss_att 275.487915 loss_ctc 7.254558 loss_rnnt 7.475049 history loss 6.314683 rank 7
2022-12-08 02:16:21,158 DEBUG CV Batch 24/1500 loss 7.453000 loss_att 275.487915 loss_ctc 7.254558 loss_rnnt 7.475049 history loss 6.314683 rank 6
2022-12-08 02:16:21,562 DEBUG CV Batch 24/1500 loss 7.453000 loss_att 275.487915 loss_ctc 7.254558 loss_rnnt 7.475049 history loss 6.314683 rank 5
2022-12-08 02:16:25,178 DEBUG CV Batch 24/1500 loss 7.453000 loss_att 275.487915 loss_ctc 7.254558 loss_rnnt 7.475049 history loss 6.314683 rank 1
2022-12-08 02:16:25,207 DEBUG CV Batch 24/1500 loss 7.453000 loss_att 275.487915 loss_ctc 7.254558 loss_rnnt 7.475049 history loss 6.314683 rank 2
2022-12-08 02:16:25,247 DEBUG CV Batch 24/1500 loss 7.453000 loss_att 275.487915 loss_ctc 7.254558 loss_rnnt 7.475049 history loss 6.314683 rank 3
2022-12-08 02:16:31,961 DEBUG CV Batch 24/1600 loss 7.792079 loss_att 593.915405 loss_ctc 14.888900 loss_rnnt 7.003543 history loss 6.282376 rank 0
2022-12-08 02:16:31,970 DEBUG CV Batch 24/1600 loss 7.792079 loss_att 593.915405 loss_ctc 14.888900 loss_rnnt 7.003543 history loss 6.282376 rank 4
2022-12-08 02:16:32,468 DEBUG CV Batch 24/1600 loss 7.792079 loss_att 593.915405 loss_ctc 14.888900 loss_rnnt 7.003543 history loss 6.282376 rank 7
2022-12-08 02:16:34,586 DEBUG CV Batch 24/1600 loss 7.792079 loss_att 593.915405 loss_ctc 14.888900 loss_rnnt 7.003543 history loss 6.282376 rank 6
2022-12-08 02:16:34,796 DEBUG CV Batch 24/1600 loss 7.792079 loss_att 593.915405 loss_ctc 14.888900 loss_rnnt 7.003543 history loss 6.282376 rank 5
2022-12-08 02:16:38,488 DEBUG CV Batch 24/1600 loss 7.792079 loss_att 593.915405 loss_ctc 14.888900 loss_rnnt 7.003543 history loss 6.282376 rank 2
2022-12-08 02:16:38,515 DEBUG CV Batch 24/1600 loss 7.792079 loss_att 593.915405 loss_ctc 14.888900 loss_rnnt 7.003543 history loss 6.282376 rank 1
2022-12-08 02:16:38,856 DEBUG CV Batch 24/1600 loss 7.792079 loss_att 593.915405 loss_ctc 14.888900 loss_rnnt 7.003543 history loss 6.282376 rank 3
2022-12-08 02:16:43,848 DEBUG CV Batch 24/1700 loss 7.682289 loss_att 210.845245 loss_ctc 15.531577 loss_rnnt 6.810145 history loss 6.214989 rank 4
2022-12-08 02:16:44,157 DEBUG CV Batch 24/1700 loss 7.682289 loss_att 210.845245 loss_ctc 15.531577 loss_rnnt 6.810145 history loss 6.214989 rank 0
2022-12-08 02:16:44,585 DEBUG CV Batch 24/1700 loss 7.682289 loss_att 210.845245 loss_ctc 15.531577 loss_rnnt 6.810145 history loss 6.214989 rank 7
2022-12-08 02:16:46,525 DEBUG CV Batch 24/1700 loss 7.682289 loss_att 210.845245 loss_ctc 15.531577 loss_rnnt 6.810145 history loss 6.214989 rank 6
2022-12-08 02:16:46,678 DEBUG CV Batch 24/1700 loss 7.682289 loss_att 210.845245 loss_ctc 15.531577 loss_rnnt 6.810145 history loss 6.214989 rank 5
2022-12-08 02:16:50,186 DEBUG CV Batch 24/1700 loss 7.682289 loss_att 210.845245 loss_ctc 15.531577 loss_rnnt 6.810145 history loss 6.214989 rank 1
2022-12-08 02:16:50,350 DEBUG CV Batch 24/1700 loss 7.682289 loss_att 210.845245 loss_ctc 15.531577 loss_rnnt 6.810145 history loss 6.214989 rank 2
2022-12-08 02:16:50,918 DEBUG CV Batch 24/1700 loss 7.682289 loss_att 210.845245 loss_ctc 15.531577 loss_rnnt 6.810145 history loss 6.214989 rank 3
2022-12-08 02:16:52,596 INFO Epoch 24 CV info cv_loss 6.1895025819566944
2022-12-08 02:16:52,596 INFO Epoch 25 TRAIN info lr 0.00026105763393660214
2022-12-08 02:16:52,598 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 02:16:53,308 INFO Epoch 24 CV info cv_loss 6.1895025819566944
2022-12-08 02:16:53,308 INFO Checkpoint: save to checkpoint exp/1204_encoder_bias_nobi_noatt/24.pt
2022-12-08 02:16:53,546 INFO Epoch 24 CV info cv_loss 6.1895025819566944
2022-12-08 02:16:53,547 INFO Epoch 25 TRAIN info lr 0.00026104340201102085
2022-12-08 02:16:53,551 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 02:16:54,891 INFO Epoch 25 TRAIN info lr 0.0002610615481242378
2022-12-08 02:16:54,895 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 02:16:55,451 INFO Epoch 24 CV info cv_loss 6.1895025819566944
2022-12-08 02:16:55,452 INFO Epoch 25 TRAIN info lr 0.00026105798976456656
2022-12-08 02:16:55,456 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 02:16:55,752 INFO Epoch 24 CV info cv_loss 6.1895025819566944
2022-12-08 02:16:55,752 INFO Epoch 25 TRAIN info lr 0.0002610540757369815
2022-12-08 02:16:55,757 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 02:16:58,815 INFO Epoch 24 CV info cv_loss 6.1895025819566944
2022-12-08 02:16:58,815 INFO Epoch 25 TRAIN info lr 0.0002610889523683394
2022-12-08 02:16:58,816 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 02:16:59,215 INFO Epoch 24 CV info cv_loss 6.1895025819566944
2022-12-08 02:16:59,215 INFO Epoch 25 TRAIN info lr 0.0002610658183479188
2022-12-08 02:16:59,219 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 02:16:59,825 INFO Epoch 24 CV info cv_loss 6.1895025819566944
2022-12-08 02:16:59,826 INFO Epoch 25 TRAIN info lr 0.0002610640390625862
2022-12-08 02:16:59,830 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 02:18:01,795 DEBUG TRAIN Batch 25/0 loss 9.050620 loss_att 70.937630 loss_ctc 13.881193 loss_rnnt 8.513890 lr 0.00026106 rank 4
2022-12-08 02:18:01,796 DEBUG TRAIN Batch 25/0 loss 7.346653 loss_att 71.329384 loss_ctc 12.139250 loss_rnnt 6.814142 lr 0.00026106 rank 6
2022-12-08 02:18:01,797 DEBUG TRAIN Batch 25/0 loss 10.622273 loss_att 82.194374 loss_ctc 15.729634 loss_rnnt 10.054789 lr 0.00026104 rank 7
2022-12-08 02:18:01,798 DEBUG TRAIN Batch 25/0 loss 7.082394 loss_att 72.167641 loss_ctc 9.579103 loss_rnnt 6.804982 lr 0.00026106 rank 0
2022-12-08 02:18:01,801 DEBUG TRAIN Batch 25/0 loss 9.555573 loss_att 79.593651 loss_ctc 14.416941 loss_rnnt 9.015421 lr 0.00026105 rank 5
2022-12-08 02:18:01,815 DEBUG TRAIN Batch 25/0 loss 5.857967 loss_att 77.533226 loss_ctc 10.011973 loss_rnnt 5.396411 lr 0.00026109 rank 1
2022-12-08 02:18:01,830 DEBUG TRAIN Batch 25/0 loss 10.244935 loss_att 76.645882 loss_ctc 16.238928 loss_rnnt 9.578937 lr 0.00026107 rank 2
2022-12-08 02:18:01,833 DEBUG TRAIN Batch 25/0 loss 7.456506 loss_att 74.892487 loss_ctc 11.712133 loss_rnnt 6.983659 lr 0.00026106 rank 3
2022-12-08 02:19:04,229 DEBUG TRAIN Batch 25/100 loss 8.562338 loss_att 446.600403 loss_ctc 22.850225 loss_rnnt 6.974795 lr 0.00026101 rank 7
2022-12-08 02:19:04,232 DEBUG TRAIN Batch 25/100 loss 7.888019 loss_att 383.954041 loss_ctc 13.683424 loss_rnnt 7.244085 lr 0.00026105 rank 1
2022-12-08 02:19:04,234 DEBUG TRAIN Batch 25/100 loss 5.987876 loss_att 381.016937 loss_ctc 10.251558 loss_rnnt 5.514133 lr 0.00026103 rank 2
2022-12-08 02:19:04,234 DEBUG TRAIN Batch 25/100 loss 3.515440 loss_att 381.749329 loss_ctc 10.452274 loss_rnnt 2.744680 lr 0.00026102 rank 4
2022-12-08 02:19:04,234 DEBUG TRAIN Batch 25/100 loss 6.454170 loss_att 390.229065 loss_ctc 15.669246 loss_rnnt 5.430273 lr 0.00026103 rank 0
2022-12-08 02:19:04,234 DEBUG TRAIN Batch 25/100 loss 5.238018 loss_att 479.254211 loss_ctc 17.638599 loss_rnnt 3.860176 lr 0.00026103 rank 3
2022-12-08 02:19:04,237 DEBUG TRAIN Batch 25/100 loss 4.380041 loss_att 381.745789 loss_ctc 12.520068 loss_rnnt 3.475594 lr 0.00026102 rank 6
2022-12-08 02:19:04,242 DEBUG TRAIN Batch 25/100 loss 6.475733 loss_att 378.638733 loss_ctc 18.915928 loss_rnnt 5.093489 lr 0.00026102 rank 5
2022-12-08 02:20:07,573 DEBUG TRAIN Batch 25/200 loss 5.266660 loss_att 391.473480 loss_ctc 11.342428 loss_rnnt 4.591575 lr 0.00026097 rank 7
2022-12-08 02:20:07,576 DEBUG TRAIN Batch 25/200 loss 6.952306 loss_att 424.663940 loss_ctc 12.609874 loss_rnnt 6.323688 lr 0.00026099 rank 0
2022-12-08 02:20:07,581 DEBUG TRAIN Batch 25/200 loss 8.896060 loss_att 435.597504 loss_ctc 15.582291 loss_rnnt 8.153146 lr 0.00026099 rank 4
2022-12-08 02:20:07,584 DEBUG TRAIN Batch 25/200 loss 2.267365 loss_att 437.887543 loss_ctc 5.583870 loss_rnnt 1.898865 lr 0.00026099 rank 6
2022-12-08 02:20:07,585 DEBUG TRAIN Batch 25/200 loss 5.453623 loss_att 397.837891 loss_ctc 9.472807 loss_rnnt 5.007047 lr 0.00026099 rank 3
2022-12-08 02:20:07,585 DEBUG TRAIN Batch 25/200 loss 7.766896 loss_att 350.982391 loss_ctc 11.697611 loss_rnnt 7.330150 lr 0.00026099 rank 2
2022-12-08 02:20:07,586 DEBUG TRAIN Batch 25/200 loss 8.114831 loss_att 408.581299 loss_ctc 16.274107 loss_rnnt 7.208245 lr 0.00026102 rank 1
2022-12-08 02:20:07,587 DEBUG TRAIN Batch 25/200 loss 9.878912 loss_att 388.637146 loss_ctc 17.836758 loss_rnnt 8.994707 lr 0.00026098 rank 5
2022-12-08 02:21:11,440 DEBUG TRAIN Batch 25/300 loss 6.855439 loss_att 372.772675 loss_ctc 19.169247 loss_rnnt 5.487239 lr 0.00026095 rank 6
2022-12-08 02:21:11,444 DEBUG TRAIN Batch 25/300 loss 14.350005 loss_att 375.805817 loss_ctc 29.574566 loss_rnnt 12.658388 lr 0.00026095 rank 5
2022-12-08 02:21:11,455 DEBUG TRAIN Batch 25/300 loss 8.958664 loss_att 423.829590 loss_ctc 17.375942 loss_rnnt 8.023411 lr 0.00026094 rank 7
2022-12-08 02:21:11,455 DEBUG TRAIN Batch 25/300 loss 6.979772 loss_att 378.437317 loss_ctc 15.528347 loss_rnnt 6.029930 lr 0.00026095 rank 4
2022-12-08 02:21:11,456 DEBUG TRAIN Batch 25/300 loss 11.020400 loss_att 371.384521 loss_ctc 26.753695 loss_rnnt 9.272257 lr 0.00026096 rank 3
2022-12-08 02:21:11,461 DEBUG TRAIN Batch 25/300 loss 6.601199 loss_att 418.085541 loss_ctc 13.705702 loss_rnnt 5.811810 lr 0.00026098 rank 1
2022-12-08 02:21:11,462 DEBUG TRAIN Batch 25/300 loss 7.104138 loss_att 375.176514 loss_ctc 14.370630 loss_rnnt 6.296750 lr 0.00026095 rank 0
2022-12-08 02:21:11,469 DEBUG TRAIN Batch 25/300 loss 2.840863 loss_att 360.025848 loss_ctc 11.310588 loss_rnnt 1.899783 lr 0.00026096 rank 2
2022-12-08 02:22:22,311 DEBUG TRAIN Batch 25/400 loss 5.505942 loss_att 386.906067 loss_ctc 15.220094 loss_rnnt 4.426592 lr 0.00026090 rank 7
2022-12-08 02:22:22,312 DEBUG TRAIN Batch 25/400 loss 6.347749 loss_att 332.896271 loss_ctc 10.246259 loss_rnnt 5.914581 lr 0.00026092 rank 6
2022-12-08 02:22:22,312 DEBUG TRAIN Batch 25/400 loss 4.742053 loss_att 337.430603 loss_ctc 12.031915 loss_rnnt 3.932069 lr 0.00026092 rank 0
2022-12-08 02:22:22,315 DEBUG TRAIN Batch 25/400 loss 4.802155 loss_att 339.307678 loss_ctc 10.965757 loss_rnnt 4.117311 lr 0.00026092 rank 2
2022-12-08 02:22:22,316 DEBUG TRAIN Batch 25/400 loss 5.929966 loss_att 386.918671 loss_ctc 13.171232 loss_rnnt 5.125381 lr 0.00026092 rank 4
2022-12-08 02:22:22,318 DEBUG TRAIN Batch 25/400 loss 7.747319 loss_att 338.257996 loss_ctc 15.396447 loss_rnnt 6.897416 lr 0.00026092 rank 3
2022-12-08 02:22:22,318 DEBUG TRAIN Batch 25/400 loss 5.392832 loss_att 375.213165 loss_ctc 12.713262 loss_rnnt 4.579452 lr 0.00026095 rank 1
2022-12-08 02:22:22,321 DEBUG TRAIN Batch 25/400 loss 9.411100 loss_att 391.276337 loss_ctc 16.200573 loss_rnnt 8.656714 lr 0.00026091 rank 5
2022-12-08 02:23:25,134 DEBUG TRAIN Batch 25/500 loss 12.675208 loss_att 322.197357 loss_ctc 26.385126 loss_rnnt 11.151884 lr 0.00026087 rank 7
2022-12-08 02:23:25,139 DEBUG TRAIN Batch 25/500 loss 6.938712 loss_att 280.108643 loss_ctc 12.345130 loss_rnnt 6.337999 lr 0.00026089 rank 3
2022-12-08 02:23:25,141 DEBUG TRAIN Batch 25/500 loss 7.118915 loss_att 385.071045 loss_ctc 18.535540 loss_rnnt 5.850401 lr 0.00026088 rank 4
2022-12-08 02:23:25,141 DEBUG TRAIN Batch 25/500 loss 7.085969 loss_att 305.856934 loss_ctc 11.641058 loss_rnnt 6.579848 lr 0.00026088 rank 0
2022-12-08 02:23:25,141 DEBUG TRAIN Batch 25/500 loss 7.810143 loss_att 294.518768 loss_ctc 20.823059 loss_rnnt 6.364264 lr 0.00026089 rank 2
2022-12-08 02:23:25,145 DEBUG TRAIN Batch 25/500 loss 5.828341 loss_att 325.802307 loss_ctc 10.274768 loss_rnnt 5.334293 lr 0.00026088 rank 5
2022-12-08 02:23:25,145 DEBUG TRAIN Batch 25/500 loss 9.669676 loss_att 361.109039 loss_ctc 20.787228 loss_rnnt 8.434393 lr 0.00026088 rank 6
2022-12-08 02:23:25,145 DEBUG TRAIN Batch 25/500 loss 14.129834 loss_att 318.386993 loss_ctc 20.602985 loss_rnnt 13.410595 lr 0.00026091 rank 1
2022-12-08 02:24:28,007 DEBUG TRAIN Batch 25/600 loss 7.442219 loss_att 139.156326 loss_ctc 11.651277 loss_rnnt 6.974546 lr 0.00026085 rank 2
2022-12-08 02:24:28,008 DEBUG TRAIN Batch 25/600 loss 4.679008 loss_att 167.431442 loss_ctc 12.179656 loss_rnnt 3.845603 lr 0.00026084 rank 4
2022-12-08 02:24:28,010 DEBUG TRAIN Batch 25/600 loss 8.442955 loss_att 196.556931 loss_ctc 15.022856 loss_rnnt 7.711855 lr 0.00026088 rank 1
2022-12-08 02:24:28,012 DEBUG TRAIN Batch 25/600 loss 6.883802 loss_att 102.191963 loss_ctc 13.082598 loss_rnnt 6.195047 lr 0.00026083 rank 7
2022-12-08 02:24:28,012 DEBUG TRAIN Batch 25/600 loss 6.845565 loss_att 233.207443 loss_ctc 12.945293 loss_rnnt 6.167818 lr 0.00026084 rank 6
2022-12-08 02:24:28,013 DEBUG TRAIN Batch 25/600 loss 6.990421 loss_att 213.427612 loss_ctc 12.411883 loss_rnnt 6.388036 lr 0.00026085 rank 0
2022-12-08 02:24:28,019 DEBUG TRAIN Batch 25/600 loss 8.118208 loss_att 72.937683 loss_ctc 13.476769 loss_rnnt 7.522812 lr 0.00026085 rank 3
2022-12-08 02:24:28,026 DEBUG TRAIN Batch 25/600 loss 18.030914 loss_att 198.831879 loss_ctc 29.305643 loss_rnnt 16.778168 lr 0.00026084 rank 5
2022-12-08 02:25:32,695 DEBUG TRAIN Batch 25/700 loss 8.501875 loss_att 426.090912 loss_ctc 19.593252 loss_rnnt 7.269500 lr 0.00026084 rank 1
2022-12-08 02:25:32,699 DEBUG TRAIN Batch 25/700 loss 7.730139 loss_att 351.805267 loss_ctc 15.726142 loss_rnnt 6.841695 lr 0.00026081 rank 5
2022-12-08 02:25:32,706 DEBUG TRAIN Batch 25/700 loss 9.335556 loss_att 399.195801 loss_ctc 22.140936 loss_rnnt 7.912737 lr 0.00026079 rank 7
2022-12-08 02:25:32,708 DEBUG TRAIN Batch 25/700 loss 10.213780 loss_att 458.619354 loss_ctc 14.827929 loss_rnnt 9.701097 lr 0.00026081 rank 6
2022-12-08 02:25:32,708 DEBUG TRAIN Batch 25/700 loss 3.053921 loss_att 397.188904 loss_ctc 9.551865 loss_rnnt 2.331927 lr 0.00026081 rank 4
2022-12-08 02:25:32,709 DEBUG TRAIN Batch 25/700 loss 6.258896 loss_att 433.463806 loss_ctc 20.129303 loss_rnnt 4.717740 lr 0.00026082 rank 2
2022-12-08 02:25:32,710 DEBUG TRAIN Batch 25/700 loss 4.099745 loss_att 436.201904 loss_ctc 11.148173 loss_rnnt 3.316586 lr 0.00026081 rank 0
2022-12-08 02:25:32,714 DEBUG TRAIN Batch 25/700 loss 7.312027 loss_att 361.623383 loss_ctc 16.091499 loss_rnnt 6.336530 lr 0.00026081 rank 3
2022-12-08 02:26:42,172 DEBUG TRAIN Batch 25/800 loss 11.045185 loss_att 334.069214 loss_ctc 14.629971 loss_rnnt 10.646875 lr 0.00026078 rank 0
2022-12-08 02:26:42,173 DEBUG TRAIN Batch 25/800 loss 8.760226 loss_att 399.719116 loss_ctc 15.467733 loss_rnnt 8.014948 lr 0.00026077 rank 4
2022-12-08 02:26:42,174 DEBUG TRAIN Batch 25/800 loss 7.467774 loss_att 418.039368 loss_ctc 17.791908 loss_rnnt 6.320648 lr 0.00026076 rank 7
2022-12-08 02:26:42,174 DEBUG TRAIN Batch 25/800 loss 16.664968 loss_att 391.563293 loss_ctc 35.969788 loss_rnnt 14.519989 lr 0.00026078 rank 2
2022-12-08 02:26:42,180 DEBUG TRAIN Batch 25/800 loss 2.104824 loss_att 353.960632 loss_ctc 4.277832 loss_rnnt 1.863379 lr 0.00026078 rank 3
2022-12-08 02:26:42,182 DEBUG TRAIN Batch 25/800 loss 5.297343 loss_att 335.643677 loss_ctc 11.284747 loss_rnnt 4.632076 lr 0.00026077 rank 5
2022-12-08 02:26:42,183 DEBUG TRAIN Batch 25/800 loss 19.397556 loss_att 422.356873 loss_ctc 43.089668 loss_rnnt 16.765099 lr 0.00026080 rank 1
2022-12-08 02:26:42,218 DEBUG TRAIN Batch 25/800 loss 8.307286 loss_att 383.485840 loss_ctc 16.497570 loss_rnnt 7.397255 lr 0.00026077 rank 6
2022-12-08 02:27:45,333 DEBUG TRAIN Batch 25/900 loss 6.566018 loss_att 355.293396 loss_ctc 15.235928 loss_rnnt 5.602694 lr 0.00026074 rank 4
2022-12-08 02:27:45,337 DEBUG TRAIN Batch 25/900 loss 18.064644 loss_att 444.375793 loss_ctc 34.157410 loss_rnnt 16.276558 lr 0.00026074 rank 3
2022-12-08 02:27:45,341 DEBUG TRAIN Batch 25/900 loss 6.501306 loss_att 436.107666 loss_ctc 13.246069 loss_rnnt 5.751887 lr 0.00026074 rank 0
2022-12-08 02:27:45,340 DEBUG TRAIN Batch 25/900 loss 4.987164 loss_att 344.545776 loss_ctc 11.154953 loss_rnnt 4.301854 lr 0.00026075 rank 2
2022-12-08 02:27:45,343 DEBUG TRAIN Batch 25/900 loss 8.705219 loss_att 421.521667 loss_ctc 25.507133 loss_rnnt 6.838340 lr 0.00026072 rank 7
2022-12-08 02:27:45,342 DEBUG TRAIN Batch 25/900 loss 4.204847 loss_att 358.771973 loss_ctc 10.448072 loss_rnnt 3.511155 lr 0.00026074 rank 6
2022-12-08 02:27:45,344 DEBUG TRAIN Batch 25/900 loss 4.328827 loss_att 354.485535 loss_ctc 10.272108 loss_rnnt 3.668463 lr 0.00026073 rank 5
2022-12-08 02:27:45,379 DEBUG TRAIN Batch 25/900 loss 8.128864 loss_att 470.304932 loss_ctc 13.123801 loss_rnnt 7.573872 lr 0.00026077 rank 1
2022-12-08 02:28:48,539 DEBUG TRAIN Batch 25/1000 loss 12.272361 loss_att 363.162048 loss_ctc 17.903378 loss_rnnt 11.646692 lr 0.00026071 rank 2
2022-12-08 02:28:48,546 DEBUG TRAIN Batch 25/1000 loss 2.159500 loss_att 368.636963 loss_ctc 8.725519 loss_rnnt 1.429942 lr 0.00026070 rank 4
2022-12-08 02:28:48,550 DEBUG TRAIN Batch 25/1000 loss 7.931824 loss_att 401.458069 loss_ctc 18.615055 loss_rnnt 6.744799 lr 0.00026071 rank 3
2022-12-08 02:28:48,551 DEBUG TRAIN Batch 25/1000 loss 7.577663 loss_att 316.102386 loss_ctc 14.400086 loss_rnnt 6.819616 lr 0.00026073 rank 1
2022-12-08 02:28:48,552 DEBUG TRAIN Batch 25/1000 loss 15.680882 loss_att 411.960358 loss_ctc 30.860723 loss_rnnt 13.994232 lr 0.00026070 rank 5
2022-12-08 02:28:48,558 DEBUG TRAIN Batch 25/1000 loss 7.904877 loss_att 416.293030 loss_ctc 15.962639 loss_rnnt 7.009570 lr 0.00026071 rank 0
2022-12-08 02:28:48,568 DEBUG TRAIN Batch 25/1000 loss 7.467443 loss_att 389.759857 loss_ctc 16.394182 loss_rnnt 6.475583 lr 0.00026069 rank 7
2022-12-08 02:28:48,604 DEBUG TRAIN Batch 25/1000 loss 11.831285 loss_att 313.160461 loss_ctc 22.046549 loss_rnnt 10.696257 lr 0.00026070 rank 6
2022-12-08 02:29:58,937 DEBUG TRAIN Batch 25/1100 loss 2.625733 loss_att 336.412018 loss_ctc 9.871632 loss_rnnt 1.820633 lr 0.00026065 rank 7
2022-12-08 02:29:58,937 DEBUG TRAIN Batch 25/1100 loss 5.045647 loss_att 348.734161 loss_ctc 10.626837 loss_rnnt 4.425515 lr 0.00026067 rank 3
2022-12-08 02:29:58,937 DEBUG TRAIN Batch 25/1100 loss 1.622124 loss_att 273.333069 loss_ctc 6.085967 loss_rnnt 1.126141 lr 0.00026070 rank 1
2022-12-08 02:29:58,940 DEBUG TRAIN Batch 25/1100 loss 12.271852 loss_att 390.383545 loss_ctc 22.269613 loss_rnnt 11.160990 lr 0.00026067 rank 6
2022-12-08 02:29:58,942 DEBUG TRAIN Batch 25/1100 loss 5.501003 loss_att 303.471619 loss_ctc 12.008801 loss_rnnt 4.777915 lr 0.00026067 rank 4
2022-12-08 02:29:58,943 DEBUG TRAIN Batch 25/1100 loss 5.891934 loss_att 279.297119 loss_ctc 10.223573 loss_rnnt 5.410641 lr 0.00026066 rank 5
2022-12-08 02:29:58,944 DEBUG TRAIN Batch 25/1100 loss 5.650442 loss_att 333.146271 loss_ctc 13.067832 loss_rnnt 4.826288 lr 0.00026067 rank 0
2022-12-08 02:29:58,976 DEBUG TRAIN Batch 25/1100 loss 4.819607 loss_att 374.239258 loss_ctc 7.745788 loss_rnnt 4.494476 lr 0.00026067 rank 2
2022-12-08 02:31:02,610 DEBUG TRAIN Batch 25/1200 loss 7.567706 loss_att 320.597900 loss_ctc 12.425137 loss_rnnt 7.027991 lr 0.00026063 rank 6
2022-12-08 02:31:02,615 DEBUG TRAIN Batch 25/1200 loss 11.226337 loss_att 177.371643 loss_ctc 16.611217 loss_rnnt 10.628018 lr 0.00026062 rank 7
2022-12-08 02:31:02,618 DEBUG TRAIN Batch 25/1200 loss 12.130904 loss_att 234.347824 loss_ctc 18.593203 loss_rnnt 11.412870 lr 0.00026064 rank 0
2022-12-08 02:31:02,617 DEBUG TRAIN Batch 25/1200 loss 15.705094 loss_att 279.306274 loss_ctc 22.829172 loss_rnnt 14.913530 lr 0.00026064 rank 2
2022-12-08 02:31:02,618 DEBUG TRAIN Batch 25/1200 loss 10.507366 loss_att 201.993103 loss_ctc 20.342785 loss_rnnt 9.414541 lr 0.00026064 rank 3
2022-12-08 02:31:02,621 DEBUG TRAIN Batch 25/1200 loss 6.809355 loss_att 227.307571 loss_ctc 8.808013 loss_rnnt 6.587282 lr 0.00026063 rank 5
2022-12-08 02:31:02,621 DEBUG TRAIN Batch 25/1200 loss 15.803846 loss_att 332.110626 loss_ctc 23.690084 loss_rnnt 14.927597 lr 0.00026063 rank 4
2022-12-08 02:31:02,623 DEBUG TRAIN Batch 25/1200 loss 9.717873 loss_att 319.551178 loss_ctc 16.535513 loss_rnnt 8.960358 lr 0.00026066 rank 1
2022-12-08 02:32:06,287 DEBUG TRAIN Batch 25/1300 loss 4.824712 loss_att 220.461945 loss_ctc 9.836750 loss_rnnt 4.267819 lr 0.00026060 rank 6
2022-12-08 02:32:06,288 DEBUG TRAIN Batch 25/1300 loss 7.235354 loss_att 71.913666 loss_ctc 11.164426 loss_rnnt 6.798791 lr 0.00026060 rank 4
2022-12-08 02:32:06,289 DEBUG TRAIN Batch 25/1300 loss 14.340496 loss_att 392.526367 loss_ctc 29.588392 loss_rnnt 12.646285 lr 0.00026060 rank 2
2022-12-08 02:32:06,289 DEBUG TRAIN Batch 25/1300 loss 2.889894 loss_att 328.481781 loss_ctc 8.870884 loss_rnnt 2.225340 lr 0.00026060 rank 3
2022-12-08 02:32:06,290 DEBUG TRAIN Batch 25/1300 loss 3.547917 loss_att 384.665771 loss_ctc 10.625275 loss_rnnt 2.761544 lr 0.00026058 rank 7
2022-12-08 02:32:06,291 DEBUG TRAIN Batch 25/1300 loss 8.862238 loss_att 76.949440 loss_ctc 11.245266 loss_rnnt 8.597457 lr 0.00026063 rank 1
2022-12-08 02:32:06,291 DEBUG TRAIN Batch 25/1300 loss 1.725928 loss_att 385.267914 loss_ctc 7.673185 loss_rnnt 1.065122 lr 0.00026060 rank 0
2022-12-08 02:32:06,293 DEBUG TRAIN Batch 25/1300 loss 5.840421 loss_att 444.161133 loss_ctc 13.095785 loss_rnnt 5.034269 lr 0.00026059 rank 5
2022-12-08 02:33:11,158 DEBUG TRAIN Batch 25/1400 loss 6.543358 loss_att 421.464783 loss_ctc 16.718325 loss_rnnt 5.412807 lr 0.00026057 rank 3
2022-12-08 02:33:11,159 DEBUG TRAIN Batch 25/1400 loss 5.354436 loss_att 373.258606 loss_ctc 8.011253 loss_rnnt 5.059234 lr 0.00026056 rank 4
2022-12-08 02:33:11,160 DEBUG TRAIN Batch 25/1400 loss 11.407374 loss_att 392.375610 loss_ctc 33.725830 loss_rnnt 8.927546 lr 0.00026056 rank 6
2022-12-08 02:33:11,160 DEBUG TRAIN Batch 25/1400 loss 4.719412 loss_att 386.996094 loss_ctc 8.177004 loss_rnnt 4.335235 lr 0.00026056 rank 0
2022-12-08 02:33:11,160 DEBUG TRAIN Batch 25/1400 loss 10.523443 loss_att 442.476288 loss_ctc 32.106014 loss_rnnt 8.125380 lr 0.00026056 rank 5
2022-12-08 02:33:11,160 DEBUG TRAIN Batch 25/1400 loss 7.821699 loss_att 408.211884 loss_ctc 16.696075 loss_rnnt 6.835657 lr 0.00026055 rank 7
2022-12-08 02:33:11,173 DEBUG TRAIN Batch 25/1400 loss 6.929099 loss_att 401.015442 loss_ctc 23.279324 loss_rnnt 5.112408 lr 0.00026057 rank 2
2022-12-08 02:33:11,181 DEBUG TRAIN Batch 25/1400 loss 4.659836 loss_att 350.344727 loss_ctc 15.288048 loss_rnnt 3.478924 lr 0.00026059 rank 1
2022-12-08 02:34:21,352 DEBUG TRAIN Batch 25/1500 loss 16.755991 loss_att 425.705505 loss_ctc 34.800232 loss_rnnt 14.751076 lr 0.00026051 rank 7
2022-12-08 02:34:21,352 DEBUG TRAIN Batch 25/1500 loss 5.224195 loss_att 386.390991 loss_ctc 13.198459 loss_rnnt 4.338166 lr 0.00026053 rank 4
2022-12-08 02:34:21,352 DEBUG TRAIN Batch 25/1500 loss 5.253028 loss_att 392.778900 loss_ctc 15.785093 loss_rnnt 4.082798 lr 0.00026056 rank 1
2022-12-08 02:34:21,353 DEBUG TRAIN Batch 25/1500 loss 5.918671 loss_att 436.395477 loss_ctc 12.428676 loss_rnnt 5.195337 lr 0.00026053 rank 6
2022-12-08 02:34:21,352 DEBUG TRAIN Batch 25/1500 loss 7.265159 loss_att 395.111664 loss_ctc 13.349093 loss_rnnt 6.589166 lr 0.00026053 rank 2
2022-12-08 02:34:21,359 DEBUG TRAIN Batch 25/1500 loss 11.437368 loss_att 427.604126 loss_ctc 30.201860 loss_rnnt 9.352425 lr 0.00026053 rank 0
2022-12-08 02:34:21,361 DEBUG TRAIN Batch 25/1500 loss 3.951727 loss_att 415.567322 loss_ctc 8.730353 loss_rnnt 3.420768 lr 0.00026052 rank 5
2022-12-08 02:34:21,398 DEBUG TRAIN Batch 25/1500 loss 11.094271 loss_att 356.350800 loss_ctc 18.830536 loss_rnnt 10.234686 lr 0.00026053 rank 3
2022-12-08 02:35:24,491 DEBUG TRAIN Batch 25/1600 loss 8.451573 loss_att 440.601074 loss_ctc 14.773664 loss_rnnt 7.749119 lr 0.00026048 rank 7
2022-12-08 02:35:24,493 DEBUG TRAIN Batch 25/1600 loss 4.210049 loss_att 321.803253 loss_ctc 9.336846 loss_rnnt 3.640405 lr 0.00026050 rank 3
2022-12-08 02:35:24,494 DEBUG TRAIN Batch 25/1600 loss 9.636192 loss_att 445.551117 loss_ctc 26.078926 loss_rnnt 7.809222 lr 0.00026049 rank 6
2022-12-08 02:35:24,497 DEBUG TRAIN Batch 25/1600 loss 7.479112 loss_att 380.047791 loss_ctc 15.920935 loss_rnnt 6.541132 lr 0.00026049 rank 0
2022-12-08 02:35:24,500 DEBUG TRAIN Batch 25/1600 loss 3.786610 loss_att 410.205933 loss_ctc 8.443489 loss_rnnt 3.269180 lr 0.00026049 rank 4
2022-12-08 02:35:24,500 DEBUG TRAIN Batch 25/1600 loss 9.289952 loss_att 377.271545 loss_ctc 21.024244 loss_rnnt 7.986142 lr 0.00026052 rank 1
2022-12-08 02:35:24,500 DEBUG TRAIN Batch 25/1600 loss 4.999090 loss_att 348.865967 loss_ctc 9.276712 loss_rnnt 4.523799 lr 0.00026049 rank 5
2022-12-08 02:35:24,505 DEBUG TRAIN Batch 25/1600 loss 4.612504 loss_att 330.503204 loss_ctc 9.494999 loss_rnnt 4.070004 lr 0.00026050 rank 2
2022-12-08 02:36:27,979 DEBUG TRAIN Batch 25/1700 loss 16.221889 loss_att 380.262360 loss_ctc 26.395966 loss_rnnt 15.091436 lr 0.00026045 rank 4
2022-12-08 02:36:27,982 DEBUG TRAIN Batch 25/1700 loss 10.843161 loss_att 360.259033 loss_ctc 19.277901 loss_rnnt 9.905968 lr 0.00026044 rank 7
2022-12-08 02:36:27,983 DEBUG TRAIN Batch 25/1700 loss 3.583804 loss_att 366.451599 loss_ctc 8.791924 loss_rnnt 3.005124 lr 0.00026046 rank 3
2022-12-08 02:36:27,983 DEBUG TRAIN Batch 25/1700 loss 10.526840 loss_att 357.311279 loss_ctc 19.840063 loss_rnnt 9.492039 lr 0.00026045 rank 6
2022-12-08 02:36:27,985 DEBUG TRAIN Batch 25/1700 loss 6.425401 loss_att 354.793945 loss_ctc 15.015852 loss_rnnt 5.470906 lr 0.00026049 rank 1
2022-12-08 02:36:27,988 DEBUG TRAIN Batch 25/1700 loss 10.375879 loss_att 359.009644 loss_ctc 25.777975 loss_rnnt 8.664536 lr 0.00026046 rank 0
2022-12-08 02:36:27,993 DEBUG TRAIN Batch 25/1700 loss 7.538881 loss_att 349.329071 loss_ctc 17.028444 loss_rnnt 6.484486 lr 0.00026045 rank 5
2022-12-08 02:36:28,003 DEBUG TRAIN Batch 25/1700 loss 9.545399 loss_att 317.694092 loss_ctc 17.938950 loss_rnnt 8.612782 lr 0.00026046 rank 2
2022-12-08 02:37:40,204 DEBUG TRAIN Batch 25/1800 loss 8.302093 loss_att 264.610291 loss_ctc 18.517948 loss_rnnt 7.166998 lr 0.00026043 rank 2
2022-12-08 02:37:40,205 DEBUG TRAIN Batch 25/1800 loss 15.268900 loss_att 356.988708 loss_ctc 24.727461 loss_rnnt 14.217949 lr 0.00026045 rank 1
2022-12-08 02:37:40,206 DEBUG TRAIN Batch 25/1800 loss 13.173185 loss_att 407.210480 loss_ctc 31.482010 loss_rnnt 11.138872 lr 0.00026042 rank 4
2022-12-08 02:37:40,206 DEBUG TRAIN Batch 25/1800 loss 6.773402 loss_att 285.783691 loss_ctc 10.671846 loss_rnnt 6.340241 lr 0.00026043 rank 3
2022-12-08 02:37:40,207 DEBUG TRAIN Batch 25/1800 loss 7.587943 loss_att 244.891220 loss_ctc 13.915011 loss_rnnt 6.884936 lr 0.00026042 rank 0
2022-12-08 02:37:40,207 DEBUG TRAIN Batch 25/1800 loss 6.550573 loss_att 284.451813 loss_ctc 16.971670 loss_rnnt 5.392673 lr 0.00026041 rank 7
2022-12-08 02:37:40,207 DEBUG TRAIN Batch 25/1800 loss 3.810484 loss_att 309.007690 loss_ctc 8.210244 loss_rnnt 3.321622 lr 0.00026042 rank 5
2022-12-08 02:37:40,249 DEBUG TRAIN Batch 25/1800 loss 2.590496 loss_att 293.287720 loss_ctc 6.922922 loss_rnnt 2.109116 lr 0.00026042 rank 6
2022-12-08 02:38:43,730 DEBUG TRAIN Batch 25/1900 loss 4.730470 loss_att 420.512878 loss_ctc 11.095699 loss_rnnt 4.023222 lr 0.00026039 rank 0
2022-12-08 02:38:43,730 DEBUG TRAIN Batch 25/1900 loss 9.892308 loss_att 243.784225 loss_ctc 23.192476 loss_rnnt 8.414512 lr 0.00026039 rank 2
2022-12-08 02:38:43,730 DEBUG TRAIN Batch 25/1900 loss 8.581675 loss_att 429.351929 loss_ctc 17.708372 loss_rnnt 7.567598 lr 0.00026039 rank 3
2022-12-08 02:38:43,730 DEBUG TRAIN Batch 25/1900 loss 9.320727 loss_att 248.095795 loss_ctc 18.174946 loss_rnnt 8.336926 lr 0.00026038 rank 4
2022-12-08 02:38:43,730 DEBUG TRAIN Batch 25/1900 loss 3.954102 loss_att 200.467072 loss_ctc 5.752685 loss_rnnt 3.754260 lr 0.00026041 rank 1
2022-12-08 02:38:43,731 DEBUG TRAIN Batch 25/1900 loss 3.396566 loss_att 133.539368 loss_ctc 8.091570 loss_rnnt 2.874899 lr 0.00026037 rank 7
2022-12-08 02:38:43,732 DEBUG TRAIN Batch 25/1900 loss 10.305151 loss_att 346.222870 loss_ctc 16.093418 loss_rnnt 9.662011 lr 0.00026038 rank 6
2022-12-08 02:38:43,734 DEBUG TRAIN Batch 25/1900 loss 10.265018 loss_att 89.285019 loss_ctc 17.217358 loss_rnnt 9.492537 lr 0.00026038 rank 5
2022-12-08 02:39:46,460 DEBUG TRAIN Batch 25/2000 loss 11.199832 loss_att 422.887634 loss_ctc 20.212524 loss_rnnt 10.198421 lr 0.00026035 rank 4
2022-12-08 02:39:46,475 DEBUG TRAIN Batch 25/2000 loss 3.806757 loss_att 369.269012 loss_ctc 5.368192 loss_rnnt 3.633264 lr 0.00026033 rank 7
2022-12-08 02:39:46,476 DEBUG TRAIN Batch 25/2000 loss 10.377067 loss_att 118.892090 loss_ctc 15.028719 loss_rnnt 9.860217 lr 0.00026035 rank 6
2022-12-08 02:39:46,476 DEBUG TRAIN Batch 25/2000 loss 13.519845 loss_att 423.947601 loss_ctc 24.140110 loss_rnnt 12.339816 lr 0.00026034 rank 5
2022-12-08 02:39:46,478 DEBUG TRAIN Batch 25/2000 loss 7.567986 loss_att 474.676758 loss_ctc 14.367786 loss_rnnt 6.812453 lr 0.00026035 rank 3
2022-12-08 02:39:46,480 DEBUG TRAIN Batch 25/2000 loss 7.768432 loss_att 418.256470 loss_ctc 16.223545 loss_rnnt 6.828975 lr 0.00026035 rank 0
2022-12-08 02:39:46,483 DEBUG TRAIN Batch 25/2000 loss 2.407941 loss_att 358.964203 loss_ctc 6.711955 loss_rnnt 1.929717 lr 0.00026038 rank 1
2022-12-08 02:39:46,518 DEBUG TRAIN Batch 25/2000 loss 4.314230 loss_att 403.690063 loss_ctc 7.998019 loss_rnnt 3.904920 lr 0.00026036 rank 2
2022-12-08 02:40:51,481 DEBUG TRAIN Batch 25/2100 loss 2.856535 loss_att 363.684631 loss_ctc 7.854553 loss_rnnt 2.301200 lr 0.00026031 rank 6
2022-12-08 02:40:51,483 DEBUG TRAIN Batch 25/2100 loss 5.930036 loss_att 415.823822 loss_ctc 10.404146 loss_rnnt 5.432912 lr 0.00026031 rank 5
2022-12-08 02:40:51,483 DEBUG TRAIN Batch 25/2100 loss 17.474960 loss_att 407.538879 loss_ctc 30.705864 loss_rnnt 16.004860 lr 0.00026034 rank 1
2022-12-08 02:40:51,492 DEBUG TRAIN Batch 25/2100 loss 7.055254 loss_att 381.490479 loss_ctc 12.808678 loss_rnnt 6.415985 lr 0.00026030 rank 7
2022-12-08 02:40:51,493 DEBUG TRAIN Batch 25/2100 loss 8.381123 loss_att 324.686707 loss_ctc 18.569084 loss_rnnt 7.249126 lr 0.00026032 rank 3
2022-12-08 02:40:51,495 DEBUG TRAIN Batch 25/2100 loss 10.086064 loss_att 425.725555 loss_ctc 21.344315 loss_rnnt 8.835148 lr 0.00026031 rank 4
2022-12-08 02:40:51,495 DEBUG TRAIN Batch 25/2100 loss 10.454273 loss_att 391.640839 loss_ctc 21.475887 loss_rnnt 9.229650 lr 0.00026032 rank 0
2022-12-08 02:40:51,498 DEBUG TRAIN Batch 25/2100 loss 10.905879 loss_att 432.641357 loss_ctc 24.182178 loss_rnnt 9.430735 lr 0.00026032 rank 2
2022-12-08 02:42:00,982 DEBUG TRAIN Batch 25/2200 loss 9.343584 loss_att 435.259979 loss_ctc 20.579750 loss_rnnt 8.095121 lr 0.00026028 rank 4
2022-12-08 02:42:00,987 DEBUG TRAIN Batch 25/2200 loss 8.627758 loss_att 400.035583 loss_ctc 21.905453 loss_rnnt 7.152459 lr 0.00026031 rank 1
2022-12-08 02:42:00,987 DEBUG TRAIN Batch 25/2200 loss 11.698014 loss_att 355.292816 loss_ctc 18.907921 loss_rnnt 10.896914 lr 0.00026026 rank 7
2022-12-08 02:42:00,988 DEBUG TRAIN Batch 25/2200 loss 7.906135 loss_att 371.534271 loss_ctc 15.679594 loss_rnnt 7.042417 lr 0.00026028 rank 3
2022-12-08 02:42:00,989 DEBUG TRAIN Batch 25/2200 loss 7.296968 loss_att 383.632324 loss_ctc 13.759300 loss_rnnt 6.578930 lr 0.00026027 rank 5
2022-12-08 02:42:00,990 DEBUG TRAIN Batch 25/2200 loss 12.478784 loss_att 343.466309 loss_ctc 23.487516 loss_rnnt 11.255590 lr 0.00026028 rank 0
2022-12-08 02:42:00,993 DEBUG TRAIN Batch 25/2200 loss 11.787793 loss_att 393.071625 loss_ctc 24.183456 loss_rnnt 10.410498 lr 0.00026029 rank 2
2022-12-08 02:42:01,000 DEBUG TRAIN Batch 25/2200 loss 7.806222 loss_att 456.249451 loss_ctc 20.441540 loss_rnnt 6.402298 lr 0.00026028 rank 6
2022-12-08 02:43:04,231 DEBUG TRAIN Batch 25/2300 loss 9.381586 loss_att 390.909485 loss_ctc 20.924356 loss_rnnt 8.099056 lr 0.00026023 rank 7
2022-12-08 02:43:04,231 DEBUG TRAIN Batch 25/2300 loss 7.246663 loss_att 372.151306 loss_ctc 26.595480 loss_rnnt 5.096794 lr 0.00026024 rank 4
2022-12-08 02:43:04,232 DEBUG TRAIN Batch 25/2300 loss 4.473337 loss_att 387.606140 loss_ctc 9.935095 loss_rnnt 3.866476 lr 0.00026024 rank 6
2022-12-08 02:43:04,233 DEBUG TRAIN Batch 25/2300 loss 5.907911 loss_att 374.150818 loss_ctc 12.455355 loss_rnnt 5.180418 lr 0.00026025 rank 3
2022-12-08 02:43:04,236 DEBUG TRAIN Batch 25/2300 loss 9.393041 loss_att 329.730560 loss_ctc 16.086132 loss_rnnt 8.649364 lr 0.00026025 rank 0
2022-12-08 02:43:04,238 DEBUG TRAIN Batch 25/2300 loss 10.701622 loss_att 360.798157 loss_ctc 21.597588 loss_rnnt 9.490959 lr 0.00026025 rank 2
2022-12-08 02:43:04,240 DEBUG TRAIN Batch 25/2300 loss 6.614559 loss_att 367.676636 loss_ctc 9.752096 loss_rnnt 6.265944 lr 0.00026027 rank 1
2022-12-08 02:43:04,243 DEBUG TRAIN Batch 25/2300 loss 3.684823 loss_att 362.118317 loss_ctc 7.965067 loss_rnnt 3.209240 lr 0.00026024 rank 5
2022-12-08 02:44:07,871 DEBUG TRAIN Batch 25/2400 loss 10.982529 loss_att 351.602966 loss_ctc 17.872728 loss_rnnt 10.216951 lr 0.00026021 rank 4
2022-12-08 02:44:07,872 DEBUG TRAIN Batch 25/2400 loss 11.720692 loss_att 377.403259 loss_ctc 25.807800 loss_rnnt 10.155457 lr 0.00026021 rank 3
2022-12-08 02:44:07,873 DEBUG TRAIN Batch 25/2400 loss 5.311082 loss_att 353.531433 loss_ctc 14.488665 loss_rnnt 4.291351 lr 0.00026024 rank 1
2022-12-08 02:44:07,875 DEBUG TRAIN Batch 25/2400 loss 17.014565 loss_att 357.082520 loss_ctc 23.532837 loss_rnnt 16.290314 lr 0.00026019 rank 7
2022-12-08 02:44:07,876 DEBUG TRAIN Batch 25/2400 loss 11.255084 loss_att 352.255463 loss_ctc 23.993462 loss_rnnt 9.839708 lr 0.00026022 rank 2
2022-12-08 02:44:07,878 DEBUG TRAIN Batch 25/2400 loss 10.577158 loss_att 355.130554 loss_ctc 23.585592 loss_rnnt 9.131776 lr 0.00026021 rank 0
2022-12-08 02:44:07,902 DEBUG TRAIN Batch 25/2400 loss 2.169126 loss_att 359.410706 loss_ctc 6.761144 loss_rnnt 1.658902 lr 0.00026021 rank 6
2022-12-08 02:44:07,916 DEBUG TRAIN Batch 25/2400 loss 8.100161 loss_att 356.660522 loss_ctc 12.887178 loss_rnnt 7.568270 lr 0.00026020 rank 5
2022-12-08 02:45:19,323 DEBUG TRAIN Batch 25/2500 loss 6.794252 loss_att 291.457947 loss_ctc 12.400189 loss_rnnt 6.171371 lr 0.00026017 rank 4
2022-12-08 02:45:19,325 DEBUG TRAIN Batch 25/2500 loss 7.312879 loss_att 210.320068 loss_ctc 13.258021 loss_rnnt 6.652307 lr 0.00026016 rank 7
2022-12-08 02:45:19,327 DEBUG TRAIN Batch 25/2500 loss 10.647426 loss_att 377.122406 loss_ctc 19.377848 loss_rnnt 9.677379 lr 0.00026018 rank 0
2022-12-08 02:45:19,329 DEBUG TRAIN Batch 25/2500 loss 9.262421 loss_att 99.457100 loss_ctc 13.968310 loss_rnnt 8.739545 lr 0.00026018 rank 3
2022-12-08 02:45:19,330 DEBUG TRAIN Batch 25/2500 loss 7.396430 loss_att 315.619293 loss_ctc 15.730777 loss_rnnt 6.470392 lr 0.00026020 rank 1
2022-12-08 02:45:19,331 DEBUG TRAIN Batch 25/2500 loss 5.819518 loss_att 373.349823 loss_ctc 17.729450 loss_rnnt 4.496192 lr 0.00026017 rank 6
2022-12-08 02:45:19,333 DEBUG TRAIN Batch 25/2500 loss 11.627759 loss_att 297.881348 loss_ctc 23.970783 loss_rnnt 10.256312 lr 0.00026017 rank 5
2022-12-08 02:45:19,335 DEBUG TRAIN Batch 25/2500 loss 7.127218 loss_att 278.977295 loss_ctc 15.078723 loss_rnnt 6.243718 lr 0.00026018 rank 2
2022-12-08 02:46:22,968 DEBUG TRAIN Batch 25/2600 loss 6.972324 loss_att 145.834351 loss_ctc 10.496117 loss_rnnt 6.580792 lr 0.00026014 rank 4
2022-12-08 02:46:22,969 DEBUG TRAIN Batch 25/2600 loss 12.589795 loss_att 557.575012 loss_ctc 35.878075 loss_rnnt 10.002209 lr 0.00026012 rank 7
2022-12-08 02:46:22,970 DEBUG TRAIN Batch 25/2600 loss 0.654425 loss_att 179.117767 loss_ctc 2.292101 loss_rnnt 0.472461 lr 0.00026017 rank 1
2022-12-08 02:46:22,971 DEBUG TRAIN Batch 25/2600 loss 5.610661 loss_att 396.161621 loss_ctc 13.294079 loss_rnnt 4.756948 lr 0.00026015 rank 2
2022-12-08 02:46:22,974 DEBUG TRAIN Batch 25/2600 loss 10.671050 loss_att 349.225464 loss_ctc 23.253052 loss_rnnt 9.273050 lr 0.00026014 rank 3
2022-12-08 02:46:22,979 DEBUG TRAIN Batch 25/2600 loss 6.743998 loss_att 77.798439 loss_ctc 12.254805 loss_rnnt 6.131686 lr 0.00026013 rank 5
2022-12-08 02:46:22,979 DEBUG TRAIN Batch 25/2600 loss 4.601404 loss_att 407.527344 loss_ctc 13.262332 loss_rnnt 3.639079 lr 0.00026014 rank 0
2022-12-08 02:46:23,016 DEBUG TRAIN Batch 25/2600 loss 7.604200 loss_att 231.728607 loss_ctc 14.493021 loss_rnnt 6.838775 lr 0.00026014 rank 6
2022-12-08 02:47:26,443 DEBUG TRAIN Batch 25/2700 loss 9.781698 loss_att 424.638275 loss_ctc 22.769253 loss_rnnt 8.338636 lr 0.00026009 rank 7
2022-12-08 02:47:26,444 DEBUG TRAIN Batch 25/2700 loss 2.088886 loss_att 404.047546 loss_ctc 7.210597 loss_rnnt 1.519807 lr 0.00026010 rank 4
2022-12-08 02:47:26,448 DEBUG TRAIN Batch 25/2700 loss 4.112903 loss_att 371.645447 loss_ctc 12.304122 loss_rnnt 3.202767 lr 0.00026013 rank 1
2022-12-08 02:47:26,448 DEBUG TRAIN Batch 25/2700 loss 14.691008 loss_att 405.077087 loss_ctc 27.361473 loss_rnnt 13.283178 lr 0.00026010 rank 5
2022-12-08 02:47:26,449 DEBUG TRAIN Batch 25/2700 loss 2.606237 loss_att 365.787292 loss_ctc 7.232856 loss_rnnt 2.092168 lr 0.00026011 rank 3
2022-12-08 02:47:26,453 DEBUG TRAIN Batch 25/2700 loss 10.702271 loss_att 413.730286 loss_ctc 16.305828 loss_rnnt 10.079655 lr 0.00026011 rank 0
2022-12-08 02:47:26,454 DEBUG TRAIN Batch 25/2700 loss 10.043684 loss_att 455.133636 loss_ctc 23.124830 loss_rnnt 8.590223 lr 0.00026010 rank 6
2022-12-08 02:47:26,456 DEBUG TRAIN Batch 25/2700 loss 7.700593 loss_att 431.115173 loss_ctc 13.797737 loss_rnnt 7.023132 lr 0.00026011 rank 2
2022-12-08 02:48:31,900 DEBUG TRAIN Batch 25/2800 loss 11.570832 loss_att 366.111023 loss_ctc 26.635223 loss_rnnt 9.897011 lr 0.00026005 rank 7
2022-12-08 02:48:31,901 DEBUG TRAIN Batch 25/2800 loss 4.858681 loss_att 385.655579 loss_ctc 9.099345 loss_rnnt 4.387496 lr 0.00026007 rank 6
2022-12-08 02:48:31,902 DEBUG TRAIN Batch 25/2800 loss 4.604571 loss_att 380.317505 loss_ctc 10.024500 loss_rnnt 4.002357 lr 0.00026010 rank 1
2022-12-08 02:48:31,913 DEBUG TRAIN Batch 25/2800 loss 12.794257 loss_att 359.840515 loss_ctc 24.379034 loss_rnnt 11.507060 lr 0.00026007 rank 2
2022-12-08 02:48:31,914 DEBUG TRAIN Batch 25/2800 loss 5.043007 loss_att 392.485291 loss_ctc 9.014818 loss_rnnt 4.601695 lr 0.00026007 rank 4
2022-12-08 02:48:31,916 DEBUG TRAIN Batch 25/2800 loss 5.634251 loss_att 372.796936 loss_ctc 15.409075 loss_rnnt 4.548160 lr 0.00026007 rank 3
2022-12-08 02:48:31,916 DEBUG TRAIN Batch 25/2800 loss 7.365865 loss_att 363.104675 loss_ctc 12.968048 loss_rnnt 6.743400 lr 0.00026006 rank 5
2022-12-08 02:48:31,918 DEBUG TRAIN Batch 25/2800 loss 8.874418 loss_att 403.790833 loss_ctc 19.367905 loss_rnnt 7.708475 lr 0.00026007 rank 0
2022-12-08 02:49:43,144 DEBUG TRAIN Batch 25/2900 loss 3.000541 loss_att 340.536682 loss_ctc 5.619420 loss_rnnt 2.709554 lr 0.00026002 rank 7
2022-12-08 02:49:43,144 DEBUG TRAIN Batch 25/2900 loss 13.158042 loss_att 429.776794 loss_ctc 27.390753 loss_rnnt 11.576630 lr 0.00026003 rank 6
2022-12-08 02:49:43,147 DEBUG TRAIN Batch 25/2900 loss 4.381992 loss_att 333.305511 loss_ctc 7.859803 loss_rnnt 3.995569 lr 0.00026004 rank 2
2022-12-08 02:49:43,149 DEBUG TRAIN Batch 25/2900 loss 4.517803 loss_att 419.909576 loss_ctc 8.066637 loss_rnnt 4.123488 lr 0.00026003 rank 5
2022-12-08 02:49:43,150 DEBUG TRAIN Batch 25/2900 loss 11.599697 loss_att 402.176575 loss_ctc 27.274403 loss_rnnt 9.858063 lr 0.00026003 rank 4
2022-12-08 02:49:43,151 DEBUG TRAIN Batch 25/2900 loss 10.658953 loss_att 400.856659 loss_ctc 21.330051 loss_rnnt 9.473275 lr 0.00026006 rank 1
2022-12-08 02:49:43,152 DEBUG TRAIN Batch 25/2900 loss 8.435175 loss_att 398.098450 loss_ctc 20.152252 loss_rnnt 7.133278 lr 0.00026004 rank 0
2022-12-08 02:49:43,153 DEBUG TRAIN Batch 25/2900 loss 15.667912 loss_att 355.642914 loss_ctc 26.960831 loss_rnnt 14.413144 lr 0.00026004 rank 3
2022-12-08 02:50:46,726 DEBUG TRAIN Batch 25/3000 loss 8.821916 loss_att 406.384064 loss_ctc 21.151024 loss_rnnt 7.452014 lr 0.00026000 rank 6
2022-12-08 02:50:46,727 DEBUG TRAIN Batch 25/3000 loss 7.905059 loss_att 312.883301 loss_ctc 15.359664 loss_rnnt 7.076769 lr 0.00026000 rank 4
2022-12-08 02:50:46,728 DEBUG TRAIN Batch 25/3000 loss 8.835231 loss_att 329.444366 loss_ctc 15.335894 loss_rnnt 8.112935 lr 0.00025999 rank 5
2022-12-08 02:50:46,728 DEBUG TRAIN Batch 25/3000 loss 16.621365 loss_att 332.384705 loss_ctc 30.966145 loss_rnnt 15.027500 lr 0.00025998 rank 7
2022-12-08 02:50:46,731 DEBUG TRAIN Batch 25/3000 loss 6.236008 loss_att 307.636688 loss_ctc 15.234922 loss_rnnt 5.236128 lr 0.00026000 rank 0
2022-12-08 02:50:46,733 DEBUG TRAIN Batch 25/3000 loss 17.932730 loss_att 377.918457 loss_ctc 28.812992 loss_rnnt 16.723812 lr 0.00026000 rank 3
2022-12-08 02:50:46,734 DEBUG TRAIN Batch 25/3000 loss 3.653313 loss_att 382.103821 loss_ctc 10.245279 loss_rnnt 2.920872 lr 0.00026000 rank 2
2022-12-08 02:50:46,734 DEBUG TRAIN Batch 25/3000 loss 7.630318 loss_att 361.894135 loss_ctc 15.970367 loss_rnnt 6.703646 lr 0.00026003 rank 1
2022-12-08 02:51:50,968 DEBUG TRAIN Batch 25/3100 loss 6.131514 loss_att 247.223679 loss_ctc 19.631947 loss_rnnt 4.631466 lr 0.00025995 rank 7
2022-12-08 02:51:50,971 DEBUG TRAIN Batch 25/3100 loss 8.073168 loss_att 346.239319 loss_ctc 16.907118 loss_rnnt 7.091618 lr 0.00025997 rank 2
2022-12-08 02:51:50,972 DEBUG TRAIN Batch 25/3100 loss 8.711624 loss_att 147.752625 loss_ctc 14.703575 loss_rnnt 8.045852 lr 0.00025997 rank 0
2022-12-08 02:51:50,973 DEBUG TRAIN Batch 25/3100 loss 6.237693 loss_att 271.941376 loss_ctc 13.547412 loss_rnnt 5.425502 lr 0.00025997 rank 3
2022-12-08 02:51:50,974 DEBUG TRAIN Batch 25/3100 loss 7.823929 loss_att 302.598999 loss_ctc 16.399555 loss_rnnt 6.871082 lr 0.00025996 rank 4
2022-12-08 02:51:50,974 DEBUG TRAIN Batch 25/3100 loss 8.749777 loss_att 370.281860 loss_ctc 20.260658 loss_rnnt 7.470791 lr 0.00025999 rank 1
2022-12-08 02:51:50,977 DEBUG TRAIN Batch 25/3100 loss 6.488426 loss_att 354.949341 loss_ctc 12.828749 loss_rnnt 5.783945 lr 0.00025996 rank 5
2022-12-08 02:51:51,012 DEBUG TRAIN Batch 25/3100 loss 18.041580 loss_att 350.671814 loss_ctc 30.964756 loss_rnnt 16.605671 lr 0.00025996 rank 6
2022-12-08 02:53:03,943 DEBUG TRAIN Batch 25/3200 loss 3.130034 loss_att 396.764648 loss_ctc 11.813778 loss_rnnt 2.165174 lr 0.00025993 rank 2
2022-12-08 02:53:03,945 DEBUG TRAIN Batch 25/3200 loss 7.029417 loss_att 445.422943 loss_ctc 11.647833 loss_rnnt 6.516260 lr 0.00025991 rank 7
2022-12-08 02:53:03,945 DEBUG TRAIN Batch 25/3200 loss 4.221118 loss_att 298.056854 loss_ctc 9.990643 loss_rnnt 3.580060 lr 0.00025993 rank 6
2022-12-08 02:53:03,945 DEBUG TRAIN Batch 25/3200 loss 15.967310 loss_att 223.986649 loss_ctc 22.922680 loss_rnnt 15.194491 lr 0.00025996 rank 1
2022-12-08 02:53:03,948 DEBUG TRAIN Batch 25/3200 loss 6.963884 loss_att 373.008026 loss_ctc 17.937004 loss_rnnt 5.744649 lr 0.00025993 rank 4
2022-12-08 02:53:03,955 DEBUG TRAIN Batch 25/3200 loss 5.183220 loss_att 422.434265 loss_ctc 7.610545 loss_rnnt 4.913518 lr 0.00025993 rank 0
2022-12-08 02:53:03,970 DEBUG TRAIN Batch 25/3200 loss 2.247027 loss_att 376.371918 loss_ctc 7.157688 loss_rnnt 1.701398 lr 0.00025993 rank 3
2022-12-08 02:53:03,980 DEBUG TRAIN Batch 25/3200 loss 13.274519 loss_att 217.711929 loss_ctc 21.021263 loss_rnnt 12.413771 lr 0.00025992 rank 5
2022-12-08 02:54:07,027 DEBUG TRAIN Batch 25/3300 loss 11.541823 loss_att 363.541199 loss_ctc 20.303410 loss_rnnt 10.568314 lr 0.00025988 rank 7
2022-12-08 02:54:07,028 DEBUG TRAIN Batch 25/3300 loss 9.344710 loss_att 325.896759 loss_ctc 14.510131 loss_rnnt 8.770775 lr 0.00025992 rank 1
2022-12-08 02:54:07,028 DEBUG TRAIN Batch 25/3300 loss 8.487105 loss_att 110.728485 loss_ctc 13.057593 loss_rnnt 7.979274 lr 0.00025989 rank 6
2022-12-08 02:54:07,029 DEBUG TRAIN Batch 25/3300 loss 3.448467 loss_att 396.621765 loss_ctc 6.459597 loss_rnnt 3.113898 lr 0.00025990 rank 2
2022-12-08 02:54:07,030 DEBUG TRAIN Batch 25/3300 loss 5.553541 loss_att 299.553436 loss_ctc 13.058703 loss_rnnt 4.719634 lr 0.00025990 rank 3
2022-12-08 02:54:07,032 DEBUG TRAIN Batch 25/3300 loss 4.783628 loss_att 397.409912 loss_ctc 10.168152 loss_rnnt 4.185348 lr 0.00025989 rank 4
2022-12-08 02:54:07,033 DEBUG TRAIN Batch 25/3300 loss 6.082276 loss_att 383.342285 loss_ctc 13.168699 loss_rnnt 5.294896 lr 0.00025989 rank 0
2022-12-08 02:54:07,034 DEBUG TRAIN Batch 25/3300 loss 9.500296 loss_att 416.145081 loss_ctc 19.637106 loss_rnnt 8.373983 lr 0.00025989 rank 5
2022-12-08 02:55:11,119 DEBUG TRAIN Batch 25/3400 loss 1.669719 loss_att 318.072357 loss_ctc 7.663438 loss_rnnt 1.003750 lr 0.00025984 rank 7
2022-12-08 02:55:11,120 DEBUG TRAIN Batch 25/3400 loss 11.909179 loss_att 324.788727 loss_ctc 17.369116 loss_rnnt 11.302519 lr 0.00025986 rank 4
2022-12-08 02:55:11,126 DEBUG TRAIN Batch 25/3400 loss 3.720962 loss_att 348.515625 loss_ctc 10.288877 loss_rnnt 2.991194 lr 0.00025986 rank 0
2022-12-08 02:55:11,126 DEBUG TRAIN Batch 25/3400 loss 1.707321 loss_att 325.015076 loss_ctc 4.760769 loss_rnnt 1.368049 lr 0.00025986 rank 2
2022-12-08 02:55:11,128 DEBUG TRAIN Batch 25/3400 loss 3.813635 loss_att 309.316833 loss_ctc 7.214459 loss_rnnt 3.435766 lr 0.00025986 rank 6
2022-12-08 02:55:11,129 DEBUG TRAIN Batch 25/3400 loss 13.145000 loss_att 410.671509 loss_ctc 21.370956 loss_rnnt 12.231005 lr 0.00025986 rank 3
2022-12-08 02:55:11,129 DEBUG TRAIN Batch 25/3400 loss 5.385762 loss_att 390.528870 loss_ctc 15.876335 loss_rnnt 4.220143 lr 0.00025985 rank 5
2022-12-08 02:55:11,173 DEBUG TRAIN Batch 25/3400 loss 5.459347 loss_att 379.821991 loss_ctc 12.105188 loss_rnnt 4.720920 lr 0.00025989 rank 1
2022-12-08 02:56:14,969 DEBUG TRAIN Batch 25/3500 loss 11.809664 loss_att 343.491058 loss_ctc 18.969702 loss_rnnt 11.014105 lr 0.00025983 rank 2
2022-12-08 02:56:14,981 DEBUG TRAIN Batch 25/3500 loss 13.801856 loss_att 420.401001 loss_ctc 22.521549 loss_rnnt 12.833001 lr 0.00025982 rank 4
2022-12-08 02:56:14,982 DEBUG TRAIN Batch 25/3500 loss 13.445448 loss_att 395.178314 loss_ctc 24.221891 loss_rnnt 12.248066 lr 0.00025982 rank 0
2022-12-08 02:56:14,982 DEBUG TRAIN Batch 25/3500 loss 10.547150 loss_att 381.742676 loss_ctc 22.451054 loss_rnnt 9.224493 lr 0.00025985 rank 1
2022-12-08 02:56:14,983 DEBUG TRAIN Batch 25/3500 loss 10.871856 loss_att 480.601746 loss_ctc 19.909798 loss_rnnt 9.867640 lr 0.00025981 rank 7
2022-12-08 02:56:14,985 DEBUG TRAIN Batch 25/3500 loss 9.032990 loss_att 368.582855 loss_ctc 19.368780 loss_rnnt 7.884568 lr 0.00025982 rank 5
2022-12-08 02:56:14,996 DEBUG TRAIN Batch 25/3500 loss 3.340077 loss_att 362.843140 loss_ctc 8.390639 loss_rnnt 2.778904 lr 0.00025982 rank 6
2022-12-08 02:56:15,003 DEBUG TRAIN Batch 25/3500 loss 3.551862 loss_att 343.086609 loss_ctc 7.931907 loss_rnnt 3.065190 lr 0.00025983 rank 3
2022-12-08 02:57:27,258 DEBUG TRAIN Batch 25/3600 loss 11.408916 loss_att 415.469513 loss_ctc 16.521133 loss_rnnt 10.840892 lr 0.00025979 rank 2
2022-12-08 02:57:27,259 DEBUG TRAIN Batch 25/3600 loss 2.987561 loss_att 365.594116 loss_ctc 6.971965 loss_rnnt 2.544850 lr 0.00025977 rank 7
2022-12-08 02:57:27,261 DEBUG TRAIN Batch 25/3600 loss 9.901896 loss_att 407.144867 loss_ctc 20.186434 loss_rnnt 8.759170 lr 0.00025979 rank 6
2022-12-08 02:57:27,262 DEBUG TRAIN Batch 25/3600 loss 3.543938 loss_att 297.512939 loss_ctc 7.575953 loss_rnnt 3.095936 lr 0.00025979 rank 3
2022-12-08 02:57:27,262 DEBUG TRAIN Batch 25/3600 loss 11.483136 loss_att 360.363007 loss_ctc 23.706074 loss_rnnt 10.125032 lr 0.00025979 rank 0
2022-12-08 02:57:27,262 DEBUG TRAIN Batch 25/3600 loss 9.450691 loss_att 341.919037 loss_ctc 19.104725 loss_rnnt 8.378021 lr 0.00025979 rank 4
2022-12-08 02:57:27,269 DEBUG TRAIN Batch 25/3600 loss 11.627790 loss_att 399.371552 loss_ctc 27.244648 loss_rnnt 9.892584 lr 0.00025978 rank 5
2022-12-08 02:57:27,269 DEBUG TRAIN Batch 25/3600 loss 4.421077 loss_att 406.249084 loss_ctc 11.930237 loss_rnnt 3.586726 lr 0.00025982 rank 1
2022-12-08 02:58:30,958 DEBUG TRAIN Batch 25/3700 loss 7.255443 loss_att 277.294495 loss_ctc 18.229748 loss_rnnt 6.036076 lr 0.00025976 rank 2
2022-12-08 02:58:30,960 DEBUG TRAIN Batch 25/3700 loss 5.643208 loss_att 322.404053 loss_ctc 12.627880 loss_rnnt 4.867133 lr 0.00025978 rank 1
2022-12-08 02:58:30,961 DEBUG TRAIN Batch 25/3700 loss 7.235794 loss_att 487.069336 loss_ctc 19.260948 loss_rnnt 5.899666 lr 0.00025976 rank 3
2022-12-08 02:58:30,962 DEBUG TRAIN Batch 25/3700 loss 10.137265 loss_att 261.642975 loss_ctc 18.404556 loss_rnnt 9.218678 lr 0.00025975 rank 4
2022-12-08 02:58:30,971 DEBUG TRAIN Batch 25/3700 loss 3.559527 loss_att 350.900848 loss_ctc 10.067671 loss_rnnt 2.836400 lr 0.00025975 rank 6
2022-12-08 02:58:30,972 DEBUG TRAIN Batch 25/3700 loss 6.026975 loss_att 261.132935 loss_ctc 14.126709 loss_rnnt 5.127005 lr 0.00025975 rank 5
2022-12-08 02:58:30,986 DEBUG TRAIN Batch 25/3700 loss 3.111716 loss_att 306.692688 loss_ctc 6.668409 loss_rnnt 2.716527 lr 0.00025974 rank 7
2022-12-08 02:58:30,992 DEBUG TRAIN Batch 25/3700 loss 5.288798 loss_att 172.554459 loss_ctc 11.400017 loss_rnnt 4.609774 lr 0.00025975 rank 0
2022-12-08 02:59:33,970 DEBUG TRAIN Batch 25/3800 loss 5.752758 loss_att 149.104919 loss_ctc 7.913458 loss_rnnt 5.512680 lr 0.00025972 rank 2
2022-12-08 02:59:33,970 DEBUG TRAIN Batch 25/3800 loss 11.497268 loss_att 207.373413 loss_ctc 17.430048 loss_rnnt 10.838070 lr 0.00025970 rank 7
2022-12-08 02:59:33,972 DEBUG TRAIN Batch 25/3800 loss 6.875539 loss_att 446.632050 loss_ctc 12.838127 loss_rnnt 6.213029 lr 0.00025972 rank 0
2022-12-08 02:59:33,972 DEBUG TRAIN Batch 25/3800 loss 5.946617 loss_att 280.220306 loss_ctc 9.807112 loss_rnnt 5.517673 lr 0.00025975 rank 1
2022-12-08 02:59:33,977 DEBUG TRAIN Batch 25/3800 loss 9.091349 loss_att 314.176025 loss_ctc 19.014877 loss_rnnt 7.988735 lr 0.00025972 rank 6
2022-12-08 02:59:33,977 DEBUG TRAIN Batch 25/3800 loss 7.575579 loss_att 406.804504 loss_ctc 20.105751 loss_rnnt 6.183337 lr 0.00025972 rank 4
2022-12-08 02:59:33,979 DEBUG TRAIN Batch 25/3800 loss 10.877650 loss_att 218.374603 loss_ctc 18.068623 loss_rnnt 10.078654 lr 0.00025971 rank 5
2022-12-08 02:59:33,980 DEBUG TRAIN Batch 25/3800 loss 7.409347 loss_att 380.544525 loss_ctc 14.328554 loss_rnnt 6.640546 lr 0.00025972 rank 3
2022-12-08 03:00:39,363 DEBUG TRAIN Batch 25/3900 loss 9.353931 loss_att 364.291016 loss_ctc 24.047661 loss_rnnt 7.721295 lr 0.00025967 rank 7
2022-12-08 03:00:39,364 DEBUG TRAIN Batch 25/3900 loss 22.155807 loss_att 410.971863 loss_ctc 42.911972 loss_rnnt 19.849567 lr 0.00025969 rank 3
2022-12-08 03:00:39,367 DEBUG TRAIN Batch 25/3900 loss 1.788039 loss_att 409.974945 loss_ctc 3.756282 loss_rnnt 1.569346 lr 0.00025968 rank 4
2022-12-08 03:00:39,373 DEBUG TRAIN Batch 25/3900 loss 4.131581 loss_att 430.042664 loss_ctc 10.779942 loss_rnnt 3.392874 lr 0.00025968 rank 5
2022-12-08 03:00:39,375 DEBUG TRAIN Batch 25/3900 loss 7.346175 loss_att 388.477905 loss_ctc 13.529750 loss_rnnt 6.659111 lr 0.00025969 rank 2
2022-12-08 03:00:39,392 DEBUG TRAIN Batch 25/3900 loss 3.781644 loss_att 385.401947 loss_ctc 14.653841 loss_rnnt 2.573622 lr 0.00025971 rank 1
2022-12-08 03:00:39,401 DEBUG TRAIN Batch 25/3900 loss 13.785386 loss_att 356.505310 loss_ctc 30.716564 loss_rnnt 11.904144 lr 0.00025968 rank 0
2022-12-08 03:00:39,415 DEBUG TRAIN Batch 25/3900 loss 8.384686 loss_att 151.267624 loss_ctc 12.999334 loss_rnnt 7.871948 lr 0.00025968 rank 6
2022-12-08 03:01:49,926 DEBUG TRAIN Batch 25/4000 loss 7.709145 loss_att 442.686707 loss_ctc 18.306936 loss_rnnt 6.531612 lr 0.00025968 rank 1
2022-12-08 03:01:49,927 DEBUG TRAIN Batch 25/4000 loss 9.000961 loss_att 367.756714 loss_ctc 21.282787 loss_rnnt 7.636315 lr 0.00025965 rank 0
2022-12-08 03:01:49,928 DEBUG TRAIN Batch 25/4000 loss 9.264594 loss_att 378.922089 loss_ctc 26.978699 loss_rnnt 7.296360 lr 0.00025963 rank 7
2022-12-08 03:01:49,931 DEBUG TRAIN Batch 25/4000 loss 18.982685 loss_att 423.219574 loss_ctc 35.054943 loss_rnnt 17.196878 lr 0.00025965 rank 4
2022-12-08 03:01:49,931 DEBUG TRAIN Batch 25/4000 loss 14.243046 loss_att 389.884766 loss_ctc 24.436523 loss_rnnt 13.110437 lr 0.00025965 rank 2
2022-12-08 03:01:49,932 DEBUG TRAIN Batch 25/4000 loss 4.176226 loss_att 307.072144 loss_ctc 7.376955 loss_rnnt 3.820590 lr 0.00025965 rank 6
2022-12-08 03:01:49,935 DEBUG TRAIN Batch 25/4000 loss 9.369513 loss_att 376.109406 loss_ctc 19.881382 loss_rnnt 8.201527 lr 0.00025965 rank 3
2022-12-08 03:01:49,941 DEBUG TRAIN Batch 25/4000 loss 11.916698 loss_att 387.495300 loss_ctc 20.854174 loss_rnnt 10.923645 lr 0.00025964 rank 5
2022-12-08 03:02:53,623 DEBUG TRAIN Batch 25/4100 loss 11.417635 loss_att 379.282623 loss_ctc 20.445194 loss_rnnt 10.414573 lr 0.00025961 rank 0
2022-12-08 03:02:53,624 DEBUG TRAIN Batch 25/4100 loss 8.065364 loss_att 378.302368 loss_ctc 13.565735 loss_rnnt 7.454212 lr 0.00025961 rank 6
2022-12-08 03:02:53,626 DEBUG TRAIN Batch 25/4100 loss 7.662184 loss_att 383.562469 loss_ctc 12.379621 loss_rnnt 7.138025 lr 0.00025962 rank 3
2022-12-08 03:02:53,627 DEBUG TRAIN Batch 25/4100 loss 13.929608 loss_att 404.073975 loss_ctc 23.611286 loss_rnnt 12.853867 lr 0.00025960 rank 7
2022-12-08 03:02:53,628 DEBUG TRAIN Batch 25/4100 loss 10.198707 loss_att 374.784668 loss_ctc 20.988522 loss_rnnt 8.999839 lr 0.00025961 rank 4
2022-12-08 03:02:53,630 DEBUG TRAIN Batch 25/4100 loss 2.228409 loss_att 334.119232 loss_ctc 5.838529 loss_rnnt 1.827285 lr 0.00025962 rank 2
2022-12-08 03:02:53,633 DEBUG TRAIN Batch 25/4100 loss 10.720234 loss_att 424.140228 loss_ctc 18.943329 loss_rnnt 9.806557 lr 0.00025961 rank 5
2022-12-08 03:02:53,673 DEBUG TRAIN Batch 25/4100 loss 9.887239 loss_att 353.683594 loss_ctc 13.156502 loss_rnnt 9.523989 lr 0.00025964 rank 1
2022-12-08 03:03:57,711 DEBUG TRAIN Batch 25/4200 loss 11.621953 loss_att 391.731567 loss_ctc 30.162458 loss_rnnt 9.561897 lr 0.00025958 rank 4
2022-12-08 03:03:57,723 DEBUG TRAIN Batch 25/4200 loss 6.783729 loss_att 360.121094 loss_ctc 17.106697 loss_rnnt 5.636732 lr 0.00025958 rank 6
2022-12-08 03:03:57,724 DEBUG TRAIN Batch 25/4200 loss 7.632452 loss_att 385.074493 loss_ctc 17.430290 loss_rnnt 6.543803 lr 0.00025961 rank 1
2022-12-08 03:03:57,734 DEBUG TRAIN Batch 25/4200 loss 5.558984 loss_att 337.537537 loss_ctc 11.649965 loss_rnnt 4.882209 lr 0.00025957 rank 5
2022-12-08 03:03:57,738 DEBUG TRAIN Batch 25/4200 loss 4.975579 loss_att 376.222168 loss_ctc 9.308386 loss_rnnt 4.494156 lr 0.00025956 rank 7
2022-12-08 03:03:57,738 DEBUG TRAIN Batch 25/4200 loss 7.853815 loss_att 320.226318 loss_ctc 17.306046 loss_rnnt 6.803567 lr 0.00025958 rank 0
2022-12-08 03:03:57,750 DEBUG TRAIN Batch 25/4200 loss 6.263177 loss_att 323.144318 loss_ctc 11.488122 loss_rnnt 5.682628 lr 0.00025958 rank 3
2022-12-08 03:03:57,765 DEBUG TRAIN Batch 25/4200 loss 6.562846 loss_att 368.565796 loss_ctc 11.063667 loss_rnnt 6.062755 lr 0.00025958 rank 2
2022-12-08 03:05:14,350 DEBUG TRAIN Batch 25/4300 loss 8.386952 loss_att 322.177887 loss_ctc 17.156147 loss_rnnt 7.412598 lr 0.00025953 rank 7
2022-12-08 03:05:14,351 DEBUG TRAIN Batch 25/4300 loss 8.132089 loss_att 286.164886 loss_ctc 18.209482 loss_rnnt 7.012379 lr 0.00025954 rank 4
2022-12-08 03:05:14,352 DEBUG TRAIN Batch 25/4300 loss 9.090239 loss_att 388.740387 loss_ctc 14.738279 loss_rnnt 8.462679 lr 0.00025957 rank 1
2022-12-08 03:05:14,352 DEBUG TRAIN Batch 25/4300 loss 4.704705 loss_att 325.708435 loss_ctc 11.477020 loss_rnnt 3.952226 lr 0.00025954 rank 6
2022-12-08 03:05:14,353 DEBUG TRAIN Batch 25/4300 loss 11.993351 loss_att 270.539612 loss_ctc 21.863707 loss_rnnt 10.896645 lr 0.00025955 rank 3
2022-12-08 03:05:14,356 DEBUG TRAIN Batch 25/4300 loss 7.066665 loss_att 266.939148 loss_ctc 11.974569 loss_rnnt 6.521343 lr 0.00025954 rank 0
2022-12-08 03:05:14,357 DEBUG TRAIN Batch 25/4300 loss 19.173588 loss_att 390.690521 loss_ctc 42.951431 loss_rnnt 16.531605 lr 0.00025954 rank 5
2022-12-08 03:05:14,358 DEBUG TRAIN Batch 25/4300 loss 8.450433 loss_att 294.796936 loss_ctc 20.649986 loss_rnnt 7.094927 lr 0.00025955 rank 2
2022-12-08 03:06:17,926 DEBUG TRAIN Batch 25/4400 loss 5.066262 loss_att 161.294617 loss_ctc 12.379454 loss_rnnt 4.253685 lr 0.00025951 rank 4
2022-12-08 03:06:17,931 DEBUG TRAIN Batch 25/4400 loss 14.128933 loss_att 248.205170 loss_ctc 18.314157 loss_rnnt 13.663908 lr 0.00025949 rank 7
2022-12-08 03:06:17,935 DEBUG TRAIN Batch 25/4400 loss 6.468969 loss_att 204.794861 loss_ctc 12.287512 loss_rnnt 5.822465 lr 0.00025951 rank 2
2022-12-08 03:06:17,936 DEBUG TRAIN Batch 25/4400 loss 5.860436 loss_att 394.279633 loss_ctc 13.028097 loss_rnnt 5.064029 lr 0.00025951 rank 3
2022-12-08 03:06:17,939 DEBUG TRAIN Batch 25/4400 loss 6.030734 loss_att 320.701904 loss_ctc 17.627575 loss_rnnt 4.742196 lr 0.00025954 rank 1
2022-12-08 03:06:17,948 DEBUG TRAIN Batch 25/4400 loss 5.743809 loss_att 486.101440 loss_ctc 12.048193 loss_rnnt 5.043322 lr 0.00025951 rank 0
2022-12-08 03:06:17,959 DEBUG TRAIN Batch 25/4400 loss 8.237880 loss_att 340.488983 loss_ctc 18.770699 loss_rnnt 7.067567 lr 0.00025950 rank 5
2022-12-08 03:06:17,964 DEBUG TRAIN Batch 25/4400 loss 6.847903 loss_att 355.824371 loss_ctc 12.533668 loss_rnnt 6.216151 lr 0.00025951 rank 6
2022-12-08 03:07:21,802 DEBUG TRAIN Batch 25/4500 loss 7.935578 loss_att 447.919128 loss_ctc 19.789278 loss_rnnt 6.618501 lr 0.00025946 rank 7
2022-12-08 03:07:21,805 DEBUG TRAIN Batch 25/4500 loss 17.115156 loss_att 375.215271 loss_ctc 28.310837 loss_rnnt 15.871191 lr 0.00025947 rank 4
2022-12-08 03:07:21,807 DEBUG TRAIN Batch 25/4500 loss 3.148097 loss_att 394.071014 loss_ctc 11.200949 loss_rnnt 2.253335 lr 0.00025948 rank 2
2022-12-08 03:07:21,810 DEBUG TRAIN Batch 25/4500 loss 12.842722 loss_att 121.788986 loss_ctc 15.610236 loss_rnnt 12.535220 lr 0.00025950 rank 1
2022-12-08 03:07:21,813 DEBUG TRAIN Batch 25/4500 loss 9.368087 loss_att 390.865845 loss_ctc 17.519556 loss_rnnt 8.462368 lr 0.00025948 rank 3
2022-12-08 03:07:21,814 DEBUG TRAIN Batch 25/4500 loss 7.918166 loss_att 156.750031 loss_ctc 13.602775 loss_rnnt 7.286542 lr 0.00025947 rank 5
2022-12-08 03:07:21,814 DEBUG TRAIN Batch 25/4500 loss 5.746612 loss_att 347.074188 loss_ctc 9.779858 loss_rnnt 5.298473 lr 0.00025947 rank 0
2022-12-08 03:07:21,850 DEBUG TRAIN Batch 25/4500 loss 4.359126 loss_att 250.859085 loss_ctc 7.699520 loss_rnnt 3.987972 lr 0.00025947 rank 6
2022-12-08 03:08:27,903 DEBUG TRAIN Batch 25/4600 loss 3.426319 loss_att 357.276123 loss_ctc 6.673167 loss_rnnt 3.065558 lr 0.00025944 rank 0
2022-12-08 03:08:27,908 DEBUG TRAIN Batch 25/4600 loss 9.043443 loss_att 434.274628 loss_ctc 25.283752 loss_rnnt 7.238964 lr 0.00025947 rank 1
2022-12-08 03:08:27,912 DEBUG TRAIN Batch 25/4600 loss 5.013921 loss_att 405.478027 loss_ctc 17.887289 loss_rnnt 3.583546 lr 0.00025944 rank 2
2022-12-08 03:08:27,915 DEBUG TRAIN Batch 25/4600 loss 10.463517 loss_att 318.235474 loss_ctc 21.497356 loss_rnnt 9.237535 lr 0.00025944 rank 4
2022-12-08 03:08:27,915 DEBUG TRAIN Batch 25/4600 loss 7.335085 loss_att 439.789551 loss_ctc 24.716694 loss_rnnt 5.403795 lr 0.00025943 rank 5
2022-12-08 03:08:27,919 DEBUG TRAIN Batch 25/4600 loss 10.961574 loss_att 369.705627 loss_ctc 21.817015 loss_rnnt 9.755413 lr 0.00025942 rank 7
2022-12-08 03:08:27,920 DEBUG TRAIN Batch 25/4600 loss 8.573113 loss_att 378.799255 loss_ctc 18.222500 loss_rnnt 7.500959 lr 0.00025944 rank 3
2022-12-08 03:08:27,945 DEBUG TRAIN Batch 25/4600 loss 13.455231 loss_att 397.162445 loss_ctc 22.180182 loss_rnnt 12.485792 lr 0.00025944 rank 6
2022-12-08 03:09:40,857 DEBUG TRAIN Batch 25/4700 loss 5.228727 loss_att 441.082367 loss_ctc 11.720966 loss_rnnt 4.507367 lr 0.00025943 rank 1
2022-12-08 03:09:40,860 DEBUG TRAIN Batch 25/4700 loss 7.091955 loss_att 343.543854 loss_ctc 11.393349 loss_rnnt 6.614023 lr 0.00025940 rank 0
2022-12-08 03:09:40,861 DEBUG TRAIN Batch 25/4700 loss 16.769855 loss_att 484.537292 loss_ctc 34.385540 loss_rnnt 14.812556 lr 0.00025939 rank 7
2022-12-08 03:09:40,862 DEBUG TRAIN Batch 25/4700 loss 10.237431 loss_att 411.527679 loss_ctc 20.079163 loss_rnnt 9.143905 lr 0.00025940 rank 6
2022-12-08 03:09:40,863 DEBUG TRAIN Batch 25/4700 loss 7.518169 loss_att 323.071167 loss_ctc 10.109407 loss_rnnt 7.230254 lr 0.00025940 rank 5
2022-12-08 03:09:40,863 DEBUG TRAIN Batch 25/4700 loss 7.719535 loss_att 367.194641 loss_ctc 15.232586 loss_rnnt 6.884751 lr 0.00025941 rank 3
2022-12-08 03:09:40,864 DEBUG TRAIN Batch 25/4700 loss 3.635839 loss_att 403.805511 loss_ctc 11.832071 loss_rnnt 2.725147 lr 0.00025941 rank 2
2022-12-08 03:09:40,866 DEBUG TRAIN Batch 25/4700 loss 8.377563 loss_att 413.467896 loss_ctc 19.929693 loss_rnnt 7.093993 lr 0.00025940 rank 4
2022-12-08 03:10:44,451 DEBUG TRAIN Batch 25/4800 loss 7.315197 loss_att 373.896790 loss_ctc 13.890381 loss_rnnt 6.584620 lr 0.00025935 rank 7
2022-12-08 03:10:44,452 DEBUG TRAIN Batch 25/4800 loss 9.088320 loss_att 407.545288 loss_ctc 19.379093 loss_rnnt 7.944901 lr 0.00025937 rank 4
2022-12-08 03:10:44,455 DEBUG TRAIN Batch 25/4800 loss 5.845668 loss_att 374.545044 loss_ctc 10.564898 loss_rnnt 5.321309 lr 0.00025940 rank 1
2022-12-08 03:10:44,457 DEBUG TRAIN Batch 25/4800 loss 3.591260 loss_att 320.810303 loss_ctc 6.341646 loss_rnnt 3.285662 lr 0.00025937 rank 6
2022-12-08 03:10:44,460 DEBUG TRAIN Batch 25/4800 loss 6.063554 loss_att 371.746399 loss_ctc 20.568611 loss_rnnt 4.451880 lr 0.00025937 rank 3
2022-12-08 03:10:44,461 DEBUG TRAIN Batch 25/4800 loss 4.890152 loss_att 294.667908 loss_ctc 9.012934 loss_rnnt 4.432066 lr 0.00025937 rank 2
2022-12-08 03:10:44,462 DEBUG TRAIN Batch 25/4800 loss 15.593139 loss_att 378.113403 loss_ctc 27.463949 loss_rnnt 14.274159 lr 0.00025937 rank 0
2022-12-08 03:10:44,500 DEBUG TRAIN Batch 25/4800 loss 6.183005 loss_att 400.364960 loss_ctc 12.134405 loss_rnnt 5.521739 lr 0.00025936 rank 5
2022-12-08 03:11:47,901 DEBUG TRAIN Batch 25/4900 loss 6.488878 loss_att 345.319397 loss_ctc 17.531063 loss_rnnt 5.261969 lr 0.00025932 rank 7
2022-12-08 03:11:47,902 DEBUG TRAIN Batch 25/4900 loss 11.450052 loss_att 280.228210 loss_ctc 15.359273 loss_rnnt 11.015694 lr 0.00025933 rank 4
2022-12-08 03:11:47,903 DEBUG TRAIN Batch 25/4900 loss 5.444957 loss_att 281.453827 loss_ctc 11.471147 loss_rnnt 4.775381 lr 0.00025934 rank 3
2022-12-08 03:11:47,904 DEBUG TRAIN Batch 25/4900 loss 6.028190 loss_att 318.107422 loss_ctc 18.131660 loss_rnnt 4.683360 lr 0.00025934 rank 2
2022-12-08 03:11:47,906 DEBUG TRAIN Batch 25/4900 loss 11.390797 loss_att 336.835205 loss_ctc 22.557835 loss_rnnt 10.150016 lr 0.00025933 rank 0
2022-12-08 03:11:47,908 DEBUG TRAIN Batch 25/4900 loss 4.798705 loss_att 314.065796 loss_ctc 10.719273 loss_rnnt 4.140864 lr 0.00025936 rank 1
2022-12-08 03:11:47,909 DEBUG TRAIN Batch 25/4900 loss 9.489260 loss_att 355.256104 loss_ctc 18.041620 loss_rnnt 8.538998 lr 0.00025933 rank 5
2022-12-08 03:11:47,952 DEBUG TRAIN Batch 25/4900 loss 4.875205 loss_att 350.363983 loss_ctc 10.737934 loss_rnnt 4.223790 lr 0.00025933 rank 6
2022-12-08 03:13:06,538 DEBUG TRAIN Batch 25/5000 loss 7.553391 loss_att 200.309921 loss_ctc 14.086940 loss_rnnt 6.827441 lr 0.00025930 rank 4
2022-12-08 03:13:06,541 DEBUG TRAIN Batch 25/5000 loss 4.215291 loss_att 351.597107 loss_ctc 8.052982 loss_rnnt 3.788880 lr 0.00025930 rank 6
2022-12-08 03:13:06,542 DEBUG TRAIN Batch 25/5000 loss 10.801537 loss_att 302.047241 loss_ctc 21.725210 loss_rnnt 9.587794 lr 0.00025928 rank 7
2022-12-08 03:13:06,543 DEBUG TRAIN Batch 25/5000 loss 12.532077 loss_att 109.370514 loss_ctc 17.946470 loss_rnnt 11.930477 lr 0.00025930 rank 0
2022-12-08 03:13:06,548 DEBUG TRAIN Batch 25/5000 loss 11.159163 loss_att 291.025330 loss_ctc 26.291355 loss_rnnt 9.477808 lr 0.00025930 rank 2
2022-12-08 03:13:06,548 DEBUG TRAIN Batch 25/5000 loss 3.494124 loss_att 304.751343 loss_ctc 12.039257 loss_rnnt 2.544665 lr 0.00025933 rank 1
2022-12-08 03:13:06,551 DEBUG TRAIN Batch 25/5000 loss 4.896178 loss_att 87.064621 loss_ctc 8.046704 loss_rnnt 4.546120 lr 0.00025930 rank 3
2022-12-08 03:13:06,553 DEBUG TRAIN Batch 25/5000 loss 8.805170 loss_att 324.105927 loss_ctc 14.251637 loss_rnnt 8.200006 lr 0.00025929 rank 5
2022-12-08 03:14:10,272 DEBUG TRAIN Batch 25/5100 loss 9.786347 loss_att 101.722717 loss_ctc 12.916090 loss_rnnt 9.438599 lr 0.00025925 rank 7
2022-12-08 03:14:10,272 DEBUG TRAIN Batch 25/5100 loss 3.498745 loss_att 251.709412 loss_ctc 7.658446 loss_rnnt 3.036556 lr 0.00025926 rank 6
2022-12-08 03:14:10,274 DEBUG TRAIN Batch 25/5100 loss 9.294525 loss_att 204.993790 loss_ctc 14.976513 loss_rnnt 8.663194 lr 0.00025929 rank 1
2022-12-08 03:14:10,274 DEBUG TRAIN Batch 25/5100 loss 6.805096 loss_att 412.656189 loss_ctc 15.467665 loss_rnnt 5.842588 lr 0.00025926 rank 4
2022-12-08 03:14:10,276 DEBUG TRAIN Batch 25/5100 loss 8.605201 loss_att 228.370239 loss_ctc 12.991660 loss_rnnt 8.117817 lr 0.00025926 rank 5
2022-12-08 03:14:10,277 DEBUG TRAIN Batch 25/5100 loss 6.240785 loss_att 257.615997 loss_ctc 17.222845 loss_rnnt 5.020556 lr 0.00025927 rank 2
2022-12-08 03:14:10,278 DEBUG TRAIN Batch 25/5100 loss 5.632053 loss_att 396.664398 loss_ctc 15.070819 loss_rnnt 4.583302 lr 0.00025927 rank 0
2022-12-08 03:14:10,315 DEBUG TRAIN Batch 25/5100 loss 7.327315 loss_att 370.959106 loss_ctc 8.461664 loss_rnnt 7.201276 lr 0.00025927 rank 3
2022-12-08 03:15:13,335 DEBUG TRAIN Batch 25/5200 loss 10.799788 loss_att 390.900269 loss_ctc 24.589046 loss_rnnt 9.267647 lr 0.00025923 rank 4
2022-12-08 03:15:13,337 DEBUG TRAIN Batch 25/5200 loss 13.281475 loss_att 372.511597 loss_ctc 23.347305 loss_rnnt 12.163051 lr 0.00025921 rank 7
2022-12-08 03:15:13,338 DEBUG TRAIN Batch 25/5200 loss 8.999516 loss_att 393.881958 loss_ctc 14.025091 loss_rnnt 8.441119 lr 0.00025923 rank 3
2022-12-08 03:15:13,339 DEBUG TRAIN Batch 25/5200 loss 16.598244 loss_att 403.754883 loss_ctc 36.090786 loss_rnnt 14.432406 lr 0.00025923 rank 6
2022-12-08 03:15:13,340 DEBUG TRAIN Batch 25/5200 loss 5.491270 loss_att 374.896729 loss_ctc 13.921458 loss_rnnt 4.554583 lr 0.00025923 rank 0
2022-12-08 03:15:13,341 DEBUG TRAIN Batch 25/5200 loss 2.189918 loss_att 345.479492 loss_ctc 8.281614 loss_rnnt 1.513063 lr 0.00025926 rank 1
2022-12-08 03:15:13,379 DEBUG TRAIN Batch 25/5200 loss 4.780953 loss_att 415.694580 loss_ctc 15.935446 loss_rnnt 3.541565 lr 0.00025922 rank 5
2022-12-08 03:15:13,387 DEBUG TRAIN Batch 25/5200 loss 7.437047 loss_att 424.581879 loss_ctc 10.066328 loss_rnnt 7.144904 lr 0.00025923 rank 2
2022-12-08 03:16:18,571 DEBUG TRAIN Batch 25/5300 loss 4.200478 loss_att 388.849335 loss_ctc 11.368770 loss_rnnt 3.404001 lr 0.00025918 rank 7
2022-12-08 03:16:18,583 DEBUG TRAIN Batch 25/5300 loss 6.811117 loss_att 412.116913 loss_ctc 18.305716 loss_rnnt 5.533939 lr 0.00025919 rank 6
2022-12-08 03:16:18,584 DEBUG TRAIN Batch 25/5300 loss 8.504325 loss_att 397.753143 loss_ctc 17.789625 loss_rnnt 7.472626 lr 0.00025919 rank 4
2022-12-08 03:16:18,593 DEBUG TRAIN Batch 25/5300 loss 3.566824 loss_att 395.251709 loss_ctc 12.132862 loss_rnnt 2.615042 lr 0.00025920 rank 0
2022-12-08 03:16:18,602 DEBUG TRAIN Batch 25/5300 loss 5.388657 loss_att 402.729065 loss_ctc 12.795727 loss_rnnt 4.565649 lr 0.00025920 rank 3
2022-12-08 03:16:18,602 DEBUG TRAIN Batch 25/5300 loss 12.442893 loss_att 382.139648 loss_ctc 24.060207 loss_rnnt 11.152081 lr 0.00025922 rank 1
2022-12-08 03:16:18,615 DEBUG TRAIN Batch 25/5300 loss 5.126628 loss_att 362.324554 loss_ctc 10.240742 loss_rnnt 4.558393 lr 0.00025920 rank 2
2022-12-08 03:16:18,625 DEBUG TRAIN Batch 25/5300 loss 10.269563 loss_att 374.452118 loss_ctc 19.521812 loss_rnnt 9.241535 lr 0.00025919 rank 5
2022-12-08 03:17:35,061 DEBUG TRAIN Batch 25/5400 loss 3.170993 loss_att 382.363770 loss_ctc 6.110037 loss_rnnt 2.844433 lr 0.00025914 rank 7
2022-12-08 03:17:35,061 DEBUG TRAIN Batch 25/5400 loss 7.690094 loss_att 333.900818 loss_ctc 18.406235 loss_rnnt 6.499412 lr 0.00025916 rank 3
2022-12-08 03:17:35,063 DEBUG TRAIN Batch 25/5400 loss 5.474953 loss_att 334.352844 loss_ctc 13.615119 loss_rnnt 4.570489 lr 0.00025916 rank 4
2022-12-08 03:17:35,064 DEBUG TRAIN Batch 25/5400 loss 10.810813 loss_att 375.805969 loss_ctc 19.343555 loss_rnnt 9.862730 lr 0.00025916 rank 0
2022-12-08 03:17:35,067 DEBUG TRAIN Batch 25/5400 loss 7.021235 loss_att 375.857544 loss_ctc 15.403654 loss_rnnt 6.089856 lr 0.00025919 rank 1
2022-12-08 03:17:35,068 DEBUG TRAIN Batch 25/5400 loss 5.349504 loss_att 349.734680 loss_ctc 16.398954 loss_rnnt 4.121788 lr 0.00025916 rank 2
2022-12-08 03:17:35,103 DEBUG TRAIN Batch 25/5400 loss 7.531732 loss_att 348.710876 loss_ctc 10.294022 loss_rnnt 7.224811 lr 0.00025916 rank 6
2022-12-08 03:17:35,127 DEBUG TRAIN Batch 25/5400 loss 6.814052 loss_att 427.220703 loss_ctc 17.617636 loss_rnnt 5.613654 lr 0.00025915 rank 5
2022-12-08 03:18:38,289 DEBUG TRAIN Batch 25/5500 loss 2.787989 loss_att 359.238861 loss_ctc 9.088110 loss_rnnt 2.087976 lr 0.00025911 rank 7
2022-12-08 03:18:38,290 DEBUG TRAIN Batch 25/5500 loss 3.721535 loss_att 314.954010 loss_ctc 10.076119 loss_rnnt 3.015471 lr 0.00025912 rank 4
2022-12-08 03:18:38,291 DEBUG TRAIN Batch 25/5500 loss 11.359866 loss_att 403.044342 loss_ctc 25.623405 loss_rnnt 9.775028 lr 0.00025913 rank 2
2022-12-08 03:18:38,294 DEBUG TRAIN Batch 25/5500 loss 11.523270 loss_att 345.321960 loss_ctc 17.678894 loss_rnnt 10.839312 lr 0.00025913 rank 0
2022-12-08 03:18:38,295 DEBUG TRAIN Batch 25/5500 loss 8.281528 loss_att 283.110870 loss_ctc 12.882500 loss_rnnt 7.770308 lr 0.00025913 rank 3
2022-12-08 03:18:38,299 DEBUG TRAIN Batch 25/5500 loss 11.156779 loss_att 369.321655 loss_ctc 25.353939 loss_rnnt 9.579317 lr 0.00025915 rank 1
2022-12-08 03:18:38,299 DEBUG TRAIN Batch 25/5500 loss 8.532953 loss_att 411.209900 loss_ctc 16.491701 loss_rnnt 7.648648 lr 0.00025912 rank 5
2022-12-08 03:18:38,339 DEBUG TRAIN Batch 25/5500 loss 8.899879 loss_att 401.166504 loss_ctc 22.589523 loss_rnnt 7.378808 lr 0.00025912 rank 6
2022-12-08 03:19:42,039 DEBUG TRAIN Batch 25/5600 loss 11.341659 loss_att 299.980408 loss_ctc 24.205595 loss_rnnt 9.912333 lr 0.00025907 rank 7
2022-12-08 03:19:42,041 DEBUG TRAIN Batch 25/5600 loss 6.278118 loss_att 218.785080 loss_ctc 9.362352 loss_rnnt 5.935425 lr 0.00025909 rank 4
2022-12-08 03:19:42,042 DEBUG TRAIN Batch 25/5600 loss 4.211562 loss_att 331.063538 loss_ctc 7.385094 loss_rnnt 3.858947 lr 0.00025910 rank 2
2022-12-08 03:19:42,042 DEBUG TRAIN Batch 25/5600 loss 9.633098 loss_att 347.056580 loss_ctc 17.751287 loss_rnnt 8.731077 lr 0.00025909 rank 6
2022-12-08 03:19:42,043 DEBUG TRAIN Batch 25/5600 loss 9.131173 loss_att 215.904572 loss_ctc 16.879272 loss_rnnt 8.270273 lr 0.00025909 rank 3
2022-12-08 03:19:42,044 DEBUG TRAIN Batch 25/5600 loss 9.829445 loss_att 363.640259 loss_ctc 21.640654 loss_rnnt 8.517088 lr 0.00025912 rank 1
2022-12-08 03:19:42,046 DEBUG TRAIN Batch 25/5600 loss 6.846040 loss_att 295.594818 loss_ctc 11.315349 loss_rnnt 6.349450 lr 0.00025908 rank 5
2022-12-08 03:19:42,048 DEBUG TRAIN Batch 25/5600 loss 10.439599 loss_att 272.589966 loss_ctc 22.064453 loss_rnnt 9.147948 lr 0.00025909 rank 0
2022-12-08 03:21:03,486 DEBUG TRAIN Batch 25/5700 loss 13.187841 loss_att 207.948044 loss_ctc 21.422291 loss_rnnt 12.272902 lr 0.00025904 rank 7
2022-12-08 03:21:03,492 DEBUG TRAIN Batch 25/5700 loss 2.956831 loss_att 413.550842 loss_ctc 9.561853 loss_rnnt 2.222939 lr 0.00025905 rank 4
2022-12-08 03:21:03,497 DEBUG TRAIN Batch 25/5700 loss 6.996061 loss_att 325.309265 loss_ctc 12.115466 loss_rnnt 6.427238 lr 0.00025906 rank 0
2022-12-08 03:21:03,501 DEBUG TRAIN Batch 25/5700 loss 9.079541 loss_att 461.107422 loss_ctc 17.713026 loss_rnnt 8.120266 lr 0.00025906 rank 3
2022-12-08 03:21:03,501 DEBUG TRAIN Batch 25/5700 loss 6.535224 loss_att 334.123291 loss_ctc 13.477411 loss_rnnt 5.763870 lr 0.00025905 rank 6
2022-12-08 03:21:03,502 DEBUG TRAIN Batch 25/5700 loss 4.332670 loss_att 269.038696 loss_ctc 8.887115 loss_rnnt 3.826621 lr 0.00025906 rank 2
2022-12-08 03:21:03,502 DEBUG TRAIN Batch 25/5700 loss 8.881569 loss_att 293.405762 loss_ctc 17.416256 loss_rnnt 7.933271 lr 0.00025905 rank 5
2022-12-08 03:21:03,537 DEBUG TRAIN Batch 25/5700 loss 7.597442 loss_att 231.934174 loss_ctc 13.302325 loss_rnnt 6.963566 lr 0.00025908 rank 1
2022-12-08 03:22:07,294 DEBUG TRAIN Batch 25/5800 loss 10.840484 loss_att 380.000824 loss_ctc 16.893414 loss_rnnt 10.167936 lr 0.00025902 rank 4
2022-12-08 03:22:07,301 DEBUG TRAIN Batch 25/5800 loss 3.630147 loss_att 413.708496 loss_ctc 8.558150 loss_rnnt 3.082591 lr 0.00025900 rank 7
2022-12-08 03:22:07,302 DEBUG TRAIN Batch 25/5800 loss 0.484881 loss_att 464.556152 loss_ctc 1.618227 loss_rnnt 0.358954 lr 0.00025903 rank 2
2022-12-08 03:22:07,302 DEBUG TRAIN Batch 25/5800 loss 6.196438 loss_att 241.954269 loss_ctc 14.977100 loss_rnnt 5.220809 lr 0.00025902 rank 6
2022-12-08 03:22:07,303 DEBUG TRAIN Batch 25/5800 loss 8.914790 loss_att 379.538574 loss_ctc 21.585701 loss_rnnt 7.506912 lr 0.00025902 rank 0
2022-12-08 03:22:07,325 DEBUG TRAIN Batch 25/5800 loss 13.962048 loss_att 516.500244 loss_ctc 32.569775 loss_rnnt 11.894522 lr 0.00025901 rank 5
2022-12-08 03:22:07,332 DEBUG TRAIN Batch 25/5800 loss 9.263930 loss_att 387.239990 loss_ctc 24.171101 loss_rnnt 7.607578 lr 0.00025902 rank 3
2022-12-08 03:22:07,341 DEBUG TRAIN Batch 25/5800 loss 6.222941 loss_att 376.295410 loss_ctc 12.641752 loss_rnnt 5.509740 lr 0.00025905 rank 1
2022-12-08 03:23:11,186 DEBUG TRAIN Batch 25/5900 loss 7.252278 loss_att 391.078827 loss_ctc 13.628619 loss_rnnt 6.543796 lr 0.00025898 rank 4
2022-12-08 03:23:11,187 DEBUG TRAIN Batch 25/5900 loss 12.719315 loss_att 418.222626 loss_ctc 22.236988 loss_rnnt 11.661796 lr 0.00025897 rank 7
2022-12-08 03:23:11,188 DEBUG TRAIN Batch 25/5900 loss 10.510275 loss_att 409.840179 loss_ctc 20.586819 loss_rnnt 9.390659 lr 0.00025899 rank 2
2022-12-08 03:23:11,192 DEBUG TRAIN Batch 25/5900 loss 6.910016 loss_att 418.856506 loss_ctc 14.477442 loss_rnnt 6.069191 lr 0.00025899 rank 3
2022-12-08 03:23:11,192 DEBUG TRAIN Batch 25/5900 loss 10.612133 loss_att 438.446991 loss_ctc 20.487396 loss_rnnt 9.514882 lr 0.00025898 rank 5
2022-12-08 03:23:11,193 DEBUG TRAIN Batch 25/5900 loss 11.559386 loss_att 407.061859 loss_ctc 19.281546 loss_rnnt 10.701368 lr 0.00025899 rank 0
2022-12-08 03:23:11,194 DEBUG TRAIN Batch 25/5900 loss 12.541319 loss_att 375.022552 loss_ctc 25.901495 loss_rnnt 11.056854 lr 0.00025901 rank 1
2022-12-08 03:23:11,236 DEBUG TRAIN Batch 25/5900 loss 14.043811 loss_att 476.097107 loss_ctc 26.512676 loss_rnnt 12.658381 lr 0.00025898 rank 6
2022-12-08 03:24:15,827 DEBUG TRAIN Batch 25/6000 loss 4.794094 loss_att 319.787781 loss_ctc 8.226479 loss_rnnt 4.412718 lr 0.00025895 rank 4
2022-12-08 03:24:15,831 DEBUG TRAIN Batch 25/6000 loss 9.239023 loss_att 369.604828 loss_ctc 17.637070 loss_rnnt 8.305907 lr 0.00025893 rank 7
2022-12-08 03:24:15,832 DEBUG TRAIN Batch 25/6000 loss 8.729052 loss_att 369.355530 loss_ctc 19.839180 loss_rnnt 7.494593 lr 0.00025896 rank 2
2022-12-08 03:24:15,832 DEBUG TRAIN Batch 25/6000 loss 3.059016 loss_att 426.654907 loss_ctc 9.232584 loss_rnnt 2.373064 lr 0.00025895 rank 0
2022-12-08 03:24:15,833 DEBUG TRAIN Batch 25/6000 loss 4.425452 loss_att 360.678528 loss_ctc 11.967546 loss_rnnt 3.587442 lr 0.00025895 rank 3
2022-12-08 03:24:15,836 DEBUG TRAIN Batch 25/6000 loss 10.396000 loss_att 362.031372 loss_ctc 19.693615 loss_rnnt 9.362932 lr 0.00025894 rank 5
2022-12-08 03:24:15,837 DEBUG TRAIN Batch 25/6000 loss 10.813169 loss_att 385.834045 loss_ctc 21.113016 loss_rnnt 9.668741 lr 0.00025898 rank 1
2022-12-08 03:24:15,871 DEBUG TRAIN Batch 25/6000 loss 3.447188 loss_att 402.135742 loss_ctc 12.872746 loss_rnnt 2.399904 lr 0.00025895 rank 6
2022-12-08 03:25:41,169 DEBUG TRAIN Batch 25/6100 loss 6.202354 loss_att 302.404175 loss_ctc 13.057236 loss_rnnt 5.440701 lr 0.00025891 rank 4
2022-12-08 03:25:41,169 DEBUG TRAIN Batch 25/6100 loss 8.354843 loss_att 382.434235 loss_ctc 18.619709 loss_rnnt 7.214302 lr 0.00025890 rank 7
2022-12-08 03:25:41,174 DEBUG TRAIN Batch 25/6100 loss 7.002614 loss_att 357.444519 loss_ctc 14.690535 loss_rnnt 6.148400 lr 0.00025892 rank 2
2022-12-08 03:25:41,175 DEBUG TRAIN Batch 25/6100 loss 10.399130 loss_att 371.804047 loss_ctc 22.598671 loss_rnnt 9.043625 lr 0.00025892 rank 3
2022-12-08 03:25:41,175 DEBUG TRAIN Batch 25/6100 loss 10.826431 loss_att 295.396362 loss_ctc 20.815825 loss_rnnt 9.716498 lr 0.00025894 rank 1
2022-12-08 03:25:41,177 DEBUG TRAIN Batch 25/6100 loss 24.246672 loss_att 397.681732 loss_ctc 35.844185 loss_rnnt 22.958059 lr 0.00025891 rank 6
2022-12-08 03:25:41,179 DEBUG TRAIN Batch 25/6100 loss 5.587838 loss_att 356.192230 loss_ctc 15.740357 loss_rnnt 4.459780 lr 0.00025892 rank 0
2022-12-08 03:25:41,184 DEBUG TRAIN Batch 25/6100 loss 4.696620 loss_att 351.921265 loss_ctc 6.919872 loss_rnnt 4.449593 lr 0.00025891 rank 5
2022-12-08 03:26:44,110 DEBUG TRAIN Batch 25/6200 loss 8.394414 loss_att 353.538483 loss_ctc 21.159863 loss_rnnt 6.976031 lr 0.00025886 rank 7
2022-12-08 03:26:44,112 DEBUG TRAIN Batch 25/6200 loss 14.016919 loss_att 267.498108 loss_ctc 28.973034 loss_rnnt 12.355129 lr 0.00025888 rank 4
2022-12-08 03:26:44,114 DEBUG TRAIN Batch 25/6200 loss 9.815764 loss_att 312.585205 loss_ctc 16.354115 loss_rnnt 9.089281 lr 0.00025888 rank 6
2022-12-08 03:26:44,113 DEBUG TRAIN Batch 25/6200 loss 10.545981 loss_att 370.714111 loss_ctc 16.000366 loss_rnnt 9.939939 lr 0.00025891 rank 1
2022-12-08 03:26:44,118 DEBUG TRAIN Batch 25/6200 loss 7.402547 loss_att 269.271210 loss_ctc 16.028006 loss_rnnt 6.444163 lr 0.00025888 rank 3
2022-12-08 03:26:44,119 DEBUG TRAIN Batch 25/6200 loss 6.090780 loss_att 315.969513 loss_ctc 15.151012 loss_rnnt 5.084088 lr 0.00025888 rank 0
2022-12-08 03:26:44,121 DEBUG TRAIN Batch 25/6200 loss 14.960766 loss_att 352.619690 loss_ctc 46.780327 loss_rnnt 11.425259 lr 0.00025888 rank 5
2022-12-08 03:26:44,161 DEBUG TRAIN Batch 25/6200 loss 5.899499 loss_att 323.571533 loss_ctc 23.087343 loss_rnnt 3.989739 lr 0.00025889 rank 2
2022-12-08 03:27:47,395 DEBUG TRAIN Batch 25/6300 loss 6.818764 loss_att 156.017456 loss_ctc 11.552861 loss_rnnt 6.292753 lr 0.00025885 rank 0
2022-12-08 03:27:47,395 DEBUG TRAIN Batch 25/6300 loss 6.515667 loss_att 394.595306 loss_ctc 13.133628 loss_rnnt 5.780338 lr 0.00025884 rank 4
2022-12-08 03:27:47,397 DEBUG TRAIN Batch 25/6300 loss 5.376426 loss_att 226.610153 loss_ctc 10.694853 loss_rnnt 4.785490 lr 0.00025883 rank 7
2022-12-08 03:27:47,404 DEBUG TRAIN Batch 25/6300 loss 9.114304 loss_att 305.396057 loss_ctc 16.013832 loss_rnnt 8.347690 lr 0.00025885 rank 2
2022-12-08 03:27:47,404 DEBUG TRAIN Batch 25/6300 loss 8.055319 loss_att 340.649536 loss_ctc 16.397333 loss_rnnt 7.128428 lr 0.00025884 rank 6
2022-12-08 03:27:47,406 DEBUG TRAIN Batch 25/6300 loss 16.750069 loss_att 402.033447 loss_ctc 23.450638 loss_rnnt 16.005562 lr 0.00025885 rank 3
2022-12-08 03:27:47,407 DEBUG TRAIN Batch 25/6300 loss 5.759070 loss_att 313.982452 loss_ctc 13.253135 loss_rnnt 4.926396 lr 0.00025884 rank 5
2022-12-08 03:27:47,410 DEBUG TRAIN Batch 25/6300 loss 8.602116 loss_att 261.043427 loss_ctc 17.565626 loss_rnnt 7.606170 lr 0.00025887 rank 1
2022-12-08 03:29:13,007 DEBUG TRAIN Batch 25/6400 loss 16.603191 loss_att 303.553101 loss_ctc 19.808704 loss_rnnt 16.247023 lr 0.00025881 rank 6
2022-12-08 03:29:13,017 DEBUG TRAIN Batch 25/6400 loss 10.309982 loss_att 433.524017 loss_ctc 20.369339 loss_rnnt 9.192276 lr 0.00025881 rank 4
2022-12-08 03:29:13,017 DEBUG TRAIN Batch 25/6400 loss 5.927782 loss_att 330.563354 loss_ctc 12.980078 loss_rnnt 5.144194 lr 0.00025880 rank 7
2022-12-08 03:29:13,018 DEBUG TRAIN Batch 25/6400 loss 5.746489 loss_att 369.982880 loss_ctc 16.653641 loss_rnnt 4.534583 lr 0.00025882 rank 3
2022-12-08 03:29:13,028 DEBUG TRAIN Batch 25/6400 loss 8.047154 loss_att 100.276093 loss_ctc 12.276935 loss_rnnt 7.577179 lr 0.00025882 rank 2
2022-12-08 03:29:13,030 DEBUG TRAIN Batch 25/6400 loss 9.450824 loss_att 277.766754 loss_ctc 14.193903 loss_rnnt 8.923815 lr 0.00025881 rank 5
2022-12-08 03:29:13,034 DEBUG TRAIN Batch 25/6400 loss 9.727114 loss_att 456.753418 loss_ctc 27.309444 loss_rnnt 7.773521 lr 0.00025884 rank 1
2022-12-08 03:29:13,051 DEBUG TRAIN Batch 25/6400 loss 9.834098 loss_att 410.881775 loss_ctc 23.506580 loss_rnnt 8.314933 lr 0.00025881 rank 0
2022-12-08 03:30:16,392 DEBUG TRAIN Batch 25/6500 loss 6.383397 loss_att 341.885742 loss_ctc 11.471575 loss_rnnt 5.818043 lr 0.00025877 rank 4
2022-12-08 03:30:16,392 DEBUG TRAIN Batch 25/6500 loss 9.890726 loss_att 337.770477 loss_ctc 20.509182 loss_rnnt 8.710897 lr 0.00025876 rank 7
2022-12-08 03:30:16,394 DEBUG TRAIN Batch 25/6500 loss 5.308352 loss_att 408.843567 loss_ctc 14.080684 loss_rnnt 4.333648 lr 0.00025878 rank 2
2022-12-08 03:30:16,395 DEBUG TRAIN Batch 25/6500 loss 7.797187 loss_att 435.616943 loss_ctc 16.988253 loss_rnnt 6.775958 lr 0.00025878 rank 6
2022-12-08 03:30:16,400 DEBUG TRAIN Batch 25/6500 loss 9.763398 loss_att 454.719330 loss_ctc 18.640545 loss_rnnt 8.777049 lr 0.00025878 rank 0
2022-12-08 03:30:16,413 DEBUG TRAIN Batch 25/6500 loss 13.792417 loss_att 397.677216 loss_ctc 26.782330 loss_rnnt 12.349093 lr 0.00025881 rank 1
2022-12-08 03:30:16,421 DEBUG TRAIN Batch 25/6500 loss 9.776579 loss_att 390.647552 loss_ctc 19.359676 loss_rnnt 8.711790 lr 0.00025878 rank 3
2022-12-08 03:30:16,438 DEBUG TRAIN Batch 25/6500 loss 6.096430 loss_att 409.855591 loss_ctc 15.434885 loss_rnnt 5.058824 lr 0.00025877 rank 5
2022-12-08 03:31:19,325 DEBUG TRAIN Batch 25/6600 loss 8.294421 loss_att 385.316284 loss_ctc 13.327881 loss_rnnt 7.735148 lr 0.00025874 rank 4
2022-12-08 03:31:19,326 DEBUG TRAIN Batch 25/6600 loss 9.092725 loss_att 394.631195 loss_ctc 18.269674 loss_rnnt 8.073064 lr 0.00025873 rank 7
2022-12-08 03:31:19,327 DEBUG TRAIN Batch 25/6600 loss 4.405342 loss_att 356.853699 loss_ctc 8.988437 loss_rnnt 3.896109 lr 0.00025875 rank 2
2022-12-08 03:31:19,328 DEBUG TRAIN Batch 25/6600 loss 13.904262 loss_att 420.630890 loss_ctc 24.720982 loss_rnnt 12.702404 lr 0.00025874 rank 0
2022-12-08 03:31:19,328 DEBUG TRAIN Batch 25/6600 loss 7.504832 loss_att 369.560364 loss_ctc 18.149052 loss_rnnt 6.322141 lr 0.00025874 rank 6
2022-12-08 03:31:19,331 DEBUG TRAIN Batch 25/6600 loss 4.940989 loss_att 341.305573 loss_ctc 12.593002 loss_rnnt 4.090765 lr 0.00025877 rank 1
2022-12-08 03:31:19,332 DEBUG TRAIN Batch 25/6600 loss 5.510859 loss_att 374.137665 loss_ctc 17.139370 loss_rnnt 4.218802 lr 0.00025875 rank 3
2022-12-08 03:31:19,335 DEBUG TRAIN Batch 25/6600 loss 9.555695 loss_att 425.798431 loss_ctc 16.172659 loss_rnnt 8.820477 lr 0.00025874 rank 5
2022-12-08 03:32:23,921 DEBUG TRAIN Batch 25/6700 loss 3.652670 loss_att 323.107605 loss_ctc 8.886024 loss_rnnt 3.071186 lr 0.00025871 rank 0
2022-12-08 03:32:23,934 DEBUG TRAIN Batch 25/6700 loss 6.295607 loss_att 430.810913 loss_ctc 18.430506 loss_rnnt 4.947285 lr 0.00025874 rank 1
2022-12-08 03:32:23,934 DEBUG TRAIN Batch 25/6700 loss 14.717151 loss_att 433.258118 loss_ctc 31.751554 loss_rnnt 12.824439 lr 0.00025871 rank 3
2022-12-08 03:32:23,939 DEBUG TRAIN Batch 25/6700 loss 2.491007 loss_att 349.375732 loss_ctc 6.224858 loss_rnnt 2.076134 lr 0.00025871 rank 6
2022-12-08 03:32:23,946 DEBUG TRAIN Batch 25/6700 loss 7.458410 loss_att 334.560913 loss_ctc 16.676125 loss_rnnt 6.434219 lr 0.00025871 rank 4
2022-12-08 03:32:23,951 DEBUG TRAIN Batch 25/6700 loss 4.372272 loss_att 335.082886 loss_ctc 15.172736 loss_rnnt 3.172221 lr 0.00025871 rank 2
2022-12-08 03:32:23,953 DEBUG TRAIN Batch 25/6700 loss 9.591619 loss_att 372.060883 loss_ctc 19.985100 loss_rnnt 8.436789 lr 0.00025869 rank 7
2022-12-08 03:32:23,960 DEBUG TRAIN Batch 25/6700 loss 13.117861 loss_att 348.044403 loss_ctc 27.086834 loss_rnnt 11.565752 lr 0.00025870 rank 5
2022-12-08 03:33:50,495 DEBUG TRAIN Batch 25/6800 loss 3.683973 loss_att 326.961487 loss_ctc 9.857387 loss_rnnt 2.998038 lr 0.00025867 rank 4
2022-12-08 03:33:50,496 DEBUG TRAIN Batch 25/6800 loss 4.398393 loss_att 353.169617 loss_ctc 11.864849 loss_rnnt 3.568787 lr 0.00025868 rank 2
2022-12-08 03:33:50,496 DEBUG TRAIN Batch 25/6800 loss 6.672930 loss_att 310.814453 loss_ctc 9.597564 loss_rnnt 6.347971 lr 0.00025867 rank 6
2022-12-08 03:33:50,497 DEBUG TRAIN Batch 25/6800 loss 7.417309 loss_att 350.852722 loss_ctc 18.491447 loss_rnnt 6.186850 lr 0.00025866 rank 7
2022-12-08 03:33:50,500 DEBUG TRAIN Batch 25/6800 loss 9.245310 loss_att 358.668335 loss_ctc 19.514027 loss_rnnt 8.104342 lr 0.00025867 rank 0
2022-12-08 03:33:50,504 DEBUG TRAIN Batch 25/6800 loss 7.665421 loss_att 389.604980 loss_ctc 11.831713 loss_rnnt 7.202500 lr 0.00025870 rank 1
2022-12-08 03:33:50,508 DEBUG TRAIN Batch 25/6800 loss 9.711866 loss_att 359.171875 loss_ctc 18.386761 loss_rnnt 8.747990 lr 0.00025868 rank 3
2022-12-08 03:33:50,543 DEBUG TRAIN Batch 25/6800 loss 4.661582 loss_att 360.248230 loss_ctc 10.324193 loss_rnnt 4.032403 lr 0.00025867 rank 5
2022-12-08 03:34:54,470 DEBUG TRAIN Batch 25/6900 loss 4.779035 loss_att 413.488617 loss_ctc 8.632155 loss_rnnt 4.350910 lr 0.00025864 rank 4
2022-12-08 03:34:54,475 DEBUG TRAIN Batch 25/6900 loss 7.642652 loss_att 370.718903 loss_ctc 12.831934 loss_rnnt 7.066065 lr 0.00025862 rank 7
2022-12-08 03:34:54,476 DEBUG TRAIN Batch 25/6900 loss 8.932292 loss_att 340.981354 loss_ctc 14.439153 loss_rnnt 8.320419 lr 0.00025864 rank 0
2022-12-08 03:34:54,477 DEBUG TRAIN Batch 25/6900 loss 4.821791 loss_att 346.653809 loss_ctc 12.850389 loss_rnnt 3.929725 lr 0.00025864 rank 2
2022-12-08 03:34:54,479 DEBUG TRAIN Batch 25/6900 loss 2.743027 loss_att 326.441376 loss_ctc 8.505009 loss_rnnt 2.102807 lr 0.00025864 rank 6
2022-12-08 03:34:54,480 DEBUG TRAIN Batch 25/6900 loss 2.983057 loss_att 323.505676 loss_ctc 8.378099 loss_rnnt 2.383608 lr 0.00025863 rank 5
2022-12-08 03:34:54,485 DEBUG TRAIN Batch 25/6900 loss 5.503324 loss_att 290.576172 loss_ctc 12.593527 loss_rnnt 4.715524 lr 0.00025867 rank 1
2022-12-08 03:34:54,515 DEBUG TRAIN Batch 25/6900 loss 9.003009 loss_att 221.881516 loss_ctc 14.840771 loss_rnnt 8.354369 lr 0.00025864 rank 3
2022-12-08 03:35:57,858 DEBUG TRAIN Batch 25/7000 loss 7.376745 loss_att 242.220016 loss_ctc 14.826552 loss_rnnt 6.548989 lr 0.00025859 rank 7
2022-12-08 03:35:57,858 DEBUG TRAIN Batch 25/7000 loss 6.410280 loss_att 327.796234 loss_ctc 10.567481 loss_rnnt 5.948370 lr 0.00025860 rank 6
2022-12-08 03:35:57,861 DEBUG TRAIN Batch 25/7000 loss 14.451976 loss_att 269.132385 loss_ctc 26.945675 loss_rnnt 13.063787 lr 0.00025861 rank 2
2022-12-08 03:35:57,862 DEBUG TRAIN Batch 25/7000 loss 12.311782 loss_att 346.421021 loss_ctc 16.966179 loss_rnnt 11.794627 lr 0.00025860 rank 4
2022-12-08 03:35:57,863 DEBUG TRAIN Batch 25/7000 loss 6.915763 loss_att 284.272003 loss_ctc 16.861240 loss_rnnt 5.810710 lr 0.00025860 rank 5
2022-12-08 03:35:57,863 DEBUG TRAIN Batch 25/7000 loss 7.603877 loss_att 142.881485 loss_ctc 12.341782 loss_rnnt 7.077443 lr 0.00025863 rank 1
2022-12-08 03:35:57,863 DEBUG TRAIN Batch 25/7000 loss 4.041233 loss_att 390.812866 loss_ctc 5.553136 loss_rnnt 3.873243 lr 0.00025861 rank 3
2022-12-08 03:35:57,865 DEBUG TRAIN Batch 25/7000 loss 4.688029 loss_att 404.714600 loss_ctc 9.308977 loss_rnnt 4.174590 lr 0.00025861 rank 0
2022-12-08 03:37:18,925 DEBUG TRAIN Batch 25/7100 loss 5.153029 loss_att 385.095551 loss_ctc 9.765795 loss_rnnt 4.640499 lr 0.00025857 rank 4
2022-12-08 03:37:18,928 DEBUG TRAIN Batch 25/7100 loss 16.435690 loss_att 386.998291 loss_ctc 34.047386 loss_rnnt 14.478834 lr 0.00025857 rank 0
2022-12-08 03:37:18,931 DEBUG TRAIN Batch 25/7100 loss 7.818261 loss_att 379.584656 loss_ctc 18.473602 loss_rnnt 6.634335 lr 0.00025857 rank 3
2022-12-08 03:37:18,933 DEBUG TRAIN Batch 25/7100 loss 6.875249 loss_att 373.516357 loss_ctc 10.708115 loss_rnnt 6.449375 lr 0.00025860 rank 1
2022-12-08 03:37:18,948 DEBUG TRAIN Batch 25/7100 loss 12.438403 loss_att 459.672821 loss_ctc 36.486835 loss_rnnt 9.766356 lr 0.00025857 rank 6
2022-12-08 03:37:18,951 DEBUG TRAIN Batch 25/7100 loss 5.056064 loss_att 77.015068 loss_ctc 8.014868 loss_rnnt 4.727307 lr 0.00025856 rank 5
2022-12-08 03:37:18,953 DEBUG TRAIN Batch 25/7100 loss 13.881475 loss_att 377.674286 loss_ctc 27.082676 loss_rnnt 12.414676 lr 0.00025857 rank 2
2022-12-08 03:37:18,966 DEBUG TRAIN Batch 25/7100 loss 16.830147 loss_att 505.436462 loss_ctc 34.750622 loss_rnnt 14.838984 lr 0.00025855 rank 7
2022-12-08 03:38:23,490 DEBUG TRAIN Batch 25/7200 loss 3.721627 loss_att 435.767822 loss_ctc 14.447040 loss_rnnt 2.529915 lr 0.00025852 rank 7
2022-12-08 03:38:23,509 DEBUG TRAIN Batch 25/7200 loss 3.491718 loss_att 366.495575 loss_ctc 10.459080 loss_rnnt 2.717567 lr 0.00025856 rank 1
2022-12-08 03:38:23,512 DEBUG TRAIN Batch 25/7200 loss 3.355586 loss_att 338.104614 loss_ctc 5.451902 loss_rnnt 3.122662 lr 0.00025854 rank 0
2022-12-08 03:38:23,514 DEBUG TRAIN Batch 25/7200 loss 6.461724 loss_att 370.408600 loss_ctc 17.679087 loss_rnnt 5.215350 lr 0.00025853 rank 4
2022-12-08 03:38:23,514 DEBUG TRAIN Batch 25/7200 loss 3.561117 loss_att 336.896820 loss_ctc 8.121135 loss_rnnt 3.054448 lr 0.00025853 rank 6
2022-12-08 03:38:23,516 DEBUG TRAIN Batch 25/7200 loss 13.327180 loss_att 417.321899 loss_ctc 26.769491 loss_rnnt 11.833590 lr 0.00025853 rank 5
2022-12-08 03:38:23,519 DEBUG TRAIN Batch 25/7200 loss 14.559256 loss_att 393.646057 loss_ctc 25.546394 loss_rnnt 13.338463 lr 0.00025854 rank 3
2022-12-08 03:38:23,551 DEBUG TRAIN Batch 25/7200 loss 5.525659 loss_att 419.300659 loss_ctc 11.951212 loss_rnnt 4.811708 lr 0.00025854 rank 2
2022-12-08 03:39:26,966 DEBUG TRAIN Batch 25/7300 loss 10.190104 loss_att 378.584503 loss_ctc 21.622242 loss_rnnt 8.919866 lr 0.00025850 rank 4
2022-12-08 03:39:26,971 DEBUG TRAIN Batch 25/7300 loss 4.577810 loss_att 422.223633 loss_ctc 8.682185 loss_rnnt 4.121768 lr 0.00025851 rank 2
2022-12-08 03:39:26,973 DEBUG TRAIN Batch 25/7300 loss 8.023770 loss_att 338.446075 loss_ctc 13.356498 loss_rnnt 7.431245 lr 0.00025850 rank 3
2022-12-08 03:39:26,974 DEBUG TRAIN Batch 25/7300 loss 10.583189 loss_att 386.676605 loss_ctc 19.771503 loss_rnnt 9.562265 lr 0.00025849 rank 5
2022-12-08 03:39:26,976 DEBUG TRAIN Batch 25/7300 loss 7.738500 loss_att 373.531738 loss_ctc 16.313118 loss_rnnt 6.785765 lr 0.00025848 rank 7
2022-12-08 03:39:26,983 DEBUG TRAIN Batch 25/7300 loss 6.314725 loss_att 390.494446 loss_ctc 15.849088 loss_rnnt 5.255351 lr 0.00025853 rank 1
2022-12-08 03:39:27,018 DEBUG TRAIN Batch 25/7300 loss 9.012199 loss_att 442.876587 loss_ctc 19.119139 loss_rnnt 7.889207 lr 0.00025850 rank 6
2022-12-08 03:39:27,019 DEBUG TRAIN Batch 25/7300 loss 9.496310 loss_att 356.282349 loss_ctc 18.264011 loss_rnnt 8.522121 lr 0.00025850 rank 0
2022-12-08 03:40:31,159 DEBUG TRAIN Batch 25/7400 loss 8.842509 loss_att 314.060455 loss_ctc 15.973572 loss_rnnt 8.050169 lr 0.00025846 rank 4
2022-12-08 03:40:31,159 DEBUG TRAIN Batch 25/7400 loss 9.075232 loss_att 369.434967 loss_ctc 14.575146 loss_rnnt 8.464130 lr 0.00025845 rank 7
2022-12-08 03:40:31,164 DEBUG TRAIN Batch 25/7400 loss 14.698009 loss_att 388.978241 loss_ctc 34.314777 loss_rnnt 12.518369 lr 0.00025849 rank 1
2022-12-08 03:40:31,167 DEBUG TRAIN Batch 25/7400 loss 11.185316 loss_att 353.747345 loss_ctc 23.535435 loss_rnnt 9.813081 lr 0.00025847 rank 2
2022-12-08 03:40:31,168 DEBUG TRAIN Batch 25/7400 loss 9.494594 loss_att 376.106537 loss_ctc 16.475845 loss_rnnt 8.718899 lr 0.00025847 rank 0
2022-12-08 03:40:31,168 DEBUG TRAIN Batch 25/7400 loss 11.859452 loss_att 352.644348 loss_ctc 28.809130 loss_rnnt 9.976155 lr 0.00025847 rank 3
2022-12-08 03:40:31,198 DEBUG TRAIN Batch 25/7400 loss 17.919926 loss_att 349.223816 loss_ctc 38.140316 loss_rnnt 15.673215 lr 0.00025846 rank 5
2022-12-08 03:40:31,203 DEBUG TRAIN Batch 25/7400 loss 14.177129 loss_att 365.702545 loss_ctc 20.794861 loss_rnnt 13.441826 lr 0.00025846 rank 6
2022-12-08 03:41:44,266 DEBUG TRAIN Batch 25/7500 loss 9.282069 loss_att 365.498901 loss_ctc 16.761782 loss_rnnt 8.450990 lr 0.00025842 rank 7
2022-12-08 03:41:44,269 DEBUG TRAIN Batch 25/7500 loss 7.252580 loss_att 202.441452 loss_ctc 14.627191 loss_rnnt 6.433179 lr 0.00025843 rank 4
2022-12-08 03:41:44,273 DEBUG TRAIN Batch 25/7500 loss 9.316561 loss_att 360.559509 loss_ctc 20.722786 loss_rnnt 8.049202 lr 0.00025843 rank 6
2022-12-08 03:41:44,276 DEBUG TRAIN Batch 25/7500 loss 6.404866 loss_att 365.507416 loss_ctc 12.927397 loss_rnnt 5.680140 lr 0.00025843 rank 5
2022-12-08 03:41:44,279 DEBUG TRAIN Batch 25/7500 loss 12.136039 loss_att 276.539062 loss_ctc 25.591032 loss_rnnt 10.641040 lr 0.00025843 rank 0
2022-12-08 03:41:44,279 DEBUG TRAIN Batch 25/7500 loss 2.813471 loss_att 272.566864 loss_ctc 6.851871 loss_rnnt 2.364760 lr 0.00025844 rank 3
2022-12-08 03:41:44,281 DEBUG TRAIN Batch 25/7500 loss 8.926851 loss_att 303.054138 loss_ctc 14.017427 loss_rnnt 8.361232 lr 0.00025844 rank 2
2022-12-08 03:41:44,284 DEBUG TRAIN Batch 25/7500 loss 13.858417 loss_att 325.002167 loss_ctc 16.711437 loss_rnnt 13.541415 lr 0.00025846 rank 1
2022-12-08 03:42:48,436 DEBUG TRAIN Batch 25/7600 loss 4.911542 loss_att 342.054749 loss_ctc 9.976142 loss_rnnt 4.348809 lr 0.00025840 rank 2
2022-12-08 03:42:48,437 DEBUG TRAIN Batch 25/7600 loss 6.279942 loss_att 343.842834 loss_ctc 21.337860 loss_rnnt 4.606840 lr 0.00025839 rank 4
2022-12-08 03:42:48,437 DEBUG TRAIN Batch 25/7600 loss 10.659197 loss_att 329.971497 loss_ctc 23.547958 loss_rnnt 9.227112 lr 0.00025838 rank 7
2022-12-08 03:42:48,438 DEBUG TRAIN Batch 25/7600 loss 2.126263 loss_att 400.559906 loss_ctc 7.838168 loss_rnnt 1.491607 lr 0.00025840 rank 3
2022-12-08 03:42:48,439 DEBUG TRAIN Batch 25/7600 loss 13.625563 loss_att 357.388794 loss_ctc 25.593307 loss_rnnt 12.295814 lr 0.00025839 rank 6
2022-12-08 03:42:48,440 DEBUG TRAIN Batch 25/7600 loss 9.078172 loss_att 364.886963 loss_ctc 18.836437 loss_rnnt 7.993920 lr 0.00025839 rank 5
2022-12-08 03:42:48,440 DEBUG TRAIN Batch 25/7600 loss 9.842983 loss_att 149.800537 loss_ctc 17.307220 loss_rnnt 9.013623 lr 0.00025842 rank 1
2022-12-08 03:42:48,442 DEBUG TRAIN Batch 25/7600 loss 9.620760 loss_att 105.240143 loss_ctc 15.212903 loss_rnnt 8.999412 lr 0.00025840 rank 0
2022-12-08 03:43:51,915 DEBUG TRAIN Batch 25/7700 loss 16.739101 loss_att 340.846527 loss_ctc 28.053885 loss_rnnt 15.481905 lr 0.00025836 rank 4
2022-12-08 03:43:51,916 DEBUG TRAIN Batch 25/7700 loss 6.595974 loss_att 83.338364 loss_ctc 9.555063 loss_rnnt 6.267187 lr 0.00025835 rank 7
2022-12-08 03:43:51,917 DEBUG TRAIN Batch 25/7700 loss 6.961187 loss_att 403.475525 loss_ctc 15.803776 loss_rnnt 5.978677 lr 0.00025837 rank 3
2022-12-08 03:43:51,923 DEBUG TRAIN Batch 25/7700 loss 4.379577 loss_att 432.296478 loss_ctc 13.791457 loss_rnnt 3.333812 lr 0.00025837 rank 2
2022-12-08 03:43:51,923 DEBUG TRAIN Batch 25/7700 loss 17.020370 loss_att 227.940491 loss_ctc 26.787882 loss_rnnt 15.935093 lr 0.00025836 rank 5
2022-12-08 03:43:51,924 DEBUG TRAIN Batch 25/7700 loss 12.192401 loss_att 388.686218 loss_ctc 23.703079 loss_rnnt 10.913437 lr 0.00025839 rank 1
2022-12-08 03:43:51,925 DEBUG TRAIN Batch 25/7700 loss 7.701396 loss_att 402.603333 loss_ctc 11.383207 loss_rnnt 7.292306 lr 0.00025836 rank 0
2022-12-08 03:43:51,961 DEBUG TRAIN Batch 25/7700 loss 4.128598 loss_att 281.181366 loss_ctc 7.258527 loss_rnnt 3.780828 lr 0.00025836 rank 6
2022-12-08 03:44:57,627 DEBUG TRAIN Batch 25/7800 loss 10.183828 loss_att 397.947266 loss_ctc 15.551200 loss_rnnt 9.587454 lr 0.00025833 rank 3
2022-12-08 03:44:57,632 DEBUG TRAIN Batch 25/7800 loss 4.731100 loss_att 417.912689 loss_ctc 9.080606 loss_rnnt 4.247822 lr 0.00025833 rank 2
2022-12-08 03:44:57,632 DEBUG TRAIN Batch 25/7800 loss 2.625495 loss_att 352.115356 loss_ctc 7.510444 loss_rnnt 2.082723 lr 0.00025833 rank 6
2022-12-08 03:44:57,633 DEBUG TRAIN Batch 25/7800 loss 7.107353 loss_att 354.128906 loss_ctc 8.944025 loss_rnnt 6.903278 lr 0.00025836 rank 1
2022-12-08 03:44:57,633 DEBUG TRAIN Batch 25/7800 loss 5.863848 loss_att 357.569183 loss_ctc 14.636635 loss_rnnt 4.889094 lr 0.00025831 rank 7
2022-12-08 03:44:57,639 DEBUG TRAIN Batch 25/7800 loss 11.324132 loss_att 390.599945 loss_ctc 24.500082 loss_rnnt 9.860138 lr 0.00025832 rank 5
2022-12-08 03:44:57,641 DEBUG TRAIN Batch 25/7800 loss 4.524162 loss_att 370.633545 loss_ctc 11.519104 loss_rnnt 3.746946 lr 0.00025833 rank 0
2022-12-08 03:44:57,643 DEBUG TRAIN Batch 25/7800 loss 4.570951 loss_att 388.053314 loss_ctc 9.803036 loss_rnnt 3.989608 lr 0.00025833 rank 4
2022-12-08 03:46:08,626 DEBUG TRAIN Batch 25/7900 loss 10.825238 loss_att 365.444427 loss_ctc 19.843006 loss_rnnt 9.823264 lr 0.00025830 rank 2
2022-12-08 03:46:08,631 DEBUG TRAIN Batch 25/7900 loss 2.138135 loss_att 408.021057 loss_ctc 8.657645 loss_rnnt 1.413745 lr 0.00025829 rank 4
2022-12-08 03:46:08,631 DEBUG TRAIN Batch 25/7900 loss 12.664201 loss_att 386.959351 loss_ctc 26.111977 loss_rnnt 11.170004 lr 0.00025832 rank 1
2022-12-08 03:46:08,633 DEBUG TRAIN Batch 25/7900 loss 10.115156 loss_att 363.689514 loss_ctc 23.360399 loss_rnnt 8.643463 lr 0.00025829 rank 0
2022-12-08 03:46:08,634 DEBUG TRAIN Batch 25/7900 loss 6.071476 loss_att 374.721741 loss_ctc 19.418392 loss_rnnt 4.588486 lr 0.00025829 rank 6
2022-12-08 03:46:08,634 DEBUG TRAIN Batch 25/7900 loss 4.885211 loss_att 420.864380 loss_ctc 9.790070 loss_rnnt 4.340227 lr 0.00025829 rank 5
2022-12-08 03:46:08,635 DEBUG TRAIN Batch 25/7900 loss 1.241890 loss_att 322.422729 loss_ctc 2.707537 loss_rnnt 1.079040 lr 0.00025828 rank 7
2022-12-08 03:46:08,635 DEBUG TRAIN Batch 25/7900 loss 10.577694 loss_att 390.121552 loss_ctc 16.709101 loss_rnnt 9.896427 lr 0.00025830 rank 3
2022-12-08 03:47:12,177 DEBUG TRAIN Batch 25/8000 loss 8.799240 loss_att 393.150391 loss_ctc 20.955873 loss_rnnt 7.448503 lr 0.00025824 rank 7
2022-12-08 03:47:12,178 DEBUG TRAIN Batch 25/8000 loss 5.878910 loss_att 323.243103 loss_ctc 10.670362 loss_rnnt 5.346526 lr 0.00025826 rank 6
2022-12-08 03:47:12,180 DEBUG TRAIN Batch 25/8000 loss 11.783553 loss_att 315.934082 loss_ctc 24.811260 loss_rnnt 10.336031 lr 0.00025826 rank 4
2022-12-08 03:47:12,182 DEBUG TRAIN Batch 25/8000 loss 5.407272 loss_att 389.321930 loss_ctc 14.913517 loss_rnnt 4.351023 lr 0.00025826 rank 0
2022-12-08 03:47:12,184 DEBUG TRAIN Batch 25/8000 loss 6.042091 loss_att 317.687195 loss_ctc 8.422310 loss_rnnt 5.777623 lr 0.00025826 rank 3
2022-12-08 03:47:12,187 DEBUG TRAIN Batch 25/8000 loss 7.707322 loss_att 385.749084 loss_ctc 14.668637 loss_rnnt 6.933843 lr 0.00025829 rank 1
2022-12-08 03:47:12,191 DEBUG TRAIN Batch 25/8000 loss 3.556144 loss_att 402.192719 loss_ctc 7.123811 loss_rnnt 3.159736 lr 0.00025825 rank 5
2022-12-08 03:47:12,193 DEBUG TRAIN Batch 25/8000 loss 8.015146 loss_att 398.160583 loss_ctc 15.063038 loss_rnnt 7.232048 lr 0.00025826 rank 2
2022-12-08 03:48:16,169 DEBUG TRAIN Batch 25/8100 loss 9.271246 loss_att 369.515656 loss_ctc 19.577072 loss_rnnt 8.126154 lr 0.00025822 rank 6
2022-12-08 03:48:16,180 DEBUG TRAIN Batch 25/8100 loss 8.503421 loss_att 317.980927 loss_ctc 14.385040 loss_rnnt 7.849908 lr 0.00025823 rank 3
2022-12-08 03:48:16,182 DEBUG TRAIN Batch 25/8100 loss 7.367434 loss_att 349.066010 loss_ctc 17.029903 loss_rnnt 6.293826 lr 0.00025823 rank 0
2022-12-08 03:48:16,183 DEBUG TRAIN Batch 25/8100 loss 5.604069 loss_att 332.507721 loss_ctc 10.107564 loss_rnnt 5.103681 lr 0.00025821 rank 7
2022-12-08 03:48:16,184 DEBUG TRAIN Batch 25/8100 loss 7.834088 loss_att 300.444305 loss_ctc 16.708622 loss_rnnt 6.848029 lr 0.00025822 rank 4
2022-12-08 03:48:16,184 DEBUG TRAIN Batch 25/8100 loss 6.643729 loss_att 349.072662 loss_ctc 13.611480 loss_rnnt 5.869535 lr 0.00025822 rank 5
2022-12-08 03:48:16,195 DEBUG TRAIN Batch 25/8100 loss 8.051154 loss_att 364.006287 loss_ctc 13.765465 loss_rnnt 7.416231 lr 0.00025823 rank 2
2022-12-08 03:48:16,212 DEBUG TRAIN Batch 25/8100 loss 10.952572 loss_att 331.820190 loss_ctc 19.633736 loss_rnnt 9.987999 lr 0.00025825 rank 1
2022-12-08 03:49:21,178 DEBUG TRAIN Batch 25/8200 loss 6.924498 loss_att 329.095032 loss_ctc 14.470905 loss_rnnt 6.086008 lr 0.00025819 rank 4
2022-12-08 03:49:21,188 DEBUG TRAIN Batch 25/8200 loss 2.351313 loss_att 288.076080 loss_ctc 4.482314 loss_rnnt 2.114535 lr 0.00025817 rank 7
2022-12-08 03:49:21,192 DEBUG TRAIN Batch 25/8200 loss 10.945148 loss_att 245.440933 loss_ctc 21.005322 loss_rnnt 9.827352 lr 0.00025822 rank 1
2022-12-08 03:49:21,192 DEBUG TRAIN Batch 25/8200 loss 12.162952 loss_att 172.275757 loss_ctc 20.536331 loss_rnnt 11.232577 lr 0.00025819 rank 0
2022-12-08 03:49:21,195 DEBUG TRAIN Batch 25/8200 loss 6.270333 loss_att 303.453094 loss_ctc 12.799913 loss_rnnt 5.544824 lr 0.00025820 rank 2
2022-12-08 03:49:21,196 DEBUG TRAIN Batch 25/8200 loss 4.474760 loss_att 309.067719 loss_ctc 9.151327 loss_rnnt 3.955142 lr 0.00025819 rank 6
2022-12-08 03:49:21,198 DEBUG TRAIN Batch 25/8200 loss 9.252432 loss_att 195.470673 loss_ctc 15.080960 loss_rnnt 8.604818 lr 0.00025819 rank 3
2022-12-08 03:49:21,236 DEBUG TRAIN Batch 25/8200 loss 17.583740 loss_att 389.816254 loss_ctc 31.477551 loss_rnnt 16.039984 lr 0.00025818 rank 5
2022-12-08 03:50:24,443 DEBUG TRAIN Batch 25/8300 loss 8.640781 loss_att 222.866547 loss_ctc 12.025602 loss_rnnt 8.264690 lr 0.00025814 rank 7
2022-12-08 03:50:24,445 DEBUG TRAIN Batch 25/8300 loss 4.421591 loss_att 226.390152 loss_ctc 7.741387 loss_rnnt 4.052725 lr 0.00025816 rank 2
2022-12-08 03:50:24,446 DEBUG TRAIN Batch 25/8300 loss 5.386585 loss_att 416.223877 loss_ctc 16.306435 loss_rnnt 4.173268 lr 0.00025815 rank 4
2022-12-08 03:50:24,446 DEBUG TRAIN Batch 25/8300 loss 6.696651 loss_att 449.724457 loss_ctc 17.563931 loss_rnnt 5.489175 lr 0.00025818 rank 1
2022-12-08 03:50:24,449 DEBUG TRAIN Batch 25/8300 loss 7.502193 loss_att 387.891663 loss_ctc 19.918114 loss_rnnt 6.122646 lr 0.00025816 rank 0
2022-12-08 03:50:24,450 DEBUG TRAIN Batch 25/8300 loss 2.714259 loss_att 348.468719 loss_ctc 4.764168 loss_rnnt 2.486492 lr 0.00025815 rank 6
2022-12-08 03:50:24,450 DEBUG TRAIN Batch 25/8300 loss 2.770053 loss_att 422.671631 loss_ctc 7.839340 loss_rnnt 2.206799 lr 0.00025816 rank 3
2022-12-08 03:50:24,455 DEBUG TRAIN Batch 25/8300 loss 9.126059 loss_att 318.410675 loss_ctc 12.883907 loss_rnnt 8.708520 lr 0.00025815 rank 5
2022-12-08 03:51:09,264 DEBUG CV Batch 25/0 loss 1.378422 loss_att 48.087337 loss_ctc 3.003592 loss_rnnt 1.197848 history loss 1.327370 rank 2
2022-12-08 03:51:09,265 DEBUG CV Batch 25/0 loss 1.378422 loss_att 48.087337 loss_ctc 3.003592 loss_rnnt 1.197848 history loss 1.327370 rank 4
2022-12-08 03:51:09,269 DEBUG CV Batch 25/0 loss 1.378422 loss_att 48.087337 loss_ctc 3.003592 loss_rnnt 1.197848 history loss 1.327370 rank 3
2022-12-08 03:51:09,270 DEBUG CV Batch 25/0 loss 1.378422 loss_att 48.087337 loss_ctc 3.003592 loss_rnnt 1.197848 history loss 1.327370 rank 5
2022-12-08 03:51:09,275 DEBUG CV Batch 25/0 loss 1.378422 loss_att 48.087337 loss_ctc 3.003592 loss_rnnt 1.197848 history loss 1.327370 rank 7
2022-12-08 03:51:09,275 DEBUG CV Batch 25/0 loss 1.378422 loss_att 48.087337 loss_ctc 3.003592 loss_rnnt 1.197848 history loss 1.327370 rank 1
2022-12-08 03:51:09,279 DEBUG CV Batch 25/0 loss 1.378422 loss_att 48.087337 loss_ctc 3.003592 loss_rnnt 1.197848 history loss 1.327370 rank 0
2022-12-08 03:51:09,288 DEBUG CV Batch 25/0 loss 1.378422 loss_att 48.087337 loss_ctc 3.003592 loss_rnnt 1.197848 history loss 1.327370 rank 6
2022-12-08 03:51:20,064 DEBUG CV Batch 25/100 loss 3.581058 loss_att 266.945496 loss_ctc 11.657439 loss_rnnt 2.683682 history loss 2.915232 rank 6
2022-12-08 03:51:20,077 DEBUG CV Batch 25/100 loss 3.581058 loss_att 266.945496 loss_ctc 11.657439 loss_rnnt 2.683682 history loss 2.915232 rank 4
2022-12-08 03:51:20,106 DEBUG CV Batch 25/100 loss 3.581058 loss_att 266.945496 loss_ctc 11.657439 loss_rnnt 2.683682 history loss 2.915232 rank 5
2022-12-08 03:51:20,135 DEBUG CV Batch 25/100 loss 3.581058 loss_att 266.945496 loss_ctc 11.657439 loss_rnnt 2.683682 history loss 2.915232 rank 2
2022-12-08 03:51:20,174 DEBUG CV Batch 25/100 loss 3.581058 loss_att 266.945496 loss_ctc 11.657439 loss_rnnt 2.683682 history loss 2.915232 rank 7
2022-12-08 03:51:20,220 DEBUG CV Batch 25/100 loss 3.581058 loss_att 266.945496 loss_ctc 11.657439 loss_rnnt 2.683682 history loss 2.915232 rank 3
2022-12-08 03:51:20,233 DEBUG CV Batch 25/100 loss 3.581058 loss_att 266.945496 loss_ctc 11.657439 loss_rnnt 2.683682 history loss 2.915232 rank 1
2022-12-08 03:51:20,262 DEBUG CV Batch 25/100 loss 3.581058 loss_att 266.945496 loss_ctc 11.657439 loss_rnnt 2.683682 history loss 2.915232 rank 0
2022-12-08 03:51:33,690 DEBUG CV Batch 25/200 loss 5.352415 loss_att 641.190613 loss_ctc 6.692130 loss_rnnt 5.203558 history loss 3.447303 rank 2
2022-12-08 03:51:33,737 DEBUG CV Batch 25/200 loss 5.352415 loss_att 641.190613 loss_ctc 6.692130 loss_rnnt 5.203558 history loss 3.447303 rank 5
2022-12-08 03:51:33,768 DEBUG CV Batch 25/200 loss 5.352415 loss_att 641.190613 loss_ctc 6.692130 loss_rnnt 5.203558 history loss 3.447303 rank 6
2022-12-08 03:51:33,775 DEBUG CV Batch 25/200 loss 5.352415 loss_att 641.190613 loss_ctc 6.692130 loss_rnnt 5.203558 history loss 3.447303 rank 1
2022-12-08 03:51:33,949 DEBUG CV Batch 25/200 loss 5.352415 loss_att 641.190613 loss_ctc 6.692130 loss_rnnt 5.203558 history loss 3.447303 rank 4
2022-12-08 03:51:33,957 DEBUG CV Batch 25/200 loss 5.352415 loss_att 641.190613 loss_ctc 6.692130 loss_rnnt 5.203558 history loss 3.447303 rank 3
2022-12-08 03:51:34,031 DEBUG CV Batch 25/200 loss 5.352415 loss_att 641.190613 loss_ctc 6.692130 loss_rnnt 5.203558 history loss 3.447303 rank 7
2022-12-08 03:51:34,272 DEBUG CV Batch 25/200 loss 5.352415 loss_att 641.190613 loss_ctc 6.692130 loss_rnnt 5.203558 history loss 3.447303 rank 0
2022-12-08 03:51:44,870 DEBUG CV Batch 25/300 loss 3.640418 loss_att 190.889175 loss_ctc 6.792761 loss_rnnt 3.290158 history loss 3.614054 rank 2
2022-12-08 03:51:44,944 DEBUG CV Batch 25/300 loss 3.640418 loss_att 190.889175 loss_ctc 6.792761 loss_rnnt 3.290158 history loss 3.614054 rank 5
2022-12-08 03:51:44,971 DEBUG CV Batch 25/300 loss 3.640418 loss_att 190.889175 loss_ctc 6.792761 loss_rnnt 3.290158 history loss 3.614054 rank 6
2022-12-08 03:51:44,973 DEBUG CV Batch 25/300 loss 3.640418 loss_att 190.889175 loss_ctc 6.792761 loss_rnnt 3.290158 history loss 3.614054 rank 1
2022-12-08 03:51:45,542 DEBUG CV Batch 25/300 loss 3.640418 loss_att 190.889175 loss_ctc 6.792761 loss_rnnt 3.290158 history loss 3.614054 rank 4
2022-12-08 03:51:45,785 DEBUG CV Batch 25/300 loss 3.640418 loss_att 190.889175 loss_ctc 6.792761 loss_rnnt 3.290158 history loss 3.614054 rank 3
2022-12-08 03:51:45,828 DEBUG CV Batch 25/300 loss 3.640418 loss_att 190.889175 loss_ctc 6.792761 loss_rnnt 3.290158 history loss 3.614054 rank 7
2022-12-08 03:51:46,112 DEBUG CV Batch 25/300 loss 3.640418 loss_att 190.889175 loss_ctc 6.792761 loss_rnnt 3.290158 history loss 3.614054 rank 0
2022-12-08 03:51:56,154 DEBUG CV Batch 25/400 loss 7.149869 loss_att 826.189941 loss_ctc 11.867488 loss_rnnt 6.625690 history loss 4.398007 rank 5
2022-12-08 03:51:56,182 DEBUG CV Batch 25/400 loss 7.149869 loss_att 826.189941 loss_ctc 11.867488 loss_rnnt 6.625690 history loss 4.398007 rank 1
2022-12-08 03:51:56,325 DEBUG CV Batch 25/400 loss 7.149869 loss_att 826.189941 loss_ctc 11.867488 loss_rnnt 6.625690 history loss 4.398007 rank 6
2022-12-08 03:51:56,356 DEBUG CV Batch 25/400 loss 7.149869 loss_att 826.189941 loss_ctc 11.867488 loss_rnnt 6.625690 history loss 4.398007 rank 2
2022-12-08 03:51:56,978 DEBUG CV Batch 25/400 loss 7.149869 loss_att 826.189941 loss_ctc 11.867488 loss_rnnt 6.625690 history loss 4.398007 rank 3
2022-12-08 03:51:57,135 DEBUG CV Batch 25/400 loss 7.149869 loss_att 826.189941 loss_ctc 11.867488 loss_rnnt 6.625690 history loss 4.398007 rank 4
2022-12-08 03:51:57,486 DEBUG CV Batch 25/400 loss 7.149869 loss_att 826.189941 loss_ctc 11.867488 loss_rnnt 6.625690 history loss 4.398007 rank 7
2022-12-08 03:51:57,877 DEBUG CV Batch 25/400 loss 7.149869 loss_att 826.189941 loss_ctc 11.867488 loss_rnnt 6.625690 history loss 4.398007 rank 0
2022-12-08 03:52:06,779 DEBUG CV Batch 25/500 loss 4.527340 loss_att 266.658722 loss_ctc 7.345332 loss_rnnt 4.214230 history loss 5.060610 rank 1
2022-12-08 03:52:06,820 DEBUG CV Batch 25/500 loss 4.527340 loss_att 266.658722 loss_ctc 7.345332 loss_rnnt 4.214230 history loss 5.060610 rank 2
2022-12-08 03:52:06,842 DEBUG CV Batch 25/500 loss 4.527340 loss_att 266.658722 loss_ctc 7.345332 loss_rnnt 4.214230 history loss 5.060610 rank 3
2022-12-08 03:52:06,913 DEBUG CV Batch 25/500 loss 4.527340 loss_att 266.658722 loss_ctc 7.345332 loss_rnnt 4.214230 history loss 5.060610 rank 5
2022-12-08 03:52:07,061 DEBUG CV Batch 25/500 loss 4.527340 loss_att 266.658722 loss_ctc 7.345332 loss_rnnt 4.214230 history loss 5.060610 rank 6
2022-12-08 03:52:07,199 DEBUG CV Batch 25/500 loss 4.527340 loss_att 266.658722 loss_ctc 7.345332 loss_rnnt 4.214230 history loss 5.060610 rank 4
2022-12-08 03:52:07,687 DEBUG CV Batch 25/500 loss 4.527340 loss_att 266.658722 loss_ctc 7.345332 loss_rnnt 4.214230 history loss 5.060610 rank 7
2022-12-08 03:52:08,250 DEBUG CV Batch 25/500 loss 4.527340 loss_att 266.658722 loss_ctc 7.345332 loss_rnnt 4.214230 history loss 5.060610 rank 0
2022-12-08 03:52:19,313 DEBUG CV Batch 25/600 loss 5.182471 loss_att 104.308014 loss_ctc 8.472880 loss_rnnt 4.816870 history loss 5.915572 rank 2
2022-12-08 03:52:19,386 DEBUG CV Batch 25/600 loss 5.182471 loss_att 104.308014 loss_ctc 8.472880 loss_rnnt 4.816870 history loss 5.915572 rank 1
2022-12-08 03:52:19,430 DEBUG CV Batch 25/600 loss 5.182471 loss_att 104.308014 loss_ctc 8.472880 loss_rnnt 4.816870 history loss 5.915572 rank 3
2022-12-08 03:52:19,483 DEBUG CV Batch 25/600 loss 5.182471 loss_att 104.308014 loss_ctc 8.472880 loss_rnnt 4.816870 history loss 5.915572 rank 5
2022-12-08 03:52:19,649 DEBUG CV Batch 25/600 loss 5.182471 loss_att 104.308014 loss_ctc 8.472880 loss_rnnt 4.816870 history loss 5.915572 rank 4
2022-12-08 03:52:19,716 DEBUG CV Batch 25/600 loss 5.182471 loss_att 104.308014 loss_ctc 8.472880 loss_rnnt 4.816870 history loss 5.915572 rank 7
2022-12-08 03:52:19,804 DEBUG CV Batch 25/600 loss 5.182471 loss_att 104.308014 loss_ctc 8.472880 loss_rnnt 4.816870 history loss 5.915572 rank 6
2022-12-08 03:52:20,239 DEBUG CV Batch 25/600 loss 5.182471 loss_att 104.308014 loss_ctc 8.472880 loss_rnnt 4.816870 history loss 5.915572 rank 0
2022-12-08 03:52:31,574 DEBUG CV Batch 25/700 loss 6.724901 loss_att 707.040405 loss_ctc 23.635948 loss_rnnt 4.845896 history loss 6.451565 rank 5
2022-12-08 03:52:31,585 DEBUG CV Batch 25/700 loss 6.724901 loss_att 707.040405 loss_ctc 23.635948 loss_rnnt 4.845896 history loss 6.451565 rank 1
2022-12-08 03:52:31,614 DEBUG CV Batch 25/700 loss 6.724901 loss_att 707.040405 loss_ctc 23.635948 loss_rnnt 4.845896 history loss 6.451565 rank 3
2022-12-08 03:52:31,747 DEBUG CV Batch 25/700 loss 6.724901 loss_att 707.040405 loss_ctc 23.635948 loss_rnnt 4.845896 history loss 6.451565 rank 4
2022-12-08 03:52:31,770 DEBUG CV Batch 25/700 loss 6.724901 loss_att 707.040405 loss_ctc 23.635948 loss_rnnt 4.845896 history loss 6.451565 rank 7
2022-12-08 03:52:31,788 DEBUG CV Batch 25/700 loss 6.724901 loss_att 707.040405 loss_ctc 23.635948 loss_rnnt 4.845896 history loss 6.451565 rank 6
2022-12-08 03:52:31,819 DEBUG CV Batch 25/700 loss 6.724901 loss_att 707.040405 loss_ctc 23.635948 loss_rnnt 4.845896 history loss 6.451565 rank 2
2022-12-08 03:52:31,845 DEBUG CV Batch 25/700 loss 6.724901 loss_att 707.040405 loss_ctc 23.635948 loss_rnnt 4.845896 history loss 6.451565 rank 0
2022-12-08 03:52:43,384 DEBUG CV Batch 25/800 loss 5.786842 loss_att 263.404297 loss_ctc 16.201401 loss_rnnt 4.629669 history loss 5.983074 rank 1
2022-12-08 03:52:43,423 DEBUG CV Batch 25/800 loss 5.786842 loss_att 263.404297 loss_ctc 16.201401 loss_rnnt 4.629669 history loss 5.983074 rank 4
2022-12-08 03:52:43,495 DEBUG CV Batch 25/800 loss 5.786842 loss_att 263.404297 loss_ctc 16.201401 loss_rnnt 4.629669 history loss 5.983074 rank 3
2022-12-08 03:52:43,557 DEBUG CV Batch 25/800 loss 5.786842 loss_att 263.404297 loss_ctc 16.201401 loss_rnnt 4.629669 history loss 5.983074 rank 5
2022-12-08 03:52:43,611 DEBUG CV Batch 25/800 loss 5.786842 loss_att 263.404297 loss_ctc 16.201401 loss_rnnt 4.629669 history loss 5.983074 rank 0
2022-12-08 03:52:43,919 DEBUG CV Batch 25/800 loss 5.786842 loss_att 263.404297 loss_ctc 16.201401 loss_rnnt 4.629669 history loss 5.983074 rank 6
2022-12-08 03:52:44,021 DEBUG CV Batch 25/800 loss 5.786842 loss_att 263.404297 loss_ctc 16.201401 loss_rnnt 4.629669 history loss 5.983074 rank 2
2022-12-08 03:52:44,084 DEBUG CV Batch 25/800 loss 5.786842 loss_att 263.404297 loss_ctc 16.201401 loss_rnnt 4.629669 history loss 5.983074 rank 7
2022-12-08 03:52:56,897 DEBUG CV Batch 25/900 loss 7.494305 loss_att 550.849976 loss_ctc 15.913398 loss_rnnt 6.558850 history loss 5.808573 rank 1
2022-12-08 03:52:57,014 DEBUG CV Batch 25/900 loss 7.494305 loss_att 550.849976 loss_ctc 15.913398 loss_rnnt 6.558850 history loss 5.808573 rank 3
2022-12-08 03:52:57,092 DEBUG CV Batch 25/900 loss 7.494305 loss_att 550.849976 loss_ctc 15.913398 loss_rnnt 6.558850 history loss 5.808573 rank 4
2022-12-08 03:52:57,135 DEBUG CV Batch 25/900 loss 7.494305 loss_att 550.849976 loss_ctc 15.913398 loss_rnnt 6.558850 history loss 5.808573 rank 5
2022-12-08 03:52:57,367 DEBUG CV Batch 25/900 loss 7.494305 loss_att 550.849976 loss_ctc 15.913398 loss_rnnt 6.558850 history loss 5.808573 rank 0
2022-12-08 03:52:57,517 DEBUG CV Batch 25/900 loss 7.494305 loss_att 550.849976 loss_ctc 15.913398 loss_rnnt 6.558850 history loss 5.808573 rank 6
2022-12-08 03:52:57,813 DEBUG CV Batch 25/900 loss 7.494305 loss_att 550.849976 loss_ctc 15.913398 loss_rnnt 6.558850 history loss 5.808573 rank 2
2022-12-08 03:52:57,874 DEBUG CV Batch 25/900 loss 7.494305 loss_att 550.849976 loss_ctc 15.913398 loss_rnnt 6.558850 history loss 5.808573 rank 7
2022-12-08 03:53:08,573 DEBUG CV Batch 25/1000 loss 2.490206 loss_att 176.488281 loss_ctc 4.606837 loss_rnnt 2.255025 history loss 5.616432 rank 5
2022-12-08 03:53:08,660 DEBUG CV Batch 25/1000 loss 2.490206 loss_att 176.488281 loss_ctc 4.606837 loss_rnnt 2.255025 history loss 5.616432 rank 3
2022-12-08 03:53:08,721 DEBUG CV Batch 25/1000 loss 2.490206 loss_att 176.488281 loss_ctc 4.606837 loss_rnnt 2.255025 history loss 5.616432 rank 1
2022-12-08 03:53:08,880 DEBUG CV Batch 25/1000 loss 2.490206 loss_att 176.488281 loss_ctc 4.606837 loss_rnnt 2.255025 history loss 5.616432 rank 6
2022-12-08 03:53:08,911 DEBUG CV Batch 25/1000 loss 2.490206 loss_att 176.488281 loss_ctc 4.606837 loss_rnnt 2.255025 history loss 5.616432 rank 4
2022-12-08 03:53:09,207 DEBUG CV Batch 25/1000 loss 2.490206 loss_att 176.488281 loss_ctc 4.606837 loss_rnnt 2.255025 history loss 5.616432 rank 2
2022-12-08 03:53:09,519 DEBUG CV Batch 25/1000 loss 2.490206 loss_att 176.488281 loss_ctc 4.606837 loss_rnnt 2.255025 history loss 5.616432 rank 0
2022-12-08 03:53:09,874 DEBUG CV Batch 25/1000 loss 2.490206 loss_att 176.488281 loss_ctc 4.606837 loss_rnnt 2.255025 history loss 5.616432 rank 7
2022-12-08 03:53:19,587 DEBUG CV Batch 25/1100 loss 5.023249 loss_att 60.694702 loss_ctc 8.436232 loss_rnnt 4.644029 history loss 5.584033 rank 5
2022-12-08 03:53:19,671 DEBUG CV Batch 25/1100 loss 5.023249 loss_att 60.694702 loss_ctc 8.436232 loss_rnnt 4.644029 history loss 5.584033 rank 1
2022-12-08 03:53:20,221 DEBUG CV Batch 25/1100 loss 5.023249 loss_att 60.694702 loss_ctc 8.436232 loss_rnnt 4.644029 history loss 5.584033 rank 6
2022-12-08 03:53:20,263 DEBUG CV Batch 25/1100 loss 5.023249 loss_att 60.694702 loss_ctc 8.436232 loss_rnnt 4.644029 history loss 5.584033 rank 3
2022-12-08 03:53:20,450 DEBUG CV Batch 25/1100 loss 5.023249 loss_att 60.694702 loss_ctc 8.436232 loss_rnnt 4.644029 history loss 5.584033 rank 4
2022-12-08 03:53:20,559 DEBUG CV Batch 25/1100 loss 5.023249 loss_att 60.694702 loss_ctc 8.436232 loss_rnnt 4.644029 history loss 5.584033 rank 2
2022-12-08 03:53:21,317 DEBUG CV Batch 25/1100 loss 5.023249 loss_att 60.694702 loss_ctc 8.436232 loss_rnnt 4.644029 history loss 5.584033 rank 0
2022-12-08 03:53:21,513 DEBUG CV Batch 25/1100 loss 5.023249 loss_att 60.694702 loss_ctc 8.436232 loss_rnnt 4.644029 history loss 5.584033 rank 7
2022-12-08 03:53:29,905 DEBUG CV Batch 25/1200 loss 6.552663 loss_att 280.460083 loss_ctc 7.690961 loss_rnnt 6.426186 history loss 5.868915 rank 1
2022-12-08 03:53:29,926 DEBUG CV Batch 25/1200 loss 6.552663 loss_att 280.460083 loss_ctc 7.690961 loss_rnnt 6.426186 history loss 5.868915 rank 5
2022-12-08 03:53:30,159 DEBUG CV Batch 25/1200 loss 6.552663 loss_att 280.460083 loss_ctc 7.690961 loss_rnnt 6.426186 history loss 5.868915 rank 3
2022-12-08 03:53:30,538 DEBUG CV Batch 25/1200 loss 6.552663 loss_att 280.460083 loss_ctc 7.690961 loss_rnnt 6.426186 history loss 5.868915 rank 4
2022-12-08 03:53:30,959 DEBUG CV Batch 25/1200 loss 6.552663 loss_att 280.460083 loss_ctc 7.690961 loss_rnnt 6.426186 history loss 5.868915 rank 6
2022-12-08 03:53:31,399 DEBUG CV Batch 25/1200 loss 6.552663 loss_att 280.460083 loss_ctc 7.690961 loss_rnnt 6.426186 history loss 5.868915 rank 2
2022-12-08 03:53:31,659 DEBUG CV Batch 25/1200 loss 6.552663 loss_att 280.460083 loss_ctc 7.690961 loss_rnnt 6.426186 history loss 5.868915 rank 0
2022-12-08 03:53:31,862 DEBUG CV Batch 25/1200 loss 6.552663 loss_att 280.460083 loss_ctc 7.690961 loss_rnnt 6.426186 history loss 5.868915 rank 7
2022-12-08 03:53:41,604 DEBUG CV Batch 25/1300 loss 4.896182 loss_att 105.975998 loss_ctc 7.827696 loss_rnnt 4.570458 history loss 6.160614 rank 1
2022-12-08 03:53:41,870 DEBUG CV Batch 25/1300 loss 4.896182 loss_att 105.975998 loss_ctc 7.827696 loss_rnnt 4.570458 history loss 6.160614 rank 3
2022-12-08 03:53:42,009 DEBUG CV Batch 25/1300 loss 4.896182 loss_att 105.975998 loss_ctc 7.827696 loss_rnnt 4.570458 history loss 6.160614 rank 4
2022-12-08 03:53:42,017 DEBUG CV Batch 25/1300 loss 4.896182 loss_att 105.975998 loss_ctc 7.827696 loss_rnnt 4.570458 history loss 6.160614 rank 5
2022-12-08 03:53:42,691 DEBUG CV Batch 25/1300 loss 4.896182 loss_att 105.975998 loss_ctc 7.827696 loss_rnnt 4.570458 history loss 6.160614 rank 6
2022-12-08 03:53:43,368 DEBUG CV Batch 25/1300 loss 4.896182 loss_att 105.975998 loss_ctc 7.827696 loss_rnnt 4.570458 history loss 6.160614 rank 2
2022-12-08 03:53:43,471 DEBUG CV Batch 25/1300 loss 4.896182 loss_att 105.975998 loss_ctc 7.827696 loss_rnnt 4.570458 history loss 6.160614 rank 0
2022-12-08 03:53:43,604 DEBUG CV Batch 25/1300 loss 4.896182 loss_att 105.975998 loss_ctc 7.827696 loss_rnnt 4.570458 history loss 6.160614 rank 7
2022-12-08 03:53:53,622 DEBUG CV Batch 25/1400 loss 2.888560 loss_att 562.097778 loss_ctc 6.494855 loss_rnnt 2.487861 history loss 6.422744 rank 4
2022-12-08 03:53:53,969 DEBUG CV Batch 25/1400 loss 2.888560 loss_att 562.097778 loss_ctc 6.494855 loss_rnnt 2.487861 history loss 6.422744 rank 1
2022-12-08 03:53:54,011 DEBUG CV Batch 25/1400 loss 2.888560 loss_att 562.097778 loss_ctc 6.494855 loss_rnnt 2.487861 history loss 6.422744 rank 3
2022-12-08 03:53:54,262 DEBUG CV Batch 25/1400 loss 2.888560 loss_att 562.097778 loss_ctc 6.494855 loss_rnnt 2.487861 history loss 6.422744 rank 5
2022-12-08 03:53:54,476 DEBUG CV Batch 25/1400 loss 2.888560 loss_att 562.097778 loss_ctc 6.494855 loss_rnnt 2.487861 history loss 6.422744 rank 0
2022-12-08 03:53:54,591 DEBUG CV Batch 25/1400 loss 2.888560 loss_att 562.097778 loss_ctc 6.494855 loss_rnnt 2.487861 history loss 6.422744 rank 7
2022-12-08 03:53:54,798 DEBUG CV Batch 25/1400 loss 2.888560 loss_att 562.097778 loss_ctc 6.494855 loss_rnnt 2.487861 history loss 6.422744 rank 6
2022-12-08 03:53:55,811 DEBUG CV Batch 25/1400 loss 2.888560 loss_att 562.097778 loss_ctc 6.494855 loss_rnnt 2.487861 history loss 6.422744 rank 2
2022-12-08 03:54:05,671 DEBUG CV Batch 25/1500 loss 7.364132 loss_att 275.489716 loss_ctc 7.275100 loss_rnnt 7.374024 history loss 6.304149 rank 4
2022-12-08 03:54:05,864 DEBUG CV Batch 25/1500 loss 7.364132 loss_att 275.489716 loss_ctc 7.275100 loss_rnnt 7.374024 history loss 6.304149 rank 0
2022-12-08 03:54:06,255 DEBUG CV Batch 25/1500 loss 7.364132 loss_att 275.489716 loss_ctc 7.275100 loss_rnnt 7.374024 history loss 6.304149 rank 1
2022-12-08 03:54:06,269 DEBUG CV Batch 25/1500 loss 7.364132 loss_att 275.489716 loss_ctc 7.275100 loss_rnnt 7.374024 history loss 6.304149 rank 3
2022-12-08 03:54:06,390 DEBUG CV Batch 25/1500 loss 7.364132 loss_att 275.489716 loss_ctc 7.275100 loss_rnnt 7.374024 history loss 6.304149 rank 5
2022-12-08 03:54:06,495 DEBUG CV Batch 25/1500 loss 7.364132 loss_att 275.489716 loss_ctc 7.275100 loss_rnnt 7.374024 history loss 6.304149 rank 7
2022-12-08 03:54:07,137 DEBUG CV Batch 25/1500 loss 7.364132 loss_att 275.489716 loss_ctc 7.275100 loss_rnnt 7.374024 history loss 6.304149 rank 6
2022-12-08 03:54:08,277 DEBUG CV Batch 25/1500 loss 7.364132 loss_att 275.489716 loss_ctc 7.275100 loss_rnnt 7.374024 history loss 6.304149 rank 2
2022-12-08 03:54:19,152 DEBUG CV Batch 25/1600 loss 6.393330 loss_att 593.917969 loss_ctc 12.567273 loss_rnnt 5.707337 history loss 6.260616 rank 4
2022-12-08 03:54:19,198 DEBUG CV Batch 25/1600 loss 6.393330 loss_att 593.917969 loss_ctc 12.567273 loss_rnnt 5.707337 history loss 6.260616 rank 0
2022-12-08 03:54:19,321 DEBUG CV Batch 25/1600 loss 6.393330 loss_att 593.917969 loss_ctc 12.567273 loss_rnnt 5.707337 history loss 6.260616 rank 1
2022-12-08 03:54:19,563 DEBUG CV Batch 25/1600 loss 6.393330 loss_att 593.917969 loss_ctc 12.567273 loss_rnnt 5.707337 history loss 6.260616 rank 3
2022-12-08 03:54:19,574 DEBUG CV Batch 25/1600 loss 6.393330 loss_att 593.917969 loss_ctc 12.567273 loss_rnnt 5.707337 history loss 6.260616 rank 5
2022-12-08 03:54:19,772 DEBUG CV Batch 25/1600 loss 6.393330 loss_att 593.917969 loss_ctc 12.567273 loss_rnnt 5.707337 history loss 6.260616 rank 7
2022-12-08 03:54:20,296 DEBUG CV Batch 25/1600 loss 6.393330 loss_att 593.917969 loss_ctc 12.567273 loss_rnnt 5.707337 history loss 6.260616 rank 6
2022-12-08 03:54:21,546 DEBUG CV Batch 25/1600 loss 6.393330 loss_att 593.917969 loss_ctc 12.567273 loss_rnnt 5.707337 history loss 6.260616 rank 2
2022-12-08 03:54:30,960 DEBUG CV Batch 25/1700 loss 7.398983 loss_att 210.844940 loss_ctc 15.342944 loss_rnnt 6.516321 history loss 6.200665 rank 1
2022-12-08 03:54:31,152 DEBUG CV Batch 25/1700 loss 7.398983 loss_att 210.844940 loss_ctc 15.342944 loss_rnnt 6.516321 history loss 6.200665 rank 4
2022-12-08 03:54:31,488 DEBUG CV Batch 25/1700 loss 7.398983 loss_att 210.844940 loss_ctc 15.342944 loss_rnnt 6.516321 history loss 6.200665 rank 5
2022-12-08 03:54:31,541 DEBUG CV Batch 25/1700 loss 7.398983 loss_att 210.844940 loss_ctc 15.342944 loss_rnnt 6.516321 history loss 6.200665 rank 0
2022-12-08 03:54:31,703 DEBUG CV Batch 25/1700 loss 7.398983 loss_att 210.844940 loss_ctc 15.342944 loss_rnnt 6.516321 history loss 6.200665 rank 3
2022-12-08 03:54:31,960 DEBUG CV Batch 25/1700 loss 7.398983 loss_att 210.844940 loss_ctc 15.342944 loss_rnnt 6.516321 history loss 6.200665 rank 7
2022-12-08 03:54:31,976 DEBUG CV Batch 25/1700 loss 7.398983 loss_att 210.844940 loss_ctc 15.342944 loss_rnnt 6.516321 history loss 6.200665 rank 6
2022-12-08 03:54:33,534 DEBUG CV Batch 25/1700 loss 7.398983 loss_att 210.844940 loss_ctc 15.342944 loss_rnnt 6.516321 history loss 6.200665 rank 2
2022-12-08 03:54:39,663 INFO Epoch 25 CV info cv_loss 6.176123914647643
2022-12-08 03:54:39,663 INFO Epoch 26 TRAIN info lr 0.00025816687903870125
2022-12-08 03:54:39,667 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 03:54:39,837 INFO Epoch 25 CV info cv_loss 6.176123914647643
2022-12-08 03:54:39,838 INFO Epoch 26 TRAIN info lr 0.0002581317842058542
2022-12-08 03:54:39,839 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 03:54:40,311 INFO Epoch 25 CV info cv_loss 6.176123914647643
2022-12-08 03:54:40,312 INFO Epoch 26 TRAIN info lr 0.00025814210472978555
2022-12-08 03:54:40,316 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 03:54:40,463 INFO Epoch 25 CV info cv_loss 6.176123914647643
2022-12-08 03:54:40,464 INFO Checkpoint: save to checkpoint exp/1204_encoder_bias_nobi_noatt/25.pt
2022-12-08 03:54:40,566 INFO Epoch 25 CV info cv_loss 6.176123914647643
2022-12-08 03:54:40,566 INFO Epoch 26 TRAIN info lr 0.00025814279280872904
2022-12-08 03:54:40,571 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 03:54:40,678 INFO Epoch 25 CV info cv_loss 6.176123914647643
2022-12-08 03:54:40,679 INFO Epoch 26 TRAIN info lr 0.0002581276563428641
2022-12-08 03:54:40,683 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 03:54:40,917 INFO Epoch 25 CV info cv_loss 6.176123914647643
2022-12-08 03:54:40,918 INFO Epoch 26 TRAIN info lr 0.00025814554517952657
2022-12-08 03:54:40,923 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 03:54:40,983 INFO Epoch 26 TRAIN info lr 0.0002581390084426282
2022-12-08 03:54:40,987 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 03:54:42,409 INFO Epoch 25 CV info cv_loss 6.176123914647643
2022-12-08 03:54:42,410 INFO Epoch 26 TRAIN info lr 0.0002581489857668314
2022-12-08 03:54:42,411 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 03:55:55,129 DEBUG TRAIN Batch 26/0 loss 6.077004 loss_att 72.845490 loss_ctc 9.939679 loss_rnnt 5.647818 lr 0.00025814 rank 3
2022-12-08 03:55:55,133 DEBUG TRAIN Batch 26/0 loss 8.758543 loss_att 64.756088 loss_ctc 13.388284 loss_rnnt 8.244127 lr 0.00025813 rank 7
2022-12-08 03:55:55,137 DEBUG TRAIN Batch 26/0 loss 7.667155 loss_att 72.312393 loss_ctc 11.629639 loss_rnnt 7.226880 lr 0.00025814 rank 5
2022-12-08 03:55:55,142 DEBUG TRAIN Batch 26/0 loss 7.165289 loss_att 69.519150 loss_ctc 12.726599 loss_rnnt 6.547366 lr 0.00025813 rank 4
2022-12-08 03:55:55,152 DEBUG TRAIN Batch 26/0 loss 8.067467 loss_att 88.973610 loss_ctc 13.288919 loss_rnnt 7.487306 lr 0.00025814 rank 0
2022-12-08 03:55:55,157 DEBUG TRAIN Batch 26/0 loss 10.133720 loss_att 65.380287 loss_ctc 14.525338 loss_rnnt 9.645763 lr 0.00025815 rank 2
2022-12-08 03:55:55,165 DEBUG TRAIN Batch 26/0 loss 8.344680 loss_att 75.191162 loss_ctc 11.465844 loss_rnnt 7.997884 lr 0.00025815 rank 6
2022-12-08 03:55:55,205 DEBUG TRAIN Batch 26/0 loss 8.039626 loss_att 69.142723 loss_ctc 13.253714 loss_rnnt 7.460283 lr 0.00025817 rank 1
2022-12-08 03:56:58,167 DEBUG TRAIN Batch 26/100 loss 4.403624 loss_att 373.534790 loss_ctc 13.734488 loss_rnnt 3.366861 lr 0.00025809 rank 7
2022-12-08 03:56:58,167 DEBUG TRAIN Batch 26/100 loss 2.221169 loss_att 311.028290 loss_ctc 8.823491 loss_rnnt 1.487578 lr 0.00025811 rank 2
2022-12-08 03:56:58,169 DEBUG TRAIN Batch 26/100 loss 2.181537 loss_att 378.479919 loss_ctc 4.489768 loss_rnnt 1.925067 lr 0.00025811 rank 3
2022-12-08 03:56:58,170 DEBUG TRAIN Batch 26/100 loss 2.993968 loss_att 470.884460 loss_ctc 8.943205 loss_rnnt 2.332942 lr 0.00025810 rank 4
2022-12-08 03:56:58,172 DEBUG TRAIN Batch 26/100 loss 4.864078 loss_att 403.779114 loss_ctc 15.377323 loss_rnnt 3.695940 lr 0.00025811 rank 5
2022-12-08 03:56:58,176 DEBUG TRAIN Batch 26/100 loss 6.143306 loss_att 341.145172 loss_ctc 13.632318 loss_rnnt 5.311193 lr 0.00025811 rank 6
2022-12-08 03:56:58,179 DEBUG TRAIN Batch 26/100 loss 6.622862 loss_att 358.524994 loss_ctc 13.223335 loss_rnnt 5.889476 lr 0.00025813 rank 1
2022-12-08 03:56:58,179 DEBUG TRAIN Batch 26/100 loss 5.782613 loss_att 379.216644 loss_ctc 18.182219 loss_rnnt 4.404880 lr 0.00025810 rank 0
2022-12-08 03:58:01,074 DEBUG TRAIN Batch 26/200 loss 4.485564 loss_att 383.510498 loss_ctc 12.828667 loss_rnnt 3.558553 lr 0.00025808 rank 2
2022-12-08 03:58:01,074 DEBUG TRAIN Batch 26/200 loss 3.807224 loss_att 373.683838 loss_ctc 12.333031 loss_rnnt 2.859912 lr 0.00025806 rank 7
2022-12-08 03:58:01,075 DEBUG TRAIN Batch 26/200 loss 11.692167 loss_att 379.418427 loss_ctc 19.797428 loss_rnnt 10.791583 lr 0.00025808 rank 6
2022-12-08 03:58:01,076 DEBUG TRAIN Batch 26/200 loss 1.877542 loss_att 379.932556 loss_ctc 9.825562 loss_rnnt 0.994429 lr 0.00025806 rank 4
2022-12-08 03:58:01,077 DEBUG TRAIN Batch 26/200 loss 8.752748 loss_att 380.979980 loss_ctc 20.706245 loss_rnnt 7.424582 lr 0.00025807 rank 0
2022-12-08 03:58:01,080 DEBUG TRAIN Batch 26/200 loss 13.326061 loss_att 432.076752 loss_ctc 25.465902 loss_rnnt 11.977191 lr 0.00025810 rank 1
2022-12-08 03:58:01,080 DEBUG TRAIN Batch 26/200 loss 3.796317 loss_att 353.969574 loss_ctc 7.653482 loss_rnnt 3.367743 lr 0.00025807 rank 5
2022-12-08 03:58:01,082 DEBUG TRAIN Batch 26/200 loss 11.244574 loss_att 385.586365 loss_ctc 25.756680 loss_rnnt 9.632117 lr 0.00025807 rank 3
2022-12-08 03:59:04,663 DEBUG TRAIN Batch 26/300 loss 12.304235 loss_att 411.439392 loss_ctc 23.977764 loss_rnnt 11.007176 lr 0.00025805 rank 2
2022-12-08 03:59:04,665 DEBUG TRAIN Batch 26/300 loss 3.219167 loss_att 415.797852 loss_ctc 7.589186 loss_rnnt 2.733610 lr 0.00025804 rank 6
2022-12-08 03:59:04,667 DEBUG TRAIN Batch 26/300 loss 7.087962 loss_att 355.260010 loss_ctc 15.880658 loss_rnnt 6.110996 lr 0.00025802 rank 7
2022-12-08 03:59:04,668 DEBUG TRAIN Batch 26/300 loss 8.079513 loss_att 341.256470 loss_ctc 21.024714 loss_rnnt 6.641157 lr 0.00025803 rank 4
2022-12-08 03:59:04,673 DEBUG TRAIN Batch 26/300 loss 10.989098 loss_att 417.430237 loss_ctc 28.353615 loss_rnnt 9.059707 lr 0.00025804 rank 0
2022-12-08 03:59:04,674 DEBUG TRAIN Batch 26/300 loss 5.876310 loss_att 309.544739 loss_ctc 14.429937 loss_rnnt 4.925908 lr 0.00025806 rank 1
2022-12-08 03:59:04,678 DEBUG TRAIN Batch 26/300 loss 9.540593 loss_att 365.317505 loss_ctc 18.852341 loss_rnnt 8.505955 lr 0.00025804 rank 5
2022-12-08 03:59:04,710 DEBUG TRAIN Batch 26/300 loss 3.036441 loss_att 348.973999 loss_ctc 9.467729 loss_rnnt 2.321853 lr 0.00025804 rank 3
2022-12-08 04:00:19,542 DEBUG TRAIN Batch 26/400 loss 3.578031 loss_att 390.542053 loss_ctc 10.780725 loss_rnnt 2.777731 lr 0.00025799 rank 4
2022-12-08 04:00:19,543 DEBUG TRAIN Batch 26/400 loss 3.093876 loss_att 391.774597 loss_ctc 8.329526 loss_rnnt 2.512137 lr 0.00025799 rank 7
2022-12-08 04:00:19,547 DEBUG TRAIN Batch 26/400 loss 6.530082 loss_att 363.760040 loss_ctc 12.339435 loss_rnnt 5.884599 lr 0.00025801 rank 6
2022-12-08 04:00:19,547 DEBUG TRAIN Batch 26/400 loss 6.871078 loss_att 389.871277 loss_ctc 13.546655 loss_rnnt 6.129348 lr 0.00025803 rank 1
2022-12-08 04:00:19,547 DEBUG TRAIN Batch 26/400 loss 5.536634 loss_att 403.540649 loss_ctc 19.026953 loss_rnnt 4.037710 lr 0.00025800 rank 0
2022-12-08 04:00:19,549 DEBUG TRAIN Batch 26/400 loss 9.493824 loss_att 385.595947 loss_ctc 18.294884 loss_rnnt 8.515928 lr 0.00025801 rank 2
2022-12-08 04:00:19,549 DEBUG TRAIN Batch 26/400 loss 3.010760 loss_att 325.251099 loss_ctc 6.081522 loss_rnnt 2.669564 lr 0.00025800 rank 5
2022-12-08 04:00:19,551 DEBUG TRAIN Batch 26/400 loss 8.318234 loss_att 360.948120 loss_ctc 12.004945 loss_rnnt 7.908600 lr 0.00025800 rank 3
2022-12-08 04:01:22,591 DEBUG TRAIN Batch 26/500 loss 15.172727 loss_att 369.773315 loss_ctc 28.806561 loss_rnnt 13.657856 lr 0.00025796 rank 4
2022-12-08 04:01:22,597 DEBUG TRAIN Batch 26/500 loss 5.474699 loss_att 323.520996 loss_ctc 12.122667 loss_rnnt 4.736036 lr 0.00025796 rank 7
2022-12-08 04:01:22,597 DEBUG TRAIN Batch 26/500 loss 5.604264 loss_att 318.714203 loss_ctc 12.064016 loss_rnnt 4.886513 lr 0.00025797 rank 0
2022-12-08 04:01:22,599 DEBUG TRAIN Batch 26/500 loss 9.832047 loss_att 343.124695 loss_ctc 24.239464 loss_rnnt 8.231222 lr 0.00025797 rank 5
2022-12-08 04:01:22,599 DEBUG TRAIN Batch 26/500 loss 4.648834 loss_att 331.622314 loss_ctc 10.974105 loss_rnnt 3.946026 lr 0.00025799 rank 1
2022-12-08 04:01:22,600 DEBUG TRAIN Batch 26/500 loss 12.407355 loss_att 341.396973 loss_ctc 23.064070 loss_rnnt 11.223276 lr 0.00025798 rank 2
2022-12-08 04:01:22,604 DEBUG TRAIN Batch 26/500 loss 7.649298 loss_att 319.283691 loss_ctc 17.197180 loss_rnnt 6.588423 lr 0.00025797 rank 3
2022-12-08 04:01:22,642 DEBUG TRAIN Batch 26/500 loss 5.759197 loss_att 319.501709 loss_ctc 11.294043 loss_rnnt 5.144215 lr 0.00025797 rank 6
2022-12-08 04:02:26,243 DEBUG TRAIN Batch 26/600 loss 15.887351 loss_att 181.579132 loss_ctc 25.372677 loss_rnnt 14.833426 lr 0.00025794 rank 2
2022-12-08 04:02:26,243 DEBUG TRAIN Batch 26/600 loss 9.055583 loss_att 256.085266 loss_ctc 18.503181 loss_rnnt 8.005850 lr 0.00025792 rank 7
2022-12-08 04:02:26,244 DEBUG TRAIN Batch 26/600 loss 7.302027 loss_att 237.676102 loss_ctc 14.985426 loss_rnnt 6.448316 lr 0.00025793 rank 4
2022-12-08 04:02:26,245 DEBUG TRAIN Batch 26/600 loss 9.496053 loss_att 178.612946 loss_ctc 17.437420 loss_rnnt 8.613679 lr 0.00025793 rank 0
2022-12-08 04:02:26,247 DEBUG TRAIN Batch 26/600 loss 5.136649 loss_att 221.097443 loss_ctc 8.707545 loss_rnnt 4.739882 lr 0.00025794 rank 6
2022-12-08 04:02:26,247 DEBUG TRAIN Batch 26/600 loss 10.072806 loss_att 205.248718 loss_ctc 20.005508 loss_rnnt 8.969172 lr 0.00025796 rank 1
2022-12-08 04:02:26,249 DEBUG TRAIN Batch 26/600 loss 9.830479 loss_att 147.719360 loss_ctc 14.030202 loss_rnnt 9.363843 lr 0.00025794 rank 3
2022-12-08 04:02:26,286 DEBUG TRAIN Batch 26/600 loss 9.017915 loss_att 98.001122 loss_ctc 12.820043 loss_rnnt 8.595456 lr 0.00025794 rank 5
2022-12-08 04:03:32,617 DEBUG TRAIN Batch 26/700 loss 5.252329 loss_att 382.313080 loss_ctc 14.310146 loss_rnnt 4.245905 lr 0.00025790 rank 5
2022-12-08 04:03:32,627 DEBUG TRAIN Batch 26/700 loss 6.390803 loss_att 467.657654 loss_ctc 17.423935 loss_rnnt 5.164899 lr 0.00025789 rank 7
2022-12-08 04:03:32,628 DEBUG TRAIN Batch 26/700 loss 7.661259 loss_att 440.663910 loss_ctc 16.324181 loss_rnnt 6.698712 lr 0.00025790 rank 6
2022-12-08 04:03:32,628 DEBUG TRAIN Batch 26/700 loss 2.564459 loss_att 395.166840 loss_ctc 7.920046 loss_rnnt 1.969394 lr 0.00025791 rank 2
2022-12-08 04:03:32,628 DEBUG TRAIN Batch 26/700 loss 4.244082 loss_att 392.786377 loss_ctc 6.202157 loss_rnnt 4.026519 lr 0.00025789 rank 4
2022-12-08 04:03:32,643 DEBUG TRAIN Batch 26/700 loss 6.017006 loss_att 322.756775 loss_ctc 10.080452 loss_rnnt 5.565513 lr 0.00025790 rank 0
2022-12-08 04:03:32,652 DEBUG TRAIN Batch 26/700 loss 6.952454 loss_att 421.160339 loss_ctc 14.449415 loss_rnnt 6.119459 lr 0.00025793 rank 1
2022-12-08 04:03:32,670 DEBUG TRAIN Batch 26/700 loss 2.938481 loss_att 377.819794 loss_ctc 5.643970 loss_rnnt 2.637871 lr 0.00025790 rank 3
2022-12-08 04:04:49,458 DEBUG TRAIN Batch 26/800 loss 10.302488 loss_att 405.494873 loss_ctc 24.594818 loss_rnnt 8.714452 lr 0.00025786 rank 4
2022-12-08 04:04:49,458 DEBUG TRAIN Batch 26/800 loss 13.416970 loss_att 405.201630 loss_ctc 34.274799 loss_rnnt 11.099434 lr 0.00025785 rank 7
2022-12-08 04:04:49,458 DEBUG TRAIN Batch 26/800 loss 3.241536 loss_att 348.304138 loss_ctc 9.573843 loss_rnnt 2.537947 lr 0.00025787 rank 3
2022-12-08 04:04:49,459 DEBUG TRAIN Batch 26/800 loss 6.584769 loss_att 376.864929 loss_ctc 11.533804 loss_rnnt 6.034877 lr 0.00025786 rank 0
2022-12-08 04:04:49,461 DEBUG TRAIN Batch 26/800 loss 2.982221 loss_att 485.190552 loss_ctc 10.831485 loss_rnnt 2.110081 lr 0.00025787 rank 5
2022-12-08 04:04:49,464 DEBUG TRAIN Batch 26/800 loss 8.092992 loss_att 469.106903 loss_ctc 18.466728 loss_rnnt 6.940355 lr 0.00025789 rank 1
2022-12-08 04:04:49,466 DEBUG TRAIN Batch 26/800 loss 4.467716 loss_att 311.400146 loss_ctc 6.906533 loss_rnnt 4.196736 lr 0.00025787 rank 2
2022-12-08 04:04:49,511 DEBUG TRAIN Batch 26/800 loss 3.320713 loss_att 387.283051 loss_ctc 7.250313 loss_rnnt 2.884090 lr 0.00025787 rank 6
2022-12-08 04:05:52,735 DEBUG TRAIN Batch 26/900 loss 12.137440 loss_att 394.046600 loss_ctc 21.157879 loss_rnnt 11.135168 lr 0.00025782 rank 4
2022-12-08 04:05:52,736 DEBUG TRAIN Batch 26/900 loss 6.188797 loss_att 383.266235 loss_ctc 10.720805 loss_rnnt 5.685240 lr 0.00025783 rank 3
2022-12-08 04:05:52,737 DEBUG TRAIN Batch 26/900 loss 4.496578 loss_att 349.389160 loss_ctc 10.719966 loss_rnnt 3.805091 lr 0.00025786 rank 1
2022-12-08 04:05:52,738 DEBUG TRAIN Batch 26/900 loss 8.334831 loss_att 381.340759 loss_ctc 17.419575 loss_rnnt 7.325415 lr 0.00025784 rank 2
2022-12-08 04:05:52,738 DEBUG TRAIN Batch 26/900 loss 4.570382 loss_att 318.597015 loss_ctc 8.252448 loss_rnnt 4.161264 lr 0.00025784 rank 6
2022-12-08 04:05:52,740 DEBUG TRAIN Batch 26/900 loss 2.798181 loss_att 327.791992 loss_ctc 4.760314 loss_rnnt 2.580167 lr 0.00025782 rank 7
2022-12-08 04:05:52,741 DEBUG TRAIN Batch 26/900 loss 9.718819 loss_att 319.432922 loss_ctc 14.587032 loss_rnnt 9.177906 lr 0.00025783 rank 5
2022-12-08 04:05:52,741 DEBUG TRAIN Batch 26/900 loss 4.501307 loss_att 336.455688 loss_ctc 12.898313 loss_rnnt 3.568307 lr 0.00025783 rank 0
2022-12-08 04:06:56,881 DEBUG TRAIN Batch 26/1000 loss 16.102312 loss_att 428.506470 loss_ctc 27.179594 loss_rnnt 14.871503 lr 0.00025780 rank 6
2022-12-08 04:06:56,883 DEBUG TRAIN Batch 26/1000 loss 9.203402 loss_att 394.205688 loss_ctc 14.826202 loss_rnnt 8.578647 lr 0.00025778 rank 7
2022-12-08 04:06:56,884 DEBUG TRAIN Batch 26/1000 loss 7.715233 loss_att 361.436157 loss_ctc 14.955528 loss_rnnt 6.910756 lr 0.00025782 rank 1
2022-12-08 04:06:56,884 DEBUG TRAIN Batch 26/1000 loss 5.289545 loss_att 402.044128 loss_ctc 11.858621 loss_rnnt 4.559648 lr 0.00025779 rank 4
2022-12-08 04:06:56,885 DEBUG TRAIN Batch 26/1000 loss 8.682217 loss_att 388.261536 loss_ctc 19.379423 loss_rnnt 7.493639 lr 0.00025780 rank 3
2022-12-08 04:06:56,886 DEBUG TRAIN Batch 26/1000 loss 4.257685 loss_att 372.184998 loss_ctc 8.042654 loss_rnnt 3.837133 lr 0.00025781 rank 2
2022-12-08 04:06:56,892 DEBUG TRAIN Batch 26/1000 loss 10.051094 loss_att 359.654938 loss_ctc 17.779072 loss_rnnt 9.192430 lr 0.00025780 rank 5
2022-12-08 04:06:56,893 DEBUG TRAIN Batch 26/1000 loss 9.959377 loss_att 341.034149 loss_ctc 23.097073 loss_rnnt 8.499634 lr 0.00025780 rank 0
2022-12-08 04:08:16,636 DEBUG TRAIN Batch 26/1100 loss 11.416202 loss_att 289.023804 loss_ctc 19.989843 loss_rnnt 10.463575 lr 0.00025775 rank 7
2022-12-08 04:08:16,639 DEBUG TRAIN Batch 26/1100 loss 7.839072 loss_att 337.151306 loss_ctc 15.659996 loss_rnnt 6.970080 lr 0.00025777 rank 2
2022-12-08 04:08:16,639 DEBUG TRAIN Batch 26/1100 loss 16.505211 loss_att 396.924744 loss_ctc 24.358715 loss_rnnt 15.632599 lr 0.00025776 rank 0
2022-12-08 04:08:16,640 DEBUG TRAIN Batch 26/1100 loss 3.742321 loss_att 316.287048 loss_ctc 12.614902 loss_rnnt 2.756479 lr 0.00025775 rank 4
2022-12-08 04:08:16,640 DEBUG TRAIN Batch 26/1100 loss 8.526113 loss_att 361.630798 loss_ctc 14.397779 loss_rnnt 7.873705 lr 0.00025777 rank 6
2022-12-08 04:08:16,642 DEBUG TRAIN Batch 26/1100 loss 5.897255 loss_att 350.328979 loss_ctc 15.030006 loss_rnnt 4.882505 lr 0.00025779 rank 1
2022-12-08 04:08:16,646 DEBUG TRAIN Batch 26/1100 loss 6.831346 loss_att 345.778992 loss_ctc 13.687321 loss_rnnt 6.069571 lr 0.00025776 rank 5
2022-12-08 04:08:16,646 DEBUG TRAIN Batch 26/1100 loss 5.189087 loss_att 309.589264 loss_ctc 9.247161 loss_rnnt 4.738191 lr 0.00025776 rank 3
2022-12-08 04:09:20,639 DEBUG TRAIN Batch 26/1200 loss 7.904310 loss_att 295.065674 loss_ctc 11.883334 loss_rnnt 7.462196 lr 0.00025773 rank 6
2022-12-08 04:09:20,640 DEBUG TRAIN Batch 26/1200 loss 12.197780 loss_att 176.075195 loss_ctc 18.242292 loss_rnnt 11.526167 lr 0.00025773 rank 3
2022-12-08 04:09:20,641 DEBUG TRAIN Batch 26/1200 loss 6.980751 loss_att 327.990601 loss_ctc 12.462612 loss_rnnt 6.371655 lr 0.00025772 rank 7
2022-12-08 04:09:20,643 DEBUG TRAIN Batch 26/1200 loss 8.515010 loss_att 281.789062 loss_ctc 22.494453 loss_rnnt 6.961739 lr 0.00025773 rank 5
2022-12-08 04:09:20,644 DEBUG TRAIN Batch 26/1200 loss 10.868518 loss_att 210.558441 loss_ctc 18.628899 loss_rnnt 10.006253 lr 0.00025773 rank 0
2022-12-08 04:09:20,646 DEBUG TRAIN Batch 26/1200 loss 6.186704 loss_att 336.541992 loss_ctc 14.408431 loss_rnnt 5.273179 lr 0.00025772 rank 4
2022-12-08 04:09:20,647 DEBUG TRAIN Batch 26/1200 loss 4.519736 loss_att 298.210846 loss_ctc 9.505515 loss_rnnt 3.965761 lr 0.00025775 rank 1
2022-12-08 04:09:20,661 DEBUG TRAIN Batch 26/1200 loss 3.459899 loss_att 275.553864 loss_ctc 7.984301 loss_rnnt 2.957188 lr 0.00025774 rank 2
2022-12-08 04:10:23,749 DEBUG TRAIN Batch 26/1300 loss 7.371156 loss_att 389.517181 loss_ctc 15.390422 loss_rnnt 6.480126 lr 0.00025769 rank 4
2022-12-08 04:10:23,754 DEBUG TRAIN Batch 26/1300 loss 9.695967 loss_att 335.325043 loss_ctc 23.174896 loss_rnnt 8.198308 lr 0.00025770 rank 3
2022-12-08 04:10:23,756 DEBUG TRAIN Batch 26/1300 loss 6.823345 loss_att 373.551697 loss_ctc 9.802773 loss_rnnt 6.492298 lr 0.00025770 rank 5
2022-12-08 04:10:23,757 DEBUG TRAIN Batch 26/1300 loss 8.817276 loss_att 341.978851 loss_ctc 19.376326 loss_rnnt 7.644049 lr 0.00025769 rank 0
2022-12-08 04:10:23,757 DEBUG TRAIN Batch 26/1300 loss 7.598130 loss_att 179.427505 loss_ctc 13.679082 loss_rnnt 6.922469 lr 0.00025768 rank 7
2022-12-08 04:10:23,759 DEBUG TRAIN Batch 26/1300 loss 9.589921 loss_att 453.272278 loss_ctc 27.056271 loss_rnnt 7.649216 lr 0.00025770 rank 2
2022-12-08 04:10:23,760 DEBUG TRAIN Batch 26/1300 loss 10.074716 loss_att 441.752869 loss_ctc 22.702705 loss_rnnt 8.671606 lr 0.00025770 rank 6
2022-12-08 04:10:23,760 DEBUG TRAIN Batch 26/1300 loss 7.569638 loss_att 86.051353 loss_ctc 10.038899 loss_rnnt 7.295275 lr 0.00025772 rank 1
2022-12-08 04:11:29,076 DEBUG TRAIN Batch 26/1400 loss 1.682196 loss_att 343.024841 loss_ctc 7.852044 loss_rnnt 0.996657 lr 0.00025767 rank 2
2022-12-08 04:11:29,080 DEBUG TRAIN Batch 26/1400 loss 8.800629 loss_att 377.102875 loss_ctc 16.235552 loss_rnnt 7.974527 lr 0.00025766 rank 3
2022-12-08 04:11:29,082 DEBUG TRAIN Batch 26/1400 loss 4.351542 loss_att 398.911743 loss_ctc 17.897306 loss_rnnt 2.846457 lr 0.00025765 rank 7
2022-12-08 04:11:29,085 DEBUG TRAIN Batch 26/1400 loss 6.542703 loss_att 424.625549 loss_ctc 14.995037 loss_rnnt 5.603555 lr 0.00025765 rank 4
2022-12-08 04:11:29,086 DEBUG TRAIN Batch 26/1400 loss 4.115649 loss_att 374.931335 loss_ctc 9.637770 loss_rnnt 3.502080 lr 0.00025766 rank 6
2022-12-08 04:11:29,087 DEBUG TRAIN Batch 26/1400 loss 13.373929 loss_att 403.862427 loss_ctc 23.400280 loss_rnnt 12.259891 lr 0.00025766 rank 0
2022-12-08 04:11:29,089 DEBUG TRAIN Batch 26/1400 loss 6.957211 loss_att 388.394531 loss_ctc 11.973201 loss_rnnt 6.399879 lr 0.00025769 rank 1
2022-12-08 04:11:29,107 DEBUG TRAIN Batch 26/1400 loss 6.302382 loss_att 350.815308 loss_ctc 12.441356 loss_rnnt 5.620275 lr 0.00025766 rank 5
2022-12-08 04:12:43,721 DEBUG TRAIN Batch 26/1500 loss 5.762470 loss_att 358.643860 loss_ctc 12.267543 loss_rnnt 5.039684 lr 0.00025762 rank 4
2022-12-08 04:12:43,726 DEBUG TRAIN Batch 26/1500 loss 4.790064 loss_att 412.809052 loss_ctc 10.351129 loss_rnnt 4.172168 lr 0.00025763 rank 6
2022-12-08 04:12:43,728 DEBUG TRAIN Batch 26/1500 loss 2.733268 loss_att 384.946960 loss_ctc 5.983459 loss_rnnt 2.372136 lr 0.00025765 rank 1
2022-12-08 04:12:43,728 DEBUG TRAIN Batch 26/1500 loss 3.039907 loss_att 355.084869 loss_ctc 4.514502 loss_rnnt 2.876064 lr 0.00025763 rank 3
2022-12-08 04:12:43,728 DEBUG TRAIN Batch 26/1500 loss 9.414378 loss_att 383.624237 loss_ctc 21.404514 loss_rnnt 8.082141 lr 0.00025761 rank 7
2022-12-08 04:12:43,729 DEBUG TRAIN Batch 26/1500 loss 7.297982 loss_att 276.493042 loss_ctc 9.779863 loss_rnnt 7.022218 lr 0.00025763 rank 5
2022-12-08 04:12:43,736 DEBUG TRAIN Batch 26/1500 loss 7.681058 loss_att 426.943359 loss_ctc 18.466089 loss_rnnt 6.482722 lr 0.00025762 rank 0
2022-12-08 04:12:43,767 DEBUG TRAIN Batch 26/1500 loss 6.821085 loss_att 444.484314 loss_ctc 21.695190 loss_rnnt 5.168406 lr 0.00025763 rank 2
2022-12-08 04:13:46,524 DEBUG TRAIN Batch 26/1600 loss 6.765510 loss_att 378.192993 loss_ctc 12.211417 loss_rnnt 6.160409 lr 0.00025758 rank 7
2022-12-08 04:13:46,527 DEBUG TRAIN Batch 26/1600 loss 10.726218 loss_att 380.401794 loss_ctc 20.545460 loss_rnnt 9.635191 lr 0.00025759 rank 3
2022-12-08 04:13:46,529 DEBUG TRAIN Batch 26/1600 loss 13.396084 loss_att 415.783264 loss_ctc 21.678410 loss_rnnt 12.475826 lr 0.00025762 rank 1
2022-12-08 04:13:46,529 DEBUG TRAIN Batch 26/1600 loss 9.041511 loss_att 391.621063 loss_ctc 18.747284 loss_rnnt 7.963091 lr 0.00025758 rank 4
2022-12-08 04:13:46,532 DEBUG TRAIN Batch 26/1600 loss 6.327620 loss_att 366.344177 loss_ctc 14.512478 loss_rnnt 5.418191 lr 0.00025760 rank 2
2022-12-08 04:13:46,534 DEBUG TRAIN Batch 26/1600 loss 11.411366 loss_att 413.784943 loss_ctc 26.634497 loss_rnnt 9.719906 lr 0.00025760 rank 6
2022-12-08 04:13:46,533 DEBUG TRAIN Batch 26/1600 loss 7.013103 loss_att 382.780090 loss_ctc 11.597742 loss_rnnt 6.503698 lr 0.00025759 rank 0
2022-12-08 04:13:46,539 DEBUG TRAIN Batch 26/1600 loss 6.310134 loss_att 364.997650 loss_ctc 20.173746 loss_rnnt 4.769733 lr 0.00025759 rank 5
2022-12-08 04:14:50,807 DEBUG TRAIN Batch 26/1700 loss 3.306913 loss_att 342.925964 loss_ctc 7.484632 loss_rnnt 2.842722 lr 0.00025755 rank 4
2022-12-08 04:14:50,810 DEBUG TRAIN Batch 26/1700 loss 7.527529 loss_att 354.446350 loss_ctc 21.756590 loss_rnnt 5.946522 lr 0.00025756 rank 3
2022-12-08 04:14:50,812 DEBUG TRAIN Batch 26/1700 loss 8.580538 loss_att 373.770752 loss_ctc 22.094952 loss_rnnt 7.078937 lr 0.00025756 rank 6
2022-12-08 04:14:50,812 DEBUG TRAIN Batch 26/1700 loss 7.590935 loss_att 316.385132 loss_ctc 14.273466 loss_rnnt 6.848432 lr 0.00025757 rank 2
2022-12-08 04:14:50,813 DEBUG TRAIN Batch 26/1700 loss 11.287658 loss_att 319.362061 loss_ctc 20.676861 loss_rnnt 10.244413 lr 0.00025756 rank 5
2022-12-08 04:14:50,814 DEBUG TRAIN Batch 26/1700 loss 6.327240 loss_att 310.276855 loss_ctc 8.458802 loss_rnnt 6.090400 lr 0.00025756 rank 0
2022-12-08 04:14:50,815 DEBUG TRAIN Batch 26/1700 loss 3.505484 loss_att 397.244690 loss_ctc 5.614110 loss_rnnt 3.271193 lr 0.00025754 rank 7
2022-12-08 04:14:50,833 DEBUG TRAIN Batch 26/1700 loss 10.583489 loss_att 358.091736 loss_ctc 19.328506 loss_rnnt 9.611821 lr 0.00025758 rank 1
2022-12-08 04:16:13,582 DEBUG TRAIN Batch 26/1800 loss 8.275963 loss_att 372.641846 loss_ctc 20.237761 loss_rnnt 6.946874 lr 0.00025751 rank 7
2022-12-08 04:16:13,583 DEBUG TRAIN Batch 26/1800 loss 11.646722 loss_att 330.787537 loss_ctc 17.410194 loss_rnnt 11.006336 lr 0.00025753 rank 6
2022-12-08 04:16:13,584 DEBUG TRAIN Batch 26/1800 loss 5.530283 loss_att 221.180603 loss_ctc 10.446795 loss_rnnt 4.984004 lr 0.00025753 rank 3
2022-12-08 04:16:13,587 DEBUG TRAIN Batch 26/1800 loss 6.046998 loss_att 342.978455 loss_ctc 9.660036 loss_rnnt 5.645549 lr 0.00025751 rank 4
2022-12-08 04:16:13,588 DEBUG TRAIN Batch 26/1800 loss 9.713080 loss_att 319.279358 loss_ctc 18.892651 loss_rnnt 8.693129 lr 0.00025755 rank 1
2022-12-08 04:16:13,590 DEBUG TRAIN Batch 26/1800 loss 12.343655 loss_att 340.713226 loss_ctc 20.171783 loss_rnnt 11.473863 lr 0.00025753 rank 2
2022-12-08 04:16:13,591 DEBUG TRAIN Batch 26/1800 loss 11.512745 loss_att 282.271912 loss_ctc 24.118141 loss_rnnt 10.112144 lr 0.00025752 rank 5
2022-12-08 04:16:13,593 DEBUG TRAIN Batch 26/1800 loss 12.616741 loss_att 279.034332 loss_ctc 24.484407 loss_rnnt 11.298112 lr 0.00025752 rank 0
2022-12-08 04:17:16,559 DEBUG TRAIN Batch 26/1900 loss 6.742110 loss_att 277.496826 loss_ctc 12.329740 loss_rnnt 6.121263 lr 0.00025748 rank 7
2022-12-08 04:17:16,562 DEBUG TRAIN Batch 26/1900 loss 5.188256 loss_att 178.520660 loss_ctc 9.846863 loss_rnnt 4.670633 lr 0.00025750 rank 2
2022-12-08 04:17:16,562 DEBUG TRAIN Batch 26/1900 loss 8.946301 loss_att 228.486191 loss_ctc 16.920198 loss_rnnt 8.060312 lr 0.00025748 rank 4
2022-12-08 04:17:16,562 DEBUG TRAIN Batch 26/1900 loss 10.912876 loss_att 185.502701 loss_ctc 16.932255 loss_rnnt 10.244056 lr 0.00025749 rank 6
2022-12-08 04:17:16,563 DEBUG TRAIN Batch 26/1900 loss 12.170823 loss_att 413.208008 loss_ctc 18.417870 loss_rnnt 11.476707 lr 0.00025749 rank 0
2022-12-08 04:17:16,563 DEBUG TRAIN Batch 26/1900 loss 7.635596 loss_att 237.807831 loss_ctc 14.508395 loss_rnnt 6.871952 lr 0.00025752 rank 1
2022-12-08 04:17:16,569 DEBUG TRAIN Batch 26/1900 loss 7.393414 loss_att 372.458679 loss_ctc 11.262359 loss_rnnt 6.963531 lr 0.00025749 rank 3
2022-12-08 04:17:16,613 DEBUG TRAIN Batch 26/1900 loss 12.567004 loss_att 144.874756 loss_ctc 20.573931 loss_rnnt 11.677346 lr 0.00025749 rank 5
2022-12-08 04:18:20,862 DEBUG TRAIN Batch 26/2000 loss 2.412219 loss_att 392.445160 loss_ctc 10.289228 loss_rnnt 1.536996 lr 0.00025745 rank 4
2022-12-08 04:18:20,863 DEBUG TRAIN Batch 26/2000 loss 3.334704 loss_att 377.889648 loss_ctc 6.311351 loss_rnnt 3.003965 lr 0.00025746 rank 2
2022-12-08 04:18:20,864 DEBUG TRAIN Batch 26/2000 loss 5.051238 loss_att 507.515076 loss_ctc 13.227484 loss_rnnt 4.142766 lr 0.00025744 rank 7
2022-12-08 04:18:20,864 DEBUG TRAIN Batch 26/2000 loss 10.404119 loss_att 399.280365 loss_ctc 18.681374 loss_rnnt 9.484424 lr 0.00025746 rank 3
2022-12-08 04:18:20,869 DEBUG TRAIN Batch 26/2000 loss 7.327553 loss_att 368.358734 loss_ctc 14.759581 loss_rnnt 6.501772 lr 0.00025745 rank 0
2022-12-08 04:18:20,870 DEBUG TRAIN Batch 26/2000 loss 5.578933 loss_att 404.351196 loss_ctc 12.565066 loss_rnnt 4.802696 lr 0.00025746 rank 5
2022-12-08 04:18:20,901 DEBUG TRAIN Batch 26/2000 loss 3.060186 loss_att 393.895996 loss_ctc 6.382349 loss_rnnt 2.691057 lr 0.00025748 rank 1
2022-12-08 04:18:20,919 DEBUG TRAIN Batch 26/2000 loss 3.216064 loss_att 352.121674 loss_ctc 10.981589 loss_rnnt 2.353229 lr 0.00025746 rank 6
2022-12-08 04:19:26,758 DEBUG TRAIN Batch 26/2100 loss 3.621598 loss_att 381.118042 loss_ctc 7.383187 loss_rnnt 3.203644 lr 0.00025745 rank 1
2022-12-08 04:19:26,759 DEBUG TRAIN Batch 26/2100 loss 7.815423 loss_att 389.829346 loss_ctc 10.252162 loss_rnnt 7.544674 lr 0.00025741 rank 4
2022-12-08 04:19:26,765 DEBUG TRAIN Batch 26/2100 loss 7.097582 loss_att 372.873901 loss_ctc 10.483027 loss_rnnt 6.721422 lr 0.00025741 rank 7
2022-12-08 04:19:26,768 DEBUG TRAIN Batch 26/2100 loss 6.089163 loss_att 351.766449 loss_ctc 11.944083 loss_rnnt 5.438617 lr 0.00025743 rank 6
2022-12-08 04:19:26,769 DEBUG TRAIN Batch 26/2100 loss 10.574938 loss_att 414.647064 loss_ctc 23.931305 loss_rnnt 9.090898 lr 0.00025742 rank 5
2022-12-08 04:19:26,769 DEBUG TRAIN Batch 26/2100 loss 11.500216 loss_att 411.071106 loss_ctc 19.146984 loss_rnnt 10.650576 lr 0.00025742 rank 3
2022-12-08 04:19:26,770 DEBUG TRAIN Batch 26/2100 loss 7.683142 loss_att 414.878998 loss_ctc 17.776552 loss_rnnt 6.561652 lr 0.00025743 rank 2
2022-12-08 04:19:26,770 DEBUG TRAIN Batch 26/2100 loss 7.003448 loss_att 349.948700 loss_ctc 12.316378 loss_rnnt 6.413122 lr 0.00025742 rank 0
2022-12-08 04:20:40,284 DEBUG TRAIN Batch 26/2200 loss 8.670116 loss_att 414.491364 loss_ctc 13.728224 loss_rnnt 8.108105 lr 0.00025738 rank 4
2022-12-08 04:20:40,285 DEBUG TRAIN Batch 26/2200 loss 6.874036 loss_att 408.062592 loss_ctc 16.312819 loss_rnnt 5.825282 lr 0.00025737 rank 7
2022-12-08 04:20:40,288 DEBUG TRAIN Batch 26/2200 loss 9.561102 loss_att 426.929016 loss_ctc 21.171879 loss_rnnt 8.271015 lr 0.00025741 rank 1
2022-12-08 04:20:40,290 DEBUG TRAIN Batch 26/2200 loss 8.775589 loss_att 337.723328 loss_ctc 17.055729 loss_rnnt 7.855573 lr 0.00025739 rank 5
2022-12-08 04:20:40,291 DEBUG TRAIN Batch 26/2200 loss 9.185057 loss_att 316.233948 loss_ctc 10.741666 loss_rnnt 9.012100 lr 0.00025739 rank 6
2022-12-08 04:20:40,291 DEBUG TRAIN Batch 26/2200 loss 19.419569 loss_att 417.244995 loss_ctc 36.269146 loss_rnnt 17.547394 lr 0.00025739 rank 0
2022-12-08 04:20:40,294 DEBUG TRAIN Batch 26/2200 loss 7.141296 loss_att 362.340424 loss_ctc 14.689911 loss_rnnt 6.302561 lr 0.00025739 rank 3
2022-12-08 04:20:40,333 DEBUG TRAIN Batch 26/2200 loss 7.955380 loss_att 361.340118 loss_ctc 17.548447 loss_rnnt 6.889484 lr 0.00025740 rank 2
2022-12-08 04:21:43,293 DEBUG TRAIN Batch 26/2300 loss 3.659088 loss_att 361.719177 loss_ctc 12.245979 loss_rnnt 2.704989 lr 0.00025734 rank 7
2022-12-08 04:21:43,309 DEBUG TRAIN Batch 26/2300 loss 4.426836 loss_att 313.408295 loss_ctc 7.692397 loss_rnnt 4.063996 lr 0.00025735 rank 3
2022-12-08 04:21:43,309 DEBUG TRAIN Batch 26/2300 loss 5.002320 loss_att 397.740051 loss_ctc 13.290590 loss_rnnt 4.081401 lr 0.00025736 rank 2
2022-12-08 04:21:43,310 DEBUG TRAIN Batch 26/2300 loss 8.615938 loss_att 334.080658 loss_ctc 19.003696 loss_rnnt 7.461743 lr 0.00025734 rank 4
2022-12-08 04:21:43,311 DEBUG TRAIN Batch 26/2300 loss 8.977774 loss_att 355.550110 loss_ctc 20.715233 loss_rnnt 7.673612 lr 0.00025736 rank 6
2022-12-08 04:21:43,312 DEBUG TRAIN Batch 26/2300 loss 12.348232 loss_att 356.007812 loss_ctc 22.325804 loss_rnnt 11.239614 lr 0.00025735 rank 0
2022-12-08 04:21:43,319 DEBUG TRAIN Batch 26/2300 loss 3.437850 loss_att 401.891083 loss_ctc 8.165075 loss_rnnt 2.912603 lr 0.00025735 rank 5
2022-12-08 04:21:43,343 DEBUG TRAIN Batch 26/2300 loss 6.481892 loss_att 345.572784 loss_ctc 12.077139 loss_rnnt 5.860198 lr 0.00025738 rank 1
2022-12-08 04:22:47,670 DEBUG TRAIN Batch 26/2400 loss 7.651745 loss_att 336.727051 loss_ctc 18.672928 loss_rnnt 6.427169 lr 0.00025731 rank 4
2022-12-08 04:22:47,672 DEBUG TRAIN Batch 26/2400 loss 6.214115 loss_att 213.156754 loss_ctc 9.935139 loss_rnnt 5.800668 lr 0.00025732 rank 3
2022-12-08 04:22:47,672 DEBUG TRAIN Batch 26/2400 loss 8.525210 loss_att 328.870789 loss_ctc 13.612678 loss_rnnt 7.959936 lr 0.00025732 rank 6
2022-12-08 04:22:47,672 DEBUG TRAIN Batch 26/2400 loss 2.830746 loss_att 295.203308 loss_ctc 5.738682 loss_rnnt 2.507642 lr 0.00025731 rank 7
2022-12-08 04:22:47,673 DEBUG TRAIN Batch 26/2400 loss 6.586365 loss_att 343.542572 loss_ctc 14.532544 loss_rnnt 5.703456 lr 0.00025732 rank 0
2022-12-08 04:22:47,674 DEBUG TRAIN Batch 26/2400 loss 10.237884 loss_att 295.791565 loss_ctc 19.545198 loss_rnnt 9.203737 lr 0.00025734 rank 1
2022-12-08 04:22:47,697 DEBUG TRAIN Batch 26/2400 loss 7.241883 loss_att 324.270325 loss_ctc 17.347176 loss_rnnt 6.119073 lr 0.00025732 rank 5
2022-12-08 04:22:47,720 DEBUG TRAIN Batch 26/2400 loss 12.384503 loss_att 336.969452 loss_ctc 26.034306 loss_rnnt 10.867859 lr 0.00025733 rank 2
2022-12-08 04:24:02,781 DEBUG TRAIN Batch 26/2500 loss 5.420076 loss_att 286.069061 loss_ctc 16.025686 loss_rnnt 4.241675 lr 0.00025727 rank 7
2022-12-08 04:24:02,784 DEBUG TRAIN Batch 26/2500 loss 15.677874 loss_att 297.613251 loss_ctc 24.629280 loss_rnnt 14.683273 lr 0.00025728 rank 4
2022-12-08 04:24:02,785 DEBUG TRAIN Batch 26/2500 loss 2.130044 loss_att 366.990173 loss_ctc 5.622329 loss_rnnt 1.742013 lr 0.00025729 rank 3
2022-12-08 04:24:02,788 DEBUG TRAIN Batch 26/2500 loss 10.226007 loss_att 323.415619 loss_ctc 17.637140 loss_rnnt 9.402549 lr 0.00025729 rank 2
2022-12-08 04:24:02,788 DEBUG TRAIN Batch 26/2500 loss 9.912800 loss_att 142.786652 loss_ctc 15.025428 loss_rnnt 9.344730 lr 0.00025728 rank 0
2022-12-08 04:24:02,792 DEBUG TRAIN Batch 26/2500 loss 15.983209 loss_att 296.245941 loss_ctc 25.843378 loss_rnnt 14.887634 lr 0.00025731 rank 1
2022-12-08 04:24:02,801 DEBUG TRAIN Batch 26/2500 loss 16.553322 loss_att 266.339844 loss_ctc 27.586134 loss_rnnt 15.327456 lr 0.00025729 rank 6
2022-12-08 04:24:02,802 DEBUG TRAIN Batch 26/2500 loss 9.011235 loss_att 176.385803 loss_ctc 14.355228 loss_rnnt 8.417459 lr 0.00025729 rank 5
2022-12-08 04:25:06,221 DEBUG TRAIN Batch 26/2600 loss 4.933635 loss_att 574.247803 loss_ctc 19.717115 loss_rnnt 3.291026 lr 0.00025726 rank 2
2022-12-08 04:25:06,221 DEBUG TRAIN Batch 26/2600 loss 5.510961 loss_att 148.265640 loss_ctc 11.531153 loss_rnnt 4.842051 lr 0.00025724 rank 7
2022-12-08 04:25:06,225 DEBUG TRAIN Batch 26/2600 loss 7.086297 loss_att 390.309174 loss_ctc 14.718750 loss_rnnt 6.238246 lr 0.00025724 rank 4
2022-12-08 04:25:06,227 DEBUG TRAIN Batch 26/2600 loss 6.592987 loss_att 434.016937 loss_ctc 10.848670 loss_rnnt 6.120133 lr 0.00025725 rank 0
2022-12-08 04:25:06,228 DEBUG TRAIN Batch 26/2600 loss 5.231426 loss_att 399.919189 loss_ctc 12.440575 loss_rnnt 4.430410 lr 0.00025725 rank 3
2022-12-08 04:25:06,230 DEBUG TRAIN Batch 26/2600 loss 6.873251 loss_att 443.379364 loss_ctc 18.706297 loss_rnnt 5.558468 lr 0.00025728 rank 1
2022-12-08 04:25:06,230 DEBUG TRAIN Batch 26/2600 loss 4.298522 loss_att 385.252258 loss_ctc 12.665462 loss_rnnt 3.368863 lr 0.00025725 rank 5
2022-12-08 04:25:06,232 DEBUG TRAIN Batch 26/2600 loss 6.676256 loss_att 500.991882 loss_ctc 17.012962 loss_rnnt 5.527733 lr 0.00025726 rank 6
2022-12-08 04:26:09,020 DEBUG TRAIN Batch 26/2700 loss 11.964820 loss_att 442.320557 loss_ctc 22.771452 loss_rnnt 10.764083 lr 0.00025720 rank 7
2022-12-08 04:26:09,021 DEBUG TRAIN Batch 26/2700 loss 15.738710 loss_att 458.713318 loss_ctc 45.202007 loss_rnnt 12.465012 lr 0.00025721 rank 4
2022-12-08 04:26:09,022 DEBUG TRAIN Batch 26/2700 loss 7.580719 loss_att 400.975037 loss_ctc 14.055433 loss_rnnt 6.861307 lr 0.00025724 rank 1
2022-12-08 04:26:09,023 DEBUG TRAIN Batch 26/2700 loss 5.276454 loss_att 321.456146 loss_ctc 12.161113 loss_rnnt 4.511492 lr 0.00025721 rank 0
2022-12-08 04:26:09,029 DEBUG TRAIN Batch 26/2700 loss 3.271362 loss_att 395.378174 loss_ctc 9.417051 loss_rnnt 2.588508 lr 0.00025722 rank 5
2022-12-08 04:26:09,056 DEBUG TRAIN Batch 26/2700 loss 3.408631 loss_att 301.718292 loss_ctc 4.365143 loss_rnnt 3.302351 lr 0.00025722 rank 6
2022-12-08 04:26:09,068 DEBUG TRAIN Batch 26/2700 loss 7.048794 loss_att 348.309387 loss_ctc 11.594425 loss_rnnt 6.543724 lr 0.00025722 rank 3
2022-12-08 04:26:09,069 DEBUG TRAIN Batch 26/2700 loss 4.216496 loss_att 375.957031 loss_ctc 8.324696 loss_rnnt 3.760029 lr 0.00025722 rank 2
2022-12-08 04:27:13,379 DEBUG TRAIN Batch 26/2800 loss 5.654246 loss_att 396.953125 loss_ctc 13.639278 loss_rnnt 4.767021 lr 0.00025719 rank 2
2022-12-08 04:27:13,380 DEBUG TRAIN Batch 26/2800 loss 6.549034 loss_att 326.709076 loss_ctc 16.578947 loss_rnnt 5.434599 lr 0.00025719 rank 6
2022-12-08 04:27:13,386 DEBUG TRAIN Batch 26/2800 loss 1.315790 loss_att 339.591614 loss_ctc 4.086588 loss_rnnt 1.007924 lr 0.00025717 rank 7
2022-12-08 04:27:13,387 DEBUG TRAIN Batch 26/2800 loss 5.597255 loss_att 436.741425 loss_ctc 21.354673 loss_rnnt 3.846431 lr 0.00025717 rank 4
2022-12-08 04:27:13,390 DEBUG TRAIN Batch 26/2800 loss 5.611437 loss_att 299.304993 loss_ctc 10.840404 loss_rnnt 5.030440 lr 0.00025721 rank 1
2022-12-08 04:27:13,392 DEBUG TRAIN Batch 26/2800 loss 7.758952 loss_att 377.847595 loss_ctc 13.920431 loss_rnnt 7.074344 lr 0.00025718 rank 5
2022-12-08 04:27:13,393 DEBUG TRAIN Batch 26/2800 loss 7.590298 loss_att 348.908905 loss_ctc 22.724529 loss_rnnt 5.908717 lr 0.00025718 rank 0
2022-12-08 04:27:13,396 DEBUG TRAIN Batch 26/2800 loss 12.740100 loss_att 412.022949 loss_ctc 30.542137 loss_rnnt 10.762096 lr 0.00025718 rank 3
2022-12-08 04:28:27,112 DEBUG TRAIN Batch 26/2900 loss 12.839955 loss_att 390.837921 loss_ctc 24.615204 loss_rnnt 11.531595 lr 0.00025716 rank 2
2022-12-08 04:28:27,114 DEBUG TRAIN Batch 26/2900 loss 19.605368 loss_att 422.149780 loss_ctc 37.417301 loss_rnnt 17.626265 lr 0.00025714 rank 4
2022-12-08 04:28:27,113 DEBUG TRAIN Batch 26/2900 loss 7.948141 loss_att 378.099213 loss_ctc 16.061937 loss_rnnt 7.046608 lr 0.00025715 rank 5
2022-12-08 04:28:27,114 DEBUG TRAIN Batch 26/2900 loss 2.019637 loss_att 343.062653 loss_ctc 5.203222 loss_rnnt 1.665906 lr 0.00025715 rank 3
2022-12-08 04:28:27,114 DEBUG TRAIN Batch 26/2900 loss 11.055239 loss_att 397.508392 loss_ctc 28.146135 loss_rnnt 9.156251 lr 0.00025714 rank 7
2022-12-08 04:28:27,115 DEBUG TRAIN Batch 26/2900 loss 9.518613 loss_att 370.233215 loss_ctc 18.026651 loss_rnnt 8.573276 lr 0.00025715 rank 6
2022-12-08 04:28:27,116 DEBUG TRAIN Batch 26/2900 loss 8.338964 loss_att 411.021301 loss_ctc 14.783016 loss_rnnt 7.622958 lr 0.00025715 rank 0
2022-12-08 04:28:27,117 DEBUG TRAIN Batch 26/2900 loss 9.402101 loss_att 400.556091 loss_ctc 19.362982 loss_rnnt 8.295336 lr 0.00025717 rank 1
2022-12-08 04:29:30,748 DEBUG TRAIN Batch 26/3000 loss 11.645559 loss_att 359.368958 loss_ctc 22.950422 loss_rnnt 10.389464 lr 0.00025710 rank 7
2022-12-08 04:29:30,751 DEBUG TRAIN Batch 26/3000 loss 4.309509 loss_att 315.818176 loss_ctc 6.363680 loss_rnnt 4.081268 lr 0.00025711 rank 4
2022-12-08 04:29:30,753 DEBUG TRAIN Batch 26/3000 loss 16.625477 loss_att 391.645386 loss_ctc 35.791393 loss_rnnt 14.495931 lr 0.00025712 rank 2
2022-12-08 04:29:30,755 DEBUG TRAIN Batch 26/3000 loss 4.298158 loss_att 318.787781 loss_ctc 12.158653 loss_rnnt 3.424769 lr 0.00025712 rank 6
2022-12-08 04:29:30,756 DEBUG TRAIN Batch 26/3000 loss 5.287090 loss_att 281.159760 loss_ctc 10.541986 loss_rnnt 4.703212 lr 0.00025712 rank 5
2022-12-08 04:29:30,756 DEBUG TRAIN Batch 26/3000 loss 13.412926 loss_att 352.286194 loss_ctc 21.866049 loss_rnnt 12.473690 lr 0.00025711 rank 0
2022-12-08 04:29:30,757 DEBUG TRAIN Batch 26/3000 loss 2.734799 loss_att 343.206085 loss_ctc 5.240806 loss_rnnt 2.456354 lr 0.00025714 rank 1
2022-12-08 04:29:30,759 DEBUG TRAIN Batch 26/3000 loss 12.301480 loss_att 363.160126 loss_ctc 25.903738 loss_rnnt 10.790118 lr 0.00025712 rank 3
2022-12-08 04:30:34,263 DEBUG TRAIN Batch 26/3100 loss 10.814814 loss_att 166.660004 loss_ctc 18.545202 loss_rnnt 9.955882 lr 0.00025708 rank 3
2022-12-08 04:30:34,263 DEBUG TRAIN Batch 26/3100 loss 4.455230 loss_att 320.534882 loss_ctc 9.998977 loss_rnnt 3.839259 lr 0.00025709 rank 6
2022-12-08 04:30:34,265 DEBUG TRAIN Batch 26/3100 loss 10.433605 loss_att 305.194702 loss_ctc 18.895693 loss_rnnt 9.493374 lr 0.00025707 rank 4
2022-12-08 04:30:34,265 DEBUG TRAIN Batch 26/3100 loss 8.324103 loss_att 299.973083 loss_ctc 15.025076 loss_rnnt 7.579551 lr 0.00025707 rank 7
2022-12-08 04:30:34,265 DEBUG TRAIN Batch 26/3100 loss 7.021530 loss_att 347.683624 loss_ctc 13.255637 loss_rnnt 6.328852 lr 0.00025709 rank 2
2022-12-08 04:30:34,270 DEBUG TRAIN Batch 26/3100 loss 5.652015 loss_att 328.177094 loss_ctc 12.537482 loss_rnnt 4.886963 lr 0.00025708 rank 0
2022-12-08 04:30:34,272 DEBUG TRAIN Batch 26/3100 loss 10.296028 loss_att 260.429565 loss_ctc 22.883076 loss_rnnt 8.897467 lr 0.00025708 rank 5
2022-12-08 04:30:34,297 DEBUG TRAIN Batch 26/3100 loss 6.661232 loss_att 306.587006 loss_ctc 14.995300 loss_rnnt 5.735224 lr 0.00025711 rank 1
2022-12-08 04:31:50,433 DEBUG TRAIN Batch 26/3200 loss 7.639171 loss_att 212.308212 loss_ctc 15.783048 loss_rnnt 6.734296 lr 0.00025704 rank 4
2022-12-08 04:31:50,433 DEBUG TRAIN Batch 26/3200 loss 14.007871 loss_att 254.519379 loss_ctc 26.604057 loss_rnnt 12.608294 lr 0.00025703 rank 7
2022-12-08 04:31:50,438 DEBUG TRAIN Batch 26/3200 loss 5.968210 loss_att 365.332458 loss_ctc 13.267460 loss_rnnt 5.157182 lr 0.00025705 rank 3
2022-12-08 04:31:50,440 DEBUG TRAIN Batch 26/3200 loss 8.227512 loss_att 474.981445 loss_ctc 18.660374 loss_rnnt 7.068306 lr 0.00025705 rank 5
2022-12-08 04:31:50,440 DEBUG TRAIN Batch 26/3200 loss 9.629066 loss_att 132.594955 loss_ctc 14.936991 loss_rnnt 9.039296 lr 0.00025705 rank 2
2022-12-08 04:31:50,440 DEBUG TRAIN Batch 26/3200 loss 7.476604 loss_att 136.855103 loss_ctc 13.633328 loss_rnnt 6.792523 lr 0.00025707 rank 1
2022-12-08 04:31:50,441 DEBUG TRAIN Batch 26/3200 loss 5.917542 loss_att 134.685211 loss_ctc 10.441244 loss_rnnt 5.414908 lr 0.00025705 rank 6
2022-12-08 04:31:50,442 DEBUG TRAIN Batch 26/3200 loss 7.337771 loss_att 83.343521 loss_ctc 10.603299 loss_rnnt 6.974935 lr 0.00025704 rank 0
2022-12-08 04:32:54,103 DEBUG TRAIN Batch 26/3300 loss 3.297579 loss_att 362.005371 loss_ctc 9.252584 loss_rnnt 2.635912 lr 0.00025700 rank 7
2022-12-08 04:32:54,107 DEBUG TRAIN Batch 26/3300 loss 8.641365 loss_att 436.303162 loss_ctc 15.154137 loss_rnnt 7.917724 lr 0.00025704 rank 1
2022-12-08 04:32:54,110 DEBUG TRAIN Batch 26/3300 loss 9.811993 loss_att 381.081482 loss_ctc 25.602522 loss_rnnt 8.057489 lr 0.00025700 rank 4
2022-12-08 04:32:54,111 DEBUG TRAIN Batch 26/3300 loss 15.689296 loss_att 369.947235 loss_ctc 23.531866 loss_rnnt 14.817900 lr 0.00025701 rank 0
2022-12-08 04:32:54,113 DEBUG TRAIN Batch 26/3300 loss 1.721442 loss_att 390.031677 loss_ctc 7.966516 loss_rnnt 1.027544 lr 0.00025702 rank 2
2022-12-08 04:32:54,117 DEBUG TRAIN Batch 26/3300 loss 6.545389 loss_att 391.981445 loss_ctc 18.106796 loss_rnnt 5.260789 lr 0.00025702 rank 6
2022-12-08 04:32:54,118 DEBUG TRAIN Batch 26/3300 loss 6.967765 loss_att 381.538147 loss_ctc 13.303195 loss_rnnt 6.263828 lr 0.00025701 rank 3
2022-12-08 04:32:54,155 DEBUG TRAIN Batch 26/3300 loss 6.889442 loss_att 372.668518 loss_ctc 15.250336 loss_rnnt 5.960454 lr 0.00025701 rank 5
2022-12-08 04:33:58,130 DEBUG TRAIN Batch 26/3400 loss 7.575292 loss_att 356.296509 loss_ctc 11.773367 loss_rnnt 7.108839 lr 0.00025698 rank 3
2022-12-08 04:33:58,132 DEBUG TRAIN Batch 26/3400 loss 7.609296 loss_att 372.476562 loss_ctc 13.661802 loss_rnnt 6.936795 lr 0.00025697 rank 7
2022-12-08 04:33:58,134 DEBUG TRAIN Batch 26/3400 loss 3.507402 loss_att 319.578613 loss_ctc 7.248304 loss_rnnt 3.091746 lr 0.00025700 rank 1
2022-12-08 04:33:58,136 DEBUG TRAIN Batch 26/3400 loss 5.950339 loss_att 406.043549 loss_ctc 14.951938 loss_rnnt 4.950161 lr 0.00025697 rank 4
2022-12-08 04:33:58,138 DEBUG TRAIN Batch 26/3400 loss 9.762680 loss_att 339.297485 loss_ctc 15.854076 loss_rnnt 9.085859 lr 0.00025698 rank 0
2022-12-08 04:33:58,141 DEBUG TRAIN Batch 26/3400 loss 8.822609 loss_att 405.482758 loss_ctc 22.678366 loss_rnnt 7.283081 lr 0.00025698 rank 6
2022-12-08 04:33:58,141 DEBUG TRAIN Batch 26/3400 loss 4.731074 loss_att 334.333160 loss_ctc 13.957438 loss_rnnt 3.705923 lr 0.00025698 rank 5
2022-12-08 04:33:58,151 DEBUG TRAIN Batch 26/3400 loss 8.068087 loss_att 348.811279 loss_ctc 25.225353 loss_rnnt 6.161723 lr 0.00025699 rank 2
2022-12-08 04:35:02,672 DEBUG TRAIN Batch 26/3500 loss 9.183743 loss_att 369.770508 loss_ctc 24.841116 loss_rnnt 7.444035 lr 0.00025693 rank 7
2022-12-08 04:35:02,673 DEBUG TRAIN Batch 26/3500 loss 6.035775 loss_att 351.235657 loss_ctc 17.008305 loss_rnnt 4.816605 lr 0.00025694 rank 4
2022-12-08 04:35:02,675 DEBUG TRAIN Batch 26/3500 loss 5.133044 loss_att 355.805908 loss_ctc 16.016315 loss_rnnt 3.923791 lr 0.00025695 rank 2
2022-12-08 04:35:02,676 DEBUG TRAIN Batch 26/3500 loss 7.126122 loss_att 384.120178 loss_ctc 12.860071 loss_rnnt 6.489017 lr 0.00025695 rank 6
2022-12-08 04:35:02,678 DEBUG TRAIN Batch 26/3500 loss 4.958861 loss_att 327.570496 loss_ctc 15.533937 loss_rnnt 3.783853 lr 0.00025695 rank 5
2022-12-08 04:35:02,680 DEBUG TRAIN Batch 26/3500 loss 5.737055 loss_att 366.010071 loss_ctc 11.990002 loss_rnnt 5.042284 lr 0.00025697 rank 1
2022-12-08 04:35:02,681 DEBUG TRAIN Batch 26/3500 loss 5.838586 loss_att 381.513794 loss_ctc 10.476671 loss_rnnt 5.323243 lr 0.00025694 rank 0
2022-12-08 04:35:02,683 DEBUG TRAIN Batch 26/3500 loss 4.137770 loss_att 343.359070 loss_ctc 8.595531 loss_rnnt 3.642463 lr 0.00025695 rank 3
2022-12-08 04:36:25,690 DEBUG TRAIN Batch 26/3600 loss 5.614612 loss_att 387.727600 loss_ctc 13.387925 loss_rnnt 4.750910 lr 0.00025691 rank 3
2022-12-08 04:36:25,701 DEBUG TRAIN Batch 26/3600 loss 3.382757 loss_att 357.783722 loss_ctc 6.518237 loss_rnnt 3.034370 lr 0.00025690 rank 4
2022-12-08 04:36:25,701 DEBUG TRAIN Batch 26/3600 loss 6.082550 loss_att 343.555420 loss_ctc 14.798756 loss_rnnt 5.114082 lr 0.00025691 rank 5
2022-12-08 04:36:25,701 DEBUG TRAIN Batch 26/3600 loss 15.382820 loss_att 412.508667 loss_ctc 28.846807 loss_rnnt 13.886822 lr 0.00025690 rank 7
2022-12-08 04:36:25,703 DEBUG TRAIN Batch 26/3600 loss 14.857528 loss_att 395.851776 loss_ctc 22.911041 loss_rnnt 13.962693 lr 0.00025692 rank 6
2022-12-08 04:36:25,704 DEBUG TRAIN Batch 26/3600 loss 6.610708 loss_att 357.607391 loss_ctc 19.654476 loss_rnnt 5.161401 lr 0.00025691 rank 0
2022-12-08 04:36:25,712 DEBUG TRAIN Batch 26/3600 loss 14.851183 loss_att 380.897278 loss_ctc 23.615114 loss_rnnt 13.877414 lr 0.00025694 rank 1
2022-12-08 04:36:25,744 DEBUG TRAIN Batch 26/3600 loss 2.392723 loss_att 404.358643 loss_ctc 5.767044 loss_rnnt 2.017799 lr 0.00025692 rank 2
2022-12-08 04:37:29,419 DEBUG TRAIN Batch 26/3700 loss 9.535660 loss_att 342.269257 loss_ctc 18.011007 loss_rnnt 8.593954 lr 0.00025687 rank 4
2022-12-08 04:37:29,419 DEBUG TRAIN Batch 26/3700 loss 11.531563 loss_att 170.244583 loss_ctc 17.058315 loss_rnnt 10.917480 lr 0.00025688 rank 3
2022-12-08 04:37:29,419 DEBUG TRAIN Batch 26/3700 loss 6.549678 loss_att 297.024902 loss_ctc 11.888554 loss_rnnt 5.956470 lr 0.00025690 rank 1
2022-12-08 04:37:29,421 DEBUG TRAIN Batch 26/3700 loss 5.728645 loss_att 354.752197 loss_ctc 13.687879 loss_rnnt 4.844286 lr 0.00025688 rank 2
2022-12-08 04:37:29,423 DEBUG TRAIN Batch 26/3700 loss 10.326106 loss_att 316.476868 loss_ctc 14.036758 loss_rnnt 9.913812 lr 0.00025688 rank 0
2022-12-08 04:37:29,425 DEBUG TRAIN Batch 26/3700 loss 14.442451 loss_att 370.295685 loss_ctc 27.502140 loss_rnnt 12.991375 lr 0.00025688 rank 6
2022-12-08 04:37:29,426 DEBUG TRAIN Batch 26/3700 loss 4.628658 loss_att 270.877686 loss_ctc 12.106956 loss_rnnt 3.797736 lr 0.00025688 rank 5
2022-12-08 04:37:29,426 DEBUG TRAIN Batch 26/3700 loss 4.915999 loss_att 305.524170 loss_ctc 11.940763 loss_rnnt 4.135470 lr 0.00025686 rank 7
2022-12-08 04:38:32,845 DEBUG TRAIN Batch 26/3800 loss 8.529904 loss_att 297.280487 loss_ctc 15.060397 loss_rnnt 7.804294 lr 0.00025683 rank 4
2022-12-08 04:38:32,846 DEBUG TRAIN Batch 26/3800 loss 10.506997 loss_att 243.035339 loss_ctc 17.698019 loss_rnnt 9.707994 lr 0.00025683 rank 7
2022-12-08 04:38:32,849 DEBUG TRAIN Batch 26/3800 loss 11.812203 loss_att 223.138611 loss_ctc 17.207951 loss_rnnt 11.212677 lr 0.00025685 rank 6
2022-12-08 04:38:32,849 DEBUG TRAIN Batch 26/3800 loss 10.050581 loss_att 256.807098 loss_ctc 13.942370 loss_rnnt 9.618159 lr 0.00025685 rank 2
2022-12-08 04:38:32,854 DEBUG TRAIN Batch 26/3800 loss 6.700485 loss_att 242.200974 loss_ctc 14.010263 loss_rnnt 5.888288 lr 0.00025684 rank 0
2022-12-08 04:38:32,855 DEBUG TRAIN Batch 26/3800 loss 4.349257 loss_att 418.037598 loss_ctc 13.815799 loss_rnnt 3.297419 lr 0.00025684 rank 3
2022-12-08 04:38:32,856 DEBUG TRAIN Batch 26/3800 loss 10.261883 loss_att 310.603516 loss_ctc 19.423779 loss_rnnt 9.243895 lr 0.00025687 rank 1
2022-12-08 04:38:32,861 DEBUG TRAIN Batch 26/3800 loss 5.026445 loss_att 455.074707 loss_ctc 10.628586 loss_rnnt 4.403985 lr 0.00025684 rank 5
2022-12-08 04:39:46,888 DEBUG TRAIN Batch 26/3900 loss 17.779819 loss_att 459.535583 loss_ctc 28.576359 loss_rnnt 16.580204 lr 0.00025680 rank 4
2022-12-08 04:39:46,894 DEBUG TRAIN Batch 26/3900 loss 15.992262 loss_att 489.441498 loss_ctc 26.223717 loss_rnnt 14.855433 lr 0.00025681 rank 6
2022-12-08 04:39:46,895 DEBUG TRAIN Batch 26/3900 loss 2.621358 loss_att 427.039246 loss_ctc 8.943148 loss_rnnt 1.918937 lr 0.00025683 rank 1
2022-12-08 04:39:46,899 DEBUG TRAIN Batch 26/3900 loss 8.458016 loss_att 436.467651 loss_ctc 12.693649 loss_rnnt 7.987390 lr 0.00025680 rank 7
2022-12-08 04:39:46,907 DEBUG TRAIN Batch 26/3900 loss 10.310589 loss_att 384.670105 loss_ctc 28.809647 loss_rnnt 8.255138 lr 0.00025681 rank 0
2022-12-08 04:39:46,909 DEBUG TRAIN Batch 26/3900 loss 8.100962 loss_att 399.470886 loss_ctc 20.794121 loss_rnnt 6.690611 lr 0.00025681 rank 3
2022-12-08 04:39:46,919 DEBUG TRAIN Batch 26/3900 loss 3.080756 loss_att 356.856812 loss_ctc 9.108759 loss_rnnt 2.410978 lr 0.00025681 rank 5
2022-12-08 04:39:46,930 DEBUG TRAIN Batch 26/3900 loss 5.443257 loss_att 345.686035 loss_ctc 14.047325 loss_rnnt 4.487250 lr 0.00025682 rank 2
2022-12-08 04:40:50,488 DEBUG TRAIN Batch 26/4000 loss 7.328901 loss_att 331.424103 loss_ctc 18.409397 loss_rnnt 6.097735 lr 0.00025676 rank 7
2022-12-08 04:40:50,495 DEBUG TRAIN Batch 26/4000 loss 6.582838 loss_att 411.646088 loss_ctc 15.634444 loss_rnnt 5.577104 lr 0.00025677 rank 4
2022-12-08 04:40:50,496 DEBUG TRAIN Batch 26/4000 loss 7.583781 loss_att 383.495209 loss_ctc 22.512274 loss_rnnt 5.925059 lr 0.00025677 rank 0
2022-12-08 04:40:50,498 DEBUG TRAIN Batch 26/4000 loss 11.855035 loss_att 437.820068 loss_ctc 26.488239 loss_rnnt 10.229124 lr 0.00025678 rank 2
2022-12-08 04:40:50,500 DEBUG TRAIN Batch 26/4000 loss 10.481230 loss_att 435.524933 loss_ctc 21.765036 loss_rnnt 9.227473 lr 0.00025678 rank 3
2022-12-08 04:40:50,501 DEBUG TRAIN Batch 26/4000 loss 9.797631 loss_att 406.032074 loss_ctc 14.064774 loss_rnnt 9.323505 lr 0.00025678 rank 6
2022-12-08 04:40:50,501 DEBUG TRAIN Batch 26/4000 loss 10.279735 loss_att 366.197113 loss_ctc 18.930513 loss_rnnt 9.318538 lr 0.00025680 rank 1
2022-12-08 04:40:50,505 DEBUG TRAIN Batch 26/4000 loss 16.748589 loss_att 375.920166 loss_ctc 27.969955 loss_rnnt 15.501770 lr 0.00025678 rank 5
2022-12-08 04:41:53,669 DEBUG TRAIN Batch 26/4100 loss 9.520231 loss_att 417.689545 loss_ctc 17.593864 loss_rnnt 8.623161 lr 0.00025673 rank 4
2022-12-08 04:41:53,674 DEBUG TRAIN Batch 26/4100 loss 11.068178 loss_att 379.454102 loss_ctc 20.273327 loss_rnnt 10.045384 lr 0.00025675 rank 6
2022-12-08 04:41:53,675 DEBUG TRAIN Batch 26/4100 loss 3.268646 loss_att 368.768036 loss_ctc 6.566432 loss_rnnt 2.902225 lr 0.00025674 rank 5
2022-12-08 04:41:53,676 DEBUG TRAIN Batch 26/4100 loss 7.436399 loss_att 387.484131 loss_ctc 16.022038 loss_rnnt 6.482439 lr 0.00025677 rank 1
2022-12-08 04:41:53,680 DEBUG TRAIN Batch 26/4100 loss 7.670476 loss_att 407.440765 loss_ctc 19.558632 loss_rnnt 6.349570 lr 0.00025675 rank 2
2022-12-08 04:41:53,683 DEBUG TRAIN Batch 26/4100 loss 8.733909 loss_att 390.887756 loss_ctc 23.044973 loss_rnnt 7.143790 lr 0.00025674 rank 0
2022-12-08 04:41:53,688 DEBUG TRAIN Batch 26/4100 loss 3.099425 loss_att 339.823059 loss_ctc 7.945676 loss_rnnt 2.560953 lr 0.00025673 rank 7
2022-12-08 04:41:53,721 DEBUG TRAIN Batch 26/4100 loss 4.500754 loss_att 311.732056 loss_ctc 8.667252 loss_rnnt 4.037810 lr 0.00025674 rank 3
2022-12-08 04:42:58,257 DEBUG TRAIN Batch 26/4200 loss 25.266619 loss_att 379.980347 loss_ctc 56.519226 loss_rnnt 21.794107 lr 0.00025671 rank 6
2022-12-08 04:42:58,271 DEBUG TRAIN Batch 26/4200 loss 2.803158 loss_att 355.411621 loss_ctc 4.557701 loss_rnnt 2.608209 lr 0.00025670 rank 4
2022-12-08 04:42:58,274 DEBUG TRAIN Batch 26/4200 loss 5.686286 loss_att 337.600098 loss_ctc 12.539623 loss_rnnt 4.924804 lr 0.00025672 rank 2
2022-12-08 04:42:58,276 DEBUG TRAIN Batch 26/4200 loss 10.976181 loss_att 399.640198 loss_ctc 16.726776 loss_rnnt 10.337226 lr 0.00025673 rank 1
2022-12-08 04:42:58,277 DEBUG TRAIN Batch 26/4200 loss 9.992714 loss_att 301.351715 loss_ctc 23.902878 loss_rnnt 8.447141 lr 0.00025671 rank 3
2022-12-08 04:42:58,278 DEBUG TRAIN Batch 26/4200 loss 4.148370 loss_att 366.285187 loss_ctc 7.895509 loss_rnnt 3.732021 lr 0.00025671 rank 5
2022-12-08 04:42:58,286 DEBUG TRAIN Batch 26/4200 loss 10.473093 loss_att 342.260651 loss_ctc 22.177464 loss_rnnt 9.172607 lr 0.00025669 rank 7
2022-12-08 04:42:58,292 DEBUG TRAIN Batch 26/4200 loss 7.752567 loss_att 351.101654 loss_ctc 15.076933 loss_rnnt 6.938749 lr 0.00025671 rank 0
2022-12-08 04:44:21,767 DEBUG TRAIN Batch 26/4300 loss 8.735994 loss_att 349.712952 loss_ctc 22.125637 loss_rnnt 7.248257 lr 0.00025666 rank 7
2022-12-08 04:44:21,769 DEBUG TRAIN Batch 26/4300 loss 15.917417 loss_att 308.553528 loss_ctc 27.372169 loss_rnnt 14.644667 lr 0.00025666 rank 4
2022-12-08 04:44:21,771 DEBUG TRAIN Batch 26/4300 loss 6.867527 loss_att 302.807922 loss_ctc 12.781981 loss_rnnt 6.210366 lr 0.00025668 rank 2
2022-12-08 04:44:21,772 DEBUG TRAIN Batch 26/4300 loss 10.549328 loss_att 182.875259 loss_ctc 20.284882 loss_rnnt 9.467600 lr 0.00025668 rank 3
2022-12-08 04:44:21,774 DEBUG TRAIN Batch 26/4300 loss 13.102244 loss_att 359.868225 loss_ctc 28.890825 loss_rnnt 11.347958 lr 0.00025667 rank 0
2022-12-08 04:44:21,777 DEBUG TRAIN Batch 26/4300 loss 6.873410 loss_att 355.239014 loss_ctc 14.655352 loss_rnnt 6.008750 lr 0.00025670 rank 1
2022-12-08 04:44:21,778 DEBUG TRAIN Batch 26/4300 loss 3.767770 loss_att 311.824554 loss_ctc 8.633883 loss_rnnt 3.227091 lr 0.00025667 rank 5
2022-12-08 04:44:21,780 DEBUG TRAIN Batch 26/4300 loss 6.439858 loss_att 308.517609 loss_ctc 14.286875 loss_rnnt 5.567968 lr 0.00025668 rank 6
2022-12-08 04:45:25,105 DEBUG TRAIN Batch 26/4400 loss 13.982620 loss_att 317.896973 loss_ctc 23.393726 loss_rnnt 12.936942 lr 0.00025663 rank 7
2022-12-08 04:45:25,108 DEBUG TRAIN Batch 26/4400 loss 3.507336 loss_att 232.540039 loss_ctc 7.517037 loss_rnnt 3.061814 lr 0.00025664 rank 0
2022-12-08 04:45:25,108 DEBUG TRAIN Batch 26/4400 loss 9.444597 loss_att 110.156708 loss_ctc 13.608635 loss_rnnt 8.981927 lr 0.00025664 rank 5
2022-12-08 04:45:25,108 DEBUG TRAIN Batch 26/4400 loss 7.217780 loss_att 278.720642 loss_ctc 16.308432 loss_rnnt 6.207708 lr 0.00025664 rank 6
2022-12-08 04:45:25,108 DEBUG TRAIN Batch 26/4400 loss 7.535732 loss_att 331.783447 loss_ctc 12.688856 loss_rnnt 6.963163 lr 0.00025667 rank 1
2022-12-08 04:45:25,110 DEBUG TRAIN Batch 26/4400 loss 6.814066 loss_att 304.294525 loss_ctc 14.778556 loss_rnnt 5.929122 lr 0.00025663 rank 4
2022-12-08 04:45:25,118 DEBUG TRAIN Batch 26/4400 loss 6.674110 loss_att 396.956360 loss_ctc 12.746651 loss_rnnt 5.999384 lr 0.00025665 rank 2
2022-12-08 04:45:25,119 DEBUG TRAIN Batch 26/4400 loss 8.132756 loss_att 367.964661 loss_ctc 27.430073 loss_rnnt 5.988610 lr 0.00025664 rank 3
2022-12-08 04:46:28,971 DEBUG TRAIN Batch 26/4500 loss 6.249262 loss_att 115.648102 loss_ctc 10.220135 loss_rnnt 5.808053 lr 0.00025659 rank 7
2022-12-08 04:46:28,973 DEBUG TRAIN Batch 26/4500 loss 7.868540 loss_att 114.575096 loss_ctc 11.791552 loss_rnnt 7.432650 lr 0.00025660 rank 4
2022-12-08 04:46:28,975 DEBUG TRAIN Batch 26/4500 loss 1.354661 loss_att 388.890991 loss_ctc 4.668939 loss_rnnt 0.986408 lr 0.00025661 rank 3
2022-12-08 04:46:28,975 DEBUG TRAIN Batch 26/4500 loss 4.122671 loss_att 406.523010 loss_ctc 10.050083 loss_rnnt 3.464070 lr 0.00025661 rank 6
2022-12-08 04:46:28,979 DEBUG TRAIN Batch 26/4500 loss 6.049875 loss_att 356.459320 loss_ctc 14.175983 loss_rnnt 5.146975 lr 0.00025660 rank 0
2022-12-08 04:46:28,980 DEBUG TRAIN Batch 26/4500 loss 9.033638 loss_att 200.166367 loss_ctc 15.769594 loss_rnnt 8.285198 lr 0.00025663 rank 1
2022-12-08 04:46:28,982 DEBUG TRAIN Batch 26/4500 loss 11.538383 loss_att 360.290863 loss_ctc 20.359097 loss_rnnt 10.558304 lr 0.00025661 rank 5
2022-12-08 04:46:29,022 DEBUG TRAIN Batch 26/4500 loss 7.843241 loss_att 284.837250 loss_ctc 12.360277 loss_rnnt 7.341348 lr 0.00025661 rank 2
2022-12-08 04:47:34,308 DEBUG TRAIN Batch 26/4600 loss 3.201077 loss_att 365.163422 loss_ctc 10.183844 loss_rnnt 2.425215 lr 0.00025656 rank 4
2022-12-08 04:47:34,312 DEBUG TRAIN Batch 26/4600 loss 7.097507 loss_att 400.057129 loss_ctc 13.369430 loss_rnnt 6.400627 lr 0.00025660 rank 1
2022-12-08 04:47:34,312 DEBUG TRAIN Batch 26/4600 loss 6.897292 loss_att 375.596436 loss_ctc 13.580032 loss_rnnt 6.154766 lr 0.00025657 rank 5
2022-12-08 04:47:34,313 DEBUG TRAIN Batch 26/4600 loss 1.215877 loss_att 414.248535 loss_ctc 3.770294 loss_rnnt 0.932053 lr 0.00025657 rank 0
2022-12-08 04:47:34,315 DEBUG TRAIN Batch 26/4600 loss 10.631364 loss_att 336.643799 loss_ctc 25.902878 loss_rnnt 8.934528 lr 0.00025658 rank 6
2022-12-08 04:47:34,315 DEBUG TRAIN Batch 26/4600 loss 4.582284 loss_att 389.335052 loss_ctc 9.790535 loss_rnnt 4.003590 lr 0.00025656 rank 7
2022-12-08 04:47:34,318 DEBUG TRAIN Batch 26/4600 loss 5.321320 loss_att 387.332916 loss_ctc 11.418572 loss_rnnt 4.643847 lr 0.00025657 rank 3
2022-12-08 04:47:34,347 DEBUG TRAIN Batch 26/4600 loss 4.834964 loss_att 430.396912 loss_ctc 9.890662 loss_rnnt 4.273220 lr 0.00025658 rank 2
2022-12-08 04:48:57,161 DEBUG TRAIN Batch 26/4700 loss 4.043253 loss_att 376.265625 loss_ctc 11.377768 loss_rnnt 3.228307 lr 0.00025653 rank 4
2022-12-08 04:48:57,162 DEBUG TRAIN Batch 26/4700 loss 3.690216 loss_att 342.086273 loss_ctc 9.266191 loss_rnnt 3.070663 lr 0.00025654 rank 6
2022-12-08 04:48:57,164 DEBUG TRAIN Batch 26/4700 loss 5.266934 loss_att 308.538818 loss_ctc 10.924894 loss_rnnt 4.638272 lr 0.00025654 rank 0
2022-12-08 04:48:57,166 DEBUG TRAIN Batch 26/4700 loss 7.029451 loss_att 402.370483 loss_ctc 14.570572 loss_rnnt 6.191549 lr 0.00025653 rank 7
2022-12-08 04:48:57,170 DEBUG TRAIN Batch 26/4700 loss 12.582607 loss_att 362.123352 loss_ctc 21.326298 loss_rnnt 11.611086 lr 0.00025654 rank 3
2022-12-08 04:48:57,170 DEBUG TRAIN Batch 26/4700 loss 3.813403 loss_att 426.864594 loss_ctc 13.343574 loss_rnnt 2.754495 lr 0.00025656 rank 1
2022-12-08 04:48:57,171 DEBUG TRAIN Batch 26/4700 loss 15.120487 loss_att 385.269501 loss_ctc 28.289165 loss_rnnt 13.657301 lr 0.00025655 rank 2
2022-12-08 04:48:57,172 DEBUG TRAIN Batch 26/4700 loss 3.699358 loss_att 429.376099 loss_ctc 8.889410 loss_rnnt 3.122685 lr 0.00025654 rank 5
2022-12-08 04:50:00,353 DEBUG TRAIN Batch 26/4800 loss 6.154165 loss_att 408.593445 loss_ctc 15.871017 loss_rnnt 5.074514 lr 0.00025649 rank 7
2022-12-08 04:50:00,360 DEBUG TRAIN Batch 26/4800 loss 6.786273 loss_att 405.379639 loss_ctc 17.710133 loss_rnnt 5.572511 lr 0.00025653 rank 1
2022-12-08 04:50:00,360 DEBUG TRAIN Batch 26/4800 loss 10.719256 loss_att 321.337280 loss_ctc 17.529160 loss_rnnt 9.962601 lr 0.00025650 rank 4
2022-12-08 04:50:00,362 DEBUG TRAIN Batch 26/4800 loss 7.470517 loss_att 376.584351 loss_ctc 14.922106 loss_rnnt 6.642563 lr 0.00025650 rank 0
2022-12-08 04:50:00,363 DEBUG TRAIN Batch 26/4800 loss 6.889144 loss_att 373.331635 loss_ctc 12.209909 loss_rnnt 6.297948 lr 0.00025651 rank 6
2022-12-08 04:50:00,363 DEBUG TRAIN Batch 26/4800 loss 8.937508 loss_att 369.545532 loss_ctc 16.647348 loss_rnnt 8.080858 lr 0.00025651 rank 5
2022-12-08 04:50:00,363 DEBUG TRAIN Batch 26/4800 loss 7.026284 loss_att 317.888550 loss_ctc 16.296650 loss_rnnt 5.996243 lr 0.00025651 rank 3
2022-12-08 04:50:00,363 DEBUG TRAIN Batch 26/4800 loss 7.675415 loss_att 413.036865 loss_ctc 16.109722 loss_rnnt 6.738270 lr 0.00025651 rank 2
2022-12-08 04:51:04,530 DEBUG TRAIN Batch 26/4900 loss 5.366680 loss_att 333.740662 loss_ctc 11.538071 loss_rnnt 4.680970 lr 0.00025646 rank 7
2022-12-08 04:51:04,532 DEBUG TRAIN Batch 26/4900 loss 9.386150 loss_att 203.464966 loss_ctc 20.371761 loss_rnnt 8.165527 lr 0.00025647 rank 3
2022-12-08 04:51:04,534 DEBUG TRAIN Batch 26/4900 loss 7.327333 loss_att 313.853058 loss_ctc 10.956515 loss_rnnt 6.924090 lr 0.00025646 rank 4
2022-12-08 04:51:04,534 DEBUG TRAIN Batch 26/4900 loss 6.847135 loss_att 361.888184 loss_ctc 14.316732 loss_rnnt 6.017179 lr 0.00025650 rank 1
2022-12-08 04:51:04,534 DEBUG TRAIN Batch 26/4900 loss 5.665053 loss_att 333.850098 loss_ctc 11.351084 loss_rnnt 5.033272 lr 0.00025648 rank 6
2022-12-08 04:51:04,538 DEBUG TRAIN Batch 26/4900 loss 6.146366 loss_att 305.164551 loss_ctc 11.594437 loss_rnnt 5.541025 lr 0.00025647 rank 0
2022-12-08 04:51:04,538 DEBUG TRAIN Batch 26/4900 loss 2.995329 loss_att 325.014221 loss_ctc 8.641130 loss_rnnt 2.368018 lr 0.00025647 rank 5
2022-12-08 04:51:04,575 DEBUG TRAIN Batch 26/4900 loss 4.156639 loss_att 327.955109 loss_ctc 9.276033 loss_rnnt 3.587817 lr 0.00025648 rank 2
2022-12-08 04:52:19,431 DEBUG TRAIN Batch 26/5000 loss 4.230470 loss_att 255.561508 loss_ctc 8.653148 loss_rnnt 3.739062 lr 0.00025642 rank 7
2022-12-08 04:52:19,433 DEBUG TRAIN Batch 26/5000 loss 5.946682 loss_att 223.985443 loss_ctc 8.490335 loss_rnnt 5.664054 lr 0.00025644 rank 0
2022-12-08 04:52:19,436 DEBUG TRAIN Batch 26/5000 loss 4.292691 loss_att 353.119263 loss_ctc 12.828592 loss_rnnt 3.344257 lr 0.00025646 rank 1
2022-12-08 04:52:19,437 DEBUG TRAIN Batch 26/5000 loss 11.396613 loss_att 330.817566 loss_ctc 21.204901 loss_rnnt 10.306804 lr 0.00025644 rank 6
2022-12-08 04:52:19,440 DEBUG TRAIN Batch 26/5000 loss 8.794525 loss_att 302.686615 loss_ctc 21.918190 loss_rnnt 7.336341 lr 0.00025643 rank 4
2022-12-08 04:52:19,440 DEBUG TRAIN Batch 26/5000 loss 6.663009 loss_att 225.338135 loss_ctc 12.815157 loss_rnnt 5.979437 lr 0.00025644 rank 5
2022-12-08 04:52:19,441 DEBUG TRAIN Batch 26/5000 loss 2.254885 loss_att 296.684631 loss_ctc 5.481045 loss_rnnt 1.896423 lr 0.00025645 rank 2
2022-12-08 04:52:19,441 DEBUG TRAIN Batch 26/5000 loss 12.475568 loss_att 441.949188 loss_ctc 27.185240 loss_rnnt 10.841160 lr 0.00025644 rank 3
2022-12-08 04:53:22,848 DEBUG TRAIN Batch 26/5100 loss 7.860539 loss_att 181.875946 loss_ctc 11.765857 loss_rnnt 7.426615 lr 0.00025639 rank 7
2022-12-08 04:53:22,852 DEBUG TRAIN Batch 26/5100 loss 5.096392 loss_att 320.331177 loss_ctc 13.150406 loss_rnnt 4.201502 lr 0.00025639 rank 4
2022-12-08 04:53:22,855 DEBUG TRAIN Batch 26/5100 loss 14.304340 loss_att 289.832397 loss_ctc 24.553274 loss_rnnt 13.165570 lr 0.00025641 rank 2
2022-12-08 04:53:22,856 DEBUG TRAIN Batch 26/5100 loss 9.045053 loss_att 266.004150 loss_ctc 17.778708 loss_rnnt 8.074646 lr 0.00025643 rank 1
2022-12-08 04:53:22,856 DEBUG TRAIN Batch 26/5100 loss 7.503924 loss_att 365.224121 loss_ctc 11.970271 loss_rnnt 7.007664 lr 0.00025640 rank 5
2022-12-08 04:53:22,857 DEBUG TRAIN Batch 26/5100 loss 9.049162 loss_att 412.587769 loss_ctc 19.639084 loss_rnnt 7.872504 lr 0.00025641 rank 6
2022-12-08 04:53:22,861 DEBUG TRAIN Batch 26/5100 loss 4.492107 loss_att 365.244690 loss_ctc 4.171545 loss_rnnt 4.527725 lr 0.00025640 rank 0
2022-12-08 04:53:22,895 DEBUG TRAIN Batch 26/5100 loss 11.189261 loss_att 396.261230 loss_ctc 15.352570 loss_rnnt 10.726671 lr 0.00025641 rank 3
2022-12-08 04:54:26,434 DEBUG TRAIN Batch 26/5200 loss 2.989658 loss_att 359.590881 loss_ctc 8.062694 loss_rnnt 2.425987 lr 0.00025636 rank 7
2022-12-08 04:54:26,437 DEBUG TRAIN Batch 26/5200 loss 2.521956 loss_att 401.919434 loss_ctc 5.294492 loss_rnnt 2.213897 lr 0.00025640 rank 1
2022-12-08 04:54:26,438 DEBUG TRAIN Batch 26/5200 loss 0.915856 loss_att 299.096313 loss_ctc 5.010072 loss_rnnt 0.460943 lr 0.00025637 rank 3
2022-12-08 04:54:26,438 DEBUG TRAIN Batch 26/5200 loss 7.768129 loss_att 440.578857 loss_ctc 9.273891 loss_rnnt 7.600822 lr 0.00025638 rank 2
2022-12-08 04:54:26,439 DEBUG TRAIN Batch 26/5200 loss 12.121405 loss_att 371.809662 loss_ctc 29.596210 loss_rnnt 10.179759 lr 0.00025636 rank 4
2022-12-08 04:54:26,441 DEBUG TRAIN Batch 26/5200 loss 15.749641 loss_att 452.567078 loss_ctc 33.306774 loss_rnnt 13.798850 lr 0.00025637 rank 5
2022-12-08 04:54:26,442 DEBUG TRAIN Batch 26/5200 loss 6.339271 loss_att 339.971191 loss_ctc 15.562030 loss_rnnt 5.314520 lr 0.00025637 rank 0
2022-12-08 04:54:26,482 DEBUG TRAIN Batch 26/5200 loss 5.743879 loss_att 318.283630 loss_ctc 6.596546 loss_rnnt 5.649138 lr 0.00025637 rank 6
2022-12-08 04:55:31,826 DEBUG TRAIN Batch 26/5300 loss 4.098831 loss_att 401.491547 loss_ctc 14.270117 loss_rnnt 2.968688 lr 0.00025634 rank 3
2022-12-08 04:55:31,832 DEBUG TRAIN Batch 26/5300 loss 6.338627 loss_att 427.661865 loss_ctc 11.482573 loss_rnnt 5.767078 lr 0.00025632 rank 7
2022-12-08 04:55:31,833 DEBUG TRAIN Batch 26/5300 loss 6.373609 loss_att 377.923187 loss_ctc 11.389570 loss_rnnt 5.816280 lr 0.00025633 rank 0
2022-12-08 04:55:31,835 DEBUG TRAIN Batch 26/5300 loss 2.548329 loss_att 276.047211 loss_ctc 3.309051 loss_rnnt 2.463804 lr 0.00025633 rank 4
2022-12-08 04:55:31,841 DEBUG TRAIN Batch 26/5300 loss 4.800714 loss_att 333.457092 loss_ctc 11.163094 loss_rnnt 4.093784 lr 0.00025634 rank 6
2022-12-08 04:55:31,842 DEBUG TRAIN Batch 26/5300 loss 4.071882 loss_att 349.448181 loss_ctc 9.991217 loss_rnnt 3.414178 lr 0.00025634 rank 2
2022-12-08 04:55:31,843 DEBUG TRAIN Batch 26/5300 loss 16.453892 loss_att 353.507812 loss_ctc 35.376301 loss_rnnt 14.351402 lr 0.00025634 rank 5
2022-12-08 04:55:31,857 DEBUG TRAIN Batch 26/5300 loss 9.936885 loss_att 404.719666 loss_ctc 16.593714 loss_rnnt 9.197237 lr 0.00025636 rank 1
2022-12-08 04:56:44,368 DEBUG TRAIN Batch 26/5400 loss 4.522358 loss_att 318.702240 loss_ctc 10.993116 loss_rnnt 3.803385 lr 0.00025631 rank 2
2022-12-08 04:56:44,370 DEBUG TRAIN Batch 26/5400 loss 3.289297 loss_att 396.372559 loss_ctc 8.091702 loss_rnnt 2.755697 lr 0.00025629 rank 4
2022-12-08 04:56:44,371 DEBUG TRAIN Batch 26/5400 loss 4.509314 loss_att 287.398438 loss_ctc 7.193146 loss_rnnt 4.211110 lr 0.00025633 rank 1
2022-12-08 04:56:44,371 DEBUG TRAIN Batch 26/5400 loss 9.255940 loss_att 389.178009 loss_ctc 18.563286 loss_rnnt 8.221791 lr 0.00025630 rank 5
2022-12-08 04:56:44,375 DEBUG TRAIN Batch 26/5400 loss 19.459707 loss_att 435.881775 loss_ctc 34.278141 loss_rnnt 17.813215 lr 0.00025630 rank 3
2022-12-08 04:56:44,375 DEBUG TRAIN Batch 26/5400 loss 7.316363 loss_att 436.156464 loss_ctc 25.305159 loss_rnnt 5.317609 lr 0.00025630 rank 0
2022-12-08 04:56:44,375 DEBUG TRAIN Batch 26/5400 loss 7.074746 loss_att 425.063416 loss_ctc 17.414009 loss_rnnt 5.925940 lr 0.00025629 rank 7
2022-12-08 04:56:44,415 DEBUG TRAIN Batch 26/5400 loss 6.971076 loss_att 322.287476 loss_ctc 11.939522 loss_rnnt 6.419026 lr 0.00025631 rank 6
2022-12-08 04:57:47,832 DEBUG TRAIN Batch 26/5500 loss 4.049181 loss_att 378.492615 loss_ctc 11.310247 loss_rnnt 3.242395 lr 0.00025626 rank 4
2022-12-08 04:57:47,834 DEBUG TRAIN Batch 26/5500 loss 5.572723 loss_att 452.791504 loss_ctc 16.027473 loss_rnnt 4.411084 lr 0.00025627 rank 5
2022-12-08 04:57:47,834 DEBUG TRAIN Batch 26/5500 loss 3.845080 loss_att 371.872742 loss_ctc 12.858177 loss_rnnt 2.843625 lr 0.00025626 rank 7
2022-12-08 04:57:47,836 DEBUG TRAIN Batch 26/5500 loss 5.711259 loss_att 316.427429 loss_ctc 16.197193 loss_rnnt 4.546155 lr 0.00025627 rank 6
2022-12-08 04:57:47,836 DEBUG TRAIN Batch 26/5500 loss 8.667540 loss_att 388.341187 loss_ctc 17.151953 loss_rnnt 7.724827 lr 0.00025628 rank 2
2022-12-08 04:57:47,836 DEBUG TRAIN Batch 26/5500 loss 11.731215 loss_att 358.820435 loss_ctc 18.782738 loss_rnnt 10.947712 lr 0.00025627 rank 0
2022-12-08 04:57:47,836 DEBUG TRAIN Batch 26/5500 loss 6.370592 loss_att 424.556519 loss_ctc 14.010733 loss_rnnt 5.521688 lr 0.00025629 rank 1
2022-12-08 04:57:47,843 DEBUG TRAIN Batch 26/5500 loss 5.808650 loss_att 362.408813 loss_ctc 12.008177 loss_rnnt 5.119814 lr 0.00025627 rank 3
2022-12-08 04:58:51,789 DEBUG TRAIN Batch 26/5600 loss 7.876907 loss_att 128.441605 loss_ctc 13.465849 loss_rnnt 7.255914 lr 0.00025624 rank 3
2022-12-08 04:58:51,798 DEBUG TRAIN Batch 26/5600 loss 6.737066 loss_att 324.362244 loss_ctc 11.879817 loss_rnnt 6.165650 lr 0.00025622 rank 7
2022-12-08 04:58:51,798 DEBUG TRAIN Batch 26/5600 loss 14.808722 loss_att 316.360107 loss_ctc 28.777000 loss_rnnt 13.256691 lr 0.00025623 rank 4
2022-12-08 04:58:51,800 DEBUG TRAIN Batch 26/5600 loss 6.374126 loss_att 278.727142 loss_ctc 14.979874 loss_rnnt 5.417932 lr 0.00025624 rank 5
2022-12-08 04:58:51,803 DEBUG TRAIN Batch 26/5600 loss 11.101149 loss_att 356.770569 loss_ctc 24.189495 loss_rnnt 9.646889 lr 0.00025626 rank 1
2022-12-08 04:58:51,804 DEBUG TRAIN Batch 26/5600 loss 7.473608 loss_att 326.689636 loss_ctc 16.319942 loss_rnnt 6.490682 lr 0.00025624 rank 2
2022-12-08 04:58:51,804 DEBUG TRAIN Batch 26/5600 loss 2.821231 loss_att 290.440521 loss_ctc 9.009755 loss_rnnt 2.133617 lr 0.00025623 rank 0
2022-12-08 04:58:51,820 DEBUG TRAIN Batch 26/5600 loss 16.342249 loss_att 345.650330 loss_ctc 25.355690 loss_rnnt 15.340756 lr 0.00025624 rank 6
2022-12-08 05:00:04,026 DEBUG TRAIN Batch 26/5700 loss 6.571765 loss_att 275.031738 loss_ctc 15.640937 loss_rnnt 5.564080 lr 0.00025619 rank 4
2022-12-08 05:00:04,029 DEBUG TRAIN Batch 26/5700 loss 6.626985 loss_att 240.287888 loss_ctc 12.475324 loss_rnnt 5.977169 lr 0.00025619 rank 7
2022-12-08 05:00:04,029 DEBUG TRAIN Batch 26/5700 loss 5.392957 loss_att 293.573761 loss_ctc 9.104494 loss_rnnt 4.980564 lr 0.00025621 rank 2
2022-12-08 05:00:04,029 DEBUG TRAIN Batch 26/5700 loss 5.762785 loss_att 134.729691 loss_ctc 9.102286 loss_rnnt 5.391730 lr 0.00025620 rank 0
2022-12-08 05:00:04,031 DEBUG TRAIN Batch 26/5700 loss 7.135459 loss_att 358.981384 loss_ctc 18.519493 loss_rnnt 5.870566 lr 0.00025620 rank 3
2022-12-08 05:00:04,033 DEBUG TRAIN Batch 26/5700 loss 8.389791 loss_att 326.469452 loss_ctc 18.903004 loss_rnnt 7.221656 lr 0.00025623 rank 1
2022-12-08 05:00:04,041 DEBUG TRAIN Batch 26/5700 loss 7.233628 loss_att 230.308975 loss_ctc 14.624726 loss_rnnt 6.412395 lr 0.00025621 rank 6
2022-12-08 05:00:04,078 DEBUG TRAIN Batch 26/5700 loss 6.484196 loss_att 376.083435 loss_ctc 13.182507 loss_rnnt 5.739940 lr 0.00025620 rank 5
2022-12-08 05:01:08,448 DEBUG TRAIN Batch 26/5800 loss 7.274737 loss_att 381.449585 loss_ctc 14.710150 loss_rnnt 6.448581 lr 0.00025616 rank 4
2022-12-08 05:01:08,449 DEBUG TRAIN Batch 26/5800 loss 3.242108 loss_att 444.771820 loss_ctc 7.279632 loss_rnnt 2.793494 lr 0.00025616 rank 7
2022-12-08 05:01:08,450 DEBUG TRAIN Batch 26/5800 loss 8.187422 loss_att 176.561340 loss_ctc 15.831703 loss_rnnt 7.338058 lr 0.00025618 rank 2
2022-12-08 05:01:08,450 DEBUG TRAIN Batch 26/5800 loss 13.953125 loss_att 393.366058 loss_ctc 19.134811 loss_rnnt 13.377383 lr 0.00025617 rank 0
2022-12-08 05:01:08,453 DEBUG TRAIN Batch 26/5800 loss 8.747954 loss_att 423.789642 loss_ctc 14.514007 loss_rnnt 8.107283 lr 0.00025617 rank 6
2022-12-08 05:01:08,455 DEBUG TRAIN Batch 26/5800 loss 8.192723 loss_att 380.373627 loss_ctc 13.532698 loss_rnnt 7.599393 lr 0.00025617 rank 3
2022-12-08 05:01:08,455 DEBUG TRAIN Batch 26/5800 loss 8.036762 loss_att 84.251602 loss_ctc 12.854855 loss_rnnt 7.501419 lr 0.00025619 rank 1
2022-12-08 05:01:08,456 DEBUG TRAIN Batch 26/5800 loss 10.617552 loss_att 447.545502 loss_ctc 21.887449 loss_rnnt 9.365342 lr 0.00025617 rank 5
2022-12-08 05:02:12,138 DEBUG TRAIN Batch 26/5900 loss 4.839593 loss_att 319.948730 loss_ctc 8.263148 loss_rnnt 4.459198 lr 0.00025613 rank 4
2022-12-08 05:02:12,139 DEBUG TRAIN Batch 26/5900 loss 4.713903 loss_att 446.025604 loss_ctc 8.898113 loss_rnnt 4.248991 lr 0.00025612 rank 7
2022-12-08 05:02:12,142 DEBUG TRAIN Batch 26/5900 loss 2.326944 loss_att 342.412476 loss_ctc 7.254561 loss_rnnt 1.779432 lr 0.00025614 rank 3
2022-12-08 05:02:12,142 DEBUG TRAIN Batch 26/5900 loss 11.293344 loss_att 349.671478 loss_ctc 21.210052 loss_rnnt 10.191488 lr 0.00025616 rank 1
2022-12-08 05:02:12,146 DEBUG TRAIN Batch 26/5900 loss 2.641718 loss_att 369.307373 loss_ctc 6.585670 loss_rnnt 2.203501 lr 0.00025613 rank 0
2022-12-08 05:02:12,149 DEBUG TRAIN Batch 26/5900 loss 9.613508 loss_att 358.794525 loss_ctc 17.015049 loss_rnnt 8.791115 lr 0.00025614 rank 5
2022-12-08 05:02:12,150 DEBUG TRAIN Batch 26/5900 loss 15.541594 loss_att 383.426941 loss_ctc 30.687717 loss_rnnt 13.858691 lr 0.00025614 rank 6
2022-12-08 05:02:12,153 DEBUG TRAIN Batch 26/5900 loss 3.590729 loss_att 370.273529 loss_ctc 7.887336 loss_rnnt 3.113328 lr 0.00025614 rank 2
2022-12-08 05:03:17,466 DEBUG TRAIN Batch 26/6000 loss 5.897782 loss_att 368.446716 loss_ctc 15.827216 loss_rnnt 4.794512 lr 0.00025610 rank 5
2022-12-08 05:03:17,467 DEBUG TRAIN Batch 26/6000 loss 8.076025 loss_att 399.610718 loss_ctc 10.101800 loss_rnnt 7.850939 lr 0.00025611 rank 6
2022-12-08 05:03:17,467 DEBUG TRAIN Batch 26/6000 loss 6.994769 loss_att 386.790070 loss_ctc 12.480778 loss_rnnt 6.385212 lr 0.00025610 rank 3
2022-12-08 05:03:17,477 DEBUG TRAIN Batch 26/6000 loss 3.472690 loss_att 410.435883 loss_ctc 9.366673 loss_rnnt 2.817803 lr 0.00025609 rank 7
2022-12-08 05:03:17,479 DEBUG TRAIN Batch 26/6000 loss 12.347572 loss_att 449.278168 loss_ctc 23.410370 loss_rnnt 11.118373 lr 0.00025611 rank 2
2022-12-08 05:03:17,479 DEBUG TRAIN Batch 26/6000 loss 6.013631 loss_att 362.640808 loss_ctc 10.767538 loss_rnnt 5.485419 lr 0.00025610 rank 0
2022-12-08 05:03:17,487 DEBUG TRAIN Batch 26/6000 loss 4.181881 loss_att 341.545898 loss_ctc 10.397979 loss_rnnt 3.491203 lr 0.00025609 rank 4
2022-12-08 05:03:17,495 DEBUG TRAIN Batch 26/6000 loss 10.817623 loss_att 374.582947 loss_ctc 20.270725 loss_rnnt 9.767279 lr 0.00025613 rank 1
2022-12-08 05:04:29,934 DEBUG TRAIN Batch 26/6100 loss 6.100442 loss_att 338.294983 loss_ctc 13.828969 loss_rnnt 5.241717 lr 0.00025605 rank 7
2022-12-08 05:04:29,937 DEBUG TRAIN Batch 26/6100 loss 7.485684 loss_att 324.864136 loss_ctc 12.780088 loss_rnnt 6.897417 lr 0.00025607 rank 3
2022-12-08 05:04:29,938 DEBUG TRAIN Batch 26/6100 loss 7.933607 loss_att 392.884338 loss_ctc 16.389084 loss_rnnt 6.994110 lr 0.00025608 rank 2
2022-12-08 05:04:29,940 DEBUG TRAIN Batch 26/6100 loss 4.311782 loss_att 335.775635 loss_ctc 9.967112 loss_rnnt 3.683412 lr 0.00025607 rank 5
2022-12-08 05:04:29,942 DEBUG TRAIN Batch 26/6100 loss 13.071529 loss_att 410.986847 loss_ctc 24.012598 loss_rnnt 11.855855 lr 0.00025606 rank 4
2022-12-08 05:04:29,942 DEBUG TRAIN Batch 26/6100 loss 3.075360 loss_att 335.173920 loss_ctc 6.352590 loss_rnnt 2.711223 lr 0.00025607 rank 0
2022-12-08 05:04:29,942 DEBUG TRAIN Batch 26/6100 loss 3.878939 loss_att 360.850281 loss_ctc 9.637840 loss_rnnt 3.239061 lr 0.00025609 rank 1
2022-12-08 05:04:29,944 DEBUG TRAIN Batch 26/6100 loss 7.646606 loss_att 378.821808 loss_ctc 17.219151 loss_rnnt 6.582990 lr 0.00025607 rank 6
2022-12-08 05:05:33,887 DEBUG TRAIN Batch 26/6200 loss 6.011447 loss_att 341.217957 loss_ctc 14.305191 loss_rnnt 5.089920 lr 0.00025604 rank 6
2022-12-08 05:05:33,887 DEBUG TRAIN Batch 26/6200 loss 3.376392 loss_att 358.398193 loss_ctc 6.655262 loss_rnnt 3.012073 lr 0.00025602 rank 7
2022-12-08 05:05:33,889 DEBUG TRAIN Batch 26/6200 loss 5.674129 loss_att 164.708267 loss_ctc 8.700440 loss_rnnt 5.337873 lr 0.00025604 rank 3
2022-12-08 05:05:33,891 DEBUG TRAIN Batch 26/6200 loss 6.137435 loss_att 334.986572 loss_ctc 14.372556 loss_rnnt 5.222422 lr 0.00025603 rank 0
2022-12-08 05:05:33,894 DEBUG TRAIN Batch 26/6200 loss 2.658663 loss_att 356.837067 loss_ctc 6.223874 loss_rnnt 2.262528 lr 0.00025606 rank 1
2022-12-08 05:05:33,895 DEBUG TRAIN Batch 26/6200 loss 11.235350 loss_att 388.196381 loss_ctc 22.276386 loss_rnnt 10.008568 lr 0.00025602 rank 4
2022-12-08 05:05:33,895 DEBUG TRAIN Batch 26/6200 loss 19.131123 loss_att 383.409058 loss_ctc 29.846643 loss_rnnt 17.940510 lr 0.00025604 rank 2
2022-12-08 05:05:33,895 DEBUG TRAIN Batch 26/6200 loss 4.646986 loss_att 349.730682 loss_ctc 7.238923 loss_rnnt 4.358993 lr 0.00025603 rank 5
2022-12-08 05:06:37,755 DEBUG TRAIN Batch 26/6300 loss 8.977394 loss_att 269.847290 loss_ctc 14.211459 loss_rnnt 8.395831 lr 0.00025599 rank 7
2022-12-08 05:06:37,760 DEBUG TRAIN Batch 26/6300 loss 6.316071 loss_att 268.505127 loss_ctc 11.578297 loss_rnnt 5.731380 lr 0.00025600 rank 6
2022-12-08 05:06:37,761 DEBUG TRAIN Batch 26/6300 loss 11.874989 loss_att 237.506851 loss_ctc 24.571665 loss_rnnt 10.464247 lr 0.00025600 rank 0
2022-12-08 05:06:37,762 DEBUG TRAIN Batch 26/6300 loss 10.414562 loss_att 376.104706 loss_ctc 28.846670 loss_rnnt 8.366550 lr 0.00025600 rank 3
2022-12-08 05:06:37,762 DEBUG TRAIN Batch 26/6300 loss 8.523054 loss_att 308.437317 loss_ctc 14.166063 loss_rnnt 7.896053 lr 0.00025603 rank 1
2022-12-08 05:06:37,765 DEBUG TRAIN Batch 26/6300 loss 17.861595 loss_att 381.422607 loss_ctc 28.616947 loss_rnnt 16.666557 lr 0.00025601 rank 2
2022-12-08 05:06:37,765 DEBUG TRAIN Batch 26/6300 loss 9.565691 loss_att 289.185059 loss_ctc 14.743759 loss_rnnt 8.990351 lr 0.00025599 rank 4
2022-12-08 05:06:37,771 DEBUG TRAIN Batch 26/6300 loss 7.719227 loss_att 255.634033 loss_ctc 12.498995 loss_rnnt 7.188142 lr 0.00025600 rank 5
2022-12-08 05:07:52,283 DEBUG TRAIN Batch 26/6400 loss 7.076659 loss_att 456.427246 loss_ctc 16.900902 loss_rnnt 5.985077 lr 0.00025596 rank 4
2022-12-08 05:07:52,286 DEBUG TRAIN Batch 26/6400 loss 3.837251 loss_att 352.773682 loss_ctc 10.594672 loss_rnnt 3.086426 lr 0.00025595 rank 7
2022-12-08 05:07:52,290 DEBUG TRAIN Batch 26/6400 loss 6.049502 loss_att 397.398926 loss_ctc 14.321934 loss_rnnt 5.130343 lr 0.00025597 rank 5
2022-12-08 05:07:52,292 DEBUG TRAIN Batch 26/6400 loss 2.724310 loss_att 165.581985 loss_ctc 7.942161 loss_rnnt 2.144549 lr 0.00025597 rank 2
2022-12-08 05:07:52,293 DEBUG TRAIN Batch 26/6400 loss 7.520192 loss_att 212.988129 loss_ctc 12.765265 loss_rnnt 6.937406 lr 0.00025599 rank 1
2022-12-08 05:07:52,295 DEBUG TRAIN Batch 26/6400 loss 13.743830 loss_att 463.919922 loss_ctc 32.860897 loss_rnnt 11.619711 lr 0.00025597 rank 3
2022-12-08 05:07:52,314 DEBUG TRAIN Batch 26/6400 loss 2.220017 loss_att 425.413086 loss_ctc 7.143142 loss_rnnt 1.673004 lr 0.00025597 rank 6
2022-12-08 05:07:52,316 DEBUG TRAIN Batch 26/6400 loss 13.262143 loss_att 410.477142 loss_ctc 17.234762 loss_rnnt 12.820742 lr 0.00025596 rank 0
2022-12-08 05:08:56,303 DEBUG TRAIN Batch 26/6500 loss 3.663338 loss_att 410.774658 loss_ctc 13.419112 loss_rnnt 2.579363 lr 0.00025592 rank 7
2022-12-08 05:08:56,304 DEBUG TRAIN Batch 26/6500 loss 4.686168 loss_att 396.907715 loss_ctc 10.997458 loss_rnnt 3.984914 lr 0.00025592 rank 4
2022-12-08 05:08:56,305 DEBUG TRAIN Batch 26/6500 loss 0.692960 loss_att 382.997040 loss_ctc 3.282254 loss_rnnt 0.405261 lr 0.00025593 rank 5
2022-12-08 05:08:56,306 DEBUG TRAIN Batch 26/6500 loss 8.261930 loss_att 349.000488 loss_ctc 11.619230 loss_rnnt 7.888897 lr 0.00025596 rank 1
2022-12-08 05:08:56,307 DEBUG TRAIN Batch 26/6500 loss 2.684259 loss_att 398.228516 loss_ctc 7.276021 loss_rnnt 2.174063 lr 0.00025594 rank 6
2022-12-08 05:08:56,310 DEBUG TRAIN Batch 26/6500 loss 12.361115 loss_att 400.373108 loss_ctc 26.926229 loss_rnnt 10.742769 lr 0.00025593 rank 0
2022-12-08 05:08:56,316 DEBUG TRAIN Batch 26/6500 loss 12.010463 loss_att 400.897430 loss_ctc 20.832443 loss_rnnt 11.030243 lr 0.00025593 rank 3
2022-12-08 05:08:56,317 DEBUG TRAIN Batch 26/6500 loss 4.944241 loss_att 344.941345 loss_ctc 8.308219 loss_rnnt 4.570465 lr 0.00025594 rank 2
2022-12-08 05:09:59,735 DEBUG TRAIN Batch 26/6600 loss 4.666286 loss_att 414.176575 loss_ctc 14.639911 loss_rnnt 3.558106 lr 0.00025589 rank 4
2022-12-08 05:09:59,736 DEBUG TRAIN Batch 26/6600 loss 10.606189 loss_att 385.889465 loss_ctc 18.934265 loss_rnnt 9.680847 lr 0.00025590 rank 0
2022-12-08 05:09:59,737 DEBUG TRAIN Batch 26/6600 loss 2.545330 loss_att 363.470398 loss_ctc 3.926247 loss_rnnt 2.391895 lr 0.00025589 rank 7
2022-12-08 05:09:59,737 DEBUG TRAIN Batch 26/6600 loss 6.668642 loss_att 329.199036 loss_ctc 15.056579 loss_rnnt 5.736650 lr 0.00025590 rank 6
2022-12-08 05:09:59,742 DEBUG TRAIN Batch 26/6600 loss 2.474596 loss_att 425.442017 loss_ctc 8.105207 loss_rnnt 1.848973 lr 0.00025591 rank 2
2022-12-08 05:09:59,743 DEBUG TRAIN Batch 26/6600 loss 16.292727 loss_att 363.014496 loss_ctc 21.540516 loss_rnnt 15.709640 lr 0.00025592 rank 1
2022-12-08 05:09:59,747 DEBUG TRAIN Batch 26/6600 loss 6.748918 loss_att 404.387390 loss_ctc 13.339339 loss_rnnt 6.016649 lr 0.00025590 rank 3
2022-12-08 05:09:59,748 DEBUG TRAIN Batch 26/6600 loss 8.648386 loss_att 450.246429 loss_ctc 21.206974 loss_rnnt 7.252987 lr 0.00025590 rank 5
2022-12-08 05:11:04,169 DEBUG TRAIN Batch 26/6700 loss 8.001754 loss_att 317.681610 loss_ctc 16.814430 loss_rnnt 7.022568 lr 0.00025585 rank 7
2022-12-08 05:11:04,172 DEBUG TRAIN Batch 26/6700 loss 3.136729 loss_att 292.397278 loss_ctc 9.082750 loss_rnnt 2.476060 lr 0.00025587 rank 3
2022-12-08 05:11:04,171 DEBUG TRAIN Batch 26/6700 loss 11.784724 loss_att 346.683777 loss_ctc 25.329248 loss_rnnt 10.279778 lr 0.00025586 rank 0
2022-12-08 05:11:04,172 DEBUG TRAIN Batch 26/6700 loss 7.881658 loss_att 297.609344 loss_ctc 17.021742 loss_rnnt 6.866094 lr 0.00025587 rank 6
2022-12-08 05:11:04,172 DEBUG TRAIN Batch 26/6700 loss 10.052611 loss_att 419.263489 loss_ctc 18.816624 loss_rnnt 9.078833 lr 0.00025587 rank 2
2022-12-08 05:11:04,175 DEBUG TRAIN Batch 26/6700 loss 6.043278 loss_att 409.990540 loss_ctc 15.351764 loss_rnnt 5.009002 lr 0.00025589 rank 1
2022-12-08 05:11:04,176 DEBUG TRAIN Batch 26/6700 loss 6.408167 loss_att 368.954132 loss_ctc 10.670881 loss_rnnt 5.934532 lr 0.00025586 rank 4
2022-12-08 05:11:04,177 DEBUG TRAIN Batch 26/6700 loss 5.344200 loss_att 339.730560 loss_ctc 14.184259 loss_rnnt 4.361971 lr 0.00025587 rank 5
2022-12-08 05:12:16,402 DEBUG TRAIN Batch 26/6800 loss 4.799417 loss_att 357.813904 loss_ctc 9.268920 loss_rnnt 4.302806 lr 0.00025582 rank 4
2022-12-08 05:12:16,407 DEBUG TRAIN Batch 26/6800 loss 8.175928 loss_att 300.893829 loss_ctc 14.788771 loss_rnnt 7.441168 lr 0.00025582 rank 7
2022-12-08 05:12:16,411 DEBUG TRAIN Batch 26/6800 loss 8.891065 loss_att 342.233887 loss_ctc 20.797125 loss_rnnt 7.568169 lr 0.00025583 rank 0
2022-12-08 05:12:16,412 DEBUG TRAIN Batch 26/6800 loss 6.314689 loss_att 381.903625 loss_ctc 17.418356 loss_rnnt 5.080948 lr 0.00025584 rank 2
2022-12-08 05:12:16,412 DEBUG TRAIN Batch 26/6800 loss 10.855448 loss_att 263.953278 loss_ctc 19.474064 loss_rnnt 9.897823 lr 0.00025583 rank 3
2022-12-08 05:12:16,416 DEBUG TRAIN Batch 26/6800 loss 4.490260 loss_att 349.043762 loss_ctc 13.957844 loss_rnnt 3.438306 lr 0.00025583 rank 5
2022-12-08 05:12:16,426 DEBUG TRAIN Batch 26/6800 loss 11.250252 loss_att 369.965393 loss_ctc 18.390404 loss_rnnt 10.456902 lr 0.00025584 rank 6
2022-12-08 05:12:16,439 DEBUG TRAIN Batch 26/6800 loss 10.172167 loss_att 386.642883 loss_ctc 27.505602 loss_rnnt 8.246229 lr 0.00025586 rank 1
2022-12-08 05:13:19,895 DEBUG TRAIN Batch 26/6900 loss 10.207609 loss_att 448.220917 loss_ctc 19.773880 loss_rnnt 9.144690 lr 0.00025580 rank 3
2022-12-08 05:13:19,903 DEBUG TRAIN Batch 26/6900 loss 3.096257 loss_att 326.342499 loss_ctc 5.927364 loss_rnnt 2.781689 lr 0.00025579 rank 4
2022-12-08 05:13:19,905 DEBUG TRAIN Batch 26/6900 loss 8.746254 loss_att 287.279968 loss_ctc 19.081459 loss_rnnt 7.597898 lr 0.00025579 rank 7
2022-12-08 05:13:19,909 DEBUG TRAIN Batch 26/6900 loss 4.435455 loss_att 319.691467 loss_ctc 10.099542 loss_rnnt 3.806113 lr 0.00025580 rank 6
2022-12-08 05:13:19,910 DEBUG TRAIN Batch 26/6900 loss 7.004333 loss_att 249.008286 loss_ctc 11.994415 loss_rnnt 6.449880 lr 0.00025580 rank 5
2022-12-08 05:13:19,911 DEBUG TRAIN Batch 26/6900 loss 6.890759 loss_att 351.269318 loss_ctc 16.495096 loss_rnnt 5.823610 lr 0.00025581 rank 2
2022-12-08 05:13:19,912 DEBUG TRAIN Batch 26/6900 loss 13.464199 loss_att 279.130127 loss_ctc 21.431152 loss_rnnt 12.578982 lr 0.00025580 rank 0
2022-12-08 05:13:19,917 DEBUG TRAIN Batch 26/6900 loss 16.067335 loss_att 353.553894 loss_ctc 31.473801 loss_rnnt 14.355505 lr 0.00025582 rank 1
2022-12-08 05:14:23,876 DEBUG TRAIN Batch 26/7000 loss 7.011698 loss_att 294.759430 loss_ctc 12.460494 loss_rnnt 6.406277 lr 0.00025577 rank 2
2022-12-08 05:14:23,879 DEBUG TRAIN Batch 26/7000 loss 5.101037 loss_att 406.711029 loss_ctc 9.415592 loss_rnnt 4.621642 lr 0.00025575 rank 7
2022-12-08 05:14:23,879 DEBUG TRAIN Batch 26/7000 loss 9.395672 loss_att 186.622528 loss_ctc 16.001726 loss_rnnt 8.661666 lr 0.00025576 rank 4
2022-12-08 05:14:23,880 DEBUG TRAIN Batch 26/7000 loss 13.515936 loss_att 447.644379 loss_ctc 32.192886 loss_rnnt 11.440720 lr 0.00025577 rank 3
2022-12-08 05:14:23,883 DEBUG TRAIN Batch 26/7000 loss 6.035525 loss_att 406.202484 loss_ctc 12.530025 loss_rnnt 5.313914 lr 0.00025576 rank 0
2022-12-08 05:14:23,886 DEBUG TRAIN Batch 26/7000 loss 11.135292 loss_att 200.051132 loss_ctc 19.873573 loss_rnnt 10.164372 lr 0.00025577 rank 6
2022-12-08 05:14:23,890 DEBUG TRAIN Batch 26/7000 loss 17.309135 loss_att 176.965942 loss_ctc 30.649471 loss_rnnt 15.826877 lr 0.00025577 rank 5
2022-12-08 05:14:23,903 DEBUG TRAIN Batch 26/7000 loss 8.748901 loss_att 331.033173 loss_ctc 15.561829 loss_rnnt 7.991910 lr 0.00025579 rank 1
2022-12-08 05:15:33,426 DEBUG TRAIN Batch 26/7100 loss 4.456562 loss_att 367.587982 loss_ctc 8.620959 loss_rnnt 3.993851 lr 0.00025573 rank 5
2022-12-08 05:15:33,434 DEBUG TRAIN Batch 26/7100 loss 10.989751 loss_att 371.261658 loss_ctc 24.831211 loss_rnnt 9.451812 lr 0.00025572 rank 7
2022-12-08 05:15:33,436 DEBUG TRAIN Batch 26/7100 loss 4.581230 loss_att 413.180725 loss_ctc 11.356402 loss_rnnt 3.828433 lr 0.00025573 rank 0
2022-12-08 05:15:33,446 DEBUG TRAIN Batch 26/7100 loss 8.429404 loss_att 346.495209 loss_ctc 12.761055 loss_rnnt 7.948110 lr 0.00025574 rank 6
2022-12-08 05:15:33,467 DEBUG TRAIN Batch 26/7100 loss 10.668056 loss_att 458.746338 loss_ctc 23.981564 loss_rnnt 9.188778 lr 0.00025572 rank 4
2022-12-08 05:15:33,469 DEBUG TRAIN Batch 26/7100 loss 14.061499 loss_att 372.067810 loss_ctc 33.209290 loss_rnnt 11.933966 lr 0.00025573 rank 3
2022-12-08 05:15:33,472 DEBUG TRAIN Batch 26/7100 loss 6.191650 loss_att 192.053406 loss_ctc 12.192646 loss_rnnt 5.524873 lr 0.00025574 rank 2
2022-12-08 05:15:33,500 DEBUG TRAIN Batch 26/7100 loss 13.335509 loss_att 374.238770 loss_ctc 34.105747 loss_rnnt 11.027705 lr 0.00025576 rank 1
2022-12-08 05:16:40,181 DEBUG TRAIN Batch 26/7200 loss 4.884190 loss_att 397.007812 loss_ctc 10.202540 loss_rnnt 4.293262 lr 0.00025569 rank 7
2022-12-08 05:16:40,182 DEBUG TRAIN Batch 26/7200 loss 5.025840 loss_att 383.891602 loss_ctc 15.420755 loss_rnnt 3.870850 lr 0.00025569 rank 4
2022-12-08 05:16:40,185 DEBUG TRAIN Batch 26/7200 loss 7.279642 loss_att 398.166931 loss_ctc 12.139235 loss_rnnt 6.739687 lr 0.00025570 rank 0
2022-12-08 05:16:40,187 DEBUG TRAIN Batch 26/7200 loss 4.370869 loss_att 376.655273 loss_ctc 9.569246 loss_rnnt 3.793272 lr 0.00025571 rank 2
2022-12-08 05:16:40,189 DEBUG TRAIN Batch 26/7200 loss 7.332744 loss_att 369.800018 loss_ctc 16.360193 loss_rnnt 6.329695 lr 0.00025572 rank 1
2022-12-08 05:16:40,189 DEBUG TRAIN Batch 26/7200 loss 2.410192 loss_att 358.354309 loss_ctc 8.340961 loss_rnnt 1.751218 lr 0.00025570 rank 5
2022-12-08 05:16:40,216 DEBUG TRAIN Batch 26/7200 loss 5.839385 loss_att 378.649017 loss_ctc 11.731550 loss_rnnt 5.184700 lr 0.00025570 rank 3
2022-12-08 05:16:40,226 DEBUG TRAIN Batch 26/7200 loss 9.148314 loss_att 405.263031 loss_ctc 19.105404 loss_rnnt 8.041970 lr 0.00025570 rank 6
2022-12-08 05:17:43,862 DEBUG TRAIN Batch 26/7300 loss 8.838194 loss_att 398.785767 loss_ctc 25.268860 loss_rnnt 7.012565 lr 0.00025565 rank 7
2022-12-08 05:17:43,863 DEBUG TRAIN Batch 26/7300 loss 9.276336 loss_att 362.531525 loss_ctc 19.515537 loss_rnnt 8.138647 lr 0.00025567 rank 6
2022-12-08 05:17:43,868 DEBUG TRAIN Batch 26/7300 loss 8.849235 loss_att 376.093994 loss_ctc 15.672796 loss_rnnt 8.091062 lr 0.00025569 rank 1
2022-12-08 05:17:43,869 DEBUG TRAIN Batch 26/7300 loss 6.404878 loss_att 387.417664 loss_ctc 12.351585 loss_rnnt 5.744133 lr 0.00025566 rank 0
2022-12-08 05:17:43,869 DEBUG TRAIN Batch 26/7300 loss 4.872444 loss_att 361.930542 loss_ctc 10.090714 loss_rnnt 4.292636 lr 0.00025566 rank 4
2022-12-08 05:17:43,870 DEBUG TRAIN Batch 26/7300 loss 11.547037 loss_att 420.893250 loss_ctc 24.334473 loss_rnnt 10.126212 lr 0.00025567 rank 5
2022-12-08 05:17:43,871 DEBUG TRAIN Batch 26/7300 loss 3.391838 loss_att 346.819427 loss_ctc 10.120317 loss_rnnt 2.644229 lr 0.00025567 rank 2
2022-12-08 05:17:43,877 DEBUG TRAIN Batch 26/7300 loss 12.219276 loss_att 413.339539 loss_ctc 22.187485 loss_rnnt 11.111698 lr 0.00025567 rank 3
2022-12-08 05:18:48,138 DEBUG TRAIN Batch 26/7400 loss 8.010777 loss_att 387.174042 loss_ctc 17.474159 loss_rnnt 6.959291 lr 0.00025564 rank 2
2022-12-08 05:18:48,141 DEBUG TRAIN Batch 26/7400 loss 12.054545 loss_att 367.327545 loss_ctc 18.710787 loss_rnnt 11.314963 lr 0.00025564 rank 6
2022-12-08 05:18:48,146 DEBUG TRAIN Batch 26/7400 loss 8.595451 loss_att 385.753235 loss_ctc 15.072044 loss_rnnt 7.875830 lr 0.00025566 rank 1
2022-12-08 05:18:48,150 DEBUG TRAIN Batch 26/7400 loss 3.373448 loss_att 337.354584 loss_ctc 6.516091 loss_rnnt 3.024266 lr 0.00025562 rank 7
2022-12-08 05:18:48,151 DEBUG TRAIN Batch 26/7400 loss 10.937843 loss_att 379.530029 loss_ctc 23.344568 loss_rnnt 9.559319 lr 0.00025562 rank 4
2022-12-08 05:18:48,153 DEBUG TRAIN Batch 26/7400 loss 12.023429 loss_att 328.496887 loss_ctc 26.276260 loss_rnnt 10.439781 lr 0.00025563 rank 5
2022-12-08 05:18:48,157 DEBUG TRAIN Batch 26/7400 loss 9.481828 loss_att 383.711761 loss_ctc 16.464184 loss_rnnt 8.706011 lr 0.00025563 rank 0
2022-12-08 05:18:48,180 DEBUG TRAIN Batch 26/7400 loss 7.233461 loss_att 331.507751 loss_ctc 13.696792 loss_rnnt 6.515314 lr 0.00025563 rank 3
2022-12-08 05:20:00,467 DEBUG TRAIN Batch 26/7500 loss 7.811799 loss_att 339.028809 loss_ctc 17.839956 loss_rnnt 6.697559 lr 0.00025559 rank 7
2022-12-08 05:20:00,469 DEBUG TRAIN Batch 26/7500 loss 7.683502 loss_att 350.617126 loss_ctc 14.381032 loss_rnnt 6.939332 lr 0.00025559 rank 4
2022-12-08 05:20:00,469 DEBUG TRAIN Batch 26/7500 loss 7.629441 loss_att 390.260376 loss_ctc 14.827278 loss_rnnt 6.829681 lr 0.00025561 rank 2
2022-12-08 05:20:00,472 DEBUG TRAIN Batch 26/7500 loss 9.373793 loss_att 317.247833 loss_ctc 20.213379 loss_rnnt 8.169394 lr 0.00025560 rank 6
2022-12-08 05:20:00,472 DEBUG TRAIN Batch 26/7500 loss 7.046173 loss_att 317.267151 loss_ctc 15.569667 loss_rnnt 6.099118 lr 0.00025562 rank 1
2022-12-08 05:20:00,475 DEBUG TRAIN Batch 26/7500 loss 6.646791 loss_att 299.709717 loss_ctc 17.205166 loss_rnnt 5.473638 lr 0.00025560 rank 5
2022-12-08 05:20:00,476 DEBUG TRAIN Batch 26/7500 loss 14.256979 loss_att 226.319290 loss_ctc 27.381981 loss_rnnt 12.798646 lr 0.00025560 rank 3
2022-12-08 05:20:00,479 DEBUG TRAIN Batch 26/7500 loss 2.560065 loss_att 298.271667 loss_ctc 8.999932 loss_rnnt 1.844524 lr 0.00025560 rank 0
2022-12-08 05:21:04,477 DEBUG TRAIN Batch 26/7600 loss 6.079815 loss_att 295.668671 loss_ctc 10.838073 loss_rnnt 5.551120 lr 0.00025556 rank 4
2022-12-08 05:21:04,485 DEBUG TRAIN Batch 26/7600 loss 6.125753 loss_att 230.242554 loss_ctc 11.877752 loss_rnnt 5.486642 lr 0.00025557 rank 6
2022-12-08 05:21:04,485 DEBUG TRAIN Batch 26/7600 loss 8.235286 loss_att 124.014732 loss_ctc 14.141438 loss_rnnt 7.579047 lr 0.00025557 rank 5
2022-12-08 05:21:04,485 DEBUG TRAIN Batch 26/7600 loss 9.750065 loss_att 259.126099 loss_ctc 17.319878 loss_rnnt 8.908975 lr 0.00025555 rank 7
2022-12-08 05:21:04,485 DEBUG TRAIN Batch 26/7600 loss 1.255071 loss_att 294.912842 loss_ctc 7.352543 loss_rnnt 0.577574 lr 0.00025556 rank 0
2022-12-08 05:21:04,487 DEBUG TRAIN Batch 26/7600 loss 7.305882 loss_att 261.144379 loss_ctc 12.139167 loss_rnnt 6.768850 lr 0.00025559 rank 1
2022-12-08 05:21:04,488 DEBUG TRAIN Batch 26/7600 loss 9.523759 loss_att 448.112885 loss_ctc 25.777771 loss_rnnt 7.717757 lr 0.00025557 rank 3
2022-12-08 05:21:04,489 DEBUG TRAIN Batch 26/7600 loss 3.533944 loss_att 350.546967 loss_ctc 8.459560 loss_rnnt 2.986654 lr 0.00025557 rank 2
2022-12-08 05:22:08,566 DEBUG TRAIN Batch 26/7700 loss 7.429302 loss_att 396.516602 loss_ctc 18.871372 loss_rnnt 6.157961 lr 0.00025554 rank 6
2022-12-08 05:22:08,582 DEBUG TRAIN Batch 26/7700 loss 2.950506 loss_att 391.136902 loss_ctc 8.159431 loss_rnnt 2.371737 lr 0.00025552 rank 7
2022-12-08 05:22:08,582 DEBUG TRAIN Batch 26/7700 loss 3.252911 loss_att 437.238953 loss_ctc 6.649175 loss_rnnt 2.875549 lr 0.00025552 rank 4
2022-12-08 05:22:08,585 DEBUG TRAIN Batch 26/7700 loss 4.493467 loss_att 395.264282 loss_ctc 8.760509 loss_rnnt 4.019351 lr 0.00025553 rank 5
2022-12-08 05:22:08,586 DEBUG TRAIN Batch 26/7700 loss 1.825475 loss_att 379.163177 loss_ctc 6.436004 loss_rnnt 1.313194 lr 0.00025553 rank 3
2022-12-08 05:22:08,587 DEBUG TRAIN Batch 26/7700 loss 2.778564 loss_att 377.476868 loss_ctc 6.261433 loss_rnnt 2.391579 lr 0.00025553 rank 0
2022-12-08 05:22:08,590 DEBUG TRAIN Batch 26/7700 loss 7.641896 loss_att 374.698914 loss_ctc 25.324797 loss_rnnt 5.677129 lr 0.00025556 rank 1
2022-12-08 05:22:08,592 DEBUG TRAIN Batch 26/7700 loss 7.442940 loss_att 239.666748 loss_ctc 14.073755 loss_rnnt 6.706182 lr 0.00025554 rank 2
2022-12-08 05:23:13,807 DEBUG TRAIN Batch 26/7800 loss 6.566688 loss_att 398.664734 loss_ctc 18.054304 loss_rnnt 5.290287 lr 0.00025549 rank 4
2022-12-08 05:23:13,809 DEBUG TRAIN Batch 26/7800 loss 16.223402 loss_att 439.540039 loss_ctc 28.873669 loss_rnnt 14.817817 lr 0.00025549 rank 7
2022-12-08 05:23:13,812 DEBUG TRAIN Batch 26/7800 loss 16.186031 loss_att 336.602539 loss_ctc 44.145855 loss_rnnt 13.079384 lr 0.00025550 rank 6
2022-12-08 05:23:13,813 DEBUG TRAIN Batch 26/7800 loss 10.185592 loss_att 408.935669 loss_ctc 18.219822 loss_rnnt 9.292899 lr 0.00025552 rank 1
2022-12-08 05:23:13,816 DEBUG TRAIN Batch 26/7800 loss 4.361081 loss_att 337.723267 loss_ctc 8.326153 loss_rnnt 3.920517 lr 0.00025550 rank 0
2022-12-08 05:23:13,816 DEBUG TRAIN Batch 26/7800 loss 1.270446 loss_att 366.088226 loss_ctc 5.404579 loss_rnnt 0.811098 lr 0.00025550 rank 5
2022-12-08 05:23:13,825 DEBUG TRAIN Batch 26/7800 loss 6.722015 loss_att 402.896301 loss_ctc 10.141626 loss_rnnt 6.342058 lr 0.00025551 rank 2
2022-12-08 05:23:13,834 DEBUG TRAIN Batch 26/7800 loss 8.328440 loss_att 329.817871 loss_ctc 16.438168 loss_rnnt 7.427360 lr 0.00025550 rank 3
2022-12-08 05:24:25,102 DEBUG TRAIN Batch 26/7900 loss 8.562344 loss_att 422.054504 loss_ctc 14.576820 loss_rnnt 7.894069 lr 0.00025546 rank 4
2022-12-08 05:24:25,112 DEBUG TRAIN Batch 26/7900 loss 12.068936 loss_att 368.498260 loss_ctc 23.676769 loss_rnnt 10.779178 lr 0.00025545 rank 7
2022-12-08 05:24:25,116 DEBUG TRAIN Batch 26/7900 loss 6.500725 loss_att 349.803345 loss_ctc 13.342349 loss_rnnt 5.740545 lr 0.00025549 rank 1
2022-12-08 05:24:25,118 DEBUG TRAIN Batch 26/7900 loss 5.430682 loss_att 394.081268 loss_ctc 17.646946 loss_rnnt 4.073319 lr 0.00025547 rank 6
2022-12-08 05:24:25,119 DEBUG TRAIN Batch 26/7900 loss 3.020245 loss_att 410.271057 loss_ctc 6.570317 loss_rnnt 2.625792 lr 0.00025546 rank 0
2022-12-08 05:24:25,119 DEBUG TRAIN Batch 26/7900 loss 12.080903 loss_att 361.512054 loss_ctc 29.866180 loss_rnnt 10.104761 lr 0.00025547 rank 2
2022-12-08 05:24:25,123 DEBUG TRAIN Batch 26/7900 loss 4.711134 loss_att 349.789368 loss_ctc 9.765831 loss_rnnt 4.149501 lr 0.00025547 rank 5
2022-12-08 05:24:25,152 DEBUG TRAIN Batch 26/7900 loss 9.972135 loss_att 430.281189 loss_ctc 26.668402 loss_rnnt 8.116994 lr 0.00025547 rank 3
2022-12-08 05:25:28,636 DEBUG TRAIN Batch 26/8000 loss 6.569461 loss_att 320.722351 loss_ctc 11.190942 loss_rnnt 6.055963 lr 0.00025542 rank 7
2022-12-08 05:25:28,638 DEBUG TRAIN Batch 26/8000 loss 17.421516 loss_att 382.921936 loss_ctc 25.894718 loss_rnnt 16.480049 lr 0.00025544 rank 2
2022-12-08 05:25:28,638 DEBUG TRAIN Batch 26/8000 loss 7.155705 loss_att 352.307739 loss_ctc 12.047733 loss_rnnt 6.612146 lr 0.00025544 rank 6
2022-12-08 05:25:28,639 DEBUG TRAIN Batch 26/8000 loss 7.171876 loss_att 313.285522 loss_ctc 11.694054 loss_rnnt 6.669412 lr 0.00025542 rank 4
2022-12-08 05:25:28,641 DEBUG TRAIN Batch 26/8000 loss 11.409114 loss_att 347.489899 loss_ctc 23.963314 loss_rnnt 10.014203 lr 0.00025543 rank 0
2022-12-08 05:25:28,646 DEBUG TRAIN Batch 26/8000 loss 7.847885 loss_att 286.996399 loss_ctc 16.678322 loss_rnnt 6.866725 lr 0.00025546 rank 1
2022-12-08 05:25:28,650 DEBUG TRAIN Batch 26/8000 loss 9.765161 loss_att 359.549622 loss_ctc 18.395893 loss_rnnt 8.806190 lr 0.00025543 rank 5
2022-12-08 05:25:28,682 DEBUG TRAIN Batch 26/8000 loss 11.417080 loss_att 364.039307 loss_ctc 24.340397 loss_rnnt 9.981155 lr 0.00025543 rank 3
2022-12-08 05:26:33,177 DEBUG TRAIN Batch 26/8100 loss 11.195522 loss_att 321.275940 loss_ctc 25.392229 loss_rnnt 9.618111 lr 0.00025539 rank 7
2022-12-08 05:26:33,178 DEBUG TRAIN Batch 26/8100 loss 17.954941 loss_att 366.296875 loss_ctc 34.142555 loss_rnnt 16.156317 lr 0.00025539 rank 4
2022-12-08 05:26:33,178 DEBUG TRAIN Batch 26/8100 loss 15.303295 loss_att 402.617493 loss_ctc 38.647869 loss_rnnt 12.709454 lr 0.00025540 rank 6
2022-12-08 05:26:33,184 DEBUG TRAIN Batch 26/8100 loss 10.064639 loss_att 349.017517 loss_ctc 18.054661 loss_rnnt 9.176860 lr 0.00025540 rank 0
2022-12-08 05:26:33,186 DEBUG TRAIN Batch 26/8100 loss 4.993911 loss_att 295.950775 loss_ctc 11.393943 loss_rnnt 4.282796 lr 0.00025540 rank 3
2022-12-08 05:26:33,186 DEBUG TRAIN Batch 26/8100 loss 5.585177 loss_att 306.859375 loss_ctc 9.124005 loss_rnnt 5.191974 lr 0.00025540 rank 5
2022-12-08 05:26:33,199 DEBUG TRAIN Batch 26/8100 loss 4.283314 loss_att 321.298309 loss_ctc 6.351676 loss_rnnt 4.053496 lr 0.00025542 rank 1
2022-12-08 05:26:33,204 DEBUG TRAIN Batch 26/8100 loss 12.369747 loss_att 380.755646 loss_ctc 22.533083 loss_rnnt 11.240488 lr 0.00025541 rank 2
2022-12-08 05:27:38,193 DEBUG TRAIN Batch 26/8200 loss 4.899480 loss_att 298.608124 loss_ctc 11.016562 loss_rnnt 4.219804 lr 0.00025536 rank 4
2022-12-08 05:27:38,206 DEBUG TRAIN Batch 26/8200 loss 21.026859 loss_att 295.188965 loss_ctc 36.393990 loss_rnnt 19.319401 lr 0.00025535 rank 7
2022-12-08 05:27:38,210 DEBUG TRAIN Batch 26/8200 loss 13.797131 loss_att 309.168457 loss_ctc 27.254484 loss_rnnt 12.301869 lr 0.00025537 rank 2
2022-12-08 05:27:38,211 DEBUG TRAIN Batch 26/8200 loss 13.694497 loss_att 479.585052 loss_ctc 27.930496 loss_rnnt 12.112720 lr 0.00025537 rank 3
2022-12-08 05:27:38,210 DEBUG TRAIN Batch 26/8200 loss 5.009068 loss_att 319.729889 loss_ctc 11.398032 loss_rnnt 4.299183 lr 0.00025537 rank 6
2022-12-08 05:27:38,211 DEBUG TRAIN Batch 26/8200 loss 3.700773 loss_att 318.942474 loss_ctc 8.374930 loss_rnnt 3.181422 lr 0.00025539 rank 1
2022-12-08 05:27:38,212 DEBUG TRAIN Batch 26/8200 loss 5.721050 loss_att 234.952682 loss_ctc 10.753473 loss_rnnt 5.161892 lr 0.00025537 rank 5
2022-12-08 05:27:38,216 DEBUG TRAIN Batch 26/8200 loss 8.489604 loss_att 206.944031 loss_ctc 12.843107 loss_rnnt 8.005881 lr 0.00025536 rank 0
2022-12-08 05:28:41,999 DEBUG TRAIN Batch 26/8300 loss 7.553975 loss_att 405.311829 loss_ctc 15.979342 loss_rnnt 6.617824 lr 0.00025532 rank 7
2022-12-08 05:28:42,000 DEBUG TRAIN Batch 26/8300 loss 13.379173 loss_att 306.477844 loss_ctc 34.736256 loss_rnnt 11.006165 lr 0.00025534 rank 2
2022-12-08 05:28:42,001 DEBUG TRAIN Batch 26/8300 loss 9.862866 loss_att 339.300842 loss_ctc 19.627630 loss_rnnt 8.777893 lr 0.00025533 rank 3
2022-12-08 05:28:42,002 DEBUG TRAIN Batch 26/8300 loss 4.975543 loss_att 145.026840 loss_ctc 9.118756 loss_rnnt 4.515185 lr 0.00025532 rank 4
2022-12-08 05:28:42,005 DEBUG TRAIN Batch 26/8300 loss 7.553694 loss_att 368.744965 loss_ctc 16.462564 loss_rnnt 6.563820 lr 0.00025533 rank 5
2022-12-08 05:28:42,005 DEBUG TRAIN Batch 26/8300 loss 3.099264 loss_att 341.330627 loss_ctc 9.159281 loss_rnnt 2.425929 lr 0.00025533 rank 0
2022-12-08 05:28:42,006 DEBUG TRAIN Batch 26/8300 loss 15.108793 loss_att 160.899521 loss_ctc 25.783525 loss_rnnt 13.922711 lr 0.00025536 rank 1
2022-12-08 05:28:42,007 DEBUG TRAIN Batch 26/8300 loss 15.758636 loss_att 363.430145 loss_ctc 28.839899 loss_rnnt 14.305162 lr 0.00025534 rank 6
2022-12-08 05:29:25,762 DEBUG CV Batch 26/0 loss 1.287113 loss_att 48.085854 loss_ctc 2.407779 loss_rnnt 1.162595 history loss 1.239442 rank 4
2022-12-08 05:29:25,765 DEBUG CV Batch 26/0 loss 1.287113 loss_att 48.085854 loss_ctc 2.407779 loss_rnnt 1.162595 history loss 1.239442 rank 3
2022-12-08 05:29:25,765 DEBUG CV Batch 26/0 loss 1.287113 loss_att 48.085854 loss_ctc 2.407779 loss_rnnt 1.162595 history loss 1.239442 rank 6
2022-12-08 05:29:25,766 DEBUG CV Batch 26/0 loss 1.287113 loss_att 48.085854 loss_ctc 2.407779 loss_rnnt 1.162595 history loss 1.239442 rank 2
2022-12-08 05:29:25,772 DEBUG CV Batch 26/0 loss 1.287113 loss_att 48.085854 loss_ctc 2.407779 loss_rnnt 1.162595 history loss 1.239442 rank 0
2022-12-08 05:29:25,776 DEBUG CV Batch 26/0 loss 1.287113 loss_att 48.085854 loss_ctc 2.407779 loss_rnnt 1.162595 history loss 1.239442 rank 1
2022-12-08 05:29:25,776 DEBUG CV Batch 26/0 loss 1.287113 loss_att 48.085854 loss_ctc 2.407779 loss_rnnt 1.162595 history loss 1.239442 rank 5
2022-12-08 05:29:25,786 DEBUG CV Batch 26/0 loss 1.287113 loss_att 48.085854 loss_ctc 2.407779 loss_rnnt 1.162595 history loss 1.239442 rank 7
2022-12-08 05:29:36,656 DEBUG CV Batch 26/100 loss 3.753123 loss_att 266.942871 loss_ctc 9.971186 loss_rnnt 3.062227 history loss 2.920529 rank 4
2022-12-08 05:29:36,703 DEBUG CV Batch 26/100 loss 3.753123 loss_att 266.942871 loss_ctc 9.971186 loss_rnnt 3.062227 history loss 2.920529 rank 1
2022-12-08 05:29:36,722 DEBUG CV Batch 26/100 loss 3.753123 loss_att 266.942871 loss_ctc 9.971186 loss_rnnt 3.062227 history loss 2.920529 rank 5
2022-12-08 05:29:36,723 DEBUG CV Batch 26/100 loss 3.753123 loss_att 266.942871 loss_ctc 9.971186 loss_rnnt 3.062227 history loss 2.920529 rank 2
2022-12-08 05:29:36,781 DEBUG CV Batch 26/100 loss 3.753123 loss_att 266.942871 loss_ctc 9.971186 loss_rnnt 3.062227 history loss 2.920529 rank 0
2022-12-08 05:29:36,783 DEBUG CV Batch 26/100 loss 3.753123 loss_att 266.942871 loss_ctc 9.971186 loss_rnnt 3.062227 history loss 2.920529 rank 7
2022-12-08 05:29:36,812 DEBUG CV Batch 26/100 loss 3.753123 loss_att 266.942871 loss_ctc 9.971186 loss_rnnt 3.062227 history loss 2.920529 rank 6
2022-12-08 05:29:37,046 DEBUG CV Batch 26/100 loss 3.753123 loss_att 266.942871 loss_ctc 9.971186 loss_rnnt 3.062227 history loss 2.920529 rank 3
2022-12-08 05:29:50,290 DEBUG CV Batch 26/200 loss 5.595520 loss_att 641.185852 loss_ctc 7.494097 loss_rnnt 5.384567 history loss 3.475422 rank 1
2022-12-08 05:29:50,340 DEBUG CV Batch 26/200 loss 5.595520 loss_att 641.185852 loss_ctc 7.494097 loss_rnnt 5.384567 history loss 3.475422 rank 5
2022-12-08 05:29:50,467 DEBUG CV Batch 26/200 loss 5.595520 loss_att 641.185852 loss_ctc 7.494097 loss_rnnt 5.384567 history loss 3.475422 rank 4
2022-12-08 05:29:50,531 DEBUG CV Batch 26/200 loss 5.595520 loss_att 641.185852 loss_ctc 7.494097 loss_rnnt 5.384567 history loss 3.475422 rank 6
2022-12-08 05:29:50,590 DEBUG CV Batch 26/200 loss 5.595520 loss_att 641.185852 loss_ctc 7.494097 loss_rnnt 5.384567 history loss 3.475422 rank 7
2022-12-08 05:29:50,594 DEBUG CV Batch 26/200 loss 5.595520 loss_att 641.185852 loss_ctc 7.494097 loss_rnnt 5.384567 history loss 3.475422 rank 2
2022-12-08 05:29:50,631 DEBUG CV Batch 26/200 loss 5.595520 loss_att 641.185852 loss_ctc 7.494097 loss_rnnt 5.384567 history loss 3.475422 rank 0
2022-12-08 05:29:50,828 DEBUG CV Batch 26/200 loss 5.595520 loss_att 641.185852 loss_ctc 7.494097 loss_rnnt 5.384567 history loss 3.475422 rank 3
2022-12-08 05:30:01,451 DEBUG CV Batch 26/300 loss 4.073652 loss_att 190.889771 loss_ctc 7.370369 loss_rnnt 3.707350 history loss 3.634009 rank 5
2022-12-08 05:30:01,545 DEBUG CV Batch 26/300 loss 4.073652 loss_att 190.889771 loss_ctc 7.370369 loss_rnnt 3.707350 history loss 3.634009 rank 1
2022-12-08 05:30:01,701 DEBUG CV Batch 26/300 loss 4.073652 loss_att 190.889771 loss_ctc 7.370369 loss_rnnt 3.707350 history loss 3.634009 rank 6
2022-12-08 05:30:01,773 DEBUG CV Batch 26/300 loss 4.073652 loss_att 190.889771 loss_ctc 7.370369 loss_rnnt 3.707350 history loss 3.634009 rank 2
2022-12-08 05:30:02,062 DEBUG CV Batch 26/300 loss 4.073652 loss_att 190.889771 loss_ctc 7.370369 loss_rnnt 3.707350 history loss 3.634009 rank 4
2022-12-08 05:30:02,178 DEBUG CV Batch 26/300 loss 4.073652 loss_att 190.889771 loss_ctc 7.370369 loss_rnnt 3.707350 history loss 3.634009 rank 7
2022-12-08 05:30:02,302 DEBUG CV Batch 26/300 loss 4.073652 loss_att 190.889771 loss_ctc 7.370369 loss_rnnt 3.707350 history loss 3.634009 rank 3
2022-12-08 05:30:02,555 DEBUG CV Batch 26/300 loss 4.073652 loss_att 190.889771 loss_ctc 7.370369 loss_rnnt 3.707350 history loss 3.634009 rank 0
2022-12-08 05:30:12,625 DEBUG CV Batch 26/400 loss 4.453539 loss_att 826.179016 loss_ctc 9.099512 loss_rnnt 3.937320 history loss 4.488374 rank 5
2022-12-08 05:30:12,694 DEBUG CV Batch 26/400 loss 4.453539 loss_att 826.179016 loss_ctc 9.099512 loss_rnnt 3.937320 history loss 4.488374 rank 1
2022-12-08 05:30:12,818 DEBUG CV Batch 26/400 loss 4.453539 loss_att 826.179016 loss_ctc 9.099512 loss_rnnt 3.937320 history loss 4.488374 rank 6
2022-12-08 05:30:12,906 DEBUG CV Batch 26/400 loss 4.453539 loss_att 826.179016 loss_ctc 9.099512 loss_rnnt 3.937320 history loss 4.488374 rank 2
2022-12-08 05:30:13,636 DEBUG CV Batch 26/400 loss 4.453539 loss_att 826.179016 loss_ctc 9.099512 loss_rnnt 3.937320 history loss 4.488374 rank 4
2022-12-08 05:30:13,795 DEBUG CV Batch 26/400 loss 4.453539 loss_att 826.179016 loss_ctc 9.099512 loss_rnnt 3.937320 history loss 4.488374 rank 7
2022-12-08 05:30:13,917 DEBUG CV Batch 26/400 loss 4.453539 loss_att 826.179016 loss_ctc 9.099512 loss_rnnt 3.937320 history loss 4.488374 rank 3
2022-12-08 05:30:14,404 DEBUG CV Batch 26/400 loss 4.453539 loss_att 826.179016 loss_ctc 9.099512 loss_rnnt 3.937320 history loss 4.488374 rank 0
2022-12-08 05:30:23,276 DEBUG CV Batch 26/500 loss 5.057044 loss_att 266.655762 loss_ctc 9.725541 loss_rnnt 4.538322 history loss 5.090300 rank 5
2022-12-08 05:30:23,334 DEBUG CV Batch 26/500 loss 5.057044 loss_att 266.655762 loss_ctc 9.725541 loss_rnnt 4.538322 history loss 5.090300 rank 1
2022-12-08 05:30:23,460 DEBUG CV Batch 26/500 loss 5.057044 loss_att 266.655762 loss_ctc 9.725541 loss_rnnt 4.538322 history loss 5.090300 rank 6
2022-12-08 05:30:23,542 DEBUG CV Batch 26/500 loss 5.057044 loss_att 266.655762 loss_ctc 9.725541 loss_rnnt 4.538322 history loss 5.090300 rank 2
2022-12-08 05:30:23,941 DEBUG CV Batch 26/500 loss 5.057044 loss_att 266.655762 loss_ctc 9.725541 loss_rnnt 4.538322 history loss 5.090300 rank 4
2022-12-08 05:30:24,123 DEBUG CV Batch 26/500 loss 5.057044 loss_att 266.655762 loss_ctc 9.725541 loss_rnnt 4.538322 history loss 5.090300 rank 3
2022-12-08 05:30:24,129 DEBUG CV Batch 26/500 loss 5.057044 loss_att 266.655762 loss_ctc 9.725541 loss_rnnt 4.538322 history loss 5.090300 rank 7
2022-12-08 05:30:24,778 DEBUG CV Batch 26/500 loss 5.057044 loss_att 266.655762 loss_ctc 9.725541 loss_rnnt 4.538322 history loss 5.090300 rank 0
2022-12-08 05:30:35,667 DEBUG CV Batch 26/600 loss 6.114017 loss_att 104.307930 loss_ctc 10.156725 loss_rnnt 5.664827 history loss 5.907665 rank 1
2022-12-08 05:30:35,717 DEBUG CV Batch 26/600 loss 6.114017 loss_att 104.307930 loss_ctc 10.156725 loss_rnnt 5.664827 history loss 5.907665 rank 5
2022-12-08 05:30:35,905 DEBUG CV Batch 26/600 loss 6.114017 loss_att 104.307930 loss_ctc 10.156725 loss_rnnt 5.664827 history loss 5.907665 rank 7
2022-12-08 05:30:35,909 DEBUG CV Batch 26/600 loss 6.114017 loss_att 104.307930 loss_ctc 10.156725 loss_rnnt 5.664827 history loss 5.907665 rank 3
2022-12-08 05:30:35,929 DEBUG CV Batch 26/600 loss 6.114017 loss_att 104.307930 loss_ctc 10.156725 loss_rnnt 5.664827 history loss 5.907665 rank 4
2022-12-08 05:30:35,997 DEBUG CV Batch 26/600 loss 6.114017 loss_att 104.307930 loss_ctc 10.156725 loss_rnnt 5.664827 history loss 5.907665 rank 2
2022-12-08 05:30:36,112 DEBUG CV Batch 26/600 loss 6.114017 loss_att 104.307930 loss_ctc 10.156725 loss_rnnt 5.664827 history loss 5.907665 rank 6
2022-12-08 05:30:36,754 DEBUG CV Batch 26/600 loss 6.114017 loss_att 104.307930 loss_ctc 10.156725 loss_rnnt 5.664827 history loss 5.907665 rank 0
2022-12-08 05:30:47,938 DEBUG CV Batch 26/700 loss 5.041342 loss_att 707.029968 loss_ctc 17.448738 loss_rnnt 3.662742 history loss 6.453235 rank 1
2022-12-08 05:30:48,060 DEBUG CV Batch 26/700 loss 5.041342 loss_att 707.029968 loss_ctc 17.448738 loss_rnnt 3.662742 history loss 6.453235 rank 2
2022-12-08 05:30:48,148 DEBUG CV Batch 26/700 loss 5.041342 loss_att 707.029968 loss_ctc 17.448738 loss_rnnt 3.662742 history loss 6.453235 rank 5
2022-12-08 05:30:48,154 DEBUG CV Batch 26/700 loss 5.041342 loss_att 707.029968 loss_ctc 17.448738 loss_rnnt 3.662742 history loss 6.453235 rank 4
2022-12-08 05:30:48,253 DEBUG CV Batch 26/700 loss 5.041342 loss_att 707.029968 loss_ctc 17.448738 loss_rnnt 3.662742 history loss 6.453235 rank 7
2022-12-08 05:30:48,289 DEBUG CV Batch 26/700 loss 5.041342 loss_att 707.029968 loss_ctc 17.448738 loss_rnnt 3.662742 history loss 6.453235 rank 0
2022-12-08 05:30:48,443 DEBUG CV Batch 26/700 loss 5.041342 loss_att 707.029968 loss_ctc 17.448738 loss_rnnt 3.662742 history loss 6.453235 rank 3
2022-12-08 05:30:48,525 DEBUG CV Batch 26/700 loss 5.041342 loss_att 707.029968 loss_ctc 17.448738 loss_rnnt 3.662742 history loss 6.453235 rank 6
2022-12-08 05:30:59,907 DEBUG CV Batch 26/800 loss 6.831538 loss_att 263.403137 loss_ctc 15.663649 loss_rnnt 5.850192 history loss 5.983993 rank 4
2022-12-08 05:30:59,924 DEBUG CV Batch 26/800 loss 6.831538 loss_att 263.403137 loss_ctc 15.663649 loss_rnnt 5.850192 history loss 5.983993 rank 1
2022-12-08 05:31:00,022 DEBUG CV Batch 26/800 loss 6.831538 loss_att 263.403137 loss_ctc 15.663649 loss_rnnt 5.850192 history loss 5.983993 rank 5
2022-12-08 05:31:00,028 DEBUG CV Batch 26/800 loss 6.831538 loss_att 263.403137 loss_ctc 15.663649 loss_rnnt 5.850192 history loss 5.983993 rank 2
2022-12-08 05:31:00,064 DEBUG CV Batch 26/800 loss 6.831538 loss_att 263.403137 loss_ctc 15.663649 loss_rnnt 5.850192 history loss 5.983993 rank 0
2022-12-08 05:31:00,064 DEBUG CV Batch 26/800 loss 6.831538 loss_att 263.403137 loss_ctc 15.663649 loss_rnnt 5.850192 history loss 5.983993 rank 6
2022-12-08 05:31:00,094 DEBUG CV Batch 26/800 loss 6.831538 loss_att 263.403137 loss_ctc 15.663649 loss_rnnt 5.850192 history loss 5.983993 rank 7
2022-12-08 05:31:00,348 DEBUG CV Batch 26/800 loss 6.831538 loss_att 263.403137 loss_ctc 15.663649 loss_rnnt 5.850192 history loss 5.983993 rank 3
2022-12-08 05:31:13,434 DEBUG CV Batch 26/900 loss 9.946202 loss_att 550.850952 loss_ctc 17.731119 loss_rnnt 9.081211 history loss 5.817241 rank 1
2022-12-08 05:31:13,471 DEBUG CV Batch 26/900 loss 9.946202 loss_att 550.850952 loss_ctc 17.731119 loss_rnnt 9.081211 history loss 5.817241 rank 4
2022-12-08 05:31:13,553 DEBUG CV Batch 26/900 loss 9.946202 loss_att 550.850952 loss_ctc 17.731119 loss_rnnt 9.081211 history loss 5.817241 rank 5
2022-12-08 05:31:13,589 DEBUG CV Batch 26/900 loss 9.946202 loss_att 550.850952 loss_ctc 17.731119 loss_rnnt 9.081211 history loss 5.817241 rank 0
2022-12-08 05:31:13,678 DEBUG CV Batch 26/900 loss 9.946202 loss_att 550.850952 loss_ctc 17.731119 loss_rnnt 9.081211 history loss 5.817241 rank 6
2022-12-08 05:31:13,701 DEBUG CV Batch 26/900 loss 9.946202 loss_att 550.850952 loss_ctc 17.731119 loss_rnnt 9.081211 history loss 5.817241 rank 7
2022-12-08 05:31:13,749 DEBUG CV Batch 26/900 loss 9.946202 loss_att 550.850952 loss_ctc 17.731119 loss_rnnt 9.081211 history loss 5.817241 rank 3
2022-12-08 05:31:13,844 DEBUG CV Batch 26/900 loss 9.946202 loss_att 550.850952 loss_ctc 17.731119 loss_rnnt 9.081211 history loss 5.817241 rank 2
2022-12-08 05:31:24,724 DEBUG CV Batch 26/1000 loss 2.458766 loss_att 176.486343 loss_ctc 4.608490 loss_rnnt 2.219908 history loss 5.624520 rank 1
2022-12-08 05:31:25,132 DEBUG CV Batch 26/1000 loss 2.458766 loss_att 176.486343 loss_ctc 4.608490 loss_rnnt 2.219908 history loss 5.624520 rank 6
2022-12-08 05:31:25,176 DEBUG CV Batch 26/1000 loss 2.458766 loss_att 176.486343 loss_ctc 4.608490 loss_rnnt 2.219908 history loss 5.624520 rank 5
2022-12-08 05:31:25,259 DEBUG CV Batch 26/1000 loss 2.458766 loss_att 176.486343 loss_ctc 4.608490 loss_rnnt 2.219908 history loss 5.624520 rank 4
2022-12-08 05:31:25,427 DEBUG CV Batch 26/1000 loss 2.458766 loss_att 176.486343 loss_ctc 4.608490 loss_rnnt 2.219908 history loss 5.624520 rank 2
2022-12-08 05:31:25,502 DEBUG CV Batch 26/1000 loss 2.458766 loss_att 176.486343 loss_ctc 4.608490 loss_rnnt 2.219908 history loss 5.624520 rank 3
2022-12-08 05:31:25,552 DEBUG CV Batch 26/1000 loss 2.458766 loss_att 176.486343 loss_ctc 4.608490 loss_rnnt 2.219908 history loss 5.624520 rank 7
2022-12-08 05:31:25,731 DEBUG CV Batch 26/1000 loss 2.458766 loss_att 176.486343 loss_ctc 4.608490 loss_rnnt 2.219908 history loss 5.624520 rank 0
2022-12-08 05:31:35,770 DEBUG CV Batch 26/1100 loss 5.143020 loss_att 60.694122 loss_ctc 8.362473 loss_rnnt 4.785303 history loss 5.608771 rank 1
2022-12-08 05:31:36,394 DEBUG CV Batch 26/1100 loss 5.143020 loss_att 60.694122 loss_ctc 8.362473 loss_rnnt 4.785303 history loss 5.608771 rank 6
2022-12-08 05:31:36,576 DEBUG CV Batch 26/1100 loss 5.143020 loss_att 60.694122 loss_ctc 8.362473 loss_rnnt 4.785303 history loss 5.608771 rank 3
2022-12-08 05:31:36,588 DEBUG CV Batch 26/1100 loss 5.143020 loss_att 60.694122 loss_ctc 8.362473 loss_rnnt 4.785303 history loss 5.608771 rank 5
2022-12-08 05:31:36,647 DEBUG CV Batch 26/1100 loss 5.143020 loss_att 60.694122 loss_ctc 8.362473 loss_rnnt 4.785303 history loss 5.608771 rank 2
2022-12-08 05:31:36,791 DEBUG CV Batch 26/1100 loss 5.143020 loss_att 60.694122 loss_ctc 8.362473 loss_rnnt 4.785303 history loss 5.608771 rank 4
2022-12-08 05:31:37,162 DEBUG CV Batch 26/1100 loss 5.143020 loss_att 60.694122 loss_ctc 8.362473 loss_rnnt 4.785303 history loss 5.608771 rank 7
2022-12-08 05:31:37,461 DEBUG CV Batch 26/1100 loss 5.143020 loss_att 60.694122 loss_ctc 8.362473 loss_rnnt 4.785303 history loss 5.608771 rank 0
2022-12-08 05:31:46,393 DEBUG CV Batch 26/1200 loss 6.872554 loss_att 280.455536 loss_ctc 11.266108 loss_rnnt 6.384382 history loss 5.884217 rank 1
2022-12-08 05:31:46,566 DEBUG CV Batch 26/1200 loss 6.872554 loss_att 280.455536 loss_ctc 11.266108 loss_rnnt 6.384382 history loss 5.884217 rank 6
2022-12-08 05:31:46,635 DEBUG CV Batch 26/1200 loss 6.872554 loss_att 280.455536 loss_ctc 11.266108 loss_rnnt 6.384382 history loss 5.884217 rank 3
2022-12-08 05:31:46,863 DEBUG CV Batch 26/1200 loss 6.872554 loss_att 280.455536 loss_ctc 11.266108 loss_rnnt 6.384382 history loss 5.884217 rank 2
2022-12-08 05:31:46,951 DEBUG CV Batch 26/1200 loss 6.872554 loss_att 280.455536 loss_ctc 11.266108 loss_rnnt 6.384382 history loss 5.884217 rank 4
2022-12-08 05:31:47,060 DEBUG CV Batch 26/1200 loss 6.872554 loss_att 280.455536 loss_ctc 11.266108 loss_rnnt 6.384382 history loss 5.884217 rank 5
2022-12-08 05:31:47,439 DEBUG CV Batch 26/1200 loss 6.872554 loss_att 280.455536 loss_ctc 11.266108 loss_rnnt 6.384382 history loss 5.884217 rank 7
2022-12-08 05:31:47,787 DEBUG CV Batch 26/1200 loss 6.872554 loss_att 280.455536 loss_ctc 11.266108 loss_rnnt 6.384382 history loss 5.884217 rank 0
2022-12-08 05:31:58,062 DEBUG CV Batch 26/1300 loss 4.895763 loss_att 105.976257 loss_ctc 8.143906 loss_rnnt 4.534858 history loss 6.153480 rank 6
2022-12-08 05:31:58,068 DEBUG CV Batch 26/1300 loss 4.895763 loss_att 105.976257 loss_ctc 8.143906 loss_rnnt 4.534858 history loss 6.153480 rank 1
2022-12-08 05:31:58,077 DEBUG CV Batch 26/1300 loss 4.895763 loss_att 105.976257 loss_ctc 8.143906 loss_rnnt 4.534858 history loss 6.153480 rank 3
2022-12-08 05:31:58,466 DEBUG CV Batch 26/1300 loss 4.895763 loss_att 105.976257 loss_ctc 8.143906 loss_rnnt 4.534858 history loss 6.153480 rank 4
2022-12-08 05:31:58,610 DEBUG CV Batch 26/1300 loss 4.895763 loss_att 105.976257 loss_ctc 8.143906 loss_rnnt 4.534858 history loss 6.153480 rank 2
2022-12-08 05:31:58,920 DEBUG CV Batch 26/1300 loss 4.895763 loss_att 105.976257 loss_ctc 8.143906 loss_rnnt 4.534858 history loss 6.153480 rank 5
2022-12-08 05:31:59,168 DEBUG CV Batch 26/1300 loss 4.895763 loss_att 105.976257 loss_ctc 8.143906 loss_rnnt 4.534858 history loss 6.153480 rank 7
2022-12-08 05:31:59,537 DEBUG CV Batch 26/1300 loss 4.895763 loss_att 105.976257 loss_ctc 8.143906 loss_rnnt 4.534858 history loss 6.153480 rank 0
2022-12-08 05:32:09,615 DEBUG CV Batch 26/1400 loss 2.190869 loss_att 562.090698 loss_ctc 5.251171 loss_rnnt 1.850835 history loss 6.426639 rank 4
2022-12-08 05:32:10,159 DEBUG CV Batch 26/1400 loss 2.190869 loss_att 562.090698 loss_ctc 5.251171 loss_rnnt 1.850835 history loss 6.426639 rank 7
2022-12-08 05:32:10,169 DEBUG CV Batch 26/1400 loss 2.190869 loss_att 562.090698 loss_ctc 5.251171 loss_rnnt 1.850835 history loss 6.426639 rank 1
2022-12-08 05:32:10,310 DEBUG CV Batch 26/1400 loss 2.190869 loss_att 562.090698 loss_ctc 5.251171 loss_rnnt 1.850835 history loss 6.426639 rank 3
2022-12-08 05:32:10,353 DEBUG CV Batch 26/1400 loss 2.190869 loss_att 562.090698 loss_ctc 5.251171 loss_rnnt 1.850835 history loss 6.426639 rank 6
2022-12-08 05:32:10,630 DEBUG CV Batch 26/1400 loss 2.190869 loss_att 562.090698 loss_ctc 5.251171 loss_rnnt 1.850835 history loss 6.426639 rank 0
2022-12-08 05:32:11,059 DEBUG CV Batch 26/1400 loss 2.190869 loss_att 562.090698 loss_ctc 5.251171 loss_rnnt 1.850835 history loss 6.426639 rank 2
2022-12-08 05:32:11,386 DEBUG CV Batch 26/1400 loss 2.190869 loss_att 562.090698 loss_ctc 5.251171 loss_rnnt 1.850835 history loss 6.426639 rank 5
2022-12-08 05:32:21,821 DEBUG CV Batch 26/1500 loss 7.955647 loss_att 275.490662 loss_ctc 7.671402 loss_rnnt 7.987230 history loss 6.303738 rank 0
2022-12-08 05:32:21,896 DEBUG CV Batch 26/1500 loss 7.955647 loss_att 275.490662 loss_ctc 7.671402 loss_rnnt 7.987230 history loss 6.303738 rank 4
2022-12-08 05:32:22,213 DEBUG CV Batch 26/1500 loss 7.955647 loss_att 275.490662 loss_ctc 7.671402 loss_rnnt 7.987230 history loss 6.303738 rank 7
2022-12-08 05:32:22,353 DEBUG CV Batch 26/1500 loss 7.955647 loss_att 275.490662 loss_ctc 7.671402 loss_rnnt 7.987230 history loss 6.303738 rank 1
2022-12-08 05:32:22,433 DEBUG CV Batch 26/1500 loss 7.955647 loss_att 275.490662 loss_ctc 7.671402 loss_rnnt 7.987230 history loss 6.303738 rank 6
2022-12-08 05:32:23,059 DEBUG CV Batch 26/1500 loss 7.955647 loss_att 275.490662 loss_ctc 7.671402 loss_rnnt 7.987230 history loss 6.303738 rank 3
2022-12-08 05:32:23,271 DEBUG CV Batch 26/1500 loss 7.955647 loss_att 275.490662 loss_ctc 7.671402 loss_rnnt 7.987230 history loss 6.303738 rank 2
2022-12-08 05:32:23,935 DEBUG CV Batch 26/1500 loss 7.955647 loss_att 275.490662 loss_ctc 7.671402 loss_rnnt 7.987230 history loss 6.303738 rank 5
2022-12-08 05:32:35,248 DEBUG CV Batch 26/1600 loss 5.876875 loss_att 593.913330 loss_ctc 10.622871 loss_rnnt 5.349543 history loss 6.260624 rank 4
2022-12-08 05:32:35,284 DEBUG CV Batch 26/1600 loss 5.876875 loss_att 593.913330 loss_ctc 10.622871 loss_rnnt 5.349543 history loss 6.260624 rank 0
2022-12-08 05:32:35,547 DEBUG CV Batch 26/1600 loss 5.876875 loss_att 593.913330 loss_ctc 10.622871 loss_rnnt 5.349543 history loss 6.260624 rank 7
2022-12-08 05:32:35,661 DEBUG CV Batch 26/1600 loss 5.876875 loss_att 593.913330 loss_ctc 10.622871 loss_rnnt 5.349543 history loss 6.260624 rank 1
2022-12-08 05:32:35,881 DEBUG CV Batch 26/1600 loss 5.876875 loss_att 593.913330 loss_ctc 10.622871 loss_rnnt 5.349543 history loss 6.260624 rank 6
2022-12-08 05:32:36,066 DEBUG CV Batch 26/1600 loss 5.876875 loss_att 593.913330 loss_ctc 10.622871 loss_rnnt 5.349543 history loss 6.260624 rank 3
2022-12-08 05:32:36,458 DEBUG CV Batch 26/1600 loss 5.876875 loss_att 593.913330 loss_ctc 10.622871 loss_rnnt 5.349543 history loss 6.260624 rank 2
2022-12-08 05:32:37,195 DEBUG CV Batch 26/1600 loss 5.876875 loss_att 593.913330 loss_ctc 10.622871 loss_rnnt 5.349543 history loss 6.260624 rank 5
2022-12-08 05:32:47,248 DEBUG CV Batch 26/1700 loss 7.660355 loss_att 210.843903 loss_ctc 14.269389 loss_rnnt 6.926017 history loss 6.202115 rank 1
2022-12-08 05:32:47,285 DEBUG CV Batch 26/1700 loss 7.660355 loss_att 210.843903 loss_ctc 14.269389 loss_rnnt 6.926017 history loss 6.202115 rank 4
2022-12-08 05:32:47,609 DEBUG CV Batch 26/1700 loss 7.660355 loss_att 210.843903 loss_ctc 14.269389 loss_rnnt 6.926017 history loss 6.202115 rank 0
2022-12-08 05:32:47,795 DEBUG CV Batch 26/1700 loss 7.660355 loss_att 210.843903 loss_ctc 14.269389 loss_rnnt 6.926017 history loss 6.202115 rank 3
2022-12-08 05:32:47,803 DEBUG CV Batch 26/1700 loss 7.660355 loss_att 210.843903 loss_ctc 14.269389 loss_rnnt 6.926017 history loss 6.202115 rank 6
2022-12-08 05:32:47,819 DEBUG CV Batch 26/1700 loss 7.660355 loss_att 210.843903 loss_ctc 14.269389 loss_rnnt 6.926017 history loss 6.202115 rank 7
2022-12-08 05:32:48,373 DEBUG CV Batch 26/1700 loss 7.660355 loss_att 210.843903 loss_ctc 14.269389 loss_rnnt 6.926017 history loss 6.202115 rank 2
2022-12-08 05:32:49,006 DEBUG CV Batch 26/1700 loss 7.660355 loss_att 210.843903 loss_ctc 14.269389 loss_rnnt 6.926017 history loss 6.202115 rank 5
2022-12-08 05:32:56,045 INFO Epoch 26 CV info cv_loss 6.181514803699752
2022-12-08 05:32:56,045 INFO Epoch 27 TRAIN info lr 0.0002553111418385944
2022-12-08 05:32:56,047 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 05:32:56,140 INFO Epoch 26 CV info cv_loss 6.181514803699752
2022-12-08 05:32:56,140 INFO Epoch 27 TRAIN info lr 0.00025534476561273425
2022-12-08 05:32:56,145 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 05:32:56,606 INFO Epoch 26 CV info cv_loss 6.181514803699752
2022-12-08 05:32:56,606 INFO Checkpoint: save to checkpoint exp/1204_encoder_bias_nobi_noatt/26.pt
2022-12-08 05:32:56,642 INFO Epoch 26 CV info cv_loss 6.181514803699752
2022-12-08 05:32:56,642 INFO Epoch 27 TRAIN info lr 0.00025531380462346466
2022-12-08 05:32:56,646 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 05:32:56,659 INFO Epoch 26 CV info cv_loss 6.181514803699752
2022-12-08 05:32:56,659 INFO Epoch 27 TRAIN info lr 0.0002553261210873277
2022-12-08 05:32:56,664 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 05:32:56,701 INFO Epoch 26 CV info cv_loss 6.181514803699752
2022-12-08 05:32:56,702 INFO Epoch 27 TRAIN info lr 0.0002553058165187868
2022-12-08 05:32:56,703 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 05:32:57,279 INFO Epoch 26 CV info cv_loss 6.181514803699752
2022-12-08 05:32:57,280 INFO Epoch 27 TRAIN info lr 0.0002553341110981078
2022-12-08 05:32:57,284 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 05:32:57,324 INFO Epoch 27 TRAIN info lr 0.00025531413747743154
2022-12-08 05:32:57,328 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 05:32:57,765 INFO Epoch 26 CV info cv_loss 6.181514803699752
2022-12-08 05:32:57,765 INFO Epoch 27 TRAIN info lr 0.0002553184646974714
2022-12-08 05:32:57,767 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 05:33:58,934 DEBUG TRAIN Batch 27/0 loss 10.514455 loss_att 73.624489 loss_ctc 16.847582 loss_rnnt 9.810774 lr 0.00025531 rank 4
2022-12-08 05:33:58,941 DEBUG TRAIN Batch 27/0 loss 7.818154 loss_att 63.738220 loss_ctc 10.193353 loss_rnnt 7.554244 lr 0.00025531 rank 0
2022-12-08 05:33:58,957 DEBUG TRAIN Batch 27/0 loss 10.014635 loss_att 78.377373 loss_ctc 15.667286 loss_rnnt 9.386563 lr 0.00025533 rank 6
2022-12-08 05:33:58,961 DEBUG TRAIN Batch 27/0 loss 6.024664 loss_att 76.448135 loss_ctc 11.399066 loss_rnnt 5.427508 lr 0.00025534 rank 1
2022-12-08 05:33:58,964 DEBUG TRAIN Batch 27/0 loss 9.638383 loss_att 90.890991 loss_ctc 14.407518 loss_rnnt 9.108479 lr 0.00025531 rank 3
2022-12-08 05:33:58,969 DEBUG TRAIN Batch 27/0 loss 12.277155 loss_att 72.133255 loss_ctc 18.197477 loss_rnnt 11.619341 lr 0.00025533 rank 2
2022-12-08 05:33:58,977 DEBUG TRAIN Batch 27/0 loss 7.512398 loss_att 77.548264 loss_ctc 10.563670 loss_rnnt 7.173368 lr 0.00025531 rank 7
2022-12-08 05:33:58,990 DEBUG TRAIN Batch 27/0 loss 4.127835 loss_att 75.963326 loss_ctc 6.970243 loss_rnnt 3.812012 lr 0.00025532 rank 5
2022-12-08 05:35:01,171 DEBUG TRAIN Batch 27/100 loss 2.842300 loss_att 376.452728 loss_ctc 8.565804 loss_rnnt 2.206356 lr 0.00025528 rank 4
2022-12-08 05:35:01,173 DEBUG TRAIN Batch 27/100 loss 8.945030 loss_att 360.902527 loss_ctc 16.954050 loss_rnnt 8.055140 lr 0.00025527 rank 7
2022-12-08 05:35:01,174 DEBUG TRAIN Batch 27/100 loss 8.322630 loss_att 380.821472 loss_ctc 13.933218 loss_rnnt 7.699231 lr 0.00025528 rank 3
2022-12-08 05:35:01,175 DEBUG TRAIN Batch 27/100 loss 1.395116 loss_att 251.922043 loss_ctc 3.482940 loss_rnnt 1.163136 lr 0.00025531 rank 1
2022-12-08 05:35:01,177 DEBUG TRAIN Batch 27/100 loss 9.023284 loss_att 352.526917 loss_ctc 16.642469 loss_rnnt 8.176708 lr 0.00025528 rank 0
2022-12-08 05:35:01,183 DEBUG TRAIN Batch 27/100 loss 9.215260 loss_att 410.814087 loss_ctc 19.653624 loss_rnnt 8.055442 lr 0.00025530 rank 2
2022-12-08 05:35:01,185 DEBUG TRAIN Batch 27/100 loss 3.153991 loss_att 351.701874 loss_ctc 5.676778 loss_rnnt 2.873681 lr 0.00025528 rank 5
2022-12-08 05:35:01,218 DEBUG TRAIN Batch 27/100 loss 4.946445 loss_att 377.266846 loss_ctc 15.665798 loss_rnnt 3.755405 lr 0.00025529 rank 6
2022-12-08 05:36:04,328 DEBUG TRAIN Batch 27/200 loss 8.334469 loss_att 371.958984 loss_ctc 15.720004 loss_rnnt 7.513855 lr 0.00025525 rank 3
2022-12-08 05:36:04,328 DEBUG TRAIN Batch 27/200 loss 8.508711 loss_att 348.689148 loss_ctc 12.320793 loss_rnnt 8.085146 lr 0.00025524 rank 4
2022-12-08 05:36:04,330 DEBUG TRAIN Batch 27/200 loss 6.392657 loss_att 386.135437 loss_ctc 8.446945 loss_rnnt 6.164403 lr 0.00025526 rank 6
2022-12-08 05:36:04,330 DEBUG TRAIN Batch 27/200 loss 3.557337 loss_att 356.739349 loss_ctc 8.862999 loss_rnnt 2.967819 lr 0.00025528 rank 1
2022-12-08 05:36:04,331 DEBUG TRAIN Batch 27/200 loss 5.938438 loss_att 340.141083 loss_ctc 15.787013 loss_rnnt 4.844151 lr 0.00025524 rank 7
2022-12-08 05:36:04,332 DEBUG TRAIN Batch 27/200 loss 7.326957 loss_att 388.499512 loss_ctc 10.089813 loss_rnnt 7.019974 lr 0.00025525 rank 5
2022-12-08 05:36:04,334 DEBUG TRAIN Batch 27/200 loss 11.859228 loss_att 396.598480 loss_ctc 21.159559 loss_rnnt 10.825858 lr 0.00025527 rank 2
2022-12-08 05:36:04,335 DEBUG TRAIN Batch 27/200 loss 4.768504 loss_att 398.549988 loss_ctc 11.909732 loss_rnnt 3.975034 lr 0.00025525 rank 0
2022-12-08 05:37:08,574 DEBUG TRAIN Batch 27/300 loss 9.947379 loss_att 430.284790 loss_ctc 20.102144 loss_rnnt 8.819072 lr 0.00025524 rank 1
2022-12-08 05:37:08,579 DEBUG TRAIN Batch 27/300 loss 6.218761 loss_att 430.549866 loss_ctc 11.515398 loss_rnnt 5.630246 lr 0.00025522 rank 5
2022-12-08 05:37:08,584 DEBUG TRAIN Batch 27/300 loss 2.372296 loss_att 380.059692 loss_ctc 10.099301 loss_rnnt 1.513739 lr 0.00025521 rank 7
2022-12-08 05:37:08,586 DEBUG TRAIN Batch 27/300 loss 8.762517 loss_att 377.101501 loss_ctc 19.979431 loss_rnnt 7.516193 lr 0.00025523 rank 6
2022-12-08 05:37:08,588 DEBUG TRAIN Batch 27/300 loss 3.363764 loss_att 401.989502 loss_ctc 9.664775 loss_rnnt 2.663652 lr 0.00025523 rank 2
2022-12-08 05:37:08,589 DEBUG TRAIN Batch 27/300 loss 13.206624 loss_att 442.754700 loss_ctc 30.079039 loss_rnnt 11.331911 lr 0.00025521 rank 4
2022-12-08 05:37:08,589 DEBUG TRAIN Batch 27/300 loss 6.188243 loss_att 399.517517 loss_ctc 12.057213 loss_rnnt 5.536136 lr 0.00025521 rank 3
2022-12-08 05:37:08,593 DEBUG TRAIN Batch 27/300 loss 6.891422 loss_att 375.586395 loss_ctc 14.174746 loss_rnnt 6.082163 lr 0.00025521 rank 0
2022-12-08 05:38:20,035 DEBUG TRAIN Batch 27/400 loss 6.658705 loss_att 347.467865 loss_ctc 11.418022 loss_rnnt 6.129892 lr 0.00025518 rank 4
2022-12-08 05:38:20,037 DEBUG TRAIN Batch 27/400 loss 7.406979 loss_att 424.878998 loss_ctc 13.991722 loss_rnnt 6.675341 lr 0.00025517 rank 7
2022-12-08 05:38:20,055 DEBUG TRAIN Batch 27/400 loss 4.158101 loss_att 340.068878 loss_ctc 9.353730 loss_rnnt 3.580809 lr 0.00025519 rank 6
2022-12-08 05:38:20,056 DEBUG TRAIN Batch 27/400 loss 8.992498 loss_att 382.108032 loss_ctc 19.865242 loss_rnnt 7.784416 lr 0.00025520 rank 2
2022-12-08 05:38:20,059 DEBUG TRAIN Batch 27/400 loss 9.060924 loss_att 368.994232 loss_ctc 20.164074 loss_rnnt 7.827240 lr 0.00025518 rank 3
2022-12-08 05:38:20,061 DEBUG TRAIN Batch 27/400 loss 16.798840 loss_att 435.866333 loss_ctc 31.214771 loss_rnnt 15.197070 lr 0.00025518 rank 0
2022-12-08 05:38:20,062 DEBUG TRAIN Batch 27/400 loss 5.371566 loss_att 307.048401 loss_ctc 11.784911 loss_rnnt 4.658973 lr 0.00025519 rank 5
2022-12-08 05:38:20,097 DEBUG TRAIN Batch 27/400 loss 15.119233 loss_att 414.393860 loss_ctc 37.317284 loss_rnnt 12.652783 lr 0.00025521 rank 1
2022-12-08 05:39:23,487 DEBUG TRAIN Batch 27/500 loss 9.803758 loss_att 360.795227 loss_ctc 20.257591 loss_rnnt 8.642220 lr 0.00025514 rank 7
2022-12-08 05:39:23,491 DEBUG TRAIN Batch 27/500 loss 4.232050 loss_att 277.237427 loss_ctc 9.017006 loss_rnnt 3.700388 lr 0.00025515 rank 0
2022-12-08 05:39:23,493 DEBUG TRAIN Batch 27/500 loss 7.034575 loss_att 357.625031 loss_ctc 14.389602 loss_rnnt 6.217350 lr 0.00025514 rank 4
2022-12-08 05:39:23,494 DEBUG TRAIN Batch 27/500 loss 15.523470 loss_att 324.753448 loss_ctc 22.642374 loss_rnnt 14.732481 lr 0.00025517 rank 2
2022-12-08 05:39:23,496 DEBUG TRAIN Batch 27/500 loss 6.287485 loss_att 294.198425 loss_ctc 11.548889 loss_rnnt 5.702885 lr 0.00025518 rank 1
2022-12-08 05:39:23,500 DEBUG TRAIN Batch 27/500 loss 11.219648 loss_att 396.147034 loss_ctc 24.315723 loss_rnnt 9.764529 lr 0.00025516 rank 6
2022-12-08 05:39:23,501 DEBUG TRAIN Batch 27/500 loss 2.214227 loss_att 306.664642 loss_ctc 5.602986 loss_rnnt 1.837698 lr 0.00025515 rank 3
2022-12-08 05:39:23,502 DEBUG TRAIN Batch 27/500 loss 10.108097 loss_att 342.415314 loss_ctc 20.229218 loss_rnnt 8.983529 lr 0.00025515 rank 5
2022-12-08 05:40:26,777 DEBUG TRAIN Batch 27/600 loss 6.156745 loss_att 168.938278 loss_ctc 9.060221 loss_rnnt 5.834137 lr 0.00025511 rank 7
2022-12-08 05:40:26,780 DEBUG TRAIN Batch 27/600 loss 7.219088 loss_att 192.935867 loss_ctc 14.201054 loss_rnnt 6.443314 lr 0.00025511 rank 4
2022-12-08 05:40:26,782 DEBUG TRAIN Batch 27/600 loss 8.310414 loss_att 209.088959 loss_ctc 16.888958 loss_rnnt 7.357243 lr 0.00025514 rank 1
2022-12-08 05:40:26,784 DEBUG TRAIN Batch 27/600 loss 11.991245 loss_att 227.061111 loss_ctc 19.358694 loss_rnnt 11.172641 lr 0.00025511 rank 3
2022-12-08 05:40:26,785 DEBUG TRAIN Batch 27/600 loss 7.413706 loss_att 76.301025 loss_ctc 11.802255 loss_rnnt 6.926090 lr 0.00025511 rank 0
2022-12-08 05:40:26,787 DEBUG TRAIN Batch 27/600 loss 8.123714 loss_att 192.437836 loss_ctc 19.123444 loss_rnnt 6.901522 lr 0.00025513 rank 2
2022-12-08 05:40:26,790 DEBUG TRAIN Batch 27/600 loss 12.391402 loss_att 236.814743 loss_ctc 21.000406 loss_rnnt 11.434847 lr 0.00025512 rank 5
2022-12-08 05:40:26,823 DEBUG TRAIN Batch 27/600 loss 9.805192 loss_att 212.056305 loss_ctc 15.774828 loss_rnnt 9.141899 lr 0.00025513 rank 6
2022-12-08 05:41:32,154 DEBUG TRAIN Batch 27/700 loss 17.539207 loss_att 425.866516 loss_ctc 36.530434 loss_rnnt 15.429072 lr 0.00025511 rank 1
2022-12-08 05:41:32,159 DEBUG TRAIN Batch 27/700 loss 7.226780 loss_att 372.333130 loss_ctc 19.552740 loss_rnnt 5.857229 lr 0.00025508 rank 4
2022-12-08 05:41:32,159 DEBUG TRAIN Batch 27/700 loss 0.737891 loss_att 308.380707 loss_ctc 3.569714 loss_rnnt 0.423244 lr 0.00025509 rank 6
2022-12-08 05:41:32,163 DEBUG TRAIN Batch 27/700 loss 9.993622 loss_att 356.138397 loss_ctc 19.872612 loss_rnnt 8.895957 lr 0.00025508 rank 0
2022-12-08 05:41:32,165 DEBUG TRAIN Batch 27/700 loss 3.866118 loss_att 293.472382 loss_ctc 6.678583 loss_rnnt 3.553622 lr 0.00025507 rank 7
2022-12-08 05:41:32,173 DEBUG TRAIN Batch 27/700 loss 8.784872 loss_att 356.833832 loss_ctc 13.539671 loss_rnnt 8.256561 lr 0.00025510 rank 2
2022-12-08 05:41:32,194 DEBUG TRAIN Batch 27/700 loss 7.210400 loss_att 393.359192 loss_ctc 17.865667 loss_rnnt 6.026482 lr 0.00025508 rank 3
2022-12-08 05:41:32,199 DEBUG TRAIN Batch 27/700 loss 5.731533 loss_att 408.194824 loss_ctc 12.699969 loss_rnnt 4.957262 lr 0.00025509 rank 5
2022-12-08 05:42:43,058 DEBUG TRAIN Batch 27/800 loss 4.836260 loss_att 408.549774 loss_ctc 14.298396 loss_rnnt 3.784912 lr 0.00025504 rank 4
2022-12-08 05:42:43,063 DEBUG TRAIN Batch 27/800 loss 0.875382 loss_att 384.438171 loss_ctc 3.305510 loss_rnnt 0.605368 lr 0.00025505 rank 3
2022-12-08 05:42:43,064 DEBUG TRAIN Batch 27/800 loss 4.421290 loss_att 373.473572 loss_ctc 6.681558 loss_rnnt 4.170150 lr 0.00025505 rank 0
2022-12-08 05:42:43,065 DEBUG TRAIN Batch 27/800 loss 6.431345 loss_att 406.700531 loss_ctc 20.662975 loss_rnnt 4.850052 lr 0.00025504 rank 7
2022-12-08 05:42:43,066 DEBUG TRAIN Batch 27/800 loss 7.685030 loss_att 430.936951 loss_ctc 15.500874 loss_rnnt 6.816603 lr 0.00025507 rank 2
2022-12-08 05:42:43,066 DEBUG TRAIN Batch 27/800 loss 4.742095 loss_att 411.105804 loss_ctc 14.522633 loss_rnnt 3.655368 lr 0.00025508 rank 1
2022-12-08 05:42:43,067 DEBUG TRAIN Batch 27/800 loss 4.919239 loss_att 360.133789 loss_ctc 22.619932 loss_rnnt 2.952496 lr 0.00025506 rank 6
2022-12-08 05:42:43,079 DEBUG TRAIN Batch 27/800 loss 5.735121 loss_att 393.458008 loss_ctc 9.353862 loss_rnnt 5.333038 lr 0.00025505 rank 5
2022-12-08 05:43:45,974 DEBUG TRAIN Batch 27/900 loss 8.447070 loss_att 357.945557 loss_ctc 13.530807 loss_rnnt 7.882211 lr 0.00025502 rank 5
2022-12-08 05:43:45,985 DEBUG TRAIN Batch 27/900 loss 6.556221 loss_att 422.011078 loss_ctc 13.170844 loss_rnnt 5.821264 lr 0.00025501 rank 7
2022-12-08 05:43:45,987 DEBUG TRAIN Batch 27/900 loss 1.172913 loss_att 335.045624 loss_ctc 4.628925 loss_rnnt 0.788911 lr 0.00025501 rank 3
2022-12-08 05:43:45,987 DEBUG TRAIN Batch 27/900 loss 7.648288 loss_att 378.006378 loss_ctc 14.356352 loss_rnnt 6.902948 lr 0.00025503 rank 2
2022-12-08 05:43:45,988 DEBUG TRAIN Batch 27/900 loss 6.835455 loss_att 367.787537 loss_ctc 16.026873 loss_rnnt 5.814187 lr 0.00025501 rank 4
2022-12-08 05:43:45,990 DEBUG TRAIN Batch 27/900 loss 17.635706 loss_att 490.614197 loss_ctc 32.411430 loss_rnnt 15.993959 lr 0.00025501 rank 0
2022-12-08 05:43:45,990 DEBUG TRAIN Batch 27/900 loss 2.774073 loss_att 364.049683 loss_ctc 6.758146 loss_rnnt 2.331398 lr 0.00025503 rank 6
2022-12-08 05:43:46,031 DEBUG TRAIN Batch 27/900 loss 10.313526 loss_att 391.885986 loss_ctc 18.113224 loss_rnnt 9.446894 lr 0.00025505 rank 1
2022-12-08 05:44:49,979 DEBUG TRAIN Batch 27/1000 loss 7.561177 loss_att 397.287354 loss_ctc 14.811384 loss_rnnt 6.755599 lr 0.00025501 rank 1
2022-12-08 05:44:49,986 DEBUG TRAIN Batch 27/1000 loss 9.714674 loss_att 351.712952 loss_ctc 16.946766 loss_rnnt 8.911109 lr 0.00025498 rank 4
2022-12-08 05:44:49,988 DEBUG TRAIN Batch 27/1000 loss 9.122299 loss_att 338.549377 loss_ctc 16.388199 loss_rnnt 8.314978 lr 0.00025500 rank 2
2022-12-08 05:44:49,990 DEBUG TRAIN Batch 27/1000 loss 6.769677 loss_att 369.552399 loss_ctc 11.163869 loss_rnnt 6.281434 lr 0.00025499 rank 6
2022-12-08 05:44:49,990 DEBUG TRAIN Batch 27/1000 loss 5.870395 loss_att 334.832794 loss_ctc 14.715616 loss_rnnt 4.887592 lr 0.00025498 rank 3
2022-12-08 05:44:49,993 DEBUG TRAIN Batch 27/1000 loss 12.993345 loss_att 350.159546 loss_ctc 17.467480 loss_rnnt 12.496220 lr 0.00025498 rank 0
2022-12-08 05:44:49,994 DEBUG TRAIN Batch 27/1000 loss 5.321363 loss_att 419.776733 loss_ctc 11.903510 loss_rnnt 4.590014 lr 0.00025499 rank 5
2022-12-08 05:44:50,007 DEBUG TRAIN Batch 27/1000 loss 7.471612 loss_att 399.357330 loss_ctc 14.530651 loss_rnnt 6.687274 lr 0.00025497 rank 7
2022-12-08 05:46:02,068 DEBUG TRAIN Batch 27/1100 loss 9.613479 loss_att 365.401917 loss_ctc 14.041801 loss_rnnt 9.121443 lr 0.00025494 rank 7
2022-12-08 05:46:02,071 DEBUG TRAIN Batch 27/1100 loss 5.315382 loss_att 368.809326 loss_ctc 17.009911 loss_rnnt 4.015990 lr 0.00025496 rank 6
2022-12-08 05:46:02,072 DEBUG TRAIN Batch 27/1100 loss 8.592864 loss_att 350.563965 loss_ctc 24.618544 loss_rnnt 6.812233 lr 0.00025495 rank 3
2022-12-08 05:46:02,072 DEBUG TRAIN Batch 27/1100 loss 2.856690 loss_att 356.272705 loss_ctc 6.806977 loss_rnnt 2.417769 lr 0.00025497 rank 2
2022-12-08 05:46:02,072 DEBUG TRAIN Batch 27/1100 loss 6.096178 loss_att 382.949707 loss_ctc 15.945127 loss_rnnt 5.001850 lr 0.00025495 rank 0
2022-12-08 05:46:02,073 DEBUG TRAIN Batch 27/1100 loss 7.595347 loss_att 389.541199 loss_ctc 11.772264 loss_rnnt 7.131246 lr 0.00025495 rank 4
2022-12-08 05:46:02,076 DEBUG TRAIN Batch 27/1100 loss 3.154611 loss_att 288.026062 loss_ctc 10.040429 loss_rnnt 2.389520 lr 0.00025495 rank 5
2022-12-08 05:46:02,078 DEBUG TRAIN Batch 27/1100 loss 4.381794 loss_att 350.484070 loss_ctc 11.960114 loss_rnnt 3.539758 lr 0.00025498 rank 1
2022-12-08 05:47:05,272 DEBUG TRAIN Batch 27/1200 loss 10.516674 loss_att 338.737640 loss_ctc 16.840748 loss_rnnt 9.814000 lr 0.00025491 rank 4
2022-12-08 05:47:05,284 DEBUG TRAIN Batch 27/1200 loss 9.242691 loss_att 349.153870 loss_ctc 14.056466 loss_rnnt 8.707828 lr 0.00025493 rank 6
2022-12-08 05:47:05,290 DEBUG TRAIN Batch 27/1200 loss 12.218997 loss_att 317.535645 loss_ctc 23.200819 loss_rnnt 10.998795 lr 0.00025492 rank 5
2022-12-08 05:47:05,290 DEBUG TRAIN Batch 27/1200 loss 4.827416 loss_att 183.890549 loss_ctc 9.410368 loss_rnnt 4.318199 lr 0.00025495 rank 1
2022-12-08 05:47:05,292 DEBUG TRAIN Batch 27/1200 loss 10.647920 loss_att 335.763885 loss_ctc 20.150288 loss_rnnt 9.592101 lr 0.00025494 rank 2
2022-12-08 05:47:05,292 DEBUG TRAIN Batch 27/1200 loss 19.341211 loss_att 310.167603 loss_ctc 43.026058 loss_rnnt 16.709562 lr 0.00025491 rank 7
2022-12-08 05:47:05,293 DEBUG TRAIN Batch 27/1200 loss 7.312403 loss_att 243.182861 loss_ctc 11.492294 loss_rnnt 6.847970 lr 0.00025492 rank 0
2022-12-08 05:47:05,293 DEBUG TRAIN Batch 27/1200 loss 3.008695 loss_att 254.266479 loss_ctc 8.888075 loss_rnnt 2.355431 lr 0.00025491 rank 3
2022-12-08 05:48:08,657 DEBUG TRAIN Batch 27/1300 loss 13.783128 loss_att 420.127136 loss_ctc 19.701069 loss_rnnt 13.125579 lr 0.00025488 rank 4
2022-12-08 05:48:08,659 DEBUG TRAIN Batch 27/1300 loss 6.394451 loss_att 365.443787 loss_ctc 13.843224 loss_rnnt 5.566810 lr 0.00025488 rank 3
2022-12-08 05:48:08,660 DEBUG TRAIN Batch 27/1300 loss 9.979754 loss_att 432.941864 loss_ctc 18.511057 loss_rnnt 9.031832 lr 0.00025487 rank 7
2022-12-08 05:48:08,663 DEBUG TRAIN Batch 27/1300 loss 5.918437 loss_att 430.110596 loss_ctc 13.387375 loss_rnnt 5.088555 lr 0.00025488 rank 0
2022-12-08 05:48:08,664 DEBUG TRAIN Batch 27/1300 loss 2.599563 loss_att 381.962463 loss_ctc 7.887744 loss_rnnt 2.011987 lr 0.00025489 rank 5
2022-12-08 05:48:08,667 DEBUG TRAIN Batch 27/1300 loss 12.122144 loss_att 234.309204 loss_ctc 21.578245 loss_rnnt 11.071466 lr 0.00025489 rank 6
2022-12-08 05:48:08,670 DEBUG TRAIN Batch 27/1300 loss 1.910865 loss_att 364.031982 loss_ctc 5.630769 loss_rnnt 1.497542 lr 0.00025491 rank 1
2022-12-08 05:48:08,672 DEBUG TRAIN Batch 27/1300 loss 8.069344 loss_att 391.028198 loss_ctc 16.809830 loss_rnnt 7.098179 lr 0.00025490 rank 2
2022-12-08 05:49:13,676 DEBUG TRAIN Batch 27/1400 loss 3.143681 loss_att 369.786926 loss_ctc 7.800489 loss_rnnt 2.626258 lr 0.00025487 rank 2
2022-12-08 05:49:13,686 DEBUG TRAIN Batch 27/1400 loss 10.637845 loss_att 470.732513 loss_ctc 23.493881 loss_rnnt 9.209397 lr 0.00025485 rank 4
2022-12-08 05:49:13,687 DEBUG TRAIN Batch 27/1400 loss 6.758838 loss_att 402.918152 loss_ctc 9.411577 loss_rnnt 6.464089 lr 0.00025486 rank 6
2022-12-08 05:49:13,688 DEBUG TRAIN Batch 27/1400 loss 0.722849 loss_att 327.260529 loss_ctc 2.768678 loss_rnnt 0.495535 lr 0.00025488 rank 1
2022-12-08 05:49:13,690 DEBUG TRAIN Batch 27/1400 loss 12.385614 loss_att 392.635132 loss_ctc 23.392759 loss_rnnt 11.162598 lr 0.00025485 rank 3
2022-12-08 05:49:13,690 DEBUG TRAIN Batch 27/1400 loss 11.957941 loss_att 328.196350 loss_ctc 19.797264 loss_rnnt 11.086905 lr 0.00025485 rank 5
2022-12-08 05:49:13,691 DEBUG TRAIN Batch 27/1400 loss 8.863010 loss_att 438.654785 loss_ctc 15.970225 loss_rnnt 8.073319 lr 0.00025484 rank 7
2022-12-08 05:49:13,692 DEBUG TRAIN Batch 27/1400 loss 4.352810 loss_att 427.200867 loss_ctc 12.321738 loss_rnnt 3.467373 lr 0.00025485 rank 0
2022-12-08 05:50:24,165 DEBUG TRAIN Batch 27/1500 loss 6.929533 loss_att 402.873291 loss_ctc 11.840282 loss_rnnt 6.383895 lr 0.00025482 rank 5
2022-12-08 05:50:24,171 DEBUG TRAIN Batch 27/1500 loss 6.527842 loss_att 365.131165 loss_ctc 12.455399 loss_rnnt 5.869224 lr 0.00025481 rank 4
2022-12-08 05:50:24,174 DEBUG TRAIN Batch 27/1500 loss 4.799201 loss_att 355.856567 loss_ctc 17.073383 loss_rnnt 3.435403 lr 0.00025484 rank 2
2022-12-08 05:50:24,174 DEBUG TRAIN Batch 27/1500 loss 7.772983 loss_att 412.095276 loss_ctc 15.940444 loss_rnnt 6.865487 lr 0.00025482 rank 3
2022-12-08 05:50:24,177 DEBUG TRAIN Batch 27/1500 loss 2.940912 loss_att 427.042725 loss_ctc 11.687801 loss_rnnt 1.969036 lr 0.00025482 rank 0
2022-12-08 05:50:24,179 DEBUG TRAIN Batch 27/1500 loss 9.081829 loss_att 438.767090 loss_ctc 17.420002 loss_rnnt 8.155366 lr 0.00025485 rank 1
2022-12-08 05:50:24,181 DEBUG TRAIN Batch 27/1500 loss 9.966125 loss_att 402.433044 loss_ctc 18.081800 loss_rnnt 9.064384 lr 0.00025481 rank 7
2022-12-08 05:50:24,217 DEBUG TRAIN Batch 27/1500 loss 6.529015 loss_att 353.110535 loss_ctc 12.263725 loss_rnnt 5.891824 lr 0.00025483 rank 6
2022-12-08 05:51:26,874 DEBUG TRAIN Batch 27/1600 loss 7.233678 loss_att 377.106384 loss_ctc 15.169088 loss_rnnt 6.351966 lr 0.00025477 rank 7
2022-12-08 05:51:26,875 DEBUG TRAIN Batch 27/1600 loss 7.993234 loss_att 397.171326 loss_ctc 15.417421 loss_rnnt 7.168324 lr 0.00025478 rank 4
2022-12-08 05:51:26,877 DEBUG TRAIN Batch 27/1600 loss 6.058977 loss_att 454.660034 loss_ctc 17.149296 loss_rnnt 4.826720 lr 0.00025480 rank 2
2022-12-08 05:51:26,880 DEBUG TRAIN Batch 27/1600 loss 9.054361 loss_att 395.520081 loss_ctc 19.255005 loss_rnnt 7.920956 lr 0.00025479 rank 6
2022-12-08 05:51:26,881 DEBUG TRAIN Batch 27/1600 loss 5.740270 loss_att 384.982391 loss_ctc 12.608739 loss_rnnt 4.977107 lr 0.00025478 rank 0
2022-12-08 05:51:26,882 DEBUG TRAIN Batch 27/1600 loss 3.891853 loss_att 334.101318 loss_ctc 9.123989 loss_rnnt 3.310504 lr 0.00025481 rank 1
2022-12-08 05:51:26,907 DEBUG TRAIN Batch 27/1600 loss 13.634601 loss_att 392.551453 loss_ctc 32.389923 loss_rnnt 11.550675 lr 0.00025479 rank 5
2022-12-08 05:51:26,914 DEBUG TRAIN Batch 27/1600 loss 5.720642 loss_att 339.883728 loss_ctc 9.736950 loss_rnnt 5.274385 lr 0.00025478 rank 3
2022-12-08 05:52:30,545 DEBUG TRAIN Batch 27/1700 loss 9.315399 loss_att 322.674744 loss_ctc 16.167479 loss_rnnt 8.554057 lr 0.00025475 rank 5
2022-12-08 05:52:30,553 DEBUG TRAIN Batch 27/1700 loss 6.455280 loss_att 397.634857 loss_ctc 12.593608 loss_rnnt 5.773244 lr 0.00025475 rank 4
2022-12-08 05:52:30,553 DEBUG TRAIN Batch 27/1700 loss 2.996303 loss_att 274.560760 loss_ctc 4.300249 loss_rnnt 2.851421 lr 0.00025478 rank 1
2022-12-08 05:52:30,556 DEBUG TRAIN Batch 27/1700 loss 4.883891 loss_att 338.253601 loss_ctc 10.406342 loss_rnnt 4.270286 lr 0.00025475 rank 0
2022-12-08 05:52:30,558 DEBUG TRAIN Batch 27/1700 loss 6.146799 loss_att 362.448792 loss_ctc 11.015045 loss_rnnt 5.605883 lr 0.00025475 rank 3
2022-12-08 05:52:30,565 DEBUG TRAIN Batch 27/1700 loss 8.239743 loss_att 365.598816 loss_ctc 17.767982 loss_rnnt 7.181050 lr 0.00025474 rank 7
2022-12-08 05:52:30,585 DEBUG TRAIN Batch 27/1700 loss 10.370199 loss_att 326.055481 loss_ctc 23.110426 loss_rnnt 8.954618 lr 0.00025477 rank 2
2022-12-08 05:52:30,599 DEBUG TRAIN Batch 27/1700 loss 7.454476 loss_att 412.610962 loss_ctc 14.011201 loss_rnnt 6.725951 lr 0.00025476 rank 6
2022-12-08 05:53:42,848 DEBUG TRAIN Batch 27/1800 loss 4.776764 loss_att 268.796600 loss_ctc 9.427470 loss_rnnt 4.260019 lr 0.00025471 rank 7
2022-12-08 05:53:42,848 DEBUG TRAIN Batch 27/1800 loss 7.918940 loss_att 324.209930 loss_ctc 15.632754 loss_rnnt 7.061850 lr 0.00025471 rank 4
2022-12-08 05:53:42,850 DEBUG TRAIN Batch 27/1800 loss 5.519628 loss_att 342.054993 loss_ctc 11.464439 loss_rnnt 4.859093 lr 0.00025475 rank 1
2022-12-08 05:53:42,850 DEBUG TRAIN Batch 27/1800 loss 5.640410 loss_att 388.532990 loss_ctc 14.755650 loss_rnnt 4.627605 lr 0.00025474 rank 2
2022-12-08 05:53:42,852 DEBUG TRAIN Batch 27/1800 loss 6.500552 loss_att 330.468689 loss_ctc 12.555033 loss_rnnt 5.827832 lr 0.00025472 rank 3
2022-12-08 05:53:42,854 DEBUG TRAIN Batch 27/1800 loss 6.465737 loss_att 258.252380 loss_ctc 11.229053 loss_rnnt 5.936480 lr 0.00025472 rank 0
2022-12-08 05:53:42,854 DEBUG TRAIN Batch 27/1800 loss 4.411680 loss_att 326.529175 loss_ctc 8.715663 loss_rnnt 3.933460 lr 0.00025473 rank 6
2022-12-08 05:53:42,859 DEBUG TRAIN Batch 27/1800 loss 6.407430 loss_att 330.893005 loss_ctc 10.426195 loss_rnnt 5.960900 lr 0.00025472 rank 5
2022-12-08 05:54:46,742 DEBUG TRAIN Batch 27/1900 loss 3.929762 loss_att 157.970963 loss_ctc 8.356412 loss_rnnt 3.437912 lr 0.00025471 rank 1
2022-12-08 05:54:46,742 DEBUG TRAIN Batch 27/1900 loss 5.291494 loss_att 222.269073 loss_ctc 10.960788 loss_rnnt 4.661572 lr 0.00025470 rank 2
2022-12-08 05:54:46,743 DEBUG TRAIN Batch 27/1900 loss 6.426126 loss_att 423.409851 loss_ctc 15.011999 loss_rnnt 5.472140 lr 0.00025468 rank 0
2022-12-08 05:54:46,745 DEBUG TRAIN Batch 27/1900 loss 10.165212 loss_att 287.977051 loss_ctc 21.078726 loss_rnnt 8.952599 lr 0.00025470 rank 6
2022-12-08 05:54:46,745 DEBUG TRAIN Batch 27/1900 loss 14.780308 loss_att 501.714691 loss_ctc 32.118214 loss_rnnt 12.853874 lr 0.00025468 rank 7
2022-12-08 05:54:46,749 DEBUG TRAIN Batch 27/1900 loss 8.731905 loss_att 93.920944 loss_ctc 13.534821 loss_rnnt 8.198248 lr 0.00025468 rank 4
2022-12-08 05:54:46,751 DEBUG TRAIN Batch 27/1900 loss 8.454540 loss_att 148.190262 loss_ctc 12.004744 loss_rnnt 8.060073 lr 0.00025469 rank 5
2022-12-08 05:54:46,757 DEBUG TRAIN Batch 27/1900 loss 10.223554 loss_att 199.848206 loss_ctc 17.070435 loss_rnnt 9.462790 lr 0.00025468 rank 3
2022-12-08 05:55:49,216 DEBUG TRAIN Batch 27/2000 loss 6.320797 loss_att 430.573181 loss_ctc 11.841056 loss_rnnt 5.707435 lr 0.00025465 rank 3
2022-12-08 05:55:49,218 DEBUG TRAIN Batch 27/2000 loss 6.421280 loss_att 430.399719 loss_ctc 22.213095 loss_rnnt 4.666634 lr 0.00025466 rank 6
2022-12-08 05:55:49,218 DEBUG TRAIN Batch 27/2000 loss 4.490751 loss_att 355.757263 loss_ctc 8.079365 loss_rnnt 4.092016 lr 0.00025467 rank 2
2022-12-08 05:55:49,219 DEBUG TRAIN Batch 27/2000 loss 7.961823 loss_att 335.910034 loss_ctc 19.240835 loss_rnnt 6.708600 lr 0.00025465 rank 4
2022-12-08 05:55:49,218 DEBUG TRAIN Batch 27/2000 loss 6.626194 loss_att 351.678955 loss_ctc 19.346207 loss_rnnt 5.212859 lr 0.00025464 rank 7
2022-12-08 05:55:49,218 DEBUG TRAIN Batch 27/2000 loss 3.602662 loss_att 367.679932 loss_ctc 10.302403 loss_rnnt 2.858247 lr 0.00025465 rank 0
2022-12-08 05:55:49,248 DEBUG TRAIN Batch 27/2000 loss 1.374707 loss_att 359.022308 loss_ctc 6.566476 loss_rnnt 0.797844 lr 0.00025468 rank 1
2022-12-08 05:55:49,254 DEBUG TRAIN Batch 27/2000 loss 6.980861 loss_att 463.215576 loss_ctc 16.420715 loss_rnnt 5.931988 lr 0.00025465 rank 5
2022-12-08 05:56:53,546 DEBUG TRAIN Batch 27/2100 loss 6.672374 loss_att 409.018127 loss_ctc 12.565033 loss_rnnt 6.017634 lr 0.00025461 rank 4
2022-12-08 05:56:53,546 DEBUG TRAIN Batch 27/2100 loss 11.892379 loss_att 378.074310 loss_ctc 18.531681 loss_rnnt 11.154678 lr 0.00025463 rank 6
2022-12-08 05:56:53,546 DEBUG TRAIN Batch 27/2100 loss 8.936828 loss_att 328.165710 loss_ctc 22.302834 loss_rnnt 7.451716 lr 0.00025464 rank 2
2022-12-08 05:56:53,548 DEBUG TRAIN Batch 27/2100 loss 24.501728 loss_att 406.124847 loss_ctc 31.764997 loss_rnnt 23.694698 lr 0.00025461 rank 7
2022-12-08 05:56:53,548 DEBUG TRAIN Batch 27/2100 loss 7.457458 loss_att 345.453918 loss_ctc 13.271434 loss_rnnt 6.811461 lr 0.00025462 rank 3
2022-12-08 05:56:53,553 DEBUG TRAIN Batch 27/2100 loss 10.911839 loss_att 423.776672 loss_ctc 22.065092 loss_rnnt 9.672589 lr 0.00025462 rank 0
2022-12-08 05:56:53,568 DEBUG TRAIN Batch 27/2100 loss 19.562035 loss_att 417.928314 loss_ctc 27.356176 loss_rnnt 18.696020 lr 0.00025465 rank 1
2022-12-08 05:56:53,575 DEBUG TRAIN Batch 27/2100 loss 2.841899 loss_att 370.667847 loss_ctc 10.028646 loss_rnnt 2.043372 lr 0.00025462 rank 5
2022-12-08 05:58:03,931 DEBUG TRAIN Batch 27/2200 loss 10.031731 loss_att 391.315186 loss_ctc 20.865036 loss_rnnt 8.828030 lr 0.00025458 rank 4
2022-12-08 05:58:03,937 DEBUG TRAIN Batch 27/2200 loss 7.740868 loss_att 349.021423 loss_ctc 21.838446 loss_rnnt 6.174471 lr 0.00025458 rank 0
2022-12-08 05:58:03,938 DEBUG TRAIN Batch 27/2200 loss 1.887258 loss_att 321.777679 loss_ctc 5.910033 loss_rnnt 1.440283 lr 0.00025460 rank 6
2022-12-08 05:58:03,938 DEBUG TRAIN Batch 27/2200 loss 4.042295 loss_att 343.754730 loss_ctc 12.743972 loss_rnnt 3.075442 lr 0.00025458 rank 3
2022-12-08 05:58:03,940 DEBUG TRAIN Batch 27/2200 loss 6.856318 loss_att 420.091644 loss_ctc 19.145926 loss_rnnt 5.490806 lr 0.00025458 rank 7
2022-12-08 05:58:03,943 DEBUG TRAIN Batch 27/2200 loss 7.716678 loss_att 362.947296 loss_ctc 25.532482 loss_rnnt 5.737144 lr 0.00025460 rank 2
2022-12-08 05:58:03,944 DEBUG TRAIN Batch 27/2200 loss 13.709696 loss_att 376.527496 loss_ctc 37.914093 loss_rnnt 11.020318 lr 0.00025462 rank 1
2022-12-08 05:58:03,983 DEBUG TRAIN Batch 27/2200 loss 10.579647 loss_att 333.554810 loss_ctc 21.927670 loss_rnnt 9.318756 lr 0.00025459 rank 5
2022-12-08 05:59:07,013 DEBUG TRAIN Batch 27/2300 loss 8.476673 loss_att 370.941254 loss_ctc 21.369766 loss_rnnt 7.044107 lr 0.00025455 rank 4
2022-12-08 05:59:07,016 DEBUG TRAIN Batch 27/2300 loss 7.428714 loss_att 399.199646 loss_ctc 17.212790 loss_rnnt 6.341594 lr 0.00025456 rank 6
2022-12-08 05:59:07,017 DEBUG TRAIN Batch 27/2300 loss 5.184642 loss_att 360.449188 loss_ctc 9.654789 loss_rnnt 4.687960 lr 0.00025454 rank 7
2022-12-08 05:59:07,019 DEBUG TRAIN Batch 27/2300 loss 7.975727 loss_att 313.813110 loss_ctc 10.604229 loss_rnnt 7.683671 lr 0.00025456 rank 5
2022-12-08 05:59:07,019 DEBUG TRAIN Batch 27/2300 loss 15.150239 loss_att 369.963806 loss_ctc 22.023323 loss_rnnt 14.386563 lr 0.00025455 rank 0
2022-12-08 05:59:07,018 DEBUG TRAIN Batch 27/2300 loss 4.709283 loss_att 367.930786 loss_ctc 11.364197 loss_rnnt 3.969848 lr 0.00025457 rank 2
2022-12-08 05:59:07,020 DEBUG TRAIN Batch 27/2300 loss 21.687479 loss_att 392.294403 loss_ctc 41.088852 loss_rnnt 19.531773 lr 0.00025458 rank 1
2022-12-08 05:59:07,024 DEBUG TRAIN Batch 27/2300 loss 16.868296 loss_att 372.451355 loss_ctc 27.133854 loss_rnnt 15.727678 lr 0.00025455 rank 3
2022-12-08 06:00:11,141 DEBUG TRAIN Batch 27/2400 loss 6.673280 loss_att 329.076263 loss_ctc 11.706059 loss_rnnt 6.114082 lr 0.00025451 rank 7
2022-12-08 06:00:11,141 DEBUG TRAIN Batch 27/2400 loss 4.310306 loss_att 276.113983 loss_ctc 10.830723 loss_rnnt 3.585815 lr 0.00025452 rank 4
2022-12-08 06:00:11,143 DEBUG TRAIN Batch 27/2400 loss 1.924743 loss_att 271.139648 loss_ctc 5.433631 loss_rnnt 1.534867 lr 0.00025455 rank 1
2022-12-08 06:00:11,144 DEBUG TRAIN Batch 27/2400 loss 7.197624 loss_att 293.003967 loss_ctc 9.977414 loss_rnnt 6.888759 lr 0.00025452 rank 3
2022-12-08 06:00:11,145 DEBUG TRAIN Batch 27/2400 loss 7.962240 loss_att 228.176682 loss_ctc 19.982227 loss_rnnt 6.626686 lr 0.00025452 rank 0
2022-12-08 06:00:11,146 DEBUG TRAIN Batch 27/2400 loss 7.818834 loss_att 373.148193 loss_ctc 22.289101 loss_rnnt 6.211027 lr 0.00025454 rank 2
2022-12-08 06:00:11,152 DEBUG TRAIN Batch 27/2400 loss 11.692205 loss_att 395.554718 loss_ctc 20.516220 loss_rnnt 10.711760 lr 0.00025453 rank 6
2022-12-08 06:00:11,152 DEBUG TRAIN Batch 27/2400 loss 8.124079 loss_att 301.403870 loss_ctc 14.120988 loss_rnnt 7.457756 lr 0.00025452 rank 5
2022-12-08 06:01:22,353 DEBUG TRAIN Batch 27/2500 loss 4.972084 loss_att 222.159988 loss_ctc 10.588172 loss_rnnt 4.348074 lr 0.00025448 rank 7
2022-12-08 06:01:22,355 DEBUG TRAIN Batch 27/2500 loss 4.830647 loss_att 285.140717 loss_ctc 12.870334 loss_rnnt 3.937349 lr 0.00025450 rank 6
2022-12-08 06:01:22,357 DEBUG TRAIN Batch 27/2500 loss 13.208334 loss_att 274.783264 loss_ctc 22.286943 loss_rnnt 12.199599 lr 0.00025451 rank 2
2022-12-08 06:01:22,358 DEBUG TRAIN Batch 27/2500 loss 18.477211 loss_att 265.839325 loss_ctc 29.754410 loss_rnnt 17.224190 lr 0.00025452 rank 1
2022-12-08 06:01:22,361 DEBUG TRAIN Batch 27/2500 loss 10.096716 loss_att 122.838943 loss_ctc 16.372082 loss_rnnt 9.399453 lr 0.00025448 rank 4
2022-12-08 06:01:22,371 DEBUG TRAIN Batch 27/2500 loss 5.459301 loss_att 286.761292 loss_ctc 9.993965 loss_rnnt 4.955450 lr 0.00025449 rank 5
2022-12-08 06:01:22,375 DEBUG TRAIN Batch 27/2500 loss 7.338654 loss_att 276.619232 loss_ctc 16.247147 loss_rnnt 6.348821 lr 0.00025449 rank 3
2022-12-08 06:01:22,377 DEBUG TRAIN Batch 27/2500 loss 2.533113 loss_att 398.234619 loss_ctc 8.848618 loss_rnnt 1.831390 lr 0.00025449 rank 0
2022-12-08 06:02:25,905 DEBUG TRAIN Batch 27/2600 loss 3.990894 loss_att 364.951233 loss_ctc 8.532057 loss_rnnt 3.486320 lr 0.00025445 rank 4
2022-12-08 06:02:25,906 DEBUG TRAIN Batch 27/2600 loss 9.682785 loss_att 396.908081 loss_ctc 21.570896 loss_rnnt 8.361883 lr 0.00025444 rank 7
2022-12-08 06:02:25,907 DEBUG TRAIN Batch 27/2600 loss 3.480059 loss_att 198.793030 loss_ctc 8.034803 loss_rnnt 2.973976 lr 0.00025446 rank 6
2022-12-08 06:02:25,908 DEBUG TRAIN Batch 27/2600 loss 2.849944 loss_att 368.497253 loss_ctc 11.103515 loss_rnnt 1.932881 lr 0.00025448 rank 1
2022-12-08 06:02:25,909 DEBUG TRAIN Batch 27/2600 loss 7.773526 loss_att 169.460617 loss_ctc 16.144939 loss_rnnt 6.843369 lr 0.00025445 rank 3
2022-12-08 06:02:25,910 DEBUG TRAIN Batch 27/2600 loss 3.296390 loss_att 374.355713 loss_ctc 10.373996 loss_rnnt 2.509989 lr 0.00025446 rank 5
2022-12-08 06:02:25,911 DEBUG TRAIN Batch 27/2600 loss 4.096890 loss_att 437.867981 loss_ctc 7.665978 loss_rnnt 3.700325 lr 0.00025447 rank 2
2022-12-08 06:02:25,911 DEBUG TRAIN Batch 27/2600 loss 5.497207 loss_att 385.675659 loss_ctc 14.624935 loss_rnnt 4.483016 lr 0.00025445 rank 0
2022-12-08 06:03:28,482 DEBUG TRAIN Batch 27/2700 loss 14.579095 loss_att 461.479340 loss_ctc 30.959007 loss_rnnt 12.759105 lr 0.00025441 rank 7
2022-12-08 06:03:28,488 DEBUG TRAIN Batch 27/2700 loss 6.650608 loss_att 386.442963 loss_ctc 17.005802 loss_rnnt 5.500031 lr 0.00025445 rank 1
2022-12-08 06:03:28,489 DEBUG TRAIN Batch 27/2700 loss 4.422455 loss_att 382.519012 loss_ctc 13.753844 loss_rnnt 3.385634 lr 0.00025442 rank 4
2022-12-08 06:03:28,489 DEBUG TRAIN Batch 27/2700 loss 7.848574 loss_att 397.953735 loss_ctc 13.877855 loss_rnnt 7.178654 lr 0.00025444 rank 2
2022-12-08 06:03:28,490 DEBUG TRAIN Batch 27/2700 loss 2.950768 loss_att 424.511932 loss_ctc 7.403472 loss_rnnt 2.456023 lr 0.00025443 rank 6
2022-12-08 06:03:28,492 DEBUG TRAIN Batch 27/2700 loss 5.662319 loss_att 352.252380 loss_ctc 14.320595 loss_rnnt 4.700288 lr 0.00025442 rank 5
2022-12-08 06:03:28,493 DEBUG TRAIN Batch 27/2700 loss 9.401824 loss_att 426.523285 loss_ctc 15.614878 loss_rnnt 8.711485 lr 0.00025442 rank 3
2022-12-08 06:03:28,496 DEBUG TRAIN Batch 27/2700 loss 5.018225 loss_att 379.271973 loss_ctc 9.902586 loss_rnnt 4.475519 lr 0.00025442 rank 0
2022-12-08 06:04:32,643 DEBUG TRAIN Batch 27/2800 loss 6.044444 loss_att 318.827454 loss_ctc 8.214168 loss_rnnt 5.803364 lr 0.00025442 rank 1
2022-12-08 06:04:32,644 DEBUG TRAIN Batch 27/2800 loss 5.116374 loss_att 401.155609 loss_ctc 10.042135 loss_rnnt 4.569067 lr 0.00025438 rank 7
2022-12-08 06:04:32,645 DEBUG TRAIN Batch 27/2800 loss 3.705853 loss_att 336.975861 loss_ctc 8.727671 loss_rnnt 3.147874 lr 0.00025439 rank 5
2022-12-08 06:04:32,646 DEBUG TRAIN Batch 27/2800 loss 11.531338 loss_att 327.096924 loss_ctc 23.583759 loss_rnnt 10.192180 lr 0.00025438 rank 4
2022-12-08 06:04:32,650 DEBUG TRAIN Batch 27/2800 loss 8.271492 loss_att 446.369385 loss_ctc 18.371367 loss_rnnt 7.149284 lr 0.00025439 rank 3
2022-12-08 06:04:32,650 DEBUG TRAIN Batch 27/2800 loss 10.640145 loss_att 370.468079 loss_ctc 16.392099 loss_rnnt 10.001040 lr 0.00025439 rank 0
2022-12-08 06:04:32,651 DEBUG TRAIN Batch 27/2800 loss 15.324253 loss_att 401.369324 loss_ctc 24.867025 loss_rnnt 14.263945 lr 0.00025440 rank 6
2022-12-08 06:04:32,675 DEBUG TRAIN Batch 27/2800 loss 9.743550 loss_att 328.068420 loss_ctc 14.695631 loss_rnnt 9.193319 lr 0.00025441 rank 2
2022-12-08 06:05:43,344 DEBUG TRAIN Batch 27/2900 loss 7.519612 loss_att 397.350342 loss_ctc 13.486774 loss_rnnt 6.856594 lr 0.00025435 rank 4
2022-12-08 06:05:43,345 DEBUG TRAIN Batch 27/2900 loss 4.139470 loss_att 386.236603 loss_ctc 10.437057 loss_rnnt 3.439738 lr 0.00025435 rank 7
2022-12-08 06:05:43,346 DEBUG TRAIN Batch 27/2900 loss 4.571314 loss_att 361.277832 loss_ctc 11.840959 loss_rnnt 3.763576 lr 0.00025437 rank 2
2022-12-08 06:05:43,352 DEBUG TRAIN Batch 27/2900 loss 8.762421 loss_att 387.260742 loss_ctc 14.781896 loss_rnnt 8.093590 lr 0.00025435 rank 0
2022-12-08 06:05:43,354 DEBUG TRAIN Batch 27/2900 loss 3.857120 loss_att 314.011353 loss_ctc 7.390044 loss_rnnt 3.464573 lr 0.00025437 rank 6
2022-12-08 06:05:43,361 DEBUG TRAIN Batch 27/2900 loss 8.418595 loss_att 344.839081 loss_ctc 14.267056 loss_rnnt 7.768767 lr 0.00025438 rank 1
2022-12-08 06:05:43,371 DEBUG TRAIN Batch 27/2900 loss 7.138407 loss_att 375.937805 loss_ctc 13.987542 loss_rnnt 6.377392 lr 0.00025435 rank 3
2022-12-08 06:05:43,375 DEBUG TRAIN Batch 27/2900 loss 7.536889 loss_att 355.800171 loss_ctc 17.623312 loss_rnnt 6.416176 lr 0.00025436 rank 5
2022-12-08 06:06:47,095 DEBUG TRAIN Batch 27/3000 loss 12.622151 loss_att 342.937622 loss_ctc 19.272753 loss_rnnt 11.883196 lr 0.00025432 rank 4
2022-12-08 06:06:47,098 DEBUG TRAIN Batch 27/3000 loss 10.780457 loss_att 337.454834 loss_ctc 21.126842 loss_rnnt 9.630858 lr 0.00025435 rank 1
2022-12-08 06:06:47,098 DEBUG TRAIN Batch 27/3000 loss 7.375124 loss_att 396.799011 loss_ctc 16.809694 loss_rnnt 6.326839 lr 0.00025434 rank 2
2022-12-08 06:06:47,099 DEBUG TRAIN Batch 27/3000 loss 7.531660 loss_att 313.269531 loss_ctc 12.821619 loss_rnnt 6.943887 lr 0.00025431 rank 7
2022-12-08 06:06:47,101 DEBUG TRAIN Batch 27/3000 loss 9.585998 loss_att 301.204712 loss_ctc 16.993952 loss_rnnt 8.762892 lr 0.00025433 rank 6
2022-12-08 06:06:47,102 DEBUG TRAIN Batch 27/3000 loss 10.167177 loss_att 270.478668 loss_ctc 19.282810 loss_rnnt 9.154329 lr 0.00025432 rank 0
2022-12-08 06:06:47,104 DEBUG TRAIN Batch 27/3000 loss 6.259505 loss_att 355.722046 loss_ctc 11.071700 loss_rnnt 5.724816 lr 0.00025433 rank 5
2022-12-08 06:06:47,139 DEBUG TRAIN Batch 27/3000 loss 9.567627 loss_att 409.518127 loss_ctc 21.371038 loss_rnnt 8.256137 lr 0.00025432 rank 3
2022-12-08 06:07:50,503 DEBUG TRAIN Batch 27/3100 loss 7.313416 loss_att 260.937500 loss_ctc 14.851246 loss_rnnt 6.475880 lr 0.00025429 rank 4
2022-12-08 06:07:50,505 DEBUG TRAIN Batch 27/3100 loss 8.774739 loss_att 344.967041 loss_ctc 18.967957 loss_rnnt 7.642160 lr 0.00025429 rank 3
2022-12-08 06:07:50,505 DEBUG TRAIN Batch 27/3100 loss 8.299656 loss_att 340.673004 loss_ctc 17.399221 loss_rnnt 7.288593 lr 0.00025431 rank 2
2022-12-08 06:07:50,506 DEBUG TRAIN Batch 27/3100 loss 5.336857 loss_att 381.642700 loss_ctc 12.434622 loss_rnnt 4.548216 lr 0.00025430 rank 6
2022-12-08 06:07:50,509 DEBUG TRAIN Batch 27/3100 loss 8.207508 loss_att 337.076202 loss_ctc 20.165379 loss_rnnt 6.878856 lr 0.00025432 rank 1
2022-12-08 06:07:50,511 DEBUG TRAIN Batch 27/3100 loss 7.571707 loss_att 412.527771 loss_ctc 16.473404 loss_rnnt 6.582630 lr 0.00025429 rank 0
2022-12-08 06:07:50,523 DEBUG TRAIN Batch 27/3100 loss 9.380000 loss_att 282.182678 loss_ctc 19.066446 loss_rnnt 8.303728 lr 0.00025428 rank 7
2022-12-08 06:07:50,546 DEBUG TRAIN Batch 27/3100 loss 9.672604 loss_att 356.592957 loss_ctc 23.627228 loss_rnnt 8.122089 lr 0.00025429 rank 5
2022-12-08 06:09:02,574 DEBUG TRAIN Batch 27/3200 loss 6.997088 loss_att 360.833221 loss_ctc 14.189811 loss_rnnt 6.197896 lr 0.00025425 rank 4
2022-12-08 06:09:02,576 DEBUG TRAIN Batch 27/3200 loss 10.238859 loss_att 296.349792 loss_ctc 14.843650 loss_rnnt 9.727216 lr 0.00025425 rank 7
2022-12-08 06:09:02,577 DEBUG TRAIN Batch 27/3200 loss 8.536702 loss_att 120.386047 loss_ctc 16.144142 loss_rnnt 7.691431 lr 0.00025429 rank 1
2022-12-08 06:09:02,577 DEBUG TRAIN Batch 27/3200 loss 8.450452 loss_att 67.168022 loss_ctc 11.308319 loss_rnnt 8.132911 lr 0.00025425 rank 3
2022-12-08 06:09:02,578 DEBUG TRAIN Batch 27/3200 loss 9.342521 loss_att 388.111816 loss_ctc 26.164795 loss_rnnt 7.473379 lr 0.00025426 rank 0
2022-12-08 06:09:02,578 DEBUG TRAIN Batch 27/3200 loss 6.637180 loss_att 321.054840 loss_ctc 13.554962 loss_rnnt 5.868537 lr 0.00025427 rank 6
2022-12-08 06:09:02,580 DEBUG TRAIN Batch 27/3200 loss 9.199935 loss_att 74.125801 loss_ctc 13.805617 loss_rnnt 8.688193 lr 0.00025428 rank 2
2022-12-08 06:09:02,617 DEBUG TRAIN Batch 27/3200 loss 4.529071 loss_att 98.064407 loss_ctc 8.875135 loss_rnnt 4.046175 lr 0.00025426 rank 5
2022-12-08 06:10:06,074 DEBUG TRAIN Batch 27/3300 loss 6.593219 loss_att 381.175262 loss_ctc 14.021698 loss_rnnt 5.767833 lr 0.00025421 rank 7
2022-12-08 06:10:06,084 DEBUG TRAIN Batch 27/3300 loss 3.950287 loss_att 333.150604 loss_ctc 10.258575 loss_rnnt 3.249367 lr 0.00025424 rank 2
2022-12-08 06:10:06,084 DEBUG TRAIN Batch 27/3300 loss 4.098475 loss_att 392.107483 loss_ctc 9.537356 loss_rnnt 3.494154 lr 0.00025422 rank 4
2022-12-08 06:10:06,088 DEBUG TRAIN Batch 27/3300 loss 3.051291 loss_att 398.531921 loss_ctc 11.284174 loss_rnnt 2.136526 lr 0.00025423 rank 6
2022-12-08 06:10:06,092 DEBUG TRAIN Batch 27/3300 loss 11.857398 loss_att 366.674042 loss_ctc 18.293907 loss_rnnt 11.142231 lr 0.00025422 rank 0
2022-12-08 06:10:06,093 DEBUG TRAIN Batch 27/3300 loss 5.492739 loss_att 359.869507 loss_ctc 13.339687 loss_rnnt 4.620856 lr 0.00025425 rank 1
2022-12-08 06:10:06,093 DEBUG TRAIN Batch 27/3300 loss 9.366948 loss_att 461.603455 loss_ctc 19.610647 loss_rnnt 8.228760 lr 0.00025423 rank 5
2022-12-08 06:10:06,125 DEBUG TRAIN Batch 27/3300 loss 5.371821 loss_att 423.542572 loss_ctc 10.702263 loss_rnnt 4.779550 lr 0.00025422 rank 3
2022-12-08 06:11:10,191 DEBUG TRAIN Batch 27/3400 loss 8.751484 loss_att 427.594604 loss_ctc 18.594654 loss_rnnt 7.657798 lr 0.00025419 rank 4
2022-12-08 06:11:10,194 DEBUG TRAIN Batch 27/3400 loss 12.676094 loss_att 375.454681 loss_ctc 22.376554 loss_rnnt 11.598265 lr 0.00025418 rank 7
2022-12-08 06:11:10,194 DEBUG TRAIN Batch 27/3400 loss 7.015331 loss_att 430.521576 loss_ctc 16.531799 loss_rnnt 5.957946 lr 0.00025420 rank 6
2022-12-08 06:11:10,195 DEBUG TRAIN Batch 27/3400 loss 6.856666 loss_att 368.272888 loss_ctc 8.709983 loss_rnnt 6.650742 lr 0.00025422 rank 1
2022-12-08 06:11:10,197 DEBUG TRAIN Batch 27/3400 loss 5.682716 loss_att 427.737183 loss_ctc 15.233852 loss_rnnt 4.621479 lr 0.00025421 rank 2
2022-12-08 06:11:10,199 DEBUG TRAIN Batch 27/3400 loss 7.297510 loss_att 356.772400 loss_ctc 14.113810 loss_rnnt 6.540143 lr 0.00025419 rank 0
2022-12-08 06:11:10,200 DEBUG TRAIN Batch 27/3400 loss 11.126190 loss_att 401.335449 loss_ctc 25.870581 loss_rnnt 9.487925 lr 0.00025419 rank 5
2022-12-08 06:11:10,201 DEBUG TRAIN Batch 27/3400 loss 6.442837 loss_att 395.145020 loss_ctc 9.847242 loss_rnnt 6.064570 lr 0.00025419 rank 3
2022-12-08 06:12:14,608 DEBUG TRAIN Batch 27/3500 loss 8.273610 loss_att 304.708923 loss_ctc 13.500462 loss_rnnt 7.692849 lr 0.00025419 rank 1
2022-12-08 06:12:14,614 DEBUG TRAIN Batch 27/3500 loss 7.284168 loss_att 457.543884 loss_ctc 13.530012 loss_rnnt 6.590186 lr 0.00025416 rank 5
2022-12-08 06:12:14,619 DEBUG TRAIN Batch 27/3500 loss 9.477873 loss_att 386.316620 loss_ctc 16.796280 loss_rnnt 8.664717 lr 0.00025416 rank 0
2022-12-08 06:12:14,623 DEBUG TRAIN Batch 27/3500 loss 5.329865 loss_att 354.057709 loss_ctc 12.480186 loss_rnnt 4.535384 lr 0.00025417 rank 6
2022-12-08 06:12:14,623 DEBUG TRAIN Batch 27/3500 loss 4.478805 loss_att 318.850433 loss_ctc 15.364442 loss_rnnt 3.269290 lr 0.00025415 rank 4
2022-12-08 06:12:14,624 DEBUG TRAIN Batch 27/3500 loss 2.680790 loss_att 313.404816 loss_ctc 8.799519 loss_rnnt 2.000931 lr 0.00025416 rank 3
2022-12-08 06:12:14,624 DEBUG TRAIN Batch 27/3500 loss 3.124393 loss_att 363.944397 loss_ctc 8.907939 loss_rnnt 2.481777 lr 0.00025415 rank 7
2022-12-08 06:12:14,640 DEBUG TRAIN Batch 27/3500 loss 7.464604 loss_att 348.893738 loss_ctc 16.414921 loss_rnnt 6.470125 lr 0.00025418 rank 2
2022-12-08 06:13:26,102 DEBUG TRAIN Batch 27/3600 loss 12.632109 loss_att 351.073792 loss_ctc 20.016068 loss_rnnt 11.811668 lr 0.00025412 rank 4
2022-12-08 06:13:26,104 DEBUG TRAIN Batch 27/3600 loss 7.441921 loss_att 338.791687 loss_ctc 12.937651 loss_rnnt 6.831285 lr 0.00025414 rank 6
2022-12-08 06:13:26,106 DEBUG TRAIN Batch 27/3600 loss 5.916262 loss_att 263.136780 loss_ctc 11.105019 loss_rnnt 5.339734 lr 0.00025412 rank 0
2022-12-08 06:13:26,106 DEBUG TRAIN Batch 27/3600 loss 8.274738 loss_att 361.519653 loss_ctc 14.691753 loss_rnnt 7.561737 lr 0.00025412 rank 7
2022-12-08 06:13:26,109 DEBUG TRAIN Batch 27/3600 loss 14.777522 loss_att 405.109802 loss_ctc 21.740463 loss_rnnt 14.003862 lr 0.00025413 rank 5
2022-12-08 06:13:26,110 DEBUG TRAIN Batch 27/3600 loss 8.522677 loss_att 350.717377 loss_ctc 17.042603 loss_rnnt 7.576020 lr 0.00025415 rank 1
2022-12-08 06:13:26,115 DEBUG TRAIN Batch 27/3600 loss 9.788826 loss_att 369.435059 loss_ctc 15.957541 loss_rnnt 9.103414 lr 0.00025412 rank 3
2022-12-08 06:13:26,152 DEBUG TRAIN Batch 27/3600 loss 11.278971 loss_att 339.315186 loss_ctc 16.316692 loss_rnnt 10.719224 lr 0.00025414 rank 2
2022-12-08 06:14:29,431 DEBUG TRAIN Batch 27/3700 loss 8.906880 loss_att 291.430054 loss_ctc 12.445919 loss_rnnt 8.513654 lr 0.00025409 rank 3
2022-12-08 06:14:29,433 DEBUG TRAIN Batch 27/3700 loss 9.201910 loss_att 338.661621 loss_ctc 14.986686 loss_rnnt 8.559157 lr 0.00025409 rank 4
2022-12-08 06:14:29,437 DEBUG TRAIN Batch 27/3700 loss 3.786022 loss_att 358.613831 loss_ctc 9.605848 loss_rnnt 3.139375 lr 0.00025408 rank 7
2022-12-08 06:14:29,438 DEBUG TRAIN Batch 27/3700 loss 6.734540 loss_att 435.316498 loss_ctc 16.251141 loss_rnnt 5.677140 lr 0.00025409 rank 0
2022-12-08 06:14:29,439 DEBUG TRAIN Batch 27/3700 loss 5.050089 loss_att 330.592041 loss_ctc 9.307987 loss_rnnt 4.576990 lr 0.00025411 rank 2
2022-12-08 06:14:29,440 DEBUG TRAIN Batch 27/3700 loss 4.448226 loss_att 324.732452 loss_ctc 11.146965 loss_rnnt 3.703922 lr 0.00025412 rank 1
2022-12-08 06:14:29,446 DEBUG TRAIN Batch 27/3700 loss 2.280559 loss_att 307.545898 loss_ctc 6.424428 loss_rnnt 1.820129 lr 0.00025410 rank 5
2022-12-08 06:14:29,477 DEBUG TRAIN Batch 27/3700 loss 12.034498 loss_att 358.870209 loss_ctc 22.991079 loss_rnnt 10.817101 lr 0.00025410 rank 6
2022-12-08 06:15:33,557 DEBUG TRAIN Batch 27/3800 loss 8.046614 loss_att 224.360153 loss_ctc 16.818970 loss_rnnt 7.071908 lr 0.00025405 rank 7
2022-12-08 06:15:33,559 DEBUG TRAIN Batch 27/3800 loss 2.890983 loss_att 159.588684 loss_ctc 6.588356 loss_rnnt 2.480164 lr 0.00025406 rank 4
2022-12-08 06:15:33,562 DEBUG TRAIN Batch 27/3800 loss 3.174062 loss_att 276.681488 loss_ctc 7.551618 loss_rnnt 2.687666 lr 0.00025407 rank 6
2022-12-08 06:15:33,563 DEBUG TRAIN Batch 27/3800 loss 8.130071 loss_att 247.646286 loss_ctc 14.611615 loss_rnnt 7.409899 lr 0.00025409 rank 1
2022-12-08 06:15:33,564 DEBUG TRAIN Batch 27/3800 loss 8.473594 loss_att 204.360718 loss_ctc 13.289953 loss_rnnt 7.938442 lr 0.00025408 rank 2
2022-12-08 06:15:33,565 DEBUG TRAIN Batch 27/3800 loss 12.937651 loss_att 248.082642 loss_ctc 21.783241 loss_rnnt 11.954808 lr 0.00025406 rank 3
2022-12-08 06:15:33,568 DEBUG TRAIN Batch 27/3800 loss 11.077711 loss_att 452.526672 loss_ctc 25.845142 loss_rnnt 9.436885 lr 0.00025406 rank 0
2022-12-08 06:15:33,574 DEBUG TRAIN Batch 27/3800 loss 5.776320 loss_att 212.165009 loss_ctc 9.715771 loss_rnnt 5.338604 lr 0.00025406 rank 5
2022-12-08 06:16:38,919 DEBUG TRAIN Batch 27/3900 loss 5.983934 loss_att 432.868408 loss_ctc 11.443713 loss_rnnt 5.377292 lr 0.00025403 rank 0
2022-12-08 06:16:38,920 DEBUG TRAIN Batch 27/3900 loss 6.661196 loss_att 439.145477 loss_ctc 20.953094 loss_rnnt 5.073207 lr 0.00025406 rank 1
2022-12-08 06:16:38,920 DEBUG TRAIN Batch 27/3900 loss 3.596860 loss_att 422.516083 loss_ctc 11.820368 loss_rnnt 2.683137 lr 0.00025402 rank 7
2022-12-08 06:16:38,921 DEBUG TRAIN Batch 27/3900 loss 7.434134 loss_att 355.110474 loss_ctc 21.377468 loss_rnnt 5.884874 lr 0.00025405 rank 2
2022-12-08 06:16:38,924 DEBUG TRAIN Batch 27/3900 loss 7.070035 loss_att 383.489990 loss_ctc 12.446696 loss_rnnt 6.472629 lr 0.00025402 rank 4
2022-12-08 06:16:38,924 DEBUG TRAIN Batch 27/3900 loss 5.004070 loss_att 326.593872 loss_ctc 11.223545 loss_rnnt 4.313018 lr 0.00025403 rank 3
2022-12-08 06:16:38,927 DEBUG TRAIN Batch 27/3900 loss 7.510708 loss_att 355.874725 loss_ctc 13.677315 loss_rnnt 6.825530 lr 0.00025404 rank 6
2022-12-08 06:16:38,970 DEBUG TRAIN Batch 27/3900 loss 5.575062 loss_att 368.160614 loss_ctc 17.237173 loss_rnnt 4.279272 lr 0.00025403 rank 5
2022-12-08 06:17:49,340 DEBUG TRAIN Batch 27/4000 loss 3.737835 loss_att 396.298767 loss_ctc 9.888733 loss_rnnt 3.054402 lr 0.00025398 rank 7
2022-12-08 06:17:49,343 DEBUG TRAIN Batch 27/4000 loss 12.616129 loss_att 374.553925 loss_ctc 24.193052 loss_rnnt 11.329803 lr 0.00025402 rank 1
2022-12-08 06:17:49,351 DEBUG TRAIN Batch 27/4000 loss 8.475286 loss_att 353.184509 loss_ctc 20.903618 loss_rnnt 7.094360 lr 0.00025399 rank 4
2022-12-08 06:17:49,353 DEBUG TRAIN Batch 27/4000 loss 7.648863 loss_att 364.563171 loss_ctc 19.992743 loss_rnnt 6.277321 lr 0.00025401 rank 2
2022-12-08 06:17:49,358 DEBUG TRAIN Batch 27/4000 loss 4.126511 loss_att 357.429016 loss_ctc 11.665823 loss_rnnt 3.288809 lr 0.00025400 rank 5
2022-12-08 06:17:49,360 DEBUG TRAIN Batch 27/4000 loss 6.093509 loss_att 372.289368 loss_ctc 16.139986 loss_rnnt 4.977234 lr 0.00025399 rank 0
2022-12-08 06:17:49,361 DEBUG TRAIN Batch 27/4000 loss 8.395152 loss_att 408.036102 loss_ctc 19.417223 loss_rnnt 7.170478 lr 0.00025400 rank 6
2022-12-08 06:17:49,395 DEBUG TRAIN Batch 27/4000 loss 4.412480 loss_att 329.486328 loss_ctc 14.860264 loss_rnnt 3.251616 lr 0.00025399 rank 3
2022-12-08 06:18:52,899 DEBUG TRAIN Batch 27/4100 loss 6.776502 loss_att 307.044556 loss_ctc 14.436297 loss_rnnt 5.925414 lr 0.00025396 rank 0
2022-12-08 06:18:52,906 DEBUG TRAIN Batch 27/4100 loss 7.509541 loss_att 401.128113 loss_ctc 23.747541 loss_rnnt 5.705318 lr 0.00025397 rank 6
2022-12-08 06:18:52,907 DEBUG TRAIN Batch 27/4100 loss 7.927272 loss_att 366.840240 loss_ctc 15.554720 loss_rnnt 7.079779 lr 0.00025396 rank 4
2022-12-08 06:18:52,908 DEBUG TRAIN Batch 27/4100 loss 3.111072 loss_att 360.232513 loss_ctc 5.599645 loss_rnnt 2.834564 lr 0.00025395 rank 7
2022-12-08 06:18:52,910 DEBUG TRAIN Batch 27/4100 loss 12.201057 loss_att 410.891052 loss_ctc 17.809320 loss_rnnt 11.577917 lr 0.00025396 rank 3
2022-12-08 06:18:52,913 DEBUG TRAIN Batch 27/4100 loss 4.074886 loss_att 339.200073 loss_ctc 10.508574 loss_rnnt 3.360032 lr 0.00025396 rank 5
2022-12-08 06:18:52,927 DEBUG TRAIN Batch 27/4100 loss 7.100034 loss_att 341.176849 loss_ctc 18.687630 loss_rnnt 5.812523 lr 0.00025399 rank 1
2022-12-08 06:18:52,975 DEBUG TRAIN Batch 27/4100 loss 2.149497 loss_att 349.869995 loss_ctc 4.836475 loss_rnnt 1.850943 lr 0.00025398 rank 2
2022-12-08 06:19:56,845 DEBUG TRAIN Batch 27/4200 loss 10.840361 loss_att 353.931335 loss_ctc 18.264759 loss_rnnt 10.015428 lr 0.00025392 rank 4
2022-12-08 06:19:56,846 DEBUG TRAIN Batch 27/4200 loss 8.172041 loss_att 273.700684 loss_ctc 13.623800 loss_rnnt 7.566291 lr 0.00025395 rank 2
2022-12-08 06:19:56,847 DEBUG TRAIN Batch 27/4200 loss 9.909373 loss_att 398.339966 loss_ctc 25.407345 loss_rnnt 8.187377 lr 0.00025392 rank 7
2022-12-08 06:19:56,849 DEBUG TRAIN Batch 27/4200 loss 4.999198 loss_att 373.588440 loss_ctc 12.774136 loss_rnnt 4.135316 lr 0.00025393 rank 3
2022-12-08 06:19:56,852 DEBUG TRAIN Batch 27/4200 loss 7.248902 loss_att 357.429321 loss_ctc 12.228158 loss_rnnt 6.695651 lr 0.00025393 rank 0
2022-12-08 06:19:56,853 DEBUG TRAIN Batch 27/4200 loss 6.039169 loss_att 330.537933 loss_ctc 16.026329 loss_rnnt 4.929484 lr 0.00025396 rank 1
2022-12-08 06:19:56,853 DEBUG TRAIN Batch 27/4200 loss 6.742524 loss_att 318.179932 loss_ctc 21.332769 loss_rnnt 5.121386 lr 0.00025393 rank 5
2022-12-08 06:19:56,879 DEBUG TRAIN Batch 27/4200 loss 5.472345 loss_att 379.789001 loss_ctc 12.793316 loss_rnnt 4.658904 lr 0.00025394 rank 6
2022-12-08 06:21:08,499 DEBUG TRAIN Batch 27/4300 loss 6.630102 loss_att 327.109222 loss_ctc 12.899073 loss_rnnt 5.933550 lr 0.00025389 rank 4
2022-12-08 06:21:08,509 DEBUG TRAIN Batch 27/4300 loss 5.088896 loss_att 348.609070 loss_ctc 11.403412 loss_rnnt 4.387283 lr 0.00025389 rank 7
2022-12-08 06:21:08,513 DEBUG TRAIN Batch 27/4300 loss 10.060861 loss_att 357.915375 loss_ctc 23.225033 loss_rnnt 8.598175 lr 0.00025391 rank 2
2022-12-08 06:21:08,513 DEBUG TRAIN Batch 27/4300 loss 2.733720 loss_att 334.840942 loss_ctc 8.669470 loss_rnnt 2.074192 lr 0.00025392 rank 1
2022-12-08 06:21:08,514 DEBUG TRAIN Batch 27/4300 loss 3.089147 loss_att 334.550354 loss_ctc 6.346677 loss_rnnt 2.727199 lr 0.00025390 rank 5
2022-12-08 06:21:08,519 DEBUG TRAIN Batch 27/4300 loss 15.626726 loss_att 432.239258 loss_ctc 26.399950 loss_rnnt 14.429701 lr 0.00025391 rank 6
2022-12-08 06:21:08,524 DEBUG TRAIN Batch 27/4300 loss 5.023489 loss_att 160.947937 loss_ctc 8.230762 loss_rnnt 4.667126 lr 0.00025389 rank 0
2022-12-08 06:21:08,548 DEBUG TRAIN Batch 27/4300 loss 5.452015 loss_att 369.537903 loss_ctc 8.204057 loss_rnnt 5.146233 lr 0.00025389 rank 3
2022-12-08 06:22:12,643 DEBUG TRAIN Batch 27/4400 loss 12.515391 loss_att 301.375336 loss_ctc 19.485006 loss_rnnt 11.740990 lr 0.00025387 rank 6
2022-12-08 06:22:12,647 DEBUG TRAIN Batch 27/4400 loss 7.431394 loss_att 220.560379 loss_ctc 13.748492 loss_rnnt 6.729494 lr 0.00025388 rank 2
2022-12-08 06:22:12,648 DEBUG TRAIN Batch 27/4400 loss 10.567760 loss_att 303.457733 loss_ctc 16.000851 loss_rnnt 9.964084 lr 0.00025389 rank 1
2022-12-08 06:22:12,648 DEBUG TRAIN Batch 27/4400 loss 9.923869 loss_att 246.955566 loss_ctc 14.515601 loss_rnnt 9.413677 lr 0.00025386 rank 3
2022-12-08 06:22:12,652 DEBUG TRAIN Batch 27/4400 loss 14.163717 loss_att 354.847626 loss_ctc 32.531685 loss_rnnt 12.122832 lr 0.00025385 rank 7
2022-12-08 06:22:12,652 DEBUG TRAIN Batch 27/4400 loss 5.003420 loss_att 167.854889 loss_ctc 9.495991 loss_rnnt 4.504246 lr 0.00025386 rank 4
2022-12-08 06:22:12,655 DEBUG TRAIN Batch 27/4400 loss 8.469198 loss_att 382.310028 loss_ctc 15.803744 loss_rnnt 7.654249 lr 0.00025386 rank 0
2022-12-08 06:22:12,691 DEBUG TRAIN Batch 27/4400 loss 6.528822 loss_att 301.893188 loss_ctc 11.861382 loss_rnnt 5.936316 lr 0.00025387 rank 5
2022-12-08 06:23:16,187 DEBUG TRAIN Batch 27/4500 loss 3.818569 loss_att 180.992157 loss_ctc 9.344467 loss_rnnt 3.204580 lr 0.00025384 rank 6
2022-12-08 06:23:16,188 DEBUG TRAIN Batch 27/4500 loss 5.675592 loss_att 400.325928 loss_ctc 15.275528 loss_rnnt 4.608932 lr 0.00025383 rank 4
2022-12-08 06:23:16,189 DEBUG TRAIN Batch 27/4500 loss 8.855930 loss_att 130.250885 loss_ctc 15.301657 loss_rnnt 8.139739 lr 0.00025382 rank 7
2022-12-08 06:23:16,196 DEBUG TRAIN Batch 27/4500 loss 10.072741 loss_att 423.454071 loss_ctc 25.677303 loss_rnnt 8.338900 lr 0.00025386 rank 1
2022-12-08 06:23:16,196 DEBUG TRAIN Batch 27/4500 loss 8.091722 loss_att 362.436127 loss_ctc 22.527851 loss_rnnt 6.487708 lr 0.00025383 rank 0
2022-12-08 06:23:16,201 DEBUG TRAIN Batch 27/4500 loss 1.215046 loss_att 397.988129 loss_ctc 4.676798 loss_rnnt 0.830407 lr 0.00025383 rank 3
2022-12-08 06:23:16,202 DEBUG TRAIN Batch 27/4500 loss 10.844446 loss_att 369.371338 loss_ctc 23.144140 loss_rnnt 9.477814 lr 0.00025385 rank 2
2022-12-08 06:23:16,233 DEBUG TRAIN Batch 27/4500 loss 6.614578 loss_att 168.206573 loss_ctc 13.053820 loss_rnnt 5.899107 lr 0.00025383 rank 5
2022-12-08 06:24:21,430 DEBUG TRAIN Batch 27/4600 loss 5.299537 loss_att 366.148529 loss_ctc 8.730597 loss_rnnt 4.918308 lr 0.00025381 rank 6
2022-12-08 06:24:21,438 DEBUG TRAIN Batch 27/4600 loss 6.215497 loss_att 369.698822 loss_ctc 14.075480 loss_rnnt 5.342166 lr 0.00025379 rank 4
2022-12-08 06:24:21,438 DEBUG TRAIN Batch 27/4600 loss 5.454011 loss_att 344.082031 loss_ctc 12.894241 loss_rnnt 4.627318 lr 0.00025379 rank 7
2022-12-08 06:24:21,439 DEBUG TRAIN Batch 27/4600 loss 7.139104 loss_att 373.808105 loss_ctc 15.617366 loss_rnnt 6.197075 lr 0.00025382 rank 2
2022-12-08 06:24:21,439 DEBUG TRAIN Batch 27/4600 loss 12.865078 loss_att 479.962982 loss_ctc 26.377623 loss_rnnt 11.363685 lr 0.00025380 rank 3
2022-12-08 06:24:21,443 DEBUG TRAIN Batch 27/4600 loss 3.250382 loss_att 377.751312 loss_ctc 8.759306 loss_rnnt 2.638279 lr 0.00025383 rank 1
2022-12-08 06:24:21,444 DEBUG TRAIN Batch 27/4600 loss 1.020468 loss_att 361.778412 loss_ctc 4.843177 loss_rnnt 0.595723 lr 0.00025380 rank 5
2022-12-08 06:24:21,446 DEBUG TRAIN Batch 27/4600 loss 5.324670 loss_att 413.263123 loss_ctc 16.665541 loss_rnnt 4.064574 lr 0.00025380 rank 0
2022-12-08 06:25:32,858 DEBUG TRAIN Batch 27/4700 loss 8.697258 loss_att 403.984131 loss_ctc 18.839300 loss_rnnt 7.570365 lr 0.00025376 rank 7
2022-12-08 06:25:32,860 DEBUG TRAIN Batch 27/4700 loss 8.564608 loss_att 408.315277 loss_ctc 15.055948 loss_rnnt 7.843348 lr 0.00025378 rank 6
2022-12-08 06:25:32,862 DEBUG TRAIN Batch 27/4700 loss 3.309590 loss_att 280.469116 loss_ctc 5.245018 loss_rnnt 3.094543 lr 0.00025376 rank 0
2022-12-08 06:25:32,863 DEBUG TRAIN Batch 27/4700 loss 12.303614 loss_att 455.492676 loss_ctc 26.353268 loss_rnnt 10.742541 lr 0.00025376 rank 4
2022-12-08 06:25:32,863 DEBUG TRAIN Batch 27/4700 loss 4.999330 loss_att 322.900635 loss_ctc 10.052400 loss_rnnt 4.437878 lr 0.00025379 rank 1
2022-12-08 06:25:32,869 DEBUG TRAIN Batch 27/4700 loss 7.262138 loss_att 333.562042 loss_ctc 13.097844 loss_rnnt 6.613727 lr 0.00025378 rank 2
2022-12-08 06:25:32,871 DEBUG TRAIN Batch 27/4700 loss 5.469193 loss_att 371.999481 loss_ctc 11.716955 loss_rnnt 4.774997 lr 0.00025377 rank 5
2022-12-08 06:25:32,872 DEBUG TRAIN Batch 27/4700 loss 6.241668 loss_att 321.858398 loss_ctc 11.784719 loss_rnnt 5.625774 lr 0.00025376 rank 3
2022-12-08 06:26:36,285 DEBUG TRAIN Batch 27/4800 loss 9.389898 loss_att 399.825653 loss_ctc 20.620197 loss_rnnt 8.142088 lr 0.00025372 rank 7
2022-12-08 06:26:36,297 DEBUG TRAIN Batch 27/4800 loss 5.601053 loss_att 391.891296 loss_ctc 14.158851 loss_rnnt 4.650187 lr 0.00025373 rank 4
2022-12-08 06:26:36,302 DEBUG TRAIN Batch 27/4800 loss 3.535183 loss_att 281.680908 loss_ctc 8.004818 loss_rnnt 3.038557 lr 0.00025373 rank 0
2022-12-08 06:26:36,302 DEBUG TRAIN Batch 27/4800 loss 12.287333 loss_att 344.917816 loss_ctc 20.830444 loss_rnnt 11.338099 lr 0.00025375 rank 2
2022-12-08 06:26:36,304 DEBUG TRAIN Batch 27/4800 loss 2.499599 loss_att 410.086731 loss_ctc 7.633492 loss_rnnt 1.929166 lr 0.00025373 rank 3
2022-12-08 06:26:36,305 DEBUG TRAIN Batch 27/4800 loss 11.884054 loss_att 383.558960 loss_ctc 22.252007 loss_rnnt 10.732059 lr 0.00025374 rank 6
2022-12-08 06:26:36,309 DEBUG TRAIN Batch 27/4800 loss 2.985982 loss_att 410.768555 loss_ctc 5.859107 loss_rnnt 2.666746 lr 0.00025374 rank 5
2022-12-08 06:26:36,344 DEBUG TRAIN Batch 27/4800 loss 7.149134 loss_att 396.283875 loss_ctc 14.955467 loss_rnnt 6.281764 lr 0.00025376 rank 1
2022-12-08 06:27:40,354 DEBUG TRAIN Batch 27/4900 loss 6.525943 loss_att 368.979187 loss_ctc 15.081917 loss_rnnt 5.575280 lr 0.00025373 rank 1
2022-12-08 06:27:40,361 DEBUG TRAIN Batch 27/4900 loss 6.405661 loss_att 294.604309 loss_ctc 8.731986 loss_rnnt 6.147180 lr 0.00025370 rank 4
2022-12-08 06:27:40,362 DEBUG TRAIN Batch 27/4900 loss 3.515782 loss_att 351.843658 loss_ctc 7.246232 loss_rnnt 3.101288 lr 0.00025369 rank 7
2022-12-08 06:27:40,363 DEBUG TRAIN Batch 27/4900 loss 6.208097 loss_att 393.938660 loss_ctc 13.584127 loss_rnnt 5.388538 lr 0.00025371 rank 6
2022-12-08 06:27:40,364 DEBUG TRAIN Batch 27/4900 loss 4.738343 loss_att 372.352905 loss_ctc 11.898581 loss_rnnt 3.942761 lr 0.00025370 rank 3
2022-12-08 06:27:40,367 DEBUG TRAIN Batch 27/4900 loss 9.778132 loss_att 394.853363 loss_ctc 18.823566 loss_rnnt 8.773085 lr 0.00025372 rank 2
2022-12-08 06:27:40,370 DEBUG TRAIN Batch 27/4900 loss 8.403463 loss_att 167.006073 loss_ctc 14.069314 loss_rnnt 7.773924 lr 0.00025370 rank 0
2022-12-08 06:27:40,405 DEBUG TRAIN Batch 27/4900 loss 2.677853 loss_att 385.367920 loss_ctc 7.265461 loss_rnnt 2.168119 lr 0.00025370 rank 5
2022-12-08 06:28:53,337 DEBUG TRAIN Batch 27/5000 loss 10.482486 loss_att 313.012299 loss_ctc 18.032825 loss_rnnt 9.643559 lr 0.00025366 rank 4
2022-12-08 06:28:53,346 DEBUG TRAIN Batch 27/5000 loss 8.624095 loss_att 327.341766 loss_ctc 19.336334 loss_rnnt 7.433846 lr 0.00025368 rank 6
2022-12-08 06:28:53,348 DEBUG TRAIN Batch 27/5000 loss 5.704389 loss_att 304.731689 loss_ctc 10.838846 loss_rnnt 5.133894 lr 0.00025366 rank 7
2022-12-08 06:28:53,348 DEBUG TRAIN Batch 27/5000 loss 4.828923 loss_att 294.424072 loss_ctc 11.800994 loss_rnnt 4.054249 lr 0.00025367 rank 3
2022-12-08 06:28:53,350 DEBUG TRAIN Batch 27/5000 loss 8.179655 loss_att 344.390137 loss_ctc 23.076023 loss_rnnt 6.524503 lr 0.00025367 rank 5
2022-12-08 06:28:53,353 DEBUG TRAIN Batch 27/5000 loss 7.602035 loss_att 226.429688 loss_ctc 13.044851 loss_rnnt 6.997278 lr 0.00025369 rank 2
2022-12-08 06:28:53,354 DEBUG TRAIN Batch 27/5000 loss 7.534478 loss_att 253.038940 loss_ctc 17.135971 loss_rnnt 6.467645 lr 0.00025370 rank 1
2022-12-08 06:28:53,355 DEBUG TRAIN Batch 27/5000 loss 10.116493 loss_att 321.589294 loss_ctc 16.330708 loss_rnnt 9.426025 lr 0.00025367 rank 0
2022-12-08 06:29:56,545 DEBUG TRAIN Batch 27/5100 loss 3.847158 loss_att 427.113251 loss_ctc 9.227478 loss_rnnt 3.249345 lr 0.00025363 rank 4
2022-12-08 06:29:56,547 DEBUG TRAIN Batch 27/5100 loss 10.274574 loss_att 183.904236 loss_ctc 17.233381 loss_rnnt 9.501373 lr 0.00025362 rank 7
2022-12-08 06:29:56,549 DEBUG TRAIN Batch 27/5100 loss 2.948746 loss_att 210.361420 loss_ctc 9.552900 loss_rnnt 2.214951 lr 0.00025363 rank 3
2022-12-08 06:29:56,550 DEBUG TRAIN Batch 27/5100 loss 6.439545 loss_att 415.685974 loss_ctc 14.904097 loss_rnnt 5.499039 lr 0.00025365 rank 2
2022-12-08 06:29:56,551 DEBUG TRAIN Batch 27/5100 loss 5.325752 loss_att 296.988647 loss_ctc 11.977221 loss_rnnt 4.586700 lr 0.00025364 rank 5
2022-12-08 06:29:56,551 DEBUG TRAIN Batch 27/5100 loss 10.091881 loss_att 308.036713 loss_ctc 22.023432 loss_rnnt 8.766153 lr 0.00025364 rank 6
2022-12-08 06:29:56,552 DEBUG TRAIN Batch 27/5100 loss 8.071873 loss_att 433.137543 loss_ctc 17.735241 loss_rnnt 6.998165 lr 0.00025366 rank 1
2022-12-08 06:29:56,552 DEBUG TRAIN Batch 27/5100 loss 8.920461 loss_att 406.934326 loss_ctc 22.949125 loss_rnnt 7.361720 lr 0.00025363 rank 0
2022-12-08 06:30:59,692 DEBUG TRAIN Batch 27/5200 loss 9.171721 loss_att 169.624390 loss_ctc 14.697216 loss_rnnt 8.557778 lr 0.00025361 rank 6
2022-12-08 06:30:59,693 DEBUG TRAIN Batch 27/5200 loss 15.780745 loss_att 354.715393 loss_ctc 29.510283 loss_rnnt 14.255240 lr 0.00025359 rank 7
2022-12-08 06:30:59,693 DEBUG TRAIN Batch 27/5200 loss 12.232182 loss_att 443.897797 loss_ctc 16.579319 loss_rnnt 11.749166 lr 0.00025362 rank 2
2022-12-08 06:30:59,694 DEBUG TRAIN Batch 27/5200 loss 2.812099 loss_att 360.264587 loss_ctc 9.253556 loss_rnnt 2.096382 lr 0.00025360 rank 4
2022-12-08 06:30:59,696 DEBUG TRAIN Batch 27/5200 loss 12.149405 loss_att 367.560486 loss_ctc 18.801960 loss_rnnt 11.410233 lr 0.00025360 rank 3
2022-12-08 06:30:59,697 DEBUG TRAIN Batch 27/5200 loss 15.396382 loss_att 346.599304 loss_ctc 42.764843 loss_rnnt 12.355442 lr 0.00025360 rank 5
2022-12-08 06:30:59,698 DEBUG TRAIN Batch 27/5200 loss 7.253227 loss_att 353.964233 loss_ctc 21.041046 loss_rnnt 5.721248 lr 0.00025360 rank 0
2022-12-08 06:30:59,705 DEBUG TRAIN Batch 27/5200 loss 3.800824 loss_att 323.240967 loss_ctc 12.476532 loss_rnnt 2.836856 lr 0.00025363 rank 1
2022-12-08 06:32:03,995 DEBUG TRAIN Batch 27/5300 loss 8.729372 loss_att 311.070190 loss_ctc 12.306747 loss_rnnt 8.331885 lr 0.00025356 rank 4
2022-12-08 06:32:03,999 DEBUG TRAIN Batch 27/5300 loss 4.654461 loss_att 317.681885 loss_ctc 12.064719 loss_rnnt 3.831099 lr 0.00025359 rank 2
2022-12-08 06:32:03,999 DEBUG TRAIN Batch 27/5300 loss 4.120784 loss_att 378.117859 loss_ctc 9.655325 loss_rnnt 3.505836 lr 0.00025360 rank 1
2022-12-08 06:32:04,000 DEBUG TRAIN Batch 27/5300 loss 4.295823 loss_att 406.509705 loss_ctc 10.799472 loss_rnnt 3.573195 lr 0.00025356 rank 7
2022-12-08 06:32:04,000 DEBUG TRAIN Batch 27/5300 loss 6.032026 loss_att 365.192383 loss_ctc 8.570292 loss_rnnt 5.749996 lr 0.00025358 rank 6
2022-12-08 06:32:04,002 DEBUG TRAIN Batch 27/5300 loss 1.761552 loss_att 367.944336 loss_ctc 5.278833 loss_rnnt 1.370743 lr 0.00025357 rank 0
2022-12-08 06:32:04,003 DEBUG TRAIN Batch 27/5300 loss 11.521490 loss_att 314.871826 loss_ctc 16.235130 loss_rnnt 10.997752 lr 0.00025357 rank 5
2022-12-08 06:32:04,008 DEBUG TRAIN Batch 27/5300 loss 3.082937 loss_att 354.749451 loss_ctc 7.377012 loss_rnnt 2.605818 lr 0.00025357 rank 3
2022-12-08 06:33:14,175 DEBUG TRAIN Batch 27/5400 loss 11.177891 loss_att 422.457001 loss_ctc 20.257198 loss_rnnt 10.169079 lr 0.00025353 rank 7
2022-12-08 06:33:14,178 DEBUG TRAIN Batch 27/5400 loss 9.215036 loss_att 387.131317 loss_ctc 23.450180 loss_rnnt 7.633354 lr 0.00025353 rank 4
2022-12-08 06:33:14,185 DEBUG TRAIN Batch 27/5400 loss 7.302175 loss_att 336.123901 loss_ctc 19.305695 loss_rnnt 5.968451 lr 0.00025357 rank 1
2022-12-08 06:33:14,185 DEBUG TRAIN Batch 27/5400 loss 9.767077 loss_att 373.732239 loss_ctc 14.958303 loss_rnnt 9.190274 lr 0.00025355 rank 2
2022-12-08 06:33:14,186 DEBUG TRAIN Batch 27/5400 loss 10.197833 loss_att 403.350372 loss_ctc 24.139969 loss_rnnt 8.648707 lr 0.00025353 rank 3
2022-12-08 06:33:14,186 DEBUG TRAIN Batch 27/5400 loss 4.186639 loss_att 364.041321 loss_ctc 10.945975 loss_rnnt 3.435602 lr 0.00025354 rank 5
2022-12-08 06:33:14,192 DEBUG TRAIN Batch 27/5400 loss 16.271877 loss_att 374.970184 loss_ctc 21.755203 loss_rnnt 15.662619 lr 0.00025354 rank 0
2022-12-08 06:33:14,224 DEBUG TRAIN Batch 27/5400 loss 3.676101 loss_att 379.136810 loss_ctc 8.472672 loss_rnnt 3.143149 lr 0.00025355 rank 6
2022-12-08 06:34:17,240 DEBUG TRAIN Batch 27/5500 loss 6.952920 loss_att 392.812378 loss_ctc 13.081732 loss_rnnt 6.271941 lr 0.00025349 rank 7
2022-12-08 06:34:17,240 DEBUG TRAIN Batch 27/5500 loss 5.465636 loss_att 371.148315 loss_ctc 13.097750 loss_rnnt 4.617623 lr 0.00025351 rank 6
2022-12-08 06:34:17,243 DEBUG TRAIN Batch 27/5500 loss 9.222465 loss_att 354.670471 loss_ctc 16.191517 loss_rnnt 8.448126 lr 0.00025350 rank 4
2022-12-08 06:34:17,244 DEBUG TRAIN Batch 27/5500 loss 4.879827 loss_att 434.654785 loss_ctc 12.252636 loss_rnnt 4.060626 lr 0.00025351 rank 5
2022-12-08 06:34:17,246 DEBUG TRAIN Batch 27/5500 loss 7.635844 loss_att 293.250336 loss_ctc 15.624469 loss_rnnt 6.748219 lr 0.00025350 rank 0
2022-12-08 06:34:17,248 DEBUG TRAIN Batch 27/5500 loss 14.884203 loss_att 380.126465 loss_ctc 26.845610 loss_rnnt 13.555159 lr 0.00025350 rank 3
2022-12-08 06:34:17,248 DEBUG TRAIN Batch 27/5500 loss 9.809020 loss_att 370.166138 loss_ctc 16.241493 loss_rnnt 9.094301 lr 0.00025352 rank 2
2022-12-08 06:34:17,252 DEBUG TRAIN Batch 27/5500 loss 21.627449 loss_att 390.953094 loss_ctc 39.221169 loss_rnnt 19.672592 lr 0.00025353 rank 1
2022-12-08 06:35:21,039 DEBUG TRAIN Batch 27/5600 loss 7.367188 loss_att 299.164398 loss_ctc 14.953903 loss_rnnt 6.524220 lr 0.00025347 rank 4
2022-12-08 06:35:21,043 DEBUG TRAIN Batch 27/5600 loss 2.868119 loss_att 315.297089 loss_ctc 4.041703 loss_rnnt 2.737721 lr 0.00025350 rank 1
2022-12-08 06:35:21,045 DEBUG TRAIN Batch 27/5600 loss 7.019800 loss_att 330.431732 loss_ctc 16.371033 loss_rnnt 5.980774 lr 0.00025346 rank 7
2022-12-08 06:35:21,045 DEBUG TRAIN Batch 27/5600 loss 6.305341 loss_att 326.394409 loss_ctc 11.782271 loss_rnnt 5.696793 lr 0.00025349 rank 2
2022-12-08 06:35:21,046 DEBUG TRAIN Batch 27/5600 loss 10.118483 loss_att 345.221802 loss_ctc 16.347103 loss_rnnt 9.426414 lr 0.00025348 rank 6
2022-12-08 06:35:21,048 DEBUG TRAIN Batch 27/5600 loss 9.916009 loss_att 452.108002 loss_ctc 23.069454 loss_rnnt 8.454515 lr 0.00025347 rank 0
2022-12-08 06:35:21,053 DEBUG TRAIN Batch 27/5600 loss 16.304310 loss_att 342.531189 loss_ctc 26.936068 loss_rnnt 15.123004 lr 0.00025347 rank 5
2022-12-08 06:35:21,065 DEBUG TRAIN Batch 27/5600 loss 8.101919 loss_att 304.381683 loss_ctc 18.479902 loss_rnnt 6.948811 lr 0.00025347 rank 3
2022-12-08 06:36:33,255 DEBUG TRAIN Batch 27/5700 loss 4.182259 loss_att 258.658752 loss_ctc 11.153361 loss_rnnt 3.407692 lr 0.00025343 rank 7
2022-12-08 06:36:33,256 DEBUG TRAIN Batch 27/5700 loss 4.819182 loss_att 390.423798 loss_ctc 11.230576 loss_rnnt 4.106805 lr 0.00025343 rank 4
2022-12-08 06:36:33,256 DEBUG TRAIN Batch 27/5700 loss 8.497458 loss_att 396.098328 loss_ctc 14.908146 loss_rnnt 7.785160 lr 0.00025345 rank 6
2022-12-08 06:36:33,259 DEBUG TRAIN Batch 27/5700 loss 8.848231 loss_att 211.707809 loss_ctc 18.102715 loss_rnnt 7.819955 lr 0.00025347 rank 1
2022-12-08 06:36:33,260 DEBUG TRAIN Batch 27/5700 loss 2.341814 loss_att 233.987885 loss_ctc 5.724172 loss_rnnt 1.965997 lr 0.00025346 rank 2
2022-12-08 06:36:33,262 DEBUG TRAIN Batch 27/5700 loss 5.495766 loss_att 375.081421 loss_ctc 16.158182 loss_rnnt 4.311053 lr 0.00025344 rank 5
2022-12-08 06:36:33,264 DEBUG TRAIN Batch 27/5700 loss 5.587496 loss_att 357.733276 loss_ctc 13.084109 loss_rnnt 4.754539 lr 0.00025344 rank 0
2022-12-08 06:36:33,286 DEBUG TRAIN Batch 27/5700 loss 4.492558 loss_att 376.384857 loss_ctc 11.878234 loss_rnnt 3.671927 lr 0.00025344 rank 3
2022-12-08 06:37:37,228 DEBUG TRAIN Batch 27/5800 loss 6.980568 loss_att 373.438721 loss_ctc 11.084800 loss_rnnt 6.524543 lr 0.00025340 rank 4
2022-12-08 06:37:37,240 DEBUG TRAIN Batch 27/5800 loss 6.715554 loss_att 255.744507 loss_ctc 14.483310 loss_rnnt 5.852470 lr 0.00025342 rank 6
2022-12-08 06:37:37,241 DEBUG TRAIN Batch 27/5800 loss 10.130229 loss_att 442.318298 loss_ctc 21.759062 loss_rnnt 8.838137 lr 0.00025340 rank 7
2022-12-08 06:37:37,241 DEBUG TRAIN Batch 27/5800 loss 5.663732 loss_att 360.965210 loss_ctc 9.765505 loss_rnnt 5.207979 lr 0.00025343 rank 1
2022-12-08 06:37:37,243 DEBUG TRAIN Batch 27/5800 loss 3.894777 loss_att 332.713257 loss_ctc 12.695723 loss_rnnt 2.916894 lr 0.00025340 rank 0
2022-12-08 06:37:37,245 DEBUG TRAIN Batch 27/5800 loss 4.820871 loss_att 379.904541 loss_ctc 12.982634 loss_rnnt 3.914009 lr 0.00025342 rank 2
2022-12-08 06:37:37,247 DEBUG TRAIN Batch 27/5800 loss 7.020984 loss_att 238.835007 loss_ctc 15.393504 loss_rnnt 6.090703 lr 0.00025341 rank 5
2022-12-08 06:37:37,281 DEBUG TRAIN Batch 27/5800 loss 11.201576 loss_att 369.048340 loss_ctc 20.060247 loss_rnnt 10.217279 lr 0.00025340 rank 3
2022-12-08 06:38:40,541 DEBUG TRAIN Batch 27/5900 loss 4.583692 loss_att 385.838440 loss_ctc 6.391081 loss_rnnt 4.382871 lr 0.00025336 rank 7
2022-12-08 06:38:40,544 DEBUG TRAIN Batch 27/5900 loss 6.401173 loss_att 392.203461 loss_ctc 16.012766 loss_rnnt 5.333218 lr 0.00025339 rank 2
2022-12-08 06:38:40,545 DEBUG TRAIN Batch 27/5900 loss 4.267718 loss_att 288.769196 loss_ctc 7.906857 loss_rnnt 3.863370 lr 0.00025337 rank 4
2022-12-08 06:38:40,546 DEBUG TRAIN Batch 27/5900 loss 10.275106 loss_att 355.991943 loss_ctc 14.962548 loss_rnnt 9.754280 lr 0.00025337 rank 0
2022-12-08 06:38:40,546 DEBUG TRAIN Batch 27/5900 loss 4.872397 loss_att 372.082611 loss_ctc 5.702384 loss_rnnt 4.780176 lr 0.00025338 rank 6
2022-12-08 06:38:40,548 DEBUG TRAIN Batch 27/5900 loss 7.598855 loss_att 401.023773 loss_ctc 18.643593 loss_rnnt 6.371662 lr 0.00025337 rank 3
2022-12-08 06:38:40,549 DEBUG TRAIN Batch 27/5900 loss 7.148397 loss_att 408.603363 loss_ctc 8.916408 loss_rnnt 6.951952 lr 0.00025338 rank 5
2022-12-08 06:38:40,551 DEBUG TRAIN Batch 27/5900 loss 8.009189 loss_att 354.162567 loss_ctc 14.233772 loss_rnnt 7.317569 lr 0.00025340 rank 1
2022-12-08 06:39:45,419 DEBUG TRAIN Batch 27/6000 loss 10.976661 loss_att 369.790833 loss_ctc 23.084455 loss_rnnt 9.631351 lr 0.00025333 rank 7
2022-12-08 06:39:45,419 DEBUG TRAIN Batch 27/6000 loss 5.116342 loss_att 355.259705 loss_ctc 13.932663 loss_rnnt 4.136750 lr 0.00025334 rank 4
2022-12-08 06:39:45,423 DEBUG TRAIN Batch 27/6000 loss 13.584958 loss_att 469.726562 loss_ctc 28.288687 loss_rnnt 11.951210 lr 0.00025334 rank 5
2022-12-08 06:39:45,423 DEBUG TRAIN Batch 27/6000 loss 5.649087 loss_att 348.134705 loss_ctc 9.583450 loss_rnnt 5.211936 lr 0.00025334 rank 3
2022-12-08 06:39:45,424 DEBUG TRAIN Batch 27/6000 loss 13.383583 loss_att 367.939697 loss_ctc 25.291027 loss_rnnt 12.060534 lr 0.00025336 rank 2
2022-12-08 06:39:45,426 DEBUG TRAIN Batch 27/6000 loss 3.707461 loss_att 386.463715 loss_ctc 7.421933 loss_rnnt 3.294743 lr 0.00025335 rank 6
2022-12-08 06:39:45,426 DEBUG TRAIN Batch 27/6000 loss 9.175192 loss_att 445.904755 loss_ctc 25.609903 loss_rnnt 7.349113 lr 0.00025337 rank 1
2022-12-08 06:39:45,427 DEBUG TRAIN Batch 27/6000 loss 6.339675 loss_att 317.034058 loss_ctc 9.301119 loss_rnnt 6.010626 lr 0.00025334 rank 0
2022-12-08 06:40:56,071 DEBUG TRAIN Batch 27/6100 loss 8.683026 loss_att 347.696228 loss_ctc 13.181957 loss_rnnt 8.183146 lr 0.00025330 rank 7
2022-12-08 06:40:56,071 DEBUG TRAIN Batch 27/6100 loss 7.280700 loss_att 321.012146 loss_ctc 14.070705 loss_rnnt 6.526255 lr 0.00025330 rank 4
2022-12-08 06:40:56,071 DEBUG TRAIN Batch 27/6100 loss 7.945286 loss_att 296.062408 loss_ctc 14.792673 loss_rnnt 7.184465 lr 0.00025331 rank 0
2022-12-08 06:40:56,074 DEBUG TRAIN Batch 27/6100 loss 6.803308 loss_att 341.611084 loss_ctc 16.430382 loss_rnnt 5.733633 lr 0.00025334 rank 1
2022-12-08 06:40:56,075 DEBUG TRAIN Batch 27/6100 loss 3.397840 loss_att 372.110321 loss_ctc 10.292324 loss_rnnt 2.631786 lr 0.00025331 rank 5
2022-12-08 06:40:56,075 DEBUG TRAIN Batch 27/6100 loss 8.419863 loss_att 348.005859 loss_ctc 16.404058 loss_rnnt 7.532730 lr 0.00025332 rank 6
2022-12-08 06:40:56,076 DEBUG TRAIN Batch 27/6100 loss 13.636295 loss_att 401.069641 loss_ctc 28.377548 loss_rnnt 11.998378 lr 0.00025333 rank 2
2022-12-08 06:40:56,079 DEBUG TRAIN Batch 27/6100 loss 5.051876 loss_att 365.375549 loss_ctc 12.169743 loss_rnnt 4.261002 lr 0.00025331 rank 3
2022-12-08 06:41:58,692 DEBUG TRAIN Batch 27/6200 loss 11.515725 loss_att 304.825562 loss_ctc 17.883421 loss_rnnt 10.808203 lr 0.00025327 rank 7
2022-12-08 06:41:58,699 DEBUG TRAIN Batch 27/6200 loss 7.419518 loss_att 299.180145 loss_ctc 13.868133 loss_rnnt 6.703005 lr 0.00025327 rank 4
2022-12-08 06:41:58,700 DEBUG TRAIN Batch 27/6200 loss 3.112473 loss_att 304.177887 loss_ctc 9.096824 loss_rnnt 2.447546 lr 0.00025327 rank 3
2022-12-08 06:41:58,701 DEBUG TRAIN Batch 27/6200 loss 5.581254 loss_att 362.204041 loss_ctc 9.481285 loss_rnnt 5.147918 lr 0.00025329 rank 2
2022-12-08 06:41:58,701 DEBUG TRAIN Batch 27/6200 loss 7.957157 loss_att 155.198807 loss_ctc 11.908397 loss_rnnt 7.518130 lr 0.00025327 rank 0
2022-12-08 06:41:58,704 DEBUG TRAIN Batch 27/6200 loss 4.678653 loss_att 378.757233 loss_ctc 14.069139 loss_rnnt 3.635266 lr 0.00025329 rank 6
2022-12-08 06:41:58,707 DEBUG TRAIN Batch 27/6200 loss 5.338563 loss_att 346.549561 loss_ctc 14.739438 loss_rnnt 4.294022 lr 0.00025330 rank 1
2022-12-08 06:41:58,708 DEBUG TRAIN Batch 27/6200 loss 7.463255 loss_att 447.085846 loss_ctc 15.327536 loss_rnnt 6.589446 lr 0.00025328 rank 5
2022-12-08 06:43:02,117 DEBUG TRAIN Batch 27/6300 loss 9.991372 loss_att 317.895264 loss_ctc 17.556620 loss_rnnt 9.150789 lr 0.00025323 rank 7
2022-12-08 06:43:02,117 DEBUG TRAIN Batch 27/6300 loss 12.075641 loss_att 360.008087 loss_ctc 25.838892 loss_rnnt 10.546391 lr 0.00025327 rank 1
2022-12-08 06:43:02,119 DEBUG TRAIN Batch 27/6300 loss 22.580750 loss_att 459.189209 loss_ctc 52.216656 loss_rnnt 19.287870 lr 0.00025324 rank 0
2022-12-08 06:43:02,125 DEBUG TRAIN Batch 27/6300 loss 8.114396 loss_att 208.242737 loss_ctc 13.492290 loss_rnnt 7.516852 lr 0.00025324 rank 3
2022-12-08 06:43:02,125 DEBUG TRAIN Batch 27/6300 loss 4.517530 loss_att 191.621826 loss_ctc 11.714941 loss_rnnt 3.717818 lr 0.00025324 rank 4
2022-12-08 06:43:02,129 DEBUG TRAIN Batch 27/6300 loss 7.484100 loss_att 354.872559 loss_ctc 14.991352 loss_rnnt 6.649961 lr 0.00025325 rank 6
2022-12-08 06:43:02,143 DEBUG TRAIN Batch 27/6300 loss 5.507676 loss_att 299.840149 loss_ctc 12.022675 loss_rnnt 4.783787 lr 0.00025325 rank 5
2022-12-08 06:43:02,145 DEBUG TRAIN Batch 27/6300 loss 3.803510 loss_att 322.428223 loss_ctc 10.219920 loss_rnnt 3.090576 lr 0.00025326 rank 2
2022-12-08 06:44:14,500 DEBUG TRAIN Batch 27/6400 loss 6.466763 loss_att 407.552917 loss_ctc 17.766174 loss_rnnt 5.211272 lr 0.00025321 rank 3
2022-12-08 06:44:14,512 DEBUG TRAIN Batch 27/6400 loss 9.894759 loss_att 71.843010 loss_ctc 13.583118 loss_rnnt 9.484942 lr 0.00025323 rank 2
2022-12-08 06:44:14,513 DEBUG TRAIN Batch 27/6400 loss 7.782247 loss_att 375.851654 loss_ctc 18.314928 loss_rnnt 6.611949 lr 0.00025321 rank 4
2022-12-08 06:44:14,514 DEBUG TRAIN Batch 27/6400 loss 8.324651 loss_att 103.652321 loss_ctc 13.654478 loss_rnnt 7.732448 lr 0.00025320 rank 7
2022-12-08 06:44:14,514 DEBUG TRAIN Batch 27/6400 loss 8.045478 loss_att 318.940643 loss_ctc 17.260544 loss_rnnt 7.021582 lr 0.00025322 rank 6
2022-12-08 06:44:14,514 DEBUG TRAIN Batch 27/6400 loss 6.331244 loss_att 172.629684 loss_ctc 13.735646 loss_rnnt 5.508532 lr 0.00025324 rank 1
2022-12-08 06:44:14,518 DEBUG TRAIN Batch 27/6400 loss 5.710020 loss_att 255.643707 loss_ctc 13.317931 loss_rnnt 4.864696 lr 0.00025321 rank 5
2022-12-08 06:44:14,520 DEBUG TRAIN Batch 27/6400 loss 13.018532 loss_att 346.216736 loss_ctc 23.439320 loss_rnnt 11.860666 lr 0.00025321 rank 0
2022-12-08 06:45:18,165 DEBUG TRAIN Batch 27/6500 loss 10.190984 loss_att 367.650482 loss_ctc 20.213268 loss_rnnt 9.077396 lr 0.00025317 rank 7
2022-12-08 06:45:18,167 DEBUG TRAIN Batch 27/6500 loss 9.185205 loss_att 391.483124 loss_ctc 22.023579 loss_rnnt 7.758719 lr 0.00025320 rank 2
2022-12-08 06:45:18,168 DEBUG TRAIN Batch 27/6500 loss 6.966603 loss_att 370.265350 loss_ctc 16.320339 loss_rnnt 5.927299 lr 0.00025317 rank 4
2022-12-08 06:45:18,169 DEBUG TRAIN Batch 27/6500 loss 10.490722 loss_att 355.814209 loss_ctc 18.551630 loss_rnnt 9.595066 lr 0.00025321 rank 1
2022-12-08 06:45:18,173 DEBUG TRAIN Batch 27/6500 loss 12.777719 loss_att 183.406845 loss_ctc 20.472855 loss_rnnt 11.922704 lr 0.00025319 rank 6
2022-12-08 06:45:18,176 DEBUG TRAIN Batch 27/6500 loss 10.146723 loss_att 363.068787 loss_ctc 20.219196 loss_rnnt 9.027559 lr 0.00025318 rank 0
2022-12-08 06:45:18,179 DEBUG TRAIN Batch 27/6500 loss 3.481184 loss_att 400.927979 loss_ctc 9.008871 loss_rnnt 2.866997 lr 0.00025318 rank 3
2022-12-08 06:45:18,179 DEBUG TRAIN Batch 27/6500 loss 5.472509 loss_att 394.301208 loss_ctc 14.424258 loss_rnnt 4.477870 lr 0.00025318 rank 5
2022-12-08 06:46:21,607 DEBUG TRAIN Batch 27/6600 loss 6.657574 loss_att 464.941620 loss_ctc 11.108401 loss_rnnt 6.163038 lr 0.00025314 rank 7
2022-12-08 06:46:21,607 DEBUG TRAIN Batch 27/6600 loss 6.041518 loss_att 444.928162 loss_ctc 15.316474 loss_rnnt 5.010968 lr 0.00025316 rank 2
2022-12-08 06:46:21,610 DEBUG TRAIN Batch 27/6600 loss 11.139278 loss_att 422.941589 loss_ctc 18.300964 loss_rnnt 10.343536 lr 0.00025317 rank 1
2022-12-08 06:46:21,610 DEBUG TRAIN Batch 27/6600 loss 7.639644 loss_att 360.020050 loss_ctc 19.163548 loss_rnnt 6.359211 lr 0.00025314 rank 3
2022-12-08 06:46:21,612 DEBUG TRAIN Batch 27/6600 loss 12.171780 loss_att 393.330444 loss_ctc 20.872612 loss_rnnt 11.205021 lr 0.00025314 rank 4
2022-12-08 06:46:21,613 DEBUG TRAIN Batch 27/6600 loss 6.542111 loss_att 433.935150 loss_ctc 14.287963 loss_rnnt 5.681461 lr 0.00025316 rank 6
2022-12-08 06:46:21,615 DEBUG TRAIN Batch 27/6600 loss 7.150351 loss_att 381.404297 loss_ctc 15.538891 loss_rnnt 6.218291 lr 0.00025314 rank 0
2022-12-08 06:46:21,653 DEBUG TRAIN Batch 27/6600 loss 12.835519 loss_att 328.496643 loss_ctc 18.269005 loss_rnnt 12.231798 lr 0.00025315 rank 5
2022-12-08 06:47:26,372 DEBUG TRAIN Batch 27/6700 loss 4.441277 loss_att 386.612152 loss_ctc 8.252494 loss_rnnt 4.017809 lr 0.00025312 rank 6
2022-12-08 06:47:26,388 DEBUG TRAIN Batch 27/6700 loss 5.592336 loss_att 340.835022 loss_ctc 13.593382 loss_rnnt 4.703331 lr 0.00025310 rank 7
2022-12-08 06:47:26,389 DEBUG TRAIN Batch 27/6700 loss 5.391184 loss_att 361.533325 loss_ctc 9.093763 loss_rnnt 4.979786 lr 0.00025311 rank 4
2022-12-08 06:47:26,389 DEBUG TRAIN Batch 27/6700 loss 8.326848 loss_att 411.906342 loss_ctc 20.514399 loss_rnnt 6.972676 lr 0.00025313 rank 2
2022-12-08 06:47:26,390 DEBUG TRAIN Batch 27/6700 loss 3.691400 loss_att 381.514069 loss_ctc 11.041359 loss_rnnt 2.874738 lr 0.00025314 rank 1
2022-12-08 06:47:26,391 DEBUG TRAIN Batch 27/6700 loss 10.195991 loss_att 360.712860 loss_ctc 16.004375 loss_rnnt 9.550615 lr 0.00025311 rank 3
2022-12-08 06:47:26,394 DEBUG TRAIN Batch 27/6700 loss 7.062936 loss_att 365.672485 loss_ctc 11.775344 loss_rnnt 6.539335 lr 0.00025312 rank 5
2022-12-08 06:47:26,396 DEBUG TRAIN Batch 27/6700 loss 6.399290 loss_att 287.017914 loss_ctc 14.556854 loss_rnnt 5.492893 lr 0.00025311 rank 0
2022-12-08 06:48:37,787 DEBUG TRAIN Batch 27/6800 loss 8.299277 loss_att 345.404602 loss_ctc 16.650803 loss_rnnt 7.371330 lr 0.00025307 rank 7
2022-12-08 06:48:37,787 DEBUG TRAIN Batch 27/6800 loss 4.086578 loss_att 299.998627 loss_ctc 9.226882 loss_rnnt 3.515433 lr 0.00025308 rank 4
2022-12-08 06:48:37,790 DEBUG TRAIN Batch 27/6800 loss 4.330060 loss_att 383.539368 loss_ctc 10.775419 loss_rnnt 3.613910 lr 0.00025309 rank 6
2022-12-08 06:48:37,791 DEBUG TRAIN Batch 27/6800 loss 11.084556 loss_att 465.884888 loss_ctc 18.713848 loss_rnnt 10.236856 lr 0.00025311 rank 1
2022-12-08 06:48:37,793 DEBUG TRAIN Batch 27/6800 loss 18.180412 loss_att 381.578918 loss_ctc 37.198845 loss_rnnt 16.067253 lr 0.00025308 rank 3
2022-12-08 06:48:37,793 DEBUG TRAIN Batch 27/6800 loss 5.954503 loss_att 416.203461 loss_ctc 12.303026 loss_rnnt 5.249111 lr 0.00025308 rank 5
2022-12-08 06:48:37,794 DEBUG TRAIN Batch 27/6800 loss 7.645984 loss_att 347.159119 loss_ctc 12.924257 loss_rnnt 7.059509 lr 0.00025310 rank 2
2022-12-08 06:48:37,795 DEBUG TRAIN Batch 27/6800 loss 8.414352 loss_att 270.624908 loss_ctc 16.089855 loss_rnnt 7.561519 lr 0.00025308 rank 0
2022-12-08 06:49:41,103 DEBUG TRAIN Batch 27/6900 loss 8.578981 loss_att 331.566315 loss_ctc 13.751887 loss_rnnt 8.004214 lr 0.00025304 rank 7
2022-12-08 06:49:41,104 DEBUG TRAIN Batch 27/6900 loss 2.320206 loss_att 396.346039 loss_ctc 8.062383 loss_rnnt 1.682186 lr 0.00025304 rank 4
2022-12-08 06:49:41,105 DEBUG TRAIN Batch 27/6900 loss 11.506475 loss_att 336.161011 loss_ctc 17.369278 loss_rnnt 10.855053 lr 0.00025306 rank 6
2022-12-08 06:49:41,108 DEBUG TRAIN Batch 27/6900 loss 10.382151 loss_att 294.588379 loss_ctc 14.376235 loss_rnnt 9.938364 lr 0.00025307 rank 2
2022-12-08 06:49:41,109 DEBUG TRAIN Batch 27/6900 loss 15.038827 loss_att 434.385254 loss_ctc 23.259117 loss_rnnt 14.125462 lr 0.00025305 rank 0
2022-12-08 06:49:41,110 DEBUG TRAIN Batch 27/6900 loss 5.486051 loss_att 251.045700 loss_ctc 13.940879 loss_rnnt 4.546626 lr 0.00025305 rank 3
2022-12-08 06:49:41,113 DEBUG TRAIN Batch 27/6900 loss 3.405600 loss_att 343.243652 loss_ctc 8.250630 loss_rnnt 2.867264 lr 0.00025305 rank 5
2022-12-08 06:49:41,148 DEBUG TRAIN Batch 27/6900 loss 8.879884 loss_att 337.570343 loss_ctc 15.686232 loss_rnnt 8.123623 lr 0.00025308 rank 1
2022-12-08 06:50:45,697 DEBUG TRAIN Batch 27/7000 loss 9.585226 loss_att 174.964172 loss_ctc 18.902115 loss_rnnt 8.550016 lr 0.00025301 rank 7
2022-12-08 06:50:45,696 DEBUG TRAIN Batch 27/7000 loss 16.348444 loss_att 302.929810 loss_ctc 37.767864 loss_rnnt 13.968509 lr 0.00025301 rank 3
2022-12-08 06:50:45,697 DEBUG TRAIN Batch 27/7000 loss 7.220408 loss_att 440.285217 loss_ctc 18.924143 loss_rnnt 5.919993 lr 0.00025303 rank 6
2022-12-08 06:50:45,700 DEBUG TRAIN Batch 27/7000 loss 5.264579 loss_att 492.813812 loss_ctc 9.526814 loss_rnnt 4.790998 lr 0.00025301 rank 4
2022-12-08 06:50:45,702 DEBUG TRAIN Batch 27/7000 loss 1.342679 loss_att 403.017273 loss_ctc 3.974873 loss_rnnt 1.050213 lr 0.00025302 rank 0
2022-12-08 06:50:45,703 DEBUG TRAIN Batch 27/7000 loss 5.494305 loss_att 185.411285 loss_ctc 12.292224 loss_rnnt 4.738980 lr 0.00025303 rank 2
2022-12-08 06:50:45,702 DEBUG TRAIN Batch 27/7000 loss 7.495207 loss_att 339.949280 loss_ctc 17.153988 loss_rnnt 6.422009 lr 0.00025302 rank 5
2022-12-08 06:50:45,741 DEBUG TRAIN Batch 27/7000 loss 7.398622 loss_att 213.087799 loss_ctc 17.399845 loss_rnnt 6.287375 lr 0.00025305 rank 1
2022-12-08 06:51:56,509 DEBUG TRAIN Batch 27/7100 loss 2.480206 loss_att 339.406128 loss_ctc 7.145154 loss_rnnt 1.961878 lr 0.00025298 rank 0
2022-12-08 06:51:56,524 DEBUG TRAIN Batch 27/7100 loss 3.750196 loss_att 378.559174 loss_ctc 7.386879 loss_rnnt 3.346121 lr 0.00025297 rank 7
2022-12-08 06:51:56,524 DEBUG TRAIN Batch 27/7100 loss 12.027059 loss_att 247.662155 loss_ctc 17.015388 loss_rnnt 11.472800 lr 0.00025299 rank 6
2022-12-08 06:51:56,525 DEBUG TRAIN Batch 27/7100 loss 9.756118 loss_att 406.239807 loss_ctc 18.995815 loss_rnnt 8.729485 lr 0.00025300 rank 2
2022-12-08 06:51:56,526 DEBUG TRAIN Batch 27/7100 loss 4.637605 loss_att 448.526123 loss_ctc 12.616795 loss_rnnt 3.751029 lr 0.00025298 rank 4
2022-12-08 06:51:56,527 DEBUG TRAIN Batch 27/7100 loss 0.734074 loss_att 376.502258 loss_ctc 2.537775 loss_rnnt 0.533662 lr 0.00025301 rank 1
2022-12-08 06:51:56,528 DEBUG TRAIN Batch 27/7100 loss 9.015799 loss_att 427.632996 loss_ctc 12.189944 loss_rnnt 8.663116 lr 0.00025299 rank 5
2022-12-08 06:51:56,540 DEBUG TRAIN Batch 27/7100 loss 7.801417 loss_att 376.102783 loss_ctc 10.965826 loss_rnnt 7.449817 lr 0.00025298 rank 3
2022-12-08 06:53:00,670 DEBUG TRAIN Batch 27/7200 loss 3.329933 loss_att 378.260376 loss_ctc 5.319663 loss_rnnt 3.108852 lr 0.00025295 rank 4
2022-12-08 06:53:00,674 DEBUG TRAIN Batch 27/7200 loss 5.540065 loss_att 443.992554 loss_ctc 19.619392 loss_rnnt 3.975695 lr 0.00025297 rank 2
2022-12-08 06:53:00,674 DEBUG TRAIN Batch 27/7200 loss 8.945995 loss_att 433.735779 loss_ctc 20.527706 loss_rnnt 7.659139 lr 0.00025294 rank 7
2022-12-08 06:53:00,676 DEBUG TRAIN Batch 27/7200 loss 12.896235 loss_att 479.676758 loss_ctc 26.442457 loss_rnnt 11.391100 lr 0.00025296 rank 6
2022-12-08 06:53:00,676 DEBUG TRAIN Batch 27/7200 loss 8.438505 loss_att 428.254364 loss_ctc 15.691063 loss_rnnt 7.632665 lr 0.00025298 rank 1
2022-12-08 06:53:00,678 DEBUG TRAIN Batch 27/7200 loss 14.557820 loss_att 426.925476 loss_ctc 29.833954 loss_rnnt 12.860473 lr 0.00025295 rank 0
2022-12-08 06:53:00,681 DEBUG TRAIN Batch 27/7200 loss 9.440540 loss_att 419.419556 loss_ctc 26.289602 loss_rnnt 7.568422 lr 0.00025295 rank 3
2022-12-08 06:53:00,688 DEBUG TRAIN Batch 27/7200 loss 5.854948 loss_att 451.090668 loss_ctc 14.888437 loss_rnnt 4.851226 lr 0.00025295 rank 5
2022-12-08 06:54:04,020 DEBUG TRAIN Batch 27/7300 loss 6.517086 loss_att 330.389221 loss_ctc 11.302176 loss_rnnt 5.985409 lr 0.00025295 rank 1
2022-12-08 06:54:04,024 DEBUG TRAIN Batch 27/7300 loss 8.013370 loss_att 381.245422 loss_ctc 16.626350 loss_rnnt 7.056372 lr 0.00025292 rank 4
2022-12-08 06:54:04,027 DEBUG TRAIN Batch 27/7300 loss 3.142528 loss_att 374.532074 loss_ctc 9.493949 loss_rnnt 2.436814 lr 0.00025294 rank 2
2022-12-08 06:54:04,027 DEBUG TRAIN Batch 27/7300 loss 6.279612 loss_att 367.133606 loss_ctc 14.289165 loss_rnnt 5.389662 lr 0.00025292 rank 0
2022-12-08 06:54:04,029 DEBUG TRAIN Batch 27/7300 loss 7.332425 loss_att 424.211609 loss_ctc 13.090567 loss_rnnt 6.692632 lr 0.00025292 rank 5
2022-12-08 06:54:04,031 DEBUG TRAIN Batch 27/7300 loss 7.638063 loss_att 373.907074 loss_ctc 12.957922 loss_rnnt 7.046968 lr 0.00025291 rank 7
2022-12-08 06:54:04,031 DEBUG TRAIN Batch 27/7300 loss 2.973472 loss_att 455.726288 loss_ctc 9.778025 loss_rnnt 2.217411 lr 0.00025293 rank 6
2022-12-08 06:54:04,031 DEBUG TRAIN Batch 27/7300 loss 13.576116 loss_att 377.560547 loss_ctc 31.998348 loss_rnnt 11.529202 lr 0.00025292 rank 3
2022-12-08 06:55:08,268 DEBUG TRAIN Batch 27/7400 loss 2.906978 loss_att 330.611816 loss_ctc 9.122585 loss_rnnt 2.216355 lr 0.00025288 rank 4
2022-12-08 06:55:08,268 DEBUG TRAIN Batch 27/7400 loss 3.348256 loss_att 352.461182 loss_ctc 10.804399 loss_rnnt 2.519795 lr 0.00025290 rank 6
2022-12-08 06:55:08,271 DEBUG TRAIN Batch 27/7400 loss 4.125279 loss_att 314.469238 loss_ctc 8.679450 loss_rnnt 3.619260 lr 0.00025291 rank 2
2022-12-08 06:55:08,274 DEBUG TRAIN Batch 27/7400 loss 9.269756 loss_att 364.340393 loss_ctc 19.989166 loss_rnnt 8.078712 lr 0.00025288 rank 7
2022-12-08 06:55:08,275 DEBUG TRAIN Batch 27/7400 loss 7.059736 loss_att 334.176178 loss_ctc 17.844135 loss_rnnt 5.861470 lr 0.00025289 rank 3
2022-12-08 06:55:08,275 DEBUG TRAIN Batch 27/7400 loss 7.497237 loss_att 341.093658 loss_ctc 15.361269 loss_rnnt 6.623456 lr 0.00025289 rank 0
2022-12-08 06:55:08,281 DEBUG TRAIN Batch 27/7400 loss 8.277409 loss_att 353.537292 loss_ctc 18.553844 loss_rnnt 7.135583 lr 0.00025292 rank 1
2022-12-08 06:55:08,289 DEBUG TRAIN Batch 27/7400 loss 8.005781 loss_att 403.197754 loss_ctc 17.304497 loss_rnnt 6.972591 lr 0.00025289 rank 5
2022-12-08 06:56:20,469 DEBUG TRAIN Batch 27/7500 loss 10.605113 loss_att 210.294205 loss_ctc 15.856294 loss_rnnt 10.021648 lr 0.00025285 rank 4
2022-12-08 06:56:20,474 DEBUG TRAIN Batch 27/7500 loss 8.174434 loss_att 341.634399 loss_ctc 13.911521 loss_rnnt 7.536980 lr 0.00025285 rank 3
2022-12-08 06:56:20,475 DEBUG TRAIN Batch 27/7500 loss 13.231532 loss_att 340.779907 loss_ctc 24.696037 loss_rnnt 11.957699 lr 0.00025287 rank 2
2022-12-08 06:56:20,476 DEBUG TRAIN Batch 27/7500 loss 7.137338 loss_att 444.940521 loss_ctc 15.273994 loss_rnnt 6.233265 lr 0.00025285 rank 0
2022-12-08 06:56:20,476 DEBUG TRAIN Batch 27/7500 loss 9.550329 loss_att 353.962921 loss_ctc 20.875967 loss_rnnt 8.291925 lr 0.00025285 rank 7
2022-12-08 06:56:20,479 DEBUG TRAIN Batch 27/7500 loss 8.210727 loss_att 343.619202 loss_ctc 19.460075 loss_rnnt 6.960799 lr 0.00025287 rank 6
2022-12-08 06:56:20,481 DEBUG TRAIN Batch 27/7500 loss 10.974893 loss_att 365.341797 loss_ctc 21.499273 loss_rnnt 9.805517 lr 0.00025286 rank 5
2022-12-08 06:56:20,482 DEBUG TRAIN Batch 27/7500 loss 15.884084 loss_att 316.628815 loss_ctc 27.826527 loss_rnnt 14.557146 lr 0.00025288 rank 1
2022-12-08 06:57:24,166 DEBUG TRAIN Batch 27/7600 loss 6.502604 loss_att 388.321960 loss_ctc 16.830383 loss_rnnt 5.355073 lr 0.00025282 rank 4
2022-12-08 06:57:24,169 DEBUG TRAIN Batch 27/7600 loss 7.272662 loss_att 258.328369 loss_ctc 16.623434 loss_rnnt 6.233687 lr 0.00025285 rank 1
2022-12-08 06:57:24,169 DEBUG TRAIN Batch 27/7600 loss 6.744114 loss_att 240.606491 loss_ctc 13.107561 loss_rnnt 6.037065 lr 0.00025281 rank 7
2022-12-08 06:57:24,170 DEBUG TRAIN Batch 27/7600 loss 13.717280 loss_att 305.359283 loss_ctc 22.231934 loss_rnnt 12.771209 lr 0.00025284 rank 2
2022-12-08 06:57:24,170 DEBUG TRAIN Batch 27/7600 loss 2.263361 loss_att 421.762177 loss_ctc 8.003971 loss_rnnt 1.625515 lr 0.00025282 rank 0
2022-12-08 06:57:24,173 DEBUG TRAIN Batch 27/7600 loss 3.402347 loss_att 160.728760 loss_ctc 7.311045 loss_rnnt 2.968047 lr 0.00025282 rank 3
2022-12-08 06:57:24,173 DEBUG TRAIN Batch 27/7600 loss 12.074469 loss_att 350.132507 loss_ctc 21.869535 loss_rnnt 10.986128 lr 0.00025283 rank 6
2022-12-08 06:57:24,175 DEBUG TRAIN Batch 27/7600 loss 12.711491 loss_att 279.002899 loss_ctc 19.271959 loss_rnnt 11.982551 lr 0.00025283 rank 5
2022-12-08 06:58:27,857 DEBUG TRAIN Batch 27/7700 loss 1.989480 loss_att 359.420837 loss_ctc 9.486300 loss_rnnt 1.156500 lr 0.00025279 rank 4
2022-12-08 06:58:27,858 DEBUG TRAIN Batch 27/7700 loss 6.176009 loss_att 422.637787 loss_ctc 16.185349 loss_rnnt 5.063860 lr 0.00025278 rank 7
2022-12-08 06:58:27,860 DEBUG TRAIN Batch 27/7700 loss 11.377142 loss_att 452.422119 loss_ctc 32.449486 loss_rnnt 9.035770 lr 0.00025281 rank 2
2022-12-08 06:58:27,861 DEBUG TRAIN Batch 27/7700 loss 8.388573 loss_att 417.798798 loss_ctc 12.069167 loss_rnnt 7.979618 lr 0.00025282 rank 1
2022-12-08 06:58:27,861 DEBUG TRAIN Batch 27/7700 loss 5.013562 loss_att 367.750977 loss_ctc 12.621730 loss_rnnt 4.168210 lr 0.00025279 rank 0
2022-12-08 06:58:27,863 DEBUG TRAIN Batch 27/7700 loss 8.486449 loss_att 293.385223 loss_ctc 16.771542 loss_rnnt 7.565884 lr 0.00025279 rank 5
2022-12-08 06:58:27,879 DEBUG TRAIN Batch 27/7700 loss 7.100713 loss_att 401.892273 loss_ctc 13.236396 loss_rnnt 6.418970 lr 0.00025279 rank 3
2022-12-08 06:58:27,904 DEBUG TRAIN Batch 27/7700 loss 4.710661 loss_att 308.220825 loss_ctc 11.769579 loss_rnnt 3.926337 lr 0.00025280 rank 6
2022-12-08 06:59:40,151 DEBUG TRAIN Batch 27/7800 loss 10.530461 loss_att 440.587891 loss_ctc 23.251781 loss_rnnt 9.116982 lr 0.00025276 rank 3
2022-12-08 06:59:40,162 DEBUG TRAIN Batch 27/7800 loss 5.362171 loss_att 393.297821 loss_ctc 11.762839 loss_rnnt 4.650986 lr 0.00025275 rank 4
2022-12-08 06:59:40,168 DEBUG TRAIN Batch 27/7800 loss 11.107977 loss_att 507.810242 loss_ctc 24.999527 loss_rnnt 9.564471 lr 0.00025275 rank 7
2022-12-08 06:59:40,168 DEBUG TRAIN Batch 27/7800 loss 11.952847 loss_att 432.421631 loss_ctc 15.699944 loss_rnnt 11.536503 lr 0.00025278 rank 2
2022-12-08 06:59:40,171 DEBUG TRAIN Batch 27/7800 loss 5.838075 loss_att 219.766739 loss_ctc 11.882162 loss_rnnt 5.166510 lr 0.00025277 rank 6
2022-12-08 06:59:40,173 DEBUG TRAIN Batch 27/7800 loss 11.544593 loss_att 406.636902 loss_ctc 17.007072 loss_rnnt 10.937651 lr 0.00025276 rank 0
2022-12-08 06:59:40,177 DEBUG TRAIN Batch 27/7800 loss 6.890679 loss_att 372.940277 loss_ctc 12.392612 loss_rnnt 6.279353 lr 0.00025276 rank 5
2022-12-08 06:59:40,179 DEBUG TRAIN Batch 27/7800 loss 5.863277 loss_att 343.016541 loss_ctc 12.395469 loss_rnnt 5.137478 lr 0.00025279 rank 1
2022-12-08 07:00:43,791 DEBUG TRAIN Batch 27/7900 loss 14.573561 loss_att 385.732117 loss_ctc 25.086388 loss_rnnt 13.405470 lr 0.00025272 rank 4
2022-12-08 07:00:43,790 DEBUG TRAIN Batch 27/7900 loss 4.515737 loss_att 312.470123 loss_ctc 11.216072 loss_rnnt 3.771255 lr 0.00025272 rank 7
2022-12-08 07:00:43,792 DEBUG TRAIN Batch 27/7900 loss 10.183196 loss_att 451.003784 loss_ctc 22.086697 loss_rnnt 8.860585 lr 0.00025274 rank 2
2022-12-08 07:00:43,793 DEBUG TRAIN Batch 27/7900 loss 10.042727 loss_att 436.700623 loss_ctc 20.990597 loss_rnnt 8.826297 lr 0.00025273 rank 5
2022-12-08 07:00:43,793 DEBUG TRAIN Batch 27/7900 loss 12.576372 loss_att 354.359100 loss_ctc 22.202353 loss_rnnt 11.506820 lr 0.00025274 rank 6
2022-12-08 07:00:43,793 DEBUG TRAIN Batch 27/7900 loss 6.892766 loss_att 355.993958 loss_ctc 12.676785 loss_rnnt 6.250097 lr 0.00025275 rank 1
2022-12-08 07:00:43,796 DEBUG TRAIN Batch 27/7900 loss 8.995498 loss_att 385.252380 loss_ctc 16.954998 loss_rnnt 8.111109 lr 0.00025272 rank 3
2022-12-08 07:00:43,796 DEBUG TRAIN Batch 27/7900 loss 10.609786 loss_att 367.943390 loss_ctc 20.386131 loss_rnnt 9.523525 lr 0.00025272 rank 0
2022-12-08 07:01:46,864 DEBUG TRAIN Batch 27/8000 loss 9.953098 loss_att 401.897278 loss_ctc 14.972670 loss_rnnt 9.395369 lr 0.00025272 rank 1
2022-12-08 07:01:46,866 DEBUG TRAIN Batch 27/8000 loss 3.554630 loss_att 290.416870 loss_ctc 7.425989 loss_rnnt 3.124479 lr 0.00025269 rank 4
2022-12-08 07:01:46,866 DEBUG TRAIN Batch 27/8000 loss 3.503099 loss_att 375.423950 loss_ctc 7.128586 loss_rnnt 3.100267 lr 0.00025270 rank 6
2022-12-08 07:01:46,869 DEBUG TRAIN Batch 27/8000 loss 13.255136 loss_att 417.892548 loss_ctc 21.250103 loss_rnnt 12.366806 lr 0.00025269 rank 3
2022-12-08 07:01:46,870 DEBUG TRAIN Batch 27/8000 loss 7.813578 loss_att 342.328064 loss_ctc 14.249657 loss_rnnt 7.098458 lr 0.00025270 rank 5
2022-12-08 07:01:46,896 DEBUG TRAIN Batch 27/8000 loss 3.090297 loss_att 298.044495 loss_ctc 4.212595 loss_rnnt 2.965597 lr 0.00025268 rank 7
2022-12-08 07:01:46,898 DEBUG TRAIN Batch 27/8000 loss 15.158934 loss_att 281.919800 loss_ctc 24.535353 loss_rnnt 14.117110 lr 0.00025269 rank 0
2022-12-08 07:01:46,909 DEBUG TRAIN Batch 27/8000 loss 5.133869 loss_att 360.614594 loss_ctc 13.892902 loss_rnnt 4.160643 lr 0.00025271 rank 2
2022-12-08 07:02:51,596 DEBUG TRAIN Batch 27/8100 loss 5.984818 loss_att 410.821716 loss_ctc 13.718402 loss_rnnt 5.125531 lr 0.00025266 rank 5
2022-12-08 07:02:51,607 DEBUG TRAIN Batch 27/8100 loss 6.297261 loss_att 301.447266 loss_ctc 15.852419 loss_rnnt 5.235577 lr 0.00025268 rank 2
2022-12-08 07:02:51,609 DEBUG TRAIN Batch 27/8100 loss 9.030538 loss_att 250.741165 loss_ctc 12.719699 loss_rnnt 8.620631 lr 0.00025266 rank 4
2022-12-08 07:02:51,609 DEBUG TRAIN Batch 27/8100 loss 12.625782 loss_att 378.300323 loss_ctc 22.604507 loss_rnnt 11.517035 lr 0.00025269 rank 1
2022-12-08 07:02:51,617 DEBUG TRAIN Batch 27/8100 loss 2.739612 loss_att 330.290009 loss_ctc 5.740047 loss_rnnt 2.406230 lr 0.00025267 rank 6
2022-12-08 07:02:51,617 DEBUG TRAIN Batch 27/8100 loss 3.466152 loss_att 346.555115 loss_ctc 8.311396 loss_rnnt 2.927792 lr 0.00025266 rank 3
2022-12-08 07:02:51,630 DEBUG TRAIN Batch 27/8100 loss 7.621394 loss_att 335.892029 loss_ctc 10.099657 loss_rnnt 7.346031 lr 0.00025265 rank 7
2022-12-08 07:02:51,640 DEBUG TRAIN Batch 27/8100 loss 15.436615 loss_att 219.577805 loss_ctc 27.970200 loss_rnnt 14.043995 lr 0.00025266 rank 0
2022-12-08 07:03:55,261 DEBUG TRAIN Batch 27/8200 loss 5.480645 loss_att 427.796875 loss_ctc 12.764313 loss_rnnt 4.671349 lr 0.00025263 rank 0
2022-12-08 07:03:55,264 DEBUG TRAIN Batch 27/8200 loss 8.341872 loss_att 307.045715 loss_ctc 18.786932 loss_rnnt 7.181310 lr 0.00025262 rank 7
2022-12-08 07:03:55,267 DEBUG TRAIN Batch 27/8200 loss 6.385850 loss_att 451.425659 loss_ctc 17.502384 loss_rnnt 5.150680 lr 0.00025262 rank 4
2022-12-08 07:03:55,268 DEBUG TRAIN Batch 27/8200 loss 8.111963 loss_att 363.787170 loss_ctc 15.896744 loss_rnnt 7.246988 lr 0.00025264 rank 6
2022-12-08 07:03:55,270 DEBUG TRAIN Batch 27/8200 loss 4.469656 loss_att 331.997223 loss_ctc 10.159537 loss_rnnt 3.837447 lr 0.00025263 rank 3
2022-12-08 07:03:55,270 DEBUG TRAIN Batch 27/8200 loss 7.299779 loss_att 295.132141 loss_ctc 14.826718 loss_rnnt 6.463453 lr 0.00025266 rank 1
2022-12-08 07:03:55,272 DEBUG TRAIN Batch 27/8200 loss 10.465534 loss_att 272.535278 loss_ctc 16.857983 loss_rnnt 9.755262 lr 0.00025263 rank 5
2022-12-08 07:03:55,273 DEBUG TRAIN Batch 27/8200 loss 7.979323 loss_att 361.318054 loss_ctc 16.555342 loss_rnnt 7.026432 lr 0.00025265 rank 2
2022-12-08 07:04:58,824 DEBUG TRAIN Batch 27/8300 loss 7.724437 loss_att 257.187286 loss_ctc 16.337017 loss_rnnt 6.767484 lr 0.00025261 rank 2
2022-12-08 07:04:58,824 DEBUG TRAIN Batch 27/8300 loss 4.684344 loss_att 186.435226 loss_ctc 9.471988 loss_rnnt 4.152383 lr 0.00025259 rank 7
2022-12-08 07:04:58,825 DEBUG TRAIN Batch 27/8300 loss 1.744976 loss_att 391.130920 loss_ctc 7.024210 loss_rnnt 1.158394 lr 0.00025260 rank 0
2022-12-08 07:04:58,825 DEBUG TRAIN Batch 27/8300 loss 6.368804 loss_att 108.000183 loss_ctc 9.361541 loss_rnnt 6.036277 lr 0.00025262 rank 1
2022-12-08 07:04:58,828 DEBUG TRAIN Batch 27/8300 loss 2.262113 loss_att 369.317749 loss_ctc 5.804400 loss_rnnt 1.868525 lr 0.00025261 rank 6
2022-12-08 07:04:58,830 DEBUG TRAIN Batch 27/8300 loss 4.020776 loss_att 396.795776 loss_ctc 11.473845 loss_rnnt 3.192657 lr 0.00025259 rank 4
2022-12-08 07:04:58,833 DEBUG TRAIN Batch 27/8300 loss 7.812086 loss_att 173.658585 loss_ctc 17.492807 loss_rnnt 6.736450 lr 0.00025259 rank 3
2022-12-08 07:04:58,869 DEBUG TRAIN Batch 27/8300 loss 8.281519 loss_att 316.051636 loss_ctc 17.929688 loss_rnnt 7.209500 lr 0.00025260 rank 5
2022-12-08 07:05:47,134 DEBUG CV Batch 27/0 loss 1.232927 loss_att 48.087494 loss_ctc 2.604557 loss_rnnt 1.080524 history loss 1.187263 rank 0
2022-12-08 07:05:47,136 DEBUG CV Batch 27/0 loss 1.232927 loss_att 48.087494 loss_ctc 2.604557 loss_rnnt 1.080524 history loss 1.187263 rank 3
2022-12-08 07:05:47,139 DEBUG CV Batch 27/0 loss 1.232927 loss_att 48.087494 loss_ctc 2.604557 loss_rnnt 1.080524 history loss 1.187263 rank 1
2022-12-08 07:05:47,139 DEBUG CV Batch 27/0 loss 1.232927 loss_att 48.087494 loss_ctc 2.604557 loss_rnnt 1.080524 history loss 1.187263 rank 6
2022-12-08 07:05:47,144 DEBUG CV Batch 27/0 loss 1.232927 loss_att 48.087494 loss_ctc 2.604557 loss_rnnt 1.080524 history loss 1.187263 rank 4
2022-12-08 07:05:47,146 DEBUG CV Batch 27/0 loss 1.232927 loss_att 48.087494 loss_ctc 2.604557 loss_rnnt 1.080524 history loss 1.187263 rank 5
2022-12-08 07:05:47,151 DEBUG CV Batch 27/0 loss 1.232927 loss_att 48.087494 loss_ctc 2.604557 loss_rnnt 1.080524 history loss 1.187263 rank 2
2022-12-08 07:05:47,153 DEBUG CV Batch 27/0 loss 1.232927 loss_att 48.087494 loss_ctc 2.604557 loss_rnnt 1.080524 history loss 1.187263 rank 7
2022-12-08 07:05:57,761 DEBUG CV Batch 27/100 loss 3.972155 loss_att 266.944458 loss_ctc 11.885974 loss_rnnt 3.092842 history loss 2.852685 rank 3
2022-12-08 07:05:57,843 DEBUG CV Batch 27/100 loss 3.972155 loss_att 266.944458 loss_ctc 11.885974 loss_rnnt 3.092842 history loss 2.852685 rank 4
2022-12-08 07:05:57,859 DEBUG CV Batch 27/100 loss 3.972155 loss_att 266.944458 loss_ctc 11.885974 loss_rnnt 3.092842 history loss 2.852685 rank 5
2022-12-08 07:05:57,874 DEBUG CV Batch 27/100 loss 3.972155 loss_att 266.944458 loss_ctc 11.885974 loss_rnnt 3.092842 history loss 2.852685 rank 0
2022-12-08 07:05:57,879 DEBUG CV Batch 27/100 loss 3.972155 loss_att 266.944458 loss_ctc 11.885974 loss_rnnt 3.092842 history loss 2.852685 rank 7
2022-12-08 07:05:58,001 DEBUG CV Batch 27/100 loss 3.972155 loss_att 266.944458 loss_ctc 11.885974 loss_rnnt 3.092842 history loss 2.852685 rank 6
2022-12-08 07:05:58,009 DEBUG CV Batch 27/100 loss 3.972155 loss_att 266.944458 loss_ctc 11.885974 loss_rnnt 3.092842 history loss 2.852685 rank 2
2022-12-08 07:05:58,112 DEBUG CV Batch 27/100 loss 3.972155 loss_att 266.944458 loss_ctc 11.885974 loss_rnnt 3.092842 history loss 2.852685 rank 1
2022-12-08 07:06:10,931 DEBUG CV Batch 27/200 loss 5.929023 loss_att 641.187012 loss_ctc 4.909511 loss_rnnt 6.042303 history loss 3.398095 rank 0
2022-12-08 07:06:10,964 DEBUG CV Batch 27/200 loss 5.929023 loss_att 641.187012 loss_ctc 4.909511 loss_rnnt 6.042303 history loss 3.398095 rank 4
2022-12-08 07:06:10,988 DEBUG CV Batch 27/200 loss 5.929023 loss_att 641.187012 loss_ctc 4.909511 loss_rnnt 6.042303 history loss 3.398095 rank 7
2022-12-08 07:06:11,448 DEBUG CV Batch 27/200 loss 5.929023 loss_att 641.187012 loss_ctc 4.909511 loss_rnnt 6.042303 history loss 3.398095 rank 3
2022-12-08 07:06:11,715 DEBUG CV Batch 27/200 loss 5.929023 loss_att 641.187012 loss_ctc 4.909511 loss_rnnt 6.042303 history loss 3.398095 rank 6
2022-12-08 07:06:11,921 DEBUG CV Batch 27/200 loss 5.929023 loss_att 641.187012 loss_ctc 4.909511 loss_rnnt 6.042303 history loss 3.398095 rank 2
2022-12-08 07:06:11,930 DEBUG CV Batch 27/200 loss 5.929023 loss_att 641.187012 loss_ctc 4.909511 loss_rnnt 6.042303 history loss 3.398095 rank 5
2022-12-08 07:06:12,166 DEBUG CV Batch 27/200 loss 5.929023 loss_att 641.187012 loss_ctc 4.909511 loss_rnnt 6.042303 history loss 3.398095 rank 1
2022-12-08 07:06:22,425 DEBUG CV Batch 27/300 loss 2.919748 loss_att 190.887970 loss_ctc 6.811913 loss_rnnt 2.487285 history loss 3.561848 rank 4
2022-12-08 07:06:22,458 DEBUG CV Batch 27/300 loss 2.919748 loss_att 190.887970 loss_ctc 6.811913 loss_rnnt 2.487285 history loss 3.561848 rank 7
2022-12-08 07:06:22,571 DEBUG CV Batch 27/300 loss 2.919748 loss_att 190.887970 loss_ctc 6.811913 loss_rnnt 2.487285 history loss 3.561848 rank 0
2022-12-08 07:06:23,057 DEBUG CV Batch 27/300 loss 2.919748 loss_att 190.887970 loss_ctc 6.811913 loss_rnnt 2.487285 history loss 3.561848 rank 3
2022-12-08 07:06:23,215 DEBUG CV Batch 27/300 loss 2.919748 loss_att 190.887970 loss_ctc 6.811913 loss_rnnt 2.487285 history loss 3.561848 rank 2
2022-12-08 07:06:23,279 DEBUG CV Batch 27/300 loss 2.919748 loss_att 190.887970 loss_ctc 6.811913 loss_rnnt 2.487285 history loss 3.561848 rank 5
2022-12-08 07:06:23,451 DEBUG CV Batch 27/300 loss 2.919748 loss_att 190.887970 loss_ctc 6.811913 loss_rnnt 2.487285 history loss 3.561848 rank 1
2022-12-08 07:06:23,473 DEBUG CV Batch 27/300 loss 2.919748 loss_att 190.887970 loss_ctc 6.811913 loss_rnnt 2.487285 history loss 3.561848 rank 6
2022-12-08 07:06:33,783 DEBUG CV Batch 27/400 loss 5.700009 loss_att 826.186096 loss_ctc 10.094432 loss_rnnt 5.211740 history loss 4.419999 rank 4
2022-12-08 07:06:33,908 DEBUG CV Batch 27/400 loss 5.700009 loss_att 826.186096 loss_ctc 10.094432 loss_rnnt 5.211740 history loss 4.419999 rank 7
2022-12-08 07:06:34,235 DEBUG CV Batch 27/400 loss 5.700009 loss_att 826.186096 loss_ctc 10.094432 loss_rnnt 5.211740 history loss 4.419999 rank 0
2022-12-08 07:06:34,433 DEBUG CV Batch 27/400 loss 5.700009 loss_att 826.186096 loss_ctc 10.094432 loss_rnnt 5.211740 history loss 4.419999 rank 2
2022-12-08 07:06:34,599 DEBUG CV Batch 27/400 loss 5.700009 loss_att 826.186096 loss_ctc 10.094432 loss_rnnt 5.211740 history loss 4.419999 rank 5
2022-12-08 07:06:34,710 DEBUG CV Batch 27/400 loss 5.700009 loss_att 826.186096 loss_ctc 10.094432 loss_rnnt 5.211740 history loss 4.419999 rank 3
2022-12-08 07:06:34,717 DEBUG CV Batch 27/400 loss 5.700009 loss_att 826.186096 loss_ctc 10.094432 loss_rnnt 5.211740 history loss 4.419999 rank 6
2022-12-08 07:06:34,807 DEBUG CV Batch 27/400 loss 5.700009 loss_att 826.186096 loss_ctc 10.094432 loss_rnnt 5.211740 history loss 4.419999 rank 1
2022-12-08 07:06:43,734 DEBUG CV Batch 27/500 loss 6.118308 loss_att 266.656250 loss_ctc 9.812390 loss_rnnt 5.707855 history loss 5.037561 rank 4
2022-12-08 07:06:43,995 DEBUG CV Batch 27/500 loss 6.118308 loss_att 266.656250 loss_ctc 9.812390 loss_rnnt 5.707855 history loss 5.037561 rank 7
2022-12-08 07:06:44,348 DEBUG CV Batch 27/500 loss 6.118308 loss_att 266.656250 loss_ctc 9.812390 loss_rnnt 5.707855 history loss 5.037561 rank 0
2022-12-08 07:06:44,370 DEBUG CV Batch 27/500 loss 6.118308 loss_att 266.656250 loss_ctc 9.812390 loss_rnnt 5.707855 history loss 5.037561 rank 3
2022-12-08 07:06:44,494 DEBUG CV Batch 27/500 loss 6.118308 loss_att 266.656250 loss_ctc 9.812390 loss_rnnt 5.707855 history loss 5.037561 rank 6
2022-12-08 07:06:45,085 DEBUG CV Batch 27/500 loss 6.118308 loss_att 266.656250 loss_ctc 9.812390 loss_rnnt 5.707855 history loss 5.037561 rank 1
2022-12-08 07:06:45,113 DEBUG CV Batch 27/500 loss 6.118308 loss_att 266.656250 loss_ctc 9.812390 loss_rnnt 5.707855 history loss 5.037561 rank 2
2022-12-08 07:06:45,214 DEBUG CV Batch 27/500 loss 6.118308 loss_att 266.656250 loss_ctc 9.812390 loss_rnnt 5.707855 history loss 5.037561 rank 5
2022-12-08 07:06:55,190 DEBUG CV Batch 27/600 loss 5.462206 loss_att 104.307762 loss_ctc 8.562524 loss_rnnt 5.117726 history loss 5.854264 rank 4
2022-12-08 07:06:55,558 DEBUG CV Batch 27/600 loss 5.462206 loss_att 104.307762 loss_ctc 8.562524 loss_rnnt 5.117726 history loss 5.854264 rank 7
2022-12-08 07:06:55,984 DEBUG CV Batch 27/600 loss 5.462206 loss_att 104.307762 loss_ctc 8.562524 loss_rnnt 5.117726 history loss 5.854264 rank 3
2022-12-08 07:06:56,112 DEBUG CV Batch 27/600 loss 5.462206 loss_att 104.307762 loss_ctc 8.562524 loss_rnnt 5.117726 history loss 5.854264 rank 0
2022-12-08 07:06:56,268 DEBUG CV Batch 27/600 loss 5.462206 loss_att 104.307762 loss_ctc 8.562524 loss_rnnt 5.117726 history loss 5.854264 rank 6
2022-12-08 07:06:57,638 DEBUG CV Batch 27/600 loss 5.462206 loss_att 104.307762 loss_ctc 8.562524 loss_rnnt 5.117726 history loss 5.854264 rank 1
2022-12-08 07:06:57,746 DEBUG CV Batch 27/600 loss 5.462206 loss_att 104.307762 loss_ctc 8.562524 loss_rnnt 5.117726 history loss 5.854264 rank 2
2022-12-08 07:06:57,888 DEBUG CV Batch 27/600 loss 5.462206 loss_att 104.307762 loss_ctc 8.562524 loss_rnnt 5.117726 history loss 5.854264 rank 5
2022-12-08 07:07:06,929 DEBUG CV Batch 27/700 loss 8.121466 loss_att 707.030334 loss_ctc 23.066626 loss_rnnt 6.460892 history loss 6.457119 rank 4
2022-12-08 07:07:07,048 DEBUG CV Batch 27/700 loss 8.121466 loss_att 707.030334 loss_ctc 23.066626 loss_rnnt 6.460892 history loss 6.457119 rank 0
2022-12-08 07:07:07,186 DEBUG CV Batch 27/700 loss 8.121466 loss_att 707.030334 loss_ctc 23.066626 loss_rnnt 6.460892 history loss 6.457119 rank 7
2022-12-08 07:07:07,486 DEBUG CV Batch 27/700 loss 8.121466 loss_att 707.030334 loss_ctc 23.066626 loss_rnnt 6.460892 history loss 6.457119 rank 3
2022-12-08 07:07:08,253 DEBUG CV Batch 27/700 loss 8.121466 loss_att 707.030334 loss_ctc 23.066626 loss_rnnt 6.460892 history loss 6.457119 rank 6
2022-12-08 07:07:09,805 DEBUG CV Batch 27/700 loss 8.121466 loss_att 707.030334 loss_ctc 23.066626 loss_rnnt 6.460892 history loss 6.457119 rank 1
2022-12-08 07:07:10,274 DEBUG CV Batch 27/700 loss 8.121466 loss_att 707.030334 loss_ctc 23.066626 loss_rnnt 6.460892 history loss 6.457119 rank 2
2022-12-08 07:07:10,648 DEBUG CV Batch 27/700 loss 8.121466 loss_att 707.030334 loss_ctc 23.066626 loss_rnnt 6.460892 history loss 6.457119 rank 5
2022-12-08 07:07:18,324 DEBUG CV Batch 27/800 loss 7.267439 loss_att 263.403809 loss_ctc 17.371269 loss_rnnt 6.144792 history loss 5.979310 rank 4
2022-12-08 07:07:18,486 DEBUG CV Batch 27/800 loss 7.267439 loss_att 263.403809 loss_ctc 17.371269 loss_rnnt 6.144792 history loss 5.979310 rank 0
2022-12-08 07:07:18,722 DEBUG CV Batch 27/800 loss 7.267439 loss_att 263.403809 loss_ctc 17.371269 loss_rnnt 6.144792 history loss 5.979310 rank 7
2022-12-08 07:07:19,067 DEBUG CV Batch 27/800 loss 7.267439 loss_att 263.403809 loss_ctc 17.371269 loss_rnnt 6.144792 history loss 5.979310 rank 3
2022-12-08 07:07:19,658 DEBUG CV Batch 27/800 loss 7.267439 loss_att 263.403809 loss_ctc 17.371269 loss_rnnt 6.144792 history loss 5.979310 rank 6
2022-12-08 07:07:22,091 DEBUG CV Batch 27/800 loss 7.267439 loss_att 263.403809 loss_ctc 17.371269 loss_rnnt 6.144792 history loss 5.979310 rank 1
2022-12-08 07:07:22,348 DEBUG CV Batch 27/800 loss 7.267439 loss_att 263.403809 loss_ctc 17.371269 loss_rnnt 6.144792 history loss 5.979310 rank 2
2022-12-08 07:07:22,671 DEBUG CV Batch 27/800 loss 7.267439 loss_att 263.403809 loss_ctc 17.371269 loss_rnnt 6.144792 history loss 5.979310 rank 5
2022-12-08 07:07:31,721 DEBUG CV Batch 27/900 loss 9.281764 loss_att 550.847900 loss_ctc 18.547491 loss_rnnt 8.252239 history loss 5.802438 rank 0
2022-12-08 07:07:31,743 DEBUG CV Batch 27/900 loss 9.281764 loss_att 550.847900 loss_ctc 18.547491 loss_rnnt 8.252239 history loss 5.802438 rank 4
2022-12-08 07:07:32,127 DEBUG CV Batch 27/900 loss 9.281764 loss_att 550.847900 loss_ctc 18.547491 loss_rnnt 8.252239 history loss 5.802438 rank 7
2022-12-08 07:07:32,221 DEBUG CV Batch 27/900 loss 9.281764 loss_att 550.847900 loss_ctc 18.547491 loss_rnnt 8.252239 history loss 5.802438 rank 3
2022-12-08 07:07:32,976 DEBUG CV Batch 27/900 loss 9.281764 loss_att 550.847900 loss_ctc 18.547491 loss_rnnt 8.252239 history loss 5.802438 rank 6
2022-12-08 07:07:35,555 DEBUG CV Batch 27/900 loss 9.281764 loss_att 550.847900 loss_ctc 18.547491 loss_rnnt 8.252239 history loss 5.802438 rank 1
2022-12-08 07:07:36,101 DEBUG CV Batch 27/900 loss 9.281764 loss_att 550.847900 loss_ctc 18.547491 loss_rnnt 8.252239 history loss 5.802438 rank 5
2022-12-08 07:07:36,158 DEBUG CV Batch 27/900 loss 9.281764 loss_att 550.847900 loss_ctc 18.547491 loss_rnnt 8.252239 history loss 5.802438 rank 2
2022-12-08 07:07:43,353 DEBUG CV Batch 27/1000 loss 2.382123 loss_att 176.487366 loss_ctc 4.255980 loss_rnnt 2.173917 history loss 5.603702 rank 4
2022-12-08 07:07:43,532 DEBUG CV Batch 27/1000 loss 2.382123 loss_att 176.487366 loss_ctc 4.255980 loss_rnnt 2.173917 history loss 5.603702 rank 0
2022-12-08 07:07:43,784 DEBUG CV Batch 27/1000 loss 2.382123 loss_att 176.487366 loss_ctc 4.255980 loss_rnnt 2.173917 history loss 5.603702 rank 3
2022-12-08 07:07:43,826 DEBUG CV Batch 27/1000 loss 2.382123 loss_att 176.487366 loss_ctc 4.255980 loss_rnnt 2.173917 history loss 5.603702 rank 7
2022-12-08 07:07:44,505 DEBUG CV Batch 27/1000 loss 2.382123 loss_att 176.487366 loss_ctc 4.255980 loss_rnnt 2.173917 history loss 5.603702 rank 6
2022-12-08 07:07:47,141 DEBUG CV Batch 27/1000 loss 2.382123 loss_att 176.487366 loss_ctc 4.255980 loss_rnnt 2.173917 history loss 5.603702 rank 1
2022-12-08 07:07:47,696 DEBUG CV Batch 27/1000 loss 2.382123 loss_att 176.487366 loss_ctc 4.255980 loss_rnnt 2.173917 history loss 5.603702 rank 2
2022-12-08 07:07:47,731 DEBUG CV Batch 27/1000 loss 2.382123 loss_att 176.487366 loss_ctc 4.255980 loss_rnnt 2.173917 history loss 5.603702 rank 5
2022-12-08 07:07:54,539 DEBUG CV Batch 27/1100 loss 5.088076 loss_att 60.694897 loss_ctc 8.362930 loss_rnnt 4.724203 history loss 5.586568 rank 4
2022-12-08 07:07:54,991 DEBUG CV Batch 27/1100 loss 5.088076 loss_att 60.694897 loss_ctc 8.362930 loss_rnnt 4.724203 history loss 5.586568 rank 0
2022-12-08 07:07:55,039 DEBUG CV Batch 27/1100 loss 5.088076 loss_att 60.694897 loss_ctc 8.362930 loss_rnnt 4.724203 history loss 5.586568 rank 3
2022-12-08 07:07:55,219 DEBUG CV Batch 27/1100 loss 5.088076 loss_att 60.694897 loss_ctc 8.362930 loss_rnnt 4.724203 history loss 5.586568 rank 7
2022-12-08 07:07:55,687 DEBUG CV Batch 27/1100 loss 5.088076 loss_att 60.694897 loss_ctc 8.362930 loss_rnnt 4.724203 history loss 5.586568 rank 6
2022-12-08 07:07:58,317 DEBUG CV Batch 27/1100 loss 5.088076 loss_att 60.694897 loss_ctc 8.362930 loss_rnnt 4.724203 history loss 5.586568 rank 1
2022-12-08 07:07:58,889 DEBUG CV Batch 27/1100 loss 5.088076 loss_att 60.694897 loss_ctc 8.362930 loss_rnnt 4.724203 history loss 5.586568 rank 2
2022-12-08 07:07:59,295 DEBUG CV Batch 27/1100 loss 5.088076 loss_att 60.694897 loss_ctc 8.362930 loss_rnnt 4.724203 history loss 5.586568 rank 5
2022-12-08 07:08:04,433 DEBUG CV Batch 27/1200 loss 7.871159 loss_att 280.458313 loss_ctc 11.229609 loss_rnnt 7.497998 history loss 5.865543 rank 4
2022-12-08 07:08:05,130 DEBUG CV Batch 27/1200 loss 7.871159 loss_att 280.458313 loss_ctc 11.229609 loss_rnnt 7.497998 history loss 5.865543 rank 0
2022-12-08 07:08:05,145 DEBUG CV Batch 27/1200 loss 7.871159 loss_att 280.458313 loss_ctc 11.229609 loss_rnnt 7.497998 history loss 5.865543 rank 3
2022-12-08 07:08:05,233 DEBUG CV Batch 27/1200 loss 7.871159 loss_att 280.458313 loss_ctc 11.229609 loss_rnnt 7.497998 history loss 5.865543 rank 7
2022-12-08 07:08:05,721 DEBUG CV Batch 27/1200 loss 7.871159 loss_att 280.458313 loss_ctc 11.229609 loss_rnnt 7.497998 history loss 5.865543 rank 6
2022-12-08 07:08:09,226 DEBUG CV Batch 27/1200 loss 7.871159 loss_att 280.458313 loss_ctc 11.229609 loss_rnnt 7.497998 history loss 5.865543 rank 1
2022-12-08 07:08:09,810 DEBUG CV Batch 27/1200 loss 7.871159 loss_att 280.458313 loss_ctc 11.229609 loss_rnnt 7.497998 history loss 5.865543 rank 2
2022-12-08 07:08:10,298 DEBUG CV Batch 27/1200 loss 7.871159 loss_att 280.458313 loss_ctc 11.229609 loss_rnnt 7.497998 history loss 5.865543 rank 5
2022-12-08 07:08:15,728 DEBUG CV Batch 27/1300 loss 5.098597 loss_att 105.976074 loss_ctc 8.805993 loss_rnnt 4.686664 history loss 6.130615 rank 4
2022-12-08 07:08:16,748 DEBUG CV Batch 27/1300 loss 5.098597 loss_att 105.976074 loss_ctc 8.805993 loss_rnnt 4.686664 history loss 6.130615 rank 0
2022-12-08 07:08:16,783 DEBUG CV Batch 27/1300 loss 5.098597 loss_att 105.976074 loss_ctc 8.805993 loss_rnnt 4.686664 history loss 6.130615 rank 3
2022-12-08 07:08:16,829 DEBUG CV Batch 27/1300 loss 5.098597 loss_att 105.976074 loss_ctc 8.805993 loss_rnnt 4.686664 history loss 6.130615 rank 7
2022-12-08 07:08:17,308 DEBUG CV Batch 27/1300 loss 5.098597 loss_att 105.976074 loss_ctc 8.805993 loss_rnnt 4.686664 history loss 6.130615 rank 6
2022-12-08 07:08:21,294 DEBUG CV Batch 27/1300 loss 5.098597 loss_att 105.976074 loss_ctc 8.805993 loss_rnnt 4.686664 history loss 6.130615 rank 1
2022-12-08 07:08:22,133 DEBUG CV Batch 27/1300 loss 5.098597 loss_att 105.976074 loss_ctc 8.805993 loss_rnnt 4.686664 history loss 6.130615 rank 2
2022-12-08 07:08:22,149 DEBUG CV Batch 27/1300 loss 5.098597 loss_att 105.976074 loss_ctc 8.805993 loss_rnnt 4.686664 history loss 6.130615 rank 5
2022-12-08 07:08:26,968 DEBUG CV Batch 27/1400 loss 3.536064 loss_att 562.088196 loss_ctc 5.810194 loss_rnnt 3.283383 history loss 6.426259 rank 4
2022-12-08 07:08:27,495 DEBUG CV Batch 27/1400 loss 3.536064 loss_att 562.088196 loss_ctc 5.810194 loss_rnnt 3.283383 history loss 6.426259 rank 0
2022-12-08 07:08:27,558 DEBUG CV Batch 27/1400 loss 3.536064 loss_att 562.088196 loss_ctc 5.810194 loss_rnnt 3.283383 history loss 6.426259 rank 7
2022-12-08 07:08:28,451 DEBUG CV Batch 27/1400 loss 3.536064 loss_att 562.088196 loss_ctc 5.810194 loss_rnnt 3.283383 history loss 6.426259 rank 3
2022-12-08 07:08:29,399 DEBUG CV Batch 27/1400 loss 3.536064 loss_att 562.088196 loss_ctc 5.810194 loss_rnnt 3.283383 history loss 6.426259 rank 6
2022-12-08 07:08:33,577 DEBUG CV Batch 27/1400 loss 3.536064 loss_att 562.088196 loss_ctc 5.810194 loss_rnnt 3.283383 history loss 6.426259 rank 1
2022-12-08 07:08:34,364 DEBUG CV Batch 27/1400 loss 3.536064 loss_att 562.088196 loss_ctc 5.810194 loss_rnnt 3.283383 history loss 6.426259 rank 2
2022-12-08 07:08:34,652 DEBUG CV Batch 27/1400 loss 3.536064 loss_att 562.088196 loss_ctc 5.810194 loss_rnnt 3.283383 history loss 6.426259 rank 5
2022-12-08 07:08:38,914 DEBUG CV Batch 27/1500 loss 8.204182 loss_att 275.485413 loss_ctc 7.907021 loss_rnnt 8.237200 history loss 6.303788 rank 4
2022-12-08 07:08:39,042 DEBUG CV Batch 27/1500 loss 8.204182 loss_att 275.485413 loss_ctc 7.907021 loss_rnnt 8.237200 history loss 6.303788 rank 0
2022-12-08 07:08:39,315 DEBUG CV Batch 27/1500 loss 8.204182 loss_att 275.485413 loss_ctc 7.907021 loss_rnnt 8.237200 history loss 6.303788 rank 7
2022-12-08 07:08:40,337 DEBUG CV Batch 27/1500 loss 8.204182 loss_att 275.485413 loss_ctc 7.907021 loss_rnnt 8.237200 history loss 6.303788 rank 3
2022-12-08 07:08:41,605 DEBUG CV Batch 27/1500 loss 8.204182 loss_att 275.485413 loss_ctc 7.907021 loss_rnnt 8.237200 history loss 6.303788 rank 6
2022-12-08 07:08:46,184 DEBUG CV Batch 27/1500 loss 8.204182 loss_att 275.485413 loss_ctc 7.907021 loss_rnnt 8.237200 history loss 6.303788 rank 1
2022-12-08 07:08:47,141 DEBUG CV Batch 27/1500 loss 8.204182 loss_att 275.485413 loss_ctc 7.907021 loss_rnnt 8.237200 history loss 6.303788 rank 2
2022-12-08 07:08:47,338 DEBUG CV Batch 27/1500 loss 8.204182 loss_att 275.485413 loss_ctc 7.907021 loss_rnnt 8.237200 history loss 6.303788 rank 5
2022-12-08 07:08:52,016 DEBUG CV Batch 27/1600 loss 6.069584 loss_att 593.907776 loss_ctc 13.536415 loss_rnnt 5.239936 history loss 6.260405 rank 4
2022-12-08 07:08:52,342 DEBUG CV Batch 27/1600 loss 6.069584 loss_att 593.907776 loss_ctc 13.536415 loss_rnnt 5.239936 history loss 6.260405 rank 0
2022-12-08 07:08:52,548 DEBUG CV Batch 27/1600 loss 6.069584 loss_att 593.907776 loss_ctc 13.536415 loss_rnnt 5.239936 history loss 6.260405 rank 7
2022-12-08 07:08:53,574 DEBUG CV Batch 27/1600 loss 6.069584 loss_att 593.907776 loss_ctc 13.536415 loss_rnnt 5.239936 history loss 6.260405 rank 3
2022-12-08 07:08:54,896 DEBUG CV Batch 27/1600 loss 6.069584 loss_att 593.907776 loss_ctc 13.536415 loss_rnnt 5.239936 history loss 6.260405 rank 6
2022-12-08 07:08:59,667 DEBUG CV Batch 27/1600 loss 6.069584 loss_att 593.907776 loss_ctc 13.536415 loss_rnnt 5.239936 history loss 6.260405 rank 1
2022-12-08 07:09:00,432 DEBUG CV Batch 27/1600 loss 6.069584 loss_att 593.907776 loss_ctc 13.536415 loss_rnnt 5.239936 history loss 6.260405 rank 2
2022-12-08 07:09:00,697 DEBUG CV Batch 27/1600 loss 6.069584 loss_att 593.907776 loss_ctc 13.536415 loss_rnnt 5.239936 history loss 6.260405 rank 5
2022-12-08 07:09:03,933 DEBUG CV Batch 27/1700 loss 7.843053 loss_att 210.845810 loss_ctc 15.357738 loss_rnnt 7.008088 history loss 6.197440 rank 4
2022-12-08 07:09:04,501 DEBUG CV Batch 27/1700 loss 7.843053 loss_att 210.845810 loss_ctc 15.357738 loss_rnnt 7.008088 history loss 6.197440 rank 0
2022-12-08 07:09:04,585 DEBUG CV Batch 27/1700 loss 7.843053 loss_att 210.845810 loss_ctc 15.357738 loss_rnnt 7.008088 history loss 6.197440 rank 7
2022-12-08 07:09:05,490 DEBUG CV Batch 27/1700 loss 7.843053 loss_att 210.845810 loss_ctc 15.357738 loss_rnnt 7.008088 history loss 6.197440 rank 3
2022-12-08 07:09:07,058 DEBUG CV Batch 27/1700 loss 7.843053 loss_att 210.845810 loss_ctc 15.357738 loss_rnnt 7.008088 history loss 6.197440 rank 6
2022-12-08 07:09:11,259 DEBUG CV Batch 27/1700 loss 7.843053 loss_att 210.845810 loss_ctc 15.357738 loss_rnnt 7.008088 history loss 6.197440 rank 1
2022-12-08 07:09:12,334 DEBUG CV Batch 27/1700 loss 7.843053 loss_att 210.845810 loss_ctc 15.357738 loss_rnnt 7.008088 history loss 6.197440 rank 2
2022-12-08 07:09:12,509 DEBUG CV Batch 27/1700 loss 7.843053 loss_att 210.845810 loss_ctc 15.357738 loss_rnnt 7.008088 history loss 6.197440 rank 5
2022-12-08 07:09:12,756 INFO Epoch 27 CV info cv_loss 6.178655887184408
2022-12-08 07:09:12,757 INFO Epoch 28 TRAIN info lr 0.00025257422074724425
2022-12-08 07:09:12,758 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 07:09:13,403 INFO Epoch 27 CV info cv_loss 6.178655887184408
2022-12-08 07:09:13,404 INFO Epoch 28 TRAIN info lr 0.0002525751875119993
2022-12-08 07:09:13,408 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 07:09:13,470 INFO Epoch 27 CV info cv_loss 6.178655887184408
2022-12-08 07:09:13,470 INFO Checkpoint: save to checkpoint exp/1204_encoder_bias_nobi_noatt/27.pt
2022-12-08 07:09:14,024 INFO Epoch 28 TRAIN info lr 0.00025257325399359034
2022-12-08 07:09:14,028 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 07:09:14,722 INFO Epoch 27 CV info cv_loss 6.178655887184408
2022-12-08 07:09:14,722 INFO Epoch 28 TRAIN info lr 0.00025258356660492424
2022-12-08 07:09:14,724 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 07:09:16,184 INFO Epoch 27 CV info cv_loss 6.178655887184408
2022-12-08 07:09:16,185 INFO Epoch 28 TRAIN info lr 0.0002526058074722506
2022-12-08 07:09:16,189 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 07:09:20,015 INFO Epoch 27 CV info cv_loss 6.178655887184408
2022-12-08 07:09:20,015 INFO Epoch 28 TRAIN info lr 0.0002526125775981048
2022-12-08 07:09:20,019 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 07:09:21,163 INFO Epoch 27 CV info cv_loss 6.178655887184408
2022-12-08 07:09:21,164 INFO Epoch 28 TRAIN info lr 0.0002526041956177514
2022-12-08 07:09:21,165 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 07:09:21,409 INFO Epoch 27 CV info cv_loss 6.178655887184408
2022-12-08 07:09:21,409 INFO Epoch 28 TRAIN info lr 0.00025259097957461567
2022-12-08 07:09:21,411 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 07:10:22,989 DEBUG TRAIN Batch 28/0 loss 7.941001 loss_att 64.845016 loss_ctc 12.788232 loss_rnnt 7.402420 lr 0.00025257 rank 0
2022-12-08 07:10:22,992 DEBUG TRAIN Batch 28/0 loss 8.312665 loss_att 87.663773 loss_ctc 11.183506 loss_rnnt 7.993683 lr 0.00025257 rank 7
2022-12-08 07:10:22,994 DEBUG TRAIN Batch 28/0 loss 7.702778 loss_att 67.731285 loss_ctc 11.961730 loss_rnnt 7.229561 lr 0.00025261 rank 6
2022-12-08 07:10:22,999 DEBUG TRAIN Batch 28/0 loss 5.885930 loss_att 63.910374 loss_ctc 9.065237 loss_rnnt 5.532673 lr 0.00025257 rank 4
2022-12-08 07:10:23,010 DEBUG TRAIN Batch 28/0 loss 7.985076 loss_att 67.406441 loss_ctc 11.722441 loss_rnnt 7.569813 lr 0.00025258 rank 3
2022-12-08 07:10:23,031 DEBUG TRAIN Batch 28/0 loss 9.871319 loss_att 65.735420 loss_ctc 13.185627 loss_rnnt 9.503063 lr 0.00025260 rank 2
2022-12-08 07:10:23,033 DEBUG TRAIN Batch 28/0 loss 5.239069 loss_att 67.658752 loss_ctc 7.882975 loss_rnnt 4.945301 lr 0.00025261 rank 1
2022-12-08 07:10:23,060 DEBUG TRAIN Batch 28/0 loss 7.421242 loss_att 70.758850 loss_ctc 12.092603 loss_rnnt 6.902202 lr 0.00025259 rank 5
2022-12-08 07:11:25,547 DEBUG TRAIN Batch 28/100 loss 4.972634 loss_att 392.387939 loss_ctc 8.753557 loss_rnnt 4.552532 lr 0.00025254 rank 4
2022-12-08 07:11:25,549 DEBUG TRAIN Batch 28/100 loss 9.834442 loss_att 356.579315 loss_ctc 19.847328 loss_rnnt 8.721899 lr 0.00025257 rank 6
2022-12-08 07:11:25,550 DEBUG TRAIN Batch 28/100 loss 1.981112 loss_att 442.024017 loss_ctc 6.311649 loss_rnnt 1.499941 lr 0.00025255 rank 3
2022-12-08 07:11:25,553 DEBUG TRAIN Batch 28/100 loss 7.271571 loss_att 301.090179 loss_ctc 17.463064 loss_rnnt 6.139183 lr 0.00025254 rank 0
2022-12-08 07:11:25,554 DEBUG TRAIN Batch 28/100 loss 6.463901 loss_att 396.343262 loss_ctc 11.224287 loss_rnnt 5.934969 lr 0.00025254 rank 7
2022-12-08 07:11:25,555 DEBUG TRAIN Batch 28/100 loss 5.617213 loss_att 425.717102 loss_ctc 14.830722 loss_rnnt 4.593490 lr 0.00025257 rank 2
2022-12-08 07:11:25,558 DEBUG TRAIN Batch 28/100 loss 9.787121 loss_att 392.233734 loss_ctc 17.198195 loss_rnnt 8.963669 lr 0.00025258 rank 1
2022-12-08 07:11:25,560 DEBUG TRAIN Batch 28/100 loss 2.081173 loss_att 329.496521 loss_ctc 5.876201 loss_rnnt 1.659503 lr 0.00025256 rank 5
2022-12-08 07:12:28,067 DEBUG TRAIN Batch 28/200 loss 5.190220 loss_att 422.053406 loss_ctc 12.849394 loss_rnnt 4.339201 lr 0.00025252 rank 3
2022-12-08 07:12:28,076 DEBUG TRAIN Batch 28/200 loss 5.182954 loss_att 371.312592 loss_ctc 8.872275 loss_rnnt 4.773029 lr 0.00025251 rank 7
2022-12-08 07:12:28,077 DEBUG TRAIN Batch 28/200 loss 3.282897 loss_att 385.230896 loss_ctc 10.153954 loss_rnnt 2.519446 lr 0.00025254 rank 2
2022-12-08 07:12:28,078 DEBUG TRAIN Batch 28/200 loss 9.165482 loss_att 425.775940 loss_ctc 21.050056 loss_rnnt 7.844974 lr 0.00025254 rank 6
2022-12-08 07:12:28,080 DEBUG TRAIN Batch 28/200 loss 5.490676 loss_att 341.859741 loss_ctc 10.342266 loss_rnnt 4.951611 lr 0.00025255 rank 1
2022-12-08 07:12:28,080 DEBUG TRAIN Batch 28/200 loss 11.926516 loss_att 385.252014 loss_ctc 18.774178 loss_rnnt 11.165665 lr 0.00025253 rank 5
2022-12-08 07:12:28,082 DEBUG TRAIN Batch 28/200 loss 7.975438 loss_att 483.596649 loss_ctc 17.243465 loss_rnnt 6.945657 lr 0.00025251 rank 0
2022-12-08 07:12:28,084 DEBUG TRAIN Batch 28/200 loss 2.764655 loss_att 365.686157 loss_ctc 5.793322 loss_rnnt 2.428137 lr 0.00025251 rank 4
2022-12-08 07:13:32,120 DEBUG TRAIN Batch 28/300 loss 8.023363 loss_att 346.237335 loss_ctc 12.988982 loss_rnnt 7.471627 lr 0.00025249 rank 3
2022-12-08 07:13:32,120 DEBUG TRAIN Batch 28/300 loss 5.769674 loss_att 426.549744 loss_ctc 19.345976 loss_rnnt 4.261196 lr 0.00025251 rank 6
2022-12-08 07:13:32,121 DEBUG TRAIN Batch 28/300 loss 8.914003 loss_att 395.990967 loss_ctc 21.123831 loss_rnnt 7.557356 lr 0.00025252 rank 1
2022-12-08 07:13:32,124 DEBUG TRAIN Batch 28/300 loss 2.761864 loss_att 328.797821 loss_ctc 5.419065 loss_rnnt 2.466619 lr 0.00025249 rank 5
2022-12-08 07:13:32,128 DEBUG TRAIN Batch 28/300 loss 10.067062 loss_att 334.900879 loss_ctc 24.114021 loss_rnnt 8.506289 lr 0.00025248 rank 0
2022-12-08 07:13:32,149 DEBUG TRAIN Batch 28/300 loss 14.657219 loss_att 408.119171 loss_ctc 26.843121 loss_rnnt 13.303230 lr 0.00025248 rank 7
2022-12-08 07:13:32,159 DEBUG TRAIN Batch 28/300 loss 6.799967 loss_att 348.934998 loss_ctc 11.678324 loss_rnnt 6.257927 lr 0.00025248 rank 4
2022-12-08 07:13:32,162 DEBUG TRAIN Batch 28/300 loss 3.258123 loss_att 321.044495 loss_ctc 4.378360 loss_rnnt 3.133653 lr 0.00025251 rank 2
2022-12-08 07:14:43,201 DEBUG TRAIN Batch 28/400 loss 8.789923 loss_att 372.451233 loss_ctc 16.035374 loss_rnnt 7.984872 lr 0.00025245 rank 4
2022-12-08 07:14:43,211 DEBUG TRAIN Batch 28/400 loss 17.399153 loss_att 341.985901 loss_ctc 22.553261 loss_rnnt 16.826475 lr 0.00025244 rank 0
2022-12-08 07:14:43,225 DEBUG TRAIN Batch 28/400 loss 9.834835 loss_att 328.807861 loss_ctc 13.817997 loss_rnnt 9.392262 lr 0.00025248 rank 2
2022-12-08 07:14:43,225 DEBUG TRAIN Batch 28/400 loss 12.431596 loss_att 403.768921 loss_ctc 19.533360 loss_rnnt 11.642511 lr 0.00025245 rank 3
2022-12-08 07:14:43,226 DEBUG TRAIN Batch 28/400 loss 9.752620 loss_att 372.838440 loss_ctc 20.596447 loss_rnnt 8.547750 lr 0.00025245 rank 7
2022-12-08 07:14:43,226 DEBUG TRAIN Batch 28/400 loss 6.444548 loss_att 377.629059 loss_ctc 13.578480 loss_rnnt 5.651888 lr 0.00025246 rank 5
2022-12-08 07:14:43,227 DEBUG TRAIN Batch 28/400 loss 16.266706 loss_att 366.703125 loss_ctc 28.794189 loss_rnnt 14.874765 lr 0.00025248 rank 6
2022-12-08 07:14:43,227 DEBUG TRAIN Batch 28/400 loss 4.377158 loss_att 357.305786 loss_ctc 7.255941 loss_rnnt 4.057293 lr 0.00025248 rank 1
2022-12-08 07:15:46,777 DEBUG TRAIN Batch 28/500 loss 5.870285 loss_att 352.962494 loss_ctc 11.484959 loss_rnnt 5.246432 lr 0.00025241 rank 4
2022-12-08 07:15:46,778 DEBUG TRAIN Batch 28/500 loss 11.931250 loss_att 368.653625 loss_ctc 19.952463 loss_rnnt 11.040005 lr 0.00025244 rank 6
2022-12-08 07:15:46,779 DEBUG TRAIN Batch 28/500 loss 10.113509 loss_att 287.657959 loss_ctc 18.112629 loss_rnnt 9.224718 lr 0.00025244 rank 2
2022-12-08 07:15:46,780 DEBUG TRAIN Batch 28/500 loss 7.803897 loss_att 325.832581 loss_ctc 12.910031 loss_rnnt 7.236549 lr 0.00025241 rank 7
2022-12-08 07:15:46,783 DEBUG TRAIN Batch 28/500 loss 16.626085 loss_att 370.020142 loss_ctc 30.726063 loss_rnnt 15.059421 lr 0.00025245 rank 1
2022-12-08 07:15:46,783 DEBUG TRAIN Batch 28/500 loss 5.449293 loss_att 316.059692 loss_ctc 17.368721 loss_rnnt 4.124912 lr 0.00025243 rank 5
2022-12-08 07:15:46,783 DEBUG TRAIN Batch 28/500 loss 2.815871 loss_att 301.176758 loss_ctc 6.604028 loss_rnnt 2.394965 lr 0.00025241 rank 0
2022-12-08 07:15:46,823 DEBUG TRAIN Batch 28/500 loss 7.109234 loss_att 369.393616 loss_ctc 16.472563 loss_rnnt 6.068864 lr 0.00025242 rank 3
2022-12-08 07:16:49,987 DEBUG TRAIN Batch 28/600 loss 4.526868 loss_att 168.583496 loss_ctc 7.053352 loss_rnnt 4.246148 lr 0.00025238 rank 7
2022-12-08 07:16:49,990 DEBUG TRAIN Batch 28/600 loss 6.759727 loss_att 222.134903 loss_ctc 12.011735 loss_rnnt 6.176171 lr 0.00025238 rank 4
2022-12-08 07:16:49,991 DEBUG TRAIN Batch 28/600 loss 9.604221 loss_att 294.129913 loss_ctc 16.584768 loss_rnnt 8.828605 lr 0.00025241 rank 6
2022-12-08 07:16:49,993 DEBUG TRAIN Batch 28/600 loss 2.469679 loss_att 244.040024 loss_ctc 6.962869 loss_rnnt 1.970436 lr 0.00025239 rank 3
2022-12-08 07:16:49,997 DEBUG TRAIN Batch 28/600 loss 6.237643 loss_att 179.991623 loss_ctc 13.221204 loss_rnnt 5.461692 lr 0.00025241 rank 2
2022-12-08 07:16:49,999 DEBUG TRAIN Batch 28/600 loss 6.468190 loss_att 143.282227 loss_ctc 12.941309 loss_rnnt 5.748954 lr 0.00025238 rank 0
2022-12-08 07:16:49,999 DEBUG TRAIN Batch 28/600 loss 6.786556 loss_att 246.892883 loss_ctc 14.673536 loss_rnnt 5.910225 lr 0.00025240 rank 5
2022-12-08 07:16:50,000 DEBUG TRAIN Batch 28/600 loss 8.575636 loss_att 231.908005 loss_ctc 17.416201 loss_rnnt 7.593351 lr 0.00025242 rank 1
2022-12-08 07:17:55,263 DEBUG TRAIN Batch 28/700 loss 5.030024 loss_att 369.526215 loss_ctc 19.190308 loss_rnnt 3.456659 lr 0.00025237 rank 5
2022-12-08 07:17:55,270 DEBUG TRAIN Batch 28/700 loss 6.142470 loss_att 398.039062 loss_ctc 14.518169 loss_rnnt 5.211837 lr 0.00025235 rank 4
2022-12-08 07:17:55,272 DEBUG TRAIN Batch 28/700 loss 4.603188 loss_att 387.974701 loss_ctc 10.987518 loss_rnnt 3.893817 lr 0.00025238 rank 6
2022-12-08 07:17:55,272 DEBUG TRAIN Batch 28/700 loss 10.848120 loss_att 431.582153 loss_ctc 22.697643 loss_rnnt 9.531506 lr 0.00025236 rank 3
2022-12-08 07:17:55,272 DEBUG TRAIN Batch 28/700 loss 15.652274 loss_att 464.320801 loss_ctc 27.826330 loss_rnnt 14.299602 lr 0.00025239 rank 1
2022-12-08 07:17:55,274 DEBUG TRAIN Batch 28/700 loss 7.197662 loss_att 386.704102 loss_ctc 11.109385 loss_rnnt 6.763027 lr 0.00025238 rank 2
2022-12-08 07:17:55,277 DEBUG TRAIN Batch 28/700 loss 12.668646 loss_att 368.456055 loss_ctc 21.927856 loss_rnnt 11.639845 lr 0.00025235 rank 0
2022-12-08 07:17:55,302 DEBUG TRAIN Batch 28/700 loss 6.072795 loss_att 399.093872 loss_ctc 10.505423 loss_rnnt 5.580281 lr 0.00025235 rank 7
2022-12-08 07:19:04,960 DEBUG TRAIN Batch 28/800 loss 10.765497 loss_att 384.930420 loss_ctc 16.511139 loss_rnnt 10.127093 lr 0.00025232 rank 7
2022-12-08 07:19:04,961 DEBUG TRAIN Batch 28/800 loss 7.823991 loss_att 409.705414 loss_ctc 11.247517 loss_rnnt 7.443599 lr 0.00025232 rank 4
2022-12-08 07:19:04,962 DEBUG TRAIN Batch 28/800 loss 1.898918 loss_att 346.154999 loss_ctc 5.794852 loss_rnnt 1.466036 lr 0.00025235 rank 2
2022-12-08 07:19:04,963 DEBUG TRAIN Batch 28/800 loss 6.667765 loss_att 389.553070 loss_ctc 8.832096 loss_rnnt 6.427283 lr 0.00025235 rank 1
2022-12-08 07:19:04,964 DEBUG TRAIN Batch 28/800 loss 6.099977 loss_att 362.493744 loss_ctc 9.852802 loss_rnnt 5.682997 lr 0.00025235 rank 6
2022-12-08 07:19:04,966 DEBUG TRAIN Batch 28/800 loss 8.706695 loss_att 474.718445 loss_ctc 19.904520 loss_rnnt 7.462492 lr 0.00025233 rank 5
2022-12-08 07:19:04,967 DEBUG TRAIN Batch 28/800 loss 4.569374 loss_att 363.829803 loss_ctc 11.952383 loss_rnnt 3.749040 lr 0.00025232 rank 0
2022-12-08 07:19:04,972 DEBUG TRAIN Batch 28/800 loss 11.000219 loss_att 356.703918 loss_ctc 21.070076 loss_rnnt 9.881347 lr 0.00025233 rank 3
2022-12-08 07:20:07,968 DEBUG TRAIN Batch 28/900 loss 5.434006 loss_att 330.572571 loss_ctc 8.050280 loss_rnnt 5.143309 lr 0.00025228 rank 4
2022-12-08 07:20:07,970 DEBUG TRAIN Batch 28/900 loss 8.597568 loss_att 373.674377 loss_ctc 16.094059 loss_rnnt 7.764625 lr 0.00025229 rank 7
2022-12-08 07:20:07,972 DEBUG TRAIN Batch 28/900 loss 3.224276 loss_att 394.390839 loss_ctc 8.587519 loss_rnnt 2.628361 lr 0.00025229 rank 3
2022-12-08 07:20:07,977 DEBUG TRAIN Batch 28/900 loss 7.986622 loss_att 386.372284 loss_ctc 16.457262 loss_rnnt 7.045440 lr 0.00025232 rank 6
2022-12-08 07:20:07,978 DEBUG TRAIN Batch 28/900 loss 5.180589 loss_att 394.897522 loss_ctc 15.061210 loss_rnnt 4.082742 lr 0.00025228 rank 0
2022-12-08 07:20:07,979 DEBUG TRAIN Batch 28/900 loss 15.069378 loss_att 381.270264 loss_ctc 22.204166 loss_rnnt 14.276624 lr 0.00025230 rank 5
2022-12-08 07:20:07,982 DEBUG TRAIN Batch 28/900 loss 7.904951 loss_att 376.995941 loss_ctc 13.436607 loss_rnnt 7.290323 lr 0.00025232 rank 1
2022-12-08 07:20:08,015 DEBUG TRAIN Batch 28/900 loss 2.915041 loss_att 408.345032 loss_ctc 5.896179 loss_rnnt 2.583803 lr 0.00025231 rank 2
2022-12-08 07:21:11,840 DEBUG TRAIN Batch 28/1000 loss 6.749983 loss_att 373.349792 loss_ctc 11.193287 loss_rnnt 6.256283 lr 0.00025228 rank 6
2022-12-08 07:21:11,856 DEBUG TRAIN Batch 28/1000 loss 7.648253 loss_att 355.802521 loss_ctc 18.945389 loss_rnnt 6.393016 lr 0.00025225 rank 7
2022-12-08 07:21:11,857 DEBUG TRAIN Batch 28/1000 loss 5.381916 loss_att 388.220581 loss_ctc 14.313327 loss_rnnt 4.389537 lr 0.00025225 rank 4
2022-12-08 07:21:11,857 DEBUG TRAIN Batch 28/1000 loss 5.442674 loss_att 343.262085 loss_ctc 17.290739 loss_rnnt 4.126223 lr 0.00025227 rank 5
2022-12-08 07:21:11,860 DEBUG TRAIN Batch 28/1000 loss 8.328528 loss_att 377.582428 loss_ctc 18.903820 loss_rnnt 7.153496 lr 0.00025229 rank 1
2022-12-08 07:21:11,885 DEBUG TRAIN Batch 28/1000 loss 10.821688 loss_att 292.342285 loss_ctc 17.767832 loss_rnnt 10.049894 lr 0.00025225 rank 0
2022-12-08 07:21:11,892 DEBUG TRAIN Batch 28/1000 loss 8.397326 loss_att 400.747681 loss_ctc 16.884871 loss_rnnt 7.454265 lr 0.00025226 rank 3
2022-12-08 07:21:11,913 DEBUG TRAIN Batch 28/1000 loss 10.618053 loss_att 385.273529 loss_ctc 20.678658 loss_rnnt 9.500208 lr 0.00025228 rank 2
2022-12-08 07:22:23,293 DEBUG TRAIN Batch 28/1100 loss 24.628994 loss_att 436.918365 loss_ctc 38.935226 loss_rnnt 23.039413 lr 0.00025222 rank 4
2022-12-08 07:22:23,297 DEBUG TRAIN Batch 28/1100 loss 10.825089 loss_att 374.773132 loss_ctc 17.249825 loss_rnnt 10.111230 lr 0.00025225 rank 6
2022-12-08 07:22:23,299 DEBUG TRAIN Batch 28/1100 loss 9.278866 loss_att 359.371552 loss_ctc 17.931850 loss_rnnt 8.317423 lr 0.00025225 rank 2
2022-12-08 07:22:23,300 DEBUG TRAIN Batch 28/1100 loss 6.172334 loss_att 353.825500 loss_ctc 15.772888 loss_rnnt 5.105605 lr 0.00025222 rank 7
2022-12-08 07:22:23,300 DEBUG TRAIN Batch 28/1100 loss 6.489530 loss_att 336.648743 loss_ctc 11.845599 loss_rnnt 5.894412 lr 0.00025223 rank 3
2022-12-08 07:22:23,301 DEBUG TRAIN Batch 28/1100 loss 11.491165 loss_att 405.286194 loss_ctc 23.407444 loss_rnnt 10.167135 lr 0.00025226 rank 1
2022-12-08 07:22:23,304 DEBUG TRAIN Batch 28/1100 loss 10.092753 loss_att 330.773346 loss_ctc 17.373055 loss_rnnt 9.283831 lr 0.00025222 rank 0
2022-12-08 07:22:23,304 DEBUG TRAIN Batch 28/1100 loss 9.560221 loss_att 395.125305 loss_ctc 20.352825 loss_rnnt 8.361043 lr 0.00025224 rank 5
2022-12-08 07:23:26,295 DEBUG TRAIN Batch 28/1200 loss 5.627604 loss_att 314.019592 loss_ctc 8.792830 loss_rnnt 5.275913 lr 0.00025219 rank 4
2022-12-08 07:23:26,301 DEBUG TRAIN Batch 28/1200 loss 9.905290 loss_att 306.328247 loss_ctc 19.203176 loss_rnnt 8.872191 lr 0.00025222 rank 6
2022-12-08 07:23:26,302 DEBUG TRAIN Batch 28/1200 loss 10.306490 loss_att 217.300980 loss_ctc 21.406229 loss_rnnt 9.073186 lr 0.00025219 rank 7
2022-12-08 07:23:26,302 DEBUG TRAIN Batch 28/1200 loss 3.130332 loss_att 282.089844 loss_ctc 8.693899 loss_rnnt 2.512158 lr 0.00025222 rank 2
2022-12-08 07:23:26,303 DEBUG TRAIN Batch 28/1200 loss 7.297317 loss_att 263.793091 loss_ctc 13.581725 loss_rnnt 6.599050 lr 0.00025219 rank 0
2022-12-08 07:23:26,307 DEBUG TRAIN Batch 28/1200 loss 4.421237 loss_att 316.364929 loss_ctc 11.804393 loss_rnnt 3.600886 lr 0.00025220 rank 3
2022-12-08 07:23:26,309 DEBUG TRAIN Batch 28/1200 loss 8.672615 loss_att 323.142365 loss_ctc 18.032515 loss_rnnt 7.632627 lr 0.00025223 rank 1
2022-12-08 07:23:26,345 DEBUG TRAIN Batch 28/1200 loss 7.558373 loss_att 231.301910 loss_ctc 15.744354 loss_rnnt 6.648820 lr 0.00025220 rank 5
2022-12-08 07:24:29,456 DEBUG TRAIN Batch 28/1300 loss 11.334480 loss_att 411.666229 loss_ctc 21.245319 loss_rnnt 10.233276 lr 0.00025216 rank 4
2022-12-08 07:24:29,460 DEBUG TRAIN Batch 28/1300 loss 6.764609 loss_att 377.383484 loss_ctc 17.960785 loss_rnnt 5.520589 lr 0.00025216 rank 7
2022-12-08 07:24:29,461 DEBUG TRAIN Batch 28/1300 loss 8.183562 loss_att 167.441940 loss_ctc 10.681846 loss_rnnt 7.905975 lr 0.00025217 rank 3
2022-12-08 07:24:29,462 DEBUG TRAIN Batch 28/1300 loss 6.221621 loss_att 93.105904 loss_ctc 8.620248 loss_rnnt 5.955107 lr 0.00025219 rank 1
2022-12-08 07:24:29,464 DEBUG TRAIN Batch 28/1300 loss 7.301835 loss_att 373.454590 loss_ctc 18.170738 loss_rnnt 6.094179 lr 0.00025219 rank 2
2022-12-08 07:24:29,464 DEBUG TRAIN Batch 28/1300 loss 7.658803 loss_att 492.778809 loss_ctc 21.898518 loss_rnnt 6.076612 lr 0.00025219 rank 6
2022-12-08 07:24:29,466 DEBUG TRAIN Batch 28/1300 loss 4.977316 loss_att 407.635590 loss_ctc 17.308994 loss_rnnt 3.607130 lr 0.00025217 rank 5
2022-12-08 07:24:29,467 DEBUG TRAIN Batch 28/1300 loss 3.711510 loss_att 357.059204 loss_ctc 8.481495 loss_rnnt 3.181512 lr 0.00025216 rank 0
2022-12-08 07:25:34,055 DEBUG TRAIN Batch 28/1400 loss 6.561671 loss_att 349.853882 loss_ctc 16.441380 loss_rnnt 5.463926 lr 0.00025215 rank 2
2022-12-08 07:25:34,055 DEBUG TRAIN Batch 28/1400 loss 7.262002 loss_att 425.475922 loss_ctc 18.051411 loss_rnnt 6.063179 lr 0.00025216 rank 6
2022-12-08 07:25:34,056 DEBUG TRAIN Batch 28/1400 loss 4.565892 loss_att 388.405365 loss_ctc 8.942006 loss_rnnt 4.079657 lr 0.00025212 rank 4
2022-12-08 07:25:34,057 DEBUG TRAIN Batch 28/1400 loss 14.052947 loss_att 312.091919 loss_ctc 20.140848 loss_rnnt 13.376514 lr 0.00025212 rank 7
2022-12-08 07:25:34,056 DEBUG TRAIN Batch 28/1400 loss 6.677457 loss_att 436.941772 loss_ctc 15.637630 loss_rnnt 5.681882 lr 0.00025216 rank 1
2022-12-08 07:25:34,059 DEBUG TRAIN Batch 28/1400 loss 3.525326 loss_att 398.776367 loss_ctc 9.803968 loss_rnnt 2.827699 lr 0.00025214 rank 5
2022-12-08 07:25:34,064 DEBUG TRAIN Batch 28/1400 loss 6.500287 loss_att 475.479675 loss_ctc 21.273300 loss_rnnt 4.858841 lr 0.00025212 rank 0
2022-12-08 07:25:34,095 DEBUG TRAIN Batch 28/1400 loss 11.420218 loss_att 388.000488 loss_ctc 25.673805 loss_rnnt 9.836487 lr 0.00025213 rank 3
2022-12-08 07:26:43,534 DEBUG TRAIN Batch 28/1500 loss 9.433879 loss_att 409.487183 loss_ctc 27.150297 loss_rnnt 7.465388 lr 0.00025212 rank 2
2022-12-08 07:26:43,541 DEBUG TRAIN Batch 28/1500 loss 9.778631 loss_att 400.892212 loss_ctc 20.086121 loss_rnnt 8.633354 lr 0.00025209 rank 0
2022-12-08 07:26:43,543 DEBUG TRAIN Batch 28/1500 loss 8.203514 loss_att 332.041870 loss_ctc 12.465513 loss_rnnt 7.729959 lr 0.00025209 rank 4
2022-12-08 07:26:43,544 DEBUG TRAIN Batch 28/1500 loss 10.642954 loss_att 406.333893 loss_ctc 27.170382 loss_rnnt 8.806574 lr 0.00025209 rank 7
2022-12-08 07:26:43,545 DEBUG TRAIN Batch 28/1500 loss 11.014151 loss_att 431.182739 loss_ctc 29.501186 loss_rnnt 8.960035 lr 0.00025210 rank 3
2022-12-08 07:26:43,545 DEBUG TRAIN Batch 28/1500 loss 12.124507 loss_att 433.161713 loss_ctc 21.196838 loss_rnnt 11.116470 lr 0.00025211 rank 5
2022-12-08 07:26:43,548 DEBUG TRAIN Batch 28/1500 loss 3.215922 loss_att 389.754150 loss_ctc 10.115810 loss_rnnt 2.449268 lr 0.00025212 rank 6
2022-12-08 07:26:43,585 DEBUG TRAIN Batch 28/1500 loss 4.596858 loss_att 355.175140 loss_ctc 10.477043 loss_rnnt 3.943504 lr 0.00025213 rank 1
2022-12-08 07:27:46,448 DEBUG TRAIN Batch 28/1600 loss 11.125448 loss_att 403.669220 loss_ctc 22.314604 loss_rnnt 9.882209 lr 0.00025209 rank 2
2022-12-08 07:27:46,449 DEBUG TRAIN Batch 28/1600 loss 11.991144 loss_att 342.553040 loss_ctc 29.994068 loss_rnnt 9.990820 lr 0.00025207 rank 3
2022-12-08 07:27:46,449 DEBUG TRAIN Batch 28/1600 loss 5.609522 loss_att 421.690369 loss_ctc 12.226669 loss_rnnt 4.874284 lr 0.00025209 rank 6
2022-12-08 07:27:46,449 DEBUG TRAIN Batch 28/1600 loss 11.073720 loss_att 396.142944 loss_ctc 20.286022 loss_rnnt 10.050131 lr 0.00025210 rank 1
2022-12-08 07:27:46,453 DEBUG TRAIN Batch 28/1600 loss 7.293848 loss_att 350.888397 loss_ctc 16.153751 loss_rnnt 6.309415 lr 0.00025208 rank 5
2022-12-08 07:27:46,464 DEBUG TRAIN Batch 28/1600 loss 4.094045 loss_att 357.186096 loss_ctc 8.526150 loss_rnnt 3.601588 lr 0.00025206 rank 0
2022-12-08 07:27:46,465 DEBUG TRAIN Batch 28/1600 loss 4.221449 loss_att 378.543518 loss_ctc 7.744077 loss_rnnt 3.830046 lr 0.00025206 rank 7
2022-12-08 07:27:46,481 DEBUG TRAIN Batch 28/1600 loss 8.540407 loss_att 385.794464 loss_ctc 19.996023 loss_rnnt 7.267562 lr 0.00025206 rank 4
2022-12-08 07:28:49,779 DEBUG TRAIN Batch 28/1700 loss 5.599199 loss_att 353.624390 loss_ctc 9.415572 loss_rnnt 5.175158 lr 0.00025203 rank 4
2022-12-08 07:28:49,779 DEBUG TRAIN Batch 28/1700 loss 5.726536 loss_att 341.502380 loss_ctc 10.084190 loss_rnnt 5.242352 lr 0.00025206 rank 2
2022-12-08 07:28:49,782 DEBUG TRAIN Batch 28/1700 loss 6.347884 loss_att 373.579224 loss_ctc 15.551630 loss_rnnt 5.325246 lr 0.00025204 rank 3
2022-12-08 07:28:49,783 DEBUG TRAIN Batch 28/1700 loss 2.290464 loss_att 302.918671 loss_ctc 4.785989 loss_rnnt 2.013184 lr 0.00025203 rank 7
2022-12-08 07:28:49,783 DEBUG TRAIN Batch 28/1700 loss 10.790817 loss_att 412.796204 loss_ctc 25.383551 loss_rnnt 9.169403 lr 0.00025207 rank 1
2022-12-08 07:28:49,787 DEBUG TRAIN Batch 28/1700 loss 4.696911 loss_att 295.508972 loss_ctc 14.244715 loss_rnnt 3.636045 lr 0.00025204 rank 5
2022-12-08 07:28:49,788 DEBUG TRAIN Batch 28/1700 loss 11.391100 loss_att 286.416626 loss_ctc 18.276720 loss_rnnt 10.626031 lr 0.00025203 rank 0
2022-12-08 07:28:49,821 DEBUG TRAIN Batch 28/1700 loss 6.302312 loss_att 340.889526 loss_ctc 13.909500 loss_rnnt 5.457069 lr 0.00025206 rank 6
2022-12-08 07:30:02,639 DEBUG TRAIN Batch 28/1800 loss 7.509912 loss_att 320.557495 loss_ctc 15.741779 loss_rnnt 6.595260 lr 0.00025200 rank 4
2022-12-08 07:30:02,639 DEBUG TRAIN Batch 28/1800 loss 5.515557 loss_att 234.493362 loss_ctc 11.534932 loss_rnnt 4.846738 lr 0.00025200 rank 7
2022-12-08 07:30:02,640 DEBUG TRAIN Batch 28/1800 loss 11.858039 loss_att 299.731750 loss_ctc 19.106499 loss_rnnt 11.052654 lr 0.00025201 rank 3
2022-12-08 07:30:02,641 DEBUG TRAIN Batch 28/1800 loss 6.841857 loss_att 309.524353 loss_ctc 14.390922 loss_rnnt 6.003073 lr 0.00025203 rank 6
2022-12-08 07:30:02,641 DEBUG TRAIN Batch 28/1800 loss 3.741978 loss_att 299.976349 loss_ctc 11.204642 loss_rnnt 2.912793 lr 0.00025203 rank 2
2022-12-08 07:30:02,643 DEBUG TRAIN Batch 28/1800 loss 4.922804 loss_att 366.610565 loss_ctc 12.036056 loss_rnnt 4.132443 lr 0.00025203 rank 1
2022-12-08 07:30:02,643 DEBUG TRAIN Batch 28/1800 loss 4.763003 loss_att 357.610657 loss_ctc 12.621385 loss_rnnt 3.889850 lr 0.00025201 rank 5
2022-12-08 07:30:02,647 DEBUG TRAIN Batch 28/1800 loss 8.212171 loss_att 270.449310 loss_ctc 13.167221 loss_rnnt 7.661609 lr 0.00025199 rank 0
2022-12-08 07:31:05,938 DEBUG TRAIN Batch 28/1900 loss 9.338012 loss_att 361.738953 loss_ctc 15.714748 loss_rnnt 8.629486 lr 0.00025196 rank 0
2022-12-08 07:31:05,941 DEBUG TRAIN Batch 28/1900 loss 6.285002 loss_att 472.290863 loss_ctc 15.923736 loss_rnnt 5.214032 lr 0.00025196 rank 7
2022-12-08 07:31:05,947 DEBUG TRAIN Batch 28/1900 loss 7.187801 loss_att 203.997910 loss_ctc 12.160787 loss_rnnt 6.635248 lr 0.00025200 rank 6
2022-12-08 07:31:05,948 DEBUG TRAIN Batch 28/1900 loss 8.327208 loss_att 99.331284 loss_ctc 12.036005 loss_rnnt 7.915119 lr 0.00025199 rank 2
2022-12-08 07:31:05,948 DEBUG TRAIN Batch 28/1900 loss 8.491781 loss_att 262.851135 loss_ctc 16.977621 loss_rnnt 7.548910 lr 0.00025196 rank 4
2022-12-08 07:31:05,950 DEBUG TRAIN Batch 28/1900 loss 9.645536 loss_att 241.459076 loss_ctc 15.714412 loss_rnnt 8.971218 lr 0.00025197 rank 3
2022-12-08 07:31:05,951 DEBUG TRAIN Batch 28/1900 loss 3.522666 loss_att 265.625519 loss_ctc 12.510860 loss_rnnt 2.523978 lr 0.00025200 rank 1
2022-12-08 07:31:05,991 DEBUG TRAIN Batch 28/1900 loss 7.115403 loss_att 150.373871 loss_ctc 11.268233 loss_rnnt 6.653977 lr 0.00025198 rank 5
2022-12-08 07:32:09,121 DEBUG TRAIN Batch 28/2000 loss 7.488076 loss_att 468.682617 loss_ctc 9.140871 loss_rnnt 7.304432 lr 0.00025193 rank 4
2022-12-08 07:32:09,138 DEBUG TRAIN Batch 28/2000 loss 9.453339 loss_att 402.964569 loss_ctc 18.211813 loss_rnnt 8.480175 lr 0.00025193 rank 7
2022-12-08 07:32:09,139 DEBUG TRAIN Batch 28/2000 loss 8.424354 loss_att 409.791321 loss_ctc 14.844401 loss_rnnt 7.711015 lr 0.00025196 rank 2
2022-12-08 07:32:09,139 DEBUG TRAIN Batch 28/2000 loss 4.394555 loss_att 446.591553 loss_ctc 13.927742 loss_rnnt 3.335312 lr 0.00025194 rank 3
2022-12-08 07:32:09,141 DEBUG TRAIN Batch 28/2000 loss 7.528193 loss_att 397.132935 loss_ctc 12.208107 loss_rnnt 7.008203 lr 0.00025196 rank 6
2022-12-08 07:32:09,142 DEBUG TRAIN Batch 28/2000 loss 2.159025 loss_att 384.333008 loss_ctc 5.258906 loss_rnnt 1.814594 lr 0.00025193 rank 0
2022-12-08 07:32:09,142 DEBUG TRAIN Batch 28/2000 loss 2.557658 loss_att 337.156250 loss_ctc 7.250680 loss_rnnt 2.036211 lr 0.00025197 rank 1
2022-12-08 07:32:09,145 DEBUG TRAIN Batch 28/2000 loss 15.916492 loss_att 425.686951 loss_ctc 25.016195 loss_rnnt 14.905414 lr 0.00025195 rank 5
2022-12-08 07:33:13,979 DEBUG TRAIN Batch 28/2100 loss 15.037655 loss_att 404.241028 loss_ctc 20.982143 loss_rnnt 14.377157 lr 0.00025194 rank 1
2022-12-08 07:33:13,991 DEBUG TRAIN Batch 28/2100 loss 10.059914 loss_att 407.848816 loss_ctc 17.895437 loss_rnnt 9.189300 lr 0.00025193 rank 6
2022-12-08 07:33:13,991 DEBUG TRAIN Batch 28/2100 loss 10.548019 loss_att 395.780212 loss_ctc 17.744429 loss_rnnt 9.748419 lr 0.00025193 rank 2
2022-12-08 07:33:13,991 DEBUG TRAIN Batch 28/2100 loss 8.429886 loss_att 357.493011 loss_ctc 15.196526 loss_rnnt 7.678037 lr 0.00025190 rank 4
2022-12-08 07:33:13,991 DEBUG TRAIN Batch 28/2100 loss 6.042085 loss_att 373.691010 loss_ctc 18.458477 loss_rnnt 4.662486 lr 0.00025190 rank 7
2022-12-08 07:33:13,998 DEBUG TRAIN Batch 28/2100 loss 8.087326 loss_att 379.478607 loss_ctc 26.340628 loss_rnnt 6.059182 lr 0.00025190 rank 0
2022-12-08 07:33:14,001 DEBUG TRAIN Batch 28/2100 loss 9.766619 loss_att 391.170471 loss_ctc 20.541033 loss_rnnt 8.569462 lr 0.00025192 rank 5
2022-12-08 07:33:14,041 DEBUG TRAIN Batch 28/2100 loss 13.899851 loss_att 362.672333 loss_ctc 24.409508 loss_rnnt 12.732112 lr 0.00025191 rank 3
2022-12-08 07:34:26,134 DEBUG TRAIN Batch 28/2200 loss 2.356632 loss_att 344.291138 loss_ctc 9.037846 loss_rnnt 1.614274 lr 0.00025187 rank 4
2022-12-08 07:34:26,135 DEBUG TRAIN Batch 28/2200 loss 8.425971 loss_att 392.452576 loss_ctc 16.551136 loss_rnnt 7.523175 lr 0.00025191 rank 1
2022-12-08 07:34:26,135 DEBUG TRAIN Batch 28/2200 loss 12.894250 loss_att 374.924622 loss_ctc 20.690147 loss_rnnt 12.028040 lr 0.00025187 rank 0
2022-12-08 07:34:26,135 DEBUG TRAIN Batch 28/2200 loss 10.545092 loss_att 404.888306 loss_ctc 22.242134 loss_rnnt 9.245420 lr 0.00025190 rank 6
2022-12-08 07:34:26,138 DEBUG TRAIN Batch 28/2200 loss 10.598340 loss_att 404.268799 loss_ctc 18.570175 loss_rnnt 9.712581 lr 0.00025188 rank 5
2022-12-08 07:34:26,138 DEBUG TRAIN Batch 28/2200 loss 8.945687 loss_att 335.245972 loss_ctc 21.079384 loss_rnnt 7.597499 lr 0.00025188 rank 3
2022-12-08 07:34:26,140 DEBUG TRAIN Batch 28/2200 loss 3.185815 loss_att 392.370178 loss_ctc 8.386090 loss_rnnt 2.608007 lr 0.00025187 rank 7
2022-12-08 07:34:26,144 DEBUG TRAIN Batch 28/2200 loss 8.276803 loss_att 366.026001 loss_ctc 12.306911 loss_rnnt 7.829013 lr 0.00025190 rank 2
2022-12-08 07:35:28,288 DEBUG TRAIN Batch 28/2300 loss 4.409633 loss_att 340.435181 loss_ctc 7.023884 loss_rnnt 4.119160 lr 0.00025187 rank 6
2022-12-08 07:35:28,297 DEBUG TRAIN Batch 28/2300 loss 4.699872 loss_att 364.273621 loss_ctc 10.196002 loss_rnnt 4.089190 lr 0.00025184 rank 4
2022-12-08 07:35:28,299 DEBUG TRAIN Batch 28/2300 loss 12.272786 loss_att 378.853943 loss_ctc 23.517082 loss_rnnt 11.023420 lr 0.00025187 rank 1
2022-12-08 07:35:28,300 DEBUG TRAIN Batch 28/2300 loss 10.843256 loss_att 326.565979 loss_ctc 23.913889 loss_rnnt 9.390964 lr 0.00025185 rank 3
2022-12-08 07:35:28,301 DEBUG TRAIN Batch 28/2300 loss 3.008850 loss_att 322.783203 loss_ctc 6.592014 loss_rnnt 2.610720 lr 0.00025184 rank 7
2022-12-08 07:35:28,304 DEBUG TRAIN Batch 28/2300 loss 4.623591 loss_att 346.206665 loss_ctc 8.553312 loss_rnnt 4.186955 lr 0.00025184 rank 0
2022-12-08 07:35:28,305 DEBUG TRAIN Batch 28/2300 loss 6.532063 loss_att 330.199982 loss_ctc 10.978998 loss_rnnt 6.037959 lr 0.00025185 rank 5
2022-12-08 07:35:28,342 DEBUG TRAIN Batch 28/2300 loss 11.969254 loss_att 408.405426 loss_ctc 29.013107 loss_rnnt 10.075493 lr 0.00025187 rank 2
2022-12-08 07:36:31,742 DEBUG TRAIN Batch 28/2400 loss 16.888191 loss_att 332.636353 loss_ctc 30.686855 loss_rnnt 15.355007 lr 0.00025181 rank 3
2022-12-08 07:36:31,747 DEBUG TRAIN Batch 28/2400 loss 4.146688 loss_att 284.265198 loss_ctc 13.684567 loss_rnnt 3.086924 lr 0.00025183 rank 2
2022-12-08 07:36:31,756 DEBUG TRAIN Batch 28/2400 loss 22.713823 loss_att 353.787292 loss_ctc 32.771496 loss_rnnt 21.596306 lr 0.00025184 rank 6
2022-12-08 07:36:31,761 DEBUG TRAIN Batch 28/2400 loss 5.833330 loss_att 347.720856 loss_ctc 12.789949 loss_rnnt 5.060372 lr 0.00025180 rank 4
2022-12-08 07:36:31,761 DEBUG TRAIN Batch 28/2400 loss 12.174902 loss_att 322.809448 loss_ctc 25.639851 loss_rnnt 10.678797 lr 0.00025180 rank 0
2022-12-08 07:36:31,762 DEBUG TRAIN Batch 28/2400 loss 9.220185 loss_att 354.140350 loss_ctc 20.241983 loss_rnnt 7.995542 lr 0.00025180 rank 7
2022-12-08 07:36:31,767 DEBUG TRAIN Batch 28/2400 loss 11.754096 loss_att 362.440094 loss_ctc 20.198124 loss_rnnt 10.815870 lr 0.00025182 rank 5
2022-12-08 07:36:31,784 DEBUG TRAIN Batch 28/2400 loss 14.931757 loss_att 395.561523 loss_ctc 22.173431 loss_rnnt 14.127127 lr 0.00025184 rank 1
2022-12-08 07:37:44,221 DEBUG TRAIN Batch 28/2500 loss 3.697872 loss_att 327.437225 loss_ctc 10.239110 loss_rnnt 2.971068 lr 0.00025177 rank 4
2022-12-08 07:37:44,222 DEBUG TRAIN Batch 28/2500 loss 10.198747 loss_att 125.365891 loss_ctc 17.178488 loss_rnnt 9.423220 lr 0.00025177 rank 7
2022-12-08 07:37:44,223 DEBUG TRAIN Batch 28/2500 loss 5.593304 loss_att 207.367294 loss_ctc 9.348820 loss_rnnt 5.176024 lr 0.00025180 rank 2
2022-12-08 07:37:44,227 DEBUG TRAIN Batch 28/2500 loss 15.197660 loss_att 266.996063 loss_ctc 30.364761 loss_rnnt 13.512427 lr 0.00025180 rank 6
2022-12-08 07:37:44,229 DEBUG TRAIN Batch 28/2500 loss 5.909564 loss_att 267.954895 loss_ctc 12.695427 loss_rnnt 5.155580 lr 0.00025181 rank 1
2022-12-08 07:37:44,233 DEBUG TRAIN Batch 28/2500 loss 4.218372 loss_att 401.709534 loss_ctc 6.072201 loss_rnnt 4.012391 lr 0.00025177 rank 0
2022-12-08 07:37:44,233 DEBUG TRAIN Batch 28/2500 loss 9.860785 loss_att 283.994232 loss_ctc 19.544647 loss_rnnt 8.784801 lr 0.00025179 rank 5
2022-12-08 07:37:44,267 DEBUG TRAIN Batch 28/2500 loss 7.322854 loss_att 260.994659 loss_ctc 12.979324 loss_rnnt 6.694357 lr 0.00025178 rank 3
2022-12-08 07:38:46,897 DEBUG TRAIN Batch 28/2600 loss 6.593060 loss_att 90.343643 loss_ctc 10.480607 loss_rnnt 6.161110 lr 0.00025174 rank 4
2022-12-08 07:38:46,898 DEBUG TRAIN Batch 28/2600 loss 5.762199 loss_att 420.788422 loss_ctc 12.739078 loss_rnnt 4.986991 lr 0.00025174 rank 7
2022-12-08 07:38:46,901 DEBUG TRAIN Batch 28/2600 loss 9.297871 loss_att 275.782288 loss_ctc 17.128109 loss_rnnt 8.427845 lr 0.00025177 rank 2
2022-12-08 07:38:46,902 DEBUG TRAIN Batch 28/2600 loss 7.592419 loss_att 396.601196 loss_ctc 18.217869 loss_rnnt 6.411813 lr 0.00025177 rank 6
2022-12-08 07:38:46,903 DEBUG TRAIN Batch 28/2600 loss 13.138758 loss_att 412.091156 loss_ctc 22.746914 loss_rnnt 12.071185 lr 0.00025175 rank 3
2022-12-08 07:38:46,903 DEBUG TRAIN Batch 28/2600 loss 6.162329 loss_att 394.117767 loss_ctc 13.929655 loss_rnnt 5.299293 lr 0.00025178 rank 1
2022-12-08 07:38:46,906 DEBUG TRAIN Batch 28/2600 loss 8.027500 loss_att 391.337860 loss_ctc 15.899141 loss_rnnt 7.152874 lr 0.00025174 rank 0
2022-12-08 07:38:46,907 DEBUG TRAIN Batch 28/2600 loss 5.059052 loss_att 387.310638 loss_ctc 17.846502 loss_rnnt 3.638224 lr 0.00025176 rank 5
2022-12-08 07:39:49,342 DEBUG TRAIN Batch 28/2700 loss 9.043034 loss_att 372.882050 loss_ctc 14.499286 loss_rnnt 8.436784 lr 0.00025171 rank 7
2022-12-08 07:39:49,343 DEBUG TRAIN Batch 28/2700 loss 8.041882 loss_att 438.667572 loss_ctc 21.546339 loss_rnnt 6.541387 lr 0.00025174 rank 6
2022-12-08 07:39:49,345 DEBUG TRAIN Batch 28/2700 loss 8.422829 loss_att 402.478455 loss_ctc 16.499954 loss_rnnt 7.525371 lr 0.00025175 rank 1
2022-12-08 07:39:49,345 DEBUG TRAIN Batch 28/2700 loss 7.124392 loss_att 441.831360 loss_ctc 12.684689 loss_rnnt 6.506581 lr 0.00025171 rank 4
2022-12-08 07:39:49,347 DEBUG TRAIN Batch 28/2700 loss 2.999180 loss_att 397.547058 loss_ctc 7.508171 loss_rnnt 2.498182 lr 0.00025174 rank 2
2022-12-08 07:39:49,350 DEBUG TRAIN Batch 28/2700 loss 3.225796 loss_att 392.018890 loss_ctc 8.712831 loss_rnnt 2.616126 lr 0.00025171 rank 0
2022-12-08 07:39:49,351 DEBUG TRAIN Batch 28/2700 loss 14.162868 loss_att 429.544922 loss_ctc 20.846657 loss_rnnt 13.420226 lr 0.00025172 rank 5
2022-12-08 07:39:49,352 DEBUG TRAIN Batch 28/2700 loss 7.907228 loss_att 447.669006 loss_ctc 11.407592 loss_rnnt 7.518298 lr 0.00025172 rank 3
2022-12-08 07:40:53,874 DEBUG TRAIN Batch 28/2800 loss 4.552924 loss_att 392.038544 loss_ctc 20.297020 loss_rnnt 2.803580 lr 0.00025169 rank 3
2022-12-08 07:40:53,884 DEBUG TRAIN Batch 28/2800 loss 10.949945 loss_att 379.035736 loss_ctc 21.932919 loss_rnnt 9.729615 lr 0.00025171 rank 6
2022-12-08 07:40:53,884 DEBUG TRAIN Batch 28/2800 loss 12.563379 loss_att 413.180603 loss_ctc 21.986404 loss_rnnt 11.516376 lr 0.00025168 rank 4
2022-12-08 07:40:53,884 DEBUG TRAIN Batch 28/2800 loss 11.216795 loss_att 318.466492 loss_ctc 21.127922 loss_rnnt 10.115559 lr 0.00025168 rank 7
2022-12-08 07:40:53,886 DEBUG TRAIN Batch 28/2800 loss 4.064288 loss_att 370.566315 loss_ctc 9.938507 loss_rnnt 3.411597 lr 0.00025171 rank 2
2022-12-08 07:40:53,891 DEBUG TRAIN Batch 28/2800 loss 2.087152 loss_att 346.003510 loss_ctc 6.239250 loss_rnnt 1.625808 lr 0.00025168 rank 0
2022-12-08 07:40:53,895 DEBUG TRAIN Batch 28/2800 loss 6.776180 loss_att 432.181335 loss_ctc 8.652961 loss_rnnt 6.567649 lr 0.00025169 rank 5
2022-12-08 07:40:53,896 DEBUG TRAIN Batch 28/2800 loss 5.383399 loss_att 366.893402 loss_ctc 10.170950 loss_rnnt 4.851449 lr 0.00025171 rank 1
2022-12-08 07:42:06,185 DEBUG TRAIN Batch 28/2900 loss 3.016439 loss_att 338.715546 loss_ctc 8.428419 loss_rnnt 2.415108 lr 0.00025164 rank 4
2022-12-08 07:42:06,189 DEBUG TRAIN Batch 28/2900 loss 7.100360 loss_att 413.611877 loss_ctc 21.768036 loss_rnnt 5.470618 lr 0.00025165 rank 3
2022-12-08 07:42:06,189 DEBUG TRAIN Batch 28/2900 loss 17.960152 loss_att 405.340973 loss_ctc 26.724281 loss_rnnt 16.986361 lr 0.00025164 rank 0
2022-12-08 07:42:06,192 DEBUG TRAIN Batch 28/2900 loss 9.370826 loss_att 374.496857 loss_ctc 17.204338 loss_rnnt 8.500436 lr 0.00025168 rank 6
2022-12-08 07:42:06,193 DEBUG TRAIN Batch 28/2900 loss 13.008713 loss_att 383.714630 loss_ctc 25.335131 loss_rnnt 11.639111 lr 0.00025165 rank 7
2022-12-08 07:42:06,196 DEBUG TRAIN Batch 28/2900 loss 8.217089 loss_att 363.283783 loss_ctc 13.920944 loss_rnnt 7.583327 lr 0.00025168 rank 1
2022-12-08 07:42:06,197 DEBUG TRAIN Batch 28/2900 loss 6.082885 loss_att 370.305481 loss_ctc 15.777122 loss_rnnt 5.005748 lr 0.00025166 rank 5
2022-12-08 07:42:06,235 DEBUG TRAIN Batch 28/2900 loss 3.482244 loss_att 376.080933 loss_ctc 7.874235 loss_rnnt 2.994246 lr 0.00025167 rank 2
2022-12-08 07:43:09,127 DEBUG TRAIN Batch 28/3000 loss 5.861002 loss_att 318.572449 loss_ctc 10.219827 loss_rnnt 5.376688 lr 0.00025162 rank 3
2022-12-08 07:43:09,129 DEBUG TRAIN Batch 28/3000 loss 6.839031 loss_att 326.559204 loss_ctc 17.035118 loss_rnnt 5.706132 lr 0.00025161 rank 7
2022-12-08 07:43:09,129 DEBUG TRAIN Batch 28/3000 loss 10.854237 loss_att 332.320679 loss_ctc 20.897011 loss_rnnt 9.738374 lr 0.00025165 rank 1
2022-12-08 07:43:09,130 DEBUG TRAIN Batch 28/3000 loss 1.714014 loss_att 311.879181 loss_ctc 3.819083 loss_rnnt 1.480117 lr 0.00025164 rank 6
2022-12-08 07:43:09,130 DEBUG TRAIN Batch 28/3000 loss 9.948449 loss_att 350.323395 loss_ctc 24.217758 loss_rnnt 8.362970 lr 0.00025161 rank 4
2022-12-08 07:43:09,131 DEBUG TRAIN Batch 28/3000 loss 6.071255 loss_att 338.330078 loss_ctc 15.380466 loss_rnnt 5.036898 lr 0.00025164 rank 2
2022-12-08 07:43:09,135 DEBUG TRAIN Batch 28/3000 loss 4.330412 loss_att 290.780884 loss_ctc 8.334228 loss_rnnt 3.885543 lr 0.00025161 rank 0
2022-12-08 07:43:09,136 DEBUG TRAIN Batch 28/3000 loss 5.568109 loss_att 352.005554 loss_ctc 11.433962 loss_rnnt 4.916348 lr 0.00025163 rank 5
2022-12-08 07:44:12,633 DEBUG TRAIN Batch 28/3100 loss 7.675090 loss_att 280.916229 loss_ctc 20.981224 loss_rnnt 6.196630 lr 0.00025158 rank 4
2022-12-08 07:44:12,634 DEBUG TRAIN Batch 28/3100 loss 12.302223 loss_att 360.998138 loss_ctc 26.415167 loss_rnnt 10.734118 lr 0.00025162 rank 1
2022-12-08 07:44:12,638 DEBUG TRAIN Batch 28/3100 loss 8.834153 loss_att 391.131714 loss_ctc 19.402441 loss_rnnt 7.659900 lr 0.00025161 rank 6
2022-12-08 07:44:12,638 DEBUG TRAIN Batch 28/3100 loss 4.393008 loss_att 335.656250 loss_ctc 11.566900 loss_rnnt 3.595909 lr 0.00025158 rank 7
2022-12-08 07:44:12,638 DEBUG TRAIN Batch 28/3100 loss 10.964581 loss_att 138.020645 loss_ctc 17.270254 loss_rnnt 10.263951 lr 0.00025158 rank 0
2022-12-08 07:44:12,639 DEBUG TRAIN Batch 28/3100 loss 10.004923 loss_att 296.941803 loss_ctc 15.930671 loss_rnnt 9.346506 lr 0.00025161 rank 2
2022-12-08 07:44:12,660 DEBUG TRAIN Batch 28/3100 loss 6.858101 loss_att 362.691345 loss_ctc 14.257259 loss_rnnt 6.035972 lr 0.00025160 rank 5
2022-12-08 07:44:12,691 DEBUG TRAIN Batch 28/3100 loss 6.972351 loss_att 300.448700 loss_ctc 14.987556 loss_rnnt 6.081773 lr 0.00025159 rank 3
2022-12-08 07:45:23,592 DEBUG TRAIN Batch 28/3200 loss 3.185458 loss_att 359.310638 loss_ctc 8.410452 loss_rnnt 2.604903 lr 0.00025155 rank 7
2022-12-08 07:45:23,594 DEBUG TRAIN Batch 28/3200 loss 4.571246 loss_att 170.091766 loss_ctc 7.311125 loss_rnnt 4.266816 lr 0.00025155 rank 4
2022-12-08 07:45:23,594 DEBUG TRAIN Batch 28/3200 loss 7.965660 loss_att 220.413971 loss_ctc 15.546292 loss_rnnt 7.123367 lr 0.00025158 rank 6
2022-12-08 07:45:23,596 DEBUG TRAIN Batch 28/3200 loss 1.592089 loss_att 370.410034 loss_ctc 6.311078 loss_rnnt 1.067756 lr 0.00025158 rank 2
2022-12-08 07:45:23,598 DEBUG TRAIN Batch 28/3200 loss 6.813939 loss_att 107.840424 loss_ctc 11.283470 loss_rnnt 6.317324 lr 0.00025156 rank 3
2022-12-08 07:45:23,616 DEBUG TRAIN Batch 28/3200 loss 9.885303 loss_att 409.553925 loss_ctc 21.149796 loss_rnnt 8.633693 lr 0.00025159 rank 1
2022-12-08 07:45:23,617 DEBUG TRAIN Batch 28/3200 loss 7.264134 loss_att 405.579834 loss_ctc 17.056240 loss_rnnt 6.176123 lr 0.00025155 rank 0
2022-12-08 07:45:23,630 DEBUG TRAIN Batch 28/3200 loss 4.352706 loss_att 151.163834 loss_ctc 9.918118 loss_rnnt 3.734327 lr 0.00025157 rank 5
2022-12-08 07:46:27,720 DEBUG TRAIN Batch 28/3300 loss 7.658725 loss_att 384.354095 loss_ctc 10.653032 loss_rnnt 7.326025 lr 0.00025153 rank 5
2022-12-08 07:46:27,732 DEBUG TRAIN Batch 28/3300 loss 4.731587 loss_att 349.950562 loss_ctc 12.714674 loss_rnnt 3.844578 lr 0.00025152 rank 7
2022-12-08 07:46:27,733 DEBUG TRAIN Batch 28/3300 loss 4.146912 loss_att 383.518127 loss_ctc 13.083958 loss_rnnt 3.153907 lr 0.00025155 rank 2
2022-12-08 07:46:27,734 DEBUG TRAIN Batch 28/3300 loss 5.671751 loss_att 365.231873 loss_ctc 8.121999 loss_rnnt 5.399502 lr 0.00025156 rank 1
2022-12-08 07:46:27,734 DEBUG TRAIN Batch 28/3300 loss 11.574700 loss_att 378.298431 loss_ctc 22.222258 loss_rnnt 10.391638 lr 0.00025152 rank 4
2022-12-08 07:46:27,735 DEBUG TRAIN Batch 28/3300 loss 0.929957 loss_att 376.887390 loss_ctc 5.659244 loss_rnnt 0.404481 lr 0.00025155 rank 6
2022-12-08 07:46:27,737 DEBUG TRAIN Batch 28/3300 loss 11.297715 loss_att 442.654633 loss_ctc 23.209217 loss_rnnt 9.974215 lr 0.00025153 rank 3
2022-12-08 07:46:27,740 DEBUG TRAIN Batch 28/3300 loss 6.769396 loss_att 387.916321 loss_ctc 14.557071 loss_rnnt 5.904099 lr 0.00025152 rank 0
2022-12-08 07:47:30,372 DEBUG TRAIN Batch 28/3400 loss 6.709800 loss_att 337.129364 loss_ctc 12.247168 loss_rnnt 6.094538 lr 0.00025148 rank 0
2022-12-08 07:47:30,383 DEBUG TRAIN Batch 28/3400 loss 10.142112 loss_att 377.787170 loss_ctc 21.519611 loss_rnnt 8.877946 lr 0.00025149 rank 7
2022-12-08 07:47:30,386 DEBUG TRAIN Batch 28/3400 loss 11.220941 loss_att 380.714111 loss_ctc 15.744030 loss_rnnt 10.718375 lr 0.00025150 rank 5
2022-12-08 07:47:30,387 DEBUG TRAIN Batch 28/3400 loss 6.691940 loss_att 405.073364 loss_ctc 11.554062 loss_rnnt 6.151704 lr 0.00025149 rank 4
2022-12-08 07:47:30,387 DEBUG TRAIN Batch 28/3400 loss 8.019643 loss_att 419.789795 loss_ctc 21.694218 loss_rnnt 6.500246 lr 0.00025152 rank 1
2022-12-08 07:47:30,389 DEBUG TRAIN Batch 28/3400 loss 6.033530 loss_att 370.191162 loss_ctc 14.178755 loss_rnnt 5.128506 lr 0.00025151 rank 2
2022-12-08 07:47:30,390 DEBUG TRAIN Batch 28/3400 loss 5.955486 loss_att 381.123596 loss_ctc 12.331343 loss_rnnt 5.247058 lr 0.00025152 rank 6
2022-12-08 07:47:30,391 DEBUG TRAIN Batch 28/3400 loss 8.519746 loss_att 447.964325 loss_ctc 26.361052 loss_rnnt 6.537378 lr 0.00025149 rank 3
2022-12-08 07:48:34,291 DEBUG TRAIN Batch 28/3500 loss 3.924838 loss_att 350.257751 loss_ctc 11.987095 loss_rnnt 3.029032 lr 0.00025148 rank 2
2022-12-08 07:48:34,303 DEBUG TRAIN Batch 28/3500 loss 14.246167 loss_att 356.331848 loss_ctc 29.747425 loss_rnnt 12.523805 lr 0.00025146 rank 3
2022-12-08 07:48:34,305 DEBUG TRAIN Batch 28/3500 loss 10.002859 loss_att 430.463165 loss_ctc 25.910791 loss_rnnt 8.235312 lr 0.00025147 rank 5
2022-12-08 07:48:34,305 DEBUG TRAIN Batch 28/3500 loss 7.747218 loss_att 345.910858 loss_ctc 10.874386 loss_rnnt 7.399755 lr 0.00025145 rank 4
2022-12-08 07:48:34,306 DEBUG TRAIN Batch 28/3500 loss 4.332317 loss_att 368.837708 loss_ctc 10.763954 loss_rnnt 3.617691 lr 0.00025145 rank 7
2022-12-08 07:48:34,308 DEBUG TRAIN Batch 28/3500 loss 4.839115 loss_att 344.350281 loss_ctc 13.772215 loss_rnnt 3.846548 lr 0.00025148 rank 6
2022-12-08 07:48:34,308 DEBUG TRAIN Batch 28/3500 loss 11.233084 loss_att 357.483643 loss_ctc 19.945515 loss_rnnt 10.265036 lr 0.00025149 rank 1
2022-12-08 07:48:34,312 DEBUG TRAIN Batch 28/3500 loss 18.168999 loss_att 441.954956 loss_ctc 34.937969 loss_rnnt 16.305780 lr 0.00025145 rank 0
2022-12-08 07:49:46,609 DEBUG TRAIN Batch 28/3600 loss 4.394282 loss_att 358.812683 loss_ctc 14.100537 loss_rnnt 3.315810 lr 0.00025142 rank 4
2022-12-08 07:49:46,618 DEBUG TRAIN Batch 28/3600 loss 6.932199 loss_att 349.791809 loss_ctc 14.660491 loss_rnnt 6.073499 lr 0.00025142 rank 0
2022-12-08 07:49:46,619 DEBUG TRAIN Batch 28/3600 loss 5.643835 loss_att 346.609589 loss_ctc 9.671270 loss_rnnt 5.196342 lr 0.00025142 rank 7
2022-12-08 07:49:46,624 DEBUG TRAIN Batch 28/3600 loss 4.446319 loss_att 348.425934 loss_ctc 9.587193 loss_rnnt 3.875111 lr 0.00025146 rank 1
2022-12-08 07:49:46,625 DEBUG TRAIN Batch 28/3600 loss 13.409211 loss_att 392.742188 loss_ctc 17.764999 loss_rnnt 12.925236 lr 0.00025143 rank 3
2022-12-08 07:49:46,626 DEBUG TRAIN Batch 28/3600 loss 5.965327 loss_att 359.144806 loss_ctc 13.803797 loss_rnnt 5.094386 lr 0.00025145 rank 6
2022-12-08 07:49:46,634 DEBUG TRAIN Batch 28/3600 loss 9.051458 loss_att 382.966644 loss_ctc 23.964176 loss_rnnt 7.394490 lr 0.00025144 rank 5
2022-12-08 07:49:46,672 DEBUG TRAIN Batch 28/3600 loss 3.904392 loss_att 333.564453 loss_ctc 7.812575 loss_rnnt 3.470149 lr 0.00025145 rank 2
2022-12-08 07:50:49,731 DEBUG TRAIN Batch 28/3700 loss 6.452587 loss_att 232.000488 loss_ctc 10.649170 loss_rnnt 5.986300 lr 0.00025139 rank 7
2022-12-08 07:50:49,733 DEBUG TRAIN Batch 28/3700 loss 7.268382 loss_att 307.696045 loss_ctc 14.135092 loss_rnnt 6.505414 lr 0.00025140 rank 3
2022-12-08 07:50:49,734 DEBUG TRAIN Batch 28/3700 loss 3.959543 loss_att 364.746216 loss_ctc 10.853462 loss_rnnt 3.193552 lr 0.00025139 rank 4
2022-12-08 07:50:49,735 DEBUG TRAIN Batch 28/3700 loss 7.648828 loss_att 320.130310 loss_ctc 10.008196 loss_rnnt 7.386676 lr 0.00025143 rank 1
2022-12-08 07:50:49,735 DEBUG TRAIN Batch 28/3700 loss 4.775572 loss_att 290.753143 loss_ctc 7.463888 loss_rnnt 4.476871 lr 0.00025142 rank 6
2022-12-08 07:50:49,739 DEBUG TRAIN Batch 28/3700 loss 5.865669 loss_att 266.480865 loss_ctc 12.001873 loss_rnnt 5.183868 lr 0.00025139 rank 0
2022-12-08 07:50:49,741 DEBUG TRAIN Batch 28/3700 loss 9.454737 loss_att 332.276001 loss_ctc 15.994387 loss_rnnt 8.728108 lr 0.00025142 rank 2
2022-12-08 07:50:49,780 DEBUG TRAIN Batch 28/3700 loss 17.162853 loss_att 322.496185 loss_ctc 30.096647 loss_rnnt 15.725765 lr 0.00025141 rank 5
2022-12-08 07:51:53,789 DEBUG TRAIN Batch 28/3800 loss 10.275108 loss_att 198.945786 loss_ctc 19.254116 loss_rnnt 9.277441 lr 0.00025136 rank 4
2022-12-08 07:51:53,791 DEBUG TRAIN Batch 28/3800 loss 10.036321 loss_att 328.633881 loss_ctc 22.198135 loss_rnnt 8.685008 lr 0.00025137 rank 3
2022-12-08 07:51:53,793 DEBUG TRAIN Batch 28/3800 loss 2.057655 loss_att 367.720306 loss_ctc 7.244859 loss_rnnt 1.481299 lr 0.00025136 rank 7
2022-12-08 07:51:53,796 DEBUG TRAIN Batch 28/3800 loss 9.438063 loss_att 207.541992 loss_ctc 17.216413 loss_rnnt 8.573802 lr 0.00025140 rank 1
2022-12-08 07:51:53,798 DEBUG TRAIN Batch 28/3800 loss 9.383818 loss_att 182.694382 loss_ctc 16.255711 loss_rnnt 8.620275 lr 0.00025139 rank 2
2022-12-08 07:51:53,797 DEBUG TRAIN Batch 28/3800 loss 7.789883 loss_att 416.182983 loss_ctc 17.444164 loss_rnnt 6.717185 lr 0.00025136 rank 0
2022-12-08 07:51:53,798 DEBUG TRAIN Batch 28/3800 loss 7.627179 loss_att 296.664032 loss_ctc 12.093904 loss_rnnt 7.130876 lr 0.00025139 rank 6
2022-12-08 07:51:53,800 DEBUG TRAIN Batch 28/3800 loss 9.122890 loss_att 206.094208 loss_ctc 15.202701 loss_rnnt 8.447355 lr 0.00025137 rank 5
2022-12-08 07:52:58,629 DEBUG TRAIN Batch 28/3900 loss 7.879887 loss_att 384.793274 loss_ctc 11.515188 loss_rnnt 7.475965 lr 0.00025136 rank 2
2022-12-08 07:52:58,633 DEBUG TRAIN Batch 28/3900 loss 7.613156 loss_att 376.280273 loss_ctc 18.997734 loss_rnnt 6.348203 lr 0.00025133 rank 7
2022-12-08 07:52:58,632 DEBUG TRAIN Batch 28/3900 loss 6.150546 loss_att 367.990662 loss_ctc 12.329962 loss_rnnt 5.463944 lr 0.00025134 rank 3
2022-12-08 07:52:58,636 DEBUG TRAIN Batch 28/3900 loss 2.234242 loss_att 411.417542 loss_ctc 5.276081 loss_rnnt 1.896260 lr 0.00025133 rank 4
2022-12-08 07:52:58,637 DEBUG TRAIN Batch 28/3900 loss 4.982533 loss_att 361.647400 loss_ctc 14.572216 loss_rnnt 3.917013 lr 0.00025133 rank 0
2022-12-08 07:52:58,639 DEBUG TRAIN Batch 28/3900 loss 3.307263 loss_att 391.429443 loss_ctc 7.074614 loss_rnnt 2.888669 lr 0.00025134 rank 5
2022-12-08 07:52:58,639 DEBUG TRAIN Batch 28/3900 loss 4.163081 loss_att 353.236176 loss_ctc 11.332169 loss_rnnt 3.366516 lr 0.00025136 rank 1
2022-12-08 07:52:58,643 DEBUG TRAIN Batch 28/3900 loss 6.721665 loss_att 436.626221 loss_ctc 16.284580 loss_rnnt 5.659119 lr 0.00025136 rank 6
2022-12-08 07:54:10,028 DEBUG TRAIN Batch 28/4000 loss 3.519615 loss_att 392.681335 loss_ctc 9.574608 loss_rnnt 2.846838 lr 0.00025129 rank 4
2022-12-08 07:54:10,029 DEBUG TRAIN Batch 28/4000 loss 6.984426 loss_att 356.626892 loss_ctc 14.241442 loss_rnnt 6.178091 lr 0.00025129 rank 0
2022-12-08 07:54:10,030 DEBUG TRAIN Batch 28/4000 loss 5.055772 loss_att 358.540863 loss_ctc 12.028427 loss_rnnt 4.281033 lr 0.00025132 rank 2
2022-12-08 07:54:10,030 DEBUG TRAIN Batch 28/4000 loss 7.742762 loss_att 409.879974 loss_ctc 18.377798 loss_rnnt 6.561091 lr 0.00025130 rank 7
2022-12-08 07:54:10,030 DEBUG TRAIN Batch 28/4000 loss 4.919681 loss_att 380.131226 loss_ctc 12.988441 loss_rnnt 4.023151 lr 0.00025130 rank 3
2022-12-08 07:54:10,032 DEBUG TRAIN Batch 28/4000 loss 8.223807 loss_att 456.778259 loss_ctc 23.337330 loss_rnnt 6.544527 lr 0.00025133 rank 6
2022-12-08 07:54:10,034 DEBUG TRAIN Batch 28/4000 loss 4.666720 loss_att 404.378265 loss_ctc 16.472370 loss_rnnt 3.354981 lr 0.00025131 rank 5
2022-12-08 07:54:10,041 DEBUG TRAIN Batch 28/4000 loss 7.065730 loss_att 384.864197 loss_ctc 14.834362 loss_rnnt 6.202549 lr 0.00025133 rank 1
2022-12-08 07:55:13,412 DEBUG TRAIN Batch 28/4100 loss 12.237977 loss_att 399.188293 loss_ctc 30.604149 loss_rnnt 10.197291 lr 0.00025126 rank 4
2022-12-08 07:55:13,413 DEBUG TRAIN Batch 28/4100 loss 5.821117 loss_att 328.315308 loss_ctc 8.001352 loss_rnnt 5.578869 lr 0.00025126 rank 0
2022-12-08 07:55:13,415 DEBUG TRAIN Batch 28/4100 loss 10.702709 loss_att 383.288147 loss_ctc 18.808598 loss_rnnt 9.802055 lr 0.00025130 rank 1
2022-12-08 07:55:13,417 DEBUG TRAIN Batch 28/4100 loss 16.065845 loss_att 391.382568 loss_ctc 31.360098 loss_rnnt 14.366486 lr 0.00025129 rank 2
2022-12-08 07:55:13,417 DEBUG TRAIN Batch 28/4100 loss 6.060529 loss_att 429.425598 loss_ctc 14.371803 loss_rnnt 5.137053 lr 0.00025127 rank 3
2022-12-08 07:55:13,419 DEBUG TRAIN Batch 28/4100 loss 9.967450 loss_att 460.542969 loss_ctc 26.637623 loss_rnnt 8.115209 lr 0.00025126 rank 7
2022-12-08 07:55:13,427 DEBUG TRAIN Batch 28/4100 loss 11.990896 loss_att 396.993561 loss_ctc 22.411816 loss_rnnt 10.833016 lr 0.00025128 rank 5
2022-12-08 07:55:13,459 DEBUG TRAIN Batch 28/4100 loss 6.885685 loss_att 413.988373 loss_ctc 15.827705 loss_rnnt 5.892127 lr 0.00025129 rank 6
2022-12-08 07:56:16,759 DEBUG TRAIN Batch 28/4200 loss 2.405227 loss_att 343.001526 loss_ctc 7.587026 loss_rnnt 1.829472 lr 0.00025126 rank 6
2022-12-08 07:56:16,772 DEBUG TRAIN Batch 28/4200 loss 9.554089 loss_att 359.371643 loss_ctc 15.518432 loss_rnnt 8.891385 lr 0.00025127 rank 1
2022-12-08 07:56:16,774 DEBUG TRAIN Batch 28/4200 loss 14.316601 loss_att 382.899048 loss_ctc 23.496803 loss_rnnt 13.296578 lr 0.00025123 rank 0
2022-12-08 07:56:16,775 DEBUG TRAIN Batch 28/4200 loss 11.534975 loss_att 392.711884 loss_ctc 22.587894 loss_rnnt 10.306873 lr 0.00025123 rank 7
2022-12-08 07:56:16,775 DEBUG TRAIN Batch 28/4200 loss 5.226425 loss_att 298.488464 loss_ctc 11.360125 loss_rnnt 4.544903 lr 0.00025124 rank 3
2022-12-08 07:56:16,776 DEBUG TRAIN Batch 28/4200 loss 2.446191 loss_att 339.325317 loss_ctc 9.034747 loss_rnnt 1.714129 lr 0.00025126 rank 2
2022-12-08 07:56:16,784 DEBUG TRAIN Batch 28/4200 loss 16.856794 loss_att 398.064453 loss_ctc 26.404737 loss_rnnt 15.795912 lr 0.00025123 rank 4
2022-12-08 07:56:16,792 DEBUG TRAIN Batch 28/4200 loss 3.878981 loss_att 309.153198 loss_ctc 12.605617 loss_rnnt 2.909355 lr 0.00025125 rank 5
2022-12-08 07:57:30,324 DEBUG TRAIN Batch 28/4300 loss 4.853907 loss_att 324.229553 loss_ctc 8.640416 loss_rnnt 4.433183 lr 0.00025120 rank 7
2022-12-08 07:57:30,325 DEBUG TRAIN Batch 28/4300 loss 4.980877 loss_att 371.870331 loss_ctc 13.382149 loss_rnnt 4.047403 lr 0.00025120 rank 4
2022-12-08 07:57:30,327 DEBUG TRAIN Batch 28/4300 loss 9.987703 loss_att 258.490631 loss_ctc 18.029041 loss_rnnt 9.094221 lr 0.00025120 rank 0
2022-12-08 07:57:30,327 DEBUG TRAIN Batch 28/4300 loss 6.766337 loss_att 296.122314 loss_ctc 11.407813 loss_rnnt 6.250618 lr 0.00025121 rank 3
2022-12-08 07:57:30,329 DEBUG TRAIN Batch 28/4300 loss 6.622775 loss_att 317.629181 loss_ctc 15.250528 loss_rnnt 5.664136 lr 0.00025123 rank 6
2022-12-08 07:57:30,331 DEBUG TRAIN Batch 28/4300 loss 5.038088 loss_att 360.588379 loss_ctc 12.478926 loss_rnnt 4.211329 lr 0.00025122 rank 5
2022-12-08 07:57:30,334 DEBUG TRAIN Batch 28/4300 loss 5.891869 loss_att 285.137360 loss_ctc 11.644241 loss_rnnt 5.252716 lr 0.00025123 rank 2
2022-12-08 07:57:30,334 DEBUG TRAIN Batch 28/4300 loss 10.887988 loss_att 307.490540 loss_ctc 20.617334 loss_rnnt 9.806950 lr 0.00025124 rank 1
2022-12-08 07:58:34,288 DEBUG TRAIN Batch 28/4400 loss 6.738694 loss_att 227.529449 loss_ctc 15.908795 loss_rnnt 5.719794 lr 0.00025117 rank 4
2022-12-08 07:58:34,288 DEBUG TRAIN Batch 28/4400 loss 7.411918 loss_att 174.895340 loss_ctc 17.261133 loss_rnnt 6.317561 lr 0.00025120 rank 2
2022-12-08 07:58:34,289 DEBUG TRAIN Batch 28/4400 loss 11.310244 loss_att 353.896271 loss_ctc 30.946569 loss_rnnt 9.128429 lr 0.00025120 rank 6
2022-12-08 07:58:34,292 DEBUG TRAIN Batch 28/4400 loss 7.835265 loss_att 179.383545 loss_ctc 13.968987 loss_rnnt 7.153741 lr 0.00025117 rank 7
2022-12-08 07:58:34,293 DEBUG TRAIN Batch 28/4400 loss 5.586878 loss_att 324.492218 loss_ctc 9.335396 loss_rnnt 5.170377 lr 0.00025118 rank 5
2022-12-08 07:58:34,296 DEBUG TRAIN Batch 28/4400 loss 4.157097 loss_att 433.731201 loss_ctc 9.935222 loss_rnnt 3.515083 lr 0.00025117 rank 0
2022-12-08 07:58:34,298 DEBUG TRAIN Batch 28/4400 loss 9.436770 loss_att 335.431244 loss_ctc 19.245579 loss_rnnt 8.346903 lr 0.00025118 rank 3
2022-12-08 07:58:34,333 DEBUG TRAIN Batch 28/4400 loss 6.502305 loss_att 239.703232 loss_ctc 13.147720 loss_rnnt 5.763925 lr 0.00025121 rank 1
2022-12-08 07:59:37,593 DEBUG TRAIN Batch 28/4500 loss 4.215576 loss_att 343.753845 loss_ctc 7.824382 loss_rnnt 3.814598 lr 0.00025117 rank 2
2022-12-08 07:59:37,595 DEBUG TRAIN Batch 28/4500 loss 6.723300 loss_att 446.722260 loss_ctc 19.165930 loss_rnnt 5.340786 lr 0.00025115 rank 3
2022-12-08 07:59:37,603 DEBUG TRAIN Batch 28/4500 loss 7.126235 loss_att 355.624359 loss_ctc 19.949421 loss_rnnt 5.701437 lr 0.00025114 rank 4
2022-12-08 07:59:37,606 DEBUG TRAIN Batch 28/4500 loss 6.241092 loss_att 156.362335 loss_ctc 9.610097 loss_rnnt 5.866759 lr 0.00025117 rank 6
2022-12-08 07:59:37,606 DEBUG TRAIN Batch 28/4500 loss 6.791385 loss_att 440.668793 loss_ctc 15.133986 loss_rnnt 5.864429 lr 0.00025114 rank 7
2022-12-08 07:59:37,613 DEBUG TRAIN Batch 28/4500 loss 9.050031 loss_att 443.295746 loss_ctc 20.092514 loss_rnnt 7.823089 lr 0.00025114 rank 0
2022-12-08 07:59:37,614 DEBUG TRAIN Batch 28/4500 loss 7.975620 loss_att 154.310471 loss_ctc 14.768095 loss_rnnt 7.220901 lr 0.00025115 rank 5
2022-12-08 07:59:37,645 DEBUG TRAIN Batch 28/4500 loss 2.208690 loss_att 358.296478 loss_ctc 6.312506 loss_rnnt 1.752710 lr 0.00025117 rank 1
2022-12-08 08:00:42,528 DEBUG TRAIN Batch 28/4600 loss 3.622259 loss_att 350.329285 loss_ctc 8.025739 loss_rnnt 3.132983 lr 0.00025110 rank 4
2022-12-08 08:00:42,529 DEBUG TRAIN Batch 28/4600 loss 2.745788 loss_att 356.716919 loss_ctc 6.854667 loss_rnnt 2.289246 lr 0.00025112 rank 5
2022-12-08 08:00:42,532 DEBUG TRAIN Batch 28/4600 loss 2.750248 loss_att 364.532837 loss_ctc 5.676791 loss_rnnt 2.425077 lr 0.00025110 rank 0
2022-12-08 08:00:42,534 DEBUG TRAIN Batch 28/4600 loss 6.597590 loss_att 360.087738 loss_ctc 10.556422 loss_rnnt 6.157720 lr 0.00025111 rank 3
2022-12-08 08:00:42,545 DEBUG TRAIN Batch 28/4600 loss 3.395623 loss_att 437.263275 loss_ctc 11.358370 loss_rnnt 2.510873 lr 0.00025111 rank 7
2022-12-08 08:00:42,553 DEBUG TRAIN Batch 28/4600 loss 4.490540 loss_att 394.154724 loss_ctc 11.801719 loss_rnnt 3.678186 lr 0.00025113 rank 2
2022-12-08 08:00:42,553 DEBUG TRAIN Batch 28/4600 loss 1.251552 loss_att 384.270935 loss_ctc 6.443199 loss_rnnt 0.674702 lr 0.00025114 rank 1
2022-12-08 08:00:42,570 DEBUG TRAIN Batch 28/4600 loss 6.944159 loss_att 378.844696 loss_ctc 19.284822 loss_rnnt 5.572974 lr 0.00025114 rank 6
2022-12-08 08:01:53,242 DEBUG TRAIN Batch 28/4700 loss 8.612844 loss_att 374.397614 loss_ctc 20.494181 loss_rnnt 7.292696 lr 0.00025107 rank 7
2022-12-08 08:01:53,243 DEBUG TRAIN Batch 28/4700 loss 4.185002 loss_att 390.916107 loss_ctc 9.861206 loss_rnnt 3.554312 lr 0.00025110 rank 6
2022-12-08 08:01:53,246 DEBUG TRAIN Batch 28/4700 loss 8.391039 loss_att 387.510925 loss_ctc 22.218748 loss_rnnt 6.854627 lr 0.00025109 rank 5
2022-12-08 08:01:53,246 DEBUG TRAIN Batch 28/4700 loss 8.698745 loss_att 340.926025 loss_ctc 13.341353 loss_rnnt 8.182899 lr 0.00025107 rank 4
2022-12-08 08:01:53,249 DEBUG TRAIN Batch 28/4700 loss 11.741698 loss_att 442.270203 loss_ctc 23.334558 loss_rnnt 10.453603 lr 0.00025110 rank 2
2022-12-08 08:01:53,250 DEBUG TRAIN Batch 28/4700 loss 4.974225 loss_att 322.918213 loss_ctc 15.843300 loss_rnnt 3.766550 lr 0.00025111 rank 1
2022-12-08 08:01:53,252 DEBUG TRAIN Batch 28/4700 loss 4.804282 loss_att 377.867310 loss_ctc 18.097466 loss_rnnt 3.327262 lr 0.00025107 rank 0
2022-12-08 08:01:53,269 DEBUG TRAIN Batch 28/4700 loss 3.235270 loss_att 384.866791 loss_ctc 6.336890 loss_rnnt 2.890645 lr 0.00025108 rank 3
2022-12-08 08:02:56,481 DEBUG TRAIN Batch 28/4800 loss 3.045537 loss_att 339.508728 loss_ctc 6.091150 loss_rnnt 2.707135 lr 0.00025104 rank 7
2022-12-08 08:02:56,484 DEBUG TRAIN Batch 28/4800 loss 9.166992 loss_att 347.517090 loss_ctc 18.624609 loss_rnnt 8.116146 lr 0.00025104 rank 4
2022-12-08 08:02:56,484 DEBUG TRAIN Batch 28/4800 loss 4.731256 loss_att 396.541809 loss_ctc 15.879732 loss_rnnt 3.492536 lr 0.00025107 rank 6
2022-12-08 08:02:56,485 DEBUG TRAIN Batch 28/4800 loss 3.842786 loss_att 346.992004 loss_ctc 15.270633 loss_rnnt 2.573025 lr 0.00025105 rank 3
2022-12-08 08:02:56,485 DEBUG TRAIN Batch 28/4800 loss 10.324438 loss_att 338.955994 loss_ctc 14.189548 loss_rnnt 9.894981 lr 0.00025108 rank 1
2022-12-08 08:02:56,486 DEBUG TRAIN Batch 28/4800 loss 10.685045 loss_att 354.733337 loss_ctc 24.483849 loss_rnnt 9.151845 lr 0.00025107 rank 2
2022-12-08 08:02:56,489 DEBUG TRAIN Batch 28/4800 loss 5.368421 loss_att 319.971497 loss_ctc 9.372589 loss_rnnt 4.923513 lr 0.00025104 rank 0
2022-12-08 08:02:56,494 DEBUG TRAIN Batch 28/4800 loss 6.933806 loss_att 375.605530 loss_ctc 16.372007 loss_rnnt 5.885118 lr 0.00025106 rank 5
2022-12-08 08:04:00,016 DEBUG TRAIN Batch 28/4900 loss 8.513214 loss_att 379.033203 loss_ctc 18.779842 loss_rnnt 7.372478 lr 0.00025101 rank 4
2022-12-08 08:04:00,017 DEBUG TRAIN Batch 28/4900 loss 5.919259 loss_att 346.731873 loss_ctc 14.519819 loss_rnnt 4.963641 lr 0.00025104 rank 6
2022-12-08 08:04:00,019 DEBUG TRAIN Batch 28/4900 loss 7.467582 loss_att 357.195740 loss_ctc 16.983807 loss_rnnt 6.410224 lr 0.00025101 rank 7
2022-12-08 08:04:00,019 DEBUG TRAIN Batch 28/4900 loss 3.435559 loss_att 360.300568 loss_ctc 5.707109 loss_rnnt 3.183164 lr 0.00025104 rank 2
2022-12-08 08:04:00,020 DEBUG TRAIN Batch 28/4900 loss 6.422488 loss_att 404.432434 loss_ctc 14.577225 loss_rnnt 5.516407 lr 0.00025103 rank 5
2022-12-08 08:04:00,022 DEBUG TRAIN Batch 28/4900 loss 9.542996 loss_att 377.865234 loss_ctc 19.358795 loss_rnnt 8.452353 lr 0.00025105 rank 1
2022-12-08 08:04:00,024 DEBUG TRAIN Batch 28/4900 loss 3.871424 loss_att 307.599945 loss_ctc 11.305085 loss_rnnt 3.045462 lr 0.00025101 rank 0
2022-12-08 08:04:00,043 DEBUG TRAIN Batch 28/4900 loss 6.428335 loss_att 365.911377 loss_ctc 15.865698 loss_rnnt 5.379739 lr 0.00025102 rank 3
2022-12-08 08:05:12,960 DEBUG TRAIN Batch 28/5000 loss 6.290901 loss_att 357.779633 loss_ctc 17.022110 loss_rnnt 5.098545 lr 0.00025098 rank 4
2022-12-08 08:05:12,972 DEBUG TRAIN Batch 28/5000 loss 7.812631 loss_att 274.058350 loss_ctc 14.850413 loss_rnnt 7.030655 lr 0.00025098 rank 7
2022-12-08 08:05:12,974 DEBUG TRAIN Batch 28/5000 loss 12.385156 loss_att 285.418060 loss_ctc 16.180092 loss_rnnt 11.963496 lr 0.00025101 rank 2
2022-12-08 08:05:12,977 DEBUG TRAIN Batch 28/5000 loss 10.240219 loss_att 146.499710 loss_ctc 16.607637 loss_rnnt 9.532728 lr 0.00025098 rank 0
2022-12-08 08:05:12,978 DEBUG TRAIN Batch 28/5000 loss 5.432697 loss_att 373.741211 loss_ctc 14.716108 loss_rnnt 4.401206 lr 0.00025101 rank 6
2022-12-08 08:05:12,981 DEBUG TRAIN Batch 28/5000 loss 14.982790 loss_att 345.903656 loss_ctc 21.343201 loss_rnnt 14.276078 lr 0.00025099 rank 3
2022-12-08 08:05:12,986 DEBUG TRAIN Batch 28/5000 loss 10.935194 loss_att 369.859863 loss_ctc 21.654591 loss_rnnt 9.744150 lr 0.00025099 rank 5
2022-12-08 08:05:13,012 DEBUG TRAIN Batch 28/5000 loss 13.085795 loss_att 330.503326 loss_ctc 26.970112 loss_rnnt 11.543094 lr 0.00025102 rank 1
2022-12-08 08:06:16,357 DEBUG TRAIN Batch 28/5100 loss 5.630073 loss_att 433.462463 loss_ctc 10.392685 loss_rnnt 5.100894 lr 0.00025095 rank 4
2022-12-08 08:06:16,358 DEBUG TRAIN Batch 28/5100 loss 7.924862 loss_att 75.403076 loss_ctc 12.744314 loss_rnnt 7.389367 lr 0.00025096 rank 3
2022-12-08 08:06:16,358 DEBUG TRAIN Batch 28/5100 loss 13.890509 loss_att 410.835205 loss_ctc 20.691212 loss_rnnt 13.134875 lr 0.00025095 rank 7
2022-12-08 08:06:16,358 DEBUG TRAIN Batch 28/5100 loss 10.238462 loss_att 256.456116 loss_ctc 20.121027 loss_rnnt 9.140400 lr 0.00025098 rank 6
2022-12-08 08:06:16,360 DEBUG TRAIN Batch 28/5100 loss 8.967520 loss_att 333.171783 loss_ctc 20.416653 loss_rnnt 7.695394 lr 0.00025096 rank 5
2022-12-08 08:06:16,364 DEBUG TRAIN Batch 28/5100 loss 7.434303 loss_att 422.832214 loss_ctc 17.647133 loss_rnnt 6.299544 lr 0.00025095 rank 0
2022-12-08 08:06:16,370 DEBUG TRAIN Batch 28/5100 loss 6.649688 loss_att 155.877869 loss_ctc 11.262226 loss_rnnt 6.137184 lr 0.00025098 rank 1
2022-12-08 08:06:16,404 DEBUG TRAIN Batch 28/5100 loss 2.045745 loss_att 400.086761 loss_ctc 4.799487 loss_rnnt 1.739774 lr 0.00025098 rank 2
2022-12-08 08:07:19,547 DEBUG TRAIN Batch 28/5200 loss 4.178782 loss_att 426.727722 loss_ctc 12.875758 loss_rnnt 3.212451 lr 0.00025095 rank 1
2022-12-08 08:07:19,555 DEBUG TRAIN Batch 28/5200 loss 3.887609 loss_att 345.061829 loss_ctc 4.783092 loss_rnnt 3.788111 lr 0.00025092 rank 7
2022-12-08 08:07:19,560 DEBUG TRAIN Batch 28/5200 loss 6.694816 loss_att 366.873260 loss_ctc 15.130051 loss_rnnt 5.757567 lr 0.00025091 rank 4
2022-12-08 08:07:19,561 DEBUG TRAIN Batch 28/5200 loss 15.131212 loss_att 400.655365 loss_ctc 27.947376 loss_rnnt 13.707194 lr 0.00025095 rank 6
2022-12-08 08:07:19,562 DEBUG TRAIN Batch 28/5200 loss 11.174154 loss_att 396.903809 loss_ctc 21.957441 loss_rnnt 9.976011 lr 0.00025094 rank 2
2022-12-08 08:07:19,563 DEBUG TRAIN Batch 28/5200 loss 9.102386 loss_att 364.780029 loss_ctc 22.700741 loss_rnnt 7.591459 lr 0.00025091 rank 0
2022-12-08 08:07:19,563 DEBUG TRAIN Batch 28/5200 loss 6.756843 loss_att 459.898865 loss_ctc 19.509426 loss_rnnt 5.339889 lr 0.00025093 rank 5
2022-12-08 08:07:19,598 DEBUG TRAIN Batch 28/5200 loss 7.063002 loss_att 372.481689 loss_ctc 9.725592 loss_rnnt 6.767159 lr 0.00025092 rank 3
2022-12-08 08:08:24,469 DEBUG TRAIN Batch 28/5300 loss 8.004386 loss_att 330.522583 loss_ctc 15.898455 loss_rnnt 7.127267 lr 0.00025090 rank 5
2022-12-08 08:08:24,472 DEBUG TRAIN Batch 28/5300 loss 10.324310 loss_att 458.247498 loss_ctc 21.836599 loss_rnnt 9.045168 lr 0.00025092 rank 1
2022-12-08 08:08:24,474 DEBUG TRAIN Batch 28/5300 loss 3.449260 loss_att 342.563904 loss_ctc 8.146284 loss_rnnt 2.927369 lr 0.00025091 rank 2
2022-12-08 08:08:24,475 DEBUG TRAIN Batch 28/5300 loss 3.158113 loss_att 363.587280 loss_ctc 9.165611 loss_rnnt 2.490613 lr 0.00025088 rank 7
2022-12-08 08:08:24,479 DEBUG TRAIN Batch 28/5300 loss 4.772713 loss_att 349.345215 loss_ctc 12.895297 loss_rnnt 3.870204 lr 0.00025088 rank 4
2022-12-08 08:08:24,482 DEBUG TRAIN Batch 28/5300 loss 2.482975 loss_att 341.060730 loss_ctc 11.666042 loss_rnnt 1.462634 lr 0.00025088 rank 0
2022-12-08 08:08:24,482 DEBUG TRAIN Batch 28/5300 loss 3.161608 loss_att 344.096680 loss_ctc 11.938190 loss_rnnt 2.186432 lr 0.00025089 rank 3
2022-12-08 08:08:24,516 DEBUG TRAIN Batch 28/5300 loss 6.882703 loss_att 391.742676 loss_ctc 17.115955 loss_rnnt 5.745675 lr 0.00025091 rank 6
2022-12-08 08:09:36,336 DEBUG TRAIN Batch 28/5400 loss 10.895639 loss_att 397.063538 loss_ctc 19.902727 loss_rnnt 9.894853 lr 0.00025088 rank 2
2022-12-08 08:09:36,346 DEBUG TRAIN Batch 28/5400 loss 6.238578 loss_att 352.311707 loss_ctc 19.727667 loss_rnnt 4.739790 lr 0.00025086 rank 3
2022-12-08 08:09:36,348 DEBUG TRAIN Batch 28/5400 loss 5.372388 loss_att 360.521362 loss_ctc 13.571127 loss_rnnt 4.461417 lr 0.00025085 rank 7
2022-12-08 08:09:36,348 DEBUG TRAIN Batch 28/5400 loss 8.010542 loss_att 362.857819 loss_ctc 16.151901 loss_rnnt 7.105946 lr 0.00025085 rank 4
2022-12-08 08:09:36,349 DEBUG TRAIN Batch 28/5400 loss 3.511673 loss_att 420.606628 loss_ctc 7.399147 loss_rnnt 3.079731 lr 0.00025087 rank 5
2022-12-08 08:09:36,351 DEBUG TRAIN Batch 28/5400 loss 9.498528 loss_att 437.110718 loss_ctc 22.697132 loss_rnnt 8.032018 lr 0.00025089 rank 1
2022-12-08 08:09:36,352 DEBUG TRAIN Batch 28/5400 loss 4.841826 loss_att 449.997406 loss_ctc 10.907114 loss_rnnt 4.167906 lr 0.00025085 rank 0
2022-12-08 08:09:36,395 DEBUG TRAIN Batch 28/5400 loss 4.898895 loss_att 365.094055 loss_ctc 11.265434 loss_rnnt 4.191502 lr 0.00025088 rank 6
2022-12-08 08:10:40,275 DEBUG TRAIN Batch 28/5500 loss 14.024156 loss_att 449.986328 loss_ctc 22.537014 loss_rnnt 13.078283 lr 0.00025085 rank 6
2022-12-08 08:10:40,280 DEBUG TRAIN Batch 28/5500 loss 11.036832 loss_att 398.202576 loss_ctc 16.032537 loss_rnnt 10.481754 lr 0.00025082 rank 4
2022-12-08 08:10:40,281 DEBUG TRAIN Batch 28/5500 loss 3.174089 loss_att 282.772247 loss_ctc 9.364904 loss_rnnt 2.486221 lr 0.00025082 rank 7
2022-12-08 08:10:40,284 DEBUG TRAIN Batch 28/5500 loss 9.593601 loss_att 339.812561 loss_ctc 18.299513 loss_rnnt 8.626278 lr 0.00025082 rank 0
2022-12-08 08:10:40,284 DEBUG TRAIN Batch 28/5500 loss 2.621439 loss_att 323.673431 loss_ctc 7.081421 loss_rnnt 2.125886 lr 0.00025084 rank 5
2022-12-08 08:10:40,293 DEBUG TRAIN Batch 28/5500 loss 10.998200 loss_att 412.933655 loss_ctc 21.003019 loss_rnnt 9.886555 lr 0.00025083 rank 3
2022-12-08 08:10:40,310 DEBUG TRAIN Batch 28/5500 loss 7.647220 loss_att 341.032806 loss_ctc 19.292862 loss_rnnt 6.353260 lr 0.00025086 rank 1
2022-12-08 08:10:40,319 DEBUG TRAIN Batch 28/5500 loss 6.839621 loss_att 346.581604 loss_ctc 12.546556 loss_rnnt 6.205517 lr 0.00025085 rank 2
2022-12-08 08:11:44,096 DEBUG TRAIN Batch 28/5600 loss 13.276928 loss_att 353.956360 loss_ctc 20.771631 loss_rnnt 12.444184 lr 0.00025080 rank 3
2022-12-08 08:11:44,097 DEBUG TRAIN Batch 28/5600 loss 5.339092 loss_att 346.100586 loss_ctc 16.082981 loss_rnnt 4.145327 lr 0.00025083 rank 1
2022-12-08 08:11:44,098 DEBUG TRAIN Batch 28/5600 loss 8.436060 loss_att 299.322998 loss_ctc 16.279903 loss_rnnt 7.564521 lr 0.00025079 rank 7
2022-12-08 08:11:44,098 DEBUG TRAIN Batch 28/5600 loss 8.996440 loss_att 299.775391 loss_ctc 16.988140 loss_rnnt 8.108473 lr 0.00025079 rank 4
2022-12-08 08:11:44,100 DEBUG TRAIN Batch 28/5600 loss 3.179185 loss_att 353.537109 loss_ctc 10.095777 loss_rnnt 2.410675 lr 0.00025082 rank 6
2022-12-08 08:11:44,101 DEBUG TRAIN Batch 28/5600 loss 8.496466 loss_att 151.392883 loss_ctc 13.252871 loss_rnnt 7.967976 lr 0.00025079 rank 0
2022-12-08 08:11:44,106 DEBUG TRAIN Batch 28/5600 loss 7.133080 loss_att 398.546936 loss_ctc 19.150219 loss_rnnt 5.797843 lr 0.00025080 rank 5
2022-12-08 08:11:44,106 DEBUG TRAIN Batch 28/5600 loss 5.948672 loss_att 202.169479 loss_ctc 9.983483 loss_rnnt 5.500360 lr 0.00025082 rank 2
2022-12-08 08:12:56,757 DEBUG TRAIN Batch 28/5700 loss 6.700140 loss_att 137.041733 loss_ctc 10.758371 loss_rnnt 6.249226 lr 0.00025076 rank 4
2022-12-08 08:12:56,758 DEBUG TRAIN Batch 28/5700 loss 2.893157 loss_att 309.240845 loss_ctc 4.243529 loss_rnnt 2.743115 lr 0.00025076 rank 7
2022-12-08 08:12:56,762 DEBUG TRAIN Batch 28/5700 loss 7.098763 loss_att 377.677826 loss_ctc 15.506472 loss_rnnt 6.164574 lr 0.00025079 rank 2
2022-12-08 08:12:56,763 DEBUG TRAIN Batch 28/5700 loss 5.287647 loss_att 196.378128 loss_ctc 8.775966 loss_rnnt 4.900056 lr 0.00025077 rank 3
2022-12-08 08:12:56,766 DEBUG TRAIN Batch 28/5700 loss 8.654427 loss_att 258.035919 loss_ctc 14.483069 loss_rnnt 8.006800 lr 0.00025079 rank 6
2022-12-08 08:12:56,768 DEBUG TRAIN Batch 28/5700 loss 3.499192 loss_att 300.401733 loss_ctc 10.788120 loss_rnnt 2.689311 lr 0.00025077 rank 5
2022-12-08 08:12:56,777 DEBUG TRAIN Batch 28/5700 loss 6.446986 loss_att 335.322266 loss_ctc 12.700751 loss_rnnt 5.752123 lr 0.00025076 rank 0
2022-12-08 08:12:56,808 DEBUG TRAIN Batch 28/5700 loss 9.460004 loss_att 131.520264 loss_ctc 18.276739 loss_rnnt 8.480367 lr 0.00025079 rank 1
2022-12-08 08:13:59,981 DEBUG TRAIN Batch 28/5800 loss 2.783433 loss_att 392.185028 loss_ctc 3.951699 loss_rnnt 2.653626 lr 0.00025076 rank 1
2022-12-08 08:13:59,993 DEBUG TRAIN Batch 28/5800 loss 7.444081 loss_att 426.662079 loss_ctc 17.790516 loss_rnnt 6.294477 lr 0.00025073 rank 4
2022-12-08 08:13:59,995 DEBUG TRAIN Batch 28/5800 loss 3.236277 loss_att 337.603943 loss_ctc 6.724858 loss_rnnt 2.848657 lr 0.00025073 rank 7
2022-12-08 08:13:59,999 DEBUG TRAIN Batch 28/5800 loss 8.881426 loss_att 81.173294 loss_ctc 12.813234 loss_rnnt 8.444559 lr 0.00025076 rank 6
2022-12-08 08:14:00,000 DEBUG TRAIN Batch 28/5800 loss 6.381299 loss_att 410.477722 loss_ctc 11.186087 loss_rnnt 5.847434 lr 0.00025072 rank 0
2022-12-08 08:14:00,003 DEBUG TRAIN Batch 28/5800 loss 2.837471 loss_att 335.168091 loss_ctc 7.811002 loss_rnnt 2.284856 lr 0.00025075 rank 2
2022-12-08 08:14:00,006 DEBUG TRAIN Batch 28/5800 loss 11.667517 loss_att 212.016815 loss_ctc 20.814280 loss_rnnt 10.651209 lr 0.00025074 rank 5
2022-12-08 08:14:00,041 DEBUG TRAIN Batch 28/5800 loss 6.315591 loss_att 430.987061 loss_ctc 16.018332 loss_rnnt 5.237509 lr 0.00025073 rank 3
2022-12-08 08:15:02,858 DEBUG TRAIN Batch 28/5900 loss 6.080479 loss_att 329.176636 loss_ctc 8.730711 loss_rnnt 5.786008 lr 0.00025069 rank 4
2022-12-08 08:15:02,858 DEBUG TRAIN Batch 28/5900 loss 5.172336 loss_att 418.057709 loss_ctc 10.645247 loss_rnnt 4.564235 lr 0.00025069 rank 7
2022-12-08 08:15:02,865 DEBUG TRAIN Batch 28/5900 loss 8.387895 loss_att 370.344177 loss_ctc 12.429133 loss_rnnt 7.938869 lr 0.00025069 rank 0
2022-12-08 08:15:02,865 DEBUG TRAIN Batch 28/5900 loss 12.480227 loss_att 363.181732 loss_ctc 22.267391 loss_rnnt 11.392764 lr 0.00025072 rank 6
2022-12-08 08:15:02,866 DEBUG TRAIN Batch 28/5900 loss 8.990829 loss_att 400.442078 loss_ctc 24.130764 loss_rnnt 7.308614 lr 0.00025072 rank 2
2022-12-08 08:15:02,866 DEBUG TRAIN Batch 28/5900 loss 10.421137 loss_att 444.294128 loss_ctc 17.868771 loss_rnnt 9.593622 lr 0.00025070 rank 3
2022-12-08 08:15:02,867 DEBUG TRAIN Batch 28/5900 loss 11.587277 loss_att 426.994141 loss_ctc 19.166876 loss_rnnt 10.745100 lr 0.00025073 rank 1
2022-12-08 08:15:02,873 DEBUG TRAIN Batch 28/5900 loss 7.956058 loss_att 442.533142 loss_ctc 14.444511 loss_rnnt 7.235119 lr 0.00025071 rank 5
2022-12-08 08:16:06,965 DEBUG TRAIN Batch 28/6000 loss 13.888240 loss_att 370.928162 loss_ctc 25.415142 loss_rnnt 12.607473 lr 0.00025067 rank 3
2022-12-08 08:16:06,967 DEBUG TRAIN Batch 28/6000 loss 1.973759 loss_att 358.225098 loss_ctc 8.564215 loss_rnnt 1.241487 lr 0.00025068 rank 5
2022-12-08 08:16:06,971 DEBUG TRAIN Batch 28/6000 loss 7.232663 loss_att 395.420258 loss_ctc 16.227612 loss_rnnt 6.233224 lr 0.00025069 rank 6
2022-12-08 08:16:06,973 DEBUG TRAIN Batch 28/6000 loss 9.131683 loss_att 316.222443 loss_ctc 15.905034 loss_rnnt 8.379089 lr 0.00025066 rank 4
2022-12-08 08:16:06,973 DEBUG TRAIN Batch 28/6000 loss 12.115946 loss_att 321.517944 loss_ctc 22.560192 loss_rnnt 10.955474 lr 0.00025066 rank 7
2022-12-08 08:16:06,975 DEBUG TRAIN Batch 28/6000 loss 10.224314 loss_att 359.753845 loss_ctc 15.542311 loss_rnnt 9.633426 lr 0.00025070 rank 1
2022-12-08 08:16:06,979 DEBUG TRAIN Batch 28/6000 loss 17.675074 loss_att 370.947540 loss_ctc 22.801174 loss_rnnt 17.105507 lr 0.00025069 rank 2
2022-12-08 08:16:06,980 DEBUG TRAIN Batch 28/6000 loss 4.371377 loss_att 326.752808 loss_ctc 9.028438 loss_rnnt 3.853926 lr 0.00025066 rank 0
2022-12-08 08:17:18,415 DEBUG TRAIN Batch 28/6100 loss 8.094628 loss_att 332.805969 loss_ctc 16.503298 loss_rnnt 7.160332 lr 0.00025067 rank 1
2022-12-08 08:17:18,415 DEBUG TRAIN Batch 28/6100 loss 9.916657 loss_att 350.248474 loss_ctc 19.604004 loss_rnnt 8.840286 lr 0.00025063 rank 4
2022-12-08 08:17:18,416 DEBUG TRAIN Batch 28/6100 loss 14.887213 loss_att 366.927490 loss_ctc 31.858202 loss_rnnt 13.001547 lr 0.00025063 rank 0
2022-12-08 08:17:18,416 DEBUG TRAIN Batch 28/6100 loss 6.533211 loss_att 281.890930 loss_ctc 14.584296 loss_rnnt 5.638646 lr 0.00025066 rank 2
2022-12-08 08:17:18,416 DEBUG TRAIN Batch 28/6100 loss 8.141258 loss_att 428.841888 loss_ctc 17.048412 loss_rnnt 7.151575 lr 0.00025066 rank 6
2022-12-08 08:17:18,417 DEBUG TRAIN Batch 28/6100 loss 17.823351 loss_att 333.426758 loss_ctc 34.430737 loss_rnnt 15.978086 lr 0.00025063 rank 7
2022-12-08 08:17:18,417 DEBUG TRAIN Batch 28/6100 loss 5.180789 loss_att 285.664795 loss_ctc 8.717241 loss_rnnt 4.787850 lr 0.00025064 rank 3
2022-12-08 08:17:18,420 DEBUG TRAIN Batch 28/6100 loss 7.996778 loss_att 407.344269 loss_ctc 16.185116 loss_rnnt 7.086963 lr 0.00025065 rank 5
2022-12-08 08:18:21,405 DEBUG TRAIN Batch 28/6200 loss 3.534387 loss_att 261.803345 loss_ctc 9.609726 loss_rnnt 2.859349 lr 0.00025060 rank 7
2022-12-08 08:18:21,414 DEBUG TRAIN Batch 28/6200 loss 7.793180 loss_att 365.714600 loss_ctc 14.851067 loss_rnnt 7.008971 lr 0.00025063 rank 6
2022-12-08 08:18:21,417 DEBUG TRAIN Batch 28/6200 loss 11.845615 loss_att 366.115967 loss_ctc 24.248970 loss_rnnt 10.467464 lr 0.00025060 rank 4
2022-12-08 08:18:21,420 DEBUG TRAIN Batch 28/6200 loss 12.487226 loss_att 280.590637 loss_ctc 23.391872 loss_rnnt 11.275599 lr 0.00025060 rank 0
2022-12-08 08:18:21,422 DEBUG TRAIN Batch 28/6200 loss 3.912650 loss_att 272.524231 loss_ctc 7.598462 loss_rnnt 3.503115 lr 0.00025061 rank 3
2022-12-08 08:18:21,422 DEBUG TRAIN Batch 28/6200 loss 6.386158 loss_att 310.113190 loss_ctc 12.278908 loss_rnnt 5.731409 lr 0.00025063 rank 2
2022-12-08 08:18:21,424 DEBUG TRAIN Batch 28/6200 loss 3.950758 loss_att 340.132935 loss_ctc 11.152620 loss_rnnt 3.150551 lr 0.00025064 rank 1
2022-12-08 08:18:21,461 DEBUG TRAIN Batch 28/6200 loss 7.751368 loss_att 375.754089 loss_ctc 17.857998 loss_rnnt 6.628408 lr 0.00025062 rank 5
2022-12-08 08:19:24,773 DEBUG TRAIN Batch 28/6300 loss 3.102435 loss_att 329.603912 loss_ctc 6.883325 loss_rnnt 2.682337 lr 0.00025058 rank 5
2022-12-08 08:19:24,783 DEBUG TRAIN Batch 28/6300 loss 6.920970 loss_att 451.973694 loss_ctc 16.687191 loss_rnnt 5.835835 lr 0.00025057 rank 0
2022-12-08 08:19:24,786 DEBUG TRAIN Batch 28/6300 loss 6.484226 loss_att 216.851669 loss_ctc 14.196798 loss_rnnt 5.627274 lr 0.00025057 rank 4
2022-12-08 08:19:24,786 DEBUG TRAIN Batch 28/6300 loss 13.514539 loss_att 382.323792 loss_ctc 28.642319 loss_rnnt 11.833674 lr 0.00025060 rank 2
2022-12-08 08:19:24,787 DEBUG TRAIN Batch 28/6300 loss 7.838145 loss_att 238.387695 loss_ctc 11.820492 loss_rnnt 7.395662 lr 0.00025061 rank 1
2022-12-08 08:19:24,788 DEBUG TRAIN Batch 28/6300 loss 5.295786 loss_att 266.935059 loss_ctc 10.816901 loss_rnnt 4.682329 lr 0.00025058 rank 3
2022-12-08 08:19:24,789 DEBUG TRAIN Batch 28/6300 loss 14.385239 loss_att 380.252686 loss_ctc 23.101185 loss_rnnt 13.416800 lr 0.00025060 rank 6
2022-12-08 08:19:24,790 DEBUG TRAIN Batch 28/6300 loss 9.669565 loss_att 379.548279 loss_ctc 15.830200 loss_rnnt 8.985050 lr 0.00025057 rank 7
2022-12-08 08:20:38,200 DEBUG TRAIN Batch 28/6400 loss 4.381991 loss_att 423.174866 loss_ctc 5.524953 loss_rnnt 4.254995 lr 0.00025054 rank 7
2022-12-08 08:20:38,202 DEBUG TRAIN Batch 28/6400 loss 12.910076 loss_att 182.299591 loss_ctc 20.157635 loss_rnnt 12.104793 lr 0.00025055 rank 3
2022-12-08 08:20:38,202 DEBUG TRAIN Batch 28/6400 loss 6.826716 loss_att 309.632904 loss_ctc 13.175295 loss_rnnt 6.121319 lr 0.00025057 rank 6
2022-12-08 08:20:38,203 DEBUG TRAIN Batch 28/6400 loss 5.393263 loss_att 393.233948 loss_ctc 10.742933 loss_rnnt 4.798855 lr 0.00025054 rank 4
2022-12-08 08:20:38,205 DEBUG TRAIN Batch 28/6400 loss 6.409019 loss_att 329.342896 loss_ctc 15.236284 loss_rnnt 5.428213 lr 0.00025057 rank 2
2022-12-08 08:20:38,209 DEBUG TRAIN Batch 28/6400 loss 4.928079 loss_att 373.647064 loss_ctc 14.093904 loss_rnnt 3.909654 lr 0.00025054 rank 0
2022-12-08 08:20:38,211 DEBUG TRAIN Batch 28/6400 loss 6.647936 loss_att 281.400726 loss_ctc 13.396274 loss_rnnt 5.898121 lr 0.00025055 rank 5
2022-12-08 08:20:38,241 DEBUG TRAIN Batch 28/6400 loss 9.080004 loss_att 411.197205 loss_ctc 18.681921 loss_rnnt 8.013124 lr 0.00025057 rank 1
2022-12-08 08:21:41,622 DEBUG TRAIN Batch 28/6500 loss 12.316896 loss_att 381.945160 loss_ctc 17.363117 loss_rnnt 11.756206 lr 0.00025050 rank 4
2022-12-08 08:21:41,623 DEBUG TRAIN Batch 28/6500 loss 6.976696 loss_att 372.689636 loss_ctc 16.869268 loss_rnnt 5.877522 lr 0.00025054 rank 6
2022-12-08 08:21:41,625 DEBUG TRAIN Batch 28/6500 loss 9.320818 loss_att 388.941589 loss_ctc 23.594687 loss_rnnt 7.734833 lr 0.00025051 rank 7
2022-12-08 08:21:41,625 DEBUG TRAIN Batch 28/6500 loss 14.271598 loss_att 437.388763 loss_ctc 33.350292 loss_rnnt 12.151743 lr 0.00025053 rank 2
2022-12-08 08:21:41,629 DEBUG TRAIN Batch 28/6500 loss 14.667285 loss_att 428.004578 loss_ctc 26.343328 loss_rnnt 13.369947 lr 0.00025054 rank 1
2022-12-08 08:21:41,629 DEBUG TRAIN Batch 28/6500 loss 11.251457 loss_att 349.555969 loss_ctc 21.437918 loss_rnnt 10.119628 lr 0.00025051 rank 3
2022-12-08 08:21:41,630 DEBUG TRAIN Batch 28/6500 loss 8.237616 loss_att 408.335297 loss_ctc 13.189352 loss_rnnt 7.687423 lr 0.00025050 rank 0
2022-12-08 08:21:41,631 DEBUG TRAIN Batch 28/6500 loss 6.595912 loss_att 365.063232 loss_ctc 13.103689 loss_rnnt 5.872826 lr 0.00025052 rank 5
2022-12-08 08:22:45,086 DEBUG TRAIN Batch 28/6600 loss 4.251037 loss_att 334.903595 loss_ctc 7.210781 loss_rnnt 3.922176 lr 0.00025047 rank 4
2022-12-08 08:22:45,089 DEBUG TRAIN Batch 28/6600 loss 7.492640 loss_att 356.906677 loss_ctc 13.315060 loss_rnnt 6.845705 lr 0.00025048 rank 3
2022-12-08 08:22:45,089 DEBUG TRAIN Batch 28/6600 loss 11.817951 loss_att 430.262817 loss_ctc 24.860010 loss_rnnt 10.368834 lr 0.00025047 rank 7
2022-12-08 08:22:45,092 DEBUG TRAIN Batch 28/6600 loss 6.487290 loss_att 431.954102 loss_ctc 18.434044 loss_rnnt 5.159873 lr 0.00025050 rank 6
2022-12-08 08:22:45,096 DEBUG TRAIN Batch 28/6600 loss 8.040713 loss_att 373.798309 loss_ctc 24.554525 loss_rnnt 6.205845 lr 0.00025050 rank 2
2022-12-08 08:22:45,097 DEBUG TRAIN Batch 28/6600 loss 10.358061 loss_att 373.799866 loss_ctc 23.734642 loss_rnnt 8.871774 lr 0.00025047 rank 0
2022-12-08 08:22:45,100 DEBUG TRAIN Batch 28/6600 loss 4.138094 loss_att 408.955811 loss_ctc 10.348351 loss_rnnt 3.448065 lr 0.00025049 rank 5
2022-12-08 08:22:45,101 DEBUG TRAIN Batch 28/6600 loss 4.469681 loss_att 353.073914 loss_ctc 13.387428 loss_rnnt 3.478820 lr 0.00025051 rank 1
2022-12-08 08:23:49,429 DEBUG TRAIN Batch 28/6700 loss 11.469022 loss_att 408.118469 loss_ctc 23.935740 loss_rnnt 10.083832 lr 0.00025044 rank 4
2022-12-08 08:23:49,435 DEBUG TRAIN Batch 28/6700 loss 4.072075 loss_att 301.177673 loss_ctc 13.926504 loss_rnnt 2.977139 lr 0.00025047 rank 6
2022-12-08 08:23:49,438 DEBUG TRAIN Batch 28/6700 loss 5.068753 loss_att 333.287842 loss_ctc 8.379648 loss_rnnt 4.700876 lr 0.00025047 rank 2
2022-12-08 08:23:49,442 DEBUG TRAIN Batch 28/6700 loss 4.799285 loss_att 357.295898 loss_ctc 10.291765 loss_rnnt 4.189010 lr 0.00025046 rank 5
2022-12-08 08:23:49,442 DEBUG TRAIN Batch 28/6700 loss 12.972244 loss_att 344.707184 loss_ctc 23.539474 loss_rnnt 11.798108 lr 0.00025044 rank 7
2022-12-08 08:23:49,443 DEBUG TRAIN Batch 28/6700 loss 11.403482 loss_att 373.283966 loss_ctc 20.525982 loss_rnnt 10.389872 lr 0.00025045 rank 3
2022-12-08 08:23:49,443 DEBUG TRAIN Batch 28/6700 loss 10.199911 loss_att 408.312469 loss_ctc 15.184904 loss_rnnt 9.646023 lr 0.00025048 rank 1
2022-12-08 08:23:49,450 DEBUG TRAIN Batch 28/6700 loss 3.725400 loss_att 333.888794 loss_ctc 12.129578 loss_rnnt 2.791603 lr 0.00025044 rank 0
2022-12-08 08:25:01,594 DEBUG TRAIN Batch 28/6800 loss 8.026514 loss_att 353.226562 loss_ctc 18.349426 loss_rnnt 6.879524 lr 0.00025042 rank 3
2022-12-08 08:25:01,595 DEBUG TRAIN Batch 28/6800 loss 8.707920 loss_att 299.560974 loss_ctc 18.629240 loss_rnnt 7.605551 lr 0.00025041 rank 7
2022-12-08 08:25:01,595 DEBUG TRAIN Batch 28/6800 loss 11.102860 loss_att 296.312469 loss_ctc 18.599920 loss_rnnt 10.269855 lr 0.00025044 rank 2
2022-12-08 08:25:01,599 DEBUG TRAIN Batch 28/6800 loss 11.661932 loss_att 378.698792 loss_ctc 20.051556 loss_rnnt 10.729752 lr 0.00025041 rank 4
2022-12-08 08:25:01,599 DEBUG TRAIN Batch 28/6800 loss 5.824736 loss_att 381.164490 loss_ctc 10.073779 loss_rnnt 5.352620 lr 0.00025045 rank 1
2022-12-08 08:25:01,599 DEBUG TRAIN Batch 28/6800 loss 5.694150 loss_att 376.584839 loss_ctc 12.576353 loss_rnnt 4.929461 lr 0.00025044 rank 6
2022-12-08 08:25:01,607 DEBUG TRAIN Batch 28/6800 loss 12.542799 loss_att 264.883698 loss_ctc 22.616428 loss_rnnt 11.423508 lr 0.00025041 rank 0
2022-12-08 08:25:01,644 DEBUG TRAIN Batch 28/6800 loss 7.667122 loss_att 426.548889 loss_ctc 18.174376 loss_rnnt 6.499650 lr 0.00025043 rank 5
2022-12-08 08:26:05,008 DEBUG TRAIN Batch 28/6900 loss 6.341871 loss_att 291.093323 loss_ctc 14.479949 loss_rnnt 5.437641 lr 0.00025038 rank 4
2022-12-08 08:26:05,009 DEBUG TRAIN Batch 28/6900 loss 8.256462 loss_att 126.429459 loss_ctc 15.279116 loss_rnnt 7.476167 lr 0.00025038 rank 7
2022-12-08 08:26:05,009 DEBUG TRAIN Batch 28/6900 loss 11.880919 loss_att 288.321014 loss_ctc 18.920099 loss_rnnt 11.098789 lr 0.00025042 rank 1
2022-12-08 08:26:05,010 DEBUG TRAIN Batch 28/6900 loss 4.506639 loss_att 342.997986 loss_ctc 13.075610 loss_rnnt 3.554531 lr 0.00025039 rank 3
2022-12-08 08:26:05,010 DEBUG TRAIN Batch 28/6900 loss 3.095832 loss_att 319.134491 loss_ctc 7.349025 loss_rnnt 2.623255 lr 0.00025041 rank 6
2022-12-08 08:26:05,011 DEBUG TRAIN Batch 28/6900 loss 6.020079 loss_att 392.327515 loss_ctc 12.988085 loss_rnnt 5.245856 lr 0.00025041 rank 2
2022-12-08 08:26:05,012 DEBUG TRAIN Batch 28/6900 loss 9.095836 loss_att 388.681580 loss_ctc 21.497002 loss_rnnt 7.717928 lr 0.00025040 rank 5
2022-12-08 08:26:05,014 DEBUG TRAIN Batch 28/6900 loss 1.171877 loss_att 362.370453 loss_ctc 4.832497 loss_rnnt 0.765141 lr 0.00025038 rank 0
2022-12-08 08:27:07,963 DEBUG TRAIN Batch 28/7000 loss 8.362876 loss_att 69.904053 loss_ctc 13.335706 loss_rnnt 7.810339 lr 0.00025035 rank 4
2022-12-08 08:27:07,965 DEBUG TRAIN Batch 28/7000 loss 5.348805 loss_att 381.960938 loss_ctc 10.497915 loss_rnnt 4.776682 lr 0.00025035 rank 7
2022-12-08 08:27:07,966 DEBUG TRAIN Batch 28/7000 loss 9.930751 loss_att 344.122894 loss_ctc 18.039984 loss_rnnt 9.029726 lr 0.00025038 rank 6
2022-12-08 08:27:07,967 DEBUG TRAIN Batch 28/7000 loss 8.157573 loss_att 393.469788 loss_ctc 20.846096 loss_rnnt 6.747737 lr 0.00025038 rank 2
2022-12-08 08:27:07,967 DEBUG TRAIN Batch 28/7000 loss 7.050422 loss_att 250.184692 loss_ctc 14.662090 loss_rnnt 6.204681 lr 0.00025036 rank 3
2022-12-08 08:27:07,969 DEBUG TRAIN Batch 28/7000 loss 4.603764 loss_att 442.597107 loss_ctc 13.501033 loss_rnnt 3.615179 lr 0.00025035 rank 0
2022-12-08 08:27:07,975 DEBUG TRAIN Batch 28/7000 loss 7.672030 loss_att 336.212402 loss_ctc 18.317326 loss_rnnt 6.489220 lr 0.00025036 rank 5
2022-12-08 08:27:08,013 DEBUG TRAIN Batch 28/7000 loss 6.397539 loss_att 222.065781 loss_ctc 13.488399 loss_rnnt 5.609666 lr 0.00025039 rank 1
2022-12-08 08:28:20,988 DEBUG TRAIN Batch 28/7100 loss 3.041104 loss_att 355.853271 loss_ctc 4.964805 loss_rnnt 2.827360 lr 0.00025032 rank 4
2022-12-08 08:28:20,990 DEBUG TRAIN Batch 28/7100 loss 3.787034 loss_att 397.427490 loss_ctc 6.926155 loss_rnnt 3.438243 lr 0.00025035 rank 1
2022-12-08 08:28:20,990 DEBUG TRAIN Batch 28/7100 loss 9.985978 loss_att 422.020447 loss_ctc 24.454430 loss_rnnt 8.378372 lr 0.00025032 rank 7
2022-12-08 08:28:20,991 DEBUG TRAIN Batch 28/7100 loss 4.286397 loss_att 389.935272 loss_ctc 14.221746 loss_rnnt 3.182469 lr 0.00025033 rank 3
2022-12-08 08:28:20,992 DEBUG TRAIN Batch 28/7100 loss 11.224930 loss_att 318.931335 loss_ctc 17.495033 loss_rnnt 10.528253 lr 0.00025032 rank 0
2022-12-08 08:28:20,993 DEBUG TRAIN Batch 28/7100 loss 13.034026 loss_att 427.839966 loss_ctc 24.033001 loss_rnnt 11.811918 lr 0.00025035 rank 2
2022-12-08 08:28:20,996 DEBUG TRAIN Batch 28/7100 loss 9.022499 loss_att 440.264099 loss_ctc 21.565290 loss_rnnt 7.628856 lr 0.00025033 rank 5
2022-12-08 08:28:21,034 DEBUG TRAIN Batch 28/7100 loss 9.264932 loss_att 152.138596 loss_ctc 13.855700 loss_rnnt 8.754847 lr 0.00025035 rank 6
2022-12-08 08:29:25,237 DEBUG TRAIN Batch 28/7200 loss 8.269132 loss_att 413.766724 loss_ctc 21.875578 loss_rnnt 6.757304 lr 0.00025029 rank 7
2022-12-08 08:29:25,250 DEBUG TRAIN Batch 28/7200 loss 7.816343 loss_att 387.538086 loss_ctc 15.617582 loss_rnnt 6.949539 lr 0.00025029 rank 4
2022-12-08 08:29:25,250 DEBUG TRAIN Batch 28/7200 loss 2.672578 loss_att 350.538086 loss_ctc 6.313689 loss_rnnt 2.268010 lr 0.00025032 rank 6
2022-12-08 08:29:25,251 DEBUG TRAIN Batch 28/7200 loss 13.335864 loss_att 425.710327 loss_ctc 24.306175 loss_rnnt 12.116941 lr 0.00025031 rank 2
2022-12-08 08:29:25,254 DEBUG TRAIN Batch 28/7200 loss 7.935931 loss_att 391.887817 loss_ctc 17.243370 loss_rnnt 6.901772 lr 0.00025028 rank 0
2022-12-08 08:29:25,255 DEBUG TRAIN Batch 28/7200 loss 2.746912 loss_att 384.820648 loss_ctc 7.151324 loss_rnnt 2.257533 lr 0.00025029 rank 3
2022-12-08 08:29:25,257 DEBUG TRAIN Batch 28/7200 loss 4.391593 loss_att 402.235840 loss_ctc 12.065872 loss_rnnt 3.538895 lr 0.00025032 rank 1
2022-12-08 08:29:25,259 DEBUG TRAIN Batch 28/7200 loss 5.512394 loss_att 487.709961 loss_ctc 16.126442 loss_rnnt 4.333055 lr 0.00025030 rank 5
2022-12-08 08:30:28,767 DEBUG TRAIN Batch 28/7300 loss 2.078863 loss_att 368.588440 loss_ctc 8.609558 loss_rnnt 1.353230 lr 0.00025025 rank 4
2022-12-08 08:30:28,785 DEBUG TRAIN Batch 28/7300 loss 3.133950 loss_att 383.116150 loss_ctc 11.546599 loss_rnnt 2.199211 lr 0.00025026 rank 3
2022-12-08 08:30:28,787 DEBUG TRAIN Batch 28/7300 loss 10.030017 loss_att 362.883942 loss_ctc 19.825800 loss_rnnt 8.941597 lr 0.00025025 rank 0
2022-12-08 08:30:28,787 DEBUG TRAIN Batch 28/7300 loss 8.216425 loss_att 422.050659 loss_ctc 13.095951 loss_rnnt 7.674256 lr 0.00025029 rank 1
2022-12-08 08:30:28,788 DEBUG TRAIN Batch 28/7300 loss 3.830007 loss_att 390.018738 loss_ctc 7.868879 loss_rnnt 3.381243 lr 0.00025025 rank 7
2022-12-08 08:30:28,788 DEBUG TRAIN Batch 28/7300 loss 2.439409 loss_att 365.367188 loss_ctc 5.743166 loss_rnnt 2.072324 lr 0.00025028 rank 2
2022-12-08 08:30:28,792 DEBUG TRAIN Batch 28/7300 loss 27.270308 loss_att 447.344910 loss_ctc 42.519600 loss_rnnt 25.575941 lr 0.00025027 rank 5
2022-12-08 08:30:28,829 DEBUG TRAIN Batch 28/7300 loss 9.929119 loss_att 351.900391 loss_ctc 24.689688 loss_rnnt 8.289056 lr 0.00025028 rank 6
2022-12-08 08:31:32,510 DEBUG TRAIN Batch 28/7400 loss 5.475327 loss_att 336.329041 loss_ctc 15.910051 loss_rnnt 4.315914 lr 0.00025026 rank 1
2022-12-08 08:31:32,510 DEBUG TRAIN Batch 28/7400 loss 3.109881 loss_att 381.259766 loss_ctc 6.422167 loss_rnnt 2.741849 lr 0.00025022 rank 4
2022-12-08 08:31:32,513 DEBUG TRAIN Batch 28/7400 loss 6.734854 loss_att 414.431885 loss_ctc 12.533428 loss_rnnt 6.090568 lr 0.00025025 rank 6
2022-12-08 08:31:32,518 DEBUG TRAIN Batch 28/7400 loss 10.517200 loss_att 345.531189 loss_ctc 15.410528 loss_rnnt 9.973496 lr 0.00025023 rank 3
2022-12-08 08:31:32,519 DEBUG TRAIN Batch 28/7400 loss 15.622913 loss_att 360.484100 loss_ctc 29.872980 loss_rnnt 14.039573 lr 0.00025022 rank 7
2022-12-08 08:31:32,520 DEBUG TRAIN Batch 28/7400 loss 12.009334 loss_att 342.782959 loss_ctc 21.354038 loss_rnnt 10.971033 lr 0.00025022 rank 0
2022-12-08 08:31:32,524 DEBUG TRAIN Batch 28/7400 loss 11.718081 loss_att 382.250427 loss_ctc 26.053234 loss_rnnt 10.125286 lr 0.00025025 rank 2
2022-12-08 08:31:32,532 DEBUG TRAIN Batch 28/7400 loss 8.411110 loss_att 392.298035 loss_ctc 11.359961 loss_rnnt 8.083460 lr 0.00025024 rank 5
2022-12-08 08:32:44,229 DEBUG TRAIN Batch 28/7500 loss 7.231797 loss_att 337.074371 loss_ctc 13.701139 loss_rnnt 6.512981 lr 0.00025019 rank 4
2022-12-08 08:32:44,230 DEBUG TRAIN Batch 28/7500 loss 6.026073 loss_att 192.573181 loss_ctc 12.302851 loss_rnnt 5.328654 lr 0.00025022 rank 2
2022-12-08 08:32:44,232 DEBUG TRAIN Batch 28/7500 loss 7.900227 loss_att 259.350739 loss_ctc 17.796827 loss_rnnt 6.800604 lr 0.00025019 rank 7
2022-12-08 08:32:44,238 DEBUG TRAIN Batch 28/7500 loss 9.534413 loss_att 165.490997 loss_ctc 15.634320 loss_rnnt 8.856647 lr 0.00025019 rank 0
2022-12-08 08:32:44,238 DEBUG TRAIN Batch 28/7500 loss 3.605931 loss_att 314.978638 loss_ctc 8.936663 loss_rnnt 3.013627 lr 0.00025021 rank 5
2022-12-08 08:32:44,241 DEBUG TRAIN Batch 28/7500 loss 8.020245 loss_att 403.566528 loss_ctc 17.504492 loss_rnnt 6.966439 lr 0.00025020 rank 3
2022-12-08 08:32:44,245 DEBUG TRAIN Batch 28/7500 loss 15.871914 loss_att 348.260315 loss_ctc 31.175846 loss_rnnt 14.171478 lr 0.00025022 rank 6
2022-12-08 08:32:44,278 DEBUG TRAIN Batch 28/7500 loss 8.181144 loss_att 324.692261 loss_ctc 14.337680 loss_rnnt 7.497085 lr 0.00025023 rank 1
2022-12-08 08:33:47,296 DEBUG TRAIN Batch 28/7600 loss 5.053536 loss_att 464.098206 loss_ctc 19.554253 loss_rnnt 3.442346 lr 0.00025016 rank 0
2022-12-08 08:33:47,297 DEBUG TRAIN Batch 28/7600 loss 6.247704 loss_att 195.180237 loss_ctc 10.931496 loss_rnnt 5.727283 lr 0.00025016 rank 4
2022-12-08 08:33:47,297 DEBUG TRAIN Batch 28/7600 loss 8.698066 loss_att 400.247162 loss_ctc 17.666889 loss_rnnt 7.701530 lr 0.00025019 rank 2
2022-12-08 08:33:47,297 DEBUG TRAIN Batch 28/7600 loss 6.805837 loss_att 329.156128 loss_ctc 16.122690 loss_rnnt 5.770631 lr 0.00025018 rank 5
2022-12-08 08:33:47,298 DEBUG TRAIN Batch 28/7600 loss 9.289629 loss_att 366.552429 loss_ctc 19.418772 loss_rnnt 8.164169 lr 0.00025016 rank 7
2022-12-08 08:33:47,301 DEBUG TRAIN Batch 28/7600 loss 5.509490 loss_att 297.933685 loss_ctc 12.201477 loss_rnnt 4.765937 lr 0.00025017 rank 3
2022-12-08 08:33:47,301 DEBUG TRAIN Batch 28/7600 loss 8.177151 loss_att 300.698975 loss_ctc 15.707264 loss_rnnt 7.340471 lr 0.00025019 rank 6
2022-12-08 08:33:47,302 DEBUG TRAIN Batch 28/7600 loss 7.672889 loss_att 234.010681 loss_ctc 12.506587 loss_rnnt 7.135811 lr 0.00025020 rank 1
2022-12-08 08:34:50,776 DEBUG TRAIN Batch 28/7700 loss 5.177621 loss_att 435.699066 loss_ctc 17.614006 loss_rnnt 3.795800 lr 0.00025013 rank 7
2022-12-08 08:34:50,777 DEBUG TRAIN Batch 28/7700 loss 9.949566 loss_att 458.723083 loss_ctc 19.682728 loss_rnnt 8.868103 lr 0.00025013 rank 4
2022-12-08 08:34:50,779 DEBUG TRAIN Batch 28/7700 loss 8.104510 loss_att 195.566574 loss_ctc 15.067532 loss_rnnt 7.330841 lr 0.00025016 rank 6
2022-12-08 08:34:50,783 DEBUG TRAIN Batch 28/7700 loss 7.958273 loss_att 271.491516 loss_ctc 21.911083 loss_rnnt 6.407960 lr 0.00025014 rank 5
2022-12-08 08:34:50,783 DEBUG TRAIN Batch 28/7700 loss 10.175279 loss_att 357.902039 loss_ctc 19.759584 loss_rnnt 9.110355 lr 0.00025016 rank 2
2022-12-08 08:34:50,784 DEBUG TRAIN Batch 28/7700 loss 11.052680 loss_att 393.292328 loss_ctc 18.637924 loss_rnnt 10.209875 lr 0.00025017 rank 1
2022-12-08 08:34:50,784 DEBUG TRAIN Batch 28/7700 loss 11.715330 loss_att 427.676605 loss_ctc 24.003250 loss_rnnt 10.350006 lr 0.00025013 rank 0
2022-12-08 08:34:50,800 DEBUG TRAIN Batch 28/7700 loss 8.270842 loss_att 385.866211 loss_ctc 20.594807 loss_rnnt 6.901513 lr 0.00025014 rank 3
2022-12-08 08:35:55,722 DEBUG TRAIN Batch 28/7800 loss 11.486074 loss_att 372.379761 loss_ctc 18.023800 loss_rnnt 10.759662 lr 0.00025010 rank 4
2022-12-08 08:35:55,722 DEBUG TRAIN Batch 28/7800 loss 13.879039 loss_att 445.539307 loss_ctc 18.563541 loss_rnnt 13.358540 lr 0.00025013 rank 6
2022-12-08 08:35:55,723 DEBUG TRAIN Batch 28/7800 loss 7.359540 loss_att 399.294739 loss_ctc 17.268377 loss_rnnt 6.258558 lr 0.00025013 rank 2
2022-12-08 08:35:55,724 DEBUG TRAIN Batch 28/7800 loss 6.579253 loss_att 353.743988 loss_ctc 7.866151 loss_rnnt 6.436265 lr 0.00025013 rank 1
2022-12-08 08:35:55,726 DEBUG TRAIN Batch 28/7800 loss 3.768344 loss_att 374.628876 loss_ctc 11.295572 loss_rnnt 2.931985 lr 0.00025010 rank 7
2022-12-08 08:35:55,727 DEBUG TRAIN Batch 28/7800 loss 5.984855 loss_att 385.814148 loss_ctc 12.007570 loss_rnnt 5.315664 lr 0.00025010 rank 0
2022-12-08 08:35:55,729 DEBUG TRAIN Batch 28/7800 loss 14.672822 loss_att 358.114319 loss_ctc 23.093306 loss_rnnt 13.737213 lr 0.00025011 rank 3
2022-12-08 08:35:55,749 DEBUG TRAIN Batch 28/7800 loss 12.875372 loss_att 416.353882 loss_ctc 27.902525 loss_rnnt 11.205688 lr 0.00025011 rank 5
2022-12-08 08:37:06,186 DEBUG TRAIN Batch 28/7900 loss 11.030043 loss_att 364.955750 loss_ctc 21.553267 loss_rnnt 9.860796 lr 0.00025007 rank 4
2022-12-08 08:37:06,187 DEBUG TRAIN Batch 28/7900 loss 10.574041 loss_att 376.773529 loss_ctc 18.726503 loss_rnnt 9.668213 lr 0.00025007 rank 7
2022-12-08 08:37:06,190 DEBUG TRAIN Batch 28/7900 loss 6.156587 loss_att 373.831726 loss_ctc 12.543791 loss_rnnt 5.446897 lr 0.00025007 rank 0
2022-12-08 08:37:06,191 DEBUG TRAIN Batch 28/7900 loss 13.712034 loss_att 370.050049 loss_ctc 24.299606 loss_rnnt 12.535637 lr 0.00025010 rank 2
2022-12-08 08:37:06,191 DEBUG TRAIN Batch 28/7900 loss 9.353209 loss_att 393.061462 loss_ctc 20.284193 loss_rnnt 8.138655 lr 0.00025010 rank 6
2022-12-08 08:37:06,195 DEBUG TRAIN Batch 28/7900 loss 6.533765 loss_att 383.954773 loss_ctc 9.803738 loss_rnnt 6.170434 lr 0.00025010 rank 1
2022-12-08 08:37:06,197 DEBUG TRAIN Batch 28/7900 loss 10.932862 loss_att 378.130920 loss_ctc 18.559151 loss_rnnt 10.085497 lr 0.00025008 rank 3
2022-12-08 08:37:06,200 DEBUG TRAIN Batch 28/7900 loss 9.815467 loss_att 394.359619 loss_ctc 17.169619 loss_rnnt 8.998340 lr 0.00025008 rank 5
2022-12-08 08:38:08,922 DEBUG TRAIN Batch 28/8000 loss 13.890373 loss_att 444.682312 loss_ctc 25.000652 loss_rnnt 12.655897 lr 0.00025003 rank 4
2022-12-08 08:38:08,925 DEBUG TRAIN Batch 28/8000 loss 12.894033 loss_att 424.689880 loss_ctc 21.780991 loss_rnnt 11.906593 lr 0.00025006 rank 2
2022-12-08 08:38:08,927 DEBUG TRAIN Batch 28/8000 loss 9.615438 loss_att 386.067566 loss_ctc 16.218271 loss_rnnt 8.881790 lr 0.00025004 rank 7
2022-12-08 08:38:08,928 DEBUG TRAIN Batch 28/8000 loss 8.177573 loss_att 346.772858 loss_ctc 15.036892 loss_rnnt 7.415427 lr 0.00025007 rank 1
2022-12-08 08:38:08,929 DEBUG TRAIN Batch 28/8000 loss 8.695212 loss_att 279.152863 loss_ctc 12.146266 loss_rnnt 8.311762 lr 0.00025003 rank 0
2022-12-08 08:38:08,930 DEBUG TRAIN Batch 28/8000 loss 3.632527 loss_att 382.841003 loss_ctc 9.167896 loss_rnnt 3.017486 lr 0.00025004 rank 3
2022-12-08 08:38:08,931 DEBUG TRAIN Batch 28/8000 loss 10.613525 loss_att 387.579865 loss_ctc 21.028740 loss_rnnt 9.456280 lr 0.00025007 rank 6
2022-12-08 08:38:08,934 DEBUG TRAIN Batch 28/8000 loss 9.793872 loss_att 358.585388 loss_ctc 16.366154 loss_rnnt 9.063619 lr 0.00025005 rank 5
2022-12-08 08:39:12,509 DEBUG TRAIN Batch 28/8100 loss 3.130555 loss_att 263.221985 loss_ctc 9.304013 loss_rnnt 2.444615 lr 0.00025000 rank 0
2022-12-08 08:39:12,509 DEBUG TRAIN Batch 28/8100 loss 5.541082 loss_att 344.850403 loss_ctc 7.916870 loss_rnnt 5.277105 lr 0.00025001 rank 3
2022-12-08 08:39:12,510 DEBUG TRAIN Batch 28/8100 loss 11.635391 loss_att 355.462280 loss_ctc 20.064234 loss_rnnt 10.698853 lr 0.00025000 rank 7
2022-12-08 08:39:12,512 DEBUG TRAIN Batch 28/8100 loss 5.277171 loss_att 390.565918 loss_ctc 12.812108 loss_rnnt 4.439956 lr 0.00025000 rank 4
2022-12-08 08:39:12,512 DEBUG TRAIN Batch 28/8100 loss 4.825512 loss_att 260.815765 loss_ctc 12.495821 loss_rnnt 3.973256 lr 0.00025003 rank 2
2022-12-08 08:39:12,513 DEBUG TRAIN Batch 28/8100 loss 10.433297 loss_att 411.692169 loss_ctc 20.640442 loss_rnnt 9.299170 lr 0.00025004 rank 1
2022-12-08 08:39:12,515 DEBUG TRAIN Batch 28/8100 loss 7.827235 loss_att 326.936890 loss_ctc 16.344707 loss_rnnt 6.880849 lr 0.00025002 rank 5
2022-12-08 08:39:12,528 DEBUG TRAIN Batch 28/8100 loss 13.526144 loss_att 414.755127 loss_ctc 25.859297 loss_rnnt 12.155794 lr 0.00025003 rank 6
2022-12-08 08:40:16,953 DEBUG TRAIN Batch 28/8200 loss 8.377111 loss_att 354.374969 loss_ctc 18.560421 loss_rnnt 7.245633 lr 0.00025000 rank 6
2022-12-08 08:40:16,953 DEBUG TRAIN Batch 28/8200 loss 2.789067 loss_att 344.015869 loss_ctc 5.877954 loss_rnnt 2.445858 lr 0.00024998 rank 3
2022-12-08 08:40:16,954 DEBUG TRAIN Batch 28/8200 loss 4.711283 loss_att 159.525787 loss_ctc 9.326160 loss_rnnt 4.198519 lr 0.00024997 rank 4
2022-12-08 08:40:16,955 DEBUG TRAIN Batch 28/8200 loss 7.308941 loss_att 81.254135 loss_ctc 14.332148 loss_rnnt 6.528585 lr 0.00025000 rank 2
2022-12-08 08:40:16,956 DEBUG TRAIN Batch 28/8200 loss 3.784322 loss_att 376.008789 loss_ctc 11.222935 loss_rnnt 2.957810 lr 0.00024997 rank 0
2022-12-08 08:40:16,957 DEBUG TRAIN Batch 28/8200 loss 14.330912 loss_att 279.165863 loss_ctc 21.693323 loss_rnnt 13.512866 lr 0.00025001 rank 1
2022-12-08 08:40:16,957 DEBUG TRAIN Batch 28/8200 loss 4.627570 loss_att 347.881256 loss_ctc 10.753480 loss_rnnt 3.946913 lr 0.00024999 rank 5
2022-12-08 08:40:16,960 DEBUG TRAIN Batch 28/8200 loss 6.874291 loss_att 158.510361 loss_ctc 12.111186 loss_rnnt 6.292414 lr 0.00024997 rank 7
2022-12-08 08:41:19,923 DEBUG TRAIN Batch 28/8300 loss 6.393661 loss_att 396.865570 loss_ctc 12.387046 loss_rnnt 5.727729 lr 0.00024994 rank 4
2022-12-08 08:41:19,923 DEBUG TRAIN Batch 28/8300 loss 10.220840 loss_att 400.796021 loss_ctc 20.996937 loss_rnnt 9.023498 lr 0.00024994 rank 7
2022-12-08 08:41:19,926 DEBUG TRAIN Batch 28/8300 loss 10.967970 loss_att 242.437653 loss_ctc 19.762905 loss_rnnt 9.990755 lr 0.00024995 rank 3
2022-12-08 08:41:19,927 DEBUG TRAIN Batch 28/8300 loss 9.550220 loss_att 188.147705 loss_ctc 17.671921 loss_rnnt 8.647809 lr 0.00024998 rank 1
2022-12-08 08:41:19,930 DEBUG TRAIN Batch 28/8300 loss 6.451427 loss_att 367.840332 loss_ctc 8.488813 loss_rnnt 6.225051 lr 0.00024997 rank 6
2022-12-08 08:41:19,930 DEBUG TRAIN Batch 28/8300 loss 6.739351 loss_att 379.275085 loss_ctc 23.360466 loss_rnnt 4.892560 lr 0.00024994 rank 0
2022-12-08 08:41:19,930 DEBUG TRAIN Batch 28/8300 loss 8.736444 loss_att 357.452881 loss_ctc 18.591604 loss_rnnt 7.641426 lr 0.00024997 rank 2
2022-12-08 08:41:19,936 DEBUG TRAIN Batch 28/8300 loss 5.798059 loss_att 318.355347 loss_ctc 9.697625 loss_rnnt 5.364775 lr 0.00024996 rank 5
2022-12-08 08:42:04,959 DEBUG CV Batch 28/0 loss 1.549043 loss_att 48.086811 loss_ctc 3.225301 loss_rnnt 1.362793 history loss 1.491671 rank 2
2022-12-08 08:42:04,964 DEBUG CV Batch 28/0 loss 1.549043 loss_att 48.086811 loss_ctc 3.225301 loss_rnnt 1.362793 history loss 1.491671 rank 1
2022-12-08 08:42:04,964 DEBUG CV Batch 28/0 loss 1.549043 loss_att 48.086811 loss_ctc 3.225301 loss_rnnt 1.362793 history loss 1.491671 rank 7
2022-12-08 08:42:04,964 DEBUG CV Batch 28/0 loss 1.549043 loss_att 48.086811 loss_ctc 3.225301 loss_rnnt 1.362793 history loss 1.491671 rank 6
2022-12-08 08:42:04,970 DEBUG CV Batch 28/0 loss 1.549043 loss_att 48.086811 loss_ctc 3.225301 loss_rnnt 1.362793 history loss 1.491671 rank 4
2022-12-08 08:42:04,980 DEBUG CV Batch 28/0 loss 1.549043 loss_att 48.086811 loss_ctc 3.225301 loss_rnnt 1.362793 history loss 1.491671 rank 0
2022-12-08 08:42:04,991 DEBUG CV Batch 28/0 loss 1.549043 loss_att 48.086811 loss_ctc 3.225301 loss_rnnt 1.362793 history loss 1.491671 rank 3
2022-12-08 08:42:04,993 DEBUG CV Batch 28/0 loss 1.549043 loss_att 48.086811 loss_ctc 3.225301 loss_rnnt 1.362793 history loss 1.491671 rank 5
2022-12-08 08:42:15,641 DEBUG CV Batch 28/100 loss 3.791755 loss_att 266.946991 loss_ctc 10.719824 loss_rnnt 3.021970 history loss 2.891825 rank 2
2022-12-08 08:42:15,650 DEBUG CV Batch 28/100 loss 3.791755 loss_att 266.946991 loss_ctc 10.719824 loss_rnnt 3.021970 history loss 2.891825 rank 3
2022-12-08 08:42:15,670 DEBUG CV Batch 28/100 loss 3.791755 loss_att 266.946991 loss_ctc 10.719824 loss_rnnt 3.021970 history loss 2.891825 rank 4
2022-12-08 08:42:15,739 DEBUG CV Batch 28/100 loss 3.791755 loss_att 266.946991 loss_ctc 10.719824 loss_rnnt 3.021970 history loss 2.891825 rank 1
2022-12-08 08:42:15,787 DEBUG CV Batch 28/100 loss 3.791755 loss_att 266.946991 loss_ctc 10.719824 loss_rnnt 3.021970 history loss 2.891825 rank 6
2022-12-08 08:42:15,800 DEBUG CV Batch 28/100 loss 3.791755 loss_att 266.946991 loss_ctc 10.719824 loss_rnnt 3.021970 history loss 2.891825 rank 0
2022-12-08 08:42:15,861 DEBUG CV Batch 28/100 loss 3.791755 loss_att 266.946991 loss_ctc 10.719824 loss_rnnt 3.021970 history loss 2.891825 rank 5
2022-12-08 08:42:16,329 DEBUG CV Batch 28/100 loss 3.791755 loss_att 266.946991 loss_ctc 10.719824 loss_rnnt 3.021970 history loss 2.891825 rank 7
2022-12-08 08:42:28,830 DEBUG CV Batch 28/200 loss 4.938206 loss_att 641.184021 loss_ctc 6.448437 loss_rnnt 4.770402 history loss 3.448289 rank 4
2022-12-08 08:42:28,984 DEBUG CV Batch 28/200 loss 4.938206 loss_att 641.184021 loss_ctc 6.448437 loss_rnnt 4.770402 history loss 3.448289 rank 0
2022-12-08 08:42:29,056 DEBUG CV Batch 28/200 loss 4.938206 loss_att 641.184021 loss_ctc 6.448437 loss_rnnt 4.770402 history loss 3.448289 rank 3
2022-12-08 08:42:29,200 DEBUG CV Batch 28/200 loss 4.938206 loss_att 641.184021 loss_ctc 6.448437 loss_rnnt 4.770402 history loss 3.448289 rank 6
2022-12-08 08:42:29,420 DEBUG CV Batch 28/200 loss 4.938206 loss_att 641.184021 loss_ctc 6.448437 loss_rnnt 4.770402 history loss 3.448289 rank 1
2022-12-08 08:42:29,560 DEBUG CV Batch 28/200 loss 4.938206 loss_att 641.184021 loss_ctc 6.448437 loss_rnnt 4.770402 history loss 3.448289 rank 2
2022-12-08 08:42:29,677 DEBUG CV Batch 28/200 loss 4.938206 loss_att 641.184021 loss_ctc 6.448437 loss_rnnt 4.770402 history loss 3.448289 rank 5
2022-12-08 08:42:30,389 DEBUG CV Batch 28/200 loss 4.938206 loss_att 641.184021 loss_ctc 6.448437 loss_rnnt 4.770402 history loss 3.448289 rank 7
2022-12-08 08:42:40,395 DEBUG CV Batch 28/300 loss 3.564427 loss_att 190.888092 loss_ctc 6.947394 loss_rnnt 3.188542 history loss 3.613818 rank 3
2022-12-08 08:42:40,402 DEBUG CV Batch 28/300 loss 3.564427 loss_att 190.888092 loss_ctc 6.947394 loss_rnnt 3.188542 history loss 3.613818 rank 6
2022-12-08 08:42:40,406 DEBUG CV Batch 28/300 loss 3.564427 loss_att 190.888092 loss_ctc 6.947394 loss_rnnt 3.188542 history loss 3.613818 rank 4
2022-12-08 08:42:40,664 DEBUG CV Batch 28/300 loss 3.564427 loss_att 190.888092 loss_ctc 6.947394 loss_rnnt 3.188542 history loss 3.613818 rank 1
2022-12-08 08:42:40,783 DEBUG CV Batch 28/300 loss 3.564427 loss_att 190.888092 loss_ctc 6.947394 loss_rnnt 3.188542 history loss 3.613818 rank 0
2022-12-08 08:42:41,040 DEBUG CV Batch 28/300 loss 3.564427 loss_att 190.888092 loss_ctc 6.947394 loss_rnnt 3.188542 history loss 3.613818 rank 2
2022-12-08 08:42:41,345 DEBUG CV Batch 28/300 loss 3.564427 loss_att 190.888092 loss_ctc 6.947394 loss_rnnt 3.188542 history loss 3.613818 rank 5
2022-12-08 08:42:41,991 DEBUG CV Batch 28/300 loss 3.564427 loss_att 190.888092 loss_ctc 6.947394 loss_rnnt 3.188542 history loss 3.613818 rank 7
2022-12-08 08:42:51,631 DEBUG CV Batch 28/400 loss 4.896646 loss_att 826.182251 loss_ctc 13.110899 loss_rnnt 3.983951 history loss 4.464325 rank 6
2022-12-08 08:42:51,762 DEBUG CV Batch 28/400 loss 4.896646 loss_att 826.182251 loss_ctc 13.110899 loss_rnnt 3.983951 history loss 4.464325 rank 4
2022-12-08 08:42:51,936 DEBUG CV Batch 28/400 loss 4.896646 loss_att 826.182251 loss_ctc 13.110899 loss_rnnt 3.983951 history loss 4.464325 rank 1
2022-12-08 08:42:51,999 DEBUG CV Batch 28/400 loss 4.896646 loss_att 826.182251 loss_ctc 13.110899 loss_rnnt 3.983951 history loss 4.464325 rank 3
2022-12-08 08:42:52,464 DEBUG CV Batch 28/400 loss 4.896646 loss_att 826.182251 loss_ctc 13.110899 loss_rnnt 3.983951 history loss 4.464325 rank 0
2022-12-08 08:42:52,552 DEBUG CV Batch 28/400 loss 4.896646 loss_att 826.182251 loss_ctc 13.110899 loss_rnnt 3.983951 history loss 4.464325 rank 2
2022-12-08 08:42:52,679 DEBUG CV Batch 28/400 loss 4.896646 loss_att 826.182251 loss_ctc 13.110899 loss_rnnt 3.983951 history loss 4.464325 rank 5
2022-12-08 08:42:53,494 DEBUG CV Batch 28/400 loss 4.896646 loss_att 826.182251 loss_ctc 13.110899 loss_rnnt 3.983951 history loss 4.464325 rank 7
2022-12-08 08:43:01,418 DEBUG CV Batch 28/500 loss 5.250555 loss_att 266.655273 loss_ctc 8.591303 loss_rnnt 4.879360 history loss 5.073872 rank 6
2022-12-08 08:43:01,675 DEBUG CV Batch 28/500 loss 5.250555 loss_att 266.655273 loss_ctc 8.591303 loss_rnnt 4.879360 history loss 5.073872 rank 4
2022-12-08 08:43:01,778 DEBUG CV Batch 28/500 loss 5.250555 loss_att 266.655273 loss_ctc 8.591303 loss_rnnt 4.879360 history loss 5.073872 rank 3
2022-12-08 08:43:02,552 DEBUG CV Batch 28/500 loss 5.250555 loss_att 266.655273 loss_ctc 8.591303 loss_rnnt 4.879360 history loss 5.073872 rank 0
2022-12-08 08:43:02,571 DEBUG CV Batch 28/500 loss 5.250555 loss_att 266.655273 loss_ctc 8.591303 loss_rnnt 4.879360 history loss 5.073872 rank 1
2022-12-08 08:43:02,654 DEBUG CV Batch 28/500 loss 5.250555 loss_att 266.655273 loss_ctc 8.591303 loss_rnnt 4.879360 history loss 5.073872 rank 2
2022-12-08 08:43:02,817 DEBUG CV Batch 28/500 loss 5.250555 loss_att 266.655273 loss_ctc 8.591303 loss_rnnt 4.879360 history loss 5.073872 rank 5
2022-12-08 08:43:04,304 DEBUG CV Batch 28/500 loss 5.250555 loss_att 266.655273 loss_ctc 8.591303 loss_rnnt 4.879360 history loss 5.073872 rank 7
2022-12-08 08:43:13,130 DEBUG CV Batch 28/600 loss 5.317163 loss_att 104.308243 loss_ctc 9.186446 loss_rnnt 4.887243 history loss 5.921117 rank 4
2022-12-08 08:43:13,678 DEBUG CV Batch 28/600 loss 5.317163 loss_att 104.308243 loss_ctc 9.186446 loss_rnnt 4.887243 history loss 5.921117 rank 6
2022-12-08 08:43:13,793 DEBUG CV Batch 28/600 loss 5.317163 loss_att 104.308243 loss_ctc 9.186446 loss_rnnt 4.887243 history loss 5.921117 rank 3
2022-12-08 08:43:14,222 DEBUG CV Batch 28/600 loss 5.317163 loss_att 104.308243 loss_ctc 9.186446 loss_rnnt 4.887243 history loss 5.921117 rank 0
2022-12-08 08:43:14,285 DEBUG CV Batch 28/600 loss 5.317163 loss_att 104.308243 loss_ctc 9.186446 loss_rnnt 4.887243 history loss 5.921117 rank 2
2022-12-08 08:43:15,117 DEBUG CV Batch 28/600 loss 5.317163 loss_att 104.308243 loss_ctc 9.186446 loss_rnnt 4.887243 history loss 5.921117 rank 1
2022-12-08 08:43:15,597 DEBUG CV Batch 28/600 loss 5.317163 loss_att 104.308243 loss_ctc 9.186446 loss_rnnt 4.887243 history loss 5.921117 rank 5
2022-12-08 08:43:17,181 DEBUG CV Batch 28/600 loss 5.317163 loss_att 104.308243 loss_ctc 9.186446 loss_rnnt 4.887243 history loss 5.921117 rank 7
2022-12-08 08:43:24,651 DEBUG CV Batch 28/700 loss 9.678112 loss_att 707.039917 loss_ctc 21.997450 loss_rnnt 8.309297 history loss 6.464582 rank 4
2022-12-08 08:43:24,751 DEBUG CV Batch 28/700 loss 9.678112 loss_att 707.039917 loss_ctc 21.997450 loss_rnnt 8.309297 history loss 6.464582 rank 3
2022-12-08 08:43:25,249 DEBUG CV Batch 28/700 loss 9.678112 loss_att 707.039917 loss_ctc 21.997450 loss_rnnt 8.309297 history loss 6.464582 rank 0
2022-12-08 08:43:25,250 DEBUG CV Batch 28/700 loss 9.678112 loss_att 707.039917 loss_ctc 21.997450 loss_rnnt 8.309297 history loss 6.464582 rank 6
2022-12-08 08:43:25,844 DEBUG CV Batch 28/700 loss 9.678112 loss_att 707.039917 loss_ctc 21.997450 loss_rnnt 8.309297 history loss 6.464582 rank 2
2022-12-08 08:43:27,448 DEBUG CV Batch 28/700 loss 9.678112 loss_att 707.039917 loss_ctc 21.997450 loss_rnnt 8.309297 history loss 6.464582 rank 1
2022-12-08 08:43:27,876 DEBUG CV Batch 28/700 loss 9.678112 loss_att 707.039917 loss_ctc 21.997450 loss_rnnt 8.309297 history loss 6.464582 rank 5
2022-12-08 08:43:29,812 DEBUG CV Batch 28/700 loss 9.678112 loss_att 707.039917 loss_ctc 21.997450 loss_rnnt 8.309297 history loss 6.464582 rank 7
2022-12-08 08:43:36,054 DEBUG CV Batch 28/800 loss 6.846731 loss_att 263.405701 loss_ctc 17.414774 loss_rnnt 5.672504 history loss 5.992955 rank 4
2022-12-08 08:43:36,560 DEBUG CV Batch 28/800 loss 6.846731 loss_att 263.405701 loss_ctc 17.414774 loss_rnnt 5.672504 history loss 5.992955 rank 3
2022-12-08 08:43:36,935 DEBUG CV Batch 28/800 loss 6.846731 loss_att 263.405701 loss_ctc 17.414774 loss_rnnt 5.672504 history loss 5.992955 rank 0
2022-12-08 08:43:37,019 DEBUG CV Batch 28/800 loss 6.846731 loss_att 263.405701 loss_ctc 17.414774 loss_rnnt 5.672504 history loss 5.992955 rank 6
2022-12-08 08:43:37,749 DEBUG CV Batch 28/800 loss 6.846731 loss_att 263.405701 loss_ctc 17.414774 loss_rnnt 5.672504 history loss 5.992955 rank 2
2022-12-08 08:43:39,741 DEBUG CV Batch 28/800 loss 6.846731 loss_att 263.405701 loss_ctc 17.414774 loss_rnnt 5.672504 history loss 5.992955 rank 1
2022-12-08 08:43:40,431 DEBUG CV Batch 28/800 loss 6.846731 loss_att 263.405701 loss_ctc 17.414774 loss_rnnt 5.672504 history loss 5.992955 rank 5
2022-12-08 08:43:42,799 DEBUG CV Batch 28/800 loss 6.846731 loss_att 263.405701 loss_ctc 17.414774 loss_rnnt 5.672504 history loss 5.992955 rank 7
2022-12-08 08:43:49,609 DEBUG CV Batch 28/900 loss 10.123048 loss_att 550.849792 loss_ctc 18.187096 loss_rnnt 9.227043 history loss 5.822338 rank 4
2022-12-08 08:43:49,787 DEBUG CV Batch 28/900 loss 10.123048 loss_att 550.849792 loss_ctc 18.187096 loss_rnnt 9.227043 history loss 5.822338 rank 3
2022-12-08 08:43:50,298 DEBUG CV Batch 28/900 loss 10.123048 loss_att 550.849792 loss_ctc 18.187096 loss_rnnt 9.227043 history loss 5.822338 rank 6
2022-12-08 08:43:50,350 DEBUG CV Batch 28/900 loss 10.123048 loss_att 550.849792 loss_ctc 18.187096 loss_rnnt 9.227043 history loss 5.822338 rank 0
2022-12-08 08:43:51,154 DEBUG CV Batch 28/900 loss 10.123048 loss_att 550.849792 loss_ctc 18.187096 loss_rnnt 9.227043 history loss 5.822338 rank 2
2022-12-08 08:43:53,347 DEBUG CV Batch 28/900 loss 10.123048 loss_att 550.849792 loss_ctc 18.187096 loss_rnnt 9.227043 history loss 5.822338 rank 1
2022-12-08 08:43:54,173 DEBUG CV Batch 28/900 loss 10.123048 loss_att 550.849792 loss_ctc 18.187096 loss_rnnt 9.227043 history loss 5.822338 rank 5
2022-12-08 08:43:56,932 DEBUG CV Batch 28/900 loss 10.123048 loss_att 550.849792 loss_ctc 18.187096 loss_rnnt 9.227043 history loss 5.822338 rank 7
2022-12-08 08:44:01,239 DEBUG CV Batch 28/1000 loss 2.126259 loss_att 176.488434 loss_ctc 4.583112 loss_rnnt 1.853276 history loss 5.630154 rank 4
2022-12-08 08:44:01,508 DEBUG CV Batch 28/1000 loss 2.126259 loss_att 176.488434 loss_ctc 4.583112 loss_rnnt 1.853276 history loss 5.630154 rank 3
2022-12-08 08:44:01,728 DEBUG CV Batch 28/1000 loss 2.126259 loss_att 176.488434 loss_ctc 4.583112 loss_rnnt 1.853276 history loss 5.630154 rank 6
2022-12-08 08:44:02,317 DEBUG CV Batch 28/1000 loss 2.126259 loss_att 176.488434 loss_ctc 4.583112 loss_rnnt 1.853276 history loss 5.630154 rank 0
2022-12-08 08:44:02,971 DEBUG CV Batch 28/1000 loss 2.126259 loss_att 176.488434 loss_ctc 4.583112 loss_rnnt 1.853276 history loss 5.630154 rank 2
2022-12-08 08:44:04,977 DEBUG CV Batch 28/1000 loss 2.126259 loss_att 176.488434 loss_ctc 4.583112 loss_rnnt 1.853276 history loss 5.630154 rank 1
2022-12-08 08:44:05,646 DEBUG CV Batch 28/1000 loss 2.126259 loss_att 176.488434 loss_ctc 4.583112 loss_rnnt 1.853276 history loss 5.630154 rank 5
2022-12-08 08:44:08,899 DEBUG CV Batch 28/1000 loss 2.126259 loss_att 176.488434 loss_ctc 4.583112 loss_rnnt 1.853276 history loss 5.630154 rank 7
2022-12-08 08:44:12,553 DEBUG CV Batch 28/1100 loss 4.692454 loss_att 60.694275 loss_ctc 7.990440 loss_rnnt 4.326012 history loss 5.608333 rank 4
2022-12-08 08:44:12,774 DEBUG CV Batch 28/1100 loss 4.692454 loss_att 60.694275 loss_ctc 7.990440 loss_rnnt 4.326012 history loss 5.608333 rank 3
2022-12-08 08:44:12,995 DEBUG CV Batch 28/1100 loss 4.692454 loss_att 60.694275 loss_ctc 7.990440 loss_rnnt 4.326012 history loss 5.608333 rank 6
2022-12-08 08:44:13,942 DEBUG CV Batch 28/1100 loss 4.692454 loss_att 60.694275 loss_ctc 7.990440 loss_rnnt 4.326012 history loss 5.608333 rank 0
2022-12-08 08:44:14,401 DEBUG CV Batch 28/1100 loss 4.692454 loss_att 60.694275 loss_ctc 7.990440 loss_rnnt 4.326012 history loss 5.608333 rank 2
2022-12-08 08:44:17,110 DEBUG CV Batch 28/1100 loss 4.692454 loss_att 60.694275 loss_ctc 7.990440 loss_rnnt 4.326012 history loss 5.608333 rank 5
2022-12-08 08:44:17,170 DEBUG CV Batch 28/1100 loss 4.692454 loss_att 60.694275 loss_ctc 7.990440 loss_rnnt 4.326012 history loss 5.608333 rank 1
2022-12-08 08:44:20,435 DEBUG CV Batch 28/1100 loss 4.692454 loss_att 60.694275 loss_ctc 7.990440 loss_rnnt 4.326012 history loss 5.608333 rank 7
2022-12-08 08:44:22,446 DEBUG CV Batch 28/1200 loss 7.609657 loss_att 280.459808 loss_ctc 9.507220 loss_rnnt 7.398817 history loss 5.884335 rank 4
2022-12-08 08:44:22,743 DEBUG CV Batch 28/1200 loss 7.609657 loss_att 280.459808 loss_ctc 9.507220 loss_rnnt 7.398817 history loss 5.884335 rank 3
2022-12-08 08:44:23,188 DEBUG CV Batch 28/1200 loss 7.609657 loss_att 280.459808 loss_ctc 9.507220 loss_rnnt 7.398817 history loss 5.884335 rank 6
2022-12-08 08:44:24,083 DEBUG CV Batch 28/1200 loss 7.609657 loss_att 280.459808 loss_ctc 9.507220 loss_rnnt 7.398817 history loss 5.884335 rank 0
2022-12-08 08:44:24,683 DEBUG CV Batch 28/1200 loss 7.609657 loss_att 280.459808 loss_ctc 9.507220 loss_rnnt 7.398817 history loss 5.884335 rank 2
2022-12-08 08:44:28,055 DEBUG CV Batch 28/1200 loss 7.609657 loss_att 280.459808 loss_ctc 9.507220 loss_rnnt 7.398817 history loss 5.884335 rank 1
2022-12-08 08:44:28,058 DEBUG CV Batch 28/1200 loss 7.609657 loss_att 280.459808 loss_ctc 9.507220 loss_rnnt 7.398817 history loss 5.884335 rank 5
2022-12-08 08:44:31,419 DEBUG CV Batch 28/1200 loss 7.609657 loss_att 280.459808 loss_ctc 9.507220 loss_rnnt 7.398817 history loss 5.884335 rank 7
2022-12-08 08:44:33,818 DEBUG CV Batch 28/1300 loss 4.245406 loss_att 105.976738 loss_ctc 8.115245 loss_rnnt 3.815424 history loss 6.170252 rank 4
2022-12-08 08:44:34,384 DEBUG CV Batch 28/1300 loss 4.245406 loss_att 105.976738 loss_ctc 8.115245 loss_rnnt 3.815424 history loss 6.170252 rank 3
2022-12-08 08:44:34,589 DEBUG CV Batch 28/1300 loss 4.245406 loss_att 105.976738 loss_ctc 8.115245 loss_rnnt 3.815424 history loss 6.170252 rank 6
2022-12-08 08:44:35,731 DEBUG CV Batch 28/1300 loss 4.245406 loss_att 105.976738 loss_ctc 8.115245 loss_rnnt 3.815424 history loss 6.170252 rank 0
2022-12-08 08:44:36,485 DEBUG CV Batch 28/1300 loss 4.245406 loss_att 105.976738 loss_ctc 8.115245 loss_rnnt 3.815424 history loss 6.170252 rank 2
2022-12-08 08:44:40,006 DEBUG CV Batch 28/1300 loss 4.245406 loss_att 105.976738 loss_ctc 8.115245 loss_rnnt 3.815424 history loss 6.170252 rank 5
2022-12-08 08:44:40,150 DEBUG CV Batch 28/1300 loss 4.245406 loss_att 105.976738 loss_ctc 8.115245 loss_rnnt 3.815424 history loss 6.170252 rank 1
2022-12-08 08:44:43,455 DEBUG CV Batch 28/1300 loss 4.245406 loss_att 105.976738 loss_ctc 8.115245 loss_rnnt 3.815424 history loss 6.170252 rank 7
2022-12-08 08:44:45,236 DEBUG CV Batch 28/1400 loss 3.027301 loss_att 562.095642 loss_ctc 4.789385 loss_rnnt 2.831513 history loss 6.440198 rank 4
2022-12-08 08:44:45,591 DEBUG CV Batch 28/1400 loss 3.027301 loss_att 562.095642 loss_ctc 4.789385 loss_rnnt 2.831513 history loss 6.440198 rank 3
2022-12-08 08:44:45,878 DEBUG CV Batch 28/1400 loss 3.027301 loss_att 562.095642 loss_ctc 4.789385 loss_rnnt 2.831513 history loss 6.440198 rank 6
2022-12-08 08:44:46,612 DEBUG CV Batch 28/1400 loss 3.027301 loss_att 562.095642 loss_ctc 4.789385 loss_rnnt 2.831513 history loss 6.440198 rank 0
2022-12-08 08:44:48,190 DEBUG CV Batch 28/1400 loss 3.027301 loss_att 562.095642 loss_ctc 4.789385 loss_rnnt 2.831513 history loss 6.440198 rank 2
2022-12-08 08:44:52,506 DEBUG CV Batch 28/1400 loss 3.027301 loss_att 562.095642 loss_ctc 4.789385 loss_rnnt 2.831513 history loss 6.440198 rank 1
2022-12-08 08:44:52,648 DEBUG CV Batch 28/1400 loss 3.027301 loss_att 562.095642 loss_ctc 4.789385 loss_rnnt 2.831513 history loss 6.440198 rank 5
2022-12-08 08:44:56,245 DEBUG CV Batch 28/1400 loss 3.027301 loss_att 562.095642 loss_ctc 4.789385 loss_rnnt 2.831513 history loss 6.440198 rank 7
2022-12-08 08:44:57,115 DEBUG CV Batch 28/1500 loss 6.381181 loss_att 275.485840 loss_ctc 8.245788 loss_rnnt 6.174003 history loss 6.312617 rank 4
2022-12-08 08:44:57,468 DEBUG CV Batch 28/1500 loss 6.381181 loss_att 275.485840 loss_ctc 8.245788 loss_rnnt 6.174003 history loss 6.312617 rank 3
2022-12-08 08:44:57,746 DEBUG CV Batch 28/1500 loss 6.381181 loss_att 275.485840 loss_ctc 8.245788 loss_rnnt 6.174003 history loss 6.312617 rank 0
2022-12-08 08:44:58,239 DEBUG CV Batch 28/1500 loss 6.381181 loss_att 275.485840 loss_ctc 8.245788 loss_rnnt 6.174003 history loss 6.312617 rank 6
2022-12-08 08:45:00,279 DEBUG CV Batch 28/1500 loss 6.381181 loss_att 275.485840 loss_ctc 8.245788 loss_rnnt 6.174003 history loss 6.312617 rank 2
2022-12-08 08:45:05,044 DEBUG CV Batch 28/1500 loss 6.381181 loss_att 275.485840 loss_ctc 8.245788 loss_rnnt 6.174003 history loss 6.312617 rank 1
2022-12-08 08:45:05,421 DEBUG CV Batch 28/1500 loss 6.381181 loss_att 275.485840 loss_ctc 8.245788 loss_rnnt 6.174003 history loss 6.312617 rank 5
2022-12-08 08:45:09,090 DEBUG CV Batch 28/1500 loss 6.381181 loss_att 275.485840 loss_ctc 8.245788 loss_rnnt 6.174003 history loss 6.312617 rank 7
2022-12-08 08:45:10,341 DEBUG CV Batch 28/1600 loss 4.746859 loss_att 593.917114 loss_ctc 11.496490 loss_rnnt 3.996900 history loss 6.270374 rank 4
2022-12-08 08:45:10,819 DEBUG CV Batch 28/1600 loss 4.746859 loss_att 593.917114 loss_ctc 11.496490 loss_rnnt 3.996900 history loss 6.270374 rank 3
2022-12-08 08:45:11,070 DEBUG CV Batch 28/1600 loss 4.746859 loss_att 593.917114 loss_ctc 11.496490 loss_rnnt 3.996900 history loss 6.270374 rank 0
2022-12-08 08:45:11,347 DEBUG CV Batch 28/1600 loss 4.746859 loss_att 593.917114 loss_ctc 11.496490 loss_rnnt 3.996900 history loss 6.270374 rank 6
2022-12-08 08:45:13,668 DEBUG CV Batch 28/1600 loss 4.746859 loss_att 593.917114 loss_ctc 11.496490 loss_rnnt 3.996900 history loss 6.270374 rank 2
2022-12-08 08:45:18,456 DEBUG CV Batch 28/1600 loss 4.746859 loss_att 593.917114 loss_ctc 11.496490 loss_rnnt 3.996900 history loss 6.270374 rank 1
2022-12-08 08:45:18,710 DEBUG CV Batch 28/1600 loss 4.746859 loss_att 593.917114 loss_ctc 11.496490 loss_rnnt 3.996900 history loss 6.270374 rank 5
2022-12-08 08:45:22,277 DEBUG CV Batch 28/1700 loss 7.970789 loss_att 210.845367 loss_ctc 15.735215 loss_rnnt 7.108075 history loss 6.206678 rank 4
2022-12-08 08:45:22,708 DEBUG CV Batch 28/1600 loss 4.746859 loss_att 593.917114 loss_ctc 11.496490 loss_rnnt 3.996900 history loss 6.270374 rank 7
2022-12-08 08:45:22,810 DEBUG CV Batch 28/1700 loss 7.970789 loss_att 210.845367 loss_ctc 15.735215 loss_rnnt 7.108075 history loss 6.206678 rank 3
2022-12-08 08:45:23,142 DEBUG CV Batch 28/1700 loss 7.970789 loss_att 210.845367 loss_ctc 15.735215 loss_rnnt 7.108075 history loss 6.206678 rank 6
2022-12-08 08:45:23,284 DEBUG CV Batch 28/1700 loss 7.970789 loss_att 210.845367 loss_ctc 15.735215 loss_rnnt 7.108075 history loss 6.206678 rank 0
2022-12-08 08:45:25,795 DEBUG CV Batch 28/1700 loss 7.970789 loss_att 210.845367 loss_ctc 15.735215 loss_rnnt 7.108075 history loss 6.206678 rank 2
2022-12-08 08:45:30,172 DEBUG CV Batch 28/1700 loss 7.970789 loss_att 210.845367 loss_ctc 15.735215 loss_rnnt 7.108075 history loss 6.206678 rank 1
2022-12-08 08:45:30,956 DEBUG CV Batch 28/1700 loss 7.970789 loss_att 210.845367 loss_ctc 15.735215 loss_rnnt 7.108075 history loss 6.206678 rank 5
2022-12-08 08:45:30,971 INFO Epoch 28 CV info cv_loss 6.183552500923894
2022-12-08 08:45:30,972 INFO Epoch 29 TRAIN info lr 0.00024992628261833805
2022-12-08 08:45:30,973 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 08:45:31,958 INFO Epoch 28 CV info cv_loss 6.183552500923894
2022-12-08 08:45:31,959 INFO Epoch 29 TRAIN info lr 0.0002499393970434347
2022-12-08 08:45:31,963 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 08:45:32,176 INFO Epoch 28 CV info cv_loss 6.183552500923894
2022-12-08 08:45:32,176 INFO Epoch 29 TRAIN info lr 0.0002499656320882194
2022-12-08 08:45:32,179 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 08:45:32,228 INFO Epoch 28 CV info cv_loss 6.183552500923894
2022-12-08 08:45:32,228 INFO Checkpoint: save to checkpoint exp/1204_encoder_bias_nobi_noatt/28.pt
2022-12-08 08:45:32,746 INFO Epoch 29 TRAIN info lr 0.00024992066278235113
2022-12-08 08:45:32,749 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 08:45:34,328 DEBUG CV Batch 28/1700 loss 7.970789 loss_att 210.845367 loss_ctc 15.735215 loss_rnnt 7.108075 history loss 6.206678 rank 7
2022-12-08 08:45:34,919 INFO Epoch 28 CV info cv_loss 6.183552500923894
2022-12-08 08:45:34,919 INFO Epoch 29 TRAIN info lr 0.00024995220121184033
2022-12-08 08:45:34,921 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 08:45:39,100 INFO Epoch 28 CV info cv_loss 6.183552500923894
2022-12-08 08:45:39,100 INFO Epoch 29 TRAIN info lr 0.00024996719395854814
2022-12-08 08:45:39,105 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 08:45:39,874 INFO Epoch 28 CV info cv_loss 6.183552500923894
2022-12-08 08:45:39,875 INFO Epoch 29 TRAIN info lr 0.0002499487657539925
2022-12-08 08:45:39,879 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 08:45:43,548 INFO Epoch 28 CV info cv_loss 6.183552500923894
2022-12-08 08:45:43,548 INFO Epoch 29 TRAIN info lr 0.0002499256581733957
2022-12-08 08:45:43,550 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 08:46:42,677 DEBUG TRAIN Batch 29/0 loss 7.727658 loss_att 66.934570 loss_ctc 11.542970 loss_rnnt 7.303735 lr 0.00024994 rank 3
2022-12-08 08:46:42,680 DEBUG TRAIN Batch 29/0 loss 9.119392 loss_att 69.804199 loss_ctc 13.871974 loss_rnnt 8.591329 lr 0.00024997 rank 6
2022-12-08 08:46:42,691 DEBUG TRAIN Batch 29/0 loss 5.307041 loss_att 69.548172 loss_ctc 9.304181 loss_rnnt 4.862914 lr 0.00024993 rank 7
2022-12-08 08:46:42,696 DEBUG TRAIN Batch 29/0 loss 6.384158 loss_att 72.715027 loss_ctc 9.679237 loss_rnnt 6.018039 lr 0.00024995 rank 5
2022-12-08 08:46:42,702 DEBUG TRAIN Batch 29/0 loss 6.895947 loss_att 76.246689 loss_ctc 11.564594 loss_rnnt 6.377209 lr 0.00024992 rank 0
2022-12-08 08:46:42,703 DEBUG TRAIN Batch 29/0 loss 4.542466 loss_att 68.375244 loss_ctc 7.976072 loss_rnnt 4.160954 lr 0.00024997 rank 1
2022-12-08 08:46:42,706 DEBUG TRAIN Batch 29/0 loss 6.641996 loss_att 67.286980 loss_ctc 11.155621 loss_rnnt 6.140483 lr 0.00024993 rank 4
2022-12-08 08:46:42,709 DEBUG TRAIN Batch 29/0 loss 4.514007 loss_att 74.470131 loss_ctc 7.962424 loss_rnnt 4.130849 lr 0.00024995 rank 2
2022-12-08 08:47:45,033 DEBUG TRAIN Batch 29/100 loss 6.180303 loss_att 389.846771 loss_ctc 11.550346 loss_rnnt 5.583632 lr 0.00024989 rank 0
2022-12-08 08:47:45,033 DEBUG TRAIN Batch 29/100 loss 11.672916 loss_att 403.335876 loss_ctc 20.542778 loss_rnnt 10.687377 lr 0.00024993 rank 6
2022-12-08 08:47:45,034 DEBUG TRAIN Batch 29/100 loss 4.329844 loss_att 375.443848 loss_ctc 11.586088 loss_rnnt 3.523595 lr 0.00024994 rank 1
2022-12-08 08:47:45,035 DEBUG TRAIN Batch 29/100 loss 11.179588 loss_att 351.212402 loss_ctc 24.935421 loss_rnnt 9.651163 lr 0.00024989 rank 7
2022-12-08 08:47:45,037 DEBUG TRAIN Batch 29/100 loss 4.555068 loss_att 400.668915 loss_ctc 13.019977 loss_rnnt 3.614523 lr 0.00024989 rank 4
2022-12-08 08:47:45,037 DEBUG TRAIN Batch 29/100 loss 8.665599 loss_att 371.474701 loss_ctc 17.366526 loss_rnnt 7.698830 lr 0.00024992 rank 2
2022-12-08 08:47:45,037 DEBUG TRAIN Batch 29/100 loss 0.941838 loss_att 387.670959 loss_ctc 3.068789 loss_rnnt 0.705510 lr 0.00024991 rank 3
2022-12-08 08:47:45,044 DEBUG TRAIN Batch 29/100 loss 6.854818 loss_att 376.403992 loss_ctc 12.248678 loss_rnnt 6.255501 lr 0.00024992 rank 5
2022-12-08 08:48:48,197 DEBUG TRAIN Batch 29/200 loss 6.607630 loss_att 414.464844 loss_ctc 14.969744 loss_rnnt 5.678506 lr 0.00024989 rank 2
2022-12-08 08:48:48,211 DEBUG TRAIN Batch 29/200 loss 10.112862 loss_att 394.432709 loss_ctc 17.379705 loss_rnnt 9.305435 lr 0.00024986 rank 7
2022-12-08 08:48:48,214 DEBUG TRAIN Batch 29/200 loss 9.526564 loss_att 369.279785 loss_ctc 14.780623 loss_rnnt 8.942780 lr 0.00024988 rank 3
2022-12-08 08:48:48,216 DEBUG TRAIN Batch 29/200 loss 2.400683 loss_att 418.612061 loss_ctc 5.498994 loss_rnnt 2.056426 lr 0.00024990 rank 1
2022-12-08 08:48:48,217 DEBUG TRAIN Batch 29/200 loss 7.272204 loss_att 343.442139 loss_ctc 11.597900 loss_rnnt 6.791572 lr 0.00024990 rank 6
2022-12-08 08:48:48,218 DEBUG TRAIN Batch 29/200 loss 2.636392 loss_att 397.609009 loss_ctc 5.909968 loss_rnnt 2.272661 lr 0.00024986 rank 0
2022-12-08 08:48:48,220 DEBUG TRAIN Batch 29/200 loss 5.121069 loss_att 397.515564 loss_ctc 9.221517 loss_rnnt 4.665464 lr 0.00024986 rank 4
2022-12-08 08:48:48,221 DEBUG TRAIN Batch 29/200 loss 1.405393 loss_att 395.086761 loss_ctc 6.525400 loss_rnnt 0.836503 lr 0.00024989 rank 5
2022-12-08 08:49:51,493 DEBUG TRAIN Batch 29/300 loss 6.696441 loss_att 371.186035 loss_ctc 14.638307 loss_rnnt 5.814011 lr 0.00024985 rank 3
2022-12-08 08:49:51,503 DEBUG TRAIN Batch 29/300 loss 9.662535 loss_att 395.416382 loss_ctc 12.939407 loss_rnnt 9.298438 lr 0.00024987 rank 1
2022-12-08 08:49:51,504 DEBUG TRAIN Batch 29/300 loss 3.908719 loss_att 404.232056 loss_ctc 10.582247 loss_rnnt 3.167216 lr 0.00024983 rank 7
2022-12-08 08:49:51,505 DEBUG TRAIN Batch 29/300 loss 10.341666 loss_att 379.960724 loss_ctc 20.586353 loss_rnnt 9.203367 lr 0.00024983 rank 4
2022-12-08 08:49:51,507 DEBUG TRAIN Batch 29/300 loss 12.957272 loss_att 349.627411 loss_ctc 22.140141 loss_rnnt 11.936953 lr 0.00024987 rank 6
2022-12-08 08:49:51,512 DEBUG TRAIN Batch 29/300 loss 4.894132 loss_att 356.800995 loss_ctc 9.341278 loss_rnnt 4.400004 lr 0.00024983 rank 0
2022-12-08 08:49:51,530 DEBUG TRAIN Batch 29/300 loss 7.049218 loss_att 373.323303 loss_ctc 20.602455 loss_rnnt 5.543303 lr 0.00024986 rank 2
2022-12-08 08:49:51,547 DEBUG TRAIN Batch 29/300 loss 6.845149 loss_att 370.982025 loss_ctc 11.423594 loss_rnnt 6.336433 lr 0.00024985 rank 5
2022-12-08 08:51:00,434 DEBUG TRAIN Batch 29/400 loss 9.520554 loss_att 309.567535 loss_ctc 12.655353 loss_rnnt 9.172243 lr 0.00024980 rank 7
2022-12-08 08:51:00,441 DEBUG TRAIN Batch 29/400 loss 3.695462 loss_att 375.494629 loss_ctc 8.310575 loss_rnnt 3.182672 lr 0.00024980 rank 0
2022-12-08 08:51:00,443 DEBUG TRAIN Batch 29/400 loss 7.459140 loss_att 318.197327 loss_ctc 20.549175 loss_rnnt 6.004692 lr 0.00024984 rank 1
2022-12-08 08:51:00,445 DEBUG TRAIN Batch 29/400 loss 3.937057 loss_att 387.816742 loss_ctc 12.586184 loss_rnnt 2.976043 lr 0.00024981 rank 3
2022-12-08 08:51:00,447 DEBUG TRAIN Batch 29/400 loss 2.164879 loss_att 367.284302 loss_ctc 6.633334 loss_rnnt 1.668384 lr 0.00024980 rank 4
2022-12-08 08:51:00,446 DEBUG TRAIN Batch 29/400 loss 6.482428 loss_att 320.169006 loss_ctc 16.864235 loss_rnnt 5.328894 lr 0.00024983 rank 2
2022-12-08 08:51:00,450 DEBUG TRAIN Batch 29/400 loss 6.871451 loss_att 430.724731 loss_ctc 21.266262 loss_rnnt 5.272028 lr 0.00024982 rank 5
2022-12-08 08:51:00,488 DEBUG TRAIN Batch 29/400 loss 8.347702 loss_att 280.269592 loss_ctc 10.407941 loss_rnnt 8.118787 lr 0.00024984 rank 6
2022-12-08 08:52:03,623 DEBUG TRAIN Batch 29/500 loss 13.055043 loss_att 374.603821 loss_ctc 20.802677 loss_rnnt 12.194195 lr 0.00024977 rank 4
2022-12-08 08:52:03,627 DEBUG TRAIN Batch 29/500 loss 5.842141 loss_att 286.948212 loss_ctc 8.873534 loss_rnnt 5.505319 lr 0.00024977 rank 7
2022-12-08 08:52:03,630 DEBUG TRAIN Batch 29/500 loss 11.019948 loss_att 298.866180 loss_ctc 17.761663 loss_rnnt 10.270869 lr 0.00024981 rank 6
2022-12-08 08:52:03,634 DEBUG TRAIN Batch 29/500 loss 9.034492 loss_att 339.296082 loss_ctc 16.837490 loss_rnnt 8.167492 lr 0.00024981 rank 1
2022-12-08 08:52:03,634 DEBUG TRAIN Batch 29/500 loss 4.984353 loss_att 376.842133 loss_ctc 10.948790 loss_rnnt 4.321637 lr 0.00024976 rank 0
2022-12-08 08:52:03,634 DEBUG TRAIN Batch 29/500 loss 5.761276 loss_att 324.386292 loss_ctc 15.568382 loss_rnnt 4.671598 lr 0.00024979 rank 5
2022-12-08 08:52:03,636 DEBUG TRAIN Batch 29/500 loss 5.453440 loss_att 287.411865 loss_ctc 12.757191 loss_rnnt 4.641912 lr 0.00024980 rank 2
2022-12-08 08:52:03,693 DEBUG TRAIN Batch 29/500 loss 11.661292 loss_att 384.582581 loss_ctc 16.318796 loss_rnnt 11.143791 lr 0.00024978 rank 3
2022-12-08 08:53:07,615 DEBUG TRAIN Batch 29/600 loss 12.215689 loss_att 156.716782 loss_ctc 21.011755 loss_rnnt 11.238349 lr 0.00024978 rank 6
2022-12-08 08:53:07,618 DEBUG TRAIN Batch 29/600 loss 5.837394 loss_att 248.735352 loss_ctc 9.052835 loss_rnnt 5.480123 lr 0.00024974 rank 4
2022-12-08 08:53:07,618 DEBUG TRAIN Batch 29/600 loss 5.576809 loss_att 252.478394 loss_ctc 13.389471 loss_rnnt 4.708736 lr 0.00024976 rank 2
2022-12-08 08:53:07,620 DEBUG TRAIN Batch 29/600 loss 11.782507 loss_att 270.489136 loss_ctc 17.500692 loss_rnnt 11.147153 lr 0.00024975 rank 3
2022-12-08 08:53:07,621 DEBUG TRAIN Batch 29/600 loss 6.183348 loss_att 101.378441 loss_ctc 10.771333 loss_rnnt 5.673572 lr 0.00024974 rank 7
2022-12-08 08:53:07,621 DEBUG TRAIN Batch 29/600 loss 5.891513 loss_att 145.493683 loss_ctc 10.353513 loss_rnnt 5.395736 lr 0.00024976 rank 5
2022-12-08 08:53:07,623 DEBUG TRAIN Batch 29/600 loss 6.423055 loss_att 251.380768 loss_ctc 14.653166 loss_rnnt 5.508598 lr 0.00024973 rank 0
2022-12-08 08:53:07,626 DEBUG TRAIN Batch 29/600 loss 4.647238 loss_att 190.130005 loss_ctc 11.182282 loss_rnnt 3.921122 lr 0.00024978 rank 1
2022-12-08 08:54:12,598 DEBUG TRAIN Batch 29/700 loss 1.968245 loss_att 415.680054 loss_ctc 4.966805 loss_rnnt 1.635072 lr 0.00024972 rank 3
2022-12-08 08:54:12,604 DEBUG TRAIN Batch 29/700 loss 6.619258 loss_att 350.051361 loss_ctc 14.657711 loss_rnnt 5.726097 lr 0.00024971 rank 4
2022-12-08 08:54:12,605 DEBUG TRAIN Batch 29/700 loss 5.947278 loss_att 405.874115 loss_ctc 16.150011 loss_rnnt 4.813641 lr 0.00024971 rank 7
2022-12-08 08:54:12,607 DEBUG TRAIN Batch 29/700 loss 0.942061 loss_att 385.850769 loss_ctc 4.893240 loss_rnnt 0.503041 lr 0.00024975 rank 6
2022-12-08 08:54:12,607 DEBUG TRAIN Batch 29/700 loss 4.501525 loss_att 367.969666 loss_ctc 11.426434 loss_rnnt 3.732091 lr 0.00024975 rank 1
2022-12-08 08:54:12,609 DEBUG TRAIN Batch 29/700 loss 3.240154 loss_att 406.557678 loss_ctc 11.296827 loss_rnnt 2.344968 lr 0.00024970 rank 0
2022-12-08 08:54:12,613 DEBUG TRAIN Batch 29/700 loss 6.412852 loss_att 423.958069 loss_ctc 19.726587 loss_rnnt 4.933548 lr 0.00024973 rank 2
2022-12-08 08:54:12,614 DEBUG TRAIN Batch 29/700 loss 3.276178 loss_att 480.720428 loss_ctc 11.029258 loss_rnnt 2.414724 lr 0.00024973 rank 5
2022-12-08 08:55:21,525 DEBUG TRAIN Batch 29/800 loss 2.360686 loss_att 335.391357 loss_ctc 6.763362 loss_rnnt 1.871500 lr 0.00024968 rank 4
2022-12-08 08:55:21,527 DEBUG TRAIN Batch 29/800 loss 4.007552 loss_att 327.914948 loss_ctc 7.605415 loss_rnnt 3.607790 lr 0.00024970 rank 2
2022-12-08 08:55:21,527 DEBUG TRAIN Batch 29/800 loss 7.164082 loss_att 352.189667 loss_ctc 10.479988 loss_rnnt 6.795648 lr 0.00024969 rank 3
2022-12-08 08:55:21,528 DEBUG TRAIN Batch 29/800 loss 6.592175 loss_att 393.294647 loss_ctc 10.281428 loss_rnnt 6.182258 lr 0.00024972 rank 6
2022-12-08 08:55:21,529 DEBUG TRAIN Batch 29/800 loss 10.585397 loss_att 388.081055 loss_ctc 19.535667 loss_rnnt 9.590922 lr 0.00024970 rank 5
2022-12-08 08:55:21,530 DEBUG TRAIN Batch 29/800 loss 6.302996 loss_att 329.957581 loss_ctc 14.136065 loss_rnnt 5.432654 lr 0.00024972 rank 1
2022-12-08 08:55:21,531 DEBUG TRAIN Batch 29/800 loss 5.777114 loss_att 371.752045 loss_ctc 8.653639 loss_rnnt 5.457500 lr 0.00024968 rank 7
2022-12-08 08:55:21,534 DEBUG TRAIN Batch 29/800 loss 6.350115 loss_att 439.088470 loss_ctc 11.799545 loss_rnnt 5.744623 lr 0.00024967 rank 0
2022-12-08 08:56:24,956 DEBUG TRAIN Batch 29/900 loss 7.908842 loss_att 380.002563 loss_ctc 15.517103 loss_rnnt 7.063480 lr 0.00024966 rank 3
2022-12-08 08:56:24,969 DEBUG TRAIN Batch 29/900 loss 4.095646 loss_att 402.420532 loss_ctc 7.975140 loss_rnnt 3.664592 lr 0.00024965 rank 4
2022-12-08 08:56:24,970 DEBUG TRAIN Batch 29/900 loss 5.095806 loss_att 376.492371 loss_ctc 13.958251 loss_rnnt 4.111090 lr 0.00024967 rank 2
2022-12-08 08:56:24,971 DEBUG TRAIN Batch 29/900 loss 18.702271 loss_att 402.729187 loss_ctc 31.059055 loss_rnnt 17.329296 lr 0.00024964 rank 7
2022-12-08 08:56:24,971 DEBUG TRAIN Batch 29/900 loss 2.960358 loss_att 329.639648 loss_ctc 8.997139 loss_rnnt 2.289604 lr 0.00024967 rank 5
2022-12-08 08:56:24,972 DEBUG TRAIN Batch 29/900 loss 6.848238 loss_att 313.236816 loss_ctc 11.907244 loss_rnnt 6.286127 lr 0.00024968 rank 6
2022-12-08 08:56:24,974 DEBUG TRAIN Batch 29/900 loss 7.961228 loss_att 420.427673 loss_ctc 17.405396 loss_rnnt 6.911877 lr 0.00024964 rank 0
2022-12-08 08:56:24,977 DEBUG TRAIN Batch 29/900 loss 14.933831 loss_att 390.773102 loss_ctc 27.338697 loss_rnnt 13.555513 lr 0.00024969 rank 1
2022-12-08 08:57:28,526 DEBUG TRAIN Batch 29/1000 loss 8.342226 loss_att 380.640320 loss_ctc 12.516795 loss_rnnt 7.878386 lr 0.00024965 rank 6
2022-12-08 08:57:28,527 DEBUG TRAIN Batch 29/1000 loss 5.681756 loss_att 369.995483 loss_ctc 15.174083 loss_rnnt 4.627054 lr 0.00024961 rank 4
2022-12-08 08:57:28,527 DEBUG TRAIN Batch 29/1000 loss 4.839315 loss_att 351.845703 loss_ctc 12.309797 loss_rnnt 4.009262 lr 0.00024966 rank 1
2022-12-08 08:57:28,531 DEBUG TRAIN Batch 29/1000 loss 4.196988 loss_att 363.005859 loss_ctc 13.337280 loss_rnnt 3.181400 lr 0.00024961 rank 7
2022-12-08 08:57:28,532 DEBUG TRAIN Batch 29/1000 loss 6.344019 loss_att 369.194153 loss_ctc 18.265085 loss_rnnt 5.019456 lr 0.00024964 rank 5
2022-12-08 08:57:28,536 DEBUG TRAIN Batch 29/1000 loss 4.129847 loss_att 335.374298 loss_ctc 6.881595 loss_rnnt 3.824097 lr 0.00024961 rank 0
2022-12-08 08:57:28,536 DEBUG TRAIN Batch 29/1000 loss 8.840075 loss_att 391.923248 loss_ctc 11.454705 loss_rnnt 8.549562 lr 0.00024963 rank 3
2022-12-08 08:57:28,572 DEBUG TRAIN Batch 29/1000 loss 9.599697 loss_att 405.397552 loss_ctc 17.190998 loss_rnnt 8.756220 lr 0.00024964 rank 2
2022-12-08 08:58:37,406 DEBUG TRAIN Batch 29/1100 loss 5.627528 loss_att 390.735474 loss_ctc 12.433047 loss_rnnt 4.871359 lr 0.00024958 rank 7
2022-12-08 08:58:37,407 DEBUG TRAIN Batch 29/1100 loss 8.499188 loss_att 337.108978 loss_ctc 14.617289 loss_rnnt 7.819400 lr 0.00024958 rank 0
2022-12-08 08:58:37,407 DEBUG TRAIN Batch 29/1100 loss 8.306312 loss_att 339.885986 loss_ctc 21.852146 loss_rnnt 6.801219 lr 0.00024958 rank 4
2022-12-08 08:58:37,408 DEBUG TRAIN Batch 29/1100 loss 10.766356 loss_att 314.486511 loss_ctc 22.004322 loss_rnnt 9.517693 lr 0.00024960 rank 3
2022-12-08 08:58:37,415 DEBUG TRAIN Batch 29/1100 loss 6.336958 loss_att 312.699585 loss_ctc 16.162529 loss_rnnt 5.245228 lr 0.00024961 rank 5
2022-12-08 08:58:37,434 DEBUG TRAIN Batch 29/1100 loss 13.888697 loss_att 327.287354 loss_ctc 22.240540 loss_rnnt 12.960714 lr 0.00024962 rank 6
2022-12-08 08:58:37,440 DEBUG TRAIN Batch 29/1100 loss 4.586972 loss_att 347.039124 loss_ctc 13.280838 loss_rnnt 3.620987 lr 0.00024961 rank 2
2022-12-08 08:58:37,458 DEBUG TRAIN Batch 29/1100 loss 10.382999 loss_att 403.390625 loss_ctc 20.829309 loss_rnnt 9.222298 lr 0.00024962 rank 1
2022-12-08 08:59:40,762 DEBUG TRAIN Batch 29/1200 loss 5.205631 loss_att 259.304749 loss_ctc 9.651057 loss_rnnt 4.711695 lr 0.00024955 rank 7
2022-12-08 08:59:40,766 DEBUG TRAIN Batch 29/1200 loss 6.705498 loss_att 302.759277 loss_ctc 20.311062 loss_rnnt 5.193769 lr 0.00024955 rank 0
2022-12-08 08:59:40,766 DEBUG TRAIN Batch 29/1200 loss 13.304283 loss_att 314.513245 loss_ctc 18.024694 loss_rnnt 12.779794 lr 0.00024955 rank 4
2022-12-08 08:59:40,767 DEBUG TRAIN Batch 29/1200 loss 10.261685 loss_att 228.545212 loss_ctc 13.950118 loss_rnnt 9.851860 lr 0.00024959 rank 6
2022-12-08 08:59:40,767 DEBUG TRAIN Batch 29/1200 loss 9.924689 loss_att 274.069885 loss_ctc 16.255314 loss_rnnt 9.221287 lr 0.00024959 rank 1
2022-12-08 08:59:40,771 DEBUG TRAIN Batch 29/1200 loss 13.143377 loss_att 273.090363 loss_ctc 21.691442 loss_rnnt 12.193592 lr 0.00024957 rank 3
2022-12-08 08:59:40,772 DEBUG TRAIN Batch 29/1200 loss 14.686932 loss_att 287.068634 loss_ctc 24.953703 loss_rnnt 13.546180 lr 0.00024958 rank 2
2022-12-08 08:59:40,775 DEBUG TRAIN Batch 29/1200 loss 5.566008 loss_att 299.296234 loss_ctc 10.956868 loss_rnnt 4.967023 lr 0.00024957 rank 5
2022-12-08 09:00:44,015 DEBUG TRAIN Batch 29/1300 loss 18.626875 loss_att 402.463806 loss_ctc 35.396179 loss_rnnt 16.763618 lr 0.00024956 rank 1
2022-12-08 09:00:44,018 DEBUG TRAIN Batch 29/1300 loss 4.421808 loss_att 439.390076 loss_ctc 12.568565 loss_rnnt 3.516613 lr 0.00024952 rank 4
2022-12-08 09:00:44,020 DEBUG TRAIN Batch 29/1300 loss 1.960251 loss_att 347.075287 loss_ctc 3.753109 loss_rnnt 1.761045 lr 0.00024955 rank 2
2022-12-08 09:00:44,022 DEBUG TRAIN Batch 29/1300 loss 4.946662 loss_att 413.240662 loss_ctc 11.756948 loss_rnnt 4.189964 lr 0.00024952 rank 7
2022-12-08 09:00:44,024 DEBUG TRAIN Batch 29/1300 loss 10.317672 loss_att 235.188629 loss_ctc 18.694923 loss_rnnt 9.386867 lr 0.00024953 rank 3
2022-12-08 09:00:44,025 DEBUG TRAIN Batch 29/1300 loss 4.258408 loss_att 420.128967 loss_ctc 11.042200 loss_rnnt 3.504653 lr 0.00024956 rank 6
2022-12-08 09:00:44,026 DEBUG TRAIN Batch 29/1300 loss 6.046555 loss_att 213.684937 loss_ctc 12.863756 loss_rnnt 5.289088 lr 0.00024952 rank 0
2022-12-08 09:00:44,025 DEBUG TRAIN Batch 29/1300 loss 2.282559 loss_att 392.412201 loss_ctc 5.925001 loss_rnnt 1.877844 lr 0.00024954 rank 5
2022-12-08 09:01:48,593 DEBUG TRAIN Batch 29/1400 loss 7.280628 loss_att 413.340424 loss_ctc 14.592753 loss_rnnt 6.468170 lr 0.00024949 rank 4
2022-12-08 09:01:48,595 DEBUG TRAIN Batch 29/1400 loss 6.866860 loss_att 398.754700 loss_ctc 16.210888 loss_rnnt 5.828634 lr 0.00024952 rank 2
2022-12-08 09:01:48,596 DEBUG TRAIN Batch 29/1400 loss 3.103168 loss_att 327.467285 loss_ctc 10.127661 loss_rnnt 2.322669 lr 0.00024949 rank 7
2022-12-08 09:01:48,597 DEBUG TRAIN Batch 29/1400 loss 6.366710 loss_att 418.819092 loss_ctc 11.670927 loss_rnnt 5.777353 lr 0.00024953 rank 1
2022-12-08 09:01:48,599 DEBUG TRAIN Batch 29/1400 loss 11.523331 loss_att 385.842865 loss_ctc 22.578863 loss_rnnt 10.294939 lr 0.00024951 rank 5
2022-12-08 09:01:48,601 DEBUG TRAIN Batch 29/1400 loss 4.729122 loss_att 374.224854 loss_ctc 9.835529 loss_rnnt 4.161743 lr 0.00024948 rank 0
2022-12-08 09:01:48,615 DEBUG TRAIN Batch 29/1400 loss 7.372075 loss_att 466.498291 loss_ctc 12.040421 loss_rnnt 6.853370 lr 0.00024953 rank 6
2022-12-08 09:01:48,640 DEBUG TRAIN Batch 29/1400 loss 4.851376 loss_att 323.731750 loss_ctc 16.989143 loss_rnnt 3.502735 lr 0.00024950 rank 3
2022-12-08 09:02:57,140 DEBUG TRAIN Batch 29/1500 loss 7.161210 loss_att 354.042572 loss_ctc 13.552172 loss_rnnt 6.451103 lr 0.00024946 rank 4
2022-12-08 09:02:57,154 DEBUG TRAIN Batch 29/1500 loss 13.859867 loss_att 467.705994 loss_ctc 32.186226 loss_rnnt 11.823605 lr 0.00024945 rank 0
2022-12-08 09:02:57,155 DEBUG TRAIN Batch 29/1500 loss 3.434564 loss_att 347.385559 loss_ctc 6.657923 loss_rnnt 3.076413 lr 0.00024947 rank 3
2022-12-08 09:02:57,156 DEBUG TRAIN Batch 29/1500 loss 10.131822 loss_att 373.668884 loss_ctc 20.663025 loss_rnnt 8.961688 lr 0.00024946 rank 7
2022-12-08 09:02:57,158 DEBUG TRAIN Batch 29/1500 loss 3.166019 loss_att 366.276917 loss_ctc 7.799956 loss_rnnt 2.651137 lr 0.00024950 rank 1
2022-12-08 09:02:57,157 DEBUG TRAIN Batch 29/1500 loss 4.276766 loss_att 421.196167 loss_ctc 10.626254 loss_rnnt 3.571267 lr 0.00024948 rank 2
2022-12-08 09:02:57,159 DEBUG TRAIN Batch 29/1500 loss 7.779377 loss_att 386.990906 loss_ctc 14.040165 loss_rnnt 7.083735 lr 0.00024948 rank 5
2022-12-08 09:02:57,159 DEBUG TRAIN Batch 29/1500 loss 4.279468 loss_att 362.142090 loss_ctc 15.367384 loss_rnnt 3.047477 lr 0.00024950 rank 6
2022-12-08 09:03:59,351 DEBUG TRAIN Batch 29/1600 loss 11.232923 loss_att 432.110748 loss_ctc 26.334019 loss_rnnt 9.555023 lr 0.00024943 rank 4
2022-12-08 09:03:59,354 DEBUG TRAIN Batch 29/1600 loss 7.014321 loss_att 377.698059 loss_ctc 12.508970 loss_rnnt 6.403805 lr 0.00024945 rank 2
2022-12-08 09:03:59,355 DEBUG TRAIN Batch 29/1600 loss 8.251864 loss_att 381.209320 loss_ctc 21.942211 loss_rnnt 6.730715 lr 0.00024944 rank 3
2022-12-08 09:03:59,354 DEBUG TRAIN Batch 29/1600 loss 6.587320 loss_att 311.968750 loss_ctc 17.027933 loss_rnnt 5.427252 lr 0.00024945 rank 5
2022-12-08 09:03:59,354 DEBUG TRAIN Batch 29/1600 loss 14.302597 loss_att 385.728668 loss_ctc 28.567184 loss_rnnt 12.717644 lr 0.00024947 rank 1
2022-12-08 09:03:59,357 DEBUG TRAIN Batch 29/1600 loss 5.093221 loss_att 317.493469 loss_ctc 12.003117 loss_rnnt 4.325455 lr 0.00024947 rank 6
2022-12-08 09:03:59,359 DEBUG TRAIN Batch 29/1600 loss 8.928492 loss_att 398.664062 loss_ctc 17.109068 loss_rnnt 8.019539 lr 0.00024942 rank 0
2022-12-08 09:03:59,359 DEBUG TRAIN Batch 29/1600 loss 6.799416 loss_att 369.376434 loss_ctc 11.622053 loss_rnnt 6.263568 lr 0.00024943 rank 7
2022-12-08 09:05:02,654 DEBUG TRAIN Batch 29/1700 loss 8.634935 loss_att 399.439819 loss_ctc 25.003582 loss_rnnt 6.816196 lr 0.00024939 rank 0
2022-12-08 09:05:02,657 DEBUG TRAIN Batch 29/1700 loss 12.539246 loss_att 410.930206 loss_ctc 24.122972 loss_rnnt 11.252165 lr 0.00024942 rank 5
2022-12-08 09:05:02,663 DEBUG TRAIN Batch 29/1700 loss 5.539423 loss_att 345.564789 loss_ctc 6.565143 loss_rnnt 5.425454 lr 0.00024940 rank 7
2022-12-08 09:05:02,666 DEBUG TRAIN Batch 29/1700 loss 12.900737 loss_att 370.486816 loss_ctc 22.405325 loss_rnnt 11.844671 lr 0.00024944 rank 6
2022-12-08 09:05:02,667 DEBUG TRAIN Batch 29/1700 loss 17.500362 loss_att 455.555237 loss_ctc 33.167084 loss_rnnt 15.759616 lr 0.00024940 rank 4
2022-12-08 09:05:02,668 DEBUG TRAIN Batch 29/1700 loss 12.755560 loss_att 362.941559 loss_ctc 23.320650 loss_rnnt 11.581662 lr 0.00024941 rank 3
2022-12-08 09:05:02,714 DEBUG TRAIN Batch 29/1700 loss 6.800041 loss_att 367.321259 loss_ctc 14.060638 loss_rnnt 5.993308 lr 0.00024944 rank 1
2022-12-08 09:05:02,734 DEBUG TRAIN Batch 29/1700 loss 4.819191 loss_att 385.769562 loss_ctc 8.133842 loss_rnnt 4.450897 lr 0.00024942 rank 2
2022-12-08 09:06:13,346 DEBUG TRAIN Batch 29/1800 loss 7.660228 loss_att 315.384888 loss_ctc 15.460575 loss_rnnt 6.793522 lr 0.00024938 rank 3
2022-12-08 09:06:13,349 DEBUG TRAIN Batch 29/1800 loss 5.242994 loss_att 340.641571 loss_ctc 7.631331 loss_rnnt 4.977624 lr 0.00024936 rank 0
2022-12-08 09:06:13,353 DEBUG TRAIN Batch 29/1800 loss 9.302546 loss_att 343.640320 loss_ctc 21.106857 loss_rnnt 7.990956 lr 0.00024937 rank 4
2022-12-08 09:06:13,353 DEBUG TRAIN Batch 29/1800 loss 4.151879 loss_att 313.874786 loss_ctc 8.472410 loss_rnnt 3.671820 lr 0.00024937 rank 7
2022-12-08 09:06:13,358 DEBUG TRAIN Batch 29/1800 loss 12.119986 loss_att 308.991882 loss_ctc 21.682386 loss_rnnt 11.057497 lr 0.00024939 rank 2
2022-12-08 09:06:13,358 DEBUG TRAIN Batch 29/1800 loss 3.969503 loss_att 330.148010 loss_ctc 6.635024 loss_rnnt 3.673335 lr 0.00024941 rank 1
2022-12-08 09:06:13,361 DEBUG TRAIN Batch 29/1800 loss 6.899795 loss_att 267.604065 loss_ctc 16.449583 loss_rnnt 5.838707 lr 0.00024939 rank 5
2022-12-08 09:06:13,397 DEBUG TRAIN Batch 29/1800 loss 6.584441 loss_att 241.909622 loss_ctc 13.692985 loss_rnnt 5.794603 lr 0.00024940 rank 6
2022-12-08 09:07:17,066 DEBUG TRAIN Batch 29/1900 loss 4.790086 loss_att 216.840134 loss_ctc 8.961863 loss_rnnt 4.326556 lr 0.00024933 rank 4
2022-12-08 09:07:17,067 DEBUG TRAIN Batch 29/1900 loss 3.565511 loss_att 123.049217 loss_ctc 8.785612 loss_rnnt 2.985499 lr 0.00024933 rank 7
2022-12-08 09:07:17,070 DEBUG TRAIN Batch 29/1900 loss 9.666981 loss_att 151.451996 loss_ctc 15.365956 loss_rnnt 9.033762 lr 0.00024936 rank 2
2022-12-08 09:07:17,071 DEBUG TRAIN Batch 29/1900 loss 10.784487 loss_att 218.714539 loss_ctc 21.081112 loss_rnnt 9.640417 lr 0.00024933 rank 0
2022-12-08 09:07:17,071 DEBUG TRAIN Batch 29/1900 loss 6.012419 loss_att 214.075531 loss_ctc 11.165960 loss_rnnt 5.439803 lr 0.00024938 rank 1
2022-12-08 09:07:17,072 DEBUG TRAIN Batch 29/1900 loss 6.007480 loss_att 402.203064 loss_ctc 16.473883 loss_rnnt 4.844546 lr 0.00024937 rank 6
2022-12-08 09:07:17,072 DEBUG TRAIN Batch 29/1900 loss 10.626925 loss_att 450.044800 loss_ctc 21.615532 loss_rnnt 9.405969 lr 0.00024936 rank 5
2022-12-08 09:07:17,073 DEBUG TRAIN Batch 29/1900 loss 5.730794 loss_att 154.526535 loss_ctc 14.367526 loss_rnnt 4.771157 lr 0.00024935 rank 3
2022-12-08 09:08:20,343 DEBUG TRAIN Batch 29/2000 loss 5.559289 loss_att 330.696594 loss_ctc 19.229420 loss_rnnt 4.040385 lr 0.00024930 rank 4
2022-12-08 09:08:20,343 DEBUG TRAIN Batch 29/2000 loss 7.249340 loss_att 377.813568 loss_ctc 10.805846 loss_rnnt 6.854173 lr 0.00024930 rank 7
2022-12-08 09:08:20,345 DEBUG TRAIN Batch 29/2000 loss 1.745801 loss_att 376.186707 loss_ctc 7.665143 loss_rnnt 1.088097 lr 0.00024933 rank 2
2022-12-08 09:08:20,348 DEBUG TRAIN Batch 29/2000 loss 8.496117 loss_att 366.092773 loss_ctc 19.037678 loss_rnnt 7.324832 lr 0.00024932 rank 3
2022-12-08 09:08:20,351 DEBUG TRAIN Batch 29/2000 loss 2.748372 loss_att 392.139404 loss_ctc 8.848078 loss_rnnt 2.070627 lr 0.00024930 rank 0
2022-12-08 09:08:20,351 DEBUG TRAIN Batch 29/2000 loss 6.879064 loss_att 456.456726 loss_ctc 21.238167 loss_rnnt 5.283607 lr 0.00024934 rank 1
2022-12-08 09:08:20,353 DEBUG TRAIN Batch 29/2000 loss 4.574730 loss_att 385.354950 loss_ctc 10.759471 loss_rnnt 3.887537 lr 0.00024934 rank 6
2022-12-08 09:08:20,354 DEBUG TRAIN Batch 29/2000 loss 2.945091 loss_att 415.710754 loss_ctc 9.567221 loss_rnnt 2.209299 lr 0.00024933 rank 5
2022-12-08 09:09:25,334 DEBUG TRAIN Batch 29/2100 loss 4.176215 loss_att 305.427643 loss_ctc 9.749098 loss_rnnt 3.557006 lr 0.00024930 rank 2
2022-12-08 09:09:25,334 DEBUG TRAIN Batch 29/2100 loss 6.020008 loss_att 320.649384 loss_ctc 11.051819 loss_rnnt 5.460918 lr 0.00024931 rank 6
2022-12-08 09:09:25,335 DEBUG TRAIN Batch 29/2100 loss 18.873192 loss_att 427.446350 loss_ctc 32.582176 loss_rnnt 17.349972 lr 0.00024929 rank 3
2022-12-08 09:09:25,342 DEBUG TRAIN Batch 29/2100 loss 9.649953 loss_att 390.956726 loss_ctc 15.653223 loss_rnnt 8.982924 lr 0.00024927 rank 4
2022-12-08 09:09:25,344 DEBUG TRAIN Batch 29/2100 loss 4.688582 loss_att 333.648132 loss_ctc 12.341526 loss_rnnt 3.838255 lr 0.00024927 rank 7
2022-12-08 09:09:25,349 DEBUG TRAIN Batch 29/2100 loss 6.120660 loss_att 399.099670 loss_ctc 12.406572 loss_rnnt 5.422225 lr 0.00024927 rank 0
2022-12-08 09:09:25,349 DEBUG TRAIN Batch 29/2100 loss 4.519503 loss_att 401.421967 loss_ctc 8.935156 loss_rnnt 4.028874 lr 0.00024931 rank 1
2022-12-08 09:09:25,351 DEBUG TRAIN Batch 29/2100 loss 11.474157 loss_att 421.186615 loss_ctc 29.973633 loss_rnnt 9.418660 lr 0.00024930 rank 5
2022-12-08 09:10:33,985 DEBUG TRAIN Batch 29/2200 loss 2.768306 loss_att 354.870911 loss_ctc 8.168517 loss_rnnt 2.168283 lr 0.00024924 rank 4
2022-12-08 09:10:33,987 DEBUG TRAIN Batch 29/2200 loss 5.978329 loss_att 344.380859 loss_ctc 9.086618 loss_rnnt 5.632963 lr 0.00024928 rank 6
2022-12-08 09:10:33,988 DEBUG TRAIN Batch 29/2200 loss 2.917275 loss_att 392.635284 loss_ctc 9.842532 loss_rnnt 2.147802 lr 0.00024924 rank 7
2022-12-08 09:10:33,992 DEBUG TRAIN Batch 29/2200 loss 4.723374 loss_att 393.414551 loss_ctc 9.642200 loss_rnnt 4.176838 lr 0.00024927 rank 2
2022-12-08 09:10:33,993 DEBUG TRAIN Batch 29/2200 loss 9.604116 loss_att 389.409668 loss_ctc 21.749596 loss_rnnt 8.254620 lr 0.00024928 rank 1
2022-12-08 09:10:33,994 DEBUG TRAIN Batch 29/2200 loss 1.949922 loss_att 327.482727 loss_ctc 3.911177 loss_rnnt 1.732005 lr 0.00024925 rank 3
2022-12-08 09:10:33,995 DEBUG TRAIN Batch 29/2200 loss 11.178690 loss_att 451.181458 loss_ctc 20.328556 loss_rnnt 10.162038 lr 0.00024924 rank 0
2022-12-08 09:10:33,998 DEBUG TRAIN Batch 29/2200 loss 12.164168 loss_att 419.944611 loss_ctc 17.723160 loss_rnnt 11.546503 lr 0.00024926 rank 5
2022-12-08 09:11:36,285 DEBUG TRAIN Batch 29/2300 loss 13.069135 loss_att 375.401367 loss_ctc 19.711170 loss_rnnt 12.331131 lr 0.00024925 rank 6
2022-12-08 09:11:36,300 DEBUG TRAIN Batch 29/2300 loss 3.108508 loss_att 354.186218 loss_ctc 6.243576 loss_rnnt 2.760167 lr 0.00024921 rank 4
2022-12-08 09:11:36,302 DEBUG TRAIN Batch 29/2300 loss 9.053921 loss_att 350.483124 loss_ctc 17.005735 loss_rnnt 8.170385 lr 0.00024921 rank 7
2022-12-08 09:11:36,303 DEBUG TRAIN Batch 29/2300 loss 13.113204 loss_att 334.399841 loss_ctc 19.022863 loss_rnnt 12.456575 lr 0.00024923 rank 5
2022-12-08 09:11:36,303 DEBUG TRAIN Batch 29/2300 loss 6.149554 loss_att 384.813232 loss_ctc 13.983071 loss_rnnt 5.279163 lr 0.00024921 rank 0
2022-12-08 09:11:36,304 DEBUG TRAIN Batch 29/2300 loss 3.844495 loss_att 404.085449 loss_ctc 9.519249 loss_rnnt 3.213967 lr 0.00024922 rank 3
2022-12-08 09:11:36,310 DEBUG TRAIN Batch 29/2300 loss 11.892853 loss_att 369.205505 loss_ctc 22.751759 loss_rnnt 10.686308 lr 0.00024924 rank 2
2022-12-08 09:11:36,356 DEBUG TRAIN Batch 29/2300 loss 12.623584 loss_att 378.213501 loss_ctc 18.826391 loss_rnnt 11.934383 lr 0.00024925 rank 1
2022-12-08 09:12:39,882 DEBUG TRAIN Batch 29/2400 loss 7.513420 loss_att 332.421082 loss_ctc 22.497816 loss_rnnt 5.848487 lr 0.00024922 rank 6
2022-12-08 09:12:39,889 DEBUG TRAIN Batch 29/2400 loss 6.817806 loss_att 346.692047 loss_ctc 15.200498 loss_rnnt 5.886396 lr 0.00024918 rank 7
2022-12-08 09:12:39,891 DEBUG TRAIN Batch 29/2400 loss 5.613214 loss_att 342.974854 loss_ctc 8.104318 loss_rnnt 5.336425 lr 0.00024917 rank 0
2022-12-08 09:12:39,890 DEBUG TRAIN Batch 29/2400 loss 6.217494 loss_att 280.586273 loss_ctc 8.690326 loss_rnnt 5.942735 lr 0.00024921 rank 2
2022-12-08 09:12:39,893 DEBUG TRAIN Batch 29/2400 loss 9.681963 loss_att 404.769592 loss_ctc 17.402868 loss_rnnt 8.824084 lr 0.00024918 rank 4
2022-12-08 09:12:39,896 DEBUG TRAIN Batch 29/2400 loss 10.470553 loss_att 339.535156 loss_ctc 24.447155 loss_rnnt 8.917598 lr 0.00024920 rank 5
2022-12-08 09:12:39,904 DEBUG TRAIN Batch 29/2400 loss 6.155816 loss_att 357.426514 loss_ctc 8.953679 loss_rnnt 5.844943 lr 0.00024919 rank 3
2022-12-08 09:12:39,907 DEBUG TRAIN Batch 29/2400 loss 4.738790 loss_att 280.566895 loss_ctc 10.256059 loss_rnnt 4.125760 lr 0.00024922 rank 1
2022-12-08 09:13:52,680 DEBUG TRAIN Batch 29/2500 loss 5.174989 loss_att 101.074654 loss_ctc 8.512190 loss_rnnt 4.804189 lr 0.00024917 rank 5
2022-12-08 09:13:52,680 DEBUG TRAIN Batch 29/2500 loss 8.712252 loss_att 182.776764 loss_ctc 14.134624 loss_rnnt 8.109766 lr 0.00024919 rank 6
2022-12-08 09:13:52,681 DEBUG TRAIN Batch 29/2500 loss 8.594289 loss_att 238.557526 loss_ctc 14.040352 loss_rnnt 7.989171 lr 0.00024916 rank 3
2022-12-08 09:13:52,682 DEBUG TRAIN Batch 29/2500 loss 8.866470 loss_att 213.381073 loss_ctc 17.596939 loss_rnnt 7.896419 lr 0.00024917 rank 2
2022-12-08 09:13:52,682 DEBUG TRAIN Batch 29/2500 loss 6.510584 loss_att 181.559540 loss_ctc 11.883856 loss_rnnt 5.913554 lr 0.00024915 rank 7
2022-12-08 09:13:52,684 DEBUG TRAIN Batch 29/2500 loss 6.866150 loss_att 315.116547 loss_ctc 9.943071 loss_rnnt 6.524270 lr 0.00024915 rank 4
2022-12-08 09:13:52,686 DEBUG TRAIN Batch 29/2500 loss 7.864299 loss_att 273.167480 loss_ctc 11.992486 loss_rnnt 7.405612 lr 0.00024919 rank 1
2022-12-08 09:13:52,690 DEBUG TRAIN Batch 29/2500 loss 9.923412 loss_att 214.524445 loss_ctc 21.364279 loss_rnnt 8.652205 lr 0.00024914 rank 0
2022-12-08 09:14:55,645 DEBUG TRAIN Batch 29/2600 loss 5.742668 loss_att 450.260101 loss_ctc 19.629250 loss_rnnt 4.199715 lr 0.00024912 rank 4
2022-12-08 09:14:55,649 DEBUG TRAIN Batch 29/2600 loss 4.354003 loss_att 367.023071 loss_ctc 12.696949 loss_rnnt 3.427009 lr 0.00024914 rank 2
2022-12-08 09:14:55,650 DEBUG TRAIN Batch 29/2600 loss 3.420298 loss_att 382.420013 loss_ctc 6.894744 loss_rnnt 3.034249 lr 0.00024912 rank 7
2022-12-08 09:14:55,650 DEBUG TRAIN Batch 29/2600 loss 7.281115 loss_att 406.690369 loss_ctc 12.694901 loss_rnnt 6.679584 lr 0.00024914 rank 5
2022-12-08 09:14:55,652 DEBUG TRAIN Batch 29/2600 loss 2.419894 loss_att 382.747650 loss_ctc 7.639144 loss_rnnt 1.839978 lr 0.00024913 rank 3
2022-12-08 09:14:55,653 DEBUG TRAIN Batch 29/2600 loss 11.592966 loss_att 452.721039 loss_ctc 21.947445 loss_rnnt 10.442468 lr 0.00024911 rank 0
2022-12-08 09:14:55,654 DEBUG TRAIN Batch 29/2600 loss 3.067129 loss_att 407.930176 loss_ctc 8.265911 loss_rnnt 2.489486 lr 0.00024916 rank 6
2022-12-08 09:14:55,692 DEBUG TRAIN Batch 29/2600 loss 1.398158 loss_att 455.461609 loss_ctc 4.913149 loss_rnnt 1.007603 lr 0.00024916 rank 1
2022-12-08 09:15:59,011 DEBUG TRAIN Batch 29/2700 loss 2.698864 loss_att 372.658386 loss_ctc 6.832820 loss_rnnt 2.239536 lr 0.00024909 rank 4
2022-12-08 09:15:59,018 DEBUG TRAIN Batch 29/2700 loss 6.850805 loss_att 465.508301 loss_ctc 21.928749 loss_rnnt 5.175478 lr 0.00024909 rank 7
2022-12-08 09:15:59,021 DEBUG TRAIN Batch 29/2700 loss 6.031684 loss_att 366.508423 loss_ctc 10.278017 loss_rnnt 5.559869 lr 0.00024910 rank 3
2022-12-08 09:15:59,021 DEBUG TRAIN Batch 29/2700 loss 5.787753 loss_att 290.358032 loss_ctc 9.544957 loss_rnnt 5.370286 lr 0.00024911 rank 5
2022-12-08 09:15:59,022 DEBUG TRAIN Batch 29/2700 loss 10.608964 loss_att 383.049408 loss_ctc 14.596342 loss_rnnt 10.165922 lr 0.00024911 rank 2
2022-12-08 09:15:59,022 DEBUG TRAIN Batch 29/2700 loss 9.047913 loss_att 444.273926 loss_ctc 18.192352 loss_rnnt 8.031864 lr 0.00024908 rank 0
2022-12-08 09:15:59,022 DEBUG TRAIN Batch 29/2700 loss 9.341326 loss_att 438.136658 loss_ctc 17.567656 loss_rnnt 8.427289 lr 0.00024913 rank 1
2022-12-08 09:15:59,067 DEBUG TRAIN Batch 29/2700 loss 6.049056 loss_att 341.863220 loss_ctc 12.350727 loss_rnnt 5.348870 lr 0.00024913 rank 6
2022-12-08 09:17:03,676 DEBUG TRAIN Batch 29/2800 loss 8.653438 loss_att 404.633789 loss_ctc 18.105209 loss_rnnt 7.603241 lr 0.00024906 rank 4
2022-12-08 09:17:03,688 DEBUG TRAIN Batch 29/2800 loss 6.893857 loss_att 339.175720 loss_ctc 12.657779 loss_rnnt 6.253422 lr 0.00024910 rank 6
2022-12-08 09:17:03,693 DEBUG TRAIN Batch 29/2800 loss 4.407439 loss_att 422.683289 loss_ctc 8.315066 loss_rnnt 3.973258 lr 0.00024905 rank 0
2022-12-08 09:17:03,693 DEBUG TRAIN Batch 29/2800 loss 12.173136 loss_att 425.090668 loss_ctc 23.709295 loss_rnnt 10.891340 lr 0.00024908 rank 2
2022-12-08 09:17:03,695 DEBUG TRAIN Batch 29/2800 loss 6.358083 loss_att 357.978699 loss_ctc 15.322004 loss_rnnt 5.362092 lr 0.00024908 rank 5
2022-12-08 09:17:03,697 DEBUG TRAIN Batch 29/2800 loss 10.250582 loss_att 371.421143 loss_ctc 18.977356 loss_rnnt 9.280940 lr 0.00024906 rank 7
2022-12-08 09:17:03,713 DEBUG TRAIN Batch 29/2800 loss 2.445304 loss_att 365.436707 loss_ctc 5.793852 loss_rnnt 2.073243 lr 0.00024907 rank 3
2022-12-08 09:17:03,736 DEBUG TRAIN Batch 29/2800 loss 5.117449 loss_att 387.646576 loss_ctc 11.399370 loss_rnnt 4.419457 lr 0.00024910 rank 1
2022-12-08 09:18:12,995 DEBUG TRAIN Batch 29/2900 loss 8.134633 loss_att 365.885925 loss_ctc 13.966452 loss_rnnt 7.486653 lr 0.00024904 rank 3
2022-12-08 09:18:12,998 DEBUG TRAIN Batch 29/2900 loss 15.465528 loss_att 433.695038 loss_ctc 29.798983 loss_rnnt 13.872922 lr 0.00024902 rank 7
2022-12-08 09:18:12,999 DEBUG TRAIN Batch 29/2900 loss 4.664971 loss_att 370.385712 loss_ctc 12.288834 loss_rnnt 3.817875 lr 0.00024902 rank 0
2022-12-08 09:18:13,002 DEBUG TRAIN Batch 29/2900 loss 5.954252 loss_att 405.051514 loss_ctc 13.751564 loss_rnnt 5.087884 lr 0.00024906 rank 6
2022-12-08 09:18:13,002 DEBUG TRAIN Batch 29/2900 loss 9.180431 loss_att 331.829468 loss_ctc 17.607288 loss_rnnt 8.244114 lr 0.00024905 rank 2
2022-12-08 09:18:13,004 DEBUG TRAIN Batch 29/2900 loss 9.143680 loss_att 328.604492 loss_ctc 22.385204 loss_rnnt 7.672399 lr 0.00024907 rank 1
2022-12-08 09:18:13,006 DEBUG TRAIN Batch 29/2900 loss 13.174476 loss_att 367.358612 loss_ctc 23.731806 loss_rnnt 12.001439 lr 0.00024903 rank 4
2022-12-08 09:18:13,011 DEBUG TRAIN Batch 29/2900 loss 10.233078 loss_att 407.696594 loss_ctc 21.821800 loss_rnnt 8.945442 lr 0.00024905 rank 5
2022-12-08 09:19:16,201 DEBUG TRAIN Batch 29/3000 loss 4.128331 loss_att 338.391602 loss_ctc 9.057523 loss_rnnt 3.580643 lr 0.00024901 rank 3
2022-12-08 09:19:16,205 DEBUG TRAIN Batch 29/3000 loss 4.821420 loss_att 357.525116 loss_ctc 7.929651 loss_rnnt 4.476061 lr 0.00024903 rank 1
2022-12-08 09:19:16,206 DEBUG TRAIN Batch 29/3000 loss 5.961795 loss_att 367.241364 loss_ctc 10.081827 loss_rnnt 5.504013 lr 0.00024899 rank 4
2022-12-08 09:19:16,207 DEBUG TRAIN Batch 29/3000 loss 5.055351 loss_att 342.745239 loss_ctc 11.344993 loss_rnnt 4.356502 lr 0.00024899 rank 0
2022-12-08 09:19:16,207 DEBUG TRAIN Batch 29/3000 loss 3.572935 loss_att 305.410095 loss_ctc 9.908863 loss_rnnt 2.868942 lr 0.00024899 rank 7
2022-12-08 09:19:16,210 DEBUG TRAIN Batch 29/3000 loss 4.071190 loss_att 348.122070 loss_ctc 8.322129 loss_rnnt 3.598864 lr 0.00024902 rank 2
2022-12-08 09:19:16,213 DEBUG TRAIN Batch 29/3000 loss 6.039767 loss_att 295.994446 loss_ctc 10.146749 loss_rnnt 5.583436 lr 0.00024902 rank 5
2022-12-08 09:19:16,215 DEBUG TRAIN Batch 29/3000 loss 3.587722 loss_att 346.882629 loss_ctc 11.560615 loss_rnnt 2.701845 lr 0.00024903 rank 6
2022-12-08 09:20:19,319 DEBUG TRAIN Batch 29/3100 loss 5.562428 loss_att 100.540237 loss_ctc 10.388025 loss_rnnt 5.026251 lr 0.00024899 rank 5
2022-12-08 09:20:19,328 DEBUG TRAIN Batch 29/3100 loss 8.175853 loss_att 231.337708 loss_ctc 16.790215 loss_rnnt 7.218702 lr 0.00024900 rank 6
2022-12-08 09:20:19,328 DEBUG TRAIN Batch 29/3100 loss 7.109820 loss_att 301.504059 loss_ctc 11.887139 loss_rnnt 6.579007 lr 0.00024899 rank 2
2022-12-08 09:20:19,329 DEBUG TRAIN Batch 29/3100 loss 6.507489 loss_att 273.787140 loss_ctc 16.072620 loss_rnnt 5.444697 lr 0.00024900 rank 1
2022-12-08 09:20:19,330 DEBUG TRAIN Batch 29/3100 loss 11.301101 loss_att 293.414276 loss_ctc 30.295706 loss_rnnt 9.190589 lr 0.00024896 rank 7
2022-12-08 09:20:19,332 DEBUG TRAIN Batch 29/3100 loss 16.644606 loss_att 293.968414 loss_ctc 36.218025 loss_rnnt 14.469782 lr 0.00024898 rank 3
2022-12-08 09:20:19,336 DEBUG TRAIN Batch 29/3100 loss 4.706233 loss_att 283.817078 loss_ctc 13.726509 loss_rnnt 3.703979 lr 0.00024896 rank 0
2022-12-08 09:20:19,344 DEBUG TRAIN Batch 29/3100 loss 7.314635 loss_att 352.311096 loss_ctc 20.765854 loss_rnnt 5.820055 lr 0.00024896 rank 4
2022-12-08 09:21:31,358 DEBUG TRAIN Batch 29/3200 loss 7.093891 loss_att 168.998154 loss_ctc 14.296426 loss_rnnt 6.293610 lr 0.00024893 rank 4
2022-12-08 09:21:31,364 DEBUG TRAIN Batch 29/3200 loss 6.595060 loss_att 355.487732 loss_ctc 17.382456 loss_rnnt 5.396461 lr 0.00024893 rank 7
2022-12-08 09:21:31,365 DEBUG TRAIN Batch 29/3200 loss 3.859019 loss_att 434.907227 loss_ctc 14.980200 loss_rnnt 2.623333 lr 0.00024895 rank 3
2022-12-08 09:21:31,366 DEBUG TRAIN Batch 29/3200 loss 3.756683 loss_att 484.517426 loss_ctc 10.992554 loss_rnnt 2.952698 lr 0.00024893 rank 0
2022-12-08 09:21:31,370 DEBUG TRAIN Batch 29/3200 loss 5.058317 loss_att 230.022125 loss_ctc 15.717512 loss_rnnt 3.873962 lr 0.00024897 rank 1
2022-12-08 09:21:31,376 DEBUG TRAIN Batch 29/3200 loss 3.684389 loss_att 451.144226 loss_ctc 10.626632 loss_rnnt 2.913028 lr 0.00024897 rank 6
2022-12-08 09:21:31,383 DEBUG TRAIN Batch 29/3200 loss 8.400708 loss_att 135.038361 loss_ctc 15.905615 loss_rnnt 7.566830 lr 0.00024896 rank 2
2022-12-08 09:21:31,398 DEBUG TRAIN Batch 29/3200 loss 6.497878 loss_att 359.115814 loss_ctc 10.657093 loss_rnnt 6.035743 lr 0.00024896 rank 5
2022-12-08 09:22:35,258 DEBUG TRAIN Batch 29/3300 loss 7.817109 loss_att 445.602234 loss_ctc 18.587822 loss_rnnt 6.620363 lr 0.00024893 rank 2
2022-12-08 09:22:35,259 DEBUG TRAIN Batch 29/3300 loss 5.322453 loss_att 422.750732 loss_ctc 12.165300 loss_rnnt 4.562136 lr 0.00024890 rank 4
2022-12-08 09:22:35,261 DEBUG TRAIN Batch 29/3300 loss 16.084099 loss_att 368.741547 loss_ctc 19.139492 loss_rnnt 15.744612 lr 0.00024890 rank 7
2022-12-08 09:22:35,261 DEBUG TRAIN Batch 29/3300 loss 1.358638 loss_att 344.423157 loss_ctc 3.422302 loss_rnnt 1.129342 lr 0.00024892 rank 5
2022-12-08 09:22:35,263 DEBUG TRAIN Batch 29/3300 loss 4.190574 loss_att 401.938599 loss_ctc 12.411707 loss_rnnt 3.277114 lr 0.00024894 rank 1
2022-12-08 09:22:35,266 DEBUG TRAIN Batch 29/3300 loss 8.292622 loss_att 379.917328 loss_ctc 16.951590 loss_rnnt 7.330514 lr 0.00024890 rank 0
2022-12-08 09:22:35,266 DEBUG TRAIN Batch 29/3300 loss 5.986745 loss_att 374.461273 loss_ctc 12.955279 loss_rnnt 5.212463 lr 0.00024894 rank 6
2022-12-08 09:22:35,267 DEBUG TRAIN Batch 29/3300 loss 5.210680 loss_att 311.574402 loss_ctc 11.331798 loss_rnnt 4.530557 lr 0.00024891 rank 3
2022-12-08 09:23:38,510 DEBUG TRAIN Batch 29/3400 loss 4.395575 loss_att 333.499878 loss_ctc 9.814150 loss_rnnt 3.793511 lr 0.00024887 rank 4
2022-12-08 09:23:38,517 DEBUG TRAIN Batch 29/3400 loss 6.815447 loss_att 272.315857 loss_ctc 10.941802 loss_rnnt 6.356963 lr 0.00024887 rank 7
2022-12-08 09:23:38,518 DEBUG TRAIN Batch 29/3400 loss 2.761434 loss_att 368.047455 loss_ctc 5.202020 loss_rnnt 2.490258 lr 0.00024891 rank 1
2022-12-08 09:23:38,519 DEBUG TRAIN Batch 29/3400 loss 10.035327 loss_att 421.640900 loss_ctc 21.899229 loss_rnnt 8.717115 lr 0.00024888 rank 3
2022-12-08 09:23:38,522 DEBUG TRAIN Batch 29/3400 loss 1.019363 loss_att 405.178711 loss_ctc 3.210054 loss_rnnt 0.775953 lr 0.00024890 rank 2
2022-12-08 09:23:38,522 DEBUG TRAIN Batch 29/3400 loss 9.717232 loss_att 386.463318 loss_ctc 14.265362 loss_rnnt 9.211884 lr 0.00024889 rank 5
2022-12-08 09:23:38,522 DEBUG TRAIN Batch 29/3400 loss 5.680964 loss_att 376.371094 loss_ctc 10.027781 loss_rnnt 5.197985 lr 0.00024887 rank 0
2022-12-08 09:23:38,569 DEBUG TRAIN Batch 29/3400 loss 5.744885 loss_att 341.817627 loss_ctc 12.478849 loss_rnnt 4.996667 lr 0.00024891 rank 6
2022-12-08 09:24:42,157 DEBUG TRAIN Batch 29/3500 loss 6.309643 loss_att 363.630981 loss_ctc 12.608189 loss_rnnt 5.609805 lr 0.00024884 rank 7
2022-12-08 09:24:42,158 DEBUG TRAIN Batch 29/3500 loss 6.703451 loss_att 407.961212 loss_ctc 10.088890 loss_rnnt 6.327291 lr 0.00024884 rank 4
2022-12-08 09:24:42,163 DEBUG TRAIN Batch 29/3500 loss 10.175694 loss_att 333.615173 loss_ctc 18.219980 loss_rnnt 9.281884 lr 0.00024886 rank 5
2022-12-08 09:24:42,165 DEBUG TRAIN Batch 29/3500 loss 9.416395 loss_att 336.193176 loss_ctc 21.208118 loss_rnnt 8.106203 lr 0.00024885 rank 3
2022-12-08 09:24:42,165 DEBUG TRAIN Batch 29/3500 loss 2.007404 loss_att 335.356812 loss_ctc 9.965345 loss_rnnt 1.123188 lr 0.00024887 rank 2
2022-12-08 09:24:42,168 DEBUG TRAIN Batch 29/3500 loss 22.003639 loss_att 419.748413 loss_ctc 46.321095 loss_rnnt 19.301701 lr 0.00024883 rank 0
2022-12-08 09:24:42,197 DEBUG TRAIN Batch 29/3500 loss 7.478482 loss_att 360.314575 loss_ctc 17.045576 loss_rnnt 6.415472 lr 0.00024888 rank 1
2022-12-08 09:24:42,197 DEBUG TRAIN Batch 29/3500 loss 10.869215 loss_att 350.960388 loss_ctc 20.531639 loss_rnnt 9.795613 lr 0.00024888 rank 6
2022-12-08 09:25:52,330 DEBUG TRAIN Batch 29/3600 loss 3.359465 loss_att 330.836792 loss_ctc 8.858988 loss_rnnt 2.748407 lr 0.00024881 rank 7
2022-12-08 09:25:52,331 DEBUG TRAIN Batch 29/3600 loss 3.746200 loss_att 331.106384 loss_ctc 9.040638 loss_rnnt 3.157929 lr 0.00024881 rank 4
2022-12-08 09:25:52,336 DEBUG TRAIN Batch 29/3600 loss 7.895538 loss_att 400.217407 loss_ctc 13.460445 loss_rnnt 7.277215 lr 0.00024884 rank 2
2022-12-08 09:25:52,336 DEBUG TRAIN Batch 29/3600 loss 8.621859 loss_att 381.527222 loss_ctc 14.007574 loss_rnnt 8.023446 lr 0.00024880 rank 0
2022-12-08 09:25:52,339 DEBUG TRAIN Batch 29/3600 loss 8.260946 loss_att 298.734131 loss_ctc 17.673471 loss_rnnt 7.215110 lr 0.00024885 rank 6
2022-12-08 09:25:52,344 DEBUG TRAIN Batch 29/3600 loss 15.639522 loss_att 342.503723 loss_ctc 27.452408 loss_rnnt 14.326979 lr 0.00024883 rank 5
2022-12-08 09:25:52,344 DEBUG TRAIN Batch 29/3600 loss 6.911401 loss_att 353.748596 loss_ctc 17.000723 loss_rnnt 5.790365 lr 0.00024885 rank 1
2022-12-08 09:25:52,375 DEBUG TRAIN Batch 29/3600 loss 7.445594 loss_att 348.705688 loss_ctc 15.288597 loss_rnnt 6.574150 lr 0.00024882 rank 3
2022-12-08 09:26:55,175 DEBUG TRAIN Batch 29/3700 loss 14.031736 loss_att 350.840881 loss_ctc 31.969580 loss_rnnt 12.038644 lr 0.00024878 rank 4
2022-12-08 09:26:55,181 DEBUG TRAIN Batch 29/3700 loss 8.473130 loss_att 309.994446 loss_ctc 15.560588 loss_rnnt 7.685636 lr 0.00024882 rank 6
2022-12-08 09:26:55,184 DEBUG TRAIN Batch 29/3700 loss 6.293457 loss_att 327.859863 loss_ctc 14.681391 loss_rnnt 5.361465 lr 0.00024880 rank 2
2022-12-08 09:26:55,183 DEBUG TRAIN Batch 29/3700 loss 13.483709 loss_att 293.943420 loss_ctc 21.151190 loss_rnnt 12.631767 lr 0.00024879 rank 3
2022-12-08 09:26:55,184 DEBUG TRAIN Batch 29/3700 loss 3.882075 loss_att 353.886108 loss_ctc 9.223197 loss_rnnt 3.288617 lr 0.00024882 rank 1
2022-12-08 09:26:55,184 DEBUG TRAIN Batch 29/3700 loss 8.257193 loss_att 326.003479 loss_ctc 11.728065 loss_rnnt 7.871540 lr 0.00024877 rank 0
2022-12-08 09:26:55,186 DEBUG TRAIN Batch 29/3700 loss 10.394919 loss_att 340.405762 loss_ctc 27.585999 loss_rnnt 8.484799 lr 0.00024878 rank 7
2022-12-08 09:26:55,186 DEBUG TRAIN Batch 29/3700 loss 7.955066 loss_att 189.437592 loss_ctc 18.367252 loss_rnnt 6.798156 lr 0.00024880 rank 5
2022-12-08 09:27:58,794 DEBUG TRAIN Batch 29/3800 loss 7.700840 loss_att 241.239014 loss_ctc 17.792904 loss_rnnt 6.579500 lr 0.00024875 rank 4
2022-12-08 09:27:58,796 DEBUG TRAIN Batch 29/3800 loss 6.395501 loss_att 102.312714 loss_ctc 11.405775 loss_rnnt 5.838804 lr 0.00024875 rank 7
2022-12-08 09:27:58,797 DEBUG TRAIN Batch 29/3800 loss 9.645202 loss_att 459.160522 loss_ctc 20.982864 loss_rnnt 8.385462 lr 0.00024879 rank 6
2022-12-08 09:27:58,798 DEBUG TRAIN Batch 29/3800 loss 4.728008 loss_att 401.295410 loss_ctc 7.911541 loss_rnnt 4.374282 lr 0.00024876 rank 3
2022-12-08 09:27:58,802 DEBUG TRAIN Batch 29/3800 loss 10.685549 loss_att 271.156952 loss_ctc 20.008446 loss_rnnt 9.649672 lr 0.00024879 rank 1
2022-12-08 09:27:58,801 DEBUG TRAIN Batch 29/3800 loss 6.682519 loss_att 251.051132 loss_ctc 11.613647 loss_rnnt 6.134616 lr 0.00024877 rank 2
2022-12-08 09:27:58,803 DEBUG TRAIN Batch 29/3800 loss 7.930891 loss_att 385.842773 loss_ctc 22.948792 loss_rnnt 6.262236 lr 0.00024877 rank 5
2022-12-08 09:27:58,806 DEBUG TRAIN Batch 29/3800 loss 7.496551 loss_att 153.310730 loss_ctc 11.487289 loss_rnnt 7.053136 lr 0.00024874 rank 0
2022-12-08 09:29:04,109 DEBUG TRAIN Batch 29/3900 loss 6.165619 loss_att 405.220062 loss_ctc 12.859648 loss_rnnt 5.421838 lr 0.00024871 rank 0
2022-12-08 09:29:04,117 DEBUG TRAIN Batch 29/3900 loss 6.294870 loss_att 354.597778 loss_ctc 18.843184 loss_rnnt 4.900613 lr 0.00024872 rank 4
2022-12-08 09:29:04,118 DEBUG TRAIN Batch 29/3900 loss 4.876307 loss_att 427.735291 loss_ctc 18.059750 loss_rnnt 3.411480 lr 0.00024876 rank 6
2022-12-08 09:29:04,118 DEBUG TRAIN Batch 29/3900 loss 1.893140 loss_att 378.888763 loss_ctc 11.736059 loss_rnnt 0.799482 lr 0.00024872 rank 7
2022-12-08 09:29:04,121 DEBUG TRAIN Batch 29/3900 loss 6.292419 loss_att 411.785645 loss_ctc 14.623831 loss_rnnt 5.366706 lr 0.00024874 rank 5
2022-12-08 09:29:04,123 DEBUG TRAIN Batch 29/3900 loss 4.589119 loss_att 368.400818 loss_ctc 13.628459 loss_rnnt 3.584748 lr 0.00024873 rank 3
2022-12-08 09:29:04,124 DEBUG TRAIN Batch 29/3900 loss 6.051136 loss_att 355.783203 loss_ctc 15.110129 loss_rnnt 5.044580 lr 0.00024874 rank 2
2022-12-08 09:29:04,147 DEBUG TRAIN Batch 29/3900 loss 3.671942 loss_att 401.530945 loss_ctc 14.555740 loss_rnnt 2.462631 lr 0.00024876 rank 1
2022-12-08 09:30:12,278 DEBUG TRAIN Batch 29/4000 loss 7.038310 loss_att 433.237122 loss_ctc 18.235144 loss_rnnt 5.794218 lr 0.00024869 rank 4
2022-12-08 09:30:12,279 DEBUG TRAIN Batch 29/4000 loss 3.490732 loss_att 391.400146 loss_ctc 10.282915 loss_rnnt 2.736044 lr 0.00024869 rank 7
2022-12-08 09:30:12,280 DEBUG TRAIN Batch 29/4000 loss 3.792335 loss_att 354.639160 loss_ctc 8.913881 loss_rnnt 3.223274 lr 0.00024871 rank 5
2022-12-08 09:30:12,280 DEBUG TRAIN Batch 29/4000 loss 9.460577 loss_att 349.240906 loss_ctc 17.015875 loss_rnnt 8.621099 lr 0.00024873 rank 6
2022-12-08 09:30:12,283 DEBUG TRAIN Batch 29/4000 loss 6.902352 loss_att 360.628479 loss_ctc 22.690605 loss_rnnt 5.148102 lr 0.00024870 rank 3
2022-12-08 09:30:12,286 DEBUG TRAIN Batch 29/4000 loss 10.284895 loss_att 388.376831 loss_ctc 22.838165 loss_rnnt 8.890087 lr 0.00024868 rank 0
2022-12-08 09:30:12,287 DEBUG TRAIN Batch 29/4000 loss 5.246861 loss_att 416.362640 loss_ctc 13.441702 loss_rnnt 4.336324 lr 0.00024873 rank 1
2022-12-08 09:30:12,326 DEBUG TRAIN Batch 29/4000 loss 10.124525 loss_att 362.824066 loss_ctc 13.962283 loss_rnnt 9.698108 lr 0.00024871 rank 2
2022-12-08 09:31:15,795 DEBUG TRAIN Batch 29/4100 loss 22.888182 loss_att 447.192993 loss_ctc 51.633720 loss_rnnt 19.694233 lr 0.00024868 rank 2
2022-12-08 09:31:15,806 DEBUG TRAIN Batch 29/4100 loss 3.867578 loss_att 386.696564 loss_ctc 11.027148 loss_rnnt 3.072070 lr 0.00024867 rank 3
2022-12-08 09:31:15,807 DEBUG TRAIN Batch 29/4100 loss 6.790251 loss_att 381.811584 loss_ctc 12.619459 loss_rnnt 6.142561 lr 0.00024866 rank 4
2022-12-08 09:31:15,809 DEBUG TRAIN Batch 29/4100 loss 11.430600 loss_att 379.004974 loss_ctc 18.807194 loss_rnnt 10.610979 lr 0.00024865 rank 7
2022-12-08 09:31:15,810 DEBUG TRAIN Batch 29/4100 loss 3.526799 loss_att 342.390228 loss_ctc 8.441592 loss_rnnt 2.980711 lr 0.00024865 rank 0
2022-12-08 09:31:15,810 DEBUG TRAIN Batch 29/4100 loss 6.756827 loss_att 390.052979 loss_ctc 10.765320 loss_rnnt 6.311440 lr 0.00024870 rank 1
2022-12-08 09:31:15,811 DEBUG TRAIN Batch 29/4100 loss 12.861379 loss_att 353.997589 loss_ctc 18.500149 loss_rnnt 12.234849 lr 0.00024868 rank 5
2022-12-08 09:31:15,848 DEBUG TRAIN Batch 29/4100 loss 14.960457 loss_att 429.375183 loss_ctc 28.262291 loss_rnnt 13.482475 lr 0.00024869 rank 6
2022-12-08 09:32:19,565 DEBUG TRAIN Batch 29/4200 loss 5.654722 loss_att 361.074615 loss_ctc 11.720011 loss_rnnt 4.980802 lr 0.00024864 rank 3
2022-12-08 09:32:19,576 DEBUG TRAIN Batch 29/4200 loss 14.612642 loss_att 364.592224 loss_ctc 21.758650 loss_rnnt 13.818642 lr 0.00024865 rank 2
2022-12-08 09:32:19,577 DEBUG TRAIN Batch 29/4200 loss 4.084837 loss_att 335.090729 loss_ctc 10.072402 loss_rnnt 3.419552 lr 0.00024862 rank 4
2022-12-08 09:32:19,576 DEBUG TRAIN Batch 29/4200 loss 8.601790 loss_att 364.279724 loss_ctc 27.400446 loss_rnnt 6.513051 lr 0.00024867 rank 1
2022-12-08 09:32:19,577 DEBUG TRAIN Batch 29/4200 loss 8.257447 loss_att 393.117188 loss_ctc 15.034279 loss_rnnt 7.504467 lr 0.00024866 rank 6
2022-12-08 09:32:19,580 DEBUG TRAIN Batch 29/4200 loss 9.427140 loss_att 382.450653 loss_ctc 19.353817 loss_rnnt 8.324177 lr 0.00024862 rank 7
2022-12-08 09:32:19,581 DEBUG TRAIN Batch 29/4200 loss 6.855581 loss_att 365.290863 loss_ctc 18.746458 loss_rnnt 5.534373 lr 0.00024862 rank 0
2022-12-08 09:32:19,602 DEBUG TRAIN Batch 29/4200 loss 11.696978 loss_att 318.421631 loss_ctc 19.525539 loss_rnnt 10.827138 lr 0.00024865 rank 5
2022-12-08 09:33:30,289 DEBUG TRAIN Batch 29/4300 loss 10.503395 loss_att 306.583405 loss_ctc 20.571407 loss_rnnt 9.384727 lr 0.00024859 rank 4
2022-12-08 09:33:30,292 DEBUG TRAIN Batch 29/4300 loss 9.656866 loss_att 343.010803 loss_ctc 25.774082 loss_rnnt 7.866065 lr 0.00024862 rank 2
2022-12-08 09:33:30,295 DEBUG TRAIN Batch 29/4300 loss 13.808364 loss_att 349.280548 loss_ctc 23.740894 loss_rnnt 12.704750 lr 0.00024863 rank 6
2022-12-08 09:33:30,296 DEBUG TRAIN Batch 29/4300 loss 10.000243 loss_att 332.919983 loss_ctc 18.583984 loss_rnnt 9.046494 lr 0.00024863 rank 1
2022-12-08 09:33:30,297 DEBUG TRAIN Batch 29/4300 loss 3.600163 loss_att 409.158875 loss_ctc 11.861994 loss_rnnt 2.682181 lr 0.00024859 rank 7
2022-12-08 09:33:30,300 DEBUG TRAIN Batch 29/4300 loss 4.280154 loss_att 306.777832 loss_ctc 11.306690 loss_rnnt 3.499428 lr 0.00024859 rank 0
2022-12-08 09:33:30,308 DEBUG TRAIN Batch 29/4300 loss 3.475777 loss_att 265.576874 loss_ctc 12.235982 loss_rnnt 2.502421 lr 0.00024861 rank 3
2022-12-08 09:33:30,335 DEBUG TRAIN Batch 29/4300 loss 12.991134 loss_att 276.636963 loss_ctc 21.701498 loss_rnnt 12.023315 lr 0.00024862 rank 5
2022-12-08 09:34:33,850 DEBUG TRAIN Batch 29/4400 loss 7.556904 loss_att 207.303070 loss_ctc 13.622534 loss_rnnt 6.882945 lr 0.00024856 rank 7
2022-12-08 09:34:33,855 DEBUG TRAIN Batch 29/4400 loss 7.403879 loss_att 312.556793 loss_ctc 13.277817 loss_rnnt 6.751219 lr 0.00024856 rank 4
2022-12-08 09:34:33,856 DEBUG TRAIN Batch 29/4400 loss 9.130146 loss_att 483.071655 loss_ctc 19.091419 loss_rnnt 8.023338 lr 0.00024858 rank 3
2022-12-08 09:34:33,859 DEBUG TRAIN Batch 29/4400 loss 11.395343 loss_att 299.716766 loss_ctc 20.793619 loss_rnnt 10.351090 lr 0.00024856 rank 0
2022-12-08 09:34:33,861 DEBUG TRAIN Batch 29/4400 loss 11.511798 loss_att 447.206482 loss_ctc 19.179783 loss_rnnt 10.659800 lr 0.00024859 rank 5
2022-12-08 09:34:33,861 DEBUG TRAIN Batch 29/4400 loss 11.068079 loss_att 285.910156 loss_ctc 15.966522 loss_rnnt 10.523808 lr 0.00024860 rank 1
2022-12-08 09:34:33,862 DEBUG TRAIN Batch 29/4400 loss 10.726372 loss_att 100.519066 loss_ctc 14.438344 loss_rnnt 10.313931 lr 0.00024860 rank 6
2022-12-08 09:34:33,863 DEBUG TRAIN Batch 29/4400 loss 11.116483 loss_att 336.388580 loss_ctc 26.393110 loss_rnnt 9.419080 lr 0.00024859 rank 2
2022-12-08 09:35:37,605 DEBUG TRAIN Batch 29/4500 loss 2.410642 loss_att 337.243896 loss_ctc 5.152905 loss_rnnt 2.105946 lr 0.00024853 rank 7
2022-12-08 09:35:37,608 DEBUG TRAIN Batch 29/4500 loss 6.314613 loss_att 73.110291 loss_ctc 10.279606 loss_rnnt 5.874058 lr 0.00024853 rank 4
2022-12-08 09:35:37,611 DEBUG TRAIN Batch 29/4500 loss 11.023003 loss_att 85.625191 loss_ctc 16.079121 loss_rnnt 10.461212 lr 0.00024856 rank 2
2022-12-08 09:35:37,613 DEBUG TRAIN Batch 29/4500 loss 3.276754 loss_att 387.623138 loss_ctc 14.882116 loss_rnnt 1.987270 lr 0.00024857 rank 6
2022-12-08 09:35:37,613 DEBUG TRAIN Batch 29/4500 loss 4.814935 loss_att 354.557251 loss_ctc 10.891051 loss_rnnt 4.139811 lr 0.00024855 rank 3
2022-12-08 09:35:37,614 DEBUG TRAIN Batch 29/4500 loss 9.448619 loss_att 412.888123 loss_ctc 17.006144 loss_rnnt 8.608894 lr 0.00024853 rank 0
2022-12-08 09:35:37,615 DEBUG TRAIN Batch 29/4500 loss 4.357352 loss_att 60.043568 loss_ctc 6.687817 loss_rnnt 4.098412 lr 0.00024857 rank 1
2022-12-08 09:35:37,624 DEBUG TRAIN Batch 29/4500 loss 8.916787 loss_att 426.781311 loss_ctc 13.869255 loss_rnnt 8.366513 lr 0.00024855 rank 5
2022-12-08 09:36:42,668 DEBUG TRAIN Batch 29/4600 loss 4.421753 loss_att 399.869324 loss_ctc 19.803782 loss_rnnt 2.712639 lr 0.00024850 rank 4
2022-12-08 09:36:42,669 DEBUG TRAIN Batch 29/4600 loss 14.190474 loss_att 374.212982 loss_ctc 19.496773 loss_rnnt 13.600885 lr 0.00024850 rank 7
2022-12-08 09:36:42,670 DEBUG TRAIN Batch 29/4600 loss 5.300261 loss_att 359.521729 loss_ctc 11.299887 loss_rnnt 4.633636 lr 0.00024854 rank 1
2022-12-08 09:36:42,670 DEBUG TRAIN Batch 29/4600 loss 5.673748 loss_att 365.501648 loss_ctc 10.896042 loss_rnnt 5.093493 lr 0.00024854 rank 6
2022-12-08 09:36:42,671 DEBUG TRAIN Batch 29/4600 loss 6.639033 loss_att 357.376892 loss_ctc 11.789233 loss_rnnt 6.066789 lr 0.00024851 rank 3
2022-12-08 09:36:42,677 DEBUG TRAIN Batch 29/4600 loss 7.980927 loss_att 327.929352 loss_ctc 16.211601 loss_rnnt 7.066408 lr 0.00024850 rank 0
2022-12-08 09:36:42,684 DEBUG TRAIN Batch 29/4600 loss 0.388202 loss_att 354.937012 loss_ctc 1.713096 loss_rnnt 0.240991 lr 0.00024853 rank 2
2022-12-08 09:36:42,696 DEBUG TRAIN Batch 29/4600 loss 10.123353 loss_att 405.686615 loss_ctc 18.545876 loss_rnnt 9.187517 lr 0.00024852 rank 5
2022-12-08 09:37:51,401 DEBUG TRAIN Batch 29/4700 loss 1.667933 loss_att 380.572388 loss_ctc 5.229640 loss_rnnt 1.272188 lr 0.00024847 rank 0
2022-12-08 09:37:51,416 DEBUG TRAIN Batch 29/4700 loss 10.537378 loss_att 438.130981 loss_ctc 19.820568 loss_rnnt 9.505913 lr 0.00024847 rank 7
2022-12-08 09:37:51,418 DEBUG TRAIN Batch 29/4700 loss 17.185131 loss_att 412.534943 loss_ctc 37.234138 loss_rnnt 14.957463 lr 0.00024848 rank 3
2022-12-08 09:37:51,418 DEBUG TRAIN Batch 29/4700 loss 10.417314 loss_att 388.034973 loss_ctc 23.563416 loss_rnnt 8.956636 lr 0.00024847 rank 4
2022-12-08 09:37:51,419 DEBUG TRAIN Batch 29/4700 loss 4.360877 loss_att 354.408447 loss_ctc 10.879618 loss_rnnt 3.636572 lr 0.00024851 rank 1
2022-12-08 09:37:51,424 DEBUG TRAIN Batch 29/4700 loss 6.868255 loss_att 354.183746 loss_ctc 12.784090 loss_rnnt 6.210940 lr 0.00024849 rank 5
2022-12-08 09:37:51,425 DEBUG TRAIN Batch 29/4700 loss 6.126174 loss_att 373.802277 loss_ctc 17.580742 loss_rnnt 4.853444 lr 0.00024851 rank 6
2022-12-08 09:37:51,462 DEBUG TRAIN Batch 29/4700 loss 9.061676 loss_att 394.610840 loss_ctc 19.715561 loss_rnnt 7.877912 lr 0.00024850 rank 2
2022-12-08 09:38:54,999 DEBUG TRAIN Batch 29/4800 loss 6.011581 loss_att 422.291016 loss_ctc 15.143251 loss_rnnt 4.996952 lr 0.00024844 rank 0
2022-12-08 09:38:54,999 DEBUG TRAIN Batch 29/4800 loss 5.983916 loss_att 363.347717 loss_ctc 12.324543 loss_rnnt 5.279402 lr 0.00024847 rank 2
2022-12-08 09:38:55,001 DEBUG TRAIN Batch 29/4800 loss 3.574894 loss_att 290.170502 loss_ctc 13.703960 loss_rnnt 2.449443 lr 0.00024844 rank 4
2022-12-08 09:38:55,002 DEBUG TRAIN Batch 29/4800 loss 5.873885 loss_att 430.118500 loss_ctc 15.904938 loss_rnnt 4.759324 lr 0.00024844 rank 7
2022-12-08 09:38:55,003 DEBUG TRAIN Batch 29/4800 loss 14.394142 loss_att 409.611267 loss_ctc 33.090748 loss_rnnt 12.316742 lr 0.00024848 rank 6
2022-12-08 09:38:55,004 DEBUG TRAIN Batch 29/4800 loss 11.377675 loss_att 350.949310 loss_ctc 21.056601 loss_rnnt 10.302238 lr 0.00024848 rank 1
2022-12-08 09:38:55,006 DEBUG TRAIN Batch 29/4800 loss 9.297805 loss_att 318.079315 loss_ctc 20.728390 loss_rnnt 8.027740 lr 0.00024846 rank 5
2022-12-08 09:38:55,056 DEBUG TRAIN Batch 29/4800 loss 5.149202 loss_att 349.421753 loss_ctc 10.051581 loss_rnnt 4.604493 lr 0.00024845 rank 3
2022-12-08 09:39:58,425 DEBUG TRAIN Batch 29/4900 loss 9.048213 loss_att 330.636169 loss_ctc 17.883747 loss_rnnt 8.066487 lr 0.00024842 rank 3
2022-12-08 09:39:58,432 DEBUG TRAIN Batch 29/4900 loss 4.726328 loss_att 294.132751 loss_ctc 10.261196 loss_rnnt 4.111343 lr 0.00024845 rank 6
2022-12-08 09:39:58,433 DEBUG TRAIN Batch 29/4900 loss 7.546815 loss_att 335.557800 loss_ctc 10.928381 loss_rnnt 7.171086 lr 0.00024841 rank 7
2022-12-08 09:39:58,434 DEBUG TRAIN Batch 29/4900 loss 6.702350 loss_att 321.598877 loss_ctc 7.914229 loss_rnnt 6.567697 lr 0.00024841 rank 4
2022-12-08 09:39:58,435 DEBUG TRAIN Batch 29/4900 loss 7.093410 loss_att 366.469727 loss_ctc 14.578440 loss_rnnt 6.261739 lr 0.00024844 rank 2
2022-12-08 09:39:58,436 DEBUG TRAIN Batch 29/4900 loss 12.856286 loss_att 367.175598 loss_ctc 23.619843 loss_rnnt 11.660336 lr 0.00024845 rank 1
2022-12-08 09:39:58,438 DEBUG TRAIN Batch 29/4900 loss 5.448995 loss_att 327.841034 loss_ctc 10.198354 loss_rnnt 4.921288 lr 0.00024843 rank 5
2022-12-08 09:39:58,441 DEBUG TRAIN Batch 29/4900 loss 5.393788 loss_att 334.409119 loss_ctc 11.406565 loss_rnnt 4.725702 lr 0.00024840 rank 0
2022-12-08 09:41:09,212 DEBUG TRAIN Batch 29/5000 loss 6.895821 loss_att 222.937469 loss_ctc 15.479709 loss_rnnt 5.942056 lr 0.00024842 rank 6
2022-12-08 09:41:09,213 DEBUG TRAIN Batch 29/5000 loss 11.823711 loss_att 323.892181 loss_ctc 20.463701 loss_rnnt 10.863712 lr 0.00024837 rank 0
2022-12-08 09:41:09,214 DEBUG TRAIN Batch 29/5000 loss 8.687241 loss_att 319.727936 loss_ctc 19.911800 loss_rnnt 7.440068 lr 0.00024838 rank 4
2022-12-08 09:41:09,217 DEBUG TRAIN Batch 29/5000 loss 6.532003 loss_att 381.480011 loss_ctc 10.723356 loss_rnnt 6.066297 lr 0.00024840 rank 2
2022-12-08 09:41:09,217 DEBUG TRAIN Batch 29/5000 loss 11.565657 loss_att 336.995575 loss_ctc 21.822004 loss_rnnt 10.426063 lr 0.00024838 rank 7
2022-12-08 09:41:09,220 DEBUG TRAIN Batch 29/5000 loss 7.407259 loss_att 332.549805 loss_ctc 15.089597 loss_rnnt 6.553666 lr 0.00024842 rank 1
2022-12-08 09:41:09,220 DEBUG TRAIN Batch 29/5000 loss 12.185593 loss_att 148.043961 loss_ctc 18.562231 loss_rnnt 11.477077 lr 0.00024839 rank 3
2022-12-08 09:41:09,222 DEBUG TRAIN Batch 29/5000 loss 5.926056 loss_att 194.097473 loss_ctc 10.996771 loss_rnnt 5.362643 lr 0.00024840 rank 5
2022-12-08 09:42:12,432 DEBUG TRAIN Batch 29/5100 loss 11.529943 loss_att 186.760666 loss_ctc 19.088367 loss_rnnt 10.690120 lr 0.00024835 rank 4
2022-12-08 09:42:12,434 DEBUG TRAIN Batch 29/5100 loss 2.651628 loss_att 378.095886 loss_ctc 7.973556 loss_rnnt 2.060303 lr 0.00024836 rank 3
2022-12-08 09:42:12,436 DEBUG TRAIN Batch 29/5100 loss 3.583429 loss_att 390.320007 loss_ctc 12.184558 loss_rnnt 2.627748 lr 0.00024837 rank 5
2022-12-08 09:42:12,437 DEBUG TRAIN Batch 29/5100 loss 8.457976 loss_att 156.570724 loss_ctc 12.960805 loss_rnnt 7.957662 lr 0.00024835 rank 7
2022-12-08 09:42:12,439 DEBUG TRAIN Batch 29/5100 loss 8.197328 loss_att 225.734573 loss_ctc 11.860642 loss_rnnt 7.790293 lr 0.00024837 rank 2
2022-12-08 09:42:12,441 DEBUG TRAIN Batch 29/5100 loss 5.994530 loss_att 294.175049 loss_ctc 11.014261 loss_rnnt 5.436782 lr 0.00024839 rank 1
2022-12-08 09:42:12,441 DEBUG TRAIN Batch 29/5100 loss 13.075628 loss_att 167.672318 loss_ctc 25.167185 loss_rnnt 11.732121 lr 0.00024834 rank 0
2022-12-08 09:42:12,481 DEBUG TRAIN Batch 29/5100 loss 13.834144 loss_att 432.418152 loss_ctc 33.039406 loss_rnnt 11.700226 lr 0.00024839 rank 6
2022-12-08 09:43:15,664 DEBUG TRAIN Batch 29/5200 loss 5.061748 loss_att 357.957245 loss_ctc 9.590407 loss_rnnt 4.558564 lr 0.00024836 rank 6
2022-12-08 09:43:15,664 DEBUG TRAIN Batch 29/5200 loss 6.573647 loss_att 389.436584 loss_ctc 11.969802 loss_rnnt 5.974073 lr 0.00024834 rank 2
2022-12-08 09:43:15,665 DEBUG TRAIN Batch 29/5200 loss 4.780340 loss_att 507.089050 loss_ctc 10.415409 loss_rnnt 4.154221 lr 0.00024836 rank 1
2022-12-08 09:43:15,668 DEBUG TRAIN Batch 29/5200 loss 8.767260 loss_att 386.784790 loss_ctc 18.345213 loss_rnnt 7.703042 lr 0.00024832 rank 7
2022-12-08 09:43:15,668 DEBUG TRAIN Batch 29/5200 loss 7.449788 loss_att 353.237488 loss_ctc 10.373043 loss_rnnt 7.124982 lr 0.00024833 rank 3
2022-12-08 09:43:15,669 DEBUG TRAIN Batch 29/5200 loss 6.806030 loss_att 361.715820 loss_ctc 11.778242 loss_rnnt 6.253562 lr 0.00024832 rank 4
2022-12-08 09:43:15,672 DEBUG TRAIN Batch 29/5200 loss 7.043356 loss_att 421.084412 loss_ctc 17.309824 loss_rnnt 5.902637 lr 0.00024831 rank 0
2022-12-08 09:43:15,712 DEBUG TRAIN Batch 29/5200 loss 3.168853 loss_att 338.807312 loss_ctc 10.252931 loss_rnnt 2.381733 lr 0.00024834 rank 5
2022-12-08 09:44:20,332 DEBUG TRAIN Batch 29/5300 loss 5.835206 loss_att 441.646301 loss_ctc 13.522994 loss_rnnt 4.981008 lr 0.00024833 rank 1
2022-12-08 09:44:20,341 DEBUG TRAIN Batch 29/5300 loss 9.708382 loss_att 316.149750 loss_ctc 18.372841 loss_rnnt 8.745665 lr 0.00024831 rank 2
2022-12-08 09:44:20,343 DEBUG TRAIN Batch 29/5300 loss 5.336271 loss_att 380.203705 loss_ctc 13.683906 loss_rnnt 4.408757 lr 0.00024829 rank 7
2022-12-08 09:44:20,344 DEBUG TRAIN Batch 29/5300 loss 8.225460 loss_att 304.941132 loss_ctc 19.066626 loss_rnnt 7.020886 lr 0.00024833 rank 6
2022-12-08 09:44:20,345 DEBUG TRAIN Batch 29/5300 loss 14.916813 loss_att 434.647430 loss_ctc 20.623398 loss_rnnt 14.282748 lr 0.00024829 rank 4
2022-12-08 09:44:20,345 DEBUG TRAIN Batch 29/5300 loss 2.972934 loss_att 392.017426 loss_ctc 9.125015 loss_rnnt 2.289369 lr 0.00024828 rank 0
2022-12-08 09:44:20,349 DEBUG TRAIN Batch 29/5300 loss 8.632982 loss_att 389.877319 loss_ctc 19.565851 loss_rnnt 7.418220 lr 0.00024830 rank 3
2022-12-08 09:44:20,364 DEBUG TRAIN Batch 29/5300 loss 6.198874 loss_att 394.173828 loss_ctc 17.965014 loss_rnnt 4.891526 lr 0.00024831 rank 5
2022-12-08 09:45:30,822 DEBUG TRAIN Batch 29/5400 loss 7.690119 loss_att 349.148438 loss_ctc 10.811427 loss_rnnt 7.343307 lr 0.00024826 rank 4
2022-12-08 09:45:30,834 DEBUG TRAIN Batch 29/5400 loss 8.590489 loss_att 395.936432 loss_ctc 20.226009 loss_rnnt 7.297654 lr 0.00024825 rank 0
2022-12-08 09:45:30,836 DEBUG TRAIN Batch 29/5400 loss 13.873167 loss_att 324.575714 loss_ctc 27.170824 loss_rnnt 12.395649 lr 0.00024826 rank 7
2022-12-08 09:45:30,836 DEBUG TRAIN Batch 29/5400 loss 6.594360 loss_att 402.937134 loss_ctc 15.074636 loss_rnnt 5.652107 lr 0.00024830 rank 6
2022-12-08 09:45:30,842 DEBUG TRAIN Batch 29/5400 loss 2.882402 loss_att 389.162720 loss_ctc 7.743754 loss_rnnt 2.342252 lr 0.00024828 rank 5
2022-12-08 09:45:30,843 DEBUG TRAIN Batch 29/5400 loss 8.026248 loss_att 410.933960 loss_ctc 19.051125 loss_rnnt 6.801262 lr 0.00024830 rank 1
2022-12-08 09:45:30,846 DEBUG TRAIN Batch 29/5400 loss 6.682231 loss_att 372.247375 loss_ctc 14.427003 loss_rnnt 5.821701 lr 0.00024828 rank 2
2022-12-08 09:45:30,884 DEBUG TRAIN Batch 29/5400 loss 4.450072 loss_att 390.929932 loss_ctc 11.083109 loss_rnnt 3.713068 lr 0.00024827 rank 3
2022-12-08 09:46:33,225 DEBUG TRAIN Batch 29/5500 loss 13.869757 loss_att 351.994690 loss_ctc 25.030874 loss_rnnt 12.629633 lr 0.00024823 rank 4
2022-12-08 09:46:33,230 DEBUG TRAIN Batch 29/5500 loss 8.202319 loss_att 344.498779 loss_ctc 11.608950 loss_rnnt 7.823805 lr 0.00024825 rank 2
2022-12-08 09:46:33,231 DEBUG TRAIN Batch 29/5500 loss 6.072291 loss_att 317.160950 loss_ctc 13.516451 loss_rnnt 5.245162 lr 0.00024824 rank 3
2022-12-08 09:46:33,232 DEBUG TRAIN Batch 29/5500 loss 10.129614 loss_att 357.167267 loss_ctc 18.853418 loss_rnnt 9.160303 lr 0.00024826 rank 6
2022-12-08 09:46:33,233 DEBUG TRAIN Batch 29/5500 loss 10.917156 loss_att 351.320038 loss_ctc 22.795910 loss_rnnt 9.597296 lr 0.00024827 rank 1
2022-12-08 09:46:33,233 DEBUG TRAIN Batch 29/5500 loss 4.090889 loss_att 348.152435 loss_ctc 8.321257 loss_rnnt 3.620848 lr 0.00024823 rank 7
2022-12-08 09:46:33,233 DEBUG TRAIN Batch 29/5500 loss 6.671847 loss_att 324.550537 loss_ctc 12.362041 loss_rnnt 6.039604 lr 0.00024825 rank 5
2022-12-08 09:46:33,237 DEBUG TRAIN Batch 29/5500 loss 8.676494 loss_att 391.385681 loss_ctc 14.812278 loss_rnnt 7.994740 lr 0.00024822 rank 0
2022-12-08 09:47:36,498 DEBUG TRAIN Batch 29/5600 loss 3.953355 loss_att 355.622467 loss_ctc 9.774542 loss_rnnt 3.306557 lr 0.00024820 rank 7
2022-12-08 09:47:36,498 DEBUG TRAIN Batch 29/5600 loss 11.632793 loss_att 291.626160 loss_ctc 20.240622 loss_rnnt 10.676369 lr 0.00024823 rank 6
2022-12-08 09:47:36,498 DEBUG TRAIN Batch 29/5600 loss 6.792612 loss_att 350.822937 loss_ctc 11.165493 loss_rnnt 6.306736 lr 0.00024824 rank 1
2022-12-08 09:47:36,499 DEBUG TRAIN Batch 29/5600 loss 6.339087 loss_att 197.693054 loss_ctc 11.213913 loss_rnnt 5.797440 lr 0.00024821 rank 3
2022-12-08 09:47:36,499 DEBUG TRAIN Batch 29/5600 loss 5.830740 loss_att 358.244690 loss_ctc 12.629441 loss_rnnt 5.075329 lr 0.00024820 rank 4
2022-12-08 09:47:36,504 DEBUG TRAIN Batch 29/5600 loss 14.544509 loss_att 277.002502 loss_ctc 30.793905 loss_rnnt 12.739021 lr 0.00024822 rank 5
2022-12-08 09:47:36,506 DEBUG TRAIN Batch 29/5600 loss 6.641731 loss_att 372.342590 loss_ctc 14.624733 loss_rnnt 5.754731 lr 0.00024819 rank 0
2022-12-08 09:47:36,517 DEBUG TRAIN Batch 29/5600 loss 14.127132 loss_att 350.598938 loss_ctc 25.244473 loss_rnnt 12.891872 lr 0.00024822 rank 2
2022-12-08 09:48:47,034 DEBUG TRAIN Batch 29/5700 loss 11.508176 loss_att 300.850159 loss_ctc 23.618155 loss_rnnt 10.162622 lr 0.00024816 rank 7
2022-12-08 09:48:47,036 DEBUG TRAIN Batch 29/5700 loss 16.023676 loss_att 351.348724 loss_ctc 25.249458 loss_rnnt 14.998590 lr 0.00024817 rank 4
2022-12-08 09:48:47,039 DEBUG TRAIN Batch 29/5700 loss 6.167548 loss_att 231.001526 loss_ctc 12.981234 loss_rnnt 5.410472 lr 0.00024819 rank 2
2022-12-08 09:48:47,039 DEBUG TRAIN Batch 29/5700 loss 6.822728 loss_att 310.553986 loss_ctc 12.075139 loss_rnnt 6.239127 lr 0.00024816 rank 0
2022-12-08 09:48:47,039 DEBUG TRAIN Batch 29/5700 loss 10.600203 loss_att 322.306122 loss_ctc 21.317535 loss_rnnt 9.409388 lr 0.00024821 rank 1
2022-12-08 09:48:47,044 DEBUG TRAIN Batch 29/5700 loss 4.857862 loss_att 408.291077 loss_ctc 12.606136 loss_rnnt 3.996943 lr 0.00024819 rank 5
2022-12-08 09:48:47,049 DEBUG TRAIN Batch 29/5700 loss 8.934671 loss_att 428.004883 loss_ctc 19.605322 loss_rnnt 7.749043 lr 0.00024818 rank 3
2022-12-08 09:48:47,057 DEBUG TRAIN Batch 29/5700 loss 4.240249 loss_att 110.456970 loss_ctc 8.867828 loss_rnnt 3.726074 lr 0.00024820 rank 6
2022-12-08 09:49:50,445 DEBUG TRAIN Batch 29/5800 loss 3.524859 loss_att 407.509277 loss_ctc 9.250821 loss_rnnt 2.888641 lr 0.00024815 rank 3
2022-12-08 09:49:50,446 DEBUG TRAIN Batch 29/5800 loss 9.856622 loss_att 429.340759 loss_ctc 17.412338 loss_rnnt 9.017097 lr 0.00024813 rank 4
2022-12-08 09:49:50,447 DEBUG TRAIN Batch 29/5800 loss 8.180649 loss_att 334.771912 loss_ctc 16.108135 loss_rnnt 7.299817 lr 0.00024813 rank 0
2022-12-08 09:49:50,447 DEBUG TRAIN Batch 29/5800 loss 8.882648 loss_att 361.381775 loss_ctc 13.098108 loss_rnnt 8.414263 lr 0.00024816 rank 2
2022-12-08 09:49:50,452 DEBUG TRAIN Batch 29/5800 loss 5.957912 loss_att 397.755920 loss_ctc 15.737540 loss_rnnt 4.871287 lr 0.00024817 rank 6
2022-12-08 09:49:50,457 DEBUG TRAIN Batch 29/5800 loss 7.031962 loss_att 334.866150 loss_ctc 14.607548 loss_rnnt 6.190230 lr 0.00024816 rank 5
2022-12-08 09:49:50,457 DEBUG TRAIN Batch 29/5800 loss 8.997836 loss_att 155.388535 loss_ctc 13.453687 loss_rnnt 8.502742 lr 0.00024817 rank 1
2022-12-08 09:49:50,458 DEBUG TRAIN Batch 29/5800 loss 8.633827 loss_att 403.940918 loss_ctc 17.600983 loss_rnnt 7.637477 lr 0.00024813 rank 7
2022-12-08 09:50:53,261 DEBUG TRAIN Batch 29/5900 loss 3.177581 loss_att 420.198090 loss_ctc 7.972444 loss_rnnt 2.644818 lr 0.00024810 rank 4
2022-12-08 09:50:53,263 DEBUG TRAIN Batch 29/5900 loss 7.570522 loss_att 372.175537 loss_ctc 14.516853 loss_rnnt 6.798708 lr 0.00024810 rank 7
2022-12-08 09:50:53,268 DEBUG TRAIN Batch 29/5900 loss 8.928303 loss_att 384.225037 loss_ctc 26.209158 loss_rnnt 7.008208 lr 0.00024813 rank 2
2022-12-08 09:50:53,268 DEBUG TRAIN Batch 29/5900 loss 6.964660 loss_att 395.682617 loss_ctc 11.253997 loss_rnnt 6.488067 lr 0.00024812 rank 3
2022-12-08 09:50:53,270 DEBUG TRAIN Batch 29/5900 loss 11.497368 loss_att 411.550781 loss_ctc 16.387074 loss_rnnt 10.954067 lr 0.00024813 rank 5
2022-12-08 09:50:53,270 DEBUG TRAIN Batch 29/5900 loss 3.681029 loss_att 407.220398 loss_ctc 8.080123 loss_rnnt 3.192241 lr 0.00024810 rank 0
2022-12-08 09:50:53,273 DEBUG TRAIN Batch 29/5900 loss 3.051554 loss_att 386.725891 loss_ctc 5.644319 loss_rnnt 2.763469 lr 0.00024814 rank 6
2022-12-08 09:50:53,273 DEBUG TRAIN Batch 29/5900 loss 2.833708 loss_att 353.840393 loss_ctc 8.268857 loss_rnnt 2.229803 lr 0.00024814 rank 1
2022-12-08 09:51:57,268 DEBUG TRAIN Batch 29/6000 loss 10.793568 loss_att 418.307159 loss_ctc 20.441107 loss_rnnt 9.721620 lr 0.00024811 rank 6
2022-12-08 09:51:57,270 DEBUG TRAIN Batch 29/6000 loss 15.390984 loss_att 398.119720 loss_ctc 24.019836 loss_rnnt 14.432223 lr 0.00024807 rank 4
2022-12-08 09:51:57,271 DEBUG TRAIN Batch 29/6000 loss 9.273739 loss_att 359.063202 loss_ctc 21.125092 loss_rnnt 7.956922 lr 0.00024809 rank 3
2022-12-08 09:51:57,275 DEBUG TRAIN Batch 29/6000 loss 13.594223 loss_att 425.799408 loss_ctc 24.110851 loss_rnnt 12.425709 lr 0.00024810 rank 5
2022-12-08 09:51:57,275 DEBUG TRAIN Batch 29/6000 loss 3.328791 loss_att 379.178589 loss_ctc 10.435512 loss_rnnt 2.539156 lr 0.00024807 rank 0
2022-12-08 09:51:57,278 DEBUG TRAIN Batch 29/6000 loss 4.506883 loss_att 372.745178 loss_ctc 6.661396 loss_rnnt 4.267492 lr 0.00024807 rank 7
2022-12-08 09:51:57,280 DEBUG TRAIN Batch 29/6000 loss 10.942430 loss_att 353.985535 loss_ctc 23.650450 loss_rnnt 9.530429 lr 0.00024811 rank 1
2022-12-08 09:51:57,298 DEBUG TRAIN Batch 29/6000 loss 2.537394 loss_att 339.205200 loss_ctc 5.190127 loss_rnnt 2.242646 lr 0.00024810 rank 2
2022-12-08 09:53:06,497 DEBUG TRAIN Batch 29/6100 loss 5.968381 loss_att 364.779480 loss_ctc 13.073574 loss_rnnt 5.178915 lr 0.00024804 rank 7
2022-12-08 09:53:06,505 DEBUG TRAIN Batch 29/6100 loss 5.475898 loss_att 385.809967 loss_ctc 14.797957 loss_rnnt 4.440114 lr 0.00024804 rank 4
2022-12-08 09:53:06,508 DEBUG TRAIN Batch 29/6100 loss 11.013926 loss_att 333.979004 loss_ctc 20.521114 loss_rnnt 9.957571 lr 0.00024808 rank 6
2022-12-08 09:53:06,510 DEBUG TRAIN Batch 29/6100 loss 4.973135 loss_att 358.941284 loss_ctc 8.989553 loss_rnnt 4.526866 lr 0.00024804 rank 0
2022-12-08 09:53:06,510 DEBUG TRAIN Batch 29/6100 loss 4.581638 loss_att 415.965393 loss_ctc 11.690208 loss_rnnt 3.791797 lr 0.00024807 rank 2
2022-12-08 09:53:06,510 DEBUG TRAIN Batch 29/6100 loss 8.014167 loss_att 341.520874 loss_ctc 19.111664 loss_rnnt 6.781111 lr 0.00024806 rank 3
2022-12-08 09:53:06,514 DEBUG TRAIN Batch 29/6100 loss 4.857718 loss_att 316.013885 loss_ctc 10.021300 loss_rnnt 4.283987 lr 0.00024806 rank 5
2022-12-08 09:53:06,548 DEBUG TRAIN Batch 29/6100 loss 7.887173 loss_att 385.995972 loss_ctc 15.948001 loss_rnnt 6.991525 lr 0.00024808 rank 1
2022-12-08 09:54:10,074 DEBUG TRAIN Batch 29/6200 loss 5.443923 loss_att 386.074127 loss_ctc 13.301035 loss_rnnt 4.570911 lr 0.00024801 rank 4
2022-12-08 09:54:10,077 DEBUG TRAIN Batch 29/6200 loss 6.047597 loss_att 313.929993 loss_ctc 12.495988 loss_rnnt 5.331110 lr 0.00024801 rank 7
2022-12-08 09:54:10,078 DEBUG TRAIN Batch 29/6200 loss 12.090677 loss_att 310.878998 loss_ctc 20.381582 loss_rnnt 11.169466 lr 0.00024805 rank 6
2022-12-08 09:54:10,081 DEBUG TRAIN Batch 29/6200 loss 3.709363 loss_att 354.998169 loss_ctc 8.189388 loss_rnnt 3.211582 lr 0.00024801 rank 0
2022-12-08 09:54:10,082 DEBUG TRAIN Batch 29/6200 loss 6.561870 loss_att 305.924316 loss_ctc 14.381615 loss_rnnt 5.693010 lr 0.00024803 rank 5
2022-12-08 09:54:10,083 DEBUG TRAIN Batch 29/6200 loss 2.974296 loss_att 290.316254 loss_ctc 9.187053 loss_rnnt 2.283989 lr 0.00024803 rank 3
2022-12-08 09:54:10,084 DEBUG TRAIN Batch 29/6200 loss 4.862469 loss_att 280.833221 loss_ctc 14.162827 loss_rnnt 3.829095 lr 0.00024804 rank 2
2022-12-08 09:54:10,085 DEBUG TRAIN Batch 29/6200 loss 2.286736 loss_att 346.531006 loss_ctc 6.501002 loss_rnnt 1.818484 lr 0.00024805 rank 1
2022-12-08 09:55:13,697 DEBUG TRAIN Batch 29/6300 loss 13.342319 loss_att 343.446777 loss_ctc 23.559721 loss_rnnt 12.207053 lr 0.00024798 rank 4
2022-12-08 09:55:13,710 DEBUG TRAIN Batch 29/6300 loss 3.130382 loss_att 252.088364 loss_ctc 5.367176 loss_rnnt 2.881849 lr 0.00024801 rank 2
2022-12-08 09:55:13,711 DEBUG TRAIN Batch 29/6300 loss 6.049268 loss_att 295.118896 loss_ctc 11.612760 loss_rnnt 5.431103 lr 0.00024798 rank 7
2022-12-08 09:55:13,711 DEBUG TRAIN Batch 29/6300 loss 8.847568 loss_att 89.266571 loss_ctc 11.723678 loss_rnnt 8.528000 lr 0.00024799 rank 3
2022-12-08 09:55:13,714 DEBUG TRAIN Batch 29/6300 loss 4.839005 loss_att 160.283310 loss_ctc 11.392366 loss_rnnt 4.110853 lr 0.00024802 rank 6
2022-12-08 09:55:13,718 DEBUG TRAIN Batch 29/6300 loss 12.183170 loss_att 332.408081 loss_ctc 20.493671 loss_rnnt 11.259782 lr 0.00024802 rank 1
2022-12-08 09:55:13,719 DEBUG TRAIN Batch 29/6300 loss 8.702944 loss_att 162.374222 loss_ctc 12.446769 loss_rnnt 8.286963 lr 0.00024800 rank 5
2022-12-08 09:55:13,722 DEBUG TRAIN Batch 29/6300 loss 7.716405 loss_att 269.115295 loss_ctc 14.191833 loss_rnnt 6.996913 lr 0.00024798 rank 0
2022-12-08 09:56:19,593 DEBUG TRAIN Batch 29/6400 loss 9.247519 loss_att 358.196594 loss_ctc 19.796295 loss_rnnt 8.075434 lr 0.00024796 rank 3
2022-12-08 09:56:19,596 DEBUG TRAIN Batch 29/6400 loss 1.059394 loss_att 417.182068 loss_ctc 5.817627 loss_rnnt 0.530701 lr 0.00024798 rank 2
2022-12-08 09:56:19,597 DEBUG TRAIN Batch 29/6400 loss 4.300927 loss_att 302.405243 loss_ctc 13.856466 loss_rnnt 3.239201 lr 0.00024799 rank 6
2022-12-08 09:56:19,606 DEBUG TRAIN Batch 29/6400 loss 9.395750 loss_att 123.787712 loss_ctc 13.323570 loss_rnnt 8.959326 lr 0.00024795 rank 4
2022-12-08 09:56:19,608 DEBUG TRAIN Batch 29/6400 loss 9.242845 loss_att 253.194504 loss_ctc 17.854923 loss_rnnt 8.285948 lr 0.00024799 rank 1
2022-12-08 09:56:19,609 DEBUG TRAIN Batch 29/6400 loss 13.184946 loss_att 297.408081 loss_ctc 28.997864 loss_rnnt 11.427956 lr 0.00024795 rank 0
2022-12-08 09:56:19,611 DEBUG TRAIN Batch 29/6400 loss 2.069708 loss_att 423.218597 loss_ctc 8.544714 loss_rnnt 1.350263 lr 0.00024797 rank 5
2022-12-08 09:56:19,618 DEBUG TRAIN Batch 29/6400 loss 5.886268 loss_att 392.564667 loss_ctc 10.981345 loss_rnnt 5.320148 lr 0.00024795 rank 7
2022-12-08 09:57:27,337 DEBUG TRAIN Batch 29/6500 loss 1.979744 loss_att 398.275635 loss_ctc 6.294132 loss_rnnt 1.500368 lr 0.00024792 rank 4
2022-12-08 09:57:27,340 DEBUG TRAIN Batch 29/6500 loss 6.618684 loss_att 366.447113 loss_ctc 9.450190 loss_rnnt 6.304072 lr 0.00024792 rank 7
2022-12-08 09:57:27,340 DEBUG TRAIN Batch 29/6500 loss 3.995257 loss_att 335.181366 loss_ctc 9.625580 loss_rnnt 3.369666 lr 0.00024796 rank 6
2022-12-08 09:57:27,342 DEBUG TRAIN Batch 29/6500 loss 6.275144 loss_att 431.677917 loss_ctc 13.862780 loss_rnnt 5.432073 lr 0.00024792 rank 0
2022-12-08 09:57:27,345 DEBUG TRAIN Batch 29/6500 loss 5.799993 loss_att 315.219788 loss_ctc 12.053325 loss_rnnt 5.105178 lr 0.00024795 rank 2
2022-12-08 09:57:27,348 DEBUG TRAIN Batch 29/6500 loss 3.575708 loss_att 388.548828 loss_ctc 8.607693 loss_rnnt 3.016599 lr 0.00024796 rank 1
2022-12-08 09:57:27,352 DEBUG TRAIN Batch 29/6500 loss 3.766139 loss_att 420.386780 loss_ctc 10.194996 loss_rnnt 3.051821 lr 0.00024794 rank 5
2022-12-08 09:57:27,352 DEBUG TRAIN Batch 29/6500 loss 4.498474 loss_att 388.316498 loss_ctc 10.190318 loss_rnnt 3.866047 lr 0.00024793 rank 3
2022-12-08 09:58:31,358 DEBUG TRAIN Batch 29/6600 loss 7.182900 loss_att 468.002777 loss_ctc 14.365481 loss_rnnt 6.384836 lr 0.00024789 rank 4
2022-12-08 09:58:31,360 DEBUG TRAIN Batch 29/6600 loss 8.745326 loss_att 368.235443 loss_ctc 13.820564 loss_rnnt 8.181411 lr 0.00024789 rank 7
2022-12-08 09:58:31,360 DEBUG TRAIN Batch 29/6600 loss 5.236608 loss_att 372.284515 loss_ctc 15.861382 loss_rnnt 4.056077 lr 0.00024793 rank 6
2022-12-08 09:58:31,363 DEBUG TRAIN Batch 29/6600 loss 5.184884 loss_att 387.133514 loss_ctc 12.500141 loss_rnnt 4.372077 lr 0.00024792 rank 2
2022-12-08 09:58:31,363 DEBUG TRAIN Batch 29/6600 loss 7.695424 loss_att 401.702820 loss_ctc 17.165394 loss_rnnt 6.643205 lr 0.00024790 rank 3
2022-12-08 09:58:31,364 DEBUG TRAIN Batch 29/6600 loss 3.477589 loss_att 295.783081 loss_ctc 5.088367 loss_rnnt 3.298614 lr 0.00024793 rank 1
2022-12-08 09:58:31,367 DEBUG TRAIN Batch 29/6600 loss 3.421650 loss_att 339.683014 loss_ctc 10.591663 loss_rnnt 2.624983 lr 0.00024791 rank 5
2022-12-08 09:58:31,371 DEBUG TRAIN Batch 29/6600 loss 9.859552 loss_att 418.184174 loss_ctc 22.964214 loss_rnnt 8.403480 lr 0.00024788 rank 0
2022-12-08 09:59:35,013 DEBUG TRAIN Batch 29/6700 loss 6.194427 loss_att 340.881348 loss_ctc 15.013454 loss_rnnt 5.214536 lr 0.00024787 rank 3
2022-12-08 09:59:35,024 DEBUG TRAIN Batch 29/6700 loss 10.949123 loss_att 431.199890 loss_ctc 22.921223 loss_rnnt 9.618890 lr 0.00024786 rank 7
2022-12-08 09:59:35,026 DEBUG TRAIN Batch 29/6700 loss 10.645374 loss_att 366.154510 loss_ctc 23.445393 loss_rnnt 9.223150 lr 0.00024786 rank 4
2022-12-08 09:59:35,028 DEBUG TRAIN Batch 29/6700 loss 2.864299 loss_att 378.409729 loss_ctc 10.369684 loss_rnnt 2.030367 lr 0.00024788 rank 5
2022-12-08 09:59:35,030 DEBUG TRAIN Batch 29/6700 loss 6.373835 loss_att 408.742798 loss_ctc 15.033795 loss_rnnt 5.411617 lr 0.00024785 rank 0
2022-12-08 09:59:35,059 DEBUG TRAIN Batch 29/6700 loss 3.722999 loss_att 377.584839 loss_ctc 10.402274 loss_rnnt 2.980857 lr 0.00024790 rank 1
2022-12-08 09:59:35,064 DEBUG TRAIN Batch 29/6700 loss 2.414443 loss_att 290.963898 loss_ctc 3.218884 loss_rnnt 2.325060 lr 0.00024790 rank 6
2022-12-08 09:59:35,073 DEBUG TRAIN Batch 29/6700 loss 10.048124 loss_att 376.585541 loss_ctc 20.746601 loss_rnnt 8.859405 lr 0.00024789 rank 2
2022-12-08 10:00:44,271 DEBUG TRAIN Batch 29/6800 loss 9.100837 loss_att 301.279724 loss_ctc 10.687490 loss_rnnt 8.924541 lr 0.00024783 rank 7
2022-12-08 10:00:44,272 DEBUG TRAIN Batch 29/6800 loss 5.029633 loss_att 403.459656 loss_ctc 11.960020 loss_rnnt 4.259590 lr 0.00024783 rank 4
2022-12-08 10:00:44,273 DEBUG TRAIN Batch 29/6800 loss 5.954973 loss_att 365.585144 loss_ctc 10.437218 loss_rnnt 5.456946 lr 0.00024785 rank 2
2022-12-08 10:00:44,279 DEBUG TRAIN Batch 29/6800 loss 3.929715 loss_att 319.226318 loss_ctc 12.005070 loss_rnnt 3.032454 lr 0.00024785 rank 5
2022-12-08 10:00:44,280 DEBUG TRAIN Batch 29/6800 loss 4.185466 loss_att 313.897217 loss_ctc 9.024357 loss_rnnt 3.647811 lr 0.00024787 rank 6
2022-12-08 10:00:44,281 DEBUG TRAIN Batch 29/6800 loss 15.095563 loss_att 366.832031 loss_ctc 23.649275 loss_rnnt 14.145151 lr 0.00024784 rank 3
2022-12-08 10:00:44,281 DEBUG TRAIN Batch 29/6800 loss 8.511928 loss_att 440.682251 loss_ctc 16.718136 loss_rnnt 7.600127 lr 0.00024782 rank 0
2022-12-08 10:00:44,321 DEBUG TRAIN Batch 29/6800 loss 12.664728 loss_att 411.041077 loss_ctc 20.307798 loss_rnnt 11.815498 lr 0.00024787 rank 1
2022-12-08 10:01:47,218 DEBUG TRAIN Batch 29/6900 loss 12.540036 loss_att 254.268051 loss_ctc 25.371305 loss_rnnt 11.114340 lr 0.00024784 rank 6
2022-12-08 10:01:47,218 DEBUG TRAIN Batch 29/6900 loss 8.775801 loss_att 262.854950 loss_ctc 16.686903 loss_rnnt 7.896790 lr 0.00024780 rank 7
2022-12-08 10:01:47,220 DEBUG TRAIN Batch 29/6900 loss 9.969381 loss_att 223.353500 loss_ctc 11.625518 loss_rnnt 9.785366 lr 0.00024781 rank 3
2022-12-08 10:01:47,224 DEBUG TRAIN Batch 29/6900 loss 6.645994 loss_att 266.952972 loss_ctc 15.070254 loss_rnnt 5.709966 lr 0.00024782 rank 2
2022-12-08 10:01:47,225 DEBUG TRAIN Batch 29/6900 loss 9.442425 loss_att 362.819580 loss_ctc 16.262098 loss_rnnt 8.684683 lr 0.00024779 rank 0
2022-12-08 10:01:47,227 DEBUG TRAIN Batch 29/6900 loss 10.869813 loss_att 348.133606 loss_ctc 17.625717 loss_rnnt 10.119158 lr 0.00024780 rank 4
2022-12-08 10:01:47,228 DEBUG TRAIN Batch 29/6900 loss 6.421137 loss_att 357.628510 loss_ctc 12.825979 loss_rnnt 5.709488 lr 0.00024784 rank 1
2022-12-08 10:01:47,229 DEBUG TRAIN Batch 29/6900 loss 6.912794 loss_att 254.263916 loss_ctc 12.954146 loss_rnnt 6.241533 lr 0.00024782 rank 5
2022-12-08 10:02:50,521 DEBUG TRAIN Batch 29/7000 loss 9.661666 loss_att 127.567429 loss_ctc 14.250995 loss_rnnt 9.151741 lr 0.00024779 rank 2
2022-12-08 10:02:50,523 DEBUG TRAIN Batch 29/7000 loss 9.691667 loss_att 389.374084 loss_ctc 17.595673 loss_rnnt 8.813444 lr 0.00024781 rank 6
2022-12-08 10:02:50,524 DEBUG TRAIN Batch 29/7000 loss 8.464993 loss_att 193.235245 loss_ctc 11.840192 loss_rnnt 8.089971 lr 0.00024777 rank 7
2022-12-08 10:02:50,525 DEBUG TRAIN Batch 29/7000 loss 5.641104 loss_att 510.900635 loss_ctc 14.954070 loss_rnnt 4.606330 lr 0.00024778 rank 3
2022-12-08 10:02:50,526 DEBUG TRAIN Batch 29/7000 loss 5.218476 loss_att 296.398163 loss_ctc 12.724020 loss_rnnt 4.384527 lr 0.00024781 rank 1
2022-12-08 10:02:50,526 DEBUG TRAIN Batch 29/7000 loss 7.051759 loss_att 372.486267 loss_ctc 16.243563 loss_rnnt 6.030448 lr 0.00024779 rank 5
2022-12-08 10:02:50,527 DEBUG TRAIN Batch 29/7000 loss 7.933296 loss_att 285.835785 loss_ctc 16.585096 loss_rnnt 6.971985 lr 0.00024777 rank 4
2022-12-08 10:02:50,946 DEBUG TRAIN Batch 29/7000 loss 9.730302 loss_att 135.572372 loss_ctc 17.832838 loss_rnnt 8.830020 lr 0.00024776 rank 0
2022-12-08 10:03:56,634 DEBUG TRAIN Batch 29/7100 loss 6.319009 loss_att 354.470886 loss_ctc 16.969202 loss_rnnt 5.135654 lr 0.00024774 rank 7
2022-12-08 10:03:56,635 DEBUG TRAIN Batch 29/7100 loss 8.503592 loss_att 457.992126 loss_ctc 18.190439 loss_rnnt 7.427277 lr 0.00024776 rank 2
2022-12-08 10:03:56,636 DEBUG TRAIN Batch 29/7100 loss 15.576361 loss_att 77.096870 loss_ctc 20.448507 loss_rnnt 15.035012 lr 0.00024774 rank 4
2022-12-08 10:03:56,639 DEBUG TRAIN Batch 29/7100 loss 4.763873 loss_att 340.336670 loss_ctc 8.753668 loss_rnnt 4.320562 lr 0.00024778 rank 6
2022-12-08 10:03:56,640 DEBUG TRAIN Batch 29/7100 loss 2.051257 loss_att 328.158020 loss_ctc 10.918757 loss_rnnt 1.065979 lr 0.00024773 rank 0
2022-12-08 10:03:56,654 DEBUG TRAIN Batch 29/7100 loss 12.402694 loss_att 164.100418 loss_ctc 16.479708 loss_rnnt 11.949692 lr 0.00024778 rank 1
2022-12-08 10:03:56,658 DEBUG TRAIN Batch 29/7100 loss 4.329291 loss_att 346.214722 loss_ctc 8.615809 loss_rnnt 3.853012 lr 0.00024775 rank 3
2022-12-08 10:03:56,683 DEBUG TRAIN Batch 29/7100 loss 3.239941 loss_att 355.672791 loss_ctc 4.316265 loss_rnnt 3.120349 lr 0.00024776 rank 5
2022-12-08 10:05:05,119 DEBUG TRAIN Batch 29/7200 loss 6.616452 loss_att 404.593719 loss_ctc 10.651117 loss_rnnt 6.168156 lr 0.00024771 rank 7
2022-12-08 10:05:05,121 DEBUG TRAIN Batch 29/7200 loss 7.984176 loss_att 335.135498 loss_ctc 23.340107 loss_rnnt 6.277961 lr 0.00024771 rank 4
2022-12-08 10:05:05,124 DEBUG TRAIN Batch 29/7200 loss 11.603796 loss_att 403.110596 loss_ctc 31.196814 loss_rnnt 9.426794 lr 0.00024775 rank 1
2022-12-08 10:05:05,124 DEBUG TRAIN Batch 29/7200 loss 7.770964 loss_att 341.318695 loss_ctc 17.877064 loss_rnnt 6.648064 lr 0.00024773 rank 2
2022-12-08 10:05:05,125 DEBUG TRAIN Batch 29/7200 loss 3.414815 loss_att 343.662231 loss_ctc 9.185781 loss_rnnt 2.773597 lr 0.00024772 rank 3
2022-12-08 10:05:05,124 DEBUG TRAIN Batch 29/7200 loss 7.044767 loss_att 327.742889 loss_ctc 14.173926 loss_rnnt 6.252638 lr 0.00024775 rank 6
2022-12-08 10:05:05,126 DEBUG TRAIN Batch 29/7200 loss 10.999271 loss_att 378.405029 loss_ctc 20.710972 loss_rnnt 9.920194 lr 0.00024770 rank 0
2022-12-08 10:05:05,133 DEBUG TRAIN Batch 29/7200 loss 5.631805 loss_att 374.739624 loss_ctc 9.242314 loss_rnnt 5.230638 lr 0.00024773 rank 5
2022-12-08 10:06:08,138 DEBUG TRAIN Batch 29/7300 loss 5.225739 loss_att 332.227875 loss_ctc 12.174192 loss_rnnt 4.453688 lr 0.00024770 rank 2
2022-12-08 10:06:08,142 DEBUG TRAIN Batch 29/7300 loss 2.981385 loss_att 402.729462 loss_ctc 10.870667 loss_rnnt 2.104798 lr 0.00024772 rank 6
2022-12-08 10:06:08,143 DEBUG TRAIN Batch 29/7300 loss 4.572951 loss_att 357.022095 loss_ctc 9.000847 loss_rnnt 4.080963 lr 0.00024768 rank 7
2022-12-08 10:06:08,143 DEBUG TRAIN Batch 29/7300 loss 14.731200 loss_att 422.084290 loss_ctc 38.828655 loss_rnnt 12.053705 lr 0.00024768 rank 4
2022-12-08 10:06:08,148 DEBUG TRAIN Batch 29/7300 loss 6.861919 loss_att 358.942688 loss_ctc 9.499117 loss_rnnt 6.568897 lr 0.00024770 rank 5
2022-12-08 10:06:08,149 DEBUG TRAIN Batch 29/7300 loss 11.213489 loss_att 417.531494 loss_ctc 20.563932 loss_rnnt 10.174550 lr 0.00024767 rank 0
2022-12-08 10:06:08,171 DEBUG TRAIN Batch 29/7300 loss 13.951021 loss_att 468.845306 loss_ctc 24.218390 loss_rnnt 12.810204 lr 0.00024772 rank 1
2022-12-08 10:06:08,182 DEBUG TRAIN Batch 29/7300 loss 5.786843 loss_att 382.492859 loss_ctc 8.822016 loss_rnnt 5.449602 lr 0.00024769 rank 3
2022-12-08 10:07:12,343 DEBUG TRAIN Batch 29/7400 loss 7.890219 loss_att 367.987549 loss_ctc 13.758300 loss_rnnt 7.238210 lr 0.00024769 rank 1
2022-12-08 10:07:12,344 DEBUG TRAIN Batch 29/7400 loss 3.727514 loss_att 296.787598 loss_ctc 8.390355 loss_rnnt 3.209420 lr 0.00024766 rank 3
2022-12-08 10:07:12,351 DEBUG TRAIN Batch 29/7400 loss 10.573854 loss_att 329.695587 loss_ctc 17.398849 loss_rnnt 9.815521 lr 0.00024769 rank 6
2022-12-08 10:07:12,351 DEBUG TRAIN Batch 29/7400 loss 5.877154 loss_att 423.772766 loss_ctc 9.973204 loss_rnnt 5.422038 lr 0.00024765 rank 4
2022-12-08 10:07:12,353 DEBUG TRAIN Batch 29/7400 loss 9.413687 loss_att 372.921509 loss_ctc 18.365126 loss_rnnt 8.419083 lr 0.00024764 rank 0
2022-12-08 10:07:12,355 DEBUG TRAIN Batch 29/7400 loss 4.999523 loss_att 331.821838 loss_ctc 12.879267 loss_rnnt 4.123996 lr 0.00024767 rank 2
2022-12-08 10:07:12,358 DEBUG TRAIN Batch 29/7400 loss 8.928432 loss_att 321.393127 loss_ctc 11.282267 loss_rnnt 8.666896 lr 0.00024767 rank 5
2022-12-08 10:07:12,368 DEBUG TRAIN Batch 29/7400 loss 6.449229 loss_att 367.308960 loss_ctc 8.198259 loss_rnnt 6.254892 lr 0.00024765 rank 7
2022-12-08 10:08:23,606 DEBUG TRAIN Batch 29/7500 loss 16.189880 loss_att 365.517853 loss_ctc 24.988041 loss_rnnt 15.212307 lr 0.00024762 rank 4
2022-12-08 10:08:23,606 DEBUG TRAIN Batch 29/7500 loss 8.720069 loss_att 319.403900 loss_ctc 14.775399 loss_rnnt 8.047255 lr 0.00024762 rank 7
2022-12-08 10:08:23,607 DEBUG TRAIN Batch 29/7500 loss 12.051092 loss_att 328.197723 loss_ctc 21.656525 loss_rnnt 10.983823 lr 0.00024763 rank 3
2022-12-08 10:08:23,607 DEBUG TRAIN Batch 29/7500 loss 5.764740 loss_att 350.421875 loss_ctc 10.463152 loss_rnnt 5.242694 lr 0.00024766 rank 1
2022-12-08 10:08:23,610 DEBUG TRAIN Batch 29/7500 loss 13.328895 loss_att 344.391937 loss_ctc 27.615765 loss_rnnt 11.741465 lr 0.00024764 rank 2
2022-12-08 10:08:23,610 DEBUG TRAIN Batch 29/7500 loss 18.683723 loss_att 324.051056 loss_ctc 33.532257 loss_rnnt 17.033888 lr 0.00024764 rank 5
2022-12-08 10:08:23,611 DEBUG TRAIN Batch 29/7500 loss 8.312204 loss_att 371.396759 loss_ctc 19.541264 loss_rnnt 7.064531 lr 0.00024761 rank 0
2022-12-08 10:08:23,653 DEBUG TRAIN Batch 29/7500 loss 15.975410 loss_att 293.885834 loss_ctc 37.583454 loss_rnnt 13.574516 lr 0.00024765 rank 6
2022-12-08 10:09:27,045 DEBUG TRAIN Batch 29/7600 loss 9.183123 loss_att 224.214203 loss_ctc 18.820173 loss_rnnt 8.112339 lr 0.00024759 rank 7
2022-12-08 10:09:27,046 DEBUG TRAIN Batch 29/7600 loss 13.418523 loss_att 380.778320 loss_ctc 26.428997 loss_rnnt 11.972915 lr 0.00024759 rank 4
2022-12-08 10:09:27,047 DEBUG TRAIN Batch 29/7600 loss 11.734849 loss_att 197.832489 loss_ctc 18.025686 loss_rnnt 11.035868 lr 0.00024761 rank 2
2022-12-08 10:09:27,051 DEBUG TRAIN Batch 29/7600 loss 8.975417 loss_att 122.159973 loss_ctc 15.486952 loss_rnnt 8.251913 lr 0.00024760 rank 3
2022-12-08 10:09:27,059 DEBUG TRAIN Batch 29/7600 loss 5.873140 loss_att 227.535126 loss_ctc 14.073862 loss_rnnt 4.961948 lr 0.00024758 rank 0
2022-12-08 10:09:27,062 DEBUG TRAIN Batch 29/7600 loss 6.186992 loss_att 284.971649 loss_ctc 21.456701 loss_rnnt 4.490357 lr 0.00024761 rank 5
2022-12-08 10:09:27,073 DEBUG TRAIN Batch 29/7600 loss 9.773045 loss_att 358.471710 loss_ctc 16.982323 loss_rnnt 8.972013 lr 0.00024763 rank 1
2022-12-08 10:09:27,075 DEBUG TRAIN Batch 29/7600 loss 4.050266 loss_att 369.770691 loss_ctc 11.147383 loss_rnnt 3.261697 lr 0.00024762 rank 6
2022-12-08 10:10:30,101 DEBUG TRAIN Batch 29/7700 loss 8.572210 loss_att 402.567963 loss_ctc 19.469517 loss_rnnt 7.361398 lr 0.00024756 rank 7
2022-12-08 10:10:30,111 DEBUG TRAIN Batch 29/7700 loss 8.534698 loss_att 190.838867 loss_ctc 15.353172 loss_rnnt 7.777091 lr 0.00024756 rank 4
2022-12-08 10:10:30,116 DEBUG TRAIN Batch 29/7700 loss 7.900844 loss_att 390.725067 loss_ctc 12.392039 loss_rnnt 7.401823 lr 0.00024759 rank 6
2022-12-08 10:10:30,116 DEBUG TRAIN Batch 29/7700 loss 8.823858 loss_att 184.108215 loss_ctc 13.708143 loss_rnnt 8.281160 lr 0.00024760 rank 1
2022-12-08 10:10:30,117 DEBUG TRAIN Batch 29/7700 loss 8.272632 loss_att 345.931244 loss_ctc 14.618023 loss_rnnt 7.567589 lr 0.00024757 rank 3
2022-12-08 10:10:30,117 DEBUG TRAIN Batch 29/7700 loss 24.623444 loss_att 430.691345 loss_ctc 42.124290 loss_rnnt 22.678905 lr 0.00024758 rank 2
2022-12-08 10:10:30,118 DEBUG TRAIN Batch 29/7700 loss 2.574929 loss_att 340.001251 loss_ctc 8.509390 loss_rnnt 1.915544 lr 0.00024758 rank 5
2022-12-08 10:10:30,120 DEBUG TRAIN Batch 29/7700 loss 0.765799 loss_att 379.533936 loss_ctc 2.472458 loss_rnnt 0.576171 lr 0.00024755 rank 0
2022-12-08 10:11:35,232 DEBUG TRAIN Batch 29/7800 loss 9.650198 loss_att 424.132904 loss_ctc 16.220413 loss_rnnt 8.920174 lr 0.00024757 rank 1
2022-12-08 10:11:35,239 DEBUG TRAIN Batch 29/7800 loss 5.951629 loss_att 380.681732 loss_ctc 12.655051 loss_rnnt 5.206804 lr 0.00024753 rank 4
2022-12-08 10:11:35,241 DEBUG TRAIN Batch 29/7800 loss 3.971671 loss_att 402.582367 loss_ctc 11.328909 loss_rnnt 3.154201 lr 0.00024753 rank 7
2022-12-08 10:11:35,243 DEBUG TRAIN Batch 29/7800 loss 5.270928 loss_att 342.433563 loss_ctc 14.051479 loss_rnnt 4.295312 lr 0.00024755 rank 5
2022-12-08 10:11:35,243 DEBUG TRAIN Batch 29/7800 loss 6.256320 loss_att 436.871185 loss_ctc 12.435466 loss_rnnt 5.569748 lr 0.00024755 rank 2
2022-12-08 10:11:35,244 DEBUG TRAIN Batch 29/7800 loss 8.799871 loss_att 413.487488 loss_ctc 19.379997 loss_rnnt 7.624302 lr 0.00024754 rank 3
2022-12-08 10:11:35,245 DEBUG TRAIN Batch 29/7800 loss 13.429307 loss_att 375.268250 loss_ctc 18.845686 loss_rnnt 12.827488 lr 0.00024756 rank 6
2022-12-08 10:11:35,246 DEBUG TRAIN Batch 29/7800 loss 7.768412 loss_att 369.370544 loss_ctc 16.409826 loss_rnnt 6.808255 lr 0.00024752 rank 0
2022-12-08 10:12:43,871 DEBUG TRAIN Batch 29/7900 loss 8.052466 loss_att 371.253784 loss_ctc 16.638672 loss_rnnt 7.098444 lr 0.00024749 rank 0
2022-12-08 10:12:43,885 DEBUG TRAIN Batch 29/7900 loss 4.589706 loss_att 335.695251 loss_ctc 11.137862 loss_rnnt 3.862133 lr 0.00024753 rank 6
2022-12-08 10:12:43,889 DEBUG TRAIN Batch 29/7900 loss 4.119116 loss_att 421.751923 loss_ctc 9.344639 loss_rnnt 3.538502 lr 0.00024752 rank 2
2022-12-08 10:12:43,893 DEBUG TRAIN Batch 29/7900 loss 11.425438 loss_att 455.250000 loss_ctc 28.126694 loss_rnnt 9.569742 lr 0.00024754 rank 1
2022-12-08 10:12:43,894 DEBUG TRAIN Batch 29/7900 loss 7.506172 loss_att 430.587494 loss_ctc 18.815807 loss_rnnt 6.249546 lr 0.00024750 rank 4
2022-12-08 10:12:43,894 DEBUG TRAIN Batch 29/7900 loss 12.089987 loss_att 408.712250 loss_ctc 21.549946 loss_rnnt 11.038880 lr 0.00024749 rank 7
2022-12-08 10:12:43,895 DEBUG TRAIN Batch 29/7900 loss 8.243955 loss_att 396.952759 loss_ctc 19.344530 loss_rnnt 7.010558 lr 0.00024752 rank 5
2022-12-08 10:12:43,931 DEBUG TRAIN Batch 29/7900 loss 3.874088 loss_att 373.494232 loss_ctc 8.851215 loss_rnnt 3.321074 lr 0.00024751 rank 3
2022-12-08 10:13:46,988 DEBUG TRAIN Batch 29/8000 loss 3.511489 loss_att 348.586121 loss_ctc 7.898122 loss_rnnt 3.024086 lr 0.00024747 rank 4
2022-12-08 10:13:46,991 DEBUG TRAIN Batch 29/8000 loss 10.378604 loss_att 374.196259 loss_ctc 22.807152 loss_rnnt 8.997655 lr 0.00024749 rank 2
2022-12-08 10:13:46,991 DEBUG TRAIN Batch 29/8000 loss 11.843416 loss_att 385.135071 loss_ctc 21.605371 loss_rnnt 10.758755 lr 0.00024748 rank 3
2022-12-08 10:13:46,993 DEBUG TRAIN Batch 29/8000 loss 7.862948 loss_att 345.794800 loss_ctc 13.284429 loss_rnnt 7.260561 lr 0.00024746 rank 7
2022-12-08 10:13:46,993 DEBUG TRAIN Batch 29/8000 loss 9.241903 loss_att 366.280029 loss_ctc 18.809853 loss_rnnt 8.178798 lr 0.00024749 rank 5
2022-12-08 10:13:46,994 DEBUG TRAIN Batch 29/8000 loss 5.846591 loss_att 379.218384 loss_ctc 13.114425 loss_rnnt 5.039054 lr 0.00024750 rank 6
2022-12-08 10:13:46,997 DEBUG TRAIN Batch 29/8000 loss 7.056458 loss_att 374.782593 loss_ctc 13.062356 loss_rnnt 6.389135 lr 0.00024746 rank 0
2022-12-08 10:13:46,999 DEBUG TRAIN Batch 29/8000 loss 15.408435 loss_att 398.389252 loss_ctc 22.600204 loss_rnnt 14.609350 lr 0.00024750 rank 1
2022-12-08 10:14:50,827 DEBUG TRAIN Batch 29/8100 loss 6.160718 loss_att 363.048340 loss_ctc 12.146530 loss_rnnt 5.495628 lr 0.00024743 rank 4
2022-12-08 10:14:50,828 DEBUG TRAIN Batch 29/8100 loss 11.834592 loss_att 359.934174 loss_ctc 24.590462 loss_rnnt 10.417273 lr 0.00024746 rank 5
2022-12-08 10:14:50,834 DEBUG TRAIN Batch 29/8100 loss 7.254933 loss_att 421.937958 loss_ctc 16.516560 loss_rnnt 6.225864 lr 0.00024747 rank 1
2022-12-08 10:14:50,836 DEBUG TRAIN Batch 29/8100 loss 6.316232 loss_att 359.433807 loss_ctc 9.722836 loss_rnnt 5.937721 lr 0.00024743 rank 7
2022-12-08 10:14:50,836 DEBUG TRAIN Batch 29/8100 loss 15.026824 loss_att 367.747742 loss_ctc 24.497955 loss_rnnt 13.974476 lr 0.00024746 rank 2
2022-12-08 10:14:50,840 DEBUG TRAIN Batch 29/8100 loss 9.608421 loss_att 305.174347 loss_ctc 13.708366 loss_rnnt 9.152872 lr 0.00024743 rank 0
2022-12-08 10:14:50,863 DEBUG TRAIN Batch 29/8100 loss 10.379390 loss_att 287.284943 loss_ctc 22.647398 loss_rnnt 9.016278 lr 0.00024747 rank 6
2022-12-08 10:14:50,866 DEBUG TRAIN Batch 29/8100 loss 6.834062 loss_att 343.934814 loss_ctc 11.220770 loss_rnnt 6.346650 lr 0.00024745 rank 3
2022-12-08 10:15:55,229 DEBUG TRAIN Batch 29/8200 loss 3.276735 loss_att 348.606293 loss_ctc 10.715065 loss_rnnt 2.450254 lr 0.00024740 rank 4
2022-12-08 10:15:55,231 DEBUG TRAIN Batch 29/8200 loss 4.350590 loss_att 213.490723 loss_ctc 7.881518 loss_rnnt 3.958265 lr 0.00024742 rank 3
2022-12-08 10:15:55,231 DEBUG TRAIN Batch 29/8200 loss 9.166843 loss_att 306.447418 loss_ctc 20.263618 loss_rnnt 7.933868 lr 0.00024740 rank 7
2022-12-08 10:15:55,234 DEBUG TRAIN Batch 29/8200 loss 5.108717 loss_att 286.267487 loss_ctc 15.958241 loss_rnnt 3.903214 lr 0.00024740 rank 0
2022-12-08 10:15:55,235 DEBUG TRAIN Batch 29/8200 loss 9.877289 loss_att 116.625626 loss_ctc 18.585144 loss_rnnt 8.909749 lr 0.00024744 rank 6
2022-12-08 10:15:55,236 DEBUG TRAIN Batch 29/8200 loss 9.365803 loss_att 209.581879 loss_ctc 19.399607 loss_rnnt 8.250936 lr 0.00024743 rank 5
2022-12-08 10:15:55,238 DEBUG TRAIN Batch 29/8200 loss 4.908191 loss_att 379.335388 loss_ctc 17.810757 loss_rnnt 3.474572 lr 0.00024744 rank 1
2022-12-08 10:15:55,242 DEBUG TRAIN Batch 29/8200 loss 6.953367 loss_att 291.740784 loss_ctc 13.766693 loss_rnnt 6.196331 lr 0.00024743 rank 2
2022-12-08 10:16:58,407 DEBUG TRAIN Batch 29/8300 loss 5.915850 loss_att 346.568329 loss_ctc 11.074450 loss_rnnt 5.342672 lr 0.00024741 rank 6
2022-12-08 10:16:58,408 DEBUG TRAIN Batch 29/8300 loss 4.822624 loss_att 406.861572 loss_ctc 9.687827 loss_rnnt 4.282046 lr 0.00024737 rank 0
2022-12-08 10:16:58,409 DEBUG TRAIN Batch 29/8300 loss 13.830348 loss_att 108.323792 loss_ctc 18.625656 loss_rnnt 13.297536 lr 0.00024737 rank 7
2022-12-08 10:16:58,410 DEBUG TRAIN Batch 29/8300 loss 7.502552 loss_att 371.302582 loss_ctc 17.120869 loss_rnnt 6.433851 lr 0.00024739 rank 3
2022-12-08 10:16:58,412 DEBUG TRAIN Batch 29/8300 loss 7.800125 loss_att 383.449677 loss_ctc 11.713000 loss_rnnt 7.365362 lr 0.00024740 rank 2
2022-12-08 10:16:58,413 DEBUG TRAIN Batch 29/8300 loss 15.475563 loss_att 323.107697 loss_ctc 25.367598 loss_rnnt 14.376448 lr 0.00024737 rank 4
2022-12-08 10:16:58,419 DEBUG TRAIN Batch 29/8300 loss 3.911515 loss_att 386.276459 loss_ctc 10.255584 loss_rnnt 3.206618 lr 0.00024740 rank 5
2022-12-08 10:16:58,430 DEBUG TRAIN Batch 29/8300 loss 5.585983 loss_att 355.606323 loss_ctc 11.382008 loss_rnnt 4.941981 lr 0.00024741 rank 1
2022-12-08 10:17:41,154 DEBUG CV Batch 29/0 loss 1.321397 loss_att 48.086594 loss_ctc 2.644385 loss_rnnt 1.174398 history loss 1.272456 rank 7
2022-12-08 10:17:41,156 DEBUG CV Batch 29/0 loss 1.321397 loss_att 48.086594 loss_ctc 2.644385 loss_rnnt 1.174398 history loss 1.272456 rank 6
2022-12-08 10:17:41,157 DEBUG CV Batch 29/0 loss 1.321397 loss_att 48.086594 loss_ctc 2.644385 loss_rnnt 1.174398 history loss 1.272456 rank 3
2022-12-08 10:17:41,157 DEBUG CV Batch 29/0 loss 1.321397 loss_att 48.086594 loss_ctc 2.644385 loss_rnnt 1.174398 history loss 1.272456 rank 2
2022-12-08 10:17:41,159 DEBUG CV Batch 29/0 loss 1.321397 loss_att 48.086594 loss_ctc 2.644385 loss_rnnt 1.174398 history loss 1.272456 rank 1
2022-12-08 10:17:41,166 DEBUG CV Batch 29/0 loss 1.321397 loss_att 48.086594 loss_ctc 2.644385 loss_rnnt 1.174398 history loss 1.272456 rank 0
2022-12-08 10:17:41,174 DEBUG CV Batch 29/0 loss 1.321397 loss_att 48.086594 loss_ctc 2.644385 loss_rnnt 1.174398 history loss 1.272456 rank 4
2022-12-08 10:17:41,183 DEBUG CV Batch 29/0 loss 1.321397 loss_att 48.086594 loss_ctc 2.644385 loss_rnnt 1.174398 history loss 1.272456 rank 5
2022-12-08 10:17:51,722 DEBUG CV Batch 29/100 loss 3.640876 loss_att 266.943207 loss_ctc 10.775828 loss_rnnt 2.848104 history loss 2.923633 rank 3
2022-12-08 10:17:51,795 DEBUG CV Batch 29/100 loss 3.640876 loss_att 266.943207 loss_ctc 10.775828 loss_rnnt 2.848104 history loss 2.923633 rank 6
2022-12-08 10:17:51,873 DEBUG CV Batch 29/100 loss 3.640876 loss_att 266.943207 loss_ctc 10.775828 loss_rnnt 2.848104 history loss 2.923633 rank 2
2022-12-08 10:17:51,912 DEBUG CV Batch 29/100 loss 3.640876 loss_att 266.943207 loss_ctc 10.775828 loss_rnnt 2.848104 history loss 2.923633 rank 4
2022-12-08 10:17:51,982 DEBUG CV Batch 29/100 loss 3.640876 loss_att 266.943207 loss_ctc 10.775828 loss_rnnt 2.848104 history loss 2.923633 rank 1
2022-12-08 10:17:52,095 DEBUG CV Batch 29/100 loss 3.640876 loss_att 266.943207 loss_ctc 10.775828 loss_rnnt 2.848104 history loss 2.923633 rank 5
2022-12-08 10:17:52,133 DEBUG CV Batch 29/100 loss 3.640876 loss_att 266.943207 loss_ctc 10.775828 loss_rnnt 2.848104 history loss 2.923633 rank 7
2022-12-08 10:17:52,217 DEBUG CV Batch 29/100 loss 3.640876 loss_att 266.943207 loss_ctc 10.775828 loss_rnnt 2.848104 history loss 2.923633 rank 0
2022-12-08 10:18:05,315 DEBUG CV Batch 29/200 loss 2.762127 loss_att 641.185181 loss_ctc 3.659544 loss_rnnt 2.662415 history loss 3.488055 rank 1
2022-12-08 10:18:05,330 DEBUG CV Batch 29/200 loss 2.762127 loss_att 641.185181 loss_ctc 3.659544 loss_rnnt 2.662415 history loss 3.488055 rank 3
2022-12-08 10:18:05,406 DEBUG CV Batch 29/200 loss 2.762127 loss_att 641.185181 loss_ctc 3.659544 loss_rnnt 2.662415 history loss 3.488055 rank 6
2022-12-08 10:18:05,432 DEBUG CV Batch 29/200 loss 2.762127 loss_att 641.185181 loss_ctc 3.659544 loss_rnnt 2.662415 history loss 3.488055 rank 4
2022-12-08 10:18:05,554 DEBUG CV Batch 29/200 loss 2.762127 loss_att 641.185181 loss_ctc 3.659544 loss_rnnt 2.662415 history loss 3.488055 rank 2
2022-12-08 10:18:05,934 DEBUG CV Batch 29/200 loss 2.762127 loss_att 641.185181 loss_ctc 3.659544 loss_rnnt 2.662415 history loss 3.488055 rank 7
2022-12-08 10:18:06,103 DEBUG CV Batch 29/200 loss 2.762127 loss_att 641.185181 loss_ctc 3.659544 loss_rnnt 2.662415 history loss 3.488055 rank 5
2022-12-08 10:18:06,687 DEBUG CV Batch 29/200 loss 2.762127 loss_att 641.185181 loss_ctc 3.659544 loss_rnnt 2.662415 history loss 3.488055 rank 0
2022-12-08 10:18:16,525 DEBUG CV Batch 29/300 loss 3.110352 loss_att 190.887604 loss_ctc 6.345486 loss_rnnt 2.750892 history loss 3.641574 rank 1
2022-12-08 10:18:16,604 DEBUG CV Batch 29/300 loss 3.110352 loss_att 190.887604 loss_ctc 6.345486 loss_rnnt 2.750892 history loss 3.641574 rank 3
2022-12-08 10:18:16,850 DEBUG CV Batch 29/300 loss 3.110352 loss_att 190.887604 loss_ctc 6.345486 loss_rnnt 2.750892 history loss 3.641574 rank 2
2022-12-08 10:18:16,856 DEBUG CV Batch 29/300 loss 3.110352 loss_att 190.887604 loss_ctc 6.345486 loss_rnnt 2.750892 history loss 3.641574 rank 4
2022-12-08 10:18:16,871 DEBUG CV Batch 29/300 loss 3.110352 loss_att 190.887604 loss_ctc 6.345486 loss_rnnt 2.750892 history loss 3.641574 rank 6
2022-12-08 10:18:17,359 DEBUG CV Batch 29/300 loss 3.110352 loss_att 190.887604 loss_ctc 6.345486 loss_rnnt 2.750892 history loss 3.641574 rank 5
2022-12-08 10:18:17,543 DEBUG CV Batch 29/300 loss 3.110352 loss_att 190.887604 loss_ctc 6.345486 loss_rnnt 2.750892 history loss 3.641574 rank 7
2022-12-08 10:18:18,509 DEBUG CV Batch 29/300 loss 3.110352 loss_att 190.887604 loss_ctc 6.345486 loss_rnnt 2.750892 history loss 3.641574 rank 0
2022-12-08 10:18:27,754 DEBUG CV Batch 29/400 loss 2.867921 loss_att 826.186523 loss_ctc 9.142393 loss_rnnt 2.170757 history loss 4.464124 rank 1
2022-12-08 10:18:28,129 DEBUG CV Batch 29/400 loss 2.867921 loss_att 826.186523 loss_ctc 9.142393 loss_rnnt 2.170757 history loss 4.464124 rank 6
2022-12-08 10:18:28,221 DEBUG CV Batch 29/400 loss 2.867921 loss_att 826.186523 loss_ctc 9.142393 loss_rnnt 2.170757 history loss 4.464124 rank 4
2022-12-08 10:18:28,234 DEBUG CV Batch 29/400 loss 2.867921 loss_att 826.186523 loss_ctc 9.142393 loss_rnnt 2.170757 history loss 4.464124 rank 2
2022-12-08 10:18:28,292 DEBUG CV Batch 29/400 loss 2.867921 loss_att 826.186523 loss_ctc 9.142393 loss_rnnt 2.170757 history loss 4.464124 rank 3
2022-12-08 10:18:28,837 DEBUG CV Batch 29/400 loss 2.867921 loss_att 826.186523 loss_ctc 9.142393 loss_rnnt 2.170757 history loss 4.464124 rank 5
2022-12-08 10:18:29,088 DEBUG CV Batch 29/400 loss 2.867921 loss_att 826.186523 loss_ctc 9.142393 loss_rnnt 2.170757 history loss 4.464124 rank 7
2022-12-08 10:18:30,185 DEBUG CV Batch 29/400 loss 2.867921 loss_att 826.186523 loss_ctc 9.142393 loss_rnnt 2.170757 history loss 4.464124 rank 0
2022-12-08 10:18:37,774 DEBUG CV Batch 29/500 loss 5.692353 loss_att 266.654510 loss_ctc 7.531547 loss_rnnt 5.487998 history loss 5.111246 rank 1
2022-12-08 10:18:38,009 DEBUG CV Batch 29/500 loss 5.692353 loss_att 266.654510 loss_ctc 7.531547 loss_rnnt 5.487998 history loss 5.111246 rank 6
2022-12-08 10:18:38,110 DEBUG CV Batch 29/500 loss 5.692353 loss_att 266.654510 loss_ctc 7.531547 loss_rnnt 5.487998 history loss 5.111246 rank 2
2022-12-08 10:18:38,194 DEBUG CV Batch 29/500 loss 5.692353 loss_att 266.654510 loss_ctc 7.531547 loss_rnnt 5.487998 history loss 5.111246 rank 4
2022-12-08 10:18:38,304 DEBUG CV Batch 29/500 loss 5.692353 loss_att 266.654510 loss_ctc 7.531547 loss_rnnt 5.487998 history loss 5.111246 rank 3
2022-12-08 10:18:38,980 DEBUG CV Batch 29/500 loss 5.692353 loss_att 266.654510 loss_ctc 7.531547 loss_rnnt 5.487998 history loss 5.111246 rank 5
2022-12-08 10:18:39,469 DEBUG CV Batch 29/500 loss 5.692353 loss_att 266.654510 loss_ctc 7.531547 loss_rnnt 5.487998 history loss 5.111246 rank 7
2022-12-08 10:18:40,645 DEBUG CV Batch 29/500 loss 5.692353 loss_att 266.654510 loss_ctc 7.531547 loss_rnnt 5.487998 history loss 5.111246 rank 0
2022-12-08 10:18:49,708 DEBUG CV Batch 29/600 loss 6.843089 loss_att 104.308464 loss_ctc 10.133002 loss_rnnt 6.477543 history loss 5.933911 rank 4
2022-12-08 10:18:49,894 DEBUG CV Batch 29/600 loss 6.843089 loss_att 104.308464 loss_ctc 10.133002 loss_rnnt 6.477543 history loss 5.933911 rank 2
2022-12-08 10:18:49,895 DEBUG CV Batch 29/600 loss 6.843089 loss_att 104.308464 loss_ctc 10.133002 loss_rnnt 6.477543 history loss 5.933911 rank 1
2022-12-08 10:18:50,060 DEBUG CV Batch 29/600 loss 6.843089 loss_att 104.308464 loss_ctc 10.133002 loss_rnnt 6.477543 history loss 5.933911 rank 3
2022-12-08 10:18:50,140 DEBUG CV Batch 29/600 loss 6.843089 loss_att 104.308464 loss_ctc 10.133002 loss_rnnt 6.477543 history loss 5.933911 rank 6
2022-12-08 10:18:51,503 DEBUG CV Batch 29/600 loss 6.843089 loss_att 104.308464 loss_ctc 10.133002 loss_rnnt 6.477543 history loss 5.933911 rank 5
2022-12-08 10:18:52,132 DEBUG CV Batch 29/600 loss 6.843089 loss_att 104.308464 loss_ctc 10.133002 loss_rnnt 6.477543 history loss 5.933911 rank 7
2022-12-08 10:18:53,050 DEBUG CV Batch 29/600 loss 6.843089 loss_att 104.308464 loss_ctc 10.133002 loss_rnnt 6.477543 history loss 5.933911 rank 0
2022-12-08 10:19:01,352 DEBUG CV Batch 29/700 loss 7.481472 loss_att 707.027344 loss_ctc 19.786718 loss_rnnt 6.114223 history loss 6.486890 rank 4
2022-12-08 10:19:01,521 DEBUG CV Batch 29/700 loss 7.481472 loss_att 707.027344 loss_ctc 19.786718 loss_rnnt 6.114223 history loss 6.486890 rank 3
2022-12-08 10:19:01,526 DEBUG CV Batch 29/700 loss 7.481472 loss_att 707.027344 loss_ctc 19.786718 loss_rnnt 6.114223 history loss 6.486890 rank 1
2022-12-08 10:19:01,801 DEBUG CV Batch 29/700 loss 7.481472 loss_att 707.027344 loss_ctc 19.786718 loss_rnnt 6.114223 history loss 6.486890 rank 2
2022-12-08 10:19:01,959 DEBUG CV Batch 29/700 loss 7.481472 loss_att 707.027344 loss_ctc 19.786718 loss_rnnt 6.114223 history loss 6.486890 rank 6
2022-12-08 10:19:03,909 DEBUG CV Batch 29/700 loss 7.481472 loss_att 707.027344 loss_ctc 19.786718 loss_rnnt 6.114223 history loss 6.486890 rank 5
2022-12-08 10:19:05,231 DEBUG CV Batch 29/700 loss 7.481472 loss_att 707.027344 loss_ctc 19.786718 loss_rnnt 6.114223 history loss 6.486890 rank 7
2022-12-08 10:19:05,535 DEBUG CV Batch 29/700 loss 7.481472 loss_att 707.027344 loss_ctc 19.786718 loss_rnnt 6.114223 history loss 6.486890 rank 0
2022-12-08 10:19:12,785 DEBUG CV Batch 29/800 loss 5.927006 loss_att 263.402588 loss_ctc 15.037586 loss_rnnt 4.914719 history loss 6.014451 rank 4
2022-12-08 10:19:13,178 DEBUG CV Batch 29/800 loss 5.927006 loss_att 263.402588 loss_ctc 15.037586 loss_rnnt 4.914719 history loss 6.014451 rank 1
2022-12-08 10:19:13,218 DEBUG CV Batch 29/800 loss 5.927006 loss_att 263.402588 loss_ctc 15.037586 loss_rnnt 4.914719 history loss 6.014451 rank 3
2022-12-08 10:19:13,265 DEBUG CV Batch 29/800 loss 5.927006 loss_att 263.402588 loss_ctc 15.037586 loss_rnnt 4.914719 history loss 6.014451 rank 2
2022-12-08 10:19:13,646 DEBUG CV Batch 29/800 loss 5.927006 loss_att 263.402588 loss_ctc 15.037586 loss_rnnt 4.914719 history loss 6.014451 rank 6
2022-12-08 10:19:16,191 DEBUG CV Batch 29/800 loss 5.927006 loss_att 263.402588 loss_ctc 15.037586 loss_rnnt 4.914719 history loss 6.014451 rank 5
2022-12-08 10:19:17,714 DEBUG CV Batch 29/800 loss 5.927006 loss_att 263.402588 loss_ctc 15.037586 loss_rnnt 4.914719 history loss 6.014451 rank 7
2022-12-08 10:19:18,118 DEBUG CV Batch 29/800 loss 5.927006 loss_att 263.402588 loss_ctc 15.037586 loss_rnnt 4.914719 history loss 6.014451 rank 0
2022-12-08 10:19:26,151 DEBUG CV Batch 29/900 loss 14.875845 loss_att 550.848145 loss_ctc 20.883350 loss_rnnt 14.208344 history loss 5.846533 rank 4
2022-12-08 10:19:26,561 DEBUG CV Batch 29/900 loss 14.875845 loss_att 550.848145 loss_ctc 20.883350 loss_rnnt 14.208344 history loss 5.846533 rank 1
2022-12-08 10:19:26,715 DEBUG CV Batch 29/900 loss 14.875845 loss_att 550.848145 loss_ctc 20.883350 loss_rnnt 14.208344 history loss 5.846533 rank 6
2022-12-08 10:19:26,767 DEBUG CV Batch 29/900 loss 14.875845 loss_att 550.848145 loss_ctc 20.883350 loss_rnnt 14.208344 history loss 5.846533 rank 2
2022-12-08 10:19:27,163 DEBUG CV Batch 29/900 loss 14.875845 loss_att 550.848145 loss_ctc 20.883350 loss_rnnt 14.208344 history loss 5.846533 rank 3
2022-12-08 10:19:30,015 DEBUG CV Batch 29/900 loss 14.875845 loss_att 550.848145 loss_ctc 20.883350 loss_rnnt 14.208344 history loss 5.846533 rank 5
2022-12-08 10:19:31,559 DEBUG CV Batch 29/900 loss 14.875845 loss_att 550.848145 loss_ctc 20.883350 loss_rnnt 14.208344 history loss 5.846533 rank 7
2022-12-08 10:19:31,922 DEBUG CV Batch 29/900 loss 14.875845 loss_att 550.848145 loss_ctc 20.883350 loss_rnnt 14.208344 history loss 5.846533 rank 0
2022-12-08 10:19:37,794 DEBUG CV Batch 29/1000 loss 2.707283 loss_att 176.486786 loss_ctc 5.210385 loss_rnnt 2.429161 history loss 5.651937 rank 4
2022-12-08 10:19:38,070 DEBUG CV Batch 29/1000 loss 2.707283 loss_att 176.486786 loss_ctc 5.210385 loss_rnnt 2.429161 history loss 5.651937 rank 1
2022-12-08 10:19:38,336 DEBUG CV Batch 29/1000 loss 2.707283 loss_att 176.486786 loss_ctc 5.210385 loss_rnnt 2.429161 history loss 5.651937 rank 2
2022-12-08 10:19:38,432 DEBUG CV Batch 29/1000 loss 2.707283 loss_att 176.486786 loss_ctc 5.210385 loss_rnnt 2.429161 history loss 5.651937 rank 6
2022-12-08 10:19:38,887 DEBUG CV Batch 29/1000 loss 2.707283 loss_att 176.486786 loss_ctc 5.210385 loss_rnnt 2.429161 history loss 5.651937 rank 3
2022-12-08 10:19:41,764 DEBUG CV Batch 29/1000 loss 2.707283 loss_att 176.486786 loss_ctc 5.210385 loss_rnnt 2.429161 history loss 5.651937 rank 5
2022-12-08 10:19:43,320 DEBUG CV Batch 29/1000 loss 2.707283 loss_att 176.486786 loss_ctc 5.210385 loss_rnnt 2.429161 history loss 5.651937 rank 7
2022-12-08 10:19:43,781 DEBUG CV Batch 29/1000 loss 2.707283 loss_att 176.486786 loss_ctc 5.210385 loss_rnnt 2.429161 history loss 5.651937 rank 0
2022-12-08 10:19:49,058 DEBUG CV Batch 29/1100 loss 5.142407 loss_att 60.694237 loss_ctc 8.342906 loss_rnnt 4.786796 history loss 5.627645 rank 4
2022-12-08 10:19:49,206 DEBUG CV Batch 29/1100 loss 5.142407 loss_att 60.694237 loss_ctc 8.342906 loss_rnnt 4.786796 history loss 5.627645 rank 1
2022-12-08 10:19:49,571 DEBUG CV Batch 29/1100 loss 5.142407 loss_att 60.694237 loss_ctc 8.342906 loss_rnnt 4.786796 history loss 5.627645 rank 6
2022-12-08 10:19:49,723 DEBUG CV Batch 29/1100 loss 5.142407 loss_att 60.694237 loss_ctc 8.342906 loss_rnnt 4.786796 history loss 5.627645 rank 2
2022-12-08 10:19:50,211 DEBUG CV Batch 29/1100 loss 5.142407 loss_att 60.694237 loss_ctc 8.342906 loss_rnnt 4.786796 history loss 5.627645 rank 3
2022-12-08 10:19:53,142 DEBUG CV Batch 29/1100 loss 5.142407 loss_att 60.694237 loss_ctc 8.342906 loss_rnnt 4.786796 history loss 5.627645 rank 5
2022-12-08 10:19:54,834 DEBUG CV Batch 29/1100 loss 5.142407 loss_att 60.694237 loss_ctc 8.342906 loss_rnnt 4.786796 history loss 5.627645 rank 7
2022-12-08 10:19:55,386 DEBUG CV Batch 29/1100 loss 5.142407 loss_att 60.694237 loss_ctc 8.342906 loss_rnnt 4.786796 history loss 5.627645 rank 0
2022-12-08 10:19:58,942 DEBUG CV Batch 29/1200 loss 7.093834 loss_att 280.458740 loss_ctc 9.997446 loss_rnnt 6.771211 history loss 5.913789 rank 4
2022-12-08 10:19:59,257 DEBUG CV Batch 29/1200 loss 7.093834 loss_att 280.458740 loss_ctc 9.997446 loss_rnnt 6.771211 history loss 5.913789 rank 1
2022-12-08 10:19:59,499 DEBUG CV Batch 29/1200 loss 7.093834 loss_att 280.458740 loss_ctc 9.997446 loss_rnnt 6.771211 history loss 5.913789 rank 6
2022-12-08 10:20:00,103 DEBUG CV Batch 29/1200 loss 7.093834 loss_att 280.458740 loss_ctc 9.997446 loss_rnnt 6.771211 history loss 5.913789 rank 2
2022-12-08 10:20:00,123 DEBUG CV Batch 29/1200 loss 7.093834 loss_att 280.458740 loss_ctc 9.997446 loss_rnnt 6.771211 history loss 5.913789 rank 3
2022-12-08 10:20:04,255 DEBUG CV Batch 29/1200 loss 7.093834 loss_att 280.458740 loss_ctc 9.997446 loss_rnnt 6.771211 history loss 5.913789 rank 5
2022-12-08 10:20:05,314 DEBUG CV Batch 29/1200 loss 7.093834 loss_att 280.458740 loss_ctc 9.997446 loss_rnnt 6.771211 history loss 5.913789 rank 7
2022-12-08 10:20:05,801 DEBUG CV Batch 29/1200 loss 7.093834 loss_att 280.458740 loss_ctc 9.997446 loss_rnnt 6.771211 history loss 5.913789 rank 0
2022-12-08 10:20:10,352 DEBUG CV Batch 29/1300 loss 4.995070 loss_att 105.975601 loss_ctc 7.913646 loss_rnnt 4.670783 history loss 6.183629 rank 4
2022-12-08 10:20:10,691 DEBUG CV Batch 29/1300 loss 4.995070 loss_att 105.975601 loss_ctc 7.913646 loss_rnnt 4.670783 history loss 6.183629 rank 1
2022-12-08 10:20:10,993 DEBUG CV Batch 29/1300 loss 4.995070 loss_att 105.975601 loss_ctc 7.913646 loss_rnnt 4.670783 history loss 6.183629 rank 6
2022-12-08 10:20:11,658 DEBUG CV Batch 29/1300 loss 4.995070 loss_att 105.975601 loss_ctc 7.913646 loss_rnnt 4.670783 history loss 6.183629 rank 3
2022-12-08 10:20:11,709 DEBUG CV Batch 29/1300 loss 4.995070 loss_att 105.975601 loss_ctc 7.913646 loss_rnnt 4.670783 history loss 6.183629 rank 2
2022-12-08 10:20:16,127 DEBUG CV Batch 29/1300 loss 4.995070 loss_att 105.975601 loss_ctc 7.913646 loss_rnnt 4.670783 history loss 6.183629 rank 5
2022-12-08 10:20:17,390 DEBUG CV Batch 29/1300 loss 4.995070 loss_att 105.975601 loss_ctc 7.913646 loss_rnnt 4.670783 history loss 6.183629 rank 7
2022-12-08 10:20:18,034 DEBUG CV Batch 29/1300 loss 4.995070 loss_att 105.975601 loss_ctc 7.913646 loss_rnnt 4.670783 history loss 6.183629 rank 0
2022-12-08 10:20:21,426 DEBUG CV Batch 29/1400 loss 3.135796 loss_att 562.090698 loss_ctc 5.638574 loss_rnnt 2.857710 history loss 6.459753 rank 4
2022-12-08 10:20:22,261 DEBUG CV Batch 29/1400 loss 3.135796 loss_att 562.090698 loss_ctc 5.638574 loss_rnnt 2.857710 history loss 6.459753 rank 3
2022-12-08 10:20:22,435 DEBUG CV Batch 29/1400 loss 3.135796 loss_att 562.090698 loss_ctc 5.638574 loss_rnnt 2.857710 history loss 6.459753 rank 6
2022-12-08 10:20:22,464 DEBUG CV Batch 29/1400 loss 3.135796 loss_att 562.090698 loss_ctc 5.638574 loss_rnnt 2.857710 history loss 6.459753 rank 1
2022-12-08 10:20:22,797 DEBUG CV Batch 29/1400 loss 3.135796 loss_att 562.090698 loss_ctc 5.638574 loss_rnnt 2.857710 history loss 6.459753 rank 2
2022-12-08 10:20:28,712 DEBUG CV Batch 29/1400 loss 3.135796 loss_att 562.090698 loss_ctc 5.638574 loss_rnnt 2.857710 history loss 6.459753 rank 5
2022-12-08 10:20:30,106 DEBUG CV Batch 29/1400 loss 3.135796 loss_att 562.090698 loss_ctc 5.638574 loss_rnnt 2.857710 history loss 6.459753 rank 7
2022-12-08 10:20:30,668 DEBUG CV Batch 29/1400 loss 3.135796 loss_att 562.090698 loss_ctc 5.638574 loss_rnnt 2.857710 history loss 6.459753 rank 0
2022-12-08 10:20:33,731 DEBUG CV Batch 29/1500 loss 7.469747 loss_att 275.485229 loss_ctc 8.760604 loss_rnnt 7.326318 history loss 6.332509 rank 4
2022-12-08 10:20:34,236 DEBUG CV Batch 29/1500 loss 7.469747 loss_att 275.485229 loss_ctc 8.760604 loss_rnnt 7.326318 history loss 6.332509 rank 3
2022-12-08 10:20:34,645 DEBUG CV Batch 29/1500 loss 7.469747 loss_att 275.485229 loss_ctc 8.760604 loss_rnnt 7.326318 history loss 6.332509 rank 6
2022-12-08 10:20:34,748 DEBUG CV Batch 29/1500 loss 7.469747 loss_att 275.485229 loss_ctc 8.760604 loss_rnnt 7.326318 history loss 6.332509 rank 1
2022-12-08 10:20:34,930 DEBUG CV Batch 29/1500 loss 7.469747 loss_att 275.485229 loss_ctc 8.760604 loss_rnnt 7.326318 history loss 6.332509 rank 2
2022-12-08 10:20:41,727 DEBUG CV Batch 29/1500 loss 7.469747 loss_att 275.485229 loss_ctc 8.760604 loss_rnnt 7.326318 history loss 6.332509 rank 5
2022-12-08 10:20:42,935 DEBUG CV Batch 29/1500 loss 7.469747 loss_att 275.485229 loss_ctc 8.760604 loss_rnnt 7.326318 history loss 6.332509 rank 7
2022-12-08 10:20:43,353 DEBUG CV Batch 29/1500 loss 7.469747 loss_att 275.485229 loss_ctc 8.760604 loss_rnnt 7.326318 history loss 6.332509 rank 0
2022-12-08 10:20:46,928 DEBUG CV Batch 29/1600 loss 9.499155 loss_att 593.911072 loss_ctc 14.102346 loss_rnnt 8.987690 history loss 6.285430 rank 4
2022-12-08 10:20:47,449 DEBUG CV Batch 29/1600 loss 9.499155 loss_att 593.911072 loss_ctc 14.102346 loss_rnnt 8.987690 history loss 6.285430 rank 3
2022-12-08 10:20:47,695 DEBUG CV Batch 29/1600 loss 9.499155 loss_att 593.911072 loss_ctc 14.102346 loss_rnnt 8.987690 history loss 6.285430 rank 1
2022-12-08 10:20:47,973 DEBUG CV Batch 29/1600 loss 9.499155 loss_att 593.911072 loss_ctc 14.102346 loss_rnnt 8.987690 history loss 6.285430 rank 6
2022-12-08 10:20:48,228 DEBUG CV Batch 29/1600 loss 9.499155 loss_att 593.911072 loss_ctc 14.102346 loss_rnnt 8.987690 history loss 6.285430 rank 2
2022-12-08 10:20:54,833 DEBUG CV Batch 29/1600 loss 9.499155 loss_att 593.911072 loss_ctc 14.102346 loss_rnnt 8.987690 history loss 6.285430 rank 5
2022-12-08 10:20:56,473 DEBUG CV Batch 29/1600 loss 9.499155 loss_att 593.911072 loss_ctc 14.102346 loss_rnnt 8.987690 history loss 6.285430 rank 7
2022-12-08 10:20:57,068 DEBUG CV Batch 29/1600 loss 9.499155 loss_att 593.911072 loss_ctc 14.102346 loss_rnnt 8.987690 history loss 6.285430 rank 0
2022-12-08 10:20:58,827 DEBUG CV Batch 29/1700 loss 6.927086 loss_att 210.845230 loss_ctc 15.722977 loss_rnnt 5.949766 history loss 6.223924 rank 4
2022-12-08 10:20:59,358 DEBUG CV Batch 29/1700 loss 6.927086 loss_att 210.845230 loss_ctc 15.722977 loss_rnnt 5.949766 history loss 6.223924 rank 1
2022-12-08 10:20:59,735 DEBUG CV Batch 29/1700 loss 6.927086 loss_att 210.845230 loss_ctc 15.722977 loss_rnnt 5.949766 history loss 6.223924 rank 6
2022-12-08 10:20:59,891 DEBUG CV Batch 29/1700 loss 6.927086 loss_att 210.845230 loss_ctc 15.722977 loss_rnnt 5.949766 history loss 6.223924 rank 3
2022-12-08 10:21:00,330 DEBUG CV Batch 29/1700 loss 6.927086 loss_att 210.845230 loss_ctc 15.722977 loss_rnnt 5.949766 history loss 6.223924 rank 2
2022-12-08 10:21:06,625 DEBUG CV Batch 29/1700 loss 6.927086 loss_att 210.845230 loss_ctc 15.722977 loss_rnnt 5.949766 history loss 6.223924 rank 5
2022-12-08 10:21:07,596 INFO Epoch 29 CV info cv_loss 6.201489309332743
2022-12-08 10:21:07,597 INFO Epoch 30 TRAIN info lr 0.00024736687943415186
2022-12-08 10:21:07,601 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 10:21:08,212 DEBUG CV Batch 29/1700 loss 6.927086 loss_att 210.845230 loss_ctc 15.722977 loss_rnnt 5.949766 history loss 6.223924 rank 7
2022-12-08 10:21:08,324 INFO Epoch 29 CV info cv_loss 6.201489309332743
2022-12-08 10:21:08,325 INFO Epoch 30 TRAIN info lr 0.0002474077580384104
2022-12-08 10:21:08,329 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 10:21:08,834 INFO Epoch 29 CV info cv_loss 6.201489309332743
2022-12-08 10:21:08,834 INFO Epoch 30 TRAIN info lr 0.00024739473524648117
2022-12-08 10:21:08,839 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 10:21:08,927 DEBUG CV Batch 29/1700 loss 6.927086 loss_att 210.845230 loss_ctc 15.722977 loss_rnnt 5.949766 history loss 6.223924 rank 0
2022-12-08 10:21:09,199 INFO Epoch 29 CV info cv_loss 6.201489309332743
2022-12-08 10:21:09,199 INFO Epoch 30 TRAIN info lr 0.00024737414526064706
2022-12-08 10:21:09,204 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 10:21:09,606 INFO Epoch 29 CV info cv_loss 6.201489309332743
2022-12-08 10:21:09,607 INFO Epoch 30 TRAIN info lr 0.0002473856507954462
2022-12-08 10:21:09,611 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 10:21:15,516 INFO Epoch 29 CV info cv_loss 6.201489309332743
2022-12-08 10:21:15,516 INFO Epoch 30 TRAIN info lr 0.00024738080616407387
2022-12-08 10:21:15,520 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 10:21:17,163 INFO Epoch 29 CV info cv_loss 6.201489309332743
2022-12-08 10:21:17,163 INFO Epoch 30 TRAIN info lr 0.0002473620359054907
2022-12-08 10:21:17,165 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 10:21:18,078 INFO Epoch 29 CV info cv_loss 6.201489309332743
2022-12-08 10:21:18,078 INFO Checkpoint: save to checkpoint exp/1204_encoder_bias_nobi_noatt/29.pt
2022-12-08 10:21:18,823 INFO Epoch 30 TRAIN info lr 0.0002473550738314687
2022-12-08 10:21:18,826 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 10:22:18,830 DEBUG TRAIN Batch 30/0 loss 6.123370 loss_att 73.004166 loss_ctc 9.484656 loss_rnnt 5.749893 lr 0.00024738 rank 5
2022-12-08 10:22:18,831 DEBUG TRAIN Batch 30/0 loss 7.617780 loss_att 74.044029 loss_ctc 11.838363 loss_rnnt 7.148827 lr 0.00024737 rank 4
2022-12-08 10:22:18,832 DEBUG TRAIN Batch 30/0 loss 6.880353 loss_att 72.576202 loss_ctc 10.429320 loss_rnnt 6.486024 lr 0.00024737 rank 3
2022-12-08 10:22:18,833 DEBUG TRAIN Batch 30/0 loss 10.122952 loss_att 78.681274 loss_ctc 15.361032 loss_rnnt 9.540944 lr 0.00024736 rank 7
2022-12-08 10:22:18,833 DEBUG TRAIN Batch 30/0 loss 8.414319 loss_att 70.598984 loss_ctc 14.654192 loss_rnnt 7.721000 lr 0.00024739 rank 2
2022-12-08 10:22:18,836 DEBUG TRAIN Batch 30/0 loss 9.123238 loss_att 67.280006 loss_ctc 11.206386 loss_rnnt 8.891777 lr 0.00024741 rank 1
2022-12-08 10:22:18,839 DEBUG TRAIN Batch 30/0 loss 7.682804 loss_att 65.099693 loss_ctc 10.424560 loss_rnnt 7.378164 lr 0.00024735 rank 0
2022-12-08 10:22:18,874 DEBUG TRAIN Batch 30/0 loss 6.599282 loss_att 71.568153 loss_ctc 9.986936 loss_rnnt 6.222876 lr 0.00024739 rank 6
2022-12-08 10:23:21,541 DEBUG TRAIN Batch 30/100 loss 6.272204 loss_att 361.095917 loss_ctc 9.522774 loss_rnnt 5.911030 lr 0.00024734 rank 4
2022-12-08 10:23:21,547 DEBUG TRAIN Batch 30/100 loss 4.748621 loss_att 361.856079 loss_ctc 11.216560 loss_rnnt 4.029961 lr 0.00024734 rank 3
2022-12-08 10:23:21,549 DEBUG TRAIN Batch 30/100 loss 16.472145 loss_att 397.010986 loss_ctc 26.275585 loss_rnnt 15.382875 lr 0.00024733 rank 7
2022-12-08 10:23:21,550 DEBUG TRAIN Batch 30/100 loss 6.437724 loss_att 455.189636 loss_ctc 15.366977 loss_rnnt 5.445585 lr 0.00024736 rank 6
2022-12-08 10:23:21,550 DEBUG TRAIN Batch 30/100 loss 5.737968 loss_att 397.654999 loss_ctc 10.557579 loss_rnnt 5.202456 lr 0.00024736 rank 2
2022-12-08 10:23:21,551 DEBUG TRAIN Batch 30/100 loss 7.807259 loss_att 363.532074 loss_ctc 17.563488 loss_rnnt 6.723234 lr 0.00024732 rank 0
2022-12-08 10:23:21,552 DEBUG TRAIN Batch 30/100 loss 6.290445 loss_att 396.436951 loss_ctc 9.744434 loss_rnnt 5.906669 lr 0.00024735 rank 5
2022-12-08 10:23:21,594 DEBUG TRAIN Batch 30/100 loss 0.921091 loss_att 368.997192 loss_ctc 2.613422 loss_rnnt 0.733055 lr 0.00024738 rank 1
2022-12-08 10:24:25,020 DEBUG TRAIN Batch 30/200 loss 6.978871 loss_att 331.526947 loss_ctc 11.934935 loss_rnnt 6.428197 lr 0.00024731 rank 4
2022-12-08 10:24:25,025 DEBUG TRAIN Batch 30/200 loss 11.505268 loss_att 375.984497 loss_ctc 20.889906 loss_rnnt 10.462531 lr 0.00024735 rank 1
2022-12-08 10:24:25,025 DEBUG TRAIN Batch 30/200 loss 14.930757 loss_att 421.454926 loss_ctc 35.134941 loss_rnnt 12.685847 lr 0.00024731 rank 3
2022-12-08 10:24:25,030 DEBUG TRAIN Batch 30/200 loss 6.849576 loss_att 396.812103 loss_ctc 19.830936 loss_rnnt 5.407203 lr 0.00024732 rank 2
2022-12-08 10:24:25,033 DEBUG TRAIN Batch 30/200 loss 7.884343 loss_att 443.218384 loss_ctc 19.604521 loss_rnnt 6.582101 lr 0.00024733 rank 6
2022-12-08 10:24:25,048 DEBUG TRAIN Batch 30/200 loss 10.350959 loss_att 399.812866 loss_ctc 23.320509 loss_rnnt 8.909898 lr 0.00024730 rank 7
2022-12-08 10:24:25,062 DEBUG TRAIN Batch 30/200 loss 9.690435 loss_att 351.060394 loss_ctc 19.780968 loss_rnnt 8.569265 lr 0.00024729 rank 0
2022-12-08 10:24:25,067 DEBUG TRAIN Batch 30/200 loss 10.865720 loss_att 414.773041 loss_ctc 27.787649 loss_rnnt 8.985506 lr 0.00024732 rank 5
2022-12-08 10:25:29,257 DEBUG TRAIN Batch 30/300 loss 7.155675 loss_att 355.724518 loss_ctc 14.081426 loss_rnnt 6.386148 lr 0.00024728 rank 3
2022-12-08 10:25:29,266 DEBUG TRAIN Batch 30/300 loss 7.326959 loss_att 378.054382 loss_ctc 15.310324 loss_rnnt 6.439919 lr 0.00024727 rank 7
2022-12-08 10:25:29,267 DEBUG TRAIN Batch 30/300 loss 5.649491 loss_att 360.407837 loss_ctc 10.736221 loss_rnnt 5.084299 lr 0.00024732 rank 1
2022-12-08 10:25:29,268 DEBUG TRAIN Batch 30/300 loss 3.987360 loss_att 393.570801 loss_ctc 10.946427 loss_rnnt 3.214131 lr 0.00024729 rank 2
2022-12-08 10:25:29,271 DEBUG TRAIN Batch 30/300 loss 5.001338 loss_att 316.842804 loss_ctc 12.818829 loss_rnnt 4.132729 lr 0.00024728 rank 4
2022-12-08 10:25:29,274 DEBUG TRAIN Batch 30/300 loss 11.717269 loss_att 377.909180 loss_ctc 20.673771 loss_rnnt 10.722102 lr 0.00024726 rank 0
2022-12-08 10:25:29,282 DEBUG TRAIN Batch 30/300 loss 9.444149 loss_att 374.648285 loss_ctc 15.990053 loss_rnnt 8.716826 lr 0.00024730 rank 6
2022-12-08 10:25:29,290 DEBUG TRAIN Batch 30/300 loss 1.192391 loss_att 336.443848 loss_ctc 5.008858 loss_rnnt 0.768339 lr 0.00024729 rank 5
2022-12-08 10:26:39,098 DEBUG TRAIN Batch 30/400 loss 6.777476 loss_att 362.020142 loss_ctc 15.105434 loss_rnnt 5.852148 lr 0.00024725 rank 3
2022-12-08 10:26:39,100 DEBUG TRAIN Batch 30/400 loss 7.738431 loss_att 363.637360 loss_ctc 19.932676 loss_rnnt 6.383516 lr 0.00024729 rank 1
2022-12-08 10:26:39,102 DEBUG TRAIN Batch 30/400 loss 7.055863 loss_att 376.564331 loss_ctc 17.801582 loss_rnnt 5.861895 lr 0.00024726 rank 2
2022-12-08 10:26:39,103 DEBUG TRAIN Batch 30/400 loss 8.529499 loss_att 391.169983 loss_ctc 15.116585 loss_rnnt 7.797601 lr 0.00024724 rank 7
2022-12-08 10:26:39,105 DEBUG TRAIN Batch 30/400 loss 4.774697 loss_att 372.966431 loss_ctc 11.733063 loss_rnnt 4.001545 lr 0.00024726 rank 5
2022-12-08 10:26:39,106 DEBUG TRAIN Batch 30/400 loss 6.409482 loss_att 348.628510 loss_ctc 16.105167 loss_rnnt 5.332183 lr 0.00024723 rank 0
2022-12-08 10:26:39,110 DEBUG TRAIN Batch 30/400 loss 9.217774 loss_att 364.408905 loss_ctc 15.085555 loss_rnnt 8.565799 lr 0.00024727 rank 6
2022-12-08 10:26:39,116 DEBUG TRAIN Batch 30/400 loss 6.088770 loss_att 392.727295 loss_ctc 10.860779 loss_rnnt 5.558547 lr 0.00024725 rank 4
2022-12-08 10:27:42,941 DEBUG TRAIN Batch 30/500 loss 9.178645 loss_att 309.744934 loss_ctc 18.527151 loss_rnnt 8.139922 lr 0.00024721 rank 7
2022-12-08 10:27:42,944 DEBUG TRAIN Batch 30/500 loss 7.483521 loss_att 315.946625 loss_ctc 9.252243 loss_rnnt 7.286996 lr 0.00024724 rank 6
2022-12-08 10:27:42,944 DEBUG TRAIN Batch 30/500 loss 2.797089 loss_att 309.815552 loss_ctc 5.047471 loss_rnnt 2.547046 lr 0.00024722 rank 4
2022-12-08 10:27:42,945 DEBUG TRAIN Batch 30/500 loss 10.378387 loss_att 408.731628 loss_ctc 32.016975 loss_rnnt 7.974100 lr 0.00024723 rank 2
2022-12-08 10:27:42,945 DEBUG TRAIN Batch 30/500 loss 13.785419 loss_att 324.416077 loss_ctc 23.571884 loss_rnnt 12.698034 lr 0.00024722 rank 3
2022-12-08 10:27:42,946 DEBUG TRAIN Batch 30/500 loss 5.611981 loss_att 316.262634 loss_ctc 15.947845 loss_rnnt 4.463552 lr 0.00024726 rank 1
2022-12-08 10:27:42,947 DEBUG TRAIN Batch 30/500 loss 5.954628 loss_att 357.321014 loss_ctc 16.076370 loss_rnnt 4.829990 lr 0.00024720 rank 0
2022-12-08 10:27:42,948 DEBUG TRAIN Batch 30/500 loss 5.558439 loss_att 304.400177 loss_ctc 16.900539 loss_rnnt 4.298205 lr 0.00024723 rank 5
2022-12-08 10:28:46,838 DEBUG TRAIN Batch 30/600 loss 5.844283 loss_att 124.837006 loss_ctc 11.180595 loss_rnnt 5.251359 lr 0.00024718 rank 7
2022-12-08 10:28:46,840 DEBUG TRAIN Batch 30/600 loss 1.418651 loss_att 254.603424 loss_ctc 4.180128 loss_rnnt 1.111820 lr 0.00024719 rank 3
2022-12-08 10:28:46,841 DEBUG TRAIN Batch 30/600 loss 5.772991 loss_att 247.538437 loss_ctc 14.614243 loss_rnnt 4.790630 lr 0.00024717 rank 0
2022-12-08 10:28:46,841 DEBUG TRAIN Batch 30/600 loss 6.946859 loss_att 75.951241 loss_ctc 11.323209 loss_rnnt 6.460598 lr 0.00024719 rank 4
2022-12-08 10:28:46,843 DEBUG TRAIN Batch 30/600 loss 8.427811 loss_att 190.961319 loss_ctc 11.397902 loss_rnnt 8.097800 lr 0.00024723 rank 1
2022-12-08 10:28:46,847 DEBUG TRAIN Batch 30/600 loss 4.089723 loss_att 230.439529 loss_ctc 7.905833 loss_rnnt 3.665711 lr 0.00024720 rank 5
2022-12-08 10:28:46,848 DEBUG TRAIN Batch 30/600 loss 6.579334 loss_att 247.386337 loss_ctc 12.636883 loss_rnnt 5.906274 lr 0.00024720 rank 2
2022-12-08 10:28:46,880 DEBUG TRAIN Batch 30/600 loss 10.039581 loss_att 246.856903 loss_ctc 15.324844 loss_rnnt 9.452331 lr 0.00024721 rank 6
2022-12-08 10:29:52,587 DEBUG TRAIN Batch 30/700 loss 7.884725 loss_att 397.958466 loss_ctc 14.468658 loss_rnnt 7.153176 lr 0.00024718 rank 6
2022-12-08 10:29:52,589 DEBUG TRAIN Batch 30/700 loss 2.896827 loss_att 456.388763 loss_ctc 8.590744 loss_rnnt 2.264170 lr 0.00024716 rank 3
2022-12-08 10:29:52,595 DEBUG TRAIN Batch 30/700 loss 9.049734 loss_att 374.229584 loss_ctc 21.856506 loss_rnnt 7.626760 lr 0.00024715 rank 7
2022-12-08 10:29:52,598 DEBUG TRAIN Batch 30/700 loss 4.177669 loss_att 444.606201 loss_ctc 9.903037 loss_rnnt 3.541517 lr 0.00024715 rank 4
2022-12-08 10:29:52,600 DEBUG TRAIN Batch 30/700 loss 5.057394 loss_att 389.312958 loss_ctc 12.812901 loss_rnnt 4.195671 lr 0.00024717 rank 2
2022-12-08 10:29:52,601 DEBUG TRAIN Batch 30/700 loss 9.759771 loss_att 458.888733 loss_ctc 28.983130 loss_rnnt 7.623842 lr 0.00024714 rank 0
2022-12-08 10:29:52,601 DEBUG TRAIN Batch 30/700 loss 8.840336 loss_att 398.374329 loss_ctc 19.113071 loss_rnnt 7.698921 lr 0.00024720 rank 1
2022-12-08 10:29:52,603 DEBUG TRAIN Batch 30/700 loss 13.720647 loss_att 446.059662 loss_ctc 23.347717 loss_rnnt 12.650972 lr 0.00024717 rank 5
2022-12-08 10:31:01,316 DEBUG TRAIN Batch 30/800 loss 13.432993 loss_att 380.635071 loss_ctc 22.755951 loss_rnnt 12.397109 lr 0.00024712 rank 4
2022-12-08 10:31:01,317 DEBUG TRAIN Batch 30/800 loss 9.455464 loss_att 387.033661 loss_ctc 19.960911 loss_rnnt 8.288193 lr 0.00024717 rank 1
2022-12-08 10:31:01,317 DEBUG TRAIN Batch 30/800 loss 13.483390 loss_att 382.246521 loss_ctc 16.556889 loss_rnnt 13.141890 lr 0.00024714 rank 2
2022-12-08 10:31:01,318 DEBUG TRAIN Batch 30/800 loss 4.698442 loss_att 441.194214 loss_ctc 10.922873 loss_rnnt 4.006838 lr 0.00024715 rank 6
2022-12-08 10:31:01,319 DEBUG TRAIN Batch 30/800 loss 7.888055 loss_att 335.156830 loss_ctc 17.991957 loss_rnnt 6.765399 lr 0.00024712 rank 7
2022-12-08 10:31:01,319 DEBUG TRAIN Batch 30/800 loss 6.326334 loss_att 389.219940 loss_ctc 13.653861 loss_rnnt 5.512165 lr 0.00024713 rank 3
2022-12-08 10:31:01,322 DEBUG TRAIN Batch 30/800 loss 7.220338 loss_att 340.619965 loss_ctc 14.864698 loss_rnnt 6.370965 lr 0.00024711 rank 0
2022-12-08 10:31:01,362 DEBUG TRAIN Batch 30/800 loss 1.458619 loss_att 408.386688 loss_ctc 6.409288 loss_rnnt 0.908545 lr 0.00024714 rank 5
2022-12-08 10:32:05,190 DEBUG TRAIN Batch 30/900 loss 3.682213 loss_att 382.616882 loss_ctc 7.929440 loss_rnnt 3.210299 lr 0.00024708 rank 0
2022-12-08 10:32:05,198 DEBUG TRAIN Batch 30/900 loss 9.484149 loss_att 418.145264 loss_ctc 21.902468 loss_rnnt 8.104336 lr 0.00024709 rank 7
2022-12-08 10:32:05,199 DEBUG TRAIN Batch 30/900 loss 10.205704 loss_att 394.694855 loss_ctc 17.719616 loss_rnnt 9.370826 lr 0.00024709 rank 4
2022-12-08 10:32:05,201 DEBUG TRAIN Batch 30/900 loss 3.559755 loss_att 336.540375 loss_ctc 11.232398 loss_rnnt 2.707239 lr 0.00024711 rank 2
2022-12-08 10:32:05,201 DEBUG TRAIN Batch 30/900 loss 9.897897 loss_att 357.988617 loss_ctc 17.308352 loss_rnnt 9.074513 lr 0.00024710 rank 3
2022-12-08 10:32:05,203 DEBUG TRAIN Batch 30/900 loss 7.502109 loss_att 411.887939 loss_ctc 15.720382 loss_rnnt 6.588968 lr 0.00024712 rank 6
2022-12-08 10:32:05,205 DEBUG TRAIN Batch 30/900 loss 4.471981 loss_att 421.574951 loss_ctc 8.443203 loss_rnnt 4.030734 lr 0.00024714 rank 1
2022-12-08 10:32:05,245 DEBUG TRAIN Batch 30/900 loss 3.323174 loss_att 357.248718 loss_ctc 15.054312 loss_rnnt 2.019714 lr 0.00024711 rank 5
2022-12-08 10:33:09,022 DEBUG TRAIN Batch 30/1000 loss 7.770396 loss_att 393.499847 loss_ctc 22.636044 loss_rnnt 6.118658 lr 0.00024707 rank 3
2022-12-08 10:33:09,023 DEBUG TRAIN Batch 30/1000 loss 6.452072 loss_att 355.693237 loss_ctc 12.381752 loss_rnnt 5.793219 lr 0.00024708 rank 5
2022-12-08 10:33:09,029 DEBUG TRAIN Batch 30/1000 loss 6.654835 loss_att 329.940186 loss_ctc 15.036368 loss_rnnt 5.723553 lr 0.00024706 rank 4
2022-12-08 10:33:09,032 DEBUG TRAIN Batch 30/1000 loss 8.156239 loss_att 384.797913 loss_ctc 20.794315 loss_rnnt 6.752008 lr 0.00024706 rank 7
2022-12-08 10:33:09,033 DEBUG TRAIN Batch 30/1000 loss 6.285511 loss_att 357.328247 loss_ctc 16.919081 loss_rnnt 5.104003 lr 0.00024709 rank 6
2022-12-08 10:33:09,035 DEBUG TRAIN Batch 30/1000 loss 9.010021 loss_att 377.655823 loss_ctc 18.019890 loss_rnnt 8.008925 lr 0.00024708 rank 2
2022-12-08 10:33:09,036 DEBUG TRAIN Batch 30/1000 loss 4.227201 loss_att 339.157776 loss_ctc 9.203949 loss_rnnt 3.674228 lr 0.00024705 rank 0
2022-12-08 10:33:09,037 DEBUG TRAIN Batch 30/1000 loss 9.428905 loss_att 410.897766 loss_ctc 19.708309 loss_rnnt 8.286749 lr 0.00024711 rank 1
2022-12-08 10:34:18,842 DEBUG TRAIN Batch 30/1100 loss 5.071826 loss_att 304.669006 loss_ctc 7.393547 loss_rnnt 4.813858 lr 0.00024703 rank 4
2022-12-08 10:34:18,843 DEBUG TRAIN Batch 30/1100 loss 4.408626 loss_att 377.182739 loss_ctc 11.136860 loss_rnnt 3.661045 lr 0.00024703 rank 7
2022-12-08 10:34:18,844 DEBUG TRAIN Batch 30/1100 loss 6.823737 loss_att 288.578796 loss_ctc 14.956532 loss_rnnt 5.920094 lr 0.00024707 rank 1
2022-12-08 10:34:18,847 DEBUG TRAIN Batch 30/1100 loss 2.723744 loss_att 347.582581 loss_ctc 8.389835 loss_rnnt 2.094179 lr 0.00024705 rank 5
2022-12-08 10:34:18,848 DEBUG TRAIN Batch 30/1100 loss 10.915010 loss_att 457.890686 loss_ctc 29.501457 loss_rnnt 8.849850 lr 0.00024704 rank 3
2022-12-08 10:34:18,848 DEBUG TRAIN Batch 30/1100 loss 7.233667 loss_att 346.139435 loss_ctc 16.628452 loss_rnnt 6.189803 lr 0.00024706 rank 6
2022-12-08 10:34:18,848 DEBUG TRAIN Batch 30/1100 loss 2.968496 loss_att 365.732208 loss_ctc 10.381613 loss_rnnt 2.144817 lr 0.00024705 rank 2
2022-12-08 10:34:18,850 DEBUG TRAIN Batch 30/1100 loss 7.639447 loss_att 328.604431 loss_ctc 8.973938 loss_rnnt 7.491171 lr 0.00024702 rank 0
2022-12-08 10:35:23,241 DEBUG TRAIN Batch 30/1200 loss 5.160855 loss_att 292.419586 loss_ctc 10.190131 loss_rnnt 4.602047 lr 0.00024703 rank 6
2022-12-08 10:35:23,241 DEBUG TRAIN Batch 30/1200 loss 6.766646 loss_att 228.704193 loss_ctc 14.705812 loss_rnnt 5.884517 lr 0.00024700 rank 7
2022-12-08 10:35:23,241 DEBUG TRAIN Batch 30/1200 loss 5.820886 loss_att 317.408325 loss_ctc 11.853012 loss_rnnt 5.150650 lr 0.00024702 rank 2
2022-12-08 10:35:23,242 DEBUG TRAIN Batch 30/1200 loss 8.561990 loss_att 165.160965 loss_ctc 15.878981 loss_rnnt 7.748991 lr 0.00024700 rank 4
2022-12-08 10:35:23,245 DEBUG TRAIN Batch 30/1200 loss 4.295957 loss_att 282.283783 loss_ctc 7.344058 loss_rnnt 3.957278 lr 0.00024699 rank 0
2022-12-08 10:35:23,246 DEBUG TRAIN Batch 30/1200 loss 5.627090 loss_att 327.359100 loss_ctc 11.140342 loss_rnnt 5.014507 lr 0.00024702 rank 5
2022-12-08 10:35:23,247 DEBUG TRAIN Batch 30/1200 loss 7.957924 loss_att 283.703186 loss_ctc 15.756335 loss_rnnt 7.091434 lr 0.00024704 rank 1
2022-12-08 10:35:23,248 DEBUG TRAIN Batch 30/1200 loss 14.406370 loss_att 265.190552 loss_ctc 23.536533 loss_rnnt 13.391909 lr 0.00024701 rank 3
2022-12-08 10:36:27,186 DEBUG TRAIN Batch 30/1300 loss 7.983196 loss_att 113.522934 loss_ctc 12.787243 loss_rnnt 7.449413 lr 0.00024700 rank 6
2022-12-08 10:36:27,187 DEBUG TRAIN Batch 30/1300 loss 5.441333 loss_att 389.075745 loss_ctc 12.009559 loss_rnnt 4.711530 lr 0.00024697 rank 7
2022-12-08 10:36:27,188 DEBUG TRAIN Batch 30/1300 loss 3.438897 loss_att 404.928406 loss_ctc 8.199900 loss_rnnt 2.909897 lr 0.00024698 rank 3
2022-12-08 10:36:27,188 DEBUG TRAIN Batch 30/1300 loss 12.876452 loss_att 374.073334 loss_ctc 24.617432 loss_rnnt 11.571899 lr 0.00024697 rank 4
2022-12-08 10:36:27,191 DEBUG TRAIN Batch 30/1300 loss 4.930857 loss_att 483.771851 loss_ctc 13.015033 loss_rnnt 4.032615 lr 0.00024701 rank 1
2022-12-08 10:36:27,192 DEBUG TRAIN Batch 30/1300 loss 7.655601 loss_att 143.821655 loss_ctc 10.161456 loss_rnnt 7.377172 lr 0.00024699 rank 5
2022-12-08 10:36:27,193 DEBUG TRAIN Batch 30/1300 loss 4.916989 loss_att 425.170258 loss_ctc 9.947916 loss_rnnt 4.357997 lr 0.00024696 rank 0
2022-12-08 10:36:27,231 DEBUG TRAIN Batch 30/1300 loss 6.462310 loss_att 155.021759 loss_ctc 10.707002 loss_rnnt 5.990677 lr 0.00024699 rank 2
2022-12-08 10:37:32,251 DEBUG TRAIN Batch 30/1400 loss 5.959265 loss_att 421.768402 loss_ctc 21.114948 loss_rnnt 4.275300 lr 0.00024694 rank 7
2022-12-08 10:37:32,251 DEBUG TRAIN Batch 30/1400 loss 4.212777 loss_att 392.488129 loss_ctc 11.645409 loss_rnnt 3.386929 lr 0.00024694 rank 4
2022-12-08 10:37:32,256 DEBUG TRAIN Batch 30/1400 loss 6.315673 loss_att 395.103119 loss_ctc 15.208694 loss_rnnt 5.327559 lr 0.00024695 rank 3
2022-12-08 10:37:32,256 DEBUG TRAIN Batch 30/1400 loss 3.438558 loss_att 437.252777 loss_ctc 8.153767 loss_rnnt 2.914646 lr 0.00024693 rank 0
2022-12-08 10:37:32,262 DEBUG TRAIN Batch 30/1400 loss 5.481868 loss_att 413.064423 loss_ctc 11.405884 loss_rnnt 4.823645 lr 0.00024696 rank 5
2022-12-08 10:37:32,289 DEBUG TRAIN Batch 30/1400 loss 3.104203 loss_att 368.729675 loss_ctc 7.708522 loss_rnnt 2.592612 lr 0.00024698 rank 1
2022-12-08 10:37:32,290 DEBUG TRAIN Batch 30/1400 loss 1.993389 loss_att 371.009705 loss_ctc 8.361758 loss_rnnt 1.285792 lr 0.00024697 rank 6
2022-12-08 10:37:32,297 DEBUG TRAIN Batch 30/1400 loss 6.524203 loss_att 377.868256 loss_ctc 15.574448 loss_rnnt 5.518620 lr 0.00024696 rank 2
2022-12-08 10:38:42,695 DEBUG TRAIN Batch 30/1500 loss 5.128700 loss_att 419.137756 loss_ctc 11.117233 loss_rnnt 4.463307 lr 0.00024693 rank 2
2022-12-08 10:38:42,697 DEBUG TRAIN Batch 30/1500 loss 3.988177 loss_att 383.926636 loss_ctc 8.135511 loss_rnnt 3.527362 lr 0.00024691 rank 7
2022-12-08 10:38:42,697 DEBUG TRAIN Batch 30/1500 loss 6.061562 loss_att 398.127930 loss_ctc 10.035118 loss_rnnt 5.620055 lr 0.00024695 rank 1
2022-12-08 10:38:42,698 DEBUG TRAIN Batch 30/1500 loss 4.852032 loss_att 362.378510 loss_ctc 9.489764 loss_rnnt 4.336729 lr 0.00024693 rank 5
2022-12-08 10:38:42,698 DEBUG TRAIN Batch 30/1500 loss 9.149084 loss_att 378.017151 loss_ctc 21.837181 loss_rnnt 7.739295 lr 0.00024691 rank 4
2022-12-08 10:38:42,700 DEBUG TRAIN Batch 30/1500 loss 2.613573 loss_att 333.340240 loss_ctc 6.927611 loss_rnnt 2.134235 lr 0.00024690 rank 0
2022-12-08 10:38:42,703 DEBUG TRAIN Batch 30/1500 loss 8.004242 loss_att 388.443115 loss_ctc 20.104904 loss_rnnt 6.659725 lr 0.00024694 rank 6
2022-12-08 10:38:42,704 DEBUG TRAIN Batch 30/1500 loss 9.940872 loss_att 459.357147 loss_ctc 23.845612 loss_rnnt 8.395902 lr 0.00024692 rank 3
2022-12-08 10:39:46,119 DEBUG TRAIN Batch 30/1600 loss 7.243215 loss_att 385.346313 loss_ctc 13.507742 loss_rnnt 6.547156 lr 0.00024688 rank 7
2022-12-08 10:39:46,122 DEBUG TRAIN Batch 30/1600 loss 13.681082 loss_att 400.676300 loss_ctc 24.572880 loss_rnnt 12.470882 lr 0.00024688 rank 4
2022-12-08 10:39:46,124 DEBUG TRAIN Batch 30/1600 loss 6.572990 loss_att 432.833679 loss_ctc 10.723713 loss_rnnt 6.111798 lr 0.00024687 rank 0
2022-12-08 10:39:46,126 DEBUG TRAIN Batch 30/1600 loss 10.099525 loss_att 349.144928 loss_ctc 18.306843 loss_rnnt 9.187601 lr 0.00024691 rank 6
2022-12-08 10:39:46,127 DEBUG TRAIN Batch 30/1600 loss 17.303753 loss_att 388.577698 loss_ctc 31.310825 loss_rnnt 15.747411 lr 0.00024690 rank 2
2022-12-08 10:39:46,126 DEBUG TRAIN Batch 30/1600 loss 6.667014 loss_att 331.496643 loss_ctc 14.679575 loss_rnnt 5.776729 lr 0.00024692 rank 1
2022-12-08 10:39:46,129 DEBUG TRAIN Batch 30/1600 loss 4.141622 loss_att 347.380981 loss_ctc 8.353386 loss_rnnt 3.673648 lr 0.00024690 rank 5
2022-12-08 10:39:46,128 DEBUG TRAIN Batch 30/1600 loss 13.720478 loss_att 429.569672 loss_ctc 25.289619 loss_rnnt 12.435018 lr 0.00024689 rank 3
2022-12-08 10:40:50,651 DEBUG TRAIN Batch 30/1700 loss 10.974955 loss_att 383.399719 loss_ctc 22.690948 loss_rnnt 9.673178 lr 0.00024686 rank 3
2022-12-08 10:40:50,655 DEBUG TRAIN Batch 30/1700 loss 6.288261 loss_att 345.129761 loss_ctc 11.414711 loss_rnnt 5.718656 lr 0.00024685 rank 7
2022-12-08 10:40:50,656 DEBUG TRAIN Batch 30/1700 loss 9.666695 loss_att 342.549866 loss_ctc 17.197275 loss_rnnt 8.829964 lr 0.00024685 rank 4
2022-12-08 10:40:50,659 DEBUG TRAIN Batch 30/1700 loss 15.230160 loss_att 390.821198 loss_ctc 32.802738 loss_rnnt 13.277651 lr 0.00024689 rank 1
2022-12-08 10:40:50,661 DEBUG TRAIN Batch 30/1700 loss 12.594978 loss_att 319.740479 loss_ctc 21.834209 loss_rnnt 11.568398 lr 0.00024684 rank 0
2022-12-08 10:40:50,663 DEBUG TRAIN Batch 30/1700 loss 12.577888 loss_att 371.057495 loss_ctc 21.955261 loss_rnnt 11.535957 lr 0.00024688 rank 6
2022-12-08 10:40:50,665 DEBUG TRAIN Batch 30/1700 loss 5.544096 loss_att 377.263123 loss_ctc 10.022748 loss_rnnt 5.046467 lr 0.00024687 rank 5
2022-12-08 10:40:50,665 DEBUG TRAIN Batch 30/1700 loss 3.855738 loss_att 388.209595 loss_ctc 9.448024 loss_rnnt 3.234373 lr 0.00024687 rank 2
2022-12-08 10:42:00,945 DEBUG TRAIN Batch 30/1800 loss 11.976122 loss_att 369.686615 loss_ctc 20.491657 loss_rnnt 11.029952 lr 0.00024682 rank 7
2022-12-08 10:42:00,946 DEBUG TRAIN Batch 30/1800 loss 8.408222 loss_att 209.428497 loss_ctc 15.009342 loss_rnnt 7.674765 lr 0.00024682 rank 4
2022-12-08 10:42:00,949 DEBUG TRAIN Batch 30/1800 loss 5.145848 loss_att 264.504120 loss_ctc 12.234983 loss_rnnt 4.358166 lr 0.00024685 rank 6
2022-12-08 10:42:00,949 DEBUG TRAIN Batch 30/1800 loss 3.595135 loss_att 334.076782 loss_ctc 11.196901 loss_rnnt 2.750494 lr 0.00024684 rank 2
2022-12-08 10:42:00,950 DEBUG TRAIN Batch 30/1800 loss 6.584059 loss_att 352.611023 loss_ctc 19.181416 loss_rnnt 5.184353 lr 0.00024681 rank 0
2022-12-08 10:42:00,950 DEBUG TRAIN Batch 30/1800 loss 11.027334 loss_att 359.727905 loss_ctc 24.996618 loss_rnnt 9.475191 lr 0.00024686 rank 1
2022-12-08 10:42:00,955 DEBUG TRAIN Batch 30/1800 loss 5.307917 loss_att 349.314789 loss_ctc 8.434279 loss_rnnt 4.960543 lr 0.00024684 rank 5
2022-12-08 10:42:00,991 DEBUG TRAIN Batch 30/1800 loss 4.119407 loss_att 331.026917 loss_ctc 9.084703 loss_rnnt 3.567708 lr 0.00024683 rank 3
2022-12-08 10:43:04,741 DEBUG TRAIN Batch 30/1900 loss 11.432257 loss_att 309.005890 loss_ctc 16.616499 loss_rnnt 10.856231 lr 0.00024679 rank 7
2022-12-08 10:43:04,754 DEBUG TRAIN Batch 30/1900 loss 3.351911 loss_att 360.685760 loss_ctc 5.666823 loss_rnnt 3.094699 lr 0.00024679 rank 4
2022-12-08 10:43:04,756 DEBUG TRAIN Batch 30/1900 loss 1.934506 loss_att 205.847595 loss_ctc 3.890502 loss_rnnt 1.717173 lr 0.00024682 rank 6
2022-12-08 10:43:04,756 DEBUG TRAIN Batch 30/1900 loss 3.196305 loss_att 259.470673 loss_ctc 10.782729 loss_rnnt 2.353369 lr 0.00024681 rank 2
2022-12-08 10:43:04,759 DEBUG TRAIN Batch 30/1900 loss 10.574284 loss_att 221.719360 loss_ctc 15.628200 loss_rnnt 10.012737 lr 0.00024681 rank 5
2022-12-08 10:43:04,759 DEBUG TRAIN Batch 30/1900 loss 6.208888 loss_att 192.985001 loss_ctc 12.712789 loss_rnnt 5.486233 lr 0.00024680 rank 3
2022-12-08 10:43:04,759 DEBUG TRAIN Batch 30/1900 loss 5.751488 loss_att 108.258072 loss_ctc 10.649304 loss_rnnt 5.207286 lr 0.00024683 rank 1
2022-12-08 10:43:04,760 DEBUG TRAIN Batch 30/1900 loss 13.905451 loss_att 211.328827 loss_ctc 22.875582 loss_rnnt 12.908770 lr 0.00024678 rank 0
2022-12-08 10:44:08,357 DEBUG TRAIN Batch 30/2000 loss 7.485448 loss_att 403.687561 loss_ctc 16.206371 loss_rnnt 6.516457 lr 0.00024676 rank 4
2022-12-08 10:44:08,366 DEBUG TRAIN Batch 30/2000 loss 2.648963 loss_att 346.923950 loss_ctc 6.930389 loss_rnnt 2.173249 lr 0.00024679 rank 6
2022-12-08 10:44:08,378 DEBUG TRAIN Batch 30/2000 loss 7.530788 loss_att 397.011078 loss_ctc 18.385082 loss_rnnt 6.324756 lr 0.00024678 rank 2
2022-12-08 10:44:08,383 DEBUG TRAIN Batch 30/2000 loss 6.844842 loss_att 397.029144 loss_ctc 18.629089 loss_rnnt 5.535482 lr 0.00024675 rank 0
2022-12-08 10:44:08,386 DEBUG TRAIN Batch 30/2000 loss 6.225402 loss_att 429.289429 loss_ctc 12.935565 loss_rnnt 5.479828 lr 0.00024678 rank 5
2022-12-08 10:44:08,387 DEBUG TRAIN Batch 30/2000 loss 9.870940 loss_att 410.045868 loss_ctc 18.757271 loss_rnnt 8.883571 lr 0.00024676 rank 7
2022-12-08 10:44:08,389 DEBUG TRAIN Batch 30/2000 loss 3.930699 loss_att 397.178070 loss_ctc 12.007084 loss_rnnt 3.033323 lr 0.00024677 rank 3
2022-12-08 10:44:08,425 DEBUG TRAIN Batch 30/2000 loss 11.565865 loss_att 469.434692 loss_ctc 21.777237 loss_rnnt 10.431268 lr 0.00024680 rank 1
2022-12-08 10:45:13,472 DEBUG TRAIN Batch 30/2100 loss 4.520408 loss_att 388.684631 loss_ctc 7.882503 loss_rnnt 4.146842 lr 0.00024675 rank 2
2022-12-08 10:45:13,483 DEBUG TRAIN Batch 30/2100 loss 11.298137 loss_att 308.491180 loss_ctc 10.401075 loss_rnnt 11.397810 lr 0.00024672 rank 0
2022-12-08 10:45:13,483 DEBUG TRAIN Batch 30/2100 loss 10.260339 loss_att 392.317200 loss_ctc 20.757301 loss_rnnt 9.094009 lr 0.00024673 rank 7
2022-12-08 10:45:13,483 DEBUG TRAIN Batch 30/2100 loss 4.722492 loss_att 379.706635 loss_ctc 12.161502 loss_rnnt 3.895935 lr 0.00024675 rank 5
2022-12-08 10:45:13,485 DEBUG TRAIN Batch 30/2100 loss 4.525828 loss_att 359.156494 loss_ctc 13.498653 loss_rnnt 3.528848 lr 0.00024673 rank 4
2022-12-08 10:45:13,487 DEBUG TRAIN Batch 30/2100 loss 6.468068 loss_att 408.455383 loss_ctc 15.790305 loss_rnnt 5.432264 lr 0.00024677 rank 1
2022-12-08 10:45:13,490 DEBUG TRAIN Batch 30/2100 loss 7.245281 loss_att 430.641357 loss_ctc 17.170977 loss_rnnt 6.142426 lr 0.00024674 rank 3
2022-12-08 10:45:13,491 DEBUG TRAIN Batch 30/2100 loss 13.827084 loss_att 426.792816 loss_ctc 26.514584 loss_rnnt 12.417361 lr 0.00024676 rank 6
2022-12-08 10:46:22,919 DEBUG TRAIN Batch 30/2200 loss 7.130880 loss_att 377.825867 loss_ctc 13.357810 loss_rnnt 6.438999 lr 0.00024673 rank 6
2022-12-08 10:46:22,923 DEBUG TRAIN Batch 30/2200 loss 3.891364 loss_att 352.281494 loss_ctc 9.349511 loss_rnnt 3.284903 lr 0.00024671 rank 3
2022-12-08 10:46:22,924 DEBUG TRAIN Batch 30/2200 loss 9.038191 loss_att 394.595947 loss_ctc 22.555674 loss_rnnt 7.536248 lr 0.00024670 rank 7
2022-12-08 10:46:22,927 DEBUG TRAIN Batch 30/2200 loss 5.516637 loss_att 380.154022 loss_ctc 11.044888 loss_rnnt 4.902387 lr 0.00024670 rank 4
2022-12-08 10:46:22,928 DEBUG TRAIN Batch 30/2200 loss 5.667515 loss_att 365.402069 loss_ctc 11.029772 loss_rnnt 5.071709 lr 0.00024669 rank 0
2022-12-08 10:46:22,930 DEBUG TRAIN Batch 30/2200 loss 3.790354 loss_att 380.327637 loss_ctc 7.000299 loss_rnnt 3.433694 lr 0.00024672 rank 5
2022-12-08 10:46:22,934 DEBUG TRAIN Batch 30/2200 loss 4.034820 loss_att 385.009186 loss_ctc 12.539743 loss_rnnt 3.089828 lr 0.00024672 rank 2
2022-12-08 10:46:22,935 DEBUG TRAIN Batch 30/2200 loss 11.459905 loss_att 464.672974 loss_ctc 20.299717 loss_rnnt 10.477703 lr 0.00024674 rank 1
2022-12-08 10:47:25,833 DEBUG TRAIN Batch 30/2300 loss 10.832443 loss_att 383.382172 loss_ctc 21.386257 loss_rnnt 9.659797 lr 0.00024667 rank 4
2022-12-08 10:47:25,834 DEBUG TRAIN Batch 30/2300 loss 5.579885 loss_att 351.471710 loss_ctc 13.303616 loss_rnnt 4.721693 lr 0.00024667 rank 7
2022-12-08 10:47:25,836 DEBUG TRAIN Batch 30/2300 loss 7.452496 loss_att 363.217102 loss_ctc 19.673723 loss_rnnt 6.094582 lr 0.00024670 rank 6
2022-12-08 10:47:25,838 DEBUG TRAIN Batch 30/2300 loss 5.135345 loss_att 350.501282 loss_ctc 8.330144 loss_rnnt 4.780367 lr 0.00024669 rank 2
2022-12-08 10:47:25,837 DEBUG TRAIN Batch 30/2300 loss 9.507586 loss_att 438.961731 loss_ctc 21.735952 loss_rnnt 8.148878 lr 0.00024668 rank 3
2022-12-08 10:47:25,842 DEBUG TRAIN Batch 30/2300 loss 7.352457 loss_att 354.407990 loss_ctc 12.956979 loss_rnnt 6.729733 lr 0.00024666 rank 0
2022-12-08 10:47:25,842 DEBUG TRAIN Batch 30/2300 loss 8.876470 loss_att 366.822571 loss_ctc 11.709593 loss_rnnt 8.561678 lr 0.00024671 rank 1
2022-12-08 10:47:25,888 DEBUG TRAIN Batch 30/2300 loss 13.732851 loss_att 384.101013 loss_ctc 26.087259 loss_rnnt 12.360139 lr 0.00024669 rank 5
2022-12-08 10:48:29,649 DEBUG TRAIN Batch 30/2400 loss 8.539740 loss_att 272.152802 loss_ctc 15.782504 loss_rnnt 7.734989 lr 0.00024664 rank 4
2022-12-08 10:48:29,651 DEBUG TRAIN Batch 30/2400 loss 10.448776 loss_att 325.949524 loss_ctc 17.304703 loss_rnnt 9.687006 lr 0.00024664 rank 7
2022-12-08 10:48:29,653 DEBUG TRAIN Batch 30/2400 loss 6.370987 loss_att 377.684906 loss_ctc 12.834875 loss_rnnt 5.652778 lr 0.00024666 rank 2
2022-12-08 10:48:29,655 DEBUG TRAIN Batch 30/2400 loss 7.760301 loss_att 375.836975 loss_ctc 20.696194 loss_rnnt 6.322979 lr 0.00024663 rank 0
2022-12-08 10:48:29,657 DEBUG TRAIN Batch 30/2400 loss 4.206748 loss_att 365.849884 loss_ctc 16.367842 loss_rnnt 2.855515 lr 0.00024667 rank 6
2022-12-08 10:48:29,659 DEBUG TRAIN Batch 30/2400 loss 10.217907 loss_att 288.935822 loss_ctc 14.970219 loss_rnnt 9.689873 lr 0.00024665 rank 3
2022-12-08 10:48:29,660 DEBUG TRAIN Batch 30/2400 loss 13.781796 loss_att 340.065155 loss_ctc 34.463570 loss_rnnt 11.483821 lr 0.00024668 rank 1
2022-12-08 10:48:29,659 DEBUG TRAIN Batch 30/2400 loss 7.978065 loss_att 318.901367 loss_ctc 13.230211 loss_rnnt 7.394493 lr 0.00024666 rank 5
2022-12-08 10:49:41,627 DEBUG TRAIN Batch 30/2500 loss 5.468506 loss_att 439.061401 loss_ctc 11.925089 loss_rnnt 4.751108 lr 0.00024661 rank 4
2022-12-08 10:49:41,629 DEBUG TRAIN Batch 30/2500 loss 8.824535 loss_att 166.742035 loss_ctc 14.268299 loss_rnnt 8.219673 lr 0.00024661 rank 7
2022-12-08 10:49:41,630 DEBUG TRAIN Batch 30/2500 loss 7.905227 loss_att 178.763214 loss_ctc 13.458336 loss_rnnt 7.288215 lr 0.00024665 rank 1
2022-12-08 10:49:41,630 DEBUG TRAIN Batch 30/2500 loss 5.489953 loss_att 256.781708 loss_ctc 12.500395 loss_rnnt 4.711015 lr 0.00024660 rank 0
2022-12-08 10:49:41,632 DEBUG TRAIN Batch 30/2500 loss 7.138949 loss_att 264.380829 loss_ctc 14.041541 loss_rnnt 6.371995 lr 0.00024662 rank 3
2022-12-08 10:49:41,634 DEBUG TRAIN Batch 30/2500 loss 6.064188 loss_att 202.971069 loss_ctc 12.226790 loss_rnnt 5.379455 lr 0.00024663 rank 2
2022-12-08 10:49:41,635 DEBUG TRAIN Batch 30/2500 loss 11.675009 loss_att 240.493942 loss_ctc 13.919477 loss_rnnt 11.425624 lr 0.00024664 rank 6
2022-12-08 10:49:41,679 DEBUG TRAIN Batch 30/2500 loss 5.996816 loss_att 269.245911 loss_ctc 10.439300 loss_rnnt 5.503207 lr 0.00024663 rank 5
2022-12-08 10:50:45,309 DEBUG TRAIN Batch 30/2600 loss 3.979579 loss_att 377.419525 loss_ctc 8.364386 loss_rnnt 3.492378 lr 0.00024661 rank 6
2022-12-08 10:50:45,310 DEBUG TRAIN Batch 30/2600 loss 7.307541 loss_att 397.808197 loss_ctc 14.016159 loss_rnnt 6.562140 lr 0.00024658 rank 4
2022-12-08 10:50:45,312 DEBUG TRAIN Batch 30/2600 loss 3.884889 loss_att 396.748718 loss_ctc 11.716772 loss_rnnt 3.014679 lr 0.00024658 rank 7
2022-12-08 10:50:45,314 DEBUG TRAIN Batch 30/2600 loss 7.751119 loss_att 460.231934 loss_ctc 16.515297 loss_rnnt 6.777322 lr 0.00024660 rank 2
2022-12-08 10:50:45,314 DEBUG TRAIN Batch 30/2600 loss 8.561843 loss_att 378.996674 loss_ctc 12.512098 loss_rnnt 8.122926 lr 0.00024662 rank 1
2022-12-08 10:50:45,316 DEBUG TRAIN Batch 30/2600 loss 9.434221 loss_att 138.291992 loss_ctc 16.743589 loss_rnnt 8.622069 lr 0.00024660 rank 5
2022-12-08 10:50:45,316 DEBUG TRAIN Batch 30/2600 loss 11.293455 loss_att 454.389160 loss_ctc 16.298300 loss_rnnt 10.737361 lr 0.00024659 rank 3
2022-12-08 10:50:45,317 DEBUG TRAIN Batch 30/2600 loss 10.130725 loss_att 470.736511 loss_ctc 23.933853 loss_rnnt 8.597044 lr 0.00024657 rank 0
2022-12-08 10:51:49,035 DEBUG TRAIN Batch 30/2700 loss 6.605601 loss_att 392.478851 loss_ctc 11.285899 loss_rnnt 6.085567 lr 0.00024655 rank 7
2022-12-08 10:51:49,036 DEBUG TRAIN Batch 30/2700 loss 3.515219 loss_att 405.148407 loss_ctc 12.512259 loss_rnnt 2.515548 lr 0.00024654 rank 0
2022-12-08 10:51:49,036 DEBUG TRAIN Batch 30/2700 loss 13.908688 loss_att 417.033905 loss_ctc 23.091553 loss_rnnt 12.888370 lr 0.00024655 rank 4
2022-12-08 10:51:49,037 DEBUG TRAIN Batch 30/2700 loss 4.401945 loss_att 423.785980 loss_ctc 6.975137 loss_rnnt 4.116035 lr 0.00024659 rank 1
2022-12-08 10:51:49,039 DEBUG TRAIN Batch 30/2700 loss 4.567129 loss_att 349.122894 loss_ctc 8.878975 loss_rnnt 4.088036 lr 0.00024657 rank 2
2022-12-08 10:51:49,040 DEBUG TRAIN Batch 30/2700 loss 2.246165 loss_att 381.831299 loss_ctc 3.732737 loss_rnnt 2.080991 lr 0.00024656 rank 3
2022-12-08 10:51:49,044 DEBUG TRAIN Batch 30/2700 loss 10.828292 loss_att 379.070312 loss_ctc 28.776289 loss_rnnt 8.834070 lr 0.00024658 rank 6
2022-12-08 10:51:49,046 DEBUG TRAIN Batch 30/2700 loss 5.498845 loss_att 351.255463 loss_ctc 7.942266 loss_rnnt 5.227354 lr 0.00024657 rank 5
2022-12-08 10:52:54,448 DEBUG TRAIN Batch 30/2800 loss 9.915339 loss_att 435.847351 loss_ctc 21.973166 loss_rnnt 8.575581 lr 0.00024653 rank 3
2022-12-08 10:52:54,450 DEBUG TRAIN Batch 30/2800 loss 13.184885 loss_att 486.350342 loss_ctc 28.697575 loss_rnnt 11.461253 lr 0.00024654 rank 2
2022-12-08 10:52:54,456 DEBUG TRAIN Batch 30/2800 loss 4.842120 loss_att 314.781525 loss_ctc 9.018241 loss_rnnt 4.378107 lr 0.00024652 rank 4
2022-12-08 10:52:54,458 DEBUG TRAIN Batch 30/2800 loss 1.343905 loss_att 363.556732 loss_ctc 3.752709 loss_rnnt 1.076260 lr 0.00024652 rank 7
2022-12-08 10:52:54,461 DEBUG TRAIN Batch 30/2800 loss 6.236032 loss_att 397.524597 loss_ctc 13.214204 loss_rnnt 5.460680 lr 0.00024655 rank 6
2022-12-08 10:52:54,466 DEBUG TRAIN Batch 30/2800 loss 6.023657 loss_att 309.316650 loss_ctc 10.281752 loss_rnnt 5.550535 lr 0.00024651 rank 0
2022-12-08 10:52:54,466 DEBUG TRAIN Batch 30/2800 loss 8.819866 loss_att 337.577698 loss_ctc 22.968174 loss_rnnt 7.247832 lr 0.00024656 rank 1
2022-12-08 10:52:54,471 DEBUG TRAIN Batch 30/2800 loss 3.699311 loss_att 353.910889 loss_ctc 7.608434 loss_rnnt 3.264965 lr 0.00024654 rank 5
2022-12-08 10:54:04,456 DEBUG TRAIN Batch 30/2900 loss 9.111781 loss_att 381.540344 loss_ctc 16.585743 loss_rnnt 8.281342 lr 0.00024649 rank 7
2022-12-08 10:54:04,457 DEBUG TRAIN Batch 30/2900 loss 6.620675 loss_att 342.479156 loss_ctc 11.861597 loss_rnnt 6.038351 lr 0.00024648 rank 0
2022-12-08 10:54:04,464 DEBUG TRAIN Batch 30/2900 loss 10.660750 loss_att 370.645660 loss_ctc 22.401342 loss_rnnt 9.356240 lr 0.00024652 rank 6
2022-12-08 10:54:04,465 DEBUG TRAIN Batch 30/2900 loss 3.545236 loss_att 338.886841 loss_ctc 13.218811 loss_rnnt 2.470394 lr 0.00024649 rank 4
2022-12-08 10:54:04,465 DEBUG TRAIN Batch 30/2900 loss 2.926947 loss_att 358.090149 loss_ctc 6.992725 loss_rnnt 2.475194 lr 0.00024653 rank 1
2022-12-08 10:54:04,466 DEBUG TRAIN Batch 30/2900 loss 1.883634 loss_att 346.637482 loss_ctc 8.811026 loss_rnnt 1.113923 lr 0.00024650 rank 3
2022-12-08 10:54:04,475 DEBUG TRAIN Batch 30/2900 loss 20.337034 loss_att 370.498474 loss_ctc 46.658195 loss_rnnt 17.412460 lr 0.00024651 rank 2
2022-12-08 10:54:04,518 DEBUG TRAIN Batch 30/2900 loss 5.480969 loss_att 377.089569 loss_ctc 13.329422 loss_rnnt 4.608919 lr 0.00024651 rank 5
2022-12-08 10:55:07,746 DEBUG TRAIN Batch 30/3000 loss 3.426548 loss_att 322.139343 loss_ctc 5.860731 loss_rnnt 3.156084 lr 0.00024646 rank 7
2022-12-08 10:55:07,752 DEBUG TRAIN Batch 30/3000 loss 10.723866 loss_att 397.687897 loss_ctc 19.946911 loss_rnnt 9.699083 lr 0.00024647 rank 3
2022-12-08 10:55:07,752 DEBUG TRAIN Batch 30/3000 loss 8.342463 loss_att 330.812561 loss_ctc 15.276163 loss_rnnt 7.572052 lr 0.00024646 rank 4
2022-12-08 10:55:07,753 DEBUG TRAIN Batch 30/3000 loss 9.723296 loss_att 377.600800 loss_ctc 19.077604 loss_rnnt 8.683928 lr 0.00024648 rank 5
2022-12-08 10:55:07,754 DEBUG TRAIN Batch 30/3000 loss 6.269711 loss_att 396.592529 loss_ctc 16.499504 loss_rnnt 5.133068 lr 0.00024645 rank 0
2022-12-08 10:55:07,756 DEBUG TRAIN Batch 30/3000 loss 2.963395 loss_att 313.464874 loss_ctc 6.647488 loss_rnnt 2.554051 lr 0.00024649 rank 6
2022-12-08 10:55:07,802 DEBUG TRAIN Batch 30/3000 loss 4.102770 loss_att 292.498169 loss_ctc 11.262828 loss_rnnt 3.307208 lr 0.00024648 rank 2
2022-12-08 10:55:07,819 DEBUG TRAIN Batch 30/3000 loss 4.309475 loss_att 291.109009 loss_ctc 11.486290 loss_rnnt 3.512052 lr 0.00024650 rank 1
2022-12-08 10:56:11,732 DEBUG TRAIN Batch 30/3100 loss 10.253708 loss_att 287.982849 loss_ctc 20.932480 loss_rnnt 9.067178 lr 0.00024643 rank 7
2022-12-08 10:56:11,733 DEBUG TRAIN Batch 30/3100 loss 5.341105 loss_att 238.568817 loss_ctc 8.844062 loss_rnnt 4.951887 lr 0.00024643 rank 4
2022-12-08 10:56:11,739 DEBUG TRAIN Batch 30/3100 loss 3.227046 loss_att 316.626556 loss_ctc 9.969240 loss_rnnt 2.477913 lr 0.00024642 rank 0
2022-12-08 10:56:11,740 DEBUG TRAIN Batch 30/3100 loss 9.007230 loss_att 308.203369 loss_ctc 10.716774 loss_rnnt 8.817281 lr 0.00024645 rank 5
2022-12-08 10:56:11,742 DEBUG TRAIN Batch 30/3100 loss 6.682306 loss_att 307.242798 loss_ctc 13.624207 loss_rnnt 5.910984 lr 0.00024644 rank 3
2022-12-08 10:56:11,743 DEBUG TRAIN Batch 30/3100 loss 8.279257 loss_att 306.162354 loss_ctc 18.430468 loss_rnnt 7.151344 lr 0.00024645 rank 2
2022-12-08 10:56:11,772 DEBUG TRAIN Batch 30/3100 loss 6.887193 loss_att 190.067703 loss_ctc 10.429150 loss_rnnt 6.493643 lr 0.00024647 rank 1
2022-12-08 10:56:11,806 DEBUG TRAIN Batch 30/3100 loss 4.611813 loss_att 216.092728 loss_ctc 11.333017 loss_rnnt 3.865012 lr 0.00024646 rank 6
2022-12-08 10:57:23,971 DEBUG TRAIN Batch 30/3200 loss 3.337661 loss_att 339.034363 loss_ctc 8.699316 loss_rnnt 2.741921 lr 0.00024640 rank 4
2022-12-08 10:57:23,974 DEBUG TRAIN Batch 30/3200 loss 1.878965 loss_att 365.623657 loss_ctc 5.036215 loss_rnnt 1.528160 lr 0.00024640 rank 7
2022-12-08 10:57:23,977 DEBUG TRAIN Batch 30/3200 loss 8.621049 loss_att 248.828766 loss_ctc 18.717741 loss_rnnt 7.499195 lr 0.00024639 rank 0
2022-12-08 10:57:23,980 DEBUG TRAIN Batch 30/3200 loss 9.713238 loss_att 390.301361 loss_ctc 15.379782 loss_rnnt 9.083622 lr 0.00024643 rank 6
2022-12-08 10:57:23,980 DEBUG TRAIN Batch 30/3200 loss 7.854222 loss_att 69.169174 loss_ctc 12.096938 loss_rnnt 7.382809 lr 0.00024642 rank 5
2022-12-08 10:57:23,984 DEBUG TRAIN Batch 30/3200 loss 5.787109 loss_att 291.294250 loss_ctc 11.964421 loss_rnnt 5.100741 lr 0.00024641 rank 3
2022-12-08 10:57:24,014 DEBUG TRAIN Batch 30/3200 loss 1.190901 loss_att 312.804840 loss_ctc 4.568295 loss_rnnt 0.815635 lr 0.00024644 rank 1
2022-12-08 10:57:24,022 DEBUG TRAIN Batch 30/3200 loss 4.435956 loss_att 462.296936 loss_ctc 6.166709 loss_rnnt 4.243649 lr 0.00024642 rank 2
2022-12-08 10:58:27,425 DEBUG TRAIN Batch 30/3300 loss 5.058009 loss_att 342.994385 loss_ctc 12.109809 loss_rnnt 4.274476 lr 0.00024637 rank 7
2022-12-08 10:58:27,426 DEBUG TRAIN Batch 30/3300 loss 7.020411 loss_att 415.910980 loss_ctc 13.167499 loss_rnnt 6.337401 lr 0.00024640 rank 6
2022-12-08 10:58:27,427 DEBUG TRAIN Batch 30/3300 loss 4.593077 loss_att 414.032318 loss_ctc 10.793609 loss_rnnt 3.904129 lr 0.00024637 rank 4
2022-12-08 10:58:27,427 DEBUG TRAIN Batch 30/3300 loss 2.650876 loss_att 369.359253 loss_ctc 9.861940 loss_rnnt 1.849646 lr 0.00024641 rank 1
2022-12-08 10:58:27,429 DEBUG TRAIN Batch 30/3300 loss 3.947305 loss_att 333.086395 loss_ctc 6.827161 loss_rnnt 3.627321 lr 0.00024636 rank 0
2022-12-08 10:58:27,430 DEBUG TRAIN Batch 30/3300 loss 5.110549 loss_att 372.743347 loss_ctc 12.628630 loss_rnnt 4.275207 lr 0.00024639 rank 2
2022-12-08 10:58:27,433 DEBUG TRAIN Batch 30/3300 loss 4.849401 loss_att 399.441406 loss_ctc 10.925999 loss_rnnt 4.174223 lr 0.00024639 rank 5
2022-12-08 10:58:27,469 DEBUG TRAIN Batch 30/3300 loss 7.714369 loss_att 405.134369 loss_ctc 15.328283 loss_rnnt 6.868379 lr 0.00024638 rank 3
2022-12-08 10:59:30,653 DEBUG TRAIN Batch 30/3400 loss 10.261527 loss_att 394.937134 loss_ctc 24.173065 loss_rnnt 8.715800 lr 0.00024634 rank 4
2022-12-08 10:59:30,655 DEBUG TRAIN Batch 30/3400 loss 8.973307 loss_att 388.258118 loss_ctc 13.530205 loss_rnnt 8.466985 lr 0.00024636 rank 2
2022-12-08 10:59:30,657 DEBUG TRAIN Batch 30/3400 loss 9.581327 loss_att 420.229004 loss_ctc 13.129604 loss_rnnt 9.187075 lr 0.00024635 rank 3
2022-12-08 10:59:30,659 DEBUG TRAIN Batch 30/3400 loss 8.576172 loss_att 424.775604 loss_ctc 27.066139 loss_rnnt 6.521730 lr 0.00024634 rank 7
2022-12-08 10:59:30,659 DEBUG TRAIN Batch 30/3400 loss 6.222789 loss_att 343.580444 loss_ctc 10.389950 loss_rnnt 5.759771 lr 0.00024637 rank 6
2022-12-08 10:59:30,661 DEBUG TRAIN Batch 30/3400 loss 8.304838 loss_att 352.582581 loss_ctc 16.217489 loss_rnnt 7.425655 lr 0.00024633 rank 0
2022-12-08 10:59:30,661 DEBUG TRAIN Batch 30/3400 loss 10.103397 loss_att 424.372406 loss_ctc 22.610149 loss_rnnt 8.713758 lr 0.00024636 rank 5
2022-12-08 10:59:30,667 DEBUG TRAIN Batch 30/3400 loss 10.876312 loss_att 399.498169 loss_ctc 26.085823 loss_rnnt 9.186367 lr 0.00024638 rank 1
2022-12-08 11:00:35,089 DEBUG TRAIN Batch 30/3500 loss 7.742105 loss_att 330.063599 loss_ctc 12.059448 loss_rnnt 7.262400 lr 0.00024633 rank 2
2022-12-08 11:00:35,090 DEBUG TRAIN Batch 30/3500 loss 13.069836 loss_att 302.931641 loss_ctc 19.869316 loss_rnnt 12.314338 lr 0.00024632 rank 3
2022-12-08 11:00:35,094 DEBUG TRAIN Batch 30/3500 loss 9.946500 loss_att 377.171692 loss_ctc 19.808022 loss_rnnt 8.850775 lr 0.00024631 rank 4
2022-12-08 11:00:35,096 DEBUG TRAIN Batch 30/3500 loss 11.191905 loss_att 356.909119 loss_ctc 19.575687 loss_rnnt 10.260373 lr 0.00024631 rank 7
2022-12-08 11:00:35,098 DEBUG TRAIN Batch 30/3500 loss 5.034627 loss_att 350.005859 loss_ctc 8.174274 loss_rnnt 4.685777 lr 0.00024630 rank 0
2022-12-08 11:00:35,100 DEBUG TRAIN Batch 30/3500 loss 2.857725 loss_att 360.682587 loss_ctc 7.924243 loss_rnnt 2.294779 lr 0.00024633 rank 5
2022-12-08 11:00:35,124 DEBUG TRAIN Batch 30/3500 loss 4.765167 loss_att 370.189270 loss_ctc 6.986259 loss_rnnt 4.518379 lr 0.00024635 rank 1
2022-12-08 11:00:35,141 DEBUG TRAIN Batch 30/3500 loss 6.560972 loss_att 333.706909 loss_ctc 11.906498 loss_rnnt 5.967025 lr 0.00024634 rank 6
2022-12-08 11:01:44,404 DEBUG TRAIN Batch 30/3600 loss 6.796495 loss_att 312.667542 loss_ctc 11.542236 loss_rnnt 6.269191 lr 0.00024628 rank 4
2022-12-08 11:01:44,411 DEBUG TRAIN Batch 30/3600 loss 4.601415 loss_att 389.899292 loss_ctc 11.436466 loss_rnnt 3.841965 lr 0.00024629 rank 3
2022-12-08 11:01:44,412 DEBUG TRAIN Batch 30/3600 loss 5.384355 loss_att 307.124237 loss_ctc 14.133018 loss_rnnt 4.412281 lr 0.00024631 rank 6
2022-12-08 11:01:44,413 DEBUG TRAIN Batch 30/3600 loss 4.355223 loss_att 313.893585 loss_ctc 7.130983 loss_rnnt 4.046805 lr 0.00024628 rank 7
2022-12-08 11:01:44,413 DEBUG TRAIN Batch 30/3600 loss 11.051651 loss_att 342.007385 loss_ctc 22.867403 loss_rnnt 9.738790 lr 0.00024630 rank 2
2022-12-08 11:01:44,416 DEBUG TRAIN Batch 30/3600 loss 7.052761 loss_att 422.984222 loss_ctc 17.622509 loss_rnnt 5.878344 lr 0.00024627 rank 0
2022-12-08 11:01:44,419 DEBUG TRAIN Batch 30/3600 loss 2.427521 loss_att 317.916809 loss_ctc 3.910718 loss_rnnt 2.262721 lr 0.00024632 rank 1
2022-12-08 11:01:44,458 DEBUG TRAIN Batch 30/3600 loss 9.341735 loss_att 358.072021 loss_ctc 15.593927 loss_rnnt 8.647047 lr 0.00024630 rank 5
2022-12-08 11:02:48,330 DEBUG TRAIN Batch 30/3700 loss 5.063049 loss_att 179.009583 loss_ctc 8.837422 loss_rnnt 4.643674 lr 0.00024625 rank 4
2022-12-08 11:02:48,335 DEBUG TRAIN Batch 30/3700 loss 7.746134 loss_att 305.933960 loss_ctc 11.837732 loss_rnnt 7.291512 lr 0.00024626 rank 3
2022-12-08 11:02:48,337 DEBUG TRAIN Batch 30/3700 loss 5.206691 loss_att 291.406158 loss_ctc 12.375168 loss_rnnt 4.410193 lr 0.00024628 rank 6
2022-12-08 11:02:48,338 DEBUG TRAIN Batch 30/3700 loss 9.970596 loss_att 346.245667 loss_ctc 23.413382 loss_rnnt 8.476954 lr 0.00024627 rank 2
2022-12-08 11:02:48,339 DEBUG TRAIN Batch 30/3700 loss 4.957320 loss_att 356.892181 loss_ctc 12.685398 loss_rnnt 4.098644 lr 0.00024625 rank 7
2022-12-08 11:02:48,340 DEBUG TRAIN Batch 30/3700 loss 5.243207 loss_att 304.946289 loss_ctc 7.938744 loss_rnnt 4.943703 lr 0.00024624 rank 0
2022-12-08 11:02:48,341 DEBUG TRAIN Batch 30/3700 loss 5.765154 loss_att 348.812012 loss_ctc 12.847734 loss_rnnt 4.978201 lr 0.00024627 rank 5
2022-12-08 11:02:48,351 DEBUG TRAIN Batch 30/3700 loss 6.866510 loss_att 222.457367 loss_ctc 12.498589 loss_rnnt 6.240724 lr 0.00024629 rank 1
2022-12-08 11:03:51,958 DEBUG TRAIN Batch 30/3800 loss 3.454704 loss_att 324.667816 loss_ctc 10.184230 loss_rnnt 2.706979 lr 0.00024622 rank 4
2022-12-08 11:03:51,959 DEBUG TRAIN Batch 30/3800 loss 4.478474 loss_att 285.086670 loss_ctc 11.318494 loss_rnnt 3.718471 lr 0.00024623 rank 3
2022-12-08 11:03:51,960 DEBUG TRAIN Batch 30/3800 loss 8.963819 loss_att 203.523056 loss_ctc 14.403971 loss_rnnt 8.359358 lr 0.00024622 rank 7
2022-12-08 11:03:51,961 DEBUG TRAIN Batch 30/3800 loss 4.553804 loss_att 438.227051 loss_ctc 7.904176 loss_rnnt 4.181540 lr 0.00024626 rank 1
2022-12-08 11:03:51,962 DEBUG TRAIN Batch 30/3800 loss 8.302917 loss_att 76.669594 loss_ctc 12.301232 loss_rnnt 7.858660 lr 0.00024624 rank 2
2022-12-08 11:03:51,963 DEBUG TRAIN Batch 30/3800 loss 2.618602 loss_att 317.480133 loss_ctc 8.717333 loss_rnnt 1.940966 lr 0.00024621 rank 0
2022-12-08 11:03:51,971 DEBUG TRAIN Batch 30/3800 loss 7.550211 loss_att 263.335541 loss_ctc 11.558024 loss_rnnt 7.104898 lr 0.00024624 rank 5
2022-12-08 11:03:52,005 DEBUG TRAIN Batch 30/3800 loss 13.087457 loss_att 368.904755 loss_ctc 29.413397 loss_rnnt 11.273464 lr 0.00024625 rank 6
2022-12-08 11:05:02,507 DEBUG TRAIN Batch 30/3900 loss 8.492867 loss_att 379.046967 loss_ctc 19.096607 loss_rnnt 7.314673 lr 0.00024621 rank 2
2022-12-08 11:05:02,519 DEBUG TRAIN Batch 30/3900 loss 8.075037 loss_att 396.612000 loss_ctc 20.716763 loss_rnnt 6.670402 lr 0.00024621 rank 5
2022-12-08 11:05:02,520 DEBUG TRAIN Batch 30/3900 loss 3.745044 loss_att 343.251434 loss_ctc 7.002720 loss_rnnt 3.383080 lr 0.00024619 rank 7
2022-12-08 11:05:02,521 DEBUG TRAIN Batch 30/3900 loss 5.214797 loss_att 382.882202 loss_ctc 12.872482 loss_rnnt 4.363943 lr 0.00024623 rank 1
2022-12-08 11:05:02,522 DEBUG TRAIN Batch 30/3900 loss 7.291389 loss_att 320.338135 loss_ctc 9.015465 loss_rnnt 7.099824 lr 0.00024619 rank 4
2022-12-08 11:05:02,523 DEBUG TRAIN Batch 30/3900 loss 8.722540 loss_att 78.392334 loss_ctc 11.651658 loss_rnnt 8.397082 lr 0.00024618 rank 0
2022-12-08 11:05:02,535 DEBUG TRAIN Batch 30/3900 loss 5.706106 loss_att 108.502762 loss_ctc 9.623817 loss_rnnt 5.270805 lr 0.00024620 rank 3
2022-12-08 11:05:02,570 DEBUG TRAIN Batch 30/3900 loss 13.262880 loss_att 325.598297 loss_ctc 29.643585 loss_rnnt 11.442802 lr 0.00024622 rank 6
2022-12-08 11:06:06,342 DEBUG TRAIN Batch 30/4000 loss 9.557186 loss_att 415.190674 loss_ctc 10.618858 loss_rnnt 9.439223 lr 0.00024618 rank 5
2022-12-08 11:06:06,347 DEBUG TRAIN Batch 30/4000 loss 7.096505 loss_att 335.137390 loss_ctc 13.206614 loss_rnnt 6.417604 lr 0.00024619 rank 6
2022-12-08 11:06:06,348 DEBUG TRAIN Batch 30/4000 loss 2.512227 loss_att 338.386475 loss_ctc 4.880260 loss_rnnt 2.249112 lr 0.00024616 rank 7
2022-12-08 11:06:06,350 DEBUG TRAIN Batch 30/4000 loss 3.060735 loss_att 383.975586 loss_ctc 10.287710 loss_rnnt 2.257738 lr 0.00024617 rank 3
2022-12-08 11:06:06,352 DEBUG TRAIN Batch 30/4000 loss 6.400111 loss_att 374.266449 loss_ctc 13.834010 loss_rnnt 5.574122 lr 0.00024615 rank 0
2022-12-08 11:06:06,355 DEBUG TRAIN Batch 30/4000 loss 10.060475 loss_att 379.395386 loss_ctc 19.355795 loss_rnnt 9.027662 lr 0.00024616 rank 4
2022-12-08 11:06:06,356 DEBUG TRAIN Batch 30/4000 loss 4.751716 loss_att 383.678192 loss_ctc 7.608143 loss_rnnt 4.434335 lr 0.00024620 rank 1
2022-12-08 11:06:06,358 DEBUG TRAIN Batch 30/4000 loss 3.928560 loss_att 413.974060 loss_ctc 11.338118 loss_rnnt 3.105276 lr 0.00024618 rank 2
2022-12-08 11:07:09,385 DEBUG TRAIN Batch 30/4100 loss 5.092715 loss_att 317.361328 loss_ctc 9.858409 loss_rnnt 4.563193 lr 0.00024613 rank 4
2022-12-08 11:07:09,386 DEBUG TRAIN Batch 30/4100 loss 2.571516 loss_att 320.961853 loss_ctc 9.495750 loss_rnnt 1.802156 lr 0.00024616 rank 6
2022-12-08 11:07:09,387 DEBUG TRAIN Batch 30/4100 loss 7.538601 loss_att 375.473755 loss_ctc 15.118841 loss_rnnt 6.696352 lr 0.00024613 rank 7
2022-12-08 11:07:09,389 DEBUG TRAIN Batch 30/4100 loss 7.189373 loss_att 385.381927 loss_ctc 15.184610 loss_rnnt 6.301014 lr 0.00024614 rank 3
2022-12-08 11:07:09,392 DEBUG TRAIN Batch 30/4100 loss 4.722602 loss_att 387.962799 loss_ctc 10.846579 loss_rnnt 4.042160 lr 0.00024617 rank 1
2022-12-08 11:07:09,395 DEBUG TRAIN Batch 30/4100 loss 2.847492 loss_att 363.377686 loss_ctc 8.121020 loss_rnnt 2.261544 lr 0.00024612 rank 0
2022-12-08 11:07:09,396 DEBUG TRAIN Batch 30/4100 loss 3.794161 loss_att 349.476501 loss_ctc 9.828881 loss_rnnt 3.123636 lr 0.00024615 rank 5
2022-12-08 11:07:09,404 DEBUG TRAIN Batch 30/4100 loss 8.921414 loss_att 298.383057 loss_ctc 13.834198 loss_rnnt 8.375550 lr 0.00024615 rank 2
2022-12-08 11:08:13,911 DEBUG TRAIN Batch 30/4200 loss 6.697269 loss_att 384.431213 loss_ctc 16.258797 loss_rnnt 5.634877 lr 0.00024615 rank 1
2022-12-08 11:08:13,924 DEBUG TRAIN Batch 30/4200 loss 6.983297 loss_att 319.641968 loss_ctc 16.449902 loss_rnnt 5.931452 lr 0.00024610 rank 4
2022-12-08 11:08:13,927 DEBUG TRAIN Batch 30/4200 loss 7.589134 loss_att 369.386353 loss_ctc 19.309418 loss_rnnt 6.286880 lr 0.00024610 rank 7
2022-12-08 11:08:13,927 DEBUG TRAIN Batch 30/4200 loss 5.772192 loss_att 393.343140 loss_ctc 9.827234 loss_rnnt 5.321632 lr 0.00024613 rank 6
2022-12-08 11:08:13,931 DEBUG TRAIN Batch 30/4200 loss 7.003371 loss_att 368.065521 loss_ctc 13.121737 loss_rnnt 6.323553 lr 0.00024609 rank 0
2022-12-08 11:08:13,931 DEBUG TRAIN Batch 30/4200 loss 7.795400 loss_att 324.833374 loss_ctc 13.152400 loss_rnnt 7.200178 lr 0.00024612 rank 2
2022-12-08 11:08:13,931 DEBUG TRAIN Batch 30/4200 loss 7.011965 loss_att 393.831421 loss_ctc 13.838074 loss_rnnt 6.253509 lr 0.00024612 rank 5
2022-12-08 11:08:13,931 DEBUG TRAIN Batch 30/4200 loss 2.818593 loss_att 341.980621 loss_ctc 6.933546 loss_rnnt 2.361376 lr 0.00024611 rank 3
2022-12-08 11:09:24,676 DEBUG TRAIN Batch 30/4300 loss 7.448282 loss_att 377.766174 loss_ctc 13.960245 loss_rnnt 6.724730 lr 0.00024607 rank 7
2022-12-08 11:09:24,678 DEBUG TRAIN Batch 30/4300 loss 9.757656 loss_att 311.827606 loss_ctc 18.945333 loss_rnnt 8.736803 lr 0.00024608 rank 4
2022-12-08 11:09:24,682 DEBUG TRAIN Batch 30/4300 loss 11.029508 loss_att 344.999939 loss_ctc 15.730227 loss_rnnt 10.507206 lr 0.00024606 rank 0
2022-12-08 11:09:24,682 DEBUG TRAIN Batch 30/4300 loss 4.594175 loss_att 309.140198 loss_ctc 12.467545 loss_rnnt 3.719356 lr 0.00024609 rank 2
2022-12-08 11:09:24,682 DEBUG TRAIN Batch 30/4300 loss 4.070386 loss_att 311.773743 loss_ctc 11.975780 loss_rnnt 3.192009 lr 0.00024608 rank 3
2022-12-08 11:09:24,683 DEBUG TRAIN Batch 30/4300 loss 8.395869 loss_att 301.477753 loss_ctc 15.746747 loss_rnnt 7.579105 lr 0.00024610 rank 6
2022-12-08 11:09:24,685 DEBUG TRAIN Batch 30/4300 loss 7.189731 loss_att 313.399719 loss_ctc 13.965474 loss_rnnt 6.436871 lr 0.00024609 rank 5
2022-12-08 11:09:24,689 DEBUG TRAIN Batch 30/4300 loss 9.653733 loss_att 253.867294 loss_ctc 21.263706 loss_rnnt 8.363736 lr 0.00024612 rank 1
2022-12-08 11:10:28,388 DEBUG TRAIN Batch 30/4400 loss 6.770264 loss_att 136.830200 loss_ctc 11.155624 loss_rnnt 6.283002 lr 0.00024606 rank 2
2022-12-08 11:10:28,390 DEBUG TRAIN Batch 30/4400 loss 7.390954 loss_att 133.096649 loss_ctc 12.233820 loss_rnnt 6.852858 lr 0.00024605 rank 4
2022-12-08 11:10:28,393 DEBUG TRAIN Batch 30/4400 loss 12.432878 loss_att 199.657242 loss_ctc 24.681303 loss_rnnt 11.071943 lr 0.00024609 rank 1
2022-12-08 11:10:28,393 DEBUG TRAIN Batch 30/4400 loss 10.335515 loss_att 229.002731 loss_ctc 18.630455 loss_rnnt 9.413856 lr 0.00024604 rank 7
2022-12-08 11:10:28,393 DEBUG TRAIN Batch 30/4400 loss 4.497665 loss_att 204.723297 loss_ctc 8.358048 loss_rnnt 4.068734 lr 0.00024607 rank 6
2022-12-08 11:10:28,396 DEBUG TRAIN Batch 30/4400 loss 3.641877 loss_att 319.461823 loss_ctc 7.676840 loss_rnnt 3.193547 lr 0.00024603 rank 0
2022-12-08 11:10:28,400 DEBUG TRAIN Batch 30/4400 loss 3.563273 loss_att 349.555420 loss_ctc 6.358283 loss_rnnt 3.252717 lr 0.00024605 rank 3
2022-12-08 11:10:28,402 DEBUG TRAIN Batch 30/4400 loss 5.908652 loss_att 325.035034 loss_ctc 10.769245 loss_rnnt 5.368587 lr 0.00024606 rank 5
2022-12-08 11:11:31,897 DEBUG TRAIN Batch 30/4500 loss 4.617191 loss_att 339.195618 loss_ctc 9.249051 loss_rnnt 4.102540 lr 0.00024606 rank 1
2022-12-08 11:11:31,897 DEBUG TRAIN Batch 30/4500 loss 2.062451 loss_att 328.811279 loss_ctc 9.356246 loss_rnnt 1.252030 lr 0.00024602 rank 4
2022-12-08 11:11:31,899 DEBUG TRAIN Batch 30/4500 loss 6.674763 loss_att 432.301514 loss_ctc 18.659414 loss_rnnt 5.343135 lr 0.00024603 rank 2
2022-12-08 11:11:31,900 DEBUG TRAIN Batch 30/4500 loss 8.529212 loss_att 174.967896 loss_ctc 15.761913 loss_rnnt 7.725579 lr 0.00024600 rank 0
2022-12-08 11:11:31,900 DEBUG TRAIN Batch 30/4500 loss 5.485662 loss_att 348.106781 loss_ctc 10.459738 loss_rnnt 4.932987 lr 0.00024601 rank 7
2022-12-08 11:11:31,900 DEBUG TRAIN Batch 30/4500 loss 5.898541 loss_att 203.193085 loss_ctc 12.579662 loss_rnnt 5.156195 lr 0.00024602 rank 3
2022-12-08 11:11:31,905 DEBUG TRAIN Batch 30/4500 loss 8.000495 loss_att 399.025146 loss_ctc 23.932653 loss_rnnt 6.230255 lr 0.00024604 rank 6
2022-12-08 11:11:31,906 DEBUG TRAIN Batch 30/4500 loss 7.233848 loss_att 159.844864 loss_ctc 13.364865 loss_rnnt 6.552624 lr 0.00024603 rank 5
2022-12-08 11:12:37,237 DEBUG TRAIN Batch 30/4600 loss 4.919631 loss_att 382.513885 loss_ctc 9.786451 loss_rnnt 4.378874 lr 0.00024601 rank 6
2022-12-08 11:12:37,239 DEBUG TRAIN Batch 30/4600 loss 7.105729 loss_att 384.602539 loss_ctc 13.871509 loss_rnnt 6.353976 lr 0.00024599 rank 4
2022-12-08 11:12:37,244 DEBUG TRAIN Batch 30/4600 loss 4.732584 loss_att 428.309814 loss_ctc 9.669370 loss_rnnt 4.184052 lr 0.00024597 rank 0
2022-12-08 11:12:37,245 DEBUG TRAIN Batch 30/4600 loss 4.080718 loss_att 439.920502 loss_ctc 16.148575 loss_rnnt 2.739844 lr 0.00024598 rank 7
2022-12-08 11:12:37,245 DEBUG TRAIN Batch 30/4600 loss 13.660619 loss_att 320.199677 loss_ctc 29.148138 loss_rnnt 11.939783 lr 0.00024600 rank 2
2022-12-08 11:12:37,248 DEBUG TRAIN Batch 30/4600 loss 7.271672 loss_att 389.322815 loss_ctc 11.093414 loss_rnnt 6.847034 lr 0.00024600 rank 5
2022-12-08 11:12:37,270 DEBUG TRAIN Batch 30/4600 loss 6.813885 loss_att 379.564209 loss_ctc 19.415791 loss_rnnt 5.413673 lr 0.00024599 rank 3
2022-12-08 11:12:37,273 DEBUG TRAIN Batch 30/4600 loss 1.556299 loss_att 303.311584 loss_ctc 3.991848 loss_rnnt 1.285682 lr 0.00024603 rank 1
2022-12-08 11:13:48,092 DEBUG TRAIN Batch 30/4700 loss 8.527370 loss_att 422.687622 loss_ctc 14.545336 loss_rnnt 7.858708 lr 0.00024595 rank 7
2022-12-08 11:13:48,097 DEBUG TRAIN Batch 30/4700 loss 4.763945 loss_att 371.409851 loss_ctc 10.179268 loss_rnnt 4.162243 lr 0.00024596 rank 4
2022-12-08 11:13:48,100 DEBUG TRAIN Batch 30/4700 loss 5.013129 loss_att 372.210754 loss_ctc 11.167602 loss_rnnt 4.329298 lr 0.00024600 rank 1
2022-12-08 11:13:48,101 DEBUG TRAIN Batch 30/4700 loss 6.068827 loss_att 380.034851 loss_ctc 8.238808 loss_rnnt 5.827718 lr 0.00024596 rank 3
2022-12-08 11:13:48,102 DEBUG TRAIN Batch 30/4700 loss 1.350059 loss_att 417.664520 loss_ctc 2.594990 loss_rnnt 1.211733 lr 0.00024597 rank 5
2022-12-08 11:13:48,103 DEBUG TRAIN Batch 30/4700 loss 7.786687 loss_att 376.937683 loss_ctc 22.915901 loss_rnnt 6.105663 lr 0.00024594 rank 0
2022-12-08 11:13:48,102 DEBUG TRAIN Batch 30/4700 loss 0.982956 loss_att 386.814514 loss_ctc 5.048360 loss_rnnt 0.531244 lr 0.00024597 rank 2
2022-12-08 11:13:48,138 DEBUG TRAIN Batch 30/4700 loss 15.827824 loss_att 408.224060 loss_ctc 34.322487 loss_rnnt 13.772861 lr 0.00024598 rank 6
2022-12-08 11:14:51,050 DEBUG TRAIN Batch 30/4800 loss 6.167885 loss_att 361.791321 loss_ctc 11.762933 loss_rnnt 5.546213 lr 0.00024593 rank 4
2022-12-08 11:14:51,056 DEBUG TRAIN Batch 30/4800 loss 2.599355 loss_att 374.178772 loss_ctc 6.846314 loss_rnnt 2.127471 lr 0.00024592 rank 7
2022-12-08 11:14:51,058 DEBUG TRAIN Batch 30/4800 loss 7.431555 loss_att 377.621094 loss_ctc 16.021837 loss_rnnt 6.477079 lr 0.00024591 rank 0
2022-12-08 11:14:51,058 DEBUG TRAIN Batch 30/4800 loss 4.924867 loss_att 450.730957 loss_ctc 19.287817 loss_rnnt 3.328983 lr 0.00024593 rank 3
2022-12-08 11:14:51,059 DEBUG TRAIN Batch 30/4800 loss 8.401384 loss_att 339.652954 loss_ctc 14.978781 loss_rnnt 7.670563 lr 0.00024595 rank 6
2022-12-08 11:14:51,061 DEBUG TRAIN Batch 30/4800 loss 5.490454 loss_att 374.982239 loss_ctc 10.180487 loss_rnnt 4.969339 lr 0.00024594 rank 5
2022-12-08 11:14:51,066 DEBUG TRAIN Batch 30/4800 loss 7.464479 loss_att 398.495117 loss_ctc 14.636445 loss_rnnt 6.667594 lr 0.00024594 rank 2
2022-12-08 11:14:51,107 DEBUG TRAIN Batch 30/4800 loss 5.081673 loss_att 345.329590 loss_ctc 8.172731 loss_rnnt 4.738222 lr 0.00024597 rank 1
2022-12-08 11:15:54,868 DEBUG TRAIN Batch 30/4900 loss 5.493630 loss_att 318.685547 loss_ctc 12.940753 loss_rnnt 4.666172 lr 0.00024591 rank 2
2022-12-08 11:15:54,874 DEBUG TRAIN Batch 30/4900 loss 10.467407 loss_att 410.777771 loss_ctc 16.862633 loss_rnnt 9.756827 lr 0.00024588 rank 0
2022-12-08 11:15:54,875 DEBUG TRAIN Batch 30/4900 loss 9.177010 loss_att 377.860382 loss_ctc 13.058123 loss_rnnt 8.745775 lr 0.00024590 rank 4
2022-12-08 11:15:54,878 DEBUG TRAIN Batch 30/4900 loss 7.646233 loss_att 304.519836 loss_ctc 11.903816 loss_rnnt 7.173168 lr 0.00024589 rank 7
2022-12-08 11:15:54,880 DEBUG TRAIN Batch 30/4900 loss 3.352318 loss_att 307.561523 loss_ctc 11.438801 loss_rnnt 2.453820 lr 0.00024594 rank 1
2022-12-08 11:15:54,880 DEBUG TRAIN Batch 30/4900 loss 2.937721 loss_att 307.181580 loss_ctc 7.705246 loss_rnnt 2.407996 lr 0.00024590 rank 3
2022-12-08 11:15:54,881 DEBUG TRAIN Batch 30/4900 loss 18.144382 loss_att 429.628754 loss_ctc 41.043270 loss_rnnt 15.600062 lr 0.00024591 rank 5
2022-12-08 11:15:54,882 DEBUG TRAIN Batch 30/4900 loss 9.609181 loss_att 337.185791 loss_ctc 15.071566 loss_rnnt 9.002251 lr 0.00024592 rank 6
2022-12-08 11:17:07,507 DEBUG TRAIN Batch 30/5000 loss 12.394117 loss_att 245.327637 loss_ctc 21.442005 loss_rnnt 11.388797 lr 0.00024587 rank 4
2022-12-08 11:17:07,510 DEBUG TRAIN Batch 30/5000 loss 11.547850 loss_att 311.472870 loss_ctc 22.624189 loss_rnnt 10.317145 lr 0.00024586 rank 7
2022-12-08 11:17:07,513 DEBUG TRAIN Batch 30/5000 loss 3.276416 loss_att 252.112946 loss_ctc 8.828639 loss_rnnt 2.659502 lr 0.00024589 rank 6
2022-12-08 11:17:07,514 DEBUG TRAIN Batch 30/5000 loss 4.847070 loss_att 262.690002 loss_ctc 12.877032 loss_rnnt 3.954852 lr 0.00024589 rank 2
2022-12-08 11:17:07,514 DEBUG TRAIN Batch 30/5000 loss 3.112526 loss_att 318.461060 loss_ctc 8.586787 loss_rnnt 2.504274 lr 0.00024586 rank 0
2022-12-08 11:17:07,516 DEBUG TRAIN Batch 30/5000 loss 14.498135 loss_att 384.530640 loss_ctc 26.714981 loss_rnnt 13.140707 lr 0.00024587 rank 3
2022-12-08 11:17:07,517 DEBUG TRAIN Batch 30/5000 loss 7.158250 loss_att 363.694458 loss_ctc 17.132484 loss_rnnt 6.050002 lr 0.00024588 rank 5
2022-12-08 11:17:07,522 DEBUG TRAIN Batch 30/5000 loss 7.125563 loss_att 180.416718 loss_ctc 13.513509 loss_rnnt 6.415792 lr 0.00024591 rank 1
2022-12-08 11:18:11,418 DEBUG TRAIN Batch 30/5100 loss 2.640310 loss_att 329.410736 loss_ctc 7.725645 loss_rnnt 2.075273 lr 0.00024586 rank 2
2022-12-08 11:18:11,419 DEBUG TRAIN Batch 30/5100 loss 6.921993 loss_att 104.777695 loss_ctc 12.535512 loss_rnnt 6.298269 lr 0.00024583 rank 7
2022-12-08 11:18:11,419 DEBUG TRAIN Batch 30/5100 loss 6.720560 loss_att 376.441132 loss_ctc 15.023237 loss_rnnt 5.798040 lr 0.00024584 rank 4
2022-12-08 11:18:11,422 DEBUG TRAIN Batch 30/5100 loss 9.060818 loss_att 257.047424 loss_ctc 16.269989 loss_rnnt 8.259799 lr 0.00024584 rank 3
2022-12-08 11:18:11,423 DEBUG TRAIN Batch 30/5100 loss 9.133946 loss_att 368.806488 loss_ctc 11.771255 loss_rnnt 8.840912 lr 0.00024588 rank 1
2022-12-08 11:18:11,424 DEBUG TRAIN Batch 30/5100 loss 6.873783 loss_att 444.341248 loss_ctc 24.813330 loss_rnnt 4.880500 lr 0.00024586 rank 6
2022-12-08 11:18:11,429 DEBUG TRAIN Batch 30/5100 loss 17.185724 loss_att 299.315338 loss_ctc 36.408016 loss_rnnt 15.049913 lr 0.00024585 rank 5
2022-12-08 11:18:11,435 DEBUG TRAIN Batch 30/5100 loss 9.093650 loss_att 280.761169 loss_ctc 17.277378 loss_rnnt 8.184347 lr 0.00024583 rank 0
2022-12-08 11:19:15,202 DEBUG TRAIN Batch 30/5200 loss 3.162594 loss_att 363.864380 loss_ctc 8.825119 loss_rnnt 2.533425 lr 0.00024581 rank 4
2022-12-08 11:19:15,203 DEBUG TRAIN Batch 30/5200 loss 7.881398 loss_att 365.011292 loss_ctc 14.180784 loss_rnnt 7.181467 lr 0.00024580 rank 7
2022-12-08 11:19:15,205 DEBUG TRAIN Batch 30/5200 loss 4.163956 loss_att 380.847412 loss_ctc 8.568195 loss_rnnt 3.674596 lr 0.00024583 rank 2
2022-12-08 11:19:15,205 DEBUG TRAIN Batch 30/5200 loss 5.700804 loss_att 426.139648 loss_ctc 14.634687 loss_rnnt 4.708150 lr 0.00024581 rank 3
2022-12-08 11:19:15,207 DEBUG TRAIN Batch 30/5200 loss 8.246368 loss_att 447.565765 loss_ctc 20.117849 loss_rnnt 6.927316 lr 0.00024583 rank 6
2022-12-08 11:19:15,211 DEBUG TRAIN Batch 30/5200 loss 10.727087 loss_att 451.629700 loss_ctc 19.541447 loss_rnnt 9.747714 lr 0.00024580 rank 0
2022-12-08 11:19:15,213 DEBUG TRAIN Batch 30/5200 loss 8.567730 loss_att 351.504211 loss_ctc 18.699581 loss_rnnt 7.441969 lr 0.00024585 rank 1
2022-12-08 11:19:15,253 DEBUG TRAIN Batch 30/5200 loss 1.420235 loss_att 344.213928 loss_ctc 4.528989 loss_rnnt 1.074818 lr 0.00024582 rank 5
2022-12-08 11:20:20,802 DEBUG TRAIN Batch 30/5300 loss 1.851417 loss_att 396.447693 loss_ctc 5.192324 loss_rnnt 1.480205 lr 0.00024577 rank 0
2022-12-08 11:20:20,810 DEBUG TRAIN Batch 30/5300 loss 4.892799 loss_att 368.451111 loss_ctc 6.460183 loss_rnnt 4.718645 lr 0.00024580 rank 6
2022-12-08 11:20:20,813 DEBUG TRAIN Batch 30/5300 loss 3.757231 loss_att 372.990082 loss_ctc 6.426551 loss_rnnt 3.460640 lr 0.00024578 rank 3
2022-12-08 11:20:20,815 DEBUG TRAIN Batch 30/5300 loss 13.287235 loss_att 322.103149 loss_ctc 22.037117 loss_rnnt 12.315027 lr 0.00024578 rank 4
2022-12-08 11:20:20,819 DEBUG TRAIN Batch 30/5300 loss 9.939307 loss_att 489.676392 loss_ctc 27.308943 loss_rnnt 8.009348 lr 0.00024579 rank 5
2022-12-08 11:20:20,820 DEBUG TRAIN Batch 30/5300 loss 4.019523 loss_att 396.551971 loss_ctc 13.331157 loss_rnnt 2.984897 lr 0.00024582 rank 1
2022-12-08 11:20:20,838 DEBUG TRAIN Batch 30/5300 loss 3.632057 loss_att 414.124695 loss_ctc 8.040816 loss_rnnt 3.142195 lr 0.00024577 rank 7
2022-12-08 11:20:20,850 DEBUG TRAIN Batch 30/5300 loss 4.364466 loss_att 366.819519 loss_ctc 10.639449 loss_rnnt 3.667245 lr 0.00024580 rank 2
2022-12-08 11:21:31,447 DEBUG TRAIN Batch 30/5400 loss 4.665658 loss_att 323.985474 loss_ctc 7.647960 loss_rnnt 4.334292 lr 0.00024575 rank 4
2022-12-08 11:21:31,448 DEBUG TRAIN Batch 30/5400 loss 6.266767 loss_att 342.345947 loss_ctc 16.315418 loss_rnnt 5.150250 lr 0.00024574 rank 7
2022-12-08 11:21:31,449 DEBUG TRAIN Batch 30/5400 loss 8.213400 loss_att 391.220032 loss_ctc 21.015068 loss_rnnt 6.790992 lr 0.00024575 rank 3
2022-12-08 11:21:31,450 DEBUG TRAIN Batch 30/5400 loss 8.193130 loss_att 359.438019 loss_ctc 16.935692 loss_rnnt 7.221734 lr 0.00024578 rank 6
2022-12-08 11:21:31,455 DEBUG TRAIN Batch 30/5400 loss 3.974717 loss_att 435.650146 loss_ctc 11.460661 loss_rnnt 3.142946 lr 0.00024577 rank 2
2022-12-08 11:21:31,456 DEBUG TRAIN Batch 30/5400 loss 14.837837 loss_att 376.930176 loss_ctc 28.592279 loss_rnnt 13.309566 lr 0.00024579 rank 1
2022-12-08 11:21:31,459 DEBUG TRAIN Batch 30/5400 loss 5.147973 loss_att 337.746521 loss_ctc 10.203991 loss_rnnt 4.586193 lr 0.00024574 rank 0
2022-12-08 11:21:31,459 DEBUG TRAIN Batch 30/5400 loss 9.902933 loss_att 357.944031 loss_ctc 18.504423 loss_rnnt 8.947213 lr 0.00024576 rank 5
2022-12-08 11:22:35,204 DEBUG TRAIN Batch 30/5500 loss 10.650204 loss_att 343.797943 loss_ctc 21.205879 loss_rnnt 9.477350 lr 0.00024572 rank 4
2022-12-08 11:22:35,207 DEBUG TRAIN Batch 30/5500 loss 18.213898 loss_att 405.410095 loss_ctc 32.697075 loss_rnnt 16.604656 lr 0.00024571 rank 7
2022-12-08 11:22:35,208 DEBUG TRAIN Batch 30/5500 loss 9.591274 loss_att 362.426880 loss_ctc 18.676334 loss_rnnt 8.581823 lr 0.00024574 rank 2
2022-12-08 11:22:35,208 DEBUG TRAIN Batch 30/5500 loss 3.732931 loss_att 363.709015 loss_ctc 14.124574 loss_rnnt 2.578304 lr 0.00024573 rank 3
2022-12-08 11:22:35,209 DEBUG TRAIN Batch 30/5500 loss 7.163896 loss_att 394.248840 loss_ctc 24.108118 loss_rnnt 5.281204 lr 0.00024575 rank 6
2022-12-08 11:22:35,211 DEBUG TRAIN Batch 30/5500 loss 4.154878 loss_att 374.760376 loss_ctc 8.519827 loss_rnnt 3.669884 lr 0.00024571 rank 0
2022-12-08 11:22:35,211 DEBUG TRAIN Batch 30/5500 loss 12.684988 loss_att 352.808960 loss_ctc 23.800873 loss_rnnt 11.449890 lr 0.00024576 rank 1
2022-12-08 11:22:35,213 DEBUG TRAIN Batch 30/5500 loss 5.679057 loss_att 393.014648 loss_ctc 12.184214 loss_rnnt 4.956262 lr 0.00024573 rank 5
2022-12-08 11:23:38,516 DEBUG TRAIN Batch 30/5600 loss 7.921285 loss_att 257.324432 loss_ctc 13.067415 loss_rnnt 7.349493 lr 0.00024569 rank 4
2022-12-08 11:23:38,521 DEBUG TRAIN Batch 30/5600 loss 6.855486 loss_att 360.507111 loss_ctc 11.887207 loss_rnnt 6.296407 lr 0.00024571 rank 2
2022-12-08 11:23:38,525 DEBUG TRAIN Batch 30/5600 loss 13.063413 loss_att 280.699799 loss_ctc 30.007236 loss_rnnt 11.180765 lr 0.00024573 rank 1
2022-12-08 11:23:38,528 DEBUG TRAIN Batch 30/5600 loss 9.945436 loss_att 296.339172 loss_ctc 21.432627 loss_rnnt 8.669081 lr 0.00024568 rank 7
2022-12-08 11:23:38,533 DEBUG TRAIN Batch 30/5600 loss 5.171335 loss_att 356.531738 loss_ctc 10.196730 loss_rnnt 4.612958 lr 0.00024570 rank 3
2022-12-08 11:23:38,533 DEBUG TRAIN Batch 30/5600 loss 9.309533 loss_att 385.300110 loss_ctc 23.169796 loss_rnnt 7.769504 lr 0.00024568 rank 0
2022-12-08 11:23:38,536 DEBUG TRAIN Batch 30/5600 loss 4.684530 loss_att 354.398254 loss_ctc 11.347291 loss_rnnt 3.944223 lr 0.00024572 rank 6
2022-12-08 11:23:38,544 DEBUG TRAIN Batch 30/5600 loss 2.503558 loss_att 361.045837 loss_ctc 6.025394 loss_rnnt 2.112243 lr 0.00024570 rank 5
2022-12-08 11:24:50,246 DEBUG TRAIN Batch 30/5700 loss 12.303671 loss_att 331.945465 loss_ctc 22.786787 loss_rnnt 11.138881 lr 0.00024567 rank 5
2022-12-08 11:24:50,252 DEBUG TRAIN Batch 30/5700 loss 7.696510 loss_att 199.439529 loss_ctc 13.252499 loss_rnnt 7.079179 lr 0.00024568 rank 2
2022-12-08 11:24:50,254 DEBUG TRAIN Batch 30/5700 loss 8.016814 loss_att 305.232666 loss_ctc 12.056254 loss_rnnt 7.567988 lr 0.00024567 rank 3
2022-12-08 11:24:50,255 DEBUG TRAIN Batch 30/5700 loss 11.412014 loss_att 341.204224 loss_ctc 19.586720 loss_rnnt 10.503715 lr 0.00024565 rank 0
2022-12-08 11:24:50,257 DEBUG TRAIN Batch 30/5700 loss 6.938565 loss_att 81.383385 loss_ctc 11.734424 loss_rnnt 6.405692 lr 0.00024565 rank 7
2022-12-08 11:24:50,280 DEBUG TRAIN Batch 30/5700 loss 10.926517 loss_att 187.550705 loss_ctc 20.680880 loss_rnnt 9.842700 lr 0.00024569 rank 6
2022-12-08 11:24:50,287 DEBUG TRAIN Batch 30/5700 loss 6.113452 loss_att 359.292419 loss_ctc 13.662071 loss_rnnt 5.274717 lr 0.00024566 rank 4
2022-12-08 11:24:50,300 DEBUG TRAIN Batch 30/5700 loss 4.202986 loss_att 327.040131 loss_ctc 11.402679 loss_rnnt 3.403020 lr 0.00024570 rank 1
2022-12-08 11:25:53,722 DEBUG TRAIN Batch 30/5800 loss 1.483518 loss_att 262.196777 loss_ctc 3.128509 loss_rnnt 1.300741 lr 0.00024563 rank 4
2022-12-08 11:25:53,724 DEBUG TRAIN Batch 30/5800 loss 5.481959 loss_att 411.571350 loss_ctc 12.395923 loss_rnnt 4.713741 lr 0.00024565 rank 2
2022-12-08 11:25:53,727 DEBUG TRAIN Batch 30/5800 loss 5.426630 loss_att 358.112305 loss_ctc 10.778086 loss_rnnt 4.832024 lr 0.00024562 rank 7
2022-12-08 11:25:53,727 DEBUG TRAIN Batch 30/5800 loss 10.073544 loss_att 392.492157 loss_ctc 22.918781 loss_rnnt 8.646296 lr 0.00024567 rank 1
2022-12-08 11:25:53,728 DEBUG TRAIN Batch 30/5800 loss 8.323817 loss_att 302.349457 loss_ctc 11.214155 loss_rnnt 8.002669 lr 0.00024562 rank 0
2022-12-08 11:25:53,730 DEBUG TRAIN Batch 30/5800 loss 6.680517 loss_att 380.768158 loss_ctc 13.609976 loss_rnnt 5.910577 lr 0.00024566 rank 6
2022-12-08 11:25:53,732 DEBUG TRAIN Batch 30/5800 loss 6.205233 loss_att 185.277588 loss_ctc 12.466717 loss_rnnt 5.509513 lr 0.00024564 rank 3
2022-12-08 11:25:53,740 DEBUG TRAIN Batch 30/5800 loss 2.846740 loss_att 377.890381 loss_ctc 8.003478 loss_rnnt 2.273769 lr 0.00024564 rank 5
2022-12-08 11:26:58,107 DEBUG TRAIN Batch 30/5900 loss 5.305228 loss_att 431.295868 loss_ctc 11.009501 loss_rnnt 4.671420 lr 0.00024559 rank 7
2022-12-08 11:26:58,110 DEBUG TRAIN Batch 30/5900 loss 16.540588 loss_att 383.832092 loss_ctc 26.027596 loss_rnnt 15.486477 lr 0.00024560 rank 4
2022-12-08 11:26:58,111 DEBUG TRAIN Batch 30/5900 loss 7.827912 loss_att 375.639404 loss_ctc 14.671791 loss_rnnt 7.067482 lr 0.00024563 rank 6
2022-12-08 11:26:58,112 DEBUG TRAIN Batch 30/5900 loss 6.181960 loss_att 451.935791 loss_ctc 12.595877 loss_rnnt 5.469303 lr 0.00024559 rank 0
2022-12-08 11:26:58,113 DEBUG TRAIN Batch 30/5900 loss 5.904509 loss_att 425.636810 loss_ctc 16.273113 loss_rnnt 4.752441 lr 0.00024561 rank 5
2022-12-08 11:26:58,116 DEBUG TRAIN Batch 30/5900 loss 5.746467 loss_att 307.472260 loss_ctc 7.870041 loss_rnnt 5.510515 lr 0.00024562 rank 2
2022-12-08 11:26:58,117 DEBUG TRAIN Batch 30/5900 loss 12.247290 loss_att 384.383148 loss_ctc 21.967243 loss_rnnt 11.167295 lr 0.00024561 rank 3
2022-12-08 11:26:58,117 DEBUG TRAIN Batch 30/5900 loss 15.555914 loss_att 417.948364 loss_ctc 34.025284 loss_rnnt 13.503761 lr 0.00024564 rank 1
2022-12-08 11:28:02,244 DEBUG TRAIN Batch 30/6000 loss 2.721774 loss_att 375.585907 loss_ctc 10.266542 loss_rnnt 1.883466 lr 0.00024558 rank 3
2022-12-08 11:28:02,249 DEBUG TRAIN Batch 30/6000 loss 4.817047 loss_att 424.254547 loss_ctc 11.735561 loss_rnnt 4.048323 lr 0.00024557 rank 4
2022-12-08 11:28:02,255 DEBUG TRAIN Batch 30/6000 loss 2.684198 loss_att 346.077942 loss_ctc 8.347421 loss_rnnt 2.054952 lr 0.00024559 rank 2
2022-12-08 11:28:02,257 DEBUG TRAIN Batch 30/6000 loss 6.372601 loss_att 373.655914 loss_ctc 11.429523 loss_rnnt 5.810720 lr 0.00024557 rank 7
2022-12-08 11:28:02,260 DEBUG TRAIN Batch 30/6000 loss 3.773686 loss_att 376.637634 loss_ctc 9.807617 loss_rnnt 3.103250 lr 0.00024558 rank 5
2022-12-08 11:28:02,260 DEBUG TRAIN Batch 30/6000 loss 4.119100 loss_att 393.775146 loss_ctc 6.821065 loss_rnnt 3.818882 lr 0.00024561 rank 1
2022-12-08 11:28:02,263 DEBUG TRAIN Batch 30/6000 loss 5.623654 loss_att 408.341736 loss_ctc 12.676959 loss_rnnt 4.839953 lr 0.00024556 rank 0
2022-12-08 11:28:02,301 DEBUG TRAIN Batch 30/6000 loss 5.242004 loss_att 311.103241 loss_ctc 12.881659 loss_rnnt 4.393154 lr 0.00024560 rank 6
2022-12-08 11:29:13,363 DEBUG TRAIN Batch 30/6100 loss 3.115258 loss_att 339.798462 loss_ctc 8.192824 loss_rnnt 2.551084 lr 0.00024553 rank 0
2022-12-08 11:29:13,362 DEBUG TRAIN Batch 30/6100 loss 4.330273 loss_att 402.867859 loss_ctc 8.420506 loss_rnnt 3.875803 lr 0.00024556 rank 2
2022-12-08 11:29:13,362 DEBUG TRAIN Batch 30/6100 loss 19.056778 loss_att 332.686646 loss_ctc 27.572853 loss_rnnt 18.110546 lr 0.00024554 rank 4
2022-12-08 11:29:13,364 DEBUG TRAIN Batch 30/6100 loss 9.429634 loss_att 402.069519 loss_ctc 17.018547 loss_rnnt 8.586421 lr 0.00024554 rank 7
2022-12-08 11:29:13,365 DEBUG TRAIN Batch 30/6100 loss 7.374980 loss_att 350.203064 loss_ctc 20.445782 loss_rnnt 5.922668 lr 0.00024558 rank 1
2022-12-08 11:29:13,367 DEBUG TRAIN Batch 30/6100 loss 4.839473 loss_att 361.986023 loss_ctc 6.879673 loss_rnnt 4.612784 lr 0.00024557 rank 6
2022-12-08 11:29:13,367 DEBUG TRAIN Batch 30/6100 loss 3.689071 loss_att 418.257568 loss_ctc 9.061095 loss_rnnt 3.092180 lr 0.00024555 rank 5
2022-12-08 11:29:13,366 DEBUG TRAIN Batch 30/6100 loss 8.698946 loss_att 409.833862 loss_ctc 18.465824 loss_rnnt 7.613738 lr 0.00024555 rank 3
2022-12-08 11:30:16,652 DEBUG TRAIN Batch 30/6200 loss 4.701957 loss_att 233.961227 loss_ctc 9.282100 loss_rnnt 4.193052 lr 0.00024551 rank 4
2022-12-08 11:30:16,654 DEBUG TRAIN Batch 30/6200 loss 1.550744 loss_att 301.093353 loss_ctc 5.584149 loss_rnnt 1.102588 lr 0.00024553 rank 2
2022-12-08 11:30:16,654 DEBUG TRAIN Batch 30/6200 loss 5.011985 loss_att 295.043579 loss_ctc 12.811536 loss_rnnt 4.145368 lr 0.00024550 rank 0
2022-12-08 11:30:16,655 DEBUG TRAIN Batch 30/6200 loss 11.563372 loss_att 385.358215 loss_ctc 22.968430 loss_rnnt 10.296143 lr 0.00024552 rank 3
2022-12-08 11:30:16,657 DEBUG TRAIN Batch 30/6200 loss 6.492674 loss_att 297.797852 loss_ctc 11.619287 loss_rnnt 5.923050 lr 0.00024551 rank 7
2022-12-08 11:30:16,658 DEBUG TRAIN Batch 30/6200 loss 8.679782 loss_att 280.558105 loss_ctc 14.622635 loss_rnnt 8.019465 lr 0.00024554 rank 6
2022-12-08 11:30:16,659 DEBUG TRAIN Batch 30/6200 loss 13.513953 loss_att 362.850952 loss_ctc 23.655048 loss_rnnt 12.387165 lr 0.00024555 rank 1
2022-12-08 11:30:16,667 DEBUG TRAIN Batch 30/6200 loss 4.437205 loss_att 362.479858 loss_ctc 9.274313 loss_rnnt 3.899749 lr 0.00024552 rank 5
2022-12-08 11:31:20,598 DEBUG TRAIN Batch 30/6300 loss 5.686346 loss_att 175.308716 loss_ctc 10.213966 loss_rnnt 5.183277 lr 0.00024548 rank 7
2022-12-08 11:31:20,605 DEBUG TRAIN Batch 30/6300 loss 9.923166 loss_att 384.767944 loss_ctc 20.868454 loss_rnnt 8.707023 lr 0.00024547 rank 0
2022-12-08 11:31:20,609 DEBUG TRAIN Batch 30/6300 loss 5.554413 loss_att 396.378601 loss_ctc 15.136401 loss_rnnt 4.489747 lr 0.00024548 rank 4
2022-12-08 11:31:20,610 DEBUG TRAIN Batch 30/6300 loss 9.864888 loss_att 391.506195 loss_ctc 18.333405 loss_rnnt 8.923942 lr 0.00024551 rank 6
2022-12-08 11:31:20,610 DEBUG TRAIN Batch 30/6300 loss 7.630651 loss_att 308.758270 loss_ctc 14.023132 loss_rnnt 6.920376 lr 0.00024550 rank 2
2022-12-08 11:31:20,611 DEBUG TRAIN Batch 30/6300 loss 8.209585 loss_att 211.632950 loss_ctc 14.785244 loss_rnnt 7.478957 lr 0.00024552 rank 1
2022-12-08 11:31:20,612 DEBUG TRAIN Batch 30/6300 loss 13.439232 loss_att 341.064087 loss_ctc 32.185368 loss_rnnt 11.356329 lr 0.00024549 rank 3
2022-12-08 11:31:20,643 DEBUG TRAIN Batch 30/6300 loss 2.320500 loss_att 371.895630 loss_ctc 6.431551 loss_rnnt 1.863717 lr 0.00024549 rank 5
2022-12-08 11:32:29,907 DEBUG TRAIN Batch 30/6400 loss 8.852425 loss_att 333.613647 loss_ctc 13.333307 loss_rnnt 8.354548 lr 0.00024545 rank 4
2022-12-08 11:32:29,916 DEBUG TRAIN Batch 30/6400 loss 3.414174 loss_att 240.425339 loss_ctc 7.125541 loss_rnnt 3.001800 lr 0.00024546 rank 3
2022-12-08 11:32:29,916 DEBUG TRAIN Batch 30/6400 loss 6.361086 loss_att 405.687958 loss_ctc 10.554660 loss_rnnt 5.895133 lr 0.00024548 rank 6
2022-12-08 11:32:29,918 DEBUG TRAIN Batch 30/6400 loss 4.303304 loss_att 220.982071 loss_ctc 9.653846 loss_rnnt 3.708800 lr 0.00024547 rank 5
2022-12-08 11:32:29,921 DEBUG TRAIN Batch 30/6400 loss 10.436021 loss_att 218.485138 loss_ctc 17.711752 loss_rnnt 9.627606 lr 0.00024544 rank 0
2022-12-08 11:32:29,921 DEBUG TRAIN Batch 30/6400 loss 6.427965 loss_att 415.486145 loss_ctc 12.108641 loss_rnnt 5.796779 lr 0.00024547 rank 2
2022-12-08 11:32:29,929 DEBUG TRAIN Batch 30/6400 loss 2.680147 loss_att 309.413788 loss_ctc 4.422923 loss_rnnt 2.486505 lr 0.00024549 rank 1
2022-12-08 11:32:29,937 DEBUG TRAIN Batch 30/6400 loss 8.844403 loss_att 455.634399 loss_ctc 17.598001 loss_rnnt 7.871782 lr 0.00024545 rank 7
2022-12-08 11:33:36,641 DEBUG TRAIN Batch 30/6500 loss 6.940579 loss_att 333.314941 loss_ctc 16.354610 loss_rnnt 5.894576 lr 0.00024542 rank 4
2022-12-08 11:33:36,645 DEBUG TRAIN Batch 30/6500 loss 6.234648 loss_att 403.568695 loss_ctc 8.818922 loss_rnnt 5.947507 lr 0.00024544 rank 2
2022-12-08 11:33:36,646 DEBUG TRAIN Batch 30/6500 loss 19.373676 loss_att 351.067383 loss_ctc 36.074883 loss_rnnt 17.517986 lr 0.00024545 rank 6
2022-12-08 11:33:36,647 DEBUG TRAIN Batch 30/6500 loss 11.747433 loss_att 368.903259 loss_ctc 20.248360 loss_rnnt 10.802885 lr 0.00024542 rank 7
2022-12-08 11:33:36,648 DEBUG TRAIN Batch 30/6500 loss 2.909255 loss_att 329.247925 loss_ctc 8.186169 loss_rnnt 2.322931 lr 0.00024544 rank 5
2022-12-08 11:33:36,649 DEBUG TRAIN Batch 30/6500 loss 2.919820 loss_att 440.032166 loss_ctc 7.985214 loss_rnnt 2.356999 lr 0.00024543 rank 3
2022-12-08 11:33:36,650 DEBUG TRAIN Batch 30/6500 loss 9.339768 loss_att 373.254578 loss_ctc 16.316053 loss_rnnt 8.564626 lr 0.00024546 rank 1
2022-12-08 11:33:36,652 DEBUG TRAIN Batch 30/6500 loss 2.913714 loss_att 337.154755 loss_ctc 5.776251 loss_rnnt 2.595654 lr 0.00024541 rank 0
2022-12-08 11:34:39,189 DEBUG TRAIN Batch 30/6600 loss 5.895657 loss_att 391.790771 loss_ctc 12.755392 loss_rnnt 5.133464 lr 0.00024539 rank 7
2022-12-08 11:34:39,191 DEBUG TRAIN Batch 30/6600 loss 2.726064 loss_att 334.874146 loss_ctc 9.404327 loss_rnnt 1.984035 lr 0.00024539 rank 4
2022-12-08 11:34:39,194 DEBUG TRAIN Batch 30/6600 loss 7.980206 loss_att 384.685059 loss_ctc 15.621487 loss_rnnt 7.131176 lr 0.00024542 rank 6
2022-12-08 11:34:39,197 DEBUG TRAIN Batch 30/6600 loss 4.805391 loss_att 386.784363 loss_ctc 12.085201 loss_rnnt 3.996524 lr 0.00024541 rank 5
2022-12-08 11:34:39,198 DEBUG TRAIN Batch 30/6600 loss 5.448040 loss_att 351.558289 loss_ctc 16.937351 loss_rnnt 4.171451 lr 0.00024543 rank 1
2022-12-08 11:34:39,199 DEBUG TRAIN Batch 30/6600 loss 9.105933 loss_att 422.149170 loss_ctc 20.052513 loss_rnnt 7.889647 lr 0.00024541 rank 2
2022-12-08 11:34:39,199 DEBUG TRAIN Batch 30/6600 loss 2.959661 loss_att 352.341644 loss_ctc 5.539171 loss_rnnt 2.673048 lr 0.00024540 rank 3
2022-12-08 11:34:39,200 DEBUG TRAIN Batch 30/6600 loss 4.424539 loss_att 422.076843 loss_ctc 10.693933 loss_rnnt 3.727939 lr 0.00024538 rank 0
2022-12-08 11:35:44,264 DEBUG TRAIN Batch 30/6700 loss 10.112867 loss_att 425.738281 loss_ctc 18.607607 loss_rnnt 9.169007 lr 0.00024539 rank 6
2022-12-08 11:35:44,274 DEBUG TRAIN Batch 30/6700 loss 3.274623 loss_att 352.503998 loss_ctc 10.458311 loss_rnnt 2.476436 lr 0.00024536 rank 7
2022-12-08 11:35:44,276 DEBUG TRAIN Batch 30/6700 loss 10.755674 loss_att 350.564331 loss_ctc 18.881340 loss_rnnt 9.852823 lr 0.00024535 rank 0
2022-12-08 11:35:44,276 DEBUG TRAIN Batch 30/6700 loss 4.177489 loss_att 373.056213 loss_ctc 8.565971 loss_rnnt 3.689880 lr 0.00024536 rank 4
2022-12-08 11:35:44,282 DEBUG TRAIN Batch 30/6700 loss 6.628119 loss_att 362.421265 loss_ctc 19.992165 loss_rnnt 5.143226 lr 0.00024538 rank 2
2022-12-08 11:35:44,291 DEBUG TRAIN Batch 30/6700 loss 5.336717 loss_att 412.424377 loss_ctc 16.012945 loss_rnnt 4.150470 lr 0.00024537 rank 3
2022-12-08 11:35:44,297 DEBUG TRAIN Batch 30/6700 loss 6.397507 loss_att 306.897156 loss_ctc 15.234702 loss_rnnt 5.415596 lr 0.00024538 rank 5
2022-12-08 11:35:44,303 DEBUG TRAIN Batch 30/6700 loss 6.354549 loss_att 321.365814 loss_ctc 18.426167 loss_rnnt 5.013258 lr 0.00024540 rank 1
2022-12-08 11:36:55,873 DEBUG TRAIN Batch 30/6800 loss 8.634209 loss_att 341.019104 loss_ctc 14.727468 loss_rnnt 7.957181 lr 0.00024533 rank 7
2022-12-08 11:36:55,874 DEBUG TRAIN Batch 30/6800 loss 7.613330 loss_att 385.666443 loss_ctc 16.487137 loss_rnnt 6.627352 lr 0.00024534 rank 3
2022-12-08 11:36:55,876 DEBUG TRAIN Batch 30/6800 loss 8.717069 loss_att 325.498322 loss_ctc 14.125474 loss_rnnt 8.116135 lr 0.00024537 rank 1
2022-12-08 11:36:55,878 DEBUG TRAIN Batch 30/6800 loss 7.530476 loss_att 399.091125 loss_ctc 15.910956 loss_rnnt 6.599311 lr 0.00024532 rank 0
2022-12-08 11:36:55,881 DEBUG TRAIN Batch 30/6800 loss 4.786138 loss_att 312.414490 loss_ctc 9.767494 loss_rnnt 4.232654 lr 0.00024533 rank 4
2022-12-08 11:36:55,882 DEBUG TRAIN Batch 30/6800 loss 7.298324 loss_att 405.824524 loss_ctc 14.809824 loss_rnnt 6.463713 lr 0.00024535 rank 5
2022-12-08 11:36:55,885 DEBUG TRAIN Batch 30/6800 loss 5.208011 loss_att 386.186035 loss_ctc 11.758274 loss_rnnt 4.480204 lr 0.00024535 rank 2
2022-12-08 11:36:55,912 DEBUG TRAIN Batch 30/6800 loss 7.713861 loss_att 326.650330 loss_ctc 13.090110 loss_rnnt 7.116500 lr 0.00024536 rank 6
2022-12-08 11:38:00,472 DEBUG TRAIN Batch 30/6900 loss 5.412001 loss_att 365.865997 loss_ctc 12.109783 loss_rnnt 4.667803 lr 0.00024531 rank 3
2022-12-08 11:38:00,475 DEBUG TRAIN Batch 30/6900 loss 7.686403 loss_att 325.473877 loss_ctc 10.761284 loss_rnnt 7.344749 lr 0.00024530 rank 7
2022-12-08 11:38:00,475 DEBUG TRAIN Batch 30/6900 loss 8.225026 loss_att 428.739014 loss_ctc 16.129236 loss_rnnt 7.346781 lr 0.00024530 rank 4
2022-12-08 11:38:00,476 DEBUG TRAIN Batch 30/6900 loss 8.784616 loss_att 171.472275 loss_ctc 15.544907 loss_rnnt 8.033472 lr 0.00024533 rank 6
2022-12-08 11:38:00,477 DEBUG TRAIN Batch 30/6900 loss 9.774452 loss_att 290.578400 loss_ctc 17.967539 loss_rnnt 8.864110 lr 0.00024534 rank 1
2022-12-08 11:38:00,478 DEBUG TRAIN Batch 30/6900 loss 12.835118 loss_att 338.448456 loss_ctc 20.786001 loss_rnnt 11.951688 lr 0.00024532 rank 2
2022-12-08 11:38:00,481 DEBUG TRAIN Batch 30/6900 loss 4.817041 loss_att 286.777100 loss_ctc 8.911560 loss_rnnt 4.362094 lr 0.00024532 rank 5
2022-12-08 11:38:00,482 DEBUG TRAIN Batch 30/6900 loss 12.316731 loss_att 344.793030 loss_ctc 24.685555 loss_rnnt 10.942418 lr 0.00024529 rank 0
2022-12-08 11:39:04,232 DEBUG TRAIN Batch 30/7000 loss 0.928123 loss_att 246.508362 loss_ctc 3.461046 loss_rnnt 0.646687 lr 0.00024526 rank 0
2022-12-08 11:39:04,236 DEBUG TRAIN Batch 30/7000 loss 5.581162 loss_att 423.622070 loss_ctc 9.990316 loss_rnnt 5.091256 lr 0.00024527 rank 4
2022-12-08 11:39:04,237 DEBUG TRAIN Batch 30/7000 loss 6.905021 loss_att 312.193542 loss_ctc 18.136421 loss_rnnt 5.657087 lr 0.00024527 rank 7
2022-12-08 11:39:04,242 DEBUG TRAIN Batch 30/7000 loss 6.017790 loss_att 406.955261 loss_ctc 12.767187 loss_rnnt 5.267858 lr 0.00024530 rank 6
2022-12-08 11:39:04,242 DEBUG TRAIN Batch 30/7000 loss 6.187315 loss_att 299.141449 loss_ctc 11.514688 loss_rnnt 5.595385 lr 0.00024529 rank 5
2022-12-08 11:39:04,242 DEBUG TRAIN Batch 30/7000 loss 4.932687 loss_att 179.713409 loss_ctc 10.597171 loss_rnnt 4.303300 lr 0.00024529 rank 2
2022-12-08 11:39:04,247 DEBUG TRAIN Batch 30/7000 loss 4.849967 loss_att 310.777649 loss_ctc 13.615844 loss_rnnt 3.875980 lr 0.00024528 rank 3
2022-12-08 11:39:04,247 DEBUG TRAIN Batch 30/7000 loss 2.538831 loss_att 371.926270 loss_ctc 4.450663 loss_rnnt 2.326406 lr 0.00024531 rank 1
2022-12-08 11:40:10,075 DEBUG TRAIN Batch 30/7100 loss 7.091243 loss_att 462.829712 loss_ctc 16.916914 loss_rnnt 5.999502 lr 0.00024528 rank 1
2022-12-08 11:40:10,082 DEBUG TRAIN Batch 30/7100 loss 3.963449 loss_att 393.367798 loss_ctc 7.507360 loss_rnnt 3.569682 lr 0.00024524 rank 4
2022-12-08 11:40:10,087 DEBUG TRAIN Batch 30/7100 loss 5.861407 loss_att 339.769135 loss_ctc 8.659828 loss_rnnt 5.550471 lr 0.00024524 rank 7
2022-12-08 11:40:10,088 DEBUG TRAIN Batch 30/7100 loss 7.343941 loss_att 403.188446 loss_ctc 16.052917 loss_rnnt 6.376277 lr 0.00024527 rank 6
2022-12-08 11:40:10,093 DEBUG TRAIN Batch 30/7100 loss 9.625380 loss_att 414.832367 loss_ctc 22.252983 loss_rnnt 8.222313 lr 0.00024525 rank 3
2022-12-08 11:40:10,094 DEBUG TRAIN Batch 30/7100 loss 2.703785 loss_att 395.429016 loss_ctc 6.519954 loss_rnnt 2.279766 lr 0.00024526 rank 5
2022-12-08 11:40:10,104 DEBUG TRAIN Batch 30/7100 loss 14.818140 loss_att 429.217834 loss_ctc 31.692900 loss_rnnt 12.943168 lr 0.00024523 rank 0
2022-12-08 11:40:10,106 DEBUG TRAIN Batch 30/7100 loss 5.025308 loss_att 378.539307 loss_ctc 8.968424 loss_rnnt 4.587183 lr 0.00024526 rank 2
2022-12-08 11:41:18,749 DEBUG TRAIN Batch 30/7200 loss 2.463853 loss_att 336.394684 loss_ctc 8.818046 loss_rnnt 1.757832 lr 0.00024526 rank 1
2022-12-08 11:41:18,751 DEBUG TRAIN Batch 30/7200 loss 6.403759 loss_att 381.415039 loss_ctc 12.308336 loss_rnnt 5.747695 lr 0.00024523 rank 5
2022-12-08 11:41:18,752 DEBUG TRAIN Batch 30/7200 loss 18.307835 loss_att 411.320892 loss_ctc 37.942986 loss_rnnt 16.126152 lr 0.00024522 rank 3
2022-12-08 11:41:18,752 DEBUG TRAIN Batch 30/7200 loss 32.073639 loss_att 320.063232 loss_ctc 55.517609 loss_rnnt 29.468756 lr 0.00024523 rank 2
2022-12-08 11:41:18,754 DEBUG TRAIN Batch 30/7200 loss 8.191000 loss_att 369.858765 loss_ctc 18.440556 loss_rnnt 7.052161 lr 0.00024524 rank 6
2022-12-08 11:41:18,756 DEBUG TRAIN Batch 30/7200 loss 11.146719 loss_att 398.622803 loss_ctc 21.416533 loss_rnnt 10.005629 lr 0.00024520 rank 0
2022-12-08 11:41:18,757 DEBUG TRAIN Batch 30/7200 loss 9.394275 loss_att 394.595886 loss_ctc 19.541359 loss_rnnt 8.266821 lr 0.00024522 rank 4
2022-12-08 11:41:18,761 DEBUG TRAIN Batch 30/7200 loss 7.409253 loss_att 435.216797 loss_ctc 15.839539 loss_rnnt 6.472555 lr 0.00024521 rank 7
2022-12-08 11:42:21,985 DEBUG TRAIN Batch 30/7300 loss 8.449655 loss_att 380.053101 loss_ctc 15.909210 loss_rnnt 7.620815 lr 0.00024519 rank 4
2022-12-08 11:42:21,991 DEBUG TRAIN Batch 30/7300 loss 6.135901 loss_att 368.366150 loss_ctc 13.875615 loss_rnnt 5.275933 lr 0.00024518 rank 7
2022-12-08 11:42:21,993 DEBUG TRAIN Batch 30/7300 loss 5.460649 loss_att 363.218750 loss_ctc 15.067242 loss_rnnt 4.393250 lr 0.00024520 rank 5
2022-12-08 11:42:21,993 DEBUG TRAIN Batch 30/7300 loss 1.237870 loss_att 338.017456 loss_ctc 4.656436 loss_rnnt 0.858030 lr 0.00024523 rank 1
2022-12-08 11:42:21,995 DEBUG TRAIN Batch 30/7300 loss 17.836390 loss_att 419.751892 loss_ctc 30.923607 loss_rnnt 16.382254 lr 0.00024519 rank 3
2022-12-08 11:42:21,999 DEBUG TRAIN Batch 30/7300 loss 10.527218 loss_att 455.774414 loss_ctc 29.024488 loss_rnnt 8.471966 lr 0.00024517 rank 0
2022-12-08 11:42:22,001 DEBUG TRAIN Batch 30/7300 loss 12.409339 loss_att 390.531097 loss_ctc 18.042149 loss_rnnt 11.783472 lr 0.00024521 rank 6
2022-12-08 11:42:22,036 DEBUG TRAIN Batch 30/7300 loss 4.866032 loss_att 324.284241 loss_ctc 12.597534 loss_rnnt 4.006976 lr 0.00024520 rank 2
2022-12-08 11:43:25,874 DEBUG TRAIN Batch 30/7400 loss 3.931647 loss_att 352.551147 loss_ctc 15.280151 loss_rnnt 2.670702 lr 0.00024520 rank 1
2022-12-08 11:43:25,877 DEBUG TRAIN Batch 30/7400 loss 4.516214 loss_att 368.766968 loss_ctc 11.304031 loss_rnnt 3.762012 lr 0.00024516 rank 3
2022-12-08 11:43:25,885 DEBUG TRAIN Batch 30/7400 loss 5.832749 loss_att 333.318359 loss_ctc 11.623156 loss_rnnt 5.189371 lr 0.00024515 rank 7
2022-12-08 11:43:25,889 DEBUG TRAIN Batch 30/7400 loss 7.710331 loss_att 369.751160 loss_ctc 18.208691 loss_rnnt 6.543847 lr 0.00024516 rank 4
2022-12-08 11:43:25,890 DEBUG TRAIN Batch 30/7400 loss 6.114227 loss_att 329.007751 loss_ctc 14.126471 loss_rnnt 5.223978 lr 0.00024518 rank 6
2022-12-08 11:43:25,893 DEBUG TRAIN Batch 30/7400 loss 13.421974 loss_att 387.820312 loss_ctc 21.775822 loss_rnnt 12.493769 lr 0.00024514 rank 0
2022-12-08 11:43:25,914 DEBUG TRAIN Batch 30/7400 loss 8.945625 loss_att 366.413422 loss_ctc 20.450340 loss_rnnt 7.667324 lr 0.00024517 rank 5
2022-12-08 11:43:25,918 DEBUG TRAIN Batch 30/7400 loss 5.183949 loss_att 347.109192 loss_ctc 7.396912 loss_rnnt 4.938064 lr 0.00024517 rank 2
2022-12-08 11:44:38,038 DEBUG TRAIN Batch 30/7500 loss 5.343727 loss_att 289.217224 loss_ctc 7.655890 loss_rnnt 5.086820 lr 0.00024515 rank 2
2022-12-08 11:44:38,039 DEBUG TRAIN Batch 30/7500 loss 5.928006 loss_att 291.671600 loss_ctc 12.702871 loss_rnnt 5.175244 lr 0.00024512 rank 7
2022-12-08 11:44:38,043 DEBUG TRAIN Batch 30/7500 loss 3.790556 loss_att 256.708466 loss_ctc 7.119107 loss_rnnt 3.420717 lr 0.00024515 rank 6
2022-12-08 11:44:38,044 DEBUG TRAIN Batch 30/7500 loss 8.181220 loss_att 81.618889 loss_ctc 10.821353 loss_rnnt 7.887872 lr 0.00024513 rank 4
2022-12-08 11:44:38,045 DEBUG TRAIN Batch 30/7500 loss 13.287061 loss_att 335.954498 loss_ctc 24.168644 loss_rnnt 12.077996 lr 0.00024514 rank 5
2022-12-08 11:44:38,047 DEBUG TRAIN Batch 30/7500 loss 8.601953 loss_att 357.290039 loss_ctc 16.264633 loss_rnnt 7.750544 lr 0.00024512 rank 0
2022-12-08 11:44:38,048 DEBUG TRAIN Batch 30/7500 loss 3.551815 loss_att 330.265076 loss_ctc 9.501364 loss_rnnt 2.890754 lr 0.00024513 rank 3
2022-12-08 11:44:38,051 DEBUG TRAIN Batch 30/7500 loss 3.577691 loss_att 291.026337 loss_ctc 9.747988 loss_rnnt 2.892102 lr 0.00024517 rank 1
2022-12-08 11:45:42,395 DEBUG TRAIN Batch 30/7600 loss 6.617070 loss_att 416.720184 loss_ctc 23.812645 loss_rnnt 4.706451 lr 0.00024510 rank 4
2022-12-08 11:45:42,395 DEBUG TRAIN Batch 30/7600 loss 13.646344 loss_att 430.281006 loss_ctc 26.741131 loss_rnnt 12.191368 lr 0.00024512 rank 6
2022-12-08 11:45:42,396 DEBUG TRAIN Batch 30/7600 loss 6.515940 loss_att 334.189880 loss_ctc 15.730852 loss_rnnt 5.492061 lr 0.00024510 rank 3
2022-12-08 11:45:42,397 DEBUG TRAIN Batch 30/7600 loss 7.061935 loss_att 104.721848 loss_ctc 11.155649 loss_rnnt 6.607079 lr 0.00024509 rank 7
2022-12-08 11:45:42,397 DEBUG TRAIN Batch 30/7600 loss 10.111313 loss_att 94.529930 loss_ctc 13.562299 loss_rnnt 9.727870 lr 0.00024514 rank 1
2022-12-08 11:45:42,399 DEBUG TRAIN Batch 30/7600 loss 9.607183 loss_att 330.413208 loss_ctc 17.863647 loss_rnnt 8.689798 lr 0.00024511 rank 5
2022-12-08 11:45:42,403 DEBUG TRAIN Batch 30/7600 loss 6.505354 loss_att 302.332672 loss_ctc 13.828981 loss_rnnt 5.691618 lr 0.00024509 rank 0
2022-12-08 11:45:42,404 DEBUG TRAIN Batch 30/7600 loss 6.251968 loss_att 99.852707 loss_ctc 10.399954 loss_rnnt 5.791081 lr 0.00024512 rank 2
2022-12-08 11:46:47,123 DEBUG TRAIN Batch 30/7700 loss 5.271118 loss_att 200.422714 loss_ctc 8.926872 loss_rnnt 4.864923 lr 0.00024508 rank 3
2022-12-08 11:46:47,124 DEBUG TRAIN Batch 30/7700 loss 4.339411 loss_att 309.077362 loss_ctc 9.037551 loss_rnnt 3.817396 lr 0.00024506 rank 7
2022-12-08 11:46:47,127 DEBUG TRAIN Batch 30/7700 loss 9.804837 loss_att 73.964882 loss_ctc 13.943378 loss_rnnt 9.345000 lr 0.00024506 rank 0
2022-12-08 11:46:47,127 DEBUG TRAIN Batch 30/7700 loss 4.851250 loss_att 371.409149 loss_ctc 7.348348 loss_rnnt 4.573795 lr 0.00024507 rank 4
2022-12-08 11:46:47,131 DEBUG TRAIN Batch 30/7700 loss 7.608868 loss_att 395.443848 loss_ctc 17.660900 loss_rnnt 6.491976 lr 0.00024510 rank 6
2022-12-08 11:46:47,132 DEBUG TRAIN Batch 30/7700 loss 23.152439 loss_att 407.840546 loss_ctc 58.854897 loss_rnnt 19.185499 lr 0.00024509 rank 2
2022-12-08 11:46:47,133 DEBUG TRAIN Batch 30/7700 loss 4.124431 loss_att 375.128510 loss_ctc 10.832266 loss_rnnt 3.379116 lr 0.00024511 rank 1
2022-12-08 11:46:47,136 DEBUG TRAIN Batch 30/7700 loss 4.992845 loss_att 285.059723 loss_ctc 10.378372 loss_rnnt 4.394453 lr 0.00024508 rank 5
2022-12-08 11:47:52,879 DEBUG TRAIN Batch 30/7800 loss 5.220112 loss_att 379.388489 loss_ctc 13.921186 loss_rnnt 4.253326 lr 0.00024505 rank 3
2022-12-08 11:47:52,892 DEBUG TRAIN Batch 30/7800 loss 3.989497 loss_att 414.835663 loss_ctc 13.054527 loss_rnnt 2.982271 lr 0.00024504 rank 4
2022-12-08 11:47:52,894 DEBUG TRAIN Batch 30/7800 loss 5.643935 loss_att 388.260315 loss_ctc 9.578787 loss_rnnt 5.206730 lr 0.00024503 rank 7
2022-12-08 11:47:52,897 DEBUG TRAIN Batch 30/7800 loss 7.518245 loss_att 397.992371 loss_ctc 17.671358 loss_rnnt 6.390121 lr 0.00024508 rank 1
2022-12-08 11:47:52,898 DEBUG TRAIN Batch 30/7800 loss 12.735622 loss_att 440.101440 loss_ctc 24.872320 loss_rnnt 11.387100 lr 0.00024505 rank 5
2022-12-08 11:47:52,899 DEBUG TRAIN Batch 30/7800 loss 7.163402 loss_att 334.639801 loss_ctc 15.371932 loss_rnnt 6.251343 lr 0.00024503 rank 0
2022-12-08 11:47:52,917 DEBUG TRAIN Batch 30/7800 loss 2.391785 loss_att 358.768433 loss_ctc 6.669200 loss_rnnt 1.916517 lr 0.00024507 rank 6
2022-12-08 11:47:52,925 DEBUG TRAIN Batch 30/7800 loss 9.132962 loss_att 411.877869 loss_ctc 25.859261 loss_rnnt 7.274485 lr 0.00024506 rank 2
2022-12-08 11:49:03,248 DEBUG TRAIN Batch 30/7900 loss 9.844341 loss_att 345.545227 loss_ctc 14.038635 loss_rnnt 9.378308 lr 0.00024500 rank 7
2022-12-08 11:49:03,249 DEBUG TRAIN Batch 30/7900 loss 1.994699 loss_att 349.075867 loss_ctc 11.545082 loss_rnnt 0.933545 lr 0.00024500 rank 0
2022-12-08 11:49:03,249 DEBUG TRAIN Batch 30/7900 loss 3.076812 loss_att 320.073669 loss_ctc 6.869296 loss_rnnt 2.655425 lr 0.00024503 rank 2
2022-12-08 11:49:03,249 DEBUG TRAIN Batch 30/7900 loss 4.469680 loss_att 395.270691 loss_ctc 8.889107 loss_rnnt 3.978633 lr 0.00024501 rank 4
2022-12-08 11:49:03,251 DEBUG TRAIN Batch 30/7900 loss 3.510257 loss_att 392.713501 loss_ctc 10.504084 loss_rnnt 2.733166 lr 0.00024504 rank 6
2022-12-08 11:49:03,254 DEBUG TRAIN Batch 30/7900 loss 12.778220 loss_att 421.183167 loss_ctc 26.305695 loss_rnnt 11.275167 lr 0.00024502 rank 3
2022-12-08 11:49:03,255 DEBUG TRAIN Batch 30/7900 loss 10.397989 loss_att 434.916870 loss_ctc 19.862507 loss_rnnt 9.346376 lr 0.00024505 rank 1
2022-12-08 11:49:03,260 DEBUG TRAIN Batch 30/7900 loss 2.812507 loss_att 355.323059 loss_ctc 6.782978 loss_rnnt 2.371344 lr 0.00024502 rank 5
2022-12-08 11:50:06,682 DEBUG TRAIN Batch 30/8000 loss 3.570175 loss_att 367.035431 loss_ctc 7.972802 loss_rnnt 3.080994 lr 0.00024498 rank 7
2022-12-08 11:50:06,682 DEBUG TRAIN Batch 30/8000 loss 6.039521 loss_att 366.552948 loss_ctc 17.652479 loss_rnnt 4.749193 lr 0.00024498 rank 4
2022-12-08 11:50:06,682 DEBUG TRAIN Batch 30/8000 loss 6.782709 loss_att 377.119476 loss_ctc 13.669093 loss_rnnt 6.017555 lr 0.00024499 rank 3
2022-12-08 11:50:06,684 DEBUG TRAIN Batch 30/8000 loss 8.198581 loss_att 371.251099 loss_ctc 17.034096 loss_rnnt 7.216857 lr 0.00024501 rank 6
2022-12-08 11:50:06,686 DEBUG TRAIN Batch 30/8000 loss 9.471078 loss_att 344.525452 loss_ctc 19.208630 loss_rnnt 8.389128 lr 0.00024502 rank 1
2022-12-08 11:50:06,687 DEBUG TRAIN Batch 30/8000 loss 9.095696 loss_att 367.031738 loss_ctc 16.451231 loss_rnnt 8.278415 lr 0.00024497 rank 0
2022-12-08 11:50:06,689 DEBUG TRAIN Batch 30/8000 loss 15.409565 loss_att 412.105530 loss_ctc 31.255726 loss_rnnt 13.648881 lr 0.00024499 rank 5
2022-12-08 11:50:06,736 DEBUG TRAIN Batch 30/8000 loss 9.076244 loss_att 405.568695 loss_ctc 18.493675 loss_rnnt 8.029863 lr 0.00024500 rank 2
2022-12-08 11:51:10,645 DEBUG TRAIN Batch 30/8100 loss 7.707401 loss_att 302.991028 loss_ctc 15.007205 loss_rnnt 6.896312 lr 0.00024499 rank 1
2022-12-08 11:51:10,658 DEBUG TRAIN Batch 30/8100 loss 5.472370 loss_att 307.283295 loss_ctc 8.646705 loss_rnnt 5.119667 lr 0.00024498 rank 6
2022-12-08 11:51:10,659 DEBUG TRAIN Batch 30/8100 loss 4.953282 loss_att 166.593765 loss_ctc 8.681429 loss_rnnt 4.539043 lr 0.00024495 rank 4
2022-12-08 11:51:10,661 DEBUG TRAIN Batch 30/8100 loss 18.269135 loss_att 372.693542 loss_ctc 37.017708 loss_rnnt 16.185959 lr 0.00024495 rank 7
2022-12-08 11:51:10,661 DEBUG TRAIN Batch 30/8100 loss 9.562447 loss_att 373.496338 loss_ctc 20.551809 loss_rnnt 8.341406 lr 0.00024496 rank 3
2022-12-08 11:51:10,664 DEBUG TRAIN Batch 30/8100 loss 5.335541 loss_att 323.722351 loss_ctc 11.924453 loss_rnnt 4.603439 lr 0.00024494 rank 0
2022-12-08 11:51:10,686 DEBUG TRAIN Batch 30/8100 loss 18.069584 loss_att 352.216248 loss_ctc 36.590443 loss_rnnt 16.011711 lr 0.00024497 rank 2
2022-12-08 11:51:10,688 DEBUG TRAIN Batch 30/8100 loss 6.087680 loss_att 325.824829 loss_ctc 9.643576 loss_rnnt 5.692581 lr 0.00024496 rank 5
2022-12-08 11:52:15,122 DEBUG TRAIN Batch 30/8200 loss 7.205081 loss_att 367.806396 loss_ctc 20.308750 loss_rnnt 5.749118 lr 0.00024492 rank 4
2022-12-08 11:52:15,123 DEBUG TRAIN Batch 30/8200 loss 10.704928 loss_att 208.617554 loss_ctc 15.238917 loss_rnnt 10.201153 lr 0.00024492 rank 7
2022-12-08 11:52:15,124 DEBUG TRAIN Batch 30/8200 loss 6.706355 loss_att 175.594727 loss_ctc 14.345023 loss_rnnt 5.857615 lr 0.00024494 rank 2
2022-12-08 11:52:15,129 DEBUG TRAIN Batch 30/8200 loss 7.335527 loss_att 318.933899 loss_ctc 19.365997 loss_rnnt 5.998809 lr 0.00024493 rank 5
2022-12-08 11:52:15,129 DEBUG TRAIN Batch 30/8200 loss 2.282307 loss_att 434.145844 loss_ctc 7.308328 loss_rnnt 1.723861 lr 0.00024495 rank 6
2022-12-08 11:52:15,129 DEBUG TRAIN Batch 30/8200 loss 7.638941 loss_att 327.241943 loss_ctc 18.839611 loss_rnnt 6.394423 lr 0.00024493 rank 3
2022-12-08 11:52:15,133 DEBUG TRAIN Batch 30/8200 loss 10.216466 loss_att 333.475464 loss_ctc 22.177755 loss_rnnt 8.887434 lr 0.00024491 rank 0
2022-12-08 11:52:15,165 DEBUG TRAIN Batch 30/8200 loss 7.568720 loss_att 75.102562 loss_ctc 11.502158 loss_rnnt 7.131671 lr 0.00024496 rank 1
2022-12-08 11:53:18,222 DEBUG TRAIN Batch 30/8300 loss 13.355155 loss_att 382.708008 loss_ctc 28.493698 loss_rnnt 11.673095 lr 0.00024491 rank 5
2022-12-08 11:53:18,229 DEBUG TRAIN Batch 30/8300 loss 3.574108 loss_att 432.307861 loss_ctc 7.577547 loss_rnnt 3.129282 lr 0.00024489 rank 4
2022-12-08 11:53:18,237 DEBUG TRAIN Batch 30/8300 loss 5.979749 loss_att 359.155884 loss_ctc 13.462147 loss_rnnt 5.148372 lr 0.00024489 rank 7
2022-12-08 11:53:18,238 DEBUG TRAIN Batch 30/8300 loss 20.169973 loss_att 323.969299 loss_ctc 37.384777 loss_rnnt 18.257217 lr 0.00024488 rank 0
2022-12-08 11:53:18,240 DEBUG TRAIN Batch 30/8300 loss 7.478827 loss_att 408.011017 loss_ctc 18.291828 loss_rnnt 6.277382 lr 0.00024490 rank 3
2022-12-08 11:53:18,240 DEBUG TRAIN Batch 30/8300 loss 3.652180 loss_att 383.250092 loss_ctc 8.714460 loss_rnnt 3.089705 lr 0.00024493 rank 1
2022-12-08 11:53:18,244 DEBUG TRAIN Batch 30/8300 loss 2.021295 loss_att 403.720886 loss_ctc 5.897464 loss_rnnt 1.590610 lr 0.00024492 rank 6
2022-12-08 11:53:18,275 DEBUG TRAIN Batch 30/8300 loss 8.321959 loss_att 406.038391 loss_ctc 20.086750 loss_rnnt 7.014760 lr 0.00024491 rank 2
2022-12-08 11:54:08,572 DEBUG CV Batch 30/0 loss 1.477041 loss_att 48.085884 loss_ctc 2.911865 loss_rnnt 1.317616 history loss 1.422335 rank 2
2022-12-08 11:54:08,572 DEBUG CV Batch 30/0 loss 1.477041 loss_att 48.085884 loss_ctc 2.911865 loss_rnnt 1.317616 history loss 1.422335 rank 7
2022-12-08 11:54:08,577 DEBUG CV Batch 30/0 loss 1.477041 loss_att 48.085884 loss_ctc 2.911865 loss_rnnt 1.317616 history loss 1.422335 rank 5
2022-12-08 11:54:08,577 DEBUG CV Batch 30/0 loss 1.477041 loss_att 48.085884 loss_ctc 2.911865 loss_rnnt 1.317616 history loss 1.422335 rank 4
2022-12-08 11:54:08,579 DEBUG CV Batch 30/0 loss 1.477041 loss_att 48.085884 loss_ctc 2.911865 loss_rnnt 1.317616 history loss 1.422335 rank 1
2022-12-08 11:54:08,580 DEBUG CV Batch 30/0 loss 1.477041 loss_att 48.085884 loss_ctc 2.911865 loss_rnnt 1.317616 history loss 1.422335 rank 3
2022-12-08 11:54:08,584 DEBUG CV Batch 30/0 loss 1.477041 loss_att 48.085884 loss_ctc 2.911865 loss_rnnt 1.317616 history loss 1.422335 rank 6
2022-12-08 11:54:08,596 DEBUG CV Batch 30/0 loss 1.477041 loss_att 48.085884 loss_ctc 2.911865 loss_rnnt 1.317616 history loss 1.422335 rank 0
2022-12-08 11:54:19,225 DEBUG CV Batch 30/100 loss 3.654276 loss_att 266.943237 loss_ctc 9.889426 loss_rnnt 2.961481 history loss 2.887517 rank 6
2022-12-08 11:54:19,249 DEBUG CV Batch 30/100 loss 3.654276 loss_att 266.943237 loss_ctc 9.889426 loss_rnnt 2.961481 history loss 2.887517 rank 5
2022-12-08 11:54:19,386 DEBUG CV Batch 30/100 loss 3.654276 loss_att 266.943237 loss_ctc 9.889426 loss_rnnt 2.961481 history loss 2.887517 rank 1
2022-12-08 11:54:19,480 DEBUG CV Batch 30/100 loss 3.654276 loss_att 266.943237 loss_ctc 9.889426 loss_rnnt 2.961481 history loss 2.887517 rank 7
2022-12-08 11:54:19,549 DEBUG CV Batch 30/100 loss 3.654276 loss_att 266.943237 loss_ctc 9.889426 loss_rnnt 2.961481 history loss 2.887517 rank 4
2022-12-08 11:54:19,567 DEBUG CV Batch 30/100 loss 3.654276 loss_att 266.943237 loss_ctc 9.889426 loss_rnnt 2.961481 history loss 2.887517 rank 0
2022-12-08 11:54:19,704 DEBUG CV Batch 30/100 loss 3.654276 loss_att 266.943237 loss_ctc 9.889426 loss_rnnt 2.961481 history loss 2.887517 rank 3
2022-12-08 11:54:19,845 DEBUG CV Batch 30/100 loss 3.654276 loss_att 266.943237 loss_ctc 9.889426 loss_rnnt 2.961481 history loss 2.887517 rank 2
2022-12-08 11:54:32,612 DEBUG CV Batch 30/200 loss 3.593295 loss_att 641.183411 loss_ctc 3.464168 loss_rnnt 3.607642 history loss 3.397951 rank 5
2022-12-08 11:54:32,959 DEBUG CV Batch 30/200 loss 3.593295 loss_att 641.183411 loss_ctc 3.464168 loss_rnnt 3.607642 history loss 3.397951 rank 1
2022-12-08 11:54:32,969 DEBUG CV Batch 30/200 loss 3.593295 loss_att 641.183411 loss_ctc 3.464168 loss_rnnt 3.607642 history loss 3.397951 rank 4
2022-12-08 11:54:33,210 DEBUG CV Batch 30/200 loss 3.593295 loss_att 641.183411 loss_ctc 3.464168 loss_rnnt 3.607642 history loss 3.397951 rank 6
2022-12-08 11:54:33,236 DEBUG CV Batch 30/200 loss 3.593295 loss_att 641.183411 loss_ctc 3.464168 loss_rnnt 3.607642 history loss 3.397951 rank 7
2022-12-08 11:54:33,460 DEBUG CV Batch 30/200 loss 3.593295 loss_att 641.183411 loss_ctc 3.464168 loss_rnnt 3.607642 history loss 3.397951 rank 0
2022-12-08 11:54:33,604 DEBUG CV Batch 30/200 loss 3.593295 loss_att 641.183411 loss_ctc 3.464168 loss_rnnt 3.607642 history loss 3.397951 rank 3
2022-12-08 11:54:34,046 DEBUG CV Batch 30/200 loss 3.593295 loss_att 641.183411 loss_ctc 3.464168 loss_rnnt 3.607642 history loss 3.397951 rank 2
2022-12-08 11:54:43,812 DEBUG CV Batch 30/300 loss 2.352882 loss_att 190.885925 loss_ctc 5.444772 loss_rnnt 2.009339 history loss 3.551271 rank 5
2022-12-08 11:54:44,144 DEBUG CV Batch 30/300 loss 2.352882 loss_att 190.885925 loss_ctc 5.444772 loss_rnnt 2.009339 history loss 3.551271 rank 1
2022-12-08 11:54:44,299 DEBUG CV Batch 30/300 loss 2.352882 loss_att 190.885925 loss_ctc 5.444772 loss_rnnt 2.009339 history loss 3.551271 rank 6
2022-12-08 11:54:44,710 DEBUG CV Batch 30/300 loss 2.352882 loss_att 190.885925 loss_ctc 5.444772 loss_rnnt 2.009339 history loss 3.551271 rank 4
2022-12-08 11:54:45,016 DEBUG CV Batch 30/300 loss 2.352882 loss_att 190.885925 loss_ctc 5.444772 loss_rnnt 2.009339 history loss 3.551271 rank 3
2022-12-08 11:54:45,069 DEBUG CV Batch 30/300 loss 2.352882 loss_att 190.885925 loss_ctc 5.444772 loss_rnnt 2.009339 history loss 3.551271 rank 7
2022-12-08 11:54:45,305 DEBUG CV Batch 30/300 loss 2.352882 loss_att 190.885925 loss_ctc 5.444772 loss_rnnt 2.009339 history loss 3.551271 rank 0
2022-12-08 11:54:45,305 DEBUG CV Batch 30/300 loss 2.352882 loss_att 190.885925 loss_ctc 5.444772 loss_rnnt 2.009339 history loss 3.551271 rank 2
2022-12-08 11:54:54,896 DEBUG CV Batch 30/400 loss 2.144981 loss_att 826.175903 loss_ctc 6.373655 loss_rnnt 1.675128 history loss 4.415901 rank 5
2022-12-08 11:54:55,306 DEBUG CV Batch 30/400 loss 2.144981 loss_att 826.175903 loss_ctc 6.373655 loss_rnnt 1.675128 history loss 4.415901 rank 1
2022-12-08 11:54:56,088 DEBUG CV Batch 30/400 loss 2.144981 loss_att 826.175903 loss_ctc 6.373655 loss_rnnt 1.675128 history loss 4.415901 rank 6
2022-12-08 11:54:56,156 DEBUG CV Batch 30/400 loss 2.144981 loss_att 826.175903 loss_ctc 6.373655 loss_rnnt 1.675128 history loss 4.415901 rank 3
2022-12-08 11:54:56,372 DEBUG CV Batch 30/400 loss 2.144981 loss_att 826.175903 loss_ctc 6.373655 loss_rnnt 1.675128 history loss 4.415901 rank 4
2022-12-08 11:54:56,908 DEBUG CV Batch 30/400 loss 2.144981 loss_att 826.175903 loss_ctc 6.373655 loss_rnnt 1.675128 history loss 4.415901 rank 2
2022-12-08 11:54:56,920 DEBUG CV Batch 30/400 loss 2.144981 loss_att 826.175903 loss_ctc 6.373655 loss_rnnt 1.675128 history loss 4.415901 rank 7
2022-12-08 11:54:57,193 DEBUG CV Batch 30/400 loss 2.144981 loss_att 826.175903 loss_ctc 6.373655 loss_rnnt 1.675128 history loss 4.415901 rank 0
2022-12-08 11:55:05,552 DEBUG CV Batch 30/500 loss 4.882785 loss_att 266.652954 loss_ctc 7.106480 loss_rnnt 4.635708 history loss 5.041702 rank 5
2022-12-08 11:55:06,036 DEBUG CV Batch 30/500 loss 4.882785 loss_att 266.652954 loss_ctc 7.106480 loss_rnnt 4.635708 history loss 5.041702 rank 1
2022-12-08 11:55:06,614 DEBUG CV Batch 30/500 loss 4.882785 loss_att 266.652954 loss_ctc 7.106480 loss_rnnt 4.635708 history loss 5.041702 rank 4
2022-12-08 11:55:06,928 DEBUG CV Batch 30/500 loss 4.882785 loss_att 266.652954 loss_ctc 7.106480 loss_rnnt 4.635708 history loss 5.041702 rank 6
2022-12-08 11:55:07,041 DEBUG CV Batch 30/500 loss 4.882785 loss_att 266.652954 loss_ctc 7.106480 loss_rnnt 4.635708 history loss 5.041702 rank 3
2022-12-08 11:55:07,105 DEBUG CV Batch 30/500 loss 4.882785 loss_att 266.652954 loss_ctc 7.106480 loss_rnnt 4.635708 history loss 5.041702 rank 7
2022-12-08 11:55:07,571 DEBUG CV Batch 30/500 loss 4.882785 loss_att 266.652954 loss_ctc 7.106480 loss_rnnt 4.635708 history loss 5.041702 rank 0
2022-12-08 11:55:07,973 DEBUG CV Batch 30/500 loss 4.882785 loss_att 266.652954 loss_ctc 7.106480 loss_rnnt 4.635708 history loss 5.041702 rank 2
2022-12-08 11:55:17,936 DEBUG CV Batch 30/600 loss 5.223745 loss_att 104.306419 loss_ctc 8.296657 loss_rnnt 4.882311 history loss 5.899791 rank 5
2022-12-08 11:55:18,591 DEBUG CV Batch 30/600 loss 5.223745 loss_att 104.306419 loss_ctc 8.296657 loss_rnnt 4.882311 history loss 5.899791 rank 4
2022-12-08 11:55:18,718 DEBUG CV Batch 30/600 loss 5.223745 loss_att 104.306419 loss_ctc 8.296657 loss_rnnt 4.882311 history loss 5.899791 rank 1
2022-12-08 11:55:19,010 DEBUG CV Batch 30/600 loss 5.223745 loss_att 104.306419 loss_ctc 8.296657 loss_rnnt 4.882311 history loss 5.899791 rank 7
2022-12-08 11:55:19,505 DEBUG CV Batch 30/600 loss 5.223745 loss_att 104.306419 loss_ctc 8.296657 loss_rnnt 4.882311 history loss 5.899791 rank 0
2022-12-08 11:55:19,841 DEBUG CV Batch 30/600 loss 5.223745 loss_att 104.306419 loss_ctc 8.296657 loss_rnnt 4.882311 history loss 5.899791 rank 6
2022-12-08 11:55:19,988 DEBUG CV Batch 30/600 loss 5.223745 loss_att 104.306419 loss_ctc 8.296657 loss_rnnt 4.882311 history loss 5.899791 rank 3
2022-12-08 11:55:20,792 DEBUG CV Batch 30/600 loss 5.223745 loss_att 104.306419 loss_ctc 8.296657 loss_rnnt 4.882311 history loss 5.899791 rank 2
2022-12-08 11:55:30,338 DEBUG CV Batch 30/700 loss 8.967454 loss_att 707.015869 loss_ctc 20.187441 loss_rnnt 7.720788 history loss 6.474372 rank 7
2022-12-08 11:55:30,444 DEBUG CV Batch 30/700 loss 8.967454 loss_att 707.015869 loss_ctc 20.187441 loss_rnnt 7.720788 history loss 6.474372 rank 4
2022-12-08 11:55:30,448 DEBUG CV Batch 30/700 loss 8.967454 loss_att 707.015869 loss_ctc 20.187441 loss_rnnt 7.720788 history loss 6.474372 rank 5
2022-12-08 11:55:30,877 DEBUG CV Batch 30/700 loss 8.967454 loss_att 707.015869 loss_ctc 20.187441 loss_rnnt 7.720788 history loss 6.474372 rank 1
2022-12-08 11:55:30,911 DEBUG CV Batch 30/700 loss 8.967454 loss_att 707.015869 loss_ctc 20.187441 loss_rnnt 7.720788 history loss 6.474372 rank 0
2022-12-08 11:55:32,183 DEBUG CV Batch 30/700 loss 8.967454 loss_att 707.015869 loss_ctc 20.187441 loss_rnnt 7.720788 history loss 6.474372 rank 6
2022-12-08 11:55:32,389 DEBUG CV Batch 30/700 loss 8.967454 loss_att 707.015869 loss_ctc 20.187441 loss_rnnt 7.720788 history loss 6.474372 rank 3
2022-12-08 11:55:33,457 DEBUG CV Batch 30/700 loss 8.967454 loss_att 707.015869 loss_ctc 20.187441 loss_rnnt 7.720788 history loss 6.474372 rank 2
2022-12-08 11:55:42,372 DEBUG CV Batch 30/800 loss 6.327447 loss_att 263.400452 loss_ctc 15.184982 loss_rnnt 5.343277 history loss 5.999857 rank 4
2022-12-08 11:55:42,411 DEBUG CV Batch 30/800 loss 6.327447 loss_att 263.400452 loss_ctc 15.184982 loss_rnnt 5.343277 history loss 5.999857 rank 5
2022-12-08 11:55:42,442 DEBUG CV Batch 30/800 loss 6.327447 loss_att 263.400452 loss_ctc 15.184982 loss_rnnt 5.343277 history loss 5.999857 rank 7
2022-12-08 11:55:42,870 DEBUG CV Batch 30/800 loss 6.327447 loss_att 263.400452 loss_ctc 15.184982 loss_rnnt 5.343277 history loss 5.999857 rank 1
2022-12-08 11:55:42,935 DEBUG CV Batch 30/800 loss 6.327447 loss_att 263.400452 loss_ctc 15.184982 loss_rnnt 5.343277 history loss 5.999857 rank 0
2022-12-08 11:55:44,567 DEBUG CV Batch 30/800 loss 6.327447 loss_att 263.400452 loss_ctc 15.184982 loss_rnnt 5.343277 history loss 5.999857 rank 6
2022-12-08 11:55:44,854 DEBUG CV Batch 30/800 loss 6.327447 loss_att 263.400452 loss_ctc 15.184982 loss_rnnt 5.343277 history loss 5.999857 rank 3
2022-12-08 11:55:45,864 DEBUG CV Batch 30/800 loss 6.327447 loss_att 263.400452 loss_ctc 15.184982 loss_rnnt 5.343277 history loss 5.999857 rank 2
2022-12-08 11:55:55,842 DEBUG CV Batch 30/900 loss 13.117373 loss_att 550.842651 loss_ctc 24.159861 loss_rnnt 11.890429 history loss 5.819063 rank 5
2022-12-08 11:55:56,012 DEBUG CV Batch 30/900 loss 13.117373 loss_att 550.842651 loss_ctc 24.159861 loss_rnnt 11.890429 history loss 5.819063 rank 4
2022-12-08 11:55:56,368 DEBUG CV Batch 30/900 loss 13.117373 loss_att 550.842651 loss_ctc 24.159861 loss_rnnt 11.890429 history loss 5.819063 rank 7
2022-12-08 11:55:56,413 DEBUG CV Batch 30/900 loss 13.117373 loss_att 550.842651 loss_ctc 24.159861 loss_rnnt 11.890429 history loss 5.819063 rank 1
2022-12-08 11:55:56,568 DEBUG CV Batch 30/900 loss 13.117373 loss_att 550.842651 loss_ctc 24.159861 loss_rnnt 11.890429 history loss 5.819063 rank 0
2022-12-08 11:55:58,199 DEBUG CV Batch 30/900 loss 13.117373 loss_att 550.842651 loss_ctc 24.159861 loss_rnnt 11.890429 history loss 5.819063 rank 6
2022-12-08 11:55:58,403 DEBUG CV Batch 30/900 loss 13.117373 loss_att 550.842651 loss_ctc 24.159861 loss_rnnt 11.890429 history loss 5.819063 rank 3
2022-12-08 11:55:59,564 DEBUG CV Batch 30/900 loss 13.117373 loss_att 550.842651 loss_ctc 24.159861 loss_rnnt 11.890429 history loss 5.819063 rank 2
2022-12-08 11:56:07,196 DEBUG CV Batch 30/1000 loss 2.231066 loss_att 176.485336 loss_ctc 5.606864 loss_rnnt 1.855978 history loss 5.618341 rank 5
2022-12-08 11:56:07,709 DEBUG CV Batch 30/1000 loss 2.231066 loss_att 176.485336 loss_ctc 5.606864 loss_rnnt 1.855978 history loss 5.618341 rank 4
2022-12-08 11:56:07,711 DEBUG CV Batch 30/1000 loss 2.231066 loss_att 176.485336 loss_ctc 5.606864 loss_rnnt 1.855978 history loss 5.618341 rank 1
2022-12-08 11:56:08,267 DEBUG CV Batch 30/1000 loss 2.231066 loss_att 176.485336 loss_ctc 5.606864 loss_rnnt 1.855978 history loss 5.618341 rank 7
2022-12-08 11:56:08,570 DEBUG CV Batch 30/1000 loss 2.231066 loss_att 176.485336 loss_ctc 5.606864 loss_rnnt 1.855978 history loss 5.618341 rank 0
2022-12-08 11:56:09,620 DEBUG CV Batch 30/1000 loss 2.231066 loss_att 176.485336 loss_ctc 5.606864 loss_rnnt 1.855978 history loss 5.618341 rank 6
2022-12-08 11:56:10,402 DEBUG CV Batch 30/1000 loss 2.231066 loss_att 176.485336 loss_ctc 5.606864 loss_rnnt 1.855978 history loss 5.618341 rank 3
2022-12-08 11:56:11,227 DEBUG CV Batch 30/1000 loss 2.231066 loss_att 176.485336 loss_ctc 5.606864 loss_rnnt 1.855978 history loss 5.618341 rank 2
2022-12-08 11:56:18,630 DEBUG CV Batch 30/1100 loss 4.470282 loss_att 60.693108 loss_ctc 8.399054 loss_rnnt 4.033751 history loss 5.594066 rank 5
2022-12-08 11:56:19,226 DEBUG CV Batch 30/1100 loss 4.470282 loss_att 60.693108 loss_ctc 8.399054 loss_rnnt 4.033751 history loss 5.594066 rank 4
2022-12-08 11:56:19,706 DEBUG CV Batch 30/1100 loss 4.470282 loss_att 60.693108 loss_ctc 8.399054 loss_rnnt 4.033751 history loss 5.594066 rank 1
2022-12-08 11:56:19,966 DEBUG CV Batch 30/1100 loss 4.470282 loss_att 60.693108 loss_ctc 8.399054 loss_rnnt 4.033751 history loss 5.594066 rank 7
2022-12-08 11:56:20,455 DEBUG CV Batch 30/1100 loss 4.470282 loss_att 60.693108 loss_ctc 8.399054 loss_rnnt 4.033751 history loss 5.594066 rank 0
2022-12-08 11:56:21,552 DEBUG CV Batch 30/1100 loss 4.470282 loss_att 60.693108 loss_ctc 8.399054 loss_rnnt 4.033751 history loss 5.594066 rank 6
2022-12-08 11:56:21,576 DEBUG CV Batch 30/1100 loss 4.470282 loss_att 60.693108 loss_ctc 8.399054 loss_rnnt 4.033751 history loss 5.594066 rank 3
2022-12-08 11:56:22,697 DEBUG CV Batch 30/1100 loss 4.470282 loss_att 60.693108 loss_ctc 8.399054 loss_rnnt 4.033751 history loss 5.594066 rank 2
2022-12-08 11:56:29,429 DEBUG CV Batch 30/1200 loss 6.836396 loss_att 280.455200 loss_ctc 9.763782 loss_rnnt 6.511131 history loss 5.874606 rank 4
2022-12-08 11:56:29,460 DEBUG CV Batch 30/1200 loss 6.836396 loss_att 280.455200 loss_ctc 9.763782 loss_rnnt 6.511131 history loss 5.874606 rank 5
2022-12-08 11:56:30,201 DEBUG CV Batch 30/1200 loss 6.836396 loss_att 280.455200 loss_ctc 9.763782 loss_rnnt 6.511131 history loss 5.874606 rank 7
2022-12-08 11:56:30,716 DEBUG CV Batch 30/1200 loss 6.836396 loss_att 280.455200 loss_ctc 9.763782 loss_rnnt 6.511131 history loss 5.874606 rank 1
2022-12-08 11:56:30,843 DEBUG CV Batch 30/1200 loss 6.836396 loss_att 280.455200 loss_ctc 9.763782 loss_rnnt 6.511131 history loss 5.874606 rank 0
2022-12-08 11:56:32,196 DEBUG CV Batch 30/1200 loss 6.836396 loss_att 280.455200 loss_ctc 9.763782 loss_rnnt 6.511131 history loss 5.874606 rank 3
2022-12-08 11:56:32,401 DEBUG CV Batch 30/1200 loss 6.836396 loss_att 280.455200 loss_ctc 9.763782 loss_rnnt 6.511131 history loss 5.874606 rank 6
2022-12-08 11:56:33,482 DEBUG CV Batch 30/1200 loss 6.836396 loss_att 280.455200 loss_ctc 9.763782 loss_rnnt 6.511131 history loss 5.874606 rank 2
2022-12-08 11:56:41,095 DEBUG CV Batch 30/1300 loss 4.737878 loss_att 105.974510 loss_ctc 8.867716 loss_rnnt 4.279007 history loss 6.158977 rank 4
2022-12-08 11:56:41,122 DEBUG CV Batch 30/1300 loss 4.737878 loss_att 105.974510 loss_ctc 8.867716 loss_rnnt 4.279007 history loss 6.158977 rank 5
2022-12-08 11:56:42,100 DEBUG CV Batch 30/1300 loss 4.737878 loss_att 105.974510 loss_ctc 8.867716 loss_rnnt 4.279007 history loss 6.158977 rank 7
2022-12-08 11:56:42,552 DEBUG CV Batch 30/1300 loss 4.737878 loss_att 105.974510 loss_ctc 8.867716 loss_rnnt 4.279007 history loss 6.158977 rank 1
2022-12-08 11:56:42,909 DEBUG CV Batch 30/1300 loss 4.737878 loss_att 105.974510 loss_ctc 8.867716 loss_rnnt 4.279007 history loss 6.158977 rank 0
2022-12-08 11:56:44,257 DEBUG CV Batch 30/1300 loss 4.737878 loss_att 105.974510 loss_ctc 8.867716 loss_rnnt 4.279007 history loss 6.158977 rank 6
2022-12-08 11:56:44,280 DEBUG CV Batch 30/1300 loss 4.737878 loss_att 105.974510 loss_ctc 8.867716 loss_rnnt 4.279007 history loss 6.158977 rank 3
2022-12-08 11:56:45,145 DEBUG CV Batch 30/1300 loss 4.737878 loss_att 105.974510 loss_ctc 8.867716 loss_rnnt 4.279007 history loss 6.158977 rank 2
2022-12-08 11:56:53,255 DEBUG CV Batch 30/1400 loss 4.756059 loss_att 562.086670 loss_ctc 9.658679 loss_rnnt 4.211323 history loss 6.447188 rank 4
2022-12-08 11:56:53,388 DEBUG CV Batch 30/1400 loss 4.756059 loss_att 562.086670 loss_ctc 9.658679 loss_rnnt 4.211323 history loss 6.447188 rank 5
2022-12-08 11:56:53,553 DEBUG CV Batch 30/1400 loss 4.756059 loss_att 562.086670 loss_ctc 9.658679 loss_rnnt 4.211323 history loss 6.447188 rank 7
2022-12-08 11:56:53,875 DEBUG CV Batch 30/1400 loss 4.756059 loss_att 562.086670 loss_ctc 9.658679 loss_rnnt 4.211323 history loss 6.447188 rank 0
2022-12-08 11:56:54,873 DEBUG CV Batch 30/1400 loss 4.756059 loss_att 562.086670 loss_ctc 9.658679 loss_rnnt 4.211323 history loss 6.447188 rank 1
2022-12-08 11:56:55,942 DEBUG CV Batch 30/1400 loss 4.756059 loss_att 562.086670 loss_ctc 9.658679 loss_rnnt 4.211323 history loss 6.447188 rank 3
2022-12-08 11:56:56,624 DEBUG CV Batch 30/1400 loss 4.756059 loss_att 562.086670 loss_ctc 9.658679 loss_rnnt 4.211323 history loss 6.447188 rank 6
2022-12-08 11:56:57,858 DEBUG CV Batch 30/1400 loss 4.756059 loss_att 562.086670 loss_ctc 9.658679 loss_rnnt 4.211323 history loss 6.447188 rank 2
2022-12-08 11:57:05,502 DEBUG CV Batch 30/1500 loss 7.178052 loss_att 275.483856 loss_ctc 6.236747 loss_rnnt 7.282641 history loss 6.329920 rank 4
2022-12-08 11:57:05,917 DEBUG CV Batch 30/1500 loss 7.178052 loss_att 275.483856 loss_ctc 6.236747 loss_rnnt 7.282641 history loss 6.329920 rank 7
2022-12-08 11:57:05,976 DEBUG CV Batch 30/1500 loss 7.178052 loss_att 275.483856 loss_ctc 6.236747 loss_rnnt 7.282641 history loss 6.329920 rank 0
2022-12-08 11:57:05,989 DEBUG CV Batch 30/1500 loss 7.178052 loss_att 275.483856 loss_ctc 6.236747 loss_rnnt 7.282641 history loss 6.329920 rank 5
2022-12-08 11:57:07,538 DEBUG CV Batch 30/1500 loss 7.178052 loss_att 275.483856 loss_ctc 6.236747 loss_rnnt 7.282641 history loss 6.329920 rank 1
2022-12-08 11:57:08,565 DEBUG CV Batch 30/1500 loss 7.178052 loss_att 275.483856 loss_ctc 6.236747 loss_rnnt 7.282641 history loss 6.329920 rank 3
2022-12-08 11:57:08,973 DEBUG CV Batch 30/1500 loss 7.178052 loss_att 275.483856 loss_ctc 6.236747 loss_rnnt 7.282641 history loss 6.329920 rank 6
2022-12-08 11:57:10,720 DEBUG CV Batch 30/1500 loss 7.178052 loss_att 275.483856 loss_ctc 6.236747 loss_rnnt 7.282641 history loss 6.329920 rank 2
2022-12-08 11:57:18,770 DEBUG CV Batch 30/1600 loss 5.777133 loss_att 593.906006 loss_ctc 13.173398 loss_rnnt 4.955325 history loss 6.283218 rank 4
2022-12-08 11:57:19,152 DEBUG CV Batch 30/1600 loss 5.777133 loss_att 593.906006 loss_ctc 13.173398 loss_rnnt 4.955325 history loss 6.283218 rank 5
2022-12-08 11:57:19,388 DEBUG CV Batch 30/1600 loss 5.777133 loss_att 593.906006 loss_ctc 13.173398 loss_rnnt 4.955325 history loss 6.283218 rank 7
2022-12-08 11:57:19,735 DEBUG CV Batch 30/1600 loss 5.777133 loss_att 593.906006 loss_ctc 13.173398 loss_rnnt 4.955325 history loss 6.283218 rank 0
2022-12-08 11:57:20,931 DEBUG CV Batch 30/1600 loss 5.777133 loss_att 593.906006 loss_ctc 13.173398 loss_rnnt 4.955325 history loss 6.283218 rank 1
2022-12-08 11:57:21,785 DEBUG CV Batch 30/1600 loss 5.777133 loss_att 593.906006 loss_ctc 13.173398 loss_rnnt 4.955325 history loss 6.283218 rank 3
2022-12-08 11:57:22,381 DEBUG CV Batch 30/1600 loss 5.777133 loss_att 593.906006 loss_ctc 13.173398 loss_rnnt 4.955325 history loss 6.283218 rank 6
2022-12-08 11:57:24,181 DEBUG CV Batch 30/1600 loss 5.777133 loss_att 593.906006 loss_ctc 13.173398 loss_rnnt 4.955325 history loss 6.283218 rank 2
2022-12-08 11:57:30,722 DEBUG CV Batch 30/1700 loss 5.773659 loss_att 210.841339 loss_ctc 14.964962 loss_rnnt 4.752403 history loss 6.221147 rank 5
2022-12-08 11:57:30,868 DEBUG CV Batch 30/1700 loss 5.773659 loss_att 210.841339 loss_ctc 14.964962 loss_rnnt 4.752403 history loss 6.221147 rank 4
2022-12-08 11:57:31,628 DEBUG CV Batch 30/1700 loss 5.773659 loss_att 210.841339 loss_ctc 14.964962 loss_rnnt 4.752403 history loss 6.221147 rank 7
2022-12-08 11:57:32,239 DEBUG CV Batch 30/1700 loss 5.773659 loss_att 210.841339 loss_ctc 14.964962 loss_rnnt 4.752403 history loss 6.221147 rank 0
2022-12-08 11:57:32,427 DEBUG CV Batch 30/1700 loss 5.773659 loss_att 210.841339 loss_ctc 14.964962 loss_rnnt 4.752403 history loss 6.221147 rank 1
2022-12-08 11:57:33,464 DEBUG CV Batch 30/1700 loss 5.773659 loss_att 210.841339 loss_ctc 14.964962 loss_rnnt 4.752403 history loss 6.221147 rank 3
2022-12-08 11:57:33,980 DEBUG CV Batch 30/1700 loss 5.773659 loss_att 210.841339 loss_ctc 14.964962 loss_rnnt 4.752403 history loss 6.221147 rank 6
2022-12-08 11:57:35,970 DEBUG CV Batch 30/1700 loss 5.773659 loss_att 210.841339 loss_ctc 14.964962 loss_rnnt 4.752403 history loss 6.221147 rank 2
2022-12-08 11:57:39,802 INFO Epoch 30 CV info cv_loss 6.199786432348014
2022-12-08 11:57:39,802 INFO Epoch 31 TRAIN info lr 0.0002448707260963194
2022-12-08 11:57:39,804 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 11:57:39,896 INFO Epoch 30 CV info cv_loss 6.199786432348014
2022-12-08 11:57:39,897 INFO Epoch 31 TRAIN info lr 0.00024489686576903777
2022-12-08 11:57:39,900 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 11:57:40,663 INFO Epoch 30 CV info cv_loss 6.199786432348014
2022-12-08 11:57:40,664 INFO Epoch 31 TRAIN info lr 0.0002448742500583764
2022-12-08 11:57:40,667 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 11:57:41,180 INFO Epoch 30 CV info cv_loss 6.199786432348014
2022-12-08 11:57:41,180 INFO Epoch 31 TRAIN info lr 0.00024491508037648944
2022-12-08 11:57:41,185 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 11:57:41,831 INFO Epoch 30 CV info cv_loss 6.199786432348014
2022-12-08 11:57:41,832 INFO Checkpoint: save to checkpoint exp/1204_encoder_bias_nobi_noatt/30.pt
2022-12-08 11:57:43,068 INFO Epoch 30 CV info cv_loss 6.199786432348014
2022-12-08 11:57:43,068 INFO Epoch 30 CV info cv_loss 6.199786432348014
2022-12-08 11:57:43,068 INFO Epoch 31 TRAIN info lr 0.0002449006846242004
2022-12-08 11:57:43,068 INFO Epoch 31 TRAIN info lr 0.00024489451579311574
2022-12-08 11:57:43,072 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 11:57:43,072 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 11:57:43,120 INFO Epoch 31 TRAIN info lr 0.0002448721943953539
2022-12-08 11:57:43,125 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 11:57:44,842 INFO Epoch 30 CV info cv_loss 6.199786432348014
2022-12-08 11:57:44,842 INFO Epoch 31 TRAIN info lr 0.000244896278268715
2022-12-08 11:57:44,844 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 11:58:46,171 DEBUG TRAIN Batch 31/0 loss 6.627945 loss_att 67.463936 loss_ctc 9.954658 loss_rnnt 6.258310 lr 0.00024490 rank 5
2022-12-08 11:58:46,177 DEBUG TRAIN Batch 31/0 loss 7.456894 loss_att 73.779900 loss_ctc 10.304013 loss_rnnt 7.140548 lr 0.00024487 rank 7
2022-12-08 11:58:46,179 DEBUG TRAIN Batch 31/0 loss 8.007874 loss_att 76.660294 loss_ctc 13.415388 loss_rnnt 7.407040 lr 0.00024487 rank 4
2022-12-08 11:58:46,181 DEBUG TRAIN Batch 31/0 loss 7.148270 loss_att 86.026131 loss_ctc 12.032505 loss_rnnt 6.605577 lr 0.00024487 rank 0
2022-12-08 11:58:46,183 DEBUG TRAIN Batch 31/0 loss 13.074026 loss_att 86.278389 loss_ctc 20.756374 loss_rnnt 12.220432 lr 0.00024491 rank 1
2022-12-08 11:58:46,186 DEBUG TRAIN Batch 31/0 loss 6.524559 loss_att 77.591972 loss_ctc 9.960379 loss_rnnt 6.142801 lr 0.00024490 rank 6
2022-12-08 11:58:46,194 DEBUG TRAIN Batch 31/0 loss 6.273843 loss_att 66.673058 loss_ctc 9.301601 loss_rnnt 5.937426 lr 0.00024490 rank 2
2022-12-08 11:58:46,206 DEBUG TRAIN Batch 31/0 loss 9.440204 loss_att 73.927917 loss_ctc 13.465471 loss_rnnt 8.992952 lr 0.00024489 rank 3
2022-12-08 11:59:49,083 DEBUG TRAIN Batch 31/100 loss 7.052939 loss_att 415.405853 loss_ctc 21.926430 loss_rnnt 5.400330 lr 0.00024489 rank 1
2022-12-08 11:59:49,085 DEBUG TRAIN Batch 31/100 loss 2.478264 loss_att 378.823975 loss_ctc 3.568810 loss_rnnt 2.357092 lr 0.00024484 rank 7
2022-12-08 11:59:49,086 DEBUG TRAIN Batch 31/100 loss 12.180391 loss_att 417.764648 loss_ctc 31.895660 loss_rnnt 9.989805 lr 0.00024486 rank 3
2022-12-08 11:59:49,088 DEBUG TRAIN Batch 31/100 loss 13.468101 loss_att 376.488525 loss_ctc 26.146421 loss_rnnt 12.059399 lr 0.00024484 rank 0
2022-12-08 11:59:49,090 DEBUG TRAIN Batch 31/100 loss 2.878384 loss_att 342.471527 loss_ctc 3.890437 loss_rnnt 2.765934 lr 0.00024487 rank 2
2022-12-08 11:59:49,094 DEBUG TRAIN Batch 31/100 loss 1.870018 loss_att 371.707245 loss_ctc 6.447191 loss_rnnt 1.361444 lr 0.00024484 rank 4
2022-12-08 11:59:49,099 DEBUG TRAIN Batch 31/100 loss 11.346533 loss_att 457.307312 loss_ctc 22.127798 loss_rnnt 10.148615 lr 0.00024487 rank 5
2022-12-08 11:59:49,134 DEBUG TRAIN Batch 31/100 loss 3.494147 loss_att 393.752380 loss_ctc 8.326802 loss_rnnt 2.957186 lr 0.00024487 rank 6
2022-12-08 12:00:51,705 DEBUG TRAIN Batch 31/200 loss 8.247970 loss_att 454.336792 loss_ctc 16.872513 loss_rnnt 7.289687 lr 0.00024484 rank 6
2022-12-08 12:00:51,708 DEBUG TRAIN Batch 31/200 loss 4.337483 loss_att 361.179047 loss_ctc 6.180993 loss_rnnt 4.132648 lr 0.00024486 rank 1
2022-12-08 12:00:51,709 DEBUG TRAIN Batch 31/200 loss 6.326569 loss_att 296.053558 loss_ctc 11.370790 loss_rnnt 5.766100 lr 0.00024481 rank 4
2022-12-08 12:00:51,709 DEBUG TRAIN Batch 31/200 loss 5.859415 loss_att 436.595215 loss_ctc 24.581356 loss_rnnt 3.779199 lr 0.00024482 rank 7
2022-12-08 12:00:51,709 DEBUG TRAIN Batch 31/200 loss 2.984629 loss_att 367.087219 loss_ctc 10.843944 loss_rnnt 2.111372 lr 0.00024484 rank 3
2022-12-08 12:00:51,712 DEBUG TRAIN Batch 31/200 loss 4.097511 loss_att 321.294189 loss_ctc 6.167961 loss_rnnt 3.867461 lr 0.00024481 rank 0
2022-12-08 12:00:51,711 DEBUG TRAIN Batch 31/200 loss 1.964544 loss_att 352.322723 loss_ctc 6.509243 loss_rnnt 1.459577 lr 0.00024484 rank 5
2022-12-08 12:00:51,717 DEBUG TRAIN Batch 31/200 loss 7.642924 loss_att 341.212372 loss_ctc 13.737590 loss_rnnt 6.965739 lr 0.00024484 rank 2
2022-12-08 12:01:54,928 DEBUG TRAIN Batch 31/300 loss 7.651970 loss_att 374.577271 loss_ctc 15.484072 loss_rnnt 6.781737 lr 0.00024478 rank 0
2022-12-08 12:01:54,928 DEBUG TRAIN Batch 31/300 loss 7.158330 loss_att 316.790710 loss_ctc 15.782308 loss_rnnt 6.200110 lr 0.00024478 rank 4
2022-12-08 12:01:54,931 DEBUG TRAIN Batch 31/300 loss 2.434305 loss_att 337.146637 loss_ctc 7.073451 loss_rnnt 1.918844 lr 0.00024481 rank 3
2022-12-08 12:01:54,931 DEBUG TRAIN Batch 31/300 loss 5.626158 loss_att 355.482239 loss_ctc 10.011529 loss_rnnt 5.138895 lr 0.00024479 rank 7
2022-12-08 12:01:54,932 DEBUG TRAIN Batch 31/300 loss 8.197456 loss_att 426.494537 loss_ctc 15.654614 loss_rnnt 7.368883 lr 0.00024483 rank 1
2022-12-08 12:01:54,934 DEBUG TRAIN Batch 31/300 loss 10.791481 loss_att 355.276917 loss_ctc 22.572128 loss_rnnt 9.482521 lr 0.00024481 rank 6
2022-12-08 12:01:54,950 DEBUG TRAIN Batch 31/300 loss 2.144497 loss_att 349.152222 loss_ctc 8.078791 loss_rnnt 1.485131 lr 0.00024481 rank 5
2022-12-08 12:01:54,956 DEBUG TRAIN Batch 31/300 loss 13.749516 loss_att 301.665619 loss_ctc 20.855633 loss_rnnt 12.959948 lr 0.00024481 rank 2
2022-12-08 12:03:05,073 DEBUG TRAIN Batch 31/400 loss 11.601206 loss_att 388.198547 loss_ctc 21.230068 loss_rnnt 10.531332 lr 0.00024478 rank 6
2022-12-08 12:03:05,076 DEBUG TRAIN Batch 31/400 loss 11.902023 loss_att 296.151184 loss_ctc 19.857809 loss_rnnt 11.018047 lr 0.00024478 rank 2
2022-12-08 12:03:05,077 DEBUG TRAIN Batch 31/400 loss 6.894821 loss_att 359.300781 loss_ctc 11.773716 loss_rnnt 6.352722 lr 0.00024475 rank 0
2022-12-08 12:03:05,078 DEBUG TRAIN Batch 31/400 loss 7.501123 loss_att 428.131348 loss_ctc 27.919191 loss_rnnt 5.232449 lr 0.00024476 rank 7
2022-12-08 12:03:05,078 DEBUG TRAIN Batch 31/400 loss 7.275187 loss_att 346.195801 loss_ctc 15.639307 loss_rnnt 6.345840 lr 0.00024475 rank 4
2022-12-08 12:03:05,079 DEBUG TRAIN Batch 31/400 loss 6.169875 loss_att 394.893921 loss_ctc 13.648558 loss_rnnt 5.338911 lr 0.00024480 rank 1
2022-12-08 12:03:05,080 DEBUG TRAIN Batch 31/400 loss 5.736804 loss_att 351.648224 loss_ctc 11.168816 loss_rnnt 5.133247 lr 0.00024478 rank 5
2022-12-08 12:03:05,082 DEBUG TRAIN Batch 31/400 loss 9.382638 loss_att 409.592773 loss_ctc 23.241947 loss_rnnt 7.842715 lr 0.00024478 rank 3
2022-12-08 12:04:08,135 DEBUG TRAIN Batch 31/500 loss 11.355739 loss_att 347.544464 loss_ctc 20.568745 loss_rnnt 10.332071 lr 0.00024473 rank 7
2022-12-08 12:04:08,140 DEBUG TRAIN Batch 31/500 loss 7.482712 loss_att 283.436859 loss_ctc 15.098499 loss_rnnt 6.636514 lr 0.00024472 rank 4
2022-12-08 12:04:08,142 DEBUG TRAIN Batch 31/500 loss 8.579527 loss_att 291.043121 loss_ctc 17.900974 loss_rnnt 7.543810 lr 0.00024475 rank 6
2022-12-08 12:04:08,145 DEBUG TRAIN Batch 31/500 loss 11.277370 loss_att 309.132660 loss_ctc 22.064207 loss_rnnt 10.078834 lr 0.00024475 rank 2
2022-12-08 12:04:08,147 DEBUG TRAIN Batch 31/500 loss 5.307804 loss_att 275.249695 loss_ctc 9.837480 loss_rnnt 4.804506 lr 0.00024473 rank 0
2022-12-08 12:04:08,150 DEBUG TRAIN Batch 31/500 loss 9.139018 loss_att 358.456299 loss_ctc 20.964226 loss_rnnt 7.825106 lr 0.00024475 rank 3
2022-12-08 12:04:08,149 DEBUG TRAIN Batch 31/500 loss 6.047289 loss_att 265.222900 loss_ctc 9.895767 loss_rnnt 5.619680 lr 0.00024475 rank 5
2022-12-08 12:04:08,156 DEBUG TRAIN Batch 31/500 loss 17.894297 loss_att 318.433685 loss_ctc 37.551128 loss_rnnt 15.710205 lr 0.00024477 rank 1
2022-12-08 12:05:12,120 DEBUG TRAIN Batch 31/600 loss 6.002782 loss_att 187.901749 loss_ctc 11.614221 loss_rnnt 5.379289 lr 0.00024469 rank 4
2022-12-08 12:05:12,120 DEBUG TRAIN Batch 31/600 loss 8.451061 loss_att 293.989319 loss_ctc 17.492950 loss_rnnt 7.446407 lr 0.00024470 rank 7
2022-12-08 12:05:12,124 DEBUG TRAIN Batch 31/600 loss 7.034078 loss_att 203.546463 loss_ctc 12.068071 loss_rnnt 6.474746 lr 0.00024472 rank 2
2022-12-08 12:05:12,125 DEBUG TRAIN Batch 31/600 loss 4.857613 loss_att 171.791016 loss_ctc 11.529005 loss_rnnt 4.116347 lr 0.00024474 rank 1
2022-12-08 12:05:12,127 DEBUG TRAIN Batch 31/600 loss 9.790255 loss_att 72.444298 loss_ctc 13.881880 loss_rnnt 9.335629 lr 0.00024472 rank 6
2022-12-08 12:05:12,128 DEBUG TRAIN Batch 31/600 loss 9.695687 loss_att 241.601166 loss_ctc 13.836177 loss_rnnt 9.235634 lr 0.00024470 rank 0
2022-12-08 12:05:12,131 DEBUG TRAIN Batch 31/600 loss 10.137376 loss_att 230.302963 loss_ctc 17.955311 loss_rnnt 9.268717 lr 0.00024472 rank 5
2022-12-08 12:05:12,166 DEBUG TRAIN Batch 31/600 loss 4.209394 loss_att 236.551437 loss_ctc 13.445000 loss_rnnt 3.183215 lr 0.00024472 rank 3
2022-12-08 12:06:17,496 DEBUG TRAIN Batch 31/700 loss 8.946651 loss_att 475.814880 loss_ctc 25.387402 loss_rnnt 7.119901 lr 0.00024467 rank 7
2022-12-08 12:06:17,498 DEBUG TRAIN Batch 31/700 loss 5.444006 loss_att 378.184814 loss_ctc 12.284373 loss_rnnt 4.683966 lr 0.00024469 rank 3
2022-12-08 12:06:17,499 DEBUG TRAIN Batch 31/700 loss 5.363698 loss_att 399.127197 loss_ctc 7.116993 loss_rnnt 5.168888 lr 0.00024471 rank 1
2022-12-08 12:06:17,501 DEBUG TRAIN Batch 31/700 loss 7.040786 loss_att 373.421387 loss_ctc 16.054775 loss_rnnt 6.039232 lr 0.00024467 rank 4
2022-12-08 12:06:17,502 DEBUG TRAIN Batch 31/700 loss 10.286557 loss_att 415.608398 loss_ctc 20.498085 loss_rnnt 9.151943 lr 0.00024467 rank 0
2022-12-08 12:06:17,503 DEBUG TRAIN Batch 31/700 loss 4.617795 loss_att 331.587494 loss_ctc 13.029902 loss_rnnt 3.683117 lr 0.00024469 rank 2
2022-12-08 12:06:17,503 DEBUG TRAIN Batch 31/700 loss 6.192465 loss_att 399.253265 loss_ctc 15.717113 loss_rnnt 5.134171 lr 0.00024470 rank 6
2022-12-08 12:06:17,507 DEBUG TRAIN Batch 31/700 loss 3.913384 loss_att 384.044617 loss_ctc 12.714409 loss_rnnt 2.935492 lr 0.00024469 rank 5
2022-12-08 12:07:26,517 DEBUG TRAIN Batch 31/800 loss 6.665650 loss_att 371.042816 loss_ctc 8.400045 loss_rnnt 6.472939 lr 0.00024464 rank 7
2022-12-08 12:07:26,517 DEBUG TRAIN Batch 31/800 loss 6.821891 loss_att 378.165466 loss_ctc 12.705725 loss_rnnt 6.168132 lr 0.00024468 rank 1
2022-12-08 12:07:26,517 DEBUG TRAIN Batch 31/800 loss 11.421740 loss_att 443.238373 loss_ctc 26.570784 loss_rnnt 9.738512 lr 0.00024464 rank 4
2022-12-08 12:07:26,518 DEBUG TRAIN Batch 31/800 loss 7.326393 loss_att 389.777557 loss_ctc 13.753527 loss_rnnt 6.612267 lr 0.00024467 rank 6
2022-12-08 12:07:26,518 DEBUG TRAIN Batch 31/800 loss 5.033169 loss_att 294.790405 loss_ctc 7.824757 loss_rnnt 4.722993 lr 0.00024464 rank 0
2022-12-08 12:07:26,520 DEBUG TRAIN Batch 31/800 loss 5.215161 loss_att 415.830902 loss_ctc 11.822051 loss_rnnt 4.481062 lr 0.00024466 rank 3
2022-12-08 12:07:26,525 DEBUG TRAIN Batch 31/800 loss 1.980502 loss_att 410.882172 loss_ctc 6.007072 loss_rnnt 1.533105 lr 0.00024466 rank 2
2022-12-08 12:07:26,559 DEBUG TRAIN Batch 31/800 loss 3.129437 loss_att 307.742462 loss_ctc 6.220168 loss_rnnt 2.786023 lr 0.00024466 rank 5
2022-12-08 12:08:29,383 DEBUG TRAIN Batch 31/900 loss 10.299187 loss_att 399.488617 loss_ctc 17.876953 loss_rnnt 9.457213 lr 0.00024463 rank 3
2022-12-08 12:08:29,384 DEBUG TRAIN Batch 31/900 loss 5.066054 loss_att 395.206390 loss_ctc 10.510294 loss_rnnt 4.461139 lr 0.00024461 rank 7
2022-12-08 12:08:29,386 DEBUG TRAIN Batch 31/900 loss 8.389928 loss_att 381.803314 loss_ctc 18.356434 loss_rnnt 7.282538 lr 0.00024461 rank 4
2022-12-08 12:08:29,386 DEBUG TRAIN Batch 31/900 loss 9.281605 loss_att 363.321167 loss_ctc 15.406552 loss_rnnt 8.601055 lr 0.00024465 rank 1
2022-12-08 12:08:29,387 DEBUG TRAIN Batch 31/900 loss 7.386546 loss_att 334.240936 loss_ctc 14.683037 loss_rnnt 6.575825 lr 0.00024464 rank 6
2022-12-08 12:08:29,389 DEBUG TRAIN Batch 31/900 loss 5.165013 loss_att 369.510956 loss_ctc 14.673605 loss_rnnt 4.108503 lr 0.00024461 rank 0
2022-12-08 12:08:29,390 DEBUG TRAIN Batch 31/900 loss 7.236330 loss_att 367.045959 loss_ctc 10.144524 loss_rnnt 6.913198 lr 0.00024463 rank 5
2022-12-08 12:08:29,392 DEBUG TRAIN Batch 31/900 loss 1.974147 loss_att 347.004974 loss_ctc 8.813238 loss_rnnt 1.214248 lr 0.00024463 rank 2
2022-12-08 12:09:33,399 DEBUG TRAIN Batch 31/1000 loss 3.740819 loss_att 346.028992 loss_ctc 15.806372 loss_rnnt 2.400202 lr 0.00024462 rank 1
2022-12-08 12:09:33,400 DEBUG TRAIN Batch 31/1000 loss 11.665950 loss_att 390.682678 loss_ctc 25.425335 loss_rnnt 10.137129 lr 0.00024458 rank 7
2022-12-08 12:09:33,400 DEBUG TRAIN Batch 31/1000 loss 2.742033 loss_att 295.032135 loss_ctc 7.497911 loss_rnnt 2.213602 lr 0.00024458 rank 4
2022-12-08 12:09:33,404 DEBUG TRAIN Batch 31/1000 loss 6.604355 loss_att 354.283752 loss_ctc 12.527098 loss_rnnt 5.946273 lr 0.00024460 rank 3
2022-12-08 12:09:33,404 DEBUG TRAIN Batch 31/1000 loss 11.331049 loss_att 348.579712 loss_ctc 23.592205 loss_rnnt 9.968699 lr 0.00024460 rank 2
2022-12-08 12:09:33,404 DEBUG TRAIN Batch 31/1000 loss 10.498213 loss_att 342.544189 loss_ctc 11.456039 loss_rnnt 10.391788 lr 0.00024461 rank 6
2022-12-08 12:09:33,405 DEBUG TRAIN Batch 31/1000 loss 5.981480 loss_att 376.185181 loss_ctc 14.523988 loss_rnnt 5.032313 lr 0.00024460 rank 5
2022-12-08 12:09:33,416 DEBUG TRAIN Batch 31/1000 loss 10.056087 loss_att 339.104492 loss_ctc 14.788033 loss_rnnt 9.530315 lr 0.00024458 rank 0
2022-12-08 12:10:43,598 DEBUG TRAIN Batch 31/1100 loss 7.270530 loss_att 335.739624 loss_ctc 10.437252 loss_rnnt 6.918672 lr 0.00024455 rank 7
2022-12-08 12:10:43,599 DEBUG TRAIN Batch 31/1100 loss 8.998718 loss_att 361.307617 loss_ctc 22.688751 loss_rnnt 7.477604 lr 0.00024458 rank 6
2022-12-08 12:10:43,600 DEBUG TRAIN Batch 31/1100 loss 1.791816 loss_att 278.151245 loss_ctc 4.479718 loss_rnnt 1.493161 lr 0.00024455 rank 4
2022-12-08 12:10:43,604 DEBUG TRAIN Batch 31/1100 loss 3.831476 loss_att 366.724060 loss_ctc 11.304247 loss_rnnt 3.001168 lr 0.00024457 rank 3
2022-12-08 12:10:43,604 DEBUG TRAIN Batch 31/1100 loss 9.323205 loss_att 381.323547 loss_ctc 19.708965 loss_rnnt 8.169232 lr 0.00024457 rank 5
2022-12-08 12:10:43,606 DEBUG TRAIN Batch 31/1100 loss 7.473647 loss_att 374.466858 loss_ctc 9.235602 loss_rnnt 7.277874 lr 0.00024457 rank 2
2022-12-08 12:10:43,606 DEBUG TRAIN Batch 31/1100 loss 3.821322 loss_att 354.539398 loss_ctc 14.062817 loss_rnnt 2.683379 lr 0.00024455 rank 0
2022-12-08 12:10:43,607 DEBUG TRAIN Batch 31/1100 loss 12.107162 loss_att 312.418152 loss_ctc 22.229435 loss_rnnt 10.982466 lr 0.00024459 rank 1
2022-12-08 12:11:47,257 DEBUG TRAIN Batch 31/1200 loss 4.362676 loss_att 311.908173 loss_ctc 9.700675 loss_rnnt 3.769564 lr 0.00024452 rank 7
2022-12-08 12:11:47,258 DEBUG TRAIN Batch 31/1200 loss 9.931656 loss_att 250.842209 loss_ctc 17.734205 loss_rnnt 9.064707 lr 0.00024455 rank 6
2022-12-08 12:11:47,259 DEBUG TRAIN Batch 31/1200 loss 10.757834 loss_att 263.742432 loss_ctc 18.024881 loss_rnnt 9.950385 lr 0.00024456 rank 1
2022-12-08 12:11:47,261 DEBUG TRAIN Batch 31/1200 loss 5.023881 loss_att 340.349457 loss_ctc 12.408342 loss_rnnt 4.203385 lr 0.00024454 rank 3
2022-12-08 12:11:47,261 DEBUG TRAIN Batch 31/1200 loss 15.463678 loss_att 275.959534 loss_ctc 25.809708 loss_rnnt 14.314120 lr 0.00024452 rank 4
2022-12-08 12:11:47,263 DEBUG TRAIN Batch 31/1200 loss 12.176018 loss_att 307.601501 loss_ctc 20.838287 loss_rnnt 11.213543 lr 0.00024452 rank 0
2022-12-08 12:11:47,273 DEBUG TRAIN Batch 31/1200 loss 6.500551 loss_att 300.842773 loss_ctc 13.597279 loss_rnnt 5.712026 lr 0.00024454 rank 5
2022-12-08 12:11:47,306 DEBUG TRAIN Batch 31/1200 loss 7.756748 loss_att 243.376694 loss_ctc 13.690242 loss_rnnt 7.097471 lr 0.00024454 rank 2
2022-12-08 12:12:50,779 DEBUG TRAIN Batch 31/1300 loss 4.041685 loss_att 138.024261 loss_ctc 7.365332 loss_rnnt 3.672391 lr 0.00024451 rank 3
2022-12-08 12:12:50,781 DEBUG TRAIN Batch 31/1300 loss 12.057635 loss_att 376.106781 loss_ctc 28.623531 loss_rnnt 10.216980 lr 0.00024452 rank 6
2022-12-08 12:12:50,782 DEBUG TRAIN Batch 31/1300 loss 18.747564 loss_att 410.102264 loss_ctc 32.539230 loss_rnnt 17.215157 lr 0.00024453 rank 1
2022-12-08 12:12:50,782 DEBUG TRAIN Batch 31/1300 loss 7.627484 loss_att 237.534363 loss_ctc 16.562475 loss_rnnt 6.634707 lr 0.00024452 rank 5
2022-12-08 12:12:50,783 DEBUG TRAIN Batch 31/1300 loss 6.161717 loss_att 303.312714 loss_ctc 12.882147 loss_rnnt 5.415003 lr 0.00024449 rank 4
2022-12-08 12:12:50,786 DEBUG TRAIN Batch 31/1300 loss 10.861053 loss_att 115.176903 loss_ctc 17.438450 loss_rnnt 10.130232 lr 0.00024449 rank 7
2022-12-08 12:12:50,787 DEBUG TRAIN Batch 31/1300 loss 8.389905 loss_att 447.814514 loss_ctc 20.830204 loss_rnnt 7.007650 lr 0.00024452 rank 2
2022-12-08 12:12:50,791 DEBUG TRAIN Batch 31/1300 loss 2.239729 loss_att 433.435394 loss_ctc 10.330271 loss_rnnt 1.340780 lr 0.00024449 rank 0
2022-12-08 12:13:55,445 DEBUG TRAIN Batch 31/1400 loss 2.685041 loss_att 317.417908 loss_ctc 3.186502 loss_rnnt 2.629324 lr 0.00024449 rank 6
2022-12-08 12:13:55,445 DEBUG TRAIN Batch 31/1400 loss 10.955873 loss_att 434.916992 loss_ctc 15.674616 loss_rnnt 10.431569 lr 0.00024446 rank 7
2022-12-08 12:13:55,448 DEBUG TRAIN Batch 31/1400 loss 6.933717 loss_att 408.786255 loss_ctc 13.087859 loss_rnnt 6.249923 lr 0.00024450 rank 1
2022-12-08 12:13:55,452 DEBUG TRAIN Batch 31/1400 loss 5.943576 loss_att 353.627167 loss_ctc 12.833986 loss_rnnt 5.177975 lr 0.00024449 rank 2
2022-12-08 12:13:55,451 DEBUG TRAIN Batch 31/1400 loss 3.821799 loss_att 310.523285 loss_ctc 11.830513 loss_rnnt 2.931942 lr 0.00024448 rank 3
2022-12-08 12:13:55,452 DEBUG TRAIN Batch 31/1400 loss 5.051585 loss_att 389.456146 loss_ctc 11.588550 loss_rnnt 4.325256 lr 0.00024446 rank 0
2022-12-08 12:13:55,453 DEBUG TRAIN Batch 31/1400 loss 6.843686 loss_att 349.730316 loss_ctc 13.879906 loss_rnnt 6.061884 lr 0.00024449 rank 5
2022-12-08 12:13:55,453 DEBUG TRAIN Batch 31/1400 loss 9.397338 loss_att 296.232605 loss_ctc 18.435675 loss_rnnt 8.393078 lr 0.00024446 rank 4
2022-12-08 12:15:06,103 DEBUG TRAIN Batch 31/1500 loss 8.740510 loss_att 373.190918 loss_ctc 17.399603 loss_rnnt 7.778389 lr 0.00024446 rank 6
2022-12-08 12:15:06,104 DEBUG TRAIN Batch 31/1500 loss 6.046176 loss_att 390.293152 loss_ctc 11.563809 loss_rnnt 5.433105 lr 0.00024443 rank 4
2022-12-08 12:15:06,106 DEBUG TRAIN Batch 31/1500 loss 8.920971 loss_att 359.735107 loss_ctc 17.774603 loss_rnnt 7.937234 lr 0.00024445 rank 3
2022-12-08 12:15:06,110 DEBUG TRAIN Batch 31/1500 loss 11.763387 loss_att 397.809448 loss_ctc 24.998543 loss_rnnt 10.292814 lr 0.00024443 rank 7
2022-12-08 12:15:06,111 DEBUG TRAIN Batch 31/1500 loss 1.871482 loss_att 319.970367 loss_ctc 5.644100 loss_rnnt 1.452303 lr 0.00024443 rank 0
2022-12-08 12:15:06,128 DEBUG TRAIN Batch 31/1500 loss 2.834327 loss_att 368.432617 loss_ctc 7.827285 loss_rnnt 2.279553 lr 0.00024446 rank 2
2022-12-08 12:15:06,134 DEBUG TRAIN Batch 31/1500 loss 5.349694 loss_att 372.086029 loss_ctc 10.220428 loss_rnnt 4.808502 lr 0.00024448 rank 1
2022-12-08 12:15:06,147 DEBUG TRAIN Batch 31/1500 loss 2.654650 loss_att 337.909729 loss_ctc 4.425631 loss_rnnt 2.457875 lr 0.00024446 rank 5
2022-12-08 12:16:09,696 DEBUG TRAIN Batch 31/1600 loss 10.686901 loss_att 374.625916 loss_ctc 25.306444 loss_rnnt 9.062508 lr 0.00024440 rank 4
2022-12-08 12:16:09,699 DEBUG TRAIN Batch 31/1600 loss 6.365491 loss_att 362.859772 loss_ctc 12.242395 loss_rnnt 5.712502 lr 0.00024443 rank 3
2022-12-08 12:16:09,699 DEBUG TRAIN Batch 31/1600 loss 9.256456 loss_att 382.007751 loss_ctc 18.060490 loss_rnnt 8.278231 lr 0.00024445 rank 1
2022-12-08 12:16:09,700 DEBUG TRAIN Batch 31/1600 loss 3.366117 loss_att 383.728912 loss_ctc 11.238475 loss_rnnt 2.491411 lr 0.00024443 rank 5
2022-12-08 12:16:09,701 DEBUG TRAIN Batch 31/1600 loss 10.691691 loss_att 372.300598 loss_ctc 22.782436 loss_rnnt 9.348275 lr 0.00024443 rank 6
2022-12-08 12:16:09,704 DEBUG TRAIN Batch 31/1600 loss 5.712480 loss_att 418.388855 loss_ctc 11.961044 loss_rnnt 5.018195 lr 0.00024440 rank 0
2022-12-08 12:16:09,703 DEBUG TRAIN Batch 31/1600 loss 9.112802 loss_att 363.682373 loss_ctc 15.805885 loss_rnnt 8.369125 lr 0.00024443 rank 2
2022-12-08 12:16:09,706 DEBUG TRAIN Batch 31/1600 loss 11.131439 loss_att 360.534454 loss_ctc 23.883127 loss_rnnt 9.714585 lr 0.00024441 rank 7
2022-12-08 12:17:13,633 DEBUG TRAIN Batch 31/1700 loss 13.934700 loss_att 376.141663 loss_ctc 28.750290 loss_rnnt 12.288524 lr 0.00024440 rank 5
2022-12-08 12:17:13,633 DEBUG TRAIN Batch 31/1700 loss 5.424485 loss_att 368.280212 loss_ctc 12.280817 loss_rnnt 4.662670 lr 0.00024437 rank 4
2022-12-08 12:17:13,633 DEBUG TRAIN Batch 31/1700 loss 10.090151 loss_att 397.394989 loss_ctc 20.382494 loss_rnnt 8.946558 lr 0.00024438 rank 7
2022-12-08 12:17:13,636 DEBUG TRAIN Batch 31/1700 loss 9.386010 loss_att 337.495392 loss_ctc 18.539169 loss_rnnt 8.368993 lr 0.00024440 rank 3
2022-12-08 12:17:13,639 DEBUG TRAIN Batch 31/1700 loss 4.733695 loss_att 315.938812 loss_ctc 15.301186 loss_rnnt 3.559529 lr 0.00024440 rank 2
2022-12-08 12:17:13,639 DEBUG TRAIN Batch 31/1700 loss 5.783930 loss_att 306.933594 loss_ctc 10.526008 loss_rnnt 5.257033 lr 0.00024437 rank 0
2022-12-08 12:17:13,642 DEBUG TRAIN Batch 31/1700 loss 7.120598 loss_att 307.587006 loss_ctc 19.849630 loss_rnnt 5.706262 lr 0.00024442 rank 1
2022-12-08 12:17:13,671 DEBUG TRAIN Batch 31/1700 loss 8.394498 loss_att 349.931274 loss_ctc 15.294439 loss_rnnt 7.627838 lr 0.00024440 rank 6
2022-12-08 12:18:25,065 DEBUG TRAIN Batch 31/1800 loss 6.595346 loss_att 303.428802 loss_ctc 12.393506 loss_rnnt 5.951107 lr 0.00024434 rank 4
2022-12-08 12:18:25,066 DEBUG TRAIN Batch 31/1800 loss 11.317207 loss_att 320.103638 loss_ctc 17.030867 loss_rnnt 10.682357 lr 0.00024437 rank 2
2022-12-08 12:18:25,067 DEBUG TRAIN Batch 31/1800 loss 9.306048 loss_att 353.001801 loss_ctc 15.546892 loss_rnnt 8.612621 lr 0.00024435 rank 7
2022-12-08 12:18:25,067 DEBUG TRAIN Batch 31/1800 loss 5.263589 loss_att 215.897873 loss_ctc 10.896196 loss_rnnt 4.637744 lr 0.00024439 rank 1
2022-12-08 12:18:25,068 DEBUG TRAIN Batch 31/1800 loss 5.700416 loss_att 325.986908 loss_ctc 13.450843 loss_rnnt 4.839258 lr 0.00024435 rank 0
2022-12-08 12:18:25,072 DEBUG TRAIN Batch 31/1800 loss 13.820970 loss_att 337.711578 loss_ctc 26.265850 loss_rnnt 12.438206 lr 0.00024437 rank 3
2022-12-08 12:18:25,073 DEBUG TRAIN Batch 31/1800 loss 11.058987 loss_att 331.856567 loss_ctc 25.682869 loss_rnnt 9.434112 lr 0.00024437 rank 5
2022-12-08 12:18:25,108 DEBUG TRAIN Batch 31/1800 loss 7.922290 loss_att 212.526901 loss_ctc 14.378924 loss_rnnt 7.204886 lr 0.00024437 rank 6
2022-12-08 12:19:28,633 DEBUG TRAIN Batch 31/1900 loss 7.928319 loss_att 246.062912 loss_ctc 15.404831 loss_rnnt 7.097595 lr 0.00024432 rank 7
2022-12-08 12:19:28,634 DEBUG TRAIN Batch 31/1900 loss 12.978187 loss_att 390.954681 loss_ctc 27.310436 loss_rnnt 11.385715 lr 0.00024434 rank 6
2022-12-08 12:19:28,636 DEBUG TRAIN Batch 31/1900 loss 10.523862 loss_att 76.281097 loss_ctc 15.843804 loss_rnnt 9.932757 lr 0.00024431 rank 4
2022-12-08 12:19:28,640 DEBUG TRAIN Batch 31/1900 loss 6.815172 loss_att 136.776535 loss_ctc 10.945655 loss_rnnt 6.356229 lr 0.00024434 rank 2
2022-12-08 12:19:28,642 DEBUG TRAIN Batch 31/1900 loss 9.199754 loss_att 230.866501 loss_ctc 17.372807 loss_rnnt 8.291637 lr 0.00024434 rank 5
2022-12-08 12:19:28,642 DEBUG TRAIN Batch 31/1900 loss 6.584743 loss_att 382.687805 loss_ctc 12.761890 loss_rnnt 5.898393 lr 0.00024436 rank 1
2022-12-08 12:19:28,644 DEBUG TRAIN Batch 31/1900 loss 6.908994 loss_att 184.136276 loss_ctc 10.785480 loss_rnnt 6.478273 lr 0.00024432 rank 0
2022-12-08 12:19:28,686 DEBUG TRAIN Batch 31/1900 loss 9.673361 loss_att 234.192596 loss_ctc 19.006691 loss_rnnt 8.636324 lr 0.00024434 rank 3
2022-12-08 12:20:31,572 DEBUG TRAIN Batch 31/2000 loss 1.564406 loss_att 410.243530 loss_ctc 7.324604 loss_rnnt 0.924384 lr 0.00024429 rank 7
2022-12-08 12:20:31,577 DEBUG TRAIN Batch 31/2000 loss 5.345048 loss_att 326.488647 loss_ctc 9.417072 loss_rnnt 4.892601 lr 0.00024429 rank 4
2022-12-08 12:20:31,579 DEBUG TRAIN Batch 31/2000 loss 3.107379 loss_att 380.946991 loss_ctc 7.487876 loss_rnnt 2.620657 lr 0.00024429 rank 0
2022-12-08 12:20:31,580 DEBUG TRAIN Batch 31/2000 loss 2.494241 loss_att 391.719238 loss_ctc 7.332414 loss_rnnt 1.956667 lr 0.00024431 rank 3
2022-12-08 12:20:31,582 DEBUG TRAIN Batch 31/2000 loss 10.072007 loss_att 423.047333 loss_ctc 18.187048 loss_rnnt 9.170337 lr 0.00024433 rank 1
2022-12-08 12:20:31,597 DEBUG TRAIN Batch 31/2000 loss 8.206805 loss_att 395.886963 loss_ctc 14.857506 loss_rnnt 7.467839 lr 0.00024431 rank 6
2022-12-08 12:20:31,604 DEBUG TRAIN Batch 31/2000 loss 6.791806 loss_att 338.794861 loss_ctc 11.507068 loss_rnnt 6.267889 lr 0.00024431 rank 2
2022-12-08 12:20:31,626 DEBUG TRAIN Batch 31/2000 loss 19.329969 loss_att 386.840912 loss_ctc 34.530983 loss_rnnt 17.640968 lr 0.00024431 rank 5
2022-12-08 12:21:36,766 DEBUG TRAIN Batch 31/2100 loss 2.552574 loss_att 403.879395 loss_ctc 11.295595 loss_rnnt 1.581127 lr 0.00024426 rank 7
2022-12-08 12:21:36,766 DEBUG TRAIN Batch 31/2100 loss 8.521323 loss_att 367.730774 loss_ctc 19.414785 loss_rnnt 7.310939 lr 0.00024428 rank 2
2022-12-08 12:21:36,767 DEBUG TRAIN Batch 31/2100 loss 5.236179 loss_att 410.295654 loss_ctc 16.080082 loss_rnnt 4.031301 lr 0.00024428 rank 3
2022-12-08 12:21:36,768 DEBUG TRAIN Batch 31/2100 loss 4.781813 loss_att 423.375183 loss_ctc 10.915493 loss_rnnt 4.100293 lr 0.00024429 rank 6
2022-12-08 12:21:36,769 DEBUG TRAIN Batch 31/2100 loss 2.931909 loss_att 353.260498 loss_ctc 8.488833 loss_rnnt 2.314473 lr 0.00024430 rank 1
2022-12-08 12:21:36,769 DEBUG TRAIN Batch 31/2100 loss 8.366731 loss_att 387.934418 loss_ctc 11.974864 loss_rnnt 7.965827 lr 0.00024426 rank 4
2022-12-08 12:21:36,771 DEBUG TRAIN Batch 31/2100 loss 3.854566 loss_att 396.926270 loss_ctc 15.070307 loss_rnnt 2.608372 lr 0.00024426 rank 0
2022-12-08 12:21:36,772 DEBUG TRAIN Batch 31/2100 loss 10.107637 loss_att 412.413422 loss_ctc 23.457062 loss_rnnt 8.624368 lr 0.00024428 rank 5
2022-12-08 12:22:48,609 DEBUG TRAIN Batch 31/2200 loss 2.748507 loss_att 382.345673 loss_ctc 7.928202 loss_rnnt 2.172985 lr 0.00024423 rank 4
2022-12-08 12:22:48,613 DEBUG TRAIN Batch 31/2200 loss 4.762197 loss_att 267.859711 loss_ctc 8.796240 loss_rnnt 4.313970 lr 0.00024425 rank 2
2022-12-08 12:22:48,614 DEBUG TRAIN Batch 31/2200 loss 4.524380 loss_att 343.432037 loss_ctc 9.145592 loss_rnnt 4.010912 lr 0.00024425 rank 5
2022-12-08 12:22:48,614 DEBUG TRAIN Batch 31/2200 loss 14.945981 loss_att 436.901794 loss_ctc 40.920181 loss_rnnt 12.059959 lr 0.00024423 rank 7
2022-12-08 12:22:48,614 DEBUG TRAIN Batch 31/2200 loss 6.264112 loss_att 423.260193 loss_ctc 16.266726 loss_rnnt 5.152710 lr 0.00024427 rank 1
2022-12-08 12:22:48,615 DEBUG TRAIN Batch 31/2200 loss 5.895585 loss_att 370.981232 loss_ctc 15.350410 loss_rnnt 4.845049 lr 0.00024423 rank 0
2022-12-08 12:22:48,619 DEBUG TRAIN Batch 31/2200 loss 6.433309 loss_att 330.910828 loss_ctc 22.782917 loss_rnnt 4.616686 lr 0.00024426 rank 6
2022-12-08 12:22:48,620 DEBUG TRAIN Batch 31/2200 loss 16.088011 loss_att 401.402588 loss_ctc 30.967724 loss_rnnt 14.434710 lr 0.00024425 rank 3
2022-12-08 12:23:51,849 DEBUG TRAIN Batch 31/2300 loss 8.571011 loss_att 364.491943 loss_ctc 19.768620 loss_rnnt 7.326832 lr 0.00024420 rank 7
2022-12-08 12:23:51,849 DEBUG TRAIN Batch 31/2300 loss 4.277251 loss_att 384.345642 loss_ctc 11.745619 loss_rnnt 3.447433 lr 0.00024423 rank 6
2022-12-08 12:23:51,850 DEBUG TRAIN Batch 31/2300 loss 5.189095 loss_att 370.058960 loss_ctc 12.301443 loss_rnnt 4.398834 lr 0.00024422 rank 2
2022-12-08 12:23:51,851 DEBUG TRAIN Batch 31/2300 loss 7.493814 loss_att 419.626465 loss_ctc 23.775021 loss_rnnt 5.684791 lr 0.00024420 rank 4
2022-12-08 12:23:51,851 DEBUG TRAIN Batch 31/2300 loss 6.641063 loss_att 408.133179 loss_ctc 18.677906 loss_rnnt 5.303636 lr 0.00024420 rank 0
2022-12-08 12:23:51,855 DEBUG TRAIN Batch 31/2300 loss 8.314095 loss_att 371.902466 loss_ctc 18.001556 loss_rnnt 7.237710 lr 0.00024424 rank 1
2022-12-08 12:23:51,855 DEBUG TRAIN Batch 31/2300 loss 8.235022 loss_att 397.761749 loss_ctc 14.679617 loss_rnnt 7.518956 lr 0.00024422 rank 3
2022-12-08 12:23:51,858 DEBUG TRAIN Batch 31/2300 loss 6.948780 loss_att 376.864807 loss_ctc 11.638908 loss_rnnt 6.427654 lr 0.00024422 rank 5
2022-12-08 12:24:55,461 DEBUG TRAIN Batch 31/2400 loss 9.425418 loss_att 331.855499 loss_ctc 14.392497 loss_rnnt 8.873520 lr 0.00024417 rank 4
2022-12-08 12:24:55,464 DEBUG TRAIN Batch 31/2400 loss 3.575478 loss_att 294.726013 loss_ctc 6.658199 loss_rnnt 3.232954 lr 0.00024417 rank 7
2022-12-08 12:24:55,463 DEBUG TRAIN Batch 31/2400 loss 7.278220 loss_att 355.992523 loss_ctc 11.070807 loss_rnnt 6.856822 lr 0.00024419 rank 3
2022-12-08 12:24:55,470 DEBUG TRAIN Batch 31/2400 loss 10.178625 loss_att 308.454529 loss_ctc 16.647289 loss_rnnt 9.459885 lr 0.00024417 rank 0
2022-12-08 12:24:55,470 DEBUG TRAIN Batch 31/2400 loss 7.729799 loss_att 352.504761 loss_ctc 17.414898 loss_rnnt 6.653677 lr 0.00024419 rank 5
2022-12-08 12:24:55,474 DEBUG TRAIN Batch 31/2400 loss 8.693905 loss_att 333.858154 loss_ctc 17.056473 loss_rnnt 7.764731 lr 0.00024421 rank 1
2022-12-08 12:24:55,483 DEBUG TRAIN Batch 31/2400 loss 7.631754 loss_att 307.296295 loss_ctc 14.717306 loss_rnnt 6.844471 lr 0.00024419 rank 2
2022-12-08 12:24:55,490 DEBUG TRAIN Batch 31/2400 loss 12.618355 loss_att 245.011444 loss_ctc 17.271933 loss_rnnt 12.101292 lr 0.00024420 rank 6
2022-12-08 12:26:05,225 DEBUG TRAIN Batch 31/2500 loss 8.897603 loss_att 195.102905 loss_ctc 14.929312 loss_rnnt 8.227413 lr 0.00024414 rank 4
2022-12-08 12:26:05,229 DEBUG TRAIN Batch 31/2500 loss 5.673009 loss_att 268.558075 loss_ctc 12.164485 loss_rnnt 4.951734 lr 0.00024416 rank 3
2022-12-08 12:26:05,230 DEBUG TRAIN Batch 31/2500 loss 8.937432 loss_att 316.006073 loss_ctc 19.156393 loss_rnnt 7.801993 lr 0.00024414 rank 7
2022-12-08 12:26:05,230 DEBUG TRAIN Batch 31/2500 loss 6.403358 loss_att 250.377411 loss_ctc 12.519722 loss_rnnt 5.723762 lr 0.00024418 rank 1
2022-12-08 12:26:05,234 DEBUG TRAIN Batch 31/2500 loss 5.815767 loss_att 180.214508 loss_ctc 11.431874 loss_rnnt 5.191755 lr 0.00024414 rank 0
2022-12-08 12:26:05,234 DEBUG TRAIN Batch 31/2500 loss 10.448403 loss_att 231.924271 loss_ctc 12.427779 loss_rnnt 10.228473 lr 0.00024417 rank 5
2022-12-08 12:26:05,246 DEBUG TRAIN Batch 31/2500 loss 6.296200 loss_att 286.075439 loss_ctc 13.071109 loss_rnnt 5.543433 lr 0.00024416 rank 2
2022-12-08 12:26:05,274 DEBUG TRAIN Batch 31/2500 loss 5.994212 loss_att 361.251770 loss_ctc 21.735365 loss_rnnt 4.245195 lr 0.00024417 rank 6
2022-12-08 12:27:08,767 DEBUG TRAIN Batch 31/2600 loss 6.962380 loss_att 375.450317 loss_ctc 10.227751 loss_rnnt 6.599562 lr 0.00024411 rank 4
2022-12-08 12:27:08,773 DEBUG TRAIN Batch 31/2600 loss 9.003513 loss_att 414.461029 loss_ctc 24.402386 loss_rnnt 7.292528 lr 0.00024411 rank 0
2022-12-08 12:27:08,774 DEBUG TRAIN Batch 31/2600 loss 5.873405 loss_att 376.389008 loss_ctc 12.536571 loss_rnnt 5.133053 lr 0.00024411 rank 7
2022-12-08 12:27:08,776 DEBUG TRAIN Batch 31/2600 loss 2.172514 loss_att 437.735107 loss_ctc 6.065477 loss_rnnt 1.739962 lr 0.00024413 rank 3
2022-12-08 12:27:08,777 DEBUG TRAIN Batch 31/2600 loss 3.698768 loss_att 419.430267 loss_ctc 8.012367 loss_rnnt 3.219479 lr 0.00024414 rank 5
2022-12-08 12:27:08,776 DEBUG TRAIN Batch 31/2600 loss 4.962018 loss_att 352.787537 loss_ctc 9.226036 loss_rnnt 4.488238 lr 0.00024415 rank 1
2022-12-08 12:27:08,777 DEBUG TRAIN Batch 31/2600 loss 5.309206 loss_att 431.086853 loss_ctc 11.685420 loss_rnnt 4.600739 lr 0.00024414 rank 6
2022-12-08 12:27:08,780 DEBUG TRAIN Batch 31/2600 loss 6.055322 loss_att 427.802307 loss_ctc 14.660834 loss_rnnt 5.099154 lr 0.00024414 rank 2
2022-12-08 12:28:12,088 DEBUG TRAIN Batch 31/2700 loss 6.340587 loss_att 404.585144 loss_ctc 12.899990 loss_rnnt 5.611764 lr 0.00024410 rank 3
2022-12-08 12:28:12,096 DEBUG TRAIN Batch 31/2700 loss 7.207035 loss_att 386.674561 loss_ctc 13.539474 loss_rnnt 6.503431 lr 0.00024408 rank 4
2022-12-08 12:28:12,100 DEBUG TRAIN Batch 31/2700 loss 5.877989 loss_att 358.769470 loss_ctc 13.138260 loss_rnnt 5.071292 lr 0.00024411 rank 6
2022-12-08 12:28:12,102 DEBUG TRAIN Batch 31/2700 loss 6.080471 loss_att 380.756927 loss_ctc 13.546854 loss_rnnt 5.250873 lr 0.00024408 rank 7
2022-12-08 12:28:12,102 DEBUG TRAIN Batch 31/2700 loss 6.913137 loss_att 358.122681 loss_ctc 13.515075 loss_rnnt 6.179588 lr 0.00024408 rank 0
2022-12-08 12:28:12,102 DEBUG TRAIN Batch 31/2700 loss 9.602822 loss_att 436.324707 loss_ctc 23.139751 loss_rnnt 8.098720 lr 0.00024411 rank 2
2022-12-08 12:28:12,106 DEBUG TRAIN Batch 31/2700 loss 10.355169 loss_att 382.982361 loss_ctc 22.777779 loss_rnnt 8.974880 lr 0.00024411 rank 5
2022-12-08 12:28:12,107 DEBUG TRAIN Batch 31/2700 loss 4.618893 loss_att 410.881042 loss_ctc 13.650561 loss_rnnt 3.615374 lr 0.00024413 rank 1
2022-12-08 12:29:16,184 DEBUG TRAIN Batch 31/2800 loss 3.631655 loss_att 376.588196 loss_ctc 11.592958 loss_rnnt 2.747066 lr 0.00024408 rank 3
2022-12-08 12:29:16,185 DEBUG TRAIN Batch 31/2800 loss 8.497542 loss_att 374.033447 loss_ctc 12.612423 loss_rnnt 8.040334 lr 0.00024408 rank 2
2022-12-08 12:29:16,186 DEBUG TRAIN Batch 31/2800 loss 3.847586 loss_att 386.873718 loss_ctc 7.214120 loss_rnnt 3.473527 lr 0.00024406 rank 7
2022-12-08 12:29:16,187 DEBUG TRAIN Batch 31/2800 loss 4.609270 loss_att 390.513916 loss_ctc 8.440571 loss_rnnt 4.183570 lr 0.00024410 rank 1
2022-12-08 12:29:16,188 DEBUG TRAIN Batch 31/2800 loss 14.133197 loss_att 367.778992 loss_ctc 20.236097 loss_rnnt 13.455097 lr 0.00024408 rank 6
2022-12-08 12:29:16,189 DEBUG TRAIN Batch 31/2800 loss 9.786526 loss_att 353.633301 loss_ctc 24.506559 loss_rnnt 8.150967 lr 0.00024408 rank 5
2022-12-08 12:29:16,215 DEBUG TRAIN Batch 31/2800 loss 5.049045 loss_att 414.117920 loss_ctc 15.852707 loss_rnnt 3.848638 lr 0.00024405 rank 0
2022-12-08 12:29:16,217 DEBUG TRAIN Batch 31/2800 loss 6.790963 loss_att 363.733765 loss_ctc 14.198306 loss_rnnt 5.967925 lr 0.00024405 rank 4
2022-12-08 12:30:26,157 DEBUG TRAIN Batch 31/2900 loss 8.603398 loss_att 364.887970 loss_ctc 18.751171 loss_rnnt 7.475868 lr 0.00024405 rank 2
2022-12-08 12:30:26,164 DEBUG TRAIN Batch 31/2900 loss 7.328599 loss_att 359.456055 loss_ctc 20.839821 loss_rnnt 5.827353 lr 0.00024402 rank 4
2022-12-08 12:30:26,168 DEBUG TRAIN Batch 31/2900 loss 6.656010 loss_att 368.996399 loss_ctc 11.888377 loss_rnnt 6.074636 lr 0.00024403 rank 7
2022-12-08 12:30:26,170 DEBUG TRAIN Batch 31/2900 loss 14.362076 loss_att 356.206421 loss_ctc 23.326580 loss_rnnt 13.366020 lr 0.00024405 rank 5
2022-12-08 12:30:26,170 DEBUG TRAIN Batch 31/2900 loss 6.426890 loss_att 388.213928 loss_ctc 13.054525 loss_rnnt 5.690486 lr 0.00024405 rank 6
2022-12-08 12:30:26,171 DEBUG TRAIN Batch 31/2900 loss 10.466059 loss_att 363.025635 loss_ctc 17.451752 loss_rnnt 9.689871 lr 0.00024405 rank 3
2022-12-08 12:30:26,173 DEBUG TRAIN Batch 31/2900 loss 6.948581 loss_att 354.462799 loss_ctc 15.866464 loss_rnnt 5.957705 lr 0.00024402 rank 0
2022-12-08 12:30:26,209 DEBUG TRAIN Batch 31/2900 loss 1.863952 loss_att 369.253754 loss_ctc 4.719459 loss_rnnt 1.546674 lr 0.00024407 rank 1
2022-12-08 12:31:28,743 DEBUG TRAIN Batch 31/3000 loss 4.686019 loss_att 281.243683 loss_ctc 9.776539 loss_rnnt 4.120406 lr 0.00024400 rank 7
2022-12-08 12:31:28,751 DEBUG TRAIN Batch 31/3000 loss 9.130610 loss_att 388.100159 loss_ctc 14.395889 loss_rnnt 8.545580 lr 0.00024399 rank 4
2022-12-08 12:31:28,756 DEBUG TRAIN Batch 31/3000 loss 16.710779 loss_att 302.958954 loss_ctc 29.025797 loss_rnnt 15.342444 lr 0.00024402 rank 6
2022-12-08 12:31:28,757 DEBUG TRAIN Batch 31/3000 loss 6.190359 loss_att 388.845093 loss_ctc 13.775911 loss_rnnt 5.347519 lr 0.00024400 rank 0
2022-12-08 12:31:28,758 DEBUG TRAIN Batch 31/3000 loss 8.120676 loss_att 342.447632 loss_ctc 21.105116 loss_rnnt 6.677960 lr 0.00024402 rank 3
2022-12-08 12:31:28,759 DEBUG TRAIN Batch 31/3000 loss 8.144336 loss_att 325.464783 loss_ctc 11.305073 loss_rnnt 7.793143 lr 0.00024402 rank 2
2022-12-08 12:31:28,763 DEBUG TRAIN Batch 31/3000 loss 9.281374 loss_att 384.904175 loss_ctc 23.533035 loss_rnnt 7.697856 lr 0.00024402 rank 5
2022-12-08 12:31:28,765 DEBUG TRAIN Batch 31/3000 loss 18.005630 loss_att 351.429382 loss_ctc 25.672060 loss_rnnt 17.153805 lr 0.00024404 rank 1
2022-12-08 12:32:31,997 DEBUG TRAIN Batch 31/3100 loss 2.638869 loss_att 262.624603 loss_ctc 5.939745 loss_rnnt 2.272105 lr 0.00024401 rank 1
2022-12-08 12:32:31,998 DEBUG TRAIN Batch 31/3100 loss 6.561073 loss_att 342.544159 loss_ctc 10.355206 loss_rnnt 6.139503 lr 0.00024399 rank 2
2022-12-08 12:32:32,005 DEBUG TRAIN Batch 31/3100 loss 7.666070 loss_att 332.713959 loss_ctc 18.068726 loss_rnnt 6.510219 lr 0.00024397 rank 7
2022-12-08 12:32:32,006 DEBUG TRAIN Batch 31/3100 loss 11.126314 loss_att 268.860443 loss_ctc 25.978523 loss_rnnt 9.476068 lr 0.00024397 rank 4
2022-12-08 12:32:32,009 DEBUG TRAIN Batch 31/3100 loss 5.163368 loss_att 343.383911 loss_ctc 14.946550 loss_rnnt 4.076348 lr 0.00024399 rank 5
2022-12-08 12:32:32,013 DEBUG TRAIN Batch 31/3100 loss 5.117418 loss_att 254.231766 loss_ctc 9.368125 loss_rnnt 4.645117 lr 0.00024399 rank 3
2022-12-08 12:32:32,013 DEBUG TRAIN Batch 31/3100 loss 7.295326 loss_att 77.577568 loss_ctc 10.189251 loss_rnnt 6.973779 lr 0.00024399 rank 6
2022-12-08 12:32:32,013 DEBUG TRAIN Batch 31/3100 loss 13.378166 loss_att 238.298584 loss_ctc 28.196590 loss_rnnt 11.731674 lr 0.00024397 rank 0
2022-12-08 12:33:44,431 DEBUG TRAIN Batch 31/3200 loss 7.208696 loss_att 404.527527 loss_ctc 17.629795 loss_rnnt 6.050796 lr 0.00024394 rank 4
2022-12-08 12:33:44,434 DEBUG TRAIN Batch 31/3200 loss 8.411694 loss_att 145.550247 loss_ctc 15.190489 loss_rnnt 7.658494 lr 0.00024394 rank 7
2022-12-08 12:33:44,437 DEBUG TRAIN Batch 31/3200 loss 7.899455 loss_att 427.981323 loss_ctc 19.553877 loss_rnnt 6.604519 lr 0.00024394 rank 0
2022-12-08 12:33:44,439 DEBUG TRAIN Batch 31/3200 loss 7.585580 loss_att 354.376587 loss_ctc 9.770195 loss_rnnt 7.342846 lr 0.00024397 rank 6
2022-12-08 12:33:44,440 DEBUG TRAIN Batch 31/3200 loss 6.433272 loss_att 278.258545 loss_ctc 10.083358 loss_rnnt 6.027707 lr 0.00024396 rank 5
2022-12-08 12:33:44,444 DEBUG TRAIN Batch 31/3200 loss 6.189087 loss_att 203.273270 loss_ctc 11.600340 loss_rnnt 5.587837 lr 0.00024396 rank 2
2022-12-08 12:33:44,460 DEBUG TRAIN Batch 31/3200 loss 7.389373 loss_att 202.861542 loss_ctc 11.289171 loss_rnnt 6.956062 lr 0.00024398 rank 1
2022-12-08 12:33:44,462 DEBUG TRAIN Batch 31/3200 loss 6.335578 loss_att 117.303749 loss_ctc 12.084200 loss_rnnt 5.696843 lr 0.00024396 rank 3
2022-12-08 12:34:47,853 DEBUG TRAIN Batch 31/3300 loss 11.533560 loss_att 393.029541 loss_ctc 23.833546 loss_rnnt 10.166896 lr 0.00024391 rank 7
2022-12-08 12:34:47,863 DEBUG TRAIN Batch 31/3300 loss 7.343298 loss_att 310.247772 loss_ctc 13.990089 loss_rnnt 6.604766 lr 0.00024393 rank 2
2022-12-08 12:34:47,865 DEBUG TRAIN Batch 31/3300 loss 2.356981 loss_att 338.001099 loss_ctc 7.112357 loss_rnnt 1.828605 lr 0.00024391 rank 4
2022-12-08 12:34:47,866 DEBUG TRAIN Batch 31/3300 loss 4.601389 loss_att 415.638062 loss_ctc 15.520607 loss_rnnt 3.388142 lr 0.00024391 rank 0
2022-12-08 12:34:47,870 DEBUG TRAIN Batch 31/3300 loss 9.564483 loss_att 438.916565 loss_ctc 20.224424 loss_rnnt 8.380045 lr 0.00024394 rank 6
2022-12-08 12:34:47,870 DEBUG TRAIN Batch 31/3300 loss 5.771463 loss_att 377.166382 loss_ctc 13.234962 loss_rnnt 4.942185 lr 0.00024395 rank 1
2022-12-08 12:34:47,871 DEBUG TRAIN Batch 31/3300 loss 14.103525 loss_att 298.511078 loss_ctc 23.029465 loss_rnnt 13.111754 lr 0.00024393 rank 5
2022-12-08 12:34:47,874 DEBUG TRAIN Batch 31/3300 loss 2.036089 loss_att 394.749969 loss_ctc 5.785533 loss_rnnt 1.619484 lr 0.00024393 rank 3
2022-12-08 12:35:50,979 DEBUG TRAIN Batch 31/3400 loss 12.140833 loss_att 385.534882 loss_ctc 26.234344 loss_rnnt 10.574888 lr 0.00024390 rank 2
2022-12-08 12:35:50,979 DEBUG TRAIN Batch 31/3400 loss 8.725765 loss_att 425.693420 loss_ctc 17.992031 loss_rnnt 7.696180 lr 0.00024391 rank 6
2022-12-08 12:35:50,979 DEBUG TRAIN Batch 31/3400 loss 4.366394 loss_att 364.680298 loss_ctc 11.547598 loss_rnnt 3.568482 lr 0.00024388 rank 4
2022-12-08 12:35:50,980 DEBUG TRAIN Batch 31/3400 loss 5.018394 loss_att 328.564545 loss_ctc 9.791381 loss_rnnt 4.488062 lr 0.00024390 rank 3
2022-12-08 12:35:50,982 DEBUG TRAIN Batch 31/3400 loss 2.906436 loss_att 349.859924 loss_ctc 4.209552 loss_rnnt 2.761646 lr 0.00024390 rank 5
2022-12-08 12:35:50,982 DEBUG TRAIN Batch 31/3400 loss 2.413119 loss_att 397.345795 loss_ctc 5.584514 loss_rnnt 2.060742 lr 0.00024392 rank 1
2022-12-08 12:35:50,985 DEBUG TRAIN Batch 31/3400 loss 6.134238 loss_att 384.825378 loss_ctc 11.416811 loss_rnnt 5.547285 lr 0.00024388 rank 0
2022-12-08 12:35:50,999 DEBUG TRAIN Batch 31/3400 loss 7.154249 loss_att 372.861145 loss_ctc 11.826818 loss_rnnt 6.635075 lr 0.00024388 rank 7
2022-12-08 12:36:55,467 DEBUG TRAIN Batch 31/3500 loss 8.635452 loss_att 368.170288 loss_ctc 18.221283 loss_rnnt 7.570360 lr 0.00024385 rank 7
2022-12-08 12:36:55,476 DEBUG TRAIN Batch 31/3500 loss 3.621643 loss_att 353.948364 loss_ctc 8.575374 loss_rnnt 3.071229 lr 0.00024387 rank 2
2022-12-08 12:36:55,484 DEBUG TRAIN Batch 31/3500 loss 3.679039 loss_att 386.315613 loss_ctc 10.272507 loss_rnnt 2.946432 lr 0.00024387 rank 3
2022-12-08 12:36:55,487 DEBUG TRAIN Batch 31/3500 loss 10.744791 loss_att 355.855652 loss_ctc 14.874472 loss_rnnt 10.285938 lr 0.00024387 rank 5
2022-12-08 12:36:55,488 DEBUG TRAIN Batch 31/3500 loss 2.279703 loss_att 366.943176 loss_ctc 6.118546 loss_rnnt 1.853165 lr 0.00024389 rank 1
2022-12-08 12:36:55,489 DEBUG TRAIN Batch 31/3500 loss 14.287045 loss_att 398.638794 loss_ctc 29.855047 loss_rnnt 12.557267 lr 0.00024385 rank 0
2022-12-08 12:36:55,502 DEBUG TRAIN Batch 31/3500 loss 10.756107 loss_att 395.758240 loss_ctc 20.866846 loss_rnnt 9.632692 lr 0.00024388 rank 6
2022-12-08 12:36:55,512 DEBUG TRAIN Batch 31/3500 loss 9.269815 loss_att 336.449341 loss_ctc 19.529095 loss_rnnt 8.129895 lr 0.00024385 rank 4
2022-12-08 12:38:06,295 DEBUG TRAIN Batch 31/3600 loss 5.708906 loss_att 317.177979 loss_ctc 13.571966 loss_rnnt 4.835233 lr 0.00024385 rank 2
2022-12-08 12:38:06,295 DEBUG TRAIN Batch 31/3600 loss 9.900579 loss_att 373.365784 loss_ctc 17.230627 loss_rnnt 9.086130 lr 0.00024385 rank 6
2022-12-08 12:38:06,301 DEBUG TRAIN Batch 31/3600 loss 8.728105 loss_att 399.016541 loss_ctc 24.251839 loss_rnnt 7.003245 lr 0.00024385 rank 5
2022-12-08 12:38:06,302 DEBUG TRAIN Batch 31/3600 loss 5.731345 loss_att 360.123322 loss_ctc 16.695267 loss_rnnt 4.513132 lr 0.00024384 rank 3
2022-12-08 12:38:06,304 DEBUG TRAIN Batch 31/3600 loss 3.682292 loss_att 311.955597 loss_ctc 10.156076 loss_rnnt 2.962983 lr 0.00024382 rank 0
2022-12-08 12:38:06,304 DEBUG TRAIN Batch 31/3600 loss 5.446317 loss_att 404.426666 loss_ctc 14.459770 loss_rnnt 4.444822 lr 0.00024386 rank 1
2022-12-08 12:38:06,326 DEBUG TRAIN Batch 31/3600 loss 13.687700 loss_att 347.473267 loss_ctc 21.767448 loss_rnnt 12.789950 lr 0.00024382 rank 7
2022-12-08 12:38:06,337 DEBUG TRAIN Batch 31/3600 loss 6.406254 loss_att 379.436218 loss_ctc 16.015533 loss_rnnt 5.338557 lr 0.00024382 rank 4
2022-12-08 12:39:09,307 DEBUG TRAIN Batch 31/3700 loss 4.627941 loss_att 268.951172 loss_ctc 10.713070 loss_rnnt 3.951815 lr 0.00024379 rank 4
2022-12-08 12:39:09,320 DEBUG TRAIN Batch 31/3700 loss 4.678161 loss_att 283.356812 loss_ctc 9.414572 loss_rnnt 4.151893 lr 0.00024379 rank 7
2022-12-08 12:39:09,321 DEBUG TRAIN Batch 31/3700 loss 13.317421 loss_att 206.262619 loss_ctc 24.849689 loss_rnnt 12.036058 lr 0.00024382 rank 6
2022-12-08 12:39:09,323 DEBUG TRAIN Batch 31/3700 loss 9.406458 loss_att 296.054993 loss_ctc 16.583084 loss_rnnt 8.609056 lr 0.00024382 rank 2
2022-12-08 12:39:09,327 DEBUG TRAIN Batch 31/3700 loss 11.685949 loss_att 353.000671 loss_ctc 22.912563 loss_rnnt 10.438547 lr 0.00024383 rank 1
2022-12-08 12:39:09,329 DEBUG TRAIN Batch 31/3700 loss 4.802649 loss_att 340.332550 loss_ctc 8.143268 loss_rnnt 4.431469 lr 0.00024382 rank 5
2022-12-08 12:39:09,330 DEBUG TRAIN Batch 31/3700 loss 5.024213 loss_att 297.360626 loss_ctc 10.397264 loss_rnnt 4.427207 lr 0.00024379 rank 0
2022-12-08 12:39:09,365 DEBUG TRAIN Batch 31/3700 loss 3.905194 loss_att 316.650391 loss_ctc 11.382256 loss_rnnt 3.074409 lr 0.00024381 rank 3
2022-12-08 12:40:13,601 DEBUG TRAIN Batch 31/3800 loss 9.884909 loss_att 135.610825 loss_ctc 14.075775 loss_rnnt 9.419257 lr 0.00024376 rank 4
2022-12-08 12:40:13,607 DEBUG TRAIN Batch 31/3800 loss 13.543325 loss_att 263.021240 loss_ctc 19.968878 loss_rnnt 12.829375 lr 0.00024376 rank 0
2022-12-08 12:40:13,606 DEBUG TRAIN Batch 31/3800 loss 6.289298 loss_att 190.102783 loss_ctc 13.128662 loss_rnnt 5.529369 lr 0.00024379 rank 3
2022-12-08 12:40:13,608 DEBUG TRAIN Batch 31/3800 loss 6.702643 loss_att 285.780304 loss_ctc 14.175452 loss_rnnt 5.872331 lr 0.00024381 rank 1
2022-12-08 12:40:13,609 DEBUG TRAIN Batch 31/3800 loss 4.859133 loss_att 172.195404 loss_ctc 8.593994 loss_rnnt 4.444148 lr 0.00024377 rank 7
2022-12-08 12:40:13,613 DEBUG TRAIN Batch 31/3800 loss 9.480877 loss_att 345.607422 loss_ctc 12.863401 loss_rnnt 9.105042 lr 0.00024379 rank 5
2022-12-08 12:40:13,612 DEBUG TRAIN Batch 31/3800 loss 9.667081 loss_att 362.515564 loss_ctc 19.880234 loss_rnnt 8.532286 lr 0.00024379 rank 6
2022-12-08 12:40:13,653 DEBUG TRAIN Batch 31/3800 loss 12.578959 loss_att 237.223969 loss_ctc 24.191883 loss_rnnt 11.288634 lr 0.00024379 rank 2
2022-12-08 12:41:25,277 DEBUG TRAIN Batch 31/3900 loss 1.277969 loss_att 453.915741 loss_ctc 3.932313 loss_rnnt 0.983042 lr 0.00024376 rank 2
2022-12-08 12:41:25,278 DEBUG TRAIN Batch 31/3900 loss 10.544041 loss_att 383.819336 loss_ctc 15.756311 loss_rnnt 9.964900 lr 0.00024376 rank 3
2022-12-08 12:41:25,280 DEBUG TRAIN Batch 31/3900 loss 5.306800 loss_att 235.591431 loss_ctc 12.023911 loss_rnnt 4.560454 lr 0.00024376 rank 5
2022-12-08 12:41:25,283 DEBUG TRAIN Batch 31/3900 loss 2.798840 loss_att 386.429535 loss_ctc 10.853313 loss_rnnt 1.903898 lr 0.00024376 rank 6
2022-12-08 12:41:25,284 DEBUG TRAIN Batch 31/3900 loss 3.452173 loss_att 423.313934 loss_ctc 11.051163 loss_rnnt 2.607841 lr 0.00024378 rank 1
2022-12-08 12:41:25,298 DEBUG TRAIN Batch 31/3900 loss 6.553268 loss_att 394.890961 loss_ctc 16.787666 loss_rnnt 5.416113 lr 0.00024373 rank 4
2022-12-08 12:41:25,300 DEBUG TRAIN Batch 31/3900 loss 2.566741 loss_att 431.239502 loss_ctc 5.575082 loss_rnnt 2.232481 lr 0.00024374 rank 7
2022-12-08 12:41:25,307 DEBUG TRAIN Batch 31/3900 loss 3.878852 loss_att 448.791107 loss_ctc 12.287546 loss_rnnt 2.944553 lr 0.00024373 rank 0
2022-12-08 12:42:29,791 DEBUG TRAIN Batch 31/4000 loss 3.443257 loss_att 344.837952 loss_ctc 9.345789 loss_rnnt 2.787420 lr 0.00024373 rank 6
2022-12-08 12:42:29,794 DEBUG TRAIN Batch 31/4000 loss 5.835874 loss_att 383.404114 loss_ctc 12.396811 loss_rnnt 5.106881 lr 0.00024371 rank 7
2022-12-08 12:42:29,795 DEBUG TRAIN Batch 31/4000 loss 4.641332 loss_att 392.557190 loss_ctc 13.309203 loss_rnnt 3.678235 lr 0.00024373 rank 3
2022-12-08 12:42:29,798 DEBUG TRAIN Batch 31/4000 loss 3.984111 loss_att 380.212219 loss_ctc 11.749137 loss_rnnt 3.121330 lr 0.00024371 rank 0
2022-12-08 12:42:29,799 DEBUG TRAIN Batch 31/4000 loss 10.660693 loss_att 364.768036 loss_ctc 25.057487 loss_rnnt 9.061049 lr 0.00024370 rank 4
2022-12-08 12:42:29,800 DEBUG TRAIN Batch 31/4000 loss 10.759492 loss_att 435.895355 loss_ctc 20.515743 loss_rnnt 9.675464 lr 0.00024373 rank 2
2022-12-08 12:42:29,801 DEBUG TRAIN Batch 31/4000 loss 4.520118 loss_att 400.611816 loss_ctc 5.808587 loss_rnnt 4.376955 lr 0.00024373 rank 5
2022-12-08 12:42:29,845 DEBUG TRAIN Batch 31/4000 loss 6.089428 loss_att 365.460327 loss_ctc 15.826716 loss_rnnt 5.007507 lr 0.00024375 rank 1
2022-12-08 12:43:32,768 DEBUG TRAIN Batch 31/4100 loss 3.758167 loss_att 334.679047 loss_ctc 11.655060 loss_rnnt 2.880734 lr 0.00024368 rank 4
2022-12-08 12:43:32,772 DEBUG TRAIN Batch 31/4100 loss 4.966113 loss_att 411.472778 loss_ctc 8.395908 loss_rnnt 4.585025 lr 0.00024368 rank 7
2022-12-08 12:43:32,776 DEBUG TRAIN Batch 31/4100 loss 3.567377 loss_att 345.108643 loss_ctc 6.951486 loss_rnnt 3.191365 lr 0.00024368 rank 0
2022-12-08 12:43:32,776 DEBUG TRAIN Batch 31/4100 loss 2.468966 loss_att 365.418732 loss_ctc 4.990826 loss_rnnt 2.188759 lr 0.00024372 rank 1
2022-12-08 12:43:32,779 DEBUG TRAIN Batch 31/4100 loss 5.054891 loss_att 325.298401 loss_ctc 13.794143 loss_rnnt 4.083863 lr 0.00024370 rank 3
2022-12-08 12:43:32,780 DEBUG TRAIN Batch 31/4100 loss 16.070396 loss_att 309.318695 loss_ctc 23.779716 loss_rnnt 15.213804 lr 0.00024370 rank 2
2022-12-08 12:43:32,783 DEBUG TRAIN Batch 31/4100 loss 5.952131 loss_att 437.034851 loss_ctc 15.688963 loss_rnnt 4.870261 lr 0.00024370 rank 5
2022-12-08 12:43:32,782 DEBUG TRAIN Batch 31/4100 loss 3.463869 loss_att 350.225220 loss_ctc 7.476328 loss_rnnt 3.018040 lr 0.00024370 rank 6
2022-12-08 12:44:36,090 DEBUG TRAIN Batch 31/4200 loss 3.456875 loss_att 375.634857 loss_ctc 5.984386 loss_rnnt 3.176041 lr 0.00024369 rank 1
2022-12-08 12:44:36,100 DEBUG TRAIN Batch 31/4200 loss 6.985967 loss_att 377.146057 loss_ctc 11.697405 loss_rnnt 6.462474 lr 0.00024365 rank 4
2022-12-08 12:44:36,101 DEBUG TRAIN Batch 31/4200 loss 8.205785 loss_att 330.965729 loss_ctc 13.237661 loss_rnnt 7.646688 lr 0.00024367 rank 5
2022-12-08 12:44:36,101 DEBUG TRAIN Batch 31/4200 loss 5.831684 loss_att 375.473572 loss_ctc 11.143120 loss_rnnt 5.241524 lr 0.00024367 rank 2
2022-12-08 12:44:36,103 DEBUG TRAIN Batch 31/4200 loss 9.619408 loss_att 416.044067 loss_ctc 23.400608 loss_rnnt 8.088163 lr 0.00024367 rank 3
2022-12-08 12:44:36,103 DEBUG TRAIN Batch 31/4200 loss 7.503402 loss_att 384.382996 loss_ctc 23.386992 loss_rnnt 5.738559 lr 0.00024365 rank 7
2022-12-08 12:44:36,110 DEBUG TRAIN Batch 31/4200 loss 4.863662 loss_att 286.769714 loss_ctc 8.752983 loss_rnnt 4.431516 lr 0.00024365 rank 0
2022-12-08 12:44:36,144 DEBUG TRAIN Batch 31/4200 loss 12.919475 loss_att 345.007935 loss_ctc 19.580780 loss_rnnt 12.179330 lr 0.00024368 rank 6
2022-12-08 12:45:46,821 DEBUG TRAIN Batch 31/4300 loss 5.984415 loss_att 362.900635 loss_ctc 14.781615 loss_rnnt 5.006948 lr 0.00024362 rank 4
2022-12-08 12:45:46,822 DEBUG TRAIN Batch 31/4300 loss 10.963630 loss_att 353.129456 loss_ctc 17.593269 loss_rnnt 10.227003 lr 0.00024362 rank 7
2022-12-08 12:45:46,826 DEBUG TRAIN Batch 31/4300 loss 6.013689 loss_att 334.043457 loss_ctc 10.027439 loss_rnnt 5.567717 lr 0.00024364 rank 3
2022-12-08 12:45:46,826 DEBUG TRAIN Batch 31/4300 loss 7.418391 loss_att 330.492340 loss_ctc 17.211927 loss_rnnt 6.330221 lr 0.00024365 rank 6
2022-12-08 12:45:46,828 DEBUG TRAIN Batch 31/4300 loss 9.687407 loss_att 391.593689 loss_ctc 18.624310 loss_rnnt 8.694418 lr 0.00024364 rank 2
2022-12-08 12:45:46,831 DEBUG TRAIN Batch 31/4300 loss 6.832081 loss_att 349.520264 loss_ctc 12.498457 loss_rnnt 6.202483 lr 0.00024366 rank 1
2022-12-08 12:45:46,832 DEBUG TRAIN Batch 31/4300 loss 4.592273 loss_att 324.244415 loss_ctc 11.232870 loss_rnnt 3.854429 lr 0.00024364 rank 5
2022-12-08 12:45:46,832 DEBUG TRAIN Batch 31/4300 loss 5.330637 loss_att 336.827606 loss_ctc 12.078737 loss_rnnt 4.580848 lr 0.00024362 rank 0
2022-12-08 12:46:50,094 DEBUG TRAIN Batch 31/4400 loss 2.437454 loss_att 196.270798 loss_ctc 7.117522 loss_rnnt 1.917446 lr 0.00024359 rank 4
2022-12-08 12:46:50,098 DEBUG TRAIN Batch 31/4400 loss 8.397241 loss_att 295.847626 loss_ctc 15.263434 loss_rnnt 7.634330 lr 0.00024359 rank 0
2022-12-08 12:46:50,100 DEBUG TRAIN Batch 31/4400 loss 17.156824 loss_att 271.998260 loss_ctc 38.975372 loss_rnnt 14.732541 lr 0.00024359 rank 7
2022-12-08 12:46:50,103 DEBUG TRAIN Batch 31/4400 loss 7.019132 loss_att 328.770874 loss_ctc 12.766305 loss_rnnt 6.380557 lr 0.00024361 rank 5
2022-12-08 12:46:50,105 DEBUG TRAIN Batch 31/4400 loss 8.009192 loss_att 169.871765 loss_ctc 12.396204 loss_rnnt 7.521746 lr 0.00024361 rank 3
2022-12-08 12:46:50,105 DEBUG TRAIN Batch 31/4400 loss 2.482409 loss_att 306.075775 loss_ctc 8.303477 loss_rnnt 1.835624 lr 0.00024363 rank 1
2022-12-08 12:46:50,106 DEBUG TRAIN Batch 31/4400 loss 9.979692 loss_att 329.128845 loss_ctc 20.457823 loss_rnnt 8.815455 lr 0.00024361 rank 2
2022-12-08 12:46:50,145 DEBUG TRAIN Batch 31/4400 loss 8.446603 loss_att 131.978180 loss_ctc 13.293032 loss_rnnt 7.908112 lr 0.00024362 rank 6
2022-12-08 12:47:52,881 DEBUG TRAIN Batch 31/4500 loss 7.789536 loss_att 336.933655 loss_ctc 9.288759 loss_rnnt 7.622955 lr 0.00024356 rank 7
2022-12-08 12:47:52,883 DEBUG TRAIN Batch 31/4500 loss 11.391275 loss_att 439.885193 loss_ctc 19.844509 loss_rnnt 10.452027 lr 0.00024356 rank 4
2022-12-08 12:47:52,886 DEBUG TRAIN Batch 31/4500 loss 4.125324 loss_att 370.767517 loss_ctc 14.516411 loss_rnnt 2.970759 lr 0.00024359 rank 6
2022-12-08 12:47:52,888 DEBUG TRAIN Batch 31/4500 loss 8.284541 loss_att 443.905823 loss_ctc 18.112123 loss_rnnt 7.192588 lr 0.00024358 rank 3
2022-12-08 12:47:52,889 DEBUG TRAIN Batch 31/4500 loss 7.749523 loss_att 391.258484 loss_ctc 18.938866 loss_rnnt 6.506263 lr 0.00024356 rank 0
2022-12-08 12:47:52,890 DEBUG TRAIN Batch 31/4500 loss 3.838150 loss_att 199.022324 loss_ctc 7.558826 loss_rnnt 3.424741 lr 0.00024358 rank 2
2022-12-08 12:47:52,890 DEBUG TRAIN Batch 31/4500 loss 5.872434 loss_att 371.281250 loss_ctc 10.942642 loss_rnnt 5.309077 lr 0.00024360 rank 1
2022-12-08 12:47:52,926 DEBUG TRAIN Batch 31/4500 loss 10.314095 loss_att 208.561401 loss_ctc 14.025238 loss_rnnt 9.901745 lr 0.00024359 rank 5
2022-12-08 12:48:57,550 DEBUG TRAIN Batch 31/4600 loss 3.185361 loss_att 375.341553 loss_ctc 6.140880 loss_rnnt 2.856970 lr 0.00024356 rank 2
2022-12-08 12:48:57,562 DEBUG TRAIN Batch 31/4600 loss 8.303505 loss_att 430.870300 loss_ctc 18.566788 loss_rnnt 7.163140 lr 0.00024353 rank 7
2022-12-08 12:48:57,564 DEBUG TRAIN Batch 31/4600 loss 3.014466 loss_att 404.349335 loss_ctc 8.204020 loss_rnnt 2.437849 lr 0.00024356 rank 6
2022-12-08 12:48:57,564 DEBUG TRAIN Batch 31/4600 loss 7.291094 loss_att 339.064545 loss_ctc 18.423735 loss_rnnt 6.054134 lr 0.00024355 rank 3
2022-12-08 12:48:57,564 DEBUG TRAIN Batch 31/4600 loss 5.610744 loss_att 423.809906 loss_ctc 13.813240 loss_rnnt 4.699355 lr 0.00024353 rank 4
2022-12-08 12:48:57,570 DEBUG TRAIN Batch 31/4600 loss 9.396141 loss_att 400.580292 loss_ctc 25.831673 loss_rnnt 7.569971 lr 0.00024353 rank 0
2022-12-08 12:48:57,572 DEBUG TRAIN Batch 31/4600 loss 10.490677 loss_att 364.889832 loss_ctc 16.292542 loss_rnnt 9.846025 lr 0.00024357 rank 1
2022-12-08 12:48:57,592 DEBUG TRAIN Batch 31/4600 loss 5.115581 loss_att 374.963379 loss_ctc 8.686300 loss_rnnt 4.718834 lr 0.00024356 rank 5
2022-12-08 12:50:08,765 DEBUG TRAIN Batch 31/4700 loss 8.403661 loss_att 375.914856 loss_ctc 26.864239 loss_rnnt 6.352485 lr 0.00024351 rank 7
2022-12-08 12:50:08,765 DEBUG TRAIN Batch 31/4700 loss 11.901187 loss_att 357.930847 loss_ctc 21.516296 loss_rnnt 10.832842 lr 0.00024353 rank 6
2022-12-08 12:50:08,772 DEBUG TRAIN Batch 31/4700 loss 3.268464 loss_att 400.338135 loss_ctc 8.811692 loss_rnnt 2.652550 lr 0.00024355 rank 1
2022-12-08 12:50:08,772 DEBUG TRAIN Batch 31/4700 loss 5.054898 loss_att 363.396118 loss_ctc 13.620255 loss_rnnt 4.103192 lr 0.00024350 rank 4
2022-12-08 12:50:08,772 DEBUG TRAIN Batch 31/4700 loss 6.441264 loss_att 419.206970 loss_ctc 16.922617 loss_rnnt 5.276670 lr 0.00024353 rank 5
2022-12-08 12:50:08,774 DEBUG TRAIN Batch 31/4700 loss 9.052505 loss_att 337.935974 loss_ctc 14.781610 loss_rnnt 8.415938 lr 0.00024350 rank 0
2022-12-08 12:50:08,775 DEBUG TRAIN Batch 31/4700 loss 8.390255 loss_att 438.959320 loss_ctc 19.975035 loss_rnnt 7.103057 lr 0.00024353 rank 2
2022-12-08 12:50:08,786 DEBUG TRAIN Batch 31/4700 loss 5.466699 loss_att 398.782867 loss_ctc 11.868337 loss_rnnt 4.755405 lr 0.00024353 rank 3
2022-12-08 12:51:11,949 DEBUG TRAIN Batch 31/4800 loss 10.621043 loss_att 389.424500 loss_ctc 17.095558 loss_rnnt 9.901653 lr 0.00024348 rank 7
2022-12-08 12:51:11,952 DEBUG TRAIN Batch 31/4800 loss 2.938953 loss_att 310.079742 loss_ctc 8.006226 loss_rnnt 2.375922 lr 0.00024347 rank 4
2022-12-08 12:51:11,955 DEBUG TRAIN Batch 31/4800 loss 4.199030 loss_att 359.844543 loss_ctc 5.941601 loss_rnnt 4.005412 lr 0.00024350 rank 3
2022-12-08 12:51:11,956 DEBUG TRAIN Batch 31/4800 loss 7.293997 loss_att 433.680420 loss_ctc 17.635729 loss_rnnt 6.144916 lr 0.00024350 rank 5
2022-12-08 12:51:11,958 DEBUG TRAIN Batch 31/4800 loss 2.304298 loss_att 387.808289 loss_ctc 6.223915 loss_rnnt 1.868785 lr 0.00024347 rank 0
2022-12-08 12:51:11,959 DEBUG TRAIN Batch 31/4800 loss 7.585757 loss_att 323.244263 loss_ctc 19.691864 loss_rnnt 6.240634 lr 0.00024350 rank 2
2022-12-08 12:51:11,962 DEBUG TRAIN Batch 31/4800 loss 5.189907 loss_att 313.289795 loss_ctc 12.200142 loss_rnnt 4.410992 lr 0.00024350 rank 6
2022-12-08 12:51:11,997 DEBUG TRAIN Batch 31/4800 loss 7.623416 loss_att 420.689270 loss_ctc 21.808403 loss_rnnt 6.047307 lr 0.00024352 rank 1
2022-12-08 12:52:15,274 DEBUG TRAIN Batch 31/4900 loss 7.747794 loss_att 297.504822 loss_ctc 15.376425 loss_rnnt 6.900168 lr 0.00024347 rank 6
2022-12-08 12:52:15,276 DEBUG TRAIN Batch 31/4900 loss 4.315887 loss_att 280.314850 loss_ctc 6.930161 loss_rnnt 4.025413 lr 0.00024347 rank 3
2022-12-08 12:52:15,277 DEBUG TRAIN Batch 31/4900 loss 16.605246 loss_att 366.390076 loss_ctc 33.965618 loss_rnnt 14.676315 lr 0.00024345 rank 0
2022-12-08 12:52:15,278 DEBUG TRAIN Batch 31/4900 loss 4.738389 loss_att 331.743042 loss_ctc 7.989379 loss_rnnt 4.377167 lr 0.00024345 rank 7
2022-12-08 12:52:15,278 DEBUG TRAIN Batch 31/4900 loss 6.350566 loss_att 391.662476 loss_ctc 13.140650 loss_rnnt 5.596112 lr 0.00024347 rank 2
2022-12-08 12:52:15,280 DEBUG TRAIN Batch 31/4900 loss 11.101425 loss_att 377.011719 loss_ctc 23.856461 loss_rnnt 9.684199 lr 0.00024344 rank 4
2022-12-08 12:52:15,280 DEBUG TRAIN Batch 31/4900 loss 6.072666 loss_att 359.860718 loss_ctc 14.025159 loss_rnnt 5.189056 lr 0.00024347 rank 5
2022-12-08 12:52:15,284 DEBUG TRAIN Batch 31/4900 loss 8.123617 loss_att 303.754730 loss_ctc 15.204807 loss_rnnt 7.336818 lr 0.00024349 rank 1
2022-12-08 12:53:27,409 DEBUG TRAIN Batch 31/5000 loss 6.781793 loss_att 220.672821 loss_ctc 14.584767 loss_rnnt 5.914795 lr 0.00024344 rank 3
2022-12-08 12:53:27,427 DEBUG TRAIN Batch 31/5000 loss 8.790356 loss_att 347.358459 loss_ctc 18.513317 loss_rnnt 7.710027 lr 0.00024346 rank 1
2022-12-08 12:53:27,428 DEBUG TRAIN Batch 31/5000 loss 5.223744 loss_att 332.958954 loss_ctc 11.898261 loss_rnnt 4.482131 lr 0.00024342 rank 7
2022-12-08 12:53:27,428 DEBUG TRAIN Batch 31/5000 loss 11.842463 loss_att 322.250061 loss_ctc 22.258366 loss_rnnt 10.685141 lr 0.00024342 rank 4
2022-12-08 12:53:27,430 DEBUG TRAIN Batch 31/5000 loss 6.362498 loss_att 274.208344 loss_ctc 17.342611 loss_rnnt 5.142486 lr 0.00024342 rank 0
2022-12-08 12:53:27,435 DEBUG TRAIN Batch 31/5000 loss 3.304526 loss_att 310.297302 loss_ctc 7.358804 loss_rnnt 2.854051 lr 0.00024344 rank 5
2022-12-08 12:53:27,441 DEBUG TRAIN Batch 31/5000 loss 12.414718 loss_att 260.621094 loss_ctc 23.505783 loss_rnnt 11.182377 lr 0.00024344 rank 6
2022-12-08 12:53:27,471 DEBUG TRAIN Batch 31/5000 loss 15.004939 loss_att 344.082947 loss_ctc 22.391455 loss_rnnt 14.184216 lr 0.00024344 rank 2
2022-12-08 12:54:30,454 DEBUG TRAIN Batch 31/5100 loss 7.202808 loss_att 116.979080 loss_ctc 10.492840 loss_rnnt 6.837250 lr 0.00024339 rank 7
2022-12-08 12:54:30,455 DEBUG TRAIN Batch 31/5100 loss 5.653341 loss_att 411.332001 loss_ctc 12.358059 loss_rnnt 4.908372 lr 0.00024339 rank 0
2022-12-08 12:54:30,455 DEBUG TRAIN Batch 31/5100 loss 7.864350 loss_att 97.320770 loss_ctc 13.415005 loss_rnnt 7.247611 lr 0.00024339 rank 4
2022-12-08 12:54:30,455 DEBUG TRAIN Batch 31/5100 loss 3.904191 loss_att 421.521240 loss_ctc 14.210341 loss_rnnt 2.759063 lr 0.00024342 rank 6
2022-12-08 12:54:30,456 DEBUG TRAIN Batch 31/5100 loss 7.861405 loss_att 283.296478 loss_ctc 15.160773 loss_rnnt 7.050364 lr 0.00024341 rank 2
2022-12-08 12:54:30,467 DEBUG TRAIN Batch 31/5100 loss 8.397120 loss_att 382.371826 loss_ctc 17.203773 loss_rnnt 7.418603 lr 0.00024341 rank 3
2022-12-08 12:54:30,469 DEBUG TRAIN Batch 31/5100 loss 11.427691 loss_att 218.282166 loss_ctc 19.870131 loss_rnnt 10.489642 lr 0.00024341 rank 5
2022-12-08 12:54:30,498 DEBUG TRAIN Batch 31/5100 loss 2.824538 loss_att 93.103081 loss_ctc 5.689195 loss_rnnt 2.506243 lr 0.00024343 rank 1
2022-12-08 12:55:33,678 DEBUG TRAIN Batch 31/5200 loss 4.072061 loss_att 374.868164 loss_ctc 14.691906 loss_rnnt 2.892078 lr 0.00024336 rank 4
2022-12-08 12:55:33,681 DEBUG TRAIN Batch 31/5200 loss 9.073174 loss_att 333.956360 loss_ctc 15.363218 loss_rnnt 8.374281 lr 0.00024336 rank 7
2022-12-08 12:55:33,682 DEBUG TRAIN Batch 31/5200 loss 5.084919 loss_att 410.214050 loss_ctc 12.063623 loss_rnnt 4.309508 lr 0.00024336 rank 0
2022-12-08 12:55:33,683 DEBUG TRAIN Batch 31/5200 loss 14.385062 loss_att 478.370209 loss_ctc 30.565315 loss_rnnt 12.587256 lr 0.00024340 rank 1
2022-12-08 12:55:33,684 DEBUG TRAIN Batch 31/5200 loss 7.021669 loss_att 375.187836 loss_ctc 13.885729 loss_rnnt 6.258996 lr 0.00024338 rank 3
2022-12-08 12:55:33,684 DEBUG TRAIN Batch 31/5200 loss 9.846065 loss_att 82.827553 loss_ctc 15.120374 loss_rnnt 9.260031 lr 0.00024338 rank 2
2022-12-08 12:55:33,685 DEBUG TRAIN Batch 31/5200 loss 11.739458 loss_att 397.528076 loss_ctc 22.269926 loss_rnnt 10.569407 lr 0.00024338 rank 5
2022-12-08 12:55:33,730 DEBUG TRAIN Batch 31/5200 loss 9.178917 loss_att 396.979431 loss_ctc 34.670910 loss_rnnt 6.346473 lr 0.00024339 rank 6
2022-12-08 12:56:38,714 DEBUG TRAIN Batch 31/5300 loss 8.024556 loss_att 479.793213 loss_ctc 19.196297 loss_rnnt 6.783252 lr 0.00024335 rank 2
2022-12-08 12:56:38,723 DEBUG TRAIN Batch 31/5300 loss 6.320089 loss_att 348.822021 loss_ctc 18.828373 loss_rnnt 4.930280 lr 0.00024333 rank 7
2022-12-08 12:56:38,723 DEBUG TRAIN Batch 31/5300 loss 4.741237 loss_att 358.526978 loss_ctc 11.418452 loss_rnnt 3.999325 lr 0.00024333 rank 4
2022-12-08 12:56:38,727 DEBUG TRAIN Batch 31/5300 loss 2.749519 loss_att 365.615723 loss_ctc 8.337793 loss_rnnt 2.128600 lr 0.00024333 rank 0
2022-12-08 12:56:38,728 DEBUG TRAIN Batch 31/5300 loss 4.944097 loss_att 344.753143 loss_ctc 9.326523 loss_rnnt 4.457160 lr 0.00024335 rank 5
2022-12-08 12:56:38,729 DEBUG TRAIN Batch 31/5300 loss 9.653604 loss_att 406.845398 loss_ctc 14.125575 loss_rnnt 9.156718 lr 0.00024335 rank 3
2022-12-08 12:56:38,729 DEBUG TRAIN Batch 31/5300 loss 5.046456 loss_att 358.664490 loss_ctc 8.356935 loss_rnnt 4.678625 lr 0.00024336 rank 6
2022-12-08 12:56:38,729 DEBUG TRAIN Batch 31/5300 loss 7.122391 loss_att 430.918304 loss_ctc 26.787895 loss_rnnt 4.937335 lr 0.00024337 rank 1
2022-12-08 12:57:48,598 DEBUG TRAIN Batch 31/5400 loss 14.470132 loss_att 396.306946 loss_ctc 25.317757 loss_rnnt 13.264841 lr 0.00024330 rank 7
2022-12-08 12:57:48,599 DEBUG TRAIN Batch 31/5400 loss 2.821768 loss_att 333.013763 loss_ctc 10.709745 loss_rnnt 1.945326 lr 0.00024330 rank 4
2022-12-08 12:57:48,604 DEBUG TRAIN Batch 31/5400 loss 6.545923 loss_att 379.975311 loss_ctc 14.522289 loss_rnnt 5.659660 lr 0.00024333 rank 6
2022-12-08 12:57:48,606 DEBUG TRAIN Batch 31/5400 loss 3.369372 loss_att 352.145935 loss_ctc 12.009718 loss_rnnt 2.409333 lr 0.00024332 rank 2
2022-12-08 12:57:48,607 DEBUG TRAIN Batch 31/5400 loss 5.163666 loss_att 333.253265 loss_ctc 10.600554 loss_rnnt 4.559568 lr 0.00024334 rank 1
2022-12-08 12:57:48,607 DEBUG TRAIN Batch 31/5400 loss 3.251359 loss_att 326.749237 loss_ctc 6.315747 loss_rnnt 2.910871 lr 0.00024330 rank 0
2022-12-08 12:57:48,608 DEBUG TRAIN Batch 31/5400 loss 6.006614 loss_att 392.612488 loss_ctc 14.095312 loss_rnnt 5.107870 lr 0.00024333 rank 5
2022-12-08 12:57:48,651 DEBUG TRAIN Batch 31/5400 loss 4.234991 loss_att 356.175262 loss_ctc 10.934914 loss_rnnt 3.490555 lr 0.00024332 rank 3
2022-12-08 12:58:51,656 DEBUG TRAIN Batch 31/5500 loss 3.219800 loss_att 302.948212 loss_ctc 7.053220 loss_rnnt 2.793865 lr 0.00024327 rank 4
2022-12-08 12:58:51,658 DEBUG TRAIN Batch 31/5500 loss 5.775295 loss_att 376.941406 loss_ctc 17.781595 loss_rnnt 4.441262 lr 0.00024331 rank 1
2022-12-08 12:58:51,660 DEBUG TRAIN Batch 31/5500 loss 6.157911 loss_att 364.806244 loss_ctc 13.248831 loss_rnnt 5.370031 lr 0.00024330 rank 6
2022-12-08 12:58:51,660 DEBUG TRAIN Batch 31/5500 loss 7.926456 loss_att 388.621368 loss_ctc 20.061687 loss_rnnt 6.578097 lr 0.00024327 rank 7
2022-12-08 12:58:51,662 DEBUG TRAIN Batch 31/5500 loss 10.896276 loss_att 358.106812 loss_ctc 23.285673 loss_rnnt 9.519676 lr 0.00024330 rank 5
2022-12-08 12:58:51,664 DEBUG TRAIN Batch 31/5500 loss 13.220968 loss_att 390.308289 loss_ctc 21.511776 loss_rnnt 12.299768 lr 0.00024329 rank 3
2022-12-08 12:58:51,665 DEBUG TRAIN Batch 31/5500 loss 9.395023 loss_att 387.673096 loss_ctc 16.329992 loss_rnnt 8.624472 lr 0.00024327 rank 0
2022-12-08 12:58:51,703 DEBUG TRAIN Batch 31/5500 loss 8.542356 loss_att 387.938080 loss_ctc 18.046040 loss_rnnt 7.486392 lr 0.00024330 rank 2
2022-12-08 12:59:55,066 DEBUG TRAIN Batch 31/5600 loss 6.905784 loss_att 301.078918 loss_ctc 12.308080 loss_rnnt 6.305529 lr 0.00024327 rank 6
2022-12-08 12:59:55,066 DEBUG TRAIN Batch 31/5600 loss 7.109773 loss_att 359.892761 loss_ctc 10.979207 loss_rnnt 6.679836 lr 0.00024325 rank 7
2022-12-08 12:59:55,068 DEBUG TRAIN Batch 31/5600 loss 2.495018 loss_att 411.909790 loss_ctc 6.075731 loss_rnnt 2.097161 lr 0.00024327 rank 2
2022-12-08 12:59:55,069 DEBUG TRAIN Batch 31/5600 loss 12.101383 loss_att 357.848846 loss_ctc 18.566345 loss_rnnt 11.383055 lr 0.00024327 rank 3
2022-12-08 12:59:55,069 DEBUG TRAIN Batch 31/5600 loss 8.223701 loss_att 328.877716 loss_ctc 16.867817 loss_rnnt 7.263245 lr 0.00024329 rank 1
2022-12-08 12:59:55,070 DEBUG TRAIN Batch 31/5600 loss 9.290227 loss_att 367.313171 loss_ctc 17.328674 loss_rnnt 8.397066 lr 0.00024324 rank 4
2022-12-08 12:59:55,070 DEBUG TRAIN Batch 31/5600 loss 13.267590 loss_att 393.885468 loss_ctc 25.078819 loss_rnnt 11.955231 lr 0.00024324 rank 0
2022-12-08 12:59:55,073 DEBUG TRAIN Batch 31/5600 loss 4.728638 loss_att 313.214294 loss_ctc 10.174900 loss_rnnt 4.123498 lr 0.00024327 rank 5
2022-12-08 13:01:07,661 DEBUG TRAIN Batch 31/5700 loss 8.296099 loss_att 188.194519 loss_ctc 15.225779 loss_rnnt 7.526134 lr 0.00024321 rank 4
2022-12-08 13:01:07,661 DEBUG TRAIN Batch 31/5700 loss 3.588720 loss_att 421.052948 loss_ctc 16.333170 loss_rnnt 2.172670 lr 0.00024324 rank 6
2022-12-08 13:01:07,662 DEBUG TRAIN Batch 31/5700 loss 7.458778 loss_att 178.345535 loss_ctc 13.181395 loss_rnnt 6.822932 lr 0.00024324 rank 3
2022-12-08 13:01:07,662 DEBUG TRAIN Batch 31/5700 loss 12.741981 loss_att 317.753723 loss_ctc 21.333168 loss_rnnt 11.787404 lr 0.00024324 rank 5
2022-12-08 13:01:07,662 DEBUG TRAIN Batch 31/5700 loss 11.254469 loss_att 202.953293 loss_ctc 16.529661 loss_rnnt 10.668336 lr 0.00024322 rank 7
2022-12-08 13:01:07,666 DEBUG TRAIN Batch 31/5700 loss 6.234527 loss_att 345.316345 loss_ctc 15.894445 loss_rnnt 5.161203 lr 0.00024324 rank 2
2022-12-08 13:01:07,667 DEBUG TRAIN Batch 31/5700 loss 3.851229 loss_att 191.782593 loss_ctc 8.618879 loss_rnnt 3.321491 lr 0.00024326 rank 1
2022-12-08 13:01:07,668 DEBUG TRAIN Batch 31/5700 loss 8.437400 loss_att 97.310333 loss_ctc 15.644952 loss_rnnt 7.636561 lr 0.00024322 rank 0
2022-12-08 13:02:10,540 DEBUG TRAIN Batch 31/5800 loss 6.699663 loss_att 390.812012 loss_ctc 9.997969 loss_rnnt 6.333184 lr 0.00024318 rank 4
2022-12-08 13:02:10,545 DEBUG TRAIN Batch 31/5800 loss 8.625227 loss_att 451.304138 loss_ctc 15.215466 loss_rnnt 7.892979 lr 0.00024321 rank 6
2022-12-08 13:02:10,548 DEBUG TRAIN Batch 31/5800 loss 9.739126 loss_att 434.167938 loss_ctc 20.262295 loss_rnnt 8.569885 lr 0.00024319 rank 0
2022-12-08 13:02:10,549 DEBUG TRAIN Batch 31/5800 loss 2.278599 loss_att 368.070862 loss_ctc 4.225905 loss_rnnt 2.062232 lr 0.00024321 rank 3
2022-12-08 13:02:10,550 DEBUG TRAIN Batch 31/5800 loss 2.364090 loss_att 380.500854 loss_ctc 5.654739 loss_rnnt 1.998462 lr 0.00024319 rank 7
2022-12-08 13:02:10,551 DEBUG TRAIN Batch 31/5800 loss 3.248530 loss_att 417.117004 loss_ctc 9.674694 loss_rnnt 2.534512 lr 0.00024323 rank 1
2022-12-08 13:02:10,557 DEBUG TRAIN Batch 31/5800 loss 4.860698 loss_att 192.598358 loss_ctc 10.242096 loss_rnnt 4.262764 lr 0.00024321 rank 5
2022-12-08 13:02:10,590 DEBUG TRAIN Batch 31/5800 loss 9.040189 loss_att 145.218262 loss_ctc 14.167208 loss_rnnt 8.470520 lr 0.00024321 rank 2
2022-12-08 13:03:14,183 DEBUG TRAIN Batch 31/5900 loss 3.014444 loss_att 334.854309 loss_ctc 7.597677 loss_rnnt 2.505196 lr 0.00024320 rank 1
2022-12-08 13:03:14,183 DEBUG TRAIN Batch 31/5900 loss 10.307734 loss_att 438.918884 loss_ctc 21.394398 loss_rnnt 9.075884 lr 0.00024316 rank 4
2022-12-08 13:03:14,185 DEBUG TRAIN Batch 31/5900 loss 1.458116 loss_att 352.214691 loss_ctc 2.703814 loss_rnnt 1.319705 lr 0.00024316 rank 7
2022-12-08 13:03:14,185 DEBUG TRAIN Batch 31/5900 loss 3.252777 loss_att 429.333832 loss_ctc 7.689766 loss_rnnt 2.759778 lr 0.00024316 rank 0
2022-12-08 13:03:14,187 DEBUG TRAIN Batch 31/5900 loss 9.662840 loss_att 370.172424 loss_ctc 21.781477 loss_rnnt 8.316325 lr 0.00024319 rank 6
2022-12-08 13:03:14,191 DEBUG TRAIN Batch 31/5900 loss 2.123213 loss_att 365.758392 loss_ctc 5.995595 loss_rnnt 1.692948 lr 0.00024318 rank 2
2022-12-08 13:03:14,192 DEBUG TRAIN Batch 31/5900 loss 5.055230 loss_att 402.076294 loss_ctc 16.261053 loss_rnnt 3.810139 lr 0.00024318 rank 5
2022-12-08 13:03:14,230 DEBUG TRAIN Batch 31/5900 loss 9.821733 loss_att 397.039551 loss_ctc 18.290241 loss_rnnt 8.880787 lr 0.00024318 rank 3
2022-12-08 13:04:18,469 DEBUG TRAIN Batch 31/6000 loss 7.411943 loss_att 337.719604 loss_ctc 12.874990 loss_rnnt 6.804938 lr 0.00024313 rank 7
2022-12-08 13:04:18,469 DEBUG TRAIN Batch 31/6000 loss 3.046736 loss_att 325.054413 loss_ctc 6.494173 loss_rnnt 2.663687 lr 0.00024315 rank 2
2022-12-08 13:04:18,469 DEBUG TRAIN Batch 31/6000 loss 1.789260 loss_att 358.851013 loss_ctc 4.271744 loss_rnnt 1.513429 lr 0.00024316 rank 6
2022-12-08 13:04:18,471 DEBUG TRAIN Batch 31/6000 loss 10.287339 loss_att 302.505554 loss_ctc 18.646160 loss_rnnt 9.358582 lr 0.00024317 rank 1
2022-12-08 13:04:18,472 DEBUG TRAIN Batch 31/6000 loss 7.273538 loss_att 360.089447 loss_ctc 16.421383 loss_rnnt 6.257111 lr 0.00024315 rank 3
2022-12-08 13:04:18,472 DEBUG TRAIN Batch 31/6000 loss 9.560152 loss_att 387.745850 loss_ctc 26.712048 loss_rnnt 7.654386 lr 0.00024313 rank 4
2022-12-08 13:04:18,475 DEBUG TRAIN Batch 31/6000 loss 10.272892 loss_att 446.132141 loss_ctc 19.119465 loss_rnnt 9.289940 lr 0.00024313 rank 0
2022-12-08 13:04:18,478 DEBUG TRAIN Batch 31/6000 loss 6.930964 loss_att 382.233856 loss_ctc 13.274401 loss_rnnt 6.226137 lr 0.00024315 rank 5
2022-12-08 13:05:28,402 DEBUG TRAIN Batch 31/6100 loss 5.438750 loss_att 300.968262 loss_ctc 8.584332 loss_rnnt 5.089241 lr 0.00024310 rank 7
2022-12-08 13:05:28,403 DEBUG TRAIN Batch 31/6100 loss 5.296171 loss_att 342.765991 loss_ctc 12.926164 loss_rnnt 4.448394 lr 0.00024310 rank 4
2022-12-08 13:05:28,405 DEBUG TRAIN Batch 31/6100 loss 7.834904 loss_att 313.225159 loss_ctc 12.565714 loss_rnnt 7.309258 lr 0.00024313 rank 6
2022-12-08 13:05:28,406 DEBUG TRAIN Batch 31/6100 loss 3.239612 loss_att 341.790710 loss_ctc 10.547426 loss_rnnt 2.427632 lr 0.00024312 rank 3
2022-12-08 13:05:28,408 DEBUG TRAIN Batch 31/6100 loss 2.905356 loss_att 312.927216 loss_ctc 7.806210 loss_rnnt 2.360817 lr 0.00024310 rank 0
2022-12-08 13:05:28,409 DEBUG TRAIN Batch 31/6100 loss 6.654847 loss_att 379.379517 loss_ctc 13.627325 loss_rnnt 5.880127 lr 0.00024312 rank 2
2022-12-08 13:05:28,417 DEBUG TRAIN Batch 31/6100 loss 9.527226 loss_att 384.711975 loss_ctc 16.927870 loss_rnnt 8.704933 lr 0.00024314 rank 1
2022-12-08 13:05:28,449 DEBUG TRAIN Batch 31/6100 loss 6.032009 loss_att 371.422363 loss_ctc 16.210825 loss_rnnt 4.901030 lr 0.00024312 rank 5
2022-12-08 13:06:31,226 DEBUG TRAIN Batch 31/6200 loss 5.246017 loss_att 390.377960 loss_ctc 18.431675 loss_rnnt 3.780943 lr 0.00024307 rank 7
2022-12-08 13:06:31,227 DEBUG TRAIN Batch 31/6200 loss 7.167323 loss_att 345.897705 loss_ctc 14.234620 loss_rnnt 6.382068 lr 0.00024309 rank 2
2022-12-08 13:06:31,228 DEBUG TRAIN Batch 31/6200 loss 4.415928 loss_att 306.506500 loss_ctc 11.301120 loss_rnnt 3.650906 lr 0.00024307 rank 0
2022-12-08 13:06:31,231 DEBUG TRAIN Batch 31/6200 loss 5.921031 loss_att 340.364716 loss_ctc 8.342908 loss_rnnt 5.651933 lr 0.00024307 rank 4
2022-12-08 13:06:31,232 DEBUG TRAIN Batch 31/6200 loss 9.565771 loss_att 328.341919 loss_ctc 17.435452 loss_rnnt 8.691362 lr 0.00024310 rank 6
2022-12-08 13:06:31,233 DEBUG TRAIN Batch 31/6200 loss 8.249957 loss_att 384.213135 loss_ctc 15.504148 loss_rnnt 7.443936 lr 0.00024311 rank 1
2022-12-08 13:06:31,236 DEBUG TRAIN Batch 31/6200 loss 13.983788 loss_att 330.878235 loss_ctc 20.444668 loss_rnnt 13.265912 lr 0.00024309 rank 3
2022-12-08 13:06:31,239 DEBUG TRAIN Batch 31/6200 loss 8.265755 loss_att 357.064819 loss_ctc 16.786337 loss_rnnt 7.319023 lr 0.00024310 rank 5
2022-12-08 13:07:34,225 DEBUG TRAIN Batch 31/6300 loss 10.127143 loss_att 384.193787 loss_ctc 30.287930 loss_rnnt 7.887056 lr 0.00024307 rank 2
2022-12-08 13:07:34,235 DEBUG TRAIN Batch 31/6300 loss 3.661784 loss_att 297.911133 loss_ctc 6.710588 loss_rnnt 3.323028 lr 0.00024307 rank 6
2022-12-08 13:07:34,235 DEBUG TRAIN Batch 31/6300 loss 3.265386 loss_att 239.151230 loss_ctc 8.198550 loss_rnnt 2.717257 lr 0.00024304 rank 7
2022-12-08 13:07:34,236 DEBUG TRAIN Batch 31/6300 loss 7.654795 loss_att 258.593628 loss_ctc 15.832171 loss_rnnt 6.746198 lr 0.00024304 rank 4
2022-12-08 13:07:34,237 DEBUG TRAIN Batch 31/6300 loss 12.205715 loss_att 219.190887 loss_ctc 21.892893 loss_rnnt 11.129362 lr 0.00024306 rank 3
2022-12-08 13:07:34,238 DEBUG TRAIN Batch 31/6300 loss 3.360960 loss_att 344.491058 loss_ctc 11.883191 loss_rnnt 2.414045 lr 0.00024308 rank 1
2022-12-08 13:07:34,242 DEBUG TRAIN Batch 31/6300 loss 6.986034 loss_att 198.093918 loss_ctc 13.545275 loss_rnnt 6.257229 lr 0.00024304 rank 0
2022-12-08 13:07:34,243 DEBUG TRAIN Batch 31/6300 loss 10.135973 loss_att 340.458618 loss_ctc 22.415808 loss_rnnt 8.771547 lr 0.00024307 rank 5
2022-12-08 13:08:46,167 DEBUG TRAIN Batch 31/6400 loss 3.789887 loss_att 239.473633 loss_ctc 7.866300 loss_rnnt 3.336953 lr 0.00024304 rank 5
2022-12-08 13:08:46,169 DEBUG TRAIN Batch 31/6400 loss 4.699839 loss_att 335.966309 loss_ctc 11.831507 loss_rnnt 3.907431 lr 0.00024301 rank 4
2022-12-08 13:08:46,169 DEBUG TRAIN Batch 31/6400 loss 10.168201 loss_att 397.911224 loss_ctc 15.101790 loss_rnnt 9.620025 lr 0.00024302 rank 7
2022-12-08 13:08:46,171 DEBUG TRAIN Batch 31/6400 loss 8.642886 loss_att 281.444458 loss_ctc 20.310896 loss_rnnt 7.346441 lr 0.00024304 rank 2
2022-12-08 13:08:46,171 DEBUG TRAIN Batch 31/6400 loss 8.319253 loss_att 124.211357 loss_ctc 14.749100 loss_rnnt 7.604825 lr 0.00024304 rank 6
2022-12-08 13:08:46,175 DEBUG TRAIN Batch 31/6400 loss 7.387096 loss_att 327.136536 loss_ctc 8.207985 loss_rnnt 7.295887 lr 0.00024306 rank 1
2022-12-08 13:08:46,177 DEBUG TRAIN Batch 31/6400 loss 8.142532 loss_att 391.044281 loss_ctc 19.336403 loss_rnnt 6.898769 lr 0.00024301 rank 0
2022-12-08 13:08:46,211 DEBUG TRAIN Batch 31/6400 loss 9.150021 loss_att 465.987152 loss_ctc 22.626890 loss_rnnt 7.652591 lr 0.00024304 rank 3
2022-12-08 13:09:49,222 DEBUG TRAIN Batch 31/6500 loss 6.264317 loss_att 382.155029 loss_ctc 15.393012 loss_rnnt 5.250017 lr 0.00024298 rank 4
2022-12-08 13:09:49,225 DEBUG TRAIN Batch 31/6500 loss 12.605342 loss_att 407.875336 loss_ctc 21.898376 loss_rnnt 11.572783 lr 0.00024299 rank 7
2022-12-08 13:09:49,227 DEBUG TRAIN Batch 31/6500 loss 4.393179 loss_att 338.698578 loss_ctc 6.714303 loss_rnnt 4.135277 lr 0.00024301 rank 2
2022-12-08 13:09:49,228 DEBUG TRAIN Batch 31/6500 loss 7.933037 loss_att 457.942627 loss_ctc 19.366570 loss_rnnt 6.662645 lr 0.00024301 rank 6
2022-12-08 13:09:49,228 DEBUG TRAIN Batch 31/6500 loss 9.387237 loss_att 405.095947 loss_ctc 16.508789 loss_rnnt 8.595953 lr 0.00024301 rank 3
2022-12-08 13:09:49,229 DEBUG TRAIN Batch 31/6500 loss 5.326404 loss_att 363.181732 loss_ctc 14.207478 loss_rnnt 4.339618 lr 0.00024301 rank 5
2022-12-08 13:09:49,232 DEBUG TRAIN Batch 31/6500 loss 6.676265 loss_att 426.934509 loss_ctc 18.733515 loss_rnnt 5.336571 lr 0.00024299 rank 0
2022-12-08 13:09:49,234 DEBUG TRAIN Batch 31/6500 loss 9.176409 loss_att 457.925903 loss_ctc 21.102154 loss_rnnt 7.851326 lr 0.00024303 rank 1
2022-12-08 13:10:52,422 DEBUG TRAIN Batch 31/6600 loss 2.563737 loss_att 397.423279 loss_ctc 9.538048 loss_rnnt 1.788813 lr 0.00024296 rank 4
2022-12-08 13:10:52,427 DEBUG TRAIN Batch 31/6600 loss 7.892439 loss_att 397.047455 loss_ctc 18.849854 loss_rnnt 6.674949 lr 0.00024298 rank 6
2022-12-08 13:10:52,428 DEBUG TRAIN Batch 31/6600 loss 7.309030 loss_att 363.962769 loss_ctc 14.423720 loss_rnnt 6.518509 lr 0.00024298 rank 3
2022-12-08 13:10:52,430 DEBUG TRAIN Batch 31/6600 loss 5.065611 loss_att 342.922974 loss_ctc 14.054180 loss_rnnt 4.066881 lr 0.00024298 rank 5
2022-12-08 13:10:52,431 DEBUG TRAIN Batch 31/6600 loss 7.099786 loss_att 480.963470 loss_ctc 16.263048 loss_rnnt 6.081645 lr 0.00024300 rank 1
2022-12-08 13:10:52,433 DEBUG TRAIN Batch 31/6600 loss 13.161860 loss_att 437.103516 loss_ctc 22.729591 loss_rnnt 12.098778 lr 0.00024298 rank 2
2022-12-08 13:10:52,434 DEBUG TRAIN Batch 31/6600 loss 9.782122 loss_att 385.326141 loss_ctc 15.373500 loss_rnnt 9.160858 lr 0.00024296 rank 7
2022-12-08 13:10:52,436 DEBUG TRAIN Batch 31/6600 loss 4.120876 loss_att 371.998016 loss_ctc 11.815265 loss_rnnt 3.265944 lr 0.00024296 rank 0
2022-12-08 13:11:56,240 DEBUG TRAIN Batch 31/6700 loss 9.107676 loss_att 373.394104 loss_ctc 21.830372 loss_rnnt 7.694043 lr 0.00024295 rank 3
2022-12-08 13:11:56,243 DEBUG TRAIN Batch 31/6700 loss 6.047335 loss_att 358.861267 loss_ctc 14.307719 loss_rnnt 5.129515 lr 0.00024293 rank 0
2022-12-08 13:11:56,254 DEBUG TRAIN Batch 31/6700 loss 15.971767 loss_att 437.170166 loss_ctc 32.368519 loss_rnnt 14.149907 lr 0.00024293 rank 7
2022-12-08 13:11:56,256 DEBUG TRAIN Batch 31/6700 loss 6.095937 loss_att 416.059174 loss_ctc 15.283991 loss_rnnt 5.075043 lr 0.00024295 rank 2
2022-12-08 13:11:56,257 DEBUG TRAIN Batch 31/6700 loss 17.486227 loss_att 444.875244 loss_ctc 30.901419 loss_rnnt 15.995650 lr 0.00024293 rank 4
2022-12-08 13:11:56,263 DEBUG TRAIN Batch 31/6700 loss 7.398724 loss_att 378.744720 loss_ctc 16.563032 loss_rnnt 6.380467 lr 0.00024295 rank 5
2022-12-08 13:11:56,279 DEBUG TRAIN Batch 31/6700 loss 7.726348 loss_att 350.724091 loss_ctc 13.710175 loss_rnnt 7.061479 lr 0.00024296 rank 6
2022-12-08 13:11:56,297 DEBUG TRAIN Batch 31/6700 loss 5.972653 loss_att 387.250183 loss_ctc 8.664759 loss_rnnt 5.673530 lr 0.00024297 rank 1
2022-12-08 13:13:06,927 DEBUG TRAIN Batch 31/6800 loss 4.971643 loss_att 353.961365 loss_ctc 10.220134 loss_rnnt 4.388477 lr 0.00024293 rank 6
2022-12-08 13:13:06,927 DEBUG TRAIN Batch 31/6800 loss 3.975859 loss_att 316.208313 loss_ctc 14.445630 loss_rnnt 2.812551 lr 0.00024292 rank 2
2022-12-08 13:13:06,927 DEBUG TRAIN Batch 31/6800 loss 5.014304 loss_att 332.872925 loss_ctc 9.282497 loss_rnnt 4.540060 lr 0.00024290 rank 7
2022-12-08 13:13:06,929 DEBUG TRAIN Batch 31/6800 loss 7.912742 loss_att 302.478790 loss_ctc 15.380882 loss_rnnt 7.082949 lr 0.00024292 rank 3
2022-12-08 13:13:06,930 DEBUG TRAIN Batch 31/6800 loss 8.275180 loss_att 334.285095 loss_ctc 14.876400 loss_rnnt 7.541711 lr 0.00024294 rank 1
2022-12-08 13:13:06,932 DEBUG TRAIN Batch 31/6800 loss 4.989563 loss_att 341.671753 loss_ctc 13.940448 loss_rnnt 3.995020 lr 0.00024290 rank 0
2022-12-08 13:13:06,933 DEBUG TRAIN Batch 31/6800 loss 4.509932 loss_att 369.500122 loss_ctc 8.722951 loss_rnnt 4.041819 lr 0.00024292 rank 5
2022-12-08 13:13:06,935 DEBUG TRAIN Batch 31/6800 loss 6.727389 loss_att 288.882874 loss_ctc 13.844213 loss_rnnt 5.936631 lr 0.00024290 rank 4
2022-12-08 13:14:10,155 DEBUG TRAIN Batch 31/6900 loss 7.147322 loss_att 305.981445 loss_ctc 11.698196 loss_rnnt 6.641669 lr 0.00024287 rank 7
2022-12-08 13:14:10,155 DEBUG TRAIN Batch 31/6900 loss 8.779088 loss_att 240.109238 loss_ctc 13.483812 loss_rnnt 8.256341 lr 0.00024287 rank 4
2022-12-08 13:14:10,157 DEBUG TRAIN Batch 31/6900 loss 6.096249 loss_att 342.823578 loss_ctc 11.810719 loss_rnnt 5.461308 lr 0.00024290 rank 6
2022-12-08 13:14:10,157 DEBUG TRAIN Batch 31/6900 loss 9.071374 loss_att 340.829895 loss_ctc 15.334424 loss_rnnt 8.375480 lr 0.00024289 rank 3
2022-12-08 13:14:10,157 DEBUG TRAIN Batch 31/6900 loss 12.455023 loss_att 351.001526 loss_ctc 18.057695 loss_rnnt 11.832503 lr 0.00024291 rank 1
2022-12-08 13:14:10,157 DEBUG TRAIN Batch 31/6900 loss 6.840051 loss_att 305.350098 loss_ctc 15.656924 loss_rnnt 5.860398 lr 0.00024289 rank 2
2022-12-08 13:14:10,162 DEBUG TRAIN Batch 31/6900 loss 7.927135 loss_att 302.427032 loss_ctc 14.618408 loss_rnnt 7.183661 lr 0.00024287 rank 0
2022-12-08 13:14:10,163 DEBUG TRAIN Batch 31/6900 loss 9.705037 loss_att 422.384033 loss_ctc 20.861244 loss_rnnt 8.465459 lr 0.00024289 rank 5
2022-12-08 13:15:13,559 DEBUG TRAIN Batch 31/7000 loss 9.274954 loss_att 228.785172 loss_ctc 14.855936 loss_rnnt 8.654845 lr 0.00024284 rank 7
2022-12-08 13:15:13,562 DEBUG TRAIN Batch 31/7000 loss 8.748562 loss_att 337.181427 loss_ctc 17.149696 loss_rnnt 7.815103 lr 0.00024287 rank 6
2022-12-08 13:15:13,563 DEBUG TRAIN Batch 31/7000 loss 7.962227 loss_att 122.487709 loss_ctc 10.851842 loss_rnnt 7.641159 lr 0.00024288 rank 1
2022-12-08 13:15:13,564 DEBUG TRAIN Batch 31/7000 loss 11.481019 loss_att 408.874939 loss_ctc 19.265425 loss_rnnt 10.616085 lr 0.00024286 rank 3
2022-12-08 13:15:13,564 DEBUG TRAIN Batch 31/7000 loss 5.682931 loss_att 294.108521 loss_ctc 12.467312 loss_rnnt 4.929111 lr 0.00024287 rank 2
2022-12-08 13:15:13,567 DEBUG TRAIN Batch 31/7000 loss 5.509919 loss_att 175.127594 loss_ctc 10.439287 loss_rnnt 4.962212 lr 0.00024284 rank 4
2022-12-08 13:15:13,569 DEBUG TRAIN Batch 31/7000 loss 5.830317 loss_att 430.722534 loss_ctc 12.845020 loss_rnnt 5.050906 lr 0.00024284 rank 0
2022-12-08 13:15:13,570 DEBUG TRAIN Batch 31/7000 loss 8.803834 loss_att 346.550049 loss_ctc 16.231817 loss_rnnt 7.978503 lr 0.00024287 rank 5
2022-12-08 13:16:25,333 DEBUG TRAIN Batch 31/7100 loss 5.747182 loss_att 393.499023 loss_ctc 10.393723 loss_rnnt 5.230900 lr 0.00024284 rank 6
2022-12-08 13:16:25,333 DEBUG TRAIN Batch 31/7100 loss 5.433683 loss_att 350.561523 loss_ctc 11.985434 loss_rnnt 4.705710 lr 0.00024283 rank 3
2022-12-08 13:16:25,333 DEBUG TRAIN Batch 31/7100 loss 10.081291 loss_att 486.001282 loss_ctc 21.754265 loss_rnnt 8.784294 lr 0.00024281 rank 4
2022-12-08 13:16:25,335 DEBUG TRAIN Batch 31/7100 loss 8.113073 loss_att 376.044800 loss_ctc 19.591820 loss_rnnt 6.837657 lr 0.00024285 rank 1
2022-12-08 13:16:25,337 DEBUG TRAIN Batch 31/7100 loss 7.061724 loss_att 208.597839 loss_ctc 10.420020 loss_rnnt 6.688580 lr 0.00024284 rank 5
2022-12-08 13:16:25,343 DEBUG TRAIN Batch 31/7100 loss 15.952372 loss_att 384.587097 loss_ctc 34.784168 loss_rnnt 13.859951 lr 0.00024281 rank 0
2022-12-08 13:16:25,344 DEBUG TRAIN Batch 31/7100 loss 1.439615 loss_att 488.234863 loss_ctc 6.359222 loss_rnnt 0.892992 lr 0.00024282 rank 7
2022-12-08 13:16:25,355 DEBUG TRAIN Batch 31/7100 loss 7.547958 loss_att 103.163284 loss_ctc 13.344807 loss_rnnt 6.903864 lr 0.00024284 rank 2
2022-12-08 13:17:28,337 DEBUG TRAIN Batch 31/7200 loss 9.045393 loss_att 354.284607 loss_ctc 14.108986 loss_rnnt 8.482772 lr 0.00024278 rank 4
2022-12-08 13:17:28,344 DEBUG TRAIN Batch 31/7200 loss 8.226291 loss_att 345.562927 loss_ctc 16.797501 loss_rnnt 7.273934 lr 0.00024281 rank 2
2022-12-08 13:17:28,345 DEBUG TRAIN Batch 31/7200 loss 2.100692 loss_att 365.784363 loss_ctc 9.844172 loss_rnnt 1.240305 lr 0.00024281 rank 6
2022-12-08 13:17:28,345 DEBUG TRAIN Batch 31/7200 loss 9.556261 loss_att 340.489136 loss_ctc 22.927429 loss_rnnt 8.070576 lr 0.00024281 rank 3
2022-12-08 13:17:28,348 DEBUG TRAIN Batch 31/7200 loss 8.566654 loss_att 394.411102 loss_ctc 19.325397 loss_rnnt 7.371238 lr 0.00024283 rank 1
2022-12-08 13:17:28,348 DEBUG TRAIN Batch 31/7200 loss 5.142968 loss_att 386.283936 loss_ctc 16.617952 loss_rnnt 3.867970 lr 0.00024279 rank 7
2022-12-08 13:17:28,349 DEBUG TRAIN Batch 31/7200 loss 3.168426 loss_att 383.299622 loss_ctc 12.531699 loss_rnnt 2.128062 lr 0.00024281 rank 5
2022-12-08 13:17:28,351 DEBUG TRAIN Batch 31/7200 loss 4.428683 loss_att 331.360687 loss_ctc 8.771557 loss_rnnt 3.946141 lr 0.00024278 rank 0
2022-12-08 13:18:31,742 DEBUG TRAIN Batch 31/7300 loss 8.812816 loss_att 371.120300 loss_ctc 11.510956 loss_rnnt 8.513022 lr 0.00024275 rank 4
2022-12-08 13:18:31,743 DEBUG TRAIN Batch 31/7300 loss 16.444950 loss_att 388.028442 loss_ctc 29.192165 loss_rnnt 15.028594 lr 0.00024276 rank 7
2022-12-08 13:18:31,746 DEBUG TRAIN Batch 31/7300 loss 3.881195 loss_att 372.519226 loss_ctc 11.382673 loss_rnnt 3.047697 lr 0.00024278 rank 6
2022-12-08 13:18:31,747 DEBUG TRAIN Batch 31/7300 loss 6.867143 loss_att 387.867889 loss_ctc 15.501656 loss_rnnt 5.907753 lr 0.00024278 rank 5
2022-12-08 13:18:31,750 DEBUG TRAIN Batch 31/7300 loss 3.895522 loss_att 336.865967 loss_ctc 6.461611 loss_rnnt 3.610401 lr 0.00024280 rank 1
2022-12-08 13:18:31,750 DEBUG TRAIN Batch 31/7300 loss 7.902944 loss_att 355.582489 loss_ctc 19.353142 loss_rnnt 6.630700 lr 0.00024278 rank 2
2022-12-08 13:18:31,751 DEBUG TRAIN Batch 31/7300 loss 5.097504 loss_att 356.882721 loss_ctc 13.288952 loss_rnnt 4.187343 lr 0.00024276 rank 0
2022-12-08 13:18:31,788 DEBUG TRAIN Batch 31/7300 loss 4.511444 loss_att 354.236206 loss_ctc 6.894595 loss_rnnt 4.246649 lr 0.00024278 rank 3
2022-12-08 13:19:35,777 DEBUG TRAIN Batch 31/7400 loss 4.520773 loss_att 358.057983 loss_ctc 10.074122 loss_rnnt 3.903734 lr 0.00024276 rank 6
2022-12-08 13:19:35,777 DEBUG TRAIN Batch 31/7400 loss 1.488817 loss_att 304.661041 loss_ctc 4.814919 loss_rnnt 1.119250 lr 0.00024273 rank 4
2022-12-08 13:19:35,778 DEBUG TRAIN Batch 31/7400 loss 7.906114 loss_att 433.674957 loss_ctc 21.939869 loss_rnnt 6.346808 lr 0.00024273 rank 7
2022-12-08 13:19:35,778 DEBUG TRAIN Batch 31/7400 loss 6.707721 loss_att 418.985229 loss_ctc 13.064611 loss_rnnt 6.001400 lr 0.00024275 rank 2
2022-12-08 13:19:35,780 DEBUG TRAIN Batch 31/7400 loss 4.802788 loss_att 419.699615 loss_ctc 15.382326 loss_rnnt 3.627284 lr 0.00024275 rank 5
2022-12-08 13:19:35,783 DEBUG TRAIN Batch 31/7400 loss 6.867426 loss_att 383.743561 loss_ctc 18.714869 loss_rnnt 5.551043 lr 0.00024275 rank 3
2022-12-08 13:19:35,783 DEBUG TRAIN Batch 31/7400 loss 2.647154 loss_att 342.397705 loss_ctc 4.973146 loss_rnnt 2.388710 lr 0.00024277 rank 1
2022-12-08 13:19:35,784 DEBUG TRAIN Batch 31/7400 loss 6.541555 loss_att 415.364868 loss_ctc 10.917300 loss_rnnt 6.055362 lr 0.00024273 rank 0
2022-12-08 13:20:47,481 DEBUG TRAIN Batch 31/7500 loss 15.201094 loss_att 381.995728 loss_ctc 25.654236 loss_rnnt 14.039634 lr 0.00024270 rank 4
2022-12-08 13:20:47,484 DEBUG TRAIN Batch 31/7500 loss 8.577656 loss_att 387.480133 loss_ctc 17.003059 loss_rnnt 7.641500 lr 0.00024272 rank 2
2022-12-08 13:20:47,484 DEBUG TRAIN Batch 31/7500 loss 10.227943 loss_att 288.530853 loss_ctc 20.992868 loss_rnnt 9.031840 lr 0.00024272 rank 3
2022-12-08 13:20:47,486 DEBUG TRAIN Batch 31/7500 loss 9.693818 loss_att 382.762146 loss_ctc 20.973789 loss_rnnt 8.440488 lr 0.00024272 rank 5
2022-12-08 13:20:47,488 DEBUG TRAIN Batch 31/7500 loss 14.136489 loss_att 315.346252 loss_ctc 23.004189 loss_rnnt 13.151190 lr 0.00024270 rank 7
2022-12-08 13:20:47,488 DEBUG TRAIN Batch 31/7500 loss 4.865628 loss_att 371.030762 loss_ctc 10.484213 loss_rnnt 4.241341 lr 0.00024273 rank 6
2022-12-08 13:20:47,493 DEBUG TRAIN Batch 31/7500 loss 10.265940 loss_att 324.671722 loss_ctc 20.468796 loss_rnnt 9.132289 lr 0.00024270 rank 0
2022-12-08 13:20:47,528 DEBUG TRAIN Batch 31/7500 loss 10.270036 loss_att 350.692474 loss_ctc 19.690216 loss_rnnt 9.223350 lr 0.00024274 rank 1
2022-12-08 13:21:51,150 DEBUG TRAIN Batch 31/7600 loss 12.112173 loss_att 288.083252 loss_ctc 27.873762 loss_rnnt 10.360886 lr 0.00024267 rank 4
2022-12-08 13:21:51,151 DEBUG TRAIN Batch 31/7600 loss 10.819777 loss_att 343.885101 loss_ctc 19.853256 loss_rnnt 9.816057 lr 0.00024269 rank 2
2022-12-08 13:21:51,153 DEBUG TRAIN Batch 31/7600 loss 2.495804 loss_att 201.580734 loss_ctc 5.921208 loss_rnnt 2.115203 lr 0.00024267 rank 7
2022-12-08 13:21:51,154 DEBUG TRAIN Batch 31/7600 loss 12.274937 loss_att 240.340820 loss_ctc 16.827030 loss_rnnt 11.769149 lr 0.00024267 rank 0
2022-12-08 13:21:51,156 DEBUG TRAIN Batch 31/7600 loss 7.717983 loss_att 474.216248 loss_ctc 14.521819 loss_rnnt 6.962001 lr 0.00024269 rank 3
2022-12-08 13:21:51,159 DEBUG TRAIN Batch 31/7600 loss 13.387963 loss_att 153.599686 loss_ctc 20.774689 loss_rnnt 12.567217 lr 0.00024271 rank 1
2022-12-08 13:21:51,161 DEBUG TRAIN Batch 31/7600 loss 5.112628 loss_att 385.149780 loss_ctc 11.394661 loss_rnnt 4.414624 lr 0.00024269 rank 5
2022-12-08 13:21:51,205 DEBUG TRAIN Batch 31/7600 loss 7.493430 loss_att 350.579956 loss_ctc 12.785407 loss_rnnt 6.905433 lr 0.00024270 rank 6
2022-12-08 13:22:54,036 DEBUG TRAIN Batch 31/7700 loss 5.700178 loss_att 372.854980 loss_ctc 18.101538 loss_rnnt 4.322249 lr 0.00024264 rank 4
2022-12-08 13:22:54,037 DEBUG TRAIN Batch 31/7700 loss 11.078040 loss_att 396.312592 loss_ctc 21.953512 loss_rnnt 9.869654 lr 0.00024264 rank 7
2022-12-08 13:22:54,037 DEBUG TRAIN Batch 31/7700 loss 6.105775 loss_att 370.660828 loss_ctc 12.030647 loss_rnnt 5.447455 lr 0.00024266 rank 3
2022-12-08 13:22:54,037 DEBUG TRAIN Batch 31/7700 loss 8.107016 loss_att 274.196136 loss_ctc 12.401913 loss_rnnt 7.629806 lr 0.00024267 rank 5
2022-12-08 13:22:54,040 DEBUG TRAIN Batch 31/7700 loss 6.209318 loss_att 380.479675 loss_ctc 15.964743 loss_rnnt 5.125382 lr 0.00024268 rank 1
2022-12-08 13:22:54,041 DEBUG TRAIN Batch 31/7700 loss 11.384567 loss_att 191.570770 loss_ctc 20.439476 loss_rnnt 10.378466 lr 0.00024266 rank 2
2022-12-08 13:22:54,042 DEBUG TRAIN Batch 31/7700 loss 5.158877 loss_att 342.891357 loss_ctc 16.510489 loss_rnnt 3.897587 lr 0.00024264 rank 0
2022-12-08 13:22:54,043 DEBUG TRAIN Batch 31/7700 loss 10.132374 loss_att 163.073196 loss_ctc 15.177542 loss_rnnt 9.571799 lr 0.00024267 rank 6
2022-12-08 13:23:59,227 DEBUG TRAIN Batch 31/7800 loss 5.417150 loss_att 345.625610 loss_ctc 8.975455 loss_rnnt 5.021783 lr 0.00024264 rank 2
2022-12-08 13:23:59,241 DEBUG TRAIN Batch 31/7800 loss 8.340397 loss_att 448.805664 loss_ctc 21.483559 loss_rnnt 6.880045 lr 0.00024261 rank 4
2022-12-08 13:23:59,243 DEBUG TRAIN Batch 31/7800 loss 14.228346 loss_att 360.041016 loss_ctc 26.245197 loss_rnnt 12.893141 lr 0.00024264 rank 6
2022-12-08 13:23:59,243 DEBUG TRAIN Batch 31/7800 loss 3.519975 loss_att 383.442932 loss_ctc 7.753761 loss_rnnt 3.049555 lr 0.00024264 rank 5
2022-12-08 13:23:59,244 DEBUG TRAIN Batch 31/7800 loss 13.848701 loss_att 468.882751 loss_ctc 25.129271 loss_rnnt 12.595305 lr 0.00024265 rank 1
2022-12-08 13:23:59,245 DEBUG TRAIN Batch 31/7800 loss 1.779012 loss_att 419.264008 loss_ctc 4.637053 loss_rnnt 1.461452 lr 0.00024261 rank 7
2022-12-08 13:23:59,249 DEBUG TRAIN Batch 31/7800 loss 1.678693 loss_att 324.603394 loss_ctc 6.314880 loss_rnnt 1.163561 lr 0.00024261 rank 0
2022-12-08 13:23:59,279 DEBUG TRAIN Batch 31/7800 loss 2.597579 loss_att 391.341003 loss_ctc 7.807193 loss_rnnt 2.018733 lr 0.00024263 rank 3
2022-12-08 13:25:09,807 DEBUG TRAIN Batch 31/7900 loss 7.590236 loss_att 420.380127 loss_ctc 17.653965 loss_rnnt 6.472044 lr 0.00024258 rank 4
2022-12-08 13:25:09,809 DEBUG TRAIN Batch 31/7900 loss 2.914021 loss_att 442.243988 loss_ctc 9.582013 loss_rnnt 2.173133 lr 0.00024261 rank 6
2022-12-08 13:25:09,811 DEBUG TRAIN Batch 31/7900 loss 5.202196 loss_att 317.068237 loss_ctc 7.342956 loss_rnnt 4.964334 lr 0.00024261 rank 5
2022-12-08 13:25:09,811 DEBUG TRAIN Batch 31/7900 loss 2.027924 loss_att 363.906464 loss_ctc 7.898138 loss_rnnt 1.375678 lr 0.00024261 rank 2
2022-12-08 13:25:09,811 DEBUG TRAIN Batch 31/7900 loss 5.700588 loss_att 347.804352 loss_ctc 15.494729 loss_rnnt 4.612350 lr 0.00024261 rank 3
2022-12-08 13:25:09,813 DEBUG TRAIN Batch 31/7900 loss 8.433475 loss_att 369.524628 loss_ctc 14.527355 loss_rnnt 7.756376 lr 0.00024258 rank 0
2022-12-08 13:25:09,821 DEBUG TRAIN Batch 31/7900 loss 3.406481 loss_att 311.771118 loss_ctc 4.281148 loss_rnnt 3.309296 lr 0.00024259 rank 7
2022-12-08 13:25:09,835 DEBUG TRAIN Batch 31/7900 loss 5.116659 loss_att 394.882935 loss_ctc 10.665558 loss_rnnt 4.500114 lr 0.00024263 rank 1
2022-12-08 13:26:13,607 DEBUG TRAIN Batch 31/8000 loss 3.844537 loss_att 333.262939 loss_ctc 8.231773 loss_rnnt 3.357066 lr 0.00024255 rank 4
2022-12-08 13:26:13,608 DEBUG TRAIN Batch 31/8000 loss 2.106634 loss_att 393.741150 loss_ctc 8.687140 loss_rnnt 1.375466 lr 0.00024256 rank 7
2022-12-08 13:26:13,611 DEBUG TRAIN Batch 31/8000 loss 9.776161 loss_att 428.092804 loss_ctc 16.442017 loss_rnnt 9.035511 lr 0.00024258 rank 6
2022-12-08 13:26:13,613 DEBUG TRAIN Batch 31/8000 loss 3.833794 loss_att 362.166504 loss_ctc 9.303485 loss_rnnt 3.226051 lr 0.00024258 rank 3
2022-12-08 13:26:13,614 DEBUG TRAIN Batch 31/8000 loss 7.088609 loss_att 352.104614 loss_ctc 13.203321 loss_rnnt 6.409197 lr 0.00024258 rank 2
2022-12-08 13:26:13,616 DEBUG TRAIN Batch 31/8000 loss 7.218659 loss_att 348.962097 loss_ctc 14.015131 loss_rnnt 6.463496 lr 0.00024260 rank 1
2022-12-08 13:26:13,619 DEBUG TRAIN Batch 31/8000 loss 8.521736 loss_att 354.892212 loss_ctc 14.392303 loss_rnnt 7.869452 lr 0.00024256 rank 0
2022-12-08 13:26:13,621 DEBUG TRAIN Batch 31/8000 loss 5.026264 loss_att 415.662598 loss_ctc 9.433204 loss_rnnt 4.536604 lr 0.00024258 rank 5
2022-12-08 13:27:17,186 DEBUG TRAIN Batch 31/8100 loss 8.773418 loss_att 370.836731 loss_ctc 16.579082 loss_rnnt 7.906122 lr 0.00024255 rank 3
2022-12-08 13:27:17,197 DEBUG TRAIN Batch 31/8100 loss 7.731151 loss_att 319.651428 loss_ctc 17.089460 loss_rnnt 6.691339 lr 0.00024253 rank 4
2022-12-08 13:27:17,198 DEBUG TRAIN Batch 31/8100 loss 18.977489 loss_att 330.207123 loss_ctc 33.801025 loss_rnnt 17.330431 lr 0.00024253 rank 7
2022-12-08 13:27:17,198 DEBUG TRAIN Batch 31/8100 loss 3.199449 loss_att 352.685364 loss_ctc 9.869699 loss_rnnt 2.458310 lr 0.00024257 rank 1
2022-12-08 13:27:17,202 DEBUG TRAIN Batch 31/8100 loss 11.311061 loss_att 358.342590 loss_ctc 26.118145 loss_rnnt 9.665830 lr 0.00024253 rank 0
2022-12-08 13:27:17,203 DEBUG TRAIN Batch 31/8100 loss 11.234486 loss_att 339.541992 loss_ctc 19.241476 loss_rnnt 10.344820 lr 0.00024255 rank 2
2022-12-08 13:27:17,230 DEBUG TRAIN Batch 31/8100 loss 11.762843 loss_att 463.274017 loss_ctc 19.715328 loss_rnnt 10.879234 lr 0.00024255 rank 5
2022-12-08 13:27:17,243 DEBUG TRAIN Batch 31/8100 loss 10.699835 loss_att 345.779236 loss_ctc 20.761780 loss_rnnt 9.581841 lr 0.00024256 rank 6
2022-12-08 13:28:21,869 DEBUG TRAIN Batch 31/8200 loss 7.210221 loss_att 411.052460 loss_ctc 18.965378 loss_rnnt 5.904093 lr 0.00024253 rank 6
2022-12-08 13:28:21,871 DEBUG TRAIN Batch 31/8200 loss 5.631426 loss_att 299.465454 loss_ctc 11.777895 loss_rnnt 4.948485 lr 0.00024250 rank 7
2022-12-08 13:28:21,872 DEBUG TRAIN Batch 31/8200 loss 3.643498 loss_att 329.399658 loss_ctc 10.253876 loss_rnnt 2.909012 lr 0.00024252 rank 2
2022-12-08 13:28:21,874 DEBUG TRAIN Batch 31/8200 loss 14.825292 loss_att 248.644653 loss_ctc 27.409468 loss_rnnt 13.427051 lr 0.00024254 rank 1
2022-12-08 13:28:21,874 DEBUG TRAIN Batch 31/8200 loss 4.803370 loss_att 337.952667 loss_ctc 11.313461 loss_rnnt 4.080026 lr 0.00024252 rank 5
2022-12-08 13:28:21,874 DEBUG TRAIN Batch 31/8200 loss 1.520048 loss_att 294.968628 loss_ctc 2.763707 loss_rnnt 1.381864 lr 0.00024250 rank 4
2022-12-08 13:28:21,874 DEBUG TRAIN Batch 31/8200 loss 4.247581 loss_att 246.766571 loss_ctc 8.185198 loss_rnnt 3.810068 lr 0.00024252 rank 3
2022-12-08 13:28:21,876 DEBUG TRAIN Batch 31/8200 loss 10.131021 loss_att 139.662552 loss_ctc 15.467581 loss_rnnt 9.538071 lr 0.00024250 rank 0
2022-12-08 13:29:25,238 DEBUG TRAIN Batch 31/8300 loss 11.140708 loss_att 145.334656 loss_ctc 17.488068 loss_rnnt 10.435446 lr 0.00024247 rank 7
2022-12-08 13:29:25,239 DEBUG TRAIN Batch 31/8300 loss 4.841004 loss_att 170.097748 loss_ctc 11.409401 loss_rnnt 4.111182 lr 0.00024247 rank 4
2022-12-08 13:29:25,242 DEBUG TRAIN Batch 31/8300 loss 8.066378 loss_att 393.618835 loss_ctc 18.232962 loss_rnnt 6.936757 lr 0.00024249 rank 2
2022-12-08 13:29:25,243 DEBUG TRAIN Batch 31/8300 loss 7.890595 loss_att 453.464355 loss_ctc 13.793421 loss_rnnt 7.234726 lr 0.00024251 rank 1
2022-12-08 13:29:25,244 DEBUG TRAIN Batch 31/8300 loss 13.141948 loss_att 349.034607 loss_ctc 30.295755 loss_rnnt 11.235970 lr 0.00024250 rank 6
2022-12-08 13:29:25,243 DEBUG TRAIN Batch 31/8300 loss 11.113771 loss_att 383.178558 loss_ctc 20.160490 loss_rnnt 10.108581 lr 0.00024249 rank 5
2022-12-08 13:29:25,246 DEBUG TRAIN Batch 31/8300 loss 10.905180 loss_att 478.138794 loss_ctc 24.055494 loss_rnnt 9.444035 lr 0.00024247 rank 0
2022-12-08 13:29:25,282 DEBUG TRAIN Batch 31/8300 loss 4.195438 loss_att 422.653442 loss_ctc 9.809513 loss_rnnt 3.571652 lr 0.00024249 rank 3
2022-12-08 13:30:04,724 DEBUG CV Batch 31/0 loss 1.162108 loss_att 48.086067 loss_ctc 2.314004 loss_rnnt 1.034119 history loss 1.119067 rank 0
2022-12-08 13:30:04,734 DEBUG CV Batch 31/0 loss 1.162108 loss_att 48.086067 loss_ctc 2.314004 loss_rnnt 1.034119 history loss 1.119067 rank 4
2022-12-08 13:30:04,741 DEBUG CV Batch 31/0 loss 1.162108 loss_att 48.086067 loss_ctc 2.314004 loss_rnnt 1.034119 history loss 1.119067 rank 5
2022-12-08 13:30:04,749 DEBUG CV Batch 31/0 loss 1.162108 loss_att 48.086067 loss_ctc 2.314004 loss_rnnt 1.034119 history loss 1.119067 rank 3
2022-12-08 13:30:04,750 DEBUG CV Batch 31/0 loss 1.162108 loss_att 48.086067 loss_ctc 2.314004 loss_rnnt 1.034119 history loss 1.119067 rank 1
2022-12-08 13:30:04,751 DEBUG CV Batch 31/0 loss 1.162108 loss_att 48.086067 loss_ctc 2.314004 loss_rnnt 1.034119 history loss 1.119067 rank 2
2022-12-08 13:30:04,753 DEBUG CV Batch 31/0 loss 1.162108 loss_att 48.086067 loss_ctc 2.314004 loss_rnnt 1.034119 history loss 1.119067 rank 7
2022-12-08 13:30:04,753 DEBUG CV Batch 31/0 loss 1.162108 loss_att 48.086067 loss_ctc 2.314004 loss_rnnt 1.034119 history loss 1.119067 rank 6
2022-12-08 13:30:15,308 DEBUG CV Batch 31/100 loss 4.407824 loss_att 266.940552 loss_ctc 10.827805 loss_rnnt 3.694492 history loss 2.949494 rank 3
2022-12-08 13:30:15,311 DEBUG CV Batch 31/100 loss 4.407824 loss_att 266.940552 loss_ctc 10.827805 loss_rnnt 3.694492 history loss 2.949494 rank 1
2022-12-08 13:30:15,529 DEBUG CV Batch 31/100 loss 4.407824 loss_att 266.940552 loss_ctc 10.827805 loss_rnnt 3.694492 history loss 2.949494 rank 5
2022-12-08 13:30:15,616 DEBUG CV Batch 31/100 loss 4.407824 loss_att 266.940552 loss_ctc 10.827805 loss_rnnt 3.694492 history loss 2.949494 rank 2
2022-12-08 13:30:15,617 DEBUG CV Batch 31/100 loss 4.407824 loss_att 266.940552 loss_ctc 10.827805 loss_rnnt 3.694492 history loss 2.949494 rank 7
2022-12-08 13:30:15,654 DEBUG CV Batch 31/100 loss 4.407824 loss_att 266.940552 loss_ctc 10.827805 loss_rnnt 3.694492 history loss 2.949494 rank 4
2022-12-08 13:30:15,656 DEBUG CV Batch 31/100 loss 4.407824 loss_att 266.940552 loss_ctc 10.827805 loss_rnnt 3.694492 history loss 2.949494 rank 6
2022-12-08 13:30:15,774 DEBUG CV Batch 31/100 loss 4.407824 loss_att 266.940552 loss_ctc 10.827805 loss_rnnt 3.694492 history loss 2.949494 rank 0
2022-12-08 13:30:28,831 DEBUG CV Batch 31/200 loss 4.031301 loss_att 641.182861 loss_ctc 4.971219 loss_rnnt 3.926866 history loss 3.517151 rank 3
2022-12-08 13:30:28,928 DEBUG CV Batch 31/200 loss 4.031301 loss_att 641.182861 loss_ctc 4.971219 loss_rnnt 3.926866 history loss 3.517151 rank 1
2022-12-08 13:30:29,189 DEBUG CV Batch 31/200 loss 4.031301 loss_att 641.182861 loss_ctc 4.971219 loss_rnnt 3.926866 history loss 3.517151 rank 5
2022-12-08 13:30:29,220 DEBUG CV Batch 31/200 loss 4.031301 loss_att 641.182861 loss_ctc 4.971219 loss_rnnt 3.926866 history loss 3.517151 rank 6
2022-12-08 13:30:29,402 DEBUG CV Batch 31/200 loss 4.031301 loss_att 641.182861 loss_ctc 4.971219 loss_rnnt 3.926866 history loss 3.517151 rank 7
2022-12-08 13:30:29,497 DEBUG CV Batch 31/200 loss 4.031301 loss_att 641.182861 loss_ctc 4.971219 loss_rnnt 3.926866 history loss 3.517151 rank 2
2022-12-08 13:30:29,579 DEBUG CV Batch 31/200 loss 4.031301 loss_att 641.182861 loss_ctc 4.971219 loss_rnnt 3.926866 history loss 3.517151 rank 4
2022-12-08 13:30:29,590 DEBUG CV Batch 31/200 loss 4.031301 loss_att 641.182861 loss_ctc 4.971219 loss_rnnt 3.926866 history loss 3.517151 rank 0
2022-12-08 13:30:40,109 DEBUG CV Batch 31/300 loss 3.322525 loss_att 190.886353 loss_ctc 6.058544 loss_rnnt 3.018523 history loss 3.616742 rank 1
2022-12-08 13:30:40,231 DEBUG CV Batch 31/300 loss 3.322525 loss_att 190.886353 loss_ctc 6.058544 loss_rnnt 3.018523 history loss 3.616742 rank 3
2022-12-08 13:30:40,415 DEBUG CV Batch 31/300 loss 3.322525 loss_att 190.886353 loss_ctc 6.058544 loss_rnnt 3.018523 history loss 3.616742 rank 5
2022-12-08 13:30:40,593 DEBUG CV Batch 31/300 loss 3.322525 loss_att 190.886353 loss_ctc 6.058544 loss_rnnt 3.018523 history loss 3.616742 rank 6
2022-12-08 13:30:40,850 DEBUG CV Batch 31/300 loss 3.322525 loss_att 190.886353 loss_ctc 6.058544 loss_rnnt 3.018523 history loss 3.616742 rank 2
2022-12-08 13:30:41,207 DEBUG CV Batch 31/300 loss 3.322525 loss_att 190.886353 loss_ctc 6.058544 loss_rnnt 3.018523 history loss 3.616742 rank 7
2022-12-08 13:30:41,221 DEBUG CV Batch 31/300 loss 3.322525 loss_att 190.886353 loss_ctc 6.058544 loss_rnnt 3.018523 history loss 3.616742 rank 4
2022-12-08 13:30:41,506 DEBUG CV Batch 31/300 loss 3.322525 loss_att 190.886353 loss_ctc 6.058544 loss_rnnt 3.018523 history loss 3.616742 rank 0
2022-12-08 13:30:51,417 DEBUG CV Batch 31/400 loss 4.158451 loss_att 826.189575 loss_ctc 11.331353 loss_rnnt 3.361462 history loss 4.446968 rank 1
2022-12-08 13:30:51,494 DEBUG CV Batch 31/400 loss 4.158451 loss_att 826.189575 loss_ctc 11.331353 loss_rnnt 3.361462 history loss 4.446968 rank 3
2022-12-08 13:30:51,708 DEBUG CV Batch 31/400 loss 4.158451 loss_att 826.189575 loss_ctc 11.331353 loss_rnnt 3.361462 history loss 4.446968 rank 5
2022-12-08 13:30:51,777 DEBUG CV Batch 31/400 loss 4.158451 loss_att 826.189575 loss_ctc 11.331353 loss_rnnt 3.361462 history loss 4.446968 rank 6
2022-12-08 13:30:52,087 DEBUG CV Batch 31/400 loss 4.158451 loss_att 826.189575 loss_ctc 11.331353 loss_rnnt 3.361462 history loss 4.446968 rank 2
2022-12-08 13:30:52,807 DEBUG CV Batch 31/400 loss 4.158451 loss_att 826.189575 loss_ctc 11.331353 loss_rnnt 3.361462 history loss 4.446968 rank 4
2022-12-08 13:30:52,880 DEBUG CV Batch 31/400 loss 4.158451 loss_att 826.189575 loss_ctc 11.331353 loss_rnnt 3.361462 history loss 4.446968 rank 7
2022-12-08 13:30:53,386 DEBUG CV Batch 31/400 loss 4.158451 loss_att 826.189575 loss_ctc 11.331353 loss_rnnt 3.361462 history loss 4.446968 rank 0
2022-12-08 13:31:01,410 DEBUG CV Batch 31/500 loss 6.026438 loss_att 266.656250 loss_ctc 7.586904 loss_rnnt 5.853053 history loss 5.035556 rank 1
2022-12-08 13:31:01,636 DEBUG CV Batch 31/500 loss 6.026438 loss_att 266.656250 loss_ctc 7.586904 loss_rnnt 5.853053 history loss 5.035556 rank 3
2022-12-08 13:31:01,786 DEBUG CV Batch 31/500 loss 6.026438 loss_att 266.656250 loss_ctc 7.586904 loss_rnnt 5.853053 history loss 5.035556 rank 5
2022-12-08 13:31:02,065 DEBUG CV Batch 31/500 loss 6.026438 loss_att 266.656250 loss_ctc 7.586904 loss_rnnt 5.853053 history loss 5.035556 rank 2
2022-12-08 13:31:02,234 DEBUG CV Batch 31/500 loss 6.026438 loss_att 266.656250 loss_ctc 7.586904 loss_rnnt 5.853053 history loss 5.035556 rank 6
2022-12-08 13:31:02,911 DEBUG CV Batch 31/500 loss 6.026438 loss_att 266.656250 loss_ctc 7.586904 loss_rnnt 5.853053 history loss 5.035556 rank 4
2022-12-08 13:31:03,138 DEBUG CV Batch 31/500 loss 6.026438 loss_att 266.656250 loss_ctc 7.586904 loss_rnnt 5.853053 history loss 5.035556 rank 7
2022-12-08 13:31:03,820 DEBUG CV Batch 31/500 loss 6.026438 loss_att 266.656250 loss_ctc 7.586904 loss_rnnt 5.853053 history loss 5.035556 rank 0
2022-12-08 13:31:14,196 DEBUG CV Batch 31/600 loss 6.005819 loss_att 104.306877 loss_ctc 9.314353 loss_rnnt 5.638204 history loss 5.850794 rank 3
2022-12-08 13:31:14,241 DEBUG CV Batch 31/600 loss 6.005819 loss_att 104.306877 loss_ctc 9.314353 loss_rnnt 5.638204 history loss 5.850794 rank 1
2022-12-08 13:31:14,384 DEBUG CV Batch 31/600 loss 6.005819 loss_att 104.306877 loss_ctc 9.314353 loss_rnnt 5.638204 history loss 5.850794 rank 5
2022-12-08 13:31:14,593 DEBUG CV Batch 31/600 loss 6.005819 loss_att 104.306877 loss_ctc 9.314353 loss_rnnt 5.638204 history loss 5.850794 rank 4
2022-12-08 13:31:14,951 DEBUG CV Batch 31/600 loss 6.005819 loss_att 104.306877 loss_ctc 9.314353 loss_rnnt 5.638204 history loss 5.850794 rank 7
2022-12-08 13:31:15,200 DEBUG CV Batch 31/600 loss 6.005819 loss_att 104.306877 loss_ctc 9.314353 loss_rnnt 5.638204 history loss 5.850794 rank 6
2022-12-08 13:31:15,209 DEBUG CV Batch 31/600 loss 6.005819 loss_att 104.306877 loss_ctc 9.314353 loss_rnnt 5.638204 history loss 5.850794 rank 2
2022-12-08 13:31:15,780 DEBUG CV Batch 31/600 loss 6.005819 loss_att 104.306877 loss_ctc 9.314353 loss_rnnt 5.638204 history loss 5.850794 rank 0
2022-12-08 13:31:25,828 DEBUG CV Batch 31/700 loss 3.702604 loss_att 707.029541 loss_ctc 17.183167 loss_rnnt 2.204763 history loss 6.422220 rank 1
2022-12-08 13:31:26,029 DEBUG CV Batch 31/700 loss 3.702604 loss_att 707.029541 loss_ctc 17.183167 loss_rnnt 2.204763 history loss 6.422220 rank 3
2022-12-08 13:31:26,094 DEBUG CV Batch 31/700 loss 3.702604 loss_att 707.029541 loss_ctc 17.183167 loss_rnnt 2.204763 history loss 6.422220 rank 4
2022-12-08 13:31:26,172 DEBUG CV Batch 31/700 loss 3.702604 loss_att 707.029541 loss_ctc 17.183167 loss_rnnt 2.204763 history loss 6.422220 rank 7
2022-12-08 13:31:26,325 DEBUG CV Batch 31/700 loss 3.702604 loss_att 707.029541 loss_ctc 17.183167 loss_rnnt 2.204763 history loss 6.422220 rank 5
2022-12-08 13:31:27,014 DEBUG CV Batch 31/700 loss 3.702604 loss_att 707.029541 loss_ctc 17.183167 loss_rnnt 2.204763 history loss 6.422220 rank 0
2022-12-08 13:31:27,342 DEBUG CV Batch 31/700 loss 3.702604 loss_att 707.029541 loss_ctc 17.183167 loss_rnnt 2.204763 history loss 6.422220 rank 2
2022-12-08 13:31:27,475 DEBUG CV Batch 31/700 loss 3.702604 loss_att 707.029541 loss_ctc 17.183167 loss_rnnt 2.204763 history loss 6.422220 rank 6
2022-12-08 13:31:37,562 DEBUG CV Batch 31/800 loss 7.792636 loss_att 263.400818 loss_ctc 16.824448 loss_rnnt 6.789102 history loss 5.957669 rank 1
2022-12-08 13:31:37,713 DEBUG CV Batch 31/800 loss 7.792636 loss_att 263.400818 loss_ctc 16.824448 loss_rnnt 6.789102 history loss 5.957669 rank 4
2022-12-08 13:31:37,762 DEBUG CV Batch 31/800 loss 7.792636 loss_att 263.400818 loss_ctc 16.824448 loss_rnnt 6.789102 history loss 5.957669 rank 3
2022-12-08 13:31:37,897 DEBUG CV Batch 31/800 loss 7.792636 loss_att 263.400818 loss_ctc 16.824448 loss_rnnt 6.789102 history loss 5.957669 rank 7
2022-12-08 13:31:38,033 DEBUG CV Batch 31/800 loss 7.792636 loss_att 263.400818 loss_ctc 16.824448 loss_rnnt 6.789102 history loss 5.957669 rank 5
2022-12-08 13:31:38,199 DEBUG CV Batch 31/800 loss 7.792636 loss_att 263.400818 loss_ctc 16.824448 loss_rnnt 6.789102 history loss 5.957669 rank 0
2022-12-08 13:31:39,213 DEBUG CV Batch 31/800 loss 7.792636 loss_att 263.400818 loss_ctc 16.824448 loss_rnnt 6.789102 history loss 5.957669 rank 2
2022-12-08 13:31:39,706 DEBUG CV Batch 31/800 loss 7.792636 loss_att 263.400818 loss_ctc 16.824448 loss_rnnt 6.789102 history loss 5.957669 rank 6
2022-12-08 13:31:51,047 DEBUG CV Batch 31/900 loss 10.927955 loss_att 550.850098 loss_ctc 20.500643 loss_rnnt 9.864324 history loss 5.801101 rank 1
2022-12-08 13:31:51,303 DEBUG CV Batch 31/900 loss 10.927955 loss_att 550.850098 loss_ctc 20.500643 loss_rnnt 9.864324 history loss 5.801101 rank 4
2022-12-08 13:31:51,335 DEBUG CV Batch 31/900 loss 10.927955 loss_att 550.850098 loss_ctc 20.500643 loss_rnnt 9.864324 history loss 5.801101 rank 3
2022-12-08 13:31:51,438 DEBUG CV Batch 31/900 loss 10.927955 loss_att 550.850098 loss_ctc 20.500643 loss_rnnt 9.864324 history loss 5.801101 rank 5
2022-12-08 13:31:51,463 DEBUG CV Batch 31/900 loss 10.927955 loss_att 550.850098 loss_ctc 20.500643 loss_rnnt 9.864324 history loss 5.801101 rank 0
2022-12-08 13:31:51,599 DEBUG CV Batch 31/900 loss 10.927955 loss_att 550.850098 loss_ctc 20.500643 loss_rnnt 9.864324 history loss 5.801101 rank 7
2022-12-08 13:31:52,846 DEBUG CV Batch 31/900 loss 10.927955 loss_att 550.850098 loss_ctc 20.500643 loss_rnnt 9.864324 history loss 5.801101 rank 2
2022-12-08 13:31:53,463 DEBUG CV Batch 31/900 loss 10.927955 loss_att 550.850098 loss_ctc 20.500643 loss_rnnt 9.864324 history loss 5.801101 rank 6
2022-12-08 13:32:02,348 DEBUG CV Batch 31/1000 loss 2.009309 loss_att 176.486603 loss_ctc 5.343640 loss_rnnt 1.638828 history loss 5.595632 rank 1
2022-12-08 13:32:02,812 DEBUG CV Batch 31/1000 loss 2.009309 loss_att 176.486603 loss_ctc 5.343640 loss_rnnt 1.638828 history loss 5.595632 rank 3
2022-12-08 13:32:02,972 DEBUG CV Batch 31/1000 loss 2.009309 loss_att 176.486603 loss_ctc 5.343640 loss_rnnt 1.638828 history loss 5.595632 rank 5
2022-12-08 13:32:03,077 DEBUG CV Batch 31/1000 loss 2.009309 loss_att 176.486603 loss_ctc 5.343640 loss_rnnt 1.638828 history loss 5.595632 rank 4
2022-12-08 13:32:03,518 DEBUG CV Batch 31/1000 loss 2.009309 loss_att 176.486603 loss_ctc 5.343640 loss_rnnt 1.638828 history loss 5.595632 rank 0
2022-12-08 13:32:03,535 DEBUG CV Batch 31/1000 loss 2.009309 loss_att 176.486603 loss_ctc 5.343640 loss_rnnt 1.638828 history loss 5.595632 rank 7
2022-12-08 13:32:04,306 DEBUG CV Batch 31/1000 loss 2.009309 loss_att 176.486603 loss_ctc 5.343640 loss_rnnt 1.638828 history loss 5.595632 rank 2
2022-12-08 13:32:05,260 DEBUG CV Batch 31/1000 loss 2.009309 loss_att 176.486603 loss_ctc 5.343640 loss_rnnt 1.638828 history loss 5.595632 rank 6
2022-12-08 13:32:13,403 DEBUG CV Batch 31/1100 loss 4.214695 loss_att 60.693798 loss_ctc 8.022058 loss_rnnt 3.791654 history loss 5.575565 rank 1
2022-12-08 13:32:13,964 DEBUG CV Batch 31/1100 loss 4.214695 loss_att 60.693798 loss_ctc 8.022058 loss_rnnt 3.791654 history loss 5.575565 rank 3
2022-12-08 13:32:14,197 DEBUG CV Batch 31/1100 loss 4.214695 loss_att 60.693798 loss_ctc 8.022058 loss_rnnt 3.791654 history loss 5.575565 rank 5
2022-12-08 13:32:14,511 DEBUG CV Batch 31/1100 loss 4.214695 loss_att 60.693798 loss_ctc 8.022058 loss_rnnt 3.791654 history loss 5.575565 rank 4
2022-12-08 13:32:15,161 DEBUG CV Batch 31/1100 loss 4.214695 loss_att 60.693798 loss_ctc 8.022058 loss_rnnt 3.791654 history loss 5.575565 rank 7
2022-12-08 13:32:15,277 DEBUG CV Batch 31/1100 loss 4.214695 loss_att 60.693798 loss_ctc 8.022058 loss_rnnt 3.791654 history loss 5.575565 rank 0
2022-12-08 13:32:15,482 DEBUG CV Batch 31/1100 loss 4.214695 loss_att 60.693798 loss_ctc 8.022058 loss_rnnt 3.791654 history loss 5.575565 rank 2
2022-12-08 13:32:16,498 DEBUG CV Batch 31/1100 loss 4.214695 loss_att 60.693798 loss_ctc 8.022058 loss_rnnt 3.791654 history loss 5.575565 rank 6
2022-12-08 13:32:23,720 DEBUG CV Batch 31/1200 loss 7.805926 loss_att 280.457489 loss_ctc 10.492436 loss_rnnt 7.507425 history loss 5.842764 rank 1
2022-12-08 13:32:24,004 DEBUG CV Batch 31/1200 loss 7.805926 loss_att 280.457489 loss_ctc 10.492436 loss_rnnt 7.507425 history loss 5.842764 rank 3
2022-12-08 13:32:24,443 DEBUG CV Batch 31/1200 loss 7.805926 loss_att 280.457489 loss_ctc 10.492436 loss_rnnt 7.507425 history loss 5.842764 rank 5
2022-12-08 13:32:24,468 DEBUG CV Batch 31/1200 loss 7.805926 loss_att 280.457489 loss_ctc 10.492436 loss_rnnt 7.507425 history loss 5.842764 rank 4
2022-12-08 13:32:25,502 DEBUG CV Batch 31/1200 loss 7.805926 loss_att 280.457489 loss_ctc 10.492436 loss_rnnt 7.507425 history loss 5.842764 rank 7
2022-12-08 13:32:25,619 DEBUG CV Batch 31/1200 loss 7.805926 loss_att 280.457489 loss_ctc 10.492436 loss_rnnt 7.507425 history loss 5.842764 rank 0
2022-12-08 13:32:26,145 DEBUG CV Batch 31/1200 loss 7.805926 loss_att 280.457489 loss_ctc 10.492436 loss_rnnt 7.507425 history loss 5.842764 rank 2
2022-12-08 13:32:26,772 DEBUG CV Batch 31/1200 loss 7.805926 loss_att 280.457489 loss_ctc 10.492436 loss_rnnt 7.507425 history loss 5.842764 rank 6
2022-12-08 13:32:35,217 DEBUG CV Batch 31/1300 loss 3.845166 loss_att 105.975723 loss_ctc 6.700155 loss_rnnt 3.527945 history loss 6.103582 rank 1
2022-12-08 13:32:35,574 DEBUG CV Batch 31/1300 loss 3.845166 loss_att 105.975723 loss_ctc 6.700155 loss_rnnt 3.527945 history loss 6.103582 rank 3
2022-12-08 13:32:36,060 DEBUG CV Batch 31/1300 loss 3.845166 loss_att 105.975723 loss_ctc 6.700155 loss_rnnt 3.527945 history loss 6.103582 rank 4
2022-12-08 13:32:36,430 DEBUG CV Batch 31/1300 loss 3.845166 loss_att 105.975723 loss_ctc 6.700155 loss_rnnt 3.527945 history loss 6.103582 rank 5
2022-12-08 13:32:37,330 DEBUG CV Batch 31/1300 loss 3.845166 loss_att 105.975723 loss_ctc 6.700155 loss_rnnt 3.527945 history loss 6.103582 rank 7
2022-12-08 13:32:37,368 DEBUG CV Batch 31/1300 loss 3.845166 loss_att 105.975723 loss_ctc 6.700155 loss_rnnt 3.527945 history loss 6.103582 rank 0
2022-12-08 13:32:38,294 DEBUG CV Batch 31/1300 loss 3.845166 loss_att 105.975723 loss_ctc 6.700155 loss_rnnt 3.527945 history loss 6.103582 rank 2
2022-12-08 13:32:39,099 DEBUG CV Batch 31/1300 loss 3.845166 loss_att 105.975723 loss_ctc 6.700155 loss_rnnt 3.527945 history loss 6.103582 rank 6
2022-12-08 13:32:47,419 DEBUG CV Batch 31/1400 loss 4.296857 loss_att 562.091309 loss_ctc 6.816186 loss_rnnt 4.016932 history loss 6.392196 rank 1
2022-12-08 13:32:47,553 DEBUG CV Batch 31/1400 loss 4.296857 loss_att 562.091309 loss_ctc 6.816186 loss_rnnt 4.016932 history loss 6.392196 rank 4
2022-12-08 13:32:47,639 DEBUG CV Batch 31/1400 loss 4.296857 loss_att 562.091309 loss_ctc 6.816186 loss_rnnt 4.016932 history loss 6.392196 rank 3
2022-12-08 13:32:48,283 DEBUG CV Batch 31/1400 loss 4.296857 loss_att 562.091309 loss_ctc 6.816186 loss_rnnt 4.016932 history loss 6.392196 rank 5
2022-12-08 13:32:48,291 DEBUG CV Batch 31/1400 loss 4.296857 loss_att 562.091309 loss_ctc 6.816186 loss_rnnt 4.016932 history loss 6.392196 rank 7
2022-12-08 13:32:48,683 DEBUG CV Batch 31/1400 loss 4.296857 loss_att 562.091309 loss_ctc 6.816186 loss_rnnt 4.016932 history loss 6.392196 rank 0
2022-12-08 13:32:50,541 DEBUG CV Batch 31/1400 loss 4.296857 loss_att 562.091309 loss_ctc 6.816186 loss_rnnt 4.016932 history loss 6.392196 rank 2
2022-12-08 13:32:51,437 DEBUG CV Batch 31/1400 loss 4.296857 loss_att 562.091309 loss_ctc 6.816186 loss_rnnt 4.016932 history loss 6.392196 rank 6
2022-12-08 13:32:59,645 DEBUG CV Batch 31/1500 loss 7.112833 loss_att 275.485596 loss_ctc 7.219309 loss_rnnt 7.101002 history loss 6.270947 rank 4
2022-12-08 13:32:59,820 DEBUG CV Batch 31/1500 loss 7.112833 loss_att 275.485596 loss_ctc 7.219309 loss_rnnt 7.101002 history loss 6.270947 rank 1
2022-12-08 13:32:59,824 DEBUG CV Batch 31/1500 loss 7.112833 loss_att 275.485596 loss_ctc 7.219309 loss_rnnt 7.101002 history loss 6.270947 rank 3
2022-12-08 13:32:59,968 DEBUG CV Batch 31/1500 loss 7.112833 loss_att 275.485596 loss_ctc 7.219309 loss_rnnt 7.101002 history loss 6.270947 rank 0
2022-12-08 13:33:00,215 DEBUG CV Batch 31/1500 loss 7.112833 loss_att 275.485596 loss_ctc 7.219309 loss_rnnt 7.101002 history loss 6.270947 rank 7
2022-12-08 13:33:00,818 DEBUG CV Batch 31/1500 loss 7.112833 loss_att 275.485596 loss_ctc 7.219309 loss_rnnt 7.101002 history loss 6.270947 rank 5
2022-12-08 13:33:03,332 DEBUG CV Batch 31/1500 loss 7.112833 loss_att 275.485596 loss_ctc 7.219309 loss_rnnt 7.101002 history loss 6.270947 rank 2
2022-12-08 13:33:03,921 DEBUG CV Batch 31/1500 loss 7.112833 loss_att 275.485596 loss_ctc 7.219309 loss_rnnt 7.101002 history loss 6.270947 rank 6
2022-12-08 13:33:12,919 DEBUG CV Batch 31/1600 loss 8.921549 loss_att 593.917664 loss_ctc 13.506189 loss_rnnt 8.412145 history loss 6.238685 rank 4
2022-12-08 13:33:12,944 DEBUG CV Batch 31/1600 loss 8.921549 loss_att 593.917664 loss_ctc 13.506189 loss_rnnt 8.412145 history loss 6.238685 rank 3
2022-12-08 13:33:12,984 DEBUG CV Batch 31/1600 loss 8.921549 loss_att 593.917664 loss_ctc 13.506189 loss_rnnt 8.412145 history loss 6.238685 rank 1
2022-12-08 13:33:13,138 DEBUG CV Batch 31/1600 loss 8.921549 loss_att 593.917664 loss_ctc 13.506189 loss_rnnt 8.412145 history loss 6.238685 rank 0
2022-12-08 13:33:13,643 DEBUG CV Batch 31/1600 loss 8.921549 loss_att 593.917664 loss_ctc 13.506189 loss_rnnt 8.412145 history loss 6.238685 rank 7
2022-12-08 13:33:14,034 DEBUG CV Batch 31/1600 loss 8.921549 loss_att 593.917664 loss_ctc 13.506189 loss_rnnt 8.412145 history loss 6.238685 rank 5
2022-12-08 13:33:16,701 DEBUG CV Batch 31/1600 loss 8.921549 loss_att 593.917664 loss_ctc 13.506189 loss_rnnt 8.412145 history loss 6.238685 rank 2
2022-12-08 13:33:17,458 DEBUG CV Batch 31/1600 loss 8.921549 loss_att 593.917664 loss_ctc 13.506189 loss_rnnt 8.412145 history loss 6.238685 rank 6
2022-12-08 13:33:24,633 DEBUG CV Batch 31/1700 loss 6.006931 loss_att 210.843765 loss_ctc 14.016077 loss_rnnt 5.117026 history loss 6.172830 rank 1
2022-12-08 13:33:24,731 DEBUG CV Batch 31/1700 loss 6.006931 loss_att 210.843765 loss_ctc 14.016077 loss_rnnt 5.117026 history loss 6.172830 rank 3
2022-12-08 13:33:25,057 DEBUG CV Batch 31/1700 loss 6.006931 loss_att 210.843765 loss_ctc 14.016077 loss_rnnt 5.117026 history loss 6.172830 rank 4
2022-12-08 13:33:25,481 DEBUG CV Batch 31/1700 loss 6.006931 loss_att 210.843765 loss_ctc 14.016077 loss_rnnt 5.117026 history loss 6.172830 rank 0
2022-12-08 13:33:25,758 DEBUG CV Batch 31/1700 loss 6.006931 loss_att 210.843765 loss_ctc 14.016077 loss_rnnt 5.117026 history loss 6.172830 rank 5
2022-12-08 13:33:25,979 DEBUG CV Batch 31/1700 loss 6.006931 loss_att 210.843765 loss_ctc 14.016077 loss_rnnt 5.117026 history loss 6.172830 rank 7
2022-12-08 13:33:28,550 DEBUG CV Batch 31/1700 loss 6.006931 loss_att 210.843765 loss_ctc 14.016077 loss_rnnt 5.117026 history loss 6.172830 rank 2
2022-12-08 13:33:29,412 DEBUG CV Batch 31/1700 loss 6.006931 loss_att 210.843765 loss_ctc 14.016077 loss_rnnt 5.117026 history loss 6.172830 rank 6
2022-12-08 13:33:33,563 INFO Epoch 31 CV info cv_loss 6.155401749704112
2022-12-08 13:33:33,564 INFO Epoch 32 TRAIN info lr 0.00024249796945175416
2022-12-08 13:33:33,569 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 13:33:33,744 INFO Epoch 31 CV info cv_loss 6.155401749704112
2022-12-08 13:33:33,744 INFO Epoch 32 TRAIN info lr 0.00024245833593276454
2022-12-08 13:33:33,749 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 13:33:33,849 INFO Epoch 31 CV info cv_loss 6.155401749704112
2022-12-08 13:33:33,850 INFO Epoch 32 TRAIN info lr 0.00024247715230281598
2022-12-08 13:33:33,851 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 13:33:34,524 INFO Epoch 31 CV info cv_loss 6.155401749704112
2022-12-08 13:33:34,525 INFO Checkpoint: save to checkpoint exp/1204_encoder_bias_nobi_noatt/31.pt
2022-12-08 13:33:34,624 INFO Epoch 31 CV info cv_loss 6.155401749704112
2022-12-08 13:33:34,624 INFO Epoch 32 TRAIN info lr 0.00024249112486599857
2022-12-08 13:33:34,626 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 13:33:34,840 INFO Epoch 31 CV info cv_loss 6.155401749704112
2022-12-08 13:33:34,840 INFO Epoch 32 TRAIN info lr 0.0002424626119958522
2022-12-08 13:33:34,842 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 13:33:35,592 INFO Epoch 32 TRAIN info lr 0.00024245577040350342
2022-12-08 13:33:35,595 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 13:33:37,472 INFO Epoch 31 CV info cv_loss 6.155401749704112
2022-12-08 13:33:37,472 INFO Epoch 32 TRAIN info lr 0.00024248684729420383
2022-12-08 13:33:37,474 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 13:33:38,233 INFO Epoch 31 CV info cv_loss 6.155401749704112
2022-12-08 13:33:38,233 INFO Epoch 32 TRAIN info lr 0.00024249283595810243
2022-12-08 13:33:38,235 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 13:34:38,150 DEBUG TRAIN Batch 32/0 loss 8.020577 loss_att 63.808182 loss_ctc 11.534231 loss_rnnt 7.630172 lr 0.00024246 rank 7
2022-12-08 13:34:38,150 DEBUG TRAIN Batch 32/0 loss 8.025690 loss_att 68.514076 loss_ctc 13.767507 loss_rnnt 7.387711 lr 0.00024246 rank 4
2022-12-08 13:34:38,155 DEBUG TRAIN Batch 32/0 loss 7.884482 loss_att 76.583481 loss_ctc 12.649133 loss_rnnt 7.355077 lr 0.00024248 rank 3
2022-12-08 13:34:38,156 DEBUG TRAIN Batch 32/0 loss 8.180198 loss_att 68.736923 loss_ctc 12.509809 loss_rnnt 7.699130 lr 0.00024246 rank 0
2022-12-08 13:34:38,161 DEBUG TRAIN Batch 32/0 loss 6.458315 loss_att 70.846115 loss_ctc 11.483418 loss_rnnt 5.899970 lr 0.00024249 rank 5
2022-12-08 13:34:38,170 DEBUG TRAIN Batch 32/0 loss 6.031263 loss_att 66.914932 loss_ctc 9.215476 loss_rnnt 5.677462 lr 0.00024249 rank 6
2022-12-08 13:34:38,174 DEBUG TRAIN Batch 32/0 loss 9.571531 loss_att 70.975677 loss_ctc 14.304293 loss_rnnt 9.045669 lr 0.00024250 rank 1
2022-12-08 13:34:38,197 DEBUG TRAIN Batch 32/0 loss 7.675623 loss_att 70.558182 loss_ctc 12.208322 loss_rnnt 7.171990 lr 0.00024249 rank 2
2022-12-08 13:35:40,397 DEBUG TRAIN Batch 32/100 loss 4.691237 loss_att 382.869080 loss_ctc 6.114353 loss_rnnt 4.533113 lr 0.00024246 rank 2
2022-12-08 13:35:40,397 DEBUG TRAIN Batch 32/100 loss 2.618196 loss_att 445.809570 loss_ctc 8.825278 loss_rnnt 1.928520 lr 0.00024243 rank 0
2022-12-08 13:35:40,399 DEBUG TRAIN Batch 32/100 loss 3.826110 loss_att 366.758484 loss_ctc 11.162130 loss_rnnt 3.010996 lr 0.00024243 rank 4
2022-12-08 13:35:40,399 DEBUG TRAIN Batch 32/100 loss 11.787810 loss_att 349.512878 loss_ctc 17.564796 loss_rnnt 11.145924 lr 0.00024243 rank 7
2022-12-08 13:35:40,399 DEBUG TRAIN Batch 32/100 loss 6.392020 loss_att 395.847015 loss_ctc 13.827202 loss_rnnt 5.565889 lr 0.00024246 rank 6
2022-12-08 13:35:40,401 DEBUG TRAIN Batch 32/100 loss 4.791892 loss_att 390.102600 loss_ctc 9.302538 loss_rnnt 4.290709 lr 0.00024247 rank 1
2022-12-08 13:35:40,401 DEBUG TRAIN Batch 32/100 loss 7.360639 loss_att 335.210175 loss_ctc 21.664478 loss_rnnt 5.771323 lr 0.00024246 rank 5
2022-12-08 13:35:40,445 DEBUG TRAIN Batch 32/100 loss 2.725142 loss_att 370.024017 loss_ctc 7.075101 loss_rnnt 2.241813 lr 0.00024245 rank 3
2022-12-08 13:36:42,999 DEBUG TRAIN Batch 32/200 loss 3.534554 loss_att 360.367310 loss_ctc 8.204636 loss_rnnt 3.015656 lr 0.00024241 rank 7
2022-12-08 13:36:43,004 DEBUG TRAIN Batch 32/200 loss 5.134883 loss_att 341.032227 loss_ctc 15.815590 loss_rnnt 3.948138 lr 0.00024243 rank 2
2022-12-08 13:36:43,005 DEBUG TRAIN Batch 32/200 loss 3.789277 loss_att 336.016602 loss_ctc 15.725276 loss_rnnt 2.463055 lr 0.00024240 rank 4
2022-12-08 13:36:43,005 DEBUG TRAIN Batch 32/200 loss 7.548429 loss_att 444.688599 loss_ctc 10.941801 loss_rnnt 7.171388 lr 0.00024244 rank 1
2022-12-08 13:36:43,006 DEBUG TRAIN Batch 32/200 loss 1.882419 loss_att 378.430847 loss_ctc 7.216083 loss_rnnt 1.289790 lr 0.00024242 rank 3
2022-12-08 13:36:43,009 DEBUG TRAIN Batch 32/200 loss 5.026583 loss_att 328.592590 loss_ctc 10.207306 loss_rnnt 4.450948 lr 0.00024244 rank 6
2022-12-08 13:36:43,010 DEBUG TRAIN Batch 32/200 loss 4.246591 loss_att 335.770508 loss_ctc 7.122266 loss_rnnt 3.927072 lr 0.00024240 rank 0
2022-12-08 13:36:43,010 DEBUG TRAIN Batch 32/200 loss 6.065224 loss_att 336.913879 loss_ctc 15.858328 loss_rnnt 4.977101 lr 0.00024243 rank 5
2022-12-08 13:37:47,271 DEBUG TRAIN Batch 32/300 loss 3.211848 loss_att 365.890198 loss_ctc 7.950716 loss_rnnt 2.685308 lr 0.00024241 rank 6
2022-12-08 13:37:47,282 DEBUG TRAIN Batch 32/300 loss 7.002815 loss_att 303.839569 loss_ctc 12.046932 loss_rnnt 6.442358 lr 0.00024238 rank 7
2022-12-08 13:37:47,283 DEBUG TRAIN Batch 32/300 loss 4.659464 loss_att 394.019135 loss_ctc 15.274845 loss_rnnt 3.479977 lr 0.00024237 rank 4
2022-12-08 13:37:47,285 DEBUG TRAIN Batch 32/300 loss 9.191089 loss_att 368.214874 loss_ctc 18.483181 loss_rnnt 8.158634 lr 0.00024241 rank 5
2022-12-08 13:37:47,290 DEBUG TRAIN Batch 32/300 loss 14.093586 loss_att 407.047760 loss_ctc 24.034710 loss_rnnt 12.989017 lr 0.00024239 rank 3
2022-12-08 13:37:47,291 DEBUG TRAIN Batch 32/300 loss 4.596293 loss_att 381.342102 loss_ctc 10.323232 loss_rnnt 3.959967 lr 0.00024241 rank 1
2022-12-08 13:37:47,296 DEBUG TRAIN Batch 32/300 loss 14.743347 loss_att 385.327606 loss_ctc 24.907536 loss_rnnt 13.613993 lr 0.00024240 rank 2
2022-12-08 13:37:47,305 DEBUG TRAIN Batch 32/300 loss 4.340624 loss_att 333.396149 loss_ctc 9.799583 loss_rnnt 3.734073 lr 0.00024237 rank 0
2022-12-08 13:38:56,969 DEBUG TRAIN Batch 32/400 loss 9.496367 loss_att 315.921997 loss_ctc 15.930570 loss_rnnt 8.781456 lr 0.00024235 rank 7
2022-12-08 13:38:56,974 DEBUG TRAIN Batch 32/400 loss 5.959180 loss_att 337.326782 loss_ctc 12.087725 loss_rnnt 5.278231 lr 0.00024234 rank 4
2022-12-08 13:38:56,976 DEBUG TRAIN Batch 32/400 loss 5.939472 loss_att 331.609863 loss_ctc 10.707525 loss_rnnt 5.409688 lr 0.00024238 rank 6
2022-12-08 13:38:56,977 DEBUG TRAIN Batch 32/400 loss 9.739278 loss_att 403.315125 loss_ctc 15.705311 loss_rnnt 9.076385 lr 0.00024236 rank 3
2022-12-08 13:38:56,977 DEBUG TRAIN Batch 32/400 loss 6.631345 loss_att 358.753418 loss_ctc 13.756392 loss_rnnt 5.839673 lr 0.00024237 rank 2
2022-12-08 13:38:56,978 DEBUG TRAIN Batch 32/400 loss 8.034163 loss_att 377.766754 loss_ctc 16.312687 loss_rnnt 7.114326 lr 0.00024238 rank 5
2022-12-08 13:38:56,979 DEBUG TRAIN Batch 32/400 loss 9.236432 loss_att 410.335266 loss_ctc 16.762459 loss_rnnt 8.400207 lr 0.00024234 rank 0
2022-12-08 13:38:56,982 DEBUG TRAIN Batch 32/400 loss 9.350851 loss_att 341.050018 loss_ctc 18.686764 loss_rnnt 8.313528 lr 0.00024238 rank 1
2022-12-08 13:40:00,142 DEBUG TRAIN Batch 32/500 loss 6.748476 loss_att 384.930359 loss_ctc 18.097952 loss_rnnt 5.487423 lr 0.00024233 rank 3
2022-12-08 13:40:00,142 DEBUG TRAIN Batch 32/500 loss 8.055226 loss_att 341.984375 loss_ctc 11.301724 loss_rnnt 7.694504 lr 0.00024235 rank 6
2022-12-08 13:40:00,143 DEBUG TRAIN Batch 32/500 loss 5.946491 loss_att 323.775787 loss_ctc 8.837212 loss_rnnt 5.625299 lr 0.00024232 rank 4
2022-12-08 13:40:00,146 DEBUG TRAIN Batch 32/500 loss 10.818620 loss_att 350.361298 loss_ctc 22.615211 loss_rnnt 9.507887 lr 0.00024234 rank 2
2022-12-08 13:40:00,150 DEBUG TRAIN Batch 32/500 loss 8.851864 loss_att 291.293549 loss_ctc 16.403984 loss_rnnt 8.012740 lr 0.00024236 rank 1
2022-12-08 13:40:00,150 DEBUG TRAIN Batch 32/500 loss 6.517216 loss_att 348.857544 loss_ctc 17.176754 loss_rnnt 5.332823 lr 0.00024235 rank 5
2022-12-08 13:40:00,159 DEBUG TRAIN Batch 32/500 loss 6.626617 loss_att 291.048737 loss_ctc 14.268438 loss_rnnt 5.777526 lr 0.00024232 rank 7
2022-12-08 13:40:00,168 DEBUG TRAIN Batch 32/500 loss 13.436225 loss_att 372.345978 loss_ctc 23.744886 loss_rnnt 12.290818 lr 0.00024231 rank 0
2022-12-08 13:41:03,391 DEBUG TRAIN Batch 32/600 loss 9.854434 loss_att 256.514252 loss_ctc 14.992412 loss_rnnt 9.283548 lr 0.00024229 rank 4
2022-12-08 13:41:03,395 DEBUG TRAIN Batch 32/600 loss 12.956472 loss_att 229.549225 loss_ctc 25.997334 loss_rnnt 11.507488 lr 0.00024232 rank 6
2022-12-08 13:41:03,395 DEBUG TRAIN Batch 32/600 loss 4.500839 loss_att 256.445770 loss_ctc 11.678775 loss_rnnt 3.703290 lr 0.00024232 rank 2
2022-12-08 13:41:03,397 DEBUG TRAIN Batch 32/600 loss 7.048069 loss_att 152.674744 loss_ctc 16.695898 loss_rnnt 5.976089 lr 0.00024233 rank 1
2022-12-08 13:41:03,398 DEBUG TRAIN Batch 32/600 loss 11.153303 loss_att 154.812515 loss_ctc 19.601507 loss_rnnt 10.214614 lr 0.00024229 rank 7
2022-12-08 13:41:03,400 DEBUG TRAIN Batch 32/600 loss 6.898582 loss_att 187.236771 loss_ctc 14.098030 loss_rnnt 6.098643 lr 0.00024228 rank 0
2022-12-08 13:41:03,405 DEBUG TRAIN Batch 32/600 loss 5.214368 loss_att 283.242035 loss_ctc 12.154922 loss_rnnt 4.443195 lr 0.00024231 rank 3
2022-12-08 13:41:03,409 DEBUG TRAIN Batch 32/600 loss 7.757886 loss_att 266.179077 loss_ctc 16.124067 loss_rnnt 6.828311 lr 0.00024232 rank 5
2022-12-08 13:42:09,544 DEBUG TRAIN Batch 32/700 loss 5.386090 loss_att 467.212036 loss_ctc 14.138628 loss_rnnt 4.413586 lr 0.00024226 rank 4
2022-12-08 13:42:09,553 DEBUG TRAIN Batch 32/700 loss 9.568032 loss_att 405.482483 loss_ctc 14.029968 loss_rnnt 9.072262 lr 0.00024226 rank 7
2022-12-08 13:42:09,557 DEBUG TRAIN Batch 32/700 loss 6.595217 loss_att 386.240662 loss_ctc 11.336683 loss_rnnt 6.068388 lr 0.00024229 rank 6
2022-12-08 13:42:09,558 DEBUG TRAIN Batch 32/700 loss 5.690250 loss_att 370.790161 loss_ctc 12.636584 loss_rnnt 4.918436 lr 0.00024229 rank 5
2022-12-08 13:42:09,564 DEBUG TRAIN Batch 32/700 loss 8.553397 loss_att 369.661560 loss_ctc 12.688108 loss_rnnt 8.093985 lr 0.00024228 rank 3
2022-12-08 13:42:09,565 DEBUG TRAIN Batch 32/700 loss 8.165323 loss_att 479.777924 loss_ctc 22.220320 loss_rnnt 6.603657 lr 0.00024229 rank 2
2022-12-08 13:42:09,568 DEBUG TRAIN Batch 32/700 loss 8.378510 loss_att 419.577515 loss_ctc 17.679043 loss_rnnt 7.345118 lr 0.00024226 rank 0
2022-12-08 13:42:09,602 DEBUG TRAIN Batch 32/700 loss 11.515171 loss_att 429.374023 loss_ctc 18.114731 loss_rnnt 10.781887 lr 0.00024230 rank 1
2022-12-08 13:43:19,064 DEBUG TRAIN Batch 32/800 loss 7.059631 loss_att 462.292328 loss_ctc 14.223475 loss_rnnt 6.263649 lr 0.00024223 rank 4
2022-12-08 13:43:19,066 DEBUG TRAIN Batch 32/800 loss 4.750262 loss_att 348.171234 loss_ctc 11.745940 loss_rnnt 3.972965 lr 0.00024226 rank 6
2022-12-08 13:43:19,068 DEBUG TRAIN Batch 32/800 loss 5.808264 loss_att 444.747986 loss_ctc 13.364815 loss_rnnt 4.968647 lr 0.00024227 rank 1
2022-12-08 13:43:19,070 DEBUG TRAIN Batch 32/800 loss 11.547909 loss_att 463.035736 loss_ctc 21.424324 loss_rnnt 10.450530 lr 0.00024223 rank 7
2022-12-08 13:43:19,072 DEBUG TRAIN Batch 32/800 loss 3.416979 loss_att 360.390106 loss_ctc 10.074333 loss_rnnt 2.677273 lr 0.00024223 rank 0
2022-12-08 13:43:19,072 DEBUG TRAIN Batch 32/800 loss 10.151968 loss_att 371.877045 loss_ctc 13.686213 loss_rnnt 9.759274 lr 0.00024225 rank 3
2022-12-08 13:43:19,077 DEBUG TRAIN Batch 32/800 loss 4.756844 loss_att 392.835632 loss_ctc 5.593429 loss_rnnt 4.663890 lr 0.00024226 rank 5
2022-12-08 13:43:19,111 DEBUG TRAIN Batch 32/800 loss 4.463901 loss_att 356.866150 loss_ctc 9.770738 loss_rnnt 3.874252 lr 0.00024226 rank 2
2022-12-08 13:44:22,821 DEBUG TRAIN Batch 32/900 loss 2.685612 loss_att 378.765015 loss_ctc 4.710424 loss_rnnt 2.460633 lr 0.00024220 rank 4
2022-12-08 13:44:22,822 DEBUG TRAIN Batch 32/900 loss 6.193352 loss_att 317.879211 loss_ctc 19.364113 loss_rnnt 4.729934 lr 0.00024221 rank 7
2022-12-08 13:44:22,824 DEBUG TRAIN Batch 32/900 loss 7.924085 loss_att 387.093750 loss_ctc 19.112480 loss_rnnt 6.680930 lr 0.00024224 rank 1
2022-12-08 13:44:22,825 DEBUG TRAIN Batch 32/900 loss 6.844366 loss_att 336.176605 loss_ctc 16.130787 loss_rnnt 5.812541 lr 0.00024224 rank 6
2022-12-08 13:44:22,826 DEBUG TRAIN Batch 32/900 loss 10.936343 loss_att 350.060242 loss_ctc 18.192757 loss_rnnt 10.130075 lr 0.00024222 rank 3
2022-12-08 13:44:22,826 DEBUG TRAIN Batch 32/900 loss 7.434130 loss_att 354.166626 loss_ctc 17.706694 loss_rnnt 6.292734 lr 0.00024223 rank 2
2022-12-08 13:44:22,828 DEBUG TRAIN Batch 32/900 loss 2.230944 loss_att 361.543213 loss_ctc 9.166941 loss_rnnt 1.460277 lr 0.00024220 rank 0
2022-12-08 13:44:22,837 DEBUG TRAIN Batch 32/900 loss 6.255476 loss_att 377.661377 loss_ctc 13.954443 loss_rnnt 5.400036 lr 0.00024223 rank 5
2022-12-08 13:45:26,358 DEBUG TRAIN Batch 32/1000 loss 11.971339 loss_att 384.654358 loss_ctc 31.634216 loss_rnnt 9.786575 lr 0.00024217 rank 4
2022-12-08 13:45:26,372 DEBUG TRAIN Batch 32/1000 loss 7.440693 loss_att 353.105347 loss_ctc 12.042011 loss_rnnt 6.929436 lr 0.00024218 rank 7
2022-12-08 13:45:26,372 DEBUG TRAIN Batch 32/1000 loss 13.557937 loss_att 344.340942 loss_ctc 25.564072 loss_rnnt 12.223923 lr 0.00024220 rank 2
2022-12-08 13:45:26,373 DEBUG TRAIN Batch 32/1000 loss 7.926961 loss_att 381.580261 loss_ctc 15.790794 loss_rnnt 7.053202 lr 0.00024219 rank 3
2022-12-08 13:45:26,373 DEBUG TRAIN Batch 32/1000 loss 6.695773 loss_att 352.582611 loss_ctc 20.129971 loss_rnnt 5.203084 lr 0.00024221 rank 6
2022-12-08 13:45:26,376 DEBUG TRAIN Batch 32/1000 loss 5.980635 loss_att 393.212708 loss_ctc 11.183788 loss_rnnt 5.402506 lr 0.00024221 rank 5
2022-12-08 13:45:26,377 DEBUG TRAIN Batch 32/1000 loss 8.824116 loss_att 376.813324 loss_ctc 19.031738 loss_rnnt 7.689936 lr 0.00024217 rank 0
2022-12-08 13:45:26,413 DEBUG TRAIN Batch 32/1000 loss 11.882850 loss_att 392.294312 loss_ctc 20.947235 loss_rnnt 10.875696 lr 0.00024221 rank 1
2022-12-08 13:46:38,163 DEBUG TRAIN Batch 32/1100 loss 7.782888 loss_att 357.131836 loss_ctc 18.739866 loss_rnnt 6.565446 lr 0.00024217 rank 2
2022-12-08 13:46:38,165 DEBUG TRAIN Batch 32/1100 loss 2.204216 loss_att 313.431885 loss_ctc 4.378217 loss_rnnt 1.962661 lr 0.00024218 rank 6
2022-12-08 13:46:38,166 DEBUG TRAIN Batch 32/1100 loss 15.035072 loss_att 379.570221 loss_ctc 26.406025 loss_rnnt 13.771634 lr 0.00024215 rank 7
2022-12-08 13:46:38,168 DEBUG TRAIN Batch 32/1100 loss 9.669518 loss_att 403.694458 loss_ctc 17.311569 loss_rnnt 8.820400 lr 0.00024215 rank 4
2022-12-08 13:46:38,172 DEBUG TRAIN Batch 32/1100 loss 10.076802 loss_att 331.684326 loss_ctc 19.189449 loss_rnnt 9.064285 lr 0.00024214 rank 0
2022-12-08 13:46:38,175 DEBUG TRAIN Batch 32/1100 loss 6.522403 loss_att 398.700165 loss_ctc 17.921621 loss_rnnt 5.255823 lr 0.00024216 rank 3
2022-12-08 13:46:38,199 DEBUG TRAIN Batch 32/1100 loss 5.486015 loss_att 297.927246 loss_ctc 9.165092 loss_rnnt 5.077229 lr 0.00024218 rank 1
2022-12-08 13:46:38,208 DEBUG TRAIN Batch 32/1100 loss 12.485482 loss_att 396.073425 loss_ctc 22.910473 loss_rnnt 11.327150 lr 0.00024218 rank 5
2022-12-08 13:47:41,059 DEBUG TRAIN Batch 32/1200 loss 8.332403 loss_att 263.736053 loss_ctc 17.366882 loss_rnnt 7.328572 lr 0.00024212 rank 4
2022-12-08 13:47:41,062 DEBUG TRAIN Batch 32/1200 loss 7.125794 loss_att 161.292267 loss_ctc 15.840966 loss_rnnt 6.157443 lr 0.00024216 rank 1
2022-12-08 13:47:41,062 DEBUG TRAIN Batch 32/1200 loss 11.956484 loss_att 168.951660 loss_ctc 18.911659 loss_rnnt 11.183687 lr 0.00024212 rank 7
2022-12-08 13:47:41,065 DEBUG TRAIN Batch 32/1200 loss 3.349014 loss_att 324.043060 loss_ctc 8.538673 loss_rnnt 2.772386 lr 0.00024215 rank 6
2022-12-08 13:47:41,065 DEBUG TRAIN Batch 32/1200 loss 2.356609 loss_att 301.373688 loss_ctc 5.963716 loss_rnnt 1.955819 lr 0.00024211 rank 0
2022-12-08 13:47:41,067 DEBUG TRAIN Batch 32/1200 loss 12.841843 loss_att 352.387299 loss_ctc 23.946005 loss_rnnt 11.608047 lr 0.00024215 rank 5
2022-12-08 13:47:41,068 DEBUG TRAIN Batch 32/1200 loss 5.418638 loss_att 232.066986 loss_ctc 11.361724 loss_rnnt 4.758296 lr 0.00024214 rank 3
2022-12-08 13:47:41,108 DEBUG TRAIN Batch 32/1200 loss 5.068333 loss_att 291.638580 loss_ctc 10.402014 loss_rnnt 4.475702 lr 0.00024215 rank 2
2022-12-08 13:48:43,998 DEBUG TRAIN Batch 32/1300 loss 4.909055 loss_att 355.308411 loss_ctc 10.954840 loss_rnnt 4.237301 lr 0.00024212 rank 2
2022-12-08 13:48:44,009 DEBUG TRAIN Batch 32/1300 loss 9.592658 loss_att 149.371628 loss_ctc 15.114860 loss_rnnt 8.979080 lr 0.00024209 rank 4
2022-12-08 13:48:44,011 DEBUG TRAIN Batch 32/1300 loss 5.381358 loss_att 374.652039 loss_ctc 9.524448 loss_rnnt 4.921015 lr 0.00024209 rank 7
2022-12-08 13:48:44,012 DEBUG TRAIN Batch 32/1300 loss 4.990322 loss_att 335.764069 loss_ctc 7.292993 loss_rnnt 4.734470 lr 0.00024211 rank 3
2022-12-08 13:48:44,015 DEBUG TRAIN Batch 32/1300 loss 2.016800 loss_att 319.753662 loss_ctc 5.969570 loss_rnnt 1.577604 lr 0.00024209 rank 0
2022-12-08 13:48:44,016 DEBUG TRAIN Batch 32/1300 loss 8.752829 loss_att 417.121033 loss_ctc 15.487361 loss_rnnt 8.004547 lr 0.00024213 rank 1
2022-12-08 13:48:44,018 DEBUG TRAIN Batch 32/1300 loss 8.690714 loss_att 461.599915 loss_ctc 17.769459 loss_rnnt 7.681965 lr 0.00024212 rank 6
2022-12-08 13:48:44,021 DEBUG TRAIN Batch 32/1300 loss 9.237685 loss_att 123.168747 loss_ctc 15.993312 loss_rnnt 8.487061 lr 0.00024212 rank 5
2022-12-08 13:49:49,442 DEBUG TRAIN Batch 32/1400 loss 4.327782 loss_att 392.029480 loss_ctc 9.277195 loss_rnnt 3.777848 lr 0.00024208 rank 3
2022-12-08 13:49:49,446 DEBUG TRAIN Batch 32/1400 loss 4.169685 loss_att 357.133301 loss_ctc 7.377359 loss_rnnt 3.813277 lr 0.00024206 rank 0
2022-12-08 13:49:49,448 DEBUG TRAIN Batch 32/1400 loss 2.890386 loss_att 404.099213 loss_ctc 7.976654 loss_rnnt 2.325245 lr 0.00024206 rank 7
2022-12-08 13:49:49,451 DEBUG TRAIN Batch 32/1400 loss 1.728110 loss_att 358.871765 loss_ctc 6.717934 loss_rnnt 1.173685 lr 0.00024209 rank 5
2022-12-08 13:49:49,453 DEBUG TRAIN Batch 32/1400 loss 6.171392 loss_att 405.680511 loss_ctc 17.598564 loss_rnnt 4.901707 lr 0.00024206 rank 4
2022-12-08 13:49:49,453 DEBUG TRAIN Batch 32/1400 loss 5.308327 loss_att 359.489197 loss_ctc 16.605818 loss_rnnt 4.053050 lr 0.00024209 rank 6
2022-12-08 13:49:49,472 DEBUG TRAIN Batch 32/1400 loss 16.198685 loss_att 402.099945 loss_ctc 33.427078 loss_rnnt 14.284419 lr 0.00024210 rank 1
2022-12-08 13:49:49,491 DEBUG TRAIN Batch 32/1400 loss 0.987975 loss_att 435.679504 loss_ctc 4.679059 loss_rnnt 0.577855 lr 0.00024209 rank 2
2022-12-08 13:51:01,310 DEBUG TRAIN Batch 32/1500 loss 8.656389 loss_att 382.421967 loss_ctc 17.022629 loss_rnnt 7.726807 lr 0.00024203 rank 4
2022-12-08 13:51:01,312 DEBUG TRAIN Batch 32/1500 loss 6.076714 loss_att 402.524994 loss_ctc 15.793193 loss_rnnt 4.997105 lr 0.00024207 rank 6
2022-12-08 13:51:01,314 DEBUG TRAIN Batch 32/1500 loss 4.417747 loss_att 351.281342 loss_ctc 13.376358 loss_rnnt 3.422345 lr 0.00024204 rank 7
2022-12-08 13:51:01,316 DEBUG TRAIN Batch 32/1500 loss 3.790739 loss_att 404.925903 loss_ctc 5.518229 loss_rnnt 3.598796 lr 0.00024206 rank 2
2022-12-08 13:51:01,319 DEBUG TRAIN Batch 32/1500 loss 7.746672 loss_att 390.549500 loss_ctc 14.131212 loss_rnnt 7.037279 lr 0.00024203 rank 0
2022-12-08 13:51:01,320 DEBUG TRAIN Batch 32/1500 loss 0.591271 loss_att 364.844849 loss_ctc 1.837971 loss_rnnt 0.452748 lr 0.00024207 rank 1
2022-12-08 13:51:01,322 DEBUG TRAIN Batch 32/1500 loss 7.461002 loss_att 361.125824 loss_ctc 12.897985 loss_rnnt 6.856893 lr 0.00024206 rank 5
2022-12-08 13:51:01,359 DEBUG TRAIN Batch 32/1500 loss 3.225589 loss_att 382.618713 loss_ctc 6.093031 loss_rnnt 2.906985 lr 0.00024205 rank 3
2022-12-08 13:52:03,659 DEBUG TRAIN Batch 32/1600 loss 4.570782 loss_att 359.814270 loss_ctc 10.334477 loss_rnnt 3.930372 lr 0.00024200 rank 4
2022-12-08 13:52:03,664 DEBUG TRAIN Batch 32/1600 loss 5.864560 loss_att 382.249329 loss_ctc 14.795601 loss_rnnt 4.872222 lr 0.00024204 rank 6
2022-12-08 13:52:03,665 DEBUG TRAIN Batch 32/1600 loss 8.245778 loss_att 352.662476 loss_ctc 17.417568 loss_rnnt 7.226690 lr 0.00024200 rank 0
2022-12-08 13:52:03,664 DEBUG TRAIN Batch 32/1600 loss 4.027721 loss_att 337.832031 loss_ctc 8.407318 loss_rnnt 3.541100 lr 0.00024204 rank 1
2022-12-08 13:52:03,666 DEBUG TRAIN Batch 32/1600 loss 3.887251 loss_att 311.846741 loss_ctc 14.798504 loss_rnnt 2.674889 lr 0.00024203 rank 2
2022-12-08 13:52:03,667 DEBUG TRAIN Batch 32/1600 loss 9.584648 loss_att 404.476196 loss_ctc 19.663422 loss_rnnt 8.464785 lr 0.00024204 rank 5
2022-12-08 13:52:03,668 DEBUG TRAIN Batch 32/1600 loss 10.040709 loss_att 301.936432 loss_ctc 14.402633 loss_rnnt 9.556051 lr 0.00024201 rank 7
2022-12-08 13:52:03,668 DEBUG TRAIN Batch 32/1600 loss 13.217181 loss_att 393.124969 loss_ctc 27.999111 loss_rnnt 11.574744 lr 0.00024202 rank 3
2022-12-08 13:53:07,386 DEBUG TRAIN Batch 32/1700 loss 2.764990 loss_att 321.015839 loss_ctc 6.492537 loss_rnnt 2.350818 lr 0.00024201 rank 5
2022-12-08 13:53:07,393 DEBUG TRAIN Batch 32/1700 loss 2.193823 loss_att 356.302673 loss_ctc 5.194133 loss_rnnt 1.860456 lr 0.00024197 rank 4
2022-12-08 13:53:07,393 DEBUG TRAIN Batch 32/1700 loss 7.238536 loss_att 368.193909 loss_ctc 14.951954 loss_rnnt 6.381490 lr 0.00024201 rank 1
2022-12-08 13:53:07,395 DEBUG TRAIN Batch 32/1700 loss 10.472943 loss_att 393.934723 loss_ctc 24.411819 loss_rnnt 8.924179 lr 0.00024198 rank 7
2022-12-08 13:53:07,400 DEBUG TRAIN Batch 32/1700 loss 7.034833 loss_att 345.893829 loss_ctc 13.958593 loss_rnnt 6.265527 lr 0.00024200 rank 2
2022-12-08 13:53:07,401 DEBUG TRAIN Batch 32/1700 loss 11.148755 loss_att 390.800293 loss_ctc 16.806862 loss_rnnt 10.520077 lr 0.00024197 rank 0
2022-12-08 13:53:07,420 DEBUG TRAIN Batch 32/1700 loss 8.062426 loss_att 322.285889 loss_ctc 13.817547 loss_rnnt 7.422968 lr 0.00024199 rank 3
2022-12-08 13:53:07,421 DEBUG TRAIN Batch 32/1700 loss 8.145082 loss_att 368.045563 loss_ctc 16.225739 loss_rnnt 7.247232 lr 0.00024201 rank 6
2022-12-08 13:54:19,454 DEBUG TRAIN Batch 32/1800 loss 2.907396 loss_att 278.381317 loss_ctc 9.085353 loss_rnnt 2.220957 lr 0.00024198 rank 6
2022-12-08 13:54:19,454 DEBUG TRAIN Batch 32/1800 loss 7.097890 loss_att 286.733551 loss_ctc 12.184733 loss_rnnt 6.532686 lr 0.00024194 rank 0
2022-12-08 13:54:19,454 DEBUG TRAIN Batch 32/1800 loss 10.642110 loss_att 229.304565 loss_ctc 20.661583 loss_rnnt 9.528835 lr 0.00024197 rank 3
2022-12-08 13:54:19,455 DEBUG TRAIN Batch 32/1800 loss 4.438877 loss_att 322.676331 loss_ctc 7.587855 loss_rnnt 4.088990 lr 0.00024195 rank 4
2022-12-08 13:54:19,456 DEBUG TRAIN Batch 32/1800 loss 8.661141 loss_att 333.814819 loss_ctc 27.579697 loss_rnnt 6.559080 lr 0.00024198 rank 5
2022-12-08 13:54:19,456 DEBUG TRAIN Batch 32/1800 loss 4.967773 loss_att 283.980286 loss_ctc 10.018656 loss_rnnt 4.406564 lr 0.00024199 rank 1
2022-12-08 13:54:19,458 DEBUG TRAIN Batch 32/1800 loss 6.420527 loss_att 230.771820 loss_ctc 11.900623 loss_rnnt 5.811628 lr 0.00024195 rank 7
2022-12-08 13:54:19,501 DEBUG TRAIN Batch 32/1800 loss 3.642995 loss_att 284.609344 loss_ctc 8.196357 loss_rnnt 3.137066 lr 0.00024197 rank 2
2022-12-08 13:55:22,712 DEBUG TRAIN Batch 32/1900 loss 8.879233 loss_att 257.051849 loss_ctc 16.152369 loss_rnnt 8.071107 lr 0.00024192 rank 4
2022-12-08 13:55:22,714 DEBUG TRAIN Batch 32/1900 loss 7.166440 loss_att 427.097260 loss_ctc 11.647033 loss_rnnt 6.668596 lr 0.00024192 rank 7
2022-12-08 13:55:22,715 DEBUG TRAIN Batch 32/1900 loss 12.817253 loss_att 466.907562 loss_ctc 29.739304 loss_rnnt 10.937025 lr 0.00024194 rank 3
2022-12-08 13:55:22,718 DEBUG TRAIN Batch 32/1900 loss 12.287814 loss_att 218.625549 loss_ctc 22.793903 loss_rnnt 11.120471 lr 0.00024195 rank 2
2022-12-08 13:55:22,718 DEBUG TRAIN Batch 32/1900 loss 10.100251 loss_att 373.560638 loss_ctc 19.419563 loss_rnnt 9.064772 lr 0.00024196 rank 1
2022-12-08 13:55:22,720 DEBUG TRAIN Batch 32/1900 loss 6.049108 loss_att 100.082001 loss_ctc 11.730788 loss_rnnt 5.417809 lr 0.00024195 rank 6
2022-12-08 13:55:22,720 DEBUG TRAIN Batch 32/1900 loss 10.724307 loss_att 137.766068 loss_ctc 17.592583 loss_rnnt 9.961165 lr 0.00024192 rank 0
2022-12-08 13:55:22,761 DEBUG TRAIN Batch 32/1900 loss 6.219862 loss_att 195.161346 loss_ctc 13.431934 loss_rnnt 5.418521 lr 0.00024195 rank 5
2022-12-08 13:56:25,452 DEBUG TRAIN Batch 32/2000 loss 0.958156 loss_att 274.997131 loss_ctc 3.112329 loss_rnnt 0.718804 lr 0.00024191 rank 3
2022-12-08 13:56:25,455 DEBUG TRAIN Batch 32/2000 loss 3.942127 loss_att 361.580994 loss_ctc 8.616736 loss_rnnt 3.422726 lr 0.00024192 rank 2
2022-12-08 13:56:25,455 DEBUG TRAIN Batch 32/2000 loss 11.476490 loss_att 443.980286 loss_ctc 25.625463 loss_rnnt 9.904382 lr 0.00024193 rank 1
2022-12-08 13:56:25,457 DEBUG TRAIN Batch 32/2000 loss 3.249352 loss_att 384.389404 loss_ctc 12.590473 loss_rnnt 2.211450 lr 0.00024189 rank 7
2022-12-08 13:56:25,461 DEBUG TRAIN Batch 32/2000 loss 2.938679 loss_att 362.374023 loss_ctc 9.298544 loss_rnnt 2.232027 lr 0.00024192 rank 6
2022-12-08 13:56:25,462 DEBUG TRAIN Batch 32/2000 loss 1.604488 loss_att 394.783325 loss_ctc 8.725676 loss_rnnt 0.813245 lr 0.00024189 rank 0
2022-12-08 13:56:25,462 DEBUG TRAIN Batch 32/2000 loss 5.550874 loss_att 419.430237 loss_ctc 9.568603 loss_rnnt 5.104460 lr 0.00024189 rank 4
2022-12-08 13:56:25,511 DEBUG TRAIN Batch 32/2000 loss 7.366211 loss_att 309.549652 loss_ctc 19.570858 loss_rnnt 6.010139 lr 0.00024192 rank 5
2022-12-08 13:57:30,748 DEBUG TRAIN Batch 32/2100 loss 5.545455 loss_att 342.067810 loss_ctc 18.699322 loss_rnnt 4.083914 lr 0.00024186 rank 4
2022-12-08 13:57:30,754 DEBUG TRAIN Batch 32/2100 loss 8.114469 loss_att 369.572266 loss_ctc 11.847944 loss_rnnt 7.699638 lr 0.00024188 rank 3
2022-12-08 13:57:30,755 DEBUG TRAIN Batch 32/2100 loss 4.415004 loss_att 339.230408 loss_ctc 9.696683 loss_rnnt 3.828151 lr 0.00024187 rank 7
2022-12-08 13:57:30,755 DEBUG TRAIN Batch 32/2100 loss 5.993306 loss_att 410.093750 loss_ctc 23.286888 loss_rnnt 4.071797 lr 0.00024189 rank 5
2022-12-08 13:57:30,760 DEBUG TRAIN Batch 32/2100 loss 7.125817 loss_att 392.790283 loss_ctc 14.136850 loss_rnnt 6.346814 lr 0.00024190 rank 1
2022-12-08 13:57:30,761 DEBUG TRAIN Batch 32/2100 loss 14.046532 loss_att 343.666595 loss_ctc 21.639767 loss_rnnt 13.202839 lr 0.00024186 rank 0
2022-12-08 13:57:30,778 DEBUG TRAIN Batch 32/2100 loss 11.752754 loss_att 406.447601 loss_ctc 20.045332 loss_rnnt 10.831356 lr 0.00024190 rank 6
2022-12-08 13:57:30,778 DEBUG TRAIN Batch 32/2100 loss 2.172123 loss_att 318.018005 loss_ctc 3.989250 loss_rnnt 1.970220 lr 0.00024189 rank 2
2022-12-08 13:58:42,585 DEBUG TRAIN Batch 32/2200 loss 7.047802 loss_att 360.124573 loss_ctc 18.862938 loss_rnnt 5.735010 lr 0.00024183 rank 4
2022-12-08 13:58:42,591 DEBUG TRAIN Batch 32/2200 loss 7.220877 loss_att 413.503296 loss_ctc 13.386772 loss_rnnt 6.535778 lr 0.00024183 rank 0
2022-12-08 13:58:42,592 DEBUG TRAIN Batch 32/2200 loss 4.359970 loss_att 345.811432 loss_ctc 8.962599 loss_rnnt 3.848567 lr 0.00024184 rank 7
2022-12-08 13:58:42,593 DEBUG TRAIN Batch 32/2200 loss 5.767677 loss_att 359.646820 loss_ctc 9.771853 loss_rnnt 5.322769 lr 0.00024187 rank 6
2022-12-08 13:58:42,594 DEBUG TRAIN Batch 32/2200 loss 4.579033 loss_att 380.608185 loss_ctc 9.698385 loss_rnnt 4.010216 lr 0.00024186 rank 2
2022-12-08 13:58:42,597 DEBUG TRAIN Batch 32/2200 loss 13.828109 loss_att 420.508148 loss_ctc 19.222561 loss_rnnt 13.228725 lr 0.00024187 rank 5
2022-12-08 13:58:42,598 DEBUG TRAIN Batch 32/2200 loss 6.540747 loss_att 346.877380 loss_ctc 11.840960 loss_rnnt 5.951835 lr 0.00024187 rank 1
2022-12-08 13:58:42,634 DEBUG TRAIN Batch 32/2200 loss 22.552616 loss_att 371.525452 loss_ctc 34.839005 loss_rnnt 21.187462 lr 0.00024185 rank 3
2022-12-08 13:59:45,720 DEBUG TRAIN Batch 32/2300 loss 10.782053 loss_att 392.073761 loss_ctc 20.425728 loss_rnnt 9.710533 lr 0.00024183 rank 2
2022-12-08 13:59:45,721 DEBUG TRAIN Batch 32/2300 loss 5.985769 loss_att 315.040863 loss_ctc 10.428102 loss_rnnt 5.492176 lr 0.00024181 rank 7
2022-12-08 13:59:45,721 DEBUG TRAIN Batch 32/2300 loss 10.571943 loss_att 386.134460 loss_ctc 21.628788 loss_rnnt 9.343405 lr 0.00024184 rank 1
2022-12-08 13:59:45,722 DEBUG TRAIN Batch 32/2300 loss 5.847216 loss_att 349.739868 loss_ctc 11.735132 loss_rnnt 5.193003 lr 0.00024181 rank 4
2022-12-08 13:59:45,724 DEBUG TRAIN Batch 32/2300 loss 4.478185 loss_att 350.063354 loss_ctc 10.692169 loss_rnnt 3.787743 lr 0.00024182 rank 3
2022-12-08 13:59:45,726 DEBUG TRAIN Batch 32/2300 loss 10.933325 loss_att 407.845978 loss_ctc 20.508369 loss_rnnt 9.869431 lr 0.00024180 rank 0
2022-12-08 13:59:45,733 DEBUG TRAIN Batch 32/2300 loss 6.727637 loss_att 336.870178 loss_ctc 15.346598 loss_rnnt 5.769975 lr 0.00024184 rank 6
2022-12-08 13:59:45,735 DEBUG TRAIN Batch 32/2300 loss 5.975162 loss_att 370.089600 loss_ctc 9.852887 loss_rnnt 5.544304 lr 0.00024184 rank 5
2022-12-08 14:00:49,485 DEBUG TRAIN Batch 32/2400 loss 5.254060 loss_att 270.113708 loss_ctc 13.762934 loss_rnnt 4.308630 lr 0.00024180 rank 3
2022-12-08 14:00:49,485 DEBUG TRAIN Batch 32/2400 loss 5.002650 loss_att 372.501617 loss_ctc 17.462975 loss_rnnt 3.618170 lr 0.00024178 rank 4
2022-12-08 14:00:49,486 DEBUG TRAIN Batch 32/2400 loss 7.918781 loss_att 299.132843 loss_ctc 14.005237 loss_rnnt 7.242508 lr 0.00024178 rank 7
2022-12-08 14:00:49,488 DEBUG TRAIN Batch 32/2400 loss 10.655642 loss_att 361.952820 loss_ctc 22.314190 loss_rnnt 9.360248 lr 0.00024181 rank 6
2022-12-08 14:00:49,489 DEBUG TRAIN Batch 32/2400 loss 8.583429 loss_att 252.119873 loss_ctc 15.837074 loss_rnnt 7.777469 lr 0.00024182 rank 1
2022-12-08 14:00:49,489 DEBUG TRAIN Batch 32/2400 loss 4.877212 loss_att 313.251373 loss_ctc 10.969387 loss_rnnt 4.200303 lr 0.00024181 rank 2
2022-12-08 14:00:49,490 DEBUG TRAIN Batch 32/2400 loss 5.362184 loss_att 378.876709 loss_ctc 10.437248 loss_rnnt 4.798288 lr 0.00024181 rank 5
2022-12-08 14:00:49,494 DEBUG TRAIN Batch 32/2400 loss 6.643791 loss_att 309.739960 loss_ctc 11.722023 loss_rnnt 6.079543 lr 0.00024177 rank 0
2022-12-08 14:02:02,696 DEBUG TRAIN Batch 32/2500 loss 3.934445 loss_att 336.054657 loss_ctc 11.140959 loss_rnnt 3.133721 lr 0.00024175 rank 4
2022-12-08 14:02:02,699 DEBUG TRAIN Batch 32/2500 loss 14.208338 loss_att 175.390930 loss_ctc 25.058842 loss_rnnt 13.002727 lr 0.00024175 rank 7
2022-12-08 14:02:02,701 DEBUG TRAIN Batch 32/2500 loss 8.160898 loss_att 209.888229 loss_ctc 14.918894 loss_rnnt 7.410010 lr 0.00024175 rank 0
2022-12-08 14:02:02,703 DEBUG TRAIN Batch 32/2500 loss 10.998556 loss_att 346.048401 loss_ctc 16.348614 loss_rnnt 10.404106 lr 0.00024179 rank 1
2022-12-08 14:02:02,703 DEBUG TRAIN Batch 32/2500 loss 6.043996 loss_att 308.650085 loss_ctc 15.140236 loss_rnnt 5.033303 lr 0.00024178 rank 5
2022-12-08 14:02:02,710 DEBUG TRAIN Batch 32/2500 loss 6.032255 loss_att 150.697189 loss_ctc 10.368391 loss_rnnt 5.550463 lr 0.00024178 rank 2
2022-12-08 14:02:02,720 DEBUG TRAIN Batch 32/2500 loss 5.501682 loss_att 523.112915 loss_ctc 11.498626 loss_rnnt 4.835355 lr 0.00024177 rank 3
2022-12-08 14:02:02,738 DEBUG TRAIN Batch 32/2500 loss 8.229692 loss_att 250.219452 loss_ctc 17.477852 loss_rnnt 7.202119 lr 0.00024178 rank 6
2022-12-08 14:03:06,265 DEBUG TRAIN Batch 32/2600 loss 2.417136 loss_att 385.112000 loss_ctc 4.883335 loss_rnnt 2.143114 lr 0.00024175 rank 2
2022-12-08 14:03:06,266 DEBUG TRAIN Batch 32/2600 loss 7.245591 loss_att 377.348572 loss_ctc 17.892729 loss_rnnt 6.062576 lr 0.00024172 rank 7
2022-12-08 14:03:06,266 DEBUG TRAIN Batch 32/2600 loss 2.265571 loss_att 438.803406 loss_ctc 9.331265 loss_rnnt 1.480493 lr 0.00024176 rank 1
2022-12-08 14:03:06,268 DEBUG TRAIN Batch 32/2600 loss 4.437932 loss_att 339.552002 loss_ctc 9.067352 loss_rnnt 3.923552 lr 0.00024174 rank 3
2022-12-08 14:03:06,268 DEBUG TRAIN Batch 32/2600 loss 8.695926 loss_att 417.218201 loss_ctc 16.172968 loss_rnnt 7.865143 lr 0.00024175 rank 6
2022-12-08 14:03:06,269 DEBUG TRAIN Batch 32/2600 loss 3.880700 loss_att 137.018204 loss_ctc 7.100053 loss_rnnt 3.522995 lr 0.00024172 rank 4
2022-12-08 14:03:06,270 DEBUG TRAIN Batch 32/2600 loss 3.972494 loss_att 141.114212 loss_ctc 7.556571 loss_rnnt 3.574263 lr 0.00024175 rank 5
2022-12-08 14:03:06,274 DEBUG TRAIN Batch 32/2600 loss 8.833069 loss_att 510.717285 loss_ctc 29.205845 loss_rnnt 6.569427 lr 0.00024172 rank 0
2022-12-08 14:04:09,589 DEBUG TRAIN Batch 32/2700 loss 2.276057 loss_att 394.440491 loss_ctc 6.548481 loss_rnnt 1.801343 lr 0.00024170 rank 7
2022-12-08 14:04:09,595 DEBUG TRAIN Batch 32/2700 loss 8.052061 loss_att 361.309753 loss_ctc 16.023872 loss_rnnt 7.166305 lr 0.00024172 rank 2
2022-12-08 14:04:09,596 DEBUG TRAIN Batch 32/2700 loss 2.892351 loss_att 393.615417 loss_ctc 9.013264 loss_rnnt 2.212249 lr 0.00024169 rank 4
2022-12-08 14:04:09,598 DEBUG TRAIN Batch 32/2700 loss 1.914687 loss_att 372.292572 loss_ctc 5.543953 loss_rnnt 1.511436 lr 0.00024171 rank 3
2022-12-08 14:04:09,599 DEBUG TRAIN Batch 32/2700 loss 4.470577 loss_att 402.588959 loss_ctc 9.207254 loss_rnnt 3.944280 lr 0.00024169 rank 0
2022-12-08 14:04:09,599 DEBUG TRAIN Batch 32/2700 loss 9.249384 loss_att 415.158539 loss_ctc 12.679286 loss_rnnt 8.868284 lr 0.00024173 rank 1
2022-12-08 14:04:09,601 DEBUG TRAIN Batch 32/2700 loss 4.478545 loss_att 306.008423 loss_ctc 6.563543 loss_rnnt 4.246879 lr 0.00024172 rank 5
2022-12-08 14:04:09,604 DEBUG TRAIN Batch 32/2700 loss 5.060708 loss_att 389.728882 loss_ctc 12.892696 loss_rnnt 4.190487 lr 0.00024173 rank 6
2022-12-08 14:05:14,139 DEBUG TRAIN Batch 32/2800 loss 5.081586 loss_att 345.194336 loss_ctc 9.042144 loss_rnnt 4.641524 lr 0.00024169 rank 2
2022-12-08 14:05:14,145 DEBUG TRAIN Batch 32/2800 loss 8.270629 loss_att 428.389984 loss_ctc 18.325468 loss_rnnt 7.153425 lr 0.00024166 rank 4
2022-12-08 14:05:14,150 DEBUG TRAIN Batch 32/2800 loss 10.721751 loss_att 329.756287 loss_ctc 12.788090 loss_rnnt 10.492159 lr 0.00024170 rank 1
2022-12-08 14:05:14,152 DEBUG TRAIN Batch 32/2800 loss 12.662020 loss_att 438.879761 loss_ctc 36.602043 loss_rnnt 10.002017 lr 0.00024167 rank 7
2022-12-08 14:05:14,153 DEBUG TRAIN Batch 32/2800 loss 5.019343 loss_att 327.627045 loss_ctc 14.591244 loss_rnnt 3.955799 lr 0.00024170 rank 5
2022-12-08 14:05:14,154 DEBUG TRAIN Batch 32/2800 loss 2.601428 loss_att 366.461975 loss_ctc 10.615671 loss_rnnt 1.710957 lr 0.00024168 rank 3
2022-12-08 14:05:14,156 DEBUG TRAIN Batch 32/2800 loss 6.153098 loss_att 395.314941 loss_ctc 16.009928 loss_rnnt 5.057895 lr 0.00024166 rank 0
2022-12-08 14:05:14,156 DEBUG TRAIN Batch 32/2800 loss 6.840580 loss_att 409.565948 loss_ctc 18.825642 loss_rnnt 5.508907 lr 0.00024170 rank 6
2022-12-08 14:06:25,555 DEBUG TRAIN Batch 32/2900 loss 13.974517 loss_att 420.498871 loss_ctc 25.578526 loss_rnnt 12.685183 lr 0.00024164 rank 7
2022-12-08 14:06:25,557 DEBUG TRAIN Batch 32/2900 loss 7.610454 loss_att 387.314819 loss_ctc 15.550531 loss_rnnt 6.728223 lr 0.00024164 rank 4
2022-12-08 14:06:25,561 DEBUG TRAIN Batch 32/2900 loss 5.995105 loss_att 340.358093 loss_ctc 18.092461 loss_rnnt 4.650954 lr 0.00024165 rank 3
2022-12-08 14:06:25,562 DEBUG TRAIN Batch 32/2900 loss 3.583736 loss_att 338.156128 loss_ctc 10.647972 loss_rnnt 2.798821 lr 0.00024167 rank 5
2022-12-08 14:06:25,562 DEBUG TRAIN Batch 32/2900 loss 5.490584 loss_att 339.954224 loss_ctc 9.908028 loss_rnnt 4.999757 lr 0.00024167 rank 1
2022-12-08 14:06:25,562 DEBUG TRAIN Batch 32/2900 loss 4.796434 loss_att 299.131348 loss_ctc 10.267787 loss_rnnt 4.188506 lr 0.00024163 rank 0
2022-12-08 14:06:25,562 DEBUG TRAIN Batch 32/2900 loss 9.605037 loss_att 373.987701 loss_ctc 16.903978 loss_rnnt 8.794044 lr 0.00024166 rank 2
2022-12-08 14:06:25,563 DEBUG TRAIN Batch 32/2900 loss 5.804226 loss_att 381.815430 loss_ctc 14.891193 loss_rnnt 4.794563 lr 0.00024167 rank 6
2022-12-08 14:07:28,716 DEBUG TRAIN Batch 32/3000 loss 9.793796 loss_att 396.462524 loss_ctc 22.386108 loss_rnnt 8.394650 lr 0.00024161 rank 4
2022-12-08 14:07:28,719 DEBUG TRAIN Batch 32/3000 loss 7.913160 loss_att 368.098145 loss_ctc 15.627954 loss_rnnt 7.055961 lr 0.00024164 rank 2
2022-12-08 14:07:28,721 DEBUG TRAIN Batch 32/3000 loss 4.457767 loss_att 290.205566 loss_ctc 11.366959 loss_rnnt 3.690079 lr 0.00024165 rank 1
2022-12-08 14:07:28,721 DEBUG TRAIN Batch 32/3000 loss 7.652774 loss_att 298.300018 loss_ctc 11.786318 loss_rnnt 7.193491 lr 0.00024163 rank 3
2022-12-08 14:07:28,726 DEBUG TRAIN Batch 32/3000 loss 9.332273 loss_att 374.009888 loss_ctc 17.415804 loss_rnnt 8.434103 lr 0.00024164 rank 5
2022-12-08 14:07:28,733 DEBUG TRAIN Batch 32/3000 loss 7.285891 loss_att 325.090820 loss_ctc 15.106503 loss_rnnt 6.416934 lr 0.00024161 rank 7
2022-12-08 14:07:28,755 DEBUG TRAIN Batch 32/3000 loss 13.342575 loss_att 371.152039 loss_ctc 21.670429 loss_rnnt 12.417258 lr 0.00024160 rank 0
2022-12-08 14:07:28,764 DEBUG TRAIN Batch 32/3000 loss 2.635770 loss_att 281.689575 loss_ctc 6.171280 loss_rnnt 2.242936 lr 0.00024164 rank 6
2022-12-08 14:08:32,479 DEBUG TRAIN Batch 32/3100 loss 5.624538 loss_att 268.070496 loss_ctc 11.778056 loss_rnnt 4.940814 lr 0.00024158 rank 7
2022-12-08 14:08:32,481 DEBUG TRAIN Batch 32/3100 loss 5.236471 loss_att 322.506958 loss_ctc 16.131027 loss_rnnt 4.025964 lr 0.00024158 rank 4
2022-12-08 14:08:32,483 DEBUG TRAIN Batch 32/3100 loss 9.452607 loss_att 303.863220 loss_ctc 17.932159 loss_rnnt 8.510435 lr 0.00024158 rank 0
2022-12-08 14:08:32,484 DEBUG TRAIN Batch 32/3100 loss 2.060176 loss_att 240.440781 loss_ctc 5.506355 loss_rnnt 1.677267 lr 0.00024161 rank 2
2022-12-08 14:08:32,486 DEBUG TRAIN Batch 32/3100 loss 5.869169 loss_att 180.387619 loss_ctc 13.742196 loss_rnnt 4.994388 lr 0.00024160 rank 3
2022-12-08 14:08:32,486 DEBUG TRAIN Batch 32/3100 loss 7.805919 loss_att 109.109283 loss_ctc 14.134162 loss_rnnt 7.102781 lr 0.00024162 rank 1
2022-12-08 14:08:32,486 DEBUG TRAIN Batch 32/3100 loss 10.381797 loss_att 248.721832 loss_ctc 21.216652 loss_rnnt 9.177924 lr 0.00024161 rank 6
2022-12-08 14:08:32,487 DEBUG TRAIN Batch 32/3100 loss 18.834486 loss_att 307.608612 loss_ctc 26.413895 loss_rnnt 17.992329 lr 0.00024161 rank 5
2022-12-08 14:09:45,275 DEBUG TRAIN Batch 32/3200 loss 13.372635 loss_att 387.904602 loss_ctc 30.887772 loss_rnnt 11.426508 lr 0.00024156 rank 7
2022-12-08 14:09:45,277 DEBUG TRAIN Batch 32/3200 loss 14.910232 loss_att 262.329102 loss_ctc 25.065983 loss_rnnt 13.781815 lr 0.00024155 rank 4
2022-12-08 14:09:45,278 DEBUG TRAIN Batch 32/3200 loss 7.843708 loss_att 120.280563 loss_ctc 14.803917 loss_rnnt 7.070352 lr 0.00024159 rank 6
2022-12-08 14:09:45,284 DEBUG TRAIN Batch 32/3200 loss 5.864311 loss_att 167.622086 loss_ctc 9.869008 loss_rnnt 5.419344 lr 0.00024155 rank 0
2022-12-08 14:09:45,302 DEBUG TRAIN Batch 32/3200 loss 9.222976 loss_att 426.160156 loss_ctc 19.995558 loss_rnnt 8.026022 lr 0.00024157 rank 3
2022-12-08 14:09:45,303 DEBUG TRAIN Batch 32/3200 loss 6.955414 loss_att 398.522308 loss_ctc 15.281955 loss_rnnt 6.030243 lr 0.00024159 rank 1
2022-12-08 14:09:45,306 DEBUG TRAIN Batch 32/3200 loss 6.925170 loss_att 251.590698 loss_ctc 13.816666 loss_rnnt 6.159448 lr 0.00024158 rank 5
2022-12-08 14:09:45,318 DEBUG TRAIN Batch 32/3200 loss 14.559515 loss_att 415.035339 loss_ctc 31.684509 loss_rnnt 12.656738 lr 0.00024158 rank 2
2022-12-08 14:10:49,376 DEBUG TRAIN Batch 32/3300 loss 1.607374 loss_att 419.673553 loss_ctc 7.865252 loss_rnnt 0.912055 lr 0.00024152 rank 4
2022-12-08 14:10:49,378 DEBUG TRAIN Batch 32/3300 loss 4.546353 loss_att 384.190125 loss_ctc 9.912886 loss_rnnt 3.950071 lr 0.00024154 rank 3
2022-12-08 14:10:49,378 DEBUG TRAIN Batch 32/3300 loss 6.200236 loss_att 441.518372 loss_ctc 13.288260 loss_rnnt 5.412678 lr 0.00024155 rank 2
2022-12-08 14:10:49,379 DEBUG TRAIN Batch 32/3300 loss 7.413298 loss_att 405.819153 loss_ctc 16.375622 loss_rnnt 6.417484 lr 0.00024153 rank 7
2022-12-08 14:10:49,381 DEBUG TRAIN Batch 32/3300 loss 8.335527 loss_att 359.265808 loss_ctc 13.703381 loss_rnnt 7.739099 lr 0.00024156 rank 1
2022-12-08 14:10:49,382 DEBUG TRAIN Batch 32/3300 loss 5.186751 loss_att 391.951233 loss_ctc 10.815955 loss_rnnt 4.561285 lr 0.00024156 rank 5
2022-12-08 14:10:49,382 DEBUG TRAIN Batch 32/3300 loss 1.204791 loss_att 405.814392 loss_ctc 3.873575 loss_rnnt 0.908260 lr 0.00024156 rank 6
2022-12-08 14:10:49,384 DEBUG TRAIN Batch 32/3300 loss 8.862564 loss_att 445.835449 loss_ctc 21.499195 loss_rnnt 7.458494 lr 0.00024152 rank 0
2022-12-08 14:11:52,648 DEBUG TRAIN Batch 32/3400 loss 5.603809 loss_att 318.737915 loss_ctc 16.719961 loss_rnnt 4.368681 lr 0.00024151 rank 3
2022-12-08 14:11:52,648 DEBUG TRAIN Batch 32/3400 loss 5.218785 loss_att 376.284821 loss_ctc 15.062851 loss_rnnt 4.125000 lr 0.00024153 rank 1
2022-12-08 14:11:52,648 DEBUG TRAIN Batch 32/3400 loss 3.847250 loss_att 366.609802 loss_ctc 8.337406 loss_rnnt 3.348343 lr 0.00024149 rank 0
2022-12-08 14:11:52,649 DEBUG TRAIN Batch 32/3400 loss 5.463897 loss_att 388.218018 loss_ctc 12.693113 loss_rnnt 4.660650 lr 0.00024152 rank 2
2022-12-08 14:11:52,650 DEBUG TRAIN Batch 32/3400 loss 8.147100 loss_att 419.603577 loss_ctc 18.023394 loss_rnnt 7.049735 lr 0.00024149 rank 4
2022-12-08 14:11:52,650 DEBUG TRAIN Batch 32/3400 loss 7.856873 loss_att 404.948364 loss_ctc 21.317024 loss_rnnt 6.361301 lr 0.00024153 rank 6
2022-12-08 14:11:52,653 DEBUG TRAIN Batch 32/3400 loss 3.446666 loss_att 410.171478 loss_ctc 12.273909 loss_rnnt 2.465862 lr 0.00024150 rank 7
2022-12-08 14:11:52,698 DEBUG TRAIN Batch 32/3400 loss 9.470606 loss_att 385.494385 loss_ctc 14.590635 loss_rnnt 8.901714 lr 0.00024153 rank 5
2022-12-08 14:12:56,716 DEBUG TRAIN Batch 32/3500 loss 6.487268 loss_att 436.713959 loss_ctc 22.307943 loss_rnnt 4.729416 lr 0.00024147 rank 7
2022-12-08 14:12:56,727 DEBUG TRAIN Batch 32/3500 loss 10.159168 loss_att 374.980408 loss_ctc 21.161991 loss_rnnt 8.936632 lr 0.00024150 rank 6
2022-12-08 14:12:56,728 DEBUG TRAIN Batch 32/3500 loss 8.499940 loss_att 328.857361 loss_ctc 18.034590 loss_rnnt 7.440534 lr 0.00024151 rank 1
2022-12-08 14:12:56,731 DEBUG TRAIN Batch 32/3500 loss 6.138334 loss_att 398.284912 loss_ctc 11.229618 loss_rnnt 5.572636 lr 0.00024146 rank 0
2022-12-08 14:12:56,730 DEBUG TRAIN Batch 32/3500 loss 4.688862 loss_att 368.326233 loss_ctc 9.311083 loss_rnnt 4.175282 lr 0.00024147 rank 4
2022-12-08 14:12:56,732 DEBUG TRAIN Batch 32/3500 loss 5.659635 loss_att 338.143616 loss_ctc 6.863289 loss_rnnt 5.525896 lr 0.00024149 rank 3
2022-12-08 14:12:56,733 DEBUG TRAIN Batch 32/3500 loss 5.847400 loss_att 340.166687 loss_ctc 13.484467 loss_rnnt 4.998837 lr 0.00024150 rank 5
2022-12-08 14:12:56,751 DEBUG TRAIN Batch 32/3500 loss 8.861609 loss_att 397.885956 loss_ctc 20.865923 loss_rnnt 7.527797 lr 0.00024149 rank 2
2022-12-08 14:14:12,252 DEBUG TRAIN Batch 32/3600 loss 14.681771 loss_att 331.551331 loss_ctc 18.004894 loss_rnnt 14.312536 lr 0.00024144 rank 7
2022-12-08 14:14:12,256 DEBUG TRAIN Batch 32/3600 loss 6.841004 loss_att 333.255646 loss_ctc 12.604323 loss_rnnt 6.200636 lr 0.00024146 rank 3
2022-12-08 14:14:12,259 DEBUG TRAIN Batch 32/3600 loss 2.515407 loss_att 362.324615 loss_ctc 7.231773 loss_rnnt 1.991367 lr 0.00024148 rank 1
2022-12-08 14:14:12,259 DEBUG TRAIN Batch 32/3600 loss 4.283754 loss_att 382.245300 loss_ctc 11.707622 loss_rnnt 3.458880 lr 0.00024147 rank 6
2022-12-08 14:14:12,260 DEBUG TRAIN Batch 32/3600 loss 3.046024 loss_att 409.784515 loss_ctc 14.063972 loss_rnnt 1.821808 lr 0.00024144 rank 0
2022-12-08 14:14:12,260 DEBUG TRAIN Batch 32/3600 loss 5.346837 loss_att 354.043884 loss_ctc 8.230916 loss_rnnt 5.026384 lr 0.00024147 rank 2
2022-12-08 14:14:12,261 DEBUG TRAIN Batch 32/3600 loss 5.932731 loss_att 344.504272 loss_ctc 13.724262 loss_rnnt 5.067005 lr 0.00024144 rank 4
2022-12-08 14:14:12,265 DEBUG TRAIN Batch 32/3600 loss 7.371441 loss_att 363.765411 loss_ctc 15.014675 loss_rnnt 6.522193 lr 0.00024147 rank 5
2022-12-08 14:15:15,473 DEBUG TRAIN Batch 32/3700 loss 5.067562 loss_att 335.244385 loss_ctc 8.891770 loss_rnnt 4.642651 lr 0.00024141 rank 4
2022-12-08 14:15:15,473 DEBUG TRAIN Batch 32/3700 loss 9.367232 loss_att 301.559113 loss_ctc 14.991449 loss_rnnt 8.742320 lr 0.00024141 rank 7
2022-12-08 14:15:15,477 DEBUG TRAIN Batch 32/3700 loss 18.544439 loss_att 371.611694 loss_ctc 26.426834 loss_rnnt 17.668617 lr 0.00024144 rank 6
2022-12-08 14:15:15,480 DEBUG TRAIN Batch 32/3700 loss 10.734198 loss_att 182.733093 loss_ctc 22.165012 loss_rnnt 9.464108 lr 0.00024145 rank 1
2022-12-08 14:15:15,480 DEBUG TRAIN Batch 32/3700 loss 4.441575 loss_att 316.824951 loss_ctc 12.555405 loss_rnnt 3.540038 lr 0.00024144 rank 2
2022-12-08 14:15:15,481 DEBUG TRAIN Batch 32/3700 loss 9.956653 loss_att 330.062744 loss_ctc 18.295086 loss_rnnt 9.030160 lr 0.00024141 rank 0
2022-12-08 14:15:15,484 DEBUG TRAIN Batch 32/3700 loss 5.029738 loss_att 240.069824 loss_ctc 12.531055 loss_rnnt 4.196259 lr 0.00024143 rank 3
2022-12-08 14:15:15,485 DEBUG TRAIN Batch 32/3700 loss 8.712100 loss_att 337.052185 loss_ctc 12.462410 loss_rnnt 8.295400 lr 0.00024144 rank 5
2022-12-08 14:16:19,613 DEBUG TRAIN Batch 32/3800 loss 6.471546 loss_att 162.071289 loss_ctc 10.926986 loss_rnnt 5.976497 lr 0.00024142 rank 6
2022-12-08 14:16:19,614 DEBUG TRAIN Batch 32/3800 loss 8.227816 loss_att 291.264740 loss_ctc 14.174407 loss_rnnt 7.567084 lr 0.00024138 rank 4
2022-12-08 14:16:19,616 DEBUG TRAIN Batch 32/3800 loss 10.811125 loss_att 299.456787 loss_ctc 20.080479 loss_rnnt 9.781197 lr 0.00024141 rank 5
2022-12-08 14:16:19,617 DEBUG TRAIN Batch 32/3800 loss 5.289673 loss_att 98.371849 loss_ctc 8.318789 loss_rnnt 4.953104 lr 0.00024139 rank 7
2022-12-08 14:16:19,619 DEBUG TRAIN Batch 32/3800 loss 11.829438 loss_att 370.826965 loss_ctc 27.023632 loss_rnnt 10.141195 lr 0.00024142 rank 1
2022-12-08 14:16:19,620 DEBUG TRAIN Batch 32/3800 loss 6.924252 loss_att 275.719482 loss_ctc 17.315741 loss_rnnt 5.769642 lr 0.00024138 rank 0
2022-12-08 14:16:19,621 DEBUG TRAIN Batch 32/3800 loss 9.513725 loss_att 483.704529 loss_ctc 21.829792 loss_rnnt 8.145273 lr 0.00024140 rank 3
2022-12-08 14:16:19,658 DEBUG TRAIN Batch 32/3800 loss 5.942497 loss_att 81.327934 loss_ctc 10.527034 loss_rnnt 5.433105 lr 0.00024141 rank 2
2022-12-08 14:17:33,072 DEBUG TRAIN Batch 32/3900 loss 2.749191 loss_att 368.402161 loss_ctc 5.707712 loss_rnnt 2.420467 lr 0.00024136 rank 7
2022-12-08 14:17:33,074 DEBUG TRAIN Batch 32/3900 loss 4.276475 loss_att 175.266937 loss_ctc 9.477267 loss_rnnt 3.698609 lr 0.00024135 rank 4
2022-12-08 14:17:33,079 DEBUG TRAIN Batch 32/3900 loss 1.647102 loss_att 422.135559 loss_ctc 5.480865 loss_rnnt 1.221128 lr 0.00024135 rank 0
2022-12-08 14:17:33,087 DEBUG TRAIN Batch 32/3900 loss 1.992238 loss_att 343.341766 loss_ctc 4.996258 loss_rnnt 1.658458 lr 0.00024137 rank 3
2022-12-08 14:17:33,088 DEBUG TRAIN Batch 32/3900 loss 10.313478 loss_att 455.483154 loss_ctc 21.909237 loss_rnnt 9.025061 lr 0.00024139 rank 1
2022-12-08 14:17:33,099 DEBUG TRAIN Batch 32/3900 loss 8.976062 loss_att 102.725273 loss_ctc 15.421465 loss_rnnt 8.259906 lr 0.00024139 rank 5
2022-12-08 14:17:33,118 DEBUG TRAIN Batch 32/3900 loss 2.823433 loss_att 295.965881 loss_ctc 8.087028 loss_rnnt 2.238590 lr 0.00024138 rank 2
2022-12-08 14:17:33,117 DEBUG TRAIN Batch 32/3900 loss 3.849583 loss_att 434.225433 loss_ctc 11.129244 loss_rnnt 3.040732 lr 0.00024139 rank 6
2022-12-08 14:18:37,023 DEBUG TRAIN Batch 32/4000 loss 6.652594 loss_att 417.217285 loss_ctc 12.495731 loss_rnnt 6.003356 lr 0.00024136 rank 1
2022-12-08 14:18:37,027 DEBUG TRAIN Batch 32/4000 loss 4.226399 loss_att 341.628662 loss_ctc 9.105576 loss_rnnt 3.684269 lr 0.00024133 rank 7
2022-12-08 14:18:37,028 DEBUG TRAIN Batch 32/4000 loss 9.419771 loss_att 380.852112 loss_ctc 18.301367 loss_rnnt 8.432928 lr 0.00024135 rank 2
2022-12-08 14:18:37,028 DEBUG TRAIN Batch 32/4000 loss 8.970204 loss_att 407.902924 loss_ctc 24.900015 loss_rnnt 7.200225 lr 0.00024132 rank 0
2022-12-08 14:18:37,032 DEBUG TRAIN Batch 32/4000 loss 6.683062 loss_att 440.326019 loss_ctc 17.880426 loss_rnnt 5.438911 lr 0.00024133 rank 4
2022-12-08 14:18:37,033 DEBUG TRAIN Batch 32/4000 loss 12.018607 loss_att 374.584320 loss_ctc 16.197525 loss_rnnt 11.554283 lr 0.00024136 rank 5
2022-12-08 14:18:37,036 DEBUG TRAIN Batch 32/4000 loss 3.887852 loss_att 382.702820 loss_ctc 8.915455 loss_rnnt 3.329230 lr 0.00024136 rank 6
2022-12-08 14:18:37,069 DEBUG TRAIN Batch 32/4000 loss 9.575040 loss_att 377.104126 loss_ctc 15.656704 loss_rnnt 8.899301 lr 0.00024134 rank 3
2022-12-08 14:19:40,746 DEBUG TRAIN Batch 32/4100 loss 7.322901 loss_att 387.542236 loss_ctc 11.772261 loss_rnnt 6.828528 lr 0.00024130 rank 7
2022-12-08 14:19:40,747 DEBUG TRAIN Batch 32/4100 loss 11.592637 loss_att 406.141846 loss_ctc 25.404364 loss_rnnt 10.058001 lr 0.00024133 rank 6
2022-12-08 14:19:40,747 DEBUG TRAIN Batch 32/4100 loss 7.727620 loss_att 417.707367 loss_ctc 19.256313 loss_rnnt 6.446654 lr 0.00024130 rank 4
2022-12-08 14:19:40,750 DEBUG TRAIN Batch 32/4100 loss 16.264505 loss_att 376.185181 loss_ctc 38.433365 loss_rnnt 13.801298 lr 0.00024132 rank 3
2022-12-08 14:19:40,751 DEBUG TRAIN Batch 32/4100 loss 7.040581 loss_att 408.713074 loss_ctc 15.704973 loss_rnnt 6.077871 lr 0.00024133 rank 5
2022-12-08 14:19:40,752 DEBUG TRAIN Batch 32/4100 loss 9.642082 loss_att 339.183716 loss_ctc 20.834663 loss_rnnt 8.398462 lr 0.00024134 rank 1
2022-12-08 14:19:40,755 DEBUG TRAIN Batch 32/4100 loss 4.612677 loss_att 373.216644 loss_ctc 11.816233 loss_rnnt 3.812282 lr 0.00024130 rank 0
2022-12-08 14:19:40,757 DEBUG TRAIN Batch 32/4100 loss 4.122425 loss_att 388.176910 loss_ctc 13.293491 loss_rnnt 3.103417 lr 0.00024133 rank 2
2022-12-08 14:20:45,133 DEBUG TRAIN Batch 32/4200 loss 10.348484 loss_att 391.146820 loss_ctc 18.669674 loss_rnnt 9.423908 lr 0.00024127 rank 0
2022-12-08 14:20:45,137 DEBUG TRAIN Batch 32/4200 loss 6.104728 loss_att 363.374756 loss_ctc 16.157734 loss_rnnt 4.987727 lr 0.00024130 rank 5
2022-12-08 14:20:45,141 DEBUG TRAIN Batch 32/4200 loss 3.660859 loss_att 376.258057 loss_ctc 8.133279 loss_rnnt 3.163923 lr 0.00024130 rank 6
2022-12-08 14:20:45,141 DEBUG TRAIN Batch 32/4200 loss 5.351232 loss_att 339.161926 loss_ctc 6.830816 loss_rnnt 5.186834 lr 0.00024127 rank 4
2022-12-08 14:20:45,145 DEBUG TRAIN Batch 32/4200 loss 3.990469 loss_att 318.956848 loss_ctc 8.813084 loss_rnnt 3.454623 lr 0.00024129 rank 3
2022-12-08 14:20:45,146 DEBUG TRAIN Batch 32/4200 loss 10.101505 loss_att 340.760559 loss_ctc 21.579952 loss_rnnt 8.826123 lr 0.00024127 rank 7
2022-12-08 14:20:45,146 DEBUG TRAIN Batch 32/4200 loss 6.296661 loss_att 326.673065 loss_ctc 10.156239 loss_rnnt 5.867819 lr 0.00024131 rank 1
2022-12-08 14:20:45,149 DEBUG TRAIN Batch 32/4200 loss 8.798960 loss_att 406.814819 loss_ctc 21.209679 loss_rnnt 7.419991 lr 0.00024130 rank 2
2022-12-08 14:21:56,953 DEBUG TRAIN Batch 32/4300 loss 4.690243 loss_att 271.367249 loss_ctc 7.127364 loss_rnnt 4.419452 lr 0.00024125 rank 7
2022-12-08 14:21:56,953 DEBUG TRAIN Batch 32/4300 loss 8.580900 loss_att 316.049713 loss_ctc 20.594654 loss_rnnt 7.246039 lr 0.00024124 rank 4
2022-12-08 14:21:56,954 DEBUG TRAIN Batch 32/4300 loss 20.609554 loss_att 382.949799 loss_ctc 33.361565 loss_rnnt 19.192665 lr 0.00024127 rank 2
2022-12-08 14:21:56,955 DEBUG TRAIN Batch 32/4300 loss 7.856591 loss_att 280.392578 loss_ctc 14.092073 loss_rnnt 7.163760 lr 0.00024128 rank 1
2022-12-08 14:21:56,959 DEBUG TRAIN Batch 32/4300 loss 6.761399 loss_att 341.559753 loss_ctc 10.689677 loss_rnnt 6.324924 lr 0.00024124 rank 0
2022-12-08 14:21:56,960 DEBUG TRAIN Batch 32/4300 loss 6.482285 loss_att 311.764832 loss_ctc 8.893251 loss_rnnt 6.214401 lr 0.00024126 rank 3
2022-12-08 14:21:56,964 DEBUG TRAIN Batch 32/4300 loss 1.624823 loss_att 325.972168 loss_ctc 3.302717 loss_rnnt 1.438390 lr 0.00024127 rank 5
2022-12-08 14:21:56,996 DEBUG TRAIN Batch 32/4300 loss 9.365321 loss_att 340.998535 loss_ctc 16.884453 loss_rnnt 8.529862 lr 0.00024128 rank 6
2022-12-08 14:23:00,698 DEBUG TRAIN Batch 32/4400 loss 6.947071 loss_att 286.440338 loss_ctc 14.909030 loss_rnnt 6.062409 lr 0.00024122 rank 7
2022-12-08 14:23:00,710 DEBUG TRAIN Batch 32/4400 loss 13.055498 loss_att 331.097717 loss_ctc 26.763309 loss_rnnt 11.532409 lr 0.00024121 rank 0
2022-12-08 14:23:00,713 DEBUG TRAIN Batch 32/4400 loss 2.237398 loss_att 383.041870 loss_ctc 4.708919 loss_rnnt 1.962785 lr 0.00024125 rank 1
2022-12-08 14:23:00,714 DEBUG TRAIN Batch 32/4400 loss 11.814655 loss_att 276.760071 loss_ctc 23.194698 loss_rnnt 10.550207 lr 0.00024124 rank 2
2022-12-08 14:23:00,716 DEBUG TRAIN Batch 32/4400 loss 6.459457 loss_att 70.215057 loss_ctc 9.996231 loss_rnnt 6.066483 lr 0.00024123 rank 3
2022-12-08 14:23:00,718 DEBUG TRAIN Batch 32/4400 loss 9.875161 loss_att 401.873596 loss_ctc 21.400116 loss_rnnt 8.594611 lr 0.00024121 rank 4
2022-12-08 14:23:00,720 DEBUG TRAIN Batch 32/4400 loss 7.666807 loss_att 245.518097 loss_ctc 12.581592 loss_rnnt 7.120720 lr 0.00024125 rank 6
2022-12-08 14:23:00,721 DEBUG TRAIN Batch 32/4400 loss 7.661063 loss_att 333.411285 loss_ctc 16.132072 loss_rnnt 6.719840 lr 0.00024125 rank 5
2022-12-08 14:24:03,492 DEBUG TRAIN Batch 32/4500 loss 1.213367 loss_att 364.889984 loss_ctc 5.906542 loss_rnnt 0.691903 lr 0.00024119 rank 7
2022-12-08 14:24:03,493 DEBUG TRAIN Batch 32/4500 loss 8.231014 loss_att 364.183228 loss_ctc 13.498652 loss_rnnt 7.645721 lr 0.00024122 rank 6
2022-12-08 14:24:03,493 DEBUG TRAIN Batch 32/4500 loss 7.605572 loss_att 400.352020 loss_ctc 13.315005 loss_rnnt 6.971191 lr 0.00024121 rank 2
2022-12-08 14:24:03,494 DEBUG TRAIN Batch 32/4500 loss 6.762661 loss_att 259.846252 loss_ctc 11.354506 loss_rnnt 6.252456 lr 0.00024119 rank 4
2022-12-08 14:24:03,494 DEBUG TRAIN Batch 32/4500 loss 2.326824 loss_att 347.247498 loss_ctc 8.657909 loss_rnnt 1.623370 lr 0.00024120 rank 3
2022-12-08 14:24:03,494 DEBUG TRAIN Batch 32/4500 loss 9.087356 loss_att 424.659485 loss_ctc 12.313627 loss_rnnt 8.728881 lr 0.00024122 rank 1
2022-12-08 14:24:03,495 DEBUG TRAIN Batch 32/4500 loss 8.085048 loss_att 104.655998 loss_ctc 11.554009 loss_rnnt 7.699607 lr 0.00024118 rank 0
2022-12-08 14:24:03,532 DEBUG TRAIN Batch 32/4500 loss 7.055507 loss_att 279.563904 loss_ctc 13.055051 loss_rnnt 6.388891 lr 0.00024122 rank 5
2022-12-08 14:25:08,957 DEBUG TRAIN Batch 32/4600 loss 6.291341 loss_att 369.088379 loss_ctc 9.001980 loss_rnnt 5.990160 lr 0.00024119 rank 2
2022-12-08 14:25:08,960 DEBUG TRAIN Batch 32/4600 loss 1.089006 loss_att 420.437592 loss_ctc 4.855664 loss_rnnt 0.670488 lr 0.00024116 rank 7
2022-12-08 14:25:08,966 DEBUG TRAIN Batch 32/4600 loss 8.607401 loss_att 419.872498 loss_ctc 22.230841 loss_rnnt 7.093685 lr 0.00024116 rank 4
2022-12-08 14:25:08,966 DEBUG TRAIN Batch 32/4600 loss 7.680948 loss_att 354.951752 loss_ctc 11.053580 loss_rnnt 7.306211 lr 0.00024118 rank 3
2022-12-08 14:25:08,967 DEBUG TRAIN Batch 32/4600 loss 4.436590 loss_att 409.707214 loss_ctc 7.769695 loss_rnnt 4.066245 lr 0.00024115 rank 0
2022-12-08 14:25:08,970 DEBUG TRAIN Batch 32/4600 loss 8.953505 loss_att 330.123779 loss_ctc 15.561466 loss_rnnt 8.219287 lr 0.00024120 rank 1
2022-12-08 14:25:08,970 DEBUG TRAIN Batch 32/4600 loss 6.395243 loss_att 400.996033 loss_ctc 13.696132 loss_rnnt 5.584033 lr 0.00024119 rank 5
2022-12-08 14:25:08,980 DEBUG TRAIN Batch 32/4600 loss 9.059093 loss_att 405.539520 loss_ctc 16.509132 loss_rnnt 8.231311 lr 0.00024119 rank 6
2022-12-08 14:26:19,045 DEBUG TRAIN Batch 32/4700 loss 7.482313 loss_att 401.857941 loss_ctc 13.346873 loss_rnnt 6.830695 lr 0.00024115 rank 3
2022-12-08 14:26:19,058 DEBUG TRAIN Batch 32/4700 loss 5.737882 loss_att 431.171967 loss_ctc 15.661914 loss_rnnt 4.635211 lr 0.00024113 rank 4
2022-12-08 14:26:19,061 DEBUG TRAIN Batch 32/4700 loss 4.436295 loss_att 423.731995 loss_ctc 9.978537 loss_rnnt 3.820490 lr 0.00024117 rank 1
2022-12-08 14:26:19,062 DEBUG TRAIN Batch 32/4700 loss 14.551719 loss_att 396.520447 loss_ctc 27.659542 loss_rnnt 13.095295 lr 0.00024116 rank 2
2022-12-08 14:26:19,063 DEBUG TRAIN Batch 32/4700 loss 2.549127 loss_att 325.990479 loss_ctc 8.035298 loss_rnnt 1.939552 lr 0.00024113 rank 7
2022-12-08 14:26:19,066 DEBUG TRAIN Batch 32/4700 loss 10.136223 loss_att 368.272705 loss_ctc 20.073681 loss_rnnt 9.032061 lr 0.00024116 rank 5
2022-12-08 14:26:19,067 DEBUG TRAIN Batch 32/4700 loss 3.921345 loss_att 348.468201 loss_ctc 7.647139 loss_rnnt 3.507368 lr 0.00024113 rank 0
2022-12-08 14:26:19,102 DEBUG TRAIN Batch 32/4700 loss 8.704746 loss_att 401.772766 loss_ctc 15.430865 loss_rnnt 7.957400 lr 0.00024116 rank 6
2022-12-08 14:27:22,449 DEBUG TRAIN Batch 32/4800 loss 3.657177 loss_att 366.722656 loss_ctc 8.859307 loss_rnnt 3.079163 lr 0.00024113 rank 2
2022-12-08 14:27:22,463 DEBUG TRAIN Batch 32/4800 loss 9.931828 loss_att 348.181671 loss_ctc 14.063452 loss_rnnt 9.472759 lr 0.00024114 rank 6
2022-12-08 14:27:22,463 DEBUG TRAIN Batch 32/4800 loss 11.124475 loss_att 378.317291 loss_ctc 21.608662 loss_rnnt 9.959566 lr 0.00024112 rank 3
2022-12-08 14:27:22,464 DEBUG TRAIN Batch 32/4800 loss 5.506695 loss_att 311.076782 loss_ctc 10.412660 loss_rnnt 4.961588 lr 0.00024114 rank 1
2022-12-08 14:27:22,464 DEBUG TRAIN Batch 32/4800 loss 5.057850 loss_att 399.728088 loss_ctc 12.615396 loss_rnnt 4.218122 lr 0.00024111 rank 7
2022-12-08 14:27:22,465 DEBUG TRAIN Batch 32/4800 loss 5.156557 loss_att 396.133057 loss_ctc 16.382584 loss_rnnt 3.909221 lr 0.00024110 rank 4
2022-12-08 14:27:22,465 DEBUG TRAIN Batch 32/4800 loss 5.515195 loss_att 330.950806 loss_ctc 7.682590 loss_rnnt 5.274374 lr 0.00024113 rank 5
2022-12-08 14:27:22,470 DEBUG TRAIN Batch 32/4800 loss 5.416588 loss_att 351.365295 loss_ctc 11.421117 loss_rnnt 4.749418 lr 0.00024110 rank 0
2022-12-08 14:28:26,091 DEBUG TRAIN Batch 32/4900 loss 9.804878 loss_att 378.433716 loss_ctc 20.870682 loss_rnnt 8.575344 lr 0.00024108 rank 7
2022-12-08 14:28:26,092 DEBUG TRAIN Batch 32/4900 loss 6.843057 loss_att 349.396667 loss_ctc 14.827733 loss_rnnt 5.955871 lr 0.00024107 rank 4
2022-12-08 14:28:26,095 DEBUG TRAIN Batch 32/4900 loss 8.493916 loss_att 319.533875 loss_ctc 13.285939 loss_rnnt 7.961469 lr 0.00024110 rank 2
2022-12-08 14:28:26,095 DEBUG TRAIN Batch 32/4900 loss 3.068670 loss_att 291.569763 loss_ctc 5.640082 loss_rnnt 2.782957 lr 0.00024111 rank 6
2022-12-08 14:28:26,097 DEBUG TRAIN Batch 32/4900 loss 6.617787 loss_att 340.142792 loss_ctc 13.750463 loss_rnnt 5.825268 lr 0.00024107 rank 0
2022-12-08 14:28:26,097 DEBUG TRAIN Batch 32/4900 loss 8.277720 loss_att 156.395569 loss_ctc 12.869452 loss_rnnt 7.767529 lr 0.00024111 rank 1
2022-12-08 14:28:26,102 DEBUG TRAIN Batch 32/4900 loss 7.039833 loss_att 396.709412 loss_ctc 11.157613 loss_rnnt 6.582302 lr 0.00024111 rank 5
2022-12-08 14:28:26,115 DEBUG TRAIN Batch 32/4900 loss 8.541084 loss_att 376.072815 loss_ctc 16.358662 loss_rnnt 7.672465 lr 0.00024109 rank 3
2022-12-08 14:29:38,495 DEBUG TRAIN Batch 32/5000 loss 4.890195 loss_att 301.826996 loss_ctc 15.057251 loss_rnnt 3.760523 lr 0.00024108 rank 6
2022-12-08 14:29:38,507 DEBUG TRAIN Batch 32/5000 loss 11.434240 loss_att 279.555511 loss_ctc 19.641668 loss_rnnt 10.522305 lr 0.00024107 rank 2
2022-12-08 14:29:38,507 DEBUG TRAIN Batch 32/5000 loss 12.572102 loss_att 362.940033 loss_ctc 19.435280 loss_rnnt 11.809526 lr 0.00024105 rank 4
2022-12-08 14:29:38,510 DEBUG TRAIN Batch 32/5000 loss 11.098711 loss_att 405.566040 loss_ctc 23.762779 loss_rnnt 9.691592 lr 0.00024105 rank 7
2022-12-08 14:29:38,512 DEBUG TRAIN Batch 32/5000 loss 8.543144 loss_att 306.468048 loss_ctc 16.420507 loss_rnnt 7.667882 lr 0.00024104 rank 0
2022-12-08 14:29:38,512 DEBUG TRAIN Batch 32/5000 loss 8.286043 loss_att 167.934464 loss_ctc 17.373495 loss_rnnt 7.276326 lr 0.00024106 rank 3
2022-12-08 14:29:38,512 DEBUG TRAIN Batch 32/5000 loss 8.699408 loss_att 325.293945 loss_ctc 13.302460 loss_rnnt 8.187958 lr 0.00024108 rank 5
2022-12-08 14:29:38,513 DEBUG TRAIN Batch 32/5000 loss 3.835384 loss_att 333.497437 loss_ctc 6.275995 loss_rnnt 3.564205 lr 0.00024108 rank 1
2022-12-08 14:30:42,780 DEBUG TRAIN Batch 32/5100 loss 13.408482 loss_att 327.222473 loss_ctc 24.891283 loss_rnnt 12.132615 lr 0.00024105 rank 5
2022-12-08 14:30:42,790 DEBUG TRAIN Batch 32/5100 loss 12.043177 loss_att 312.681335 loss_ctc 32.270325 loss_rnnt 9.795716 lr 0.00024102 rank 4
2022-12-08 14:30:42,792 DEBUG TRAIN Batch 32/5100 loss 13.084826 loss_att 368.332092 loss_ctc 27.420227 loss_rnnt 11.492003 lr 0.00024104 rank 3
2022-12-08 14:30:42,793 DEBUG TRAIN Batch 32/5100 loss 7.855804 loss_att 226.389084 loss_ctc 12.419917 loss_rnnt 7.348680 lr 0.00024101 rank 0
2022-12-08 14:30:42,794 DEBUG TRAIN Batch 32/5100 loss 1.973841 loss_att 301.849945 loss_ctc 7.298477 loss_rnnt 1.382215 lr 0.00024106 rank 1
2022-12-08 14:30:42,795 DEBUG TRAIN Batch 32/5100 loss 5.893854 loss_att 402.405029 loss_ctc 21.536381 loss_rnnt 4.155796 lr 0.00024105 rank 2
2022-12-08 14:30:42,798 DEBUG TRAIN Batch 32/5100 loss 7.100878 loss_att 182.569870 loss_ctc 14.178387 loss_rnnt 6.314488 lr 0.00024102 rank 7
2022-12-08 14:30:42,835 DEBUG TRAIN Batch 32/5100 loss 9.759319 loss_att 81.574524 loss_ctc 13.607752 loss_rnnt 9.331717 lr 0.00024105 rank 6
2022-12-08 14:31:45,719 DEBUG TRAIN Batch 32/5200 loss 9.517549 loss_att 401.452942 loss_ctc 15.042171 loss_rnnt 8.903702 lr 0.00024102 rank 2
2022-12-08 14:31:45,722 DEBUG TRAIN Batch 32/5200 loss 4.973228 loss_att 394.380463 loss_ctc 7.043159 loss_rnnt 4.743237 lr 0.00024099 rank 0
2022-12-08 14:31:45,724 DEBUG TRAIN Batch 32/5200 loss 5.498902 loss_att 415.270111 loss_ctc 12.254519 loss_rnnt 4.748278 lr 0.00024099 rank 7
2022-12-08 14:31:45,724 DEBUG TRAIN Batch 32/5200 loss 8.060737 loss_att 187.220642 loss_ctc 16.180897 loss_rnnt 7.158497 lr 0.00024099 rank 4
2022-12-08 14:31:45,729 DEBUG TRAIN Batch 32/5200 loss 7.265379 loss_att 221.992889 loss_ctc 12.871905 loss_rnnt 6.642432 lr 0.00024102 rank 5
2022-12-08 14:31:45,729 DEBUG TRAIN Batch 32/5200 loss 5.699156 loss_att 376.101868 loss_ctc 11.456355 loss_rnnt 5.059468 lr 0.00024103 rank 1
2022-12-08 14:31:45,730 DEBUG TRAIN Batch 32/5200 loss 18.532295 loss_att 373.505951 loss_ctc 37.259304 loss_rnnt 16.451517 lr 0.00024101 rank 3
2022-12-08 14:31:45,767 DEBUG TRAIN Batch 32/5200 loss 1.521695 loss_att 380.576355 loss_ctc 3.742689 loss_rnnt 1.274917 lr 0.00024102 rank 6
2022-12-08 14:32:50,834 DEBUG TRAIN Batch 32/5300 loss 2.083944 loss_att 307.680389 loss_ctc 2.929955 loss_rnnt 1.989943 lr 0.00024096 rank 0
2022-12-08 14:32:50,835 DEBUG TRAIN Batch 32/5300 loss 8.022253 loss_att 406.108521 loss_ctc 19.486708 loss_rnnt 6.748425 lr 0.00024098 rank 3
2022-12-08 14:32:50,835 DEBUG TRAIN Batch 32/5300 loss 1.885686 loss_att 327.052612 loss_ctc 5.262887 loss_rnnt 1.510441 lr 0.00024100 rank 1
2022-12-08 14:32:50,835 DEBUG TRAIN Batch 32/5300 loss 10.622327 loss_att 352.732239 loss_ctc 14.929405 loss_rnnt 10.143763 lr 0.00024097 rank 7
2022-12-08 14:32:50,835 DEBUG TRAIN Batch 32/5300 loss 7.874206 loss_att 375.061371 loss_ctc 14.308868 loss_rnnt 7.159244 lr 0.00024100 rank 6
2022-12-08 14:32:50,838 DEBUG TRAIN Batch 32/5300 loss 3.218934 loss_att 393.121887 loss_ctc 9.371699 loss_rnnt 2.535294 lr 0.00024099 rank 2
2022-12-08 14:32:50,839 DEBUG TRAIN Batch 32/5300 loss 2.353524 loss_att 448.474945 loss_ctc 9.664415 loss_rnnt 1.541203 lr 0.00024096 rank 4
2022-12-08 14:32:50,839 DEBUG TRAIN Batch 32/5300 loss 1.934886 loss_att 513.747009 loss_ctc 9.455144 loss_rnnt 1.099302 lr 0.00024099 rank 5
2022-12-08 14:34:01,304 DEBUG TRAIN Batch 32/5400 loss 8.926408 loss_att 339.452454 loss_ctc 15.490708 loss_rnnt 8.197042 lr 0.00024097 rank 1
2022-12-08 14:34:01,316 DEBUG TRAIN Batch 32/5400 loss 13.767749 loss_att 436.917297 loss_ctc 15.993826 loss_rnnt 13.520408 lr 0.00024093 rank 4
2022-12-08 14:34:01,320 DEBUG TRAIN Batch 32/5400 loss 6.530031 loss_att 361.623657 loss_ctc 15.791838 loss_rnnt 5.500942 lr 0.00024097 rank 5
2022-12-08 14:34:01,320 DEBUG TRAIN Batch 32/5400 loss 3.619479 loss_att 332.164429 loss_ctc 8.142348 loss_rnnt 3.116938 lr 0.00024095 rank 3
2022-12-08 14:34:01,320 DEBUG TRAIN Batch 32/5400 loss 8.927024 loss_att 401.274994 loss_ctc 15.913549 loss_rnnt 8.150743 lr 0.00024097 rank 6
2022-12-08 14:34:01,321 DEBUG TRAIN Batch 32/5400 loss 7.547644 loss_att 315.032776 loss_ctc 15.529573 loss_rnnt 6.660762 lr 0.00024094 rank 7
2022-12-08 14:34:01,322 DEBUG TRAIN Batch 32/5400 loss 8.434237 loss_att 358.145996 loss_ctc 21.021139 loss_rnnt 7.035692 lr 0.00024096 rank 2
2022-12-08 14:34:01,323 DEBUG TRAIN Batch 32/5400 loss 8.655954 loss_att 422.925598 loss_ctc 16.125336 loss_rnnt 7.826023 lr 0.00024093 rank 0
2022-12-08 14:35:04,320 DEBUG TRAIN Batch 32/5500 loss 4.414530 loss_att 375.870850 loss_ctc 10.639470 loss_rnnt 3.722870 lr 0.00024091 rank 4
2022-12-08 14:35:04,322 DEBUG TRAIN Batch 32/5500 loss 12.771353 loss_att 366.197510 loss_ctc 19.244970 loss_rnnt 12.052063 lr 0.00024094 rank 6
2022-12-08 14:35:04,324 DEBUG TRAIN Batch 32/5500 loss 12.230784 loss_att 455.953156 loss_ctc 22.311155 loss_rnnt 11.110744 lr 0.00024090 rank 0
2022-12-08 14:35:04,325 DEBUG TRAIN Batch 32/5500 loss 8.418407 loss_att 349.723480 loss_ctc 17.691624 loss_rnnt 7.388050 lr 0.00024091 rank 7
2022-12-08 14:35:04,326 DEBUG TRAIN Batch 32/5500 loss 2.776618 loss_att 351.699219 loss_ctc 3.590364 loss_rnnt 2.686202 lr 0.00024092 rank 3
2022-12-08 14:35:04,331 DEBUG TRAIN Batch 32/5500 loss 5.755087 loss_att 396.674561 loss_ctc 8.226839 loss_rnnt 5.480448 lr 0.00024094 rank 5
2022-12-08 14:35:04,334 DEBUG TRAIN Batch 32/5500 loss 13.783710 loss_att 290.086273 loss_ctc 24.330931 loss_rnnt 12.611796 lr 0.00024094 rank 1
2022-12-08 14:35:04,367 DEBUG TRAIN Batch 32/5500 loss 3.794859 loss_att 301.344940 loss_ctc 7.105495 loss_rnnt 3.427011 lr 0.00024093 rank 2
2022-12-08 14:36:09,041 DEBUG TRAIN Batch 32/5600 loss 9.462934 loss_att 386.495300 loss_ctc 16.000538 loss_rnnt 8.736534 lr 0.00024088 rank 4
2022-12-08 14:36:09,041 DEBUG TRAIN Batch 32/5600 loss 6.496169 loss_att 285.754578 loss_ctc 12.259456 loss_rnnt 5.855804 lr 0.00024091 rank 2
2022-12-08 14:36:09,043 DEBUG TRAIN Batch 32/5600 loss 9.125564 loss_att 252.826141 loss_ctc 17.003061 loss_rnnt 8.250286 lr 0.00024090 rank 3
2022-12-08 14:36:09,044 DEBUG TRAIN Batch 32/5600 loss 13.306331 loss_att 384.675659 loss_ctc 21.971218 loss_rnnt 12.343566 lr 0.00024091 rank 5
2022-12-08 14:36:09,046 DEBUG TRAIN Batch 32/5600 loss 5.482469 loss_att 313.954224 loss_ctc 12.652086 loss_rnnt 4.685844 lr 0.00024087 rank 0
2022-12-08 14:36:09,046 DEBUG TRAIN Batch 32/5600 loss 12.772310 loss_att 380.902588 loss_ctc 22.033838 loss_rnnt 11.743252 lr 0.00024091 rank 6
2022-12-08 14:36:09,047 DEBUG TRAIN Batch 32/5600 loss 11.805925 loss_att 355.252991 loss_ctc 20.902580 loss_rnnt 10.795185 lr 0.00024088 rank 7
2022-12-08 14:36:09,084 DEBUG TRAIN Batch 32/5600 loss 12.482953 loss_att 389.251709 loss_ctc 19.592543 loss_rnnt 11.692999 lr 0.00024092 rank 1
2022-12-08 14:37:21,653 DEBUG TRAIN Batch 32/5700 loss 8.750767 loss_att 354.709930 loss_ctc 16.840027 loss_rnnt 7.851960 lr 0.00024085 rank 4
2022-12-08 14:37:21,654 DEBUG TRAIN Batch 32/5700 loss 10.157199 loss_att 74.237953 loss_ctc 14.558461 loss_rnnt 9.668170 lr 0.00024088 rank 2
2022-12-08 14:37:21,656 DEBUG TRAIN Batch 32/5700 loss 5.032074 loss_att 342.416321 loss_ctc 13.313335 loss_rnnt 4.111934 lr 0.00024088 rank 5
2022-12-08 14:37:21,657 DEBUG TRAIN Batch 32/5700 loss 4.219941 loss_att 425.517334 loss_ctc 14.064926 loss_rnnt 3.126053 lr 0.00024087 rank 3
2022-12-08 14:37:21,658 DEBUG TRAIN Batch 32/5700 loss 6.175206 loss_att 276.029541 loss_ctc 12.324862 loss_rnnt 5.491910 lr 0.00024085 rank 7
2022-12-08 14:37:21,658 DEBUG TRAIN Batch 32/5700 loss 8.771260 loss_att 478.170990 loss_ctc 21.155167 loss_rnnt 7.395271 lr 0.00024089 rank 1
2022-12-08 14:37:21,658 DEBUG TRAIN Batch 32/5700 loss 5.815113 loss_att 275.874451 loss_ctc 13.654475 loss_rnnt 4.944072 lr 0.00024085 rank 0
2022-12-08 14:37:21,663 DEBUG TRAIN Batch 32/5700 loss 7.928396 loss_att 275.072876 loss_ctc 12.731281 loss_rnnt 7.394742 lr 0.00024088 rank 6
2022-12-08 14:38:25,779 DEBUG TRAIN Batch 32/5800 loss 9.204279 loss_att 228.676468 loss_ctc 16.026707 loss_rnnt 8.446232 lr 0.00024082 rank 4
2022-12-08 14:38:25,780 DEBUG TRAIN Batch 32/5800 loss 3.855518 loss_att 367.467773 loss_ctc 12.377903 loss_rnnt 2.908587 lr 0.00024083 rank 7
2022-12-08 14:38:25,781 DEBUG TRAIN Batch 32/5800 loss 17.590614 loss_att 418.920746 loss_ctc 42.724274 loss_rnnt 14.797987 lr 0.00024084 rank 3
2022-12-08 14:38:25,783 DEBUG TRAIN Batch 32/5800 loss 9.700795 loss_att 409.169861 loss_ctc 28.048986 loss_rnnt 7.662107 lr 0.00024085 rank 2
2022-12-08 14:38:25,785 DEBUG TRAIN Batch 32/5800 loss 2.741672 loss_att 408.393524 loss_ctc 8.265669 loss_rnnt 2.127894 lr 0.00024086 rank 6
2022-12-08 14:38:25,786 DEBUG TRAIN Batch 32/5800 loss 3.149455 loss_att 465.124878 loss_ctc 8.381758 loss_rnnt 2.568088 lr 0.00024082 rank 0
2022-12-08 14:38:25,786 DEBUG TRAIN Batch 32/5800 loss 9.386465 loss_att 370.816620 loss_ctc 26.117743 loss_rnnt 7.527435 lr 0.00024086 rank 1
2022-12-08 14:38:25,791 DEBUG TRAIN Batch 32/5800 loss 4.198610 loss_att 299.753174 loss_ctc 7.115707 loss_rnnt 3.874488 lr 0.00024085 rank 5
2022-12-08 14:39:29,550 DEBUG TRAIN Batch 32/5900 loss 6.050967 loss_att 317.709473 loss_ctc 10.566496 loss_rnnt 5.549242 lr 0.00024079 rank 4
2022-12-08 14:39:29,553 DEBUG TRAIN Batch 32/5900 loss 9.548062 loss_att 369.089783 loss_ctc 14.277946 loss_rnnt 9.022520 lr 0.00024082 rank 2
2022-12-08 14:39:29,554 DEBUG TRAIN Batch 32/5900 loss 6.154843 loss_att 444.739838 loss_ctc 14.461096 loss_rnnt 5.231926 lr 0.00024083 rank 6
2022-12-08 14:39:29,554 DEBUG TRAIN Batch 32/5900 loss 5.737327 loss_att 368.838318 loss_ctc 10.894733 loss_rnnt 5.164282 lr 0.00024080 rank 7
2022-12-08 14:39:29,555 DEBUG TRAIN Batch 32/5900 loss 5.690021 loss_att 403.002289 loss_ctc 12.802084 loss_rnnt 4.899792 lr 0.00024079 rank 0
2022-12-08 14:39:29,556 DEBUG TRAIN Batch 32/5900 loss 8.526238 loss_att 98.203415 loss_ctc 14.046568 loss_rnnt 7.912868 lr 0.00024083 rank 5
2022-12-08 14:39:29,560 DEBUG TRAIN Batch 32/5900 loss 7.634210 loss_att 390.268311 loss_ctc 11.225224 loss_rnnt 7.235208 lr 0.00024081 rank 3
2022-12-08 14:39:29,594 DEBUG TRAIN Batch 32/5900 loss 9.257812 loss_att 416.349915 loss_ctc 23.142824 loss_rnnt 7.715034 lr 0.00024083 rank 1
2022-12-08 14:40:34,741 DEBUG TRAIN Batch 32/6000 loss 5.702339 loss_att 360.523560 loss_ctc 10.380778 loss_rnnt 5.182513 lr 0.00024078 rank 3
2022-12-08 14:40:34,750 DEBUG TRAIN Batch 32/6000 loss 13.113862 loss_att 376.746002 loss_ctc 23.178635 loss_rnnt 11.995554 lr 0.00024079 rank 2
2022-12-08 14:40:34,752 DEBUG TRAIN Batch 32/6000 loss 6.683907 loss_att 342.530365 loss_ctc 12.766199 loss_rnnt 6.008096 lr 0.00024077 rank 4
2022-12-08 14:40:34,754 DEBUG TRAIN Batch 32/6000 loss 2.998896 loss_att 310.503265 loss_ctc 7.835472 loss_rnnt 2.461498 lr 0.00024080 rank 1
2022-12-08 14:40:34,756 DEBUG TRAIN Batch 32/6000 loss 4.540511 loss_att 382.446899 loss_ctc 12.434677 loss_rnnt 3.663382 lr 0.00024076 rank 0
2022-12-08 14:40:34,757 DEBUG TRAIN Batch 32/6000 loss 6.905126 loss_att 414.376251 loss_ctc 18.839767 loss_rnnt 5.579055 lr 0.00024077 rank 7
2022-12-08 14:40:34,759 DEBUG TRAIN Batch 32/6000 loss 2.842131 loss_att 384.973633 loss_ctc 9.298048 loss_rnnt 2.124807 lr 0.00024080 rank 5
2022-12-08 14:40:34,771 DEBUG TRAIN Batch 32/6000 loss 5.978452 loss_att 446.128479 loss_ctc 11.634830 loss_rnnt 5.349966 lr 0.00024080 rank 6
2022-12-08 14:41:48,344 DEBUG TRAIN Batch 32/6100 loss 10.184810 loss_att 366.600189 loss_ctc 20.235851 loss_rnnt 9.068027 lr 0.00024077 rank 2
2022-12-08 14:41:48,346 DEBUG TRAIN Batch 32/6100 loss 3.926871 loss_att 341.777283 loss_ctc 15.620321 loss_rnnt 2.627599 lr 0.00024074 rank 7
2022-12-08 14:41:48,346 DEBUG TRAIN Batch 32/6100 loss 12.794964 loss_att 455.030640 loss_ctc 25.322634 loss_rnnt 11.403000 lr 0.00024077 rank 6
2022-12-08 14:41:48,348 DEBUG TRAIN Batch 32/6100 loss 3.079919 loss_att 326.265289 loss_ctc 9.265221 loss_rnnt 2.392664 lr 0.00024074 rank 0
2022-12-08 14:41:48,349 DEBUG TRAIN Batch 32/6100 loss 5.656048 loss_att 280.720337 loss_ctc 7.801892 loss_rnnt 5.417622 lr 0.00024078 rank 1
2022-12-08 14:41:48,351 DEBUG TRAIN Batch 32/6100 loss 8.313204 loss_att 359.536743 loss_ctc 16.734997 loss_rnnt 7.377449 lr 0.00024074 rank 4
2022-12-08 14:41:48,353 DEBUG TRAIN Batch 32/6100 loss 5.517979 loss_att 349.034882 loss_ctc 13.077679 loss_rnnt 4.678012 lr 0.00024076 rank 3
2022-12-08 14:41:48,391 DEBUG TRAIN Batch 32/6100 loss 7.197423 loss_att 380.649841 loss_ctc 15.386367 loss_rnnt 6.287540 lr 0.00024077 rank 5
2022-12-08 14:42:51,981 DEBUG TRAIN Batch 32/6200 loss 13.957932 loss_att 440.084320 loss_ctc 32.733921 loss_rnnt 11.871710 lr 0.00024071 rank 4
2022-12-08 14:42:51,982 DEBUG TRAIN Batch 32/6200 loss 6.145551 loss_att 337.425049 loss_ctc 11.411099 loss_rnnt 5.560490 lr 0.00024071 rank 7
2022-12-08 14:42:51,984 DEBUG TRAIN Batch 32/6200 loss 7.016914 loss_att 390.307220 loss_ctc 13.113253 loss_rnnt 6.339543 lr 0.00024074 rank 6
2022-12-08 14:42:51,984 DEBUG TRAIN Batch 32/6200 loss 4.178828 loss_att 186.517624 loss_ctc 7.590314 loss_rnnt 3.799774 lr 0.00024075 rank 1
2022-12-08 14:42:51,988 DEBUG TRAIN Batch 32/6200 loss 10.984917 loss_att 313.297485 loss_ctc 18.270199 loss_rnnt 10.175442 lr 0.00024073 rank 3
2022-12-08 14:42:51,988 DEBUG TRAIN Batch 32/6200 loss 5.620142 loss_att 325.488922 loss_ctc 11.446159 loss_rnnt 4.972806 lr 0.00024074 rank 5
2022-12-08 14:42:51,989 DEBUG TRAIN Batch 32/6200 loss 7.782043 loss_att 356.446594 loss_ctc 13.836277 loss_rnnt 7.109351 lr 0.00024074 rank 2
2022-12-08 14:42:51,991 DEBUG TRAIN Batch 32/6200 loss 7.156476 loss_att 383.121582 loss_ctc 15.122698 loss_rnnt 6.271340 lr 0.00024071 rank 0
2022-12-08 14:43:56,002 DEBUG TRAIN Batch 32/6300 loss 13.346933 loss_att 192.517441 loss_ctc 18.307800 loss_rnnt 12.795727 lr 0.00024071 rank 2
2022-12-08 14:43:56,003 DEBUG TRAIN Batch 32/6300 loss 6.647056 loss_att 329.178894 loss_ctc 18.042381 loss_rnnt 5.380909 lr 0.00024072 rank 6
2022-12-08 14:43:56,004 DEBUG TRAIN Batch 32/6300 loss 17.663866 loss_att 290.392822 loss_ctc 33.045757 loss_rnnt 15.954768 lr 0.00024069 rank 7
2022-12-08 14:43:56,005 DEBUG TRAIN Batch 32/6300 loss 8.159221 loss_att 363.274628 loss_ctc 13.642299 loss_rnnt 7.549990 lr 0.00024068 rank 0
2022-12-08 14:43:56,005 DEBUG TRAIN Batch 32/6300 loss 5.817073 loss_att 363.208191 loss_ctc 15.268099 loss_rnnt 4.766959 lr 0.00024068 rank 4
2022-12-08 14:43:56,006 DEBUG TRAIN Batch 32/6300 loss 9.952994 loss_att 357.472656 loss_ctc 11.601522 loss_rnnt 9.769825 lr 0.00024070 rank 3
2022-12-08 14:43:56,014 DEBUG TRAIN Batch 32/6300 loss 3.155965 loss_att 352.370575 loss_ctc 6.461913 loss_rnnt 2.788637 lr 0.00024072 rank 1
2022-12-08 14:43:56,045 DEBUG TRAIN Batch 32/6300 loss 6.982190 loss_att 401.010590 loss_ctc 14.053728 loss_rnnt 6.196464 lr 0.00024071 rank 5
2022-12-08 14:45:08,703 DEBUG TRAIN Batch 32/6400 loss 5.346259 loss_att 467.951141 loss_ctc 13.823360 loss_rnnt 4.404359 lr 0.00024066 rank 7
2022-12-08 14:45:08,705 DEBUG TRAIN Batch 32/6400 loss 15.166592 loss_att 343.066132 loss_ctc 28.562445 loss_rnnt 13.678164 lr 0.00024065 rank 4
2022-12-08 14:45:08,706 DEBUG TRAIN Batch 32/6400 loss 5.875249 loss_att 327.262512 loss_ctc 11.195229 loss_rnnt 5.284141 lr 0.00024069 rank 5
2022-12-08 14:45:08,708 DEBUG TRAIN Batch 32/6400 loss 9.137488 loss_att 438.351562 loss_ctc 17.795872 loss_rnnt 8.175447 lr 0.00024069 rank 1
2022-12-08 14:45:08,709 DEBUG TRAIN Batch 32/6400 loss 7.120691 loss_att 438.051636 loss_ctc 12.755394 loss_rnnt 6.494614 lr 0.00024068 rank 2
2022-12-08 14:45:08,710 DEBUG TRAIN Batch 32/6400 loss 6.461479 loss_att 117.157501 loss_ctc 13.281860 loss_rnnt 5.703659 lr 0.00024065 rank 0
2022-12-08 14:45:08,717 DEBUG TRAIN Batch 32/6400 loss 4.532634 loss_att 171.700882 loss_ctc 8.035797 loss_rnnt 4.143394 lr 0.00024069 rank 6
2022-12-08 14:45:08,718 DEBUG TRAIN Batch 32/6400 loss 3.885702 loss_att 380.310547 loss_ctc 9.361649 loss_rnnt 3.277263 lr 0.00024067 rank 3
2022-12-08 14:46:12,360 DEBUG TRAIN Batch 32/6500 loss 7.954345 loss_att 409.630859 loss_ctc 16.875616 loss_rnnt 6.963093 lr 0.00024063 rank 7
2022-12-08 14:46:12,365 DEBUG TRAIN Batch 32/6500 loss 5.896253 loss_att 220.245819 loss_ctc 11.194770 loss_rnnt 5.307529 lr 0.00024066 rank 5
2022-12-08 14:46:12,365 DEBUG TRAIN Batch 32/6500 loss 5.578579 loss_att 389.806152 loss_ctc 7.791284 loss_rnnt 5.332723 lr 0.00024065 rank 2
2022-12-08 14:46:12,367 DEBUG TRAIN Batch 32/6500 loss 7.434425 loss_att 401.020020 loss_ctc 10.343147 loss_rnnt 7.111234 lr 0.00024066 rank 6
2022-12-08 14:46:12,368 DEBUG TRAIN Batch 32/6500 loss 2.403450 loss_att 363.320007 loss_ctc 7.033623 loss_rnnt 1.888987 lr 0.00024066 rank 1
2022-12-08 14:46:12,371 DEBUG TRAIN Batch 32/6500 loss 3.867151 loss_att 347.854248 loss_ctc 4.934825 loss_rnnt 3.748521 lr 0.00024062 rank 0
2022-12-08 14:46:12,373 DEBUG TRAIN Batch 32/6500 loss 3.511744 loss_att 377.138977 loss_ctc 7.155960 loss_rnnt 3.106831 lr 0.00024063 rank 4
2022-12-08 14:46:12,376 DEBUG TRAIN Batch 32/6500 loss 3.921488 loss_att 324.460327 loss_ctc 8.923770 loss_rnnt 3.365679 lr 0.00024064 rank 3
2022-12-08 14:47:15,680 DEBUG TRAIN Batch 32/6600 loss 8.646705 loss_att 354.755981 loss_ctc 19.391220 loss_rnnt 7.452869 lr 0.00024062 rank 3
2022-12-08 14:47:15,680 DEBUG TRAIN Batch 32/6600 loss 8.367031 loss_att 360.991943 loss_ctc 15.409686 loss_rnnt 7.584514 lr 0.00024060 rank 4
2022-12-08 14:47:15,680 DEBUG TRAIN Batch 32/6600 loss 11.717404 loss_att 341.138519 loss_ctc 25.353210 loss_rnnt 10.202315 lr 0.00024063 rank 2
2022-12-08 14:47:15,681 DEBUG TRAIN Batch 32/6600 loss 7.934311 loss_att 410.143402 loss_ctc 16.035847 loss_rnnt 7.034141 lr 0.00024063 rank 6
2022-12-08 14:47:15,681 DEBUG TRAIN Batch 32/6600 loss 7.590362 loss_att 361.579346 loss_ctc 15.259600 loss_rnnt 6.738225 lr 0.00024060 rank 7
2022-12-08 14:47:15,683 DEBUG TRAIN Batch 32/6600 loss 9.323698 loss_att 431.764832 loss_ctc 24.723579 loss_rnnt 7.612600 lr 0.00024060 rank 0
2022-12-08 14:47:15,687 DEBUG TRAIN Batch 32/6600 loss 6.810266 loss_att 349.497528 loss_ctc 10.681607 loss_rnnt 6.380116 lr 0.00024064 rank 1
2022-12-08 14:47:15,693 DEBUG TRAIN Batch 32/6600 loss 6.790185 loss_att 386.572845 loss_ctc 18.229559 loss_rnnt 5.519144 lr 0.00024063 rank 5
2022-12-08 14:48:19,923 DEBUG TRAIN Batch 32/6700 loss 8.927611 loss_att 383.108337 loss_ctc 15.983557 loss_rnnt 8.143618 lr 0.00024060 rank 6
2022-12-08 14:48:19,929 DEBUG TRAIN Batch 32/6700 loss 11.472795 loss_att 376.009247 loss_ctc 19.475557 loss_rnnt 10.583599 lr 0.00024060 rank 2
2022-12-08 14:48:19,929 DEBUG TRAIN Batch 32/6700 loss 4.643199 loss_att 377.892700 loss_ctc 8.822766 loss_rnnt 4.178802 lr 0.00024057 rank 0
2022-12-08 14:48:19,931 DEBUG TRAIN Batch 32/6700 loss 1.922056 loss_att 346.247406 loss_ctc 5.346238 loss_rnnt 1.541591 lr 0.00024059 rank 3
2022-12-08 14:48:19,932 DEBUG TRAIN Batch 32/6700 loss 6.072977 loss_att 314.838776 loss_ctc 10.105245 loss_rnnt 5.624948 lr 0.00024061 rank 1
2022-12-08 14:48:19,938 DEBUG TRAIN Batch 32/6700 loss 3.389719 loss_att 365.752411 loss_ctc 6.188415 loss_rnnt 3.078753 lr 0.00024057 rank 7
2022-12-08 14:48:19,948 DEBUG TRAIN Batch 32/6700 loss 15.565453 loss_att 438.964203 loss_ctc 29.637716 loss_rnnt 14.001868 lr 0.00024057 rank 4
2022-12-08 14:48:19,950 DEBUG TRAIN Batch 32/6700 loss 3.352033 loss_att 365.347778 loss_ctc 7.914798 loss_rnnt 2.845059 lr 0.00024060 rank 5
2022-12-08 14:49:30,879 DEBUG TRAIN Batch 32/6800 loss 13.548936 loss_att 388.643188 loss_ctc 21.693991 loss_rnnt 12.643929 lr 0.00024054 rank 4
2022-12-08 14:49:30,883 DEBUG TRAIN Batch 32/6800 loss 6.418272 loss_att 364.549103 loss_ctc 13.261675 loss_rnnt 5.657894 lr 0.00024055 rank 7
2022-12-08 14:49:30,884 DEBUG TRAIN Batch 32/6800 loss 6.488012 loss_att 301.432648 loss_ctc 10.355225 loss_rnnt 6.058322 lr 0.00024056 rank 3
2022-12-08 14:49:30,887 DEBUG TRAIN Batch 32/6800 loss 7.875060 loss_att 368.875580 loss_ctc 15.982912 loss_rnnt 6.974187 lr 0.00024054 rank 0
2022-12-08 14:49:30,888 DEBUG TRAIN Batch 32/6800 loss 4.381993 loss_att 344.053894 loss_ctc 10.199188 loss_rnnt 3.735638 lr 0.00024057 rank 5
2022-12-08 14:49:30,889 DEBUG TRAIN Batch 32/6800 loss 9.410755 loss_att 368.938019 loss_ctc 19.441513 loss_rnnt 8.296227 lr 0.00024058 rank 6
2022-12-08 14:49:30,891 DEBUG TRAIN Batch 32/6800 loss 11.603484 loss_att 287.982086 loss_ctc 19.141813 loss_rnnt 10.765892 lr 0.00024058 rank 1
2022-12-08 14:49:30,926 DEBUG TRAIN Batch 32/6800 loss 6.257938 loss_att 332.571625 loss_ctc 12.286035 loss_rnnt 5.588150 lr 0.00024057 rank 2
2022-12-08 14:50:34,460 DEBUG TRAIN Batch 32/6900 loss 8.708028 loss_att 295.413757 loss_ctc 20.853168 loss_rnnt 7.358568 lr 0.00024052 rank 7
2022-12-08 14:50:34,464 DEBUG TRAIN Batch 32/6900 loss 7.874668 loss_att 325.773865 loss_ctc 15.042182 loss_rnnt 7.078278 lr 0.00024055 rank 6
2022-12-08 14:50:34,465 DEBUG TRAIN Batch 32/6900 loss 2.086693 loss_att 305.137207 loss_ctc 4.819174 loss_rnnt 1.783084 lr 0.00024051 rank 4
2022-12-08 14:50:34,465 DEBUG TRAIN Batch 32/6900 loss 5.344851 loss_att 143.839630 loss_ctc 10.811867 loss_rnnt 4.737404 lr 0.00024053 rank 3
2022-12-08 14:50:34,466 DEBUG TRAIN Batch 32/6900 loss 13.535189 loss_att 268.378967 loss_ctc 22.301619 loss_rnnt 12.561141 lr 0.00024054 rank 2
2022-12-08 14:50:34,468 DEBUG TRAIN Batch 32/6900 loss 2.613870 loss_att 403.598145 loss_ctc 3.911766 loss_rnnt 2.469659 lr 0.00024055 rank 1
2022-12-08 14:50:34,468 DEBUG TRAIN Batch 32/6900 loss 14.422773 loss_att 404.539886 loss_ctc 22.849514 loss_rnnt 13.486469 lr 0.00024055 rank 5
2022-12-08 14:50:34,473 DEBUG TRAIN Batch 32/6900 loss 4.314535 loss_att 315.089844 loss_ctc 8.655276 loss_rnnt 3.832230 lr 0.00024051 rank 0
2022-12-08 14:51:38,265 DEBUG TRAIN Batch 32/7000 loss 6.116820 loss_att 95.206612 loss_ctc 10.816533 loss_rnnt 5.594630 lr 0.00024049 rank 7
2022-12-08 14:51:38,266 DEBUG TRAIN Batch 32/7000 loss 8.822943 loss_att 220.889618 loss_ctc 13.743096 loss_rnnt 8.276259 lr 0.00024052 rank 6
2022-12-08 14:51:38,268 DEBUG TRAIN Batch 32/7000 loss 2.629324 loss_att 311.668121 loss_ctc 7.021004 loss_rnnt 2.141359 lr 0.00024049 rank 4
2022-12-08 14:51:38,270 DEBUG TRAIN Batch 32/7000 loss 3.747183 loss_att 387.888123 loss_ctc 11.253117 loss_rnnt 2.913191 lr 0.00024051 rank 2
2022-12-08 14:51:38,271 DEBUG TRAIN Batch 32/7000 loss 4.765883 loss_att 328.937378 loss_ctc 9.122076 loss_rnnt 4.281862 lr 0.00024051 rank 3
2022-12-08 14:51:38,271 DEBUG TRAIN Batch 32/7000 loss 12.278652 loss_att 429.545471 loss_ctc 26.374113 loss_rnnt 10.712490 lr 0.00024053 rank 1
2022-12-08 14:51:38,273 DEBUG TRAIN Batch 32/7000 loss 7.916411 loss_att 111.389832 loss_ctc 13.193117 loss_rnnt 7.330111 lr 0.00024048 rank 0
2022-12-08 14:51:38,277 DEBUG TRAIN Batch 32/7000 loss 9.763492 loss_att 340.903320 loss_ctc 17.386316 loss_rnnt 8.916512 lr 0.00024052 rank 5
2022-12-08 14:52:50,760 DEBUG TRAIN Batch 32/7100 loss 9.702004 loss_att 349.582581 loss_ctc 16.370167 loss_rnnt 8.961099 lr 0.00024049 rank 5
2022-12-08 14:52:50,765 DEBUG TRAIN Batch 32/7100 loss 6.693256 loss_att 132.325592 loss_ctc 14.517254 loss_rnnt 5.823923 lr 0.00024046 rank 4
2022-12-08 14:52:50,765 DEBUG TRAIN Batch 32/7100 loss 7.341665 loss_att 386.782471 loss_ctc 14.360435 loss_rnnt 6.561802 lr 0.00024046 rank 7
2022-12-08 14:52:50,770 DEBUG TRAIN Batch 32/7100 loss 10.818079 loss_att 427.349731 loss_ctc 33.560486 loss_rnnt 8.291145 lr 0.00024050 rank 1
2022-12-08 14:52:50,770 DEBUG TRAIN Batch 32/7100 loss 7.933870 loss_att 419.331116 loss_ctc 20.182793 loss_rnnt 6.572879 lr 0.00024049 rank 6
2022-12-08 14:52:50,771 DEBUG TRAIN Batch 32/7100 loss 1.669953 loss_att 369.082214 loss_ctc 5.809202 loss_rnnt 1.210037 lr 0.00024048 rank 3
2022-12-08 14:52:50,774 DEBUG TRAIN Batch 32/7100 loss 9.852317 loss_att 469.219910 loss_ctc 19.748043 loss_rnnt 8.752792 lr 0.00024046 rank 0
2022-12-08 14:52:50,774 DEBUG TRAIN Batch 32/7100 loss 5.857513 loss_att 388.124268 loss_ctc 11.255267 loss_rnnt 5.257763 lr 0.00024049 rank 2
2022-12-08 14:53:54,461 DEBUG TRAIN Batch 32/7200 loss 12.622211 loss_att 393.386688 loss_ctc 24.152561 loss_rnnt 11.341061 lr 0.00024046 rank 6
2022-12-08 14:53:54,463 DEBUG TRAIN Batch 32/7200 loss 5.200079 loss_att 326.713837 loss_ctc 13.746536 loss_rnnt 4.250473 lr 0.00024046 rank 2
2022-12-08 14:53:54,465 DEBUG TRAIN Batch 32/7200 loss 7.418992 loss_att 329.849487 loss_ctc 12.027041 loss_rnnt 6.906986 lr 0.00024043 rank 4
2022-12-08 14:53:54,466 DEBUG TRAIN Batch 32/7200 loss 10.257183 loss_att 427.477142 loss_ctc 20.758276 loss_rnnt 9.090395 lr 0.00024045 rank 3
2022-12-08 14:53:54,468 DEBUG TRAIN Batch 32/7200 loss 4.727726 loss_att 348.567841 loss_ctc 12.095146 loss_rnnt 3.909124 lr 0.00024044 rank 7
2022-12-08 14:53:54,468 DEBUG TRAIN Batch 32/7200 loss 6.871247 loss_att 359.560516 loss_ctc 13.898266 loss_rnnt 6.090467 lr 0.00024043 rank 0
2022-12-08 14:53:54,473 DEBUG TRAIN Batch 32/7200 loss 11.467345 loss_att 365.061584 loss_ctc 26.245506 loss_rnnt 9.825327 lr 0.00024047 rank 1
2022-12-08 14:53:54,479 DEBUG TRAIN Batch 32/7200 loss 12.842869 loss_att 103.735878 loss_ctc 15.959148 loss_rnnt 12.496615 lr 0.00024046 rank 5
2022-12-08 14:54:58,048 DEBUG TRAIN Batch 32/7300 loss 3.658250 loss_att 356.397827 loss_ctc 7.338437 loss_rnnt 3.249341 lr 0.00024044 rank 6
2022-12-08 14:54:58,050 DEBUG TRAIN Batch 32/7300 loss 5.455285 loss_att 346.899780 loss_ctc 11.542961 loss_rnnt 4.778876 lr 0.00024040 rank 0
2022-12-08 14:54:58,051 DEBUG TRAIN Batch 32/7300 loss 4.070948 loss_att 358.115204 loss_ctc 8.453705 loss_rnnt 3.583975 lr 0.00024042 rank 3
2022-12-08 14:54:58,052 DEBUG TRAIN Batch 32/7300 loss 8.039974 loss_att 408.099426 loss_ctc 12.297904 loss_rnnt 7.566871 lr 0.00024043 rank 2
2022-12-08 14:54:58,052 DEBUG TRAIN Batch 32/7300 loss 5.967559 loss_att 382.094238 loss_ctc 13.650597 loss_rnnt 5.113888 lr 0.00024041 rank 7
2022-12-08 14:54:58,054 DEBUG TRAIN Batch 32/7300 loss 9.632222 loss_att 405.176941 loss_ctc 16.506144 loss_rnnt 8.868453 lr 0.00024040 rank 4
2022-12-08 14:54:58,057 DEBUG TRAIN Batch 32/7300 loss 9.036036 loss_att 363.102753 loss_ctc 16.126635 loss_rnnt 8.248192 lr 0.00024044 rank 1
2022-12-08 14:54:58,057 DEBUG TRAIN Batch 32/7300 loss 11.693864 loss_att 420.921875 loss_ctc 19.323910 loss_rnnt 10.846081 lr 0.00024044 rank 5
2022-12-08 14:56:02,160 DEBUG TRAIN Batch 32/7400 loss 14.393446 loss_att 422.216064 loss_ctc 25.750835 loss_rnnt 13.131514 lr 0.00024038 rank 4
2022-12-08 14:56:02,163 DEBUG TRAIN Batch 32/7400 loss 3.620690 loss_att 379.256592 loss_ctc 7.624000 loss_rnnt 3.175878 lr 0.00024038 rank 7
2022-12-08 14:56:02,164 DEBUG TRAIN Batch 32/7400 loss 9.096827 loss_att 390.413635 loss_ctc 20.332087 loss_rnnt 7.848464 lr 0.00024041 rank 6
2022-12-08 14:56:02,165 DEBUG TRAIN Batch 32/7400 loss 4.584461 loss_att 336.006592 loss_ctc 11.007746 loss_rnnt 3.870763 lr 0.00024041 rank 5
2022-12-08 14:56:02,167 DEBUG TRAIN Batch 32/7400 loss 8.773250 loss_att 406.143188 loss_ctc 12.295214 loss_rnnt 8.381920 lr 0.00024037 rank 0
2022-12-08 14:56:02,177 DEBUG TRAIN Batch 32/7400 loss 7.887935 loss_att 347.082184 loss_ctc 17.371052 loss_rnnt 6.834255 lr 0.00024041 rank 1
2022-12-08 14:56:02,180 DEBUG TRAIN Batch 32/7400 loss 11.214850 loss_att 397.833191 loss_ctc 21.546661 loss_rnnt 10.066872 lr 0.00024040 rank 2
2022-12-08 14:56:02,186 DEBUG TRAIN Batch 32/7400 loss 8.840799 loss_att 309.389984 loss_ctc 13.336855 loss_rnnt 8.341238 lr 0.00024039 rank 3
2022-12-08 14:57:16,449 DEBUG TRAIN Batch 32/7500 loss 5.139742 loss_att 386.557312 loss_ctc 14.075874 loss_rnnt 4.146838 lr 0.00024035 rank 0
2022-12-08 14:57:16,467 DEBUG TRAIN Batch 32/7500 loss 11.882042 loss_att 400.340759 loss_ctc 18.418533 loss_rnnt 11.155766 lr 0.00024035 rank 4
2022-12-08 14:57:16,467 DEBUG TRAIN Batch 32/7500 loss 6.211935 loss_att 72.906914 loss_ctc 11.074592 loss_rnnt 5.671640 lr 0.00024039 rank 1
2022-12-08 14:57:16,470 DEBUG TRAIN Batch 32/7500 loss 4.990661 loss_att 367.147003 loss_ctc 12.658655 loss_rnnt 4.138662 lr 0.00024035 rank 7
2022-12-08 14:57:16,471 DEBUG TRAIN Batch 32/7500 loss 6.521940 loss_att 378.685547 loss_ctc 13.347010 loss_rnnt 5.763599 lr 0.00024038 rank 6
2022-12-08 14:57:16,474 DEBUG TRAIN Batch 32/7500 loss 12.449115 loss_att 243.531769 loss_ctc 19.070164 loss_rnnt 11.713443 lr 0.00024037 rank 3
2022-12-08 14:57:16,478 DEBUG TRAIN Batch 32/7500 loss 7.578677 loss_att 391.392151 loss_ctc 15.080853 loss_rnnt 6.745102 lr 0.00024038 rank 5
2022-12-08 14:57:16,506 DEBUG TRAIN Batch 32/7500 loss 7.441716 loss_att 280.630310 loss_ctc 12.972153 loss_rnnt 6.827223 lr 0.00024038 rank 2
2022-12-08 14:58:19,773 DEBUG TRAIN Batch 32/7600 loss 7.137331 loss_att 240.986816 loss_ctc 12.050060 loss_rnnt 6.591473 lr 0.00024032 rank 7
2022-12-08 14:58:19,774 DEBUG TRAIN Batch 32/7600 loss 4.717148 loss_att 342.475586 loss_ctc 12.314004 loss_rnnt 3.873054 lr 0.00024032 rank 4
2022-12-08 14:58:19,774 DEBUG TRAIN Batch 32/7600 loss 5.709971 loss_att 412.819672 loss_ctc 13.122634 loss_rnnt 4.886342 lr 0.00024035 rank 2
2022-12-08 14:58:19,777 DEBUG TRAIN Batch 32/7600 loss 8.970964 loss_att 401.373169 loss_ctc 16.127480 loss_rnnt 8.175797 lr 0.00024034 rank 3
2022-12-08 14:58:19,780 DEBUG TRAIN Batch 32/7600 loss 10.294618 loss_att 455.239319 loss_ctc 19.945526 loss_rnnt 9.222295 lr 0.00024036 rank 1
2022-12-08 14:58:19,781 DEBUG TRAIN Batch 32/7600 loss 8.629633 loss_att 373.509827 loss_ctc 16.650942 loss_rnnt 7.738377 lr 0.00024035 rank 5
2022-12-08 14:58:19,782 DEBUG TRAIN Batch 32/7600 loss 8.263103 loss_att 245.712875 loss_ctc 16.239141 loss_rnnt 7.376876 lr 0.00024032 rank 0
2022-12-08 14:58:19,818 DEBUG TRAIN Batch 32/7600 loss 5.701296 loss_att 275.147583 loss_ctc 10.396678 loss_rnnt 5.179586 lr 0.00024035 rank 6
2022-12-08 14:59:23,269 DEBUG TRAIN Batch 32/7700 loss 6.222096 loss_att 209.801346 loss_ctc 15.409772 loss_rnnt 5.201244 lr 0.00024029 rank 4
2022-12-08 14:59:23,269 DEBUG TRAIN Batch 32/7700 loss 5.610902 loss_att 378.656342 loss_ctc 13.656341 loss_rnnt 4.716965 lr 0.00024030 rank 7
2022-12-08 14:59:23,271 DEBUG TRAIN Batch 32/7700 loss 4.189453 loss_att 403.824829 loss_ctc 4.434468 loss_rnnt 4.162230 lr 0.00024033 rank 6
2022-12-08 14:59:23,272 DEBUG TRAIN Batch 32/7700 loss 2.226818 loss_att 302.857300 loss_ctc 6.300024 loss_rnnt 1.774239 lr 0.00024032 rank 2
2022-12-08 14:59:23,274 DEBUG TRAIN Batch 32/7700 loss 13.343793 loss_att 395.371674 loss_ctc 22.381077 loss_rnnt 12.339651 lr 0.00024031 rank 3
2022-12-08 14:59:23,278 DEBUG TRAIN Batch 32/7700 loss 7.572768 loss_att 394.239258 loss_ctc 11.997339 loss_rnnt 7.081149 lr 0.00024033 rank 1
2022-12-08 14:59:23,278 DEBUG TRAIN Batch 32/7700 loss 4.501344 loss_att 341.957367 loss_ctc 7.971046 loss_rnnt 4.115822 lr 0.00024029 rank 0
2022-12-08 14:59:23,279 DEBUG TRAIN Batch 32/7700 loss 18.504126 loss_att 315.744629 loss_ctc 29.032795 loss_rnnt 17.334274 lr 0.00024032 rank 5
2022-12-08 15:00:35,160 DEBUG TRAIN Batch 32/7800 loss 6.621950 loss_att 341.460083 loss_ctc 13.710075 loss_rnnt 5.834381 lr 0.00024027 rank 7
2022-12-08 15:00:35,162 DEBUG TRAIN Batch 32/7800 loss 9.817407 loss_att 420.947937 loss_ctc 13.666739 loss_rnnt 9.389704 lr 0.00024026 rank 0
2022-12-08 15:00:35,163 DEBUG TRAIN Batch 32/7800 loss 3.207395 loss_att 409.420013 loss_ctc 8.807091 loss_rnnt 2.585206 lr 0.00024026 rank 4
2022-12-08 15:00:35,163 DEBUG TRAIN Batch 32/7800 loss 11.350508 loss_att 359.682953 loss_ctc 23.453640 loss_rnnt 10.005716 lr 0.00024028 rank 3
2022-12-08 15:00:35,164 DEBUG TRAIN Batch 32/7800 loss 4.881091 loss_att 387.795349 loss_ctc 11.414947 loss_rnnt 4.155107 lr 0.00024030 rank 6
2022-12-08 15:00:35,166 DEBUG TRAIN Batch 32/7800 loss 11.741213 loss_att 378.808197 loss_ctc 17.058453 loss_rnnt 11.150409 lr 0.00024029 rank 2
2022-12-08 15:00:35,168 DEBUG TRAIN Batch 32/7800 loss 4.396957 loss_att 367.329803 loss_ctc 9.753103 loss_rnnt 3.801830 lr 0.00024030 rank 1
2022-12-08 15:00:35,189 DEBUG TRAIN Batch 32/7800 loss 11.029052 loss_att 104.463547 loss_ctc 15.892190 loss_rnnt 10.488704 lr 0.00024030 rank 5
2022-12-08 15:01:39,605 DEBUG TRAIN Batch 32/7900 loss 4.677053 loss_att 485.893188 loss_ctc 13.918310 loss_rnnt 3.650247 lr 0.00024024 rank 4
2022-12-08 15:01:39,608 DEBUG TRAIN Batch 32/7900 loss 11.553815 loss_att 310.186951 loss_ctc 18.071953 loss_rnnt 10.829577 lr 0.00024027 rank 6
2022-12-08 15:01:39,609 DEBUG TRAIN Batch 32/7900 loss 3.458478 loss_att 411.090332 loss_ctc 8.627556 loss_rnnt 2.884137 lr 0.00024024 rank 7
2022-12-08 15:01:39,612 DEBUG TRAIN Batch 32/7900 loss 19.019854 loss_att 432.792114 loss_ctc 33.574772 loss_rnnt 17.402641 lr 0.00024026 rank 3
2022-12-08 15:01:39,613 DEBUG TRAIN Batch 32/7900 loss 5.773942 loss_att 405.519287 loss_ctc 11.466007 loss_rnnt 5.141491 lr 0.00024023 rank 0
2022-12-08 15:01:39,613 DEBUG TRAIN Batch 32/7900 loss 4.446942 loss_att 302.020813 loss_ctc 8.593090 loss_rnnt 3.986259 lr 0.00024028 rank 1
2022-12-08 15:01:39,615 DEBUG TRAIN Batch 32/7900 loss 8.431901 loss_att 391.451355 loss_ctc 15.862192 loss_rnnt 7.606313 lr 0.00024027 rank 5
2022-12-08 15:01:39,651 DEBUG TRAIN Batch 32/7900 loss 5.291735 loss_att 377.959503 loss_ctc 12.574766 loss_rnnt 4.482510 lr 0.00024026 rank 2
2022-12-08 15:02:43,011 DEBUG TRAIN Batch 32/8000 loss 8.814810 loss_att 324.257080 loss_ctc 11.985449 loss_rnnt 8.462517 lr 0.00024021 rank 4
2022-12-08 15:02:43,015 DEBUG TRAIN Batch 32/8000 loss 12.068202 loss_att 384.159851 loss_ctc 22.303963 loss_rnnt 10.930896 lr 0.00024025 rank 1
2022-12-08 15:02:43,015 DEBUG TRAIN Batch 32/8000 loss 4.266441 loss_att 377.912781 loss_ctc 12.684260 loss_rnnt 3.331128 lr 0.00024024 rank 5
2022-12-08 15:02:43,016 DEBUG TRAIN Batch 32/8000 loss 2.652562 loss_att 391.549713 loss_ctc 4.914312 loss_rnnt 2.401257 lr 0.00024021 rank 7
2022-12-08 15:02:43,017 DEBUG TRAIN Batch 32/8000 loss 6.460834 loss_att 337.081116 loss_ctc 13.301773 loss_rnnt 5.700730 lr 0.00024023 rank 3
2022-12-08 15:02:43,019 DEBUG TRAIN Batch 32/8000 loss 4.103721 loss_att 379.808044 loss_ctc 12.150023 loss_rnnt 3.209687 lr 0.00024021 rank 0
2022-12-08 15:02:43,019 DEBUG TRAIN Batch 32/8000 loss 9.915227 loss_att 380.278870 loss_ctc 17.220039 loss_rnnt 9.103581 lr 0.00024024 rank 6
2022-12-08 15:02:43,074 DEBUG TRAIN Batch 32/8000 loss 3.654691 loss_att 342.339539 loss_ctc 7.971400 loss_rnnt 3.175056 lr 0.00024024 rank 2
2022-12-08 15:03:46,459 DEBUG TRAIN Batch 32/8100 loss 5.681568 loss_att 367.153046 loss_ctc 14.066773 loss_rnnt 4.749879 lr 0.00024018 rank 4
2022-12-08 15:03:46,462 DEBUG TRAIN Batch 32/8100 loss 8.874469 loss_att 316.840271 loss_ctc 19.270470 loss_rnnt 7.719357 lr 0.00024019 rank 7
2022-12-08 15:03:46,462 DEBUG TRAIN Batch 32/8100 loss 9.294248 loss_att 383.838867 loss_ctc 15.205096 loss_rnnt 8.637487 lr 0.00024018 rank 0
2022-12-08 15:03:46,465 DEBUG TRAIN Batch 32/8100 loss 3.768770 loss_att 340.664185 loss_ctc 7.339103 loss_rnnt 3.372067 lr 0.00024021 rank 5
2022-12-08 15:03:46,470 DEBUG TRAIN Batch 32/8100 loss 8.869377 loss_att 302.236267 loss_ctc 18.485966 loss_rnnt 7.800868 lr 0.00024020 rank 3
2022-12-08 15:03:46,471 DEBUG TRAIN Batch 32/8100 loss 15.277196 loss_att 325.900391 loss_ctc 29.450428 loss_rnnt 13.702393 lr 0.00024021 rank 2
2022-12-08 15:03:46,483 DEBUG TRAIN Batch 32/8100 loss 5.608335 loss_att 311.416443 loss_ctc 14.292213 loss_rnnt 4.643459 lr 0.00024022 rank 6
2022-12-08 15:03:46,514 DEBUG TRAIN Batch 32/8100 loss 6.640534 loss_att 144.258453 loss_ctc 10.463974 loss_rnnt 6.215708 lr 0.00024022 rank 1
2022-12-08 15:04:50,538 DEBUG TRAIN Batch 32/8200 loss 10.171637 loss_att 351.070465 loss_ctc 17.833099 loss_rnnt 9.320363 lr 0.00024015 rank 4
2022-12-08 15:04:50,540 DEBUG TRAIN Batch 32/8200 loss 9.545815 loss_att 284.213440 loss_ctc 17.403154 loss_rnnt 8.672776 lr 0.00024016 rank 7
2022-12-08 15:04:50,541 DEBUG TRAIN Batch 32/8200 loss 7.935730 loss_att 295.225891 loss_ctc 12.970301 loss_rnnt 7.376334 lr 0.00024019 rank 6
2022-12-08 15:04:50,542 DEBUG TRAIN Batch 32/8200 loss 8.084586 loss_att 69.938065 loss_ctc 12.010272 loss_rnnt 7.648399 lr 0.00024018 rank 2
2022-12-08 15:04:50,544 DEBUG TRAIN Batch 32/8200 loss 7.732342 loss_att 305.881470 loss_ctc 13.440389 loss_rnnt 7.098115 lr 0.00024019 rank 5
2022-12-08 15:04:50,547 DEBUG TRAIN Batch 32/8200 loss 1.696690 loss_att 408.150452 loss_ctc 6.685478 loss_rnnt 1.142380 lr 0.00024017 rank 3
2022-12-08 15:04:50,547 DEBUG TRAIN Batch 32/8200 loss 8.493769 loss_att 247.478973 loss_ctc 17.907993 loss_rnnt 7.447744 lr 0.00024015 rank 0
2022-12-08 15:04:50,548 DEBUG TRAIN Batch 32/8200 loss 13.611947 loss_att 395.697235 loss_ctc 24.817688 loss_rnnt 12.366865 lr 0.00024019 rank 1
2022-12-08 15:05:54,044 DEBUG TRAIN Batch 32/8300 loss 6.932387 loss_att 318.131622 loss_ctc 17.443331 loss_rnnt 5.764504 lr 0.00024016 rank 6
2022-12-08 15:05:54,044 DEBUG TRAIN Batch 32/8300 loss 8.967962 loss_att 437.634521 loss_ctc 23.381285 loss_rnnt 7.366483 lr 0.00024013 rank 4
2022-12-08 15:05:54,045 DEBUG TRAIN Batch 32/8300 loss 5.571577 loss_att 480.002045 loss_ctc 15.923096 loss_rnnt 4.421408 lr 0.00024013 rank 7
2022-12-08 15:05:54,046 DEBUG TRAIN Batch 32/8300 loss 9.355997 loss_att 356.381287 loss_ctc 18.009876 loss_rnnt 8.394455 lr 0.00024014 rank 3
2022-12-08 15:05:54,046 DEBUG TRAIN Batch 32/8300 loss 3.808161 loss_att 335.188110 loss_ctc 8.381789 loss_rnnt 3.299980 lr 0.00024016 rank 1
2022-12-08 15:05:54,049 DEBUG TRAIN Batch 32/8300 loss 4.344350 loss_att 355.953857 loss_ctc 4.888723 loss_rnnt 4.283864 lr 0.00024016 rank 5
2022-12-08 15:05:54,050 DEBUG TRAIN Batch 32/8300 loss 9.408377 loss_att 445.861328 loss_ctc 17.402443 loss_rnnt 8.520147 lr 0.00024015 rank 2
2022-12-08 15:05:54,051 DEBUG TRAIN Batch 32/8300 loss 4.901282 loss_att 416.019745 loss_ctc 14.659708 loss_rnnt 3.817013 lr 0.00024012 rank 0
2022-12-08 15:06:43,484 DEBUG CV Batch 32/0 loss 1.231334 loss_att 48.086460 loss_ctc 2.374939 loss_rnnt 1.104267 history loss 1.185729 rank 3
2022-12-08 15:06:43,488 DEBUG CV Batch 32/0 loss 1.231334 loss_att 48.086460 loss_ctc 2.374939 loss_rnnt 1.104267 history loss 1.185729 rank 2
2022-12-08 15:06:43,488 DEBUG CV Batch 32/0 loss 1.231334 loss_att 48.086460 loss_ctc 2.374939 loss_rnnt 1.104267 history loss 1.185729 rank 1
2022-12-08 15:06:43,490 DEBUG CV Batch 32/0 loss 1.231334 loss_att 48.086460 loss_ctc 2.374939 loss_rnnt 1.104267 history loss 1.185729 rank 5
2022-12-08 15:06:43,491 DEBUG CV Batch 32/0 loss 1.231334 loss_att 48.086460 loss_ctc 2.374939 loss_rnnt 1.104267 history loss 1.185729 rank 7
2022-12-08 15:06:43,492 DEBUG CV Batch 32/0 loss 1.231334 loss_att 48.086460 loss_ctc 2.374939 loss_rnnt 1.104267 history loss 1.185729 rank 6
2022-12-08 15:06:43,507 DEBUG CV Batch 32/0 loss 1.231334 loss_att 48.086460 loss_ctc 2.374939 loss_rnnt 1.104267 history loss 1.185729 rank 4
2022-12-08 15:06:43,511 DEBUG CV Batch 32/0 loss 1.231334 loss_att 48.086460 loss_ctc 2.374939 loss_rnnt 1.104267 history loss 1.185729 rank 0
2022-12-08 15:06:55,255 DEBUG CV Batch 32/100 loss 3.561971 loss_att 266.942108 loss_ctc 12.420334 loss_rnnt 2.577709 history loss 2.994355 rank 4
2022-12-08 15:06:55,412 DEBUG CV Batch 32/100 loss 3.561971 loss_att 266.942108 loss_ctc 12.420334 loss_rnnt 2.577709 history loss 2.994355 rank 0
2022-12-08 15:06:55,586 DEBUG CV Batch 32/100 loss 3.561971 loss_att 266.942108 loss_ctc 12.420334 loss_rnnt 2.577709 history loss 2.994355 rank 5
2022-12-08 15:06:55,704 DEBUG CV Batch 32/100 loss 3.561971 loss_att 266.942108 loss_ctc 12.420334 loss_rnnt 2.577709 history loss 2.994355 rank 7
2022-12-08 15:06:55,739 DEBUG CV Batch 32/100 loss 3.561971 loss_att 266.942108 loss_ctc 12.420334 loss_rnnt 2.577709 history loss 2.994355 rank 3
2022-12-08 15:06:55,775 DEBUG CV Batch 32/100 loss 3.561971 loss_att 266.942108 loss_ctc 12.420334 loss_rnnt 2.577709 history loss 2.994355 rank 2
2022-12-08 15:06:56,248 DEBUG CV Batch 32/100 loss 3.561971 loss_att 266.942108 loss_ctc 12.420334 loss_rnnt 2.577709 history loss 2.994355 rank 6
2022-12-08 15:06:56,443 DEBUG CV Batch 32/100 loss 3.561971 loss_att 266.942108 loss_ctc 12.420334 loss_rnnt 2.577709 history loss 2.994355 rank 1
2022-12-08 15:07:10,433 DEBUG CV Batch 32/200 loss 2.284513 loss_att 641.182983 loss_ctc 3.064611 loss_rnnt 2.197835 history loss 3.521033 rank 3
2022-12-08 15:07:10,540 DEBUG CV Batch 32/200 loss 2.284513 loss_att 641.182983 loss_ctc 3.064611 loss_rnnt 2.197835 history loss 3.521033 rank 5
2022-12-08 15:07:10,556 DEBUG CV Batch 32/200 loss 2.284513 loss_att 641.182983 loss_ctc 3.064611 loss_rnnt 2.197835 history loss 3.521033 rank 4
2022-12-08 15:07:10,677 DEBUG CV Batch 32/200 loss 2.284513 loss_att 641.182983 loss_ctc 3.064611 loss_rnnt 2.197835 history loss 3.521033 rank 7
2022-12-08 15:07:10,725 DEBUG CV Batch 32/200 loss 2.284513 loss_att 641.182983 loss_ctc 3.064611 loss_rnnt 2.197835 history loss 3.521033 rank 0
2022-12-08 15:07:11,099 DEBUG CV Batch 32/200 loss 2.284513 loss_att 641.182983 loss_ctc 3.064611 loss_rnnt 2.197835 history loss 3.521033 rank 2
2022-12-08 15:07:11,499 DEBUG CV Batch 32/200 loss 2.284513 loss_att 641.182983 loss_ctc 3.064611 loss_rnnt 2.197835 history loss 3.521033 rank 6
2022-12-08 15:07:11,846 DEBUG CV Batch 32/200 loss 2.284513 loss_att 641.182983 loss_ctc 3.064611 loss_rnnt 2.197835 history loss 3.521033 rank 1
2022-12-08 15:07:21,930 DEBUG CV Batch 32/300 loss 2.390305 loss_att 190.886871 loss_ctc 5.609693 loss_rnnt 2.032595 history loss 3.621504 rank 5
2022-12-08 15:07:22,011 DEBUG CV Batch 32/300 loss 2.390305 loss_att 190.886871 loss_ctc 5.609693 loss_rnnt 2.032595 history loss 3.621504 rank 3
2022-12-08 15:07:22,263 DEBUG CV Batch 32/300 loss 2.390305 loss_att 190.886871 loss_ctc 5.609693 loss_rnnt 2.032595 history loss 3.621504 rank 4
2022-12-08 15:07:22,328 DEBUG CV Batch 32/300 loss 2.390305 loss_att 190.886871 loss_ctc 5.609693 loss_rnnt 2.032595 history loss 3.621504 rank 7
2022-12-08 15:07:22,436 DEBUG CV Batch 32/300 loss 2.390305 loss_att 190.886871 loss_ctc 5.609693 loss_rnnt 2.032595 history loss 3.621504 rank 2
2022-12-08 15:07:22,575 DEBUG CV Batch 32/300 loss 2.390305 loss_att 190.886871 loss_ctc 5.609693 loss_rnnt 2.032595 history loss 3.621504 rank 0
2022-12-08 15:07:22,743 DEBUG CV Batch 32/300 loss 2.390305 loss_att 190.886871 loss_ctc 5.609693 loss_rnnt 2.032595 history loss 3.621504 rank 6
2022-12-08 15:07:23,172 DEBUG CV Batch 32/300 loss 2.390305 loss_att 190.886871 loss_ctc 5.609693 loss_rnnt 2.032595 history loss 3.621504 rank 1
2022-12-08 15:07:33,286 DEBUG CV Batch 32/400 loss 6.501900 loss_att 826.176025 loss_ctc 12.019024 loss_rnnt 5.888886 history loss 4.439871 rank 5
2022-12-08 15:07:33,480 DEBUG CV Batch 32/400 loss 6.501900 loss_att 826.176025 loss_ctc 12.019024 loss_rnnt 5.888886 history loss 4.439871 rank 3
2022-12-08 15:07:33,822 DEBUG CV Batch 32/400 loss 6.501900 loss_att 826.176025 loss_ctc 12.019024 loss_rnnt 5.888886 history loss 4.439871 rank 4
2022-12-08 15:07:33,854 DEBUG CV Batch 32/400 loss 6.501900 loss_att 826.176025 loss_ctc 12.019024 loss_rnnt 5.888886 history loss 4.439871 rank 2
2022-12-08 15:07:33,970 DEBUG CV Batch 32/400 loss 6.501900 loss_att 826.176025 loss_ctc 12.019024 loss_rnnt 5.888886 history loss 4.439871 rank 7
2022-12-08 15:07:34,061 DEBUG CV Batch 32/400 loss 6.501900 loss_att 826.176025 loss_ctc 12.019024 loss_rnnt 5.888886 history loss 4.439871 rank 6
2022-12-08 15:07:34,367 DEBUG CV Batch 32/400 loss 6.501900 loss_att 826.176025 loss_ctc 12.019024 loss_rnnt 5.888886 history loss 4.439871 rank 1
2022-12-08 15:07:34,384 DEBUG CV Batch 32/400 loss 6.501900 loss_att 826.176025 loss_ctc 12.019024 loss_rnnt 5.888886 history loss 4.439871 rank 0
2022-12-08 15:07:43,455 DEBUG CV Batch 32/500 loss 4.952437 loss_att 266.657074 loss_ctc 8.944640 loss_rnnt 4.508859 history loss 5.056947 rank 5
2022-12-08 15:07:43,487 DEBUG CV Batch 32/500 loss 4.952437 loss_att 266.657074 loss_ctc 8.944640 loss_rnnt 4.508859 history loss 5.056947 rank 3
2022-12-08 15:07:44,049 DEBUG CV Batch 32/500 loss 4.952437 loss_att 266.657074 loss_ctc 8.944640 loss_rnnt 4.508859 history loss 5.056947 rank 4
2022-12-08 15:07:44,263 DEBUG CV Batch 32/500 loss 4.952437 loss_att 266.657074 loss_ctc 8.944640 loss_rnnt 4.508859 history loss 5.056947 rank 7
2022-12-08 15:07:44,694 DEBUG CV Batch 32/500 loss 4.952437 loss_att 266.657074 loss_ctc 8.944640 loss_rnnt 4.508859 history loss 5.056947 rank 0
2022-12-08 15:07:44,976 DEBUG CV Batch 32/500 loss 4.952437 loss_att 266.657074 loss_ctc 8.944640 loss_rnnt 4.508859 history loss 5.056947 rank 2
2022-12-08 15:07:45,047 DEBUG CV Batch 32/500 loss 4.952437 loss_att 266.657074 loss_ctc 8.944640 loss_rnnt 4.508859 history loss 5.056947 rank 6
2022-12-08 15:07:45,080 DEBUG CV Batch 32/500 loss 4.952437 loss_att 266.657074 loss_ctc 8.944640 loss_rnnt 4.508859 history loss 5.056947 rank 1
2022-12-08 15:07:55,891 DEBUG CV Batch 32/600 loss 5.372096 loss_att 104.307396 loss_ctc 8.893578 loss_rnnt 4.980820 history loss 5.931967 rank 3
2022-12-08 15:07:56,025 DEBUG CV Batch 32/600 loss 5.372096 loss_att 104.307396 loss_ctc 8.893578 loss_rnnt 4.980820 history loss 5.931967 rank 4
2022-12-08 15:07:56,116 DEBUG CV Batch 32/600 loss 5.372096 loss_att 104.307396 loss_ctc 8.893578 loss_rnnt 4.980820 history loss 5.931967 rank 7
2022-12-08 15:07:56,213 DEBUG CV Batch 32/600 loss 5.372096 loss_att 104.307396 loss_ctc 8.893578 loss_rnnt 4.980820 history loss 5.931967 rank 5
2022-12-08 15:07:56,647 DEBUG CV Batch 32/600 loss 5.372096 loss_att 104.307396 loss_ctc 8.893578 loss_rnnt 4.980820 history loss 5.931967 rank 0
2022-12-08 15:07:57,487 DEBUG CV Batch 32/600 loss 5.372096 loss_att 104.307396 loss_ctc 8.893578 loss_rnnt 4.980820 history loss 5.931967 rank 6
2022-12-08 15:07:57,554 DEBUG CV Batch 32/600 loss 5.372096 loss_att 104.307396 loss_ctc 8.893578 loss_rnnt 4.980820 history loss 5.931967 rank 2
2022-12-08 15:07:57,635 DEBUG CV Batch 32/600 loss 5.372096 loss_att 104.307396 loss_ctc 8.893578 loss_rnnt 4.980820 history loss 5.931967 rank 1
2022-12-08 15:08:08,083 DEBUG CV Batch 32/700 loss 9.032997 loss_att 707.026184 loss_ctc 22.117804 loss_rnnt 7.579130 history loss 6.510488 rank 3
2022-12-08 15:08:08,098 DEBUG CV Batch 32/700 loss 9.032997 loss_att 707.026184 loss_ctc 22.117804 loss_rnnt 7.579130 history loss 6.510488 rank 5
2022-12-08 15:08:08,190 DEBUG CV Batch 32/700 loss 9.032997 loss_att 707.026184 loss_ctc 22.117804 loss_rnnt 7.579130 history loss 6.510488 rank 4
2022-12-08 15:08:08,301 DEBUG CV Batch 32/700 loss 9.032997 loss_att 707.026184 loss_ctc 22.117804 loss_rnnt 7.579130 history loss 6.510488 rank 7
2022-12-08 15:08:08,400 DEBUG CV Batch 32/700 loss 9.032997 loss_att 707.026184 loss_ctc 22.117804 loss_rnnt 7.579130 history loss 6.510488 rank 0
2022-12-08 15:08:09,740 DEBUG CV Batch 32/700 loss 9.032997 loss_att 707.026184 loss_ctc 22.117804 loss_rnnt 7.579130 history loss 6.510488 rank 1
2022-12-08 15:08:09,909 DEBUG CV Batch 32/700 loss 9.032997 loss_att 707.026184 loss_ctc 22.117804 loss_rnnt 7.579130 history loss 6.510488 rank 6
2022-12-08 15:08:09,954 DEBUG CV Batch 32/700 loss 9.032997 loss_att 707.026184 loss_ctc 22.117804 loss_rnnt 7.579130 history loss 6.510488 rank 2
2022-12-08 15:08:19,703 DEBUG CV Batch 32/800 loss 5.136542 loss_att 263.402191 loss_ctc 17.540531 loss_rnnt 3.758321 history loss 6.041275 rank 4
2022-12-08 15:08:20,013 DEBUG CV Batch 32/800 loss 5.136542 loss_att 263.402191 loss_ctc 17.540531 loss_rnnt 3.758321 history loss 6.041275 rank 5
2022-12-08 15:08:20,039 DEBUG CV Batch 32/800 loss 5.136542 loss_att 263.402191 loss_ctc 17.540531 loss_rnnt 3.758321 history loss 6.041275 rank 0
2022-12-08 15:08:20,047 DEBUG CV Batch 32/800 loss 5.136542 loss_att 263.402191 loss_ctc 17.540531 loss_rnnt 3.758321 history loss 6.041275 rank 7
2022-12-08 15:08:20,081 DEBUG CV Batch 32/800 loss 5.136542 loss_att 263.402191 loss_ctc 17.540531 loss_rnnt 3.758321 history loss 6.041275 rank 3
2022-12-08 15:08:21,486 DEBUG CV Batch 32/800 loss 5.136542 loss_att 263.402191 loss_ctc 17.540531 loss_rnnt 3.758321 history loss 6.041275 rank 6
2022-12-08 15:08:21,880 DEBUG CV Batch 32/800 loss 5.136542 loss_att 263.402191 loss_ctc 17.540531 loss_rnnt 3.758321 history loss 6.041275 rank 1
2022-12-08 15:08:22,005 DEBUG CV Batch 32/800 loss 5.136542 loss_att 263.402191 loss_ctc 17.540531 loss_rnnt 3.758321 history loss 6.041275 rank 2
2022-12-08 15:08:33,298 DEBUG CV Batch 32/900 loss 13.533317 loss_att 550.844849 loss_ctc 21.316525 loss_rnnt 12.668516 history loss 5.872321 rank 4
2022-12-08 15:08:33,456 DEBUG CV Batch 32/900 loss 13.533317 loss_att 550.844849 loss_ctc 21.316525 loss_rnnt 12.668516 history loss 5.872321 rank 3
2022-12-08 15:08:33,541 DEBUG CV Batch 32/900 loss 13.533317 loss_att 550.844849 loss_ctc 21.316525 loss_rnnt 12.668516 history loss 5.872321 rank 5
2022-12-08 15:08:33,579 DEBUG CV Batch 32/900 loss 13.533317 loss_att 550.844849 loss_ctc 21.316525 loss_rnnt 12.668516 history loss 5.872321 rank 0
2022-12-08 15:08:33,687 DEBUG CV Batch 32/900 loss 13.533317 loss_att 550.844849 loss_ctc 21.316525 loss_rnnt 12.668516 history loss 5.872321 rank 7
2022-12-08 15:08:35,297 DEBUG CV Batch 32/900 loss 13.533317 loss_att 550.844849 loss_ctc 21.316525 loss_rnnt 12.668516 history loss 5.872321 rank 6
2022-12-08 15:08:35,369 DEBUG CV Batch 32/900 loss 13.533317 loss_att 550.844849 loss_ctc 21.316525 loss_rnnt 12.668516 history loss 5.872321 rank 1
2022-12-08 15:08:35,538 DEBUG CV Batch 32/900 loss 13.533317 loss_att 550.844849 loss_ctc 21.316525 loss_rnnt 12.668516 history loss 5.872321 rank 2
2022-12-08 15:08:45,006 DEBUG CV Batch 32/1000 loss 2.267350 loss_att 176.484604 loss_ctc 4.834105 loss_rnnt 1.982155 history loss 5.660961 rank 5
2022-12-08 15:08:45,030 DEBUG CV Batch 32/1000 loss 2.267350 loss_att 176.484604 loss_ctc 4.834105 loss_rnnt 1.982155 history loss 5.660961 rank 4
2022-12-08 15:08:45,195 DEBUG CV Batch 32/1000 loss 2.267350 loss_att 176.484604 loss_ctc 4.834105 loss_rnnt 1.982155 history loss 5.660961 rank 3
2022-12-08 15:08:45,676 DEBUG CV Batch 32/1000 loss 2.267350 loss_att 176.484604 loss_ctc 4.834105 loss_rnnt 1.982155 history loss 5.660961 rank 0
2022-12-08 15:08:45,736 DEBUG CV Batch 32/1000 loss 2.267350 loss_att 176.484604 loss_ctc 4.834105 loss_rnnt 1.982155 history loss 5.660961 rank 7
2022-12-08 15:08:46,775 DEBUG CV Batch 32/1000 loss 2.267350 loss_att 176.484604 loss_ctc 4.834105 loss_rnnt 1.982155 history loss 5.660961 rank 6
2022-12-08 15:08:46,973 DEBUG CV Batch 32/1000 loss 2.267350 loss_att 176.484604 loss_ctc 4.834105 loss_rnnt 1.982155 history loss 5.660961 rank 1
2022-12-08 15:08:47,142 DEBUG CV Batch 32/1000 loss 2.267350 loss_att 176.484604 loss_ctc 4.834105 loss_rnnt 1.982155 history loss 5.660961 rank 2
2022-12-08 15:08:56,368 DEBUG CV Batch 32/1100 loss 4.439180 loss_att 60.693993 loss_ctc 7.711051 loss_rnnt 4.075639 history loss 5.630173 rank 5
2022-12-08 15:08:56,418 DEBUG CV Batch 32/1100 loss 4.439180 loss_att 60.693993 loss_ctc 7.711051 loss_rnnt 4.075639 history loss 5.630173 rank 4
2022-12-08 15:08:56,659 DEBUG CV Batch 32/1100 loss 4.439180 loss_att 60.693993 loss_ctc 7.711051 loss_rnnt 4.075639 history loss 5.630173 rank 3
2022-12-08 15:08:57,369 DEBUG CV Batch 32/1100 loss 4.439180 loss_att 60.693993 loss_ctc 7.711051 loss_rnnt 4.075639 history loss 5.630173 rank 7
2022-12-08 15:08:57,566 DEBUG CV Batch 32/1100 loss 4.439180 loss_att 60.693993 loss_ctc 7.711051 loss_rnnt 4.075639 history loss 5.630173 rank 0
2022-12-08 15:08:57,940 DEBUG CV Batch 32/1100 loss 4.439180 loss_att 60.693993 loss_ctc 7.711051 loss_rnnt 4.075639 history loss 5.630173 rank 1
2022-12-08 15:08:58,414 DEBUG CV Batch 32/1100 loss 4.439180 loss_att 60.693993 loss_ctc 7.711051 loss_rnnt 4.075639 history loss 5.630173 rank 6
2022-12-08 15:08:58,486 DEBUG CV Batch 32/1100 loss 4.439180 loss_att 60.693993 loss_ctc 7.711051 loss_rnnt 4.075639 history loss 5.630173 rank 2
2022-12-08 15:09:06,409 DEBUG CV Batch 32/1200 loss 7.383047 loss_att 280.456268 loss_ctc 10.493464 loss_rnnt 7.037445 history loss 5.903100 rank 4
2022-12-08 15:09:06,593 DEBUG CV Batch 32/1200 loss 7.383047 loss_att 280.456268 loss_ctc 10.493464 loss_rnnt 7.037445 history loss 5.903100 rank 3
2022-12-08 15:09:06,649 DEBUG CV Batch 32/1200 loss 7.383047 loss_att 280.456268 loss_ctc 10.493464 loss_rnnt 7.037445 history loss 5.903100 rank 5
2022-12-08 15:09:07,605 DEBUG CV Batch 32/1200 loss 7.383047 loss_att 280.456268 loss_ctc 10.493464 loss_rnnt 7.037445 history loss 5.903100 rank 7
2022-12-08 15:09:07,838 DEBUG CV Batch 32/1200 loss 7.383047 loss_att 280.456268 loss_ctc 10.493464 loss_rnnt 7.037445 history loss 5.903100 rank 0
2022-12-08 15:09:08,530 DEBUG CV Batch 32/1200 loss 7.383047 loss_att 280.456268 loss_ctc 10.493464 loss_rnnt 7.037445 history loss 5.903100 rank 1
2022-12-08 15:09:08,544 DEBUG CV Batch 32/1200 loss 7.383047 loss_att 280.456268 loss_ctc 10.493464 loss_rnnt 7.037445 history loss 5.903100 rank 6
2022-12-08 15:09:08,729 DEBUG CV Batch 32/1200 loss 7.383047 loss_att 280.456268 loss_ctc 10.493464 loss_rnnt 7.037445 history loss 5.903100 rank 2
2022-12-08 15:09:17,941 DEBUG CV Batch 32/1300 loss 4.614967 loss_att 105.975807 loss_ctc 7.439727 loss_rnnt 4.301105 history loss 6.192594 rank 4
2022-12-08 15:09:18,061 DEBUG CV Batch 32/1300 loss 4.614967 loss_att 105.975807 loss_ctc 7.439727 loss_rnnt 4.301105 history loss 6.192594 rank 3
2022-12-08 15:09:18,347 DEBUG CV Batch 32/1300 loss 4.614967 loss_att 105.975807 loss_ctc 7.439727 loss_rnnt 4.301105 history loss 6.192594 rank 5
2022-12-08 15:09:19,399 DEBUG CV Batch 32/1300 loss 4.614967 loss_att 105.975807 loss_ctc 7.439727 loss_rnnt 4.301105 history loss 6.192594 rank 7
2022-12-08 15:09:19,765 DEBUG CV Batch 32/1300 loss 4.614967 loss_att 105.975807 loss_ctc 7.439727 loss_rnnt 4.301105 history loss 6.192594 rank 0
2022-12-08 15:09:19,999 DEBUG CV Batch 32/1300 loss 4.614967 loss_att 105.975807 loss_ctc 7.439727 loss_rnnt 4.301105 history loss 6.192594 rank 6
2022-12-08 15:09:20,162 DEBUG CV Batch 32/1300 loss 4.614967 loss_att 105.975807 loss_ctc 7.439727 loss_rnnt 4.301105 history loss 6.192594 rank 1
2022-12-08 15:09:20,697 DEBUG CV Batch 32/1300 loss 4.614967 loss_att 105.975807 loss_ctc 7.439727 loss_rnnt 4.301105 history loss 6.192594 rank 2
2022-12-08 15:09:29,738 DEBUG CV Batch 32/1400 loss 2.291585 loss_att 562.092529 loss_ctc 4.154096 loss_rnnt 2.084639 history loss 6.480298 rank 4
2022-12-08 15:09:30,115 DEBUG CV Batch 32/1400 loss 2.291585 loss_att 562.092529 loss_ctc 4.154096 loss_rnnt 2.084639 history loss 6.480298 rank 3
2022-12-08 15:09:30,310 DEBUG CV Batch 32/1400 loss 2.291585 loss_att 562.092529 loss_ctc 4.154096 loss_rnnt 2.084639 history loss 6.480298 rank 5
2022-12-08 15:09:30,315 DEBUG CV Batch 32/1400 loss 2.291585 loss_att 562.092529 loss_ctc 4.154096 loss_rnnt 2.084639 history loss 6.480298 rank 7
2022-12-08 15:09:30,703 DEBUG CV Batch 32/1400 loss 2.291585 loss_att 562.092529 loss_ctc 4.154096 loss_rnnt 2.084639 history loss 6.480298 rank 0
2022-12-08 15:09:32,456 DEBUG CV Batch 32/1400 loss 2.291585 loss_att 562.092529 loss_ctc 4.154096 loss_rnnt 2.084639 history loss 6.480298 rank 6
2022-12-08 15:09:32,520 DEBUG CV Batch 32/1400 loss 2.291585 loss_att 562.092529 loss_ctc 4.154096 loss_rnnt 2.084639 history loss 6.480298 rank 1
2022-12-08 15:09:33,052 DEBUG CV Batch 32/1400 loss 2.291585 loss_att 562.092529 loss_ctc 4.154096 loss_rnnt 2.084639 history loss 6.480298 rank 2
2022-12-08 15:09:41,858 DEBUG CV Batch 32/1500 loss 7.460716 loss_att 275.484344 loss_ctc 8.389750 loss_rnnt 7.357490 history loss 6.363234 rank 4
2022-12-08 15:09:41,980 DEBUG CV Batch 32/1500 loss 7.460716 loss_att 275.484344 loss_ctc 8.389750 loss_rnnt 7.357490 history loss 6.363234 rank 3
2022-12-08 15:09:42,097 DEBUG CV Batch 32/1500 loss 7.460716 loss_att 275.484344 loss_ctc 8.389750 loss_rnnt 7.357490 history loss 6.363234 rank 7
2022-12-08 15:09:42,251 DEBUG CV Batch 32/1500 loss 7.460716 loss_att 275.484344 loss_ctc 8.389750 loss_rnnt 7.357490 history loss 6.363234 rank 0
2022-12-08 15:09:42,624 DEBUG CV Batch 32/1500 loss 7.460716 loss_att 275.484344 loss_ctc 8.389750 loss_rnnt 7.357490 history loss 6.363234 rank 5
2022-12-08 15:09:44,953 DEBUG CV Batch 32/1500 loss 7.460716 loss_att 275.484344 loss_ctc 8.389750 loss_rnnt 7.357490 history loss 6.363234 rank 6
2022-12-08 15:09:45,431 DEBUG CV Batch 32/1500 loss 7.460716 loss_att 275.484344 loss_ctc 8.389750 loss_rnnt 7.357490 history loss 6.363234 rank 1
2022-12-08 15:09:45,829 DEBUG CV Batch 32/1500 loss 7.460716 loss_att 275.484344 loss_ctc 8.389750 loss_rnnt 7.357490 history loss 6.363234 rank 2
2022-12-08 15:09:55,197 DEBUG CV Batch 32/1600 loss 5.082057 loss_att 593.910095 loss_ctc 12.930822 loss_rnnt 4.209972 history loss 6.324916 rank 4
2022-12-08 15:09:55,321 DEBUG CV Batch 32/1600 loss 5.082057 loss_att 593.910095 loss_ctc 12.930822 loss_rnnt 4.209972 history loss 6.324916 rank 3
2022-12-08 15:09:55,503 DEBUG CV Batch 32/1600 loss 5.082057 loss_att 593.910095 loss_ctc 12.930822 loss_rnnt 4.209972 history loss 6.324916 rank 7
2022-12-08 15:09:55,864 DEBUG CV Batch 32/1600 loss 5.082057 loss_att 593.910095 loss_ctc 12.930822 loss_rnnt 4.209972 history loss 6.324916 rank 5
2022-12-08 15:09:56,103 DEBUG CV Batch 32/1600 loss 5.082057 loss_att 593.910095 loss_ctc 12.930822 loss_rnnt 4.209972 history loss 6.324916 rank 0
2022-12-08 15:09:58,419 DEBUG CV Batch 32/1600 loss 5.082057 loss_att 593.910095 loss_ctc 12.930822 loss_rnnt 4.209972 history loss 6.324916 rank 6
2022-12-08 15:09:58,536 DEBUG CV Batch 32/1600 loss 5.082057 loss_att 593.910095 loss_ctc 12.930822 loss_rnnt 4.209972 history loss 6.324916 rank 1
2022-12-08 15:09:59,073 DEBUG CV Batch 32/1600 loss 5.082057 loss_att 593.910095 loss_ctc 12.930822 loss_rnnt 4.209972 history loss 6.324916 rank 2
2022-12-08 15:10:07,130 DEBUG CV Batch 32/1700 loss 6.049610 loss_att 210.842636 loss_ctc 14.203387 loss_rnnt 5.143635 history loss 6.257410 rank 3
2022-12-08 15:10:07,220 DEBUG CV Batch 32/1700 loss 6.049610 loss_att 210.842636 loss_ctc 14.203387 loss_rnnt 5.143635 history loss 6.257410 rank 4
2022-12-08 15:10:07,819 DEBUG CV Batch 32/1700 loss 6.049610 loss_att 210.842636 loss_ctc 14.203387 loss_rnnt 5.143635 history loss 6.257410 rank 5
2022-12-08 15:10:07,841 DEBUG CV Batch 32/1700 loss 6.049610 loss_att 210.842636 loss_ctc 14.203387 loss_rnnt 5.143635 history loss 6.257410 rank 7
2022-12-08 15:10:08,420 DEBUG CV Batch 32/1700 loss 6.049610 loss_att 210.842636 loss_ctc 14.203387 loss_rnnt 5.143635 history loss 6.257410 rank 0
2022-12-08 15:10:10,221 DEBUG CV Batch 32/1700 loss 6.049610 loss_att 210.842636 loss_ctc 14.203387 loss_rnnt 5.143635 history loss 6.257410 rank 6
2022-12-08 15:10:10,236 DEBUG CV Batch 32/1700 loss 6.049610 loss_att 210.842636 loss_ctc 14.203387 loss_rnnt 5.143635 history loss 6.257410 rank 1
2022-12-08 15:10:11,058 DEBUG CV Batch 32/1700 loss 6.049610 loss_att 210.842636 loss_ctc 14.203387 loss_rnnt 5.143635 history loss 6.257410 rank 2
2022-12-08 15:10:15,998 INFO Epoch 32 CV info cv_loss 6.2382704797178645
2022-12-08 15:10:15,999 INFO Epoch 33 TRAIN info lr 0.0002401222360419356
2022-12-08 15:10:16,000 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 15:10:16,226 INFO Epoch 32 CV info cv_loss 6.2382704797178645
2022-12-08 15:10:16,227 INFO Epoch 33 TRAIN info lr 0.0002401274973654482
2022-12-08 15:10:16,231 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 15:10:16,798 INFO Epoch 32 CV info cv_loss 6.2382704797178645
2022-12-08 15:10:16,799 INFO Epoch 33 TRAIN info lr 0.00024011919017059787
2022-12-08 15:10:16,803 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 15:10:17,010 INFO Epoch 32 CV info cv_loss 6.2382704797178645
2022-12-08 15:10:17,010 INFO Epoch 33 TRAIN info lr 0.00024015657933862256
2022-12-08 15:10:17,015 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 15:10:17,455 INFO Epoch 32 CV info cv_loss 6.2382704797178645
2022-12-08 15:10:17,456 INFO Checkpoint: save to checkpoint exp/1204_encoder_bias_nobi_noatt/32.pt
2022-12-08 15:10:18,076 INFO Epoch 33 TRAIN info lr 0.00024011060697493568
2022-12-08 15:10:18,079 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 15:10:19,053 INFO Epoch 32 CV info cv_loss 6.2382704797178645
2022-12-08 15:10:19,053 INFO Epoch 33 TRAIN info lr 0.0002401515931070725
2022-12-08 15:10:19,058 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 15:10:19,062 INFO Epoch 32 CV info cv_loss 6.2382704797178645
2022-12-08 15:10:19,063 INFO Epoch 33 TRAIN info lr 0.00024014605321403707
2022-12-08 15:10:19,067 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 15:10:20,014 INFO Epoch 32 CV info cv_loss 6.2382704797178645
2022-12-08 15:10:20,014 INFO Epoch 33 TRAIN info lr 0.00024013912888685214
2022-12-08 15:10:20,016 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 15:11:20,364 DEBUG TRAIN Batch 33/0 loss 7.117920 loss_att 71.449638 loss_ctc 9.993105 loss_rnnt 6.798455 lr 0.00024012 rank 7
2022-12-08 15:11:20,366 DEBUG TRAIN Batch 33/0 loss 7.064251 loss_att 71.607582 loss_ctc 10.399889 loss_rnnt 6.693625 lr 0.00024012 rank 4
2022-12-08 15:11:20,368 DEBUG TRAIN Batch 33/0 loss 4.087804 loss_att 65.384789 loss_ctc 7.706848 loss_rnnt 3.685688 lr 0.00024013 rank 3
2022-12-08 15:11:20,372 DEBUG TRAIN Batch 33/0 loss 6.022175 loss_att 75.921158 loss_ctc 9.728749 loss_rnnt 5.610334 lr 0.00024011 rank 0
2022-12-08 15:11:20,404 DEBUG TRAIN Batch 33/0 loss 7.727062 loss_att 77.625313 loss_ctc 12.131931 loss_rnnt 7.237632 lr 0.00024016 rank 5
2022-12-08 15:11:20,410 DEBUG TRAIN Batch 33/0 loss 10.207776 loss_att 74.629738 loss_ctc 14.270669 loss_rnnt 9.756344 lr 0.00024015 rank 1
2022-12-08 15:11:20,410 DEBUG TRAIN Batch 33/0 loss 3.840718 loss_att 68.020813 loss_ctc 7.428159 loss_rnnt 3.442113 lr 0.00024014 rank 2
2022-12-08 15:11:20,421 DEBUG TRAIN Batch 33/0 loss 8.662479 loss_att 76.865891 loss_ctc 14.685593 loss_rnnt 7.993244 lr 0.00024015 rank 6
2022-12-08 15:12:22,909 DEBUG TRAIN Batch 33/100 loss 3.727926 loss_att 329.805695 loss_ctc 12.426241 loss_rnnt 2.761447 lr 0.00024012 rank 1
2022-12-08 15:12:22,922 DEBUG TRAIN Batch 33/100 loss 7.995601 loss_att 360.294006 loss_ctc 16.134457 loss_rnnt 7.091283 lr 0.00024011 rank 2
2022-12-08 15:12:22,924 DEBUG TRAIN Batch 33/100 loss 4.763614 loss_att 332.379608 loss_ctc 13.866373 loss_rnnt 3.752196 lr 0.00024009 rank 7
2022-12-08 15:12:22,926 DEBUG TRAIN Batch 33/100 loss 6.049195 loss_att 376.737305 loss_ctc 12.032953 loss_rnnt 5.384334 lr 0.00024012 rank 6
2022-12-08 15:12:22,926 DEBUG TRAIN Batch 33/100 loss 10.524165 loss_att 343.262756 loss_ctc 18.515491 loss_rnnt 9.636240 lr 0.00024013 rank 5
2022-12-08 15:12:22,926 DEBUG TRAIN Batch 33/100 loss 8.802955 loss_att 408.495117 loss_ctc 21.367050 loss_rnnt 7.406944 lr 0.00024008 rank 0
2022-12-08 15:12:22,930 DEBUG TRAIN Batch 33/100 loss 5.853814 loss_att 431.649994 loss_ctc 14.064169 loss_rnnt 4.941552 lr 0.00024009 rank 4
2022-12-08 15:12:22,964 DEBUG TRAIN Batch 33/100 loss 2.057328 loss_att 434.798279 loss_ctc 5.030316 loss_rnnt 1.726996 lr 0.00024010 rank 3
2022-12-08 15:13:26,347 DEBUG TRAIN Batch 33/200 loss 12.953783 loss_att 465.386108 loss_ctc 20.157022 loss_rnnt 12.153423 lr 0.00024007 rank 4
2022-12-08 15:13:26,348 DEBUG TRAIN Batch 33/200 loss 10.054045 loss_att 323.132233 loss_ctc 20.984550 loss_rnnt 8.839544 lr 0.00024006 rank 7
2022-12-08 15:13:26,352 DEBUG TRAIN Batch 33/200 loss 7.973286 loss_att 491.568359 loss_ctc 20.379002 loss_rnnt 6.594873 lr 0.00024008 rank 2
2022-12-08 15:13:26,354 DEBUG TRAIN Batch 33/200 loss 5.942398 loss_att 387.132507 loss_ctc 9.302613 loss_rnnt 5.569041 lr 0.00024010 rank 6
2022-12-08 15:13:26,359 DEBUG TRAIN Batch 33/200 loss 2.591502 loss_att 359.485199 loss_ctc 6.000027 loss_rnnt 2.212777 lr 0.00024010 rank 5
2022-12-08 15:13:26,359 DEBUG TRAIN Batch 33/200 loss 4.244267 loss_att 349.627686 loss_ctc 12.168394 loss_rnnt 3.363809 lr 0.00024007 rank 3
2022-12-08 15:13:26,359 DEBUG TRAIN Batch 33/200 loss 11.156878 loss_att 419.720398 loss_ctc 17.480247 loss_rnnt 10.454282 lr 0.00024005 rank 0
2022-12-08 15:13:26,360 DEBUG TRAIN Batch 33/200 loss 3.172913 loss_att 309.396179 loss_ctc 8.821894 loss_rnnt 2.545248 lr 0.00024009 rank 1
2022-12-08 15:14:30,599 DEBUG TRAIN Batch 33/300 loss 7.886477 loss_att 353.944092 loss_ctc 10.564926 loss_rnnt 7.588871 lr 0.00024007 rank 6
2022-12-08 15:14:30,600 DEBUG TRAIN Batch 33/300 loss 7.486972 loss_att 350.470703 loss_ctc 12.666456 loss_rnnt 6.911474 lr 0.00024004 rank 7
2022-12-08 15:14:30,601 DEBUG TRAIN Batch 33/300 loss 7.999704 loss_att 394.634064 loss_ctc 17.140650 loss_rnnt 6.984043 lr 0.00024006 rank 2
2022-12-08 15:14:30,602 DEBUG TRAIN Batch 33/300 loss 13.709402 loss_att 420.653931 loss_ctc 29.542431 loss_rnnt 11.950177 lr 0.00024004 rank 3
2022-12-08 15:14:30,602 DEBUG TRAIN Batch 33/300 loss 4.379703 loss_att 371.174622 loss_ctc 10.727459 loss_rnnt 3.674397 lr 0.00024004 rank 4
2022-12-08 15:14:30,605 DEBUG TRAIN Batch 33/300 loss 7.567981 loss_att 413.988647 loss_ctc 17.636229 loss_rnnt 6.449287 lr 0.00024003 rank 0
2022-12-08 15:14:30,628 DEBUG TRAIN Batch 33/300 loss 3.388177 loss_att 391.627136 loss_ctc 17.756544 loss_rnnt 1.791691 lr 0.00024007 rank 5
2022-12-08 15:14:30,643 DEBUG TRAIN Batch 33/300 loss 6.938290 loss_att 443.631042 loss_ctc 21.622883 loss_rnnt 5.306668 lr 0.00024006 rank 1
2022-12-08 15:15:40,348 DEBUG TRAIN Batch 33/400 loss 5.991102 loss_att 378.107727 loss_ctc 12.338675 loss_rnnt 5.285816 lr 0.00024001 rank 7
2022-12-08 15:15:40,349 DEBUG TRAIN Batch 33/400 loss 11.971634 loss_att 441.326660 loss_ctc 24.013290 loss_rnnt 10.633673 lr 0.00024001 rank 4
2022-12-08 15:15:40,353 DEBUG TRAIN Batch 33/400 loss 5.843787 loss_att 345.888763 loss_ctc 18.397686 loss_rnnt 4.448910 lr 0.00024004 rank 6
2022-12-08 15:15:40,354 DEBUG TRAIN Batch 33/400 loss 7.352639 loss_att 268.622772 loss_ctc 14.317228 loss_rnnt 6.578796 lr 0.00024002 rank 3
2022-12-08 15:15:40,354 DEBUG TRAIN Batch 33/400 loss 6.864434 loss_att 348.546600 loss_ctc 20.168253 loss_rnnt 5.386232 lr 0.00024003 rank 2
2022-12-08 15:15:40,355 DEBUG TRAIN Batch 33/400 loss 7.731181 loss_att 375.540283 loss_ctc 20.729475 loss_rnnt 6.286926 lr 0.00024004 rank 1
2022-12-08 15:15:40,355 DEBUG TRAIN Batch 33/400 loss 5.182050 loss_att 374.768433 loss_ctc 9.676999 loss_rnnt 4.682611 lr 0.00024005 rank 5
2022-12-08 15:15:40,356 DEBUG TRAIN Batch 33/400 loss 12.104288 loss_att 340.324890 loss_ctc 18.319828 loss_rnnt 11.413673 lr 0.00024000 rank 0
2022-12-08 15:16:43,234 DEBUG TRAIN Batch 33/500 loss 8.438784 loss_att 339.752136 loss_ctc 15.976653 loss_rnnt 7.601242 lr 0.00023998 rank 4
2022-12-08 15:16:43,241 DEBUG TRAIN Batch 33/500 loss 5.864469 loss_att 351.424561 loss_ctc 17.648643 loss_rnnt 4.555116 lr 0.00023999 rank 3
2022-12-08 15:16:43,241 DEBUG TRAIN Batch 33/500 loss 7.250962 loss_att 318.117249 loss_ctc 15.476590 loss_rnnt 6.337004 lr 0.00023997 rank 0
2022-12-08 15:16:43,241 DEBUG TRAIN Batch 33/500 loss 3.485764 loss_att 352.797913 loss_ctc 12.137686 loss_rnnt 2.524440 lr 0.00024001 rank 1
2022-12-08 15:16:43,243 DEBUG TRAIN Batch 33/500 loss 5.773763 loss_att 329.526428 loss_ctc 10.612172 loss_rnnt 5.236162 lr 0.00024002 rank 5
2022-12-08 15:16:43,244 DEBUG TRAIN Batch 33/500 loss 2.880541 loss_att 362.757355 loss_ctc 7.491908 loss_rnnt 2.368166 lr 0.00024000 rank 2
2022-12-08 15:16:43,246 DEBUG TRAIN Batch 33/500 loss 8.379198 loss_att 272.252258 loss_ctc 10.309521 loss_rnnt 8.164718 lr 0.00024001 rank 6
2022-12-08 15:16:43,247 DEBUG TRAIN Batch 33/500 loss 4.920883 loss_att 350.996643 loss_ctc 10.147348 loss_rnnt 4.340165 lr 0.00023998 rank 7
2022-12-08 15:17:46,663 DEBUG TRAIN Batch 33/600 loss 14.399092 loss_att 170.570786 loss_ctc 17.863022 loss_rnnt 14.014211 lr 0.00023999 rank 6
2022-12-08 15:17:46,664 DEBUG TRAIN Batch 33/600 loss 7.805925 loss_att 164.271805 loss_ctc 12.583025 loss_rnnt 7.275136 lr 0.00023995 rank 7
2022-12-08 15:17:46,665 DEBUG TRAIN Batch 33/600 loss 6.361828 loss_att 254.518661 loss_ctc 14.112974 loss_rnnt 5.500590 lr 0.00023996 rank 4
2022-12-08 15:17:46,668 DEBUG TRAIN Batch 33/600 loss 10.000029 loss_att 280.368744 loss_ctc 21.421398 loss_rnnt 8.730988 lr 0.00023997 rank 2
2022-12-08 15:17:46,668 DEBUG TRAIN Batch 33/600 loss 11.746213 loss_att 276.920502 loss_ctc 20.979578 loss_rnnt 10.720284 lr 0.00023998 rank 1
2022-12-08 15:17:46,668 DEBUG TRAIN Batch 33/600 loss 8.211156 loss_att 215.823990 loss_ctc 14.094961 loss_rnnt 7.557400 lr 0.00023996 rank 3
2022-12-08 15:17:46,669 DEBUG TRAIN Batch 33/600 loss 6.443196 loss_att 190.527847 loss_ctc 13.428434 loss_rnnt 5.667058 lr 0.00023994 rank 0
2022-12-08 15:17:46,669 DEBUG TRAIN Batch 33/600 loss 8.027830 loss_att 255.825485 loss_ctc 14.123886 loss_rnnt 7.350491 lr 0.00023999 rank 5
2022-12-08 15:19:00,141 DEBUG TRAIN Batch 33/700 loss 6.773904 loss_att 346.413757 loss_ctc 18.698364 loss_rnnt 5.448964 lr 0.00023993 rank 4
2022-12-08 15:19:00,143 DEBUG TRAIN Batch 33/700 loss 2.801324 loss_att 397.106079 loss_ctc 7.091468 loss_rnnt 2.324642 lr 0.00023995 rank 2
2022-12-08 15:19:00,145 DEBUG TRAIN Batch 33/700 loss 4.693570 loss_att 420.666077 loss_ctc 11.574886 loss_rnnt 3.928979 lr 0.00023996 rank 5
2022-12-08 15:19:00,161 DEBUG TRAIN Batch 33/700 loss 10.130250 loss_att 418.931335 loss_ctc 16.161152 loss_rnnt 9.460150 lr 0.00023992 rank 0
2022-12-08 15:19:00,164 DEBUG TRAIN Batch 33/700 loss 3.225283 loss_att 389.422119 loss_ctc 7.171142 loss_rnnt 2.786855 lr 0.00023993 rank 7
2022-12-08 15:19:00,172 DEBUG TRAIN Batch 33/700 loss 2.450429 loss_att 439.933441 loss_ctc 10.890713 loss_rnnt 1.512619 lr 0.00023993 rank 3
2022-12-08 15:19:00,177 DEBUG TRAIN Batch 33/700 loss 3.191096 loss_att 407.195007 loss_ctc 7.917987 loss_rnnt 2.665886 lr 0.00023996 rank 6
2022-12-08 15:19:00,198 DEBUG TRAIN Batch 33/700 loss 7.816159 loss_att 314.185883 loss_ctc 20.607048 loss_rnnt 6.394949 lr 0.00023995 rank 1
2022-12-08 15:20:03,384 DEBUG TRAIN Batch 33/800 loss 2.705826 loss_att 347.859192 loss_ctc 6.441760 loss_rnnt 2.290723 lr 0.00023992 rank 1
2022-12-08 15:20:03,390 DEBUG TRAIN Batch 33/800 loss 2.665576 loss_att 374.757660 loss_ctc 6.875491 loss_rnnt 2.197808 lr 0.00023991 rank 3
2022-12-08 15:20:03,390 DEBUG TRAIN Batch 33/800 loss 5.163789 loss_att 388.696381 loss_ctc 11.417397 loss_rnnt 4.468944 lr 0.00023990 rank 7
2022-12-08 15:20:03,394 DEBUG TRAIN Batch 33/800 loss 3.115282 loss_att 353.835876 loss_ctc 10.346281 loss_rnnt 2.311837 lr 0.00023992 rank 2
2022-12-08 15:20:03,394 DEBUG TRAIN Batch 33/800 loss 10.659218 loss_att 419.846191 loss_ctc 22.026493 loss_rnnt 9.396188 lr 0.00023993 rank 5
2022-12-08 15:20:03,395 DEBUG TRAIN Batch 33/800 loss 2.950483 loss_att 355.258057 loss_ctc 8.239565 loss_rnnt 2.362807 lr 0.00023989 rank 0
2022-12-08 15:20:03,395 DEBUG TRAIN Batch 33/800 loss 2.323392 loss_att 346.722137 loss_ctc 6.927105 loss_rnnt 1.811868 lr 0.00023990 rank 4
2022-12-08 15:20:03,401 DEBUG TRAIN Batch 33/800 loss 3.968069 loss_att 316.885864 loss_ctc 10.065048 loss_rnnt 3.290627 lr 0.00023993 rank 6
2022-12-08 15:21:06,314 DEBUG TRAIN Batch 33/900 loss 7.249366 loss_att 316.421448 loss_ctc 15.370847 loss_rnnt 6.346980 lr 0.00023987 rank 4
2022-12-08 15:21:06,317 DEBUG TRAIN Batch 33/900 loss 5.894270 loss_att 323.644470 loss_ctc 9.135405 loss_rnnt 5.534144 lr 0.00023988 rank 3
2022-12-08 15:21:06,317 DEBUG TRAIN Batch 33/900 loss 4.146988 loss_att 299.002136 loss_ctc 9.683933 loss_rnnt 3.531772 lr 0.00023987 rank 7
2022-12-08 15:21:06,321 DEBUG TRAIN Batch 33/900 loss 10.973069 loss_att 409.096497 loss_ctc 17.566252 loss_rnnt 10.240494 lr 0.00023991 rank 5
2022-12-08 15:21:06,321 DEBUG TRAIN Batch 33/900 loss 7.460782 loss_att 357.542114 loss_ctc 19.743681 loss_rnnt 6.096015 lr 0.00023986 rank 0
2022-12-08 15:21:06,321 DEBUG TRAIN Batch 33/900 loss 5.448495 loss_att 379.740173 loss_ctc 7.777641 loss_rnnt 5.189701 lr 0.00023989 rank 2
2022-12-08 15:21:06,323 DEBUG TRAIN Batch 33/900 loss 2.260987 loss_att 357.598022 loss_ctc 4.280433 loss_rnnt 2.036604 lr 0.00023990 rank 1
2022-12-08 15:21:06,328 DEBUG TRAIN Batch 33/900 loss 15.563064 loss_att 445.403687 loss_ctc 30.678221 loss_rnnt 13.883601 lr 0.00023990 rank 6
2022-12-08 15:22:10,050 DEBUG TRAIN Batch 33/1000 loss 7.921809 loss_att 347.987762 loss_ctc 16.020420 loss_rnnt 7.021964 lr 0.00023985 rank 3
2022-12-08 15:22:10,050 DEBUG TRAIN Batch 33/1000 loss 5.139762 loss_att 373.664490 loss_ctc 12.757671 loss_rnnt 4.293328 lr 0.00023984 rank 7
2022-12-08 15:22:10,051 DEBUG TRAIN Batch 33/1000 loss 6.786466 loss_att 387.754639 loss_ctc 13.206305 loss_rnnt 6.073151 lr 0.00023987 rank 6
2022-12-08 15:22:10,054 DEBUG TRAIN Batch 33/1000 loss 9.564284 loss_att 387.945007 loss_ctc 21.209459 loss_rnnt 8.270376 lr 0.00023983 rank 0
2022-12-08 15:22:10,055 DEBUG TRAIN Batch 33/1000 loss 10.860879 loss_att 353.621521 loss_ctc 24.200922 loss_rnnt 9.378652 lr 0.00023985 rank 4
2022-12-08 15:22:10,055 DEBUG TRAIN Batch 33/1000 loss 4.347547 loss_att 407.035950 loss_ctc 11.761153 loss_rnnt 3.523813 lr 0.00023988 rank 5
2022-12-08 15:22:10,056 DEBUG TRAIN Batch 33/1000 loss 6.327606 loss_att 388.924561 loss_ctc 17.613640 loss_rnnt 5.073603 lr 0.00023987 rank 1
2022-12-08 15:22:10,056 DEBUG TRAIN Batch 33/1000 loss 2.875878 loss_att 348.287323 loss_ctc 8.252119 loss_rnnt 2.278518 lr 0.00023986 rank 2
2022-12-08 15:23:20,329 DEBUG TRAIN Batch 33/1100 loss 5.725908 loss_att 330.093781 loss_ctc 11.868000 loss_rnnt 5.043453 lr 0.00023981 rank 0
2022-12-08 15:23:20,330 DEBUG TRAIN Batch 33/1100 loss 10.190624 loss_att 369.146179 loss_ctc 21.207352 loss_rnnt 8.966544 lr 0.00023981 rank 7
2022-12-08 15:23:20,332 DEBUG TRAIN Batch 33/1100 loss 5.734058 loss_att 341.147919 loss_ctc 8.419010 loss_rnnt 5.435730 lr 0.00023982 rank 3
2022-12-08 15:23:20,333 DEBUG TRAIN Batch 33/1100 loss 6.636522 loss_att 340.212219 loss_ctc 14.695507 loss_rnnt 5.741079 lr 0.00023983 rank 2
2022-12-08 15:23:20,333 DEBUG TRAIN Batch 33/1100 loss 11.263015 loss_att 411.255554 loss_ctc 19.251614 loss_rnnt 10.375393 lr 0.00023982 rank 4
2022-12-08 15:23:20,336 DEBUG TRAIN Batch 33/1100 loss 5.948694 loss_att 360.700287 loss_ctc 13.498764 loss_rnnt 5.109797 lr 0.00023985 rank 6
2022-12-08 15:23:20,336 DEBUG TRAIN Batch 33/1100 loss 12.335814 loss_att 317.234558 loss_ctc 19.147760 loss_rnnt 11.578931 lr 0.00023984 rank 1
2022-12-08 15:23:20,344 DEBUG TRAIN Batch 33/1100 loss 6.548343 loss_att 349.105103 loss_ctc 16.487381 loss_rnnt 5.444005 lr 0.00023985 rank 5
2022-12-08 15:24:23,909 DEBUG TRAIN Batch 33/1200 loss 13.075260 loss_att 355.010529 loss_ctc 22.336870 loss_rnnt 12.046192 lr 0.00023981 rank 1
2022-12-08 15:24:23,916 DEBUG TRAIN Batch 33/1200 loss 11.436517 loss_att 292.005280 loss_ctc 19.905281 loss_rnnt 10.495543 lr 0.00023979 rank 4
2022-12-08 15:24:23,921 DEBUG TRAIN Batch 33/1200 loss 5.359108 loss_att 277.904419 loss_ctc 11.694448 loss_rnnt 4.655181 lr 0.00023979 rank 7
2022-12-08 15:24:23,921 DEBUG TRAIN Batch 33/1200 loss 8.246295 loss_att 224.037842 loss_ctc 17.510073 loss_rnnt 7.216986 lr 0.00023982 rank 6
2022-12-08 15:24:23,922 DEBUG TRAIN Batch 33/1200 loss 6.447913 loss_att 276.118378 loss_ctc 13.027804 loss_rnnt 5.716814 lr 0.00023980 rank 3
2022-12-08 15:24:23,923 DEBUG TRAIN Batch 33/1200 loss 2.397493 loss_att 255.080276 loss_ctc 4.777497 loss_rnnt 2.133048 lr 0.00023982 rank 5
2022-12-08 15:24:23,927 DEBUG TRAIN Batch 33/1200 loss 7.724858 loss_att 279.006104 loss_ctc 15.740318 loss_rnnt 6.834251 lr 0.00023981 rank 2
2022-12-08 15:24:23,927 DEBUG TRAIN Batch 33/1200 loss 11.939273 loss_att 258.035248 loss_ctc 18.197294 loss_rnnt 11.243937 lr 0.00023978 rank 0
2022-12-08 15:25:27,591 DEBUG TRAIN Batch 33/1300 loss 5.438031 loss_att 420.960754 loss_ctc 11.641166 loss_rnnt 4.748795 lr 0.00023976 rank 4
2022-12-08 15:25:27,609 DEBUG TRAIN Batch 33/1300 loss 2.742883 loss_att 407.814392 loss_ctc 6.543610 loss_rnnt 2.320580 lr 0.00023979 rank 1
2022-12-08 15:25:27,610 DEBUG TRAIN Batch 33/1300 loss 6.316875 loss_att 380.641785 loss_ctc 24.841154 loss_rnnt 4.258621 lr 0.00023976 rank 7
2022-12-08 15:25:27,610 DEBUG TRAIN Batch 33/1300 loss 2.825104 loss_att 475.379761 loss_ctc 8.411494 loss_rnnt 2.204394 lr 0.00023978 rank 2
2022-12-08 15:25:27,611 DEBUG TRAIN Batch 33/1300 loss 6.863480 loss_att 263.872498 loss_ctc 12.515730 loss_rnnt 6.235452 lr 0.00023977 rank 3
2022-12-08 15:25:27,612 DEBUG TRAIN Batch 33/1300 loss 1.243832 loss_att 342.474213 loss_ctc 4.114050 loss_rnnt 0.924919 lr 0.00023980 rank 5
2022-12-08 15:25:27,615 DEBUG TRAIN Batch 33/1300 loss 2.646596 loss_att 409.121460 loss_ctc 6.235361 loss_rnnt 2.247844 lr 0.00023975 rank 0
2022-12-08 15:25:27,649 DEBUG TRAIN Batch 33/1300 loss 5.624439 loss_att 99.333282 loss_ctc 9.614261 loss_rnnt 5.181126 lr 0.00023979 rank 6
2022-12-08 15:26:32,366 DEBUG TRAIN Batch 33/1400 loss 7.364748 loss_att 373.591309 loss_ctc 16.076580 loss_rnnt 6.396766 lr 0.00023976 rank 1
2022-12-08 15:26:32,372 DEBUG TRAIN Batch 33/1400 loss 12.504028 loss_att 376.655975 loss_ctc 21.078018 loss_rnnt 11.551364 lr 0.00023975 rank 2
2022-12-08 15:26:32,373 DEBUG TRAIN Batch 33/1400 loss 10.460594 loss_att 358.749603 loss_ctc 23.481808 loss_rnnt 9.013793 lr 0.00023976 rank 6
2022-12-08 15:26:32,373 DEBUG TRAIN Batch 33/1400 loss 3.242574 loss_att 367.795746 loss_ctc 11.178671 loss_rnnt 2.360785 lr 0.00023974 rank 3
2022-12-08 15:26:32,378 DEBUG TRAIN Batch 33/1400 loss 12.623192 loss_att 431.214844 loss_ctc 22.164169 loss_rnnt 11.563083 lr 0.00023977 rank 5
2022-12-08 15:26:32,384 DEBUG TRAIN Batch 33/1400 loss 7.659113 loss_att 319.076355 loss_ctc 20.608496 loss_rnnt 6.220293 lr 0.00023972 rank 0
2022-12-08 15:26:32,393 DEBUG TRAIN Batch 33/1400 loss 15.813887 loss_att 390.248871 loss_ctc 27.444586 loss_rnnt 14.521586 lr 0.00023974 rank 4
2022-12-08 15:26:32,396 DEBUG TRAIN Batch 33/1400 loss 4.830966 loss_att 377.975525 loss_ctc 10.920001 loss_rnnt 4.154406 lr 0.00023973 rank 7
2022-12-08 15:27:43,869 DEBUG TRAIN Batch 33/1500 loss 1.008888 loss_att 392.095795 loss_ctc 3.997222 loss_rnnt 0.676851 lr 0.00023971 rank 3
2022-12-08 15:27:43,871 DEBUG TRAIN Batch 33/1500 loss 4.093144 loss_att 352.359314 loss_ctc 10.675047 loss_rnnt 3.361822 lr 0.00023974 rank 5
2022-12-08 15:27:43,871 DEBUG TRAIN Batch 33/1500 loss 5.666381 loss_att 376.375580 loss_ctc 9.203639 loss_rnnt 5.273352 lr 0.00023974 rank 6
2022-12-08 15:27:43,876 DEBUG TRAIN Batch 33/1500 loss 2.507797 loss_att 319.067078 loss_ctc 9.068457 loss_rnnt 1.778835 lr 0.00023970 rank 0
2022-12-08 15:27:43,876 DEBUG TRAIN Batch 33/1500 loss 7.721141 loss_att 420.207642 loss_ctc 13.329355 loss_rnnt 7.098006 lr 0.00023971 rank 4
2022-12-08 15:27:43,879 DEBUG TRAIN Batch 33/1500 loss 6.668429 loss_att 355.414886 loss_ctc 9.589483 loss_rnnt 6.343868 lr 0.00023973 rank 1
2022-12-08 15:27:43,878 DEBUG TRAIN Batch 33/1500 loss 21.422543 loss_att 454.336060 loss_ctc 34.648994 loss_rnnt 19.952938 lr 0.00023970 rank 7
2022-12-08 15:27:43,916 DEBUG TRAIN Batch 33/1500 loss 1.421735 loss_att 334.199890 loss_ctc 5.611065 loss_rnnt 0.956254 lr 0.00023972 rank 2
2022-12-08 15:28:46,881 DEBUG TRAIN Batch 33/1600 loss 2.507803 loss_att 398.402374 loss_ctc 6.548619 loss_rnnt 2.058824 lr 0.00023968 rank 4
2022-12-08 15:28:46,892 DEBUG TRAIN Batch 33/1600 loss 9.531677 loss_att 376.760193 loss_ctc 18.267565 loss_rnnt 8.561024 lr 0.00023969 rank 3
2022-12-08 15:28:46,897 DEBUG TRAIN Batch 33/1600 loss 5.688754 loss_att 364.216736 loss_ctc 12.708045 loss_rnnt 4.908833 lr 0.00023968 rank 7
2022-12-08 15:28:46,900 DEBUG TRAIN Batch 33/1600 loss 5.938697 loss_att 417.377289 loss_ctc 14.450904 loss_rnnt 4.992897 lr 0.00023971 rank 6
2022-12-08 15:28:46,901 DEBUG TRAIN Batch 33/1600 loss 7.914275 loss_att 356.303223 loss_ctc 18.566914 loss_rnnt 6.730649 lr 0.00023970 rank 1
2022-12-08 15:28:46,904 DEBUG TRAIN Batch 33/1600 loss 5.688704 loss_att 329.782043 loss_ctc 17.690098 loss_rnnt 4.355215 lr 0.00023970 rank 2
2022-12-08 15:28:46,904 DEBUG TRAIN Batch 33/1600 loss 8.985365 loss_att 451.973083 loss_ctc 16.976139 loss_rnnt 8.097502 lr 0.00023967 rank 0
2022-12-08 15:28:46,945 DEBUG TRAIN Batch 33/1600 loss 10.125402 loss_att 304.937195 loss_ctc 12.788401 loss_rnnt 9.829514 lr 0.00023971 rank 5
2022-12-08 15:29:50,759 DEBUG TRAIN Batch 33/1700 loss 2.928345 loss_att 407.732300 loss_ctc 12.125690 loss_rnnt 1.906417 lr 0.00023965 rank 7
2022-12-08 15:29:50,761 DEBUG TRAIN Batch 33/1700 loss 6.562022 loss_att 353.369293 loss_ctc 15.050823 loss_rnnt 5.618822 lr 0.00023965 rank 4
2022-12-08 15:29:50,762 DEBUG TRAIN Batch 33/1700 loss 18.919828 loss_att 425.695129 loss_ctc 37.108021 loss_rnnt 16.898918 lr 0.00023968 rank 6
2022-12-08 15:29:50,765 DEBUG TRAIN Batch 33/1700 loss 16.007259 loss_att 423.558899 loss_ctc 24.332874 loss_rnnt 15.082191 lr 0.00023967 rank 2
2022-12-08 15:29:50,766 DEBUG TRAIN Batch 33/1700 loss 12.418504 loss_att 336.886719 loss_ctc 23.000019 loss_rnnt 11.242780 lr 0.00023969 rank 5
2022-12-08 15:29:50,766 DEBUG TRAIN Batch 33/1700 loss 6.198855 loss_att 328.935852 loss_ctc 10.890446 loss_rnnt 5.677567 lr 0.00023964 rank 0
2022-12-08 15:29:50,768 DEBUG TRAIN Batch 33/1700 loss 12.209581 loss_att 408.076782 loss_ctc 17.749214 loss_rnnt 11.594067 lr 0.00023968 rank 1
2022-12-08 15:29:50,804 DEBUG TRAIN Batch 33/1700 loss 4.695107 loss_att 349.686188 loss_ctc 11.976868 loss_rnnt 3.886022 lr 0.00023966 rank 3
2022-12-08 15:31:03,748 DEBUG TRAIN Batch 33/1800 loss 5.467816 loss_att 337.153900 loss_ctc 11.736049 loss_rnnt 4.771346 lr 0.00023962 rank 7
2022-12-08 15:31:03,749 DEBUG TRAIN Batch 33/1800 loss 7.930006 loss_att 304.453430 loss_ctc 13.566401 loss_rnnt 7.303740 lr 0.00023964 rank 2
2022-12-08 15:31:03,749 DEBUG TRAIN Batch 33/1800 loss 7.428557 loss_att 344.976318 loss_ctc 15.805597 loss_rnnt 6.497776 lr 0.00023963 rank 3
2022-12-08 15:31:03,754 DEBUG TRAIN Batch 33/1800 loss 7.777228 loss_att 258.499817 loss_ctc 16.558094 loss_rnnt 6.801577 lr 0.00023966 rank 5
2022-12-08 15:31:03,754 DEBUG TRAIN Batch 33/1800 loss 6.454225 loss_att 360.809753 loss_ctc 15.284402 loss_rnnt 5.473094 lr 0.00023965 rank 1
2022-12-08 15:31:03,758 DEBUG TRAIN Batch 33/1800 loss 5.771562 loss_att 313.955261 loss_ctc 10.344970 loss_rnnt 5.263405 lr 0.00023961 rank 0
2022-12-08 15:31:03,761 DEBUG TRAIN Batch 33/1800 loss 2.979118 loss_att 307.820190 loss_ctc 7.492484 loss_rnnt 2.477633 lr 0.00023963 rank 4
2022-12-08 15:31:03,796 DEBUG TRAIN Batch 33/1800 loss 3.408337 loss_att 309.647095 loss_ctc 9.402684 loss_rnnt 2.742298 lr 0.00023965 rank 6
2022-12-08 15:32:07,756 DEBUG TRAIN Batch 33/1900 loss 4.167303 loss_att 152.923828 loss_ctc 7.250069 loss_rnnt 3.824774 lr 0.00023960 rank 4
2022-12-08 15:32:07,760 DEBUG TRAIN Batch 33/1900 loss 6.847054 loss_att 196.014740 loss_ctc 12.410001 loss_rnnt 6.228950 lr 0.00023963 rank 6
2022-12-08 15:32:07,761 DEBUG TRAIN Batch 33/1900 loss 4.439674 loss_att 391.070404 loss_ctc 13.054439 loss_rnnt 3.482478 lr 0.00023959 rank 7
2022-12-08 15:32:07,761 DEBUG TRAIN Batch 33/1900 loss 7.856092 loss_att 190.049042 loss_ctc 13.348200 loss_rnnt 7.245859 lr 0.00023961 rank 2
2022-12-08 15:32:07,766 DEBUG TRAIN Batch 33/1900 loss 7.845609 loss_att 228.075592 loss_ctc 9.974400 loss_rnnt 7.609076 lr 0.00023962 rank 1
2022-12-08 15:32:07,769 DEBUG TRAIN Batch 33/1900 loss 5.892992 loss_att 322.824036 loss_ctc 11.786487 loss_rnnt 5.238159 lr 0.00023960 rank 3
2022-12-08 15:32:07,770 DEBUG TRAIN Batch 33/1900 loss 7.060391 loss_att 216.094116 loss_ctc 13.374800 loss_rnnt 6.358790 lr 0.00023959 rank 0
2022-12-08 15:32:07,771 DEBUG TRAIN Batch 33/1900 loss 3.339840 loss_att 383.717957 loss_ctc 8.762112 loss_rnnt 2.737365 lr 0.00023963 rank 5
2022-12-08 15:33:10,995 DEBUG TRAIN Batch 33/2000 loss 9.821298 loss_att 412.554443 loss_ctc 19.411436 loss_rnnt 8.755727 lr 0.00023960 rank 6
2022-12-08 15:33:10,998 DEBUG TRAIN Batch 33/2000 loss 1.644745 loss_att 333.414307 loss_ctc 4.086313 loss_rnnt 1.373460 lr 0.00023959 rank 2
2022-12-08 15:33:10,998 DEBUG TRAIN Batch 33/2000 loss 13.555828 loss_att 478.770935 loss_ctc 29.368088 loss_rnnt 11.798911 lr 0.00023957 rank 7
2022-12-08 15:33:10,999 DEBUG TRAIN Batch 33/2000 loss 2.138954 loss_att 470.442230 loss_ctc 8.134319 loss_rnnt 1.472803 lr 0.00023957 rank 4
2022-12-08 15:33:11,000 DEBUG TRAIN Batch 33/2000 loss 1.083606 loss_att 442.206573 loss_ctc 4.832638 loss_rnnt 0.667047 lr 0.00023958 rank 3
2022-12-08 15:33:11,000 DEBUG TRAIN Batch 33/2000 loss 5.852684 loss_att 394.747894 loss_ctc 18.065563 loss_rnnt 4.495697 lr 0.00023959 rank 1
2022-12-08 15:33:11,001 DEBUG TRAIN Batch 33/2000 loss 8.420609 loss_att 394.705811 loss_ctc 15.143118 loss_rnnt 7.673663 lr 0.00023960 rank 5
2022-12-08 15:33:11,005 DEBUG TRAIN Batch 33/2000 loss 8.119135 loss_att 378.301758 loss_ctc 11.767330 loss_rnnt 7.713779 lr 0.00023956 rank 0
2022-12-08 15:34:15,493 DEBUG TRAIN Batch 33/2100 loss 11.079250 loss_att 440.550720 loss_ctc 18.745131 loss_rnnt 10.227487 lr 0.00023954 rank 7
2022-12-08 15:34:15,494 DEBUG TRAIN Batch 33/2100 loss 3.494843 loss_att 355.053711 loss_ctc 9.980512 loss_rnnt 2.774214 lr 0.00023957 rank 6
2022-12-08 15:34:15,494 DEBUG TRAIN Batch 33/2100 loss 29.086964 loss_att 537.830933 loss_ctc 76.616829 loss_rnnt 23.805866 lr 0.00023955 rank 3
2022-12-08 15:34:15,499 DEBUG TRAIN Batch 33/2100 loss 5.643664 loss_att 410.184174 loss_ctc 10.523977 loss_rnnt 5.101407 lr 0.00023954 rank 4
2022-12-08 15:34:15,514 DEBUG TRAIN Batch 33/2100 loss 7.890209 loss_att 358.560760 loss_ctc 21.233078 loss_rnnt 6.407668 lr 0.00023953 rank 0
2022-12-08 15:34:15,514 DEBUG TRAIN Batch 33/2100 loss 2.049049 loss_att 332.418152 loss_ctc 4.965166 loss_rnnt 1.725037 lr 0.00023958 rank 5
2022-12-08 15:34:15,521 DEBUG TRAIN Batch 33/2100 loss 6.857203 loss_att 387.971680 loss_ctc 15.008758 loss_rnnt 5.951474 lr 0.00023957 rank 1
2022-12-08 15:34:15,529 DEBUG TRAIN Batch 33/2100 loss 4.356620 loss_att 397.758484 loss_ctc 9.982302 loss_rnnt 3.731544 lr 0.00023956 rank 2
2022-12-08 15:35:25,490 DEBUG TRAIN Batch 33/2200 loss 6.445399 loss_att 326.811310 loss_ctc 14.591833 loss_rnnt 5.540240 lr 0.00023952 rank 4
2022-12-08 15:35:25,491 DEBUG TRAIN Batch 33/2200 loss 14.805532 loss_att 397.916718 loss_ctc 29.914042 loss_rnnt 13.126809 lr 0.00023951 rank 7
2022-12-08 15:35:25,495 DEBUG TRAIN Batch 33/2200 loss 9.375723 loss_att 391.944641 loss_ctc 22.187021 loss_rnnt 7.952246 lr 0.00023954 rank 6
2022-12-08 15:35:25,496 DEBUG TRAIN Batch 33/2200 loss 10.447282 loss_att 343.410217 loss_ctc 16.820181 loss_rnnt 9.739182 lr 0.00023955 rank 5
2022-12-08 15:35:25,497 DEBUG TRAIN Batch 33/2200 loss 4.139434 loss_att 324.608490 loss_ctc 7.407943 loss_rnnt 3.776267 lr 0.00023952 rank 3
2022-12-08 15:35:25,497 DEBUG TRAIN Batch 33/2200 loss 10.980886 loss_att 457.679688 loss_ctc 24.337858 loss_rnnt 9.496778 lr 0.00023950 rank 0
2022-12-08 15:35:25,499 DEBUG TRAIN Batch 33/2200 loss 3.392789 loss_att 407.603516 loss_ctc 10.019077 loss_rnnt 2.656535 lr 0.00023954 rank 1
2022-12-08 15:35:25,505 DEBUG TRAIN Batch 33/2200 loss 7.470105 loss_att 407.019653 loss_ctc 19.653389 loss_rnnt 6.116407 lr 0.00023953 rank 2
2022-12-08 15:36:28,314 DEBUG TRAIN Batch 33/2300 loss 10.131070 loss_att 414.546173 loss_ctc 20.738413 loss_rnnt 8.952477 lr 0.00023949 rank 4
2022-12-08 15:36:28,316 DEBUG TRAIN Batch 33/2300 loss 8.756344 loss_att 340.794098 loss_ctc 19.741940 loss_rnnt 7.535723 lr 0.00023950 rank 2
2022-12-08 15:36:28,317 DEBUG TRAIN Batch 33/2300 loss 5.298460 loss_att 381.107361 loss_ctc 10.386782 loss_rnnt 4.733091 lr 0.00023952 rank 6
2022-12-08 15:36:28,317 DEBUG TRAIN Batch 33/2300 loss 10.364450 loss_att 394.975861 loss_ctc 18.910015 loss_rnnt 9.414944 lr 0.00023949 rank 3
2022-12-08 15:36:28,318 DEBUG TRAIN Batch 33/2300 loss 5.387632 loss_att 338.844360 loss_ctc 10.713571 loss_rnnt 4.795861 lr 0.00023948 rank 7
2022-12-08 15:36:28,323 DEBUG TRAIN Batch 33/2300 loss 11.303426 loss_att 349.756836 loss_ctc 16.681927 loss_rnnt 10.705814 lr 0.00023948 rank 0
2022-12-08 15:36:28,324 DEBUG TRAIN Batch 33/2300 loss 3.136966 loss_att 376.952118 loss_ctc 10.943578 loss_rnnt 2.269564 lr 0.00023951 rank 1
2022-12-08 15:36:28,378 DEBUG TRAIN Batch 33/2300 loss 30.012045 loss_att 405.309296 loss_ctc 54.265770 loss_rnnt 27.317188 lr 0.00023952 rank 5
2022-12-08 15:37:31,799 DEBUG TRAIN Batch 33/2400 loss 10.560798 loss_att 353.997681 loss_ctc 23.442322 loss_rnnt 9.129517 lr 0.00023947 rank 3
2022-12-08 15:37:31,806 DEBUG TRAIN Batch 33/2400 loss 8.203470 loss_att 293.576904 loss_ctc 21.744604 loss_rnnt 6.698899 lr 0.00023946 rank 7
2022-12-08 15:37:31,814 DEBUG TRAIN Batch 33/2400 loss 25.113010 loss_att 334.667480 loss_ctc 46.206032 loss_rnnt 22.769341 lr 0.00023949 rank 6
2022-12-08 15:37:31,814 DEBUG TRAIN Batch 33/2400 loss 5.789815 loss_att 341.439575 loss_ctc 17.791647 loss_rnnt 4.456279 lr 0.00023945 rank 0
2022-12-08 15:37:31,814 DEBUG TRAIN Batch 33/2400 loss 3.982142 loss_att 350.537201 loss_ctc 10.354516 loss_rnnt 3.274100 lr 0.00023946 rank 4
2022-12-08 15:37:31,814 DEBUG TRAIN Batch 33/2400 loss 7.783291 loss_att 346.503021 loss_ctc 16.117682 loss_rnnt 6.857248 lr 0.00023948 rank 2
2022-12-08 15:37:31,815 DEBUG TRAIN Batch 33/2400 loss 5.916100 loss_att 229.554108 loss_ctc 9.608782 loss_rnnt 5.505802 lr 0.00023949 rank 5
2022-12-08 15:37:31,817 DEBUG TRAIN Batch 33/2400 loss 3.118742 loss_att 359.584045 loss_ctc 9.327559 loss_rnnt 2.428874 lr 0.00023948 rank 1
2022-12-08 15:38:42,501 DEBUG TRAIN Batch 33/2500 loss 7.675025 loss_att 177.254456 loss_ctc 13.505412 loss_rnnt 7.027205 lr 0.00023943 rank 7
2022-12-08 15:38:42,502 DEBUG TRAIN Batch 33/2500 loss 7.482224 loss_att 170.930222 loss_ctc 10.583522 loss_rnnt 7.137635 lr 0.00023943 rank 4
2022-12-08 15:38:42,505 DEBUG TRAIN Batch 33/2500 loss 6.434820 loss_att 283.630127 loss_ctc 14.561124 loss_rnnt 5.531897 lr 0.00023946 rank 1
2022-12-08 15:38:42,505 DEBUG TRAIN Batch 33/2500 loss 7.293148 loss_att 259.672211 loss_ctc 15.150511 loss_rnnt 6.420108 lr 0.00023946 rank 6
2022-12-08 15:38:42,506 DEBUG TRAIN Batch 33/2500 loss 8.392449 loss_att 326.721252 loss_ctc 20.615978 loss_rnnt 7.034280 lr 0.00023944 rank 3
2022-12-08 15:38:42,507 DEBUG TRAIN Batch 33/2500 loss 5.230595 loss_att 296.359039 loss_ctc 10.392585 loss_rnnt 4.657040 lr 0.00023945 rank 2
2022-12-08 15:38:42,508 DEBUG TRAIN Batch 33/2500 loss 13.080874 loss_att 279.207184 loss_ctc 26.014240 loss_rnnt 11.643834 lr 0.00023942 rank 0
2022-12-08 15:38:42,508 DEBUG TRAIN Batch 33/2500 loss 5.096087 loss_att 448.215546 loss_ctc 18.187086 loss_rnnt 3.641531 lr 0.00023947 rank 5
2022-12-08 15:39:46,489 DEBUG TRAIN Batch 33/2600 loss 10.557663 loss_att 437.033936 loss_ctc 12.795477 loss_rnnt 10.309017 lr 0.00023940 rank 7
2022-12-08 15:39:46,494 DEBUG TRAIN Batch 33/2600 loss 3.709453 loss_att 378.683044 loss_ctc 11.604300 loss_rnnt 2.832248 lr 0.00023941 rank 4
2022-12-08 15:39:46,495 DEBUG TRAIN Batch 33/2600 loss 3.324826 loss_att 362.673676 loss_ctc 8.874346 loss_rnnt 2.708212 lr 0.00023939 rank 0
2022-12-08 15:39:46,500 DEBUG TRAIN Batch 33/2600 loss 5.906895 loss_att 445.039520 loss_ctc 14.865147 loss_rnnt 4.911534 lr 0.00023942 rank 2
2022-12-08 15:39:46,501 DEBUG TRAIN Batch 33/2600 loss 4.228145 loss_att 439.521576 loss_ctc 9.855379 loss_rnnt 3.602897 lr 0.00023943 rank 1
2022-12-08 15:39:46,504 DEBUG TRAIN Batch 33/2600 loss 8.227098 loss_att 367.906799 loss_ctc 21.507702 loss_rnnt 6.751476 lr 0.00023944 rank 5
2022-12-08 15:39:46,504 DEBUG TRAIN Batch 33/2600 loss 4.882982 loss_att 429.769775 loss_ctc 13.497332 loss_rnnt 3.925832 lr 0.00023943 rank 6
2022-12-08 15:39:46,553 DEBUG TRAIN Batch 33/2600 loss 8.691272 loss_att 145.760620 loss_ctc 11.482261 loss_rnnt 8.381162 lr 0.00023941 rank 3
2022-12-08 15:40:50,251 DEBUG TRAIN Batch 33/2700 loss 4.460814 loss_att 374.563599 loss_ctc 12.750359 loss_rnnt 3.539754 lr 0.00023938 rank 3
2022-12-08 15:40:50,252 DEBUG TRAIN Batch 33/2700 loss 2.374693 loss_att 371.790039 loss_ctc 6.682545 loss_rnnt 1.896043 lr 0.00023938 rank 4
2022-12-08 15:40:50,252 DEBUG TRAIN Batch 33/2700 loss 2.203218 loss_att 368.942108 loss_ctc 7.271938 loss_rnnt 1.640028 lr 0.00023937 rank 7
2022-12-08 15:40:50,259 DEBUG TRAIN Batch 33/2700 loss 9.290534 loss_att 435.855164 loss_ctc 21.914806 loss_rnnt 7.887837 lr 0.00023939 rank 2
2022-12-08 15:40:50,260 DEBUG TRAIN Batch 33/2700 loss 10.905394 loss_att 439.773285 loss_ctc 24.339851 loss_rnnt 9.412676 lr 0.00023940 rank 1
2022-12-08 15:40:50,260 DEBUG TRAIN Batch 33/2700 loss 7.082996 loss_att 392.774780 loss_ctc 18.800200 loss_rnnt 5.781084 lr 0.00023941 rank 6
2022-12-08 15:40:50,261 DEBUG TRAIN Batch 33/2700 loss 11.294581 loss_att 410.742035 loss_ctc 22.680676 loss_rnnt 10.029460 lr 0.00023937 rank 0
2022-12-08 15:40:50,271 DEBUG TRAIN Batch 33/2700 loss 13.306019 loss_att 363.448425 loss_ctc 22.425472 loss_rnnt 12.292747 lr 0.00023941 rank 5
2022-12-08 15:41:54,639 DEBUG TRAIN Batch 33/2800 loss 9.295531 loss_att 393.751099 loss_ctc 21.167381 loss_rnnt 7.976437 lr 0.00023938 rank 6
2022-12-08 15:41:54,639 DEBUG TRAIN Batch 33/2800 loss 4.889485 loss_att 360.160339 loss_ctc 8.189865 loss_rnnt 4.522777 lr 0.00023937 rank 2
2022-12-08 15:41:54,642 DEBUG TRAIN Batch 33/2800 loss 2.000291 loss_att 382.124329 loss_ctc 7.550283 loss_rnnt 1.383626 lr 0.00023937 rank 1
2022-12-08 15:41:54,642 DEBUG TRAIN Batch 33/2800 loss 7.427276 loss_att 348.505920 loss_ctc 14.273243 loss_rnnt 6.666614 lr 0.00023935 rank 4
2022-12-08 15:41:54,642 DEBUG TRAIN Batch 33/2800 loss 4.146768 loss_att 342.217163 loss_ctc 10.894548 loss_rnnt 3.397014 lr 0.00023935 rank 7
2022-12-08 15:41:54,643 DEBUG TRAIN Batch 33/2800 loss 3.149569 loss_att 394.233490 loss_ctc 5.145345 loss_rnnt 2.927816 lr 0.00023934 rank 0
2022-12-08 15:41:54,673 DEBUG TRAIN Batch 33/2800 loss 8.106029 loss_att 376.059937 loss_ctc 14.669541 loss_rnnt 7.376750 lr 0.00023938 rank 5
2022-12-08 15:41:54,685 DEBUG TRAIN Batch 33/2800 loss 6.251910 loss_att 409.704193 loss_ctc 18.468407 loss_rnnt 4.894522 lr 0.00023936 rank 3
2022-12-08 15:43:05,541 DEBUG TRAIN Batch 33/2900 loss 9.539961 loss_att 417.560699 loss_ctc 25.528179 loss_rnnt 7.763493 lr 0.00023932 rank 4
2022-12-08 15:43:05,542 DEBUG TRAIN Batch 33/2900 loss 7.217710 loss_att 334.613831 loss_ctc 10.680411 loss_rnnt 6.832966 lr 0.00023932 rank 7
2022-12-08 15:43:05,544 DEBUG TRAIN Batch 33/2900 loss 8.141207 loss_att 397.294128 loss_ctc 16.910267 loss_rnnt 7.166867 lr 0.00023934 rank 2
2022-12-08 15:43:05,545 DEBUG TRAIN Batch 33/2900 loss 5.245777 loss_att 376.986938 loss_ctc 17.044613 loss_rnnt 3.934795 lr 0.00023933 rank 3
2022-12-08 15:43:05,547 DEBUG TRAIN Batch 33/2900 loss 8.504099 loss_att 362.177124 loss_ctc 18.647043 loss_rnnt 7.377106 lr 0.00023936 rank 5
2022-12-08 15:43:05,549 DEBUG TRAIN Batch 33/2900 loss 15.163888 loss_att 399.027039 loss_ctc 21.644951 loss_rnnt 14.443769 lr 0.00023935 rank 1
2022-12-08 15:43:05,551 DEBUG TRAIN Batch 33/2900 loss 8.143918 loss_att 353.573914 loss_ctc 17.684357 loss_rnnt 7.083869 lr 0.00023935 rank 6
2022-12-08 15:43:05,551 DEBUG TRAIN Batch 33/2900 loss 5.290630 loss_att 333.756897 loss_ctc 8.495025 loss_rnnt 4.934586 lr 0.00023931 rank 0
2022-12-08 15:44:09,337 DEBUG TRAIN Batch 33/3000 loss 2.588665 loss_att 277.146973 loss_ctc 7.245968 loss_rnnt 2.071187 lr 0.00023929 rank 7
2022-12-08 15:44:09,343 DEBUG TRAIN Batch 33/3000 loss 2.559629 loss_att 359.270233 loss_ctc 9.247069 loss_rnnt 1.816581 lr 0.00023930 rank 4
2022-12-08 15:44:09,345 DEBUG TRAIN Batch 33/3000 loss 3.252493 loss_att 292.822205 loss_ctc 6.419315 loss_rnnt 2.900624 lr 0.00023928 rank 0
2022-12-08 15:44:09,346 DEBUG TRAIN Batch 33/3000 loss 1.684081 loss_att 376.525299 loss_ctc 5.789260 loss_rnnt 1.227950 lr 0.00023932 rank 6
2022-12-08 15:44:09,347 DEBUG TRAIN Batch 33/3000 loss 5.221479 loss_att 265.767578 loss_ctc 12.617661 loss_rnnt 4.399681 lr 0.00023933 rank 5
2022-12-08 15:44:09,347 DEBUG TRAIN Batch 33/3000 loss 9.929729 loss_att 338.197815 loss_ctc 15.971426 loss_rnnt 9.258430 lr 0.00023932 rank 1
2022-12-08 15:44:09,348 DEBUG TRAIN Batch 33/3000 loss 4.520724 loss_att 371.139221 loss_ctc 10.277109 loss_rnnt 3.881125 lr 0.00023931 rank 2
2022-12-08 15:44:09,348 DEBUG TRAIN Batch 33/3000 loss 7.273837 loss_att 363.144989 loss_ctc 13.357695 loss_rnnt 6.597852 lr 0.00023930 rank 3
2022-12-08 15:45:12,937 DEBUG TRAIN Batch 33/3100 loss 5.878940 loss_att 306.106689 loss_ctc 14.649199 loss_rnnt 4.904467 lr 0.00023928 rank 2
2022-12-08 15:45:12,945 DEBUG TRAIN Batch 33/3100 loss 6.070689 loss_att 260.646210 loss_ctc 11.615072 loss_rnnt 5.454647 lr 0.00023927 rank 4
2022-12-08 15:45:12,946 DEBUG TRAIN Batch 33/3100 loss 5.371398 loss_att 215.593491 loss_ctc 8.457451 loss_rnnt 5.028504 lr 0.00023927 rank 7
2022-12-08 15:45:12,950 DEBUG TRAIN Batch 33/3100 loss 4.389514 loss_att 307.975739 loss_ctc 8.551682 loss_rnnt 3.927051 lr 0.00023930 rank 6
2022-12-08 15:45:12,953 DEBUG TRAIN Batch 33/3100 loss 8.369181 loss_att 297.206512 loss_ctc 17.748667 loss_rnnt 7.327016 lr 0.00023929 rank 1
2022-12-08 15:45:12,953 DEBUG TRAIN Batch 33/3100 loss 8.795731 loss_att 314.467499 loss_ctc 22.238050 loss_rnnt 7.302139 lr 0.00023926 rank 0
2022-12-08 15:45:12,953 DEBUG TRAIN Batch 33/3100 loss 6.660792 loss_att 331.492065 loss_ctc 11.351963 loss_rnnt 6.139551 lr 0.00023927 rank 3
2022-12-08 15:45:12,955 DEBUG TRAIN Batch 33/3100 loss 4.281592 loss_att 405.312073 loss_ctc 9.708427 loss_rnnt 3.678611 lr 0.00023930 rank 5
2022-12-08 15:46:25,080 DEBUG TRAIN Batch 33/3200 loss 6.925603 loss_att 367.195496 loss_ctc 12.863830 loss_rnnt 6.265800 lr 0.00023924 rank 7
2022-12-08 15:46:25,088 DEBUG TRAIN Batch 33/3200 loss 10.052176 loss_att 97.759499 loss_ctc 15.732107 loss_rnnt 9.421073 lr 0.00023923 rank 0
2022-12-08 15:46:25,088 DEBUG TRAIN Batch 33/3200 loss 5.338250 loss_att 380.759583 loss_ctc 14.107471 loss_rnnt 4.363893 lr 0.00023927 rank 6
2022-12-08 15:46:25,092 DEBUG TRAIN Batch 33/3200 loss 6.366434 loss_att 399.413269 loss_ctc 17.850584 loss_rnnt 5.090417 lr 0.00023927 rank 5
2022-12-08 15:46:25,094 DEBUG TRAIN Batch 33/3200 loss 7.019209 loss_att 289.048248 loss_ctc 11.870544 loss_rnnt 6.480172 lr 0.00023925 rank 3
2022-12-08 15:46:25,096 DEBUG TRAIN Batch 33/3200 loss 3.156960 loss_att 381.082214 loss_ctc 8.717014 loss_rnnt 2.539176 lr 0.00023924 rank 4
2022-12-08 15:46:25,112 DEBUG TRAIN Batch 33/3200 loss 14.623976 loss_att 372.146820 loss_ctc 29.061872 loss_rnnt 13.019766 lr 0.00023926 rank 2
2022-12-08 15:46:25,167 DEBUG TRAIN Batch 33/3200 loss 7.752501 loss_att 75.913689 loss_ctc 11.308509 loss_rnnt 7.357390 lr 0.00023926 rank 1
2022-12-08 15:47:28,178 DEBUG TRAIN Batch 33/3300 loss 7.923225 loss_att 357.704285 loss_ctc 22.065212 loss_rnnt 6.351894 lr 0.00023923 rank 2
2022-12-08 15:47:28,184 DEBUG TRAIN Batch 33/3300 loss 8.956992 loss_att 372.920898 loss_ctc 14.624830 loss_rnnt 8.327232 lr 0.00023921 rank 4
2022-12-08 15:47:28,186 DEBUG TRAIN Batch 33/3300 loss 5.511642 loss_att 376.462006 loss_ctc 10.665204 loss_rnnt 4.939025 lr 0.00023922 rank 3
2022-12-08 15:47:28,190 DEBUG TRAIN Batch 33/3300 loss 8.379286 loss_att 408.232849 loss_ctc 16.292807 loss_rnnt 7.500005 lr 0.00023921 rank 7
2022-12-08 15:47:28,193 DEBUG TRAIN Batch 33/3300 loss 6.011207 loss_att 381.480408 loss_ctc 10.046391 loss_rnnt 5.562853 lr 0.00023925 rank 5
2022-12-08 15:47:28,196 DEBUG TRAIN Batch 33/3300 loss 3.151349 loss_att 375.775269 loss_ctc 7.980321 loss_rnnt 2.614796 lr 0.00023924 rank 1
2022-12-08 15:47:28,198 DEBUG TRAIN Batch 33/3300 loss 2.443013 loss_att 330.982178 loss_ctc 5.589340 loss_rnnt 2.093421 lr 0.00023920 rank 0
2022-12-08 15:47:28,231 DEBUG TRAIN Batch 33/3300 loss 8.660604 loss_att 378.326416 loss_ctc 16.978615 loss_rnnt 7.736381 lr 0.00023924 rank 6
2022-12-08 15:48:31,674 DEBUG TRAIN Batch 33/3400 loss 3.984776 loss_att 397.202972 loss_ctc 5.923980 loss_rnnt 3.769310 lr 0.00023919 rank 4
2022-12-08 15:48:31,678 DEBUG TRAIN Batch 33/3400 loss 7.406157 loss_att 409.332397 loss_ctc 16.306818 loss_rnnt 6.417194 lr 0.00023922 rank 6
2022-12-08 15:48:31,678 DEBUG TRAIN Batch 33/3400 loss 10.487265 loss_att 477.149414 loss_ctc 33.972950 loss_rnnt 7.877744 lr 0.00023918 rank 7
2022-12-08 15:48:31,679 DEBUG TRAIN Batch 33/3400 loss 6.274347 loss_att 431.873016 loss_ctc 15.185748 loss_rnnt 5.284192 lr 0.00023919 rank 3
2022-12-08 15:48:31,681 DEBUG TRAIN Batch 33/3400 loss 7.086492 loss_att 398.379272 loss_ctc 16.165524 loss_rnnt 6.077711 lr 0.00023920 rank 2
2022-12-08 15:48:31,682 DEBUG TRAIN Batch 33/3400 loss 6.261884 loss_att 393.648804 loss_ctc 13.675797 loss_rnnt 5.438116 lr 0.00023917 rank 0
2022-12-08 15:48:31,683 DEBUG TRAIN Batch 33/3400 loss 11.800253 loss_att 330.081848 loss_ctc 24.334396 loss_rnnt 10.407570 lr 0.00023922 rank 5
2022-12-08 15:48:31,684 DEBUG TRAIN Batch 33/3400 loss 7.139707 loss_att 393.298309 loss_ctc 13.349472 loss_rnnt 6.449734 lr 0.00023921 rank 1
2022-12-08 15:49:35,861 DEBUG TRAIN Batch 33/3500 loss 7.574227 loss_att 363.225220 loss_ctc 11.873487 loss_rnnt 7.096531 lr 0.00023916 rank 7
2022-12-08 15:49:35,869 DEBUG TRAIN Batch 33/3500 loss 2.555050 loss_att 345.656799 loss_ctc 3.926308 loss_rnnt 2.402688 lr 0.00023919 rank 5
2022-12-08 15:49:35,874 DEBUG TRAIN Batch 33/3500 loss 19.713491 loss_att 421.227783 loss_ctc 31.715355 loss_rnnt 18.379951 lr 0.00023916 rank 4
2022-12-08 15:49:35,877 DEBUG TRAIN Batch 33/3500 loss 5.126983 loss_att 339.492798 loss_ctc 11.292125 loss_rnnt 4.441967 lr 0.00023915 rank 0
2022-12-08 15:49:35,878 DEBUG TRAIN Batch 33/3500 loss 12.784477 loss_att 411.149872 loss_ctc 21.721802 loss_rnnt 11.791441 lr 0.00023919 rank 6
2022-12-08 15:49:35,879 DEBUG TRAIN Batch 33/3500 loss 3.583665 loss_att 392.485229 loss_ctc 7.425934 loss_rnnt 3.156746 lr 0.00023918 rank 2
2022-12-08 15:49:35,885 DEBUG TRAIN Batch 33/3500 loss 8.383873 loss_att 326.486115 loss_ctc 17.023760 loss_rnnt 7.423885 lr 0.00023916 rank 3
2022-12-08 15:49:35,919 DEBUG TRAIN Batch 33/3500 loss 4.381666 loss_att 350.534027 loss_ctc 11.123248 loss_rnnt 3.632601 lr 0.00023918 rank 1
2022-12-08 15:50:47,989 DEBUG TRAIN Batch 33/3600 loss 6.124072 loss_att 349.123016 loss_ctc 8.950699 loss_rnnt 5.810002 lr 0.00023913 rank 7
2022-12-08 15:50:47,990 DEBUG TRAIN Batch 33/3600 loss 6.534755 loss_att 336.862091 loss_ctc 19.221912 loss_rnnt 5.125071 lr 0.00023916 rank 6
2022-12-08 15:50:47,991 DEBUG TRAIN Batch 33/3600 loss 9.934197 loss_att 367.463837 loss_ctc 16.430712 loss_rnnt 9.212362 lr 0.00023915 rank 2
2022-12-08 15:50:47,991 DEBUG TRAIN Batch 33/3600 loss 8.306820 loss_att 375.068909 loss_ctc 16.178986 loss_rnnt 7.432135 lr 0.00023915 rank 1
2022-12-08 15:50:47,992 DEBUG TRAIN Batch 33/3600 loss 3.709092 loss_att 334.567902 loss_ctc 8.684868 loss_rnnt 3.156228 lr 0.00023913 rank 4
2022-12-08 15:50:47,994 DEBUG TRAIN Batch 33/3600 loss 7.257481 loss_att 393.125519 loss_ctc 13.847832 loss_rnnt 6.525219 lr 0.00023914 rank 3
2022-12-08 15:50:47,995 DEBUG TRAIN Batch 33/3600 loss 6.931768 loss_att 386.538696 loss_ctc 21.613081 loss_rnnt 5.300511 lr 0.00023912 rank 0
2022-12-08 15:50:48,041 DEBUG TRAIN Batch 33/3600 loss 6.112981 loss_att 254.321655 loss_ctc 13.626976 loss_rnnt 5.278093 lr 0.00023917 rank 5
2022-12-08 15:51:51,336 DEBUG TRAIN Batch 33/3700 loss 4.797919 loss_att 399.504150 loss_ctc 12.196361 loss_rnnt 3.975870 lr 0.00023914 rank 5
2022-12-08 15:51:51,350 DEBUG TRAIN Batch 33/3700 loss 9.411122 loss_att 340.962738 loss_ctc 15.941867 loss_rnnt 8.685484 lr 0.00023912 rank 2
2022-12-08 15:51:51,350 DEBUG TRAIN Batch 33/3700 loss 5.363498 loss_att 303.660645 loss_ctc 11.357399 loss_rnnt 4.697509 lr 0.00023913 rank 1
2022-12-08 15:51:51,351 DEBUG TRAIN Batch 33/3700 loss 4.708364 loss_att 242.259750 loss_ctc 8.356133 loss_rnnt 4.303056 lr 0.00023910 rank 4
2022-12-08 15:51:51,352 DEBUG TRAIN Batch 33/3700 loss 11.556351 loss_att 376.742584 loss_ctc 23.813446 loss_rnnt 10.194451 lr 0.00023910 rank 7
2022-12-08 15:51:51,352 DEBUG TRAIN Batch 33/3700 loss 8.467710 loss_att 363.076141 loss_ctc 17.379896 loss_rnnt 7.477468 lr 0.00023909 rank 0
2022-12-08 15:51:51,353 DEBUG TRAIN Batch 33/3700 loss 7.791811 loss_att 356.895142 loss_ctc 13.763576 loss_rnnt 7.128281 lr 0.00023911 rank 3
2022-12-08 15:51:51,393 DEBUG TRAIN Batch 33/3700 loss 6.942518 loss_att 380.083069 loss_ctc 10.418621 loss_rnnt 6.556285 lr 0.00023913 rank 6
2022-12-08 15:52:54,752 DEBUG TRAIN Batch 33/3800 loss 10.295979 loss_att 190.001190 loss_ctc 16.338581 loss_rnnt 9.624580 lr 0.00023907 rank 7
2022-12-08 15:52:54,759 DEBUG TRAIN Batch 33/3800 loss 12.448867 loss_att 321.900116 loss_ctc 21.695967 loss_rnnt 11.421412 lr 0.00023907 rank 0
2022-12-08 15:52:54,760 DEBUG TRAIN Batch 33/3800 loss 8.537070 loss_att 430.102753 loss_ctc 18.977312 loss_rnnt 7.377044 lr 0.00023908 rank 4
2022-12-08 15:52:54,760 DEBUG TRAIN Batch 33/3800 loss 5.218481 loss_att 292.263153 loss_ctc 9.213962 loss_rnnt 4.774539 lr 0.00023908 rank 3
2022-12-08 15:52:54,760 DEBUG TRAIN Batch 33/3800 loss 7.156300 loss_att 138.702362 loss_ctc 12.747643 loss_rnnt 6.535039 lr 0.00023910 rank 1
2022-12-08 15:52:54,762 DEBUG TRAIN Batch 33/3800 loss 12.842214 loss_att 141.698624 loss_ctc 20.167547 loss_rnnt 12.028288 lr 0.00023909 rank 2
2022-12-08 15:52:54,766 DEBUG TRAIN Batch 33/3800 loss 9.573939 loss_att 143.573334 loss_ctc 15.293876 loss_rnnt 8.938392 lr 0.00023911 rank 6
2022-12-08 15:52:54,807 DEBUG TRAIN Batch 33/3800 loss 12.498961 loss_att 351.102783 loss_ctc 19.865944 loss_rnnt 11.680408 lr 0.00023911 rank 5
2022-12-08 15:54:00,207 DEBUG TRAIN Batch 33/3900 loss 4.302692 loss_att 466.753662 loss_ctc 12.370888 loss_rnnt 3.406226 lr 0.00023905 rank 3
2022-12-08 15:54:00,212 DEBUG TRAIN Batch 33/3900 loss 4.920689 loss_att 383.691162 loss_ctc 11.448543 loss_rnnt 4.195372 lr 0.00023908 rank 6
2022-12-08 15:54:00,217 DEBUG TRAIN Batch 33/3900 loss 9.657361 loss_att 393.817139 loss_ctc 23.685339 loss_rnnt 8.098697 lr 0.00023905 rank 4
2022-12-08 15:54:00,223 DEBUG TRAIN Batch 33/3900 loss 8.338236 loss_att 452.207733 loss_ctc 22.116751 loss_rnnt 6.807290 lr 0.00023904 rank 0
2022-12-08 15:54:00,225 DEBUG TRAIN Batch 33/3900 loss 4.884907 loss_att 350.930847 loss_ctc 11.281677 loss_rnnt 4.174155 lr 0.00023907 rank 1
2022-12-08 15:54:00,235 DEBUG TRAIN Batch 33/3900 loss 3.526021 loss_att 401.912201 loss_ctc 11.835120 loss_rnnt 2.602787 lr 0.00023905 rank 7
2022-12-08 15:54:00,238 DEBUG TRAIN Batch 33/3900 loss 4.962159 loss_att 342.383881 loss_ctc 6.991447 loss_rnnt 4.736682 lr 0.00023907 rank 2
2022-12-08 15:54:00,255 DEBUG TRAIN Batch 33/3900 loss 11.173563 loss_att 369.468567 loss_ctc 20.808289 loss_rnnt 10.103039 lr 0.00023908 rank 5
2022-12-08 15:55:10,125 DEBUG TRAIN Batch 33/4000 loss 5.552693 loss_att 404.631592 loss_ctc 11.028641 loss_rnnt 4.944254 lr 0.00023902 rank 7
2022-12-08 15:55:10,133 DEBUG TRAIN Batch 33/4000 loss 5.532735 loss_att 400.310547 loss_ctc 7.121072 loss_rnnt 5.356254 lr 0.00023902 rank 4
2022-12-08 15:55:10,134 DEBUG TRAIN Batch 33/4000 loss 9.634897 loss_att 439.043152 loss_ctc 19.365536 loss_rnnt 8.553716 lr 0.00023903 rank 3
2022-12-08 15:55:10,134 DEBUG TRAIN Batch 33/4000 loss 5.660501 loss_att 377.121552 loss_ctc 11.854334 loss_rnnt 4.972298 lr 0.00023904 rank 2
2022-12-08 15:55:10,135 DEBUG TRAIN Batch 33/4000 loss 9.662594 loss_att 420.271240 loss_ctc 19.801105 loss_rnnt 8.536093 lr 0.00023901 rank 0
2022-12-08 15:55:10,135 DEBUG TRAIN Batch 33/4000 loss 6.551205 loss_att 413.645752 loss_ctc 14.518486 loss_rnnt 5.665952 lr 0.00023905 rank 6
2022-12-08 15:55:10,139 DEBUG TRAIN Batch 33/4000 loss 11.040316 loss_att 331.445984 loss_ctc 22.761421 loss_rnnt 9.737971 lr 0.00023906 rank 5
2022-12-08 15:55:10,176 DEBUG TRAIN Batch 33/4000 loss 11.724771 loss_att 403.295013 loss_ctc 26.200073 loss_rnnt 10.116404 lr 0.00023905 rank 1
2022-12-08 15:56:13,817 DEBUG TRAIN Batch 33/4100 loss 8.679695 loss_att 395.392639 loss_ctc 12.085752 loss_rnnt 8.301245 lr 0.00023899 rank 7
2022-12-08 15:56:13,821 DEBUG TRAIN Batch 33/4100 loss 11.373569 loss_att 347.036713 loss_ctc 19.025711 loss_rnnt 10.523332 lr 0.00023902 rank 1
2022-12-08 15:56:13,822 DEBUG TRAIN Batch 33/4100 loss 2.208201 loss_att 377.015961 loss_ctc 5.633173 loss_rnnt 1.827649 lr 0.00023901 rank 2
2022-12-08 15:56:13,823 DEBUG TRAIN Batch 33/4100 loss 8.649875 loss_att 358.773926 loss_ctc 20.401423 loss_rnnt 7.344147 lr 0.00023903 rank 5
2022-12-08 15:56:13,823 DEBUG TRAIN Batch 33/4100 loss 15.782914 loss_att 442.077148 loss_ctc 41.334045 loss_rnnt 12.943900 lr 0.00023898 rank 0
2022-12-08 15:56:13,824 DEBUG TRAIN Batch 33/4100 loss 16.205055 loss_att 434.626343 loss_ctc 25.419121 loss_rnnt 15.181272 lr 0.00023899 rank 4
2022-12-08 15:56:13,827 DEBUG TRAIN Batch 33/4100 loss 14.490769 loss_att 472.515625 loss_ctc 29.575949 loss_rnnt 12.814639 lr 0.00023902 rank 6
2022-12-08 15:56:13,867 DEBUG TRAIN Batch 33/4100 loss 0.532288 loss_att 310.898804 loss_ctc 1.859511 loss_rnnt 0.384819 lr 0.00023900 rank 3
2022-12-08 15:57:17,608 DEBUG TRAIN Batch 33/4200 loss 4.472873 loss_att 360.692932 loss_ctc 13.850389 loss_rnnt 3.430926 lr 0.00023897 rank 3
2022-12-08 15:57:17,617 DEBUG TRAIN Batch 33/4200 loss 3.382626 loss_att 381.410004 loss_ctc 10.629980 loss_rnnt 2.577364 lr 0.00023896 rank 7
2022-12-08 15:57:17,617 DEBUG TRAIN Batch 33/4200 loss 8.595502 loss_att 349.051392 loss_ctc 17.966232 loss_rnnt 7.554310 lr 0.00023897 rank 4
2022-12-08 15:57:17,617 DEBUG TRAIN Batch 33/4200 loss 15.150972 loss_att 397.045746 loss_ctc 29.131149 loss_rnnt 13.597620 lr 0.00023899 rank 1
2022-12-08 15:57:17,622 DEBUG TRAIN Batch 33/4200 loss 5.381123 loss_att 372.392548 loss_ctc 15.765537 loss_rnnt 4.227299 lr 0.00023896 rank 0
2022-12-08 15:57:17,622 DEBUG TRAIN Batch 33/4200 loss 5.868383 loss_att 299.772064 loss_ctc 8.374557 loss_rnnt 5.589920 lr 0.00023900 rank 5
2022-12-08 15:57:17,637 DEBUG TRAIN Batch 33/4200 loss 5.369679 loss_att 320.981873 loss_ctc 11.939909 loss_rnnt 4.639654 lr 0.00023898 rank 2
2022-12-08 15:57:17,664 DEBUG TRAIN Batch 33/4200 loss 7.766276 loss_att 404.336914 loss_ctc 18.026278 loss_rnnt 6.626276 lr 0.00023900 rank 6
2022-12-08 15:58:28,302 DEBUG TRAIN Batch 33/4300 loss 11.394204 loss_att 358.994751 loss_ctc 26.780354 loss_rnnt 9.684631 lr 0.00023894 rank 4
2022-12-08 15:58:28,305 DEBUG TRAIN Batch 33/4300 loss 7.258746 loss_att 407.578430 loss_ctc 18.708706 loss_rnnt 5.986528 lr 0.00023894 rank 7
2022-12-08 15:58:28,305 DEBUG TRAIN Batch 33/4300 loss 6.211090 loss_att 372.335480 loss_ctc 15.927849 loss_rnnt 5.131450 lr 0.00023896 rank 2
2022-12-08 15:58:28,306 DEBUG TRAIN Batch 33/4300 loss 11.537671 loss_att 338.916626 loss_ctc 22.771664 loss_rnnt 10.289450 lr 0.00023897 rank 6
2022-12-08 15:58:28,306 DEBUG TRAIN Batch 33/4300 loss 13.481632 loss_att 344.541504 loss_ctc 24.474453 loss_rnnt 12.260207 lr 0.00023895 rank 3
2022-12-08 15:58:28,307 DEBUG TRAIN Batch 33/4300 loss 11.281590 loss_att 129.601807 loss_ctc 17.798168 loss_rnnt 10.557526 lr 0.00023897 rank 5
2022-12-08 15:58:28,310 DEBUG TRAIN Batch 33/4300 loss 10.202963 loss_att 353.411865 loss_ctc 26.646061 loss_rnnt 8.375952 lr 0.00023896 rank 1
2022-12-08 15:58:28,317 DEBUG TRAIN Batch 33/4300 loss 3.795487 loss_att 332.137878 loss_ctc 7.069734 loss_rnnt 3.431682 lr 0.00023893 rank 0
2022-12-08 15:59:31,418 DEBUG TRAIN Batch 33/4400 loss 1.791704 loss_att 306.151428 loss_ctc 5.811679 loss_rnnt 1.345040 lr 0.00023892 rank 3
2022-12-08 15:59:31,422 DEBUG TRAIN Batch 33/4400 loss 5.733244 loss_att 291.994385 loss_ctc 9.326552 loss_rnnt 5.333988 lr 0.00023891 rank 7
2022-12-08 15:59:31,424 DEBUG TRAIN Batch 33/4400 loss 5.738213 loss_att 336.261230 loss_ctc 16.015596 loss_rnnt 4.596282 lr 0.00023890 rank 0
2022-12-08 15:59:31,424 DEBUG TRAIN Batch 33/4400 loss 7.173680 loss_att 158.042923 loss_ctc 13.834937 loss_rnnt 6.433540 lr 0.00023891 rank 4
2022-12-08 15:59:31,425 DEBUG TRAIN Batch 33/4400 loss 9.997369 loss_att 296.948914 loss_ctc 22.500860 loss_rnnt 8.608092 lr 0.00023894 rank 6
2022-12-08 15:59:31,427 DEBUG TRAIN Batch 33/4400 loss 5.772238 loss_att 357.297363 loss_ctc 7.357540 loss_rnnt 5.596094 lr 0.00023895 rank 5
2022-12-08 15:59:31,430 DEBUG TRAIN Batch 33/4400 loss 13.218105 loss_att 350.500549 loss_ctc 26.897970 loss_rnnt 11.698120 lr 0.00023894 rank 1
2022-12-08 15:59:31,463 DEBUG TRAIN Batch 33/4400 loss 8.205218 loss_att 246.575165 loss_ctc 15.535265 loss_rnnt 7.390769 lr 0.00023893 rank 2
2022-12-08 16:00:34,424 DEBUG TRAIN Batch 33/4500 loss 5.762796 loss_att 443.292694 loss_ctc 11.771789 loss_rnnt 5.095131 lr 0.00023889 rank 4
2022-12-08 16:00:34,427 DEBUG TRAIN Batch 33/4500 loss 5.139489 loss_att 396.328613 loss_ctc 11.533312 loss_rnnt 4.429064 lr 0.00023891 rank 6
2022-12-08 16:00:34,433 DEBUG TRAIN Batch 33/4500 loss 14.206613 loss_att 467.826782 loss_ctc 21.826717 loss_rnnt 13.359935 lr 0.00023891 rank 1
2022-12-08 16:00:34,434 DEBUG TRAIN Batch 33/4500 loss 5.224095 loss_att 427.691254 loss_ctc 19.123190 loss_rnnt 3.679751 lr 0.00023888 rank 7
2022-12-08 16:00:34,435 DEBUG TRAIN Batch 33/4500 loss 4.175693 loss_att 91.812798 loss_ctc 8.170889 loss_rnnt 3.731782 lr 0.00023887 rank 0
2022-12-08 16:00:34,438 DEBUG TRAIN Batch 33/4500 loss 9.054557 loss_att 146.476929 loss_ctc 15.411334 loss_rnnt 8.348248 lr 0.00023889 rank 3
2022-12-08 16:00:34,438 DEBUG TRAIN Batch 33/4500 loss 8.239689 loss_att 419.259277 loss_ctc 16.394672 loss_rnnt 7.333579 lr 0.00023892 rank 5
2022-12-08 16:00:34,441 DEBUG TRAIN Batch 33/4500 loss 4.057477 loss_att 410.932220 loss_ctc 12.850029 loss_rnnt 3.080526 lr 0.00023890 rank 2
2022-12-08 16:01:39,311 DEBUG TRAIN Batch 33/4600 loss 8.392683 loss_att 415.026794 loss_ctc 18.246531 loss_rnnt 7.297812 lr 0.00023886 rank 4
2022-12-08 16:01:39,312 DEBUG TRAIN Batch 33/4600 loss 11.604200 loss_att 407.178894 loss_ctc 23.898657 loss_rnnt 10.238150 lr 0.00023887 rank 2
2022-12-08 16:01:39,312 DEBUG TRAIN Batch 33/4600 loss 7.743104 loss_att 323.042755 loss_ctc 9.766047 loss_rnnt 7.518332 lr 0.00023888 rank 1
2022-12-08 16:01:39,313 DEBUG TRAIN Batch 33/4600 loss 6.496273 loss_att 399.949524 loss_ctc 14.769576 loss_rnnt 5.577016 lr 0.00023886 rank 7
2022-12-08 16:01:39,315 DEBUG TRAIN Batch 33/4600 loss 2.252585 loss_att 375.371277 loss_ctc 5.981140 loss_rnnt 1.838301 lr 0.00023885 rank 0
2022-12-08 16:01:39,318 DEBUG TRAIN Batch 33/4600 loss 13.633022 loss_att 376.439575 loss_ctc 29.587196 loss_rnnt 11.860336 lr 0.00023889 rank 5
2022-12-08 16:01:39,344 DEBUG TRAIN Batch 33/4600 loss 14.979338 loss_att 442.521576 loss_ctc 29.278633 loss_rnnt 13.390528 lr 0.00023889 rank 6
2022-12-08 16:01:39,353 DEBUG TRAIN Batch 33/4600 loss 5.090637 loss_att 422.981415 loss_ctc 10.570272 loss_rnnt 4.481789 lr 0.00023886 rank 3
2022-12-08 16:02:49,603 DEBUG TRAIN Batch 33/4700 loss 26.186863 loss_att 428.330261 loss_ctc 38.091618 loss_rnnt 24.864113 lr 0.00023883 rank 7
2022-12-08 16:02:49,604 DEBUG TRAIN Batch 33/4700 loss 6.381053 loss_att 385.284790 loss_ctc 18.059675 loss_rnnt 5.083428 lr 0.00023883 rank 4
2022-12-08 16:02:49,607 DEBUG TRAIN Batch 33/4700 loss 11.451921 loss_att 401.803802 loss_ctc 20.590279 loss_rnnt 10.436549 lr 0.00023884 rank 3
2022-12-08 16:02:49,608 DEBUG TRAIN Batch 33/4700 loss 7.683092 loss_att 391.219513 loss_ctc 15.176918 loss_rnnt 6.850445 lr 0.00023885 rank 1
2022-12-08 16:02:49,612 DEBUG TRAIN Batch 33/4700 loss 15.679249 loss_att 410.341034 loss_ctc 28.211246 loss_rnnt 14.286804 lr 0.00023885 rank 2
2022-12-08 16:02:49,613 DEBUG TRAIN Batch 33/4700 loss 3.386616 loss_att 396.831970 loss_ctc 7.685403 loss_rnnt 2.908973 lr 0.00023882 rank 0
2022-12-08 16:02:49,636 DEBUG TRAIN Batch 33/4700 loss 3.255644 loss_att 393.854065 loss_ctc 7.934293 loss_rnnt 2.735794 lr 0.00023886 rank 6
2022-12-08 16:02:49,673 DEBUG TRAIN Batch 33/4700 loss 8.121023 loss_att 370.931152 loss_ctc 20.975243 loss_rnnt 6.692776 lr 0.00023886 rank 5
2022-12-08 16:03:52,375 DEBUG TRAIN Batch 33/4800 loss 7.870331 loss_att 391.099915 loss_ctc 15.197224 loss_rnnt 7.056232 lr 0.00023881 rank 3
2022-12-08 16:03:52,375 DEBUG TRAIN Batch 33/4800 loss 5.423281 loss_att 334.384399 loss_ctc 12.767124 loss_rnnt 4.607298 lr 0.00023882 rank 2
2022-12-08 16:03:52,377 DEBUG TRAIN Batch 33/4800 loss 5.100961 loss_att 390.273407 loss_ctc 7.570427 loss_rnnt 4.826575 lr 0.00023883 rank 6
2022-12-08 16:03:52,379 DEBUG TRAIN Batch 33/4800 loss 8.453635 loss_att 321.727234 loss_ctc 12.663787 loss_rnnt 7.985840 lr 0.00023880 rank 4
2022-12-08 16:03:52,380 DEBUG TRAIN Batch 33/4800 loss 6.271545 loss_att 377.037598 loss_ctc 12.376950 loss_rnnt 5.593167 lr 0.00023880 rank 7
2022-12-08 16:03:52,380 DEBUG TRAIN Batch 33/4800 loss 7.776358 loss_att 263.669006 loss_ctc 13.426048 loss_rnnt 7.148614 lr 0.00023879 rank 0
2022-12-08 16:03:52,383 DEBUG TRAIN Batch 33/4800 loss 8.804336 loss_att 350.050476 loss_ctc 17.974106 loss_rnnt 7.785472 lr 0.00023884 rank 5
2022-12-08 16:03:52,383 DEBUG TRAIN Batch 33/4800 loss 6.228597 loss_att 355.077698 loss_ctc 13.378123 loss_rnnt 5.434206 lr 0.00023883 rank 1
2022-12-08 16:04:56,419 DEBUG TRAIN Batch 33/4900 loss 5.455330 loss_att 408.728821 loss_ctc 12.718317 loss_rnnt 4.648332 lr 0.00023881 rank 6
2022-12-08 16:04:56,421 DEBUG TRAIN Batch 33/4900 loss 10.373971 loss_att 340.427551 loss_ctc 18.212755 loss_rnnt 9.502995 lr 0.00023878 rank 4
2022-12-08 16:04:56,423 DEBUG TRAIN Batch 33/4900 loss 9.511006 loss_att 392.722290 loss_ctc 17.989105 loss_rnnt 8.568995 lr 0.00023880 rank 1
2022-12-08 16:04:56,424 DEBUG TRAIN Batch 33/4900 loss 12.090324 loss_att 392.885345 loss_ctc 24.765852 loss_rnnt 10.681932 lr 0.00023877 rank 7
2022-12-08 16:04:56,426 DEBUG TRAIN Batch 33/4900 loss 8.112121 loss_att 332.995392 loss_ctc 13.334215 loss_rnnt 7.531888 lr 0.00023879 rank 2
2022-12-08 16:04:56,427 DEBUG TRAIN Batch 33/4900 loss 11.043453 loss_att 378.963501 loss_ctc 17.244431 loss_rnnt 10.354456 lr 0.00023878 rank 3
2022-12-08 16:04:56,431 DEBUG TRAIN Batch 33/4900 loss 10.087505 loss_att 352.090729 loss_ctc 21.400908 loss_rnnt 8.830461 lr 0.00023877 rank 0
2022-12-08 16:04:56,433 DEBUG TRAIN Batch 33/4900 loss 3.518326 loss_att 266.461731 loss_ctc 6.939847 loss_rnnt 3.138157 lr 0.00023881 rank 5
2022-12-08 16:06:08,566 DEBUG TRAIN Batch 33/5000 loss 6.616726 loss_att 289.044617 loss_ctc 10.333280 loss_rnnt 6.203775 lr 0.00023874 rank 0
2022-12-08 16:06:08,568 DEBUG TRAIN Batch 33/5000 loss 6.433035 loss_att 306.501312 loss_ctc 12.105373 loss_rnnt 5.802775 lr 0.00023877 rank 1
2022-12-08 16:06:08,568 DEBUG TRAIN Batch 33/5000 loss 7.186547 loss_att 302.667084 loss_ctc 14.860870 loss_rnnt 6.333845 lr 0.00023875 rank 7
2022-12-08 16:06:08,569 DEBUG TRAIN Batch 33/5000 loss 6.098207 loss_att 297.886932 loss_ctc 10.151232 loss_rnnt 5.647871 lr 0.00023878 rank 6
2022-12-08 16:06:08,570 DEBUG TRAIN Batch 33/5000 loss 8.991826 loss_att 277.331512 loss_ctc 16.558813 loss_rnnt 8.151051 lr 0.00023875 rank 4
2022-12-08 16:06:08,570 DEBUG TRAIN Batch 33/5000 loss 5.899140 loss_att 312.701569 loss_ctc 14.272320 loss_rnnt 4.968788 lr 0.00023875 rank 3
2022-12-08 16:06:08,574 DEBUG TRAIN Batch 33/5000 loss 7.990662 loss_att 405.342957 loss_ctc 14.939198 loss_rnnt 7.218603 lr 0.00023878 rank 5
2022-12-08 16:06:08,614 DEBUG TRAIN Batch 33/5000 loss 5.888520 loss_att 354.827728 loss_ctc 12.550055 loss_rnnt 5.148349 lr 0.00023877 rank 2
2022-12-08 16:07:12,399 DEBUG TRAIN Batch 33/5100 loss 10.601073 loss_att 196.504242 loss_ctc 16.198191 loss_rnnt 9.979172 lr 0.00023874 rank 2
2022-12-08 16:07:12,402 DEBUG TRAIN Batch 33/5100 loss 6.538404 loss_att 463.400146 loss_ctc 20.834114 loss_rnnt 4.949992 lr 0.00023875 rank 6
2022-12-08 16:07:12,404 DEBUG TRAIN Batch 33/5100 loss 12.697294 loss_att 199.009583 loss_ctc 23.328548 loss_rnnt 11.516044 lr 0.00023875 rank 1
2022-12-08 16:07:12,404 DEBUG TRAIN Batch 33/5100 loss 8.238521 loss_att 102.306786 loss_ctc 11.938762 loss_rnnt 7.827383 lr 0.00023873 rank 3
2022-12-08 16:07:12,405 DEBUG TRAIN Batch 33/5100 loss 8.984257 loss_att 277.948242 loss_ctc 18.266405 loss_rnnt 7.952908 lr 0.00023871 rank 0
2022-12-08 16:07:12,405 DEBUG TRAIN Batch 33/5100 loss 5.756265 loss_att 466.788330 loss_ctc 14.600676 loss_rnnt 4.773552 lr 0.00023876 rank 5
2022-12-08 16:07:12,406 DEBUG TRAIN Batch 33/5100 loss 4.121187 loss_att 352.156342 loss_ctc 7.504275 loss_rnnt 3.745288 lr 0.00023872 rank 4
2022-12-08 16:07:12,406 DEBUG TRAIN Batch 33/5100 loss 1.678495 loss_att 394.832092 loss_ctc 2.671601 loss_rnnt 1.568150 lr 0.00023872 rank 7
2022-12-08 16:08:15,543 DEBUG TRAIN Batch 33/5200 loss 6.769886 loss_att 340.609558 loss_ctc 13.986034 loss_rnnt 5.968092 lr 0.00023869 rank 4
2022-12-08 16:08:15,552 DEBUG TRAIN Batch 33/5200 loss 8.905893 loss_att 420.153809 loss_ctc 24.787169 loss_rnnt 7.141308 lr 0.00023869 rank 7
2022-12-08 16:08:15,558 DEBUG TRAIN Batch 33/5200 loss 1.994984 loss_att 358.559082 loss_ctc 7.983926 loss_rnnt 1.329546 lr 0.00023872 rank 6
2022-12-08 16:08:15,560 DEBUG TRAIN Batch 33/5200 loss 9.333778 loss_att 384.888885 loss_ctc 17.586380 loss_rnnt 8.416822 lr 0.00023868 rank 0
2022-12-08 16:08:15,562 DEBUG TRAIN Batch 33/5200 loss 7.319409 loss_att 338.764343 loss_ctc 20.177269 loss_rnnt 5.890759 lr 0.00023871 rank 2
2022-12-08 16:08:15,563 DEBUG TRAIN Batch 33/5200 loss 10.715008 loss_att 443.584778 loss_ctc 26.601192 loss_rnnt 8.949877 lr 0.00023873 rank 5
2022-12-08 16:08:15,563 DEBUG TRAIN Batch 33/5200 loss 10.201137 loss_att 407.497498 loss_ctc 20.929581 loss_rnnt 9.009087 lr 0.00023870 rank 3
2022-12-08 16:08:15,565 DEBUG TRAIN Batch 33/5200 loss 0.640833 loss_att 391.266205 loss_ctc 2.015254 loss_rnnt 0.488120 lr 0.00023872 rank 1
2022-12-08 16:09:20,139 DEBUG TRAIN Batch 33/5300 loss 5.501852 loss_att 371.428711 loss_ctc 15.382673 loss_rnnt 4.403983 lr 0.00023867 rank 4
2022-12-08 16:09:20,148 DEBUG TRAIN Batch 33/5300 loss 9.919279 loss_att 393.906250 loss_ctc 12.972420 loss_rnnt 9.580041 lr 0.00023870 rank 6
2022-12-08 16:09:20,151 DEBUG TRAIN Batch 33/5300 loss 1.804985 loss_att 381.318939 loss_ctc 4.528403 loss_rnnt 1.502383 lr 0.00023866 rank 7
2022-12-08 16:09:20,153 DEBUG TRAIN Batch 33/5300 loss 4.113985 loss_att 366.786224 loss_ctc 12.151756 loss_rnnt 3.220899 lr 0.00023869 rank 1
2022-12-08 16:09:20,152 DEBUG TRAIN Batch 33/5300 loss 2.127759 loss_att 351.336060 loss_ctc 4.124507 loss_rnnt 1.905898 lr 0.00023868 rank 2
2022-12-08 16:09:20,154 DEBUG TRAIN Batch 33/5300 loss 8.745557 loss_att 413.961456 loss_ctc 16.264675 loss_rnnt 7.910100 lr 0.00023870 rank 5
2022-12-08 16:09:20,157 DEBUG TRAIN Batch 33/5300 loss 7.589568 loss_att 457.268158 loss_ctc 15.132360 loss_rnnt 6.751480 lr 0.00023866 rank 0
2022-12-08 16:09:20,184 DEBUG TRAIN Batch 33/5300 loss 1.394747 loss_att 415.783936 loss_ctc 3.999899 loss_rnnt 1.105286 lr 0.00023867 rank 3
2022-12-08 16:10:31,387 DEBUG TRAIN Batch 33/5400 loss 7.106723 loss_att 366.422577 loss_ctc 19.406208 loss_rnnt 5.740113 lr 0.00023864 rank 4
2022-12-08 16:10:31,389 DEBUG TRAIN Batch 33/5400 loss 3.821527 loss_att 385.559509 loss_ctc 10.240340 loss_rnnt 3.108325 lr 0.00023865 rank 3
2022-12-08 16:10:31,391 DEBUG TRAIN Batch 33/5400 loss 5.236042 loss_att 401.837921 loss_ctc 10.447729 loss_rnnt 4.656966 lr 0.00023864 rank 7
2022-12-08 16:10:31,392 DEBUG TRAIN Batch 33/5400 loss 6.403707 loss_att 387.615326 loss_ctc 11.472860 loss_rnnt 5.840468 lr 0.00023867 rank 5
2022-12-08 16:10:31,392 DEBUG TRAIN Batch 33/5400 loss 3.783005 loss_att 299.651917 loss_ctc 5.782504 loss_rnnt 3.560838 lr 0.00023866 rank 2
2022-12-08 16:10:31,393 DEBUG TRAIN Batch 33/5400 loss 11.154219 loss_att 359.641083 loss_ctc 27.499966 loss_rnnt 9.338024 lr 0.00023863 rank 0
2022-12-08 16:10:31,394 DEBUG TRAIN Batch 33/5400 loss 7.176106 loss_att 320.716644 loss_ctc 15.401136 loss_rnnt 6.262215 lr 0.00023867 rank 6
2022-12-08 16:10:31,395 DEBUG TRAIN Batch 33/5400 loss 7.022456 loss_att 363.588776 loss_ctc 8.750274 loss_rnnt 6.830476 lr 0.00023866 rank 1
2022-12-08 16:11:34,500 DEBUG TRAIN Batch 33/5500 loss 5.941551 loss_att 382.153778 loss_ctc 11.813051 loss_rnnt 5.289162 lr 0.00023861 rank 7
2022-12-08 16:11:34,507 DEBUG TRAIN Batch 33/5500 loss 5.975831 loss_att 377.119385 loss_ctc 11.428046 loss_rnnt 5.370029 lr 0.00023864 rank 1
2022-12-08 16:11:34,511 DEBUG TRAIN Batch 33/5500 loss 9.429681 loss_att 408.142426 loss_ctc 14.996882 loss_rnnt 8.811103 lr 0.00023863 rank 2
2022-12-08 16:11:34,512 DEBUG TRAIN Batch 33/5500 loss 4.754442 loss_att 355.538757 loss_ctc 10.111700 loss_rnnt 4.159191 lr 0.00023860 rank 0
2022-12-08 16:11:34,514 DEBUG TRAIN Batch 33/5500 loss 7.146977 loss_att 269.193787 loss_ctc 12.577147 loss_rnnt 6.543625 lr 0.00023865 rank 5
2022-12-08 16:11:34,515 DEBUG TRAIN Batch 33/5500 loss 7.159891 loss_att 364.510345 loss_ctc 14.010319 loss_rnnt 6.398733 lr 0.00023861 rank 4
2022-12-08 16:11:34,516 DEBUG TRAIN Batch 33/5500 loss 3.585267 loss_att 342.373718 loss_ctc 8.353541 loss_rnnt 3.055459 lr 0.00023864 rank 6
2022-12-08 16:11:34,547 DEBUG TRAIN Batch 33/5500 loss 5.974859 loss_att 383.018402 loss_ctc 10.800936 loss_rnnt 5.438628 lr 0.00023862 rank 3
2022-12-08 16:12:38,615 DEBUG TRAIN Batch 33/5600 loss 2.914853 loss_att 305.551178 loss_ctc 6.793436 loss_rnnt 2.483899 lr 0.00023858 rank 7
2022-12-08 16:12:38,618 DEBUG TRAIN Batch 33/5600 loss 9.182886 loss_att 268.371918 loss_ctc 17.068670 loss_rnnt 8.306688 lr 0.00023861 rank 6
2022-12-08 16:12:38,620 DEBUG TRAIN Batch 33/5600 loss 5.002188 loss_att 312.275360 loss_ctc 13.657387 loss_rnnt 4.040499 lr 0.00023859 rank 4
2022-12-08 16:12:38,620 DEBUG TRAIN Batch 33/5600 loss 8.268188 loss_att 341.521149 loss_ctc 17.970463 loss_rnnt 7.190157 lr 0.00023857 rank 0
2022-12-08 16:12:38,623 DEBUG TRAIN Batch 33/5600 loss 5.722525 loss_att 327.619507 loss_ctc 13.541026 loss_rnnt 4.853803 lr 0.00023859 rank 3
2022-12-08 16:12:38,624 DEBUG TRAIN Batch 33/5600 loss 6.480507 loss_att 68.054428 loss_ctc 10.494172 loss_rnnt 6.034544 lr 0.00023862 rank 5
2022-12-08 16:12:38,625 DEBUG TRAIN Batch 33/5600 loss 4.370495 loss_att 365.534790 loss_ctc 7.768508 loss_rnnt 3.992938 lr 0.00023860 rank 2
2022-12-08 16:12:38,646 DEBUG TRAIN Batch 33/5600 loss 8.863766 loss_att 370.554321 loss_ctc 15.502111 loss_rnnt 8.126172 lr 0.00023861 rank 1
2022-12-08 16:13:52,878 DEBUG TRAIN Batch 33/5700 loss 1.963846 loss_att 435.099670 loss_ctc 9.382071 loss_rnnt 1.139599 lr 0.00023856 rank 4
2022-12-08 16:13:52,880 DEBUG TRAIN Batch 33/5700 loss 5.057836 loss_att 87.961487 loss_ctc 10.054316 loss_rnnt 4.502672 lr 0.00023856 rank 7
2022-12-08 16:13:52,883 DEBUG TRAIN Batch 33/5700 loss 7.601586 loss_att 119.896301 loss_ctc 12.813653 loss_rnnt 7.022468 lr 0.00023859 rank 6
2022-12-08 16:13:52,883 DEBUG TRAIN Batch 33/5700 loss 4.885938 loss_att 330.466736 loss_ctc 9.256630 loss_rnnt 4.400306 lr 0.00023855 rank 0
2022-12-08 16:13:52,886 DEBUG TRAIN Batch 33/5700 loss 2.932644 loss_att 207.067673 loss_ctc 7.890676 loss_rnnt 2.381752 lr 0.00023858 rank 1
2022-12-08 16:13:52,889 DEBUG TRAIN Batch 33/5700 loss 9.890411 loss_att 301.780731 loss_ctc 15.436549 loss_rnnt 9.274175 lr 0.00023858 rank 2
2022-12-08 16:13:52,890 DEBUG TRAIN Batch 33/5700 loss 6.275939 loss_att 242.117844 loss_ctc 13.850750 loss_rnnt 5.434294 lr 0.00023856 rank 3
2022-12-08 16:13:52,893 DEBUG TRAIN Batch 33/5700 loss 13.815752 loss_att 435.652588 loss_ctc 31.281019 loss_rnnt 11.875167 lr 0.00023859 rank 5
2022-12-08 16:14:56,479 DEBUG TRAIN Batch 33/5800 loss 4.872424 loss_att 330.118652 loss_ctc 9.300007 loss_rnnt 4.380470 lr 0.00023853 rank 4
2022-12-08 16:14:56,482 DEBUG TRAIN Batch 33/5800 loss 12.476967 loss_att 378.977264 loss_ctc 22.203346 loss_rnnt 11.396258 lr 0.00023855 rank 2
2022-12-08 16:14:56,482 DEBUG TRAIN Batch 33/5800 loss 9.164191 loss_att 403.091888 loss_ctc 16.257547 loss_rnnt 8.376040 lr 0.00023856 rank 6
2022-12-08 16:14:56,483 DEBUG TRAIN Batch 33/5800 loss 2.213389 loss_att 352.114929 loss_ctc 7.176921 loss_rnnt 1.661885 lr 0.00023853 rank 7
2022-12-08 16:14:56,485 DEBUG TRAIN Batch 33/5800 loss 4.306886 loss_att 409.515564 loss_ctc 11.699648 loss_rnnt 3.485468 lr 0.00023857 rank 5
2022-12-08 16:14:56,488 DEBUG TRAIN Batch 33/5800 loss 7.450566 loss_att 375.852722 loss_ctc 18.273857 loss_rnnt 6.247978 lr 0.00023854 rank 3
2022-12-08 16:14:56,489 DEBUG TRAIN Batch 33/5800 loss 8.324345 loss_att 70.579498 loss_ctc 11.746304 loss_rnnt 7.944127 lr 0.00023852 rank 0
2022-12-08 16:14:56,490 DEBUG TRAIN Batch 33/5800 loss 3.359362 loss_att 391.691010 loss_ctc 11.766630 loss_rnnt 2.425221 lr 0.00023856 rank 1
2022-12-08 16:16:00,498 DEBUG TRAIN Batch 33/5900 loss 4.330317 loss_att 354.665039 loss_ctc 11.650721 loss_rnnt 3.516938 lr 0.00023850 rank 4
2022-12-08 16:16:00,501 DEBUG TRAIN Batch 33/5900 loss 3.480153 loss_att 453.259705 loss_ctc 7.980239 loss_rnnt 2.980143 lr 0.00023853 rank 1
2022-12-08 16:16:00,502 DEBUG TRAIN Batch 33/5900 loss 3.480898 loss_att 403.845398 loss_ctc 9.731934 loss_rnnt 2.786338 lr 0.00023850 rank 7
2022-12-08 16:16:00,502 DEBUG TRAIN Batch 33/5900 loss 8.511747 loss_att 421.063416 loss_ctc 19.195431 loss_rnnt 7.324672 lr 0.00023853 rank 6
2022-12-08 16:16:00,503 DEBUG TRAIN Batch 33/5900 loss 12.384890 loss_att 416.867279 loss_ctc 26.260452 loss_rnnt 10.843161 lr 0.00023852 rank 2
2022-12-08 16:16:00,504 DEBUG TRAIN Batch 33/5900 loss 11.173173 loss_att 411.847351 loss_ctc 23.564127 loss_rnnt 9.796400 lr 0.00023854 rank 5
2022-12-08 16:16:00,507 DEBUG TRAIN Batch 33/5900 loss 6.533381 loss_att 390.750946 loss_ctc 15.935104 loss_rnnt 5.488744 lr 0.00023851 rank 3
2022-12-08 16:16:00,510 DEBUG TRAIN Batch 33/5900 loss 4.565488 loss_att 457.170837 loss_ctc 12.972832 loss_rnnt 3.631339 lr 0.00023849 rank 0
2022-12-08 16:17:05,221 DEBUG TRAIN Batch 33/6000 loss 3.567668 loss_att 313.323853 loss_ctc 7.404568 loss_rnnt 3.141346 lr 0.00023851 rank 5
2022-12-08 16:17:05,224 DEBUG TRAIN Batch 33/6000 loss 6.469090 loss_att 396.123291 loss_ctc 14.618015 loss_rnnt 5.563654 lr 0.00023847 rank 7
2022-12-08 16:17:05,229 DEBUG TRAIN Batch 33/6000 loss 8.372380 loss_att 463.458923 loss_ctc 21.115225 loss_rnnt 6.956509 lr 0.00023848 rank 3
2022-12-08 16:17:05,229 DEBUG TRAIN Batch 33/6000 loss 7.805224 loss_att 385.680603 loss_ctc 15.871779 loss_rnnt 6.908941 lr 0.00023849 rank 2
2022-12-08 16:17:05,230 DEBUG TRAIN Batch 33/6000 loss 5.792019 loss_att 357.817871 loss_ctc 12.157761 loss_rnnt 5.084714 lr 0.00023848 rank 4
2022-12-08 16:17:05,234 DEBUG TRAIN Batch 33/6000 loss 9.185417 loss_att 365.146240 loss_ctc 21.342001 loss_rnnt 7.834686 lr 0.00023850 rank 1
2022-12-08 16:17:05,236 DEBUG TRAIN Batch 33/6000 loss 3.495325 loss_att 396.640228 loss_ctc 11.618942 loss_rnnt 2.592701 lr 0.00023847 rank 0
2022-12-08 16:17:05,251 DEBUG TRAIN Batch 33/6000 loss 9.916153 loss_att 376.316956 loss_ctc 20.199352 loss_rnnt 8.773576 lr 0.00023851 rank 6
2022-12-08 16:18:16,616 DEBUG TRAIN Batch 33/6100 loss 7.485783 loss_att 407.083832 loss_ctc 16.181820 loss_rnnt 6.519556 lr 0.00023847 rank 2
2022-12-08 16:18:16,616 DEBUG TRAIN Batch 33/6100 loss 4.540760 loss_att 356.906281 loss_ctc 9.232024 loss_rnnt 4.019508 lr 0.00023845 rank 4
2022-12-08 16:18:16,616 DEBUG TRAIN Batch 33/6100 loss 4.590152 loss_att 304.140503 loss_ctc 10.902602 loss_rnnt 3.888769 lr 0.00023847 rank 1
2022-12-08 16:18:16,619 DEBUG TRAIN Batch 33/6100 loss 6.677838 loss_att 375.996857 loss_ctc 14.571179 loss_rnnt 5.800800 lr 0.00023848 rank 6
2022-12-08 16:18:16,620 DEBUG TRAIN Batch 33/6100 loss 6.255606 loss_att 405.263123 loss_ctc 12.935099 loss_rnnt 5.513441 lr 0.00023846 rank 3
2022-12-08 16:18:16,621 DEBUG TRAIN Batch 33/6100 loss 7.646699 loss_att 346.217590 loss_ctc 10.625289 loss_rnnt 7.315744 lr 0.00023844 rank 0
2022-12-08 16:18:16,622 DEBUG TRAIN Batch 33/6100 loss 4.937732 loss_att 412.762085 loss_ctc 14.118752 loss_rnnt 3.917619 lr 0.00023845 rank 7
2022-12-08 16:18:16,627 DEBUG TRAIN Batch 33/6100 loss 9.094563 loss_att 330.743225 loss_ctc 18.436687 loss_rnnt 8.056549 lr 0.00023848 rank 5
2022-12-08 16:19:20,528 DEBUG TRAIN Batch 33/6200 loss 10.630351 loss_att 363.512939 loss_ctc 16.872602 loss_rnnt 9.936768 lr 0.00023842 rank 7
2022-12-08 16:19:20,531 DEBUG TRAIN Batch 33/6200 loss 8.791148 loss_att 371.209106 loss_ctc 14.435129 loss_rnnt 8.164040 lr 0.00023844 rank 2
2022-12-08 16:19:20,532 DEBUG TRAIN Batch 33/6200 loss 11.274296 loss_att 396.385193 loss_ctc 17.208838 loss_rnnt 10.614902 lr 0.00023841 rank 0
2022-12-08 16:19:20,534 DEBUG TRAIN Batch 33/6200 loss 3.950179 loss_att 292.737640 loss_ctc 8.374938 loss_rnnt 3.458539 lr 0.00023842 rank 4
2022-12-08 16:19:20,535 DEBUG TRAIN Batch 33/6200 loss 12.710873 loss_att 403.665375 loss_ctc 28.678127 loss_rnnt 10.936733 lr 0.00023843 rank 3
2022-12-08 16:19:20,540 DEBUG TRAIN Batch 33/6200 loss 2.282165 loss_att 313.799103 loss_ctc 5.935597 loss_rnnt 1.876228 lr 0.00023845 rank 1
2022-12-08 16:19:20,541 DEBUG TRAIN Batch 33/6200 loss 8.135553 loss_att 330.214905 loss_ctc 11.106244 loss_rnnt 7.805477 lr 0.00023845 rank 6
2022-12-08 16:19:20,586 DEBUG TRAIN Batch 33/6200 loss 8.959720 loss_att 257.116669 loss_ctc 19.269630 loss_rnnt 7.814175 lr 0.00023846 rank 5
2022-12-08 16:20:24,480 DEBUG TRAIN Batch 33/6300 loss 1.337927 loss_att 369.304993 loss_ctc 2.363646 loss_rnnt 1.223959 lr 0.00023840 rank 4
2022-12-08 16:20:24,493 DEBUG TRAIN Batch 33/6300 loss 11.776988 loss_att 277.901855 loss_ctc 19.171202 loss_rnnt 10.955409 lr 0.00023839 rank 7
2022-12-08 16:20:24,496 DEBUG TRAIN Batch 33/6300 loss 9.254158 loss_att 317.432617 loss_ctc 17.959423 loss_rnnt 8.286906 lr 0.00023838 rank 0
2022-12-08 16:20:24,497 DEBUG TRAIN Batch 33/6300 loss 12.983256 loss_att 243.001282 loss_ctc 22.827513 loss_rnnt 11.889450 lr 0.00023842 rank 6
2022-12-08 16:20:24,498 DEBUG TRAIN Batch 33/6300 loss 10.474297 loss_att 395.233154 loss_ctc 28.235718 loss_rnnt 8.500806 lr 0.00023843 rank 5
2022-12-08 16:20:24,499 DEBUG TRAIN Batch 33/6300 loss 5.490909 loss_att 280.592651 loss_ctc 7.705460 loss_rnnt 5.244848 lr 0.00023840 rank 3
2022-12-08 16:20:24,500 DEBUG TRAIN Batch 33/6300 loss 6.815979 loss_att 238.125290 loss_ctc 12.044380 loss_rnnt 6.235046 lr 0.00023842 rank 1
2022-12-08 16:20:24,536 DEBUG TRAIN Batch 33/6300 loss 14.963980 loss_att 360.571045 loss_ctc 35.697193 loss_rnnt 12.660290 lr 0.00023841 rank 2
2022-12-08 16:21:38,660 DEBUG TRAIN Batch 33/6400 loss 4.075595 loss_att 427.193115 loss_ctc 9.832636 loss_rnnt 3.435925 lr 0.00023837 rank 4
2022-12-08 16:21:38,662 DEBUG TRAIN Batch 33/6400 loss 5.694953 loss_att 399.602295 loss_ctc 15.409983 loss_rnnt 4.615505 lr 0.00023837 rank 7
2022-12-08 16:21:38,666 DEBUG TRAIN Batch 33/6400 loss 10.462223 loss_att 187.114944 loss_ctc 19.182993 loss_rnnt 9.493249 lr 0.00023837 rank 3
2022-12-08 16:21:38,668 DEBUG TRAIN Batch 33/6400 loss 2.401651 loss_att 346.123749 loss_ctc 6.582102 loss_rnnt 1.937156 lr 0.00023839 rank 1
2022-12-08 16:21:38,670 DEBUG TRAIN Batch 33/6400 loss 4.524693 loss_att 124.045441 loss_ctc 11.620972 loss_rnnt 3.736217 lr 0.00023836 rank 0
2022-12-08 16:21:38,673 DEBUG TRAIN Batch 33/6400 loss 7.900396 loss_att 191.604553 loss_ctc 17.088552 loss_rnnt 6.879490 lr 0.00023839 rank 2
2022-12-08 16:21:38,690 DEBUG TRAIN Batch 33/6400 loss 12.596596 loss_att 472.671356 loss_ctc 27.195044 loss_rnnt 10.974546 lr 0.00023840 rank 6
2022-12-08 16:21:38,710 DEBUG TRAIN Batch 33/6400 loss 6.597931 loss_att 337.344452 loss_ctc 10.974857 loss_rnnt 6.111606 lr 0.00023840 rank 5
2022-12-08 16:22:42,670 DEBUG TRAIN Batch 33/6500 loss 2.038820 loss_att 409.607239 loss_ctc 8.868260 loss_rnnt 1.279993 lr 0.00023834 rank 4
2022-12-08 16:22:42,671 DEBUG TRAIN Batch 33/6500 loss 4.285638 loss_att 339.738739 loss_ctc 6.910007 loss_rnnt 3.994042 lr 0.00023834 rank 7
2022-12-08 16:22:42,678 DEBUG TRAIN Batch 33/6500 loss 10.480650 loss_att 400.908386 loss_ctc 17.551632 loss_rnnt 9.694985 lr 0.00023833 rank 0
2022-12-08 16:22:42,680 DEBUG TRAIN Batch 33/6500 loss 10.312604 loss_att 413.864105 loss_ctc 17.913229 loss_rnnt 9.468090 lr 0.00023837 rank 1
2022-12-08 16:22:42,681 DEBUG TRAIN Batch 33/6500 loss 2.291913 loss_att 281.472534 loss_ctc 6.012249 loss_rnnt 1.878542 lr 0.00023835 rank 3
2022-12-08 16:22:42,681 DEBUG TRAIN Batch 33/6500 loss 5.110601 loss_att 314.591064 loss_ctc 10.431694 loss_rnnt 4.519369 lr 0.00023838 rank 5
2022-12-08 16:22:42,683 DEBUG TRAIN Batch 33/6500 loss 5.067204 loss_att 433.795746 loss_ctc 10.963163 loss_rnnt 4.412097 lr 0.00023836 rank 2
2022-12-08 16:22:42,721 DEBUG TRAIN Batch 33/6500 loss 4.308050 loss_att 395.709656 loss_ctc 11.047928 loss_rnnt 3.559174 lr 0.00023837 rank 6
2022-12-08 16:23:46,655 DEBUG TRAIN Batch 33/6600 loss 7.141931 loss_att 419.416260 loss_ctc 10.622915 loss_rnnt 6.755155 lr 0.00023831 rank 7
2022-12-08 16:23:46,656 DEBUG TRAIN Batch 33/6600 loss 12.116128 loss_att 373.875824 loss_ctc 24.943821 loss_rnnt 10.690829 lr 0.00023832 rank 3
2022-12-08 16:23:46,658 DEBUG TRAIN Batch 33/6600 loss 6.673958 loss_att 411.708740 loss_ctc 11.618449 loss_rnnt 6.124570 lr 0.00023833 rank 2
2022-12-08 16:23:46,658 DEBUG TRAIN Batch 33/6600 loss 4.278942 loss_att 310.179535 loss_ctc 9.780554 loss_rnnt 3.667652 lr 0.00023832 rank 4
2022-12-08 16:23:46,660 DEBUG TRAIN Batch 33/6600 loss 6.317908 loss_att 378.692932 loss_ctc 11.602727 loss_rnnt 5.730707 lr 0.00023834 rank 6
2022-12-08 16:23:46,662 DEBUG TRAIN Batch 33/6600 loss 6.631970 loss_att 388.300568 loss_ctc 14.614746 loss_rnnt 5.744995 lr 0.00023834 rank 1
2022-12-08 16:23:46,663 DEBUG TRAIN Batch 33/6600 loss 8.693679 loss_att 420.302490 loss_ctc 15.229892 loss_rnnt 7.967433 lr 0.00023830 rank 0
2022-12-08 16:23:46,666 DEBUG TRAIN Batch 33/6600 loss 7.743669 loss_att 362.439209 loss_ctc 15.517681 loss_rnnt 6.879889 lr 0.00023835 rank 5
2022-12-08 16:24:50,864 DEBUG TRAIN Batch 33/6700 loss 2.701731 loss_att 377.002930 loss_ctc 7.776282 loss_rnnt 2.137892 lr 0.00023832 rank 5
2022-12-08 16:24:50,876 DEBUG TRAIN Batch 33/6700 loss 8.917851 loss_att 439.152405 loss_ctc 21.349819 loss_rnnt 7.536521 lr 0.00023828 rank 7
2022-12-08 16:24:50,876 DEBUG TRAIN Batch 33/6700 loss 10.897673 loss_att 440.584106 loss_ctc 20.653601 loss_rnnt 9.813681 lr 0.00023829 rank 4
2022-12-08 16:24:50,877 DEBUG TRAIN Batch 33/6700 loss 9.030455 loss_att 380.788635 loss_ctc 24.695221 loss_rnnt 7.289926 lr 0.00023828 rank 0
2022-12-08 16:24:50,881 DEBUG TRAIN Batch 33/6700 loss 9.919591 loss_att 415.885071 loss_ctc 18.175228 loss_rnnt 9.002298 lr 0.00023831 rank 1
2022-12-08 16:24:50,881 DEBUG TRAIN Batch 33/6700 loss 6.489009 loss_att 348.998108 loss_ctc 17.130087 loss_rnnt 5.306667 lr 0.00023832 rank 6
2022-12-08 16:24:50,882 DEBUG TRAIN Batch 33/6700 loss 8.642257 loss_att 352.926483 loss_ctc 15.514702 loss_rnnt 7.878653 lr 0.00023830 rank 2
2022-12-08 16:24:50,910 DEBUG TRAIN Batch 33/6700 loss 10.182345 loss_att 348.385712 loss_ctc 15.702746 loss_rnnt 9.568968 lr 0.00023829 rank 3
2022-12-08 16:26:02,404 DEBUG TRAIN Batch 33/6800 loss 12.437133 loss_att 347.723480 loss_ctc 23.324413 loss_rnnt 11.227435 lr 0.00023826 rank 7
2022-12-08 16:26:02,410 DEBUG TRAIN Batch 33/6800 loss 7.064899 loss_att 296.938568 loss_ctc 15.727028 loss_rnnt 6.102440 lr 0.00023826 rank 4
2022-12-08 16:26:02,416 DEBUG TRAIN Batch 33/6800 loss 5.424402 loss_att 363.539581 loss_ctc 11.074816 loss_rnnt 4.796579 lr 0.00023828 rank 1
2022-12-08 16:26:02,417 DEBUG TRAIN Batch 33/6800 loss 4.741406 loss_att 265.479736 loss_ctc 10.993458 loss_rnnt 4.046733 lr 0.00023829 rank 6
2022-12-08 16:26:02,418 DEBUG TRAIN Batch 33/6800 loss 7.611704 loss_att 333.878967 loss_ctc 11.856413 loss_rnnt 7.140069 lr 0.00023829 rank 5
2022-12-08 16:26:02,419 DEBUG TRAIN Batch 33/6800 loss 7.096961 loss_att 308.598328 loss_ctc 13.023506 loss_rnnt 6.438457 lr 0.00023828 rank 2
2022-12-08 16:26:02,420 DEBUG TRAIN Batch 33/6800 loss 10.490263 loss_att 403.717072 loss_ctc 26.956625 loss_rnnt 8.660667 lr 0.00023825 rank 0
2022-12-08 16:26:02,453 DEBUG TRAIN Batch 33/6800 loss 12.580001 loss_att 301.115967 loss_ctc 17.891279 loss_rnnt 11.989859 lr 0.00023827 rank 3
2022-12-08 16:27:06,035 DEBUG TRAIN Batch 33/6900 loss 4.923683 loss_att 298.737793 loss_ctc 10.150293 loss_rnnt 4.342948 lr 0.00023823 rank 7
2022-12-08 16:27:06,036 DEBUG TRAIN Batch 33/6900 loss 5.168355 loss_att 320.982849 loss_ctc 11.946026 loss_rnnt 4.415281 lr 0.00023822 rank 0
2022-12-08 16:27:06,039 DEBUG TRAIN Batch 33/6900 loss 7.627797 loss_att 347.826630 loss_ctc 14.591460 loss_rnnt 6.854057 lr 0.00023826 rank 6
2022-12-08 16:27:06,040 DEBUG TRAIN Batch 33/6900 loss 5.869963 loss_att 159.499832 loss_ctc 11.643888 loss_rnnt 5.228416 lr 0.00023823 rank 4
2022-12-08 16:27:06,041 DEBUG TRAIN Batch 33/6900 loss 9.407237 loss_att 312.439301 loss_ctc 19.892248 loss_rnnt 8.242236 lr 0.00023826 rank 1
2022-12-08 16:27:06,042 DEBUG TRAIN Batch 33/6900 loss 5.467713 loss_att 414.307739 loss_ctc 14.478924 loss_rnnt 4.466468 lr 0.00023825 rank 2
2022-12-08 16:27:06,045 DEBUG TRAIN Batch 33/6900 loss 10.500939 loss_att 389.927216 loss_ctc 15.483501 loss_rnnt 9.947321 lr 0.00023827 rank 5
2022-12-08 16:27:06,084 DEBUG TRAIN Batch 33/6900 loss 8.079025 loss_att 397.946350 loss_ctc 18.034077 loss_rnnt 6.972909 lr 0.00023824 rank 3
2022-12-08 16:28:09,763 DEBUG TRAIN Batch 33/7000 loss 8.912724 loss_att 79.894928 loss_ctc 12.199397 loss_rnnt 8.547538 lr 0.00023820 rank 7
2022-12-08 16:28:09,764 DEBUG TRAIN Batch 33/7000 loss 7.219677 loss_att 205.249924 loss_ctc 11.269328 loss_rnnt 6.769716 lr 0.00023821 rank 3
2022-12-08 16:28:09,766 DEBUG TRAIN Batch 33/7000 loss 3.883694 loss_att 250.700439 loss_ctc 5.707602 loss_rnnt 3.681038 lr 0.00023822 rank 2
2022-12-08 16:28:09,768 DEBUG TRAIN Batch 33/7000 loss 2.524965 loss_att 239.365692 loss_ctc 10.362787 loss_rnnt 1.654096 lr 0.00023823 rank 1
2022-12-08 16:28:09,768 DEBUG TRAIN Batch 33/7000 loss 8.874012 loss_att 385.444275 loss_ctc 20.887268 loss_rnnt 7.539206 lr 0.00023824 rank 5
2022-12-08 16:28:09,768 DEBUG TRAIN Batch 33/7000 loss 5.120971 loss_att 402.142670 loss_ctc 11.836935 loss_rnnt 4.374753 lr 0.00023821 rank 4
2022-12-08 16:28:09,775 DEBUG TRAIN Batch 33/7000 loss 7.892595 loss_att 217.088760 loss_ctc 12.595117 loss_rnnt 7.370093 lr 0.00023820 rank 0
2022-12-08 16:28:09,810 DEBUG TRAIN Batch 33/7000 loss 5.773664 loss_att 292.775452 loss_ctc 8.542121 loss_rnnt 5.466058 lr 0.00023824 rank 6
2022-12-08 16:29:15,188 DEBUG TRAIN Batch 33/7100 loss 12.506640 loss_att 424.094177 loss_ctc 34.671249 loss_rnnt 10.043906 lr 0.00023818 rank 4
2022-12-08 16:29:15,191 DEBUG TRAIN Batch 33/7100 loss 11.833706 loss_att 436.034912 loss_ctc 25.993132 loss_rnnt 10.260437 lr 0.00023817 rank 0
2022-12-08 16:29:15,193 DEBUG TRAIN Batch 33/7100 loss 5.114131 loss_att 425.010254 loss_ctc 12.484024 loss_rnnt 4.295255 lr 0.00023818 rank 7
2022-12-08 16:29:15,194 DEBUG TRAIN Batch 33/7100 loss 7.412591 loss_att 417.206024 loss_ctc 17.141569 loss_rnnt 6.331594 lr 0.00023818 rank 3
2022-12-08 16:29:15,195 DEBUG TRAIN Batch 33/7100 loss 2.729558 loss_att 271.219055 loss_ctc 9.635481 loss_rnnt 1.962233 lr 0.00023821 rank 6
2022-12-08 16:29:15,219 DEBUG TRAIN Batch 33/7100 loss 16.016737 loss_att 415.507019 loss_ctc 31.949932 loss_rnnt 14.246383 lr 0.00023820 rank 1
2022-12-08 16:29:15,223 DEBUG TRAIN Batch 33/7100 loss 9.841356 loss_att 428.459320 loss_ctc 20.525013 loss_rnnt 8.654284 lr 0.00023821 rank 5
2022-12-08 16:29:15,232 DEBUG TRAIN Batch 33/7100 loss 5.443420 loss_att 459.172180 loss_ctc 10.695025 loss_rnnt 4.859909 lr 0.00023820 rank 2
2022-12-08 16:30:25,602 DEBUG TRAIN Batch 33/7200 loss 6.127016 loss_att 393.015686 loss_ctc 14.478489 loss_rnnt 5.199075 lr 0.00023815 rank 4
2022-12-08 16:30:25,617 DEBUG TRAIN Batch 33/7200 loss 7.246812 loss_att 393.551971 loss_ctc 23.526943 loss_rnnt 5.437908 lr 0.00023818 rank 1
2022-12-08 16:30:25,618 DEBUG TRAIN Batch 33/7200 loss 8.423358 loss_att 412.390747 loss_ctc 21.864111 loss_rnnt 6.929941 lr 0.00023815 rank 7
2022-12-08 16:30:25,620 DEBUG TRAIN Batch 33/7200 loss 6.602324 loss_att 349.210907 loss_ctc 15.912987 loss_rnnt 5.567806 lr 0.00023814 rank 0
2022-12-08 16:30:25,620 DEBUG TRAIN Batch 33/7200 loss 6.934181 loss_att 351.202484 loss_ctc 10.079235 loss_rnnt 6.584730 lr 0.00023816 rank 3
2022-12-08 16:30:25,621 DEBUG TRAIN Batch 33/7200 loss 13.501072 loss_att 433.588074 loss_ctc 32.082485 loss_rnnt 11.436470 lr 0.00023817 rank 2
2022-12-08 16:30:25,622 DEBUG TRAIN Batch 33/7200 loss 6.567648 loss_att 402.678467 loss_ctc 13.426008 loss_rnnt 5.805609 lr 0.00023818 rank 6
2022-12-08 16:30:25,621 DEBUG TRAIN Batch 33/7200 loss 8.547850 loss_att 408.514404 loss_ctc 18.396923 loss_rnnt 7.453508 lr 0.00023819 rank 5
2022-12-08 16:31:29,122 DEBUG TRAIN Batch 33/7300 loss 6.600558 loss_att 371.911194 loss_ctc 13.762762 loss_rnnt 5.804758 lr 0.00023813 rank 4
2022-12-08 16:31:29,125 DEBUG TRAIN Batch 33/7300 loss 7.776338 loss_att 356.938965 loss_ctc 15.579714 loss_rnnt 6.909296 lr 0.00023815 rank 1
2022-12-08 16:31:29,128 DEBUG TRAIN Batch 33/7300 loss 4.646878 loss_att 376.598938 loss_ctc 8.203911 loss_rnnt 4.251652 lr 0.00023812 rank 7
2022-12-08 16:31:29,129 DEBUG TRAIN Batch 33/7300 loss 4.787973 loss_att 335.648621 loss_ctc 12.701481 loss_rnnt 3.908695 lr 0.00023813 rank 3
2022-12-08 16:31:29,132 DEBUG TRAIN Batch 33/7300 loss 17.088715 loss_att 446.425049 loss_ctc 33.611309 loss_rnnt 15.252872 lr 0.00023811 rank 0
2022-12-08 16:31:29,134 DEBUG TRAIN Batch 33/7300 loss 10.767978 loss_att 371.842712 loss_ctc 22.109676 loss_rnnt 9.507789 lr 0.00023814 rank 2
2022-12-08 16:31:29,134 DEBUG TRAIN Batch 33/7300 loss 12.170129 loss_att 359.039581 loss_ctc 16.952549 loss_rnnt 11.638748 lr 0.00023816 rank 5
2022-12-08 16:31:29,169 DEBUG TRAIN Batch 33/7300 loss 6.136357 loss_att 359.222565 loss_ctc 14.054559 loss_rnnt 5.256557 lr 0.00023815 rank 6
2022-12-08 16:32:33,102 DEBUG TRAIN Batch 33/7400 loss 3.835274 loss_att 419.770386 loss_ctc 7.721478 loss_rnnt 3.403473 lr 0.00023812 rank 2
2022-12-08 16:32:33,106 DEBUG TRAIN Batch 33/7400 loss 10.313667 loss_att 387.422241 loss_ctc 18.831364 loss_rnnt 9.367256 lr 0.00023810 rank 3
2022-12-08 16:32:33,107 DEBUG TRAIN Batch 33/7400 loss 11.058713 loss_att 425.052673 loss_ctc 20.089891 loss_rnnt 10.055248 lr 0.00023809 rank 0
2022-12-08 16:32:33,108 DEBUG TRAIN Batch 33/7400 loss 3.596917 loss_att 324.326111 loss_ctc 6.417424 loss_rnnt 3.283528 lr 0.00023810 rank 7
2022-12-08 16:32:33,108 DEBUG TRAIN Batch 33/7400 loss 4.886058 loss_att 367.835449 loss_ctc 10.822118 loss_rnnt 4.226496 lr 0.00023810 rank 4
2022-12-08 16:32:33,108 DEBUG TRAIN Batch 33/7400 loss 7.816129 loss_att 295.725220 loss_ctc 10.084335 loss_rnnt 7.564106 lr 0.00023813 rank 6
2022-12-08 16:32:33,113 DEBUG TRAIN Batch 33/7400 loss 16.437683 loss_att 360.001465 loss_ctc 27.821438 loss_rnnt 15.172821 lr 0.00023813 rank 5
2022-12-08 16:32:33,122 DEBUG TRAIN Batch 33/7400 loss 10.225287 loss_att 431.728882 loss_ctc 30.250679 loss_rnnt 8.000244 lr 0.00023812 rank 1
2022-12-08 16:33:43,456 DEBUG TRAIN Batch 33/7500 loss 8.310976 loss_att 201.334732 loss_ctc 14.840894 loss_rnnt 7.585430 lr 0.00023807 rank 4
2022-12-08 16:33:43,459 DEBUG TRAIN Batch 33/7500 loss 10.911864 loss_att 285.090332 loss_ctc 21.848270 loss_rnnt 9.696709 lr 0.00023810 rank 6
2022-12-08 16:33:43,458 DEBUG TRAIN Batch 33/7500 loss 2.828602 loss_att 342.262085 loss_ctc 10.790939 loss_rnnt 1.943898 lr 0.00023807 rank 7
2022-12-08 16:33:43,460 DEBUG TRAIN Batch 33/7500 loss 6.871059 loss_att 339.710632 loss_ctc 14.054307 loss_rnnt 6.072921 lr 0.00023809 rank 2
2022-12-08 16:33:43,460 DEBUG TRAIN Batch 33/7500 loss 10.886982 loss_att 438.713623 loss_ctc 21.567793 loss_rnnt 9.700226 lr 0.00023806 rank 0
2022-12-08 16:33:43,464 DEBUG TRAIN Batch 33/7500 loss 4.235808 loss_att 428.493225 loss_ctc 15.856844 loss_rnnt 2.944582 lr 0.00023808 rank 3
2022-12-08 16:33:43,465 DEBUG TRAIN Batch 33/7500 loss 4.690699 loss_att 217.165695 loss_ctc 11.298010 loss_rnnt 3.956553 lr 0.00023811 rank 5
2022-12-08 16:33:43,471 DEBUG TRAIN Batch 33/7500 loss 9.001167 loss_att 324.939575 loss_ctc 13.591838 loss_rnnt 8.491093 lr 0.00023809 rank 1
2022-12-08 16:34:47,436 DEBUG TRAIN Batch 33/7600 loss 8.732870 loss_att 380.962616 loss_ctc 23.132736 loss_rnnt 7.132885 lr 0.00023804 rank 4
2022-12-08 16:34:47,443 DEBUG TRAIN Batch 33/7600 loss 6.636990 loss_att 153.453506 loss_ctc 9.753847 loss_rnnt 6.290672 lr 0.00023807 rank 6
2022-12-08 16:34:47,446 DEBUG TRAIN Batch 33/7600 loss 5.492107 loss_att 199.926117 loss_ctc 9.947765 loss_rnnt 4.997034 lr 0.00023804 rank 7
2022-12-08 16:34:47,448 DEBUG TRAIN Batch 33/7600 loss 8.596220 loss_att 333.126282 loss_ctc 15.885300 loss_rnnt 7.786322 lr 0.00023803 rank 0
2022-12-08 16:34:47,448 DEBUG TRAIN Batch 33/7600 loss 6.703494 loss_att 213.678650 loss_ctc 14.517430 loss_rnnt 5.835279 lr 0.00023807 rank 1
2022-12-08 16:34:47,448 DEBUG TRAIN Batch 33/7600 loss 3.653309 loss_att 295.720337 loss_ctc 7.691036 loss_rnnt 3.204672 lr 0.00023805 rank 3
2022-12-08 16:34:47,452 DEBUG TRAIN Batch 33/7600 loss 9.477791 loss_att 404.234467 loss_ctc 27.516058 loss_rnnt 7.473539 lr 0.00023808 rank 5
2022-12-08 16:34:47,453 DEBUG TRAIN Batch 33/7600 loss 7.912903 loss_att 321.618713 loss_ctc 18.025385 loss_rnnt 6.789295 lr 0.00023806 rank 2
2022-12-08 16:35:50,921 DEBUG TRAIN Batch 33/7700 loss 1.549102 loss_att 377.841125 loss_ctc 4.249016 loss_rnnt 1.249112 lr 0.00023801 rank 7
2022-12-08 16:35:50,930 DEBUG TRAIN Batch 33/7700 loss 13.646576 loss_att 466.128601 loss_ctc 23.512474 loss_rnnt 12.550364 lr 0.00023802 rank 4
2022-12-08 16:35:50,933 DEBUG TRAIN Batch 33/7700 loss 1.092387 loss_att 333.777069 loss_ctc 2.462337 loss_rnnt 0.940170 lr 0.00023804 rank 1
2022-12-08 16:35:50,935 DEBUG TRAIN Batch 33/7700 loss 9.516868 loss_att 443.932800 loss_ctc 19.066084 loss_rnnt 8.455844 lr 0.00023802 rank 3
2022-12-08 16:35:50,936 DEBUG TRAIN Batch 33/7700 loss 8.234781 loss_att 125.312012 loss_ctc 16.037357 loss_rnnt 7.367828 lr 0.00023803 rank 2
2022-12-08 16:35:50,941 DEBUG TRAIN Batch 33/7700 loss 3.956883 loss_att 479.046875 loss_ctc 7.250239 loss_rnnt 3.590955 lr 0.00023805 rank 6
2022-12-08 16:35:50,941 DEBUG TRAIN Batch 33/7700 loss 8.917095 loss_att 429.126801 loss_ctc 17.420506 loss_rnnt 7.972272 lr 0.00023805 rank 5
2022-12-08 16:35:50,944 DEBUG TRAIN Batch 33/7700 loss 9.336321 loss_att 251.029709 loss_ctc 14.856229 loss_rnnt 8.722999 lr 0.00023801 rank 0
2022-12-08 16:36:56,732 DEBUG TRAIN Batch 33/7800 loss 10.020422 loss_att 420.179443 loss_ctc 19.691084 loss_rnnt 8.945904 lr 0.00023802 rank 6
2022-12-08 16:36:56,744 DEBUG TRAIN Batch 33/7800 loss 5.657397 loss_att 418.225891 loss_ctc 15.639849 loss_rnnt 4.548236 lr 0.00023799 rank 4
2022-12-08 16:36:56,749 DEBUG TRAIN Batch 33/7800 loss 9.667488 loss_att 364.238220 loss_ctc 16.132160 loss_rnnt 8.949191 lr 0.00023799 rank 7
2022-12-08 16:36:56,750 DEBUG TRAIN Batch 33/7800 loss 5.614656 loss_att 415.267181 loss_ctc 15.217129 loss_rnnt 4.547715 lr 0.00023801 rank 2
2022-12-08 16:36:56,751 DEBUG TRAIN Batch 33/7800 loss 3.061029 loss_att 340.263153 loss_ctc 5.284563 loss_rnnt 2.813970 lr 0.00023801 rank 1
2022-12-08 16:36:56,750 DEBUG TRAIN Batch 33/7800 loss 7.868329 loss_att 415.512390 loss_ctc 13.199196 loss_rnnt 7.276011 lr 0.00023798 rank 0
2022-12-08 16:36:56,767 DEBUG TRAIN Batch 33/7800 loss 7.477301 loss_att 394.455078 loss_ctc 14.039683 loss_rnnt 6.748148 lr 0.00023800 rank 3
2022-12-08 16:36:56,769 DEBUG TRAIN Batch 33/7800 loss 5.217773 loss_att 357.293549 loss_ctc 13.914371 loss_rnnt 4.251484 lr 0.00023802 rank 5
2022-12-08 16:38:06,594 DEBUG TRAIN Batch 33/7900 loss 6.285218 loss_att 343.743256 loss_ctc 12.630450 loss_rnnt 5.580193 lr 0.00023796 rank 4
2022-12-08 16:38:06,596 DEBUG TRAIN Batch 33/7900 loss 9.244935 loss_att 393.549255 loss_ctc 28.642654 loss_rnnt 7.089633 lr 0.00023798 rank 2
2022-12-08 16:38:06,596 DEBUG TRAIN Batch 33/7900 loss 4.480177 loss_att 310.098145 loss_ctc 11.436922 loss_rnnt 3.707206 lr 0.00023799 rank 1
2022-12-08 16:38:06,596 DEBUG TRAIN Batch 33/7900 loss 4.647339 loss_att 346.634247 loss_ctc 12.263522 loss_rnnt 3.801096 lr 0.00023796 rank 7
2022-12-08 16:38:06,597 DEBUG TRAIN Batch 33/7900 loss 6.533727 loss_att 358.230042 loss_ctc 13.836174 loss_rnnt 5.722344 lr 0.00023799 rank 6
2022-12-08 16:38:06,602 DEBUG TRAIN Batch 33/7900 loss 7.979481 loss_att 435.920502 loss_ctc 17.315468 loss_rnnt 6.942149 lr 0.00023795 rank 0
2022-12-08 16:38:06,604 DEBUG TRAIN Batch 33/7900 loss 4.138565 loss_att 350.941895 loss_ctc 8.013419 loss_rnnt 3.708025 lr 0.00023797 rank 3
2022-12-08 16:38:06,606 DEBUG TRAIN Batch 33/7900 loss 4.695759 loss_att 378.788910 loss_ctc 11.762215 loss_rnnt 3.910597 lr 0.00023800 rank 5
2022-12-08 16:39:09,723 DEBUG TRAIN Batch 33/8000 loss 6.095634 loss_att 369.257935 loss_ctc 14.166071 loss_rnnt 5.198919 lr 0.00023794 rank 4
2022-12-08 16:39:09,732 DEBUG TRAIN Batch 33/8000 loss 5.727002 loss_att 358.824738 loss_ctc 10.827040 loss_rnnt 5.160331 lr 0.00023793 rank 7
2022-12-08 16:39:09,732 DEBUG TRAIN Batch 33/8000 loss 10.073059 loss_att 365.579163 loss_ctc 19.373032 loss_rnnt 9.039729 lr 0.00023794 rank 3
2022-12-08 16:39:09,733 DEBUG TRAIN Batch 33/8000 loss 7.506111 loss_att 338.331665 loss_ctc 10.408165 loss_rnnt 7.183661 lr 0.00023797 rank 5
2022-12-08 16:39:09,735 DEBUG TRAIN Batch 33/8000 loss 4.437894 loss_att 276.400269 loss_ctc 9.904451 loss_rnnt 3.830499 lr 0.00023795 rank 2
2022-12-08 16:39:09,741 DEBUG TRAIN Batch 33/8000 loss 6.321085 loss_att 386.927185 loss_ctc 11.201583 loss_rnnt 5.778808 lr 0.00023793 rank 0
2022-12-08 16:39:09,747 DEBUG TRAIN Batch 33/8000 loss 7.854649 loss_att 355.445312 loss_ctc 19.567982 loss_rnnt 6.553167 lr 0.00023796 rank 1
2022-12-08 16:39:09,771 DEBUG TRAIN Batch 33/8000 loss 12.210010 loss_att 448.289551 loss_ctc 26.528547 loss_rnnt 10.619061 lr 0.00023797 rank 6
2022-12-08 16:40:13,137 DEBUG TRAIN Batch 33/8100 loss 13.272289 loss_att 384.036133 loss_ctc 21.645750 loss_rnnt 12.341906 lr 0.00023793 rank 2
2022-12-08 16:40:13,152 DEBUG TRAIN Batch 33/8100 loss 4.667300 loss_att 388.004333 loss_ctc 10.261559 loss_rnnt 4.045716 lr 0.00023791 rank 7
2022-12-08 16:40:13,152 DEBUG TRAIN Batch 33/8100 loss 4.791873 loss_att 259.463684 loss_ctc 8.569934 loss_rnnt 4.372089 lr 0.00023791 rank 4
2022-12-08 16:40:13,155 DEBUG TRAIN Batch 33/8100 loss 1.382859 loss_att 379.031158 loss_ctc 3.723888 loss_rnnt 1.122744 lr 0.00023792 rank 3
2022-12-08 16:40:13,158 DEBUG TRAIN Batch 33/8100 loss 7.023580 loss_att 266.450195 loss_ctc 14.191623 loss_rnnt 6.227131 lr 0.00023794 rank 5
2022-12-08 16:40:13,159 DEBUG TRAIN Batch 33/8100 loss 7.757345 loss_att 323.391968 loss_ctc 10.991367 loss_rnnt 7.398009 lr 0.00023794 rank 6
2022-12-08 16:40:13,167 DEBUG TRAIN Batch 33/8100 loss 7.236610 loss_att 344.489136 loss_ctc 11.429044 loss_rnnt 6.770784 lr 0.00023793 rank 1
2022-12-08 16:40:13,180 DEBUG TRAIN Batch 33/8100 loss 3.284505 loss_att 385.447479 loss_ctc 11.136425 loss_rnnt 2.412070 lr 0.00023790 rank 0
2022-12-08 16:41:17,906 DEBUG TRAIN Batch 33/8200 loss 2.138577 loss_att 326.907501 loss_ctc 5.111776 loss_rnnt 1.808222 lr 0.00023788 rank 4
2022-12-08 16:41:17,912 DEBUG TRAIN Batch 33/8200 loss 10.088775 loss_att 327.077271 loss_ctc 17.629013 loss_rnnt 9.250971 lr 0.00023789 rank 3
2022-12-08 16:41:17,915 DEBUG TRAIN Batch 33/8200 loss 9.201275 loss_att 253.774567 loss_ctc 12.081070 loss_rnnt 8.881297 lr 0.00023790 rank 2
2022-12-08 16:41:17,916 DEBUG TRAIN Batch 33/8200 loss 5.975455 loss_att 307.082733 loss_ctc 13.570833 loss_rnnt 5.131525 lr 0.00023788 rank 7
2022-12-08 16:41:17,917 DEBUG TRAIN Batch 33/8200 loss 10.026337 loss_att 339.830170 loss_ctc 17.816471 loss_rnnt 9.160767 lr 0.00023787 rank 0
2022-12-08 16:41:17,919 DEBUG TRAIN Batch 33/8200 loss 6.643969 loss_att 402.432220 loss_ctc 17.119593 loss_rnnt 5.480011 lr 0.00023792 rank 5
2022-12-08 16:41:17,923 DEBUG TRAIN Batch 33/8200 loss 7.871510 loss_att 243.766571 loss_ctc 17.164398 loss_rnnt 6.838967 lr 0.00023791 rank 1
2022-12-08 16:41:17,956 DEBUG TRAIN Batch 33/8200 loss 6.603547 loss_att 196.104355 loss_ctc 12.835008 loss_rnnt 5.911162 lr 0.00023791 rank 6
2022-12-08 16:42:21,800 DEBUG TRAIN Batch 33/8300 loss 3.077192 loss_att 426.532288 loss_ctc 6.677616 loss_rnnt 2.677145 lr 0.00023788 rank 1
2022-12-08 16:42:21,807 DEBUG TRAIN Batch 33/8300 loss 1.517368 loss_att 407.700745 loss_ctc 4.329244 loss_rnnt 1.204937 lr 0.00023786 rank 4
2022-12-08 16:42:21,807 DEBUG TRAIN Batch 33/8300 loss 7.489597 loss_att 446.877899 loss_ctc 9.366045 loss_rnnt 7.281103 lr 0.00023785 rank 7
2022-12-08 16:42:21,808 DEBUG TRAIN Batch 33/8300 loss 12.240710 loss_att 330.167633 loss_ctc 21.762197 loss_rnnt 11.182767 lr 0.00023786 rank 3
2022-12-08 16:42:21,810 DEBUG TRAIN Batch 33/8300 loss 1.891116 loss_att 345.985046 loss_ctc 7.087875 loss_rnnt 1.313698 lr 0.00023789 rank 5
2022-12-08 16:42:21,812 DEBUG TRAIN Batch 33/8300 loss 4.395100 loss_att 285.862640 loss_ctc 8.716159 loss_rnnt 3.914983 lr 0.00023787 rank 2
2022-12-08 16:42:21,814 DEBUG TRAIN Batch 33/8300 loss 7.076708 loss_att 323.879486 loss_ctc 13.052779 loss_rnnt 6.412701 lr 0.00023788 rank 6
2022-12-08 16:42:21,814 DEBUG TRAIN Batch 33/8300 loss 11.798172 loss_att 345.028320 loss_ctc 24.284988 loss_rnnt 10.410748 lr 0.00023784 rank 0
2022-12-08 16:43:06,878 DEBUG CV Batch 33/0 loss 1.567770 loss_att 48.086014 loss_ctc 2.629975 loss_rnnt 1.449747 history loss 1.509705 rank 5
2022-12-08 16:43:06,882 DEBUG CV Batch 33/0 loss 1.567770 loss_att 48.086014 loss_ctc 2.629975 loss_rnnt 1.449747 history loss 1.509705 rank 2
2022-12-08 16:43:06,883 DEBUG CV Batch 33/0 loss 1.567770 loss_att 48.086014 loss_ctc 2.629975 loss_rnnt 1.449747 history loss 1.509705 rank 3
2022-12-08 16:43:06,883 DEBUG CV Batch 33/0 loss 1.567770 loss_att 48.086014 loss_ctc 2.629975 loss_rnnt 1.449747 history loss 1.509705 rank 1
2022-12-08 16:43:06,883 DEBUG CV Batch 33/0 loss 1.567770 loss_att 48.086014 loss_ctc 2.629975 loss_rnnt 1.449747 history loss 1.509705 rank 6
2022-12-08 16:43:06,884 DEBUG CV Batch 33/0 loss 1.567770 loss_att 48.086014 loss_ctc 2.629975 loss_rnnt 1.449747 history loss 1.509705 rank 4
2022-12-08 16:43:06,893 DEBUG CV Batch 33/0 loss 1.567770 loss_att 48.086014 loss_ctc 2.629975 loss_rnnt 1.449747 history loss 1.509705 rank 0
2022-12-08 16:43:06,898 DEBUG CV Batch 33/0 loss 1.567770 loss_att 48.086014 loss_ctc 2.629975 loss_rnnt 1.449747 history loss 1.509705 rank 7
2022-12-08 16:43:17,571 DEBUG CV Batch 33/100 loss 3.703180 loss_att 266.941895 loss_ctc 11.501844 loss_rnnt 2.836662 history loss 2.927889 rank 3
2022-12-08 16:43:17,776 DEBUG CV Batch 33/100 loss 3.703180 loss_att 266.941895 loss_ctc 11.501844 loss_rnnt 2.836662 history loss 2.927889 rank 5
2022-12-08 16:43:17,811 DEBUG CV Batch 33/100 loss 3.703180 loss_att 266.941895 loss_ctc 11.501844 loss_rnnt 2.836662 history loss 2.927889 rank 2
2022-12-08 16:43:17,879 DEBUG CV Batch 33/100 loss 3.703180 loss_att 266.941895 loss_ctc 11.501844 loss_rnnt 2.836662 history loss 2.927889 rank 4
2022-12-08 16:43:17,918 DEBUG CV Batch 33/100 loss 3.703180 loss_att 266.941895 loss_ctc 11.501844 loss_rnnt 2.836662 history loss 2.927889 rank 1
2022-12-08 16:43:17,975 DEBUG CV Batch 33/100 loss 3.703180 loss_att 266.941895 loss_ctc 11.501844 loss_rnnt 2.836662 history loss 2.927889 rank 0
2022-12-08 16:43:18,198 DEBUG CV Batch 33/100 loss 3.703180 loss_att 266.941895 loss_ctc 11.501844 loss_rnnt 2.836662 history loss 2.927889 rank 7
2022-12-08 16:43:18,289 DEBUG CV Batch 33/100 loss 3.703180 loss_att 266.941895 loss_ctc 11.501844 loss_rnnt 2.836662 history loss 2.927889 rank 6
2022-12-08 16:43:31,294 DEBUG CV Batch 33/200 loss 2.642679 loss_att 641.180542 loss_ctc 5.178558 loss_rnnt 2.360915 history loss 3.462792 rank 3
2022-12-08 16:43:31,349 DEBUG CV Batch 33/200 loss 2.642679 loss_att 641.180542 loss_ctc 5.178558 loss_rnnt 2.360915 history loss 3.462792 rank 5
2022-12-08 16:43:31,515 DEBUG CV Batch 33/200 loss 2.642679 loss_att 641.180542 loss_ctc 5.178558 loss_rnnt 2.360915 history loss 3.462792 rank 2
2022-12-08 16:43:31,564 DEBUG CV Batch 33/200 loss 2.642679 loss_att 641.180542 loss_ctc 5.178558 loss_rnnt 2.360915 history loss 3.462792 rank 1
2022-12-08 16:43:31,924 DEBUG CV Batch 33/200 loss 2.642679 loss_att 641.180542 loss_ctc 5.178558 loss_rnnt 2.360915 history loss 3.462792 rank 4
2022-12-08 16:43:31,965 DEBUG CV Batch 33/200 loss 2.642679 loss_att 641.180542 loss_ctc 5.178558 loss_rnnt 2.360915 history loss 3.462792 rank 6
2022-12-08 16:43:32,092 DEBUG CV Batch 33/200 loss 2.642679 loss_att 641.180542 loss_ctc 5.178558 loss_rnnt 2.360915 history loss 3.462792 rank 0
2022-12-08 16:43:32,419 DEBUG CV Batch 33/200 loss 2.642679 loss_att 641.180542 loss_ctc 5.178558 loss_rnnt 2.360915 history loss 3.462792 rank 7
2022-12-08 16:43:42,461 DEBUG CV Batch 33/300 loss 2.374458 loss_att 190.885590 loss_ctc 5.010248 loss_rnnt 2.081592 history loss 3.587923 rank 3
2022-12-08 16:43:42,465 DEBUG CV Batch 33/300 loss 2.374458 loss_att 190.885590 loss_ctc 5.010248 loss_rnnt 2.081592 history loss 3.587923 rank 5
2022-12-08 16:43:42,583 DEBUG CV Batch 33/300 loss 2.374458 loss_att 190.885590 loss_ctc 5.010248 loss_rnnt 2.081592 history loss 3.587923 rank 1
2022-12-08 16:43:43,097 DEBUG CV Batch 33/300 loss 2.374458 loss_att 190.885590 loss_ctc 5.010248 loss_rnnt 2.081592 history loss 3.587923 rank 6
2022-12-08 16:43:43,157 DEBUG CV Batch 33/300 loss 2.374458 loss_att 190.885590 loss_ctc 5.010248 loss_rnnt 2.081592 history loss 3.587923 rank 2
2022-12-08 16:43:43,831 DEBUG CV Batch 33/300 loss 2.374458 loss_att 190.885590 loss_ctc 5.010248 loss_rnnt 2.081592 history loss 3.587923 rank 4
2022-12-08 16:43:44,070 DEBUG CV Batch 33/300 loss 2.374458 loss_att 190.885590 loss_ctc 5.010248 loss_rnnt 2.081592 history loss 3.587923 rank 0
2022-12-08 16:43:44,273 DEBUG CV Batch 33/300 loss 2.374458 loss_att 190.885590 loss_ctc 5.010248 loss_rnnt 2.081592 history loss 3.587923 rank 7
2022-12-08 16:43:53,917 DEBUG CV Batch 33/400 loss 5.609227 loss_att 826.186768 loss_ctc 16.773977 loss_rnnt 4.368699 history loss 4.410384 rank 5
2022-12-08 16:43:53,917 DEBUG CV Batch 33/400 loss 5.609227 loss_att 826.186768 loss_ctc 16.773977 loss_rnnt 4.368699 history loss 4.410384 rank 1
2022-12-08 16:43:54,080 DEBUG CV Batch 33/400 loss 5.609227 loss_att 826.186768 loss_ctc 16.773977 loss_rnnt 4.368699 history loss 4.410384 rank 3
2022-12-08 16:43:54,393 DEBUG CV Batch 33/400 loss 5.609227 loss_att 826.186768 loss_ctc 16.773977 loss_rnnt 4.368699 history loss 4.410384 rank 2
2022-12-08 16:43:54,588 DEBUG CV Batch 33/400 loss 5.609227 loss_att 826.186768 loss_ctc 16.773977 loss_rnnt 4.368699 history loss 4.410384 rank 6
2022-12-08 16:43:55,549 DEBUG CV Batch 33/400 loss 5.609227 loss_att 826.186768 loss_ctc 16.773977 loss_rnnt 4.368699 history loss 4.410384 rank 4
2022-12-08 16:43:56,032 DEBUG CV Batch 33/400 loss 5.609227 loss_att 826.186768 loss_ctc 16.773977 loss_rnnt 4.368699 history loss 4.410384 rank 0
2022-12-08 16:43:56,277 DEBUG CV Batch 33/400 loss 5.609227 loss_att 826.186768 loss_ctc 16.773977 loss_rnnt 4.368699 history loss 4.410384 rank 7
2022-12-08 16:44:04,748 DEBUG CV Batch 33/500 loss 4.107078 loss_att 266.656006 loss_ctc 6.645320 loss_rnnt 3.825051 history loss 5.010686 rank 1
2022-12-08 16:44:04,918 DEBUG CV Batch 33/500 loss 4.107078 loss_att 266.656006 loss_ctc 6.645320 loss_rnnt 3.825051 history loss 5.010686 rank 5
2022-12-08 16:44:04,966 DEBUG CV Batch 33/500 loss 4.107078 loss_att 266.656006 loss_ctc 6.645320 loss_rnnt 3.825051 history loss 5.010686 rank 2
2022-12-08 16:44:05,035 DEBUG CV Batch 33/500 loss 4.107078 loss_att 266.656006 loss_ctc 6.645320 loss_rnnt 3.825051 history loss 5.010686 rank 3
2022-12-08 16:44:05,553 DEBUG CV Batch 33/500 loss 4.107078 loss_att 266.656006 loss_ctc 6.645320 loss_rnnt 3.825051 history loss 5.010686 rank 6
2022-12-08 16:44:05,808 DEBUG CV Batch 33/500 loss 4.107078 loss_att 266.656006 loss_ctc 6.645320 loss_rnnt 3.825051 history loss 5.010686 rank 4
2022-12-08 16:44:06,515 DEBUG CV Batch 33/500 loss 4.107078 loss_att 266.656006 loss_ctc 6.645320 loss_rnnt 3.825051 history loss 5.010686 rank 0
2022-12-08 16:44:06,610 DEBUG CV Batch 33/500 loss 4.107078 loss_att 266.656006 loss_ctc 6.645320 loss_rnnt 3.825051 history loss 5.010686 rank 7
2022-12-08 16:44:17,421 DEBUG CV Batch 33/600 loss 6.567881 loss_att 104.306900 loss_ctc 9.991465 loss_rnnt 6.187483 history loss 5.848478 rank 5
2022-12-08 16:44:17,579 DEBUG CV Batch 33/600 loss 6.567881 loss_att 104.306900 loss_ctc 9.991465 loss_rnnt 6.187483 history loss 5.848478 rank 2
2022-12-08 16:44:17,583 DEBUG CV Batch 33/600 loss 6.567881 loss_att 104.306900 loss_ctc 9.991465 loss_rnnt 6.187483 history loss 5.848478 rank 1
2022-12-08 16:44:17,601 DEBUG CV Batch 33/600 loss 6.567881 loss_att 104.306900 loss_ctc 9.991465 loss_rnnt 6.187483 history loss 5.848478 rank 3
2022-12-08 16:44:17,708 DEBUG CV Batch 33/600 loss 6.567881 loss_att 104.306900 loss_ctc 9.991465 loss_rnnt 6.187483 history loss 5.848478 rank 4
2022-12-08 16:44:18,131 DEBUG CV Batch 33/600 loss 6.567881 loss_att 104.306900 loss_ctc 9.991465 loss_rnnt 6.187483 history loss 5.848478 rank 6
2022-12-08 16:44:18,701 DEBUG CV Batch 33/600 loss 6.567881 loss_att 104.306900 loss_ctc 9.991465 loss_rnnt 6.187483 history loss 5.848478 rank 0
2022-12-08 16:44:18,776 DEBUG CV Batch 33/600 loss 6.567881 loss_att 104.306900 loss_ctc 9.991465 loss_rnnt 6.187483 history loss 5.848478 rank 7
2022-12-08 16:44:29,679 DEBUG CV Batch 33/700 loss 4.461215 loss_att 707.029053 loss_ctc 13.962102 loss_rnnt 3.405561 history loss 6.403351 rank 3
2022-12-08 16:44:29,830 DEBUG CV Batch 33/700 loss 4.461215 loss_att 707.029053 loss_ctc 13.962102 loss_rnnt 3.405561 history loss 6.403351 rank 1
2022-12-08 16:44:29,881 DEBUG CV Batch 33/700 loss 4.461215 loss_att 707.029053 loss_ctc 13.962102 loss_rnnt 3.405561 history loss 6.403351 rank 5
2022-12-08 16:44:29,975 DEBUG CV Batch 33/700 loss 4.461215 loss_att 707.029053 loss_ctc 13.962102 loss_rnnt 3.405561 history loss 6.403351 rank 2
2022-12-08 16:44:30,100 DEBUG CV Batch 33/700 loss 4.461215 loss_att 707.029053 loss_ctc 13.962102 loss_rnnt 3.405561 history loss 6.403351 rank 4
2022-12-08 16:44:30,257 DEBUG CV Batch 33/700 loss 4.461215 loss_att 707.029053 loss_ctc 13.962102 loss_rnnt 3.405561 history loss 6.403351 rank 0
2022-12-08 16:44:30,323 DEBUG CV Batch 33/700 loss 4.461215 loss_att 707.029053 loss_ctc 13.962102 loss_rnnt 3.405561 history loss 6.403351 rank 6
2022-12-08 16:44:30,329 DEBUG CV Batch 33/700 loss 4.461215 loss_att 707.029053 loss_ctc 13.962102 loss_rnnt 3.405561 history loss 6.403351 rank 7
2022-12-08 16:44:41,771 DEBUG CV Batch 33/800 loss 6.375031 loss_att 263.401337 loss_ctc 17.648998 loss_rnnt 5.122369 history loss 5.941670 rank 2
2022-12-08 16:44:41,793 DEBUG CV Batch 33/800 loss 6.375031 loss_att 263.401337 loss_ctc 17.648998 loss_rnnt 5.122369 history loss 5.941670 rank 1
2022-12-08 16:44:41,818 DEBUG CV Batch 33/800 loss 6.375031 loss_att 263.401337 loss_ctc 17.648998 loss_rnnt 5.122369 history loss 5.941670 rank 3
2022-12-08 16:44:41,869 DEBUG CV Batch 33/800 loss 6.375031 loss_att 263.401337 loss_ctc 17.648998 loss_rnnt 5.122369 history loss 5.941670 rank 4
2022-12-08 16:44:42,112 DEBUG CV Batch 33/800 loss 6.375031 loss_att 263.401337 loss_ctc 17.648998 loss_rnnt 5.122369 history loss 5.941670 rank 5
2022-12-08 16:44:42,130 DEBUG CV Batch 33/800 loss 6.375031 loss_att 263.401337 loss_ctc 17.648998 loss_rnnt 5.122369 history loss 5.941670 rank 7
2022-12-08 16:44:42,244 DEBUG CV Batch 33/800 loss 6.375031 loss_att 263.401337 loss_ctc 17.648998 loss_rnnt 5.122369 history loss 5.941670 rank 0
2022-12-08 16:44:42,529 DEBUG CV Batch 33/800 loss 6.375031 loss_att 263.401337 loss_ctc 17.648998 loss_rnnt 5.122369 history loss 5.941670 rank 6
2022-12-08 16:44:55,099 DEBUG CV Batch 33/900 loss 11.495718 loss_att 550.848511 loss_ctc 19.812977 loss_rnnt 10.571579 history loss 5.778250 rank 1
2022-12-08 16:44:55,443 DEBUG CV Batch 33/900 loss 11.495718 loss_att 550.848511 loss_ctc 19.812977 loss_rnnt 10.571579 history loss 5.778250 rank 3
2022-12-08 16:44:55,579 DEBUG CV Batch 33/900 loss 11.495718 loss_att 550.848511 loss_ctc 19.812977 loss_rnnt 10.571579 history loss 5.778250 rank 4
2022-12-08 16:44:55,635 DEBUG CV Batch 33/900 loss 11.495718 loss_att 550.848511 loss_ctc 19.812977 loss_rnnt 10.571579 history loss 5.778250 rank 2
2022-12-08 16:44:55,720 DEBUG CV Batch 33/900 loss 11.495718 loss_att 550.848511 loss_ctc 19.812977 loss_rnnt 10.571579 history loss 5.778250 rank 5
2022-12-08 16:44:56,008 DEBUG CV Batch 33/900 loss 11.495718 loss_att 550.848511 loss_ctc 19.812977 loss_rnnt 10.571579 history loss 5.778250 rank 7
2022-12-08 16:44:56,142 DEBUG CV Batch 33/900 loss 11.495718 loss_att 550.848511 loss_ctc 19.812977 loss_rnnt 10.571579 history loss 5.778250 rank 6
2022-12-08 16:44:56,643 DEBUG CV Batch 33/900 loss 11.495718 loss_att 550.848511 loss_ctc 19.812977 loss_rnnt 10.571579 history loss 5.778250 rank 0
2022-12-08 16:45:06,424 DEBUG CV Batch 33/1000 loss 2.838519 loss_att 176.484390 loss_ctc 5.055309 loss_rnnt 2.592209 history loss 5.578104 rank 1
2022-12-08 16:45:07,077 DEBUG CV Batch 33/1000 loss 2.838519 loss_att 176.484390 loss_ctc 5.055309 loss_rnnt 2.592209 history loss 5.578104 rank 5
2022-12-08 16:45:07,082 DEBUG CV Batch 33/1000 loss 2.838519 loss_att 176.484390 loss_ctc 5.055309 loss_rnnt 2.592209 history loss 5.578104 rank 3
2022-12-08 16:45:07,141 DEBUG CV Batch 33/1000 loss 2.838519 loss_att 176.484390 loss_ctc 5.055309 loss_rnnt 2.592209 history loss 5.578104 rank 2
2022-12-08 16:45:07,502 DEBUG CV Batch 33/1000 loss 2.838519 loss_att 176.484390 loss_ctc 5.055309 loss_rnnt 2.592209 history loss 5.578104 rank 6
2022-12-08 16:45:07,564 DEBUG CV Batch 33/1000 loss 2.838519 loss_att 176.484390 loss_ctc 5.055309 loss_rnnt 2.592209 history loss 5.578104 rank 4
2022-12-08 16:45:08,311 DEBUG CV Batch 33/1000 loss 2.838519 loss_att 176.484390 loss_ctc 5.055309 loss_rnnt 2.592209 history loss 5.578104 rank 7
2022-12-08 16:45:09,031 DEBUG CV Batch 33/1000 loss 2.838519 loss_att 176.484390 loss_ctc 5.055309 loss_rnnt 2.592209 history loss 5.578104 rank 0
2022-12-08 16:45:17,721 DEBUG CV Batch 33/1100 loss 4.162347 loss_att 60.693756 loss_ctc 7.795138 loss_rnnt 3.758703 history loss 5.547870 rank 1
2022-12-08 16:45:18,183 DEBUG CV Batch 33/1100 loss 4.162347 loss_att 60.693756 loss_ctc 7.795138 loss_rnnt 3.758703 history loss 5.547870 rank 3
2022-12-08 16:45:18,307 DEBUG CV Batch 33/1100 loss 4.162347 loss_att 60.693756 loss_ctc 7.795138 loss_rnnt 3.758703 history loss 5.547870 rank 2
2022-12-08 16:45:18,861 DEBUG CV Batch 33/1100 loss 4.162347 loss_att 60.693756 loss_ctc 7.795138 loss_rnnt 3.758703 history loss 5.547870 rank 5
2022-12-08 16:45:19,060 DEBUG CV Batch 33/1100 loss 4.162347 loss_att 60.693756 loss_ctc 7.795138 loss_rnnt 3.758703 history loss 5.547870 rank 4
2022-12-08 16:45:19,441 DEBUG CV Batch 33/1100 loss 4.162347 loss_att 60.693756 loss_ctc 7.795138 loss_rnnt 3.758703 history loss 5.547870 rank 6
2022-12-08 16:45:20,102 DEBUG CV Batch 33/1100 loss 4.162347 loss_att 60.693756 loss_ctc 7.795138 loss_rnnt 3.758703 history loss 5.547870 rank 7
2022-12-08 16:45:20,868 DEBUG CV Batch 33/1100 loss 4.162347 loss_att 60.693756 loss_ctc 7.795138 loss_rnnt 3.758703 history loss 5.547870 rank 0
2022-12-08 16:45:28,402 DEBUG CV Batch 33/1200 loss 6.362620 loss_att 280.456604 loss_ctc 8.826121 loss_rnnt 6.088898 history loss 5.820949 rank 1
2022-12-08 16:45:28,482 DEBUG CV Batch 33/1200 loss 6.362620 loss_att 280.456604 loss_ctc 8.826121 loss_rnnt 6.088898 history loss 5.820949 rank 2
2022-12-08 16:45:28,743 DEBUG CV Batch 33/1200 loss 6.362620 loss_att 280.456604 loss_ctc 8.826121 loss_rnnt 6.088898 history loss 5.820949 rank 3
2022-12-08 16:45:29,242 DEBUG CV Batch 33/1200 loss 6.362620 loss_att 280.456604 loss_ctc 8.826121 loss_rnnt 6.088898 history loss 5.820949 rank 4
2022-12-08 16:45:29,729 DEBUG CV Batch 33/1200 loss 6.362620 loss_att 280.456604 loss_ctc 8.826121 loss_rnnt 6.088898 history loss 5.820949 rank 5
2022-12-08 16:45:30,276 DEBUG CV Batch 33/1200 loss 6.362620 loss_att 280.456604 loss_ctc 8.826121 loss_rnnt 6.088898 history loss 5.820949 rank 6
2022-12-08 16:45:30,443 DEBUG CV Batch 33/1200 loss 6.362620 loss_att 280.456604 loss_ctc 8.826121 loss_rnnt 6.088898 history loss 5.820949 rank 7
2022-12-08 16:45:31,355 DEBUG CV Batch 33/1200 loss 6.362620 loss_att 280.456604 loss_ctc 8.826121 loss_rnnt 6.088898 history loss 5.820949 rank 0
2022-12-08 16:45:40,251 DEBUG CV Batch 33/1300 loss 4.822495 loss_att 105.974998 loss_ctc 8.427385 loss_rnnt 4.421952 history loss 6.099903 rank 2
2022-12-08 16:45:40,354 DEBUG CV Batch 33/1300 loss 4.822495 loss_att 105.974998 loss_ctc 8.427385 loss_rnnt 4.421952 history loss 6.099903 rank 1
2022-12-08 16:45:40,449 DEBUG CV Batch 33/1300 loss 4.822495 loss_att 105.974998 loss_ctc 8.427385 loss_rnnt 4.421952 history loss 6.099903 rank 3
2022-12-08 16:45:40,884 DEBUG CV Batch 33/1300 loss 4.822495 loss_att 105.974998 loss_ctc 8.427385 loss_rnnt 4.421952 history loss 6.099903 rank 4
2022-12-08 16:45:41,488 DEBUG CV Batch 33/1300 loss 4.822495 loss_att 105.974998 loss_ctc 8.427385 loss_rnnt 4.421952 history loss 6.099903 rank 5
2022-12-08 16:45:42,045 DEBUG CV Batch 33/1300 loss 4.822495 loss_att 105.974998 loss_ctc 8.427385 loss_rnnt 4.421952 history loss 6.099903 rank 6
2022-12-08 16:45:42,321 DEBUG CV Batch 33/1300 loss 4.822495 loss_att 105.974998 loss_ctc 8.427385 loss_rnnt 4.421952 history loss 6.099903 rank 7
2022-12-08 16:45:43,476 DEBUG CV Batch 33/1300 loss 4.822495 loss_att 105.974998 loss_ctc 8.427385 loss_rnnt 4.421952 history loss 6.099903 rank 0
2022-12-08 16:45:52,277 DEBUG CV Batch 33/1400 loss 5.100409 loss_att 562.087830 loss_ctc 8.138067 loss_rnnt 4.762891 history loss 6.375770 rank 4
2022-12-08 16:45:52,549 DEBUG CV Batch 33/1400 loss 5.100409 loss_att 562.087830 loss_ctc 8.138067 loss_rnnt 4.762891 history loss 6.375770 rank 1
2022-12-08 16:45:52,616 DEBUG CV Batch 33/1400 loss 5.100409 loss_att 562.087830 loss_ctc 8.138067 loss_rnnt 4.762891 history loss 6.375770 rank 2
2022-12-08 16:45:52,948 DEBUG CV Batch 33/1400 loss 5.100409 loss_att 562.087830 loss_ctc 8.138067 loss_rnnt 4.762891 history loss 6.375770 rank 3
2022-12-08 16:45:53,349 DEBUG CV Batch 33/1400 loss 5.100409 loss_att 562.087830 loss_ctc 8.138067 loss_rnnt 4.762891 history loss 6.375770 rank 7
2022-12-08 16:45:53,942 DEBUG CV Batch 33/1400 loss 5.100409 loss_att 562.087830 loss_ctc 8.138067 loss_rnnt 4.762891 history loss 6.375770 rank 5
2022-12-08 16:45:54,551 DEBUG CV Batch 33/1400 loss 5.100409 loss_att 562.087830 loss_ctc 8.138067 loss_rnnt 4.762891 history loss 6.375770 rank 0
2022-12-08 16:45:54,587 DEBUG CV Batch 33/1400 loss 5.100409 loss_att 562.087830 loss_ctc 8.138067 loss_rnnt 4.762891 history loss 6.375770 rank 6
2022-12-08 16:46:04,490 DEBUG CV Batch 33/1500 loss 7.484809 loss_att 275.484436 loss_ctc 8.309870 loss_rnnt 7.393136 history loss 6.261570 rank 4
2022-12-08 16:46:04,751 DEBUG CV Batch 33/1500 loss 7.484809 loss_att 275.484436 loss_ctc 8.309870 loss_rnnt 7.393136 history loss 6.261570 rank 1
2022-12-08 16:46:04,978 DEBUG CV Batch 33/1500 loss 7.484809 loss_att 275.484436 loss_ctc 8.309870 loss_rnnt 7.393136 history loss 6.261570 rank 7
2022-12-08 16:46:05,064 DEBUG CV Batch 33/1500 loss 7.484809 loss_att 275.484436 loss_ctc 8.309870 loss_rnnt 7.393136 history loss 6.261570 rank 2
2022-12-08 16:46:05,249 DEBUG CV Batch 33/1500 loss 7.484809 loss_att 275.484436 loss_ctc 8.309870 loss_rnnt 7.393136 history loss 6.261570 rank 3
2022-12-08 16:46:06,019 DEBUG CV Batch 33/1500 loss 7.484809 loss_att 275.484436 loss_ctc 8.309870 loss_rnnt 7.393136 history loss 6.261570 rank 0
2022-12-08 16:46:06,483 DEBUG CV Batch 33/1500 loss 7.484809 loss_att 275.484436 loss_ctc 8.309870 loss_rnnt 7.393136 history loss 6.261570 rank 5
2022-12-08 16:46:07,178 DEBUG CV Batch 33/1500 loss 7.484809 loss_att 275.484436 loss_ctc 8.309870 loss_rnnt 7.393136 history loss 6.261570 rank 6
2022-12-08 16:46:17,849 DEBUG CV Batch 33/1600 loss 8.460008 loss_att 593.905396 loss_ctc 15.009188 loss_rnnt 7.732321 history loss 6.228254 rank 4
2022-12-08 16:46:17,938 DEBUG CV Batch 33/1600 loss 8.460008 loss_att 593.905396 loss_ctc 15.009188 loss_rnnt 7.732321 history loss 6.228254 rank 1
2022-12-08 16:46:18,338 DEBUG CV Batch 33/1600 loss 8.460008 loss_att 593.905396 loss_ctc 15.009188 loss_rnnt 7.732321 history loss 6.228254 rank 2
2022-12-08 16:46:18,585 DEBUG CV Batch 33/1600 loss 8.460008 loss_att 593.905396 loss_ctc 15.009188 loss_rnnt 7.732321 history loss 6.228254 rank 7
2022-12-08 16:46:18,702 DEBUG CV Batch 33/1600 loss 8.460008 loss_att 593.905396 loss_ctc 15.009188 loss_rnnt 7.732321 history loss 6.228254 rank 3
2022-12-08 16:46:19,529 DEBUG CV Batch 33/1600 loss 8.460008 loss_att 593.905396 loss_ctc 15.009188 loss_rnnt 7.732321 history loss 6.228254 rank 0
2022-12-08 16:46:19,768 DEBUG CV Batch 33/1600 loss 8.460008 loss_att 593.905396 loss_ctc 15.009188 loss_rnnt 7.732321 history loss 6.228254 rank 5
2022-12-08 16:46:20,601 DEBUG CV Batch 33/1600 loss 8.460008 loss_att 593.905396 loss_ctc 15.009188 loss_rnnt 7.732321 history loss 6.228254 rank 6
2022-12-08 16:46:29,475 DEBUG CV Batch 33/1700 loss 6.994079 loss_att 210.842834 loss_ctc 15.538250 loss_rnnt 6.044726 history loss 6.166168 rank 1
2022-12-08 16:46:29,960 DEBUG CV Batch 33/1700 loss 6.994079 loss_att 210.842834 loss_ctc 15.538250 loss_rnnt 6.044726 history loss 6.166168 rank 4
2022-12-08 16:46:30,233 DEBUG CV Batch 33/1700 loss 6.994079 loss_att 210.842834 loss_ctc 15.538250 loss_rnnt 6.044726 history loss 6.166168 rank 2
2022-12-08 16:46:30,492 DEBUG CV Batch 33/1700 loss 6.994079 loss_att 210.842834 loss_ctc 15.538250 loss_rnnt 6.044726 history loss 6.166168 rank 3
2022-12-08 16:46:30,920 DEBUG CV Batch 33/1700 loss 6.994079 loss_att 210.842834 loss_ctc 15.538250 loss_rnnt 6.044726 history loss 6.166168 rank 7
2022-12-08 16:46:31,552 DEBUG CV Batch 33/1700 loss 6.994079 loss_att 210.842834 loss_ctc 15.538250 loss_rnnt 6.044726 history loss 6.166168 rank 5
2022-12-08 16:46:32,078 DEBUG CV Batch 33/1700 loss 6.994079 loss_att 210.842834 loss_ctc 15.538250 loss_rnnt 6.044726 history loss 6.166168 rank 0
2022-12-08 16:46:32,401 DEBUG CV Batch 33/1700 loss 6.994079 loss_att 210.842834 loss_ctc 15.538250 loss_rnnt 6.044726 history loss 6.166168 rank 6
2022-12-08 16:46:38,062 INFO Epoch 33 CV info cv_loss 6.147429031366893
2022-12-08 16:46:38,063 INFO Epoch 34 TRAIN info lr 0.0002378674582638209
2022-12-08 16:46:38,064 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 16:46:38,868 INFO Epoch 33 CV info cv_loss 6.147429031366893
2022-12-08 16:46:38,869 INFO Epoch 34 TRAIN info lr 0.00023784000714317655
2022-12-08 16:46:38,873 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 16:46:39,048 INFO Epoch 33 CV info cv_loss 6.147429031366893
2022-12-08 16:46:39,048 INFO Epoch 34 TRAIN info lr 0.00023786395906305689
2022-12-08 16:46:39,050 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 16:46:39,611 INFO Epoch 33 CV info cv_loss 6.147429031366893
2022-12-08 16:46:39,611 INFO Epoch 34 TRAIN info lr 0.00023785292413364665
2022-12-08 16:46:39,613 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 16:46:39,890 INFO Epoch 33 CV info cv_loss 6.147429031366893
2022-12-08 16:46:39,890 INFO Epoch 34 TRAIN info lr 0.0002378421598287807
2022-12-08 16:46:39,892 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 16:46:40,377 INFO Epoch 33 CV info cv_loss 6.147429031366893
2022-12-08 16:46:40,377 INFO Epoch 34 TRAIN info lr 0.00023787338034001406
2022-12-08 16:46:40,381 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 16:46:41,154 INFO Epoch 33 CV info cv_loss 6.147429031366893
2022-12-08 16:46:41,154 INFO Epoch 34 TRAIN info lr 0.0002378720343747667
2022-12-08 16:46:41,158 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 16:46:41,168 INFO Epoch 33 CV info cv_loss 6.147429031366893
2022-12-08 16:46:41,168 INFO Checkpoint: save to checkpoint exp/1204_encoder_bias_nobi_noatt/33.pt
2022-12-08 16:46:41,694 INFO Epoch 34 TRAIN info lr 0.0002378418907398836
2022-12-08 16:46:41,698 INFO using accumulate grad, new batch size is 1 times larger than before
2022-12-08 16:47:44,311 DEBUG TRAIN Batch 34/0 loss 6.027466 loss_att 61.563992 loss_ctc 9.225557 loss_rnnt 5.672122 lr 0.00023784 rank 4
2022-12-08 16:47:44,315 DEBUG TRAIN Batch 34/0 loss 6.132228 loss_att 70.172379 loss_ctc 9.262371 loss_rnnt 5.784434 lr 0.00023784 rank 0
2022-12-08 16:47:44,317 DEBUG TRAIN Batch 34/0 loss 7.524069 loss_att 81.064156 loss_ctc 12.291362 loss_rnnt 6.994370 lr 0.00023784 rank 7
2022-12-08 16:47:44,319 DEBUG TRAIN Batch 34/0 loss 9.275257 loss_att 63.481236 loss_ctc 11.388192 loss_rnnt 9.040487 lr 0.00023785 rank 3
2022-12-08 16:47:44,321 DEBUG TRAIN Batch 34/0 loss 8.853819 loss_att 75.023262 loss_ctc 14.196109 loss_rnnt 8.260232 lr 0.00023787 rank 5
2022-12-08 16:47:44,364 DEBUG TRAIN Batch 34/0 loss 10.490490 loss_att 69.757866 loss_ctc 14.429491 loss_rnnt 10.052823 lr 0.00023786 rank 2
2022-12-08 16:47:44,370 DEBUG TRAIN Batch 34/0 loss 7.847315 loss_att 78.777405 loss_ctc 12.571376 loss_rnnt 7.322420 lr 0.00023787 rank 1
2022-12-08 16:47:44,381 DEBUG TRAIN Batch 34/0 loss 6.527219 loss_att 65.928299 loss_ctc 8.690243 loss_rnnt 6.286883 lr 0.00023787 rank 6
2022-12-08 16:48:46,593 DEBUG TRAIN Batch 34/100 loss 3.045745 loss_att 353.390961 loss_ctc 8.329089 loss_rnnt 2.458707 lr 0.00023781 rank 7
2022-12-08 16:48:46,597 DEBUG TRAIN Batch 34/100 loss 6.795798 loss_att 452.870941 loss_ctc 13.483958 loss_rnnt 6.052670 lr 0.00023784 rank 1
2022-12-08 16:48:46,600 DEBUG TRAIN Batch 34/100 loss 4.470394 loss_att 356.758881 loss_ctc 10.757534 loss_rnnt 3.771823 lr 0.00023785 rank 5
2022-12-08 16:48:46,599 DEBUG TRAIN Batch 34/100 loss 5.636480 loss_att 453.354584 loss_ctc 10.066074 loss_rnnt 5.144303 lr 0.00023781 rank 4
2022-12-08 16:48:46,600 DEBUG TRAIN Batch 34/100 loss 2.281848 loss_att 399.740906 loss_ctc 8.128252 loss_rnnt 1.632248 lr 0.00023784 rank 2
2022-12-08 16:48:46,600 DEBUG TRAIN Batch 34/100 loss 1.353891 loss_att 387.467133 loss_ctc 2.502773 loss_rnnt 1.226238 lr 0.00023784 rank 6
2022-12-08 16:48:46,602 DEBUG TRAIN Batch 34/100 loss 15.028737 loss_att 391.735046 loss_ctc 32.314377 loss_rnnt 13.108110 lr 0.00023781 rank 0
2022-12-08 16:48:46,641 DEBUG TRAIN Batch 34/100 loss 8.906488 loss_att 398.918915 loss_ctc 16.521702 loss_rnnt 8.060354 lr 0.00023783 rank 3
2022-12-08 16:49:49,544 DEBUG TRAIN Batch 34/200 loss 5.185653 loss_att 308.919434 loss_ctc 9.403047 loss_rnnt 4.717053 lr 0.00023779 rank 4
2022-12-08 16:49:49,547 DEBUG TRAIN Batch 34/200 loss 5.805505 loss_att 405.601746 loss_ctc 13.145061 loss_rnnt 4.989999 lr 0.00023779 rank 0
2022-12-08 16:49:49,547 DEBUG TRAIN Batch 34/200 loss 8.661611 loss_att 330.443817 loss_ctc 19.112652 loss_rnnt 7.500384 lr 0.00023779 rank 7
2022-12-08 16:49:49,548 DEBUG TRAIN Batch 34/200 loss 10.293237 loss_att 393.036224 loss_ctc 13.985100 loss_rnnt 9.883030 lr 0.00023781 rank 2
2022-12-08 16:49:49,551 DEBUG TRAIN Batch 34/200 loss 5.786127 loss_att 353.418945 loss_ctc 11.749358 loss_rnnt 5.123546 lr 0.00023782 rank 6
2022-12-08 16:49:49,551 DEBUG TRAIN Batch 34/200 loss 11.489837 loss_att 377.966309 loss_ctc 20.438402 loss_rnnt 10.495552 lr 0.00023782 rank 5
2022-12-08 16:49:49,554 DEBUG TRAIN Batch 34/200 loss 7.828074 loss_att 336.711975 loss_ctc 12.406573 loss_rnnt 7.319352 lr 0.00023781 rank 1
2022-12-08 16:49:49,588 DEBUG TRAIN Batch 34/200 loss 1.238098 loss_att 415.594666 loss_ctc 4.165527 loss_rnnt 0.912828 lr 0.00023780 rank 3
2022-12-08 16:50:53,442 DEBUG TRAIN Batch 34/300 loss 13.768047 loss_att 420.743469 loss_ctc 26.091885 loss_rnnt 12.398733 lr 0.00023778 rank 2
2022-12-08 16:50:53,442 DEBUG TRAIN Batch 34/300 loss 6.063776 loss_att 346.653748 loss_ctc 14.381281 loss_rnnt 5.139608 lr 0.00023777 rank 3
2022-12-08 16:50:53,446 DEBUG TRAIN Batch 34/300 loss 8.823835 loss_att 417.358765 loss_ctc 18.665997 loss_rnnt 7.730262 lr 0.00023779 rank 1
2022-12-08 16:50:53,451 DEBUG TRAIN Batch 34/300 loss 5.579903 loss_att 358.934937 loss_ctc 11.156271 loss_rnnt 4.960306 lr 0.00023776 rank 4
2022-12-08 16:50:53,454 DEBUG TRAIN Batch 34/300 loss 2.616786 loss_att 332.332764 loss_ctc 5.419981 loss_rnnt 2.305320 lr 0.00023776 rank 7
2022-12-08 16:50:53,459 DEBUG TRAIN Batch 34/300 loss 3.132264 loss_att 332.002869 loss_ctc 6.914173 loss_rnnt 2.712052 lr 0.00023779 rank 5
2022-12-08 16:50:53,462 DEBUG TRAIN Batch 34/300 loss 10.303616 loss_att 403.735748 loss_ctc 18.990894 loss_rnnt 9.338362 lr 0.00023776 rank 0
2022-12-08 16:50:53,472 DEBUG TRAIN Batch 34/300 loss 7.432538 loss_att 367.124725 loss_ctc 15.762825 loss_rnnt 6.506950 lr 0.00023779 rank 6
2022-12-08 16:52:04,030 DEBUG TRAIN Batch 34/400 loss 14.105316 loss_att 437.677490 loss_ctc 20.703018 loss_rnnt 13.372238 lr 0.00023773 rank 4
2022-12-08 16:52:04,049 DEBUG TRAIN Batch 34/400 loss 3.584033 loss_att 348.573792 loss_ctc 12.849386 loss_rnnt 2.554549 lr 0.00023775 rank 3
2022-12-08 16:52:04,049 DEBUG TRAIN Batch 34/400 loss 8.276493 loss_att 371.807861 loss_ctc 20.080566 loss_rnnt 6.964930 lr 0.00023773 rank 7
2022-12-08 16:52:04,052 DEBUG TRAIN Batch 34/400 loss 2.370281 loss_att 319.605011 loss_ctc 8.005965 loss_rnnt 1.744094 lr 0.00023776 rank 6
2022-12-08 16:52:04,054 DEBUG TRAIN Batch 34/400 loss 6.847945 loss_att 278.129456 loss_ctc 16.331947 loss_rnnt 5.794167 lr 0.00023773 rank 0
2022-12-08 16:52:04,056 DEBUG TRAIN Batch 34/400 loss 5.426063 loss_att 322.915833 loss_ctc 10.006086 loss_rnnt 4.917171 lr 0.00023776 rank 1
2022-12-08 16:52:04,057 DEBUG TRAIN Batch 34/400 loss 10.352722 loss_att 443.658264 loss_ctc 24.168062 loss_rnnt 8.817684 lr 0.00023776 rank 2
2022-12-08 16:52:04,094 DEBUG TRAIN Batch 34/400 loss 5.964800 loss_att 380.409302 loss_ctc 12.667957 loss_rnnt 5.220005 lr 0.00023777 rank 5
2022-12-08 16:53:07,363 DEBUG TRAIN Batch 34/500 loss 7.221906 loss_att 346.166473 loss_ctc 13.293455 loss_rnnt 6.547290 lr 0.00023771 rank 4
2022-12-08 16:53:07,367 DEBUG TRAIN Batch 34/500 loss 4.467317 loss_att 412.561676 loss_ctc 12.087886 loss_rnnt 3.620587 lr 0.00023772 rank 3
2022-12-08 16:53:07,368 DEBUG TRAIN Batch 34/500 loss 7.873793 loss_att 334.763123 loss_ctc 16.486723 loss_rnnt 6.916800 lr 0.00023774 rank 6
2022-12-08 16:53:07,368 DEBUG TRAIN Batch 34/500 loss 3.369177 loss_att 329.595703 loss_ctc 9.348565 loss_rnnt 2.704801 lr 0.00023771 rank 7
2022-12-08 16:53:07,368 DEBUG TRAIN Batch 34/500 loss 4.597373 loss_att 334.631805 loss_ctc 11.612850 loss_rnnt 3.817875 lr 0.00023774 rank 5
2022-12-08 16:53:07,370 DEBUG TRAIN Batch 34/500 loss 6.480700 loss_att 290.812225 loss_ctc 14.418001 loss_rnnt 5.598777 lr 0.00023771 rank 0
2022-12-08 16:53:07,370 DEBUG TRAIN Batch 34/500 loss 3.959246 loss_att 285.614502 loss_ctc 8.976471 loss_rnnt 3.401777 lr 0.00023773 rank 1
2022-12-08 16:53:07,371 DEBUG TRAIN Batch 34/500 loss 4.934108 loss_att 319.866974 loss_ctc 9.589467 loss_rnnt 4.416846 lr 0.00023773 rank 2
2022-12-08 16:54:11,576 DEBUG TRAIN Batch 34/600 loss 5.761343 loss_att 168.373322 loss_ctc 10.552622 loss_rnnt 5.228979 lr 0.00023768 rank 7
2022-12-08 16:54:11,578 DEBUG TRAIN Batch 34/600 loss 11.476256 loss_att 256.868591 loss_ctc 16.900579 loss_rnnt 10.873554 lr 0.00023768 rank 4
2022-12-08 16:54:11,578 DEBUG TRAIN Batch 34/600 loss 8.019404 loss_att 162.668442 loss_ctc 13.983127 loss_rnnt 7.356769 lr 0.00023771 rank 6
2022-12-08 16:54:11,585 DEBUG TRAIN Batch 34/600 loss 7.247808 loss_att 64.415115 loss_ctc 13.132736 loss_rnnt 6.593927 lr 0.00023768 rank 0
2022-12-08 16:54:11,587 DEBUG TRAIN Batch 34/600 loss 10.791925 loss_att 231.791061 loss_ctc 22.081417 loss_rnnt 9.537537 lr 0.00023771 rank 5
2022-12-08 16:54:11,598 DEBUG TRAIN Batch 34/600 loss 8.726450 loss_att 255.640549 loss_ctc 13.773242 loss_rnnt 8.165695 lr 0.00023769 rank 3
2022-12-08 16:54:11,618 DEBUG TRAIN Batch 34/600 loss 6.018873 loss_att 183.302383 loss_ctc 8.392686 loss_rnnt 5.755116 lr 0.00023771 rank 1
2022-12-08 16:54:11,620 DEBUG TRAIN Batch 34/600 loss 12.339586 loss_att 131.770340 loss_ctc 21.461458 loss_rnnt 11.326045 lr 0.00023770 rank 2
2022-12-08 16:55:17,155 DEBUG TRAIN Batch 34/700 loss 2.456990 loss_att 374.583435 loss_ctc 9.376341 loss_rnnt 1.688173 lr 0.00023768 rank 5
2022-12-08 16:55:17,163 DEBUG TRAIN Batch 34/700 loss 6.346671 loss_att 397.681976 loss_ctc 16.310993 loss_rnnt 5.239524 lr 0.00023765 rank 4
2022-12-08 16:55:17,164 DEBUG TRAIN Batch 34/700 loss 6.099639 loss_att 393.777832 loss_ctc 9.612443 loss_rnnt 5.709328 lr 0.00023766 rank 3
2022-12-08 16:55:17,165 DEBUG TRAIN Batch 34/700 loss 12.081119 loss_att 358.424530 loss_ctc 23.946226 loss_rnnt 10.762774 lr 0.00023765 rank 7
2022-12-08 16:55:17,169 DEBUG TRAIN Batch 34/700 loss 4.684861 loss_att 374.063812 loss_ctc 12.358101 loss_rnnt 3.832279 lr 0.00023765 rank 0
2022-12-08 16:55:17,189 DEBUG TRAIN Batch 34/700 loss 6.907271 loss_att 409.572266 loss_ctc 8.661096 loss_rnnt 6.712402 lr 0.00023768 rank 1
2022-12-08 16:55:17,193 DEBUG TRAIN Batch 34/700 loss 16.054831 loss_att 458.852875 loss_ctc 28.424398 loss_rnnt 14.680435 lr 0.00023768 rank 2
2022-12-08 16:55:17,208 DEBUG TRAIN Batch 34/700 loss 2.361463 loss_att 369.508392 loss_ctc 3.869293 loss_rnnt 2.193927 lr 0.00023768 rank 6
2022-12-08 16:56:26,347 DEBUG TRAIN Batch 34/800 loss 4.809419 loss_att 455.568329 loss_ctc 12.060478 loss_rnnt 4.003746 lr 0.00023762 rank 4
2022-12-08 16:56:26,351 DEBUG TRAIN Batch 34/800 loss 8.096541 loss_att 368.759857 loss_ctc 12.419989 loss_rnnt 7.616159 lr 0.00023766 rank 6
2022-12-08 16:56:26,351 DEBUG TRAIN Batch 34/800 loss 3.051630 loss_att 392.997894 loss_ctc 5.714993 loss_rnnt 2.755701 lr 0.00023763 rank 7
2022-12-08 16:56:26,352 DEBUG TRAIN Batch 34/800 loss 5.200399 loss_att 317.749084 loss_ctc 6.701723 loss_rnnt 5.033586 lr 0.00023763 rank 0
2022-12-08 16:56:26,353 DEBUG TRAIN Batch 34/800 loss 5.484534 loss_att 361.295593 loss_ctc 11.231628 loss_rnnt 4.845969 lr 0.00023765 rank 2
2022-12-08 16:56:26,355 DEBUG TRAIN Batch 34/800 loss 8.434981 loss_att 407.481659 loss_ctc 13.353333 loss_rnnt 7.888498 lr 0.00023765 rank 1
2022-12-08 16:56:26,357 DEBUG TRAIN Batch 34/800 loss 8.334869 loss_att 425.624023 loss_ctc 20.205526 loss_rnnt 7.015908 lr 0.00023766 rank 5
2022-12-08 16:56:26,358 DEBUG TRAIN Batch 34/800 loss 5.300254 loss_att 399.061371 loss_ctc 13.012308 loss_rnnt 4.443359 lr 0.00023764 rank 3
2022-12-08 16:57:30,079 DEBUG TRAIN Batch 34/900 loss 4.764298 loss_att 361.209595 loss_ctc 8.880642 loss_rnnt 4.306927 lr 0.00023763 rank 6
2022-12-08 16:57:30,082 DEBUG TRAIN Batch 34/900 loss 3.478419 loss_att 344.119141 loss_ctc 6.583363 loss_rnnt 3.133426 lr 0.00023760 rank 4
2022-12-08 16:57:30,083 DEBUG TRAIN Batch 34/900 loss 8.679450 loss_att 362.058655 loss_ctc 17.924988 loss_rnnt 7.652168 lr 0.00023762 rank 2
2022-12-08 16:57:30,083 DEBUG TRAIN Batch 34/900 loss 9.157984 loss_att 402.404358 loss_ctc 18.312948 loss_rnnt 8.140766 lr 0.00023760 rank 7
2022-12-08 16:57:30,085 DEBUG TRAIN Batch 34/900 loss 4.543068 loss_att 325.204834 loss_ctc 8.067591 loss_rnnt 4.151455 lr 0.00023761 rank 3
2022-12-08 16:57:30,090 DEBUG TRAIN Batch 34/900 loss 9.181691 loss_att 373.375031 loss_ctc 14.001603 loss_rnnt 8.646146 lr 0.00023760 rank 0
2022-12-08 16:57:30,090 DEBUG TRAIN Batch 34/900 loss 7.519218 loss_att 362.800140 loss_ctc 14.963687 loss_rnnt 6.692055 lr 0.00023763 rank 1
2022-12-08 16:57:30,131 DEBUG TRAIN Batch 34/900 loss 6.209088 loss_att 449.248962 loss_ctc 14.617204 loss_rnnt 5.274853 lr 0.00023763 rank 5
2022-12-08 16:58:33,841 DEBUG TRAIN Batch 34/1000 loss 6.451033 loss_att 378.983459 loss_ctc 13.875154 loss_rnnt 5.626130 lr 0.00023757 rank 7
2022-12-08 16:58:33,847 DEBUG TRAIN Batch 34/1000 loss 10.997991 loss_att 442.074615 loss_ctc 23.634117 loss_rnnt 9.593977 lr 0.00023757 rank 4
2022-12-08 16:58:33,847 DEBUG TRAIN Batch 34/1000 loss 5.956645 loss_att 343.283417 loss_ctc 11.651576 loss_rnnt 5.323874 lr 0.00023759 rank 2
2022-12-08 16:58:33,847 DEBUG TRAIN Batch 34/1000 loss 10.111493 loss_att 392.648651 loss_ctc 21.447397 loss_rnnt 8.851948 lr 0.00023760 rank 5
2022-12-08 16:58:33,850 DEBUG TRAIN Batch 34/1000 loss 3.612624 loss_att 393.228729 loss_ctc 11.394361 loss_rnnt 2.747987 lr 0.00023758 rank 3
2022-12-08 16:58:33,855 DEBUG TRAIN Batch 34/1000 loss 10.924612 loss_att 381.518982 loss_ctc 24.444889 loss_rnnt 9.422359 lr 0.00023757 rank 0
2022-12-08 16:58:33,860 DEBUG TRAIN Batch 34/1000 loss 9.165269 loss_att 436.554169 loss_ctc 20.770054 loss_rnnt 7.875848 lr 0.00023760 rank 1
2022-12-08 16:58:33,873 DEBUG TRAIN Batch 34/1000 loss 4.517394 loss_att 352.978943 loss_ctc 9.761803 loss_rnnt 3.934682 lr 0.00023760 rank 6
2022-12-08 16:59:44,746 DEBUG TRAIN Batch 34/1100 loss 8.644113 loss_att 366.506317 loss_ctc 21.031988 loss_rnnt 7.267683 lr 0.00023754 rank 4
2022-12-08 16:59:44,748 DEBUG TRAIN Batch 34/1100 loss 5.656715 loss_att 350.227966 loss_ctc 12.545941 loss_rnnt 4.891246 lr 0.00023758 rank 6
2022-12-08 16:59:44,749 DEBUG TRAIN Batch 34/1100 loss 5.545127 loss_att 318.822113 loss_ctc 10.347395 loss_rnnt 5.011542 lr 0.00023757 rank 2
2022-12-08 16:59:44,749 DEBUG TRAIN Batch 34/1100 loss 4.330544 loss_att 343.264282 loss_ctc 10.177559 loss_rnnt 3.680876 lr 0.00023755 rank 7
2022-12-08 16:59:44,752 DEBUG TRAIN Batch 34/1100 loss 4.349716 loss_att 338.065155 loss_ctc 11.480935 loss_rnnt 3.557358 lr 0.00023757 rank 1
2022-12-08 16:59:44,752 DEBUG TRAIN Batch 34/1100 loss 4.906044 loss_att 330.245483 loss_ctc 11.751087 loss_rnnt 4.145484 lr 0.00023755 rank 0
2022-12-08 16:59:44,752 DEBUG TRAIN Batch 34/1100 loss 9.459629 loss_att 334.738953 loss_ctc 18.716175 loss_rnnt 8.431124 lr 0.00023758 rank 5
2022-12-08 16:59:44,792 DEBUG TRAIN Batch 34/1100 loss 8.367565 loss_att 303.992462 loss_ctc 19.026871 loss_rnnt 7.183198 lr 0.00023756 rank 3
2022-12-08 17:00:49,241 DEBUG TRAIN Batch 34/1200 loss 8.681547 loss_att 281.207031 loss_ctc 18.396799 loss_rnnt 7.602075 lr 0.00023752 rank 7
2022-12-08 17:00:49,241 DEBUG TRAIN Batch 34/1200 loss 9.106087 loss_att 248.832642 loss_ctc 18.184397 loss_rnnt 8.097385 lr 0.00023755 rank 6
2022-12-08 17:00:49,241 DEBUG TRAIN Batch 34/1200 loss 5.885328 loss_att 256.087311 loss_ctc 9.743179 loss_rnnt 5.456677 lr 0.00023754 rank 2
2022-12-08 17:00:49,246 DEBUG TRAIN Batch 34/1200 loss 6.906030 loss_att 292.213776 loss_ctc 15.932953 loss_rnnt 5.903038 lr 0.00023754 rank 1
2022-12-08 17:00:49,249 DEBUG TRAIN Batch 34/1200 loss 17.961569 loss_att 341.958801 loss_ctc 28.339746 loss_rnnt 16.808439 lr 0.00023755 rank 5
2022-12-08 17:00:49,250 DEBUG TRAIN Batch 34/1200 loss 2.188351 loss_att 218.838440 loss_ctc 6.122232 loss_rnnt 1.751253 lr 0.00023752 rank 0
2022-12-08 17:00:49,252 DEBUG TRAIN Batch 34/1200 loss 8.629170 loss_att 342.024261 loss_ctc 19.997467 loss_rnnt 7.366026 lr 0.00023752 rank 4
2022-12-08 17:00:49,282 DEBUG TRAIN Batch 34/1200 loss 12.423231 loss_att 381.571747 loss_ctc 20.599327 loss_rnnt 11.514776 lr 0.00023753 rank 3
2022-12-08 17:01:53,749 DEBUG TRAIN Batch 34/1300 loss 4.470731 loss_att 393.221375 loss_ctc 15.874908 loss_rnnt 3.203600 lr 0.00023752 rank 1
2022-12-08 17:01:53,758 DEBUG TRAIN Batch 34/1300 loss 9.419975 loss_att 147.964645 loss_ctc 18.053839 loss_rnnt 8.460657 lr 0.00023749 rank 7
2022-12-08 17:01:53,761 DEBUG TRAIN Batch 34/1300 loss 6.656960 loss_att 106.940628 loss_ctc 11.819339 loss_rnnt 6.083362 lr 0.00023749 rank 4
2022-12-08 17:01:53,765 DEBUG TRAIN Batch 34/1300 loss 5.583079 loss_att 442.840790 loss_ctc 10.184912 loss_rnnt 5.071764 lr 0.00023752 rank 5
2022-12-08 17:01:53,765 DEBUG TRAIN Batch 34/1300 loss 9.650784 loss_att 383.532471 loss_ctc 26.217209 loss_rnnt 7.810070 lr 0.00023752 rank 6
2022-12-08 17:01:53,766 DEBUG TRAIN Batch 34/1300 loss 4.434174 loss_att 350.744812 loss_ctc 7.150002 loss_rnnt 4.132415 lr 0.00023751 rank 2
2022-12-08 17:01:53,767 DEBUG TRAIN Batch 34/1300 loss 5.618677 loss_att 397.322205 loss_ctc 13.369064 loss_rnnt 4.757523 lr 0.00023749 rank 0
2022-12-08 17:01:53,802 DEBUG TRAIN Batch 34/1300 loss 3.875179 loss_att 365.779388 loss_ctc 11.736090 loss_rnnt 3.001744 lr 0.00023750 rank 3
2022-12-08 17:02:58,746 DEBUG TRAIN Batch 34/1400 loss 1.676155 loss_att 387.806976 loss_ctc 5.115253 loss_rnnt 1.294033 lr 0.00023750 rank 6
2022-12-08 17:02:58,747 DEBUG TRAIN Batch 34/1400 loss 3.985188 loss_att 425.403656 loss_ctc 11.817419 loss_rnnt 3.114941 lr 0.00023748 rank 3
2022-12-08 17:02:58,749 DEBUG TRAIN Batch 34/1400 loss 8.884530 loss_att 381.247040 loss_ctc 18.051746 loss_rnnt 7.865951 lr 0.00023747 rank 7
2022-12-08 17:02:58,750 DEBUG TRAIN Batch 34/1400 loss 2.800962 loss_att 412.724457 loss_ctc 8.788746 loss_rnnt 2.135653 lr 0.00023749 rank 1
2022-12-08 17:02:58,754 DEBUG TRAIN Batch 34/1400 loss 9.757329 loss_att 472.371429 loss_ctc 24.211395 loss_rnnt 8.151321 lr 0.00023749 rank 2
2022-12-08 17:02:58,758 DEBUG TRAIN Batch 34/1400 loss 10.984904 loss_att 440.646606 loss_ctc 25.509525 loss_rnnt 9.371058 lr 0.00023747 rank 0
2022-12-08 17:02:58,758 DEBUG TRAIN Batch 34/1400 loss 2.315405 loss_att 342.577240 loss_ctc 8.989858 loss_rnnt 1.573800 lr 0.00023746 rank 4
2022-12-08 17:02:58,761 DEBUG TRAIN Batch 34/1400 loss 9.111685 loss_att 414.300995 loss_ctc 29.788086 loss_rnnt 6.814307 lr 0.00023750 rank 5
2022-12-08 17:04:08,305 DEBUG TRAIN Batch 34/1500 loss 2.398147 loss_att 357.322357 loss_ctc 8.843664 loss_rnnt 1.681978 lr 0.00023744 rank 4
2022-12-08 17:04:08,310 DEBUG TRAIN Batch 34/1500 loss 3.357423 loss_att 416.964203 loss_ctc 7.747446 loss_rnnt 2.869642 lr 0.00023744 rank 7
2022-12-08 17:04:08,312 DEBUG TRAIN Batch 34/1500 loss 2.816129 loss_att 336.227600 loss_ctc 8.606743 loss_rnnt 2.172727 lr 0.00023746 rank 2
2022-12-08 17:04:08,312 DEBUG TRAIN Batch 34/1500 loss 2.396331 loss_att 362.878265 loss_ctc 3.457256 loss_rnnt 2.278451 lr 0.00023744 rank 0
2022-12-08 17:04:08,314 DEBUG TRAIN Batch 34/1500 loss 5.197155 loss_att 375.929138 loss_ctc 12.622711 loss_rnnt 4.372093 lr 0.00023746 rank 1
2022-12-08 17:04:08,315 DEBUG TRAIN Batch 34/1500 loss 17.822723 loss_att 428.213104 loss_ctc 35.501518 loss_rnnt 15.858413 lr 0.00023745 rank 3
2022-12-08 17:04:08,318 DEBUG TRAIN Batch 34/1500 loss 3.437817 loss_att 395.408203 loss_ctc 7.616324 loss_rnnt 2.973538 lr 0.00023747 rank 5
2022-12-08 17:04:08,355 DEBUG TRAIN Batch 34/1500 loss 4.641541 loss_att 374.837128 loss_ctc 10.729036 loss_rnnt 3.965152 lr 0.00023747 rank 6
2022-12-08 17:05:11,403 DEBUG TRAIN Batch 34/1600 loss 7.332881 loss_att 426.958923 loss_ctc 13.175789 loss_rnnt 6.683670 lr 0.00023741 rank 7
2022-12-08 17:05:11,403 DEBUG TRAIN Batch 34/1600 loss 1.529653 loss_att 349.786194 loss_ctc 4.482735 loss_rnnt 1.201533 lr 0.00023741 rank 4
2022-12-08 17:05:11,408 DEBUG TRAIN Batch 34/1600 loss 2.782572 loss_att 302.885071 loss_ctc 6.232792 loss_rnnt 2.399214 lr 0.00023744 rank 5
2022-12-08 17:05:11,409 DEBUG TRAIN Batch 34/1600 loss 7.444331 loss_att 307.005310 loss_ctc 14.846680 loss_rnnt 6.621848 lr 0.00023743 rank 2
2022-12-08 17:05:11,410 DEBUG TRAIN Batch 34/1600 loss 4.726295 loss_att 394.888855 loss_ctc 9.633820 loss_rnnt 4.181015 lr 0.00023741 rank 0
2022-12-08 17:05:11,413 DEBUG TRAIN Batch 34/1600 loss 4.237698 loss_att 423.438354 loss_ctc 10.915248 loss_rnnt 3.495748 lr 0.00023744 rank 1
2022-12-08 17:05:11,412 DEBUG TRAIN Batch 34/1600 loss 3.676147 loss_att 359.610962 loss_ctc 5.494234 loss_rnnt 3.474137 lr 0.00023742 rank 3
2022-12-08 17:05:11,414 DEBUG TRAIN Batch 34/1600 loss 6.918740 loss_att 394.804932 loss_ctc 12.653835 loss_rnnt 6.281507 lr 0.00023744 rank 6
2022-12-08 17:06:14,980 DEBUG TRAIN Batch 34/1700 loss 2.549779 loss_att 334.269501 loss_ctc 7.763893 loss_rnnt 1.970433 lr 0.00023740 rank 3
2022-12-08 17:06:14,981 DEBUG TRAIN Batch 34/1700 loss 3.821207 loss_att 366.889252 loss_ctc 9.163481 loss_rnnt 3.227620 lr 0.00023738 rank 4
2022-12-08 17:06:14,985 DEBUG TRAIN Batch 34/1700 loss 6.372673 loss_att 325.919495 loss_ctc 9.047470 loss_rnnt 6.075473 lr 0.00023739 rank 7
2022-12-08 17:06:14,992 DEBUG TRAIN Batch 34/1700 loss 7.048780 loss_att 354.679626 loss_ctc 16.063692 loss_rnnt 6.047124 lr 0.00023739 rank 0
2022-12-08 17:06:14,992 DEBUG TRAIN Batch 34/1700 loss 15.225491 loss_att 355.583130 loss_ctc 26.474016 loss_rnnt 13.975655 lr 0.00023742 rank 6
2022-12-08 17:06:14,994 DEBUG TRAIN Batch 34/1700 loss 1.674736 loss_att 328.375580 loss_ctc 4.269186 loss_rnnt 1.386464 lr 0.00023742 rank 5
2022-12-08 17:06:15,019 DEBUG TRAIN Batch 34/1700 loss 13.421424 loss_att 360.363342 loss_ctc 27.444431 loss_rnnt 11.863313 lr 0.00023741 rank 2
2022-12-08 17:06:15,036 DEBUG TRAIN Batch 34/1700 loss 4.481177 loss_att 370.323029 loss_ctc 7.584037 loss_rnnt 4.136415 lr 0.00023741 rank 1
2022-12-08 17:07:26,494 DEBUG TRAIN Batch 34/1800 loss 15.485082 loss_att 341.406097 loss_ctc 24.936634 loss_rnnt 14.434909 lr 0.00023736 rank 7
2022-12-08 17:07:26,509 DEBUG TRAIN Batch 34/1800 loss 5.689318 loss_att 253.436279 loss_ctc 15.450818 loss_rnnt 4.604707 lr 0.00023738 rank 2
2022-12-08 17:07:26,509 DEBUG TRAIN Batch 34/1800 loss 6.550773 loss_att 298.411987 loss_ctc 10.218516 loss_rnnt 6.143247 lr 0.00023738 rank 1
2022-12-08 17:07:26,510 DEBUG TRAIN Batch 34/1800 loss 6.723569 loss_att 359.236237 loss_ctc 15.025645 loss_rnnt 5.801116 lr 0.00023736 rank 4
2022-12-08 17:07:26,512 DEBUG TRAIN Batch 34/1800 loss 6.080689 loss_att 313.552704 loss_ctc 14.046335 loss_rnnt 5.195617 lr 0.00023739 rank 6
2022-12-08 17:07:26,513 DEBUG TRAIN Batch 34/1800 loss 9.163550 loss_att 312.583557 loss_ctc 24.409433 loss_rnnt 7.469563 lr 0.00023736 rank 0
2022-12-08 17:07:26,517 DEBUG TRAIN Batch 34/1800 loss 9.640183 loss_att 349.763000 loss_ctc 17.132757 loss_rnnt 8.807675 lr 0.00023737 rank 3
2022-12-08 17:07:26,553 DEBUG TRAIN Batch 34/1800 loss 13.818277 loss_att 214.508026 loss_ctc 25.778992 loss_rnnt 12.489309 lr 0.00023739 rank 5
2022-12-08 17:08:30,932 DEBUG TRAIN Batch 34/1900 loss 10.145702 loss_att 110.682289 loss_ctc 16.018040 loss_rnnt 9.493221 lr 0.00023736 rank 6
2022-12-08 17:08:30,934 DEBUG TRAIN Batch 34/1900 loss 4.083340 loss_att 298.303619 loss_ctc 8.859710 loss_rnnt 3.552632 lr 0.00023733 rank 4
2022-12-08 17:08:30,938 DEBUG TRAIN Batch 34/1900 loss 7.268024 loss_att 212.429245 loss_ctc 12.963883 loss_rnnt 6.635151 lr 0.00023733 rank 0
2022-12-08 17:08:30,939 DEBUG TRAIN Batch 34/1900 loss 8.787800 loss_att 99.381630 loss_ctc 14.369612 loss_rnnt 8.167599 lr 0.00023733 rank 7
2022-12-08 17:08:30,941 DEBUG TRAIN Batch 34/1900 loss 13.909657 loss_att 138.285645 loss_ctc 21.486883 loss_rnnt 13.067743 lr 0.00023734 rank 3
2022-12-08 17:08:30,942 DEBUG TRAIN Batch 34/1900 loss 12.554779 loss_att 129.191422 loss_ctc 20.970303 loss_rnnt 11.619720 lr 0.00023736 rank 1
2022-12-08 17:08:30,943 DEBUG TRAIN Batch 34/1900 loss 8.101501 loss_att 416.660950 loss_ctc 22.162071 loss_rnnt 6.539215 lr 0.00023736 rank 5
2022-12-08 17:08:30,943 DEBUG TRAIN Batch 34/1900 loss 4.830949 loss_att 336.891449 loss_ctc 9.817320 loss_rnnt 4.276908 lr 0.00023735 rank 2
2022-12-08 17:09:34,080 DEBUG TRAIN Batch 34/2000 loss 10.272175 loss_att 417.168549 loss_ctc 22.678267 loss_rnnt 8.893720 lr 0.00023730 rank 4
2022-12-08 17:09:34,081 DEBUG TRAIN Batch 34/2000 loss 7.387706 loss_att 441.684540 loss_ctc 15.295240 loss_rnnt 6.509091 lr 0.00023731 rank 7
2022-12-08 17:09:34,082 DEBUG TRAIN Batch 34/2000 loss 5.389713 loss_att 428.582703 loss_ctc 17.018906 loss_rnnt 4.097581 lr 0.00023733 rank 1
2022-12-08 17:09:34,086 DEBUG TRAIN Batch 34/2000 loss 4.636896 loss_att 456.152222 loss_ctc 8.031309 loss_rnnt 4.259739 lr 0.00023731 rank 0
2022-12-08 17:09:34,087 DEBUG TRAIN Batch 34/2000 loss 15.088799 loss_att 431.965576 loss_ctc 36.999840 loss_rnnt 12.654239 lr 0.00023732 rank 3
2022-12-08 17:09:34,091 DEBUG TRAIN Batch 34/2000 loss 5.615689 loss_att 488.601746 loss_ctc 11.312014 loss_rnnt 4.982765 lr 0.00023734 rank 5
2022-12-08 17:09:34,106 DEBUG TRAIN Batch 34/2000 loss 5.220917 loss_att 417.262665 loss_ctc 12.021655 loss_rnnt 4.465279 lr 0.00023734 rank 6
2022-12-08 17:09:34,115 DEBUG TRAIN Batch 34/2000 loss 7.656046 loss_att 339.352631 loss_ctc 18.321568 loss_rnnt 6.470989 lr 0.00023733 rank 2
2022-12-08 17:10:39,390 DEBUG TRAIN Batch 34/2100 loss 3.040866 loss_att 422.386719 loss_ctc 6.418415 loss_rnnt 2.665583 lr 0.00023728 rank 4
2022-12-08 17:10:39,395 DEBUG TRAIN Batch 34/2100 loss 15.248219 loss_att 371.846039 loss_ctc 25.274456 loss_rnnt 14.134193 lr 0.00023728 rank 7
2022-12-08 17:10:39,396 DEBUG TRAIN Batch 34/2100 loss 4.978563 loss_att 363.242645 loss_ctc 9.820241 loss_rnnt 4.440599 lr 0.00023728 rank 0
2022-12-08 17:10:39,399 DEBUG TRAIN Batch 34/2100 loss 10.851839 loss_att 399.488861 loss_ctc 17.347494 loss_rnnt 10.130099 lr 0.00023730 rank 1
2022-12-08 17:10:39,399 DEBUG TRAIN Batch 34/2100 loss 13.072201 loss_att 423.043213 loss_ctc 24.164289 loss_rnnt 11.839747 lr 0.00023731 rank 6
2022-12-08 17:10:39,400 DEBUG TRAIN Batch 34/2100 loss 2.786342 loss_att 329.063995 loss_ctc 6.858454 loss_rnnt 2.333886 lr 0.00023731 rank 5
2022-12-08 17:10:39,412 DEBUG TRAIN Batch 34/2100 loss 5.845993 loss_att 391.744141 loss_ctc 11.591933 loss_rnnt 5.207555 lr 0.00023729 rank 3
2022-12-08 17:10:39,437 DEBUG TRAIN Batch 34/2100 loss 3.428144 loss_att 300.400208 loss_ctc 8.136584 loss_rnnt 2.904984 lr 0.00023730 rank 2
2022-12-08 17:11:49,725 DEBUG TRAIN Batch 34/2200 loss 3.223610 loss_att 338.377411 loss_ctc 9.323441 loss_rnnt 2.545851 lr 0.00023725 rank 7
2022-12-08 17:11:49,728 DEBUG TRAIN Batch 34/2200 loss 7.696219 loss_att 352.585205 loss_ctc 17.718857 loss_rnnt 6.582593 lr 0.00023728 rank 5
2022-12-08 17:11:49,731 DEBUG TRAIN Batch 34/2200 loss 5.682760 loss_att 420.884949 loss_ctc 13.576545 loss_rnnt 4.805673 lr 0.00023725 rank 4
2022-12-08 17:11:49,734 DEBUG TRAIN Batch 34/2200 loss 7.652289 loss_att 353.504456 loss_ctc 15.156174 loss_rnnt 6.818525 lr 0.00023726 rank 3
2022-12-08 17:11:49,734 DEBUG TRAIN Batch 34/2200 loss 8.714900 loss_att 391.101013 loss_ctc 20.791241 loss_rnnt 7.373084 lr 0.00023727 rank 2
2022-12-08 17:11:49,735 DEBUG TRAIN Batch 34/2200 loss 3.375618 loss_att 380.248077 loss_ctc 9.963371 loss_rnnt 2.643646 lr 0.00023725 rank 0
2022-12-08 17:11:49,737 DEBUG TRAIN Batch 34/2200 loss 11.069104 loss_att 420.551880 loss_ctc 23.570200 loss_rnnt 9.680094 lr 0.00023728 rank 6
2022-12-08 17:11:49,743 DEBUG TRAIN Batch 34/2200 loss 10.834455 loss_att 390.472656 loss_ctc 19.998919 loss_rnnt 9.816181 lr 0.00023728 rank 1
2022-12-08 17:12:53,310 DEBUG TRAIN Batch 34/2300 loss 5.251746 loss_att 336.155151 loss_ctc 10.974653 loss_rnnt 4.615868 lr 0.00023723 rank 7
2022-12-08 17:12:53,311 DEBUG TRAIN Batch 34/2300 loss 10.906729 loss_att 373.271790 loss_ctc 23.669035 loss_rnnt 9.488695 lr 0.00023722 rank 4
2022-12-08 17:12:53,312 DEBUG TRAIN Batch 34/2300 loss 2.997081 loss_att 344.544922 loss_ctc 6.807519 loss_rnnt 2.573699 lr 0.00023724 rank 3
2022-12-08 17:12:53,314 DEBUG TRAIN Batch 34/2300 loss 6.712215 loss_att 291.899750 loss_ctc 11.882219 loss_rnnt 6.137771 lr 0.00023726 rank 6
2022-12-08 17:12:53,316 DEBUG TRAIN Batch 34/2300 loss 3.986596 loss_att 299.695862 loss_ctc 8.434700 loss_rnnt 3.492362 lr 0.00023723 rank 0
2022-12-08 17:12:53,319 DEBUG TRAIN Batch 34/2300 loss 10.773766 loss_att 413.443512 loss_ctc 21.032345 loss_rnnt 9.633924 lr 0.00023725 rank 2
2022-12-08 17:12:53,319 DEBUG TRAIN Batch 34/2300 loss 12.006644 loss_att 395.810547 loss_ctc 25.490524 loss_rnnt 10.508436 lr 0.00023726 rank 5
2022-12-08 17:12:53,358 DEBUG TRAIN Batch 34/2300 loss 6.633887 loss_att 388.597046 loss_ctc 16.307203 loss_rnnt 5.559075 lr 0.00023725 rank 1
2022-12-08 17:13:57,311 DEBUG TRAIN Batch 34/2400 loss 17.507202 loss_att 390.527893 loss_ctc 36.284496 loss_rnnt 15.420835 lr 0.00023721 rank 3
2022-12-08 17:13:57,313 DEBUG TRAIN Batch 34/2400 loss 10.345763 loss_att 313.329651 loss_ctc 19.732256 loss_rnnt 9.302820 lr 0.00023720 rank 0
2022-12-08 17:13:57,318 DEBUG TRAIN Batch 34/2400 loss 7.157568 loss_att 352.433838 loss_ctc 15.709155 loss_rnnt 6.207391 lr 0.00023720 rank 7
2022-12-08 17:13:57,318 DEBUG TRAIN Batch 34/2400 loss 13.060266 loss_att 346.470703 loss_ctc 18.747526 loss_rnnt 12.428349 lr 0.00023720 rank 4
2022-12-08 17:13:57,321 DEBUG TRAIN Batch 34/2400 loss 6.799020 loss_att 304.497406 loss_ctc 13.830800 loss_rnnt 6.017711 lr 0.00023722 rank 2
2022-12-08 17:13:57,322 DEBUG TRAIN Batch 34/2400 loss 8.498280 loss_att 300.463257 loss_ctc 16.703192 loss_rnnt 7.586623 lr 0.00023722 rank 1
2022-12-08 17:13:57,324 DEBUG TRAIN Batch 34/2400 loss 7.241232 loss_att 289.736847 loss_ctc 18.914457 loss_rnnt 5.944207 lr 0.00023723 rank 5
2022-12-08 17:13:57,329 DEBUG TRAIN Batch 34/2400 loss 2.645362 loss_att 345.514954 loss_ctc 4.043760 loss_rnnt 2.489985 lr 0.00023723 rank 6
