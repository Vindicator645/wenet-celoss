/home/work_nfs5_ssd/kxhuang/wenet-encoder_decoder_bias/examples/librispeech/s0/data/lang_char/train_960_unigram5000
dictionary: /home/work_nfs5_ssd/kxhuang/wenet-encoder_decoder_bias/examples/librispeech/s0/data/lang_char/train_960_unigram5000_units.txt
run_1_13_rnnt_bias.sh: init method is file:///home/work_nfs6/tyxu/workspace/wenet-bias-celoss/examples/librispeech/s0/exp2_10_rnnt_bias_loss/ddp_init
2023-02-11 00:30:04,596 INFO training on multiple gpus, this gpu 4
2023-02-11 00:30:04,596 INFO training on multiple gpus, this gpu 6
2023-02-11 00:30:04,596 INFO training on multiple gpus, this gpu 7
2023-02-11 00:30:04,597 INFO training on multiple gpus, this gpu 2
2023-02-11 00:30:04,597 INFO training on multiple gpus, this gpu 3
2023-02-11 00:30:04,597 INFO training on multiple gpus, this gpu 5
2023-02-11 00:30:04,597 INFO training on multiple gpus, this gpu 0
2023-02-11 00:30:04,598 INFO training on multiple gpus, this gpu 1
2023-02-11 00:30:04,663 INFO Added key: store_based_barrier_key:1 to store for rank: 0
2023-02-11 00:30:04,695 INFO Added key: store_based_barrier_key:1 to store for rank: 1
2023-02-11 00:30:04,704 INFO Added key: store_based_barrier_key:1 to store for rank: 2
2023-02-11 00:30:04,713 INFO Added key: store_based_barrier_key:1 to store for rank: 3
2023-02-11 00:30:04,716 INFO Added key: store_based_barrier_key:1 to store for rank: 5
2023-02-11 00:30:04,724 INFO Added key: store_based_barrier_key:1 to store for rank: 6
2023-02-11 00:30:04,727 INFO Added key: store_based_barrier_key:1 to store for rank: 4
2023-02-11 00:30:04,734 INFO Added key: store_based_barrier_key:1 to store for rank: 7
2023-02-11 00:30:04,735 INFO Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-11 00:30:04,737 INFO Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-11 00:30:04,740 INFO Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-11 00:30:04,740 INFO Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-11 00:30:04,743 INFO Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-11 00:30:04,744 INFO Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-11 00:30:04,745 INFO Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-11 00:30:04,749 INFO Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-02-11 00:30:23,073 INFO Epoch 0 TRAIN info lr 4e-08
2023-02-11 00:30:23,073 INFO Epoch 0 TRAIN info lr 4e-08
2023-02-11 00:30:23,075 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 00:30:23,075 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=256, out_features=51, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58380379
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=256, out_features=51, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58380379
2023-02-11 00:30:23,130 INFO Epoch 0 TRAIN info lr 4e-08
2023-02-11 00:30:23,138 INFO Epoch 0 TRAIN info lr 4e-08
2023-02-11 00:30:23,140 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=256, out_features=51, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58380379
2023-02-11 00:30:23,151 INFO Epoch 0 TRAIN info lr 4e-08
2023-02-11 00:30:23,154 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=256, out_features=51, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58380379
2023-02-11 00:30:23,161 INFO Epoch 0 TRAIN info lr 4e-08
2023-02-11 00:30:23,161 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 00:30:23,163 INFO Epoch 0 TRAIN info lr 4e-08
2023-02-11 00:30:23,163 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 00:30:23,166 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=256, out_features=51, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58380379
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=256, out_features=51, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58380379
2023-02-11 00:30:23,173 INFO Checkpoint: save to checkpoint exp2_10_rnnt_bias_loss/init.pt
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=256, out_features=51, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58380379
2023-02-11 00:30:23,850 INFO Epoch 0 TRAIN info lr 4e-08
2023-02-11 00:30:23,854 INFO using accumulate grad, new batch size is 1 times larger than before
Transducer(
  (encoder): ConformerEncoder(
    (global_cmvn): GlobalCMVN()
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): RelPositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (1): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (2): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (3): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (4): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (5): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (6): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (7): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (8): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (9): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (10): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
      (11): ConformerEncoderLayer(
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (feed_forward_macaron): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): SiLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (conv_module): ConvolutionModule(
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
          (depthwise_conv): Conv1d(256, 256, kernel_size=(15,), stride=(1,), padding=(7,), groups=256)
          (norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
          (activation): SiLU()
        )
        (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_mha): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_ff_macaron): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_conv): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm_final): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (concat_linear): Identity()
      )
    )
  )
  (decoder): BiTransformerDecoder(
    (left_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
    (right_decoder): TransformerDecoder(
      (embed): Sequential(
        (0): Embedding(5002, 256)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
      (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (output_layer): Linear(in_features=256, out_features=5002, bias=True)
      (decoders): ModuleList(
        (0): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (1): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
        (2): DecoderLayer(
          (self_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (src_attn): MultiHeadedAttention(
            (linear_q): Linear(in_features=256, out_features=256, bias=True)
            (linear_k): Linear(in_features=256, out_features=256, bias=True)
            (linear_v): Linear(in_features=256, out_features=256, bias=True)
            (linear_out): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): PositionwiseFeedForward(
            (w_1): Linear(in_features=256, out_features=2048, bias=True)
            (activation): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
            (w_2): Linear(in_features=2048, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (concat_linear1): Identity()
          (concat_linear2): Identity()
        )
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=5002, bias=True)
    (ctc_loss): CTCLoss()
  )
  (context_bias): ContextBias(
    (context_extractor): BLSTM(
      (word_embedding): Embedding(5002, 256)
      (sen_rnn): LSTM(256, 256, batch_first=True, bidirectional=True)
    )
    (context_encoder): Sequential(
      (0): Linear(in_features=1024, out_features=256, bias=True)
      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (encoder_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (predictor_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (hw_bias): MultiHeadedAttention(
      (linear_q): Linear(in_features=256, out_features=256, bias=True)
      (linear_k): Linear(in_features=256, out_features=256, bias=True)
      (linear_v): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=256, out_features=256, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoder_ffn): Linear(in_features=512, out_features=256, bias=True)
    (encoder_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (encdoer_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encdoer_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_combine): Linear(in_features=512, out_features=256, bias=True)
    (predictor_bias_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (predictor_bias_out_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_bias_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (hw_output_layer): Linear(in_features=256, out_features=51, bias=True)
  )
  (predictor): RNNPredictor(
    (embed): Embedding(5002, 256)
    (dropout): Dropout(p=0.1, inplace=False)
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.1)
    (projection): Linear(in_features=256, out_features=256, bias=True)
  )
  (joint): TransducerJoint(
    (activatoin): Tanh()
    (enc_ffn): Linear(in_features=256, out_features=512, bias=True)
    (pred_ffn): Linear(in_features=256, out_features=512, bias=True)
    (ffn_out): Linear(in_features=512, out_features=5002, bias=True)
  )
  (hw_criterion): CrossEntropyLoss()
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
the number of model params: 58380379
2023-02-11 00:31:38,174 DEBUG TRAIN Batch 0/0 loss 522.311707 loss_att 72.896469 loss_ctc 500.316681 loss_rnnt 594.436157 hw_loss 3.879609 lr 0.00000004 rank 3
2023-02-11 00:31:38,176 DEBUG TRAIN Batch 0/0 loss 568.803589 loss_att 81.403282 loss_ctc 548.077454 loss_rnnt 647.004578 hw_loss 4.132982 lr 0.00000004 rank 2
2023-02-11 00:31:38,179 DEBUG TRAIN Batch 0/0 loss 490.880554 loss_att 70.786919 loss_ctc 477.775024 loss_rnnt 555.828430 hw_loss 3.903422 lr 0.00000004 rank 7
2023-02-11 00:31:38,209 DEBUG TRAIN Batch 0/0 loss 521.470947 loss_att 77.442978 loss_ctc 507.266968 loss_rnnt 593.696350 hw_loss 3.463877 lr 0.00000004 rank 0
2023-02-11 00:31:38,234 DEBUG TRAIN Batch 0/0 loss 544.894653 loss_att 74.653305 loss_ctc 544.208252 loss_rnnt 620.020447 hw_loss 3.565129 lr 0.00000004 rank 4
2023-02-11 00:31:38,238 DEBUG TRAIN Batch 0/0 loss 546.291687 loss_att 71.469589 loss_ctc 551.144958 loss_rnnt 619.608948 hw_loss 3.937499 lr 0.00000004 rank 1
2023-02-11 00:31:38,239 DEBUG TRAIN Batch 0/0 loss 538.821960 loss_att 74.950287 loss_ctc 501.396576 loss_rnnt 614.025574 hw_loss 4.230150 lr 0.00000004 rank 5
2023-02-11 00:31:38,247 DEBUG TRAIN Batch 0/0 loss 566.021362 loss_att 86.318047 loss_ctc 546.398560 loss_rnnt 643.756287 hw_loss 3.904162 lr 0.00000004 rank 6
2023-02-11 00:32:56,987 DEBUG TRAIN Batch 0/100 loss 2151.694824 loss_att 390.774017 loss_ctc 3013.515137 loss_rnnt 2371.449219 hw_loss 3.285017 lr 0.00000404 rank 1
2023-02-11 00:32:56,988 DEBUG TRAIN Batch 0/100 loss 2114.319580 loss_att 379.515228 loss_ctc 3106.304688 loss_rnnt 2307.586670 hw_loss 4.017935 lr 0.00000404 rank 7
2023-02-11 00:32:56,989 DEBUG TRAIN Batch 0/100 loss 2195.278564 loss_att 374.808960 loss_ctc 3134.208496 loss_rnnt 2415.218750 hw_loss 3.555549 lr 0.00000404 rank 3
2023-02-11 00:32:56,992 DEBUG TRAIN Batch 0/100 loss 2195.490723 loss_att 362.970184 loss_ctc 3186.224121 loss_rnnt 2410.180420 hw_loss 3.696928 lr 0.00000404 rank 6
2023-02-11 00:32:56,994 DEBUG TRAIN Batch 0/100 loss 2126.063721 loss_att 372.423218 loss_ctc 3003.346436 loss_rnnt 2340.819824 hw_loss 3.562669 lr 0.00000404 rank 2
2023-02-11 00:32:56,995 DEBUG TRAIN Batch 0/100 loss 2096.896729 loss_att 394.160889 loss_ctc 3139.498779 loss_rnnt 2279.095459 hw_loss 3.625318 lr 0.00000404 rank 0
2023-02-11 00:32:56,997 DEBUG TRAIN Batch 0/100 loss 2173.051270 loss_att 371.310150 loss_ctc 3006.013428 loss_rnnt 2402.660645 hw_loss 3.689458 lr 0.00000404 rank 5
2023-02-11 00:32:57,000 DEBUG TRAIN Batch 0/100 loss 2221.249512 loss_att 365.373138 loss_ctc 3216.394043 loss_rnnt 2441.198975 hw_loss 3.476251 lr 0.00000404 rank 4
2023-02-11 00:34:11,874 DEBUG TRAIN Batch 0/200 loss 871.981140 loss_att 358.062134 loss_ctc 2679.793457 loss_rnnt 724.278442 hw_loss 1.770885 lr 0.00000804 rank 4
2023-02-11 00:34:11,874 DEBUG TRAIN Batch 0/200 loss 861.041870 loss_att 388.956848 loss_ctc 2882.686523 loss_rnnt 677.750854 hw_loss 1.529137 lr 0.00000804 rank 3
2023-02-11 00:34:11,875 DEBUG TRAIN Batch 0/200 loss 875.830139 loss_att 369.421997 loss_ctc 2795.275879 loss_rnnt 712.506958 hw_loss 1.627245 lr 0.00000804 rank 0
2023-02-11 00:34:11,875 DEBUG TRAIN Batch 0/200 loss 916.755493 loss_att 397.471741 loss_ctc 2746.161865 loss_rnnt 765.146851 hw_loss 2.164592 lr 0.00000804 rank 7
2023-02-11 00:34:11,876 DEBUG TRAIN Batch 0/200 loss 859.594788 loss_att 412.291748 loss_ctc 2759.425537 loss_rnnt 686.960327 hw_loss 1.647057 lr 0.00000804 rank 5
2023-02-11 00:34:11,876 DEBUG TRAIN Batch 0/200 loss 828.354248 loss_att 319.603516 loss_ctc 2832.228516 loss_rnnt 653.719360 hw_loss 1.725332 lr 0.00000804 rank 1
2023-02-11 00:34:11,879 DEBUG TRAIN Batch 0/200 loss 838.181885 loss_att 410.538635 loss_ctc 2436.927490 loss_rnnt 699.536804 hw_loss 2.063942 lr 0.00000804 rank 6
2023-02-11 00:34:11,928 DEBUG TRAIN Batch 0/200 loss 852.805786 loss_att 402.771576 loss_ctc 2492.744141 loss_rnnt 716.638062 hw_loss 1.409291 lr 0.00000804 rank 2
2023-02-11 00:35:29,436 DEBUG TRAIN Batch 0/300 loss 545.892395 loss_att 435.953369 loss_ctc 1349.891357 loss_rnnt 456.166321 hw_loss 0.846381 lr 0.00001204 rank 3
2023-02-11 00:35:29,439 DEBUG TRAIN Batch 0/300 loss 537.631104 loss_att 341.672974 loss_ctc 2088.592041 loss_rnnt 366.194672 hw_loss 0.718739 lr 0.00001204 rank 4
2023-02-11 00:35:29,441 DEBUG TRAIN Batch 0/300 loss 506.684509 loss_att 399.900848 loss_ctc 1296.099609 loss_rnnt 418.173523 hw_loss 0.864814 lr 0.00001204 rank 0
2023-02-11 00:35:29,444 DEBUG TRAIN Batch 0/300 loss 437.479370 loss_att 319.819122 loss_ctc 1300.572754 loss_rnnt 339.660645 hw_loss 1.175931 lr 0.00001204 rank 7
2023-02-11 00:35:29,445 DEBUG TRAIN Batch 0/300 loss 443.026428 loss_att 332.734772 loss_ctc 1233.342407 loss_rnnt 357.567322 hw_loss 0.401627 lr 0.00001204 rank 1
2023-02-11 00:35:29,447 DEBUG TRAIN Batch 0/300 loss 470.914001 loss_att 332.903595 loss_ctc 1526.942993 loss_rnnt 352.081360 hw_loss 1.055776 lr 0.00001204 rank 5
2023-02-11 00:35:29,447 DEBUG TRAIN Batch 0/300 loss 429.604614 loss_att 330.055054 loss_ctc 1112.844849 loss_rnnt 354.460663 hw_loss 0.741594 lr 0.00001204 rank 2
2023-02-11 00:35:29,448 DEBUG TRAIN Batch 0/300 loss 434.899292 loss_att 327.154114 loss_ctc 1259.210449 loss_rnnt 342.124634 hw_loss 0.827915 lr 0.00001204 rank 6
2023-02-11 00:36:47,220 DEBUG TRAIN Batch 0/400 loss 322.099854 loss_att 272.399994 loss_ctc 576.654419 loss_rnnt 295.244232 hw_loss 0.535308 lr 0.00001604 rank 7
2023-02-11 00:36:47,220 DEBUG TRAIN Batch 0/400 loss 378.611023 loss_att 286.839966 loss_ctc 1065.124023 loss_rnnt 302.243713 hw_loss 0.597456 lr 0.00001604 rank 0
2023-02-11 00:36:47,222 DEBUG TRAIN Batch 0/400 loss 379.560883 loss_att 273.024353 loss_ctc 1209.802856 loss_rnnt 287.511841 hw_loss 0.498269 lr 0.00001604 rank 3
2023-02-11 00:36:47,225 DEBUG TRAIN Batch 0/400 loss 383.693909 loss_att 325.995972 loss_ctc 653.495178 loss_rnnt 354.126709 hw_loss 0.962496 lr 0.00001604 rank 5
2023-02-11 00:36:47,228 DEBUG TRAIN Batch 0/400 loss 391.872467 loss_att 314.432129 loss_ctc 930.568970 loss_rnnt 330.671417 hw_loss 0.911787 lr 0.00001604 rank 6
2023-02-11 00:36:47,228 DEBUG TRAIN Batch 0/400 loss 391.244965 loss_att 334.669067 loss_ctc 654.941589 loss_rnnt 361.811646 hw_loss 1.047917 lr 0.00001604 rank 2
2023-02-11 00:36:47,229 DEBUG TRAIN Batch 0/400 loss 377.521088 loss_att 286.067291 loss_ctc 1044.969482 loss_rnnt 305.177185 hw_loss 0.307795 lr 0.00001604 rank 1
2023-02-11 00:36:47,279 DEBUG TRAIN Batch 0/400 loss 372.404633 loss_att 302.732544 loss_ctc 802.776489 loss_rnnt 323.686066 hw_loss 0.988137 lr 0.00001604 rank 4
2023-02-11 00:38:03,819 DEBUG TRAIN Batch 0/500 loss 339.308777 loss_att 272.006042 loss_ctc 676.485779 loss_rnnt 304.244141 hw_loss 0.669043 lr 0.00002004 rank 2
2023-02-11 00:38:03,824 DEBUG TRAIN Batch 0/500 loss 302.900787 loss_att 246.110825 loss_ctc 553.143188 loss_rnnt 275.166260 hw_loss 1.073782 lr 0.00002004 rank 7
2023-02-11 00:38:03,825 DEBUG TRAIN Batch 0/500 loss 332.996674 loss_att 275.507050 loss_ctc 551.464355 loss_rnnt 311.243225 hw_loss 0.772943 lr 0.00002004 rank 1
2023-02-11 00:38:03,826 DEBUG TRAIN Batch 0/500 loss 382.363556 loss_att 320.422638 loss_ctc 641.634827 loss_rnnt 355.727844 hw_loss 0.835194 lr 0.00002004 rank 0
2023-02-11 00:38:03,828 DEBUG TRAIN Batch 0/500 loss 295.903137 loss_att 234.779755 loss_ctc 641.672058 loss_rnnt 260.216919 hw_loss 0.339066 lr 0.00002004 rank 3
2023-02-11 00:38:03,829 DEBUG TRAIN Batch 0/500 loss 318.553833 loss_att 264.933319 loss_ctc 535.812439 loss_rnnt 296.154663 hw_loss 0.779151 lr 0.00002004 rank 4
2023-02-11 00:38:03,831 DEBUG TRAIN Batch 0/500 loss 322.733032 loss_att 236.634155 loss_ctc 870.699768 loss_rnnt 262.465515 hw_loss 0.829699 lr 0.00002004 rank 5
2023-02-11 00:38:03,872 DEBUG TRAIN Batch 0/500 loss 352.724945 loss_att 301.600555 loss_ctc 522.221863 loss_rnnt 336.985657 hw_loss 0.630861 lr 0.00002004 rank 6
2023-02-11 00:39:20,543 DEBUG TRAIN Batch 0/600 loss 241.528275 loss_att 158.982910 loss_ctc 751.825317 loss_rnnt 181.483307 hw_loss 1.596453 lr 0.00002404 rank 6
2023-02-11 00:39:20,547 DEBUG TRAIN Batch 0/600 loss 184.691238 loss_att 139.547516 loss_ctc 383.344666 loss_rnnt 158.660400 hw_loss 1.607335 lr 0.00002404 rank 0
2023-02-11 00:39:20,548 DEBUG TRAIN Batch 0/600 loss 193.581543 loss_att 147.546936 loss_ctc 391.383911 loss_rnnt 169.248215 hw_loss 1.343736 lr 0.00002404 rank 3
2023-02-11 00:39:20,550 DEBUG TRAIN Batch 0/600 loss 237.678619 loss_att 169.056366 loss_ctc 603.835571 loss_rnnt 193.002548 hw_loss 1.796175 lr 0.00002404 rank 7
2023-02-11 00:39:20,553 DEBUG TRAIN Batch 0/600 loss 180.160629 loss_att 133.290405 loss_ctc 402.156982 loss_rnnt 151.731293 hw_loss 1.538227 lr 0.00002404 rank 2
2023-02-11 00:39:20,553 DEBUG TRAIN Batch 0/600 loss 177.544037 loss_att 121.638351 loss_ctc 499.165405 loss_rnnt 138.472656 hw_loss 1.381813 lr 0.00002404 rank 5
2023-02-11 00:39:20,553 DEBUG TRAIN Batch 0/600 loss 132.042175 loss_att 88.352257 loss_ctc 373.657074 loss_rnnt 99.549866 hw_loss 1.690308 lr 0.00002404 rank 1
2023-02-11 00:39:20,604 DEBUG TRAIN Batch 0/600 loss 214.534515 loss_att 169.262802 loss_ctc 424.469269 loss_rnnt 191.810455 hw_loss 0.710079 lr 0.00002404 rank 4
2023-02-11 00:40:39,489 DEBUG TRAIN Batch 0/700 loss 332.226532 loss_att 288.156097 loss_ctc 340.054657 loss_rnnt 334.509644 hw_loss 1.028858 lr 0.00002804 rank 7
2023-02-11 00:40:39,492 DEBUG TRAIN Batch 0/700 loss 346.549591 loss_att 304.621216 loss_ctc 358.528992 loss_rnnt 351.273560 hw_loss 0.387087 lr 0.00002804 rank 5
2023-02-11 00:40:39,492 DEBUG TRAIN Batch 0/700 loss 301.008881 loss_att 262.631470 loss_ctc 316.870209 loss_rnnt 301.949402 hw_loss 0.866273 lr 0.00002804 rank 3
2023-02-11 00:40:39,495 DEBUG TRAIN Batch 0/700 loss 330.341888 loss_att 290.315796 loss_ctc 345.675964 loss_rnnt 332.398254 hw_loss 0.732064 lr 0.00002804 rank 4
2023-02-11 00:40:39,495 DEBUG TRAIN Batch 0/700 loss 392.981689 loss_att 344.507477 loss_ctc 408.695282 loss_rnnt 396.320312 hw_loss 0.798954 lr 0.00002804 rank 0
2023-02-11 00:40:39,498 DEBUG TRAIN Batch 0/700 loss 340.507263 loss_att 298.656219 loss_ctc 354.366425 loss_rnnt 345.344910 hw_loss 0.315883 lr 0.00002804 rank 2
2023-02-11 00:40:39,526 DEBUG TRAIN Batch 0/700 loss 376.493256 loss_att 329.150970 loss_ctc 386.355591 loss_rnnt 381.945068 hw_loss 0.506562 lr 0.00002804 rank 6
2023-02-11 00:40:39,535 DEBUG TRAIN Batch 0/700 loss 339.581757 loss_att 298.068390 loss_ctc 353.082275 loss_rnnt 341.181458 hw_loss 0.919290 lr 0.00002804 rank 1
2023-02-11 00:41:55,405 DEBUG TRAIN Batch 0/800 loss 337.287292 loss_att 294.541473 loss_ctc 346.338226 loss_rnnt 341.072479 hw_loss 0.666979 lr 0.00003204 rank 0
2023-02-11 00:41:55,407 DEBUG TRAIN Batch 0/800 loss 358.139801 loss_att 312.467987 loss_ctc 366.412659 loss_rnnt 363.496887 hw_loss 0.501408 lr 0.00003204 rank 7
2023-02-11 00:41:55,409 DEBUG TRAIN Batch 0/800 loss 340.942963 loss_att 296.896790 loss_ctc 348.387634 loss_rnnt 347.507172 hw_loss 0.234824 lr 0.00003204 rank 6
2023-02-11 00:41:55,412 DEBUG TRAIN Batch 0/800 loss 409.247101 loss_att 358.041412 loss_ctc 419.837524 loss_rnnt 415.524414 hw_loss 0.478456 lr 0.00003204 rank 3
2023-02-11 00:41:55,412 DEBUG TRAIN Batch 0/800 loss 292.809265 loss_att 254.577316 loss_ctc 296.765259 loss_rnnt 293.992188 hw_loss 1.112998 lr 0.00003204 rank 4
2023-02-11 00:41:55,413 DEBUG TRAIN Batch 0/800 loss 297.176666 loss_att 260.097534 loss_ctc 304.202637 loss_rnnt 302.546265 hw_loss 0.208018 lr 0.00003204 rank 5
2023-02-11 00:41:55,414 DEBUG TRAIN Batch 0/800 loss 300.689972 loss_att 261.183136 loss_ctc 307.292572 loss_rnnt 303.808716 hw_loss 0.731686 lr 0.00003204 rank 1
2023-02-11 00:41:55,421 DEBUG TRAIN Batch 0/800 loss 301.560974 loss_att 263.032288 loss_ctc 308.892670 loss_rnnt 306.354797 hw_loss 0.362696 lr 0.00003204 rank 2
2023-02-11 00:43:11,817 DEBUG TRAIN Batch 0/900 loss 292.522827 loss_att 255.899994 loss_ctc 301.868652 loss_rnnt 296.826721 hw_loss 0.332735 lr 0.00003604 rank 0
2023-02-11 00:43:11,818 DEBUG TRAIN Batch 0/900 loss 358.976135 loss_att 314.703308 loss_ctc 371.132446 loss_rnnt 364.849487 hw_loss 0.255066 lr 0.00003604 rank 2
2023-02-11 00:43:11,822 DEBUG TRAIN Batch 0/900 loss 333.181519 loss_att 289.714783 loss_ctc 342.469391 loss_rnnt 336.260254 hw_loss 0.820543 lr 0.00003604 rank 7
2023-02-11 00:43:11,823 DEBUG TRAIN Batch 0/900 loss 312.086670 loss_att 272.143402 loss_ctc 319.803864 loss_rnnt 316.250885 hw_loss 0.524155 lr 0.00003604 rank 3
2023-02-11 00:43:11,824 DEBUG TRAIN Batch 0/900 loss 323.052490 loss_att 281.970398 loss_ctc 332.763000 loss_rnnt 327.538422 hw_loss 0.456706 lr 0.00003604 rank 5
2023-02-11 00:43:11,827 DEBUG TRAIN Batch 0/900 loss 346.024506 loss_att 303.058167 loss_ctc 356.652069 loss_rnnt 351.410522 hw_loss 0.335667 lr 0.00003604 rank 6
2023-02-11 00:43:11,827 DEBUG TRAIN Batch 0/900 loss 290.571472 loss_att 252.208435 loss_ctc 297.729370 loss_rnnt 294.338806 hw_loss 0.553290 lr 0.00003604 rank 1
2023-02-11 00:43:11,850 DEBUG TRAIN Batch 0/900 loss 354.227722 loss_att 311.111511 loss_ctc 362.992279 loss_rnnt 358.058441 hw_loss 0.679490 lr 0.00003604 rank 4
2023-02-11 00:44:29,463 DEBUG TRAIN Batch 0/1000 loss 368.095795 loss_att 320.238342 loss_ctc 380.753174 loss_rnnt 371.314178 hw_loss 0.874772 lr 0.00004004 rank 5
2023-02-11 00:44:29,463 DEBUG TRAIN Batch 0/1000 loss 327.833191 loss_att 283.311340 loss_ctc 335.592651 loss_rnnt 330.994690 hw_loss 0.882795 lr 0.00004004 rank 0
2023-02-11 00:44:29,464 DEBUG TRAIN Batch 0/1000 loss 280.688965 loss_att 245.553207 loss_ctc 290.514099 loss_rnnt 284.391724 hw_loss 0.377691 lr 0.00004004 rank 3
2023-02-11 00:44:29,465 DEBUG TRAIN Batch 0/1000 loss 263.157379 loss_att 230.750015 loss_ctc 271.155823 loss_rnnt 265.391418 hw_loss 0.596430 lr 0.00004004 rank 1
2023-02-11 00:44:29,467 DEBUG TRAIN Batch 0/1000 loss 315.856903 loss_att 276.902161 loss_ctc 326.797211 loss_rnnt 320.681519 hw_loss 0.282679 lr 0.00004004 rank 4
2023-02-11 00:44:29,467 DEBUG TRAIN Batch 0/1000 loss 336.760956 loss_att 295.290894 loss_ctc 347.694275 loss_rnnt 339.431427 hw_loss 0.781072 lr 0.00004004 rank 7
2023-02-11 00:44:29,469 DEBUG TRAIN Batch 0/1000 loss 318.440247 loss_att 278.407227 loss_ctc 327.020782 loss_rnnt 321.094696 hw_loss 0.789017 lr 0.00004004 rank 6
2023-02-11 00:44:29,469 DEBUG TRAIN Batch 0/1000 loss 330.046417 loss_att 289.055664 loss_ctc 339.159302 loss_rnnt 333.661621 hw_loss 0.631477 lr 0.00004004 rank 2
2023-02-11 00:45:47,918 DEBUG TRAIN Batch 0/1100 loss 230.140442 loss_att 200.402100 loss_ctc 239.403900 loss_rnnt 232.464981 hw_loss 0.447749 lr 0.00004404 rank 3
2023-02-11 00:45:47,919 DEBUG TRAIN Batch 0/1100 loss 237.153885 loss_att 206.861267 loss_ctc 245.458801 loss_rnnt 239.798279 hw_loss 0.432525 lr 0.00004404 rank 7
2023-02-11 00:45:47,920 DEBUG TRAIN Batch 0/1100 loss 258.914703 loss_att 225.177002 loss_ctc 267.649689 loss_rnnt 260.470428 hw_loss 0.755096 lr 0.00004404 rank 1
2023-02-11 00:45:47,920 DEBUG TRAIN Batch 0/1100 loss 311.704681 loss_att 273.325226 loss_ctc 323.029297 loss_rnnt 314.491455 hw_loss 0.633601 lr 0.00004404 rank 0
2023-02-11 00:45:47,921 DEBUG TRAIN Batch 0/1100 loss 281.544983 loss_att 244.703537 loss_ctc 290.822266 loss_rnnt 282.843750 hw_loss 0.906105 lr 0.00004404 rank 4
2023-02-11 00:45:47,921 DEBUG TRAIN Batch 0/1100 loss 338.165192 loss_att 295.822449 loss_ctc 351.896912 loss_rnnt 340.369568 hw_loss 0.831242 lr 0.00004404 rank 5
2023-02-11 00:45:47,922 DEBUG TRAIN Batch 0/1100 loss 274.249847 loss_att 239.001770 loss_ctc 282.588013 loss_rnnt 275.654907 hw_loss 0.849897 lr 0.00004404 rank 2
2023-02-11 00:45:47,924 DEBUG TRAIN Batch 0/1100 loss 262.882568 loss_att 230.477173 loss_ctc 273.248962 loss_rnnt 262.374512 hw_loss 1.051300 lr 0.00004404 rank 6
2023-02-11 00:47:03,716 DEBUG TRAIN Batch 0/1200 loss 258.587860 loss_att 224.190460 loss_ctc 266.267792 loss_rnnt 259.263245 hw_loss 0.971268 lr 0.00004804 rank 3
2023-02-11 00:47:03,717 DEBUG TRAIN Batch 0/1200 loss 244.464340 loss_att 213.495850 loss_ctc 251.464844 loss_rnnt 245.193756 hw_loss 0.849537 lr 0.00004804 rank 6
2023-02-11 00:47:03,717 DEBUG TRAIN Batch 0/1200 loss 138.324875 loss_att 117.247459 loss_ctc 138.955292 loss_rnnt 135.390060 hw_loss 1.324919 lr 0.00004804 rank 1
2023-02-11 00:47:03,718 DEBUG TRAIN Batch 0/1200 loss 241.108505 loss_att 211.966919 loss_ctc 255.101562 loss_rnnt 242.864380 hw_loss 0.413752 lr 0.00004804 rank 5
2023-02-11 00:47:03,722 DEBUG TRAIN Batch 0/1200 loss 224.270950 loss_att 194.515350 loss_ctc 230.843307 loss_rnnt 223.703659 hw_loss 1.057892 lr 0.00004804 rank 7
2023-02-11 00:47:03,723 DEBUG TRAIN Batch 0/1200 loss 214.898026 loss_att 185.948761 loss_ctc 220.580734 loss_rnnt 214.114868 hw_loss 1.090371 lr 0.00004804 rank 0
2023-02-11 00:47:03,724 DEBUG TRAIN Batch 0/1200 loss 260.902252 loss_att 229.517883 loss_ctc 270.160126 loss_rnnt 263.812805 hw_loss 0.399741 lr 0.00004804 rank 4
2023-02-11 00:47:03,725 DEBUG TRAIN Batch 0/1200 loss 221.687012 loss_att 193.447723 loss_ctc 231.562210 loss_rnnt 222.561630 hw_loss 0.648100 lr 0.00004804 rank 2
2023-02-11 00:48:19,347 DEBUG TRAIN Batch 0/1300 loss 305.918640 loss_att 272.156097 loss_ctc 321.962677 loss_rnnt 307.700928 hw_loss 0.530816 lr 0.00005204 rank 3
2023-02-11 00:48:19,350 DEBUG TRAIN Batch 0/1300 loss 345.574493 loss_att 303.860046 loss_ctc 361.505585 loss_rnnt 348.970673 hw_loss 0.529238 lr 0.00005204 rank 4
2023-02-11 00:48:19,351 DEBUG TRAIN Batch 0/1300 loss 353.794617 loss_att 313.866882 loss_ctc 370.071045 loss_rnnt 357.624878 hw_loss 0.372208 lr 0.00005204 rank 7
2023-02-11 00:48:19,353 DEBUG TRAIN Batch 0/1300 loss 293.993042 loss_att 259.285095 loss_ctc 310.660980 loss_rnnt 296.863464 hw_loss 0.346639 lr 0.00005204 rank 0
2023-02-11 00:48:19,356 DEBUG TRAIN Batch 0/1300 loss 307.646271 loss_att 274.387238 loss_ctc 322.447357 loss_rnnt 311.137543 hw_loss 0.222576 lr 0.00005204 rank 1
2023-02-11 00:48:19,357 DEBUG TRAIN Batch 0/1300 loss 402.804443 loss_att 355.207855 loss_ctc 428.877625 loss_rnnt 407.175232 hw_loss 0.313522 lr 0.00005204 rank 2
2023-02-11 00:48:19,357 DEBUG TRAIN Batch 0/1300 loss 353.568787 loss_att 317.832825 loss_ctc 372.656677 loss_rnnt 355.330780 hw_loss 0.532535 lr 0.00005204 rank 6
2023-02-11 00:48:19,358 DEBUG TRAIN Batch 0/1300 loss 148.699234 loss_att 126.497429 loss_ctc 151.974869 loss_rnnt 145.754303 hw_loss 1.302851 lr 0.00005204 rank 5
2023-02-11 00:49:37,262 DEBUG TRAIN Batch 0/1400 loss 387.710358 loss_att 342.066803 loss_ctc 408.881409 loss_rnnt 389.075378 hw_loss 0.926412 lr 0.00005604 rank 0
2023-02-11 00:49:37,263 DEBUG TRAIN Batch 0/1400 loss 362.615692 loss_att 320.289062 loss_ctc 379.462891 loss_rnnt 365.388733 hw_loss 0.646115 lr 0.00005604 rank 3
2023-02-11 00:49:37,266 DEBUG TRAIN Batch 0/1400 loss 358.563751 loss_att 315.166138 loss_ctc 374.863647 loss_rnnt 358.702240 hw_loss 1.193946 lr 0.00005604 rank 4
2023-02-11 00:49:37,266 DEBUG TRAIN Batch 0/1400 loss 252.219711 loss_att 224.684509 loss_ctc 270.387299 loss_rnnt 253.224670 hw_loss 0.389950 lr 0.00005604 rank 7
2023-02-11 00:49:37,267 DEBUG TRAIN Batch 0/1400 loss 358.162476 loss_att 314.848511 loss_ctc 376.785522 loss_rnnt 360.599304 hw_loss 0.701795 lr 0.00005604 rank 6
2023-02-11 00:49:37,269 DEBUG TRAIN Batch 0/1400 loss 313.120819 loss_att 275.080627 loss_ctc 326.733246 loss_rnnt 314.936462 hw_loss 0.745769 lr 0.00005604 rank 5
2023-02-11 00:49:37,272 DEBUG TRAIN Batch 0/1400 loss 311.786804 loss_att 271.633545 loss_ctc 322.117432 loss_rnnt 314.652008 hw_loss 0.710255 lr 0.00005604 rank 1
2023-02-11 00:49:37,317 DEBUG TRAIN Batch 0/1400 loss 304.897583 loss_att 269.397308 loss_ctc 327.846405 loss_rnnt 306.871307 hw_loss 0.387469 lr 0.00005604 rank 2
2023-02-11 00:50:55,672 DEBUG TRAIN Batch 0/1500 loss 337.258484 loss_att 297.717346 loss_ctc 360.330383 loss_rnnt 339.609619 hw_loss 0.465153 lr 0.00006004 rank 3
2023-02-11 00:50:55,672 DEBUG TRAIN Batch 0/1500 loss 310.769806 loss_att 276.201111 loss_ctc 332.877075 loss_rnnt 313.078949 hw_loss 0.310680 lr 0.00006004 rank 1
2023-02-11 00:50:55,674 DEBUG TRAIN Batch 0/1500 loss 304.216064 loss_att 270.608032 loss_ctc 332.115845 loss_rnnt 303.426514 hw_loss 0.710845 lr 0.00006004 rank 4
2023-02-11 00:50:55,675 DEBUG TRAIN Batch 0/1500 loss 366.995483 loss_att 325.619812 loss_ctc 397.477173 loss_rnnt 369.806885 hw_loss 0.262402 lr 0.00006004 rank 7
2023-02-11 00:50:55,677 DEBUG TRAIN Batch 0/1500 loss 299.520325 loss_att 265.819061 loss_ctc 317.487518 loss_rnnt 301.065063 hw_loss 0.524982 lr 0.00006004 rank 2
2023-02-11 00:50:55,677 DEBUG TRAIN Batch 0/1500 loss 356.570526 loss_att 314.669830 loss_ctc 387.579651 loss_rnnt 357.543579 hw_loss 0.613601 lr 0.00006004 rank 5
2023-02-11 00:50:55,677 DEBUG TRAIN Batch 0/1500 loss 337.047516 loss_att 297.129242 loss_ctc 361.388611 loss_rnnt 338.773499 hw_loss 0.564781 lr 0.00006004 rank 0
2023-02-11 00:50:55,726 DEBUG TRAIN Batch 0/1500 loss 298.981049 loss_att 264.106689 loss_ctc 315.209290 loss_rnnt 302.233215 hw_loss 0.292308 lr 0.00006004 rank 6
2023-02-11 00:52:10,838 DEBUG TRAIN Batch 0/1600 loss 287.832947 loss_att 253.416595 loss_ctc 305.021973 loss_rnnt 289.968201 hw_loss 0.460523 lr 0.00006404 rank 0
2023-02-11 00:52:10,842 DEBUG TRAIN Batch 0/1600 loss 363.305176 loss_att 324.253845 loss_ctc 384.951416 loss_rnnt 365.720551 hw_loss 0.470385 lr 0.00006404 rank 3
2023-02-11 00:52:10,845 DEBUG TRAIN Batch 0/1600 loss 291.889771 loss_att 257.956024 loss_ctc 309.977295 loss_rnnt 291.966553 hw_loss 0.805933 lr 0.00006404 rank 2
2023-02-11 00:52:10,846 DEBUG TRAIN Batch 0/1600 loss 329.001831 loss_att 293.123413 loss_ctc 353.083252 loss_rnnt 329.761078 hw_loss 0.601054 lr 0.00006404 rank 6
2023-02-11 00:52:10,848 DEBUG TRAIN Batch 0/1600 loss 312.365112 loss_att 274.637268 loss_ctc 333.274231 loss_rnnt 312.140259 hw_loss 0.934226 lr 0.00006404 rank 7
2023-02-11 00:52:10,850 DEBUG TRAIN Batch 0/1600 loss 302.707336 loss_att 268.483917 loss_ctc 319.897919 loss_rnnt 304.195679 hw_loss 0.574554 lr 0.00006404 rank 5
2023-02-11 00:52:10,852 DEBUG TRAIN Batch 0/1600 loss 317.476349 loss_att 280.994049 loss_ctc 342.069275 loss_rnnt 318.198303 hw_loss 0.617894 lr 0.00006404 rank 4
2023-02-11 00:52:10,897 DEBUG TRAIN Batch 0/1600 loss 306.202484 loss_att 273.354431 loss_ctc 331.411804 loss_rnnt 305.907654 hw_loss 0.656848 lr 0.00006404 rank 1
2023-02-11 00:53:27,115 DEBUG TRAIN Batch 0/1700 loss 317.731018 loss_att 277.794067 loss_ctc 336.764282 loss_rnnt 318.300964 hw_loss 0.914930 lr 0.00006804 rank 7
2023-02-11 00:53:27,117 DEBUG TRAIN Batch 0/1700 loss 308.313629 loss_att 273.333252 loss_ctc 335.053650 loss_rnnt 308.610107 hw_loss 0.587671 lr 0.00006804 rank 0
2023-02-11 00:53:27,118 DEBUG TRAIN Batch 0/1700 loss 291.839264 loss_att 256.604858 loss_ctc 310.451477 loss_rnnt 291.526550 hw_loss 0.914620 lr 0.00006804 rank 2
2023-02-11 00:53:27,119 DEBUG TRAIN Batch 0/1700 loss 256.625244 loss_att 228.316864 loss_ctc 275.843201 loss_rnnt 258.698730 hw_loss 0.192338 lr 0.00006804 rank 4
2023-02-11 00:53:27,120 DEBUG TRAIN Batch 0/1700 loss 253.467545 loss_att 219.820129 loss_ctc 266.706299 loss_rnnt 253.504639 hw_loss 0.923853 lr 0.00006804 rank 1
2023-02-11 00:53:27,120 DEBUG TRAIN Batch 0/1700 loss 278.853607 loss_att 244.720428 loss_ctc 298.079285 loss_rnnt 279.521667 hw_loss 0.674098 lr 0.00006804 rank 6
2023-02-11 00:53:27,121 DEBUG TRAIN Batch 0/1700 loss 308.281586 loss_att 271.578674 loss_ctc 331.092957 loss_rnnt 307.979370 hw_loss 0.862738 lr 0.00006804 rank 3
2023-02-11 00:53:27,123 DEBUG TRAIN Batch 0/1700 loss 282.133179 loss_att 248.662476 loss_ctc 302.003418 loss_rnnt 281.603119 hw_loss 0.857783 lr 0.00006804 rank 5
2023-02-11 00:54:46,369 DEBUG TRAIN Batch 0/1800 loss 243.242477 loss_att 213.157043 loss_ctc 256.926697 loss_rnnt 242.978012 hw_loss 0.835686 lr 0.00007204 rank 3
2023-02-11 00:54:46,371 DEBUG TRAIN Batch 0/1800 loss 159.809677 loss_att 141.363647 loss_ctc 170.634247 loss_rnnt 157.367798 hw_loss 0.878964 lr 0.00007204 rank 1
2023-02-11 00:54:46,374 DEBUG TRAIN Batch 0/1800 loss 267.146973 loss_att 236.352783 loss_ctc 287.106689 loss_rnnt 266.021820 hw_loss 0.866761 lr 0.00007204 rank 0
2023-02-11 00:54:46,376 DEBUG TRAIN Batch 0/1800 loss 264.688812 loss_att 233.099426 loss_ctc 286.148132 loss_rnnt 266.559753 hw_loss 0.297315 lr 0.00007204 rank 2
2023-02-11 00:54:46,377 DEBUG TRAIN Batch 0/1800 loss 271.684082 loss_att 239.069366 loss_ctc 287.476868 loss_rnnt 272.059448 hw_loss 0.757850 lr 0.00007204 rank 7
2023-02-11 00:54:46,377 DEBUG TRAIN Batch 0/1800 loss 304.034515 loss_att 268.814423 loss_ctc 329.237762 loss_rnnt 304.226074 hw_loss 0.654755 lr 0.00007204 rank 6
2023-02-11 00:54:46,379 DEBUG TRAIN Batch 0/1800 loss 244.498840 loss_att 218.796692 loss_ctc 262.497498 loss_rnnt 243.583572 hw_loss 0.685474 lr 0.00007204 rank 5
2023-02-11 00:54:46,381 DEBUG TRAIN Batch 0/1800 loss 283.829193 loss_att 249.252365 loss_ctc 304.296631 loss_rnnt 283.372345 hw_loss 0.870602 lr 0.00007204 rank 4
2023-02-11 00:56:02,028 DEBUG TRAIN Batch 0/1900 loss 167.062012 loss_att 144.391891 loss_ctc 172.272675 loss_rnnt 165.082397 hw_loss 1.091042 lr 0.00007604 rank 3
2023-02-11 00:56:02,030 DEBUG TRAIN Batch 0/1900 loss 308.417328 loss_att 274.508881 loss_ctc 335.424561 loss_rnnt 309.899048 hw_loss 0.318562 lr 0.00007604 rank 1
2023-02-11 00:56:02,032 DEBUG TRAIN Batch 0/1900 loss 353.332031 loss_att 313.432190 loss_ctc 379.113495 loss_rnnt 354.430908 hw_loss 0.645670 lr 0.00007604 rank 0
2023-02-11 00:56:02,033 DEBUG TRAIN Batch 0/1900 loss 163.300247 loss_att 143.077835 loss_ctc 173.641251 loss_rnnt 160.451111 hw_loss 1.034031 lr 0.00007604 rank 7
2023-02-11 00:56:02,034 DEBUG TRAIN Batch 0/1900 loss 88.460709 loss_att 73.917435 loss_ctc 87.826332 loss_rnnt 82.236191 hw_loss 1.728328 lr 0.00007604 rank 6
2023-02-11 00:56:02,037 DEBUG TRAIN Batch 0/1900 loss 191.153931 loss_att 169.668610 loss_ctc 202.496872 loss_rnnt 189.212326 hw_loss 0.886175 lr 0.00007604 rank 2
2023-02-11 00:56:02,037 DEBUG TRAIN Batch 0/1900 loss 227.381195 loss_att 200.897568 loss_ctc 244.275269 loss_rnnt 225.249008 hw_loss 0.970573 lr 0.00007604 rank 5
2023-02-11 00:56:02,038 DEBUG TRAIN Batch 0/1900 loss 148.112411 loss_att 131.603546 loss_ctc 156.937927 loss_rnnt 146.077713 hw_loss 0.779950 lr 0.00007604 rank 4
2023-02-11 00:57:16,769 DEBUG TRAIN Batch 0/2000 loss 257.342224 loss_att 230.496552 loss_ctc 278.670532 loss_rnnt 257.094574 hw_loss 0.519943 lr 0.00008004 rank 0
2023-02-11 00:57:16,769 DEBUG TRAIN Batch 0/2000 loss 317.754822 loss_att 281.531433 loss_ctc 341.768799 loss_rnnt 318.798767 hw_loss 0.562293 lr 0.00008004 rank 7
2023-02-11 00:57:16,770 DEBUG TRAIN Batch 0/2000 loss 338.083160 loss_att 298.811493 loss_ctc 358.519836 loss_rnnt 341.024841 hw_loss 0.410207 lr 0.00008004 rank 3
2023-02-11 00:57:16,771 DEBUG TRAIN Batch 0/2000 loss 389.430176 loss_att 347.993835 loss_ctc 431.588135 loss_rnnt 389.247040 hw_loss 0.534256 lr 0.00008004 rank 1
2023-02-11 00:57:16,773 DEBUG TRAIN Batch 0/2000 loss 256.426056 loss_att 228.901062 loss_ctc 280.402161 loss_rnnt 256.451782 hw_loss 0.427960 lr 0.00008004 rank 6
2023-02-11 00:57:16,776 DEBUG TRAIN Batch 0/2000 loss 297.261108 loss_att 263.238434 loss_ctc 325.218262 loss_rnnt 298.847900 hw_loss 0.279396 lr 0.00008004 rank 4
2023-02-11 00:57:16,777 DEBUG TRAIN Batch 0/2000 loss 329.929443 loss_att 291.983521 loss_ctc 354.687225 loss_rnnt 332.206665 hw_loss 0.377044 lr 0.00008004 rank 2
2023-02-11 00:57:16,780 DEBUG TRAIN Batch 0/2000 loss 316.720459 loss_att 283.276367 loss_ctc 360.822998 loss_rnnt 313.310394 hw_loss 0.790979 lr 0.00008004 rank 5
2023-02-11 00:58:35,445 DEBUG TRAIN Batch 0/2100 loss 303.505890 loss_att 270.947540 loss_ctc 327.069427 loss_rnnt 302.905457 hw_loss 0.744429 lr 0.00008404 rank 3
2023-02-11 00:58:35,446 DEBUG TRAIN Batch 0/2100 loss 304.406158 loss_att 269.912170 loss_ctc 327.071350 loss_rnnt 307.155609 hw_loss 0.211380 lr 0.00008404 rank 0
2023-02-11 00:58:35,448 DEBUG TRAIN Batch 0/2100 loss 348.858521 loss_att 309.965210 loss_ctc 374.238159 loss_rnnt 349.728821 hw_loss 0.660820 lr 0.00008404 rank 4
2023-02-11 00:58:35,449 DEBUG TRAIN Batch 0/2100 loss 278.420135 loss_att 247.613556 loss_ctc 307.197998 loss_rnnt 278.859222 hw_loss 0.353471 lr 0.00008404 rank 7
2023-02-11 00:58:35,450 DEBUG TRAIN Batch 0/2100 loss 301.280426 loss_att 265.311646 loss_ctc 324.096985 loss_rnnt 302.029022 hw_loss 0.638050 lr 0.00008404 rank 6
2023-02-11 00:58:35,453 DEBUG TRAIN Batch 0/2100 loss 305.035217 loss_att 273.348572 loss_ctc 328.852478 loss_rnnt 304.702606 hw_loss 0.655180 lr 0.00008404 rank 5
2023-02-11 00:58:35,453 DEBUG TRAIN Batch 0/2100 loss 267.279205 loss_att 231.516052 loss_ctc 282.636261 loss_rnnt 266.856720 hw_loss 1.036407 lr 0.00008404 rank 2
2023-02-11 00:58:35,461 DEBUG TRAIN Batch 0/2100 loss 321.296753 loss_att 285.190826 loss_ctc 351.592682 loss_rnnt 322.144226 hw_loss 0.437678 lr 0.00008404 rank 1
2023-02-11 00:59:52,564 DEBUG TRAIN Batch 0/2200 loss 318.186829 loss_att 278.616943 loss_ctc 344.554688 loss_rnnt 316.658142 hw_loss 1.111309 lr 0.00008804 rank 3
2023-02-11 00:59:52,566 DEBUG TRAIN Batch 0/2200 loss 266.537872 loss_att 235.401978 loss_ctc 299.223450 loss_rnnt 263.222900 hw_loss 0.972014 lr 0.00008804 rank 5
2023-02-11 00:59:52,567 DEBUG TRAIN Batch 0/2200 loss 300.606812 loss_att 265.317749 loss_ctc 328.652893 loss_rnnt 301.052338 hw_loss 0.538648 lr 0.00008804 rank 1
2023-02-11 00:59:52,568 DEBUG TRAIN Batch 0/2200 loss 329.951385 loss_att 292.420654 loss_ctc 350.692993 loss_rnnt 331.563293 hw_loss 0.586630 lr 0.00008804 rank 7
2023-02-11 00:59:52,569 DEBUG TRAIN Batch 0/2200 loss 293.088806 loss_att 259.097626 loss_ctc 319.472534 loss_rnnt 290.708405 hw_loss 1.061400 lr 0.00008804 rank 0
2023-02-11 00:59:52,573 DEBUG TRAIN Batch 0/2200 loss 307.103607 loss_att 270.177002 loss_ctc 325.802551 loss_rnnt 309.828064 hw_loss 0.406438 lr 0.00008804 rank 4
2023-02-11 00:59:52,573 DEBUG TRAIN Batch 0/2200 loss 345.267700 loss_att 306.215851 loss_ctc 369.790283 loss_rnnt 346.264252 hw_loss 0.664527 lr 0.00008804 rank 2
2023-02-11 00:59:52,618 DEBUG TRAIN Batch 0/2200 loss 273.005707 loss_att 240.309143 loss_ctc 292.903687 loss_rnnt 272.582825 hw_loss 0.807961 lr 0.00008804 rank 6
2023-02-11 01:01:08,214 DEBUG TRAIN Batch 0/2300 loss 281.270721 loss_att 248.146759 loss_ctc 298.286560 loss_rnnt 280.711304 hw_loss 0.921636 lr 0.00009204 rank 0
2023-02-11 01:01:08,216 DEBUG TRAIN Batch 0/2300 loss 298.787262 loss_att 267.030029 loss_ctc 327.472504 loss_rnnt 299.507202 hw_loss 0.338777 lr 0.00009204 rank 3
2023-02-11 01:01:08,218 DEBUG TRAIN Batch 0/2300 loss 298.292023 loss_att 266.182129 loss_ctc 332.584991 loss_rnnt 297.284729 hw_loss 0.535668 lr 0.00009204 rank 2
2023-02-11 01:01:08,219 DEBUG TRAIN Batch 0/2300 loss 291.034821 loss_att 257.292786 loss_ctc 318.068176 loss_rnnt 291.139587 hw_loss 0.569848 lr 0.00009204 rank 7
2023-02-11 01:01:08,220 DEBUG TRAIN Batch 0/2300 loss 257.316711 loss_att 225.703125 loss_ctc 278.645874 loss_rnnt 257.152832 hw_loss 0.683004 lr 0.00009204 rank 6
2023-02-11 01:01:08,222 DEBUG TRAIN Batch 0/2300 loss 261.521179 loss_att 232.457245 loss_ctc 287.856232 loss_rnnt 261.384583 hw_loss 0.457130 lr 0.00009204 rank 1
2023-02-11 01:01:08,223 DEBUG TRAIN Batch 0/2300 loss 322.846649 loss_att 287.799225 loss_ctc 353.191711 loss_rnnt 322.078613 hw_loss 0.699651 lr 0.00009204 rank 5
2023-02-11 01:01:08,270 DEBUG TRAIN Batch 0/2300 loss 300.482361 loss_att 267.088318 loss_ctc 324.645325 loss_rnnt 300.065247 hw_loss 0.726412 lr 0.00009204 rank 4
2023-02-11 01:02:25,643 DEBUG TRAIN Batch 0/2400 loss 234.181305 loss_att 209.141891 loss_ctc 253.537476 loss_rnnt 232.271118 hw_loss 0.813232 lr 0.00009604 rank 3
2023-02-11 01:02:25,649 DEBUG TRAIN Batch 0/2400 loss 265.374512 loss_att 235.320953 loss_ctc 286.831421 loss_rnnt 263.533691 hw_loss 0.935735 lr 0.00009604 rank 5
2023-02-11 01:02:25,652 DEBUG TRAIN Batch 0/2400 loss 170.749893 loss_att 151.186157 loss_ctc 185.316742 loss_rnnt 169.318939 hw_loss 0.637775 lr 0.00009604 rank 1
2023-02-11 01:02:25,657 DEBUG TRAIN Batch 0/2400 loss 261.140869 loss_att 233.936218 loss_ctc 286.637146 loss_rnnt 259.889893 hw_loss 0.617329 lr 0.00009604 rank 0
2023-02-11 01:02:25,658 DEBUG TRAIN Batch 0/2400 loss 259.797913 loss_att 229.580780 loss_ctc 278.759766 loss_rnnt 259.248108 hw_loss 0.762187 lr 0.00009604 rank 2
2023-02-11 01:02:25,673 DEBUG TRAIN Batch 0/2400 loss 255.194122 loss_att 227.734802 loss_ctc 273.263977 loss_rnnt 252.532852 hw_loss 1.076964 lr 0.00009604 rank 7
2023-02-11 01:02:25,679 DEBUG TRAIN Batch 0/2400 loss 275.103912 loss_att 243.185303 loss_ctc 301.128479 loss_rnnt 271.941895 hw_loss 1.139212 lr 0.00009604 rank 4
2023-02-11 01:02:25,684 DEBUG TRAIN Batch 0/2400 loss 240.847305 loss_att 216.660568 loss_ctc 255.674683 loss_rnnt 240.111237 hw_loss 0.674327 lr 0.00009604 rank 6
2023-02-11 01:03:45,460 DEBUG TRAIN Batch 0/2500 loss 224.745956 loss_att 203.346863 loss_ctc 244.654495 loss_rnnt 222.619370 hw_loss 0.703487 lr 0.00010004 rank 5
2023-02-11 01:03:45,464 DEBUG TRAIN Batch 0/2500 loss 208.805084 loss_att 185.966599 loss_ctc 225.906693 loss_rnnt 207.025131 hw_loss 0.762647 lr 0.00010004 rank 3
2023-02-11 01:03:45,465 DEBUG TRAIN Batch 0/2500 loss 242.558990 loss_att 216.253311 loss_ctc 260.624573 loss_rnnt 242.555328 hw_loss 0.535508 lr 0.00010004 rank 7
2023-02-11 01:03:45,467 DEBUG TRAIN Batch 0/2500 loss 198.346863 loss_att 178.740784 loss_ctc 214.156601 loss_rnnt 195.782928 hw_loss 0.820725 lr 0.00010004 rank 2
2023-02-11 01:03:45,467 DEBUG TRAIN Batch 0/2500 loss 313.719482 loss_att 279.491211 loss_ctc 339.598999 loss_rnnt 313.033905 hw_loss 0.765124 lr 0.00010004 rank 1
2023-02-11 01:03:45,467 DEBUG TRAIN Batch 0/2500 loss 117.729080 loss_att 104.500305 loss_ctc 128.431992 loss_rnnt 115.138527 hw_loss 0.714232 lr 0.00010004 rank 0
2023-02-11 01:03:45,469 DEBUG TRAIN Batch 0/2500 loss 228.880936 loss_att 206.196365 loss_ctc 254.917877 loss_rnnt 226.402664 hw_loss 0.664421 lr 0.00010004 rank 4
2023-02-11 01:03:45,469 DEBUG TRAIN Batch 0/2500 loss 103.142113 loss_att 87.189583 loss_ctc 105.444214 loss_rnnt 96.426682 hw_loss 1.799812 lr 0.00010004 rank 6
2023-02-11 01:05:02,593 DEBUG TRAIN Batch 0/2600 loss 290.435577 loss_att 265.892487 loss_ctc 317.261414 loss_rnnt 288.686920 hw_loss 0.577589 lr 0.00010404 rank 1
2023-02-11 01:05:02,594 DEBUG TRAIN Batch 0/2600 loss 302.299225 loss_att 272.526642 loss_ctc 332.039520 loss_rnnt 299.864929 hw_loss 0.829391 lr 0.00010404 rank 6
2023-02-11 01:05:02,594 DEBUG TRAIN Batch 0/2600 loss 272.807678 loss_att 243.905426 loss_ctc 290.707214 loss_rnnt 269.951324 hw_loss 1.171909 lr 0.00010404 rank 3
2023-02-11 01:05:02,595 DEBUG TRAIN Batch 0/2600 loss 329.801361 loss_att 297.322113 loss_ctc 359.719452 loss_rnnt 328.715027 hw_loss 0.673708 lr 0.00010404 rank 0
2023-02-11 01:05:02,596 DEBUG TRAIN Batch 0/2600 loss 101.176208 loss_att 87.086281 loss_ctc 104.416534 loss_rnnt 95.127525 hw_loss 1.581494 lr 0.00010404 rank 7
2023-02-11 01:05:02,596 DEBUG TRAIN Batch 0/2600 loss 352.431091 loss_att 318.993622 loss_ctc 377.937866 loss_rnnt 352.319672 hw_loss 0.637129 lr 0.00010404 rank 2
2023-02-11 01:05:02,601 DEBUG TRAIN Batch 0/2600 loss 114.033615 loss_att 100.246956 loss_ctc 124.623489 loss_rnnt 111.642494 hw_loss 0.700589 lr 0.00010404 rank 5
2023-02-11 01:05:02,647 DEBUG TRAIN Batch 0/2600 loss 129.895218 loss_att 114.657471 loss_ctc 135.735382 loss_rnnt 125.822388 hw_loss 1.189067 lr 0.00010404 rank 4
2023-02-11 01:06:19,540 DEBUG TRAIN Batch 0/2700 loss 284.354156 loss_att 262.254578 loss_ctc 305.126953 loss_rnnt 284.422729 hw_loss 0.296557 lr 0.00010804 rank 2
2023-02-11 01:06:19,541 DEBUG TRAIN Batch 0/2700 loss 290.119415 loss_att 264.466125 loss_ctc 315.489716 loss_rnnt 288.653534 hw_loss 0.602594 lr 0.00010804 rank 3
2023-02-11 01:06:19,545 DEBUG TRAIN Batch 0/2700 loss 286.326233 loss_att 259.779114 loss_ctc 304.409241 loss_rnnt 285.838409 hw_loss 0.634910 lr 0.00010804 rank 6
2023-02-11 01:06:19,546 DEBUG TRAIN Batch 0/2700 loss 241.702728 loss_att 219.472168 loss_ctc 254.436264 loss_rnnt 240.188232 hw_loss 0.799273 lr 0.00010804 rank 7
2023-02-11 01:06:19,547 DEBUG TRAIN Batch 0/2700 loss 325.505157 loss_att 294.669922 loss_ctc 350.879639 loss_rnnt 325.339233 hw_loss 0.553071 lr 0.00010804 rank 0
2023-02-11 01:06:19,550 DEBUG TRAIN Batch 0/2700 loss 321.509674 loss_att 296.727722 loss_ctc 345.874603 loss_rnnt 319.975952 hw_loss 0.607774 lr 0.00010804 rank 5
2023-02-11 01:06:19,551 DEBUG TRAIN Batch 0/2700 loss 310.878448 loss_att 281.250671 loss_ctc 335.405487 loss_rnnt 310.248016 hw_loss 0.616074 lr 0.00010804 rank 4
2023-02-11 01:06:19,593 DEBUG TRAIN Batch 0/2700 loss 255.866043 loss_att 234.808212 loss_ctc 280.265808 loss_rnnt 252.172897 hw_loss 0.872139 lr 0.00010804 rank 1
2023-02-11 01:07:36,360 DEBUG TRAIN Batch 0/2800 loss 256.801544 loss_att 241.384979 loss_ctc 272.833496 loss_rnnt 256.445038 hw_loss 0.244167 lr 0.00011204 rank 3
2023-02-11 01:07:36,361 DEBUG TRAIN Batch 0/2800 loss 280.348480 loss_att 256.792236 loss_ctc 301.251801 loss_rnnt 279.872498 hw_loss 0.450021 lr 0.00011204 rank 1
2023-02-11 01:07:36,364 DEBUG TRAIN Batch 0/2800 loss 276.949280 loss_att 251.429993 loss_ctc 296.542297 loss_rnnt 276.795654 hw_loss 0.495946 lr 0.00011204 rank 0
2023-02-11 01:07:36,366 DEBUG TRAIN Batch 0/2800 loss 317.080170 loss_att 288.763458 loss_ctc 346.866272 loss_rnnt 316.893066 hw_loss 0.352307 lr 0.00011204 rank 2
2023-02-11 01:07:36,366 DEBUG TRAIN Batch 0/2800 loss 255.739883 loss_att 234.874817 loss_ctc 273.458893 loss_rnnt 253.351349 hw_loss 0.787312 lr 0.00011204 rank 7
2023-02-11 01:07:36,370 DEBUG TRAIN Batch 0/2800 loss 271.458191 loss_att 249.099060 loss_ctc 292.311737 loss_rnnt 270.942108 hw_loss 0.413896 lr 0.00011204 rank 4
2023-02-11 01:07:36,372 DEBUG TRAIN Batch 0/2800 loss 313.852081 loss_att 291.798706 loss_ctc 345.961517 loss_rnnt 310.700500 hw_loss 0.615192 lr 0.00011204 rank 5
2023-02-11 01:07:36,409 DEBUG TRAIN Batch 0/2800 loss 269.623352 loss_att 247.939987 loss_ctc 295.882202 loss_rnnt 268.540558 hw_loss 0.359671 lr 0.00011204 rank 6
2023-02-11 01:08:53,362 DEBUG TRAIN Batch 0/2900 loss 238.094864 loss_att 224.136993 loss_ctc 255.749023 loss_rnnt 234.551361 hw_loss 0.746473 lr 0.00011604 rank 7
2023-02-11 01:08:53,363 DEBUG TRAIN Batch 0/2900 loss 293.600281 loss_att 271.701782 loss_ctc 313.717987 loss_rnnt 291.949127 hw_loss 0.627836 lr 0.00011604 rank 3
2023-02-11 01:08:53,363 DEBUG TRAIN Batch 0/2900 loss 233.198395 loss_att 221.449493 loss_ctc 258.933716 loss_rnnt 230.158829 hw_loss 0.367120 lr 0.00011604 rank 6
2023-02-11 01:08:53,364 DEBUG TRAIN Batch 0/2900 loss 267.204773 loss_att 248.644440 loss_ctc 290.094910 loss_rnnt 263.389832 hw_loss 0.839060 lr 0.00011604 rank 0
2023-02-11 01:08:53,364 DEBUG TRAIN Batch 0/2900 loss 249.833389 loss_att 237.194733 loss_ctc 268.192352 loss_rnnt 245.788544 hw_loss 0.773389 lr 0.00011604 rank 4
2023-02-11 01:08:53,365 DEBUG TRAIN Batch 0/2900 loss 245.456299 loss_att 226.737976 loss_ctc 265.874512 loss_rnnt 243.188629 hw_loss 0.616668 lr 0.00011604 rank 1
2023-02-11 01:08:53,365 DEBUG TRAIN Batch 0/2900 loss 265.028748 loss_att 247.290390 loss_ctc 284.021637 loss_rnnt 262.304291 hw_loss 0.701205 lr 0.00011604 rank 2
2023-02-11 01:08:53,367 DEBUG TRAIN Batch 0/2900 loss 278.292023 loss_att 257.480957 loss_ctc 297.420532 loss_rnnt 276.490967 hw_loss 0.639899 lr 0.00011604 rank 5
2023-02-11 01:10:08,802 DEBUG TRAIN Batch 0/3000 loss 217.685181 loss_att 208.047516 loss_ctc 230.391891 loss_rnnt 214.603561 hw_loss 0.621552 lr 0.00012004 rank 1
2023-02-11 01:10:08,805 DEBUG TRAIN Batch 0/3000 loss 260.947784 loss_att 244.876556 loss_ctc 280.052490 loss_rnnt 259.369995 hw_loss 0.420894 lr 0.00012004 rank 3
2023-02-11 01:10:08,805 DEBUG TRAIN Batch 0/3000 loss 243.990005 loss_att 235.243256 loss_ctc 262.874146 loss_rnnt 240.573151 hw_loss 0.496554 lr 0.00012004 rank 2
2023-02-11 01:10:08,806 DEBUG TRAIN Batch 0/3000 loss 279.563568 loss_att 262.042603 loss_ctc 302.659241 loss_rnnt 276.475250 hw_loss 0.658701 lr 0.00012004 rank 5
2023-02-11 01:10:08,807 DEBUG TRAIN Batch 0/3000 loss 267.084473 loss_att 248.805832 loss_ctc 293.857361 loss_rnnt 261.932739 hw_loss 0.982068 lr 0.00012004 rank 0
2023-02-11 01:10:08,808 DEBUG TRAIN Batch 0/3000 loss 263.770813 loss_att 252.329285 loss_ctc 286.873169 loss_rnnt 258.394623 hw_loss 0.859538 lr 0.00012004 rank 7
2023-02-11 01:10:08,811 DEBUG TRAIN Batch 0/3000 loss 250.220840 loss_att 230.059082 loss_ctc 274.692993 loss_rnnt 247.199295 hw_loss 0.710801 lr 0.00012004 rank 4
2023-02-11 01:10:08,856 DEBUG TRAIN Batch 0/3000 loss 292.413971 loss_att 273.413208 loss_ctc 300.975220 loss_rnnt 289.151306 hw_loss 1.110243 lr 0.00012004 rank 6
2023-02-11 01:11:24,220 DEBUG TRAIN Batch 0/3100 loss 137.112106 loss_att 130.219666 loss_ctc 147.671997 loss_rnnt 132.461304 hw_loss 0.866498 lr 0.00012404 rank 0
2023-02-11 01:11:24,226 DEBUG TRAIN Batch 0/3100 loss 261.312744 loss_att 253.648254 loss_ctc 281.033264 loss_rnnt 256.515991 hw_loss 0.693797 lr 0.00012404 rank 1
2023-02-11 01:11:24,226 DEBUG TRAIN Batch 0/3100 loss 220.557678 loss_att 206.539398 loss_ctc 233.601837 loss_rnnt 218.980988 hw_loss 0.495210 lr 0.00012404 rank 3
2023-02-11 01:11:24,227 DEBUG TRAIN Batch 0/3100 loss 262.331360 loss_att 252.900299 loss_ctc 275.500580 loss_rnnt 258.989014 hw_loss 0.651120 lr 0.00012404 rank 7
2023-02-11 01:11:24,227 DEBUG TRAIN Batch 0/3100 loss 151.311462 loss_att 145.093246 loss_ctc 158.768402 loss_rnnt 147.656219 hw_loss 0.732116 lr 0.00012404 rank 6
2023-02-11 01:11:24,227 DEBUG TRAIN Batch 0/3100 loss 263.031891 loss_att 252.398972 loss_ctc 276.498352 loss_rnnt 258.992798 hw_loss 0.819407 lr 0.00012404 rank 2
2023-02-11 01:11:24,229 DEBUG TRAIN Batch 0/3100 loss 201.358704 loss_att 193.768112 loss_ctc 211.719269 loss_rnnt 196.627518 hw_loss 0.912731 lr 0.00012404 rank 5
2023-02-11 01:11:24,232 DEBUG TRAIN Batch 0/3100 loss 226.521896 loss_att 218.179993 loss_ctc 243.003113 loss_rnnt 220.077148 hw_loss 1.109179 lr 0.00012404 rank 4
2023-02-11 01:12:43,732 DEBUG TRAIN Batch 0/3200 loss 320.914551 loss_att 305.629944 loss_ctc 335.283997 loss_rnnt 320.525513 hw_loss 0.286878 lr 0.00012804 rank 3
2023-02-11 01:12:43,732 DEBUG TRAIN Batch 0/3200 loss 165.126846 loss_att 160.865585 loss_ctc 168.608658 loss_rnnt 160.953812 hw_loss 0.855195 lr 0.00012804 rank 7
2023-02-11 01:12:43,732 DEBUG TRAIN Batch 0/3200 loss 121.849419 loss_att 117.956169 loss_ctc 123.625244 loss_rnnt 116.220894 hw_loss 1.156948 lr 0.00012804 rank 2
2023-02-11 01:12:43,734 DEBUG TRAIN Batch 0/3200 loss 227.796646 loss_att 227.403839 loss_ctc 228.560349 loss_rnnt 222.962555 hw_loss 0.902028 lr 0.00012804 rank 0
2023-02-11 01:12:43,734 DEBUG TRAIN Batch 0/3200 loss 97.041153 loss_att 90.361008 loss_ctc 98.364868 loss_rnnt 91.404457 hw_loss 1.274291 lr 0.00012804 rank 5
2023-02-11 01:12:43,740 DEBUG TRAIN Batch 0/3200 loss 276.498077 loss_att 271.479431 loss_ctc 286.691376 loss_rnnt 272.896027 hw_loss 0.608749 lr 0.00012804 rank 6
2023-02-11 01:12:43,744 DEBUG TRAIN Batch 0/3200 loss 269.925598 loss_att 275.675903 loss_ctc 279.114288 loss_rnnt 262.696167 hw_loss 0.910161 lr 0.00012804 rank 1
2023-02-11 01:12:43,787 DEBUG TRAIN Batch 0/3200 loss 163.769211 loss_att 157.542145 loss_ctc 166.912994 loss_rnnt 161.610764 hw_loss 0.559631 lr 0.00012804 rank 4
2023-02-11 01:14:00,536 DEBUG TRAIN Batch 0/3300 loss 292.912994 loss_att 290.842590 loss_ctc 298.079163 loss_rnnt 289.475189 hw_loss 0.593069 lr 0.00013204 rank 3
2023-02-11 01:14:00,538 DEBUG TRAIN Batch 0/3300 loss 287.378754 loss_att 290.695770 loss_ctc 287.503296 loss_rnnt 285.015381 hw_loss 0.315628 lr 0.00013204 rank 0
2023-02-11 01:14:00,539 DEBUG TRAIN Batch 0/3300 loss 254.515503 loss_att 252.934753 loss_ctc 257.208801 loss_rnnt 251.215546 hw_loss 0.610686 lr 0.00013204 rank 7
2023-02-11 01:14:00,540 DEBUG TRAIN Batch 0/3300 loss 244.956650 loss_att 258.231201 loss_ctc 242.260300 loss_rnnt 239.489624 hw_loss 0.594682 lr 0.00013204 rank 1
2023-02-11 01:14:00,540 DEBUG TRAIN Batch 0/3300 loss 270.950684 loss_att 273.525879 loss_ctc 284.588470 loss_rnnt 267.588623 hw_loss 0.192871 lr 0.00013204 rank 2
2023-02-11 01:14:00,543 DEBUG TRAIN Batch 0/3300 loss 230.972900 loss_att 245.646149 loss_ctc 238.398727 loss_rnnt 222.969528 hw_loss 0.764742 lr 0.00013204 rank 5
2023-02-11 01:14:00,545 DEBUG TRAIN Batch 0/3300 loss 260.547272 loss_att 259.785583 loss_ctc 268.291077 loss_rnnt 258.866913 hw_loss 0.150037 lr 0.00013204 rank 6
2023-02-11 01:14:00,547 DEBUG TRAIN Batch 0/3300 loss 275.380402 loss_att 284.319702 loss_ctc 282.072784 loss_rnnt 269.616699 hw_loss 0.578161 lr 0.00013204 rank 4
2023-02-11 01:15:17,083 DEBUG TRAIN Batch 0/3400 loss 218.836823 loss_att 233.077179 loss_ctc 221.851776 loss_rnnt 212.283905 hw_loss 0.619286 lr 0.00013604 rank 7
2023-02-11 01:15:17,086 DEBUG TRAIN Batch 0/3400 loss 295.503998 loss_att 300.526459 loss_ctc 303.095947 loss_rnnt 290.420471 hw_loss 0.575022 lr 0.00013604 rank 3
2023-02-11 01:15:17,089 DEBUG TRAIN Batch 0/3400 loss 258.472107 loss_att 262.928009 loss_ctc 264.078674 loss_rnnt 252.173935 hw_loss 0.873649 lr 0.00013604 rank 0
2023-02-11 01:15:17,090 DEBUG TRAIN Batch 0/3400 loss 283.303467 loss_att 278.719421 loss_ctc 289.692505 loss_rnnt 280.930267 hw_loss 0.457153 lr 0.00013604 rank 6
2023-02-11 01:15:17,091 DEBUG TRAIN Batch 0/3400 loss 222.536453 loss_att 236.749512 loss_ctc 234.290207 loss_rnnt 214.511505 hw_loss 0.677847 lr 0.00013604 rank 4
2023-02-11 01:15:17,093 DEBUG TRAIN Batch 0/3400 loss 259.515106 loss_att 266.735474 loss_ctc 265.073334 loss_rnnt 252.857239 hw_loss 0.838629 lr 0.00013604 rank 2
2023-02-11 01:15:17,093 DEBUG TRAIN Batch 0/3400 loss 226.343887 loss_att 237.527069 loss_ctc 230.739059 loss_rnnt 220.687134 hw_loss 0.531389 lr 0.00013604 rank 5
2023-02-11 01:15:17,095 DEBUG TRAIN Batch 0/3400 loss 254.436111 loss_att 261.890472 loss_ctc 260.370087 loss_rnnt 249.705292 hw_loss 0.459145 lr 0.00013604 rank 1
2023-02-11 01:16:34,715 DEBUG TRAIN Batch 0/3500 loss 251.597687 loss_att 263.124664 loss_ctc 253.515533 loss_rnnt 246.446960 hw_loss 0.485552 lr 0.00014004 rank 0
2023-02-11 01:16:34,716 DEBUG TRAIN Batch 0/3500 loss 251.699570 loss_att 270.057861 loss_ctc 254.872543 loss_rnnt 242.937744 hw_loss 0.875080 lr 0.00014004 rank 7
2023-02-11 01:16:34,718 DEBUG TRAIN Batch 0/3500 loss 220.173950 loss_att 237.282471 loss_ctc 225.293030 loss_rnnt 212.378021 hw_loss 0.692191 lr 0.00014004 rank 3
2023-02-11 01:16:34,718 DEBUG TRAIN Batch 0/3500 loss 237.766602 loss_att 246.925140 loss_ctc 240.079697 loss_rnnt 230.957458 hw_loss 0.875444 lr 0.00014004 rank 2
2023-02-11 01:16:34,720 DEBUG TRAIN Batch 0/3500 loss 234.072464 loss_att 247.018768 loss_ctc 237.798096 loss_rnnt 227.241562 hw_loss 0.702167 lr 0.00014004 rank 5
2023-02-11 01:16:34,720 DEBUG TRAIN Batch 0/3500 loss 211.380295 loss_att 229.931564 loss_ctc 208.494308 loss_rnnt 204.369110 hw_loss 0.691079 lr 0.00014004 rank 1
2023-02-11 01:16:34,722 DEBUG TRAIN Batch 0/3500 loss 217.094284 loss_att 235.537186 loss_ctc 214.287964 loss_rnnt 211.286011 hw_loss 0.467597 lr 0.00014004 rank 6
2023-02-11 01:16:34,726 DEBUG TRAIN Batch 0/3500 loss 256.878418 loss_att 262.225464 loss_ctc 263.151062 loss_rnnt 252.678253 hw_loss 0.430196 lr 0.00014004 rank 4
2023-02-11 01:17:53,849 DEBUG TRAIN Batch 0/3600 loss 202.959061 loss_att 223.970749 loss_ctc 194.718719 loss_rnnt 197.601227 hw_loss 0.422663 lr 0.00014404 rank 3
2023-02-11 01:17:53,854 DEBUG TRAIN Batch 0/3600 loss 219.307617 loss_att 229.245758 loss_ctc 220.280060 loss_rnnt 213.106384 hw_loss 0.765739 lr 0.00014404 rank 0
2023-02-11 01:17:53,855 DEBUG TRAIN Batch 0/3600 loss 228.537277 loss_att 243.249481 loss_ctc 224.182953 loss_rnnt 220.872726 hw_loss 0.994254 lr 0.00014404 rank 6
2023-02-11 01:17:53,856 DEBUG TRAIN Batch 0/3600 loss 273.154663 loss_att 288.826080 loss_ctc 287.040955 loss_rnnt 264.809082 hw_loss 0.629963 lr 0.00014404 rank 7
2023-02-11 01:17:53,857 DEBUG TRAIN Batch 0/3600 loss 229.213593 loss_att 242.556717 loss_ctc 229.128876 loss_rnnt 223.304382 hw_loss 0.609724 lr 0.00014404 rank 4
2023-02-11 01:17:53,860 DEBUG TRAIN Batch 0/3600 loss 216.496704 loss_att 231.625748 loss_ctc 219.138092 loss_rnnt 211.843597 hw_loss 0.239085 lr 0.00014404 rank 5
2023-02-11 01:17:53,861 DEBUG TRAIN Batch 0/3600 loss 204.265808 loss_att 230.153854 loss_ctc 204.294876 loss_rnnt 198.334900 hw_loss 0.140517 lr 0.00014404 rank 2
2023-02-11 01:17:53,903 DEBUG TRAIN Batch 0/3600 loss 235.675964 loss_att 242.670853 loss_ctc 242.915283 loss_rnnt 230.093277 hw_loss 0.603460 lr 0.00014404 rank 1
2023-02-11 01:19:10,942 DEBUG TRAIN Batch 0/3700 loss 236.763885 loss_att 237.632172 loss_ctc 243.764145 loss_rnnt 229.118881 hw_loss 1.225867 lr 0.00014804 rank 7
2023-02-11 01:19:10,945 DEBUG TRAIN Batch 0/3700 loss 165.575684 loss_att 198.760559 loss_ctc 163.153168 loss_rnnt 156.461334 hw_loss 0.525070 lr 0.00014804 rank 3
2023-02-11 01:19:10,945 DEBUG TRAIN Batch 0/3700 loss 152.138382 loss_att 172.301605 loss_ctc 147.094772 loss_rnnt 145.053711 hw_loss 0.698345 lr 0.00014804 rank 0
2023-02-11 01:19:10,950 DEBUG TRAIN Batch 0/3700 loss 159.183899 loss_att 178.855621 loss_ctc 157.987778 loss_rnnt 153.852234 hw_loss 0.291901 lr 0.00014804 rank 6
2023-02-11 01:19:10,951 DEBUG TRAIN Batch 0/3700 loss 176.390366 loss_att 200.692368 loss_ctc 178.729523 loss_rnnt 167.612396 hw_loss 0.676068 lr 0.00014804 rank 5
2023-02-11 01:19:10,952 DEBUG TRAIN Batch 0/3700 loss 192.523834 loss_att 214.209641 loss_ctc 188.005447 loss_rnnt 184.299240 hw_loss 0.841856 lr 0.00014804 rank 2
2023-02-11 01:19:10,954 DEBUG TRAIN Batch 0/3700 loss 196.419373 loss_att 226.540985 loss_ctc 184.431015 loss_rnnt 186.716064 hw_loss 0.989516 lr 0.00014804 rank 4
2023-02-11 01:19:10,997 DEBUG TRAIN Batch 0/3700 loss 153.674072 loss_att 167.904800 loss_ctc 157.350861 loss_rnnt 146.021652 hw_loss 0.809259 lr 0.00014804 rank 1
2023-02-11 01:20:27,892 DEBUG TRAIN Batch 0/3800 loss 224.842621 loss_att 253.250153 loss_ctc 228.899597 loss_rnnt 216.079407 hw_loss 0.476395 lr 0.00015204 rank 0
2023-02-11 01:20:27,894 DEBUG TRAIN Batch 0/3800 loss 92.058220 loss_att 95.351700 loss_ctc 89.697472 loss_rnnt 84.657364 hw_loss 1.323173 lr 0.00015204 rank 2
2023-02-11 01:20:27,895 DEBUG TRAIN Batch 0/3800 loss 180.700943 loss_att 192.848206 loss_ctc 178.828369 loss_rnnt 172.471237 hw_loss 1.134360 lr 0.00015204 rank 4
2023-02-11 01:20:27,894 DEBUG TRAIN Batch 0/3800 loss 268.836182 loss_att 296.327179 loss_ctc 272.127869 loss_rnnt 260.973236 hw_loss 0.361102 lr 0.00015204 rank 1
2023-02-11 01:20:27,895 DEBUG TRAIN Batch 0/3800 loss 107.835098 loss_att 113.544678 loss_ctc 104.677292 loss_rnnt 102.029472 hw_loss 0.953393 lr 0.00015204 rank 3
2023-02-11 01:20:27,895 DEBUG TRAIN Batch 0/3800 loss 177.265808 loss_att 197.785583 loss_ctc 176.274658 loss_rnnt 168.694458 hw_loss 0.862410 lr 0.00015204 rank 7
2023-02-11 01:20:27,895 DEBUG TRAIN Batch 0/3800 loss 267.993988 loss_att 282.696808 loss_ctc 276.278931 loss_rnnt 262.719360 hw_loss 0.230515 lr 0.00015204 rank 5
2023-02-11 01:20:27,900 DEBUG TRAIN Batch 0/3800 loss 208.453094 loss_att 245.852859 loss_ctc 202.128479 loss_rnnt 199.653839 hw_loss 0.405485 lr 0.00015204 rank 6
2023-02-11 01:21:46,066 DEBUG TRAIN Batch 0/3900 loss 199.864090 loss_att 234.478271 loss_ctc 200.646698 loss_rnnt 191.038055 hw_loss 0.337287 lr 0.00015604 rank 7
2023-02-11 01:21:46,068 DEBUG TRAIN Batch 0/3900 loss 241.666443 loss_att 270.034088 loss_ctc 240.070251 loss_rnnt 235.288452 hw_loss 0.171992 lr 0.00015604 rank 0
2023-02-11 01:21:46,068 DEBUG TRAIN Batch 0/3900 loss 245.595108 loss_att 270.386108 loss_ctc 249.421066 loss_rnnt 234.481049 hw_loss 1.058575 lr 0.00015604 rank 6
2023-02-11 01:21:46,071 DEBUG TRAIN Batch 0/3900 loss 216.578766 loss_att 250.265091 loss_ctc 220.654877 loss_rnnt 205.924789 hw_loss 0.632481 lr 0.00015604 rank 1
2023-02-11 01:21:46,074 DEBUG TRAIN Batch 0/3900 loss 218.137833 loss_att 268.111328 loss_ctc 207.131927 loss_rnnt 206.851166 hw_loss 0.517390 lr 0.00015604 rank 2
2023-02-11 01:21:46,074 DEBUG TRAIN Batch 0/3900 loss 281.301331 loss_att 310.281311 loss_ctc 275.577362 loss_rnnt 271.964813 hw_loss 0.806949 lr 0.00015604 rank 5
2023-02-11 01:21:46,074 DEBUG TRAIN Batch 0/3900 loss 233.454514 loss_att 287.039062 loss_ctc 229.951508 loss_rnnt 221.566010 hw_loss 0.307252 lr 0.00015604 rank 3
2023-02-11 01:21:46,078 DEBUG TRAIN Batch 0/3900 loss 292.463989 loss_att 345.839355 loss_ctc 283.559509 loss_rnnt 280.671844 hw_loss 0.432059 lr 0.00015604 rank 4
2023-02-11 01:23:04,606 DEBUG TRAIN Batch 0/4000 loss 217.334518 loss_att 242.902451 loss_ctc 222.431381 loss_rnnt 207.690887 hw_loss 0.721964 lr 0.00016004 rank 4
2023-02-11 01:23:04,607 DEBUG TRAIN Batch 0/4000 loss 215.733780 loss_att 274.216217 loss_ctc 209.559967 loss_rnnt 202.123535 hw_loss 0.513177 lr 0.00016004 rank 3
2023-02-11 01:23:04,608 DEBUG TRAIN Batch 0/4000 loss 200.091171 loss_att 253.984360 loss_ctc 192.607346 loss_rnnt 188.626190 hw_loss 0.315783 lr 0.00016004 rank 0
2023-02-11 01:23:04,609 DEBUG TRAIN Batch 0/4000 loss 190.003342 loss_att 224.354523 loss_ctc 187.753281 loss_rnnt 179.869125 hw_loss 0.668248 lr 0.00016004 rank 5
2023-02-11 01:23:04,612 DEBUG TRAIN Batch 0/4000 loss 218.141693 loss_att 261.474243 loss_ctc 218.526489 loss_rnnt 207.515289 hw_loss 0.357857 lr 0.00016004 rank 7
2023-02-11 01:23:04,612 DEBUG TRAIN Batch 0/4000 loss 185.257355 loss_att 231.872406 loss_ctc 167.646851 loss_rnnt 172.696381 hw_loss 1.047387 lr 0.00016004 rank 1
2023-02-11 01:23:04,612 DEBUG TRAIN Batch 0/4000 loss 234.302872 loss_att 278.085999 loss_ctc 229.589645 loss_rnnt 223.521851 hw_loss 0.497402 lr 0.00016004 rank 2
2023-02-11 01:23:04,666 DEBUG TRAIN Batch 0/4000 loss 195.083984 loss_att 233.511688 loss_ctc 200.696457 loss_rnnt 184.688568 hw_loss 0.367789 lr 0.00016004 rank 6
2023-02-11 01:24:21,014 DEBUG TRAIN Batch 0/4100 loss 198.655838 loss_att 253.627655 loss_ctc 196.103409 loss_rnnt 183.693512 hw_loss 0.807805 lr 0.00016404 rank 1
2023-02-11 01:24:21,017 DEBUG TRAIN Batch 0/4100 loss 215.244904 loss_att 273.638641 loss_ctc 218.264908 loss_rnnt 201.486237 hw_loss 0.314482 lr 0.00016404 rank 2
2023-02-11 01:24:21,018 DEBUG TRAIN Batch 0/4100 loss 184.267502 loss_att 229.878265 loss_ctc 183.695984 loss_rnnt 172.853973 hw_loss 0.443920 lr 0.00016404 rank 3
2023-02-11 01:24:21,019 DEBUG TRAIN Batch 0/4100 loss 229.706802 loss_att 269.767273 loss_ctc 217.108734 loss_rnnt 220.771973 hw_loss 0.487966 lr 0.00016404 rank 7
2023-02-11 01:24:21,019 DEBUG TRAIN Batch 0/4100 loss 226.815964 loss_att 273.479279 loss_ctc 218.156738 loss_rnnt 217.044403 hw_loss 0.298773 lr 0.00016404 rank 4
2023-02-11 01:24:21,020 DEBUG TRAIN Batch 0/4100 loss 193.494446 loss_att 234.539261 loss_ctc 185.511505 loss_rnnt 184.353363 hw_loss 0.374347 lr 0.00016404 rank 0
2023-02-11 01:24:21,022 DEBUG TRAIN Batch 0/4100 loss 179.159286 loss_att 217.868484 loss_ctc 181.892365 loss_rnnt 168.526825 hw_loss 0.473666 lr 0.00016404 rank 5
2023-02-11 01:24:21,063 DEBUG TRAIN Batch 0/4100 loss 207.945343 loss_att 254.809158 loss_ctc 209.106857 loss_rnnt 195.387299 hw_loss 0.568201 lr 0.00016404 rank 6
2023-02-11 01:25:38,653 DEBUG TRAIN Batch 0/4200 loss 181.815369 loss_att 226.286896 loss_ctc 177.606705 loss_rnnt 170.257202 hw_loss 0.604691 lr 0.00016804 rank 0
2023-02-11 01:25:38,656 DEBUG TRAIN Batch 0/4200 loss 210.779907 loss_att 245.818008 loss_ctc 202.199738 loss_rnnt 200.508789 hw_loss 0.826409 lr 0.00016804 rank 6
2023-02-11 01:25:38,656 DEBUG TRAIN Batch 0/4200 loss 209.533081 loss_att 248.662231 loss_ctc 203.924103 loss_rnnt 197.603928 hw_loss 0.909600 lr 0.00016804 rank 3
2023-02-11 01:25:38,657 DEBUG TRAIN Batch 0/4200 loss 203.387360 loss_att 245.430588 loss_ctc 197.157852 loss_rnnt 193.988724 hw_loss 0.341358 lr 0.00016804 rank 7
2023-02-11 01:25:38,657 DEBUG TRAIN Batch 0/4200 loss 195.382233 loss_att 241.485031 loss_ctc 187.109528 loss_rnnt 183.763062 hw_loss 0.656554 lr 0.00016804 rank 5
2023-02-11 01:25:38,659 DEBUG TRAIN Batch 0/4200 loss 192.751251 loss_att 236.555008 loss_ctc 190.751663 loss_rnnt 180.443192 hw_loss 0.715109 lr 0.00016804 rank 2
2023-02-11 01:25:38,661 DEBUG TRAIN Batch 0/4200 loss 188.409775 loss_att 229.176605 loss_ctc 185.727707 loss_rnnt 177.716827 hw_loss 0.543220 lr 0.00016804 rank 1
2023-02-11 01:25:38,667 DEBUG TRAIN Batch 0/4200 loss 168.295395 loss_att 219.575165 loss_ctc 163.283875 loss_rnnt 156.087097 hw_loss 0.491354 lr 0.00016804 rank 4
2023-02-11 01:26:57,737 DEBUG TRAIN Batch 0/4300 loss 183.522812 loss_att 233.572952 loss_ctc 182.687256 loss_rnnt 170.970581 hw_loss 0.497549 lr 0.00017204 rank 6
2023-02-11 01:26:57,737 DEBUG TRAIN Batch 0/4300 loss 172.215271 loss_att 222.147827 loss_ctc 171.727478 loss_rnnt 158.810791 hw_loss 0.653065 lr 0.00017204 rank 7
2023-02-11 01:26:57,739 DEBUG TRAIN Batch 0/4300 loss 131.778137 loss_att 162.358673 loss_ctc 128.720383 loss_rnnt 121.617424 hw_loss 0.834808 lr 0.00017204 rank 0
2023-02-11 01:26:57,743 DEBUG TRAIN Batch 0/4300 loss 163.459122 loss_att 228.807617 loss_ctc 159.526199 loss_rnnt 147.125229 hw_loss 0.710361 lr 0.00017204 rank 3
2023-02-11 01:26:57,745 DEBUG TRAIN Batch 0/4300 loss 174.880188 loss_att 219.900360 loss_ctc 167.192307 loss_rnnt 163.634995 hw_loss 0.612420 lr 0.00017204 rank 1
2023-02-11 01:26:57,745 DEBUG TRAIN Batch 0/4300 loss 182.092163 loss_att 238.312958 loss_ctc 170.433548 loss_rnnt 170.636292 hw_loss 0.331163 lr 0.00017204 rank 4
2023-02-11 01:26:57,747 DEBUG TRAIN Batch 0/4300 loss 129.617371 loss_att 173.417603 loss_ctc 124.961380 loss_rnnt 116.287102 hw_loss 0.973314 lr 0.00017204 rank 5
2023-02-11 01:26:57,785 DEBUG TRAIN Batch 0/4300 loss 173.809296 loss_att 228.926468 loss_ctc 173.289612 loss_rnnt 160.570267 hw_loss 0.428414 lr 0.00017204 rank 2
2023-02-11 01:28:16,021 DEBUG TRAIN Batch 0/4400 loss 64.931007 loss_att 77.190742 loss_ctc 63.362419 loss_rnnt 56.903313 hw_loss 1.084668 lr 0.00017604 rank 0
2023-02-11 01:28:16,023 DEBUG TRAIN Batch 0/4400 loss 220.558365 loss_att 307.721619 loss_ctc 220.247726 loss_rnnt 198.117859 hw_loss 0.946738 lr 0.00017604 rank 5
2023-02-11 01:28:16,023 DEBUG TRAIN Batch 0/4400 loss 151.721909 loss_att 209.849182 loss_ctc 140.375275 loss_rnnt 137.211594 hw_loss 0.824576 lr 0.00017604 rank 1
2023-02-11 01:28:16,023 DEBUG TRAIN Batch 0/4400 loss 127.706543 loss_att 156.578918 loss_ctc 125.079765 loss_rnnt 118.678894 hw_loss 0.675639 lr 0.00017604 rank 2
2023-02-11 01:28:16,029 DEBUG TRAIN Batch 0/4400 loss 149.812042 loss_att 192.366409 loss_ctc 152.198410 loss_rnnt 135.623459 hw_loss 1.004915 lr 0.00017604 rank 7
2023-02-11 01:28:16,031 DEBUG TRAIN Batch 0/4400 loss 131.824066 loss_att 174.212296 loss_ctc 120.509300 loss_rnnt 121.622452 hw_loss 0.606110 lr 0.00017604 rank 3
2023-02-11 01:28:16,033 DEBUG TRAIN Batch 0/4400 loss 142.493927 loss_att 184.929703 loss_ctc 148.302887 loss_rnnt 129.108551 hw_loss 0.773193 lr 0.00017604 rank 4
2023-02-11 01:28:16,074 DEBUG TRAIN Batch 0/4400 loss 120.906029 loss_att 149.944626 loss_ctc 119.317978 loss_rnnt 109.610016 hw_loss 1.068754 lr 0.00017604 rank 6
2023-02-11 01:29:33,188 DEBUG TRAIN Batch 0/4500 loss 206.008881 loss_att 260.301270 loss_ctc 206.488007 loss_rnnt 192.430222 hw_loss 0.498056 lr 0.00018004 rank 1
2023-02-11 01:29:33,188 DEBUG TRAIN Batch 0/4500 loss 173.862885 loss_att 208.617584 loss_ctc 162.732224 loss_rnnt 162.471191 hw_loss 1.110908 lr 0.00018004 rank 0
2023-02-11 01:29:33,189 DEBUG TRAIN Batch 0/4500 loss 177.755600 loss_att 243.374817 loss_ctc 172.735352 loss_rnnt 162.259140 hw_loss 0.570374 lr 0.00018004 rank 6
2023-02-11 01:29:33,189 DEBUG TRAIN Batch 0/4500 loss 70.474052 loss_att 85.403046 loss_ctc 68.657227 loss_rnnt 61.742760 hw_loss 1.122702 lr 0.00018004 rank 7
2023-02-11 01:29:33,194 DEBUG TRAIN Batch 0/4500 loss 138.581390 loss_att 191.284760 loss_ctc 139.297958 loss_rnnt 125.664169 hw_loss 0.427689 lr 0.00018004 rank 3
2023-02-11 01:29:33,196 DEBUG TRAIN Batch 0/4500 loss 229.690231 loss_att 289.608826 loss_ctc 225.546432 loss_rnnt 213.938095 hw_loss 0.810174 lr 0.00018004 rank 2
2023-02-11 01:29:33,196 DEBUG TRAIN Batch 0/4500 loss 186.957397 loss_att 257.146606 loss_ctc 181.174133 loss_rnnt 171.144821 hw_loss 0.477346 lr 0.00018004 rank 5
2023-02-11 01:29:33,244 DEBUG TRAIN Batch 0/4500 loss 106.370033 loss_att 129.790100 loss_ctc 102.636887 loss_rnnt 95.809074 hw_loss 1.195257 lr 0.00018004 rank 4
2023-02-11 01:30:51,481 DEBUG TRAIN Batch 0/4600 loss 123.220734 loss_att 193.571884 loss_ctc 113.239075 loss_rnnt 107.462219 hw_loss 0.566095 lr 0.00018404 rank 2
2023-02-11 01:30:51,484 DEBUG TRAIN Batch 0/4600 loss 154.437805 loss_att 241.337952 loss_ctc 151.132568 loss_rnnt 136.698181 hw_loss 0.150054 lr 0.00018404 rank 4
2023-02-11 01:30:51,484 DEBUG TRAIN Batch 0/4600 loss 189.162384 loss_att 254.048645 loss_ctc 184.892075 loss_rnnt 175.142075 hw_loss 0.302330 lr 0.00018404 rank 6
2023-02-11 01:30:51,485 DEBUG TRAIN Batch 0/4600 loss 173.999588 loss_att 239.466110 loss_ctc 169.348358 loss_rnnt 157.921188 hw_loss 0.675988 lr 0.00018404 rank 0
2023-02-11 01:30:51,485 DEBUG TRAIN Batch 0/4600 loss 210.319504 loss_att 269.586945 loss_ctc 203.186691 loss_rnnt 195.171143 hw_loss 0.796108 lr 0.00018404 rank 5
2023-02-11 01:30:51,485 DEBUG TRAIN Batch 0/4600 loss 197.406631 loss_att 275.271545 loss_ctc 196.264633 loss_rnnt 178.384018 hw_loss 0.675356 lr 0.00018404 rank 3
2023-02-11 01:30:51,487 DEBUG TRAIN Batch 0/4600 loss 181.196426 loss_att 263.966858 loss_ctc 179.301270 loss_rnnt 163.051178 hw_loss 0.345723 lr 0.00018404 rank 1
2023-02-11 01:30:51,489 DEBUG TRAIN Batch 0/4600 loss 186.792496 loss_att 265.793732 loss_ctc 176.843323 loss_rnnt 167.995605 hw_loss 0.810601 lr 0.00018404 rank 7
2023-02-11 01:32:07,214 DEBUG TRAIN Batch 0/4700 loss 137.219360 loss_att 198.285950 loss_ctc 122.410568 loss_rnnt 124.397934 hw_loss 0.484241 lr 0.00018804 rank 2
2023-02-11 01:32:07,216 DEBUG TRAIN Batch 0/4700 loss 169.630661 loss_att 238.145981 loss_ctc 174.284393 loss_rnnt 151.891190 hw_loss 0.640483 lr 0.00018804 rank 6
2023-02-11 01:32:07,220 DEBUG TRAIN Batch 0/4700 loss 186.440964 loss_att 247.775085 loss_ctc 189.254593 loss_rnnt 171.526917 hw_loss 0.426015 lr 0.00018804 rank 1
2023-02-11 01:32:07,222 DEBUG TRAIN Batch 0/4700 loss 184.494736 loss_att 271.825836 loss_ctc 179.394653 loss_rnnt 166.654602 hw_loss 0.197610 lr 0.00018804 rank 5
2023-02-11 01:32:07,224 DEBUG TRAIN Batch 0/4700 loss 176.149811 loss_att 233.825012 loss_ctc 172.914658 loss_rnnt 160.800568 hw_loss 0.796043 lr 0.00018804 rank 7
2023-02-11 01:32:07,224 DEBUG TRAIN Batch 0/4700 loss 160.416046 loss_att 247.192841 loss_ctc 146.539658 loss_rnnt 141.856537 hw_loss 0.572686 lr 0.00018804 rank 0
2023-02-11 01:32:07,225 DEBUG TRAIN Batch 0/4700 loss 197.503586 loss_att 289.069000 loss_ctc 184.551605 loss_rnnt 176.652100 hw_loss 0.799750 lr 0.00018804 rank 4
2023-02-11 01:32:07,226 DEBUG TRAIN Batch 0/4700 loss 153.492401 loss_att 212.057861 loss_ctc 148.361694 loss_rnnt 139.679077 hw_loss 0.522061 lr 0.00018804 rank 3
2023-02-11 01:33:22,000 DEBUG TRAIN Batch 0/4800 loss 193.483337 loss_att 251.321030 loss_ctc 198.909912 loss_rnnt 178.194717 hw_loss 0.562039 lr 0.00019204 rank 0
2023-02-11 01:33:22,003 DEBUG TRAIN Batch 0/4800 loss 140.045471 loss_att 214.546188 loss_ctc 126.645660 loss_rnnt 121.702965 hw_loss 0.980438 lr 0.00019204 rank 7
2023-02-11 01:33:22,007 DEBUG TRAIN Batch 0/4800 loss 130.888596 loss_att 214.714249 loss_ctc 128.201202 loss_rnnt 109.948288 hw_loss 0.850032 lr 0.00019204 rank 2
2023-02-11 01:33:22,006 DEBUG TRAIN Batch 0/4800 loss 169.748764 loss_att 245.859024 loss_ctc 165.246353 loss_rnnt 153.037079 hw_loss 0.391864 lr 0.00019204 rank 5
2023-02-11 01:33:22,008 DEBUG TRAIN Batch 0/4800 loss 123.909378 loss_att 198.097137 loss_ctc 120.198364 loss_rnnt 105.415489 hw_loss 0.778340 lr 0.00019204 rank 3
2023-02-11 01:33:22,009 DEBUG TRAIN Batch 0/4800 loss 157.354691 loss_att 223.831238 loss_ctc 152.573669 loss_rnnt 139.836700 hw_loss 0.911279 lr 0.00019204 rank 6
2023-02-11 01:33:22,010 DEBUG TRAIN Batch 0/4800 loss 135.274429 loss_att 205.954391 loss_ctc 118.218895 loss_rnnt 119.173782 hw_loss 0.794756 lr 0.00019204 rank 4
2023-02-11 01:33:22,059 DEBUG TRAIN Batch 0/4800 loss 146.895462 loss_att 224.106110 loss_ctc 144.308502 loss_rnnt 128.623627 hw_loss 0.595244 lr 0.00019204 rank 1
2023-02-11 01:34:40,534 DEBUG TRAIN Batch 0/4900 loss 165.978394 loss_att 256.066406 loss_ctc 158.572647 loss_rnnt 143.415222 hw_loss 1.037439 lr 0.00019604 rank 7
2023-02-11 01:34:40,534 DEBUG TRAIN Batch 0/4900 loss 120.000435 loss_att 177.370239 loss_ctc 114.460770 loss_rnnt 102.187729 hw_loss 1.327006 lr 0.00019604 rank 5
2023-02-11 01:34:40,537 DEBUG TRAIN Batch 0/4900 loss 181.488464 loss_att 265.827454 loss_ctc 171.940231 loss_rnnt 163.113953 hw_loss 0.521218 lr 0.00019604 rank 3
2023-02-11 01:34:40,538 DEBUG TRAIN Batch 0/4900 loss 157.249954 loss_att 220.900696 loss_ctc 154.736313 loss_rnnt 139.695679 hw_loss 0.967366 lr 0.00019604 rank 1
2023-02-11 01:34:40,538 DEBUG TRAIN Batch 0/4900 loss 120.092117 loss_att 197.720062 loss_ctc 106.483490 loss_rnnt 102.057800 hw_loss 0.810601 lr 0.00019604 rank 0
2023-02-11 01:34:40,543 DEBUG TRAIN Batch 0/4900 loss 186.932144 loss_att 257.731262 loss_ctc 186.702698 loss_rnnt 170.273499 hw_loss 0.474263 lr 0.00019604 rank 6
2023-02-11 01:34:40,543 DEBUG TRAIN Batch 0/4900 loss 145.192337 loss_att 218.225189 loss_ctc 150.447540 loss_rnnt 128.216248 hw_loss 0.312906 lr 0.00019604 rank 4
2023-02-11 01:34:40,545 DEBUG TRAIN Batch 0/4900 loss 164.555222 loss_att 227.341064 loss_ctc 159.236160 loss_rnnt 151.990356 hw_loss 0.134420 lr 0.00019604 rank 2
2023-02-11 01:35:58,828 DEBUG TRAIN Batch 0/5000 loss 187.551300 loss_att 246.342163 loss_ctc 186.481903 loss_rnnt 169.734375 hw_loss 1.162749 lr 0.00020004 rank 3
2023-02-11 01:35:58,829 DEBUG TRAIN Batch 0/5000 loss 130.880112 loss_att 195.536987 loss_ctc 125.046532 loss_rnnt 113.842827 hw_loss 0.915696 lr 0.00020004 rank 2
2023-02-11 01:35:58,830 DEBUG TRAIN Batch 0/5000 loss 119.961655 loss_att 165.607559 loss_ctc 118.295349 loss_rnnt 107.167114 hw_loss 0.728912 lr 0.00020004 rank 0
2023-02-11 01:35:58,831 DEBUG TRAIN Batch 0/5000 loss 37.803246 loss_att 39.859753 loss_ctc 35.732254 loss_rnnt 31.257027 hw_loss 1.202073 lr 0.00020004 rank 5
2023-02-11 01:35:58,831 DEBUG TRAIN Batch 0/5000 loss 128.565094 loss_att 183.098923 loss_ctc 123.140625 loss_rnnt 116.555260 hw_loss 0.342438 lr 0.00020004 rank 6
2023-02-11 01:35:58,831 DEBUG TRAIN Batch 0/5000 loss 128.219193 loss_att 204.443268 loss_ctc 123.972527 loss_rnnt 110.015533 hw_loss 0.660951 lr 0.00020004 rank 7
2023-02-11 01:35:58,835 DEBUG TRAIN Batch 0/5000 loss 150.838303 loss_att 217.373123 loss_ctc 149.956207 loss_rnnt 133.544983 hw_loss 0.769491 lr 0.00020004 rank 4
2023-02-11 01:35:58,837 DEBUG TRAIN Batch 0/5000 loss 164.037964 loss_att 253.891968 loss_ctc 156.703232 loss_rnnt 142.439484 hw_loss 0.863557 lr 0.00020004 rank 1
2023-02-11 01:37:16,216 DEBUG TRAIN Batch 0/5100 loss 101.809380 loss_att 140.784622 loss_ctc 103.285767 loss_rnnt 91.229980 hw_loss 0.485155 lr 0.00020404 rank 3
2023-02-11 01:37:16,219 DEBUG TRAIN Batch 0/5100 loss 70.681503 loss_att 99.048279 loss_ctc 67.108818 loss_rnnt 61.639828 hw_loss 0.720878 lr 0.00020404 rank 2
2023-02-11 01:37:16,219 DEBUG TRAIN Batch 0/5100 loss 200.122742 loss_att 287.105988 loss_ctc 195.830612 loss_rnnt 180.502487 hw_loss 0.524225 lr 0.00020404 rank 0
2023-02-11 01:37:16,222 DEBUG TRAIN Batch 0/5100 loss 147.127396 loss_att 236.849121 loss_ctc 131.173004 loss_rnnt 128.919830 hw_loss 0.448213 lr 0.00020404 rank 5
2023-02-11 01:37:16,222 DEBUG TRAIN Batch 0/5100 loss 190.997711 loss_att 246.565125 loss_ctc 193.220505 loss_rnnt 173.151031 hw_loss 1.206903 lr 0.00020404 rank 1
2023-02-11 01:37:16,225 DEBUG TRAIN Batch 0/5100 loss 188.400101 loss_att 290.399780 loss_ctc 184.276825 loss_rnnt 166.092743 hw_loss 0.460725 lr 0.00020404 rank 6
2023-02-11 01:37:16,225 DEBUG TRAIN Batch 0/5100 loss 74.832787 loss_att 92.930634 loss_ctc 76.264603 loss_rnnt 65.927780 hw_loss 0.955223 lr 0.00020404 rank 7
2023-02-11 01:37:16,266 DEBUG TRAIN Batch 0/5100 loss 122.234360 loss_att 179.107590 loss_ctc 121.718971 loss_rnnt 107.165604 hw_loss 0.705528 lr 0.00020404 rank 4
2023-02-11 01:38:32,425 DEBUG TRAIN Batch 0/5200 loss 144.737457 loss_att 237.079254 loss_ctc 135.539337 loss_rnnt 124.361656 hw_loss 0.587599 lr 0.00020804 rank 3
2023-02-11 01:38:32,429 DEBUG TRAIN Batch 0/5200 loss 167.290466 loss_att 233.181122 loss_ctc 170.332855 loss_rnnt 150.540604 hw_loss 0.593639 lr 0.00020804 rank 7
2023-02-11 01:38:32,428 DEBUG TRAIN Batch 0/5200 loss 145.811203 loss_att 233.009338 loss_ctc 143.588745 loss_rnnt 126.462448 hw_loss 0.413523 lr 0.00020804 rank 0
2023-02-11 01:38:32,431 DEBUG TRAIN Batch 0/5200 loss 162.397018 loss_att 268.355957 loss_ctc 157.491364 loss_rnnt 138.915924 hw_loss 0.551885 lr 0.00020804 rank 2
2023-02-11 01:38:32,431 DEBUG TRAIN Batch 0/5200 loss 172.597519 loss_att 258.843903 loss_ctc 174.188843 loss_rnnt 151.242554 hw_loss 0.730034 lr 0.00020804 rank 5
2023-02-11 01:38:32,435 DEBUG TRAIN Batch 0/5200 loss 216.076126 loss_att 307.135559 loss_ctc 215.823471 loss_rnnt 196.495483 hw_loss 0.262960 lr 0.00020804 rank 6
2023-02-11 01:38:32,435 DEBUG TRAIN Batch 0/5200 loss 154.396957 loss_att 249.890854 loss_ctc 146.257004 loss_rnnt 134.744247 hw_loss 0.307360 lr 0.00020804 rank 1
2023-02-11 01:38:32,436 DEBUG TRAIN Batch 0/5200 loss 138.427902 loss_att 229.598297 loss_ctc 136.622604 loss_rnnt 117.036682 hw_loss 0.637097 lr 0.00020804 rank 4
2023-02-11 01:39:49,806 DEBUG TRAIN Batch 0/5300 loss 150.156815 loss_att 239.229614 loss_ctc 143.803604 loss_rnnt 130.205963 hw_loss 0.559384 lr 0.00021204 rank 1
2023-02-11 01:39:49,807 DEBUG TRAIN Batch 0/5300 loss 135.442581 loss_att 221.306854 loss_ctc 133.544342 loss_rnnt 115.521042 hw_loss 0.562835 lr 0.00021204 rank 0
2023-02-11 01:39:49,808 DEBUG TRAIN Batch 0/5300 loss 134.499695 loss_att 222.405304 loss_ctc 121.521820 loss_rnnt 115.509148 hw_loss 0.588715 lr 0.00021204 rank 7
2023-02-11 01:39:49,813 DEBUG TRAIN Batch 0/5300 loss 152.693024 loss_att 256.073578 loss_ctc 149.260696 loss_rnnt 128.436462 hw_loss 0.757139 lr 0.00021204 rank 5
2023-02-11 01:39:49,814 DEBUG TRAIN Batch 0/5300 loss 152.487305 loss_att 231.074829 loss_ctc 152.714691 loss_rnnt 133.336823 hw_loss 0.638002 lr 0.00021204 rank 2
2023-02-11 01:39:49,815 DEBUG TRAIN Batch 0/5300 loss 157.028046 loss_att 243.282806 loss_ctc 152.821503 loss_rnnt 137.609344 hw_loss 0.511616 lr 0.00021204 rank 4
2023-02-11 01:39:49,816 DEBUG TRAIN Batch 0/5300 loss 150.630188 loss_att 242.049957 loss_ctc 152.344299 loss_rnnt 129.538040 hw_loss 0.483681 lr 0.00021204 rank 6
2023-02-11 01:39:49,839 DEBUG TRAIN Batch 0/5300 loss 125.679085 loss_att 244.558731 loss_ctc 113.969910 loss_rnnt 102.253159 hw_loss 0.227105 lr 0.00021204 rank 3
2023-02-11 01:41:07,463 DEBUG TRAIN Batch 0/5400 loss 153.274384 loss_att 247.360107 loss_ctc 147.578522 loss_rnnt 131.557724 hw_loss 0.686059 lr 0.00021604 rank 6
2023-02-11 01:41:07,465 DEBUG TRAIN Batch 0/5400 loss 173.675964 loss_att 265.347046 loss_ctc 162.950180 loss_rnnt 152.827332 hw_loss 0.739596 lr 0.00021604 rank 7
2023-02-11 01:41:07,469 DEBUG TRAIN Batch 0/5400 loss 122.515831 loss_att 220.972504 loss_ctc 116.942139 loss_rnnt 99.936813 hw_loss 0.680785 lr 0.00021604 rank 0
2023-02-11 01:41:07,470 DEBUG TRAIN Batch 0/5400 loss 160.949783 loss_att 243.878738 loss_ctc 153.557678 loss_rnnt 141.226547 hw_loss 0.773074 lr 0.00021604 rank 3
2023-02-11 01:41:07,473 DEBUG TRAIN Batch 0/5400 loss 150.521057 loss_att 252.029449 loss_ctc 140.339355 loss_rnnt 128.025574 hw_loss 0.665880 lr 0.00021604 rank 5
2023-02-11 01:41:07,476 DEBUG TRAIN Batch 0/5400 loss 131.675125 loss_att 247.838486 loss_ctc 125.819824 loss_rnnt 105.814590 hw_loss 0.639101 lr 0.00021604 rank 2
2023-02-11 01:41:07,478 DEBUG TRAIN Batch 0/5400 loss 132.567245 loss_att 258.723572 loss_ctc 119.907150 loss_rnnt 106.936577 hw_loss 0.391390 lr 0.00021604 rank 4
2023-02-11 01:41:07,480 DEBUG TRAIN Batch 0/5400 loss 161.802338 loss_att 241.876022 loss_ctc 156.320724 loss_rnnt 140.530014 hw_loss 1.122836 lr 0.00021604 rank 1
2023-02-11 01:42:23,103 DEBUG TRAIN Batch 0/5500 loss 122.038666 loss_att 184.030182 loss_ctc 120.888611 loss_rnnt 105.412689 hw_loss 0.821439 lr 0.00022004 rank 1
2023-02-11 01:42:23,106 DEBUG TRAIN Batch 0/5500 loss 129.401215 loss_att 231.188126 loss_ctc 120.182785 loss_rnnt 107.242500 hw_loss 0.568212 lr 0.00022004 rank 6
2023-02-11 01:42:23,107 DEBUG TRAIN Batch 0/5500 loss 181.413086 loss_att 274.263062 loss_ctc 178.642609 loss_rnnt 161.573074 hw_loss 0.307390 lr 0.00022004 rank 3
2023-02-11 01:42:23,106 DEBUG TRAIN Batch 0/5500 loss 139.710129 loss_att 245.803864 loss_ctc 132.962753 loss_rnnt 115.894257 hw_loss 0.655642 lr 0.00022004 rank 7
2023-02-11 01:42:23,110 DEBUG TRAIN Batch 0/5500 loss 97.281090 loss_att 185.230804 loss_ctc 99.169312 loss_rnnt 78.541260 hw_loss 0.168397 lr 0.00022004 rank 5
2023-02-11 01:42:23,111 DEBUG TRAIN Batch 0/5500 loss 165.532684 loss_att 240.927185 loss_ctc 170.539856 loss_rnnt 145.350327 hw_loss 0.831720 lr 0.00022004 rank 4
2023-02-11 01:42:23,112 DEBUG TRAIN Batch 0/5500 loss 141.199387 loss_att 218.993835 loss_ctc 132.223068 loss_rnnt 121.490891 hw_loss 1.002461 lr 0.00022004 rank 2
2023-02-11 01:42:23,112 DEBUG TRAIN Batch 0/5500 loss 159.227280 loss_att 259.284851 loss_ctc 153.957748 loss_rnnt 136.015930 hw_loss 0.731710 lr 0.00022004 rank 0
2023-02-11 01:43:39,844 DEBUG TRAIN Batch 0/5600 loss 140.706223 loss_att 219.230637 loss_ctc 143.601425 loss_rnnt 123.141441 hw_loss 0.276348 lr 0.00022404 rank 7
2023-02-11 01:43:39,845 DEBUG TRAIN Batch 0/5600 loss 127.999657 loss_att 199.297745 loss_ctc 123.506432 loss_rnnt 110.303726 hw_loss 0.756638 lr 0.00022404 rank 0
2023-02-11 01:43:39,847 DEBUG TRAIN Batch 0/5600 loss 118.919044 loss_att 189.327240 loss_ctc 112.400352 loss_rnnt 101.322388 hw_loss 0.822033 lr 0.00022404 rank 6
2023-02-11 01:43:39,847 DEBUG TRAIN Batch 0/5600 loss 126.866425 loss_att 212.672913 loss_ctc 119.100204 loss_rnnt 107.661728 hw_loss 0.577294 lr 0.00022404 rank 3
2023-02-11 01:43:39,849 DEBUG TRAIN Batch 0/5600 loss 74.450241 loss_att 118.686768 loss_ctc 72.047470 loss_rnnt 59.751709 hw_loss 1.157172 lr 0.00022404 rank 5
2023-02-11 01:43:39,851 DEBUG TRAIN Batch 0/5600 loss 76.481880 loss_att 113.073990 loss_ctc 72.343979 loss_rnnt 61.568466 hw_loss 1.527508 lr 0.00022404 rank 1
2023-02-11 01:43:39,851 DEBUG TRAIN Batch 0/5600 loss 174.209503 loss_att 270.005768 loss_ctc 175.421341 loss_rnnt 152.679947 hw_loss 0.414135 lr 0.00022404 rank 2
2023-02-11 01:43:39,851 DEBUG TRAIN Batch 0/5600 loss 157.954147 loss_att 227.456177 loss_ctc 160.802307 loss_rnnt 142.317017 hw_loss 0.254431 lr 0.00022404 rank 4
2023-02-11 01:44:58,191 DEBUG TRAIN Batch 0/5700 loss 110.804909 loss_att 179.988892 loss_ctc 114.650879 loss_rnnt 95.096100 hw_loss 0.254853 lr 0.00022804 rank 3
2023-02-11 01:44:58,194 DEBUG TRAIN Batch 0/5700 loss 62.933250 loss_att 97.292801 loss_ctc 56.667427 loss_rnnt 50.863808 hw_loss 1.131181 lr 0.00022804 rank 6
2023-02-11 01:44:58,195 DEBUG TRAIN Batch 0/5700 loss 128.351196 loss_att 203.488434 loss_ctc 128.035110 loss_rnnt 109.418961 hw_loss 0.740048 lr 0.00022804 rank 4
2023-02-11 01:44:58,198 DEBUG TRAIN Batch 0/5700 loss 85.200935 loss_att 146.793472 loss_ctc 87.195633 loss_rnnt 68.346146 hw_loss 0.800685 lr 0.00022804 rank 7
2023-02-11 01:44:58,200 DEBUG TRAIN Batch 0/5700 loss 113.223427 loss_att 213.201569 loss_ctc 107.891022 loss_rnnt 90.347488 hw_loss 0.673369 lr 0.00022804 rank 5
2023-02-11 01:44:58,201 DEBUG TRAIN Batch 0/5700 loss 86.343918 loss_att 164.184692 loss_ctc 74.758141 loss_rnnt 68.670555 hw_loss 0.684372 lr 0.00022804 rank 2
2023-02-11 01:44:58,202 DEBUG TRAIN Batch 0/5700 loss 54.568638 loss_att 76.947922 loss_ctc 51.104603 loss_rnnt 43.414364 hw_loss 1.338803 lr 0.00022804 rank 0
2023-02-11 01:44:58,210 DEBUG TRAIN Batch 0/5700 loss 130.269318 loss_att 259.072144 loss_ctc 117.027954 loss_rnnt 103.752060 hw_loss 0.472917 lr 0.00022804 rank 1
2023-02-11 01:46:14,431 DEBUG TRAIN Batch 0/5800 loss 154.423996 loss_att 242.079773 loss_ctc 156.969955 loss_rnnt 135.687866 hw_loss 0.162282 lr 0.00023204 rank 0
2023-02-11 01:46:14,434 DEBUG TRAIN Batch 0/5800 loss 105.182556 loss_att 220.232010 loss_ctc 98.276512 loss_rnnt 78.830521 hw_loss 0.799305 lr 0.00023204 rank 7
2023-02-11 01:46:14,435 DEBUG TRAIN Batch 0/5800 loss 78.755730 loss_att 121.507843 loss_ctc 76.361702 loss_rnnt 64.873489 hw_loss 1.059567 lr 0.00023204 rank 4
2023-02-11 01:46:14,437 DEBUG TRAIN Batch 0/5800 loss 129.786621 loss_att 270.010406 loss_ctc 131.765564 loss_rnnt 98.700073 hw_loss 0.520861 lr 0.00023204 rank 3
2023-02-11 01:46:14,440 DEBUG TRAIN Batch 0/5800 loss 182.306839 loss_att 271.738617 loss_ctc 186.034149 loss_rnnt 160.811920 hw_loss 0.583424 lr 0.00023204 rank 1
2023-02-11 01:46:14,442 DEBUG TRAIN Batch 0/5800 loss 183.051712 loss_att 292.438995 loss_ctc 179.449860 loss_rnnt 156.313599 hw_loss 1.001415 lr 0.00023204 rank 2
2023-02-11 01:46:14,441 DEBUG TRAIN Batch 0/5800 loss 125.944038 loss_att 237.524323 loss_ctc 118.090118 loss_rnnt 100.164261 hw_loss 0.845793 lr 0.00023204 rank 6
2023-02-11 01:46:14,444 DEBUG TRAIN Batch 0/5800 loss 135.986710 loss_att 238.120148 loss_ctc 126.115524 loss_rnnt 115.711845 hw_loss 0.218310 lr 0.00023204 rank 5
2023-02-11 01:47:30,254 DEBUG TRAIN Batch 0/5900 loss 113.390663 loss_att 231.300949 loss_ctc 109.518494 loss_rnnt 87.427277 hw_loss 0.543303 lr 0.00023604 rank 2
2023-02-11 01:47:30,254 DEBUG TRAIN Batch 0/5900 loss 134.715652 loss_att 232.679077 loss_ctc 129.685089 loss_rnnt 109.708054 hw_loss 1.141065 lr 0.00023604 rank 7
2023-02-11 01:47:30,256 DEBUG TRAIN Batch 0/5900 loss 168.882446 loss_att 276.056641 loss_ctc 164.064865 loss_rnnt 144.649628 hw_loss 0.645062 lr 0.00023604 rank 4
2023-02-11 01:47:30,257 DEBUG TRAIN Batch 0/5900 loss 120.419884 loss_att 223.639404 loss_ctc 113.476562 loss_rnnt 97.623924 hw_loss 0.577093 lr 0.00023604 rank 3
2023-02-11 01:47:30,257 DEBUG TRAIN Batch 0/5900 loss 156.332306 loss_att 260.325928 loss_ctc 154.814850 loss_rnnt 133.174377 hw_loss 0.480285 lr 0.00023604 rank 0
2023-02-11 01:47:30,257 DEBUG TRAIN Batch 0/5900 loss 111.925491 loss_att 226.390533 loss_ctc 101.089134 loss_rnnt 88.012779 hw_loss 0.462104 lr 0.00023604 rank 6
2023-02-11 01:47:30,258 DEBUG TRAIN Batch 0/5900 loss 123.828613 loss_att 221.060089 loss_ctc 113.242104 loss_rnnt 101.727333 hw_loss 0.762471 lr 0.00023604 rank 5
2023-02-11 01:47:30,305 DEBUG TRAIN Batch 0/5900 loss 142.718658 loss_att 254.310181 loss_ctc 134.825867 loss_rnnt 116.892944 hw_loss 0.854958 lr 0.00023604 rank 1
2023-02-11 01:48:47,628 DEBUG TRAIN Batch 0/6000 loss 104.902618 loss_att 213.580643 loss_ctc 101.282631 loss_rnnt 79.698334 hw_loss 0.740875 lr 0.00024004 rank 6
2023-02-11 01:48:47,629 DEBUG TRAIN Batch 0/6000 loss 151.502213 loss_att 249.130371 loss_ctc 160.170456 loss_rnnt 127.027878 hw_loss 0.711179 lr 0.00024004 rank 7
2023-02-11 01:48:47,630 DEBUG TRAIN Batch 0/6000 loss 147.585464 loss_att 224.282364 loss_ctc 142.355316 loss_rnnt 128.435776 hw_loss 0.845190 lr 0.00024004 rank 0
2023-02-11 01:48:47,632 DEBUG TRAIN Batch 0/6000 loss 148.573990 loss_att 252.352051 loss_ctc 141.150894 loss_rnnt 127.358940 hw_loss 0.271720 lr 0.00024004 rank 4
2023-02-11 01:48:47,634 DEBUG TRAIN Batch 0/6000 loss 112.644424 loss_att 220.982330 loss_ctc 107.414803 loss_rnnt 87.149857 hw_loss 0.848301 lr 0.00024004 rank 1
2023-02-11 01:48:47,635 DEBUG TRAIN Batch 0/6000 loss 133.089233 loss_att 239.209106 loss_ctc 135.412643 loss_rnnt 107.979172 hw_loss 0.670554 lr 0.00024004 rank 3
2023-02-11 01:48:47,637 DEBUG TRAIN Batch 0/6000 loss 136.253906 loss_att 252.825043 loss_ctc 127.855545 loss_rnnt 109.627968 hw_loss 0.830901 lr 0.00024004 rank 5
2023-02-11 01:48:47,675 DEBUG TRAIN Batch 0/6000 loss 124.787308 loss_att 214.497757 loss_ctc 127.778931 loss_rnnt 104.546402 hw_loss 0.356235 lr 0.00024004 rank 2
2023-02-11 01:50:06,227 DEBUG TRAIN Batch 0/6100 loss 118.465599 loss_att 212.311050 loss_ctc 110.898895 loss_rnnt 97.986847 hw_loss 0.509730 lr 0.00024404 rank 6
2023-02-11 01:50:06,232 DEBUG TRAIN Batch 0/6100 loss 128.659988 loss_att 236.871811 loss_ctc 129.201782 loss_rnnt 104.275665 hw_loss 0.500570 lr 0.00024404 rank 3
2023-02-11 01:50:06,234 DEBUG TRAIN Batch 0/6100 loss 125.711655 loss_att 229.414764 loss_ctc 120.033936 loss_rnnt 102.652260 hw_loss 0.576712 lr 0.00024404 rank 5
2023-02-11 01:50:06,234 DEBUG TRAIN Batch 0/6100 loss 138.505722 loss_att 226.138428 loss_ctc 138.143402 loss_rnnt 116.439590 hw_loss 0.860230 lr 0.00024404 rank 7
2023-02-11 01:50:06,234 DEBUG TRAIN Batch 0/6100 loss 125.965408 loss_att 246.653534 loss_ctc 118.334457 loss_rnnt 99.934509 hw_loss 0.545763 lr 0.00024404 rank 2
2023-02-11 01:50:06,235 DEBUG TRAIN Batch 0/6100 loss 142.973267 loss_att 236.018936 loss_ctc 143.451050 loss_rnnt 120.170448 hw_loss 0.774367 lr 0.00024404 rank 4
2023-02-11 01:50:06,235 DEBUG TRAIN Batch 0/6100 loss 133.153336 loss_att 215.343079 loss_ctc 124.465622 loss_rnnt 113.499123 hw_loss 0.820242 lr 0.00024404 rank 1
2023-02-11 01:50:06,235 DEBUG TRAIN Batch 0/6100 loss 119.766281 loss_att 207.137817 loss_ctc 118.951233 loss_rnnt 100.760345 hw_loss 0.307555 lr 0.00024404 rank 0
2023-02-11 01:51:21,685 DEBUG TRAIN Batch 0/6200 loss 117.967537 loss_att 231.969452 loss_ctc 108.537712 loss_rnnt 91.309364 hw_loss 0.959080 lr 0.00024804 rank 3
2023-02-11 01:51:21,687 DEBUG TRAIN Batch 0/6200 loss 153.766495 loss_att 249.569397 loss_ctc 155.033279 loss_rnnt 130.322815 hw_loss 0.771413 lr 0.00024804 rank 0
2023-02-11 01:51:21,691 DEBUG TRAIN Batch 0/6200 loss 81.229584 loss_att 158.723450 loss_ctc 80.239632 loss_rnnt 62.515175 hw_loss 0.627680 lr 0.00024804 rank 5
2023-02-11 01:51:21,692 DEBUG TRAIN Batch 0/6200 loss 127.193527 loss_att 216.811523 loss_ctc 126.170372 loss_rnnt 105.655533 hw_loss 0.703278 lr 0.00024804 rank 7
2023-02-11 01:51:21,693 DEBUG TRAIN Batch 0/6200 loss 91.540817 loss_att 177.510681 loss_ctc 88.785309 loss_rnnt 71.107117 hw_loss 0.676336 lr 0.00024804 rank 6
2023-02-11 01:51:21,693 DEBUG TRAIN Batch 0/6200 loss 94.132294 loss_att 207.418762 loss_ctc 87.854111 loss_rnnt 69.070465 hw_loss 0.607804 lr 0.00024804 rank 2
2023-02-11 01:51:21,695 DEBUG TRAIN Batch 0/6200 loss 120.617111 loss_att 233.119415 loss_ctc 117.399475 loss_rnnt 95.557526 hw_loss 0.560275 lr 0.00024804 rank 4
2023-02-11 01:51:21,735 DEBUG TRAIN Batch 0/6200 loss 94.932281 loss_att 166.085007 loss_ctc 93.531364 loss_rnnt 76.733849 hw_loss 0.779004 lr 0.00024804 rank 1
2023-02-11 01:52:39,349 DEBUG TRAIN Batch 0/6300 loss 60.607323 loss_att 121.819992 loss_ctc 57.349392 loss_rnnt 45.975719 hw_loss 0.529399 lr 0.00025204 rank 0
2023-02-11 01:52:39,350 DEBUG TRAIN Batch 0/6300 loss 98.584557 loss_att 180.471466 loss_ctc 93.491234 loss_rnnt 79.301842 hw_loss 0.672083 lr 0.00025204 rank 7
2023-02-11 01:52:39,350 DEBUG TRAIN Batch 0/6300 loss 62.720856 loss_att 96.112640 loss_ctc 63.101067 loss_rnnt 52.164803 hw_loss 0.717561 lr 0.00025204 rank 6
2023-02-11 01:52:39,353 DEBUG TRAIN Batch 0/6300 loss 132.234924 loss_att 265.541565 loss_ctc 124.701340 loss_rnnt 104.825104 hw_loss 0.328681 lr 0.00025204 rank 1
2023-02-11 01:52:39,354 DEBUG TRAIN Batch 0/6300 loss 82.027252 loss_att 160.083496 loss_ctc 79.173355 loss_rnnt 62.511086 hw_loss 0.803519 lr 0.00025204 rank 3
2023-02-11 01:52:39,356 DEBUG TRAIN Batch 0/6300 loss 87.292328 loss_att 151.594681 loss_ctc 84.720818 loss_rnnt 71.412369 hw_loss 0.630443 lr 0.00025204 rank 2
2023-02-11 01:52:39,360 DEBUG TRAIN Batch 0/6300 loss 119.936600 loss_att 220.021606 loss_ctc 113.296837 loss_rnnt 96.537170 hw_loss 0.800200 lr 0.00025204 rank 4
2023-02-11 01:52:39,366 DEBUG TRAIN Batch 0/6300 loss 30.294897 loss_att 38.121628 loss_ctc 24.630209 loss_rnnt 22.178648 hw_loss 1.369912 lr 0.00025204 rank 5
2023-02-11 01:53:57,861 DEBUG TRAIN Batch 0/6400 loss 118.487152 loss_att 236.184418 loss_ctc 112.122421 loss_rnnt 93.345322 hw_loss 0.459564 lr 0.00025604 rank 0
2023-02-11 01:53:57,864 DEBUG TRAIN Batch 0/6400 loss 43.539330 loss_att 59.561031 loss_ctc 42.505512 loss_rnnt 34.995174 hw_loss 1.027061 lr 0.00025604 rank 2
2023-02-11 01:53:57,864 DEBUG TRAIN Batch 0/6400 loss 71.872772 loss_att 120.815750 loss_ctc 61.905525 loss_rnnt 58.651138 hw_loss 0.892875 lr 0.00025604 rank 7
2023-02-11 01:53:57,867 DEBUG TRAIN Batch 0/6400 loss 62.019070 loss_att 91.274681 loss_ctc 58.629395 loss_rnnt 49.731285 hw_loss 1.291616 lr 0.00025604 rank 3
2023-02-11 01:53:57,868 DEBUG TRAIN Batch 0/6400 loss 132.919754 loss_att 249.007156 loss_ctc 120.522484 loss_rnnt 109.070892 hw_loss 0.428318 lr 0.00025604 rank 1
2023-02-11 01:53:57,868 DEBUG TRAIN Batch 0/6400 loss 90.557777 loss_att 163.295700 loss_ctc 91.920364 loss_rnnt 72.420975 hw_loss 0.638913 lr 0.00025604 rank 4
2023-02-11 01:53:57,870 DEBUG TRAIN Batch 0/6400 loss 111.037079 loss_att 225.510406 loss_ctc 102.382530 loss_rnnt 87.902206 hw_loss 0.261404 lr 0.00025604 rank 5
2023-02-11 01:53:57,912 DEBUG TRAIN Batch 0/6400 loss 124.905800 loss_att 245.484833 loss_ctc 122.206772 loss_rnnt 99.424561 hw_loss 0.323492 lr 0.00025604 rank 6
2023-02-11 01:55:14,976 DEBUG TRAIN Batch 0/6500 loss 110.601715 loss_att 207.283539 loss_ctc 104.763306 loss_rnnt 91.105515 hw_loss 0.175929 lr 0.00026004 rank 5
2023-02-11 01:55:14,977 DEBUG TRAIN Batch 0/6500 loss 176.329483 loss_att 279.441040 loss_ctc 176.114014 loss_rnnt 154.109100 hw_loss 0.305028 lr 0.00026004 rank 3
2023-02-11 01:55:14,979 DEBUG TRAIN Batch 0/6500 loss 161.492126 loss_att 258.718018 loss_ctc 155.131989 loss_rnnt 140.293243 hw_loss 0.487822 lr 0.00026004 rank 4
2023-02-11 01:55:14,980 DEBUG TRAIN Batch 0/6500 loss 110.105423 loss_att 227.071320 loss_ctc 114.030785 loss_rnnt 84.863182 hw_loss 0.248566 lr 0.00026004 rank 1
2023-02-11 01:55:14,980 DEBUG TRAIN Batch 0/6500 loss 137.699036 loss_att 283.822510 loss_ctc 137.627548 loss_rnnt 106.936798 hw_loss 0.290077 lr 0.00026004 rank 0
2023-02-11 01:55:14,981 DEBUG TRAIN Batch 0/6500 loss 157.452194 loss_att 268.233856 loss_ctc 155.118195 loss_rnnt 134.459274 hw_loss 0.215211 lr 0.00026004 rank 7
2023-02-11 01:55:14,985 DEBUG TRAIN Batch 0/6500 loss 103.761734 loss_att 233.812988 loss_ctc 102.725632 loss_rnnt 75.926102 hw_loss 0.368160 lr 0.00026004 rank 2
2023-02-11 01:55:14,986 DEBUG TRAIN Batch 0/6500 loss 100.518463 loss_att 200.358704 loss_ctc 94.589294 loss_rnnt 78.531754 hw_loss 0.526729 lr 0.00026004 rank 6
2023-02-11 01:56:30,320 DEBUG TRAIN Batch 0/6600 loss 105.109840 loss_att 232.933853 loss_ctc 99.443909 loss_rnnt 76.875656 hw_loss 0.642157 lr 0.00026404 rank 0
2023-02-11 01:56:30,322 DEBUG TRAIN Batch 0/6600 loss 164.738037 loss_att 283.140991 loss_ctc 178.781540 loss_rnnt 136.592239 hw_loss 0.486139 lr 0.00026404 rank 3
2023-02-11 01:56:30,323 DEBUG TRAIN Batch 0/6600 loss 117.728065 loss_att 219.759872 loss_ctc 118.713486 loss_rnnt 95.031906 hw_loss 0.404703 lr 0.00026404 rank 1
2023-02-11 01:56:30,326 DEBUG TRAIN Batch 0/6600 loss 118.309227 loss_att 210.358688 loss_ctc 110.650543 loss_rnnt 97.112473 hw_loss 0.714005 lr 0.00026404 rank 6
2023-02-11 01:56:30,328 DEBUG TRAIN Batch 0/6600 loss 116.071579 loss_att 223.544891 loss_ctc 119.797508 loss_rnnt 91.587090 hw_loss 0.467444 lr 0.00026404 rank 7
2023-02-11 01:56:30,329 DEBUG TRAIN Batch 0/6600 loss 125.306641 loss_att 250.068176 loss_ctc 118.450485 loss_rnnt 97.838745 hw_loss 0.643077 lr 0.00026404 rank 2
2023-02-11 01:56:30,331 DEBUG TRAIN Batch 0/6600 loss 118.308907 loss_att 227.073364 loss_ctc 108.394760 loss_rnnt 92.321304 hw_loss 1.041861 lr 0.00026404 rank 5
2023-02-11 01:56:30,331 DEBUG TRAIN Batch 0/6600 loss 109.118431 loss_att 212.636749 loss_ctc 104.095871 loss_rnnt 84.381729 hw_loss 0.881758 lr 0.00026404 rank 4
2023-02-11 01:57:46,856 DEBUG TRAIN Batch 0/6700 loss 119.543091 loss_att 242.644440 loss_ctc 115.139832 loss_rnnt 92.667633 hw_loss 0.532929 lr 0.00026804 rank 7
2023-02-11 01:57:46,867 DEBUG TRAIN Batch 0/6700 loss 101.274223 loss_att 201.481720 loss_ctc 92.939018 loss_rnnt 76.959335 hw_loss 1.009639 lr 0.00026804 rank 5
2023-02-11 01:57:46,869 DEBUG TRAIN Batch 0/6700 loss 140.781799 loss_att 275.355804 loss_ctc 133.976562 loss_rnnt 111.044434 hw_loss 0.699362 lr 0.00026804 rank 4
2023-02-11 01:57:46,878 DEBUG TRAIN Batch 0/6700 loss 108.964905 loss_att 224.466553 loss_ctc 104.486694 loss_rnnt 83.030022 hw_loss 0.643435 lr 0.00026804 rank 0
2023-02-11 01:57:46,888 DEBUG TRAIN Batch 0/6700 loss 131.668396 loss_att 259.398254 loss_ctc 128.984238 loss_rnnt 102.191345 hw_loss 0.804181 lr 0.00026804 rank 3
2023-02-11 01:57:46,898 DEBUG TRAIN Batch 0/6700 loss 107.327042 loss_att 214.660217 loss_ctc 103.505821 loss_rnnt 82.732498 hw_loss 0.682013 lr 0.00026804 rank 2
2023-02-11 01:57:46,906 DEBUG TRAIN Batch 0/6700 loss 123.098274 loss_att 227.696442 loss_ctc 118.700378 loss_rnnt 98.483002 hw_loss 0.802877 lr 0.00026804 rank 1
2023-02-11 01:57:46,910 DEBUG TRAIN Batch 0/6700 loss 115.352776 loss_att 217.980316 loss_ctc 120.458687 loss_rnnt 91.823364 hw_loss 0.435583 lr 0.00026804 rank 6
2023-02-11 01:59:04,347 DEBUG TRAIN Batch 0/6800 loss 120.649208 loss_att 244.942261 loss_ctc 123.757500 loss_rnnt 92.992172 hw_loss 0.446998 lr 0.00027204 rank 3
2023-02-11 01:59:04,347 DEBUG TRAIN Batch 0/6800 loss 98.338730 loss_att 187.821411 loss_ctc 99.848503 loss_rnnt 74.793602 hw_loss 1.021367 lr 0.00027204 rank 1
2023-02-11 01:59:04,348 DEBUG TRAIN Batch 0/6800 loss 114.130096 loss_att 226.687988 loss_ctc 112.585205 loss_rnnt 89.396629 hw_loss 0.455226 lr 0.00027204 rank 0
2023-02-11 01:59:04,352 DEBUG TRAIN Batch 0/6800 loss 140.002808 loss_att 255.553497 loss_ctc 135.460007 loss_rnnt 115.015320 hw_loss 0.465573 lr 0.00027204 rank 4
2023-02-11 01:59:04,352 DEBUG TRAIN Batch 0/6800 loss 102.818153 loss_att 213.281342 loss_ctc 97.064903 loss_rnnt 77.713623 hw_loss 0.708562 lr 0.00027204 rank 7
2023-02-11 01:59:04,353 DEBUG TRAIN Batch 0/6800 loss 99.404381 loss_att 188.809784 loss_ctc 95.857307 loss_rnnt 78.985825 hw_loss 0.564455 lr 0.00027204 rank 5
2023-02-11 01:59:04,354 DEBUG TRAIN Batch 0/6800 loss 141.458328 loss_att 245.069763 loss_ctc 147.629272 loss_rnnt 116.841278 hw_loss 0.575991 lr 0.00027204 rank 2
2023-02-11 01:59:04,357 DEBUG TRAIN Batch 0/6800 loss 105.095123 loss_att 202.074142 loss_ctc 101.959503 loss_rnnt 85.200684 hw_loss 0.171882 lr 0.00027204 rank 6
2023-02-11 02:00:19,801 DEBUG TRAIN Batch 0/6900 loss 71.440071 loss_att 133.143890 loss_ctc 66.205353 loss_rnnt 55.856705 hw_loss 0.738856 lr 0.00027604 rank 5
2023-02-11 02:00:19,803 DEBUG TRAIN Batch 0/6900 loss 111.915466 loss_att 214.419098 loss_ctc 106.674477 loss_rnnt 86.924362 hw_loss 0.972971 lr 0.00027604 rank 0
2023-02-11 02:00:19,804 DEBUG TRAIN Batch 0/6900 loss 102.744904 loss_att 196.880203 loss_ctc 102.641312 loss_rnnt 80.514809 hw_loss 0.640659 lr 0.00027604 rank 7
2023-02-11 02:00:19,807 DEBUG TRAIN Batch 0/6900 loss 84.386047 loss_att 184.579254 loss_ctc 74.617462 loss_rnnt 62.482384 hw_loss 0.593906 lr 0.00027604 rank 3
2023-02-11 02:00:19,808 DEBUG TRAIN Batch 0/6900 loss 98.516212 loss_att 200.582855 loss_ctc 94.116333 loss_rnnt 74.883369 hw_loss 0.713655 lr 0.00027604 rank 2
2023-02-11 02:00:19,808 DEBUG TRAIN Batch 0/6900 loss 98.005646 loss_att 188.419800 loss_ctc 98.475098 loss_rnnt 77.487099 hw_loss 0.444960 lr 0.00027604 rank 1
2023-02-11 02:00:19,809 DEBUG TRAIN Batch 0/6900 loss 114.652252 loss_att 200.029510 loss_ctc 108.687332 loss_rnnt 95.586044 hw_loss 0.522391 lr 0.00027604 rank 6
2023-02-11 02:00:19,810 DEBUG TRAIN Batch 0/6900 loss 111.003876 loss_att 190.124863 loss_ctc 114.623627 loss_rnnt 91.066467 hw_loss 0.680733 lr 0.00027604 rank 4
2023-02-11 02:01:35,596 DEBUG TRAIN Batch 0/7000 loss 138.125458 loss_att 285.438477 loss_ctc 136.322556 loss_rnnt 104.929840 hw_loss 0.745010 lr 0.00028004 rank 5
2023-02-11 02:01:35,597 DEBUG TRAIN Batch 0/7000 loss 112.122086 loss_att 239.690186 loss_ctc 106.053116 loss_rnnt 84.650681 hw_loss 0.518809 lr 0.00028004 rank 1
2023-02-11 02:01:35,600 DEBUG TRAIN Batch 0/7000 loss 74.857132 loss_att 121.608032 loss_ctc 73.408539 loss_rnnt 57.650116 hw_loss 1.509370 lr 0.00028004 rank 3
2023-02-11 02:01:35,602 DEBUG TRAIN Batch 0/7000 loss 85.012779 loss_att 148.977829 loss_ctc 83.561668 loss_rnnt 67.192657 hw_loss 0.978861 lr 0.00028004 rank 7
2023-02-11 02:01:35,604 DEBUG TRAIN Batch 0/7000 loss 48.536339 loss_att 87.845688 loss_ctc 43.946350 loss_rnnt 35.754002 hw_loss 1.037338 lr 0.00028004 rank 0
2023-02-11 02:01:35,605 DEBUG TRAIN Batch 0/7000 loss 123.780235 loss_att 218.430725 loss_ctc 130.523010 loss_rnnt 102.400467 hw_loss 0.290743 lr 0.00028004 rank 6
2023-02-11 02:01:35,607 DEBUG TRAIN Batch 0/7000 loss 85.709862 loss_att 164.014587 loss_ctc 82.602760 loss_rnnt 66.548691 hw_loss 0.733969 lr 0.00028004 rank 4
2023-02-11 02:01:35,647 DEBUG TRAIN Batch 0/7000 loss 78.779198 loss_att 139.764496 loss_ctc 75.025108 loss_rnnt 62.306126 hw_loss 0.895606 lr 0.00028004 rank 2
2023-02-11 02:02:54,003 DEBUG TRAIN Batch 0/7100 loss 89.574013 loss_att 216.097397 loss_ctc 87.603760 loss_rnnt 61.982491 hw_loss 0.478038 lr 0.00028404 rank 3
2023-02-11 02:02:54,004 DEBUG TRAIN Batch 0/7100 loss 77.281357 loss_att 175.806381 loss_ctc 73.172546 loss_rnnt 55.087566 hw_loss 0.569368 lr 0.00028404 rank 5
2023-02-11 02:02:54,006 DEBUG TRAIN Batch 0/7100 loss 97.178810 loss_att 230.423706 loss_ctc 82.804520 loss_rnnt 69.717514 hw_loss 0.511667 lr 0.00028404 rank 6
2023-02-11 02:02:54,007 DEBUG TRAIN Batch 0/7100 loss 50.129173 loss_att 76.420296 loss_ctc 48.364429 loss_rnnt 40.680054 hw_loss 0.829912 lr 0.00028404 rank 4
2023-02-11 02:02:54,008 DEBUG TRAIN Batch 0/7100 loss 111.930222 loss_att 242.812469 loss_ctc 112.738853 loss_rnnt 84.263794 hw_loss 0.259156 lr 0.00028404 rank 7
2023-02-11 02:02:54,011 DEBUG TRAIN Batch 0/7100 loss 111.104385 loss_att 220.550644 loss_ctc 105.613449 loss_rnnt 86.149002 hw_loss 0.712169 lr 0.00028404 rank 0
2023-02-11 02:02:54,015 DEBUG TRAIN Batch 0/7100 loss 100.045815 loss_att 226.603729 loss_ctc 100.009705 loss_rnnt 73.530907 hw_loss 0.226526 lr 0.00028404 rank 2
2023-02-11 02:02:54,019 DEBUG TRAIN Batch 0/7100 loss 111.319710 loss_att 218.028534 loss_ctc 112.529465 loss_rnnt 87.268394 hw_loss 0.477796 lr 0.00028404 rank 1
2023-02-11 02:04:09,495 DEBUG TRAIN Batch 0/7200 loss 101.635162 loss_att 225.514191 loss_ctc 98.136780 loss_rnnt 74.107559 hw_loss 0.603420 lr 0.00028804 rank 6
2023-02-11 02:04:09,496 DEBUG TRAIN Batch 0/7200 loss 115.858055 loss_att 235.728760 loss_ctc 117.954773 loss_rnnt 88.757645 hw_loss 0.533756 lr 0.00028804 rank 2
2023-02-11 02:04:09,496 DEBUG TRAIN Batch 0/7200 loss 128.519653 loss_att 263.481201 loss_ctc 123.407349 loss_rnnt 100.494247 hw_loss 0.321515 lr 0.00028804 rank 3
2023-02-11 02:04:09,498 DEBUG TRAIN Batch 0/7200 loss 136.530624 loss_att 256.930725 loss_ctc 142.327301 loss_rnnt 109.109329 hw_loss 0.481569 lr 0.00028804 rank 1
2023-02-11 02:04:09,499 DEBUG TRAIN Batch 0/7200 loss 126.671089 loss_att 224.611923 loss_ctc 133.375153 loss_rnnt 102.520660 hw_loss 0.687823 lr 0.00028804 rank 0
2023-02-11 02:04:09,502 DEBUG TRAIN Batch 0/7200 loss 90.443077 loss_att 208.817490 loss_ctc 82.822479 loss_rnnt 63.372772 hw_loss 0.827157 lr 0.00028804 rank 7
2023-02-11 02:04:09,503 DEBUG TRAIN Batch 0/7200 loss 88.192070 loss_att 194.887177 loss_ctc 75.915985 loss_rnnt 65.119125 hw_loss 0.632014 lr 0.00028804 rank 5
2023-02-11 02:04:09,505 DEBUG TRAIN Batch 0/7200 loss 112.060905 loss_att 229.359406 loss_ctc 104.854172 loss_rnnt 87.297058 hw_loss 0.424696 lr 0.00028804 rank 4
2023-02-11 02:05:25,115 DEBUG TRAIN Batch 0/7300 loss 106.995026 loss_att 219.126511 loss_ctc 103.925430 loss_rnnt 82.727203 hw_loss 0.422027 lr 0.00029204 rank 3
2023-02-11 02:05:25,120 DEBUG TRAIN Batch 0/7300 loss 85.355103 loss_att 196.351089 loss_ctc 78.326225 loss_rnnt 59.660213 hw_loss 0.831163 lr 0.00029204 rank 6
2023-02-11 02:05:25,120 DEBUG TRAIN Batch 0/7300 loss 138.099808 loss_att 253.219543 loss_ctc 139.016251 loss_rnnt 111.072052 hw_loss 0.727802 lr 0.00029204 rank 2
2023-02-11 02:05:25,120 DEBUG TRAIN Batch 0/7300 loss 102.526169 loss_att 215.626831 loss_ctc 102.297791 loss_rnnt 78.149826 hw_loss 0.334999 lr 0.00029204 rank 0
2023-02-11 02:05:25,121 DEBUG TRAIN Batch 0/7300 loss 120.024506 loss_att 217.688385 loss_ctc 121.566826 loss_rnnt 95.876785 hw_loss 0.826742 lr 0.00029204 rank 1
2023-02-11 02:05:25,123 DEBUG TRAIN Batch 0/7300 loss 123.566353 loss_att 229.588959 loss_ctc 128.556183 loss_rnnt 99.227325 hw_loss 0.462973 lr 0.00029204 rank 5
2023-02-11 02:05:25,124 DEBUG TRAIN Batch 0/7300 loss 105.598618 loss_att 225.882385 loss_ctc 96.567917 loss_rnnt 81.404419 hw_loss 0.251537 lr 0.00029204 rank 7
2023-02-11 02:05:25,128 DEBUG TRAIN Batch 0/7300 loss 101.162323 loss_att 213.911057 loss_ctc 100.891441 loss_rnnt 77.338203 hw_loss 0.245717 lr 0.00029204 rank 4
2023-02-11 02:06:40,824 DEBUG TRAIN Batch 0/7400 loss 88.185371 loss_att 191.209381 loss_ctc 86.398727 loss_rnnt 65.159515 hw_loss 0.498614 lr 0.00029604 rank 3
2023-02-11 02:06:40,826 DEBUG TRAIN Batch 0/7400 loss 87.902969 loss_att 182.688797 loss_ctc 79.385956 loss_rnnt 65.044777 hw_loss 0.944367 lr 0.00029604 rank 1
2023-02-11 02:06:40,827 DEBUG TRAIN Batch 0/7400 loss 101.317566 loss_att 198.299622 loss_ctc 98.165726 loss_rnnt 78.279892 hw_loss 0.761533 lr 0.00029604 rank 0
2023-02-11 02:06:40,828 DEBUG TRAIN Batch 0/7400 loss 91.607903 loss_att 192.479950 loss_ctc 79.853409 loss_rnnt 69.434227 hw_loss 0.668726 lr 0.00029604 rank 7
2023-02-11 02:06:40,831 DEBUG TRAIN Batch 0/7400 loss 104.881882 loss_att 197.444626 loss_ctc 105.583618 loss_rnnt 82.575676 hw_loss 0.693767 lr 0.00029604 rank 4
2023-02-11 02:06:40,832 DEBUG TRAIN Batch 0/7400 loss 118.705933 loss_att 219.754120 loss_ctc 116.026817 loss_rnnt 95.901665 hw_loss 0.553470 lr 0.00029604 rank 2
2023-02-11 02:06:40,833 DEBUG TRAIN Batch 0/7400 loss 141.175293 loss_att 238.573547 loss_ctc 141.018021 loss_rnnt 117.188431 hw_loss 0.849034 lr 0.00029604 rank 6
2023-02-11 02:06:40,834 DEBUG TRAIN Batch 0/7400 loss 75.003540 loss_att 160.979324 loss_ctc 60.759155 loss_rnnt 54.813042 hw_loss 0.917736 lr 0.00029604 rank 5
2023-02-11 02:07:58,657 DEBUG TRAIN Batch 0/7500 loss 69.425842 loss_att 170.265747 loss_ctc 65.117523 loss_rnnt 48.936840 hw_loss 0.167900 lr 0.00030004 rank 3
2023-02-11 02:07:58,660 DEBUG TRAIN Batch 0/7500 loss 91.444405 loss_att 163.686981 loss_ctc 91.556824 loss_rnnt 73.040718 hw_loss 0.738783 lr 0.00030004 rank 0
2023-02-11 02:07:58,662 DEBUG TRAIN Batch 0/7500 loss 53.679138 loss_att 89.200394 loss_ctc 52.085026 loss_rnnt 43.201263 hw_loss 0.672407 lr 0.00030004 rank 1
2023-02-11 02:07:58,663 DEBUG TRAIN Batch 0/7500 loss 62.288441 loss_att 153.009003 loss_ctc 55.018127 loss_rnnt 43.049717 hw_loss 0.386997 lr 0.00030004 rank 6
2023-02-11 02:07:58,663 DEBUG TRAIN Batch 0/7500 loss 90.402519 loss_att 180.157150 loss_ctc 84.073792 loss_rnnt 70.367203 hw_loss 0.549041 lr 0.00030004 rank 2
2023-02-11 02:07:58,664 DEBUG TRAIN Batch 0/7500 loss 99.197952 loss_att 204.113968 loss_ctc 96.302887 loss_rnnt 75.107063 hw_loss 0.655067 lr 0.00030004 rank 7
2023-02-11 02:07:58,666 DEBUG TRAIN Batch 0/7500 loss 99.059280 loss_att 177.953705 loss_ctc 97.196060 loss_rnnt 80.978722 hw_loss 0.478146 lr 0.00030004 rank 5
2023-02-11 02:07:58,667 DEBUG TRAIN Batch 0/7500 loss 129.966507 loss_att 250.091125 loss_ctc 132.327515 loss_rnnt 103.154419 hw_loss 0.463567 lr 0.00030004 rank 4
2023-02-11 02:09:16,521 DEBUG TRAIN Batch 0/7600 loss 80.506287 loss_att 146.139404 loss_ctc 77.843124 loss_rnnt 63.890472 hw_loss 0.720803 lr 0.00030404 rank 2
2023-02-11 02:09:16,523 DEBUG TRAIN Batch 0/7600 loss 56.623470 loss_att 95.134491 loss_ctc 55.005566 loss_rnnt 40.727371 hw_loss 1.576802 lr 0.00030404 rank 5
2023-02-11 02:09:16,526 DEBUG TRAIN Batch 0/7600 loss 131.795242 loss_att 240.451065 loss_ctc 127.574608 loss_rnnt 106.550591 hw_loss 0.764295 lr 0.00030404 rank 1
2023-02-11 02:09:16,529 DEBUG TRAIN Batch 0/7600 loss 77.376778 loss_att 136.235321 loss_ctc 77.254280 loss_rnnt 62.939594 hw_loss 0.502838 lr 0.00030404 rank 3
2023-02-11 02:09:16,530 DEBUG TRAIN Batch 0/7600 loss 45.673222 loss_att 65.256004 loss_ctc 42.946495 loss_rnnt 36.620010 hw_loss 1.031291 lr 0.00030404 rank 6
2023-02-11 02:09:16,534 DEBUG TRAIN Batch 0/7600 loss 85.978577 loss_att 173.610794 loss_ctc 82.204063 loss_rnnt 64.103676 hw_loss 0.909699 lr 0.00030404 rank 4
2023-02-11 02:09:16,561 DEBUG TRAIN Batch 0/7600 loss 80.127007 loss_att 149.777664 loss_ctc 84.026443 loss_rnnt 63.690750 hw_loss 0.372412 lr 0.00030404 rank 7
2023-02-11 02:09:16,569 DEBUG TRAIN Batch 0/7600 loss 53.036373 loss_att 77.604454 loss_ctc 50.487736 loss_rnnt 42.729115 hw_loss 1.075023 lr 0.00030404 rank 0
2023-02-11 02:10:32,850 DEBUG TRAIN Batch 0/7700 loss 100.186638 loss_att 240.955688 loss_ctc 94.147942 loss_rnnt 71.038879 hw_loss 0.337332 lr 0.00030804 rank 0
2023-02-11 02:10:32,854 DEBUG TRAIN Batch 0/7700 loss 101.863380 loss_att 234.545685 loss_ctc 100.786827 loss_rnnt 71.947433 hw_loss 0.660567 lr 0.00030804 rank 3
2023-02-11 02:10:32,856 DEBUG TRAIN Batch 0/7700 loss 92.898911 loss_att 217.589813 loss_ctc 89.819992 loss_rnnt 64.904846 hw_loss 0.649952 lr 0.00030804 rank 2
2023-02-11 02:10:32,857 DEBUG TRAIN Batch 0/7700 loss 111.077415 loss_att 228.877106 loss_ctc 103.699394 loss_rnnt 85.233185 hw_loss 0.612754 lr 0.00030804 rank 1
2023-02-11 02:10:32,857 DEBUG TRAIN Batch 0/7700 loss 55.723404 loss_att 115.374634 loss_ctc 52.464523 loss_rnnt 40.601971 hw_loss 0.679819 lr 0.00030804 rank 4
2023-02-11 02:10:32,860 DEBUG TRAIN Batch 0/7700 loss 121.094330 loss_att 245.303040 loss_ctc 126.572845 loss_rnnt 93.472885 hw_loss 0.384232 lr 0.00030804 rank 5
2023-02-11 02:10:32,861 DEBUG TRAIN Batch 0/7700 loss 133.962296 loss_att 250.341705 loss_ctc 133.717682 loss_rnnt 105.993706 hw_loss 0.885996 lr 0.00030804 rank 7
2023-02-11 02:10:32,861 DEBUG TRAIN Batch 0/7700 loss 110.638519 loss_att 229.838379 loss_ctc 102.764496 loss_rnnt 85.255318 hw_loss 0.486206 lr 0.00030804 rank 6
2023-02-11 02:11:50,513 DEBUG TRAIN Batch 0/7800 loss 92.750053 loss_att 212.178879 loss_ctc 87.098564 loss_rnnt 65.401352 hw_loss 0.790586 lr 0.00031204 rank 3
2023-02-11 02:11:50,513 DEBUG TRAIN Batch 0/7800 loss 85.410858 loss_att 171.827026 loss_ctc 82.016060 loss_rnnt 64.216431 hw_loss 0.818218 lr 0.00031204 rank 0
2023-02-11 02:11:50,516 DEBUG TRAIN Batch 0/7800 loss 99.438484 loss_att 216.974396 loss_ctc 83.590126 loss_rnnt 77.060898 hw_loss 0.184408 lr 0.00031204 rank 4
2023-02-11 02:11:50,518 DEBUG TRAIN Batch 0/7800 loss 146.275696 loss_att 251.185486 loss_ctc 162.942093 loss_rnnt 120.061920 hw_loss 0.564303 lr 0.00031204 rank 2
2023-02-11 02:11:50,521 DEBUG TRAIN Batch 0/7800 loss 104.930626 loss_att 212.864471 loss_ctc 94.842270 loss_rnnt 80.964188 hw_loss 0.698396 lr 0.00031204 rank 7
2023-02-11 02:11:50,521 DEBUG TRAIN Batch 0/7800 loss 94.338814 loss_att 222.323059 loss_ctc 91.566330 loss_rnnt 64.419495 hw_loss 0.879774 lr 0.00031204 rank 5
2023-02-11 02:11:50,520 DEBUG TRAIN Batch 0/7800 loss 118.288696 loss_att 208.492615 loss_ctc 133.810577 loss_rnnt 95.649002 hw_loss 0.474247 lr 0.00031204 rank 1
2023-02-11 02:11:50,522 DEBUG TRAIN Batch 0/7800 loss 102.427879 loss_att 191.871521 loss_ctc 105.024803 loss_rnnt 82.210220 hw_loss 0.371751 lr 0.00031204 rank 6
2023-02-11 02:13:08,259 DEBUG TRAIN Batch 0/7900 loss 86.753098 loss_att 194.416061 loss_ctc 81.187485 loss_rnnt 63.446789 hw_loss 0.471712 lr 0.00031604 rank 7
2023-02-11 02:13:08,260 DEBUG TRAIN Batch 0/7900 loss 82.904144 loss_att 177.776566 loss_ctc 78.806007 loss_rnnt 60.886208 hw_loss 0.673099 lr 0.00031604 rank 1
2023-02-11 02:13:08,260 DEBUG TRAIN Batch 0/7900 loss 69.079239 loss_att 187.574203 loss_ctc 63.109161 loss_rnnt 45.277512 hw_loss 0.168514 lr 0.00031604 rank 5
2023-02-11 02:13:08,262 DEBUG TRAIN Batch 0/7900 loss 113.589859 loss_att 234.710602 loss_ctc 119.918991 loss_rnnt 85.956589 hw_loss 0.480983 lr 0.00031604 rank 4
2023-02-11 02:13:08,262 DEBUG TRAIN Batch 0/7900 loss 100.772964 loss_att 237.910248 loss_ctc 99.683136 loss_rnnt 71.233505 hw_loss 0.423245 lr 0.00031604 rank 6
2023-02-11 02:13:08,264 DEBUG TRAIN Batch 0/7900 loss 114.810242 loss_att 232.815216 loss_ctc 112.741013 loss_rnnt 89.379837 hw_loss 0.394746 lr 0.00031604 rank 3
2023-02-11 02:13:08,267 DEBUG TRAIN Batch 0/7900 loss 108.860306 loss_att 200.542511 loss_ctc 114.412956 loss_rnnt 85.434875 hw_loss 0.815368 lr 0.00031604 rank 0
2023-02-11 02:13:08,267 DEBUG TRAIN Batch 0/7900 loss 94.872223 loss_att 188.739975 loss_ctc 101.347618 loss_rnnt 72.152313 hw_loss 0.578059 lr 0.00031604 rank 2
2023-02-11 02:14:22,389 DEBUG TRAIN Batch 0/8000 loss 121.336441 loss_att 225.837448 loss_ctc 131.971161 loss_rnnt 96.187317 hw_loss 0.530806 lr 0.00032004 rank 7
2023-02-11 02:14:22,389 DEBUG TRAIN Batch 0/8000 loss 95.690895 loss_att 211.380844 loss_ctc 94.603394 loss_rnnt 69.225357 hw_loss 0.651102 lr 0.00032004 rank 3
2023-02-11 02:14:22,391 DEBUG TRAIN Batch 0/8000 loss 98.235001 loss_att 211.892334 loss_ctc 101.706932 loss_rnnt 71.744980 hw_loss 0.617931 lr 0.00032004 rank 0
2023-02-11 02:14:22,392 DEBUG TRAIN Batch 0/8000 loss 72.015205 loss_att 173.548752 loss_ctc 64.974274 loss_rnnt 47.542885 hw_loss 0.957076 lr 0.00032004 rank 5
2023-02-11 02:14:22,393 DEBUG TRAIN Batch 0/8000 loss 73.182472 loss_att 173.673492 loss_ctc 69.970566 loss_rnnt 51.673901 hw_loss 0.344742 lr 0.00032004 rank 2
2023-02-11 02:14:22,395 DEBUG TRAIN Batch 0/8000 loss 72.820496 loss_att 170.795792 loss_ctc 71.013977 loss_rnnt 49.882858 hw_loss 0.671897 lr 0.00032004 rank 6
2023-02-11 02:14:22,398 DEBUG TRAIN Batch 0/8000 loss 74.043610 loss_att 142.193542 loss_ctc 71.861908 loss_rnnt 58.274151 hw_loss 0.455691 lr 0.00032004 rank 1
2023-02-11 02:14:22,398 DEBUG TRAIN Batch 0/8000 loss 67.697273 loss_att 146.041595 loss_ctc 69.342224 loss_rnnt 48.844955 hw_loss 0.555772 lr 0.00032004 rank 4
2023-02-11 02:15:38,825 DEBUG TRAIN Batch 0/8100 loss 70.625076 loss_att 171.905365 loss_ctc 70.567764 loss_rnnt 48.059891 hw_loss 0.434394 lr 0.00032404 rank 6
2023-02-11 02:15:38,825 DEBUG TRAIN Batch 0/8100 loss 92.919144 loss_att 192.981400 loss_ctc 95.287064 loss_rnnt 69.036942 hw_loss 0.666380 lr 0.00032404 rank 3
2023-02-11 02:15:38,830 DEBUG TRAIN Batch 0/8100 loss 68.610878 loss_att 172.406998 loss_ctc 64.871323 loss_rnnt 45.941589 hw_loss 0.451625 lr 0.00032404 rank 1
2023-02-11 02:15:38,830 DEBUG TRAIN Batch 0/8100 loss 104.098495 loss_att 202.491959 loss_ctc 110.870163 loss_rnnt 81.651268 hw_loss 0.349809 lr 0.00032404 rank 7
2023-02-11 02:15:38,833 DEBUG TRAIN Batch 0/8100 loss 75.920532 loss_att 161.718796 loss_ctc 81.214813 loss_rnnt 55.591011 hw_loss 0.461992 lr 0.00032404 rank 0
2023-02-11 02:15:38,834 DEBUG TRAIN Batch 0/8100 loss 129.049683 loss_att 213.817444 loss_ctc 139.202911 loss_rnnt 108.480453 hw_loss 0.424111 lr 0.00032404 rank 5
2023-02-11 02:15:38,834 DEBUG TRAIN Batch 0/8100 loss 71.319717 loss_att 144.475433 loss_ctc 75.575958 loss_rnnt 52.365303 hw_loss 0.704206 lr 0.00032404 rank 2
2023-02-11 02:15:38,837 DEBUG TRAIN Batch 0/8100 loss 72.607353 loss_att 168.468628 loss_ctc 72.089233 loss_rnnt 50.776291 hw_loss 0.511479 lr 0.00032404 rank 4
2023-02-11 02:16:55,959 DEBUG TRAIN Batch 0/8200 loss 79.688110 loss_att 137.812561 loss_ctc 78.174309 loss_rnnt 62.697121 hw_loss 1.043987 lr 0.00032804 rank 5
2023-02-11 02:16:55,962 DEBUG TRAIN Batch 0/8200 loss 67.475555 loss_att 140.182938 loss_ctc 63.097523 loss_rnnt 50.449177 hw_loss 0.575369 lr 0.00032804 rank 2
2023-02-11 02:16:55,963 DEBUG TRAIN Batch 0/8200 loss 77.622200 loss_att 153.956619 loss_ctc 76.183472 loss_rnnt 57.946083 hw_loss 0.862699 lr 0.00032804 rank 3
2023-02-11 02:16:55,963 DEBUG TRAIN Batch 0/8200 loss 82.052742 loss_att 152.782043 loss_ctc 85.604874 loss_rnnt 61.758739 hw_loss 1.063974 lr 0.00032804 rank 7
2023-02-11 02:16:55,965 DEBUG TRAIN Batch 0/8200 loss 65.013771 loss_att 120.704910 loss_ctc 67.161621 loss_rnnt 50.608044 hw_loss 0.558960 lr 0.00032804 rank 0
2023-02-11 02:16:55,966 DEBUG TRAIN Batch 0/8200 loss 78.058472 loss_att 157.012405 loss_ctc 72.127571 loss_rnnt 60.129768 hw_loss 0.549131 lr 0.00032804 rank 6
2023-02-11 02:16:55,969 DEBUG TRAIN Batch 0/8200 loss 115.504303 loss_att 242.355896 loss_ctc 115.481735 loss_rnnt 86.752335 hw_loss 0.634623 lr 0.00032804 rank 1
2023-02-11 02:16:55,976 DEBUG TRAIN Batch 0/8200 loss 67.905167 loss_att 156.876038 loss_ctc 64.146843 loss_rnnt 46.785233 hw_loss 0.717537 lr 0.00032804 rank 4
2023-02-11 02:18:10,116 DEBUG TRAIN Batch 0/8300 loss 105.002846 loss_att 214.786514 loss_ctc 111.527733 loss_rnnt 80.343040 hw_loss 0.343704 lr 0.00033204 rank 0
2023-02-11 02:18:10,119 DEBUG TRAIN Batch 0/8300 loss 121.582291 loss_att 245.070160 loss_ctc 135.384476 loss_rnnt 93.666428 hw_loss 0.258377 lr 0.00033204 rank 2
2023-02-11 02:18:10,119 DEBUG TRAIN Batch 0/8300 loss 95.343109 loss_att 212.477234 loss_ctc 92.282310 loss_rnnt 69.149666 hw_loss 0.595261 lr 0.00033204 rank 6
2023-02-11 02:18:10,119 DEBUG TRAIN Batch 0/8300 loss 71.071388 loss_att 146.392181 loss_ctc 71.367447 loss_rnnt 53.490082 hw_loss 0.464563 lr 0.00033204 rank 3
2023-02-11 02:18:10,123 DEBUG TRAIN Batch 0/8300 loss 63.039299 loss_att 178.842026 loss_ctc 59.751411 loss_rnnt 40.022148 hw_loss 0.055310 lr 0.00033204 rank 1
2023-02-11 02:18:10,149 DEBUG TRAIN Batch 0/8300 loss 86.095787 loss_att 202.763580 loss_ctc 87.201500 loss_rnnt 61.532722 hw_loss 0.202889 lr 0.00033204 rank 5
2023-02-11 02:18:10,153 DEBUG TRAIN Batch 0/8300 loss 22.289280 loss_att 32.344261 loss_ctc 20.498785 loss_rnnt 16.151997 hw_loss 0.818441 lr 0.00033204 rank 7
2023-02-11 02:18:10,167 DEBUG TRAIN Batch 0/8300 loss 90.071655 loss_att 185.517960 loss_ctc 88.998672 loss_rnnt 66.294556 hw_loss 0.905794 lr 0.00033204 rank 4
2023-02-11 02:19:10,797 DEBUG CV Batch 0/0 loss 20.543774 loss_att 20.532740 loss_ctc 14.685361 loss_rnnt 11.204678 hw_loss 1.897954 history loss 19.782893 rank 4
2023-02-11 02:19:10,799 DEBUG CV Batch 0/0 loss 20.543772 loss_att 20.532740 loss_ctc 14.685361 loss_rnnt 11.204678 hw_loss 1.897954 history loss 19.782891 rank 5
2023-02-11 02:19:10,804 DEBUG CV Batch 0/0 loss 20.543774 loss_att 20.532740 loss_ctc 14.685361 loss_rnnt 11.204678 hw_loss 1.897954 history loss 19.782893 rank 0
2023-02-11 02:19:10,804 DEBUG CV Batch 0/0 loss 20.543772 loss_att 20.532740 loss_ctc 14.685361 loss_rnnt 11.204678 hw_loss 1.897954 history loss 19.782891 rank 6
2023-02-11 02:19:10,807 DEBUG CV Batch 0/0 loss 20.543772 loss_att 20.532740 loss_ctc 14.685361 loss_rnnt 11.204678 hw_loss 1.897954 history loss 19.782891 rank 3
2023-02-11 02:19:10,815 DEBUG CV Batch 0/0 loss 20.543774 loss_att 20.532740 loss_ctc 14.685361 loss_rnnt 11.204678 hw_loss 1.897954 history loss 19.782893 rank 7
2023-02-11 02:19:10,817 DEBUG CV Batch 0/0 loss 20.543774 loss_att 20.532740 loss_ctc 14.685361 loss_rnnt 11.204678 hw_loss 1.897954 history loss 19.782893 rank 1
2023-02-11 02:19:10,819 DEBUG CV Batch 0/0 loss 20.543774 loss_att 20.532740 loss_ctc 14.685361 loss_rnnt 11.204678 hw_loss 1.897954 history loss 19.782893 rank 2
2023-02-11 02:19:21,959 DEBUG CV Batch 0/100 loss 63.393421 loss_att 118.825829 loss_ctc 66.588310 loss_rnnt 46.602001 hw_loss 0.989803 history loss 41.462842 rank 6
2023-02-11 02:19:21,996 DEBUG CV Batch 0/100 loss 63.393421 loss_att 118.825829 loss_ctc 66.588310 loss_rnnt 46.602001 hw_loss 0.989803 history loss 41.462842 rank 3
2023-02-11 02:19:22,062 DEBUG CV Batch 0/100 loss 63.393421 loss_att 118.825829 loss_ctc 66.588310 loss_rnnt 46.602001 hw_loss 0.989803 history loss 41.462842 rank 7
2023-02-11 02:19:22,120 DEBUG CV Batch 0/100 loss 63.393421 loss_att 118.825829 loss_ctc 66.588310 loss_rnnt 46.602001 hw_loss 0.989803 history loss 41.462842 rank 1
2023-02-11 02:19:22,147 DEBUG CV Batch 0/100 loss 63.393421 loss_att 118.825829 loss_ctc 66.588310 loss_rnnt 46.602001 hw_loss 0.989803 history loss 41.462843 rank 4
2023-02-11 02:19:22,233 DEBUG CV Batch 0/100 loss 63.393421 loss_att 118.825829 loss_ctc 66.588310 loss_rnnt 46.602001 hw_loss 0.989803 history loss 41.462842 rank 2
2023-02-11 02:19:22,294 DEBUG CV Batch 0/100 loss 63.393421 loss_att 118.825829 loss_ctc 66.588310 loss_rnnt 46.602001 hw_loss 0.989803 history loss 41.462842 rank 0
2023-02-11 02:19:22,396 DEBUG CV Batch 0/100 loss 63.393421 loss_att 118.825829 loss_ctc 66.588310 loss_rnnt 46.602001 hw_loss 0.989803 history loss 41.462842 rank 5
2023-02-11 02:19:35,569 DEBUG CV Batch 0/200 loss 131.563934 loss_att 325.562958 loss_ctc 129.049576 loss_rnnt 89.899292 hw_loss 0.600015 history loss 45.909070 rank 7
2023-02-11 02:19:35,673 DEBUG CV Batch 0/200 loss 131.563934 loss_att 325.562958 loss_ctc 129.049576 loss_rnnt 89.899292 hw_loss 0.600015 history loss 45.909070 rank 0
2023-02-11 02:19:35,879 DEBUG CV Batch 0/200 loss 131.563934 loss_att 325.562958 loss_ctc 129.049576 loss_rnnt 89.899292 hw_loss 0.600015 history loss 45.909070 rank 3
2023-02-11 02:19:35,886 DEBUG CV Batch 0/200 loss 131.563934 loss_att 325.562958 loss_ctc 129.049576 loss_rnnt 89.899292 hw_loss 0.600015 history loss 45.909070 rank 2
2023-02-11 02:19:35,935 DEBUG CV Batch 0/200 loss 131.563934 loss_att 325.562958 loss_ctc 129.049576 loss_rnnt 89.899292 hw_loss 0.600015 history loss 45.909070 rank 1
2023-02-11 02:19:35,966 DEBUG CV Batch 0/200 loss 131.563934 loss_att 325.562958 loss_ctc 129.049576 loss_rnnt 89.899292 hw_loss 0.600015 history loss 45.909070 rank 5
2023-02-11 02:19:36,242 DEBUG CV Batch 0/200 loss 131.563934 loss_att 325.562958 loss_ctc 129.049576 loss_rnnt 89.899292 hw_loss 0.600015 history loss 45.909070 rank 6
2023-02-11 02:19:36,531 DEBUG CV Batch 0/200 loss 131.563934 loss_att 325.562958 loss_ctc 129.049576 loss_rnnt 89.899292 hw_loss 0.600015 history loss 45.909070 rank 4
2023-02-11 02:19:47,709 DEBUG CV Batch 0/300 loss 44.970287 loss_att 85.230667 loss_ctc 47.779259 loss_rnnt 32.653481 hw_loss 0.729413 history loss 45.228262 rank 0
2023-02-11 02:19:47,958 DEBUG CV Batch 0/300 loss 44.970287 loss_att 85.230667 loss_ctc 47.779259 loss_rnnt 32.653481 hw_loss 0.729413 history loss 45.228262 rank 7
2023-02-11 02:19:48,114 DEBUG CV Batch 0/300 loss 44.970287 loss_att 85.230667 loss_ctc 47.779259 loss_rnnt 32.653481 hw_loss 0.729413 history loss 45.228262 rank 5
2023-02-11 02:19:48,295 DEBUG CV Batch 0/300 loss 44.970287 loss_att 85.230667 loss_ctc 47.779259 loss_rnnt 32.653481 hw_loss 0.729413 history loss 45.228262 rank 3
2023-02-11 02:19:48,357 DEBUG CV Batch 0/300 loss 44.970287 loss_att 85.230667 loss_ctc 47.779259 loss_rnnt 32.653481 hw_loss 0.729413 history loss 45.228262 rank 2
2023-02-11 02:19:48,444 DEBUG CV Batch 0/300 loss 44.970287 loss_att 85.230667 loss_ctc 47.779259 loss_rnnt 32.653481 hw_loss 0.729413 history loss 45.228262 rank 1
2023-02-11 02:19:48,682 DEBUG CV Batch 0/300 loss 44.970287 loss_att 85.230667 loss_ctc 47.779259 loss_rnnt 32.653481 hw_loss 0.729413 history loss 45.228262 rank 6
2023-02-11 02:19:48,926 DEBUG CV Batch 0/300 loss 44.970287 loss_att 85.230667 loss_ctc 47.779259 loss_rnnt 32.653481 hw_loss 0.729413 history loss 45.228262 rank 4
2023-02-11 02:19:59,654 DEBUG CV Batch 0/400 loss 182.677933 loss_att 463.001648 loss_ctc 155.437027 loss_rnnt 127.657562 hw_loss 0.485202 history loss 47.848997 rank 0
2023-02-11 02:19:59,997 DEBUG CV Batch 0/400 loss 182.677933 loss_att 463.001648 loss_ctc 155.437027 loss_rnnt 127.657562 hw_loss 0.485202 history loss 47.848997 rank 7
2023-02-11 02:20:00,172 DEBUG CV Batch 0/400 loss 182.677933 loss_att 463.001648 loss_ctc 155.437027 loss_rnnt 127.657562 hw_loss 0.485202 history loss 47.848997 rank 5
2023-02-11 02:20:00,289 DEBUG CV Batch 0/400 loss 182.677933 loss_att 463.001648 loss_ctc 155.437027 loss_rnnt 127.657562 hw_loss 0.485202 history loss 47.848997 rank 3
2023-02-11 02:20:00,337 DEBUG CV Batch 0/400 loss 182.677933 loss_att 463.001648 loss_ctc 155.437027 loss_rnnt 127.657562 hw_loss 0.485202 history loss 47.848997 rank 2
2023-02-11 02:20:00,424 DEBUG CV Batch 0/400 loss 182.677933 loss_att 463.001648 loss_ctc 155.437027 loss_rnnt 127.657562 hw_loss 0.485202 history loss 47.848997 rank 1
2023-02-11 02:20:00,605 DEBUG CV Batch 0/400 loss 182.677933 loss_att 463.001648 loss_ctc 155.437027 loss_rnnt 127.657562 hw_loss 0.485202 history loss 47.848997 rank 6
2023-02-11 02:20:01,742 DEBUG CV Batch 0/400 loss 182.677933 loss_att 463.001648 loss_ctc 155.437027 loss_rnnt 127.657562 hw_loss 0.485202 history loss 47.848997 rank 4
2023-02-11 02:20:10,061 DEBUG CV Batch 0/500 loss 62.017509 loss_att 117.688614 loss_ctc 64.537804 loss_rnnt 45.832718 hw_loss 0.883974 history loss 48.297553 rank 0
2023-02-11 02:20:10,535 DEBUG CV Batch 0/500 loss 62.017509 loss_att 117.688614 loss_ctc 64.537804 loss_rnnt 45.832718 hw_loss 0.883974 history loss 48.297553 rank 7
2023-02-11 02:20:10,685 DEBUG CV Batch 0/500 loss 62.017509 loss_att 117.688614 loss_ctc 64.537804 loss_rnnt 45.832718 hw_loss 0.883974 history loss 48.297553 rank 5
2023-02-11 02:20:10,781 DEBUG CV Batch 0/500 loss 62.017509 loss_att 117.688614 loss_ctc 64.537804 loss_rnnt 45.832718 hw_loss 0.883974 history loss 48.297553 rank 3
2023-02-11 02:20:10,982 DEBUG CV Batch 0/500 loss 62.017509 loss_att 117.688614 loss_ctc 64.537804 loss_rnnt 45.832718 hw_loss 0.883974 history loss 48.297553 rank 1
2023-02-11 02:20:11,045 DEBUG CV Batch 0/500 loss 62.017509 loss_att 117.688614 loss_ctc 64.537804 loss_rnnt 45.832718 hw_loss 0.883974 history loss 48.297553 rank 6
2023-02-11 02:20:11,405 DEBUG CV Batch 0/500 loss 62.017509 loss_att 117.688614 loss_ctc 64.537804 loss_rnnt 45.832718 hw_loss 0.883974 history loss 48.297553 rank 2
2023-02-11 02:20:12,240 DEBUG CV Batch 0/500 loss 62.017509 loss_att 117.688614 loss_ctc 64.537804 loss_rnnt 45.832718 hw_loss 0.883974 history loss 48.297553 rank 4
2023-02-11 02:20:22,137 DEBUG CV Batch 0/600 loss 42.511581 loss_att 47.355412 loss_ctc 37.763779 loss_rnnt 28.930845 hw_loss 2.483439 history loss 50.021501 rank 0
2023-02-11 02:20:22,609 DEBUG CV Batch 0/600 loss 42.511581 loss_att 47.355412 loss_ctc 37.763779 loss_rnnt 28.930845 hw_loss 2.483439 history loss 50.021501 rank 7
2023-02-11 02:20:22,730 DEBUG CV Batch 0/600 loss 42.511581 loss_att 47.355412 loss_ctc 37.763779 loss_rnnt 28.930845 hw_loss 2.483439 history loss 50.021501 rank 5
2023-02-11 02:20:22,855 DEBUG CV Batch 0/600 loss 42.511581 loss_att 47.355412 loss_ctc 37.763779 loss_rnnt 28.930845 hw_loss 2.483439 history loss 50.021501 rank 3
2023-02-11 02:20:23,044 DEBUG CV Batch 0/600 loss 42.511581 loss_att 47.355412 loss_ctc 37.763779 loss_rnnt 28.930845 hw_loss 2.483439 history loss 50.021501 rank 1
2023-02-11 02:20:23,128 DEBUG CV Batch 0/600 loss 42.511581 loss_att 47.355412 loss_ctc 37.763779 loss_rnnt 28.930845 hw_loss 2.483439 history loss 50.021501 rank 6
2023-02-11 02:20:23,852 DEBUG CV Batch 0/600 loss 42.511581 loss_att 47.355412 loss_ctc 37.763779 loss_rnnt 28.930845 hw_loss 2.483439 history loss 50.021501 rank 2
2023-02-11 02:20:24,328 DEBUG CV Batch 0/600 loss 42.511581 loss_att 47.355412 loss_ctc 37.763779 loss_rnnt 28.930845 hw_loss 2.483439 history loss 50.021501 rank 4
2023-02-11 02:20:33,394 DEBUG CV Batch 0/700 loss 185.438828 loss_att 401.640472 loss_ctc 185.107224 loss_rnnt 141.730560 hw_loss 0.096029 history loss 51.123726 rank 0
2023-02-11 02:20:33,881 DEBUG CV Batch 0/700 loss 185.438828 loss_att 401.640472 loss_ctc 185.107224 loss_rnnt 141.730560 hw_loss 0.096029 history loss 51.123726 rank 7
2023-02-11 02:20:34,150 DEBUG CV Batch 0/700 loss 185.438828 loss_att 401.640472 loss_ctc 185.107224 loss_rnnt 141.730560 hw_loss 0.096029 history loss 51.123726 rank 5
2023-02-11 02:20:34,157 DEBUG CV Batch 0/700 loss 185.438828 loss_att 401.640472 loss_ctc 185.107224 loss_rnnt 141.730560 hw_loss 0.096029 history loss 51.123726 rank 3
2023-02-11 02:20:34,266 DEBUG CV Batch 0/700 loss 185.438828 loss_att 401.640472 loss_ctc 185.107224 loss_rnnt 141.730560 hw_loss 0.096029 history loss 51.123726 rank 1
2023-02-11 02:20:34,839 DEBUG CV Batch 0/700 loss 185.438828 loss_att 401.640472 loss_ctc 185.107224 loss_rnnt 141.730560 hw_loss 0.096029 history loss 51.123726 rank 6
2023-02-11 02:20:35,199 DEBUG CV Batch 0/700 loss 185.438828 loss_att 401.640472 loss_ctc 185.107224 loss_rnnt 141.730560 hw_loss 0.096029 history loss 51.123726 rank 2
2023-02-11 02:20:35,662 DEBUG CV Batch 0/700 loss 185.438828 loss_att 401.640472 loss_ctc 185.107224 loss_rnnt 141.730560 hw_loss 0.096029 history loss 51.123726 rank 4
2023-02-11 02:20:44,515 DEBUG CV Batch 0/800 loss 64.096809 loss_att 119.972382 loss_ctc 66.403549 loss_rnnt 46.968597 hw_loss 1.058538 history loss 49.732799 rank 0
2023-02-11 02:20:45,117 DEBUG CV Batch 0/800 loss 64.096809 loss_att 119.972382 loss_ctc 66.403549 loss_rnnt 46.968597 hw_loss 1.058538 history loss 49.732799 rank 7
2023-02-11 02:20:45,381 DEBUG CV Batch 0/800 loss 64.096809 loss_att 119.972382 loss_ctc 66.403549 loss_rnnt 46.968597 hw_loss 1.058538 history loss 49.732799 rank 5
2023-02-11 02:20:45,386 DEBUG CV Batch 0/800 loss 64.096809 loss_att 119.972382 loss_ctc 66.403549 loss_rnnt 46.968597 hw_loss 1.058538 history loss 49.732799 rank 3
2023-02-11 02:20:46,343 DEBUG CV Batch 0/800 loss 64.096809 loss_att 119.972382 loss_ctc 66.403549 loss_rnnt 46.968597 hw_loss 1.058538 history loss 49.732799 rank 1
2023-02-11 02:20:46,580 DEBUG CV Batch 0/800 loss 64.096809 loss_att 119.972382 loss_ctc 66.403549 loss_rnnt 46.968597 hw_loss 1.058538 history loss 49.732799 rank 2
2023-02-11 02:20:46,915 DEBUG CV Batch 0/800 loss 64.096809 loss_att 119.972382 loss_ctc 66.403549 loss_rnnt 46.968597 hw_loss 1.058538 history loss 49.732799 rank 6
2023-02-11 02:20:47,636 DEBUG CV Batch 0/800 loss 64.096809 loss_att 119.972382 loss_ctc 66.403549 loss_rnnt 46.968597 hw_loss 1.058538 history loss 49.732799 rank 4
2023-02-11 02:20:58,124 DEBUG CV Batch 0/900 loss 114.772713 loss_att 291.169464 loss_ctc 108.581497 loss_rnnt 78.393646 hw_loss 0.360977 history loss 49.903301 rank 0
2023-02-11 02:20:58,443 DEBUG CV Batch 0/900 loss 114.772713 loss_att 291.169464 loss_ctc 108.581497 loss_rnnt 78.393646 hw_loss 0.360977 history loss 49.903301 rank 7
2023-02-11 02:20:58,688 DEBUG CV Batch 0/900 loss 114.772713 loss_att 291.169464 loss_ctc 108.581497 loss_rnnt 78.393646 hw_loss 0.360977 history loss 49.903301 rank 3
2023-02-11 02:20:59,048 DEBUG CV Batch 0/900 loss 114.772713 loss_att 291.169464 loss_ctc 108.581497 loss_rnnt 78.393646 hw_loss 0.360977 history loss 49.903301 rank 5
2023-02-11 02:21:00,022 DEBUG CV Batch 0/900 loss 114.772713 loss_att 291.169464 loss_ctc 108.581497 loss_rnnt 78.393646 hw_loss 0.360977 history loss 49.903301 rank 1
2023-02-11 02:21:00,680 DEBUG CV Batch 0/900 loss 114.772713 loss_att 291.169464 loss_ctc 108.581497 loss_rnnt 78.393646 hw_loss 0.360977 history loss 49.903301 rank 6
2023-02-11 02:21:00,992 DEBUG CV Batch 0/900 loss 114.772713 loss_att 291.169464 loss_ctc 108.581497 loss_rnnt 78.393646 hw_loss 0.360977 history loss 49.903301 rank 4
2023-02-11 02:21:01,390 DEBUG CV Batch 0/900 loss 114.772713 loss_att 291.169464 loss_ctc 108.581497 loss_rnnt 78.393646 hw_loss 0.360977 history loss 49.903301 rank 2
2023-02-11 02:21:10,379 DEBUG CV Batch 0/1000 loss 40.830231 loss_att 77.136665 loss_ctc 38.826332 loss_rnnt 27.836187 hw_loss 1.124989 history loss 49.392879 rank 0
2023-02-11 02:21:10,617 DEBUG CV Batch 0/1000 loss 40.830231 loss_att 77.136665 loss_ctc 38.826332 loss_rnnt 27.836187 hw_loss 1.124989 history loss 49.392879 rank 7
2023-02-11 02:21:10,795 DEBUG CV Batch 0/1000 loss 40.830231 loss_att 77.136665 loss_ctc 38.826332 loss_rnnt 27.836187 hw_loss 1.124989 history loss 49.392879 rank 3
2023-02-11 02:21:11,198 DEBUG CV Batch 0/1000 loss 40.830231 loss_att 77.136665 loss_ctc 38.826332 loss_rnnt 27.836187 hw_loss 1.124989 history loss 49.392879 rank 5
2023-02-11 02:21:12,240 DEBUG CV Batch 0/1000 loss 40.830231 loss_att 77.136665 loss_ctc 38.826332 loss_rnnt 27.836187 hw_loss 1.124989 history loss 49.392879 rank 1
2023-02-11 02:21:12,926 DEBUG CV Batch 0/1000 loss 40.830231 loss_att 77.136665 loss_ctc 38.826332 loss_rnnt 27.836187 hw_loss 1.124989 history loss 49.392879 rank 6
2023-02-11 02:21:13,189 DEBUG CV Batch 0/1000 loss 40.830231 loss_att 77.136665 loss_ctc 38.826332 loss_rnnt 27.836187 hw_loss 1.124989 history loss 49.392879 rank 4
2023-02-11 02:21:13,851 DEBUG CV Batch 0/1000 loss 40.830231 loss_att 77.136665 loss_ctc 38.826332 loss_rnnt 27.836187 hw_loss 1.124989 history loss 49.392879 rank 2
2023-02-11 02:21:22,236 DEBUG CV Batch 0/1100 loss 27.747623 loss_att 24.416775 loss_ctc 22.004467 loss_rnnt 16.278229 hw_loss 2.418997 history loss 49.503250 rank 0
2023-02-11 02:21:22,602 DEBUG CV Batch 0/1100 loss 27.747623 loss_att 24.416775 loss_ctc 22.004467 loss_rnnt 16.278229 hw_loss 2.418997 history loss 49.503250 rank 7
2023-02-11 02:21:22,631 DEBUG CV Batch 0/1100 loss 27.747623 loss_att 24.416775 loss_ctc 22.004467 loss_rnnt 16.278229 hw_loss 2.418997 history loss 49.503250 rank 3
2023-02-11 02:21:23,171 DEBUG CV Batch 0/1100 loss 27.747623 loss_att 24.416775 loss_ctc 22.004467 loss_rnnt 16.278229 hw_loss 2.418997 history loss 49.503250 rank 5
2023-02-11 02:21:24,145 DEBUG CV Batch 0/1100 loss 27.747623 loss_att 24.416775 loss_ctc 22.004467 loss_rnnt 16.278229 hw_loss 2.418997 history loss 49.503250 rank 1
2023-02-11 02:21:24,736 DEBUG CV Batch 0/1100 loss 27.747623 loss_att 24.416775 loss_ctc 22.004467 loss_rnnt 16.278229 hw_loss 2.418997 history loss 49.503250 rank 6
2023-02-11 02:21:25,247 DEBUG CV Batch 0/1100 loss 27.747622 loss_att 24.416775 loss_ctc 22.004467 loss_rnnt 16.278229 hw_loss 2.418997 history loss 49.503250 rank 4
2023-02-11 02:21:26,742 DEBUG CV Batch 0/1100 loss 27.747623 loss_att 24.416775 loss_ctc 22.004467 loss_rnnt 16.278229 hw_loss 2.418997 history loss 49.503250 rank 2
2023-02-11 02:21:32,603 DEBUG CV Batch 0/1200 loss 72.468628 loss_att 132.792572 loss_ctc 78.768333 loss_rnnt 54.956154 hw_loss 0.863948 history loss 49.916694 rank 0
2023-02-11 02:21:33,062 DEBUG CV Batch 0/1200 loss 72.468628 loss_att 132.792572 loss_ctc 78.768333 loss_rnnt 54.956154 hw_loss 0.863948 history loss 49.916694 rank 7
2023-02-11 02:21:33,081 DEBUG CV Batch 0/1200 loss 72.468628 loss_att 132.792572 loss_ctc 78.768333 loss_rnnt 54.956154 hw_loss 0.863948 history loss 49.916694 rank 3
2023-02-11 02:21:33,666 DEBUG CV Batch 0/1200 loss 72.468628 loss_att 132.792572 loss_ctc 78.768333 loss_rnnt 54.956154 hw_loss 0.863948 history loss 49.916694 rank 5
2023-02-11 02:21:34,587 DEBUG CV Batch 0/1200 loss 72.468628 loss_att 132.792572 loss_ctc 78.768333 loss_rnnt 54.956154 hw_loss 0.863948 history loss 49.916694 rank 1
2023-02-11 02:21:35,559 DEBUG CV Batch 0/1200 loss 72.468628 loss_att 132.792572 loss_ctc 78.768333 loss_rnnt 54.956154 hw_loss 0.863948 history loss 49.916694 rank 6
2023-02-11 02:21:35,766 DEBUG CV Batch 0/1200 loss 72.468628 loss_att 132.792572 loss_ctc 78.768333 loss_rnnt 54.956154 hw_loss 0.863948 history loss 49.916694 rank 4
2023-02-11 02:21:37,239 DEBUG CV Batch 0/1200 loss 72.468628 loss_att 132.792572 loss_ctc 78.768333 loss_rnnt 54.956154 hw_loss 0.863948 history loss 49.916694 rank 2
2023-02-11 02:21:44,460 DEBUG CV Batch 0/1300 loss 37.918571 loss_att 45.824982 loss_ctc 36.024853 loss_rnnt 26.883835 hw_loss 1.819866 history loss 50.414595 rank 0
2023-02-11 02:21:44,967 DEBUG CV Batch 0/1300 loss 37.918571 loss_att 45.824982 loss_ctc 36.024853 loss_rnnt 26.883835 hw_loss 1.819865 history loss 50.414595 rank 3
2023-02-11 02:21:44,989 DEBUG CV Batch 0/1300 loss 37.918571 loss_att 45.824982 loss_ctc 36.024853 loss_rnnt 26.883835 hw_loss 1.819865 history loss 50.414595 rank 7
2023-02-11 02:21:45,535 DEBUG CV Batch 0/1300 loss 37.918571 loss_att 45.824982 loss_ctc 36.024853 loss_rnnt 26.883835 hw_loss 1.819866 history loss 50.414595 rank 5
2023-02-11 02:21:46,502 DEBUG CV Batch 0/1300 loss 37.918571 loss_att 45.824982 loss_ctc 36.024853 loss_rnnt 26.883835 hw_loss 1.819865 history loss 50.414595 rank 1
2023-02-11 02:21:47,506 DEBUG CV Batch 0/1300 loss 37.918571 loss_att 45.824982 loss_ctc 36.024853 loss_rnnt 26.883835 hw_loss 1.819866 history loss 50.414595 rank 6
2023-02-11 02:21:47,733 DEBUG CV Batch 0/1300 loss 37.918571 loss_att 45.824982 loss_ctc 36.024853 loss_rnnt 26.883835 hw_loss 1.819866 history loss 50.414595 rank 4
2023-02-11 02:21:49,316 DEBUG CV Batch 0/1300 loss 37.918571 loss_att 45.824982 loss_ctc 36.024853 loss_rnnt 26.883835 hw_loss 1.819866 history loss 50.414595 rank 2
2023-02-11 02:21:55,527 DEBUG CV Batch 0/1400 loss 136.816132 loss_att 308.288116 loss_ctc 127.072159 loss_rnnt 100.567642 hw_loss 0.609991 history loss 51.029973 rank 0
2023-02-11 02:21:56,117 DEBUG CV Batch 0/1400 loss 136.816132 loss_att 308.288116 loss_ctc 127.072159 loss_rnnt 100.567642 hw_loss 0.609991 history loss 51.029973 rank 3
2023-02-11 02:21:56,118 DEBUG CV Batch 0/1400 loss 136.816132 loss_att 308.288116 loss_ctc 127.072159 loss_rnnt 100.567642 hw_loss 0.609991 history loss 51.029973 rank 7
2023-02-11 02:21:56,682 DEBUG CV Batch 0/1400 loss 136.816132 loss_att 308.288116 loss_ctc 127.072159 loss_rnnt 100.567642 hw_loss 0.609991 history loss 51.029973 rank 5
2023-02-11 02:21:58,879 DEBUG CV Batch 0/1400 loss 136.816132 loss_att 308.288116 loss_ctc 127.072159 loss_rnnt 100.567642 hw_loss 0.609991 history loss 51.029973 rank 4
2023-02-11 02:21:58,965 DEBUG CV Batch 0/1400 loss 136.816132 loss_att 308.288116 loss_ctc 127.072159 loss_rnnt 100.567642 hw_loss 0.609991 history loss 51.029973 rank 1
2023-02-11 02:21:59,732 DEBUG CV Batch 0/1400 loss 136.816132 loss_att 308.288116 loss_ctc 127.072159 loss_rnnt 100.567642 hw_loss 0.609991 history loss 51.029973 rank 6
2023-02-11 02:22:00,542 DEBUG CV Batch 0/1400 loss 136.816132 loss_att 308.288116 loss_ctc 127.072159 loss_rnnt 100.567642 hw_loss 0.609991 history loss 51.029973 rank 2
2023-02-11 02:22:07,335 DEBUG CV Batch 0/1500 loss 66.204254 loss_att 127.399963 loss_ctc 63.481899 loss_rnnt 48.681702 hw_loss 1.058699 history loss 50.368759 rank 7
2023-02-11 02:22:07,432 DEBUG CV Batch 0/1500 loss 66.204254 loss_att 127.399963 loss_ctc 63.481899 loss_rnnt 48.681702 hw_loss 1.058699 history loss 50.368759 rank 0
2023-02-11 02:22:07,978 DEBUG CV Batch 0/1500 loss 66.204254 loss_att 127.399963 loss_ctc 63.481899 loss_rnnt 48.681702 hw_loss 1.058699 history loss 50.368759 rank 3
2023-02-11 02:22:08,174 DEBUG CV Batch 0/1500 loss 66.204254 loss_att 127.399963 loss_ctc 63.481899 loss_rnnt 48.681702 hw_loss 1.058699 history loss 50.368759 rank 5
2023-02-11 02:22:10,546 DEBUG CV Batch 0/1500 loss 66.204254 loss_att 127.399963 loss_ctc 63.481899 loss_rnnt 48.681702 hw_loss 1.058699 history loss 50.368759 rank 4
2023-02-11 02:22:11,362 DEBUG CV Batch 0/1500 loss 66.204254 loss_att 127.399963 loss_ctc 63.481899 loss_rnnt 48.681702 hw_loss 1.058699 history loss 50.368759 rank 1
2023-02-11 02:22:11,922 DEBUG CV Batch 0/1500 loss 66.204254 loss_att 127.399963 loss_ctc 63.481899 loss_rnnt 48.681702 hw_loss 1.058699 history loss 50.368759 rank 2
2023-02-11 02:22:12,247 DEBUG CV Batch 0/1500 loss 66.204254 loss_att 127.399963 loss_ctc 63.481899 loss_rnnt 48.681702 hw_loss 1.058699 history loss 50.368759 rank 6
2023-02-11 02:22:20,468 DEBUG CV Batch 0/1600 loss 116.411224 loss_att 305.331879 loss_ctc 102.300507 loss_rnnt 75.757065 hw_loss 0.890898 history loss 50.475584 rank 7
2023-02-11 02:22:21,018 DEBUG CV Batch 0/1600 loss 116.411224 loss_att 305.331879 loss_ctc 102.300507 loss_rnnt 75.757065 hw_loss 0.890898 history loss 50.475584 rank 0
2023-02-11 02:22:21,684 DEBUG CV Batch 0/1600 loss 116.411224 loss_att 305.331879 loss_ctc 102.300507 loss_rnnt 75.757065 hw_loss 0.890898 history loss 50.475584 rank 5
2023-02-11 02:22:21,730 DEBUG CV Batch 0/1600 loss 116.411224 loss_att 305.331879 loss_ctc 102.300507 loss_rnnt 75.757065 hw_loss 0.890898 history loss 50.475584 rank 3
2023-02-11 02:22:24,306 DEBUG CV Batch 0/1600 loss 116.411224 loss_att 305.331879 loss_ctc 102.300507 loss_rnnt 75.757065 hw_loss 0.890898 history loss 50.475584 rank 4
2023-02-11 02:22:25,172 DEBUG CV Batch 0/1600 loss 116.411224 loss_att 305.331879 loss_ctc 102.300507 loss_rnnt 75.757065 hw_loss 0.890898 history loss 50.475584 rank 1
2023-02-11 02:22:25,532 DEBUG CV Batch 0/1600 loss 116.411224 loss_att 305.331879 loss_ctc 102.300507 loss_rnnt 75.757065 hw_loss 0.890898 history loss 50.475584 rank 2
2023-02-11 02:22:25,995 DEBUG CV Batch 0/1600 loss 116.411224 loss_att 305.331879 loss_ctc 102.300507 loss_rnnt 75.757065 hw_loss 0.890898 history loss 50.475584 rank 6
2023-02-11 02:22:33,009 DEBUG CV Batch 0/1700 loss 57.551491 loss_att 98.391068 loss_ctc 60.627178 loss_rnnt 44.396183 hw_loss 0.858244 history loss 50.166222 rank 7
2023-02-11 02:22:33,466 DEBUG CV Batch 0/1700 loss 57.551491 loss_att 98.391068 loss_ctc 60.627178 loss_rnnt 44.396183 hw_loss 0.858244 history loss 50.166222 rank 0
2023-02-11 02:22:34,132 DEBUG CV Batch 0/1700 loss 57.551491 loss_att 98.391068 loss_ctc 60.627178 loss_rnnt 44.396183 hw_loss 0.858244 history loss 50.166222 rank 3
2023-02-11 02:22:34,202 DEBUG CV Batch 0/1700 loss 57.551491 loss_att 98.391068 loss_ctc 60.627178 loss_rnnt 44.396183 hw_loss 0.858244 history loss 50.166222 rank 5
2023-02-11 02:22:36,839 DEBUG CV Batch 0/1700 loss 57.551491 loss_att 98.391068 loss_ctc 60.627178 loss_rnnt 44.396183 hw_loss 0.858244 history loss 50.166222 rank 4
2023-02-11 02:22:37,672 DEBUG CV Batch 0/1700 loss 57.551491 loss_att 98.391068 loss_ctc 60.627178 loss_rnnt 44.396183 hw_loss 0.858244 history loss 50.166222 rank 1
2023-02-11 02:22:38,142 DEBUG CV Batch 0/1700 loss 57.551491 loss_att 98.391068 loss_ctc 60.627178 loss_rnnt 44.396183 hw_loss 0.858244 history loss 50.166222 rank 2
2023-02-11 02:22:38,422 DEBUG CV Batch 0/1700 loss 57.551491 loss_att 98.391068 loss_ctc 60.627178 loss_rnnt 44.396183 hw_loss 0.858244 history loss 50.166222 rank 6
2023-02-11 02:22:42,188 INFO Epoch 0 CV info cv_loss 50.27249523779788
2023-02-11 02:22:42,190 INFO Epoch 1 TRAIN info lr 0.00033351999999999996
2023-02-11 02:22:42,193 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 02:22:42,660 INFO Epoch 0 CV info cv_loss 50.272495207198695
2023-02-11 02:22:42,661 INFO Checkpoint: save to checkpoint exp2_10_rnnt_bias_loss/0.pt
2023-02-11 02:22:43,247 INFO Epoch 0 CV info cv_loss 50.27249520664736
2023-02-11 02:22:43,248 INFO Epoch 1 TRAIN info lr 0.00033332
2023-02-11 02:22:43,251 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 02:22:43,277 INFO Epoch 1 TRAIN info lr 0.0003338
2023-02-11 02:22:43,281 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 02:22:43,362 INFO Epoch 0 CV info cv_loss 50.272495238762716
2023-02-11 02:22:43,363 INFO Epoch 1 TRAIN info lr 0.00033371999999999997
2023-02-11 02:22:43,368 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 02:22:45,992 INFO Epoch 0 CV info cv_loss 50.2724952197416
2023-02-11 02:22:45,993 INFO Epoch 1 TRAIN info lr 0.0003328
2023-02-11 02:22:45,995 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 02:22:46,776 INFO Epoch 0 CV info cv_loss 50.2724952249793
2023-02-11 02:22:46,777 INFO Epoch 1 TRAIN info lr 0.00033496
2023-02-11 02:22:46,780 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 02:22:47,311 INFO Epoch 0 CV info cv_loss 50.2724952358682
2023-02-11 02:22:47,313 INFO Epoch 1 TRAIN info lr 0.00033363999999999996
2023-02-11 02:22:47,316 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 02:22:47,483 INFO Epoch 0 CV info cv_loss 50.272495215193075
2023-02-11 02:22:47,484 INFO Epoch 1 TRAIN info lr 0.00033368
2023-02-11 02:22:47,489 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 02:23:59,883 DEBUG TRAIN Batch 1/0 loss 39.309502 loss_att 40.136475 loss_ctc 37.275421 loss_rnnt 31.037304 hw_loss 1.570877 lr 0.00033356 rank 7
2023-02-11 02:23:59,886 DEBUG TRAIN Batch 1/0 loss 36.864243 loss_att 38.921089 loss_ctc 36.496841 loss_rnnt 29.829733 hw_loss 1.251023 lr 0.00033376 rank 5
2023-02-11 02:23:59,887 DEBUG TRAIN Batch 1/0 loss 38.351601 loss_att 39.098721 loss_ctc 35.689293 loss_rnnt 30.631733 hw_loss 1.486016 lr 0.00033336 rank 3
2023-02-11 02:23:59,893 DEBUG TRAIN Batch 1/0 loss 32.592190 loss_att 36.791866 loss_ctc 27.730227 loss_rnnt 24.755003 hw_loss 1.433534 lr 0.00033384 rank 0
2023-02-11 02:23:59,896 DEBUG TRAIN Batch 1/0 loss 30.975855 loss_att 37.760273 loss_ctc 30.108320 loss_rnnt 24.489424 hw_loss 0.983478 lr 0.00033372 rank 6
2023-02-11 02:23:59,896 DEBUG TRAIN Batch 1/0 loss 33.067310 loss_att 36.900742 loss_ctc 30.886076 loss_rnnt 26.471682 hw_loss 1.147457 lr 0.00033368 rank 2
2023-02-11 02:23:59,910 DEBUG TRAIN Batch 1/0 loss 26.394871 loss_att 29.896692 loss_ctc 22.824831 loss_rnnt 21.438551 hw_loss 0.887242 lr 0.00033500 rank 1
2023-02-11 02:23:59,933 DEBUG TRAIN Batch 1/0 loss 29.809885 loss_att 31.395256 loss_ctc 25.819635 loss_rnnt 23.250429 hw_loss 1.270202 lr 0.00033284 rank 4
2023-02-11 02:25:15,728 DEBUG TRAIN Batch 1/100 loss 99.520370 loss_att 201.777954 loss_ctc 105.026726 loss_rnnt 74.706375 hw_loss 0.680306 lr 0.00033768 rank 2
2023-02-11 02:25:15,730 DEBUG TRAIN Batch 1/100 loss 93.137711 loss_att 203.073120 loss_ctc 97.670029 loss_rnnt 67.454971 hw_loss 0.579628 lr 0.00033776 rank 5
2023-02-11 02:25:15,731 DEBUG TRAIN Batch 1/100 loss 87.691917 loss_att 179.974808 loss_ctc 87.383713 loss_rnnt 64.912979 hw_loss 0.818149 lr 0.00033756 rank 7
2023-02-11 02:25:15,733 DEBUG TRAIN Batch 1/100 loss 97.881508 loss_att 201.305847 loss_ctc 89.896118 loss_rnnt 74.338615 hw_loss 0.735516 lr 0.00033736 rank 3
2023-02-11 02:25:15,734 DEBUG TRAIN Batch 1/100 loss 89.259354 loss_att 176.554657 loss_ctc 93.158501 loss_rnnt 68.091446 hw_loss 0.597931 lr 0.00033784 rank 0
2023-02-11 02:25:15,734 DEBUG TRAIN Batch 1/100 loss 113.858818 loss_att 198.701050 loss_ctc 123.546890 loss_rnnt 92.787567 hw_loss 0.527073 lr 0.00033900 rank 1
2023-02-11 02:25:15,735 DEBUG TRAIN Batch 1/100 loss 94.873764 loss_att 185.535492 loss_ctc 102.740440 loss_rnnt 73.216904 hw_loss 0.464180 lr 0.00033684 rank 4
2023-02-11 02:25:15,739 DEBUG TRAIN Batch 1/100 loss 98.638596 loss_att 200.437378 loss_ctc 106.203110 loss_rnnt 75.255272 hw_loss 0.377807 lr 0.00033772 rank 6
2023-02-11 02:26:30,389 DEBUG TRAIN Batch 1/200 loss 113.089233 loss_att 217.199310 loss_ctc 118.705711 loss_rnnt 90.727142 hw_loss 0.148354 lr 0.00034184 rank 0
2023-02-11 02:26:30,391 DEBUG TRAIN Batch 1/200 loss 100.767731 loss_att 175.984863 loss_ctc 106.545403 loss_rnnt 80.813751 hw_loss 0.776288 lr 0.00034172 rank 6
2023-02-11 02:26:30,392 DEBUG TRAIN Batch 1/200 loss 80.864655 loss_att 161.698547 loss_ctc 71.412674 loss_rnnt 61.059475 hw_loss 0.918499 lr 0.00034168 rank 2
2023-02-11 02:26:30,394 DEBUG TRAIN Batch 1/200 loss 126.255783 loss_att 227.175247 loss_ctc 135.145248 loss_rnnt 101.527817 hw_loss 0.629775 lr 0.00034156 rank 7
2023-02-11 02:26:30,394 DEBUG TRAIN Batch 1/200 loss 77.686394 loss_att 157.238007 loss_ctc 76.421249 loss_rnnt 59.186886 hw_loss 0.517102 lr 0.00034136 rank 3
2023-02-11 02:26:30,397 DEBUG TRAIN Batch 1/200 loss 75.353844 loss_att 169.530579 loss_ctc 71.144379 loss_rnnt 54.846321 hw_loss 0.418767 lr 0.00034084 rank 4
2023-02-11 02:26:30,398 DEBUG TRAIN Batch 1/200 loss 71.397240 loss_att 148.947540 loss_ctc 66.781128 loss_rnnt 53.779266 hw_loss 0.510637 lr 0.00034176 rank 5
2023-02-11 02:26:30,399 DEBUG TRAIN Batch 1/200 loss 64.516907 loss_att 156.989410 loss_ctc 62.440361 loss_rnnt 45.258297 hw_loss 0.195183 lr 0.00034300 rank 1
2023-02-11 02:27:48,682 DEBUG TRAIN Batch 1/300 loss 86.490601 loss_att 188.876694 loss_ctc 94.618973 loss_rnnt 62.425739 hw_loss 0.469474 lr 0.00034556 rank 7
2023-02-11 02:27:48,687 DEBUG TRAIN Batch 1/300 loss 88.859146 loss_att 180.390167 loss_ctc 97.712837 loss_rnnt 66.532738 hw_loss 0.532445 lr 0.00034536 rank 3
2023-02-11 02:27:48,689 DEBUG TRAIN Batch 1/300 loss 88.111992 loss_att 181.272781 loss_ctc 88.170555 loss_rnnt 66.784248 hw_loss 0.503959 lr 0.00034576 rank 5
2023-02-11 02:27:48,689 DEBUG TRAIN Batch 1/300 loss 98.964622 loss_att 195.945435 loss_ctc 94.467415 loss_rnnt 77.140762 hw_loss 0.567624 lr 0.00034700 rank 1
2023-02-11 02:27:48,690 DEBUG TRAIN Batch 1/300 loss 111.288841 loss_att 226.765366 loss_ctc 117.587708 loss_rnnt 85.040421 hw_loss 0.433736 lr 0.00034572 rank 6
2023-02-11 02:27:48,695 DEBUG TRAIN Batch 1/300 loss 94.647110 loss_att 185.431595 loss_ctc 101.154106 loss_rnnt 72.479706 hw_loss 0.589294 lr 0.00034568 rank 2
2023-02-11 02:27:48,695 DEBUG TRAIN Batch 1/300 loss 75.719978 loss_att 156.245346 loss_ctc 78.840256 loss_rnnt 54.906639 hw_loss 0.804793 lr 0.00034584 rank 0
2023-02-11 02:27:48,743 DEBUG TRAIN Batch 1/300 loss 120.562309 loss_att 221.086182 loss_ctc 128.435410 loss_rnnt 96.565025 hw_loss 0.533018 lr 0.00034484 rank 4
2023-02-11 02:29:05,910 DEBUG TRAIN Batch 1/400 loss 88.112328 loss_att 184.302780 loss_ctc 82.837555 loss_rnnt 65.192513 hw_loss 0.822190 lr 0.00034936 rank 3
2023-02-11 02:29:05,912 DEBUG TRAIN Batch 1/400 loss 64.922668 loss_att 149.862747 loss_ctc 66.422028 loss_rnnt 47.185135 hw_loss 0.103051 lr 0.00034956 rank 7
2023-02-11 02:29:05,914 DEBUG TRAIN Batch 1/400 loss 74.322311 loss_att 163.696838 loss_ctc 73.292946 loss_rnnt 52.885765 hw_loss 0.693542 lr 0.00034984 rank 0
2023-02-11 02:29:05,918 DEBUG TRAIN Batch 1/400 loss 78.062386 loss_att 163.900452 loss_ctc 77.130676 loss_rnnt 57.692085 hw_loss 0.623796 lr 0.00035100 rank 1
2023-02-11 02:29:05,920 DEBUG TRAIN Batch 1/400 loss 75.757248 loss_att 138.263000 loss_ctc 80.113617 loss_rnnt 57.918076 hw_loss 0.891970 lr 0.00034972 rank 6
2023-02-11 02:29:05,921 DEBUG TRAIN Batch 1/400 loss 87.307938 loss_att 165.959320 loss_ctc 95.357475 loss_rnnt 67.565903 hw_loss 0.550965 lr 0.00034884 rank 4
2023-02-11 02:29:05,921 DEBUG TRAIN Batch 1/400 loss 61.744350 loss_att 138.326965 loss_ctc 60.770103 loss_rnnt 43.598370 hw_loss 0.554879 lr 0.00034976 rank 5
2023-02-11 02:29:05,924 DEBUG TRAIN Batch 1/400 loss 90.237587 loss_att 184.378357 loss_ctc 88.311111 loss_rnnt 69.706863 hw_loss 0.367393 lr 0.00034968 rank 2
2023-02-11 02:30:20,852 DEBUG TRAIN Batch 1/500 loss 70.953888 loss_att 150.691605 loss_ctc 67.217422 loss_rnnt 52.287659 hw_loss 0.603165 lr 0.00035336 rank 3
2023-02-11 02:30:20,853 DEBUG TRAIN Batch 1/500 loss 105.230148 loss_att 178.863113 loss_ctc 105.877571 loss_rnnt 85.250786 hw_loss 0.968709 lr 0.00035356 rank 7
2023-02-11 02:30:20,857 DEBUG TRAIN Batch 1/500 loss 61.640160 loss_att 133.996780 loss_ctc 66.595993 loss_rnnt 44.201374 hw_loss 0.432503 lr 0.00035384 rank 0
2023-02-11 02:30:20,860 DEBUG TRAIN Batch 1/500 loss 64.420761 loss_att 133.156738 loss_ctc 68.105446 loss_rnnt 47.741035 hw_loss 0.457732 lr 0.00035284 rank 4
2023-02-11 02:30:20,862 DEBUG TRAIN Batch 1/500 loss 76.556145 loss_att 150.608994 loss_ctc 84.389977 loss_rnnt 58.918812 hw_loss 0.334171 lr 0.00035372 rank 6
2023-02-11 02:30:20,863 DEBUG TRAIN Batch 1/500 loss 61.617222 loss_att 132.756958 loss_ctc 65.543488 loss_rnnt 44.369377 hw_loss 0.468075 lr 0.00035376 rank 5
2023-02-11 02:30:20,864 DEBUG TRAIN Batch 1/500 loss 81.063499 loss_att 169.042511 loss_ctc 80.225746 loss_rnnt 59.466969 hw_loss 0.771080 lr 0.00035368 rank 2
2023-02-11 02:30:20,868 DEBUG TRAIN Batch 1/500 loss 72.233101 loss_att 153.764404 loss_ctc 74.422173 loss_rnnt 51.420303 hw_loss 0.790250 lr 0.00035500 rank 1
2023-02-11 02:31:37,505 DEBUG TRAIN Batch 1/600 loss 47.810955 loss_att 67.409256 loss_ctc 51.083225 loss_rnnt 38.424534 hw_loss 0.943211 lr 0.00035784 rank 0
2023-02-11 02:31:37,507 DEBUG TRAIN Batch 1/600 loss 70.147354 loss_att 122.408920 loss_ctc 72.973442 loss_rnnt 55.911175 hw_loss 0.638822 lr 0.00035756 rank 7
2023-02-11 02:31:37,507 DEBUG TRAIN Batch 1/600 loss 85.533783 loss_att 189.312286 loss_ctc 88.717346 loss_rnnt 62.956005 hw_loss 0.262051 lr 0.00035772 rank 6
2023-02-11 02:31:37,510 DEBUG TRAIN Batch 1/600 loss 67.260788 loss_att 127.602890 loss_ctc 71.661736 loss_rnnt 50.138577 hw_loss 0.837563 lr 0.00035900 rank 1
2023-02-11 02:31:37,511 DEBUG TRAIN Batch 1/600 loss 50.631363 loss_att 80.003967 loss_ctc 55.174885 loss_rnnt 42.403564 hw_loss 0.327652 lr 0.00035736 rank 3
2023-02-11 02:31:37,512 DEBUG TRAIN Batch 1/600 loss 47.648758 loss_att 88.324852 loss_ctc 45.368065 loss_rnnt 35.980450 hw_loss 0.719472 lr 0.00035684 rank 4
2023-02-11 02:31:37,512 DEBUG TRAIN Batch 1/600 loss 68.097122 loss_att 102.042282 loss_ctc 73.267929 loss_rnnt 57.176220 hw_loss 0.645454 lr 0.00035776 rank 5
2023-02-11 02:31:37,515 DEBUG TRAIN Batch 1/600 loss 69.362930 loss_att 104.412415 loss_ctc 72.434387 loss_rnnt 57.942951 hw_loss 0.750103 lr 0.00035768 rank 2
2023-02-11 02:32:56,916 DEBUG TRAIN Batch 1/700 loss 93.478622 loss_att 199.331085 loss_ctc 85.238892 loss_rnnt 69.814499 hw_loss 0.673548 lr 0.00036156 rank 7
2023-02-11 02:32:56,918 DEBUG TRAIN Batch 1/700 loss 86.277382 loss_att 167.505768 loss_ctc 84.851921 loss_rnnt 69.679413 hw_loss 0.101690 lr 0.00036136 rank 3
2023-02-11 02:32:56,920 DEBUG TRAIN Batch 1/700 loss 76.890167 loss_att 176.236481 loss_ctc 75.533569 loss_rnnt 56.754009 hw_loss 0.083959 lr 0.00036184 rank 0
2023-02-11 02:32:56,922 DEBUG TRAIN Batch 1/700 loss 82.002853 loss_att 186.749542 loss_ctc 76.356216 loss_rnnt 56.950195 hw_loss 0.910537 lr 0.00036172 rank 6
2023-02-11 02:32:56,926 DEBUG TRAIN Batch 1/700 loss 91.589912 loss_att 200.541779 loss_ctc 97.976944 loss_rnnt 66.836029 hw_loss 0.395983 lr 0.00036176 rank 5
2023-02-11 02:32:56,927 DEBUG TRAIN Batch 1/700 loss 118.966843 loss_att 210.465622 loss_ctc 134.190842 loss_rnnt 95.776299 hw_loss 0.536423 lr 0.00036084 rank 4
2023-02-11 02:32:56,930 DEBUG TRAIN Batch 1/700 loss 100.813545 loss_att 203.235718 loss_ctc 107.377441 loss_rnnt 75.764946 hw_loss 0.691684 lr 0.00036168 rank 2
2023-02-11 02:32:56,936 DEBUG TRAIN Batch 1/700 loss 118.616379 loss_att 195.898880 loss_ctc 121.253265 loss_rnnt 100.635704 hw_loss 0.407360 lr 0.00036300 rank 1
2023-02-11 02:34:12,713 DEBUG TRAIN Batch 1/800 loss 67.186340 loss_att 170.721359 loss_ctc 67.871979 loss_rnnt 42.728374 hw_loss 0.686165 lr 0.00036536 rank 3
2023-02-11 02:34:12,717 DEBUG TRAIN Batch 1/800 loss 107.579041 loss_att 195.366669 loss_ctc 112.491318 loss_rnnt 86.489639 hw_loss 0.539420 lr 0.00036568 rank 2
2023-02-11 02:34:12,717 DEBUG TRAIN Batch 1/800 loss 89.376694 loss_att 178.619812 loss_ctc 101.189743 loss_rnnt 63.593029 hw_loss 1.192493 lr 0.00036576 rank 5
2023-02-11 02:34:12,717 DEBUG TRAIN Batch 1/800 loss 110.566963 loss_att 208.595428 loss_ctc 117.277924 loss_rnnt 87.912384 hw_loss 0.403893 lr 0.00036584 rank 0
2023-02-11 02:34:12,719 DEBUG TRAIN Batch 1/800 loss 102.131149 loss_att 191.050217 loss_ctc 108.174530 loss_rnnt 82.471741 hw_loss 0.200591 lr 0.00036700 rank 1
2023-02-11 02:34:12,721 DEBUG TRAIN Batch 1/800 loss 76.296776 loss_att 170.701050 loss_ctc 79.453445 loss_rnnt 55.318996 hw_loss 0.314257 lr 0.00036556 rank 7
2023-02-11 02:34:12,722 DEBUG TRAIN Batch 1/800 loss 91.405991 loss_att 182.381042 loss_ctc 93.412094 loss_rnnt 71.811165 hw_loss 0.212313 lr 0.00036572 rank 6
2023-02-11 02:34:12,773 DEBUG TRAIN Batch 1/800 loss 77.186653 loss_att 159.404968 loss_ctc 81.746506 loss_rnnt 56.971321 hw_loss 0.593191 lr 0.00036484 rank 4
2023-02-11 02:35:29,455 DEBUG TRAIN Batch 1/900 loss 103.797974 loss_att 192.784576 loss_ctc 120.951424 loss_rnnt 82.520164 hw_loss 0.223756 lr 0.00036972 rank 6
2023-02-11 02:35:29,457 DEBUG TRAIN Batch 1/900 loss 87.071579 loss_att 176.311890 loss_ctc 96.215805 loss_rnnt 64.178108 hw_loss 0.717408 lr 0.00036984 rank 0
2023-02-11 02:35:29,459 DEBUG TRAIN Batch 1/900 loss 70.491562 loss_att 155.545929 loss_ctc 73.170654 loss_rnnt 49.134552 hw_loss 0.747924 lr 0.00036936 rank 3
2023-02-11 02:35:29,459 DEBUG TRAIN Batch 1/900 loss 68.926849 loss_att 142.953949 loss_ctc 75.276802 loss_rnnt 50.981548 hw_loss 0.429980 lr 0.00037100 rank 1
2023-02-11 02:35:29,460 DEBUG TRAIN Batch 1/900 loss 69.053650 loss_att 132.480011 loss_ctc 69.829704 loss_rnnt 54.139870 hw_loss 0.398443 lr 0.00036956 rank 7
2023-02-11 02:35:29,462 DEBUG TRAIN Batch 1/900 loss 104.100044 loss_att 198.417389 loss_ctc 103.559387 loss_rnnt 80.418976 hw_loss 0.916814 lr 0.00036976 rank 5
2023-02-11 02:35:29,463 DEBUG TRAIN Batch 1/900 loss 85.282303 loss_att 165.711548 loss_ctc 94.918213 loss_rnnt 66.759712 hw_loss 0.215991 lr 0.00036968 rank 2
2023-02-11 02:35:29,466 DEBUG TRAIN Batch 1/900 loss 62.437138 loss_att 127.633392 loss_ctc 67.106186 loss_rnnt 45.382835 hw_loss 0.636096 lr 0.00036884 rank 4
2023-02-11 02:36:46,901 DEBUG TRAIN Batch 1/1000 loss 84.207230 loss_att 157.954956 loss_ctc 85.214478 loss_rnnt 66.864983 hw_loss 0.460951 lr 0.00037336 rank 3
2023-02-11 02:36:46,903 DEBUG TRAIN Batch 1/1000 loss 72.250061 loss_att 158.197891 loss_ctc 79.274300 loss_rnnt 50.620117 hw_loss 0.656965 lr 0.00037384 rank 0
2023-02-11 02:36:46,905 DEBUG TRAIN Batch 1/1000 loss 59.214760 loss_att 128.509567 loss_ctc 62.147678 loss_rnnt 41.584503 hw_loss 0.633795 lr 0.00037356 rank 7
2023-02-11 02:36:46,906 DEBUG TRAIN Batch 1/1000 loss 103.309158 loss_att 171.965576 loss_ctc 117.385254 loss_rnnt 84.724648 hw_loss 0.558077 lr 0.00037368 rank 2
2023-02-11 02:36:46,906 DEBUG TRAIN Batch 1/1000 loss 88.025703 loss_att 197.312286 loss_ctc 101.593788 loss_rnnt 62.339600 hw_loss 0.378695 lr 0.00037376 rank 5
2023-02-11 02:36:46,915 DEBUG TRAIN Batch 1/1000 loss 86.573166 loss_att 183.062714 loss_ctc 90.020470 loss_rnnt 63.301208 hw_loss 0.658951 lr 0.00037500 rank 1
2023-02-11 02:36:46,937 DEBUG TRAIN Batch 1/1000 loss 89.896111 loss_att 183.003479 loss_ctc 95.146225 loss_rnnt 65.656845 hw_loss 0.922083 lr 0.00037372 rank 6
2023-02-11 02:36:46,946 DEBUG TRAIN Batch 1/1000 loss 63.621216 loss_att 142.608368 loss_ctc 60.435448 loss_rnnt 45.202080 hw_loss 0.571215 lr 0.00037284 rank 4
2023-02-11 02:38:04,418 DEBUG TRAIN Batch 1/1100 loss 85.570763 loss_att 151.386734 loss_ctc 93.620537 loss_rnnt 68.411491 hw_loss 0.548021 lr 0.00037900 rank 1
2023-02-11 02:38:04,419 DEBUG TRAIN Batch 1/1100 loss 73.484016 loss_att 129.667664 loss_ctc 81.585129 loss_rnnt 56.564911 hw_loss 0.862916 lr 0.00037736 rank 3
2023-02-11 02:38:04,419 DEBUG TRAIN Batch 1/1100 loss 83.972519 loss_att 151.391724 loss_ctc 89.938835 loss_rnnt 64.011185 hw_loss 1.065372 lr 0.00037756 rank 7
2023-02-11 02:38:04,420 DEBUG TRAIN Batch 1/1100 loss 69.030006 loss_att 146.823700 loss_ctc 69.991287 loss_rnnt 49.328392 hw_loss 0.752756 lr 0.00037784 rank 0
2023-02-11 02:38:04,421 DEBUG TRAIN Batch 1/1100 loss 93.511795 loss_att 156.567596 loss_ctc 98.624695 loss_rnnt 76.450485 hw_loss 0.706581 lr 0.00037772 rank 6
2023-02-11 02:38:04,423 DEBUG TRAIN Batch 1/1100 loss 73.853775 loss_att 124.936615 loss_ctc 76.251289 loss_rnnt 58.651772 hw_loss 0.874830 lr 0.00037768 rank 2
2023-02-11 02:38:04,426 DEBUG TRAIN Batch 1/1100 loss 91.348969 loss_att 183.064423 loss_ctc 94.728134 loss_rnnt 70.960197 hw_loss 0.299085 lr 0.00037776 rank 5
2023-02-11 02:38:04,427 DEBUG TRAIN Batch 1/1100 loss 73.368668 loss_att 139.543839 loss_ctc 77.983444 loss_rnnt 56.625008 hw_loss 0.542497 lr 0.00037684 rank 4
2023-02-11 02:39:19,671 DEBUG TRAIN Batch 1/1200 loss 70.275490 loss_att 125.123276 loss_ctc 79.990372 loss_rnnt 54.742035 hw_loss 0.612858 lr 0.00038136 rank 3
2023-02-11 02:39:19,671 DEBUG TRAIN Batch 1/1200 loss 67.099663 loss_att 109.216797 loss_ctc 74.105324 loss_rnnt 52.841946 hw_loss 0.918787 lr 0.00038156 rank 7
2023-02-11 02:39:19,671 DEBUG TRAIN Batch 1/1200 loss 47.170708 loss_att 83.526512 loss_ctc 48.057293 loss_rnnt 37.212421 hw_loss 0.481671 lr 0.00038184 rank 0
2023-02-11 02:39:19,673 DEBUG TRAIN Batch 1/1200 loss 38.754177 loss_att 57.818329 loss_ctc 41.408878 loss_rnnt 30.511580 hw_loss 0.764213 lr 0.00038172 rank 6
2023-02-11 02:39:19,676 DEBUG TRAIN Batch 1/1200 loss 32.088249 loss_att 42.787609 loss_ctc 32.264145 loss_rnnt 23.996494 hw_loss 1.111581 lr 0.00038168 rank 2
2023-02-11 02:39:19,676 DEBUG TRAIN Batch 1/1200 loss 76.253120 loss_att 145.720856 loss_ctc 84.735283 loss_rnnt 57.323486 hw_loss 0.732211 lr 0.00038176 rank 5
2023-02-11 02:39:19,677 DEBUG TRAIN Batch 1/1200 loss 85.175980 loss_att 155.254578 loss_ctc 95.727798 loss_rnnt 67.280693 hw_loss 0.463623 lr 0.00038300 rank 1
2023-02-11 02:39:19,730 DEBUG TRAIN Batch 1/1200 loss 60.234798 loss_att 106.107605 loss_ctc 68.854332 loss_rnnt 47.879814 hw_loss 0.380841 lr 0.00038084 rank 4
2023-02-11 02:40:35,948 DEBUG TRAIN Batch 1/1300 loss 31.270435 loss_att 33.903530 loss_ctc 29.415251 loss_rnnt 22.177368 hw_loss 1.652589 lr 0.00038556 rank 7
2023-02-11 02:40:35,951 DEBUG TRAIN Batch 1/1300 loss 61.792461 loss_att 95.262077 loss_ctc 68.033745 loss_rnnt 49.828484 hw_loss 0.832103 lr 0.00038700 rank 1
2023-02-11 02:40:35,954 DEBUG TRAIN Batch 1/1300 loss 96.997818 loss_att 187.578857 loss_ctc 102.856216 loss_rnnt 75.296715 hw_loss 0.525708 lr 0.00038584 rank 0
2023-02-11 02:40:35,955 DEBUG TRAIN Batch 1/1300 loss 35.363018 loss_att 47.760849 loss_ctc 32.786911 loss_rnnt 27.382467 hw_loss 1.095838 lr 0.00038576 rank 5
2023-02-11 02:40:35,955 DEBUG TRAIN Batch 1/1300 loss 100.356873 loss_att 197.195374 loss_ctc 122.769363 loss_rnnt 76.500854 hw_loss 0.281246 lr 0.00038484 rank 4
2023-02-11 02:40:35,957 DEBUG TRAIN Batch 1/1300 loss 107.666748 loss_att 218.403687 loss_ctc 111.182816 loss_rnnt 80.471130 hw_loss 0.858643 lr 0.00038536 rank 3
2023-02-11 02:40:35,961 DEBUG TRAIN Batch 1/1300 loss 68.242111 loss_att 158.930420 loss_ctc 75.045158 loss_rnnt 46.482651 hw_loss 0.509010 lr 0.00038568 rank 2
2023-02-11 02:40:35,998 DEBUG TRAIN Batch 1/1300 loss 99.946655 loss_att 189.312363 loss_ctc 106.236420 loss_rnnt 78.355186 hw_loss 0.539942 lr 0.00038572 rank 6
2023-02-11 02:41:54,553 DEBUG TRAIN Batch 1/1400 loss 97.945686 loss_att 198.999634 loss_ctc 102.614029 loss_rnnt 75.186615 hw_loss 0.361093 lr 0.00038984 rank 0
2023-02-11 02:41:54,554 DEBUG TRAIN Batch 1/1400 loss 69.791763 loss_att 150.542038 loss_ctc 72.533234 loss_rnnt 51.911968 hw_loss 0.255791 lr 0.00038956 rank 7
2023-02-11 02:41:54,555 DEBUG TRAIN Batch 1/1400 loss 51.585609 loss_att 109.268661 loss_ctc 53.438263 loss_rnnt 35.792343 hw_loss 0.751807 lr 0.00038936 rank 3
2023-02-11 02:41:54,555 DEBUG TRAIN Batch 1/1400 loss 100.057762 loss_att 184.473297 loss_ctc 102.886810 loss_rnnt 79.427444 hw_loss 0.631875 lr 0.00038884 rank 4
2023-02-11 02:41:54,557 DEBUG TRAIN Batch 1/1400 loss 75.109604 loss_att 166.302841 loss_ctc 68.973053 loss_rnnt 56.195141 hw_loss 0.280128 lr 0.00038976 rank 5
2023-02-11 02:41:54,557 DEBUG TRAIN Batch 1/1400 loss 83.613487 loss_att 171.342224 loss_ctc 92.396576 loss_rnnt 60.775200 hw_loss 0.772774 lr 0.00038972 rank 6
2023-02-11 02:41:54,563 DEBUG TRAIN Batch 1/1400 loss 58.594856 loss_att 136.239548 loss_ctc 55.996624 loss_rnnt 39.200912 hw_loss 0.789644 lr 0.00038968 rank 2
2023-02-11 02:41:54,564 DEBUG TRAIN Batch 1/1400 loss 72.269020 loss_att 149.501740 loss_ctc 79.831360 loss_rnnt 52.830170 hw_loss 0.559500 lr 0.00039100 rank 1
2023-02-11 02:43:10,285 DEBUG TRAIN Batch 1/1500 loss 82.108856 loss_att 141.272736 loss_ctc 91.013901 loss_rnnt 67.978271 hw_loss 0.208214 lr 0.00039500 rank 1
2023-02-11 02:43:10,285 DEBUG TRAIN Batch 1/1500 loss 80.869797 loss_att 161.535995 loss_ctc 85.872681 loss_rnnt 61.299061 hw_loss 0.519459 lr 0.00039368 rank 2
2023-02-11 02:43:10,285 DEBUG TRAIN Batch 1/1500 loss 71.979988 loss_att 142.948761 loss_ctc 77.360481 loss_rnnt 53.507721 hw_loss 0.667707 lr 0.00039336 rank 3
2023-02-11 02:43:10,285 DEBUG TRAIN Batch 1/1500 loss 78.058357 loss_att 171.301758 loss_ctc 86.884827 loss_rnnt 55.047729 hw_loss 0.597203 lr 0.00039384 rank 0
2023-02-11 02:43:10,286 DEBUG TRAIN Batch 1/1500 loss 76.924850 loss_att 151.059326 loss_ctc 88.275322 loss_rnnt 57.218819 hw_loss 0.631075 lr 0.00039356 rank 7
2023-02-11 02:43:10,286 DEBUG TRAIN Batch 1/1500 loss 116.976181 loss_att 197.649719 loss_ctc 141.261780 loss_rnnt 95.095016 hw_loss 0.470322 lr 0.00039376 rank 5
2023-02-11 02:43:10,288 DEBUG TRAIN Batch 1/1500 loss 76.465576 loss_att 160.721207 loss_ctc 77.967705 loss_rnnt 56.921207 hw_loss 0.467429 lr 0.00039372 rank 6
2023-02-11 02:43:10,289 DEBUG TRAIN Batch 1/1500 loss 74.805450 loss_att 168.469574 loss_ctc 75.312332 loss_rnnt 52.017090 hw_loss 0.747740 lr 0.00039284 rank 4
2023-02-11 02:44:26,895 DEBUG TRAIN Batch 1/1600 loss 108.298912 loss_att 196.480438 loss_ctc 117.851334 loss_rnnt 84.853874 hw_loss 0.850327 lr 0.00039768 rank 2
2023-02-11 02:44:26,896 DEBUG TRAIN Batch 1/1600 loss 83.059319 loss_att 163.643219 loss_ctc 87.695183 loss_rnnt 63.045593 hw_loss 0.614781 lr 0.00039756 rank 7
2023-02-11 02:44:26,902 DEBUG TRAIN Batch 1/1600 loss 80.726494 loss_att 152.476517 loss_ctc 94.588989 loss_rnnt 61.787163 hw_loss 0.513937 lr 0.00039736 rank 3
2023-02-11 02:44:26,902 DEBUG TRAIN Batch 1/1600 loss 83.960373 loss_att 163.166519 loss_ctc 91.201271 loss_rnnt 64.129089 hw_loss 0.567112 lr 0.00039784 rank 0
2023-02-11 02:44:26,902 DEBUG TRAIN Batch 1/1600 loss 102.447800 loss_att 174.735764 loss_ctc 116.162430 loss_rnnt 84.091476 hw_loss 0.388145 lr 0.00039684 rank 4
2023-02-11 02:44:26,904 DEBUG TRAIN Batch 1/1600 loss 68.158958 loss_att 150.180267 loss_ctc 74.517807 loss_rnnt 48.238609 hw_loss 0.500296 lr 0.00039772 rank 6
2023-02-11 02:44:26,907 DEBUG TRAIN Batch 1/1600 loss 58.751770 loss_att 130.910339 loss_ctc 58.699623 loss_rnnt 41.571365 hw_loss 0.516684 lr 0.00039776 rank 5
2023-02-11 02:44:26,944 DEBUG TRAIN Batch 1/1600 loss 61.277046 loss_att 141.783508 loss_ctc 61.071068 loss_rnnt 41.518082 hw_loss 0.690964 lr 0.00039900 rank 1
2023-02-11 02:45:43,718 DEBUG TRAIN Batch 1/1700 loss 98.893173 loss_att 196.028168 loss_ctc 105.448410 loss_rnnt 77.296829 hw_loss 0.242871 lr 0.00040136 rank 3
2023-02-11 02:45:43,719 DEBUG TRAIN Batch 1/1700 loss 66.406624 loss_att 135.408752 loss_ctc 69.647667 loss_rnnt 47.092232 hw_loss 0.952841 lr 0.00040184 rank 0
2023-02-11 02:45:43,719 DEBUG TRAIN Batch 1/1700 loss 67.254929 loss_att 118.150696 loss_ctc 70.683495 loss_rnnt 52.606194 hw_loss 0.752332 lr 0.00040172 rank 6
2023-02-11 02:45:43,724 DEBUG TRAIN Batch 1/1700 loss 97.672882 loss_att 153.418793 loss_ctc 110.198685 loss_rnnt 79.781662 hw_loss 0.950988 lr 0.00040300 rank 1
2023-02-11 02:45:43,724 DEBUG TRAIN Batch 1/1700 loss 46.132362 loss_att 107.282379 loss_ctc 45.909771 loss_rnnt 29.816418 hw_loss 0.771678 lr 0.00040168 rank 2
2023-02-11 02:45:43,726 DEBUG TRAIN Batch 1/1700 loss 64.230667 loss_att 119.800072 loss_ctc 65.773033 loss_rnnt 49.435356 hw_loss 0.651708 lr 0.00040176 rank 5
2023-02-11 02:45:43,730 DEBUG TRAIN Batch 1/1700 loss 75.505928 loss_att 128.743958 loss_ctc 89.795738 loss_rnnt 61.210503 hw_loss 0.326721 lr 0.00040156 rank 7
2023-02-11 02:45:43,772 DEBUG TRAIN Batch 1/1700 loss 97.529823 loss_att 164.551819 loss_ctc 113.599213 loss_rnnt 80.360596 hw_loss 0.304171 lr 0.00040084 rank 4
2023-02-11 02:47:03,000 DEBUG TRAIN Batch 1/1800 loss 41.631393 loss_att 58.250587 loss_ctc 43.280693 loss_rnnt 33.383728 hw_loss 0.881984 lr 0.00040568 rank 2
2023-02-11 02:47:03,001 DEBUG TRAIN Batch 1/1800 loss 68.654137 loss_att 115.935593 loss_ctc 76.654160 loss_rnnt 55.885715 hw_loss 0.421023 lr 0.00040536 rank 3
2023-02-11 02:47:03,002 DEBUG TRAIN Batch 1/1800 loss 52.120983 loss_att 93.961395 loss_ctc 58.322403 loss_rnnt 40.508221 hw_loss 0.453341 lr 0.00040584 rank 0
2023-02-11 02:47:03,005 DEBUG TRAIN Batch 1/1800 loss 70.708832 loss_att 124.009125 loss_ctc 82.927521 loss_rnnt 55.648003 hw_loss 0.519677 lr 0.00040556 rank 7
2023-02-11 02:47:03,005 DEBUG TRAIN Batch 1/1800 loss 61.083435 loss_att 104.123260 loss_ctc 67.232803 loss_rnnt 48.077755 hw_loss 0.670838 lr 0.00040484 rank 4
2023-02-11 02:47:03,010 DEBUG TRAIN Batch 1/1800 loss 52.424904 loss_att 81.327553 loss_ctc 52.027813 loss_rnnt 38.374512 hw_loss 1.560525 lr 0.00040572 rank 6
2023-02-11 02:47:03,009 DEBUG TRAIN Batch 1/1800 loss 47.422722 loss_att 99.114090 loss_ctc 49.968269 loss_rnnt 33.378708 hw_loss 0.631187 lr 0.00040700 rank 1
2023-02-11 02:47:03,012 DEBUG TRAIN Batch 1/1800 loss 87.287079 loss_att 153.309418 loss_ctc 99.921402 loss_rnnt 67.501999 hw_loss 0.918007 lr 0.00040576 rank 5
2023-02-11 02:48:18,050 DEBUG TRAIN Batch 1/1900 loss 59.447136 loss_att 78.680672 loss_ctc 62.736530 loss_rnnt 51.405178 hw_loss 0.704374 lr 0.00040936 rank 3
2023-02-11 02:48:18,057 DEBUG TRAIN Batch 1/1900 loss 80.083481 loss_att 157.816254 loss_ctc 92.419914 loss_rnnt 59.719414 hw_loss 0.594872 lr 0.00040984 rank 0
2023-02-11 02:48:18,058 DEBUG TRAIN Batch 1/1900 loss 45.420410 loss_att 76.967987 loss_ctc 47.150677 loss_rnnt 33.988487 hw_loss 0.917194 lr 0.00040956 rank 7
2023-02-11 02:48:18,062 DEBUG TRAIN Batch 1/1900 loss 54.763050 loss_att 77.060745 loss_ctc 61.235081 loss_rnnt 44.455185 hw_loss 0.934760 lr 0.00040976 rank 5
2023-02-11 02:48:18,062 DEBUG TRAIN Batch 1/1900 loss 53.101192 loss_att 118.052704 loss_ctc 54.504223 loss_rnnt 37.522694 hw_loss 0.450210 lr 0.00040972 rank 6
2023-02-11 02:48:18,062 DEBUG TRAIN Batch 1/1900 loss 82.752205 loss_att 176.720688 loss_ctc 100.925354 loss_rnnt 59.506798 hw_loss 0.380368 lr 0.00040968 rank 2
2023-02-11 02:48:18,063 DEBUG TRAIN Batch 1/1900 loss 49.163319 loss_att 88.890366 loss_ctc 56.945995 loss_rnnt 37.992760 hw_loss 0.410147 lr 0.00041100 rank 1
2023-02-11 02:48:18,063 DEBUG TRAIN Batch 1/1900 loss 59.662827 loss_att 107.855103 loss_ctc 73.428406 loss_rnnt 44.940060 hw_loss 0.609169 lr 0.00040884 rank 4
2023-02-11 02:49:34,617 DEBUG TRAIN Batch 1/2000 loss 83.594505 loss_att 185.179504 loss_ctc 97.114990 loss_rnnt 58.725876 hw_loss 0.515419 lr 0.00041336 rank 3
2023-02-11 02:49:34,620 DEBUG TRAIN Batch 1/2000 loss 64.334518 loss_att 129.619522 loss_ctc 70.308937 loss_rnnt 45.335831 hw_loss 0.964706 lr 0.00041384 rank 0
2023-02-11 02:49:34,620 DEBUG TRAIN Batch 1/2000 loss 57.626022 loss_att 132.112366 loss_ctc 62.609764 loss_rnnt 39.252346 hw_loss 0.527234 lr 0.00041376 rank 5
2023-02-11 02:49:34,622 DEBUG TRAIN Batch 1/2000 loss 78.032028 loss_att 174.977097 loss_ctc 92.862846 loss_rnnt 52.546902 hw_loss 0.772252 lr 0.00041356 rank 7
2023-02-11 02:49:34,625 DEBUG TRAIN Batch 1/2000 loss 112.414742 loss_att 194.814209 loss_ctc 128.055313 loss_rnnt 90.856400 hw_loss 0.561193 lr 0.00041500 rank 1
2023-02-11 02:49:34,629 DEBUG TRAIN Batch 1/2000 loss 72.983482 loss_att 150.734192 loss_ctc 87.108597 loss_rnnt 53.043785 hw_loss 0.469913 lr 0.00041284 rank 4
2023-02-11 02:49:34,631 DEBUG TRAIN Batch 1/2000 loss 78.145271 loss_att 154.091736 loss_ctc 87.452782 loss_rnnt 58.830627 hw_loss 0.540815 lr 0.00041368 rank 2
2023-02-11 02:49:34,670 DEBUG TRAIN Batch 1/2000 loss 76.552101 loss_att 171.140656 loss_ctc 97.497925 loss_rnnt 53.863842 hw_loss 0.183332 lr 0.00041372 rank 6
2023-02-11 02:50:53,505 DEBUG TRAIN Batch 1/2100 loss 64.645233 loss_att 132.114380 loss_ctc 76.010239 loss_rnnt 47.842621 hw_loss 0.336272 lr 0.00041776 rank 5
2023-02-11 02:50:53,506 DEBUG TRAIN Batch 1/2100 loss 102.307953 loss_att 171.452408 loss_ctc 107.859154 loss_rnnt 84.564392 hw_loss 0.595220 lr 0.00041736 rank 3
2023-02-11 02:50:53,508 DEBUG TRAIN Batch 1/2100 loss 69.085701 loss_att 125.453171 loss_ctc 77.888458 loss_rnnt 52.945366 hw_loss 0.692465 lr 0.00041772 rank 6
2023-02-11 02:50:53,508 DEBUG TRAIN Batch 1/2100 loss 60.213982 loss_att 115.409233 loss_ctc 62.241356 loss_rnnt 46.814983 hw_loss 0.391806 lr 0.00041784 rank 0
2023-02-11 02:50:53,511 DEBUG TRAIN Batch 1/2100 loss 43.960018 loss_att 116.873650 loss_ctc 46.272186 loss_rnnt 26.049229 hw_loss 0.566207 lr 0.00041900 rank 1
2023-02-11 02:50:53,512 DEBUG TRAIN Batch 1/2100 loss 96.465950 loss_att 168.987640 loss_ctc 112.888115 loss_rnnt 75.337906 hw_loss 0.831391 lr 0.00041756 rank 7
2023-02-11 02:50:53,512 DEBUG TRAIN Batch 1/2100 loss 96.283951 loss_att 186.316971 loss_ctc 114.751678 loss_rnnt 74.711487 hw_loss 0.206906 lr 0.00041768 rank 2
2023-02-11 02:50:53,517 DEBUG TRAIN Batch 1/2100 loss 67.371414 loss_att 133.704376 loss_ctc 80.490662 loss_rnnt 49.175987 hw_loss 0.596177 lr 0.00041684 rank 4
2023-02-11 02:52:09,791 DEBUG TRAIN Batch 1/2200 loss 56.781883 loss_att 116.210007 loss_ctc 66.612373 loss_rnnt 41.992516 hw_loss 0.298689 lr 0.00042168 rank 2
2023-02-11 02:52:09,793 DEBUG TRAIN Batch 1/2200 loss 62.096748 loss_att 131.513336 loss_ctc 67.061043 loss_rnnt 44.199333 hw_loss 0.628536 lr 0.00042172 rank 6
2023-02-11 02:52:09,794 DEBUG TRAIN Batch 1/2200 loss 61.980438 loss_att 124.628937 loss_ctc 70.716934 loss_rnnt 47.547039 hw_loss 0.138531 lr 0.00042184 rank 0
2023-02-11 02:52:09,796 DEBUG TRAIN Batch 1/2200 loss 48.594170 loss_att 106.104118 loss_ctc 53.913670 loss_rnnt 33.951778 hw_loss 0.455838 lr 0.00042136 rank 3
2023-02-11 02:52:09,798 DEBUG TRAIN Batch 1/2200 loss 65.701248 loss_att 142.739639 loss_ctc 71.497147 loss_rnnt 46.539024 hw_loss 0.559079 lr 0.00042176 rank 5
2023-02-11 02:52:09,799 DEBUG TRAIN Batch 1/2200 loss 74.362289 loss_att 140.696045 loss_ctc 82.188293 loss_rnnt 56.789440 hw_loss 0.611744 lr 0.00042300 rank 1
2023-02-11 02:52:09,801 DEBUG TRAIN Batch 1/2200 loss 75.272118 loss_att 137.515976 loss_ctc 88.940536 loss_rnnt 59.936016 hw_loss 0.199664 lr 0.00042156 rank 7
2023-02-11 02:52:09,810 DEBUG TRAIN Batch 1/2200 loss 54.639275 loss_att 110.733871 loss_ctc 58.317940 loss_rnnt 40.142403 hw_loss 0.522649 lr 0.00042084 rank 4
2023-02-11 02:53:25,573 DEBUG TRAIN Batch 1/2300 loss 80.814705 loss_att 142.321548 loss_ctc 91.299522 loss_rnnt 64.190903 hw_loss 0.548336 lr 0.00042584 rank 0
2023-02-11 02:53:25,572 DEBUG TRAIN Batch 1/2300 loss 66.269234 loss_att 128.535019 loss_ctc 70.676186 loss_rnnt 49.914471 hw_loss 0.621377 lr 0.00042700 rank 1
2023-02-11 02:53:25,573 DEBUG TRAIN Batch 1/2300 loss 71.943886 loss_att 151.041321 loss_ctc 82.786140 loss_rnnt 51.644760 hw_loss 0.568877 lr 0.00042568 rank 2
2023-02-11 02:53:25,574 DEBUG TRAIN Batch 1/2300 loss 82.307266 loss_att 144.092026 loss_ctc 96.013458 loss_rnnt 63.137772 hw_loss 0.934697 lr 0.00042536 rank 3
2023-02-11 02:53:25,575 DEBUG TRAIN Batch 1/2300 loss 59.672863 loss_att 123.976624 loss_ctc 64.441002 loss_rnnt 43.825829 hw_loss 0.440725 lr 0.00042572 rank 6
2023-02-11 02:53:25,576 DEBUG TRAIN Batch 1/2300 loss 75.787849 loss_att 143.627945 loss_ctc 86.983742 loss_rnnt 58.266907 hw_loss 0.461275 lr 0.00042556 rank 7
2023-02-11 02:53:25,578 DEBUG TRAIN Batch 1/2300 loss 52.798042 loss_att 100.501694 loss_ctc 63.632046 loss_rnnt 38.804760 hw_loss 0.564003 lr 0.00042576 rank 5
2023-02-11 02:53:25,580 DEBUG TRAIN Batch 1/2300 loss 51.046146 loss_att 103.283157 loss_ctc 51.256535 loss_rnnt 35.857239 hw_loss 0.883773 lr 0.00042484 rank 4
2023-02-11 02:54:42,218 DEBUG TRAIN Batch 1/2400 loss 76.898750 loss_att 148.685349 loss_ctc 92.156418 loss_rnnt 57.492798 hw_loss 0.565175 lr 0.00042936 rank 3
2023-02-11 02:54:42,222 DEBUG TRAIN Batch 1/2400 loss 58.615604 loss_att 120.555199 loss_ctc 62.842133 loss_rnnt 42.226204 hw_loss 0.644614 lr 0.00043100 rank 1
2023-02-11 02:54:42,223 DEBUG TRAIN Batch 1/2400 loss 61.314194 loss_att 124.150261 loss_ctc 68.860352 loss_rnnt 43.179966 hw_loss 0.855161 lr 0.00042956 rank 7
2023-02-11 02:54:42,224 DEBUG TRAIN Batch 1/2400 loss 51.509983 loss_att 97.833160 loss_ctc 55.582466 loss_rnnt 38.481628 hw_loss 0.603885 lr 0.00042984 rank 0
2023-02-11 02:54:42,224 DEBUG TRAIN Batch 1/2400 loss 65.749390 loss_att 118.056541 loss_ctc 72.831688 loss_rnnt 50.865170 hw_loss 0.652217 lr 0.00042968 rank 2
2023-02-11 02:54:42,226 DEBUG TRAIN Batch 1/2400 loss 50.503845 loss_att 94.203224 loss_ctc 52.700737 loss_rnnt 36.960129 hw_loss 0.845798 lr 0.00042884 rank 4
2023-02-11 02:54:42,228 DEBUG TRAIN Batch 1/2400 loss 60.855125 loss_att 106.348358 loss_ctc 70.229820 loss_rnnt 47.938557 hw_loss 0.481492 lr 0.00042972 rank 6
2023-02-11 02:54:42,229 DEBUG TRAIN Batch 1/2400 loss 56.601395 loss_att 109.287567 loss_ctc 63.400864 loss_rnnt 41.501083 hw_loss 0.685590 lr 0.00042976 rank 5
2023-02-11 02:56:01,123 DEBUG TRAIN Batch 1/2500 loss 52.002026 loss_att 97.040955 loss_ctc 55.679382 loss_rnnt 35.853218 hw_loss 1.247007 lr 0.00043356 rank 7
2023-02-11 02:56:01,128 DEBUG TRAIN Batch 1/2500 loss 28.437336 loss_att 30.116100 loss_ctc 28.060173 loss_rnnt 20.956999 hw_loss 1.349039 lr 0.00043384 rank 0
2023-02-11 02:56:01,131 DEBUG TRAIN Batch 1/2500 loss 41.180290 loss_att 61.273262 loss_ctc 39.798237 loss_rnnt 33.996410 hw_loss 0.628043 lr 0.00043336 rank 3
2023-02-11 02:56:01,133 DEBUG TRAIN Batch 1/2500 loss 74.166985 loss_att 107.518684 loss_ctc 85.016159 loss_rnnt 61.791992 hw_loss 0.798392 lr 0.00043500 rank 1
2023-02-11 02:56:01,134 DEBUG TRAIN Batch 1/2500 loss 67.552299 loss_att 113.327744 loss_ctc 74.704506 loss_rnnt 52.670849 hw_loss 0.894887 lr 0.00043376 rank 5
2023-02-11 02:56:01,136 DEBUG TRAIN Batch 1/2500 loss 67.874603 loss_att 147.186615 loss_ctc 71.835327 loss_rnnt 50.054138 hw_loss 0.268117 lr 0.00043372 rank 6
2023-02-11 02:56:01,144 DEBUG TRAIN Batch 1/2500 loss 72.662994 loss_att 150.426178 loss_ctc 75.268082 loss_rnnt 56.330574 hw_loss 0.081082 lr 0.00043368 rank 2
2023-02-11 02:56:01,144 DEBUG TRAIN Batch 1/2500 loss 44.786674 loss_att 84.172417 loss_ctc 48.242420 loss_rnnt 32.961632 hw_loss 0.653836 lr 0.00043284 rank 4
2023-02-11 02:57:18,483 DEBUG TRAIN Batch 1/2600 loss 58.250050 loss_att 115.446655 loss_ctc 62.031487 loss_rnnt 45.236717 hw_loss 0.200591 lr 0.00043776 rank 5
2023-02-11 02:57:18,484 DEBUG TRAIN Batch 1/2600 loss 88.637146 loss_att 160.333054 loss_ctc 99.297783 loss_rnnt 72.510956 hw_loss 0.068548 lr 0.00043756 rank 7
2023-02-11 02:57:18,484 DEBUG TRAIN Batch 1/2600 loss 84.788475 loss_att 160.681671 loss_ctc 101.402618 loss_rnnt 65.062973 hw_loss 0.437184 lr 0.00043736 rank 3
2023-02-11 02:57:18,486 DEBUG TRAIN Batch 1/2600 loss 48.179592 loss_att 111.458847 loss_ctc 57.317146 loss_rnnt 32.469955 hw_loss 0.344146 lr 0.00043768 rank 2
2023-02-11 02:57:18,489 DEBUG TRAIN Batch 1/2600 loss 38.513363 loss_att 48.442928 loss_ctc 44.320396 loss_rnnt 31.051414 hw_loss 0.881581 lr 0.00043900 rank 1
2023-02-11 02:57:18,491 DEBUG TRAIN Batch 1/2600 loss 70.513565 loss_att 150.893829 loss_ctc 78.589684 loss_rnnt 50.220917 hw_loss 0.588710 lr 0.00043684 rank 4
2023-02-11 02:57:18,490 DEBUG TRAIN Batch 1/2600 loss 88.632553 loss_att 154.776367 loss_ctc 104.244995 loss_rnnt 70.721466 hw_loss 0.487626 lr 0.00043772 rank 6
2023-02-11 02:57:18,493 DEBUG TRAIN Batch 1/2600 loss 56.761002 loss_att 121.644257 loss_ctc 62.630440 loss_rnnt 40.968700 hw_loss 0.381199 lr 0.00043784 rank 0
2023-02-11 02:58:34,060 DEBUG TRAIN Batch 1/2700 loss 66.644791 loss_att 128.990952 loss_ctc 78.738663 loss_rnnt 50.431519 hw_loss 0.399660 lr 0.00044172 rank 6
2023-02-11 02:58:34,063 DEBUG TRAIN Batch 1/2700 loss 58.339516 loss_att 121.285004 loss_ctc 68.892525 loss_rnnt 42.190441 hw_loss 0.403671 lr 0.00044184 rank 0
2023-02-11 02:58:34,064 DEBUG TRAIN Batch 1/2700 loss 41.662834 loss_att 88.715942 loss_ctc 50.798260 loss_rnnt 27.736221 hw_loss 0.618363 lr 0.00044136 rank 3
2023-02-11 02:58:34,065 DEBUG TRAIN Batch 1/2700 loss 93.973183 loss_att 147.766525 loss_ctc 112.275597 loss_rnnt 77.658920 hw_loss 0.584113 lr 0.00044156 rank 7
2023-02-11 02:58:34,066 DEBUG TRAIN Batch 1/2700 loss 70.027878 loss_att 149.205673 loss_ctc 82.577057 loss_rnnt 50.342438 hw_loss 0.408123 lr 0.00044300 rank 1
2023-02-11 02:58:34,069 DEBUG TRAIN Batch 1/2700 loss 55.703533 loss_att 106.321121 loss_ctc 60.959209 loss_rnnt 41.467796 hw_loss 0.639649 lr 0.00044168 rank 2
2023-02-11 02:58:34,070 DEBUG TRAIN Batch 1/2700 loss 54.575432 loss_att 112.051971 loss_ctc 56.899307 loss_rnnt 40.613354 hw_loss 0.404423 lr 0.00044084 rank 4
2023-02-11 02:58:34,072 DEBUG TRAIN Batch 1/2700 loss 64.135933 loss_att 118.448647 loss_ctc 68.489174 loss_rnnt 49.618603 hw_loss 0.576441 lr 0.00044176 rank 5
2023-02-11 02:59:51,258 DEBUG TRAIN Batch 1/2800 loss 65.526443 loss_att 117.209541 loss_ctc 75.346100 loss_rnnt 49.529152 hw_loss 0.815883 lr 0.00044556 rank 7
2023-02-11 02:59:51,263 DEBUG TRAIN Batch 1/2800 loss 52.122654 loss_att 96.518158 loss_ctc 61.767937 loss_rnnt 36.678337 hw_loss 0.989846 lr 0.00044484 rank 4
2023-02-11 02:59:51,262 DEBUG TRAIN Batch 1/2800 loss 55.892467 loss_att 123.299500 loss_ctc 62.037800 loss_rnnt 37.081306 hw_loss 0.845695 lr 0.00044572 rank 6
2023-02-11 02:59:51,266 DEBUG TRAIN Batch 1/2800 loss 64.040489 loss_att 133.662766 loss_ctc 77.311424 loss_rnnt 45.205837 hw_loss 0.588888 lr 0.00044700 rank 1
2023-02-11 02:59:51,267 DEBUG TRAIN Batch 1/2800 loss 54.638374 loss_att 110.526718 loss_ctc 64.240433 loss_rnnt 40.826935 hw_loss 0.253781 lr 0.00044584 rank 0
2023-02-11 02:59:51,268 DEBUG TRAIN Batch 1/2800 loss 86.838097 loss_att 154.053299 loss_ctc 98.590546 loss_rnnt 69.408264 hw_loss 0.453713 lr 0.00044536 rank 3
2023-02-11 02:59:51,267 DEBUG TRAIN Batch 1/2800 loss 47.992134 loss_att 106.106041 loss_ctc 54.436798 loss_rnnt 34.089127 hw_loss 0.266426 lr 0.00044576 rank 5
2023-02-11 02:59:51,267 DEBUG TRAIN Batch 1/2800 loss 79.038521 loss_att 142.515137 loss_ctc 93.801300 loss_rnnt 60.193588 hw_loss 0.783982 lr 0.00044568 rank 2
2023-02-11 03:01:07,997 DEBUG TRAIN Batch 1/2900 loss 53.805645 loss_att 100.789696 loss_ctc 60.142715 loss_rnnt 38.941013 hw_loss 0.866790 lr 0.00044936 rank 3
2023-02-11 03:01:08,000 DEBUG TRAIN Batch 1/2900 loss 50.037563 loss_att 104.561310 loss_ctc 53.015343 loss_rnnt 34.584930 hw_loss 0.778283 lr 0.00044984 rank 0
2023-02-11 03:01:08,001 DEBUG TRAIN Batch 1/2900 loss 52.562344 loss_att 108.352783 loss_ctc 50.944931 loss_rnnt 36.650661 hw_loss 0.931734 lr 0.00045100 rank 1
2023-02-11 03:01:08,005 DEBUG TRAIN Batch 1/2900 loss 57.309772 loss_att 125.146652 loss_ctc 66.959290 loss_rnnt 39.562347 hw_loss 0.542520 lr 0.00044956 rank 7
2023-02-11 03:01:08,005 DEBUG TRAIN Batch 1/2900 loss 67.418137 loss_att 128.142578 loss_ctc 80.083603 loss_rnnt 50.808094 hw_loss 0.520578 lr 0.00044972 rank 6
2023-02-11 03:01:08,006 DEBUG TRAIN Batch 1/2900 loss 80.290504 loss_att 152.940460 loss_ctc 94.868256 loss_rnnt 61.144711 hw_loss 0.501018 lr 0.00044976 rank 5
2023-02-11 03:01:08,007 DEBUG TRAIN Batch 1/2900 loss 52.997456 loss_att 118.315636 loss_ctc 61.036285 loss_rnnt 36.943001 hw_loss 0.359807 lr 0.00044968 rank 2
2023-02-11 03:01:08,012 DEBUG TRAIN Batch 1/2900 loss 66.849190 loss_att 124.907013 loss_ctc 74.996849 loss_rnnt 50.944214 hw_loss 0.601324 lr 0.00044884 rank 4
2023-02-11 03:02:23,254 DEBUG TRAIN Batch 1/3000 loss 47.647881 loss_att 91.669647 loss_ctc 51.777893 loss_rnnt 33.398083 hw_loss 0.917770 lr 0.00045356 rank 7
2023-02-11 03:02:23,255 DEBUG TRAIN Batch 1/3000 loss 35.947906 loss_att 77.663315 loss_ctc 42.681793 loss_rnnt 24.427498 hw_loss 0.427402 lr 0.00045384 rank 0
2023-02-11 03:02:23,255 DEBUG TRAIN Batch 1/3000 loss 43.990620 loss_att 84.399139 loss_ctc 54.170807 loss_rnnt 32.078896 hw_loss 0.463624 lr 0.00045336 rank 3
2023-02-11 03:02:23,258 DEBUG TRAIN Batch 1/3000 loss 58.424114 loss_att 107.190292 loss_ctc 69.343643 loss_rnnt 44.345161 hw_loss 0.538083 lr 0.00045372 rank 6
2023-02-11 03:02:23,258 DEBUG TRAIN Batch 1/3000 loss 84.971581 loss_att 151.075363 loss_ctc 99.239357 loss_rnnt 66.017136 hw_loss 0.718373 lr 0.00045500 rank 1
2023-02-11 03:02:23,259 DEBUG TRAIN Batch 1/3000 loss 68.428772 loss_att 115.884766 loss_ctc 78.453430 loss_rnnt 54.865791 hw_loss 0.512842 lr 0.00045368 rank 2
2023-02-11 03:02:23,259 DEBUG TRAIN Batch 1/3000 loss 70.855499 loss_att 123.204010 loss_ctc 70.652496 loss_rnnt 55.604050 hw_loss 0.901653 lr 0.00045284 rank 4
2023-02-11 03:02:23,260 DEBUG TRAIN Batch 1/3000 loss 64.961159 loss_att 111.475266 loss_ctc 70.139114 loss_rnnt 50.993572 hw_loss 0.745195 lr 0.00045376 rank 5
2023-02-11 03:03:40,523 DEBUG TRAIN Batch 1/3100 loss 59.700100 loss_att 128.563919 loss_ctc 69.254776 loss_rnnt 42.079987 hw_loss 0.482512 lr 0.00045776 rank 5
2023-02-11 03:03:40,523 DEBUG TRAIN Batch 1/3100 loss 41.031281 loss_att 54.845577 loss_ctc 43.641979 loss_rnnt 32.837746 hw_loss 0.952983 lr 0.00045772 rank 6
2023-02-11 03:03:40,523 DEBUG TRAIN Batch 1/3100 loss 53.563496 loss_att 94.663719 loss_ctc 61.572845 loss_rnnt 40.152191 hw_loss 0.773127 lr 0.00045736 rank 3
2023-02-11 03:03:40,525 DEBUG TRAIN Batch 1/3100 loss 49.035896 loss_att 63.950596 loss_ctc 54.842396 loss_rnnt 40.361877 hw_loss 0.921915 lr 0.00045784 rank 0
2023-02-11 03:03:40,529 DEBUG TRAIN Batch 1/3100 loss 71.205345 loss_att 117.220985 loss_ctc 82.166710 loss_rnnt 57.281017 hw_loss 0.611190 lr 0.00045900 rank 1
2023-02-11 03:03:40,530 DEBUG TRAIN Batch 1/3100 loss 48.378029 loss_att 89.662384 loss_ctc 56.149742 loss_rnnt 35.861328 hw_loss 0.604425 lr 0.00045756 rank 7
2023-02-11 03:03:40,533 DEBUG TRAIN Batch 1/3100 loss 63.241436 loss_att 125.334534 loss_ctc 72.871468 loss_rnnt 46.566277 hw_loss 0.557351 lr 0.00045684 rank 4
2023-02-11 03:03:40,578 DEBUG TRAIN Batch 1/3100 loss 27.886875 loss_att 37.883858 loss_ctc 29.890881 loss_rnnt 20.515520 hw_loss 0.957142 lr 0.00045768 rank 2
2023-02-11 03:05:01,772 DEBUG TRAIN Batch 1/3200 loss 28.211370 loss_att 38.268074 loss_ctc 35.006512 loss_rnnt 20.872904 hw_loss 0.828957 lr 0.00046156 rank 7
2023-02-11 03:05:01,775 DEBUG TRAIN Batch 1/3200 loss 44.210880 loss_att 108.941437 loss_ctc 47.028778 loss_rnnt 27.647665 hw_loss 0.607760 lr 0.00046136 rank 3
2023-02-11 03:05:01,777 DEBUG TRAIN Batch 1/3200 loss 55.177597 loss_att 86.912643 loss_ctc 65.007965 loss_rnnt 43.642517 hw_loss 0.727004 lr 0.00046176 rank 5
2023-02-11 03:05:01,779 DEBUG TRAIN Batch 1/3200 loss 40.141830 loss_att 99.715080 loss_ctc 41.469818 loss_rnnt 26.162178 hw_loss 0.353988 lr 0.00046172 rank 6
2023-02-11 03:05:01,780 DEBUG TRAIN Batch 1/3200 loss 30.982407 loss_att 51.888145 loss_ctc 30.164923 loss_rnnt 21.907112 hw_loss 0.938089 lr 0.00046084 rank 4
2023-02-11 03:05:01,788 DEBUG TRAIN Batch 1/3200 loss 40.381493 loss_att 60.610550 loss_ctc 46.652199 loss_rnnt 31.362247 hw_loss 0.775751 lr 0.00046300 rank 1
2023-02-11 03:05:01,798 DEBUG TRAIN Batch 1/3200 loss 57.081173 loss_att 117.997757 loss_ctc 64.377312 loss_rnnt 39.750805 hw_loss 0.782668 lr 0.00046184 rank 0
2023-02-11 03:05:01,836 DEBUG TRAIN Batch 1/3200 loss 63.077991 loss_att 123.255653 loss_ctc 72.163292 loss_rnnt 47.002892 hw_loss 0.530288 lr 0.00046168 rank 2
2023-02-11 03:06:16,937 DEBUG TRAIN Batch 1/3300 loss 52.611237 loss_att 117.139923 loss_ctc 55.313641 loss_rnnt 34.925659 hw_loss 0.828659 lr 0.00046536 rank 3
2023-02-11 03:06:16,939 DEBUG TRAIN Batch 1/3300 loss 36.510551 loss_att 82.878166 loss_ctc 47.580116 loss_rnnt 23.887274 hw_loss 0.351340 lr 0.00046584 rank 0
2023-02-11 03:06:16,944 DEBUG TRAIN Batch 1/3300 loss 51.061550 loss_att 111.699493 loss_ctc 59.235546 loss_rnnt 35.832825 hw_loss 0.377113 lr 0.00046556 rank 7
2023-02-11 03:06:16,945 DEBUG TRAIN Batch 1/3300 loss 59.450871 loss_att 131.993683 loss_ctc 72.659843 loss_rnnt 40.915558 hw_loss 0.424791 lr 0.00046576 rank 5
2023-02-11 03:06:16,946 DEBUG TRAIN Batch 1/3300 loss 50.160698 loss_att 113.952385 loss_ctc 47.986816 loss_rnnt 35.788418 hw_loss 0.356962 lr 0.00046484 rank 4
2023-02-11 03:06:16,947 DEBUG TRAIN Batch 1/3300 loss 61.366039 loss_att 118.767036 loss_ctc 75.676872 loss_rnnt 46.931988 hw_loss 0.196077 lr 0.00046572 rank 6
2023-02-11 03:06:16,949 DEBUG TRAIN Batch 1/3300 loss 50.151413 loss_att 103.616745 loss_ctc 58.142021 loss_rnnt 37.107300 hw_loss 0.241057 lr 0.00046700 rank 1
2023-02-11 03:06:16,952 DEBUG TRAIN Batch 1/3300 loss 69.455986 loss_att 131.258865 loss_ctc 69.140625 loss_rnnt 54.579002 hw_loss 0.479712 lr 0.00046568 rank 2
2023-02-11 03:07:32,150 DEBUG TRAIN Batch 1/3400 loss 64.923592 loss_att 136.439270 loss_ctc 73.713852 loss_rnnt 44.746975 hw_loss 0.881521 lr 0.00046936 rank 3
2023-02-11 03:07:32,150 DEBUG TRAIN Batch 1/3400 loss 63.283245 loss_att 121.801201 loss_ctc 78.836700 loss_rnnt 46.338638 hw_loss 0.593854 lr 0.00046984 rank 0
2023-02-11 03:07:32,156 DEBUG TRAIN Batch 1/3400 loss 61.798862 loss_att 126.479271 loss_ctc 70.412453 loss_rnnt 46.964031 hw_loss 0.140675 lr 0.00047100 rank 1
2023-02-11 03:07:32,157 DEBUG TRAIN Batch 1/3400 loss 100.649223 loss_att 165.652298 loss_ctc 114.518951 loss_rnnt 84.658409 hw_loss 0.213918 lr 0.00046956 rank 7
2023-02-11 03:07:32,158 DEBUG TRAIN Batch 1/3400 loss 92.138168 loss_att 149.299042 loss_ctc 114.402184 loss_rnnt 75.411743 hw_loss 0.436071 lr 0.00046976 rank 5
2023-02-11 03:07:32,162 DEBUG TRAIN Batch 1/3400 loss 39.218941 loss_att 89.387550 loss_ctc 47.959442 loss_rnnt 26.425795 hw_loss 0.298880 lr 0.00046884 rank 4
2023-02-11 03:07:32,167 DEBUG TRAIN Batch 1/3400 loss 63.227131 loss_att 122.529907 loss_ctc 79.639755 loss_rnnt 46.014080 hw_loss 0.593278 lr 0.00046972 rank 6
2023-02-11 03:07:32,200 DEBUG TRAIN Batch 1/3400 loss 50.593235 loss_att 103.915985 loss_ctc 55.258125 loss_rnnt 36.309486 hw_loss 0.561977 lr 0.00046968 rank 2
2023-02-11 03:08:49,473 DEBUG TRAIN Batch 1/3500 loss 97.751984 loss_att 157.056015 loss_ctc 119.185562 loss_rnnt 80.615944 hw_loss 0.453265 lr 0.00047500 rank 1
2023-02-11 03:08:49,479 DEBUG TRAIN Batch 1/3500 loss 58.421772 loss_att 128.366531 loss_ctc 67.100357 loss_rnnt 38.927998 hw_loss 0.815189 lr 0.00047356 rank 7
2023-02-11 03:08:49,480 DEBUG TRAIN Batch 1/3500 loss 57.231339 loss_att 102.149841 loss_ctc 65.780472 loss_rnnt 42.881485 hw_loss 0.792425 lr 0.00047384 rank 0
2023-02-11 03:08:49,480 DEBUG TRAIN Batch 1/3500 loss 72.230881 loss_att 128.659821 loss_ctc 88.088547 loss_rnnt 55.333618 hw_loss 0.655711 lr 0.00047376 rank 5
2023-02-11 03:08:49,483 DEBUG TRAIN Batch 1/3500 loss 74.689835 loss_att 148.088501 loss_ctc 81.736771 loss_rnnt 55.844368 hw_loss 0.604900 lr 0.00047336 rank 3
2023-02-11 03:08:49,483 DEBUG TRAIN Batch 1/3500 loss 61.449074 loss_att 109.012390 loss_ctc 77.856316 loss_rnnt 46.658615 hw_loss 0.579405 lr 0.00047372 rank 6
2023-02-11 03:08:49,484 DEBUG TRAIN Batch 1/3500 loss 65.794029 loss_att 110.927826 loss_ctc 82.589020 loss_rnnt 51.415604 hw_loss 0.583562 lr 0.00047368 rank 2
2023-02-11 03:08:49,487 DEBUG TRAIN Batch 1/3500 loss 45.361656 loss_att 82.826523 loss_ctc 55.082191 loss_rnnt 33.797604 hw_loss 0.520315 lr 0.00047284 rank 4
2023-02-11 03:10:06,591 DEBUG TRAIN Batch 1/3600 loss 38.887131 loss_att 92.842056 loss_ctc 47.283310 loss_rnnt 23.724293 hw_loss 0.609818 lr 0.00047900 rank 1
2023-02-11 03:10:06,593 DEBUG TRAIN Batch 1/3600 loss 44.842052 loss_att 84.747086 loss_ctc 50.926105 loss_rnnt 32.812218 hw_loss 0.607054 lr 0.00047756 rank 7
2023-02-11 03:10:06,594 DEBUG TRAIN Batch 1/3600 loss 58.026688 loss_att 110.472969 loss_ctc 72.862923 loss_rnnt 42.641060 hw_loss 0.547164 lr 0.00047684 rank 4
2023-02-11 03:10:06,595 DEBUG TRAIN Batch 1/3600 loss 58.094643 loss_att 93.983292 loss_ctc 70.234100 loss_rnnt 45.972343 hw_loss 0.623621 lr 0.00047784 rank 0
2023-02-11 03:10:06,596 DEBUG TRAIN Batch 1/3600 loss 53.766228 loss_att 104.174973 loss_ctc 62.279926 loss_rnnt 37.129776 hw_loss 1.016164 lr 0.00047736 rank 3
2023-02-11 03:10:06,598 DEBUG TRAIN Batch 1/3600 loss 64.939583 loss_att 118.355339 loss_ctc 70.381607 loss_rnnt 50.794258 hw_loss 0.513105 lr 0.00047776 rank 5
2023-02-11 03:10:06,598 DEBUG TRAIN Batch 1/3600 loss 61.703045 loss_att 109.151154 loss_ctc 76.195557 loss_rnnt 48.796288 hw_loss 0.278401 lr 0.00047772 rank 6
2023-02-11 03:10:06,598 DEBUG TRAIN Batch 1/3600 loss 56.647289 loss_att 101.869904 loss_ctc 66.415985 loss_rnnt 43.016060 hw_loss 0.615789 lr 0.00047768 rank 2
2023-02-11 03:11:21,790 DEBUG TRAIN Batch 1/3700 loss 33.622158 loss_att 52.402805 loss_ctc 35.154015 loss_rnnt 25.553926 hw_loss 0.770222 lr 0.00048184 rank 0
2023-02-11 03:11:21,792 DEBUG TRAIN Batch 1/3700 loss 74.787392 loss_att 125.863129 loss_ctc 94.190720 loss_rnnt 57.736053 hw_loss 0.796702 lr 0.00048156 rank 7
2023-02-11 03:11:21,793 DEBUG TRAIN Batch 1/3700 loss 41.666847 loss_att 79.938736 loss_ctc 51.483292 loss_rnnt 31.259312 hw_loss 0.270805 lr 0.00048136 rank 3
2023-02-11 03:11:21,795 DEBUG TRAIN Batch 1/3700 loss 58.976822 loss_att 108.905739 loss_ctc 71.973053 loss_rnnt 42.514275 hw_loss 0.889488 lr 0.00048176 rank 5
2023-02-11 03:11:21,796 DEBUG TRAIN Batch 1/3700 loss 70.768318 loss_att 118.500565 loss_ctc 76.650116 loss_rnnt 56.516354 hw_loss 0.735238 lr 0.00048300 rank 1
2023-02-11 03:11:21,796 DEBUG TRAIN Batch 1/3700 loss 42.399422 loss_att 52.650845 loss_ctc 47.727398 loss_rnnt 34.943989 hw_loss 0.880266 lr 0.00048172 rank 6
2023-02-11 03:11:21,796 DEBUG TRAIN Batch 1/3700 loss 60.260242 loss_att 102.439133 loss_ctc 58.728073 loss_rnnt 46.104698 hw_loss 1.110760 lr 0.00048084 rank 4
2023-02-11 03:11:21,797 DEBUG TRAIN Batch 1/3700 loss 34.485771 loss_att 44.632965 loss_ctc 38.937355 loss_rnnt 25.535421 hw_loss 1.186381 lr 0.00048168 rank 2
2023-02-11 03:12:37,235 DEBUG TRAIN Batch 1/3800 loss 52.228458 loss_att 80.438171 loss_ctc 59.393719 loss_rnnt 42.096771 hw_loss 0.662695 lr 0.00048536 rank 3
2023-02-11 03:12:37,236 DEBUG TRAIN Batch 1/3800 loss 45.277119 loss_att 84.884033 loss_ctc 54.590485 loss_rnnt 32.555859 hw_loss 0.667143 lr 0.00048484 rank 4
2023-02-11 03:12:37,239 DEBUG TRAIN Batch 1/3800 loss 41.797276 loss_att 78.429138 loss_ctc 48.340229 loss_rnnt 29.361219 hw_loss 0.794492 lr 0.00048700 rank 1
2023-02-11 03:12:37,239 DEBUG TRAIN Batch 1/3800 loss 56.292931 loss_att 108.076515 loss_ctc 65.589111 loss_rnnt 40.554188 hw_loss 0.776726 lr 0.00048556 rank 7
2023-02-11 03:12:37,239 DEBUG TRAIN Batch 1/3800 loss 62.720257 loss_att 132.696350 loss_ctc 64.344215 loss_rnnt 45.969292 hw_loss 0.476104 lr 0.00048568 rank 2
2023-02-11 03:12:37,265 DEBUG TRAIN Batch 1/3800 loss 49.086216 loss_att 86.533836 loss_ctc 54.543896 loss_rnnt 34.439022 hw_loss 1.205621 lr 0.00048576 rank 5
2023-02-11 03:12:37,279 DEBUG TRAIN Batch 1/3800 loss 45.622490 loss_att 91.679932 loss_ctc 49.017117 loss_rnnt 32.852871 hw_loss 0.582284 lr 0.00048584 rank 0
2023-02-11 03:12:37,286 DEBUG TRAIN Batch 1/3800 loss 59.601009 loss_att 121.549927 loss_ctc 72.932343 loss_rnnt 42.080624 hw_loss 0.628704 lr 0.00048572 rank 6
2023-02-11 03:13:56,669 DEBUG TRAIN Batch 1/3900 loss 40.852158 loss_att 52.804676 loss_ctc 48.314102 loss_rnnt 33.861160 hw_loss 0.676045 lr 0.00048956 rank 7
2023-02-11 03:13:56,669 DEBUG TRAIN Batch 1/3900 loss 76.017296 loss_att 124.692924 loss_ctc 95.683708 loss_rnnt 60.556511 hw_loss 0.581902 lr 0.00048972 rank 6
2023-02-11 03:13:56,672 DEBUG TRAIN Batch 1/3900 loss 37.515465 loss_att 39.023891 loss_ctc 39.133171 loss_rnnt 30.782736 hw_loss 1.165379 lr 0.00049100 rank 1
2023-02-11 03:13:56,674 DEBUG TRAIN Batch 1/3900 loss 45.958858 loss_att 102.896774 loss_ctc 61.034637 loss_rnnt 32.443451 hw_loss 0.022073 lr 0.00048984 rank 0
2023-02-11 03:13:56,674 DEBUG TRAIN Batch 1/3900 loss 61.085247 loss_att 115.050896 loss_ctc 78.478172 loss_rnnt 45.020447 hw_loss 0.553614 lr 0.00048968 rank 2
2023-02-11 03:13:56,675 DEBUG TRAIN Batch 1/3900 loss 71.935783 loss_att 133.887039 loss_ctc 83.435120 loss_rnnt 55.811504 hw_loss 0.412645 lr 0.00048884 rank 4
2023-02-11 03:13:56,688 DEBUG TRAIN Batch 1/3900 loss 23.202665 loss_att 24.422464 loss_ctc 23.924913 loss_rnnt 15.748105 hw_loss 1.333931 lr 0.00048976 rank 5
2023-02-11 03:13:56,694 DEBUG TRAIN Batch 1/3900 loss 41.353397 loss_att 88.220390 loss_ctc 42.877682 loss_rnnt 28.760754 hw_loss 0.565501 lr 0.00048936 rank 3
2023-02-11 03:15:12,792 DEBUG TRAIN Batch 1/4000 loss 53.298481 loss_att 106.851257 loss_ctc 56.051208 loss_rnnt 40.478523 hw_loss 0.326695 lr 0.00049336 rank 3
2023-02-11 03:15:12,792 DEBUG TRAIN Batch 1/4000 loss 50.309574 loss_att 105.992355 loss_ctc 53.145397 loss_rnnt 35.294647 hw_loss 0.656299 lr 0.00049500 rank 1
2023-02-11 03:15:12,792 DEBUG TRAIN Batch 1/4000 loss 56.448635 loss_att 104.403336 loss_ctc 68.755127 loss_rnnt 44.593132 hw_loss 0.116944 lr 0.00049384 rank 0
2023-02-11 03:15:12,793 DEBUG TRAIN Batch 1/4000 loss 68.051811 loss_att 123.394684 loss_ctc 86.787590 loss_rnnt 52.278656 hw_loss 0.413714 lr 0.00049356 rank 7
2023-02-11 03:15:12,793 DEBUG TRAIN Batch 1/4000 loss 37.893257 loss_att 93.051346 loss_ctc 47.023815 loss_rnnt 25.198700 hw_loss 0.083537 lr 0.00049368 rank 2
2023-02-11 03:15:12,793 DEBUG TRAIN Batch 1/4000 loss 35.539116 loss_att 71.711739 loss_ctc 39.333183 loss_rnnt 25.697437 hw_loss 0.393989 lr 0.00049376 rank 5
2023-02-11 03:15:12,796 DEBUG TRAIN Batch 1/4000 loss 39.343548 loss_att 89.450829 loss_ctc 52.108234 loss_rnnt 25.905445 hw_loss 0.321503 lr 0.00049372 rank 6
2023-02-11 03:15:12,796 DEBUG TRAIN Batch 1/4000 loss 60.959179 loss_att 112.570984 loss_ctc 67.924210 loss_rnnt 47.130669 hw_loss 0.483277 lr 0.00049284 rank 4
2023-02-11 03:16:29,285 DEBUG TRAIN Batch 1/4100 loss 54.647236 loss_att 110.611107 loss_ctc 67.392593 loss_rnnt 38.887295 hw_loss 0.537710 lr 0.00049900 rank 1
2023-02-11 03:16:29,286 DEBUG TRAIN Batch 1/4100 loss 55.482590 loss_att 108.317780 loss_ctc 67.180450 loss_rnnt 40.805435 hw_loss 0.478201 lr 0.00049776 rank 5
2023-02-11 03:16:29,286 DEBUG TRAIN Batch 1/4100 loss 63.332169 loss_att 104.456482 loss_ctc 72.129852 loss_rnnt 51.234848 hw_loss 0.506143 lr 0.00049772 rank 6
2023-02-11 03:16:29,288 DEBUG TRAIN Batch 1/4100 loss 47.370010 loss_att 90.215164 loss_ctc 53.779213 loss_rnnt 35.002350 hw_loss 0.552013 lr 0.00049736 rank 3
2023-02-11 03:16:29,290 DEBUG TRAIN Batch 1/4100 loss 36.452763 loss_att 78.521332 loss_ctc 39.774673 loss_rnnt 23.986580 hw_loss 0.676790 lr 0.00049768 rank 2
2023-02-11 03:16:29,291 DEBUG TRAIN Batch 1/4100 loss 51.098129 loss_att 96.896423 loss_ctc 60.866703 loss_rnnt 36.674530 hw_loss 0.742775 lr 0.00049784 rank 0
2023-02-11 03:16:29,291 DEBUG TRAIN Batch 1/4100 loss 62.263523 loss_att 106.494476 loss_ctc 81.212883 loss_rnnt 49.127483 hw_loss 0.330613 lr 0.00049756 rank 7
2023-02-11 03:16:29,298 DEBUG TRAIN Batch 1/4100 loss 80.791069 loss_att 145.198120 loss_ctc 99.657944 loss_rnnt 62.806053 hw_loss 0.485254 lr 0.00049684 rank 4
2023-02-11 03:17:45,819 DEBUG TRAIN Batch 1/4200 loss 49.422310 loss_att 87.881119 loss_ctc 55.135605 loss_rnnt 37.155392 hw_loss 0.715010 lr 0.00050156 rank 7
2023-02-11 03:17:45,819 DEBUG TRAIN Batch 1/4200 loss 53.463131 loss_att 98.915962 loss_ctc 60.723721 loss_rnnt 40.527889 hw_loss 0.539362 lr 0.00050136 rank 3
2023-02-11 03:17:45,820 DEBUG TRAIN Batch 1/4200 loss 45.132648 loss_att 79.504036 loss_ctc 54.234905 loss_rnnt 32.370102 hw_loss 0.876494 lr 0.00050172 rank 6
2023-02-11 03:17:45,821 DEBUG TRAIN Batch 1/4200 loss 67.497742 loss_att 108.063202 loss_ctc 76.119225 loss_rnnt 55.386330 hw_loss 0.534148 lr 0.00050184 rank 0
2023-02-11 03:17:45,824 DEBUG TRAIN Batch 1/4200 loss 64.254044 loss_att 107.654007 loss_ctc 81.775604 loss_rnnt 51.078987 hw_loss 0.404785 lr 0.00050084 rank 4
2023-02-11 03:17:45,824 DEBUG TRAIN Batch 1/4200 loss 53.726002 loss_att 96.138321 loss_ctc 63.942589 loss_rnnt 40.431744 hw_loss 0.646796 lr 0.00050300 rank 1
2023-02-11 03:17:45,824 DEBUG TRAIN Batch 1/4200 loss 67.051643 loss_att 113.735748 loss_ctc 79.663162 loss_rnnt 53.129410 hw_loss 0.544478 lr 0.00050176 rank 5
2023-02-11 03:17:45,825 DEBUG TRAIN Batch 1/4200 loss 66.002907 loss_att 103.598297 loss_ctc 77.370285 loss_rnnt 53.209393 hw_loss 0.704772 lr 0.00050168 rank 2
2023-02-11 03:19:04,331 DEBUG TRAIN Batch 1/4300 loss 49.552586 loss_att 84.542038 loss_ctc 59.722477 loss_rnnt 37.409332 hw_loss 0.710508 lr 0.00050536 rank 3
2023-02-11 03:19:04,332 DEBUG TRAIN Batch 1/4300 loss 71.915695 loss_att 119.076691 loss_ctc 86.368408 loss_rnnt 58.144211 hw_loss 0.452298 lr 0.00050556 rank 7
2023-02-11 03:19:04,335 DEBUG TRAIN Batch 1/4300 loss 60.289074 loss_att 103.853668 loss_ctc 67.912323 loss_rnnt 48.224319 hw_loss 0.437888 lr 0.00050484 rank 4
2023-02-11 03:19:04,335 DEBUG TRAIN Batch 1/4300 loss 77.207771 loss_att 112.972214 loss_ctc 91.916428 loss_rnnt 61.889248 hw_loss 1.163339 lr 0.00050572 rank 6
2023-02-11 03:19:04,337 DEBUG TRAIN Batch 1/4300 loss 44.145683 loss_att 80.226242 loss_ctc 50.790421 loss_rnnt 31.079674 hw_loss 0.930737 lr 0.00050700 rank 1
2023-02-11 03:19:04,338 DEBUG TRAIN Batch 1/4300 loss 68.289162 loss_att 105.056290 loss_ctc 82.217270 loss_rnnt 55.662155 hw_loss 0.640593 lr 0.00050576 rank 5
2023-02-11 03:19:04,339 DEBUG TRAIN Batch 1/4300 loss 44.431538 loss_att 75.370605 loss_ctc 52.168396 loss_rnnt 32.047554 hw_loss 0.968360 lr 0.00050584 rank 0
2023-02-11 03:19:04,386 DEBUG TRAIN Batch 1/4300 loss 56.146881 loss_att 91.642532 loss_ctc 71.655861 loss_rnnt 45.043945 hw_loss 0.362989 lr 0.00050568 rank 2
2023-02-11 03:20:19,234 DEBUG TRAIN Batch 1/4400 loss 40.649967 loss_att 71.990631 loss_ctc 47.930374 loss_rnnt 30.880720 hw_loss 0.474449 lr 0.00050956 rank 7
2023-02-11 03:20:19,239 DEBUG TRAIN Batch 1/4400 loss 46.702843 loss_att 105.628418 loss_ctc 54.677444 loss_rnnt 32.093185 hw_loss 0.330237 lr 0.00050984 rank 0
2023-02-11 03:20:19,240 DEBUG TRAIN Batch 1/4400 loss 44.884651 loss_att 105.823120 loss_ctc 57.719040 loss_rnnt 26.597626 hw_loss 0.822765 lr 0.00050972 rank 6
2023-02-11 03:20:19,242 DEBUG TRAIN Batch 1/4400 loss 70.846100 loss_att 104.274918 loss_ctc 84.589760 loss_rnnt 58.025478 hw_loss 0.806693 lr 0.00050936 rank 3
2023-02-11 03:20:19,242 DEBUG TRAIN Batch 1/4400 loss 48.477066 loss_att 88.004494 loss_ctc 52.309559 loss_rnnt 35.725697 hw_loss 0.812790 lr 0.00050884 rank 4
2023-02-11 03:20:19,242 DEBUG TRAIN Batch 1/4400 loss 30.106714 loss_att 31.082680 loss_ctc 33.072506 loss_rnnt 23.112514 hw_loss 1.200669 lr 0.00050968 rank 2
2023-02-11 03:20:19,245 DEBUG TRAIN Batch 1/4400 loss 40.909901 loss_att 73.764580 loss_ctc 50.296101 loss_rnnt 30.592842 hw_loss 0.467743 lr 0.00050976 rank 5
2023-02-11 03:20:19,246 DEBUG TRAIN Batch 1/4400 loss 60.853760 loss_att 106.896774 loss_ctc 72.605072 loss_rnnt 49.317970 hw_loss 0.142564 lr 0.00051100 rank 1
2023-02-11 03:21:35,389 DEBUG TRAIN Batch 1/4500 loss 31.038580 loss_att 36.515862 loss_ctc 35.819504 loss_rnnt 22.392365 hw_loss 1.296244 lr 0.00051336 rank 3
2023-02-11 03:21:35,389 DEBUG TRAIN Batch 1/4500 loss 48.667080 loss_att 52.561634 loss_ctc 53.260403 loss_rnnt 41.963032 hw_loss 0.996129 lr 0.00051356 rank 7
2023-02-11 03:21:35,390 DEBUG TRAIN Batch 1/4500 loss 41.159752 loss_att 74.663200 loss_ctc 46.882935 loss_rnnt 30.286978 hw_loss 0.639187 lr 0.00051384 rank 0
2023-02-11 03:21:35,394 DEBUG TRAIN Batch 1/4500 loss 54.418880 loss_att 92.053833 loss_ctc 68.167336 loss_rnnt 39.710205 hw_loss 1.002855 lr 0.00051368 rank 2
2023-02-11 03:21:35,394 DEBUG TRAIN Batch 1/4500 loss 26.412708 loss_att 30.844021 loss_ctc 24.513607 loss_rnnt 18.515739 hw_loss 1.361985 lr 0.00051376 rank 5
2023-02-11 03:21:35,397 DEBUG TRAIN Batch 1/4500 loss 57.045895 loss_att 119.565201 loss_ctc 79.429993 loss_rnnt 41.313282 hw_loss 0.045788 lr 0.00051372 rank 6
2023-02-11 03:21:35,398 DEBUG TRAIN Batch 1/4500 loss 38.916786 loss_att 69.916306 loss_ctc 45.812004 loss_rnnt 27.197269 hw_loss 0.862547 lr 0.00051500 rank 1
2023-02-11 03:21:35,399 DEBUG TRAIN Batch 1/4500 loss 28.806902 loss_att 35.188164 loss_ctc 30.079935 loss_rnnt 22.450974 hw_loss 0.920613 lr 0.00051284 rank 4
2023-02-11 03:22:56,682 DEBUG TRAIN Batch 1/4600 loss 30.181034 loss_att 75.394951 loss_ctc 39.624748 loss_rnnt 16.759045 hw_loss 0.585009 lr 0.00051772 rank 6
2023-02-11 03:22:56,684 DEBUG TRAIN Batch 1/4600 loss 31.153036 loss_att 62.358650 loss_ctc 35.251003 loss_rnnt 22.574865 hw_loss 0.335747 lr 0.00051736 rank 3
2023-02-11 03:22:56,686 DEBUG TRAIN Batch 1/4600 loss 46.024193 loss_att 101.898880 loss_ctc 53.528191 loss_rnnt 32.456493 hw_loss 0.261043 lr 0.00051784 rank 0
2023-02-11 03:22:56,685 DEBUG TRAIN Batch 1/4600 loss 41.888542 loss_att 80.565971 loss_ctc 44.390640 loss_rnnt 31.167625 hw_loss 0.497215 lr 0.00051768 rank 2
2023-02-11 03:22:56,686 DEBUG TRAIN Batch 1/4600 loss 42.439796 loss_att 80.694168 loss_ctc 50.703564 loss_rnnt 32.475071 hw_loss 0.227253 lr 0.00051776 rank 5
2023-02-11 03:22:56,686 DEBUG TRAIN Batch 1/4600 loss 39.890152 loss_att 83.524597 loss_ctc 49.061035 loss_rnnt 27.019012 hw_loss 0.547775 lr 0.00051684 rank 4
2023-02-11 03:22:56,694 DEBUG TRAIN Batch 1/4600 loss 21.782183 loss_att 22.711058 loss_ctc 21.082584 loss_rnnt 14.008171 hw_loss 1.440284 lr 0.00051900 rank 1
2023-02-11 03:22:56,701 DEBUG TRAIN Batch 1/4600 loss 62.419357 loss_att 122.422043 loss_ctc 73.945068 loss_rnnt 46.693092 hw_loss 0.410430 lr 0.00051756 rank 7
2023-02-11 03:24:12,501 DEBUG TRAIN Batch 1/4700 loss 51.603603 loss_att 89.723244 loss_ctc 63.501495 loss_rnnt 40.957291 hw_loss 0.269249 lr 0.00052136 rank 3
2023-02-11 03:24:12,501 DEBUG TRAIN Batch 1/4700 loss 36.968006 loss_att 70.333511 loss_ctc 46.283371 loss_rnnt 28.654991 hw_loss 0.074600 lr 0.00052176 rank 5
2023-02-11 03:24:12,503 DEBUG TRAIN Batch 1/4700 loss 40.722828 loss_att 92.768646 loss_ctc 50.474060 loss_rnnt 27.490385 hw_loss 0.285583 lr 0.00052156 rank 7
2023-02-11 03:24:12,504 DEBUG TRAIN Batch 1/4700 loss 42.854664 loss_att 82.254814 loss_ctc 47.921913 loss_rnnt 31.470434 hw_loss 0.530357 lr 0.00052300 rank 1
2023-02-11 03:24:12,504 DEBUG TRAIN Batch 1/4700 loss 53.090630 loss_att 100.759567 loss_ctc 67.765289 loss_rnnt 36.809807 hw_loss 0.898203 lr 0.00052184 rank 0
2023-02-11 03:24:12,505 DEBUG TRAIN Batch 1/4700 loss 70.279243 loss_att 120.504395 loss_ctc 89.713547 loss_rnnt 55.262558 hw_loss 0.446327 lr 0.00052168 rank 2
2023-02-11 03:24:12,507 DEBUG TRAIN Batch 1/4700 loss 59.720200 loss_att 113.460159 loss_ctc 68.842941 loss_rnnt 44.796951 hw_loss 0.554792 lr 0.00052084 rank 4
2023-02-11 03:24:12,513 DEBUG TRAIN Batch 1/4700 loss 46.502377 loss_att 75.276634 loss_ctc 54.112366 loss_rnnt 36.229897 hw_loss 0.656805 lr 0.00052172 rank 6
2023-02-11 03:25:29,249 DEBUG TRAIN Batch 1/4800 loss 55.904270 loss_att 97.653900 loss_ctc 62.529121 loss_rnnt 44.482536 hw_loss 0.410343 lr 0.00052556 rank 7
2023-02-11 03:25:29,249 DEBUG TRAIN Batch 1/4800 loss 68.390892 loss_att 106.613144 loss_ctc 82.045341 loss_rnnt 56.427513 hw_loss 0.468437 lr 0.00052584 rank 0
2023-02-11 03:25:29,252 DEBUG TRAIN Batch 1/4800 loss 61.656464 loss_att 95.378830 loss_ctc 72.026855 loss_rnnt 49.598656 hw_loss 0.736991 lr 0.00052572 rank 6
2023-02-11 03:25:29,252 DEBUG TRAIN Batch 1/4800 loss 39.049461 loss_att 71.297783 loss_ctc 42.088394 loss_rnnt 28.523766 hw_loss 0.688282 lr 0.00052536 rank 3
2023-02-11 03:25:29,254 DEBUG TRAIN Batch 1/4800 loss 69.110176 loss_att 96.467117 loss_ctc 85.477051 loss_rnnt 59.225224 hw_loss 0.418372 lr 0.00052568 rank 2
2023-02-11 03:25:29,256 DEBUG TRAIN Batch 1/4800 loss 53.259323 loss_att 84.437515 loss_ctc 60.299278 loss_rnnt 39.478790 hw_loss 1.238669 lr 0.00052576 rank 5
2023-02-11 03:25:29,257 DEBUG TRAIN Batch 1/4800 loss 59.090538 loss_att 87.801758 loss_ctc 73.872055 loss_rnnt 48.414108 hw_loss 0.555621 lr 0.00052700 rank 1
2023-02-11 03:25:29,259 DEBUG TRAIN Batch 1/4800 loss 65.585457 loss_att 107.836784 loss_ctc 82.094971 loss_rnnt 51.005035 hw_loss 0.736666 lr 0.00052484 rank 4
2023-02-11 03:26:44,765 DEBUG TRAIN Batch 1/4900 loss 45.230957 loss_att 79.876930 loss_ctc 59.133259 loss_rnnt 33.416500 hw_loss 0.568429 lr 0.00052936 rank 3
2023-02-11 03:26:44,770 DEBUG TRAIN Batch 1/4900 loss 43.235588 loss_att 73.386101 loss_ctc 56.190224 loss_rnnt 32.209099 hw_loss 0.612957 lr 0.00052956 rank 7
2023-02-11 03:26:44,772 DEBUG TRAIN Batch 1/4900 loss 60.635933 loss_att 94.837479 loss_ctc 85.563057 loss_rnnt 48.380733 hw_loss 0.392115 lr 0.00053100 rank 1
2023-02-11 03:26:44,775 DEBUG TRAIN Batch 1/4900 loss 42.209248 loss_att 76.855751 loss_ctc 53.506760 loss_rnnt 30.403860 hw_loss 0.631828 lr 0.00052976 rank 5
2023-02-11 03:26:44,775 DEBUG TRAIN Batch 1/4900 loss 54.349236 loss_att 79.905212 loss_ctc 66.304909 loss_rnnt 42.181091 hw_loss 1.024287 lr 0.00052884 rank 4
2023-02-11 03:26:44,776 DEBUG TRAIN Batch 1/4900 loss 50.279099 loss_att 74.608383 loss_ctc 68.014099 loss_rnnt 38.934628 hw_loss 0.771365 lr 0.00052984 rank 0
2023-02-11 03:26:44,778 DEBUG TRAIN Batch 1/4900 loss 55.220894 loss_att 84.771248 loss_ctc 65.501793 loss_rnnt 44.550350 hw_loss 0.635566 lr 0.00052968 rank 2
2023-02-11 03:26:44,780 DEBUG TRAIN Batch 1/4900 loss 47.849472 loss_att 68.848251 loss_ctc 61.347004 loss_rnnt 38.545475 hw_loss 0.619606 lr 0.00052972 rank 6
2023-02-11 03:28:06,807 DEBUG TRAIN Batch 1/5000 loss 33.375332 loss_att 42.150162 loss_ctc 37.067108 loss_rnnt 24.303795 hw_loss 1.279562 lr 0.00053384 rank 0
2023-02-11 03:28:06,809 DEBUG TRAIN Batch 1/5000 loss 48.224075 loss_att 70.932602 loss_ctc 51.737595 loss_rnnt 39.626144 hw_loss 0.672705 lr 0.00053356 rank 7
2023-02-11 03:28:06,810 DEBUG TRAIN Batch 1/5000 loss 51.608883 loss_att 72.856812 loss_ctc 62.889965 loss_rnnt 43.525486 hw_loss 0.436812 lr 0.00053336 rank 3
2023-02-11 03:28:06,811 DEBUG TRAIN Batch 1/5000 loss 28.513344 loss_att 30.698273 loss_ctc 30.384594 loss_rnnt 22.336880 hw_loss 1.029371 lr 0.00053372 rank 6
2023-02-11 03:28:06,813 DEBUG TRAIN Batch 1/5000 loss 43.069492 loss_att 70.366104 loss_ctc 52.189224 loss_rnnt 32.920437 hw_loss 0.651332 lr 0.00053500 rank 1
2023-02-11 03:28:06,814 DEBUG TRAIN Batch 1/5000 loss 48.885406 loss_att 72.876541 loss_ctc 60.969669 loss_rnnt 39.377777 hw_loss 0.580907 lr 0.00053376 rank 5
2023-02-11 03:28:06,815 DEBUG TRAIN Batch 1/5000 loss 38.555420 loss_att 55.531593 loss_ctc 42.561310 loss_rnnt 31.437546 hw_loss 0.597848 lr 0.00053368 rank 2
2023-02-11 03:28:06,826 DEBUG TRAIN Batch 1/5000 loss 44.997627 loss_att 69.787552 loss_ctc 60.854069 loss_rnnt 34.999432 hw_loss 0.548628 lr 0.00053284 rank 4
2023-02-11 03:29:23,041 DEBUG TRAIN Batch 1/5100 loss 32.557281 loss_att 38.220135 loss_ctc 36.842789 loss_rnnt 24.620377 hw_loss 1.168675 lr 0.00053736 rank 3
2023-02-11 03:29:23,042 DEBUG TRAIN Batch 1/5100 loss 29.767178 loss_att 39.180771 loss_ctc 37.282478 loss_rnnt 25.628075 hw_loss 0.235189 lr 0.00053756 rank 7
2023-02-11 03:29:23,043 DEBUG TRAIN Batch 1/5100 loss 61.664993 loss_att 104.121414 loss_ctc 77.393120 loss_rnnt 47.653839 hw_loss 0.641772 lr 0.00053768 rank 2
2023-02-11 03:29:23,043 DEBUG TRAIN Batch 1/5100 loss 50.741035 loss_att 75.355667 loss_ctc 59.265717 loss_rnnt 41.226776 hw_loss 0.647758 lr 0.00053776 rank 5
2023-02-11 03:29:23,043 DEBUG TRAIN Batch 1/5100 loss 66.660965 loss_att 106.330963 loss_ctc 80.201561 loss_rnnt 53.793633 hw_loss 0.586484 lr 0.00053784 rank 0
2023-02-11 03:29:23,046 DEBUG TRAIN Batch 1/5100 loss 41.173378 loss_att 58.267632 loss_ctc 49.257259 loss_rnnt 32.692108 hw_loss 0.747107 lr 0.00053900 rank 1
2023-02-11 03:29:23,049 DEBUG TRAIN Batch 1/5100 loss 45.969036 loss_att 81.040848 loss_ctc 57.767853 loss_rnnt 33.939064 hw_loss 0.645456 lr 0.00053772 rank 6
2023-02-11 03:29:23,051 DEBUG TRAIN Batch 1/5100 loss 35.539936 loss_att 45.802834 loss_ctc 41.981716 loss_rnnt 27.907293 hw_loss 0.885218 lr 0.00053684 rank 4
2023-02-11 03:30:38,656 DEBUG TRAIN Batch 1/5200 loss 50.318645 loss_att 83.818558 loss_ctc 64.097801 loss_rnnt 39.589684 hw_loss 0.410954 lr 0.00054184 rank 0
2023-02-11 03:30:38,661 DEBUG TRAIN Batch 1/5200 loss 58.491798 loss_att 79.418427 loss_ctc 76.180855 loss_rnnt 49.736832 hw_loss 0.414581 lr 0.00054172 rank 6
2023-02-11 03:30:38,661 DEBUG TRAIN Batch 1/5200 loss 67.087547 loss_att 107.233978 loss_ctc 83.633942 loss_rnnt 54.055138 hw_loss 0.524425 lr 0.00054136 rank 3
2023-02-11 03:30:38,662 DEBUG TRAIN Batch 1/5200 loss 59.315903 loss_att 92.560196 loss_ctc 74.015884 loss_rnnt 46.141808 hw_loss 0.855983 lr 0.00054168 rank 2
2023-02-11 03:30:38,663 DEBUG TRAIN Batch 1/5200 loss 29.954876 loss_att 45.564285 loss_ctc 33.590179 loss_rnnt 23.083075 hw_loss 0.612227 lr 0.00054176 rank 5
2023-02-11 03:30:38,665 DEBUG TRAIN Batch 1/5200 loss 34.464653 loss_att 59.900871 loss_ctc 50.457439 loss_rnnt 23.800467 hw_loss 0.645857 lr 0.00054084 rank 4
2023-02-11 03:30:38,669 DEBUG TRAIN Batch 1/5200 loss 32.393536 loss_att 35.703232 loss_ctc 35.146935 loss_rnnt 23.091784 hw_loss 1.551130 lr 0.00054300 rank 1
2023-02-11 03:30:38,672 DEBUG TRAIN Batch 1/5200 loss 58.102859 loss_att 91.858597 loss_ctc 77.169212 loss_rnnt 46.755249 hw_loss 0.385178 lr 0.00054156 rank 7
2023-02-11 03:31:55,856 DEBUG TRAIN Batch 1/5300 loss 61.490936 loss_att 91.751930 loss_ctc 82.188004 loss_rnnt 48.839016 hw_loss 0.720021 lr 0.00054568 rank 2
2023-02-11 03:31:55,856 DEBUG TRAIN Batch 1/5300 loss 49.323914 loss_att 69.128174 loss_ctc 66.025055 loss_rnnt 41.267883 hw_loss 0.350317 lr 0.00054576 rank 5
2023-02-11 03:31:55,859 DEBUG TRAIN Batch 1/5300 loss 46.298279 loss_att 72.418411 loss_ctc 58.578850 loss_rnnt 34.052963 hw_loss 1.009478 lr 0.00054572 rank 6
2023-02-11 03:31:55,859 DEBUG TRAIN Batch 1/5300 loss 60.409550 loss_att 92.732063 loss_ctc 75.593109 loss_rnnt 46.908142 hw_loss 0.939831 lr 0.00054584 rank 0
2023-02-11 03:31:55,860 DEBUG TRAIN Batch 1/5300 loss 49.086842 loss_att 71.020386 loss_ctc 59.099625 loss_rnnt 40.045769 hw_loss 0.622374 lr 0.00054536 rank 3
2023-02-11 03:31:55,860 DEBUG TRAIN Batch 1/5300 loss 72.539680 loss_att 112.966545 loss_ctc 95.058914 loss_rnnt 59.356552 hw_loss 0.392847 lr 0.00054556 rank 7
2023-02-11 03:31:55,864 DEBUG TRAIN Batch 1/5300 loss 52.838837 loss_att 93.056534 loss_ctc 70.480179 loss_rnnt 41.164074 hw_loss 0.239820 lr 0.00054700 rank 1
2023-02-11 03:31:55,867 DEBUG TRAIN Batch 1/5300 loss 105.172180 loss_att 142.510895 loss_ctc 125.220154 loss_rnnt 91.083099 hw_loss 0.740302 lr 0.00054484 rank 4
2023-02-11 03:33:14,198 DEBUG TRAIN Batch 1/5400 loss 89.085564 loss_att 118.315468 loss_ctc 115.165489 loss_rnnt 76.265259 hw_loss 0.655688 lr 0.00054976 rank 5
2023-02-11 03:33:14,199 DEBUG TRAIN Batch 1/5400 loss 57.558868 loss_att 83.349907 loss_ctc 87.236572 loss_rnnt 45.917503 hw_loss 0.473650 lr 0.00054972 rank 6
2023-02-11 03:33:14,202 DEBUG TRAIN Batch 1/5400 loss 43.568787 loss_att 83.419632 loss_ctc 58.009323 loss_rnnt 31.185392 hw_loss 0.466467 lr 0.00054956 rank 7
2023-02-11 03:33:14,202 DEBUG TRAIN Batch 1/5400 loss 33.044426 loss_att 60.082447 loss_ctc 41.134445 loss_rnnt 22.193695 hw_loss 0.818336 lr 0.00054936 rank 3
2023-02-11 03:33:14,203 DEBUG TRAIN Batch 1/5400 loss 39.062889 loss_att 61.383022 loss_ctc 49.066532 loss_rnnt 28.790157 hw_loss 0.839041 lr 0.00054968 rank 2
2023-02-11 03:33:14,208 DEBUG TRAIN Batch 1/5400 loss 33.351349 loss_att 49.381424 loss_ctc 32.357071 loss_rnnt 26.445944 hw_loss 0.718493 lr 0.00054984 rank 0
2023-02-11 03:33:14,208 DEBUG TRAIN Batch 1/5400 loss 56.947536 loss_att 86.362015 loss_ctc 75.843079 loss_rnnt 45.842247 hw_loss 0.506810 lr 0.00055100 rank 1
2023-02-11 03:33:14,208 DEBUG TRAIN Batch 1/5400 loss 59.117016 loss_att 93.601669 loss_ctc 74.164886 loss_rnnt 47.161949 hw_loss 0.572203 lr 0.00054884 rank 4
2023-02-11 03:34:30,241 DEBUG TRAIN Batch 1/5500 loss 37.466591 loss_att 46.033318 loss_ctc 44.111397 loss_rnnt 28.140667 hw_loss 1.261238 lr 0.00055384 rank 0
2023-02-11 03:34:30,242 DEBUG TRAIN Batch 1/5500 loss 69.827393 loss_att 89.185165 loss_ctc 87.883469 loss_rnnt 61.539825 hw_loss 0.376601 lr 0.00055372 rank 6
2023-02-11 03:34:30,245 DEBUG TRAIN Batch 1/5500 loss 51.139332 loss_att 80.024239 loss_ctc 67.202515 loss_rnnt 38.700500 hw_loss 0.847517 lr 0.00055356 rank 7
2023-02-11 03:34:30,250 DEBUG TRAIN Batch 1/5500 loss 39.921143 loss_att 61.417458 loss_ctc 48.565208 loss_rnnt 31.807911 hw_loss 0.499016 lr 0.00055368 rank 2
2023-02-11 03:34:30,249 DEBUG TRAIN Batch 1/5500 loss 35.849461 loss_att 65.172211 loss_ctc 46.425896 loss_rnnt 24.575806 hw_loss 0.749796 lr 0.00055376 rank 5
2023-02-11 03:34:30,252 DEBUG TRAIN Batch 1/5500 loss 24.425705 loss_att 38.455734 loss_ctc 28.720900 loss_rnnt 17.490044 hw_loss 0.666930 lr 0.00055284 rank 4
2023-02-11 03:34:30,252 DEBUG TRAIN Batch 1/5500 loss 52.873154 loss_att 79.834564 loss_ctc 68.360703 loss_rnnt 44.121834 hw_loss 0.242630 lr 0.00055500 rank 1
2023-02-11 03:34:30,254 DEBUG TRAIN Batch 1/5500 loss 49.796101 loss_att 72.757812 loss_ctc 64.965981 loss_rnnt 41.068996 hw_loss 0.396021 lr 0.00055336 rank 3
2023-02-11 03:35:45,906 DEBUG TRAIN Batch 1/5600 loss 39.090313 loss_att 62.442085 loss_ctc 49.097324 loss_rnnt 31.236422 hw_loss 0.346738 lr 0.00055736 rank 3
2023-02-11 03:35:45,905 DEBUG TRAIN Batch 1/5600 loss 40.075043 loss_att 53.775940 loss_ctc 50.462124 loss_rnnt 31.088905 hw_loss 0.911440 lr 0.00055772 rank 6
2023-02-11 03:35:45,907 DEBUG TRAIN Batch 1/5600 loss 50.660412 loss_att 61.474010 loss_ctc 67.379517 loss_rnnt 42.019577 hw_loss 0.796668 lr 0.00055784 rank 0
2023-02-11 03:35:45,908 DEBUG TRAIN Batch 1/5600 loss 33.324780 loss_att 52.404354 loss_ctc 41.682674 loss_rnnt 25.436102 hw_loss 0.554695 lr 0.00055768 rank 2
2023-02-11 03:35:45,910 DEBUG TRAIN Batch 1/5600 loss 45.061386 loss_att 66.863121 loss_ctc 58.715214 loss_rnnt 36.355125 hw_loss 0.473513 lr 0.00055684 rank 4
2023-02-11 03:35:45,912 DEBUG TRAIN Batch 1/5600 loss 57.585461 loss_att 80.617691 loss_ctc 74.057266 loss_rnnt 48.506809 hw_loss 0.426743 lr 0.00055756 rank 7
2023-02-11 03:35:45,914 DEBUG TRAIN Batch 1/5600 loss 50.412598 loss_att 82.520287 loss_ctc 73.400528 loss_rnnt 38.498638 hw_loss 0.455131 lr 0.00055776 rank 5
2023-02-11 03:35:45,914 DEBUG TRAIN Batch 1/5600 loss 42.302513 loss_att 66.046425 loss_ctc 60.859940 loss_rnnt 31.995565 hw_loss 0.578220 lr 0.00055900 rank 1
2023-02-11 03:37:04,509 DEBUG TRAIN Batch 1/5700 loss 38.603737 loss_att 52.321346 loss_ctc 52.210110 loss_rnnt 31.489582 hw_loss 0.479334 lr 0.00056136 rank 3
2023-02-11 03:37:04,511 DEBUG TRAIN Batch 1/5700 loss 73.845024 loss_att 106.986176 loss_ctc 103.518394 loss_rnnt 61.268219 hw_loss 0.373522 lr 0.00056172 rank 6
2023-02-11 03:37:04,512 DEBUG TRAIN Batch 1/5700 loss 52.905777 loss_att 66.265343 loss_ctc 64.440430 loss_rnnt 44.501774 hw_loss 0.786400 lr 0.00056156 rank 7
2023-02-11 03:37:04,513 DEBUG TRAIN Batch 1/5700 loss 34.374187 loss_att 48.327721 loss_ctc 46.513069 loss_rnnt 27.280817 hw_loss 0.503278 lr 0.00056300 rank 1
2023-02-11 03:37:04,515 DEBUG TRAIN Batch 1/5700 loss 51.604736 loss_att 67.657898 loss_ctc 67.086853 loss_rnnt 42.126404 hw_loss 0.788140 lr 0.00056176 rank 5
2023-02-11 03:37:04,516 DEBUG TRAIN Batch 1/5700 loss 58.587067 loss_att 99.705444 loss_ctc 76.972198 loss_rnnt 46.134960 hw_loss 0.333203 lr 0.00056184 rank 0
2023-02-11 03:37:04,518 DEBUG TRAIN Batch 1/5700 loss 41.206406 loss_att 68.238480 loss_ctc 47.424313 loss_rnnt 32.385895 hw_loss 0.484695 lr 0.00056168 rank 2
2023-02-11 03:37:04,521 DEBUG TRAIN Batch 1/5700 loss 45.235397 loss_att 62.019943 loss_ctc 48.475842 loss_rnnt 37.876827 hw_loss 0.669300 lr 0.00056084 rank 4
2023-02-11 03:38:19,257 DEBUG TRAIN Batch 1/5800 loss 29.052849 loss_att 39.269722 loss_ctc 35.882866 loss_rnnt 22.317930 hw_loss 0.708914 lr 0.00056584 rank 0
2023-02-11 03:38:19,258 DEBUG TRAIN Batch 1/5800 loss 38.742657 loss_att 65.981354 loss_ctc 50.268341 loss_rnnt 29.001953 hw_loss 0.516788 lr 0.00056536 rank 3
2023-02-11 03:38:19,262 DEBUG TRAIN Batch 1/5800 loss 31.170567 loss_att 59.358990 loss_ctc 42.439587 loss_rnnt 20.426441 hw_loss 0.675732 lr 0.00056484 rank 4
2023-02-11 03:38:19,265 DEBUG TRAIN Batch 1/5800 loss 47.888237 loss_att 68.971962 loss_ctc 59.504417 loss_rnnt 38.381050 hw_loss 0.701553 lr 0.00056568 rank 2
2023-02-11 03:38:19,266 DEBUG TRAIN Batch 1/5800 loss 25.797518 loss_att 31.525660 loss_ctc 27.076069 loss_rnnt 16.886499 hw_loss 1.424047 lr 0.00056700 rank 1
2023-02-11 03:38:19,266 DEBUG TRAIN Batch 1/5800 loss 46.268532 loss_att 64.230614 loss_ctc 60.096203 loss_rnnt 37.941490 hw_loss 0.542051 lr 0.00056572 rank 6
2023-02-11 03:38:19,267 DEBUG TRAIN Batch 1/5800 loss 20.538786 loss_att 22.241743 loss_ctc 18.396168 loss_rnnt 12.762811 hw_loss 1.447700 lr 0.00056576 rank 5
2023-02-11 03:38:19,267 DEBUG TRAIN Batch 1/5800 loss 57.713951 loss_att 90.434059 loss_ctc 67.885712 loss_rnnt 49.047386 hw_loss 0.143684 lr 0.00056556 rank 7
2023-02-11 03:39:36,460 DEBUG TRAIN Batch 1/5900 loss 44.308605 loss_att 65.453201 loss_ctc 55.790031 loss_rnnt 37.341274 hw_loss 0.226416 lr 0.00056984 rank 0
2023-02-11 03:39:36,461 DEBUG TRAIN Batch 1/5900 loss 36.733719 loss_att 62.253059 loss_ctc 48.882168 loss_rnnt 28.308722 hw_loss 0.319000 lr 0.00056936 rank 3
2023-02-11 03:39:36,469 DEBUG TRAIN Batch 1/5900 loss 77.965897 loss_att 99.475006 loss_ctc 95.228783 loss_rnnt 67.970154 hw_loss 0.636039 lr 0.00056968 rank 2
2023-02-11 03:39:36,470 DEBUG TRAIN Batch 1/5900 loss 55.061325 loss_att 78.554680 loss_ctc 72.636673 loss_rnnt 46.010326 hw_loss 0.376677 lr 0.00057100 rank 1
2023-02-11 03:39:36,470 DEBUG TRAIN Batch 1/5900 loss 73.529282 loss_att 102.484505 loss_ctc 91.754456 loss_rnnt 61.107845 hw_loss 0.787570 lr 0.00056956 rank 7
2023-02-11 03:39:36,471 DEBUG TRAIN Batch 1/5900 loss 38.796524 loss_att 64.181030 loss_ctc 58.625137 loss_rnnt 29.006897 hw_loss 0.387920 lr 0.00056884 rank 4
2023-02-11 03:39:36,475 DEBUG TRAIN Batch 1/5900 loss 53.711014 loss_att 88.938881 loss_ctc 64.756210 loss_rnnt 42.530838 hw_loss 0.499108 lr 0.00056976 rank 5
2023-02-11 03:39:36,517 DEBUG TRAIN Batch 1/5900 loss 37.402908 loss_att 53.878593 loss_ctc 46.771271 loss_rnnt 28.928846 hw_loss 0.736840 lr 0.00056972 rank 6
2023-02-11 03:40:55,010 DEBUG TRAIN Batch 1/6000 loss 37.300709 loss_att 61.755127 loss_ctc 57.800690 loss_rnnt 25.147747 hw_loss 0.849140 lr 0.00057336 rank 3
2023-02-11 03:40:55,013 DEBUG TRAIN Batch 1/6000 loss 63.867188 loss_att 90.819290 loss_ctc 87.776283 loss_rnnt 53.158134 hw_loss 0.399516 lr 0.00057384 rank 0
2023-02-11 03:40:55,017 DEBUG TRAIN Batch 1/6000 loss 32.538265 loss_att 53.852547 loss_ctc 39.862862 loss_rnnt 25.266485 hw_loss 0.381058 lr 0.00057356 rank 7
2023-02-11 03:40:55,020 DEBUG TRAIN Batch 1/6000 loss 56.475727 loss_att 73.694542 loss_ctc 77.661942 loss_rnnt 44.744492 hw_loss 1.024245 lr 0.00057372 rank 6
2023-02-11 03:40:55,021 DEBUG TRAIN Batch 1/6000 loss 64.034027 loss_att 86.059036 loss_ctc 77.881218 loss_rnnt 55.497070 hw_loss 0.428562 lr 0.00057284 rank 4
2023-02-11 03:40:55,021 DEBUG TRAIN Batch 1/6000 loss 46.533958 loss_att 76.514603 loss_ctc 60.464897 loss_rnnt 37.556232 hw_loss 0.210775 lr 0.00057376 rank 5
2023-02-11 03:40:55,021 DEBUG TRAIN Batch 1/6000 loss 66.821716 loss_att 92.121628 loss_ctc 91.745972 loss_rnnt 56.080254 hw_loss 0.442170 lr 0.00057368 rank 2
2023-02-11 03:40:55,063 DEBUG TRAIN Batch 1/6000 loss 33.884312 loss_att 53.155701 loss_ctc 41.972305 loss_rnnt 24.553410 hw_loss 0.824667 lr 0.00057500 rank 1
2023-02-11 03:42:11,713 DEBUG TRAIN Batch 1/6100 loss 52.415909 loss_att 86.790855 loss_ctc 71.011406 loss_rnnt 41.089165 hw_loss 0.369816 lr 0.00057900 rank 1
2023-02-11 03:42:11,713 DEBUG TRAIN Batch 1/6100 loss 50.199036 loss_att 74.685303 loss_ctc 66.273521 loss_rnnt 40.702324 hw_loss 0.460536 lr 0.00057776 rank 5
2023-02-11 03:42:11,714 DEBUG TRAIN Batch 1/6100 loss 55.232395 loss_att 75.316193 loss_ctc 68.645721 loss_rnnt 47.170074 hw_loss 0.423210 lr 0.00057684 rank 4
2023-02-11 03:42:11,714 DEBUG TRAIN Batch 1/6100 loss 40.069759 loss_att 61.764961 loss_ctc 53.634487 loss_rnnt 30.649033 hw_loss 0.613698 lr 0.00057784 rank 0
2023-02-11 03:42:11,715 DEBUG TRAIN Batch 1/6100 loss 60.744144 loss_att 83.777588 loss_ctc 75.418747 loss_rnnt 49.534370 hw_loss 0.871213 lr 0.00057736 rank 3
2023-02-11 03:42:11,719 DEBUG TRAIN Batch 1/6100 loss 55.199459 loss_att 80.299286 loss_ctc 76.849754 loss_rnnt 41.633759 hw_loss 1.061068 lr 0.00057756 rank 7
2023-02-11 03:42:11,719 DEBUG TRAIN Batch 1/6100 loss 41.427269 loss_att 58.762272 loss_ctc 54.477814 loss_rnnt 33.079918 hw_loss 0.588801 lr 0.00057768 rank 2
2023-02-11 03:42:11,720 DEBUG TRAIN Batch 1/6100 loss 45.480320 loss_att 68.056465 loss_ctc 62.363304 loss_rnnt 35.972244 hw_loss 0.514084 lr 0.00057772 rank 6
2023-02-11 03:43:26,939 DEBUG TRAIN Batch 1/6200 loss 42.714691 loss_att 62.690189 loss_ctc 61.708012 loss_rnnt 35.341591 hw_loss 0.158541 lr 0.00058136 rank 3
2023-02-11 03:43:26,943 DEBUG TRAIN Batch 1/6200 loss 50.577427 loss_att 74.240791 loss_ctc 65.370483 loss_rnnt 38.726517 hw_loss 0.964843 lr 0.00058184 rank 0
2023-02-11 03:43:26,948 DEBUG TRAIN Batch 1/6200 loss 41.883938 loss_att 64.195435 loss_ctc 66.474022 loss_rnnt 31.616604 hw_loss 0.473692 lr 0.00058156 rank 7
2023-02-11 03:43:26,949 DEBUG TRAIN Batch 1/6200 loss 41.358662 loss_att 58.062248 loss_ctc 50.945774 loss_rnnt 32.946796 hw_loss 0.711162 lr 0.00058084 rank 4
2023-02-11 03:43:26,950 DEBUG TRAIN Batch 1/6200 loss 44.355049 loss_att 69.468163 loss_ctc 58.238750 loss_rnnt 34.824867 hw_loss 0.498074 lr 0.00058300 rank 1
2023-02-11 03:43:26,950 DEBUG TRAIN Batch 1/6200 loss 41.903950 loss_att 64.287033 loss_ctc 59.647724 loss_rnnt 32.190109 hw_loss 0.538385 lr 0.00058176 rank 5
2023-02-11 03:43:26,951 DEBUG TRAIN Batch 1/6200 loss 30.223612 loss_att 43.728378 loss_ctc 36.170746 loss_rnnt 21.566038 hw_loss 0.968188 lr 0.00058168 rank 2
2023-02-11 03:43:26,953 DEBUG TRAIN Batch 1/6200 loss 36.705143 loss_att 49.820122 loss_ctc 47.005108 loss_rnnt 27.164602 hw_loss 1.039540 lr 0.00058172 rank 6
2023-02-11 03:44:42,858 DEBUG TRAIN Batch 1/6300 loss 31.837160 loss_att 39.783321 loss_ctc 38.903358 loss_rnnt 27.324482 hw_loss 0.371491 lr 0.00058584 rank 0
2023-02-11 03:44:42,860 DEBUG TRAIN Batch 1/6300 loss 56.921761 loss_att 80.083244 loss_ctc 67.461555 loss_rnnt 45.609570 hw_loss 0.988985 lr 0.00058576 rank 5
2023-02-11 03:44:42,861 DEBUG TRAIN Batch 1/6300 loss 48.244160 loss_att 63.474552 loss_ctc 59.390114 loss_rnnt 40.899792 hw_loss 0.527281 lr 0.00058536 rank 3
2023-02-11 03:44:42,860 DEBUG TRAIN Batch 1/6300 loss 56.307209 loss_att 68.457748 loss_ctc 67.712303 loss_rnnt 49.161148 hw_loss 0.599114 lr 0.00058700 rank 1
2023-02-11 03:44:42,861 DEBUG TRAIN Batch 1/6300 loss 40.271584 loss_att 54.433502 loss_ctc 52.909973 loss_rnnt 31.957518 hw_loss 0.711855 lr 0.00058556 rank 7
2023-02-11 03:44:42,864 DEBUG TRAIN Batch 1/6300 loss 80.177811 loss_att 117.105316 loss_ctc 109.396408 loss_rnnt 65.844749 hw_loss 0.572203 lr 0.00058572 rank 6
2023-02-11 03:44:42,870 DEBUG TRAIN Batch 1/6300 loss 55.891197 loss_att 67.364151 loss_ctc 72.596565 loss_rnnt 48.944511 hw_loss 0.454634 lr 0.00058484 rank 4
2023-02-11 03:44:42,911 DEBUG TRAIN Batch 1/6300 loss 24.636757 loss_att 28.777020 loss_ctc 31.273808 loss_rnnt 18.740931 hw_loss 0.784281 lr 0.00058568 rank 2
2023-02-11 03:46:02,697 DEBUG TRAIN Batch 1/6400 loss 41.517056 loss_att 77.077057 loss_ctc 51.507675 loss_rnnt 31.020458 hw_loss 0.384847 lr 0.00058936 rank 3
2023-02-11 03:46:02,701 DEBUG TRAIN Batch 1/6400 loss 46.643044 loss_att 69.291885 loss_ctc 65.758423 loss_rnnt 38.520256 hw_loss 0.195807 lr 0.00058972 rank 6
2023-02-11 03:46:02,703 DEBUG TRAIN Batch 1/6400 loss 23.998016 loss_att 24.347256 loss_ctc 26.341137 loss_rnnt 18.847084 hw_loss 0.894125 lr 0.00058976 rank 5
2023-02-11 03:46:02,704 DEBUG TRAIN Batch 1/6400 loss 38.287395 loss_att 53.573883 loss_ctc 53.329945 loss_rnnt 30.286959 hw_loss 0.550775 lr 0.00058956 rank 7
2023-02-11 03:46:02,709 DEBUG TRAIN Batch 1/6400 loss 41.388985 loss_att 59.683022 loss_ctc 62.989025 loss_rnnt 30.572186 hw_loss 0.802122 lr 0.00058968 rank 2
2023-02-11 03:46:02,710 DEBUG TRAIN Batch 1/6400 loss 42.099091 loss_att 70.576508 loss_ctc 57.696861 loss_rnnt 31.616146 hw_loss 0.507705 lr 0.00058984 rank 0
2023-02-11 03:46:02,712 DEBUG TRAIN Batch 1/6400 loss 42.961315 loss_att 47.588207 loss_ctc 50.952881 loss_rnnt 36.873650 hw_loss 0.768140 lr 0.00059100 rank 1
2023-02-11 03:46:02,758 DEBUG TRAIN Batch 1/6400 loss 37.205231 loss_att 58.994400 loss_ctc 54.910912 loss_rnnt 26.652960 hw_loss 0.718815 lr 0.00058884 rank 4
2023-02-11 03:47:18,018 DEBUG TRAIN Batch 1/6500 loss 58.658154 loss_att 88.544724 loss_ctc 79.030518 loss_rnnt 48.137146 hw_loss 0.342633 lr 0.00059336 rank 3
2023-02-11 03:47:18,022 DEBUG TRAIN Batch 1/6500 loss 72.028671 loss_att 103.038300 loss_ctc 93.260315 loss_rnnt 60.185589 hw_loss 0.526926 lr 0.00059284 rank 4
2023-02-11 03:47:18,024 DEBUG TRAIN Batch 1/6500 loss 57.475555 loss_att 93.963501 loss_ctc 83.658585 loss_rnnt 44.445007 hw_loss 0.420354 lr 0.00059368 rank 2
2023-02-11 03:47:18,025 DEBUG TRAIN Batch 1/6500 loss 36.165222 loss_att 56.082169 loss_ctc 52.807861 loss_rnnt 26.533794 hw_loss 0.642941 lr 0.00059356 rank 7
2023-02-11 03:47:18,025 DEBUG TRAIN Batch 1/6500 loss 44.374443 loss_att 72.656586 loss_ctc 63.092476 loss_rnnt 33.925236 hw_loss 0.430694 lr 0.00059372 rank 6
2023-02-11 03:47:18,027 DEBUG TRAIN Batch 1/6500 loss 32.246574 loss_att 54.042480 loss_ctc 45.564373 loss_rnnt 23.888474 hw_loss 0.416852 lr 0.00059500 rank 1
2023-02-11 03:47:18,028 DEBUG TRAIN Batch 1/6500 loss 42.850819 loss_att 68.200310 loss_ctc 63.036598 loss_rnnt 33.337456 hw_loss 0.328505 lr 0.00059384 rank 0
2023-02-11 03:47:18,033 DEBUG TRAIN Batch 1/6500 loss 47.317642 loss_att 74.485001 loss_ctc 67.511429 loss_rnnt 36.969078 hw_loss 0.416735 lr 0.00059376 rank 5
2023-02-11 03:48:33,274 DEBUG TRAIN Batch 1/6600 loss 35.297802 loss_att 56.300797 loss_ctc 48.949890 loss_rnnt 25.982225 hw_loss 0.617756 lr 0.00059772 rank 6
2023-02-11 03:48:33,275 DEBUG TRAIN Batch 1/6600 loss 33.174107 loss_att 53.026894 loss_ctc 42.896770 loss_rnnt 26.418766 hw_loss 0.279080 lr 0.00059756 rank 7
2023-02-11 03:48:33,275 DEBUG TRAIN Batch 1/6600 loss 63.684814 loss_att 84.479996 loss_ctc 84.720856 loss_rnnt 54.663189 hw_loss 0.385835 lr 0.00059776 rank 5
2023-02-11 03:48:33,276 DEBUG TRAIN Batch 1/6600 loss 42.524002 loss_att 58.293751 loss_ctc 60.624649 loss_rnnt 33.895000 hw_loss 0.574055 lr 0.00059900 rank 1
2023-02-11 03:48:33,276 DEBUG TRAIN Batch 1/6600 loss 47.503059 loss_att 66.411728 loss_ctc 65.457870 loss_rnnt 38.564064 hw_loss 0.518116 lr 0.00059784 rank 0
2023-02-11 03:48:33,277 DEBUG TRAIN Batch 1/6600 loss 42.938400 loss_att 66.327354 loss_ctc 62.346371 loss_rnnt 34.537548 hw_loss 0.212874 lr 0.00059736 rank 3
2023-02-11 03:48:33,281 DEBUG TRAIN Batch 1/6600 loss 56.892475 loss_att 93.010071 loss_ctc 76.203720 loss_rnnt 46.198593 hw_loss 0.167911 lr 0.00059768 rank 2
2023-02-11 03:48:33,281 DEBUG TRAIN Batch 1/6600 loss 33.491802 loss_att 45.087502 loss_ctc 42.361221 loss_rnnt 26.315292 hw_loss 0.689021 lr 0.00059684 rank 4
2023-02-11 03:49:51,023 DEBUG TRAIN Batch 1/6700 loss 35.063618 loss_att 53.564697 loss_ctc 51.808502 loss_rnnt 26.571758 hw_loss 0.479811 lr 0.00060184 rank 0
2023-02-11 03:49:51,026 DEBUG TRAIN Batch 1/6700 loss 40.681118 loss_att 60.890629 loss_ctc 50.854942 loss_rnnt 33.183922 hw_loss 0.393521 lr 0.00060168 rank 2
2023-02-11 03:49:51,027 DEBUG TRAIN Batch 1/6700 loss 34.470894 loss_att 56.914215 loss_ctc 42.063042 loss_rnnt 25.984436 hw_loss 0.559782 lr 0.00060300 rank 1
2023-02-11 03:49:51,028 DEBUG TRAIN Batch 1/6700 loss 52.088249 loss_att 67.924164 loss_ctc 61.075394 loss_rnnt 43.558914 hw_loss 0.780724 lr 0.00060172 rank 6
2023-02-11 03:49:51,030 DEBUG TRAIN Batch 1/6700 loss 38.523643 loss_att 62.048103 loss_ctc 52.535103 loss_rnnt 29.666126 hw_loss 0.428330 lr 0.00060156 rank 7
2023-02-11 03:49:51,030 DEBUG TRAIN Batch 1/6700 loss 49.590870 loss_att 69.533875 loss_ctc 67.911919 loss_rnnt 40.050430 hw_loss 0.582944 lr 0.00060136 rank 3
2023-02-11 03:49:51,036 DEBUG TRAIN Batch 1/6700 loss 34.644188 loss_att 55.026855 loss_ctc 44.112621 loss_rnnt 26.749447 hw_loss 0.479203 lr 0.00060176 rank 5
2023-02-11 03:49:51,049 DEBUG TRAIN Batch 1/6700 loss 48.740749 loss_att 75.390396 loss_ctc 61.634674 loss_rnnt 38.500107 hw_loss 0.598411 lr 0.00060084 rank 4
2023-02-11 03:51:09,035 DEBUG TRAIN Batch 1/6800 loss 60.450909 loss_att 72.571915 loss_ctc 76.313820 loss_rnnt 52.937298 hw_loss 0.557692 lr 0.00060584 rank 0
2023-02-11 03:51:09,038 DEBUG TRAIN Batch 1/6800 loss 34.935619 loss_att 51.192703 loss_ctc 45.690990 loss_rnnt 27.354406 hw_loss 0.542953 lr 0.00060572 rank 6
2023-02-11 03:51:09,038 DEBUG TRAIN Batch 1/6800 loss 52.816853 loss_att 70.047783 loss_ctc 65.815201 loss_rnnt 44.995441 hw_loss 0.495396 lr 0.00060700 rank 1
2023-02-11 03:51:09,039 DEBUG TRAIN Batch 1/6800 loss 35.108089 loss_att 51.018742 loss_ctc 42.657089 loss_rnnt 29.576763 hw_loss 0.251749 lr 0.00060536 rank 3
2023-02-11 03:51:09,039 DEBUG TRAIN Batch 1/6800 loss 39.657089 loss_att 63.359341 loss_ctc 55.932343 loss_rnnt 30.310417 hw_loss 0.456785 lr 0.00060556 rank 7
2023-02-11 03:51:09,040 DEBUG TRAIN Batch 1/6800 loss 45.142399 loss_att 70.796211 loss_ctc 57.358665 loss_rnnt 36.052948 hw_loss 0.436846 lr 0.00060568 rank 2
2023-02-11 03:51:09,041 DEBUG TRAIN Batch 1/6800 loss 42.773960 loss_att 55.586803 loss_ctc 58.774216 loss_rnnt 34.999695 hw_loss 0.577187 lr 0.00060576 rank 5
2023-02-11 03:51:09,046 DEBUG TRAIN Batch 1/6800 loss 57.138454 loss_att 73.304581 loss_ctc 69.195343 loss_rnnt 49.474266 hw_loss 0.529384 lr 0.00060484 rank 4
2023-02-11 03:52:24,128 DEBUG TRAIN Batch 1/6900 loss 40.839092 loss_att 56.301971 loss_ctc 49.209538 loss_rnnt 34.035725 hw_loss 0.486513 lr 0.00060936 rank 3
2023-02-11 03:52:24,129 DEBUG TRAIN Batch 1/6900 loss 30.848894 loss_att 50.086819 loss_ctc 36.727837 loss_rnnt 22.926146 hw_loss 0.617120 lr 0.00060956 rank 7
2023-02-11 03:52:24,130 DEBUG TRAIN Batch 1/6900 loss 56.973442 loss_att 76.769699 loss_ctc 69.877602 loss_rnnt 48.719284 hw_loss 0.482691 lr 0.00061100 rank 1
2023-02-11 03:52:24,131 DEBUG TRAIN Batch 1/6900 loss 47.536545 loss_att 61.013367 loss_ctc 64.608421 loss_rnnt 41.149063 hw_loss 0.265475 lr 0.00060884 rank 4
2023-02-11 03:52:24,134 DEBUG TRAIN Batch 1/6900 loss 44.891022 loss_att 58.030159 loss_ctc 53.309917 loss_rnnt 37.564449 hw_loss 0.670543 lr 0.00060968 rank 2
2023-02-11 03:52:24,137 DEBUG TRAIN Batch 1/6900 loss 49.695908 loss_att 72.959930 loss_ctc 64.920364 loss_rnnt 42.391029 hw_loss 0.116653 lr 0.00060972 rank 6
2023-02-11 03:52:24,137 DEBUG TRAIN Batch 1/6900 loss 40.966187 loss_att 60.353340 loss_ctc 53.027454 loss_rnnt 32.820065 hw_loss 0.498848 lr 0.00060976 rank 5
2023-02-11 03:52:24,140 DEBUG TRAIN Batch 1/6900 loss 39.926273 loss_att 42.704952 loss_ctc 48.862675 loss_rnnt 34.114208 hw_loss 0.762152 lr 0.00060984 rank 0
2023-02-11 03:53:41,354 DEBUG TRAIN Batch 1/7000 loss 45.103333 loss_att 52.225174 loss_ctc 53.166992 loss_rnnt 37.017433 hw_loss 1.047445 lr 0.00061356 rank 7
2023-02-11 03:53:41,355 DEBUG TRAIN Batch 1/7000 loss 41.236298 loss_att 69.435204 loss_ctc 59.592995 loss_rnnt 31.092451 hw_loss 0.385595 lr 0.00061384 rank 0
2023-02-11 03:53:41,354 DEBUG TRAIN Batch 1/7000 loss 76.711342 loss_att 108.526505 loss_ctc 95.776878 loss_rnnt 66.094131 hw_loss 0.321020 lr 0.00061372 rank 6
2023-02-11 03:53:41,355 DEBUG TRAIN Batch 1/7000 loss 29.191547 loss_att 31.902401 loss_ctc 34.370354 loss_rnnt 21.306793 hw_loss 1.247265 lr 0.00061376 rank 5
2023-02-11 03:53:41,355 DEBUG TRAIN Batch 1/7000 loss 28.468092 loss_att 27.945374 loss_ctc 30.339352 loss_rnnt 21.856441 hw_loss 1.212505 lr 0.00061336 rank 3
2023-02-11 03:53:41,360 DEBUG TRAIN Batch 1/7000 loss 26.246851 loss_att 45.262280 loss_ctc 36.399513 loss_rnnt 18.540154 hw_loss 0.478110 lr 0.00061368 rank 2
2023-02-11 03:53:41,361 DEBUG TRAIN Batch 1/7000 loss 18.980705 loss_att 25.922695 loss_ctc 24.746288 loss_rnnt 14.319973 hw_loss 0.469423 lr 0.00061284 rank 4
2023-02-11 03:53:41,362 DEBUG TRAIN Batch 1/7000 loss 29.297405 loss_att 33.028114 loss_ctc 36.812347 loss_rnnt 24.005749 hw_loss 0.664410 lr 0.00061500 rank 1
2023-02-11 03:55:01,639 DEBUG TRAIN Batch 1/7100 loss 51.672997 loss_att 79.253265 loss_ctc 74.281021 loss_rnnt 39.948330 hw_loss 0.598915 lr 0.00061768 rank 2
2023-02-11 03:55:01,640 DEBUG TRAIN Batch 1/7100 loss 58.976189 loss_att 92.994659 loss_ctc 83.051208 loss_rnnt 46.234245 hw_loss 0.511547 lr 0.00061736 rank 3
2023-02-11 03:55:01,645 DEBUG TRAIN Batch 1/7100 loss 41.488510 loss_att 64.476402 loss_ctc 52.122566 loss_rnnt 34.087517 hw_loss 0.259789 lr 0.00061776 rank 5
2023-02-11 03:55:01,646 DEBUG TRAIN Batch 1/7100 loss 50.405849 loss_att 66.800644 loss_ctc 66.292847 loss_rnnt 43.344376 hw_loss 0.312047 lr 0.00061784 rank 0
2023-02-11 03:55:01,646 DEBUG TRAIN Batch 1/7100 loss 30.334259 loss_att 32.960869 loss_ctc 33.664215 loss_rnnt 23.237402 hw_loss 1.148914 lr 0.00061756 rank 7
2023-02-11 03:55:01,647 DEBUG TRAIN Batch 1/7100 loss 55.282047 loss_att 74.041206 loss_ctc 69.539177 loss_rnnt 45.974266 hw_loss 0.685313 lr 0.00061900 rank 1
2023-02-11 03:55:01,649 DEBUG TRAIN Batch 1/7100 loss 43.089645 loss_att 61.256390 loss_ctc 63.823372 loss_rnnt 33.652340 hw_loss 0.569899 lr 0.00061772 rank 6
2023-02-11 03:55:01,657 DEBUG TRAIN Batch 1/7100 loss 61.763096 loss_att 83.759407 loss_ctc 84.608681 loss_rnnt 53.521698 hw_loss 0.149261 lr 0.00061684 rank 4
2023-02-11 03:56:17,350 DEBUG TRAIN Batch 1/7200 loss 65.489853 loss_att 99.021042 loss_ctc 92.905228 loss_rnnt 53.164135 hw_loss 0.368267 lr 0.00062136 rank 3
2023-02-11 03:56:17,351 DEBUG TRAIN Batch 1/7200 loss 50.444782 loss_att 69.840958 loss_ctc 60.004189 loss_rnnt 38.599731 hw_loss 1.254606 lr 0.00062184 rank 0
2023-02-11 03:56:17,357 DEBUG TRAIN Batch 1/7200 loss 46.884235 loss_att 70.073654 loss_ctc 61.155632 loss_rnnt 38.217609 hw_loss 0.398604 lr 0.00062156 rank 7
2023-02-11 03:56:17,357 DEBUG TRAIN Batch 1/7200 loss 25.864603 loss_att 42.338211 loss_ctc 32.319229 loss_rnnt 18.005798 hw_loss 0.694400 lr 0.00062168 rank 2
2023-02-11 03:56:17,358 DEBUG TRAIN Batch 1/7200 loss 62.221931 loss_att 86.307922 loss_ctc 78.273239 loss_rnnt 51.840454 hw_loss 0.642019 lr 0.00062300 rank 1
2023-02-11 03:56:17,358 DEBUG TRAIN Batch 1/7200 loss 54.834496 loss_att 75.786766 loss_ctc 74.957947 loss_rnnt 45.461670 hw_loss 0.468608 lr 0.00062176 rank 5
2023-02-11 03:56:17,361 DEBUG TRAIN Batch 1/7200 loss 58.497433 loss_att 77.672981 loss_ctc 68.782776 loss_rnnt 50.615265 hw_loss 0.501689 lr 0.00062172 rank 6
2023-02-11 03:56:17,362 DEBUG TRAIN Batch 1/7200 loss 41.063889 loss_att 63.060791 loss_ctc 52.885658 loss_rnnt 32.366817 hw_loss 0.510273 lr 0.00062084 rank 4
2023-02-11 03:57:33,136 DEBUG TRAIN Batch 1/7300 loss 50.422832 loss_att 69.168190 loss_ctc 68.984421 loss_rnnt 41.455109 hw_loss 0.514458 lr 0.00062568 rank 2
2023-02-11 03:57:33,139 DEBUG TRAIN Batch 1/7300 loss 53.632298 loss_att 80.717163 loss_ctc 67.642494 loss_rnnt 44.000534 hw_loss 0.440018 lr 0.00062584 rank 0
2023-02-11 03:57:33,141 DEBUG TRAIN Batch 1/7300 loss 37.491890 loss_att 60.144077 loss_ctc 56.936852 loss_rnnt 28.745420 hw_loss 0.304382 lr 0.00062536 rank 3
2023-02-11 03:57:33,143 DEBUG TRAIN Batch 1/7300 loss 56.490089 loss_att 77.003059 loss_ctc 77.724419 loss_rnnt 45.760689 hw_loss 0.711668 lr 0.00062484 rank 4
2023-02-11 03:57:33,143 DEBUG TRAIN Batch 1/7300 loss 39.159054 loss_att 53.199436 loss_ctc 56.540718 loss_rnnt 30.475773 hw_loss 0.667059 lr 0.00062576 rank 5
2023-02-11 03:57:33,146 DEBUG TRAIN Batch 1/7300 loss 61.302181 loss_att 88.456551 loss_ctc 77.105751 loss_rnnt 51.678886 hw_loss 0.390990 lr 0.00062700 rank 1
2023-02-11 03:57:33,147 DEBUG TRAIN Batch 1/7300 loss 48.536270 loss_att 69.799850 loss_ctc 72.182732 loss_rnnt 36.041451 hw_loss 0.954233 lr 0.00062556 rank 7
2023-02-11 03:57:33,150 DEBUG TRAIN Batch 1/7300 loss 55.515358 loss_att 76.272324 loss_ctc 76.518326 loss_rnnt 46.112793 hw_loss 0.459520 lr 0.00062572 rank 6
2023-02-11 03:58:49,192 DEBUG TRAIN Batch 1/7400 loss 36.934963 loss_att 57.815617 loss_ctc 49.769211 loss_rnnt 28.958141 hw_loss 0.391773 lr 0.00062936 rank 3
2023-02-11 03:58:49,193 DEBUG TRAIN Batch 1/7400 loss 25.039345 loss_att 45.285416 loss_ctc 35.909256 loss_rnnt 14.487679 hw_loss 0.947462 lr 0.00063100 rank 1
2023-02-11 03:58:49,197 DEBUG TRAIN Batch 1/7400 loss 20.902905 loss_att 33.465759 loss_ctc 30.480553 loss_rnnt 14.325992 hw_loss 0.522623 lr 0.00062968 rank 2
2023-02-11 03:58:49,197 DEBUG TRAIN Batch 1/7400 loss 36.081833 loss_att 53.252220 loss_ctc 47.351494 loss_rnnt 27.457390 hw_loss 0.691452 lr 0.00062984 rank 0
2023-02-11 03:58:49,198 DEBUG TRAIN Batch 1/7400 loss 54.607883 loss_att 70.073959 loss_ctc 81.252365 loss_rnnt 44.531364 hw_loss 0.643258 lr 0.00062976 rank 5
2023-02-11 03:58:49,200 DEBUG TRAIN Batch 1/7400 loss 54.046474 loss_att 57.468430 loss_ctc 65.601013 loss_rnnt 45.922722 hw_loss 1.106017 lr 0.00062972 rank 6
2023-02-11 03:58:49,204 DEBUG TRAIN Batch 1/7400 loss 54.611019 loss_att 74.974442 loss_ctc 73.204880 loss_rnnt 45.232224 hw_loss 0.530049 lr 0.00062956 rank 7
2023-02-11 03:58:49,243 DEBUG TRAIN Batch 1/7400 loss 37.579128 loss_att 53.092350 loss_ctc 49.807674 loss_rnnt 30.112194 hw_loss 0.512590 lr 0.00062884 rank 4
2023-02-11 04:00:10,357 DEBUG TRAIN Batch 1/7500 loss 76.772118 loss_att 91.668839 loss_ctc 99.279243 loss_rnnt 68.674042 hw_loss 0.397083 lr 0.00063500 rank 1
2023-02-11 04:00:10,359 DEBUG TRAIN Batch 1/7500 loss 36.984528 loss_att 47.503410 loss_ctc 50.348236 loss_rnnt 29.823126 hw_loss 0.614212 lr 0.00063336 rank 3
2023-02-11 04:00:10,361 DEBUG TRAIN Batch 1/7500 loss 34.780304 loss_att 47.547569 loss_ctc 50.748238 loss_rnnt 27.584030 hw_loss 0.471331 lr 0.00063284 rank 4
2023-02-11 04:00:10,361 DEBUG TRAIN Batch 1/7500 loss 30.014090 loss_att 36.863911 loss_ctc 41.987827 loss_rnnt 24.292349 hw_loss 0.516614 lr 0.00063384 rank 0
2023-02-11 04:00:10,362 DEBUG TRAIN Batch 1/7500 loss 27.064821 loss_att 35.520844 loss_ctc 34.499916 loss_rnnt 19.589203 hw_loss 0.898700 lr 0.00063372 rank 6
2023-02-11 04:00:10,363 DEBUG TRAIN Batch 1/7500 loss 49.904106 loss_att 62.469231 loss_ctc 66.503868 loss_rnnt 43.480606 hw_loss 0.318220 lr 0.00063356 rank 7
2023-02-11 04:00:10,366 DEBUG TRAIN Batch 1/7500 loss 52.116531 loss_att 76.616432 loss_ctc 74.992477 loss_rnnt 42.933342 hw_loss 0.231203 lr 0.00063376 rank 5
2023-02-11 04:00:10,366 DEBUG TRAIN Batch 1/7500 loss 43.027321 loss_att 47.342270 loss_ctc 50.796783 loss_rnnt 36.318363 hw_loss 0.901882 lr 0.00063368 rank 2
2023-02-11 04:01:26,213 DEBUG TRAIN Batch 1/7600 loss 63.876541 loss_att 84.464996 loss_ctc 90.023117 loss_rnnt 52.924065 hw_loss 0.627858 lr 0.00063768 rank 2
2023-02-11 04:01:26,216 DEBUG TRAIN Batch 1/7600 loss 43.296314 loss_att 56.540649 loss_ctc 65.737648 loss_rnnt 34.685833 hw_loss 0.556770 lr 0.00063756 rank 7
2023-02-11 04:01:26,218 DEBUG TRAIN Batch 1/7600 loss 51.307137 loss_att 55.460007 loss_ctc 59.320255 loss_rnnt 45.645309 hw_loss 0.705532 lr 0.00063736 rank 3
2023-02-11 04:01:26,220 DEBUG TRAIN Batch 1/7600 loss 34.069340 loss_att 37.169525 loss_ctc 38.368896 loss_rnnt 28.929092 hw_loss 0.740050 lr 0.00063684 rank 4
2023-02-11 04:01:26,220 DEBUG TRAIN Batch 1/7600 loss 37.890652 loss_att 59.582062 loss_ctc 60.996532 loss_rnnt 28.507641 hw_loss 0.368239 lr 0.00063772 rank 6
2023-02-11 04:01:26,221 DEBUG TRAIN Batch 1/7600 loss 69.266380 loss_att 88.396225 loss_ctc 95.557922 loss_rnnt 61.417023 hw_loss 0.097096 lr 0.00063784 rank 0
2023-02-11 04:01:26,222 DEBUG TRAIN Batch 1/7600 loss 52.099941 loss_att 66.149086 loss_ctc 63.750744 loss_rnnt 45.482136 hw_loss 0.422725 lr 0.00063776 rank 5
2023-02-11 04:01:26,269 DEBUG TRAIN Batch 1/7600 loss 33.801018 loss_att 36.262718 loss_ctc 44.684059 loss_rnnt 26.680716 hw_loss 0.970666 lr 0.00063900 rank 1
2023-02-11 04:02:43,032 DEBUG TRAIN Batch 1/7700 loss 73.327866 loss_att 98.227661 loss_ctc 90.728905 loss_rnnt 62.807140 hw_loss 0.603867 lr 0.00064184 rank 0
2023-02-11 04:02:43,033 DEBUG TRAIN Batch 1/7700 loss 39.152218 loss_att 59.974499 loss_ctc 54.058464 loss_rnnt 30.424198 hw_loss 0.483012 lr 0.00064136 rank 3
2023-02-11 04:02:43,033 DEBUG TRAIN Batch 1/7700 loss 42.966496 loss_att 62.132645 loss_ctc 50.867462 loss_rnnt 35.978481 hw_loss 0.393998 lr 0.00064168 rank 2
2023-02-11 04:02:43,035 DEBUG TRAIN Batch 1/7700 loss 57.568840 loss_att 70.549103 loss_ctc 80.586288 loss_rnnt 51.067425 hw_loss 0.156820 lr 0.00064172 rank 6
2023-02-11 04:02:43,036 DEBUG TRAIN Batch 1/7700 loss 49.902142 loss_att 79.414276 loss_ctc 71.719559 loss_rnnt 39.799530 hw_loss 0.242098 lr 0.00064084 rank 4
2023-02-11 04:02:43,038 DEBUG TRAIN Batch 1/7700 loss 61.749573 loss_att 80.982338 loss_ctc 81.311920 loss_rnnt 53.197018 hw_loss 0.393318 lr 0.00064300 rank 1
2023-02-11 04:02:43,040 DEBUG TRAIN Batch 1/7700 loss 36.882034 loss_att 62.717102 loss_ctc 53.143486 loss_rnnt 27.113831 hw_loss 0.456187 lr 0.00064176 rank 5
2023-02-11 04:02:43,041 DEBUG TRAIN Batch 1/7700 loss 21.791853 loss_att 22.921036 loss_ctc 23.860014 loss_rnnt 15.161300 hw_loss 1.149180 lr 0.00064156 rank 7
2023-02-11 04:04:00,964 DEBUG TRAIN Batch 1/7800 loss 55.754776 loss_att 73.433716 loss_ctc 73.388390 loss_rnnt 48.552795 hw_loss 0.246570 lr 0.00064556 rank 7
2023-02-11 04:04:00,968 DEBUG TRAIN Batch 1/7800 loss 30.676868 loss_att 51.267303 loss_ctc 45.685577 loss_rnnt 22.851185 hw_loss 0.319956 lr 0.00064536 rank 3
2023-02-11 04:04:00,970 DEBUG TRAIN Batch 1/7800 loss 40.262718 loss_att 63.230705 loss_ctc 60.174503 loss_rnnt 29.882668 hw_loss 0.587166 lr 0.00064572 rank 6
2023-02-11 04:04:00,971 DEBUG TRAIN Batch 1/7800 loss 62.993896 loss_att 82.366127 loss_ctc 86.633606 loss_rnnt 53.228004 hw_loss 0.513653 lr 0.00064584 rank 0
2023-02-11 04:04:00,971 DEBUG TRAIN Batch 1/7800 loss 55.970680 loss_att 70.996147 loss_ctc 77.898956 loss_rnnt 48.120819 hw_loss 0.360187 lr 0.00064700 rank 1
2023-02-11 04:04:00,978 DEBUG TRAIN Batch 1/7800 loss 48.720673 loss_att 66.928398 loss_ctc 65.493126 loss_rnnt 39.224167 hw_loss 0.678493 lr 0.00064576 rank 5
2023-02-11 04:04:00,994 DEBUG TRAIN Batch 1/7800 loss 40.253063 loss_att 55.076462 loss_ctc 47.421383 loss_rnnt 34.920918 hw_loss 0.264691 lr 0.00064484 rank 4
2023-02-11 04:04:01,001 DEBUG TRAIN Batch 1/7800 loss 30.434032 loss_att 43.803394 loss_ctc 37.950844 loss_rnnt 23.275848 hw_loss 0.652888 lr 0.00064568 rank 2
2023-02-11 04:05:17,468 DEBUG TRAIN Batch 1/7900 loss 44.844116 loss_att 61.488426 loss_ctc 58.335686 loss_rnnt 35.411358 hw_loss 0.807192 lr 0.00064936 rank 3
2023-02-11 04:05:17,468 DEBUG TRAIN Batch 1/7900 loss 42.948708 loss_att 61.439140 loss_ctc 71.782974 loss_rnnt 32.991852 hw_loss 0.452662 lr 0.00064956 rank 7
2023-02-11 04:05:17,471 DEBUG TRAIN Batch 1/7900 loss 50.366215 loss_att 75.329796 loss_ctc 69.159599 loss_rnnt 41.666218 hw_loss 0.225281 lr 0.00064972 rank 6
2023-02-11 04:05:17,473 DEBUG TRAIN Batch 1/7900 loss 37.127193 loss_att 50.640335 loss_ctc 41.478767 loss_rnnt 31.140259 hw_loss 0.507018 lr 0.00064884 rank 4
2023-02-11 04:05:17,474 DEBUG TRAIN Batch 1/7900 loss 33.460133 loss_att 50.922832 loss_ctc 51.238499 loss_rnnt 24.102026 hw_loss 0.655335 lr 0.00064968 rank 2
2023-02-11 04:05:17,476 DEBUG TRAIN Batch 1/7900 loss 31.517452 loss_att 49.285843 loss_ctc 43.382271 loss_rnnt 24.024862 hw_loss 0.441926 lr 0.00064984 rank 0
2023-02-11 04:05:17,476 DEBUG TRAIN Batch 1/7900 loss 37.734707 loss_att 58.976109 loss_ctc 61.738495 loss_rnnt 28.817490 hw_loss 0.275331 lr 0.00064976 rank 5
2023-02-11 04:05:17,477 DEBUG TRAIN Batch 1/7900 loss 29.010170 loss_att 44.236336 loss_ctc 35.079189 loss_rnnt 19.252485 hw_loss 1.106859 lr 0.00065100 rank 1
2023-02-11 04:06:32,585 DEBUG TRAIN Batch 1/8000 loss 38.539722 loss_att 55.373909 loss_ctc 51.258690 loss_rnnt 31.473183 hw_loss 0.375720 lr 0.00065500 rank 1
2023-02-11 04:06:32,587 DEBUG TRAIN Batch 1/8000 loss 32.977730 loss_att 46.311409 loss_ctc 46.307571 loss_rnnt 25.208889 hw_loss 0.623399 lr 0.00065336 rank 3
2023-02-11 04:06:32,589 DEBUG TRAIN Batch 1/8000 loss 54.825260 loss_att 61.744209 loss_ctc 63.618557 loss_rnnt 49.188606 hw_loss 0.577579 lr 0.00065384 rank 0
2023-02-11 04:06:32,590 DEBUG TRAIN Batch 1/8000 loss 34.728580 loss_att 41.119141 loss_ctc 48.129143 loss_rnnt 25.800608 hw_loss 1.099335 lr 0.00065372 rank 6
2023-02-11 04:06:32,590 DEBUG TRAIN Batch 1/8000 loss 50.179905 loss_att 66.922058 loss_ctc 61.909836 loss_rnnt 41.636940 hw_loss 0.680726 lr 0.00065356 rank 7
2023-02-11 04:06:32,591 DEBUG TRAIN Batch 1/8000 loss 44.760742 loss_att 64.039703 loss_ctc 60.038322 loss_rnnt 35.489677 hw_loss 0.633424 lr 0.00065284 rank 4
2023-02-11 04:06:32,594 DEBUG TRAIN Batch 1/8000 loss 46.354965 loss_att 63.874420 loss_ctc 65.329681 loss_rnnt 38.693123 hw_loss 0.305249 lr 0.00065376 rank 5
2023-02-11 04:06:32,637 DEBUG TRAIN Batch 1/8000 loss 41.282230 loss_att 54.005867 loss_ctc 53.683907 loss_rnnt 33.325836 hw_loss 0.704645 lr 0.00065368 rank 2
2023-02-11 04:07:49,661 DEBUG TRAIN Batch 1/8100 loss 46.675053 loss_att 69.230865 loss_ctc 58.753876 loss_rnnt 37.938713 hw_loss 0.490251 lr 0.00065756 rank 7
2023-02-11 04:07:49,662 DEBUG TRAIN Batch 1/8100 loss 53.894581 loss_att 68.391777 loss_ctc 72.831223 loss_rnnt 45.993649 hw_loss 0.464364 lr 0.00065784 rank 0
2023-02-11 04:07:49,662 DEBUG TRAIN Batch 1/8100 loss 43.548374 loss_att 52.002838 loss_ctc 52.436035 loss_rnnt 36.496754 hw_loss 0.782945 lr 0.00065736 rank 3
2023-02-11 04:07:49,664 DEBUG TRAIN Batch 1/8100 loss 41.308285 loss_att 52.344322 loss_ctc 56.719563 loss_rnnt 35.366566 hw_loss 0.314939 lr 0.00065684 rank 4
2023-02-11 04:07:49,665 DEBUG TRAIN Batch 1/8100 loss 35.703495 loss_att 43.121124 loss_ctc 45.725384 loss_rnnt 30.123810 hw_loss 0.517482 lr 0.00065768 rank 2
2023-02-11 04:07:49,666 DEBUG TRAIN Batch 1/8100 loss 50.291138 loss_att 70.977097 loss_ctc 69.520218 loss_rnnt 39.881554 hw_loss 0.695347 lr 0.00065772 rank 6
2023-02-11 04:07:49,669 DEBUG TRAIN Batch 1/8100 loss 28.086649 loss_att 43.394932 loss_ctc 39.333458 loss_rnnt 21.109617 hw_loss 0.452962 lr 0.00065776 rank 5
2023-02-11 04:07:49,669 DEBUG TRAIN Batch 1/8100 loss 54.861912 loss_att 64.300064 loss_ctc 76.718307 loss_rnnt 45.584332 hw_loss 0.839206 lr 0.00065900 rank 1
2023-02-11 04:09:07,129 DEBUG TRAIN Batch 1/8200 loss 59.214272 loss_att 75.685005 loss_ctc 79.449059 loss_rnnt 50.814129 hw_loss 0.451506 lr 0.00066168 rank 2
2023-02-11 04:09:07,132 DEBUG TRAIN Batch 1/8200 loss 54.766338 loss_att 62.640030 loss_ctc 65.825203 loss_rnnt 48.705521 hw_loss 0.564669 lr 0.00066300 rank 1
2023-02-11 04:09:07,133 DEBUG TRAIN Batch 1/8200 loss 28.944384 loss_att 42.707638 loss_ctc 42.251858 loss_rnnt 22.923721 hw_loss 0.280065 lr 0.00066156 rank 7
2023-02-11 04:09:07,133 DEBUG TRAIN Batch 1/8200 loss 51.985657 loss_att 69.089012 loss_ctc 63.719452 loss_rnnt 41.570934 hw_loss 1.018040 lr 0.00066136 rank 3
2023-02-11 04:09:07,134 DEBUG TRAIN Batch 1/8200 loss 36.585312 loss_att 43.312828 loss_ctc 43.165932 loss_rnnt 31.148987 hw_loss 0.602513 lr 0.00066084 rank 4
2023-02-11 04:09:07,135 DEBUG TRAIN Batch 1/8200 loss 33.286911 loss_att 36.801422 loss_ctc 40.927967 loss_rnnt 26.577772 hw_loss 0.935143 lr 0.00066172 rank 6
2023-02-11 04:09:07,136 DEBUG TRAIN Batch 1/8200 loss 34.575302 loss_att 45.006668 loss_ctc 40.010201 loss_rnnt 27.588825 hw_loss 0.782915 lr 0.00066176 rank 5
2023-02-11 04:09:07,137 DEBUG TRAIN Batch 1/8200 loss 30.644716 loss_att 54.753284 loss_ctc 39.821304 loss_rnnt 21.128651 hw_loss 0.650777 lr 0.00066184 rank 0
2023-02-11 04:10:22,270 DEBUG TRAIN Batch 1/8300 loss 38.668243 loss_att 47.128769 loss_ctc 51.886902 loss_rnnt 32.624077 hw_loss 0.485546 lr 0.00066536 rank 3
2023-02-11 04:10:22,273 DEBUG TRAIN Batch 1/8300 loss 45.612366 loss_att 64.467728 loss_ctc 66.535240 loss_rnnt 38.059479 hw_loss 0.186019 lr 0.00066556 rank 7
2023-02-11 04:10:22,275 DEBUG TRAIN Batch 1/8300 loss 44.367100 loss_att 58.051125 loss_ctc 55.403557 loss_rnnt 36.258648 hw_loss 0.731273 lr 0.00066576 rank 5
2023-02-11 04:10:22,278 DEBUG TRAIN Batch 1/8300 loss 56.639378 loss_att 80.552994 loss_ctc 78.780624 loss_rnnt 46.098812 hw_loss 0.526064 lr 0.00066484 rank 4
2023-02-11 04:10:22,278 DEBUG TRAIN Batch 1/8300 loss 42.148273 loss_att 62.723358 loss_ctc 56.487694 loss_rnnt 33.521835 hw_loss 0.487405 lr 0.00066700 rank 1
2023-02-11 04:10:22,280 DEBUG TRAIN Batch 1/8300 loss 33.777477 loss_att 52.252579 loss_ctc 44.386177 loss_rnnt 27.168434 hw_loss 0.281162 lr 0.00066584 rank 0
2023-02-11 04:10:22,281 DEBUG TRAIN Batch 1/8300 loss 31.488358 loss_att 37.173149 loss_ctc 42.504852 loss_rnnt 25.046370 hw_loss 0.719280 lr 0.00066568 rank 2
2023-02-11 04:10:22,322 DEBUG TRAIN Batch 1/8300 loss 49.977127 loss_att 69.164223 loss_ctc 71.252853 loss_rnnt 40.569679 hw_loss 0.512487 lr 0.00066572 rank 6
2023-02-11 04:11:10,754 DEBUG CV Batch 1/0 loss 12.781369 loss_att 8.292049 loss_ctc 9.661868 loss_rnnt 5.380353 hw_loss 1.634027 history loss 12.307985 rank 1
2023-02-11 04:11:10,756 DEBUG CV Batch 1/0 loss 12.781368 loss_att 8.292049 loss_ctc 9.661868 loss_rnnt 5.380353 hw_loss 1.634027 history loss 12.307984 rank 7
2023-02-11 04:11:10,757 DEBUG CV Batch 1/0 loss 12.781368 loss_att 8.292049 loss_ctc 9.661868 loss_rnnt 5.380353 hw_loss 1.634027 history loss 12.307984 rank 3
2023-02-11 04:11:10,759 DEBUG CV Batch 1/0 loss 12.781368 loss_att 8.292049 loss_ctc 9.661868 loss_rnnt 5.380353 hw_loss 1.634027 history loss 12.307984 rank 2
2023-02-11 04:11:10,766 DEBUG CV Batch 1/0 loss 12.781368 loss_att 8.292049 loss_ctc 9.661868 loss_rnnt 5.380353 hw_loss 1.634027 history loss 12.307984 rank 6
2023-02-11 04:11:10,770 DEBUG CV Batch 1/0 loss 12.781368 loss_att 8.292049 loss_ctc 9.661868 loss_rnnt 5.380353 hw_loss 1.634027 history loss 12.307984 rank 4
2023-02-11 04:11:10,770 DEBUG CV Batch 1/0 loss 12.781368 loss_att 8.292049 loss_ctc 9.661868 loss_rnnt 5.380353 hw_loss 1.634027 history loss 12.307984 rank 0
2023-02-11 04:11:10,773 DEBUG CV Batch 1/0 loss 12.781368 loss_att 8.292049 loss_ctc 9.661868 loss_rnnt 5.380353 hw_loss 1.634027 history loss 12.307984 rank 5
2023-02-11 04:11:21,821 DEBUG CV Batch 1/100 loss 28.556053 loss_att 36.368862 loss_ctc 38.702946 loss_rnnt 22.342770 hw_loss 0.618338 history loss 18.937010 rank 3
2023-02-11 04:11:21,837 DEBUG CV Batch 1/100 loss 28.556053 loss_att 36.368862 loss_ctc 38.702946 loss_rnnt 22.342770 hw_loss 0.618338 history loss 18.937010 rank 0
2023-02-11 04:11:21,841 DEBUG CV Batch 1/100 loss 28.556053 loss_att 36.368862 loss_ctc 38.702946 loss_rnnt 22.342770 hw_loss 0.618338 history loss 18.937010 rank 2
2023-02-11 04:11:21,966 DEBUG CV Batch 1/100 loss 28.556053 loss_att 36.368862 loss_ctc 38.702946 loss_rnnt 22.342770 hw_loss 0.618338 history loss 18.937010 rank 4
2023-02-11 04:11:21,971 DEBUG CV Batch 1/100 loss 28.556053 loss_att 36.368862 loss_ctc 38.702946 loss_rnnt 22.342770 hw_loss 0.618338 history loss 18.937010 rank 7
2023-02-11 04:11:21,970 DEBUG CV Batch 1/100 loss 28.556053 loss_att 36.368862 loss_ctc 38.702946 loss_rnnt 22.342770 hw_loss 0.618338 history loss 18.937010 rank 1
2023-02-11 04:11:22,021 DEBUG CV Batch 1/100 loss 28.556053 loss_att 36.368862 loss_ctc 38.702946 loss_rnnt 22.342770 hw_loss 0.618338 history loss 18.937010 rank 5
2023-02-11 04:11:22,339 DEBUG CV Batch 1/100 loss 28.556053 loss_att 36.368862 loss_ctc 38.702946 loss_rnnt 22.342770 hw_loss 0.618338 history loss 18.937010 rank 6
2023-02-11 04:11:35,823 DEBUG CV Batch 1/200 loss 41.203911 loss_att 77.252640 loss_ctc 59.341560 loss_rnnt 30.574062 hw_loss 0.187828 history loss 20.203965 rank 0
2023-02-11 04:11:35,829 DEBUG CV Batch 1/200 loss 41.203911 loss_att 77.252640 loss_ctc 59.341560 loss_rnnt 30.574062 hw_loss 0.187828 history loss 20.203965 rank 3
2023-02-11 04:11:35,843 DEBUG CV Batch 1/200 loss 41.203911 loss_att 77.252640 loss_ctc 59.341560 loss_rnnt 30.574062 hw_loss 0.187828 history loss 20.203965 rank 5
2023-02-11 04:11:35,852 DEBUG CV Batch 1/200 loss 41.203911 loss_att 77.252640 loss_ctc 59.341560 loss_rnnt 30.574062 hw_loss 0.187828 history loss 20.203965 rank 7
2023-02-11 04:11:35,885 DEBUG CV Batch 1/200 loss 41.203911 loss_att 77.252640 loss_ctc 59.341560 loss_rnnt 30.574062 hw_loss 0.187828 history loss 20.203965 rank 2
2023-02-11 04:11:36,251 DEBUG CV Batch 1/200 loss 41.203911 loss_att 77.252640 loss_ctc 59.341560 loss_rnnt 30.574062 hw_loss 0.187828 history loss 20.203965 rank 4
2023-02-11 04:11:36,258 DEBUG CV Batch 1/200 loss 41.203911 loss_att 77.252640 loss_ctc 59.341560 loss_rnnt 30.574062 hw_loss 0.187828 history loss 20.203965 rank 6
2023-02-11 04:11:36,575 DEBUG CV Batch 1/200 loss 41.203911 loss_att 77.252640 loss_ctc 59.341560 loss_rnnt 30.574062 hw_loss 0.187828 history loss 20.203965 rank 1
2023-02-11 04:11:47,857 DEBUG CV Batch 1/300 loss 19.865957 loss_att 24.680515 loss_ctc 28.068592 loss_rnnt 15.266444 hw_loss 0.476797 history loss 20.429445 rank 0
2023-02-11 04:11:47,864 DEBUG CV Batch 1/300 loss 19.865957 loss_att 24.680515 loss_ctc 28.068592 loss_rnnt 15.266444 hw_loss 0.476797 history loss 20.429445 rank 3
2023-02-11 04:11:47,889 DEBUG CV Batch 1/300 loss 19.865957 loss_att 24.680515 loss_ctc 28.068592 loss_rnnt 15.266444 hw_loss 0.476797 history loss 20.429445 rank 5
2023-02-11 04:11:47,917 DEBUG CV Batch 1/300 loss 19.865957 loss_att 24.680515 loss_ctc 28.068592 loss_rnnt 15.266444 hw_loss 0.476797 history loss 20.429445 rank 7
2023-02-11 04:11:47,963 DEBUG CV Batch 1/300 loss 19.865957 loss_att 24.680515 loss_ctc 28.068592 loss_rnnt 15.266444 hw_loss 0.476797 history loss 20.429445 rank 2
2023-02-11 04:11:48,306 DEBUG CV Batch 1/300 loss 19.865957 loss_att 24.680515 loss_ctc 28.068592 loss_rnnt 15.266444 hw_loss 0.476797 history loss 20.429445 rank 6
2023-02-11 04:11:48,364 DEBUG CV Batch 1/300 loss 19.865957 loss_att 24.680515 loss_ctc 28.068592 loss_rnnt 15.266444 hw_loss 0.476797 history loss 20.429445 rank 4
2023-02-11 04:11:48,650 DEBUG CV Batch 1/300 loss 19.865957 loss_att 24.680515 loss_ctc 28.068592 loss_rnnt 15.266444 hw_loss 0.476797 history loss 20.429445 rank 1
2023-02-11 04:11:59,729 DEBUG CV Batch 1/400 loss 74.947166 loss_att 177.484619 loss_ctc 88.552345 loss_rnnt 51.532490 hw_loss 0.204967 history loss 22.067007 rank 0
2023-02-11 04:11:59,796 DEBUG CV Batch 1/400 loss 74.947166 loss_att 177.484619 loss_ctc 88.552345 loss_rnnt 51.532490 hw_loss 0.204967 history loss 22.067007 rank 3
2023-02-11 04:11:59,820 DEBUG CV Batch 1/400 loss 74.947166 loss_att 177.484619 loss_ctc 88.552345 loss_rnnt 51.532490 hw_loss 0.204967 history loss 22.067007 rank 5
2023-02-11 04:11:59,890 DEBUG CV Batch 1/400 loss 74.947166 loss_att 177.484619 loss_ctc 88.552345 loss_rnnt 51.532490 hw_loss 0.204967 history loss 22.067007 rank 7
2023-02-11 04:11:59,927 DEBUG CV Batch 1/400 loss 74.947166 loss_att 177.484619 loss_ctc 88.552345 loss_rnnt 51.532490 hw_loss 0.204967 history loss 22.067007 rank 2
2023-02-11 04:12:00,298 DEBUG CV Batch 1/400 loss 74.947166 loss_att 177.484619 loss_ctc 88.552345 loss_rnnt 51.532490 hw_loss 0.204967 history loss 22.067007 rank 6
2023-02-11 04:12:00,667 DEBUG CV Batch 1/400 loss 74.947166 loss_att 177.484619 loss_ctc 88.552345 loss_rnnt 51.532490 hw_loss 0.204967 history loss 22.067007 rank 1
2023-02-11 04:12:00,694 DEBUG CV Batch 1/400 loss 74.947166 loss_att 177.484619 loss_ctc 88.552345 loss_rnnt 51.532490 hw_loss 0.204967 history loss 22.067007 rank 4
2023-02-11 04:12:10,144 DEBUG CV Batch 1/500 loss 34.775955 loss_att 36.301003 loss_ctc 46.247242 loss_rnnt 27.714029 hw_loss 0.980139 history loss 23.437796 rank 0
2023-02-11 04:12:10,239 DEBUG CV Batch 1/500 loss 34.775955 loss_att 36.301003 loss_ctc 46.247242 loss_rnnt 27.714029 hw_loss 0.980139 history loss 23.437796 rank 3
2023-02-11 04:12:10,302 DEBUG CV Batch 1/500 loss 34.775955 loss_att 36.301003 loss_ctc 46.247242 loss_rnnt 27.714029 hw_loss 0.980139 history loss 23.437796 rank 5
2023-02-11 04:12:10,333 DEBUG CV Batch 1/500 loss 34.775955 loss_att 36.301003 loss_ctc 46.247242 loss_rnnt 27.714029 hw_loss 0.980139 history loss 23.437796 rank 7
2023-02-11 04:12:10,697 DEBUG CV Batch 1/500 loss 34.775955 loss_att 36.301003 loss_ctc 46.247242 loss_rnnt 27.714029 hw_loss 0.980139 history loss 23.437796 rank 6
2023-02-11 04:12:11,134 DEBUG CV Batch 1/500 loss 34.775955 loss_att 36.301003 loss_ctc 46.247242 loss_rnnt 27.714029 hw_loss 0.980139 history loss 23.437796 rank 1
2023-02-11 04:12:11,199 DEBUG CV Batch 1/500 loss 34.775955 loss_att 36.301003 loss_ctc 46.247242 loss_rnnt 27.714029 hw_loss 0.980139 history loss 23.437796 rank 4
2023-02-11 04:12:11,243 DEBUG CV Batch 1/500 loss 34.775955 loss_att 36.301003 loss_ctc 46.247242 loss_rnnt 27.714029 hw_loss 0.980139 history loss 23.437796 rank 2
2023-02-11 04:12:22,179 DEBUG CV Batch 1/600 loss 24.898138 loss_att 22.531309 loss_ctc 28.275848 loss_rnnt 17.063248 hw_loss 1.473355 history loss 24.897935 rank 0
2023-02-11 04:12:22,309 DEBUG CV Batch 1/600 loss 24.898136 loss_att 22.531309 loss_ctc 28.275848 loss_rnnt 17.063248 hw_loss 1.473355 history loss 24.897935 rank 5
2023-02-11 04:12:22,360 DEBUG CV Batch 1/600 loss 24.898136 loss_att 22.531309 loss_ctc 28.275848 loss_rnnt 17.063248 hw_loss 1.473355 history loss 24.897935 rank 3
2023-02-11 04:12:22,477 DEBUG CV Batch 1/600 loss 24.898136 loss_att 22.531309 loss_ctc 28.275848 loss_rnnt 17.063248 hw_loss 1.473355 history loss 24.897936 rank 7
2023-02-11 04:12:22,755 DEBUG CV Batch 1/600 loss 24.898136 loss_att 22.531309 loss_ctc 28.275848 loss_rnnt 17.063248 hw_loss 1.473355 history loss 24.897936 rank 6
2023-02-11 04:12:23,249 DEBUG CV Batch 1/600 loss 24.898136 loss_att 22.531309 loss_ctc 28.275848 loss_rnnt 17.063248 hw_loss 1.473355 history loss 24.897936 rank 1
2023-02-11 04:12:23,267 DEBUG CV Batch 1/600 loss 24.898136 loss_att 22.531309 loss_ctc 28.275848 loss_rnnt 17.063248 hw_loss 1.473355 history loss 24.897936 rank 2
2023-02-11 04:12:23,327 DEBUG CV Batch 1/600 loss 24.898136 loss_att 22.531309 loss_ctc 28.275848 loss_rnnt 17.063248 hw_loss 1.473355 history loss 24.897936 rank 4
2023-02-11 04:12:33,760 DEBUG CV Batch 1/700 loss 75.983871 loss_att 145.693726 loss_ctc 104.985962 loss_rnnt 56.656460 hw_loss 0.284717 history loss 25.994364 rank 7
2023-02-11 04:12:33,840 DEBUG CV Batch 1/700 loss 75.983871 loss_att 145.693726 loss_ctc 104.985962 loss_rnnt 56.656460 hw_loss 0.284717 history loss 25.994364 rank 5
2023-02-11 04:12:33,907 DEBUG CV Batch 1/700 loss 75.983871 loss_att 145.693726 loss_ctc 104.985962 loss_rnnt 56.656460 hw_loss 0.284717 history loss 25.994364 rank 0
2023-02-11 04:12:33,916 DEBUG CV Batch 1/700 loss 75.983871 loss_att 145.693726 loss_ctc 104.985962 loss_rnnt 56.656460 hw_loss 0.284717 history loss 25.994364 rank 3
2023-02-11 04:12:34,568 DEBUG CV Batch 1/700 loss 75.983871 loss_att 145.693726 loss_ctc 104.985962 loss_rnnt 56.656460 hw_loss 0.284717 history loss 25.994364 rank 2
2023-02-11 04:12:34,576 DEBUG CV Batch 1/700 loss 75.983871 loss_att 145.693726 loss_ctc 104.985962 loss_rnnt 56.656460 hw_loss 0.284717 history loss 25.994364 rank 6
2023-02-11 04:12:34,684 DEBUG CV Batch 1/700 loss 75.983871 loss_att 145.693726 loss_ctc 104.985962 loss_rnnt 56.656460 hw_loss 0.284717 history loss 25.994364 rank 4
2023-02-11 04:12:34,913 DEBUG CV Batch 1/700 loss 75.983871 loss_att 145.693726 loss_ctc 104.985962 loss_rnnt 56.656460 hw_loss 0.284717 history loss 25.994364 rank 1
2023-02-11 04:12:45,677 DEBUG CV Batch 1/800 loss 29.491270 loss_att 36.001221 loss_ctc 40.810341 loss_rnnt 22.338827 hw_loss 0.813983 history loss 24.973343 rank 7
2023-02-11 04:12:45,700 DEBUG CV Batch 1/800 loss 29.491270 loss_att 36.001221 loss_ctc 40.810341 loss_rnnt 22.338827 hw_loss 0.813983 history loss 24.973343 rank 0
2023-02-11 04:12:45,703 DEBUG CV Batch 1/800 loss 29.491270 loss_att 36.001221 loss_ctc 40.810341 loss_rnnt 22.338827 hw_loss 0.813983 history loss 24.973343 rank 5
2023-02-11 04:12:46,029 DEBUG CV Batch 1/800 loss 29.491270 loss_att 36.001221 loss_ctc 40.810341 loss_rnnt 22.338827 hw_loss 0.813983 history loss 24.973343 rank 3
2023-02-11 04:12:46,043 DEBUG CV Batch 1/800 loss 29.491270 loss_att 36.001221 loss_ctc 40.810341 loss_rnnt 22.338827 hw_loss 0.813983 history loss 24.973343 rank 2
2023-02-11 04:12:46,621 DEBUG CV Batch 1/800 loss 29.491270 loss_att 36.001221 loss_ctc 40.810341 loss_rnnt 22.338827 hw_loss 0.813983 history loss 24.973343 rank 6
2023-02-11 04:12:46,760 DEBUG CV Batch 1/800 loss 29.491270 loss_att 36.001221 loss_ctc 40.810341 loss_rnnt 22.338827 hw_loss 0.813983 history loss 24.973343 rank 1
2023-02-11 04:12:47,120 DEBUG CV Batch 1/800 loss 29.491270 loss_att 36.001221 loss_ctc 40.810341 loss_rnnt 22.338827 hw_loss 0.813983 history loss 24.973343 rank 4
2023-02-11 04:12:59,131 DEBUG CV Batch 1/900 loss 45.964867 loss_att 83.125366 loss_ctc 59.213615 loss_rnnt 34.603302 hw_loss 0.405556 history loss 24.693978 rank 7
2023-02-11 04:12:59,185 DEBUG CV Batch 1/900 loss 45.964867 loss_att 83.125366 loss_ctc 59.213615 loss_rnnt 34.603302 hw_loss 0.405556 history loss 24.693978 rank 0
2023-02-11 04:12:59,192 DEBUG CV Batch 1/900 loss 45.964867 loss_att 83.125366 loss_ctc 59.213615 loss_rnnt 34.603302 hw_loss 0.405556 history loss 24.693978 rank 5
2023-02-11 04:12:59,387 DEBUG CV Batch 1/900 loss 45.964867 loss_att 83.125366 loss_ctc 59.213615 loss_rnnt 34.603302 hw_loss 0.405556 history loss 24.693978 rank 3
2023-02-11 04:12:59,844 DEBUG CV Batch 1/900 loss 45.964867 loss_att 83.125366 loss_ctc 59.213615 loss_rnnt 34.603302 hw_loss 0.405556 history loss 24.693978 rank 2
2023-02-11 04:13:00,523 DEBUG CV Batch 1/900 loss 45.964867 loss_att 83.125366 loss_ctc 59.213615 loss_rnnt 34.603302 hw_loss 0.405556 history loss 24.693978 rank 6
2023-02-11 04:13:00,568 DEBUG CV Batch 1/900 loss 45.964867 loss_att 83.125366 loss_ctc 59.213615 loss_rnnt 34.603302 hw_loss 0.405556 history loss 24.693978 rank 1
2023-02-11 04:13:01,059 DEBUG CV Batch 1/900 loss 45.964867 loss_att 83.125366 loss_ctc 59.213615 loss_rnnt 34.603302 hw_loss 0.405556 history loss 24.693978 rank 4
2023-02-11 04:13:11,282 DEBUG CV Batch 1/1000 loss 19.230770 loss_att 20.590292 loss_ctc 20.746098 loss_rnnt 13.995314 hw_loss 0.892783 history loss 24.328405 rank 7
2023-02-11 04:13:11,294 DEBUG CV Batch 1/1000 loss 19.230770 loss_att 20.590292 loss_ctc 20.746098 loss_rnnt 13.995314 hw_loss 0.892783 history loss 24.328405 rank 0
2023-02-11 04:13:11,453 DEBUG CV Batch 1/1000 loss 19.230770 loss_att 20.590292 loss_ctc 20.746098 loss_rnnt 13.995314 hw_loss 0.892783 history loss 24.328405 rank 5
2023-02-11 04:13:11,612 DEBUG CV Batch 1/1000 loss 19.230770 loss_att 20.590292 loss_ctc 20.746098 loss_rnnt 13.995314 hw_loss 0.892783 history loss 24.328405 rank 3
2023-02-11 04:13:12,031 DEBUG CV Batch 1/1000 loss 19.230770 loss_att 20.590292 loss_ctc 20.746098 loss_rnnt 13.995314 hw_loss 0.892783 history loss 24.328405 rank 2
2023-02-11 04:13:12,675 DEBUG CV Batch 1/1000 loss 19.230770 loss_att 20.590292 loss_ctc 20.746098 loss_rnnt 13.995314 hw_loss 0.892783 history loss 24.328405 rank 6
2023-02-11 04:13:12,819 DEBUG CV Batch 1/1000 loss 19.230770 loss_att 20.590292 loss_ctc 20.746098 loss_rnnt 13.995314 hw_loss 0.892783 history loss 24.328405 rank 1
2023-02-11 04:13:13,336 DEBUG CV Batch 1/1000 loss 19.230770 loss_att 20.590292 loss_ctc 20.746098 loss_rnnt 13.995314 hw_loss 0.892783 history loss 24.328405 rank 4
2023-02-11 04:13:23,168 DEBUG CV Batch 1/1100 loss 17.388729 loss_att 12.769712 loss_ctc 16.013885 loss_rnnt 10.199274 hw_loss 1.555607 history loss 24.302641 rank 0
2023-02-11 04:13:23,172 DEBUG CV Batch 1/1100 loss 17.388729 loss_att 12.769712 loss_ctc 16.013885 loss_rnnt 10.199274 hw_loss 1.555607 history loss 24.302641 rank 7
2023-02-11 04:13:23,368 DEBUG CV Batch 1/1100 loss 17.388729 loss_att 12.769712 loss_ctc 16.013885 loss_rnnt 10.199274 hw_loss 1.555607 history loss 24.302641 rank 5
2023-02-11 04:13:23,455 DEBUG CV Batch 1/1100 loss 17.388729 loss_att 12.769712 loss_ctc 16.013885 loss_rnnt 10.199274 hw_loss 1.555607 history loss 24.302641 rank 3
2023-02-11 04:13:24,536 DEBUG CV Batch 1/1100 loss 17.388729 loss_att 12.769712 loss_ctc 16.013885 loss_rnnt 10.199274 hw_loss 1.555607 history loss 24.302641 rank 6
2023-02-11 04:13:24,727 DEBUG CV Batch 1/1100 loss 17.388729 loss_att 12.769712 loss_ctc 16.013885 loss_rnnt 10.199274 hw_loss 1.555607 history loss 24.302641 rank 1
2023-02-11 04:13:24,892 DEBUG CV Batch 1/1100 loss 17.388731 loss_att 12.769712 loss_ctc 16.013885 loss_rnnt 10.199274 hw_loss 1.555608 history loss 24.302641 rank 2
2023-02-11 04:13:25,223 DEBUG CV Batch 1/1100 loss 17.388729 loss_att 12.769712 loss_ctc 16.013885 loss_rnnt 10.199274 hw_loss 1.555607 history loss 24.302641 rank 4
2023-02-11 04:13:33,506 DEBUG CV Batch 1/1200 loss 33.132507 loss_att 42.289085 loss_ctc 48.919880 loss_rnnt 25.865992 hw_loss 0.624415 history loss 24.873626 rank 0
2023-02-11 04:13:33,598 DEBUG CV Batch 1/1200 loss 33.132507 loss_att 42.289085 loss_ctc 48.919880 loss_rnnt 25.865992 hw_loss 0.624415 history loss 24.873626 rank 7
2023-02-11 04:13:33,819 DEBUG CV Batch 1/1200 loss 33.132507 loss_att 42.289085 loss_ctc 48.919880 loss_rnnt 25.865992 hw_loss 0.624415 history loss 24.873626 rank 5
2023-02-11 04:13:33,879 DEBUG CV Batch 1/1200 loss 33.132507 loss_att 42.289085 loss_ctc 48.919880 loss_rnnt 25.865992 hw_loss 0.624415 history loss 24.873626 rank 3
2023-02-11 04:13:35,071 DEBUG CV Batch 1/1200 loss 33.132507 loss_att 42.289085 loss_ctc 48.919880 loss_rnnt 25.865992 hw_loss 0.624415 history loss 24.873626 rank 6
2023-02-11 04:13:35,283 DEBUG CV Batch 1/1200 loss 33.132507 loss_att 42.289085 loss_ctc 48.919880 loss_rnnt 25.865992 hw_loss 0.624415 history loss 24.873626 rank 1
2023-02-11 04:13:35,347 DEBUG CV Batch 1/1200 loss 33.132507 loss_att 42.289085 loss_ctc 48.919880 loss_rnnt 25.865992 hw_loss 0.624415 history loss 24.873626 rank 2
2023-02-11 04:13:35,781 DEBUG CV Batch 1/1200 loss 33.132507 loss_att 42.289085 loss_ctc 48.919880 loss_rnnt 25.865992 hw_loss 0.624415 history loss 24.873626 rank 4
2023-02-11 04:13:45,350 DEBUG CV Batch 1/1300 loss 23.122169 loss_att 19.892534 loss_ctc 25.353994 loss_rnnt 15.459208 hw_loss 1.502121 history loss 25.333801 rank 0
2023-02-11 04:13:45,485 DEBUG CV Batch 1/1300 loss 23.122169 loss_att 19.892534 loss_ctc 25.353994 loss_rnnt 15.459208 hw_loss 1.502121 history loss 25.333801 rank 7
2023-02-11 04:13:45,712 DEBUG CV Batch 1/1300 loss 23.122169 loss_att 19.892534 loss_ctc 25.353994 loss_rnnt 15.459208 hw_loss 1.502121 history loss 25.333801 rank 5
2023-02-11 04:13:45,747 DEBUG CV Batch 1/1300 loss 23.122169 loss_att 19.892534 loss_ctc 25.353994 loss_rnnt 15.459208 hw_loss 1.502121 history loss 25.333801 rank 3
2023-02-11 04:13:47,221 DEBUG CV Batch 1/1300 loss 23.122169 loss_att 19.892534 loss_ctc 25.353994 loss_rnnt 15.459208 hw_loss 1.502121 history loss 25.333801 rank 1
2023-02-11 04:13:47,237 DEBUG CV Batch 1/1300 loss 23.122169 loss_att 19.892534 loss_ctc 25.353994 loss_rnnt 15.459208 hw_loss 1.502121 history loss 25.333801 rank 2
2023-02-11 04:13:47,785 DEBUG CV Batch 1/1300 loss 23.122169 loss_att 19.892534 loss_ctc 25.353994 loss_rnnt 15.459208 hw_loss 1.502121 history loss 25.333801 rank 4
2023-02-11 04:13:47,814 DEBUG CV Batch 1/1300 loss 23.122169 loss_att 19.892534 loss_ctc 25.353994 loss_rnnt 15.459208 hw_loss 1.502121 history loss 25.333801 rank 6
2023-02-11 04:13:56,411 DEBUG CV Batch 1/1400 loss 48.903206 loss_att 97.213112 loss_ctc 58.702190 loss_rnnt 36.418427 hw_loss 0.284300 history loss 25.904497 rank 0
2023-02-11 04:13:56,627 DEBUG CV Batch 1/1400 loss 48.903206 loss_att 97.213112 loss_ctc 58.702190 loss_rnnt 36.418427 hw_loss 0.284300 history loss 25.904497 rank 7
2023-02-11 04:13:56,864 DEBUG CV Batch 1/1400 loss 48.903206 loss_att 97.213112 loss_ctc 58.702190 loss_rnnt 36.418427 hw_loss 0.284300 history loss 25.904497 rank 5
2023-02-11 04:13:56,865 DEBUG CV Batch 1/1400 loss 48.903206 loss_att 97.213112 loss_ctc 58.702190 loss_rnnt 36.418427 hw_loss 0.284300 history loss 25.904497 rank 3
2023-02-11 04:13:58,364 DEBUG CV Batch 1/1400 loss 48.903206 loss_att 97.213112 loss_ctc 58.702190 loss_rnnt 36.418427 hw_loss 0.284300 history loss 25.904497 rank 1
2023-02-11 04:13:58,370 DEBUG CV Batch 1/1400 loss 48.903206 loss_att 97.213112 loss_ctc 58.702190 loss_rnnt 36.418427 hw_loss 0.284300 history loss 25.904497 rank 2
2023-02-11 04:13:58,917 DEBUG CV Batch 1/1400 loss 48.903206 loss_att 97.213112 loss_ctc 58.702190 loss_rnnt 36.418427 hw_loss 0.284300 history loss 25.904497 rank 6
2023-02-11 04:13:59,026 DEBUG CV Batch 1/1400 loss 48.903206 loss_att 97.213112 loss_ctc 58.702190 loss_rnnt 36.418427 hw_loss 0.284300 history loss 25.904497 rank 4
2023-02-11 04:14:07,903 DEBUG CV Batch 1/1500 loss 27.999315 loss_att 35.661011 loss_ctc 33.112839 loss_rnnt 20.482048 hw_loss 0.994336 history loss 25.506323 rank 0
2023-02-11 04:14:08,275 DEBUG CV Batch 1/1500 loss 27.999315 loss_att 35.661011 loss_ctc 33.112839 loss_rnnt 20.482048 hw_loss 0.994336 history loss 25.506323 rank 7
2023-02-11 04:14:08,341 DEBUG CV Batch 1/1500 loss 27.999315 loss_att 35.661011 loss_ctc 33.112839 loss_rnnt 20.482048 hw_loss 0.994336 history loss 25.506323 rank 5
2023-02-11 04:14:08,652 DEBUG CV Batch 1/1500 loss 27.999315 loss_att 35.661011 loss_ctc 33.112839 loss_rnnt 20.482048 hw_loss 0.994336 history loss 25.506323 rank 3
2023-02-11 04:14:09,946 DEBUG CV Batch 1/1500 loss 27.999315 loss_att 35.661011 loss_ctc 33.112839 loss_rnnt 20.482048 hw_loss 0.994336 history loss 25.506323 rank 2
2023-02-11 04:14:10,958 DEBUG CV Batch 1/1500 loss 27.999315 loss_att 35.661011 loss_ctc 33.112839 loss_rnnt 20.482048 hw_loss 0.994336 history loss 25.506323 rank 4
2023-02-11 04:14:11,067 DEBUG CV Batch 1/1500 loss 27.999315 loss_att 35.661011 loss_ctc 33.112839 loss_rnnt 20.482048 hw_loss 0.994336 history loss 25.506323 rank 6
2023-02-11 04:14:11,146 DEBUG CV Batch 1/1500 loss 27.999315 loss_att 35.661011 loss_ctc 33.112839 loss_rnnt 20.482048 hw_loss 0.994336 history loss 25.506323 rank 1
2023-02-11 04:14:21,289 DEBUG CV Batch 1/1600 loss 34.645660 loss_att 71.483070 loss_ctc 44.534657 loss_rnnt 25.326836 hw_loss 0.118651 history loss 25.357674 rank 0
2023-02-11 04:14:21,718 DEBUG CV Batch 1/1600 loss 34.645660 loss_att 71.483070 loss_ctc 44.534657 loss_rnnt 25.326836 hw_loss 0.118651 history loss 25.357674 rank 7
2023-02-11 04:14:21,787 DEBUG CV Batch 1/1600 loss 34.645660 loss_att 71.483070 loss_ctc 44.534657 loss_rnnt 25.326836 hw_loss 0.118651 history loss 25.357674 rank 5
2023-02-11 04:14:22,148 DEBUG CV Batch 1/1600 loss 34.645660 loss_att 71.483070 loss_ctc 44.534657 loss_rnnt 25.326836 hw_loss 0.118651 history loss 25.357674 rank 3
2023-02-11 04:14:23,458 DEBUG CV Batch 1/1600 loss 34.645660 loss_att 71.483070 loss_ctc 44.534657 loss_rnnt 25.326836 hw_loss 0.118651 history loss 25.357674 rank 2
2023-02-11 04:14:24,508 DEBUG CV Batch 1/1600 loss 34.645660 loss_att 71.483070 loss_ctc 44.534657 loss_rnnt 25.326836 hw_loss 0.118651 history loss 25.357674 rank 4
2023-02-11 04:14:24,729 DEBUG CV Batch 1/1600 loss 34.645660 loss_att 71.483070 loss_ctc 44.534657 loss_rnnt 25.326836 hw_loss 0.118651 history loss 25.357674 rank 6
2023-02-11 04:14:25,360 DEBUG CV Batch 1/1600 loss 34.645660 loss_att 71.483070 loss_ctc 44.534657 loss_rnnt 25.326836 hw_loss 0.118651 history loss 25.357674 rank 1
2023-02-11 04:14:33,729 DEBUG CV Batch 1/1700 loss 27.796223 loss_att 30.128176 loss_ctc 35.841122 loss_rnnt 21.015478 hw_loss 0.982819 history loss 25.144972 rank 0
2023-02-11 04:14:34,237 DEBUG CV Batch 1/1700 loss 27.796223 loss_att 30.128176 loss_ctc 35.841122 loss_rnnt 21.015478 hw_loss 0.982819 history loss 25.144972 rank 7
2023-02-11 04:14:34,305 DEBUG CV Batch 1/1700 loss 27.796225 loss_att 30.128176 loss_ctc 35.841122 loss_rnnt 21.015478 hw_loss 0.982819 history loss 25.144972 rank 5
2023-02-11 04:14:34,665 DEBUG CV Batch 1/1700 loss 27.796225 loss_att 30.128176 loss_ctc 35.841122 loss_rnnt 21.015478 hw_loss 0.982819 history loss 25.144972 rank 3
2023-02-11 04:14:35,990 DEBUG CV Batch 1/1700 loss 27.796223 loss_att 30.128176 loss_ctc 35.841122 loss_rnnt 21.015478 hw_loss 0.982819 history loss 25.144972 rank 2
2023-02-11 04:14:37,066 DEBUG CV Batch 1/1700 loss 27.796223 loss_att 30.128176 loss_ctc 35.841122 loss_rnnt 21.015478 hw_loss 0.982819 history loss 25.144972 rank 4
2023-02-11 04:14:37,135 DEBUG CV Batch 1/1700 loss 27.796223 loss_att 30.128176 loss_ctc 35.841122 loss_rnnt 21.015478 hw_loss 0.982819 history loss 25.144972 rank 6
2023-02-11 04:14:37,811 DEBUG CV Batch 1/1700 loss 27.796225 loss_att 30.128176 loss_ctc 35.841122 loss_rnnt 21.015478 hw_loss 0.982819 history loss 25.144972 rank 1
2023-02-11 04:14:42,927 INFO Epoch 1 CV info cv_loss 25.09646499065637
2023-02-11 04:14:42,929 INFO Checkpoint: save to checkpoint exp2_10_rnnt_bias_loss/1.pt
2023-02-11 04:14:43,393 INFO Epoch 1 CV info cv_loss 25.09646497632162
2023-02-11 04:14:43,394 INFO Epoch 2 TRAIN info lr 0.00066636
2023-02-11 04:14:43,396 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 04:14:43,448 INFO Epoch 1 CV info cv_loss 25.09646498024989
2023-02-11 04:14:43,449 INFO Epoch 2 TRAIN info lr 0.00066688
2023-02-11 04:14:43,452 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 04:14:43,528 INFO Epoch 2 TRAIN info lr 0.00066804
2023-02-11 04:14:43,533 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 04:14:43,768 INFO Epoch 1 CV info cv_loss 25.096464996652152
2023-02-11 04:14:43,769 INFO Epoch 2 TRAIN info lr 0.00066664
2023-02-11 04:14:43,772 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 04:14:45,157 INFO Epoch 1 CV info cv_loss 25.0964650138125
2023-02-11 04:14:45,158 INFO Epoch 2 TRAIN info lr 0.0006679199999999999
2023-02-11 04:14:45,162 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 04:14:46,180 INFO Epoch 1 CV info cv_loss 25.096464999271
2023-02-11 04:14:46,182 INFO Epoch 2 TRAIN info lr 0.0006664399999999999
2023-02-11 04:14:46,186 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 04:14:46,232 INFO Epoch 1 CV info cv_loss 25.096465008092384
2023-02-11 04:14:46,233 INFO Epoch 2 TRAIN info lr 0.00066756
2023-02-11 04:14:46,236 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 04:14:47,849 INFO Epoch 1 CV info cv_loss 25.09646500023584
2023-02-11 04:14:47,850 INFO Epoch 2 TRAIN info lr 0.0006686
2023-02-11 04:14:47,854 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 04:16:00,084 DEBUG TRAIN Batch 2/0 loss 18.415234 loss_att 16.375065 loss_ctc 17.323957 loss_rnnt 12.950575 hw_loss 1.128412 lr 0.00066640 rank 7
2023-02-11 04:16:00,087 DEBUG TRAIN Batch 2/0 loss 27.005281 loss_att 24.189531 loss_ctc 27.290070 loss_rnnt 19.583090 hw_loss 1.490132 lr 0.00066808 rank 0
2023-02-11 04:16:00,096 DEBUG TRAIN Batch 2/0 loss 25.609795 loss_att 23.557951 loss_ctc 25.201714 loss_rnnt 20.350033 hw_loss 1.073352 lr 0.00066692 rank 5
2023-02-11 04:16:00,109 DEBUG TRAIN Batch 2/0 loss 26.683014 loss_att 23.820927 loss_ctc 27.697332 loss_rnnt 20.187033 hw_loss 1.299967 lr 0.00066648 rank 4
2023-02-11 04:16:00,110 DEBUG TRAIN Batch 2/0 loss 29.078354 loss_att 27.477913 loss_ctc 34.057007 loss_rnnt 23.912716 hw_loss 0.904108 lr 0.00066668 rank 3
2023-02-11 04:16:00,115 DEBUG TRAIN Batch 2/0 loss 24.816313 loss_att 20.029497 loss_ctc 22.368698 loss_rnnt 17.145552 hw_loss 1.678964 lr 0.00066864 rank 1
2023-02-11 04:16:00,126 DEBUG TRAIN Batch 2/0 loss 30.374628 loss_att 26.905003 loss_ctc 31.220924 loss_rnnt 24.457130 hw_loss 1.218484 lr 0.00066796 rank 2
2023-02-11 04:16:00,166 DEBUG TRAIN Batch 2/0 loss 24.208788 loss_att 19.492905 loss_ctc 23.388327 loss_rnnt 16.012674 hw_loss 1.734129 lr 0.00066760 rank 6
2023-02-11 04:17:14,501 DEBUG TRAIN Batch 2/100 loss 28.820780 loss_att 46.271465 loss_ctc 42.491486 loss_rnnt 22.054449 hw_loss 0.272518 lr 0.00067196 rank 2
2023-02-11 04:17:14,506 DEBUG TRAIN Batch 2/100 loss 68.258652 loss_att 100.195244 loss_ctc 101.728271 loss_rnnt 50.826172 hw_loss 1.234225 lr 0.00067068 rank 3
2023-02-11 04:17:14,507 DEBUG TRAIN Batch 2/100 loss 35.774242 loss_att 54.988083 loss_ctc 52.458565 loss_rnnt 28.256123 hw_loss 0.272019 lr 0.00067208 rank 0
2023-02-11 04:17:14,509 DEBUG TRAIN Batch 2/100 loss 59.421059 loss_att 73.586876 loss_ctc 76.130638 loss_rnnt 52.743359 hw_loss 0.303111 lr 0.00067040 rank 7
2023-02-11 04:17:14,510 DEBUG TRAIN Batch 2/100 loss 38.704468 loss_att 54.765530 loss_ctc 60.587002 loss_rnnt 28.563393 hw_loss 0.752098 lr 0.00067264 rank 1
2023-02-11 04:17:14,510 DEBUG TRAIN Batch 2/100 loss 37.398083 loss_att 56.812973 loss_ctc 50.661633 loss_rnnt 31.126785 hw_loss 0.116221 lr 0.00067160 rank 6
2023-02-11 04:17:14,511 DEBUG TRAIN Batch 2/100 loss 58.211929 loss_att 75.142090 loss_ctc 84.197388 loss_rnnt 48.913254 hw_loss 0.458985 lr 0.00067048 rank 4
2023-02-11 04:17:14,511 DEBUG TRAIN Batch 2/100 loss 50.929688 loss_att 71.076920 loss_ctc 71.513191 loss_rnnt 38.406067 hw_loss 1.078071 lr 0.00067092 rank 5
2023-02-11 04:18:31,311 DEBUG TRAIN Batch 2/200 loss 40.243198 loss_att 71.372391 loss_ctc 65.150208 loss_rnnt 29.590820 hw_loss 0.207301 lr 0.00067468 rank 3
2023-02-11 04:18:31,313 DEBUG TRAIN Batch 2/200 loss 43.407494 loss_att 70.031380 loss_ctc 68.516403 loss_rnnt 31.113064 hw_loss 0.679087 lr 0.00067608 rank 0
2023-02-11 04:18:31,314 DEBUG TRAIN Batch 2/200 loss 54.571785 loss_att 71.598145 loss_ctc 61.831482 loss_rnnt 46.103188 hw_loss 0.767881 lr 0.00067664 rank 1
2023-02-11 04:18:31,313 DEBUG TRAIN Batch 2/200 loss 32.482330 loss_att 48.272530 loss_ctc 45.998672 loss_rnnt 24.461926 hw_loss 0.573786 lr 0.00067492 rank 5
2023-02-11 04:18:31,317 DEBUG TRAIN Batch 2/200 loss 43.907623 loss_att 62.741207 loss_ctc 60.514008 loss_rnnt 35.067665 hw_loss 0.536072 lr 0.00067448 rank 4
2023-02-11 04:18:31,317 DEBUG TRAIN Batch 2/200 loss 40.848026 loss_att 61.557289 loss_ctc 52.294243 loss_rnnt 33.895306 hw_loss 0.240883 lr 0.00067440 rank 7
2023-02-11 04:18:31,318 DEBUG TRAIN Batch 2/200 loss 61.560719 loss_att 82.966125 loss_ctc 86.903336 loss_rnnt 50.835815 hw_loss 0.574651 lr 0.00067596 rank 2
2023-02-11 04:18:31,363 DEBUG TRAIN Batch 2/200 loss 30.173288 loss_att 52.109261 loss_ctc 55.018341 loss_rnnt 20.578520 hw_loss 0.355294 lr 0.00067560 rank 6
2023-02-11 04:19:48,365 DEBUG TRAIN Batch 2/300 loss 41.215260 loss_att 54.768654 loss_ctc 55.505627 loss_rnnt 32.860764 hw_loss 0.700956 lr 0.00068008 rank 0
2023-02-11 04:19:48,369 DEBUG TRAIN Batch 2/300 loss 30.340134 loss_att 44.117455 loss_ctc 43.620144 loss_rnnt 22.540985 hw_loss 0.613691 lr 0.00067840 rank 7
2023-02-11 04:19:48,369 DEBUG TRAIN Batch 2/300 loss 50.857086 loss_att 66.220581 loss_ctc 67.823395 loss_rnnt 41.679405 hw_loss 0.720527 lr 0.00067892 rank 5
2023-02-11 04:19:48,371 DEBUG TRAIN Batch 2/300 loss 34.888294 loss_att 48.091942 loss_ctc 49.259758 loss_rnnt 26.701506 hw_loss 0.680600 lr 0.00067848 rank 4
2023-02-11 04:19:48,371 DEBUG TRAIN Batch 2/300 loss 48.698162 loss_att 69.497520 loss_ctc 61.153976 loss_rnnt 40.264877 hw_loss 0.489869 lr 0.00067868 rank 3
2023-02-11 04:19:48,375 DEBUG TRAIN Batch 2/300 loss 35.017902 loss_att 48.596001 loss_ctc 43.962288 loss_rnnt 27.997181 hw_loss 0.583596 lr 0.00068064 rank 1
2023-02-11 04:19:48,375 DEBUG TRAIN Batch 2/300 loss 36.865749 loss_att 52.806255 loss_ctc 51.870720 loss_rnnt 28.466358 hw_loss 0.601993 lr 0.00067960 rank 6
2023-02-11 04:19:48,376 DEBUG TRAIN Batch 2/300 loss 35.737217 loss_att 56.018307 loss_ctc 53.444321 loss_rnnt 28.450607 hw_loss 0.163020 lr 0.00067996 rank 2
2023-02-11 04:21:06,078 DEBUG TRAIN Batch 2/400 loss 49.227402 loss_att 57.223469 loss_ctc 65.221809 loss_rnnt 40.906929 hw_loss 0.860377 lr 0.00068408 rank 0
2023-02-11 04:21:06,078 DEBUG TRAIN Batch 2/400 loss 47.916599 loss_att 57.735649 loss_ctc 60.384212 loss_rnnt 39.650093 hw_loss 0.870066 lr 0.00068268 rank 3
2023-02-11 04:21:06,080 DEBUG TRAIN Batch 2/400 loss 27.200529 loss_att 38.239391 loss_ctc 33.927635 loss_rnnt 21.543642 hw_loss 0.478531 lr 0.00068396 rank 2
2023-02-11 04:21:06,080 DEBUG TRAIN Batch 2/400 loss 44.362598 loss_att 59.053406 loss_ctc 61.650894 loss_rnnt 35.015640 hw_loss 0.769443 lr 0.00068292 rank 5
2023-02-11 04:21:06,081 DEBUG TRAIN Batch 2/400 loss 49.158493 loss_att 61.889565 loss_ctc 61.499554 loss_rnnt 41.687317 hw_loss 0.614903 lr 0.00068240 rank 7
2023-02-11 04:21:06,082 DEBUG TRAIN Batch 2/400 loss 42.832275 loss_att 60.168549 loss_ctc 56.815300 loss_rnnt 35.158543 hw_loss 0.439139 lr 0.00068248 rank 4
2023-02-11 04:21:06,083 DEBUG TRAIN Batch 2/400 loss 42.094128 loss_att 55.406723 loss_ctc 63.481064 loss_rnnt 34.448944 hw_loss 0.399576 lr 0.00068360 rank 6
2023-02-11 04:21:06,087 DEBUG TRAIN Batch 2/400 loss 33.897999 loss_att 46.963982 loss_ctc 43.671101 loss_rnnt 27.431541 hw_loss 0.478159 lr 0.00068464 rank 1
2023-02-11 04:22:22,322 DEBUG TRAIN Batch 2/500 loss 25.584259 loss_att 40.176613 loss_ctc 34.989487 loss_rnnt 18.944809 hw_loss 0.462553 lr 0.00068668 rank 3
2023-02-11 04:22:22,324 DEBUG TRAIN Batch 2/500 loss 52.578064 loss_att 69.150269 loss_ctc 72.796646 loss_rnnt 41.360298 hw_loss 0.976409 lr 0.00068692 rank 5
2023-02-11 04:22:22,326 DEBUG TRAIN Batch 2/500 loss 49.470657 loss_att 59.776775 loss_ctc 74.732193 loss_rnnt 42.164215 hw_loss 0.351940 lr 0.00068808 rank 0
2023-02-11 04:22:22,328 DEBUG TRAIN Batch 2/500 loss 42.849030 loss_att 48.038834 loss_ctc 55.415604 loss_rnnt 36.561874 hw_loss 0.670059 lr 0.00068648 rank 4
2023-02-11 04:22:22,328 DEBUG TRAIN Batch 2/500 loss 33.526695 loss_att 49.012814 loss_ctc 41.193733 loss_rnnt 26.631744 hw_loss 0.520398 lr 0.00068640 rank 7
2023-02-11 04:22:22,328 DEBUG TRAIN Batch 2/500 loss 37.443069 loss_att 44.692284 loss_ctc 52.796703 loss_rnnt 30.483093 hw_loss 0.649309 lr 0.00068760 rank 6
2023-02-11 04:22:22,335 DEBUG TRAIN Batch 2/500 loss 56.365536 loss_att 72.932915 loss_ctc 77.461739 loss_rnnt 45.860573 hw_loss 0.820998 lr 0.00068796 rank 2
2023-02-11 04:22:22,345 DEBUG TRAIN Batch 2/500 loss 51.893940 loss_att 66.619942 loss_ctc 66.231865 loss_rnnt 43.540588 hw_loss 0.655579 lr 0.00068864 rank 1
2023-02-11 04:23:39,327 DEBUG TRAIN Batch 2/600 loss 38.343430 loss_att 41.707230 loss_ctc 47.159946 loss_rnnt 31.065006 hw_loss 1.018149 lr 0.00069208 rank 0
2023-02-11 04:23:39,331 DEBUG TRAIN Batch 2/600 loss 33.703465 loss_att 35.710678 loss_ctc 41.214783 loss_rnnt 28.284500 hw_loss 0.753002 lr 0.00069040 rank 7
2023-02-11 04:23:39,334 DEBUG TRAIN Batch 2/600 loss 45.924747 loss_att 52.400352 loss_ctc 60.815449 loss_rnnt 39.356762 hw_loss 0.616395 lr 0.00069092 rank 5
2023-02-11 04:23:39,336 DEBUG TRAIN Batch 2/600 loss 35.609837 loss_att 42.638084 loss_ctc 48.800282 loss_rnnt 30.020739 hw_loss 0.454636 lr 0.00069196 rank 2
2023-02-11 04:23:39,335 DEBUG TRAIN Batch 2/600 loss 52.476154 loss_att 59.272469 loss_ctc 77.537209 loss_rnnt 45.826813 hw_loss 0.365363 lr 0.00069068 rank 3
2023-02-11 04:23:39,337 DEBUG TRAIN Batch 2/600 loss 41.402340 loss_att 44.505840 loss_ctc 46.700558 loss_rnnt 35.675240 hw_loss 0.824995 lr 0.00069048 rank 4
2023-02-11 04:23:39,339 DEBUG TRAIN Batch 2/600 loss 45.492229 loss_att 50.891327 loss_ctc 52.955620 loss_rnnt 38.107330 hw_loss 0.995618 lr 0.00069264 rank 1
2023-02-11 04:23:39,386 DEBUG TRAIN Batch 2/600 loss 33.501423 loss_att 40.152016 loss_ctc 42.692551 loss_rnnt 27.111813 hw_loss 0.718877 lr 0.00069160 rank 6
2023-02-11 04:24:59,286 DEBUG TRAIN Batch 2/700 loss 39.439453 loss_att 58.445557 loss_ctc 50.361675 loss_rnnt 31.617146 hw_loss 0.480897 lr 0.00069664 rank 1
2023-02-11 04:24:59,288 DEBUG TRAIN Batch 2/700 loss 43.118423 loss_att 60.556484 loss_ctc 59.472595 loss_rnnt 34.137352 hw_loss 0.621170 lr 0.00069560 rank 6
2023-02-11 04:24:59,288 DEBUG TRAIN Batch 2/700 loss 41.620396 loss_att 68.865303 loss_ctc 50.521278 loss_rnnt 31.407173 hw_loss 0.670774 lr 0.00069468 rank 3
2023-02-11 04:24:59,289 DEBUG TRAIN Batch 2/700 loss 38.258202 loss_att 56.635494 loss_ctc 46.275452 loss_rnnt 30.987103 hw_loss 0.473752 lr 0.00069608 rank 0
2023-02-11 04:24:59,289 DEBUG TRAIN Batch 2/700 loss 53.556168 loss_att 72.548744 loss_ctc 71.581619 loss_rnnt 43.661983 hw_loss 0.692302 lr 0.00069440 rank 7
2023-02-11 04:24:59,289 DEBUG TRAIN Batch 2/700 loss 61.509548 loss_att 85.579407 loss_ctc 78.306786 loss_rnnt 51.435879 hw_loss 0.566263 lr 0.00069448 rank 4
2023-02-11 04:24:59,294 DEBUG TRAIN Batch 2/700 loss 33.132210 loss_att 49.466232 loss_ctc 51.835373 loss_rnnt 24.425856 hw_loss 0.552337 lr 0.00069492 rank 5
2023-02-11 04:24:59,294 DEBUG TRAIN Batch 2/700 loss 47.936436 loss_att 83.906837 loss_ctc 75.122147 loss_rnnt 35.587791 hw_loss 0.286838 lr 0.00069596 rank 2
2023-02-11 04:26:14,704 DEBUG TRAIN Batch 2/800 loss 39.419098 loss_att 56.396477 loss_ctc 53.489510 loss_rnnt 31.696373 hw_loss 0.459598 lr 0.00069840 rank 7
2023-02-11 04:26:14,704 DEBUG TRAIN Batch 2/800 loss 43.529030 loss_att 58.932732 loss_ctc 56.086494 loss_rnnt 36.960171 hw_loss 0.340086 lr 0.00069868 rank 3
2023-02-11 04:26:14,708 DEBUG TRAIN Batch 2/800 loss 42.632725 loss_att 59.723145 loss_ctc 63.804016 loss_rnnt 33.745743 hw_loss 0.496135 lr 0.00069892 rank 5
2023-02-11 04:26:14,708 DEBUG TRAIN Batch 2/800 loss 36.094440 loss_att 44.707077 loss_ctc 58.804821 loss_rnnt 29.602428 hw_loss 0.326519 lr 0.00069848 rank 4
2023-02-11 04:26:14,713 DEBUG TRAIN Batch 2/800 loss 25.381773 loss_att 41.943943 loss_ctc 43.277401 loss_rnnt 18.526119 hw_loss 0.216963 lr 0.00069960 rank 6
2023-02-11 04:26:14,715 DEBUG TRAIN Batch 2/800 loss 38.181416 loss_att 62.694595 loss_ctc 49.756805 loss_rnnt 29.605495 hw_loss 0.399356 lr 0.00070008 rank 0
2023-02-11 04:26:14,715 DEBUG TRAIN Batch 2/800 loss 52.960690 loss_att 71.485703 loss_ctc 70.252319 loss_rnnt 42.873390 hw_loss 0.764390 lr 0.00069996 rank 2
2023-02-11 04:26:14,763 DEBUG TRAIN Batch 2/800 loss 37.765354 loss_att 52.617298 loss_ctc 49.612259 loss_rnnt 29.033009 hw_loss 0.784194 lr 0.00070064 rank 1
2023-02-11 04:27:30,832 DEBUG TRAIN Batch 2/900 loss 41.350441 loss_att 52.512466 loss_ctc 54.232994 loss_rnnt 33.146927 hw_loss 0.797519 lr 0.00070240 rank 7
2023-02-11 04:27:30,832 DEBUG TRAIN Batch 2/900 loss 42.812183 loss_att 55.908424 loss_ctc 57.048355 loss_rnnt 36.203213 hw_loss 0.392169 lr 0.00070268 rank 3
2023-02-11 04:27:30,833 DEBUG TRAIN Batch 2/900 loss 45.711021 loss_att 63.118393 loss_ctc 65.709305 loss_rnnt 36.710724 hw_loss 0.534823 lr 0.00070396 rank 2
2023-02-11 04:27:30,837 DEBUG TRAIN Batch 2/900 loss 39.375931 loss_att 58.611217 loss_ctc 57.721062 loss_rnnt 31.663382 hw_loss 0.266152 lr 0.00070464 rank 1
2023-02-11 04:27:30,840 DEBUG TRAIN Batch 2/900 loss 56.403606 loss_att 63.919464 loss_ctc 62.946320 loss_rnnt 50.634392 hw_loss 0.636315 lr 0.00070292 rank 5
2023-02-11 04:27:30,842 DEBUG TRAIN Batch 2/900 loss 29.067078 loss_att 43.942234 loss_ctc 45.605282 loss_rnnt 22.516861 hw_loss 0.256892 lr 0.00070408 rank 0
2023-02-11 04:27:30,849 DEBUG TRAIN Batch 2/900 loss 50.930000 loss_att 55.578716 loss_ctc 61.753288 loss_rnnt 44.846817 hw_loss 0.695688 lr 0.00070360 rank 6
2023-02-11 04:27:30,887 DEBUG TRAIN Batch 2/900 loss 55.069927 loss_att 69.490608 loss_ctc 74.314651 loss_rnnt 46.586124 hw_loss 0.568819 lr 0.00070248 rank 4
2023-02-11 04:28:47,330 DEBUG TRAIN Batch 2/1000 loss 62.331871 loss_att 80.458099 loss_ctc 83.909912 loss_rnnt 52.164154 hw_loss 0.687263 lr 0.00070668 rank 3
2023-02-11 04:28:47,330 DEBUG TRAIN Batch 2/1000 loss 39.341038 loss_att 51.107071 loss_ctc 54.995090 loss_rnnt 32.850307 hw_loss 0.384435 lr 0.00070692 rank 5
2023-02-11 04:28:47,331 DEBUG TRAIN Batch 2/1000 loss 52.117989 loss_att 57.406223 loss_ctc 63.844185 loss_rnnt 46.322800 hw_loss 0.595134 lr 0.00070648 rank 4
2023-02-11 04:28:47,331 DEBUG TRAIN Batch 2/1000 loss 78.764381 loss_att 88.628120 loss_ctc 105.541290 loss_rnnt 72.063438 hw_loss 0.217113 lr 0.00070796 rank 2
2023-02-11 04:28:47,334 DEBUG TRAIN Batch 2/1000 loss 71.789978 loss_att 92.717072 loss_ctc 95.979942 loss_rnnt 60.755436 hw_loss 0.679460 lr 0.00070808 rank 0
2023-02-11 04:28:47,335 DEBUG TRAIN Batch 2/1000 loss 48.446732 loss_att 61.691788 loss_ctc 65.953133 loss_rnnt 40.379852 hw_loss 0.578190 lr 0.00070760 rank 6
2023-02-11 04:28:47,337 DEBUG TRAIN Batch 2/1000 loss 42.536713 loss_att 55.022575 loss_ctc 63.465309 loss_rnnt 33.886627 hw_loss 0.630456 lr 0.00070640 rank 7
2023-02-11 04:28:47,342 DEBUG TRAIN Batch 2/1000 loss 33.396580 loss_att 43.483788 loss_ctc 48.352158 loss_rnnt 26.470856 hw_loss 0.546413 lr 0.00070864 rank 1
2023-02-11 04:30:05,685 DEBUG TRAIN Batch 2/1100 loss 44.433990 loss_att 64.491631 loss_ctc 62.339333 loss_rnnt 35.650715 hw_loss 0.447069 lr 0.00071208 rank 0
2023-02-11 04:30:05,686 DEBUG TRAIN Batch 2/1100 loss 42.118122 loss_att 49.855759 loss_ctc 51.024509 loss_rnnt 37.305664 hw_loss 0.389515 lr 0.00071092 rank 5
2023-02-11 04:30:05,687 DEBUG TRAIN Batch 2/1100 loss 40.265980 loss_att 51.683224 loss_ctc 54.292183 loss_rnnt 34.082253 hw_loss 0.380647 lr 0.00071068 rank 3
2023-02-11 04:30:05,687 DEBUG TRAIN Batch 2/1100 loss 37.354546 loss_att 52.784882 loss_ctc 54.289284 loss_rnnt 30.640541 hw_loss 0.256869 lr 0.00071040 rank 7
2023-02-11 04:30:05,690 DEBUG TRAIN Batch 2/1100 loss 35.498749 loss_att 46.748943 loss_ctc 57.097214 loss_rnnt 29.083021 hw_loss 0.241105 lr 0.00071264 rank 1
2023-02-11 04:30:05,690 DEBUG TRAIN Batch 2/1100 loss 24.163908 loss_att 33.442986 loss_ctc 31.718384 loss_rnnt 20.181473 hw_loss 0.209880 lr 0.00071160 rank 6
2023-02-11 04:30:05,692 DEBUG TRAIN Batch 2/1100 loss 28.658585 loss_att 36.545036 loss_ctc 43.864716 loss_rnnt 24.743950 hw_loss 0.058098 lr 0.00071196 rank 2
2023-02-11 04:30:05,697 DEBUG TRAIN Batch 2/1100 loss 45.627403 loss_att 63.438961 loss_ctc 68.535614 loss_rnnt 37.371803 hw_loss 0.307286 lr 0.00071048 rank 4
2023-02-11 04:31:21,095 DEBUG TRAIN Batch 2/1200 loss 38.477577 loss_att 46.131096 loss_ctc 45.666042 loss_rnnt 32.409588 hw_loss 0.671029 lr 0.00071468 rank 3
2023-02-11 04:31:21,096 DEBUG TRAIN Batch 2/1200 loss 25.017035 loss_att 33.341599 loss_ctc 35.929138 loss_rnnt 18.230577 hw_loss 0.687487 lr 0.00071664 rank 1
2023-02-11 04:31:21,097 DEBUG TRAIN Batch 2/1200 loss 35.686703 loss_att 39.982605 loss_ctc 50.571709 loss_rnnt 27.308136 hw_loss 1.037760 lr 0.00071448 rank 4
2023-02-11 04:31:21,099 DEBUG TRAIN Batch 2/1200 loss 40.878513 loss_att 45.738773 loss_ctc 53.359009 loss_rnnt 34.722107 hw_loss 0.660054 lr 0.00071492 rank 5
2023-02-11 04:31:21,100 DEBUG TRAIN Batch 2/1200 loss 29.491930 loss_att 31.348867 loss_ctc 37.225250 loss_rnnt 23.871922 hw_loss 0.790783 lr 0.00071608 rank 0
2023-02-11 04:31:21,101 DEBUG TRAIN Batch 2/1200 loss 42.833553 loss_att 52.862984 loss_ctc 55.002621 loss_rnnt 35.131081 hw_loss 0.763884 lr 0.00071596 rank 2
2023-02-11 04:31:21,103 DEBUG TRAIN Batch 2/1200 loss 44.584877 loss_att 50.174255 loss_ctc 59.766014 loss_rnnt 36.455185 hw_loss 0.935187 lr 0.00071440 rank 7
2023-02-11 04:31:21,103 DEBUG TRAIN Batch 2/1200 loss 51.323189 loss_att 61.031166 loss_ctc 66.273598 loss_rnnt 45.433754 hw_loss 0.366458 lr 0.00071560 rank 6
2023-02-11 04:32:36,477 DEBUG TRAIN Batch 2/1300 loss 62.507401 loss_att 85.106041 loss_ctc 89.489349 loss_rnnt 51.952354 hw_loss 0.457073 lr 0.00071848 rank 4
2023-02-11 04:32:36,477 DEBUG TRAIN Batch 2/1300 loss 36.292538 loss_att 47.948929 loss_ctc 42.547771 loss_rnnt 30.578344 hw_loss 0.477916 lr 0.00072064 rank 1
2023-02-11 04:32:36,480 DEBUG TRAIN Batch 2/1300 loss 33.392094 loss_att 50.394512 loss_ctc 50.394409 loss_rnnt 26.199171 hw_loss 0.286025 lr 0.00072008 rank 0
2023-02-11 04:32:36,481 DEBUG TRAIN Batch 2/1300 loss 34.560440 loss_att 50.386391 loss_ctc 45.171036 loss_rnnt 27.621685 hw_loss 0.442279 lr 0.00071868 rank 3
2023-02-11 04:32:36,484 DEBUG TRAIN Batch 2/1300 loss 36.617851 loss_att 61.977943 loss_ctc 44.212597 loss_rnnt 26.429785 hw_loss 0.769390 lr 0.00071892 rank 5
2023-02-11 04:32:36,485 DEBUG TRAIN Batch 2/1300 loss 43.036263 loss_att 55.506306 loss_ctc 53.168663 loss_rnnt 36.097672 hw_loss 0.580049 lr 0.00071840 rank 7
2023-02-11 04:32:36,489 DEBUG TRAIN Batch 2/1300 loss 36.218536 loss_att 54.055756 loss_ctc 52.864159 loss_rnnt 28.773037 hw_loss 0.310995 lr 0.00071960 rank 6
2023-02-11 04:32:36,525 DEBUG TRAIN Batch 2/1300 loss 59.500065 loss_att 77.820480 loss_ctc 73.834335 loss_rnnt 51.063454 hw_loss 0.536491 lr 0.00071996 rank 2
2023-02-11 04:33:54,464 DEBUG TRAIN Batch 2/1400 loss 34.017162 loss_att 44.958252 loss_ctc 44.696548 loss_rnnt 24.905487 hw_loss 1.031164 lr 0.00072396 rank 2
2023-02-11 04:33:54,466 DEBUG TRAIN Batch 2/1400 loss 37.870953 loss_att 51.006397 loss_ctc 47.893875 loss_rnnt 28.797407 hw_loss 0.958137 lr 0.00072240 rank 7
2023-02-11 04:33:54,467 DEBUG TRAIN Batch 2/1400 loss 42.339985 loss_att 53.718498 loss_ctc 56.365730 loss_rnnt 35.050632 hw_loss 0.589415 lr 0.00072360 rank 6
2023-02-11 04:33:54,467 DEBUG TRAIN Batch 2/1400 loss 29.620874 loss_att 44.594067 loss_ctc 41.541019 loss_rnnt 22.651281 hw_loss 0.447301 lr 0.00072268 rank 3
2023-02-11 04:33:54,469 DEBUG TRAIN Batch 2/1400 loss 38.490047 loss_att 52.785614 loss_ctc 55.551739 loss_rnnt 31.438137 hw_loss 0.359608 lr 0.00072248 rank 4
2023-02-11 04:33:54,469 DEBUG TRAIN Batch 2/1400 loss 58.253384 loss_att 74.650063 loss_ctc 84.581314 loss_rnnt 47.257782 hw_loss 0.788602 lr 0.00072408 rank 0
2023-02-11 04:33:54,471 DEBUG TRAIN Batch 2/1400 loss 40.001968 loss_att 48.147926 loss_ctc 48.655930 loss_rnnt 33.223541 hw_loss 0.749132 lr 0.00072464 rank 1
2023-02-11 04:33:54,470 DEBUG TRAIN Batch 2/1400 loss 35.075066 loss_att 51.260002 loss_ctc 45.757217 loss_rnnt 26.409504 hw_loss 0.750804 lr 0.00072292 rank 5
2023-02-11 04:35:13,642 DEBUG TRAIN Batch 2/1500 loss 38.759869 loss_att 53.743439 loss_ctc 53.599846 loss_rnnt 30.445320 hw_loss 0.626094 lr 0.00072808 rank 0
2023-02-11 04:35:13,645 DEBUG TRAIN Batch 2/1500 loss 53.397808 loss_att 79.907150 loss_ctc 77.527649 loss_rnnt 43.579163 hw_loss 0.243650 lr 0.00072640 rank 7
2023-02-11 04:35:13,646 DEBUG TRAIN Batch 2/1500 loss 45.352455 loss_att 57.622562 loss_ctc 61.795097 loss_rnnt 38.815365 hw_loss 0.354509 lr 0.00072796 rank 2
2023-02-11 04:35:13,647 DEBUG TRAIN Batch 2/1500 loss 34.938011 loss_att 54.252274 loss_ctc 46.367825 loss_rnnt 27.273758 hw_loss 0.427017 lr 0.00072692 rank 5
2023-02-11 04:35:13,648 DEBUG TRAIN Batch 2/1500 loss 57.588917 loss_att 70.482018 loss_ctc 73.441742 loss_rnnt 50.674316 hw_loss 0.416675 lr 0.00072668 rank 3
2023-02-11 04:35:13,654 DEBUG TRAIN Batch 2/1500 loss 28.860926 loss_att 46.549213 loss_ctc 42.564034 loss_rnnt 21.172415 hw_loss 0.435708 lr 0.00072760 rank 6
2023-02-11 04:35:13,657 DEBUG TRAIN Batch 2/1500 loss 52.539787 loss_att 68.864525 loss_ctc 68.230232 loss_rnnt 43.283016 hw_loss 0.731205 lr 0.00072648 rank 4
2023-02-11 04:35:13,696 DEBUG TRAIN Batch 2/1500 loss 52.404408 loss_att 66.605240 loss_ctc 61.126350 loss_rnnt 46.008289 hw_loss 0.448691 lr 0.00072864 rank 1
2023-02-11 04:36:28,843 DEBUG TRAIN Batch 2/1600 loss 50.293781 loss_att 58.071426 loss_ctc 66.359810 loss_rnnt 44.325390 hw_loss 0.425761 lr 0.00073048 rank 4
2023-02-11 04:36:28,844 DEBUG TRAIN Batch 2/1600 loss 61.961617 loss_att 70.434868 loss_ctc 77.815628 loss_rnnt 55.005898 hw_loss 0.590099 lr 0.00073196 rank 2
2023-02-11 04:36:28,844 DEBUG TRAIN Batch 2/1600 loss 62.643066 loss_att 69.919342 loss_ctc 88.165710 loss_rnnt 56.569649 hw_loss 0.227839 lr 0.00073208 rank 0
2023-02-11 04:36:28,848 DEBUG TRAIN Batch 2/1600 loss 39.629826 loss_att 59.231361 loss_ctc 49.496971 loss_rnnt 29.991709 hw_loss 0.825410 lr 0.00073068 rank 3
2023-02-11 04:36:28,848 DEBUG TRAIN Batch 2/1600 loss 49.547722 loss_att 69.635803 loss_ctc 78.323318 loss_rnnt 40.374390 hw_loss 0.247306 lr 0.00073092 rank 5
2023-02-11 04:36:28,848 DEBUG TRAIN Batch 2/1600 loss 42.756119 loss_att 63.720612 loss_ctc 59.449226 loss_rnnt 34.760384 hw_loss 0.295704 lr 0.00073160 rank 6
2023-02-11 04:36:28,849 DEBUG TRAIN Batch 2/1600 loss 51.728622 loss_att 62.731346 loss_ctc 68.764061 loss_rnnt 45.357754 hw_loss 0.356050 lr 0.00073264 rank 1
2023-02-11 04:36:28,849 DEBUG TRAIN Batch 2/1600 loss 34.036419 loss_att 45.250149 loss_ctc 48.592186 loss_rnnt 27.434872 hw_loss 0.453382 lr 0.00073040 rank 7
2023-02-11 04:37:46,415 DEBUG TRAIN Batch 2/1700 loss 34.276970 loss_att 43.455547 loss_ctc 39.124237 loss_rnnt 26.467785 hw_loss 0.998845 lr 0.00073440 rank 7
2023-02-11 04:37:46,416 DEBUG TRAIN Batch 2/1700 loss 43.160004 loss_att 49.288200 loss_ctc 56.947964 loss_rnnt 38.248901 hw_loss 0.346325 lr 0.00073492 rank 5
2023-02-11 04:37:46,417 DEBUG TRAIN Batch 2/1700 loss 40.496498 loss_att 51.731758 loss_ctc 51.780083 loss_rnnt 31.129593 hw_loss 1.052882 lr 0.00073468 rank 3
2023-02-11 04:37:46,419 DEBUG TRAIN Batch 2/1700 loss 69.003708 loss_att 87.789398 loss_ctc 95.818359 loss_rnnt 57.803436 hw_loss 0.725222 lr 0.00073664 rank 1
2023-02-11 04:37:46,421 DEBUG TRAIN Batch 2/1700 loss 44.730118 loss_att 59.786720 loss_ctc 62.452190 loss_rnnt 35.378891 hw_loss 0.745679 lr 0.00073608 rank 0
2023-02-11 04:37:46,420 DEBUG TRAIN Batch 2/1700 loss 40.562531 loss_att 54.249718 loss_ctc 51.056061 loss_rnnt 32.821415 hw_loss 0.675851 lr 0.00073596 rank 2
2023-02-11 04:37:46,437 DEBUG TRAIN Batch 2/1700 loss 38.109936 loss_att 50.163387 loss_ctc 54.551903 loss_rnnt 29.826309 hw_loss 0.690126 lr 0.00073560 rank 6
2023-02-11 04:37:46,450 DEBUG TRAIN Batch 2/1700 loss 46.272274 loss_att 51.726982 loss_ctc 59.148212 loss_rnnt 38.846603 hw_loss 0.865863 lr 0.00073448 rank 4
2023-02-11 04:39:04,613 DEBUG TRAIN Batch 2/1800 loss 46.347912 loss_att 51.319023 loss_ctc 61.322304 loss_rnnt 39.852821 hw_loss 0.657053 lr 0.00073840 rank 7
2023-02-11 04:39:04,615 DEBUG TRAIN Batch 2/1800 loss 41.584774 loss_att 58.920605 loss_ctc 59.841534 loss_rnnt 33.142239 hw_loss 0.476462 lr 0.00073996 rank 2
2023-02-11 04:39:04,618 DEBUG TRAIN Batch 2/1800 loss 26.483107 loss_att 31.034039 loss_ctc 38.812855 loss_rnnt 20.212952 hw_loss 0.696751 lr 0.00074008 rank 0
2023-02-11 04:39:04,620 DEBUG TRAIN Batch 2/1800 loss 48.909069 loss_att 53.000015 loss_ctc 59.961353 loss_rnnt 42.118858 hw_loss 0.843448 lr 0.00073960 rank 6
2023-02-11 04:39:04,620 DEBUG TRAIN Batch 2/1800 loss 32.483093 loss_att 40.203762 loss_ctc 47.138882 loss_rnnt 22.869354 hw_loss 1.146656 lr 0.00074064 rank 1
2023-02-11 04:39:04,622 DEBUG TRAIN Batch 2/1800 loss 29.718851 loss_att 34.486511 loss_ctc 37.473522 loss_rnnt 24.330103 hw_loss 0.637736 lr 0.00073892 rank 5
2023-02-11 04:39:04,624 DEBUG TRAIN Batch 2/1800 loss 33.402012 loss_att 39.640488 loss_ctc 43.287022 loss_rnnt 27.110992 hw_loss 0.698498 lr 0.00073868 rank 3
2023-02-11 04:39:04,627 DEBUG TRAIN Batch 2/1800 loss 42.173168 loss_att 53.973660 loss_ctc 55.800690 loss_rnnt 33.380432 hw_loss 0.865432 lr 0.00073848 rank 4
2023-02-11 04:40:19,977 DEBUG TRAIN Batch 2/1900 loss 25.031403 loss_att 23.351168 loss_ctc 29.161409 loss_rnnt 19.504612 hw_loss 0.996032 lr 0.00074240 rank 7
2023-02-11 04:40:19,977 DEBUG TRAIN Batch 2/1900 loss 31.737818 loss_att 37.790810 loss_ctc 43.900917 loss_rnnt 24.249247 hw_loss 0.873043 lr 0.00074268 rank 3
2023-02-11 04:40:19,979 DEBUG TRAIN Batch 2/1900 loss 36.881844 loss_att 56.382339 loss_ctc 50.778057 loss_rnnt 28.010252 hw_loss 0.584749 lr 0.00074408 rank 0
2023-02-11 04:40:19,980 DEBUG TRAIN Batch 2/1900 loss 34.364830 loss_att 46.782326 loss_ctc 49.633629 loss_rnnt 28.289074 hw_loss 0.291828 lr 0.00074464 rank 1
2023-02-11 04:40:19,981 DEBUG TRAIN Batch 2/1900 loss 26.351116 loss_att 20.385242 loss_ctc 24.064610 loss_rnnt 18.179838 hw_loss 1.812997 lr 0.00074396 rank 2
2023-02-11 04:40:19,982 DEBUG TRAIN Batch 2/1900 loss 24.954514 loss_att 21.599689 loss_ctc 25.006590 loss_rnnt 18.694908 hw_loss 1.298180 lr 0.00074360 rank 6
2023-02-11 04:40:19,985 DEBUG TRAIN Batch 2/1900 loss 24.495010 loss_att 23.295719 loss_ctc 27.945539 loss_rnnt 18.738558 hw_loss 1.038045 lr 0.00074248 rank 4
2023-02-11 04:40:19,984 DEBUG TRAIN Batch 2/1900 loss 37.309845 loss_att 51.285923 loss_ctc 52.642502 loss_rnnt 29.095455 hw_loss 0.632779 lr 0.00074292 rank 5
2023-02-11 04:41:35,560 DEBUG TRAIN Batch 2/2000 loss 57.769222 loss_att 82.788116 loss_ctc 80.381226 loss_rnnt 47.077206 hw_loss 0.501244 lr 0.00074668 rank 3
2023-02-11 04:41:35,562 DEBUG TRAIN Batch 2/2000 loss 65.563835 loss_att 78.748863 loss_ctc 87.945679 loss_rnnt 56.591686 hw_loss 0.628295 lr 0.00074692 rank 5
2023-02-11 04:41:35,564 DEBUG TRAIN Batch 2/2000 loss 44.721367 loss_att 56.921661 loss_ctc 61.078194 loss_rnnt 37.541367 hw_loss 0.479819 lr 0.00074808 rank 0
2023-02-11 04:41:35,564 DEBUG TRAIN Batch 2/2000 loss 51.604172 loss_att 69.367767 loss_ctc 70.287949 loss_rnnt 43.949623 hw_loss 0.301999 lr 0.00074796 rank 2
2023-02-11 04:41:35,566 DEBUG TRAIN Batch 2/2000 loss 25.278240 loss_att 38.493484 loss_ctc 37.863308 loss_rnnt 18.011551 hw_loss 0.552305 lr 0.00074864 rank 1
2023-02-11 04:41:35,565 DEBUG TRAIN Batch 2/2000 loss 33.895805 loss_att 49.120197 loss_ctc 45.565628 loss_rnnt 25.530956 hw_loss 0.705749 lr 0.00074640 rank 7
2023-02-11 04:41:35,569 DEBUG TRAIN Batch 2/2000 loss 60.149818 loss_att 80.699089 loss_ctc 86.235458 loss_rnnt 52.510307 hw_loss 0.009670 lr 0.00074648 rank 4
2023-02-11 04:41:35,575 DEBUG TRAIN Batch 2/2000 loss 50.444824 loss_att 65.742905 loss_ctc 70.854454 loss_rnnt 42.000671 hw_loss 0.499360 lr 0.00074760 rank 6
2023-02-11 04:42:53,536 DEBUG TRAIN Batch 2/2100 loss 39.266266 loss_att 63.702988 loss_ctc 56.251831 loss_rnnt 29.642920 hw_loss 0.463362 lr 0.00075160 rank 6
2023-02-11 04:42:53,536 DEBUG TRAIN Batch 2/2100 loss 38.703629 loss_att 46.740891 loss_ctc 56.528381 loss_rnnt 31.653652 hw_loss 0.574855 lr 0.00075208 rank 0
2023-02-11 04:42:53,541 DEBUG TRAIN Batch 2/2100 loss 32.767681 loss_att 43.460026 loss_ctc 45.875885 loss_rnnt 26.876471 hw_loss 0.375933 lr 0.00075040 rank 7
2023-02-11 04:42:53,541 DEBUG TRAIN Batch 2/2100 loss 31.142672 loss_att 38.774460 loss_ctc 50.533737 loss_rnnt 25.964987 hw_loss 0.199847 lr 0.00075092 rank 5
2023-02-11 04:42:53,543 DEBUG TRAIN Batch 2/2100 loss 51.215725 loss_att 63.760281 loss_ctc 69.601959 loss_rnnt 43.812897 hw_loss 0.457953 lr 0.00075068 rank 3
2023-02-11 04:42:53,544 DEBUG TRAIN Batch 2/2100 loss 51.945831 loss_att 75.021347 loss_ctc 73.125023 loss_rnnt 41.365292 hw_loss 0.589039 lr 0.00075048 rank 4
2023-02-11 04:42:53,545 DEBUG TRAIN Batch 2/2100 loss 35.664162 loss_att 43.967045 loss_ctc 50.218246 loss_rnnt 28.864677 hw_loss 0.599692 lr 0.00075264 rank 1
2023-02-11 04:42:53,591 DEBUG TRAIN Batch 2/2100 loss 35.987541 loss_att 48.027336 loss_ctc 46.050804 loss_rnnt 28.226837 hw_loss 0.752059 lr 0.00075196 rank 2
2023-02-11 04:44:11,559 DEBUG TRAIN Batch 2/2200 loss 39.976055 loss_att 47.613647 loss_ctc 48.849575 loss_rnnt 33.677101 hw_loss 0.672806 lr 0.00075596 rank 2
2023-02-11 04:44:11,560 DEBUG TRAIN Batch 2/2200 loss 46.379051 loss_att 55.861301 loss_ctc 67.954521 loss_rnnt 37.285683 hw_loss 0.810036 lr 0.00075608 rank 0
2023-02-11 04:44:11,560 DEBUG TRAIN Batch 2/2200 loss 48.388023 loss_att 62.805634 loss_ctc 59.701313 loss_rnnt 40.662842 hw_loss 0.624979 lr 0.00075440 rank 7
2023-02-11 04:44:11,562 DEBUG TRAIN Batch 2/2200 loss 54.866615 loss_att 60.232056 loss_ctc 63.053722 loss_rnnt 49.054337 hw_loss 0.683921 lr 0.00075468 rank 3
2023-02-11 04:44:11,565 DEBUG TRAIN Batch 2/2200 loss 38.973007 loss_att 50.656204 loss_ctc 57.741051 loss_rnnt 31.639812 hw_loss 0.467654 lr 0.00075492 rank 5
2023-02-11 04:44:11,565 DEBUG TRAIN Batch 2/2200 loss 24.611059 loss_att 42.300220 loss_ctc 33.178642 loss_rnnt 18.267479 hw_loss 0.311888 lr 0.00075448 rank 4
2023-02-11 04:44:11,567 DEBUG TRAIN Batch 2/2200 loss 25.588371 loss_att 39.391815 loss_ctc 34.385941 loss_rnnt 18.842344 hw_loss 0.527311 lr 0.00075664 rank 1
2023-02-11 04:44:11,570 DEBUG TRAIN Batch 2/2200 loss 40.135872 loss_att 56.173576 loss_ctc 54.588303 loss_rnnt 32.128445 hw_loss 0.538668 lr 0.00075560 rank 6
2023-02-11 04:45:26,155 DEBUG TRAIN Batch 2/2300 loss 56.783237 loss_att 70.336189 loss_ctc 81.842514 loss_rnnt 47.860344 hw_loss 0.538325 lr 0.00075868 rank 3
2023-02-11 04:45:26,155 DEBUG TRAIN Batch 2/2300 loss 51.248642 loss_att 74.026634 loss_ctc 75.814957 loss_rnnt 40.422779 hw_loss 0.561516 lr 0.00075960 rank 6
2023-02-11 04:45:26,160 DEBUG TRAIN Batch 2/2300 loss 37.774220 loss_att 53.616074 loss_ctc 48.108498 loss_rnnt 31.796108 hw_loss 0.268470 lr 0.00076008 rank 0
2023-02-11 04:45:26,161 DEBUG TRAIN Batch 2/2300 loss 30.339886 loss_att 43.822964 loss_ctc 35.751511 loss_rnnt 25.160515 hw_loss 0.330226 lr 0.00075840 rank 7
2023-02-11 04:45:26,162 DEBUG TRAIN Batch 2/2300 loss 51.097080 loss_att 62.349831 loss_ctc 74.013458 loss_rnnt 43.116150 hw_loss 0.501537 lr 0.00075996 rank 2
2023-02-11 04:45:26,162 DEBUG TRAIN Batch 2/2300 loss 39.145485 loss_att 53.081593 loss_ctc 50.723679 loss_rnnt 31.926003 hw_loss 0.541593 lr 0.00075892 rank 5
2023-02-11 04:45:26,163 DEBUG TRAIN Batch 2/2300 loss 30.960382 loss_att 45.112389 loss_ctc 40.791348 loss_rnnt 24.885984 hw_loss 0.362475 lr 0.00075848 rank 4
2023-02-11 04:45:26,164 DEBUG TRAIN Batch 2/2300 loss 38.197433 loss_att 48.828442 loss_ctc 47.847218 loss_rnnt 32.286400 hw_loss 0.468411 lr 0.00076064 rank 1
2023-02-11 04:46:42,048 DEBUG TRAIN Batch 2/2400 loss 30.588406 loss_att 35.146042 loss_ctc 36.828777 loss_rnnt 24.842690 hw_loss 0.750401 lr 0.00076360 rank 6
2023-02-11 04:46:42,049 DEBUG TRAIN Batch 2/2400 loss 39.995701 loss_att 52.836006 loss_ctc 51.706272 loss_rnnt 33.043705 hw_loss 0.529223 lr 0.00076240 rank 7
2023-02-11 04:46:42,052 DEBUG TRAIN Batch 2/2400 loss 35.401695 loss_att 43.256561 loss_ctc 43.508694 loss_rnnt 27.731033 hw_loss 0.941016 lr 0.00076464 rank 1
2023-02-11 04:46:42,052 DEBUG TRAIN Batch 2/2400 loss 48.155960 loss_att 58.353134 loss_ctc 69.184204 loss_rnnt 41.678383 hw_loss 0.306445 lr 0.00076248 rank 4
2023-02-11 04:46:42,052 DEBUG TRAIN Batch 2/2400 loss 49.915089 loss_att 52.092316 loss_ctc 60.055775 loss_rnnt 42.891785 hw_loss 0.981706 lr 0.00076292 rank 5
2023-02-11 04:46:42,055 DEBUG TRAIN Batch 2/2400 loss 44.911297 loss_att 56.185848 loss_ctc 62.706451 loss_rnnt 37.839478 hw_loss 0.458291 lr 0.00076396 rank 2
2023-02-11 04:46:42,059 DEBUG TRAIN Batch 2/2400 loss 37.123466 loss_att 39.771435 loss_ctc 45.088646 loss_rnnt 30.737867 hw_loss 0.898872 lr 0.00076268 rank 3
2023-02-11 04:46:42,069 DEBUG TRAIN Batch 2/2400 loss 31.112114 loss_att 45.864761 loss_ctc 48.184795 loss_rnnt 22.972126 hw_loss 0.546206 lr 0.00076408 rank 0
2023-02-11 04:48:02,195 DEBUG TRAIN Batch 2/2500 loss 25.171358 loss_att 31.298775 loss_ctc 28.584564 loss_rnnt 19.125511 hw_loss 0.818488 lr 0.00076668 rank 3
2023-02-11 04:48:02,197 DEBUG TRAIN Batch 2/2500 loss 28.171131 loss_att 29.496525 loss_ctc 32.772671 loss_rnnt 21.947407 hw_loss 1.002208 lr 0.00076640 rank 7
2023-02-11 04:48:02,198 DEBUG TRAIN Batch 2/2500 loss 37.413673 loss_att 41.153538 loss_ctc 45.820602 loss_rnnt 32.824165 hw_loss 0.510115 lr 0.00076796 rank 2
2023-02-11 04:48:02,201 DEBUG TRAIN Batch 2/2500 loss 33.614677 loss_att 37.520096 loss_ctc 43.771496 loss_rnnt 28.801008 hw_loss 0.502190 lr 0.00076760 rank 6
2023-02-11 04:48:02,201 DEBUG TRAIN Batch 2/2500 loss 22.535154 loss_att 25.102077 loss_ctc 30.079420 loss_rnnt 17.423304 hw_loss 0.673605 lr 0.00076648 rank 4
2023-02-11 04:48:02,202 DEBUG TRAIN Batch 2/2500 loss 31.305979 loss_att 27.135462 loss_ctc 33.862202 loss_rnnt 25.778955 hw_loss 1.128805 lr 0.00076864 rank 1
2023-02-11 04:48:02,203 DEBUG TRAIN Batch 2/2500 loss 28.699499 loss_att 39.473999 loss_ctc 37.079521 loss_rnnt 24.635292 hw_loss 0.148494 lr 0.00076692 rank 5
2023-02-11 04:48:02,203 DEBUG TRAIN Batch 2/2500 loss 24.135128 loss_att 28.376301 loss_ctc 32.222523 loss_rnnt 16.399754 hw_loss 1.089154 lr 0.00076808 rank 0
2023-02-11 04:49:18,912 DEBUG TRAIN Batch 2/2600 loss 47.569916 loss_att 55.305428 loss_ctc 64.160507 loss_rnnt 40.788414 hw_loss 0.566684 lr 0.00077068 rank 3
2023-02-11 04:49:18,912 DEBUG TRAIN Batch 2/2600 loss 53.922607 loss_att 64.071152 loss_ctc 71.265747 loss_rnnt 45.958736 hw_loss 0.679077 lr 0.00077208 rank 0
2023-02-11 04:49:18,915 DEBUG TRAIN Batch 2/2600 loss 43.099606 loss_att 58.769020 loss_ctc 59.472275 loss_rnnt 35.366611 hw_loss 0.453016 lr 0.00077160 rank 6
2023-02-11 04:49:18,917 DEBUG TRAIN Batch 2/2600 loss 29.380848 loss_att 44.980820 loss_ctc 43.256020 loss_rnnt 23.553379 hw_loss 0.160772 lr 0.00077048 rank 4
2023-02-11 04:49:18,917 DEBUG TRAIN Batch 2/2600 loss 41.142502 loss_att 51.483765 loss_ctc 54.553963 loss_rnnt 35.870964 hw_loss 0.265329 lr 0.00077092 rank 5
2023-02-11 04:49:18,917 DEBUG TRAIN Batch 2/2600 loss 44.318047 loss_att 56.661564 loss_ctc 57.557796 loss_rnnt 38.141064 hw_loss 0.364309 lr 0.00077040 rank 7
2023-02-11 04:49:18,918 DEBUG TRAIN Batch 2/2600 loss 42.304405 loss_att 55.281139 loss_ctc 57.740417 loss_rnnt 34.369286 hw_loss 0.615307 lr 0.00077264 rank 1
2023-02-11 04:49:18,923 DEBUG TRAIN Batch 2/2600 loss 54.832195 loss_att 74.314133 loss_ctc 83.621681 loss_rnnt 45.012917 hw_loss 0.390804 lr 0.00077196 rank 2
2023-02-11 04:50:33,736 DEBUG TRAIN Batch 2/2700 loss 34.054291 loss_att 53.326077 loss_ctc 42.734921 loss_rnnt 26.189518 hw_loss 0.534937 lr 0.00077560 rank 6
2023-02-11 04:50:33,736 DEBUG TRAIN Batch 2/2700 loss 57.258720 loss_att 75.208397 loss_ctc 78.081154 loss_rnnt 48.339798 hw_loss 0.478624 lr 0.00077440 rank 7
2023-02-11 04:50:33,740 DEBUG TRAIN Batch 2/2700 loss 48.939701 loss_att 63.910088 loss_ctc 65.457413 loss_rnnt 42.116577 hw_loss 0.305003 lr 0.00077664 rank 1
2023-02-11 04:50:33,742 DEBUG TRAIN Batch 2/2700 loss 47.157181 loss_att 58.126438 loss_ctc 67.969437 loss_rnnt 39.782753 hw_loss 0.451051 lr 0.00077608 rank 0
2023-02-11 04:50:33,742 DEBUG TRAIN Batch 2/2700 loss 41.354889 loss_att 61.094120 loss_ctc 60.571148 loss_rnnt 31.726391 hw_loss 0.584716 lr 0.00077492 rank 5
2023-02-11 04:50:33,744 DEBUG TRAIN Batch 2/2700 loss 57.447632 loss_att 67.277008 loss_ctc 81.051773 loss_rnnt 49.562634 hw_loss 0.519732 lr 0.00077448 rank 4
2023-02-11 04:50:33,746 DEBUG TRAIN Batch 2/2700 loss 42.158844 loss_att 55.499382 loss_ctc 56.753075 loss_rnnt 33.278423 hw_loss 0.799953 lr 0.00077468 rank 3
2023-02-11 04:50:33,748 DEBUG TRAIN Batch 2/2700 loss 38.503254 loss_att 45.439171 loss_ctc 45.724396 loss_rnnt 34.028709 hw_loss 0.398352 lr 0.00077596 rank 2
2023-02-11 04:51:51,851 DEBUG TRAIN Batch 2/2800 loss 34.871376 loss_att 49.295513 loss_ctc 55.546204 loss_rnnt 27.806271 hw_loss 0.266932 lr 0.00077996 rank 2
2023-02-11 04:51:51,858 DEBUG TRAIN Batch 2/2800 loss 45.040897 loss_att 54.312386 loss_ctc 67.802948 loss_rnnt 37.446602 hw_loss 0.507198 lr 0.00078008 rank 0
2023-02-11 04:51:51,860 DEBUG TRAIN Batch 2/2800 loss 41.910770 loss_att 48.083839 loss_ctc 49.497833 loss_rnnt 36.600262 hw_loss 0.574554 lr 0.00077840 rank 7
2023-02-11 04:51:51,860 DEBUG TRAIN Batch 2/2800 loss 40.424702 loss_att 53.471085 loss_ctc 59.817612 loss_rnnt 34.054916 hw_loss 0.220272 lr 0.00077848 rank 4
2023-02-11 04:51:51,862 DEBUG TRAIN Batch 2/2800 loss 34.498051 loss_att 42.601757 loss_ctc 54.527191 loss_rnnt 26.634787 hw_loss 0.669744 lr 0.00077868 rank 3
2023-02-11 04:51:51,862 DEBUG TRAIN Batch 2/2800 loss 39.630337 loss_att 54.299686 loss_ctc 53.287956 loss_rnnt 30.858240 hw_loss 0.753226 lr 0.00078064 rank 1
2023-02-11 04:51:51,874 DEBUG TRAIN Batch 2/2800 loss 51.942879 loss_att 68.180351 loss_ctc 78.027924 loss_rnnt 43.084721 hw_loss 0.399874 lr 0.00077892 rank 5
2023-02-11 04:51:51,899 DEBUG TRAIN Batch 2/2800 loss 34.712772 loss_att 44.914978 loss_ctc 54.211559 loss_rnnt 26.327490 hw_loss 0.702188 lr 0.00077960 rank 6
2023-02-11 04:53:09,107 DEBUG TRAIN Batch 2/2900 loss 70.506958 loss_att 83.579460 loss_ctc 97.264496 loss_rnnt 60.353710 hw_loss 0.744578 lr 0.00078408 rank 0
2023-02-11 04:53:09,110 DEBUG TRAIN Batch 2/2900 loss 44.914783 loss_att 57.096191 loss_ctc 55.497059 loss_rnnt 38.550335 hw_loss 0.471974 lr 0.00078396 rank 2
2023-02-11 04:53:09,113 DEBUG TRAIN Batch 2/2900 loss 43.405563 loss_att 50.590759 loss_ctc 56.554287 loss_rnnt 37.938515 hw_loss 0.426909 lr 0.00078268 rank 3
2023-02-11 04:53:09,114 DEBUG TRAIN Batch 2/2900 loss 45.843521 loss_att 58.492714 loss_ctc 57.954384 loss_rnnt 38.879124 hw_loss 0.528708 lr 0.00078240 rank 7
2023-02-11 04:53:09,114 DEBUG TRAIN Batch 2/2900 loss 21.179701 loss_att 35.494049 loss_ctc 26.136917 loss_rnnt 16.077967 hw_loss 0.295857 lr 0.00078292 rank 5
2023-02-11 04:53:09,117 DEBUG TRAIN Batch 2/2900 loss 50.783710 loss_att 60.606567 loss_ctc 66.433952 loss_rnnt 43.615280 hw_loss 0.584468 lr 0.00078248 rank 4
2023-02-11 04:53:09,119 DEBUG TRAIN Batch 2/2900 loss 32.068584 loss_att 39.103493 loss_ctc 51.951870 loss_rnnt 26.793024 hw_loss 0.228276 lr 0.00078360 rank 6
2023-02-11 04:53:09,162 DEBUG TRAIN Batch 2/2900 loss 38.311043 loss_att 53.264290 loss_ctc 55.663525 loss_rnnt 28.814047 hw_loss 0.786128 lr 0.00078464 rank 1
2023-02-11 04:54:24,893 DEBUG TRAIN Batch 2/3000 loss 30.639874 loss_att 43.911343 loss_ctc 42.982483 loss_rnnt 23.126236 hw_loss 0.602562 lr 0.00078640 rank 7
2023-02-11 04:54:24,895 DEBUG TRAIN Batch 2/3000 loss 29.749264 loss_att 33.293869 loss_ctc 37.413971 loss_rnnt 24.356060 hw_loss 0.686686 lr 0.00078808 rank 0
2023-02-11 04:54:24,896 DEBUG TRAIN Batch 2/3000 loss 31.645643 loss_att 48.576324 loss_ctc 51.283325 loss_rnnt 24.803291 hw_loss 0.157098 lr 0.00078668 rank 3
2023-02-11 04:54:24,897 DEBUG TRAIN Batch 2/3000 loss 25.286039 loss_att 32.175346 loss_ctc 34.316994 loss_rnnt 19.526497 hw_loss 0.595791 lr 0.00078692 rank 5
2023-02-11 04:54:24,898 DEBUG TRAIN Batch 2/3000 loss 22.994179 loss_att 34.953568 loss_ctc 36.514717 loss_rnnt 17.454414 hw_loss 0.252216 lr 0.00078864 rank 1
2023-02-11 04:54:24,899 DEBUG TRAIN Batch 2/3000 loss 42.346519 loss_att 54.176510 loss_ctc 61.468597 loss_rnnt 34.869011 hw_loss 0.480356 lr 0.00078796 rank 2
2023-02-11 04:54:24,901 DEBUG TRAIN Batch 2/3000 loss 20.153986 loss_att 28.433884 loss_ctc 28.412624 loss_rnnt 14.125824 hw_loss 0.613318 lr 0.00078648 rank 4
2023-02-11 04:54:24,901 DEBUG TRAIN Batch 2/3000 loss 38.567276 loss_att 43.419155 loss_ctc 52.918678 loss_rnnt 32.468227 hw_loss 0.602841 lr 0.00078760 rank 6
2023-02-11 04:55:40,237 DEBUG TRAIN Batch 2/3100 loss 32.006668 loss_att 30.814106 loss_ctc 32.337986 loss_rnnt 25.221752 hw_loss 1.308610 lr 0.00079092 rank 5
2023-02-11 04:55:40,240 DEBUG TRAIN Batch 2/3100 loss 44.608185 loss_att 49.708923 loss_ctc 56.623501 loss_rnnt 39.055046 hw_loss 0.549553 lr 0.00079196 rank 2
2023-02-11 04:55:40,241 DEBUG TRAIN Batch 2/3100 loss 27.913696 loss_att 26.953596 loss_ctc 33.806732 loss_rnnt 19.589180 hw_loss 1.449525 lr 0.00079208 rank 0
2023-02-11 04:55:40,243 DEBUG TRAIN Batch 2/3100 loss 34.302948 loss_att 46.339790 loss_ctc 53.801270 loss_rnnt 27.493900 hw_loss 0.337856 lr 0.00079068 rank 3
2023-02-11 04:55:40,245 DEBUG TRAIN Batch 2/3100 loss 36.775585 loss_att 41.194138 loss_ctc 50.609200 loss_rnnt 30.190393 hw_loss 0.723187 lr 0.00079040 rank 7
2023-02-11 04:55:40,246 DEBUG TRAIN Batch 2/3100 loss 37.341461 loss_att 46.997665 loss_ctc 46.966747 loss_rnnt 30.630945 hw_loss 0.655481 lr 0.00079160 rank 6
2023-02-11 04:55:40,247 DEBUG TRAIN Batch 2/3100 loss 48.788857 loss_att 56.470955 loss_ctc 62.609047 loss_rnnt 41.060070 hw_loss 0.815563 lr 0.00079048 rank 4
2023-02-11 04:55:40,252 DEBUG TRAIN Batch 2/3100 loss 26.771137 loss_att 29.514122 loss_ctc 36.134525 loss_rnnt 22.275375 hw_loss 0.506009 lr 0.00079264 rank 1
2023-02-11 04:56:59,348 DEBUG TRAIN Batch 2/3200 loss 36.920723 loss_att 44.015987 loss_ctc 46.050522 loss_rnnt 31.399237 hw_loss 0.540962 lr 0.00079560 rank 6
2023-02-11 04:56:59,350 DEBUG TRAIN Batch 2/3200 loss 38.256596 loss_att 48.585201 loss_ctc 53.252068 loss_rnnt 33.416801 hw_loss 0.145252 lr 0.00079608 rank 0
2023-02-11 04:56:59,351 DEBUG TRAIN Batch 2/3200 loss 59.065655 loss_att 71.812073 loss_ctc 81.732910 loss_rnnt 52.289581 hw_loss 0.225841 lr 0.00079440 rank 7
2023-02-11 04:56:59,352 DEBUG TRAIN Batch 2/3200 loss 57.046898 loss_att 70.399567 loss_ctc 80.931747 loss_rnnt 47.921352 hw_loss 0.613194 lr 0.00079468 rank 3
2023-02-11 04:56:59,355 DEBUG TRAIN Batch 2/3200 loss 26.714207 loss_att 44.659634 loss_ctc 39.118195 loss_rnnt 18.681156 hw_loss 0.523143 lr 0.00079664 rank 1
2023-02-11 04:56:59,355 DEBUG TRAIN Batch 2/3200 loss 52.678780 loss_att 71.705765 loss_ctc 81.291130 loss_rnnt 43.524689 hw_loss 0.287571 lr 0.00079448 rank 4
2023-02-11 04:56:59,355 DEBUG TRAIN Batch 2/3200 loss 36.501606 loss_att 48.094296 loss_ctc 47.222225 loss_rnnt 29.482506 hw_loss 0.613340 lr 0.00079492 rank 5
2023-02-11 04:56:59,356 DEBUG TRAIN Batch 2/3200 loss 15.952259 loss_att 13.610591 loss_ctc 15.909943 loss_rnnt 10.207612 hw_loss 1.165992 lr 0.00079596 rank 2
2023-02-11 04:58:16,177 DEBUG TRAIN Batch 2/3300 loss 60.730865 loss_att 76.256004 loss_ctc 80.315460 loss_rnnt 53.152630 hw_loss 0.349112 lr 0.00080008 rank 0
2023-02-11 04:58:16,177 DEBUG TRAIN Batch 2/3300 loss 44.291008 loss_att 58.875637 loss_ctc 72.233887 loss_rnnt 34.534767 hw_loss 0.583799 lr 0.00079868 rank 3
2023-02-11 04:58:16,177 DEBUG TRAIN Batch 2/3300 loss 58.859474 loss_att 76.372162 loss_ctc 83.523849 loss_rnnt 49.590271 hw_loss 0.464640 lr 0.00079840 rank 7
2023-02-11 04:58:16,179 DEBUG TRAIN Batch 2/3300 loss 37.926788 loss_att 60.454399 loss_ctc 50.546753 loss_rnnt 30.015882 hw_loss 0.323011 lr 0.00079960 rank 6
2023-02-11 04:58:16,182 DEBUG TRAIN Batch 2/3300 loss 79.006798 loss_att 97.897453 loss_ctc 103.344040 loss_rnnt 70.406494 hw_loss 0.295727 lr 0.00079848 rank 4
2023-02-11 04:58:16,183 DEBUG TRAIN Batch 2/3300 loss 25.961596 loss_att 41.301132 loss_ctc 36.578732 loss_rnnt 18.158760 hw_loss 0.622371 lr 0.00079892 rank 5
2023-02-11 04:58:16,183 DEBUG TRAIN Batch 2/3300 loss 52.724632 loss_att 69.971619 loss_ctc 72.973007 loss_rnnt 43.420990 hw_loss 0.591461 lr 0.00080064 rank 1
2023-02-11 04:58:16,228 DEBUG TRAIN Batch 2/3300 loss 42.053280 loss_att 53.168446 loss_ctc 57.171562 loss_rnnt 37.105186 hw_loss 0.132991 lr 0.00079996 rank 2
2023-02-11 04:59:33,061 DEBUG TRAIN Batch 2/3400 loss 69.512802 loss_att 77.200073 loss_ctc 84.636696 loss_rnnt 61.778255 hw_loss 0.783858 lr 0.00080268 rank 3
2023-02-11 04:59:33,062 DEBUG TRAIN Batch 2/3400 loss 45.202534 loss_att 55.643749 loss_ctc 59.966900 loss_rnnt 38.407700 hw_loss 0.513378 lr 0.00080240 rank 7
2023-02-11 04:59:33,067 DEBUG TRAIN Batch 2/3400 loss 31.561596 loss_att 39.261654 loss_ctc 41.780197 loss_rnnt 27.374418 hw_loss 0.240879 lr 0.00080408 rank 0
2023-02-11 04:59:33,068 DEBUG TRAIN Batch 2/3400 loss 33.915909 loss_att 43.909901 loss_ctc 41.704235 loss_rnnt 26.574368 hw_loss 0.807057 lr 0.00080396 rank 2
2023-02-11 04:59:33,069 DEBUG TRAIN Batch 2/3400 loss 34.319950 loss_att 46.554245 loss_ctc 45.505241 loss_rnnt 25.811245 hw_loss 0.856964 lr 0.00080292 rank 5
2023-02-11 04:59:33,070 DEBUG TRAIN Batch 2/3400 loss 34.477165 loss_att 50.475929 loss_ctc 50.007519 loss_rnnt 26.534054 hw_loss 0.501121 lr 0.00080248 rank 4
2023-02-11 04:59:33,072 DEBUG TRAIN Batch 2/3400 loss 17.152357 loss_att 29.030201 loss_ctc 24.695784 loss_rnnt 9.790413 hw_loss 0.746359 lr 0.00080464 rank 1
2023-02-11 04:59:33,121 DEBUG TRAIN Batch 2/3400 loss 39.316402 loss_att 51.940083 loss_ctc 56.939247 loss_rnnt 32.748421 hw_loss 0.317537 lr 0.00080360 rank 6
2023-02-11 05:00:50,038 DEBUG TRAIN Batch 2/3500 loss 58.360531 loss_att 72.846024 loss_ctc 86.003075 loss_rnnt 49.194130 hw_loss 0.484430 lr 0.00080760 rank 6
2023-02-11 05:00:50,041 DEBUG TRAIN Batch 2/3500 loss 47.520870 loss_att 56.663326 loss_ctc 65.709244 loss_rnnt 39.129665 hw_loss 0.775800 lr 0.00080668 rank 3
2023-02-11 05:00:50,042 DEBUG TRAIN Batch 2/3500 loss 37.255905 loss_att 48.327351 loss_ctc 48.785160 loss_rnnt 29.636656 hw_loss 0.725198 lr 0.00080640 rank 7
2023-02-11 05:00:50,043 DEBUG TRAIN Batch 2/3500 loss 28.600279 loss_att 35.025154 loss_ctc 37.173950 loss_rnnt 21.793879 hw_loss 0.820925 lr 0.00080808 rank 0
2023-02-11 05:00:50,043 DEBUG TRAIN Batch 2/3500 loss 49.780285 loss_att 60.113049 loss_ctc 74.620834 loss_rnnt 41.682755 hw_loss 0.509795 lr 0.00080692 rank 5
2023-02-11 05:00:50,047 DEBUG TRAIN Batch 2/3500 loss 45.876167 loss_att 60.412842 loss_ctc 59.406433 loss_rnnt 38.847855 hw_loss 0.434426 lr 0.00080864 rank 1
2023-02-11 05:00:50,049 DEBUG TRAIN Batch 2/3500 loss 31.551931 loss_att 38.918602 loss_ctc 49.240238 loss_rnnt 24.102154 hw_loss 0.678376 lr 0.00080648 rank 4
2023-02-11 05:00:50,051 DEBUG TRAIN Batch 2/3500 loss 38.262199 loss_att 55.889198 loss_ctc 59.272171 loss_rnnt 29.133278 hw_loss 0.525411 lr 0.00080796 rank 2
2023-02-11 05:02:08,219 DEBUG TRAIN Batch 2/3600 loss 27.847904 loss_att 40.223957 loss_ctc 45.020973 loss_rnnt 21.309156 hw_loss 0.332586 lr 0.00081208 rank 0
2023-02-11 05:02:08,220 DEBUG TRAIN Batch 2/3600 loss 45.157539 loss_att 59.878532 loss_ctc 67.837250 loss_rnnt 36.376167 hw_loss 0.527477 lr 0.00081160 rank 6
2023-02-11 05:02:08,221 DEBUG TRAIN Batch 2/3600 loss 44.605663 loss_att 51.337006 loss_ctc 61.288326 loss_rnnt 36.890610 hw_loss 0.777080 lr 0.00081264 rank 1
2023-02-11 05:02:08,224 DEBUG TRAIN Batch 2/3600 loss 36.190506 loss_att 44.920780 loss_ctc 49.096947 loss_rnnt 29.105305 hw_loss 0.678429 lr 0.00081068 rank 3
2023-02-11 05:02:08,225 DEBUG TRAIN Batch 2/3600 loss 58.689613 loss_att 74.059250 loss_ctc 82.729462 loss_rnnt 50.805645 hw_loss 0.300888 lr 0.00081040 rank 7
2023-02-11 05:02:08,226 DEBUG TRAIN Batch 2/3600 loss 31.636023 loss_att 39.121929 loss_ctc 43.718323 loss_rnnt 26.184093 hw_loss 0.439458 lr 0.00081196 rank 2
2023-02-11 05:02:08,227 DEBUG TRAIN Batch 2/3600 loss 31.449663 loss_att 39.397980 loss_ctc 39.266212 loss_rnnt 24.647507 hw_loss 0.781929 lr 0.00081092 rank 5
2023-02-11 05:02:08,226 DEBUG TRAIN Batch 2/3600 loss 35.162609 loss_att 45.852451 loss_ctc 46.711044 loss_rnnt 27.244007 hw_loss 0.795157 lr 0.00081048 rank 4
2023-02-11 05:03:25,110 DEBUG TRAIN Batch 2/3700 loss 21.422590 loss_att 24.007704 loss_ctc 27.287384 loss_rnnt 17.026840 hw_loss 0.580641 lr 0.00081440 rank 7
2023-02-11 05:03:25,112 DEBUG TRAIN Batch 2/3700 loss 40.242538 loss_att 45.000641 loss_ctc 51.412476 loss_rnnt 34.144711 hw_loss 0.685666 lr 0.00081448 rank 4
2023-02-11 05:03:25,114 DEBUG TRAIN Batch 2/3700 loss 42.007458 loss_att 43.091461 loss_ctc 54.133572 loss_rnnt 39.649139 hw_loss 0.098382 lr 0.00081664 rank 1
2023-02-11 05:03:25,118 DEBUG TRAIN Batch 2/3700 loss 26.862700 loss_att 31.099052 loss_ctc 29.522430 loss_rnnt 21.695234 hw_loss 0.743543 lr 0.00081492 rank 5
2023-02-11 05:03:25,119 DEBUG TRAIN Batch 2/3700 loss 23.955240 loss_att 29.615469 loss_ctc 33.109112 loss_rnnt 17.916664 hw_loss 0.691128 lr 0.00081596 rank 2
2023-02-11 05:03:25,120 DEBUG TRAIN Batch 2/3700 loss 33.610310 loss_att 45.217419 loss_ctc 50.514969 loss_rnnt 25.475853 hw_loss 0.667328 lr 0.00081468 rank 3
2023-02-11 05:03:25,121 DEBUG TRAIN Batch 2/3700 loss 35.228317 loss_att 38.225510 loss_ctc 45.987083 loss_rnnt 27.522327 hw_loss 1.063509 lr 0.00081608 rank 0
2023-02-11 05:03:25,168 DEBUG TRAIN Batch 2/3700 loss 42.697266 loss_att 50.614582 loss_ctc 52.186493 loss_rnnt 35.673210 hw_loss 0.782881 lr 0.00081560 rank 6
2023-02-11 05:04:41,137 DEBUG TRAIN Batch 2/3800 loss 33.385418 loss_att 32.641838 loss_ctc 37.471176 loss_rnnt 27.442749 hw_loss 1.039991 lr 0.00081868 rank 3
2023-02-11 05:04:41,138 DEBUG TRAIN Batch 2/3800 loss 29.985752 loss_att 39.071899 loss_ctc 47.604294 loss_rnnt 25.141991 hw_loss 0.127011 lr 0.00081840 rank 7
2023-02-11 05:04:41,141 DEBUG TRAIN Batch 2/3800 loss 23.592644 loss_att 17.990856 loss_ctc 26.243177 loss_rnnt 16.491377 hw_loss 1.475291 lr 0.00081848 rank 4
2023-02-11 05:04:41,143 DEBUG TRAIN Batch 2/3800 loss 44.492012 loss_att 43.439568 loss_ctc 55.311790 loss_rnnt 40.483784 hw_loss 0.520515 lr 0.00081960 rank 6
2023-02-11 05:04:41,143 DEBUG TRAIN Batch 2/3800 loss 29.439108 loss_att 30.152189 loss_ctc 34.820786 loss_rnnt 23.352800 hw_loss 0.979900 lr 0.00082064 rank 1
2023-02-11 05:04:41,144 DEBUG TRAIN Batch 2/3800 loss 31.225031 loss_att 52.254513 loss_ctc 47.855145 loss_rnnt 22.166708 hw_loss 0.494077 lr 0.00082008 rank 0
2023-02-11 05:04:41,145 DEBUG TRAIN Batch 2/3800 loss 34.212563 loss_att 31.994749 loss_ctc 40.793007 loss_rnnt 30.369396 hw_loss 0.639251 lr 0.00081996 rank 2
2023-02-11 05:04:41,148 DEBUG TRAIN Batch 2/3800 loss 43.982403 loss_att 56.949646 loss_ctc 57.060593 loss_rnnt 36.541683 hw_loss 0.581909 lr 0.00081892 rank 5
2023-02-11 05:06:00,017 DEBUG TRAIN Batch 2/3900 loss 31.375307 loss_att 42.840473 loss_ctc 46.353981 loss_rnnt 25.049709 hw_loss 0.381639 lr 0.00082408 rank 0
2023-02-11 05:06:00,018 DEBUG TRAIN Batch 2/3900 loss 43.957027 loss_att 59.891006 loss_ctc 65.136681 loss_rnnt 35.545467 hw_loss 0.450152 lr 0.00082268 rank 3
2023-02-11 05:06:00,019 DEBUG TRAIN Batch 2/3900 loss 29.602167 loss_att 49.808731 loss_ctc 45.718735 loss_rnnt 19.250399 hw_loss 0.780296 lr 0.00082240 rank 7
2023-02-11 05:06:00,023 DEBUG TRAIN Batch 2/3900 loss 57.865383 loss_att 70.507774 loss_ctc 83.950394 loss_rnnt 49.382248 hw_loss 0.464374 lr 0.00082360 rank 6
2023-02-11 05:06:00,023 DEBUG TRAIN Batch 2/3900 loss 40.724545 loss_att 46.895615 loss_ctc 56.654446 loss_rnnt 32.544647 hw_loss 0.904068 lr 0.00082248 rank 4
2023-02-11 05:06:00,025 DEBUG TRAIN Batch 2/3900 loss 21.683170 loss_att 30.542765 loss_ctc 29.851528 loss_rnnt 17.028381 hw_loss 0.336329 lr 0.00082464 rank 1
2023-02-11 05:06:00,025 DEBUG TRAIN Batch 2/3900 loss 25.895269 loss_att 44.436081 loss_ctc 37.770691 loss_rnnt 17.478661 hw_loss 0.585948 lr 0.00082292 rank 5
2023-02-11 05:06:00,025 DEBUG TRAIN Batch 2/3900 loss 37.621426 loss_att 65.429810 loss_ctc 52.938049 loss_rnnt 29.000065 hw_loss 0.190775 lr 0.00082396 rank 2
2023-02-11 05:07:16,048 DEBUG TRAIN Batch 2/4000 loss 53.372635 loss_att 67.363319 loss_ctc 82.244858 loss_rnnt 45.881645 hw_loss 0.158104 lr 0.00082796 rank 2
2023-02-11 05:07:16,051 DEBUG TRAIN Batch 2/4000 loss 38.460621 loss_att 55.275368 loss_ctc 60.910393 loss_rnnt 29.875458 hw_loss 0.417921 lr 0.00082808 rank 0
2023-02-11 05:07:16,057 DEBUG TRAIN Batch 2/4000 loss 29.750830 loss_att 36.097763 loss_ctc 35.285492 loss_rnnt 24.801947 hw_loss 0.551539 lr 0.00082864 rank 1
2023-02-11 05:07:16,057 DEBUG TRAIN Batch 2/4000 loss 34.707024 loss_att 53.120190 loss_ctc 46.109886 loss_rnnt 28.098364 hw_loss 0.263559 lr 0.00082668 rank 3
2023-02-11 05:07:16,058 DEBUG TRAIN Batch 2/4000 loss 24.466114 loss_att 36.497490 loss_ctc 37.342236 loss_rnnt 17.652876 hw_loss 0.504402 lr 0.00082760 rank 6
2023-02-11 05:07:16,059 DEBUG TRAIN Batch 2/4000 loss 53.509121 loss_att 63.877335 loss_ctc 67.522331 loss_rnnt 46.768791 hw_loss 0.524674 lr 0.00082692 rank 5
2023-02-11 05:07:16,059 DEBUG TRAIN Batch 2/4000 loss 34.983593 loss_att 49.383785 loss_ctc 54.619347 loss_rnnt 27.603592 hw_loss 0.352849 lr 0.00082648 rank 4
2023-02-11 05:07:16,059 DEBUG TRAIN Batch 2/4000 loss 46.024975 loss_att 60.779903 loss_ctc 68.259018 loss_rnnt 38.426292 hw_loss 0.315592 lr 0.00082640 rank 7
2023-02-11 05:08:31,930 DEBUG TRAIN Batch 2/4100 loss 34.798138 loss_att 43.795662 loss_ctc 46.360855 loss_rnnt 26.956169 hw_loss 0.843894 lr 0.00083048 rank 4
2023-02-11 05:08:31,930 DEBUG TRAIN Batch 2/4100 loss 23.719086 loss_att 34.361427 loss_ctc 31.304712 loss_rnnt 16.770096 hw_loss 0.714207 lr 0.00083092 rank 5
2023-02-11 05:08:31,932 DEBUG TRAIN Batch 2/4100 loss 29.742310 loss_att 37.110622 loss_ctc 42.001686 loss_rnnt 24.327356 hw_loss 0.432508 lr 0.00083208 rank 0
2023-02-11 05:08:31,932 DEBUG TRAIN Batch 2/4100 loss 38.739418 loss_att 55.696693 loss_ctc 56.948807 loss_rnnt 31.063179 hw_loss 0.348162 lr 0.00083196 rank 2
2023-02-11 05:08:31,932 DEBUG TRAIN Batch 2/4100 loss 24.976851 loss_att 36.253853 loss_ctc 30.384697 loss_rnnt 19.483551 hw_loss 0.471910 lr 0.00083068 rank 3
2023-02-11 05:08:31,932 DEBUG TRAIN Batch 2/4100 loss 36.822212 loss_att 53.235306 loss_ctc 51.757065 loss_rnnt 29.585884 hw_loss 0.367949 lr 0.00083040 rank 7
2023-02-11 05:08:31,938 DEBUG TRAIN Batch 2/4100 loss 64.207993 loss_att 77.139023 loss_ctc 87.781555 loss_rnnt 55.818417 hw_loss 0.498793 lr 0.00083160 rank 6
2023-02-11 05:08:31,986 DEBUG TRAIN Batch 2/4100 loss 41.936222 loss_att 48.868729 loss_ctc 46.435936 loss_rnnt 32.424232 hw_loss 1.411036 lr 0.00083264 rank 1
2023-02-11 05:09:48,717 DEBUG TRAIN Batch 2/4200 loss 24.267326 loss_att 36.057163 loss_ctc 41.462135 loss_rnnt 18.222195 hw_loss 0.261473 lr 0.00083608 rank 0
2023-02-11 05:09:48,717 DEBUG TRAIN Batch 2/4200 loss 33.872334 loss_att 49.843781 loss_ctc 55.311440 loss_rnnt 25.495213 hw_loss 0.435803 lr 0.00083560 rank 6
2023-02-11 05:09:48,717 DEBUG TRAIN Batch 2/4200 loss 32.029449 loss_att 42.208298 loss_ctc 42.418503 loss_rnnt 25.754185 hw_loss 0.535178 lr 0.00083468 rank 3
2023-02-11 05:09:48,718 DEBUG TRAIN Batch 2/4200 loss 24.395405 loss_att 30.253536 loss_ctc 33.502594 loss_rnnt 19.642490 hw_loss 0.443812 lr 0.00083440 rank 7
2023-02-11 05:09:48,718 DEBUG TRAIN Batch 2/4200 loss 33.664505 loss_att 41.354218 loss_ctc 45.830189 loss_rnnt 27.145256 hw_loss 0.629852 lr 0.00083664 rank 1
2023-02-11 05:09:48,720 DEBUG TRAIN Batch 2/4200 loss 49.490536 loss_att 58.021980 loss_ctc 69.550514 loss_rnnt 41.922749 hw_loss 0.597532 lr 0.00083448 rank 4
2023-02-11 05:09:48,721 DEBUG TRAIN Batch 2/4200 loss 33.116749 loss_att 42.168488 loss_ctc 49.075336 loss_rnnt 26.306463 hw_loss 0.538523 lr 0.00083492 rank 5
2023-02-11 05:09:48,768 DEBUG TRAIN Batch 2/4200 loss 44.629940 loss_att 53.468136 loss_ctc 58.634117 loss_rnnt 38.815819 hw_loss 0.408611 lr 0.00083596 rank 2
2023-02-11 05:11:07,278 DEBUG TRAIN Batch 2/4300 loss 33.892502 loss_att 41.718163 loss_ctc 48.633755 loss_rnnt 27.527599 hw_loss 0.531425 lr 0.00084008 rank 0
2023-02-11 05:11:07,281 DEBUG TRAIN Batch 2/4300 loss 41.215744 loss_att 53.155136 loss_ctc 69.324615 loss_rnnt 32.551811 hw_loss 0.474038 lr 0.00083840 rank 7
2023-02-11 05:11:07,282 DEBUG TRAIN Batch 2/4300 loss 46.105221 loss_att 60.087761 loss_ctc 62.586617 loss_rnnt 37.544109 hw_loss 0.668828 lr 0.00083892 rank 5
2023-02-11 05:11:07,284 DEBUG TRAIN Batch 2/4300 loss 39.884937 loss_att 49.215073 loss_ctc 57.497032 loss_rnnt 33.798256 hw_loss 0.351070 lr 0.00083848 rank 4
2023-02-11 05:11:07,283 DEBUG TRAIN Batch 2/4300 loss 77.510292 loss_att 90.715469 loss_ctc 101.839706 loss_rnnt 69.062393 hw_loss 0.480550 lr 0.00084064 rank 1
2023-02-11 05:11:07,283 DEBUG TRAIN Batch 2/4300 loss 30.664139 loss_att 33.602264 loss_ctc 39.765434 loss_rnnt 24.795553 hw_loss 0.762648 lr 0.00083868 rank 3
2023-02-11 05:11:07,286 DEBUG TRAIN Batch 2/4300 loss 30.053101 loss_att 34.147179 loss_ctc 37.382599 loss_rnnt 22.889120 hw_loss 1.006481 lr 0.00083996 rank 2
2023-02-11 05:11:07,331 DEBUG TRAIN Batch 2/4300 loss 33.204819 loss_att 37.855549 loss_ctc 36.164135 loss_rnnt 28.033085 hw_loss 0.721314 lr 0.00083960 rank 6
2023-02-11 05:12:25,841 DEBUG TRAIN Batch 2/4400 loss 21.647650 loss_att 26.303564 loss_ctc 28.636129 loss_rnnt 17.276976 hw_loss 0.470192 lr 0.00084268 rank 3
2023-02-11 05:12:25,844 DEBUG TRAIN Batch 2/4400 loss 20.907526 loss_att 17.240034 loss_ctc 21.634565 loss_rnnt 15.045295 hw_loss 1.218524 lr 0.00084408 rank 0
2023-02-11 05:12:25,845 DEBUG TRAIN Batch 2/4400 loss 37.766964 loss_att 43.526970 loss_ctc 54.099014 loss_rnnt 32.045223 hw_loss 0.448525 lr 0.00084292 rank 5
2023-02-11 05:12:25,851 DEBUG TRAIN Batch 2/4400 loss 35.167221 loss_att 38.836254 loss_ctc 48.439751 loss_rnnt 30.033981 hw_loss 0.493080 lr 0.00084240 rank 7
2023-02-11 05:12:25,855 DEBUG TRAIN Batch 2/4400 loss 42.380440 loss_att 50.839066 loss_ctc 53.523998 loss_rnnt 33.597393 hw_loss 1.051034 lr 0.00084464 rank 1
2023-02-11 05:12:25,854 DEBUG TRAIN Batch 2/4400 loss 30.748957 loss_att 45.777725 loss_ctc 42.228668 loss_rnnt 24.827860 hw_loss 0.259634 lr 0.00084396 rank 2
2023-02-11 05:12:25,855 DEBUG TRAIN Batch 2/4400 loss 34.533024 loss_att 37.136864 loss_ctc 43.803741 loss_rnnt 29.432251 hw_loss 0.626983 lr 0.00084248 rank 4
2023-02-11 05:12:25,893 DEBUG TRAIN Batch 2/4400 loss 54.124424 loss_att 57.303020 loss_ctc 71.400444 loss_rnnt 48.822063 hw_loss 0.443095 lr 0.00084360 rank 6
2023-02-11 05:13:41,350 DEBUG TRAIN Batch 2/4500 loss 23.429897 loss_att 31.804478 loss_ctc 38.455727 loss_rnnt 15.957939 hw_loss 0.711300 lr 0.00084668 rank 3
2023-02-11 05:13:41,354 DEBUG TRAIN Batch 2/4500 loss 55.581020 loss_att 69.665741 loss_ctc 82.448746 loss_rnnt 46.698174 hw_loss 0.465665 lr 0.00084796 rank 2
2023-02-11 05:13:41,355 DEBUG TRAIN Batch 2/4500 loss 56.681381 loss_att 63.145203 loss_ctc 65.438835 loss_rnnt 50.906281 hw_loss 0.621502 lr 0.00084640 rank 7
2023-02-11 05:13:41,357 DEBUG TRAIN Batch 2/4500 loss 37.127377 loss_att 55.383041 loss_ctc 52.032578 loss_rnnt 29.817312 hw_loss 0.313419 lr 0.00084864 rank 1
2023-02-11 05:13:41,358 DEBUG TRAIN Batch 2/4500 loss 40.864193 loss_att 56.642891 loss_ctc 62.195141 loss_rnnt 30.754110 hw_loss 0.770666 lr 0.00084760 rank 6
2023-02-11 05:13:41,359 DEBUG TRAIN Batch 2/4500 loss 46.464668 loss_att 69.147736 loss_ctc 65.434692 loss_rnnt 36.793884 hw_loss 0.488406 lr 0.00084808 rank 0
2023-02-11 05:13:41,363 DEBUG TRAIN Batch 2/4500 loss 25.330608 loss_att 34.894623 loss_ctc 34.865326 loss_rnnt 20.712347 hw_loss 0.268905 lr 0.00084692 rank 5
2023-02-11 05:13:41,364 DEBUG TRAIN Batch 2/4500 loss 40.119308 loss_att 53.661068 loss_ctc 57.851402 loss_rnnt 34.724655 hw_loss 0.060379 lr 0.00084648 rank 4
2023-02-11 05:14:58,358 DEBUG TRAIN Batch 2/4600 loss 30.883593 loss_att 36.978645 loss_ctc 44.786079 loss_rnnt 25.572912 hw_loss 0.419626 lr 0.00085264 rank 1
2023-02-11 05:14:58,362 DEBUG TRAIN Batch 2/4600 loss 14.040734 loss_att 21.669676 loss_ctc 18.532686 loss_rnnt 9.739821 hw_loss 0.408037 lr 0.00085068 rank 3
2023-02-11 05:14:58,363 DEBUG TRAIN Batch 2/4600 loss 43.220757 loss_att 53.265251 loss_ctc 58.347198 loss_rnnt 37.753693 hw_loss 0.270245 lr 0.00085208 rank 0
2023-02-11 05:14:58,363 DEBUG TRAIN Batch 2/4600 loss 36.650806 loss_att 47.710457 loss_ctc 62.044724 loss_rnnt 29.159946 hw_loss 0.354951 lr 0.00085048 rank 4
2023-02-11 05:14:58,364 DEBUG TRAIN Batch 2/4600 loss 36.458176 loss_att 50.191280 loss_ctc 51.457825 loss_rnnt 27.992697 hw_loss 0.697294 lr 0.00085040 rank 7
2023-02-11 05:14:58,365 DEBUG TRAIN Batch 2/4600 loss 49.771301 loss_att 53.291264 loss_ctc 59.699780 loss_rnnt 45.473431 hw_loss 0.425640 lr 0.00085092 rank 5
2023-02-11 05:14:58,398 DEBUG TRAIN Batch 2/4600 loss 72.209328 loss_att 80.883507 loss_ctc 97.784500 loss_rnnt 65.895264 hw_loss 0.219226 lr 0.00085196 rank 2
2023-02-11 05:14:58,407 DEBUG TRAIN Batch 2/4600 loss 30.578768 loss_att 44.673130 loss_ctc 39.272781 loss_rnnt 23.115273 hw_loss 0.653516 lr 0.00085160 rank 6
2023-02-11 05:16:15,363 DEBUG TRAIN Batch 2/4700 loss 43.312386 loss_att 57.822472 loss_ctc 68.919334 loss_rnnt 36.509941 hw_loss 0.091156 lr 0.00085468 rank 3
2023-02-11 05:16:15,367 DEBUG TRAIN Batch 2/4700 loss 47.440521 loss_att 65.753204 loss_ctc 68.093887 loss_rnnt 39.795212 hw_loss 0.230437 lr 0.00085440 rank 7
2023-02-11 05:16:15,368 DEBUG TRAIN Batch 2/4700 loss 44.559265 loss_att 52.943733 loss_ctc 61.651825 loss_rnnt 36.958496 hw_loss 0.683413 lr 0.00085596 rank 2
2023-02-11 05:16:15,368 DEBUG TRAIN Batch 2/4700 loss 30.635525 loss_att 37.085011 loss_ctc 51.834961 loss_rnnt 24.906345 hw_loss 0.302379 lr 0.00085560 rank 6
2023-02-11 05:16:15,369 DEBUG TRAIN Batch 2/4700 loss 48.011631 loss_att 65.041428 loss_ctc 60.337593 loss_rnnt 41.084709 hw_loss 0.352032 lr 0.00085664 rank 1
2023-02-11 05:16:15,369 DEBUG TRAIN Batch 2/4700 loss 37.549301 loss_att 56.562378 loss_ctc 55.213875 loss_rnnt 29.809048 hw_loss 0.296693 lr 0.00085608 rank 0
2023-02-11 05:16:15,377 DEBUG TRAIN Batch 2/4700 loss 28.718349 loss_att 35.059235 loss_ctc 41.424480 loss_rnnt 21.809427 hw_loss 0.739987 lr 0.00085492 rank 5
2023-02-11 05:16:15,424 DEBUG TRAIN Batch 2/4700 loss 30.830332 loss_att 41.351860 loss_ctc 43.600746 loss_rnnt 25.305923 hw_loss 0.322008 lr 0.00085448 rank 4
2023-02-11 05:17:31,160 DEBUG TRAIN Batch 2/4800 loss 42.950546 loss_att 61.798546 loss_ctc 63.647919 loss_rnnt 34.675087 hw_loss 0.327414 lr 0.00085840 rank 7
2023-02-11 05:17:31,164 DEBUG TRAIN Batch 2/4800 loss 24.320326 loss_att 36.143848 loss_ctc 38.461922 loss_rnnt 16.633785 hw_loss 0.644304 lr 0.00086064 rank 1
2023-02-11 05:17:31,165 DEBUG TRAIN Batch 2/4800 loss 40.667332 loss_att 50.537811 loss_ctc 63.325851 loss_rnnt 33.595779 hw_loss 0.389310 lr 0.00086008 rank 0
2023-02-11 05:17:31,165 DEBUG TRAIN Batch 2/4800 loss 34.975540 loss_att 44.837368 loss_ctc 47.494202 loss_rnnt 25.333923 hw_loss 1.125018 lr 0.00085996 rank 2
2023-02-11 05:17:31,170 DEBUG TRAIN Batch 2/4800 loss 66.048340 loss_att 75.693527 loss_ctc 84.833061 loss_rnnt 57.811401 hw_loss 0.713113 lr 0.00085868 rank 3
2023-02-11 05:17:31,169 DEBUG TRAIN Batch 2/4800 loss 33.473850 loss_att 47.572636 loss_ctc 44.984528 loss_rnnt 27.456856 hw_loss 0.311715 lr 0.00085960 rank 6
2023-02-11 05:17:31,171 DEBUG TRAIN Batch 2/4800 loss 35.131798 loss_att 45.559338 loss_ctc 50.508820 loss_rnnt 28.877136 hw_loss 0.397290 lr 0.00085892 rank 5
2023-02-11 05:17:31,174 DEBUG TRAIN Batch 2/4800 loss 42.984535 loss_att 50.063995 loss_ctc 55.898098 loss_rnnt 37.815212 hw_loss 0.380930 lr 0.00085848 rank 4
2023-02-11 05:18:48,625 DEBUG TRAIN Batch 2/4900 loss 48.813408 loss_att 61.254971 loss_ctc 69.308662 loss_rnnt 38.877781 hw_loss 0.883989 lr 0.00086464 rank 1
2023-02-11 05:18:48,626 DEBUG TRAIN Batch 2/4900 loss 35.684078 loss_att 46.645592 loss_ctc 47.438347 loss_rnnt 28.279505 hw_loss 0.683444 lr 0.00086240 rank 7
2023-02-11 05:18:48,628 DEBUG TRAIN Batch 2/4900 loss 40.011818 loss_att 54.615120 loss_ctc 55.510391 loss_rnnt 34.083496 hw_loss 0.176472 lr 0.00086360 rank 6
2023-02-11 05:18:48,629 DEBUG TRAIN Batch 2/4900 loss 54.795769 loss_att 67.707001 loss_ctc 77.862854 loss_rnnt 47.440968 hw_loss 0.318176 lr 0.00086396 rank 2
2023-02-11 05:18:48,630 DEBUG TRAIN Batch 2/4900 loss 32.814159 loss_att 37.689381 loss_ctc 39.680641 loss_rnnt 25.797035 hw_loss 0.961229 lr 0.00086248 rank 4
2023-02-11 05:18:48,630 DEBUG TRAIN Batch 2/4900 loss 38.236179 loss_att 49.215954 loss_ctc 51.962395 loss_rnnt 30.561823 hw_loss 0.684045 lr 0.00086268 rank 3
2023-02-11 05:18:48,664 DEBUG TRAIN Batch 2/4900 loss 30.725922 loss_att 42.522186 loss_ctc 47.440994 loss_rnnt 21.682325 hw_loss 0.835437 lr 0.00086292 rank 5
2023-02-11 05:18:48,665 DEBUG TRAIN Batch 2/4900 loss 25.012339 loss_att 33.016907 loss_ctc 33.592880 loss_rnnt 20.585276 hw_loss 0.315390 lr 0.00086408 rank 0
2023-02-11 05:20:07,529 DEBUG TRAIN Batch 2/5000 loss 50.057056 loss_att 53.076157 loss_ctc 74.080559 loss_rnnt 42.315804 hw_loss 0.737682 lr 0.00086668 rank 3
2023-02-11 05:20:07,529 DEBUG TRAIN Batch 2/5000 loss 43.045364 loss_att 49.518379 loss_ctc 57.587452 loss_rnnt 36.878975 hw_loss 0.549907 lr 0.00086640 rank 7
2023-02-11 05:20:07,530 DEBUG TRAIN Batch 2/5000 loss 31.102276 loss_att 28.554081 loss_ctc 33.370243 loss_rnnt 24.529047 hw_loss 1.271338 lr 0.00086692 rank 5
2023-02-11 05:20:07,532 DEBUG TRAIN Batch 2/5000 loss 33.076088 loss_att 39.676983 loss_ctc 46.182583 loss_rnnt 24.359282 hw_loss 1.059206 lr 0.00086760 rank 6
2023-02-11 05:20:07,532 DEBUG TRAIN Batch 2/5000 loss 34.977951 loss_att 42.785179 loss_ctc 45.915112 loss_rnnt 28.111990 hw_loss 0.721168 lr 0.00086808 rank 0
2023-02-11 05:20:07,533 DEBUG TRAIN Batch 2/5000 loss 36.805096 loss_att 43.622200 loss_ctc 54.164539 loss_rnnt 29.967550 hw_loss 0.592412 lr 0.00086796 rank 2
2023-02-11 05:20:07,535 DEBUG TRAIN Batch 2/5000 loss 32.381626 loss_att 33.027996 loss_ctc 42.508919 loss_rnnt 27.646667 hw_loss 0.610383 lr 0.00086864 rank 1
2023-02-11 05:20:07,536 DEBUG TRAIN Batch 2/5000 loss 41.173126 loss_att 44.937042 loss_ctc 56.528511 loss_rnnt 34.581036 hw_loss 0.710985 lr 0.00086648 rank 4
2023-02-11 05:21:23,239 DEBUG TRAIN Batch 2/5100 loss 48.957558 loss_att 58.822678 loss_ctc 74.536194 loss_rnnt 42.485054 hw_loss 0.204186 lr 0.00087092 rank 5
2023-02-11 05:21:23,239 DEBUG TRAIN Batch 2/5100 loss 26.997644 loss_att 28.399208 loss_ctc 31.593420 loss_rnnt 21.217583 hw_loss 0.916309 lr 0.00087196 rank 2
2023-02-11 05:21:23,240 DEBUG TRAIN Batch 2/5100 loss 67.451485 loss_att 82.877167 loss_ctc 89.864944 loss_rnnt 58.919979 hw_loss 0.460858 lr 0.00087068 rank 3
2023-02-11 05:21:23,241 DEBUG TRAIN Batch 2/5100 loss 68.659225 loss_att 73.275452 loss_ctc 85.003693 loss_rnnt 62.829437 hw_loss 0.511364 lr 0.00087040 rank 7
2023-02-11 05:21:23,242 DEBUG TRAIN Batch 2/5100 loss 33.808739 loss_att 48.019272 loss_ctc 52.171719 loss_rnnt 27.027390 hw_loss 0.279534 lr 0.00087264 rank 1
2023-02-11 05:21:23,242 DEBUG TRAIN Batch 2/5100 loss 33.512825 loss_att 32.308971 loss_ctc 40.816528 loss_rnnt 27.186298 hw_loss 1.048775 lr 0.00087160 rank 6
2023-02-11 05:21:23,244 DEBUG TRAIN Batch 2/5100 loss 26.552820 loss_att 28.093925 loss_ctc 28.531746 loss_rnnt 21.866749 hw_loss 0.771374 lr 0.00087048 rank 4
2023-02-11 05:21:23,245 DEBUG TRAIN Batch 2/5100 loss 49.728058 loss_att 59.465515 loss_ctc 68.010651 loss_rnnt 44.052975 hw_loss 0.241860 lr 0.00087208 rank 0
2023-02-11 05:22:39,024 DEBUG TRAIN Batch 2/5200 loss 21.399408 loss_att 36.836334 loss_ctc 36.907116 loss_rnnt 13.133984 hw_loss 0.583189 lr 0.00087492 rank 5
2023-02-11 05:22:39,025 DEBUG TRAIN Batch 2/5200 loss 31.211905 loss_att 45.697781 loss_ctc 43.399773 loss_rnnt 25.484352 hw_loss 0.225999 lr 0.00087468 rank 3
2023-02-11 05:22:39,026 DEBUG TRAIN Batch 2/5200 loss 30.753073 loss_att 46.479229 loss_ctc 47.095333 loss_rnnt 23.448988 hw_loss 0.371229 lr 0.00087608 rank 0
2023-02-11 05:22:39,028 DEBUG TRAIN Batch 2/5200 loss 54.585621 loss_att 58.677979 loss_ctc 79.137970 loss_rnnt 47.032650 hw_loss 0.648911 lr 0.00087560 rank 6
2023-02-11 05:22:39,030 DEBUG TRAIN Batch 2/5200 loss 58.860016 loss_att 73.008186 loss_ctc 88.891136 loss_rnnt 48.872112 hw_loss 0.591397 lr 0.00087664 rank 1
2023-02-11 05:22:39,030 DEBUG TRAIN Batch 2/5200 loss 39.066711 loss_att 49.754036 loss_ctc 54.047188 loss_rnnt 31.956142 hw_loss 0.557945 lr 0.00087440 rank 7
2023-02-11 05:22:39,030 DEBUG TRAIN Batch 2/5200 loss 30.730396 loss_att 37.650612 loss_ctc 45.719879 loss_rnnt 25.174206 hw_loss 0.407541 lr 0.00087596 rank 2
2023-02-11 05:22:39,032 DEBUG TRAIN Batch 2/5200 loss 60.222778 loss_att 87.584488 loss_ctc 82.170471 loss_rnnt 47.983757 hw_loss 0.720060 lr 0.00087448 rank 4
2023-02-11 05:23:55,869 DEBUG TRAIN Batch 2/5300 loss 32.452930 loss_att 39.685028 loss_ctc 41.676910 loss_rnnt 26.082844 hw_loss 0.692588 lr 0.00088008 rank 0
2023-02-11 05:23:55,869 DEBUG TRAIN Batch 2/5300 loss 26.388533 loss_att 32.269928 loss_ctc 29.135563 loss_rnnt 23.751791 hw_loss 0.205161 lr 0.00087848 rank 4
2023-02-11 05:23:55,871 DEBUG TRAIN Batch 2/5300 loss 22.617710 loss_att 35.806580 loss_ctc 38.488640 loss_rnnt 15.614504 hw_loss 0.421745 lr 0.00087868 rank 3
2023-02-11 05:23:55,872 DEBUG TRAIN Batch 2/5300 loss 27.376339 loss_att 34.845848 loss_ctc 41.867088 loss_rnnt 22.414593 hw_loss 0.287952 lr 0.00087960 rank 6
2023-02-11 05:23:55,874 DEBUG TRAIN Batch 2/5300 loss 31.187300 loss_att 43.820831 loss_ctc 57.057953 loss_rnnt 24.072723 hw_loss 0.213459 lr 0.00088064 rank 1
2023-02-11 05:23:55,873 DEBUG TRAIN Batch 2/5300 loss 59.325047 loss_att 66.961746 loss_ctc 81.848930 loss_rnnt 52.947289 hw_loss 0.346356 lr 0.00087840 rank 7
2023-02-11 05:23:55,875 DEBUG TRAIN Batch 2/5300 loss 36.645172 loss_att 43.707680 loss_ctc 46.090157 loss_rnnt 31.558764 hw_loss 0.452732 lr 0.00087892 rank 5
2023-02-11 05:23:55,880 DEBUG TRAIN Batch 2/5300 loss 38.274632 loss_att 45.334045 loss_ctc 51.965080 loss_rnnt 32.762650 hw_loss 0.426507 lr 0.00087996 rank 2
2023-02-11 05:25:13,136 DEBUG TRAIN Batch 2/5400 loss 27.829443 loss_att 32.033504 loss_ctc 34.661304 loss_rnnt 22.943731 hw_loss 0.587622 lr 0.00088292 rank 5
2023-02-11 05:25:13,137 DEBUG TRAIN Batch 2/5400 loss 30.745857 loss_att 40.750168 loss_ctc 48.712757 loss_rnnt 22.550453 hw_loss 0.712304 lr 0.00088408 rank 0
2023-02-11 05:25:13,138 DEBUG TRAIN Batch 2/5400 loss 39.714077 loss_att 44.028625 loss_ctc 48.954506 loss_rnnt 35.456635 hw_loss 0.405465 lr 0.00088240 rank 7
2023-02-11 05:25:13,140 DEBUG TRAIN Batch 2/5400 loss 43.252468 loss_att 59.382263 loss_ctc 73.177475 loss_rnnt 35.354771 hw_loss 0.127825 lr 0.00088396 rank 2
2023-02-11 05:25:13,140 DEBUG TRAIN Batch 2/5400 loss 39.396004 loss_att 51.914291 loss_ctc 53.983841 loss_rnnt 33.042480 hw_loss 0.357154 lr 0.00088268 rank 3
2023-02-11 05:25:13,142 DEBUG TRAIN Batch 2/5400 loss 26.185869 loss_att 34.660362 loss_ctc 36.298622 loss_rnnt 19.671085 hw_loss 0.650909 lr 0.00088464 rank 1
2023-02-11 05:25:13,145 DEBUG TRAIN Batch 2/5400 loss 32.628742 loss_att 39.744034 loss_ctc 51.074593 loss_rnnt 23.844440 hw_loss 0.919087 lr 0.00088248 rank 4
2023-02-11 05:25:13,189 DEBUG TRAIN Batch 2/5400 loss 51.095036 loss_att 60.897255 loss_ctc 71.402115 loss_rnnt 44.422646 hw_loss 0.375811 lr 0.00088360 rank 6
2023-02-11 05:26:28,612 DEBUG TRAIN Batch 2/5500 loss 29.888927 loss_att 38.572403 loss_ctc 47.265953 loss_rnnt 24.048975 hw_loss 0.334935 lr 0.00088640 rank 7
2023-02-11 05:26:28,614 DEBUG TRAIN Batch 2/5500 loss 36.483116 loss_att 45.141533 loss_ctc 48.317257 loss_rnnt 30.187778 hw_loss 0.559831 lr 0.00088808 rank 0
2023-02-11 05:26:28,614 DEBUG TRAIN Batch 2/5500 loss 62.883053 loss_att 69.033798 loss_ctc 77.132408 loss_rnnt 56.438721 hw_loss 0.621425 lr 0.00088668 rank 3
2023-02-11 05:26:28,614 DEBUG TRAIN Batch 2/5500 loss 35.487255 loss_att 44.800869 loss_ctc 45.283783 loss_rnnt 29.999344 hw_loss 0.434810 lr 0.00088648 rank 4
2023-02-11 05:26:28,617 DEBUG TRAIN Batch 2/5500 loss 32.879246 loss_att 37.411507 loss_ctc 48.052689 loss_rnnt 27.801584 hw_loss 0.402765 lr 0.00088864 rank 1
2023-02-11 05:26:28,617 DEBUG TRAIN Batch 2/5500 loss 24.535847 loss_att 31.246086 loss_ctc 27.841335 loss_rnnt 19.283794 hw_loss 0.650489 lr 0.00088692 rank 5
2023-02-11 05:26:28,618 DEBUG TRAIN Batch 2/5500 loss 13.684975 loss_att 22.213192 loss_ctc 20.790565 loss_rnnt 8.921227 hw_loss 0.395755 lr 0.00088796 rank 2
2023-02-11 05:26:28,619 DEBUG TRAIN Batch 2/5500 loss 27.030767 loss_att 30.599541 loss_ctc 38.154804 loss_rnnt 19.315859 hw_loss 1.034615 lr 0.00088760 rank 6
2023-02-11 05:27:43,889 DEBUG TRAIN Batch 2/5600 loss 41.874844 loss_att 48.583691 loss_ctc 54.586349 loss_rnnt 36.504086 hw_loss 0.437648 lr 0.00089068 rank 3
2023-02-11 05:27:43,890 DEBUG TRAIN Batch 2/5600 loss 41.210133 loss_att 52.377048 loss_ctc 60.248024 loss_rnnt 35.657375 hw_loss 0.146436 lr 0.00089040 rank 7
2023-02-11 05:27:43,895 DEBUG TRAIN Batch 2/5600 loss 27.599899 loss_att 27.948847 loss_ctc 36.297348 loss_rnnt 21.918665 hw_loss 0.834710 lr 0.00089092 rank 5
2023-02-11 05:27:43,898 DEBUG TRAIN Batch 2/5600 loss 37.755028 loss_att 43.864990 loss_ctc 48.984455 loss_rnnt 32.240387 hw_loss 0.524135 lr 0.00089208 rank 0
2023-02-11 05:27:43,901 DEBUG TRAIN Batch 2/5600 loss 50.687737 loss_att 56.159740 loss_ctc 70.111443 loss_rnnt 43.321136 hw_loss 0.690445 lr 0.00089196 rank 2
2023-02-11 05:27:43,901 DEBUG TRAIN Batch 2/5600 loss 32.956413 loss_att 40.041382 loss_ctc 45.895725 loss_rnnt 23.741444 hw_loss 1.138637 lr 0.00089048 rank 4
2023-02-11 05:27:43,914 DEBUG TRAIN Batch 2/5600 loss 28.227800 loss_att 35.671352 loss_ctc 42.785957 loss_rnnt 20.435738 hw_loss 0.817924 lr 0.00089160 rank 6
2023-02-11 05:27:43,918 DEBUG TRAIN Batch 2/5600 loss 30.086300 loss_att 33.226692 loss_ctc 40.961304 loss_rnnt 22.929029 hw_loss 0.952349 lr 0.00089264 rank 1
2023-02-11 05:29:03,545 DEBUG TRAIN Batch 2/5700 loss 34.811676 loss_att 40.897781 loss_ctc 45.506592 loss_rnnt 32.092106 hw_loss 0.014317 lr 0.00089440 rank 7
2023-02-11 05:29:03,547 DEBUG TRAIN Batch 2/5700 loss 33.265923 loss_att 32.306431 loss_ctc 40.003223 loss_rnnt 24.949707 hw_loss 1.426839 lr 0.00089608 rank 0
2023-02-11 05:29:03,547 DEBUG TRAIN Batch 2/5700 loss 48.136322 loss_att 50.828079 loss_ctc 58.342690 loss_rnnt 41.705513 hw_loss 0.849676 lr 0.00089468 rank 3
2023-02-11 05:29:03,548 DEBUG TRAIN Batch 2/5700 loss 35.637566 loss_att 39.684235 loss_ctc 50.037132 loss_rnnt 31.105621 hw_loss 0.338000 lr 0.00089492 rank 5
2023-02-11 05:29:03,549 DEBUG TRAIN Batch 2/5700 loss 27.466949 loss_att 31.282684 loss_ctc 39.430683 loss_rnnt 22.299366 hw_loss 0.526738 lr 0.00089448 rank 4
2023-02-11 05:29:03,550 DEBUG TRAIN Batch 2/5700 loss 24.382320 loss_att 22.618410 loss_ctc 30.003986 loss_rnnt 19.056553 hw_loss 0.924187 lr 0.00089664 rank 1
2023-02-11 05:29:03,556 DEBUG TRAIN Batch 2/5700 loss 21.632187 loss_att 21.737593 loss_ctc 29.151236 loss_rnnt 14.931868 hw_loss 1.064381 lr 0.00089596 rank 2
2023-02-11 05:29:03,592 DEBUG TRAIN Batch 2/5700 loss 38.454769 loss_att 44.076344 loss_ctc 44.978096 loss_rnnt 33.993385 hw_loss 0.462617 lr 0.00089560 rank 6
2023-02-11 05:30:20,793 DEBUG TRAIN Batch 2/5800 loss 32.432484 loss_att 44.577995 loss_ctc 48.883354 loss_rnnt 26.215317 hw_loss 0.298990 lr 0.00089840 rank 7
2023-02-11 05:30:20,793 DEBUG TRAIN Batch 2/5800 loss 28.848822 loss_att 38.786865 loss_ctc 44.969200 loss_rnnt 22.480932 hw_loss 0.418294 lr 0.00089892 rank 5
2023-02-11 05:30:20,794 DEBUG TRAIN Batch 2/5800 loss 22.601574 loss_att 20.165401 loss_ctc 25.708176 loss_rnnt 17.381016 hw_loss 0.992546 lr 0.00089960 rank 6
2023-02-11 05:30:20,796 DEBUG TRAIN Batch 2/5800 loss 30.230421 loss_att 33.201614 loss_ctc 39.736572 loss_rnnt 24.415571 hw_loss 0.741211 lr 0.00090008 rank 0
2023-02-11 05:30:20,797 DEBUG TRAIN Batch 2/5800 loss 40.445869 loss_att 47.354084 loss_ctc 60.674034 loss_rnnt 35.309128 hw_loss 0.198378 lr 0.00090064 rank 1
2023-02-11 05:30:20,797 DEBUG TRAIN Batch 2/5800 loss 45.300938 loss_att 53.384773 loss_ctc 68.970886 loss_rnnt 38.621841 hw_loss 0.357438 lr 0.00089868 rank 3
2023-02-11 05:30:20,797 DEBUG TRAIN Batch 2/5800 loss 22.852467 loss_att 36.614204 loss_ctc 29.108212 loss_rnnt 16.204556 hw_loss 0.574025 lr 0.00089996 rank 2
2023-02-11 05:30:20,798 DEBUG TRAIN Batch 2/5800 loss 61.527702 loss_att 62.423763 loss_ctc 92.643738 loss_rnnt 53.364529 hw_loss 0.719093 lr 0.00089848 rank 4
2023-02-11 05:31:36,423 DEBUG TRAIN Batch 2/5900 loss 14.481838 loss_att 21.367569 loss_ctc 22.720341 loss_rnnt 10.066700 hw_loss 0.363661 lr 0.00090268 rank 3
2023-02-11 05:31:36,432 DEBUG TRAIN Batch 2/5900 loss 25.365524 loss_att 35.985519 loss_ctc 34.806328 loss_rnnt 20.141586 hw_loss 0.345219 lr 0.00090292 rank 5
2023-02-11 05:31:36,433 DEBUG TRAIN Batch 2/5900 loss 26.882727 loss_att 35.439198 loss_ctc 38.694244 loss_rnnt 21.213684 hw_loss 0.446790 lr 0.00090396 rank 2
2023-02-11 05:31:36,433 DEBUG TRAIN Batch 2/5900 loss 23.390896 loss_att 33.843231 loss_ctc 32.021019 loss_rnnt 17.336197 hw_loss 0.527540 lr 0.00090240 rank 7
2023-02-11 05:31:36,435 DEBUG TRAIN Batch 2/5900 loss 28.311064 loss_att 43.709957 loss_ctc 44.584633 loss_rnnt 19.767035 hw_loss 0.617708 lr 0.00090464 rank 1
2023-02-11 05:31:36,435 DEBUG TRAIN Batch 2/5900 loss 31.761969 loss_att 45.417412 loss_ctc 44.178856 loss_rnnt 24.643383 hw_loss 0.512234 lr 0.00090360 rank 6
2023-02-11 05:31:36,436 DEBUG TRAIN Batch 2/5900 loss 49.433750 loss_att 59.889507 loss_ctc 63.475395 loss_rnnt 42.565727 hw_loss 0.544623 lr 0.00090408 rank 0
2023-02-11 05:31:36,442 DEBUG TRAIN Batch 2/5900 loss 20.693914 loss_att 29.554932 loss_ctc 31.997917 loss_rnnt 15.320057 hw_loss 0.392710 lr 0.00090248 rank 4
2023-02-11 05:32:54,672 DEBUG TRAIN Batch 2/6000 loss 69.385056 loss_att 85.263405 loss_ctc 96.940765 loss_rnnt 59.993996 hw_loss 0.476492 lr 0.00090864 rank 1
2023-02-11 05:32:54,677 DEBUG TRAIN Batch 2/6000 loss 34.040657 loss_att 45.253521 loss_ctc 49.288483 loss_rnnt 27.892023 hw_loss 0.351191 lr 0.00090808 rank 0
2023-02-11 05:32:54,682 DEBUG TRAIN Batch 2/6000 loss 31.680241 loss_att 36.678612 loss_ctc 45.169739 loss_rnnt 28.160034 hw_loss 0.135362 lr 0.00090760 rank 6
2023-02-11 05:32:54,683 DEBUG TRAIN Batch 2/6000 loss 22.956968 loss_att 32.295113 loss_ctc 29.985546 loss_rnnt 17.871849 hw_loss 0.427565 lr 0.00090648 rank 4
2023-02-11 05:32:54,684 DEBUG TRAIN Batch 2/6000 loss 39.594734 loss_att 48.637878 loss_ctc 60.530972 loss_rnnt 31.318655 hw_loss 0.689242 lr 0.00090796 rank 2
2023-02-11 05:32:54,685 DEBUG TRAIN Batch 2/6000 loss 37.634094 loss_att 41.800240 loss_ctc 54.282589 loss_rnnt 31.778234 hw_loss 0.525530 lr 0.00090692 rank 5
2023-02-11 05:32:54,707 DEBUG TRAIN Batch 2/6000 loss 30.619322 loss_att 41.789021 loss_ctc 45.227417 loss_rnnt 26.015881 hw_loss 0.079079 lr 0.00090668 rank 3
2023-02-11 05:32:54,716 DEBUG TRAIN Batch 2/6000 loss 28.639288 loss_att 33.415020 loss_ctc 38.316525 loss_rnnt 22.488049 hw_loss 0.732337 lr 0.00090640 rank 7
2023-02-11 05:34:12,840 DEBUG TRAIN Batch 2/6100 loss 20.454361 loss_att 28.509487 loss_ctc 27.367424 loss_rnnt 14.918818 hw_loss 0.563021 lr 0.00091264 rank 1
2023-02-11 05:34:12,843 DEBUG TRAIN Batch 2/6100 loss 29.669035 loss_att 38.859001 loss_ctc 48.701168 loss_rnnt 23.692101 hw_loss 0.300248 lr 0.00091092 rank 5
2023-02-11 05:34:12,843 DEBUG TRAIN Batch 2/6100 loss 54.935005 loss_att 60.202332 loss_ctc 68.943390 loss_rnnt 47.640869 hw_loss 0.819916 lr 0.00091068 rank 3
2023-02-11 05:34:12,846 DEBUG TRAIN Batch 2/6100 loss 61.045998 loss_att 69.386017 loss_ctc 89.203354 loss_rnnt 52.254322 hw_loss 0.631755 lr 0.00091040 rank 7
2023-02-11 05:34:12,848 DEBUG TRAIN Batch 2/6100 loss 35.204796 loss_att 43.717896 loss_ctc 50.396778 loss_rnnt 29.691242 hw_loss 0.334750 lr 0.00091160 rank 6
2023-02-11 05:34:12,849 DEBUG TRAIN Batch 2/6100 loss 31.544540 loss_att 37.279289 loss_ctc 41.687809 loss_rnnt 25.761776 hw_loss 0.615633 lr 0.00091048 rank 4
2023-02-11 05:34:12,850 DEBUG TRAIN Batch 2/6100 loss 24.977026 loss_att 30.484535 loss_ctc 36.109650 loss_rnnt 18.350216 hw_loss 0.757680 lr 0.00091208 rank 0
2023-02-11 05:34:12,852 DEBUG TRAIN Batch 2/6100 loss 40.532352 loss_att 49.512394 loss_ctc 59.832626 loss_rnnt 34.634205 hw_loss 0.286644 lr 0.00091196 rank 2
2023-02-11 05:35:28,290 DEBUG TRAIN Batch 2/6200 loss 39.328686 loss_att 43.678761 loss_ctc 48.560303 loss_rnnt 33.580635 hw_loss 0.683841 lr 0.00091492 rank 5
2023-02-11 05:35:28,291 DEBUG TRAIN Batch 2/6200 loss 43.235901 loss_att 54.301888 loss_ctc 57.122631 loss_rnnt 37.418606 hw_loss 0.328601 lr 0.00091608 rank 0
2023-02-11 05:35:28,292 DEBUG TRAIN Batch 2/6200 loss 32.634483 loss_att 35.098305 loss_ctc 40.930225 loss_rnnt 26.169659 hw_loss 0.912368 lr 0.00091664 rank 1
2023-02-11 05:35:28,293 DEBUG TRAIN Batch 2/6200 loss 38.491573 loss_att 48.495338 loss_ctc 57.364479 loss_rnnt 31.426298 hw_loss 0.477775 lr 0.00091468 rank 3
2023-02-11 05:35:28,296 DEBUG TRAIN Batch 2/6200 loss 43.747879 loss_att 49.372528 loss_ctc 58.162167 loss_rnnt 36.828850 hw_loss 0.726036 lr 0.00091560 rank 6
2023-02-11 05:35:28,296 DEBUG TRAIN Batch 2/6200 loss 39.404060 loss_att 48.660423 loss_ctc 56.831905 loss_rnnt 32.093410 hw_loss 0.587937 lr 0.00091440 rank 7
2023-02-11 05:35:28,300 DEBUG TRAIN Batch 2/6200 loss 49.232914 loss_att 55.479713 loss_ctc 68.019989 loss_rnnt 43.296867 hw_loss 0.409077 lr 0.00091448 rank 4
2023-02-11 05:35:28,300 DEBUG TRAIN Batch 2/6200 loss 29.618917 loss_att 37.633366 loss_ctc 46.000244 loss_rnnt 24.174841 hw_loss 0.310690 lr 0.00091596 rank 2
2023-02-11 05:36:44,442 DEBUG TRAIN Batch 2/6300 loss 37.907829 loss_att 44.042686 loss_ctc 49.348141 loss_rnnt 32.040859 hw_loss 0.583992 lr 0.00092008 rank 0
2023-02-11 05:36:44,444 DEBUG TRAIN Batch 2/6300 loss 39.130203 loss_att 43.862022 loss_ctc 51.391628 loss_rnnt 33.662994 hw_loss 0.541122 lr 0.00091868 rank 3
2023-02-11 05:36:44,444 DEBUG TRAIN Batch 2/6300 loss 23.212339 loss_att 22.942982 loss_ctc 30.466288 loss_rnnt 18.180082 hw_loss 0.772300 lr 0.00091996 rank 2
2023-02-11 05:36:44,445 DEBUG TRAIN Batch 2/6300 loss 26.937815 loss_att 36.639141 loss_ctc 36.466053 loss_rnnt 20.890463 hw_loss 0.531873 lr 0.00091960 rank 6
2023-02-11 05:36:44,445 DEBUG TRAIN Batch 2/6300 loss 40.212944 loss_att 48.360138 loss_ctc 55.758408 loss_rnnt 34.061306 hw_loss 0.459277 lr 0.00092064 rank 1
2023-02-11 05:36:44,446 DEBUG TRAIN Batch 2/6300 loss 32.607899 loss_att 50.964024 loss_ctc 52.211700 loss_rnnt 25.406744 hw_loss 0.171767 lr 0.00091848 rank 4
2023-02-11 05:36:44,448 DEBUG TRAIN Batch 2/6300 loss 29.273474 loss_att 31.215311 loss_ctc 38.358177 loss_rnnt 24.059799 hw_loss 0.677627 lr 0.00091840 rank 7
2023-02-11 05:36:44,449 DEBUG TRAIN Batch 2/6300 loss 30.179771 loss_att 40.551044 loss_ctc 38.756332 loss_rnnt 23.991211 hw_loss 0.557018 lr 0.00091892 rank 5
2023-02-11 05:38:05,126 DEBUG TRAIN Batch 2/6400 loss 47.192696 loss_att 55.733692 loss_ctc 51.634808 loss_rnnt 44.242992 hw_loss 0.121729 lr 0.00092464 rank 1
2023-02-11 05:38:05,127 DEBUG TRAIN Batch 2/6400 loss 52.288570 loss_att 66.858978 loss_ctc 76.480835 loss_rnnt 44.744240 hw_loss 0.263365 lr 0.00092240 rank 7
2023-02-11 05:38:05,128 DEBUG TRAIN Batch 2/6400 loss 31.024244 loss_att 52.831776 loss_ctc 42.875877 loss_rnnt 22.222118 hw_loss 0.536326 lr 0.00092408 rank 0
2023-02-11 05:38:05,128 DEBUG TRAIN Batch 2/6400 loss 24.176302 loss_att 28.144390 loss_ctc 37.819111 loss_rnnt 20.558475 hw_loss 0.188469 lr 0.00092268 rank 3
2023-02-11 05:38:05,130 DEBUG TRAIN Batch 2/6400 loss 21.827150 loss_att 20.584789 loss_ctc 23.245855 loss_rnnt 15.249201 hw_loss 1.244486 lr 0.00092248 rank 4
2023-02-11 05:38:05,133 DEBUG TRAIN Batch 2/6400 loss 38.566956 loss_att 53.063011 loss_ctc 55.611420 loss_rnnt 31.212082 hw_loss 0.409325 lr 0.00092396 rank 2
2023-02-11 05:38:05,133 DEBUG TRAIN Batch 2/6400 loss 38.104412 loss_att 53.366722 loss_ctc 64.995346 loss_rnnt 29.522102 hw_loss 0.364574 lr 0.00092292 rank 5
2023-02-11 05:38:05,179 DEBUG TRAIN Batch 2/6400 loss 39.231586 loss_att 38.984211 loss_ctc 45.005516 loss_rnnt 32.962246 hw_loss 1.040430 lr 0.00092360 rank 6
2023-02-11 05:39:22,028 DEBUG TRAIN Batch 2/6500 loss 38.634945 loss_att 48.273964 loss_ctc 56.960995 loss_rnnt 32.794136 hw_loss 0.275537 lr 0.00092640 rank 7
2023-02-11 05:39:22,029 DEBUG TRAIN Batch 2/6500 loss 33.384705 loss_att 39.570686 loss_ctc 49.597763 loss_rnnt 26.871954 hw_loss 0.583840 lr 0.00092796 rank 2
2023-02-11 05:39:22,030 DEBUG TRAIN Batch 2/6500 loss 57.126255 loss_att 69.913193 loss_ctc 81.502411 loss_rnnt 47.785698 hw_loss 0.662441 lr 0.00092808 rank 0
2023-02-11 05:39:22,030 DEBUG TRAIN Batch 2/6500 loss 31.885647 loss_att 39.888309 loss_ctc 45.617973 loss_rnnt 26.340094 hw_loss 0.396383 lr 0.00092692 rank 5
2023-02-11 05:39:22,032 DEBUG TRAIN Batch 2/6500 loss 49.941628 loss_att 53.518066 loss_ctc 67.780731 loss_rnnt 43.574463 hw_loss 0.613749 lr 0.00092668 rank 3
2023-02-11 05:39:22,033 DEBUG TRAIN Batch 2/6500 loss 34.991676 loss_att 46.512569 loss_ctc 49.096127 loss_rnnt 25.756330 hw_loss 0.946982 lr 0.00092760 rank 6
2023-02-11 05:39:22,066 DEBUG TRAIN Batch 2/6500 loss 43.293041 loss_att 51.480927 loss_ctc 60.864281 loss_rnnt 37.611279 hw_loss 0.319003 lr 0.00092864 rank 1
2023-02-11 05:39:22,098 DEBUG TRAIN Batch 2/6500 loss 51.526974 loss_att 57.462814 loss_ctc 75.750580 loss_rnnt 43.867264 hw_loss 0.608012 lr 0.00092648 rank 4
2023-02-11 05:40:39,389 DEBUG TRAIN Batch 2/6600 loss 36.493233 loss_att 37.049187 loss_ctc 48.226269 loss_rnnt 32.747040 hw_loss 0.388237 lr 0.00093208 rank 0
2023-02-11 05:40:39,389 DEBUG TRAIN Batch 2/6600 loss 25.909407 loss_att 38.381592 loss_ctc 36.554329 loss_rnnt 17.927055 hw_loss 0.762861 lr 0.00093048 rank 4
2023-02-11 05:40:39,390 DEBUG TRAIN Batch 2/6600 loss 31.594114 loss_att 38.870209 loss_ctc 45.193314 loss_rnnt 25.313095 hw_loss 0.564857 lr 0.00093092 rank 5
2023-02-11 05:40:39,392 DEBUG TRAIN Batch 2/6600 loss 29.017115 loss_att 42.602276 loss_ctc 41.802773 loss_rnnt 22.526188 hw_loss 0.387964 lr 0.00093040 rank 7
2023-02-11 05:40:39,393 DEBUG TRAIN Batch 2/6600 loss 41.643398 loss_att 51.938953 loss_ctc 55.509850 loss_rnnt 35.772339 hw_loss 0.368079 lr 0.00093160 rank 6
2023-02-11 05:40:39,394 DEBUG TRAIN Batch 2/6600 loss 33.028728 loss_att 43.572937 loss_ctc 48.492645 loss_rnnt 27.272299 hw_loss 0.297325 lr 0.00093068 rank 3
2023-02-11 05:40:39,393 DEBUG TRAIN Batch 2/6600 loss 62.793259 loss_att 69.570473 loss_ctc 90.431625 loss_rnnt 54.031425 hw_loss 0.697739 lr 0.00093264 rank 1
2023-02-11 05:40:39,395 DEBUG TRAIN Batch 2/6600 loss 44.271423 loss_att 53.066006 loss_ctc 61.728577 loss_rnnt 37.213886 hw_loss 0.557062 lr 0.00093196 rank 2
2023-02-11 05:41:55,935 DEBUG TRAIN Batch 2/6700 loss 24.178558 loss_att 31.534145 loss_ctc 39.487003 loss_rnnt 19.231159 hw_loss 0.269091 lr 0.00093492 rank 5
2023-02-11 05:41:55,937 DEBUG TRAIN Batch 2/6700 loss 33.609409 loss_att 45.732483 loss_ctc 53.001549 loss_rnnt 25.594528 hw_loss 0.563371 lr 0.00093440 rank 7
2023-02-11 05:41:55,941 DEBUG TRAIN Batch 2/6700 loss 28.878607 loss_att 33.938019 loss_ctc 37.528107 loss_rnnt 23.184483 hw_loss 0.661682 lr 0.00093608 rank 0
2023-02-11 05:41:55,944 DEBUG TRAIN Batch 2/6700 loss 42.908115 loss_att 53.766670 loss_ctc 65.559692 loss_rnnt 34.970886 hw_loss 0.514745 lr 0.00093664 rank 1
2023-02-11 05:41:55,944 DEBUG TRAIN Batch 2/6700 loss 49.141945 loss_att 66.156227 loss_ctc 74.263245 loss_rnnt 40.082153 hw_loss 0.432643 lr 0.00093468 rank 3
2023-02-11 05:41:55,947 DEBUG TRAIN Batch 2/6700 loss 66.672195 loss_att 73.065636 loss_ctc 81.907883 loss_rnnt 59.667545 hw_loss 0.692724 lr 0.00093596 rank 2
2023-02-11 05:41:55,950 DEBUG TRAIN Batch 2/6700 loss 35.542393 loss_att 41.720497 loss_ctc 53.592255 loss_rnnt 28.646410 hw_loss 0.610071 lr 0.00093448 rank 4
2023-02-11 05:41:55,992 DEBUG TRAIN Batch 2/6700 loss 35.678299 loss_att 47.294003 loss_ctc 58.743145 loss_rnnt 27.487661 hw_loss 0.523535 lr 0.00093560 rank 6
2023-02-11 05:43:14,573 DEBUG TRAIN Batch 2/6800 loss 35.797173 loss_att 43.087975 loss_ctc 50.060555 loss_rnnt 30.070084 hw_loss 0.443839 lr 0.00093996 rank 2
2023-02-11 05:43:14,575 DEBUG TRAIN Batch 2/6800 loss 39.472225 loss_att 50.420563 loss_ctc 61.635601 loss_rnnt 31.091034 hw_loss 0.606826 lr 0.00093840 rank 7
2023-02-11 05:43:14,578 DEBUG TRAIN Batch 2/6800 loss 37.611198 loss_att 44.103439 loss_ctc 52.833092 loss_rnnt 32.163403 hw_loss 0.397455 lr 0.00094008 rank 0
2023-02-11 05:43:14,578 DEBUG TRAIN Batch 2/6800 loss 25.616779 loss_att 36.177284 loss_ctc 38.526520 loss_rnnt 18.077461 hw_loss 0.694859 lr 0.00093868 rank 3
2023-02-11 05:43:14,579 DEBUG TRAIN Batch 2/6800 loss 31.337376 loss_att 36.441326 loss_ctc 40.222462 loss_rnnt 25.112591 hw_loss 0.753622 lr 0.00093892 rank 5
2023-02-11 05:43:14,583 DEBUG TRAIN Batch 2/6800 loss 39.716228 loss_att 51.165726 loss_ctc 60.401447 loss_rnnt 30.806015 hw_loss 0.724178 lr 0.00093848 rank 4
2023-02-11 05:43:14,583 DEBUG TRAIN Batch 2/6800 loss 52.349705 loss_att 60.898705 loss_ctc 69.722702 loss_rnnt 44.361771 hw_loss 0.742826 lr 0.00093960 rank 6
2023-02-11 05:43:14,627 DEBUG TRAIN Batch 2/6800 loss 29.118460 loss_att 36.251282 loss_ctc 43.905331 loss_rnnt 22.442322 hw_loss 0.614623 lr 0.00094064 rank 1
2023-02-11 05:44:32,120 DEBUG TRAIN Batch 2/6900 loss 42.879669 loss_att 46.136871 loss_ctc 54.205135 loss_rnnt 38.285492 hw_loss 0.456126 lr 0.00094408 rank 0
2023-02-11 05:44:32,125 DEBUG TRAIN Batch 2/6900 loss 22.905991 loss_att 33.734627 loss_ctc 33.258827 loss_rnnt 16.989643 hw_loss 0.444421 lr 0.00094464 rank 1
2023-02-11 05:44:32,124 DEBUG TRAIN Batch 2/6900 loss 39.628887 loss_att 43.258881 loss_ctc 52.286816 loss_rnnt 34.936958 hw_loss 0.427163 lr 0.00094268 rank 3
2023-02-11 05:44:32,126 DEBUG TRAIN Batch 2/6900 loss 29.049526 loss_att 42.317513 loss_ctc 39.644730 loss_rnnt 21.840302 hw_loss 0.589300 lr 0.00094240 rank 7
2023-02-11 05:44:32,131 DEBUG TRAIN Batch 2/6900 loss 39.588497 loss_att 42.005444 loss_ctc 43.167084 loss_rnnt 34.557632 hw_loss 0.763188 lr 0.00094248 rank 4
2023-02-11 05:44:32,131 DEBUG TRAIN Batch 2/6900 loss 36.078667 loss_att 47.077785 loss_ctc 53.535278 loss_rnnt 29.028233 hw_loss 0.473074 lr 0.00094292 rank 5
2023-02-11 05:44:32,131 DEBUG TRAIN Batch 2/6900 loss 38.606377 loss_att 48.694744 loss_ctc 52.206676 loss_rnnt 32.361214 hw_loss 0.452647 lr 0.00094396 rank 2
2023-02-11 05:44:32,175 DEBUG TRAIN Batch 2/6900 loss 38.826065 loss_att 44.949123 loss_ctc 56.041695 loss_rnnt 32.072334 hw_loss 0.606320 lr 0.00094360 rank 6
2023-02-11 05:45:50,147 DEBUG TRAIN Batch 2/7000 loss 32.049660 loss_att 38.355091 loss_ctc 44.944866 loss_rnnt 26.014637 hw_loss 0.572732 lr 0.00094640 rank 7
2023-02-11 05:45:50,148 DEBUG TRAIN Batch 2/7000 loss 23.055031 loss_att 28.221552 loss_ctc 26.540949 loss_rnnt 17.753626 hw_loss 0.713121 lr 0.00094760 rank 6
2023-02-11 05:45:50,150 DEBUG TRAIN Batch 2/7000 loss 29.341845 loss_att 43.842308 loss_ctc 36.959114 loss_rnnt 24.420347 hw_loss 0.188582 lr 0.00094692 rank 5
2023-02-11 05:45:50,153 DEBUG TRAIN Batch 2/7000 loss 26.714613 loss_att 26.583199 loss_ctc 29.852428 loss_rnnt 21.657413 hw_loss 0.874707 lr 0.00094668 rank 3
2023-02-11 05:45:50,155 DEBUG TRAIN Batch 2/7000 loss 22.329191 loss_att 21.438717 loss_ctc 26.032419 loss_rnnt 15.091847 hw_loss 1.297814 lr 0.00094808 rank 0
2023-02-11 05:45:50,156 DEBUG TRAIN Batch 2/7000 loss 34.651966 loss_att 49.023117 loss_ctc 44.447826 loss_rnnt 28.080715 hw_loss 0.448295 lr 0.00094796 rank 2
2023-02-11 05:45:50,156 DEBUG TRAIN Batch 2/7000 loss 32.024876 loss_att 31.974430 loss_ctc 37.511036 loss_rnnt 27.618780 hw_loss 0.690881 lr 0.00094864 rank 1
2023-02-11 05:45:50,157 DEBUG TRAIN Batch 2/7000 loss 38.851997 loss_att 42.535320 loss_ctc 58.975716 loss_rnnt 33.893204 hw_loss 0.288556 lr 0.00094648 rank 4
2023-02-11 05:47:08,446 DEBUG TRAIN Batch 2/7100 loss 31.861189 loss_att 37.386116 loss_ctc 49.334496 loss_rnnt 26.763571 hw_loss 0.311786 lr 0.00095208 rank 0
2023-02-11 05:47:08,446 DEBUG TRAIN Batch 2/7100 loss 39.617691 loss_att 47.043915 loss_ctc 57.573650 loss_rnnt 33.079144 hw_loss 0.498595 lr 0.00095264 rank 1
2023-02-11 05:47:08,450 DEBUG TRAIN Batch 2/7100 loss 29.712957 loss_att 37.088306 loss_ctc 41.544006 loss_rnnt 25.183605 hw_loss 0.276902 lr 0.00095040 rank 7
2023-02-11 05:47:08,449 DEBUG TRAIN Batch 2/7100 loss 33.876156 loss_att 49.202045 loss_ctc 63.073326 loss_rnnt 26.319160 hw_loss 0.112286 lr 0.00095160 rank 6
2023-02-11 05:47:08,449 DEBUG TRAIN Batch 2/7100 loss 25.753277 loss_att 34.396233 loss_ctc 37.437748 loss_rnnt 19.613407 hw_loss 0.535003 lr 0.00095068 rank 3
2023-02-11 05:47:08,455 DEBUG TRAIN Batch 2/7100 loss 39.817982 loss_att 52.176598 loss_ctc 58.712933 loss_rnnt 31.786444 hw_loss 0.570092 lr 0.00095092 rank 5
2023-02-11 05:47:08,470 DEBUG TRAIN Batch 2/7100 loss 58.702469 loss_att 73.991653 loss_ctc 87.114777 loss_rnnt 49.965893 hw_loss 0.354456 lr 0.00095196 rank 2
2023-02-11 05:47:08,499 DEBUG TRAIN Batch 2/7100 loss 43.532120 loss_att 55.217636 loss_ctc 57.104687 loss_rnnt 38.425980 hw_loss 0.179880 lr 0.00095048 rank 4
2023-02-11 05:48:25,405 DEBUG TRAIN Batch 2/7200 loss 50.137581 loss_att 56.525475 loss_ctc 56.675713 loss_rnnt 43.650200 hw_loss 0.813385 lr 0.00095664 rank 1
2023-02-11 05:48:25,405 DEBUG TRAIN Batch 2/7200 loss 41.656757 loss_att 52.717438 loss_ctc 59.931969 loss_rnnt 35.264297 hw_loss 0.326930 lr 0.00095596 rank 2
2023-02-11 05:48:25,407 DEBUG TRAIN Batch 2/7200 loss 25.709831 loss_att 35.535801 loss_ctc 40.550919 loss_rnnt 20.474535 hw_loss 0.242117 lr 0.00095468 rank 3
2023-02-11 05:48:25,407 DEBUG TRAIN Batch 2/7200 loss 59.111027 loss_att 69.865997 loss_ctc 86.678162 loss_rnnt 49.836159 hw_loss 0.646548 lr 0.00095492 rank 5
2023-02-11 05:48:25,408 DEBUG TRAIN Batch 2/7200 loss 32.760803 loss_att 42.725201 loss_ctc 47.891510 loss_rnnt 25.699394 hw_loss 0.572081 lr 0.00095440 rank 7
2023-02-11 05:48:25,408 DEBUG TRAIN Batch 2/7200 loss 28.635456 loss_att 45.701595 loss_ctc 42.544769 loss_rnnt 21.312325 hw_loss 0.385374 lr 0.00095608 rank 0
2023-02-11 05:48:25,410 DEBUG TRAIN Batch 2/7200 loss 58.871899 loss_att 71.780060 loss_ctc 88.040245 loss_rnnt 50.223907 hw_loss 0.408233 lr 0.00095448 rank 4
2023-02-11 05:48:25,412 DEBUG TRAIN Batch 2/7200 loss 30.260067 loss_att 41.296574 loss_ctc 48.039436 loss_rnnt 23.376204 hw_loss 0.432371 lr 0.00095560 rank 6
2023-02-11 05:49:42,213 DEBUG TRAIN Batch 2/7300 loss 30.968901 loss_att 38.983299 loss_ctc 45.416241 loss_rnnt 26.783167 hw_loss 0.123102 lr 0.00095892 rank 5
2023-02-11 05:49:42,214 DEBUG TRAIN Batch 2/7300 loss 41.565647 loss_att 53.331234 loss_ctc 64.292282 loss_rnnt 33.499550 hw_loss 0.503018 lr 0.00095868 rank 3
2023-02-11 05:49:42,215 DEBUG TRAIN Batch 2/7300 loss 39.342056 loss_att 46.100548 loss_ctc 57.239216 loss_rnnt 33.049774 hw_loss 0.478930 lr 0.00096008 rank 0
2023-02-11 05:49:42,219 DEBUG TRAIN Batch 2/7300 loss 13.523474 loss_att 22.075933 loss_ctc 17.135832 loss_rnnt 9.519503 hw_loss 0.339718 lr 0.00095840 rank 7
2023-02-11 05:49:42,222 DEBUG TRAIN Batch 2/7300 loss 24.584957 loss_att 30.723154 loss_ctc 35.239632 loss_rnnt 19.159697 hw_loss 0.520687 lr 0.00096064 rank 1
2023-02-11 05:49:42,247 DEBUG TRAIN Batch 2/7300 loss 35.732224 loss_att 39.493042 loss_ctc 45.349926 loss_rnnt 29.408123 hw_loss 0.804295 lr 0.00095848 rank 4
2023-02-11 05:49:42,259 DEBUG TRAIN Batch 2/7300 loss 41.873192 loss_att 47.729790 loss_ctc 55.017815 loss_rnnt 34.949333 hw_loss 0.749986 lr 0.00095960 rank 6
2023-02-11 05:49:42,268 DEBUG TRAIN Batch 2/7300 loss 49.567890 loss_att 57.155708 loss_ctc 61.628651 loss_rnnt 43.247040 hw_loss 0.599097 lr 0.00095996 rank 2
2023-02-11 05:50:58,551 DEBUG TRAIN Batch 2/7400 loss 37.976261 loss_att 41.235104 loss_ctc 45.508224 loss_rnnt 32.860008 hw_loss 0.648791 lr 0.00096292 rank 5
2023-02-11 05:50:58,553 DEBUG TRAIN Batch 2/7400 loss 33.695187 loss_att 39.071777 loss_ctc 46.493999 loss_rnnt 28.261427 hw_loss 0.497237 lr 0.00096408 rank 0
2023-02-11 05:50:58,554 DEBUG TRAIN Batch 2/7400 loss 23.703629 loss_att 30.394604 loss_ctc 30.736631 loss_rnnt 19.779594 hw_loss 0.309019 lr 0.00096396 rank 2
2023-02-11 05:50:58,556 DEBUG TRAIN Batch 2/7400 loss 38.169174 loss_att 47.030655 loss_ctc 66.156143 loss_rnnt 30.079977 hw_loss 0.484745 lr 0.00096360 rank 6
2023-02-11 05:50:58,557 DEBUG TRAIN Batch 2/7400 loss 33.779465 loss_att 42.421677 loss_ctc 47.024048 loss_rnnt 27.880110 hw_loss 0.450931 lr 0.00096268 rank 3
2023-02-11 05:50:58,561 DEBUG TRAIN Batch 2/7400 loss 42.653679 loss_att 55.181046 loss_ctc 65.839226 loss_rnnt 35.188671 hw_loss 0.350274 lr 0.00096240 rank 7
2023-02-11 05:50:58,564 DEBUG TRAIN Batch 2/7400 loss 54.790569 loss_att 62.339310 loss_ctc 75.463295 loss_rnnt 47.672550 hw_loss 0.534732 lr 0.00096464 rank 1
2023-02-11 05:50:58,565 DEBUG TRAIN Batch 2/7400 loss 31.154833 loss_att 39.392765 loss_ctc 48.532188 loss_rnnt 25.811630 hw_loss 0.258494 lr 0.00096248 rank 4
2023-02-11 05:52:16,837 DEBUG TRAIN Batch 2/7500 loss 41.208736 loss_att 41.953556 loss_ctc 55.849133 loss_rnnt 34.110767 hw_loss 0.936929 lr 0.00096796 rank 2
2023-02-11 05:52:16,839 DEBUG TRAIN Batch 2/7500 loss 21.692093 loss_att 32.534195 loss_ctc 37.202454 loss_rnnt 17.414608 hw_loss 0.007691 lr 0.00096808 rank 0
2023-02-11 05:52:16,841 DEBUG TRAIN Batch 2/7500 loss 31.603910 loss_att 36.530663 loss_ctc 41.915009 loss_rnnt 27.595406 hw_loss 0.309064 lr 0.00096668 rank 3
2023-02-11 05:52:16,843 DEBUG TRAIN Batch 2/7500 loss 39.166332 loss_att 43.834457 loss_ctc 55.653942 loss_rnnt 29.492815 hw_loss 1.226540 lr 0.00096760 rank 6
2023-02-11 05:52:16,843 DEBUG TRAIN Batch 2/7500 loss 28.370388 loss_att 25.271465 loss_ctc 32.061020 loss_rnnt 21.071066 hw_loss 1.392567 lr 0.00096692 rank 5
2023-02-11 05:52:16,844 DEBUG TRAIN Batch 2/7500 loss 37.775330 loss_att 46.390331 loss_ctc 58.870247 loss_rnnt 29.680763 hw_loss 0.667296 lr 0.00096640 rank 7
2023-02-11 05:52:16,844 DEBUG TRAIN Batch 2/7500 loss 32.001160 loss_att 42.242340 loss_ctc 44.595333 loss_rnnt 26.126984 hw_loss 0.402509 lr 0.00096864 rank 1
2023-02-11 05:52:16,893 DEBUG TRAIN Batch 2/7500 loss 30.151213 loss_att 39.021851 loss_ctc 40.345955 loss_rnnt 24.579218 hw_loss 0.457231 lr 0.00096648 rank 4
2023-02-11 05:53:31,818 DEBUG TRAIN Batch 2/7600 loss 27.829964 loss_att 37.642895 loss_ctc 37.614544 loss_rnnt 20.772892 hw_loss 0.710601 lr 0.00097092 rank 5
2023-02-11 05:53:31,819 DEBUG TRAIN Batch 2/7600 loss 27.517193 loss_att 23.694317 loss_ctc 31.340469 loss_rnnt 21.570004 hw_loss 1.162874 lr 0.00097208 rank 0
2023-02-11 05:53:31,820 DEBUG TRAIN Batch 2/7600 loss 27.601965 loss_att 34.339279 loss_ctc 39.441093 loss_rnnt 21.534828 hw_loss 0.588961 lr 0.00097160 rank 6
2023-02-11 05:53:31,823 DEBUG TRAIN Batch 2/7600 loss 45.251266 loss_att 46.475807 loss_ctc 59.626709 loss_rnnt 38.974121 hw_loss 0.771658 lr 0.00097068 rank 3
2023-02-11 05:53:31,823 DEBUG TRAIN Batch 2/7600 loss 33.093781 loss_att 34.398746 loss_ctc 45.322792 loss_rnnt 26.314814 hw_loss 0.916394 lr 0.00097196 rank 2
2023-02-11 05:53:31,824 DEBUG TRAIN Batch 2/7600 loss 39.390717 loss_att 43.593876 loss_ctc 52.403614 loss_rnnt 34.528656 hw_loss 0.428696 lr 0.00097040 rank 7
2023-02-11 05:53:31,826 DEBUG TRAIN Batch 2/7600 loss 32.773129 loss_att 37.419079 loss_ctc 41.418133 loss_rnnt 26.350788 hw_loss 0.813841 lr 0.00097048 rank 4
2023-02-11 05:53:31,830 DEBUG TRAIN Batch 2/7600 loss 25.979837 loss_att 31.655273 loss_ctc 39.391964 loss_rnnt 20.428572 hw_loss 0.492730 lr 0.00097264 rank 1
2023-02-11 05:54:48,900 DEBUG TRAIN Batch 2/7700 loss 26.694651 loss_att 36.376728 loss_ctc 40.234886 loss_rnnt 21.068668 hw_loss 0.353288 lr 0.00097468 rank 3
2023-02-11 05:54:48,901 DEBUG TRAIN Batch 2/7700 loss 30.320442 loss_att 40.009758 loss_ctc 44.206314 loss_rnnt 25.609594 hw_loss 0.172788 lr 0.00097492 rank 5
2023-02-11 05:54:48,910 DEBUG TRAIN Batch 2/7700 loss 42.647964 loss_att 57.808273 loss_ctc 61.869640 loss_rnnt 34.669533 hw_loss 0.446902 lr 0.00097664 rank 1
2023-02-11 05:54:48,910 DEBUG TRAIN Batch 2/7700 loss 20.874523 loss_att 17.932444 loss_ctc 20.907227 loss_rnnt 14.669880 hw_loss 1.272881 lr 0.00097448 rank 4
2023-02-11 05:54:48,913 DEBUG TRAIN Batch 2/7700 loss 36.788235 loss_att 46.804939 loss_ctc 51.555321 loss_rnnt 29.838675 hw_loss 0.558239 lr 0.00097596 rank 2
2023-02-11 05:54:48,921 DEBUG TRAIN Batch 2/7700 loss 40.867046 loss_att 46.866348 loss_ctc 56.322720 loss_rnnt 36.593201 hw_loss 0.189980 lr 0.00097440 rank 7
2023-02-11 05:54:48,931 DEBUG TRAIN Batch 2/7700 loss 35.116875 loss_att 41.336315 loss_ctc 51.006989 loss_rnnt 28.260929 hw_loss 0.655007 lr 0.00097608 rank 0
2023-02-11 05:54:48,952 DEBUG TRAIN Batch 2/7700 loss 29.972670 loss_att 33.697342 loss_ctc 40.742714 loss_rnnt 24.359354 hw_loss 0.643570 lr 0.00097560 rank 6
2023-02-11 05:56:06,721 DEBUG TRAIN Batch 2/7800 loss 28.403168 loss_att 35.915066 loss_ctc 45.599182 loss_rnnt 22.566374 hw_loss 0.382802 lr 0.00097892 rank 5
2023-02-11 05:56:06,723 DEBUG TRAIN Batch 2/7800 loss 57.553593 loss_att 70.993729 loss_ctc 70.932358 loss_rnnt 50.520012 hw_loss 0.480323 lr 0.00098008 rank 0
2023-02-11 05:56:06,725 DEBUG TRAIN Batch 2/7800 loss 43.934570 loss_att 49.037453 loss_ctc 67.637413 loss_rnnt 37.213284 hw_loss 0.476312 lr 0.00098064 rank 1
2023-02-11 05:56:06,727 DEBUG TRAIN Batch 2/7800 loss 41.909195 loss_att 53.853374 loss_ctc 68.001404 loss_rnnt 33.848946 hw_loss 0.411085 lr 0.00097868 rank 3
2023-02-11 05:56:06,728 DEBUG TRAIN Batch 2/7800 loss 40.355114 loss_att 55.406532 loss_ctc 59.920563 loss_rnnt 32.738960 hw_loss 0.374465 lr 0.00097848 rank 4
2023-02-11 05:56:06,729 DEBUG TRAIN Batch 2/7800 loss 41.776623 loss_att 49.830322 loss_ctc 59.810360 loss_rnnt 33.476173 hw_loss 0.803478 lr 0.00097996 rank 2
2023-02-11 05:56:06,749 DEBUG TRAIN Batch 2/7800 loss 30.147684 loss_att 40.046192 loss_ctc 51.340240 loss_rnnt 24.022284 hw_loss 0.247505 lr 0.00097840 rank 7
2023-02-11 05:56:06,773 DEBUG TRAIN Batch 2/7800 loss 32.956467 loss_att 40.099258 loss_ctc 45.897453 loss_rnnt 27.337719 hw_loss 0.462136 lr 0.00097960 rank 6
2023-02-11 05:57:24,174 DEBUG TRAIN Batch 2/7900 loss 27.782084 loss_att 36.073879 loss_ctc 39.596615 loss_rnnt 21.779617 hw_loss 0.519157 lr 0.00098408 rank 0
2023-02-11 05:57:24,178 DEBUG TRAIN Batch 2/7900 loss 34.291538 loss_att 39.368145 loss_ctc 43.838799 loss_rnnt 28.520056 hw_loss 0.653099 lr 0.00098268 rank 3
2023-02-11 05:57:24,179 DEBUG TRAIN Batch 2/7900 loss 37.638535 loss_att 45.874912 loss_ctc 66.780312 loss_rnnt 31.745031 hw_loss 0.067623 lr 0.00098464 rank 1
2023-02-11 05:57:24,182 DEBUG TRAIN Batch 2/7900 loss 32.572121 loss_att 41.279129 loss_ctc 58.081108 loss_rnnt 24.247845 hw_loss 0.596564 lr 0.00098360 rank 6
2023-02-11 05:57:24,182 DEBUG TRAIN Batch 2/7900 loss 43.753036 loss_att 59.422485 loss_ctc 62.530621 loss_rnnt 35.420006 hw_loss 0.505400 lr 0.00098248 rank 4
2023-02-11 05:57:24,183 DEBUG TRAIN Batch 2/7900 loss 43.184883 loss_att 54.473633 loss_ctc 60.167080 loss_rnnt 36.702496 hw_loss 0.367565 lr 0.00098396 rank 2
2023-02-11 05:57:24,186 DEBUG TRAIN Batch 2/7900 loss 40.685902 loss_att 45.952087 loss_ctc 54.085724 loss_rnnt 35.961830 hw_loss 0.353285 lr 0.00098292 rank 5
2023-02-11 05:57:24,185 DEBUG TRAIN Batch 2/7900 loss 39.319828 loss_att 44.416149 loss_ctc 52.983299 loss_rnnt 35.604301 hw_loss 0.163962 lr 0.00098240 rank 7
2023-02-11 05:58:40,650 DEBUG TRAIN Batch 2/8000 loss 28.321470 loss_att 34.169327 loss_ctc 40.868866 loss_rnnt 21.644096 hw_loss 0.719028 lr 0.00098692 rank 5
2023-02-11 05:58:40,652 DEBUG TRAIN Batch 2/8000 loss 33.009815 loss_att 42.904064 loss_ctc 49.845680 loss_rnnt 25.109194 hw_loss 0.689435 lr 0.00098668 rank 3
2023-02-11 05:58:40,654 DEBUG TRAIN Batch 2/8000 loss 28.948868 loss_att 32.253052 loss_ctc 36.866573 loss_rnnt 24.948643 hw_loss 0.428193 lr 0.00098640 rank 7
2023-02-11 05:58:40,654 DEBUG TRAIN Batch 2/8000 loss 51.072395 loss_att 57.073051 loss_ctc 74.496223 loss_rnnt 43.025993 hw_loss 0.698080 lr 0.00098808 rank 0
2023-02-11 05:58:40,658 DEBUG TRAIN Batch 2/8000 loss 46.448608 loss_att 57.627468 loss_ctc 63.456444 loss_rnnt 38.932152 hw_loss 0.564933 lr 0.00098864 rank 1
2023-02-11 05:58:40,658 DEBUG TRAIN Batch 2/8000 loss 38.855381 loss_att 47.977859 loss_ctc 56.020893 loss_rnnt 32.228973 hw_loss 0.471221 lr 0.00098648 rank 4
2023-02-11 05:58:40,663 DEBUG TRAIN Batch 2/8000 loss 19.982723 loss_att 27.153954 loss_ctc 32.079483 loss_rnnt 15.213000 hw_loss 0.322983 lr 0.00098760 rank 6
2023-02-11 05:58:40,699 DEBUG TRAIN Batch 2/8000 loss 34.239433 loss_att 42.044895 loss_ctc 54.913162 loss_rnnt 28.395367 hw_loss 0.286215 lr 0.00098796 rank 2
2023-02-11 05:59:57,340 DEBUG TRAIN Batch 2/8100 loss 29.828852 loss_att 32.663658 loss_ctc 38.542488 loss_rnnt 25.937742 hw_loss 0.405437 lr 0.00099092 rank 5
2023-02-11 05:59:57,341 DEBUG TRAIN Batch 2/8100 loss 29.362938 loss_att 38.982117 loss_ctc 39.895142 loss_rnnt 22.968731 hw_loss 0.574890 lr 0.00099196 rank 2
2023-02-11 05:59:57,342 DEBUG TRAIN Batch 2/8100 loss 35.103073 loss_att 35.464348 loss_ctc 47.230846 loss_rnnt 30.939659 hw_loss 0.463898 lr 0.00099068 rank 3
2023-02-11 05:59:57,344 DEBUG TRAIN Batch 2/8100 loss 21.029615 loss_att 32.323624 loss_ctc 36.323051 loss_rnnt 16.273346 hw_loss 0.085940 lr 0.00099040 rank 7
2023-02-11 05:59:57,345 DEBUG TRAIN Batch 2/8100 loss 32.660416 loss_att 40.140739 loss_ctc 47.006783 loss_rnnt 26.418411 hw_loss 0.531205 lr 0.00099208 rank 0
2023-02-11 05:59:57,346 DEBUG TRAIN Batch 2/8100 loss 29.960390 loss_att 34.053509 loss_ctc 43.726349 loss_rnnt 23.816727 hw_loss 0.654296 lr 0.00099264 rank 1
2023-02-11 05:59:57,352 DEBUG TRAIN Batch 2/8100 loss 47.874775 loss_att 56.456020 loss_ctc 67.338516 loss_rnnt 40.057095 hw_loss 0.657425 lr 0.00099160 rank 6
2023-02-11 05:59:57,385 DEBUG TRAIN Batch 2/8100 loss 28.091507 loss_att 32.405384 loss_ctc 36.183876 loss_rnnt 23.922823 hw_loss 0.417549 lr 0.00099048 rank 4
2023-02-11 06:01:14,633 DEBUG TRAIN Batch 2/8200 loss 34.810982 loss_att 39.773643 loss_ctc 51.841160 loss_rnnt 27.290257 hw_loss 0.798281 lr 0.00099440 rank 7
2023-02-11 06:01:14,635 DEBUG TRAIN Batch 2/8200 loss 50.134247 loss_att 69.362038 loss_ctc 73.052979 loss_rnnt 39.319992 hw_loss 0.733661 lr 0.00099492 rank 5
2023-02-11 06:01:14,637 DEBUG TRAIN Batch 2/8200 loss 46.612488 loss_att 51.544525 loss_ctc 64.617485 loss_rnnt 38.851246 hw_loss 0.820156 lr 0.00099596 rank 2
2023-02-11 06:01:14,640 DEBUG TRAIN Batch 2/8200 loss 42.271042 loss_att 45.746201 loss_ctc 54.121223 loss_rnnt 36.495602 hw_loss 0.656323 lr 0.00099664 rank 1
2023-02-11 06:01:14,641 DEBUG TRAIN Batch 2/8200 loss 39.513134 loss_att 43.247993 loss_ctc 61.185619 loss_rnnt 34.899597 hw_loss 0.183170 lr 0.00099468 rank 3
2023-02-11 06:01:14,642 DEBUG TRAIN Batch 2/8200 loss 27.616148 loss_att 28.269022 loss_ctc 37.598034 loss_rnnt 20.982708 hw_loss 0.969741 lr 0.00099608 rank 0
2023-02-11 06:01:14,643 DEBUG TRAIN Batch 2/8200 loss 49.722080 loss_att 53.578514 loss_ctc 71.246643 loss_rnnt 42.071301 hw_loss 0.751791 lr 0.00099448 rank 4
2023-02-11 06:01:14,652 DEBUG TRAIN Batch 2/8200 loss 47.724125 loss_att 48.615784 loss_ctc 67.259071 loss_rnnt 42.708450 hw_loss 0.418627 lr 0.00099560 rank 6
2023-02-11 06:02:30,086 DEBUG TRAIN Batch 2/8300 loss 61.596630 loss_att 68.701057 loss_ctc 88.504349 loss_rnnt 55.038300 hw_loss 0.290578 lr 0.00099996 rank 0
2023-02-11 06:02:30,087 DEBUG TRAIN Batch 2/8300 loss 21.650232 loss_att 29.136162 loss_ctc 31.349445 loss_rnnt 16.347639 hw_loss 0.471034 lr 0.00099960 rank 6
2023-02-11 06:02:30,087 DEBUG TRAIN Batch 2/8300 loss 26.579632 loss_att 30.864819 loss_ctc 34.048225 loss_rnnt 21.271816 hw_loss 0.647806 lr 0.00099868 rank 3
2023-02-11 06:02:30,089 DEBUG TRAIN Batch 2/8300 loss 45.666203 loss_att 58.984467 loss_ctc 63.539429 loss_rnnt 37.834396 hw_loss 0.522198 lr 0.00099996 rank 2
2023-02-11 06:02:30,091 DEBUG TRAIN Batch 2/8300 loss 40.206482 loss_att 48.791573 loss_ctc 61.228977 loss_rnnt 32.374481 hw_loss 0.620997 lr 0.00099840 rank 7
2023-02-11 06:02:30,092 DEBUG TRAIN Batch 2/8300 loss 44.291279 loss_att 53.382057 loss_ctc 55.285461 loss_rnnt 40.693130 hw_loss 0.058894 lr 0.00099892 rank 5
2023-02-11 06:02:30,095 DEBUG TRAIN Batch 2/8300 loss 44.805817 loss_att 46.996719 loss_ctc 58.778412 loss_rnnt 38.320404 hw_loss 0.784541 lr 0.00099968 rank 1
2023-02-11 06:02:30,096 DEBUG TRAIN Batch 2/8300 loss 47.043476 loss_att 49.272835 loss_ctc 60.937569 loss_rnnt 39.934166 hw_loss 0.902042 lr 0.00099848 rank 4
2023-02-11 06:03:27,022 DEBUG CV Batch 2/0 loss 11.904501 loss_att 6.073905 loss_ctc 9.896407 loss_rnnt 5.939312 hw_loss 1.387323 history loss 11.463594 rank 7
2023-02-11 06:03:27,028 DEBUG CV Batch 2/0 loss 11.904501 loss_att 6.073905 loss_ctc 9.896407 loss_rnnt 5.939312 hw_loss 1.387323 history loss 11.463594 rank 1
2023-02-11 06:03:27,030 DEBUG CV Batch 2/0 loss 11.904501 loss_att 6.073905 loss_ctc 9.896407 loss_rnnt 5.939312 hw_loss 1.387323 history loss 11.463594 rank 3
2023-02-11 06:03:27,035 DEBUG CV Batch 2/0 loss 11.904501 loss_att 6.073905 loss_ctc 9.896407 loss_rnnt 5.939312 hw_loss 1.387323 history loss 11.463594 rank 4
2023-02-11 06:03:27,040 DEBUG CV Batch 2/0 loss 11.904501 loss_att 6.073905 loss_ctc 9.896407 loss_rnnt 5.939312 hw_loss 1.387323 history loss 11.463594 rank 5
2023-02-11 06:03:27,042 DEBUG CV Batch 2/0 loss 11.904501 loss_att 6.073905 loss_ctc 9.896407 loss_rnnt 5.939312 hw_loss 1.387323 history loss 11.463594 rank 0
2023-02-11 06:03:27,048 DEBUG CV Batch 2/0 loss 11.904501 loss_att 6.073905 loss_ctc 9.896407 loss_rnnt 5.939312 hw_loss 1.387323 history loss 11.463594 rank 2
2023-02-11 06:03:27,056 DEBUG CV Batch 2/0 loss 11.904501 loss_att 6.073905 loss_ctc 9.896407 loss_rnnt 5.939312 hw_loss 1.387323 history loss 11.463594 rank 6
2023-02-11 06:03:38,179 DEBUG CV Batch 2/100 loss 33.199543 loss_att 29.365681 loss_ctc 43.984112 loss_rnnt 25.641430 hw_loss 1.291303 history loss 17.253399 rank 6
2023-02-11 06:03:38,182 DEBUG CV Batch 2/100 loss 33.199543 loss_att 29.365681 loss_ctc 43.984112 loss_rnnt 25.641430 hw_loss 1.291303 history loss 17.253399 rank 0
2023-02-11 06:03:38,209 DEBUG CV Batch 2/100 loss 33.199543 loss_att 29.365681 loss_ctc 43.984112 loss_rnnt 25.641430 hw_loss 1.291303 history loss 17.253399 rank 7
2023-02-11 06:03:38,268 DEBUG CV Batch 2/100 loss 33.199543 loss_att 29.365681 loss_ctc 43.984112 loss_rnnt 25.641430 hw_loss 1.291303 history loss 17.253399 rank 5
2023-02-11 06:03:38,269 DEBUG CV Batch 2/100 loss 33.199543 loss_att 29.365681 loss_ctc 43.984112 loss_rnnt 25.641430 hw_loss 1.291303 history loss 17.253399 rank 3
2023-02-11 06:03:38,499 DEBUG CV Batch 2/100 loss 33.199543 loss_att 29.365681 loss_ctc 43.984112 loss_rnnt 25.641430 hw_loss 1.291303 history loss 17.253399 rank 4
2023-02-11 06:03:38,501 DEBUG CV Batch 2/100 loss 33.199543 loss_att 29.365681 loss_ctc 43.984112 loss_rnnt 25.641430 hw_loss 1.291303 history loss 17.253399 rank 2
2023-02-11 06:03:38,865 DEBUG CV Batch 2/100 loss 33.199543 loss_att 29.365681 loss_ctc 43.984112 loss_rnnt 25.641430 hw_loss 1.291303 history loss 17.253399 rank 1
2023-02-11 06:03:51,867 DEBUG CV Batch 2/200 loss 37.070492 loss_att 62.197376 loss_ctc 54.932526 loss_rnnt 29.067244 hw_loss 0.111801 history loss 18.285223 rank 0
2023-02-11 06:03:51,890 DEBUG CV Batch 2/200 loss 37.070492 loss_att 62.197376 loss_ctc 54.932526 loss_rnnt 29.067244 hw_loss 0.111801 history loss 18.285223 rank 3
2023-02-11 06:03:51,948 DEBUG CV Batch 2/200 loss 37.070492 loss_att 62.197376 loss_ctc 54.932526 loss_rnnt 29.067244 hw_loss 0.111801 history loss 18.285223 rank 7
2023-02-11 06:03:51,979 DEBUG CV Batch 2/200 loss 37.070492 loss_att 62.197376 loss_ctc 54.932526 loss_rnnt 29.067244 hw_loss 0.111801 history loss 18.285223 rank 5
2023-02-11 06:03:52,067 DEBUG CV Batch 2/200 loss 37.070492 loss_att 62.197376 loss_ctc 54.932526 loss_rnnt 29.067244 hw_loss 0.111801 history loss 18.285223 rank 6
2023-02-11 06:03:52,146 DEBUG CV Batch 2/200 loss 37.070492 loss_att 62.197376 loss_ctc 54.932526 loss_rnnt 29.067244 hw_loss 0.111801 history loss 18.285223 rank 4
2023-02-11 06:03:52,241 DEBUG CV Batch 2/200 loss 37.070492 loss_att 62.197376 loss_ctc 54.932526 loss_rnnt 29.067244 hw_loss 0.111801 history loss 18.285223 rank 1
2023-02-11 06:03:53,403 DEBUG CV Batch 2/200 loss 37.070492 loss_att 62.197376 loss_ctc 54.932526 loss_rnnt 29.067244 hw_loss 0.111801 history loss 18.285223 rank 2
2023-02-11 06:04:03,847 DEBUG CV Batch 2/300 loss 20.055359 loss_att 18.951088 loss_ctc 24.291996 loss_rnnt 13.028315 hw_loss 1.253065 history loss 18.565798 rank 3
2023-02-11 06:04:03,921 DEBUG CV Batch 2/300 loss 20.055359 loss_att 18.951088 loss_ctc 24.291996 loss_rnnt 13.028315 hw_loss 1.253065 history loss 18.565798 rank 0
2023-02-11 06:04:03,995 DEBUG CV Batch 2/300 loss 20.055359 loss_att 18.951088 loss_ctc 24.291996 loss_rnnt 13.028315 hw_loss 1.253065 history loss 18.565798 rank 5
2023-02-11 06:04:04,047 DEBUG CV Batch 2/300 loss 20.055359 loss_att 18.951088 loss_ctc 24.291996 loss_rnnt 13.028315 hw_loss 1.253065 history loss 18.565798 rank 7
2023-02-11 06:04:04,069 DEBUG CV Batch 2/300 loss 20.055359 loss_att 18.951088 loss_ctc 24.291996 loss_rnnt 13.028315 hw_loss 1.253065 history loss 18.565798 rank 6
2023-02-11 06:04:04,266 DEBUG CV Batch 2/300 loss 20.055359 loss_att 18.951088 loss_ctc 24.291996 loss_rnnt 13.028315 hw_loss 1.253065 history loss 18.565798 rank 1
2023-02-11 06:04:04,734 DEBUG CV Batch 2/300 loss 20.055359 loss_att 18.951088 loss_ctc 24.291996 loss_rnnt 13.028315 hw_loss 1.253065 history loss 18.565798 rank 4
2023-02-11 06:04:06,116 DEBUG CV Batch 2/300 loss 20.055359 loss_att 18.951088 loss_ctc 24.291996 loss_rnnt 13.028315 hw_loss 1.253065 history loss 18.565798 rank 2
2023-02-11 06:04:15,849 DEBUG CV Batch 2/400 loss 74.395828 loss_att 189.117249 loss_ctc 91.215149 loss_rnnt 48.124378 hw_loss 0.203361 history loss 20.206505 rank 3
2023-02-11 06:04:15,886 DEBUG CV Batch 2/400 loss 74.395828 loss_att 189.117249 loss_ctc 91.215149 loss_rnnt 48.124378 hw_loss 0.203361 history loss 20.206505 rank 0
2023-02-11 06:04:15,949 DEBUG CV Batch 2/400 loss 74.395828 loss_att 189.117249 loss_ctc 91.215149 loss_rnnt 48.124378 hw_loss 0.203361 history loss 20.206505 rank 5
2023-02-11 06:04:15,990 DEBUG CV Batch 2/400 loss 74.395828 loss_att 189.117249 loss_ctc 91.215149 loss_rnnt 48.124378 hw_loss 0.203361 history loss 20.206505 rank 7
2023-02-11 06:04:16,013 DEBUG CV Batch 2/400 loss 74.395828 loss_att 189.117249 loss_ctc 91.215149 loss_rnnt 48.124378 hw_loss 0.203361 history loss 20.206505 rank 6
2023-02-11 06:04:16,313 DEBUG CV Batch 2/400 loss 74.395828 loss_att 189.117249 loss_ctc 91.215149 loss_rnnt 48.124378 hw_loss 0.203361 history loss 20.206505 rank 1
2023-02-11 06:04:16,996 DEBUG CV Batch 2/400 loss 74.395828 loss_att 189.117249 loss_ctc 91.215149 loss_rnnt 48.124378 hw_loss 0.203361 history loss 20.206505 rank 4
2023-02-11 06:04:18,181 DEBUG CV Batch 2/400 loss 74.395828 loss_att 189.117249 loss_ctc 91.215149 loss_rnnt 48.124378 hw_loss 0.203361 history loss 20.206505 rank 2
2023-02-11 06:04:26,260 DEBUG CV Batch 2/500 loss 27.237755 loss_att 28.887333 loss_ctc 41.061390 loss_rnnt 23.796085 hw_loss 0.237863 history loss 21.747525 rank 3
2023-02-11 06:04:26,282 DEBUG CV Batch 2/500 loss 27.237755 loss_att 28.887333 loss_ctc 41.061390 loss_rnnt 23.796085 hw_loss 0.237863 history loss 21.747525 rank 0
2023-02-11 06:04:26,419 DEBUG CV Batch 2/500 loss 27.237755 loss_att 28.887333 loss_ctc 41.061390 loss_rnnt 23.796085 hw_loss 0.237863 history loss 21.747525 rank 5
2023-02-11 06:04:26,448 DEBUG CV Batch 2/500 loss 27.237755 loss_att 28.887333 loss_ctc 41.061390 loss_rnnt 23.796085 hw_loss 0.237863 history loss 21.747525 rank 7
2023-02-11 06:04:26,529 DEBUG CV Batch 2/500 loss 27.237755 loss_att 28.887333 loss_ctc 41.061390 loss_rnnt 23.796085 hw_loss 0.237863 history loss 21.747525 rank 6
2023-02-11 06:04:26,815 DEBUG CV Batch 2/500 loss 27.237755 loss_att 28.887333 loss_ctc 41.061390 loss_rnnt 23.796085 hw_loss 0.237863 history loss 21.747525 rank 1
2023-02-11 06:04:27,527 DEBUG CV Batch 2/500 loss 27.237755 loss_att 28.887333 loss_ctc 41.061390 loss_rnnt 23.796085 hw_loss 0.237863 history loss 21.747525 rank 4
2023-02-11 06:04:28,693 DEBUG CV Batch 2/500 loss 27.237755 loss_att 28.887333 loss_ctc 41.061390 loss_rnnt 23.796085 hw_loss 0.237863 history loss 21.747525 rank 2
2023-02-11 06:04:38,298 DEBUG CV Batch 2/600 loss 20.756531 loss_att 18.430845 loss_ctc 23.973177 loss_rnnt 14.814976 hw_loss 1.120839 history loss 23.393297 rank 0
2023-02-11 06:04:38,337 DEBUG CV Batch 2/600 loss 20.756531 loss_att 18.430845 loss_ctc 23.973177 loss_rnnt 14.814976 hw_loss 1.120839 history loss 23.393297 rank 3
2023-02-11 06:04:38,508 DEBUG CV Batch 2/600 loss 20.756531 loss_att 18.430845 loss_ctc 23.973177 loss_rnnt 14.814976 hw_loss 1.120839 history loss 23.393297 rank 7
2023-02-11 06:04:38,546 DEBUG CV Batch 2/600 loss 20.756531 loss_att 18.430845 loss_ctc 23.973177 loss_rnnt 14.814976 hw_loss 1.120839 history loss 23.393297 rank 5
2023-02-11 06:04:38,636 DEBUG CV Batch 2/600 loss 20.756531 loss_att 18.430845 loss_ctc 23.973177 loss_rnnt 14.814976 hw_loss 1.120839 history loss 23.393297 rank 6
2023-02-11 06:04:38,980 DEBUG CV Batch 2/600 loss 20.756531 loss_att 18.430845 loss_ctc 23.973177 loss_rnnt 14.814976 hw_loss 1.120839 history loss 23.393297 rank 1
2023-02-11 06:04:39,641 DEBUG CV Batch 2/600 loss 20.756531 loss_att 18.430845 loss_ctc 23.973177 loss_rnnt 14.814976 hw_loss 1.120839 history loss 23.393297 rank 4
2023-02-11 06:04:41,467 DEBUG CV Batch 2/600 loss 20.756531 loss_att 18.430845 loss_ctc 23.973177 loss_rnnt 14.814976 hw_loss 1.120839 history loss 23.393297 rank 2
2023-02-11 06:04:49,910 DEBUG CV Batch 2/700 loss 62.569672 loss_att 137.002899 loss_ctc 90.261887 loss_rnnt 40.768509 hw_loss 0.604166 history loss 24.669227 rank 3
2023-02-11 06:04:49,980 DEBUG CV Batch 2/700 loss 62.569672 loss_att 137.002899 loss_ctc 90.261887 loss_rnnt 40.768509 hw_loss 0.604166 history loss 24.669227 rank 7
2023-02-11 06:04:50,050 DEBUG CV Batch 2/700 loss 62.569672 loss_att 137.002899 loss_ctc 90.261887 loss_rnnt 40.768509 hw_loss 0.604166 history loss 24.669227 rank 0
2023-02-11 06:04:50,185 DEBUG CV Batch 2/700 loss 62.569672 loss_att 137.002899 loss_ctc 90.261887 loss_rnnt 40.768509 hw_loss 0.604166 history loss 24.669227 rank 5
2023-02-11 06:04:50,591 DEBUG CV Batch 2/700 loss 62.569672 loss_att 137.002899 loss_ctc 90.261887 loss_rnnt 40.768509 hw_loss 0.604166 history loss 24.669227 rank 6
2023-02-11 06:04:50,976 DEBUG CV Batch 2/700 loss 62.569672 loss_att 137.002899 loss_ctc 90.261887 loss_rnnt 40.768509 hw_loss 0.604166 history loss 24.669227 rank 1
2023-02-11 06:04:50,994 DEBUG CV Batch 2/700 loss 62.569672 loss_att 137.002899 loss_ctc 90.261887 loss_rnnt 40.768509 hw_loss 0.604166 history loss 24.669227 rank 4
2023-02-11 06:04:52,790 DEBUG CV Batch 2/700 loss 62.569672 loss_att 137.002899 loss_ctc 90.261887 loss_rnnt 40.768509 hw_loss 0.604166 history loss 24.669227 rank 2
2023-02-11 06:05:01,791 DEBUG CV Batch 2/800 loss 31.317482 loss_att 30.116474 loss_ctc 45.000622 loss_rnnt 26.267944 hw_loss 0.649747 history loss 23.683618 rank 0
2023-02-11 06:05:01,837 DEBUG CV Batch 2/800 loss 31.317482 loss_att 30.116474 loss_ctc 45.000622 loss_rnnt 26.267944 hw_loss 0.649747 history loss 23.683618 rank 3
2023-02-11 06:05:01,937 DEBUG CV Batch 2/800 loss 31.317482 loss_att 30.116474 loss_ctc 45.000622 loss_rnnt 26.267944 hw_loss 0.649747 history loss 23.683618 rank 5
2023-02-11 06:05:02,043 DEBUG CV Batch 2/800 loss 31.317482 loss_att 30.116474 loss_ctc 45.000622 loss_rnnt 26.267944 hw_loss 0.649747 history loss 23.683618 rank 7
2023-02-11 06:05:02,622 DEBUG CV Batch 2/800 loss 31.317482 loss_att 30.116474 loss_ctc 45.000622 loss_rnnt 26.267944 hw_loss 0.649747 history loss 23.683618 rank 6
2023-02-11 06:05:03,149 DEBUG CV Batch 2/800 loss 31.317482 loss_att 30.116474 loss_ctc 45.000622 loss_rnnt 26.267944 hw_loss 0.649747 history loss 23.683618 rank 1
2023-02-11 06:05:03,532 DEBUG CV Batch 2/800 loss 31.317482 loss_att 30.116474 loss_ctc 45.000622 loss_rnnt 26.267944 hw_loss 0.649747 history loss 23.683618 rank 4
2023-02-11 06:05:04,073 DEBUG CV Batch 2/800 loss 31.317482 loss_att 30.116474 loss_ctc 45.000622 loss_rnnt 26.267944 hw_loss 0.649747 history loss 23.683618 rank 2
2023-02-11 06:05:15,353 DEBUG CV Batch 2/900 loss 34.898689 loss_att 66.611732 loss_ctc 52.068756 loss_rnnt 24.354908 hw_loss 0.358468 history loss 23.323465 rank 3
2023-02-11 06:05:15,396 DEBUG CV Batch 2/900 loss 34.898689 loss_att 66.611732 loss_ctc 52.068756 loss_rnnt 24.354908 hw_loss 0.358468 history loss 23.323465 rank 5
2023-02-11 06:05:15,460 DEBUG CV Batch 2/900 loss 34.898689 loss_att 66.611732 loss_ctc 52.068756 loss_rnnt 24.354908 hw_loss 0.358468 history loss 23.323465 rank 7
2023-02-11 06:05:15,468 DEBUG CV Batch 2/900 loss 34.898689 loss_att 66.611732 loss_ctc 52.068756 loss_rnnt 24.354908 hw_loss 0.358468 history loss 23.323465 rank 0
2023-02-11 06:05:16,289 DEBUG CV Batch 2/900 loss 34.898689 loss_att 66.611732 loss_ctc 52.068756 loss_rnnt 24.354908 hw_loss 0.358468 history loss 23.323465 rank 6
2023-02-11 06:05:16,992 DEBUG CV Batch 2/900 loss 34.898689 loss_att 66.611732 loss_ctc 52.068756 loss_rnnt 24.354908 hw_loss 0.358468 history loss 23.323465 rank 4
2023-02-11 06:05:17,055 DEBUG CV Batch 2/900 loss 34.898689 loss_att 66.611732 loss_ctc 52.068756 loss_rnnt 24.354908 hw_loss 0.358468 history loss 23.323465 rank 1
2023-02-11 06:05:17,448 DEBUG CV Batch 2/900 loss 34.898689 loss_att 66.611732 loss_ctc 52.068756 loss_rnnt 24.354908 hw_loss 0.358468 history loss 23.323465 rank 2
2023-02-11 06:05:27,532 DEBUG CV Batch 2/1000 loss 16.313320 loss_att 14.293465 loss_ctc 18.471678 loss_rnnt 10.771807 hw_loss 1.060819 history loss 22.904382 rank 3
2023-02-11 06:05:27,572 DEBUG CV Batch 2/1000 loss 16.313320 loss_att 14.293465 loss_ctc 18.471678 loss_rnnt 10.771807 hw_loss 1.060819 history loss 22.904382 rank 5
2023-02-11 06:05:27,636 DEBUG CV Batch 2/1000 loss 16.313320 loss_att 14.293465 loss_ctc 18.471678 loss_rnnt 10.771807 hw_loss 1.060819 history loss 22.904382 rank 7
2023-02-11 06:05:27,648 DEBUG CV Batch 2/1000 loss 16.313320 loss_att 14.293465 loss_ctc 18.471678 loss_rnnt 10.771807 hw_loss 1.060819 history loss 22.904382 rank 0
2023-02-11 06:05:28,505 DEBUG CV Batch 2/1000 loss 16.313320 loss_att 14.293465 loss_ctc 18.471678 loss_rnnt 10.771807 hw_loss 1.060819 history loss 22.904382 rank 6
2023-02-11 06:05:29,223 DEBUG CV Batch 2/1000 loss 16.313320 loss_att 14.293465 loss_ctc 18.471678 loss_rnnt 10.771807 hw_loss 1.060819 history loss 22.904382 rank 4
2023-02-11 06:05:29,675 DEBUG CV Batch 2/1000 loss 16.313320 loss_att 14.293465 loss_ctc 18.471678 loss_rnnt 10.771807 hw_loss 1.060819 history loss 22.904382 rank 2
2023-02-11 06:05:29,761 DEBUG CV Batch 2/1000 loss 16.313320 loss_att 14.293465 loss_ctc 18.471678 loss_rnnt 10.771807 hw_loss 1.060819 history loss 22.904382 rank 1
2023-02-11 06:05:39,352 DEBUG CV Batch 2/1100 loss 15.336566 loss_att 10.028494 loss_ctc 14.853267 loss_rnnt 9.558421 hw_loss 1.294537 history loss 22.859623 rank 3
2023-02-11 06:05:39,453 DEBUG CV Batch 2/1100 loss 15.336567 loss_att 10.028494 loss_ctc 14.853267 loss_rnnt 9.558421 hw_loss 1.294537 history loss 22.859623 rank 5
2023-02-11 06:05:39,481 DEBUG CV Batch 2/1100 loss 15.336565 loss_att 10.028494 loss_ctc 14.853267 loss_rnnt 9.558421 hw_loss 1.294537 history loss 22.859623 rank 0
2023-02-11 06:05:39,487 DEBUG CV Batch 2/1100 loss 15.336565 loss_att 10.028494 loss_ctc 14.853267 loss_rnnt 9.558421 hw_loss 1.294537 history loss 22.859623 rank 7
2023-02-11 06:05:40,406 DEBUG CV Batch 2/1100 loss 15.336566 loss_att 10.028494 loss_ctc 14.853267 loss_rnnt 9.558421 hw_loss 1.294537 history loss 22.859623 rank 6
2023-02-11 06:05:41,178 DEBUG CV Batch 2/1100 loss 15.336565 loss_att 10.028494 loss_ctc 14.853267 loss_rnnt 9.558421 hw_loss 1.294537 history loss 22.859623 rank 4
2023-02-11 06:05:41,550 DEBUG CV Batch 2/1100 loss 15.336566 loss_att 10.028494 loss_ctc 14.853267 loss_rnnt 9.558421 hw_loss 1.294537 history loss 22.859623 rank 2
2023-02-11 06:05:43,011 DEBUG CV Batch 2/1100 loss 15.336565 loss_att 10.028494 loss_ctc 14.853267 loss_rnnt 9.558421 hw_loss 1.294537 history loss 22.859623 rank 1
2023-02-11 06:05:49,747 DEBUG CV Batch 2/1200 loss 40.886318 loss_att 38.710850 loss_ctc 50.646179 loss_rnnt 36.445385 hw_loss 0.670259 history loss 23.447318 rank 3
2023-02-11 06:05:49,846 DEBUG CV Batch 2/1200 loss 40.886318 loss_att 38.710850 loss_ctc 50.646179 loss_rnnt 36.445385 hw_loss 0.670259 history loss 23.447318 rank 7
2023-02-11 06:05:49,863 DEBUG CV Batch 2/1200 loss 40.886318 loss_att 38.710850 loss_ctc 50.646179 loss_rnnt 36.445385 hw_loss 0.670259 history loss 23.447318 rank 0
2023-02-11 06:05:49,897 DEBUG CV Batch 2/1200 loss 40.886318 loss_att 38.710850 loss_ctc 50.646179 loss_rnnt 36.445385 hw_loss 0.670259 history loss 23.447318 rank 5
2023-02-11 06:05:50,829 DEBUG CV Batch 2/1200 loss 40.886318 loss_att 38.710850 loss_ctc 50.646179 loss_rnnt 36.445385 hw_loss 0.670259 history loss 23.447318 rank 6
2023-02-11 06:05:51,737 DEBUG CV Batch 2/1200 loss 40.886318 loss_att 38.710850 loss_ctc 50.646179 loss_rnnt 36.445385 hw_loss 0.670259 history loss 23.447318 rank 4
2023-02-11 06:05:52,070 DEBUG CV Batch 2/1200 loss 40.886318 loss_att 38.710850 loss_ctc 50.646179 loss_rnnt 36.445385 hw_loss 0.670259 history loss 23.447318 rank 2
2023-02-11 06:05:54,052 DEBUG CV Batch 2/1200 loss 40.886318 loss_att 38.710850 loss_ctc 50.646179 loss_rnnt 36.445385 hw_loss 0.670259 history loss 23.447318 rank 1
2023-02-11 06:06:01,645 DEBUG CV Batch 2/1300 loss 20.621778 loss_att 17.658962 loss_ctc 26.320158 loss_rnnt 15.276338 hw_loss 0.970916 history loss 23.954728 rank 3
2023-02-11 06:06:01,706 DEBUG CV Batch 2/1300 loss 20.621778 loss_att 17.658962 loss_ctc 26.320158 loss_rnnt 15.276338 hw_loss 0.970916 history loss 23.954728 rank 7
2023-02-11 06:06:01,709 DEBUG CV Batch 2/1300 loss 20.621778 loss_att 17.658962 loss_ctc 26.320158 loss_rnnt 15.276338 hw_loss 0.970916 history loss 23.954728 rank 0
2023-02-11 06:06:01,777 DEBUG CV Batch 2/1300 loss 20.621778 loss_att 17.658962 loss_ctc 26.320158 loss_rnnt 15.276338 hw_loss 0.970916 history loss 23.954728 rank 5
2023-02-11 06:06:02,849 DEBUG CV Batch 2/1300 loss 20.621778 loss_att 17.658962 loss_ctc 26.320158 loss_rnnt 15.276338 hw_loss 0.970916 history loss 23.954728 rank 6
2023-02-11 06:06:03,729 DEBUG CV Batch 2/1300 loss 20.621778 loss_att 17.658962 loss_ctc 26.320158 loss_rnnt 15.276338 hw_loss 0.970916 history loss 23.954728 rank 4
2023-02-11 06:06:03,999 DEBUG CV Batch 2/1300 loss 20.621778 loss_att 17.658962 loss_ctc 26.320158 loss_rnnt 15.276338 hw_loss 0.970916 history loss 23.954728 rank 2
2023-02-11 06:06:05,921 DEBUG CV Batch 2/1300 loss 20.621778 loss_att 17.658962 loss_ctc 26.320158 loss_rnnt 15.276338 hw_loss 0.970916 history loss 23.954728 rank 1
2023-02-11 06:06:12,761 DEBUG CV Batch 2/1400 loss 46.821983 loss_att 103.707077 loss_ctc 52.349464 loss_rnnt 33.960659 hw_loss 0.140120 history loss 24.568831 rank 0
2023-02-11 06:06:12,780 DEBUG CV Batch 2/1400 loss 46.821983 loss_att 103.707077 loss_ctc 52.349464 loss_rnnt 33.960659 hw_loss 0.140120 history loss 24.568831 rank 7
2023-02-11 06:06:12,890 DEBUG CV Batch 2/1400 loss 46.821983 loss_att 103.707077 loss_ctc 52.349464 loss_rnnt 33.960659 hw_loss 0.140120 history loss 24.568831 rank 3
2023-02-11 06:06:12,961 DEBUG CV Batch 2/1400 loss 46.821983 loss_att 103.707077 loss_ctc 52.349464 loss_rnnt 33.960659 hw_loss 0.140120 history loss 24.568831 rank 5
2023-02-11 06:06:14,670 DEBUG CV Batch 2/1400 loss 46.821983 loss_att 103.707077 loss_ctc 52.349464 loss_rnnt 33.960659 hw_loss 0.140120 history loss 24.568831 rank 6
2023-02-11 06:06:14,920 DEBUG CV Batch 2/1400 loss 46.821983 loss_att 103.707077 loss_ctc 52.349464 loss_rnnt 33.960659 hw_loss 0.140120 history loss 24.568831 rank 4
2023-02-11 06:06:15,168 DEBUG CV Batch 2/1400 loss 46.821983 loss_att 103.707077 loss_ctc 52.349464 loss_rnnt 33.960659 hw_loss 0.140120 history loss 24.568831 rank 2
2023-02-11 06:06:17,597 DEBUG CV Batch 2/1400 loss 46.821983 loss_att 103.707077 loss_ctc 52.349464 loss_rnnt 33.960659 hw_loss 0.140120 history loss 24.568831 rank 1
2023-02-11 06:06:24,089 DEBUG CV Batch 2/1500 loss 26.775532 loss_att 26.993118 loss_ctc 34.866203 loss_rnnt 21.123577 hw_loss 0.849315 history loss 24.177652 rank 7
2023-02-11 06:06:24,117 DEBUG CV Batch 2/1500 loss 26.775532 loss_att 26.993118 loss_ctc 34.866203 loss_rnnt 21.123577 hw_loss 0.849315 history loss 24.177652 rank 0
2023-02-11 06:06:24,277 DEBUG CV Batch 2/1500 loss 26.775532 loss_att 26.993118 loss_ctc 34.866203 loss_rnnt 21.123577 hw_loss 0.849315 history loss 24.177652 rank 5
2023-02-11 06:06:24,303 DEBUG CV Batch 2/1500 loss 26.775532 loss_att 26.993118 loss_ctc 34.866203 loss_rnnt 21.123577 hw_loss 0.849315 history loss 24.177652 rank 3
2023-02-11 06:06:27,314 DEBUG CV Batch 2/1500 loss 26.775532 loss_att 26.993118 loss_ctc 34.866203 loss_rnnt 21.123577 hw_loss 0.849315 history loss 24.177652 rank 2
2023-02-11 06:06:27,485 DEBUG CV Batch 2/1500 loss 26.775532 loss_att 26.993118 loss_ctc 34.866203 loss_rnnt 21.123577 hw_loss 0.849315 history loss 24.177652 rank 4
2023-02-11 06:06:27,576 DEBUG CV Batch 2/1500 loss 26.775532 loss_att 26.993118 loss_ctc 34.866203 loss_rnnt 21.123577 hw_loss 0.849315 history loss 24.177652 rank 6
2023-02-11 06:06:28,853 DEBUG CV Batch 2/1500 loss 26.775532 loss_att 26.993118 loss_ctc 34.866203 loss_rnnt 21.123577 hw_loss 0.849315 history loss 24.177652 rank 1
2023-02-11 06:06:37,290 DEBUG CV Batch 2/1600 loss 35.111973 loss_att 66.633095 loss_ctc 51.374805 loss_rnnt 24.980877 hw_loss 0.310967 history loss 23.992133 rank 0
2023-02-11 06:06:37,314 DEBUG CV Batch 2/1600 loss 35.111973 loss_att 66.633095 loss_ctc 51.374805 loss_rnnt 24.980877 hw_loss 0.310967 history loss 23.992133 rank 7
2023-02-11 06:06:37,637 DEBUG CV Batch 2/1600 loss 35.111973 loss_att 66.633095 loss_ctc 51.374805 loss_rnnt 24.980877 hw_loss 0.310967 history loss 23.992133 rank 5
2023-02-11 06:06:38,011 DEBUG CV Batch 2/1600 loss 35.111973 loss_att 66.633095 loss_ctc 51.374805 loss_rnnt 24.980877 hw_loss 0.310967 history loss 23.992133 rank 3
2023-02-11 06:06:40,562 DEBUG CV Batch 2/1600 loss 35.111973 loss_att 66.633095 loss_ctc 51.374805 loss_rnnt 24.980877 hw_loss 0.310967 history loss 23.992133 rank 2
2023-02-11 06:06:40,850 DEBUG CV Batch 2/1600 loss 35.111973 loss_att 66.633095 loss_ctc 51.374805 loss_rnnt 24.980877 hw_loss 0.310967 history loss 23.992133 rank 4
2023-02-11 06:06:41,175 DEBUG CV Batch 2/1600 loss 35.111973 loss_att 66.633095 loss_ctc 51.374805 loss_rnnt 24.980877 hw_loss 0.310967 history loss 23.992133 rank 6
2023-02-11 06:06:41,825 DEBUG CV Batch 2/1600 loss 35.111973 loss_att 66.633095 loss_ctc 51.374805 loss_rnnt 24.980877 hw_loss 0.310967 history loss 23.992133 rank 1
2023-02-11 06:06:49,785 DEBUG CV Batch 2/1700 loss 28.377298 loss_att 26.150238 loss_ctc 40.108894 loss_rnnt 22.906727 hw_loss 0.815957 history loss 23.755947 rank 0
2023-02-11 06:06:49,833 DEBUG CV Batch 2/1700 loss 28.377298 loss_att 26.150238 loss_ctc 40.108894 loss_rnnt 22.906727 hw_loss 0.815957 history loss 23.755947 rank 7
2023-02-11 06:06:50,177 DEBUG CV Batch 2/1700 loss 28.377298 loss_att 26.150238 loss_ctc 40.108894 loss_rnnt 22.906727 hw_loss 0.815957 history loss 23.755947 rank 5
2023-02-11 06:06:50,482 DEBUG CV Batch 2/1700 loss 28.377298 loss_att 26.150238 loss_ctc 40.108894 loss_rnnt 22.906727 hw_loss 0.815957 history loss 23.755947 rank 3
2023-02-11 06:06:53,046 DEBUG CV Batch 2/1700 loss 28.377298 loss_att 26.150238 loss_ctc 40.108894 loss_rnnt 22.906727 hw_loss 0.815957 history loss 23.755947 rank 2
2023-02-11 06:06:53,380 DEBUG CV Batch 2/1700 loss 28.377298 loss_att 26.150238 loss_ctc 40.108894 loss_rnnt 22.906727 hw_loss 0.815957 history loss 23.755947 rank 4
2023-02-11 06:06:53,708 DEBUG CV Batch 2/1700 loss 28.377298 loss_att 26.150238 loss_ctc 40.108894 loss_rnnt 22.906727 hw_loss 0.815957 history loss 23.755947 rank 6
2023-02-11 06:06:54,310 DEBUG CV Batch 2/1700 loss 28.377298 loss_att 26.150238 loss_ctc 40.108894 loss_rnnt 22.906727 hw_loss 0.815957 history loss 23.755947 rank 1
2023-02-11 06:06:58,849 INFO Epoch 2 CV info cv_loss 23.66759017596167
2023-02-11 06:06:58,850 INFO Checkpoint: save to checkpoint exp2_10_rnnt_bias_loss/2.pt
2023-02-11 06:06:59,008 INFO Epoch 2 CV info cv_loss 23.66759015204745
2023-02-11 06:06:59,009 INFO Epoch 3 TRAIN info lr 0.00099936
2023-02-11 06:06:59,012 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 06:06:59,329 INFO Epoch 2 CV info cv_loss 23.667590164383604
2023-02-11 06:06:59,330 INFO Epoch 3 TRAIN info lr 0.0009991810072235551
2023-02-11 06:06:59,333 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 06:06:59,454 INFO Epoch 3 TRAIN info lr 0.0009990214382510482
2023-02-11 06:06:59,458 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 06:06:59,622 INFO Epoch 2 CV info cv_loss 23.667590132199333
2023-02-11 06:06:59,623 INFO Epoch 3 TRAIN info lr 0.0009999600023998401
2023-02-11 06:06:59,628 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 06:07:02,204 INFO Epoch 2 CV info cv_loss 23.667590157974317
2023-02-11 06:07:02,205 INFO Epoch 3 TRAIN info lr 0.0009991810072235551
2023-02-11 06:07:02,209 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 06:07:02,537 INFO Epoch 2 CV info cv_loss 23.66759017410091
2023-02-11 06:07:02,539 INFO Epoch 3 TRAIN info lr 0.0009994399999999999
2023-02-11 06:07:02,541 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 06:07:02,774 INFO Epoch 2 CV info cv_loss 23.667590158939156
2023-02-11 06:07:02,775 INFO Epoch 3 TRAIN info lr 0.00099992000959872
2023-02-11 06:07:02,779 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 06:07:03,354 INFO Epoch 2 CV info cv_loss 23.667590154735215
2023-02-11 06:07:03,356 INFO Epoch 3 TRAIN info lr 0.000998941682427973
2023-02-11 06:07:03,361 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 06:08:16,477 DEBUG TRAIN Batch 3/0 loss 20.231119 loss_att 18.459553 loss_ctc 22.668421 loss_rnnt 16.875469 hw_loss 0.634685 lr 0.00099994 rank 3
2023-02-11 06:08:16,478 DEBUG TRAIN Batch 3/0 loss 22.583628 loss_att 19.029512 loss_ctc 23.370968 loss_rnnt 16.917381 hw_loss 1.176017 lr 0.00099900 rank 0
2023-02-11 06:08:16,479 DEBUG TRAIN Batch 3/0 loss 18.518656 loss_att 15.351415 loss_ctc 18.774948 loss_rnnt 12.353712 hw_loss 1.268291 lr 0.00099940 rank 7
2023-02-11 06:08:16,488 DEBUG TRAIN Batch 3/0 loss 22.075901 loss_att 20.228178 loss_ctc 25.128212 loss_rnnt 16.086926 hw_loss 1.115915 lr 0.00099916 rank 5
2023-02-11 06:08:16,492 DEBUG TRAIN Batch 3/0 loss 28.362469 loss_att 24.654400 loss_ctc 30.815588 loss_rnnt 22.349195 hw_loss 1.205214 lr 0.00099990 rank 6
2023-02-11 06:08:16,501 DEBUG TRAIN Batch 3/0 loss 21.556789 loss_att 17.811058 loss_ctc 20.276463 loss_rnnt 16.161776 hw_loss 1.184038 lr 0.00099916 rank 2
2023-02-11 06:08:16,523 DEBUG TRAIN Batch 3/0 loss 17.655355 loss_att 14.445401 loss_ctc 18.233021 loss_rnnt 12.347555 hw_loss 1.101144 lr 0.00099892 rank 1
2023-02-11 06:08:16,560 DEBUG TRAIN Batch 3/0 loss 22.518293 loss_att 17.559761 loss_ctc 21.996271 loss_rnnt 16.503605 hw_loss 1.326750 lr 0.00099948 rank 4
2023-02-11 06:09:32,388 DEBUG TRAIN Batch 3/100 loss 17.283192 loss_att 22.152676 loss_ctc 28.102186 loss_rnnt 12.058261 hw_loss 0.526594 lr 0.00099693 rank 1
2023-02-11 06:09:32,389 DEBUG TRAIN Batch 3/100 loss 27.021709 loss_att 35.242138 loss_ctc 39.455177 loss_rnnt 21.142719 hw_loss 0.483208 lr 0.00099830 rank 7
2023-02-11 06:09:32,390 DEBUG TRAIN Batch 3/100 loss 38.840317 loss_att 48.035343 loss_ctc 52.422775 loss_rnnt 32.913193 hw_loss 0.426961 lr 0.00099795 rank 3
2023-02-11 06:09:32,392 DEBUG TRAIN Batch 3/100 loss 56.220455 loss_att 56.096306 loss_ctc 89.780235 loss_rnnt 48.486492 hw_loss 0.615779 lr 0.00099701 rank 0
2023-02-11 06:09:32,393 DEBUG TRAIN Batch 3/100 loss 51.463440 loss_att 68.339996 loss_ctc 71.305565 loss_rnnt 43.290932 hw_loss 0.403420 lr 0.00099791 rank 6
2023-02-11 06:09:32,394 DEBUG TRAIN Batch 3/100 loss 13.983969 loss_att 21.601295 loss_ctc 20.911160 loss_rnnt 9.330988 hw_loss 0.413604 lr 0.00099717 rank 5
2023-02-11 06:09:32,398 DEBUG TRAIN Batch 3/100 loss 39.058487 loss_att 51.511246 loss_ctc 55.340660 loss_rnnt 33.153175 hw_loss 0.233212 lr 0.00099826 rank 4
2023-02-11 06:09:32,398 DEBUG TRAIN Batch 3/100 loss 46.123951 loss_att 58.981976 loss_ctc 58.130661 loss_rnnt 40.865707 hw_loss 0.203577 lr 0.00099717 rank 2
2023-02-11 06:10:47,847 DEBUG TRAIN Batch 3/200 loss 35.657738 loss_att 48.901119 loss_ctc 54.307068 loss_rnnt 29.952986 hw_loss 0.106781 lr 0.00099632 rank 7
2023-02-11 06:10:47,849 DEBUG TRAIN Batch 3/200 loss 29.257122 loss_att 40.368217 loss_ctc 46.156967 loss_rnnt 23.031696 hw_loss 0.328105 lr 0.00099596 rank 3
2023-02-11 06:10:47,852 DEBUG TRAIN Batch 3/200 loss 35.247051 loss_att 42.059044 loss_ctc 43.220684 loss_rnnt 30.408598 hw_loss 0.452419 lr 0.00099496 rank 1
2023-02-11 06:10:47,854 DEBUG TRAIN Batch 3/200 loss 49.781773 loss_att 62.618401 loss_ctc 74.046806 loss_rnnt 41.971001 hw_loss 0.376520 lr 0.00099504 rank 0
2023-02-11 06:10:47,857 DEBUG TRAIN Batch 3/200 loss 29.831072 loss_att 38.682610 loss_ctc 45.966675 loss_rnnt 23.413231 hw_loss 0.468022 lr 0.00099519 rank 2
2023-02-11 06:10:47,858 DEBUG TRAIN Batch 3/200 loss 26.299387 loss_att 40.762810 loss_ctc 38.784466 loss_rnnt 19.422684 hw_loss 0.434876 lr 0.00099628 rank 4
2023-02-11 06:10:47,861 DEBUG TRAIN Batch 3/200 loss 54.142765 loss_att 70.030586 loss_ctc 73.171799 loss_rnnt 46.221581 hw_loss 0.413703 lr 0.00099519 rank 5
2023-02-11 06:10:47,899 DEBUG TRAIN Batch 3/200 loss 32.777729 loss_att 42.957645 loss_ctc 51.776028 loss_rnnt 25.541019 hw_loss 0.500178 lr 0.00099593 rank 6
2023-02-11 06:12:04,081 DEBUG TRAIN Batch 3/300 loss 45.129158 loss_att 55.716499 loss_ctc 59.051544 loss_rnnt 37.082565 hw_loss 0.763651 lr 0.00099435 rank 7
2023-02-11 06:12:04,081 DEBUG TRAIN Batch 3/300 loss 38.496227 loss_att 49.182919 loss_ctc 56.449341 loss_rnnt 32.208637 hw_loss 0.329344 lr 0.00099307 rank 0
2023-02-11 06:12:04,083 DEBUG TRAIN Batch 3/300 loss 40.673130 loss_att 45.407001 loss_ctc 55.381248 loss_rnnt 35.682632 hw_loss 0.390496 lr 0.00099323 rank 2
2023-02-11 06:12:04,087 DEBUG TRAIN Batch 3/300 loss 45.491310 loss_att 53.455849 loss_ctc 68.591805 loss_rnnt 37.561459 hw_loss 0.610664 lr 0.00099399 rank 3
2023-02-11 06:12:04,086 DEBUG TRAIN Batch 3/300 loss 35.055798 loss_att 44.030174 loss_ctc 47.167488 loss_rnnt 28.481880 hw_loss 0.593278 lr 0.00099323 rank 5
2023-02-11 06:12:04,088 DEBUG TRAIN Batch 3/300 loss 46.308159 loss_att 50.909634 loss_ctc 54.830437 loss_rnnt 40.810181 hw_loss 0.645259 lr 0.00099431 rank 4
2023-02-11 06:12:04,089 DEBUG TRAIN Batch 3/300 loss 45.914219 loss_att 53.896797 loss_ctc 62.997444 loss_rnnt 40.155861 hw_loss 0.353265 lr 0.00099396 rank 6
2023-02-11 06:12:04,091 DEBUG TRAIN Batch 3/300 loss 38.055489 loss_att 45.171379 loss_ctc 53.134621 loss_rnnt 31.558777 hw_loss 0.574309 lr 0.00099299 rank 1
2023-02-11 06:13:21,566 DEBUG TRAIN Batch 3/400 loss 32.864124 loss_att 40.416687 loss_ctc 39.946663 loss_rnnt 27.918339 hw_loss 0.467050 lr 0.00099104 rank 1
2023-02-11 06:13:21,566 DEBUG TRAIN Batch 3/400 loss 49.953453 loss_att 61.702240 loss_ctc 71.674133 loss_rnnt 39.999397 hw_loss 0.882789 lr 0.00099128 rank 5
2023-02-11 06:13:21,567 DEBUG TRAIN Batch 3/400 loss 50.867905 loss_att 56.243828 loss_ctc 65.256332 loss_rnnt 44.841621 hw_loss 0.568619 lr 0.00099204 rank 3
2023-02-11 06:13:21,569 DEBUG TRAIN Batch 3/400 loss 22.730488 loss_att 27.993567 loss_ctc 31.965561 loss_rnnt 17.637518 hw_loss 0.526690 lr 0.00099239 rank 7
2023-02-11 06:13:21,571 DEBUG TRAIN Batch 3/400 loss 25.541138 loss_att 32.334602 loss_ctc 38.065918 loss_rnnt 20.157879 hw_loss 0.441486 lr 0.00099200 rank 6
2023-02-11 06:13:21,571 DEBUG TRAIN Batch 3/400 loss 66.655678 loss_att 74.477150 loss_ctc 81.980156 loss_rnnt 61.233780 hw_loss 0.340189 lr 0.00099128 rank 2
2023-02-11 06:13:21,574 DEBUG TRAIN Batch 3/400 loss 26.543440 loss_att 39.489861 loss_ctc 42.311237 loss_rnnt 20.034044 hw_loss 0.340826 lr 0.00099235 rank 4
2023-02-11 06:13:21,574 DEBUG TRAIN Batch 3/400 loss 49.902428 loss_att 54.905052 loss_ctc 72.604828 loss_rnnt 43.293770 hw_loss 0.483964 lr 0.00099112 rank 0
2023-02-11 06:14:37,813 DEBUG TRAIN Batch 3/500 loss 44.044075 loss_att 52.462292 loss_ctc 59.124111 loss_rnnt 36.301056 hw_loss 0.759132 lr 0.00099005 rank 6
2023-02-11 06:14:37,813 DEBUG TRAIN Batch 3/500 loss 35.535416 loss_att 40.721588 loss_ctc 51.133011 loss_rnnt 30.698738 hw_loss 0.322456 lr 0.00099009 rank 3
2023-02-11 06:14:37,815 DEBUG TRAIN Batch 3/500 loss 37.758476 loss_att 44.469391 loss_ctc 53.480545 loss_rnnt 32.634735 hw_loss 0.315991 lr 0.00099044 rank 7
2023-02-11 06:14:37,817 DEBUG TRAIN Batch 3/500 loss 45.182442 loss_att 48.220699 loss_ctc 69.105095 loss_rnnt 37.284931 hw_loss 0.768781 lr 0.00099040 rank 4
2023-02-11 06:14:37,816 DEBUG TRAIN Batch 3/500 loss 28.644865 loss_att 33.687195 loss_ctc 42.932541 loss_rnnt 24.323555 hw_loss 0.263966 lr 0.00098933 rank 5
2023-02-11 06:14:37,816 DEBUG TRAIN Batch 3/500 loss 27.302343 loss_att 34.525116 loss_ctc 47.009796 loss_rnnt 21.200226 hw_loss 0.380607 lr 0.00098918 rank 0
2023-02-11 06:14:37,817 DEBUG TRAIN Batch 3/500 loss 37.863235 loss_att 43.235344 loss_ctc 55.639633 loss_rnnt 30.591906 hw_loss 0.717510 lr 0.00098933 rank 2
2023-02-11 06:14:37,862 DEBUG TRAIN Batch 3/500 loss 45.740459 loss_att 50.109741 loss_ctc 64.924713 loss_rnnt 37.269341 hw_loss 0.944880 lr 0.00098910 rank 1
2023-02-11 06:15:55,615 DEBUG TRAIN Batch 3/600 loss 29.095322 loss_att 32.042534 loss_ctc 33.281963 loss_rnnt 23.314072 hw_loss 0.868798 lr 0.00098815 rank 3
2023-02-11 06:15:55,619 DEBUG TRAIN Batch 3/600 loss 74.254166 loss_att 83.096664 loss_ctc 107.312744 loss_rnnt 66.950455 hw_loss 0.211387 lr 0.00098740 rank 2
2023-02-11 06:15:55,620 DEBUG TRAIN Batch 3/600 loss 39.991756 loss_att 43.892574 loss_ctc 52.819572 loss_rnnt 33.816620 hw_loss 0.690862 lr 0.00098850 rank 7
2023-02-11 06:15:55,622 DEBUG TRAIN Batch 3/600 loss 22.972631 loss_att 26.832211 loss_ctc 32.600113 loss_rnnt 18.952536 hw_loss 0.368347 lr 0.00098740 rank 5
2023-02-11 06:15:55,625 DEBUG TRAIN Batch 3/600 loss 18.917141 loss_att 15.829342 loss_ctc 20.675995 loss_rnnt 11.874846 hw_loss 1.392252 lr 0.00098725 rank 0
2023-02-11 06:15:55,651 DEBUG TRAIN Batch 3/600 loss 21.546511 loss_att 16.840473 loss_ctc 19.591427 loss_rnnt 16.193106 hw_loss 1.229117 lr 0.00098846 rank 4
2023-02-11 06:15:55,663 DEBUG TRAIN Batch 3/600 loss 37.923290 loss_att 38.144745 loss_ctc 46.293892 loss_rnnt 30.737213 hw_loss 1.129820 lr 0.00098717 rank 1
2023-02-11 06:15:55,669 DEBUG TRAIN Batch 3/600 loss 41.855415 loss_att 41.320969 loss_ctc 51.503395 loss_rnnt 35.631172 hw_loss 0.945887 lr 0.00098812 rank 6
2023-02-11 06:17:14,686 DEBUG TRAIN Batch 3/700 loss 24.507313 loss_att 31.190491 loss_ctc 34.575455 loss_rnnt 19.664604 hw_loss 0.405685 lr 0.00098623 rank 3
2023-02-11 06:17:14,687 DEBUG TRAIN Batch 3/700 loss 47.257896 loss_att 54.678829 loss_ctc 70.490372 loss_rnnt 39.004959 hw_loss 0.688329 lr 0.00098533 rank 0
2023-02-11 06:17:14,690 DEBUG TRAIN Batch 3/700 loss 34.574562 loss_att 44.097603 loss_ctc 56.618389 loss_rnnt 27.380066 hw_loss 0.440759 lr 0.00098525 rank 1
2023-02-11 06:17:14,694 DEBUG TRAIN Batch 3/700 loss 20.066107 loss_att 29.056641 loss_ctc 32.185505 loss_rnnt 14.225685 hw_loss 0.454949 lr 0.00098654 rank 4
2023-02-11 06:17:14,695 DEBUG TRAIN Batch 3/700 loss 40.778507 loss_att 42.102589 loss_ctc 62.624397 loss_rnnt 32.903328 hw_loss 0.880795 lr 0.00098548 rank 5
2023-02-11 06:17:14,699 DEBUG TRAIN Batch 3/700 loss 22.196949 loss_att 31.028267 loss_ctc 32.826958 loss_rnnt 15.417675 hw_loss 0.674189 lr 0.00098658 rank 7
2023-02-11 06:17:14,700 DEBUG TRAIN Batch 3/700 loss 31.151237 loss_att 32.742149 loss_ctc 47.583797 loss_rnnt 27.134762 hw_loss 0.282616 lr 0.00098548 rank 2
2023-02-11 06:17:14,702 DEBUG TRAIN Batch 3/700 loss 57.200146 loss_att 65.583649 loss_ctc 88.787834 loss_rnnt 48.116863 hw_loss 0.599042 lr 0.00098619 rank 6
2023-02-11 06:18:30,562 DEBUG TRAIN Batch 3/800 loss 48.979362 loss_att 60.653946 loss_ctc 76.017624 loss_rnnt 40.886597 hw_loss 0.403640 lr 0.00098357 rank 5
2023-02-11 06:18:30,562 DEBUG TRAIN Batch 3/800 loss 45.447021 loss_att 53.500591 loss_ctc 56.132599 loss_rnnt 39.627308 hw_loss 0.522048 lr 0.00098432 rank 3
2023-02-11 06:18:30,565 DEBUG TRAIN Batch 3/800 loss 37.533989 loss_att 47.082237 loss_ctc 52.607582 loss_rnnt 31.312820 hw_loss 0.431570 lr 0.00098342 rank 0
2023-02-11 06:18:30,565 DEBUG TRAIN Batch 3/800 loss 24.142899 loss_att 31.017035 loss_ctc 44.036110 loss_rnnt 18.181667 hw_loss 0.362621 lr 0.00098357 rank 2
2023-02-11 06:18:30,566 DEBUG TRAIN Batch 3/800 loss 48.173138 loss_att 56.337868 loss_ctc 64.667381 loss_rnnt 40.751556 hw_loss 0.673013 lr 0.00098335 rank 1
2023-02-11 06:18:30,568 DEBUG TRAIN Batch 3/800 loss 18.338461 loss_att 31.795485 loss_ctc 26.012253 loss_rnnt 13.609510 hw_loss 0.190195 lr 0.00098462 rank 4
2023-02-11 06:18:30,568 DEBUG TRAIN Batch 3/800 loss 22.093643 loss_att 35.511658 loss_ctc 33.787762 loss_rnnt 14.009173 hw_loss 0.720309 lr 0.00098466 rank 7
2023-02-11 06:18:30,612 DEBUG TRAIN Batch 3/800 loss 27.612671 loss_att 36.186089 loss_ctc 41.450706 loss_rnnt 22.203787 hw_loss 0.346712 lr 0.00098428 rank 6
2023-02-11 06:19:46,496 DEBUG TRAIN Batch 3/900 loss 34.020718 loss_att 43.153336 loss_ctc 50.935570 loss_rnnt 26.545048 hw_loss 0.636343 lr 0.00098152 rank 0
2023-02-11 06:19:46,499 DEBUG TRAIN Batch 3/900 loss 29.692059 loss_att 38.197201 loss_ctc 41.241131 loss_rnnt 24.713362 hw_loss 0.325836 lr 0.00098241 rank 3
2023-02-11 06:19:46,500 DEBUG TRAIN Batch 3/900 loss 26.568470 loss_att 32.091553 loss_ctc 33.759102 loss_rnnt 19.302288 hw_loss 0.975528 lr 0.00098168 rank 5
2023-02-11 06:19:46,500 DEBUG TRAIN Batch 3/900 loss 26.007788 loss_att 32.455650 loss_ctc 40.302204 loss_rnnt 20.155212 hw_loss 0.498203 lr 0.00098276 rank 7
2023-02-11 06:19:46,503 DEBUG TRAIN Batch 3/900 loss 27.579693 loss_att 32.685722 loss_ctc 36.329895 loss_rnnt 22.417654 hw_loss 0.557651 lr 0.00098238 rank 6
2023-02-11 06:19:46,503 DEBUG TRAIN Batch 3/900 loss 48.991383 loss_att 63.377785 loss_ctc 80.784515 loss_rnnt 37.320705 hw_loss 0.853934 lr 0.00098272 rank 4
2023-02-11 06:19:46,504 DEBUG TRAIN Batch 3/900 loss 33.165520 loss_att 35.616161 loss_ctc 48.151527 loss_rnnt 28.858589 hw_loss 0.341000 lr 0.00098145 rank 1
2023-02-11 06:19:46,504 DEBUG TRAIN Batch 3/900 loss 30.462307 loss_att 38.869835 loss_ctc 37.102203 loss_rnnt 23.007526 hw_loss 0.916492 lr 0.00098168 rank 2
2023-02-11 06:21:03,373 DEBUG TRAIN Batch 3/1000 loss 36.788593 loss_att 52.094414 loss_ctc 54.179367 loss_rnnt 29.039137 hw_loss 0.444286 lr 0.00098086 rank 7
2023-02-11 06:21:03,374 DEBUG TRAIN Batch 3/1000 loss 48.746346 loss_att 60.414143 loss_ctc 78.740143 loss_rnnt 39.237602 hw_loss 0.595502 lr 0.00098083 rank 4
2023-02-11 06:21:03,376 DEBUG TRAIN Batch 3/1000 loss 39.976524 loss_att 44.528740 loss_ctc 58.491604 loss_rnnt 33.546635 hw_loss 0.572018 lr 0.00098052 rank 3
2023-02-11 06:21:03,377 DEBUG TRAIN Batch 3/1000 loss 35.992062 loss_att 39.297749 loss_ctc 41.273521 loss_rnnt 30.599125 hw_loss 0.755176 lr 0.00097956 rank 1
2023-02-11 06:21:03,377 DEBUG TRAIN Batch 3/1000 loss 27.462193 loss_att 31.759567 loss_ctc 40.673981 loss_rnnt 22.315254 hw_loss 0.473605 lr 0.00097964 rank 0
2023-02-11 06:21:03,378 DEBUG TRAIN Batch 3/1000 loss 24.019344 loss_att 31.708952 loss_ctc 39.938381 loss_rnnt 18.261803 hw_loss 0.393203 lr 0.00097979 rank 2
2023-02-11 06:21:03,379 DEBUG TRAIN Batch 3/1000 loss 41.666775 loss_att 50.630630 loss_ctc 64.122421 loss_rnnt 34.119228 hw_loss 0.517629 lr 0.00097979 rank 5
2023-02-11 06:21:03,396 DEBUG TRAIN Batch 3/1000 loss 49.667137 loss_att 60.517532 loss_ctc 68.456398 loss_rnnt 42.914780 hw_loss 0.389446 lr 0.00098049 rank 6
2023-02-11 06:22:21,823 DEBUG TRAIN Batch 3/1100 loss 35.618473 loss_att 40.826347 loss_ctc 49.155151 loss_rnnt 29.057129 hw_loss 0.696540 lr 0.00097776 rank 0
2023-02-11 06:22:21,827 DEBUG TRAIN Batch 3/1100 loss 24.890635 loss_att 32.997570 loss_ctc 38.792297 loss_rnnt 19.774590 hw_loss 0.307706 lr 0.00097864 rank 3
2023-02-11 06:22:21,827 DEBUG TRAIN Batch 3/1100 loss 17.731142 loss_att 25.332016 loss_ctc 21.760174 loss_rnnt 12.697630 hw_loss 0.558025 lr 0.00097769 rank 1
2023-02-11 06:22:21,828 DEBUG TRAIN Batch 3/1100 loss 50.746510 loss_att 60.342773 loss_ctc 76.491425 loss_rnnt 42.006393 hw_loss 0.635289 lr 0.00097861 rank 6
2023-02-11 06:22:21,830 DEBUG TRAIN Batch 3/1100 loss 36.643566 loss_att 41.627247 loss_ctc 52.526073 loss_rnnt 29.868156 hw_loss 0.686439 lr 0.00097898 rank 7
2023-02-11 06:22:21,831 DEBUG TRAIN Batch 3/1100 loss 34.941296 loss_att 46.462902 loss_ctc 50.947430 loss_rnnt 27.133085 hw_loss 0.631825 lr 0.00097791 rank 5
2023-02-11 06:22:21,834 DEBUG TRAIN Batch 3/1100 loss 31.848120 loss_att 35.938126 loss_ctc 42.362434 loss_rnnt 26.354237 hw_loss 0.613869 lr 0.00097791 rank 2
2023-02-11 06:22:21,838 DEBUG TRAIN Batch 3/1100 loss 30.382931 loss_att 35.665539 loss_ctc 43.907185 loss_rnnt 24.936373 hw_loss 0.485026 lr 0.00097894 rank 4
2023-02-11 06:23:38,403 DEBUG TRAIN Batch 3/1200 loss 44.721676 loss_att 48.985077 loss_ctc 60.254322 loss_rnnt 40.133595 hw_loss 0.312071 lr 0.00097711 rank 7
2023-02-11 06:23:38,406 DEBUG TRAIN Batch 3/1200 loss 38.699883 loss_att 39.447464 loss_ctc 49.422588 loss_rnnt 34.533463 hw_loss 0.485102 lr 0.00097674 rank 6
2023-02-11 06:23:38,407 DEBUG TRAIN Batch 3/1200 loss 54.793259 loss_att 60.656944 loss_ctc 82.764381 loss_rnnt 48.982231 hw_loss 0.170402 lr 0.00097583 rank 1
2023-02-11 06:23:38,409 DEBUG TRAIN Batch 3/1200 loss 19.301836 loss_att 23.410278 loss_ctc 29.820164 loss_rnnt 14.365985 hw_loss 0.508447 lr 0.00097677 rank 3
2023-02-11 06:23:38,410 DEBUG TRAIN Batch 3/1200 loss 43.936714 loss_att 43.370876 loss_ctc 50.326912 loss_rnnt 37.970074 hw_loss 0.980209 lr 0.00097707 rank 4
2023-02-11 06:23:38,414 DEBUG TRAIN Batch 3/1200 loss 40.417751 loss_att 41.551430 loss_ctc 53.227730 loss_rnnt 34.705555 hw_loss 0.708274 lr 0.00097590 rank 0
2023-02-11 06:23:38,416 DEBUG TRAIN Batch 3/1200 loss 32.094414 loss_att 27.843027 loss_ctc 42.829483 loss_rnnt 26.315491 hw_loss 0.974599 lr 0.00097605 rank 2
2023-02-11 06:23:38,420 DEBUG TRAIN Batch 3/1200 loss 27.022263 loss_att 27.312614 loss_ctc 32.108612 loss_rnnt 20.239897 hw_loss 1.133647 lr 0.00097605 rank 5
2023-02-11 06:24:53,948 DEBUG TRAIN Batch 3/1300 loss 35.938351 loss_att 42.333740 loss_ctc 59.925606 loss_rnnt 28.129684 hw_loss 0.624616 lr 0.00097397 rank 1
2023-02-11 06:24:53,952 DEBUG TRAIN Batch 3/1300 loss 26.995409 loss_att 31.709126 loss_ctc 30.471710 loss_rnnt 23.727596 hw_loss 0.349043 lr 0.00097419 rank 2
2023-02-11 06:24:53,953 DEBUG TRAIN Batch 3/1300 loss 27.876511 loss_att 33.335838 loss_ctc 45.627838 loss_rnnt 23.557487 hw_loss 0.161309 lr 0.00097492 rank 3
2023-02-11 06:24:53,954 DEBUG TRAIN Batch 3/1300 loss 38.602993 loss_att 45.687103 loss_ctc 50.136368 loss_rnnt 32.346100 hw_loss 0.619179 lr 0.00097405 rank 0
2023-02-11 06:24:53,955 DEBUG TRAIN Batch 3/1300 loss 25.351120 loss_att 24.435909 loss_ctc 27.165375 loss_rnnt 19.256659 hw_loss 1.131675 lr 0.00097525 rank 7
2023-02-11 06:24:53,959 DEBUG TRAIN Batch 3/1300 loss 51.701675 loss_att 60.019157 loss_ctc 66.951752 loss_rnnt 44.834347 hw_loss 0.594468 lr 0.00097419 rank 5
2023-02-11 06:24:53,960 DEBUG TRAIN Batch 3/1300 loss 31.512222 loss_att 42.747814 loss_ctc 55.779350 loss_rnnt 24.318260 hw_loss 0.320855 lr 0.00097521 rank 4
2023-02-11 06:24:53,995 DEBUG TRAIN Batch 3/1300 loss 38.881920 loss_att 41.960537 loss_ctc 50.417603 loss_rnnt 34.990906 hw_loss 0.325726 lr 0.00097488 rank 6
2023-02-11 06:26:11,486 DEBUG TRAIN Batch 3/1400 loss 36.945129 loss_att 51.111477 loss_ctc 49.449505 loss_rnnt 29.001842 hw_loss 0.645519 lr 0.00097336 rank 4
2023-02-11 06:26:11,486 DEBUG TRAIN Batch 3/1400 loss 26.697716 loss_att 40.521870 loss_ctc 38.250439 loss_rnnt 20.945755 hw_loss 0.271268 lr 0.00097340 rank 7
2023-02-11 06:26:11,487 DEBUG TRAIN Batch 3/1400 loss 38.466091 loss_att 43.614494 loss_ctc 54.475258 loss_rnnt 31.538671 hw_loss 0.705597 lr 0.00097220 rank 0
2023-02-11 06:26:11,487 DEBUG TRAIN Batch 3/1400 loss 38.893993 loss_att 46.259289 loss_ctc 55.600174 loss_rnnt 32.881378 hw_loss 0.433513 lr 0.00097307 rank 3
2023-02-11 06:26:11,490 DEBUG TRAIN Batch 3/1400 loss 35.108112 loss_att 45.877430 loss_ctc 47.895599 loss_rnnt 28.284195 hw_loss 0.555947 lr 0.00097235 rank 2
2023-02-11 06:26:11,492 DEBUG TRAIN Batch 3/1400 loss 21.615545 loss_att 30.068794 loss_ctc 29.525747 loss_rnnt 17.678860 hw_loss 0.223377 lr 0.00097235 rank 5
2023-02-11 06:26:11,492 DEBUG TRAIN Batch 3/1400 loss 51.134636 loss_att 64.670692 loss_ctc 73.258293 loss_rnnt 44.102276 hw_loss 0.257875 lr 0.00097303 rank 6
2023-02-11 06:26:11,535 DEBUG TRAIN Batch 3/1400 loss 23.821993 loss_att 31.251389 loss_ctc 32.573845 loss_rnnt 19.205046 hw_loss 0.368279 lr 0.00097213 rank 1
2023-02-11 06:27:27,981 DEBUG TRAIN Batch 3/1500 loss 54.777706 loss_att 71.006187 loss_ctc 89.066635 loss_rnnt 45.246746 hw_loss 0.321265 lr 0.00097156 rank 7
2023-02-11 06:27:27,986 DEBUG TRAIN Batch 3/1500 loss 23.892900 loss_att 33.016937 loss_ctc 36.655792 loss_rnnt 18.863991 hw_loss 0.281697 lr 0.00097123 rank 3
2023-02-11 06:27:27,988 DEBUG TRAIN Batch 3/1500 loss 35.334057 loss_att 42.304138 loss_ctc 42.582016 loss_rnnt 29.583469 hw_loss 0.635657 lr 0.00097119 rank 6
2023-02-11 06:27:27,989 DEBUG TRAIN Batch 3/1500 loss 21.713966 loss_att 31.308235 loss_ctc 34.975327 loss_rnnt 15.342434 hw_loss 0.503343 lr 0.00097052 rank 2
2023-02-11 06:27:27,990 DEBUG TRAIN Batch 3/1500 loss 24.535547 loss_att 31.420900 loss_ctc 37.947449 loss_rnnt 18.430363 hw_loss 0.551224 lr 0.00097030 rank 1
2023-02-11 06:27:27,991 DEBUG TRAIN Batch 3/1500 loss 20.817213 loss_att 27.301931 loss_ctc 32.571201 loss_rnnt 13.642912 hw_loss 0.808155 lr 0.00097052 rank 5
2023-02-11 06:27:27,993 DEBUG TRAIN Batch 3/1500 loss 22.283121 loss_att 28.188931 loss_ctc 38.110970 loss_rnnt 16.973701 hw_loss 0.378352 lr 0.00097037 rank 0
2023-02-11 06:27:27,995 DEBUG TRAIN Batch 3/1500 loss 39.504581 loss_att 49.680260 loss_ctc 50.339458 loss_rnnt 31.898354 hw_loss 0.773708 lr 0.00097152 rank 4
2023-02-11 06:28:42,952 DEBUG TRAIN Batch 3/1600 loss 40.116539 loss_att 46.261108 loss_ctc 59.891766 loss_rnnt 34.172974 hw_loss 0.389616 lr 0.00096869 rank 5
2023-02-11 06:28:42,952 DEBUG TRAIN Batch 3/1600 loss 42.352234 loss_att 49.958000 loss_ctc 55.898880 loss_rnnt 37.060860 hw_loss 0.368250 lr 0.00096940 rank 3
2023-02-11 06:28:42,953 DEBUG TRAIN Batch 3/1600 loss 38.376507 loss_att 40.885956 loss_ctc 51.852722 loss_rnnt 33.627899 hw_loss 0.459354 lr 0.00096855 rank 0
2023-02-11 06:28:42,953 DEBUG TRAIN Batch 3/1600 loss 24.591259 loss_att 26.948952 loss_ctc 36.041458 loss_rnnt 19.232655 hw_loss 0.630070 lr 0.00096973 rank 7
2023-02-11 06:28:42,957 DEBUG TRAIN Batch 3/1600 loss 36.514614 loss_att 42.453892 loss_ctc 50.823212 loss_rnnt 31.399395 hw_loss 0.378666 lr 0.00096869 rank 2
2023-02-11 06:28:42,958 DEBUG TRAIN Batch 3/1600 loss 29.319078 loss_att 36.812210 loss_ctc 43.498325 loss_rnnt 24.338686 hw_loss 0.298350 lr 0.00096937 rank 6
2023-02-11 06:28:43,003 DEBUG TRAIN Batch 3/1600 loss 63.015514 loss_att 69.480431 loss_ctc 80.278435 loss_rnnt 55.890335 hw_loss 0.661964 lr 0.00096848 rank 1
2023-02-11 06:28:43,028 DEBUG TRAIN Batch 3/1600 loss 39.807426 loss_att 44.245483 loss_ctc 57.845779 loss_rnnt 35.015785 hw_loss 0.281047 lr 0.00096970 rank 4
2023-02-11 06:29:59,059 DEBUG TRAIN Batch 3/1700 loss 36.992146 loss_att 46.142406 loss_ctc 50.622509 loss_rnnt 31.955023 hw_loss 0.260567 lr 0.00096674 rank 0
2023-02-11 06:29:59,063 DEBUG TRAIN Batch 3/1700 loss 45.756302 loss_att 50.462616 loss_ctc 70.169075 loss_rnnt 38.101776 hw_loss 0.648417 lr 0.00096755 rank 6
2023-02-11 06:29:59,062 DEBUG TRAIN Batch 3/1700 loss 31.800823 loss_att 44.854874 loss_ctc 46.298649 loss_rnnt 25.094936 hw_loss 0.405381 lr 0.00096788 rank 4
2023-02-11 06:29:59,065 DEBUG TRAIN Batch 3/1700 loss 41.398502 loss_att 47.123726 loss_ctc 61.858585 loss_rnnt 35.516434 hw_loss 0.376690 lr 0.00096688 rank 5
2023-02-11 06:29:59,065 DEBUG TRAIN Batch 3/1700 loss 49.946198 loss_att 55.864937 loss_ctc 64.098801 loss_rnnt 42.382442 hw_loss 0.842436 lr 0.00096759 rank 3
2023-02-11 06:29:59,066 DEBUG TRAIN Batch 3/1700 loss 36.154671 loss_att 43.279781 loss_ctc 49.694931 loss_rnnt 29.808191 hw_loss 0.584267 lr 0.00096688 rank 2
2023-02-11 06:29:59,066 DEBUG TRAIN Batch 3/1700 loss 32.098206 loss_att 34.424355 loss_ctc 45.958229 loss_rnnt 28.021877 hw_loss 0.330581 lr 0.00096666 rank 1
2023-02-11 06:29:59,068 DEBUG TRAIN Batch 3/1700 loss 47.290901 loss_att 51.202831 loss_ctc 60.580147 loss_rnnt 40.385727 hw_loss 0.815792 lr 0.00096791 rank 7
2023-02-11 06:31:17,505 DEBUG TRAIN Batch 3/1800 loss 36.994576 loss_att 43.504421 loss_ctc 50.258739 loss_rnnt 32.398235 hw_loss 0.286091 lr 0.00096574 rank 6
2023-02-11 06:31:17,505 DEBUG TRAIN Batch 3/1800 loss 51.852425 loss_att 55.595894 loss_ctc 68.718185 loss_rnnt 46.415848 hw_loss 0.457335 lr 0.00096610 rank 7
2023-02-11 06:31:17,506 DEBUG TRAIN Batch 3/1800 loss 32.248882 loss_att 36.871620 loss_ctc 46.378635 loss_rnnt 28.231873 hw_loss 0.226593 lr 0.00096578 rank 3
2023-02-11 06:31:17,508 DEBUG TRAIN Batch 3/1800 loss 26.829168 loss_att 30.255329 loss_ctc 39.401520 loss_rnnt 20.464298 hw_loss 0.750623 lr 0.00096493 rank 0
2023-02-11 06:31:17,509 DEBUG TRAIN Batch 3/1800 loss 24.502729 loss_att 28.422092 loss_ctc 31.744329 loss_rnnt 20.512943 hw_loss 0.420068 lr 0.00096508 rank 5
2023-02-11 06:31:17,515 DEBUG TRAIN Batch 3/1800 loss 31.076229 loss_att 28.521982 loss_ctc 37.310574 loss_rnnt 25.535938 hw_loss 0.978730 lr 0.00096508 rank 2
2023-02-11 06:31:17,515 DEBUG TRAIN Batch 3/1800 loss 27.256643 loss_att 30.657627 loss_ctc 39.960369 loss_rnnt 21.353559 hw_loss 0.661698 lr 0.00096607 rank 4
2023-02-11 06:31:17,515 DEBUG TRAIN Batch 3/1800 loss 26.463188 loss_att 32.975712 loss_ctc 35.035275 loss_rnnt 20.925856 hw_loss 0.579728 lr 0.00096486 rank 1
2023-02-11 06:32:34,093 DEBUG TRAIN Batch 3/1900 loss 65.850998 loss_att 87.313400 loss_ctc 91.522644 loss_rnnt 55.687981 hw_loss 0.458935 lr 0.00096314 rank 0
2023-02-11 06:32:34,095 DEBUG TRAIN Batch 3/1900 loss 21.883640 loss_att 22.298601 loss_ctc 27.641804 loss_rnnt 16.735638 hw_loss 0.805735 lr 0.00096398 rank 3
2023-02-11 06:32:34,096 DEBUG TRAIN Batch 3/1900 loss 50.604599 loss_att 76.536415 loss_ctc 70.314682 loss_rnnt 40.028393 hw_loss 0.517844 lr 0.00096307 rank 1
2023-02-11 06:32:34,097 DEBUG TRAIN Batch 3/1900 loss 32.778629 loss_att 33.932701 loss_ctc 44.354946 loss_rnnt 29.256577 hw_loss 0.327699 lr 0.00096395 rank 6
2023-02-11 06:32:34,099 DEBUG TRAIN Batch 3/1900 loss 24.318720 loss_att 27.744183 loss_ctc 34.268780 loss_rnnt 18.744207 hw_loss 0.668015 lr 0.00096427 rank 4
2023-02-11 06:32:34,101 DEBUG TRAIN Batch 3/1900 loss 25.374607 loss_att 19.262730 loss_ctc 25.445656 loss_rnnt 18.737232 hw_loss 1.471927 lr 0.00096329 rank 5
2023-02-11 06:32:34,103 DEBUG TRAIN Batch 3/1900 loss 28.789177 loss_att 31.397499 loss_ctc 38.762959 loss_rnnt 25.720520 hw_loss 0.228217 lr 0.00096431 rank 7
2023-02-11 06:32:34,104 DEBUG TRAIN Batch 3/1900 loss 34.972790 loss_att 36.185371 loss_ctc 42.535835 loss_rnnt 30.309082 hw_loss 0.639897 lr 0.00096329 rank 2
2023-02-11 06:33:50,346 DEBUG TRAIN Batch 3/2000 loss 33.389328 loss_att 42.980377 loss_ctc 47.475533 loss_rnnt 27.374123 hw_loss 0.416032 lr 0.00096216 rank 6
2023-02-11 06:33:50,348 DEBUG TRAIN Batch 3/2000 loss 35.892586 loss_att 45.205345 loss_ctc 50.474274 loss_rnnt 30.677895 hw_loss 0.263983 lr 0.00096248 rank 4
2023-02-11 06:33:50,350 DEBUG TRAIN Batch 3/2000 loss 19.483728 loss_att 24.842886 loss_ctc 34.406971 loss_rnnt 16.207272 hw_loss 0.040286 lr 0.00096136 rank 0
2023-02-11 06:33:50,350 DEBUG TRAIN Batch 3/2000 loss 27.133430 loss_att 34.051380 loss_ctc 35.258831 loss_rnnt 22.951551 hw_loss 0.321545 lr 0.00096220 rank 3
2023-02-11 06:33:50,350 DEBUG TRAIN Batch 3/2000 loss 52.853992 loss_att 59.442097 loss_ctc 67.540466 loss_rnnt 46.231041 hw_loss 0.627587 lr 0.00096129 rank 1
2023-02-11 06:33:50,352 DEBUG TRAIN Batch 3/2000 loss 36.026455 loss_att 42.024677 loss_ctc 58.023022 loss_rnnt 28.192715 hw_loss 0.693978 lr 0.00096252 rank 7
2023-02-11 06:33:50,352 DEBUG TRAIN Batch 3/2000 loss 46.490261 loss_att 56.068531 loss_ctc 75.284325 loss_rnnt 39.438759 hw_loss 0.243120 lr 0.00096150 rank 2
2023-02-11 06:33:50,354 DEBUG TRAIN Batch 3/2000 loss 46.373119 loss_att 52.105213 loss_ctc 71.189255 loss_rnnt 39.671047 hw_loss 0.421282 lr 0.00096150 rank 5
2023-02-11 06:35:08,516 DEBUG TRAIN Batch 3/2100 loss 44.198345 loss_att 48.006977 loss_ctc 60.569275 loss_rnnt 39.618557 hw_loss 0.306614 lr 0.00095959 rank 0
2023-02-11 06:35:08,517 DEBUG TRAIN Batch 3/2100 loss 31.187796 loss_att 40.699661 loss_ctc 49.308727 loss_rnnt 24.584021 hw_loss 0.428489 lr 0.00096070 rank 4
2023-02-11 06:35:08,519 DEBUG TRAIN Batch 3/2100 loss 60.168060 loss_att 71.483612 loss_ctc 76.371552 loss_rnnt 52.367157 hw_loss 0.633249 lr 0.00096038 rank 6
2023-02-11 06:35:08,518 DEBUG TRAIN Batch 3/2100 loss 34.763092 loss_att 44.400593 loss_ctc 58.836143 loss_rnnt 28.607967 hw_loss 0.190854 lr 0.00096042 rank 3
2023-02-11 06:35:08,520 DEBUG TRAIN Batch 3/2100 loss 46.553905 loss_att 48.921539 loss_ctc 63.193371 loss_rnnt 42.402599 hw_loss 0.273598 lr 0.00096074 rank 7
2023-02-11 06:35:08,522 DEBUG TRAIN Batch 3/2100 loss 18.491333 loss_att 23.957697 loss_ctc 26.018188 loss_rnnt 13.887576 hw_loss 0.470044 lr 0.00095973 rank 2
2023-02-11 06:35:08,524 DEBUG TRAIN Batch 3/2100 loss 36.169678 loss_att 48.015862 loss_ctc 62.064087 loss_rnnt 26.898291 hw_loss 0.646792 lr 0.00095973 rank 5
2023-02-11 06:35:08,526 DEBUG TRAIN Batch 3/2100 loss 43.654533 loss_att 51.544056 loss_ctc 67.140549 loss_rnnt 36.548058 hw_loss 0.449456 lr 0.00095952 rank 1
2023-02-11 06:36:25,203 DEBUG TRAIN Batch 3/2200 loss 43.020081 loss_att 51.786194 loss_ctc 60.716167 loss_rnnt 35.101440 hw_loss 0.713614 lr 0.00095797 rank 2
2023-02-11 06:36:25,203 DEBUG TRAIN Batch 3/2200 loss 28.855299 loss_att 40.847393 loss_ctc 54.308071 loss_rnnt 20.750576 hw_loss 0.433612 lr 0.00095865 rank 3
2023-02-11 06:36:25,203 DEBUG TRAIN Batch 3/2200 loss 22.164648 loss_att 34.050240 loss_ctc 35.275604 loss_rnnt 16.144318 hw_loss 0.355328 lr 0.00095783 rank 0
2023-02-11 06:36:25,204 DEBUG TRAIN Batch 3/2200 loss 52.433670 loss_att 59.578056 loss_ctc 79.151962 loss_rnnt 45.298889 hw_loss 0.401899 lr 0.00095897 rank 7
2023-02-11 06:36:25,206 DEBUG TRAIN Batch 3/2200 loss 24.225931 loss_att 34.872406 loss_ctc 40.178989 loss_rnnt 18.038263 hw_loss 0.362118 lr 0.00095797 rank 5
2023-02-11 06:36:25,208 DEBUG TRAIN Batch 3/2200 loss 32.813316 loss_att 35.334358 loss_ctc 43.508224 loss_rnnt 27.203924 hw_loss 0.689849 lr 0.00095894 rank 4
2023-02-11 06:36:25,207 DEBUG TRAIN Batch 3/2200 loss 31.995935 loss_att 38.708328 loss_ctc 43.474190 loss_rnnt 27.038162 hw_loss 0.390911 lr 0.00095776 rank 1
2023-02-11 06:36:25,213 DEBUG TRAIN Batch 3/2200 loss 31.895535 loss_att 37.137230 loss_ctc 44.917152 loss_rnnt 27.732647 hw_loss 0.258438 lr 0.00095862 rank 6
2023-02-11 06:37:40,054 DEBUG TRAIN Batch 3/2300 loss 26.453829 loss_att 31.737694 loss_ctc 41.772472 loss_rnnt 19.252705 hw_loss 0.769100 lr 0.00095600 rank 1
2023-02-11 06:37:40,055 DEBUG TRAIN Batch 3/2300 loss 48.491829 loss_att 63.835152 loss_ctc 69.619560 loss_rnnt 40.017525 hw_loss 0.485365 lr 0.00095721 rank 7
2023-02-11 06:37:40,056 DEBUG TRAIN Batch 3/2300 loss 41.094490 loss_att 44.245014 loss_ctc 55.230560 loss_rnnt 36.522793 hw_loss 0.385647 lr 0.00095690 rank 3
2023-02-11 06:37:40,057 DEBUG TRAIN Batch 3/2300 loss 39.558170 loss_att 50.612343 loss_ctc 57.078259 loss_rnnt 33.389290 hw_loss 0.304132 lr 0.00095607 rank 0
2023-02-11 06:37:40,060 DEBUG TRAIN Batch 3/2300 loss 36.083755 loss_att 46.655197 loss_ctc 56.791557 loss_rnnt 29.719477 hw_loss 0.279178 lr 0.00095686 rank 6
2023-02-11 06:37:40,062 DEBUG TRAIN Batch 3/2300 loss 52.478271 loss_att 61.248352 loss_ctc 67.896576 loss_rnnt 45.998360 hw_loss 0.500648 lr 0.00095621 rank 5
2023-02-11 06:37:40,062 DEBUG TRAIN Batch 3/2300 loss 24.810259 loss_att 28.901005 loss_ctc 38.923969 loss_rnnt 18.406082 hw_loss 0.694538 lr 0.00095621 rank 2
2023-02-11 06:37:40,108 DEBUG TRAIN Batch 3/2300 loss 36.274696 loss_att 43.834709 loss_ctc 49.044319 loss_rnnt 29.692244 hw_loss 0.631469 lr 0.00095718 rank 4
2023-02-11 06:38:57,252 DEBUG TRAIN Batch 3/2400 loss 48.969772 loss_att 61.419170 loss_ctc 70.240402 loss_rnnt 41.440041 hw_loss 0.413206 lr 0.00095546 rank 7
2023-02-11 06:38:57,254 DEBUG TRAIN Batch 3/2400 loss 32.214184 loss_att 41.745152 loss_ctc 48.124039 loss_rnnt 25.907537 hw_loss 0.427339 lr 0.00095515 rank 3
2023-02-11 06:38:57,254 DEBUG TRAIN Batch 3/2400 loss 23.121788 loss_att 27.178749 loss_ctc 30.001793 loss_rnnt 18.513552 hw_loss 0.539908 lr 0.00095433 rank 0
2023-02-11 06:38:57,256 DEBUG TRAIN Batch 3/2400 loss 24.972654 loss_att 26.890850 loss_ctc 31.657776 loss_rnnt 19.934303 hw_loss 0.705631 lr 0.00095447 rank 2
2023-02-11 06:38:57,256 DEBUG TRAIN Batch 3/2400 loss 36.390797 loss_att 43.753944 loss_ctc 49.797760 loss_rnnt 29.955442 hw_loss 0.595337 lr 0.00095511 rank 6
2023-02-11 06:38:57,256 DEBUG TRAIN Batch 3/2400 loss 34.123070 loss_att 40.153179 loss_ctc 47.205124 loss_rnnt 30.566914 hw_loss 0.113599 lr 0.00095426 rank 1
2023-02-11 06:38:57,261 DEBUG TRAIN Batch 3/2400 loss 23.702028 loss_att 33.294300 loss_ctc 36.555321 loss_rnnt 16.948559 hw_loss 0.585233 lr 0.00095447 rank 5
2023-02-11 06:38:57,261 DEBUG TRAIN Batch 3/2400 loss 27.294817 loss_att 29.624306 loss_ctc 41.848770 loss_rnnt 21.587034 hw_loss 0.619005 lr 0.00095543 rank 4
2023-02-11 06:40:16,296 DEBUG TRAIN Batch 3/2500 loss 36.978642 loss_att 38.015553 loss_ctc 46.342957 loss_rnnt 32.437843 hw_loss 0.578408 lr 0.00095369 rank 4
2023-02-11 06:40:16,298 DEBUG TRAIN Batch 3/2500 loss 33.453465 loss_att 36.315334 loss_ctc 46.524719 loss_rnnt 26.016529 hw_loss 0.960323 lr 0.00095341 rank 3
2023-02-11 06:40:16,300 DEBUG TRAIN Batch 3/2500 loss 27.044411 loss_att 27.424744 loss_ctc 36.422504 loss_rnnt 20.559309 hw_loss 0.967242 lr 0.00095274 rank 5
2023-02-11 06:40:16,300 DEBUG TRAIN Batch 3/2500 loss 20.412628 loss_att 18.660816 loss_ctc 27.900776 loss_rnnt 14.427173 hw_loss 1.000763 lr 0.00095253 rank 1
2023-02-11 06:40:16,300 DEBUG TRAIN Batch 3/2500 loss 30.978003 loss_att 33.240562 loss_ctc 41.732922 loss_rnnt 25.807135 hw_loss 0.615819 lr 0.00095260 rank 0
2023-02-11 06:40:16,301 DEBUG TRAIN Batch 3/2500 loss 47.291943 loss_att 51.662064 loss_ctc 70.445435 loss_rnnt 38.606850 hw_loss 0.885738 lr 0.00095372 rank 7
2023-02-11 06:40:16,302 DEBUG TRAIN Batch 3/2500 loss 24.942095 loss_att 24.474403 loss_ctc 33.708485 loss_rnnt 17.481281 hw_loss 1.197281 lr 0.00095338 rank 6
2023-02-11 06:40:16,315 DEBUG TRAIN Batch 3/2500 loss 38.399475 loss_att 43.423225 loss_ctc 61.632904 loss_rnnt 30.935715 hw_loss 0.630229 lr 0.00095274 rank 2
2023-02-11 06:41:31,022 DEBUG TRAIN Batch 3/2600 loss 34.466743 loss_att 43.668751 loss_ctc 45.094025 loss_rnnt 29.489780 hw_loss 0.322423 lr 0.00095168 rank 3
2023-02-11 06:41:31,023 DEBUG TRAIN Batch 3/2600 loss 25.441328 loss_att 29.233137 loss_ctc 37.671547 loss_rnnt 22.135975 hw_loss 0.171805 lr 0.00095080 rank 1
2023-02-11 06:41:31,026 DEBUG TRAIN Batch 3/2600 loss 24.251158 loss_att 31.437519 loss_ctc 42.916756 loss_rnnt 18.324324 hw_loss 0.375153 lr 0.00095101 rank 2
2023-02-11 06:41:31,027 DEBUG TRAIN Batch 3/2600 loss 36.289040 loss_att 40.155682 loss_ctc 46.584423 loss_rnnt 32.071396 hw_loss 0.388424 lr 0.00095101 rank 5
2023-02-11 06:41:31,030 DEBUG TRAIN Batch 3/2600 loss 38.329853 loss_att 44.834717 loss_ctc 63.649258 loss_rnnt 31.752594 hw_loss 0.356319 lr 0.00095087 rank 0
2023-02-11 06:41:31,032 DEBUG TRAIN Batch 3/2600 loss 27.752764 loss_att 25.153637 loss_ctc 30.375061 loss_rnnt 20.659159 hw_loss 1.361961 lr 0.00095196 rank 4
2023-02-11 06:41:31,033 DEBUG TRAIN Batch 3/2600 loss 51.880711 loss_att 58.683640 loss_ctc 72.882477 loss_rnnt 43.053631 hw_loss 0.874924 lr 0.00095165 rank 6
2023-02-11 06:41:31,033 DEBUG TRAIN Batch 3/2600 loss 26.643446 loss_att 30.311581 loss_ctc 33.565098 loss_rnnt 22.248425 hw_loss 0.513470 lr 0.00095199 rank 7
2023-02-11 06:42:46,074 DEBUG TRAIN Batch 3/2700 loss 24.379816 loss_att 27.251680 loss_ctc 34.239563 loss_rnnt 20.061382 hw_loss 0.455517 lr 0.00094996 rank 3
2023-02-11 06:42:46,075 DEBUG TRAIN Batch 3/2700 loss 43.954884 loss_att 57.451935 loss_ctc 69.411301 loss_rnnt 35.048996 hw_loss 0.527304 lr 0.00094916 rank 0
2023-02-11 06:42:46,077 DEBUG TRAIN Batch 3/2700 loss 41.051418 loss_att 53.391365 loss_ctc 65.321045 loss_rnnt 30.601767 hw_loss 0.889821 lr 0.00094909 rank 1
2023-02-11 06:42:46,078 DEBUG TRAIN Batch 3/2700 loss 53.989182 loss_att 57.674290 loss_ctc 74.335793 loss_rnnt 49.963074 hw_loss 0.108038 lr 0.00095027 rank 7
2023-02-11 06:42:46,079 DEBUG TRAIN Batch 3/2700 loss 17.846771 loss_att 23.160549 loss_ctc 28.216019 loss_rnnt 13.642164 hw_loss 0.329866 lr 0.00094929 rank 5
2023-02-11 06:42:46,081 DEBUG TRAIN Batch 3/2700 loss 33.777889 loss_att 38.799656 loss_ctc 57.383148 loss_rnnt 26.254272 hw_loss 0.632230 lr 0.00094993 rank 6
2023-02-11 06:42:46,081 DEBUG TRAIN Batch 3/2700 loss 30.630590 loss_att 46.341949 loss_ctc 52.952667 loss_rnnt 23.836020 hw_loss 0.126754 lr 0.00094929 rank 2
2023-02-11 06:42:46,123 DEBUG TRAIN Batch 3/2700 loss 18.200106 loss_att 26.046173 loss_ctc 17.132162 loss_rnnt 12.097198 hw_loss 0.876766 lr 0.00095024 rank 4
2023-02-11 06:44:03,841 DEBUG TRAIN Batch 3/2800 loss 16.679373 loss_att 21.708450 loss_ctc 30.445658 loss_rnnt 11.597933 hw_loss 0.420022 lr 0.00094745 rank 0
2023-02-11 06:44:03,842 DEBUG TRAIN Batch 3/2800 loss 30.107487 loss_att 36.606815 loss_ctc 39.555161 loss_rnnt 23.613106 hw_loss 0.737780 lr 0.00094822 rank 6
2023-02-11 06:44:03,846 DEBUG TRAIN Batch 3/2800 loss 32.717491 loss_att 38.539558 loss_ctc 47.315109 loss_rnnt 26.920992 hw_loss 0.503575 lr 0.00094759 rank 2
2023-02-11 06:44:03,847 DEBUG TRAIN Batch 3/2800 loss 19.201443 loss_att 25.003941 loss_ctc 30.998337 loss_rnnt 14.798812 hw_loss 0.312977 lr 0.00094853 rank 4
2023-02-11 06:44:03,849 DEBUG TRAIN Batch 3/2800 loss 25.311333 loss_att 29.524338 loss_ctc 31.155060 loss_rnnt 20.470215 hw_loss 0.603629 lr 0.00094825 rank 3
2023-02-11 06:44:03,849 DEBUG TRAIN Batch 3/2800 loss 27.554729 loss_att 32.916199 loss_ctc 45.108944 loss_rnnt 21.532797 hw_loss 0.489202 lr 0.00094856 rank 7
2023-02-11 06:44:03,854 DEBUG TRAIN Batch 3/2800 loss 17.659836 loss_att 25.682251 loss_ctc 23.586086 loss_rnnt 13.248055 hw_loss 0.378212 lr 0.00094738 rank 1
2023-02-11 06:44:03,856 DEBUG TRAIN Batch 3/2800 loss 37.893723 loss_att 47.417519 loss_ctc 63.252090 loss_rnnt 30.224915 hw_loss 0.446801 lr 0.00094759 rank 5
2023-02-11 06:45:22,214 DEBUG TRAIN Batch 3/2900 loss 35.222103 loss_att 37.728298 loss_ctc 48.371628 loss_rnnt 30.752817 hw_loss 0.415271 lr 0.00094576 rank 0
2023-02-11 06:45:22,218 DEBUG TRAIN Batch 3/2900 loss 27.593758 loss_att 31.375065 loss_ctc 44.360382 loss_rnnt 22.735994 hw_loss 0.349866 lr 0.00094682 rank 4
2023-02-11 06:45:22,218 DEBUG TRAIN Batch 3/2900 loss 33.670795 loss_att 39.376572 loss_ctc 49.895004 loss_rnnt 28.881664 hw_loss 0.278391 lr 0.00094686 rank 7
2023-02-11 06:45:22,219 DEBUG TRAIN Batch 3/2900 loss 38.789871 loss_att 46.432369 loss_ctc 49.189602 loss_rnnt 33.024540 hw_loss 0.534412 lr 0.00094589 rank 5
2023-02-11 06:45:22,220 DEBUG TRAIN Batch 3/2900 loss 41.524441 loss_att 52.102089 loss_ctc 57.017960 loss_rnnt 36.218506 hw_loss 0.210862 lr 0.00094589 rank 2
2023-02-11 06:45:22,222 DEBUG TRAIN Batch 3/2900 loss 38.158463 loss_att 45.170734 loss_ctc 60.555534 loss_rnnt 32.376381 hw_loss 0.261254 lr 0.00094652 rank 6
2023-02-11 06:45:22,224 DEBUG TRAIN Batch 3/2900 loss 22.155087 loss_att 27.473522 loss_ctc 34.554871 loss_rnnt 18.130333 hw_loss 0.245206 lr 0.00094569 rank 1
2023-02-11 06:45:22,224 DEBUG TRAIN Batch 3/2900 loss 36.218536 loss_att 44.684689 loss_ctc 57.166771 loss_rnnt 29.124603 hw_loss 0.488925 lr 0.00094655 rank 3
2023-02-11 06:46:37,499 DEBUG TRAIN Batch 3/3000 loss 42.139446 loss_att 46.350220 loss_ctc 61.427452 loss_rnnt 37.421562 hw_loss 0.244499 lr 0.00094486 rank 3
2023-02-11 06:46:37,499 DEBUG TRAIN Batch 3/3000 loss 39.567860 loss_att 48.347084 loss_ctc 56.732700 loss_rnnt 31.465895 hw_loss 0.760777 lr 0.00094516 rank 7
2023-02-11 06:46:37,499 DEBUG TRAIN Batch 3/3000 loss 44.746105 loss_att 56.863960 loss_ctc 63.498497 loss_rnnt 37.836990 hw_loss 0.372229 lr 0.00094483 rank 6
2023-02-11 06:46:37,499 DEBUG TRAIN Batch 3/3000 loss 27.123104 loss_att 29.550076 loss_ctc 41.710629 loss_rnnt 21.680254 hw_loss 0.564834 lr 0.00094407 rank 0
2023-02-11 06:46:37,500 DEBUG TRAIN Batch 3/3000 loss 38.558056 loss_att 42.706604 loss_ctc 55.593910 loss_rnnt 32.661663 hw_loss 0.524107 lr 0.00094420 rank 2
2023-02-11 06:46:37,501 DEBUG TRAIN Batch 3/3000 loss 21.743477 loss_att 25.655056 loss_ctc 24.759260 loss_rnnt 17.949747 hw_loss 0.489245 lr 0.00094400 rank 1
2023-02-11 06:46:37,501 DEBUG TRAIN Batch 3/3000 loss 29.954777 loss_att 39.411194 loss_ctc 52.023388 loss_rnnt 21.811241 hw_loss 0.620582 lr 0.00094420 rank 5
2023-02-11 06:46:37,502 DEBUG TRAIN Batch 3/3000 loss 40.603413 loss_att 51.234310 loss_ctc 56.691990 loss_rnnt 33.896755 hw_loss 0.456625 lr 0.00094513 rank 4
2023-02-11 06:47:52,652 DEBUG TRAIN Batch 3/3100 loss 27.941214 loss_att 35.689873 loss_ctc 51.362083 loss_rnnt 21.234888 hw_loss 0.381340 lr 0.00094348 rank 7
2023-02-11 06:47:52,652 DEBUG TRAIN Batch 3/3100 loss 38.274799 loss_att 36.813885 loss_ctc 48.173973 loss_rnnt 33.818260 hw_loss 0.642907 lr 0.00094239 rank 0
2023-02-11 06:47:52,653 DEBUG TRAIN Batch 3/3100 loss 37.557137 loss_att 43.195126 loss_ctc 47.829613 loss_rnnt 31.999802 hw_loss 0.573764 lr 0.00094252 rank 5
2023-02-11 06:47:52,654 DEBUG TRAIN Batch 3/3100 loss 39.446533 loss_att 39.774384 loss_ctc 49.024658 loss_rnnt 33.562439 hw_loss 0.851521 lr 0.00094232 rank 1
2023-02-11 06:47:52,655 DEBUG TRAIN Batch 3/3100 loss 43.650780 loss_att 50.931984 loss_ctc 68.049629 loss_rnnt 35.661102 hw_loss 0.615048 lr 0.00094345 rank 4
2023-02-11 06:47:52,655 DEBUG TRAIN Batch 3/3100 loss 23.259970 loss_att 28.001068 loss_ctc 35.006531 loss_rnnt 18.311371 hw_loss 0.456407 lr 0.00094314 rank 6
2023-02-11 06:47:52,656 DEBUG TRAIN Batch 3/3100 loss 21.208637 loss_att 17.102728 loss_ctc 24.801027 loss_rnnt 15.689673 hw_loss 1.098968 lr 0.00094252 rank 2
2023-02-11 06:47:52,657 DEBUG TRAIN Batch 3/3100 loss 27.542673 loss_att 30.996981 loss_ctc 36.140503 loss_rnnt 21.221462 hw_loss 0.840745 lr 0.00094318 rank 3
2023-02-11 06:49:12,050 DEBUG TRAIN Batch 3/3200 loss 14.350843 loss_att 21.565380 loss_ctc 23.580254 loss_rnnt 10.645388 hw_loss 0.193493 lr 0.00094150 rank 3
2023-02-11 06:49:12,057 DEBUG TRAIN Batch 3/3200 loss 37.311306 loss_att 54.580315 loss_ctc 57.746914 loss_rnnt 28.348038 hw_loss 0.522134 lr 0.00094085 rank 2
2023-02-11 06:49:12,058 DEBUG TRAIN Batch 3/3200 loss 33.864700 loss_att 35.537292 loss_ctc 47.685432 loss_rnnt 29.511772 hw_loss 0.407934 lr 0.00094147 rank 6
2023-02-11 06:49:12,058 DEBUG TRAIN Batch 3/3200 loss 20.488232 loss_att 18.878847 loss_ctc 23.251637 loss_rnnt 13.925881 hw_loss 1.221708 lr 0.00094177 rank 4
2023-02-11 06:49:12,059 DEBUG TRAIN Batch 3/3200 loss 38.800552 loss_att 44.229511 loss_ctc 53.103138 loss_rnnt 33.572491 hw_loss 0.419111 lr 0.00094180 rank 7
2023-02-11 06:49:12,076 DEBUG TRAIN Batch 3/3200 loss 18.478373 loss_att 20.133947 loss_ctc 26.919724 loss_rnnt 13.537883 hw_loss 0.653224 lr 0.00094085 rank 5
2023-02-11 06:49:12,083 DEBUG TRAIN Batch 3/3200 loss 30.487659 loss_att 38.272415 loss_ctc 40.428986 loss_rnnt 22.643072 hw_loss 0.930399 lr 0.00094072 rank 0
2023-02-11 06:49:12,108 DEBUG TRAIN Batch 3/3200 loss 43.143223 loss_att 49.202431 loss_ctc 61.573662 loss_rnnt 37.128811 hw_loss 0.439722 lr 0.00094065 rank 1
2023-02-11 06:50:28,734 DEBUG TRAIN Batch 3/3300 loss 14.765627 loss_att 20.385326 loss_ctc 33.037971 loss_rnnt 9.401337 hw_loss 0.338257 lr 0.00093984 rank 3
2023-02-11 06:50:28,740 DEBUG TRAIN Batch 3/3300 loss 23.864048 loss_att 33.740017 loss_ctc 45.855465 loss_rnnt 17.718784 hw_loss 0.232103 lr 0.00093906 rank 0
2023-02-11 06:50:28,742 DEBUG TRAIN Batch 3/3300 loss 21.810909 loss_att 32.780880 loss_ctc 38.618717 loss_rnnt 15.075903 hw_loss 0.431245 lr 0.00093919 rank 2
2023-02-11 06:50:28,743 DEBUG TRAIN Batch 3/3300 loss 44.199932 loss_att 54.194973 loss_ctc 65.147461 loss_rnnt 36.966301 hw_loss 0.457804 lr 0.00094011 rank 4
2023-02-11 06:50:28,742 DEBUG TRAIN Batch 3/3300 loss 25.836576 loss_att 35.413132 loss_ctc 37.454967 loss_rnnt 22.339973 hw_loss 0.006032 lr 0.00093981 rank 6
2023-02-11 06:50:28,742 DEBUG TRAIN Batch 3/3300 loss 50.487041 loss_att 59.666580 loss_ctc 70.579155 loss_rnnt 43.363110 hw_loss 0.489201 lr 0.00093899 rank 1
2023-02-11 06:50:28,743 DEBUG TRAIN Batch 3/3300 loss 34.949406 loss_att 38.380150 loss_ctc 45.594475 loss_rnnt 30.019756 hw_loss 0.529530 lr 0.00093919 rank 5
2023-02-11 06:50:28,745 DEBUG TRAIN Batch 3/3300 loss 43.070354 loss_att 52.688232 loss_ctc 55.617775 loss_rnnt 36.078560 hw_loss 0.636605 lr 0.00094014 rank 7
2023-02-11 06:51:44,269 DEBUG TRAIN Batch 3/3400 loss 50.290379 loss_att 52.487789 loss_ctc 71.102570 loss_rnnt 43.547821 hw_loss 0.661522 lr 0.00093741 rank 0
2023-02-11 06:51:44,270 DEBUG TRAIN Batch 3/3400 loss 41.925488 loss_att 45.053074 loss_ctc 57.013088 loss_rnnt 36.494125 hw_loss 0.523905 lr 0.00093815 rank 6
2023-02-11 06:51:44,275 DEBUG TRAIN Batch 3/3400 loss 27.587904 loss_att 31.917028 loss_ctc 49.799362 loss_rnnt 20.965740 hw_loss 0.524027 lr 0.00093848 rank 7
2023-02-11 06:51:44,277 DEBUG TRAIN Batch 3/3400 loss 24.494072 loss_att 35.073177 loss_ctc 42.113213 loss_rnnt 17.619701 hw_loss 0.451749 lr 0.00093754 rank 5
2023-02-11 06:51:44,277 DEBUG TRAIN Batch 3/3400 loss 41.248722 loss_att 43.076797 loss_ctc 50.525677 loss_rnnt 36.708618 hw_loss 0.550793 lr 0.00093818 rank 3
2023-02-11 06:51:44,279 DEBUG TRAIN Batch 3/3400 loss 36.681065 loss_att 39.369614 loss_ctc 56.242092 loss_rnnt 30.613804 hw_loss 0.547765 lr 0.00093845 rank 4
2023-02-11 06:51:44,281 DEBUG TRAIN Batch 3/3400 loss 29.393150 loss_att 31.628855 loss_ctc 46.555084 loss_rnnt 22.883602 hw_loss 0.707653 lr 0.00093754 rank 2
2023-02-11 06:51:44,326 DEBUG TRAIN Batch 3/3400 loss 24.427067 loss_att 24.241312 loss_ctc 28.858540 loss_rnnt 20.929569 hw_loss 0.551960 lr 0.00093734 rank 1
2023-02-11 06:53:01,502 DEBUG TRAIN Batch 3/3500 loss 19.456373 loss_att 25.416800 loss_ctc 29.659584 loss_rnnt 12.796320 hw_loss 0.770163 lr 0.00093650 rank 6
2023-02-11 06:53:01,502 DEBUG TRAIN Batch 3/3500 loss 35.043564 loss_att 42.408882 loss_ctc 52.257515 loss_rnnt 29.226952 hw_loss 0.384066 lr 0.00093577 rank 0
2023-02-11 06:53:01,502 DEBUG TRAIN Batch 3/3500 loss 32.383369 loss_att 37.593620 loss_ctc 43.532326 loss_rnnt 28.699993 hw_loss 0.216525 lr 0.00093654 rank 3
2023-02-11 06:53:01,503 DEBUG TRAIN Batch 3/3500 loss 16.211830 loss_att 23.426926 loss_ctc 24.669321 loss_rnnt 10.701632 hw_loss 0.551159 lr 0.00093590 rank 5
2023-02-11 06:53:01,502 DEBUG TRAIN Batch 3/3500 loss 40.198235 loss_att 39.923656 loss_ctc 54.215065 loss_rnnt 33.440788 hw_loss 0.926897 lr 0.00093680 rank 4
2023-02-11 06:53:01,505 DEBUG TRAIN Batch 3/3500 loss 39.380253 loss_att 45.233002 loss_ctc 54.046982 loss_rnnt 33.619080 hw_loss 0.494074 lr 0.00093683 rank 7
2023-02-11 06:53:01,506 DEBUG TRAIN Batch 3/3500 loss 36.311108 loss_att 43.547272 loss_ctc 55.334473 loss_rnnt 30.048138 hw_loss 0.427368 lr 0.00093590 rank 2
2023-02-11 06:53:01,507 DEBUG TRAIN Batch 3/3500 loss 30.853270 loss_att 35.460350 loss_ctc 52.415596 loss_rnnt 23.660561 hw_loss 0.636809 lr 0.00093570 rank 1
2023-02-11 06:54:19,330 DEBUG TRAIN Batch 3/3600 loss 27.338350 loss_att 34.580296 loss_ctc 46.591583 loss_rnnt 21.262680 hw_loss 0.386284 lr 0.00093519 rank 7
2023-02-11 06:54:19,330 DEBUG TRAIN Batch 3/3600 loss 71.364639 loss_att 76.596016 loss_ctc 93.917084 loss_rnnt 64.463715 hw_loss 0.533936 lr 0.00093516 rank 4
2023-02-11 06:54:19,332 DEBUG TRAIN Batch 3/3600 loss 42.316784 loss_att 46.087547 loss_ctc 66.785522 loss_rnnt 36.047607 hw_loss 0.422349 lr 0.00093426 rank 5
2023-02-11 06:54:19,332 DEBUG TRAIN Batch 3/3600 loss 31.066242 loss_att 35.335655 loss_ctc 43.941948 loss_rnnt 26.995609 hw_loss 0.281248 lr 0.00093490 rank 3
2023-02-11 06:54:19,336 DEBUG TRAIN Batch 3/3600 loss 25.122372 loss_att 29.547497 loss_ctc 31.013739 loss_rnnt 20.718763 hw_loss 0.512450 lr 0.00093413 rank 0
2023-02-11 06:54:19,338 DEBUG TRAIN Batch 3/3600 loss 33.984474 loss_att 41.422829 loss_ctc 41.516781 loss_rnnt 29.356499 hw_loss 0.400499 lr 0.00093487 rank 6
2023-02-11 06:54:19,339 DEBUG TRAIN Batch 3/3600 loss 34.290920 loss_att 38.989731 loss_ctc 46.586281 loss_rnnt 29.805780 hw_loss 0.357374 lr 0.00093426 rank 2
2023-02-11 06:54:19,342 DEBUG TRAIN Batch 3/3600 loss 35.391933 loss_att 38.864269 loss_ctc 42.866409 loss_rnnt 29.689220 hw_loss 0.752185 lr 0.00093407 rank 1
2023-02-11 06:55:36,554 DEBUG TRAIN Batch 3/3700 loss 29.111538 loss_att 37.601795 loss_ctc 48.115486 loss_rnnt 21.903324 hw_loss 0.558057 lr 0.00093356 rank 7
2023-02-11 06:55:36,558 DEBUG TRAIN Batch 3/3700 loss 19.976362 loss_att 22.753822 loss_ctc 29.468790 loss_rnnt 17.662067 hw_loss 0.092465 lr 0.00093250 rank 0
2023-02-11 06:55:36,558 DEBUG TRAIN Batch 3/3700 loss 23.393797 loss_att 26.394781 loss_ctc 31.946039 loss_rnnt 17.673353 hw_loss 0.746240 lr 0.00093327 rank 3
2023-02-11 06:55:36,559 DEBUG TRAIN Batch 3/3700 loss 40.600807 loss_att 40.915840 loss_ctc 54.996151 loss_rnnt 34.810497 hw_loss 0.713987 lr 0.00093263 rank 2
2023-02-11 06:55:36,561 DEBUG TRAIN Batch 3/3700 loss 23.575623 loss_att 27.174866 loss_ctc 32.191158 loss_rnnt 18.170654 hw_loss 0.663072 lr 0.00093244 rank 1
2023-02-11 06:55:36,561 DEBUG TRAIN Batch 3/3700 loss 35.234741 loss_att 39.362431 loss_ctc 52.755051 loss_rnnt 28.778454 hw_loss 0.617757 lr 0.00093263 rank 5
2023-02-11 06:55:36,586 DEBUG TRAIN Batch 3/3700 loss 33.397926 loss_att 34.915878 loss_ctc 46.377529 loss_rnnt 28.191154 hw_loss 0.594856 lr 0.00093324 rank 6
2023-02-11 06:55:36,594 DEBUG TRAIN Batch 3/3700 loss 20.730778 loss_att 25.262745 loss_ctc 27.881817 loss_rnnt 16.598988 hw_loss 0.425986 lr 0.00093353 rank 4
2023-02-11 06:56:53,925 DEBUG TRAIN Batch 3/3800 loss 26.960863 loss_att 29.985680 loss_ctc 39.577942 loss_rnnt 20.169851 hw_loss 0.844457 lr 0.00093194 rank 7
2023-02-11 06:56:53,929 DEBUG TRAIN Batch 3/3800 loss 22.131699 loss_att 20.376419 loss_ctc 29.760805 loss_rnnt 17.667183 hw_loss 0.712192 lr 0.00093165 rank 3
2023-02-11 06:56:53,931 DEBUG TRAIN Batch 3/3800 loss 18.110672 loss_att 17.554585 loss_ctc 22.244144 loss_rnnt 13.234634 hw_loss 0.831773 lr 0.00093089 rank 0
2023-02-11 06:56:53,931 DEBUG TRAIN Batch 3/3800 loss 28.500391 loss_att 42.194618 loss_ctc 49.364548 loss_rnnt 21.881832 hw_loss 0.205843 lr 0.00093082 rank 1
2023-02-11 06:56:53,935 DEBUG TRAIN Batch 3/3800 loss 29.338640 loss_att 31.324272 loss_ctc 35.230347 loss_rnnt 23.114122 hw_loss 0.945343 lr 0.00093161 rank 6
2023-02-11 06:56:53,935 DEBUG TRAIN Batch 3/3800 loss 44.242653 loss_att 53.955963 loss_ctc 71.607773 loss_rnnt 35.433342 hw_loss 0.603369 lr 0.00093102 rank 2
2023-02-11 06:56:53,936 DEBUG TRAIN Batch 3/3800 loss 33.724228 loss_att 37.118889 loss_ctc 43.713173 loss_rnnt 27.903511 hw_loss 0.714361 lr 0.00093102 rank 5
2023-02-11 06:56:53,979 DEBUG TRAIN Batch 3/3800 loss 36.761650 loss_att 36.210068 loss_ctc 50.267357 loss_rnnt 31.210873 hw_loss 0.723813 lr 0.00093191 rank 4
2023-02-11 06:58:13,389 DEBUG TRAIN Batch 3/3900 loss 20.194300 loss_att 21.774496 loss_ctc 25.431906 loss_rnnt 16.686937 hw_loss 0.467433 lr 0.00093000 rank 6
2023-02-11 06:58:13,390 DEBUG TRAIN Batch 3/3900 loss 51.669567 loss_att 60.700596 loss_ctc 86.540909 loss_rnnt 44.127998 hw_loss 0.203597 lr 0.00093003 rank 3
2023-02-11 06:58:13,391 DEBUG TRAIN Batch 3/3900 loss 31.994907 loss_att 44.741520 loss_ctc 47.397179 loss_rnnt 24.773174 hw_loss 0.491020 lr 0.00093029 rank 4
2023-02-11 06:58:13,392 DEBUG TRAIN Batch 3/3900 loss 26.639294 loss_att 28.582497 loss_ctc 44.137524 loss_rnnt 22.157528 hw_loss 0.330005 lr 0.00092941 rank 2
2023-02-11 06:58:13,391 DEBUG TRAIN Batch 3/3900 loss 17.051853 loss_att 15.287378 loss_ctc 19.766880 loss_rnnt 12.118007 hw_loss 0.923388 lr 0.00093032 rank 7
2023-02-11 06:58:13,392 DEBUG TRAIN Batch 3/3900 loss 28.848627 loss_att 35.183220 loss_ctc 38.031036 loss_rnnt 25.995726 hw_loss 0.067812 lr 0.00092921 rank 1
2023-02-11 06:58:13,392 DEBUG TRAIN Batch 3/3900 loss 51.518169 loss_att 63.263832 loss_ctc 72.772392 loss_rnnt 45.284164 hw_loss 0.197058 lr 0.00092941 rank 5
2023-02-11 06:58:13,394 DEBUG TRAIN Batch 3/3900 loss 29.396147 loss_att 34.776905 loss_ctc 42.229031 loss_rnnt 25.315842 hw_loss 0.242457 lr 0.00092928 rank 0
2023-02-11 06:59:29,216 DEBUG TRAIN Batch 3/4000 loss 35.159695 loss_att 41.710396 loss_ctc 58.172176 loss_rnnt 30.013983 hw_loss 0.143857 lr 0.00092768 rank 0
2023-02-11 06:59:29,219 DEBUG TRAIN Batch 3/4000 loss 38.278214 loss_att 45.225986 loss_ctc 52.256531 loss_rnnt 32.392471 hw_loss 0.493577 lr 0.00092843 rank 3
2023-02-11 06:59:29,221 DEBUG TRAIN Batch 3/4000 loss 55.326923 loss_att 59.538986 loss_ctc 71.359024 loss_rnnt 48.926067 hw_loss 0.641406 lr 0.00092868 rank 4
2023-02-11 06:59:29,222 DEBUG TRAIN Batch 3/4000 loss 47.260456 loss_att 47.663399 loss_ctc 70.594666 loss_rnnt 40.456196 hw_loss 0.677333 lr 0.00092872 rank 7
2023-02-11 06:59:29,224 DEBUG TRAIN Batch 3/4000 loss 12.236402 loss_att 17.717628 loss_ctc 15.268098 loss_rnnt 7.555102 hw_loss 0.596405 lr 0.00092761 rank 1
2023-02-11 06:59:29,225 DEBUG TRAIN Batch 3/4000 loss 33.519119 loss_att 37.071815 loss_ctc 44.964027 loss_rnnt 27.691504 hw_loss 0.673329 lr 0.00092840 rank 6
2023-02-11 06:59:29,225 DEBUG TRAIN Batch 3/4000 loss 40.699230 loss_att 42.139374 loss_ctc 62.410149 loss_rnnt 35.241215 hw_loss 0.426599 lr 0.00092781 rank 5
2023-02-11 06:59:29,225 DEBUG TRAIN Batch 3/4000 loss 31.354736 loss_att 38.681290 loss_ctc 55.048676 loss_rnnt 24.596981 hw_loss 0.399985 lr 0.00092781 rank 2
2023-02-11 07:00:45,142 DEBUG TRAIN Batch 3/4100 loss 28.510193 loss_att 32.182167 loss_ctc 38.300602 loss_rnnt 23.574858 hw_loss 0.542916 lr 0.00092683 rank 3
2023-02-11 07:00:45,142 DEBUG TRAIN Batch 3/4100 loss 32.229012 loss_att 37.644413 loss_ctc 49.467270 loss_rnnt 27.116459 hw_loss 0.324569 lr 0.00092608 rank 0
2023-02-11 07:00:45,150 DEBUG TRAIN Batch 3/4100 loss 18.011711 loss_att 23.880478 loss_ctc 26.972492 loss_rnnt 13.323011 hw_loss 0.435033 lr 0.00092602 rank 1
2023-02-11 07:00:45,151 DEBUG TRAIN Batch 3/4100 loss 35.945351 loss_att 43.044930 loss_ctc 50.941265 loss_rnnt 27.764393 hw_loss 0.892797 lr 0.00092712 rank 7
2023-02-11 07:00:45,152 DEBUG TRAIN Batch 3/4100 loss 26.972139 loss_att 34.181747 loss_ctc 37.366497 loss_rnnt 22.365250 hw_loss 0.333572 lr 0.00092621 rank 5
2023-02-11 07:00:45,153 DEBUG TRAIN Batch 3/4100 loss 11.135441 loss_att 19.265480 loss_ctc 16.337097 loss_rnnt 7.194590 hw_loss 0.303992 lr 0.00092709 rank 4
2023-02-11 07:00:45,154 DEBUG TRAIN Batch 3/4100 loss 32.961460 loss_att 42.232544 loss_ctc 53.728233 loss_rnnt 27.655239 hw_loss 0.128082 lr 0.00092680 rank 6
2023-02-11 07:00:45,154 DEBUG TRAIN Batch 3/4100 loss 36.670723 loss_att 42.695862 loss_ctc 56.823586 loss_rnnt 30.673641 hw_loss 0.394689 lr 0.00092621 rank 2
2023-02-11 07:02:02,208 DEBUG TRAIN Batch 3/4200 loss 20.061619 loss_att 29.831963 loss_ctc 32.875767 loss_rnnt 13.337934 hw_loss 0.573949 lr 0.00092550 rank 4
2023-02-11 07:02:02,208 DEBUG TRAIN Batch 3/4200 loss 53.494579 loss_att 52.882019 loss_ctc 69.710098 loss_rnnt 46.536072 hw_loss 0.922304 lr 0.00092553 rank 7
2023-02-11 07:02:02,208 DEBUG TRAIN Batch 3/4200 loss 30.099228 loss_att 34.526344 loss_ctc 46.795910 loss_rnnt 25.159634 hw_loss 0.342740 lr 0.00092450 rank 0
2023-02-11 07:02:02,209 DEBUG TRAIN Batch 3/4200 loss 34.317684 loss_att 36.613914 loss_ctc 49.552864 loss_rnnt 28.103319 hw_loss 0.698205 lr 0.00092524 rank 3
2023-02-11 07:02:02,209 DEBUG TRAIN Batch 3/4200 loss 39.109463 loss_att 42.483643 loss_ctc 61.265282 loss_rnnt 32.787632 hw_loss 0.504917 lr 0.00092521 rank 6
2023-02-11 07:02:02,210 DEBUG TRAIN Batch 3/4200 loss 34.655251 loss_att 46.955803 loss_ctc 53.456367 loss_rnnt 28.023764 hw_loss 0.312105 lr 0.00092463 rank 5
2023-02-11 07:02:02,213 DEBUG TRAIN Batch 3/4200 loss 37.675625 loss_att 41.522629 loss_ctc 50.551903 loss_rnnt 33.488129 hw_loss 0.318986 lr 0.00092444 rank 1
2023-02-11 07:02:02,219 DEBUG TRAIN Batch 3/4200 loss 36.754066 loss_att 37.407349 loss_ctc 48.659843 loss_rnnt 30.835524 hw_loss 0.787585 lr 0.00092463 rank 2
2023-02-11 07:03:20,677 DEBUG TRAIN Batch 3/4300 loss 28.433403 loss_att 29.074268 loss_ctc 39.231148 loss_rnnt 23.034197 hw_loss 0.718375 lr 0.00092395 rank 7
2023-02-11 07:03:20,680 DEBUG TRAIN Batch 3/4300 loss 27.481113 loss_att 41.119957 loss_ctc 45.325817 loss_rnnt 20.502501 hw_loss 0.350916 lr 0.00092366 rank 3
2023-02-11 07:03:20,680 DEBUG TRAIN Batch 3/4300 loss 39.586990 loss_att 42.134270 loss_ctc 55.297993 loss_rnnt 34.531208 hw_loss 0.459660 lr 0.00092292 rank 0
2023-02-11 07:03:20,681 DEBUG TRAIN Batch 3/4300 loss 40.265888 loss_att 41.150639 loss_ctc 49.553986 loss_rnnt 36.350601 hw_loss 0.468736 lr 0.00092286 rank 1
2023-02-11 07:03:20,684 DEBUG TRAIN Batch 3/4300 loss 25.747625 loss_att 29.496841 loss_ctc 36.003479 loss_rnnt 19.910669 hw_loss 0.697437 lr 0.00092305 rank 5
2023-02-11 07:03:20,686 DEBUG TRAIN Batch 3/4300 loss 24.248112 loss_att 28.562946 loss_ctc 35.882629 loss_rnnt 19.603531 hw_loss 0.418190 lr 0.00092363 rank 6
2023-02-11 07:03:20,688 DEBUG TRAIN Batch 3/4300 loss 25.786606 loss_att 28.744905 loss_ctc 38.402142 loss_rnnt 19.727192 hw_loss 0.709815 lr 0.00092305 rank 2
2023-02-11 07:03:20,692 DEBUG TRAIN Batch 3/4300 loss 38.019978 loss_att 45.238457 loss_ctc 56.027451 loss_rnnt 33.276829 hw_loss 0.168460 lr 0.00092392 rank 4
2023-02-11 07:04:37,528 DEBUG TRAIN Batch 3/4400 loss 35.671074 loss_att 32.926498 loss_ctc 47.258850 loss_rnnt 32.361828 hw_loss 0.433711 lr 0.00092136 rank 0
2023-02-11 07:04:37,533 DEBUG TRAIN Batch 3/4400 loss 25.353745 loss_att 28.670160 loss_ctc 34.473125 loss_rnnt 20.173481 hw_loss 0.618949 lr 0.00092209 rank 3
2023-02-11 07:04:37,534 DEBUG TRAIN Batch 3/4400 loss 37.935356 loss_att 45.524208 loss_ctc 45.305252 loss_rnnt 30.790968 hw_loss 0.870744 lr 0.00092237 rank 7
2023-02-11 07:04:37,535 DEBUG TRAIN Batch 3/4400 loss 13.459227 loss_att 10.361021 loss_ctc 12.760676 loss_rnnt 9.149879 hw_loss 0.941649 lr 0.00092129 rank 1
2023-02-11 07:04:37,536 DEBUG TRAIN Batch 3/4400 loss 16.845270 loss_att 20.611996 loss_ctc 20.561848 loss_rnnt 14.257866 hw_loss 0.250971 lr 0.00092148 rank 2
2023-02-11 07:04:37,537 DEBUG TRAIN Batch 3/4400 loss 30.984705 loss_att 35.215782 loss_ctc 44.168064 loss_rnnt 26.199570 hw_loss 0.408963 lr 0.00092206 rank 6
2023-02-11 07:04:37,540 DEBUG TRAIN Batch 3/4400 loss 38.017925 loss_att 46.194122 loss_ctc 59.394508 loss_rnnt 30.984312 hw_loss 0.477780 lr 0.00092148 rank 5
2023-02-11 07:04:37,541 DEBUG TRAIN Batch 3/4400 loss 22.494234 loss_att 22.982758 loss_ctc 30.285620 loss_rnnt 17.127043 hw_loss 0.793244 lr 0.00092234 rank 4
2023-02-11 07:05:53,089 DEBUG TRAIN Batch 3/4500 loss 35.657784 loss_att 45.544838 loss_ctc 52.821819 loss_rnnt 28.116116 hw_loss 0.614197 lr 0.00092078 rank 4
2023-02-11 07:05:53,090 DEBUG TRAIN Batch 3/4500 loss 16.593102 loss_att 27.782288 loss_ctc 23.248482 loss_rnnt 10.508165 hw_loss 0.554946 lr 0.00092053 rank 3
2023-02-11 07:05:53,091 DEBUG TRAIN Batch 3/4500 loss 31.106852 loss_att 29.107368 loss_ctc 42.303974 loss_rnnt 25.713541 hw_loss 0.806298 lr 0.00092050 rank 6
2023-02-11 07:05:53,091 DEBUG TRAIN Batch 3/4500 loss 56.107620 loss_att 65.476273 loss_ctc 79.450523 loss_rnnt 47.622021 hw_loss 0.656153 lr 0.00091980 rank 0
2023-02-11 07:05:53,094 DEBUG TRAIN Batch 3/4500 loss 30.670935 loss_att 37.535305 loss_ctc 53.512993 loss_rnnt 24.393270 hw_loss 0.348597 lr 0.00091992 rank 5
2023-02-11 07:05:53,095 DEBUG TRAIN Batch 3/4500 loss 20.734417 loss_att 28.197067 loss_ctc 25.544365 loss_rnnt 15.880255 hw_loss 0.510057 lr 0.00091973 rank 1
2023-02-11 07:05:53,099 DEBUG TRAIN Batch 3/4500 loss 30.141993 loss_att 29.549242 loss_ctc 34.941978 loss_rnnt 24.327856 hw_loss 0.992379 lr 0.00092081 rank 7
2023-02-11 07:05:53,150 DEBUG TRAIN Batch 3/4500 loss 26.707890 loss_att 30.576107 loss_ctc 38.340420 loss_rnnt 22.919750 hw_loss 0.274405 lr 0.00091992 rank 2
2023-02-11 07:07:12,424 DEBUG TRAIN Batch 3/4600 loss 30.699068 loss_att 39.365257 loss_ctc 44.821007 loss_rnnt 25.994345 hw_loss 0.204105 lr 0.00091837 rank 5
2023-02-11 07:07:12,425 DEBUG TRAIN Batch 3/4600 loss 44.072369 loss_att 58.026482 loss_ctc 68.265762 loss_rnnt 34.979858 hw_loss 0.576732 lr 0.00091925 rank 7
2023-02-11 07:07:12,427 DEBUG TRAIN Batch 3/4600 loss 17.632170 loss_att 23.469887 loss_ctc 23.433331 loss_rnnt 11.614618 hw_loss 0.764347 lr 0.00091837 rank 2
2023-02-11 07:07:12,427 DEBUG TRAIN Batch 3/4600 loss 40.457512 loss_att 51.629688 loss_ctc 71.114624 loss_rnnt 30.334980 hw_loss 0.712590 lr 0.00091894 rank 6
2023-02-11 07:07:12,427 DEBUG TRAIN Batch 3/4600 loss 27.129559 loss_att 31.623180 loss_ctc 32.991508 loss_rnnt 22.749006 hw_loss 0.506294 lr 0.00091824 rank 0
2023-02-11 07:07:12,428 DEBUG TRAIN Batch 3/4600 loss 25.506800 loss_att 30.872423 loss_ctc 37.593376 loss_rnnt 21.626110 hw_loss 0.224254 lr 0.00091897 rank 3
2023-02-11 07:07:12,430 DEBUG TRAIN Batch 3/4600 loss 24.910982 loss_att 29.793312 loss_ctc 30.084532 loss_rnnt 21.143223 hw_loss 0.394029 lr 0.00091922 rank 4
2023-02-11 07:07:12,471 DEBUG TRAIN Batch 3/4600 loss 44.131599 loss_att 49.214577 loss_ctc 69.844543 loss_rnnt 36.089317 hw_loss 0.674493 lr 0.00091818 rank 1
2023-02-11 07:08:30,320 DEBUG TRAIN Batch 3/4700 loss 25.519701 loss_att 26.508945 loss_ctc 34.912205 loss_rnnt 21.256432 hw_loss 0.527454 lr 0.00091682 rank 2
2023-02-11 07:08:30,321 DEBUG TRAIN Batch 3/4700 loss 41.643970 loss_att 41.647190 loss_ctc 58.493965 loss_rnnt 35.759048 hw_loss 0.682053 lr 0.00091682 rank 5
2023-02-11 07:08:30,321 DEBUG TRAIN Batch 3/4700 loss 35.822060 loss_att 39.717812 loss_ctc 49.620636 loss_rnnt 32.394958 hw_loss 0.151526 lr 0.00091770 rank 7
2023-02-11 07:08:30,322 DEBUG TRAIN Batch 3/4700 loss 31.453014 loss_att 35.071762 loss_ctc 43.071098 loss_rnnt 25.791233 hw_loss 0.635428 lr 0.00091670 rank 0
2023-02-11 07:08:30,325 DEBUG TRAIN Batch 3/4700 loss 29.282887 loss_att 29.804684 loss_ctc 45.984917 loss_rnnt 21.544445 hw_loss 1.013840 lr 0.00091742 rank 3
2023-02-11 07:08:30,326 DEBUG TRAIN Batch 3/4700 loss 19.208170 loss_att 19.872274 loss_ctc 28.030682 loss_rnnt 14.878206 hw_loss 0.566402 lr 0.00091767 rank 4
2023-02-11 07:08:30,327 DEBUG TRAIN Batch 3/4700 loss 16.190716 loss_att 24.827417 loss_ctc 24.996588 loss_rnnt 12.230338 hw_loss 0.198548 lr 0.00091664 rank 1
2023-02-11 07:08:30,328 DEBUG TRAIN Batch 3/4700 loss 33.675972 loss_att 40.005524 loss_ctc 47.659695 loss_rnnt 26.484985 hw_loss 0.761358 lr 0.00091739 rank 6
2023-02-11 07:09:44,296 DEBUG TRAIN Batch 3/4800 loss 35.796215 loss_att 38.359966 loss_ctc 50.253677 loss_rnnt 31.732925 hw_loss 0.304290 lr 0.00091516 rank 0
2023-02-11 07:09:44,299 DEBUG TRAIN Batch 3/4800 loss 22.146654 loss_att 28.586409 loss_ctc 35.126694 loss_rnnt 18.562210 hw_loss 0.106091 lr 0.00091528 rank 5
2023-02-11 07:09:44,299 DEBUG TRAIN Batch 3/4800 loss 38.880749 loss_att 41.447720 loss_ctc 53.561089 loss_rnnt 33.119316 hw_loss 0.616999 lr 0.00091585 rank 6
2023-02-11 07:09:44,299 DEBUG TRAIN Batch 3/4800 loss 28.281673 loss_att 35.943142 loss_ctc 39.419388 loss_rnnt 23.545399 hw_loss 0.322303 lr 0.00091588 rank 3
2023-02-11 07:09:44,300 DEBUG TRAIN Batch 3/4800 loss 28.789686 loss_att 27.709995 loss_ctc 43.253117 loss_rnnt 23.564564 hw_loss 0.658613 lr 0.00091616 rank 7
2023-02-11 07:09:44,302 DEBUG TRAIN Batch 3/4800 loss 50.375050 loss_att 52.025078 loss_ctc 68.467346 loss_rnnt 44.447273 hw_loss 0.597274 lr 0.00091528 rank 2
2023-02-11 07:09:44,305 DEBUG TRAIN Batch 3/4800 loss 39.935577 loss_att 43.124435 loss_ctc 66.273331 loss_rnnt 32.481102 hw_loss 0.619688 lr 0.00091510 rank 1
2023-02-11 07:09:44,313 DEBUG TRAIN Batch 3/4800 loss 42.512272 loss_att 48.915470 loss_ctc 62.674686 loss_rnnt 34.814049 hw_loss 0.699236 lr 0.00091613 rank 4
2023-02-11 07:10:59,719 DEBUG TRAIN Batch 3/4900 loss 29.579372 loss_att 34.748093 loss_ctc 45.985634 loss_rnnt 24.767189 hw_loss 0.298301 lr 0.00091363 rank 0
2023-02-11 07:10:59,722 DEBUG TRAIN Batch 3/4900 loss 38.589668 loss_att 45.349762 loss_ctc 57.077675 loss_rnnt 32.166901 hw_loss 0.488565 lr 0.00091435 rank 3
2023-02-11 07:10:59,725 DEBUG TRAIN Batch 3/4900 loss 27.027805 loss_att 30.570848 loss_ctc 37.662811 loss_rnnt 23.158161 hw_loss 0.326818 lr 0.00091357 rank 1
2023-02-11 07:10:59,727 DEBUG TRAIN Batch 3/4900 loss 18.559393 loss_att 21.000458 loss_ctc 30.755699 loss_rnnt 13.534029 hw_loss 0.545808 lr 0.00091463 rank 7
2023-02-11 07:10:59,731 DEBUG TRAIN Batch 3/4900 loss 37.564629 loss_att 45.218285 loss_ctc 59.025959 loss_rnnt 32.686859 hw_loss 0.091037 lr 0.00091460 rank 4
2023-02-11 07:10:59,735 DEBUG TRAIN Batch 3/4900 loss 29.177162 loss_att 32.277130 loss_ctc 54.264309 loss_rnnt 22.170479 hw_loss 0.570325 lr 0.00091375 rank 2
2023-02-11 07:10:59,751 DEBUG TRAIN Batch 3/4900 loss 25.978029 loss_att 29.309521 loss_ctc 33.653351 loss_rnnt 20.463310 hw_loss 0.717196 lr 0.00091375 rank 5
2023-02-11 07:10:59,755 DEBUG TRAIN Batch 3/4900 loss 33.595619 loss_att 35.745041 loss_ctc 48.788040 loss_rnnt 27.471369 hw_loss 0.687883 lr 0.00091432 rank 6
2023-02-11 07:12:18,873 DEBUG TRAIN Batch 3/5000 loss 26.039606 loss_att 30.383808 loss_ctc 37.064243 loss_rnnt 19.513725 hw_loss 0.785079 lr 0.00091223 rank 5
2023-02-11 07:12:18,874 DEBUG TRAIN Batch 3/5000 loss 24.979212 loss_att 25.878986 loss_ctc 40.243233 loss_rnnt 21.103279 hw_loss 0.311395 lr 0.00091310 rank 7
2023-02-11 07:12:18,875 DEBUG TRAIN Batch 3/5000 loss 35.303555 loss_att 36.318848 loss_ctc 50.880352 loss_rnnt 30.493681 hw_loss 0.474358 lr 0.00091211 rank 0
2023-02-11 07:12:18,879 DEBUG TRAIN Batch 3/5000 loss 29.993391 loss_att 36.279793 loss_ctc 43.652447 loss_rnnt 26.124432 hw_loss 0.148213 lr 0.00091279 rank 6
2023-02-11 07:12:18,878 DEBUG TRAIN Batch 3/5000 loss 37.826748 loss_att 41.663857 loss_ctc 53.661392 loss_rnnt 30.455854 hw_loss 0.842284 lr 0.00091307 rank 4
2023-02-11 07:12:18,879 DEBUG TRAIN Batch 3/5000 loss 18.198587 loss_att 18.718008 loss_ctc 24.491314 loss_rnnt 13.517755 hw_loss 0.700859 lr 0.00091205 rank 1
2023-02-11 07:12:18,879 DEBUG TRAIN Batch 3/5000 loss 27.152290 loss_att 29.048443 loss_ctc 39.819092 loss_rnnt 21.608664 hw_loss 0.651654 lr 0.00091283 rank 3
2023-02-11 07:12:18,887 DEBUG TRAIN Batch 3/5000 loss 22.354555 loss_att 20.278313 loss_ctc 23.478949 loss_rnnt 18.821987 hw_loss 0.712105 lr 0.00091223 rank 2
2023-02-11 07:13:35,640 DEBUG TRAIN Batch 3/5100 loss 30.457794 loss_att 28.093681 loss_ctc 36.318279 loss_rnnt 23.929504 hw_loss 1.166196 lr 0.00091158 rank 7
2023-02-11 07:13:35,643 DEBUG TRAIN Batch 3/5100 loss 38.308697 loss_att 41.757774 loss_ctc 55.703915 loss_rnnt 30.449743 hw_loss 0.909332 lr 0.00091128 rank 6
2023-02-11 07:13:35,643 DEBUG TRAIN Batch 3/5100 loss 46.855843 loss_att 49.520714 loss_ctc 54.455109 loss_rnnt 42.977764 hw_loss 0.437225 lr 0.00091054 rank 1
2023-02-11 07:13:35,644 DEBUG TRAIN Batch 3/5100 loss 68.347580 loss_att 87.847374 loss_ctc 100.707237 loss_rnnt 58.039501 hw_loss 0.392531 lr 0.00091060 rank 0
2023-02-11 07:13:35,645 DEBUG TRAIN Batch 3/5100 loss 22.069401 loss_att 18.821045 loss_ctc 23.806749 loss_rnnt 16.586918 hw_loss 1.106345 lr 0.00091131 rank 3
2023-02-11 07:13:35,645 DEBUG TRAIN Batch 3/5100 loss 25.051254 loss_att 23.488083 loss_ctc 30.097399 loss_rnnt 20.787361 hw_loss 0.731945 lr 0.00091155 rank 4
2023-02-11 07:13:35,645 DEBUG TRAIN Batch 3/5100 loss 24.019587 loss_att 27.893232 loss_ctc 34.262203 loss_rnnt 18.144979 hw_loss 0.700162 lr 0.00091072 rank 5
2023-02-11 07:13:35,645 DEBUG TRAIN Batch 3/5100 loss 19.132265 loss_att 23.016983 loss_ctc 22.159103 loss_rnnt 15.515326 hw_loss 0.456829 lr 0.00091072 rank 2
2023-02-11 07:14:51,210 DEBUG TRAIN Batch 3/5200 loss 16.167368 loss_att 24.265797 loss_ctc 29.666576 loss_rnnt 10.955263 hw_loss 0.336098 lr 0.00090977 rank 6
2023-02-11 07:14:51,211 DEBUG TRAIN Batch 3/5200 loss 14.101646 loss_att 17.327591 loss_ctc 21.551176 loss_rnnt 9.072042 hw_loss 0.635839 lr 0.00090909 rank 0
2023-02-11 07:14:51,211 DEBUG TRAIN Batch 3/5200 loss 48.339630 loss_att 52.196426 loss_ctc 57.288651 loss_rnnt 43.234188 hw_loss 0.588915 lr 0.00090980 rank 3
2023-02-11 07:14:51,212 DEBUG TRAIN Batch 3/5200 loss 40.475800 loss_att 46.873020 loss_ctc 60.370300 loss_rnnt 35.159042 hw_loss 0.259634 lr 0.00090903 rank 1
2023-02-11 07:14:51,213 DEBUG TRAIN Batch 3/5200 loss 46.431194 loss_att 47.349964 loss_ctc 57.690258 loss_rnnt 41.971542 hw_loss 0.520255 lr 0.00091007 rank 7
2023-02-11 07:14:51,214 DEBUG TRAIN Batch 3/5200 loss 31.756363 loss_att 39.981236 loss_ctc 44.623589 loss_rnnt 26.051250 hw_loss 0.439595 lr 0.00090921 rank 2
2023-02-11 07:14:51,216 DEBUG TRAIN Batch 3/5200 loss 19.061050 loss_att 27.035854 loss_ctc 30.641460 loss_rnnt 14.563571 hw_loss 0.254712 lr 0.00091004 rank 4
2023-02-11 07:14:51,218 DEBUG TRAIN Batch 3/5200 loss 42.944065 loss_att 49.928570 loss_ctc 59.233582 loss_rnnt 36.323860 hw_loss 0.572132 lr 0.00090921 rank 5
2023-02-11 07:16:09,697 DEBUG TRAIN Batch 3/5300 loss 31.849642 loss_att 34.989929 loss_ctc 40.100502 loss_rnnt 27.286137 hw_loss 0.531625 lr 0.00090830 rank 3
2023-02-11 07:16:09,701 DEBUG TRAIN Batch 3/5300 loss 41.530708 loss_att 49.288589 loss_ctc 55.592133 loss_rnnt 34.456562 hw_loss 0.683946 lr 0.00090771 rank 5
2023-02-11 07:16:09,701 DEBUG TRAIN Batch 3/5300 loss 16.901592 loss_att 25.238249 loss_ctc 35.503460 loss_rnnt 12.081019 hw_loss 0.126186 lr 0.00090759 rank 0
2023-02-11 07:16:09,701 DEBUG TRAIN Batch 3/5300 loss 47.452206 loss_att 53.147011 loss_ctc 75.927948 loss_rnnt 40.139782 hw_loss 0.445630 lr 0.00090753 rank 1
2023-02-11 07:16:09,702 DEBUG TRAIN Batch 3/5300 loss 31.394974 loss_att 39.451809 loss_ctc 61.786694 loss_rnnt 21.789490 hw_loss 0.739104 lr 0.00090854 rank 4
2023-02-11 07:16:09,705 DEBUG TRAIN Batch 3/5300 loss 27.590656 loss_att 31.439484 loss_ctc 34.775280 loss_rnnt 24.047737 hw_loss 0.340350 lr 0.00090771 rank 2
2023-02-11 07:16:09,705 DEBUG TRAIN Batch 3/5300 loss 27.869003 loss_att 32.169998 loss_ctc 48.734528 loss_rnnt 23.246223 hw_loss 0.183845 lr 0.00090857 rank 7
2023-02-11 07:16:09,707 DEBUG TRAIN Batch 3/5300 loss 17.984793 loss_att 26.531746 loss_ctc 31.254009 loss_rnnt 13.653675 hw_loss 0.159843 lr 0.00090827 rank 6
2023-02-11 07:17:26,710 DEBUG TRAIN Batch 3/5400 loss 36.447834 loss_att 43.697987 loss_ctc 51.094719 loss_rnnt 28.922150 hw_loss 0.773013 lr 0.00090610 rank 0
2023-02-11 07:17:26,710 DEBUG TRAIN Batch 3/5400 loss 26.472775 loss_att 32.998325 loss_ctc 35.922436 loss_rnnt 22.927580 hw_loss 0.183774 lr 0.00090677 rank 6
2023-02-11 07:17:26,712 DEBUG TRAIN Batch 3/5400 loss 31.283812 loss_att 37.892242 loss_ctc 51.381210 loss_rnnt 26.776215 hw_loss 0.094924 lr 0.00090622 rank 5
2023-02-11 07:17:26,714 DEBUG TRAIN Batch 3/5400 loss 30.943327 loss_att 35.230282 loss_ctc 50.486244 loss_rnnt 25.848743 hw_loss 0.305901 lr 0.00090604 rank 1
2023-02-11 07:17:26,715 DEBUG TRAIN Batch 3/5400 loss 32.590721 loss_att 41.147640 loss_ctc 50.401459 loss_rnnt 28.021927 hw_loss 0.090496 lr 0.00090680 rank 3
2023-02-11 07:17:26,716 DEBUG TRAIN Batch 3/5400 loss 16.093039 loss_att 20.876539 loss_ctc 22.680367 loss_rnnt 11.806203 hw_loss 0.459717 lr 0.00090704 rank 4
2023-02-11 07:17:26,716 DEBUG TRAIN Batch 3/5400 loss 25.865528 loss_att 32.546562 loss_ctc 38.947792 loss_rnnt 19.511969 hw_loss 0.613697 lr 0.00090707 rank 7
2023-02-11 07:17:26,717 DEBUG TRAIN Batch 3/5400 loss 47.395805 loss_att 50.971733 loss_ctc 66.243195 loss_rnnt 42.104820 hw_loss 0.386778 lr 0.00090622 rank 2
2023-02-11 07:18:41,666 DEBUG TRAIN Batch 3/5500 loss 20.972313 loss_att 24.461868 loss_ctc 25.315002 loss_rnnt 17.062840 hw_loss 0.493601 lr 0.00090531 rank 3
2023-02-11 07:18:41,671 DEBUG TRAIN Batch 3/5500 loss 26.452002 loss_att 31.662050 loss_ctc 39.666519 loss_rnnt 20.428558 hw_loss 0.603656 lr 0.00090456 rank 1
2023-02-11 07:18:41,671 DEBUG TRAIN Batch 3/5500 loss 34.003784 loss_att 41.068649 loss_ctc 44.550907 loss_rnnt 27.473516 hw_loss 0.695814 lr 0.00090528 rank 6
2023-02-11 07:18:41,672 DEBUG TRAIN Batch 3/5500 loss 44.676487 loss_att 42.694260 loss_ctc 52.386890 loss_rnnt 39.869781 hw_loss 0.782830 lr 0.00090558 rank 7
2023-02-11 07:18:41,674 DEBUG TRAIN Batch 3/5500 loss 23.882513 loss_att 34.054482 loss_ctc 43.910912 loss_rnnt 16.509239 hw_loss 0.500329 lr 0.00090473 rank 2
2023-02-11 07:18:41,674 DEBUG TRAIN Batch 3/5500 loss 22.434284 loss_att 23.155031 loss_ctc 29.983234 loss_rnnt 20.001099 hw_loss 0.240470 lr 0.00090462 rank 0
2023-02-11 07:18:41,675 DEBUG TRAIN Batch 3/5500 loss 39.297997 loss_att 44.046204 loss_ctc 48.842236 loss_rnnt 33.864944 hw_loss 0.602033 lr 0.00090473 rank 5
2023-02-11 07:18:41,676 DEBUG TRAIN Batch 3/5500 loss 19.878319 loss_att 24.528166 loss_ctc 30.724678 loss_rnnt 15.183380 hw_loss 0.434773 lr 0.00090555 rank 4
2023-02-11 07:19:57,199 DEBUG TRAIN Batch 3/5600 loss 28.609066 loss_att 33.032562 loss_ctc 45.346783 loss_rnnt 22.180836 hw_loss 0.620969 lr 0.00090407 rank 4
2023-02-11 07:19:57,202 DEBUG TRAIN Batch 3/5600 loss 28.412510 loss_att 30.874500 loss_ctc 37.583408 loss_rnnt 22.177986 hw_loss 0.847376 lr 0.00090314 rank 0
2023-02-11 07:19:57,205 DEBUG TRAIN Batch 3/5600 loss 24.925972 loss_att 25.392689 loss_ctc 40.625469 loss_rnnt 19.167166 hw_loss 0.669787 lr 0.00090308 rank 1
2023-02-11 07:19:57,205 DEBUG TRAIN Batch 3/5600 loss 33.952728 loss_att 38.743317 loss_ctc 47.753433 loss_rnnt 26.753548 hw_loss 0.825182 lr 0.00090326 rank 5
2023-02-11 07:19:57,207 DEBUG TRAIN Batch 3/5600 loss 45.810764 loss_att 50.771862 loss_ctc 72.490128 loss_rnnt 37.481342 hw_loss 0.708741 lr 0.00090383 rank 3
2023-02-11 07:19:57,207 DEBUG TRAIN Batch 3/5600 loss 40.278027 loss_att 48.312992 loss_ctc 56.509644 loss_rnnt 33.104996 hw_loss 0.637841 lr 0.00090410 rank 7
2023-02-11 07:19:57,209 DEBUG TRAIN Batch 3/5600 loss 19.952990 loss_att 20.299099 loss_ctc 20.903177 loss_rnnt 14.811424 hw_loss 0.927309 lr 0.00090326 rank 2
2023-02-11 07:19:57,245 DEBUG TRAIN Batch 3/5600 loss 33.238914 loss_att 34.422642 loss_ctc 48.389175 loss_rnnt 27.557621 hw_loss 0.642096 lr 0.00090380 rank 6
2023-02-11 07:21:17,219 DEBUG TRAIN Batch 3/5700 loss 34.253239 loss_att 37.406998 loss_ctc 43.178696 loss_rnnt 29.214575 hw_loss 0.603347 lr 0.00090259 rank 4
2023-02-11 07:21:17,219 DEBUG TRAIN Batch 3/5700 loss 16.420324 loss_att 18.076025 loss_ctc 23.310921 loss_rnnt 12.275580 hw_loss 0.542786 lr 0.00090236 rank 3
2023-02-11 07:21:17,219 DEBUG TRAIN Batch 3/5700 loss 31.191883 loss_att 40.681862 loss_ctc 49.152901 loss_rnnt 24.345963 hw_loss 0.478710 lr 0.00090179 rank 2
2023-02-11 07:21:17,221 DEBUG TRAIN Batch 3/5700 loss 28.986479 loss_att 35.005486 loss_ctc 42.689922 loss_rnnt 22.213327 hw_loss 0.701666 lr 0.00090179 rank 5
2023-02-11 07:21:17,221 DEBUG TRAIN Batch 3/5700 loss 31.136971 loss_att 29.764732 loss_ctc 41.985798 loss_rnnt 25.655407 hw_loss 0.808031 lr 0.00090167 rank 0
2023-02-11 07:21:17,222 DEBUG TRAIN Batch 3/5700 loss 39.442703 loss_att 36.252335 loss_ctc 53.450562 loss_rnnt 34.285275 hw_loss 0.736461 lr 0.00090262 rank 7
2023-02-11 07:21:17,223 DEBUG TRAIN Batch 3/5700 loss 22.117479 loss_att 18.178476 loss_ctc 24.681725 loss_rnnt 15.189562 hw_loss 1.382591 lr 0.00090161 rank 1
2023-02-11 07:21:17,263 DEBUG TRAIN Batch 3/5700 loss 19.712137 loss_att 24.238258 loss_ctc 25.064634 loss_rnnt 15.936017 hw_loss 0.404480 lr 0.00090233 rank 6
2023-02-11 07:22:34,696 DEBUG TRAIN Batch 3/5800 loss 40.333794 loss_att 42.630264 loss_ctc 54.766350 loss_rnnt 36.396767 hw_loss 0.291262 lr 0.00090015 rank 1
2023-02-11 07:22:34,702 DEBUG TRAIN Batch 3/5800 loss 31.294693 loss_att 33.666298 loss_ctc 41.306599 loss_rnnt 26.722281 hw_loss 0.518094 lr 0.00090032 rank 2
2023-02-11 07:22:34,702 DEBUG TRAIN Batch 3/5800 loss 34.571423 loss_att 42.265205 loss_ctc 52.195282 loss_rnnt 27.338591 hw_loss 0.627043 lr 0.00090089 rank 3
2023-02-11 07:22:34,702 DEBUG TRAIN Batch 3/5800 loss 39.602894 loss_att 50.094765 loss_ctc 65.706696 loss_rnnt 32.286125 hw_loss 0.325855 lr 0.00090113 rank 4
2023-02-11 07:22:34,704 DEBUG TRAIN Batch 3/5800 loss 35.901478 loss_att 40.005157 loss_ctc 54.441574 loss_rnnt 30.017416 hw_loss 0.485872 lr 0.00090021 rank 0
2023-02-11 07:22:34,707 DEBUG TRAIN Batch 3/5800 loss 13.889692 loss_att 16.081734 loss_ctc 19.432629 loss_rnnt 10.201658 hw_loss 0.470732 lr 0.00090086 rank 6
2023-02-11 07:22:34,707 DEBUG TRAIN Batch 3/5800 loss 19.978405 loss_att 16.179432 loss_ctc 22.227322 loss_rnnt 16.251169 hw_loss 0.785095 lr 0.00090032 rank 5
2023-02-11 07:22:34,709 DEBUG TRAIN Batch 3/5800 loss 28.979610 loss_att 36.252251 loss_ctc 45.971550 loss_rnnt 23.413260 hw_loss 0.346169 lr 0.00090116 rank 7
2023-02-11 07:23:51,297 DEBUG TRAIN Batch 3/5900 loss 19.265305 loss_att 23.489483 loss_ctc 29.705275 loss_rnnt 13.811850 hw_loss 0.603117 lr 0.00089943 rank 3
2023-02-11 07:23:51,298 DEBUG TRAIN Batch 3/5900 loss 38.005253 loss_att 46.366837 loss_ctc 51.560753 loss_rnnt 31.007111 hw_loss 0.659705 lr 0.00089875 rank 0
2023-02-11 07:23:51,299 DEBUG TRAIN Batch 3/5900 loss 21.577579 loss_att 25.842588 loss_ctc 34.202885 loss_rnnt 16.324188 hw_loss 0.509440 lr 0.00089970 rank 7
2023-02-11 07:23:51,300 DEBUG TRAIN Batch 3/5900 loss 47.027657 loss_att 54.635796 loss_ctc 73.814453 loss_rnnt 40.898674 hw_loss 0.194210 lr 0.00089887 rank 2
2023-02-11 07:23:51,300 DEBUG TRAIN Batch 3/5900 loss 52.456657 loss_att 55.105980 loss_ctc 74.201248 loss_rnnt 46.685043 hw_loss 0.439213 lr 0.00089967 rank 4
2023-02-11 07:23:51,304 DEBUG TRAIN Batch 3/5900 loss 46.587391 loss_att 48.778584 loss_ctc 55.487549 loss_rnnt 40.044865 hw_loss 0.922050 lr 0.00089941 rank 6
2023-02-11 07:23:51,304 DEBUG TRAIN Batch 3/5900 loss 17.512625 loss_att 21.964382 loss_ctc 27.906284 loss_rnnt 15.093764 hw_loss 0.026754 lr 0.00089887 rank 5
2023-02-11 07:23:51,307 DEBUG TRAIN Batch 3/5900 loss 12.022549 loss_att 18.827578 loss_ctc 16.946722 loss_rnnt 9.158582 hw_loss 0.158701 lr 0.00089869 rank 1
2023-02-11 07:25:09,761 DEBUG TRAIN Batch 3/6000 loss 37.262238 loss_att 41.538765 loss_ctc 49.746918 loss_rnnt 32.536736 hw_loss 0.413545 lr 0.00089824 rank 7
2023-02-11 07:25:09,762 DEBUG TRAIN Batch 3/6000 loss 32.054981 loss_att 33.088181 loss_ctc 46.677605 loss_rnnt 27.122417 hw_loss 0.520545 lr 0.00089742 rank 5
2023-02-11 07:25:09,761 DEBUG TRAIN Batch 3/6000 loss 14.032576 loss_att 18.064249 loss_ctc 20.777264 loss_rnnt 9.536636 hw_loss 0.523184 lr 0.00089795 rank 6
2023-02-11 07:25:09,762 DEBUG TRAIN Batch 3/6000 loss 22.962904 loss_att 26.700405 loss_ctc 33.078156 loss_rnnt 19.376394 hw_loss 0.279433 lr 0.00089742 rank 2
2023-02-11 07:25:09,763 DEBUG TRAIN Batch 3/6000 loss 23.553413 loss_att 23.315483 loss_ctc 30.294949 loss_rnnt 18.403748 hw_loss 0.805946 lr 0.00089798 rank 3
2023-02-11 07:25:09,766 DEBUG TRAIN Batch 3/6000 loss 28.842323 loss_att 35.689499 loss_ctc 45.163216 loss_rnnt 23.319860 hw_loss 0.370670 lr 0.00089730 rank 0
2023-02-11 07:25:09,766 DEBUG TRAIN Batch 3/6000 loss 19.902208 loss_att 20.852943 loss_ctc 27.224310 loss_rnnt 15.406256 hw_loss 0.624286 lr 0.00089725 rank 1
2023-02-11 07:25:09,767 DEBUG TRAIN Batch 3/6000 loss 41.632721 loss_att 47.070023 loss_ctc 58.135769 loss_rnnt 33.107426 hw_loss 0.982017 lr 0.00089821 rank 4
2023-02-11 07:26:27,440 DEBUG TRAIN Batch 3/6100 loss 25.788603 loss_att 27.593132 loss_ctc 35.240379 loss_rnnt 22.509489 hw_loss 0.310870 lr 0.00089651 rank 6
2023-02-11 07:26:27,441 DEBUG TRAIN Batch 3/6100 loss 23.521358 loss_att 23.249132 loss_ctc 30.656483 loss_rnnt 18.040190 hw_loss 0.859549 lr 0.00089680 rank 7
2023-02-11 07:26:27,442 DEBUG TRAIN Batch 3/6100 loss 33.777702 loss_att 35.330872 loss_ctc 45.649010 loss_rnnt 28.096279 hw_loss 0.710240 lr 0.00089586 rank 0
2023-02-11 07:26:27,444 DEBUG TRAIN Batch 3/6100 loss 23.417759 loss_att 31.078239 loss_ctc 37.332016 loss_rnnt 18.102560 hw_loss 0.361476 lr 0.00089598 rank 2
2023-02-11 07:26:27,444 DEBUG TRAIN Batch 3/6100 loss 23.209965 loss_att 28.268353 loss_ctc 34.689686 loss_rnnt 20.192707 hw_loss 0.089053 lr 0.00089654 rank 3
2023-02-11 07:26:27,447 DEBUG TRAIN Batch 3/6100 loss 35.811199 loss_att 36.348560 loss_ctc 47.227646 loss_rnnt 29.915396 hw_loss 0.799901 lr 0.00089677 rank 4
2023-02-11 07:26:27,448 DEBUG TRAIN Batch 3/6100 loss 42.240566 loss_att 43.782055 loss_ctc 62.456871 loss_rnnt 35.926949 hw_loss 0.620589 lr 0.00089598 rank 5
2023-02-11 07:26:27,448 DEBUG TRAIN Batch 3/6100 loss 18.080517 loss_att 21.893452 loss_ctc 22.972244 loss_rnnt 13.367548 hw_loss 0.618403 lr 0.00089580 rank 1
2023-02-11 07:27:44,151 DEBUG TRAIN Batch 3/6200 loss 35.413906 loss_att 37.428925 loss_ctc 49.430168 loss_rnnt 30.913359 hw_loss 0.417883 lr 0.00089507 rank 6
2023-02-11 07:27:44,155 DEBUG TRAIN Batch 3/6200 loss 30.273731 loss_att 31.050098 loss_ctc 43.871410 loss_rnnt 26.774170 hw_loss 0.287112 lr 0.00089510 rank 3
2023-02-11 07:27:44,158 DEBUG TRAIN Batch 3/6200 loss 16.973122 loss_att 19.028385 loss_ctc 20.160683 loss_rnnt 12.488206 hw_loss 0.684160 lr 0.00089443 rank 0
2023-02-11 07:27:44,159 DEBUG TRAIN Batch 3/6200 loss 23.950945 loss_att 27.515022 loss_ctc 37.709572 loss_rnnt 19.140915 hw_loss 0.424261 lr 0.00089454 rank 5
2023-02-11 07:27:44,161 DEBUG TRAIN Batch 3/6200 loss 29.901428 loss_att 35.533554 loss_ctc 52.649212 loss_rnnt 21.366400 hw_loss 0.820418 lr 0.00089437 rank 1
2023-02-11 07:27:44,163 DEBUG TRAIN Batch 3/6200 loss 18.915539 loss_att 24.122063 loss_ctc 25.051987 loss_rnnt 13.314260 hw_loss 0.701584 lr 0.00089536 rank 7
2023-02-11 07:27:44,167 DEBUG TRAIN Batch 3/6200 loss 21.647228 loss_att 24.980473 loss_ctc 34.445370 loss_rnnt 16.265228 hw_loss 0.564175 lr 0.00089454 rank 2
2023-02-11 07:27:44,202 DEBUG TRAIN Batch 3/6200 loss 45.191132 loss_att 53.453568 loss_ctc 72.402367 loss_rnnt 37.231476 hw_loss 0.502312 lr 0.00089533 rank 4
2023-02-11 07:29:00,930 DEBUG TRAIN Batch 3/6300 loss 24.293905 loss_att 27.496506 loss_ctc 30.645161 loss_rnnt 17.905384 hw_loss 0.918969 lr 0.00089367 rank 3
2023-02-11 07:29:00,930 DEBUG TRAIN Batch 3/6300 loss 41.897732 loss_att 46.366264 loss_ctc 65.259422 loss_rnnt 35.071369 hw_loss 0.528330 lr 0.00089311 rank 5
2023-02-11 07:29:00,933 DEBUG TRAIN Batch 3/6300 loss 34.698761 loss_att 39.275879 loss_ctc 53.273224 loss_rnnt 28.004869 hw_loss 0.619101 lr 0.00089364 rank 6
2023-02-11 07:29:00,934 DEBUG TRAIN Batch 3/6300 loss 23.228777 loss_att 24.509071 loss_ctc 32.472954 loss_rnnt 18.985470 hw_loss 0.516505 lr 0.00089311 rank 2
2023-02-11 07:29:00,933 DEBUG TRAIN Batch 3/6300 loss 28.524948 loss_att 32.843609 loss_ctc 42.138012 loss_rnnt 21.856873 hw_loss 0.747988 lr 0.00089300 rank 0
2023-02-11 07:29:00,936 DEBUG TRAIN Batch 3/6300 loss 34.595715 loss_att 37.335293 loss_ctc 48.470837 loss_rnnt 26.694281 hw_loss 1.031907 lr 0.00089294 rank 1
2023-02-11 07:29:00,937 DEBUG TRAIN Batch 3/6300 loss 19.739006 loss_att 23.437817 loss_ctc 32.388496 loss_rnnt 15.646753 hw_loss 0.312355 lr 0.00089393 rank 7
2023-02-11 07:29:00,946 DEBUG TRAIN Batch 3/6300 loss 17.826509 loss_att 23.688030 loss_ctc 36.236870 loss_rnnt 12.610655 hw_loss 0.297907 lr 0.00089390 rank 4
2023-02-11 07:30:20,221 DEBUG TRAIN Batch 3/6400 loss 26.382275 loss_att 21.089794 loss_ctc 28.769384 loss_rnnt 19.210585 hw_loss 1.483482 lr 0.00089158 rank 0
2023-02-11 07:30:20,222 DEBUG TRAIN Batch 3/6400 loss 15.872738 loss_att 14.268656 loss_ctc 15.998947 loss_rnnt 9.238317 hw_loss 1.300951 lr 0.00089250 rank 7
2023-02-11 07:30:20,223 DEBUG TRAIN Batch 3/6400 loss 20.112055 loss_att 26.796253 loss_ctc 37.493660 loss_rnnt 13.530055 hw_loss 0.548927 lr 0.00089225 rank 3
2023-02-11 07:30:20,225 DEBUG TRAIN Batch 3/6400 loss 18.243616 loss_att 20.713753 loss_ctc 25.522955 loss_rnnt 13.810934 hw_loss 0.556514 lr 0.00089169 rank 5
2023-02-11 07:30:20,227 DEBUG TRAIN Batch 3/6400 loss 13.904571 loss_att 10.498255 loss_ctc 15.834063 loss_rnnt 9.054327 hw_loss 0.988920 lr 0.00089152 rank 1
2023-02-11 07:30:20,230 DEBUG TRAIN Batch 3/6400 loss 25.773146 loss_att 27.289660 loss_ctc 34.619392 loss_rnnt 20.702694 hw_loss 0.672684 lr 0.00089247 rank 4
2023-02-11 07:30:20,231 DEBUG TRAIN Batch 3/6400 loss 27.323389 loss_att 30.008463 loss_ctc 40.193611 loss_rnnt 21.395107 hw_loss 0.689107 lr 0.00089222 rank 6
2023-02-11 07:30:20,232 DEBUG TRAIN Batch 3/6400 loss 13.614684 loss_att 17.318222 loss_ctc 18.059309 loss_rnnt 8.958941 hw_loss 0.622954 lr 0.00089169 rank 2
2023-02-11 07:31:36,947 DEBUG TRAIN Batch 3/6500 loss 20.606144 loss_att 23.815908 loss_ctc 32.546165 loss_rnnt 13.663181 hw_loss 0.882939 lr 0.00089011 rank 1
2023-02-11 07:31:36,950 DEBUG TRAIN Batch 3/6500 loss 32.503616 loss_att 36.062813 loss_ctc 50.701614 loss_rnnt 26.815929 hw_loss 0.478022 lr 0.00089083 rank 3
2023-02-11 07:31:36,952 DEBUG TRAIN Batch 3/6500 loss 35.669853 loss_att 39.893845 loss_ctc 51.075390 loss_rnnt 29.846598 hw_loss 0.548321 lr 0.00089028 rank 2
2023-02-11 07:31:36,953 DEBUG TRAIN Batch 3/6500 loss 40.022263 loss_att 47.266403 loss_ctc 54.293255 loss_rnnt 33.595520 hw_loss 0.576584 lr 0.00089108 rank 7
2023-02-11 07:31:36,954 DEBUG TRAIN Batch 3/6500 loss 35.408634 loss_att 43.687515 loss_ctc 44.557644 loss_rnnt 27.361889 hw_loss 0.969582 lr 0.00089016 rank 0
2023-02-11 07:31:36,955 DEBUG TRAIN Batch 3/6500 loss 27.725124 loss_att 30.910172 loss_ctc 38.231571 loss_rnnt 22.568787 hw_loss 0.584713 lr 0.00089105 rank 4
2023-02-11 07:31:36,957 DEBUG TRAIN Batch 3/6500 loss 34.312969 loss_att 40.782825 loss_ctc 51.088146 loss_rnnt 29.001286 hw_loss 0.333942 lr 0.00089028 rank 5
2023-02-11 07:31:36,958 DEBUG TRAIN Batch 3/6500 loss 31.446520 loss_att 34.138245 loss_ctc 43.394104 loss_rnnt 27.494675 hw_loss 0.341342 lr 0.00089080 rank 6
2023-02-11 07:32:53,361 DEBUG TRAIN Batch 3/6600 loss 34.772572 loss_att 40.622894 loss_ctc 54.291698 loss_rnnt 27.346977 hw_loss 0.684934 lr 0.00088942 rank 3
2023-02-11 07:32:53,362 DEBUG TRAIN Batch 3/6600 loss 32.258789 loss_att 35.949242 loss_ctc 38.338554 loss_rnnt 26.054373 hw_loss 0.872942 lr 0.00088876 rank 0
2023-02-11 07:32:53,363 DEBUG TRAIN Batch 3/6600 loss 24.203379 loss_att 28.183399 loss_ctc 41.241566 loss_rnnt 17.477171 hw_loss 0.685958 lr 0.00088967 rank 7
2023-02-11 07:32:53,364 DEBUG TRAIN Batch 3/6600 loss 16.719624 loss_att 27.955776 loss_ctc 30.407293 loss_rnnt 9.754626 hw_loss 0.542389 lr 0.00088939 rank 6
2023-02-11 07:32:53,370 DEBUG TRAIN Batch 3/6600 loss 32.116940 loss_att 34.340927 loss_ctc 47.832802 loss_rnnt 26.686327 hw_loss 0.541944 lr 0.00088887 rank 2
2023-02-11 07:32:53,371 DEBUG TRAIN Batch 3/6600 loss 21.172615 loss_att 26.945915 loss_ctc 29.641201 loss_rnnt 14.935080 hw_loss 0.741324 lr 0.00088870 rank 1
2023-02-11 07:32:53,371 DEBUG TRAIN Batch 3/6600 loss 43.526264 loss_att 42.991688 loss_ctc 60.043285 loss_rnnt 39.490799 hw_loss 0.363770 lr 0.00088887 rank 5
2023-02-11 07:32:53,375 DEBUG TRAIN Batch 3/6600 loss 27.630119 loss_att 35.730202 loss_ctc 44.057549 loss_rnnt 21.498959 hw_loss 0.435154 lr 0.00088964 rank 4
2023-02-11 07:34:10,627 DEBUG TRAIN Batch 3/6700 loss 22.076832 loss_att 25.885798 loss_ctc 31.872444 loss_rnnt 17.635704 hw_loss 0.444985 lr 0.00088747 rank 2
2023-02-11 07:34:10,628 DEBUG TRAIN Batch 3/6700 loss 34.185677 loss_att 41.254021 loss_ctc 52.845184 loss_rnnt 27.427071 hw_loss 0.535688 lr 0.00088799 rank 6
2023-02-11 07:34:10,629 DEBUG TRAIN Batch 3/6700 loss 30.462162 loss_att 37.189396 loss_ctc 38.715034 loss_rnnt 24.371691 hw_loss 0.683370 lr 0.00088747 rank 5
2023-02-11 07:34:10,631 DEBUG TRAIN Batch 3/6700 loss 25.190893 loss_att 33.073097 loss_ctc 37.082165 loss_rnnt 19.705568 hw_loss 0.435634 lr 0.00088736 rank 0
2023-02-11 07:34:10,634 DEBUG TRAIN Batch 3/6700 loss 49.048035 loss_att 49.548332 loss_ctc 66.286995 loss_rnnt 43.450882 hw_loss 0.599731 lr 0.00088801 rank 3
2023-02-11 07:34:10,637 DEBUG TRAIN Batch 3/6700 loss 39.867107 loss_att 50.492912 loss_ctc 65.629730 loss_rnnt 31.102806 hw_loss 0.600773 lr 0.00088730 rank 1
2023-02-11 07:34:10,639 DEBUG TRAIN Batch 3/6700 loss 33.447807 loss_att 37.795021 loss_ctc 42.026829 loss_rnnt 30.412231 hw_loss 0.191674 lr 0.00088827 rank 7
2023-02-11 07:34:10,677 DEBUG TRAIN Batch 3/6700 loss 25.767330 loss_att 29.276878 loss_ctc 40.543282 loss_rnnt 20.017889 hw_loss 0.577013 lr 0.00088824 rank 4
2023-02-11 07:35:28,348 DEBUG TRAIN Batch 3/6800 loss 26.406216 loss_att 29.868876 loss_ctc 32.691948 loss_rnnt 21.519253 hw_loss 0.629313 lr 0.00088662 rank 3
2023-02-11 07:35:28,348 DEBUG TRAIN Batch 3/6800 loss 37.950550 loss_att 47.106819 loss_ctc 66.240479 loss_rnnt 31.191006 hw_loss 0.216806 lr 0.00088687 rank 7
2023-02-11 07:35:28,348 DEBUG TRAIN Batch 3/6800 loss 25.836578 loss_att 24.530148 loss_ctc 37.223099 loss_rnnt 21.841930 hw_loss 0.513325 lr 0.00088596 rank 0
2023-02-11 07:35:28,349 DEBUG TRAIN Batch 3/6800 loss 30.022713 loss_att 34.564728 loss_ctc 48.679298 loss_rnnt 25.204451 hw_loss 0.266684 lr 0.00088607 rank 5
2023-02-11 07:35:28,351 DEBUG TRAIN Batch 3/6800 loss 35.058025 loss_att 43.840057 loss_ctc 50.828682 loss_rnnt 28.369604 hw_loss 0.530486 lr 0.00088684 rank 4
2023-02-11 07:35:28,353 DEBUG TRAIN Batch 3/6800 loss 39.898708 loss_att 49.053661 loss_ctc 52.454170 loss_rnnt 32.639252 hw_loss 0.703951 lr 0.00088591 rank 1
2023-02-11 07:35:28,357 DEBUG TRAIN Batch 3/6800 loss 50.046726 loss_att 55.052616 loss_ctc 68.633316 loss_rnnt 44.950058 hw_loss 0.303239 lr 0.00088659 rank 6
2023-02-11 07:35:28,392 DEBUG TRAIN Batch 3/6800 loss 47.903980 loss_att 49.515369 loss_ctc 59.321327 loss_rnnt 42.296833 hw_loss 0.705479 lr 0.00088607 rank 2
2023-02-11 07:36:44,352 DEBUG TRAIN Batch 3/6900 loss 30.802931 loss_att 35.370853 loss_ctc 51.109718 loss_rnnt 26.531525 hw_loss 0.121922 lr 0.00088520 rank 6
2023-02-11 07:36:44,353 DEBUG TRAIN Batch 3/6900 loss 26.919533 loss_att 36.302414 loss_ctc 36.620293 loss_rnnt 22.621098 hw_loss 0.211579 lr 0.00088469 rank 5
2023-02-11 07:36:44,353 DEBUG TRAIN Batch 3/6900 loss 31.093292 loss_att 32.583397 loss_ctc 38.486488 loss_rnnt 27.122126 hw_loss 0.503885 lr 0.00088523 rank 3
2023-02-11 07:36:44,358 DEBUG TRAIN Batch 3/6900 loss 16.221592 loss_att 13.737310 loss_ctc 18.241606 loss_rnnt 10.814111 hw_loss 1.056563 lr 0.00088469 rank 2
2023-02-11 07:36:44,359 DEBUG TRAIN Batch 3/6900 loss 27.618996 loss_att 29.565128 loss_ctc 42.965042 loss_rnnt 23.402023 hw_loss 0.334051 lr 0.00088545 rank 4
2023-02-11 07:36:44,360 DEBUG TRAIN Batch 3/6900 loss 27.851873 loss_att 30.085121 loss_ctc 32.973549 loss_rnnt 24.438843 hw_loss 0.428154 lr 0.00088457 rank 0
2023-02-11 07:36:44,360 DEBUG TRAIN Batch 3/6900 loss 27.880342 loss_att 32.411831 loss_ctc 41.518108 loss_rnnt 22.834486 hw_loss 0.435223 lr 0.00088548 rank 7
2023-02-11 07:36:44,405 DEBUG TRAIN Batch 3/6900 loss 29.082659 loss_att 34.146259 loss_ctc 44.459530 loss_rnnt 23.165390 hw_loss 0.535181 lr 0.00088452 rank 1
2023-02-11 07:38:01,491 DEBUG TRAIN Batch 3/7000 loss 19.672848 loss_att 24.402494 loss_ctc 25.566635 loss_rnnt 14.846001 hw_loss 0.580328 lr 0.00088319 rank 0
2023-02-11 07:38:01,493 DEBUG TRAIN Batch 3/7000 loss 15.160661 loss_att 19.311831 loss_ctc 20.783253 loss_rnnt 11.111473 hw_loss 0.462989 lr 0.00088330 rank 2
2023-02-11 07:38:01,493 DEBUG TRAIN Batch 3/7000 loss 23.850243 loss_att 25.017227 loss_ctc 28.813791 loss_rnnt 18.041927 hw_loss 0.921209 lr 0.00088409 rank 7
2023-02-11 07:38:01,496 DEBUG TRAIN Batch 3/7000 loss 20.825516 loss_att 20.272602 loss_ctc 26.708279 loss_rnnt 14.569734 hw_loss 1.046624 lr 0.00088314 rank 1
2023-02-11 07:38:01,496 DEBUG TRAIN Batch 3/7000 loss 17.181673 loss_att 19.023230 loss_ctc 25.507299 loss_rnnt 12.347838 hw_loss 0.629145 lr 0.00088381 rank 6
2023-02-11 07:38:01,498 DEBUG TRAIN Batch 3/7000 loss 16.318871 loss_att 14.547667 loss_ctc 17.842506 loss_rnnt 11.167557 hw_loss 0.994200 lr 0.00088384 rank 3
2023-02-11 07:38:01,500 DEBUG TRAIN Batch 3/7000 loss 33.963810 loss_att 35.853691 loss_ctc 50.621349 loss_rnnt 28.956039 hw_loss 0.451648 lr 0.00088330 rank 5
2023-02-11 07:38:01,499 DEBUG TRAIN Batch 3/7000 loss 31.512028 loss_att 31.961914 loss_ctc 34.499554 loss_rnnt 26.290079 hw_loss 0.887556 lr 0.00088406 rank 4
2023-02-11 07:39:20,717 DEBUG TRAIN Batch 3/7100 loss 31.181133 loss_att 42.244095 loss_ctc 54.968147 loss_rnnt 23.481352 hw_loss 0.434173 lr 0.00088271 rank 7
2023-02-11 07:39:20,717 DEBUG TRAIN Batch 3/7100 loss 21.126743 loss_att 26.358669 loss_ctc 40.096786 loss_rnnt 17.002739 hw_loss 0.102802 lr 0.00088246 rank 3
2023-02-11 07:39:20,720 DEBUG TRAIN Batch 3/7100 loss 18.986904 loss_att 19.961777 loss_ctc 20.804123 loss_rnnt 17.946022 hw_loss 0.113177 lr 0.00088193 rank 5
2023-02-11 07:39:20,723 DEBUG TRAIN Batch 3/7100 loss 20.242668 loss_att 25.069542 loss_ctc 29.924734 loss_rnnt 17.664127 hw_loss 0.060417 lr 0.00088182 rank 0
2023-02-11 07:39:20,726 DEBUG TRAIN Batch 3/7100 loss 11.800595 loss_att 17.322214 loss_ctc 22.621237 loss_rnnt 8.108412 hw_loss 0.214708 lr 0.00088193 rank 2
2023-02-11 07:39:20,726 DEBUG TRAIN Batch 3/7100 loss 31.482943 loss_att 40.942451 loss_ctc 43.123779 loss_rnnt 25.287075 hw_loss 0.515972 lr 0.00088244 rank 6
2023-02-11 07:39:20,727 DEBUG TRAIN Batch 3/7100 loss 29.503132 loss_att 43.466694 loss_ctc 42.951637 loss_rnnt 23.955490 hw_loss 0.180336 lr 0.00088268 rank 4
2023-02-11 07:39:20,740 DEBUG TRAIN Batch 3/7100 loss 36.417477 loss_att 43.656853 loss_ctc 55.704830 loss_rnnt 30.869551 hw_loss 0.286576 lr 0.00088176 rank 1
2023-02-11 07:40:38,204 DEBUG TRAIN Batch 3/7200 loss 20.346277 loss_att 27.906961 loss_ctc 30.045872 loss_rnnt 15.931892 hw_loss 0.301681 lr 0.00088134 rank 7
2023-02-11 07:40:38,206 DEBUG TRAIN Batch 3/7200 loss 30.720566 loss_att 32.064850 loss_ctc 40.374928 loss_rnnt 25.606419 hw_loss 0.667133 lr 0.00088040 rank 1
2023-02-11 07:40:38,206 DEBUG TRAIN Batch 3/7200 loss 24.893978 loss_att 28.446253 loss_ctc 44.496502 loss_rnnt 20.293121 hw_loss 0.239387 lr 0.00088109 rank 3
2023-02-11 07:40:38,210 DEBUG TRAIN Batch 3/7200 loss 28.936781 loss_att 30.289883 loss_ctc 41.419079 loss_rnnt 23.495564 hw_loss 0.657429 lr 0.00088045 rank 0
2023-02-11 07:40:38,210 DEBUG TRAIN Batch 3/7200 loss 23.830585 loss_att 32.896782 loss_ctc 41.072495 loss_rnnt 17.763763 hw_loss 0.366499 lr 0.00088056 rank 2
2023-02-11 07:40:38,214 DEBUG TRAIN Batch 3/7200 loss 50.774265 loss_att 55.562637 loss_ctc 70.902817 loss_rnnt 44.940308 hw_loss 0.411089 lr 0.00088056 rank 5
2023-02-11 07:40:38,218 DEBUG TRAIN Batch 3/7200 loss 29.799334 loss_att 37.740360 loss_ctc 46.881054 loss_rnnt 24.645071 hw_loss 0.241592 lr 0.00088107 rank 6
2023-02-11 07:40:38,263 DEBUG TRAIN Batch 3/7200 loss 40.190918 loss_att 44.706982 loss_ctc 52.748024 loss_rnnt 36.711388 hw_loss 0.169132 lr 0.00088131 rank 4
2023-02-11 07:41:54,732 DEBUG TRAIN Batch 3/7300 loss 33.170647 loss_att 38.116764 loss_ctc 54.447235 loss_rnnt 27.679142 hw_loss 0.312263 lr 0.00087909 rank 0
2023-02-11 07:41:54,737 DEBUG TRAIN Batch 3/7300 loss 40.136738 loss_att 48.307892 loss_ctc 54.880417 loss_rnnt 33.879543 hw_loss 0.498213 lr 0.00087997 rank 7
2023-02-11 07:41:54,738 DEBUG TRAIN Batch 3/7300 loss 59.034008 loss_att 65.293190 loss_ctc 91.012733 loss_rnnt 50.291225 hw_loss 0.605085 lr 0.00087920 rank 2
2023-02-11 07:41:54,739 DEBUG TRAIN Batch 3/7300 loss 35.406807 loss_att 37.199398 loss_ctc 50.980705 loss_rnnt 30.391949 hw_loss 0.483717 lr 0.00087920 rank 5
2023-02-11 07:41:54,742 DEBUG TRAIN Batch 3/7300 loss 19.898701 loss_att 28.503834 loss_ctc 20.563393 loss_rnnt 13.036749 hw_loss 0.947306 lr 0.00087973 rank 3
2023-02-11 07:41:54,746 DEBUG TRAIN Batch 3/7300 loss 15.642050 loss_att 24.457024 loss_ctc 31.433289 loss_rnnt 10.951068 hw_loss 0.154217 lr 0.00087970 rank 6
2023-02-11 07:41:54,747 DEBUG TRAIN Batch 3/7300 loss 26.327276 loss_att 35.005173 loss_ctc 39.098503 loss_rnnt 20.387123 hw_loss 0.469076 lr 0.00087903 rank 1
2023-02-11 07:41:54,747 DEBUG TRAIN Batch 3/7300 loss 28.339359 loss_att 34.053261 loss_ctc 39.377121 loss_rnnt 23.110691 hw_loss 0.490160 lr 0.00087995 rank 4
2023-02-11 07:43:10,643 DEBUG TRAIN Batch 3/7400 loss 14.308903 loss_att 20.543530 loss_ctc 26.543816 loss_rnnt 10.549011 hw_loss 0.165308 lr 0.00087861 rank 7
2023-02-11 07:43:10,642 DEBUG TRAIN Batch 3/7400 loss 42.517025 loss_att 46.320011 loss_ctc 58.792480 loss_rnnt 35.905022 hw_loss 0.690252 lr 0.00087834 rank 6
2023-02-11 07:43:10,643 DEBUG TRAIN Batch 3/7400 loss 32.044487 loss_att 43.007919 loss_ctc 44.647690 loss_rnnt 25.830509 hw_loss 0.438912 lr 0.00087784 rank 5
2023-02-11 07:43:10,645 DEBUG TRAIN Batch 3/7400 loss 25.514425 loss_att 30.319609 loss_ctc 38.982231 loss_rnnt 21.079235 hw_loss 0.314709 lr 0.00087768 rank 1
2023-02-11 07:43:10,647 DEBUG TRAIN Batch 3/7400 loss 31.892769 loss_att 37.568863 loss_ctc 49.127579 loss_rnnt 26.288992 hw_loss 0.406985 lr 0.00087859 rank 4
2023-02-11 07:43:10,648 DEBUG TRAIN Batch 3/7400 loss 28.714890 loss_att 31.275642 loss_ctc 36.344917 loss_rnnt 21.764484 hw_loss 1.016422 lr 0.00087784 rank 2
2023-02-11 07:43:10,651 DEBUG TRAIN Batch 3/7400 loss 24.703173 loss_att 29.237272 loss_ctc 34.715622 loss_rnnt 20.686710 hw_loss 0.332747 lr 0.00087837 rank 3
2023-02-11 07:43:10,655 DEBUG TRAIN Batch 3/7400 loss 24.314413 loss_att 30.579231 loss_ctc 33.466927 loss_rnnt 18.398378 hw_loss 0.645513 lr 0.00087773 rank 0
2023-02-11 07:44:28,272 DEBUG TRAIN Batch 3/7500 loss 24.074358 loss_att 27.232466 loss_ctc 35.200233 loss_rnnt 18.426846 hw_loss 0.662333 lr 0.00087726 rank 7
2023-02-11 07:44:28,273 DEBUG TRAIN Batch 3/7500 loss 20.579065 loss_att 20.292772 loss_ctc 27.526876 loss_rnnt 15.432033 hw_loss 0.802109 lr 0.00087649 rank 2
2023-02-11 07:44:28,273 DEBUG TRAIN Batch 3/7500 loss 40.775734 loss_att 44.846313 loss_ctc 56.996113 loss_rnnt 35.928005 hw_loss 0.350793 lr 0.00087638 rank 0
2023-02-11 07:44:28,277 DEBUG TRAIN Batch 3/7500 loss 28.083229 loss_att 27.003159 loss_ctc 32.950333 loss_rnnt 23.114531 hw_loss 0.850456 lr 0.00087702 rank 3
2023-02-11 07:44:28,278 DEBUG TRAIN Batch 3/7500 loss 23.744431 loss_att 26.450832 loss_ctc 36.850060 loss_rnnt 18.969774 hw_loss 0.466118 lr 0.00087633 rank 1
2023-02-11 07:44:28,279 DEBUG TRAIN Batch 3/7500 loss 25.047455 loss_att 27.475784 loss_ctc 36.013718 loss_rnnt 21.746998 hw_loss 0.253617 lr 0.00087699 rank 6
2023-02-11 07:44:28,287 DEBUG TRAIN Batch 3/7500 loss 25.718340 loss_att 32.289612 loss_ctc 38.016975 loss_rnnt 20.337730 hw_loss 0.454976 lr 0.00087649 rank 5
2023-02-11 07:44:28,287 DEBUG TRAIN Batch 3/7500 loss 34.435139 loss_att 38.374508 loss_ctc 48.987999 loss_rnnt 28.340599 hw_loss 0.631178 lr 0.00087723 rank 4
2023-02-11 07:45:44,981 DEBUG TRAIN Batch 3/7600 loss 28.354046 loss_att 30.129959 loss_ctc 34.826572 loss_rnnt 25.058945 hw_loss 0.389422 lr 0.00087504 rank 0
2023-02-11 07:45:44,986 DEBUG TRAIN Batch 3/7600 loss 27.603065 loss_att 24.240425 loss_ctc 33.303253 loss_rnnt 23.585892 hw_loss 0.736814 lr 0.00087567 rank 3
2023-02-11 07:45:44,986 DEBUG TRAIN Batch 3/7600 loss 24.331766 loss_att 27.433222 loss_ctc 29.751877 loss_rnnt 19.253048 hw_loss 0.700452 lr 0.00087591 rank 7
2023-02-11 07:45:44,988 DEBUG TRAIN Batch 3/7600 loss 31.873299 loss_att 35.974792 loss_ctc 48.521908 loss_rnnt 26.032537 hw_loss 0.525121 lr 0.00087499 rank 1
2023-02-11 07:45:44,990 DEBUG TRAIN Batch 3/7600 loss 32.571823 loss_att 32.260281 loss_ctc 41.041626 loss_rnnt 27.446629 hw_loss 0.760911 lr 0.00087564 rank 6
2023-02-11 07:45:44,991 DEBUG TRAIN Batch 3/7600 loss 25.619358 loss_att 27.554893 loss_ctc 30.803446 loss_rnnt 20.102537 hw_loss 0.832219 lr 0.00087589 rank 4
2023-02-11 07:45:44,992 DEBUG TRAIN Batch 3/7600 loss 17.750805 loss_att 20.183861 loss_ctc 29.543587 loss_rnnt 13.138903 hw_loss 0.478672 lr 0.00087515 rank 5
2023-02-11 07:45:45,038 DEBUG TRAIN Batch 3/7600 loss 20.034252 loss_att 31.967915 loss_ctc 35.180130 loss_rnnt 14.139643 hw_loss 0.279080 lr 0.00087515 rank 2
2023-02-11 07:47:01,682 DEBUG TRAIN Batch 3/7700 loss 42.094830 loss_att 49.645554 loss_ctc 63.628197 loss_rnnt 36.527267 hw_loss 0.222431 lr 0.00087370 rank 0
2023-02-11 07:47:01,682 DEBUG TRAIN Batch 3/7700 loss 14.982631 loss_att 17.228859 loss_ctc 21.067635 loss_rnnt 9.251409 hw_loss 0.838245 lr 0.00087381 rank 5
2023-02-11 07:47:01,683 DEBUG TRAIN Batch 3/7700 loss 28.929024 loss_att 33.968307 loss_ctc 44.233562 loss_rnnt 23.507530 hw_loss 0.444943 lr 0.00087433 rank 3
2023-02-11 07:47:01,684 DEBUG TRAIN Batch 3/7700 loss 27.552504 loss_att 23.563068 loss_ctc 30.751699 loss_rnnt 23.389832 hw_loss 0.850125 lr 0.00087430 rank 6
2023-02-11 07:47:01,685 DEBUG TRAIN Batch 3/7700 loss 17.884308 loss_att 12.631003 loss_ctc 14.809351 loss_rnnt 12.920216 hw_loss 1.204640 lr 0.00087457 rank 7
2023-02-11 07:47:01,684 DEBUG TRAIN Batch 3/7700 loss 35.017097 loss_att 37.503468 loss_ctc 51.892311 loss_rnnt 30.853783 hw_loss 0.265502 lr 0.00087365 rank 1
2023-02-11 07:47:01,686 DEBUG TRAIN Batch 3/7700 loss 33.357666 loss_att 38.370834 loss_ctc 45.642731 loss_rnnt 29.539963 hw_loss 0.220699 lr 0.00087381 rank 2
2023-02-11 07:47:01,689 DEBUG TRAIN Batch 3/7700 loss 30.538008 loss_att 34.707741 loss_ctc 43.327660 loss_rnnt 26.172340 hw_loss 0.342456 lr 0.00087455 rank 4
2023-02-11 07:48:19,938 DEBUG TRAIN Batch 3/7800 loss 50.727215 loss_att 56.956310 loss_ctc 88.973351 loss_rnnt 42.515667 hw_loss 0.349921 lr 0.00087237 rank 0
2023-02-11 07:48:19,939 DEBUG TRAIN Batch 3/7800 loss 27.127636 loss_att 32.994545 loss_ctc 36.160637 loss_rnnt 24.184673 hw_loss 0.105972 lr 0.00087297 rank 6
2023-02-11 07:48:19,940 DEBUG TRAIN Batch 3/7800 loss 21.861288 loss_att 25.913376 loss_ctc 35.637856 loss_rnnt 16.957552 hw_loss 0.423083 lr 0.00087300 rank 3
2023-02-11 07:48:19,945 DEBUG TRAIN Batch 3/7800 loss 20.224630 loss_att 28.518791 loss_ctc 30.011616 loss_rnnt 15.160080 hw_loss 0.393898 lr 0.00087248 rank 2
2023-02-11 07:48:19,947 DEBUG TRAIN Batch 3/7800 loss 20.473322 loss_att 25.605234 loss_ctc 36.651329 loss_rnnt 14.609164 hw_loss 0.502633 lr 0.00087321 rank 4
2023-02-11 07:48:19,947 DEBUG TRAIN Batch 3/7800 loss 21.385710 loss_att 31.634033 loss_ctc 41.280197 loss_rnnt 15.798388 hw_loss 0.165948 lr 0.00087324 rank 7
2023-02-11 07:48:19,948 DEBUG TRAIN Batch 3/7800 loss 14.244437 loss_att 23.779232 loss_ctc 29.335220 loss_rnnt 9.892496 hw_loss 0.081165 lr 0.00087232 rank 1
2023-02-11 07:48:19,953 DEBUG TRAIN Batch 3/7800 loss 42.091911 loss_att 48.196022 loss_ctc 59.444038 loss_rnnt 37.224915 hw_loss 0.249854 lr 0.00087248 rank 5
2023-02-11 07:49:36,209 DEBUG TRAIN Batch 3/7900 loss 26.787151 loss_att 37.798084 loss_ctc 39.567772 loss_rnnt 20.076508 hw_loss 0.525820 lr 0.00087105 rank 0
2023-02-11 07:49:36,209 DEBUG TRAIN Batch 3/7900 loss 12.528332 loss_att 16.452349 loss_ctc 23.617413 loss_rnnt 8.972958 hw_loss 0.242255 lr 0.00087100 rank 1
2023-02-11 07:49:36,211 DEBUG TRAIN Batch 3/7900 loss 29.939129 loss_att 38.197819 loss_ctc 56.557648 loss_rnnt 21.962055 hw_loss 0.520537 lr 0.00087191 rank 7
2023-02-11 07:49:36,211 DEBUG TRAIN Batch 3/7900 loss 21.137274 loss_att 28.355782 loss_ctc 34.334442 loss_rnnt 15.972347 hw_loss 0.367800 lr 0.00087167 rank 3
2023-02-11 07:49:36,214 DEBUG TRAIN Batch 3/7900 loss 32.882469 loss_att 38.157623 loss_ctc 42.237209 loss_rnnt 26.185854 hw_loss 0.823929 lr 0.00087115 rank 2
2023-02-11 07:49:36,215 DEBUG TRAIN Batch 3/7900 loss 40.208920 loss_att 44.531521 loss_ctc 61.109478 loss_rnnt 35.008148 hw_loss 0.290533 lr 0.00087115 rank 5
2023-02-11 07:49:36,215 DEBUG TRAIN Batch 3/7900 loss 25.793613 loss_att 28.973230 loss_ctc 42.413719 loss_rnnt 20.359509 hw_loss 0.484156 lr 0.00087164 rank 6
2023-02-11 07:49:36,269 DEBUG TRAIN Batch 3/7900 loss 31.464405 loss_att 35.281918 loss_ctc 49.398933 loss_rnnt 26.882635 hw_loss 0.267562 lr 0.00087188 rank 4
2023-02-11 07:50:52,589 DEBUG TRAIN Batch 3/8000 loss 32.015259 loss_att 36.099136 loss_ctc 50.456383 loss_rnnt 25.728218 hw_loss 0.564646 lr 0.00086973 rank 0
2023-02-11 07:50:52,589 DEBUG TRAIN Batch 3/8000 loss 27.797489 loss_att 27.168064 loss_ctc 33.443562 loss_rnnt 23.135653 hw_loss 0.756546 lr 0.00087059 rank 7
2023-02-11 07:50:52,593 DEBUG TRAIN Batch 3/8000 loss 15.490687 loss_att 19.557287 loss_ctc 28.626343 loss_rnnt 10.411689 hw_loss 0.471423 lr 0.00086983 rank 5
2023-02-11 07:50:52,594 DEBUG TRAIN Batch 3/8000 loss 55.178562 loss_att 66.973732 loss_ctc 83.761887 loss_rnnt 45.595093 hw_loss 0.639998 lr 0.00087035 rank 3
2023-02-11 07:50:52,594 DEBUG TRAIN Batch 3/8000 loss 29.621616 loss_att 35.111118 loss_ctc 45.844921 loss_rnnt 23.456497 hw_loss 0.544521 lr 0.00086968 rank 1
2023-02-11 07:50:52,595 DEBUG TRAIN Batch 3/8000 loss 26.325512 loss_att 31.279766 loss_ctc 36.791798 loss_rnnt 21.725937 hw_loss 0.414979 lr 0.00087056 rank 4
2023-02-11 07:50:52,597 DEBUG TRAIN Batch 3/8000 loss 31.721540 loss_att 37.578854 loss_ctc 40.859406 loss_rnnt 24.382545 hw_loss 0.927966 lr 0.00087032 rank 6
2023-02-11 07:50:52,598 DEBUG TRAIN Batch 3/8000 loss 28.921379 loss_att 28.829117 loss_ctc 36.603271 loss_rnnt 25.487820 hw_loss 0.455205 lr 0.00086983 rank 2
2023-02-11 07:52:09,155 DEBUG TRAIN Batch 3/8100 loss 20.849504 loss_att 23.324795 loss_ctc 27.269619 loss_rnnt 14.479745 hw_loss 0.941003 lr 0.00086903 rank 3
2023-02-11 07:52:09,155 DEBUG TRAIN Batch 3/8100 loss 23.068222 loss_att 23.506205 loss_ctc 37.285763 loss_rnnt 17.938839 hw_loss 0.589897 lr 0.00086852 rank 2
2023-02-11 07:52:09,159 DEBUG TRAIN Batch 3/8100 loss 27.070553 loss_att 27.376333 loss_ctc 39.534500 loss_rnnt 21.714474 hw_loss 0.681200 lr 0.00086842 rank 0
2023-02-11 07:52:09,163 DEBUG TRAIN Batch 3/8100 loss 21.291597 loss_att 26.197689 loss_ctc 39.695469 loss_rnnt 15.990491 hw_loss 0.349882 lr 0.00086836 rank 1
2023-02-11 07:52:09,165 DEBUG TRAIN Batch 3/8100 loss 22.871580 loss_att 26.989239 loss_ctc 35.676701 loss_rnnt 18.177647 hw_loss 0.405572 lr 0.00086901 rank 6
2023-02-11 07:52:09,165 DEBUG TRAIN Batch 3/8100 loss 36.987976 loss_att 37.656948 loss_ctc 52.621468 loss_rnnt 30.729761 hw_loss 0.757492 lr 0.00086924 rank 4
2023-02-11 07:52:09,166 DEBUG TRAIN Batch 3/8100 loss 26.388979 loss_att 29.403343 loss_ctc 39.470974 loss_rnnt 19.890995 hw_loss 0.778283 lr 0.00086852 rank 5
2023-02-11 07:52:09,171 DEBUG TRAIN Batch 3/8100 loss 33.778252 loss_att 38.254250 loss_ctc 44.465744 loss_rnnt 28.422695 hw_loss 0.569129 lr 0.00086927 rank 7
2023-02-11 07:53:26,318 DEBUG TRAIN Batch 3/8200 loss 12.972104 loss_att 15.683055 loss_ctc 20.810488 loss_rnnt 10.225267 hw_loss 0.217412 lr 0.00086772 rank 3
2023-02-11 07:53:26,320 DEBUG TRAIN Batch 3/8200 loss 58.083168 loss_att 59.336018 loss_ctc 71.663536 loss_rnnt 51.026882 hw_loss 0.936562 lr 0.00086706 rank 1
2023-02-11 07:53:26,320 DEBUG TRAIN Batch 3/8200 loss 16.157457 loss_att 21.174847 loss_ctc 26.853643 loss_rnnt 11.483461 hw_loss 0.420817 lr 0.00086793 rank 4
2023-02-11 07:53:26,321 DEBUG TRAIN Batch 3/8200 loss 18.993725 loss_att 19.414074 loss_ctc 24.129864 loss_rnnt 13.019752 hw_loss 0.975953 lr 0.00086711 rank 0
2023-02-11 07:53:26,321 DEBUG TRAIN Batch 3/8200 loss 24.227316 loss_att 29.053244 loss_ctc 38.217308 loss_rnnt 19.663298 hw_loss 0.325031 lr 0.00086796 rank 7
2023-02-11 07:53:26,327 DEBUG TRAIN Batch 3/8200 loss 30.394751 loss_att 33.941704 loss_ctc 43.716110 loss_rnnt 25.504761 hw_loss 0.450829 lr 0.00086770 rank 6
2023-02-11 07:53:26,326 DEBUG TRAIN Batch 3/8200 loss 24.270863 loss_att 24.020542 loss_ctc 37.749687 loss_rnnt 17.312881 hw_loss 0.977038 lr 0.00086721 rank 5
2023-02-11 07:53:26,328 DEBUG TRAIN Batch 3/8200 loss 32.769821 loss_att 49.030228 loss_ctc 45.820587 loss_rnnt 25.295864 hw_loss 0.465333 lr 0.00086721 rank 2
2023-02-11 07:54:41,358 DEBUG TRAIN Batch 3/8300 loss 21.274977 loss_att 24.378864 loss_ctc 35.521034 loss_rnnt 16.655434 hw_loss 0.393617 lr 0.00086665 rank 7
2023-02-11 07:54:41,363 DEBUG TRAIN Batch 3/8300 loss 33.708744 loss_att 42.946934 loss_ctc 59.850601 loss_rnnt 25.943352 hw_loss 0.456032 lr 0.00086639 rank 6
2023-02-11 07:54:41,364 DEBUG TRAIN Batch 3/8300 loss 23.937445 loss_att 21.296261 loss_ctc 24.689327 loss_rnnt 19.803232 hw_loss 0.855412 lr 0.00086642 rank 3
2023-02-11 07:54:41,366 DEBUG TRAIN Batch 3/8300 loss 27.656054 loss_att 32.522987 loss_ctc 42.727509 loss_rnnt 23.460056 hw_loss 0.227453 lr 0.00086576 rank 1
2023-02-11 07:54:41,366 DEBUG TRAIN Batch 3/8300 loss 22.284773 loss_att 26.436729 loss_ctc 25.280455 loss_rnnt 17.557310 hw_loss 0.655809 lr 0.00086591 rank 2
2023-02-11 07:54:41,367 DEBUG TRAIN Batch 3/8300 loss 47.703926 loss_att 52.639412 loss_ctc 67.094742 loss_rnnt 43.477776 hw_loss 0.122553 lr 0.00086581 rank 0
2023-02-11 07:54:41,370 DEBUG TRAIN Batch 3/8300 loss 41.003948 loss_att 39.648888 loss_ctc 50.681572 loss_rnnt 37.725143 hw_loss 0.423650 lr 0.00086591 rank 5
2023-02-11 07:54:41,372 DEBUG TRAIN Batch 3/8300 loss 17.101082 loss_att 20.879272 loss_ctc 25.595589 loss_rnnt 13.136622 hw_loss 0.389291 lr 0.00086663 rank 4
2023-02-11 07:55:36,368 DEBUG CV Batch 3/0 loss 10.497037 loss_att 4.516377 loss_ctc 7.743890 loss_rnnt 4.040408 hw_loss 1.503721 history loss 10.108258 rank 1
2023-02-11 07:55:36,369 DEBUG CV Batch 3/0 loss 10.497036 loss_att 4.516377 loss_ctc 7.743890 loss_rnnt 4.040408 hw_loss 1.503721 history loss 10.108257 rank 6
2023-02-11 07:55:36,370 DEBUG CV Batch 3/0 loss 10.497036 loss_att 4.516377 loss_ctc 7.743890 loss_rnnt 4.040408 hw_loss 1.503721 history loss 10.108257 rank 7
2023-02-11 07:55:36,371 DEBUG CV Batch 3/0 loss 10.497036 loss_att 4.516377 loss_ctc 7.743890 loss_rnnt 4.040408 hw_loss 1.503721 history loss 10.108257 rank 5
2023-02-11 07:55:36,373 DEBUG CV Batch 3/0 loss 10.497037 loss_att 4.516377 loss_ctc 7.743890 loss_rnnt 4.040408 hw_loss 1.503721 history loss 10.108258 rank 3
2023-02-11 07:55:36,381 DEBUG CV Batch 3/0 loss 10.497036 loss_att 4.516377 loss_ctc 7.743890 loss_rnnt 4.040408 hw_loss 1.503721 history loss 10.108257 rank 0
2023-02-11 07:55:36,384 DEBUG CV Batch 3/0 loss 10.497036 loss_att 4.516377 loss_ctc 7.743890 loss_rnnt 4.040408 hw_loss 1.503721 history loss 10.108257 rank 2
2023-02-11 07:55:36,394 DEBUG CV Batch 3/0 loss 10.497038 loss_att 4.516377 loss_ctc 7.743890 loss_rnnt 4.040408 hw_loss 1.503721 history loss 10.108259 rank 4
2023-02-11 07:55:47,461 DEBUG CV Batch 3/100 loss 20.436310 loss_att 19.939302 loss_ctc 26.569939 loss_rnnt 13.604658 hw_loss 1.146232 history loss 12.460088 rank 0
2023-02-11 07:55:47,465 DEBUG CV Batch 3/100 loss 20.436310 loss_att 19.939302 loss_ctc 26.569939 loss_rnnt 13.604658 hw_loss 1.146232 history loss 12.460088 rank 3
2023-02-11 07:55:47,508 DEBUG CV Batch 3/100 loss 20.436310 loss_att 19.939302 loss_ctc 26.569939 loss_rnnt 13.604658 hw_loss 1.146232 history loss 12.460088 rank 1
2023-02-11 07:55:47,586 DEBUG CV Batch 3/100 loss 20.436310 loss_att 19.939302 loss_ctc 26.569939 loss_rnnt 13.604658 hw_loss 1.146232 history loss 12.460088 rank 7
2023-02-11 07:55:47,592 DEBUG CV Batch 3/100 loss 20.436310 loss_att 19.939302 loss_ctc 26.569939 loss_rnnt 13.604658 hw_loss 1.146232 history loss 12.460088 rank 6
2023-02-11 07:55:47,633 DEBUG CV Batch 3/100 loss 20.436310 loss_att 19.939302 loss_ctc 26.569939 loss_rnnt 13.604658 hw_loss 1.146232 history loss 12.460088 rank 5
2023-02-11 07:55:47,704 DEBUG CV Batch 3/100 loss 20.436310 loss_att 19.939302 loss_ctc 26.569939 loss_rnnt 13.604658 hw_loss 1.146232 history loss 12.460088 rank 4
2023-02-11 07:55:48,683 DEBUG CV Batch 3/100 loss 20.436310 loss_att 19.939302 loss_ctc 26.569939 loss_rnnt 13.604658 hw_loss 1.146232 history loss 12.460088 rank 2
2023-02-11 07:56:00,998 DEBUG CV Batch 3/200 loss 26.615404 loss_att 36.640919 loss_ctc 35.558498 loss_rnnt 21.419579 hw_loss 0.374684 history loss 13.127022 rank 7
2023-02-11 07:56:01,082 DEBUG CV Batch 3/200 loss 26.615404 loss_att 36.640919 loss_ctc 35.558498 loss_rnnt 21.419579 hw_loss 0.374684 history loss 13.127022 rank 0
2023-02-11 07:56:01,158 DEBUG CV Batch 3/200 loss 26.615404 loss_att 36.640919 loss_ctc 35.558498 loss_rnnt 21.419579 hw_loss 0.374684 history loss 13.127022 rank 5
2023-02-11 07:56:01,251 DEBUG CV Batch 3/200 loss 26.615404 loss_att 36.640919 loss_ctc 35.558498 loss_rnnt 21.419579 hw_loss 0.374684 history loss 13.127022 rank 1
2023-02-11 07:56:01,256 DEBUG CV Batch 3/200 loss 26.615404 loss_att 36.640919 loss_ctc 35.558498 loss_rnnt 21.419579 hw_loss 0.374684 history loss 13.127022 rank 3
2023-02-11 07:56:01,480 DEBUG CV Batch 3/200 loss 26.615404 loss_att 36.640919 loss_ctc 35.558498 loss_rnnt 21.419579 hw_loss 0.374684 history loss 13.127022 rank 6
2023-02-11 07:56:01,827 DEBUG CV Batch 3/200 loss 26.615404 loss_att 36.640919 loss_ctc 35.558498 loss_rnnt 21.419579 hw_loss 0.374684 history loss 13.127022 rank 4
2023-02-11 07:56:03,326 DEBUG CV Batch 3/200 loss 26.615404 loss_att 36.640919 loss_ctc 35.558498 loss_rnnt 21.419579 hw_loss 0.374684 history loss 13.127022 rank 2
2023-02-11 07:56:12,992 DEBUG CV Batch 3/300 loss 17.184170 loss_att 14.180340 loss_ctc 20.441927 loss_rnnt 11.087285 hw_loss 1.174365 history loss 13.411576 rank 7
2023-02-11 07:56:13,058 DEBUG CV Batch 3/300 loss 17.184170 loss_att 14.180340 loss_ctc 20.441927 loss_rnnt 11.087285 hw_loss 1.174365 history loss 13.411576 rank 0
2023-02-11 07:56:13,235 DEBUG CV Batch 3/300 loss 17.184170 loss_att 14.180340 loss_ctc 20.441927 loss_rnnt 11.087285 hw_loss 1.174365 history loss 13.411576 rank 5
2023-02-11 07:56:13,291 DEBUG CV Batch 3/300 loss 17.184170 loss_att 14.180340 loss_ctc 20.441927 loss_rnnt 11.087285 hw_loss 1.174365 history loss 13.411576 rank 1
2023-02-11 07:56:13,324 DEBUG CV Batch 3/300 loss 17.184170 loss_att 14.180340 loss_ctc 20.441927 loss_rnnt 11.087285 hw_loss 1.174365 history loss 13.411576 rank 3
2023-02-11 07:56:13,590 DEBUG CV Batch 3/300 loss 17.184170 loss_att 14.180340 loss_ctc 20.441927 loss_rnnt 11.087285 hw_loss 1.174365 history loss 13.411576 rank 6
2023-02-11 07:56:13,916 DEBUG CV Batch 3/300 loss 17.184170 loss_att 14.180340 loss_ctc 20.441927 loss_rnnt 11.087285 hw_loss 1.174365 history loss 13.411576 rank 4
2023-02-11 07:56:15,430 DEBUG CV Batch 3/300 loss 17.184170 loss_att 14.180340 loss_ctc 20.441927 loss_rnnt 11.087285 hw_loss 1.174365 history loss 13.411576 rank 2
2023-02-11 07:56:24,920 DEBUG CV Batch 3/400 loss 36.303631 loss_att 88.998154 loss_ctc 48.882797 loss_rnnt 22.979715 hw_loss 0.207710 history loss 14.678522 rank 0
2023-02-11 07:56:24,933 DEBUG CV Batch 3/400 loss 36.303631 loss_att 88.998154 loss_ctc 48.882797 loss_rnnt 22.979715 hw_loss 0.207710 history loss 14.678522 rank 7
2023-02-11 07:56:25,231 DEBUG CV Batch 3/400 loss 36.303631 loss_att 88.998154 loss_ctc 48.882797 loss_rnnt 22.979715 hw_loss 0.207710 history loss 14.678522 rank 5
2023-02-11 07:56:25,276 DEBUG CV Batch 3/400 loss 36.303631 loss_att 88.998154 loss_ctc 48.882797 loss_rnnt 22.979715 hw_loss 0.207710 history loss 14.678522 rank 1
2023-02-11 07:56:25,284 DEBUG CV Batch 3/400 loss 36.303631 loss_att 88.998154 loss_ctc 48.882797 loss_rnnt 22.979715 hw_loss 0.207710 history loss 14.678522 rank 3
2023-02-11 07:56:25,542 DEBUG CV Batch 3/400 loss 36.303631 loss_att 88.998154 loss_ctc 48.882797 loss_rnnt 22.979715 hw_loss 0.207710 history loss 14.678522 rank 6
2023-02-11 07:56:25,965 DEBUG CV Batch 3/400 loss 36.303631 loss_att 88.998154 loss_ctc 48.882797 loss_rnnt 22.979715 hw_loss 0.207710 history loss 14.678522 rank 4
2023-02-11 07:56:27,478 DEBUG CV Batch 3/400 loss 36.303631 loss_att 88.998154 loss_ctc 48.882797 loss_rnnt 22.979715 hw_loss 0.207710 history loss 14.678522 rank 2
2023-02-11 07:56:35,259 DEBUG CV Batch 3/500 loss 12.403781 loss_att 13.552368 loss_ctc 20.063225 loss_rnnt 7.248369 hw_loss 0.732082 history loss 15.741053 rank 0
2023-02-11 07:56:35,435 DEBUG CV Batch 3/500 loss 12.403782 loss_att 13.552368 loss_ctc 20.063225 loss_rnnt 7.248369 hw_loss 0.732082 history loss 15.741053 rank 7
2023-02-11 07:56:35,681 DEBUG CV Batch 3/500 loss 12.403782 loss_att 13.552368 loss_ctc 20.063225 loss_rnnt 7.248369 hw_loss 0.732082 history loss 15.741053 rank 3
2023-02-11 07:56:35,706 DEBUG CV Batch 3/500 loss 12.403782 loss_att 13.552368 loss_ctc 20.063225 loss_rnnt 7.248369 hw_loss 0.732082 history loss 15.741053 rank 5
2023-02-11 07:56:36,032 DEBUG CV Batch 3/500 loss 12.403781 loss_att 13.552368 loss_ctc 20.063225 loss_rnnt 7.248369 hw_loss 0.732082 history loss 15.741053 rank 6
2023-02-11 07:56:36,507 DEBUG CV Batch 3/500 loss 12.403782 loss_att 13.552368 loss_ctc 20.063225 loss_rnnt 7.248369 hw_loss 0.732082 history loss 15.741053 rank 1
2023-02-11 07:56:36,636 DEBUG CV Batch 3/500 loss 12.403782 loss_att 13.552368 loss_ctc 20.063225 loss_rnnt 7.248369 hw_loss 0.732082 history loss 15.741053 rank 4
2023-02-11 07:56:37,983 DEBUG CV Batch 3/500 loss 12.403782 loss_att 13.552368 loss_ctc 20.063225 loss_rnnt 7.248369 hw_loss 0.732082 history loss 15.741053 rank 2
2023-02-11 07:56:47,225 DEBUG CV Batch 3/600 loss 20.541267 loss_att 15.313334 loss_ctc 19.189701 loss_rnnt 12.182111 hw_loss 1.797178 history loss 17.017663 rank 0
2023-02-11 07:56:47,416 DEBUG CV Batch 3/600 loss 20.541267 loss_att 15.313334 loss_ctc 19.189701 loss_rnnt 12.182111 hw_loss 1.797179 history loss 17.017663 rank 7
2023-02-11 07:56:47,781 DEBUG CV Batch 3/600 loss 20.541267 loss_att 15.313334 loss_ctc 19.189701 loss_rnnt 12.182111 hw_loss 1.797178 history loss 17.017663 rank 3
2023-02-11 07:56:47,810 DEBUG CV Batch 3/600 loss 20.541267 loss_att 15.313334 loss_ctc 19.189701 loss_rnnt 12.182111 hw_loss 1.797178 history loss 17.017663 rank 5
2023-02-11 07:56:48,151 DEBUG CV Batch 3/600 loss 20.541267 loss_att 15.313334 loss_ctc 19.189701 loss_rnnt 12.182111 hw_loss 1.797179 history loss 17.017663 rank 6
2023-02-11 07:56:48,501 DEBUG CV Batch 3/600 loss 20.541267 loss_att 15.313334 loss_ctc 19.189701 loss_rnnt 12.182111 hw_loss 1.797179 history loss 17.017663 rank 1
2023-02-11 07:56:49,056 DEBUG CV Batch 3/600 loss 20.541267 loss_att 15.313334 loss_ctc 19.189701 loss_rnnt 12.182111 hw_loss 1.797178 history loss 17.017663 rank 4
2023-02-11 07:56:50,029 DEBUG CV Batch 3/600 loss 20.541267 loss_att 15.313334 loss_ctc 19.189701 loss_rnnt 12.182111 hw_loss 1.797179 history loss 17.017663 rank 2
2023-02-11 07:56:58,446 DEBUG CV Batch 3/700 loss 35.375526 loss_att 81.011795 loss_ctc 48.588581 loss_rnnt 24.300375 hw_loss 0.034904 history loss 17.921905 rank 0
2023-02-11 07:56:58,696 DEBUG CV Batch 3/700 loss 35.375526 loss_att 81.011795 loss_ctc 48.588581 loss_rnnt 24.300375 hw_loss 0.034904 history loss 17.921905 rank 7
2023-02-11 07:56:59,021 DEBUG CV Batch 3/700 loss 35.375526 loss_att 81.011795 loss_ctc 48.588581 loss_rnnt 24.300375 hw_loss 0.034904 history loss 17.921905 rank 3
2023-02-11 07:56:59,181 DEBUG CV Batch 3/700 loss 35.375526 loss_att 81.011795 loss_ctc 48.588581 loss_rnnt 24.300375 hw_loss 0.034904 history loss 17.921905 rank 5
2023-02-11 07:56:59,764 DEBUG CV Batch 3/700 loss 35.375526 loss_att 81.011795 loss_ctc 48.588581 loss_rnnt 24.300375 hw_loss 0.034904 history loss 17.921905 rank 1
2023-02-11 07:57:01,041 DEBUG CV Batch 3/700 loss 35.375526 loss_att 81.011795 loss_ctc 48.588581 loss_rnnt 24.300375 hw_loss 0.034904 history loss 17.921905 rank 6
2023-02-11 07:57:01,301 DEBUG CV Batch 3/700 loss 35.375526 loss_att 81.011795 loss_ctc 48.588581 loss_rnnt 24.300375 hw_loss 0.034904 history loss 17.921905 rank 2
2023-02-11 07:57:01,322 DEBUG CV Batch 3/700 loss 35.375526 loss_att 81.011795 loss_ctc 48.588581 loss_rnnt 24.300375 hw_loss 0.034904 history loss 17.921905 rank 4
2023-02-11 07:57:10,119 DEBUG CV Batch 3/800 loss 22.152201 loss_att 21.510748 loss_ctc 31.341894 loss_rnnt 15.776355 hw_loss 0.989783 history loss 17.195985 rank 0
2023-02-11 07:57:10,413 DEBUG CV Batch 3/800 loss 22.152199 loss_att 21.510748 loss_ctc 31.341894 loss_rnnt 15.776355 hw_loss 0.989783 history loss 17.195985 rank 3
2023-02-11 07:57:10,418 DEBUG CV Batch 3/800 loss 22.152201 loss_att 21.510748 loss_ctc 31.341894 loss_rnnt 15.776355 hw_loss 0.989783 history loss 17.195985 rank 5
2023-02-11 07:57:10,607 DEBUG CV Batch 3/800 loss 22.152199 loss_att 21.510748 loss_ctc 31.341894 loss_rnnt 15.776355 hw_loss 0.989783 history loss 17.195985 rank 7
2023-02-11 07:57:11,932 DEBUG CV Batch 3/800 loss 22.152199 loss_att 21.510748 loss_ctc 31.341894 loss_rnnt 15.776355 hw_loss 0.989783 history loss 17.195985 rank 1
2023-02-11 07:57:12,489 DEBUG CV Batch 3/800 loss 22.152199 loss_att 21.510748 loss_ctc 31.341894 loss_rnnt 15.776355 hw_loss 0.989783 history loss 17.195985 rank 2
2023-02-11 07:57:12,979 DEBUG CV Batch 3/800 loss 22.152201 loss_att 21.510748 loss_ctc 31.341894 loss_rnnt 15.776355 hw_loss 0.989783 history loss 17.195985 rank 6
2023-02-11 07:57:13,389 DEBUG CV Batch 3/800 loss 22.152199 loss_att 21.510748 loss_ctc 31.341894 loss_rnnt 15.776355 hw_loss 0.989783 history loss 17.195985 rank 4
2023-02-11 07:57:23,922 DEBUG CV Batch 3/900 loss 22.991505 loss_att 36.281281 loss_ctc 40.112404 loss_rnnt 15.904667 hw_loss 0.402393 history loss 16.893577 rank 0
2023-02-11 07:57:24,056 DEBUG CV Batch 3/900 loss 22.991505 loss_att 36.281281 loss_ctc 40.112404 loss_rnnt 15.904667 hw_loss 0.402393 history loss 16.893577 rank 7
2023-02-11 07:57:24,122 DEBUG CV Batch 3/900 loss 22.991505 loss_att 36.281281 loss_ctc 40.112404 loss_rnnt 15.904667 hw_loss 0.402393 history loss 16.893577 rank 5
2023-02-11 07:57:24,375 DEBUG CV Batch 3/900 loss 22.991505 loss_att 36.281281 loss_ctc 40.112404 loss_rnnt 15.904667 hw_loss 0.402393 history loss 16.893577 rank 3
2023-02-11 07:57:25,853 DEBUG CV Batch 3/900 loss 22.991505 loss_att 36.281281 loss_ctc 40.112404 loss_rnnt 15.904667 hw_loss 0.402393 history loss 16.893577 rank 2
2023-02-11 07:57:26,263 DEBUG CV Batch 3/900 loss 22.991505 loss_att 36.281281 loss_ctc 40.112404 loss_rnnt 15.904667 hw_loss 0.402393 history loss 16.893577 rank 1
2023-02-11 07:57:27,149 DEBUG CV Batch 3/900 loss 22.991505 loss_att 36.281281 loss_ctc 40.112404 loss_rnnt 15.904667 hw_loss 0.402393 history loss 16.893577 rank 6
2023-02-11 07:57:28,426 DEBUG CV Batch 3/900 loss 22.991505 loss_att 36.281281 loss_ctc 40.112404 loss_rnnt 15.904667 hw_loss 0.402393 history loss 16.893577 rank 4
2023-02-11 07:57:36,043 DEBUG CV Batch 3/1000 loss 11.554386 loss_att 9.937280 loss_ctc 12.998861 loss_rnnt 7.201408 hw_loss 0.840713 history loss 16.610574 rank 0
2023-02-11 07:57:36,229 DEBUG CV Batch 3/1000 loss 11.554386 loss_att 9.937280 loss_ctc 12.998861 loss_rnnt 7.201408 hw_loss 0.840713 history loss 16.610574 rank 7
2023-02-11 07:57:36,349 DEBUG CV Batch 3/1000 loss 11.554386 loss_att 9.937280 loss_ctc 12.998861 loss_rnnt 7.201408 hw_loss 0.840713 history loss 16.610574 rank 5
2023-02-11 07:57:36,580 DEBUG CV Batch 3/1000 loss 11.554386 loss_att 9.937280 loss_ctc 12.998861 loss_rnnt 7.201408 hw_loss 0.840713 history loss 16.610574 rank 3
2023-02-11 07:57:38,160 DEBUG CV Batch 3/1000 loss 11.554386 loss_att 9.937280 loss_ctc 12.998861 loss_rnnt 7.201408 hw_loss 0.840713 history loss 16.610574 rank 2
2023-02-11 07:57:38,417 DEBUG CV Batch 3/1000 loss 11.554386 loss_att 9.937280 loss_ctc 12.998861 loss_rnnt 7.201408 hw_loss 0.840713 history loss 16.610574 rank 1
2023-02-11 07:57:40,062 DEBUG CV Batch 3/1000 loss 11.554386 loss_att 9.937280 loss_ctc 12.998861 loss_rnnt 7.201408 hw_loss 0.840713 history loss 16.610574 rank 6
2023-02-11 07:57:40,649 DEBUG CV Batch 3/1000 loss 11.554386 loss_att 9.937280 loss_ctc 12.998861 loss_rnnt 7.201408 hw_loss 0.840713 history loss 16.610574 rank 4
2023-02-11 07:57:47,918 DEBUG CV Batch 3/1100 loss 14.933418 loss_att 9.297590 loss_ctc 14.129951 loss_rnnt 8.908359 hw_loss 1.361129 history loss 16.556662 rank 0
2023-02-11 07:57:48,121 DEBUG CV Batch 3/1100 loss 14.933419 loss_att 9.297590 loss_ctc 14.129951 loss_rnnt 8.908359 hw_loss 1.361129 history loss 16.556662 rank 7
2023-02-11 07:57:48,293 DEBUG CV Batch 3/1100 loss 14.933420 loss_att 9.297590 loss_ctc 14.129951 loss_rnnt 8.908359 hw_loss 1.361129 history loss 16.556662 rank 5
2023-02-11 07:57:48,389 DEBUG CV Batch 3/1100 loss 14.933419 loss_att 9.297590 loss_ctc 14.129951 loss_rnnt 8.908359 hw_loss 1.361129 history loss 16.556662 rank 3
2023-02-11 07:57:50,118 DEBUG CV Batch 3/1100 loss 14.933418 loss_att 9.297590 loss_ctc 14.129951 loss_rnnt 8.908359 hw_loss 1.361129 history loss 16.556662 rank 2
2023-02-11 07:57:51,149 DEBUG CV Batch 3/1100 loss 14.933420 loss_att 9.297590 loss_ctc 14.129951 loss_rnnt 8.908359 hw_loss 1.361129 history loss 16.556662 rank 1
2023-02-11 07:57:52,063 DEBUG CV Batch 3/1100 loss 14.933419 loss_att 9.297590 loss_ctc 14.129951 loss_rnnt 8.908359 hw_loss 1.361129 history loss 16.556662 rank 6
2023-02-11 07:57:52,760 DEBUG CV Batch 3/1100 loss 14.933419 loss_att 9.297590 loss_ctc 14.129951 loss_rnnt 8.908359 hw_loss 1.361129 history loss 16.556662 rank 4
2023-02-11 07:57:58,317 DEBUG CV Batch 3/1200 loss 17.876657 loss_att 19.578341 loss_ctc 22.127638 loss_rnnt 13.833788 hw_loss 0.587950 history loss 17.025235 rank 0
2023-02-11 07:57:58,568 DEBUG CV Batch 3/1200 loss 17.876657 loss_att 19.578341 loss_ctc 22.127638 loss_rnnt 13.833788 hw_loss 0.587950 history loss 17.025235 rank 7
2023-02-11 07:57:58,784 DEBUG CV Batch 3/1200 loss 17.876657 loss_att 19.578341 loss_ctc 22.127638 loss_rnnt 13.833788 hw_loss 0.587950 history loss 17.025235 rank 5
2023-02-11 07:57:58,786 DEBUG CV Batch 3/1200 loss 17.876657 loss_att 19.578341 loss_ctc 22.127638 loss_rnnt 13.833788 hw_loss 0.587950 history loss 17.025235 rank 3
2023-02-11 07:58:00,585 DEBUG CV Batch 3/1200 loss 17.876657 loss_att 19.578341 loss_ctc 22.127638 loss_rnnt 13.833788 hw_loss 0.587950 history loss 17.025235 rank 2
2023-02-11 07:58:01,872 DEBUG CV Batch 3/1200 loss 17.876657 loss_att 19.578341 loss_ctc 22.127638 loss_rnnt 13.833788 hw_loss 0.587950 history loss 17.025235 rank 1
2023-02-11 07:58:02,504 DEBUG CV Batch 3/1200 loss 17.876657 loss_att 19.578341 loss_ctc 22.127638 loss_rnnt 13.833788 hw_loss 0.587950 history loss 17.025235 rank 6
2023-02-11 07:58:03,317 DEBUG CV Batch 3/1200 loss 17.876657 loss_att 19.578341 loss_ctc 22.127638 loss_rnnt 13.833788 hw_loss 0.587950 history loss 17.025235 rank 4
2023-02-11 07:58:10,199 DEBUG CV Batch 3/1300 loss 17.873623 loss_att 11.638594 loss_ctc 15.828665 loss_rnnt 9.317070 hw_loss 1.889291 history loss 17.411757 rank 0
2023-02-11 07:58:10,394 DEBUG CV Batch 3/1300 loss 17.873623 loss_att 11.638594 loss_ctc 15.828665 loss_rnnt 9.317070 hw_loss 1.889291 history loss 17.411757 rank 7
2023-02-11 07:58:10,553 DEBUG CV Batch 3/1300 loss 17.873623 loss_att 11.638594 loss_ctc 15.828665 loss_rnnt 9.317070 hw_loss 1.889291 history loss 17.411757 rank 3
2023-02-11 07:58:10,711 DEBUG CV Batch 3/1300 loss 17.873623 loss_att 11.638594 loss_ctc 15.828665 loss_rnnt 9.317070 hw_loss 1.889291 history loss 17.411757 rank 5
2023-02-11 07:58:12,470 DEBUG CV Batch 3/1300 loss 17.873623 loss_att 11.638594 loss_ctc 15.828665 loss_rnnt 9.317070 hw_loss 1.889291 history loss 17.411757 rank 2
2023-02-11 07:58:13,710 DEBUG CV Batch 3/1300 loss 17.873623 loss_att 11.638594 loss_ctc 15.828665 loss_rnnt 9.317070 hw_loss 1.889291 history loss 17.411757 rank 1
2023-02-11 07:58:14,418 DEBUG CV Batch 3/1300 loss 17.873623 loss_att 11.638594 loss_ctc 15.828665 loss_rnnt 9.317070 hw_loss 1.889291 history loss 17.411757 rank 6
2023-02-11 07:58:15,548 DEBUG CV Batch 3/1300 loss 17.873623 loss_att 11.638594 loss_ctc 15.828665 loss_rnnt 9.317070 hw_loss 1.889291 history loss 17.411757 rank 4
2023-02-11 07:58:21,289 DEBUG CV Batch 3/1400 loss 25.471025 loss_att 58.538815 loss_ctc 37.052258 loss_rnnt 15.514119 hw_loss 0.337347 history loss 17.885650 rank 0
2023-02-11 07:58:21,512 DEBUG CV Batch 3/1400 loss 25.471025 loss_att 58.538815 loss_ctc 37.052258 loss_rnnt 15.514119 hw_loss 0.337347 history loss 17.885650 rank 7
2023-02-11 07:58:21,763 DEBUG CV Batch 3/1400 loss 25.471025 loss_att 58.538815 loss_ctc 37.052258 loss_rnnt 15.514119 hw_loss 0.337347 history loss 17.885650 rank 3
2023-02-11 07:58:21,897 DEBUG CV Batch 3/1400 loss 25.471025 loss_att 58.538815 loss_ctc 37.052258 loss_rnnt 15.514119 hw_loss 0.337347 history loss 17.885650 rank 5
2023-02-11 07:58:23,539 DEBUG CV Batch 3/1400 loss 25.471025 loss_att 58.538815 loss_ctc 37.052258 loss_rnnt 15.514119 hw_loss 0.337347 history loss 17.885650 rank 2
2023-02-11 07:58:24,837 DEBUG CV Batch 3/1400 loss 25.471025 loss_att 58.538815 loss_ctc 37.052258 loss_rnnt 15.514119 hw_loss 0.337347 history loss 17.885650 rank 1
2023-02-11 07:58:25,526 DEBUG CV Batch 3/1400 loss 25.471025 loss_att 58.538815 loss_ctc 37.052258 loss_rnnt 15.514119 hw_loss 0.337347 history loss 17.885650 rank 6
2023-02-11 07:58:26,757 DEBUG CV Batch 3/1400 loss 25.471025 loss_att 58.538815 loss_ctc 37.052258 loss_rnnt 15.514119 hw_loss 0.337347 history loss 17.885650 rank 4
2023-02-11 07:58:32,631 DEBUG CV Batch 3/1500 loss 21.168747 loss_att 20.292044 loss_ctc 23.999481 loss_rnnt 17.082369 hw_loss 0.728304 history loss 17.638163 rank 0
2023-02-11 07:58:32,846 DEBUG CV Batch 3/1500 loss 21.168747 loss_att 20.292044 loss_ctc 23.999481 loss_rnnt 17.082369 hw_loss 0.728304 history loss 17.638163 rank 7
2023-02-11 07:58:33,325 DEBUG CV Batch 3/1500 loss 21.168747 loss_att 20.292044 loss_ctc 23.999481 loss_rnnt 17.082369 hw_loss 0.728304 history loss 17.638163 rank 5
2023-02-11 07:58:33,364 DEBUG CV Batch 3/1500 loss 21.168747 loss_att 20.292044 loss_ctc 23.999481 loss_rnnt 17.082369 hw_loss 0.728304 history loss 17.638163 rank 3
2023-02-11 07:58:35,170 DEBUG CV Batch 3/1500 loss 21.168747 loss_att 20.292044 loss_ctc 23.999481 loss_rnnt 17.082369 hw_loss 0.728304 history loss 17.638163 rank 2
2023-02-11 07:58:36,859 DEBUG CV Batch 3/1500 loss 21.168747 loss_att 20.292044 loss_ctc 23.999481 loss_rnnt 17.082369 hw_loss 0.728304 history loss 17.638163 rank 6
2023-02-11 07:58:38,061 DEBUG CV Batch 3/1500 loss 21.168747 loss_att 20.292044 loss_ctc 23.999481 loss_rnnt 17.082369 hw_loss 0.728304 history loss 17.638163 rank 1
2023-02-11 07:58:38,981 DEBUG CV Batch 3/1500 loss 21.168747 loss_att 20.292044 loss_ctc 23.999481 loss_rnnt 17.082369 hw_loss 0.728304 history loss 17.638163 rank 4
2023-02-11 07:58:45,889 DEBUG CV Batch 3/1600 loss 19.836237 loss_att 35.203819 loss_ctc 28.845327 loss_rnnt 13.184074 hw_loss 0.445769 history loss 17.505034 rank 7
2023-02-11 07:58:46,063 DEBUG CV Batch 3/1600 loss 19.836237 loss_att 35.203819 loss_ctc 28.845327 loss_rnnt 13.184074 hw_loss 0.445769 history loss 17.505034 rank 0
2023-02-11 07:58:46,705 DEBUG CV Batch 3/1600 loss 19.836237 loss_att 35.203819 loss_ctc 28.845327 loss_rnnt 13.184074 hw_loss 0.445769 history loss 17.505034 rank 5
2023-02-11 07:58:47,003 DEBUG CV Batch 3/1600 loss 19.836237 loss_att 35.203819 loss_ctc 28.845327 loss_rnnt 13.184074 hw_loss 0.445769 history loss 17.505034 rank 3
2023-02-11 07:58:48,451 DEBUG CV Batch 3/1600 loss 19.836237 loss_att 35.203819 loss_ctc 28.845327 loss_rnnt 13.184074 hw_loss 0.445769 history loss 17.505034 rank 2
2023-02-11 07:58:50,318 DEBUG CV Batch 3/1600 loss 19.836237 loss_att 35.203819 loss_ctc 28.845327 loss_rnnt 13.184074 hw_loss 0.445769 history loss 17.505034 rank 6
2023-02-11 07:58:51,538 DEBUG CV Batch 3/1600 loss 19.836237 loss_att 35.203819 loss_ctc 28.845327 loss_rnnt 13.184074 hw_loss 0.445769 history loss 17.505034 rank 1
2023-02-11 07:58:52,164 DEBUG CV Batch 3/1600 loss 19.836237 loss_att 35.203819 loss_ctc 28.845327 loss_rnnt 13.184074 hw_loss 0.445769 history loss 17.505034 rank 4
2023-02-11 07:58:58,374 DEBUG CV Batch 3/1700 loss 21.987503 loss_att 18.353811 loss_ctc 28.063477 loss_rnnt 15.944609 hw_loss 1.117407 history loss 17.353433 rank 7
2023-02-11 07:58:58,482 DEBUG CV Batch 3/1700 loss 21.987503 loss_att 18.353811 loss_ctc 28.063477 loss_rnnt 15.944609 hw_loss 1.117407 history loss 17.353433 rank 0
2023-02-11 07:58:59,219 DEBUG CV Batch 3/1700 loss 21.987503 loss_att 18.353811 loss_ctc 28.063477 loss_rnnt 15.944609 hw_loss 1.117407 history loss 17.353433 rank 5
2023-02-11 07:58:59,414 DEBUG CV Batch 3/1700 loss 21.987503 loss_att 18.353811 loss_ctc 28.063477 loss_rnnt 15.944609 hw_loss 1.117407 history loss 17.353433 rank 3
2023-02-11 07:59:00,898 DEBUG CV Batch 3/1700 loss 21.987503 loss_att 18.353811 loss_ctc 28.063477 loss_rnnt 15.944609 hw_loss 1.117407 history loss 17.353433 rank 2
2023-02-11 07:59:02,724 DEBUG CV Batch 3/1700 loss 21.987503 loss_att 18.353811 loss_ctc 28.063477 loss_rnnt 15.944609 hw_loss 1.117407 history loss 17.353433 rank 6
2023-02-11 07:59:03,945 DEBUG CV Batch 3/1700 loss 21.987503 loss_att 18.353811 loss_ctc 28.063477 loss_rnnt 15.944609 hw_loss 1.117407 history loss 17.353433 rank 1
2023-02-11 07:59:05,618 DEBUG CV Batch 3/1700 loss 21.987503 loss_att 18.353811 loss_ctc 28.063477 loss_rnnt 15.944609 hw_loss 1.117407 history loss 17.353433 rank 4
2023-02-11 07:59:07,617 INFO Epoch 3 CV info cv_loss 17.282900448702787
2023-02-11 07:59:07,619 INFO Epoch 4 TRAIN info lr 0.0008661986608440464
2023-02-11 07:59:07,622 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 07:59:07,632 INFO Epoch 3 CV info cv_loss 17.28290045125272
2023-02-11 07:59:07,633 INFO Checkpoint: save to checkpoint exp2_10_rnnt_bias_loss/3.pt
2023-02-11 07:59:08,239 INFO Epoch 4 TRAIN info lr 0.0008651865794350749
2023-02-11 07:59:08,243 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 07:59:08,410 INFO Epoch 3 CV info cv_loss 17.28290045263106
2023-02-11 07:59:08,412 INFO Epoch 4 TRAIN info lr 0.0008656143345812724
2023-02-11 07:59:08,416 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 07:59:08,524 INFO Epoch 3 CV info cv_loss 17.282900456455955
2023-02-11 07:59:08,525 INFO Epoch 4 TRAIN info lr 0.0008658998574065672
2023-02-11 07:59:08,530 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 07:59:10,158 INFO Epoch 3 CV info cv_loss 17.282900449460875
2023-02-11 07:59:10,159 INFO Epoch 4 TRAIN info lr 0.0008650829766830049
2023-02-11 07:59:10,162 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 07:59:11,861 INFO Epoch 3 CV info cv_loss 17.28290045876468
2023-02-11 07:59:11,862 INFO Epoch 4 TRAIN info lr 0.0008660817009247153
2023-02-11 07:59:11,867 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 07:59:13,036 INFO Epoch 3 CV info cv_loss 17.282900455732328
2023-02-11 07:59:13,038 INFO Epoch 4 TRAIN info lr 0.0008652772623838088
2023-02-11 07:59:13,041 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 07:59:15,674 INFO Epoch 3 CV info cv_loss 17.28290044425764
2023-02-11 07:59:15,675 INFO Epoch 4 TRAIN info lr 0.0008661986608440464
2023-02-11 07:59:15,678 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 08:00:27,922 DEBUG TRAIN Batch 4/0 loss 20.713936 loss_att 13.943509 loss_ctc 17.801521 loss_rnnt 13.087731 hw_loss 1.756615 lr 0.00086517 rank 0
2023-02-11 08:00:27,922 DEBUG TRAIN Batch 4/0 loss 15.146532 loss_att 11.240965 loss_ctc 15.560037 loss_rnnt 9.751042 hw_loss 1.147776 lr 0.00086607 rank 6
2023-02-11 08:00:27,926 DEBUG TRAIN Batch 4/0 loss 15.388624 loss_att 12.273683 loss_ctc 16.218140 loss_rnnt 10.525043 hw_loss 1.007994 lr 0.00086560 rank 5
2023-02-11 08:00:27,927 DEBUG TRAIN Batch 4/0 loss 14.733354 loss_att 11.836047 loss_ctc 15.594707 loss_rnnt 10.954590 hw_loss 0.795633 lr 0.00086526 rank 1
2023-02-11 08:00:27,928 DEBUG TRAIN Batch 4/0 loss 15.627885 loss_att 12.609079 loss_ctc 16.770813 loss_rnnt 11.266057 hw_loss 0.902475 lr 0.00086589 rank 3
2023-02-11 08:00:27,930 DEBUG TRAIN Batch 4/0 loss 16.856331 loss_att 12.712401 loss_ctc 16.159737 loss_rnnt 12.628179 hw_loss 0.965591 lr 0.00086619 rank 7
2023-02-11 08:00:27,931 DEBUG TRAIN Batch 4/0 loss 21.331299 loss_att 16.145378 loss_ctc 17.587709 loss_rnnt 16.866779 hw_loss 1.125159 lr 0.00086507 rank 2
2023-02-11 08:00:28,016 DEBUG TRAIN Batch 4/0 loss 20.592167 loss_att 16.326775 loss_ctc 22.068388 loss_rnnt 15.980507 hw_loss 0.987733 lr 0.00086619 rank 4
2023-02-11 08:01:44,212 DEBUG TRAIN Batch 4/100 loss 15.088181 loss_att 24.426945 loss_ctc 25.550179 loss_rnnt 10.464397 hw_loss 0.255206 lr 0.00086459 rank 3
2023-02-11 08:01:44,215 DEBUG TRAIN Batch 4/100 loss 25.843288 loss_att 29.118160 loss_ctc 42.871117 loss_rnnt 20.067055 hw_loss 0.534540 lr 0.00086378 rank 2
2023-02-11 08:01:44,216 DEBUG TRAIN Batch 4/100 loss 25.131359 loss_att 35.809536 loss_ctc 46.268997 loss_rnnt 17.765944 hw_loss 0.452143 lr 0.00086431 rank 5
2023-02-11 08:01:44,217 DEBUG TRAIN Batch 4/100 loss 40.853214 loss_att 51.849762 loss_ctc 56.066124 loss_rnnt 36.269775 hw_loss 0.066701 lr 0.00086388 rank 0
2023-02-11 08:01:44,218 DEBUG TRAIN Batch 4/100 loss 27.502398 loss_att 33.678070 loss_ctc 42.433117 loss_rnnt 21.726162 hw_loss 0.478189 lr 0.00086489 rank 7
2023-02-11 08:01:44,220 DEBUG TRAIN Batch 4/100 loss 27.388279 loss_att 29.261557 loss_ctc 47.695068 loss_rnnt 20.881336 hw_loss 0.642134 lr 0.00086477 rank 6
2023-02-11 08:01:44,220 DEBUG TRAIN Batch 4/100 loss 21.845518 loss_att 29.454771 loss_ctc 33.171547 loss_rnnt 16.973289 hw_loss 0.345046 lr 0.00086489 rank 4
2023-02-11 08:01:44,222 DEBUG TRAIN Batch 4/100 loss 21.201075 loss_att 20.225800 loss_ctc 31.401672 loss_rnnt 17.244989 hw_loss 0.523323 lr 0.00086397 rank 1
2023-02-11 08:02:59,293 DEBUG TRAIN Batch 4/200 loss 17.659176 loss_att 22.683710 loss_ctc 24.358242 loss_rnnt 14.628487 hw_loss 0.212358 lr 0.00086360 rank 7
2023-02-11 08:02:59,298 DEBUG TRAIN Batch 4/200 loss 23.415827 loss_att 32.019859 loss_ctc 39.707367 loss_rnnt 17.022434 hw_loss 0.468822 lr 0.00086259 rank 0
2023-02-11 08:02:59,300 DEBUG TRAIN Batch 4/200 loss 16.695654 loss_att 19.690538 loss_ctc 31.376984 loss_rnnt 12.227150 hw_loss 0.358503 lr 0.00086330 rank 3
2023-02-11 08:02:59,301 DEBUG TRAIN Batch 4/200 loss 24.387436 loss_att 34.334740 loss_ctc 44.609146 loss_rnnt 17.394825 hw_loss 0.432548 lr 0.00086348 rank 6
2023-02-11 08:02:59,301 DEBUG TRAIN Batch 4/200 loss 56.903419 loss_att 63.531006 loss_ctc 76.889061 loss_rnnt 51.373772 hw_loss 0.288634 lr 0.00086249 rank 2
2023-02-11 08:02:59,303 DEBUG TRAIN Batch 4/200 loss 15.786506 loss_att 17.346889 loss_ctc 25.267635 loss_rnnt 13.177943 hw_loss 0.193563 lr 0.00086360 rank 4
2023-02-11 08:02:59,303 DEBUG TRAIN Batch 4/200 loss 16.992199 loss_att 24.126083 loss_ctc 25.746582 loss_rnnt 13.974827 hw_loss 0.079377 lr 0.00086268 rank 1
2023-02-11 08:02:59,305 DEBUG TRAIN Batch 4/200 loss 25.623505 loss_att 28.529388 loss_ctc 35.876259 loss_rnnt 20.401754 hw_loss 0.613789 lr 0.00086302 rank 5
2023-02-11 08:04:16,026 DEBUG TRAIN Batch 4/300 loss 22.362972 loss_att 27.345768 loss_ctc 33.162724 loss_rnnt 18.561821 hw_loss 0.255867 lr 0.00086231 rank 4
2023-02-11 08:04:16,028 DEBUG TRAIN Batch 4/300 loss 30.748606 loss_att 39.029228 loss_ctc 46.793793 loss_rnnt 22.322968 hw_loss 0.868154 lr 0.00086202 rank 3
2023-02-11 08:04:16,033 DEBUG TRAIN Batch 4/300 loss 22.102434 loss_att 31.423960 loss_ctc 36.475044 loss_rnnt 16.219320 hw_loss 0.394211 lr 0.00086220 rank 6
2023-02-11 08:04:16,033 DEBUG TRAIN Batch 4/300 loss 28.511337 loss_att 34.927311 loss_ctc 46.501556 loss_rnnt 22.118603 hw_loss 0.508283 lr 0.00086231 rank 7
2023-02-11 08:04:16,034 DEBUG TRAIN Batch 4/300 loss 22.763792 loss_att 28.385014 loss_ctc 36.773010 loss_rnnt 16.476894 hw_loss 0.617767 lr 0.00086121 rank 2
2023-02-11 08:04:16,035 DEBUG TRAIN Batch 4/300 loss 27.774933 loss_att 31.624630 loss_ctc 37.918591 loss_rnnt 22.053196 hw_loss 0.674870 lr 0.00086131 rank 0
2023-02-11 08:04:16,037 DEBUG TRAIN Batch 4/300 loss 28.336227 loss_att 28.565168 loss_ctc 37.913574 loss_rnnt 24.069916 hw_loss 0.551915 lr 0.00086140 rank 1
2023-02-11 08:04:16,040 DEBUG TRAIN Batch 4/300 loss 29.088943 loss_att 27.052618 loss_ctc 39.652580 loss_rnnt 24.201614 hw_loss 0.728646 lr 0.00086174 rank 5
2023-02-11 08:05:33,674 DEBUG TRAIN Batch 4/400 loss 20.791744 loss_att 23.516026 loss_ctc 30.221403 loss_rnnt 17.241516 hw_loss 0.327765 lr 0.00086074 rank 3
2023-02-11 08:05:33,675 DEBUG TRAIN Batch 4/400 loss 27.077271 loss_att 35.677769 loss_ctc 41.493538 loss_rnnt 21.902786 hw_loss 0.287291 lr 0.00085994 rank 2
2023-02-11 08:05:33,676 DEBUG TRAIN Batch 4/400 loss 35.621277 loss_att 45.693352 loss_ctc 49.748329 loss_rnnt 29.862688 hw_loss 0.348856 lr 0.00086046 rank 5
2023-02-11 08:05:33,677 DEBUG TRAIN Batch 4/400 loss 34.337044 loss_att 40.438644 loss_ctc 54.893787 loss_rnnt 28.476286 hw_loss 0.356164 lr 0.00086004 rank 0
2023-02-11 08:05:33,679 DEBUG TRAIN Batch 4/400 loss 30.975935 loss_att 35.100731 loss_ctc 38.408398 loss_rnnt 27.524471 hw_loss 0.306658 lr 0.00086103 rank 7
2023-02-11 08:05:33,682 DEBUG TRAIN Batch 4/400 loss 22.787199 loss_att 29.467617 loss_ctc 37.277111 loss_rnnt 17.355766 hw_loss 0.405630 lr 0.00086103 rank 4
2023-02-11 08:05:33,685 DEBUG TRAIN Batch 4/400 loss 33.888916 loss_att 43.148487 loss_ctc 49.440628 loss_rnnt 26.480482 hw_loss 0.653054 lr 0.00086013 rank 1
2023-02-11 08:05:33,685 DEBUG TRAIN Batch 4/400 loss 22.521490 loss_att 27.071308 loss_ctc 28.108608 loss_rnnt 17.424850 hw_loss 0.645324 lr 0.00086092 rank 6
2023-02-11 08:06:49,808 DEBUG TRAIN Batch 4/500 loss 40.697906 loss_att 38.533333 loss_ctc 51.373875 loss_rnnt 37.025700 hw_loss 0.502811 lr 0.00085947 rank 3
2023-02-11 08:06:49,808 DEBUG TRAIN Batch 4/500 loss 19.759806 loss_att 23.814615 loss_ctc 31.733440 loss_rnnt 14.492330 hw_loss 0.536255 lr 0.00085976 rank 7
2023-02-11 08:06:49,809 DEBUG TRAIN Batch 4/500 loss 20.329861 loss_att 23.052570 loss_ctc 25.063299 loss_rnnt 16.345837 hw_loss 0.526567 lr 0.00085877 rank 0
2023-02-11 08:06:49,809 DEBUG TRAIN Batch 4/500 loss 21.934244 loss_att 23.431019 loss_ctc 28.536196 loss_rnnt 14.369591 hw_loss 1.197195 lr 0.00085867 rank 2
2023-02-11 08:06:49,810 DEBUG TRAIN Batch 4/500 loss 23.111742 loss_att 25.076288 loss_ctc 35.290096 loss_rnnt 20.131905 hw_loss 0.180590 lr 0.00085886 rank 1
2023-02-11 08:06:49,814 DEBUG TRAIN Batch 4/500 loss 19.810312 loss_att 26.748650 loss_ctc 34.189865 loss_rnnt 14.989326 hw_loss 0.284258 lr 0.00085964 rank 6
2023-02-11 08:06:49,816 DEBUG TRAIN Batch 4/500 loss 18.401125 loss_att 23.045923 loss_ctc 32.762817 loss_rnnt 14.722265 hw_loss 0.156564 lr 0.00085919 rank 5
2023-02-11 08:06:49,861 DEBUG TRAIN Batch 4/500 loss 26.510830 loss_att 28.153435 loss_ctc 37.261230 loss_rnnt 19.651573 hw_loss 0.955753 lr 0.00085976 rank 4
2023-02-11 08:08:06,326 DEBUG TRAIN Batch 4/600 loss 29.036354 loss_att 27.797634 loss_ctc 42.206615 loss_rnnt 24.237167 hw_loss 0.617043 lr 0.00085751 rank 0
2023-02-11 08:08:06,332 DEBUG TRAIN Batch 4/600 loss 16.459503 loss_att 15.979958 loss_ctc 20.592327 loss_rnnt 13.902084 hw_loss 0.394178 lr 0.00085820 rank 3
2023-02-11 08:08:06,333 DEBUG TRAIN Batch 4/600 loss 43.714577 loss_att 43.151516 loss_ctc 54.286724 loss_rnnt 38.672329 hw_loss 0.702233 lr 0.00085838 rank 6
2023-02-11 08:08:06,333 DEBUG TRAIN Batch 4/600 loss 24.063070 loss_att 23.610912 loss_ctc 34.347439 loss_rnnt 19.741058 hw_loss 0.570224 lr 0.00085740 rank 2
2023-02-11 08:08:06,334 DEBUG TRAIN Batch 4/600 loss 15.572640 loss_att 14.559275 loss_ctc 19.015390 loss_rnnt 11.716292 hw_loss 0.674998 lr 0.00085792 rank 5
2023-02-11 08:08:06,335 DEBUG TRAIN Batch 4/600 loss 20.339819 loss_att 17.198265 loss_ctc 24.218592 loss_rnnt 15.422596 hw_loss 0.942818 lr 0.00085759 rank 1
2023-02-11 08:08:06,335 DEBUG TRAIN Batch 4/600 loss 28.657995 loss_att 27.209648 loss_ctc 36.308521 loss_rnnt 24.678183 hw_loss 0.609265 lr 0.00085849 rank 4
2023-02-11 08:08:06,338 DEBUG TRAIN Batch 4/600 loss 16.408575 loss_att 15.480627 loss_ctc 22.799376 loss_rnnt 12.361828 hw_loss 0.633793 lr 0.00085849 rank 7
2023-02-11 08:09:24,966 DEBUG TRAIN Batch 4/700 loss 27.301945 loss_att 34.686935 loss_ctc 39.083496 loss_rnnt 22.229393 hw_loss 0.379627 lr 0.00085694 rank 3
2023-02-11 08:09:24,977 DEBUG TRAIN Batch 4/700 loss 25.640453 loss_att 26.324251 loss_ctc 32.999050 loss_rnnt 20.471035 hw_loss 0.759659 lr 0.00085666 rank 5
2023-02-11 08:09:24,978 DEBUG TRAIN Batch 4/700 loss 10.893588 loss_att 18.689493 loss_ctc 17.111992 loss_rnnt 5.162023 hw_loss 0.626862 lr 0.00085615 rank 2
2023-02-11 08:09:24,986 DEBUG TRAIN Batch 4/700 loss 40.108822 loss_att 49.166130 loss_ctc 66.576164 loss_rnnt 34.198467 hw_loss 0.106859 lr 0.00085634 rank 1
2023-02-11 08:09:24,987 DEBUG TRAIN Batch 4/700 loss 31.917324 loss_att 33.719360 loss_ctc 43.683422 loss_rnnt 25.405323 hw_loss 0.859271 lr 0.00085723 rank 7
2023-02-11 08:09:24,991 DEBUG TRAIN Batch 4/700 loss 32.218853 loss_att 41.597218 loss_ctc 57.352768 loss_rnnt 23.884115 hw_loss 0.582727 lr 0.00085625 rank 0
2023-02-11 08:09:24,993 DEBUG TRAIN Batch 4/700 loss 16.919706 loss_att 22.178757 loss_ctc 33.916622 loss_rnnt 12.495163 hw_loss 0.207465 lr 0.00085711 rank 6
2023-02-11 08:09:25,028 DEBUG TRAIN Batch 4/700 loss 34.275257 loss_att 36.868156 loss_ctc 53.613110 loss_rnnt 25.419943 hw_loss 1.079691 lr 0.00085723 rank 4
2023-02-11 08:10:42,420 DEBUG TRAIN Batch 4/800 loss 24.814583 loss_att 31.002357 loss_ctc 41.563610 loss_rnnt 17.347183 hw_loss 0.749370 lr 0.00085508 rank 1
2023-02-11 08:10:42,421 DEBUG TRAIN Batch 4/800 loss 50.917637 loss_att 59.922241 loss_ctc 69.092728 loss_rnnt 42.987740 hw_loss 0.694806 lr 0.00085568 rank 3
2023-02-11 08:10:42,421 DEBUG TRAIN Batch 4/800 loss 12.024158 loss_att 18.033604 loss_ctc 23.426250 loss_rnnt 7.588674 hw_loss 0.321247 lr 0.00085499 rank 0
2023-02-11 08:10:42,423 DEBUG TRAIN Batch 4/800 loss 26.354542 loss_att 30.928061 loss_ctc 38.523422 loss_rnnt 18.216501 hw_loss 1.050153 lr 0.00085597 rank 4
2023-02-11 08:10:42,425 DEBUG TRAIN Batch 4/800 loss 22.120934 loss_att 24.585217 loss_ctc 28.353725 loss_rnnt 16.892729 hw_loss 0.732058 lr 0.00085597 rank 7
2023-02-11 08:10:42,425 DEBUG TRAIN Batch 4/800 loss 20.991159 loss_att 27.456673 loss_ctc 35.268368 loss_rnnt 16.650944 hw_loss 0.214403 lr 0.00085489 rank 2
2023-02-11 08:10:42,429 DEBUG TRAIN Batch 4/800 loss 27.384075 loss_att 25.464653 loss_ctc 34.941246 loss_rnnt 22.997265 hw_loss 0.705576 lr 0.00085541 rank 5
2023-02-11 08:10:42,430 DEBUG TRAIN Batch 4/800 loss 27.998606 loss_att 29.402699 loss_ctc 40.692314 loss_rnnt 21.964199 hw_loss 0.761455 lr 0.00085586 rank 6
2023-02-11 08:11:57,492 DEBUG TRAIN Batch 4/900 loss 22.557020 loss_att 26.499435 loss_ctc 32.196495 loss_rnnt 17.734835 hw_loss 0.515332 lr 0.00085375 rank 0
2023-02-11 08:11:57,493 DEBUG TRAIN Batch 4/900 loss 27.117949 loss_att 29.921640 loss_ctc 38.412590 loss_rnnt 23.204739 hw_loss 0.346222 lr 0.00085383 rank 1
2023-02-11 08:11:57,498 DEBUG TRAIN Batch 4/900 loss 30.650560 loss_att 35.174210 loss_ctc 38.350048 loss_rnnt 25.534842 hw_loss 0.597073 lr 0.00085416 rank 5
2023-02-11 08:11:57,498 DEBUG TRAIN Batch 4/900 loss 19.354586 loss_att 25.780113 loss_ctc 31.909084 loss_rnnt 15.603335 hw_loss 0.148540 lr 0.00085461 rank 6
2023-02-11 08:11:57,499 DEBUG TRAIN Batch 4/900 loss 30.205198 loss_att 33.465611 loss_ctc 46.153778 loss_rnnt 24.493393 hw_loss 0.549983 lr 0.00085443 rank 3
2023-02-11 08:11:57,501 DEBUG TRAIN Batch 4/900 loss 24.643505 loss_att 29.726757 loss_ctc 35.615116 loss_rnnt 19.637962 hw_loss 0.473627 lr 0.00085472 rank 4
2023-02-11 08:11:57,502 DEBUG TRAIN Batch 4/900 loss 17.973694 loss_att 20.457668 loss_ctc 23.394619 loss_rnnt 11.473826 hw_loss 0.990053 lr 0.00085365 rank 2
2023-02-11 08:11:57,502 DEBUG TRAIN Batch 4/900 loss 18.549109 loss_att 25.393330 loss_ctc 31.532246 loss_rnnt 13.626211 hw_loss 0.341806 lr 0.00085472 rank 7
2023-02-11 08:13:13,465 DEBUG TRAIN Batch 4/1000 loss 20.178553 loss_att 24.533659 loss_ctc 26.234182 loss_rnnt 14.739898 hw_loss 0.705041 lr 0.00085347 rank 7
2023-02-11 08:13:13,469 DEBUG TRAIN Batch 4/1000 loss 18.698771 loss_att 23.882244 loss_ctc 31.750965 loss_rnnt 13.497999 hw_loss 0.454460 lr 0.00085291 rank 5
2023-02-11 08:13:13,470 DEBUG TRAIN Batch 4/1000 loss 43.273857 loss_att 47.670792 loss_ctc 65.535629 loss_rnnt 35.919609 hw_loss 0.657492 lr 0.00085336 rank 6
2023-02-11 08:13:13,470 DEBUG TRAIN Batch 4/1000 loss 20.569086 loss_att 23.275753 loss_ctc 35.046410 loss_rnnt 14.566965 hw_loss 0.661964 lr 0.00085347 rank 4
2023-02-11 08:13:13,470 DEBUG TRAIN Batch 4/1000 loss 17.361740 loss_att 18.774363 loss_ctc 22.661697 loss_rnnt 13.164227 hw_loss 0.601562 lr 0.00085319 rank 3
2023-02-11 08:13:13,472 DEBUG TRAIN Batch 4/1000 loss 31.144800 loss_att 35.568428 loss_ctc 49.071720 loss_rnnt 23.502804 hw_loss 0.818815 lr 0.00085251 rank 0
2023-02-11 08:13:13,475 DEBUG TRAIN Batch 4/1000 loss 25.708992 loss_att 27.759626 loss_ctc 38.208679 loss_rnnt 21.631207 hw_loss 0.375194 lr 0.00085259 rank 1
2023-02-11 08:13:13,520 DEBUG TRAIN Batch 4/1000 loss 19.426949 loss_att 26.401766 loss_ctc 29.029165 loss_rnnt 14.000772 hw_loss 0.515796 lr 0.00085241 rank 2
2023-02-11 08:14:31,528 DEBUG TRAIN Batch 4/1100 loss 28.716354 loss_att 29.420063 loss_ctc 43.246040 loss_rnnt 23.172094 hw_loss 0.649917 lr 0.00085136 rank 1
2023-02-11 08:14:31,530 DEBUG TRAIN Batch 4/1100 loss 42.878231 loss_att 41.391533 loss_ctc 45.676624 loss_rnnt 38.557144 hw_loss 0.795996 lr 0.00085127 rank 0
2023-02-11 08:14:31,531 DEBUG TRAIN Batch 4/1100 loss 20.145302 loss_att 21.707472 loss_ctc 26.212484 loss_rnnt 16.561506 hw_loss 0.461701 lr 0.00085195 rank 3
2023-02-11 08:14:31,531 DEBUG TRAIN Batch 4/1100 loss 19.629858 loss_att 32.588608 loss_ctc 30.394066 loss_rnnt 12.387515 hw_loss 0.602881 lr 0.00085223 rank 7
2023-02-11 08:14:31,532 DEBUG TRAIN Batch 4/1100 loss 20.137177 loss_att 21.539005 loss_ctc 32.673122 loss_rnnt 15.615576 hw_loss 0.481833 lr 0.00085117 rank 2
2023-02-11 08:14:31,533 DEBUG TRAIN Batch 4/1100 loss 19.183027 loss_att 23.019176 loss_ctc 28.777725 loss_rnnt 15.300749 hw_loss 0.344204 lr 0.00085223 rank 4
2023-02-11 08:14:31,533 DEBUG TRAIN Batch 4/1100 loss 42.374355 loss_att 47.348751 loss_ctc 82.469276 loss_rnnt 34.590569 hw_loss 0.270547 lr 0.00085212 rank 6
2023-02-11 08:14:31,534 DEBUG TRAIN Batch 4/1100 loss 31.547693 loss_att 30.933775 loss_ctc 43.093529 loss_rnnt 24.498241 hw_loss 1.056149 lr 0.00085168 rank 5
2023-02-11 08:15:46,073 DEBUG TRAIN Batch 4/1200 loss 28.179953 loss_att 28.650059 loss_ctc 44.653587 loss_rnnt 23.026365 hw_loss 0.536827 lr 0.00085012 rank 1
2023-02-11 08:15:46,074 DEBUG TRAIN Batch 4/1200 loss 24.174154 loss_att 28.752922 loss_ctc 40.372089 loss_rnnt 18.982008 hw_loss 0.396876 lr 0.00084994 rank 2
2023-02-11 08:15:46,075 DEBUG TRAIN Batch 4/1200 loss 25.355110 loss_att 25.683830 loss_ctc 37.381821 loss_rnnt 18.554266 hw_loss 0.962163 lr 0.00085100 rank 7
2023-02-11 08:15:46,076 DEBUG TRAIN Batch 4/1200 loss 18.492929 loss_att 14.203825 loss_ctc 18.956509 loss_rnnt 12.300602 hw_loss 1.310313 lr 0.00085100 rank 4
2023-02-11 08:15:46,076 DEBUG TRAIN Batch 4/1200 loss 33.111126 loss_att 34.545731 loss_ctc 44.975502 loss_rnnt 28.325966 hw_loss 0.546810 lr 0.00085071 rank 3
2023-02-11 08:15:46,077 DEBUG TRAIN Batch 4/1200 loss 26.779572 loss_att 30.713888 loss_ctc 41.914883 loss_rnnt 20.699097 hw_loss 0.614169 lr 0.00085089 rank 6
2023-02-11 08:15:46,077 DEBUG TRAIN Batch 4/1200 loss 24.691616 loss_att 30.582384 loss_ctc 39.811337 loss_rnnt 17.952114 hw_loss 0.664760 lr 0.00085044 rank 5
2023-02-11 08:15:46,077 DEBUG TRAIN Batch 4/1200 loss 20.273605 loss_att 23.598122 loss_ctc 31.930073 loss_rnnt 14.389236 hw_loss 0.687238 lr 0.00085004 rank 0
2023-02-11 08:17:02,906 DEBUG TRAIN Batch 4/1300 loss 21.903082 loss_att 25.376560 loss_ctc 34.584053 loss_rnnt 16.577095 hw_loss 0.551342 lr 0.00084881 rank 0
2023-02-11 08:17:02,907 DEBUG TRAIN Batch 4/1300 loss 15.943757 loss_att 13.288549 loss_ctc 18.617722 loss_rnnt 13.173390 hw_loss 0.552165 lr 0.00084890 rank 1
2023-02-11 08:17:02,909 DEBUG TRAIN Batch 4/1300 loss 14.421307 loss_att 22.449001 loss_ctc 33.253262 loss_rnnt 8.882126 hw_loss 0.266759 lr 0.00084871 rank 2
2023-02-11 08:17:02,912 DEBUG TRAIN Batch 4/1300 loss 29.074234 loss_att 36.299526 loss_ctc 47.684616 loss_rnnt 22.216766 hw_loss 0.549567 lr 0.00084966 rank 6
2023-02-11 08:17:02,915 DEBUG TRAIN Batch 4/1300 loss 19.306034 loss_att 24.689560 loss_ctc 29.922821 loss_rnnt 16.435888 hw_loss 0.070850 lr 0.00084922 rank 5
2023-02-11 08:17:02,923 DEBUG TRAIN Batch 4/1300 loss 21.162340 loss_att 15.282495 loss_ctc 22.600445 loss_rnnt 15.260660 hw_loss 1.291106 lr 0.00084977 rank 7
2023-02-11 08:17:02,933 DEBUG TRAIN Batch 4/1300 loss 31.292879 loss_att 35.891018 loss_ctc 48.663742 loss_rnnt 27.172470 hw_loss 0.165875 lr 0.00084949 rank 3
2023-02-11 08:17:02,960 DEBUG TRAIN Batch 4/1300 loss 29.916004 loss_att 38.849369 loss_ctc 54.786980 loss_rnnt 24.619358 hw_loss 0.036345 lr 0.00084977 rank 4
2023-02-11 08:18:22,081 DEBUG TRAIN Batch 4/1400 loss 28.997921 loss_att 38.637157 loss_ctc 44.576752 loss_rnnt 22.378241 hw_loss 0.490248 lr 0.00084759 rank 0
2023-02-11 08:18:22,086 DEBUG TRAIN Batch 4/1400 loss 35.940193 loss_att 40.575985 loss_ctc 52.258347 loss_rnnt 30.315550 hw_loss 0.472824 lr 0.00084826 rank 3
2023-02-11 08:18:22,089 DEBUG TRAIN Batch 4/1400 loss 26.861366 loss_att 35.331444 loss_ctc 44.457535 loss_rnnt 20.227598 hw_loss 0.486299 lr 0.00084843 rank 6
2023-02-11 08:18:22,088 DEBUG TRAIN Batch 4/1400 loss 31.971132 loss_att 43.055672 loss_ctc 56.516197 loss_rnnt 24.908842 hw_loss 0.294882 lr 0.00084799 rank 5
2023-02-11 08:18:22,088 DEBUG TRAIN Batch 4/1400 loss 18.224390 loss_att 23.739983 loss_ctc 35.107971 loss_rnnt 12.782066 hw_loss 0.391511 lr 0.00084749 rank 2
2023-02-11 08:18:22,088 DEBUG TRAIN Batch 4/1400 loss 13.873254 loss_att 15.582398 loss_ctc 21.175564 loss_rnnt 7.712229 hw_loss 0.908542 lr 0.00084854 rank 7
2023-02-11 08:18:22,090 DEBUG TRAIN Batch 4/1400 loss 53.847263 loss_att 64.502884 loss_ctc 84.106339 loss_rnnt 45.635956 hw_loss 0.383558 lr 0.00084768 rank 1
2023-02-11 08:18:22,096 DEBUG TRAIN Batch 4/1400 loss 19.730118 loss_att 23.826920 loss_ctc 35.489525 loss_rnnt 13.757144 hw_loss 0.572317 lr 0.00084854 rank 4
2023-02-11 08:19:38,128 DEBUG TRAIN Batch 4/1500 loss 23.192108 loss_att 27.345798 loss_ctc 31.411007 loss_rnnt 20.537354 hw_loss 0.136531 lr 0.00084646 rank 1
2023-02-11 08:19:38,130 DEBUG TRAIN Batch 4/1500 loss 29.017048 loss_att 37.937286 loss_ctc 35.231319 loss_rnnt 22.239418 hw_loss 0.780940 lr 0.00084638 rank 0
2023-02-11 08:19:38,132 DEBUG TRAIN Batch 4/1500 loss 44.879276 loss_att 49.949959 loss_ctc 53.681084 loss_rnnt 39.045788 hw_loss 0.683584 lr 0.00084704 rank 3
2023-02-11 08:19:38,135 DEBUG TRAIN Batch 4/1500 loss 20.505003 loss_att 27.594410 loss_ctc 38.876942 loss_rnnt 14.884592 hw_loss 0.328676 lr 0.00084721 rank 6
2023-02-11 08:19:38,135 DEBUG TRAIN Batch 4/1500 loss 22.725313 loss_att 30.438643 loss_ctc 40.646580 loss_rnnt 17.118931 hw_loss 0.313915 lr 0.00084732 rank 7
2023-02-11 08:19:38,135 DEBUG TRAIN Batch 4/1500 loss 26.865307 loss_att 29.681570 loss_ctc 38.685219 loss_rnnt 22.293247 hw_loss 0.456153 lr 0.00084678 rank 5
2023-02-11 08:19:38,137 DEBUG TRAIN Batch 4/1500 loss 37.746124 loss_att 38.125751 loss_ctc 44.078156 loss_rnnt 33.426987 hw_loss 0.637302 lr 0.00084628 rank 2
2023-02-11 08:19:38,140 DEBUG TRAIN Batch 4/1500 loss 19.569712 loss_att 28.228472 loss_ctc 31.233324 loss_rnnt 13.157608 hw_loss 0.585975 lr 0.00084732 rank 4
2023-02-11 08:20:51,953 DEBUG TRAIN Batch 4/1600 loss 27.004747 loss_att 30.674568 loss_ctc 42.468525 loss_rnnt 20.323658 hw_loss 0.728492 lr 0.00084611 rank 7
2023-02-11 08:20:51,955 DEBUG TRAIN Batch 4/1600 loss 33.230515 loss_att 37.159294 loss_ctc 44.414566 loss_rnnt 27.187027 hw_loss 0.706223 lr 0.00084600 rank 6
2023-02-11 08:20:51,959 DEBUG TRAIN Batch 4/1600 loss 28.528286 loss_att 38.285965 loss_ctc 44.497498 loss_rnnt 23.751522 hw_loss 0.130500 lr 0.00084583 rank 3
2023-02-11 08:20:51,962 DEBUG TRAIN Batch 4/1600 loss 17.947058 loss_att 25.186897 loss_ctc 24.446705 loss_rnnt 12.254532 hw_loss 0.633363 lr 0.00084525 rank 1
2023-02-11 08:20:51,964 DEBUG TRAIN Batch 4/1600 loss 24.274530 loss_att 28.716354 loss_ctc 36.076729 loss_rnnt 19.915234 hw_loss 0.355745 lr 0.00084507 rank 2
2023-02-11 08:20:51,966 DEBUG TRAIN Batch 4/1600 loss 43.236053 loss_att 54.684799 loss_ctc 73.372070 loss_rnnt 34.035866 hw_loss 0.542307 lr 0.00084611 rank 4
2023-02-11 08:20:51,992 DEBUG TRAIN Batch 4/1600 loss 32.349487 loss_att 37.756039 loss_ctc 45.161430 loss_rnnt 26.843010 hw_loss 0.509420 lr 0.00084517 rank 0
2023-02-11 08:20:52,004 DEBUG TRAIN Batch 4/1600 loss 16.680162 loss_att 21.750751 loss_ctc 28.371372 loss_rnnt 12.723778 hw_loss 0.259394 lr 0.00084557 rank 5
2023-02-11 08:22:07,799 DEBUG TRAIN Batch 4/1700 loss 20.952543 loss_att 20.559849 loss_ctc 33.596569 loss_rnnt 14.396462 hw_loss 0.927890 lr 0.00084396 rank 0
2023-02-11 08:22:07,802 DEBUG TRAIN Batch 4/1700 loss 54.782204 loss_att 52.049591 loss_ctc 70.545609 loss_rnnt 49.338730 hw_loss 0.729039 lr 0.00084490 rank 7
2023-02-11 08:22:07,802 DEBUG TRAIN Batch 4/1700 loss 51.669373 loss_att 57.933319 loss_ctc 73.209259 loss_rnnt 42.487774 hw_loss 0.948155 lr 0.00084462 rank 3
2023-02-11 08:22:07,804 DEBUG TRAIN Batch 4/1700 loss 19.763458 loss_att 28.348928 loss_ctc 29.864700 loss_rnnt 13.132000 hw_loss 0.668912 lr 0.00084405 rank 1
2023-02-11 08:22:07,805 DEBUG TRAIN Batch 4/1700 loss 21.162407 loss_att 27.579647 loss_ctc 33.557076 loss_rnnt 13.980924 hw_loss 0.796015 lr 0.00084479 rank 6
2023-02-11 08:22:07,807 DEBUG TRAIN Batch 4/1700 loss 26.835274 loss_att 30.437000 loss_ctc 38.997063 loss_rnnt 21.550493 hw_loss 0.551787 lr 0.00084436 rank 5
2023-02-11 08:22:07,811 DEBUG TRAIN Batch 4/1700 loss 16.730614 loss_att 22.036358 loss_ctc 25.216427 loss_rnnt 12.252285 hw_loss 0.428576 lr 0.00084387 rank 2
2023-02-11 08:22:07,811 DEBUG TRAIN Batch 4/1700 loss 22.063616 loss_att 25.046040 loss_ctc 32.159595 loss_rnnt 16.956348 hw_loss 0.593372 lr 0.00084490 rank 4
2023-02-11 08:23:26,789 DEBUG TRAIN Batch 4/1800 loss 17.581703 loss_att 23.585703 loss_ctc 25.130148 loss_rnnt 14.195349 hw_loss 0.221081 lr 0.00084267 rank 2
2023-02-11 08:23:26,789 DEBUG TRAIN Batch 4/1800 loss 31.410231 loss_att 30.074654 loss_ctc 36.224434 loss_rnnt 27.120001 hw_loss 0.734147 lr 0.00084342 rank 3
2023-02-11 08:23:26,795 DEBUG TRAIN Batch 4/1800 loss 17.356791 loss_att 18.999517 loss_ctc 24.930019 loss_rnnt 13.504182 hw_loss 0.471431 lr 0.00084276 rank 0
2023-02-11 08:23:26,797 DEBUG TRAIN Batch 4/1800 loss 25.147324 loss_att 31.129971 loss_ctc 34.563995 loss_rnnt 21.216726 hw_loss 0.277221 lr 0.00084285 rank 1
2023-02-11 08:23:26,797 DEBUG TRAIN Batch 4/1800 loss 19.232420 loss_att 17.100939 loss_ctc 23.874067 loss_rnnt 15.232954 hw_loss 0.713789 lr 0.00084370 rank 4
2023-02-11 08:23:26,797 DEBUG TRAIN Batch 4/1800 loss 35.729446 loss_att 37.665764 loss_ctc 46.275002 loss_rnnt 30.647242 hw_loss 0.616662 lr 0.00084359 rank 6
2023-02-11 08:23:26,799 DEBUG TRAIN Batch 4/1800 loss 26.805967 loss_att 33.598454 loss_ctc 45.288246 loss_rnnt 19.824751 hw_loss 0.592203 lr 0.00084316 rank 5
2023-02-11 08:23:26,801 DEBUG TRAIN Batch 4/1800 loss 15.896708 loss_att 20.956717 loss_ctc 26.310532 loss_rnnt 11.282340 hw_loss 0.415098 lr 0.00084370 rank 7
2023-02-11 08:24:42,321 DEBUG TRAIN Batch 4/1900 loss 28.915939 loss_att 29.473038 loss_ctc 36.042648 loss_rnnt 23.886620 hw_loss 0.743938 lr 0.00084250 rank 7
2023-02-11 08:24:42,328 DEBUG TRAIN Batch 4/1900 loss 47.169174 loss_att 55.199673 loss_ctc 78.062302 loss_rnnt 39.714058 hw_loss 0.324361 lr 0.00084222 rank 3
2023-02-11 08:24:42,329 DEBUG TRAIN Batch 4/1900 loss 15.580708 loss_att 13.216240 loss_ctc 16.433739 loss_rnnt 10.663486 hw_loss 0.989321 lr 0.00084239 rank 6
2023-02-11 08:24:42,329 DEBUG TRAIN Batch 4/1900 loss 44.183350 loss_att 53.162621 loss_ctc 64.826248 loss_rnnt 34.941936 hw_loss 0.879971 lr 0.00084250 rank 4
2023-02-11 08:24:42,329 DEBUG TRAIN Batch 4/1900 loss 21.315689 loss_att 18.501740 loss_ctc 22.573795 loss_rnnt 15.774413 hw_loss 1.113060 lr 0.00084157 rank 0
2023-02-11 08:24:42,330 DEBUG TRAIN Batch 4/1900 loss 24.020573 loss_att 20.137751 loss_ctc 25.844173 loss_rnnt 18.256475 hw_loss 1.180784 lr 0.00084196 rank 5
2023-02-11 08:24:42,331 DEBUG TRAIN Batch 4/1900 loss 26.986954 loss_att 26.062717 loss_ctc 31.159883 loss_rnnt 21.448320 hw_loss 0.968829 lr 0.00084165 rank 1
2023-02-11 08:24:42,335 DEBUG TRAIN Batch 4/1900 loss 24.076384 loss_att 23.980959 loss_ctc 33.779171 loss_rnnt 19.367712 hw_loss 0.643885 lr 0.00084147 rank 2
2023-02-11 08:25:57,817 DEBUG TRAIN Batch 4/2000 loss 21.251644 loss_att 27.863327 loss_ctc 33.727203 loss_rnnt 14.943214 hw_loss 0.623004 lr 0.00084103 rank 3
2023-02-11 08:25:57,817 DEBUG TRAIN Batch 4/2000 loss 14.351811 loss_att 21.084740 loss_ctc 25.278128 loss_rnnt 10.071674 hw_loss 0.276883 lr 0.00084038 rank 0
2023-02-11 08:25:57,817 DEBUG TRAIN Batch 4/2000 loss 40.397556 loss_att 40.917660 loss_ctc 60.721466 loss_rnnt 32.724670 hw_loss 0.911064 lr 0.00084046 rank 1
2023-02-11 08:25:57,817 DEBUG TRAIN Batch 4/2000 loss 22.434719 loss_att 28.507339 loss_ctc 41.287205 loss_rnnt 16.754141 hw_loss 0.366073 lr 0.00084028 rank 2
2023-02-11 08:25:57,819 DEBUG TRAIN Batch 4/2000 loss 28.472773 loss_att 31.189096 loss_ctc 47.116554 loss_rnnt 23.527794 hw_loss 0.359227 lr 0.00084131 rank 4
2023-02-11 08:25:57,822 DEBUG TRAIN Batch 4/2000 loss 37.703274 loss_att 40.702175 loss_ctc 58.649700 loss_rnnt 32.836376 hw_loss 0.276424 lr 0.00084077 rank 5
2023-02-11 08:25:57,823 DEBUG TRAIN Batch 4/2000 loss 19.453909 loss_att 25.833532 loss_ctc 29.588226 loss_rnnt 14.298275 hw_loss 0.474087 lr 0.00084131 rank 7
2023-02-11 08:25:57,825 DEBUG TRAIN Batch 4/2000 loss 28.089146 loss_att 32.317459 loss_ctc 40.040218 loss_rnnt 22.119156 hw_loss 0.662034 lr 0.00084120 rank 6
2023-02-11 08:27:16,332 DEBUG TRAIN Batch 4/2100 loss 18.509834 loss_att 22.966305 loss_ctc 29.053524 loss_rnnt 13.258444 hw_loss 0.553926 lr 0.00083984 rank 3
2023-02-11 08:27:16,331 DEBUG TRAIN Batch 4/2100 loss 25.988510 loss_att 28.433325 loss_ctc 40.653656 loss_rnnt 22.013212 hw_loss 0.287059 lr 0.00084012 rank 7
2023-02-11 08:27:16,331 DEBUG TRAIN Batch 4/2100 loss 17.014225 loss_att 22.111153 loss_ctc 21.059402 loss_rnnt 13.078459 hw_loss 0.445692 lr 0.00083910 rank 2
2023-02-11 08:27:16,335 DEBUG TRAIN Batch 4/2100 loss 32.792088 loss_att 31.161209 loss_ctc 39.333271 loss_rnnt 30.351400 hw_loss 0.355258 lr 0.00084001 rank 6
2023-02-11 08:27:16,336 DEBUG TRAIN Batch 4/2100 loss 18.425463 loss_att 23.419056 loss_ctc 29.860342 loss_rnnt 14.082703 hw_loss 0.341135 lr 0.00083919 rank 0
2023-02-11 08:27:16,337 DEBUG TRAIN Batch 4/2100 loss 22.482803 loss_att 26.151966 loss_ctc 32.917965 loss_rnnt 17.870771 hw_loss 0.466284 lr 0.00083958 rank 5
2023-02-11 08:27:16,338 DEBUG TRAIN Batch 4/2100 loss 27.693426 loss_att 33.097763 loss_ctc 45.068615 loss_rnnt 22.200407 hw_loss 0.392899 lr 0.00084012 rank 4
2023-02-11 08:27:16,339 DEBUG TRAIN Batch 4/2100 loss 24.970789 loss_att 29.036438 loss_ctc 35.271584 loss_rnnt 22.104427 hw_loss 0.127461 lr 0.00083928 rank 1
2023-02-11 08:28:33,172 DEBUG TRAIN Batch 4/2200 loss 36.440823 loss_att 38.360725 loss_ctc 50.055038 loss_rnnt 30.101883 hw_loss 0.776199 lr 0.00083810 rank 1
2023-02-11 08:28:33,173 DEBUG TRAIN Batch 4/2200 loss 25.875992 loss_att 31.692442 loss_ctc 39.126522 loss_rnnt 20.693193 hw_loss 0.422394 lr 0.00083866 rank 3
2023-02-11 08:28:33,174 DEBUG TRAIN Batch 4/2200 loss 29.887938 loss_att 34.866440 loss_ctc 44.898743 loss_rnnt 24.574818 hw_loss 0.434245 lr 0.00083801 rank 0
2023-02-11 08:28:33,174 DEBUG TRAIN Batch 4/2200 loss 45.494785 loss_att 51.467678 loss_ctc 61.586102 loss_rnnt 41.179279 hw_loss 0.182891 lr 0.00083883 rank 6
2023-02-11 08:28:33,175 DEBUG TRAIN Batch 4/2200 loss 33.211494 loss_att 41.087227 loss_ctc 53.090729 loss_rnnt 26.727783 hw_loss 0.423375 lr 0.00083792 rank 2
2023-02-11 08:28:33,177 DEBUG TRAIN Batch 4/2200 loss 29.059717 loss_att 35.087395 loss_ctc 44.238258 loss_rnnt 24.387299 hw_loss 0.270577 lr 0.00083893 rank 7
2023-02-11 08:28:33,179 DEBUG TRAIN Batch 4/2200 loss 29.050097 loss_att 35.064461 loss_ctc 39.156525 loss_rnnt 23.861439 hw_loss 0.494673 lr 0.00083840 rank 5
2023-02-11 08:28:33,180 DEBUG TRAIN Batch 4/2200 loss 24.371748 loss_att 30.996475 loss_ctc 35.916233 loss_rnnt 17.946726 hw_loss 0.667652 lr 0.00083893 rank 4
2023-02-11 08:29:48,985 DEBUG TRAIN Batch 4/2300 loss 22.683950 loss_att 26.917650 loss_ctc 38.045170 loss_rnnt 17.275610 hw_loss 0.471270 lr 0.00083684 rank 0
2023-02-11 08:29:48,988 DEBUG TRAIN Batch 4/2300 loss 16.760042 loss_att 17.868769 loss_ctc 22.476151 loss_rnnt 13.221544 hw_loss 0.478988 lr 0.00083675 rank 2
2023-02-11 08:29:48,989 DEBUG TRAIN Batch 4/2300 loss 49.392719 loss_att 58.882301 loss_ctc 74.581673 loss_rnnt 40.861057 hw_loss 0.614102 lr 0.00083748 rank 3
2023-02-11 08:29:48,992 DEBUG TRAIN Batch 4/2300 loss 19.038605 loss_att 21.823738 loss_ctc 26.781658 loss_rnnt 14.503919 hw_loss 0.552235 lr 0.00083765 rank 6
2023-02-11 08:29:48,993 DEBUG TRAIN Batch 4/2300 loss 14.022820 loss_att 16.468517 loss_ctc 21.946058 loss_rnnt 9.197001 hw_loss 0.615047 lr 0.00083723 rank 5
2023-02-11 08:29:48,994 DEBUG TRAIN Batch 4/2300 loss 26.886162 loss_att 28.357834 loss_ctc 32.916836 loss_rnnt 25.321302 hw_loss 0.087457 lr 0.00083775 rank 7
2023-02-11 08:29:48,995 DEBUG TRAIN Batch 4/2300 loss 20.160175 loss_att 22.436848 loss_ctc 33.702179 loss_rnnt 14.613954 hw_loss 0.615991 lr 0.00083692 rank 1
2023-02-11 08:29:49,046 DEBUG TRAIN Batch 4/2300 loss 20.378639 loss_att 22.968893 loss_ctc 29.296095 loss_rnnt 15.914689 hw_loss 0.516919 lr 0.00083775 rank 4
2023-02-11 08:31:05,585 DEBUG TRAIN Batch 4/2400 loss 32.604206 loss_att 33.356003 loss_ctc 42.688835 loss_rnnt 29.080492 hw_loss 0.380387 lr 0.00083631 rank 3
2023-02-11 08:31:05,588 DEBUG TRAIN Batch 4/2400 loss 41.924423 loss_att 38.053986 loss_ctc 54.667927 loss_rnnt 39.356785 hw_loss 0.307986 lr 0.00083567 rank 0
2023-02-11 08:31:05,589 DEBUG TRAIN Batch 4/2400 loss 33.019424 loss_att 39.647518 loss_ctc 53.903111 loss_rnnt 26.770889 hw_loss 0.400955 lr 0.00083658 rank 7
2023-02-11 08:31:05,590 DEBUG TRAIN Batch 4/2400 loss 21.952511 loss_att 26.471527 loss_ctc 34.761368 loss_rnnt 15.737496 hw_loss 0.675630 lr 0.00083605 rank 5
2023-02-11 08:31:05,594 DEBUG TRAIN Batch 4/2400 loss 15.976061 loss_att 23.501675 loss_ctc 25.027494 loss_rnnt 11.190155 hw_loss 0.388861 lr 0.00083575 rank 1
2023-02-11 08:31:05,596 DEBUG TRAIN Batch 4/2400 loss 27.305901 loss_att 30.764881 loss_ctc 35.887573 loss_rnnt 24.195168 hw_loss 0.239009 lr 0.00083558 rank 2
2023-02-11 08:31:05,601 DEBUG TRAIN Batch 4/2400 loss 30.896612 loss_att 35.168327 loss_ctc 53.021435 loss_rnnt 26.226696 hw_loss 0.162300 lr 0.00083648 rank 6
2023-02-11 08:31:05,615 DEBUG TRAIN Batch 4/2400 loss 26.077860 loss_att 25.959888 loss_ctc 36.756142 loss_rnnt 23.121469 hw_loss 0.291790 lr 0.00083658 rank 4
2023-02-11 08:32:24,074 DEBUG TRAIN Batch 4/2500 loss 17.365110 loss_att 19.221727 loss_ctc 23.427237 loss_rnnt 12.717029 hw_loss 0.650339 lr 0.00083450 rank 0
2023-02-11 08:32:24,078 DEBUG TRAIN Batch 4/2500 loss 30.071465 loss_att 30.979773 loss_ctc 39.771538 loss_rnnt 26.055569 hw_loss 0.476418 lr 0.00083531 rank 6
2023-02-11 08:32:24,080 DEBUG TRAIN Batch 4/2500 loss 22.442171 loss_att 21.727880 loss_ctc 26.068703 loss_rnnt 18.655781 hw_loss 0.646071 lr 0.00083441 rank 2
2023-02-11 08:32:24,081 DEBUG TRAIN Batch 4/2500 loss 15.388083 loss_att 15.151831 loss_ctc 21.149622 loss_rnnt 10.307393 hw_loss 0.817450 lr 0.00083489 rank 5
2023-02-11 08:32:24,081 DEBUG TRAIN Batch 4/2500 loss 17.360952 loss_att 16.824202 loss_ctc 23.035208 loss_rnnt 12.498942 hw_loss 0.789899 lr 0.00083514 rank 3
2023-02-11 08:32:24,081 DEBUG TRAIN Batch 4/2500 loss 27.618027 loss_att 28.473965 loss_ctc 39.951641 loss_rnnt 22.253214 hw_loss 0.665464 lr 0.00083541 rank 7
2023-02-11 08:32:24,085 DEBUG TRAIN Batch 4/2500 loss 26.066420 loss_att 32.628860 loss_ctc 40.762390 loss_rnnt 22.094870 hw_loss 0.131175 lr 0.00083541 rank 4
2023-02-11 08:32:24,087 DEBUG TRAIN Batch 4/2500 loss 25.111561 loss_att 23.569347 loss_ctc 34.246498 loss_rnnt 21.482595 hw_loss 0.509890 lr 0.00083459 rank 1
2023-02-11 08:33:38,521 DEBUG TRAIN Batch 4/2600 loss 22.010269 loss_att 17.709366 loss_ctc 22.808441 loss_rnnt 15.847272 hw_loss 1.296892 lr 0.00083343 rank 1
2023-02-11 08:33:38,521 DEBUG TRAIN Batch 4/2600 loss 26.397228 loss_att 28.806793 loss_ctc 36.817894 loss_rnnt 22.158676 hw_loss 0.443853 lr 0.00083334 rank 0
2023-02-11 08:33:38,523 DEBUG TRAIN Batch 4/2600 loss 34.432846 loss_att 41.572990 loss_ctc 55.829784 loss_rnnt 28.402014 hw_loss 0.328102 lr 0.00083425 rank 4
2023-02-11 08:33:38,523 DEBUG TRAIN Batch 4/2600 loss 16.164322 loss_att 20.464951 loss_ctc 27.998037 loss_rnnt 12.840022 hw_loss 0.166189 lr 0.00083425 rank 7
2023-02-11 08:33:38,524 DEBUG TRAIN Batch 4/2600 loss 32.314793 loss_att 35.670010 loss_ctc 50.685909 loss_rnnt 26.636299 hw_loss 0.479619 lr 0.00083398 rank 3
2023-02-11 08:33:38,525 DEBUG TRAIN Batch 4/2600 loss 16.043919 loss_att 18.973448 loss_ctc 23.227919 loss_rnnt 9.886339 hw_loss 0.865089 lr 0.00083325 rank 2
2023-02-11 08:33:38,526 DEBUG TRAIN Batch 4/2600 loss 30.107506 loss_att 40.970421 loss_ctc 49.549866 loss_rnnt 23.865391 hw_loss 0.276978 lr 0.00083414 rank 6
2023-02-11 08:33:38,528 DEBUG TRAIN Batch 4/2600 loss 33.706505 loss_att 38.590164 loss_ctc 55.344326 loss_rnnt 27.264494 hw_loss 0.483794 lr 0.00083373 rank 5
2023-02-11 08:34:53,562 DEBUG TRAIN Batch 4/2700 loss 40.344585 loss_att 41.796211 loss_ctc 59.636520 loss_rnnt 34.015152 hw_loss 0.650035 lr 0.00083219 rank 0
2023-02-11 08:34:53,567 DEBUG TRAIN Batch 4/2700 loss 20.563259 loss_att 24.017834 loss_ctc 41.607464 loss_rnnt 15.602221 hw_loss 0.274543 lr 0.00083309 rank 4
2023-02-11 08:34:53,567 DEBUG TRAIN Batch 4/2700 loss 18.089655 loss_att 26.467857 loss_ctc 36.264359 loss_rnnt 13.827101 hw_loss 0.030679 lr 0.00083299 rank 6
2023-02-11 08:34:53,568 DEBUG TRAIN Batch 4/2700 loss 31.509115 loss_att 32.940510 loss_ctc 51.879196 loss_rnnt 24.367947 hw_loss 0.776040 lr 0.00083282 rank 3
2023-02-11 08:34:53,570 DEBUG TRAIN Batch 4/2700 loss 17.648155 loss_att 21.181526 loss_ctc 22.292721 loss_rnnt 12.521597 hw_loss 0.712615 lr 0.00083309 rank 7
2023-02-11 08:34:53,573 DEBUG TRAIN Batch 4/2700 loss 30.919355 loss_att 34.126217 loss_ctc 43.417721 loss_rnnt 27.011946 hw_loss 0.299923 lr 0.00083210 rank 2
2023-02-11 08:34:53,574 DEBUG TRAIN Batch 4/2700 loss 28.778280 loss_att 31.277420 loss_ctc 41.465660 loss_rnnt 25.428074 hw_loss 0.217261 lr 0.00083227 rank 1
2023-02-11 08:34:53,574 DEBUG TRAIN Batch 4/2700 loss 38.892113 loss_att 41.583511 loss_ctc 56.069702 loss_rnnt 33.500294 hw_loss 0.480599 lr 0.00083257 rank 5
2023-02-11 08:36:11,809 DEBUG TRAIN Batch 4/2800 loss 14.664686 loss_att 22.099516 loss_ctc 27.973995 loss_rnnt 9.911282 hw_loss 0.279725 lr 0.00083167 rank 3
2023-02-11 08:36:11,809 DEBUG TRAIN Batch 4/2800 loss 39.794952 loss_att 48.006504 loss_ctc 54.282928 loss_rnnt 34.405819 hw_loss 0.340330 lr 0.00083104 rank 0
2023-02-11 08:36:11,814 DEBUG TRAIN Batch 4/2800 loss 21.670780 loss_att 28.321724 loss_ctc 29.612988 loss_rnnt 14.167207 hw_loss 0.958954 lr 0.00083183 rank 6
2023-02-11 08:36:11,814 DEBUG TRAIN Batch 4/2800 loss 13.654995 loss_att 16.755909 loss_ctc 18.584692 loss_rnnt 8.657271 hw_loss 0.697546 lr 0.00083095 rank 2
2023-02-11 08:36:11,815 DEBUG TRAIN Batch 4/2800 loss 21.750420 loss_att 23.588150 loss_ctc 31.455730 loss_rnnt 16.141994 hw_loss 0.740032 lr 0.00083142 rank 5
2023-02-11 08:36:11,816 DEBUG TRAIN Batch 4/2800 loss 30.201433 loss_att 39.669422 loss_ctc 50.957741 loss_rnnt 24.319454 hw_loss 0.228914 lr 0.00083194 rank 4
2023-02-11 08:36:11,819 DEBUG TRAIN Batch 4/2800 loss 27.949209 loss_att 32.051231 loss_ctc 43.665569 loss_rnnt 23.869678 hw_loss 0.218176 lr 0.00083194 rank 7
2023-02-11 08:36:11,823 DEBUG TRAIN Batch 4/2800 loss 21.804516 loss_att 25.853523 loss_ctc 32.001495 loss_rnnt 18.052338 hw_loss 0.296771 lr 0.00083112 rank 1
2023-02-11 08:37:28,930 DEBUG TRAIN Batch 4/2900 loss 29.962347 loss_att 36.156990 loss_ctc 48.078033 loss_rnnt 24.952160 hw_loss 0.254218 lr 0.00083052 rank 3
2023-02-11 08:37:28,932 DEBUG TRAIN Batch 4/2900 loss 22.290861 loss_att 26.645203 loss_ctc 33.426582 loss_rnnt 17.453171 hw_loss 0.465386 lr 0.00083079 rank 7
2023-02-11 08:37:28,934 DEBUG TRAIN Batch 4/2900 loss 26.907999 loss_att 32.364609 loss_ctc 44.625164 loss_rnnt 21.870234 hw_loss 0.297029 lr 0.00082997 rank 1
2023-02-11 08:37:28,934 DEBUG TRAIN Batch 4/2900 loss 14.992759 loss_att 16.264004 loss_ctc 18.591358 loss_rnnt 10.652100 hw_loss 0.676237 lr 0.00082980 rank 2
2023-02-11 08:37:28,935 DEBUG TRAIN Batch 4/2900 loss 31.831043 loss_att 37.023338 loss_ctc 49.607811 loss_rnnt 26.246284 hw_loss 0.408012 lr 0.00083068 rank 6
2023-02-11 08:37:28,936 DEBUG TRAIN Batch 4/2900 loss 34.143742 loss_att 33.973770 loss_ctc 46.419518 loss_rnnt 29.037046 hw_loss 0.656985 lr 0.00082989 rank 0
2023-02-11 08:37:28,937 DEBUG TRAIN Batch 4/2900 loss 18.874437 loss_att 21.607035 loss_ctc 29.779116 loss_rnnt 14.591200 hw_loss 0.428017 lr 0.00083079 rank 4
2023-02-11 08:37:28,940 DEBUG TRAIN Batch 4/2900 loss 26.114555 loss_att 32.527779 loss_ctc 39.075554 loss_rnnt 21.482216 hw_loss 0.304043 lr 0.00083027 rank 5
2023-02-11 08:38:44,697 DEBUG TRAIN Batch 4/3000 loss 34.006622 loss_att 36.226879 loss_ctc 42.895226 loss_rnnt 31.497898 hw_loss 0.164912 lr 0.00082938 rank 3
2023-02-11 08:38:44,697 DEBUG TRAIN Batch 4/3000 loss 12.517679 loss_att 19.845064 loss_ctc 23.274683 loss_rnnt 8.341616 hw_loss 0.239310 lr 0.00082913 rank 5
2023-02-11 08:38:44,698 DEBUG TRAIN Batch 4/3000 loss 24.907358 loss_att 27.956383 loss_ctc 44.996052 loss_rnnt 17.268316 hw_loss 0.815765 lr 0.00082964 rank 7
2023-02-11 08:38:44,701 DEBUG TRAIN Batch 4/3000 loss 15.385979 loss_att 18.079071 loss_ctc 26.415722 loss_rnnt 10.344675 hw_loss 0.568510 lr 0.00082883 rank 1
2023-02-11 08:38:44,704 DEBUG TRAIN Batch 4/3000 loss 34.120544 loss_att 40.933178 loss_ctc 49.374115 loss_rnnt 29.246979 hw_loss 0.276980 lr 0.00082866 rank 2
2023-02-11 08:38:44,703 DEBUG TRAIN Batch 4/3000 loss 14.189320 loss_att 16.003185 loss_ctc 18.315567 loss_rnnt 8.718795 hw_loss 0.854547 lr 0.00082954 rank 6
2023-02-11 08:38:44,704 DEBUG TRAIN Batch 4/3000 loss 17.485628 loss_att 19.176855 loss_ctc 24.344536 loss_rnnt 13.601841 hw_loss 0.493316 lr 0.00082964 rank 4
2023-02-11 08:38:44,706 DEBUG TRAIN Batch 4/3000 loss 26.849749 loss_att 37.556908 loss_ctc 41.177921 loss_rnnt 22.567698 hw_loss 0.043162 lr 0.00082875 rank 0
2023-02-11 08:40:00,539 DEBUG TRAIN Batch 4/3100 loss 22.680618 loss_att 26.629538 loss_ctc 33.882641 loss_rnnt 18.611872 hw_loss 0.334755 lr 0.00082770 rank 1
2023-02-11 08:40:00,540 DEBUG TRAIN Batch 4/3100 loss 14.043880 loss_att 13.996353 loss_ctc 19.479162 loss_rnnt 10.139728 hw_loss 0.597929 lr 0.00082850 rank 4
2023-02-11 08:40:00,543 DEBUG TRAIN Batch 4/3100 loss 21.732115 loss_att 23.256283 loss_ctc 34.955750 loss_rnnt 18.895721 hw_loss 0.144076 lr 0.00082753 rank 2
2023-02-11 08:40:00,543 DEBUG TRAIN Batch 4/3100 loss 27.935738 loss_att 29.434515 loss_ctc 41.544624 loss_rnnt 22.409653 hw_loss 0.639714 lr 0.00082762 rank 0
2023-02-11 08:40:00,544 DEBUG TRAIN Batch 4/3100 loss 20.864779 loss_att 21.336956 loss_ctc 27.431431 loss_rnnt 17.215586 hw_loss 0.502350 lr 0.00082824 rank 3
2023-02-11 08:40:00,545 DEBUG TRAIN Batch 4/3100 loss 18.193087 loss_att 19.388983 loss_ctc 26.897837 loss_rnnt 13.009979 hw_loss 0.709368 lr 0.00082850 rank 7
2023-02-11 08:40:00,546 DEBUG TRAIN Batch 4/3100 loss 41.186306 loss_att 43.138035 loss_ctc 59.763000 loss_rnnt 36.168770 hw_loss 0.403180 lr 0.00082799 rank 5
2023-02-11 08:40:00,585 DEBUG TRAIN Batch 4/3100 loss 17.743284 loss_att 17.920822 loss_ctc 27.130154 loss_rnnt 13.573592 hw_loss 0.540488 lr 0.00082840 rank 6
2023-02-11 08:41:20,656 DEBUG TRAIN Batch 4/3200 loss 16.827362 loss_att 16.074898 loss_ctc 17.562914 loss_rnnt 12.652520 hw_loss 0.792611 lr 0.00082737 rank 7
2023-02-11 08:41:20,660 DEBUG TRAIN Batch 4/3200 loss 18.505720 loss_att 17.592339 loss_ctc 24.305752 loss_rnnt 15.882012 hw_loss 0.381196 lr 0.00082686 rank 5
2023-02-11 08:41:20,660 DEBUG TRAIN Batch 4/3200 loss 19.336714 loss_att 17.623306 loss_ctc 23.026772 loss_rnnt 14.946798 hw_loss 0.795111 lr 0.00082711 rank 3
2023-02-11 08:41:20,664 DEBUG TRAIN Batch 4/3200 loss 51.304085 loss_att 49.338509 loss_ctc 72.923630 loss_rnnt 45.805435 hw_loss 0.564218 lr 0.00082649 rank 0
2023-02-11 08:41:20,667 DEBUG TRAIN Batch 4/3200 loss 16.877132 loss_att 22.062580 loss_ctc 28.387009 loss_rnnt 11.759514 hw_loss 0.477352 lr 0.00082727 rank 6
2023-02-11 08:41:20,668 DEBUG TRAIN Batch 4/3200 loss 16.632021 loss_att 14.023586 loss_ctc 17.585449 loss_rnnt 13.401626 hw_loss 0.679680 lr 0.00082640 rank 2
2023-02-11 08:41:20,669 DEBUG TRAIN Batch 4/3200 loss 22.386322 loss_att 29.978615 loss_ctc 39.597557 loss_rnnt 15.650154 hw_loss 0.548040 lr 0.00082737 rank 4
2023-02-11 08:41:20,709 DEBUG TRAIN Batch 4/3200 loss 16.648962 loss_att 12.269641 loss_ctc 17.154076 loss_rnnt 12.043504 hw_loss 1.015120 lr 0.00082656 rank 1
2023-02-11 08:42:36,420 DEBUG TRAIN Batch 4/3300 loss 32.424484 loss_att 38.642586 loss_ctc 64.258118 loss_rnnt 24.576435 hw_loss 0.442489 lr 0.00082544 rank 1
2023-02-11 08:42:36,420 DEBUG TRAIN Batch 4/3300 loss 29.188404 loss_att 32.185921 loss_ctc 42.985992 loss_rnnt 25.552467 hw_loss 0.224391 lr 0.00082527 rank 2
2023-02-11 08:42:36,422 DEBUG TRAIN Batch 4/3300 loss 17.703743 loss_att 19.130569 loss_ctc 23.892403 loss_rnnt 14.456396 hw_loss 0.400655 lr 0.00082598 rank 3
2023-02-11 08:42:36,423 DEBUG TRAIN Batch 4/3300 loss 34.647396 loss_att 36.555290 loss_ctc 55.462933 loss_rnnt 29.076149 hw_loss 0.452674 lr 0.00082624 rank 7
2023-02-11 08:42:36,425 DEBUG TRAIN Batch 4/3300 loss 19.744282 loss_att 22.214314 loss_ctc 27.087881 loss_rnnt 16.373257 hw_loss 0.355851 lr 0.00082573 rank 5
2023-02-11 08:42:36,425 DEBUG TRAIN Batch 4/3300 loss 19.123732 loss_att 25.729511 loss_ctc 25.427292 loss_rnnt 14.063468 hw_loss 0.543494 lr 0.00082624 rank 4
2023-02-11 08:42:36,425 DEBUG TRAIN Batch 4/3300 loss 40.856739 loss_att 44.204395 loss_ctc 60.685650 loss_rnnt 34.451408 hw_loss 0.579740 lr 0.00082536 rank 0
2023-02-11 08:42:36,428 DEBUG TRAIN Batch 4/3300 loss 26.706009 loss_att 29.924656 loss_ctc 35.972519 loss_rnnt 22.725925 hw_loss 0.393903 lr 0.00082614 rank 6
2023-02-11 08:43:52,093 DEBUG TRAIN Batch 4/3400 loss 31.811224 loss_att 37.395500 loss_ctc 43.644218 loss_rnnt 26.298779 hw_loss 0.528349 lr 0.00082511 rank 7
2023-02-11 08:43:52,098 DEBUG TRAIN Batch 4/3400 loss 26.942747 loss_att 30.144142 loss_ctc 39.260460 loss_rnnt 18.402555 hw_loss 1.173291 lr 0.00082424 rank 0
2023-02-11 08:43:52,100 DEBUG TRAIN Batch 4/3400 loss 14.752907 loss_att 21.688583 loss_ctc 23.494108 loss_rnnt 9.899058 hw_loss 0.431479 lr 0.00082485 rank 3
2023-02-11 08:43:52,101 DEBUG TRAIN Batch 4/3400 loss 24.889849 loss_att 28.143923 loss_ctc 32.940933 loss_rnnt 21.630787 hw_loss 0.287769 lr 0.00082501 rank 6
2023-02-11 08:43:52,102 DEBUG TRAIN Batch 4/3400 loss 24.534803 loss_att 27.509609 loss_ctc 33.875229 loss_rnnt 19.725950 hw_loss 0.556594 lr 0.00082461 rank 5
2023-02-11 08:43:52,102 DEBUG TRAIN Batch 4/3400 loss 22.173771 loss_att 23.260279 loss_ctc 31.510771 loss_rnnt 18.425053 hw_loss 0.428716 lr 0.00082511 rank 4
2023-02-11 08:43:52,102 DEBUG TRAIN Batch 4/3400 loss 33.364685 loss_att 36.284233 loss_ctc 44.674362 loss_rnnt 28.442160 hw_loss 0.530749 lr 0.00082415 rank 2
2023-02-11 08:43:52,148 DEBUG TRAIN Batch 4/3400 loss 13.669119 loss_att 15.185740 loss_ctc 20.295607 loss_rnnt 10.020319 hw_loss 0.461615 lr 0.00082432 rank 1
2023-02-11 08:45:08,869 DEBUG TRAIN Batch 4/3500 loss 19.227959 loss_att 22.599636 loss_ctc 29.405598 loss_rnnt 15.655926 hw_loss 0.288877 lr 0.00082373 rank 3
2023-02-11 08:45:08,874 DEBUG TRAIN Batch 4/3500 loss 31.945477 loss_att 33.502792 loss_ctc 41.808651 loss_rnnt 27.953293 hw_loss 0.443555 lr 0.00082312 rank 0
2023-02-11 08:45:08,876 DEBUG TRAIN Batch 4/3500 loss 54.656147 loss_att 57.298340 loss_ctc 80.496864 loss_rnnt 46.793587 hw_loss 0.729129 lr 0.00082399 rank 7
2023-02-11 08:45:08,879 DEBUG TRAIN Batch 4/3500 loss 34.470409 loss_att 42.283253 loss_ctc 53.178226 loss_rnnt 29.190054 hw_loss 0.229389 lr 0.00082349 rank 5
2023-02-11 08:45:08,879 DEBUG TRAIN Batch 4/3500 loss 28.765217 loss_att 30.233450 loss_ctc 36.509407 loss_rnnt 24.195400 hw_loss 0.608177 lr 0.00082389 rank 6
2023-02-11 08:45:08,879 DEBUG TRAIN Batch 4/3500 loss 34.550262 loss_att 39.091702 loss_ctc 49.641209 loss_rnnt 29.995762 hw_loss 0.306391 lr 0.00082303 rank 2
2023-02-11 08:45:08,882 DEBUG TRAIN Batch 4/3500 loss 20.889860 loss_att 26.768257 loss_ctc 25.763130 loss_rnnt 17.700230 hw_loss 0.255784 lr 0.00082320 rank 1
2023-02-11 08:45:08,886 DEBUG TRAIN Batch 4/3500 loss 24.690271 loss_att 27.110767 loss_ctc 32.822659 loss_rnnt 21.296959 hw_loss 0.342167 lr 0.00082399 rank 4
2023-02-11 08:46:27,159 DEBUG TRAIN Batch 4/3600 loss 31.005003 loss_att 32.405800 loss_ctc 50.195110 loss_rnnt 26.555038 hw_loss 0.302085 lr 0.00082287 rank 7
2023-02-11 08:46:27,161 DEBUG TRAIN Batch 4/3600 loss 23.935026 loss_att 31.006359 loss_ctc 42.704697 loss_rnnt 16.465401 hw_loss 0.666138 lr 0.00082262 rank 3
2023-02-11 08:46:27,162 DEBUG TRAIN Batch 4/3600 loss 37.637642 loss_att 40.133526 loss_ctc 46.367226 loss_rnnt 33.481480 hw_loss 0.467445 lr 0.00082192 rank 2
2023-02-11 08:46:27,162 DEBUG TRAIN Batch 4/3600 loss 35.675579 loss_att 46.341961 loss_ctc 59.988541 loss_rnnt 28.464705 hw_loss 0.344226 lr 0.00082201 rank 0
2023-02-11 08:46:27,163 DEBUG TRAIN Batch 4/3600 loss 14.931091 loss_att 20.337982 loss_ctc 24.267624 loss_rnnt 10.981947 hw_loss 0.304293 lr 0.00082277 rank 6
2023-02-11 08:46:27,164 DEBUG TRAIN Batch 4/3600 loss 32.936954 loss_att 36.372208 loss_ctc 47.222359 loss_rnnt 29.621126 hw_loss 0.135760 lr 0.00082237 rank 5
2023-02-11 08:46:27,169 DEBUG TRAIN Batch 4/3600 loss 24.152170 loss_att 31.287487 loss_ctc 36.789940 loss_rnnt 18.290579 hw_loss 0.515530 lr 0.00082287 rank 4
2023-02-11 08:46:27,209 DEBUG TRAIN Batch 4/3600 loss 29.541494 loss_att 32.003315 loss_ctc 39.856972 loss_rnnt 24.301428 hw_loss 0.632307 lr 0.00082208 rank 1
2023-02-11 08:47:43,521 DEBUG TRAIN Batch 4/3700 loss 29.584402 loss_att 33.038754 loss_ctc 37.985958 loss_rnnt 26.324829 hw_loss 0.271593 lr 0.00082176 rank 7
2023-02-11 08:47:43,522 DEBUG TRAIN Batch 4/3700 loss 15.402750 loss_att 18.137756 loss_ctc 27.187550 loss_rnnt 11.937495 hw_loss 0.252552 lr 0.00082151 rank 3
2023-02-11 08:47:43,523 DEBUG TRAIN Batch 4/3700 loss 30.081131 loss_att 32.902569 loss_ctc 41.926037 loss_rnnt 25.810421 hw_loss 0.398832 lr 0.00082081 rank 2
2023-02-11 08:47:43,523 DEBUG TRAIN Batch 4/3700 loss 14.381195 loss_att 16.793049 loss_ctc 18.585722 loss_rnnt 8.806395 hw_loss 0.849717 lr 0.00082166 rank 6
2023-02-11 08:47:43,524 DEBUG TRAIN Batch 4/3700 loss 36.183479 loss_att 33.321552 loss_ctc 41.577934 loss_rnnt 30.537245 hw_loss 1.031129 lr 0.00082090 rank 0
2023-02-11 08:47:43,527 DEBUG TRAIN Batch 4/3700 loss 26.423462 loss_att 27.602201 loss_ctc 36.134033 loss_rnnt 22.470369 hw_loss 0.454238 lr 0.00082097 rank 1
2023-02-11 08:47:43,528 DEBUG TRAIN Batch 4/3700 loss 29.360504 loss_att 29.364796 loss_ctc 37.323166 loss_rnnt 24.770496 hw_loss 0.661399 lr 0.00082126 rank 5
2023-02-11 08:47:43,534 DEBUG TRAIN Batch 4/3700 loss 24.597242 loss_att 26.209808 loss_ctc 37.696457 loss_rnnt 20.397297 hw_loss 0.399538 lr 0.00082176 rank 4
2023-02-11 08:49:00,065 DEBUG TRAIN Batch 4/3800 loss 18.836140 loss_att 19.214880 loss_ctc 23.505140 loss_rnnt 12.661902 hw_loss 1.026742 lr 0.00082065 rank 7
2023-02-11 08:49:00,067 DEBUG TRAIN Batch 4/3800 loss 26.545265 loss_att 35.434444 loss_ctc 42.394958 loss_rnnt 21.781088 hw_loss 0.163697 lr 0.00081979 rank 0
2023-02-11 08:49:00,068 DEBUG TRAIN Batch 4/3800 loss 38.094700 loss_att 40.926369 loss_ctc 50.656681 loss_rnnt 32.672249 hw_loss 0.596473 lr 0.00082016 rank 5
2023-02-11 08:49:00,069 DEBUG TRAIN Batch 4/3800 loss 22.148916 loss_att 19.281109 loss_ctc 26.301996 loss_rnnt 17.101093 hw_loss 0.950182 lr 0.00082040 rank 3
2023-02-11 08:49:00,073 DEBUG TRAIN Batch 4/3800 loss 14.325249 loss_att 11.868290 loss_ctc 18.768404 loss_rnnt 9.070265 hw_loss 0.966367 lr 0.00081987 rank 1
2023-02-11 08:49:00,073 DEBUG TRAIN Batch 4/3800 loss 18.241848 loss_att 19.251577 loss_ctc 23.006420 loss_rnnt 14.281878 hw_loss 0.585515 lr 0.00081971 rank 2
2023-02-11 08:49:00,078 DEBUG TRAIN Batch 4/3800 loss 20.140751 loss_att 23.175625 loss_ctc 34.726746 loss_rnnt 14.676908 hw_loss 0.546013 lr 0.00082065 rank 4
2023-02-11 08:49:00,077 DEBUG TRAIN Batch 4/3800 loss 22.258028 loss_att 22.873466 loss_ctc 28.448915 loss_rnnt 17.327084 hw_loss 0.746701 lr 0.00082055 rank 6
2023-02-11 08:50:18,479 DEBUG TRAIN Batch 4/3900 loss 18.106354 loss_att 22.874174 loss_ctc 27.963436 loss_rnnt 12.925982 hw_loss 0.546099 lr 0.00081930 rank 3
2023-02-11 08:50:18,481 DEBUG TRAIN Batch 4/3900 loss 29.052860 loss_att 31.201408 loss_ctc 43.014885 loss_rnnt 25.053684 hw_loss 0.320224 lr 0.00081955 rank 4
2023-02-11 08:50:18,481 DEBUG TRAIN Batch 4/3900 loss 34.993603 loss_att 38.413197 loss_ctc 46.111389 loss_rnnt 29.023529 hw_loss 0.713209 lr 0.00081877 rank 1
2023-02-11 08:50:18,482 DEBUG TRAIN Batch 4/3900 loss 33.404171 loss_att 30.134403 loss_ctc 35.966141 loss_rnnt 31.222013 hw_loss 0.467721 lr 0.00081861 rank 2
2023-02-11 08:50:18,485 DEBUG TRAIN Batch 4/3900 loss 26.830748 loss_att 32.415386 loss_ctc 49.847748 loss_rnnt 21.333344 hw_loss 0.245914 lr 0.00081869 rank 0
2023-02-11 08:50:18,487 DEBUG TRAIN Batch 4/3900 loss 18.514341 loss_att 23.385799 loss_ctc 31.182394 loss_rnnt 12.995746 hw_loss 0.535355 lr 0.00081945 rank 6
2023-02-11 08:50:18,488 DEBUG TRAIN Batch 4/3900 loss 20.100014 loss_att 24.047911 loss_ctc 26.045227 loss_rnnt 15.512736 hw_loss 0.563438 lr 0.00081955 rank 7
2023-02-11 08:50:18,500 DEBUG TRAIN Batch 4/3900 loss 20.731150 loss_att 25.053133 loss_ctc 27.908009 loss_rnnt 17.168083 hw_loss 0.326579 lr 0.00081906 rank 5
2023-02-11 08:51:34,462 DEBUG TRAIN Batch 4/4000 loss 9.943522 loss_att 14.436998 loss_ctc 17.758261 loss_rnnt 6.627899 hw_loss 0.257805 lr 0.00081760 rank 0
2023-02-11 08:51:34,464 DEBUG TRAIN Batch 4/4000 loss 22.087095 loss_att 31.871044 loss_ctc 44.984230 loss_rnnt 14.766532 hw_loss 0.433279 lr 0.00081751 rank 2
2023-02-11 08:51:34,466 DEBUG TRAIN Batch 4/4000 loss 18.179014 loss_att 24.648827 loss_ctc 21.209820 loss_rnnt 13.968277 hw_loss 0.471125 lr 0.00081845 rank 7
2023-02-11 08:51:34,469 DEBUG TRAIN Batch 4/4000 loss 26.843067 loss_att 30.262226 loss_ctc 44.736740 loss_rnnt 21.390423 hw_loss 0.446811 lr 0.00081820 rank 3
2023-02-11 08:51:34,469 DEBUG TRAIN Batch 4/4000 loss 20.057714 loss_att 26.423973 loss_ctc 31.954235 loss_rnnt 15.905340 hw_loss 0.242423 lr 0.00081845 rank 4
2023-02-11 08:51:34,469 DEBUG TRAIN Batch 4/4000 loss 23.339334 loss_att 26.721102 loss_ctc 33.914898 loss_rnnt 19.558468 hw_loss 0.317707 lr 0.00081835 rank 6
2023-02-11 08:51:34,470 DEBUG TRAIN Batch 4/4000 loss 38.819988 loss_att 41.938931 loss_ctc 64.224258 loss_rnnt 32.036652 hw_loss 0.519809 lr 0.00081767 rank 1
2023-02-11 08:51:34,470 DEBUG TRAIN Batch 4/4000 loss 35.631775 loss_att 42.940578 loss_ctc 50.957726 loss_rnnt 30.056442 hw_loss 0.388146 lr 0.00081796 rank 5
2023-02-11 08:52:49,742 DEBUG TRAIN Batch 4/4100 loss 23.561525 loss_att 30.138142 loss_ctc 38.397293 loss_rnnt 16.853062 hw_loss 0.640319 lr 0.00081651 rank 0
2023-02-11 08:52:49,743 DEBUG TRAIN Batch 4/4100 loss 25.826406 loss_att 32.442474 loss_ctc 35.010395 loss_rnnt 22.515295 hw_loss 0.143131 lr 0.00081642 rank 2
2023-02-11 08:52:49,744 DEBUG TRAIN Batch 4/4100 loss 20.631285 loss_att 23.603586 loss_ctc 31.975105 loss_rnnt 16.800194 hw_loss 0.323273 lr 0.00081658 rank 1
2023-02-11 08:52:49,747 DEBUG TRAIN Batch 4/4100 loss 34.827610 loss_att 38.177471 loss_ctc 61.846157 loss_rnnt 28.459311 hw_loss 0.392973 lr 0.00081736 rank 7
2023-02-11 08:52:49,748 DEBUG TRAIN Batch 4/4100 loss 40.198761 loss_att 42.250519 loss_ctc 60.340889 loss_rnnt 35.591873 hw_loss 0.283297 lr 0.00081687 rank 5
2023-02-11 08:52:49,751 DEBUG TRAIN Batch 4/4100 loss 15.821935 loss_att 19.846994 loss_ctc 25.932064 loss_rnnt 11.299807 hw_loss 0.444206 lr 0.00081711 rank 3
2023-02-11 08:52:49,753 DEBUG TRAIN Batch 4/4100 loss 35.326881 loss_att 43.221497 loss_ctc 48.343735 loss_rnnt 29.983055 hw_loss 0.380497 lr 0.00081736 rank 4
2023-02-11 08:52:49,755 DEBUG TRAIN Batch 4/4100 loss 39.922035 loss_att 43.709572 loss_ctc 58.588318 loss_rnnt 33.369652 hw_loss 0.619882 lr 0.00081726 rank 6
2023-02-11 08:54:05,597 DEBUG TRAIN Batch 4/4200 loss 19.749495 loss_att 25.364435 loss_ctc 30.971020 loss_rnnt 12.505287 hw_loss 0.867190 lr 0.00081627 rank 7
2023-02-11 08:54:05,600 DEBUG TRAIN Batch 4/4200 loss 25.977919 loss_att 31.745289 loss_ctc 38.989899 loss_rnnt 20.353157 hw_loss 0.513067 lr 0.00081627 rank 4
2023-02-11 08:54:05,602 DEBUG TRAIN Batch 4/4200 loss 24.757601 loss_att 24.684765 loss_ctc 35.609856 loss_rnnt 20.882801 hw_loss 0.457950 lr 0.00081578 rank 5
2023-02-11 08:54:05,604 DEBUG TRAIN Batch 4/4200 loss 24.069942 loss_att 27.497272 loss_ctc 38.168659 loss_rnnt 19.781315 hw_loss 0.323125 lr 0.00081542 rank 0
2023-02-11 08:54:05,606 DEBUG TRAIN Batch 4/4200 loss 20.716873 loss_att 22.435600 loss_ctc 26.648920 loss_rnnt 16.444897 hw_loss 0.588242 lr 0.00081602 rank 3
2023-02-11 08:54:05,609 DEBUG TRAIN Batch 4/4200 loss 27.969276 loss_att 37.063171 loss_ctc 42.934307 loss_rnnt 22.105824 hw_loss 0.384251 lr 0.00081617 rank 6
2023-02-11 08:54:05,635 DEBUG TRAIN Batch 4/4200 loss 19.318838 loss_att 23.416462 loss_ctc 32.830349 loss_rnnt 15.220808 hw_loss 0.276932 lr 0.00081533 rank 2
2023-02-11 08:54:05,645 DEBUG TRAIN Batch 4/4200 loss 37.196854 loss_att 38.635635 loss_ctc 50.269962 loss_rnnt 32.827164 hw_loss 0.438535 lr 0.00081550 rank 1
2023-02-11 08:55:24,538 DEBUG TRAIN Batch 4/4300 loss 21.554647 loss_att 23.965258 loss_ctc 29.091747 loss_rnnt 18.132805 hw_loss 0.362770 lr 0.00081493 rank 3
2023-02-11 08:55:24,541 DEBUG TRAIN Batch 4/4300 loss 17.907450 loss_att 21.127831 loss_ctc 27.213150 loss_rnnt 11.722836 hw_loss 0.806208 lr 0.00081441 rank 1
2023-02-11 08:55:24,541 DEBUG TRAIN Batch 4/4300 loss 23.089762 loss_att 27.242598 loss_ctc 36.276352 loss_rnnt 18.914930 hw_loss 0.297385 lr 0.00081425 rank 2
2023-02-11 08:55:24,542 DEBUG TRAIN Batch 4/4300 loss 22.710611 loss_att 21.891569 loss_ctc 33.348145 loss_rnnt 16.409601 hw_loss 0.946215 lr 0.00081434 rank 0
2023-02-11 08:55:24,543 DEBUG TRAIN Batch 4/4300 loss 28.028349 loss_att 29.726830 loss_ctc 43.490047 loss_rnnt 24.411358 hw_loss 0.227951 lr 0.00081518 rank 7
2023-02-11 08:55:24,544 DEBUG TRAIN Batch 4/4300 loss 32.718632 loss_att 33.959377 loss_ctc 45.596893 loss_rnnt 26.734547 hw_loss 0.753531 lr 0.00081518 rank 4
2023-02-11 08:55:24,546 DEBUG TRAIN Batch 4/4300 loss 24.893747 loss_att 35.582039 loss_ctc 45.103294 loss_rnnt 18.941902 hw_loss 0.209921 lr 0.00081508 rank 6
2023-02-11 08:55:24,553 DEBUG TRAIN Batch 4/4300 loss 31.652775 loss_att 34.932522 loss_ctc 36.130806 loss_rnnt 28.336319 hw_loss 0.386894 lr 0.00081470 rank 5
2023-02-11 08:56:41,293 DEBUG TRAIN Batch 4/4400 loss 28.490305 loss_att 29.367348 loss_ctc 39.728111 loss_rnnt 21.949865 hw_loss 0.912498 lr 0.00081326 rank 0
2023-02-11 08:56:41,294 DEBUG TRAIN Batch 4/4400 loss 20.776939 loss_att 26.100685 loss_ctc 29.159460 loss_rnnt 15.360721 hw_loss 0.606337 lr 0.00081410 rank 7
2023-02-11 08:56:41,296 DEBUG TRAIN Batch 4/4400 loss 15.397541 loss_att 12.922734 loss_ctc 17.999872 loss_rnnt 10.071100 hw_loss 1.026455 lr 0.00081385 rank 3
2023-02-11 08:56:41,297 DEBUG TRAIN Batch 4/4400 loss 31.899357 loss_att 35.051212 loss_ctc 50.026760 loss_rnnt 27.221962 hw_loss 0.305632 lr 0.00081362 rank 5
2023-02-11 08:56:41,298 DEBUG TRAIN Batch 4/4400 loss 27.224316 loss_att 27.747395 loss_ctc 36.683697 loss_rnnt 20.904552 hw_loss 0.928855 lr 0.00081317 rank 2
2023-02-11 08:56:41,298 DEBUG TRAIN Batch 4/4400 loss 20.060833 loss_att 19.039970 loss_ctc 26.004663 loss_rnnt 14.976590 hw_loss 0.842982 lr 0.00081334 rank 1
2023-02-11 08:56:41,301 DEBUG TRAIN Batch 4/4400 loss 13.525036 loss_att 9.777018 loss_ctc 14.063098 loss_rnnt 8.972716 hw_loss 0.980659 lr 0.00081410 rank 4
2023-02-11 08:56:41,346 DEBUG TRAIN Batch 4/4400 loss 18.248573 loss_att 22.044262 loss_ctc 26.277948 loss_rnnt 13.145496 hw_loss 0.613754 lr 0.00081400 rank 6
2023-02-11 08:57:58,000 DEBUG TRAIN Batch 4/4500 loss 14.479059 loss_att 18.769602 loss_ctc 24.921249 loss_rnnt 11.607780 hw_loss 0.116415 lr 0.00081278 rank 3
2023-02-11 08:57:58,006 DEBUG TRAIN Batch 4/4500 loss 23.155819 loss_att 20.768967 loss_ctc 30.978935 loss_rnnt 17.332150 hw_loss 0.985867 lr 0.00081293 rank 6
2023-02-11 08:57:58,007 DEBUG TRAIN Batch 4/4500 loss 18.564590 loss_att 16.451195 loss_ctc 22.814260 loss_rnnt 13.550296 hw_loss 0.913191 lr 0.00081302 rank 7
2023-02-11 08:57:58,008 DEBUG TRAIN Batch 4/4500 loss 16.632353 loss_att 16.204548 loss_ctc 23.154987 loss_rnnt 13.365461 hw_loss 0.465519 lr 0.00081254 rank 5
2023-02-11 08:57:58,009 DEBUG TRAIN Batch 4/4500 loss 28.166939 loss_att 34.284359 loss_ctc 41.605873 loss_rnnt 24.433950 hw_loss 0.134559 lr 0.00081210 rank 2
2023-02-11 08:57:58,011 DEBUG TRAIN Batch 4/4500 loss 9.319709 loss_att 13.272295 loss_ctc 15.983710 loss_rnnt 4.498505 hw_loss 0.589154 lr 0.00081219 rank 0
2023-02-11 08:57:58,016 DEBUG TRAIN Batch 4/4500 loss 30.284952 loss_att 45.772625 loss_ctc 58.462395 loss_rnnt 21.757582 hw_loss 0.313658 lr 0.00081226 rank 1
2023-02-11 08:57:58,022 DEBUG TRAIN Batch 4/4500 loss 21.213259 loss_att 28.018881 loss_ctc 32.606743 loss_rnnt 16.638569 hw_loss 0.317706 lr 0.00081302 rank 4
2023-02-11 08:59:16,653 DEBUG TRAIN Batch 4/4600 loss 18.009230 loss_att 23.161654 loss_ctc 22.213650 loss_rnnt 14.389637 hw_loss 0.380347 lr 0.00081195 rank 7
2023-02-11 08:59:16,654 DEBUG TRAIN Batch 4/4600 loss 23.183502 loss_att 27.769760 loss_ctc 34.467964 loss_rnnt 17.719849 hw_loss 0.570339 lr 0.00081186 rank 6
2023-02-11 08:59:16,659 DEBUG TRAIN Batch 4/4600 loss 28.014711 loss_att 30.127920 loss_ctc 47.937355 loss_rnnt 21.021080 hw_loss 0.733994 lr 0.00081119 rank 1
2023-02-11 08:59:16,658 DEBUG TRAIN Batch 4/4600 loss 21.533499 loss_att 24.520330 loss_ctc 40.131432 loss_rnnt 16.003742 hw_loss 0.459875 lr 0.00081112 rank 0
2023-02-11 08:59:16,662 DEBUG TRAIN Batch 4/4600 loss 29.102570 loss_att 33.200302 loss_ctc 43.292828 loss_rnnt 23.268734 hw_loss 0.585423 lr 0.00081103 rank 2
2023-02-11 08:59:16,663 DEBUG TRAIN Batch 4/4600 loss 35.864304 loss_att 45.832668 loss_ctc 53.511578 loss_rnnt 28.889418 hw_loss 0.492796 lr 0.00081171 rank 3
2023-02-11 08:59:16,662 DEBUG TRAIN Batch 4/4600 loss 30.226614 loss_att 37.453033 loss_ctc 47.132763 loss_rnnt 25.325478 hw_loss 0.225318 lr 0.00081147 rank 5
2023-02-11 08:59:16,662 DEBUG TRAIN Batch 4/4600 loss 20.041294 loss_att 26.111971 loss_ctc 33.596428 loss_rnnt 16.263319 hw_loss 0.141842 lr 0.00081195 rank 4
2023-02-11 09:00:35,125 DEBUG TRAIN Batch 4/4700 loss 13.956484 loss_att 17.063854 loss_ctc 23.269485 loss_rnnt 10.576107 hw_loss 0.284469 lr 0.00081064 rank 3
2023-02-11 09:00:35,125 DEBUG TRAIN Batch 4/4700 loss 21.814238 loss_att 29.411156 loss_ctc 35.802208 loss_rnnt 17.536915 hw_loss 0.167414 lr 0.00081040 rank 5
2023-02-11 09:00:35,125 DEBUG TRAIN Batch 4/4700 loss 17.931379 loss_att 17.801991 loss_ctc 22.365383 loss_rnnt 13.431124 hw_loss 0.737800 lr 0.00081088 rank 4
2023-02-11 09:00:35,128 DEBUG TRAIN Batch 4/4700 loss 30.090965 loss_att 36.559238 loss_ctc 44.689095 loss_rnnt 25.501793 hw_loss 0.252956 lr 0.00081013 rank 1
2023-02-11 09:00:35,131 DEBUG TRAIN Batch 4/4700 loss 16.582592 loss_att 18.935871 loss_ctc 24.093231 loss_rnnt 13.364983 hw_loss 0.327288 lr 0.00081005 rank 0
2023-02-11 09:00:35,131 DEBUG TRAIN Batch 4/4700 loss 21.734322 loss_att 24.550709 loss_ctc 34.526878 loss_rnnt 18.146553 hw_loss 0.247278 lr 0.00080997 rank 2
2023-02-11 09:00:35,132 DEBUG TRAIN Batch 4/4700 loss 19.057779 loss_att 23.300961 loss_ctc 27.106773 loss_rnnt 15.742933 hw_loss 0.261189 lr 0.00081088 rank 7
2023-02-11 09:00:35,173 DEBUG TRAIN Batch 4/4700 loss 15.812008 loss_att 17.661314 loss_ctc 23.685429 loss_rnnt 11.842621 hw_loss 0.478075 lr 0.00081079 rank 6
2023-02-11 09:01:51,402 DEBUG TRAIN Batch 4/4800 loss 37.343384 loss_att 43.401325 loss_ctc 55.515240 loss_rnnt 31.238859 hw_loss 0.463129 lr 0.00080891 rank 2
2023-02-11 09:01:51,403 DEBUG TRAIN Batch 4/4800 loss 26.516502 loss_att 39.999649 loss_ctc 44.447578 loss_rnnt 17.700981 hw_loss 0.699016 lr 0.00080982 rank 4
2023-02-11 09:01:51,405 DEBUG TRAIN Batch 4/4800 loss 28.680977 loss_att 29.364597 loss_ctc 40.717163 loss_rnnt 23.368650 hw_loss 0.669521 lr 0.00080899 rank 0
2023-02-11 09:01:51,405 DEBUG TRAIN Batch 4/4800 loss 35.646549 loss_att 44.883274 loss_ctc 59.764679 loss_rnnt 27.583410 hw_loss 0.562508 lr 0.00080982 rank 7
2023-02-11 09:01:51,406 DEBUG TRAIN Batch 4/4800 loss 26.924501 loss_att 35.560631 loss_ctc 34.779922 loss_rnnt 20.853348 hw_loss 0.618101 lr 0.00080934 rank 5
2023-02-11 09:01:51,407 DEBUG TRAIN Batch 4/4800 loss 22.156870 loss_att 23.844990 loss_ctc 32.868435 loss_rnnt 17.086803 hw_loss 0.619544 lr 0.00080907 rank 1
2023-02-11 09:01:51,407 DEBUG TRAIN Batch 4/4800 loss 19.828825 loss_att 23.883980 loss_ctc 35.479797 loss_rnnt 12.292874 hw_loss 0.869648 lr 0.00080957 rank 3
2023-02-11 09:01:51,456 DEBUG TRAIN Batch 4/4800 loss 11.698156 loss_att 12.279243 loss_ctc 14.199625 loss_rnnt 8.313193 hw_loss 0.550353 lr 0.00080972 rank 6
2023-02-11 09:03:08,860 DEBUG TRAIN Batch 4/4900 loss 23.546049 loss_att 26.387180 loss_ctc 34.702896 loss_rnnt 19.625643 hw_loss 0.349613 lr 0.00080801 rank 1
2023-02-11 09:03:08,860 DEBUG TRAIN Batch 4/4900 loss 22.116285 loss_att 25.591019 loss_ctc 29.444839 loss_rnnt 19.934265 hw_loss 0.095612 lr 0.00080876 rank 7
2023-02-11 09:03:08,862 DEBUG TRAIN Batch 4/4900 loss 18.081408 loss_att 24.227797 loss_ctc 31.269569 loss_rnnt 13.860469 hw_loss 0.231232 lr 0.00080852 rank 3
2023-02-11 09:03:08,865 DEBUG TRAIN Batch 4/4900 loss 17.071587 loss_att 20.571018 loss_ctc 34.380341 loss_rnnt 12.313393 hw_loss 0.328214 lr 0.00080866 rank 6
2023-02-11 09:03:08,865 DEBUG TRAIN Batch 4/4900 loss 21.283552 loss_att 22.986279 loss_ctc 30.839132 loss_rnnt 16.593628 hw_loss 0.576619 lr 0.00080828 rank 5
2023-02-11 09:03:08,866 DEBUG TRAIN Batch 4/4900 loss 34.825710 loss_att 42.570686 loss_ctc 58.905525 loss_rnnt 28.664825 hw_loss 0.262733 lr 0.00080785 rank 2
2023-02-11 09:03:08,867 DEBUG TRAIN Batch 4/4900 loss 16.121716 loss_att 19.638933 loss_ctc 22.726740 loss_rnnt 12.269647 hw_loss 0.425242 lr 0.00080793 rank 0
2023-02-11 09:03:08,908 DEBUG TRAIN Batch 4/4900 loss 31.605156 loss_att 32.253014 loss_ctc 36.855202 loss_rnnt 27.361177 hw_loss 0.640200 lr 0.00080876 rank 4
2023-02-11 09:04:28,503 DEBUG TRAIN Batch 4/5000 loss 23.995483 loss_att 29.492941 loss_ctc 36.496304 loss_rnnt 18.049513 hw_loss 0.596195 lr 0.00080746 rank 3
2023-02-11 09:04:28,507 DEBUG TRAIN Batch 4/5000 loss 32.195030 loss_att 32.358467 loss_ctc 39.010231 loss_rnnt 28.584702 hw_loss 0.500427 lr 0.00080680 rank 2
2023-02-11 09:04:28,508 DEBUG TRAIN Batch 4/5000 loss 35.497620 loss_att 41.077335 loss_ctc 48.296192 loss_rnnt 31.260216 hw_loss 0.265309 lr 0.00080770 rank 7
2023-02-11 09:04:28,510 DEBUG TRAIN Batch 4/5000 loss 18.514931 loss_att 18.809299 loss_ctc 28.622541 loss_rnnt 14.737430 hw_loss 0.444552 lr 0.00080688 rank 0
2023-02-11 09:04:28,513 DEBUG TRAIN Batch 4/5000 loss 24.407341 loss_att 28.902187 loss_ctc 37.891205 loss_rnnt 18.185131 hw_loss 0.661011 lr 0.00080723 rank 5
2023-02-11 09:04:28,516 DEBUG TRAIN Batch 4/5000 loss 17.069065 loss_att 18.703083 loss_ctc 27.941181 loss_rnnt 10.165863 hw_loss 0.961272 lr 0.00080696 rank 1
2023-02-11 09:04:28,516 DEBUG TRAIN Batch 4/5000 loss 17.001518 loss_att 20.063082 loss_ctc 29.547077 loss_rnnt 10.795240 hw_loss 0.735229 lr 0.00080770 rank 4
2023-02-11 09:04:28,560 DEBUG TRAIN Batch 4/5000 loss 29.889236 loss_att 30.531519 loss_ctc 40.202030 loss_rnnt 25.834980 hw_loss 0.478268 lr 0.00080761 rank 6
2023-02-11 09:05:45,212 DEBUG TRAIN Batch 4/5100 loss 27.649420 loss_att 27.869289 loss_ctc 43.466778 loss_rnnt 24.204826 hw_loss 0.242182 lr 0.00080641 rank 3
2023-02-11 09:05:45,214 DEBUG TRAIN Batch 4/5100 loss 13.133986 loss_att 9.848022 loss_ctc 13.993473 loss_rnnt 8.680113 hw_loss 0.936838 lr 0.00080583 rank 0
2023-02-11 09:05:45,218 DEBUG TRAIN Batch 4/5100 loss 13.989347 loss_att 10.725323 loss_ctc 13.171854 loss_rnnt 9.243940 hw_loss 1.032602 lr 0.00080575 rank 2
2023-02-11 09:05:45,218 DEBUG TRAIN Batch 4/5100 loss 33.567348 loss_att 34.191700 loss_ctc 43.778713 loss_rnnt 29.134106 hw_loss 0.552536 lr 0.00080665 rank 7
2023-02-11 09:05:45,220 DEBUG TRAIN Batch 4/5100 loss 20.452932 loss_att 20.122608 loss_ctc 23.879601 loss_rnnt 15.081935 hw_loss 0.933783 lr 0.00080656 rank 6
2023-02-11 09:05:45,220 DEBUG TRAIN Batch 4/5100 loss 24.713720 loss_att 23.139477 loss_ctc 26.043625 loss_rnnt 21.946434 hw_loss 0.544652 lr 0.00080618 rank 5
2023-02-11 09:05:45,226 DEBUG TRAIN Batch 4/5100 loss 16.750950 loss_att 20.193857 loss_ctc 23.970673 loss_rnnt 13.416504 hw_loss 0.315607 lr 0.00080591 rank 1
2023-02-11 09:05:45,263 DEBUG TRAIN Batch 4/5100 loss 22.116798 loss_att 25.618317 loss_ctc 24.679241 loss_rnnt 14.431562 hw_loss 1.245614 lr 0.00080665 rank 4
2023-02-11 09:07:02,057 DEBUG TRAIN Batch 4/5200 loss 22.769320 loss_att 27.770226 loss_ctc 39.240799 loss_rnnt 16.230085 hw_loss 0.626786 lr 0.00080536 rank 3
2023-02-11 09:07:02,058 DEBUG TRAIN Batch 4/5200 loss 16.514511 loss_att 22.497391 loss_ctc 31.676807 loss_rnnt 12.850051 hw_loss 0.083671 lr 0.00080560 rank 7
2023-02-11 09:07:02,062 DEBUG TRAIN Batch 4/5200 loss 16.126507 loss_att 19.161999 loss_ctc 22.030430 loss_rnnt 10.442734 hw_loss 0.804279 lr 0.00080479 rank 0
2023-02-11 09:07:02,064 DEBUG TRAIN Batch 4/5200 loss 27.305883 loss_att 31.986597 loss_ctc 34.521091 loss_rnnt 23.074509 hw_loss 0.437476 lr 0.00080513 rank 5
2023-02-11 09:07:02,065 DEBUG TRAIN Batch 4/5200 loss 26.573456 loss_att 30.015141 loss_ctc 34.366287 loss_rnnt 22.542326 hw_loss 0.431953 lr 0.00080560 rank 4
2023-02-11 09:07:02,065 DEBUG TRAIN Batch 4/5200 loss 27.904076 loss_att 32.446404 loss_ctc 41.229656 loss_rnnt 21.293728 hw_loss 0.735963 lr 0.00080471 rank 2
2023-02-11 09:07:02,067 DEBUG TRAIN Batch 4/5200 loss 13.388647 loss_att 16.575867 loss_ctc 22.410498 loss_rnnt 9.259176 hw_loss 0.429209 lr 0.00080551 rank 6
2023-02-11 09:07:02,113 DEBUG TRAIN Batch 4/5200 loss 12.259785 loss_att 14.586864 loss_ctc 17.001478 loss_rnnt 8.356707 hw_loss 0.526019 lr 0.00080486 rank 1
2023-02-11 09:08:21,522 DEBUG TRAIN Batch 4/5300 loss 27.258007 loss_att 31.022358 loss_ctc 41.002407 loss_rnnt 22.903137 hw_loss 0.331765 lr 0.00080375 rank 0
2023-02-11 09:08:21,525 DEBUG TRAIN Batch 4/5300 loss 14.892043 loss_att 16.533850 loss_ctc 20.168671 loss_rnnt 12.543480 hw_loss 0.246872 lr 0.00080409 rank 5
2023-02-11 09:08:21,528 DEBUG TRAIN Batch 4/5300 loss 34.860950 loss_att 38.092773 loss_ctc 44.445671 loss_rnnt 31.911530 hw_loss 0.192206 lr 0.00080432 rank 3
2023-02-11 09:08:21,529 DEBUG TRAIN Batch 4/5300 loss 14.692824 loss_att 18.519318 loss_ctc 24.365692 loss_rnnt 10.063503 hw_loss 0.482682 lr 0.00080447 rank 6
2023-02-11 09:08:21,529 DEBUG TRAIN Batch 4/5300 loss 30.768156 loss_att 32.529903 loss_ctc 47.659805 loss_rnnt 26.055084 hw_loss 0.395344 lr 0.00080367 rank 2
2023-02-11 09:08:21,530 DEBUG TRAIN Batch 4/5300 loss 34.334469 loss_att 45.460949 loss_ctc 50.068645 loss_rnnt 29.393665 hw_loss 0.115803 lr 0.00080382 rank 1
2023-02-11 09:08:21,533 DEBUG TRAIN Batch 4/5300 loss 22.121655 loss_att 24.866755 loss_ctc 32.857300 loss_rnnt 15.743205 hw_loss 0.824627 lr 0.00080456 rank 7
2023-02-11 09:08:21,534 DEBUG TRAIN Batch 4/5300 loss 17.009148 loss_att 19.874638 loss_ctc 31.084042 loss_rnnt 11.074842 hw_loss 0.653354 lr 0.00080456 rank 4
2023-02-11 09:09:38,596 DEBUG TRAIN Batch 4/5400 loss 20.915602 loss_att 22.508829 loss_ctc 30.504375 loss_rnnt 17.137745 hw_loss 0.408883 lr 0.00080305 rank 5
2023-02-11 09:09:38,596 DEBUG TRAIN Batch 4/5400 loss 27.704399 loss_att 27.277802 loss_ctc 38.840302 loss_rnnt 22.354542 hw_loss 0.740698 lr 0.00080271 rank 0
2023-02-11 09:09:38,596 DEBUG TRAIN Batch 4/5400 loss 18.410934 loss_att 26.620735 loss_ctc 31.897079 loss_rnnt 12.444265 hw_loss 0.473729 lr 0.00080328 rank 3
2023-02-11 09:09:38,599 DEBUG TRAIN Batch 4/5400 loss 33.384407 loss_att 36.784988 loss_ctc 51.669724 loss_rnnt 26.250193 hw_loss 0.753010 lr 0.00080263 rank 2
2023-02-11 09:09:38,600 DEBUG TRAIN Batch 4/5400 loss 8.160079 loss_att 11.840028 loss_ctc 15.859295 loss_rnnt 3.983572 hw_loss 0.452617 lr 0.00080352 rank 7
2023-02-11 09:09:38,601 DEBUG TRAIN Batch 4/5400 loss 29.552872 loss_att 30.422241 loss_ctc 41.162476 loss_rnnt 26.069983 hw_loss 0.330200 lr 0.00080343 rank 6
2023-02-11 09:09:38,602 DEBUG TRAIN Batch 4/5400 loss 28.604454 loss_att 27.046635 loss_ctc 41.013069 loss_rnnt 24.865627 hw_loss 0.449233 lr 0.00080352 rank 4
2023-02-11 09:09:38,604 DEBUG TRAIN Batch 4/5400 loss 34.610188 loss_att 38.557030 loss_ctc 56.824287 loss_rnnt 28.840582 hw_loss 0.378442 lr 0.00080278 rank 1
2023-02-11 09:10:53,065 DEBUG TRAIN Batch 4/5500 loss 18.085768 loss_att 20.894278 loss_ctc 30.571445 loss_rnnt 14.399474 hw_loss 0.273719 lr 0.00080168 rank 0
2023-02-11 09:10:53,065 DEBUG TRAIN Batch 4/5500 loss 14.556279 loss_att 15.596525 loss_ctc 22.365341 loss_rnnt 11.692348 hw_loss 0.302751 lr 0.00080248 rank 7
2023-02-11 09:10:53,067 DEBUG TRAIN Batch 4/5500 loss 16.689896 loss_att 20.604641 loss_ctc 23.671091 loss_rnnt 13.757803 hw_loss 0.228435 lr 0.00080202 rank 5
2023-02-11 09:10:53,069 DEBUG TRAIN Batch 4/5500 loss 26.503447 loss_att 29.913895 loss_ctc 44.638817 loss_rnnt 20.909996 hw_loss 0.467495 lr 0.00080239 rank 6
2023-02-11 09:10:53,070 DEBUG TRAIN Batch 4/5500 loss 28.861423 loss_att 31.978828 loss_ctc 39.041000 loss_rnnt 25.015511 hw_loss 0.349716 lr 0.00080225 rank 3
2023-02-11 09:10:53,072 DEBUG TRAIN Batch 4/5500 loss 25.719465 loss_att 31.188509 loss_ctc 42.270294 loss_rnnt 20.995131 hw_loss 0.266953 lr 0.00080160 rank 2
2023-02-11 09:10:53,073 DEBUG TRAIN Batch 4/5500 loss 19.181479 loss_att 20.179613 loss_ctc 29.670456 loss_rnnt 14.900898 hw_loss 0.502954 lr 0.00080248 rank 4
2023-02-11 09:10:53,075 DEBUG TRAIN Batch 4/5500 loss 16.216536 loss_att 19.739420 loss_ctc 29.267069 loss_rnnt 10.005752 hw_loss 0.706150 lr 0.00080175 rank 1
2023-02-11 09:12:09,853 DEBUG TRAIN Batch 4/5600 loss 32.816910 loss_att 33.426128 loss_ctc 49.183285 loss_rnnt 28.199677 hw_loss 0.433726 lr 0.00080145 rank 4
2023-02-11 09:12:09,853 DEBUG TRAIN Batch 4/5600 loss 26.016899 loss_att 28.677837 loss_ctc 32.849434 loss_rnnt 20.186314 hw_loss 0.822636 lr 0.00080072 rank 1
2023-02-11 09:12:09,855 DEBUG TRAIN Batch 4/5600 loss 24.464197 loss_att 26.557400 loss_ctc 31.479849 loss_rnnt 21.274311 hw_loss 0.344217 lr 0.00080122 rank 3
2023-02-11 09:12:09,856 DEBUG TRAIN Batch 4/5600 loss 17.757921 loss_att 22.252151 loss_ctc 31.752907 loss_rnnt 12.816730 hw_loss 0.408065 lr 0.00080136 rank 6
2023-02-11 09:12:09,856 DEBUG TRAIN Batch 4/5600 loss 15.799269 loss_att 18.989401 loss_ctc 20.965403 loss_rnnt 12.807825 hw_loss 0.312112 lr 0.00080057 rank 2
2023-02-11 09:12:09,857 DEBUG TRAIN Batch 4/5600 loss 46.787106 loss_att 46.342972 loss_ctc 70.974388 loss_rnnt 39.943039 hw_loss 0.695235 lr 0.00080145 rank 7
2023-02-11 09:12:09,858 DEBUG TRAIN Batch 4/5600 loss 19.376263 loss_att 19.901239 loss_ctc 27.867926 loss_rnnt 16.313522 hw_loss 0.342286 lr 0.00080065 rank 0
2023-02-11 09:12:09,859 DEBUG TRAIN Batch 4/5600 loss 16.419758 loss_att 19.866316 loss_ctc 29.848961 loss_rnnt 11.793852 hw_loss 0.402381 lr 0.00080099 rank 5
2023-02-11 09:13:29,483 DEBUG TRAIN Batch 4/5700 loss 12.181170 loss_att 7.738688 loss_ctc 9.675446 loss_rnnt 6.134810 hw_loss 1.362928 lr 0.00079963 rank 0
2023-02-11 09:13:29,489 DEBUG TRAIN Batch 4/5700 loss 17.028706 loss_att 15.796537 loss_ctc 22.117428 loss_rnnt 13.263152 hw_loss 0.625029 lr 0.00079970 rank 1
2023-02-11 09:13:29,489 DEBUG TRAIN Batch 4/5700 loss 18.072498 loss_att 14.647339 loss_ctc 19.878666 loss_rnnt 12.005569 hw_loss 1.220839 lr 0.00079954 rank 2
2023-02-11 09:13:29,489 DEBUG TRAIN Batch 4/5700 loss 22.011116 loss_att 22.633471 loss_ctc 31.248438 loss_rnnt 17.910904 hw_loss 0.514518 lr 0.00080019 rank 3
2023-02-11 09:13:29,492 DEBUG TRAIN Batch 4/5700 loss 19.834734 loss_att 22.706713 loss_ctc 34.312782 loss_rnnt 15.217158 hw_loss 0.396145 lr 0.00080043 rank 4
2023-02-11 09:13:29,498 DEBUG TRAIN Batch 4/5700 loss 25.431246 loss_att 27.569510 loss_ctc 35.662457 loss_rnnt 20.098825 hw_loss 0.663864 lr 0.00080043 rank 7
2023-02-11 09:13:29,500 DEBUG TRAIN Batch 4/5700 loss 15.024935 loss_att 19.276011 loss_ctc 29.538588 loss_rnnt 10.881363 hw_loss 0.254663 lr 0.00080033 rank 6
2023-02-11 09:13:29,510 DEBUG TRAIN Batch 4/5700 loss 26.543999 loss_att 25.516832 loss_ctc 31.891205 loss_rnnt 21.503387 hw_loss 0.849953 lr 0.00079996 rank 5
2023-02-11 09:14:45,937 DEBUG TRAIN Batch 4/5800 loss 37.479588 loss_att 41.511757 loss_ctc 61.140518 loss_rnnt 29.589794 hw_loss 0.736607 lr 0.00079861 rank 0
2023-02-11 09:14:45,940 DEBUG TRAIN Batch 4/5800 loss 15.021979 loss_att 22.407040 loss_ctc 24.900480 loss_rnnt 11.107539 hw_loss 0.210055 lr 0.00079917 rank 3
2023-02-11 09:14:45,941 DEBUG TRAIN Batch 4/5800 loss 21.197258 loss_att 26.190001 loss_ctc 35.450996 loss_rnnt 18.191319 hw_loss 0.020042 lr 0.00079868 rank 1
2023-02-11 09:14:45,942 DEBUG TRAIN Batch 4/5800 loss 14.921108 loss_att 11.626700 loss_ctc 15.430969 loss_rnnt 10.308251 hw_loss 0.975704 lr 0.00079894 rank 5
2023-02-11 09:14:45,943 DEBUG TRAIN Batch 4/5800 loss 21.880487 loss_att 20.586658 loss_ctc 24.112173 loss_rnnt 18.414799 hw_loss 0.642543 lr 0.00079940 rank 4
2023-02-11 09:14:45,943 DEBUG TRAIN Batch 4/5800 loss 24.561569 loss_att 27.297869 loss_ctc 40.781979 loss_rnnt 19.523497 hw_loss 0.436517 lr 0.00079940 rank 7
2023-02-11 09:14:45,947 DEBUG TRAIN Batch 4/5800 loss 31.201132 loss_att 35.752453 loss_ctc 52.671062 loss_rnnt 24.376877 hw_loss 0.572125 lr 0.00079852 rank 2
2023-02-11 09:14:45,947 DEBUG TRAIN Batch 4/5800 loss 21.669529 loss_att 20.733791 loss_ctc 29.291195 loss_rnnt 16.274132 hw_loss 0.856186 lr 0.00079931 rank 6
2023-02-11 09:16:01,360 DEBUG TRAIN Batch 4/5900 loss 30.974237 loss_att 33.990273 loss_ctc 42.970200 loss_rnnt 26.216259 hw_loss 0.479121 lr 0.00079829 rank 6
2023-02-11 09:16:01,362 DEBUG TRAIN Batch 4/5900 loss 17.540598 loss_att 21.687428 loss_ctc 26.593824 loss_rnnt 13.430410 hw_loss 0.388823 lr 0.00079815 rank 3
2023-02-11 09:16:01,362 DEBUG TRAIN Batch 4/5900 loss 20.795202 loss_att 21.936934 loss_ctc 28.491756 loss_rnnt 17.292171 hw_loss 0.421589 lr 0.00079759 rank 0
2023-02-11 09:16:01,362 DEBUG TRAIN Batch 4/5900 loss 15.759492 loss_att 23.335587 loss_ctc 28.001272 loss_rnnt 9.360922 hw_loss 0.609584 lr 0.00079838 rank 7
2023-02-11 09:16:01,363 DEBUG TRAIN Batch 4/5900 loss 19.652845 loss_att 23.048866 loss_ctc 36.164299 loss_rnnt 14.045706 hw_loss 0.511201 lr 0.00079838 rank 4
2023-02-11 09:16:01,363 DEBUG TRAIN Batch 4/5900 loss 18.974060 loss_att 22.210415 loss_ctc 28.646515 loss_rnnt 15.789560 hw_loss 0.233919 lr 0.00079766 rank 1
2023-02-11 09:16:01,363 DEBUG TRAIN Batch 4/5900 loss 21.041035 loss_att 30.299854 loss_ctc 32.019951 loss_rnnt 15.555889 hw_loss 0.406786 lr 0.00079792 rank 5
2023-02-11 09:16:01,364 DEBUG TRAIN Batch 4/5900 loss 25.375086 loss_att 28.281151 loss_ctc 31.825750 loss_rnnt 21.036530 hw_loss 0.543235 lr 0.00079751 rank 2
2023-02-11 09:17:18,616 DEBUG TRAIN Batch 4/6000 loss 25.778917 loss_att 28.641796 loss_ctc 37.565979 loss_rnnt 22.431520 hw_loss 0.225603 lr 0.00079650 rank 2
2023-02-11 09:17:18,620 DEBUG TRAIN Batch 4/6000 loss 27.808882 loss_att 31.777500 loss_ctc 39.856583 loss_rnnt 21.574303 hw_loss 0.718968 lr 0.00079658 rank 0
2023-02-11 09:17:18,620 DEBUG TRAIN Batch 4/6000 loss 25.733603 loss_att 29.879902 loss_ctc 39.574738 loss_rnnt 18.911339 hw_loss 0.777660 lr 0.00079727 rank 6
2023-02-11 09:17:18,621 DEBUG TRAIN Batch 4/6000 loss 18.406799 loss_att 21.879959 loss_ctc 30.381697 loss_rnnt 13.634418 hw_loss 0.465205 lr 0.00079713 rank 3
2023-02-11 09:17:18,623 DEBUG TRAIN Batch 4/6000 loss 26.329435 loss_att 35.961243 loss_ctc 44.391857 loss_rnnt 21.121181 hw_loss 0.163795 lr 0.00079737 rank 7
2023-02-11 09:17:18,627 DEBUG TRAIN Batch 4/6000 loss 35.071327 loss_att 39.261211 loss_ctc 45.697304 loss_rnnt 29.433424 hw_loss 0.634336 lr 0.00079665 rank 1
2023-02-11 09:17:18,627 DEBUG TRAIN Batch 4/6000 loss 26.054453 loss_att 27.705917 loss_ctc 38.408234 loss_rnnt 20.690580 hw_loss 0.634952 lr 0.00079691 rank 5
2023-02-11 09:17:18,673 DEBUG TRAIN Batch 4/6000 loss 28.047009 loss_att 40.029316 loss_ctc 43.266006 loss_rnnt 20.809673 hw_loss 0.527189 lr 0.00079737 rank 4
2023-02-11 09:18:36,617 DEBUG TRAIN Batch 4/6100 loss 26.310307 loss_att 26.767006 loss_ctc 43.551685 loss_rnnt 19.858217 hw_loss 0.761606 lr 0.00079635 rank 4
2023-02-11 09:18:36,619 DEBUG TRAIN Batch 4/6100 loss 30.429798 loss_att 31.373751 loss_ctc 44.700466 loss_rnnt 26.370106 hw_loss 0.369027 lr 0.00079564 rank 1
2023-02-11 09:18:36,619 DEBUG TRAIN Batch 4/6100 loss 19.868628 loss_att 25.193275 loss_ctc 31.763170 loss_rnnt 14.013550 hw_loss 0.600789 lr 0.00079635 rank 7
2023-02-11 09:18:36,619 DEBUG TRAIN Batch 4/6100 loss 26.467260 loss_att 28.992615 loss_ctc 40.012383 loss_rnnt 22.499611 hw_loss 0.310605 lr 0.00079612 rank 3
2023-02-11 09:18:36,620 DEBUG TRAIN Batch 4/6100 loss 46.421082 loss_att 48.843407 loss_ctc 65.369469 loss_rnnt 41.385384 hw_loss 0.379646 lr 0.00079626 rank 6
2023-02-11 09:18:36,623 DEBUG TRAIN Batch 4/6100 loss 28.838247 loss_att 26.980083 loss_ctc 31.677864 loss_rnnt 24.408276 hw_loss 0.829311 lr 0.00079549 rank 2
2023-02-11 09:18:36,623 DEBUG TRAIN Batch 4/6100 loss 17.320635 loss_att 19.645760 loss_ctc 23.596252 loss_rnnt 12.772710 hw_loss 0.608653 lr 0.00079590 rank 5
2023-02-11 09:18:36,624 DEBUG TRAIN Batch 4/6100 loss 20.983738 loss_att 26.353968 loss_ctc 33.249321 loss_rnnt 16.274115 hw_loss 0.375031 lr 0.00079557 rank 0
2023-02-11 09:19:52,492 DEBUG TRAIN Batch 4/6200 loss 22.852564 loss_att 26.568775 loss_ctc 36.015579 loss_rnnt 17.845570 hw_loss 0.470378 lr 0.00079489 rank 5
2023-02-11 09:19:52,496 DEBUG TRAIN Batch 4/6200 loss 14.554586 loss_att 17.824808 loss_ctc 26.232979 loss_rnnt 11.469509 hw_loss 0.163859 lr 0.00079535 rank 7
2023-02-11 09:19:52,497 DEBUG TRAIN Batch 4/6200 loss 27.258398 loss_att 27.753181 loss_ctc 39.782177 loss_rnnt 22.804056 hw_loss 0.503540 lr 0.00079456 rank 0
2023-02-11 09:19:52,499 DEBUG TRAIN Batch 4/6200 loss 11.313114 loss_att 13.797655 loss_ctc 22.517305 loss_rnnt 7.757503 hw_loss 0.293402 lr 0.00079511 rank 3
2023-02-11 09:19:52,500 DEBUG TRAIN Batch 4/6200 loss 22.724236 loss_att 28.761005 loss_ctc 43.165756 loss_rnnt 16.274529 hw_loss 0.471903 lr 0.00079535 rank 4
2023-02-11 09:19:52,500 DEBUG TRAIN Batch 4/6200 loss 18.471788 loss_att 22.461004 loss_ctc 27.619892 loss_rnnt 14.438253 hw_loss 0.377990 lr 0.00079526 rank 6
2023-02-11 09:19:52,502 DEBUG TRAIN Batch 4/6200 loss 19.321150 loss_att 19.347275 loss_ctc 26.488125 loss_rnnt 13.056145 hw_loss 0.994534 lr 0.00079463 rank 1
2023-02-11 09:19:52,546 DEBUG TRAIN Batch 4/6200 loss 21.408447 loss_att 21.469437 loss_ctc 26.849432 loss_rnnt 16.785122 hw_loss 0.728562 lr 0.00079448 rank 2
2023-02-11 09:21:08,633 DEBUG TRAIN Batch 4/6300 loss 15.977030 loss_att 16.373472 loss_ctc 20.251915 loss_rnnt 9.594211 hw_loss 1.075040 lr 0.00079434 rank 7
2023-02-11 09:21:08,633 DEBUG TRAIN Batch 4/6300 loss 18.795803 loss_att 13.930725 loss_ctc 17.367647 loss_rnnt 13.228733 hw_loss 1.261970 lr 0.00079348 rank 2
2023-02-11 09:21:08,634 DEBUG TRAIN Batch 4/6300 loss 18.776752 loss_att 11.746184 loss_ctc 14.864621 loss_rnnt 11.318902 hw_loss 1.759796 lr 0.00079356 rank 0
2023-02-11 09:21:08,634 DEBUG TRAIN Batch 4/6300 loss 12.595211 loss_att 16.926277 loss_ctc 18.727100 loss_rnnt 9.168965 hw_loss 0.326709 lr 0.00079389 rank 5
2023-02-11 09:21:08,637 DEBUG TRAIN Batch 4/6300 loss 20.570576 loss_att 23.206837 loss_ctc 32.822884 loss_rnnt 15.689185 hw_loss 0.510093 lr 0.00079411 rank 3
2023-02-11 09:21:08,637 DEBUG TRAIN Batch 4/6300 loss 19.438101 loss_att 18.728188 loss_ctc 27.726706 loss_rnnt 16.490509 hw_loss 0.372080 lr 0.00079434 rank 4
2023-02-11 09:21:08,639 DEBUG TRAIN Batch 4/6300 loss 28.237318 loss_att 30.452387 loss_ctc 49.371712 loss_rnnt 21.968628 hw_loss 0.563954 lr 0.00079425 rank 6
2023-02-11 09:21:08,687 DEBUG TRAIN Batch 4/6300 loss 24.008556 loss_att 25.022675 loss_ctc 30.374786 loss_rnnt 19.413445 hw_loss 0.664398 lr 0.00079363 rank 1
2023-02-11 09:22:28,094 DEBUG TRAIN Batch 4/6400 loss 14.177108 loss_att 16.117981 loss_ctc 21.160976 loss_rnnt 9.536773 hw_loss 0.622683 lr 0.00079311 rank 3
2023-02-11 09:22:28,098 DEBUG TRAIN Batch 4/6400 loss 17.317406 loss_att 20.587046 loss_ctc 27.331753 loss_rnnt 11.753147 hw_loss 0.670328 lr 0.00079334 rank 7
2023-02-11 09:22:28,100 DEBUG TRAIN Batch 4/6400 loss 19.729549 loss_att 19.351803 loss_ctc 25.900787 loss_rnnt 16.472996 hw_loss 0.470488 lr 0.00079263 rank 1
2023-02-11 09:22:28,103 DEBUG TRAIN Batch 4/6400 loss 33.004665 loss_att 34.729259 loss_ctc 54.360466 loss_rnnt 25.768120 hw_loss 0.758285 lr 0.00079248 rank 2
2023-02-11 09:22:28,105 DEBUG TRAIN Batch 4/6400 loss 27.291115 loss_att 30.559381 loss_ctc 48.890503 loss_rnnt 21.129910 hw_loss 0.492681 lr 0.00079334 rank 4
2023-02-11 09:22:28,121 DEBUG TRAIN Batch 4/6400 loss 29.457981 loss_att 27.531832 loss_ctc 44.267075 loss_rnnt 24.494106 hw_loss 0.632730 lr 0.00079256 rank 0
2023-02-11 09:22:28,124 DEBUG TRAIN Batch 4/6400 loss 15.584913 loss_att 12.359392 loss_ctc 15.895343 loss_rnnt 10.720203 hw_loss 1.025330 lr 0.00079289 rank 5
2023-02-11 09:22:28,143 DEBUG TRAIN Batch 4/6400 loss 28.095121 loss_att 32.600075 loss_ctc 44.604961 loss_rnnt 23.361404 hw_loss 0.305890 lr 0.00079325 rank 6
2023-02-11 09:23:44,009 DEBUG TRAIN Batch 4/6500 loss 28.717333 loss_att 29.563099 loss_ctc 37.029610 loss_rnnt 22.569206 hw_loss 0.913251 lr 0.00079212 rank 3
2023-02-11 09:23:44,012 DEBUG TRAIN Batch 4/6500 loss 12.417286 loss_att 18.401684 loss_ctc 22.537670 loss_rnnt 8.953479 hw_loss 0.172039 lr 0.00079149 rank 2
2023-02-11 09:23:44,012 DEBUG TRAIN Batch 4/6500 loss 18.814852 loss_att 24.645939 loss_ctc 29.333014 loss_rnnt 13.985538 hw_loss 0.423876 lr 0.00079234 rank 7
2023-02-11 09:23:44,012 DEBUG TRAIN Batch 4/6500 loss 30.585096 loss_att 31.763817 loss_ctc 45.911133 loss_rnnt 25.766790 hw_loss 0.476079 lr 0.00079157 rank 0
2023-02-11 09:23:44,015 DEBUG TRAIN Batch 4/6500 loss 35.694508 loss_att 46.264450 loss_ctc 59.565605 loss_rnnt 28.802608 hw_loss 0.299081 lr 0.00079190 rank 5
2023-02-11 09:23:44,016 DEBUG TRAIN Batch 4/6500 loss 19.131701 loss_att 23.997356 loss_ctc 38.001923 loss_rnnt 13.648890 hw_loss 0.373809 lr 0.00079225 rank 6
2023-02-11 09:23:44,017 DEBUG TRAIN Batch 4/6500 loss 24.622562 loss_att 32.474007 loss_ctc 43.149300 loss_rnnt 18.072777 hw_loss 0.470487 lr 0.00079234 rank 4
2023-02-11 09:23:44,062 DEBUG TRAIN Batch 4/6500 loss 19.777359 loss_att 26.271954 loss_ctc 33.749325 loss_rnnt 16.507025 hw_loss 0.020342 lr 0.00079164 rank 1
2023-02-11 09:25:00,826 DEBUG TRAIN Batch 4/6600 loss 19.628899 loss_att 27.412800 loss_ctc 28.698936 loss_rnnt 15.257377 hw_loss 0.301013 lr 0.00079135 rank 7
2023-02-11 09:25:00,828 DEBUG TRAIN Batch 4/6600 loss 35.355465 loss_att 39.395271 loss_ctc 53.874279 loss_rnnt 29.697226 hw_loss 0.446457 lr 0.00079058 rank 0
2023-02-11 09:25:00,829 DEBUG TRAIN Batch 4/6600 loss 19.311985 loss_att 22.895390 loss_ctc 30.585159 loss_rnnt 14.970230 hw_loss 0.397872 lr 0.00079065 rank 1
2023-02-11 09:25:00,830 DEBUG TRAIN Batch 4/6600 loss 19.614222 loss_att 23.803976 loss_ctc 27.187216 loss_rnnt 14.726962 hw_loss 0.569921 lr 0.00079135 rank 4
2023-02-11 09:25:00,831 DEBUG TRAIN Batch 4/6600 loss 22.822552 loss_att 23.999046 loss_ctc 32.893791 loss_rnnt 18.014336 hw_loss 0.605641 lr 0.00079126 rank 6
2023-02-11 09:25:00,834 DEBUG TRAIN Batch 4/6600 loss 22.328951 loss_att 28.682674 loss_ctc 37.211403 loss_rnnt 18.710037 hw_loss 0.068221 lr 0.00079112 rank 3
2023-02-11 09:25:00,835 DEBUG TRAIN Batch 4/6600 loss 23.879665 loss_att 29.158285 loss_ctc 35.741295 loss_rnnt 17.280014 hw_loss 0.742946 lr 0.00079091 rank 5
2023-02-11 09:25:00,838 DEBUG TRAIN Batch 4/6600 loss 25.111443 loss_att 30.714088 loss_ctc 33.496605 loss_rnnt 18.869900 hw_loss 0.750561 lr 0.00079050 rank 2
2023-02-11 09:26:16,851 DEBUG TRAIN Batch 4/6700 loss 20.069344 loss_att 25.431046 loss_ctc 37.398777 loss_rnnt 15.289526 hw_loss 0.261916 lr 0.00079036 rank 7
2023-02-11 09:26:16,855 DEBUG TRAIN Batch 4/6700 loss 23.873125 loss_att 24.759993 loss_ctc 36.438446 loss_rnnt 19.092979 hw_loss 0.548887 lr 0.00079036 rank 4
2023-02-11 09:26:16,858 DEBUG TRAIN Batch 4/6700 loss 19.350050 loss_att 25.580441 loss_ctc 27.650169 loss_rnnt 13.230664 hw_loss 0.706242 lr 0.00078959 rank 0
2023-02-11 09:26:16,859 DEBUG TRAIN Batch 4/6700 loss 28.623892 loss_att 31.379822 loss_ctc 37.691597 loss_rnnt 23.522909 hw_loss 0.626394 lr 0.00079013 rank 3
2023-02-11 09:26:16,861 DEBUG TRAIN Batch 4/6700 loss 21.799458 loss_att 24.710815 loss_ctc 33.103485 loss_rnnt 16.406710 hw_loss 0.619363 lr 0.00079027 rank 6
2023-02-11 09:26:16,862 DEBUG TRAIN Batch 4/6700 loss 19.841072 loss_att 22.739868 loss_ctc 31.699835 loss_rnnt 15.676652 hw_loss 0.375655 lr 0.00078966 rank 1
2023-02-11 09:26:16,864 DEBUG TRAIN Batch 4/6700 loss 16.619370 loss_att 24.280373 loss_ctc 32.988289 loss_rnnt 11.378731 hw_loss 0.286109 lr 0.00078992 rank 5
2023-02-11 09:26:16,907 DEBUG TRAIN Batch 4/6700 loss 37.144764 loss_att 42.528557 loss_ctc 56.729465 loss_rnnt 30.682903 hw_loss 0.520089 lr 0.00078951 rank 2
2023-02-11 09:27:35,042 DEBUG TRAIN Batch 4/6800 loss 17.669109 loss_att 20.567223 loss_ctc 26.542038 loss_rnnt 13.948615 hw_loss 0.367090 lr 0.00078938 rank 7
2023-02-11 09:27:35,043 DEBUG TRAIN Batch 4/6800 loss 22.017578 loss_att 19.894897 loss_ctc 27.094460 loss_rnnt 16.050835 hw_loss 1.071443 lr 0.00078861 rank 0
2023-02-11 09:27:35,043 DEBUG TRAIN Batch 4/6800 loss 27.377102 loss_att 33.027935 loss_ctc 40.911552 loss_rnnt 21.388123 hw_loss 0.572666 lr 0.00078915 rank 3
2023-02-11 09:27:35,044 DEBUG TRAIN Batch 4/6800 loss 37.536335 loss_att 41.117989 loss_ctc 54.318638 loss_rnnt 30.061760 hw_loss 0.847613 lr 0.00078929 rank 6
2023-02-11 09:27:35,045 DEBUG TRAIN Batch 4/6800 loss 22.367247 loss_att 25.710873 loss_ctc 33.320240 loss_rnnt 17.029381 hw_loss 0.601639 lr 0.00078868 rank 1
2023-02-11 09:27:35,045 DEBUG TRAIN Batch 4/6800 loss 17.397007 loss_att 20.185034 loss_ctc 28.315029 loss_rnnt 11.990284 hw_loss 0.636259 lr 0.00078893 rank 5
2023-02-11 09:27:35,092 DEBUG TRAIN Batch 4/6800 loss 18.080820 loss_att 22.926998 loss_ctc 33.059586 loss_rnnt 13.668465 hw_loss 0.271116 lr 0.00078853 rank 2
2023-02-11 09:27:35,096 DEBUG TRAIN Batch 4/6800 loss 44.806324 loss_att 54.912056 loss_ctc 73.635757 loss_rnnt 37.856216 hw_loss 0.203444 lr 0.00078938 rank 4
2023-02-11 09:28:50,411 DEBUG TRAIN Batch 4/6900 loss 17.914646 loss_att 24.156590 loss_ctc 32.782333 loss_rnnt 13.224097 hw_loss 0.273712 lr 0.00078770 rank 1
2023-02-11 09:28:50,411 DEBUG TRAIN Batch 4/6900 loss 19.878922 loss_att 18.802296 loss_ctc 28.490171 loss_rnnt 14.259587 hw_loss 0.878717 lr 0.00078817 rank 3
2023-02-11 09:28:50,417 DEBUG TRAIN Batch 4/6900 loss 19.344389 loss_att 17.978539 loss_ctc 24.704775 loss_rnnt 13.890209 hw_loss 0.939868 lr 0.00078763 rank 0
2023-02-11 09:28:50,419 DEBUG TRAIN Batch 4/6900 loss 36.939148 loss_att 44.113094 loss_ctc 56.027637 loss_rnnt 29.517540 hw_loss 0.645316 lr 0.00078839 rank 4
2023-02-11 09:28:50,419 DEBUG TRAIN Batch 4/6900 loss 16.533932 loss_att 21.860752 loss_ctc 31.008102 loss_rnnt 11.816238 hw_loss 0.322957 lr 0.00078839 rank 7
2023-02-11 09:28:50,419 DEBUG TRAIN Batch 4/6900 loss 19.068617 loss_att 23.214100 loss_ctc 29.414261 loss_rnnt 15.549375 hw_loss 0.245761 lr 0.00078795 rank 5
2023-02-11 09:28:50,420 DEBUG TRAIN Batch 4/6900 loss 24.317469 loss_att 24.267826 loss_ctc 35.120026 loss_rnnt 18.565334 hw_loss 0.810323 lr 0.00078755 rank 2
2023-02-11 09:28:50,461 DEBUG TRAIN Batch 4/6900 loss 25.600891 loss_att 27.575981 loss_ctc 38.736450 loss_rnnt 20.239027 hw_loss 0.602895 lr 0.00078831 rank 6
2023-02-11 09:30:07,096 DEBUG TRAIN Batch 4/7000 loss 25.894638 loss_att 21.408186 loss_ctc 30.208038 loss_rnnt 21.325327 hw_loss 0.917153 lr 0.00078719 rank 3
2023-02-11 09:30:07,100 DEBUG TRAIN Batch 4/7000 loss 14.495831 loss_att 16.294727 loss_ctc 23.573345 loss_rnnt 9.500844 hw_loss 0.642164 lr 0.00078733 rank 6
2023-02-11 09:30:07,102 DEBUG TRAIN Batch 4/7000 loss 19.307856 loss_att 14.841782 loss_ctc 18.760965 loss_rnnt 12.130502 hw_loss 1.526904 lr 0.00078742 rank 7
2023-02-11 09:30:07,106 DEBUG TRAIN Batch 4/7000 loss 26.823053 loss_att 30.873074 loss_ctc 35.395901 loss_rnnt 23.488752 hw_loss 0.258984 lr 0.00078666 rank 0
2023-02-11 09:30:07,107 DEBUG TRAIN Batch 4/7000 loss 27.680687 loss_att 34.225662 loss_ctc 43.835747 loss_rnnt 21.254574 hw_loss 0.555583 lr 0.00078658 rank 2
2023-02-11 09:30:07,110 DEBUG TRAIN Batch 4/7000 loss 13.767308 loss_att 11.798138 loss_ctc 14.642812 loss_rnnt 9.881356 hw_loss 0.780572 lr 0.00078742 rank 4
2023-02-11 09:30:07,110 DEBUG TRAIN Batch 4/7000 loss 20.905905 loss_att 16.523479 loss_ctc 21.563713 loss_rnnt 16.114761 hw_loss 1.046235 lr 0.00078698 rank 5
2023-02-11 09:30:07,155 DEBUG TRAIN Batch 4/7000 loss 15.579338 loss_att 10.129953 loss_ctc 13.476853 loss_rnnt 9.683064 hw_loss 1.362465 lr 0.00078672 rank 1
2023-02-11 09:31:26,347 DEBUG TRAIN Batch 4/7100 loss 14.658560 loss_att 21.583126 loss_ctc 21.285980 loss_rnnt 10.492939 hw_loss 0.355697 lr 0.00078600 rank 5
2023-02-11 09:31:26,348 DEBUG TRAIN Batch 4/7100 loss 18.668264 loss_att 22.415991 loss_ctc 28.344015 loss_rnnt 14.165946 hw_loss 0.461751 lr 0.00078575 rank 1
2023-02-11 09:31:26,349 DEBUG TRAIN Batch 4/7100 loss 30.036018 loss_att 33.134087 loss_ctc 51.911957 loss_rnnt 23.568930 hw_loss 0.549503 lr 0.00078568 rank 0
2023-02-11 09:31:26,352 DEBUG TRAIN Batch 4/7100 loss 34.193016 loss_att 34.128510 loss_ctc 50.268597 loss_rnnt 29.703125 hw_loss 0.442383 lr 0.00078622 rank 3
2023-02-11 09:31:26,352 DEBUG TRAIN Batch 4/7100 loss 17.146633 loss_att 23.853910 loss_ctc 34.751156 loss_rnnt 11.569083 hw_loss 0.354155 lr 0.00078635 rank 6
2023-02-11 09:31:26,352 DEBUG TRAIN Batch 4/7100 loss 33.064320 loss_att 40.841454 loss_ctc 54.382584 loss_rnnt 26.223349 hw_loss 0.458083 lr 0.00078561 rank 2
2023-02-11 09:31:26,354 DEBUG TRAIN Batch 4/7100 loss 16.449417 loss_att 17.810959 loss_ctc 23.156628 loss_rnnt 12.632397 hw_loss 0.496953 lr 0.00078644 rank 4
2023-02-11 09:31:26,354 DEBUG TRAIN Batch 4/7100 loss 13.228858 loss_att 18.424112 loss_ctc 24.427984 loss_rnnt 10.342265 hw_loss 0.066436 lr 0.00078644 rank 7
2023-02-11 09:32:43,987 DEBUG TRAIN Batch 4/7200 loss 27.769171 loss_att 33.664307 loss_ctc 45.682198 loss_rnnt 21.010380 hw_loss 0.598380 lr 0.00078525 rank 3
2023-02-11 09:32:43,990 DEBUG TRAIN Batch 4/7200 loss 25.069571 loss_att 26.086695 loss_ctc 36.131737 loss_rnnt 20.935457 hw_loss 0.460450 lr 0.00078503 rank 5
2023-02-11 09:32:43,993 DEBUG TRAIN Batch 4/7200 loss 11.782263 loss_att 14.344866 loss_ctc 19.323471 loss_rnnt 8.376732 hw_loss 0.353909 lr 0.00078538 rank 6
2023-02-11 09:32:43,994 DEBUG TRAIN Batch 4/7200 loss 40.121593 loss_att 41.594723 loss_ctc 56.835793 loss_rnnt 35.739594 hw_loss 0.348528 lr 0.00078472 rank 0
2023-02-11 09:32:43,996 DEBUG TRAIN Batch 4/7200 loss 21.948090 loss_att 21.245190 loss_ctc 35.217117 loss_rnnt 18.037436 hw_loss 0.427881 lr 0.00078464 rank 2
2023-02-11 09:32:43,996 DEBUG TRAIN Batch 4/7200 loss 14.421906 loss_att 13.533632 loss_ctc 15.784316 loss_rnnt 9.881104 hw_loss 0.850650 lr 0.00078547 rank 7
2023-02-11 09:32:43,997 DEBUG TRAIN Batch 4/7200 loss 17.505863 loss_att 20.182217 loss_ctc 29.366964 loss_rnnt 13.222613 hw_loss 0.406219 lr 0.00078547 rank 4
2023-02-11 09:32:43,997 DEBUG TRAIN Batch 4/7200 loss 21.147085 loss_att 25.182957 loss_ctc 34.389275 loss_rnnt 16.870335 hw_loss 0.319491 lr 0.00078478 rank 1
2023-02-11 09:34:00,375 DEBUG TRAIN Batch 4/7300 loss 18.042007 loss_att 19.709269 loss_ctc 28.960043 loss_rnnt 13.567719 hw_loss 0.503456 lr 0.00078450 rank 7
2023-02-11 09:34:00,375 DEBUG TRAIN Batch 4/7300 loss 18.671635 loss_att 23.039820 loss_ctc 29.923462 loss_rnnt 14.479347 hw_loss 0.340952 lr 0.00078442 rank 6
2023-02-11 09:34:00,378 DEBUG TRAIN Batch 4/7300 loss 27.275715 loss_att 31.188393 loss_ctc 39.008133 loss_rnnt 23.943642 hw_loss 0.184728 lr 0.00078428 rank 3
2023-02-11 09:34:00,379 DEBUG TRAIN Batch 4/7300 loss 17.705666 loss_att 17.530993 loss_ctc 22.295383 loss_rnnt 14.816074 hw_loss 0.433606 lr 0.00078375 rank 0
2023-02-11 09:34:00,379 DEBUG TRAIN Batch 4/7300 loss 17.475109 loss_att 20.259998 loss_ctc 24.094795 loss_rnnt 12.931098 hw_loss 0.582076 lr 0.00078367 rank 2
2023-02-11 09:34:00,382 DEBUG TRAIN Batch 4/7300 loss 19.729610 loss_att 24.204746 loss_ctc 24.002939 loss_rnnt 15.078300 hw_loss 0.597470 lr 0.00078407 rank 5
2023-02-11 09:34:00,384 DEBUG TRAIN Batch 4/7300 loss 16.208359 loss_att 17.343010 loss_ctc 22.849833 loss_rnnt 13.235596 hw_loss 0.348807 lr 0.00078450 rank 4
2023-02-11 09:34:00,429 DEBUG TRAIN Batch 4/7300 loss 46.471252 loss_att 46.349297 loss_ctc 64.027237 loss_rnnt 42.218739 hw_loss 0.363019 lr 0.00078382 rank 1
2023-02-11 09:35:18,564 DEBUG TRAIN Batch 4/7400 loss 24.157425 loss_att 33.367607 loss_ctc 36.460827 loss_rnnt 19.718121 hw_loss 0.179402 lr 0.00078271 rank 2
2023-02-11 09:35:18,566 DEBUG TRAIN Batch 4/7400 loss 9.775103 loss_att 14.316744 loss_ctc 16.309813 loss_rnnt 6.706674 hw_loss 0.241651 lr 0.00078279 rank 0
2023-02-11 09:35:18,569 DEBUG TRAIN Batch 4/7400 loss 20.730480 loss_att 22.056313 loss_ctc 30.685181 loss_rnnt 17.385014 hw_loss 0.328689 lr 0.00078311 rank 5
2023-02-11 09:35:18,571 DEBUG TRAIN Batch 4/7400 loss 17.802624 loss_att 21.239433 loss_ctc 26.288458 loss_rnnt 12.835700 hw_loss 0.590272 lr 0.00078286 rank 1
2023-02-11 09:35:18,571 DEBUG TRAIN Batch 4/7400 loss 31.828424 loss_att 31.329021 loss_ctc 41.171921 loss_rnnt 27.257710 hw_loss 0.642150 lr 0.00078354 rank 7
2023-02-11 09:35:18,571 DEBUG TRAIN Batch 4/7400 loss 40.430023 loss_att 36.309090 loss_ctc 51.843315 loss_rnnt 36.738377 hw_loss 0.561386 lr 0.00078332 rank 3
2023-02-11 09:35:18,575 DEBUG TRAIN Batch 4/7400 loss 28.862722 loss_att 33.779243 loss_ctc 51.635475 loss_rnnt 22.694796 hw_loss 0.402798 lr 0.00078354 rank 4
2023-02-11 09:35:18,591 DEBUG TRAIN Batch 4/7400 loss 37.771587 loss_att 44.223835 loss_ctc 44.180931 loss_rnnt 33.210033 hw_loss 0.453099 lr 0.00078345 rank 6
2023-02-11 09:36:37,261 DEBUG TRAIN Batch 4/7500 loss 16.570402 loss_att 17.426353 loss_ctc 22.445707 loss_rnnt 13.258743 hw_loss 0.441955 lr 0.00078183 rank 0
2023-02-11 09:36:37,261 DEBUG TRAIN Batch 4/7500 loss 17.977022 loss_att 16.487453 loss_ctc 21.451195 loss_rnnt 13.455286 hw_loss 0.816830 lr 0.00078190 rank 1
2023-02-11 09:36:37,264 DEBUG TRAIN Batch 4/7500 loss 31.969252 loss_att 32.746689 loss_ctc 46.518467 loss_rnnt 25.232426 hw_loss 0.870270 lr 0.00078258 rank 7
2023-02-11 09:36:37,264 DEBUG TRAIN Batch 4/7500 loss 13.440934 loss_att 15.700994 loss_ctc 23.753603 loss_rnnt 9.305099 hw_loss 0.432900 lr 0.00078236 rank 3
2023-02-11 09:36:37,265 DEBUG TRAIN Batch 4/7500 loss 30.790815 loss_att 29.455290 loss_ctc 39.645500 loss_rnnt 24.708241 hw_loss 0.969198 lr 0.00078249 rank 6
2023-02-11 09:36:37,266 DEBUG TRAIN Batch 4/7500 loss 15.167664 loss_att 15.919776 loss_ctc 16.051699 loss_rnnt 11.706502 hw_loss 0.598662 lr 0.00078176 rank 2
2023-02-11 09:36:37,272 DEBUG TRAIN Batch 4/7500 loss 17.297722 loss_att 22.309048 loss_ctc 26.226843 loss_rnnt 13.539108 hw_loss 0.293587 lr 0.00078258 rank 4
2023-02-11 09:36:37,274 DEBUG TRAIN Batch 4/7500 loss 10.605247 loss_att 16.034245 loss_ctc 19.324139 loss_rnnt 6.031203 hw_loss 0.436073 lr 0.00078215 rank 5
2023-02-11 09:37:52,677 DEBUG TRAIN Batch 4/7600 loss 29.444384 loss_att 29.034641 loss_ctc 40.316383 loss_rnnt 25.074240 hw_loss 0.562967 lr 0.00078088 rank 0
2023-02-11 09:37:52,679 DEBUG TRAIN Batch 4/7600 loss 18.708397 loss_att 16.496380 loss_ctc 23.625216 loss_rnnt 15.102257 hw_loss 0.636181 lr 0.00078162 rank 7
2023-02-11 09:37:52,679 DEBUG TRAIN Batch 4/7600 loss 34.746147 loss_att 38.329155 loss_ctc 58.899933 loss_rnnt 28.481567 hw_loss 0.436402 lr 0.00078080 rank 2
2023-02-11 09:37:52,680 DEBUG TRAIN Batch 4/7600 loss 13.944852 loss_att 16.739431 loss_ctc 19.760708 loss_rnnt 10.209465 hw_loss 0.450192 lr 0.00078119 rank 5
2023-02-11 09:37:52,681 DEBUG TRAIN Batch 4/7600 loss 19.918610 loss_att 18.695564 loss_ctc 27.627243 loss_rnnt 14.761930 hw_loss 0.820026 lr 0.00078095 rank 1
2023-02-11 09:37:52,683 DEBUG TRAIN Batch 4/7600 loss 17.544552 loss_att 12.566463 loss_ctc 14.944468 loss_rnnt 9.927188 hw_loss 1.679936 lr 0.00078162 rank 4
2023-02-11 09:37:52,682 DEBUG TRAIN Batch 4/7600 loss 23.654709 loss_att 20.730148 loss_ctc 26.326878 loss_rnnt 19.688351 hw_loss 0.786559 lr 0.00078140 rank 3
2023-02-11 09:37:52,730 DEBUG TRAIN Batch 4/7600 loss 30.126205 loss_att 31.145130 loss_ctc 47.065838 loss_rnnt 25.590126 hw_loss 0.388814 lr 0.00078154 rank 6
2023-02-11 09:39:09,429 DEBUG TRAIN Batch 4/7700 loss 14.169676 loss_att 15.014069 loss_ctc 22.058287 loss_rnnt 10.180202 hw_loss 0.519146 lr 0.00078067 rank 7
2023-02-11 09:39:09,433 DEBUG TRAIN Batch 4/7700 loss 33.183567 loss_att 41.463112 loss_ctc 48.325272 loss_rnnt 28.497086 hw_loss 0.189689 lr 0.00078067 rank 4
2023-02-11 09:39:09,436 DEBUG TRAIN Batch 4/7700 loss 53.091656 loss_att 57.575363 loss_ctc 67.601372 loss_rnnt 48.945679 hw_loss 0.246490 lr 0.00077993 rank 0
2023-02-11 09:39:09,436 DEBUG TRAIN Batch 4/7700 loss 20.722471 loss_att 17.454735 loss_ctc 23.546713 loss_rnnt 15.897464 hw_loss 0.956623 lr 0.00078058 rank 6
2023-02-11 09:39:09,437 DEBUG TRAIN Batch 4/7700 loss 16.016111 loss_att 19.574554 loss_ctc 24.872503 loss_rnnt 10.968502 hw_loss 0.591575 lr 0.00078045 rank 3
2023-02-11 09:39:09,441 DEBUG TRAIN Batch 4/7700 loss 18.831966 loss_att 25.307323 loss_ctc 27.841230 loss_rnnt 12.519979 hw_loss 0.715440 lr 0.00077999 rank 1
2023-02-11 09:39:09,441 DEBUG TRAIN Batch 4/7700 loss 18.569710 loss_att 19.267670 loss_ctc 31.280704 loss_rnnt 15.141848 hw_loss 0.298776 lr 0.00078024 rank 5
2023-02-11 09:39:09,488 DEBUG TRAIN Batch 4/7700 loss 24.855467 loss_att 26.017389 loss_ctc 34.603104 loss_rnnt 20.772430 hw_loss 0.478306 lr 0.00077985 rank 2
2023-02-11 09:40:28,030 DEBUG TRAIN Batch 4/7800 loss 22.009344 loss_att 24.876955 loss_ctc 33.632111 loss_rnnt 18.819984 hw_loss 0.199901 lr 0.00077898 rank 0
2023-02-11 09:40:28,036 DEBUG TRAIN Batch 4/7800 loss 21.206320 loss_att 23.934677 loss_ctc 39.832718 loss_rnnt 17.876030 hw_loss 0.056456 lr 0.00077891 rank 2
2023-02-11 09:40:28,037 DEBUG TRAIN Batch 4/7800 loss 15.874895 loss_att 20.716700 loss_ctc 23.952698 loss_rnnt 11.257228 hw_loss 0.482300 lr 0.00077929 rank 5
2023-02-11 09:40:28,038 DEBUG TRAIN Batch 4/7800 loss 17.856846 loss_att 23.453402 loss_ctc 28.379025 loss_rnnt 14.078327 hw_loss 0.235547 lr 0.00077963 rank 6
2023-02-11 09:40:28,038 DEBUG TRAIN Batch 4/7800 loss 13.920017 loss_att 20.735588 loss_ctc 22.540104 loss_rnnt 10.238310 hw_loss 0.219234 lr 0.00077950 rank 3
2023-02-11 09:40:28,039 DEBUG TRAIN Batch 4/7800 loss 20.901011 loss_att 24.021179 loss_ctc 35.792023 loss_rnnt 15.771719 hw_loss 0.472460 lr 0.00077972 rank 4
2023-02-11 09:40:28,039 DEBUG TRAIN Batch 4/7800 loss 29.686852 loss_att 31.412764 loss_ctc 45.459896 loss_rnnt 23.681601 hw_loss 0.666937 lr 0.00077905 rank 1
2023-02-11 09:40:28,040 DEBUG TRAIN Batch 4/7800 loss 11.454768 loss_att 14.472010 loss_ctc 21.488224 loss_rnnt 5.564550 hw_loss 0.740433 lr 0.00077972 rank 7
2023-02-11 09:41:45,203 DEBUG TRAIN Batch 4/7900 loss 32.730614 loss_att 39.194500 loss_ctc 43.261902 loss_rnnt 26.447485 hw_loss 0.672409 lr 0.00077856 rank 3
2023-02-11 09:41:45,205 DEBUG TRAIN Batch 4/7900 loss 33.252068 loss_att 36.253967 loss_ctc 53.182804 loss_rnnt 29.167427 hw_loss 0.155030 lr 0.00077804 rank 0
2023-02-11 09:41:45,205 DEBUG TRAIN Batch 4/7900 loss 29.650997 loss_att 32.843464 loss_ctc 42.411942 loss_rnnt 24.809589 hw_loss 0.469023 lr 0.00077877 rank 7
2023-02-11 09:41:45,208 DEBUG TRAIN Batch 4/7900 loss 19.415504 loss_att 20.822186 loss_ctc 23.725605 loss_rnnt 17.810596 hw_loss 0.140417 lr 0.00077869 rank 6
2023-02-11 09:41:45,211 DEBUG TRAIN Batch 4/7900 loss 24.266340 loss_att 27.284184 loss_ctc 41.440125 loss_rnnt 18.547997 hw_loss 0.529676 lr 0.00077835 rank 5
2023-02-11 09:41:45,212 DEBUG TRAIN Batch 4/7900 loss 34.382378 loss_att 44.060932 loss_ctc 59.769058 loss_rnnt 26.874546 hw_loss 0.410106 lr 0.00077877 rank 4
2023-02-11 09:41:45,214 DEBUG TRAIN Batch 4/7900 loss 28.295694 loss_att 30.583790 loss_ctc 35.831390 loss_rnnt 23.783291 hw_loss 0.571880 lr 0.00077810 rank 1
2023-02-11 09:41:45,218 DEBUG TRAIN Batch 4/7900 loss 19.262423 loss_att 24.472904 loss_ctc 33.211628 loss_rnnt 14.656723 hw_loss 0.319445 lr 0.00077796 rank 2
2023-02-11 09:42:59,153 DEBUG TRAIN Batch 4/8000 loss 18.727787 loss_att 22.202713 loss_ctc 32.204239 loss_rnnt 15.175549 hw_loss 0.198824 lr 0.00077761 rank 3
2023-02-11 09:42:59,154 DEBUG TRAIN Batch 4/8000 loss 28.999874 loss_att 30.649261 loss_ctc 46.156223 loss_rnnt 25.052069 hw_loss 0.249453 lr 0.00077710 rank 0
2023-02-11 09:42:59,155 DEBUG TRAIN Batch 4/8000 loss 19.154076 loss_att 27.610069 loss_ctc 29.678442 loss_rnnt 15.669310 hw_loss 0.073185 lr 0.00077783 rank 7
2023-02-11 09:42:59,155 DEBUG TRAIN Batch 4/8000 loss 20.098661 loss_att 21.166792 loss_ctc 30.804365 loss_rnnt 17.076866 hw_loss 0.258889 lr 0.00077741 rank 5
2023-02-11 09:42:59,157 DEBUG TRAIN Batch 4/8000 loss 23.395014 loss_att 31.792171 loss_ctc 40.029552 loss_rnnt 17.552794 hw_loss 0.364660 lr 0.00077775 rank 6
2023-02-11 09:42:59,157 DEBUG TRAIN Batch 4/8000 loss 25.229620 loss_att 26.143017 loss_ctc 37.644905 loss_rnnt 21.009918 hw_loss 0.446559 lr 0.00077702 rank 2
2023-02-11 09:42:59,158 DEBUG TRAIN Batch 4/8000 loss 27.483486 loss_att 29.640574 loss_ctc 47.474190 loss_rnnt 22.556770 hw_loss 0.343101 lr 0.00077783 rank 4
2023-02-11 09:42:59,161 DEBUG TRAIN Batch 4/8000 loss 22.340292 loss_att 26.284719 loss_ctc 34.900074 loss_rnnt 16.421499 hw_loss 0.647863 lr 0.00077716 rank 1
2023-02-11 09:44:14,876 DEBUG TRAIN Batch 4/8100 loss 31.660814 loss_att 36.981632 loss_ctc 53.589317 loss_rnnt 26.896542 hw_loss 0.145558 lr 0.00077623 rank 1
2023-02-11 09:44:14,881 DEBUG TRAIN Batch 4/8100 loss 24.595821 loss_att 28.049498 loss_ctc 37.829552 loss_rnnt 18.910814 hw_loss 0.605582 lr 0.00077681 rank 6
2023-02-11 09:44:14,882 DEBUG TRAIN Batch 4/8100 loss 27.688444 loss_att 33.498699 loss_ctc 37.653015 loss_rnnt 22.392645 hw_loss 0.525964 lr 0.00077647 rank 5
2023-02-11 09:44:14,882 DEBUG TRAIN Batch 4/8100 loss 24.965298 loss_att 24.725750 loss_ctc 30.905224 loss_rnnt 21.126553 hw_loss 0.580250 lr 0.00077667 rank 3
2023-02-11 09:44:14,885 DEBUG TRAIN Batch 4/8100 loss 18.416405 loss_att 19.577883 loss_ctc 25.877308 loss_rnnt 13.793653 hw_loss 0.636688 lr 0.00077609 rank 2
2023-02-11 09:44:14,911 DEBUG TRAIN Batch 4/8100 loss 13.798527 loss_att 17.171116 loss_ctc 19.994535 loss_rnnt 10.672671 hw_loss 0.304726 lr 0.00077616 rank 0
2023-02-11 09:44:14,917 DEBUG TRAIN Batch 4/8100 loss 25.688725 loss_att 31.314198 loss_ctc 37.263298 loss_rnnt 20.225767 hw_loss 0.523985 lr 0.00077689 rank 7
2023-02-11 09:44:14,928 DEBUG TRAIN Batch 4/8100 loss 34.821789 loss_att 34.719292 loss_ctc 51.252102 loss_rnnt 30.604027 hw_loss 0.383916 lr 0.00077689 rank 4
2023-02-11 09:45:32,063 DEBUG TRAIN Batch 4/8200 loss 16.958298 loss_att 16.760490 loss_ctc 23.869144 loss_rnnt 11.914323 hw_loss 0.780392 lr 0.00077595 rank 7
2023-02-11 09:45:32,064 DEBUG TRAIN Batch 4/8200 loss 38.729240 loss_att 45.895313 loss_ctc 59.006714 loss_rnnt 33.474117 hw_loss 0.209671 lr 0.00077587 rank 6
2023-02-11 09:45:32,068 DEBUG TRAIN Batch 4/8200 loss 15.215212 loss_att 12.406743 loss_ctc 16.135614 loss_rnnt 10.121564 hw_loss 1.037367 lr 0.00077523 rank 0
2023-02-11 09:45:32,068 DEBUG TRAIN Batch 4/8200 loss 28.943783 loss_att 33.587753 loss_ctc 50.295643 loss_rnnt 22.881399 hw_loss 0.428752 lr 0.00077574 rank 3
2023-02-11 09:45:32,069 DEBUG TRAIN Batch 4/8200 loss 25.737312 loss_att 27.175684 loss_ctc 36.077389 loss_rnnt 20.367033 hw_loss 0.694486 lr 0.00077553 rank 5
2023-02-11 09:45:32,070 DEBUG TRAIN Batch 4/8200 loss 15.188894 loss_att 14.331264 loss_ctc 16.780855 loss_rnnt 10.755809 hw_loss 0.823566 lr 0.00077595 rank 4
2023-02-11 09:45:32,072 DEBUG TRAIN Batch 4/8200 loss 15.488955 loss_att 13.738602 loss_ctc 16.900705 loss_rnnt 11.168190 hw_loss 0.840488 lr 0.00077515 rank 2
2023-02-11 09:45:32,115 DEBUG TRAIN Batch 4/8200 loss 31.761814 loss_att 35.710556 loss_ctc 51.625771 loss_rnnt 26.667654 hw_loss 0.310478 lr 0.00077529 rank 1
2023-02-11 09:46:47,972 DEBUG TRAIN Batch 4/8300 loss 10.386335 loss_att 16.169357 loss_ctc 24.366070 loss_rnnt 7.096024 hw_loss 0.050577 lr 0.00077502 rank 7
2023-02-11 09:46:47,973 DEBUG TRAIN Batch 4/8300 loss 18.918066 loss_att 25.366217 loss_ctc 31.483303 loss_rnnt 12.516775 hw_loss 0.644306 lr 0.00077481 rank 3
2023-02-11 09:46:47,975 DEBUG TRAIN Batch 4/8300 loss 21.059195 loss_att 26.594383 loss_ctc 31.176434 loss_rnnt 17.930130 hw_loss 0.126199 lr 0.00077494 rank 6
2023-02-11 09:46:47,976 DEBUG TRAIN Batch 4/8300 loss 18.241198 loss_att 24.801510 loss_ctc 28.692640 loss_rnnt 13.767092 hw_loss 0.331597 lr 0.00077460 rank 5
2023-02-11 09:46:47,977 DEBUG TRAIN Batch 4/8300 loss 64.116074 loss_att 70.130646 loss_ctc 87.162964 loss_rnnt 57.540325 hw_loss 0.431235 lr 0.00077422 rank 2
2023-02-11 09:46:47,977 DEBUG TRAIN Batch 4/8300 loss 19.411465 loss_att 23.664190 loss_ctc 33.970078 loss_rnnt 13.126542 hw_loss 0.654980 lr 0.00077436 rank 1
2023-02-11 09:46:47,977 DEBUG TRAIN Batch 4/8300 loss 12.603731 loss_att 14.624605 loss_ctc 20.625677 loss_rnnt 8.511501 hw_loss 0.490961 lr 0.00077430 rank 0
2023-02-11 09:46:47,980 DEBUG TRAIN Batch 4/8300 loss 16.292000 loss_att 20.031080 loss_ctc 23.658682 loss_rnnt 11.349770 hw_loss 0.602285 lr 0.00077502 rank 4
2023-02-11 09:47:36,432 DEBUG CV Batch 4/0 loss 8.703712 loss_att 3.839462 loss_ctc 6.678563 loss_rnnt 3.348343 hw_loss 1.237170 history loss 8.381352 rank 3
2023-02-11 09:47:36,433 DEBUG CV Batch 4/0 loss 8.703712 loss_att 3.839462 loss_ctc 6.678563 loss_rnnt 3.348343 hw_loss 1.237170 history loss 8.381352 rank 1
2023-02-11 09:47:36,434 DEBUG CV Batch 4/0 loss 8.703711 loss_att 3.839462 loss_ctc 6.678563 loss_rnnt 3.348343 hw_loss 1.237170 history loss 8.381351 rank 7
2023-02-11 09:47:36,439 DEBUG CV Batch 4/0 loss 8.703712 loss_att 3.839462 loss_ctc 6.678563 loss_rnnt 3.348343 hw_loss 1.237170 history loss 8.381352 rank 4
2023-02-11 09:47:36,440 DEBUG CV Batch 4/0 loss 8.703711 loss_att 3.839462 loss_ctc 6.678563 loss_rnnt 3.348343 hw_loss 1.237170 history loss 8.381351 rank 6
2023-02-11 09:47:36,456 DEBUG CV Batch 4/0 loss 8.703712 loss_att 3.839462 loss_ctc 6.678563 loss_rnnt 3.348343 hw_loss 1.237170 history loss 8.381352 rank 2
2023-02-11 09:47:36,461 DEBUG CV Batch 4/0 loss 8.703712 loss_att 3.839462 loss_ctc 6.678563 loss_rnnt 3.348343 hw_loss 1.237170 history loss 8.381353 rank 0
2023-02-11 09:47:36,463 DEBUG CV Batch 4/0 loss 8.703712 loss_att 3.839462 loss_ctc 6.678563 loss_rnnt 3.348343 hw_loss 1.237170 history loss 8.381352 rank 5
2023-02-11 09:47:47,525 DEBUG CV Batch 4/100 loss 18.285400 loss_att 14.851780 loss_ctc 24.301727 loss_rnnt 14.068846 hw_loss 0.768957 history loss 10.009113 rank 1
2023-02-11 09:47:47,608 DEBUG CV Batch 4/100 loss 18.285400 loss_att 14.851780 loss_ctc 24.301727 loss_rnnt 14.068846 hw_loss 0.768957 history loss 10.009113 rank 0
2023-02-11 09:47:47,613 DEBUG CV Batch 4/100 loss 18.285400 loss_att 14.851780 loss_ctc 24.301727 loss_rnnt 14.068846 hw_loss 0.768957 history loss 10.009113 rank 3
2023-02-11 09:47:47,645 DEBUG CV Batch 4/100 loss 18.285400 loss_att 14.851780 loss_ctc 24.301727 loss_rnnt 14.068846 hw_loss 0.768957 history loss 10.009113 rank 4
2023-02-11 09:47:47,703 DEBUG CV Batch 4/100 loss 18.285400 loss_att 14.851780 loss_ctc 24.301727 loss_rnnt 14.068846 hw_loss 0.768957 history loss 10.009113 rank 5
2023-02-11 09:47:47,711 DEBUG CV Batch 4/100 loss 18.285400 loss_att 14.851780 loss_ctc 24.301727 loss_rnnt 14.068846 hw_loss 0.768957 history loss 10.009113 rank 2
2023-02-11 09:47:47,736 DEBUG CV Batch 4/100 loss 18.285400 loss_att 14.851780 loss_ctc 24.301727 loss_rnnt 14.068846 hw_loss 0.768957 history loss 10.009113 rank 7
2023-02-11 09:47:48,832 DEBUG CV Batch 4/100 loss 18.285400 loss_att 14.851780 loss_ctc 24.301727 loss_rnnt 14.068846 hw_loss 0.768957 history loss 10.009113 rank 6
2023-02-11 09:48:01,137 DEBUG CV Batch 4/200 loss 15.697933 loss_att 24.092697 loss_ctc 24.434719 loss_rnnt 12.172405 hw_loss 0.127813 history loss 10.563745 rank 1
2023-02-11 09:48:01,183 DEBUG CV Batch 4/200 loss 15.697933 loss_att 24.092697 loss_ctc 24.434719 loss_rnnt 12.172405 hw_loss 0.127813 history loss 10.563745 rank 3
2023-02-11 09:48:01,185 DEBUG CV Batch 4/200 loss 15.697933 loss_att 24.092697 loss_ctc 24.434719 loss_rnnt 12.172405 hw_loss 0.127813 history loss 10.563745 rank 0
2023-02-11 09:48:01,237 DEBUG CV Batch 4/200 loss 15.697933 loss_att 24.092697 loss_ctc 24.434719 loss_rnnt 12.172405 hw_loss 0.127813 history loss 10.563745 rank 2
2023-02-11 09:48:01,264 DEBUG CV Batch 4/200 loss 15.697933 loss_att 24.092697 loss_ctc 24.434719 loss_rnnt 12.172405 hw_loss 0.127813 history loss 10.563745 rank 7
2023-02-11 09:48:01,432 DEBUG CV Batch 4/200 loss 15.697933 loss_att 24.092697 loss_ctc 24.434719 loss_rnnt 12.172405 hw_loss 0.127813 history loss 10.563745 rank 4
2023-02-11 09:48:01,493 DEBUG CV Batch 4/200 loss 15.697933 loss_att 24.092697 loss_ctc 24.434719 loss_rnnt 12.172405 hw_loss 0.127813 history loss 10.563745 rank 5
2023-02-11 09:48:02,575 DEBUG CV Batch 4/200 loss 15.697933 loss_att 24.092697 loss_ctc 24.434719 loss_rnnt 12.172405 hw_loss 0.127813 history loss 10.563745 rank 6
2023-02-11 09:48:13,163 DEBUG CV Batch 4/300 loss 12.749883 loss_att 10.235456 loss_ctc 18.482609 loss_rnnt 7.956421 hw_loss 0.849747 history loss 10.835611 rank 0
2023-02-11 09:48:13,171 DEBUG CV Batch 4/300 loss 12.749883 loss_att 10.235456 loss_ctc 18.482609 loss_rnnt 7.956421 hw_loss 0.849747 history loss 10.835611 rank 1
2023-02-11 09:48:13,176 DEBUG CV Batch 4/300 loss 12.749883 loss_att 10.235456 loss_ctc 18.482609 loss_rnnt 7.956421 hw_loss 0.849747 history loss 10.835611 rank 3
2023-02-11 09:48:13,285 DEBUG CV Batch 4/300 loss 12.749883 loss_att 10.235456 loss_ctc 18.482609 loss_rnnt 7.956421 hw_loss 0.849747 history loss 10.835611 rank 7
2023-02-11 09:48:13,330 DEBUG CV Batch 4/300 loss 12.749883 loss_att 10.235456 loss_ctc 18.482609 loss_rnnt 7.956421 hw_loss 0.849747 history loss 10.835611 rank 2
2023-02-11 09:48:13,569 DEBUG CV Batch 4/300 loss 12.749883 loss_att 10.235456 loss_ctc 18.482609 loss_rnnt 7.956421 hw_loss 0.849747 history loss 10.835611 rank 4
2023-02-11 09:48:13,606 DEBUG CV Batch 4/300 loss 12.749883 loss_att 10.235456 loss_ctc 18.482609 loss_rnnt 7.956421 hw_loss 0.849747 history loss 10.835611 rank 5
2023-02-11 09:48:14,665 DEBUG CV Batch 4/300 loss 12.749884 loss_att 10.235456 loss_ctc 18.482609 loss_rnnt 7.956421 hw_loss 0.849747 history loss 10.835611 rank 6
2023-02-11 09:48:25,093 DEBUG CV Batch 4/400 loss 30.420918 loss_att 83.563171 loss_ctc 33.978859 loss_rnnt 18.156157 hw_loss 0.217859 history loss 11.910767 rank 3
2023-02-11 09:48:25,141 DEBUG CV Batch 4/400 loss 30.420918 loss_att 83.563171 loss_ctc 33.978859 loss_rnnt 18.156157 hw_loss 0.217859 history loss 11.910767 rank 1
2023-02-11 09:48:25,167 DEBUG CV Batch 4/400 loss 30.420918 loss_att 83.563171 loss_ctc 33.978859 loss_rnnt 18.156157 hw_loss 0.217859 history loss 11.910767 rank 0
2023-02-11 09:48:25,292 DEBUG CV Batch 4/400 loss 30.420918 loss_att 83.563171 loss_ctc 33.978859 loss_rnnt 18.156157 hw_loss 0.217859 history loss 11.910767 rank 7
2023-02-11 09:48:25,536 DEBUG CV Batch 4/400 loss 30.420918 loss_att 83.563171 loss_ctc 33.978859 loss_rnnt 18.156157 hw_loss 0.217859 history loss 11.910767 rank 2
2023-02-11 09:48:25,598 DEBUG CV Batch 4/400 loss 30.420918 loss_att 83.563171 loss_ctc 33.978859 loss_rnnt 18.156157 hw_loss 0.217859 history loss 11.910767 rank 4
2023-02-11 09:48:25,650 DEBUG CV Batch 4/400 loss 30.420918 loss_att 83.563171 loss_ctc 33.978859 loss_rnnt 18.156157 hw_loss 0.217859 history loss 11.910767 rank 5
2023-02-11 09:48:26,763 DEBUG CV Batch 4/400 loss 30.420918 loss_att 83.563171 loss_ctc 33.978859 loss_rnnt 18.156157 hw_loss 0.217859 history loss 11.910767 rank 6
2023-02-11 09:48:35,508 DEBUG CV Batch 4/500 loss 10.374101 loss_att 11.855917 loss_ctc 15.686975 loss_rnnt 7.665902 hw_loss 0.319397 history loss 12.929632 rank 3
2023-02-11 09:48:35,537 DEBUG CV Batch 4/500 loss 10.374101 loss_att 11.855917 loss_ctc 15.686975 loss_rnnt 7.665902 hw_loss 0.319397 history loss 12.929632 rank 0
2023-02-11 09:48:35,613 DEBUG CV Batch 4/500 loss 10.374101 loss_att 11.855917 loss_ctc 15.686975 loss_rnnt 7.665902 hw_loss 0.319397 history loss 12.929632 rank 1
2023-02-11 09:48:35,754 DEBUG CV Batch 4/500 loss 10.374101 loss_att 11.855917 loss_ctc 15.686975 loss_rnnt 7.665902 hw_loss 0.319397 history loss 12.929632 rank 7
2023-02-11 09:48:36,061 DEBUG CV Batch 4/500 loss 10.374101 loss_att 11.855917 loss_ctc 15.686975 loss_rnnt 7.665902 hw_loss 0.319397 history loss 12.929632 rank 5
2023-02-11 09:48:36,133 DEBUG CV Batch 4/500 loss 10.374101 loss_att 11.855917 loss_ctc 15.686975 loss_rnnt 7.665902 hw_loss 0.319397 history loss 12.929632 rank 4
2023-02-11 09:48:36,146 DEBUG CV Batch 4/500 loss 10.374101 loss_att 11.855917 loss_ctc 15.686975 loss_rnnt 7.665902 hw_loss 0.319397 history loss 12.929632 rank 2
2023-02-11 09:48:38,266 DEBUG CV Batch 4/500 loss 10.374101 loss_att 11.855917 loss_ctc 15.686975 loss_rnnt 7.665902 hw_loss 0.319397 history loss 12.929632 rank 6
2023-02-11 09:48:47,523 DEBUG CV Batch 4/600 loss 12.650120 loss_att 10.757130 loss_ctc 12.551074 loss_rnnt 8.285301 hw_loss 0.891867 history loss 14.030078 rank 0
2023-02-11 09:48:47,623 DEBUG CV Batch 4/600 loss 12.650120 loss_att 10.757130 loss_ctc 12.551074 loss_rnnt 8.285301 hw_loss 0.891867 history loss 14.030078 rank 3
2023-02-11 09:48:47,657 DEBUG CV Batch 4/600 loss 12.650120 loss_att 10.757130 loss_ctc 12.551074 loss_rnnt 8.285301 hw_loss 0.891867 history loss 14.030078 rank 1
2023-02-11 09:48:47,831 DEBUG CV Batch 4/600 loss 12.650119 loss_att 10.757130 loss_ctc 12.551074 loss_rnnt 8.285301 hw_loss 0.891867 history loss 14.030078 rank 7
2023-02-11 09:48:48,166 DEBUG CV Batch 4/600 loss 12.650119 loss_att 10.757130 loss_ctc 12.551074 loss_rnnt 8.285301 hw_loss 0.891867 history loss 14.030078 rank 5
2023-02-11 09:48:48,215 DEBUG CV Batch 4/600 loss 12.650119 loss_att 10.757130 loss_ctc 12.551074 loss_rnnt 8.285301 hw_loss 0.891866 history loss 14.030078 rank 4
2023-02-11 09:48:48,258 DEBUG CV Batch 4/600 loss 12.650119 loss_att 10.757130 loss_ctc 12.551074 loss_rnnt 8.285301 hw_loss 0.891867 history loss 14.030078 rank 2
2023-02-11 09:48:50,297 DEBUG CV Batch 4/600 loss 12.650120 loss_att 10.757130 loss_ctc 12.551074 loss_rnnt 8.285301 hw_loss 0.891867 history loss 14.030078 rank 6
2023-02-11 09:48:58,796 DEBUG CV Batch 4/700 loss 35.639675 loss_att 72.430916 loss_ctc 53.586407 loss_rnnt 22.731495 hw_loss 0.591943 history loss 14.743423 rank 0
2023-02-11 09:48:58,945 DEBUG CV Batch 4/700 loss 35.639675 loss_att 72.430916 loss_ctc 53.586407 loss_rnnt 22.731495 hw_loss 0.591943 history loss 14.743423 rank 3
2023-02-11 09:48:59,222 DEBUG CV Batch 4/700 loss 35.639675 loss_att 72.430916 loss_ctc 53.586407 loss_rnnt 22.731495 hw_loss 0.591943 history loss 14.743423 rank 7
2023-02-11 09:48:59,277 DEBUG CV Batch 4/700 loss 35.639675 loss_att 72.430916 loss_ctc 53.586407 loss_rnnt 22.731495 hw_loss 0.591943 history loss 14.743423 rank 1
2023-02-11 09:48:59,491 DEBUG CV Batch 4/700 loss 35.639675 loss_att 72.430916 loss_ctc 53.586407 loss_rnnt 22.731495 hw_loss 0.591943 history loss 14.743423 rank 5
2023-02-11 09:48:59,653 DEBUG CV Batch 4/700 loss 35.639675 loss_att 72.430916 loss_ctc 53.586407 loss_rnnt 22.731495 hw_loss 0.591943 history loss 14.743423 rank 4
2023-02-11 09:48:59,748 DEBUG CV Batch 4/700 loss 35.639675 loss_att 72.430916 loss_ctc 53.586407 loss_rnnt 22.731495 hw_loss 0.591943 history loss 14.743423 rank 2
2023-02-11 09:49:01,730 DEBUG CV Batch 4/700 loss 35.639675 loss_att 72.430916 loss_ctc 53.586407 loss_rnnt 22.731495 hw_loss 0.591943 history loss 14.743423 rank 6
2023-02-11 09:49:10,379 DEBUG CV Batch 4/800 loss 19.070433 loss_att 16.198544 loss_ctc 28.187374 loss_rnnt 15.588656 hw_loss 0.532606 history loss 14.115467 rank 7
2023-02-11 09:49:10,554 DEBUG CV Batch 4/800 loss 19.070433 loss_att 16.198544 loss_ctc 28.187374 loss_rnnt 15.588656 hw_loss 0.532606 history loss 14.115467 rank 0
2023-02-11 09:49:10,929 DEBUG CV Batch 4/800 loss 19.070433 loss_att 16.198544 loss_ctc 28.187374 loss_rnnt 15.588656 hw_loss 0.532606 history loss 14.115467 rank 3
2023-02-11 09:49:11,285 DEBUG CV Batch 4/800 loss 19.070433 loss_att 16.198544 loss_ctc 28.187374 loss_rnnt 15.588656 hw_loss 0.532606 history loss 14.115467 rank 1
2023-02-11 09:49:11,317 DEBUG CV Batch 4/800 loss 19.070433 loss_att 16.198544 loss_ctc 28.187374 loss_rnnt 15.588656 hw_loss 0.532606 history loss 14.115467 rank 5
2023-02-11 09:49:11,947 DEBUG CV Batch 4/800 loss 19.070433 loss_att 16.198544 loss_ctc 28.187374 loss_rnnt 15.588656 hw_loss 0.532606 history loss 14.115467 rank 4
2023-02-11 09:49:12,475 DEBUG CV Batch 4/800 loss 19.070433 loss_att 16.198544 loss_ctc 28.187374 loss_rnnt 15.588656 hw_loss 0.532606 history loss 14.115467 rank 2
2023-02-11 09:49:13,201 DEBUG CV Batch 4/800 loss 19.070433 loss_att 16.198544 loss_ctc 28.187374 loss_rnnt 15.588656 hw_loss 0.532606 history loss 14.115467 rank 6
2023-02-11 09:49:23,881 DEBUG CV Batch 4/900 loss 20.723726 loss_att 30.282074 loss_ctc 33.429359 loss_rnnt 17.025726 hw_loss 0.017296 history loss 13.876003 rank 7
2023-02-11 09:49:24,493 DEBUG CV Batch 4/900 loss 20.723726 loss_att 30.282074 loss_ctc 33.429359 loss_rnnt 17.025726 hw_loss 0.017296 history loss 13.876003 rank 0
2023-02-11 09:49:24,611 DEBUG CV Batch 4/900 loss 20.723726 loss_att 30.282074 loss_ctc 33.429359 loss_rnnt 17.025726 hw_loss 0.017296 history loss 13.876003 rank 3
2023-02-11 09:49:24,911 DEBUG CV Batch 4/900 loss 20.723726 loss_att 30.282074 loss_ctc 33.429359 loss_rnnt 17.025726 hw_loss 0.017296 history loss 13.876003 rank 5
2023-02-11 09:49:25,054 DEBUG CV Batch 4/900 loss 20.723726 loss_att 30.282074 loss_ctc 33.429359 loss_rnnt 17.025726 hw_loss 0.017296 history loss 13.876003 rank 1
2023-02-11 09:49:25,810 DEBUG CV Batch 4/900 loss 20.723726 loss_att 30.282074 loss_ctc 33.429359 loss_rnnt 17.025726 hw_loss 0.017296 history loss 13.876003 rank 2
2023-02-11 09:49:26,016 DEBUG CV Batch 4/900 loss 20.723726 loss_att 30.282074 loss_ctc 33.429359 loss_rnnt 17.025726 hw_loss 0.017296 history loss 13.876003 rank 4
2023-02-11 09:49:27,075 DEBUG CV Batch 4/900 loss 20.723726 loss_att 30.282074 loss_ctc 33.429359 loss_rnnt 17.025726 hw_loss 0.017296 history loss 13.876003 rank 6
2023-02-11 09:49:36,071 DEBUG CV Batch 4/1000 loss 9.733551 loss_att 7.187505 loss_ctc 8.202393 loss_rnnt 4.802128 hw_loss 1.058398 history loss 13.616181 rank 7
2023-02-11 09:49:36,610 DEBUG CV Batch 4/1000 loss 9.733551 loss_att 7.187505 loss_ctc 8.202393 loss_rnnt 4.802128 hw_loss 1.058398 history loss 13.616181 rank 0
2023-02-11 09:49:36,757 DEBUG CV Batch 4/1000 loss 9.733551 loss_att 7.187505 loss_ctc 8.202393 loss_rnnt 4.802128 hw_loss 1.058398 history loss 13.616181 rank 3
2023-02-11 09:49:37,102 DEBUG CV Batch 4/1000 loss 9.733551 loss_att 7.187505 loss_ctc 8.202393 loss_rnnt 4.802128 hw_loss 1.058398 history loss 13.616181 rank 5
2023-02-11 09:49:37,303 DEBUG CV Batch 4/1000 loss 9.733551 loss_att 7.187505 loss_ctc 8.202393 loss_rnnt 4.802128 hw_loss 1.058397 history loss 13.616181 rank 1
2023-02-11 09:49:38,058 DEBUG CV Batch 4/1000 loss 9.733551 loss_att 7.187505 loss_ctc 8.202393 loss_rnnt 4.802128 hw_loss 1.058398 history loss 13.616181 rank 2
2023-02-11 09:49:38,306 DEBUG CV Batch 4/1000 loss 9.733551 loss_att 7.187505 loss_ctc 8.202393 loss_rnnt 4.802128 hw_loss 1.058398 history loss 13.616181 rank 4
2023-02-11 09:49:39,320 DEBUG CV Batch 4/1000 loss 9.733551 loss_att 7.187505 loss_ctc 8.202393 loss_rnnt 4.802128 hw_loss 1.058398 history loss 13.616181 rank 6
2023-02-11 09:49:47,939 DEBUG CV Batch 4/1100 loss 12.625732 loss_att 7.153073 loss_ctc 11.496103 loss_rnnt 5.507365 hw_loss 1.568159 history loss 13.577582 rank 7
2023-02-11 09:49:48,504 DEBUG CV Batch 4/1100 loss 12.625732 loss_att 7.153073 loss_ctc 11.496103 loss_rnnt 5.507365 hw_loss 1.568159 history loss 13.577582 rank 0
2023-02-11 09:49:48,662 DEBUG CV Batch 4/1100 loss 12.625732 loss_att 7.153073 loss_ctc 11.496103 loss_rnnt 5.507365 hw_loss 1.568159 history loss 13.577582 rank 3
2023-02-11 09:49:49,044 DEBUG CV Batch 4/1100 loss 12.625732 loss_att 7.153073 loss_ctc 11.496103 loss_rnnt 5.507365 hw_loss 1.568159 history loss 13.577582 rank 5
2023-02-11 09:49:49,188 DEBUG CV Batch 4/1100 loss 12.625732 loss_att 7.153073 loss_ctc 11.496103 loss_rnnt 5.507365 hw_loss 1.568159 history loss 13.577582 rank 1
2023-02-11 09:49:49,949 DEBUG CV Batch 4/1100 loss 12.625732 loss_att 7.153073 loss_ctc 11.496103 loss_rnnt 5.507365 hw_loss 1.568159 history loss 13.577582 rank 2
2023-02-11 09:49:50,188 DEBUG CV Batch 4/1100 loss 12.625732 loss_att 7.153073 loss_ctc 11.496103 loss_rnnt 5.507365 hw_loss 1.568159 history loss 13.577582 rank 4
2023-02-11 09:49:51,160 DEBUG CV Batch 4/1100 loss 12.625732 loss_att 7.153073 loss_ctc 11.496103 loss_rnnt 5.507365 hw_loss 1.568159 history loss 13.577582 rank 6
2023-02-11 09:49:58,369 DEBUG CV Batch 4/1200 loss 12.884114 loss_att 14.462345 loss_ctc 20.523535 loss_rnnt 10.618236 hw_loss 0.174683 history loss 13.990155 rank 7
2023-02-11 09:49:58,905 DEBUG CV Batch 4/1200 loss 12.884114 loss_att 14.462345 loss_ctc 20.523535 loss_rnnt 10.618236 hw_loss 0.174683 history loss 13.990155 rank 0
2023-02-11 09:49:59,056 DEBUG CV Batch 4/1200 loss 12.884114 loss_att 14.462345 loss_ctc 20.523535 loss_rnnt 10.618236 hw_loss 0.174683 history loss 13.990155 rank 3
2023-02-11 09:49:59,467 DEBUG CV Batch 4/1200 loss 12.884114 loss_att 14.462345 loss_ctc 20.523535 loss_rnnt 10.618236 hw_loss 0.174683 history loss 13.990155 rank 5
2023-02-11 09:49:59,595 DEBUG CV Batch 4/1200 loss 12.884114 loss_att 14.462345 loss_ctc 20.523535 loss_rnnt 10.618236 hw_loss 0.174683 history loss 13.990155 rank 1
2023-02-11 09:50:00,367 DEBUG CV Batch 4/1200 loss 12.884114 loss_att 14.462345 loss_ctc 20.523535 loss_rnnt 10.618236 hw_loss 0.174683 history loss 13.990155 rank 2
2023-02-11 09:50:00,943 DEBUG CV Batch 4/1200 loss 12.884114 loss_att 14.462345 loss_ctc 20.523535 loss_rnnt 10.618236 hw_loss 0.174683 history loss 13.990155 rank 4
2023-02-11 09:50:01,721 DEBUG CV Batch 4/1200 loss 12.884114 loss_att 14.462345 loss_ctc 20.523535 loss_rnnt 10.618236 hw_loss 0.174683 history loss 13.990155 rank 6
2023-02-11 09:50:10,299 DEBUG CV Batch 4/1300 loss 12.632500 loss_att 7.769969 loss_ctc 12.003504 loss_rnnt 7.199625 hw_loss 1.216734 history loss 14.309316 rank 7
2023-02-11 09:50:10,749 DEBUG CV Batch 4/1300 loss 12.632500 loss_att 7.769969 loss_ctc 12.003504 loss_rnnt 7.199625 hw_loss 1.216734 history loss 14.309316 rank 0
2023-02-11 09:50:10,911 DEBUG CV Batch 4/1300 loss 12.632500 loss_att 7.769969 loss_ctc 12.003504 loss_rnnt 7.199625 hw_loss 1.216734 history loss 14.309316 rank 3
2023-02-11 09:50:11,455 DEBUG CV Batch 4/1300 loss 12.632500 loss_att 7.769969 loss_ctc 12.003504 loss_rnnt 7.199625 hw_loss 1.216734 history loss 14.309316 rank 5
2023-02-11 09:50:11,507 DEBUG CV Batch 4/1300 loss 12.632500 loss_att 7.769969 loss_ctc 12.003504 loss_rnnt 7.199625 hw_loss 1.216734 history loss 14.309316 rank 1
2023-02-11 09:50:12,363 DEBUG CV Batch 4/1300 loss 12.632500 loss_att 7.769969 loss_ctc 12.003504 loss_rnnt 7.199625 hw_loss 1.216734 history loss 14.309316 rank 2
2023-02-11 09:50:13,076 DEBUG CV Batch 4/1300 loss 12.632500 loss_att 7.769969 loss_ctc 12.003504 loss_rnnt 7.199625 hw_loss 1.216734 history loss 14.309316 rank 4
2023-02-11 09:50:13,665 DEBUG CV Batch 4/1300 loss 12.632500 loss_att 7.769969 loss_ctc 12.003504 loss_rnnt 7.199625 hw_loss 1.216734 history loss 14.309316 rank 6
2023-02-11 09:50:21,386 DEBUG CV Batch 4/1400 loss 16.481964 loss_att 34.924942 loss_ctc 26.929127 loss_rnnt 9.545376 hw_loss 0.347819 history loss 14.676763 rank 7
2023-02-11 09:50:21,803 DEBUG CV Batch 4/1400 loss 16.481964 loss_att 34.924942 loss_ctc 26.929127 loss_rnnt 9.545376 hw_loss 0.347819 history loss 14.676763 rank 0
2023-02-11 09:50:22,042 DEBUG CV Batch 4/1400 loss 16.481964 loss_att 34.924942 loss_ctc 26.929127 loss_rnnt 9.545376 hw_loss 0.347819 history loss 14.676763 rank 3
2023-02-11 09:50:22,625 DEBUG CV Batch 4/1400 loss 16.481964 loss_att 34.924942 loss_ctc 26.929127 loss_rnnt 9.545376 hw_loss 0.347819 history loss 14.676763 rank 5
2023-02-11 09:50:23,606 DEBUG CV Batch 4/1400 loss 16.481964 loss_att 34.924942 loss_ctc 26.929127 loss_rnnt 9.545376 hw_loss 0.347819 history loss 14.676764 rank 1
2023-02-11 09:50:23,921 DEBUG CV Batch 4/1400 loss 16.481964 loss_att 34.924942 loss_ctc 26.929127 loss_rnnt 9.545376 hw_loss 0.347819 history loss 14.676763 rank 2
2023-02-11 09:50:24,699 DEBUG CV Batch 4/1400 loss 16.481964 loss_att 34.924942 loss_ctc 26.929127 loss_rnnt 9.545376 hw_loss 0.347819 history loss 14.676764 rank 4
2023-02-11 09:50:25,703 DEBUG CV Batch 4/1400 loss 16.481964 loss_att 34.924942 loss_ctc 26.929127 loss_rnnt 9.545376 hw_loss 0.347819 history loss 14.676763 rank 6
2023-02-11 09:50:32,703 DEBUG CV Batch 4/1500 loss 12.533751 loss_att 13.039538 loss_ctc 12.868727 loss_rnnt 10.616795 hw_loss 0.332088 history loss 14.470414 rank 7
2023-02-11 09:50:33,291 DEBUG CV Batch 4/1500 loss 12.533751 loss_att 13.039538 loss_ctc 12.868727 loss_rnnt 10.616795 hw_loss 0.332088 history loss 14.470414 rank 0
2023-02-11 09:50:33,339 DEBUG CV Batch 4/1500 loss 12.533751 loss_att 13.039538 loss_ctc 12.868727 loss_rnnt 10.616795 hw_loss 0.332088 history loss 14.470414 rank 3
2023-02-11 09:50:34,043 DEBUG CV Batch 4/1500 loss 12.533751 loss_att 13.039538 loss_ctc 12.868727 loss_rnnt 10.616795 hw_loss 0.332088 history loss 14.470414 rank 5
2023-02-11 09:50:35,101 DEBUG CV Batch 4/1500 loss 12.533751 loss_att 13.039538 loss_ctc 12.868727 loss_rnnt 10.616795 hw_loss 0.332088 history loss 14.470414 rank 1
2023-02-11 09:50:36,114 DEBUG CV Batch 4/1500 loss 12.533751 loss_att 13.039538 loss_ctc 12.868727 loss_rnnt 10.616795 hw_loss 0.332088 history loss 14.470414 rank 4
2023-02-11 09:50:36,612 DEBUG CV Batch 4/1500 loss 12.533751 loss_att 13.039538 loss_ctc 12.868727 loss_rnnt 10.616795 hw_loss 0.332088 history loss 14.470414 rank 2
2023-02-11 09:50:38,043 DEBUG CV Batch 4/1500 loss 12.533751 loss_att 13.039538 loss_ctc 12.868727 loss_rnnt 10.616795 hw_loss 0.332088 history loss 14.470414 rank 6
2023-02-11 09:50:46,319 DEBUG CV Batch 4/1600 loss 16.459335 loss_att 20.931517 loss_ctc 25.601822 loss_rnnt 11.101087 hw_loss 0.608402 history loss 14.359519 rank 7
2023-02-11 09:50:46,823 DEBUG CV Batch 4/1600 loss 16.459335 loss_att 20.931517 loss_ctc 25.601822 loss_rnnt 11.101087 hw_loss 0.608402 history loss 14.359519 rank 0
2023-02-11 09:50:47,006 DEBUG CV Batch 4/1600 loss 16.459335 loss_att 20.931517 loss_ctc 25.601822 loss_rnnt 11.101087 hw_loss 0.608402 history loss 14.359519 rank 3
2023-02-11 09:50:47,175 DEBUG CV Batch 4/1600 loss 16.459335 loss_att 20.931517 loss_ctc 25.601822 loss_rnnt 11.101087 hw_loss 0.608402 history loss 14.359519 rank 5
2023-02-11 09:50:48,504 DEBUG CV Batch 4/1600 loss 16.459335 loss_att 20.931517 loss_ctc 25.601822 loss_rnnt 11.101087 hw_loss 0.608402 history loss 14.359519 rank 1
2023-02-11 09:50:49,202 DEBUG CV Batch 4/1600 loss 16.459335 loss_att 20.931517 loss_ctc 25.601822 loss_rnnt 11.101087 hw_loss 0.608402 history loss 14.359519 rank 4
2023-02-11 09:50:50,074 DEBUG CV Batch 4/1600 loss 16.459335 loss_att 20.931517 loss_ctc 25.601822 loss_rnnt 11.101087 hw_loss 0.608402 history loss 14.359519 rank 2
2023-02-11 09:50:51,826 DEBUG CV Batch 4/1600 loss 16.459335 loss_att 20.931517 loss_ctc 25.601822 loss_rnnt 11.101087 hw_loss 0.608402 history loss 14.359519 rank 6
2023-02-11 09:50:58,837 DEBUG CV Batch 4/1700 loss 15.440244 loss_att 12.315767 loss_ctc 20.224043 loss_rnnt 9.907219 hw_loss 1.035015 history loss 14.242858 rank 7
2023-02-11 09:50:59,356 DEBUG CV Batch 4/1700 loss 15.440244 loss_att 12.315767 loss_ctc 20.224043 loss_rnnt 9.907219 hw_loss 1.035015 history loss 14.242858 rank 0
2023-02-11 09:50:59,455 DEBUG CV Batch 4/1700 loss 15.440244 loss_att 12.315767 loss_ctc 20.224043 loss_rnnt 9.907219 hw_loss 1.035015 history loss 14.242858 rank 3
2023-02-11 09:50:59,658 DEBUG CV Batch 4/1700 loss 15.440244 loss_att 12.315767 loss_ctc 20.224043 loss_rnnt 9.907219 hw_loss 1.035015 history loss 14.242858 rank 5
2023-02-11 09:51:00,943 DEBUG CV Batch 4/1700 loss 15.440244 loss_att 12.315767 loss_ctc 20.224043 loss_rnnt 9.907219 hw_loss 1.035015 history loss 14.242858 rank 1
2023-02-11 09:51:01,693 DEBUG CV Batch 4/1700 loss 15.440245 loss_att 12.315767 loss_ctc 20.224043 loss_rnnt 9.907219 hw_loss 1.035015 history loss 14.242858 rank 4
2023-02-11 09:51:02,565 DEBUG CV Batch 4/1700 loss 15.440245 loss_att 12.315767 loss_ctc 20.224043 loss_rnnt 9.907219 hw_loss 1.035015 history loss 14.242858 rank 2
2023-02-11 09:51:04,215 DEBUG CV Batch 4/1700 loss 15.440244 loss_att 12.315767 loss_ctc 20.224043 loss_rnnt 9.907219 hw_loss 1.035015 history loss 14.242858 rank 6
2023-02-11 09:51:08,069 INFO Epoch 4 CV info cv_loss 14.178563952635505
2023-02-11 09:51:08,070 INFO Epoch 5 TRAIN info lr 0.0007745749814456279
2023-02-11 09:51:08,072 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 09:51:08,591 INFO Epoch 4 CV info cv_loss 14.178563965591914
2023-02-11 09:51:08,592 INFO Checkpoint: save to checkpoint exp2_10_rnnt_bias_loss/4.pt
2023-02-11 09:51:08,593 INFO Epoch 4 CV info cv_loss 14.178563970588401
2023-02-11 09:51:08,594 INFO Epoch 5 TRAIN info lr 0.0007744448929150946
2023-02-11 09:51:08,598 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 09:51:08,873 INFO Epoch 4 CV info cv_loss 14.178563951911876
2023-02-11 09:51:08,874 INFO Epoch 5 TRAIN info lr 0.0007742034737231392
2023-02-11 09:51:08,876 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 09:51:09,209 INFO Epoch 5 TRAIN info lr 0.0007738232325341369
2023-02-11 09:51:09,212 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 09:51:10,064 INFO Epoch 4 CV info cv_loss 14.178563961663642
2023-02-11 09:51:10,065 INFO Epoch 5 TRAIN info lr 0.0007740735722537014
2023-02-11 09:51:10,068 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 09:51:10,824 INFO Epoch 4 CV info cv_loss 14.178563967590508
2023-02-11 09:51:10,825 INFO Epoch 5 TRAIN info lr 0.0007745470998132664
2023-02-11 09:51:10,828 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 09:51:11,696 INFO Epoch 4 CV info cv_loss 14.178563961422432
2023-02-11 09:51:11,697 INFO Epoch 5 TRAIN info lr 0.0007737120483721796
2023-02-11 09:51:11,701 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 09:51:13,324 INFO Epoch 4 CV info cv_loss 14.178563962559563
2023-02-11 09:51:13,325 INFO Epoch 5 TRAIN info lr 0.0007747330342566901
2023-02-11 09:51:13,330 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 09:52:25,096 DEBUG TRAIN Batch 5/0 loss 13.788557 loss_att 10.567226 loss_ctc 13.732282 loss_rnnt 9.441288 hw_loss 0.937320 lr 0.00077444 rank 3
2023-02-11 09:52:25,102 DEBUG TRAIN Batch 5/0 loss 20.807774 loss_att 16.363516 loss_ctc 20.575003 loss_rnnt 15.400378 hw_loss 1.186365 lr 0.00077381 rank 0
2023-02-11 09:52:25,103 DEBUG TRAIN Batch 5/0 loss 13.961521 loss_att 11.413635 loss_ctc 14.203931 loss_rnnt 9.567064 hw_loss 0.913446 lr 0.00077406 rank 1
2023-02-11 09:52:25,110 DEBUG TRAIN Batch 5/0 loss 11.827613 loss_att 9.057307 loss_ctc 11.501328 loss_rnnt 7.825291 hw_loss 0.862479 lr 0.00077457 rank 7
2023-02-11 09:52:25,117 DEBUG TRAIN Batch 5/0 loss 16.883266 loss_att 13.585878 loss_ctc 18.850855 loss_rnnt 12.472389 hw_loss 0.901502 lr 0.00077419 rank 5
2023-02-11 09:52:25,122 DEBUG TRAIN Batch 5/0 loss 14.328498 loss_att 11.283525 loss_ctc 16.050253 loss_rnnt 10.193968 hw_loss 0.846367 lr 0.00077370 rank 2
2023-02-11 09:52:25,129 DEBUG TRAIN Batch 5/0 loss 16.496853 loss_att 11.524888 loss_ctc 14.377943 loss_rnnt 11.273751 hw_loss 1.218753 lr 0.00077472 rank 6
2023-02-11 09:52:25,168 DEBUG TRAIN Batch 5/0 loss 20.186708 loss_att 12.665001 loss_ctc 15.690455 loss_rnnt 11.500918 hw_loss 2.023056 lr 0.00077454 rank 4
2023-02-11 09:53:41,904 DEBUG TRAIN Batch 5/100 loss 29.633015 loss_att 36.708168 loss_ctc 44.095989 loss_rnnt 23.900341 hw_loss 0.447984 lr 0.00077351 rank 3
2023-02-11 09:53:41,906 DEBUG TRAIN Batch 5/100 loss 23.791149 loss_att 32.518364 loss_ctc 35.162304 loss_rnnt 18.632473 hw_loss 0.355702 lr 0.00077289 rank 0
2023-02-11 09:53:41,906 DEBUG TRAIN Batch 5/100 loss 18.449171 loss_att 22.249758 loss_ctc 29.812498 loss_rnnt 12.038943 hw_loss 0.775313 lr 0.00077380 rank 6
2023-02-11 09:53:41,906 DEBUG TRAIN Batch 5/100 loss 14.054011 loss_att 16.936665 loss_ctc 19.538965 loss_rnnt 9.045952 hw_loss 0.693788 lr 0.00077278 rank 2
2023-02-11 09:53:41,907 DEBUG TRAIN Batch 5/100 loss 20.096588 loss_att 24.650021 loss_ctc 37.104225 loss_rnnt 15.742279 hw_loss 0.220488 lr 0.00077364 rank 7
2023-02-11 09:53:41,911 DEBUG TRAIN Batch 5/100 loss 31.640568 loss_att 38.131233 loss_ctc 50.167797 loss_rnnt 24.395187 hw_loss 0.651928 lr 0.00077327 rank 5
2023-02-11 09:53:41,914 DEBUG TRAIN Batch 5/100 loss 49.513004 loss_att 53.349930 loss_ctc 70.763939 loss_rnnt 41.767323 hw_loss 0.777156 lr 0.00077361 rank 4
2023-02-11 09:53:41,962 DEBUG TRAIN Batch 5/100 loss 17.626442 loss_att 21.344971 loss_ctc 28.732872 loss_rnnt 12.806974 hw_loss 0.486544 lr 0.00077314 rank 1
2023-02-11 09:54:57,688 DEBUG TRAIN Batch 5/200 loss 12.078023 loss_att 16.504923 loss_ctc 23.104057 loss_rnnt 8.461114 hw_loss 0.236511 lr 0.00077258 rank 3
2023-02-11 09:54:57,692 DEBUG TRAIN Batch 5/200 loss 19.254705 loss_att 24.005537 loss_ctc 27.949057 loss_rnnt 15.891067 hw_loss 0.235168 lr 0.00077271 rank 7
2023-02-11 09:54:57,693 DEBUG TRAIN Batch 5/200 loss 27.600292 loss_att 32.765961 loss_ctc 35.357738 loss_rnnt 21.993315 hw_loss 0.663659 lr 0.00077234 rank 5
2023-02-11 09:54:57,697 DEBUG TRAIN Batch 5/200 loss 46.266277 loss_att 55.882591 loss_ctc 69.262405 loss_rnnt 39.206818 hw_loss 0.388134 lr 0.00077287 rank 6
2023-02-11 09:54:57,698 DEBUG TRAIN Batch 5/200 loss 21.899286 loss_att 25.060017 loss_ctc 37.201164 loss_rnnt 16.277554 hw_loss 0.553001 lr 0.00077222 rank 1
2023-02-11 09:54:57,698 DEBUG TRAIN Batch 5/200 loss 17.698368 loss_att 24.144255 loss_ctc 32.380646 loss_rnnt 11.438156 hw_loss 0.565012 lr 0.00077197 rank 0
2023-02-11 09:54:57,699 DEBUG TRAIN Batch 5/200 loss 36.634594 loss_att 41.938911 loss_ctc 64.754425 loss_rnnt 28.936193 hw_loss 0.541542 lr 0.00077269 rank 4
2023-02-11 09:54:57,701 DEBUG TRAIN Batch 5/200 loss 18.784107 loss_att 24.241623 loss_ctc 32.186920 loss_rnnt 14.039221 hw_loss 0.349939 lr 0.00077186 rank 2
2023-02-11 09:56:14,621 DEBUG TRAIN Batch 5/300 loss 30.512970 loss_att 37.104462 loss_ctc 49.814693 loss_rnnt 21.667847 hw_loss 0.928736 lr 0.00077105 rank 0
2023-02-11 09:56:14,624 DEBUG TRAIN Batch 5/300 loss 25.747963 loss_att 33.578320 loss_ctc 45.084732 loss_rnnt 19.301035 hw_loss 0.431742 lr 0.00077166 rank 3
2023-02-11 09:56:14,625 DEBUG TRAIN Batch 5/300 loss 18.895338 loss_att 23.299278 loss_ctc 31.745522 loss_rnnt 12.871651 hw_loss 0.643039 lr 0.00077179 rank 7
2023-02-11 09:56:14,626 DEBUG TRAIN Batch 5/300 loss 13.906832 loss_att 16.286442 loss_ctc 22.054787 loss_rnnt 10.851068 hw_loss 0.280021 lr 0.00077142 rank 5
2023-02-11 09:56:14,628 DEBUG TRAIN Batch 5/300 loss 18.711758 loss_att 19.398678 loss_ctc 31.117636 loss_rnnt 15.130213 hw_loss 0.335633 lr 0.00077094 rank 2
2023-02-11 09:56:14,628 DEBUG TRAIN Batch 5/300 loss 16.309950 loss_att 20.047768 loss_ctc 21.906914 loss_rnnt 12.096327 hw_loss 0.509962 lr 0.00077195 rank 6
2023-02-11 09:56:14,630 DEBUG TRAIN Batch 5/300 loss 11.776420 loss_att 16.488621 loss_ctc 22.666142 loss_rnnt 6.660919 hw_loss 0.510206 lr 0.00077130 rank 1
2023-02-11 09:56:14,675 DEBUG TRAIN Batch 5/300 loss 19.487982 loss_att 20.594448 loss_ctc 24.495220 loss_rnnt 15.701809 hw_loss 0.543234 lr 0.00077176 rank 4
2023-02-11 09:57:31,897 DEBUG TRAIN Batch 5/400 loss 17.506775 loss_att 19.624355 loss_ctc 21.527714 loss_rnnt 13.381254 hw_loss 0.593603 lr 0.00077013 rank 0
2023-02-11 09:57:31,900 DEBUG TRAIN Batch 5/400 loss 27.693974 loss_att 30.388193 loss_ctc 40.643028 loss_rnnt 22.230225 hw_loss 0.599693 lr 0.00077103 rank 6
2023-02-11 09:57:31,902 DEBUG TRAIN Batch 5/400 loss 11.026985 loss_att 19.652494 loss_ctc 23.304180 loss_rnnt 6.595389 hw_loss 0.200538 lr 0.00077002 rank 2
2023-02-11 09:57:31,902 DEBUG TRAIN Batch 5/400 loss 22.320063 loss_att 23.661335 loss_ctc 32.535133 loss_rnnt 17.579531 hw_loss 0.583175 lr 0.00077087 rank 7
2023-02-11 09:57:31,903 DEBUG TRAIN Batch 5/400 loss 28.059948 loss_att 32.604187 loss_ctc 41.322090 loss_rnnt 23.011856 hw_loss 0.444554 lr 0.00077051 rank 5
2023-02-11 09:57:31,902 DEBUG TRAIN Batch 5/400 loss 24.851250 loss_att 25.857475 loss_ctc 40.618271 loss_rnnt 20.279572 hw_loss 0.425281 lr 0.00077075 rank 3
2023-02-11 09:57:31,906 DEBUG TRAIN Batch 5/400 loss 34.983227 loss_att 37.070168 loss_ctc 54.872009 loss_rnnt 30.916897 hw_loss 0.186957 lr 0.00077085 rank 4
2023-02-11 09:57:31,953 DEBUG TRAIN Batch 5/400 loss 20.918842 loss_att 27.052267 loss_ctc 35.165634 loss_rnnt 14.608805 hw_loss 0.596959 lr 0.00077038 rank 1
2023-02-11 09:58:47,005 DEBUG TRAIN Batch 5/500 loss 24.929741 loss_att 27.211634 loss_ctc 40.065628 loss_rnnt 19.478115 hw_loss 0.558212 lr 0.00077012 rank 6
2023-02-11 09:58:47,008 DEBUG TRAIN Batch 5/500 loss 22.140419 loss_att 27.250231 loss_ctc 38.138885 loss_rnnt 14.840551 hw_loss 0.777145 lr 0.00076947 rank 1
2023-02-11 09:58:47,013 DEBUG TRAIN Batch 5/500 loss 26.475853 loss_att 28.558443 loss_ctc 38.755959 loss_rnnt 20.919044 hw_loss 0.656802 lr 0.00076922 rank 0
2023-02-11 09:58:47,013 DEBUG TRAIN Batch 5/500 loss 21.177153 loss_att 25.074722 loss_ctc 36.143295 loss_rnnt 15.984056 hw_loss 0.453394 lr 0.00076996 rank 7
2023-02-11 09:58:47,014 DEBUG TRAIN Batch 5/500 loss 11.877387 loss_att 14.324974 loss_ctc 13.361825 loss_rnnt 7.067759 hw_loss 0.772910 lr 0.00076983 rank 3
2023-02-11 09:58:47,014 DEBUG TRAIN Batch 5/500 loss 29.666073 loss_att 27.016272 loss_ctc 36.562542 loss_rnnt 25.588051 hw_loss 0.691585 lr 0.00076960 rank 5
2023-02-11 09:58:47,015 DEBUG TRAIN Batch 5/500 loss 26.958607 loss_att 27.816429 loss_ctc 40.806526 loss_rnnt 20.503153 hw_loss 0.832031 lr 0.00076911 rank 2
2023-02-11 09:58:47,029 DEBUG TRAIN Batch 5/500 loss 18.121426 loss_att 20.843876 loss_ctc 27.534035 loss_rnnt 12.733672 hw_loss 0.672797 lr 0.00076993 rank 4
2023-02-11 10:00:03,483 DEBUG TRAIN Batch 5/600 loss 40.041016 loss_att 37.785179 loss_ctc 60.191650 loss_rnnt 35.072540 hw_loss 0.512416 lr 0.00076892 rank 3
2023-02-11 10:00:03,484 DEBUG TRAIN Batch 5/600 loss 13.391801 loss_att 10.211821 loss_ctc 13.737247 loss_rnnt 8.389935 hw_loss 1.048463 lr 0.00076905 rank 7
2023-02-11 10:00:03,486 DEBUG TRAIN Batch 5/600 loss 19.439596 loss_att 17.490297 loss_ctc 24.896721 loss_rnnt 16.271444 hw_loss 0.530699 lr 0.00076856 rank 1
2023-02-11 10:00:03,489 DEBUG TRAIN Batch 5/600 loss 18.106924 loss_att 20.074436 loss_ctc 23.998745 loss_rnnt 14.075719 hw_loss 0.534774 lr 0.00076831 rank 0
2023-02-11 10:00:03,492 DEBUG TRAIN Batch 5/600 loss 21.337343 loss_att 18.445801 loss_ctc 26.378401 loss_rnnt 15.596160 hw_loss 1.058879 lr 0.00076920 rank 6
2023-02-11 10:00:03,494 DEBUG TRAIN Batch 5/600 loss 15.543962 loss_att 13.710596 loss_ctc 21.794228 loss_rnnt 11.098306 hw_loss 0.746055 lr 0.00076820 rank 2
2023-02-11 10:00:03,494 DEBUG TRAIN Batch 5/600 loss 24.612421 loss_att 22.614874 loss_ctc 32.144577 loss_rnnt 19.379158 hw_loss 0.867841 lr 0.00076869 rank 5
2023-02-11 10:00:03,498 DEBUG TRAIN Batch 5/600 loss 25.625622 loss_att 25.200455 loss_ctc 35.164806 loss_rnnt 21.450668 hw_loss 0.560267 lr 0.00076902 rank 4
2023-02-11 10:01:23,042 DEBUG TRAIN Batch 5/700 loss 28.692333 loss_att 32.703491 loss_ctc 36.435158 loss_rnnt 25.778959 hw_loss 0.202269 lr 0.00076829 rank 6
2023-02-11 10:01:23,043 DEBUG TRAIN Batch 5/700 loss 23.110207 loss_att 27.744259 loss_ctc 35.576588 loss_rnnt 19.150723 hw_loss 0.256966 lr 0.00076814 rank 7
2023-02-11 10:01:23,044 DEBUG TRAIN Batch 5/700 loss 20.362984 loss_att 19.517174 loss_ctc 24.973257 loss_rnnt 18.040106 hw_loss 0.352001 lr 0.00076801 rank 3
2023-02-11 10:01:23,046 DEBUG TRAIN Batch 5/700 loss 23.692280 loss_att 26.700180 loss_ctc 29.207413 loss_rnnt 18.816481 hw_loss 0.663538 lr 0.00076765 rank 1
2023-02-11 10:01:23,048 DEBUG TRAIN Batch 5/700 loss 33.336380 loss_att 40.176079 loss_ctc 60.291576 loss_rnnt 26.033340 hw_loss 0.438952 lr 0.00076811 rank 4
2023-02-11 10:01:23,048 DEBUG TRAIN Batch 5/700 loss 30.166616 loss_att 37.174801 loss_ctc 44.805313 loss_rnnt 25.851894 hw_loss 0.180237 lr 0.00076741 rank 0
2023-02-11 10:01:23,047 DEBUG TRAIN Batch 5/700 loss 15.646552 loss_att 21.146635 loss_ctc 30.459236 loss_rnnt 10.687892 hw_loss 0.353179 lr 0.00076730 rank 2
2023-02-11 10:01:23,049 DEBUG TRAIN Batch 5/700 loss 11.973615 loss_att 16.665342 loss_ctc 17.303900 loss_rnnt 8.818810 hw_loss 0.282329 lr 0.00076778 rank 5
2023-02-11 10:02:39,718 DEBUG TRAIN Batch 5/800 loss 13.165246 loss_att 19.072464 loss_ctc 23.748373 loss_rnnt 9.150377 hw_loss 0.266689 lr 0.00076640 rank 2
2023-02-11 10:02:39,721 DEBUG TRAIN Batch 5/800 loss 15.551978 loss_att 24.331648 loss_ctc 28.188772 loss_rnnt 11.350375 hw_loss 0.142643 lr 0.00076739 rank 6
2023-02-11 10:02:39,722 DEBUG TRAIN Batch 5/800 loss 12.242908 loss_att 19.112280 loss_ctc 18.828030 loss_rnnt 7.763406 hw_loss 0.417677 lr 0.00076721 rank 4
2023-02-11 10:02:39,723 DEBUG TRAIN Batch 5/800 loss 22.293016 loss_att 29.063843 loss_ctc 38.088257 loss_rnnt 17.047905 hw_loss 0.334671 lr 0.00076651 rank 0
2023-02-11 10:02:39,723 DEBUG TRAIN Batch 5/800 loss 19.313065 loss_att 20.255623 loss_ctc 24.542633 loss_rnnt 13.820503 hw_loss 0.863770 lr 0.00076711 rank 3
2023-02-11 10:02:39,725 DEBUG TRAIN Batch 5/800 loss 18.421440 loss_att 17.400711 loss_ctc 23.448776 loss_rnnt 14.710653 hw_loss 0.608367 lr 0.00076724 rank 7
2023-02-11 10:02:39,727 DEBUG TRAIN Batch 5/800 loss 26.296968 loss_att 31.552628 loss_ctc 38.140572 loss_rnnt 22.650036 hw_loss 0.190623 lr 0.00076687 rank 5
2023-02-11 10:02:39,727 DEBUG TRAIN Batch 5/800 loss 27.286608 loss_att 31.836191 loss_ctc 40.069939 loss_rnnt 19.815062 hw_loss 0.910722 lr 0.00076675 rank 1
2023-02-11 10:03:56,022 DEBUG TRAIN Batch 5/900 loss 21.242155 loss_att 28.080915 loss_ctc 34.378433 loss_rnnt 15.559919 hw_loss 0.480559 lr 0.00076597 rank 5
2023-02-11 10:03:56,024 DEBUG TRAIN Batch 5/900 loss 11.746665 loss_att 14.729860 loss_ctc 21.298920 loss_rnnt 7.940021 hw_loss 0.363070 lr 0.00076633 rank 7
2023-02-11 10:03:56,026 DEBUG TRAIN Batch 5/900 loss 20.909451 loss_att 28.564346 loss_ctc 36.326653 loss_rnnt 14.273853 hw_loss 0.571686 lr 0.00076649 rank 6
2023-02-11 10:03:56,026 DEBUG TRAIN Batch 5/900 loss 29.113771 loss_att 29.219978 loss_ctc 40.363697 loss_rnnt 23.849831 hw_loss 0.701758 lr 0.00076561 rank 0
2023-02-11 10:03:56,026 DEBUG TRAIN Batch 5/900 loss 26.789845 loss_att 30.775524 loss_ctc 44.589123 loss_rnnt 21.050924 hw_loss 0.481603 lr 0.00076631 rank 4
2023-02-11 10:03:56,028 DEBUG TRAIN Batch 5/900 loss 42.210522 loss_att 46.379696 loss_ctc 69.508820 loss_rnnt 37.495422 hw_loss 0.045280 lr 0.00076621 rank 3
2023-02-11 10:03:56,029 DEBUG TRAIN Batch 5/900 loss 29.666088 loss_att 30.924900 loss_ctc 43.838005 loss_rnnt 24.127499 hw_loss 0.636982 lr 0.00076550 rank 2
2023-02-11 10:03:56,078 DEBUG TRAIN Batch 5/900 loss 23.829615 loss_att 27.141941 loss_ctc 35.202404 loss_rnnt 18.309134 hw_loss 0.626558 lr 0.00076585 rank 1
2023-02-11 10:05:13,099 DEBUG TRAIN Batch 5/1000 loss 14.575898 loss_att 20.410759 loss_ctc 25.214077 loss_rnnt 9.972361 hw_loss 0.378402 lr 0.00076559 rank 6
2023-02-11 10:05:13,099 DEBUG TRAIN Batch 5/1000 loss 15.305989 loss_att 21.853813 loss_ctc 26.408516 loss_rnnt 9.524437 hw_loss 0.560934 lr 0.00076531 rank 3
2023-02-11 10:05:13,102 DEBUG TRAIN Batch 5/1000 loss 22.348272 loss_att 23.585564 loss_ctc 28.273296 loss_rnnt 18.427023 hw_loss 0.540711 lr 0.00076544 rank 7
2023-02-11 10:05:13,104 DEBUG TRAIN Batch 5/1000 loss 20.259037 loss_att 24.322208 loss_ctc 33.507996 loss_rnnt 14.766222 hw_loss 0.546310 lr 0.00076495 rank 1
2023-02-11 10:05:13,107 DEBUG TRAIN Batch 5/1000 loss 23.175194 loss_att 31.092785 loss_ctc 44.411964 loss_rnnt 17.344624 hw_loss 0.265403 lr 0.00076508 rank 5
2023-02-11 10:05:13,109 DEBUG TRAIN Batch 5/1000 loss 19.942471 loss_att 21.654449 loss_ctc 29.141262 loss_rnnt 15.635533 hw_loss 0.513382 lr 0.00076541 rank 4
2023-02-11 10:05:13,108 DEBUG TRAIN Batch 5/1000 loss 16.863413 loss_att 21.609051 loss_ctc 28.356918 loss_rnnt 12.018258 hw_loss 0.443167 lr 0.00076460 rank 2
2023-02-11 10:05:13,113 DEBUG TRAIN Batch 5/1000 loss 28.877409 loss_att 35.682892 loss_ctc 41.356094 loss_rnnt 23.491997 hw_loss 0.442592 lr 0.00076471 rank 0
2023-02-11 10:06:31,066 DEBUG TRAIN Batch 5/1100 loss 13.080493 loss_att 14.629862 loss_ctc 19.674082 loss_rnnt 10.485355 hw_loss 0.263647 lr 0.00076371 rank 2
2023-02-11 10:06:31,067 DEBUG TRAIN Batch 5/1100 loss 36.328705 loss_att 38.285614 loss_ctc 50.293159 loss_rnnt 28.938345 hw_loss 0.963197 lr 0.00076382 rank 0
2023-02-11 10:06:31,068 DEBUG TRAIN Batch 5/1100 loss 20.377434 loss_att 22.070852 loss_ctc 28.870892 loss_rnnt 16.466450 hw_loss 0.457470 lr 0.00076406 rank 1
2023-02-11 10:06:31,068 DEBUG TRAIN Batch 5/1100 loss 17.180588 loss_att 17.941650 loss_ctc 24.171272 loss_rnnt 13.495892 hw_loss 0.487573 lr 0.00076442 rank 3
2023-02-11 10:06:31,069 DEBUG TRAIN Batch 5/1100 loss 27.147541 loss_att 31.888128 loss_ctc 42.209736 loss_rnnt 22.564405 hw_loss 0.305011 lr 0.00076418 rank 5
2023-02-11 10:06:31,069 DEBUG TRAIN Batch 5/1100 loss 13.309018 loss_att 18.724676 loss_ctc 24.193356 loss_rnnt 8.126045 hw_loss 0.496612 lr 0.00076469 rank 6
2023-02-11 10:06:31,070 DEBUG TRAIN Batch 5/1100 loss 22.029524 loss_att 26.849165 loss_ctc 34.869320 loss_rnnt 17.866890 hw_loss 0.278763 lr 0.00076454 rank 7
2023-02-11 10:06:31,119 DEBUG TRAIN Batch 5/1100 loss 14.390687 loss_att 22.042570 loss_ctc 21.438965 loss_rnnt 8.302045 hw_loss 0.678468 lr 0.00076451 rank 4
2023-02-11 10:07:46,661 DEBUG TRAIN Batch 5/1200 loss 18.077621 loss_att 20.329105 loss_ctc 24.055180 loss_rnnt 14.378624 hw_loss 0.459692 lr 0.00076282 rank 2
2023-02-11 10:07:46,664 DEBUG TRAIN Batch 5/1200 loss 14.945889 loss_att 15.775421 loss_ctc 21.059078 loss_rnnt 10.966969 hw_loss 0.562110 lr 0.00076365 rank 7
2023-02-11 10:07:46,665 DEBUG TRAIN Batch 5/1200 loss 20.582754 loss_att 21.147896 loss_ctc 25.896442 loss_rnnt 16.975060 hw_loss 0.522407 lr 0.00076329 rank 5
2023-02-11 10:07:46,665 DEBUG TRAIN Batch 5/1200 loss 24.383402 loss_att 27.560537 loss_ctc 38.904156 loss_rnnt 21.055771 hw_loss 0.141769 lr 0.00076293 rank 0
2023-02-11 10:07:46,667 DEBUG TRAIN Batch 5/1200 loss 12.826921 loss_att 13.232780 loss_ctc 19.144285 loss_rnnt 8.424828 hw_loss 0.652239 lr 0.00076352 rank 3
2023-02-11 10:07:46,669 DEBUG TRAIN Batch 5/1200 loss 13.880588 loss_att 18.188410 loss_ctc 26.277964 loss_rnnt 8.763449 hw_loss 0.487986 lr 0.00076380 rank 6
2023-02-11 10:07:46,672 DEBUG TRAIN Batch 5/1200 loss 19.992861 loss_att 20.062983 loss_ctc 25.444799 loss_rnnt 16.163181 hw_loss 0.579137 lr 0.00076317 rank 1
2023-02-11 10:07:46,675 DEBUG TRAIN Batch 5/1200 loss 21.282867 loss_att 22.596275 loss_ctc 33.827610 loss_rnnt 14.601329 hw_loss 0.889918 lr 0.00076362 rank 4
2023-02-11 10:09:01,438 DEBUG TRAIN Batch 5/1300 loss 22.390892 loss_att 17.872463 loss_ctc 24.040005 loss_rnnt 15.324497 hw_loss 1.453162 lr 0.00076240 rank 5
2023-02-11 10:09:01,438 DEBUG TRAIN Batch 5/1300 loss 17.692902 loss_att 22.981035 loss_ctc 30.379141 loss_rnnt 12.224681 hw_loss 0.509830 lr 0.00076276 rank 7
2023-02-11 10:09:01,441 DEBUG TRAIN Batch 5/1300 loss 13.350855 loss_att 22.530046 loss_ctc 21.319691 loss_rnnt 10.068906 hw_loss 0.071925 lr 0.00076263 rank 3
2023-02-11 10:09:01,441 DEBUG TRAIN Batch 5/1300 loss 24.304235 loss_att 26.838484 loss_ctc 35.265747 loss_rnnt 17.532234 hw_loss 0.900678 lr 0.00076204 rank 0
2023-02-11 10:09:01,442 DEBUG TRAIN Batch 5/1300 loss 20.852394 loss_att 23.516390 loss_ctc 29.566830 loss_rnnt 15.762531 hw_loss 0.636589 lr 0.00076193 rank 2
2023-02-11 10:09:01,442 DEBUG TRAIN Batch 5/1300 loss 13.423828 loss_att 10.311243 loss_ctc 14.053591 loss_rnnt 8.448844 hw_loss 1.033787 lr 0.00076291 rank 6
2023-02-11 10:09:01,446 DEBUG TRAIN Batch 5/1300 loss 26.688545 loss_att 25.097914 loss_ctc 34.256523 loss_rnnt 23.363871 hw_loss 0.493826 lr 0.00076228 rank 1
2023-02-11 10:09:01,449 DEBUG TRAIN Batch 5/1300 loss 37.488338 loss_att 43.405502 loss_ctc 55.995499 loss_rnnt 32.777023 hw_loss 0.198799 lr 0.00076273 rank 4
2023-02-11 10:10:19,960 DEBUG TRAIN Batch 5/1400 loss 28.501080 loss_att 34.106644 loss_ctc 43.744762 loss_rnnt 22.382786 hw_loss 0.555879 lr 0.00076116 rank 0
2023-02-11 10:10:19,963 DEBUG TRAIN Batch 5/1400 loss 25.759977 loss_att 23.398394 loss_ctc 35.985703 loss_rnnt 22.978130 hw_loss 0.354513 lr 0.00076185 rank 4
2023-02-11 10:10:19,965 DEBUG TRAIN Batch 5/1400 loss 11.029975 loss_att 17.533417 loss_ctc 21.349487 loss_rnnt 8.206686 hw_loss 0.027500 lr 0.00076140 rank 1
2023-02-11 10:10:19,965 DEBUG TRAIN Batch 5/1400 loss 23.303307 loss_att 28.084946 loss_ctc 34.991585 loss_rnnt 19.371086 hw_loss 0.265773 lr 0.00076105 rank 2
2023-02-11 10:10:19,965 DEBUG TRAIN Batch 5/1400 loss 15.281406 loss_att 19.868843 loss_ctc 22.684408 loss_rnnt 12.368528 hw_loss 0.189061 lr 0.00076187 rank 7
2023-02-11 10:10:19,967 DEBUG TRAIN Batch 5/1400 loss 39.095318 loss_att 38.122124 loss_ctc 55.958153 loss_rnnt 32.888870 hw_loss 0.778632 lr 0.00076152 rank 5
2023-02-11 10:10:19,967 DEBUG TRAIN Batch 5/1400 loss 21.716185 loss_att 27.362877 loss_ctc 35.510811 loss_rnnt 15.039537 hw_loss 0.695255 lr 0.00076175 rank 3
2023-02-11 10:10:20,008 DEBUG TRAIN Batch 5/1400 loss 14.384195 loss_att 23.494661 loss_ctc 23.059414 loss_rnnt 10.049948 hw_loss 0.254149 lr 0.00076202 rank 6
2023-02-11 10:11:37,895 DEBUG TRAIN Batch 5/1500 loss 33.755997 loss_att 34.649265 loss_ctc 52.391171 loss_rnnt 28.680014 hw_loss 0.452370 lr 0.00076087 rank 3
2023-02-11 10:11:37,900 DEBUG TRAIN Batch 5/1500 loss 38.182003 loss_att 41.212555 loss_ctc 55.060131 loss_rnnt 34.176666 hw_loss 0.215402 lr 0.00076051 rank 1
2023-02-11 10:11:37,900 DEBUG TRAIN Batch 5/1500 loss 56.474609 loss_att 63.080158 loss_ctc 73.864075 loss_rnnt 51.191326 hw_loss 0.308171 lr 0.00076099 rank 7
2023-02-11 10:11:37,902 DEBUG TRAIN Batch 5/1500 loss 13.380514 loss_att 21.119312 loss_ctc 22.215668 loss_rnnt 10.124488 hw_loss 0.099421 lr 0.00076114 rank 6
2023-02-11 10:11:37,902 DEBUG TRAIN Batch 5/1500 loss 26.480755 loss_att 28.767223 loss_ctc 40.042458 loss_rnnt 22.952223 hw_loss 0.236814 lr 0.00076028 rank 0
2023-02-11 10:11:37,904 DEBUG TRAIN Batch 5/1500 loss 13.553843 loss_att 19.934202 loss_ctc 25.367659 loss_rnnt 10.415331 hw_loss 0.053862 lr 0.00076017 rank 2
2023-02-11 10:11:37,908 DEBUG TRAIN Batch 5/1500 loss 26.159952 loss_att 30.228415 loss_ctc 39.619564 loss_rnnt 20.448681 hw_loss 0.581806 lr 0.00076096 rank 4
2023-02-11 10:11:37,914 DEBUG TRAIN Batch 5/1500 loss 48.181515 loss_att 51.205811 loss_ctc 77.010399 loss_rnnt 43.078960 hw_loss 0.122596 lr 0.00076064 rank 5
2023-02-11 10:12:53,474 DEBUG TRAIN Batch 5/1600 loss 22.106810 loss_att 26.265776 loss_ctc 33.574551 loss_rnnt 17.232328 hw_loss 0.471311 lr 0.00075976 rank 5
2023-02-11 10:12:53,474 DEBUG TRAIN Batch 5/1600 loss 28.196852 loss_att 25.552069 loss_ctc 36.933174 loss_rnnt 21.683392 hw_loss 1.102046 lr 0.00075929 rank 2
2023-02-11 10:12:53,479 DEBUG TRAIN Batch 5/1600 loss 19.078949 loss_att 20.354139 loss_ctc 30.692190 loss_rnnt 14.818712 hw_loss 0.460643 lr 0.00075940 rank 0
2023-02-11 10:12:53,479 DEBUG TRAIN Batch 5/1600 loss 32.467384 loss_att 36.359642 loss_ctc 51.631901 loss_rnnt 28.041039 hw_loss 0.204867 lr 0.00075964 rank 1
2023-02-11 10:12:53,480 DEBUG TRAIN Batch 5/1600 loss 15.771119 loss_att 19.456728 loss_ctc 22.507610 loss_rnnt 12.113892 hw_loss 0.379107 lr 0.00075999 rank 3
2023-02-11 10:12:53,481 DEBUG TRAIN Batch 5/1600 loss 17.222773 loss_att 21.338482 loss_ctc 28.014782 loss_rnnt 12.290242 hw_loss 0.500710 lr 0.00076011 rank 7
2023-02-11 10:12:53,482 DEBUG TRAIN Batch 5/1600 loss 23.864544 loss_att 27.926163 loss_ctc 35.950386 loss_rnnt 18.879242 hw_loss 0.480287 lr 0.00076008 rank 4
2023-02-11 10:12:53,527 DEBUG TRAIN Batch 5/1600 loss 10.607802 loss_att 15.830358 loss_ctc 18.992302 loss_rnnt 6.425599 hw_loss 0.378705 lr 0.00076026 rank 6
2023-02-11 10:14:09,884 DEBUG TRAIN Batch 5/1700 loss 21.849154 loss_att 22.865974 loss_ctc 35.210106 loss_rnnt 17.208982 hw_loss 0.497878 lr 0.00075888 rank 5
2023-02-11 10:14:09,887 DEBUG TRAIN Batch 5/1700 loss 22.273190 loss_att 25.281467 loss_ctc 36.271732 loss_rnnt 17.492630 hw_loss 0.433581 lr 0.00075923 rank 7
2023-02-11 10:14:09,887 DEBUG TRAIN Batch 5/1700 loss 29.766651 loss_att 33.126072 loss_ctc 51.052887 loss_rnnt 23.460503 hw_loss 0.524268 lr 0.00075876 rank 1
2023-02-11 10:14:09,888 DEBUG TRAIN Batch 5/1700 loss 12.892408 loss_att 19.914978 loss_ctc 20.905991 loss_rnnt 7.605341 hw_loss 0.527639 lr 0.00075921 rank 4
2023-02-11 10:14:09,890 DEBUG TRAIN Batch 5/1700 loss 24.011765 loss_att 26.100250 loss_ctc 36.677673 loss_rnnt 18.569248 hw_loss 0.625506 lr 0.00075853 rank 0
2023-02-11 10:14:09,890 DEBUG TRAIN Batch 5/1700 loss 24.225838 loss_att 28.029657 loss_ctc 36.694130 loss_rnnt 17.815817 hw_loss 0.747528 lr 0.00075911 rank 3
2023-02-11 10:14:09,893 DEBUG TRAIN Batch 5/1700 loss 14.252612 loss_att 22.309105 loss_ctc 23.161968 loss_rnnt 8.611279 hw_loss 0.532897 lr 0.00075938 rank 6
2023-02-11 10:14:09,892 DEBUG TRAIN Batch 5/1700 loss 38.977299 loss_att 44.459164 loss_ctc 61.402210 loss_rnnt 32.374161 hw_loss 0.471896 lr 0.00075842 rank 2
2023-02-11 10:15:27,777 DEBUG TRAIN Batch 5/1800 loss 21.612345 loss_att 22.255363 loss_ctc 27.920799 loss_rnnt 17.690624 hw_loss 0.553498 lr 0.00075833 rank 4
2023-02-11 10:15:27,778 DEBUG TRAIN Batch 5/1800 loss 19.562151 loss_att 23.012894 loss_ctc 30.670374 loss_rnnt 15.448130 hw_loss 0.364270 lr 0.00075801 rank 5
2023-02-11 10:15:27,779 DEBUG TRAIN Batch 5/1800 loss 20.494011 loss_att 22.744951 loss_ctc 29.897404 loss_rnnt 17.961704 hw_loss 0.155312 lr 0.00075824 rank 3
2023-02-11 10:15:27,779 DEBUG TRAIN Batch 5/1800 loss 13.476843 loss_att 15.768835 loss_ctc 22.048872 loss_rnnt 9.153534 hw_loss 0.510370 lr 0.00075789 rank 1
2023-02-11 10:15:27,779 DEBUG TRAIN Batch 5/1800 loss 17.718796 loss_att 17.927050 loss_ctc 22.544468 loss_rnnt 12.712196 hw_loss 0.810286 lr 0.00075836 rank 7
2023-02-11 10:15:27,781 DEBUG TRAIN Batch 5/1800 loss 19.297516 loss_att 21.648209 loss_ctc 35.027607 loss_rnnt 12.922924 hw_loss 0.713833 lr 0.00075765 rank 0
2023-02-11 10:15:27,784 DEBUG TRAIN Batch 5/1800 loss 16.678885 loss_att 19.813356 loss_ctc 19.139509 loss_rnnt 11.502839 hw_loss 0.791450 lr 0.00075851 rank 6
2023-02-11 10:15:27,827 DEBUG TRAIN Batch 5/1800 loss 20.749823 loss_att 21.756874 loss_ctc 29.064297 loss_rnnt 17.351624 hw_loss 0.391536 lr 0.00075755 rank 2
2023-02-11 10:16:43,162 DEBUG TRAIN Batch 5/1900 loss 14.663869 loss_att 14.210421 loss_ctc 21.812515 loss_rnnt 10.688869 hw_loss 0.583601 lr 0.00075737 rank 3
2023-02-11 10:16:43,162 DEBUG TRAIN Batch 5/1900 loss 14.238976 loss_att 12.715073 loss_ctc 18.441359 loss_rnnt 9.090981 hw_loss 0.917336 lr 0.00075746 rank 4
2023-02-11 10:16:43,163 DEBUG TRAIN Batch 5/1900 loss 16.811562 loss_att 16.658749 loss_ctc 21.942677 loss_rnnt 14.008925 hw_loss 0.402947 lr 0.00075679 rank 0
2023-02-11 10:16:43,163 DEBUG TRAIN Batch 5/1900 loss 12.234567 loss_att 17.699802 loss_ctc 19.627686 loss_rnnt 9.231651 hw_loss 0.173272 lr 0.00075749 rank 7
2023-02-11 10:16:43,164 DEBUG TRAIN Batch 5/1900 loss 26.983526 loss_att 25.847214 loss_ctc 31.245300 loss_rnnt 22.376244 hw_loss 0.799932 lr 0.00075702 rank 1
2023-02-11 10:16:43,167 DEBUG TRAIN Batch 5/1900 loss 16.204556 loss_att 24.127165 loss_ctc 22.403702 loss_rnnt 11.643373 hw_loss 0.403145 lr 0.00075668 rank 2
2023-02-11 10:16:43,167 DEBUG TRAIN Batch 5/1900 loss 22.567139 loss_att 24.680077 loss_ctc 30.081625 loss_rnnt 17.348103 hw_loss 0.711472 lr 0.00075714 rank 5
2023-02-11 10:16:43,169 DEBUG TRAIN Batch 5/1900 loss 17.203079 loss_att 16.972561 loss_ctc 22.519781 loss_rnnt 12.194290 hw_loss 0.814875 lr 0.00075764 rank 6
2023-02-11 10:17:58,620 DEBUG TRAIN Batch 5/2000 loss 21.373812 loss_att 26.161543 loss_ctc 35.052433 loss_rnnt 16.941744 hw_loss 0.309507 lr 0.00075592 rank 0
2023-02-11 10:17:58,621 DEBUG TRAIN Batch 5/2000 loss 15.886305 loss_att 19.521317 loss_ctc 31.581701 loss_rnnt 12.846214 hw_loss 0.041319 lr 0.00075650 rank 3
2023-02-11 10:17:58,626 DEBUG TRAIN Batch 5/2000 loss 21.862448 loss_att 22.087702 loss_ctc 35.979763 loss_rnnt 16.882347 hw_loss 0.572389 lr 0.00075662 rank 7
2023-02-11 10:17:58,628 DEBUG TRAIN Batch 5/2000 loss 12.359845 loss_att 17.751348 loss_ctc 21.846333 loss_rnnt 9.005934 hw_loss 0.189515 lr 0.00075615 rank 1
2023-02-11 10:17:58,629 DEBUG TRAIN Batch 5/2000 loss 15.426955 loss_att 21.526957 loss_ctc 30.032436 loss_rnnt 11.141647 hw_loss 0.209608 lr 0.00075660 rank 4
2023-02-11 10:17:58,629 DEBUG TRAIN Batch 5/2000 loss 17.085806 loss_att 19.879974 loss_ctc 21.702728 loss_rnnt 13.225702 hw_loss 0.503565 lr 0.00075582 rank 2
2023-02-11 10:17:58,632 DEBUG TRAIN Batch 5/2000 loss 16.507713 loss_att 18.217047 loss_ctc 29.671913 loss_rnnt 12.676387 hw_loss 0.325169 lr 0.00075627 rank 5
2023-02-11 10:17:58,676 DEBUG TRAIN Batch 5/2000 loss 19.398075 loss_att 28.218765 loss_ctc 35.095860 loss_rnnt 13.338440 hw_loss 0.412961 lr 0.00075677 rank 6
2023-02-11 10:19:17,459 DEBUG TRAIN Batch 5/2100 loss 14.329735 loss_att 18.845654 loss_ctc 22.015722 loss_rnnt 10.777945 hw_loss 0.304464 lr 0.00075576 rank 7
2023-02-11 10:19:17,466 DEBUG TRAIN Batch 5/2100 loss 23.001953 loss_att 24.049271 loss_ctc 33.478432 loss_rnnt 17.372520 hw_loss 0.754332 lr 0.00075495 rank 2
2023-02-11 10:19:17,468 DEBUG TRAIN Batch 5/2100 loss 9.497809 loss_att 12.219602 loss_ctc 18.409866 loss_rnnt 5.695310 hw_loss 0.388100 lr 0.00075529 rank 1
2023-02-11 10:19:17,468 DEBUG TRAIN Batch 5/2100 loss 14.348840 loss_att 18.768358 loss_ctc 22.142803 loss_rnnt 10.500091 hw_loss 0.361059 lr 0.00075564 rank 3
2023-02-11 10:19:17,472 DEBUG TRAIN Batch 5/2100 loss 14.559443 loss_att 14.594177 loss_ctc 18.730574 loss_rnnt 9.377405 hw_loss 0.866051 lr 0.00075573 rank 4
2023-02-11 10:19:17,477 DEBUG TRAIN Batch 5/2100 loss 38.228668 loss_att 40.781853 loss_ctc 58.385979 loss_rnnt 31.882521 hw_loss 0.590226 lr 0.00075541 rank 5
2023-02-11 10:19:17,482 DEBUG TRAIN Batch 5/2100 loss 17.463488 loss_att 22.576626 loss_ctc 25.161123 loss_rnnt 13.154914 hw_loss 0.423674 lr 0.00075506 rank 0
2023-02-11 10:19:17,513 DEBUG TRAIN Batch 5/2100 loss 18.876774 loss_att 19.168533 loss_ctc 22.804413 loss_rnnt 15.628737 hw_loss 0.499875 lr 0.00075590 rank 6
2023-02-11 10:20:33,617 DEBUG TRAIN Batch 5/2200 loss 33.630325 loss_att 41.220451 loss_ctc 43.875828 loss_rnnt 27.893429 hw_loss 0.534901 lr 0.00075477 rank 3
2023-02-11 10:20:33,617 DEBUG TRAIN Batch 5/2200 loss 18.898418 loss_att 19.269581 loss_ctc 24.291004 loss_rnnt 14.950328 hw_loss 0.591534 lr 0.00075504 rank 6
2023-02-11 10:20:33,621 DEBUG TRAIN Batch 5/2200 loss 13.364673 loss_att 17.543571 loss_ctc 21.733551 loss_rnnt 9.021624 hw_loss 0.448391 lr 0.00075489 rank 7
2023-02-11 10:20:33,621 DEBUG TRAIN Batch 5/2200 loss 25.758247 loss_att 29.864079 loss_ctc 42.376030 loss_rnnt 19.711077 hw_loss 0.564431 lr 0.00075420 rank 0
2023-02-11 10:20:33,623 DEBUG TRAIN Batch 5/2200 loss 21.398016 loss_att 21.377092 loss_ctc 27.774990 loss_rnnt 16.290625 hw_loss 0.798996 lr 0.00075487 rank 4
2023-02-11 10:20:33,626 DEBUG TRAIN Batch 5/2200 loss 10.638081 loss_att 14.742561 loss_ctc 18.324818 loss_rnnt 6.149981 hw_loss 0.495432 lr 0.00075443 rank 1
2023-02-11 10:20:33,627 DEBUG TRAIN Batch 5/2200 loss 20.571150 loss_att 21.036253 loss_ctc 31.445784 loss_rnnt 14.869050 hw_loss 0.779836 lr 0.00075410 rank 2
2023-02-11 10:20:33,628 DEBUG TRAIN Batch 5/2200 loss 25.570593 loss_att 31.400616 loss_ctc 43.183662 loss_rnnt 19.045008 hw_loss 0.564594 lr 0.00075455 rank 5
2023-02-11 10:21:48,429 DEBUG TRAIN Batch 5/2300 loss 15.007064 loss_att 15.936167 loss_ctc 22.790627 loss_rnnt 11.906139 hw_loss 0.351993 lr 0.00075334 rank 0
2023-02-11 10:21:48,429 DEBUG TRAIN Batch 5/2300 loss 21.143454 loss_att 27.110878 loss_ctc 40.457512 loss_rnnt 15.865041 hw_loss 0.283073 lr 0.00075392 rank 3
2023-02-11 10:21:48,430 DEBUG TRAIN Batch 5/2300 loss 28.203703 loss_att 31.234966 loss_ctc 42.135410 loss_rnnt 24.444075 hw_loss 0.242965 lr 0.00075404 rank 7
2023-02-11 10:21:48,432 DEBUG TRAIN Batch 5/2300 loss 37.280731 loss_att 41.062317 loss_ctc 48.294235 loss_rnnt 33.207321 hw_loss 0.346617 lr 0.00075401 rank 4
2023-02-11 10:21:48,432 DEBUG TRAIN Batch 5/2300 loss 19.425066 loss_att 18.912403 loss_ctc 23.910284 loss_rnnt 14.535852 hw_loss 0.823822 lr 0.00075418 rank 6
2023-02-11 10:21:48,434 DEBUG TRAIN Batch 5/2300 loss 30.197081 loss_att 36.220448 loss_ctc 49.335339 loss_rnnt 23.706327 hw_loss 0.512683 lr 0.00075324 rank 2
2023-02-11 10:21:48,434 DEBUG TRAIN Batch 5/2300 loss 14.594578 loss_att 16.166111 loss_ctc 20.827877 loss_rnnt 9.535553 hw_loss 0.733802 lr 0.00075369 rank 5
2023-02-11 10:21:48,483 DEBUG TRAIN Batch 5/2300 loss 16.869970 loss_att 19.774431 loss_ctc 30.243692 loss_rnnt 13.651163 hw_loss 0.160266 lr 0.00075357 rank 1
2023-02-11 10:23:04,362 DEBUG TRAIN Batch 5/2400 loss 31.449102 loss_att 29.942669 loss_ctc 46.003166 loss_rnnt 27.143145 hw_loss 0.500006 lr 0.00075306 rank 3
2023-02-11 10:23:04,363 DEBUG TRAIN Batch 5/2400 loss 24.253046 loss_att 28.669973 loss_ctc 35.397018 loss_rnnt 20.942001 hw_loss 0.176587 lr 0.00075284 rank 5
2023-02-11 10:23:04,364 DEBUG TRAIN Batch 5/2400 loss 25.393421 loss_att 25.985214 loss_ctc 37.649452 loss_rnnt 21.748569 hw_loss 0.354817 lr 0.00075249 rank 0
2023-02-11 10:23:04,365 DEBUG TRAIN Batch 5/2400 loss 13.871258 loss_att 13.348476 loss_ctc 14.661342 loss_rnnt 11.032565 hw_loss 0.532107 lr 0.00075318 rank 7
2023-02-11 10:23:04,365 DEBUG TRAIN Batch 5/2400 loss 20.331125 loss_att 24.492172 loss_ctc 28.752975 loss_rnnt 17.451550 hw_loss 0.173335 lr 0.00075332 rank 6
2023-02-11 10:23:04,368 DEBUG TRAIN Batch 5/2400 loss 22.006523 loss_att 24.243927 loss_ctc 29.839649 loss_rnnt 17.656345 hw_loss 0.535928 lr 0.00075239 rank 2
2023-02-11 10:23:04,369 DEBUG TRAIN Batch 5/2400 loss 18.853355 loss_att 19.390383 loss_ctc 29.965649 loss_rnnt 14.672806 hw_loss 0.485907 lr 0.00075315 rank 4
2023-02-11 10:23:04,371 DEBUG TRAIN Batch 5/2400 loss 21.838413 loss_att 27.057804 loss_ctc 35.861080 loss_rnnt 17.836475 hw_loss 0.204069 lr 0.00075272 rank 1
2023-02-11 10:24:23,680 DEBUG TRAIN Batch 5/2500 loss 22.437363 loss_att 19.845480 loss_ctc 25.547855 loss_rnnt 17.961674 hw_loss 0.858625 lr 0.00075221 rank 3
2023-02-11 10:24:23,682 DEBUG TRAIN Batch 5/2500 loss 25.348888 loss_att 23.886734 loss_ctc 36.049000 loss_rnnt 21.698475 hw_loss 0.471781 lr 0.00075187 rank 1
2023-02-11 10:24:23,684 DEBUG TRAIN Batch 5/2500 loss 42.272255 loss_att 43.887730 loss_ctc 66.010971 loss_rnnt 36.618851 hw_loss 0.405964 lr 0.00075233 rank 7
2023-02-11 10:24:23,685 DEBUG TRAIN Batch 5/2500 loss 18.118093 loss_att 22.529736 loss_ctc 28.810791 loss_rnnt 13.363144 hw_loss 0.458799 lr 0.00075199 rank 5
2023-02-11 10:24:23,685 DEBUG TRAIN Batch 5/2500 loss 13.692316 loss_att 15.427090 loss_ctc 20.432350 loss_rnnt 9.501450 hw_loss 0.552233 lr 0.00075164 rank 0
2023-02-11 10:24:23,686 DEBUG TRAIN Batch 5/2500 loss 42.133163 loss_att 41.973015 loss_ctc 56.839672 loss_rnnt 37.299763 hw_loss 0.544605 lr 0.00075230 rank 4
2023-02-11 10:24:23,687 DEBUG TRAIN Batch 5/2500 loss 14.251105 loss_att 11.250346 loss_ctc 15.922021 loss_rnnt 10.610077 hw_loss 0.753448 lr 0.00075154 rank 2
2023-02-11 10:24:23,729 DEBUG TRAIN Batch 5/2500 loss 17.192196 loss_att 17.567612 loss_ctc 21.721367 loss_rnnt 13.418090 hw_loss 0.580338 lr 0.00075247 rank 6
2023-02-11 10:25:40,007 DEBUG TRAIN Batch 5/2600 loss 21.911867 loss_att 30.447960 loss_ctc 37.364986 loss_rnnt 17.062374 hw_loss 0.202848 lr 0.00075069 rank 2
2023-02-11 10:25:40,010 DEBUG TRAIN Batch 5/2600 loss 19.973652 loss_att 17.263895 loss_ctc 23.271872 loss_rnnt 15.521108 hw_loss 0.854012 lr 0.00075145 rank 4
2023-02-11 10:25:40,010 DEBUG TRAIN Batch 5/2600 loss 26.889898 loss_att 29.328485 loss_ctc 43.389778 loss_rnnt 19.290953 hw_loss 0.920858 lr 0.00075148 rank 7
2023-02-11 10:25:40,011 DEBUG TRAIN Batch 5/2600 loss 18.286629 loss_att 22.107597 loss_ctc 24.476910 loss_rnnt 14.161784 hw_loss 0.475365 lr 0.00075136 rank 3
2023-02-11 10:25:40,012 DEBUG TRAIN Batch 5/2600 loss 18.491346 loss_att 25.088182 loss_ctc 28.105764 loss_rnnt 14.638804 hw_loss 0.234610 lr 0.00075079 rank 0
2023-02-11 10:25:40,013 DEBUG TRAIN Batch 5/2600 loss 30.108906 loss_att 30.084137 loss_ctc 39.697716 loss_rnnt 26.953350 hw_loss 0.352875 lr 0.00075162 rank 6
2023-02-11 10:25:40,013 DEBUG TRAIN Batch 5/2600 loss 21.703552 loss_att 20.520134 loss_ctc 25.808262 loss_rnnt 16.153126 hw_loss 0.982465 lr 0.00075102 rank 1
2023-02-11 10:25:40,014 DEBUG TRAIN Batch 5/2600 loss 14.212786 loss_att 11.394184 loss_ctc 16.311800 loss_rnnt 10.013660 hw_loss 0.840558 lr 0.00075114 rank 5
2023-02-11 10:26:55,059 DEBUG TRAIN Batch 5/2700 loss 19.043468 loss_att 20.511023 loss_ctc 26.405804 loss_rnnt 15.212362 hw_loss 0.479241 lr 0.00075077 rank 6
2023-02-11 10:26:55,064 DEBUG TRAIN Batch 5/2700 loss 20.366570 loss_att 22.501995 loss_ctc 28.630331 loss_rnnt 16.537010 hw_loss 0.431370 lr 0.00075063 rank 7
2023-02-11 10:26:55,064 DEBUG TRAIN Batch 5/2700 loss 17.382318 loss_att 20.125647 loss_ctc 25.089195 loss_rnnt 14.063744 hw_loss 0.326686 lr 0.00075029 rank 5
2023-02-11 10:26:55,069 DEBUG TRAIN Batch 5/2700 loss 17.325668 loss_att 22.715410 loss_ctc 23.007658 loss_rnnt 13.534193 hw_loss 0.366737 lr 0.00074994 rank 0
2023-02-11 10:26:55,069 DEBUG TRAIN Batch 5/2700 loss 42.113033 loss_att 45.056755 loss_ctc 62.840637 loss_rnnt 36.799507 hw_loss 0.367707 lr 0.00075051 rank 3
2023-02-11 10:26:55,071 DEBUG TRAIN Batch 5/2700 loss 22.541172 loss_att 20.849852 loss_ctc 28.723965 loss_rnnt 19.255838 hw_loss 0.524855 lr 0.00074984 rank 2
2023-02-11 10:26:55,072 DEBUG TRAIN Batch 5/2700 loss 14.360128 loss_att 15.860855 loss_ctc 16.220098 loss_rnnt 12.188743 hw_loss 0.304358 lr 0.00075060 rank 4
2023-02-11 10:26:55,125 DEBUG TRAIN Batch 5/2700 loss 33.490021 loss_att 35.431442 loss_ctc 48.512218 loss_rnnt 29.467094 hw_loss 0.305941 lr 0.00075017 rank 1
2023-02-11 10:28:12,802 DEBUG TRAIN Batch 5/2800 loss 16.620241 loss_att 18.027401 loss_ctc 27.041859 loss_rnnt 11.646914 hw_loss 0.619190 lr 0.00074910 rank 0
2023-02-11 10:28:12,807 DEBUG TRAIN Batch 5/2800 loss 20.599863 loss_att 22.991848 loss_ctc 34.040169 loss_rnnt 16.363264 hw_loss 0.368655 lr 0.00074900 rank 2
2023-02-11 10:28:12,812 DEBUG TRAIN Batch 5/2800 loss 23.229221 loss_att 26.481483 loss_ctc 34.389828 loss_rnnt 19.058523 hw_loss 0.381031 lr 0.00074978 rank 7
2023-02-11 10:28:12,813 DEBUG TRAIN Batch 5/2800 loss 25.297495 loss_att 29.828037 loss_ctc 39.167301 loss_rnnt 19.467821 hw_loss 0.576423 lr 0.00074967 rank 3
2023-02-11 10:28:12,814 DEBUG TRAIN Batch 5/2800 loss 12.672082 loss_att 14.317558 loss_ctc 22.217739 loss_rnnt 9.451368 hw_loss 0.303537 lr 0.00074933 rank 1
2023-02-11 10:28:12,815 DEBUG TRAIN Batch 5/2800 loss 17.672632 loss_att 20.407564 loss_ctc 25.352489 loss_rnnt 14.676651 hw_loss 0.267190 lr 0.00074945 rank 5
2023-02-11 10:28:12,816 DEBUG TRAIN Batch 5/2800 loss 25.050562 loss_att 30.171984 loss_ctc 35.821854 loss_rnnt 19.655926 hw_loss 0.550159 lr 0.00074976 rank 4
2023-02-11 10:28:12,817 DEBUG TRAIN Batch 5/2800 loss 26.709272 loss_att 27.328949 loss_ctc 35.759045 loss_rnnt 23.612947 hw_loss 0.331079 lr 0.00074993 rank 6
2023-02-11 10:29:30,684 DEBUG TRAIN Batch 5/2900 loss 23.526297 loss_att 29.630821 loss_ctc 38.226212 loss_rnnt 17.977907 hw_loss 0.443905 lr 0.00074883 rank 3
2023-02-11 10:29:30,685 DEBUG TRAIN Batch 5/2900 loss 19.579313 loss_att 28.583593 loss_ctc 36.748863 loss_rnnt 12.843161 hw_loss 0.496130 lr 0.00074892 rank 4
2023-02-11 10:29:30,687 DEBUG TRAIN Batch 5/2900 loss 33.506702 loss_att 37.538162 loss_ctc 55.111576 loss_rnnt 27.988401 hw_loss 0.343380 lr 0.00074894 rank 7
2023-02-11 10:29:30,688 DEBUG TRAIN Batch 5/2900 loss 23.814686 loss_att 24.916740 loss_ctc 40.223637 loss_rnnt 18.772621 hw_loss 0.493836 lr 0.00074826 rank 0
2023-02-11 10:29:30,689 DEBUG TRAIN Batch 5/2900 loss 19.228725 loss_att 24.889053 loss_ctc 33.132828 loss_rnnt 13.619184 hw_loss 0.491924 lr 0.00074861 rank 5
2023-02-11 10:29:30,690 DEBUG TRAIN Batch 5/2900 loss 28.048565 loss_att 33.459862 loss_ctc 44.059296 loss_rnnt 23.233685 hw_loss 0.299598 lr 0.00074909 rank 6
2023-02-11 10:29:30,693 DEBUG TRAIN Batch 5/2900 loss 18.441784 loss_att 22.587200 loss_ctc 24.702568 loss_rnnt 14.819166 hw_loss 0.367268 lr 0.00074816 rank 2
2023-02-11 10:29:30,739 DEBUG TRAIN Batch 5/2900 loss 28.976511 loss_att 32.927483 loss_ctc 43.577614 loss_rnnt 23.903509 hw_loss 0.437999 lr 0.00074849 rank 1
2023-02-11 10:30:45,815 DEBUG TRAIN Batch 5/3000 loss 21.515095 loss_att 23.234135 loss_ctc 25.348545 loss_rnnt 17.562897 hw_loss 0.580737 lr 0.00074799 rank 3
2023-02-11 10:30:45,816 DEBUG TRAIN Batch 5/3000 loss 22.553095 loss_att 26.589653 loss_ctc 35.270927 loss_rnnt 16.685892 hw_loss 0.630783 lr 0.00074825 rank 6
2023-02-11 10:30:45,818 DEBUG TRAIN Batch 5/3000 loss 17.621010 loss_att 19.110750 loss_ctc 20.444038 loss_rnnt 13.332560 hw_loss 0.677643 lr 0.00074765 rank 1
2023-02-11 10:30:45,818 DEBUG TRAIN Batch 5/3000 loss 23.545721 loss_att 25.997261 loss_ctc 36.280876 loss_rnnt 16.368589 hw_loss 0.935400 lr 0.00074808 rank 4
2023-02-11 10:30:45,821 DEBUG TRAIN Batch 5/3000 loss 21.307613 loss_att 21.133635 loss_ctc 27.204559 loss_rnnt 18.346180 hw_loss 0.414369 lr 0.00074810 rank 7
2023-02-11 10:30:45,822 DEBUG TRAIN Batch 5/3000 loss 28.314964 loss_att 29.863579 loss_ctc 41.264412 loss_rnnt 22.334293 hw_loss 0.739566 lr 0.00074743 rank 0
2023-02-11 10:30:45,825 DEBUG TRAIN Batch 5/3000 loss 24.441952 loss_att 22.238337 loss_ctc 28.635017 loss_rnnt 21.825661 hw_loss 0.468363 lr 0.00074777 rank 5
2023-02-11 10:30:45,827 DEBUG TRAIN Batch 5/3000 loss 9.293660 loss_att 12.710137 loss_ctc 16.654633 loss_rnnt 3.760486 hw_loss 0.725328 lr 0.00074733 rank 2
2023-02-11 10:32:00,599 DEBUG TRAIN Batch 5/3100 loss 17.091091 loss_att 16.558073 loss_ctc 20.759565 loss_rnnt 12.185818 hw_loss 0.848015 lr 0.00074649 rank 2
2023-02-11 10:32:00,602 DEBUG TRAIN Batch 5/3100 loss 21.646444 loss_att 17.221945 loss_ctc 21.669102 loss_rnnt 16.100779 hw_loss 1.205164 lr 0.00074727 rank 7
2023-02-11 10:32:00,603 DEBUG TRAIN Batch 5/3100 loss 27.252634 loss_att 28.273577 loss_ctc 33.768215 loss_rnnt 22.686449 hw_loss 0.654984 lr 0.00074659 rank 0
2023-02-11 10:32:00,603 DEBUG TRAIN Batch 5/3100 loss 24.191105 loss_att 22.291946 loss_ctc 33.000671 loss_rnnt 18.467955 hw_loss 0.924070 lr 0.00074741 rank 6
2023-02-11 10:32:00,605 DEBUG TRAIN Batch 5/3100 loss 19.502258 loss_att 19.779663 loss_ctc 26.639084 loss_rnnt 15.071280 hw_loss 0.641986 lr 0.00074715 rank 3
2023-02-11 10:32:00,606 DEBUG TRAIN Batch 5/3100 loss 14.391024 loss_att 16.097038 loss_ctc 23.875200 loss_rnnt 10.558568 hw_loss 0.417506 lr 0.00074693 rank 5
2023-02-11 10:32:00,611 DEBUG TRAIN Batch 5/3100 loss 10.946800 loss_att 13.787109 loss_ctc 14.951986 loss_rnnt 8.182949 hw_loss 0.311581 lr 0.00074724 rank 4
2023-02-11 10:32:00,649 DEBUG TRAIN Batch 5/3100 loss 18.319536 loss_att 19.686218 loss_ctc 25.207521 loss_rnnt 14.568756 hw_loss 0.479821 lr 0.00074682 rank 1
2023-02-11 10:33:19,433 DEBUG TRAIN Batch 5/3200 loss 14.987329 loss_att 20.641083 loss_ctc 30.212257 loss_rnnt 10.940211 hw_loss 0.166195 lr 0.00074632 rank 3
2023-02-11 10:33:19,434 DEBUG TRAIN Batch 5/3200 loss 20.513268 loss_att 17.345272 loss_ctc 26.770414 loss_rnnt 15.289020 hw_loss 0.941918 lr 0.00074576 rank 0
2023-02-11 10:33:19,434 DEBUG TRAIN Batch 5/3200 loss 28.060074 loss_att 31.992119 loss_ctc 40.142059 loss_rnnt 24.764502 hw_loss 0.168418 lr 0.00074658 rank 6
2023-02-11 10:33:19,435 DEBUG TRAIN Batch 5/3200 loss 21.603662 loss_att 28.902472 loss_ctc 34.809246 loss_rnnt 15.706676 hw_loss 0.501840 lr 0.00074643 rank 7
2023-02-11 10:33:19,436 DEBUG TRAIN Batch 5/3200 loss 17.486729 loss_att 21.321514 loss_ctc 36.509373 loss_rnnt 12.158226 hw_loss 0.379724 lr 0.00074566 rank 2
2023-02-11 10:33:19,441 DEBUG TRAIN Batch 5/3200 loss 18.003448 loss_att 20.853161 loss_ctc 29.159122 loss_rnnt 14.241501 hw_loss 0.319609 lr 0.00074641 rank 4
2023-02-11 10:33:19,440 DEBUG TRAIN Batch 5/3200 loss 17.578489 loss_att 14.892681 loss_ctc 22.053961 loss_rnnt 12.643712 hw_loss 0.914102 lr 0.00074610 rank 5
2023-02-11 10:33:19,460 DEBUG TRAIN Batch 5/3200 loss 16.634020 loss_att 13.953328 loss_ctc 16.707640 loss_rnnt 10.845930 hw_loss 1.183952 lr 0.00074599 rank 1
2023-02-11 10:34:35,440 DEBUG TRAIN Batch 5/3300 loss 16.092451 loss_att 20.027832 loss_ctc 29.626072 loss_rnnt 10.801563 hw_loss 0.506124 lr 0.00074493 rank 0
2023-02-11 10:34:35,444 DEBUG TRAIN Batch 5/3300 loss 26.115488 loss_att 27.286392 loss_ctc 43.788010 loss_rnnt 19.776232 hw_loss 0.702888 lr 0.00074558 rank 4
2023-02-11 10:34:35,444 DEBUG TRAIN Batch 5/3300 loss 16.784260 loss_att 23.450298 loss_ctc 22.967678 loss_rnnt 12.827423 hw_loss 0.337345 lr 0.00074483 rank 2
2023-02-11 10:34:35,445 DEBUG TRAIN Batch 5/3300 loss 25.367313 loss_att 26.943634 loss_ctc 38.551285 loss_rnnt 19.862961 hw_loss 0.643354 lr 0.00074549 rank 3
2023-02-11 10:34:35,446 DEBUG TRAIN Batch 5/3300 loss 28.523098 loss_att 32.568260 loss_ctc 43.405117 loss_rnnt 20.668568 hw_loss 0.948980 lr 0.00074575 rank 6
2023-02-11 10:34:35,445 DEBUG TRAIN Batch 5/3300 loss 21.382557 loss_att 22.443354 loss_ctc 30.956257 loss_rnnt 18.579502 hw_loss 0.246450 lr 0.00074560 rank 7
2023-02-11 10:34:35,446 DEBUG TRAIN Batch 5/3300 loss 20.287720 loss_att 25.195345 loss_ctc 34.798462 loss_rnnt 14.732933 hw_loss 0.494718 lr 0.00074527 rank 5
2023-02-11 10:34:35,447 DEBUG TRAIN Batch 5/3300 loss 21.615948 loss_att 28.157825 loss_ctc 39.789295 loss_rnnt 16.661579 hw_loss 0.229290 lr 0.00074516 rank 1
2023-02-11 10:35:51,511 DEBUG TRAIN Batch 5/3400 loss 21.049864 loss_att 24.799643 loss_ctc 30.395267 loss_rnnt 18.075367 hw_loss 0.183466 lr 0.00074478 rank 7
2023-02-11 10:35:51,515 DEBUG TRAIN Batch 5/3400 loss 15.196519 loss_att 17.984196 loss_ctc 25.813278 loss_rnnt 10.597292 hw_loss 0.492398 lr 0.00074466 rank 3
2023-02-11 10:35:51,515 DEBUG TRAIN Batch 5/3400 loss 16.528532 loss_att 24.595636 loss_ctc 28.621992 loss_rnnt 10.488433 hw_loss 0.527666 lr 0.00074475 rank 4
2023-02-11 10:35:51,520 DEBUG TRAIN Batch 5/3400 loss 38.537025 loss_att 37.555222 loss_ctc 54.129147 loss_rnnt 31.844757 hw_loss 0.901816 lr 0.00074411 rank 0
2023-02-11 10:35:51,521 DEBUG TRAIN Batch 5/3400 loss 20.618937 loss_att 28.256084 loss_ctc 31.319672 loss_rnnt 17.117132 hw_loss 0.102677 lr 0.00074445 rank 5
2023-02-11 10:35:51,521 DEBUG TRAIN Batch 5/3400 loss 13.931602 loss_att 16.218311 loss_ctc 19.299431 loss_rnnt 10.587524 hw_loss 0.407067 lr 0.00074492 rank 6
2023-02-11 10:35:51,523 DEBUG TRAIN Batch 5/3400 loss 12.844337 loss_att 14.344479 loss_ctc 16.322880 loss_rnnt 7.883294 hw_loss 0.786977 lr 0.00074401 rank 2
2023-02-11 10:35:51,568 DEBUG TRAIN Batch 5/3400 loss 18.944237 loss_att 25.105656 loss_ctc 34.058315 loss_rnnt 14.931285 hw_loss 0.143523 lr 0.00074433 rank 1
2023-02-11 10:37:09,824 DEBUG TRAIN Batch 5/3500 loss 19.978256 loss_att 20.800022 loss_ctc 31.131920 loss_rnnt 14.879459 hw_loss 0.646366 lr 0.00074409 rank 6
2023-02-11 10:37:09,825 DEBUG TRAIN Batch 5/3500 loss 14.532824 loss_att 20.907314 loss_ctc 27.087320 loss_rnnt 10.519321 hw_loss 0.199626 lr 0.00074395 rank 7
2023-02-11 10:37:09,826 DEBUG TRAIN Batch 5/3500 loss 34.768623 loss_att 34.298767 loss_ctc 48.429340 loss_rnnt 30.147739 hw_loss 0.542517 lr 0.00074319 rank 2
2023-02-11 10:37:09,828 DEBUG TRAIN Batch 5/3500 loss 23.916985 loss_att 27.203854 loss_ctc 34.921799 loss_rnnt 19.862919 hw_loss 0.361759 lr 0.00074384 rank 3
2023-02-11 10:37:09,828 DEBUG TRAIN Batch 5/3500 loss 17.871367 loss_att 19.164560 loss_ctc 28.443977 loss_rnnt 13.893853 hw_loss 0.432974 lr 0.00074329 rank 0
2023-02-11 10:37:09,830 DEBUG TRAIN Batch 5/3500 loss 21.989838 loss_att 28.810211 loss_ctc 39.883678 loss_rnnt 16.624390 hw_loss 0.302912 lr 0.00074351 rank 1
2023-02-11 10:37:09,831 DEBUG TRAIN Batch 5/3500 loss 20.286055 loss_att 20.294008 loss_ctc 32.425392 loss_rnnt 17.008728 hw_loss 0.310717 lr 0.00074362 rank 5
2023-02-11 10:37:09,834 DEBUG TRAIN Batch 5/3500 loss 10.653033 loss_att 13.736290 loss_ctc 15.287475 loss_rnnt 8.536877 hw_loss 0.165296 lr 0.00074393 rank 4
2023-02-11 10:38:27,489 DEBUG TRAIN Batch 5/3600 loss 29.281815 loss_att 36.239708 loss_ctc 48.829620 loss_rnnt 23.243593 hw_loss 0.382550 lr 0.00074302 rank 3
2023-02-11 10:38:27,491 DEBUG TRAIN Batch 5/3600 loss 19.609077 loss_att 22.229816 loss_ctc 27.685301 loss_rnnt 14.633084 hw_loss 0.632815 lr 0.00074247 rank 0
2023-02-11 10:38:27,494 DEBUG TRAIN Batch 5/3600 loss 31.593025 loss_att 32.179626 loss_ctc 40.083344 loss_rnnt 28.851597 hw_loss 0.279762 lr 0.00074237 rank 2
2023-02-11 10:38:27,495 DEBUG TRAIN Batch 5/3600 loss 9.638510 loss_att 12.474504 loss_ctc 12.388680 loss_rnnt 6.824189 hw_loss 0.352581 lr 0.00074280 rank 5
2023-02-11 10:38:27,496 DEBUG TRAIN Batch 5/3600 loss 18.413445 loss_att 19.563578 loss_ctc 28.117392 loss_rnnt 14.054693 hw_loss 0.531538 lr 0.00074313 rank 7
2023-02-11 10:38:27,496 DEBUG TRAIN Batch 5/3600 loss 24.116444 loss_att 25.088417 loss_ctc 35.088074 loss_rnnt 20.478743 hw_loss 0.371329 lr 0.00074269 rank 1
2023-02-11 10:38:27,497 DEBUG TRAIN Batch 5/3600 loss 44.332283 loss_att 48.765728 loss_ctc 67.157982 loss_rnnt 37.690552 hw_loss 0.508429 lr 0.00074327 rank 6
2023-02-11 10:38:27,499 DEBUG TRAIN Batch 5/3600 loss 24.410322 loss_att 28.945950 loss_ctc 39.183281 loss_rnnt 19.204918 hw_loss 0.436604 lr 0.00074311 rank 4
2023-02-11 10:39:42,538 DEBUG TRAIN Batch 5/3700 loss 24.151213 loss_att 26.055836 loss_ctc 30.935434 loss_rnnt 18.820778 hw_loss 0.758428 lr 0.00074165 rank 0
2023-02-11 10:39:42,538 DEBUG TRAIN Batch 5/3700 loss 11.332377 loss_att 10.502918 loss_ctc 16.185326 loss_rnnt 6.299680 hw_loss 0.853412 lr 0.00074245 rank 6
2023-02-11 10:39:42,538 DEBUG TRAIN Batch 5/3700 loss 19.079689 loss_att 22.289549 loss_ctc 31.117430 loss_rnnt 16.021284 hw_loss 0.152138 lr 0.00074231 rank 7
2023-02-11 10:39:42,539 DEBUG TRAIN Batch 5/3700 loss 28.706408 loss_att 29.883747 loss_ctc 43.203533 loss_rnnt 23.087271 hw_loss 0.647009 lr 0.00074220 rank 3
2023-02-11 10:39:42,539 DEBUG TRAIN Batch 5/3700 loss 21.841629 loss_att 25.350679 loss_ctc 31.598969 loss_rnnt 18.008106 hw_loss 0.343262 lr 0.00074187 rank 1
2023-02-11 10:39:42,540 DEBUG TRAIN Batch 5/3700 loss 19.551546 loss_att 22.095966 loss_ctc 28.472078 loss_rnnt 14.930786 hw_loss 0.547963 lr 0.00074229 rank 4
2023-02-11 10:39:42,542 DEBUG TRAIN Batch 5/3700 loss 13.537334 loss_att 17.031326 loss_ctc 19.531189 loss_rnnt 8.900478 hw_loss 0.588539 lr 0.00074198 rank 5
2023-02-11 10:39:42,586 DEBUG TRAIN Batch 5/3700 loss 21.403559 loss_att 23.842047 loss_ctc 29.724573 loss_rnnt 18.402166 hw_loss 0.263292 lr 0.00074155 rank 2
2023-02-11 10:40:58,332 DEBUG TRAIN Batch 5/3800 loss 10.757366 loss_att 17.126463 loss_ctc 23.140152 loss_rnnt 6.954393 hw_loss 0.164647 lr 0.00074149 rank 7
2023-02-11 10:40:58,333 DEBUG TRAIN Batch 5/3800 loss 21.325794 loss_att 22.294933 loss_ctc 36.260845 loss_rnnt 17.628431 hw_loss 0.283536 lr 0.00074083 rank 0
2023-02-11 10:40:58,335 DEBUG TRAIN Batch 5/3800 loss 13.169751 loss_att 13.371504 loss_ctc 17.414293 loss_rnnt 9.504681 hw_loss 0.573521 lr 0.00074138 rank 3
2023-02-11 10:40:58,335 DEBUG TRAIN Batch 5/3800 loss 23.044653 loss_att 26.228195 loss_ctc 31.767822 loss_rnnt 20.318241 hw_loss 0.173741 lr 0.00074105 rank 1
2023-02-11 10:40:58,336 DEBUG TRAIN Batch 5/3800 loss 19.177177 loss_att 19.370247 loss_ctc 23.913296 loss_rnnt 17.467278 hw_loss 0.194963 lr 0.00074147 rank 4
2023-02-11 10:40:58,336 DEBUG TRAIN Batch 5/3800 loss 15.738740 loss_att 13.130617 loss_ctc 14.636926 loss_rnnt 10.308328 hw_loss 1.143552 lr 0.00074163 rank 6
2023-02-11 10:40:58,336 DEBUG TRAIN Batch 5/3800 loss 38.949265 loss_att 38.309376 loss_ctc 55.655598 loss_rnnt 30.869938 hw_loss 1.121211 lr 0.00074117 rank 5
2023-02-11 10:40:58,336 DEBUG TRAIN Batch 5/3800 loss 50.718784 loss_att 54.917130 loss_ctc 79.229401 loss_rnnt 45.467537 hw_loss 0.114406 lr 0.00074074 rank 2
2023-02-11 10:42:17,288 DEBUG TRAIN Batch 5/3900 loss 36.439671 loss_att 42.807972 loss_ctc 59.032131 loss_rnnt 30.641783 hw_loss 0.283481 lr 0.00074024 rank 1
2023-02-11 10:42:17,289 DEBUG TRAIN Batch 5/3900 loss 11.299279 loss_att 15.029559 loss_ctc 18.165077 loss_rnnt 7.397424 hw_loss 0.420067 lr 0.00074066 rank 4
2023-02-11 10:42:17,289 DEBUG TRAIN Batch 5/3900 loss 5.312374 loss_att 11.146266 loss_ctc 12.072162 loss_rnnt 1.985293 hw_loss 0.236062 lr 0.00074057 rank 3
2023-02-11 10:42:17,292 DEBUG TRAIN Batch 5/3900 loss 21.306452 loss_att 26.586391 loss_ctc 40.325157 loss_rnnt 14.994680 hw_loss 0.509992 lr 0.00074068 rank 7
2023-02-11 10:42:17,295 DEBUG TRAIN Batch 5/3900 loss 33.131866 loss_att 34.727036 loss_ctc 50.753662 loss_rnnt 27.630348 hw_loss 0.531170 lr 0.00074002 rank 0
2023-02-11 10:42:17,294 DEBUG TRAIN Batch 5/3900 loss 17.999470 loss_att 20.039164 loss_ctc 30.632717 loss_rnnt 15.703985 hw_loss 0.038084 lr 0.00074035 rank 5
2023-02-11 10:42:17,296 DEBUG TRAIN Batch 5/3900 loss 30.790676 loss_att 41.543800 loss_ctc 48.553734 loss_rnnt 24.363897 hw_loss 0.357702 lr 0.00073993 rank 2
2023-02-11 10:42:17,297 DEBUG TRAIN Batch 5/3900 loss 17.703135 loss_att 21.137867 loss_ctc 24.851187 loss_rnnt 14.351825 hw_loss 0.320867 lr 0.00074082 rank 6
2023-02-11 10:43:32,734 DEBUG TRAIN Batch 5/4000 loss 40.154778 loss_att 53.130817 loss_ctc 56.229641 loss_rnnt 33.577499 hw_loss 0.344766 lr 0.00073954 rank 5
2023-02-11 10:43:32,735 DEBUG TRAIN Batch 5/4000 loss 26.965729 loss_att 36.978165 loss_ctc 36.617718 loss_rnnt 22.789419 hw_loss 0.166292 lr 0.00073921 rank 0
2023-02-11 10:43:32,735 DEBUG TRAIN Batch 5/4000 loss 9.459759 loss_att 16.196163 loss_ctc 14.763556 loss_rnnt 5.504459 hw_loss 0.356409 lr 0.00073943 rank 1
2023-02-11 10:43:32,737 DEBUG TRAIN Batch 5/4000 loss 18.281723 loss_att 23.941265 loss_ctc 27.238808 loss_rnnt 12.822906 hw_loss 0.587368 lr 0.00074001 rank 6
2023-02-11 10:43:32,738 DEBUG TRAIN Batch 5/4000 loss 22.291924 loss_att 25.389740 loss_ctc 32.802383 loss_rnnt 14.861826 hw_loss 1.014214 lr 0.00073976 rank 3
2023-02-11 10:43:32,739 DEBUG TRAIN Batch 5/4000 loss 36.097393 loss_att 42.046486 loss_ctc 64.869904 loss_rnnt 30.724869 hw_loss 0.064944 lr 0.00073912 rank 2
2023-02-11 10:43:32,740 DEBUG TRAIN Batch 5/4000 loss 26.951542 loss_att 34.663471 loss_ctc 39.114807 loss_rnnt 20.621513 hw_loss 0.593601 lr 0.00073987 rank 7
2023-02-11 10:43:32,740 DEBUG TRAIN Batch 5/4000 loss 14.460011 loss_att 20.987303 loss_ctc 26.138714 loss_rnnt 11.300739 hw_loss 0.055622 lr 0.00073984 rank 4
2023-02-11 10:44:47,011 DEBUG TRAIN Batch 5/4100 loss 19.443434 loss_att 23.977142 loss_ctc 28.230667 loss_rnnt 14.381603 hw_loss 0.559398 lr 0.00073895 rank 3
2023-02-11 10:44:47,011 DEBUG TRAIN Batch 5/4100 loss 15.802451 loss_att 19.433043 loss_ctc 22.035187 loss_rnnt 11.103390 hw_loss 0.589108 lr 0.00073841 rank 0
2023-02-11 10:44:47,015 DEBUG TRAIN Batch 5/4100 loss 20.097847 loss_att 24.100721 loss_ctc 29.957432 loss_rnnt 14.450674 hw_loss 0.662247 lr 0.00073920 rank 6
2023-02-11 10:44:47,016 DEBUG TRAIN Batch 5/4100 loss 13.909652 loss_att 15.212999 loss_ctc 21.639980 loss_rnnt 10.749359 hw_loss 0.350421 lr 0.00073874 rank 5
2023-02-11 10:44:47,020 DEBUG TRAIN Batch 5/4100 loss 17.566357 loss_att 24.672974 loss_ctc 22.640764 loss_rnnt 12.159008 hw_loss 0.620519 lr 0.00073831 rank 2
2023-02-11 10:44:47,022 DEBUG TRAIN Batch 5/4100 loss 30.024782 loss_att 34.056885 loss_ctc 44.913418 loss_rnnt 24.043713 hw_loss 0.598031 lr 0.00073904 rank 4
2023-02-11 10:44:47,022 DEBUG TRAIN Batch 5/4100 loss 15.791922 loss_att 19.828630 loss_ctc 23.989536 loss_rnnt 13.098282 hw_loss 0.148741 lr 0.00073862 rank 1
2023-02-11 10:44:47,023 DEBUG TRAIN Batch 5/4100 loss 25.819550 loss_att 30.278606 loss_ctc 42.138771 loss_rnnt 21.271383 hw_loss 0.277586 lr 0.00073906 rank 7
2023-02-11 10:46:03,132 DEBUG TRAIN Batch 5/4200 loss 27.520071 loss_att 26.736534 loss_ctc 41.887478 loss_rnnt 22.953794 hw_loss 0.526374 lr 0.00073825 rank 7
2023-02-11 10:46:03,136 DEBUG TRAIN Batch 5/4200 loss 21.886932 loss_att 26.948650 loss_ctc 33.227211 loss_rnnt 15.742528 hw_loss 0.678754 lr 0.00073760 rank 0
2023-02-11 10:46:03,135 DEBUG TRAIN Batch 5/4200 loss 18.433079 loss_att 21.582935 loss_ctc 21.383934 loss_rnnt 12.665171 hw_loss 0.889592 lr 0.00073782 rank 1
2023-02-11 10:46:03,135 DEBUG TRAIN Batch 5/4200 loss 18.965872 loss_att 19.268333 loss_ctc 26.331936 loss_rnnt 13.939549 hw_loss 0.746942 lr 0.00073751 rank 2
2023-02-11 10:46:03,138 DEBUG TRAIN Batch 5/4200 loss 20.988018 loss_att 25.794865 loss_ctc 26.310808 loss_rnnt 18.846676 hw_loss 0.088175 lr 0.00073839 rank 6
2023-02-11 10:46:03,139 DEBUG TRAIN Batch 5/4200 loss 30.353197 loss_att 32.296032 loss_ctc 40.594971 loss_rnnt 25.370361 hw_loss 0.605380 lr 0.00073814 rank 3
2023-02-11 10:46:03,142 DEBUG TRAIN Batch 5/4200 loss 15.862002 loss_att 16.930088 loss_ctc 21.791466 loss_rnnt 12.590141 hw_loss 0.425184 lr 0.00073823 rank 4
2023-02-11 10:46:03,145 DEBUG TRAIN Batch 5/4200 loss 21.696203 loss_att 30.142063 loss_ctc 30.807140 loss_rnnt 17.221577 hw_loss 0.294499 lr 0.00073793 rank 5
2023-02-11 10:47:21,333 DEBUG TRAIN Batch 5/4300 loss 18.413820 loss_att 19.698341 loss_ctc 27.676079 loss_rnnt 15.101316 hw_loss 0.341369 lr 0.00073713 rank 5
2023-02-11 10:47:21,336 DEBUG TRAIN Batch 5/4300 loss 16.700417 loss_att 16.965158 loss_ctc 21.114828 loss_rnnt 13.160057 hw_loss 0.543529 lr 0.00073680 rank 0
2023-02-11 10:47:21,337 DEBUG TRAIN Batch 5/4300 loss 29.106417 loss_att 31.000408 loss_ctc 36.245522 loss_rnnt 26.748600 hw_loss 0.192588 lr 0.00073734 rank 3
2023-02-11 10:47:21,337 DEBUG TRAIN Batch 5/4300 loss 11.456023 loss_att 12.883401 loss_ctc 17.523535 loss_rnnt 6.095644 hw_loss 0.799857 lr 0.00073745 rank 7
2023-02-11 10:47:21,338 DEBUG TRAIN Batch 5/4300 loss 40.542336 loss_att 41.431049 loss_ctc 57.843994 loss_rnnt 35.461174 hw_loss 0.486849 lr 0.00073743 rank 4
2023-02-11 10:47:21,339 DEBUG TRAIN Batch 5/4300 loss 20.999298 loss_att 25.144896 loss_ctc 31.040421 loss_rnnt 16.374449 hw_loss 0.460671 lr 0.00073759 rank 6
2023-02-11 10:47:21,339 DEBUG TRAIN Batch 5/4300 loss 24.067513 loss_att 24.364084 loss_ctc 35.405193 loss_rnnt 19.020636 hw_loss 0.651726 lr 0.00073702 rank 1
2023-02-11 10:47:21,345 DEBUG TRAIN Batch 5/4300 loss 25.581230 loss_att 29.312933 loss_ctc 37.083313 loss_rnnt 19.842823 hw_loss 0.648460 lr 0.00073671 rank 2
2023-02-11 10:48:37,661 DEBUG TRAIN Batch 5/4400 loss 18.147774 loss_att 14.211782 loss_ctc 21.549587 loss_rnnt 11.702917 hw_loss 1.270965 lr 0.00073665 rank 7
2023-02-11 10:48:37,663 DEBUG TRAIN Batch 5/4400 loss 26.557293 loss_att 21.615685 loss_ctc 31.874359 loss_rnnt 19.975067 hw_loss 1.286551 lr 0.00073591 rank 2
2023-02-11 10:48:37,663 DEBUG TRAIN Batch 5/4400 loss 22.846846 loss_att 20.188534 loss_ctc 28.305969 loss_rnnt 18.707111 hw_loss 0.739409 lr 0.00073654 rank 3
2023-02-11 10:48:37,663 DEBUG TRAIN Batch 5/4400 loss 15.161559 loss_att 14.766062 loss_ctc 21.868668 loss_rnnt 9.390914 hw_loss 0.929149 lr 0.00073622 rank 1
2023-02-11 10:48:37,665 DEBUG TRAIN Batch 5/4400 loss 24.976902 loss_att 27.846876 loss_ctc 33.505863 loss_rnnt 19.418348 hw_loss 0.721381 lr 0.00073600 rank 0
2023-02-11 10:48:37,666 DEBUG TRAIN Batch 5/4400 loss 27.521412 loss_att 29.153984 loss_ctc 36.396950 loss_rnnt 23.621151 hw_loss 0.448189 lr 0.00073663 rank 4
2023-02-11 10:48:37,666 DEBUG TRAIN Batch 5/4400 loss 22.968925 loss_att 22.499189 loss_ctc 31.983027 loss_rnnt 17.449661 hw_loss 0.827124 lr 0.00073633 rank 5
2023-02-11 10:48:37,665 DEBUG TRAIN Batch 5/4400 loss 11.937254 loss_att 9.894375 loss_ctc 10.717587 loss_rnnt 5.936681 hw_loss 1.232207 lr 0.00073679 rank 6
2023-02-11 10:49:54,406 DEBUG TRAIN Batch 5/4500 loss 21.997673 loss_att 28.001213 loss_ctc 30.099501 loss_rnnt 16.384512 hw_loss 0.624789 lr 0.00073585 rank 7
2023-02-11 10:49:54,406 DEBUG TRAIN Batch 5/4500 loss 15.977375 loss_att 15.171713 loss_ctc 20.880676 loss_rnnt 11.610079 hw_loss 0.726498 lr 0.00073542 rank 1
2023-02-11 10:49:54,407 DEBUG TRAIN Batch 5/4500 loss 36.931347 loss_att 48.400822 loss_ctc 58.131447 loss_rnnt 30.495125 hw_loss 0.246684 lr 0.00073574 rank 3
2023-02-11 10:49:54,407 DEBUG TRAIN Batch 5/4500 loss 27.906853 loss_att 22.561895 loss_ctc 30.299675 loss_rnnt 25.231201 hw_loss 0.642300 lr 0.00073521 rank 0
2023-02-11 10:49:54,410 DEBUG TRAIN Batch 5/4500 loss 37.200634 loss_att 54.785278 loss_ctc 61.555016 loss_rnnt 29.397787 hw_loss 0.194750 lr 0.00073553 rank 5
2023-02-11 10:49:54,411 DEBUG TRAIN Batch 5/4500 loss 14.050330 loss_att 14.441362 loss_ctc 21.988506 loss_rnnt 9.041480 hw_loss 0.726041 lr 0.00073583 rank 4
2023-02-11 10:49:54,413 DEBUG TRAIN Batch 5/4500 loss 9.575915 loss_att 16.116995 loss_ctc 14.578303 loss_rnnt 6.291904 hw_loss 0.245402 lr 0.00073599 rank 6
2023-02-11 10:49:54,420 DEBUG TRAIN Batch 5/4500 loss 11.875351 loss_att 16.660488 loss_ctc 16.916409 loss_rnnt 6.586490 hw_loss 0.686192 lr 0.00073511 rank 2
2023-02-11 10:51:12,202 DEBUG TRAIN Batch 5/4600 loss 15.655093 loss_att 19.716614 loss_ctc 29.718269 loss_rnnt 11.992179 hw_loss 0.182910 lr 0.00073506 rank 7
2023-02-11 10:51:12,203 DEBUG TRAIN Batch 5/4600 loss 23.971949 loss_att 28.864285 loss_ctc 40.883472 loss_rnnt 20.455173 hw_loss 0.053145 lr 0.00073441 rank 0
2023-02-11 10:51:12,203 DEBUG TRAIN Batch 5/4600 loss 28.218313 loss_att 36.795872 loss_ctc 45.815125 loss_rnnt 21.236502 hw_loss 0.547511 lr 0.00073503 rank 4
2023-02-11 10:51:12,204 DEBUG TRAIN Batch 5/4600 loss 28.440882 loss_att 30.355122 loss_ctc 36.431568 loss_rnnt 26.198944 hw_loss 0.148812 lr 0.00073519 rank 6
2023-02-11 10:51:12,208 DEBUG TRAIN Batch 5/4600 loss 29.476145 loss_att 33.571896 loss_ctc 50.384377 loss_rnnt 24.906536 hw_loss 0.180505 lr 0.00073494 rank 3
2023-02-11 10:51:12,208 DEBUG TRAIN Batch 5/4600 loss 17.121859 loss_att 20.369734 loss_ctc 28.864538 loss_rnnt 13.142111 hw_loss 0.330841 lr 0.00073474 rank 5
2023-02-11 10:51:12,208 DEBUG TRAIN Batch 5/4600 loss 12.591011 loss_att 15.869141 loss_ctc 18.870031 loss_rnnt 10.173748 hw_loss 0.173331 lr 0.00073463 rank 1
2023-02-11 10:51:12,213 DEBUG TRAIN Batch 5/4600 loss 22.804874 loss_att 29.457691 loss_ctc 43.044415 loss_rnnt 18.370682 hw_loss 0.075942 lr 0.00073432 rank 2
2023-02-11 10:52:29,706 DEBUG TRAIN Batch 5/4700 loss 22.364758 loss_att 21.356686 loss_ctc 24.719997 loss_rnnt 17.139837 hw_loss 0.958595 lr 0.00073415 rank 3
2023-02-11 10:52:29,706 DEBUG TRAIN Batch 5/4700 loss 24.123707 loss_att 24.246628 loss_ctc 33.003036 loss_rnnt 20.118111 hw_loss 0.524456 lr 0.00073426 rank 7
2023-02-11 10:52:29,707 DEBUG TRAIN Batch 5/4700 loss 10.055299 loss_att 12.074928 loss_ctc 11.165735 loss_rnnt 7.535602 hw_loss 0.368946 lr 0.00073362 rank 0
2023-02-11 10:52:29,711 DEBUG TRAIN Batch 5/4700 loss 12.816225 loss_att 14.333620 loss_ctc 14.768873 loss_rnnt 8.808681 hw_loss 0.645696 lr 0.00073395 rank 5
2023-02-11 10:52:29,714 DEBUG TRAIN Batch 5/4700 loss 26.677738 loss_att 27.010576 loss_ctc 46.790997 loss_rnnt 18.925585 hw_loss 0.938216 lr 0.00073384 rank 1
2023-02-11 10:52:29,716 DEBUG TRAIN Batch 5/4700 loss 16.047565 loss_att 18.422520 loss_ctc 24.940557 loss_rnnt 14.049677 hw_loss 0.063218 lr 0.00073440 rank 6
2023-02-11 10:52:29,718 DEBUG TRAIN Batch 5/4700 loss 28.844305 loss_att 32.055771 loss_ctc 44.446037 loss_rnnt 24.450096 hw_loss 0.313441 lr 0.00073353 rank 2
2023-02-11 10:52:29,720 DEBUG TRAIN Batch 5/4700 loss 15.561163 loss_att 22.679699 loss_ctc 26.546875 loss_rnnt 9.658770 hw_loss 0.565111 lr 0.00073424 rank 4
2023-02-11 10:53:45,654 DEBUG TRAIN Batch 5/4800 loss 22.880241 loss_att 23.358448 loss_ctc 34.675812 loss_rnnt 18.277927 hw_loss 0.550112 lr 0.00073347 rank 7
2023-02-11 10:53:45,660 DEBUG TRAIN Batch 5/4800 loss 22.755192 loss_att 25.950462 loss_ctc 36.219337 loss_rnnt 18.526337 hw_loss 0.336484 lr 0.00073283 rank 0
2023-02-11 10:53:45,660 DEBUG TRAIN Batch 5/4800 loss 24.231390 loss_att 30.267544 loss_ctc 40.315163 loss_rnnt 19.439724 hw_loss 0.269987 lr 0.00073361 rank 6
2023-02-11 10:53:45,663 DEBUG TRAIN Batch 5/4800 loss 25.407705 loss_att 25.344444 loss_ctc 30.575178 loss_rnnt 22.063530 hw_loss 0.500218 lr 0.00073336 rank 3
2023-02-11 10:53:45,663 DEBUG TRAIN Batch 5/4800 loss 16.815710 loss_att 24.973843 loss_ctc 25.598499 loss_rnnt 11.574141 hw_loss 0.457295 lr 0.00073274 rank 2
2023-02-11 10:53:45,664 DEBUG TRAIN Batch 5/4800 loss 14.788507 loss_att 19.577959 loss_ctc 24.761139 loss_rnnt 10.095039 hw_loss 0.451105 lr 0.00073345 rank 4
2023-02-11 10:53:45,665 DEBUG TRAIN Batch 5/4800 loss 20.075569 loss_att 26.385767 loss_ctc 25.490044 loss_rnnt 16.130327 hw_loss 0.367738 lr 0.00073305 rank 1
2023-02-11 10:53:45,667 DEBUG TRAIN Batch 5/4800 loss 15.737411 loss_att 18.782776 loss_ctc 22.275587 loss_rnnt 12.835353 hw_loss 0.266480 lr 0.00073316 rank 5
2023-02-11 10:55:01,790 DEBUG TRAIN Batch 5/4900 loss 16.643948 loss_att 19.154039 loss_ctc 26.376896 loss_rnnt 12.559649 hw_loss 0.428354 lr 0.00073266 rank 4
2023-02-11 10:55:01,796 DEBUG TRAIN Batch 5/4900 loss 30.051682 loss_att 30.516972 loss_ctc 34.235859 loss_rnnt 26.805260 hw_loss 0.486651 lr 0.00073282 rank 6
2023-02-11 10:55:01,797 DEBUG TRAIN Batch 5/4900 loss 38.813866 loss_att 47.031155 loss_ctc 58.264252 loss_rnnt 33.682953 hw_loss 0.167638 lr 0.00073195 rank 2
2023-02-11 10:55:01,800 DEBUG TRAIN Batch 5/4900 loss 18.086008 loss_att 17.606976 loss_ctc 25.858582 loss_rnnt 15.093044 hw_loss 0.384830 lr 0.00073257 rank 3
2023-02-11 10:55:01,801 DEBUG TRAIN Batch 5/4900 loss 31.574659 loss_att 33.416336 loss_ctc 48.819389 loss_rnnt 27.835327 hw_loss 0.200943 lr 0.00073226 rank 1
2023-02-11 10:55:01,801 DEBUG TRAIN Batch 5/4900 loss 19.251385 loss_att 27.958549 loss_ctc 25.514561 loss_rnnt 15.126110 hw_loss 0.290391 lr 0.00073205 rank 0
2023-02-11 10:55:01,811 DEBUG TRAIN Batch 5/4900 loss 39.015598 loss_att 38.170452 loss_ctc 49.485420 loss_rnnt 36.470650 hw_loss 0.247125 lr 0.00073268 rank 7
2023-02-11 10:55:01,825 DEBUG TRAIN Batch 5/4900 loss 11.938408 loss_att 12.290405 loss_ctc 18.320770 loss_rnnt 8.393463 hw_loss 0.491918 lr 0.00073237 rank 5
2023-02-11 10:56:19,927 DEBUG TRAIN Batch 5/5000 loss 17.220634 loss_att 16.989170 loss_ctc 23.567930 loss_rnnt 13.278121 hw_loss 0.589219 lr 0.00073190 rank 7
2023-02-11 10:56:19,927 DEBUG TRAIN Batch 5/5000 loss 22.227781 loss_att 22.913998 loss_ctc 32.661156 loss_rnnt 17.021225 hw_loss 0.689662 lr 0.00073126 rank 0
2023-02-11 10:56:19,928 DEBUG TRAIN Batch 5/5000 loss 16.840229 loss_att 14.051624 loss_ctc 20.567719 loss_rnnt 12.037617 hw_loss 0.911875 lr 0.00073148 rank 1
2023-02-11 10:56:19,931 DEBUG TRAIN Batch 5/5000 loss 24.033381 loss_att 25.889225 loss_ctc 36.503353 loss_rnnt 19.375746 hw_loss 0.491963 lr 0.00073159 rank 5
2023-02-11 10:56:19,932 DEBUG TRAIN Batch 5/5000 loss 22.349710 loss_att 18.384859 loss_ctc 25.122465 loss_rnnt 16.955366 hw_loss 1.090803 lr 0.00073117 rank 2
2023-02-11 10:56:19,937 DEBUG TRAIN Batch 5/5000 loss 29.440163 loss_att 30.570797 loss_ctc 46.011158 loss_rnnt 23.298141 hw_loss 0.694955 lr 0.00073203 rank 6
2023-02-11 10:56:19,937 DEBUG TRAIN Batch 5/5000 loss 39.289333 loss_att 41.524513 loss_ctc 49.319138 loss_rnnt 34.549816 hw_loss 0.554095 lr 0.00073188 rank 4
2023-02-11 10:56:19,939 DEBUG TRAIN Batch 5/5000 loss 33.792118 loss_att 35.402657 loss_ctc 55.705608 loss_rnnt 27.532070 hw_loss 0.565527 lr 0.00073179 rank 3
2023-02-11 10:57:36,661 DEBUG TRAIN Batch 5/5100 loss 26.164389 loss_att 27.044470 loss_ctc 34.279682 loss_rnnt 21.469763 hw_loss 0.644357 lr 0.00073069 rank 1
2023-02-11 10:57:36,661 DEBUG TRAIN Batch 5/5100 loss 12.760381 loss_att 15.232675 loss_ctc 16.641693 loss_rnnt 10.660518 hw_loss 0.203981 lr 0.00073048 rank 0
2023-02-11 10:57:36,661 DEBUG TRAIN Batch 5/5100 loss 19.151625 loss_att 23.604050 loss_ctc 36.487087 loss_rnnt 13.390852 hw_loss 0.479793 lr 0.00073039 rank 2
2023-02-11 10:57:36,663 DEBUG TRAIN Batch 5/5100 loss 24.988194 loss_att 27.340359 loss_ctc 37.503918 loss_rnnt 20.458265 hw_loss 0.448262 lr 0.00073112 rank 7
2023-02-11 10:57:36,664 DEBUG TRAIN Batch 5/5100 loss 12.052165 loss_att 11.708201 loss_ctc 15.206209 loss_rnnt 7.879263 hw_loss 0.716467 lr 0.00073101 rank 3
2023-02-11 10:57:36,664 DEBUG TRAIN Batch 5/5100 loss 20.572748 loss_att 24.127615 loss_ctc 29.159939 loss_rnnt 16.709288 hw_loss 0.376412 lr 0.00073080 rank 5
2023-02-11 10:57:36,664 DEBUG TRAIN Batch 5/5100 loss 27.216339 loss_att 23.530970 loss_ctc 35.251743 loss_rnnt 22.284645 hw_loss 0.862008 lr 0.00073125 rank 6
2023-02-11 10:57:36,671 DEBUG TRAIN Batch 5/5100 loss 18.572325 loss_att 18.089180 loss_ctc 31.123579 loss_rnnt 15.069211 hw_loss 0.361170 lr 0.00073109 rank 4
2023-02-11 10:58:53,144 DEBUG TRAIN Batch 5/5200 loss 16.764471 loss_att 21.070156 loss_ctc 28.685806 loss_rnnt 13.459704 hw_loss 0.160147 lr 0.00072971 rank 0
2023-02-11 10:58:53,144 DEBUG TRAIN Batch 5/5200 loss 29.845715 loss_att 29.675137 loss_ctc 43.190331 loss_rnnt 25.798527 hw_loss 0.431629 lr 0.00073002 rank 5
2023-02-11 10:58:53,145 DEBUG TRAIN Batch 5/5200 loss 42.414970 loss_att 49.379986 loss_ctc 64.513153 loss_rnnt 36.079952 hw_loss 0.374174 lr 0.00073023 rank 3
2023-02-11 10:58:53,146 DEBUG TRAIN Batch 5/5200 loss 35.445480 loss_att 40.171394 loss_ctc 57.834282 loss_rnnt 29.200043 hw_loss 0.434077 lr 0.00073034 rank 7
2023-02-11 10:58:53,147 DEBUG TRAIN Batch 5/5200 loss 11.884169 loss_att 16.312031 loss_ctc 17.756155 loss_rnnt 9.040741 hw_loss 0.220298 lr 0.00072992 rank 1
2023-02-11 10:58:53,148 DEBUG TRAIN Batch 5/5200 loss 17.255272 loss_att 23.366295 loss_ctc 32.357513 loss_rnnt 13.033408 hw_loss 0.184880 lr 0.00073047 rank 6
2023-02-11 10:58:53,148 DEBUG TRAIN Batch 5/5200 loss 21.564138 loss_att 24.293652 loss_ctc 23.978981 loss_rnnt 18.274479 hw_loss 0.454083 lr 0.00072961 rank 2
2023-02-11 10:58:53,149 DEBUG TRAIN Batch 5/5200 loss 16.609266 loss_att 24.620007 loss_ctc 24.855505 loss_rnnt 13.033420 hw_loss 0.163912 lr 0.00073031 rank 4
2023-02-11 11:00:11,846 DEBUG TRAIN Batch 5/5300 loss 15.792248 loss_att 19.956707 loss_ctc 25.100754 loss_rnnt 12.375290 hw_loss 0.251799 lr 0.00072914 rank 1
2023-02-11 11:00:11,848 DEBUG TRAIN Batch 5/5300 loss 29.433233 loss_att 36.146164 loss_ctc 49.061630 loss_rnnt 22.797626 hw_loss 0.501731 lr 0.00072956 rank 7
2023-02-11 11:00:11,849 DEBUG TRAIN Batch 5/5300 loss 19.916777 loss_att 24.121799 loss_ctc 36.293518 loss_rnnt 13.436899 hw_loss 0.647870 lr 0.00072893 rank 0
2023-02-11 11:00:11,849 DEBUG TRAIN Batch 5/5300 loss 48.152409 loss_att 47.971382 loss_ctc 66.353226 loss_rnnt 40.856583 hw_loss 0.919735 lr 0.00072945 rank 3
2023-02-11 11:00:11,850 DEBUG TRAIN Batch 5/5300 loss 9.619036 loss_att 14.495319 loss_ctc 22.296825 loss_rnnt 5.307488 hw_loss 0.308610 lr 0.00072953 rank 4
2023-02-11 11:00:11,852 DEBUG TRAIN Batch 5/5300 loss 15.090759 loss_att 20.915390 loss_ctc 25.929283 loss_rnnt 8.519127 hw_loss 0.742795 lr 0.00072884 rank 2
2023-02-11 11:00:11,854 DEBUG TRAIN Batch 5/5300 loss 20.656813 loss_att 21.504208 loss_ctc 30.884140 loss_rnnt 18.357168 hw_loss 0.143723 lr 0.00072925 rank 5
2023-02-11 11:00:11,895 DEBUG TRAIN Batch 5/5300 loss 41.780678 loss_att 45.400795 loss_ctc 70.169304 loss_rnnt 34.437683 hw_loss 0.531342 lr 0.00072969 rank 6
2023-02-11 11:01:28,417 DEBUG TRAIN Batch 5/5400 loss 21.607660 loss_att 23.440010 loss_ctc 29.387238 loss_rnnt 18.746883 hw_loss 0.273193 lr 0.00072867 rank 3
2023-02-11 11:01:28,418 DEBUG TRAIN Batch 5/5400 loss 19.470280 loss_att 26.418179 loss_ctc 29.896408 loss_rnnt 14.036685 hw_loss 0.497599 lr 0.00072816 rank 0
2023-02-11 11:01:28,418 DEBUG TRAIN Batch 5/5400 loss 17.229813 loss_att 17.834827 loss_ctc 20.402361 loss_rnnt 11.391951 hw_loss 0.992597 lr 0.00072878 rank 7
2023-02-11 11:01:28,421 DEBUG TRAIN Batch 5/5400 loss 34.263687 loss_att 39.200226 loss_ctc 53.047577 loss_rnnt 27.822407 hw_loss 0.553022 lr 0.00072891 rank 6
2023-02-11 11:01:28,422 DEBUG TRAIN Batch 5/5400 loss 24.119331 loss_att 24.084251 loss_ctc 30.259087 loss_rnnt 19.930244 hw_loss 0.633275 lr 0.00072806 rank 2
2023-02-11 11:01:28,424 DEBUG TRAIN Batch 5/5400 loss 15.918117 loss_att 19.744802 loss_ctc 29.394100 loss_rnnt 11.693321 hw_loss 0.311749 lr 0.00072836 rank 1
2023-02-11 11:01:28,423 DEBUG TRAIN Batch 5/5400 loss 29.640741 loss_att 31.074123 loss_ctc 40.574944 loss_rnnt 25.867821 hw_loss 0.380315 lr 0.00072847 rank 5
2023-02-11 11:01:28,431 DEBUG TRAIN Batch 5/5400 loss 16.506525 loss_att 21.331190 loss_ctc 28.944439 loss_rnnt 12.759108 hw_loss 0.210768 lr 0.00072876 rank 4
2023-02-11 11:02:43,949 DEBUG TRAIN Batch 5/5500 loss 34.856140 loss_att 42.930489 loss_ctc 61.360950 loss_rnnt 27.943439 hw_loss 0.330723 lr 0.00072814 rank 6
2023-02-11 11:02:43,952 DEBUG TRAIN Batch 5/5500 loss 17.767866 loss_att 18.924273 loss_ctc 23.307087 loss_rnnt 10.662632 hw_loss 1.150386 lr 0.00072739 rank 0
2023-02-11 11:02:43,954 DEBUG TRAIN Batch 5/5500 loss 15.047630 loss_att 13.568449 loss_ctc 14.526029 loss_rnnt 11.759130 hw_loss 0.685103 lr 0.00072790 rank 3
2023-02-11 11:02:43,954 DEBUG TRAIN Batch 5/5500 loss 12.685494 loss_att 16.057976 loss_ctc 22.037729 loss_rnnt 8.831717 hw_loss 0.362309 lr 0.00072801 rank 7
2023-02-11 11:02:43,956 DEBUG TRAIN Batch 5/5500 loss 30.427773 loss_att 33.333092 loss_ctc 45.763916 loss_rnnt 25.042610 hw_loss 0.517365 lr 0.00072729 rank 2
2023-02-11 11:02:43,958 DEBUG TRAIN Batch 5/5500 loss 27.750582 loss_att 29.304958 loss_ctc 38.359154 loss_rnnt 24.304630 hw_loss 0.322612 lr 0.00072770 rank 5
2023-02-11 11:02:43,959 DEBUG TRAIN Batch 5/5500 loss 35.151897 loss_att 34.911228 loss_ctc 51.880299 loss_rnnt 31.014111 hw_loss 0.366650 lr 0.00072799 rank 4
2023-02-11 11:02:44,019 DEBUG TRAIN Batch 5/5500 loss 19.607738 loss_att 22.839291 loss_ctc 29.718794 loss_rnnt 15.746083 hw_loss 0.350100 lr 0.00072759 rank 1
2023-02-11 11:04:00,646 DEBUG TRAIN Batch 5/5600 loss 11.611648 loss_att 12.799274 loss_ctc 12.729399 loss_rnnt 7.223593 hw_loss 0.750280 lr 0.00072662 rank 0
2023-02-11 11:04:00,646 DEBUG TRAIN Batch 5/5600 loss 18.564396 loss_att 22.759153 loss_ctc 32.221191 loss_rnnt 15.757576 hw_loss 0.027555 lr 0.00072682 rank 1
2023-02-11 11:04:00,653 DEBUG TRAIN Batch 5/5600 loss 15.132986 loss_att 16.891359 loss_ctc 32.328796 loss_rnnt 10.907146 hw_loss 0.296511 lr 0.00072693 rank 5
2023-02-11 11:04:00,654 DEBUG TRAIN Batch 5/5600 loss 14.137677 loss_att 16.785194 loss_ctc 25.117504 loss_rnnt 11.999261 hw_loss 0.027175 lr 0.00072652 rank 2
2023-02-11 11:04:00,654 DEBUG TRAIN Batch 5/5600 loss 10.932661 loss_att 11.890902 loss_ctc 15.733429 loss_rnnt 8.802529 hw_loss 0.243446 lr 0.00072737 rank 6
2023-02-11 11:04:00,655 DEBUG TRAIN Batch 5/5600 loss 22.712482 loss_att 26.524776 loss_ctc 31.100773 loss_rnnt 18.173834 hw_loss 0.498329 lr 0.00072722 rank 4
2023-02-11 11:04:00,678 DEBUG TRAIN Batch 5/5600 loss 25.292231 loss_att 25.745855 loss_ctc 31.544382 loss_rnnt 21.378157 hw_loss 0.560574 lr 0.00072724 rank 7
2023-02-11 11:04:00,690 DEBUG TRAIN Batch 5/5600 loss 28.906521 loss_att 31.643925 loss_ctc 42.963753 loss_rnnt 24.748077 hw_loss 0.325624 lr 0.00072713 rank 3
2023-02-11 11:05:19,729 DEBUG TRAIN Batch 5/5700 loss 35.434521 loss_att 34.527870 loss_ctc 48.935852 loss_rnnt 30.052307 hw_loss 0.705631 lr 0.00072585 rank 0
2023-02-11 11:05:19,729 DEBUG TRAIN Batch 5/5700 loss 10.848205 loss_att 12.198289 loss_ctc 14.103405 loss_rnnt 7.876316 hw_loss 0.425221 lr 0.00072660 rank 6
2023-02-11 11:05:19,730 DEBUG TRAIN Batch 5/5700 loss 23.932737 loss_att 27.598145 loss_ctc 36.469173 loss_rnnt 19.428265 hw_loss 0.393725 lr 0.00072606 rank 1
2023-02-11 11:05:19,732 DEBUG TRAIN Batch 5/5700 loss 15.927189 loss_att 17.929068 loss_ctc 23.838909 loss_rnnt 12.236495 hw_loss 0.419142 lr 0.00072645 rank 4
2023-02-11 11:05:19,732 DEBUG TRAIN Batch 5/5700 loss 23.527430 loss_att 21.926046 loss_ctc 30.532927 loss_rnnt 19.374001 hw_loss 0.663682 lr 0.00072636 rank 3
2023-02-11 11:05:19,732 DEBUG TRAIN Batch 5/5700 loss 17.958649 loss_att 17.798334 loss_ctc 22.378492 loss_rnnt 15.215210 hw_loss 0.409910 lr 0.00072647 rank 7
2023-02-11 11:05:19,733 DEBUG TRAIN Batch 5/5700 loss 15.518571 loss_att 12.538903 loss_ctc 16.707611 loss_rnnt 11.824283 hw_loss 0.774691 lr 0.00072616 rank 5
2023-02-11 11:05:19,733 DEBUG TRAIN Batch 5/5700 loss 17.035374 loss_att 21.916351 loss_ctc 29.025742 loss_rnnt 13.531193 hw_loss 0.174238 lr 0.00072576 rank 2
2023-02-11 11:06:35,100 DEBUG TRAIN Batch 5/5800 loss 39.951256 loss_att 48.662590 loss_ctc 61.804180 loss_rnnt 33.528851 hw_loss 0.331203 lr 0.00072509 rank 0
2023-02-11 11:06:35,104 DEBUG TRAIN Batch 5/5800 loss 31.176680 loss_att 40.270580 loss_ctc 47.404018 loss_rnnt 26.257942 hw_loss 0.175558 lr 0.00072584 rank 6
2023-02-11 11:06:35,105 DEBUG TRAIN Batch 5/5800 loss 23.659178 loss_att 28.468842 loss_ctc 43.350567 loss_rnnt 18.553450 hw_loss 0.284677 lr 0.00072560 rank 3
2023-02-11 11:06:35,106 DEBUG TRAIN Batch 5/5800 loss 17.432627 loss_att 22.000246 loss_ctc 28.632999 loss_rnnt 11.761318 hw_loss 0.612075 lr 0.00072571 rank 7
2023-02-11 11:06:35,107 DEBUG TRAIN Batch 5/5800 loss 19.576775 loss_att 15.953696 loss_ctc 19.591650 loss_rnnt 14.860029 hw_loss 1.019884 lr 0.00072529 rank 1
2023-02-11 11:06:35,110 DEBUG TRAIN Batch 5/5800 loss 12.990767 loss_att 22.922401 loss_ctc 31.037457 loss_rnnt 7.415543 hw_loss 0.221751 lr 0.00072500 rank 2
2023-02-11 11:06:35,114 DEBUG TRAIN Batch 5/5800 loss 22.049007 loss_att 25.150532 loss_ctc 31.442997 loss_rnnt 18.010693 hw_loss 0.406027 lr 0.00072540 rank 5
2023-02-11 11:06:35,155 DEBUG TRAIN Batch 5/5800 loss 18.773798 loss_att 17.158098 loss_ctc 22.911835 loss_rnnt 12.836279 hw_loss 1.070423 lr 0.00072568 rank 4
2023-02-11 11:07:51,008 DEBUG TRAIN Batch 5/5900 loss 24.613159 loss_att 31.345736 loss_ctc 44.939846 loss_rnnt 19.219372 hw_loss 0.250696 lr 0.00072484 rank 3
2023-02-11 11:07:51,009 DEBUG TRAIN Batch 5/5900 loss 15.342049 loss_att 19.157375 loss_ctc 27.300167 loss_rnnt 10.647800 hw_loss 0.438144 lr 0.00072492 rank 4
2023-02-11 11:07:51,009 DEBUG TRAIN Batch 5/5900 loss 15.518036 loss_att 16.067709 loss_ctc 21.392469 loss_rnnt 11.944405 hw_loss 0.502582 lr 0.00072494 rank 7
2023-02-11 11:07:51,009 DEBUG TRAIN Batch 5/5900 loss 11.481976 loss_att 14.513369 loss_ctc 19.095337 loss_rnnt 6.729809 hw_loss 0.587020 lr 0.00072433 rank 0
2023-02-11 11:07:51,010 DEBUG TRAIN Batch 5/5900 loss 24.416393 loss_att 25.560921 loss_ctc 29.344738 loss_rnnt 20.810841 hw_loss 0.509912 lr 0.00072453 rank 1
2023-02-11 11:07:51,012 DEBUG TRAIN Batch 5/5900 loss 22.774742 loss_att 25.437103 loss_ctc 38.536407 loss_rnnt 18.573919 hw_loss 0.293774 lr 0.00072507 rank 6
2023-02-11 11:07:51,015 DEBUG TRAIN Batch 5/5900 loss 24.092611 loss_att 27.051697 loss_ctc 37.998222 loss_rnnt 20.840603 hw_loss 0.151145 lr 0.00072464 rank 5
2023-02-11 11:07:51,064 DEBUG TRAIN Batch 5/5900 loss 18.427738 loss_att 17.207405 loss_ctc 25.305225 loss_rnnt 14.030895 hw_loss 0.698233 lr 0.00072423 rank 2
2023-02-11 11:09:09,977 DEBUG TRAIN Batch 5/6000 loss 16.268999 loss_att 20.105919 loss_ctc 27.349794 loss_rnnt 11.116708 hw_loss 0.545150 lr 0.00072418 rank 7
2023-02-11 11:09:09,978 DEBUG TRAIN Batch 5/6000 loss 22.427111 loss_att 28.688766 loss_ctc 42.904854 loss_rnnt 15.337207 hw_loss 0.582601 lr 0.00072377 rank 1
2023-02-11 11:09:09,980 DEBUG TRAIN Batch 5/6000 loss 23.177284 loss_att 29.904179 loss_ctc 34.282650 loss_rnnt 19.486576 hw_loss 0.162115 lr 0.00072348 rank 2
2023-02-11 11:09:09,983 DEBUG TRAIN Batch 5/6000 loss 28.908947 loss_att 31.984301 loss_ctc 38.898521 loss_rnnt 23.684984 hw_loss 0.614428 lr 0.00072431 rank 6
2023-02-11 11:09:09,987 DEBUG TRAIN Batch 5/6000 loss 20.788023 loss_att 26.976021 loss_ctc 32.404999 loss_rnnt 16.161022 hw_loss 0.345088 lr 0.00072357 rank 0
2023-02-11 11:09:09,990 DEBUG TRAIN Batch 5/6000 loss 22.215382 loss_att 22.715717 loss_ctc 26.441467 loss_rnnt 18.487097 hw_loss 0.574639 lr 0.00072416 rank 4
2023-02-11 11:09:10,015 DEBUG TRAIN Batch 5/6000 loss 23.241291 loss_att 32.176743 loss_ctc 47.687302 loss_rnnt 16.666122 hw_loss 0.286614 lr 0.00072408 rank 3
2023-02-11 11:09:10,026 DEBUG TRAIN Batch 5/6000 loss 23.015106 loss_att 26.004713 loss_ctc 30.946159 loss_rnnt 18.788746 hw_loss 0.482056 lr 0.00072388 rank 5
2023-02-11 11:10:28,856 DEBUG TRAIN Batch 5/6100 loss 16.894236 loss_att 18.287428 loss_ctc 21.805386 loss_rnnt 14.253231 hw_loss 0.320165 lr 0.00072342 rank 7
2023-02-11 11:10:28,860 DEBUG TRAIN Batch 5/6100 loss 17.636608 loss_att 21.384426 loss_ctc 28.629633 loss_rnnt 12.629118 hw_loss 0.523536 lr 0.00072312 rank 5
2023-02-11 11:10:28,861 DEBUG TRAIN Batch 5/6100 loss 17.298840 loss_att 19.566708 loss_ctc 26.124620 loss_rnnt 15.077595 hw_loss 0.110794 lr 0.00072272 rank 2
2023-02-11 11:10:28,861 DEBUG TRAIN Batch 5/6100 loss 15.195574 loss_att 16.796921 loss_ctc 24.969475 loss_rnnt 10.633749 hw_loss 0.550944 lr 0.00072281 rank 0
2023-02-11 11:10:28,862 DEBUG TRAIN Batch 5/6100 loss 19.353800 loss_att 22.102711 loss_ctc 33.671242 loss_rnnt 15.747631 hw_loss 0.215136 lr 0.00072332 rank 3
2023-02-11 11:10:28,862 DEBUG TRAIN Batch 5/6100 loss 17.699776 loss_att 19.637510 loss_ctc 27.981932 loss_rnnt 14.576487 hw_loss 0.255898 lr 0.00072355 rank 6
2023-02-11 11:10:28,865 DEBUG TRAIN Batch 5/6100 loss 29.179148 loss_att 32.184731 loss_ctc 40.221664 loss_rnnt 25.451925 hw_loss 0.310082 lr 0.00072301 rank 1
2023-02-11 11:10:28,867 DEBUG TRAIN Batch 5/6100 loss 19.317039 loss_att 21.636303 loss_ctc 33.863960 loss_rnnt 13.918551 hw_loss 0.561571 lr 0.00072340 rank 4
2023-02-11 11:11:45,107 DEBUG TRAIN Batch 5/6200 loss 22.457748 loss_att 25.835850 loss_ctc 35.962402 loss_rnnt 17.255806 hw_loss 0.511069 lr 0.00072256 rank 3
2023-02-11 11:11:45,109 DEBUG TRAIN Batch 5/6200 loss 27.634377 loss_att 27.607895 loss_ctc 41.284348 loss_rnnt 22.985352 hw_loss 0.531436 lr 0.00072267 rank 7
2023-02-11 11:11:45,111 DEBUG TRAIN Batch 5/6200 loss 20.057262 loss_att 19.285717 loss_ctc 23.975462 loss_rnnt 17.588545 hw_loss 0.393863 lr 0.00072197 rank 2
2023-02-11 11:11:45,111 DEBUG TRAIN Batch 5/6200 loss 27.532736 loss_att 31.797228 loss_ctc 38.154503 loss_rnnt 22.310293 hw_loss 0.553745 lr 0.00072206 rank 0
2023-02-11 11:11:45,113 DEBUG TRAIN Batch 5/6200 loss 29.199213 loss_att 29.203875 loss_ctc 44.613655 loss_rnnt 24.953960 hw_loss 0.410450 lr 0.00072280 rank 6
2023-02-11 11:11:45,118 DEBUG TRAIN Batch 5/6200 loss 19.630766 loss_att 19.700478 loss_ctc 31.472515 loss_rnnt 16.413441 hw_loss 0.304590 lr 0.00072226 rank 1
2023-02-11 11:11:45,121 DEBUG TRAIN Batch 5/6200 loss 12.392984 loss_att 15.347662 loss_ctc 20.874763 loss_rnnt 8.700027 hw_loss 0.369585 lr 0.00072264 rank 4
2023-02-11 11:11:45,122 DEBUG TRAIN Batch 5/6200 loss 15.947926 loss_att 15.917189 loss_ctc 21.691330 loss_rnnt 11.615022 hw_loss 0.669987 lr 0.00072237 rank 5
2023-02-11 11:13:00,983 DEBUG TRAIN Batch 5/6300 loss 22.517845 loss_att 22.900066 loss_ctc 28.393856 loss_rnnt 17.232473 hw_loss 0.829774 lr 0.00072181 rank 3
2023-02-11 11:13:00,988 DEBUG TRAIN Batch 5/6300 loss 33.917183 loss_att 38.320671 loss_ctc 50.118240 loss_rnnt 26.976599 hw_loss 0.731203 lr 0.00072161 rank 5
2023-02-11 11:13:00,991 DEBUG TRAIN Batch 5/6300 loss 21.044270 loss_att 20.306530 loss_ctc 31.326460 loss_rnnt 16.007250 hw_loss 0.715051 lr 0.00072151 rank 1
2023-02-11 11:13:00,993 DEBUG TRAIN Batch 5/6300 loss 19.644600 loss_att 19.467283 loss_ctc 28.119865 loss_rnnt 15.672643 hw_loss 0.539510 lr 0.00072191 rank 7
2023-02-11 11:13:00,992 DEBUG TRAIN Batch 5/6300 loss 16.404497 loss_att 16.572437 loss_ctc 19.765385 loss_rnnt 12.682814 hw_loss 0.607496 lr 0.00072130 rank 0
2023-02-11 11:13:00,995 DEBUG TRAIN Batch 5/6300 loss 32.642139 loss_att 34.952721 loss_ctc 47.914936 loss_rnnt 25.396301 hw_loss 0.890127 lr 0.00072189 rank 4
2023-02-11 11:13:00,996 DEBUG TRAIN Batch 5/6300 loss 17.322336 loss_att 15.033739 loss_ctc 22.191809 loss_rnnt 12.918818 hw_loss 0.789745 lr 0.00072121 rank 2
2023-02-11 11:13:00,995 DEBUG TRAIN Batch 5/6300 loss 16.248837 loss_att 18.544531 loss_ctc 21.736723 loss_rnnt 11.275931 hw_loss 0.709134 lr 0.00072204 rank 6
2023-02-11 11:14:20,588 DEBUG TRAIN Batch 5/6400 loss 21.794588 loss_att 18.855728 loss_ctc 27.562828 loss_rnnt 18.530676 hw_loss 0.577985 lr 0.00072056 rank 0
2023-02-11 11:14:20,588 DEBUG TRAIN Batch 5/6400 loss 19.469677 loss_att 20.297058 loss_ctc 26.054945 loss_rnnt 14.872057 hw_loss 0.666395 lr 0.00072106 rank 3
2023-02-11 11:14:20,594 DEBUG TRAIN Batch 5/6400 loss 26.901665 loss_att 32.427277 loss_ctc 47.025116 loss_rnnt 20.478722 hw_loss 0.494005 lr 0.00072086 rank 5
2023-02-11 11:14:20,597 DEBUG TRAIN Batch 5/6400 loss 24.993900 loss_att 25.928242 loss_ctc 31.677582 loss_rnnt 20.411371 hw_loss 0.657094 lr 0.00072114 rank 4
2023-02-11 11:14:20,598 DEBUG TRAIN Batch 5/6400 loss 19.264900 loss_att 13.723071 loss_ctc 15.733296 loss_rnnt 13.286091 hw_loss 1.417135 lr 0.00072076 rank 1
2023-02-11 11:14:20,600 DEBUG TRAIN Batch 5/6400 loss 38.781883 loss_att 38.624542 loss_ctc 68.349876 loss_rnnt 32.163044 hw_loss 0.507733 lr 0.00072047 rank 2
2023-02-11 11:14:20,602 DEBUG TRAIN Batch 5/6400 loss 13.687929 loss_att 16.366323 loss_ctc 19.122761 loss_rnnt 10.337581 hw_loss 0.391880 lr 0.00072116 rank 7
2023-02-11 11:14:20,602 DEBUG TRAIN Batch 5/6400 loss 21.695450 loss_att 24.897530 loss_ctc 25.878315 loss_rnnt 16.347889 hw_loss 0.778018 lr 0.00072129 rank 6
2023-02-11 11:15:35,258 DEBUG TRAIN Batch 5/6500 loss 25.189337 loss_att 24.993813 loss_ctc 35.288887 loss_rnnt 20.410585 hw_loss 0.650859 lr 0.00071981 rank 0
2023-02-11 11:15:35,263 DEBUG TRAIN Batch 5/6500 loss 12.492576 loss_att 18.555275 loss_ctc 20.516834 loss_rnnt 9.201977 hw_loss 0.189029 lr 0.00071972 rank 2
2023-02-11 11:15:35,264 DEBUG TRAIN Batch 5/6500 loss 41.681568 loss_att 44.352894 loss_ctc 61.341537 loss_rnnt 36.519814 hw_loss 0.376155 lr 0.00072041 rank 7
2023-02-11 11:15:35,266 DEBUG TRAIN Batch 5/6500 loss 32.672001 loss_att 36.731030 loss_ctc 42.340919 loss_rnnt 28.616394 hw_loss 0.366490 lr 0.00072011 rank 5
2023-02-11 11:15:35,267 DEBUG TRAIN Batch 5/6500 loss 25.094141 loss_att 31.020298 loss_ctc 37.332272 loss_rnnt 21.485508 hw_loss 0.148434 lr 0.00072039 rank 4
2023-02-11 11:15:35,267 DEBUG TRAIN Batch 5/6500 loss 23.770081 loss_att 30.120663 loss_ctc 35.883484 loss_rnnt 18.282745 hw_loss 0.487893 lr 0.00072031 rank 3
2023-02-11 11:15:35,273 DEBUG TRAIN Batch 5/6500 loss 20.744827 loss_att 26.245800 loss_ctc 34.594143 loss_rnnt 16.356358 hw_loss 0.270318 lr 0.00072001 rank 1
2023-02-11 11:15:35,318 DEBUG TRAIN Batch 5/6500 loss 15.198938 loss_att 16.509518 loss_ctc 17.403828 loss_rnnt 10.485198 hw_loss 0.779557 lr 0.00072054 rank 6
2023-02-11 11:16:51,276 DEBUG TRAIN Batch 5/6600 loss 16.586214 loss_att 16.608582 loss_ctc 20.993229 loss_rnnt 11.790950 hw_loss 0.788098 lr 0.00071956 rank 3
2023-02-11 11:16:51,276 DEBUG TRAIN Batch 5/6600 loss 14.417431 loss_att 17.662510 loss_ctc 20.066336 loss_rnnt 10.964298 hw_loss 0.384549 lr 0.00071967 rank 7
2023-02-11 11:16:51,276 DEBUG TRAIN Batch 5/6600 loss 14.249273 loss_att 19.792027 loss_ctc 27.818653 loss_rnnt 10.053033 hw_loss 0.239707 lr 0.00071906 rank 0
2023-02-11 11:16:51,277 DEBUG TRAIN Batch 5/6600 loss 9.628877 loss_att 16.092007 loss_ctc 16.388493 loss_rnnt 6.752725 hw_loss 0.127921 lr 0.00071979 rank 6
2023-02-11 11:16:51,278 DEBUG TRAIN Batch 5/6600 loss 17.877865 loss_att 22.872442 loss_ctc 31.094196 loss_rnnt 13.099257 hw_loss 0.378284 lr 0.00071897 rank 2
2023-02-11 11:16:51,278 DEBUG TRAIN Batch 5/6600 loss 29.357199 loss_att 36.083191 loss_ctc 47.960567 loss_rnnt 24.710865 hw_loss 0.153878 lr 0.00071937 rank 5
2023-02-11 11:16:51,279 DEBUG TRAIN Batch 5/6600 loss 35.342606 loss_att 37.228924 loss_ctc 45.803558 loss_rnnt 31.404358 hw_loss 0.406161 lr 0.00071964 rank 4
2023-02-11 11:16:51,279 DEBUG TRAIN Batch 5/6600 loss 19.020615 loss_att 20.103106 loss_ctc 33.028648 loss_rnnt 15.322642 hw_loss 0.302576 lr 0.00071926 rank 1
2023-02-11 11:18:07,889 DEBUG TRAIN Batch 5/6700 loss 21.895187 loss_att 22.520863 loss_ctc 28.796108 loss_rnnt 18.345982 hw_loss 0.469490 lr 0.00071832 rank 0
2023-02-11 11:18:07,891 DEBUG TRAIN Batch 5/6700 loss 17.544870 loss_att 22.650650 loss_ctc 27.392643 loss_rnnt 13.090883 hw_loss 0.397461 lr 0.00071892 rank 7
2023-02-11 11:18:07,897 DEBUG TRAIN Batch 5/6700 loss 28.167328 loss_att 31.345585 loss_ctc 37.670967 loss_rnnt 25.348719 hw_loss 0.171714 lr 0.00071863 rank 5
2023-02-11 11:18:07,897 DEBUG TRAIN Batch 5/6700 loss 9.146080 loss_att 10.790703 loss_ctc 15.824272 loss_rnnt 6.119668 hw_loss 0.338824 lr 0.00071890 rank 4
2023-02-11 11:18:07,897 DEBUG TRAIN Batch 5/6700 loss 16.073252 loss_att 17.905163 loss_ctc 22.216810 loss_rnnt 8.903383 hw_loss 1.122065 lr 0.00071823 rank 2
2023-02-11 11:18:07,900 DEBUG TRAIN Batch 5/6700 loss 29.213104 loss_att 29.343971 loss_ctc 37.146572 loss_rnnt 23.409840 hw_loss 0.884868 lr 0.00071882 rank 3
2023-02-11 11:18:07,923 DEBUG TRAIN Batch 5/6700 loss 16.457417 loss_att 19.672293 loss_ctc 27.301640 loss_rnnt 12.302540 hw_loss 0.387376 lr 0.00071905 rank 6
2023-02-11 11:18:07,947 DEBUG TRAIN Batch 5/6700 loss 12.658924 loss_att 16.581497 loss_ctc 16.900135 loss_rnnt 7.669342 hw_loss 0.682420 lr 0.00071852 rank 1
2023-02-11 11:19:25,660 DEBUG TRAIN Batch 5/6800 loss 21.047623 loss_att 20.338655 loss_ctc 25.079605 loss_rnnt 16.901398 hw_loss 0.703204 lr 0.00071808 rank 3
2023-02-11 11:19:25,663 DEBUG TRAIN Batch 5/6800 loss 38.724258 loss_att 39.160591 loss_ctc 63.497993 loss_rnnt 32.000885 hw_loss 0.624926 lr 0.00071818 rank 7
2023-02-11 11:19:25,665 DEBUG TRAIN Batch 5/6800 loss 19.932512 loss_att 23.867939 loss_ctc 28.586716 loss_rnnt 16.452255 hw_loss 0.288615 lr 0.00071749 rank 2
2023-02-11 11:19:25,665 DEBUG TRAIN Batch 5/6800 loss 22.646324 loss_att 30.927719 loss_ctc 37.709045 loss_rnnt 14.992182 hw_loss 0.748031 lr 0.00071758 rank 0
2023-02-11 11:19:25,668 DEBUG TRAIN Batch 5/6800 loss 36.077541 loss_att 40.759018 loss_ctc 59.629417 loss_rnnt 28.366913 hw_loss 0.681390 lr 0.00071788 rank 5
2023-02-11 11:19:25,669 DEBUG TRAIN Batch 5/6800 loss 25.692984 loss_att 28.375235 loss_ctc 36.250732 loss_rnnt 20.694786 hw_loss 0.572634 lr 0.00071778 rank 1
2023-02-11 11:19:25,670 DEBUG TRAIN Batch 5/6800 loss 11.570625 loss_att 13.816084 loss_ctc 17.744755 loss_rnnt 8.458717 hw_loss 0.344925 lr 0.00071816 rank 4
2023-02-11 11:19:25,671 DEBUG TRAIN Batch 5/6800 loss 28.765858 loss_att 29.189011 loss_ctc 36.835808 loss_rnnt 25.203701 hw_loss 0.450288 lr 0.00071831 rank 6
2023-02-11 11:20:42,485 DEBUG TRAIN Batch 5/6900 loss 23.813133 loss_att 21.921396 loss_ctc 27.526443 loss_rnnt 21.279064 hw_loss 0.453245 lr 0.00071734 rank 3
2023-02-11 11:20:42,490 DEBUG TRAIN Batch 5/6900 loss 19.188734 loss_att 16.305241 loss_ctc 21.326368 loss_rnnt 13.389280 hw_loss 1.142088 lr 0.00071675 rank 2
2023-02-11 11:20:42,491 DEBUG TRAIN Batch 5/6900 loss 23.968290 loss_att 30.204212 loss_ctc 42.311371 loss_rnnt 18.688652 hw_loss 0.297508 lr 0.00071757 rank 6
2023-02-11 11:20:42,492 DEBUG TRAIN Batch 5/6900 loss 19.808405 loss_att 22.717255 loss_ctc 25.910795 loss_rnnt 15.467617 hw_loss 0.552256 lr 0.00071684 rank 0
2023-02-11 11:20:42,495 DEBUG TRAIN Batch 5/6900 loss 26.779316 loss_att 28.542305 loss_ctc 46.234661 loss_rnnt 21.475443 hw_loss 0.441981 lr 0.00071744 rank 7
2023-02-11 11:20:42,496 DEBUG TRAIN Batch 5/6900 loss 27.685278 loss_att 30.044846 loss_ctc 37.780243 loss_rnnt 23.359476 hw_loss 0.470229 lr 0.00071715 rank 5
2023-02-11 11:20:42,496 DEBUG TRAIN Batch 5/6900 loss 18.167807 loss_att 21.211578 loss_ctc 26.763721 loss_rnnt 14.630990 hw_loss 0.334114 lr 0.00071742 rank 4
2023-02-11 11:20:42,496 DEBUG TRAIN Batch 5/6900 loss 14.557592 loss_att 17.081758 loss_ctc 23.086765 loss_rnnt 11.219544 hw_loss 0.317999 lr 0.00071704 rank 1
2023-02-11 11:21:58,028 DEBUG TRAIN Batch 5/7000 loss 29.373531 loss_att 35.104828 loss_ctc 48.594997 loss_rnnt 24.119612 hw_loss 0.289650 lr 0.00071611 rank 0
2023-02-11 11:21:58,031 DEBUG TRAIN Batch 5/7000 loss 20.078171 loss_att 26.656139 loss_ctc 29.829212 loss_rnnt 16.536636 hw_loss 0.173588 lr 0.00071602 rank 2
2023-02-11 11:21:58,034 DEBUG TRAIN Batch 5/7000 loss 20.783699 loss_att 20.789307 loss_ctc 28.634779 loss_rnnt 16.599794 hw_loss 0.587995 lr 0.00071660 rank 3
2023-02-11 11:21:58,034 DEBUG TRAIN Batch 5/7000 loss 19.901138 loss_att 21.339231 loss_ctc 27.847427 loss_rnnt 15.440905 hw_loss 0.583708 lr 0.00071641 rank 5
2023-02-11 11:21:58,035 DEBUG TRAIN Batch 5/7000 loss 18.331165 loss_att 14.048753 loss_ctc 18.769289 loss_rnnt 13.169479 hw_loss 1.117453 lr 0.00071670 rank 7
2023-02-11 11:21:58,035 DEBUG TRAIN Batch 5/7000 loss 17.119530 loss_att 16.520325 loss_ctc 20.742140 loss_rnnt 13.265945 hw_loss 0.654452 lr 0.00071631 rank 1
2023-02-11 11:21:58,036 DEBUG TRAIN Batch 5/7000 loss 22.735279 loss_att 24.901775 loss_ctc 35.144993 loss_rnnt 16.986374 hw_loss 0.686433 lr 0.00071668 rank 4
2023-02-11 11:21:58,072 DEBUG TRAIN Batch 5/7000 loss 19.771906 loss_att 20.817104 loss_ctc 29.488037 loss_rnnt 16.058689 hw_loss 0.414130 lr 0.00071683 rank 6
2023-02-11 11:23:17,178 DEBUG TRAIN Batch 5/7100 loss 14.096302 loss_att 21.183210 loss_ctc 21.098442 loss_rnnt 10.710128 hw_loss 0.194095 lr 0.00071587 rank 3
2023-02-11 11:23:17,181 DEBUG TRAIN Batch 5/7100 loss 33.322384 loss_att 42.252907 loss_ctc 51.002968 loss_rnnt 27.993191 hw_loss 0.222315 lr 0.00071597 rank 7
2023-02-11 11:23:17,185 DEBUG TRAIN Batch 5/7100 loss 18.779043 loss_att 24.336094 loss_ctc 32.603569 loss_rnnt 15.344862 hw_loss 0.089907 lr 0.00071567 rank 5
2023-02-11 11:23:17,186 DEBUG TRAIN Batch 5/7100 loss 17.893658 loss_att 20.621080 loss_ctc 26.130026 loss_rnnt 13.221388 hw_loss 0.567863 lr 0.00071529 rank 2
2023-02-11 11:23:17,187 DEBUG TRAIN Batch 5/7100 loss 20.809509 loss_att 24.451767 loss_ctc 39.917789 loss_rnnt 15.271792 hw_loss 0.424030 lr 0.00071609 rank 6
2023-02-11 11:23:17,191 DEBUG TRAIN Batch 5/7100 loss 14.674103 loss_att 14.810446 loss_ctc 19.965248 loss_rnnt 10.921059 hw_loss 0.566304 lr 0.00071595 rank 4
2023-02-11 11:23:17,196 DEBUG TRAIN Batch 5/7100 loss 38.448837 loss_att 40.275040 loss_ctc 52.583305 loss_rnnt 35.725571 hw_loss 0.088768 lr 0.00071537 rank 0
2023-02-11 11:23:17,215 DEBUG TRAIN Batch 5/7100 loss 12.308640 loss_att 16.426453 loss_ctc 22.458847 loss_rnnt 9.365918 hw_loss 0.143587 lr 0.00071557 rank 1
2023-02-11 11:24:33,464 DEBUG TRAIN Batch 5/7200 loss 33.206676 loss_att 39.138039 loss_ctc 56.324017 loss_rnnt 27.630486 hw_loss 0.245176 lr 0.00071464 rank 0
2023-02-11 11:24:33,468 DEBUG TRAIN Batch 5/7200 loss 16.354561 loss_att 19.853420 loss_ctc 25.136185 loss_rnnt 10.935745 hw_loss 0.665280 lr 0.00071521 rank 4
2023-02-11 11:24:33,471 DEBUG TRAIN Batch 5/7200 loss 15.950599 loss_att 20.887077 loss_ctc 23.168686 loss_rnnt 11.058421 hw_loss 0.551713 lr 0.00071513 rank 3
2023-02-11 11:24:33,471 DEBUG TRAIN Batch 5/7200 loss 18.229656 loss_att 22.995506 loss_ctc 25.309132 loss_rnnt 15.075889 hw_loss 0.235625 lr 0.00071494 rank 5
2023-02-11 11:24:33,471 DEBUG TRAIN Batch 5/7200 loss 16.518906 loss_att 22.495125 loss_ctc 34.128151 loss_rnnt 12.826193 hw_loss 0.028044 lr 0.00071456 rank 2
2023-02-11 11:24:33,472 DEBUG TRAIN Batch 5/7200 loss 27.476078 loss_att 32.706104 loss_ctc 44.598293 loss_rnnt 23.285736 hw_loss 0.161508 lr 0.00071536 rank 6
2023-02-11 11:24:33,472 DEBUG TRAIN Batch 5/7200 loss 21.328371 loss_att 18.931204 loss_ctc 27.593826 loss_rnnt 18.479576 hw_loss 0.467407 lr 0.00071524 rank 7
2023-02-11 11:24:33,514 DEBUG TRAIN Batch 5/7200 loss 17.469517 loss_att 20.238726 loss_ctc 25.839636 loss_rnnt 12.888049 hw_loss 0.545927 lr 0.00071484 rank 1
2023-02-11 11:25:50,303 DEBUG TRAIN Batch 5/7300 loss 21.084345 loss_att 22.577431 loss_ctc 31.467350 loss_rnnt 17.438015 hw_loss 0.368121 lr 0.00071450 rank 7
2023-02-11 11:25:50,303 DEBUG TRAIN Batch 5/7300 loss 15.364081 loss_att 15.633299 loss_ctc 23.492809 loss_rnnt 11.531592 hw_loss 0.505278 lr 0.00071448 rank 4
2023-02-11 11:25:50,304 DEBUG TRAIN Batch 5/7300 loss 35.542297 loss_att 40.266685 loss_ctc 52.538788 loss_rnnt 30.487226 hw_loss 0.345749 lr 0.00071440 rank 3
2023-02-11 11:25:50,305 DEBUG TRAIN Batch 5/7300 loss 22.937466 loss_att 24.682796 loss_ctc 35.623985 loss_rnnt 18.236841 hw_loss 0.498754 lr 0.00071383 rank 2
2023-02-11 11:25:50,307 DEBUG TRAIN Batch 5/7300 loss 25.420881 loss_att 26.866783 loss_ctc 36.837955 loss_rnnt 21.481245 hw_loss 0.399033 lr 0.00071391 rank 0
2023-02-11 11:25:50,308 DEBUG TRAIN Batch 5/7300 loss 20.276827 loss_att 22.612694 loss_ctc 28.554794 loss_rnnt 14.771534 hw_loss 0.737698 lr 0.00071463 rank 6
2023-02-11 11:25:50,309 DEBUG TRAIN Batch 5/7300 loss 15.864084 loss_att 18.014488 loss_ctc 19.404224 loss_rnnt 11.476768 hw_loss 0.653479 lr 0.00071421 rank 5
2023-02-11 11:25:50,310 DEBUG TRAIN Batch 5/7300 loss 28.812321 loss_att 30.610123 loss_ctc 41.610443 loss_rnnt 25.228285 hw_loss 0.284636 lr 0.00071411 rank 1
2023-02-11 11:27:07,575 DEBUG TRAIN Batch 5/7400 loss 29.129580 loss_att 28.940971 loss_ctc 44.176430 loss_rnnt 23.280609 hw_loss 0.727583 lr 0.00071319 rank 0
2023-02-11 11:27:07,577 DEBUG TRAIN Batch 5/7400 loss 20.754667 loss_att 26.553595 loss_ctc 36.060562 loss_rnnt 13.694355 hw_loss 0.723701 lr 0.00071367 rank 3
2023-02-11 11:27:07,578 DEBUG TRAIN Batch 5/7400 loss 27.855213 loss_att 32.393932 loss_ctc 48.752228 loss_rnnt 22.712212 hw_loss 0.271686 lr 0.00071375 rank 4
2023-02-11 11:27:07,582 DEBUG TRAIN Batch 5/7400 loss 18.428610 loss_att 20.627502 loss_ctc 31.059349 loss_rnnt 13.608313 hw_loss 0.505579 lr 0.00071349 rank 5
2023-02-11 11:27:07,582 DEBUG TRAIN Batch 5/7400 loss 25.782425 loss_att 28.072567 loss_ctc 39.349670 loss_rnnt 20.629164 hw_loss 0.541175 lr 0.00071390 rank 6
2023-02-11 11:27:07,585 DEBUG TRAIN Batch 5/7400 loss 18.251602 loss_att 20.507231 loss_ctc 28.781818 loss_rnnt 14.328195 hw_loss 0.387797 lr 0.00071378 rank 7
2023-02-11 11:27:07,611 DEBUG TRAIN Batch 5/7400 loss 29.003256 loss_att 31.035566 loss_ctc 42.643684 loss_rnnt 23.543648 hw_loss 0.606454 lr 0.00071310 rank 2
2023-02-11 11:27:07,619 DEBUG TRAIN Batch 5/7400 loss 34.117195 loss_att 36.094620 loss_ctc 58.595303 loss_rnnt 28.568544 hw_loss 0.354266 lr 0.00071338 rank 1
2023-02-11 11:28:25,909 DEBUG TRAIN Batch 5/7500 loss 12.131699 loss_att 12.653217 loss_ctc 16.886541 loss_rnnt 8.891651 hw_loss 0.469081 lr 0.00071246 rank 0
2023-02-11 11:28:25,909 DEBUG TRAIN Batch 5/7500 loss 27.716146 loss_att 31.760160 loss_ctc 42.162460 loss_rnnt 23.975986 hw_loss 0.188471 lr 0.00071303 rank 4
2023-02-11 11:28:25,910 DEBUG TRAIN Batch 5/7500 loss 16.893059 loss_att 19.897110 loss_ctc 29.310562 loss_rnnt 11.991337 hw_loss 0.495983 lr 0.00071305 rank 7
2023-02-11 11:28:25,911 DEBUG TRAIN Batch 5/7500 loss 17.812426 loss_att 19.865831 loss_ctc 26.353745 loss_rnnt 14.602068 hw_loss 0.311406 lr 0.00071238 rank 2
2023-02-11 11:28:25,912 DEBUG TRAIN Batch 5/7500 loss 32.104218 loss_att 34.235657 loss_ctc 41.675869 loss_rnnt 28.152218 hw_loss 0.421779 lr 0.00071317 rank 6
2023-02-11 11:28:25,912 DEBUG TRAIN Batch 5/7500 loss 21.745554 loss_att 30.610065 loss_ctc 45.343315 loss_rnnt 14.825797 hw_loss 0.375091 lr 0.00071295 rank 3
2023-02-11 11:28:25,913 DEBUG TRAIN Batch 5/7500 loss 21.673876 loss_att 22.632208 loss_ctc 27.297897 loss_rnnt 18.619097 hw_loss 0.396233 lr 0.00071276 rank 5
2023-02-11 11:28:25,915 DEBUG TRAIN Batch 5/7500 loss 20.013317 loss_att 21.674891 loss_ctc 28.183117 loss_rnnt 13.783240 hw_loss 0.901586 lr 0.00071266 rank 1
2023-02-11 11:29:43,267 DEBUG TRAIN Batch 5/7600 loss 23.072378 loss_att 24.959084 loss_ctc 32.863693 loss_rnnt 17.681879 hw_loss 0.695184 lr 0.00071230 rank 4
2023-02-11 11:29:43,267 DEBUG TRAIN Batch 5/7600 loss 15.950408 loss_att 17.608143 loss_ctc 24.917927 loss_rnnt 10.756090 hw_loss 0.687581 lr 0.00071174 rank 0
2023-02-11 11:29:43,267 DEBUG TRAIN Batch 5/7600 loss 27.615995 loss_att 25.153969 loss_ctc 38.923901 loss_rnnt 21.869961 hw_loss 0.887010 lr 0.00071245 rank 6
2023-02-11 11:29:43,268 DEBUG TRAIN Batch 5/7600 loss 17.532784 loss_att 20.964520 loss_ctc 28.615705 loss_rnnt 12.227534 hw_loss 0.588971 lr 0.00071222 rank 3
2023-02-11 11:29:43,269 DEBUG TRAIN Batch 5/7600 loss 20.404991 loss_att 22.831459 loss_ctc 31.299564 loss_rnnt 15.795265 hw_loss 0.500966 lr 0.00071204 rank 5
2023-02-11 11:29:43,271 DEBUG TRAIN Batch 5/7600 loss 21.156136 loss_att 18.480389 loss_ctc 28.113377 loss_rnnt 15.853106 hw_loss 0.920728 lr 0.00071233 rank 7
2023-02-11 11:29:43,272 DEBUG TRAIN Batch 5/7600 loss 20.726496 loss_att 21.029825 loss_ctc 27.028131 loss_rnnt 17.412380 hw_loss 0.452481 lr 0.00071194 rank 1
2023-02-11 11:29:43,274 DEBUG TRAIN Batch 5/7600 loss 13.357396 loss_att 16.601105 loss_ctc 17.572939 loss_rnnt 9.657301 hw_loss 0.466740 lr 0.00071165 rank 2
2023-02-11 11:30:58,370 DEBUG TRAIN Batch 5/7700 loss 17.484581 loss_att 17.678612 loss_ctc 23.174097 loss_rnnt 12.933591 hw_loss 0.703797 lr 0.00071150 rank 3
2023-02-11 11:30:58,371 DEBUG TRAIN Batch 5/7700 loss 22.882942 loss_att 27.186001 loss_ctc 45.588654 loss_rnnt 18.485279 hw_loss 0.095555 lr 0.00071173 rank 6
2023-02-11 11:30:58,372 DEBUG TRAIN Batch 5/7700 loss 27.130600 loss_att 33.454601 loss_ctc 38.473465 loss_rnnt 23.247566 hw_loss 0.207347 lr 0.00071122 rank 1
2023-02-11 11:30:58,374 DEBUG TRAIN Batch 5/7700 loss 13.891578 loss_att 17.767439 loss_ctc 26.194607 loss_rnnt 10.473405 hw_loss 0.187987 lr 0.00071093 rank 2
2023-02-11 11:30:58,376 DEBUG TRAIN Batch 5/7700 loss 10.095114 loss_att 8.041764 loss_ctc 8.898374 loss_rnnt 6.180832 hw_loss 0.840847 lr 0.00071102 rank 0
2023-02-11 11:30:58,377 DEBUG TRAIN Batch 5/7700 loss 25.879284 loss_att 27.374371 loss_ctc 36.807014 loss_rnnt 22.965321 hw_loss 0.217109 lr 0.00071160 rank 7
2023-02-11 11:30:58,378 DEBUG TRAIN Batch 5/7700 loss 13.514658 loss_att 12.809608 loss_ctc 16.099112 loss_rnnt 9.251433 hw_loss 0.761183 lr 0.00071132 rank 5
2023-02-11 11:30:58,381 DEBUG TRAIN Batch 5/7700 loss 17.624260 loss_att 20.610367 loss_ctc 28.340092 loss_rnnt 14.531321 hw_loss 0.200051 lr 0.00071158 rank 4
2023-02-11 11:32:16,659 DEBUG TRAIN Batch 5/7800 loss 17.303970 loss_att 17.865898 loss_ctc 27.077641 loss_rnnt 13.702433 hw_loss 0.409874 lr 0.00071088 rank 7
2023-02-11 11:32:16,660 DEBUG TRAIN Batch 5/7800 loss 15.595854 loss_att 17.786186 loss_ctc 24.327209 loss_rnnt 11.389166 hw_loss 0.488333 lr 0.00071030 rank 0
2023-02-11 11:32:16,666 DEBUG TRAIN Batch 5/7800 loss 19.936562 loss_att 26.314894 loss_ctc 37.015469 loss_rnnt 14.395973 hw_loss 0.372700 lr 0.00071101 rank 6
2023-02-11 11:32:16,666 DEBUG TRAIN Batch 5/7800 loss 20.137421 loss_att 26.564796 loss_ctc 32.560059 loss_rnnt 16.205027 hw_loss 0.185731 lr 0.00071078 rank 3
2023-02-11 11:32:16,668 DEBUG TRAIN Batch 5/7800 loss 23.272629 loss_att 33.039211 loss_ctc 36.206657 loss_rnnt 15.939738 hw_loss 0.685320 lr 0.00071086 rank 4
2023-02-11 11:32:16,670 DEBUG TRAIN Batch 5/7800 loss 28.137959 loss_att 32.004456 loss_ctc 39.084927 loss_rnnt 24.464561 hw_loss 0.270094 lr 0.00071060 rank 5
2023-02-11 11:32:16,670 DEBUG TRAIN Batch 5/7800 loss 12.854452 loss_att 14.900907 loss_ctc 16.896191 loss_rnnt 9.028711 hw_loss 0.539541 lr 0.00071022 rank 2
2023-02-11 11:32:16,670 DEBUG TRAIN Batch 5/7800 loss 17.022425 loss_att 19.212994 loss_ctc 28.461697 loss_rnnt 13.127833 hw_loss 0.362108 lr 0.00071050 rank 1
2023-02-11 11:33:33,920 DEBUG TRAIN Batch 5/7900 loss 17.135082 loss_att 20.475832 loss_ctc 26.033096 loss_rnnt 12.642734 hw_loss 0.494587 lr 0.00071017 rank 7
2023-02-11 11:33:33,923 DEBUG TRAIN Batch 5/7900 loss 24.660528 loss_att 24.840254 loss_ctc 37.989182 loss_rnnt 21.210377 hw_loss 0.306947 lr 0.00071007 rank 3
2023-02-11 11:33:33,924 DEBUG TRAIN Batch 5/7900 loss 37.748764 loss_att 43.494762 loss_ctc 59.932518 loss_rnnt 32.591850 hw_loss 0.196853 lr 0.00070959 rank 0
2023-02-11 11:33:33,928 DEBUG TRAIN Batch 5/7900 loss 17.266169 loss_att 21.174042 loss_ctc 28.771814 loss_rnnt 14.088280 hw_loss 0.161667 lr 0.00070950 rank 2
2023-02-11 11:33:33,929 DEBUG TRAIN Batch 5/7900 loss 17.812540 loss_att 19.160107 loss_ctc 26.222675 loss_rnnt 13.970897 hw_loss 0.459521 lr 0.00070988 rank 5
2023-02-11 11:33:33,930 DEBUG TRAIN Batch 5/7900 loss 17.557629 loss_att 23.934214 loss_ctc 24.496859 loss_rnnt 13.324424 hw_loss 0.381123 lr 0.00071029 rank 6
2023-02-11 11:33:33,930 DEBUG TRAIN Batch 5/7900 loss 21.194698 loss_att 26.728363 loss_ctc 33.794853 loss_rnnt 16.650896 hw_loss 0.329447 lr 0.00070978 rank 1
2023-02-11 11:33:33,936 DEBUG TRAIN Batch 5/7900 loss 15.972446 loss_att 21.952171 loss_ctc 22.701851 loss_rnnt 10.680655 hw_loss 0.599736 lr 0.00071015 rank 4
2023-02-11 11:34:50,743 DEBUG TRAIN Batch 5/8000 loss 13.445375 loss_att 17.269749 loss_ctc 21.680939 loss_rnnt 6.909621 hw_loss 0.876151 lr 0.00070887 rank 0
2023-02-11 11:34:50,746 DEBUG TRAIN Batch 5/8000 loss 44.640026 loss_att 53.641495 loss_ctc 58.727837 loss_rnnt 35.655434 hw_loss 0.994861 lr 0.00070907 rank 1
2023-02-11 11:34:50,751 DEBUG TRAIN Batch 5/8000 loss 18.882404 loss_att 20.242271 loss_ctc 27.367804 loss_rnnt 12.810333 hw_loss 0.875383 lr 0.00070935 rank 3
2023-02-11 11:34:50,751 DEBUG TRAIN Batch 5/8000 loss 18.328211 loss_att 22.640776 loss_ctc 30.234821 loss_rnnt 14.338184 hw_loss 0.288743 lr 0.00070879 rank 2
2023-02-11 11:34:50,752 DEBUG TRAIN Batch 5/8000 loss 23.520605 loss_att 22.732344 loss_ctc 31.917330 loss_rnnt 19.501675 hw_loss 0.573191 lr 0.00070945 rank 7
2023-02-11 11:34:50,753 DEBUG TRAIN Batch 5/8000 loss 18.264853 loss_att 23.776974 loss_ctc 29.827118 loss_rnnt 13.893208 hw_loss 0.323922 lr 0.00070957 rank 6
2023-02-11 11:34:50,754 DEBUG TRAIN Batch 5/8000 loss 18.013367 loss_att 21.951633 loss_ctc 26.841412 loss_rnnt 14.848516 hw_loss 0.225023 lr 0.00070943 rank 4
2023-02-11 11:34:50,759 DEBUG TRAIN Batch 5/8000 loss 19.572382 loss_att 23.288515 loss_ctc 32.030422 loss_rnnt 14.899919 hw_loss 0.425281 lr 0.00070917 rank 5
2023-02-11 11:36:05,988 DEBUG TRAIN Batch 5/8100 loss 23.814882 loss_att 24.169676 loss_ctc 39.565338 loss_rnnt 20.075333 hw_loss 0.294099 lr 0.00070816 rank 0
2023-02-11 11:36:05,989 DEBUG TRAIN Batch 5/8100 loss 14.328470 loss_att 15.279938 loss_ctc 23.361353 loss_rnnt 10.489800 hw_loss 0.458249 lr 0.00070886 rank 6
2023-02-11 11:36:05,989 DEBUG TRAIN Batch 5/8100 loss 14.173791 loss_att 14.135012 loss_ctc 19.249565 loss_rnnt 8.699740 hw_loss 0.900944 lr 0.00070874 rank 7
2023-02-11 11:36:05,989 DEBUG TRAIN Batch 5/8100 loss 21.822079 loss_att 25.473413 loss_ctc 31.418678 loss_rnnt 18.426376 hw_loss 0.259854 lr 0.00070845 rank 5
2023-02-11 11:36:05,990 DEBUG TRAIN Batch 5/8100 loss 24.290760 loss_att 26.921543 loss_ctc 40.031097 loss_rnnt 20.471882 hw_loss 0.223877 lr 0.00070835 rank 1
2023-02-11 11:36:05,991 DEBUG TRAIN Batch 5/8100 loss 13.223917 loss_att 15.279902 loss_ctc 19.868120 loss_rnnt 7.016052 hw_loss 0.920770 lr 0.00070872 rank 4
2023-02-11 11:36:05,991 DEBUG TRAIN Batch 5/8100 loss 43.313358 loss_att 41.728310 loss_ctc 63.377670 loss_rnnt 39.557529 hw_loss 0.262048 lr 0.00070864 rank 3
2023-02-11 11:36:06,015 DEBUG TRAIN Batch 5/8100 loss 18.942070 loss_att 23.272697 loss_ctc 27.091400 loss_rnnt 15.132237 hw_loss 0.348212 lr 0.00070808 rank 2
2023-02-11 11:37:21,846 DEBUG TRAIN Batch 5/8200 loss 23.812973 loss_att 28.980919 loss_ctc 44.675472 loss_rnnt 18.614159 hw_loss 0.259418 lr 0.00070764 rank 1
2023-02-11 11:37:21,849 DEBUG TRAIN Batch 5/8200 loss 12.632836 loss_att 13.057445 loss_ctc 19.952244 loss_rnnt 8.116798 hw_loss 0.647849 lr 0.00070793 rank 3
2023-02-11 11:37:21,852 DEBUG TRAIN Batch 5/8200 loss 12.089231 loss_att 15.610983 loss_ctc 25.346523 loss_rnnt 7.809165 hw_loss 0.339014 lr 0.00070745 rank 0
2023-02-11 11:37:21,852 DEBUG TRAIN Batch 5/8200 loss 23.047523 loss_att 21.607866 loss_ctc 29.750500 loss_rnnt 18.140921 hw_loss 0.806401 lr 0.00070737 rank 2
2023-02-11 11:37:21,853 DEBUG TRAIN Batch 5/8200 loss 15.158695 loss_att 13.757715 loss_ctc 18.123692 loss_rnnt 10.562572 hw_loss 0.840185 lr 0.00070803 rank 7
2023-02-11 11:37:21,854 DEBUG TRAIN Batch 5/8200 loss 18.563694 loss_att 21.450031 loss_ctc 28.404350 loss_rnnt 15.713518 hw_loss 0.180154 lr 0.00070774 rank 5
2023-02-11 11:37:21,854 DEBUG TRAIN Batch 5/8200 loss 21.036963 loss_att 24.228434 loss_ctc 33.337875 loss_rnnt 16.404306 hw_loss 0.441420 lr 0.00070801 rank 4
2023-02-11 11:37:21,858 DEBUG TRAIN Batch 5/8200 loss 30.442862 loss_att 33.106644 loss_ctc 42.845814 loss_rnnt 23.485184 hw_loss 0.894599 lr 0.00070815 rank 6
2023-02-11 11:38:37,296 DEBUG TRAIN Batch 5/8300 loss 18.282074 loss_att 17.464588 loss_ctc 24.709286 loss_rnnt 13.673975 hw_loss 0.733994 lr 0.00070722 rank 3
2023-02-11 11:38:37,301 DEBUG TRAIN Batch 5/8300 loss 20.524040 loss_att 21.203535 loss_ctc 32.092373 loss_rnnt 17.175125 hw_loss 0.313232 lr 0.00070732 rank 7
2023-02-11 11:38:37,301 DEBUG TRAIN Batch 5/8300 loss 15.998277 loss_att 18.154861 loss_ctc 21.719097 loss_rnnt 13.443214 hw_loss 0.255182 lr 0.00070666 rank 2
2023-02-11 11:38:37,301 DEBUG TRAIN Batch 5/8300 loss 19.182230 loss_att 23.520807 loss_ctc 36.845943 loss_rnnt 13.340916 hw_loss 0.490957 lr 0.00070744 rank 6
2023-02-11 11:38:37,302 DEBUG TRAIN Batch 5/8300 loss 11.858101 loss_att 12.671589 loss_ctc 17.789587 loss_rnnt 7.459581 hw_loss 0.645930 lr 0.00070675 rank 0
2023-02-11 11:38:37,304 DEBUG TRAIN Batch 5/8300 loss 25.749271 loss_att 23.897301 loss_ctc 33.299419 loss_rnnt 21.610886 hw_loss 0.656643 lr 0.00070694 rank 1
2023-02-11 11:38:37,307 DEBUG TRAIN Batch 5/8300 loss 22.064598 loss_att 24.607204 loss_ctc 36.986576 loss_rnnt 17.285667 hw_loss 0.427652 lr 0.00070730 rank 4
2023-02-11 11:38:37,307 DEBUG TRAIN Batch 5/8300 loss 26.040329 loss_att 25.438086 loss_ctc 28.388433 loss_rnnt 21.387129 hw_loss 0.836357 lr 0.00070704 rank 5
2023-02-11 11:39:19,547 DEBUG CV Batch 5/0 loss 9.089380 loss_att 2.946402 loss_ctc 5.254117 loss_rnnt 2.235965 hw_loss 1.611259 history loss 8.752737 rank 3
2023-02-11 11:39:19,548 DEBUG CV Batch 5/0 loss 9.089381 loss_att 2.946402 loss_ctc 5.254117 loss_rnnt 2.235965 hw_loss 1.611259 history loss 8.752737 rank 7
2023-02-11 11:39:19,549 DEBUG CV Batch 5/0 loss 9.089380 loss_att 2.946402 loss_ctc 5.254117 loss_rnnt 2.235965 hw_loss 1.611259 history loss 8.752737 rank 6
2023-02-11 11:39:19,552 DEBUG CV Batch 5/0 loss 9.089380 loss_att 2.946402 loss_ctc 5.254117 loss_rnnt 2.235965 hw_loss 1.611259 history loss 8.752737 rank 0
2023-02-11 11:39:19,553 DEBUG CV Batch 5/0 loss 9.089381 loss_att 2.946402 loss_ctc 5.254117 loss_rnnt 2.235965 hw_loss 1.611259 history loss 8.752737 rank 4
2023-02-11 11:39:19,563 DEBUG CV Batch 5/0 loss 9.089381 loss_att 2.946402 loss_ctc 5.254117 loss_rnnt 2.235965 hw_loss 1.611259 history loss 8.752737 rank 5
2023-02-11 11:39:19,564 DEBUG CV Batch 5/0 loss 9.089380 loss_att 2.946402 loss_ctc 5.254117 loss_rnnt 2.235965 hw_loss 1.611259 history loss 8.752737 rank 2
2023-02-11 11:39:19,577 DEBUG CV Batch 5/0 loss 9.089380 loss_att 2.946402 loss_ctc 5.254117 loss_rnnt 2.235965 hw_loss 1.611259 history loss 8.752737 rank 1
2023-02-11 11:39:30,634 DEBUG CV Batch 5/100 loss 15.938168 loss_att 14.299049 loss_ctc 24.587738 loss_rnnt 11.780643 hw_loss 0.624763 history loss 9.033273 rank 0
2023-02-11 11:39:30,678 DEBUG CV Batch 5/100 loss 15.938168 loss_att 14.299049 loss_ctc 24.587738 loss_rnnt 11.780643 hw_loss 0.624764 history loss 9.033273 rank 3
2023-02-11 11:39:30,694 DEBUG CV Batch 5/100 loss 15.938168 loss_att 14.299049 loss_ctc 24.587738 loss_rnnt 11.780643 hw_loss 0.624763 history loss 9.033273 rank 7
2023-02-11 11:39:30,694 DEBUG CV Batch 5/100 loss 15.938168 loss_att 14.299049 loss_ctc 24.587738 loss_rnnt 11.780643 hw_loss 0.624763 history loss 9.033273 rank 5
2023-02-11 11:39:30,788 DEBUG CV Batch 5/100 loss 15.938168 loss_att 14.299049 loss_ctc 24.587738 loss_rnnt 11.780643 hw_loss 0.624763 history loss 9.033273 rank 6
2023-02-11 11:39:30,794 DEBUG CV Batch 5/100 loss 15.938168 loss_att 14.299049 loss_ctc 24.587738 loss_rnnt 11.780643 hw_loss 0.624763 history loss 9.033273 rank 1
2023-02-11 11:39:31,024 DEBUG CV Batch 5/100 loss 15.938168 loss_att 14.299049 loss_ctc 24.587738 loss_rnnt 11.780643 hw_loss 0.624763 history loss 9.033273 rank 4
2023-02-11 11:39:31,427 DEBUG CV Batch 5/100 loss 15.938168 loss_att 14.299049 loss_ctc 24.587738 loss_rnnt 11.780643 hw_loss 0.624763 history loss 9.033273 rank 2
2023-02-11 11:39:44,635 DEBUG CV Batch 5/200 loss 12.800846 loss_att 25.113409 loss_ctc 15.289948 loss_rnnt 8.256892 hw_loss 0.328043 history loss 9.503633 rank 3
2023-02-11 11:39:44,716 DEBUG CV Batch 5/200 loss 12.800846 loss_att 25.113409 loss_ctc 15.289948 loss_rnnt 8.256892 hw_loss 0.328043 history loss 9.503633 rank 0
2023-02-11 11:39:44,735 DEBUG CV Batch 5/200 loss 12.800846 loss_att 25.113409 loss_ctc 15.289948 loss_rnnt 8.256892 hw_loss 0.328043 history loss 9.503633 rank 7
2023-02-11 11:39:44,763 DEBUG CV Batch 5/200 loss 12.800846 loss_att 25.113409 loss_ctc 15.289948 loss_rnnt 8.256892 hw_loss 0.328043 history loss 9.503633 rank 5
2023-02-11 11:39:44,827 DEBUG CV Batch 5/200 loss 12.800846 loss_att 25.113409 loss_ctc 15.289948 loss_rnnt 8.256892 hw_loss 0.328043 history loss 9.503633 rank 2
2023-02-11 11:39:44,917 DEBUG CV Batch 5/200 loss 12.800846 loss_att 25.113409 loss_ctc 15.289948 loss_rnnt 8.256892 hw_loss 0.328043 history loss 9.503633 rank 1
2023-02-11 11:39:45,030 DEBUG CV Batch 5/200 loss 12.800846 loss_att 25.113409 loss_ctc 15.289948 loss_rnnt 8.256892 hw_loss 0.328043 history loss 9.503633 rank 4
2023-02-11 11:39:45,077 DEBUG CV Batch 5/200 loss 12.800846 loss_att 25.113409 loss_ctc 15.289948 loss_rnnt 8.256892 hw_loss 0.328043 history loss 9.503633 rank 6
2023-02-11 11:39:56,692 DEBUG CV Batch 5/300 loss 9.073791 loss_att 7.002232 loss_ctc 12.240219 loss_rnnt 5.511041 hw_loss 0.666538 history loss 9.702647 rank 3
2023-02-11 11:39:56,727 DEBUG CV Batch 5/300 loss 9.073791 loss_att 7.002232 loss_ctc 12.240219 loss_rnnt 5.511041 hw_loss 0.666538 history loss 9.702647 rank 0
2023-02-11 11:39:56,772 DEBUG CV Batch 5/300 loss 9.073791 loss_att 7.002232 loss_ctc 12.240219 loss_rnnt 5.511041 hw_loss 0.666538 history loss 9.702647 rank 7
2023-02-11 11:39:56,826 DEBUG CV Batch 5/300 loss 9.073791 loss_att 7.002232 loss_ctc 12.240219 loss_rnnt 5.511041 hw_loss 0.666538 history loss 9.702647 rank 5
2023-02-11 11:39:56,900 DEBUG CV Batch 5/300 loss 9.073791 loss_att 7.002232 loss_ctc 12.240219 loss_rnnt 5.511041 hw_loss 0.666538 history loss 9.702647 rank 2
2023-02-11 11:39:56,990 DEBUG CV Batch 5/300 loss 9.073791 loss_att 7.002232 loss_ctc 12.240219 loss_rnnt 5.511041 hw_loss 0.666538 history loss 9.702647 rank 1
2023-02-11 11:39:57,165 DEBUG CV Batch 5/300 loss 9.073791 loss_att 7.002232 loss_ctc 12.240219 loss_rnnt 5.511041 hw_loss 0.666538 history loss 9.702647 rank 4
2023-02-11 11:39:57,209 DEBUG CV Batch 5/300 loss 9.073791 loss_att 7.002232 loss_ctc 12.240219 loss_rnnt 5.511041 hw_loss 0.666538 history loss 9.702647 rank 6
2023-02-11 11:40:08,661 DEBUG CV Batch 5/400 loss 35.695072 loss_att 119.432014 loss_ctc 30.273649 loss_rnnt 19.347801 hw_loss 0.060514 history loss 10.722305 rank 0
2023-02-11 11:40:08,668 DEBUG CV Batch 5/400 loss 35.695072 loss_att 119.432014 loss_ctc 30.273649 loss_rnnt 19.347801 hw_loss 0.060514 history loss 10.722305 rank 3
2023-02-11 11:40:08,764 DEBUG CV Batch 5/400 loss 35.695072 loss_att 119.432014 loss_ctc 30.273649 loss_rnnt 19.347801 hw_loss 0.060514 history loss 10.722305 rank 7
2023-02-11 11:40:08,798 DEBUG CV Batch 5/400 loss 35.695072 loss_att 119.432014 loss_ctc 30.273649 loss_rnnt 19.347801 hw_loss 0.060514 history loss 10.722305 rank 5
2023-02-11 11:40:08,955 DEBUG CV Batch 5/400 loss 35.695072 loss_att 119.432014 loss_ctc 30.273649 loss_rnnt 19.347801 hw_loss 0.060514 history loss 10.722305 rank 2
2023-02-11 11:40:09,151 DEBUG CV Batch 5/400 loss 35.695072 loss_att 119.432014 loss_ctc 30.273649 loss_rnnt 19.347801 hw_loss 0.060514 history loss 10.722305 rank 4
2023-02-11 11:40:09,181 DEBUG CV Batch 5/400 loss 35.695072 loss_att 119.432014 loss_ctc 30.273649 loss_rnnt 19.347801 hw_loss 0.060514 history loss 10.722305 rank 6
2023-02-11 11:40:09,919 DEBUG CV Batch 5/400 loss 35.695072 loss_att 119.432014 loss_ctc 30.273649 loss_rnnt 19.347801 hw_loss 0.060514 history loss 10.722305 rank 1
2023-02-11 11:40:19,041 DEBUG CV Batch 5/500 loss 12.071661 loss_att 10.792899 loss_ctc 16.317421 loss_rnnt 8.713605 hw_loss 0.571445 history loss 11.629370 rank 0
2023-02-11 11:40:19,049 DEBUG CV Batch 5/500 loss 12.071661 loss_att 10.792899 loss_ctc 16.317421 loss_rnnt 8.713605 hw_loss 0.571445 history loss 11.629370 rank 3
2023-02-11 11:40:19,220 DEBUG CV Batch 5/500 loss 12.071661 loss_att 10.792899 loss_ctc 16.317421 loss_rnnt 8.713605 hw_loss 0.571445 history loss 11.629370 rank 7
2023-02-11 11:40:19,304 DEBUG CV Batch 5/500 loss 12.071661 loss_att 10.792899 loss_ctc 16.317421 loss_rnnt 8.713605 hw_loss 0.571445 history loss 11.629370 rank 5
2023-02-11 11:40:19,376 DEBUG CV Batch 5/500 loss 12.071661 loss_att 10.792899 loss_ctc 16.317421 loss_rnnt 8.713605 hw_loss 0.571445 history loss 11.629370 rank 2
2023-02-11 11:40:19,742 DEBUG CV Batch 5/500 loss 12.071661 loss_att 10.792899 loss_ctc 16.317421 loss_rnnt 8.713605 hw_loss 0.571445 history loss 11.629370 rank 4
2023-02-11 11:40:19,832 DEBUG CV Batch 5/500 loss 12.071661 loss_att 10.792899 loss_ctc 16.317421 loss_rnnt 8.713605 hw_loss 0.571445 history loss 11.629370 rank 6
2023-02-11 11:40:21,881 DEBUG CV Batch 5/500 loss 12.071661 loss_att 10.792899 loss_ctc 16.317421 loss_rnnt 8.713605 hw_loss 0.571445 history loss 11.629370 rank 1
2023-02-11 11:40:31,051 DEBUG CV Batch 5/600 loss 12.745182 loss_att 10.355856 loss_ctc 12.968897 loss_rnnt 7.370867 hw_loss 1.091691 history loss 12.568130 rank 0
2023-02-11 11:40:31,084 DEBUG CV Batch 5/600 loss 12.745182 loss_att 10.355856 loss_ctc 12.968897 loss_rnnt 7.370867 hw_loss 1.091691 history loss 12.568130 rank 3
2023-02-11 11:40:31,276 DEBUG CV Batch 5/600 loss 12.745182 loss_att 10.355856 loss_ctc 12.968897 loss_rnnt 7.370867 hw_loss 1.091691 history loss 12.568130 rank 7
2023-02-11 11:40:31,393 DEBUG CV Batch 5/600 loss 12.745182 loss_att 10.355856 loss_ctc 12.968897 loss_rnnt 7.370867 hw_loss 1.091691 history loss 12.568130 rank 5
2023-02-11 11:40:31,461 DEBUG CV Batch 5/600 loss 12.745181 loss_att 10.355856 loss_ctc 12.968897 loss_rnnt 7.370867 hw_loss 1.091691 history loss 12.568130 rank 2
2023-02-11 11:40:31,926 DEBUG CV Batch 5/600 loss 12.745182 loss_att 10.355856 loss_ctc 12.968897 loss_rnnt 7.370867 hw_loss 1.091691 history loss 12.568130 rank 4
2023-02-11 11:40:32,008 DEBUG CV Batch 5/600 loss 12.745182 loss_att 10.355856 loss_ctc 12.968897 loss_rnnt 7.370867 hw_loss 1.091691 history loss 12.568130 rank 6
2023-02-11 11:40:33,987 DEBUG CV Batch 5/600 loss 12.745181 loss_att 10.355856 loss_ctc 12.968897 loss_rnnt 7.370867 hw_loss 1.091691 history loss 12.568130 rank 1
2023-02-11 11:40:42,245 DEBUG CV Batch 5/700 loss 22.425098 loss_att 56.296967 loss_ctc 36.027821 loss_rnnt 11.071066 hw_loss 0.518618 history loss 13.250881 rank 0
2023-02-11 11:40:42,326 DEBUG CV Batch 5/700 loss 22.425098 loss_att 56.296967 loss_ctc 36.027821 loss_rnnt 11.071066 hw_loss 0.518618 history loss 13.250881 rank 3
2023-02-11 11:40:42,638 DEBUG CV Batch 5/700 loss 22.425098 loss_att 56.296967 loss_ctc 36.027821 loss_rnnt 11.071066 hw_loss 0.518618 history loss 13.250881 rank 5
2023-02-11 11:40:42,663 DEBUG CV Batch 5/700 loss 22.425098 loss_att 56.296967 loss_ctc 36.027821 loss_rnnt 11.071066 hw_loss 0.518618 history loss 13.250881 rank 7
2023-02-11 11:40:42,979 DEBUG CV Batch 5/700 loss 22.425098 loss_att 56.296967 loss_ctc 36.027821 loss_rnnt 11.071066 hw_loss 0.518618 history loss 13.250881 rank 2
2023-02-11 11:40:44,013 DEBUG CV Batch 5/700 loss 22.425098 loss_att 56.296967 loss_ctc 36.027821 loss_rnnt 11.071066 hw_loss 0.518618 history loss 13.250881 rank 4
2023-02-11 11:40:44,092 DEBUG CV Batch 5/700 loss 22.425098 loss_att 56.296967 loss_ctc 36.027821 loss_rnnt 11.071066 hw_loss 0.518618 history loss 13.250881 rank 6
2023-02-11 11:40:45,275 DEBUG CV Batch 5/700 loss 22.425098 loss_att 56.296967 loss_ctc 36.027821 loss_rnnt 11.071066 hw_loss 0.518618 history loss 13.250881 rank 1
2023-02-11 11:40:53,650 DEBUG CV Batch 5/800 loss 14.004547 loss_att 13.225461 loss_ctc 22.183607 loss_rnnt 10.360289 hw_loss 0.508038 history loss 12.693267 rank 3
2023-02-11 11:40:53,918 DEBUG CV Batch 5/800 loss 14.004547 loss_att 13.225461 loss_ctc 22.183607 loss_rnnt 10.360289 hw_loss 0.508038 history loss 12.693267 rank 0
2023-02-11 11:40:54,007 DEBUG CV Batch 5/800 loss 14.004546 loss_att 13.225461 loss_ctc 22.183607 loss_rnnt 10.360289 hw_loss 0.508038 history loss 12.693267 rank 5
2023-02-11 11:40:54,104 DEBUG CV Batch 5/800 loss 14.004547 loss_att 13.225461 loss_ctc 22.183607 loss_rnnt 10.360289 hw_loss 0.508038 history loss 12.693267 rank 7
2023-02-11 11:40:54,986 DEBUG CV Batch 5/800 loss 14.004547 loss_att 13.225461 loss_ctc 22.183607 loss_rnnt 10.360289 hw_loss 0.508038 history loss 12.693267 rank 2
2023-02-11 11:40:56,030 DEBUG CV Batch 5/800 loss 14.004547 loss_att 13.225461 loss_ctc 22.183607 loss_rnnt 10.360289 hw_loss 0.508038 history loss 12.693267 rank 4
2023-02-11 11:40:56,204 DEBUG CV Batch 5/800 loss 14.004547 loss_att 13.225461 loss_ctc 22.183607 loss_rnnt 10.360289 hw_loss 0.508038 history loss 12.693267 rank 6
2023-02-11 11:40:56,992 DEBUG CV Batch 5/800 loss 14.004547 loss_att 13.225461 loss_ctc 22.183607 loss_rnnt 10.360289 hw_loss 0.508038 history loss 12.693267 rank 1
2023-02-11 11:41:07,331 DEBUG CV Batch 5/900 loss 14.272484 loss_att 20.247734 loss_ctc 25.194584 loss_rnnt 9.737688 hw_loss 0.353150 history loss 12.453411 rank 0
2023-02-11 11:41:07,460 DEBUG CV Batch 5/900 loss 14.272484 loss_att 20.247734 loss_ctc 25.194584 loss_rnnt 9.737688 hw_loss 0.353150 history loss 12.453411 rank 5
2023-02-11 11:41:07,760 DEBUG CV Batch 5/900 loss 14.272484 loss_att 20.247734 loss_ctc 25.194584 loss_rnnt 9.737688 hw_loss 0.353150 history loss 12.453411 rank 3
2023-02-11 11:41:07,816 DEBUG CV Batch 5/900 loss 14.272484 loss_att 20.247734 loss_ctc 25.194584 loss_rnnt 9.737688 hw_loss 0.353150 history loss 12.453411 rank 7
2023-02-11 11:41:08,988 DEBUG CV Batch 5/900 loss 14.272484 loss_att 20.247734 loss_ctc 25.194584 loss_rnnt 9.737688 hw_loss 0.353150 history loss 12.453411 rank 2
2023-02-11 11:41:09,783 DEBUG CV Batch 5/900 loss 14.272484 loss_att 20.247734 loss_ctc 25.194584 loss_rnnt 9.737688 hw_loss 0.353150 history loss 12.453411 rank 4
2023-02-11 11:41:10,115 DEBUG CV Batch 5/900 loss 14.272484 loss_att 20.247734 loss_ctc 25.194584 loss_rnnt 9.737688 hw_loss 0.353150 history loss 12.453411 rank 6
2023-02-11 11:41:10,742 DEBUG CV Batch 5/900 loss 14.272484 loss_att 20.247734 loss_ctc 25.194584 loss_rnnt 9.737688 hw_loss 0.353150 history loss 12.453411 rank 1
2023-02-11 11:41:19,451 DEBUG CV Batch 5/1000 loss 8.304544 loss_att 6.491911 loss_ctc 7.417535 loss_rnnt 3.357138 hw_loss 1.017788 history loss 12.208308 rank 0
2023-02-11 11:41:19,684 DEBUG CV Batch 5/1000 loss 8.304544 loss_att 6.491911 loss_ctc 7.417535 loss_rnnt 3.357138 hw_loss 1.017788 history loss 12.208308 rank 5
2023-02-11 11:41:19,937 DEBUG CV Batch 5/1000 loss 8.304544 loss_att 6.491911 loss_ctc 7.417535 loss_rnnt 3.357138 hw_loss 1.017788 history loss 12.208308 rank 3
2023-02-11 11:41:19,949 DEBUG CV Batch 5/1000 loss 8.304544 loss_att 6.491911 loss_ctc 7.417535 loss_rnnt 3.357138 hw_loss 1.017788 history loss 12.208308 rank 7
2023-02-11 11:41:21,146 DEBUG CV Batch 5/1000 loss 8.304544 loss_att 6.491911 loss_ctc 7.417535 loss_rnnt 3.357138 hw_loss 1.017788 history loss 12.208308 rank 2
2023-02-11 11:41:22,089 DEBUG CV Batch 5/1000 loss 8.304544 loss_att 6.491911 loss_ctc 7.417535 loss_rnnt 3.357138 hw_loss 1.017788 history loss 12.208308 rank 4
2023-02-11 11:41:22,737 DEBUG CV Batch 5/1000 loss 8.304544 loss_att 6.491911 loss_ctc 7.417535 loss_rnnt 3.357138 hw_loss 1.017788 history loss 12.208308 rank 6
2023-02-11 11:41:22,905 DEBUG CV Batch 5/1000 loss 8.304544 loss_att 6.491911 loss_ctc 7.417535 loss_rnnt 3.357138 hw_loss 1.017788 history loss 12.208308 rank 1
2023-02-11 11:41:31,270 DEBUG CV Batch 5/1100 loss 13.121048 loss_att 7.017282 loss_ctc 11.565860 loss_rnnt 6.221218 hw_loss 1.561489 history loss 12.190190 rank 0
2023-02-11 11:41:31,583 DEBUG CV Batch 5/1100 loss 13.121048 loss_att 7.017282 loss_ctc 11.565860 loss_rnnt 6.221218 hw_loss 1.561489 history loss 12.190190 rank 5
2023-02-11 11:41:31,754 DEBUG CV Batch 5/1100 loss 13.121048 loss_att 7.017282 loss_ctc 11.565860 loss_rnnt 6.221218 hw_loss 1.561489 history loss 12.190190 rank 3
2023-02-11 11:41:31,870 DEBUG CV Batch 5/1100 loss 13.121050 loss_att 7.017282 loss_ctc 11.565860 loss_rnnt 6.221218 hw_loss 1.561489 history loss 12.190190 rank 7
2023-02-11 11:41:33,127 DEBUG CV Batch 5/1100 loss 13.121050 loss_att 7.017282 loss_ctc 11.565860 loss_rnnt 6.221218 hw_loss 1.561489 history loss 12.190190 rank 2
2023-02-11 11:41:34,019 DEBUG CV Batch 5/1100 loss 13.121048 loss_att 7.017282 loss_ctc 11.565860 loss_rnnt 6.221218 hw_loss 1.561489 history loss 12.190190 rank 4
2023-02-11 11:41:34,757 DEBUG CV Batch 5/1100 loss 13.121048 loss_att 7.017282 loss_ctc 11.565860 loss_rnnt 6.221218 hw_loss 1.561489 history loss 12.190190 rank 1
2023-02-11 11:41:35,694 DEBUG CV Batch 5/1100 loss 13.121049 loss_att 7.017282 loss_ctc 11.565860 loss_rnnt 6.221218 hw_loss 1.561489 history loss 12.190190 rank 6
2023-02-11 11:41:41,636 DEBUG CV Batch 5/1200 loss 13.276325 loss_att 13.851774 loss_ctc 15.944921 loss_rnnt 10.260549 hw_loss 0.477164 history loss 12.560288 rank 0
2023-02-11 11:41:42,070 DEBUG CV Batch 5/1200 loss 13.276325 loss_att 13.851774 loss_ctc 15.944921 loss_rnnt 10.260549 hw_loss 0.477164 history loss 12.560288 rank 5
2023-02-11 11:41:42,156 DEBUG CV Batch 5/1200 loss 13.276326 loss_att 13.851774 loss_ctc 15.944921 loss_rnnt 10.260549 hw_loss 0.477164 history loss 12.560288 rank 3
2023-02-11 11:41:42,343 DEBUG CV Batch 5/1200 loss 13.276325 loss_att 13.851774 loss_ctc 15.944921 loss_rnnt 10.260549 hw_loss 0.477164 history loss 12.560288 rank 7
2023-02-11 11:41:43,559 DEBUG CV Batch 5/1200 loss 13.276325 loss_att 13.851774 loss_ctc 15.944921 loss_rnnt 10.260549 hw_loss 0.477164 history loss 12.560288 rank 2
2023-02-11 11:41:45,235 DEBUG CV Batch 5/1200 loss 13.276325 loss_att 13.851774 loss_ctc 15.944921 loss_rnnt 10.260549 hw_loss 0.477164 history loss 12.560288 rank 1
2023-02-11 11:41:45,283 DEBUG CV Batch 5/1200 loss 13.276325 loss_att 13.851774 loss_ctc 15.944921 loss_rnnt 10.260549 hw_loss 0.477164 history loss 12.560288 rank 4
2023-02-11 11:41:46,221 DEBUG CV Batch 5/1200 loss 13.276325 loss_att 13.851774 loss_ctc 15.944921 loss_rnnt 10.260549 hw_loss 0.477164 history loss 12.560288 rank 6
2023-02-11 11:41:53,563 DEBUG CV Batch 5/1300 loss 10.626419 loss_att 8.079334 loss_ctc 12.589623 loss_rnnt 5.556069 hw_loss 0.997126 history loss 12.842154 rank 0
2023-02-11 11:41:53,995 DEBUG CV Batch 5/1300 loss 10.626420 loss_att 8.079334 loss_ctc 12.589623 loss_rnnt 5.556069 hw_loss 0.997126 history loss 12.842154 rank 3
2023-02-11 11:41:54,012 DEBUG CV Batch 5/1300 loss 10.626419 loss_att 8.079334 loss_ctc 12.589623 loss_rnnt 5.556069 hw_loss 0.997126 history loss 12.842154 rank 5
2023-02-11 11:41:54,201 DEBUG CV Batch 5/1300 loss 10.626419 loss_att 8.079334 loss_ctc 12.589623 loss_rnnt 5.556069 hw_loss 0.997126 history loss 12.842154 rank 7
2023-02-11 11:41:55,535 DEBUG CV Batch 5/1300 loss 10.626420 loss_att 8.079334 loss_ctc 12.589623 loss_rnnt 5.556069 hw_loss 0.997126 history loss 12.842154 rank 2
2023-02-11 11:41:57,365 DEBUG CV Batch 5/1300 loss 10.626420 loss_att 8.079334 loss_ctc 12.589623 loss_rnnt 5.556069 hw_loss 0.997126 history loss 12.842154 rank 1
2023-02-11 11:41:58,097 DEBUG CV Batch 5/1300 loss 10.626419 loss_att 8.079334 loss_ctc 12.589623 loss_rnnt 5.556069 hw_loss 0.997126 history loss 12.842154 rank 6
2023-02-11 11:41:58,283 DEBUG CV Batch 5/1300 loss 10.626420 loss_att 8.079334 loss_ctc 12.589623 loss_rnnt 5.556069 hw_loss 0.997126 history loss 12.842154 rank 4
2023-02-11 11:42:04,653 DEBUG CV Batch 5/1400 loss 18.377943 loss_att 55.795792 loss_ctc 22.449306 loss_rnnt 9.526126 hw_loss 0.154762 history loss 13.184307 rank 0
2023-02-11 11:42:05,099 DEBUG CV Batch 5/1400 loss 18.377943 loss_att 55.795792 loss_ctc 22.449306 loss_rnnt 9.526126 hw_loss 0.154762 history loss 13.184307 rank 3
2023-02-11 11:42:05,126 DEBUG CV Batch 5/1400 loss 18.377943 loss_att 55.795792 loss_ctc 22.449306 loss_rnnt 9.526126 hw_loss 0.154762 history loss 13.184307 rank 5
2023-02-11 11:42:05,325 DEBUG CV Batch 5/1400 loss 18.377943 loss_att 55.795792 loss_ctc 22.449306 loss_rnnt 9.526126 hw_loss 0.154762 history loss 13.184307 rank 7
2023-02-11 11:42:07,056 DEBUG CV Batch 5/1400 loss 18.377943 loss_att 55.795792 loss_ctc 22.449306 loss_rnnt 9.526126 hw_loss 0.154762 history loss 13.184307 rank 2
2023-02-11 11:42:09,194 DEBUG CV Batch 5/1400 loss 18.377943 loss_att 55.795792 loss_ctc 22.449306 loss_rnnt 9.526126 hw_loss 0.154762 history loss 13.184307 rank 1
2023-02-11 11:42:09,281 DEBUG CV Batch 5/1400 loss 18.377943 loss_att 55.795792 loss_ctc 22.449306 loss_rnnt 9.526126 hw_loss 0.154762 history loss 13.184307 rank 6
2023-02-11 11:42:09,479 DEBUG CV Batch 5/1400 loss 18.377943 loss_att 55.795792 loss_ctc 22.449306 loss_rnnt 9.526126 hw_loss 0.154762 history loss 13.184307 rank 4
2023-02-11 11:42:16,632 DEBUG CV Batch 5/1500 loss 12.801670 loss_att 12.232062 loss_ctc 12.813011 loss_rnnt 10.220116 hw_loss 0.505118 history loss 12.998523 rank 0
2023-02-11 11:42:16,669 DEBUG CV Batch 5/1500 loss 12.801671 loss_att 12.232062 loss_ctc 12.813011 loss_rnnt 10.220116 hw_loss 0.505118 history loss 12.998523 rank 3
2023-02-11 11:42:16,857 DEBUG CV Batch 5/1500 loss 12.801671 loss_att 12.232062 loss_ctc 12.813011 loss_rnnt 10.220116 hw_loss 0.505118 history loss 12.998523 rank 5
2023-02-11 11:42:16,862 DEBUG CV Batch 5/1500 loss 12.801670 loss_att 12.232062 loss_ctc 12.813011 loss_rnnt 10.220116 hw_loss 0.505118 history loss 12.998523 rank 7
2023-02-11 11:42:19,229 DEBUG CV Batch 5/1500 loss 12.801671 loss_att 12.232062 loss_ctc 12.813011 loss_rnnt 10.220116 hw_loss 0.505118 history loss 12.998523 rank 2
2023-02-11 11:42:20,901 DEBUG CV Batch 5/1500 loss 12.801670 loss_att 12.232062 loss_ctc 12.813011 loss_rnnt 10.220116 hw_loss 0.505118 history loss 12.998523 rank 6
2023-02-11 11:42:20,951 DEBUG CV Batch 5/1500 loss 12.801671 loss_att 12.232062 loss_ctc 12.813011 loss_rnnt 10.220116 hw_loss 0.505118 history loss 12.998523 rank 4
2023-02-11 11:42:21,340 DEBUG CV Batch 5/1500 loss 12.801670 loss_att 12.232062 loss_ctc 12.813011 loss_rnnt 10.220116 hw_loss 0.505118 history loss 12.998523 rank 1
2023-02-11 11:42:30,001 DEBUG CV Batch 5/1600 loss 13.551323 loss_att 25.228733 loss_ctc 19.812416 loss_rnnt 8.181280 hw_loss 0.412453 history loss 12.889823 rank 0
2023-02-11 11:42:30,213 DEBUG CV Batch 5/1600 loss 13.551323 loss_att 25.228733 loss_ctc 19.812416 loss_rnnt 8.181280 hw_loss 0.412453 history loss 12.889823 rank 3
2023-02-11 11:42:30,387 DEBUG CV Batch 5/1600 loss 13.551323 loss_att 25.228733 loss_ctc 19.812416 loss_rnnt 8.181280 hw_loss 0.412453 history loss 12.889823 rank 5
2023-02-11 11:42:30,522 DEBUG CV Batch 5/1600 loss 13.551323 loss_att 25.228733 loss_ctc 19.812416 loss_rnnt 8.181280 hw_loss 0.412453 history loss 12.889823 rank 7
2023-02-11 11:42:33,127 DEBUG CV Batch 5/1600 loss 13.551323 loss_att 25.228733 loss_ctc 19.812416 loss_rnnt 8.181280 hw_loss 0.412453 history loss 12.889823 rank 2
2023-02-11 11:42:34,307 DEBUG CV Batch 5/1600 loss 13.551323 loss_att 25.228733 loss_ctc 19.812416 loss_rnnt 8.181280 hw_loss 0.412453 history loss 12.889823 rank 4
2023-02-11 11:42:34,408 DEBUG CV Batch 5/1600 loss 13.551323 loss_att 25.228733 loss_ctc 19.812416 loss_rnnt 8.181280 hw_loss 0.412453 history loss 12.889823 rank 6
2023-02-11 11:42:34,509 DEBUG CV Batch 5/1600 loss 13.551323 loss_att 25.228733 loss_ctc 19.812416 loss_rnnt 8.181280 hw_loss 0.412453 history loss 12.889823 rank 1
2023-02-11 11:42:42,434 DEBUG CV Batch 5/1700 loss 11.003491 loss_att 8.867474 loss_ctc 15.791945 loss_rnnt 7.176392 hw_loss 0.677971 history loss 12.796665 rank 0
2023-02-11 11:42:42,713 DEBUG CV Batch 5/1700 loss 11.003492 loss_att 8.867474 loss_ctc 15.791945 loss_rnnt 7.176392 hw_loss 0.677971 history loss 12.796665 rank 3
2023-02-11 11:42:42,897 DEBUG CV Batch 5/1700 loss 11.003491 loss_att 8.867474 loss_ctc 15.791945 loss_rnnt 7.176392 hw_loss 0.677971 history loss 12.796665 rank 5
2023-02-11 11:42:42,980 DEBUG CV Batch 5/1700 loss 11.003491 loss_att 8.867474 loss_ctc 15.791945 loss_rnnt 7.176392 hw_loss 0.677971 history loss 12.796665 rank 7
2023-02-11 11:42:45,715 DEBUG CV Batch 5/1700 loss 11.003491 loss_att 8.867474 loss_ctc 15.791945 loss_rnnt 7.176392 hw_loss 0.677971 history loss 12.796665 rank 2
2023-02-11 11:42:46,830 DEBUG CV Batch 5/1700 loss 11.003491 loss_att 8.867474 loss_ctc 15.791945 loss_rnnt 7.176392 hw_loss 0.677971 history loss 12.796665 rank 6
2023-02-11 11:42:46,834 DEBUG CV Batch 5/1700 loss 11.003491 loss_att 8.867474 loss_ctc 15.791945 loss_rnnt 7.176392 hw_loss 0.677971 history loss 12.796665 rank 4
2023-02-11 11:42:47,009 DEBUG CV Batch 5/1700 loss 11.003491 loss_att 8.867474 loss_ctc 15.791945 loss_rnnt 7.176392 hw_loss 0.677971 history loss 12.796665 rank 1
2023-02-11 11:42:51,578 INFO Epoch 5 CV info cv_loss 12.744374433785682
2023-02-11 11:42:51,579 INFO Checkpoint: save to checkpoint exp2_10_rnnt_bias_loss/5.pt
2023-02-11 11:42:51,843 INFO Epoch 5 CV info cv_loss 12.744374417280044
2023-02-11 11:42:51,844 INFO Epoch 6 TRAIN info lr 0.0007069795363210172
2023-02-11 11:42:51,848 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 11:42:52,076 INFO Epoch 5 CV info cv_loss 12.744374413351773
2023-02-11 11:42:52,077 INFO Epoch 6 TRAIN info lr 0.0007068452967924013
2023-02-11 11:42:52,081 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 11:42:52,184 INFO Epoch 6 TRAIN info lr 0.000706534719654791
2023-02-11 11:42:52,188 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 11:42:52,204 INFO Epoch 5 CV info cv_loss 12.744374437610578
2023-02-11 11:42:52,205 INFO Epoch 6 TRAIN info lr 0.0007069795363210172
2023-02-11 11:42:52,208 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 11:42:54,889 INFO Epoch 5 CV info cv_loss 12.744374442193562
2023-02-11 11:42:54,890 INFO Epoch 6 TRAIN info lr 0.0007063372926804531
2023-02-11 11:42:54,894 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 11:42:55,904 INFO Epoch 5 CV info cv_loss 12.744374420863732
2023-02-11 11:42:55,905 INFO Epoch 6 TRAIN info lr 0.0007071633565181728
2023-02-11 11:42:55,908 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 11:42:55,922 INFO Epoch 5 CV info cv_loss 12.744374422862327
2023-02-11 11:42:55,923 INFO Epoch 6 TRAIN info lr 0.0007071562838590719
2023-02-11 11:42:55,926 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 11:42:56,130 INFO Epoch 5 CV info cv_loss 12.744374440608471
2023-02-11 11:42:56,133 INFO Epoch 6 TRAIN info lr 0.0007066828985740602
2023-02-11 11:42:56,137 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 11:44:09,512 DEBUG TRAIN Batch 6/0 loss 15.446042 loss_att 11.932261 loss_ctc 16.327621 loss_rnnt 10.144071 hw_loss 1.103847 lr 0.00070697 rank 3
2023-02-11 11:44:09,516 DEBUG TRAIN Batch 6/0 loss 16.973934 loss_att 12.779257 loss_ctc 16.993217 loss_rnnt 12.101302 hw_loss 1.070437 lr 0.00070684 rank 5
2023-02-11 11:44:09,517 DEBUG TRAIN Batch 6/0 loss 16.172146 loss_att 12.457274 loss_ctc 18.123220 loss_rnnt 10.137134 hw_loss 1.222096 lr 0.00070668 rank 1
2023-02-11 11:44:09,528 DEBUG TRAIN Batch 6/0 loss 15.301449 loss_att 11.128216 loss_ctc 15.557833 loss_rnnt 10.513067 hw_loss 1.047908 lr 0.00070716 rank 4
2023-02-11 11:44:09,529 DEBUG TRAIN Batch 6/0 loss 11.959666 loss_att 8.774190 loss_ctc 12.489814 loss_rnnt 7.810688 hw_loss 0.884135 lr 0.00070633 rank 2
2023-02-11 11:44:09,532 DEBUG TRAIN Batch 6/0 loss 17.537447 loss_att 13.633679 loss_ctc 16.485861 loss_rnnt 13.135372 hw_loss 0.998070 lr 0.00070653 rank 0
2023-02-11 11:44:09,544 DEBUG TRAIN Batch 6/0 loss 13.918405 loss_att 9.996575 loss_ctc 13.691151 loss_rnnt 9.509379 hw_loss 0.979442 lr 0.00070697 rank 7
2023-02-11 11:44:09,613 DEBUG TRAIN Batch 6/0 loss 11.959940 loss_att 9.319344 loss_ctc 12.888909 loss_rnnt 8.306870 hw_loss 0.760749 lr 0.00070715 rank 6
2023-02-11 11:45:25,606 DEBUG TRAIN Batch 6/100 loss 30.647209 loss_att 33.137444 loss_ctc 42.020851 loss_rnnt 24.249954 hw_loss 0.821760 lr 0.00070627 rank 3
2023-02-11 11:45:25,610 DEBUG TRAIN Batch 6/100 loss 17.085945 loss_att 22.064041 loss_ctc 31.318810 loss_rnnt 10.327824 hw_loss 0.724648 lr 0.00070627 rank 7
2023-02-11 11:45:25,612 DEBUG TRAIN Batch 6/100 loss 25.690165 loss_att 30.057522 loss_ctc 39.569569 loss_rnnt 21.204229 hw_loss 0.330352 lr 0.00070644 rank 6
2023-02-11 11:45:25,614 DEBUG TRAIN Batch 6/100 loss 16.965906 loss_att 25.152355 loss_ctc 32.870857 loss_rnnt 12.029399 hw_loss 0.220980 lr 0.00070597 rank 1
2023-02-11 11:45:25,615 DEBUG TRAIN Batch 6/100 loss 15.199271 loss_att 24.619417 loss_ctc 26.029751 loss_rnnt 10.437949 hw_loss 0.268730 lr 0.00070582 rank 0
2023-02-11 11:45:25,618 DEBUG TRAIN Batch 6/100 loss 22.379057 loss_att 26.096504 loss_ctc 30.524693 loss_rnnt 19.692101 hw_loss 0.160759 lr 0.00070563 rank 2
2023-02-11 11:45:25,618 DEBUG TRAIN Batch 6/100 loss 31.367718 loss_att 35.822590 loss_ctc 54.371735 loss_rnnt 25.358936 hw_loss 0.384488 lr 0.00070613 rank 5
2023-02-11 11:45:25,618 DEBUG TRAIN Batch 6/100 loss 21.151836 loss_att 22.879049 loss_ctc 31.300011 loss_rnnt 19.089005 hw_loss 0.068306 lr 0.00070645 rank 4
2023-02-11 11:46:42,154 DEBUG TRAIN Batch 6/200 loss 8.042747 loss_att 13.222635 loss_ctc 11.017921 loss_rnnt 2.278080 hw_loss 0.812250 lr 0.00070556 rank 7
2023-02-11 11:46:42,155 DEBUG TRAIN Batch 6/200 loss 23.216850 loss_att 22.683807 loss_ctc 31.095327 loss_rnnt 19.100746 hw_loss 0.594797 lr 0.00070527 rank 1
2023-02-11 11:46:42,156 DEBUG TRAIN Batch 6/200 loss 22.101120 loss_att 26.070351 loss_ctc 33.314716 loss_rnnt 16.943966 hw_loss 0.537781 lr 0.00070574 rank 6
2023-02-11 11:46:42,157 DEBUG TRAIN Batch 6/200 loss 20.978769 loss_att 28.010731 loss_ctc 32.590012 loss_rnnt 14.466520 hw_loss 0.667067 lr 0.00070575 rank 4
2023-02-11 11:46:42,159 DEBUG TRAIN Batch 6/200 loss 21.000196 loss_att 26.763876 loss_ctc 32.186855 loss_rnnt 14.301429 hw_loss 0.760214 lr 0.00070556 rank 3
2023-02-11 11:46:42,159 DEBUG TRAIN Batch 6/200 loss 14.662240 loss_att 17.510830 loss_ctc 22.111973 loss_rnnt 11.573874 hw_loss 0.286003 lr 0.00070543 rank 5
2023-02-11 11:46:42,161 DEBUG TRAIN Batch 6/200 loss 19.102360 loss_att 24.056309 loss_ctc 26.484158 loss_rnnt 16.143559 hw_loss 0.184457 lr 0.00070512 rank 0
2023-02-11 11:46:42,165 DEBUG TRAIN Batch 6/200 loss 32.946701 loss_att 38.220268 loss_ctc 46.859859 loss_rnnt 26.905102 hw_loss 0.587213 lr 0.00070492 rank 2
2023-02-11 11:48:00,299 DEBUG TRAIN Batch 6/300 loss 15.522120 loss_att 20.189793 loss_ctc 26.865082 loss_rnnt 10.389454 hw_loss 0.503763 lr 0.00070486 rank 7
2023-02-11 11:48:00,300 DEBUG TRAIN Batch 6/300 loss 22.764107 loss_att 25.337313 loss_ctc 33.608719 loss_rnnt 18.902182 hw_loss 0.356501 lr 0.00070442 rank 0
2023-02-11 11:48:00,303 DEBUG TRAIN Batch 6/300 loss 22.978554 loss_att 26.339403 loss_ctc 38.214062 loss_rnnt 18.440510 hw_loss 0.343963 lr 0.00070486 rank 3
2023-02-11 11:48:00,305 DEBUG TRAIN Batch 6/300 loss 30.907997 loss_att 33.341408 loss_ctc 45.544132 loss_rnnt 24.697006 hw_loss 0.707405 lr 0.00070473 rank 5
2023-02-11 11:48:00,305 DEBUG TRAIN Batch 6/300 loss 18.897806 loss_att 25.021338 loss_ctc 28.091434 loss_rnnt 12.250957 hw_loss 0.786811 lr 0.00070457 rank 1
2023-02-11 11:48:00,306 DEBUG TRAIN Batch 6/300 loss 26.937031 loss_att 30.857483 loss_ctc 40.889774 loss_rnnt 21.523954 hw_loss 0.519117 lr 0.00070423 rank 2
2023-02-11 11:48:00,308 DEBUG TRAIN Batch 6/300 loss 21.923719 loss_att 23.716755 loss_ctc 31.854721 loss_rnnt 16.325748 hw_loss 0.734106 lr 0.00070504 rank 4
2023-02-11 11:48:00,351 DEBUG TRAIN Batch 6/300 loss 18.594423 loss_att 20.077791 loss_ctc 22.086012 loss_rnnt 14.073776 hw_loss 0.704705 lr 0.00070504 rank 6
2023-02-11 11:49:16,985 DEBUG TRAIN Batch 6/400 loss 21.884195 loss_att 23.456505 loss_ctc 26.940742 loss_rnnt 18.757505 hw_loss 0.400879 lr 0.00070416 rank 7
2023-02-11 11:49:16,986 DEBUG TRAIN Batch 6/400 loss 20.886026 loss_att 21.449081 loss_ctc 27.988213 loss_rnnt 15.925913 hw_loss 0.731352 lr 0.00070416 rank 3
2023-02-11 11:49:16,986 DEBUG TRAIN Batch 6/400 loss 37.440208 loss_att 39.056374 loss_ctc 49.508183 loss_rnnt 30.919928 hw_loss 0.860247 lr 0.00070372 rank 0
2023-02-11 11:49:16,986 DEBUG TRAIN Batch 6/400 loss 17.491556 loss_att 22.341362 loss_ctc 30.603218 loss_rnnt 12.358912 hw_loss 0.452711 lr 0.00070387 rank 1
2023-02-11 11:49:16,987 DEBUG TRAIN Batch 6/400 loss 21.544363 loss_att 21.585041 loss_ctc 30.658533 loss_rnnt 15.912797 hw_loss 0.826539 lr 0.00070353 rank 2
2023-02-11 11:49:16,989 DEBUG TRAIN Batch 6/400 loss 27.865368 loss_att 31.478992 loss_ctc 34.082787 loss_rnnt 21.291660 hw_loss 0.941624 lr 0.00070434 rank 6
2023-02-11 11:49:16,991 DEBUG TRAIN Batch 6/400 loss 16.229052 loss_att 19.825275 loss_ctc 22.347635 loss_rnnt 12.575303 hw_loss 0.397255 lr 0.00070403 rank 5
2023-02-11 11:49:17,032 DEBUG TRAIN Batch 6/400 loss 17.187363 loss_att 21.980034 loss_ctc 22.567139 loss_rnnt 11.407522 hw_loss 0.769501 lr 0.00070434 rank 4
2023-02-11 11:50:34,529 DEBUG TRAIN Batch 6/500 loss 13.817554 loss_att 16.029087 loss_ctc 21.961472 loss_rnnt 10.623959 hw_loss 0.312269 lr 0.00070347 rank 3
2023-02-11 11:50:34,530 DEBUG TRAIN Batch 6/500 loss 13.538214 loss_att 15.829903 loss_ctc 25.138096 loss_rnnt 9.142372 hw_loss 0.448285 lr 0.00070303 rank 0
2023-02-11 11:50:34,531 DEBUG TRAIN Batch 6/500 loss 19.261726 loss_att 21.088264 loss_ctc 24.670830 loss_rnnt 17.028463 hw_loss 0.215014 lr 0.00070347 rank 7
2023-02-11 11:50:34,533 DEBUG TRAIN Batch 6/500 loss 20.111612 loss_att 20.928730 loss_ctc 26.641546 loss_rnnt 16.504637 hw_loss 0.482418 lr 0.00070364 rank 6
2023-02-11 11:50:34,534 DEBUG TRAIN Batch 6/500 loss 19.757137 loss_att 20.002308 loss_ctc 28.284561 loss_rnnt 13.531698 hw_loss 0.944890 lr 0.00070333 rank 5
2023-02-11 11:50:34,534 DEBUG TRAIN Batch 6/500 loss 14.664926 loss_att 15.488596 loss_ctc 21.017288 loss_rnnt 11.301389 hw_loss 0.440966 lr 0.00070283 rank 2
2023-02-11 11:50:34,535 DEBUG TRAIN Batch 6/500 loss 32.923096 loss_att 36.069546 loss_ctc 49.677734 loss_rnnt 28.509222 hw_loss 0.290744 lr 0.00070365 rank 4
2023-02-11 11:50:34,580 DEBUG TRAIN Batch 6/500 loss 15.683120 loss_att 17.678394 loss_ctc 27.634352 loss_rnnt 10.118232 hw_loss 0.669813 lr 0.00070317 rank 1
2023-02-11 11:51:51,939 DEBUG TRAIN Batch 6/600 loss 12.780199 loss_att 10.187854 loss_ctc 12.724779 loss_rnnt 7.502936 hw_loss 1.088085 lr 0.00070248 rank 1
2023-02-11 11:51:51,944 DEBUG TRAIN Batch 6/600 loss 15.087250 loss_att 14.841273 loss_ctc 20.877069 loss_rnnt 10.854828 hw_loss 0.658058 lr 0.00070277 rank 3
2023-02-11 11:51:51,944 DEBUG TRAIN Batch 6/600 loss 15.511159 loss_att 16.627724 loss_ctc 19.275251 loss_rnnt 10.841585 hw_loss 0.739571 lr 0.00070214 rank 2
2023-02-11 11:51:51,944 DEBUG TRAIN Batch 6/600 loss 15.311062 loss_att 11.690025 loss_ctc 16.167452 loss_rnnt 10.791989 hw_loss 0.961705 lr 0.00070233 rank 0
2023-02-11 11:51:51,945 DEBUG TRAIN Batch 6/600 loss 20.853699 loss_att 20.884802 loss_ctc 26.900536 loss_rnnt 15.603512 hw_loss 0.832072 lr 0.00070264 rank 5
2023-02-11 11:51:51,946 DEBUG TRAIN Batch 6/600 loss 23.858423 loss_att 31.017792 loss_ctc 37.848473 loss_rnnt 18.839933 hw_loss 0.322739 lr 0.00070295 rank 4
2023-02-11 11:51:51,949 DEBUG TRAIN Batch 6/600 loss 19.991068 loss_att 19.224062 loss_ctc 25.298189 loss_rnnt 15.328102 hw_loss 0.770390 lr 0.00070277 rank 7
2023-02-11 11:51:51,950 DEBUG TRAIN Batch 6/600 loss 18.191185 loss_att 13.825682 loss_ctc 17.930307 loss_rnnt 10.729088 hw_loss 1.569371 lr 0.00070294 rank 6
2023-02-11 11:53:10,407 DEBUG TRAIN Batch 6/700 loss 11.087736 loss_att 14.645274 loss_ctc 17.613865 loss_rnnt 5.718116 hw_loss 0.710243 lr 0.00070208 rank 3
2023-02-11 11:53:10,410 DEBUG TRAIN Batch 6/700 loss 18.014221 loss_att 22.245728 loss_ctc 27.113272 loss_rnnt 14.520979 hw_loss 0.268825 lr 0.00070164 rank 0
2023-02-11 11:53:10,415 DEBUG TRAIN Batch 6/700 loss 17.089029 loss_att 25.021111 loss_ctc 31.845037 loss_rnnt 11.405268 hw_loss 0.399352 lr 0.00070195 rank 5
2023-02-11 11:53:10,416 DEBUG TRAIN Batch 6/700 loss 21.905987 loss_att 29.150866 loss_ctc 30.586086 loss_rnnt 15.417931 hw_loss 0.727825 lr 0.00070208 rank 7
2023-02-11 11:53:10,422 DEBUG TRAIN Batch 6/700 loss 13.327526 loss_att 15.642079 loss_ctc 23.578518 loss_rnnt 8.827277 hw_loss 0.500726 lr 0.00070226 rank 4
2023-02-11 11:53:10,423 DEBUG TRAIN Batch 6/700 loss 11.352476 loss_att 17.080513 loss_ctc 17.009777 loss_rnnt 8.274538 hw_loss 0.220880 lr 0.00070179 rank 1
2023-02-11 11:53:10,427 DEBUG TRAIN Batch 6/700 loss 23.529551 loss_att 26.630756 loss_ctc 34.254631 loss_rnnt 19.753506 hw_loss 0.323586 lr 0.00070225 rank 6
2023-02-11 11:53:10,465 DEBUG TRAIN Batch 6/700 loss 43.887287 loss_att 46.653938 loss_ctc 66.259598 loss_rnnt 38.170616 hw_loss 0.408818 lr 0.00070145 rank 2
2023-02-11 11:54:25,509 DEBUG TRAIN Batch 6/800 loss 14.989794 loss_att 17.554178 loss_ctc 23.821844 loss_rnnt 12.838698 hw_loss 0.086365 lr 0.00070095 rank 0
2023-02-11 11:54:25,511 DEBUG TRAIN Batch 6/800 loss 25.291939 loss_att 28.626120 loss_ctc 38.118443 loss_rnnt 20.990591 hw_loss 0.360809 lr 0.00070076 rank 2
2023-02-11 11:54:25,513 DEBUG TRAIN Batch 6/800 loss 14.349154 loss_att 17.134748 loss_ctc 17.020937 loss_rnnt 9.951550 hw_loss 0.653296 lr 0.00070157 rank 4
2023-02-11 11:54:25,516 DEBUG TRAIN Batch 6/800 loss 23.449411 loss_att 29.255676 loss_ctc 44.301086 loss_rnnt 17.109310 hw_loss 0.449742 lr 0.00070139 rank 3
2023-02-11 11:54:25,516 DEBUG TRAIN Batch 6/800 loss 13.192403 loss_att 13.973014 loss_ctc 18.905903 loss_rnnt 9.628714 hw_loss 0.496081 lr 0.00070139 rank 7
2023-02-11 11:54:25,519 DEBUG TRAIN Batch 6/800 loss 19.997080 loss_att 23.959780 loss_ctc 28.054077 loss_rnnt 16.490009 hw_loss 0.307549 lr 0.00070125 rank 5
2023-02-11 11:54:25,518 DEBUG TRAIN Batch 6/800 loss 12.153049 loss_att 15.774083 loss_ctc 20.473394 loss_rnnt 8.291652 hw_loss 0.380215 lr 0.00070110 rank 1
2023-02-11 11:54:25,520 DEBUG TRAIN Batch 6/800 loss 21.388142 loss_att 21.798820 loss_ctc 24.624954 loss_rnnt 18.820692 hw_loss 0.385076 lr 0.00070156 rank 6
2023-02-11 11:55:40,525 DEBUG TRAIN Batch 6/900 loss 12.673155 loss_att 18.906860 loss_ctc 19.773396 loss_rnnt 10.007939 hw_loss 0.088458 lr 0.00070070 rank 3
2023-02-11 11:55:40,527 DEBUG TRAIN Batch 6/900 loss 15.571352 loss_att 20.605757 loss_ctc 25.007969 loss_rnnt 10.840075 hw_loss 0.462408 lr 0.00070041 rank 1
2023-02-11 11:55:40,527 DEBUG TRAIN Batch 6/900 loss 20.516949 loss_att 23.713953 loss_ctc 32.875751 loss_rnnt 16.914398 hw_loss 0.246620 lr 0.00070070 rank 7
2023-02-11 11:55:40,530 DEBUG TRAIN Batch 6/900 loss 20.338951 loss_att 22.096313 loss_ctc 26.810852 loss_rnnt 16.445475 hw_loss 0.502328 lr 0.00070088 rank 4
2023-02-11 11:55:40,531 DEBUG TRAIN Batch 6/900 loss 19.303534 loss_att 24.056997 loss_ctc 33.916061 loss_rnnt 14.729659 hw_loss 0.314033 lr 0.00070007 rank 2
2023-02-11 11:55:40,531 DEBUG TRAIN Batch 6/900 loss 11.846008 loss_att 14.400997 loss_ctc 14.036067 loss_rnnt 6.205782 hw_loss 0.906979 lr 0.00070026 rank 0
2023-02-11 11:55:40,534 DEBUG TRAIN Batch 6/900 loss 18.294777 loss_att 21.704523 loss_ctc 34.262871 loss_rnnt 14.904211 hw_loss 0.108663 lr 0.00070087 rank 6
2023-02-11 11:55:40,535 DEBUG TRAIN Batch 6/900 loss 23.870867 loss_att 27.360933 loss_ctc 34.251183 loss_rnnt 18.520145 hw_loss 0.612874 lr 0.00070057 rank 5
2023-02-11 11:56:58,419 DEBUG TRAIN Batch 6/1000 loss 26.802950 loss_att 27.972893 loss_ctc 33.204876 loss_rnnt 22.066727 hw_loss 0.684121 lr 0.00070001 rank 3
2023-02-11 11:56:58,422 DEBUG TRAIN Batch 6/1000 loss 19.870842 loss_att 22.532675 loss_ctc 25.264355 loss_rnnt 16.083012 hw_loss 0.475562 lr 0.00069972 rank 1
2023-02-11 11:56:58,422 DEBUG TRAIN Batch 6/1000 loss 12.260934 loss_att 16.800953 loss_ctc 16.179401 loss_rnnt 9.054938 hw_loss 0.332912 lr 0.00069988 rank 5
2023-02-11 11:56:58,423 DEBUG TRAIN Batch 6/1000 loss 14.140504 loss_att 17.571741 loss_ctc 22.188477 loss_rnnt 9.997639 hw_loss 0.446916 lr 0.00070001 rank 7
2023-02-11 11:56:58,423 DEBUG TRAIN Batch 6/1000 loss 9.494017 loss_att 10.522985 loss_ctc 13.904206 loss_rnnt 7.274626 hw_loss 0.267295 lr 0.00070019 rank 4
2023-02-11 11:56:58,423 DEBUG TRAIN Batch 6/1000 loss 24.149124 loss_att 28.694984 loss_ctc 33.134602 loss_rnnt 19.988018 hw_loss 0.385100 lr 0.00070018 rank 6
2023-02-11 11:56:58,427 DEBUG TRAIN Batch 6/1000 loss 16.575897 loss_att 18.787008 loss_ctc 27.101187 loss_rnnt 13.118122 hw_loss 0.302284 lr 0.00069958 rank 0
2023-02-11 11:56:58,429 DEBUG TRAIN Batch 6/1000 loss 17.155598 loss_att 19.114126 loss_ctc 26.764645 loss_rnnt 12.375935 hw_loss 0.582516 lr 0.00069939 rank 2
2023-02-11 11:58:17,364 DEBUG TRAIN Batch 6/1100 loss 10.903141 loss_att 13.966780 loss_ctc 22.513777 loss_rnnt 7.828968 hw_loss 0.171255 lr 0.00069932 rank 3
2023-02-11 11:58:17,368 DEBUG TRAIN Batch 6/1100 loss 22.615473 loss_att 20.892952 loss_ctc 35.125397 loss_rnnt 19.232456 hw_loss 0.386162 lr 0.00069950 rank 4
2023-02-11 11:58:17,369 DEBUG TRAIN Batch 6/1100 loss 15.487037 loss_att 21.406384 loss_ctc 22.115747 loss_rnnt 11.731392 hw_loss 0.316490 lr 0.00069904 rank 1
2023-02-11 11:58:17,369 DEBUG TRAIN Batch 6/1100 loss 17.369324 loss_att 20.773426 loss_ctc 26.545275 loss_rnnt 13.928774 hw_loss 0.288050 lr 0.00069932 rank 7
2023-02-11 11:58:17,369 DEBUG TRAIN Batch 6/1100 loss 20.249369 loss_att 20.625505 loss_ctc 24.490875 loss_rnnt 15.077835 hw_loss 0.849520 lr 0.00069870 rank 2
2023-02-11 11:58:17,370 DEBUG TRAIN Batch 6/1100 loss 14.839198 loss_att 18.466616 loss_ctc 28.175808 loss_rnnt 10.639088 hw_loss 0.318077 lr 0.00069950 rank 6
2023-02-11 11:58:17,370 DEBUG TRAIN Batch 6/1100 loss 26.991966 loss_att 29.382805 loss_ctc 37.561665 loss_rnnt 23.254105 hw_loss 0.346950 lr 0.00069889 rank 0
2023-02-11 11:58:17,371 DEBUG TRAIN Batch 6/1100 loss 14.562974 loss_att 16.030556 loss_ctc 20.783398 loss_rnnt 11.111499 hw_loss 0.436607 lr 0.00069919 rank 5
2023-02-11 11:59:32,921 DEBUG TRAIN Batch 6/1200 loss 20.358433 loss_att 20.563400 loss_ctc 33.599010 loss_rnnt 16.107180 hw_loss 0.458409 lr 0.00069864 rank 3
2023-02-11 11:59:32,921 DEBUG TRAIN Batch 6/1200 loss 11.015232 loss_att 13.662316 loss_ctc 18.936516 loss_rnnt 6.609716 hw_loss 0.528737 lr 0.00069836 rank 1
2023-02-11 11:59:32,925 DEBUG TRAIN Batch 6/1200 loss 20.169731 loss_att 18.603981 loss_ctc 25.670532 loss_rnnt 15.701533 hw_loss 0.758982 lr 0.00069882 rank 4
2023-02-11 11:59:32,927 DEBUG TRAIN Batch 6/1200 loss 14.345959 loss_att 15.996375 loss_ctc 19.348455 loss_rnnt 12.054708 hw_loss 0.242657 lr 0.00069864 rank 7
2023-02-11 11:59:32,927 DEBUG TRAIN Batch 6/1200 loss 19.879606 loss_att 19.363686 loss_ctc 26.058962 loss_rnnt 15.665949 hw_loss 0.654924 lr 0.00069881 rank 6
2023-02-11 11:59:32,928 DEBUG TRAIN Batch 6/1200 loss 13.718949 loss_att 10.925399 loss_ctc 14.216602 loss_rnnt 8.823341 hw_loss 1.010243 lr 0.00069802 rank 2
2023-02-11 11:59:32,928 DEBUG TRAIN Batch 6/1200 loss 15.982299 loss_att 21.485889 loss_ctc 24.198902 loss_rnnt 11.787827 hw_loss 0.374664 lr 0.00069851 rank 5
2023-02-11 11:59:32,929 DEBUG TRAIN Batch 6/1200 loss 18.296127 loss_att 17.520115 loss_ctc 27.945089 loss_rnnt 13.018484 hw_loss 0.777435 lr 0.00069821 rank 0
2023-02-11 12:00:48,307 DEBUG TRAIN Batch 6/1300 loss 22.112270 loss_att 23.517553 loss_ctc 31.822577 loss_rnnt 18.685036 hw_loss 0.347151 lr 0.00069796 rank 3
2023-02-11 12:00:48,308 DEBUG TRAIN Batch 6/1300 loss 18.268953 loss_att 21.813478 loss_ctc 29.732891 loss_rnnt 13.058192 hw_loss 0.557500 lr 0.00069813 rank 6
2023-02-11 12:00:48,308 DEBUG TRAIN Batch 6/1300 loss 15.646250 loss_att 22.493652 loss_ctc 32.757843 loss_rnnt 10.057674 hw_loss 0.363290 lr 0.00069768 rank 1
2023-02-11 12:00:48,310 DEBUG TRAIN Batch 6/1300 loss 18.527103 loss_att 21.931770 loss_ctc 26.907501 loss_rnnt 14.807415 hw_loss 0.360256 lr 0.00069796 rank 7
2023-02-11 12:00:48,310 DEBUG TRAIN Batch 6/1300 loss 19.142050 loss_att 23.121895 loss_ctc 25.723637 loss_rnnt 16.390038 hw_loss 0.202218 lr 0.00069734 rank 2
2023-02-11 12:00:48,310 DEBUG TRAIN Batch 6/1300 loss 33.860840 loss_att 40.262302 loss_ctc 48.674038 loss_rnnt 27.956081 hw_loss 0.496758 lr 0.00069783 rank 5
2023-02-11 12:00:48,311 DEBUG TRAIN Batch 6/1300 loss 9.866501 loss_att 16.167229 loss_ctc 13.573650 loss_rnnt 7.258189 hw_loss 0.160102 lr 0.00069753 rank 0
2023-02-11 12:00:48,312 DEBUG TRAIN Batch 6/1300 loss 15.014355 loss_att 22.736361 loss_ctc 29.666637 loss_rnnt 9.882555 hw_loss 0.306330 lr 0.00069814 rank 4
2023-02-11 12:02:06,193 DEBUG TRAIN Batch 6/1400 loss 18.312601 loss_att 21.701494 loss_ctc 34.739487 loss_rnnt 13.343455 hw_loss 0.393959 lr 0.00069728 rank 3
2023-02-11 12:02:06,195 DEBUG TRAIN Batch 6/1400 loss 30.955624 loss_att 36.683701 loss_ctc 51.676147 loss_rnnt 25.965008 hw_loss 0.202925 lr 0.00069685 rank 0
2023-02-11 12:02:06,198 DEBUG TRAIN Batch 6/1400 loss 16.238525 loss_att 19.782757 loss_ctc 29.886639 loss_rnnt 12.148879 hw_loss 0.292697 lr 0.00069700 rank 1
2023-02-11 12:02:06,203 DEBUG TRAIN Batch 6/1400 loss 17.689983 loss_att 20.191271 loss_ctc 25.540245 loss_rnnt 12.661848 hw_loss 0.652720 lr 0.00069715 rank 5
2023-02-11 12:02:06,204 DEBUG TRAIN Batch 6/1400 loss 23.501329 loss_att 26.350639 loss_ctc 35.315159 loss_rnnt 18.757553 hw_loss 0.487263 lr 0.00069746 rank 4
2023-02-11 12:02:06,204 DEBUG TRAIN Batch 6/1400 loss 20.657457 loss_att 23.193132 loss_ctc 30.516424 loss_rnnt 17.919266 hw_loss 0.171849 lr 0.00069667 rank 2
2023-02-11 12:02:06,205 DEBUG TRAIN Batch 6/1400 loss 11.998223 loss_att 16.144676 loss_ctc 20.379959 loss_rnnt 8.109683 hw_loss 0.364066 lr 0.00069728 rank 7
2023-02-11 12:02:06,207 DEBUG TRAIN Batch 6/1400 loss 15.724748 loss_att 16.896294 loss_ctc 24.093349 loss_rnnt 12.644669 hw_loss 0.324367 lr 0.00069745 rank 6
2023-02-11 12:03:22,279 DEBUG TRAIN Batch 6/1500 loss 20.958979 loss_att 26.253193 loss_ctc 29.145048 loss_rnnt 15.483366 hw_loss 0.623493 lr 0.00069660 rank 3
2023-02-11 12:03:22,284 DEBUG TRAIN Batch 6/1500 loss 12.173413 loss_att 15.916538 loss_ctc 22.440306 loss_rnnt 8.356188 hw_loss 0.318690 lr 0.00069599 rank 2
2023-02-11 12:03:22,287 DEBUG TRAIN Batch 6/1500 loss 16.507713 loss_att 17.686176 loss_ctc 25.755087 loss_rnnt 10.991417 hw_loss 0.758929 lr 0.00069677 rank 6
2023-02-11 12:03:22,286 DEBUG TRAIN Batch 6/1500 loss 12.948167 loss_att 15.732830 loss_ctc 16.985558 loss_rnnt 9.450748 hw_loss 0.450406 lr 0.00069660 rank 7
2023-02-11 12:03:22,287 DEBUG TRAIN Batch 6/1500 loss 17.051662 loss_att 20.365894 loss_ctc 28.147274 loss_rnnt 12.238318 hw_loss 0.500828 lr 0.00069618 rank 0
2023-02-11 12:03:22,288 DEBUG TRAIN Batch 6/1500 loss 22.515057 loss_att 28.441240 loss_ctc 36.129326 loss_rnnt 16.708817 hw_loss 0.526082 lr 0.00069678 rank 4
2023-02-11 12:03:22,292 DEBUG TRAIN Batch 6/1500 loss 12.034734 loss_att 14.580235 loss_ctc 15.035705 loss_rnnt 8.875529 hw_loss 0.421870 lr 0.00069648 rank 5
2023-02-11 12:03:22,297 DEBUG TRAIN Batch 6/1500 loss 28.712437 loss_att 30.702728 loss_ctc 36.648720 loss_rnnt 24.852461 hw_loss 0.450702 lr 0.00069632 rank 1
2023-02-11 12:04:38,264 DEBUG TRAIN Batch 6/1600 loss 12.805597 loss_att 19.373505 loss_ctc 22.107735 loss_rnnt 9.762604 hw_loss 0.091711 lr 0.00069551 rank 0
2023-02-11 12:04:38,266 DEBUG TRAIN Batch 6/1600 loss 27.075651 loss_att 32.487026 loss_ctc 31.892139 loss_rnnt 23.128353 hw_loss 0.416780 lr 0.00069593 rank 3
2023-02-11 12:04:38,271 DEBUG TRAIN Batch 6/1600 loss 13.253944 loss_att 17.672110 loss_ctc 26.636477 loss_rnnt 9.030887 hw_loss 0.291579 lr 0.00069593 rank 7
2023-02-11 12:04:38,273 DEBUG TRAIN Batch 6/1600 loss 20.303421 loss_att 23.080452 loss_ctc 35.617397 loss_rnnt 16.094635 hw_loss 0.302159 lr 0.00069610 rank 6
2023-02-11 12:04:38,281 DEBUG TRAIN Batch 6/1600 loss 13.772039 loss_att 18.181038 loss_ctc 25.184820 loss_rnnt 10.299021 hw_loss 0.200534 lr 0.00069580 rank 5
2023-02-11 12:04:38,295 DEBUG TRAIN Batch 6/1600 loss 23.249699 loss_att 29.096270 loss_ctc 41.976658 loss_rnnt 18.571465 hw_loss 0.189748 lr 0.00069532 rank 2
2023-02-11 12:04:38,304 DEBUG TRAIN Batch 6/1600 loss 24.104933 loss_att 28.001381 loss_ctc 40.710419 loss_rnnt 17.519058 hw_loss 0.673598 lr 0.00069565 rank 1
2023-02-11 12:04:38,320 DEBUG TRAIN Batch 6/1600 loss 36.157841 loss_att 39.568729 loss_ctc 50.410988 loss_rnnt 32.337196 hw_loss 0.232134 lr 0.00069610 rank 4
2023-02-11 12:05:54,565 DEBUG TRAIN Batch 6/1700 loss 25.149172 loss_att 24.295963 loss_ctc 41.685707 loss_rnnt 21.379211 hw_loss 0.325449 lr 0.00069513 rank 5
2023-02-11 12:05:54,569 DEBUG TRAIN Batch 6/1700 loss 19.527054 loss_att 20.163260 loss_ctc 26.322327 loss_rnnt 15.065192 hw_loss 0.642860 lr 0.00069497 rank 1
2023-02-11 12:05:54,570 DEBUG TRAIN Batch 6/1700 loss 28.271715 loss_att 27.675058 loss_ctc 41.028225 loss_rnnt 23.551571 hw_loss 0.588489 lr 0.00069526 rank 3
2023-02-11 12:05:54,570 DEBUG TRAIN Batch 6/1700 loss 20.234900 loss_att 23.076401 loss_ctc 36.651215 loss_rnnt 13.493952 hw_loss 0.746963 lr 0.00069543 rank 4
2023-02-11 12:05:54,570 DEBUG TRAIN Batch 6/1700 loss 20.315634 loss_att 22.315178 loss_ctc 24.890997 loss_rnnt 14.152311 hw_loss 0.966256 lr 0.00069526 rank 7
2023-02-11 12:05:54,571 DEBUG TRAIN Batch 6/1700 loss 17.351395 loss_att 18.730061 loss_ctc 29.385048 loss_rnnt 13.922182 hw_loss 0.290436 lr 0.00069465 rank 2
2023-02-11 12:05:54,572 DEBUG TRAIN Batch 6/1700 loss 26.572077 loss_att 27.869839 loss_ctc 44.499397 loss_rnnt 22.484529 hw_loss 0.269566 lr 0.00069483 rank 0
2023-02-11 12:05:54,578 DEBUG TRAIN Batch 6/1700 loss 15.426161 loss_att 20.829142 loss_ctc 31.265041 loss_rnnt 11.119868 hw_loss 0.208846 lr 0.00069542 rank 6
2023-02-11 12:07:13,645 DEBUG TRAIN Batch 6/1800 loss 18.979618 loss_att 17.909550 loss_ctc 25.665745 loss_rnnt 14.847935 hw_loss 0.647665 lr 0.00069459 rank 7
2023-02-11 12:07:13,646 DEBUG TRAIN Batch 6/1800 loss 18.944239 loss_att 19.542162 loss_ctc 28.691538 loss_rnnt 12.347887 hw_loss 0.970711 lr 0.00069476 rank 4
2023-02-11 12:07:13,649 DEBUG TRAIN Batch 6/1800 loss 14.848389 loss_att 17.214649 loss_ctc 20.389322 loss_rnnt 11.446364 hw_loss 0.410622 lr 0.00069430 rank 1
2023-02-11 12:07:13,650 DEBUG TRAIN Batch 6/1800 loss 15.731089 loss_att 15.249662 loss_ctc 22.200363 loss_rnnt 11.168084 hw_loss 0.711885 lr 0.00069446 rank 5
2023-02-11 12:07:13,652 DEBUG TRAIN Batch 6/1800 loss 28.294531 loss_att 24.958426 loss_ctc 35.658901 loss_rnnt 21.863867 hw_loss 1.146744 lr 0.00069475 rank 6
2023-02-11 12:07:13,680 DEBUG TRAIN Batch 6/1800 loss 15.734347 loss_att 16.693819 loss_ctc 22.199835 loss_rnnt 11.703588 hw_loss 0.558150 lr 0.00069416 rank 0
2023-02-11 12:07:13,690 DEBUG TRAIN Batch 6/1800 loss 15.277151 loss_att 18.140490 loss_ctc 27.072210 loss_rnnt 10.256550 hw_loss 0.539111 lr 0.00069459 rank 3
2023-02-11 12:07:13,711 DEBUG TRAIN Batch 6/1800 loss 18.343998 loss_att 18.700827 loss_ctc 25.856131 loss_rnnt 13.353226 hw_loss 0.734585 lr 0.00069398 rank 2
2023-02-11 12:08:31,003 DEBUG TRAIN Batch 6/1900 loss 16.047976 loss_att 17.128841 loss_ctc 25.163290 loss_rnnt 12.726482 hw_loss 0.354365 lr 0.00069392 rank 7
2023-02-11 12:08:31,004 DEBUG TRAIN Batch 6/1900 loss 16.754305 loss_att 16.980461 loss_ctc 19.624451 loss_rnnt 12.672185 hw_loss 0.685163 lr 0.00069350 rank 0
2023-02-11 12:08:31,009 DEBUG TRAIN Batch 6/1900 loss 34.998886 loss_att 40.426521 loss_ctc 56.620483 loss_rnnt 29.126282 hw_loss 0.357036 lr 0.00069331 rank 2
2023-02-11 12:08:31,009 DEBUG TRAIN Batch 6/1900 loss 23.044500 loss_att 26.115273 loss_ctc 31.688549 loss_rnnt 19.225201 hw_loss 0.384864 lr 0.00069409 rank 4
2023-02-11 12:08:31,011 DEBUG TRAIN Batch 6/1900 loss 16.004749 loss_att 13.338210 loss_ctc 16.994011 loss_rnnt 9.829535 hw_loss 1.233116 lr 0.00069364 rank 1
2023-02-11 12:08:31,013 DEBUG TRAIN Batch 6/1900 loss 16.356232 loss_att 12.039192 loss_ctc 16.676914 loss_rnnt 10.988965 hw_loss 1.160234 lr 0.00069392 rank 3
2023-02-11 12:08:31,015 DEBUG TRAIN Batch 6/1900 loss 20.946545 loss_att 21.426004 loss_ctc 34.331062 loss_rnnt 15.566434 hw_loss 0.656178 lr 0.00069379 rank 5
2023-02-11 12:08:31,064 DEBUG TRAIN Batch 6/1900 loss 16.671017 loss_att 12.944903 loss_ctc 17.029243 loss_rnnt 10.737189 hw_loss 1.243366 lr 0.00069408 rank 6
2023-02-11 12:09:46,767 DEBUG TRAIN Batch 6/2000 loss 32.253342 loss_att 36.633892 loss_ctc 54.984192 loss_rnnt 26.770943 hw_loss 0.295409 lr 0.00069325 rank 7
2023-02-11 12:09:46,767 DEBUG TRAIN Batch 6/2000 loss 26.523056 loss_att 30.973185 loss_ctc 35.939663 loss_rnnt 21.613846 hw_loss 0.518182 lr 0.00069325 rank 3
2023-02-11 12:09:46,769 DEBUG TRAIN Batch 6/2000 loss 22.020113 loss_att 23.076395 loss_ctc 36.580875 loss_rnnt 16.382477 hw_loss 0.653427 lr 0.00069342 rank 4
2023-02-11 12:09:46,770 DEBUG TRAIN Batch 6/2000 loss 21.261595 loss_att 22.674835 loss_ctc 27.779301 loss_rnnt 18.278019 hw_loss 0.343481 lr 0.00069297 rank 1
2023-02-11 12:09:46,772 DEBUG TRAIN Batch 6/2000 loss 18.643370 loss_att 19.276161 loss_ctc 27.822592 loss_rnnt 15.281197 hw_loss 0.377197 lr 0.00069312 rank 5
2023-02-11 12:09:46,772 DEBUG TRAIN Batch 6/2000 loss 33.404602 loss_att 38.333801 loss_ctc 41.918911 loss_rnnt 26.452816 hw_loss 0.905757 lr 0.00069283 rank 0
2023-02-11 12:09:46,773 DEBUG TRAIN Batch 6/2000 loss 19.100983 loss_att 20.429155 loss_ctc 25.944134 loss_rnnt 12.958471 hw_loss 0.930836 lr 0.00069342 rank 6
2023-02-11 12:09:46,825 DEBUG TRAIN Batch 6/2000 loss 21.293571 loss_att 22.804100 loss_ctc 26.587196 loss_rnnt 17.787970 hw_loss 0.468315 lr 0.00069264 rank 2
2023-02-11 12:11:04,603 DEBUG TRAIN Batch 6/2100 loss 24.347677 loss_att 28.576488 loss_ctc 39.239223 loss_rnnt 19.114746 hw_loss 0.450305 lr 0.00069198 rank 2
2023-02-11 12:11:04,604 DEBUG TRAIN Batch 6/2100 loss 10.602353 loss_att 17.406988 loss_ctc 12.399321 loss_rnnt 7.989225 hw_loss 0.189863 lr 0.00069246 rank 5
2023-02-11 12:11:04,605 DEBUG TRAIN Batch 6/2100 loss 21.269310 loss_att 21.180401 loss_ctc 33.782406 loss_rnnt 16.442556 hw_loss 0.595523 lr 0.00069258 rank 3
2023-02-11 12:11:04,608 DEBUG TRAIN Batch 6/2100 loss 8.940407 loss_att 11.643395 loss_ctc 12.370689 loss_rnnt 5.282173 hw_loss 0.498800 lr 0.00069217 rank 0
2023-02-11 12:11:04,611 DEBUG TRAIN Batch 6/2100 loss 27.113970 loss_att 29.560844 loss_ctc 39.659111 loss_rnnt 21.010611 hw_loss 0.738993 lr 0.00069258 rank 7
2023-02-11 12:11:04,613 DEBUG TRAIN Batch 6/2100 loss 30.314405 loss_att 26.620401 loss_ctc 39.495728 loss_rnnt 25.815033 hw_loss 0.752624 lr 0.00069275 rank 6
2023-02-11 12:11:04,614 DEBUG TRAIN Batch 6/2100 loss 17.788239 loss_att 28.192623 loss_ctc 27.741985 loss_rnnt 13.288549 hw_loss 0.204684 lr 0.00069230 rank 1
2023-02-11 12:11:04,614 DEBUG TRAIN Batch 6/2100 loss 20.040527 loss_att 20.099075 loss_ctc 32.088924 loss_rnnt 15.710410 hw_loss 0.508491 lr 0.00069276 rank 4
2023-02-11 12:12:21,262 DEBUG TRAIN Batch 6/2200 loss 13.880075 loss_att 15.875305 loss_ctc 17.709593 loss_rnnt 10.096432 hw_loss 0.538874 lr 0.00069132 rank 2
2023-02-11 12:12:21,262 DEBUG TRAIN Batch 6/2200 loss 17.171459 loss_att 20.405285 loss_ctc 27.173355 loss_rnnt 12.396868 hw_loss 0.523920 lr 0.00069179 rank 5
2023-02-11 12:12:21,264 DEBUG TRAIN Batch 6/2200 loss 25.548418 loss_att 27.411707 loss_ctc 37.913513 loss_rnnt 19.205650 hw_loss 0.810268 lr 0.00069150 rank 0
2023-02-11 12:12:21,265 DEBUG TRAIN Batch 6/2200 loss 16.470261 loss_att 17.621660 loss_ctc 21.365370 loss_rnnt 14.213017 hw_loss 0.257678 lr 0.00069192 rank 7
2023-02-11 12:12:21,266 DEBUG TRAIN Batch 6/2200 loss 7.866514 loss_att 11.603479 loss_ctc 14.796738 loss_rnnt 3.604892 hw_loss 0.485662 lr 0.00069192 rank 3
2023-02-11 12:12:21,267 DEBUG TRAIN Batch 6/2200 loss 23.779285 loss_att 26.455566 loss_ctc 37.234753 loss_rnnt 18.605465 hw_loss 0.533344 lr 0.00069209 rank 4
2023-02-11 12:12:21,267 DEBUG TRAIN Batch 6/2200 loss 18.432867 loss_att 21.224777 loss_ctc 35.091301 loss_rnnt 14.284172 hw_loss 0.256723 lr 0.00069164 rank 1
2023-02-11 12:12:21,270 DEBUG TRAIN Batch 6/2200 loss 24.973009 loss_att 28.386166 loss_ctc 30.912453 loss_rnnt 19.012127 hw_loss 0.841186 lr 0.00069209 rank 6
2023-02-11 12:13:36,392 DEBUG TRAIN Batch 6/2300 loss 23.339176 loss_att 22.737072 loss_ctc 33.084888 loss_rnnt 19.250879 hw_loss 0.545492 lr 0.00069113 rank 5
2023-02-11 12:13:36,394 DEBUG TRAIN Batch 6/2300 loss 9.386154 loss_att 11.645676 loss_ctc 12.953882 loss_rnnt 5.193321 hw_loss 0.612231 lr 0.00069084 rank 0
2023-02-11 12:13:36,394 DEBUG TRAIN Batch 6/2300 loss 23.124990 loss_att 24.341484 loss_ctc 30.384817 loss_rnnt 18.450272 hw_loss 0.649395 lr 0.00069143 rank 4
2023-02-11 12:13:36,394 DEBUG TRAIN Batch 6/2300 loss 20.237677 loss_att 22.362436 loss_ctc 31.233612 loss_rnnt 16.152548 hw_loss 0.411385 lr 0.00069126 rank 3
2023-02-11 12:13:36,394 DEBUG TRAIN Batch 6/2300 loss 17.603252 loss_att 23.120897 loss_ctc 28.508038 loss_rnnt 13.437536 hw_loss 0.301541 lr 0.00069126 rank 7
2023-02-11 12:13:36,395 DEBUG TRAIN Batch 6/2300 loss 20.945724 loss_att 24.305304 loss_ctc 30.980152 loss_rnnt 16.169186 hw_loss 0.518756 lr 0.00069098 rank 1
2023-02-11 12:13:36,399 DEBUG TRAIN Batch 6/2300 loss 17.219284 loss_att 20.150040 loss_ctc 24.356613 loss_rnnt 13.436964 hw_loss 0.420849 lr 0.00069142 rank 6
2023-02-11 12:13:36,400 DEBUG TRAIN Batch 6/2300 loss 32.307674 loss_att 34.087185 loss_ctc 52.477573 loss_rnnt 25.871849 hw_loss 0.635738 lr 0.00069066 rank 2
2023-02-11 12:14:51,757 DEBUG TRAIN Batch 6/2400 loss 20.710526 loss_att 26.370667 loss_ctc 32.106747 loss_rnnt 15.219214 hw_loss 0.532460 lr 0.00069047 rank 5
2023-02-11 12:14:51,757 DEBUG TRAIN Batch 6/2400 loss 12.292807 loss_att 14.536536 loss_ctc 20.160572 loss_rnnt 10.178341 hw_loss 0.115628 lr 0.00069060 rank 3
2023-02-11 12:14:51,758 DEBUG TRAIN Batch 6/2400 loss 15.027251 loss_att 17.320915 loss_ctc 24.435066 loss_rnnt 12.535868 hw_loss 0.145927 lr 0.00069018 rank 0
2023-02-11 12:14:51,761 DEBUG TRAIN Batch 6/2400 loss 11.640522 loss_att 15.756838 loss_ctc 21.005814 loss_rnnt 7.183077 hw_loss 0.447277 lr 0.00069032 rank 1
2023-02-11 12:14:51,761 DEBUG TRAIN Batch 6/2400 loss 22.714018 loss_att 27.177713 loss_ctc 34.823025 loss_rnnt 17.568968 hw_loss 0.494584 lr 0.00069077 rank 4
2023-02-11 12:14:51,761 DEBUG TRAIN Batch 6/2400 loss 13.042582 loss_att 14.818949 loss_ctc 19.240919 loss_rnnt 9.140072 hw_loss 0.510148 lr 0.00069000 rank 2
2023-02-11 12:14:51,762 DEBUG TRAIN Batch 6/2400 loss 19.520836 loss_att 21.447523 loss_ctc 24.695068 loss_rnnt 15.211020 hw_loss 0.606484 lr 0.00069060 rank 7
2023-02-11 12:14:51,802 DEBUG TRAIN Batch 6/2400 loss 17.491024 loss_att 20.522564 loss_ctc 27.174160 loss_rnnt 13.618896 hw_loss 0.370262 lr 0.00069076 rank 6
2023-02-11 12:16:11,198 DEBUG TRAIN Batch 6/2500 loss 24.661709 loss_att 25.762899 loss_ctc 38.488064 loss_rnnt 19.092844 hw_loss 0.657208 lr 0.00068982 rank 5
2023-02-11 12:16:11,199 DEBUG TRAIN Batch 6/2500 loss 20.402472 loss_att 21.302376 loss_ctc 28.605986 loss_rnnt 16.167112 hw_loss 0.555295 lr 0.00069010 rank 6
2023-02-11 12:16:11,200 DEBUG TRAIN Batch 6/2500 loss 19.719635 loss_att 23.324121 loss_ctc 30.900959 loss_rnnt 16.034235 hw_loss 0.276311 lr 0.00068953 rank 0
2023-02-11 12:16:11,201 DEBUG TRAIN Batch 6/2500 loss 16.447840 loss_att 13.349623 loss_ctc 19.255356 loss_rnnt 10.839180 hw_loss 1.097619 lr 0.00069011 rank 4
2023-02-11 12:16:11,207 DEBUG TRAIN Batch 6/2500 loss 23.158209 loss_att 23.898041 loss_ctc 37.437447 loss_rnnt 19.276756 hw_loss 0.343048 lr 0.00068967 rank 1
2023-02-11 12:16:11,208 DEBUG TRAIN Batch 6/2500 loss 16.591583 loss_att 15.994407 loss_ctc 20.209045 loss_rnnt 12.213205 hw_loss 0.752903 lr 0.00068994 rank 7
2023-02-11 12:16:11,209 DEBUG TRAIN Batch 6/2500 loss 18.402084 loss_att 17.703972 loss_ctc 21.027575 loss_rnnt 13.386332 hw_loss 0.900996 lr 0.00068994 rank 3
2023-02-11 12:16:11,232 DEBUG TRAIN Batch 6/2500 loss 8.365456 loss_att 9.983913 loss_ctc 14.747980 loss_rnnt 6.797767 hw_loss 0.073686 lr 0.00068934 rank 2
2023-02-11 12:17:28,008 DEBUG TRAIN Batch 6/2600 loss 18.231943 loss_att 22.995279 loss_ctc 36.111000 loss_rnnt 12.124857 hw_loss 0.519477 lr 0.00068928 rank 7
2023-02-11 12:17:28,010 DEBUG TRAIN Batch 6/2600 loss 14.888586 loss_att 11.372252 loss_ctc 16.608585 loss_rnnt 9.634480 hw_loss 1.074008 lr 0.00068887 rank 0
2023-02-11 12:17:28,012 DEBUG TRAIN Batch 6/2600 loss 13.216520 loss_att 14.434773 loss_ctc 20.546684 loss_rnnt 10.699503 hw_loss 0.243002 lr 0.00068869 rank 2
2023-02-11 12:17:28,015 DEBUG TRAIN Batch 6/2600 loss 16.097260 loss_att 12.216345 loss_ctc 16.630503 loss_rnnt 10.600048 hw_loss 1.162930 lr 0.00068928 rank 3
2023-02-11 12:17:28,018 DEBUG TRAIN Batch 6/2600 loss 19.537083 loss_att 24.502962 loss_ctc 32.150345 loss_rnnt 16.049652 hw_loss 0.152342 lr 0.00068901 rank 1
2023-02-11 12:17:28,019 DEBUG TRAIN Batch 6/2600 loss 26.298193 loss_att 27.001032 loss_ctc 35.251701 loss_rnnt 23.205801 hw_loss 0.329629 lr 0.00068946 rank 4
2023-02-11 12:17:28,019 DEBUG TRAIN Batch 6/2600 loss 22.956490 loss_att 24.916016 loss_ctc 34.077614 loss_rnnt 20.235893 hw_loss 0.158602 lr 0.00068916 rank 5
2023-02-11 12:17:28,062 DEBUG TRAIN Batch 6/2600 loss 13.195874 loss_att 9.874455 loss_ctc 13.013513 loss_rnnt 9.310246 hw_loss 0.857667 lr 0.00068945 rank 6
2023-02-11 12:18:45,508 DEBUG TRAIN Batch 6/2700 loss 18.518816 loss_att 20.832726 loss_ctc 30.008299 loss_rnnt 14.995516 hw_loss 0.286610 lr 0.00068822 rank 0
2023-02-11 12:18:45,510 DEBUG TRAIN Batch 6/2700 loss 21.193848 loss_att 24.260292 loss_ctc 32.322823 loss_rnnt 18.030100 hw_loss 0.199986 lr 0.00068863 rank 7
2023-02-11 12:18:45,511 DEBUG TRAIN Batch 6/2700 loss 25.145460 loss_att 27.223690 loss_ctc 43.073559 loss_rnnt 19.043346 hw_loss 0.618010 lr 0.00068863 rank 3
2023-02-11 12:18:45,512 DEBUG TRAIN Batch 6/2700 loss 17.304758 loss_att 19.914631 loss_ctc 30.211988 loss_rnnt 13.943161 hw_loss 0.209748 lr 0.00068879 rank 6
2023-02-11 12:18:45,512 DEBUG TRAIN Batch 6/2700 loss 17.946915 loss_att 18.388714 loss_ctc 28.549618 loss_rnnt 14.473593 hw_loss 0.369613 lr 0.00068880 rank 4
2023-02-11 12:18:45,513 DEBUG TRAIN Batch 6/2700 loss 26.281475 loss_att 29.473627 loss_ctc 36.649807 loss_rnnt 21.973549 hw_loss 0.428823 lr 0.00068836 rank 1
2023-02-11 12:18:45,513 DEBUG TRAIN Batch 6/2700 loss 16.273466 loss_att 18.010784 loss_ctc 21.395063 loss_rnnt 14.308356 hw_loss 0.175269 lr 0.00068851 rank 5
2023-02-11 12:18:45,516 DEBUG TRAIN Batch 6/2700 loss 24.981367 loss_att 27.888159 loss_ctc 32.370502 loss_rnnt 21.481274 hw_loss 0.362535 lr 0.00068804 rank 2
2023-02-11 12:20:03,150 DEBUG TRAIN Batch 6/2800 loss 16.008669 loss_att 21.278320 loss_ctc 25.638134 loss_rnnt 12.884916 hw_loss 0.147355 lr 0.00068757 rank 0
2023-02-11 12:20:03,152 DEBUG TRAIN Batch 6/2800 loss 23.521355 loss_att 25.922497 loss_ctc 35.918194 loss_rnnt 17.973785 hw_loss 0.640205 lr 0.00068771 rank 1
2023-02-11 12:20:03,154 DEBUG TRAIN Batch 6/2800 loss 30.645775 loss_att 33.614639 loss_ctc 45.934174 loss_rnnt 26.794533 hw_loss 0.228565 lr 0.00068814 rank 6
2023-02-11 12:20:03,155 DEBUG TRAIN Batch 6/2800 loss 14.219187 loss_att 21.096960 loss_ctc 23.592480 loss_rnnt 9.927965 hw_loss 0.312355 lr 0.00068798 rank 7
2023-02-11 12:20:03,158 DEBUG TRAIN Batch 6/2800 loss 18.984409 loss_att 22.285061 loss_ctc 27.417789 loss_rnnt 16.480106 hw_loss 0.134948 lr 0.00068739 rank 2
2023-02-11 12:20:03,158 DEBUG TRAIN Batch 6/2800 loss 13.241447 loss_att 16.467516 loss_ctc 15.818699 loss_rnnt 6.821616 hw_loss 1.018310 lr 0.00068815 rank 4
2023-02-11 12:20:03,160 DEBUG TRAIN Batch 6/2800 loss 15.465105 loss_att 19.499186 loss_ctc 23.540167 loss_rnnt 10.913403 hw_loss 0.500290 lr 0.00068798 rank 3
2023-02-11 12:20:03,159 DEBUG TRAIN Batch 6/2800 loss 21.964010 loss_att 24.521000 loss_ctc 30.740303 loss_rnnt 18.145353 hw_loss 0.400704 lr 0.00068785 rank 5
2023-02-11 12:21:20,185 DEBUG TRAIN Batch 6/2900 loss 24.868633 loss_att 30.873795 loss_ctc 36.852936 loss_rnnt 20.896275 hw_loss 0.220016 lr 0.00068692 rank 0
2023-02-11 12:21:20,186 DEBUG TRAIN Batch 6/2900 loss 15.441577 loss_att 20.155487 loss_ctc 21.776726 loss_rnnt 11.145016 hw_loss 0.470455 lr 0.00068733 rank 7
2023-02-11 12:21:20,188 DEBUG TRAIN Batch 6/2900 loss 21.471172 loss_att 23.896969 loss_ctc 31.615688 loss_rnnt 17.848793 hw_loss 0.334616 lr 0.00068733 rank 3
2023-02-11 12:21:20,189 DEBUG TRAIN Batch 6/2900 loss 24.833471 loss_att 25.374569 loss_ctc 40.320450 loss_rnnt 19.372112 hw_loss 0.616540 lr 0.00068749 rank 6
2023-02-11 12:21:20,189 DEBUG TRAIN Batch 6/2900 loss 16.299278 loss_att 16.249546 loss_ctc 19.574543 loss_rnnt 13.956904 hw_loss 0.359178 lr 0.00068720 rank 5
2023-02-11 12:21:20,190 DEBUG TRAIN Batch 6/2900 loss 26.835697 loss_att 33.038349 loss_ctc 42.294868 loss_rnnt 21.975006 hw_loss 0.292301 lr 0.00068706 rank 1
2023-02-11 12:21:20,190 DEBUG TRAIN Batch 6/2900 loss 24.354267 loss_att 25.961174 loss_ctc 36.871689 loss_rnnt 20.137901 hw_loss 0.417374 lr 0.00068750 rank 4
2023-02-11 12:21:20,193 DEBUG TRAIN Batch 6/2900 loss 33.127960 loss_att 32.774605 loss_ctc 50.912552 loss_rnnt 28.623653 hw_loss 0.413194 lr 0.00068674 rank 2
2023-02-11 12:22:35,094 DEBUG TRAIN Batch 6/3000 loss 16.750299 loss_att 17.195389 loss_ctc 26.638039 loss_rnnt 13.685933 hw_loss 0.310684 lr 0.00068684 rank 6
2023-02-11 12:22:35,095 DEBUG TRAIN Batch 6/3000 loss 18.188244 loss_att 18.468250 loss_ctc 25.073620 loss_rnnt 13.342016 hw_loss 0.726033 lr 0.00068668 rank 3
2023-02-11 12:22:35,095 DEBUG TRAIN Batch 6/3000 loss 17.720673 loss_att 21.101778 loss_ctc 27.077301 loss_rnnt 14.214732 hw_loss 0.296657 lr 0.00068627 rank 0
2023-02-11 12:22:35,097 DEBUG TRAIN Batch 6/3000 loss 16.096479 loss_att 18.680607 loss_ctc 20.038803 loss_rnnt 10.288363 hw_loss 0.893559 lr 0.00068668 rank 7
2023-02-11 12:22:35,098 DEBUG TRAIN Batch 6/3000 loss 13.727420 loss_att 17.323404 loss_ctc 22.754377 loss_rnnt 10.026412 hw_loss 0.333416 lr 0.00068609 rank 2
2023-02-11 12:22:35,099 DEBUG TRAIN Batch 6/3000 loss 22.706274 loss_att 25.143959 loss_ctc 39.682983 loss_rnnt 16.603836 hw_loss 0.628376 lr 0.00068685 rank 4
2023-02-11 12:22:35,101 DEBUG TRAIN Batch 6/3000 loss 14.874853 loss_att 16.874022 loss_ctc 22.546356 loss_rnnt 8.015188 hw_loss 1.019431 lr 0.00068656 rank 5
2023-02-11 12:22:35,102 DEBUG TRAIN Batch 6/3000 loss 27.891113 loss_att 25.364113 loss_ctc 38.751701 loss_rnnt 22.605730 hw_loss 0.814257 lr 0.00068641 rank 1
2023-02-11 12:23:50,085 DEBUG TRAIN Batch 6/3100 loss 24.378187 loss_att 26.275337 loss_ctc 34.563957 loss_rnnt 19.958128 hw_loss 0.502973 lr 0.00068619 rank 6
2023-02-11 12:23:50,085 DEBUG TRAIN Batch 6/3100 loss 22.533035 loss_att 21.044657 loss_ctc 30.079187 loss_rnnt 19.247114 hw_loss 0.483271 lr 0.00068620 rank 4
2023-02-11 12:23:50,087 DEBUG TRAIN Batch 6/3100 loss 20.994617 loss_att 19.473902 loss_ctc 26.288347 loss_rnnt 18.499456 hw_loss 0.392526 lr 0.00068603 rank 7
2023-02-11 12:23:50,087 DEBUG TRAIN Batch 6/3100 loss 11.856414 loss_att 15.200384 loss_ctc 15.726047 loss_rnnt 8.674647 hw_loss 0.374441 lr 0.00068576 rank 1
2023-02-11 12:23:50,090 DEBUG TRAIN Batch 6/3100 loss 12.421307 loss_att 16.854372 loss_ctc 22.381775 loss_rnnt 7.646794 hw_loss 0.479969 lr 0.00068603 rank 3
2023-02-11 12:23:50,092 DEBUG TRAIN Batch 6/3100 loss 16.456034 loss_att 18.753263 loss_ctc 24.227514 loss_rnnt 13.264015 hw_loss 0.318070 lr 0.00068563 rank 0
2023-02-11 12:23:50,110 DEBUG TRAIN Batch 6/3100 loss 13.163561 loss_att 14.599449 loss_ctc 20.995903 loss_rnnt 9.522225 hw_loss 0.433096 lr 0.00068591 rank 5
2023-02-11 12:23:50,139 DEBUG TRAIN Batch 6/3100 loss 18.065636 loss_att 14.061439 loss_ctc 18.547937 loss_rnnt 14.271624 hw_loss 0.849477 lr 0.00068545 rank 2
2023-02-11 12:25:09,007 DEBUG TRAIN Batch 6/3200 loss 19.285299 loss_att 21.011517 loss_ctc 26.568464 loss_rnnt 14.276871 hw_loss 0.692268 lr 0.00068539 rank 3
2023-02-11 12:25:09,009 DEBUG TRAIN Batch 6/3200 loss 14.410369 loss_att 13.091003 loss_ctc 17.780966 loss_rnnt 12.345137 hw_loss 0.352443 lr 0.00068539 rank 7
2023-02-11 12:25:09,009 DEBUG TRAIN Batch 6/3200 loss 16.536053 loss_att 15.118775 loss_ctc 16.218790 loss_rnnt 12.253098 hw_loss 0.864134 lr 0.00068498 rank 0
2023-02-11 12:25:09,010 DEBUG TRAIN Batch 6/3200 loss 22.263985 loss_att 22.273405 loss_ctc 32.310253 loss_rnnt 18.802170 hw_loss 0.397580 lr 0.00068555 rank 6
2023-02-11 12:25:09,014 DEBUG TRAIN Batch 6/3200 loss 16.365343 loss_att 17.961416 loss_ctc 21.882584 loss_rnnt 11.991905 hw_loss 0.622236 lr 0.00068480 rank 2
2023-02-11 12:25:09,015 DEBUG TRAIN Batch 6/3200 loss 12.750696 loss_att 17.446310 loss_ctc 17.768780 loss_rnnt 7.091674 hw_loss 0.759529 lr 0.00068556 rank 4
2023-02-11 12:25:09,015 DEBUG TRAIN Batch 6/3200 loss 37.041218 loss_att 53.964024 loss_ctc 56.084396 loss_rnnt 28.377640 hw_loss 0.513736 lr 0.00068527 rank 5
2023-02-11 12:25:09,036 DEBUG TRAIN Batch 6/3200 loss 14.959570 loss_att 18.804516 loss_ctc 22.106285 loss_rnnt 11.804989 hw_loss 0.268630 lr 0.00068512 rank 1
2023-02-11 12:26:23,954 DEBUG TRAIN Batch 6/3300 loss 22.995514 loss_att 26.553230 loss_ctc 36.062897 loss_rnnt 18.131247 hw_loss 0.451952 lr 0.00068491 rank 6
2023-02-11 12:26:23,955 DEBUG TRAIN Batch 6/3300 loss 24.217333 loss_att 26.778111 loss_ctc 36.694965 loss_rnnt 21.365179 hw_loss 0.126809 lr 0.00068475 rank 7
2023-02-11 12:26:23,958 DEBUG TRAIN Batch 6/3300 loss 21.265818 loss_att 25.727354 loss_ctc 33.924362 loss_rnnt 18.360016 hw_loss 0.061066 lr 0.00068475 rank 3
2023-02-11 12:26:23,959 DEBUG TRAIN Batch 6/3300 loss 27.604084 loss_att 35.195385 loss_ctc 38.251995 loss_rnnt 20.982555 hw_loss 0.690665 lr 0.00068434 rank 0
2023-02-11 12:26:23,960 DEBUG TRAIN Batch 6/3300 loss 21.276306 loss_att 28.195948 loss_ctc 39.414196 loss_rnnt 17.138828 hw_loss 0.062843 lr 0.00068448 rank 1
2023-02-11 12:26:23,961 DEBUG TRAIN Batch 6/3300 loss 22.377377 loss_att 24.869503 loss_ctc 32.298027 loss_rnnt 19.775799 hw_loss 0.146325 lr 0.00068416 rank 2
2023-02-11 12:26:23,962 DEBUG TRAIN Batch 6/3300 loss 15.507734 loss_att 17.690462 loss_ctc 24.236767 loss_rnnt 10.655207 hw_loss 0.609771 lr 0.00068462 rank 5
2023-02-11 12:26:23,964 DEBUG TRAIN Batch 6/3300 loss 26.404627 loss_att 27.783609 loss_ctc 36.567108 loss_rnnt 21.648199 hw_loss 0.586056 lr 0.00068491 rank 4
2023-02-11 12:27:40,930 DEBUG TRAIN Batch 6/3400 loss 30.393536 loss_att 29.058632 loss_ctc 40.364517 loss_rnnt 26.424217 hw_loss 0.545032 lr 0.00068370 rank 0
2023-02-11 12:27:40,934 DEBUG TRAIN Batch 6/3400 loss 34.312187 loss_att 38.488144 loss_ctc 49.970039 loss_rnnt 28.111366 hw_loss 0.614609 lr 0.00068410 rank 7
2023-02-11 12:27:40,937 DEBUG TRAIN Batch 6/3400 loss 23.538483 loss_att 25.712685 loss_ctc 36.187897 loss_rnnt 20.775711 hw_loss 0.120252 lr 0.00068384 rank 1
2023-02-11 12:27:40,937 DEBUG TRAIN Batch 6/3400 loss 22.622416 loss_att 28.801109 loss_ctc 31.590191 loss_rnnt 18.470165 hw_loss 0.322652 lr 0.00068398 rank 5
2023-02-11 12:27:40,938 DEBUG TRAIN Batch 6/3400 loss 17.837599 loss_att 18.803490 loss_ctc 23.277838 loss_rnnt 14.225959 hw_loss 0.504956 lr 0.00068352 rank 2
2023-02-11 12:27:40,939 DEBUG TRAIN Batch 6/3400 loss 14.579413 loss_att 13.811648 loss_ctc 15.369723 loss_rnnt 12.417040 hw_loss 0.414479 lr 0.00068410 rank 3
2023-02-11 12:27:40,939 DEBUG TRAIN Batch 6/3400 loss 17.341032 loss_att 22.523874 loss_ctc 30.330502 loss_rnnt 11.846151 hw_loss 0.511197 lr 0.00068427 rank 4
2023-02-11 12:27:40,941 DEBUG TRAIN Batch 6/3400 loss 15.286245 loss_att 24.040848 loss_ctc 23.770782 loss_rnnt 11.142212 hw_loss 0.236595 lr 0.00068426 rank 6
2023-02-11 12:28:57,668 DEBUG TRAIN Batch 6/3500 loss 20.462315 loss_att 23.395962 loss_ctc 27.057644 loss_rnnt 17.150623 hw_loss 0.346047 lr 0.00068306 rank 0
2023-02-11 12:28:57,667 DEBUG TRAIN Batch 6/3500 loss 21.684689 loss_att 25.123518 loss_ctc 41.248611 loss_rnnt 15.366199 hw_loss 0.566663 lr 0.00068346 rank 3
2023-02-11 12:28:57,673 DEBUG TRAIN Batch 6/3500 loss 33.912342 loss_att 38.464569 loss_ctc 55.749092 loss_rnnt 29.265774 hw_loss 0.154605 lr 0.00068362 rank 6
2023-02-11 12:28:57,674 DEBUG TRAIN Batch 6/3500 loss 13.214155 loss_att 17.819578 loss_ctc 19.334709 loss_rnnt 9.875355 hw_loss 0.300308 lr 0.00068288 rank 2
2023-02-11 12:28:57,674 DEBUG TRAIN Batch 6/3500 loss 19.749249 loss_att 21.982346 loss_ctc 28.894890 loss_rnnt 16.743862 hw_loss 0.251128 lr 0.00068334 rank 5
2023-02-11 12:28:57,676 DEBUG TRAIN Batch 6/3500 loss 22.376417 loss_att 23.205557 loss_ctc 30.128635 loss_rnnt 17.429386 hw_loss 0.702670 lr 0.00068346 rank 7
2023-02-11 12:28:57,683 DEBUG TRAIN Batch 6/3500 loss 10.229824 loss_att 13.677980 loss_ctc 12.178032 loss_rnnt 5.650666 hw_loss 0.680581 lr 0.00068320 rank 1
2023-02-11 12:28:57,727 DEBUG TRAIN Batch 6/3500 loss 15.326402 loss_att 17.953199 loss_ctc 21.625996 loss_rnnt 10.979445 hw_loss 0.559060 lr 0.00068363 rank 4
2023-02-11 12:30:15,190 DEBUG TRAIN Batch 6/3600 loss 26.898678 loss_att 28.702572 loss_ctc 40.379879 loss_rnnt 20.278015 hw_loss 0.836698 lr 0.00068243 rank 0
2023-02-11 12:30:15,191 DEBUG TRAIN Batch 6/3600 loss 25.913601 loss_att 27.353821 loss_ctc 43.105721 loss_rnnt 21.753395 hw_loss 0.296228 lr 0.00068256 rank 1
2023-02-11 12:30:15,192 DEBUG TRAIN Batch 6/3600 loss 27.202524 loss_att 27.851955 loss_ctc 38.809631 loss_rnnt 24.363628 hw_loss 0.217762 lr 0.00068283 rank 7
2023-02-11 12:30:15,192 DEBUG TRAIN Batch 6/3600 loss 20.624292 loss_att 25.302301 loss_ctc 30.568165 loss_rnnt 16.724680 hw_loss 0.307155 lr 0.00068283 rank 3
2023-02-11 12:30:15,193 DEBUG TRAIN Batch 6/3600 loss 18.932453 loss_att 22.478888 loss_ctc 26.022842 loss_rnnt 13.989935 hw_loss 0.616472 lr 0.00068225 rank 2
2023-02-11 12:30:15,195 DEBUG TRAIN Batch 6/3600 loss 12.300220 loss_att 12.062449 loss_ctc 13.166406 loss_rnnt 9.027891 hw_loss 0.600823 lr 0.00068271 rank 5
2023-02-11 12:30:15,196 DEBUG TRAIN Batch 6/3600 loss 17.878592 loss_att 18.459608 loss_ctc 23.895273 loss_rnnt 13.910355 hw_loss 0.571840 lr 0.00068299 rank 4
2023-02-11 12:30:15,241 DEBUG TRAIN Batch 6/3600 loss 29.065012 loss_att 29.677572 loss_ctc 37.476406 loss_rnnt 24.521267 hw_loss 0.618697 lr 0.00068299 rank 6
2023-02-11 12:31:30,706 DEBUG TRAIN Batch 6/3700 loss 19.715775 loss_att 20.964058 loss_ctc 30.331272 loss_rnnt 16.590876 hw_loss 0.273720 lr 0.00068179 rank 0
2023-02-11 12:31:30,708 DEBUG TRAIN Batch 6/3700 loss 15.340107 loss_att 15.302845 loss_ctc 20.390179 loss_rnnt 11.914848 hw_loss 0.517382 lr 0.00068161 rank 2
2023-02-11 12:31:30,709 DEBUG TRAIN Batch 6/3700 loss 22.817148 loss_att 29.289820 loss_ctc 41.987465 loss_rnnt 17.393501 hw_loss 0.294951 lr 0.00068219 rank 3
2023-02-11 12:31:30,711 DEBUG TRAIN Batch 6/3700 loss 7.236539 loss_att 9.224371 loss_ctc 10.546308 loss_rnnt 3.818484 hw_loss 0.483598 lr 0.00068207 rank 5
2023-02-11 12:31:30,712 DEBUG TRAIN Batch 6/3700 loss 19.225090 loss_att 21.218616 loss_ctc 29.106323 loss_rnnt 15.204859 hw_loss 0.432005 lr 0.00068219 rank 7
2023-02-11 12:31:30,713 DEBUG TRAIN Batch 6/3700 loss 13.817298 loss_att 14.511097 loss_ctc 15.929382 loss_rnnt 9.919315 hw_loss 0.652052 lr 0.00068192 rank 1
2023-02-11 12:31:30,714 DEBUG TRAIN Batch 6/3700 loss 19.178926 loss_att 19.611341 loss_ctc 27.710279 loss_rnnt 14.282557 hw_loss 0.688569 lr 0.00068236 rank 4
2023-02-11 12:31:30,715 DEBUG TRAIN Batch 6/3700 loss 14.160088 loss_att 16.181032 loss_ctc 23.593973 loss_rnnt 9.416409 hw_loss 0.577807 lr 0.00068235 rank 6
2023-02-11 12:32:46,094 DEBUG TRAIN Batch 6/3800 loss 21.413197 loss_att 24.985916 loss_ctc 27.739386 loss_rnnt 16.438086 hw_loss 0.640701 lr 0.00068116 rank 0
2023-02-11 12:32:46,094 DEBUG TRAIN Batch 6/3800 loss 31.077322 loss_att 26.046225 loss_ctc 36.166683 loss_rnnt 26.132004 hw_loss 0.988679 lr 0.00068156 rank 7
2023-02-11 12:32:46,096 DEBUG TRAIN Batch 6/3800 loss 16.290407 loss_att 19.023300 loss_ctc 25.056431 loss_rnnt 13.799153 hw_loss 0.145476 lr 0.00068172 rank 6
2023-02-11 12:32:46,097 DEBUG TRAIN Batch 6/3800 loss 18.604778 loss_att 14.176203 loss_ctc 22.255909 loss_rnnt 12.988057 hw_loss 1.127928 lr 0.00068129 rank 1
2023-02-11 12:32:46,100 DEBUG TRAIN Batch 6/3800 loss 12.396456 loss_att 15.195823 loss_ctc 20.140488 loss_rnnt 8.598746 hw_loss 0.413494 lr 0.00068156 rank 3
2023-02-11 12:32:46,101 DEBUG TRAIN Batch 6/3800 loss 16.734785 loss_att 21.410093 loss_ctc 27.637863 loss_rnnt 10.963695 hw_loss 0.634178 lr 0.00068098 rank 2
2023-02-11 12:32:46,102 DEBUG TRAIN Batch 6/3800 loss 16.235670 loss_att 22.433090 loss_ctc 32.754410 loss_rnnt 9.250853 hw_loss 0.664282 lr 0.00068172 rank 4
2023-02-11 12:32:46,102 DEBUG TRAIN Batch 6/3800 loss 13.368747 loss_att 10.700349 loss_ctc 15.497507 loss_rnnt 9.613853 hw_loss 0.750889 lr 0.00068144 rank 5
2023-02-11 12:34:05,861 DEBUG TRAIN Batch 6/3900 loss 35.052769 loss_att 39.857075 loss_ctc 58.016357 loss_rnnt 28.826588 hw_loss 0.413158 lr 0.00068092 rank 3
2023-02-11 12:34:05,863 DEBUG TRAIN Batch 6/3900 loss 11.923076 loss_att 24.584373 loss_ctc 18.039610 loss_rnnt 7.633063 hw_loss 0.176665 lr 0.00068108 rank 6
2023-02-11 12:34:05,869 DEBUG TRAIN Batch 6/3900 loss 16.873770 loss_att 24.168877 loss_ctc 26.488094 loss_rnnt 12.424399 hw_loss 0.320332 lr 0.00068080 rank 5
2023-02-11 12:34:05,870 DEBUG TRAIN Batch 6/3900 loss 11.846487 loss_att 16.355581 loss_ctc 20.123728 loss_rnnt 8.654896 hw_loss 0.222401 lr 0.00068066 rank 1
2023-02-11 12:34:05,874 DEBUG TRAIN Batch 6/3900 loss 20.109001 loss_att 24.942694 loss_ctc 33.106590 loss_rnnt 15.918368 hw_loss 0.279541 lr 0.00068035 rank 2
2023-02-11 12:34:05,875 DEBUG TRAIN Batch 6/3900 loss 12.043541 loss_att 13.883268 loss_ctc 17.346813 loss_rnnt 7.116095 hw_loss 0.722324 lr 0.00068109 rank 4
2023-02-11 12:34:05,888 DEBUG TRAIN Batch 6/3900 loss 15.471620 loss_att 18.066071 loss_ctc 24.248175 loss_rnnt 12.513664 hw_loss 0.237911 lr 0.00068092 rank 7
2023-02-11 12:34:05,904 DEBUG TRAIN Batch 6/3900 loss 25.607681 loss_att 30.177063 loss_ctc 41.504105 loss_rnnt 21.045895 hw_loss 0.286572 lr 0.00068053 rank 0
2023-02-11 12:35:22,116 DEBUG TRAIN Batch 6/4000 loss 35.039375 loss_att 41.301991 loss_ctc 61.471672 loss_rnnt 28.684759 hw_loss 0.295835 lr 0.00068029 rank 3
2023-02-11 12:35:22,116 DEBUG TRAIN Batch 6/4000 loss 32.921860 loss_att 35.996449 loss_ctc 52.099960 loss_rnnt 29.262344 hw_loss 0.091410 lr 0.00067990 rank 0
2023-02-11 12:35:22,116 DEBUG TRAIN Batch 6/4000 loss 23.711737 loss_att 27.849125 loss_ctc 38.952690 loss_rnnt 18.300034 hw_loss 0.478518 lr 0.00068029 rank 7
2023-02-11 12:35:22,118 DEBUG TRAIN Batch 6/4000 loss 17.950172 loss_att 23.320568 loss_ctc 31.924368 loss_rnnt 14.163291 hw_loss 0.159295 lr 0.00067972 rank 2
2023-02-11 12:35:22,122 DEBUG TRAIN Batch 6/4000 loss 2.618552 loss_att 6.927034 loss_ctc 5.219650 loss_rnnt 0.988067 hw_loss 0.079120 lr 0.00068045 rank 6
2023-02-11 12:35:22,124 DEBUG TRAIN Batch 6/4000 loss 11.170955 loss_att 12.629889 loss_ctc 14.505637 loss_rnnt 9.738141 hw_loss 0.130575 lr 0.00068003 rank 1
2023-02-11 12:35:22,124 DEBUG TRAIN Batch 6/4000 loss 10.795749 loss_att 12.248878 loss_ctc 14.742004 loss_rnnt 7.357240 hw_loss 0.491572 lr 0.00068017 rank 5
2023-02-11 12:35:22,164 DEBUG TRAIN Batch 6/4000 loss 26.851606 loss_att 25.926119 loss_ctc 34.534019 loss_rnnt 23.393871 hw_loss 0.490971 lr 0.00068046 rank 4
2023-02-11 12:36:38,811 DEBUG TRAIN Batch 6/4100 loss 17.543612 loss_att 20.563038 loss_ctc 28.441467 loss_rnnt 13.493899 hw_loss 0.373646 lr 0.00067967 rank 7
2023-02-11 12:36:38,813 DEBUG TRAIN Batch 6/4100 loss 17.199301 loss_att 18.721058 loss_ctc 25.923580 loss_rnnt 13.328448 hw_loss 0.450612 lr 0.00067967 rank 3
2023-02-11 12:36:38,815 DEBUG TRAIN Batch 6/4100 loss 12.676512 loss_att 18.114548 loss_ctc 19.782768 loss_rnnt 8.109091 hw_loss 0.474809 lr 0.00067940 rank 1
2023-02-11 12:36:38,817 DEBUG TRAIN Batch 6/4100 loss 20.886148 loss_att 18.642841 loss_ctc 27.482388 loss_rnnt 18.069752 hw_loss 0.447292 lr 0.00067982 rank 6
2023-02-11 12:36:38,817 DEBUG TRAIN Batch 6/4100 loss 33.825638 loss_att 34.309891 loss_ctc 47.339764 loss_rnnt 30.286291 hw_loss 0.307616 lr 0.00067927 rank 0
2023-02-11 12:36:38,818 DEBUG TRAIN Batch 6/4100 loss 13.803689 loss_att 17.037184 loss_ctc 18.186708 loss_rnnt 10.201855 hw_loss 0.444512 lr 0.00067955 rank 5
2023-02-11 12:36:38,819 DEBUG TRAIN Batch 6/4100 loss 29.751080 loss_att 30.864452 loss_ctc 42.379597 loss_rnnt 26.451241 hw_loss 0.261255 lr 0.00067909 rank 2
2023-02-11 12:36:38,872 DEBUG TRAIN Batch 6/4100 loss 21.447868 loss_att 23.463703 loss_ctc 27.567701 loss_rnnt 17.492699 hw_loss 0.513005 lr 0.00067983 rank 4
2023-02-11 12:37:55,522 DEBUG TRAIN Batch 6/4200 loss 18.517891 loss_att 23.540867 loss_ctc 31.306610 loss_rnnt 14.944476 hw_loss 0.161936 lr 0.00067847 rank 2
2023-02-11 12:37:55,522 DEBUG TRAIN Batch 6/4200 loss 19.210257 loss_att 23.062574 loss_ctc 35.042900 loss_rnnt 12.973873 hw_loss 0.629043 lr 0.00067904 rank 7
2023-02-11 12:37:55,524 DEBUG TRAIN Batch 6/4200 loss 20.152758 loss_att 26.267593 loss_ctc 28.645222 loss_rnnt 13.408257 hw_loss 0.822976 lr 0.00067864 rank 0
2023-02-11 12:37:55,529 DEBUG TRAIN Batch 6/4200 loss 19.578279 loss_att 26.293470 loss_ctc 35.029213 loss_rnnt 14.938760 hw_loss 0.231817 lr 0.00067904 rank 3
2023-02-11 12:37:55,530 DEBUG TRAIN Batch 6/4200 loss 23.886894 loss_att 27.099678 loss_ctc 40.235519 loss_rnnt 17.906404 hw_loss 0.592147 lr 0.00067878 rank 1
2023-02-11 12:37:55,531 DEBUG TRAIN Batch 6/4200 loss 13.668134 loss_att 18.199314 loss_ctc 25.309551 loss_rnnt 9.621423 hw_loss 0.297803 lr 0.00067919 rank 6
2023-02-11 12:37:55,534 DEBUG TRAIN Batch 6/4200 loss 13.153979 loss_att 17.017181 loss_ctc 24.640095 loss_rnnt 10.502436 hw_loss 0.065141 lr 0.00067892 rank 5
2023-02-11 12:37:55,536 DEBUG TRAIN Batch 6/4200 loss 17.772852 loss_att 23.348988 loss_ctc 30.036383 loss_rnnt 13.175989 hw_loss 0.346218 lr 0.00067920 rank 4
2023-02-11 12:39:13,961 DEBUG TRAIN Batch 6/4300 loss 17.067024 loss_att 18.333286 loss_ctc 29.728268 loss_rnnt 13.830670 hw_loss 0.242800 lr 0.00067841 rank 7
2023-02-11 12:39:13,963 DEBUG TRAIN Batch 6/4300 loss 20.060530 loss_att 23.586304 loss_ctc 28.894028 loss_rnnt 15.690657 hw_loss 0.466297 lr 0.00067841 rank 3
2023-02-11 12:39:13,963 DEBUG TRAIN Batch 6/4300 loss 25.064857 loss_att 27.472187 loss_ctc 35.386147 loss_rnnt 20.704840 hw_loss 0.469196 lr 0.00067785 rank 2
2023-02-11 12:39:13,968 DEBUG TRAIN Batch 6/4300 loss 19.426411 loss_att 19.162434 loss_ctc 27.718397 loss_rnnt 14.598524 hw_loss 0.707828 lr 0.00067857 rank 6
2023-02-11 12:39:13,968 DEBUG TRAIN Batch 6/4300 loss 20.467449 loss_att 21.542660 loss_ctc 24.856476 loss_rnnt 16.975639 hw_loss 0.504668 lr 0.00067802 rank 0
2023-02-11 12:39:13,970 DEBUG TRAIN Batch 6/4300 loss 22.400991 loss_att 22.084061 loss_ctc 28.587486 loss_rnnt 19.015511 hw_loss 0.492000 lr 0.00067815 rank 1
2023-02-11 12:39:13,970 DEBUG TRAIN Batch 6/4300 loss 15.482087 loss_att 20.162437 loss_ctc 23.500647 loss_rnnt 12.608021 hw_loss 0.162910 lr 0.00067829 rank 5
2023-02-11 12:39:13,971 DEBUG TRAIN Batch 6/4300 loss 23.466606 loss_att 30.318272 loss_ctc 32.781803 loss_rnnt 17.724897 hw_loss 0.586753 lr 0.00067858 rank 4
2023-02-11 12:40:29,905 DEBUG TRAIN Batch 6/4400 loss 22.966909 loss_att 25.446941 loss_ctc 37.022930 loss_rnnt 17.694782 hw_loss 0.544122 lr 0.00067779 rank 7
2023-02-11 12:40:29,911 DEBUG TRAIN Batch 6/4400 loss 14.716358 loss_att 14.533306 loss_ctc 21.876965 loss_rnnt 10.068325 hw_loss 0.699355 lr 0.00067767 rank 5
2023-02-11 12:40:29,913 DEBUG TRAIN Batch 6/4400 loss 14.821574 loss_att 15.127831 loss_ctc 21.904676 loss_rnnt 11.512885 hw_loss 0.431817 lr 0.00067740 rank 0
2023-02-11 12:40:29,912 DEBUG TRAIN Batch 6/4400 loss 16.654705 loss_att 16.631073 loss_ctc 19.013464 loss_rnnt 13.588859 hw_loss 0.516763 lr 0.00067779 rank 3
2023-02-11 12:40:29,912 DEBUG TRAIN Batch 6/4400 loss 20.724516 loss_att 25.477118 loss_ctc 34.114132 loss_rnnt 14.136273 hw_loss 0.722333 lr 0.00067795 rank 6
2023-02-11 12:40:29,913 DEBUG TRAIN Batch 6/4400 loss 12.394486 loss_att 13.876656 loss_ctc 19.328857 loss_rnnt 9.273097 hw_loss 0.356320 lr 0.00067753 rank 1
2023-02-11 12:40:29,914 DEBUG TRAIN Batch 6/4400 loss 21.491602 loss_att 22.586958 loss_ctc 32.853638 loss_rnnt 15.898196 hw_loss 0.723637 lr 0.00067795 rank 4
2023-02-11 12:40:29,965 DEBUG TRAIN Batch 6/4400 loss 19.350229 loss_att 19.989510 loss_ctc 27.006498 loss_rnnt 15.499537 hw_loss 0.506625 lr 0.00067722 rank 2
2023-02-11 12:41:47,441 DEBUG TRAIN Batch 6/4500 loss 18.914982 loss_att 20.550886 loss_ctc 29.308485 loss_rnnt 15.983644 hw_loss 0.228441 lr 0.00067717 rank 3
2023-02-11 12:41:47,442 DEBUG TRAIN Batch 6/4500 loss 30.817560 loss_att 31.193085 loss_ctc 42.618515 loss_rnnt 24.895947 hw_loss 0.801196 lr 0.00067705 rank 5
2023-02-11 12:41:47,443 DEBUG TRAIN Batch 6/4500 loss 11.142879 loss_att 8.875051 loss_ctc 12.867812 loss_rnnt 8.379785 hw_loss 0.560000 lr 0.00067732 rank 6
2023-02-11 12:41:47,445 DEBUG TRAIN Batch 6/4500 loss 14.163991 loss_att 18.679205 loss_ctc 20.852806 loss_rnnt 10.023874 hw_loss 0.439731 lr 0.00067660 rank 2
2023-02-11 12:41:47,448 DEBUG TRAIN Batch 6/4500 loss 22.501160 loss_att 26.976028 loss_ctc 29.172546 loss_rnnt 18.973419 hw_loss 0.326859 lr 0.00067691 rank 1
2023-02-11 12:41:47,450 DEBUG TRAIN Batch 6/4500 loss 6.950434 loss_att 10.290051 loss_ctc 10.751364 loss_rnnt 5.325888 hw_loss 0.084344 lr 0.00067717 rank 7
2023-02-11 12:41:47,451 DEBUG TRAIN Batch 6/4500 loss 27.163177 loss_att 31.307938 loss_ctc 41.084103 loss_rnnt 22.962524 hw_loss 0.284171 lr 0.00067678 rank 0
2023-02-11 12:41:47,491 DEBUG TRAIN Batch 6/4500 loss 32.298786 loss_att 36.678600 loss_ctc 50.795818 loss_rnnt 25.452038 hw_loss 0.657097 lr 0.00067733 rank 4
2023-02-11 12:43:06,811 DEBUG TRAIN Batch 6/4600 loss 30.487520 loss_att 34.622433 loss_ctc 40.628265 loss_rnnt 23.946751 hw_loss 0.817816 lr 0.00067655 rank 3
2023-02-11 12:43:06,819 DEBUG TRAIN Batch 6/4600 loss 17.879772 loss_att 26.802849 loss_ctc 31.310644 loss_rnnt 14.105655 hw_loss 0.037260 lr 0.00067629 rank 1
2023-02-11 12:43:06,820 DEBUG TRAIN Batch 6/4600 loss 21.590252 loss_att 29.274132 loss_ctc 31.545523 loss_rnnt 16.650867 hw_loss 0.389107 lr 0.00067655 rank 7
2023-02-11 12:43:06,821 DEBUG TRAIN Batch 6/4600 loss 26.955299 loss_att 27.739944 loss_ctc 38.733688 loss_rnnt 22.786999 hw_loss 0.457673 lr 0.00067616 rank 0
2023-02-11 12:43:06,822 DEBUG TRAIN Batch 6/4600 loss 35.321766 loss_att 35.868706 loss_ctc 48.764374 loss_rnnt 33.333523 hw_loss 0.016220 lr 0.00067643 rank 5
2023-02-11 12:43:06,823 DEBUG TRAIN Batch 6/4600 loss 20.277849 loss_att 24.796307 loss_ctc 32.281036 loss_rnnt 16.998732 hw_loss 0.145313 lr 0.00067598 rank 2
2023-02-11 12:43:06,825 DEBUG TRAIN Batch 6/4600 loss 20.623909 loss_att 24.870838 loss_ctc 38.117359 loss_rnnt 16.097645 hw_loss 0.252079 lr 0.00067671 rank 4
2023-02-11 12:43:06,854 DEBUG TRAIN Batch 6/4600 loss 24.489458 loss_att 25.393192 loss_ctc 35.324520 loss_rnnt 18.661230 hw_loss 0.788026 lr 0.00067670 rank 6
2023-02-11 12:44:23,576 DEBUG TRAIN Batch 6/4700 loss 18.943626 loss_att 19.638391 loss_ctc 27.289654 loss_rnnt 12.923247 hw_loss 0.894116 lr 0.00067593 rank 3
2023-02-11 12:44:23,577 DEBUG TRAIN Batch 6/4700 loss 23.076971 loss_att 33.042297 loss_ctc 38.859303 loss_rnnt 17.020845 hw_loss 0.367265 lr 0.00067608 rank 6
2023-02-11 12:44:23,578 DEBUG TRAIN Batch 6/4700 loss 13.178194 loss_att 16.390591 loss_ctc 19.814529 loss_rnnt 9.864771 hw_loss 0.334893 lr 0.00067537 rank 2
2023-02-11 12:44:23,578 DEBUG TRAIN Batch 6/4700 loss 15.774967 loss_att 19.836334 loss_ctc 24.303671 loss_rnnt 10.321159 hw_loss 0.657070 lr 0.00067593 rank 7
2023-02-11 12:44:23,579 DEBUG TRAIN Batch 6/4700 loss 21.972340 loss_att 25.454208 loss_ctc 29.536806 loss_rnnt 17.204796 hw_loss 0.574232 lr 0.00067609 rank 4
2023-02-11 12:44:23,580 DEBUG TRAIN Batch 6/4700 loss 12.459930 loss_att 14.187922 loss_ctc 16.773045 loss_rnnt 7.973995 hw_loss 0.668485 lr 0.00067554 rank 0
2023-02-11 12:44:23,580 DEBUG TRAIN Batch 6/4700 loss 16.891171 loss_att 22.507708 loss_ctc 29.652723 loss_rnnt 12.679295 hw_loss 0.260068 lr 0.00067581 rank 5
2023-02-11 12:44:23,582 DEBUG TRAIN Batch 6/4700 loss 16.661755 loss_att 23.552689 loss_ctc 24.290396 loss_rnnt 11.504863 hw_loss 0.517791 lr 0.00067567 rank 1
2023-02-11 12:45:38,631 DEBUG TRAIN Batch 6/4800 loss 23.712753 loss_att 26.862041 loss_ctc 31.802116 loss_rnnt 20.478588 hw_loss 0.286074 lr 0.00067531 rank 3
2023-02-11 12:45:38,634 DEBUG TRAIN Batch 6/4800 loss 22.250839 loss_att 23.288265 loss_ctc 29.078775 loss_rnnt 18.437294 hw_loss 0.505438 lr 0.00067475 rank 2
2023-02-11 12:45:38,636 DEBUG TRAIN Batch 6/4800 loss 22.117449 loss_att 27.104950 loss_ctc 35.575478 loss_rnnt 17.171860 hw_loss 0.403816 lr 0.00067531 rank 7
2023-02-11 12:45:38,635 DEBUG TRAIN Batch 6/4800 loss 15.837933 loss_att 18.614883 loss_ctc 21.048344 loss_rnnt 12.425435 hw_loss 0.405447 lr 0.00067492 rank 0
2023-02-11 12:45:38,635 DEBUG TRAIN Batch 6/4800 loss 18.421545 loss_att 24.593559 loss_ctc 35.431732 loss_rnnt 14.426842 hw_loss 0.092302 lr 0.00067519 rank 5
2023-02-11 12:45:38,635 DEBUG TRAIN Batch 6/4800 loss 7.254534 loss_att 10.063054 loss_ctc 12.516219 loss_rnnt 4.776077 hw_loss 0.227849 lr 0.00067505 rank 1
2023-02-11 12:45:38,636 DEBUG TRAIN Batch 6/4800 loss 18.312346 loss_att 21.752941 loss_ctc 30.709229 loss_rnnt 13.938391 hw_loss 0.381172 lr 0.00067547 rank 4
2023-02-11 12:45:38,638 DEBUG TRAIN Batch 6/4800 loss 16.742018 loss_att 18.431347 loss_ctc 27.854378 loss_rnnt 12.730335 hw_loss 0.411032 lr 0.00067547 rank 6
2023-02-11 12:46:55,419 DEBUG TRAIN Batch 6/4900 loss 15.806158 loss_att 21.528202 loss_ctc 31.361782 loss_rnnt 11.668676 hw_loss 0.172311 lr 0.00067431 rank 0
2023-02-11 12:46:55,421 DEBUG TRAIN Batch 6/4900 loss 14.948869 loss_att 16.573954 loss_ctc 19.785704 loss_rnnt 11.741487 hw_loss 0.419522 lr 0.00067470 rank 7
2023-02-11 12:46:55,422 DEBUG TRAIN Batch 6/4900 loss 19.699619 loss_att 20.058384 loss_ctc 32.063965 loss_rnnt 14.429673 hw_loss 0.665552 lr 0.00067470 rank 3
2023-02-11 12:46:55,423 DEBUG TRAIN Batch 6/4900 loss 13.897263 loss_att 15.235060 loss_ctc 17.494396 loss_rnnt 11.421748 hw_loss 0.324063 lr 0.00067486 rank 4
2023-02-11 12:46:55,425 DEBUG TRAIN Batch 6/4900 loss 17.867710 loss_att 19.766714 loss_ctc 22.621613 loss_rnnt 13.967279 hw_loss 0.541270 lr 0.00067444 rank 1
2023-02-11 12:46:55,426 DEBUG TRAIN Batch 6/4900 loss 13.128633 loss_att 16.426861 loss_ctc 20.695457 loss_rnnt 10.349136 hw_loss 0.208301 lr 0.00067458 rank 5
2023-02-11 12:46:55,426 DEBUG TRAIN Batch 6/4900 loss 23.381355 loss_att 27.841228 loss_ctc 37.328911 loss_rnnt 18.853031 hw_loss 0.333126 lr 0.00067414 rank 2
2023-02-11 12:46:55,428 DEBUG TRAIN Batch 6/4900 loss 25.570997 loss_att 26.554333 loss_ctc 29.681990 loss_rnnt 21.957512 hw_loss 0.537878 lr 0.00067485 rank 6
2023-02-11 12:48:14,211 DEBUG TRAIN Batch 6/5000 loss 21.609863 loss_att 21.830513 loss_ctc 30.247339 loss_rnnt 16.729092 hw_loss 0.690933 lr 0.00067424 rank 6
2023-02-11 12:48:14,211 DEBUG TRAIN Batch 6/5000 loss 21.297325 loss_att 22.828304 loss_ctc 27.405287 loss_rnnt 17.174891 hw_loss 0.562845 lr 0.00067397 rank 5
2023-02-11 12:48:14,212 DEBUG TRAIN Batch 6/5000 loss 17.316471 loss_att 19.849195 loss_ctc 26.263031 loss_rnnt 12.717090 hw_loss 0.543743 lr 0.00067370 rank 0
2023-02-11 12:48:14,212 DEBUG TRAIN Batch 6/5000 loss 25.742212 loss_att 25.751522 loss_ctc 37.019539 loss_rnnt 22.313787 hw_loss 0.360548 lr 0.00067424 rank 4
2023-02-11 12:48:14,212 DEBUG TRAIN Batch 6/5000 loss 16.790842 loss_att 19.327675 loss_ctc 26.541248 loss_rnnt 12.694605 hw_loss 0.429153 lr 0.00067408 rank 7
2023-02-11 12:48:14,215 DEBUG TRAIN Batch 6/5000 loss 13.226959 loss_att 16.959757 loss_ctc 20.441095 loss_rnnt 7.758650 hw_loss 0.704975 lr 0.00067408 rank 3
2023-02-11 12:48:14,217 DEBUG TRAIN Batch 6/5000 loss 12.277462 loss_att 11.586221 loss_ctc 14.706379 loss_rnnt 8.205368 hw_loss 0.728716 lr 0.00067353 rank 2
2023-02-11 12:48:14,221 DEBUG TRAIN Batch 6/5000 loss 16.261152 loss_att 16.914955 loss_ctc 22.828665 loss_rnnt 11.540189 hw_loss 0.696475 lr 0.00067383 rank 1
2023-02-11 12:49:29,220 DEBUG TRAIN Batch 6/5100 loss 18.167284 loss_att 13.662832 loss_ctc 19.102468 loss_rnnt 12.326303 hw_loss 1.240721 lr 0.00067309 rank 0
2023-02-11 12:49:29,223 DEBUG TRAIN Batch 6/5100 loss 17.123739 loss_att 18.283360 loss_ctc 24.046291 loss_rnnt 12.677298 hw_loss 0.617159 lr 0.00067347 rank 3
2023-02-11 12:49:29,224 DEBUG TRAIN Batch 6/5100 loss 14.093667 loss_att 11.283486 loss_ctc 13.921912 loss_rnnt 8.866018 hw_loss 1.089860 lr 0.00067347 rank 7
2023-02-11 12:49:29,227 DEBUG TRAIN Batch 6/5100 loss 18.359457 loss_att 21.199694 loss_ctc 28.787086 loss_rnnt 13.784040 hw_loss 0.490691 lr 0.00067292 rank 2
2023-02-11 12:49:29,227 DEBUG TRAIN Batch 6/5100 loss 15.590536 loss_att 25.047689 loss_ctc 27.283386 loss_rnnt 10.160566 hw_loss 0.371155 lr 0.00067322 rank 1
2023-02-11 12:49:29,228 DEBUG TRAIN Batch 6/5100 loss 19.177406 loss_att 26.393021 loss_ctc 39.896435 loss_rnnt 14.002733 hw_loss 0.181690 lr 0.00067363 rank 4
2023-02-11 12:49:29,228 DEBUG TRAIN Batch 6/5100 loss 40.072632 loss_att 43.489429 loss_ctc 56.495392 loss_rnnt 36.521301 hw_loss 0.127175 lr 0.00067336 rank 5
2023-02-11 12:49:29,277 DEBUG TRAIN Batch 6/5100 loss 33.145382 loss_att 29.169046 loss_ctc 43.941174 loss_rnnt 27.753136 hw_loss 0.890264 lr 0.00067362 rank 6
2023-02-11 12:50:45,053 DEBUG TRAIN Batch 6/5200 loss 13.162670 loss_att 17.558701 loss_ctc 22.599796 loss_rnnt 9.176693 hw_loss 0.346591 lr 0.00067248 rank 0
2023-02-11 12:50:45,059 DEBUG TRAIN Batch 6/5200 loss 22.121931 loss_att 22.279320 loss_ctc 25.995491 loss_rnnt 17.464092 hw_loss 0.770604 lr 0.00067286 rank 3
2023-02-11 12:50:45,059 DEBUG TRAIN Batch 6/5200 loss 11.819734 loss_att 13.491198 loss_ctc 20.621576 loss_rnnt 8.339455 hw_loss 0.369826 lr 0.00067301 rank 6
2023-02-11 12:50:45,061 DEBUG TRAIN Batch 6/5200 loss 20.403652 loss_att 23.087845 loss_ctc 33.995773 loss_rnnt 15.632772 hw_loss 0.454080 lr 0.00067286 rank 7
2023-02-11 12:50:45,061 DEBUG TRAIN Batch 6/5200 loss 25.282370 loss_att 28.890087 loss_ctc 28.431526 loss_rnnt 22.571966 hw_loss 0.294182 lr 0.00067275 rank 5
2023-02-11 12:50:45,062 DEBUG TRAIN Batch 6/5200 loss 24.892094 loss_att 32.729118 loss_ctc 38.147892 loss_rnnt 20.638937 hw_loss 0.172184 lr 0.00067261 rank 1
2023-02-11 12:50:45,063 DEBUG TRAIN Batch 6/5200 loss 24.189789 loss_att 29.039574 loss_ctc 41.920086 loss_rnnt 19.480434 hw_loss 0.257880 lr 0.00067302 rank 4
2023-02-11 12:50:45,064 DEBUG TRAIN Batch 6/5200 loss 11.664535 loss_att 12.197955 loss_ctc 13.116099 loss_rnnt 8.839710 hw_loss 0.473362 lr 0.00067231 rank 2
2023-02-11 12:52:04,064 DEBUG TRAIN Batch 6/5300 loss 13.135776 loss_att 14.606358 loss_ctc 21.918539 loss_rnnt 10.682785 hw_loss 0.185219 lr 0.00067241 rank 6
2023-02-11 12:52:04,064 DEBUG TRAIN Batch 6/5300 loss 25.642990 loss_att 25.470974 loss_ctc 31.571327 loss_rnnt 21.407814 hw_loss 0.652338 lr 0.00067214 rank 5
2023-02-11 12:52:04,064 DEBUG TRAIN Batch 6/5300 loss 29.200518 loss_att 25.928858 loss_ctc 39.165127 loss_rnnt 27.222204 hw_loss 0.244506 lr 0.00067170 rank 2
2023-02-11 12:52:04,064 DEBUG TRAIN Batch 6/5300 loss 22.242870 loss_att 23.861015 loss_ctc 30.046551 loss_rnnt 17.780767 hw_loss 0.580871 lr 0.00067225 rank 7
2023-02-11 12:52:04,069 DEBUG TRAIN Batch 6/5300 loss 22.261757 loss_att 24.851397 loss_ctc 30.326117 loss_rnnt 18.836239 hw_loss 0.343565 lr 0.00067200 rank 1
2023-02-11 12:52:04,070 DEBUG TRAIN Batch 6/5300 loss 25.563282 loss_att 32.873688 loss_ctc 39.171471 loss_rnnt 21.139454 hw_loss 0.215123 lr 0.00067241 rank 4
2023-02-11 12:52:04,072 DEBUG TRAIN Batch 6/5300 loss 16.258377 loss_att 19.357155 loss_ctc 20.659904 loss_rnnt 11.222972 hw_loss 0.717896 lr 0.00067187 rank 0
2023-02-11 12:52:04,099 DEBUG TRAIN Batch 6/5300 loss 19.970366 loss_att 23.621986 loss_ctc 29.614849 loss_rnnt 14.760765 hw_loss 0.598752 lr 0.00067225 rank 3
2023-02-11 12:53:20,446 DEBUG TRAIN Batch 6/5400 loss 25.569386 loss_att 29.767937 loss_ctc 37.742199 loss_rnnt 21.440693 hw_loss 0.312364 lr 0.00067126 rank 0
2023-02-11 12:53:20,446 DEBUG TRAIN Batch 6/5400 loss 11.512466 loss_att 17.313562 loss_ctc 20.427477 loss_rnnt 8.613493 hw_loss 0.103141 lr 0.00067153 rank 5
2023-02-11 12:53:20,447 DEBUG TRAIN Batch 6/5400 loss 26.658546 loss_att 26.013954 loss_ctc 38.293060 loss_rnnt 21.392000 hw_loss 0.720786 lr 0.00067180 rank 4
2023-02-11 12:53:20,451 DEBUG TRAIN Batch 6/5400 loss 14.773409 loss_att 20.738848 loss_ctc 26.907700 loss_rnnt 10.895063 hw_loss 0.200128 lr 0.00067165 rank 3
2023-02-11 12:53:20,452 DEBUG TRAIN Batch 6/5400 loss 9.366670 loss_att 15.036654 loss_ctc 14.872470 loss_rnnt 6.959571 hw_loss 0.101062 lr 0.00067165 rank 7
2023-02-11 12:53:20,454 DEBUG TRAIN Batch 6/5400 loss 20.162739 loss_att 22.008383 loss_ctc 29.572111 loss_rnnt 15.864424 hw_loss 0.501488 lr 0.00067139 rank 1
2023-02-11 12:53:20,462 DEBUG TRAIN Batch 6/5400 loss 21.069805 loss_att 22.463657 loss_ctc 34.231697 loss_rnnt 16.591864 hw_loss 0.458297 lr 0.00067180 rank 6
2023-02-11 12:53:20,494 DEBUG TRAIN Batch 6/5400 loss 16.689341 loss_att 17.530142 loss_ctc 20.126499 loss_rnnt 11.498476 hw_loss 0.855828 lr 0.00067110 rank 2
2023-02-11 12:54:36,821 DEBUG TRAIN Batch 6/5500 loss 24.136372 loss_att 29.172565 loss_ctc 31.192598 loss_rnnt 20.552872 hw_loss 0.306643 lr 0.00067120 rank 4
2023-02-11 12:54:36,824 DEBUG TRAIN Batch 6/5500 loss 16.152590 loss_att 21.267708 loss_ctc 21.465916 loss_rnnt 11.899179 hw_loss 0.472864 lr 0.00067104 rank 3
2023-02-11 12:54:36,825 DEBUG TRAIN Batch 6/5500 loss 12.910435 loss_att 13.774935 loss_ctc 18.771023 loss_rnnt 9.508178 hw_loss 0.458990 lr 0.00067104 rank 7
2023-02-11 12:54:36,825 DEBUG TRAIN Batch 6/5500 loss 22.880987 loss_att 27.124752 loss_ctc 35.093609 loss_rnnt 17.845434 hw_loss 0.479709 lr 0.00067079 rank 1
2023-02-11 12:54:36,826 DEBUG TRAIN Batch 6/5500 loss 19.647015 loss_att 23.654856 loss_ctc 32.280930 loss_rnnt 15.845873 hw_loss 0.246572 lr 0.00067049 rank 2
2023-02-11 12:54:36,827 DEBUG TRAIN Batch 6/5500 loss 23.580143 loss_att 27.786325 loss_ctc 38.592186 loss_rnnt 18.131809 hw_loss 0.488529 lr 0.00067093 rank 5
2023-02-11 12:54:36,827 DEBUG TRAIN Batch 6/5500 loss 25.120188 loss_att 29.951092 loss_ctc 37.823769 loss_rnnt 20.877123 hw_loss 0.296826 lr 0.00067066 rank 0
2023-02-11 12:54:36,829 DEBUG TRAIN Batch 6/5500 loss 30.499046 loss_att 34.383041 loss_ctc 43.619846 loss_rnnt 26.063185 hw_loss 0.358054 lr 0.00067119 rank 6
2023-02-11 12:55:52,523 DEBUG TRAIN Batch 6/5600 loss 13.184131 loss_att 15.152328 loss_ctc 19.974035 loss_rnnt 9.976418 hw_loss 0.357891 lr 0.00066989 rank 2
2023-02-11 12:55:52,524 DEBUG TRAIN Batch 6/5600 loss 14.096233 loss_att 15.975222 loss_ctc 17.982172 loss_rnnt 10.800364 hw_loss 0.450365 lr 0.00067044 rank 7
2023-02-11 12:55:52,524 DEBUG TRAIN Batch 6/5600 loss 23.305273 loss_att 25.208088 loss_ctc 36.969093 loss_rnnt 17.387936 hw_loss 0.696549 lr 0.00067006 rank 0
2023-02-11 12:55:52,525 DEBUG TRAIN Batch 6/5600 loss 19.254358 loss_att 22.903049 loss_ctc 26.922516 loss_rnnt 15.653049 hw_loss 0.346716 lr 0.00067059 rank 4
2023-02-11 12:55:52,526 DEBUG TRAIN Batch 6/5600 loss 21.469620 loss_att 23.205759 loss_ctc 31.617090 loss_rnnt 17.663971 hw_loss 0.394767 lr 0.00067044 rank 3
2023-02-11 12:55:52,525 DEBUG TRAIN Batch 6/5600 loss 16.893591 loss_att 19.665676 loss_ctc 24.206570 loss_rnnt 14.777161 hw_loss 0.110053 lr 0.00067059 rank 6
2023-02-11 12:55:52,525 DEBUG TRAIN Batch 6/5600 loss 18.090738 loss_att 18.490887 loss_ctc 26.003113 loss_rnnt 11.964831 hw_loss 0.935793 lr 0.00067032 rank 5
2023-02-11 12:55:52,526 DEBUG TRAIN Batch 6/5600 loss 27.406044 loss_att 29.716732 loss_ctc 50.533737 loss_rnnt 21.566933 hw_loss 0.429990 lr 0.00067018 rank 1
2023-02-11 12:57:11,173 DEBUG TRAIN Batch 6/5700 loss 21.884396 loss_att 20.084404 loss_ctc 30.129488 loss_rnnt 16.708462 hw_loss 0.831860 lr 0.00066984 rank 7
2023-02-11 12:57:11,175 DEBUG TRAIN Batch 6/5700 loss 19.785252 loss_att 17.262194 loss_ctc 21.291067 loss_rnnt 13.617229 hw_loss 1.213473 lr 0.00066958 rank 1
2023-02-11 12:57:11,176 DEBUG TRAIN Batch 6/5700 loss 23.714785 loss_att 21.876148 loss_ctc 29.727240 loss_rnnt 18.613546 hw_loss 0.875120 lr 0.00066946 rank 0
2023-02-11 12:57:11,179 DEBUG TRAIN Batch 6/5700 loss 21.874596 loss_att 20.831202 loss_ctc 36.944767 loss_rnnt 16.043736 hw_loss 0.755659 lr 0.00066984 rank 3
2023-02-11 12:57:11,181 DEBUG TRAIN Batch 6/5700 loss 37.307873 loss_att 37.088943 loss_ctc 46.646381 loss_rnnt 34.093178 hw_loss 0.377503 lr 0.00066999 rank 6
2023-02-11 12:57:11,181 DEBUG TRAIN Batch 6/5700 loss 13.393604 loss_att 15.233602 loss_ctc 21.898357 loss_rnnt 8.653765 hw_loss 0.607101 lr 0.00066929 rank 2
2023-02-11 12:57:11,183 DEBUG TRAIN Batch 6/5700 loss 13.951875 loss_att 12.382369 loss_ctc 18.089121 loss_rnnt 9.241480 hw_loss 0.838624 lr 0.00066972 rank 5
2023-02-11 12:57:11,183 DEBUG TRAIN Batch 6/5700 loss 12.330421 loss_att 11.717274 loss_ctc 15.658695 loss_rnnt 8.586635 hw_loss 0.641746 lr 0.00066999 rank 4
2023-02-11 12:58:27,874 DEBUG TRAIN Batch 6/5800 loss 8.194471 loss_att 9.463586 loss_ctc 10.701087 loss_rnnt 4.964832 hw_loss 0.495300 lr 0.00066924 rank 3
2023-02-11 12:58:27,879 DEBUG TRAIN Batch 6/5800 loss 26.546471 loss_att 33.833626 loss_ctc 42.708260 loss_rnnt 20.672485 hw_loss 0.424059 lr 0.00066898 rank 1
2023-02-11 12:58:27,879 DEBUG TRAIN Batch 6/5800 loss 16.583174 loss_att 13.125061 loss_ctc 17.311590 loss_rnnt 12.062066 hw_loss 0.959176 lr 0.00066886 rank 0
2023-02-11 12:58:27,881 DEBUG TRAIN Batch 6/5800 loss 25.420218 loss_att 25.402838 loss_ctc 36.695015 loss_rnnt 22.135223 hw_loss 0.334718 lr 0.00066939 rank 6
2023-02-11 12:58:27,881 DEBUG TRAIN Batch 6/5800 loss 13.599373 loss_att 18.596943 loss_ctc 22.949093 loss_rnnt 8.670614 hw_loss 0.502990 lr 0.00066924 rank 7
2023-02-11 12:58:27,882 DEBUG TRAIN Batch 6/5800 loss 28.951740 loss_att 33.474209 loss_ctc 54.119682 loss_rnnt 22.336416 hw_loss 0.441582 lr 0.00066912 rank 5
2023-02-11 12:58:27,885 DEBUG TRAIN Batch 6/5800 loss 14.144872 loss_att 18.152157 loss_ctc 16.225895 loss_rnnt 10.741709 hw_loss 0.435794 lr 0.00066869 rank 2
2023-02-11 12:58:27,933 DEBUG TRAIN Batch 6/5800 loss 15.114174 loss_att 17.872448 loss_ctc 26.837601 loss_rnnt 11.516369 hw_loss 0.278067 lr 0.00066939 rank 4
2023-02-11 12:59:44,155 DEBUG TRAIN Batch 6/5900 loss 13.124659 loss_att 10.818021 loss_ctc 14.797663 loss_rnnt 9.494496 hw_loss 0.725329 lr 0.00066864 rank 3
2023-02-11 12:59:44,159 DEBUG TRAIN Batch 6/5900 loss 23.199902 loss_att 24.369091 loss_ctc 32.282524 loss_rnnt 18.622862 hw_loss 0.587285 lr 0.00066864 rank 7
2023-02-11 12:59:44,159 DEBUG TRAIN Batch 6/5900 loss 14.455797 loss_att 18.004145 loss_ctc 27.506168 loss_rnnt 9.916233 hw_loss 0.391846 lr 0.00066826 rank 0
2023-02-11 12:59:44,161 DEBUG TRAIN Batch 6/5900 loss 24.818254 loss_att 27.708763 loss_ctc 31.794296 loss_rnnt 19.504696 hw_loss 0.713497 lr 0.00066852 rank 5
2023-02-11 12:59:44,162 DEBUG TRAIN Batch 6/5900 loss 11.505184 loss_att 21.417233 loss_ctc 24.422928 loss_rnnt 6.396294 hw_loss 0.263271 lr 0.00066879 rank 6
2023-02-11 12:59:44,162 DEBUG TRAIN Batch 6/5900 loss 19.521021 loss_att 22.816751 loss_ctc 26.548634 loss_rnnt 17.102247 hw_loss 0.154240 lr 0.00066839 rank 1
2023-02-11 12:59:44,164 DEBUG TRAIN Batch 6/5900 loss 25.518095 loss_att 29.182661 loss_ctc 39.874115 loss_rnnt 21.970655 hw_loss 0.168823 lr 0.00066879 rank 4
2023-02-11 12:59:44,205 DEBUG TRAIN Batch 6/5900 loss 19.139992 loss_att 19.279966 loss_ctc 31.346214 loss_rnnt 15.778373 hw_loss 0.319899 lr 0.00066809 rank 2
2023-02-11 13:01:02,677 DEBUG TRAIN Batch 6/6000 loss 12.126997 loss_att 15.377912 loss_ctc 14.709373 loss_rnnt 8.579960 hw_loss 0.478601 lr 0.00066766 rank 0
2023-02-11 13:01:02,680 DEBUG TRAIN Batch 6/6000 loss 20.903847 loss_att 22.094284 loss_ctc 32.763039 loss_rnnt 17.325535 hw_loss 0.329812 lr 0.00066804 rank 3
2023-02-11 13:01:02,682 DEBUG TRAIN Batch 6/6000 loss 19.291214 loss_att 24.607534 loss_ctc 31.394699 loss_rnnt 14.766250 hw_loss 0.346482 lr 0.00066750 rank 2
2023-02-11 13:01:02,685 DEBUG TRAIN Batch 6/6000 loss 11.483091 loss_att 15.204731 loss_ctc 16.602224 loss_rnnt 7.948376 hw_loss 0.395219 lr 0.00066804 rank 7
2023-02-11 13:01:02,686 DEBUG TRAIN Batch 6/6000 loss 21.821774 loss_att 26.752407 loss_ctc 28.508158 loss_rnnt 17.409546 hw_loss 0.475234 lr 0.00066793 rank 5
2023-02-11 13:01:02,689 DEBUG TRAIN Batch 6/6000 loss 11.089020 loss_att 10.612240 loss_ctc 12.305954 loss_rnnt 7.076749 hw_loss 0.739756 lr 0.00066779 rank 1
2023-02-11 13:01:02,690 DEBUG TRAIN Batch 6/6000 loss 31.145742 loss_att 32.181740 loss_ctc 46.771225 loss_rnnt 26.689241 hw_loss 0.406107 lr 0.00066819 rank 4
2023-02-11 13:01:02,692 DEBUG TRAIN Batch 6/6000 loss 21.987730 loss_att 27.081814 loss_ctc 29.256794 loss_rnnt 19.284622 hw_loss 0.134078 lr 0.00066819 rank 6
2023-02-11 13:02:20,324 DEBUG TRAIN Batch 6/6100 loss 22.399492 loss_att 25.137783 loss_ctc 34.416580 loss_rnnt 17.162022 hw_loss 0.578912 lr 0.00066744 rank 3
2023-02-11 13:02:20,329 DEBUG TRAIN Batch 6/6100 loss 30.391151 loss_att 31.253902 loss_ctc 44.473351 loss_rnnt 26.781303 hw_loss 0.292438 lr 0.00066690 rank 2
2023-02-11 13:02:20,329 DEBUG TRAIN Batch 6/6100 loss 21.485657 loss_att 25.281321 loss_ctc 26.004805 loss_rnnt 17.030075 hw_loss 0.580105 lr 0.00066719 rank 1
2023-02-11 13:02:20,331 DEBUG TRAIN Batch 6/6100 loss 18.395346 loss_att 18.903336 loss_ctc 27.402233 loss_rnnt 14.758471 hw_loss 0.437692 lr 0.00066744 rank 7
2023-02-11 13:02:20,332 DEBUG TRAIN Batch 6/6100 loss 12.980219 loss_att 12.727154 loss_ctc 22.002016 loss_rnnt 10.597649 hw_loss 0.230677 lr 0.00066733 rank 5
2023-02-11 13:02:20,332 DEBUG TRAIN Batch 6/6100 loss 29.930193 loss_att 30.847435 loss_ctc 47.732754 loss_rnnt 25.974567 hw_loss 0.262219 lr 0.00066759 rank 6
2023-02-11 13:02:20,333 DEBUG TRAIN Batch 6/6100 loss 18.481825 loss_att 19.791571 loss_ctc 23.641352 loss_rnnt 15.025600 hw_loss 0.469939 lr 0.00066707 rank 0
2023-02-11 13:02:20,383 DEBUG TRAIN Batch 6/6100 loss 37.281986 loss_att 39.170647 loss_ctc 47.893700 loss_rnnt 35.080715 hw_loss 0.076621 lr 0.00066760 rank 4
2023-02-11 13:03:36,678 DEBUG TRAIN Batch 6/6200 loss 27.572056 loss_att 30.055164 loss_ctc 38.304367 loss_rnnt 22.143131 hw_loss 0.656499 lr 0.00066631 rank 2
2023-02-11 13:03:36,679 DEBUG TRAIN Batch 6/6200 loss 11.308649 loss_att 12.255330 loss_ctc 15.571095 loss_rnnt 7.726648 hw_loss 0.529563 lr 0.00066674 rank 5
2023-02-11 13:03:36,679 DEBUG TRAIN Batch 6/6200 loss 18.151049 loss_att 21.939934 loss_ctc 24.503433 loss_rnnt 14.690743 hw_loss 0.347914 lr 0.00066700 rank 6
2023-02-11 13:03:36,680 DEBUG TRAIN Batch 6/6200 loss 21.498632 loss_att 23.114370 loss_ctc 27.478447 loss_rnnt 17.892675 hw_loss 0.466032 lr 0.00066648 rank 0
2023-02-11 13:03:36,681 DEBUG TRAIN Batch 6/6200 loss 16.960630 loss_att 18.339682 loss_ctc 22.536545 loss_rnnt 13.271834 hw_loss 0.500537 lr 0.00066660 rank 1
2023-02-11 13:03:36,682 DEBUG TRAIN Batch 6/6200 loss 22.387352 loss_att 26.065762 loss_ctc 32.736397 loss_rnnt 19.176228 hw_loss 0.205419 lr 0.00066685 rank 3
2023-02-11 13:03:36,683 DEBUG TRAIN Batch 6/6200 loss 16.320509 loss_att 17.772423 loss_ctc 26.185698 loss_rnnt 14.065680 hw_loss 0.121704 lr 0.00066685 rank 7
2023-02-11 13:03:36,727 DEBUG TRAIN Batch 6/6200 loss 21.702162 loss_att 24.247965 loss_ctc 35.121311 loss_rnnt 17.736393 hw_loss 0.312635 lr 0.00066700 rank 4
2023-02-11 13:04:53,330 DEBUG TRAIN Batch 6/6300 loss 20.704710 loss_att 21.901134 loss_ctc 32.141460 loss_rnnt 16.625237 hw_loss 0.434117 lr 0.00066601 rank 1
2023-02-11 13:04:53,331 DEBUG TRAIN Batch 6/6300 loss 16.905418 loss_att 19.965422 loss_ctc 20.805378 loss_rnnt 11.172167 hw_loss 0.862736 lr 0.00066626 rank 3
2023-02-11 13:04:53,331 DEBUG TRAIN Batch 6/6300 loss 22.161242 loss_att 22.801159 loss_ctc 27.879749 loss_rnnt 18.414816 hw_loss 0.535495 lr 0.00066641 rank 6
2023-02-11 13:04:53,332 DEBUG TRAIN Batch 6/6300 loss 19.725780 loss_att 17.286543 loss_ctc 23.162521 loss_rnnt 16.159882 hw_loss 0.674159 lr 0.00066572 rank 2
2023-02-11 13:04:53,333 DEBUG TRAIN Batch 6/6300 loss 17.021767 loss_att 18.999418 loss_ctc 24.793980 loss_rnnt 11.169991 hw_loss 0.828741 lr 0.00066589 rank 0
2023-02-11 13:04:53,338 DEBUG TRAIN Batch 6/6300 loss 17.251106 loss_att 17.517574 loss_ctc 21.676506 loss_rnnt 11.934284 hw_loss 0.876277 lr 0.00066641 rank 4
2023-02-11 13:04:53,352 DEBUG TRAIN Batch 6/6300 loss 12.346811 loss_att 14.713255 loss_ctc 19.886719 loss_rnnt 8.658607 hw_loss 0.414299 lr 0.00066626 rank 7
2023-02-11 13:04:53,364 DEBUG TRAIN Batch 6/6300 loss 24.129208 loss_att 23.315878 loss_ctc 32.839630 loss_rnnt 19.304602 hw_loss 0.717354 lr 0.00066615 rank 5
2023-02-11 13:06:12,931 DEBUG TRAIN Batch 6/6400 loss 19.667040 loss_att 17.577442 loss_ctc 23.623266 loss_rnnt 13.427014 hw_loss 1.149459 lr 0.00066530 rank 0
2023-02-11 13:06:12,931 DEBUG TRAIN Batch 6/6400 loss 19.432339 loss_att 13.617050 loss_ctc 19.654970 loss_rnnt 13.688582 hw_loss 1.289462 lr 0.00066567 rank 7
2023-02-11 13:06:12,938 DEBUG TRAIN Batch 6/6400 loss 18.949095 loss_att 18.096188 loss_ctc 19.607466 loss_rnnt 15.948279 hw_loss 0.578178 lr 0.00066567 rank 3
2023-02-11 13:06:12,939 DEBUG TRAIN Batch 6/6400 loss 21.368881 loss_att 24.469915 loss_ctc 28.493534 loss_rnnt 18.422234 hw_loss 0.258091 lr 0.00066513 rank 2
2023-02-11 13:06:12,940 DEBUG TRAIN Batch 6/6400 loss 13.105869 loss_att 17.442057 loss_ctc 17.339922 loss_rnnt 10.758873 hw_loss 0.171603 lr 0.00066581 rank 6
2023-02-11 13:06:12,940 DEBUG TRAIN Batch 6/6400 loss 9.121181 loss_att 14.904404 loss_ctc 16.362164 loss_rnnt 6.640920 hw_loss 0.067154 lr 0.00066582 rank 4
2023-02-11 13:06:12,940 DEBUG TRAIN Batch 6/6400 loss 14.959374 loss_att 20.260944 loss_ctc 21.892036 loss_rnnt 11.953143 hw_loss 0.191543 lr 0.00066556 rank 5
2023-02-11 13:06:12,942 DEBUG TRAIN Batch 6/6400 loss 22.623669 loss_att 25.705996 loss_ctc 29.136429 loss_rnnt 18.608471 hw_loss 0.474443 lr 0.00066542 rank 1
2023-02-11 13:07:29,506 DEBUG TRAIN Batch 6/6500 loss 59.220837 loss_att 55.881393 loss_ctc 74.955742 loss_rnnt 56.442062 hw_loss 0.252876 lr 0.00066508 rank 7
2023-02-11 13:07:29,507 DEBUG TRAIN Batch 6/6500 loss 20.280436 loss_att 21.403513 loss_ctc 35.597763 loss_rnnt 15.168094 hw_loss 0.533515 lr 0.00066454 rank 2
2023-02-11 13:07:29,508 DEBUG TRAIN Batch 6/6500 loss 21.749863 loss_att 21.814293 loss_ctc 26.843491 loss_rnnt 17.417030 hw_loss 0.682649 lr 0.00066508 rank 3
2023-02-11 13:07:29,509 DEBUG TRAIN Batch 6/6500 loss 14.101841 loss_att 18.859489 loss_ctc 26.658545 loss_rnnt 10.857140 hw_loss 0.116052 lr 0.00066497 rank 5
2023-02-11 13:07:29,509 DEBUG TRAIN Batch 6/6500 loss 19.339802 loss_att 26.112202 loss_ctc 36.481506 loss_rnnt 13.688670 hw_loss 0.377079 lr 0.00066523 rank 6
2023-02-11 13:07:29,510 DEBUG TRAIN Batch 6/6500 loss 21.820351 loss_att 25.814798 loss_ctc 34.067169 loss_rnnt 17.227516 hw_loss 0.405194 lr 0.00066471 rank 0
2023-02-11 13:07:29,513 DEBUG TRAIN Batch 6/6500 loss 11.963905 loss_att 14.027519 loss_ctc 15.231035 loss_rnnt 7.320331 hw_loss 0.711607 lr 0.00066483 rank 1
2023-02-11 13:07:29,513 DEBUG TRAIN Batch 6/6500 loss 11.607866 loss_att 15.989620 loss_ctc 20.540232 loss_rnnt 8.811039 hw_loss 0.136780 lr 0.00066523 rank 4
2023-02-11 13:08:45,200 DEBUG TRAIN Batch 6/6600 loss 13.495549 loss_att 19.236423 loss_ctc 21.062462 loss_rnnt 10.040236 hw_loss 0.243415 lr 0.00066464 rank 6
2023-02-11 13:08:45,200 DEBUG TRAIN Batch 6/6600 loss 19.675318 loss_att 27.699272 loss_ctc 32.626358 loss_rnnt 12.950561 hw_loss 0.636218 lr 0.00066438 rank 5
2023-02-11 13:08:45,201 DEBUG TRAIN Batch 6/6600 loss 13.573311 loss_att 16.340586 loss_ctc 22.260777 loss_rnnt 10.369307 hw_loss 0.279791 lr 0.00066464 rank 4
2023-02-11 13:08:45,201 DEBUG TRAIN Batch 6/6600 loss 17.248333 loss_att 19.961227 loss_ctc 26.174549 loss_rnnt 13.647863 hw_loss 0.350199 lr 0.00066396 rank 2
2023-02-11 13:08:45,202 DEBUG TRAIN Batch 6/6600 loss 20.711145 loss_att 22.366243 loss_ctc 34.989403 loss_rnnt 15.704865 hw_loss 0.519655 lr 0.00066412 rank 0
2023-02-11 13:08:45,203 DEBUG TRAIN Batch 6/6600 loss 20.055340 loss_att 22.502863 loss_ctc 27.898048 loss_rnnt 17.550806 hw_loss 0.181750 lr 0.00066449 rank 3
2023-02-11 13:08:45,205 DEBUG TRAIN Batch 6/6600 loss 30.084188 loss_att 38.819229 loss_ctc 51.775482 loss_rnnt 24.970581 hw_loss 0.088956 lr 0.00066449 rank 7
2023-02-11 13:08:45,207 DEBUG TRAIN Batch 6/6600 loss 11.270629 loss_att 15.792681 loss_ctc 17.274603 loss_rnnt 8.521071 hw_loss 0.195866 lr 0.00066424 rank 1
2023-02-11 13:10:01,374 DEBUG TRAIN Batch 6/6700 loss 18.381737 loss_att 20.637089 loss_ctc 30.446165 loss_rnnt 15.071213 hw_loss 0.234537 lr 0.00066405 rank 6
2023-02-11 13:10:01,376 DEBUG TRAIN Batch 6/6700 loss 23.693108 loss_att 24.213196 loss_ctc 37.169250 loss_rnnt 20.084803 hw_loss 0.320150 lr 0.00066379 rank 5
2023-02-11 13:10:01,376 DEBUG TRAIN Batch 6/6700 loss 14.713984 loss_att 15.581734 loss_ctc 23.262310 loss_rnnt 11.329755 hw_loss 0.388294 lr 0.00066337 rank 2
2023-02-11 13:10:01,377 DEBUG TRAIN Batch 6/6700 loss 25.369581 loss_att 23.897284 loss_ctc 32.681557 loss_rnnt 21.717024 hw_loss 0.557266 lr 0.00066390 rank 3
2023-02-11 13:10:01,378 DEBUG TRAIN Batch 6/6700 loss 18.892254 loss_att 20.997066 loss_ctc 26.464939 loss_rnnt 15.995703 hw_loss 0.274856 lr 0.00066406 rank 4
2023-02-11 13:10:01,379 DEBUG TRAIN Batch 6/6700 loss 36.693684 loss_att 37.620045 loss_ctc 48.778210 loss_rnnt 32.838612 hw_loss 0.385974 lr 0.00066390 rank 7
2023-02-11 13:10:01,384 DEBUG TRAIN Batch 6/6700 loss 18.937632 loss_att 20.605949 loss_ctc 29.457748 loss_rnnt 15.439013 hw_loss 0.330426 lr 0.00066354 rank 0
2023-02-11 13:10:01,390 DEBUG TRAIN Batch 6/6700 loss 36.684570 loss_att 43.046658 loss_ctc 65.666977 loss_rnnt 29.800915 hw_loss 0.327547 lr 0.00066366 rank 1
2023-02-11 13:11:19,148 DEBUG TRAIN Batch 6/6800 loss 12.434727 loss_att 18.830709 loss_ctc 21.982113 loss_rnnt 9.179420 hw_loss 0.131836 lr 0.00066295 rank 0
2023-02-11 13:11:19,148 DEBUG TRAIN Batch 6/6800 loss 15.825842 loss_att 17.552879 loss_ctc 27.079844 loss_rnnt 11.128619 hw_loss 0.534615 lr 0.00066332 rank 7
2023-02-11 13:11:19,150 DEBUG TRAIN Batch 6/6800 loss 15.954211 loss_att 17.847338 loss_ctc 29.052862 loss_rnnt 9.476013 hw_loss 0.816203 lr 0.00066347 rank 6
2023-02-11 13:11:19,154 DEBUG TRAIN Batch 6/6800 loss 19.987097 loss_att 23.049423 loss_ctc 28.447645 loss_rnnt 15.761069 hw_loss 0.466029 lr 0.00066332 rank 3
2023-02-11 13:11:19,154 DEBUG TRAIN Batch 6/6800 loss 23.993061 loss_att 27.463690 loss_ctc 35.002914 loss_rnnt 21.560253 hw_loss 0.050757 lr 0.00066279 rank 2
2023-02-11 13:11:19,157 DEBUG TRAIN Batch 6/6800 loss 18.731272 loss_att 18.918268 loss_ctc 28.002768 loss_rnnt 13.443729 hw_loss 0.752614 lr 0.00066347 rank 4
2023-02-11 13:11:19,157 DEBUG TRAIN Batch 6/6800 loss 8.661736 loss_att 10.947246 loss_ctc 12.074102 loss_rnnt 5.262001 hw_loss 0.466434 lr 0.00066308 rank 1
2023-02-11 13:11:19,164 DEBUG TRAIN Batch 6/6800 loss 23.676395 loss_att 22.041260 loss_ctc 33.187981 loss_rnnt 19.731937 hw_loss 0.563114 lr 0.00066321 rank 5
2023-02-11 13:12:34,152 DEBUG TRAIN Batch 6/6900 loss 22.118916 loss_att 19.677353 loss_ctc 27.933136 loss_rnnt 17.552088 hw_loss 0.802483 lr 0.00066263 rank 5
2023-02-11 13:12:34,155 DEBUG TRAIN Batch 6/6900 loss 19.879728 loss_att 21.478737 loss_ctc 32.913319 loss_rnnt 13.692823 hw_loss 0.774242 lr 0.00066237 rank 0
2023-02-11 13:12:34,155 DEBUG TRAIN Batch 6/6900 loss 26.487825 loss_att 25.540993 loss_ctc 31.975464 loss_rnnt 22.125982 hw_loss 0.716161 lr 0.00066289 rank 4
2023-02-11 13:12:34,160 DEBUG TRAIN Batch 6/6900 loss 16.764221 loss_att 18.431894 loss_ctc 23.166153 loss_rnnt 14.178444 hw_loss 0.262247 lr 0.00066288 rank 6
2023-02-11 13:12:34,159 DEBUG TRAIN Batch 6/6900 loss 27.729933 loss_att 24.894911 loss_ctc 38.761368 loss_rnnt 22.475578 hw_loss 0.815719 lr 0.00066274 rank 3
2023-02-11 13:12:34,160 DEBUG TRAIN Batch 6/6900 loss 19.915340 loss_att 19.091743 loss_ctc 25.264479 loss_rnnt 16.518810 hw_loss 0.534006 lr 0.00066221 rank 2
2023-02-11 13:12:34,161 DEBUG TRAIN Batch 6/6900 loss 11.053950 loss_att 8.927777 loss_ctc 10.117827 loss_rnnt 6.967778 hw_loss 0.869292 lr 0.00066249 rank 1
2023-02-11 13:12:34,174 DEBUG TRAIN Batch 6/6900 loss 27.666861 loss_att 29.121649 loss_ctc 39.221680 loss_rnnt 23.430649 hw_loss 0.450864 lr 0.00066274 rank 7
2023-02-11 13:13:51,376 DEBUG TRAIN Batch 6/7000 loss 15.969077 loss_att 14.410349 loss_ctc 19.866282 loss_rnnt 11.127605 hw_loss 0.868798 lr 0.00066230 rank 6
2023-02-11 13:13:51,376 DEBUG TRAIN Batch 6/7000 loss 19.690201 loss_att 22.389648 loss_ctc 31.435268 loss_rnnt 14.561620 hw_loss 0.566753 lr 0.00066216 rank 3
2023-02-11 13:13:51,380 DEBUG TRAIN Batch 6/7000 loss 11.555079 loss_att 16.431387 loss_ctc 18.905354 loss_rnnt 8.053156 hw_loss 0.289992 lr 0.00066163 rank 2
2023-02-11 13:13:51,381 DEBUG TRAIN Batch 6/7000 loss 13.815730 loss_att 11.500025 loss_ctc 16.317076 loss_rnnt 10.178746 hw_loss 0.706240 lr 0.00066216 rank 7
2023-02-11 13:13:51,382 DEBUG TRAIN Batch 6/7000 loss 20.696777 loss_att 18.595041 loss_ctc 23.876631 loss_rnnt 15.583452 hw_loss 0.958067 lr 0.00066191 rank 1
2023-02-11 13:13:51,382 DEBUG TRAIN Batch 6/7000 loss 23.335236 loss_att 29.022415 loss_ctc 37.041962 loss_rnnt 19.435158 hw_loss 0.175327 lr 0.00066205 rank 5
2023-02-11 13:13:51,383 DEBUG TRAIN Batch 6/7000 loss 16.747585 loss_att 15.983156 loss_ctc 20.411987 loss_rnnt 12.350264 hw_loss 0.761554 lr 0.00066179 rank 0
2023-02-11 13:13:51,385 DEBUG TRAIN Batch 6/7000 loss 26.666971 loss_att 26.179651 loss_ctc 40.818733 loss_rnnt 23.570419 hw_loss 0.245084 lr 0.00066231 rank 4
2023-02-11 13:15:09,322 DEBUG TRAIN Batch 6/7100 loss 16.028698 loss_att 13.766253 loss_ctc 17.517294 loss_rnnt 10.670925 hw_loss 1.052209 lr 0.00066158 rank 3
2023-02-11 13:15:09,322 DEBUG TRAIN Batch 6/7100 loss 15.502286 loss_att 19.519131 loss_ctc 26.215826 loss_rnnt 12.871239 hw_loss 0.074851 lr 0.00066121 rank 0
2023-02-11 13:15:09,325 DEBUG TRAIN Batch 6/7100 loss 28.252794 loss_att 29.776533 loss_ctc 33.169415 loss_rnnt 24.533024 hw_loss 0.517401 lr 0.00066133 rank 1
2023-02-11 13:15:09,325 DEBUG TRAIN Batch 6/7100 loss 17.152386 loss_att 19.689947 loss_ctc 28.477392 loss_rnnt 12.599929 hw_loss 0.475302 lr 0.00066105 rank 2
2023-02-11 13:15:09,328 DEBUG TRAIN Batch 6/7100 loss 14.569366 loss_att 18.451450 loss_ctc 21.840824 loss_rnnt 12.395918 hw_loss 0.080157 lr 0.00066147 rank 5
2023-02-11 13:15:09,329 DEBUG TRAIN Batch 6/7100 loss 16.654419 loss_att 11.662047 loss_ctc 15.645725 loss_rnnt 11.200629 hw_loss 1.235017 lr 0.00066158 rank 7
2023-02-11 13:15:09,330 DEBUG TRAIN Batch 6/7100 loss 14.357890 loss_att 20.546446 loss_ctc 23.332573 loss_rnnt 10.622256 hw_loss 0.243993 lr 0.00066172 rank 6
2023-02-11 13:15:09,331 DEBUG TRAIN Batch 6/7100 loss 28.019117 loss_att 30.895466 loss_ctc 40.222301 loss_rnnt 24.603531 hw_loss 0.227479 lr 0.00066173 rank 4
2023-02-11 13:16:25,727 DEBUG TRAIN Batch 6/7200 loss 21.814871 loss_att 25.162655 loss_ctc 31.983618 loss_rnnt 17.314867 hw_loss 0.463990 lr 0.00066100 rank 3
2023-02-11 13:16:25,728 DEBUG TRAIN Batch 6/7200 loss 17.149565 loss_att 16.734859 loss_ctc 20.893612 loss_rnnt 13.813290 hw_loss 0.547502 lr 0.00066063 rank 0
2023-02-11 13:16:25,730 DEBUG TRAIN Batch 6/7200 loss 18.372099 loss_att 18.837347 loss_ctc 26.476543 loss_rnnt 14.894592 hw_loss 0.431974 lr 0.00066047 rank 2
2023-02-11 13:16:25,731 DEBUG TRAIN Batch 6/7200 loss 13.629851 loss_att 19.164288 loss_ctc 24.452824 loss_rnnt 9.365965 hw_loss 0.321363 lr 0.00066114 rank 6
2023-02-11 13:16:25,735 DEBUG TRAIN Batch 6/7200 loss 13.719382 loss_att 18.477360 loss_ctc 20.933977 loss_rnnt 11.061441 hw_loss 0.139575 lr 0.00066100 rank 7
2023-02-11 13:16:25,735 DEBUG TRAIN Batch 6/7200 loss 14.355636 loss_att 15.663690 loss_ctc 20.969662 loss_rnnt 11.347331 hw_loss 0.349655 lr 0.00066089 rank 5
2023-02-11 13:16:25,735 DEBUG TRAIN Batch 6/7200 loss 36.839584 loss_att 37.586414 loss_ctc 59.045330 loss_rnnt 32.466255 hw_loss 0.236849 lr 0.00066115 rank 4
2023-02-11 13:16:25,736 DEBUG TRAIN Batch 6/7200 loss 40.407623 loss_att 41.026131 loss_ctc 54.160141 loss_rnnt 37.035118 hw_loss 0.265338 lr 0.00066076 rank 1
2023-02-11 13:17:41,672 DEBUG TRAIN Batch 6/7300 loss 11.359793 loss_att 12.685308 loss_ctc 15.604921 loss_rnnt 6.438550 hw_loss 0.766898 lr 0.00066042 rank 7
2023-02-11 13:17:41,676 DEBUG TRAIN Batch 6/7300 loss 28.053551 loss_att 29.834145 loss_ctc 39.379292 loss_rnnt 24.642601 hw_loss 0.289637 lr 0.00065990 rank 2
2023-02-11 13:17:41,678 DEBUG TRAIN Batch 6/7300 loss 34.267586 loss_att 31.173552 loss_ctc 53.231232 loss_rnnt 31.877823 hw_loss 0.090015 lr 0.00066042 rank 3
2023-02-11 13:17:41,679 DEBUG TRAIN Batch 6/7300 loss 19.329309 loss_att 21.545441 loss_ctc 27.162773 loss_rnnt 14.699907 hw_loss 0.589071 lr 0.00066006 rank 0
2023-02-11 13:17:41,679 DEBUG TRAIN Batch 6/7300 loss 28.589149 loss_att 26.215973 loss_ctc 34.530514 loss_rnnt 24.957619 hw_loss 0.621372 lr 0.00066031 rank 5
2023-02-11 13:17:41,680 DEBUG TRAIN Batch 6/7300 loss 16.667391 loss_att 22.695982 loss_ctc 29.476961 loss_rnnt 12.548721 hw_loss 0.225939 lr 0.00066057 rank 4
2023-02-11 13:17:41,681 DEBUG TRAIN Batch 6/7300 loss 14.896508 loss_att 19.290016 loss_ctc 24.038582 loss_rnnt 10.588099 hw_loss 0.414518 lr 0.00066056 rank 6
2023-02-11 13:17:41,728 DEBUG TRAIN Batch 6/7300 loss 28.860680 loss_att 32.160271 loss_ctc 44.851212 loss_rnnt 24.412271 hw_loss 0.310578 lr 0.00066018 rank 1
2023-02-11 13:18:58,924 DEBUG TRAIN Batch 6/7400 loss 25.704027 loss_att 27.060034 loss_ctc 39.297768 loss_rnnt 22.001543 hw_loss 0.303522 lr 0.00065999 rank 6
2023-02-11 13:18:58,924 DEBUG TRAIN Batch 6/7400 loss 33.059490 loss_att 37.551376 loss_ctc 47.920914 loss_rnnt 27.061535 hw_loss 0.584636 lr 0.00065985 rank 7
2023-02-11 13:18:58,926 DEBUG TRAIN Batch 6/7400 loss 38.084816 loss_att 44.040478 loss_ctc 57.254505 loss_rnnt 32.718410 hw_loss 0.303621 lr 0.00065985 rank 3
2023-02-11 13:18:58,926 DEBUG TRAIN Batch 6/7400 loss 18.481314 loss_att 22.072651 loss_ctc 27.323259 loss_rnnt 15.564317 hw_loss 0.191213 lr 0.00065974 rank 5
2023-02-11 13:18:58,929 DEBUG TRAIN Batch 6/7400 loss 18.456223 loss_att 21.488148 loss_ctc 27.714136 loss_rnnt 13.102790 hw_loss 0.658624 lr 0.00065948 rank 0
2023-02-11 13:18:58,931 DEBUG TRAIN Batch 6/7400 loss 18.002253 loss_att 20.697361 loss_ctc 30.403900 loss_rnnt 13.819456 hw_loss 0.373166 lr 0.00065932 rank 2
2023-02-11 13:18:58,934 DEBUG TRAIN Batch 6/7400 loss 23.374495 loss_att 22.439087 loss_ctc 29.659779 loss_rnnt 17.732553 hw_loss 0.935809 lr 0.00065999 rank 4
2023-02-11 13:18:58,979 DEBUG TRAIN Batch 6/7400 loss 25.035313 loss_att 25.420477 loss_ctc 38.543945 loss_rnnt 21.053013 hw_loss 0.394522 lr 0.00065960 rank 1
2023-02-11 13:20:16,818 DEBUG TRAIN Batch 6/7500 loss 34.289600 loss_att 38.013527 loss_ctc 48.669060 loss_rnnt 28.942562 hw_loss 0.503436 lr 0.00065903 rank 1
2023-02-11 13:20:16,822 DEBUG TRAIN Batch 6/7500 loss 22.394398 loss_att 25.661554 loss_ctc 37.150169 loss_rnnt 17.957853 hw_loss 0.340439 lr 0.00065942 rank 4
2023-02-11 13:20:16,823 DEBUG TRAIN Batch 6/7500 loss 16.221199 loss_att 17.808275 loss_ctc 23.909555 loss_rnnt 11.207933 hw_loss 0.688263 lr 0.00065891 rank 0
2023-02-11 13:20:16,824 DEBUG TRAIN Batch 6/7500 loss 25.877800 loss_att 29.039753 loss_ctc 38.223347 loss_rnnt 20.551664 hw_loss 0.571439 lr 0.00065927 rank 3
2023-02-11 13:20:16,825 DEBUG TRAIN Batch 6/7500 loss 21.598804 loss_att 23.735298 loss_ctc 31.844116 loss_rnnt 16.391653 hw_loss 0.640090 lr 0.00065875 rank 2
2023-02-11 13:20:16,825 DEBUG TRAIN Batch 6/7500 loss 12.066623 loss_att 13.648747 loss_ctc 20.557129 loss_rnnt 8.198994 hw_loss 0.453588 lr 0.00065927 rank 7
2023-02-11 13:20:16,828 DEBUG TRAIN Batch 6/7500 loss 32.653141 loss_att 29.985147 loss_ctc 41.502842 loss_rnnt 28.750229 hw_loss 0.610603 lr 0.00065941 rank 6
2023-02-11 13:20:16,831 DEBUG TRAIN Batch 6/7500 loss 9.088410 loss_att 9.149155 loss_ctc 12.183393 loss_rnnt 4.611653 hw_loss 0.759739 lr 0.00065916 rank 5
2023-02-11 13:21:33,304 DEBUG TRAIN Batch 6/7600 loss 23.086260 loss_att 28.974293 loss_ctc 39.206097 loss_rnnt 17.994614 hw_loss 0.330886 lr 0.00065870 rank 7
2023-02-11 13:21:33,306 DEBUG TRAIN Batch 6/7600 loss 14.815435 loss_att 19.705805 loss_ctc 19.101734 loss_rnnt 11.585696 hw_loss 0.315030 lr 0.00065818 rank 2
2023-02-11 13:21:33,307 DEBUG TRAIN Batch 6/7600 loss 24.950388 loss_att 22.860422 loss_ctc 31.125044 loss_rnnt 21.767828 hw_loss 0.520737 lr 0.00065885 rank 4
2023-02-11 13:21:33,308 DEBUG TRAIN Batch 6/7600 loss 18.122620 loss_att 20.361687 loss_ctc 29.619921 loss_rnnt 14.266315 hw_loss 0.351659 lr 0.00065870 rank 3
2023-02-11 13:21:33,309 DEBUG TRAIN Batch 6/7600 loss 16.627838 loss_att 17.432587 loss_ctc 25.175228 loss_rnnt 11.865542 hw_loss 0.649068 lr 0.00065834 rank 0
2023-02-11 13:21:33,309 DEBUG TRAIN Batch 6/7600 loss 20.698479 loss_att 18.690165 loss_ctc 25.289385 loss_rnnt 16.466551 hw_loss 0.754026 lr 0.00065859 rank 5
2023-02-11 13:21:33,339 DEBUG TRAIN Batch 6/7600 loss 22.285662 loss_att 25.530888 loss_ctc 31.266020 loss_rnnt 19.327347 hw_loss 0.208479 lr 0.00065846 rank 1
2023-02-11 13:21:33,352 DEBUG TRAIN Batch 6/7600 loss 28.556749 loss_att 29.556696 loss_ctc 44.637482 loss_rnnt 22.294062 hw_loss 0.734737 lr 0.00065884 rank 6
2023-02-11 13:22:48,018 DEBUG TRAIN Batch 6/7700 loss 14.620244 loss_att 18.976204 loss_ctc 27.133688 loss_rnnt 9.310515 hw_loss 0.519390 lr 0.00065777 rank 0
2023-02-11 13:22:48,019 DEBUG TRAIN Batch 6/7700 loss 22.139046 loss_att 23.728378 loss_ctc 26.002775 loss_rnnt 18.594593 hw_loss 0.508391 lr 0.00065828 rank 4
2023-02-11 13:22:48,023 DEBUG TRAIN Batch 6/7700 loss 13.157383 loss_att 15.039524 loss_ctc 21.334482 loss_rnnt 9.870712 hw_loss 0.341243 lr 0.00065813 rank 3
2023-02-11 13:22:48,024 DEBUG TRAIN Batch 6/7700 loss 16.639574 loss_att 15.524402 loss_ctc 21.099674 loss_rnnt 12.441381 hw_loss 0.717478 lr 0.00065813 rank 7
2023-02-11 13:22:48,026 DEBUG TRAIN Batch 6/7700 loss 26.493748 loss_att 30.953035 loss_ctc 38.748909 loss_rnnt 23.173733 hw_loss 0.148900 lr 0.00065827 rank 6
2023-02-11 13:22:48,026 DEBUG TRAIN Batch 6/7700 loss 11.449947 loss_att 16.920502 loss_ctc 17.940620 loss_rnnt 8.864597 hw_loss 0.117341 lr 0.00065802 rank 5
2023-02-11 13:22:48,030 DEBUG TRAIN Batch 6/7700 loss 22.083433 loss_att 28.287071 loss_ctc 38.889854 loss_rnnt 17.165428 hw_loss 0.269329 lr 0.00065761 rank 2
2023-02-11 13:22:48,074 DEBUG TRAIN Batch 6/7700 loss 12.795156 loss_att 16.575422 loss_ctc 21.479643 loss_rnnt 8.730139 hw_loss 0.403319 lr 0.00065789 rank 1
2023-02-11 13:24:07,100 DEBUG TRAIN Batch 6/7800 loss 16.199345 loss_att 20.957085 loss_ctc 30.075523 loss_rnnt 12.826330 hw_loss 0.107120 lr 0.00065720 rank 0
2023-02-11 13:24:07,103 DEBUG TRAIN Batch 6/7800 loss 13.424003 loss_att 17.554417 loss_ctc 24.486540 loss_rnnt 10.358034 hw_loss 0.143415 lr 0.00065756 rank 7
2023-02-11 13:24:07,107 DEBUG TRAIN Batch 6/7800 loss 7.433060 loss_att 13.620957 loss_ctc 15.939041 loss_rnnt 4.864676 hw_loss 0.036876 lr 0.00065704 rank 2
2023-02-11 13:24:07,108 DEBUG TRAIN Batch 6/7800 loss 13.899675 loss_att 16.603956 loss_ctc 16.454950 loss_rnnt 8.549530 hw_loss 0.837860 lr 0.00065745 rank 5
2023-02-11 13:24:07,108 DEBUG TRAIN Batch 6/7800 loss 5.520395 loss_att 9.833010 loss_ctc 8.786398 loss_rnnt 2.285674 hw_loss 0.363137 lr 0.00065732 rank 1
2023-02-11 13:24:07,109 DEBUG TRAIN Batch 6/7800 loss 18.133654 loss_att 29.386805 loss_ctc 27.846434 loss_rnnt 12.679050 hw_loss 0.357925 lr 0.00065756 rank 3
2023-02-11 13:24:07,114 DEBUG TRAIN Batch 6/7800 loss 24.999826 loss_att 26.960403 loss_ctc 32.727974 loss_rnnt 21.516808 hw_loss 0.386340 lr 0.00065770 rank 6
2023-02-11 13:24:07,116 DEBUG TRAIN Batch 6/7800 loss 32.078053 loss_att 34.018276 loss_ctc 47.921600 loss_rnnt 28.300030 hw_loss 0.239533 lr 0.00065771 rank 4
2023-02-11 13:25:24,687 DEBUG TRAIN Batch 6/7900 loss 21.876879 loss_att 27.040554 loss_ctc 33.323059 loss_rnnt 16.813381 hw_loss 0.469613 lr 0.00065713 rank 6
2023-02-11 13:25:24,688 DEBUG TRAIN Batch 6/7900 loss 13.690125 loss_att 18.266811 loss_ctc 20.823524 loss_rnnt 10.603367 hw_loss 0.228806 lr 0.00065648 rank 2
2023-02-11 13:25:24,688 DEBUG TRAIN Batch 6/7900 loss 37.005589 loss_att 42.191498 loss_ctc 57.680862 loss_rnnt 31.145588 hw_loss 0.387396 lr 0.00065663 rank 0
2023-02-11 13:25:24,689 DEBUG TRAIN Batch 6/7900 loss 17.251389 loss_att 20.082020 loss_ctc 31.378416 loss_rnnt 12.666666 hw_loss 0.400311 lr 0.00065699 rank 7
2023-02-11 13:25:24,689 DEBUG TRAIN Batch 6/7900 loss 16.170069 loss_att 18.495483 loss_ctc 20.558548 loss_rnnt 11.830775 hw_loss 0.616702 lr 0.00065714 rank 4
2023-02-11 13:25:24,691 DEBUG TRAIN Batch 6/7900 loss 16.480581 loss_att 20.131258 loss_ctc 21.231770 loss_rnnt 14.046241 hw_loss 0.200759 lr 0.00065699 rank 3
2023-02-11 13:25:24,694 DEBUG TRAIN Batch 6/7900 loss 19.251747 loss_att 26.701363 loss_ctc 27.858168 loss_rnnt 15.861586 hw_loss 0.141134 lr 0.00065675 rank 1
2023-02-11 13:25:24,697 DEBUG TRAIN Batch 6/7900 loss 14.869837 loss_att 15.427588 loss_ctc 16.812218 loss_rnnt 10.243681 hw_loss 0.797929 lr 0.00065688 rank 5
2023-02-11 13:26:40,943 DEBUG TRAIN Batch 6/8000 loss 20.493723 loss_att 21.594564 loss_ctc 29.217796 loss_rnnt 16.500946 hw_loss 0.489262 lr 0.00065607 rank 0
2023-02-11 13:26:40,944 DEBUG TRAIN Batch 6/8000 loss 9.515265 loss_att 12.720737 loss_ctc 17.805363 loss_rnnt 4.143390 hw_loss 0.679769 lr 0.00065642 rank 3
2023-02-11 13:26:40,945 DEBUG TRAIN Batch 6/8000 loss 15.944775 loss_att 16.484268 loss_ctc 20.518093 loss_rnnt 14.774364 hw_loss 0.084888 lr 0.00065642 rank 7
2023-02-11 13:26:40,952 DEBUG TRAIN Batch 6/8000 loss 15.480841 loss_att 14.565277 loss_ctc 19.037933 loss_rnnt 10.503383 hw_loss 0.878680 lr 0.00065632 rank 5
2023-02-11 13:26:40,952 DEBUG TRAIN Batch 6/8000 loss 20.301937 loss_att 23.589994 loss_ctc 32.546402 loss_rnnt 15.680179 hw_loss 0.437165 lr 0.00065657 rank 6
2023-02-11 13:26:40,957 DEBUG TRAIN Batch 6/8000 loss 20.455784 loss_att 25.546875 loss_ctc 34.741196 loss_rnnt 14.333371 hw_loss 0.599901 lr 0.00065657 rank 4
2023-02-11 13:26:40,971 DEBUG TRAIN Batch 6/8000 loss 18.380783 loss_att 21.936600 loss_ctc 26.342100 loss_rnnt 15.023911 hw_loss 0.297037 lr 0.00065591 rank 2
2023-02-11 13:26:41,015 DEBUG TRAIN Batch 6/8000 loss 18.404499 loss_att 23.742161 loss_ctc 31.373110 loss_rnnt 12.888815 hw_loss 0.509813 lr 0.00065619 rank 1
2023-02-11 13:27:59,206 DEBUG TRAIN Batch 6/8100 loss 12.805110 loss_att 18.414703 loss_ctc 18.848581 loss_rnnt 8.825834 hw_loss 0.384668 lr 0.00065550 rank 0
2023-02-11 13:27:59,212 DEBUG TRAIN Batch 6/8100 loss 27.054094 loss_att 27.807838 loss_ctc 38.650749 loss_rnnt 21.872665 hw_loss 0.653336 lr 0.00065562 rank 1
2023-02-11 13:27:59,211 DEBUG TRAIN Batch 6/8100 loss 20.912762 loss_att 22.925777 loss_ctc 27.642139 loss_rnnt 15.475155 hw_loss 0.775828 lr 0.00065586 rank 7
2023-02-11 13:27:59,215 DEBUG TRAIN Batch 6/8100 loss 13.927710 loss_att 16.978146 loss_ctc 24.894896 loss_rnnt 8.729390 hw_loss 0.586114 lr 0.00065535 rank 2
2023-02-11 13:27:59,215 DEBUG TRAIN Batch 6/8100 loss 15.088305 loss_att 16.174105 loss_ctc 23.308262 loss_rnnt 11.763077 hw_loss 0.377264 lr 0.00065575 rank 5
2023-02-11 13:27:59,215 DEBUG TRAIN Batch 6/8100 loss 33.789944 loss_att 33.752060 loss_ctc 47.292908 loss_rnnt 28.338108 hw_loss 0.686065 lr 0.00065586 rank 3
2023-02-11 13:27:59,216 DEBUG TRAIN Batch 6/8100 loss 20.268429 loss_att 20.945732 loss_ctc 22.127304 loss_rnnt 14.782675 hw_loss 0.956708 lr 0.00065601 rank 4
2023-02-11 13:27:59,217 DEBUG TRAIN Batch 6/8100 loss 36.188423 loss_att 34.119583 loss_ctc 46.182606 loss_rnnt 34.223061 hw_loss 0.196232 lr 0.00065600 rank 6
2023-02-11 13:29:16,871 DEBUG TRAIN Batch 6/8200 loss 12.625601 loss_att 14.667693 loss_ctc 18.086357 loss_rnnt 9.152169 hw_loss 0.438171 lr 0.00065530 rank 7
2023-02-11 13:29:16,875 DEBUG TRAIN Batch 6/8200 loss 8.790545 loss_att 13.118915 loss_ctc 17.190104 loss_rnnt 5.307027 hw_loss 0.280857 lr 0.00065530 rank 3
2023-02-11 13:29:16,876 DEBUG TRAIN Batch 6/8200 loss 22.292263 loss_att 21.047913 loss_ctc 27.115356 loss_rnnt 18.670498 hw_loss 0.605167 lr 0.00065494 rank 0
2023-02-11 13:29:16,876 DEBUG TRAIN Batch 6/8200 loss 33.063992 loss_att 31.426664 loss_ctc 44.579098 loss_rnnt 29.234074 hw_loss 0.491632 lr 0.00065544 rank 6
2023-02-11 13:29:16,876 DEBUG TRAIN Batch 6/8200 loss 20.843462 loss_att 21.803814 loss_ctc 33.702755 loss_rnnt 17.653685 hw_loss 0.240588 lr 0.00065478 rank 2
2023-02-11 13:29:16,879 DEBUG TRAIN Batch 6/8200 loss 22.265070 loss_att 25.710285 loss_ctc 33.541290 loss_rnnt 17.484230 hw_loss 0.485306 lr 0.00065519 rank 5
2023-02-11 13:29:16,879 DEBUG TRAIN Batch 6/8200 loss 11.028666 loss_att 9.748581 loss_ctc 15.051817 loss_rnnt 6.847958 hw_loss 0.731307 lr 0.00065544 rank 4
2023-02-11 13:29:16,879 DEBUG TRAIN Batch 6/8200 loss 11.519618 loss_att 13.310357 loss_ctc 21.664715 loss_rnnt 8.361232 hw_loss 0.271417 lr 0.00065506 rank 1
2023-02-11 13:30:32,385 DEBUG TRAIN Batch 6/8300 loss 33.151981 loss_att 31.162598 loss_ctc 39.957729 loss_rnnt 28.604027 hw_loss 0.757199 lr 0.00065438 rank 0
2023-02-11 13:30:32,386 DEBUG TRAIN Batch 6/8300 loss 24.504753 loss_att 26.981625 loss_ctc 34.125664 loss_rnnt 20.989395 hw_loss 0.325724 lr 0.00065422 rank 2
2023-02-11 13:30:32,386 DEBUG TRAIN Batch 6/8300 loss 21.597803 loss_att 21.148872 loss_ctc 30.203430 loss_rnnt 17.403061 hw_loss 0.588208 lr 0.00065473 rank 7
2023-02-11 13:30:32,388 DEBUG TRAIN Batch 6/8300 loss 17.658270 loss_att 24.927483 loss_ctc 30.280380 loss_rnnt 12.094048 hw_loss 0.455144 lr 0.00065463 rank 5
2023-02-11 13:30:32,388 DEBUG TRAIN Batch 6/8300 loss 20.434303 loss_att 26.225372 loss_ctc 35.747601 loss_rnnt 15.699203 hw_loss 0.287834 lr 0.00065473 rank 3
2023-02-11 13:30:32,394 DEBUG TRAIN Batch 6/8300 loss 11.893069 loss_att 12.328192 loss_ctc 16.274590 loss_rnnt 9.558212 hw_loss 0.311931 lr 0.00065487 rank 6
2023-02-11 13:30:32,395 DEBUG TRAIN Batch 6/8300 loss 13.404410 loss_att 17.866547 loss_ctc 16.870707 loss_rnnt 10.714567 hw_loss 0.250358 lr 0.00065488 rank 4
2023-02-11 13:30:32,397 DEBUG TRAIN Batch 6/8300 loss 17.018373 loss_att 19.888700 loss_ctc 28.224409 loss_rnnt 14.743481 hw_loss 0.038754 lr 0.00065450 rank 1
2023-02-11 13:31:20,031 DEBUG CV Batch 6/0 loss 6.732652 loss_att 2.803704 loss_ctc 4.290991 loss_rnnt 1.885961 hw_loss 1.117132 history loss 6.483294 rank 3
2023-02-11 13:31:20,032 DEBUG CV Batch 6/0 loss 6.732652 loss_att 2.803704 loss_ctc 4.290991 loss_rnnt 1.885961 hw_loss 1.117132 history loss 6.483294 rank 0
2023-02-11 13:31:20,033 DEBUG CV Batch 6/0 loss 6.732652 loss_att 2.803704 loss_ctc 4.290991 loss_rnnt 1.885961 hw_loss 1.117132 history loss 6.483294 rank 2
2023-02-11 13:31:20,033 DEBUG CV Batch 6/0 loss 6.732653 loss_att 2.803704 loss_ctc 4.290991 loss_rnnt 1.885961 hw_loss 1.117132 history loss 6.483295 rank 4
2023-02-11 13:31:20,034 DEBUG CV Batch 6/0 loss 6.732652 loss_att 2.803704 loss_ctc 4.290991 loss_rnnt 1.885961 hw_loss 1.117131 history loss 6.483294 rank 7
2023-02-11 13:31:20,036 DEBUG CV Batch 6/0 loss 6.732652 loss_att 2.803704 loss_ctc 4.290991 loss_rnnt 1.885961 hw_loss 1.117132 history loss 6.483294 rank 5
2023-02-11 13:31:20,045 DEBUG CV Batch 6/0 loss 6.732652 loss_att 2.803704 loss_ctc 4.290991 loss_rnnt 1.885961 hw_loss 1.117131 history loss 6.483294 rank 1
2023-02-11 13:31:20,055 DEBUG CV Batch 6/0 loss 6.732652 loss_att 2.803704 loss_ctc 4.290991 loss_rnnt 1.885961 hw_loss 1.117132 history loss 6.483294 rank 6
2023-02-11 13:31:31,144 DEBUG CV Batch 6/100 loss 13.400059 loss_att 11.875659 loss_ctc 20.781250 loss_rnnt 9.261909 hw_loss 0.648538 history loss 8.198030 rank 1
2023-02-11 13:31:31,150 DEBUG CV Batch 6/100 loss 13.400059 loss_att 11.875659 loss_ctc 20.781250 loss_rnnt 9.261909 hw_loss 0.648538 history loss 8.198030 rank 2
2023-02-11 13:31:31,169 DEBUG CV Batch 6/100 loss 13.400059 loss_att 11.875659 loss_ctc 20.781250 loss_rnnt 9.261909 hw_loss 0.648538 history loss 8.198030 rank 3
2023-02-11 13:31:31,192 DEBUG CV Batch 6/100 loss 13.400060 loss_att 11.875659 loss_ctc 20.781250 loss_rnnt 9.261909 hw_loss 0.648538 history loss 8.198030 rank 7
2023-02-11 13:31:31,198 DEBUG CV Batch 6/100 loss 13.400059 loss_att 11.875659 loss_ctc 20.781250 loss_rnnt 9.261909 hw_loss 0.648538 history loss 8.198030 rank 0
2023-02-11 13:31:31,293 DEBUG CV Batch 6/100 loss 13.400059 loss_att 11.875659 loss_ctc 20.781250 loss_rnnt 9.261909 hw_loss 0.648538 history loss 8.198030 rank 5
2023-02-11 13:31:31,427 DEBUG CV Batch 6/100 loss 13.400060 loss_att 11.875659 loss_ctc 20.781250 loss_rnnt 9.261909 hw_loss 0.648538 history loss 8.198030 rank 6
2023-02-11 13:31:31,812 DEBUG CV Batch 6/100 loss 13.400059 loss_att 11.875659 loss_ctc 20.781250 loss_rnnt 9.261909 hw_loss 0.648538 history loss 8.198030 rank 4
2023-02-11 13:31:44,867 DEBUG CV Batch 6/200 loss 12.847071 loss_att 17.740025 loss_ctc 18.674021 loss_rnnt 10.141945 hw_loss 0.178052 history loss 8.672542 rank 0
2023-02-11 13:31:44,993 DEBUG CV Batch 6/200 loss 12.847071 loss_att 17.740025 loss_ctc 18.674021 loss_rnnt 10.141945 hw_loss 0.178052 history loss 8.672542 rank 3
2023-02-11 13:31:45,052 DEBUG CV Batch 6/200 loss 12.847071 loss_att 17.740025 loss_ctc 18.674021 loss_rnnt 10.141945 hw_loss 0.178052 history loss 8.672542 rank 1
2023-02-11 13:31:45,079 DEBUG CV Batch 6/200 loss 12.847071 loss_att 17.740025 loss_ctc 18.674021 loss_rnnt 10.141945 hw_loss 0.178052 history loss 8.672542 rank 7
2023-02-11 13:31:45,133 DEBUG CV Batch 6/200 loss 12.847071 loss_att 17.740025 loss_ctc 18.674021 loss_rnnt 10.141945 hw_loss 0.178052 history loss 8.672542 rank 2
2023-02-11 13:31:45,141 DEBUG CV Batch 6/200 loss 12.847071 loss_att 17.740025 loss_ctc 18.674021 loss_rnnt 10.141945 hw_loss 0.178052 history loss 8.672542 rank 5
2023-02-11 13:31:45,624 DEBUG CV Batch 6/200 loss 12.847071 loss_att 17.740025 loss_ctc 18.674021 loss_rnnt 10.141945 hw_loss 0.178052 history loss 8.672542 rank 4
2023-02-11 13:31:46,134 DEBUG CV Batch 6/200 loss 12.847071 loss_att 17.740025 loss_ctc 18.674021 loss_rnnt 10.141945 hw_loss 0.178052 history loss 8.672542 rank 6
2023-02-11 13:31:56,917 DEBUG CV Batch 6/300 loss 7.467939 loss_att 6.194868 loss_ctc 10.934471 loss_rnnt 4.136899 hw_loss 0.585647 history loss 8.902694 rank 0
2023-02-11 13:31:57,027 DEBUG CV Batch 6/300 loss 7.467939 loss_att 6.194868 loss_ctc 10.934471 loss_rnnt 4.136899 hw_loss 0.585647 history loss 8.902694 rank 3
2023-02-11 13:31:57,081 DEBUG CV Batch 6/300 loss 7.467939 loss_att 6.194868 loss_ctc 10.934471 loss_rnnt 4.136899 hw_loss 0.585647 history loss 8.902694 rank 7
2023-02-11 13:31:57,116 DEBUG CV Batch 6/300 loss 7.467939 loss_att 6.194868 loss_ctc 10.934471 loss_rnnt 4.136899 hw_loss 0.585647 history loss 8.902694 rank 1
2023-02-11 13:31:57,222 DEBUG CV Batch 6/300 loss 7.467939 loss_att 6.194868 loss_ctc 10.934471 loss_rnnt 4.136899 hw_loss 0.585647 history loss 8.902694 rank 5
2023-02-11 13:31:57,266 DEBUG CV Batch 6/300 loss 7.467939 loss_att 6.194868 loss_ctc 10.934471 loss_rnnt 4.136899 hw_loss 0.585647 history loss 8.902694 rank 2
2023-02-11 13:31:57,835 DEBUG CV Batch 6/300 loss 7.467939 loss_att 6.194868 loss_ctc 10.934471 loss_rnnt 4.136899 hw_loss 0.585647 history loss 8.902694 rank 4
2023-02-11 13:31:58,859 DEBUG CV Batch 6/300 loss 7.467939 loss_att 6.194868 loss_ctc 10.934471 loss_rnnt 4.136899 hw_loss 0.585647 history loss 8.902694 rank 6
2023-02-11 13:32:08,886 DEBUG CV Batch 6/400 loss 25.931866 loss_att 95.519501 loss_ctc 24.998882 loss_rnnt 10.615203 hw_loss 0.285662 history loss 9.890781 rank 0
2023-02-11 13:32:08,985 DEBUG CV Batch 6/400 loss 25.931866 loss_att 95.519501 loss_ctc 24.998882 loss_rnnt 10.615203 hw_loss 0.285662 history loss 9.890782 rank 3
2023-02-11 13:32:09,094 DEBUG CV Batch 6/400 loss 25.931866 loss_att 95.519501 loss_ctc 24.998882 loss_rnnt 10.615203 hw_loss 0.285662 history loss 9.890782 rank 1
2023-02-11 13:32:09,133 DEBUG CV Batch 6/400 loss 25.931866 loss_att 95.519501 loss_ctc 24.998882 loss_rnnt 10.615203 hw_loss 0.285662 history loss 9.890782 rank 7
2023-02-11 13:32:09,311 DEBUG CV Batch 6/400 loss 25.931866 loss_att 95.519501 loss_ctc 24.998882 loss_rnnt 10.615203 hw_loss 0.285662 history loss 9.890782 rank 2
2023-02-11 13:32:09,331 DEBUG CV Batch 6/400 loss 25.931866 loss_att 95.519501 loss_ctc 24.998882 loss_rnnt 10.615203 hw_loss 0.285662 history loss 9.890782 rank 5
2023-02-11 13:32:09,808 DEBUG CV Batch 6/400 loss 25.931866 loss_att 95.519501 loss_ctc 24.998882 loss_rnnt 10.615203 hw_loss 0.285662 history loss 9.890782 rank 4
2023-02-11 13:32:10,930 DEBUG CV Batch 6/400 loss 25.931866 loss_att 95.519501 loss_ctc 24.998882 loss_rnnt 10.615203 hw_loss 0.285662 history loss 9.890782 rank 6
2023-02-11 13:32:19,257 DEBUG CV Batch 6/500 loss 9.215266 loss_att 8.405978 loss_ctc 12.645844 loss_rnnt 5.579584 hw_loss 0.626274 history loss 10.795102 rank 0
2023-02-11 13:32:19,350 DEBUG CV Batch 6/500 loss 9.215266 loss_att 8.405978 loss_ctc 12.645844 loss_rnnt 5.579584 hw_loss 0.626274 history loss 10.795102 rank 3
2023-02-11 13:32:19,537 DEBUG CV Batch 6/500 loss 9.215266 loss_att 8.405978 loss_ctc 12.645844 loss_rnnt 5.579584 hw_loss 0.626274 history loss 10.795102 rank 7
2023-02-11 13:32:19,789 DEBUG CV Batch 6/500 loss 9.215266 loss_att 8.405978 loss_ctc 12.645844 loss_rnnt 5.579584 hw_loss 0.626274 history loss 10.795102 rank 5
2023-02-11 13:32:19,809 DEBUG CV Batch 6/500 loss 9.215266 loss_att 8.405978 loss_ctc 12.645844 loss_rnnt 5.579584 hw_loss 0.626274 history loss 10.795102 rank 2
2023-02-11 13:32:20,211 DEBUG CV Batch 6/500 loss 9.215266 loss_att 8.405978 loss_ctc 12.645844 loss_rnnt 5.579584 hw_loss 0.626274 history loss 10.795102 rank 1
2023-02-11 13:32:20,332 DEBUG CV Batch 6/500 loss 9.215266 loss_att 8.405978 loss_ctc 12.645844 loss_rnnt 5.579584 hw_loss 0.626274 history loss 10.795102 rank 4
2023-02-11 13:32:21,397 DEBUG CV Batch 6/500 loss 9.215266 loss_att 8.405978 loss_ctc 12.645844 loss_rnnt 5.579584 hw_loss 0.626274 history loss 10.795102 rank 6
2023-02-11 13:32:31,313 DEBUG CV Batch 6/600 loss 12.252874 loss_att 9.137962 loss_ctc 11.931287 loss_rnnt 7.347272 hw_loss 1.044649 history loss 11.745553 rank 0
2023-02-11 13:32:31,381 DEBUG CV Batch 6/600 loss 12.252873 loss_att 9.137962 loss_ctc 11.931287 loss_rnnt 7.347272 hw_loss 1.044649 history loss 11.745553 rank 3
2023-02-11 13:32:31,618 DEBUG CV Batch 6/600 loss 12.252873 loss_att 9.137962 loss_ctc 11.931287 loss_rnnt 7.347272 hw_loss 1.044649 history loss 11.745553 rank 7
2023-02-11 13:32:31,804 DEBUG CV Batch 6/600 loss 12.252873 loss_att 9.137962 loss_ctc 11.931287 loss_rnnt 7.347272 hw_loss 1.044649 history loss 11.745553 rank 5
2023-02-11 13:32:31,924 DEBUG CV Batch 6/600 loss 12.252873 loss_att 9.137962 loss_ctc 11.931287 loss_rnnt 7.347272 hw_loss 1.044649 history loss 11.745553 rank 2
2023-02-11 13:32:32,516 DEBUG CV Batch 6/600 loss 12.252873 loss_att 9.137962 loss_ctc 11.931287 loss_rnnt 7.347272 hw_loss 1.044649 history loss 11.745553 rank 4
2023-02-11 13:32:32,860 DEBUG CV Batch 6/600 loss 12.252873 loss_att 9.137962 loss_ctc 11.931287 loss_rnnt 7.347272 hw_loss 1.044649 history loss 11.745553 rank 1
2023-02-11 13:32:33,521 DEBUG CV Batch 6/600 loss 12.252873 loss_att 9.137962 loss_ctc 11.931287 loss_rnnt 7.347272 hw_loss 1.044649 history loss 11.745553 rank 6
2023-02-11 13:32:42,663 DEBUG CV Batch 6/700 loss 23.681389 loss_att 62.015980 loss_ctc 36.092365 loss_rnnt 11.454433 hw_loss 0.544732 history loss 12.432305 rank 3
2023-02-11 13:32:42,661 DEBUG CV Batch 6/700 loss 23.681389 loss_att 62.015980 loss_ctc 36.092365 loss_rnnt 11.454433 hw_loss 0.544732 history loss 12.432305 rank 0
2023-02-11 13:32:42,905 DEBUG CV Batch 6/700 loss 23.681389 loss_att 62.015980 loss_ctc 36.092365 loss_rnnt 11.454433 hw_loss 0.544732 history loss 12.432305 rank 7
2023-02-11 13:32:43,136 DEBUG CV Batch 6/700 loss 23.681389 loss_att 62.015980 loss_ctc 36.092365 loss_rnnt 11.454433 hw_loss 0.544732 history loss 12.432305 rank 5
2023-02-11 13:32:43,309 DEBUG CV Batch 6/700 loss 23.681389 loss_att 62.015980 loss_ctc 36.092365 loss_rnnt 11.454433 hw_loss 0.544732 history loss 12.432305 rank 2
2023-02-11 13:32:43,922 DEBUG CV Batch 6/700 loss 23.681389 loss_att 62.015980 loss_ctc 36.092365 loss_rnnt 11.454433 hw_loss 0.544732 history loss 12.432305 rank 4
2023-02-11 13:32:44,627 DEBUG CV Batch 6/700 loss 23.681389 loss_att 62.015980 loss_ctc 36.092365 loss_rnnt 11.454433 hw_loss 0.544732 history loss 12.432305 rank 1
2023-02-11 13:32:44,813 DEBUG CV Batch 6/700 loss 23.681389 loss_att 62.015980 loss_ctc 36.092365 loss_rnnt 11.454433 hw_loss 0.544732 history loss 12.432305 rank 6
2023-02-11 13:32:54,255 DEBUG CV Batch 6/800 loss 15.024630 loss_att 12.723208 loss_ctc 23.299862 loss_rnnt 11.341674 hw_loss 0.569976 history loss 11.873517 rank 7
2023-02-11 13:32:54,344 DEBUG CV Batch 6/800 loss 15.024630 loss_att 12.723208 loss_ctc 23.299862 loss_rnnt 11.341674 hw_loss 0.569976 history loss 11.873517 rank 0
2023-02-11 13:32:54,443 DEBUG CV Batch 6/800 loss 15.024630 loss_att 12.723208 loss_ctc 23.299862 loss_rnnt 11.341674 hw_loss 0.569976 history loss 11.873517 rank 3
2023-02-11 13:32:54,836 DEBUG CV Batch 6/800 loss 15.024629 loss_att 12.723208 loss_ctc 23.299862 loss_rnnt 11.341674 hw_loss 0.569976 history loss 11.873517 rank 5
2023-02-11 13:32:55,660 DEBUG CV Batch 6/800 loss 15.024629 loss_att 12.723208 loss_ctc 23.299862 loss_rnnt 11.341674 hw_loss 0.569976 history loss 11.873517 rank 4
2023-02-11 13:32:55,793 DEBUG CV Batch 6/800 loss 15.024630 loss_att 12.723208 loss_ctc 23.299862 loss_rnnt 11.341674 hw_loss 0.569976 history loss 11.873517 rank 2
2023-02-11 13:32:55,967 DEBUG CV Batch 6/800 loss 15.024630 loss_att 12.723208 loss_ctc 23.299862 loss_rnnt 11.341674 hw_loss 0.569976 history loss 11.873517 rank 1
2023-02-11 13:32:56,160 DEBUG CV Batch 6/800 loss 15.024629 loss_att 12.723208 loss_ctc 23.299862 loss_rnnt 11.341674 hw_loss 0.569976 history loss 11.873517 rank 6
2023-02-11 13:33:07,590 DEBUG CV Batch 6/900 loss 20.669176 loss_att 29.567436 loss_ctc 30.776133 loss_rnnt 16.596184 hw_loss 0.177327 history loss 11.629476 rank 7
2023-02-11 13:33:07,858 DEBUG CV Batch 6/900 loss 20.669176 loss_att 29.567436 loss_ctc 30.776133 loss_rnnt 16.596184 hw_loss 0.177327 history loss 11.629476 rank 0
2023-02-11 13:33:08,083 DEBUG CV Batch 6/900 loss 20.669176 loss_att 29.567436 loss_ctc 30.776133 loss_rnnt 16.596184 hw_loss 0.177327 history loss 11.629476 rank 3
2023-02-11 13:33:08,373 DEBUG CV Batch 6/900 loss 20.669176 loss_att 29.567436 loss_ctc 30.776133 loss_rnnt 16.596184 hw_loss 0.177327 history loss 11.629476 rank 5
2023-02-11 13:33:09,290 DEBUG CV Batch 6/900 loss 20.669176 loss_att 29.567436 loss_ctc 30.776133 loss_rnnt 16.596184 hw_loss 0.177327 history loss 11.629476 rank 1
2023-02-11 13:33:09,390 DEBUG CV Batch 6/900 loss 20.669176 loss_att 29.567436 loss_ctc 30.776133 loss_rnnt 16.596184 hw_loss 0.177327 history loss 11.629476 rank 4
2023-02-11 13:33:09,608 DEBUG CV Batch 6/900 loss 20.669176 loss_att 29.567436 loss_ctc 30.776133 loss_rnnt 16.596184 hw_loss 0.177327 history loss 11.629476 rank 2
2023-02-11 13:33:09,789 DEBUG CV Batch 6/900 loss 20.669176 loss_att 29.567436 loss_ctc 30.776133 loss_rnnt 16.596184 hw_loss 0.177327 history loss 11.629476 rank 6
2023-02-11 13:33:19,790 DEBUG CV Batch 6/1000 loss 9.317301 loss_att 7.431197 loss_ctc 9.391231 loss_rnnt 6.180369 hw_loss 0.657055 history loss 11.414850 rank 7
2023-02-11 13:33:19,967 DEBUG CV Batch 6/1000 loss 9.317301 loss_att 7.431197 loss_ctc 9.391231 loss_rnnt 6.180369 hw_loss 0.657055 history loss 11.414850 rank 0
2023-02-11 13:33:20,263 DEBUG CV Batch 6/1000 loss 9.317301 loss_att 7.431197 loss_ctc 9.391231 loss_rnnt 6.180369 hw_loss 0.657055 history loss 11.414850 rank 3
2023-02-11 13:33:20,630 DEBUG CV Batch 6/1000 loss 9.317301 loss_att 7.431197 loss_ctc 9.391231 loss_rnnt 6.180369 hw_loss 0.657055 history loss 11.414850 rank 5
2023-02-11 13:33:21,503 DEBUG CV Batch 6/1000 loss 9.317301 loss_att 7.431197 loss_ctc 9.391231 loss_rnnt 6.180369 hw_loss 0.657055 history loss 11.414850 rank 1
2023-02-11 13:33:21,658 DEBUG CV Batch 6/1000 loss 9.317301 loss_att 7.431197 loss_ctc 9.391231 loss_rnnt 6.180369 hw_loss 0.657055 history loss 11.414850 rank 4
2023-02-11 13:33:21,867 DEBUG CV Batch 6/1000 loss 9.317301 loss_att 7.431197 loss_ctc 9.391231 loss_rnnt 6.180369 hw_loss 0.657055 history loss 11.414850 rank 2
2023-02-11 13:33:21,930 DEBUG CV Batch 6/1000 loss 9.317301 loss_att 7.431197 loss_ctc 9.391231 loss_rnnt 6.180369 hw_loss 0.657055 history loss 11.414850 rank 6
2023-02-11 13:33:31,794 DEBUG CV Batch 6/1100 loss 11.394587 loss_att 6.261709 loss_ctc 10.175445 loss_rnnt 5.849586 hw_loss 1.262649 history loss 11.376094 rank 7
2023-02-11 13:33:31,843 DEBUG CV Batch 6/1100 loss 11.394586 loss_att 6.261709 loss_ctc 10.175445 loss_rnnt 5.849586 hw_loss 1.262649 history loss 11.376094 rank 0
2023-02-11 13:33:32,131 DEBUG CV Batch 6/1100 loss 11.394587 loss_att 6.261709 loss_ctc 10.175445 loss_rnnt 5.849586 hw_loss 1.262649 history loss 11.376094 rank 3
2023-02-11 13:33:32,479 DEBUG CV Batch 6/1100 loss 11.394586 loss_att 6.261709 loss_ctc 10.175445 loss_rnnt 5.849586 hw_loss 1.262649 history loss 11.376094 rank 5
2023-02-11 13:33:33,494 DEBUG CV Batch 6/1100 loss 11.394585 loss_att 6.261709 loss_ctc 10.175445 loss_rnnt 5.849586 hw_loss 1.262648 history loss 11.376094 rank 1
2023-02-11 13:33:33,573 DEBUG CV Batch 6/1100 loss 11.394586 loss_att 6.261709 loss_ctc 10.175445 loss_rnnt 5.849586 hw_loss 1.262649 history loss 11.376094 rank 4
2023-02-11 13:33:33,820 DEBUG CV Batch 6/1100 loss 11.394585 loss_att 6.261709 loss_ctc 10.175445 loss_rnnt 5.849586 hw_loss 1.262648 history loss 11.376094 rank 6
2023-02-11 13:33:33,902 DEBUG CV Batch 6/1100 loss 11.394586 loss_att 6.261709 loss_ctc 10.175445 loss_rnnt 5.849586 hw_loss 1.262649 history loss 11.376094 rank 2
2023-02-11 13:33:42,249 DEBUG CV Batch 6/1200 loss 15.147405 loss_att 13.705724 loss_ctc 16.603506 loss_rnnt 11.413930 hw_loss 0.717687 history loss 11.747120 rank 0
2023-02-11 13:33:42,255 DEBUG CV Batch 6/1200 loss 15.147405 loss_att 13.705724 loss_ctc 16.603506 loss_rnnt 11.413930 hw_loss 0.717687 history loss 11.747120 rank 7
2023-02-11 13:33:42,483 DEBUG CV Batch 6/1200 loss 15.147405 loss_att 13.705724 loss_ctc 16.603506 loss_rnnt 11.413930 hw_loss 0.717687 history loss 11.747120 rank 3
2023-02-11 13:33:42,951 DEBUG CV Batch 6/1200 loss 15.147405 loss_att 13.705724 loss_ctc 16.603506 loss_rnnt 11.413930 hw_loss 0.717687 history loss 11.747120 rank 5
2023-02-11 13:33:44,076 DEBUG CV Batch 6/1200 loss 15.147405 loss_att 13.705724 loss_ctc 16.603506 loss_rnnt 11.413930 hw_loss 0.717687 history loss 11.747120 rank 4
2023-02-11 13:33:44,239 DEBUG CV Batch 6/1200 loss 15.147405 loss_att 13.705724 loss_ctc 16.603506 loss_rnnt 11.413930 hw_loss 0.717687 history loss 11.747120 rank 6
2023-02-11 13:33:44,375 DEBUG CV Batch 6/1200 loss 15.147405 loss_att 13.705724 loss_ctc 16.603506 loss_rnnt 11.413930 hw_loss 0.717687 history loss 11.747120 rank 2
2023-02-11 13:33:44,767 DEBUG CV Batch 6/1200 loss 15.147405 loss_att 13.705724 loss_ctc 16.603506 loss_rnnt 11.413930 hw_loss 0.717687 history loss 11.747120 rank 1
2023-02-11 13:33:54,117 DEBUG CV Batch 6/1300 loss 10.715737 loss_att 7.742976 loss_ctc 12.175137 loss_rnnt 6.228200 hw_loss 0.916407 history loss 12.049368 rank 0
2023-02-11 13:33:54,227 DEBUG CV Batch 6/1300 loss 10.715736 loss_att 7.742976 loss_ctc 12.175137 loss_rnnt 6.228200 hw_loss 0.916407 history loss 12.049368 rank 7
2023-02-11 13:33:54,296 DEBUG CV Batch 6/1300 loss 10.715737 loss_att 7.742976 loss_ctc 12.175137 loss_rnnt 6.228200 hw_loss 0.916407 history loss 12.049368 rank 3
2023-02-11 13:33:54,909 DEBUG CV Batch 6/1300 loss 10.715737 loss_att 7.742976 loss_ctc 12.175137 loss_rnnt 6.228200 hw_loss 0.916407 history loss 12.049368 rank 5
2023-02-11 13:33:56,054 DEBUG CV Batch 6/1300 loss 10.715737 loss_att 7.742976 loss_ctc 12.175137 loss_rnnt 6.228200 hw_loss 0.916407 history loss 12.049368 rank 4
2023-02-11 13:33:56,238 DEBUG CV Batch 6/1300 loss 10.715737 loss_att 7.742976 loss_ctc 12.175137 loss_rnnt 6.228200 hw_loss 0.916407 history loss 12.049368 rank 6
2023-02-11 13:33:56,334 DEBUG CV Batch 6/1300 loss 10.715737 loss_att 7.742976 loss_ctc 12.175137 loss_rnnt 6.228200 hw_loss 0.916407 history loss 12.049368 rank 2
2023-02-11 13:33:57,617 DEBUG CV Batch 6/1300 loss 10.715737 loss_att 7.742976 loss_ctc 12.175137 loss_rnnt 6.228200 hw_loss 0.916407 history loss 12.049368 rank 1
2023-02-11 13:34:05,197 DEBUG CV Batch 6/1400 loss 14.549406 loss_att 38.893272 loss_ctc 18.513702 loss_rnnt 7.695497 hw_loss 0.273106 history loss 12.404140 rank 0
2023-02-11 13:34:05,330 DEBUG CV Batch 6/1400 loss 14.549406 loss_att 38.893272 loss_ctc 18.513702 loss_rnnt 7.695497 hw_loss 0.273106 history loss 12.404140 rank 7
2023-02-11 13:34:05,482 DEBUG CV Batch 6/1400 loss 14.549406 loss_att 38.893272 loss_ctc 18.513702 loss_rnnt 7.695497 hw_loss 0.273106 history loss 12.404140 rank 3
2023-02-11 13:34:06,140 DEBUG CV Batch 6/1400 loss 14.549406 loss_att 38.893272 loss_ctc 18.513702 loss_rnnt 7.695497 hw_loss 0.273106 history loss 12.404140 rank 5
2023-02-11 13:34:07,405 DEBUG CV Batch 6/1400 loss 14.549406 loss_att 38.893272 loss_ctc 18.513702 loss_rnnt 7.695497 hw_loss 0.273106 history loss 12.404140 rank 6
2023-02-11 13:34:07,420 DEBUG CV Batch 6/1400 loss 14.549406 loss_att 38.893272 loss_ctc 18.513702 loss_rnnt 7.695497 hw_loss 0.273106 history loss 12.404140 rank 4
2023-02-11 13:34:07,475 DEBUG CV Batch 6/1400 loss 14.549406 loss_att 38.893272 loss_ctc 18.513702 loss_rnnt 7.695497 hw_loss 0.273106 history loss 12.404140 rank 2
2023-02-11 13:34:08,787 DEBUG CV Batch 6/1400 loss 14.549406 loss_att 38.893272 loss_ctc 18.513702 loss_rnnt 7.695497 hw_loss 0.273106 history loss 12.404140 rank 1
2023-02-11 13:34:16,531 DEBUG CV Batch 6/1500 loss 12.297445 loss_att 11.709572 loss_ctc 10.372723 loss_rnnt 8.704881 hw_loss 0.743769 history loss 12.241259 rank 0
2023-02-11 13:34:16,683 DEBUG CV Batch 6/1500 loss 12.297445 loss_att 11.709572 loss_ctc 10.372723 loss_rnnt 8.704881 hw_loss 0.743769 history loss 12.241259 rank 7
2023-02-11 13:34:16,802 DEBUG CV Batch 6/1500 loss 12.297445 loss_att 11.709572 loss_ctc 10.372723 loss_rnnt 8.704881 hw_loss 0.743769 history loss 12.241259 rank 3
2023-02-11 13:34:17,620 DEBUG CV Batch 6/1500 loss 12.297445 loss_att 11.709572 loss_ctc 10.372723 loss_rnnt 8.704881 hw_loss 0.743769 history loss 12.241259 rank 5
2023-02-11 13:34:18,747 DEBUG CV Batch 6/1500 loss 12.297445 loss_att 11.709572 loss_ctc 10.372723 loss_rnnt 8.704881 hw_loss 0.743769 history loss 12.241259 rank 2
2023-02-11 13:34:19,618 DEBUG CV Batch 6/1500 loss 12.297445 loss_att 11.709572 loss_ctc 10.372723 loss_rnnt 8.704881 hw_loss 0.743769 history loss 12.241259 rank 6
2023-02-11 13:34:19,710 DEBUG CV Batch 6/1500 loss 12.297445 loss_att 11.709572 loss_ctc 10.372723 loss_rnnt 8.704881 hw_loss 0.743769 history loss 12.241259 rank 4
2023-02-11 13:34:20,783 DEBUG CV Batch 6/1500 loss 12.297445 loss_att 11.709572 loss_ctc 10.372723 loss_rnnt 8.704881 hw_loss 0.743769 history loss 12.241259 rank 1
2023-02-11 13:34:29,796 DEBUG CV Batch 6/1600 loss 12.865144 loss_att 25.556152 loss_ctc 20.018459 loss_rnnt 6.667442 hw_loss 0.507323 history loss 12.145230 rank 7
2023-02-11 13:34:30,191 DEBUG CV Batch 6/1600 loss 12.865144 loss_att 25.556152 loss_ctc 20.018459 loss_rnnt 6.667442 hw_loss 0.507323 history loss 12.145230 rank 0
2023-02-11 13:34:30,541 DEBUG CV Batch 6/1600 loss 12.865144 loss_att 25.556152 loss_ctc 20.018459 loss_rnnt 6.667442 hw_loss 0.507323 history loss 12.145230 rank 3
2023-02-11 13:34:30,898 DEBUG CV Batch 6/1600 loss 12.865144 loss_att 25.556152 loss_ctc 20.018459 loss_rnnt 6.667442 hw_loss 0.507323 history loss 12.145230 rank 5
2023-02-11 13:34:32,800 DEBUG CV Batch 6/1600 loss 12.865144 loss_att 25.556152 loss_ctc 20.018459 loss_rnnt 6.667442 hw_loss 0.507323 history loss 12.145230 rank 2
2023-02-11 13:34:33,326 DEBUG CV Batch 6/1600 loss 12.865144 loss_att 25.556152 loss_ctc 20.018459 loss_rnnt 6.667442 hw_loss 0.507323 history loss 12.145230 rank 6
2023-02-11 13:34:33,531 DEBUG CV Batch 6/1600 loss 12.865144 loss_att 25.556152 loss_ctc 20.018459 loss_rnnt 6.667442 hw_loss 0.507323 history loss 12.145230 rank 4
2023-02-11 13:34:33,918 DEBUG CV Batch 6/1600 loss 12.865144 loss_att 25.556152 loss_ctc 20.018459 loss_rnnt 6.667442 hw_loss 0.507323 history loss 12.145230 rank 1
2023-02-11 13:34:42,342 DEBUG CV Batch 6/1700 loss 12.556760 loss_att 10.305027 loss_ctc 14.944118 loss_rnnt 8.575399 hw_loss 0.771261 history loss 12.065886 rank 7
2023-02-11 13:34:42,626 DEBUG CV Batch 6/1700 loss 12.556760 loss_att 10.305027 loss_ctc 14.944118 loss_rnnt 8.575399 hw_loss 0.771261 history loss 12.065886 rank 0
2023-02-11 13:34:43,065 DEBUG CV Batch 6/1700 loss 12.556760 loss_att 10.305027 loss_ctc 14.944118 loss_rnnt 8.575399 hw_loss 0.771261 history loss 12.065886 rank 3
2023-02-11 13:34:43,510 DEBUG CV Batch 6/1700 loss 12.556760 loss_att 10.305027 loss_ctc 14.944118 loss_rnnt 8.575399 hw_loss 0.771261 history loss 12.065886 rank 5
2023-02-11 13:34:45,607 DEBUG CV Batch 6/1700 loss 12.556760 loss_att 10.305027 loss_ctc 14.944118 loss_rnnt 8.575399 hw_loss 0.771261 history loss 12.065886 rank 2
2023-02-11 13:34:45,911 DEBUG CV Batch 6/1700 loss 12.556760 loss_att 10.305027 loss_ctc 14.944118 loss_rnnt 8.575399 hw_loss 0.771261 history loss 12.065886 rank 6
2023-02-11 13:34:46,007 DEBUG CV Batch 6/1700 loss 12.556760 loss_att 10.305027 loss_ctc 14.944118 loss_rnnt 8.575399 hw_loss 0.771261 history loss 12.065886 rank 4
2023-02-11 13:34:46,307 DEBUG CV Batch 6/1700 loss 12.556760 loss_att 10.305027 loss_ctc 14.944118 loss_rnnt 8.575399 hw_loss 0.771261 history loss 12.065886 rank 1
2023-02-11 13:34:51,590 INFO Epoch 6 CV info cv_loss 12.012349429098164
2023-02-11 13:34:51,591 INFO Epoch 7 TRAIN info lr 0.0006546218755604563
2023-02-11 13:34:51,594 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 13:34:51,738 INFO Epoch 6 CV info cv_loss 12.012349445328132
2023-02-11 13:34:51,739 INFO Checkpoint: save to checkpoint exp2_10_rnnt_bias_loss/6.pt
2023-02-11 13:34:52,160 INFO Epoch 6 CV info cv_loss 12.012349434490924
2023-02-11 13:34:52,161 INFO Epoch 7 TRAIN info lr 0.000654638707708519
2023-02-11 13:34:52,165 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 13:34:52,358 INFO Epoch 7 TRAIN info lr 0.0006542014933741448
2023-02-11 13:34:52,361 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 13:34:52,643 INFO Epoch 6 CV info cv_loss 12.012349460662177
2023-02-11 13:34:52,644 INFO Epoch 7 TRAIN info lr 0.0006543191187436711
2023-02-11 13:34:52,647 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 13:34:55,021 INFO Epoch 6 CV info cv_loss 12.012349438212444
2023-02-11 13:34:55,022 INFO Epoch 7 TRAIN info lr 0.0006547004366951574
2023-02-11 13:34:55,025 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 13:34:55,084 INFO Epoch 6 CV info cv_loss 12.012349423705404
2023-02-11 13:34:55,085 INFO Epoch 7 TRAIN info lr 0.0006545938248653886
2023-02-11 13:34:55,088 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 13:34:55,250 INFO Epoch 6 CV info cv_loss 12.012349439418493
2023-02-11 13:34:55,251 INFO Epoch 7 TRAIN info lr 0.0006542799032377671
2023-02-11 13:34:55,254 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 13:34:55,613 INFO Epoch 6 CV info cv_loss 12.012349449532072
2023-02-11 13:34:55,614 INFO Epoch 7 TRAIN info lr 0.0006539552457760795
2023-02-11 13:34:55,618 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 13:36:08,289 DEBUG TRAIN Batch 7/0 loss 17.096624 loss_att 11.709189 loss_ctc 16.774172 loss_rnnt 10.103009 hw_loss 1.521393 lr 0.00065463 rank 3
2023-02-11 13:36:08,292 DEBUG TRAIN Batch 7/0 loss 16.624866 loss_att 12.311012 loss_ctc 15.959903 loss_rnnt 12.426138 hw_loss 0.965655 lr 0.00065431 rank 5
2023-02-11 13:36:08,294 DEBUG TRAIN Batch 7/0 loss 15.228163 loss_att 12.158814 loss_ctc 15.436118 loss_rnnt 10.406544 hw_loss 1.013955 lr 0.00065420 rank 0
2023-02-11 13:36:08,297 DEBUG TRAIN Batch 7/0 loss 14.158842 loss_att 9.947618 loss_ctc 14.268421 loss_rnnt 9.560704 hw_loss 1.017332 lr 0.00065462 rank 7
2023-02-11 13:36:08,297 DEBUG TRAIN Batch 7/0 loss 21.546337 loss_att 17.404507 loss_ctc 22.916510 loss_rnnt 17.033939 hw_loss 0.967139 lr 0.00065427 rank 1
2023-02-11 13:36:08,299 DEBUG TRAIN Batch 7/0 loss 16.826908 loss_att 13.607510 loss_ctc 17.176146 loss_rnnt 12.155223 hw_loss 0.987938 lr 0.00065469 rank 6
2023-02-11 13:36:08,302 DEBUG TRAIN Batch 7/0 loss 10.502780 loss_att 7.093171 loss_ctc 9.568736 loss_rnnt 5.268636 hw_loss 1.132613 lr 0.00065459 rank 4
2023-02-11 13:36:08,360 DEBUG TRAIN Batch 7/0 loss 14.102633 loss_att 9.263283 loss_ctc 11.859693 loss_rnnt 8.381092 hw_loss 1.310338 lr 0.00065395 rank 2
2023-02-11 13:37:24,046 DEBUG TRAIN Batch 7/100 loss 25.166162 loss_att 29.540798 loss_ctc 46.695049 loss_rnnt 19.873722 hw_loss 0.290061 lr 0.00065407 rank 3
2023-02-11 13:37:24,049 DEBUG TRAIN Batch 7/100 loss 26.679996 loss_att 26.925259 loss_ctc 38.523521 loss_rnnt 20.228674 hw_loss 0.904338 lr 0.00065364 rank 0
2023-02-11 13:37:24,052 DEBUG TRAIN Batch 7/100 loss 16.488003 loss_att 18.533110 loss_ctc 24.395691 loss_rnnt 11.894556 hw_loss 0.586887 lr 0.00065406 rank 7
2023-02-11 13:37:24,055 DEBUG TRAIN Batch 7/100 loss 33.129082 loss_att 38.117744 loss_ctc 51.627960 loss_rnnt 25.570585 hw_loss 0.767672 lr 0.00065403 rank 4
2023-02-11 13:37:24,055 DEBUG TRAIN Batch 7/100 loss 17.887369 loss_att 19.994593 loss_ctc 24.750797 loss_rnnt 13.643844 hw_loss 0.545054 lr 0.00065375 rank 5
2023-02-11 13:37:24,057 DEBUG TRAIN Batch 7/100 loss 12.367521 loss_att 17.299086 loss_ctc 19.862249 loss_rnnt 7.803288 hw_loss 0.483492 lr 0.00065413 rank 6
2023-02-11 13:37:24,057 DEBUG TRAIN Batch 7/100 loss 11.595118 loss_att 20.016630 loss_ctc 25.275269 loss_rnnt 7.378672 hw_loss 0.132773 lr 0.00065371 rank 1
2023-02-11 13:37:24,104 DEBUG TRAIN Batch 7/100 loss 19.528275 loss_att 22.177574 loss_ctc 26.534437 loss_rnnt 14.875842 hw_loss 0.597828 lr 0.00065339 rank 2
2023-02-11 13:38:39,973 DEBUG TRAIN Batch 7/200 loss 15.008330 loss_att 18.647224 loss_ctc 24.894791 loss_rnnt 9.360683 hw_loss 0.675314 lr 0.00065308 rank 0
2023-02-11 13:38:39,974 DEBUG TRAIN Batch 7/200 loss 14.811230 loss_att 14.916864 loss_ctc 21.305611 loss_rnnt 10.899168 hw_loss 0.567191 lr 0.00065358 rank 6
2023-02-11 13:38:39,977 DEBUG TRAIN Batch 7/200 loss 43.391144 loss_att 48.079655 loss_ctc 65.117065 loss_rnnt 39.321392 hw_loss 0.044111 lr 0.00065350 rank 7
2023-02-11 13:38:39,978 DEBUG TRAIN Batch 7/200 loss 12.826002 loss_att 13.829910 loss_ctc 15.861113 loss_rnnt 10.406685 hw_loss 0.340098 lr 0.00065283 rank 2
2023-02-11 13:38:39,979 DEBUG TRAIN Batch 7/200 loss 25.553892 loss_att 24.563454 loss_ctc 36.782639 loss_rnnt 20.750488 hw_loss 0.657061 lr 0.00065347 rank 4
2023-02-11 13:38:39,981 DEBUG TRAIN Batch 7/200 loss 28.075085 loss_att 34.124805 loss_ctc 47.599426 loss_rnnt 20.935688 hw_loss 0.623664 lr 0.00065351 rank 3
2023-02-11 13:38:39,985 DEBUG TRAIN Batch 7/200 loss 20.037800 loss_att 27.893341 loss_ctc 32.275616 loss_rnnt 15.364203 hw_loss 0.275771 lr 0.00065316 rank 1
2023-02-11 13:38:39,986 DEBUG TRAIN Batch 7/200 loss 18.431389 loss_att 29.357353 loss_ctc 28.930677 loss_rnnt 13.220191 hw_loss 0.304894 lr 0.00065320 rank 5
2023-02-11 13:39:55,995 DEBUG TRAIN Batch 7/300 loss 17.553570 loss_att 18.823765 loss_ctc 20.687899 loss_rnnt 14.655084 hw_loss 0.417476 lr 0.00065302 rank 6
2023-02-11 13:39:55,997 DEBUG TRAIN Batch 7/300 loss 14.387522 loss_att 17.181845 loss_ctc 18.237995 loss_rnnt 10.890922 hw_loss 0.454564 lr 0.00065296 rank 3
2023-02-11 13:39:55,997 DEBUG TRAIN Batch 7/300 loss 20.401094 loss_att 25.236671 loss_ctc 32.533932 loss_rnnt 16.475792 hw_loss 0.251339 lr 0.00065264 rank 5
2023-02-11 13:39:55,998 DEBUG TRAIN Batch 7/300 loss 16.369158 loss_att 21.976185 loss_ctc 29.730528 loss_rnnt 11.230985 hw_loss 0.419109 lr 0.00065260 rank 1
2023-02-11 13:39:55,998 DEBUG TRAIN Batch 7/300 loss 14.543112 loss_att 18.245617 loss_ctc 22.899410 loss_rnnt 10.126762 hw_loss 0.480314 lr 0.00065228 rank 2
2023-02-11 13:39:55,999 DEBUG TRAIN Batch 7/300 loss 20.972755 loss_att 23.769978 loss_ctc 32.338882 loss_rnnt 18.040047 hw_loss 0.160834 lr 0.00065294 rank 7
2023-02-11 13:39:55,999 DEBUG TRAIN Batch 7/300 loss 14.722405 loss_att 15.776304 loss_ctc 21.508141 loss_rnnt 11.298649 hw_loss 0.432790 lr 0.00065252 rank 0
2023-02-11 13:39:56,004 DEBUG TRAIN Batch 7/300 loss 23.287989 loss_att 25.463192 loss_ctc 34.483418 loss_rnnt 18.460789 hw_loss 0.543644 lr 0.00065291 rank 4
2023-02-11 13:41:11,857 DEBUG TRAIN Batch 7/400 loss 18.115871 loss_att 20.464607 loss_ctc 27.620409 loss_rnnt 13.652496 hw_loss 0.511192 lr 0.00065240 rank 3
2023-02-11 13:41:11,859 DEBUG TRAIN Batch 7/400 loss 12.174216 loss_att 15.250314 loss_ctc 18.023897 loss_rnnt 8.372482 hw_loss 0.451229 lr 0.00065246 rank 6
2023-02-11 13:41:11,860 DEBUG TRAIN Batch 7/400 loss 22.988977 loss_att 27.634991 loss_ctc 36.172020 loss_rnnt 15.858755 hw_loss 0.833115 lr 0.00065208 rank 5
2023-02-11 13:41:11,862 DEBUG TRAIN Batch 7/400 loss 23.890038 loss_att 29.324451 loss_ctc 41.860748 loss_rnnt 18.458506 hw_loss 0.365353 lr 0.00065205 rank 1
2023-02-11 13:41:11,863 DEBUG TRAIN Batch 7/400 loss 17.008129 loss_att 18.346397 loss_ctc 20.458973 loss_rnnt 12.060351 hw_loss 0.791252 lr 0.00065197 rank 0
2023-02-11 13:41:11,865 DEBUG TRAIN Batch 7/400 loss 8.554485 loss_att 12.407755 loss_ctc 13.778884 loss_rnnt 4.671779 hw_loss 0.452900 lr 0.00065238 rank 7
2023-02-11 13:41:11,866 DEBUG TRAIN Batch 7/400 loss 20.592676 loss_att 24.535475 loss_ctc 33.542439 loss_rnnt 15.911890 hw_loss 0.406048 lr 0.00065172 rank 2
2023-02-11 13:41:11,912 DEBUG TRAIN Batch 7/400 loss 16.394186 loss_att 17.738773 loss_ctc 25.576900 loss_rnnt 12.193408 hw_loss 0.507656 lr 0.00065236 rank 4
2023-02-11 13:42:26,916 DEBUG TRAIN Batch 7/500 loss 12.797632 loss_att 13.638462 loss_ctc 18.179398 loss_rnnt 9.472330 hw_loss 0.457419 lr 0.00065183 rank 7
2023-02-11 13:42:26,917 DEBUG TRAIN Batch 7/500 loss 29.629745 loss_att 28.060688 loss_ctc 37.874516 loss_rnnt 24.253557 hw_loss 0.860756 lr 0.00065185 rank 3
2023-02-11 13:42:26,918 DEBUG TRAIN Batch 7/500 loss 17.476454 loss_att 16.715046 loss_ctc 19.107304 loss_rnnt 13.468752 hw_loss 0.739226 lr 0.00065149 rank 1
2023-02-11 13:42:26,919 DEBUG TRAIN Batch 7/500 loss 14.753851 loss_att 17.336636 loss_ctc 25.615789 loss_rnnt 11.298647 hw_loss 0.279448 lr 0.00065141 rank 0
2023-02-11 13:42:26,924 DEBUG TRAIN Batch 7/500 loss 7.581278 loss_att 9.660072 loss_ctc 12.100992 loss_rnnt 6.080237 hw_loss 0.090498 lr 0.00065153 rank 5
2023-02-11 13:42:26,925 DEBUG TRAIN Batch 7/500 loss 22.953423 loss_att 23.440102 loss_ctc 30.082069 loss_rnnt 18.316557 hw_loss 0.672945 lr 0.00065117 rank 2
2023-02-11 13:42:26,926 DEBUG TRAIN Batch 7/500 loss 19.926453 loss_att 21.654921 loss_ctc 30.122776 loss_rnnt 15.967936 hw_loss 0.422496 lr 0.00065191 rank 6
2023-02-11 13:42:26,932 DEBUG TRAIN Batch 7/500 loss 18.942743 loss_att 24.057848 loss_ctc 35.216869 loss_rnnt 15.121367 hw_loss 0.117838 lr 0.00065180 rank 4
2023-02-11 13:43:41,117 DEBUG TRAIN Batch 7/600 loss 13.340179 loss_att 12.488955 loss_ctc 17.348019 loss_rnnt 8.374329 hw_loss 0.862822 lr 0.00065135 rank 6
2023-02-11 13:43:41,120 DEBUG TRAIN Batch 7/600 loss 8.298586 loss_att 10.660451 loss_ctc 12.414486 loss_rnnt 5.506188 hw_loss 0.332107 lr 0.00065129 rank 3
2023-02-11 13:43:41,121 DEBUG TRAIN Batch 7/600 loss 22.017813 loss_att 21.830219 loss_ctc 30.763145 loss_rnnt 15.352985 hw_loss 1.038056 lr 0.00065062 rank 2
2023-02-11 13:43:41,123 DEBUG TRAIN Batch 7/600 loss 11.722279 loss_att 12.568124 loss_ctc 17.008999 loss_rnnt 8.215702 hw_loss 0.493596 lr 0.00065128 rank 7
2023-02-11 13:43:41,122 DEBUG TRAIN Batch 7/600 loss 17.436323 loss_att 15.314989 loss_ctc 24.339909 loss_rnnt 13.227053 hw_loss 0.696198 lr 0.00065086 rank 0
2023-02-11 13:43:41,128 DEBUG TRAIN Batch 7/600 loss 15.248406 loss_att 11.717558 loss_ctc 16.714140 loss_rnnt 8.795226 hw_loss 1.305735 lr 0.00065094 rank 1
2023-02-11 13:43:41,130 DEBUG TRAIN Batch 7/600 loss 19.927443 loss_att 21.291950 loss_ctc 27.706453 loss_rnnt 16.999477 hw_loss 0.303349 lr 0.00065098 rank 5
2023-02-11 13:43:41,133 DEBUG TRAIN Batch 7/600 loss 12.264221 loss_att 11.033920 loss_ctc 14.956367 loss_rnnt 8.498807 hw_loss 0.684848 lr 0.00065125 rank 4
2023-02-11 13:44:59,729 DEBUG TRAIN Batch 7/700 loss 25.504457 loss_att 27.196199 loss_ctc 45.410248 loss_rnnt 20.483662 hw_loss 0.380314 lr 0.00065031 rank 0
2023-02-11 13:44:59,734 DEBUG TRAIN Batch 7/700 loss 13.776175 loss_att 18.555458 loss_ctc 25.275335 loss_rnnt 10.831534 hw_loss 0.085418 lr 0.00065039 rank 1
2023-02-11 13:44:59,735 DEBUG TRAIN Batch 7/700 loss 18.655993 loss_att 19.789370 loss_ctc 30.011763 loss_rnnt 15.529707 hw_loss 0.259783 lr 0.00065072 rank 7
2023-02-11 13:44:59,737 DEBUG TRAIN Batch 7/700 loss 26.000757 loss_att 26.718754 loss_ctc 40.027397 loss_rnnt 21.895834 hw_loss 0.392083 lr 0.00065080 rank 6
2023-02-11 13:44:59,742 DEBUG TRAIN Batch 7/700 loss 13.478563 loss_att 15.310328 loss_ctc 27.005636 loss_rnnt 10.233396 hw_loss 0.201601 lr 0.00065043 rank 5
2023-02-11 13:44:59,745 DEBUG TRAIN Batch 7/700 loss 15.326924 loss_att 19.641140 loss_ctc 23.810041 loss_rnnt 10.708845 hw_loss 0.492029 lr 0.00065074 rank 3
2023-02-11 13:44:59,753 DEBUG TRAIN Batch 7/700 loss 6.359388 loss_att 9.453580 loss_ctc 14.000812 loss_rnnt 4.142103 hw_loss 0.108673 lr 0.00065007 rank 2
2023-02-11 13:44:59,804 DEBUG TRAIN Batch 7/700 loss 15.931010 loss_att 21.818766 loss_ctc 30.210442 loss_rnnt 9.598574 hw_loss 0.609555 lr 0.00065070 rank 4
2023-02-11 13:46:15,520 DEBUG TRAIN Batch 7/800 loss 6.830307 loss_att 8.241863 loss_ctc 7.617470 loss_rnnt 3.630492 hw_loss 0.527353 lr 0.00065017 rank 7
2023-02-11 13:46:15,526 DEBUG TRAIN Batch 7/800 loss 17.603668 loss_att 24.511589 loss_ctc 29.551702 loss_rnnt 10.885145 hw_loss 0.701975 lr 0.00065019 rank 3
2023-02-11 13:46:15,527 DEBUG TRAIN Batch 7/800 loss 13.808720 loss_att 15.190818 loss_ctc 22.523788 loss_rnnt 10.922286 hw_loss 0.271501 lr 0.00064976 rank 0
2023-02-11 13:46:15,528 DEBUG TRAIN Batch 7/800 loss 22.402996 loss_att 24.451721 loss_ctc 27.733109 loss_rnnt 18.769993 hw_loss 0.471108 lr 0.00064984 rank 1
2023-02-11 13:46:15,529 DEBUG TRAIN Batch 7/800 loss 14.107727 loss_att 17.597576 loss_ctc 17.221209 loss_rnnt 9.652106 hw_loss 0.626722 lr 0.00064952 rank 2
2023-02-11 13:46:15,529 DEBUG TRAIN Batch 7/800 loss 13.147354 loss_att 13.643562 loss_ctc 16.278332 loss_rnnt 9.964602 hw_loss 0.499884 lr 0.00065015 rank 4
2023-02-11 13:46:15,531 DEBUG TRAIN Batch 7/800 loss 14.259039 loss_att 15.656372 loss_ctc 23.406782 loss_rnnt 10.583151 hw_loss 0.408135 lr 0.00064988 rank 5
2023-02-11 13:46:15,573 DEBUG TRAIN Batch 7/800 loss 19.357477 loss_att 24.703289 loss_ctc 33.311455 loss_rnnt 14.251902 hw_loss 0.407978 lr 0.00065025 rank 6
2023-02-11 13:47:31,228 DEBUG TRAIN Batch 7/900 loss 19.509167 loss_att 23.050116 loss_ctc 28.928295 loss_rnnt 16.366947 hw_loss 0.220902 lr 0.00064962 rank 7
2023-02-11 13:47:31,228 DEBUG TRAIN Batch 7/900 loss 18.913588 loss_att 25.276096 loss_ctc 29.663153 loss_rnnt 13.283657 hw_loss 0.548279 lr 0.00064921 rank 0
2023-02-11 13:47:31,229 DEBUG TRAIN Batch 7/900 loss 27.706457 loss_att 31.149261 loss_ctc 39.270401 loss_rnnt 23.619774 hw_loss 0.348049 lr 0.00064933 rank 5
2023-02-11 13:47:31,233 DEBUG TRAIN Batch 7/900 loss 19.645006 loss_att 25.772526 loss_ctc 30.424290 loss_rnnt 15.660986 hw_loss 0.247740 lr 0.00064970 rank 6
2023-02-11 13:47:31,233 DEBUG TRAIN Batch 7/900 loss 12.730863 loss_att 15.601133 loss_ctc 19.815741 loss_rnnt 10.233368 hw_loss 0.183523 lr 0.00064897 rank 2
2023-02-11 13:47:31,234 DEBUG TRAIN Batch 7/900 loss 13.708235 loss_att 14.964518 loss_ctc 19.810898 loss_rnnt 10.677896 hw_loss 0.368511 lr 0.00064964 rank 3
2023-02-11 13:47:31,234 DEBUG TRAIN Batch 7/900 loss 17.789780 loss_att 26.370626 loss_ctc 32.388947 loss_rnnt 12.353798 hw_loss 0.332486 lr 0.00064929 rank 1
2023-02-11 13:47:31,235 DEBUG TRAIN Batch 7/900 loss 21.268209 loss_att 27.751175 loss_ctc 28.861708 loss_rnnt 16.984030 hw_loss 0.370335 lr 0.00064960 rank 4
2023-02-11 13:48:47,582 DEBUG TRAIN Batch 7/1000 loss 15.383451 loss_att 17.400881 loss_ctc 23.014179 loss_rnnt 11.424520 hw_loss 0.475878 lr 0.00064908 rank 7
2023-02-11 13:48:47,583 DEBUG TRAIN Batch 7/1000 loss 16.316910 loss_att 18.242405 loss_ctc 22.849037 loss_rnnt 11.791605 hw_loss 0.612985 lr 0.00064909 rank 3
2023-02-11 13:48:47,582 DEBUG TRAIN Batch 7/1000 loss 20.309763 loss_att 22.613110 loss_ctc 32.571053 loss_rnnt 16.463972 hw_loss 0.328178 lr 0.00064843 rank 2
2023-02-11 13:48:47,584 DEBUG TRAIN Batch 7/1000 loss 15.646468 loss_att 20.545677 loss_ctc 29.962456 loss_rnnt 9.729019 hw_loss 0.567902 lr 0.00064867 rank 0
2023-02-11 13:48:47,584 DEBUG TRAIN Batch 7/1000 loss 29.448191 loss_att 32.800179 loss_ctc 39.527931 loss_rnnt 22.519810 hw_loss 0.921378 lr 0.00064905 rank 4
2023-02-11 13:48:47,587 DEBUG TRAIN Batch 7/1000 loss 10.484211 loss_att 12.450602 loss_ctc 10.824924 loss_rnnt 7.057458 hw_loss 0.560259 lr 0.00064878 rank 5
2023-02-11 13:48:47,588 DEBUG TRAIN Batch 7/1000 loss 20.883348 loss_att 25.128050 loss_ctc 39.582878 loss_rnnt 14.793984 hw_loss 0.515091 lr 0.00064874 rank 1
2023-02-11 13:48:47,630 DEBUG TRAIN Batch 7/1000 loss 25.833580 loss_att 27.994194 loss_ctc 32.755272 loss_rnnt 24.172796 hw_loss 0.057331 lr 0.00064915 rank 6
2023-02-11 13:50:05,725 DEBUG TRAIN Batch 7/1100 loss 13.356908 loss_att 16.765072 loss_ctc 25.706245 loss_rnnt 9.835230 hw_loss 0.223775 lr 0.00064853 rank 7
2023-02-11 13:50:05,728 DEBUG TRAIN Batch 7/1100 loss 22.772861 loss_att 26.560839 loss_ctc 32.343761 loss_rnnt 18.019558 hw_loss 0.509923 lr 0.00064855 rank 3
2023-02-11 13:50:05,728 DEBUG TRAIN Batch 7/1100 loss 18.624479 loss_att 18.265331 loss_ctc 22.627552 loss_rnnt 16.447557 hw_loss 0.321564 lr 0.00064824 rank 5
2023-02-11 13:50:05,731 DEBUG TRAIN Batch 7/1100 loss 15.914144 loss_att 20.732382 loss_ctc 28.311008 loss_rnnt 11.713243 hw_loss 0.297063 lr 0.00064820 rank 1
2023-02-11 13:50:05,733 DEBUG TRAIN Batch 7/1100 loss 21.481894 loss_att 28.659023 loss_ctc 39.316708 loss_rnnt 16.955528 hw_loss 0.133681 lr 0.00064812 rank 0
2023-02-11 13:50:05,734 DEBUG TRAIN Batch 7/1100 loss 17.697027 loss_att 19.257183 loss_ctc 26.507530 loss_rnnt 14.282520 hw_loss 0.361451 lr 0.00064861 rank 6
2023-02-11 13:50:05,735 DEBUG TRAIN Batch 7/1100 loss 27.929800 loss_att 31.556961 loss_ctc 42.889091 loss_rnnt 21.654306 hw_loss 0.666654 lr 0.00064850 rank 4
2023-02-11 13:50:05,778 DEBUG TRAIN Batch 7/1100 loss 12.649929 loss_att 12.007400 loss_ctc 16.583963 loss_rnnt 7.823686 hw_loss 0.830665 lr 0.00064788 rank 2
2023-02-11 13:51:21,045 DEBUG TRAIN Batch 7/1200 loss 19.552021 loss_att 20.537579 loss_ctc 27.077803 loss_rnnt 15.162677 hw_loss 0.597899 lr 0.00064800 rank 3
2023-02-11 13:51:21,046 DEBUG TRAIN Batch 7/1200 loss 23.863634 loss_att 24.352383 loss_ctc 34.027275 loss_rnnt 18.349653 hw_loss 0.761453 lr 0.00064799 rank 7
2023-02-11 13:51:21,047 DEBUG TRAIN Batch 7/1200 loss 15.008307 loss_att 13.214460 loss_ctc 21.865370 loss_rnnt 10.650238 hw_loss 0.712981 lr 0.00064769 rank 5
2023-02-11 13:51:21,047 DEBUG TRAIN Batch 7/1200 loss 18.790262 loss_att 17.872322 loss_ctc 25.971069 loss_rnnt 15.417724 hw_loss 0.487254 lr 0.00064806 rank 6
2023-02-11 13:51:21,047 DEBUG TRAIN Batch 7/1200 loss 18.827503 loss_att 19.435907 loss_ctc 28.838224 loss_rnnt 15.788218 hw_loss 0.296783 lr 0.00064758 rank 0
2023-02-11 13:51:21,049 DEBUG TRAIN Batch 7/1200 loss 25.480957 loss_att 23.626390 loss_ctc 38.114563 loss_rnnt 20.774401 hw_loss 0.636185 lr 0.00064734 rank 2
2023-02-11 13:51:21,051 DEBUG TRAIN Batch 7/1200 loss 16.368525 loss_att 17.340755 loss_ctc 22.195435 loss_rnnt 12.717769 hw_loss 0.502385 lr 0.00064796 rank 4
2023-02-11 13:51:21,096 DEBUG TRAIN Batch 7/1200 loss 16.792545 loss_att 18.261923 loss_ctc 20.440962 loss_rnnt 14.309326 hw_loss 0.319291 lr 0.00064765 rank 1
2023-02-11 13:52:37,064 DEBUG TRAIN Batch 7/1300 loss 19.654734 loss_att 26.384052 loss_ctc 21.470175 loss_rnnt 13.950145 hw_loss 0.771875 lr 0.00064746 rank 3
2023-02-11 13:52:37,066 DEBUG TRAIN Batch 7/1300 loss 15.190903 loss_att 18.737349 loss_ctc 24.788422 loss_rnnt 12.762381 hw_loss 0.082418 lr 0.00064715 rank 5
2023-02-11 13:52:37,071 DEBUG TRAIN Batch 7/1300 loss 14.258075 loss_att 18.582819 loss_ctc 19.627728 loss_rnnt 10.457290 hw_loss 0.416228 lr 0.00064704 rank 0
2023-02-11 13:52:37,073 DEBUG TRAIN Batch 7/1300 loss 15.820850 loss_att 17.458996 loss_ctc 18.828936 loss_rnnt 12.701991 hw_loss 0.448153 lr 0.00064711 rank 1
2023-02-11 13:52:37,073 DEBUG TRAIN Batch 7/1300 loss 12.248640 loss_att 10.626859 loss_ctc 12.818910 loss_rnnt 7.006655 hw_loss 1.029432 lr 0.00064744 rank 7
2023-02-11 13:52:37,075 DEBUG TRAIN Batch 7/1300 loss 20.888212 loss_att 15.381290 loss_ctc 20.529079 loss_rnnt 15.877287 hw_loss 1.155036 lr 0.00064742 rank 4
2023-02-11 13:52:37,075 DEBUG TRAIN Batch 7/1300 loss 18.963003 loss_att 26.285580 loss_ctc 27.588242 loss_rnnt 14.786433 hw_loss 0.292879 lr 0.00064680 rank 2
2023-02-11 13:52:37,077 DEBUG TRAIN Batch 7/1300 loss 17.537838 loss_att 14.176786 loss_ctc 19.601313 loss_rnnt 12.060976 hw_loss 1.101364 lr 0.00064752 rank 6
2023-02-11 13:53:56,610 DEBUG TRAIN Batch 7/1400 loss 18.900084 loss_att 26.786549 loss_ctc 36.165081 loss_rnnt 13.988983 hw_loss 0.193464 lr 0.00064661 rank 5
2023-02-11 13:53:56,611 DEBUG TRAIN Batch 7/1400 loss 13.715237 loss_att 17.184715 loss_ctc 22.208782 loss_rnnt 9.682837 hw_loss 0.413631 lr 0.00064692 rank 3
2023-02-11 13:53:56,611 DEBUG TRAIN Batch 7/1400 loss 22.067549 loss_att 26.224758 loss_ctc 29.287207 loss_rnnt 17.890892 hw_loss 0.446736 lr 0.00064698 rank 6
2023-02-11 13:53:56,612 DEBUG TRAIN Batch 7/1400 loss 37.602509 loss_att 35.754368 loss_ctc 46.678814 loss_rnnt 32.571529 hw_loss 0.785707 lr 0.00064690 rank 7
2023-02-11 13:53:56,612 DEBUG TRAIN Batch 7/1400 loss 17.868925 loss_att 21.325312 loss_ctc 29.159695 loss_rnnt 13.303820 hw_loss 0.444073 lr 0.00064687 rank 4
2023-02-11 13:53:56,616 DEBUG TRAIN Batch 7/1400 loss 15.978539 loss_att 17.191063 loss_ctc 23.110508 loss_rnnt 11.830630 hw_loss 0.553964 lr 0.00064649 rank 0
2023-02-11 13:53:56,617 DEBUG TRAIN Batch 7/1400 loss 20.584337 loss_att 25.130547 loss_ctc 29.477287 loss_rnnt 18.039997 hw_loss 0.084257 lr 0.00064657 rank 1
2023-02-11 13:53:56,662 DEBUG TRAIN Batch 7/1400 loss 14.057673 loss_att 13.479508 loss_ctc 18.155487 loss_rnnt 10.341496 hw_loss 0.616019 lr 0.00064626 rank 2
2023-02-11 13:55:14,682 DEBUG TRAIN Batch 7/1500 loss 15.606626 loss_att 27.053043 loss_ctc 28.649084 loss_rnnt 9.661570 hw_loss 0.359396 lr 0.00064595 rank 0
2023-02-11 13:55:14,689 DEBUG TRAIN Batch 7/1500 loss 36.076626 loss_att 38.689880 loss_ctc 52.291931 loss_rnnt 30.740261 hw_loss 0.497189 lr 0.00064607 rank 5
2023-02-11 13:55:14,692 DEBUG TRAIN Batch 7/1500 loss 16.638996 loss_att 16.680702 loss_ctc 21.748638 loss_rnnt 13.734354 hw_loss 0.415315 lr 0.00064636 rank 7
2023-02-11 13:55:14,693 DEBUG TRAIN Batch 7/1500 loss 18.105236 loss_att 18.368677 loss_ctc 26.460760 loss_rnnt 15.911514 hw_loss 0.192555 lr 0.00064603 rank 1
2023-02-11 13:55:14,693 DEBUG TRAIN Batch 7/1500 loss 19.945339 loss_att 23.262730 loss_ctc 34.243576 loss_rnnt 15.377475 hw_loss 0.374617 lr 0.00064572 rank 2
2023-02-11 13:55:14,693 DEBUG TRAIN Batch 7/1500 loss 20.099121 loss_att 20.887936 loss_ctc 29.145056 loss_rnnt 16.012764 hw_loss 0.510463 lr 0.00064638 rank 3
2023-02-11 13:55:14,700 DEBUG TRAIN Batch 7/1500 loss 17.320791 loss_att 24.084337 loss_ctc 32.992287 loss_rnnt 12.701591 hw_loss 0.220680 lr 0.00064633 rank 4
2023-02-11 13:55:14,736 DEBUG TRAIN Batch 7/1500 loss 12.869457 loss_att 18.124859 loss_ctc 21.105164 loss_rnnt 10.336350 hw_loss 0.071987 lr 0.00064644 rank 6
2023-02-11 13:56:29,297 DEBUG TRAIN Batch 7/1600 loss 14.034828 loss_att 14.688240 loss_ctc 18.180111 loss_rnnt 10.105841 hw_loss 0.608550 lr 0.00064590 rank 6
2023-02-11 13:56:29,297 DEBUG TRAIN Batch 7/1600 loss 19.476131 loss_att 22.934391 loss_ctc 30.405643 loss_rnnt 15.224152 hw_loss 0.394323 lr 0.00064553 rank 5
2023-02-11 13:56:29,300 DEBUG TRAIN Batch 7/1600 loss 14.490916 loss_att 15.367432 loss_ctc 23.526011 loss_rnnt 11.152391 hw_loss 0.367227 lr 0.00064542 rank 0
2023-02-11 13:56:29,302 DEBUG TRAIN Batch 7/1600 loss 22.124578 loss_att 27.252281 loss_ctc 36.789574 loss_rnnt 17.755814 hw_loss 0.260230 lr 0.00064584 rank 3
2023-02-11 13:56:29,302 DEBUG TRAIN Batch 7/1600 loss 18.100933 loss_att 18.152994 loss_ctc 28.361164 loss_rnnt 13.751057 hw_loss 0.557144 lr 0.00064549 rank 1
2023-02-11 13:56:29,302 DEBUG TRAIN Batch 7/1600 loss 26.225037 loss_att 28.018143 loss_ctc 38.043888 loss_rnnt 21.195503 hw_loss 0.580325 lr 0.00064582 rank 7
2023-02-11 13:56:29,306 DEBUG TRAIN Batch 7/1600 loss 16.909374 loss_att 18.325342 loss_ctc 21.652742 loss_rnnt 13.542267 hw_loss 0.459649 lr 0.00064579 rank 4
2023-02-11 13:56:29,308 DEBUG TRAIN Batch 7/1600 loss 23.000883 loss_att 30.269039 loss_ctc 44.105705 loss_rnnt 18.137569 hw_loss 0.111695 lr 0.00064518 rank 2
2023-02-11 13:57:45,862 DEBUG TRAIN Batch 7/1700 loss 21.233454 loss_att 22.371685 loss_ctc 27.657787 loss_rnnt 15.770609 hw_loss 0.820991 lr 0.00064530 rank 3
2023-02-11 13:57:45,862 DEBUG TRAIN Batch 7/1700 loss 18.574318 loss_att 21.077810 loss_ctc 25.986691 loss_rnnt 14.258520 hw_loss 0.530021 lr 0.00064495 rank 1
2023-02-11 13:57:45,864 DEBUG TRAIN Batch 7/1700 loss 14.690491 loss_att 18.656322 loss_ctc 32.187778 loss_rnnt 9.923496 hw_loss 0.307660 lr 0.00064499 rank 5
2023-02-11 13:57:45,864 DEBUG TRAIN Batch 7/1700 loss 24.759134 loss_att 25.340206 loss_ctc 30.993183 loss_rnnt 20.282330 hw_loss 0.661759 lr 0.00064528 rank 7
2023-02-11 13:57:45,865 DEBUG TRAIN Batch 7/1700 loss 14.556744 loss_att 19.038525 loss_ctc 21.055223 loss_rnnt 11.621149 hw_loss 0.219895 lr 0.00064488 rank 0
2023-02-11 13:57:45,891 DEBUG TRAIN Batch 7/1700 loss 16.514652 loss_att 21.132307 loss_ctc 26.043055 loss_rnnt 12.960096 hw_loss 0.255107 lr 0.00064536 rank 6
2023-02-11 13:57:45,899 DEBUG TRAIN Batch 7/1700 loss 25.087940 loss_att 22.323978 loss_ctc 28.340061 loss_rnnt 21.619747 hw_loss 0.672632 lr 0.00064464 rank 2
2023-02-11 13:57:45,913 DEBUG TRAIN Batch 7/1700 loss 16.490887 loss_att 17.760323 loss_ctc 22.360111 loss_rnnt 13.863195 hw_loss 0.298358 lr 0.00064526 rank 4
2023-02-11 13:59:05,171 DEBUG TRAIN Batch 7/1800 loss 23.424952 loss_att 24.745678 loss_ctc 31.022743 loss_rnnt 18.156958 hw_loss 0.748277 lr 0.00064475 rank 7
2023-02-11 13:59:05,173 DEBUG TRAIN Batch 7/1800 loss 11.004206 loss_att 13.899231 loss_ctc 18.777802 loss_rnnt 8.133953 hw_loss 0.235269 lr 0.00064476 rank 3
2023-02-11 13:59:05,175 DEBUG TRAIN Batch 7/1800 loss 16.905512 loss_att 16.376953 loss_ctc 20.233639 loss_rnnt 12.531721 hw_loss 0.756704 lr 0.00064442 rank 1
2023-02-11 13:59:05,175 DEBUG TRAIN Batch 7/1800 loss 18.037939 loss_att 20.389280 loss_ctc 28.060709 loss_rnnt 12.708569 hw_loss 0.660512 lr 0.00064434 rank 0
2023-02-11 13:59:05,181 DEBUG TRAIN Batch 7/1800 loss 15.182173 loss_att 14.668634 loss_ctc 21.714390 loss_rnnt 8.611611 hw_loss 1.087932 lr 0.00064411 rank 2
2023-02-11 13:59:05,183 DEBUG TRAIN Batch 7/1800 loss 15.698546 loss_att 20.097210 loss_ctc 25.504116 loss_rnnt 12.388195 hw_loss 0.210601 lr 0.00064482 rank 6
2023-02-11 13:59:05,183 DEBUG TRAIN Batch 7/1800 loss 33.358616 loss_att 31.358799 loss_ctc 42.703796 loss_rnnt 29.486816 hw_loss 0.567326 lr 0.00064446 rank 5
2023-02-11 13:59:05,185 DEBUG TRAIN Batch 7/1800 loss 15.790644 loss_att 17.193964 loss_ctc 20.154776 loss_rnnt 11.981196 hw_loss 0.552543 lr 0.00064472 rank 4
2023-02-11 14:00:21,422 DEBUG TRAIN Batch 7/1900 loss 23.695513 loss_att 19.325283 loss_ctc 25.630833 loss_rnnt 18.934509 hw_loss 1.008189 lr 0.00064381 rank 0
2023-02-11 14:00:21,421 DEBUG TRAIN Batch 7/1900 loss 19.541027 loss_att 16.861092 loss_ctc 22.436926 loss_rnnt 13.770306 hw_loss 1.110110 lr 0.00064423 rank 3
2023-02-11 14:00:21,424 DEBUG TRAIN Batch 7/1900 loss 19.470274 loss_att 24.625587 loss_ctc 28.922840 loss_rnnt 15.374812 hw_loss 0.338261 lr 0.00064421 rank 7
2023-02-11 14:00:21,427 DEBUG TRAIN Batch 7/1900 loss 17.487507 loss_att 16.340876 loss_ctc 21.543968 loss_rnnt 11.714078 hw_loss 1.024105 lr 0.00064357 rank 2
2023-02-11 14:00:21,427 DEBUG TRAIN Batch 7/1900 loss 13.666345 loss_att 11.205921 loss_ctc 15.584676 loss_rnnt 10.003370 hw_loss 0.731115 lr 0.00064388 rank 1
2023-02-11 14:00:21,427 DEBUG TRAIN Batch 7/1900 loss 18.578360 loss_att 18.678383 loss_ctc 26.353893 loss_rnnt 14.580936 hw_loss 0.551378 lr 0.00064418 rank 4
2023-02-11 14:00:21,427 DEBUG TRAIN Batch 7/1900 loss 19.409513 loss_att 22.927666 loss_ctc 28.749001 loss_rnnt 14.509006 hw_loss 0.553427 lr 0.00064392 rank 5
2023-02-11 14:00:21,473 DEBUG TRAIN Batch 7/1900 loss 11.294581 loss_att 12.857042 loss_ctc 20.747961 loss_rnnt 8.328256 hw_loss 0.261259 lr 0.00064428 rank 6
2023-02-11 14:01:36,455 DEBUG TRAIN Batch 7/2000 loss 56.653072 loss_att 54.279953 loss_ctc 80.891106 loss_rnnt 51.253647 hw_loss 0.495432 lr 0.00064335 rank 1
2023-02-11 14:01:36,455 DEBUG TRAIN Batch 7/2000 loss 29.415440 loss_att 32.014729 loss_ctc 46.838737 loss_rnnt 24.314566 hw_loss 0.423358 lr 0.00064328 rank 0
2023-02-11 14:01:36,459 DEBUG TRAIN Batch 7/2000 loss 24.267580 loss_att 27.768942 loss_ctc 37.237473 loss_rnnt 20.285154 hw_loss 0.291156 lr 0.00064304 rank 2
2023-02-11 14:01:36,458 DEBUG TRAIN Batch 7/2000 loss 15.270714 loss_att 20.573891 loss_ctc 22.070707 loss_rnnt 11.147163 hw_loss 0.404297 lr 0.00064369 rank 3
2023-02-11 14:01:36,461 DEBUG TRAIN Batch 7/2000 loss 25.099739 loss_att 29.837164 loss_ctc 41.253929 loss_rnnt 20.355606 hw_loss 0.308017 lr 0.00064368 rank 7
2023-02-11 14:01:36,460 DEBUG TRAIN Batch 7/2000 loss 24.354185 loss_att 23.295303 loss_ctc 37.258186 loss_rnnt 18.471313 hw_loss 0.820147 lr 0.00064339 rank 5
2023-02-11 14:01:36,462 DEBUG TRAIN Batch 7/2000 loss 14.786080 loss_att 21.535984 loss_ctc 26.154053 loss_rnnt 10.803293 hw_loss 0.209452 lr 0.00064375 rank 6
2023-02-11 14:01:36,462 DEBUG TRAIN Batch 7/2000 loss 11.077644 loss_att 14.437935 loss_ctc 18.504419 loss_rnnt 7.887584 hw_loss 0.286456 lr 0.00064365 rank 4
2023-02-11 14:02:53,883 DEBUG TRAIN Batch 7/2100 loss 16.836769 loss_att 19.699921 loss_ctc 28.918133 loss_rnnt 12.541878 hw_loss 0.395890 lr 0.00064314 rank 7
2023-02-11 14:02:53,884 DEBUG TRAIN Batch 7/2100 loss 14.589087 loss_att 18.703344 loss_ctc 31.281668 loss_rnnt 10.720687 hw_loss 0.153726 lr 0.00064316 rank 3
2023-02-11 14:02:53,885 DEBUG TRAIN Batch 7/2100 loss 13.808288 loss_att 16.177746 loss_ctc 24.976891 loss_rnnt 9.154854 hw_loss 0.504449 lr 0.00064322 rank 6
2023-02-11 14:02:53,886 DEBUG TRAIN Batch 7/2100 loss 18.636961 loss_att 26.101810 loss_ctc 30.580839 loss_rnnt 14.727509 hw_loss 0.154494 lr 0.00064251 rank 2
2023-02-11 14:02:53,887 DEBUG TRAIN Batch 7/2100 loss 10.491007 loss_att 12.648825 loss_ctc 17.868622 loss_rnnt 6.244352 hw_loss 0.530889 lr 0.00064286 rank 5
2023-02-11 14:02:53,888 DEBUG TRAIN Batch 7/2100 loss 12.140318 loss_att 15.735331 loss_ctc 15.506273 loss_rnnt 9.501958 hw_loss 0.275731 lr 0.00064312 rank 4
2023-02-11 14:02:53,891 DEBUG TRAIN Batch 7/2100 loss 31.067089 loss_att 31.891453 loss_ctc 47.165070 loss_rnnt 26.063732 hw_loss 0.504766 lr 0.00064274 rank 0
2023-02-11 14:02:53,895 DEBUG TRAIN Batch 7/2100 loss 10.544508 loss_att 13.147407 loss_ctc 17.760429 loss_rnnt 6.664750 hw_loss 0.449448 lr 0.00064282 rank 1
2023-02-11 14:04:11,715 DEBUG TRAIN Batch 7/2200 loss 13.928552 loss_att 14.816453 loss_ctc 15.710506 loss_rnnt 8.505293 hw_loss 0.939016 lr 0.00064263 rank 3
2023-02-11 14:04:11,717 DEBUG TRAIN Batch 7/2200 loss 19.668520 loss_att 26.273758 loss_ctc 31.728924 loss_rnnt 13.662278 hw_loss 0.576964 lr 0.00064229 rank 1
2023-02-11 14:04:11,718 DEBUG TRAIN Batch 7/2200 loss 30.045179 loss_att 35.318035 loss_ctc 49.344513 loss_rnnt 24.687149 hw_loss 0.324415 lr 0.00064221 rank 0
2023-02-11 14:04:11,720 DEBUG TRAIN Batch 7/2200 loss 21.624699 loss_att 25.695997 loss_ctc 32.154381 loss_rnnt 16.322529 hw_loss 0.578241 lr 0.00064233 rank 5
2023-02-11 14:04:11,721 DEBUG TRAIN Batch 7/2200 loss 21.882103 loss_att 21.166874 loss_ctc 31.632481 loss_rnnt 19.250816 hw_loss 0.276428 lr 0.00064261 rank 7
2023-02-11 14:04:11,721 DEBUG TRAIN Batch 7/2200 loss 14.536383 loss_att 15.822453 loss_ctc 21.572144 loss_rnnt 9.879799 hw_loss 0.648988 lr 0.00064269 rank 6
2023-02-11 14:04:11,723 DEBUG TRAIN Batch 7/2200 loss 16.450304 loss_att 20.065294 loss_ctc 19.228107 loss_rnnt 12.546700 hw_loss 0.526918 lr 0.00064259 rank 4
2023-02-11 14:04:11,771 DEBUG TRAIN Batch 7/2200 loss 17.981846 loss_att 19.113701 loss_ctc 25.048981 loss_rnnt 13.664348 hw_loss 0.590408 lr 0.00064198 rank 2
2023-02-11 14:05:26,704 DEBUG TRAIN Batch 7/2300 loss 13.131594 loss_att 15.437748 loss_ctc 18.186684 loss_rnnt 9.612993 hw_loss 0.446880 lr 0.00064169 rank 0
2023-02-11 14:05:26,704 DEBUG TRAIN Batch 7/2300 loss 19.113449 loss_att 19.857489 loss_ctc 25.253225 loss_rnnt 16.274151 hw_loss 0.350972 lr 0.00064180 rank 5
2023-02-11 14:05:26,704 DEBUG TRAIN Batch 7/2300 loss 12.916677 loss_att 15.153386 loss_ctc 19.947336 loss_rnnt 9.621126 hw_loss 0.358273 lr 0.00064210 rank 3
2023-02-11 14:05:26,704 DEBUG TRAIN Batch 7/2300 loss 17.278452 loss_att 16.684816 loss_ctc 23.535774 loss_rnnt 14.364891 hw_loss 0.412121 lr 0.00064206 rank 4
2023-02-11 14:05:26,705 DEBUG TRAIN Batch 7/2300 loss 28.673252 loss_att 32.760666 loss_ctc 34.339909 loss_rnnt 22.511698 hw_loss 0.860347 lr 0.00064208 rank 7
2023-02-11 14:05:26,704 DEBUG TRAIN Batch 7/2300 loss 33.894573 loss_att 40.917366 loss_ctc 51.535728 loss_rnnt 29.145126 hw_loss 0.186138 lr 0.00064216 rank 6
2023-02-11 14:05:26,706 DEBUG TRAIN Batch 7/2300 loss 19.593039 loss_att 25.140345 loss_ctc 30.050419 loss_rnnt 15.344313 hw_loss 0.327177 lr 0.00064145 rank 2
2023-02-11 14:05:26,755 DEBUG TRAIN Batch 7/2300 loss 11.142387 loss_att 12.354387 loss_ctc 21.497171 loss_rnnt 6.748631 hw_loss 0.519510 lr 0.00064176 rank 1
2023-02-11 14:06:43,570 DEBUG TRAIN Batch 7/2400 loss 20.833317 loss_att 22.075727 loss_ctc 31.632069 loss_rnnt 16.236210 hw_loss 0.545398 lr 0.00064123 rank 1
2023-02-11 14:06:43,570 DEBUG TRAIN Batch 7/2400 loss 15.552668 loss_att 15.529777 loss_ctc 17.762419 loss_rnnt 11.558093 hw_loss 0.694597 lr 0.00064127 rank 5
2023-02-11 14:06:43,570 DEBUG TRAIN Batch 7/2400 loss 22.286255 loss_att 24.065094 loss_ctc 31.090641 loss_rnnt 16.863922 hw_loss 0.729871 lr 0.00064155 rank 7
2023-02-11 14:06:43,572 DEBUG TRAIN Batch 7/2400 loss 15.363718 loss_att 18.731651 loss_ctc 25.995329 loss_rnnt 10.744368 hw_loss 0.474041 lr 0.00064093 rank 2
2023-02-11 14:06:43,573 DEBUG TRAIN Batch 7/2400 loss 17.161413 loss_att 16.818676 loss_ctc 25.051107 loss_rnnt 13.795262 hw_loss 0.446763 lr 0.00064116 rank 0
2023-02-11 14:06:43,574 DEBUG TRAIN Batch 7/2400 loss 17.296803 loss_att 19.456968 loss_ctc 24.723042 loss_rnnt 11.773381 hw_loss 0.768979 lr 0.00064157 rank 3
2023-02-11 14:06:43,575 DEBUG TRAIN Batch 7/2400 loss 17.363621 loss_att 20.633581 loss_ctc 26.516293 loss_rnnt 13.973286 hw_loss 0.284248 lr 0.00064153 rank 4
2023-02-11 14:06:43,578 DEBUG TRAIN Batch 7/2400 loss 29.661669 loss_att 32.509731 loss_ctc 44.178719 loss_rnnt 23.062731 hw_loss 0.767572 lr 0.00064163 rank 6
2023-02-11 14:08:03,326 DEBUG TRAIN Batch 7/2500 loss 16.402905 loss_att 13.795708 loss_ctc 19.543324 loss_rnnt 11.113565 hw_loss 1.011010 lr 0.00064074 rank 5
2023-02-11 14:08:03,328 DEBUG TRAIN Batch 7/2500 loss 26.196041 loss_att 31.202309 loss_ctc 35.867538 loss_rnnt 22.240940 hw_loss 0.312058 lr 0.00064103 rank 7
2023-02-11 14:08:03,331 DEBUG TRAIN Batch 7/2500 loss 13.628471 loss_att 13.944265 loss_ctc 20.128626 loss_rnnt 10.556548 hw_loss 0.401640 lr 0.00064104 rank 3
2023-02-11 14:08:03,331 DEBUG TRAIN Batch 7/2500 loss 11.879543 loss_att 8.108476 loss_ctc 11.503400 loss_rnnt 6.770609 hw_loss 1.108744 lr 0.00064063 rank 0
2023-02-11 14:08:03,332 DEBUG TRAIN Batch 7/2500 loss 17.842297 loss_att 19.364172 loss_ctc 32.261154 loss_rnnt 13.711896 hw_loss 0.356908 lr 0.00064040 rank 2
2023-02-11 14:08:03,335 DEBUG TRAIN Batch 7/2500 loss 15.962897 loss_att 15.996914 loss_ctc 21.799541 loss_rnnt 11.418244 hw_loss 0.704931 lr 0.00064110 rank 6
2023-02-11 14:08:03,351 DEBUG TRAIN Batch 7/2500 loss 14.054576 loss_att 12.858551 loss_ctc 18.065804 loss_rnnt 11.120708 hw_loss 0.494671 lr 0.00064070 rank 1
2023-02-11 14:08:03,363 DEBUG TRAIN Batch 7/2500 loss 10.948711 loss_att 9.105900 loss_ctc 11.896502 loss_rnnt 6.517818 hw_loss 0.876203 lr 0.00064100 rank 4
2023-02-11 14:09:19,216 DEBUG TRAIN Batch 7/2600 loss 22.962843 loss_att 25.854160 loss_ctc 36.303005 loss_rnnt 19.984901 hw_loss 0.116435 lr 0.00064050 rank 7
2023-02-11 14:09:19,225 DEBUG TRAIN Batch 7/2600 loss 19.009521 loss_att 22.433462 loss_ctc 25.962746 loss_rnnt 15.630206 hw_loss 0.331393 lr 0.00064011 rank 0
2023-02-11 14:09:19,224 DEBUG TRAIN Batch 7/2600 loss 21.829548 loss_att 24.810860 loss_ctc 29.904018 loss_rnnt 18.854286 hw_loss 0.244201 lr 0.00064052 rank 3
2023-02-11 14:09:19,225 DEBUG TRAIN Batch 7/2600 loss 22.623394 loss_att 28.722075 loss_ctc 37.403358 loss_rnnt 16.301716 hw_loss 0.587115 lr 0.00063988 rank 2
2023-02-11 14:09:19,230 DEBUG TRAIN Batch 7/2600 loss 19.914022 loss_att 21.667206 loss_ctc 28.550455 loss_rnnt 17.626709 hw_loss 0.147216 lr 0.00064057 rank 6
2023-02-11 14:09:19,231 DEBUG TRAIN Batch 7/2600 loss 21.417416 loss_att 27.962254 loss_ctc 34.363491 loss_rnnt 17.152557 hw_loss 0.230577 lr 0.00064047 rank 4
2023-02-11 14:09:19,231 DEBUG TRAIN Batch 7/2600 loss 12.379230 loss_att 16.354876 loss_ctc 22.410915 loss_rnnt 8.769774 hw_loss 0.276894 lr 0.00064022 rank 5
2023-02-11 14:09:19,233 DEBUG TRAIN Batch 7/2600 loss 14.949834 loss_att 15.862959 loss_ctc 23.921200 loss_rnnt 11.386360 hw_loss 0.409625 lr 0.00064018 rank 1
2023-02-11 14:10:34,787 DEBUG TRAIN Batch 7/2700 loss 15.478123 loss_att 18.193672 loss_ctc 24.567974 loss_rnnt 10.684752 hw_loss 0.569678 lr 0.00063999 rank 3
2023-02-11 14:10:34,793 DEBUG TRAIN Batch 7/2700 loss 10.051293 loss_att 12.401617 loss_ctc 19.021824 loss_rnnt 6.794452 hw_loss 0.298257 lr 0.00063958 rank 0
2023-02-11 14:10:34,794 DEBUG TRAIN Batch 7/2700 loss 35.016712 loss_att 33.785934 loss_ctc 49.263222 loss_rnnt 30.507946 hw_loss 0.535385 lr 0.00063997 rank 7
2023-02-11 14:10:34,795 DEBUG TRAIN Batch 7/2700 loss 15.196426 loss_att 17.725311 loss_ctc 26.885717 loss_rnnt 11.888897 hw_loss 0.233096 lr 0.00063995 rank 4
2023-02-11 14:10:34,797 DEBUG TRAIN Batch 7/2700 loss 12.421670 loss_att 15.426436 loss_ctc 19.420959 loss_rnnt 8.108706 hw_loss 0.521020 lr 0.00063966 rank 1
2023-02-11 14:10:34,797 DEBUG TRAIN Batch 7/2700 loss 16.618839 loss_att 19.266510 loss_ctc 26.343616 loss_rnnt 11.886288 hw_loss 0.544946 lr 0.00064005 rank 6
2023-02-11 14:10:34,797 DEBUG TRAIN Batch 7/2700 loss 16.119963 loss_att 17.541164 loss_ctc 20.546055 loss_rnnt 11.823086 hw_loss 0.641717 lr 0.00063935 rank 2
2023-02-11 14:10:34,800 DEBUG TRAIN Batch 7/2700 loss 15.022672 loss_att 15.119909 loss_ctc 20.506878 loss_rnnt 12.208004 hw_loss 0.386999 lr 0.00063969 rank 5
2023-02-11 14:11:52,362 DEBUG TRAIN Batch 7/2800 loss 23.764399 loss_att 28.025209 loss_ctc 41.592983 loss_rnnt 19.910639 hw_loss 0.117085 lr 0.00063947 rank 3
2023-02-11 14:11:52,362 DEBUG TRAIN Batch 7/2800 loss 30.917145 loss_att 33.338104 loss_ctc 42.081108 loss_rnnt 25.545124 hw_loss 0.637369 lr 0.00063906 rank 0
2023-02-11 14:11:52,367 DEBUG TRAIN Batch 7/2800 loss 23.701273 loss_att 29.915676 loss_ctc 40.094658 loss_rnnt 17.469673 hw_loss 0.525550 lr 0.00063942 rank 4
2023-02-11 14:11:52,367 DEBUG TRAIN Batch 7/2800 loss 28.239269 loss_att 27.243397 loss_ctc 39.636215 loss_rnnt 24.120234 hw_loss 0.524741 lr 0.00063917 rank 5
2023-02-11 14:11:52,369 DEBUG TRAIN Batch 7/2800 loss 9.628478 loss_att 12.717378 loss_ctc 20.698742 loss_rnnt 6.439407 hw_loss 0.205360 lr 0.00063945 rank 7
2023-02-11 14:11:52,382 DEBUG TRAIN Batch 7/2800 loss 20.099163 loss_att 23.237003 loss_ctc 29.616606 loss_rnnt 17.231300 hw_loss 0.182119 lr 0.00063883 rank 2
2023-02-11 14:11:52,390 DEBUG TRAIN Batch 7/2800 loss 5.866257 loss_att 11.340934 loss_ctc 11.506838 loss_rnnt 2.966510 hw_loss 0.197388 lr 0.00063952 rank 6
2023-02-11 14:11:52,415 DEBUG TRAIN Batch 7/2800 loss 16.974211 loss_att 21.729841 loss_ctc 27.281092 loss_rnnt 14.180161 hw_loss 0.087876 lr 0.00063913 rank 1
2023-02-11 14:13:08,900 DEBUG TRAIN Batch 7/2900 loss 15.663742 loss_att 22.386234 loss_ctc 27.439434 loss_rnnt 10.262961 hw_loss 0.466161 lr 0.00063893 rank 7
2023-02-11 14:13:08,900 DEBUG TRAIN Batch 7/2900 loss 22.420671 loss_att 21.512909 loss_ctc 28.402151 loss_rnnt 19.702703 hw_loss 0.394123 lr 0.00063854 rank 0
2023-02-11 14:13:08,908 DEBUG TRAIN Batch 7/2900 loss 18.205723 loss_att 22.252123 loss_ctc 30.094078 loss_rnnt 15.165796 hw_loss 0.121037 lr 0.00063865 rank 5
2023-02-11 14:13:08,909 DEBUG TRAIN Batch 7/2900 loss 14.019150 loss_att 14.015400 loss_ctc 15.666079 loss_rnnt 9.054989 hw_loss 0.889748 lr 0.00063831 rank 2
2023-02-11 14:13:08,909 DEBUG TRAIN Batch 7/2900 loss 16.815273 loss_att 21.024265 loss_ctc 26.210783 loss_rnnt 12.081921 hw_loss 0.494779 lr 0.00063861 rank 1
2023-02-11 14:13:08,911 DEBUG TRAIN Batch 7/2900 loss 16.668261 loss_att 18.681770 loss_ctc 19.435699 loss_rnnt 11.201424 hw_loss 0.880339 lr 0.00063894 rank 3
2023-02-11 14:13:08,912 DEBUG TRAIN Batch 7/2900 loss 34.314602 loss_att 35.029949 loss_ctc 40.092537 loss_rnnt 30.788261 hw_loss 0.489915 lr 0.00063900 rank 6
2023-02-11 14:13:08,912 DEBUG TRAIN Batch 7/2900 loss 13.330557 loss_att 14.520237 loss_ctc 21.114326 loss_rnnt 8.487837 hw_loss 0.668803 lr 0.00063890 rank 4
2023-02-11 14:14:26,115 DEBUG TRAIN Batch 7/3000 loss 18.351040 loss_att 18.893669 loss_ctc 23.084942 loss_rnnt 14.639496 hw_loss 0.557218 lr 0.00063848 rank 6
2023-02-11 14:14:26,122 DEBUG TRAIN Batch 7/3000 loss 12.302086 loss_att 16.417997 loss_ctc 22.896235 loss_rnnt 9.408750 hw_loss 0.123300 lr 0.00063841 rank 7
2023-02-11 14:14:26,122 DEBUG TRAIN Batch 7/3000 loss 18.978724 loss_att 22.382700 loss_ctc 28.812389 loss_rnnt 15.359975 hw_loss 0.305025 lr 0.00063813 rank 5
2023-02-11 14:14:26,122 DEBUG TRAIN Batch 7/3000 loss 19.510262 loss_att 21.993670 loss_ctc 26.176359 loss_rnnt 14.452638 hw_loss 0.688524 lr 0.00063842 rank 3
2023-02-11 14:14:26,124 DEBUG TRAIN Batch 7/3000 loss 14.752422 loss_att 16.326738 loss_ctc 22.082844 loss_rnnt 11.748186 hw_loss 0.320997 lr 0.00063809 rank 1
2023-02-11 14:14:26,125 DEBUG TRAIN Batch 7/3000 loss 15.474470 loss_att 18.719862 loss_ctc 18.965130 loss_rnnt 12.497696 hw_loss 0.349176 lr 0.00063802 rank 0
2023-02-11 14:14:26,126 DEBUG TRAIN Batch 7/3000 loss 12.410985 loss_att 12.690233 loss_ctc 16.822464 loss_rnnt 9.085938 hw_loss 0.502688 lr 0.00063779 rank 2
2023-02-11 14:14:26,128 DEBUG TRAIN Batch 7/3000 loss 24.126553 loss_att 28.358063 loss_ctc 40.100903 loss_rnnt 17.385830 hw_loss 0.705845 lr 0.00063838 rank 4
2023-02-11 14:15:40,725 DEBUG TRAIN Batch 7/3100 loss 9.725793 loss_att 8.647087 loss_ctc 13.220012 loss_rnnt 6.987500 hw_loss 0.466526 lr 0.00063750 rank 0
2023-02-11 14:15:40,727 DEBUG TRAIN Batch 7/3100 loss 14.167094 loss_att 14.456387 loss_ctc 24.243155 loss_rnnt 9.630095 hw_loss 0.587937 lr 0.00063757 rank 1
2023-02-11 14:15:40,727 DEBUG TRAIN Batch 7/3100 loss 34.435081 loss_att 36.510201 loss_ctc 42.840588 loss_rnnt 31.277328 hw_loss 0.304124 lr 0.00063790 rank 3
2023-02-11 14:15:40,730 DEBUG TRAIN Batch 7/3100 loss 11.289804 loss_att 10.692135 loss_ctc 11.520156 loss_rnnt 7.990321 hw_loss 0.635307 lr 0.00063761 rank 5
2023-02-11 14:15:40,732 DEBUG TRAIN Batch 7/3100 loss 19.900520 loss_att 21.634754 loss_ctc 30.470015 loss_rnnt 16.122770 hw_loss 0.379057 lr 0.00063786 rank 4
2023-02-11 14:15:40,732 DEBUG TRAIN Batch 7/3100 loss 18.817476 loss_att 17.535112 loss_ctc 25.291840 loss_rnnt 14.417914 hw_loss 0.711147 lr 0.00063727 rank 2
2023-02-11 14:15:40,732 DEBUG TRAIN Batch 7/3100 loss 27.249561 loss_att 30.145496 loss_ctc 43.759399 loss_rnnt 23.763147 hw_loss 0.132359 lr 0.00063789 rank 7
2023-02-11 14:15:40,734 DEBUG TRAIN Batch 7/3100 loss 20.501122 loss_att 19.898804 loss_ctc 28.767179 loss_rnnt 15.411730 hw_loss 0.770196 lr 0.00063796 rank 6
2023-02-11 14:17:00,252 DEBUG TRAIN Batch 7/3200 loss 13.294499 loss_att 10.887873 loss_ctc 16.032492 loss_rnnt 8.822816 hw_loss 0.860239 lr 0.00063739 rank 3
2023-02-11 14:17:00,252 DEBUG TRAIN Batch 7/3200 loss 14.903565 loss_att 15.760782 loss_ctc 20.772116 loss_rnnt 10.462277 hw_loss 0.653882 lr 0.00063737 rank 7
2023-02-11 14:17:00,254 DEBUG TRAIN Batch 7/3200 loss 16.009239 loss_att 19.910675 loss_ctc 28.135954 loss_rnnt 11.893985 hw_loss 0.322139 lr 0.00063675 rank 2
2023-02-11 14:17:00,255 DEBUG TRAIN Batch 7/3200 loss 22.292736 loss_att 25.149494 loss_ctc 38.040871 loss_rnnt 18.038910 hw_loss 0.296761 lr 0.00063709 rank 5
2023-02-11 14:17:00,258 DEBUG TRAIN Batch 7/3200 loss 12.252493 loss_att 15.095966 loss_ctc 15.488493 loss_rnnt 9.092931 hw_loss 0.404888 lr 0.00063698 rank 0
2023-02-11 14:17:00,259 DEBUG TRAIN Batch 7/3200 loss 11.971255 loss_att 9.822393 loss_ctc 12.009688 loss_rnnt 8.524260 hw_loss 0.725933 lr 0.00063734 rank 4
2023-02-11 14:17:00,275 DEBUG TRAIN Batch 7/3200 loss 10.831566 loss_att 15.538794 loss_ctc 22.716656 loss_rnnt 5.468107 hw_loss 0.532000 lr 0.00063744 rank 6
2023-02-11 14:17:00,316 DEBUG TRAIN Batch 7/3200 loss 14.159335 loss_att 19.742012 loss_ctc 22.138672 loss_rnnt 10.572485 hw_loss 0.263701 lr 0.00063705 rank 1
2023-02-11 14:18:18,196 DEBUG TRAIN Batch 7/3300 loss 16.787405 loss_att 24.065245 loss_ctc 26.757008 loss_rnnt 12.688507 hw_loss 0.246384 lr 0.00063692 rank 6
2023-02-11 14:18:18,197 DEBUG TRAIN Batch 7/3300 loss 22.514225 loss_att 30.572247 loss_ctc 39.900906 loss_rnnt 15.947500 hw_loss 0.494418 lr 0.00063687 rank 3
2023-02-11 14:18:18,197 DEBUG TRAIN Batch 7/3300 loss 7.767039 loss_att 10.845089 loss_ctc 10.918513 loss_rnnt 3.434270 hw_loss 0.618181 lr 0.00063685 rank 7
2023-02-11 14:18:18,201 DEBUG TRAIN Batch 7/3300 loss 7.647907 loss_att 11.354035 loss_ctc 11.489500 loss_rnnt 5.562890 hw_loss 0.155921 lr 0.00063654 rank 1
2023-02-11 14:18:18,202 DEBUG TRAIN Batch 7/3300 loss 24.082788 loss_att 29.905773 loss_ctc 38.820316 loss_rnnt 17.815111 hw_loss 0.588389 lr 0.00063624 rank 2
2023-02-11 14:18:18,201 DEBUG TRAIN Batch 7/3300 loss 13.993145 loss_att 16.836964 loss_ctc 18.685339 loss_rnnt 11.009654 hw_loss 0.335456 lr 0.00063657 rank 5
2023-02-11 14:18:18,203 DEBUG TRAIN Batch 7/3300 loss 19.482143 loss_att 27.190754 loss_ctc 35.329445 loss_rnnt 12.301992 hw_loss 0.661023 lr 0.00063647 rank 0
2023-02-11 14:18:18,205 DEBUG TRAIN Batch 7/3300 loss 17.434553 loss_att 27.033392 loss_ctc 33.361614 loss_rnnt 11.063656 hw_loss 0.436410 lr 0.00063683 rank 4
2023-02-11 14:19:32,822 DEBUG TRAIN Batch 7/3400 loss 27.577326 loss_att 31.758850 loss_ctc 46.074364 loss_rnnt 24.158684 hw_loss 0.021762 lr 0.00063595 rank 0
2023-02-11 14:19:32,824 DEBUG TRAIN Batch 7/3400 loss 9.028632 loss_att 14.047988 loss_ctc 17.085461 loss_rnnt 6.818515 hw_loss 0.024750 lr 0.00063634 rank 7
2023-02-11 14:19:32,828 DEBUG TRAIN Batch 7/3400 loss 13.470717 loss_att 17.008179 loss_ctc 24.431351 loss_rnnt 9.568247 hw_loss 0.325043 lr 0.00063641 rank 6
2023-02-11 14:19:32,828 DEBUG TRAIN Batch 7/3400 loss 16.009848 loss_att 18.628136 loss_ctc 30.423359 loss_rnnt 13.038825 hw_loss 0.098543 lr 0.00063606 rank 5
2023-02-11 14:19:32,829 DEBUG TRAIN Batch 7/3400 loss 12.444925 loss_att 16.417286 loss_ctc 19.392313 loss_rnnt 8.342664 hw_loss 0.446526 lr 0.00063602 rank 1
2023-02-11 14:19:32,829 DEBUG TRAIN Batch 7/3400 loss 11.856666 loss_att 11.484523 loss_ctc 13.313463 loss_rnnt 8.706868 hw_loss 0.568122 lr 0.00063635 rank 3
2023-02-11 14:19:32,833 DEBUG TRAIN Batch 7/3400 loss 13.503150 loss_att 15.986502 loss_ctc 20.177183 loss_rnnt 9.542473 hw_loss 0.482650 lr 0.00063572 rank 2
2023-02-11 14:19:32,836 DEBUG TRAIN Batch 7/3400 loss 30.635712 loss_att 31.284927 loss_ctc 46.940273 loss_rnnt 26.121269 hw_loss 0.414498 lr 0.00063631 rank 4
2023-02-11 14:20:50,303 DEBUG TRAIN Batch 7/3500 loss 23.826187 loss_att 26.906614 loss_ctc 35.067909 loss_rnnt 19.634083 hw_loss 0.389461 lr 0.00063589 rank 6
2023-02-11 14:20:50,302 DEBUG TRAIN Batch 7/3500 loss 7.850090 loss_att 10.724211 loss_ctc 10.887087 loss_rnnt 4.940207 hw_loss 0.361899 lr 0.00063584 rank 3
2023-02-11 14:20:50,303 DEBUG TRAIN Batch 7/3500 loss 21.822098 loss_att 22.352150 loss_ctc 33.438717 loss_rnnt 17.194427 hw_loss 0.557396 lr 0.00063580 rank 4
2023-02-11 14:20:50,304 DEBUG TRAIN Batch 7/3500 loss 15.215382 loss_att 16.475775 loss_ctc 23.869263 loss_rnnt 12.756163 hw_loss 0.197492 lr 0.00063544 rank 0
2023-02-11 14:20:50,306 DEBUG TRAIN Batch 7/3500 loss 12.711278 loss_att 14.806530 loss_ctc 20.102032 loss_rnnt 9.365415 hw_loss 0.364009 lr 0.00063521 rank 2
2023-02-11 14:20:50,309 DEBUG TRAIN Batch 7/3500 loss 18.697050 loss_att 21.496792 loss_ctc 29.049208 loss_rnnt 16.016542 hw_loss 0.138801 lr 0.00063554 rank 5
2023-02-11 14:20:50,309 DEBUG TRAIN Batch 7/3500 loss 28.395256 loss_att 28.176487 loss_ctc 43.284641 loss_rnnt 24.755428 hw_loss 0.318437 lr 0.00063582 rank 7
2023-02-11 14:20:50,313 DEBUG TRAIN Batch 7/3500 loss 13.894702 loss_att 15.008852 loss_ctc 21.790503 loss_rnnt 10.304436 hw_loss 0.433999 lr 0.00063551 rank 1
2023-02-11 14:22:07,363 DEBUG TRAIN Batch 7/3600 loss 12.987059 loss_att 15.626907 loss_ctc 16.159594 loss_rnnt 8.623377 hw_loss 0.639883 lr 0.00063531 rank 7
2023-02-11 14:22:07,366 DEBUG TRAIN Batch 7/3600 loss 27.474987 loss_att 28.042524 loss_ctc 45.453255 loss_rnnt 22.363621 hw_loss 0.487641 lr 0.00063532 rank 3
2023-02-11 14:22:07,369 DEBUG TRAIN Batch 7/3600 loss 25.080322 loss_att 25.187544 loss_ctc 39.894165 loss_rnnt 21.176037 hw_loss 0.357687 lr 0.00063470 rank 2
2023-02-11 14:22:07,369 DEBUG TRAIN Batch 7/3600 loss 12.339962 loss_att 16.036186 loss_ctc 14.889668 loss_rnnt 9.539934 hw_loss 0.322654 lr 0.00063500 rank 1
2023-02-11 14:22:07,371 DEBUG TRAIN Batch 7/3600 loss 16.768114 loss_att 21.746590 loss_ctc 27.293106 loss_rnnt 13.245501 hw_loss 0.210672 lr 0.00063492 rank 0
2023-02-11 14:22:07,371 DEBUG TRAIN Batch 7/3600 loss 24.531406 loss_att 25.011953 loss_ctc 35.988625 loss_rnnt 20.631104 hw_loss 0.426856 lr 0.00063528 rank 4
2023-02-11 14:22:07,372 DEBUG TRAIN Batch 7/3600 loss 24.638342 loss_att 26.128349 loss_ctc 38.321457 loss_rnnt 19.919481 hw_loss 0.486833 lr 0.00063538 rank 6
2023-02-11 14:22:07,373 DEBUG TRAIN Batch 7/3600 loss 12.613784 loss_att 13.328204 loss_ctc 21.000406 loss_rnnt 7.809327 hw_loss 0.664379 lr 0.00063503 rank 5
2023-02-11 14:23:22,219 DEBUG TRAIN Batch 7/3700 loss 11.215338 loss_att 14.424063 loss_ctc 17.650080 loss_rnnt 7.638587 hw_loss 0.389445 lr 0.00063448 rank 1
2023-02-11 14:23:22,219 DEBUG TRAIN Batch 7/3700 loss 30.598351 loss_att 30.753527 loss_ctc 42.248051 loss_rnnt 26.167206 hw_loss 0.533778 lr 0.00063487 rank 6
2023-02-11 14:23:22,221 DEBUG TRAIN Batch 7/3700 loss 20.018806 loss_att 17.660114 loss_ctc 26.942682 loss_rnnt 14.109247 hw_loss 1.023396 lr 0.00063441 rank 0
2023-02-11 14:23:22,221 DEBUG TRAIN Batch 7/3700 loss 16.246607 loss_att 15.296953 loss_ctc 20.260330 loss_rnnt 13.825863 hw_loss 0.389158 lr 0.00063477 rank 4
2023-02-11 14:23:22,223 DEBUG TRAIN Batch 7/3700 loss 19.978546 loss_att 20.860941 loss_ctc 29.941380 loss_rnnt 15.062314 hw_loss 0.639633 lr 0.00063452 rank 5
2023-02-11 14:23:22,224 DEBUG TRAIN Batch 7/3700 loss 25.686892 loss_att 28.078838 loss_ctc 32.578728 loss_rnnt 21.042929 hw_loss 0.608749 lr 0.00063480 rank 7
2023-02-11 14:23:22,224 DEBUG TRAIN Batch 7/3700 loss 10.210015 loss_att 14.783093 loss_ctc 19.345158 loss_rnnt 6.571103 hw_loss 0.282427 lr 0.00063481 rank 3
2023-02-11 14:23:22,226 DEBUG TRAIN Batch 7/3700 loss 14.282016 loss_att 15.582449 loss_ctc 23.086697 loss_rnnt 11.004050 hw_loss 0.345735 lr 0.00063419 rank 2
2023-02-11 14:24:37,941 DEBUG TRAIN Batch 7/3800 loss 15.456494 loss_att 14.011131 loss_ctc 17.206654 loss_rnnt 11.520798 hw_loss 0.748390 lr 0.00063430 rank 3
2023-02-11 14:24:37,945 DEBUG TRAIN Batch 7/3800 loss 25.588741 loss_att 25.428497 loss_ctc 37.866119 loss_rnnt 22.264280 hw_loss 0.322412 lr 0.00063428 rank 7
2023-02-11 14:24:37,946 DEBUG TRAIN Batch 7/3800 loss 17.892229 loss_att 13.732941 loss_ctc 18.070972 loss_rnnt 13.368123 hw_loss 0.999774 lr 0.00063390 rank 0
2023-02-11 14:24:37,949 DEBUG TRAIN Batch 7/3800 loss 15.906967 loss_att 12.397921 loss_ctc 15.443652 loss_rnnt 10.488052 hw_loss 1.159219 lr 0.00063397 rank 1
2023-02-11 14:24:37,953 DEBUG TRAIN Batch 7/3800 loss 10.820036 loss_att 8.124826 loss_ctc 10.677672 loss_rnnt 5.746015 hw_loss 1.056008 lr 0.00063401 rank 5
2023-02-11 14:24:37,953 DEBUG TRAIN Batch 7/3800 loss 17.961380 loss_att 14.883951 loss_ctc 23.068739 loss_rnnt 12.264102 hw_loss 1.055959 lr 0.00063436 rank 6
2023-02-11 14:24:37,953 DEBUG TRAIN Batch 7/3800 loss 13.089833 loss_att 10.525141 loss_ctc 15.319791 loss_rnnt 8.874516 hw_loss 0.830799 lr 0.00063368 rank 2
2023-02-11 14:24:37,958 DEBUG TRAIN Batch 7/3800 loss 14.579405 loss_att 13.144789 loss_ctc 18.075462 loss_rnnt 10.773445 hw_loss 0.680014 lr 0.00063426 rank 4
2023-02-11 14:25:56,195 DEBUG TRAIN Batch 7/3900 loss 18.838732 loss_att 18.625851 loss_ctc 25.215675 loss_rnnt 15.512694 hw_loss 0.472192 lr 0.00063350 rank 5
2023-02-11 14:25:56,199 DEBUG TRAIN Batch 7/3900 loss 13.512380 loss_att 17.166664 loss_ctc 15.268633 loss_rnnt 11.432307 hw_loss 0.209072 lr 0.00063385 rank 6
2023-02-11 14:25:56,200 DEBUG TRAIN Batch 7/3900 loss 32.381687 loss_att 36.491188 loss_ctc 53.492855 loss_rnnt 26.691467 hw_loss 0.385030 lr 0.00063339 rank 0
2023-02-11 14:25:56,201 DEBUG TRAIN Batch 7/3900 loss 17.915337 loss_att 19.023354 loss_ctc 19.177456 loss_rnnt 15.478514 hw_loss 0.383801 lr 0.00063346 rank 1
2023-02-11 14:25:56,202 DEBUG TRAIN Batch 7/3900 loss 24.778944 loss_att 26.343220 loss_ctc 33.579800 loss_rnnt 22.326416 hw_loss 0.181167 lr 0.00063317 rank 2
2023-02-11 14:25:56,202 DEBUG TRAIN Batch 7/3900 loss 18.778978 loss_att 29.482887 loss_ctc 36.746941 loss_rnnt 12.641536 hw_loss 0.300175 lr 0.00063375 rank 4
2023-02-11 14:25:56,211 DEBUG TRAIN Batch 7/3900 loss 11.748451 loss_att 18.643978 loss_ctc 22.792770 loss_rnnt 8.067184 hw_loss 0.155547 lr 0.00063379 rank 3
2023-02-11 14:25:56,212 DEBUG TRAIN Batch 7/3900 loss 4.581023 loss_att 7.380621 loss_ctc 7.610437 loss_rnnt 2.633584 hw_loss 0.184424 lr 0.00063378 rank 7
2023-02-11 14:27:11,093 DEBUG TRAIN Batch 7/4000 loss 35.096546 loss_att 40.002174 loss_ctc 56.915569 loss_rnnt 30.249212 hw_loss 0.179439 lr 0.00063289 rank 0
2023-02-11 14:27:11,093 DEBUG TRAIN Batch 7/4000 loss 22.071182 loss_att 25.107300 loss_ctc 34.383549 loss_rnnt 18.386982 hw_loss 0.269124 lr 0.00063327 rank 7
2023-02-11 14:27:11,094 DEBUG TRAIN Batch 7/4000 loss 9.213181 loss_att 10.934607 loss_ctc 10.327507 loss_rnnt 7.390693 hw_loss 0.249305 lr 0.00063296 rank 1
2023-02-11 14:27:11,097 DEBUG TRAIN Batch 7/4000 loss 20.258600 loss_att 23.561584 loss_ctc 26.515430 loss_rnnt 15.923186 hw_loss 0.532607 lr 0.00063299 rank 5
2023-02-11 14:27:11,097 DEBUG TRAIN Batch 7/4000 loss 19.921143 loss_att 23.425909 loss_ctc 27.059944 loss_rnnt 15.886607 hw_loss 0.446577 lr 0.00063328 rank 3
2023-02-11 14:27:11,100 DEBUG TRAIN Batch 7/4000 loss 8.525908 loss_att 10.330074 loss_ctc 8.217284 loss_rnnt 4.921941 hw_loss 0.615803 lr 0.00063266 rank 2
2023-02-11 14:27:11,100 DEBUG TRAIN Batch 7/4000 loss 20.817568 loss_att 22.987089 loss_ctc 37.988766 loss_rnnt 16.813835 hw_loss 0.240063 lr 0.00063334 rank 6
2023-02-11 14:27:11,102 DEBUG TRAIN Batch 7/4000 loss 17.096296 loss_att 20.267469 loss_ctc 24.326132 loss_rnnt 12.900172 hw_loss 0.487108 lr 0.00063324 rank 4
2023-02-11 14:28:26,060 DEBUG TRAIN Batch 7/4100 loss 16.674053 loss_att 20.506905 loss_ctc 22.283474 loss_rnnt 12.992881 hw_loss 0.406253 lr 0.00063277 rank 3
2023-02-11 14:28:26,062 DEBUG TRAIN Batch 7/4100 loss 12.758691 loss_att 13.843369 loss_ctc 20.872463 loss_rnnt 8.843459 hw_loss 0.490586 lr 0.00063276 rank 7
2023-02-11 14:28:26,062 DEBUG TRAIN Batch 7/4100 loss 17.557226 loss_att 23.901630 loss_ctc 29.302999 loss_rnnt 13.807379 hw_loss 0.171537 lr 0.00063216 rank 2
2023-02-11 14:28:26,063 DEBUG TRAIN Batch 7/4100 loss 20.472807 loss_att 25.045805 loss_ctc 29.959797 loss_rnnt 16.795532 hw_loss 0.280827 lr 0.00063238 rank 0
2023-02-11 14:28:26,063 DEBUG TRAIN Batch 7/4100 loss 16.549114 loss_att 17.110931 loss_ctc 26.579971 loss_rnnt 13.066710 hw_loss 0.381111 lr 0.00063249 rank 5
2023-02-11 14:28:26,064 DEBUG TRAIN Batch 7/4100 loss 16.887880 loss_att 21.560019 loss_ctc 28.576462 loss_rnnt 12.738414 hw_loss 0.310605 lr 0.00063245 rank 1
2023-02-11 14:28:26,065 DEBUG TRAIN Batch 7/4100 loss 9.914919 loss_att 15.504527 loss_ctc 19.320728 loss_rnnt 6.934184 hw_loss 0.114132 lr 0.00063283 rank 6
2023-02-11 14:28:26,066 DEBUG TRAIN Batch 7/4100 loss 21.424091 loss_att 19.778275 loss_ctc 30.805439 loss_rnnt 17.947416 hw_loss 0.479061 lr 0.00063273 rank 4
2023-02-11 14:29:41,636 DEBUG TRAIN Batch 7/4200 loss 11.064446 loss_att 13.198586 loss_ctc 21.264568 loss_rnnt 7.439273 hw_loss 0.344687 lr 0.00063165 rank 2
2023-02-11 14:29:41,636 DEBUG TRAIN Batch 7/4200 loss 19.415176 loss_att 24.804111 loss_ctc 33.928268 loss_rnnt 15.830471 hw_loss 0.107220 lr 0.00063195 rank 1
2023-02-11 14:29:41,637 DEBUG TRAIN Batch 7/4200 loss 8.727776 loss_att 11.273751 loss_ctc 15.071733 loss_rnnt 6.201804 hw_loss 0.219546 lr 0.00063225 rank 7
2023-02-11 14:29:41,637 DEBUG TRAIN Batch 7/4200 loss 13.585756 loss_att 22.678949 loss_ctc 27.490986 loss_rnnt 8.896546 hw_loss 0.190601 lr 0.00063232 rank 6
2023-02-11 14:29:41,638 DEBUG TRAIN Batch 7/4200 loss 25.123501 loss_att 27.798971 loss_ctc 32.939453 loss_rnnt 19.530519 hw_loss 0.752955 lr 0.00063198 rank 5
2023-02-11 14:29:41,639 DEBUG TRAIN Batch 7/4200 loss 19.275002 loss_att 20.143824 loss_ctc 28.247070 loss_rnnt 15.008491 hw_loss 0.543088 lr 0.00063227 rank 3
2023-02-11 14:29:41,641 DEBUG TRAIN Batch 7/4200 loss 19.280350 loss_att 24.821043 loss_ctc 32.665928 loss_rnnt 14.461531 hw_loss 0.361113 lr 0.00063187 rank 0
2023-02-11 14:29:41,643 DEBUG TRAIN Batch 7/4200 loss 14.215049 loss_att 17.758835 loss_ctc 17.365725 loss_rnnt 12.379905 hw_loss 0.132431 lr 0.00063223 rank 4
2023-02-11 14:30:59,465 DEBUG TRAIN Batch 7/4300 loss 25.116011 loss_att 29.101562 loss_ctc 44.932480 loss_rnnt 19.565439 hw_loss 0.395862 lr 0.00063176 rank 3
2023-02-11 14:30:59,471 DEBUG TRAIN Batch 7/4300 loss 16.507748 loss_att 19.746342 loss_ctc 30.271778 loss_rnnt 12.015571 hw_loss 0.376735 lr 0.00063175 rank 7
2023-02-11 14:30:59,474 DEBUG TRAIN Batch 7/4300 loss 24.020102 loss_att 27.289757 loss_ctc 32.890816 loss_rnnt 19.688095 hw_loss 0.467871 lr 0.00063137 rank 0
2023-02-11 14:30:59,477 DEBUG TRAIN Batch 7/4300 loss 21.852089 loss_att 21.470009 loss_ctc 33.783527 loss_rnnt 17.809353 hw_loss 0.474056 lr 0.00063182 rank 6
2023-02-11 14:30:59,479 DEBUG TRAIN Batch 7/4300 loss 12.944777 loss_att 15.747399 loss_ctc 21.301790 loss_rnnt 9.171644 hw_loss 0.393439 lr 0.00063148 rank 5
2023-02-11 14:30:59,480 DEBUG TRAIN Batch 7/4300 loss 23.508331 loss_att 25.992229 loss_ctc 33.453342 loss_rnnt 19.538069 hw_loss 0.402653 lr 0.00063115 rank 2
2023-02-11 14:30:59,494 DEBUG TRAIN Batch 7/4300 loss 21.947609 loss_att 20.746140 loss_ctc 29.718794 loss_rnnt 17.639027 hw_loss 0.658635 lr 0.00063172 rank 4
2023-02-11 14:30:59,504 DEBUG TRAIN Batch 7/4300 loss 16.284019 loss_att 19.377567 loss_ctc 24.326515 loss_rnnt 12.555064 hw_loss 0.382109 lr 0.00063144 rank 1
2023-02-11 14:32:16,606 DEBUG TRAIN Batch 7/4400 loss 12.476349 loss_att 14.922367 loss_ctc 20.585945 loss_rnnt 9.934707 hw_loss 0.182092 lr 0.00063124 rank 7
2023-02-11 14:32:16,608 DEBUG TRAIN Batch 7/4400 loss 13.132044 loss_att 11.582948 loss_ctc 13.089871 loss_rnnt 8.001331 hw_loss 1.021154 lr 0.00063132 rank 6
2023-02-11 14:32:16,611 DEBUG TRAIN Batch 7/4400 loss 39.102501 loss_att 34.538666 loss_ctc 57.072296 loss_rnnt 35.426613 hw_loss 0.411127 lr 0.00063126 rank 3
2023-02-11 14:32:16,612 DEBUG TRAIN Batch 7/4400 loss 13.050675 loss_att 15.446983 loss_ctc 20.798822 loss_rnnt 9.277701 hw_loss 0.423868 lr 0.00063065 rank 2
2023-02-11 14:32:16,612 DEBUG TRAIN Batch 7/4400 loss 6.722112 loss_att 11.283123 loss_ctc 12.545343 loss_rnnt 4.294840 hw_loss 0.138495 lr 0.00063087 rank 0
2023-02-11 14:32:16,614 DEBUG TRAIN Batch 7/4400 loss 18.141228 loss_att 16.220581 loss_ctc 28.414310 loss_rnnt 13.688136 hw_loss 0.650152 lr 0.00063094 rank 1
2023-02-11 14:32:16,615 DEBUG TRAIN Batch 7/4400 loss 19.508230 loss_att 19.795492 loss_ctc 24.740248 loss_rnnt 15.350782 hw_loss 0.637949 lr 0.00063097 rank 5
2023-02-11 14:32:16,617 DEBUG TRAIN Batch 7/4400 loss 28.248272 loss_att 27.104532 loss_ctc 41.872608 loss_rnnt 24.142202 hw_loss 0.472170 lr 0.00063122 rank 4
2023-02-11 14:33:32,870 DEBUG TRAIN Batch 7/4500 loss 14.888253 loss_att 10.600322 loss_ctc 13.688913 loss_rnnt 10.370621 hw_loss 1.037837 lr 0.00063074 rank 7
2023-02-11 14:33:32,870 DEBUG TRAIN Batch 7/4500 loss 13.039043 loss_att 19.164848 loss_ctc 23.144344 loss_rnnt 8.684599 hw_loss 0.334108 lr 0.00063076 rank 3
2023-02-11 14:33:32,871 DEBUG TRAIN Batch 7/4500 loss 21.590717 loss_att 18.851463 loss_ctc 26.295715 loss_rnnt 17.424770 hw_loss 0.766212 lr 0.00063047 rank 5
2023-02-11 14:33:32,872 DEBUG TRAIN Batch 7/4500 loss 9.621535 loss_att 11.481548 loss_ctc 12.939101 loss_rnnt 7.266635 hw_loss 0.288854 lr 0.00063037 rank 0
2023-02-11 14:33:32,872 DEBUG TRAIN Batch 7/4500 loss 18.980898 loss_att 19.706108 loss_ctc 29.194525 loss_rnnt 16.037035 hw_loss 0.269438 lr 0.00063015 rank 2
2023-02-11 14:33:32,873 DEBUG TRAIN Batch 7/4500 loss 22.746859 loss_att 28.775290 loss_ctc 37.381405 loss_rnnt 18.370394 hw_loss 0.228657 lr 0.00063081 rank 6
2023-02-11 14:33:32,878 DEBUG TRAIN Batch 7/4500 loss 13.903642 loss_att 10.311123 loss_ctc 13.469617 loss_rnnt 8.119664 hw_loss 1.230066 lr 0.00063072 rank 4
2023-02-11 14:33:32,878 DEBUG TRAIN Batch 7/4500 loss 19.143251 loss_att 25.136007 loss_ctc 27.216284 loss_rnnt 15.076011 hw_loss 0.336054 lr 0.00063044 rank 1
2023-02-11 14:34:50,982 DEBUG TRAIN Batch 7/4600 loss 26.442282 loss_att 32.724648 loss_ctc 44.460655 loss_rnnt 20.720848 hw_loss 0.386721 lr 0.00063026 rank 3
2023-02-11 14:34:50,987 DEBUG TRAIN Batch 7/4600 loss 12.703241 loss_att 15.661639 loss_ctc 20.428028 loss_rnnt 7.949582 hw_loss 0.587251 lr 0.00062965 rank 2
2023-02-11 14:34:50,989 DEBUG TRAIN Batch 7/4600 loss 8.613020 loss_att 12.721878 loss_ctc 13.810659 loss_rnnt 5.440725 hw_loss 0.310782 lr 0.00063024 rank 7
2023-02-11 14:34:50,993 DEBUG TRAIN Batch 7/4600 loss 14.294467 loss_att 19.707325 loss_ctc 23.433064 loss_rnnt 9.926372 hw_loss 0.387571 lr 0.00063022 rank 4
2023-02-11 14:34:50,996 DEBUG TRAIN Batch 7/4600 loss 8.291926 loss_att 10.238669 loss_ctc 10.676994 loss_rnnt 3.747609 hw_loss 0.719430 lr 0.00062987 rank 0
2023-02-11 14:34:50,997 DEBUG TRAIN Batch 7/4600 loss 6.436396 loss_att 8.265539 loss_ctc 9.471251 loss_rnnt 5.231776 hw_loss 0.081402 lr 0.00063031 rank 6
2023-02-11 14:34:50,999 DEBUG TRAIN Batch 7/4600 loss 22.089458 loss_att 22.531651 loss_ctc 28.327599 loss_rnnt 17.082119 hw_loss 0.766340 lr 0.00062997 rank 5
2023-02-11 14:34:51,039 DEBUG TRAIN Batch 7/4600 loss 14.916306 loss_att 16.947552 loss_ctc 19.046921 loss_rnnt 10.127016 hw_loss 0.718555 lr 0.00062994 rank 1
2023-02-11 14:36:07,953 DEBUG TRAIN Batch 7/4700 loss 16.408012 loss_att 20.083620 loss_ctc 22.152225 loss_rnnt 14.264232 hw_loss 0.120518 lr 0.00062937 rank 0
2023-02-11 14:36:07,955 DEBUG TRAIN Batch 7/4700 loss 11.966547 loss_att 12.797965 loss_ctc 14.625144 loss_rnnt 8.657749 hw_loss 0.522756 lr 0.00062915 rank 2
2023-02-11 14:36:07,958 DEBUG TRAIN Batch 7/4700 loss 17.921421 loss_att 23.570618 loss_ctc 31.026831 loss_rnnt 14.289734 hw_loss 0.141461 lr 0.00062976 rank 3
2023-02-11 14:36:07,958 DEBUG TRAIN Batch 7/4700 loss 11.548429 loss_att 15.121346 loss_ctc 26.517395 loss_rnnt 6.087369 hw_loss 0.515740 lr 0.00062972 rank 4
2023-02-11 14:36:07,959 DEBUG TRAIN Batch 7/4700 loss 7.723035 loss_att 9.645386 loss_ctc 11.105841 loss_rnnt 5.360241 hw_loss 0.286365 lr 0.00062944 rank 1
2023-02-11 14:36:07,962 DEBUG TRAIN Batch 7/4700 loss 15.203512 loss_att 18.708126 loss_ctc 21.572525 loss_rnnt 10.185944 hw_loss 0.650146 lr 0.00062974 rank 7
2023-02-11 14:36:07,962 DEBUG TRAIN Batch 7/4700 loss 20.261789 loss_att 19.039375 loss_ctc 26.259024 loss_rnnt 18.319511 hw_loss 0.260086 lr 0.00062981 rank 6
2023-02-11 14:36:07,966 DEBUG TRAIN Batch 7/4700 loss 20.434278 loss_att 22.682629 loss_ctc 25.343784 loss_rnnt 17.947090 hw_loss 0.259297 lr 0.00062947 rank 5
2023-02-11 14:37:22,133 DEBUG TRAIN Batch 7/4800 loss 16.695303 loss_att 19.046320 loss_ctc 27.065435 loss_rnnt 11.661354 hw_loss 0.596449 lr 0.00062887 rank 0
2023-02-11 14:37:22,141 DEBUG TRAIN Batch 7/4800 loss 13.089863 loss_att 14.204085 loss_ctc 18.345337 loss_rnnt 9.786230 hw_loss 0.446261 lr 0.00062924 rank 7
2023-02-11 14:37:22,142 DEBUG TRAIN Batch 7/4800 loss 18.308689 loss_att 20.298328 loss_ctc 27.812103 loss_rnnt 14.729717 hw_loss 0.358860 lr 0.00062926 rank 3
2023-02-11 14:37:22,143 DEBUG TRAIN Batch 7/4800 loss 10.718258 loss_att 12.595781 loss_ctc 16.427082 loss_rnnt 6.820070 hw_loss 0.517783 lr 0.00062865 rank 2
2023-02-11 14:37:22,143 DEBUG TRAIN Batch 7/4800 loss 16.661266 loss_att 17.935179 loss_ctc 26.057384 loss_rnnt 12.826413 hw_loss 0.436360 lr 0.00062897 rank 5
2023-02-11 14:37:22,146 DEBUG TRAIN Batch 7/4800 loss 17.252003 loss_att 18.405083 loss_ctc 26.369839 loss_rnnt 13.538604 hw_loss 0.425076 lr 0.00062931 rank 6
2023-02-11 14:37:22,168 DEBUG TRAIN Batch 7/4800 loss 10.627671 loss_att 12.969120 loss_ctc 18.836403 loss_rnnt 7.690701 hw_loss 0.257659 lr 0.00062894 rank 1
2023-02-11 14:37:22,179 DEBUG TRAIN Batch 7/4800 loss 19.830626 loss_att 19.156818 loss_ctc 29.263714 loss_rnnt 15.358079 hw_loss 0.628043 lr 0.00062922 rank 4
2023-02-11 14:38:38,106 DEBUG TRAIN Batch 7/4900 loss 19.872629 loss_att 21.425150 loss_ctc 25.125181 loss_rnnt 14.714690 hw_loss 0.777580 lr 0.00062837 rank 0
2023-02-11 14:38:38,106 DEBUG TRAIN Batch 7/4900 loss 20.171099 loss_att 21.647171 loss_ctc 24.407906 loss_rnnt 17.046686 hw_loss 0.424554 lr 0.00062881 rank 6
2023-02-11 14:38:38,108 DEBUG TRAIN Batch 7/4900 loss 15.709533 loss_att 15.776923 loss_ctc 29.095791 loss_rnnt 10.712212 hw_loss 0.599814 lr 0.00062815 rank 2
2023-02-11 14:38:38,111 DEBUG TRAIN Batch 7/4900 loss 10.936033 loss_att 14.965874 loss_ctc 17.076691 loss_rnnt 8.580672 hw_loss 0.136995 lr 0.00062848 rank 5
2023-02-11 14:38:38,113 DEBUG TRAIN Batch 7/4900 loss 15.311982 loss_att 22.559551 loss_ctc 31.171942 loss_rnnt 10.383743 hw_loss 0.255762 lr 0.00062874 rank 7
2023-02-11 14:38:38,114 DEBUG TRAIN Batch 7/4900 loss 16.029865 loss_att 18.732922 loss_ctc 24.945358 loss_rnnt 13.061234 hw_loss 0.232366 lr 0.00062872 rank 4
2023-02-11 14:38:38,114 DEBUG TRAIN Batch 7/4900 loss 20.911253 loss_att 23.287346 loss_ctc 29.899109 loss_rnnt 16.087837 hw_loss 0.590590 lr 0.00062876 rank 3
2023-02-11 14:38:38,155 DEBUG TRAIN Batch 7/4900 loss 19.937740 loss_att 23.500673 loss_ctc 32.911449 loss_rnnt 15.493319 hw_loss 0.375376 lr 0.00062844 rank 1
2023-02-11 14:39:57,179 DEBUG TRAIN Batch 7/5000 loss 14.485315 loss_att 16.931068 loss_ctc 19.906986 loss_rnnt 10.451600 hw_loss 0.529064 lr 0.00062766 rank 2
2023-02-11 14:39:57,179 DEBUG TRAIN Batch 7/5000 loss 20.882265 loss_att 19.963364 loss_ctc 28.275822 loss_rnnt 17.336077 hw_loss 0.514530 lr 0.00062788 rank 0
2023-02-11 14:39:57,180 DEBUG TRAIN Batch 7/5000 loss 21.675762 loss_att 21.430593 loss_ctc 29.541546 loss_rnnt 17.635300 hw_loss 0.570136 lr 0.00062832 rank 6
2023-02-11 14:39:57,182 DEBUG TRAIN Batch 7/5000 loss 11.971886 loss_att 13.148441 loss_ctc 20.150650 loss_rnnt 8.565208 hw_loss 0.390162 lr 0.00062825 rank 7
2023-02-11 14:39:57,182 DEBUG TRAIN Batch 7/5000 loss 19.653685 loss_att 20.007191 loss_ctc 29.422047 loss_rnnt 14.221581 hw_loss 0.761054 lr 0.00062826 rank 3
2023-02-11 14:39:57,183 DEBUG TRAIN Batch 7/5000 loss 14.179358 loss_att 17.121105 loss_ctc 23.663330 loss_rnnt 10.283831 hw_loss 0.382997 lr 0.00062798 rank 5
2023-02-11 14:39:57,186 DEBUG TRAIN Batch 7/5000 loss 17.302967 loss_att 15.196919 loss_ctc 28.394049 loss_rnnt 11.615405 hw_loss 0.868117 lr 0.00062795 rank 1
2023-02-11 14:39:57,233 DEBUG TRAIN Batch 7/5000 loss 26.152691 loss_att 28.200424 loss_ctc 37.101479 loss_rnnt 21.849747 hw_loss 0.456292 lr 0.00062822 rank 4
2023-02-11 14:41:13,301 DEBUG TRAIN Batch 7/5100 loss 29.182652 loss_att 30.368286 loss_ctc 41.197735 loss_rnnt 25.157288 hw_loss 0.409917 lr 0.00062738 rank 0
2023-02-11 14:41:13,303 DEBUG TRAIN Batch 7/5100 loss 9.865121 loss_att 16.771654 loss_ctc 19.855175 loss_rnnt 6.635278 hw_loss 0.096849 lr 0.00062782 rank 6
2023-02-11 14:41:13,304 DEBUG TRAIN Batch 7/5100 loss 20.808311 loss_att 19.932472 loss_ctc 24.979855 loss_rnnt 17.198929 hw_loss 0.605314 lr 0.00062773 rank 4
2023-02-11 14:41:13,305 DEBUG TRAIN Batch 7/5100 loss 18.172857 loss_att 15.730898 loss_ctc 23.537327 loss_rnnt 12.294060 hw_loss 1.059736 lr 0.00062775 rank 7
2023-02-11 14:41:13,307 DEBUG TRAIN Batch 7/5100 loss 20.287106 loss_att 22.315153 loss_ctc 29.741943 loss_rnnt 15.987346 hw_loss 0.493782 lr 0.00062777 rank 3
2023-02-11 14:41:13,307 DEBUG TRAIN Batch 7/5100 loss 17.066799 loss_att 18.280106 loss_ctc 22.966644 loss_rnnt 14.027704 hw_loss 0.376835 lr 0.00062716 rank 2
2023-02-11 14:41:13,309 DEBUG TRAIN Batch 7/5100 loss 19.414543 loss_att 18.953766 loss_ctc 26.644978 loss_rnnt 15.931199 hw_loss 0.489645 lr 0.00062749 rank 5
2023-02-11 14:41:13,309 DEBUG TRAIN Batch 7/5100 loss 14.537971 loss_att 9.653486 loss_ctc 12.691149 loss_rnnt 7.362995 hw_loss 1.574647 lr 0.00062745 rank 1
2023-02-11 14:42:27,909 DEBUG TRAIN Batch 7/5200 loss 20.489117 loss_att 24.456980 loss_ctc 30.062710 loss_rnnt 15.786568 hw_loss 0.493593 lr 0.00062689 rank 0
2023-02-11 14:42:27,914 DEBUG TRAIN Batch 7/5200 loss 11.096175 loss_att 13.589496 loss_ctc 13.689095 loss_rnnt 8.367308 hw_loss 0.353340 lr 0.00062733 rank 6
2023-02-11 14:42:27,915 DEBUG TRAIN Batch 7/5200 loss 19.604544 loss_att 23.116053 loss_ctc 29.810619 loss_rnnt 13.171036 hw_loss 0.819449 lr 0.00062727 rank 3
2023-02-11 14:42:27,916 DEBUG TRAIN Batch 7/5200 loss 25.887974 loss_att 27.834616 loss_ctc 37.258881 loss_rnnt 21.457891 hw_loss 0.473369 lr 0.00062667 rank 2
2023-02-11 14:42:27,917 DEBUG TRAIN Batch 7/5200 loss 15.377153 loss_att 21.767391 loss_ctc 29.854391 loss_rnnt 11.178663 hw_loss 0.185652 lr 0.00062726 rank 7
2023-02-11 14:42:27,917 DEBUG TRAIN Batch 7/5200 loss 17.933334 loss_att 23.804396 loss_ctc 28.735296 loss_rnnt 13.182727 hw_loss 0.400525 lr 0.00062699 rank 5
2023-02-11 14:42:27,918 DEBUG TRAIN Batch 7/5200 loss 14.851507 loss_att 18.415384 loss_ctc 30.622913 loss_rnnt 11.393626 hw_loss 0.120422 lr 0.00062723 rank 4
2023-02-11 14:42:27,971 DEBUG TRAIN Batch 7/5200 loss 11.116096 loss_att 16.727182 loss_ctc 18.807339 loss_rnnt 6.620943 hw_loss 0.440144 lr 0.00062696 rank 1
2023-02-11 14:43:46,445 DEBUG TRAIN Batch 7/5300 loss 15.608191 loss_att 20.224436 loss_ctc 25.572485 loss_rnnt 11.243877 hw_loss 0.396092 lr 0.00062678 rank 3
2023-02-11 14:43:46,450 DEBUG TRAIN Batch 7/5300 loss 9.775096 loss_att 12.586530 loss_ctc 15.545355 loss_rnnt 5.877677 hw_loss 0.481081 lr 0.00062640 rank 0
2023-02-11 14:43:46,454 DEBUG TRAIN Batch 7/5300 loss 14.602112 loss_att 21.383642 loss_ctc 22.829985 loss_rnnt 11.982206 hw_loss 0.031228 lr 0.00062677 rank 7
2023-02-11 14:43:46,457 DEBUG TRAIN Batch 7/5300 loss 18.229139 loss_att 18.405561 loss_ctc 21.519453 loss_rnnt 14.200987 hw_loss 0.666405 lr 0.00062647 rank 1
2023-02-11 14:43:46,460 DEBUG TRAIN Batch 7/5300 loss 8.877624 loss_att 13.808684 loss_ctc 13.562453 loss_rnnt 5.993608 hw_loss 0.238717 lr 0.00062650 rank 5
2023-02-11 14:43:46,469 DEBUG TRAIN Batch 7/5300 loss 13.003694 loss_att 14.828718 loss_ctc 19.264772 loss_rnnt 9.105198 hw_loss 0.506002 lr 0.00062674 rank 4
2023-02-11 14:43:46,482 DEBUG TRAIN Batch 7/5300 loss 15.791391 loss_att 13.304396 loss_ctc 27.204479 loss_rnnt 12.517876 hw_loss 0.421719 lr 0.00062618 rank 2
2023-02-11 14:43:46,492 DEBUG TRAIN Batch 7/5300 loss 13.920946 loss_att 16.626331 loss_ctc 19.759945 loss_rnnt 9.801225 hw_loss 0.525021 lr 0.00062683 rank 6
2023-02-11 14:45:03,438 DEBUG TRAIN Batch 7/5400 loss 23.897968 loss_att 22.499111 loss_ctc 36.277016 loss_rnnt 19.879526 hw_loss 0.496439 lr 0.00062591 rank 0
2023-02-11 14:45:03,441 DEBUG TRAIN Batch 7/5400 loss 21.892767 loss_att 19.746332 loss_ctc 29.901045 loss_rnnt 18.700424 hw_loss 0.478848 lr 0.00062597 rank 1
2023-02-11 14:45:03,443 DEBUG TRAIN Batch 7/5400 loss 10.339454 loss_att 18.134401 loss_ctc 16.265770 loss_rnnt 5.856542 hw_loss 0.400078 lr 0.00062627 rank 7
2023-02-11 14:45:03,444 DEBUG TRAIN Batch 7/5400 loss 22.513844 loss_att 26.884001 loss_ctc 33.279037 loss_rnnt 18.430437 hw_loss 0.332628 lr 0.00062569 rank 2
2023-02-11 14:45:03,445 DEBUG TRAIN Batch 7/5400 loss 10.581463 loss_att 13.851690 loss_ctc 17.033028 loss_rnnt 6.750701 hw_loss 0.434345 lr 0.00062634 rank 6
2023-02-11 14:45:03,446 DEBUG TRAIN Batch 7/5400 loss 10.079288 loss_att 15.226864 loss_ctc 12.920050 loss_rnnt 7.783303 hw_loss 0.166444 lr 0.00062629 rank 3
2023-02-11 14:45:03,449 DEBUG TRAIN Batch 7/5400 loss 35.130032 loss_att 37.893894 loss_ctc 60.618736 loss_rnnt 27.727013 hw_loss 0.647203 lr 0.00062601 rank 5
2023-02-11 14:45:03,459 DEBUG TRAIN Batch 7/5400 loss 13.575293 loss_att 14.876640 loss_ctc 19.266378 loss_rnnt 10.935122 hw_loss 0.303954 lr 0.00062625 rank 4
2023-02-11 14:46:18,191 DEBUG TRAIN Batch 7/5500 loss 35.587112 loss_att 36.708988 loss_ctc 48.169258 loss_rnnt 31.414549 hw_loss 0.425732 lr 0.00062585 rank 6
2023-02-11 14:46:18,193 DEBUG TRAIN Batch 7/5500 loss 19.059443 loss_att 23.751490 loss_ctc 30.706308 loss_rnnt 13.916302 hw_loss 0.497215 lr 0.00062580 rank 3
2023-02-11 14:46:18,196 DEBUG TRAIN Batch 7/5500 loss 21.297501 loss_att 22.866257 loss_ctc 38.778084 loss_rnnt 15.484021 hw_loss 0.594184 lr 0.00062578 rank 7
2023-02-11 14:46:18,196 DEBUG TRAIN Batch 7/5500 loss 10.522402 loss_att 12.472634 loss_ctc 16.059689 loss_rnnt 6.606013 hw_loss 0.522757 lr 0.00062520 rank 2
2023-02-11 14:46:18,198 DEBUG TRAIN Batch 7/5500 loss 18.183392 loss_att 21.509892 loss_ctc 30.469292 loss_rnnt 14.822573 hw_loss 0.198262 lr 0.00062552 rank 5
2023-02-11 14:46:18,199 DEBUG TRAIN Batch 7/5500 loss 14.182766 loss_att 16.349085 loss_ctc 21.341579 loss_rnnt 8.302660 hw_loss 0.842313 lr 0.00062548 rank 1
2023-02-11 14:46:18,198 DEBUG TRAIN Batch 7/5500 loss 15.153997 loss_att 20.110802 loss_ctc 27.713013 loss_rnnt 10.159556 hw_loss 0.436602 lr 0.00062542 rank 0
2023-02-11 14:46:18,205 DEBUG TRAIN Batch 7/5500 loss 9.360259 loss_att 10.846567 loss_ctc 13.523156 loss_rnnt 5.974490 hw_loss 0.475023 lr 0.00062576 rank 4
2023-02-11 14:47:34,143 DEBUG TRAIN Batch 7/5600 loss 19.190714 loss_att 20.148367 loss_ctc 30.425240 loss_rnnt 16.204779 hw_loss 0.243088 lr 0.00062493 rank 0
2023-02-11 14:47:34,144 DEBUG TRAIN Batch 7/5600 loss 13.717819 loss_att 16.467426 loss_ctc 26.035309 loss_rnnt 11.072882 hw_loss 0.084878 lr 0.00062500 rank 1
2023-02-11 14:47:34,144 DEBUG TRAIN Batch 7/5600 loss 17.136448 loss_att 19.723711 loss_ctc 25.293152 loss_rnnt 13.455029 hw_loss 0.389326 lr 0.00062531 rank 3
2023-02-11 14:47:34,147 DEBUG TRAIN Batch 7/5600 loss 12.499701 loss_att 16.149784 loss_ctc 20.985786 loss_rnnt 9.291465 hw_loss 0.252514 lr 0.00062503 rank 5
2023-02-11 14:47:34,150 DEBUG TRAIN Batch 7/5600 loss 18.943293 loss_att 20.072674 loss_ctc 25.082485 loss_rnnt 17.061958 hw_loss 0.156919 lr 0.00062529 rank 7
2023-02-11 14:47:34,151 DEBUG TRAIN Batch 7/5600 loss 15.956595 loss_att 14.814219 loss_ctc 20.900993 loss_rnnt 12.630551 hw_loss 0.542862 lr 0.00062536 rank 6
2023-02-11 14:47:34,152 DEBUG TRAIN Batch 7/5600 loss 20.205421 loss_att 24.889839 loss_ctc 34.235535 loss_rnnt 15.358457 hw_loss 0.382387 lr 0.00062527 rank 4
2023-02-11 14:47:34,193 DEBUG TRAIN Batch 7/5600 loss 14.431622 loss_att 18.806355 loss_ctc 25.966137 loss_rnnt 9.246490 hw_loss 0.519797 lr 0.00062471 rank 2
2023-02-11 14:48:53,190 DEBUG TRAIN Batch 7/5700 loss 16.767159 loss_att 18.534046 loss_ctc 27.323025 loss_rnnt 11.262840 hw_loss 0.701905 lr 0.00062480 rank 7
2023-02-11 14:48:53,192 DEBUG TRAIN Batch 7/5700 loss 24.971598 loss_att 25.543377 loss_ctc 35.804951 loss_rnnt 21.926916 hw_loss 0.278602 lr 0.00062482 rank 3
2023-02-11 14:48:53,192 DEBUG TRAIN Batch 7/5700 loss 20.957813 loss_att 21.598925 loss_ctc 28.859308 loss_rnnt 16.880503 hw_loss 0.542916 lr 0.00062478 rank 4
2023-02-11 14:48:53,195 DEBUG TRAIN Batch 7/5700 loss 17.635824 loss_att 15.361910 loss_ctc 22.343082 loss_rnnt 13.665045 hw_loss 0.712111 lr 0.00062451 rank 1
2023-02-11 14:48:53,195 DEBUG TRAIN Batch 7/5700 loss 18.128048 loss_att 14.207764 loss_ctc 21.261856 loss_rnnt 13.873320 hw_loss 0.866427 lr 0.00062444 rank 0
2023-02-11 14:48:53,195 DEBUG TRAIN Batch 7/5700 loss 16.785467 loss_att 16.033369 loss_ctc 22.774895 loss_rnnt 11.196001 hw_loss 0.926493 lr 0.00062454 rank 5
2023-02-11 14:48:53,198 DEBUG TRAIN Batch 7/5700 loss 24.388449 loss_att 30.199322 loss_ctc 36.605274 loss_rnnt 19.209784 hw_loss 0.447671 lr 0.00062487 rank 6
2023-02-11 14:48:53,243 DEBUG TRAIN Batch 7/5700 loss 11.250702 loss_att 12.412925 loss_ctc 14.876255 loss_rnnt 9.276274 hw_loss 0.235983 lr 0.00062423 rank 2
2023-02-11 14:50:09,589 DEBUG TRAIN Batch 7/5800 loss 18.154980 loss_att 24.457565 loss_ctc 33.168022 loss_rnnt 14.680447 hw_loss 0.039802 lr 0.00062395 rank 0
2023-02-11 14:50:09,591 DEBUG TRAIN Batch 7/5800 loss 13.322613 loss_att 17.460442 loss_ctc 17.538055 loss_rnnt 10.398987 hw_loss 0.287625 lr 0.00062429 rank 4
2023-02-11 14:50:09,593 DEBUG TRAIN Batch 7/5800 loss 5.806419 loss_att 9.610637 loss_ctc 15.045544 loss_rnnt 2.057149 hw_loss 0.329352 lr 0.00062432 rank 7
2023-02-11 14:50:09,594 DEBUG TRAIN Batch 7/5800 loss 19.753725 loss_att 19.492193 loss_ctc 23.994045 loss_rnnt 18.166578 hw_loss 0.201390 lr 0.00062402 rank 1
2023-02-11 14:50:09,595 DEBUG TRAIN Batch 7/5800 loss 17.784325 loss_att 12.905252 loss_ctc 18.563213 loss_rnnt 12.953232 hw_loss 1.069323 lr 0.00062433 rank 3
2023-02-11 14:50:09,599 DEBUG TRAIN Batch 7/5800 loss 16.994581 loss_att 19.661842 loss_ctc 27.915840 loss_rnnt 13.462502 hw_loss 0.289211 lr 0.00062439 rank 6
2023-02-11 14:50:09,599 DEBUG TRAIN Batch 7/5800 loss 36.121990 loss_att 41.636932 loss_ctc 57.057053 loss_rnnt 29.313686 hw_loss 0.546371 lr 0.00062405 rank 5
2023-02-11 14:50:09,645 DEBUG TRAIN Batch 7/5800 loss 24.588522 loss_att 22.978172 loss_ctc 26.416937 loss_rnnt 20.949842 hw_loss 0.696931 lr 0.00062374 rank 2
2023-02-11 14:51:24,991 DEBUG TRAIN Batch 7/5900 loss 18.961636 loss_att 19.210499 loss_ctc 25.144156 loss_rnnt 14.511287 hw_loss 0.670545 lr 0.00062354 rank 1
2023-02-11 14:51:24,993 DEBUG TRAIN Batch 7/5900 loss 9.671908 loss_att 13.107042 loss_ctc 13.854510 loss_rnnt 7.333452 hw_loss 0.205078 lr 0.00062347 rank 0
2023-02-11 14:51:24,995 DEBUG TRAIN Batch 7/5900 loss 16.484686 loss_att 22.578228 loss_ctc 25.154852 loss_rnnt 11.786758 hw_loss 0.435599 lr 0.00062381 rank 4
2023-02-11 14:51:24,995 DEBUG TRAIN Batch 7/5900 loss 24.122688 loss_att 30.036737 loss_ctc 41.665905 loss_rnnt 20.452768 hw_loss 0.027752 lr 0.00062385 rank 3
2023-02-11 14:51:24,995 DEBUG TRAIN Batch 7/5900 loss 19.533741 loss_att 21.886002 loss_ctc 35.068436 loss_rnnt 14.106441 hw_loss 0.541042 lr 0.00062325 rank 2
2023-02-11 14:51:24,996 DEBUG TRAIN Batch 7/5900 loss 9.192327 loss_att 11.332606 loss_ctc 11.539875 loss_rnnt 6.421930 hw_loss 0.380500 lr 0.00062383 rank 7
2023-02-11 14:51:24,999 DEBUG TRAIN Batch 7/5900 loss 13.371525 loss_att 18.855145 loss_ctc 16.746035 loss_rnnt 8.784921 hw_loss 0.569990 lr 0.00062357 rank 5
2023-02-11 14:51:25,001 DEBUG TRAIN Batch 7/5900 loss 20.074825 loss_att 22.206821 loss_ctc 24.687420 loss_rnnt 17.810343 hw_loss 0.229325 lr 0.00062390 rank 6
2023-02-11 14:52:41,942 DEBUG TRAIN Batch 7/6000 loss 13.806917 loss_att 17.532404 loss_ctc 27.888268 loss_rnnt 9.845768 hw_loss 0.250976 lr 0.00062336 rank 3
2023-02-11 14:52:41,944 DEBUG TRAIN Batch 7/6000 loss 13.428741 loss_att 19.032501 loss_ctc 22.959938 loss_rnnt 10.105942 hw_loss 0.174604 lr 0.00062332 rank 4
2023-02-11 14:52:41,946 DEBUG TRAIN Batch 7/6000 loss 22.257549 loss_att 23.378088 loss_ctc 35.625195 loss_rnnt 16.550175 hw_loss 0.693921 lr 0.00062305 rank 1
2023-02-11 14:52:41,948 DEBUG TRAIN Batch 7/6000 loss 23.730532 loss_att 26.285847 loss_ctc 31.839022 loss_rnnt 19.702131 hw_loss 0.456789 lr 0.00062298 rank 0
2023-02-11 14:52:41,949 DEBUG TRAIN Batch 7/6000 loss 11.822411 loss_att 12.948195 loss_ctc 16.817684 loss_rnnt 7.856119 hw_loss 0.576581 lr 0.00062277 rank 2
2023-02-11 14:52:41,950 DEBUG TRAIN Batch 7/6000 loss 23.318094 loss_att 25.979269 loss_ctc 29.366589 loss_rnnt 19.819271 hw_loss 0.405023 lr 0.00062341 rank 6
2023-02-11 14:52:41,950 DEBUG TRAIN Batch 7/6000 loss 13.116422 loss_att 15.121523 loss_ctc 19.412766 loss_rnnt 7.510141 hw_loss 0.818578 lr 0.00062335 rank 7
2023-02-11 14:52:41,953 DEBUG TRAIN Batch 7/6000 loss 12.591584 loss_att 14.964680 loss_ctc 15.215195 loss_rnnt 8.712986 hw_loss 0.572656 lr 0.00062309 rank 5
2023-02-11 14:53:59,233 DEBUG TRAIN Batch 7/6100 loss 14.976159 loss_att 14.549029 loss_ctc 16.891777 loss_rnnt 11.639630 hw_loss 0.593726 lr 0.00062286 rank 7
2023-02-11 14:53:59,241 DEBUG TRAIN Batch 7/6100 loss 24.131338 loss_att 25.366606 loss_ctc 34.921501 loss_rnnt 19.482769 hw_loss 0.555530 lr 0.00062288 rank 3
2023-02-11 14:53:59,244 DEBUG TRAIN Batch 7/6100 loss 16.236631 loss_att 16.315655 loss_ctc 17.500576 loss_rnnt 12.899271 hw_loss 0.591193 lr 0.00062257 rank 1
2023-02-11 14:53:59,245 DEBUG TRAIN Batch 7/6100 loss 21.756926 loss_att 23.646515 loss_ctc 35.490196 loss_rnnt 18.333857 hw_loss 0.227634 lr 0.00062250 rank 0
2023-02-11 14:53:59,246 DEBUG TRAIN Batch 7/6100 loss 16.502798 loss_att 18.958639 loss_ctc 25.226782 loss_rnnt 12.244720 hw_loss 0.488196 lr 0.00062293 rank 6
2023-02-11 14:53:59,250 DEBUG TRAIN Batch 7/6100 loss 10.294996 loss_att 12.092544 loss_ctc 17.929028 loss_rnnt 7.710242 hw_loss 0.226383 lr 0.00062284 rank 4
2023-02-11 14:53:59,251 DEBUG TRAIN Batch 7/6100 loss 17.926567 loss_att 21.373131 loss_ctc 36.920444 loss_rnnt 14.012770 hw_loss 0.129744 lr 0.00062260 rank 5
2023-02-11 14:53:59,293 DEBUG TRAIN Batch 7/6100 loss 14.073997 loss_att 16.428940 loss_ctc 22.703690 loss_rnnt 9.947285 hw_loss 0.469706 lr 0.00062229 rank 2
2023-02-11 14:55:16,916 DEBUG TRAIN Batch 7/6200 loss 20.099371 loss_att 22.419792 loss_ctc 33.977112 loss_rnnt 15.805925 hw_loss 0.371062 lr 0.00062238 rank 7
2023-02-11 14:55:16,918 DEBUG TRAIN Batch 7/6200 loss 17.927904 loss_att 19.792326 loss_ctc 27.478432 loss_rnnt 13.788363 hw_loss 0.467485 lr 0.00062212 rank 5
2023-02-11 14:55:16,919 DEBUG TRAIN Batch 7/6200 loss 15.769396 loss_att 16.982513 loss_ctc 19.578814 loss_rnnt 11.628989 hw_loss 0.635599 lr 0.00062245 rank 6
2023-02-11 14:55:16,922 DEBUG TRAIN Batch 7/6200 loss 16.950005 loss_att 19.602102 loss_ctc 23.699657 loss_rnnt 12.123679 hw_loss 0.636741 lr 0.00062209 rank 1
2023-02-11 14:55:16,922 DEBUG TRAIN Batch 7/6200 loss 13.718663 loss_att 16.938665 loss_ctc 26.014856 loss_rnnt 9.843722 hw_loss 0.298396 lr 0.00062239 rank 3
2023-02-11 14:55:16,923 DEBUG TRAIN Batch 7/6200 loss 23.215590 loss_att 23.859806 loss_ctc 27.803532 loss_rnnt 18.796021 hw_loss 0.689812 lr 0.00062202 rank 0
2023-02-11 14:55:16,924 DEBUG TRAIN Batch 7/6200 loss 21.787004 loss_att 21.360758 loss_ctc 32.564316 loss_rnnt 16.406477 hw_loss 0.755400 lr 0.00062181 rank 2
2023-02-11 14:55:16,972 DEBUG TRAIN Batch 7/6200 loss 17.384184 loss_att 19.882790 loss_ctc 27.300419 loss_rnnt 14.464204 hw_loss 0.205893 lr 0.00062236 rank 4
2023-02-11 14:56:33,651 DEBUG TRAIN Batch 7/6300 loss 15.574543 loss_att 14.502532 loss_ctc 20.249977 loss_rnnt 12.561485 hw_loss 0.488263 lr 0.00062133 rank 2
2023-02-11 14:56:33,656 DEBUG TRAIN Batch 7/6300 loss 14.674373 loss_att 16.821041 loss_ctc 23.866034 loss_rnnt 10.414012 hw_loss 0.488526 lr 0.00062154 rank 0
2023-02-11 14:56:33,656 DEBUG TRAIN Batch 7/6300 loss 12.056748 loss_att 10.166488 loss_ctc 14.876579 loss_rnnt 7.802989 hw_loss 0.797969 lr 0.00062161 rank 1
2023-02-11 14:56:33,657 DEBUG TRAIN Batch 7/6300 loss 27.078482 loss_att 30.047655 loss_ctc 37.748943 loss_rnnt 22.265213 hw_loss 0.524382 lr 0.00062187 rank 4
2023-02-11 14:56:33,660 DEBUG TRAIN Batch 7/6300 loss 12.839425 loss_att 11.662083 loss_ctc 17.442776 loss_rnnt 10.466980 hw_loss 0.373900 lr 0.00062164 rank 5
2023-02-11 14:56:33,663 DEBUG TRAIN Batch 7/6300 loss 22.788963 loss_att 26.578310 loss_ctc 38.493019 loss_rnnt 17.609743 hw_loss 0.436402 lr 0.00062191 rank 3
2023-02-11 14:56:33,663 DEBUG TRAIN Batch 7/6300 loss 16.435722 loss_att 16.967501 loss_ctc 23.788193 loss_rnnt 12.838260 hw_loss 0.470771 lr 0.00062190 rank 7
2023-02-11 14:56:33,710 DEBUG TRAIN Batch 7/6300 loss 24.553627 loss_att 23.642019 loss_ctc 42.525101 loss_rnnt 19.755806 hw_loss 0.484490 lr 0.00062197 rank 6
2023-02-11 14:57:52,493 DEBUG TRAIN Batch 7/6400 loss 14.021368 loss_att 19.174829 loss_ctc 22.171513 loss_rnnt 10.658000 hw_loss 0.233623 lr 0.00062116 rank 5
2023-02-11 14:57:52,498 DEBUG TRAIN Batch 7/6400 loss 22.496655 loss_att 26.773798 loss_ctc 33.092892 loss_rnnt 18.236130 hw_loss 0.373549 lr 0.00062148 rank 6
2023-02-11 14:57:52,499 DEBUG TRAIN Batch 7/6400 loss 17.662102 loss_att 19.138247 loss_ctc 25.744093 loss_rnnt 12.802051 hw_loss 0.653854 lr 0.00062143 rank 3
2023-02-11 14:57:52,501 DEBUG TRAIN Batch 7/6400 loss 18.526434 loss_att 22.774557 loss_ctc 24.662487 loss_rnnt 13.340118 hw_loss 0.659728 lr 0.00062106 rank 0
2023-02-11 14:57:52,503 DEBUG TRAIN Batch 7/6400 loss 8.645754 loss_att 11.011717 loss_ctc 19.839861 loss_rnnt 3.129570 hw_loss 0.665708 lr 0.00062085 rank 2
2023-02-11 14:57:52,510 DEBUG TRAIN Batch 7/6400 loss 13.189156 loss_att 9.975243 loss_ctc 13.358614 loss_rnnt 8.802519 hw_loss 0.938779 lr 0.00062142 rank 7
2023-02-11 14:57:52,516 DEBUG TRAIN Batch 7/6400 loss 14.221104 loss_att 11.501193 loss_ctc 15.294039 loss_rnnt 9.421501 hw_loss 0.975099 lr 0.00062139 rank 4
2023-02-11 14:57:52,540 DEBUG TRAIN Batch 7/6400 loss 11.854274 loss_att 15.498025 loss_ctc 15.543064 loss_rnnt 8.276161 hw_loss 0.442036 lr 0.00062113 rank 1
2023-02-11 14:59:08,474 DEBUG TRAIN Batch 7/6500 loss 16.776640 loss_att 22.327700 loss_ctc 29.207916 loss_rnnt 10.957522 hw_loss 0.572138 lr 0.00062058 rank 0
2023-02-11 14:59:08,475 DEBUG TRAIN Batch 7/6500 loss 5.499811 loss_att 9.030918 loss_ctc 11.100340 loss_rnnt 3.550132 hw_loss 0.093135 lr 0.00062101 rank 6
2023-02-11 14:59:08,476 DEBUG TRAIN Batch 7/6500 loss 19.100582 loss_att 18.588793 loss_ctc 28.225052 loss_rnnt 15.820091 hw_loss 0.406172 lr 0.00062037 rank 2
2023-02-11 14:59:08,479 DEBUG TRAIN Batch 7/6500 loss 26.871250 loss_att 28.652939 loss_ctc 40.559269 loss_rnnt 21.635010 hw_loss 0.572781 lr 0.00062095 rank 3
2023-02-11 14:59:08,479 DEBUG TRAIN Batch 7/6500 loss 14.278109 loss_att 16.997107 loss_ctc 22.037247 loss_rnnt 10.202087 hw_loss 0.468313 lr 0.00062091 rank 4
2023-02-11 14:59:08,480 DEBUG TRAIN Batch 7/6500 loss 17.132090 loss_att 19.248772 loss_ctc 18.990496 loss_rnnt 14.132063 hw_loss 0.436669 lr 0.00062094 rank 7
2023-02-11 14:59:08,481 DEBUG TRAIN Batch 7/6500 loss 15.592093 loss_att 20.499704 loss_ctc 21.956688 loss_rnnt 11.938121 hw_loss 0.341969 lr 0.00062068 rank 5
2023-02-11 14:59:08,481 DEBUG TRAIN Batch 7/6500 loss 17.032614 loss_att 18.737019 loss_ctc 20.387062 loss_rnnt 12.399039 hw_loss 0.721019 lr 0.00062065 rank 1
2023-02-11 15:00:23,833 DEBUG TRAIN Batch 7/6600 loss 18.454142 loss_att 19.966503 loss_ctc 27.538750 loss_rnnt 15.295843 hw_loss 0.308353 lr 0.00061989 rank 2
2023-02-11 15:00:23,835 DEBUG TRAIN Batch 7/6600 loss 14.848989 loss_att 15.608965 loss_ctc 17.009777 loss_rnnt 12.697631 hw_loss 0.320861 lr 0.00062010 rank 0
2023-02-11 15:00:23,836 DEBUG TRAIN Batch 7/6600 loss 20.777168 loss_att 24.225033 loss_ctc 33.523438 loss_rnnt 15.861807 hw_loss 0.473678 lr 0.00062044 rank 4
2023-02-11 15:00:23,836 DEBUG TRAIN Batch 7/6600 loss 12.419861 loss_att 14.404749 loss_ctc 15.784861 loss_rnnt 10.336446 hw_loss 0.232082 lr 0.00062017 rank 1
2023-02-11 15:00:23,837 DEBUG TRAIN Batch 7/6600 loss 20.545740 loss_att 21.844021 loss_ctc 26.994572 loss_rnnt 17.130547 hw_loss 0.430442 lr 0.00062053 rank 6
2023-02-11 15:00:23,837 DEBUG TRAIN Batch 7/6600 loss 20.392113 loss_att 25.609734 loss_ctc 31.197546 loss_rnnt 14.697243 hw_loss 0.601992 lr 0.00062020 rank 5
2023-02-11 15:00:23,839 DEBUG TRAIN Batch 7/6600 loss 21.475906 loss_att 29.077679 loss_ctc 36.908192 loss_rnnt 17.084082 hw_loss 0.152593 lr 0.00062046 rank 7
2023-02-11 15:00:23,840 DEBUG TRAIN Batch 7/6600 loss 10.816562 loss_att 15.848679 loss_ctc 16.036695 loss_rnnt 6.582412 hw_loss 0.474695 lr 0.00062047 rank 3
2023-02-11 15:01:42,052 DEBUG TRAIN Batch 7/6700 loss 33.441410 loss_att 36.971561 loss_ctc 46.801491 loss_rnnt 29.144156 hw_loss 0.339353 lr 0.00062000 rank 3
2023-02-11 15:01:42,056 DEBUG TRAIN Batch 7/6700 loss 19.572937 loss_att 20.528296 loss_ctc 24.400162 loss_rnnt 16.101479 hw_loss 0.494392 lr 0.00062005 rank 6
2023-02-11 15:01:42,056 DEBUG TRAIN Batch 7/6700 loss 13.246565 loss_att 18.018204 loss_ctc 24.910881 loss_rnnt 9.121674 hw_loss 0.302873 lr 0.00061963 rank 0
2023-02-11 15:01:42,057 DEBUG TRAIN Batch 7/6700 loss 21.655231 loss_att 29.961710 loss_ctc 35.642448 loss_rnnt 17.024662 hw_loss 0.207059 lr 0.00061969 rank 1
2023-02-11 15:01:42,057 DEBUG TRAIN Batch 7/6700 loss 27.418402 loss_att 30.262863 loss_ctc 46.443123 loss_rnnt 22.743214 hw_loss 0.294312 lr 0.00061998 rank 7
2023-02-11 15:01:42,065 DEBUG TRAIN Batch 7/6700 loss 27.800293 loss_att 27.435715 loss_ctc 42.904907 loss_rnnt 22.811386 hw_loss 0.571476 lr 0.00061996 rank 4
2023-02-11 15:01:42,065 DEBUG TRAIN Batch 7/6700 loss 13.963801 loss_att 17.892756 loss_ctc 21.878366 loss_rnnt 10.127253 hw_loss 0.374153 lr 0.00061973 rank 5
2023-02-11 15:01:42,109 DEBUG TRAIN Batch 7/6700 loss 23.512001 loss_att 27.084110 loss_ctc 34.314156 loss_rnnt 19.962412 hw_loss 0.261540 lr 0.00061942 rank 2
2023-02-11 15:03:00,350 DEBUG TRAIN Batch 7/6800 loss 18.786879 loss_att 17.030226 loss_ctc 22.321232 loss_rnnt 15.626907 hw_loss 0.570010 lr 0.00061952 rank 3
2023-02-11 15:03:00,350 DEBUG TRAIN Batch 7/6800 loss 13.615322 loss_att 16.740713 loss_ctc 22.240335 loss_rnnt 10.559871 hw_loss 0.240070 lr 0.00061951 rank 7
2023-02-11 15:03:00,352 DEBUG TRAIN Batch 7/6800 loss 10.064902 loss_att 12.722672 loss_ctc 14.744256 loss_rnnt 6.605655 hw_loss 0.431959 lr 0.00061948 rank 4
2023-02-11 15:03:00,353 DEBUG TRAIN Batch 7/6800 loss 27.922527 loss_att 31.357552 loss_ctc 33.795185 loss_rnnt 23.413919 hw_loss 0.569734 lr 0.00061922 rank 1
2023-02-11 15:03:00,354 DEBUG TRAIN Batch 7/6800 loss 15.619279 loss_att 16.325418 loss_ctc 21.059334 loss_rnnt 10.835302 hw_loss 0.734514 lr 0.00061925 rank 5
2023-02-11 15:03:00,355 DEBUG TRAIN Batch 7/6800 loss 12.627367 loss_att 13.679882 loss_ctc 17.037437 loss_rnnt 10.337103 hw_loss 0.279704 lr 0.00061915 rank 0
2023-02-11 15:03:00,356 DEBUG TRAIN Batch 7/6800 loss 16.961117 loss_att 16.928373 loss_ctc 23.989758 loss_rnnt 14.564760 hw_loss 0.274829 lr 0.00061957 rank 6
2023-02-11 15:03:00,399 DEBUG TRAIN Batch 7/6800 loss 21.613754 loss_att 25.097799 loss_ctc 29.375154 loss_rnnt 16.233009 hw_loss 0.684203 lr 0.00061894 rank 2
2023-02-11 15:04:16,202 DEBUG TRAIN Batch 7/6900 loss 8.152970 loss_att 11.221048 loss_ctc 11.655211 loss_rnnt 5.017204 hw_loss 0.385347 lr 0.00061903 rank 7
2023-02-11 15:04:16,205 DEBUG TRAIN Batch 7/6900 loss 18.337038 loss_att 18.674150 loss_ctc 22.601868 loss_rnnt 15.894040 hw_loss 0.338800 lr 0.00061878 rank 5
2023-02-11 15:04:16,206 DEBUG TRAIN Batch 7/6900 loss 21.183187 loss_att 23.624199 loss_ctc 34.033852 loss_rnnt 16.461843 hw_loss 0.472447 lr 0.00061868 rank 0
2023-02-11 15:04:16,206 DEBUG TRAIN Batch 7/6900 loss 30.466379 loss_att 35.752754 loss_ctc 48.145073 loss_rnnt 25.052485 hw_loss 0.374899 lr 0.00061847 rank 2
2023-02-11 15:04:16,208 DEBUG TRAIN Batch 7/6900 loss 29.525993 loss_att 28.369034 loss_ctc 40.484940 loss_rnnt 25.586769 hw_loss 0.508017 lr 0.00061874 rank 1
2023-02-11 15:04:16,209 DEBUG TRAIN Batch 7/6900 loss 30.104425 loss_att 29.425184 loss_ctc 35.287529 loss_rnnt 27.894096 hw_loss 0.310330 lr 0.00061905 rank 3
2023-02-11 15:04:16,213 DEBUG TRAIN Batch 7/6900 loss 16.335976 loss_att 13.322662 loss_ctc 19.145981 loss_rnnt 12.750401 hw_loss 0.715044 lr 0.00061910 rank 6
2023-02-11 15:04:16,260 DEBUG TRAIN Batch 7/6900 loss 15.357904 loss_att 17.559332 loss_ctc 23.687702 loss_rnnt 11.454174 hw_loss 0.441151 lr 0.00061901 rank 4
2023-02-11 15:05:31,343 DEBUG TRAIN Batch 7/7000 loss 14.430161 loss_att 14.619353 loss_ctc 17.621435 loss_rnnt 10.356415 hw_loss 0.676951 lr 0.00061820 rank 0
2023-02-11 15:05:31,345 DEBUG TRAIN Batch 7/7000 loss 24.654137 loss_att 28.021666 loss_ctc 37.436035 loss_rnnt 18.842360 hw_loss 0.643879 lr 0.00061857 rank 3
2023-02-11 15:05:31,348 DEBUG TRAIN Batch 7/7000 loss 10.914556 loss_att 13.544179 loss_ctc 14.701275 loss_rnnt 8.163616 hw_loss 0.322522 lr 0.00061862 rank 6
2023-02-11 15:05:31,348 DEBUG TRAIN Batch 7/7000 loss 17.275377 loss_att 15.437084 loss_ctc 21.895422 loss_rnnt 13.818720 hw_loss 0.601558 lr 0.00061800 rank 2
2023-02-11 15:05:31,353 DEBUG TRAIN Batch 7/7000 loss 20.372753 loss_att 21.445934 loss_ctc 26.247238 loss_rnnt 17.580770 hw_loss 0.336391 lr 0.00061853 rank 4
2023-02-11 15:05:31,353 DEBUG TRAIN Batch 7/7000 loss 16.606688 loss_att 13.381021 loss_ctc 16.533384 loss_rnnt 12.376797 hw_loss 0.915900 lr 0.00061856 rank 7
2023-02-11 15:05:31,354 DEBUG TRAIN Batch 7/7000 loss 20.656570 loss_att 15.360895 loss_ctc 19.967831 loss_rnnt 14.427416 hw_loss 1.383772 lr 0.00061827 rank 1
2023-02-11 15:05:31,355 DEBUG TRAIN Batch 7/7000 loss 14.860352 loss_att 12.667558 loss_ctc 16.107946 loss_rnnt 10.315158 hw_loss 0.903264 lr 0.00061830 rank 5
2023-02-11 15:06:50,973 DEBUG TRAIN Batch 7/7100 loss 13.370725 loss_att 15.051721 loss_ctc 14.085859 loss_rnnt 10.590654 hw_loss 0.440347 lr 0.00061809 rank 7
2023-02-11 15:06:50,974 DEBUG TRAIN Batch 7/7100 loss 12.525656 loss_att 16.093224 loss_ctc 18.028130 loss_rnnt 9.514209 hw_loss 0.293301 lr 0.00061783 rank 5
2023-02-11 15:06:50,974 DEBUG TRAIN Batch 7/7100 loss 10.522854 loss_att 12.593558 loss_ctc 13.281337 loss_rnnt 7.657865 hw_loss 0.390572 lr 0.00061773 rank 0
2023-02-11 15:06:50,976 DEBUG TRAIN Batch 7/7100 loss 46.821457 loss_att 45.942848 loss_ctc 61.785652 loss_rnnt 43.826431 hw_loss 0.220410 lr 0.00061752 rank 2
2023-02-11 15:06:50,977 DEBUG TRAIN Batch 7/7100 loss 17.577827 loss_att 14.989475 loss_ctc 16.824696 loss_rnnt 13.000982 hw_loss 0.974050 lr 0.00061810 rank 3
2023-02-11 15:06:50,981 DEBUG TRAIN Batch 7/7100 loss 12.725368 loss_att 14.948479 loss_ctc 18.167183 loss_rnnt 10.418780 hw_loss 0.213073 lr 0.00061780 rank 1
2023-02-11 15:06:50,993 DEBUG TRAIN Batch 7/7100 loss 12.669565 loss_att 14.669806 loss_ctc 25.792738 loss_rnnt 8.687512 hw_loss 0.343546 lr 0.00061806 rank 4
2023-02-11 15:06:51,001 DEBUG TRAIN Batch 7/7100 loss 16.983536 loss_att 23.256969 loss_ctc 36.440826 loss_rnnt 12.662670 hw_loss 0.088476 lr 0.00061815 rank 6
2023-02-11 15:08:07,722 DEBUG TRAIN Batch 7/7200 loss 17.691868 loss_att 21.245689 loss_ctc 24.425795 loss_rnnt 14.124722 hw_loss 0.367223 lr 0.00061726 rank 0
2023-02-11 15:08:07,724 DEBUG TRAIN Batch 7/7200 loss 32.940948 loss_att 37.666916 loss_ctc 52.380577 loss_rnnt 27.090664 hw_loss 0.433714 lr 0.00061768 rank 6
2023-02-11 15:08:07,726 DEBUG TRAIN Batch 7/7200 loss 15.036852 loss_att 22.972254 loss_ctc 22.554655 loss_rnnt 11.032577 hw_loss 0.265279 lr 0.00061763 rank 3
2023-02-11 15:08:07,729 DEBUG TRAIN Batch 7/7200 loss 10.925547 loss_att 12.309027 loss_ctc 13.196894 loss_rnnt 7.657072 hw_loss 0.504175 lr 0.00061736 rank 5
2023-02-11 15:08:07,729 DEBUG TRAIN Batch 7/7200 loss 13.013658 loss_att 15.288230 loss_ctc 16.810423 loss_rnnt 8.996426 hw_loss 0.573015 lr 0.00061761 rank 7
2023-02-11 15:08:07,732 DEBUG TRAIN Batch 7/7200 loss 29.142937 loss_att 30.944872 loss_ctc 45.293777 loss_rnnt 25.734739 hw_loss 0.167693 lr 0.00061705 rank 2
2023-02-11 15:08:07,733 DEBUG TRAIN Batch 7/7200 loss 19.927563 loss_att 23.119598 loss_ctc 25.829285 loss_rnnt 18.433390 hw_loss 0.012913 lr 0.00061759 rank 4
2023-02-11 15:08:07,776 DEBUG TRAIN Batch 7/7200 loss 16.957235 loss_att 22.800755 loss_ctc 30.682043 loss_rnnt 12.448179 hw_loss 0.283196 lr 0.00061733 rank 1
2023-02-11 15:09:23,049 DEBUG TRAIN Batch 7/7300 loss 29.706692 loss_att 32.926582 loss_ctc 38.279556 loss_rnnt 26.665134 hw_loss 0.235224 lr 0.00061716 rank 3
2023-02-11 15:09:23,055 DEBUG TRAIN Batch 7/7300 loss 13.665562 loss_att 14.988592 loss_ctc 20.665985 loss_rnnt 9.161220 hw_loss 0.619940 lr 0.00061721 rank 6
2023-02-11 15:09:23,055 DEBUG TRAIN Batch 7/7300 loss 13.320610 loss_att 16.003887 loss_ctc 24.575367 loss_rnnt 10.306305 hw_loss 0.183190 lr 0.00061686 rank 1
2023-02-11 15:09:23,055 DEBUG TRAIN Batch 7/7300 loss 7.992796 loss_att 8.432030 loss_ctc 9.143286 loss_rnnt 4.277671 hw_loss 0.651352 lr 0.00061679 rank 0
2023-02-11 15:09:23,057 DEBUG TRAIN Batch 7/7300 loss 25.039516 loss_att 33.552208 loss_ctc 42.478256 loss_rnnt 19.956457 hw_loss 0.197879 lr 0.00061714 rank 7
2023-02-11 15:09:23,057 DEBUG TRAIN Batch 7/7300 loss 13.890624 loss_att 15.110111 loss_ctc 22.661633 loss_rnnt 11.031353 hw_loss 0.271107 lr 0.00061658 rank 2
2023-02-11 15:09:23,059 DEBUG TRAIN Batch 7/7300 loss 13.668449 loss_att 15.345830 loss_ctc 25.193876 loss_rnnt 9.571918 hw_loss 0.417062 lr 0.00061689 rank 5
2023-02-11 15:09:23,062 DEBUG TRAIN Batch 7/7300 loss 16.265953 loss_att 17.084808 loss_ctc 30.256268 loss_rnnt 13.672827 hw_loss 0.105746 lr 0.00061712 rank 4
2023-02-11 15:10:40,837 DEBUG TRAIN Batch 7/7400 loss 28.040556 loss_att 28.828335 loss_ctc 41.908222 loss_rnnt 21.673683 hw_loss 0.817555 lr 0.00061612 rank 2
2023-02-11 15:10:40,841 DEBUG TRAIN Batch 7/7400 loss 22.470917 loss_att 19.651112 loss_ctc 35.723087 loss_rnnt 17.206459 hw_loss 0.761524 lr 0.00061674 rank 6
2023-02-11 15:10:40,841 DEBUG TRAIN Batch 7/7400 loss 20.986309 loss_att 28.597767 loss_ctc 37.395023 loss_rnnt 15.972129 hw_loss 0.244511 lr 0.00061639 rank 1
2023-02-11 15:10:40,842 DEBUG TRAIN Batch 7/7400 loss 23.139696 loss_att 24.758123 loss_ctc 33.789597 loss_rnnt 17.861328 hw_loss 0.662756 lr 0.00061669 rank 3
2023-02-11 15:10:40,843 DEBUG TRAIN Batch 7/7400 loss 11.076458 loss_att 15.041674 loss_ctc 19.503395 loss_rnnt 6.222507 hw_loss 0.550747 lr 0.00061667 rank 7
2023-02-11 15:10:40,845 DEBUG TRAIN Batch 7/7400 loss 13.367439 loss_att 17.050491 loss_ctc 20.957825 loss_rnnt 10.523382 hw_loss 0.205387 lr 0.00061632 rank 0
2023-02-11 15:10:40,845 DEBUG TRAIN Batch 7/7400 loss 11.547443 loss_att 13.994298 loss_ctc 17.786411 loss_rnnt 8.585100 hw_loss 0.307708 lr 0.00061642 rank 5
2023-02-11 15:10:40,846 DEBUG TRAIN Batch 7/7400 loss 29.167454 loss_att 31.591648 loss_ctc 43.298615 loss_rnnt 24.128906 hw_loss 0.500542 lr 0.00061665 rank 4
2023-02-11 15:12:00,393 DEBUG TRAIN Batch 7/7500 loss 21.160948 loss_att 24.867846 loss_ctc 23.546644 loss_rnnt 17.874947 hw_loss 0.417474 lr 0.00061622 rank 3
2023-02-11 15:12:00,395 DEBUG TRAIN Batch 7/7500 loss 18.154831 loss_att 24.494450 loss_ctc 36.436119 loss_rnnt 12.757741 hw_loss 0.317186 lr 0.00061620 rank 7
2023-02-11 15:12:00,401 DEBUG TRAIN Batch 7/7500 loss 8.660467 loss_att 9.512529 loss_ctc 10.073896 loss_rnnt 5.295501 hw_loss 0.563643 lr 0.00061627 rank 6
2023-02-11 15:12:00,401 DEBUG TRAIN Batch 7/7500 loss 12.245787 loss_att 20.399200 loss_ctc 21.839067 loss_rnnt 7.919466 hw_loss 0.265600 lr 0.00061565 rank 2
2023-02-11 15:12:00,402 DEBUG TRAIN Batch 7/7500 loss 16.633692 loss_att 19.981331 loss_ctc 28.483862 loss_rnnt 12.526754 hw_loss 0.348260 lr 0.00061618 rank 4
2023-02-11 15:12:00,403 DEBUG TRAIN Batch 7/7500 loss 17.402967 loss_att 20.115080 loss_ctc 23.335640 loss_rnnt 14.421446 hw_loss 0.309014 lr 0.00061595 rank 5
2023-02-11 15:12:00,402 DEBUG TRAIN Batch 7/7500 loss 15.753403 loss_att 18.289862 loss_ctc 23.130190 loss_rnnt 11.474333 hw_loss 0.522789 lr 0.00061585 rank 0
2023-02-11 15:12:00,404 DEBUG TRAIN Batch 7/7500 loss 26.255783 loss_att 27.614740 loss_ctc 37.288670 loss_rnnt 22.356281 hw_loss 0.404373 lr 0.00061592 rank 1
2023-02-11 15:13:16,375 DEBUG TRAIN Batch 7/7600 loss 25.294022 loss_att 24.832239 loss_ctc 38.253033 loss_rnnt 20.585562 hw_loss 0.576177 lr 0.00061574 rank 7
2023-02-11 15:13:16,377 DEBUG TRAIN Batch 7/7600 loss 17.760086 loss_att 20.105629 loss_ctc 25.413614 loss_rnnt 15.357882 hw_loss 0.171117 lr 0.00061575 rank 3
2023-02-11 15:13:16,380 DEBUG TRAIN Batch 7/7600 loss 15.533112 loss_att 18.463398 loss_ctc 23.785341 loss_rnnt 11.377404 hw_loss 0.463004 lr 0.00061518 rank 2
2023-02-11 15:13:16,381 DEBUG TRAIN Batch 7/7600 loss 16.506708 loss_att 19.308777 loss_ctc 23.356548 loss_rnnt 12.971142 hw_loss 0.386595 lr 0.00061539 rank 0
2023-02-11 15:13:16,382 DEBUG TRAIN Batch 7/7600 loss 14.566534 loss_att 15.507975 loss_ctc 21.865108 loss_rnnt 10.344950 hw_loss 0.573779 lr 0.00061571 rank 4
2023-02-11 15:13:16,382 DEBUG TRAIN Batch 7/7600 loss 14.875175 loss_att 13.940459 loss_ctc 20.224463 loss_rnnt 9.679621 hw_loss 0.875486 lr 0.00061549 rank 5
2023-02-11 15:13:16,384 DEBUG TRAIN Batch 7/7600 loss 24.132828 loss_att 24.652697 loss_ctc 35.548820 loss_rnnt 20.744534 hw_loss 0.330411 lr 0.00061580 rank 6
2023-02-11 15:13:16,429 DEBUG TRAIN Batch 7/7600 loss 15.226883 loss_att 13.712448 loss_ctc 17.423367 loss_rnnt 12.591888 hw_loss 0.495941 lr 0.00061545 rank 1
2023-02-11 15:14:32,037 DEBUG TRAIN Batch 7/7700 loss 12.063210 loss_att 11.733386 loss_ctc 13.774350 loss_rnnt 7.404022 hw_loss 0.843188 lr 0.00061529 rank 3
2023-02-11 15:14:32,039 DEBUG TRAIN Batch 7/7700 loss 17.501963 loss_att 17.279125 loss_ctc 21.780525 loss_rnnt 14.477018 hw_loss 0.468569 lr 0.00061492 rank 0
2023-02-11 15:14:32,039 DEBUG TRAIN Batch 7/7700 loss 21.504896 loss_att 20.925882 loss_ctc 28.612698 loss_rnnt 17.231049 hw_loss 0.645364 lr 0.00061527 rank 7
2023-02-11 15:14:32,041 DEBUG TRAIN Batch 7/7700 loss 27.049366 loss_att 31.273174 loss_ctc 54.760956 loss_rnnt 21.573116 hw_loss 0.175614 lr 0.00061499 rank 1
2023-02-11 15:14:32,041 DEBUG TRAIN Batch 7/7700 loss 15.786858 loss_att 14.528067 loss_ctc 20.629253 loss_rnnt 10.083438 hw_loss 0.995536 lr 0.00061472 rank 2
2023-02-11 15:14:32,042 DEBUG TRAIN Batch 7/7700 loss 25.684280 loss_att 27.199242 loss_ctc 36.134880 loss_rnnt 22.049191 hw_loss 0.363503 lr 0.00061534 rank 6
2023-02-11 15:14:32,046 DEBUG TRAIN Batch 7/7700 loss 23.595369 loss_att 27.702522 loss_ctc 37.971970 loss_rnnt 19.070087 hw_loss 0.335057 lr 0.00061502 rank 5
2023-02-11 15:14:32,048 DEBUG TRAIN Batch 7/7700 loss 19.040907 loss_att 20.329807 loss_ctc 26.764706 loss_rnnt 15.188549 hw_loss 0.480888 lr 0.00061525 rank 4
2023-02-11 15:15:50,791 DEBUG TRAIN Batch 7/7800 loss 12.628325 loss_att 13.851254 loss_ctc 16.096783 loss_rnnt 7.935951 hw_loss 0.747249 lr 0.00061482 rank 3
2023-02-11 15:15:50,797 DEBUG TRAIN Batch 7/7800 loss 17.366711 loss_att 21.355389 loss_ctc 24.448715 loss_rnnt 13.863727 hw_loss 0.330184 lr 0.00061455 rank 5
2023-02-11 15:15:50,798 DEBUG TRAIN Batch 7/7800 loss 12.605420 loss_att 12.865069 loss_ctc 15.919215 loss_rnnt 9.618146 hw_loss 0.467532 lr 0.00061446 rank 0
2023-02-11 15:15:50,800 DEBUG TRAIN Batch 7/7800 loss 33.629883 loss_att 37.544640 loss_ctc 48.499908 loss_rnnt 28.766678 hw_loss 0.393297 lr 0.00061487 rank 6
2023-02-11 15:15:50,801 DEBUG TRAIN Batch 7/7800 loss 9.683274 loss_att 11.485361 loss_ctc 13.896888 loss_rnnt 7.297246 hw_loss 0.274462 lr 0.00061481 rank 7
2023-02-11 15:15:50,804 DEBUG TRAIN Batch 7/7800 loss 14.566017 loss_att 16.728987 loss_ctc 19.720264 loss_rnnt 12.927962 hw_loss 0.097168 lr 0.00061478 rank 4
2023-02-11 15:15:50,811 DEBUG TRAIN Batch 7/7800 loss 18.580643 loss_att 26.103676 loss_ctc 38.164024 loss_rnnt 12.580818 hw_loss 0.353269 lr 0.00061452 rank 1
2023-02-11 15:15:50,823 DEBUG TRAIN Batch 7/7800 loss 23.177414 loss_att 27.828848 loss_ctc 36.813290 loss_rnnt 18.947350 hw_loss 0.277811 lr 0.00061425 rank 2
2023-02-11 15:17:07,889 DEBUG TRAIN Batch 7/7900 loss 30.788269 loss_att 32.255795 loss_ctc 50.411800 loss_rnnt 25.899864 hw_loss 0.370955 lr 0.00061436 rank 3
2023-02-11 15:17:07,893 DEBUG TRAIN Batch 7/7900 loss 12.779364 loss_att 15.543859 loss_ctc 17.321346 loss_rnnt 10.048698 hw_loss 0.294781 lr 0.00061434 rank 7
2023-02-11 15:17:07,895 DEBUG TRAIN Batch 7/7900 loss 11.500956 loss_att 12.983170 loss_ctc 17.608892 loss_rnnt 8.322632 hw_loss 0.387654 lr 0.00061399 rank 0
2023-02-11 15:17:07,897 DEBUG TRAIN Batch 7/7900 loss 17.813999 loss_att 22.531830 loss_ctc 31.892141 loss_rnnt 12.471054 hw_loss 0.472930 lr 0.00061379 rank 2
2023-02-11 15:17:07,897 DEBUG TRAIN Batch 7/7900 loss 13.392508 loss_att 15.486597 loss_ctc 20.295502 loss_rnnt 10.481358 hw_loss 0.294737 lr 0.00061441 rank 6
2023-02-11 15:17:07,898 DEBUG TRAIN Batch 7/7900 loss 26.468079 loss_att 27.258062 loss_ctc 36.198845 loss_rnnt 21.981682 hw_loss 0.568306 lr 0.00061406 rank 1
2023-02-11 15:17:07,899 DEBUG TRAIN Batch 7/7900 loss 22.800488 loss_att 28.227642 loss_ctc 35.909195 loss_rnnt 18.741768 hw_loss 0.229774 lr 0.00061409 rank 5
2023-02-11 15:17:07,904 DEBUG TRAIN Batch 7/7900 loss 22.311872 loss_att 22.023567 loss_ctc 32.738659 loss_rnnt 19.089691 hw_loss 0.354301 lr 0.00061432 rank 4
2023-02-11 15:18:23,968 DEBUG TRAIN Batch 7/8000 loss 17.596848 loss_att 20.126955 loss_ctc 28.525175 loss_rnnt 13.092368 hw_loss 0.476503 lr 0.00061389 rank 3
2023-02-11 15:18:23,971 DEBUG TRAIN Batch 7/8000 loss 16.452003 loss_att 18.502724 loss_ctc 18.072060 loss_rnnt 13.844552 hw_loss 0.371493 lr 0.00061388 rank 7
2023-02-11 15:18:23,971 DEBUG TRAIN Batch 7/8000 loss 9.080756 loss_att 11.068695 loss_ctc 15.317116 loss_rnnt 5.784279 hw_loss 0.387633 lr 0.00061394 rank 6
2023-02-11 15:18:23,971 DEBUG TRAIN Batch 7/8000 loss 24.670149 loss_att 26.304810 loss_ctc 34.344612 loss_rnnt 21.801136 hw_loss 0.234778 lr 0.00061353 rank 0
2023-02-11 15:18:23,974 DEBUG TRAIN Batch 7/8000 loss 23.005188 loss_att 29.245338 loss_ctc 34.180855 loss_rnnt 17.998466 hw_loss 0.425363 lr 0.00061333 rank 2
2023-02-11 15:18:23,975 DEBUG TRAIN Batch 7/8000 loss 16.203279 loss_att 15.615001 loss_ctc 21.094513 loss_rnnt 12.739276 hw_loss 0.549280 lr 0.00061360 rank 1
2023-02-11 15:18:23,976 DEBUG TRAIN Batch 7/8000 loss 15.108323 loss_att 15.179008 loss_ctc 18.130018 loss_rnnt 10.488012 hw_loss 0.788115 lr 0.00061363 rank 5
2023-02-11 15:18:24,021 DEBUG TRAIN Batch 7/8000 loss 15.232418 loss_att 17.855610 loss_ctc 22.746338 loss_rnnt 9.484564 hw_loss 0.791505 lr 0.00061386 rank 4
2023-02-11 15:19:41,062 DEBUG TRAIN Batch 7/8100 loss 22.528164 loss_att 29.972736 loss_ctc 36.551361 loss_rnnt 17.306726 hw_loss 0.349268 lr 0.00061343 rank 3
2023-02-11 15:19:41,068 DEBUG TRAIN Batch 7/8100 loss 12.169629 loss_att 13.233940 loss_ctc 16.139080 loss_rnnt 10.475359 hw_loss 0.178528 lr 0.00061307 rank 0
2023-02-11 15:19:41,070 DEBUG TRAIN Batch 7/8100 loss 23.205229 loss_att 24.615353 loss_ctc 40.303696 loss_rnnt 16.369806 hw_loss 0.801300 lr 0.00061342 rank 7
2023-02-11 15:19:41,073 DEBUG TRAIN Batch 7/8100 loss 23.524475 loss_att 24.013832 loss_ctc 29.304108 loss_rnnt 20.432594 hw_loss 0.416886 lr 0.00061317 rank 5
2023-02-11 15:19:41,072 DEBUG TRAIN Batch 7/8100 loss 18.075388 loss_att 19.885687 loss_ctc 29.792208 loss_rnnt 13.198977 hw_loss 0.553520 lr 0.00061287 rank 2
2023-02-11 15:19:41,072 DEBUG TRAIN Batch 7/8100 loss 18.657734 loss_att 17.630894 loss_ctc 23.143414 loss_rnnt 13.924385 hw_loss 0.813867 lr 0.00061339 rank 4
2023-02-11 15:19:41,084 DEBUG TRAIN Batch 7/8100 loss 23.694210 loss_att 24.623671 loss_ctc 35.783600 loss_rnnt 16.890305 hw_loss 0.938643 lr 0.00061348 rank 6
2023-02-11 15:19:41,121 DEBUG TRAIN Batch 7/8100 loss 13.931780 loss_att 15.917440 loss_ctc 20.976448 loss_rnnt 10.698284 hw_loss 0.355701 lr 0.00061313 rank 1
2023-02-11 15:20:57,174 DEBUG TRAIN Batch 7/8200 loss 6.783826 loss_att 9.595135 loss_ctc 11.328075 loss_rnnt 4.227182 hw_loss 0.260340 lr 0.00061261 rank 0
2023-02-11 15:20:57,176 DEBUG TRAIN Batch 7/8200 loss 22.795315 loss_att 29.199228 loss_ctc 35.429359 loss_rnnt 19.347345 hw_loss 0.090496 lr 0.00061296 rank 7
2023-02-11 15:20:57,177 DEBUG TRAIN Batch 7/8200 loss 11.345314 loss_att 11.202417 loss_ctc 12.414858 loss_rnnt 7.336517 hw_loss 0.730270 lr 0.00061267 rank 1
2023-02-11 15:20:57,178 DEBUG TRAIN Batch 7/8200 loss 18.468603 loss_att 22.401388 loss_ctc 24.632801 loss_rnnt 15.101082 hw_loss 0.329826 lr 0.00061241 rank 2
2023-02-11 15:20:57,178 DEBUG TRAIN Batch 7/8200 loss 17.435528 loss_att 18.051437 loss_ctc 22.487415 loss_rnnt 14.786932 hw_loss 0.347218 lr 0.00061297 rank 3
2023-02-11 15:20:57,182 DEBUG TRAIN Batch 7/8200 loss 18.794168 loss_att 22.461689 loss_ctc 34.629147 loss_rnnt 14.712209 hw_loss 0.231961 lr 0.00061271 rank 5
2023-02-11 15:20:57,183 DEBUG TRAIN Batch 7/8200 loss 13.135308 loss_att 14.282377 loss_ctc 19.778820 loss_rnnt 8.111804 hw_loss 0.732804 lr 0.00061302 rank 6
2023-02-11 15:20:57,192 DEBUG TRAIN Batch 7/8200 loss 19.684933 loss_att 21.027115 loss_ctc 27.583006 loss_rnnt 15.588297 hw_loss 0.520335 lr 0.00061293 rank 4
2023-02-11 15:22:11,760 DEBUG TRAIN Batch 7/8300 loss 5.463940 loss_att 6.891145 loss_ctc 8.124819 loss_rnnt 3.565920 hw_loss 0.235836 lr 0.00061249 rank 7
2023-02-11 15:22:11,765 DEBUG TRAIN Batch 7/8300 loss 8.385721 loss_att 13.378501 loss_ctc 10.473991 loss_rnnt 5.770502 hw_loss 0.250918 lr 0.00061215 rank 0
2023-02-11 15:22:11,766 DEBUG TRAIN Batch 7/8300 loss 12.724029 loss_att 13.498546 loss_ctc 19.263792 loss_rnnt 9.138871 hw_loss 0.479678 lr 0.00061251 rank 3
2023-02-11 15:22:11,766 DEBUG TRAIN Batch 7/8300 loss 19.825869 loss_att 24.583675 loss_ctc 30.409271 loss_rnnt 16.597185 hw_loss 0.162375 lr 0.00061225 rank 5
2023-02-11 15:22:11,766 DEBUG TRAIN Batch 7/8300 loss 13.439058 loss_att 15.245876 loss_ctc 22.871838 loss_rnnt 10.089668 hw_loss 0.324436 lr 0.00061247 rank 4
2023-02-11 15:22:11,769 DEBUG TRAIN Batch 7/8300 loss 27.422874 loss_att 35.745811 loss_ctc 39.196842 loss_rnnt 22.311974 hw_loss 0.351835 lr 0.00061195 rank 2
2023-02-11 15:22:11,769 DEBUG TRAIN Batch 7/8300 loss 31.634058 loss_att 32.447674 loss_ctc 51.416794 loss_rnnt 26.088902 hw_loss 0.514637 lr 0.00061221 rank 1
2023-02-11 15:22:11,769 DEBUG TRAIN Batch 7/8300 loss 8.760768 loss_att 11.154419 loss_ctc 11.702731 loss_rnnt 5.345766 hw_loss 0.477002 lr 0.00061256 rank 6
2023-02-11 15:23:05,418 DEBUG CV Batch 7/0 loss 7.451066 loss_att 1.803636 loss_ctc 3.030516 loss_rnnt 1.524120 hw_loss 1.433595 history loss 7.175100 rank 5
2023-02-11 15:23:05,419 DEBUG CV Batch 7/0 loss 7.451065 loss_att 1.803636 loss_ctc 3.030516 loss_rnnt 1.524120 hw_loss 1.433594 history loss 7.175099 rank 7
2023-02-11 15:23:05,421 DEBUG CV Batch 7/0 loss 7.451066 loss_att 1.803636 loss_ctc 3.030516 loss_rnnt 1.524120 hw_loss 1.433595 history loss 7.175100 rank 0
2023-02-11 15:23:05,422 DEBUG CV Batch 7/0 loss 7.451065 loss_att 1.803636 loss_ctc 3.030516 loss_rnnt 1.524120 hw_loss 1.433594 history loss 7.175100 rank 1
2023-02-11 15:23:05,426 DEBUG CV Batch 7/0 loss 7.451064 loss_att 1.803636 loss_ctc 3.030516 loss_rnnt 1.524120 hw_loss 1.433594 history loss 7.175099 rank 6
2023-02-11 15:23:05,426 DEBUG CV Batch 7/0 loss 7.451065 loss_att 1.803636 loss_ctc 3.030516 loss_rnnt 1.524120 hw_loss 1.433594 history loss 7.175099 rank 4
2023-02-11 15:23:05,428 DEBUG CV Batch 7/0 loss 7.451066 loss_att 1.803636 loss_ctc 3.030516 loss_rnnt 1.524120 hw_loss 1.433595 history loss 7.175100 rank 2
2023-02-11 15:23:05,441 DEBUG CV Batch 7/0 loss 7.451066 loss_att 1.803636 loss_ctc 3.030516 loss_rnnt 1.524120 hw_loss 1.433595 history loss 7.175100 rank 3
2023-02-11 15:23:16,506 DEBUG CV Batch 7/100 loss 12.691690 loss_att 8.910173 loss_ctc 14.314798 loss_rnnt 7.072471 hw_loss 1.154833 history loss 8.086506 rank 6
2023-02-11 15:23:16,519 DEBUG CV Batch 7/100 loss 12.691690 loss_att 8.910173 loss_ctc 14.314798 loss_rnnt 7.072471 hw_loss 1.154833 history loss 8.086506 rank 0
2023-02-11 15:23:16,624 DEBUG CV Batch 7/100 loss 12.691690 loss_att 8.910173 loss_ctc 14.314798 loss_rnnt 7.072471 hw_loss 1.154833 history loss 8.086506 rank 5
2023-02-11 15:23:16,642 DEBUG CV Batch 7/100 loss 12.691690 loss_att 8.910173 loss_ctc 14.314798 loss_rnnt 7.072471 hw_loss 1.154833 history loss 8.086506 rank 2
2023-02-11 15:23:16,679 DEBUG CV Batch 7/100 loss 12.691690 loss_att 8.910173 loss_ctc 14.314798 loss_rnnt 7.072471 hw_loss 1.154833 history loss 8.086506 rank 7
2023-02-11 15:23:16,681 DEBUG CV Batch 7/100 loss 12.691690 loss_att 8.910173 loss_ctc 14.314798 loss_rnnt 7.072471 hw_loss 1.154833 history loss 8.086506 rank 3
2023-02-11 15:23:16,844 DEBUG CV Batch 7/100 loss 12.691690 loss_att 8.910173 loss_ctc 14.314798 loss_rnnt 7.072471 hw_loss 1.154833 history loss 8.086506 rank 4
2023-02-11 15:23:16,918 DEBUG CV Batch 7/100 loss 12.691690 loss_att 8.910173 loss_ctc 14.314798 loss_rnnt 7.072471 hw_loss 1.154833 history loss 8.086506 rank 1
2023-02-11 15:23:30,299 DEBUG CV Batch 7/200 loss 17.534641 loss_att 23.597315 loss_ctc 24.671858 loss_rnnt 15.123241 hw_loss 0.046357 history loss 8.528846 rank 7
2023-02-11 15:23:30,357 DEBUG CV Batch 7/200 loss 17.534641 loss_att 23.597315 loss_ctc 24.671858 loss_rnnt 15.123241 hw_loss 0.046357 history loss 8.528846 rank 0
2023-02-11 15:23:30,445 DEBUG CV Batch 7/200 loss 17.534641 loss_att 23.597315 loss_ctc 24.671858 loss_rnnt 15.123241 hw_loss 0.046357 history loss 8.528846 rank 2
2023-02-11 15:23:30,514 DEBUG CV Batch 7/200 loss 17.534641 loss_att 23.597315 loss_ctc 24.671858 loss_rnnt 15.123241 hw_loss 0.046357 history loss 8.528845 rank 5
2023-02-11 15:23:30,531 DEBUG CV Batch 7/200 loss 17.534641 loss_att 23.597315 loss_ctc 24.671858 loss_rnnt 15.123241 hw_loss 0.046357 history loss 8.528846 rank 3
2023-02-11 15:23:30,759 DEBUG CV Batch 7/200 loss 17.534641 loss_att 23.597315 loss_ctc 24.671858 loss_rnnt 15.123241 hw_loss 0.046357 history loss 8.528846 rank 1
2023-02-11 15:23:30,881 DEBUG CV Batch 7/200 loss 17.534641 loss_att 23.597315 loss_ctc 24.671858 loss_rnnt 15.123241 hw_loss 0.046357 history loss 8.528846 rank 6
2023-02-11 15:23:31,062 DEBUG CV Batch 7/200 loss 17.534641 loss_att 23.597315 loss_ctc 24.671858 loss_rnnt 15.123241 hw_loss 0.046357 history loss 8.528846 rank 4
2023-02-11 15:23:42,357 DEBUG CV Batch 7/300 loss 10.566148 loss_att 6.703096 loss_ctc 11.044874 loss_rnnt 5.539070 hw_loss 1.075473 history loss 8.854336 rank 0
2023-02-11 15:23:42,407 DEBUG CV Batch 7/300 loss 10.566148 loss_att 6.703096 loss_ctc 11.044874 loss_rnnt 5.539070 hw_loss 1.075473 history loss 8.854336 rank 7
2023-02-11 15:23:42,530 DEBUG CV Batch 7/300 loss 10.566147 loss_att 6.703096 loss_ctc 11.044874 loss_rnnt 5.539070 hw_loss 1.075473 history loss 8.854336 rank 2
2023-02-11 15:23:42,561 DEBUG CV Batch 7/300 loss 10.566147 loss_att 6.703096 loss_ctc 11.044874 loss_rnnt 5.539070 hw_loss 1.075473 history loss 8.854336 rank 3
2023-02-11 15:23:42,621 DEBUG CV Batch 7/300 loss 10.566147 loss_att 6.703096 loss_ctc 11.044874 loss_rnnt 5.539070 hw_loss 1.075473 history loss 8.854336 rank 5
2023-02-11 15:23:42,946 DEBUG CV Batch 7/300 loss 10.566147 loss_att 6.703096 loss_ctc 11.044874 loss_rnnt 5.539070 hw_loss 1.075473 history loss 8.854336 rank 6
2023-02-11 15:23:43,170 DEBUG CV Batch 7/300 loss 10.566147 loss_att 6.703096 loss_ctc 11.044874 loss_rnnt 5.539070 hw_loss 1.075473 history loss 8.854336 rank 4
2023-02-11 15:23:43,573 DEBUG CV Batch 7/300 loss 10.566147 loss_att 6.703096 loss_ctc 11.044874 loss_rnnt 5.539070 hw_loss 1.075473 history loss 8.854336 rank 1
2023-02-11 15:23:54,300 DEBUG CV Batch 7/400 loss 21.454638 loss_att 95.121185 loss_ctc 18.285875 loss_rnnt 6.299905 hw_loss 0.158236 history loss 9.728358 rank 0
2023-02-11 15:23:54,384 DEBUG CV Batch 7/400 loss 21.454638 loss_att 95.121185 loss_ctc 18.285875 loss_rnnt 6.299905 hw_loss 0.158236 history loss 9.728358 rank 7
2023-02-11 15:23:54,495 DEBUG CV Batch 7/400 loss 21.454638 loss_att 95.121185 loss_ctc 18.285875 loss_rnnt 6.299905 hw_loss 0.158236 history loss 9.728358 rank 3
2023-02-11 15:23:54,600 DEBUG CV Batch 7/400 loss 21.454638 loss_att 95.121185 loss_ctc 18.285875 loss_rnnt 6.299905 hw_loss 0.158236 history loss 9.728358 rank 5
2023-02-11 15:23:54,904 DEBUG CV Batch 7/400 loss 21.454638 loss_att 95.121185 loss_ctc 18.285875 loss_rnnt 6.299905 hw_loss 0.158236 history loss 9.728358 rank 6
2023-02-11 15:23:55,261 DEBUG CV Batch 7/400 loss 21.454638 loss_att 95.121185 loss_ctc 18.285875 loss_rnnt 6.299905 hw_loss 0.158236 history loss 9.728358 rank 4
2023-02-11 15:23:55,390 DEBUG CV Batch 7/400 loss 21.454638 loss_att 95.121185 loss_ctc 18.285875 loss_rnnt 6.299905 hw_loss 0.158236 history loss 9.728358 rank 2
2023-02-11 15:23:55,600 DEBUG CV Batch 7/400 loss 21.454638 loss_att 95.121185 loss_ctc 18.285875 loss_rnnt 6.299905 hw_loss 0.158236 history loss 9.728358 rank 1
2023-02-11 15:24:04,682 DEBUG CV Batch 7/500 loss 9.726750 loss_att 8.410560 loss_ctc 12.076508 loss_rnnt 6.459207 hw_loss 0.603278 history loss 10.443318 rank 0
2023-02-11 15:24:04,801 DEBUG CV Batch 7/500 loss 9.726750 loss_att 8.410560 loss_ctc 12.076508 loss_rnnt 6.459207 hw_loss 0.603278 history loss 10.443318 rank 7
2023-02-11 15:24:04,863 DEBUG CV Batch 7/500 loss 9.726750 loss_att 8.410560 loss_ctc 12.076508 loss_rnnt 6.459207 hw_loss 0.603278 history loss 10.443318 rank 3
2023-02-11 15:24:05,058 DEBUG CV Batch 7/500 loss 9.726750 loss_att 8.410560 loss_ctc 12.076508 loss_rnnt 6.459207 hw_loss 0.603278 history loss 10.443318 rank 5
2023-02-11 15:24:05,405 DEBUG CV Batch 7/500 loss 9.726750 loss_att 8.410560 loss_ctc 12.076508 loss_rnnt 6.459207 hw_loss 0.603278 history loss 10.443318 rank 6
2023-02-11 15:24:05,750 DEBUG CV Batch 7/500 loss 9.726750 loss_att 8.410560 loss_ctc 12.076508 loss_rnnt 6.459207 hw_loss 0.603278 history loss 10.443318 rank 4
2023-02-11 15:24:05,913 DEBUG CV Batch 7/500 loss 9.726750 loss_att 8.410560 loss_ctc 12.076508 loss_rnnt 6.459207 hw_loss 0.603278 history loss 10.443318 rank 2
2023-02-11 15:24:06,745 DEBUG CV Batch 7/500 loss 9.726750 loss_att 8.410560 loss_ctc 12.076508 loss_rnnt 6.459207 hw_loss 0.603278 history loss 10.443318 rank 1
2023-02-11 15:24:16,703 DEBUG CV Batch 7/600 loss 12.801275 loss_att 9.609532 loss_ctc 11.334898 loss_rnnt 7.009229 hw_loss 1.242359 history loss 11.329401 rank 0
2023-02-11 15:24:16,832 DEBUG CV Batch 7/600 loss 12.801275 loss_att 9.609532 loss_ctc 11.334898 loss_rnnt 7.009229 hw_loss 1.242358 history loss 11.329401 rank 7
2023-02-11 15:24:16,962 DEBUG CV Batch 7/600 loss 12.801275 loss_att 9.609532 loss_ctc 11.334898 loss_rnnt 7.009229 hw_loss 1.242359 history loss 11.329401 rank 3
2023-02-11 15:24:17,248 DEBUG CV Batch 7/600 loss 12.801275 loss_att 9.609532 loss_ctc 11.334898 loss_rnnt 7.009229 hw_loss 1.242358 history loss 11.329401 rank 5
2023-02-11 15:24:17,434 DEBUG CV Batch 7/600 loss 12.801275 loss_att 9.609532 loss_ctc 11.334898 loss_rnnt 7.009229 hw_loss 1.242359 history loss 11.329401 rank 6
2023-02-11 15:24:17,854 DEBUG CV Batch 7/600 loss 12.801275 loss_att 9.609532 loss_ctc 11.334898 loss_rnnt 7.009229 hw_loss 1.242359 history loss 11.329401 rank 4
2023-02-11 15:24:18,188 DEBUG CV Batch 7/600 loss 12.801275 loss_att 9.609532 loss_ctc 11.334898 loss_rnnt 7.009229 hw_loss 1.242359 history loss 11.329401 rank 2
2023-02-11 15:24:18,855 DEBUG CV Batch 7/600 loss 12.801275 loss_att 9.609532 loss_ctc 11.334898 loss_rnnt 7.009229 hw_loss 1.242359 history loss 11.329401 rank 1
2023-02-11 15:24:28,105 DEBUG CV Batch 7/700 loss 23.680811 loss_att 66.382858 loss_ctc 35.544319 loss_rnnt 13.441303 hw_loss 0.021993 history loss 11.976109 rank 7
2023-02-11 15:24:28,157 DEBUG CV Batch 7/700 loss 23.680811 loss_att 66.382858 loss_ctc 35.544319 loss_rnnt 13.441303 hw_loss 0.021993 history loss 11.976109 rank 3
2023-02-11 15:24:28,163 DEBUG CV Batch 7/700 loss 23.680811 loss_att 66.382858 loss_ctc 35.544319 loss_rnnt 13.441303 hw_loss 0.021993 history loss 11.976109 rank 0
2023-02-11 15:24:28,644 DEBUG CV Batch 7/700 loss 23.680811 loss_att 66.382858 loss_ctc 35.544319 loss_rnnt 13.441303 hw_loss 0.021993 history loss 11.976109 rank 5
2023-02-11 15:24:29,285 DEBUG CV Batch 7/700 loss 23.680811 loss_att 66.382858 loss_ctc 35.544319 loss_rnnt 13.441303 hw_loss 0.021993 history loss 11.976109 rank 4
2023-02-11 15:24:30,101 DEBUG CV Batch 7/700 loss 23.680811 loss_att 66.382858 loss_ctc 35.544319 loss_rnnt 13.441303 hw_loss 0.021993 history loss 11.976109 rank 2
2023-02-11 15:24:30,171 DEBUG CV Batch 7/700 loss 23.680811 loss_att 66.382858 loss_ctc 35.544319 loss_rnnt 13.441303 hw_loss 0.021993 history loss 11.976109 rank 1
2023-02-11 15:24:30,503 DEBUG CV Batch 7/700 loss 23.680811 loss_att 66.382858 loss_ctc 35.544319 loss_rnnt 13.441303 hw_loss 0.021993 history loss 11.976109 rank 6
2023-02-11 15:24:39,329 DEBUG CV Batch 7/800 loss 14.640310 loss_att 10.118189 loss_ctc 16.601818 loss_rnnt 8.530457 hw_loss 1.266139 history loss 11.438469 rank 7
2023-02-11 15:24:39,868 DEBUG CV Batch 7/800 loss 14.640310 loss_att 10.118189 loss_ctc 16.601818 loss_rnnt 8.530457 hw_loss 1.266139 history loss 11.438469 rank 3
2023-02-11 15:24:39,978 DEBUG CV Batch 7/800 loss 14.640310 loss_att 10.118189 loss_ctc 16.601818 loss_rnnt 8.530457 hw_loss 1.266139 history loss 11.438469 rank 5
2023-02-11 15:24:40,014 DEBUG CV Batch 7/800 loss 14.640311 loss_att 10.118189 loss_ctc 16.601818 loss_rnnt 8.530457 hw_loss 1.266139 history loss 11.438469 rank 0
2023-02-11 15:24:41,379 DEBUG CV Batch 7/800 loss 14.640310 loss_att 10.118189 loss_ctc 16.601818 loss_rnnt 8.530457 hw_loss 1.266139 history loss 11.438469 rank 2
2023-02-11 15:24:41,494 DEBUG CV Batch 7/800 loss 14.640310 loss_att 10.118189 loss_ctc 16.601818 loss_rnnt 8.530457 hw_loss 1.266139 history loss 11.438469 rank 4
2023-02-11 15:24:41,801 DEBUG CV Batch 7/800 loss 14.640310 loss_att 10.118189 loss_ctc 16.601818 loss_rnnt 8.530457 hw_loss 1.266139 history loss 11.438469 rank 1
2023-02-11 15:24:41,858 DEBUG CV Batch 7/800 loss 14.640310 loss_att 10.118189 loss_ctc 16.601818 loss_rnnt 8.530457 hw_loss 1.266139 history loss 11.438469 rank 6
2023-02-11 15:24:52,845 DEBUG CV Batch 7/900 loss 20.791250 loss_att 28.729687 loss_ctc 32.449772 loss_rnnt 15.776615 hw_loss 0.351090 history loss 11.217430 rank 7
2023-02-11 15:24:53,363 DEBUG CV Batch 7/900 loss 20.791250 loss_att 28.729687 loss_ctc 32.449772 loss_rnnt 15.776615 hw_loss 0.351090 history loss 11.217430 rank 3
2023-02-11 15:24:53,645 DEBUG CV Batch 7/900 loss 20.791250 loss_att 28.729687 loss_ctc 32.449772 loss_rnnt 15.776615 hw_loss 0.351090 history loss 11.217430 rank 0
2023-02-11 15:24:53,647 DEBUG CV Batch 7/900 loss 20.791250 loss_att 28.729687 loss_ctc 32.449772 loss_rnnt 15.776615 hw_loss 0.351090 history loss 11.217430 rank 5
2023-02-11 15:24:54,758 DEBUG CV Batch 7/900 loss 20.791250 loss_att 28.729687 loss_ctc 32.449772 loss_rnnt 15.776615 hw_loss 0.351090 history loss 11.217430 rank 2
2023-02-11 15:24:54,861 DEBUG CV Batch 7/900 loss 20.791250 loss_att 28.729687 loss_ctc 32.449772 loss_rnnt 15.776615 hw_loss 0.351090 history loss 11.217430 rank 4
2023-02-11 15:24:55,307 DEBUG CV Batch 7/900 loss 20.791250 loss_att 28.729687 loss_ctc 32.449772 loss_rnnt 15.776615 hw_loss 0.351090 history loss 11.217430 rank 6
2023-02-11 15:24:56,313 DEBUG CV Batch 7/900 loss 20.791250 loss_att 28.729687 loss_ctc 32.449772 loss_rnnt 15.776615 hw_loss 0.351090 history loss 11.217430 rank 1
2023-02-11 15:25:04,979 DEBUG CV Batch 7/1000 loss 9.078917 loss_att 6.080380 loss_ctc 7.163377 loss_rnnt 4.638161 hw_loss 0.992975 history loss 11.043170 rank 7
2023-02-11 15:25:05,543 DEBUG CV Batch 7/1000 loss 9.078916 loss_att 6.080380 loss_ctc 7.163377 loss_rnnt 4.638161 hw_loss 0.992975 history loss 11.043170 rank 3
2023-02-11 15:25:05,746 DEBUG CV Batch 7/1000 loss 9.078917 loss_att 6.080380 loss_ctc 7.163377 loss_rnnt 4.638161 hw_loss 0.992975 history loss 11.043170 rank 0
2023-02-11 15:25:05,838 DEBUG CV Batch 7/1000 loss 9.078916 loss_att 6.080380 loss_ctc 7.163377 loss_rnnt 4.638161 hw_loss 0.992975 history loss 11.043170 rank 5
2023-02-11 15:25:07,003 DEBUG CV Batch 7/1000 loss 9.078917 loss_att 6.080380 loss_ctc 7.163377 loss_rnnt 4.638161 hw_loss 0.992975 history loss 11.043170 rank 2
2023-02-11 15:25:07,126 DEBUG CV Batch 7/1000 loss 9.078917 loss_att 6.080380 loss_ctc 7.163377 loss_rnnt 4.638161 hw_loss 0.992975 history loss 11.043170 rank 4
2023-02-11 15:25:07,462 DEBUG CV Batch 7/1000 loss 9.078917 loss_att 6.080380 loss_ctc 7.163377 loss_rnnt 4.638161 hw_loss 0.992975 history loss 11.043170 rank 6
2023-02-11 15:25:08,580 DEBUG CV Batch 7/1000 loss 9.078917 loss_att 6.080380 loss_ctc 7.163377 loss_rnnt 4.638161 hw_loss 0.992975 history loss 11.043170 rank 1
2023-02-11 15:25:16,863 DEBUG CV Batch 7/1100 loss 10.236786 loss_att 6.056121 loss_ctc 10.568147 loss_rnnt 4.702720 hw_loss 1.186128 history loss 11.005094 rank 7
2023-02-11 15:25:17,391 DEBUG CV Batch 7/1100 loss 10.236787 loss_att 6.056121 loss_ctc 10.568147 loss_rnnt 4.702720 hw_loss 1.186128 history loss 11.005094 rank 3
2023-02-11 15:25:17,569 DEBUG CV Batch 7/1100 loss 10.236786 loss_att 6.056121 loss_ctc 10.568147 loss_rnnt 4.702720 hw_loss 1.186128 history loss 11.005094 rank 0
2023-02-11 15:25:17,678 DEBUG CV Batch 7/1100 loss 10.236786 loss_att 6.056121 loss_ctc 10.568147 loss_rnnt 4.702720 hw_loss 1.186128 history loss 11.005094 rank 5
2023-02-11 15:25:18,919 DEBUG CV Batch 7/1100 loss 10.236786 loss_att 6.056121 loss_ctc 10.568147 loss_rnnt 4.702720 hw_loss 1.186128 history loss 11.005094 rank 2
2023-02-11 15:25:19,390 DEBUG CV Batch 7/1100 loss 10.236786 loss_att 6.056121 loss_ctc 10.568147 loss_rnnt 4.702720 hw_loss 1.186128 history loss 11.005094 rank 6
2023-02-11 15:25:20,020 DEBUG CV Batch 7/1100 loss 10.236786 loss_att 6.056121 loss_ctc 10.568147 loss_rnnt 4.702720 hw_loss 1.186128 history loss 11.005094 rank 4
2023-02-11 15:25:20,523 DEBUG CV Batch 7/1100 loss 10.236786 loss_att 6.056121 loss_ctc 10.568147 loss_rnnt 4.702720 hw_loss 1.186128 history loss 11.005094 rank 1
2023-02-11 15:25:27,297 DEBUG CV Batch 7/1200 loss 10.281380 loss_att 9.888550 loss_ctc 11.177608 loss_rnnt 6.685835 hw_loss 0.666490 history loss 11.329193 rank 7
2023-02-11 15:25:27,833 DEBUG CV Batch 7/1200 loss 10.281380 loss_att 9.888550 loss_ctc 11.177608 loss_rnnt 6.685835 hw_loss 0.666490 history loss 11.329193 rank 3
2023-02-11 15:25:28,017 DEBUG CV Batch 7/1200 loss 10.281380 loss_att 9.888550 loss_ctc 11.177608 loss_rnnt 6.685835 hw_loss 0.666490 history loss 11.329193 rank 0
2023-02-11 15:25:28,113 DEBUG CV Batch 7/1200 loss 10.281380 loss_att 9.888550 loss_ctc 11.177608 loss_rnnt 6.685835 hw_loss 0.666490 history loss 11.329193 rank 5
2023-02-11 15:25:29,437 DEBUG CV Batch 7/1200 loss 10.281380 loss_att 9.888550 loss_ctc 11.177608 loss_rnnt 6.685835 hw_loss 0.666490 history loss 11.329193 rank 2
2023-02-11 15:25:30,551 DEBUG CV Batch 7/1200 loss 10.281380 loss_att 9.888550 loss_ctc 11.177608 loss_rnnt 6.685835 hw_loss 0.666490 history loss 11.329193 rank 4
2023-02-11 15:25:30,638 DEBUG CV Batch 7/1200 loss 10.281380 loss_att 9.888550 loss_ctc 11.177608 loss_rnnt 6.685835 hw_loss 0.666490 history loss 11.329193 rank 6
2023-02-11 15:25:31,045 DEBUG CV Batch 7/1200 loss 10.281380 loss_att 9.888550 loss_ctc 11.177608 loss_rnnt 6.685835 hw_loss 0.666490 history loss 11.329193 rank 1
2023-02-11 15:25:39,240 DEBUG CV Batch 7/1300 loss 9.227369 loss_att 5.974244 loss_ctc 8.795456 loss_rnnt 5.189437 hw_loss 0.889902 history loss 11.592178 rank 7
2023-02-11 15:25:39,793 DEBUG CV Batch 7/1300 loss 9.227369 loss_att 5.974244 loss_ctc 8.795456 loss_rnnt 5.189437 hw_loss 0.889902 history loss 11.592178 rank 3
2023-02-11 15:25:39,814 DEBUG CV Batch 7/1300 loss 9.227369 loss_att 5.974244 loss_ctc 8.795456 loss_rnnt 5.189437 hw_loss 0.889902 history loss 11.592178 rank 0
2023-02-11 15:25:40,018 DEBUG CV Batch 7/1300 loss 9.227369 loss_att 5.974244 loss_ctc 8.795456 loss_rnnt 5.189437 hw_loss 0.889902 history loss 11.592178 rank 5
2023-02-11 15:25:41,412 DEBUG CV Batch 7/1300 loss 9.227368 loss_att 5.974244 loss_ctc 8.795456 loss_rnnt 5.189437 hw_loss 0.889902 history loss 11.592178 rank 2
2023-02-11 15:25:42,533 DEBUG CV Batch 7/1300 loss 9.227369 loss_att 5.974244 loss_ctc 8.795456 loss_rnnt 5.189437 hw_loss 0.889902 history loss 11.592178 rank 4
2023-02-11 15:25:42,620 DEBUG CV Batch 7/1300 loss 9.227368 loss_att 5.974244 loss_ctc 8.795456 loss_rnnt 5.189437 hw_loss 0.889902 history loss 11.592178 rank 6
2023-02-11 15:25:42,961 DEBUG CV Batch 7/1300 loss 9.227369 loss_att 5.974244 loss_ctc 8.795456 loss_rnnt 5.189437 hw_loss 0.889902 history loss 11.592178 rank 1
2023-02-11 15:25:50,404 DEBUG CV Batch 7/1400 loss 16.074471 loss_att 46.259262 loss_ctc 20.247431 loss_rnnt 8.452324 hw_loss 0.192899 history loss 11.913623 rank 7
2023-02-11 15:25:50,986 DEBUG CV Batch 7/1400 loss 16.074471 loss_att 46.259262 loss_ctc 20.247431 loss_rnnt 8.452324 hw_loss 0.192899 history loss 11.913623 rank 3
2023-02-11 15:25:51,014 DEBUG CV Batch 7/1400 loss 16.074471 loss_att 46.259262 loss_ctc 20.247431 loss_rnnt 8.452324 hw_loss 0.192899 history loss 11.913623 rank 0
2023-02-11 15:25:51,234 DEBUG CV Batch 7/1400 loss 16.074471 loss_att 46.259262 loss_ctc 20.247431 loss_rnnt 8.452324 hw_loss 0.192899 history loss 11.913623 rank 5
2023-02-11 15:25:52,546 DEBUG CV Batch 7/1400 loss 16.074471 loss_att 46.259262 loss_ctc 20.247431 loss_rnnt 8.452324 hw_loss 0.192899 history loss 11.913623 rank 2
2023-02-11 15:25:53,787 DEBUG CV Batch 7/1400 loss 16.074471 loss_att 46.259262 loss_ctc 20.247431 loss_rnnt 8.452324 hw_loss 0.192899 history loss 11.913623 rank 4
2023-02-11 15:25:53,809 DEBUG CV Batch 7/1400 loss 16.074471 loss_att 46.259262 loss_ctc 20.247431 loss_rnnt 8.452324 hw_loss 0.192899 history loss 11.913623 rank 6
2023-02-11 15:25:54,110 DEBUG CV Batch 7/1400 loss 16.074471 loss_att 46.259262 loss_ctc 20.247431 loss_rnnt 8.452324 hw_loss 0.192899 history loss 11.913623 rank 1
2023-02-11 15:26:01,847 DEBUG CV Batch 7/1500 loss 12.079054 loss_att 10.204357 loss_ctc 9.706578 loss_rnnt 9.309860 hw_loss 0.648837 history loss 11.734010 rank 7
2023-02-11 15:26:02,340 DEBUG CV Batch 7/1500 loss 12.079054 loss_att 10.204357 loss_ctc 9.706578 loss_rnnt 9.309860 hw_loss 0.648837 history loss 11.734010 rank 0
2023-02-11 15:26:02,743 DEBUG CV Batch 7/1500 loss 12.079054 loss_att 10.204357 loss_ctc 9.706578 loss_rnnt 9.309860 hw_loss 0.648837 history loss 11.734010 rank 5
2023-02-11 15:26:03,121 DEBUG CV Batch 7/1500 loss 12.079054 loss_att 10.204357 loss_ctc 9.706578 loss_rnnt 9.309860 hw_loss 0.648837 history loss 11.734010 rank 3
2023-02-11 15:26:04,800 DEBUG CV Batch 7/1500 loss 12.079054 loss_att 10.204357 loss_ctc 9.706578 loss_rnnt 9.309860 hw_loss 0.648837 history loss 11.734010 rank 2
2023-02-11 15:26:05,465 DEBUG CV Batch 7/1500 loss 12.079054 loss_att 10.204357 loss_ctc 9.706578 loss_rnnt 9.309860 hw_loss 0.648837 history loss 11.734010 rank 4
2023-02-11 15:26:05,474 DEBUG CV Batch 7/1500 loss 12.079054 loss_att 10.204357 loss_ctc 9.706578 loss_rnnt 9.309860 hw_loss 0.648837 history loss 11.734010 rank 1
2023-02-11 15:26:06,116 DEBUG CV Batch 7/1500 loss 12.079054 loss_att 10.204357 loss_ctc 9.706578 loss_rnnt 9.309860 hw_loss 0.648837 history loss 11.734010 rank 6
2023-02-11 15:26:15,575 DEBUG CV Batch 7/1600 loss 9.985106 loss_att 20.388565 loss_ctc 14.752811 loss_rnnt 5.210826 hw_loss 0.385855 history loss 11.632862 rank 7
2023-02-11 15:26:15,735 DEBUG CV Batch 7/1600 loss 9.985106 loss_att 20.388565 loss_ctc 14.752811 loss_rnnt 5.210826 hw_loss 0.385855 history loss 11.632862 rank 0
2023-02-11 15:26:16,173 DEBUG CV Batch 7/1600 loss 9.985106 loss_att 20.388565 loss_ctc 14.752811 loss_rnnt 5.210826 hw_loss 0.385855 history loss 11.632862 rank 5
2023-02-11 15:26:16,487 DEBUG CV Batch 7/1600 loss 9.985106 loss_att 20.388565 loss_ctc 14.752811 loss_rnnt 5.210826 hw_loss 0.385855 history loss 11.632862 rank 3
2023-02-11 15:26:17,944 DEBUG CV Batch 7/1600 loss 9.985106 loss_att 20.388565 loss_ctc 14.752811 loss_rnnt 5.210826 hw_loss 0.385855 history loss 11.632862 rank 2
2023-02-11 15:26:18,552 DEBUG CV Batch 7/1600 loss 9.985106 loss_att 20.388565 loss_ctc 14.752811 loss_rnnt 5.210826 hw_loss 0.385855 history loss 11.632862 rank 1
2023-02-11 15:26:18,751 DEBUG CV Batch 7/1600 loss 9.985106 loss_att 20.388565 loss_ctc 14.752811 loss_rnnt 5.210826 hw_loss 0.385855 history loss 11.632862 rank 4
2023-02-11 15:26:19,629 DEBUG CV Batch 7/1600 loss 9.985106 loss_att 20.388565 loss_ctc 14.752811 loss_rnnt 5.210826 hw_loss 0.385855 history loss 11.632862 rank 6
2023-02-11 15:26:28,123 DEBUG CV Batch 7/1700 loss 14.100683 loss_att 11.887220 loss_ctc 18.078999 loss_rnnt 9.039330 hw_loss 0.932551 history loss 11.560072 rank 7
2023-02-11 15:26:28,280 DEBUG CV Batch 7/1700 loss 14.100683 loss_att 11.887220 loss_ctc 18.078999 loss_rnnt 9.039330 hw_loss 0.932551 history loss 11.560072 rank 0
2023-02-11 15:26:28,687 DEBUG CV Batch 7/1700 loss 14.100683 loss_att 11.887220 loss_ctc 18.078999 loss_rnnt 9.039330 hw_loss 0.932551 history loss 11.560071 rank 5
2023-02-11 15:26:28,970 DEBUG CV Batch 7/1700 loss 14.100683 loss_att 11.887220 loss_ctc 18.078999 loss_rnnt 9.039330 hw_loss 0.932551 history loss 11.560072 rank 3
2023-02-11 15:26:30,420 DEBUG CV Batch 7/1700 loss 14.100683 loss_att 11.887220 loss_ctc 18.078999 loss_rnnt 9.039330 hw_loss 0.932551 history loss 11.560072 rank 2
2023-02-11 15:26:31,005 DEBUG CV Batch 7/1700 loss 14.100683 loss_att 11.887220 loss_ctc 18.078999 loss_rnnt 9.039330 hw_loss 0.932551 history loss 11.560072 rank 1
2023-02-11 15:26:31,307 DEBUG CV Batch 7/1700 loss 14.100683 loss_att 11.887220 loss_ctc 18.078999 loss_rnnt 9.039330 hw_loss 0.932551 history loss 11.560072 rank 4
2023-02-11 15:26:32,531 DEBUG CV Batch 7/1700 loss 14.100683 loss_att 11.887220 loss_ctc 18.078999 loss_rnnt 9.039330 hw_loss 0.932551 history loss 11.560072 rank 6
2023-02-11 15:26:37,337 INFO Epoch 7 CV info cv_loss 11.511197528220237
2023-02-11 15:26:37,338 INFO Epoch 8 TRAIN info lr 0.0006123157991036987
2023-02-11 15:26:37,342 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 15:26:37,436 INFO Epoch 7 CV info cv_loss 11.511197517693155
2023-02-11 15:26:37,437 INFO Checkpoint: save to checkpoint exp2_10_rnnt_bias_loss/7.pt
2023-02-11 15:26:37,792 INFO Epoch 7 CV info cv_loss 11.511197489764514
2023-02-11 15:26:37,793 INFO Epoch 8 TRAIN info lr 0.0006120496646061483
2023-02-11 15:26:37,797 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 15:26:38,041 INFO Epoch 7 CV info cv_loss 11.51119750539146
2023-02-11 15:26:38,042 INFO Epoch 8 TRAIN info lr 0.0006124352135227091
2023-02-11 15:26:38,045 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 15:26:38,114 INFO Epoch 8 TRAIN info lr 0.0006119488077768228
2023-02-11 15:26:38,117 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 15:26:39,586 INFO Epoch 7 CV info cv_loss 11.511197505977254
2023-02-11 15:26:39,587 INFO Epoch 8 TRAIN info lr 0.0006118617442640643
2023-02-11 15:26:39,590 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 15:26:40,133 INFO Epoch 7 CV info cv_loss 11.511197518554617
2023-02-11 15:26:40,134 INFO Epoch 8 TRAIN info lr 0.0006120909385934907
2023-02-11 15:26:40,138 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 15:26:40,464 INFO Epoch 7 CV info cv_loss 11.51119750794139
2023-02-11 15:26:40,465 INFO Epoch 8 TRAIN info lr 0.0006123203906744066
2023-02-11 15:26:40,469 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 15:26:42,600 INFO Epoch 7 CV info cv_loss 11.511197513902717
2023-02-11 15:26:42,601 INFO Epoch 8 TRAIN info lr 0.0006122607083107216
2023-02-11 15:26:42,604 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 15:27:56,325 DEBUG TRAIN Batch 8/0 loss 12.354433 loss_att 8.864397 loss_ctc 14.565145 loss_rnnt 8.555143 hw_loss 0.787975 lr 0.00061243 rank 3
2023-02-11 15:27:56,327 DEBUG TRAIN Batch 8/0 loss 16.761591 loss_att 12.528918 loss_ctc 19.783016 loss_rnnt 12.261312 hw_loss 0.926992 lr 0.00061209 rank 1
2023-02-11 15:27:56,331 DEBUG TRAIN Batch 8/0 loss 16.560925 loss_att 11.467525 loss_ctc 14.521106 loss_rnnt 11.312610 hw_loss 1.226057 lr 0.00061194 rank 0
2023-02-11 15:27:56,333 DEBUG TRAIN Batch 8/0 loss 13.474129 loss_att 9.887066 loss_ctc 13.323803 loss_rnnt 10.121349 hw_loss 0.766919 lr 0.00061232 rank 4
2023-02-11 15:27:56,334 DEBUG TRAIN Batch 8/0 loss 13.781588 loss_att 9.965179 loss_ctc 14.838298 loss_rnnt 9.556884 hw_loss 0.908830 lr 0.00061231 rank 7
2023-02-11 15:27:56,334 DEBUG TRAIN Batch 8/0 loss 16.121881 loss_att 11.873369 loss_ctc 17.675911 loss_rnnt 11.373055 hw_loss 1.010873 lr 0.00061186 rank 2
2023-02-11 15:27:56,335 DEBUG TRAIN Batch 8/0 loss 15.609839 loss_att 11.614030 loss_ctc 16.053816 loss_rnnt 11.951309 hw_loss 0.824718 lr 0.00061205 rank 5
2023-02-11 15:27:56,400 DEBUG TRAIN Batch 8/0 loss 11.620693 loss_att 9.289383 loss_ctc 12.278884 loss_rnnt 8.399053 hw_loss 0.675027 lr 0.00061226 rank 6
2023-02-11 15:29:11,992 DEBUG TRAIN Batch 8/100 loss 10.075061 loss_att 15.571010 loss_ctc 14.355189 loss_rnnt 7.008424 hw_loss 0.261893 lr 0.00061180 rank 6
2023-02-11 15:29:11,992 DEBUG TRAIN Batch 8/100 loss 17.829506 loss_att 21.976006 loss_ctc 28.003920 loss_rnnt 13.004868 hw_loss 0.494765 lr 0.00061186 rank 4
2023-02-11 15:29:11,995 DEBUG TRAIN Batch 8/100 loss 13.824835 loss_att 19.347206 loss_ctc 20.680054 loss_rnnt 10.098919 hw_loss 0.320140 lr 0.00061185 rank 7
2023-02-11 15:29:11,995 DEBUG TRAIN Batch 8/100 loss 26.885466 loss_att 31.772739 loss_ctc 38.404053 loss_rnnt 21.106741 hw_loss 0.612274 lr 0.00061159 rank 5
2023-02-11 15:29:11,996 DEBUG TRAIN Batch 8/100 loss 10.478311 loss_att 12.121945 loss_ctc 12.763977 loss_rnnt 7.189682 hw_loss 0.497840 lr 0.00061163 rank 1
2023-02-11 15:29:11,997 DEBUG TRAIN Batch 8/100 loss 26.095345 loss_att 26.853413 loss_ctc 39.030895 loss_rnnt 22.811865 hw_loss 0.263836 lr 0.00061197 rank 3
2023-02-11 15:29:11,998 DEBUG TRAIN Batch 8/100 loss 10.022074 loss_att 12.873419 loss_ctc 17.078403 loss_rnnt 6.502510 hw_loss 0.376585 lr 0.00061149 rank 0
2023-02-11 15:29:11,999 DEBUG TRAIN Batch 8/100 loss 21.861494 loss_att 29.565359 loss_ctc 38.545662 loss_rnnt 16.407375 hw_loss 0.316648 lr 0.00061140 rank 2
2023-02-11 15:30:26,452 DEBUG TRAIN Batch 8/200 loss 28.904797 loss_att 34.362305 loss_ctc 44.976265 loss_rnnt 23.788105 hw_loss 0.352936 lr 0.00061151 rank 3
2023-02-11 15:30:26,456 DEBUG TRAIN Batch 8/200 loss 23.398890 loss_att 26.807137 loss_ctc 35.668324 loss_rnnt 19.399284 hw_loss 0.315381 lr 0.00061117 rank 1
2023-02-11 15:30:26,456 DEBUG TRAIN Batch 8/200 loss 12.522373 loss_att 13.385645 loss_ctc 20.178417 loss_rnnt 7.065365 hw_loss 0.799415 lr 0.00061103 rank 0
2023-02-11 15:30:26,456 DEBUG TRAIN Batch 8/200 loss 23.335571 loss_att 27.863155 loss_ctc 39.664700 loss_rnnt 18.114357 hw_loss 0.400965 lr 0.00061140 rank 4
2023-02-11 15:30:26,457 DEBUG TRAIN Batch 8/200 loss 21.214138 loss_att 29.018288 loss_ctc 43.977291 loss_rnnt 14.045993 hw_loss 0.482293 lr 0.00061113 rank 5
2023-02-11 15:30:26,457 DEBUG TRAIN Batch 8/200 loss 15.862645 loss_att 18.912590 loss_ctc 25.979521 loss_rnnt 12.886623 hw_loss 0.190709 lr 0.00061139 rank 7
2023-02-11 15:30:26,458 DEBUG TRAIN Batch 8/200 loss 19.285658 loss_att 20.550011 loss_ctc 25.172537 loss_rnnt 15.278879 hw_loss 0.556686 lr 0.00061134 rank 6
2023-02-11 15:30:26,504 DEBUG TRAIN Batch 8/200 loss 12.707680 loss_att 10.575387 loss_ctc 14.449091 loss_rnnt 9.102258 hw_loss 0.712442 lr 0.00061094 rank 2
2023-02-11 15:31:44,072 DEBUG TRAIN Batch 8/300 loss 23.196274 loss_att 24.647282 loss_ctc 36.830299 loss_rnnt 18.281504 hw_loss 0.526256 lr 0.00061072 rank 1
2023-02-11 15:31:44,074 DEBUG TRAIN Batch 8/300 loss 14.266714 loss_att 13.288181 loss_ctc 12.691883 loss_rnnt 10.886145 hw_loss 0.709923 lr 0.00061088 rank 6
2023-02-11 15:31:44,078 DEBUG TRAIN Batch 8/300 loss 25.539894 loss_att 30.862951 loss_ctc 38.799034 loss_rnnt 21.756325 hw_loss 0.178326 lr 0.00061049 rank 2
2023-02-11 15:31:44,078 DEBUG TRAIN Batch 8/300 loss 16.762087 loss_att 19.452560 loss_ctc 21.875111 loss_rnnt 14.685200 hw_loss 0.160698 lr 0.00061094 rank 7
2023-02-11 15:31:44,078 DEBUG TRAIN Batch 8/300 loss 15.858829 loss_att 17.206762 loss_ctc 27.213055 loss_rnnt 11.968134 hw_loss 0.395102 lr 0.00061057 rank 0
2023-02-11 15:31:44,079 DEBUG TRAIN Batch 8/300 loss 16.410789 loss_att 17.993067 loss_ctc 21.384645 loss_rnnt 12.117361 hw_loss 0.621336 lr 0.00061094 rank 4
2023-02-11 15:31:44,081 DEBUG TRAIN Batch 8/300 loss 19.603451 loss_att 24.105938 loss_ctc 34.030849 loss_rnnt 14.515686 hw_loss 0.424427 lr 0.00061106 rank 3
2023-02-11 15:31:44,084 DEBUG TRAIN Batch 8/300 loss 14.449598 loss_att 17.429531 loss_ctc 21.268410 loss_rnnt 9.999034 hw_loss 0.552263 lr 0.00061067 rank 5
2023-02-11 15:33:02,096 DEBUG TRAIN Batch 8/400 loss 21.901764 loss_att 22.771034 loss_ctc 34.486584 loss_rnnt 17.234510 hw_loss 0.527892 lr 0.00061060 rank 3
2023-02-11 15:33:02,099 DEBUG TRAIN Batch 8/400 loss 19.046082 loss_att 21.659573 loss_ctc 33.790348 loss_rnnt 15.041735 hw_loss 0.284202 lr 0.00061022 rank 5
2023-02-11 15:33:02,101 DEBUG TRAIN Batch 8/400 loss 17.973253 loss_att 18.129951 loss_ctc 25.311039 loss_rnnt 14.142435 hw_loss 0.528957 lr 0.00061026 rank 1
2023-02-11 15:33:02,102 DEBUG TRAIN Batch 8/400 loss 18.270893 loss_att 18.218679 loss_ctc 25.216114 loss_rnnt 12.814466 hw_loss 0.851407 lr 0.00061003 rank 2
2023-02-11 15:33:02,101 DEBUG TRAIN Batch 8/400 loss 17.577232 loss_att 22.084387 loss_ctc 26.985825 loss_rnnt 14.138063 hw_loss 0.240611 lr 0.00061012 rank 0
2023-02-11 15:33:02,104 DEBUG TRAIN Batch 8/400 loss 17.148474 loss_att 21.326521 loss_ctc 29.371700 loss_rnnt 12.513906 hw_loss 0.406724 lr 0.00061048 rank 7
2023-02-11 15:33:02,104 DEBUG TRAIN Batch 8/400 loss 20.789070 loss_att 27.711864 loss_ctc 33.942245 loss_rnnt 15.623623 hw_loss 0.380087 lr 0.00061043 rank 6
2023-02-11 15:33:02,145 DEBUG TRAIN Batch 8/400 loss 15.448994 loss_att 16.878399 loss_ctc 23.908279 loss_rnnt 12.982586 hw_loss 0.197367 lr 0.00061049 rank 4
2023-02-11 15:34:18,297 DEBUG TRAIN Batch 8/500 loss 30.924187 loss_att 32.540134 loss_ctc 47.708641 loss_rnnt 25.471664 hw_loss 0.542138 lr 0.00061015 rank 3
2023-02-11 15:34:18,298 DEBUG TRAIN Batch 8/500 loss 25.630131 loss_att 25.672585 loss_ctc 38.937683 loss_rnnt 21.276632 hw_loss 0.482000 lr 0.00061003 rank 4
2023-02-11 15:34:18,300 DEBUG TRAIN Batch 8/500 loss 12.054333 loss_att 15.275604 loss_ctc 20.044149 loss_rnnt 7.520898 hw_loss 0.529476 lr 0.00060981 rank 1
2023-02-11 15:34:18,300 DEBUG TRAIN Batch 8/500 loss 13.713158 loss_att 18.377148 loss_ctc 22.224024 loss_rnnt 9.665361 hw_loss 0.371291 lr 0.00060967 rank 0
2023-02-11 15:34:18,301 DEBUG TRAIN Batch 8/500 loss 15.280454 loss_att 15.594136 loss_ctc 19.077658 loss_rnnt 14.137571 hw_loss 0.107597 lr 0.00060958 rank 2
2023-02-11 15:34:18,301 DEBUG TRAIN Batch 8/500 loss 10.273484 loss_att 11.977638 loss_ctc 13.368862 loss_rnnt 8.431955 hw_loss 0.203996 lr 0.00060977 rank 5
2023-02-11 15:34:18,302 DEBUG TRAIN Batch 8/500 loss 10.485703 loss_att 15.666713 loss_ctc 18.861534 loss_rnnt 6.466887 hw_loss 0.349844 lr 0.00061003 rank 7
2023-02-11 15:34:18,342 DEBUG TRAIN Batch 8/500 loss 14.396235 loss_att 15.566004 loss_ctc 23.321430 loss_rnnt 11.518427 hw_loss 0.272593 lr 0.00060997 rank 6
2023-02-11 15:35:34,914 DEBUG TRAIN Batch 8/600 loss 14.749701 loss_att 13.558666 loss_ctc 21.278778 loss_rnnt 9.193523 hw_loss 0.923220 lr 0.00060957 rank 7
2023-02-11 15:35:34,914 DEBUG TRAIN Batch 8/600 loss 15.777704 loss_att 17.056742 loss_ctc 24.529755 loss_rnnt 10.759636 hw_loss 0.674123 lr 0.00060921 rank 0
2023-02-11 15:35:34,915 DEBUG TRAIN Batch 8/600 loss 15.274862 loss_att 14.226234 loss_ctc 19.454924 loss_rnnt 10.093797 hw_loss 0.906272 lr 0.00060952 rank 6
2023-02-11 15:35:34,918 DEBUG TRAIN Batch 8/600 loss 17.375736 loss_att 13.557789 loss_ctc 18.110249 loss_rnnt 10.883463 hw_loss 1.342112 lr 0.00060931 rank 5
2023-02-11 15:35:34,921 DEBUG TRAIN Batch 8/600 loss 15.284129 loss_att 12.819690 loss_ctc 17.380501 loss_rnnt 9.251526 hw_loss 1.171120 lr 0.00060969 rank 3
2023-02-11 15:35:34,924 DEBUG TRAIN Batch 8/600 loss 16.070477 loss_att 14.756968 loss_ctc 16.231695 loss_rnnt 11.927254 hw_loss 0.822080 lr 0.00060913 rank 2
2023-02-11 15:35:34,929 DEBUG TRAIN Batch 8/600 loss 18.446411 loss_att 16.542549 loss_ctc 25.415998 loss_rnnt 13.772677 hw_loss 0.773480 lr 0.00060935 rank 1
2023-02-11 15:35:34,977 DEBUG TRAIN Batch 8/600 loss 12.195579 loss_att 12.191902 loss_ctc 18.420317 loss_rnnt 8.624969 hw_loss 0.514009 lr 0.00060958 rank 4
2023-02-11 15:36:53,709 DEBUG TRAIN Batch 8/700 loss 17.060074 loss_att 16.350956 loss_ctc 24.747038 loss_rnnt 13.622007 hw_loss 0.479055 lr 0.00060868 rank 2
2023-02-11 15:36:53,711 DEBUG TRAIN Batch 8/700 loss 23.435179 loss_att 22.634617 loss_ctc 28.940826 loss_rnnt 21.357994 hw_loss 0.281852 lr 0.00060890 rank 1
2023-02-11 15:36:53,712 DEBUG TRAIN Batch 8/700 loss 9.432341 loss_att 12.062588 loss_ctc 11.823730 loss_rnnt 6.913237 hw_loss 0.313913 lr 0.00060924 rank 3
2023-02-11 15:36:53,711 DEBUG TRAIN Batch 8/700 loss 14.110248 loss_att 22.745949 loss_ctc 25.128508 loss_rnnt 9.362040 hw_loss 0.290994 lr 0.00060912 rank 7
2023-02-11 15:36:53,712 DEBUG TRAIN Batch 8/700 loss 31.314337 loss_att 33.253731 loss_ctc 40.098766 loss_rnnt 27.278210 hw_loss 0.464436 lr 0.00060876 rank 0
2023-02-11 15:36:53,715 DEBUG TRAIN Batch 8/700 loss 18.742939 loss_att 19.561384 loss_ctc 27.198299 loss_rnnt 15.009336 hw_loss 0.457975 lr 0.00060913 rank 4
2023-02-11 15:36:53,725 DEBUG TRAIN Batch 8/700 loss 12.751207 loss_att 17.576359 loss_ctc 17.478149 loss_rnnt 7.714867 hw_loss 0.645197 lr 0.00060907 rank 6
2023-02-11 15:36:53,727 DEBUG TRAIN Batch 8/700 loss 21.484108 loss_att 27.189470 loss_ctc 30.334679 loss_rnnt 17.281439 hw_loss 0.352785 lr 0.00060886 rank 5
2023-02-11 15:38:08,374 DEBUG TRAIN Batch 8/800 loss 5.616038 loss_att 10.316327 loss_ctc 13.630264 loss_rnnt 2.656137 hw_loss 0.178365 lr 0.00060845 rank 1
2023-02-11 15:38:08,377 DEBUG TRAIN Batch 8/800 loss 18.428442 loss_att 19.665365 loss_ctc 23.602718 loss_rnnt 13.959455 hw_loss 0.662194 lr 0.00060868 rank 4
2023-02-11 15:38:08,378 DEBUG TRAIN Batch 8/800 loss 11.019849 loss_att 12.891813 loss_ctc 17.437481 loss_rnnt 6.816041 hw_loss 0.557574 lr 0.00060841 rank 5
2023-02-11 15:38:08,378 DEBUG TRAIN Batch 8/800 loss 33.349548 loss_att 40.155052 loss_ctc 43.179581 loss_rnnt 29.850157 hw_loss 0.155178 lr 0.00060867 rank 7
2023-02-11 15:38:08,380 DEBUG TRAIN Batch 8/800 loss 13.560102 loss_att 17.521814 loss_ctc 25.191885 loss_rnnt 10.118605 hw_loss 0.205922 lr 0.00060862 rank 6
2023-02-11 15:38:08,381 DEBUG TRAIN Batch 8/800 loss 12.056903 loss_att 11.401114 loss_ctc 13.377064 loss_rnnt 7.904149 hw_loss 0.770229 lr 0.00060822 rank 2
2023-02-11 15:38:08,412 DEBUG TRAIN Batch 8/800 loss 19.116938 loss_att 23.311443 loss_ctc 26.380180 loss_rnnt 14.215529 hw_loss 0.580139 lr 0.00060831 rank 0
2023-02-11 15:38:08,416 DEBUG TRAIN Batch 8/800 loss 19.340258 loss_att 24.926706 loss_ctc 30.029587 loss_rnnt 13.488116 hw_loss 0.620552 lr 0.00060879 rank 3
2023-02-11 15:39:22,811 DEBUG TRAIN Batch 8/900 loss 29.798008 loss_att 33.066162 loss_ctc 38.755165 loss_rnnt 26.423080 hw_loss 0.286314 lr 0.00060834 rank 3
2023-02-11 15:39:22,816 DEBUG TRAIN Batch 8/900 loss 25.235788 loss_att 27.213779 loss_ctc 33.551250 loss_rnnt 21.030907 hw_loss 0.506354 lr 0.00060822 rank 7
2023-02-11 15:39:22,816 DEBUG TRAIN Batch 8/900 loss 17.150635 loss_att 26.253925 loss_ctc 29.507673 loss_rnnt 12.608711 hw_loss 0.201311 lr 0.00060822 rank 4
2023-02-11 15:39:22,816 DEBUG TRAIN Batch 8/900 loss 18.488214 loss_att 22.847340 loss_ctc 32.549744 loss_rnnt 13.318019 hw_loss 0.454406 lr 0.00060786 rank 0
2023-02-11 15:39:22,816 DEBUG TRAIN Batch 8/900 loss 16.384764 loss_att 17.930418 loss_ctc 25.479628 loss_rnnt 14.034782 hw_loss 0.155288 lr 0.00060778 rank 2
2023-02-11 15:39:22,817 DEBUG TRAIN Batch 8/900 loss 41.932781 loss_att 53.204277 loss_ctc 74.264847 loss_rnnt 34.105736 hw_loss 0.236589 lr 0.00060817 rank 6
2023-02-11 15:39:22,820 DEBUG TRAIN Batch 8/900 loss 19.171625 loss_att 21.746765 loss_ctc 27.069189 loss_rnnt 16.806135 hw_loss 0.149523 lr 0.00060796 rank 5
2023-02-11 15:39:22,862 DEBUG TRAIN Batch 8/900 loss 27.134298 loss_att 27.164965 loss_ctc 38.465179 loss_rnnt 22.367188 hw_loss 0.609411 lr 0.00060800 rank 1
2023-02-11 15:40:38,801 DEBUG TRAIN Batch 8/1000 loss 31.329451 loss_att 29.574661 loss_ctc 41.532032 loss_rnnt 26.546503 hw_loss 0.707542 lr 0.00060755 rank 1
2023-02-11 15:40:38,802 DEBUG TRAIN Batch 8/1000 loss 13.150464 loss_att 17.915421 loss_ctc 19.079710 loss_rnnt 9.481449 hw_loss 0.361023 lr 0.00060733 rank 2
2023-02-11 15:40:38,803 DEBUG TRAIN Batch 8/1000 loss 13.422871 loss_att 13.499290 loss_ctc 18.412529 loss_rnnt 11.470572 hw_loss 0.238449 lr 0.00060741 rank 0
2023-02-11 15:40:38,804 DEBUG TRAIN Batch 8/1000 loss 43.805313 loss_att 45.279259 loss_ctc 66.196388 loss_rnnt 39.146877 hw_loss 0.258406 lr 0.00060778 rank 4
2023-02-11 15:40:38,805 DEBUG TRAIN Batch 8/1000 loss 11.860039 loss_att 13.867365 loss_ctc 18.038939 loss_rnnt 8.964101 hw_loss 0.313241 lr 0.00060772 rank 6
2023-02-11 15:40:38,806 DEBUG TRAIN Batch 8/1000 loss 15.228780 loss_att 22.237141 loss_ctc 31.289995 loss_rnnt 10.894707 hw_loss 0.148295 lr 0.00060751 rank 5
2023-02-11 15:40:38,828 DEBUG TRAIN Batch 8/1000 loss 17.632959 loss_att 16.010344 loss_ctc 17.722088 loss_rnnt 14.327135 hw_loss 0.678461 lr 0.00060777 rank 7
2023-02-11 15:40:38,835 DEBUG TRAIN Batch 8/1000 loss 16.263432 loss_att 17.651997 loss_ctc 26.040573 loss_rnnt 11.961197 hw_loss 0.510169 lr 0.00060789 rank 3
2023-02-11 15:41:56,249 DEBUG TRAIN Batch 8/1100 loss 29.316294 loss_att 34.723656 loss_ctc 46.594570 loss_rnnt 24.980072 hw_loss 0.178308 lr 0.00060688 rank 2
2023-02-11 15:41:56,251 DEBUG TRAIN Batch 8/1100 loss 20.338301 loss_att 22.901628 loss_ctc 30.337101 loss_rnnt 17.158939 hw_loss 0.250035 lr 0.00060706 rank 5
2023-02-11 15:41:56,252 DEBUG TRAIN Batch 8/1100 loss 20.386511 loss_att 23.035101 loss_ctc 31.326103 loss_rnnt 16.437843 hw_loss 0.367563 lr 0.00060732 rank 7
2023-02-11 15:41:56,252 DEBUG TRAIN Batch 8/1100 loss 15.696096 loss_att 17.842503 loss_ctc 32.968498 loss_rnnt 9.239964 hw_loss 0.698225 lr 0.00060696 rank 0
2023-02-11 15:41:56,255 DEBUG TRAIN Batch 8/1100 loss 23.305216 loss_att 26.023773 loss_ctc 39.659485 loss_rnnt 18.185646 hw_loss 0.449117 lr 0.00060744 rank 3
2023-02-11 15:41:56,257 DEBUG TRAIN Batch 8/1100 loss 14.430176 loss_att 15.467777 loss_ctc 23.306301 loss_rnnt 8.610377 hw_loss 0.830399 lr 0.00060710 rank 1
2023-02-11 15:41:56,259 DEBUG TRAIN Batch 8/1100 loss 14.868465 loss_att 16.073971 loss_ctc 21.226219 loss_rnnt 10.465312 hw_loss 0.621441 lr 0.00060727 rank 6
2023-02-11 15:41:56,260 DEBUG TRAIN Batch 8/1100 loss 24.127945 loss_att 30.378469 loss_ctc 29.754189 loss_rnnt 18.834660 hw_loss 0.617440 lr 0.00060733 rank 4
2023-02-11 15:43:10,774 DEBUG TRAIN Batch 8/1200 loss 13.155110 loss_att 12.121091 loss_ctc 17.871641 loss_rnnt 9.174467 hw_loss 0.667233 lr 0.00060699 rank 3
2023-02-11 15:43:10,774 DEBUG TRAIN Batch 8/1200 loss 9.634729 loss_att 9.667110 loss_ctc 11.505137 loss_rnnt 6.047426 hw_loss 0.624645 lr 0.00060687 rank 7
2023-02-11 15:43:10,774 DEBUG TRAIN Batch 8/1200 loss 32.322212 loss_att 32.795395 loss_ctc 50.742496 loss_rnnt 27.388107 hw_loss 0.446893 lr 0.00060652 rank 0
2023-02-11 15:43:10,776 DEBUG TRAIN Batch 8/1200 loss 13.001058 loss_att 13.899184 loss_ctc 18.277496 loss_rnnt 9.748331 hw_loss 0.444295 lr 0.00060643 rank 2
2023-02-11 15:43:10,777 DEBUG TRAIN Batch 8/1200 loss 16.335972 loss_att 16.254295 loss_ctc 21.030918 loss_rnnt 12.948895 hw_loss 0.520766 lr 0.00060682 rank 6
2023-02-11 15:43:10,777 DEBUG TRAIN Batch 8/1200 loss 23.572567 loss_att 23.204525 loss_ctc 32.903011 loss_rnnt 19.742004 hw_loss 0.498771 lr 0.00060662 rank 5
2023-02-11 15:43:10,811 DEBUG TRAIN Batch 8/1200 loss 18.916529 loss_att 19.908318 loss_ctc 28.561253 loss_rnnt 14.071586 hw_loss 0.630117 lr 0.00060688 rank 4
2023-02-11 15:43:10,819 DEBUG TRAIN Batch 8/1200 loss 12.461277 loss_att 12.298811 loss_ctc 18.161200 loss_rnnt 9.910319 hw_loss 0.341899 lr 0.00060666 rank 1
2023-02-11 15:44:26,917 DEBUG TRAIN Batch 8/1300 loss 6.069114 loss_att 8.566164 loss_ctc 10.788596 loss_rnnt 3.893742 hw_loss 0.196256 lr 0.00060643 rank 7
2023-02-11 15:44:26,920 DEBUG TRAIN Batch 8/1300 loss 11.694314 loss_att 7.269611 loss_ctc 10.600786 loss_rnnt 6.690150 hw_loss 1.131545 lr 0.00060607 rank 0
2023-02-11 15:44:26,921 DEBUG TRAIN Batch 8/1300 loss 7.856580 loss_att 9.437339 loss_ctc 11.391546 loss_rnnt 2.812503 hw_loss 0.798112 lr 0.00060654 rank 3
2023-02-11 15:44:26,921 DEBUG TRAIN Batch 8/1300 loss 16.972795 loss_att 14.205425 loss_ctc 18.884586 loss_rnnt 12.491157 hw_loss 0.896289 lr 0.00060599 rank 2
2023-02-11 15:44:26,924 DEBUG TRAIN Batch 8/1300 loss 14.586287 loss_att 10.152827 loss_ctc 12.996913 loss_rnnt 8.816657 hw_loss 1.287795 lr 0.00060643 rank 4
2023-02-11 15:44:26,925 DEBUG TRAIN Batch 8/1300 loss 10.212601 loss_att 11.642395 loss_ctc 12.377964 loss_rnnt 6.790386 hw_loss 0.533914 lr 0.00060617 rank 5
2023-02-11 15:44:26,925 DEBUG TRAIN Batch 8/1300 loss 13.899561 loss_att 17.979597 loss_ctc 26.846035 loss_rnnt 10.154356 hw_loss 0.225563 lr 0.00060621 rank 1
2023-02-11 15:44:26,972 DEBUG TRAIN Batch 8/1300 loss 10.721357 loss_att 7.824301 loss_ctc 9.430503 loss_rnnt 6.916677 hw_loss 0.854289 lr 0.00060637 rank 6
2023-02-11 15:45:45,552 DEBUG TRAIN Batch 8/1400 loss 16.550350 loss_att 19.047449 loss_ctc 21.412054 loss_rnnt 12.636898 hw_loss 0.518588 lr 0.00060572 rank 5
2023-02-11 15:45:45,553 DEBUG TRAIN Batch 8/1400 loss 13.044903 loss_att 14.665497 loss_ctc 21.889843 loss_rnnt 8.870218 hw_loss 0.500857 lr 0.00060598 rank 7
2023-02-11 15:45:45,555 DEBUG TRAIN Batch 8/1400 loss 7.695886 loss_att 10.927095 loss_ctc 10.272441 loss_rnnt 4.372659 hw_loss 0.437521 lr 0.00060599 rank 4
2023-02-11 15:45:45,554 DEBUG TRAIN Batch 8/1400 loss 13.004310 loss_att 15.286150 loss_ctc 23.498558 loss_rnnt 10.062535 hw_loss 0.203657 lr 0.00060610 rank 3
2023-02-11 15:45:45,556 DEBUG TRAIN Batch 8/1400 loss 14.445341 loss_att 19.420780 loss_ctc 21.623646 loss_rnnt 11.571768 hw_loss 0.172758 lr 0.00060576 rank 1
2023-02-11 15:45:45,559 DEBUG TRAIN Batch 8/1400 loss 17.928228 loss_att 22.343300 loss_ctc 28.918013 loss_rnnt 14.815867 hw_loss 0.143257 lr 0.00060593 rank 6
2023-02-11 15:45:45,562 DEBUG TRAIN Batch 8/1400 loss 10.946694 loss_att 14.268071 loss_ctc 19.208300 loss_rnnt 7.238750 hw_loss 0.364148 lr 0.00060563 rank 0
2023-02-11 15:45:45,607 DEBUG TRAIN Batch 8/1400 loss 14.409632 loss_att 17.182770 loss_ctc 24.469091 loss_rnnt 9.932770 hw_loss 0.483933 lr 0.00060554 rank 2
2023-02-11 15:47:01,997 DEBUG TRAIN Batch 8/1500 loss 18.527290 loss_att 23.636278 loss_ctc 28.143072 loss_rnnt 13.432277 hw_loss 0.523334 lr 0.00060518 rank 0
2023-02-11 15:47:01,999 DEBUG TRAIN Batch 8/1500 loss 38.773628 loss_att 40.027573 loss_ctc 56.920158 loss_rnnt 34.563671 hw_loss 0.288681 lr 0.00060532 rank 1
2023-02-11 15:47:02,000 DEBUG TRAIN Batch 8/1500 loss 11.634642 loss_att 13.757864 loss_ctc 20.958458 loss_rnnt 7.806198 hw_loss 0.405117 lr 0.00060565 rank 3
2023-02-11 15:47:02,000 DEBUG TRAIN Batch 8/1500 loss 17.907104 loss_att 20.003630 loss_ctc 20.198360 loss_rnnt 14.898888 hw_loss 0.428140 lr 0.00060528 rank 5
2023-02-11 15:47:02,000 DEBUG TRAIN Batch 8/1500 loss 18.098372 loss_att 17.395742 loss_ctc 23.657589 loss_rnnt 13.370028 hw_loss 0.773933 lr 0.00060554 rank 7
2023-02-11 15:47:02,001 DEBUG TRAIN Batch 8/1500 loss 14.327473 loss_att 13.737152 loss_ctc 17.733221 loss_rnnt 11.550554 hw_loss 0.457666 lr 0.00060510 rank 2
2023-02-11 15:47:02,005 DEBUG TRAIN Batch 8/1500 loss 10.809196 loss_att 13.274866 loss_ctc 16.223877 loss_rnnt 8.083944 hw_loss 0.283155 lr 0.00060554 rank 4
2023-02-11 15:47:02,049 DEBUG TRAIN Batch 8/1500 loss 17.519894 loss_att 19.549908 loss_ctc 30.718313 loss_rnnt 13.771083 hw_loss 0.296816 lr 0.00060548 rank 6
2023-02-11 15:48:17,129 DEBUG TRAIN Batch 8/1600 loss 18.726234 loss_att 21.044174 loss_ctc 37.843849 loss_rnnt 13.534045 hw_loss 0.408672 lr 0.00060509 rank 7
2023-02-11 15:48:17,131 DEBUG TRAIN Batch 8/1600 loss 25.615635 loss_att 26.679916 loss_ctc 38.346287 loss_rnnt 22.364857 hw_loss 0.251344 lr 0.00060466 rank 2
2023-02-11 15:48:17,132 DEBUG TRAIN Batch 8/1600 loss 20.231274 loss_att 24.617649 loss_ctc 31.321014 loss_rnnt 16.075184 hw_loss 0.337534 lr 0.00060521 rank 3
2023-02-11 15:48:17,133 DEBUG TRAIN Batch 8/1600 loss 19.567425 loss_att 22.862011 loss_ctc 26.999271 loss_rnnt 14.795517 hw_loss 0.585389 lr 0.00060484 rank 5
2023-02-11 15:48:17,134 DEBUG TRAIN Batch 8/1600 loss 20.092882 loss_att 23.211420 loss_ctc 34.788986 loss_rnnt 16.767452 hw_loss 0.139171 lr 0.00060474 rank 0
2023-02-11 15:48:17,135 DEBUG TRAIN Batch 8/1600 loss 17.332424 loss_att 20.953094 loss_ctc 29.242926 loss_rnnt 13.544510 hw_loss 0.276696 lr 0.00060504 rank 6
2023-02-11 15:48:17,138 DEBUG TRAIN Batch 8/1600 loss 29.886692 loss_att 33.838181 loss_ctc 57.679565 loss_rnnt 23.268547 hw_loss 0.397899 lr 0.00060488 rank 1
2023-02-11 15:48:17,142 DEBUG TRAIN Batch 8/1600 loss 14.970205 loss_att 18.058590 loss_ctc 24.507641 loss_rnnt 11.514038 hw_loss 0.293781 lr 0.00060510 rank 4
2023-02-11 15:49:33,344 DEBUG TRAIN Batch 8/1700 loss 19.472717 loss_att 22.359116 loss_ctc 31.016174 loss_rnnt 15.287240 hw_loss 0.387951 lr 0.00060465 rank 7
2023-02-11 15:49:33,347 DEBUG TRAIN Batch 8/1700 loss 14.765561 loss_att 18.230988 loss_ctc 25.055580 loss_rnnt 11.875082 hw_loss 0.154761 lr 0.00060477 rank 3
2023-02-11 15:49:33,348 DEBUG TRAIN Batch 8/1700 loss 15.651778 loss_att 17.047495 loss_ctc 22.330944 loss_rnnt 12.914574 hw_loss 0.293907 lr 0.00060460 rank 6
2023-02-11 15:49:33,348 DEBUG TRAIN Batch 8/1700 loss 20.563034 loss_att 21.406263 loss_ctc 32.137253 loss_rnnt 16.743423 hw_loss 0.395200 lr 0.00060444 rank 1
2023-02-11 15:49:33,351 DEBUG TRAIN Batch 8/1700 loss 17.677258 loss_att 21.227251 loss_ctc 30.080196 loss_rnnt 12.455710 hw_loss 0.535842 lr 0.00060421 rank 2
2023-02-11 15:49:33,352 DEBUG TRAIN Batch 8/1700 loss 15.905225 loss_att 18.135691 loss_ctc 27.849625 loss_rnnt 11.923762 hw_loss 0.364272 lr 0.00060466 rank 4
2023-02-11 15:49:33,357 DEBUG TRAIN Batch 8/1700 loss 17.846762 loss_att 19.578152 loss_ctc 22.399511 loss_rnnt 13.817317 hw_loss 0.576775 lr 0.00060430 rank 0
2023-02-11 15:49:33,359 DEBUG TRAIN Batch 8/1700 loss 13.160909 loss_att 17.284245 loss_ctc 22.908966 loss_rnnt 10.184248 hw_loss 0.159797 lr 0.00060440 rank 5
2023-02-11 15:50:52,788 DEBUG TRAIN Batch 8/1800 loss 19.158392 loss_att 23.734718 loss_ctc 35.566792 loss_rnnt 14.727933 hw_loss 0.248889 lr 0.00060421 rank 7
2023-02-11 15:50:52,789 DEBUG TRAIN Batch 8/1800 loss 19.855703 loss_att 23.707623 loss_ctc 34.988087 loss_rnnt 16.003717 hw_loss 0.199491 lr 0.00060377 rank 2
2023-02-11 15:50:52,790 DEBUG TRAIN Batch 8/1800 loss 15.622152 loss_att 14.363518 loss_ctc 18.438906 loss_rnnt 11.993360 hw_loss 0.657179 lr 0.00060399 rank 1
2023-02-11 15:50:52,790 DEBUG TRAIN Batch 8/1800 loss 30.096518 loss_att 29.701702 loss_ctc 42.908504 loss_rnnt 26.884657 hw_loss 0.296730 lr 0.00060386 rank 0
2023-02-11 15:50:52,790 DEBUG TRAIN Batch 8/1800 loss 23.647743 loss_att 24.414848 loss_ctc 35.170746 loss_rnnt 18.782137 hw_loss 0.595459 lr 0.00060395 rank 5
2023-02-11 15:50:52,792 DEBUG TRAIN Batch 8/1800 loss 16.764235 loss_att 17.712154 loss_ctc 21.642763 loss_rnnt 11.759055 hw_loss 0.780961 lr 0.00060433 rank 3
2023-02-11 15:50:52,793 DEBUG TRAIN Batch 8/1800 loss 13.338807 loss_att 18.901699 loss_ctc 26.974737 loss_rnnt 9.519016 hw_loss 0.166704 lr 0.00060416 rank 6
2023-02-11 15:50:52,843 DEBUG TRAIN Batch 8/1800 loss 20.777510 loss_att 21.543575 loss_ctc 27.779762 loss_rnnt 15.672680 hw_loss 0.753372 lr 0.00060421 rank 4
2023-02-11 15:52:08,883 DEBUG TRAIN Batch 8/1900 loss 19.820057 loss_att 17.481686 loss_ctc 25.647358 loss_rnnt 16.840462 hw_loss 0.500680 lr 0.00060372 rank 6
2023-02-11 15:52:08,885 DEBUG TRAIN Batch 8/1900 loss 11.056704 loss_att 10.650920 loss_ctc 13.435437 loss_rnnt 6.470998 hw_loss 0.815568 lr 0.00060342 rank 0
2023-02-11 15:52:08,885 DEBUG TRAIN Batch 8/1900 loss 16.298525 loss_att 15.271877 loss_ctc 22.493685 loss_rnnt 12.136831 hw_loss 0.663938 lr 0.00060351 rank 5
2023-02-11 15:52:08,885 DEBUG TRAIN Batch 8/1900 loss 10.693788 loss_att 17.386030 loss_ctc 15.014979 loss_rnnt 6.457826 hw_loss 0.435254 lr 0.00060377 rank 7
2023-02-11 15:52:08,887 DEBUG TRAIN Batch 8/1900 loss 14.211592 loss_att 16.501585 loss_ctc 27.331478 loss_rnnt 9.947850 hw_loss 0.385579 lr 0.00060388 rank 3
2023-02-11 15:52:08,891 DEBUG TRAIN Batch 8/1900 loss 11.967469 loss_att 9.903274 loss_ctc 11.830792 loss_rnnt 7.384627 hw_loss 0.940107 lr 0.00060355 rank 1
2023-02-11 15:52:08,892 DEBUG TRAIN Batch 8/1900 loss 10.556932 loss_att 13.072262 loss_ctc 17.225576 loss_rnnt 7.197564 hw_loss 0.368840 lr 0.00060333 rank 2
2023-02-11 15:52:08,899 DEBUG TRAIN Batch 8/1900 loss 11.973980 loss_att 10.063700 loss_ctc 11.708786 loss_rnnt 5.930245 hw_loss 1.211466 lr 0.00060377 rank 4
2023-02-11 15:53:25,690 DEBUG TRAIN Batch 8/2000 loss 26.561550 loss_att 26.205912 loss_ctc 35.342224 loss_rnnt 24.201168 hw_loss 0.236392 lr 0.00060344 rank 3
2023-02-11 15:53:25,694 DEBUG TRAIN Batch 8/2000 loss 11.846500 loss_att 14.296948 loss_ctc 18.054794 loss_rnnt 8.378599 hw_loss 0.403132 lr 0.00060308 rank 5
2023-02-11 15:53:25,696 DEBUG TRAIN Batch 8/2000 loss 20.609394 loss_att 24.248112 loss_ctc 31.586807 loss_rnnt 17.118618 hw_loss 0.243633 lr 0.00060333 rank 7
2023-02-11 15:53:25,698 DEBUG TRAIN Batch 8/2000 loss 9.577509 loss_att 13.301406 loss_ctc 12.000124 loss_rnnt 6.550427 hw_loss 0.367366 lr 0.00060298 rank 0
2023-02-11 15:53:25,700 DEBUG TRAIN Batch 8/2000 loss 10.480471 loss_att 12.283623 loss_ctc 12.340034 loss_rnnt 6.786759 hw_loss 0.578464 lr 0.00060333 rank 4
2023-02-11 15:53:25,701 DEBUG TRAIN Batch 8/2000 loss 12.166969 loss_att 15.359745 loss_ctc 18.422901 loss_rnnt 9.451208 hw_loss 0.233078 lr 0.00060311 rank 1
2023-02-11 15:53:25,701 DEBUG TRAIN Batch 8/2000 loss 12.730421 loss_att 9.792469 loss_ctc 11.060285 loss_rnnt 7.918061 hw_loss 1.054244 lr 0.00060290 rank 2
2023-02-11 15:53:25,740 DEBUG TRAIN Batch 8/2000 loss 18.350477 loss_att 21.457088 loss_ctc 38.205860 loss_rnnt 13.322363 hw_loss 0.329889 lr 0.00060328 rank 6
2023-02-11 15:54:43,407 DEBUG TRAIN Batch 8/2100 loss 8.907217 loss_att 10.304739 loss_ctc 15.514930 loss_rnnt 5.694839 hw_loss 0.384721 lr 0.00060301 rank 3
2023-02-11 15:54:43,410 DEBUG TRAIN Batch 8/2100 loss 13.321843 loss_att 15.527524 loss_ctc 18.471909 loss_rnnt 9.036604 hw_loss 0.592018 lr 0.00060254 rank 0
2023-02-11 15:54:43,412 DEBUG TRAIN Batch 8/2100 loss 28.207621 loss_att 30.542992 loss_ctc 33.598763 loss_rnnt 24.626572 hw_loss 0.449091 lr 0.00060268 rank 1
2023-02-11 15:54:43,418 DEBUG TRAIN Batch 8/2100 loss 24.150276 loss_att 26.335138 loss_ctc 39.968586 loss_rnnt 18.946096 hw_loss 0.498393 lr 0.00060246 rank 2
2023-02-11 15:54:43,418 DEBUG TRAIN Batch 8/2100 loss 13.750340 loss_att 13.825535 loss_ctc 18.884092 loss_rnnt 9.977361 hw_loss 0.576270 lr 0.00060289 rank 7
2023-02-11 15:54:43,418 DEBUG TRAIN Batch 8/2100 loss 18.361971 loss_att 21.915375 loss_ctc 29.494543 loss_rnnt 14.753562 hw_loss 0.265010 lr 0.00060264 rank 5
2023-02-11 15:54:43,422 DEBUG TRAIN Batch 8/2100 loss 7.788720 loss_att 12.281302 loss_ctc 12.634742 loss_rnnt 4.204572 hw_loss 0.382405 lr 0.00060290 rank 4
2023-02-11 15:54:43,465 DEBUG TRAIN Batch 8/2100 loss 11.711052 loss_att 16.385197 loss_ctc 21.402647 loss_rnnt 7.873565 hw_loss 0.301959 lr 0.00060284 rank 6
2023-02-11 15:55:59,711 DEBUG TRAIN Batch 8/2200 loss 18.721983 loss_att 20.633522 loss_ctc 30.546431 loss_rnnt 14.361476 hw_loss 0.450301 lr 0.00060210 rank 0
2023-02-11 15:55:59,711 DEBUG TRAIN Batch 8/2200 loss 15.340591 loss_att 18.434458 loss_ctc 25.184032 loss_rnnt 12.536334 hw_loss 0.163693 lr 0.00060240 rank 6
2023-02-11 15:55:59,713 DEBUG TRAIN Batch 8/2200 loss 13.113688 loss_att 16.165535 loss_ctc 25.095215 loss_rnnt 7.892028 hw_loss 0.565079 lr 0.00060224 rank 1
2023-02-11 15:55:59,715 DEBUG TRAIN Batch 8/2200 loss 17.703056 loss_att 23.611666 loss_ctc 25.684830 loss_rnnt 14.614300 hw_loss 0.158025 lr 0.00060257 rank 3
2023-02-11 15:55:59,717 DEBUG TRAIN Batch 8/2200 loss 17.876596 loss_att 20.582157 loss_ctc 24.995750 loss_rnnt 15.692779 hw_loss 0.130028 lr 0.00060245 rank 7
2023-02-11 15:55:59,718 DEBUG TRAIN Batch 8/2200 loss 22.400225 loss_att 26.437305 loss_ctc 36.016502 loss_rnnt 17.198048 hw_loss 0.483611 lr 0.00060220 rank 5
2023-02-11 15:55:59,721 DEBUG TRAIN Batch 8/2200 loss 16.256433 loss_att 23.454802 loss_ctc 38.281025 loss_rnnt 10.976841 hw_loss 0.169370 lr 0.00060202 rank 2
2023-02-11 15:55:59,725 DEBUG TRAIN Batch 8/2200 loss 28.220430 loss_att 29.985153 loss_ctc 46.304428 loss_rnnt 22.986294 hw_loss 0.463124 lr 0.00060246 rank 4
2023-02-11 15:57:15,072 DEBUG TRAIN Batch 8/2300 loss 14.881556 loss_att 15.954990 loss_ctc 21.653194 loss_rnnt 11.151325 hw_loss 0.489873 lr 0.00060167 rank 0
2023-02-11 15:57:15,076 DEBUG TRAIN Batch 8/2300 loss 11.939466 loss_att 12.477496 loss_ctc 13.802844 loss_rnnt 9.316847 hw_loss 0.424980 lr 0.00060158 rank 2
2023-02-11 15:57:15,077 DEBUG TRAIN Batch 8/2300 loss 18.319735 loss_att 20.863974 loss_ctc 24.726604 loss_rnnt 12.201441 hw_loss 0.891599 lr 0.00060176 rank 5
2023-02-11 15:57:15,079 DEBUG TRAIN Batch 8/2300 loss 12.614883 loss_att 14.627769 loss_ctc 22.309664 loss_rnnt 9.232491 hw_loss 0.316346 lr 0.00060202 rank 7
2023-02-11 15:57:15,080 DEBUG TRAIN Batch 8/2300 loss 13.643864 loss_att 14.605692 loss_ctc 17.256474 loss_rnnt 10.075161 hw_loss 0.542748 lr 0.00060213 rank 3
2023-02-11 15:57:15,082 DEBUG TRAIN Batch 8/2300 loss 9.889837 loss_att 12.074928 loss_ctc 20.691887 loss_rnnt 4.775105 hw_loss 0.607020 lr 0.00060196 rank 6
2023-02-11 15:57:15,083 DEBUG TRAIN Batch 8/2300 loss 16.440002 loss_att 17.895397 loss_ctc 24.935390 loss_rnnt 12.728619 hw_loss 0.428922 lr 0.00060202 rank 4
2023-02-11 15:57:15,122 DEBUG TRAIN Batch 8/2300 loss 23.868221 loss_att 26.055555 loss_ctc 38.689789 loss_rnnt 19.431767 hw_loss 0.379271 lr 0.00060180 rank 1
2023-02-11 15:58:31,233 DEBUG TRAIN Batch 8/2400 loss 20.559088 loss_att 20.731602 loss_ctc 34.659393 loss_rnnt 16.822046 hw_loss 0.341718 lr 0.00060158 rank 4
2023-02-11 15:58:31,235 DEBUG TRAIN Batch 8/2400 loss 12.894904 loss_att 16.519199 loss_ctc 20.041023 loss_rnnt 9.670052 hw_loss 0.290096 lr 0.00060133 rank 5
2023-02-11 15:58:31,235 DEBUG TRAIN Batch 8/2400 loss 21.820244 loss_att 22.361238 loss_ctc 29.896700 loss_rnnt 17.545568 hw_loss 0.579303 lr 0.00060153 rank 6
2023-02-11 15:58:31,239 DEBUG TRAIN Batch 8/2400 loss 18.815233 loss_att 20.967745 loss_ctc 36.359268 loss_rnnt 12.956215 hw_loss 0.579246 lr 0.00060169 rank 3
2023-02-11 15:58:31,241 DEBUG TRAIN Batch 8/2400 loss 20.865210 loss_att 26.306881 loss_ctc 40.047314 loss_rnnt 15.411779 hw_loss 0.338903 lr 0.00060137 rank 1
2023-02-11 15:58:31,243 DEBUG TRAIN Batch 8/2400 loss 17.798889 loss_att 15.586781 loss_ctc 23.284710 loss_rnnt 13.889238 hw_loss 0.678868 lr 0.00060158 rank 7
2023-02-11 15:58:31,242 DEBUG TRAIN Batch 8/2400 loss 19.411270 loss_att 23.006809 loss_ctc 29.519341 loss_rnnt 15.079660 hw_loss 0.424642 lr 0.00060115 rank 2
2023-02-11 15:58:31,244 DEBUG TRAIN Batch 8/2400 loss 26.579662 loss_att 28.560785 loss_ctc 45.893173 loss_rnnt 22.279749 hw_loss 0.249104 lr 0.00060123 rank 0
2023-02-11 15:59:51,242 DEBUG TRAIN Batch 8/2500 loss 14.244700 loss_att 13.397678 loss_ctc 17.462124 loss_rnnt 10.129186 hw_loss 0.722987 lr 0.00060115 rank 7
2023-02-11 15:59:51,244 DEBUG TRAIN Batch 8/2500 loss 19.977928 loss_att 18.094725 loss_ctc 26.737164 loss_rnnt 15.807273 hw_loss 0.683637 lr 0.00060093 rank 1
2023-02-11 15:59:51,244 DEBUG TRAIN Batch 8/2500 loss 16.510822 loss_att 13.657811 loss_ctc 19.438589 loss_rnnt 12.006072 hw_loss 0.878434 lr 0.00060126 rank 3
2023-02-11 15:59:51,245 DEBUG TRAIN Batch 8/2500 loss 11.064477 loss_att 11.413386 loss_ctc 17.480850 loss_rnnt 7.754128 hw_loss 0.447197 lr 0.00060089 rank 5
2023-02-11 15:59:51,249 DEBUG TRAIN Batch 8/2500 loss 17.249559 loss_att 20.166595 loss_ctc 29.962137 loss_rnnt 12.073722 hw_loss 0.543266 lr 0.00060080 rank 0
2023-02-11 15:59:51,250 DEBUG TRAIN Batch 8/2500 loss 9.960628 loss_att 10.662457 loss_ctc 13.424743 loss_rnnt 6.720392 hw_loss 0.494623 lr 0.00060072 rank 2
2023-02-11 15:59:51,251 DEBUG TRAIN Batch 8/2500 loss 15.386976 loss_att 15.108598 loss_ctc 21.635794 loss_rnnt 10.509566 hw_loss 0.768733 lr 0.00060109 rank 6
2023-02-11 15:59:51,296 DEBUG TRAIN Batch 8/2500 loss 17.671141 loss_att 20.010252 loss_ctc 33.921097 loss_rnnt 12.611049 hw_loss 0.454802 lr 0.00060115 rank 4
2023-02-11 16:01:07,569 DEBUG TRAIN Batch 8/2600 loss 20.532303 loss_att 18.082331 loss_ctc 24.013260 loss_rnnt 16.203945 hw_loss 0.816417 lr 0.00060028 rank 2
2023-02-11 16:01:07,570 DEBUG TRAIN Batch 8/2600 loss 17.157017 loss_att 22.063961 loss_ctc 25.724539 loss_rnnt 13.910776 hw_loss 0.210471 lr 0.00060071 rank 7
2023-02-11 16:01:07,571 DEBUG TRAIN Batch 8/2600 loss 21.931461 loss_att 27.705910 loss_ctc 33.674461 loss_rnnt 16.561272 hw_loss 0.496794 lr 0.00060066 rank 6
2023-02-11 16:01:07,573 DEBUG TRAIN Batch 8/2600 loss 12.935028 loss_att 11.076634 loss_ctc 13.632977 loss_rnnt 7.761434 hw_loss 1.022290 lr 0.00060037 rank 0
2023-02-11 16:01:07,576 DEBUG TRAIN Batch 8/2600 loss 17.584734 loss_att 18.339722 loss_ctc 30.246010 loss_rnnt 12.869719 hw_loss 0.539222 lr 0.00060082 rank 3
2023-02-11 16:01:07,577 DEBUG TRAIN Batch 8/2600 loss 17.276884 loss_att 21.354239 loss_ctc 29.813246 loss_rnnt 12.729681 hw_loss 0.386290 lr 0.00060050 rank 1
2023-02-11 16:01:07,578 DEBUG TRAIN Batch 8/2600 loss 21.183670 loss_att 23.790867 loss_ctc 33.688660 loss_rnnt 15.268635 hw_loss 0.698674 lr 0.00060046 rank 5
2023-02-11 16:01:07,625 DEBUG TRAIN Batch 8/2600 loss 19.572599 loss_att 13.869864 loss_ctc 19.029171 loss_rnnt 12.892162 hw_loss 1.480020 lr 0.00060072 rank 4
2023-02-11 16:02:23,657 DEBUG TRAIN Batch 8/2700 loss 10.658697 loss_att 10.992055 loss_ctc 9.270663 loss_rnnt 5.485360 hw_loss 0.992200 lr 0.00060039 rank 3
2023-02-11 16:02:23,658 DEBUG TRAIN Batch 8/2700 loss 22.493643 loss_att 28.995438 loss_ctc 32.763809 loss_rnnt 16.607227 hw_loss 0.603131 lr 0.00060028 rank 7
2023-02-11 16:02:23,659 DEBUG TRAIN Batch 8/2700 loss 12.596376 loss_att 18.261621 loss_ctc 20.666828 loss_rnnt 7.550935 hw_loss 0.531812 lr 0.00060003 rank 5
2023-02-11 16:02:23,661 DEBUG TRAIN Batch 8/2700 loss 9.357368 loss_att 12.769066 loss_ctc 15.145859 loss_rnnt 6.245229 hw_loss 0.310875 lr 0.00059993 rank 0
2023-02-11 16:02:23,662 DEBUG TRAIN Batch 8/2700 loss 10.848183 loss_att 12.057475 loss_ctc 17.608685 loss_rnnt 7.443288 hw_loss 0.424057 lr 0.00059985 rank 2
2023-02-11 16:02:23,662 DEBUG TRAIN Batch 8/2700 loss 15.052488 loss_att 13.800018 loss_ctc 18.573425 loss_rnnt 11.740240 hw_loss 0.579991 lr 0.00060007 rank 1
2023-02-11 16:02:23,663 DEBUG TRAIN Batch 8/2700 loss 7.703770 loss_att 11.097980 loss_ctc 13.287636 loss_rnnt 5.827867 hw_loss 0.084852 lr 0.00060028 rank 4
2023-02-11 16:02:23,664 DEBUG TRAIN Batch 8/2700 loss 35.209183 loss_att 38.655277 loss_ctc 49.753716 loss_rnnt 31.490597 hw_loss 0.204393 lr 0.00060023 rank 6
2023-02-11 16:03:41,379 DEBUG TRAIN Batch 8/2800 loss 9.481559 loss_att 13.879169 loss_ctc 16.860390 loss_rnnt 6.653605 hw_loss 0.180860 lr 0.00059985 rank 7
2023-02-11 16:03:41,379 DEBUG TRAIN Batch 8/2800 loss 13.794130 loss_att 18.537573 loss_ctc 22.595974 loss_rnnt 11.020063 hw_loss 0.122213 lr 0.00059996 rank 3
2023-02-11 16:03:41,381 DEBUG TRAIN Batch 8/2800 loss 19.466757 loss_att 24.529894 loss_ctc 34.247345 loss_rnnt 14.303518 hw_loss 0.408725 lr 0.00059985 rank 4
2023-02-11 16:03:41,383 DEBUG TRAIN Batch 8/2800 loss 15.897706 loss_att 17.201290 loss_ctc 18.111889 loss_rnnt 10.764245 hw_loss 0.858285 lr 0.00059964 rank 1
2023-02-11 16:03:41,383 DEBUG TRAIN Batch 8/2800 loss 19.493368 loss_att 19.091291 loss_ctc 27.230309 loss_rnnt 17.039555 hw_loss 0.281744 lr 0.00059979 rank 6
2023-02-11 16:03:41,386 DEBUG TRAIN Batch 8/2800 loss 15.886532 loss_att 17.937504 loss_ctc 24.604406 loss_rnnt 13.385619 hw_loss 0.174063 lr 0.00059942 rank 2
2023-02-11 16:03:41,385 DEBUG TRAIN Batch 8/2800 loss 9.264476 loss_att 11.581052 loss_ctc 12.352191 loss_rnnt 6.514148 hw_loss 0.351622 lr 0.00059960 rank 5
2023-02-11 16:03:41,387 DEBUG TRAIN Batch 8/2800 loss 7.836411 loss_att 12.055752 loss_ctc 16.243528 loss_rnnt 3.850163 hw_loss 0.379018 lr 0.00059950 rank 0
2023-02-11 16:04:58,013 DEBUG TRAIN Batch 8/2900 loss 17.315170 loss_att 21.603542 loss_ctc 28.396477 loss_rnnt 13.454491 hw_loss 0.286031 lr 0.00059942 rank 7
2023-02-11 16:04:58,015 DEBUG TRAIN Batch 8/2900 loss 14.638064 loss_att 18.713411 loss_ctc 23.171324 loss_rnnt 7.703445 hw_loss 0.934084 lr 0.00059936 rank 6
2023-02-11 16:04:58,016 DEBUG TRAIN Batch 8/2900 loss 16.015434 loss_att 20.869473 loss_ctc 25.082783 loss_rnnt 11.479771 hw_loss 0.441726 lr 0.00059907 rank 0
2023-02-11 16:04:58,016 DEBUG TRAIN Batch 8/2900 loss 15.811781 loss_att 24.336380 loss_ctc 28.839428 loss_rnnt 10.803029 hw_loss 0.293777 lr 0.00059942 rank 4
2023-02-11 16:04:58,019 DEBUG TRAIN Batch 8/2900 loss 18.058390 loss_att 19.570160 loss_ctc 26.792103 loss_rnnt 16.032942 hw_loss 0.104737 lr 0.00059953 rank 3
2023-02-11 16:04:58,019 DEBUG TRAIN Batch 8/2900 loss 15.544955 loss_att 19.017561 loss_ctc 25.032698 loss_rnnt 10.795340 hw_loss 0.523137 lr 0.00059917 rank 5
2023-02-11 16:04:58,020 DEBUG TRAIN Batch 8/2900 loss 13.471178 loss_att 15.861017 loss_ctc 19.994406 loss_rnnt 9.943638 hw_loss 0.408714 lr 0.00059920 rank 1
2023-02-11 16:04:58,027 DEBUG TRAIN Batch 8/2900 loss 14.580130 loss_att 17.603008 loss_ctc 15.938498 loss_rnnt 10.832698 hw_loss 0.555326 lr 0.00059899 rank 2
2023-02-11 16:06:14,062 DEBUG TRAIN Batch 8/3000 loss 17.412653 loss_att 17.336239 loss_ctc 21.370125 loss_rnnt 14.758670 hw_loss 0.401551 lr 0.00059910 rank 3
2023-02-11 16:06:14,065 DEBUG TRAIN Batch 8/3000 loss 20.003712 loss_att 21.489326 loss_ctc 29.404663 loss_rnnt 15.638720 hw_loss 0.527701 lr 0.00059877 rank 1
2023-02-11 16:06:14,065 DEBUG TRAIN Batch 8/3000 loss 8.865904 loss_att 9.520223 loss_ctc 11.153463 loss_rnnt 3.703785 hw_loss 0.886171 lr 0.00059898 rank 7
2023-02-11 16:06:14,065 DEBUG TRAIN Batch 8/3000 loss 40.408550 loss_att 40.896751 loss_ctc 54.266682 loss_rnnt 35.768883 hw_loss 0.505177 lr 0.00059864 rank 0
2023-02-11 16:06:14,072 DEBUG TRAIN Batch 8/3000 loss 19.391148 loss_att 22.427038 loss_ctc 28.032547 loss_rnnt 15.931504 hw_loss 0.318802 lr 0.00059899 rank 4
2023-02-11 16:06:14,073 DEBUG TRAIN Batch 8/3000 loss 18.217672 loss_att 18.967274 loss_ctc 26.547298 loss_rnnt 14.970003 hw_loss 0.372587 lr 0.00059893 rank 6
2023-02-11 16:06:14,074 DEBUG TRAIN Batch 8/3000 loss 17.389160 loss_att 18.155611 loss_ctc 22.963856 loss_rnnt 12.911692 hw_loss 0.671416 lr 0.00059856 rank 2
2023-02-11 16:06:14,075 DEBUG TRAIN Batch 8/3000 loss 16.925728 loss_att 17.173737 loss_ctc 23.424826 loss_rnnt 13.294261 hw_loss 0.509122 lr 0.00059874 rank 5
2023-02-11 16:07:30,010 DEBUG TRAIN Batch 8/3100 loss 26.193623 loss_att 28.498312 loss_ctc 43.027168 loss_rnnt 19.733942 hw_loss 0.703925 lr 0.00059867 rank 3
2023-02-11 16:07:30,012 DEBUG TRAIN Batch 8/3100 loss 7.717707 loss_att 10.901630 loss_ctc 14.082152 loss_rnnt 5.284233 hw_loss 0.177768 lr 0.00059821 rank 0
2023-02-11 16:07:30,015 DEBUG TRAIN Batch 8/3100 loss 9.812387 loss_att 12.177619 loss_ctc 17.261488 loss_rnnt 5.627995 hw_loss 0.509650 lr 0.00059856 rank 7
2023-02-11 16:07:30,018 DEBUG TRAIN Batch 8/3100 loss 14.111588 loss_att 13.192705 loss_ctc 14.702372 loss_rnnt 9.938001 hw_loss 0.802236 lr 0.00059831 rank 5
2023-02-11 16:07:30,017 DEBUG TRAIN Batch 8/3100 loss 9.862641 loss_att 10.263251 loss_ctc 15.518466 loss_rnnt 7.432438 hw_loss 0.299245 lr 0.00059835 rank 1
2023-02-11 16:07:30,019 DEBUG TRAIN Batch 8/3100 loss 24.335472 loss_att 25.143345 loss_ctc 38.524635 loss_rnnt 19.856842 hw_loss 0.454719 lr 0.00059850 rank 6
2023-02-11 16:07:30,020 DEBUG TRAIN Batch 8/3100 loss 19.047962 loss_att 17.160305 loss_ctc 27.698145 loss_rnnt 13.796867 hw_loss 0.839113 lr 0.00059813 rank 2
2023-02-11 16:07:30,021 DEBUG TRAIN Batch 8/3100 loss 18.603785 loss_att 19.995411 loss_ctc 22.207138 loss_rnnt 15.071942 hw_loss 0.519950 lr 0.00059856 rank 4
2023-02-11 16:08:49,170 DEBUG TRAIN Batch 8/3200 loss 22.614208 loss_att 20.839010 loss_ctc 29.057720 loss_rnnt 19.302555 hw_loss 0.526417 lr 0.00059813 rank 4
2023-02-11 16:08:49,172 DEBUG TRAIN Batch 8/3200 loss 18.152662 loss_att 21.436388 loss_ctc 24.454723 loss_rnnt 14.295027 hw_loss 0.442616 lr 0.00059824 rank 3
2023-02-11 16:08:49,172 DEBUG TRAIN Batch 8/3200 loss 12.832401 loss_att 17.651318 loss_ctc 19.596653 loss_rnnt 8.399524 hw_loss 0.481349 lr 0.00059813 rank 7
2023-02-11 16:08:49,173 DEBUG TRAIN Batch 8/3200 loss 11.532719 loss_att 12.244392 loss_ctc 15.678507 loss_rnnt 8.699783 hw_loss 0.400843 lr 0.00059779 rank 0
2023-02-11 16:08:49,174 DEBUG TRAIN Batch 8/3200 loss 22.253956 loss_att 21.848335 loss_ctc 29.176136 loss_rnnt 19.101370 hw_loss 0.433266 lr 0.00059770 rank 2
2023-02-11 16:08:49,178 DEBUG TRAIN Batch 8/3200 loss 13.609195 loss_att 14.553820 loss_ctc 21.430042 loss_rnnt 8.859357 hw_loss 0.659650 lr 0.00059808 rank 6
2023-02-11 16:08:49,191 DEBUG TRAIN Batch 8/3200 loss 25.172522 loss_att 25.828686 loss_ctc 35.630096 loss_rnnt 19.981779 hw_loss 0.687219 lr 0.00059788 rank 5
2023-02-11 16:08:49,241 DEBUG TRAIN Batch 8/3200 loss 19.261868 loss_att 23.423223 loss_ctc 31.102581 loss_rnnt 14.118528 hw_loss 0.512308 lr 0.00059792 rank 1
2023-02-11 16:10:05,244 DEBUG TRAIN Batch 8/3300 loss 17.336109 loss_att 18.318848 loss_ctc 27.865576 loss_rnnt 13.827404 hw_loss 0.357793 lr 0.00059736 rank 0
2023-02-11 16:10:05,247 DEBUG TRAIN Batch 8/3300 loss 17.631100 loss_att 18.739559 loss_ctc 28.153128 loss_rnnt 12.367924 hw_loss 0.682227 lr 0.00059781 rank 3
2023-02-11 16:10:05,248 DEBUG TRAIN Batch 8/3300 loss 15.657212 loss_att 16.654573 loss_ctc 15.580829 loss_rnnt 10.527499 hw_loss 0.926330 lr 0.00059770 rank 4
2023-02-11 16:10:05,248 DEBUG TRAIN Batch 8/3300 loss 13.893015 loss_att 16.319221 loss_ctc 19.184212 loss_rnnt 10.920977 hw_loss 0.333994 lr 0.00059745 rank 5
2023-02-11 16:10:05,251 DEBUG TRAIN Batch 8/3300 loss 18.185600 loss_att 20.332249 loss_ctc 23.596649 loss_rnnt 15.022728 hw_loss 0.377263 lr 0.00059765 rank 6
2023-02-11 16:10:05,254 DEBUG TRAIN Batch 8/3300 loss 34.960598 loss_att 40.090576 loss_ctc 62.624344 loss_rnnt 28.273809 hw_loss 0.369806 lr 0.00059749 rank 1
2023-02-11 16:10:05,253 DEBUG TRAIN Batch 8/3300 loss 11.102382 loss_att 13.115546 loss_ctc 14.105899 loss_rnnt 9.764842 hw_loss 0.100207 lr 0.00059770 rank 7
2023-02-11 16:10:05,253 DEBUG TRAIN Batch 8/3300 loss 16.692604 loss_att 25.679165 loss_ctc 31.142920 loss_rnnt 12.619589 hw_loss 0.065436 lr 0.00059728 rank 2
2023-02-11 16:11:22,019 DEBUG TRAIN Batch 8/3400 loss 27.133921 loss_att 30.792709 loss_ctc 38.430641 loss_rnnt 23.533688 hw_loss 0.255422 lr 0.00059722 rank 6
2023-02-11 16:11:22,023 DEBUG TRAIN Batch 8/3400 loss 15.256677 loss_att 15.746875 loss_ctc 24.009289 loss_rnnt 12.050983 hw_loss 0.363870 lr 0.00059685 rank 2
2023-02-11 16:11:22,023 DEBUG TRAIN Batch 8/3400 loss 22.049107 loss_att 22.875462 loss_ctc 29.430130 loss_rnnt 19.113504 hw_loss 0.334911 lr 0.00059738 rank 3
2023-02-11 16:11:22,024 DEBUG TRAIN Batch 8/3400 loss 18.797861 loss_att 20.360798 loss_ctc 29.368759 loss_rnnt 15.642799 hw_loss 0.268692 lr 0.00059693 rank 0
2023-02-11 16:11:22,024 DEBUG TRAIN Batch 8/3400 loss 15.169233 loss_att 15.391094 loss_ctc 19.862953 loss_rnnt 12.135307 hw_loss 0.443198 lr 0.00059727 rank 7
2023-02-11 16:11:22,029 DEBUG TRAIN Batch 8/3400 loss 19.169134 loss_att 22.891094 loss_ctc 28.008446 loss_rnnt 13.919361 hw_loss 0.623776 lr 0.00059706 rank 1
2023-02-11 16:11:22,029 DEBUG TRAIN Batch 8/3400 loss 9.601624 loss_att 13.588686 loss_ctc 16.261612 loss_rnnt 6.771196 hw_loss 0.214691 lr 0.00059728 rank 4
2023-02-11 16:11:22,030 DEBUG TRAIN Batch 8/3400 loss 5.930809 loss_att 7.605465 loss_ctc 10.788218 loss_rnnt 4.050564 hw_loss 0.168311 lr 0.00059703 rank 5
2023-02-11 16:12:38,455 DEBUG TRAIN Batch 8/3500 loss 24.035976 loss_att 27.468443 loss_ctc 38.595894 loss_rnnt 20.982513 hw_loss 0.079809 lr 0.00059664 rank 1
2023-02-11 16:12:38,455 DEBUG TRAIN Batch 8/3500 loss 20.497616 loss_att 22.502979 loss_ctc 28.871536 loss_rnnt 16.977444 hw_loss 0.375483 lr 0.00059685 rank 4
2023-02-11 16:12:38,456 DEBUG TRAIN Batch 8/3500 loss 17.400854 loss_att 18.716719 loss_ctc 22.161186 loss_rnnt 14.568743 hw_loss 0.362668 lr 0.00059696 rank 3
2023-02-11 16:12:38,457 DEBUG TRAIN Batch 8/3500 loss 12.847097 loss_att 19.932682 loss_ctc 20.231331 loss_rnnt 9.467373 hw_loss 0.183383 lr 0.00059643 rank 2
2023-02-11 16:12:38,456 DEBUG TRAIN Batch 8/3500 loss 15.373331 loss_att 15.675259 loss_ctc 20.572111 loss_rnnt 12.729769 hw_loss 0.354376 lr 0.00059660 rank 5
2023-02-11 16:12:38,457 DEBUG TRAIN Batch 8/3500 loss 14.325617 loss_att 14.432279 loss_ctc 20.311214 loss_rnnt 10.160315 hw_loss 0.627354 lr 0.00059680 rank 6
2023-02-11 16:12:38,458 DEBUG TRAIN Batch 8/3500 loss 18.103252 loss_att 19.565557 loss_ctc 22.664902 loss_rnnt 14.541213 hw_loss 0.499005 lr 0.00059651 rank 0
2023-02-11 16:12:38,460 DEBUG TRAIN Batch 8/3500 loss 16.472717 loss_att 18.617294 loss_ctc 25.853542 loss_rnnt 13.444695 hw_loss 0.252812 lr 0.00059685 rank 7
2023-02-11 16:13:56,816 DEBUG TRAIN Batch 8/3600 loss 16.368984 loss_att 15.443300 loss_ctc 22.798944 loss_rnnt 10.827662 hw_loss 0.912962 lr 0.00059600 rank 2
2023-02-11 16:13:56,818 DEBUG TRAIN Batch 8/3600 loss 10.349659 loss_att 11.549080 loss_ctc 13.848729 loss_rnnt 6.186741 hw_loss 0.648092 lr 0.00059643 rank 4
2023-02-11 16:13:56,819 DEBUG TRAIN Batch 8/3600 loss 13.002005 loss_att 16.492783 loss_ctc 24.231937 loss_rnnt 8.044895 hw_loss 0.517806 lr 0.00059653 rank 3
2023-02-11 16:13:56,820 DEBUG TRAIN Batch 8/3600 loss 25.112572 loss_att 30.223473 loss_ctc 35.625916 loss_rnnt 21.727854 hw_loss 0.180142 lr 0.00059637 rank 6
2023-02-11 16:13:56,821 DEBUG TRAIN Batch 8/3600 loss 28.325253 loss_att 25.179131 loss_ctc 32.801102 loss_rnnt 24.973974 hw_loss 0.634448 lr 0.00059618 rank 5
2023-02-11 16:13:56,824 DEBUG TRAIN Batch 8/3600 loss 10.109953 loss_att 12.878954 loss_ctc 13.784259 loss_rnnt 6.233634 hw_loss 0.531115 lr 0.00059621 rank 1
2023-02-11 16:13:56,825 DEBUG TRAIN Batch 8/3600 loss 18.938492 loss_att 21.329700 loss_ctc 25.777020 loss_rnnt 14.033216 hw_loss 0.659106 lr 0.00059642 rank 7
2023-02-11 16:13:56,831 DEBUG TRAIN Batch 8/3600 loss 13.613808 loss_att 18.037430 loss_ctc 25.666212 loss_rnnt 9.366575 hw_loss 0.329160 lr 0.00059608 rank 0
2023-02-11 16:15:11,409 DEBUG TRAIN Batch 8/3700 loss 20.890451 loss_att 25.133842 loss_ctc 26.660252 loss_rnnt 16.515123 hw_loss 0.517002 lr 0.00059595 rank 6
2023-02-11 16:15:11,412 DEBUG TRAIN Batch 8/3700 loss 19.203716 loss_att 20.586294 loss_ctc 30.839144 loss_rnnt 14.276961 hw_loss 0.581034 lr 0.00059600 rank 4
2023-02-11 16:15:11,413 DEBUG TRAIN Batch 8/3700 loss 18.045561 loss_att 16.082085 loss_ctc 24.437328 loss_rnnt 13.625957 hw_loss 0.742512 lr 0.00059611 rank 3
2023-02-11 16:15:11,413 DEBUG TRAIN Batch 8/3700 loss 13.082579 loss_att 14.891764 loss_ctc 22.307264 loss_rnnt 10.857149 hw_loss 0.118806 lr 0.00059600 rank 7
2023-02-11 16:15:11,414 DEBUG TRAIN Batch 8/3700 loss 8.029490 loss_att 9.950087 loss_ctc 7.811854 loss_rnnt 5.485566 hw_loss 0.410404 lr 0.00059566 rank 0
2023-02-11 16:15:11,415 DEBUG TRAIN Batch 8/3700 loss 13.443132 loss_att 14.147690 loss_ctc 20.080778 loss_rnnt 10.712276 hw_loss 0.319674 lr 0.00059575 rank 5
2023-02-11 16:15:11,418 DEBUG TRAIN Batch 8/3700 loss 15.239445 loss_att 20.104187 loss_ctc 23.662695 loss_rnnt 10.131981 hw_loss 0.564640 lr 0.00059558 rank 2
2023-02-11 16:15:11,427 DEBUG TRAIN Batch 8/3700 loss 22.846325 loss_att 26.757385 loss_ctc 32.764721 loss_rnnt 17.597927 hw_loss 0.589450 lr 0.00059579 rank 1
2023-02-11 16:16:27,193 DEBUG TRAIN Batch 8/3800 loss 13.330962 loss_att 8.648115 loss_ctc 11.816433 loss_rnnt 8.380092 hw_loss 1.141758 lr 0.00059533 rank 5
2023-02-11 16:16:27,194 DEBUG TRAIN Batch 8/3800 loss 11.042910 loss_att 9.509556 loss_ctc 12.855231 loss_rnnt 7.004298 hw_loss 0.769432 lr 0.00059558 rank 4
2023-02-11 16:16:27,194 DEBUG TRAIN Batch 8/3800 loss 18.095299 loss_att 17.686474 loss_ctc 21.363197 loss_rnnt 13.942390 hw_loss 0.712304 lr 0.00059524 rank 0
2023-02-11 16:16:27,194 DEBUG TRAIN Batch 8/3800 loss 10.431838 loss_att 9.479305 loss_ctc 12.270869 loss_rnnt 6.383285 hw_loss 0.748848 lr 0.00059553 rank 6
2023-02-11 16:16:27,198 DEBUG TRAIN Batch 8/3800 loss 7.543356 loss_att 10.166513 loss_ctc 8.996594 loss_rnnt 3.821916 hw_loss 0.563071 lr 0.00059569 rank 3
2023-02-11 16:16:27,202 DEBUG TRAIN Batch 8/3800 loss 16.333199 loss_att 18.166962 loss_ctc 25.820698 loss_rnnt 11.630134 hw_loss 0.575871 lr 0.00059558 rank 7
2023-02-11 16:16:27,202 DEBUG TRAIN Batch 8/3800 loss 21.722179 loss_att 26.038393 loss_ctc 29.881580 loss_rnnt 18.109680 hw_loss 0.311500 lr 0.00059537 rank 1
2023-02-11 16:16:27,205 DEBUG TRAIN Batch 8/3800 loss 11.278899 loss_att 12.038205 loss_ctc 11.185375 loss_rnnt 6.101585 hw_loss 0.944611 lr 0.00059516 rank 2
2023-02-11 16:17:46,435 DEBUG TRAIN Batch 8/3900 loss 14.316747 loss_att 15.667026 loss_ctc 21.361549 loss_rnnt 11.339025 hw_loss 0.331567 lr 0.00059491 rank 5
2023-02-11 16:17:46,436 DEBUG TRAIN Batch 8/3900 loss 16.465359 loss_att 13.428751 loss_ctc 17.894907 loss_rnnt 10.772083 hw_loss 1.145623 lr 0.00059474 rank 2
2023-02-11 16:17:46,440 DEBUG TRAIN Batch 8/3900 loss 14.368659 loss_att 17.331835 loss_ctc 21.034178 loss_rnnt 12.787890 hw_loss 0.018637 lr 0.00059526 rank 3
2023-02-11 16:17:46,440 DEBUG TRAIN Batch 8/3900 loss 15.192244 loss_att 19.245832 loss_ctc 20.414955 loss_rnnt 13.085066 hw_loss 0.112519 lr 0.00059482 rank 0
2023-02-11 16:17:46,442 DEBUG TRAIN Batch 8/3900 loss 8.758728 loss_att 13.603762 loss_ctc 13.188229 loss_rnnt 4.290018 hw_loss 0.545457 lr 0.00059516 rank 4
2023-02-11 16:17:46,443 DEBUG TRAIN Batch 8/3900 loss 10.719113 loss_att 14.118204 loss_ctc 19.385952 loss_rnnt 7.387730 hw_loss 0.280498 lr 0.00059515 rank 7
2023-02-11 16:17:46,443 DEBUG TRAIN Batch 8/3900 loss 25.047604 loss_att 27.806841 loss_ctc 34.293095 loss_rnnt 19.762932 hw_loss 0.656267 lr 0.00059495 rank 1
2023-02-11 16:17:46,490 DEBUG TRAIN Batch 8/3900 loss 23.426205 loss_att 26.297626 loss_ctc 33.712944 loss_rnnt 17.844002 hw_loss 0.681816 lr 0.00059510 rank 6
2023-02-11 16:19:03,417 DEBUG TRAIN Batch 8/4000 loss 15.280784 loss_att 17.430698 loss_ctc 24.199339 loss_rnnt 12.030002 hw_loss 0.305936 lr 0.00059484 rank 3
2023-02-11 16:19:03,420 DEBUG TRAIN Batch 8/4000 loss 27.387035 loss_att 27.297054 loss_ctc 42.373684 loss_rnnt 23.169426 hw_loss 0.419510 lr 0.00059440 rank 0
2023-02-11 16:19:03,421 DEBUG TRAIN Batch 8/4000 loss 19.740509 loss_att 19.770830 loss_ctc 25.415312 loss_rnnt 16.704184 hw_loss 0.426304 lr 0.00059474 rank 4
2023-02-11 16:19:03,424 DEBUG TRAIN Batch 8/4000 loss 12.508857 loss_att 13.799566 loss_ctc 20.871845 loss_rnnt 7.959351 hw_loss 0.595556 lr 0.00059473 rank 7
2023-02-11 16:19:03,424 DEBUG TRAIN Batch 8/4000 loss 20.385502 loss_att 22.737806 loss_ctc 30.641216 loss_rnnt 16.210543 hw_loss 0.438200 lr 0.00059449 rank 5
2023-02-11 16:19:03,425 DEBUG TRAIN Batch 8/4000 loss 18.322948 loss_att 23.417339 loss_ctc 33.148300 loss_rnnt 13.196882 hw_loss 0.399464 lr 0.00059432 rank 2
2023-02-11 16:19:03,425 DEBUG TRAIN Batch 8/4000 loss 24.970158 loss_att 28.470901 loss_ctc 37.824501 loss_rnnt 19.660738 hw_loss 0.542880 lr 0.00059453 rank 1
2023-02-11 16:19:03,470 DEBUG TRAIN Batch 8/4000 loss 15.672782 loss_att 19.140343 loss_ctc 23.432182 loss_rnnt 12.241802 hw_loss 0.319290 lr 0.00059468 rank 6
2023-02-11 16:20:18,935 DEBUG TRAIN Batch 8/4100 loss 9.568282 loss_att 11.944438 loss_ctc 18.571224 loss_rnnt 6.673275 hw_loss 0.228634 lr 0.00059411 rank 1
2023-02-11 16:20:18,935 DEBUG TRAIN Batch 8/4100 loss 29.443014 loss_att 34.879326 loss_ctc 47.489128 loss_rnnt 25.025253 hw_loss 0.173316 lr 0.00059426 rank 6
2023-02-11 16:20:18,935 DEBUG TRAIN Batch 8/4100 loss 19.959978 loss_att 25.017612 loss_ctc 30.817411 loss_rnnt 14.912349 hw_loss 0.485334 lr 0.00059431 rank 7
2023-02-11 16:20:18,938 DEBUG TRAIN Batch 8/4100 loss 12.689683 loss_att 14.610514 loss_ctc 15.767829 loss_rnnt 9.505558 hw_loss 0.448038 lr 0.00059407 rank 5
2023-02-11 16:20:18,941 DEBUG TRAIN Batch 8/4100 loss 14.490982 loss_att 18.402544 loss_ctc 23.844290 loss_rnnt 9.738691 hw_loss 0.510538 lr 0.00059442 rank 3
2023-02-11 16:20:18,941 DEBUG TRAIN Batch 8/4100 loss 35.298229 loss_att 31.816595 loss_ctc 40.649689 loss_rnnt 34.607269 hw_loss 0.126330 lr 0.00059390 rank 2
2023-02-11 16:20:18,945 DEBUG TRAIN Batch 8/4100 loss 18.825312 loss_att 20.065134 loss_ctc 29.834547 loss_rnnt 15.463633 hw_loss 0.308591 lr 0.00059432 rank 4
2023-02-11 16:20:18,946 DEBUG TRAIN Batch 8/4100 loss 28.541992 loss_att 34.441662 loss_ctc 39.658348 loss_rnnt 23.874699 hw_loss 0.375971 lr 0.00059398 rank 0
2023-02-11 16:21:35,929 DEBUG TRAIN Batch 8/4200 loss 12.458501 loss_att 15.219413 loss_ctc 21.748825 loss_rnnt 6.561618 hw_loss 0.769873 lr 0.00059400 rank 3
2023-02-11 16:21:35,931 DEBUG TRAIN Batch 8/4200 loss 14.238249 loss_att 16.981247 loss_ctc 22.187065 loss_rnnt 8.937424 hw_loss 0.692322 lr 0.00059365 rank 5
2023-02-11 16:21:35,932 DEBUG TRAIN Batch 8/4200 loss 15.826877 loss_att 20.687584 loss_ctc 25.090736 loss_rnnt 12.974545 hw_loss 0.120939 lr 0.00059356 rank 0
2023-02-11 16:21:35,932 DEBUG TRAIN Batch 8/4200 loss 17.299908 loss_att 21.607510 loss_ctc 32.348267 loss_rnnt 11.801302 hw_loss 0.493244 lr 0.00059390 rank 4
2023-02-11 16:21:35,932 DEBUG TRAIN Batch 8/4200 loss 17.002522 loss_att 22.483017 loss_ctc 25.311859 loss_rnnt 11.570213 hw_loss 0.605306 lr 0.00059369 rank 1
2023-02-11 16:21:35,937 DEBUG TRAIN Batch 8/4200 loss 12.103762 loss_att 14.240082 loss_ctc 19.669413 loss_rnnt 8.678133 hw_loss 0.373052 lr 0.00059348 rank 2
2023-02-11 16:21:35,937 DEBUG TRAIN Batch 8/4200 loss 23.250813 loss_att 26.422688 loss_ctc 35.907856 loss_rnnt 18.456055 hw_loss 0.463645 lr 0.00059384 rank 6
2023-02-11 16:21:35,948 DEBUG TRAIN Batch 8/4200 loss 11.175220 loss_att 8.750420 loss_ctc 11.249764 loss_rnnt 7.680308 hw_loss 0.744362 lr 0.00059389 rank 7
2023-02-11 16:22:54,266 DEBUG TRAIN Batch 8/4300 loss 12.810972 loss_att 14.446102 loss_ctc 18.992971 loss_rnnt 9.721684 hw_loss 0.363374 lr 0.00059314 rank 0
2023-02-11 16:22:54,272 DEBUG TRAIN Batch 8/4300 loss 20.874958 loss_att 24.653086 loss_ctc 36.698536 loss_rnnt 15.085131 hw_loss 0.548323 lr 0.00059327 rank 1
2023-02-11 16:22:54,273 DEBUG TRAIN Batch 8/4300 loss 11.904318 loss_att 14.672199 loss_ctc 15.533443 loss_rnnt 7.104197 hw_loss 0.705499 lr 0.00059323 rank 5
2023-02-11 16:22:54,273 DEBUG TRAIN Batch 8/4300 loss 17.377129 loss_att 21.327911 loss_ctc 36.139343 loss_rnnt 12.546346 hw_loss 0.288562 lr 0.00059347 rank 7
2023-02-11 16:22:54,274 DEBUG TRAIN Batch 8/4300 loss 12.710854 loss_att 13.213672 loss_ctc 21.578880 loss_rnnt 7.175230 hw_loss 0.797373 lr 0.00059306 rank 2
2023-02-11 16:22:54,274 DEBUG TRAIN Batch 8/4300 loss 14.016756 loss_att 13.545769 loss_ctc 20.031742 loss_rnnt 11.179891 hw_loss 0.399200 lr 0.00059348 rank 4
2023-02-11 16:22:54,275 DEBUG TRAIN Batch 8/4300 loss 10.477004 loss_att 10.573425 loss_ctc 10.683280 loss_rnnt 6.684899 hw_loss 0.702247 lr 0.00059358 rank 3
2023-02-11 16:22:54,277 DEBUG TRAIN Batch 8/4300 loss 17.165148 loss_att 17.491913 loss_ctc 25.444872 loss_rnnt 12.023174 hw_loss 0.744873 lr 0.00059342 rank 6
2023-02-11 16:24:11,210 DEBUG TRAIN Batch 8/4400 loss 50.366856 loss_att 55.950096 loss_ctc 77.122681 loss_rnnt 43.399719 hw_loss 0.428071 lr 0.00059317 rank 3
2023-02-11 16:24:11,216 DEBUG TRAIN Batch 8/4400 loss 16.798655 loss_att 18.243364 loss_ctc 28.317184 loss_rnnt 11.533287 hw_loss 0.645117 lr 0.00059272 rank 0
2023-02-11 16:24:11,218 DEBUG TRAIN Batch 8/4400 loss 21.377333 loss_att 21.550571 loss_ctc 29.664045 loss_rnnt 18.855560 hw_loss 0.259168 lr 0.00059301 rank 6
2023-02-11 16:24:11,219 DEBUG TRAIN Batch 8/4400 loss 10.789448 loss_att 11.752254 loss_ctc 18.401697 loss_rnnt 7.541165 hw_loss 0.382641 lr 0.00059306 rank 7
2023-02-11 16:24:11,220 DEBUG TRAIN Batch 8/4400 loss 12.051449 loss_att 9.382107 loss_ctc 12.449533 loss_rnnt 7.622362 hw_loss 0.920602 lr 0.00059285 rank 1
2023-02-11 16:24:11,223 DEBUG TRAIN Batch 8/4400 loss 10.037872 loss_att 10.297827 loss_ctc 11.337838 loss_rnnt 6.385210 hw_loss 0.642627 lr 0.00059281 rank 5
2023-02-11 16:24:11,224 DEBUG TRAIN Batch 8/4400 loss 19.673964 loss_att 22.493372 loss_ctc 29.711378 loss_rnnt 15.426538 hw_loss 0.439729 lr 0.00059306 rank 4
2023-02-11 16:24:11,270 DEBUG TRAIN Batch 8/4400 loss 15.829520 loss_att 18.038998 loss_ctc 23.339848 loss_rnnt 10.932280 hw_loss 0.647619 lr 0.00059264 rank 2
2023-02-11 16:25:27,145 DEBUG TRAIN Batch 8/4500 loss 24.337011 loss_att 23.539511 loss_ctc 39.203178 loss_rnnt 20.589613 hw_loss 0.360889 lr 0.00059264 rank 7
2023-02-11 16:25:27,149 DEBUG TRAIN Batch 8/4500 loss 16.698885 loss_att 20.452072 loss_ctc 21.770748 loss_rnnt 12.506071 hw_loss 0.518612 lr 0.00059275 rank 3
2023-02-11 16:25:27,149 DEBUG TRAIN Batch 8/4500 loss 17.130873 loss_att 11.631827 loss_ctc 15.260430 loss_rnnt 9.837930 hw_loss 1.620402 lr 0.00059264 rank 4
2023-02-11 16:25:27,151 DEBUG TRAIN Batch 8/4500 loss 15.588726 loss_att 16.868217 loss_ctc 22.443920 loss_rnnt 13.333903 hw_loss 0.203419 lr 0.00059244 rank 1
2023-02-11 16:25:27,152 DEBUG TRAIN Batch 8/4500 loss 14.512711 loss_att 12.943701 loss_ctc 18.352669 loss_rnnt 9.122028 hw_loss 0.973592 lr 0.00059231 rank 0
2023-02-11 16:25:27,157 DEBUG TRAIN Batch 8/4500 loss 10.612317 loss_att 13.743331 loss_ctc 16.765926 loss_rnnt 5.092423 hw_loss 0.763727 lr 0.00059240 rank 5
2023-02-11 16:25:27,162 DEBUG TRAIN Batch 8/4500 loss 11.776140 loss_att 10.812128 loss_ctc 12.378493 loss_rnnt 7.576426 hw_loss 0.808538 lr 0.00059259 rank 6
2023-02-11 16:25:27,163 DEBUG TRAIN Batch 8/4500 loss 13.288172 loss_att 12.530590 loss_ctc 18.377373 loss_rnnt 7.799907 hw_loss 0.930229 lr 0.00059223 rank 2
2023-02-11 16:26:45,601 DEBUG TRAIN Batch 8/4600 loss 29.146730 loss_att 34.073265 loss_ctc 45.398575 loss_rnnt 24.182646 hw_loss 0.339724 lr 0.00059233 rank 3
2023-02-11 16:26:45,604 DEBUG TRAIN Batch 8/4600 loss 13.302856 loss_att 18.509157 loss_ctc 21.273258 loss_rnnt 7.564531 hw_loss 0.681440 lr 0.00059189 rank 0
2023-02-11 16:26:45,606 DEBUG TRAIN Batch 8/4600 loss 23.653748 loss_att 28.593822 loss_ctc 41.830273 loss_rnnt 16.915007 hw_loss 0.623848 lr 0.00059198 rank 5
2023-02-11 16:26:45,607 DEBUG TRAIN Batch 8/4600 loss 18.256802 loss_att 27.021385 loss_ctc 28.372450 loss_rnnt 12.601039 hw_loss 0.478893 lr 0.00059181 rank 2
2023-02-11 16:26:45,608 DEBUG TRAIN Batch 8/4600 loss 29.184023 loss_att 30.379147 loss_ctc 42.895836 loss_rnnt 23.891233 hw_loss 0.604786 lr 0.00059202 rank 1
2023-02-11 16:26:45,610 DEBUG TRAIN Batch 8/4600 loss 6.334299 loss_att 9.663294 loss_ctc 9.969117 loss_rnnt 2.785942 hw_loss 0.449609 lr 0.00059223 rank 4
2023-02-11 16:26:45,610 DEBUG TRAIN Batch 8/4600 loss 18.993484 loss_att 21.872562 loss_ctc 30.799183 loss_rnnt 14.123238 hw_loss 0.510064 lr 0.00059217 rank 6
2023-02-11 16:26:45,614 DEBUG TRAIN Batch 8/4600 loss 20.022926 loss_att 24.723293 loss_ctc 27.618008 loss_rnnt 16.969046 hw_loss 0.206462 lr 0.00059222 rank 7
2023-02-11 16:28:02,259 DEBUG TRAIN Batch 8/4700 loss 15.672147 loss_att 15.576852 loss_ctc 17.322876 loss_rnnt 11.273284 hw_loss 0.787092 lr 0.00059181 rank 4
2023-02-11 16:28:02,261 DEBUG TRAIN Batch 8/4700 loss 12.465275 loss_att 14.576942 loss_ctc 17.317087 loss_rnnt 8.214096 hw_loss 0.596613 lr 0.00059192 rank 3
2023-02-11 16:28:02,262 DEBUG TRAIN Batch 8/4700 loss 24.410955 loss_att 26.232548 loss_ctc 35.398895 loss_rnnt 20.289854 hw_loss 0.429698 lr 0.00059176 rank 6
2023-02-11 16:28:02,262 DEBUG TRAIN Batch 8/4700 loss 9.719265 loss_att 11.638465 loss_ctc 14.018690 loss_rnnt 6.299067 hw_loss 0.461832 lr 0.00059140 rank 2
2023-02-11 16:28:02,265 DEBUG TRAIN Batch 8/4700 loss 19.221893 loss_att 21.438545 loss_ctc 31.257950 loss_rnnt 15.422986 hw_loss 0.328269 lr 0.00059157 rank 5
2023-02-11 16:28:02,303 DEBUG TRAIN Batch 8/4700 loss 21.077194 loss_att 25.050465 loss_ctc 29.676947 loss_rnnt 18.255318 hw_loss 0.165110 lr 0.00059181 rank 7
2023-02-11 16:28:02,305 DEBUG TRAIN Batch 8/4700 loss 12.678470 loss_att 17.262173 loss_ctc 19.501297 loss_rnnt 9.072628 hw_loss 0.333636 lr 0.00059148 rank 0
2023-02-11 16:28:02,311 DEBUG TRAIN Batch 8/4700 loss 10.777830 loss_att 15.550629 loss_ctc 17.289614 loss_rnnt 7.233616 hw_loss 0.322766 lr 0.00059161 rank 1
2023-02-11 16:29:17,789 DEBUG TRAIN Batch 8/4800 loss 13.452913 loss_att 18.381107 loss_ctc 20.152805 loss_rnnt 10.499876 hw_loss 0.201390 lr 0.00059106 rank 0
2023-02-11 16:29:17,789 DEBUG TRAIN Batch 8/4800 loss 13.566156 loss_att 16.464922 loss_ctc 19.761339 loss_rnnt 10.368434 hw_loss 0.335989 lr 0.00059140 rank 4
2023-02-11 16:29:17,789 DEBUG TRAIN Batch 8/4800 loss 14.972037 loss_att 20.521606 loss_ctc 20.890247 loss_rnnt 10.114189 hw_loss 0.554782 lr 0.00059140 rank 7
2023-02-11 16:29:17,790 DEBUG TRAIN Batch 8/4800 loss 15.708199 loss_att 19.678644 loss_ctc 26.300951 loss_rnnt 10.255695 hw_loss 0.608634 lr 0.00059150 rank 3
2023-02-11 16:29:17,790 DEBUG TRAIN Batch 8/4800 loss 28.561911 loss_att 35.500603 loss_ctc 42.415428 loss_rnnt 23.819393 hw_loss 0.282683 lr 0.00059119 rank 1
2023-02-11 16:29:17,792 DEBUG TRAIN Batch 8/4800 loss 14.952884 loss_att 17.042181 loss_ctc 23.634604 loss_rnnt 11.634846 hw_loss 0.326740 lr 0.00059116 rank 5
2023-02-11 16:29:17,793 DEBUG TRAIN Batch 8/4800 loss 19.331263 loss_att 19.293325 loss_ctc 28.149410 loss_rnnt 17.152098 hw_loss 0.189562 lr 0.00059099 rank 2
2023-02-11 16:29:17,794 DEBUG TRAIN Batch 8/4800 loss 25.715508 loss_att 25.908211 loss_ctc 37.188652 loss_rnnt 22.403553 hw_loss 0.326936 lr 0.00059135 rank 6
2023-02-11 16:30:34,528 DEBUG TRAIN Batch 8/4900 loss 11.383477 loss_att 14.349249 loss_ctc 17.510336 loss_rnnt 8.561865 hw_loss 0.264664 lr 0.00059057 rank 2
2023-02-11 16:30:34,529 DEBUG TRAIN Batch 8/4900 loss 8.026476 loss_att 9.676854 loss_ctc 11.611604 loss_rnnt 4.285554 hw_loss 0.549906 lr 0.00059065 rank 0
2023-02-11 16:30:34,530 DEBUG TRAIN Batch 8/4900 loss 17.333405 loss_att 19.953747 loss_ctc 29.782328 loss_rnnt 13.584651 hw_loss 0.293405 lr 0.00059078 rank 1
2023-02-11 16:30:34,531 DEBUG TRAIN Batch 8/4900 loss 7.495675 loss_att 9.681278 loss_ctc 10.334946 loss_rnnt 5.004873 hw_loss 0.314083 lr 0.00059109 rank 3
2023-02-11 16:30:34,532 DEBUG TRAIN Batch 8/4900 loss 22.530209 loss_att 25.557207 loss_ctc 30.773914 loss_rnnt 19.793753 hw_loss 0.193481 lr 0.00059074 rank 5
2023-02-11 16:30:34,534 DEBUG TRAIN Batch 8/4900 loss 19.735752 loss_att 17.678427 loss_ctc 26.887520 loss_rnnt 14.772776 hw_loss 0.828913 lr 0.00059093 rank 6
2023-02-11 16:30:34,535 DEBUG TRAIN Batch 8/4900 loss 25.247297 loss_att 22.614981 loss_ctc 40.039635 loss_rnnt 22.825172 hw_loss 0.183052 lr 0.00059098 rank 7
2023-02-11 16:30:34,546 DEBUG TRAIN Batch 8/4900 loss 12.303301 loss_att 14.845562 loss_ctc 25.067656 loss_rnnt 9.310443 hw_loss 0.146717 lr 0.00059099 rank 4
2023-02-11 16:31:53,383 DEBUG TRAIN Batch 8/5000 loss 17.565641 loss_att 20.507687 loss_ctc 29.338083 loss_rnnt 13.948425 hw_loss 0.273590 lr 0.00059024 rank 0
2023-02-11 16:31:53,383 DEBUG TRAIN Batch 8/5000 loss 12.384918 loss_att 10.786580 loss_ctc 16.451752 loss_rnnt 10.267892 hw_loss 0.355209 lr 0.00059033 rank 5
2023-02-11 16:31:53,388 DEBUG TRAIN Batch 8/5000 loss 11.756943 loss_att 12.151149 loss_ctc 17.796038 loss_rnnt 6.781037 hw_loss 0.767222 lr 0.00059057 rank 7
2023-02-11 16:31:53,389 DEBUG TRAIN Batch 8/5000 loss 13.957644 loss_att 14.876575 loss_ctc 21.319809 loss_rnnt 10.976343 hw_loss 0.340480 lr 0.00059016 rank 2
2023-02-11 16:31:53,390 DEBUG TRAIN Batch 8/5000 loss 12.560011 loss_att 10.608854 loss_ctc 14.813388 loss_rnnt 6.842592 hw_loss 1.088850 lr 0.00059068 rank 3
2023-02-11 16:31:53,391 DEBUG TRAIN Batch 8/5000 loss 16.666283 loss_att 15.122423 loss_ctc 19.993515 loss_rnnt 12.538340 hw_loss 0.748703 lr 0.00059037 rank 1
2023-02-11 16:31:53,391 DEBUG TRAIN Batch 8/5000 loss 26.861776 loss_att 26.954136 loss_ctc 38.410477 loss_rnnt 23.504679 hw_loss 0.337275 lr 0.00059052 rank 6
2023-02-11 16:31:53,397 DEBUG TRAIN Batch 8/5000 loss 12.655491 loss_att 14.795749 loss_ctc 20.053352 loss_rnnt 8.894586 hw_loss 0.439963 lr 0.00059057 rank 4
2023-02-11 16:33:08,571 DEBUG TRAIN Batch 8/5100 loss 12.066504 loss_att 9.538443 loss_ctc 13.598629 loss_rnnt 8.735981 hw_loss 0.680972 lr 0.00059011 rank 6
2023-02-11 16:33:08,574 DEBUG TRAIN Batch 8/5100 loss 18.775085 loss_att 16.148941 loss_ctc 24.511688 loss_rnnt 12.327227 hw_loss 1.164038 lr 0.00059016 rank 7
2023-02-11 16:33:08,574 DEBUG TRAIN Batch 8/5100 loss 17.156494 loss_att 14.384438 loss_ctc 20.801357 loss_rnnt 12.966070 hw_loss 0.798535 lr 0.00058983 rank 0
2023-02-11 16:33:08,576 DEBUG TRAIN Batch 8/5100 loss 10.155342 loss_att 12.086313 loss_ctc 11.643356 loss_rnnt 5.711751 hw_loss 0.723561 lr 0.00059026 rank 3
2023-02-11 16:33:08,576 DEBUG TRAIN Batch 8/5100 loss 13.342014 loss_att 16.152237 loss_ctc 21.009954 loss_rnnt 10.298469 hw_loss 0.273583 lr 0.00058975 rank 2
2023-02-11 16:33:08,578 DEBUG TRAIN Batch 8/5100 loss 8.662499 loss_att 11.759323 loss_ctc 19.825600 loss_rnnt 6.466835 hw_loss 0.016479 lr 0.00058996 rank 1
2023-02-11 16:33:08,579 DEBUG TRAIN Batch 8/5100 loss 17.460306 loss_att 19.079290 loss_ctc 30.456615 loss_rnnt 12.776167 hw_loss 0.492656 lr 0.00058992 rank 5
2023-02-11 16:33:08,587 DEBUG TRAIN Batch 8/5100 loss 17.479893 loss_att 14.504326 loss_ctc 22.925604 loss_rnnt 14.274841 hw_loss 0.576388 lr 0.00059016 rank 4
2023-02-11 16:34:24,237 DEBUG TRAIN Batch 8/5200 loss 14.874756 loss_att 23.278505 loss_ctc 27.939085 loss_rnnt 10.662212 hw_loss 0.148103 lr 0.00058942 rank 0
2023-02-11 16:34:24,238 DEBUG TRAIN Batch 8/5200 loss 32.013504 loss_att 33.991127 loss_ctc 44.227444 loss_rnnt 27.435528 hw_loss 0.478862 lr 0.00058985 rank 3
2023-02-11 16:34:24,239 DEBUG TRAIN Batch 8/5200 loss 16.492762 loss_att 20.357430 loss_ctc 28.774117 loss_rnnt 11.861152 hw_loss 0.416468 lr 0.00058951 rank 5
2023-02-11 16:34:24,241 DEBUG TRAIN Batch 8/5200 loss 7.292569 loss_att 10.636791 loss_ctc 17.101955 loss_rnnt 4.783485 hw_loss 0.099810 lr 0.00058975 rank 7
2023-02-11 16:34:24,241 DEBUG TRAIN Batch 8/5200 loss 14.312925 loss_att 17.927921 loss_ctc 20.659939 loss_rnnt 8.760130 hw_loss 0.746911 lr 0.00058955 rank 1
2023-02-11 16:34:24,242 DEBUG TRAIN Batch 8/5200 loss 14.155041 loss_att 15.024602 loss_ctc 25.723066 loss_rnnt 11.122749 hw_loss 0.246745 lr 0.00058970 rank 6
2023-02-11 16:34:24,244 DEBUG TRAIN Batch 8/5200 loss 11.215913 loss_att 14.951334 loss_ctc 18.529852 loss_rnnt 8.878186 hw_loss 0.115397 lr 0.00058975 rank 4
2023-02-11 16:34:24,291 DEBUG TRAIN Batch 8/5200 loss 30.867643 loss_att 36.822483 loss_ctc 47.463654 loss_rnnt 26.418674 hw_loss 0.195975 lr 0.00058934 rank 2
2023-02-11 16:35:41,557 DEBUG TRAIN Batch 8/5300 loss 9.088509 loss_att 8.067554 loss_ctc 8.077112 loss_rnnt 3.538578 hw_loss 1.104183 lr 0.00058944 rank 3
2023-02-11 16:35:41,562 DEBUG TRAIN Batch 8/5300 loss 23.261345 loss_att 24.242165 loss_ctc 38.596321 loss_rnnt 19.424511 hw_loss 0.299251 lr 0.00058910 rank 5
2023-02-11 16:35:41,562 DEBUG TRAIN Batch 8/5300 loss 13.442985 loss_att 15.966681 loss_ctc 23.242369 loss_rnnt 9.859157 hw_loss 0.332344 lr 0.00058901 rank 0
2023-02-11 16:35:41,563 DEBUG TRAIN Batch 8/5300 loss 15.070312 loss_att 18.565683 loss_ctc 33.249466 loss_rnnt 9.759571 hw_loss 0.410209 lr 0.00058934 rank 4
2023-02-11 16:35:41,564 DEBUG TRAIN Batch 8/5300 loss 12.104115 loss_att 15.013717 loss_ctc 19.881771 loss_rnnt 9.243963 hw_loss 0.232727 lr 0.00058914 rank 1
2023-02-11 16:35:41,564 DEBUG TRAIN Batch 8/5300 loss 12.931109 loss_att 14.281277 loss_ctc 17.303890 loss_rnnt 8.999266 hw_loss 0.577270 lr 0.00058934 rank 7
2023-02-11 16:35:41,567 DEBUG TRAIN Batch 8/5300 loss 22.905243 loss_att 26.733681 loss_ctc 35.380058 loss_rnnt 18.982862 hw_loss 0.280010 lr 0.00058893 rank 2
2023-02-11 16:35:41,569 DEBUG TRAIN Batch 8/5300 loss 19.876013 loss_att 20.835985 loss_ctc 24.334202 loss_rnnt 16.818243 hw_loss 0.425878 lr 0.00058929 rank 6
2023-02-11 16:36:58,384 DEBUG TRAIN Batch 8/5400 loss 19.799402 loss_att 18.544710 loss_ctc 22.029984 loss_rnnt 18.153908 hw_loss 0.299817 lr 0.00058852 rank 2
2023-02-11 16:36:58,385 DEBUG TRAIN Batch 8/5400 loss 11.061040 loss_att 19.267700 loss_ctc 13.779819 loss_rnnt 8.039456 hw_loss 0.190828 lr 0.00058888 rank 6
2023-02-11 16:36:58,389 DEBUG TRAIN Batch 8/5400 loss 10.337061 loss_att 10.318022 loss_ctc 11.551172 loss_rnnt 5.915577 hw_loss 0.799390 lr 0.00058873 rank 1
2023-02-11 16:36:58,389 DEBUG TRAIN Batch 8/5400 loss 28.476326 loss_att 27.639988 loss_ctc 41.919071 loss_rnnt 22.479998 hw_loss 0.819605 lr 0.00058903 rank 3
2023-02-11 16:36:58,390 DEBUG TRAIN Batch 8/5400 loss 12.339594 loss_att 14.104289 loss_ctc 17.642298 loss_rnnt 9.219017 hw_loss 0.386365 lr 0.00058869 rank 5
2023-02-11 16:36:58,391 DEBUG TRAIN Batch 8/5400 loss 16.954058 loss_att 20.963717 loss_ctc 30.325466 loss_rnnt 12.217540 hw_loss 0.403450 lr 0.00058893 rank 7
2023-02-11 16:36:58,393 DEBUG TRAIN Batch 8/5400 loss 16.653624 loss_att 21.279169 loss_ctc 25.347355 loss_rnnt 13.107994 hw_loss 0.274004 lr 0.00058860 rank 0
2023-02-11 16:36:58,433 DEBUG TRAIN Batch 8/5400 loss 16.452045 loss_att 21.336020 loss_ctc 23.647278 loss_rnnt 12.795839 hw_loss 0.322509 lr 0.00058893 rank 4
2023-02-11 16:38:14,673 DEBUG TRAIN Batch 8/5500 loss 18.943886 loss_att 21.531897 loss_ctc 29.037251 loss_rnnt 14.454381 hw_loss 0.492398 lr 0.00058847 rank 6
2023-02-11 16:38:14,674 DEBUG TRAIN Batch 8/5500 loss 12.556552 loss_att 15.404888 loss_ctc 18.187504 loss_rnnt 9.245481 hw_loss 0.373239 lr 0.00058819 rank 0
2023-02-11 16:38:14,676 DEBUG TRAIN Batch 8/5500 loss 17.718323 loss_att 20.016884 loss_ctc 23.553772 loss_rnnt 13.737257 hw_loss 0.514368 lr 0.00058863 rank 3
2023-02-11 16:38:14,678 DEBUG TRAIN Batch 8/5500 loss 15.234412 loss_att 21.357883 loss_ctc 27.626806 loss_rnnt 11.152005 hw_loss 0.226011 lr 0.00058828 rank 5
2023-02-11 16:38:14,679 DEBUG TRAIN Batch 8/5500 loss 35.788414 loss_att 35.830029 loss_ctc 43.191639 loss_rnnt 32.617245 hw_loss 0.407954 lr 0.00058852 rank 7
2023-02-11 16:38:14,682 DEBUG TRAIN Batch 8/5500 loss 16.842308 loss_att 19.628016 loss_ctc 26.064041 loss_rnnt 13.751062 hw_loss 0.244601 lr 0.00058812 rank 2
2023-02-11 16:38:14,688 DEBUG TRAIN Batch 8/5500 loss 17.879890 loss_att 20.284595 loss_ctc 29.215687 loss_rnnt 14.742028 hw_loss 0.214778 lr 0.00058832 rank 1
2023-02-11 16:38:14,730 DEBUG TRAIN Batch 8/5500 loss 28.410276 loss_att 28.038021 loss_ctc 37.510666 loss_rnnt 24.942469 hw_loss 0.436664 lr 0.00058852 rank 4
2023-02-11 16:39:31,380 DEBUG TRAIN Batch 8/5600 loss 11.492950 loss_att 12.981357 loss_ctc 20.223307 loss_rnnt 7.252113 hw_loss 0.521083 lr 0.00058779 rank 0
2023-02-11 16:39:31,385 DEBUG TRAIN Batch 8/5600 loss 28.497408 loss_att 26.782143 loss_ctc 42.919369 loss_rnnt 21.129988 hw_loss 1.085165 lr 0.00058788 rank 5
2023-02-11 16:39:31,387 DEBUG TRAIN Batch 8/5600 loss 10.296556 loss_att 12.481899 loss_ctc 14.555296 loss_rnnt 7.058357 hw_loss 0.418744 lr 0.00058806 rank 6
2023-02-11 16:39:31,387 DEBUG TRAIN Batch 8/5600 loss 11.144138 loss_att 12.953915 loss_ctc 16.045712 loss_rnnt 7.821789 hw_loss 0.432535 lr 0.00058811 rank 7
2023-02-11 16:39:31,387 DEBUG TRAIN Batch 8/5600 loss 10.484043 loss_att 12.425100 loss_ctc 16.737280 loss_rnnt 8.247054 hw_loss 0.190315 lr 0.00058822 rank 3
2023-02-11 16:39:31,391 DEBUG TRAIN Batch 8/5600 loss 21.227211 loss_att 22.264971 loss_ctc 31.362991 loss_rnnt 16.629675 hw_loss 0.569728 lr 0.00058791 rank 1
2023-02-11 16:39:31,401 DEBUG TRAIN Batch 8/5600 loss 17.793806 loss_att 23.105568 loss_ctc 23.859571 loss_rnnt 15.449102 hw_loss 0.088796 lr 0.00058812 rank 4
2023-02-11 16:39:31,404 DEBUG TRAIN Batch 8/5600 loss 15.429259 loss_att 18.638371 loss_ctc 21.470535 loss_rnnt 11.708867 hw_loss 0.426200 lr 0.00058771 rank 2
2023-02-11 16:40:50,793 DEBUG TRAIN Batch 8/5700 loss 18.171871 loss_att 15.231522 loss_ctc 18.686459 loss_rnnt 13.312176 hw_loss 1.008591 lr 0.00058781 rank 3
2023-02-11 16:40:50,793 DEBUG TRAIN Batch 8/5700 loss 13.603889 loss_att 10.028452 loss_ctc 13.040697 loss_rnnt 8.042672 hw_loss 1.190887 lr 0.00058751 rank 1
2023-02-11 16:40:50,794 DEBUG TRAIN Batch 8/5700 loss 25.484327 loss_att 22.503582 loss_ctc 31.154959 loss_rnnt 23.071117 hw_loss 0.422489 lr 0.00058771 rank 7
2023-02-11 16:40:50,794 DEBUG TRAIN Batch 8/5700 loss 13.978208 loss_att 12.869634 loss_ctc 19.130451 loss_rnnt 8.374386 hw_loss 0.963482 lr 0.00058766 rank 6
2023-02-11 16:40:50,795 DEBUG TRAIN Batch 8/5700 loss 22.688044 loss_att 23.131210 loss_ctc 30.853439 loss_rnnt 17.859993 hw_loss 0.684506 lr 0.00058771 rank 4
2023-02-11 16:40:50,795 DEBUG TRAIN Batch 8/5700 loss 22.335749 loss_att 20.894169 loss_ctc 27.113159 loss_rnnt 19.343029 hw_loss 0.495759 lr 0.00058731 rank 2
2023-02-11 16:40:50,796 DEBUG TRAIN Batch 8/5700 loss 18.940826 loss_att 22.818596 loss_ctc 29.106779 loss_rnnt 13.424210 hw_loss 0.634800 lr 0.00058747 rank 5
2023-02-11 16:40:50,796 DEBUG TRAIN Batch 8/5700 loss 13.419363 loss_att 13.723265 loss_ctc 15.063425 loss_rnnt 9.591132 hw_loss 0.665295 lr 0.00058738 rank 0
2023-02-11 16:42:06,802 DEBUG TRAIN Batch 8/5800 loss 12.379941 loss_att 13.680936 loss_ctc 20.466101 loss_rnnt 8.584505 hw_loss 0.460703 lr 0.00058741 rank 3
2023-02-11 16:42:06,805 DEBUG TRAIN Batch 8/5800 loss 20.596909 loss_att 19.630913 loss_ctc 23.955261 loss_rnnt 18.156042 hw_loss 0.409928 lr 0.00058698 rank 0
2023-02-11 16:42:06,806 DEBUG TRAIN Batch 8/5800 loss 23.271481 loss_att 25.015266 loss_ctc 35.064693 loss_rnnt 19.961006 hw_loss 0.260491 lr 0.00058707 rank 5
2023-02-11 16:42:06,806 DEBUG TRAIN Batch 8/5800 loss 17.389990 loss_att 14.519310 loss_ctc 19.611128 loss_rnnt 14.021851 hw_loss 0.683648 lr 0.00058730 rank 7
2023-02-11 16:42:06,807 DEBUG TRAIN Batch 8/5800 loss 24.154160 loss_att 27.891922 loss_ctc 28.249653 loss_rnnt 20.541271 hw_loss 0.434863 lr 0.00058731 rank 4
2023-02-11 16:42:06,808 DEBUG TRAIN Batch 8/5800 loss 11.855919 loss_att 8.775661 loss_ctc 9.511513 loss_rnnt 7.539315 hw_loss 0.983483 lr 0.00058690 rank 2
2023-02-11 16:42:06,810 DEBUG TRAIN Batch 8/5800 loss 10.957997 loss_att 15.204180 loss_ctc 22.051361 loss_rnnt 6.832980 hw_loss 0.336875 lr 0.00058725 rank 6
2023-02-11 16:42:06,854 DEBUG TRAIN Batch 8/5800 loss 7.724865 loss_att 12.538248 loss_ctc 10.369289 loss_rnnt 4.310742 hw_loss 0.393536 lr 0.00058710 rank 1
2023-02-11 16:43:21,459 DEBUG TRAIN Batch 8/5900 loss 10.149410 loss_att 13.448288 loss_ctc 17.762777 loss_rnnt 6.123819 hw_loss 0.440756 lr 0.00058657 rank 0
2023-02-11 16:43:21,463 DEBUG TRAIN Batch 8/5900 loss 15.601743 loss_att 16.079124 loss_ctc 20.876463 loss_rnnt 11.220279 hw_loss 0.671755 lr 0.00058650 rank 2
2023-02-11 16:43:21,463 DEBUG TRAIN Batch 8/5900 loss 43.236595 loss_att 41.295898 loss_ctc 35.893639 loss_rnnt 44.399017 hw_loss 0.038396 lr 0.00058690 rank 7
2023-02-11 16:43:21,465 DEBUG TRAIN Batch 8/5900 loss 5.126026 loss_att 13.531725 loss_ctc 7.947161 loss_rnnt 1.802813 hw_loss 0.237360 lr 0.00058690 rank 4
2023-02-11 16:43:21,465 DEBUG TRAIN Batch 8/5900 loss 16.784359 loss_att 20.687119 loss_ctc 29.264355 loss_rnnt 13.098194 hw_loss 0.232802 lr 0.00058700 rank 3
2023-02-11 16:43:21,465 DEBUG TRAIN Batch 8/5900 loss 10.156918 loss_att 14.088572 loss_ctc 15.155922 loss_rnnt 5.183417 hw_loss 0.660119 lr 0.00058670 rank 1
2023-02-11 16:43:21,467 DEBUG TRAIN Batch 8/5900 loss 15.635186 loss_att 16.335796 loss_ctc 18.155981 loss_rnnt 11.209200 hw_loss 0.740579 lr 0.00058666 rank 5
2023-02-11 16:43:21,525 DEBUG TRAIN Batch 8/5900 loss 16.938471 loss_att 15.427289 loss_ctc 23.263388 loss_rnnt 14.163341 hw_loss 0.418883 lr 0.00058685 rank 6
2023-02-11 16:44:38,706 DEBUG TRAIN Batch 8/6000 loss 15.367063 loss_att 17.176914 loss_ctc 23.116493 loss_rnnt 11.277586 hw_loss 0.505172 lr 0.00058626 rank 5
2023-02-11 16:44:38,706 DEBUG TRAIN Batch 8/6000 loss 21.196465 loss_att 28.295204 loss_ctc 31.774143 loss_rnnt 16.081299 hw_loss 0.428449 lr 0.00058630 rank 1
2023-02-11 16:44:38,708 DEBUG TRAIN Batch 8/6000 loss 20.848087 loss_att 29.035263 loss_ctc 31.599997 loss_rnnt 15.908177 hw_loss 0.350416 lr 0.00058660 rank 3
2023-02-11 16:44:38,709 DEBUG TRAIN Batch 8/6000 loss 13.423245 loss_att 16.770998 loss_ctc 21.564651 loss_rnnt 9.244703 hw_loss 0.454401 lr 0.00058649 rank 7
2023-02-11 16:44:38,710 DEBUG TRAIN Batch 8/6000 loss 29.627193 loss_att 30.254143 loss_ctc 48.636749 loss_rnnt 24.574310 hw_loss 0.448666 lr 0.00058617 rank 0
2023-02-11 16:44:38,714 DEBUG TRAIN Batch 8/6000 loss 18.711823 loss_att 24.063341 loss_ctc 30.228264 loss_rnnt 14.070486 hw_loss 0.381658 lr 0.00058650 rank 4
2023-02-11 16:44:38,715 DEBUG TRAIN Batch 8/6000 loss 25.195606 loss_att 31.348389 loss_ctc 39.744225 loss_rnnt 19.516481 hw_loss 0.470391 lr 0.00058609 rank 2
2023-02-11 16:44:38,731 DEBUG TRAIN Batch 8/6000 loss 19.577810 loss_att 21.178963 loss_ctc 25.423326 loss_rnnt 14.857770 hw_loss 0.678826 lr 0.00058644 rank 6
2023-02-11 16:45:56,228 DEBUG TRAIN Batch 8/6100 loss 18.703983 loss_att 19.916164 loss_ctc 31.053310 loss_rnnt 14.799871 hw_loss 0.377831 lr 0.00058589 rank 1
2023-02-11 16:45:56,228 DEBUG TRAIN Batch 8/6100 loss 12.175781 loss_att 13.844211 loss_ctc 21.307587 loss_rnnt 7.326645 hw_loss 0.618352 lr 0.00058577 rank 0
2023-02-11 16:45:56,228 DEBUG TRAIN Batch 8/6100 loss 19.047909 loss_att 23.463943 loss_ctc 33.935635 loss_rnnt 14.687860 hw_loss 0.279715 lr 0.00058609 rank 7
2023-02-11 16:45:56,228 DEBUG TRAIN Batch 8/6100 loss 13.285975 loss_att 14.583138 loss_ctc 17.099720 loss_rnnt 9.148582 hw_loss 0.631774 lr 0.00058619 rank 3
2023-02-11 16:45:56,229 DEBUG TRAIN Batch 8/6100 loss 18.811985 loss_att 25.366545 loss_ctc 32.313530 loss_rnnt 13.507438 hw_loss 0.411268 lr 0.00058586 rank 5
2023-02-11 16:45:56,233 DEBUG TRAIN Batch 8/6100 loss 20.796852 loss_att 20.231581 loss_ctc 24.324928 loss_rnnt 17.966530 hw_loss 0.463681 lr 0.00058604 rank 6
2023-02-11 16:45:56,237 DEBUG TRAIN Batch 8/6100 loss 23.010565 loss_att 22.830267 loss_ctc 31.383465 loss_rnnt 19.044321 hw_loss 0.541110 lr 0.00058569 rank 2
2023-02-11 16:45:56,273 DEBUG TRAIN Batch 8/6100 loss 24.622561 loss_att 24.226643 loss_ctc 38.593552 loss_rnnt 19.604469 hw_loss 0.606464 lr 0.00058609 rank 4
2023-02-11 16:47:13,314 DEBUG TRAIN Batch 8/6200 loss 23.527241 loss_att 23.323671 loss_ctc 32.432713 loss_rnnt 18.622044 hw_loss 0.704721 lr 0.00058569 rank 7
2023-02-11 16:47:13,314 DEBUG TRAIN Batch 8/6200 loss 17.292866 loss_att 18.662445 loss_ctc 25.969831 loss_rnnt 12.853578 hw_loss 0.564083 lr 0.00058537 rank 0
2023-02-11 16:47:13,317 DEBUG TRAIN Batch 8/6200 loss 15.903105 loss_att 15.968421 loss_ctc 19.289314 loss_rnnt 12.894735 hw_loss 0.476965 lr 0.00058564 rank 6
2023-02-11 16:47:13,318 DEBUG TRAIN Batch 8/6200 loss 10.046302 loss_att 10.042261 loss_ctc 12.037336 loss_rnnt 6.657976 hw_loss 0.585687 lr 0.00058545 rank 5
2023-02-11 16:47:13,323 DEBUG TRAIN Batch 8/6200 loss 13.762234 loss_att 14.329242 loss_ctc 18.225647 loss_rnnt 10.158085 hw_loss 0.542930 lr 0.00058549 rank 1
2023-02-11 16:47:13,323 DEBUG TRAIN Batch 8/6200 loss 25.310926 loss_att 25.067795 loss_ctc 35.682076 loss_rnnt 23.006897 hw_loss 0.181844 lr 0.00058579 rank 3
2023-02-11 16:47:13,324 DEBUG TRAIN Batch 8/6200 loss 19.515629 loss_att 21.146301 loss_ctc 26.567879 loss_rnnt 16.812595 hw_loss 0.269362 lr 0.00058529 rank 2
2023-02-11 16:47:13,332 DEBUG TRAIN Batch 8/6200 loss 19.860697 loss_att 20.283484 loss_ctc 23.605112 loss_rnnt 15.549215 hw_loss 0.698938 lr 0.00058569 rank 4
2023-02-11 16:48:29,243 DEBUG TRAIN Batch 8/6300 loss 11.207711 loss_att 12.063007 loss_ctc 16.829130 loss_rnnt 7.776689 hw_loss 0.470708 lr 0.00058539 rank 3
2023-02-11 16:48:29,243 DEBUG TRAIN Batch 8/6300 loss 9.007911 loss_att 11.179868 loss_ctc 15.409424 loss_rnnt 4.971302 hw_loss 0.515378 lr 0.00058497 rank 0
2023-02-11 16:48:29,245 DEBUG TRAIN Batch 8/6300 loss 13.669029 loss_att 11.533777 loss_ctc 18.321369 loss_rnnt 9.554132 hw_loss 0.735307 lr 0.00058509 rank 1
2023-02-11 16:48:29,245 DEBUG TRAIN Batch 8/6300 loss 25.077740 loss_att 23.803951 loss_ctc 32.487537 loss_rnnt 22.141705 hw_loss 0.413029 lr 0.00058529 rank 7
2023-02-11 16:48:29,246 DEBUG TRAIN Batch 8/6300 loss 14.854744 loss_att 11.799338 loss_ctc 16.321304 loss_rnnt 10.197596 hw_loss 0.951129 lr 0.00058505 rank 5
2023-02-11 16:48:29,246 DEBUG TRAIN Batch 8/6300 loss 20.277275 loss_att 19.618080 loss_ctc 30.259256 loss_rnnt 14.767090 hw_loss 0.808330 lr 0.00058489 rank 2
2023-02-11 16:48:29,248 DEBUG TRAIN Batch 8/6300 loss 25.691153 loss_att 27.685152 loss_ctc 32.398621 loss_rnnt 20.829971 hw_loss 0.669010 lr 0.00058529 rank 4
2023-02-11 16:48:29,295 DEBUG TRAIN Batch 8/6300 loss 19.371382 loss_att 20.645765 loss_ctc 25.972166 loss_rnnt 15.852524 hw_loss 0.446977 lr 0.00058524 rank 6
2023-02-11 16:49:48,355 DEBUG TRAIN Batch 8/6400 loss 18.520317 loss_att 23.930183 loss_ctc 26.395483 loss_rnnt 13.482856 hw_loss 0.544775 lr 0.00058457 rank 0
2023-02-11 16:49:48,359 DEBUG TRAIN Batch 8/6400 loss 10.754333 loss_att 15.649660 loss_ctc 15.582446 loss_rnnt 7.470412 hw_loss 0.311458 lr 0.00058465 rank 5
2023-02-11 16:49:48,359 DEBUG TRAIN Batch 8/6400 loss 24.536434 loss_att 25.634121 loss_ctc 30.600018 loss_rnnt 20.945293 hw_loss 0.480586 lr 0.00058489 rank 7
2023-02-11 16:49:48,360 DEBUG TRAIN Batch 8/6400 loss 16.579447 loss_att 15.990086 loss_ctc 21.399342 loss_rnnt 12.281374 hw_loss 0.707492 lr 0.00058449 rank 2
2023-02-11 16:49:48,361 DEBUG TRAIN Batch 8/6400 loss 18.461525 loss_att 17.212784 loss_ctc 24.870523 loss_rnnt 14.300082 hw_loss 0.666873 lr 0.00058484 rank 6
2023-02-11 16:49:48,364 DEBUG TRAIN Batch 8/6400 loss 10.685987 loss_att 14.431151 loss_ctc 15.975960 loss_rnnt 8.816379 hw_loss 0.077858 lr 0.00058499 rank 3
2023-02-11 16:49:48,366 DEBUG TRAIN Batch 8/6400 loss 9.218859 loss_att 11.558967 loss_ctc 12.075272 loss_rnnt 7.324534 hw_loss 0.196021 lr 0.00058469 rank 1
2023-02-11 16:49:48,368 DEBUG TRAIN Batch 8/6400 loss 15.962462 loss_att 17.711058 loss_ctc 20.484741 loss_rnnt 11.238209 hw_loss 0.707168 lr 0.00058489 rank 4
2023-02-11 16:51:04,908 DEBUG TRAIN Batch 8/6500 loss 12.584489 loss_att 14.588078 loss_ctc 16.706413 loss_rnnt 9.313225 hw_loss 0.435180 lr 0.00058444 rank 6
2023-02-11 16:51:04,909 DEBUG TRAIN Batch 8/6500 loss 12.059317 loss_att 15.482643 loss_ctc 20.045147 loss_rnnt 6.535713 hw_loss 0.707655 lr 0.00058417 rank 0
2023-02-11 16:51:04,909 DEBUG TRAIN Batch 8/6500 loss 14.098951 loss_att 22.831753 loss_ctc 26.736740 loss_rnnt 9.726089 hw_loss 0.176487 lr 0.00058449 rank 4
2023-02-11 16:51:04,911 DEBUG TRAIN Batch 8/6500 loss 13.457837 loss_att 15.706614 loss_ctc 22.554184 loss_rnnt 10.408241 hw_loss 0.260061 lr 0.00058459 rank 3
2023-02-11 16:51:04,912 DEBUG TRAIN Batch 8/6500 loss 17.487715 loss_att 18.694933 loss_ctc 24.948483 loss_rnnt 15.143448 hw_loss 0.207760 lr 0.00058449 rank 7
2023-02-11 16:51:04,914 DEBUG TRAIN Batch 8/6500 loss 20.048101 loss_att 20.450371 loss_ctc 27.337276 loss_rnnt 15.724803 hw_loss 0.613304 lr 0.00058425 rank 5
2023-02-11 16:51:04,916 DEBUG TRAIN Batch 8/6500 loss 17.000111 loss_att 22.912779 loss_ctc 29.249935 loss_rnnt 13.876483 hw_loss 0.057710 lr 0.00058409 rank 2
2023-02-11 16:51:04,963 DEBUG TRAIN Batch 8/6500 loss 14.331002 loss_att 16.963535 loss_ctc 30.174538 loss_rnnt 9.832031 hw_loss 0.348748 lr 0.00058429 rank 1
2023-02-11 16:52:20,800 DEBUG TRAIN Batch 8/6600 loss 13.461423 loss_att 17.873844 loss_ctc 17.542908 loss_rnnt 11.422989 hw_loss 0.114703 lr 0.00058409 rank 7
2023-02-11 16:52:20,801 DEBUG TRAIN Batch 8/6600 loss 14.476575 loss_att 16.711605 loss_ctc 20.248701 loss_rnnt 9.871189 hw_loss 0.635393 lr 0.00058377 rank 0
2023-02-11 16:52:20,804 DEBUG TRAIN Batch 8/6600 loss 13.397820 loss_att 14.396753 loss_ctc 21.888237 loss_rnnt 11.066245 hw_loss 0.187450 lr 0.00058369 rank 2
2023-02-11 16:52:20,804 DEBUG TRAIN Batch 8/6600 loss 17.456314 loss_att 18.024734 loss_ctc 27.954353 loss_rnnt 13.324699 hw_loss 0.490911 lr 0.00058404 rank 6
2023-02-11 16:52:20,804 DEBUG TRAIN Batch 8/6600 loss 10.571366 loss_att 14.186216 loss_ctc 17.230961 loss_rnnt 5.372172 hw_loss 0.672802 lr 0.00058386 rank 5
2023-02-11 16:52:20,805 DEBUG TRAIN Batch 8/6600 loss 17.269464 loss_att 22.363783 loss_ctc 32.817627 loss_rnnt 12.040377 hw_loss 0.400713 lr 0.00058389 rank 1
2023-02-11 16:52:20,808 DEBUG TRAIN Batch 8/6600 loss 17.948963 loss_att 20.596409 loss_ctc 21.229275 loss_rnnt 12.576529 hw_loss 0.826045 lr 0.00058419 rank 3
2023-02-11 16:52:20,811 DEBUG TRAIN Batch 8/6600 loss 16.446861 loss_att 15.766258 loss_ctc 24.412014 loss_rnnt 13.755150 hw_loss 0.331090 lr 0.00058409 rank 4
2023-02-11 16:53:37,783 DEBUG TRAIN Batch 8/6700 loss 14.925459 loss_att 19.843639 loss_ctc 25.565180 loss_rnnt 10.667930 hw_loss 0.347862 lr 0.00058364 rank 6
2023-02-11 16:53:37,783 DEBUG TRAIN Batch 8/6700 loss 20.372978 loss_att 24.535662 loss_ctc 37.407166 loss_rnnt 14.367755 hw_loss 0.544024 lr 0.00058369 rank 7
2023-02-11 16:53:37,784 DEBUG TRAIN Batch 8/6700 loss 33.215374 loss_att 32.250004 loss_ctc 48.666847 loss_rnnt 27.589424 hw_loss 0.704780 lr 0.00058330 rank 2
2023-02-11 16:53:37,785 DEBUG TRAIN Batch 8/6700 loss 13.855345 loss_att 19.169264 loss_ctc 19.129276 loss_rnnt 11.664333 hw_loss 0.079694 lr 0.00058337 rank 0
2023-02-11 16:53:37,785 DEBUG TRAIN Batch 8/6700 loss 11.692595 loss_att 13.785450 loss_ctc 17.770514 loss_rnnt 8.121026 hw_loss 0.439239 lr 0.00058369 rank 4
2023-02-11 16:53:37,790 DEBUG TRAIN Batch 8/6700 loss 8.337547 loss_att 9.152669 loss_ctc 11.638187 loss_rnnt 4.898657 hw_loss 0.531709 lr 0.00058346 rank 5
2023-02-11 16:53:37,792 DEBUG TRAIN Batch 8/6700 loss 34.461430 loss_att 32.712250 loss_ctc 52.540367 loss_rnnt 29.862364 hw_loss 0.475945 lr 0.00058379 rank 3
2023-02-11 16:53:37,841 DEBUG TRAIN Batch 8/6700 loss 14.245005 loss_att 14.477694 loss_ctc 19.105146 loss_rnnt 11.138506 hw_loss 0.452239 lr 0.00058349 rank 1
2023-02-11 16:54:56,930 DEBUG TRAIN Batch 8/6800 loss 20.603624 loss_att 20.545292 loss_ctc 25.111530 loss_rnnt 17.963718 hw_loss 0.384472 lr 0.00058290 rank 2
2023-02-11 16:54:56,930 DEBUG TRAIN Batch 8/6800 loss 20.809280 loss_att 21.897207 loss_ctc 28.773474 loss_rnnt 16.997345 hw_loss 0.474835 lr 0.00058297 rank 0
2023-02-11 16:54:56,932 DEBUG TRAIN Batch 8/6800 loss 14.782628 loss_att 14.290009 loss_ctc 22.965754 loss_rnnt 10.046571 hw_loss 0.701906 lr 0.00058339 rank 3
2023-02-11 16:54:56,934 DEBUG TRAIN Batch 8/6800 loss 13.048244 loss_att 17.921074 loss_ctc 21.459030 loss_rnnt 8.733709 hw_loss 0.415974 lr 0.00058329 rank 7
2023-02-11 16:54:56,934 DEBUG TRAIN Batch 8/6800 loss 26.174553 loss_att 27.987419 loss_ctc 39.738316 loss_rnnt 21.433237 hw_loss 0.481920 lr 0.00058330 rank 4
2023-02-11 16:54:56,937 DEBUG TRAIN Batch 8/6800 loss 21.522278 loss_att 23.826698 loss_ctc 28.493492 loss_rnnt 16.708448 hw_loss 0.641897 lr 0.00058310 rank 1
2023-02-11 16:54:56,939 DEBUG TRAIN Batch 8/6800 loss 24.024439 loss_att 28.160812 loss_ctc 39.753143 loss_rnnt 17.558258 hw_loss 0.664077 lr 0.00058306 rank 5
2023-02-11 16:54:56,984 DEBUG TRAIN Batch 8/6800 loss 14.098330 loss_att 15.510656 loss_ctc 24.171562 loss_rnnt 11.030690 hw_loss 0.270389 lr 0.00058324 rank 6
2023-02-11 16:56:12,797 DEBUG TRAIN Batch 8/6900 loss 11.541093 loss_att 12.617657 loss_ctc 17.613388 loss_rnnt 9.202862 hw_loss 0.246240 lr 0.00058300 rank 3
2023-02-11 16:56:12,802 DEBUG TRAIN Batch 8/6900 loss 16.879944 loss_att 17.315514 loss_ctc 23.367247 loss_rnnt 14.156113 hw_loss 0.332202 lr 0.00058290 rank 4
2023-02-11 16:56:12,804 DEBUG TRAIN Batch 8/6900 loss 11.959504 loss_att 14.102662 loss_ctc 18.654621 loss_rnnt 8.618167 hw_loss 0.378754 lr 0.00058285 rank 6
2023-02-11 16:56:12,804 DEBUG TRAIN Batch 8/6900 loss 15.072432 loss_att 15.124603 loss_ctc 21.873180 loss_rnnt 12.052658 hw_loss 0.394232 lr 0.00058267 rank 5
2023-02-11 16:56:12,806 DEBUG TRAIN Batch 8/6900 loss 21.548376 loss_att 20.643150 loss_ctc 30.224581 loss_rnnt 18.212950 hw_loss 0.442433 lr 0.00058258 rank 0
2023-02-11 16:56:12,806 DEBUG TRAIN Batch 8/6900 loss 10.184793 loss_att 12.535158 loss_ctc 18.233171 loss_rnnt 6.865101 hw_loss 0.333094 lr 0.00058289 rank 7
2023-02-11 16:56:12,809 DEBUG TRAIN Batch 8/6900 loss 25.736406 loss_att 26.144464 loss_ctc 39.794136 loss_rnnt 20.038670 hw_loss 0.701581 lr 0.00058270 rank 1
2023-02-11 16:56:12,809 DEBUG TRAIN Batch 8/6900 loss 19.994339 loss_att 20.483599 loss_ctc 34.959450 loss_rnnt 15.710105 hw_loss 0.410819 lr 0.00058250 rank 2
2023-02-11 16:57:29,824 DEBUG TRAIN Batch 8/7000 loss 18.364664 loss_att 19.286013 loss_ctc 23.297436 loss_rnnt 14.857201 hw_loss 0.499780 lr 0.00058260 rank 3
2023-02-11 16:57:29,827 DEBUG TRAIN Batch 8/7000 loss 21.878664 loss_att 26.540123 loss_ctc 28.095963 loss_rnnt 17.058296 hw_loss 0.573582 lr 0.00058250 rank 7
2023-02-11 16:57:29,829 DEBUG TRAIN Batch 8/7000 loss 16.362942 loss_att 17.990973 loss_ctc 19.933903 loss_rnnt 12.400734 hw_loss 0.592589 lr 0.00058231 rank 1
2023-02-11 16:57:29,830 DEBUG TRAIN Batch 8/7000 loss 15.082146 loss_att 11.077276 loss_ctc 13.870845 loss_rnnt 8.998306 hw_loss 1.321185 lr 0.00058245 rank 6
2023-02-11 16:57:29,832 DEBUG TRAIN Batch 8/7000 loss 16.787956 loss_att 16.844622 loss_ctc 20.653891 loss_rnnt 13.808696 hw_loss 0.459838 lr 0.00058218 rank 0
2023-02-11 16:57:29,836 DEBUG TRAIN Batch 8/7000 loss 17.623720 loss_att 15.966267 loss_ctc 20.854265 loss_rnnt 12.246011 hw_loss 0.989711 lr 0.00058250 rank 4
2023-02-11 16:57:29,850 DEBUG TRAIN Batch 8/7000 loss 19.423058 loss_att 22.500792 loss_ctc 30.841381 loss_rnnt 15.462360 hw_loss 0.341758 lr 0.00058227 rank 5
2023-02-11 16:57:29,877 DEBUG TRAIN Batch 8/7000 loss 13.936603 loss_att 13.270828 loss_ctc 20.852949 loss_rnnt 11.336755 hw_loss 0.339529 lr 0.00058211 rank 2
2023-02-11 16:58:48,993 DEBUG TRAIN Batch 8/7100 loss 16.262917 loss_att 19.551155 loss_ctc 25.270950 loss_rnnt 13.473033 hw_loss 0.174594 lr 0.00058221 rank 3
2023-02-11 16:58:48,995 DEBUG TRAIN Batch 8/7100 loss 13.935341 loss_att 9.569282 loss_ctc 14.341716 loss_rnnt 9.741089 hw_loss 0.939990 lr 0.00058179 rank 0
2023-02-11 16:58:49,000 DEBUG TRAIN Batch 8/7100 loss 13.449973 loss_att 17.474937 loss_ctc 20.419548 loss_rnnt 9.753344 hw_loss 0.367943 lr 0.00058211 rank 4
2023-02-11 16:58:49,001 DEBUG TRAIN Batch 8/7100 loss 17.899263 loss_att 18.718346 loss_ctc 24.446989 loss_rnnt 15.035613 hw_loss 0.342525 lr 0.00058206 rank 6
2023-02-11 16:58:49,002 DEBUG TRAIN Batch 8/7100 loss 16.846260 loss_att 17.555527 loss_ctc 21.071535 loss_rnnt 15.496646 hw_loss 0.120823 lr 0.00058188 rank 5
2023-02-11 16:58:49,003 DEBUG TRAIN Batch 8/7100 loss 17.186663 loss_att 16.391726 loss_ctc 21.906792 loss_rnnt 13.542613 hw_loss 0.595066 lr 0.00058210 rank 7
2023-02-11 16:58:49,004 DEBUG TRAIN Batch 8/7100 loss 10.331158 loss_att 12.606887 loss_ctc 14.825706 loss_rnnt 6.062387 hw_loss 0.602691 lr 0.00058171 rank 2
2023-02-11 16:58:49,008 DEBUG TRAIN Batch 8/7100 loss 6.898617 loss_att 9.218285 loss_ctc 11.759680 loss_rnnt 5.456613 hw_loss 0.061862 lr 0.00058191 rank 1
2023-02-11 17:00:05,981 DEBUG TRAIN Batch 8/7200 loss 12.455832 loss_att 15.236255 loss_ctc 20.665792 loss_rnnt 8.704584 hw_loss 0.393844 lr 0.00058171 rank 7
2023-02-11 17:00:05,982 DEBUG TRAIN Batch 8/7200 loss 22.164318 loss_att 22.741875 loss_ctc 33.098606 loss_rnnt 17.715233 hw_loss 0.539188 lr 0.00058140 rank 0
2023-02-11 17:00:05,985 DEBUG TRAIN Batch 8/7200 loss 23.329174 loss_att 25.435667 loss_ctc 30.187313 loss_rnnt 16.734573 hw_loss 0.986041 lr 0.00058166 rank 6
2023-02-11 17:00:05,986 DEBUG TRAIN Batch 8/7200 loss 40.676098 loss_att 40.372177 loss_ctc 58.938263 loss_rnnt 37.663986 hw_loss 0.119614 lr 0.00058181 rank 3
2023-02-11 17:00:05,988 DEBUG TRAIN Batch 8/7200 loss 16.977287 loss_att 17.313696 loss_ctc 28.166092 loss_rnnt 12.436121 hw_loss 0.559133 lr 0.00058152 rank 1
2023-02-11 17:00:05,989 DEBUG TRAIN Batch 8/7200 loss 15.124109 loss_att 18.378344 loss_ctc 21.563757 loss_rnnt 10.981882 hw_loss 0.493642 lr 0.00058148 rank 5
2023-02-11 17:00:05,996 DEBUG TRAIN Batch 8/7200 loss 21.230539 loss_att 24.390135 loss_ctc 36.482559 loss_rnnt 17.547306 hw_loss 0.190821 lr 0.00058132 rank 2
2023-02-11 17:00:06,041 DEBUG TRAIN Batch 8/7200 loss 8.789238 loss_att 10.363311 loss_ctc 12.942570 loss_rnnt 3.906523 hw_loss 0.752648 lr 0.00058171 rank 4
2023-02-11 17:01:22,357 DEBUG TRAIN Batch 8/7300 loss 15.200482 loss_att 18.890602 loss_ctc 24.842793 loss_rnnt 11.962032 hw_loss 0.227772 lr 0.00058100 rank 0
2023-02-11 17:01:22,361 DEBUG TRAIN Batch 8/7300 loss 14.060257 loss_att 15.758986 loss_ctc 19.551283 loss_rnnt 11.458400 hw_loss 0.286870 lr 0.00058127 rank 6
2023-02-11 17:01:22,362 DEBUG TRAIN Batch 8/7300 loss 15.342427 loss_att 16.014399 loss_ctc 20.872862 loss_rnnt 11.997470 hw_loss 0.463720 lr 0.00058093 rank 2
2023-02-11 17:01:22,362 DEBUG TRAIN Batch 8/7300 loss 17.803747 loss_att 24.665178 loss_ctc 34.769642 loss_rnnt 11.507438 hw_loss 0.499107 lr 0.00058132 rank 7
2023-02-11 17:01:22,365 DEBUG TRAIN Batch 8/7300 loss 10.580011 loss_att 15.005373 loss_ctc 16.430017 loss_rnnt 8.058657 hw_loss 0.160553 lr 0.00058142 rank 3
2023-02-11 17:01:22,368 DEBUG TRAIN Batch 8/7300 loss 18.604214 loss_att 24.580357 loss_ctc 34.557709 loss_rnnt 14.027580 hw_loss 0.235176 lr 0.00058112 rank 1
2023-02-11 17:01:22,368 DEBUG TRAIN Batch 8/7300 loss 18.515276 loss_att 21.589849 loss_ctc 28.079861 loss_rnnt 15.069887 hw_loss 0.291599 lr 0.00058109 rank 5
2023-02-11 17:01:22,369 DEBUG TRAIN Batch 8/7300 loss 15.612816 loss_att 15.824394 loss_ctc 25.190079 loss_rnnt 11.835300 hw_loss 0.460919 lr 0.00058132 rank 4
2023-02-11 17:02:39,992 DEBUG TRAIN Batch 8/7400 loss 13.546587 loss_att 15.790148 loss_ctc 16.636530 loss_rnnt 9.000996 hw_loss 0.690916 lr 0.00058061 rank 0
2023-02-11 17:02:39,994 DEBUG TRAIN Batch 8/7400 loss 18.589603 loss_att 18.331940 loss_ctc 22.308271 loss_rnnt 14.443865 hw_loss 0.694021 lr 0.00058093 rank 4
2023-02-11 17:02:39,996 DEBUG TRAIN Batch 8/7400 loss 11.952550 loss_att 14.325121 loss_ctc 18.416302 loss_rnnt 7.291426 hw_loss 0.623395 lr 0.00058088 rank 6
2023-02-11 17:02:39,998 DEBUG TRAIN Batch 8/7400 loss 17.775682 loss_att 19.803328 loss_ctc 32.622459 loss_rnnt 12.409829 hw_loss 0.558891 lr 0.00058054 rank 2
2023-02-11 17:02:40,003 DEBUG TRAIN Batch 8/7400 loss 14.905989 loss_att 15.900433 loss_ctc 18.449385 loss_rnnt 11.964476 hw_loss 0.425657 lr 0.00058070 rank 5
2023-02-11 17:02:40,004 DEBUG TRAIN Batch 8/7400 loss 13.036871 loss_att 13.358484 loss_ctc 14.892320 loss_rnnt 10.512781 hw_loss 0.414820 lr 0.00058103 rank 3
2023-02-11 17:02:40,005 DEBUG TRAIN Batch 8/7400 loss 17.936708 loss_att 16.518822 loss_ctc 26.203754 loss_rnnt 13.436243 hw_loss 0.690332 lr 0.00058092 rank 7
2023-02-11 17:02:40,041 DEBUG TRAIN Batch 8/7400 loss 18.846914 loss_att 20.512199 loss_ctc 21.644657 loss_rnnt 17.654964 hw_loss 0.091099 lr 0.00058073 rank 1
2023-02-11 17:03:58,779 DEBUG TRAIN Batch 8/7500 loss 18.291956 loss_att 17.672796 loss_ctc 20.707554 loss_rnnt 14.738383 hw_loss 0.629124 lr 0.00058031 rank 5
2023-02-11 17:03:58,780 DEBUG TRAIN Batch 8/7500 loss 24.231270 loss_att 23.389900 loss_ctc 34.764290 loss_rnnt 19.133301 hw_loss 0.724095 lr 0.00058034 rank 1
2023-02-11 17:03:58,782 DEBUG TRAIN Batch 8/7500 loss 17.513422 loss_att 17.477768 loss_ctc 24.581844 loss_rnnt 13.123344 hw_loss 0.647766 lr 0.00058063 rank 3
2023-02-11 17:03:58,783 DEBUG TRAIN Batch 8/7500 loss 15.466483 loss_att 18.800190 loss_ctc 23.791254 loss_rnnt 11.857723 hw_loss 0.343509 lr 0.00058054 rank 4
2023-02-11 17:03:58,786 DEBUG TRAIN Batch 8/7500 loss 14.874203 loss_att 20.055576 loss_ctc 23.772997 loss_rnnt 11.428074 hw_loss 0.229378 lr 0.00058015 rank 2
2023-02-11 17:03:58,786 DEBUG TRAIN Batch 8/7500 loss 14.197903 loss_att 18.928532 loss_ctc 28.164932 loss_rnnt 9.803128 hw_loss 0.297446 lr 0.00058022 rank 0
2023-02-11 17:03:58,789 DEBUG TRAIN Batch 8/7500 loss 14.010031 loss_att 16.315241 loss_ctc 18.252764 loss_rnnt 10.843678 hw_loss 0.401177 lr 0.00058053 rank 7
2023-02-11 17:03:58,791 DEBUG TRAIN Batch 8/7500 loss 13.943834 loss_att 13.667032 loss_ctc 14.108510 loss_rnnt 11.177957 hw_loss 0.524865 lr 0.00058049 rank 6
2023-02-11 17:05:13,977 DEBUG TRAIN Batch 8/7600 loss 14.937297 loss_att 15.939274 loss_ctc 19.814255 loss_rnnt 11.839062 hw_loss 0.421421 lr 0.00058014 rank 7
2023-02-11 17:05:13,979 DEBUG TRAIN Batch 8/7600 loss 23.001537 loss_att 26.633545 loss_ctc 32.469406 loss_rnnt 18.387426 hw_loss 0.492249 lr 0.00057983 rank 0
2023-02-11 17:05:13,981 DEBUG TRAIN Batch 8/7600 loss 9.806124 loss_att 14.032883 loss_ctc 17.142944 loss_rnnt 6.191891 hw_loss 0.335745 lr 0.00058024 rank 3
2023-02-11 17:05:13,983 DEBUG TRAIN Batch 8/7600 loss 14.410270 loss_att 14.833706 loss_ctc 17.720724 loss_rnnt 10.486600 hw_loss 0.637048 lr 0.00057976 rank 2
2023-02-11 17:05:13,984 DEBUG TRAIN Batch 8/7600 loss 8.056723 loss_att 9.408547 loss_ctc 7.695955 loss_rnnt 3.369444 hw_loss 0.837190 lr 0.00058009 rank 6
2023-02-11 17:05:13,985 DEBUG TRAIN Batch 8/7600 loss 12.515295 loss_att 9.514563 loss_ctc 13.033694 loss_rnnt 7.749975 hw_loss 0.993065 lr 0.00058015 rank 4
2023-02-11 17:05:13,986 DEBUG TRAIN Batch 8/7600 loss 18.978350 loss_att 12.920280 loss_ctc 16.207912 loss_rnnt 13.276636 hw_loss 1.365509 lr 0.00057992 rank 5
2023-02-11 17:05:13,988 DEBUG TRAIN Batch 8/7600 loss 16.539894 loss_att 20.818760 loss_ctc 30.368237 loss_rnnt 12.609716 hw_loss 0.230743 lr 0.00057995 rank 1
2023-02-11 17:06:29,377 DEBUG TRAIN Batch 8/7700 loss 13.327882 loss_att 15.295281 loss_ctc 18.251347 loss_rnnt 9.748583 hw_loss 0.474254 lr 0.00057975 rank 7
2023-02-11 17:06:29,378 DEBUG TRAIN Batch 8/7700 loss 34.626194 loss_att 36.704254 loss_ctc 49.741730 loss_rnnt 31.804680 hw_loss 0.073218 lr 0.00057985 rank 3
2023-02-11 17:06:29,378 DEBUG TRAIN Batch 8/7700 loss 13.514801 loss_att 14.504577 loss_ctc 17.358351 loss_rnnt 11.237796 hw_loss 0.293733 lr 0.00057953 rank 5
2023-02-11 17:06:29,379 DEBUG TRAIN Batch 8/7700 loss 16.605755 loss_att 15.435652 loss_ctc 16.534666 loss_rnnt 11.629718 hw_loss 0.978663 lr 0.00057944 rank 0
2023-02-11 17:06:29,381 DEBUG TRAIN Batch 8/7700 loss 13.888960 loss_att 10.253210 loss_ctc 14.467792 loss_rnnt 8.838243 hw_loss 1.068879 lr 0.00057937 rank 2
2023-02-11 17:06:29,383 DEBUG TRAIN Batch 8/7700 loss 16.896006 loss_att 16.473951 loss_ctc 22.591179 loss_rnnt 14.619460 hw_loss 0.300300 lr 0.00057956 rank 1
2023-02-11 17:06:29,385 DEBUG TRAIN Batch 8/7700 loss 17.293488 loss_att 19.973057 loss_ctc 28.134888 loss_rnnt 14.020987 hw_loss 0.242075 lr 0.00057976 rank 4
2023-02-11 17:06:29,386 DEBUG TRAIN Batch 8/7700 loss 16.001575 loss_att 19.293898 loss_ctc 25.817266 loss_rnnt 11.372211 hw_loss 0.499151 lr 0.00057970 rank 6
2023-02-11 17:07:47,821 DEBUG TRAIN Batch 8/7800 loss 19.998222 loss_att 22.350677 loss_ctc 26.725052 loss_rnnt 15.717581 hw_loss 0.546233 lr 0.00057946 rank 3
2023-02-11 17:07:47,823 DEBUG TRAIN Batch 8/7800 loss 7.794669 loss_att 13.016427 loss_ctc 11.952473 loss_rnnt 4.337796 hw_loss 0.348403 lr 0.00057936 rank 7
2023-02-11 17:07:47,825 DEBUG TRAIN Batch 8/7800 loss 21.193575 loss_att 24.988972 loss_ctc 36.817234 loss_rnnt 17.911276 hw_loss 0.082512 lr 0.00057905 rank 0
2023-02-11 17:07:47,826 DEBUG TRAIN Batch 8/7800 loss 12.803287 loss_att 13.477451 loss_ctc 25.870314 loss_rnnt 8.602468 hw_loss 0.435696 lr 0.00057932 rank 6
2023-02-11 17:07:47,827 DEBUG TRAIN Batch 8/7800 loss 14.339746 loss_att 16.964598 loss_ctc 19.910000 loss_rnnt 10.778801 hw_loss 0.429989 lr 0.00057917 rank 1
2023-02-11 17:07:47,827 DEBUG TRAIN Batch 8/7800 loss 15.993499 loss_att 21.497469 loss_ctc 22.737028 loss_rnnt 11.957652 hw_loss 0.381734 lr 0.00057914 rank 5
2023-02-11 17:07:47,829 DEBUG TRAIN Batch 8/7800 loss 5.359993 loss_att 9.388147 loss_ctc 8.428438 loss_rnnt 3.650625 hw_loss 0.092740 lr 0.00057898 rank 2
2023-02-11 17:07:47,831 DEBUG TRAIN Batch 8/7800 loss 11.658207 loss_att 14.092704 loss_ctc 18.071682 loss_rnnt 7.715980 hw_loss 0.487537 lr 0.00057937 rank 4
2023-02-11 17:09:03,871 DEBUG TRAIN Batch 8/7900 loss 12.732708 loss_att 14.000751 loss_ctc 23.699408 loss_rnnt 9.150329 hw_loss 0.349977 lr 0.00057893 rank 6
2023-02-11 17:09:03,874 DEBUG TRAIN Batch 8/7900 loss 11.789655 loss_att 14.140537 loss_ctc 18.241280 loss_rnnt 6.077331 hw_loss 0.821612 lr 0.00057907 rank 3
2023-02-11 17:09:03,875 DEBUG TRAIN Batch 8/7900 loss 27.571217 loss_att 33.887142 loss_ctc 52.769257 loss_rnnt 22.205929 hw_loss 0.139194 lr 0.00057866 rank 0
2023-02-11 17:09:03,876 DEBUG TRAIN Batch 8/7900 loss 14.107030 loss_att 17.642178 loss_ctc 25.979469 loss_rnnt 8.863428 hw_loss 0.553796 lr 0.00057897 rank 7
2023-02-11 17:09:03,881 DEBUG TRAIN Batch 8/7900 loss 15.561108 loss_att 17.080797 loss_ctc 21.836193 loss_rnnt 13.917210 hw_loss 0.094365 lr 0.00057859 rank 2
2023-02-11 17:09:03,881 DEBUG TRAIN Batch 8/7900 loss 21.442173 loss_att 23.689693 loss_ctc 30.615849 loss_rnnt 17.005442 hw_loss 0.518263 lr 0.00057898 rank 4
2023-02-11 17:09:03,884 DEBUG TRAIN Batch 8/7900 loss 11.223289 loss_att 12.606871 loss_ctc 19.946815 loss_rnnt 7.294928 hw_loss 0.466595 lr 0.00057875 rank 5
2023-02-11 17:09:03,922 DEBUG TRAIN Batch 8/7900 loss 8.309333 loss_att 9.946048 loss_ctc 11.125659 loss_rnnt 6.171969 hw_loss 0.268971 lr 0.00057878 rank 1
2023-02-11 17:10:19,910 DEBUG TRAIN Batch 8/8000 loss 12.127538 loss_att 13.925066 loss_ctc 15.966739 loss_rnnt 7.899704 hw_loss 0.629332 lr 0.00057859 rank 7
2023-02-11 17:10:19,911 DEBUG TRAIN Batch 8/8000 loss 11.365936 loss_att 10.760023 loss_ctc 12.259713 loss_rnnt 9.315578 hw_loss 0.384820 lr 0.00057828 rank 0
2023-02-11 17:10:19,913 DEBUG TRAIN Batch 8/8000 loss 10.266594 loss_att 12.334506 loss_ctc 12.556812 loss_rnnt 8.117503 hw_loss 0.268153 lr 0.00057859 rank 4
2023-02-11 17:10:19,914 DEBUG TRAIN Batch 8/8000 loss 20.753622 loss_att 22.678249 loss_ctc 30.288218 loss_rnnt 14.711591 hw_loss 0.822342 lr 0.00057836 rank 5
2023-02-11 17:10:19,914 DEBUG TRAIN Batch 8/8000 loss 22.854033 loss_att 24.803322 loss_ctc 34.761795 loss_rnnt 17.983999 hw_loss 0.542339 lr 0.00057869 rank 3
2023-02-11 17:10:19,916 DEBUG TRAIN Batch 8/8000 loss 28.794998 loss_att 29.317041 loss_ctc 41.270836 loss_rnnt 23.219564 hw_loss 0.713921 lr 0.00057820 rank 2
2023-02-11 17:10:19,917 DEBUG TRAIN Batch 8/8000 loss 12.098715 loss_att 16.536108 loss_ctc 24.194132 loss_rnnt 8.336880 hw_loss 0.236556 lr 0.00057854 rank 6
2023-02-11 17:10:19,961 DEBUG TRAIN Batch 8/8000 loss 12.313986 loss_att 17.017551 loss_ctc 20.098402 loss_rnnt 8.618944 hw_loss 0.321826 lr 0.00057840 rank 1
2023-02-11 17:11:36,454 DEBUG TRAIN Batch 8/8100 loss 10.246511 loss_att 10.883228 loss_ctc 15.937992 loss_rnnt 8.027725 hw_loss 0.249858 lr 0.00057820 rank 7
2023-02-11 17:11:36,454 DEBUG TRAIN Batch 8/8100 loss 15.768936 loss_att 14.854147 loss_ctc 19.890182 loss_rnnt 11.054942 hw_loss 0.815147 lr 0.00057801 rank 1
2023-02-11 17:11:36,457 DEBUG TRAIN Batch 8/8100 loss 17.798407 loss_att 20.597553 loss_ctc 25.562866 loss_rnnt 13.943065 hw_loss 0.423797 lr 0.00057830 rank 3
2023-02-11 17:11:36,458 DEBUG TRAIN Batch 8/8100 loss 12.228583 loss_att 16.445959 loss_ctc 19.926142 loss_rnnt 7.765234 hw_loss 0.486287 lr 0.00057820 rank 4
2023-02-11 17:11:36,458 DEBUG TRAIN Batch 8/8100 loss 11.702900 loss_att 12.272317 loss_ctc 21.195698 loss_rnnt 9.651871 hw_loss 0.125895 lr 0.00057789 rank 0
2023-02-11 17:11:36,459 DEBUG TRAIN Batch 8/8100 loss 8.787390 loss_att 14.048697 loss_ctc 18.252434 loss_rnnt 6.000360 hw_loss 0.088643 lr 0.00057782 rank 2
2023-02-11 17:11:36,460 DEBUG TRAIN Batch 8/8100 loss 14.864494 loss_att 14.844481 loss_ctc 20.221687 loss_rnnt 10.200304 hw_loss 0.741356 lr 0.00057815 rank 6
2023-02-11 17:11:36,461 DEBUG TRAIN Batch 8/8100 loss 18.319292 loss_att 16.620178 loss_ctc 24.113251 loss_rnnt 15.559153 hw_loss 0.436394 lr 0.00057797 rank 5
2023-02-11 17:12:53,193 DEBUG TRAIN Batch 8/8200 loss 10.082678 loss_att 11.992353 loss_ctc 12.311533 loss_rnnt 6.665957 hw_loss 0.513301 lr 0.00057750 rank 0
2023-02-11 17:12:53,193 DEBUG TRAIN Batch 8/8200 loss 13.512104 loss_att 14.739023 loss_ctc 21.142387 loss_rnnt 10.943552 hw_loss 0.244837 lr 0.00057781 rank 7
2023-02-11 17:12:53,194 DEBUG TRAIN Batch 8/8200 loss 13.126589 loss_att 7.944752 loss_ctc 10.606833 loss_rnnt 7.914445 hw_loss 1.234589 lr 0.00057791 rank 3
2023-02-11 17:12:53,196 DEBUG TRAIN Batch 8/8200 loss 16.325825 loss_att 13.656549 loss_ctc 19.092487 loss_rnnt 11.803539 hw_loss 0.878860 lr 0.00057759 rank 5
2023-02-11 17:12:53,198 DEBUG TRAIN Batch 8/8200 loss 10.187554 loss_att 12.897505 loss_ctc 16.064796 loss_rnnt 6.873956 hw_loss 0.372746 lr 0.00057762 rank 1
2023-02-11 17:12:53,202 DEBUG TRAIN Batch 8/8200 loss 11.726713 loss_att 8.104589 loss_ctc 11.403894 loss_rnnt 6.698921 hw_loss 1.086611 lr 0.00057782 rank 4
2023-02-11 17:12:53,224 DEBUG TRAIN Batch 8/8200 loss 12.336657 loss_att 14.303204 loss_ctc 17.494143 loss_rnnt 5.718250 hw_loss 1.038269 lr 0.00057777 rank 6
2023-02-11 17:12:53,234 DEBUG TRAIN Batch 8/8200 loss 21.277111 loss_att 24.487448 loss_ctc 33.722969 loss_rnnt 17.163857 hw_loss 0.339701 lr 0.00057743 rank 2
2023-02-11 17:14:08,057 DEBUG TRAIN Batch 8/8300 loss 11.814265 loss_att 15.100602 loss_ctc 15.833494 loss_rnnt 9.633104 hw_loss 0.185249 lr 0.00057753 rank 3
2023-02-11 17:14:08,058 DEBUG TRAIN Batch 8/8300 loss 24.097815 loss_att 24.456343 loss_ctc 33.172070 loss_rnnt 19.017385 hw_loss 0.712279 lr 0.00057705 rank 2
2023-02-11 17:14:08,059 DEBUG TRAIN Batch 8/8300 loss 9.713865 loss_att 14.581793 loss_ctc 12.594208 loss_rnnt 6.307251 hw_loss 0.384184 lr 0.00057724 rank 1
2023-02-11 17:14:08,059 DEBUG TRAIN Batch 8/8300 loss 13.382610 loss_att 13.483697 loss_ctc 19.040649 loss_rnnt 8.383302 hw_loss 0.792129 lr 0.00057712 rank 0
2023-02-11 17:14:08,059 DEBUG TRAIN Batch 8/8300 loss 11.175563 loss_att 16.515919 loss_ctc 18.970615 loss_rnnt 8.141157 hw_loss 0.173811 lr 0.00057743 rank 7
2023-02-11 17:14:08,060 DEBUG TRAIN Batch 8/8300 loss 13.143935 loss_att 15.459543 loss_ctc 23.722406 loss_rnnt 9.712462 hw_loss 0.292104 lr 0.00057738 rank 6
2023-02-11 17:14:08,061 DEBUG TRAIN Batch 8/8300 loss 15.407938 loss_att 20.553391 loss_ctc 20.646564 loss_rnnt 11.717300 hw_loss 0.368074 lr 0.00057720 rank 5
2023-02-11 17:14:08,067 DEBUG TRAIN Batch 8/8300 loss 12.127210 loss_att 16.176958 loss_ctc 19.540985 loss_rnnt 8.902573 hw_loss 0.267410 lr 0.00057743 rank 4
2023-02-11 17:15:04,848 DEBUG CV Batch 8/0 loss 6.673301 loss_att 1.717778 loss_ctc 3.227750 loss_rnnt 1.210961 hw_loss 1.296160 history loss 6.426141 rank 3
2023-02-11 17:15:04,849 DEBUG CV Batch 8/0 loss 6.673301 loss_att 1.717778 loss_ctc 3.227750 loss_rnnt 1.210961 hw_loss 1.296160 history loss 6.426141 rank 6
2023-02-11 17:15:04,851 DEBUG CV Batch 8/0 loss 6.673301 loss_att 1.717778 loss_ctc 3.227750 loss_rnnt 1.210961 hw_loss 1.296160 history loss 6.426141 rank 7
2023-02-11 17:15:04,852 DEBUG CV Batch 8/0 loss 6.673300 loss_att 1.717778 loss_ctc 3.227750 loss_rnnt 1.210961 hw_loss 1.296159 history loss 6.426141 rank 1
2023-02-11 17:15:04,852 DEBUG CV Batch 8/0 loss 6.673301 loss_att 1.717778 loss_ctc 3.227750 loss_rnnt 1.210961 hw_loss 1.296160 history loss 6.426141 rank 0
2023-02-11 17:15:04,853 DEBUG CV Batch 8/0 loss 6.673301 loss_att 1.717778 loss_ctc 3.227750 loss_rnnt 1.210961 hw_loss 1.296160 history loss 6.426141 rank 4
2023-02-11 17:15:04,860 DEBUG CV Batch 8/0 loss 6.673301 loss_att 1.717778 loss_ctc 3.227750 loss_rnnt 1.210961 hw_loss 1.296160 history loss 6.426141 rank 5
2023-02-11 17:15:04,878 DEBUG CV Batch 8/0 loss 6.673301 loss_att 1.717778 loss_ctc 3.227750 loss_rnnt 1.210961 hw_loss 1.296160 history loss 6.426141 rank 2
2023-02-11 17:15:15,938 DEBUG CV Batch 8/100 loss 9.700424 loss_att 9.784759 loss_ctc 14.968165 loss_rnnt 5.596525 hw_loss 0.634625 history loss 7.586703 rank 7
2023-02-11 17:15:15,943 DEBUG CV Batch 8/100 loss 9.700424 loss_att 9.784759 loss_ctc 14.968165 loss_rnnt 5.596525 hw_loss 0.634625 history loss 7.586703 rank 0
2023-02-11 17:15:15,984 DEBUG CV Batch 8/100 loss 9.700424 loss_att 9.784759 loss_ctc 14.968165 loss_rnnt 5.596525 hw_loss 0.634625 history loss 7.586703 rank 3
2023-02-11 17:15:16,011 DEBUG CV Batch 8/100 loss 9.700424 loss_att 9.784759 loss_ctc 14.968165 loss_rnnt 5.596525 hw_loss 0.634625 history loss 7.586703 rank 4
2023-02-11 17:15:16,027 DEBUG CV Batch 8/100 loss 9.700424 loss_att 9.784759 loss_ctc 14.968165 loss_rnnt 5.596525 hw_loss 0.634625 history loss 7.586703 rank 5
2023-02-11 17:15:16,047 DEBUG CV Batch 8/100 loss 9.700424 loss_att 9.784759 loss_ctc 14.968165 loss_rnnt 5.596525 hw_loss 0.634625 history loss 7.586703 rank 6
2023-02-11 17:15:16,105 DEBUG CV Batch 8/100 loss 9.700424 loss_att 9.784759 loss_ctc 14.968165 loss_rnnt 5.596525 hw_loss 0.634625 history loss 7.586703 rank 2
2023-02-11 17:15:16,571 DEBUG CV Batch 8/100 loss 9.700424 loss_att 9.784759 loss_ctc 14.968165 loss_rnnt 5.596525 hw_loss 0.634625 history loss 7.586703 rank 1
2023-02-11 17:15:29,542 DEBUG CV Batch 8/200 loss 12.378107 loss_att 19.549660 loss_ctc 20.488701 loss_rnnt 8.438969 hw_loss 0.266890 history loss 8.069271 rank 5
2023-02-11 17:15:29,574 DEBUG CV Batch 8/200 loss 12.378107 loss_att 19.549660 loss_ctc 20.488701 loss_rnnt 8.438969 hw_loss 0.266890 history loss 8.069271 rank 7
2023-02-11 17:15:29,597 DEBUG CV Batch 8/200 loss 12.378107 loss_att 19.549660 loss_ctc 20.488701 loss_rnnt 8.438969 hw_loss 0.266890 history loss 8.069271 rank 0
2023-02-11 17:15:29,684 DEBUG CV Batch 8/200 loss 12.378107 loss_att 19.549660 loss_ctc 20.488701 loss_rnnt 8.438969 hw_loss 0.266890 history loss 8.069271 rank 3
2023-02-11 17:15:29,792 DEBUG CV Batch 8/200 loss 12.378107 loss_att 19.549660 loss_ctc 20.488701 loss_rnnt 8.438969 hw_loss 0.266890 history loss 8.069271 rank 2
2023-02-11 17:15:29,945 DEBUG CV Batch 8/200 loss 12.378107 loss_att 19.549660 loss_ctc 20.488701 loss_rnnt 8.438969 hw_loss 0.266890 history loss 8.069271 rank 4
2023-02-11 17:15:30,074 DEBUG CV Batch 8/200 loss 12.378107 loss_att 19.549660 loss_ctc 20.488701 loss_rnnt 8.438969 hw_loss 0.266890 history loss 8.069271 rank 6
2023-02-11 17:15:30,286 DEBUG CV Batch 8/200 loss 12.378107 loss_att 19.549660 loss_ctc 20.488701 loss_rnnt 8.438969 hw_loss 0.266890 history loss 8.069271 rank 1
2023-02-11 17:15:41,639 DEBUG CV Batch 8/300 loss 6.692795 loss_att 5.711765 loss_ctc 8.414837 loss_rnnt 3.758106 hw_loss 0.543992 history loss 8.324467 rank 0
2023-02-11 17:15:41,659 DEBUG CV Batch 8/300 loss 6.692795 loss_att 5.711765 loss_ctc 8.414837 loss_rnnt 3.758106 hw_loss 0.543992 history loss 8.324467 rank 7
2023-02-11 17:15:41,670 DEBUG CV Batch 8/300 loss 6.692795 loss_att 5.711765 loss_ctc 8.414837 loss_rnnt 3.758106 hw_loss 0.543992 history loss 8.324467 rank 5
2023-02-11 17:15:41,715 DEBUG CV Batch 8/300 loss 6.692795 loss_att 5.711765 loss_ctc 8.414837 loss_rnnt 3.758106 hw_loss 0.543992 history loss 8.324467 rank 3
2023-02-11 17:15:41,912 DEBUG CV Batch 8/300 loss 6.692795 loss_att 5.711765 loss_ctc 8.414837 loss_rnnt 3.758106 hw_loss 0.543992 history loss 8.324467 rank 2
2023-02-11 17:15:42,086 DEBUG CV Batch 8/300 loss 6.692795 loss_att 5.711765 loss_ctc 8.414837 loss_rnnt 3.758106 hw_loss 0.543992 history loss 8.324467 rank 4
2023-02-11 17:15:42,110 DEBUG CV Batch 8/300 loss 6.692795 loss_att 5.711765 loss_ctc 8.414837 loss_rnnt 3.758106 hw_loss 0.543992 history loss 8.324467 rank 6
2023-02-11 17:15:43,150 DEBUG CV Batch 8/300 loss 6.692795 loss_att 5.711765 loss_ctc 8.414837 loss_rnnt 3.758106 hw_loss 0.543992 history loss 8.324467 rank 1
2023-02-11 17:15:53,508 DEBUG CV Batch 8/400 loss 15.214766 loss_att 65.842377 loss_ctc 14.519621 loss_rnnt 4.486160 hw_loss 0.130456 history loss 9.200882 rank 0
2023-02-11 17:15:53,635 DEBUG CV Batch 8/400 loss 15.214766 loss_att 65.842377 loss_ctc 14.519621 loss_rnnt 4.486160 hw_loss 0.130456 history loss 9.200882 rank 3
2023-02-11 17:15:53,653 DEBUG CV Batch 8/400 loss 15.214766 loss_att 65.842377 loss_ctc 14.519621 loss_rnnt 4.486160 hw_loss 0.130456 history loss 9.200882 rank 7
2023-02-11 17:15:53,753 DEBUG CV Batch 8/400 loss 15.214766 loss_att 65.842377 loss_ctc 14.519621 loss_rnnt 4.486160 hw_loss 0.130456 history loss 9.200882 rank 5
2023-02-11 17:15:53,992 DEBUG CV Batch 8/400 loss 15.214766 loss_att 65.842377 loss_ctc 14.519621 loss_rnnt 4.486160 hw_loss 0.130456 history loss 9.200882 rank 2
2023-02-11 17:15:54,122 DEBUG CV Batch 8/400 loss 15.214766 loss_att 65.842377 loss_ctc 14.519621 loss_rnnt 4.486160 hw_loss 0.130456 history loss 9.200882 rank 4
2023-02-11 17:15:54,175 DEBUG CV Batch 8/400 loss 15.214766 loss_att 65.842377 loss_ctc 14.519621 loss_rnnt 4.486160 hw_loss 0.130456 history loss 9.200882 rank 6
2023-02-11 17:15:55,112 DEBUG CV Batch 8/400 loss 15.214766 loss_att 65.842377 loss_ctc 14.519621 loss_rnnt 4.486160 hw_loss 0.130456 history loss 9.200882 rank 1
2023-02-11 17:16:03,845 DEBUG CV Batch 8/500 loss 7.316175 loss_att 8.746560 loss_ctc 14.167597 loss_rnnt 5.198261 hw_loss 0.172184 history loss 9.982571 rank 0
2023-02-11 17:16:04,045 DEBUG CV Batch 8/500 loss 7.316175 loss_att 8.746560 loss_ctc 14.167597 loss_rnnt 5.198261 hw_loss 0.172184 history loss 9.982571 rank 3
2023-02-11 17:16:04,093 DEBUG CV Batch 8/500 loss 7.316175 loss_att 8.746560 loss_ctc 14.167597 loss_rnnt 5.198261 hw_loss 0.172184 history loss 9.982571 rank 7
2023-02-11 17:16:04,247 DEBUG CV Batch 8/500 loss 7.316175 loss_att 8.746560 loss_ctc 14.167597 loss_rnnt 5.198261 hw_loss 0.172184 history loss 9.982571 rank 5
2023-02-11 17:16:04,587 DEBUG CV Batch 8/500 loss 7.316175 loss_att 8.746560 loss_ctc 14.167597 loss_rnnt 5.198261 hw_loss 0.172184 history loss 9.982571 rank 2
2023-02-11 17:16:04,628 DEBUG CV Batch 8/500 loss 7.316175 loss_att 8.746560 loss_ctc 14.167597 loss_rnnt 5.198261 hw_loss 0.172184 history loss 9.982571 rank 4
2023-02-11 17:16:04,762 DEBUG CV Batch 8/500 loss 7.316175 loss_att 8.746560 loss_ctc 14.167597 loss_rnnt 5.198261 hw_loss 0.172184 history loss 9.982571 rank 6
2023-02-11 17:16:05,609 DEBUG CV Batch 8/500 loss 7.316175 loss_att 8.746560 loss_ctc 14.167597 loss_rnnt 5.198261 hw_loss 0.172184 history loss 9.982571 rank 1
2023-02-11 17:16:15,797 DEBUG CV Batch 8/600 loss 13.526585 loss_att 9.329194 loss_ctc 12.251040 loss_rnnt 8.340166 hw_loss 1.161744 history loss 10.957610 rank 0
2023-02-11 17:16:16,053 DEBUG CV Batch 8/600 loss 13.526585 loss_att 9.329194 loss_ctc 12.251040 loss_rnnt 8.340166 hw_loss 1.161744 history loss 10.957610 rank 3
2023-02-11 17:16:16,094 DEBUG CV Batch 8/600 loss 13.526584 loss_att 9.329194 loss_ctc 12.251040 loss_rnnt 8.340166 hw_loss 1.161744 history loss 10.957610 rank 7
2023-02-11 17:16:16,362 DEBUG CV Batch 8/600 loss 13.526584 loss_att 9.329194 loss_ctc 12.251040 loss_rnnt 8.340166 hw_loss 1.161744 history loss 10.957609 rank 5
2023-02-11 17:16:16,663 DEBUG CV Batch 8/600 loss 13.526585 loss_att 9.329194 loss_ctc 12.251040 loss_rnnt 8.340166 hw_loss 1.161744 history loss 10.957610 rank 2
2023-02-11 17:16:16,926 DEBUG CV Batch 8/600 loss 13.526584 loss_att 9.329194 loss_ctc 12.251040 loss_rnnt 8.340166 hw_loss 1.161744 history loss 10.957610 rank 6
2023-02-11 17:16:17,107 DEBUG CV Batch 8/600 loss 13.526585 loss_att 9.329194 loss_ctc 12.251040 loss_rnnt 8.340166 hw_loss 1.161744 history loss 10.957609 rank 4
2023-02-11 17:16:17,789 DEBUG CV Batch 8/600 loss 13.526584 loss_att 9.329194 loss_ctc 12.251040 loss_rnnt 8.340166 hw_loss 1.161744 history loss 10.957609 rank 1
2023-02-11 17:16:27,395 DEBUG CV Batch 8/700 loss 19.327312 loss_att 51.417824 loss_ctc 28.161287 loss_rnnt 10.168858 hw_loss 0.292967 history loss 11.598322 rank 0
2023-02-11 17:16:27,467 DEBUG CV Batch 8/700 loss 19.327312 loss_att 51.417824 loss_ctc 28.161287 loss_rnnt 10.168858 hw_loss 0.292967 history loss 11.598322 rank 7
2023-02-11 17:16:27,519 DEBUG CV Batch 8/700 loss 19.327312 loss_att 51.417824 loss_ctc 28.161287 loss_rnnt 10.168858 hw_loss 0.292967 history loss 11.598322 rank 3
2023-02-11 17:16:27,701 DEBUG CV Batch 8/700 loss 19.327312 loss_att 51.417824 loss_ctc 28.161287 loss_rnnt 10.168858 hw_loss 0.292967 history loss 11.598322 rank 5
2023-02-11 17:16:27,962 DEBUG CV Batch 8/700 loss 19.327312 loss_att 51.417824 loss_ctc 28.161287 loss_rnnt 10.168858 hw_loss 0.292967 history loss 11.598322 rank 2
2023-02-11 17:16:28,979 DEBUG CV Batch 8/700 loss 19.327312 loss_att 51.417824 loss_ctc 28.161287 loss_rnnt 10.168858 hw_loss 0.292967 history loss 11.598322 rank 6
2023-02-11 17:16:29,045 DEBUG CV Batch 8/700 loss 19.327312 loss_att 51.417824 loss_ctc 28.161287 loss_rnnt 10.168858 hw_loss 0.292967 history loss 11.598322 rank 4
2023-02-11 17:16:29,655 DEBUG CV Batch 8/700 loss 19.327312 loss_att 51.417824 loss_ctc 28.161287 loss_rnnt 10.168858 hw_loss 0.292967 history loss 11.598322 rank 1
2023-02-11 17:16:39,209 DEBUG CV Batch 8/800 loss 14.649911 loss_att 12.610979 loss_ctc 23.595959 loss_rnnt 10.140826 hw_loss 0.698262 history loss 11.051385 rank 7
2023-02-11 17:16:39,338 DEBUG CV Batch 8/800 loss 14.649911 loss_att 12.610979 loss_ctc 23.595959 loss_rnnt 10.140826 hw_loss 0.698262 history loss 11.051385 rank 5
2023-02-11 17:16:39,413 DEBUG CV Batch 8/800 loss 14.649911 loss_att 12.610979 loss_ctc 23.595959 loss_rnnt 10.140826 hw_loss 0.698262 history loss 11.051385 rank 0
2023-02-11 17:16:39,426 DEBUG CV Batch 8/800 loss 14.649911 loss_att 12.610979 loss_ctc 23.595959 loss_rnnt 10.140826 hw_loss 0.698262 history loss 11.051385 rank 3
2023-02-11 17:16:40,304 DEBUG CV Batch 8/800 loss 14.649911 loss_att 12.610979 loss_ctc 23.595959 loss_rnnt 10.140826 hw_loss 0.698262 history loss 11.051385 rank 2
2023-02-11 17:16:41,385 DEBUG CV Batch 8/800 loss 14.649911 loss_att 12.610979 loss_ctc 23.595959 loss_rnnt 10.140826 hw_loss 0.698262 history loss 11.051385 rank 4
2023-02-11 17:16:41,827 DEBUG CV Batch 8/800 loss 14.649911 loss_att 12.610979 loss_ctc 23.595959 loss_rnnt 10.140826 hw_loss 0.698262 history loss 11.051385 rank 6
2023-02-11 17:16:41,905 DEBUG CV Batch 8/800 loss 14.649911 loss_att 12.610979 loss_ctc 23.595959 loss_rnnt 10.140826 hw_loss 0.698262 history loss 11.051385 rank 1
2023-02-11 17:16:52,846 DEBUG CV Batch 8/900 loss 13.578547 loss_att 19.116180 loss_ctc 24.879719 loss_rnnt 8.511209 hw_loss 0.459935 history loss 10.841731 rank 5
2023-02-11 17:16:52,877 DEBUG CV Batch 8/900 loss 13.578547 loss_att 19.116180 loss_ctc 24.879719 loss_rnnt 8.511209 hw_loss 0.459935 history loss 10.841731 rank 7
2023-02-11 17:16:53,028 DEBUG CV Batch 8/900 loss 13.578547 loss_att 19.116180 loss_ctc 24.879719 loss_rnnt 8.511209 hw_loss 0.459935 history loss 10.841731 rank 0
2023-02-11 17:16:53,272 DEBUG CV Batch 8/900 loss 13.578547 loss_att 19.116180 loss_ctc 24.879719 loss_rnnt 8.511209 hw_loss 0.459935 history loss 10.841731 rank 3
2023-02-11 17:16:54,534 DEBUG CV Batch 8/900 loss 13.578547 loss_att 19.116180 loss_ctc 24.879719 loss_rnnt 8.511209 hw_loss 0.459935 history loss 10.841731 rank 2
2023-02-11 17:16:55,281 DEBUG CV Batch 8/900 loss 13.578547 loss_att 19.116180 loss_ctc 24.879719 loss_rnnt 8.511209 hw_loss 0.459935 history loss 10.841731 rank 4
2023-02-11 17:16:55,517 DEBUG CV Batch 8/900 loss 13.578547 loss_att 19.116180 loss_ctc 24.879719 loss_rnnt 8.511209 hw_loss 0.459935 history loss 10.841731 rank 1
2023-02-11 17:16:55,600 DEBUG CV Batch 8/900 loss 13.578547 loss_att 19.116180 loss_ctc 24.879719 loss_rnnt 8.511209 hw_loss 0.459935 history loss 10.841731 rank 6
2023-02-11 17:17:05,035 DEBUG CV Batch 8/1000 loss 10.306173 loss_att 6.437344 loss_ctc 7.939996 loss_rnnt 5.475192 hw_loss 1.110045 history loss 10.653764 rank 7
2023-02-11 17:17:05,078 DEBUG CV Batch 8/1000 loss 10.306173 loss_att 6.437344 loss_ctc 7.939996 loss_rnnt 5.475192 hw_loss 1.110045 history loss 10.653764 rank 5
2023-02-11 17:17:05,122 DEBUG CV Batch 8/1000 loss 10.306174 loss_att 6.437344 loss_ctc 7.939996 loss_rnnt 5.475192 hw_loss 1.110045 history loss 10.653764 rank 0
2023-02-11 17:17:05,408 DEBUG CV Batch 8/1000 loss 10.306173 loss_att 6.437344 loss_ctc 7.939996 loss_rnnt 5.475192 hw_loss 1.110045 history loss 10.653764 rank 3
2023-02-11 17:17:06,721 DEBUG CV Batch 8/1000 loss 10.306173 loss_att 6.437344 loss_ctc 7.939996 loss_rnnt 5.475192 hw_loss 1.110045 history loss 10.653764 rank 2
2023-02-11 17:17:07,555 DEBUG CV Batch 8/1000 loss 10.306173 loss_att 6.437344 loss_ctc 7.939996 loss_rnnt 5.475192 hw_loss 1.110045 history loss 10.653764 rank 4
2023-02-11 17:17:07,749 DEBUG CV Batch 8/1000 loss 10.306173 loss_att 6.437344 loss_ctc 7.939996 loss_rnnt 5.475192 hw_loss 1.110045 history loss 10.653764 rank 1
2023-02-11 17:17:07,776 DEBUG CV Batch 8/1000 loss 10.306173 loss_att 6.437344 loss_ctc 7.939996 loss_rnnt 5.475192 hw_loss 1.110045 history loss 10.653764 rank 6
2023-02-11 17:17:16,901 DEBUG CV Batch 8/1100 loss 11.207855 loss_att 5.397744 loss_ctc 10.031880 loss_rnnt 5.633407 hw_loss 1.292488 history loss 10.610739 rank 0
2023-02-11 17:17:16,918 DEBUG CV Batch 8/1100 loss 11.207856 loss_att 5.397744 loss_ctc 10.031880 loss_rnnt 5.633407 hw_loss 1.292488 history loss 10.610739 rank 7
2023-02-11 17:17:17,000 DEBUG CV Batch 8/1100 loss 11.207856 loss_att 5.397744 loss_ctc 10.031880 loss_rnnt 5.633407 hw_loss 1.292488 history loss 10.610739 rank 5
2023-02-11 17:17:17,230 DEBUG CV Batch 8/1100 loss 11.207857 loss_att 5.397744 loss_ctc 10.031880 loss_rnnt 5.633407 hw_loss 1.292488 history loss 10.610739 rank 3
2023-02-11 17:17:18,649 DEBUG CV Batch 8/1100 loss 11.207856 loss_att 5.397744 loss_ctc 10.031880 loss_rnnt 5.633407 hw_loss 1.292488 history loss 10.610739 rank 2
2023-02-11 17:17:19,450 DEBUG CV Batch 8/1100 loss 11.207857 loss_att 5.397744 loss_ctc 10.031880 loss_rnnt 5.633407 hw_loss 1.292488 history loss 10.610739 rank 4
2023-02-11 17:17:19,553 DEBUG CV Batch 8/1100 loss 11.207857 loss_att 5.397744 loss_ctc 10.031880 loss_rnnt 5.633407 hw_loss 1.292488 history loss 10.610739 rank 1
2023-02-11 17:17:19,773 DEBUG CV Batch 8/1100 loss 11.207856 loss_att 5.397744 loss_ctc 10.031880 loss_rnnt 5.633407 hw_loss 1.292488 history loss 10.610739 rank 6
2023-02-11 17:17:27,304 DEBUG CV Batch 8/1200 loss 15.406142 loss_att 14.867592 loss_ctc 18.939764 loss_rnnt 13.148150 hw_loss 0.355229 history loss 10.953166 rank 7
2023-02-11 17:17:27,328 DEBUG CV Batch 8/1200 loss 15.406142 loss_att 14.867592 loss_ctc 18.939764 loss_rnnt 13.148150 hw_loss 0.355229 history loss 10.953166 rank 0
2023-02-11 17:17:27,409 DEBUG CV Batch 8/1200 loss 15.406142 loss_att 14.867592 loss_ctc 18.939764 loss_rnnt 13.148150 hw_loss 0.355229 history loss 10.953166 rank 5
2023-02-11 17:17:27,685 DEBUG CV Batch 8/1200 loss 15.406142 loss_att 14.867592 loss_ctc 18.939764 loss_rnnt 13.148150 hw_loss 0.355229 history loss 10.953166 rank 3
2023-02-11 17:17:29,095 DEBUG CV Batch 8/1200 loss 15.406142 loss_att 14.867592 loss_ctc 18.939764 loss_rnnt 13.148150 hw_loss 0.355229 history loss 10.953166 rank 2
2023-02-11 17:17:29,994 DEBUG CV Batch 8/1200 loss 15.406142 loss_att 14.867592 loss_ctc 18.939764 loss_rnnt 13.148150 hw_loss 0.355229 history loss 10.953166 rank 4
2023-02-11 17:17:29,996 DEBUG CV Batch 8/1200 loss 15.406142 loss_att 14.867592 loss_ctc 18.939764 loss_rnnt 13.148150 hw_loss 0.355229 history loss 10.953166 rank 1
2023-02-11 17:17:30,793 DEBUG CV Batch 8/1200 loss 15.406142 loss_att 14.867592 loss_ctc 18.939764 loss_rnnt 13.148150 hw_loss 0.355229 history loss 10.953166 rank 6
2023-02-11 17:17:39,152 DEBUG CV Batch 8/1300 loss 8.604383 loss_att 5.604317 loss_ctc 8.447033 loss_rnnt 4.571942 hw_loss 0.872519 history loss 11.259784 rank 7
2023-02-11 17:17:39,213 DEBUG CV Batch 8/1300 loss 8.604383 loss_att 5.604317 loss_ctc 8.447033 loss_rnnt 4.571942 hw_loss 0.872519 history loss 11.259784 rank 0
2023-02-11 17:17:39,299 DEBUG CV Batch 8/1300 loss 8.604383 loss_att 5.604317 loss_ctc 8.447033 loss_rnnt 4.571942 hw_loss 0.872519 history loss 11.259784 rank 5
2023-02-11 17:17:39,582 DEBUG CV Batch 8/1300 loss 8.604383 loss_att 5.604317 loss_ctc 8.447033 loss_rnnt 4.571942 hw_loss 0.872519 history loss 11.259784 rank 3
2023-02-11 17:17:41,101 DEBUG CV Batch 8/1300 loss 8.604382 loss_att 5.604317 loss_ctc 8.447033 loss_rnnt 4.571942 hw_loss 0.872519 history loss 11.259784 rank 2
2023-02-11 17:17:42,072 DEBUG CV Batch 8/1300 loss 8.604382 loss_att 5.604317 loss_ctc 8.447033 loss_rnnt 4.571942 hw_loss 0.872518 history loss 11.259784 rank 4
2023-02-11 17:17:42,928 DEBUG CV Batch 8/1300 loss 8.604383 loss_att 5.604317 loss_ctc 8.447033 loss_rnnt 4.571942 hw_loss 0.872519 history loss 11.259784 rank 6
2023-02-11 17:17:42,993 DEBUG CV Batch 8/1300 loss 8.604382 loss_att 5.604317 loss_ctc 8.447033 loss_rnnt 4.571942 hw_loss 0.872519 history loss 11.259784 rank 1
2023-02-11 17:17:50,225 DEBUG CV Batch 8/1400 loss 8.963703 loss_att 16.788857 loss_ctc 12.488079 loss_rnnt 5.358352 hw_loss 0.294451 history loss 11.570253 rank 7
2023-02-11 17:17:50,344 DEBUG CV Batch 8/1400 loss 8.963703 loss_att 16.788857 loss_ctc 12.488079 loss_rnnt 5.358352 hw_loss 0.294451 history loss 11.570253 rank 0
2023-02-11 17:17:50,457 DEBUG CV Batch 8/1400 loss 8.963703 loss_att 16.788857 loss_ctc 12.488079 loss_rnnt 5.358352 hw_loss 0.294451 history loss 11.570253 rank 5
2023-02-11 17:17:50,672 DEBUG CV Batch 8/1400 loss 8.963703 loss_att 16.788857 loss_ctc 12.488079 loss_rnnt 5.358352 hw_loss 0.294451 history loss 11.570253 rank 3
2023-02-11 17:17:52,386 DEBUG CV Batch 8/1400 loss 8.963703 loss_att 16.788857 loss_ctc 12.488079 loss_rnnt 5.358352 hw_loss 0.294451 history loss 11.570253 rank 2
2023-02-11 17:17:53,565 DEBUG CV Batch 8/1400 loss 8.963703 loss_att 16.788857 loss_ctc 12.488079 loss_rnnt 5.358352 hw_loss 0.294451 history loss 11.570253 rank 4
2023-02-11 17:17:54,038 DEBUG CV Batch 8/1400 loss 8.963703 loss_att 16.788857 loss_ctc 12.488079 loss_rnnt 5.358352 hw_loss 0.294451 history loss 11.570253 rank 6
2023-02-11 17:17:54,657 DEBUG CV Batch 8/1400 loss 8.963703 loss_att 16.788857 loss_ctc 12.488079 loss_rnnt 5.358352 hw_loss 0.294451 history loss 11.570253 rank 1
2023-02-11 17:18:01,800 DEBUG CV Batch 8/1500 loss 11.272851 loss_att 9.378491 loss_ctc 8.107122 loss_rnnt 8.056220 hw_loss 0.753300 history loss 11.411693 rank 7
2023-02-11 17:18:01,840 DEBUG CV Batch 8/1500 loss 11.272851 loss_att 9.378491 loss_ctc 8.107122 loss_rnnt 8.056220 hw_loss 0.753300 history loss 11.411693 rank 5
2023-02-11 17:18:01,949 DEBUG CV Batch 8/1500 loss 11.272851 loss_att 9.378491 loss_ctc 8.107122 loss_rnnt 8.056220 hw_loss 0.753300 history loss 11.411693 rank 0
2023-02-11 17:18:02,424 DEBUG CV Batch 8/1500 loss 11.272851 loss_att 9.378491 loss_ctc 8.107122 loss_rnnt 8.056220 hw_loss 0.753300 history loss 11.411693 rank 3
2023-02-11 17:18:04,693 DEBUG CV Batch 8/1500 loss 11.272851 loss_att 9.378491 loss_ctc 8.107122 loss_rnnt 8.056220 hw_loss 0.753300 history loss 11.411693 rank 2
2023-02-11 17:18:05,593 DEBUG CV Batch 8/1500 loss 11.272851 loss_att 9.378491 loss_ctc 8.107122 loss_rnnt 8.056220 hw_loss 0.753300 history loss 11.411694 rank 6
2023-02-11 17:18:05,695 DEBUG CV Batch 8/1500 loss 11.272851 loss_att 9.378491 loss_ctc 8.107122 loss_rnnt 8.056220 hw_loss 0.753300 history loss 11.411693 rank 4
2023-02-11 17:18:06,120 DEBUG CV Batch 8/1500 loss 11.272851 loss_att 9.378491 loss_ctc 8.107122 loss_rnnt 8.056220 hw_loss 0.753300 history loss 11.411693 rank 1
2023-02-11 17:18:15,096 DEBUG CV Batch 8/1600 loss 8.954145 loss_att 16.392984 loss_ctc 13.733588 loss_rnnt 4.030169 hw_loss 0.524803 history loss 11.329800 rank 5
2023-02-11 17:18:15,274 DEBUG CV Batch 8/1600 loss 8.954145 loss_att 16.392984 loss_ctc 13.733588 loss_rnnt 4.030169 hw_loss 0.524803 history loss 11.329800 rank 7
2023-02-11 17:18:15,382 DEBUG CV Batch 8/1600 loss 8.954145 loss_att 16.392984 loss_ctc 13.733588 loss_rnnt 4.030169 hw_loss 0.524803 history loss 11.329800 rank 0
2023-02-11 17:18:15,920 DEBUG CV Batch 8/1600 loss 8.954145 loss_att 16.392984 loss_ctc 13.733588 loss_rnnt 4.030169 hw_loss 0.524803 history loss 11.329800 rank 3
2023-02-11 17:18:19,161 DEBUG CV Batch 8/1600 loss 8.954145 loss_att 16.392984 loss_ctc 13.733588 loss_rnnt 4.030169 hw_loss 0.524803 history loss 11.329800 rank 1
2023-02-11 17:18:19,206 DEBUG CV Batch 8/1600 loss 8.954145 loss_att 16.392984 loss_ctc 13.733588 loss_rnnt 4.030169 hw_loss 0.524803 history loss 11.329800 rank 2
2023-02-11 17:18:19,294 DEBUG CV Batch 8/1600 loss 8.954145 loss_att 16.392984 loss_ctc 13.733588 loss_rnnt 4.030169 hw_loss 0.524803 history loss 11.329800 rank 4
2023-02-11 17:18:19,335 DEBUG CV Batch 8/1600 loss 8.954145 loss_att 16.392984 loss_ctc 13.733588 loss_rnnt 4.030169 hw_loss 0.524803 history loss 11.329800 rank 6
2023-02-11 17:18:27,666 DEBUG CV Batch 8/1700 loss 11.390117 loss_att 7.271092 loss_ctc 13.919379 loss_rnnt 6.379570 hw_loss 1.030710 history loss 11.247875 rank 5
2023-02-11 17:18:27,790 DEBUG CV Batch 8/1700 loss 11.390117 loss_att 7.271092 loss_ctc 13.919379 loss_rnnt 6.379570 hw_loss 1.030710 history loss 11.247875 rank 7
2023-02-11 17:18:27,824 DEBUG CV Batch 8/1700 loss 11.390117 loss_att 7.271092 loss_ctc 13.919379 loss_rnnt 6.379570 hw_loss 1.030710 history loss 11.247875 rank 0
2023-02-11 17:18:28,378 DEBUG CV Batch 8/1700 loss 11.390118 loss_att 7.271092 loss_ctc 13.919379 loss_rnnt 6.379570 hw_loss 1.030710 history loss 11.247875 rank 3
2023-02-11 17:18:31,563 DEBUG CV Batch 8/1700 loss 11.390117 loss_att 7.271092 loss_ctc 13.919379 loss_rnnt 6.379570 hw_loss 1.030710 history loss 11.247875 rank 1
2023-02-11 17:18:31,755 DEBUG CV Batch 8/1700 loss 11.390117 loss_att 7.271092 loss_ctc 13.919379 loss_rnnt 6.379570 hw_loss 1.030710 history loss 11.247875 rank 6
2023-02-11 17:18:31,795 DEBUG CV Batch 8/1700 loss 11.390117 loss_att 7.271092 loss_ctc 13.919379 loss_rnnt 6.379570 hw_loss 1.030710 history loss 11.247875 rank 4
2023-02-11 17:18:32,453 DEBUG CV Batch 8/1700 loss 11.390116 loss_att 7.271092 loss_ctc 13.919379 loss_rnnt 6.379570 hw_loss 1.030709 history loss 11.247875 rank 2
2023-02-11 17:18:36,917 INFO Epoch 8 CV info cv_loss 11.199260078132593
2023-02-11 17:18:36,918 INFO Checkpoint: save to checkpoint exp2_10_rnnt_bias_loss/8.pt
2023-02-11 17:18:36,919 INFO Epoch 8 CV info cv_loss 11.199260062023228
2023-02-11 17:18:36,920 INFO Epoch 9 TRAIN info lr 0.0005770041704858152
2023-02-11 17:18:36,924 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 17:18:36,973 INFO Epoch 8 CV info cv_loss 11.199260060507052
2023-02-11 17:18:36,974 INFO Epoch 9 TRAIN info lr 0.0005774003127187083
2023-02-11 17:18:36,979 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 17:18:37,465 INFO Epoch 8 CV info cv_loss 11.19926007818428
2023-02-11 17:18:37,466 INFO Epoch 9 TRAIN info lr 0.0005773194796384112
2023-02-11 17:18:37,469 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 17:18:38,177 INFO Epoch 9 TRAIN info lr 0.0005770272243712146
2023-02-11 17:18:38,182 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 17:18:40,668 INFO Epoch 8 CV info cv_loss 11.199260073842504
2023-02-11 17:18:40,669 INFO Epoch 9 TRAIN info lr 0.000576984961025286
2023-02-11 17:18:40,672 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 17:18:40,897 INFO Epoch 8 CV info cv_loss 11.199260090003555
2023-02-11 17:18:40,898 INFO Epoch 9 TRAIN info lr 0.0005772579153108954
2023-02-11 17:18:40,901 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 17:18:41,608 INFO Epoch 8 CV info cv_loss 11.199260079958893
2023-02-11 17:18:41,609 INFO Epoch 9 TRAIN info lr 0.0005769542298786203
2023-02-11 17:18:41,612 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 17:18:41,668 INFO Epoch 8 CV info cv_loss 11.199260082129781
2023-02-11 17:18:41,669 INFO Epoch 9 TRAIN info lr 0.0005772117549881386
2023-02-11 17:18:41,673 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 17:19:53,712 DEBUG TRAIN Batch 9/0 loss 15.049688 loss_att 12.182631 loss_ctc 16.998821 loss_rnnt 12.007119 hw_loss 0.629268 lr 0.00057702 rank 0
2023-02-11 17:19:53,714 DEBUG TRAIN Batch 9/0 loss 16.107985 loss_att 10.744173 loss_ctc 15.198213 loss_rnnt 10.818657 hw_loss 1.215636 lr 0.00057732 rank 3
2023-02-11 17:19:53,716 DEBUG TRAIN Batch 9/0 loss 13.319502 loss_att 9.740996 loss_ctc 12.547769 loss_rnnt 8.686016 hw_loss 1.022266 lr 0.00057740 rank 7
2023-02-11 17:19:53,721 DEBUG TRAIN Batch 9/0 loss 11.820702 loss_att 7.952925 loss_ctc 10.958946 loss_rnnt 7.203662 hw_loss 1.032280 lr 0.00057725 rank 6
2023-02-11 17:19:53,721 DEBUG TRAIN Batch 9/0 loss 13.657424 loss_att 9.506960 loss_ctc 12.203712 loss_rnnt 8.144033 hw_loss 1.225746 lr 0.00057700 rank 5
2023-02-11 17:19:53,737 DEBUG TRAIN Batch 9/0 loss 16.100731 loss_att 10.862486 loss_ctc 14.034408 loss_rnnt 10.699979 hw_loss 1.260733 lr 0.00057695 rank 2
2023-02-11 17:19:53,740 DEBUG TRAIN Batch 9/0 loss 13.518241 loss_att 9.685239 loss_ctc 12.518479 loss_rnnt 9.258301 hw_loss 0.967470 lr 0.00057698 rank 1
2023-02-11 17:19:53,771 DEBUG TRAIN Batch 9/0 loss 12.392038 loss_att 8.400805 loss_ctc 12.537155 loss_rnnt 7.710700 hw_loss 1.023795 lr 0.00057721 rank 4
2023-02-11 17:21:07,096 DEBUG TRAIN Batch 9/100 loss 15.402584 loss_att 19.473301 loss_ctc 28.028692 loss_rnnt 10.031447 hw_loss 0.538783 lr 0.00057693 rank 3
2023-02-11 17:21:07,103 DEBUG TRAIN Batch 9/100 loss 16.333284 loss_att 21.307028 loss_ctc 27.101456 loss_rnnt 12.099045 hw_loss 0.338200 lr 0.00057664 rank 0
2023-02-11 17:21:07,104 DEBUG TRAIN Batch 9/100 loss 18.237337 loss_att 20.411928 loss_ctc 31.554815 loss_rnnt 14.906561 hw_loss 0.210037 lr 0.00057662 rank 5
2023-02-11 17:21:07,104 DEBUG TRAIN Batch 9/100 loss 8.187095 loss_att 11.843956 loss_ctc 13.755785 loss_rnnt 4.793423 hw_loss 0.359964 lr 0.00057701 rank 7
2023-02-11 17:21:07,105 DEBUG TRAIN Batch 9/100 loss 17.695141 loss_att 19.851711 loss_ctc 31.947128 loss_rnnt 14.054798 hw_loss 0.245393 lr 0.00057657 rank 2
2023-02-11 17:21:07,107 DEBUG TRAIN Batch 9/100 loss 12.365068 loss_att 12.933414 loss_ctc 17.102257 loss_rnnt 10.007273 hw_loss 0.302344 lr 0.00057660 rank 1
2023-02-11 17:21:07,109 DEBUG TRAIN Batch 9/100 loss 9.645943 loss_att 13.729808 loss_ctc 17.676247 loss_rnnt 5.978015 hw_loss 0.333834 lr 0.00057682 rank 4
2023-02-11 17:21:07,109 DEBUG TRAIN Batch 9/100 loss 15.557087 loss_att 16.445553 loss_ctc 23.622005 loss_rnnt 10.831446 hw_loss 0.651117 lr 0.00057687 rank 6
2023-02-11 17:22:21,724 DEBUG TRAIN Batch 9/200 loss 21.603764 loss_att 22.967293 loss_ctc 29.597464 loss_rnnt 18.177214 hw_loss 0.391503 lr 0.00057663 rank 7
2023-02-11 17:22:21,725 DEBUG TRAIN Batch 9/200 loss 13.811767 loss_att 17.324745 loss_ctc 18.031391 loss_rnnt 10.630865 hw_loss 0.359192 lr 0.00057626 rank 0
2023-02-11 17:22:21,726 DEBUG TRAIN Batch 9/200 loss 21.511320 loss_att 21.346638 loss_ctc 27.767586 loss_rnnt 19.057398 hw_loss 0.309879 lr 0.00057649 rank 6
2023-02-11 17:22:21,726 DEBUG TRAIN Batch 9/200 loss 12.474306 loss_att 14.922108 loss_ctc 18.992306 loss_rnnt 8.510117 hw_loss 0.488543 lr 0.00057621 rank 1
2023-02-11 17:22:21,727 DEBUG TRAIN Batch 9/200 loss 12.842922 loss_att 16.179155 loss_ctc 19.820004 loss_rnnt 8.567110 hw_loss 0.502179 lr 0.00057655 rank 3
2023-02-11 17:22:21,729 DEBUG TRAIN Batch 9/200 loss 18.796932 loss_att 21.246822 loss_ctc 28.961140 loss_rnnt 14.764579 hw_loss 0.410090 lr 0.00057618 rank 2
2023-02-11 17:22:21,730 DEBUG TRAIN Batch 9/200 loss 16.115242 loss_att 20.834879 loss_ctc 37.253067 loss_rnnt 11.985591 hw_loss 0.068878 lr 0.00057623 rank 5
2023-02-11 17:22:21,731 DEBUG TRAIN Batch 9/200 loss 9.896994 loss_att 13.194607 loss_ctc 18.619810 loss_rnnt 4.538963 hw_loss 0.662900 lr 0.00057644 rank 4
2023-02-11 17:23:37,327 DEBUG TRAIN Batch 9/300 loss 5.312671 loss_att 8.472866 loss_ctc 8.469928 loss_rnnt 3.142061 hw_loss 0.209551 lr 0.00057587 rank 0
2023-02-11 17:23:37,332 DEBUG TRAIN Batch 9/300 loss 20.711239 loss_att 21.154217 loss_ctc 30.934242 loss_rnnt 16.190327 hw_loss 0.575485 lr 0.00057580 rank 2
2023-02-11 17:23:37,332 DEBUG TRAIN Batch 9/300 loss 17.418024 loss_att 20.989677 loss_ctc 29.380749 loss_rnnt 13.596098 hw_loss 0.283606 lr 0.00057606 rank 4
2023-02-11 17:23:37,332 DEBUG TRAIN Batch 9/300 loss 8.217211 loss_att 13.577867 loss_ctc 10.760666 loss_rnnt 4.345058 hw_loss 0.461418 lr 0.00057616 rank 3
2023-02-11 17:23:37,333 DEBUG TRAIN Batch 9/300 loss 18.650183 loss_att 23.497221 loss_ctc 34.354782 loss_rnnt 13.151089 hw_loss 0.456701 lr 0.00057583 rank 1
2023-02-11 17:23:37,334 DEBUG TRAIN Batch 9/300 loss 4.978719 loss_att 6.733196 loss_ctc 5.076716 loss_rnnt 2.565524 hw_loss 0.384231 lr 0.00057585 rank 5
2023-02-11 17:23:37,336 DEBUG TRAIN Batch 9/300 loss 16.176216 loss_att 15.847287 loss_ctc 21.609886 loss_rnnt 12.603155 hw_loss 0.546442 lr 0.00057610 rank 6
2023-02-11 17:23:37,347 DEBUG TRAIN Batch 9/300 loss 20.004093 loss_att 24.548359 loss_ctc 29.263744 loss_rnnt 15.252695 hw_loss 0.488985 lr 0.00057624 rank 7
2023-02-11 17:24:54,671 DEBUG TRAIN Batch 9/400 loss 16.012781 loss_att 18.927870 loss_ctc 23.137234 loss_rnnt 12.770064 hw_loss 0.320582 lr 0.00057586 rank 7
2023-02-11 17:24:54,675 DEBUG TRAIN Batch 9/400 loss 16.823298 loss_att 18.501854 loss_ctc 22.105793 loss_rnnt 12.273537 hw_loss 0.658072 lr 0.00057578 rank 3
2023-02-11 17:24:54,675 DEBUG TRAIN Batch 9/400 loss 10.389573 loss_att 10.601246 loss_ctc 12.503788 loss_rnnt 5.206391 hw_loss 0.911053 lr 0.00057545 rank 1
2023-02-11 17:24:54,676 DEBUG TRAIN Batch 9/400 loss 12.461064 loss_att 14.092628 loss_ctc 16.681728 loss_rnnt 9.489698 hw_loss 0.390431 lr 0.00057549 rank 0
2023-02-11 17:24:54,679 DEBUG TRAIN Batch 9/400 loss 4.656860 loss_att 7.235777 loss_ctc 6.860735 loss_rnnt 2.599460 hw_loss 0.233956 lr 0.00057547 rank 5
2023-02-11 17:24:54,680 DEBUG TRAIN Batch 9/400 loss 25.348473 loss_att 23.130573 loss_ctc 25.507797 loss_rnnt 21.764725 hw_loss 0.751141 lr 0.00057568 rank 4
2023-02-11 17:24:54,681 DEBUG TRAIN Batch 9/400 loss 16.661077 loss_att 21.280106 loss_ctc 23.356712 loss_rnnt 12.104837 hw_loss 0.513691 lr 0.00057572 rank 6
2023-02-11 17:24:54,683 DEBUG TRAIN Batch 9/400 loss 11.956676 loss_att 13.427652 loss_ctc 15.876568 loss_rnnt 9.447464 hw_loss 0.317318 lr 0.00057542 rank 2
2023-02-11 17:26:09,732 DEBUG TRAIN Batch 9/500 loss 9.130143 loss_att 9.563669 loss_ctc 10.652082 loss_rnnt 4.698091 hw_loss 0.776704 lr 0.00057548 rank 7
2023-02-11 17:26:09,735 DEBUG TRAIN Batch 9/500 loss 17.549105 loss_att 20.644539 loss_ctc 22.292788 loss_rnnt 13.435130 hw_loss 0.536700 lr 0.00057540 rank 3
2023-02-11 17:26:09,738 DEBUG TRAIN Batch 9/500 loss 13.482575 loss_att 15.765232 loss_ctc 16.182529 loss_rnnt 10.061644 hw_loss 0.488326 lr 0.00057504 rank 2
2023-02-11 17:26:09,738 DEBUG TRAIN Batch 9/500 loss 18.611034 loss_att 18.848627 loss_ctc 22.170834 loss_rnnt 13.491671 hw_loss 0.861976 lr 0.00057507 rank 1
2023-02-11 17:26:09,739 DEBUG TRAIN Batch 9/500 loss 13.980165 loss_att 16.798347 loss_ctc 16.806229 loss_rnnt 8.520571 hw_loss 0.847340 lr 0.00057534 rank 6
2023-02-11 17:26:09,742 DEBUG TRAIN Batch 9/500 loss 20.544514 loss_att 21.295883 loss_ctc 36.509823 loss_rnnt 15.560242 hw_loss 0.507242 lr 0.00057509 rank 5
2023-02-11 17:26:09,742 DEBUG TRAIN Batch 9/500 loss 12.486733 loss_att 13.078136 loss_ctc 17.257767 loss_rnnt 7.923429 hw_loss 0.714166 lr 0.00057529 rank 4
2023-02-11 17:26:09,742 DEBUG TRAIN Batch 9/500 loss 25.996717 loss_att 28.128767 loss_ctc 35.977406 loss_rnnt 21.627531 hw_loss 0.489754 lr 0.00057511 rank 0
2023-02-11 17:27:25,762 DEBUG TRAIN Batch 9/600 loss 8.782581 loss_att 7.412700 loss_ctc 10.683973 loss_rnnt 5.830857 hw_loss 0.557284 lr 0.00057471 rank 5
2023-02-11 17:27:25,763 DEBUG TRAIN Batch 9/600 loss 16.917854 loss_att 13.835266 loss_ctc 17.854948 loss_rnnt 12.068592 hw_loss 1.001407 lr 0.00057473 rank 0
2023-02-11 17:27:25,764 DEBUG TRAIN Batch 9/600 loss 8.832633 loss_att 9.955265 loss_ctc 10.847132 loss_rnnt 6.647713 hw_loss 0.317211 lr 0.00057466 rank 2
2023-02-11 17:27:25,764 DEBUG TRAIN Batch 9/600 loss 16.077253 loss_att 14.426110 loss_ctc 22.102304 loss_rnnt 12.421247 hw_loss 0.596793 lr 0.00057502 rank 3
2023-02-11 17:27:25,765 DEBUG TRAIN Batch 9/600 loss 20.208344 loss_att 17.878859 loss_ctc 24.729229 loss_rnnt 14.671091 hw_loss 1.012568 lr 0.00057469 rank 1
2023-02-11 17:27:25,768 DEBUG TRAIN Batch 9/600 loss 11.003706 loss_att 6.590186 loss_ctc 8.534793 loss_rnnt 6.178531 hw_loss 1.131950 lr 0.00057510 rank 7
2023-02-11 17:27:25,769 DEBUG TRAIN Batch 9/600 loss 17.380135 loss_att 15.763635 loss_ctc 18.376577 loss_rnnt 13.975699 hw_loss 0.674039 lr 0.00057496 rank 6
2023-02-11 17:27:25,772 DEBUG TRAIN Batch 9/600 loss 22.473829 loss_att 22.964724 loss_ctc 34.251175 loss_rnnt 19.458488 hw_loss 0.252534 lr 0.00057491 rank 4
2023-02-11 17:28:43,775 DEBUG TRAIN Batch 9/700 loss 14.886525 loss_att 18.711830 loss_ctc 26.492239 loss_rnnt 9.987632 hw_loss 0.484951 lr 0.00057433 rank 5
2023-02-11 17:28:43,776 DEBUG TRAIN Batch 9/700 loss 14.642519 loss_att 15.060868 loss_ctc 20.105064 loss_rnnt 11.272720 hw_loss 0.479586 lr 0.00057464 rank 3
2023-02-11 17:28:43,777 DEBUG TRAIN Batch 9/700 loss 13.504540 loss_att 14.154428 loss_ctc 23.132305 loss_rnnt 10.480228 hw_loss 0.301994 lr 0.00057472 rank 7
2023-02-11 17:28:43,781 DEBUG TRAIN Batch 9/700 loss 7.904212 loss_att 11.485115 loss_ctc 15.353869 loss_rnnt 2.972513 hw_loss 0.604168 lr 0.00057435 rank 0
2023-02-11 17:28:43,785 DEBUG TRAIN Batch 9/700 loss 14.783075 loss_att 17.871799 loss_ctc 21.949734 loss_rnnt 11.763460 hw_loss 0.271184 lr 0.00057431 rank 1
2023-02-11 17:28:43,787 DEBUG TRAIN Batch 9/700 loss 19.470837 loss_att 20.589582 loss_ctc 30.251980 loss_rnnt 16.735786 hw_loss 0.201340 lr 0.00057458 rank 6
2023-02-11 17:28:43,797 DEBUG TRAIN Batch 9/700 loss 17.438992 loss_att 18.859325 loss_ctc 29.647100 loss_rnnt 12.183889 hw_loss 0.626866 lr 0.00057428 rank 2
2023-02-11 17:28:43,813 DEBUG TRAIN Batch 9/700 loss 10.454775 loss_att 14.826595 loss_ctc 17.322704 loss_rnnt 7.621791 hw_loss 0.195543 lr 0.00057453 rank 4
2023-02-11 17:29:58,757 DEBUG TRAIN Batch 9/800 loss 13.555532 loss_att 17.038258 loss_ctc 25.830856 loss_rnnt 10.734612 hw_loss 0.091437 lr 0.00057395 rank 5
2023-02-11 17:29:58,757 DEBUG TRAIN Batch 9/800 loss 12.464660 loss_att 14.101492 loss_ctc 19.362465 loss_rnnt 10.865847 hw_loss 0.065951 lr 0.00057426 rank 3
2023-02-11 17:29:58,759 DEBUG TRAIN Batch 9/800 loss 9.937128 loss_att 12.343512 loss_ctc 12.181166 loss_rnnt 8.206821 hw_loss 0.178092 lr 0.00057416 rank 4
2023-02-11 17:29:58,761 DEBUG TRAIN Batch 9/800 loss 19.286364 loss_att 23.248747 loss_ctc 27.863653 loss_rnnt 15.260696 hw_loss 0.391791 lr 0.00057393 rank 1
2023-02-11 17:29:58,761 DEBUG TRAIN Batch 9/800 loss 16.051287 loss_att 15.694174 loss_ctc 27.299963 loss_rnnt 13.743556 hw_loss 0.164874 lr 0.00057390 rank 2
2023-02-11 17:29:58,761 DEBUG TRAIN Batch 9/800 loss 13.991665 loss_att 15.900154 loss_ctc 19.778452 loss_rnnt 8.702217 hw_loss 0.775533 lr 0.00057397 rank 0
2023-02-11 17:29:58,762 DEBUG TRAIN Batch 9/800 loss 21.429312 loss_att 20.610474 loss_ctc 33.908699 loss_rnnt 17.629354 hw_loss 0.431214 lr 0.00057434 rank 7
2023-02-11 17:29:58,765 DEBUG TRAIN Batch 9/800 loss 8.942502 loss_att 11.075714 loss_ctc 11.553341 loss_rnnt 5.475515 hw_loss 0.504794 lr 0.00057420 rank 6
2023-02-11 17:31:13,829 DEBUG TRAIN Batch 9/900 loss 21.121231 loss_att 21.933146 loss_ctc 30.565765 loss_rnnt 18.321482 hw_loss 0.258393 lr 0.00057352 rank 2
2023-02-11 17:31:13,829 DEBUG TRAIN Batch 9/900 loss 18.819910 loss_att 21.700510 loss_ctc 26.943310 loss_rnnt 13.693592 hw_loss 0.650077 lr 0.00057360 rank 0
2023-02-11 17:31:13,830 DEBUG TRAIN Batch 9/900 loss 9.907219 loss_att 13.129974 loss_ctc 16.315962 loss_rnnt 7.013314 hw_loss 0.261535 lr 0.00057357 rank 5
2023-02-11 17:31:13,833 DEBUG TRAIN Batch 9/900 loss 20.276699 loss_att 22.400755 loss_ctc 28.367445 loss_rnnt 16.844137 hw_loss 0.361685 lr 0.00057388 rank 3
2023-02-11 17:31:13,833 DEBUG TRAIN Batch 9/900 loss 13.675332 loss_att 17.558073 loss_ctc 21.532940 loss_rnnt 9.726754 hw_loss 0.398315 lr 0.00057382 rank 6
2023-02-11 17:31:13,833 DEBUG TRAIN Batch 9/900 loss 5.431683 loss_att 6.303262 loss_ctc 9.048729 loss_rnnt 2.151990 hw_loss 0.491832 lr 0.00057355 rank 1
2023-02-11 17:31:13,835 DEBUG TRAIN Batch 9/900 loss 10.330188 loss_att 18.676281 loss_ctc 18.322189 loss_rnnt 7.319039 hw_loss 0.051812 lr 0.00057378 rank 4
2023-02-11 17:31:13,835 DEBUG TRAIN Batch 9/900 loss 17.164867 loss_att 19.809402 loss_ctc 29.074205 loss_rnnt 13.609585 hw_loss 0.269712 lr 0.00057396 rank 7
2023-02-11 17:32:30,602 DEBUG TRAIN Batch 9/1000 loss 15.109924 loss_att 15.576093 loss_ctc 20.982712 loss_rnnt 11.311266 hw_loss 0.547947 lr 0.00057315 rank 2
2023-02-11 17:32:30,605 DEBUG TRAIN Batch 9/1000 loss 14.610693 loss_att 16.098879 loss_ctc 21.697819 loss_rnnt 11.076259 hw_loss 0.429721 lr 0.00057358 rank 7
2023-02-11 17:32:30,605 DEBUG TRAIN Batch 9/1000 loss 7.683927 loss_att 12.209290 loss_ctc 7.659400 loss_rnnt 4.357551 hw_loss 0.454608 lr 0.00057351 rank 3
2023-02-11 17:32:30,605 DEBUG TRAIN Batch 9/1000 loss 10.169183 loss_att 13.310638 loss_ctc 15.351324 loss_rnnt 7.872265 hw_loss 0.183314 lr 0.00057322 rank 0
2023-02-11 17:32:30,610 DEBUG TRAIN Batch 9/1000 loss 11.419361 loss_att 11.240953 loss_ctc 13.717912 loss_rnnt 7.163958 hw_loss 0.747115 lr 0.00057320 rank 5
2023-02-11 17:32:30,626 DEBUG TRAIN Batch 9/1000 loss 20.988449 loss_att 23.621262 loss_ctc 33.367203 loss_rnnt 16.591175 hw_loss 0.416289 lr 0.00057340 rank 4
2023-02-11 17:32:30,636 DEBUG TRAIN Batch 9/1000 loss 18.890842 loss_att 20.889574 loss_ctc 35.305370 loss_rnnt 15.189684 hw_loss 0.208652 lr 0.00057345 rank 6
2023-02-11 17:32:30,644 DEBUG TRAIN Batch 9/1000 loss 21.638058 loss_att 27.331791 loss_ctc 34.675694 loss_rnnt 17.689827 hw_loss 0.200837 lr 0.00057318 rank 1
2023-02-11 17:33:48,703 DEBUG TRAIN Batch 9/1100 loss 11.496791 loss_att 13.794302 loss_ctc 20.325670 loss_rnnt 7.681138 hw_loss 0.408556 lr 0.00057321 rank 7
2023-02-11 17:33:48,707 DEBUG TRAIN Batch 9/1100 loss 10.815770 loss_att 14.463845 loss_ctc 18.952703 loss_rnnt 7.377968 hw_loss 0.304362 lr 0.00057313 rank 3
2023-02-11 17:33:48,708 DEBUG TRAIN Batch 9/1100 loss 7.058167 loss_att 8.905321 loss_ctc 11.871300 loss_rnnt 4.434026 hw_loss 0.302430 lr 0.00057280 rank 1
2023-02-11 17:33:48,708 DEBUG TRAIN Batch 9/1100 loss 18.487679 loss_att 18.159946 loss_ctc 24.657356 loss_rnnt 14.571478 hw_loss 0.592336 lr 0.00057284 rank 0
2023-02-11 17:33:48,709 DEBUG TRAIN Batch 9/1100 loss 32.720833 loss_att 30.206188 loss_ctc 37.659851 loss_rnnt 29.159161 hw_loss 0.638638 lr 0.00057277 rank 2
2023-02-11 17:33:48,711 DEBUG TRAIN Batch 9/1100 loss 28.653904 loss_att 26.301760 loss_ctc 43.385094 loss_rnnt 23.379274 hw_loss 0.708918 lr 0.00057302 rank 4
2023-02-11 17:33:48,712 DEBUG TRAIN Batch 9/1100 loss 12.949337 loss_att 14.264435 loss_ctc 17.354156 loss_rnnt 9.007210 hw_loss 0.579712 lr 0.00057282 rank 5
2023-02-11 17:33:48,757 DEBUG TRAIN Batch 9/1100 loss 13.387384 loss_att 13.248653 loss_ctc 15.866722 loss_rnnt 9.763666 hw_loss 0.622666 lr 0.00057307 rank 6
2023-02-11 17:35:04,120 DEBUG TRAIN Batch 9/1200 loss 16.579628 loss_att 19.245920 loss_ctc 24.719265 loss_rnnt 13.033946 hw_loss 0.361338 lr 0.00057247 rank 0
2023-02-11 17:35:04,120 DEBUG TRAIN Batch 9/1200 loss 11.299932 loss_att 13.219417 loss_ctc 14.099634 loss_rnnt 7.759103 hw_loss 0.521932 lr 0.00057275 rank 3
2023-02-11 17:35:04,122 DEBUG TRAIN Batch 9/1200 loss 17.731157 loss_att 17.605267 loss_ctc 22.608551 loss_rnnt 13.537050 hw_loss 0.669181 lr 0.00057240 rank 2
2023-02-11 17:35:04,127 DEBUG TRAIN Batch 9/1200 loss 19.240269 loss_att 18.361753 loss_ctc 22.883427 loss_rnnt 14.577768 hw_loss 0.816084 lr 0.00057265 rank 4
2023-02-11 17:35:04,127 DEBUG TRAIN Batch 9/1200 loss 14.188320 loss_att 15.644676 loss_ctc 27.386541 loss_rnnt 8.699077 hw_loss 0.644664 lr 0.00057243 rank 1
2023-02-11 17:35:04,129 DEBUG TRAIN Batch 9/1200 loss 13.507181 loss_att 11.143477 loss_ctc 15.840070 loss_rnnt 9.365108 hw_loss 0.806955 lr 0.00057244 rank 5
2023-02-11 17:35:04,132 DEBUG TRAIN Batch 9/1200 loss 15.132334 loss_att 12.668885 loss_ctc 18.013330 loss_rnnt 10.841861 hw_loss 0.824818 lr 0.00057283 rank 7
2023-02-11 17:35:04,173 DEBUG TRAIN Batch 9/1200 loss 16.190504 loss_att 17.245720 loss_ctc 22.713720 loss_rnnt 12.509822 hw_loss 0.487477 lr 0.00057269 rank 6
2023-02-11 17:36:19,766 DEBUG TRAIN Batch 9/1300 loss 9.517717 loss_att 11.987135 loss_ctc 16.905636 loss_rnnt 3.842915 hw_loss 0.786724 lr 0.00057202 rank 2
2023-02-11 17:36:19,767 DEBUG TRAIN Batch 9/1300 loss 10.767322 loss_att 14.583764 loss_ctc 12.506862 loss_rnnt 6.900121 hw_loss 0.538495 lr 0.00057238 rank 3
2023-02-11 17:36:19,768 DEBUG TRAIN Batch 9/1300 loss 16.211262 loss_att 20.584171 loss_ctc 23.864960 loss_rnnt 11.184271 hw_loss 0.587235 lr 0.00057246 rank 7
2023-02-11 17:36:19,773 DEBUG TRAIN Batch 9/1300 loss 17.928965 loss_att 22.120937 loss_ctc 23.121222 loss_rnnt 15.405552 hw_loss 0.186134 lr 0.00057209 rank 0
2023-02-11 17:36:19,772 DEBUG TRAIN Batch 9/1300 loss 16.353136 loss_att 20.969168 loss_ctc 30.172726 loss_rnnt 12.407225 hw_loss 0.221267 lr 0.00057207 rank 5
2023-02-11 17:36:19,775 DEBUG TRAIN Batch 9/1300 loss 15.050476 loss_att 11.917525 loss_ctc 15.894295 loss_rnnt 10.539764 hw_loss 0.942148 lr 0.00057205 rank 1
2023-02-11 17:36:19,777 DEBUG TRAIN Batch 9/1300 loss 15.798434 loss_att 17.162783 loss_ctc 19.474926 loss_rnnt 11.017864 hw_loss 0.753281 lr 0.00057227 rank 4
2023-02-11 17:36:19,779 DEBUG TRAIN Batch 9/1300 loss 13.844410 loss_att 11.026995 loss_ctc 16.192793 loss_rnnt 8.879140 hw_loss 0.977932 lr 0.00057232 rank 6
2023-02-11 17:37:38,336 DEBUG TRAIN Batch 9/1400 loss 6.632003 loss_att 11.091339 loss_ctc 11.819761 loss_rnnt 4.016450 hw_loss 0.193497 lr 0.00057208 rank 7
2023-02-11 17:37:38,337 DEBUG TRAIN Batch 9/1400 loss 20.235706 loss_att 26.916843 loss_ctc 31.296505 loss_rnnt 14.983633 hw_loss 0.457701 lr 0.00057194 rank 6
2023-02-11 17:37:38,340 DEBUG TRAIN Batch 9/1400 loss 9.250213 loss_att 14.770029 loss_ctc 16.430546 loss_rnnt 5.992730 hw_loss 0.224277 lr 0.00057190 rank 4
2023-02-11 17:37:38,341 DEBUG TRAIN Batch 9/1400 loss 12.734112 loss_att 17.119473 loss_ctc 21.301834 loss_rnnt 9.026989 hw_loss 0.316442 lr 0.00057165 rank 2
2023-02-11 17:37:38,342 DEBUG TRAIN Batch 9/1400 loss 20.994907 loss_att 20.789690 loss_ctc 23.077307 loss_rnnt 16.657621 hw_loss 0.768877 lr 0.00057200 rank 3
2023-02-11 17:37:38,344 DEBUG TRAIN Batch 9/1400 loss 14.483278 loss_att 17.070499 loss_ctc 21.147953 loss_rnnt 10.800762 hw_loss 0.426834 lr 0.00057172 rank 0
2023-02-11 17:37:38,347 DEBUG TRAIN Batch 9/1400 loss 12.068363 loss_att 12.735598 loss_ctc 19.647594 loss_rnnt 9.060318 hw_loss 0.349506 lr 0.00057168 rank 1
2023-02-11 17:37:38,348 DEBUG TRAIN Batch 9/1400 loss 17.053593 loss_att 19.739910 loss_ctc 27.951553 loss_rnnt 13.817804 hw_loss 0.233524 lr 0.00057170 rank 5
2023-02-11 17:38:55,752 DEBUG TRAIN Batch 9/1500 loss 24.749693 loss_att 24.870518 loss_ctc 29.000254 loss_rnnt 21.425880 hw_loss 0.512420 lr 0.00057171 rank 7
2023-02-11 17:38:55,756 DEBUG TRAIN Batch 9/1500 loss 18.810333 loss_att 18.164845 loss_ctc 19.100803 loss_rnnt 15.100805 hw_loss 0.712481 lr 0.00057132 rank 5
2023-02-11 17:38:55,759 DEBUG TRAIN Batch 9/1500 loss 11.266887 loss_att 14.853580 loss_ctc 19.445471 loss_rnnt 7.455089 hw_loss 0.375746 lr 0.00057152 rank 4
2023-02-11 17:38:55,759 DEBUG TRAIN Batch 9/1500 loss 19.279819 loss_att 18.993734 loss_ctc 28.685253 loss_rnnt 15.382729 hw_loss 0.506297 lr 0.00057163 rank 3
2023-02-11 17:38:55,760 DEBUG TRAIN Batch 9/1500 loss 8.985387 loss_att 11.671051 loss_ctc 11.227550 loss_rnnt 4.765506 hw_loss 0.634461 lr 0.00057127 rank 2
2023-02-11 17:38:55,760 DEBUG TRAIN Batch 9/1500 loss 11.015297 loss_att 13.504639 loss_ctc 14.246674 loss_rnnt 7.594682 hw_loss 0.467231 lr 0.00057134 rank 0
2023-02-11 17:38:55,761 DEBUG TRAIN Batch 9/1500 loss 11.743466 loss_att 13.803299 loss_ctc 18.897955 loss_rnnt 8.350671 hw_loss 0.380043 lr 0.00057130 rank 1
2023-02-11 17:38:55,768 DEBUG TRAIN Batch 9/1500 loss 17.717882 loss_att 19.531878 loss_ctc 33.240494 loss_rnnt 14.407741 hw_loss 0.164562 lr 0.00057157 rank 6
2023-02-11 17:40:09,588 DEBUG TRAIN Batch 9/1600 loss 29.168989 loss_att 33.274258 loss_ctc 49.315933 loss_rnnt 23.374430 hw_loss 0.428859 lr 0.00057126 rank 3
2023-02-11 17:40:09,588 DEBUG TRAIN Batch 9/1600 loss 12.832379 loss_att 14.613631 loss_ctc 15.271886 loss_rnnt 8.432074 hw_loss 0.697272 lr 0.00057095 rank 5
2023-02-11 17:40:09,591 DEBUG TRAIN Batch 9/1600 loss 15.606136 loss_att 17.339033 loss_ctc 23.464560 loss_rnnt 12.006444 hw_loss 0.413498 lr 0.00057133 rank 7
2023-02-11 17:40:09,592 DEBUG TRAIN Batch 9/1600 loss 14.373732 loss_att 16.366890 loss_ctc 23.015263 loss_rnnt 9.133224 hw_loss 0.691814 lr 0.00057120 rank 6
2023-02-11 17:40:09,594 DEBUG TRAIN Batch 9/1600 loss 19.427406 loss_att 21.447117 loss_ctc 31.474146 loss_rnnt 15.607727 hw_loss 0.339282 lr 0.00057097 rank 0
2023-02-11 17:40:09,596 DEBUG TRAIN Batch 9/1600 loss 27.059855 loss_att 31.314636 loss_ctc 46.675598 loss_rnnt 22.113811 hw_loss 0.277435 lr 0.00057115 rank 4
2023-02-11 17:40:09,597 DEBUG TRAIN Batch 9/1600 loss 17.346853 loss_att 18.015644 loss_ctc 25.945692 loss_rnnt 11.056575 hw_loss 0.939376 lr 0.00057090 rank 2
2023-02-11 17:40:09,645 DEBUG TRAIN Batch 9/1600 loss 17.325207 loss_att 22.394934 loss_ctc 27.967783 loss_rnnt 12.256364 hw_loss 0.494229 lr 0.00057093 rank 1
2023-02-11 17:41:26,092 DEBUG TRAIN Batch 9/1700 loss 6.463643 loss_att 8.690758 loss_ctc 10.889791 loss_rnnt 4.278639 hw_loss 0.215517 lr 0.00057096 rank 7
2023-02-11 17:41:26,095 DEBUG TRAIN Batch 9/1700 loss 19.239725 loss_att 21.100439 loss_ctc 27.239042 loss_rnnt 15.056259 hw_loss 0.514640 lr 0.00057053 rank 2
2023-02-11 17:41:26,094 DEBUG TRAIN Batch 9/1700 loss 20.955160 loss_att 26.009094 loss_ctc 30.848495 loss_rnnt 17.723923 hw_loss 0.169001 lr 0.00057058 rank 5
2023-02-11 17:41:26,094 DEBUG TRAIN Batch 9/1700 loss 12.662421 loss_att 15.338720 loss_ctc 19.116425 loss_rnnt 9.907310 hw_loss 0.254872 lr 0.00057082 rank 6
2023-02-11 17:41:26,096 DEBUG TRAIN Batch 9/1700 loss 5.758775 loss_att 7.586696 loss_ctc 11.924057 loss_rnnt 3.569909 hw_loss 0.187733 lr 0.00057088 rank 3
2023-02-11 17:41:26,099 DEBUG TRAIN Batch 9/1700 loss 14.386330 loss_att 15.458287 loss_ctc 19.263847 loss_rnnt 11.851023 hw_loss 0.313233 lr 0.00057060 rank 0
2023-02-11 17:41:26,099 DEBUG TRAIN Batch 9/1700 loss 6.052031 loss_att 9.659555 loss_ctc 7.495876 loss_rnnt 2.508710 hw_loss 0.492994 lr 0.00057078 rank 4
2023-02-11 17:41:26,105 DEBUG TRAIN Batch 9/1700 loss 8.129482 loss_att 9.754084 loss_ctc 11.782352 loss_rnnt 4.723135 hw_loss 0.486446 lr 0.00057056 rank 1
2023-02-11 17:42:45,615 DEBUG TRAIN Batch 9/1800 loss 17.085537 loss_att 19.176422 loss_ctc 27.961512 loss_rnnt 11.543544 hw_loss 0.688816 lr 0.00057023 rank 0
2023-02-11 17:42:45,615 DEBUG TRAIN Batch 9/1800 loss 18.584501 loss_att 19.206778 loss_ctc 28.538465 loss_rnnt 13.578903 hw_loss 0.666365 lr 0.00057021 rank 5
2023-02-11 17:42:45,617 DEBUG TRAIN Batch 9/1800 loss 15.050726 loss_att 16.428074 loss_ctc 21.001143 loss_rnnt 11.517488 hw_loss 0.462071 lr 0.00057045 rank 6
2023-02-11 17:42:45,617 DEBUG TRAIN Batch 9/1800 loss 11.969930 loss_att 10.413125 loss_ctc 13.836874 loss_rnnt 8.447290 hw_loss 0.672201 lr 0.00057059 rank 7
2023-02-11 17:42:45,618 DEBUG TRAIN Batch 9/1800 loss 14.450260 loss_att 13.951025 loss_ctc 17.787451 loss_rnnt 9.987314 hw_loss 0.772094 lr 0.00057051 rank 3
2023-02-11 17:42:45,622 DEBUG TRAIN Batch 9/1800 loss 21.295582 loss_att 19.919205 loss_ctc 30.519512 loss_rnnt 17.926302 hw_loss 0.452756 lr 0.00057041 rank 4
2023-02-11 17:42:45,624 DEBUG TRAIN Batch 9/1800 loss 9.939670 loss_att 9.133688 loss_ctc 10.599288 loss_rnnt 4.574108 hw_loss 1.019777 lr 0.00057016 rank 2
2023-02-11 17:42:45,624 DEBUG TRAIN Batch 9/1800 loss 9.986371 loss_att 13.754089 loss_ctc 17.093853 loss_rnnt 5.907805 hw_loss 0.445755 lr 0.00057019 rank 1
2023-02-11 17:44:01,940 DEBUG TRAIN Batch 9/1900 loss 11.794771 loss_att 9.027678 loss_ctc 12.277679 loss_rnnt 7.626076 hw_loss 0.873324 lr 0.00057014 rank 3
2023-02-11 17:44:01,946 DEBUG TRAIN Batch 9/1900 loss 18.091995 loss_att 13.081682 loss_ctc 16.918159 loss_rnnt 12.403995 hw_loss 1.283733 lr 0.00056979 rank 2
2023-02-11 17:44:01,947 DEBUG TRAIN Batch 9/1900 loss 14.262452 loss_att 12.091109 loss_ctc 15.537439 loss_rnnt 9.627579 hw_loss 0.918589 lr 0.00056984 rank 5
2023-02-11 17:44:01,947 DEBUG TRAIN Batch 9/1900 loss 19.536583 loss_att 22.544302 loss_ctc 34.448299 loss_rnnt 14.346610 hw_loss 0.487537 lr 0.00057022 rank 7
2023-02-11 17:44:01,948 DEBUG TRAIN Batch 9/1900 loss 11.888272 loss_att 10.345421 loss_ctc 18.369398 loss_rnnt 7.713829 hw_loss 0.678537 lr 0.00056986 rank 0
2023-02-11 17:44:01,950 DEBUG TRAIN Batch 9/1900 loss 15.523312 loss_att 16.161905 loss_ctc 26.116909 loss_rnnt 11.125720 hw_loss 0.535761 lr 0.00056982 rank 1
2023-02-11 17:44:01,951 DEBUG TRAIN Batch 9/1900 loss 13.870916 loss_att 14.695818 loss_ctc 15.259511 loss_rnnt 10.021443 hw_loss 0.656127 lr 0.00057008 rank 6
2023-02-11 17:44:01,952 DEBUG TRAIN Batch 9/1900 loss 13.695586 loss_att 16.167522 loss_ctc 20.814987 loss_rnnt 10.367865 hw_loss 0.353265 lr 0.00057004 rank 4
2023-02-11 17:45:17,465 DEBUG TRAIN Batch 9/2000 loss 5.332419 loss_att 7.041756 loss_ctc 10.205929 loss_rnnt 2.220723 hw_loss 0.397505 lr 0.00056942 rank 2
2023-02-11 17:45:17,469 DEBUG TRAIN Batch 9/2000 loss 22.131630 loss_att 25.414282 loss_ctc 41.475563 loss_rnnt 16.509212 hw_loss 0.447506 lr 0.00056977 rank 3
2023-02-11 17:45:17,472 DEBUG TRAIN Batch 9/2000 loss 18.716227 loss_att 21.489199 loss_ctc 28.509274 loss_rnnt 16.287685 hw_loss 0.106539 lr 0.00056971 rank 6
2023-02-11 17:45:17,473 DEBUG TRAIN Batch 9/2000 loss 17.868937 loss_att 22.944172 loss_ctc 32.861244 loss_rnnt 14.273868 hw_loss 0.108946 lr 0.00056947 rank 5
2023-02-11 17:45:17,473 DEBUG TRAIN Batch 9/2000 loss 28.842659 loss_att 27.294674 loss_ctc 39.886444 loss_rnnt 26.475906 hw_loss 0.225722 lr 0.00056985 rank 7
2023-02-11 17:45:17,475 DEBUG TRAIN Batch 9/2000 loss 13.030136 loss_att 17.959232 loss_ctc 19.338694 loss_rnnt 7.482400 hw_loss 0.697645 lr 0.00056949 rank 0
2023-02-11 17:45:17,477 DEBUG TRAIN Batch 9/2000 loss 31.986519 loss_att 34.302612 loss_ctc 51.490997 loss_rnnt 27.104504 hw_loss 0.340913 lr 0.00056967 rank 4
2023-02-11 17:45:17,523 DEBUG TRAIN Batch 9/2000 loss 16.311750 loss_att 20.235523 loss_ctc 30.068029 loss_rnnt 12.557460 hw_loss 0.212881 lr 0.00056945 rank 1
2023-02-11 17:46:35,754 DEBUG TRAIN Batch 9/2100 loss 14.754767 loss_att 18.126545 loss_ctc 16.897770 loss_rnnt 10.452727 hw_loss 0.626616 lr 0.00056940 rank 3
2023-02-11 17:46:35,756 DEBUG TRAIN Batch 9/2100 loss 13.616682 loss_att 14.969378 loss_ctc 21.513165 loss_rnnt 11.166107 hw_loss 0.211345 lr 0.00056934 rank 6
2023-02-11 17:46:35,757 DEBUG TRAIN Batch 9/2100 loss 23.162760 loss_att 26.710342 loss_ctc 28.345831 loss_rnnt 20.126503 hw_loss 0.306687 lr 0.00056910 rank 5
2023-02-11 17:46:35,758 DEBUG TRAIN Batch 9/2100 loss 11.147763 loss_att 13.845318 loss_ctc 18.931358 loss_rnnt 8.836463 hw_loss 0.137621 lr 0.00056930 rank 4
2023-02-11 17:46:35,762 DEBUG TRAIN Batch 9/2100 loss 17.428003 loss_att 19.513065 loss_ctc 22.731308 loss_rnnt 14.674673 hw_loss 0.305477 lr 0.00056948 rank 7
2023-02-11 17:46:35,763 DEBUG TRAIN Batch 9/2100 loss 33.477875 loss_att 36.981441 loss_ctc 62.060081 loss_rnnt 25.599583 hw_loss 0.631240 lr 0.00056908 rank 1
2023-02-11 17:46:35,764 DEBUG TRAIN Batch 9/2100 loss 14.074152 loss_att 20.831573 loss_ctc 29.650213 loss_rnnt 10.036059 hw_loss 0.114338 lr 0.00056912 rank 0
2023-02-11 17:46:35,765 DEBUG TRAIN Batch 9/2100 loss 4.459224 loss_att 8.029420 loss_ctc 7.444396 loss_rnnt 2.597135 hw_loss 0.140630 lr 0.00056905 rank 2
2023-02-11 17:47:52,692 DEBUG TRAIN Batch 9/2200 loss 12.111871 loss_att 14.025237 loss_ctc 15.973907 loss_rnnt 9.299786 hw_loss 0.358964 lr 0.00056903 rank 3
2023-02-11 17:47:52,696 DEBUG TRAIN Batch 9/2200 loss 23.889206 loss_att 25.655794 loss_ctc 25.324999 loss_rnnt 20.129913 hw_loss 0.602725 lr 0.00056911 rank 7
2023-02-11 17:47:52,699 DEBUG TRAIN Batch 9/2200 loss 16.034771 loss_att 20.234497 loss_ctc 24.978596 loss_rnnt 12.590301 hw_loss 0.264753 lr 0.00056875 rank 0
2023-02-11 17:47:52,701 DEBUG TRAIN Batch 9/2200 loss 15.852348 loss_att 19.638552 loss_ctc 30.964882 loss_rnnt 11.330447 hw_loss 0.328061 lr 0.00056897 rank 6
2023-02-11 17:47:52,701 DEBUG TRAIN Batch 9/2200 loss 8.169209 loss_att 11.405985 loss_ctc 13.524052 loss_rnnt 3.989540 hw_loss 0.528438 lr 0.00056868 rank 2
2023-02-11 17:47:52,703 DEBUG TRAIN Batch 9/2200 loss 16.419731 loss_att 17.691368 loss_ctc 22.560482 loss_rnnt 13.174529 hw_loss 0.407270 lr 0.00056871 rank 1
2023-02-11 17:47:52,703 DEBUG TRAIN Batch 9/2200 loss 22.729504 loss_att 21.810802 loss_ctc 29.534462 loss_rnnt 18.478413 hw_loss 0.661407 lr 0.00056873 rank 5
2023-02-11 17:47:52,705 DEBUG TRAIN Batch 9/2200 loss 17.695576 loss_att 18.694626 loss_ctc 21.851608 loss_rnnt 14.236647 hw_loss 0.507184 lr 0.00056893 rank 4
2023-02-11 17:49:08,637 DEBUG TRAIN Batch 9/2300 loss 18.515924 loss_att 19.021235 loss_ctc 24.874880 loss_rnnt 14.773130 hw_loss 0.523851 lr 0.00056838 rank 0
2023-02-11 17:49:08,641 DEBUG TRAIN Batch 9/2300 loss 15.374500 loss_att 19.101753 loss_ctc 22.452869 loss_rnnt 11.111747 hw_loss 0.482535 lr 0.00056874 rank 7
2023-02-11 17:49:08,642 DEBUG TRAIN Batch 9/2300 loss 20.872112 loss_att 22.198345 loss_ctc 30.835545 loss_rnnt 16.043291 hw_loss 0.606584 lr 0.00056834 rank 1
2023-02-11 17:49:08,643 DEBUG TRAIN Batch 9/2300 loss 12.175450 loss_att 14.214787 loss_ctc 15.853139 loss_rnnt 8.526174 hw_loss 0.515822 lr 0.00056860 rank 6
2023-02-11 17:49:08,644 DEBUG TRAIN Batch 9/2300 loss 16.957909 loss_att 18.458893 loss_ctc 18.622635 loss_rnnt 12.563437 hw_loss 0.726058 lr 0.00056831 rank 2
2023-02-11 17:49:08,644 DEBUG TRAIN Batch 9/2300 loss 15.563808 loss_att 18.119928 loss_ctc 27.501326 loss_rnnt 12.002354 hw_loss 0.273481 lr 0.00056836 rank 5
2023-02-11 17:49:08,644 DEBUG TRAIN Batch 9/2300 loss 8.066668 loss_att 12.047423 loss_ctc 12.131433 loss_rnnt 4.685068 hw_loss 0.383152 lr 0.00056866 rank 3
2023-02-11 17:49:08,649 DEBUG TRAIN Batch 9/2300 loss 15.468674 loss_att 20.070747 loss_ctc 20.938347 loss_rnnt 10.472115 hw_loss 0.627535 lr 0.00056856 rank 4
2023-02-11 17:50:25,540 DEBUG TRAIN Batch 9/2400 loss 14.617779 loss_att 14.521845 loss_ctc 17.722046 loss_rnnt 10.003634 hw_loss 0.791143 lr 0.00056837 rank 7
2023-02-11 17:50:25,540 DEBUG TRAIN Batch 9/2400 loss 26.348900 loss_att 29.374016 loss_ctc 33.985657 loss_rnnt 21.433250 hw_loss 0.617323 lr 0.00056798 rank 1
2023-02-11 17:50:25,544 DEBUG TRAIN Batch 9/2400 loss 22.170053 loss_att 22.023218 loss_ctc 31.093670 loss_rnnt 17.874374 hw_loss 0.587856 lr 0.00056802 rank 0
2023-02-11 17:50:25,545 DEBUG TRAIN Batch 9/2400 loss 13.553183 loss_att 15.829720 loss_ctc 24.843487 loss_rnnt 9.721128 hw_loss 0.350882 lr 0.00056830 rank 3
2023-02-11 17:50:25,550 DEBUG TRAIN Batch 9/2400 loss 13.601844 loss_att 14.467407 loss_ctc 21.407486 loss_rnnt 10.815289 hw_loss 0.294879 lr 0.00056795 rank 2
2023-02-11 17:50:25,550 DEBUG TRAIN Batch 9/2400 loss 10.467638 loss_att 13.744087 loss_ctc 15.093426 loss_rnnt 5.868204 hw_loss 0.623882 lr 0.00056819 rank 4
2023-02-11 17:50:25,552 DEBUG TRAIN Batch 9/2400 loss 12.053835 loss_att 13.714096 loss_ctc 19.480915 loss_rnnt 8.367240 hw_loss 0.443300 lr 0.00056799 rank 5
2023-02-11 17:50:25,553 DEBUG TRAIN Batch 9/2400 loss 6.623458 loss_att 9.732188 loss_ctc 8.632617 loss_rnnt 4.316045 hw_loss 0.265834 lr 0.00056824 rank 6
2023-02-11 17:51:44,651 DEBUG TRAIN Batch 9/2500 loss 14.662404 loss_att 16.626951 loss_ctc 25.653769 loss_rnnt 10.277885 hw_loss 0.473643 lr 0.00056801 rank 7
2023-02-11 17:51:44,653 DEBUG TRAIN Batch 9/2500 loss 14.237745 loss_att 13.485995 loss_ctc 18.446815 loss_rnnt 10.660642 hw_loss 0.593671 lr 0.00056793 rank 3
2023-02-11 17:51:44,655 DEBUG TRAIN Batch 9/2500 loss 19.256418 loss_att 18.413372 loss_ctc 31.131672 loss_rnnt 13.686325 hw_loss 0.779126 lr 0.00056787 rank 6
2023-02-11 17:51:44,655 DEBUG TRAIN Batch 9/2500 loss 17.230005 loss_att 20.493259 loss_ctc 26.701670 loss_rnnt 14.631454 hw_loss 0.128064 lr 0.00056783 rank 4
2023-02-11 17:51:44,655 DEBUG TRAIN Batch 9/2500 loss 14.478321 loss_att 15.267157 loss_ctc 20.648479 loss_rnnt 10.616146 hw_loss 0.540323 lr 0.00056761 rank 1
2023-02-11 17:51:44,656 DEBUG TRAIN Batch 9/2500 loss 15.120795 loss_att 19.063723 loss_ctc 29.565184 loss_rnnt 10.969429 hw_loss 0.269412 lr 0.00056765 rank 0
2023-02-11 17:51:44,659 DEBUG TRAIN Batch 9/2500 loss 23.600550 loss_att 22.278513 loss_ctc 31.270903 loss_rnnt 20.024937 hw_loss 0.528245 lr 0.00056763 rank 5
2023-02-11 17:51:44,659 DEBUG TRAIN Batch 9/2500 loss 10.078100 loss_att 11.398741 loss_ctc 14.092667 loss_rnnt 6.148633 hw_loss 0.586887 lr 0.00056758 rank 2
2023-02-11 17:53:00,032 DEBUG TRAIN Batch 9/2600 loss 13.772171 loss_att 14.158078 loss_ctc 18.334785 loss_rnnt 9.124228 hw_loss 0.742952 lr 0.00056746 rank 4
2023-02-11 17:53:00,034 DEBUG TRAIN Batch 9/2600 loss 23.892031 loss_att 27.172642 loss_ctc 37.788158 loss_rnnt 20.257214 hw_loss 0.211102 lr 0.00056756 rank 3
2023-02-11 17:53:00,034 DEBUG TRAIN Batch 9/2600 loss 16.860937 loss_att 19.885199 loss_ctc 24.826841 loss_rnnt 14.478927 hw_loss 0.134069 lr 0.00056764 rank 7
2023-02-11 17:53:00,034 DEBUG TRAIN Batch 9/2600 loss 14.347795 loss_att 14.556488 loss_ctc 19.053328 loss_rnnt 10.484495 hw_loss 0.598904 lr 0.00056729 rank 0
2023-02-11 17:53:00,036 DEBUG TRAIN Batch 9/2600 loss 12.634157 loss_att 12.827865 loss_ctc 19.302391 loss_rnnt 10.184250 hw_loss 0.285388 lr 0.00056722 rank 2
2023-02-11 17:53:00,038 DEBUG TRAIN Batch 9/2600 loss 10.348541 loss_att 14.401243 loss_ctc 18.657255 loss_rnnt 7.541198 hw_loss 0.166683 lr 0.00056750 rank 6
2023-02-11 17:53:00,039 DEBUG TRAIN Batch 9/2600 loss 38.161407 loss_att 45.756435 loss_ctc 63.749763 loss_rnnt 30.990601 hw_loss 0.420004 lr 0.00056726 rank 5
2023-02-11 17:53:00,039 DEBUG TRAIN Batch 9/2600 loss 23.158703 loss_att 21.059908 loss_ctc 29.152884 loss_rnnt 19.690495 hw_loss 0.579139 lr 0.00056724 rank 1
2023-02-11 17:54:15,422 DEBUG TRAIN Batch 9/2700 loss 15.637578 loss_att 19.366068 loss_ctc 26.023754 loss_rnnt 10.108355 hw_loss 0.637257 lr 0.00056727 rank 7
2023-02-11 17:54:15,425 DEBUG TRAIN Batch 9/2700 loss 13.049582 loss_att 15.726902 loss_ctc 23.091759 loss_rnnt 10.414917 hw_loss 0.142546 lr 0.00056720 rank 3
2023-02-11 17:54:15,425 DEBUG TRAIN Batch 9/2700 loss 15.780341 loss_att 14.182138 loss_ctc 17.794781 loss_rnnt 13.064716 hw_loss 0.518751 lr 0.00056692 rank 0
2023-02-11 17:54:15,427 DEBUG TRAIN Batch 9/2700 loss 16.172421 loss_att 20.427671 loss_ctc 32.816231 loss_rnnt 12.152456 hw_loss 0.178076 lr 0.00056714 rank 6
2023-02-11 17:54:15,427 DEBUG TRAIN Batch 9/2700 loss 8.853106 loss_att 10.942088 loss_ctc 11.154276 loss_rnnt 6.354803 hw_loss 0.332566 lr 0.00056685 rank 2
2023-02-11 17:54:15,428 DEBUG TRAIN Batch 9/2700 loss 12.849884 loss_att 15.319258 loss_ctc 21.155132 loss_rnnt 10.330593 hw_loss 0.172134 lr 0.00056688 rank 1
2023-02-11 17:54:15,429 DEBUG TRAIN Batch 9/2700 loss 9.649972 loss_att 14.370955 loss_ctc 14.467098 loss_rnnt 6.602403 hw_loss 0.273954 lr 0.00056710 rank 4
2023-02-11 17:54:15,431 DEBUG TRAIN Batch 9/2700 loss 19.488297 loss_att 28.188622 loss_ctc 44.659557 loss_rnnt 12.268341 hw_loss 0.398198 lr 0.00056690 rank 5
2023-02-11 17:55:32,794 DEBUG TRAIN Batch 9/2800 loss 19.467604 loss_att 22.185423 loss_ctc 32.431774 loss_rnnt 14.990438 hw_loss 0.413446 lr 0.00056656 rank 0
2023-02-11 17:55:32,794 DEBUG TRAIN Batch 9/2800 loss 13.426311 loss_att 16.902998 loss_ctc 17.501688 loss_rnnt 8.274611 hw_loss 0.733684 lr 0.00056683 rank 3
2023-02-11 17:55:32,799 DEBUG TRAIN Batch 9/2800 loss 22.593239 loss_att 27.773071 loss_ctc 31.993643 loss_rnnt 18.450571 hw_loss 0.347497 lr 0.00056673 rank 4
2023-02-11 17:55:32,799 DEBUG TRAIN Batch 9/2800 loss 8.926021 loss_att 11.113007 loss_ctc 15.080367 loss_rnnt 5.595104 hw_loss 0.388676 lr 0.00056677 rank 6
2023-02-11 17:55:32,802 DEBUG TRAIN Batch 9/2800 loss 20.307449 loss_att 23.321571 loss_ctc 34.764751 loss_rnnt 14.563087 hw_loss 0.602606 lr 0.00056652 rank 1
2023-02-11 17:55:32,802 DEBUG TRAIN Batch 9/2800 loss 24.590517 loss_att 28.187088 loss_ctc 36.311317 loss_rnnt 19.210758 hw_loss 0.580813 lr 0.00056653 rank 5
2023-02-11 17:55:32,802 DEBUG TRAIN Batch 9/2800 loss 16.544420 loss_att 16.567886 loss_ctc 17.671158 loss_rnnt 13.482376 hw_loss 0.545085 lr 0.00056691 rank 7
2023-02-11 17:55:32,806 DEBUG TRAIN Batch 9/2800 loss 14.484968 loss_att 17.346567 loss_ctc 19.532207 loss_rnnt 10.134726 hw_loss 0.582179 lr 0.00056649 rank 2
2023-02-11 17:56:50,281 DEBUG TRAIN Batch 9/2900 loss 17.341152 loss_att 21.094048 loss_ctc 28.846624 loss_rnnt 14.832035 hw_loss 0.042089 lr 0.00056655 rank 7
2023-02-11 17:56:50,285 DEBUG TRAIN Batch 9/2900 loss 9.980442 loss_att 12.990026 loss_ctc 14.548409 loss_rnnt 5.730590 hw_loss 0.569789 lr 0.00056647 rank 3
2023-02-11 17:56:50,288 DEBUG TRAIN Batch 9/2900 loss 13.992458 loss_att 17.473911 loss_ctc 20.423597 loss_rnnt 10.522276 hw_loss 0.359326 lr 0.00056615 rank 1
2023-02-11 17:56:50,288 DEBUG TRAIN Batch 9/2900 loss 17.299763 loss_att 19.763798 loss_ctc 33.952908 loss_rnnt 12.818916 hw_loss 0.331429 lr 0.00056612 rank 2
2023-02-11 17:56:50,291 DEBUG TRAIN Batch 9/2900 loss 10.523439 loss_att 12.995251 loss_ctc 15.535484 loss_rnnt 7.282608 hw_loss 0.389662 lr 0.00056617 rank 5
2023-02-11 17:56:50,294 DEBUG TRAIN Batch 9/2900 loss 11.403014 loss_att 16.077921 loss_ctc 20.556417 loss_rnnt 8.506927 hw_loss 0.138872 lr 0.00056619 rank 0
2023-02-11 17:56:50,295 DEBUG TRAIN Batch 9/2900 loss 18.299446 loss_att 22.839266 loss_ctc 35.977055 loss_rnnt 12.516459 hw_loss 0.472126 lr 0.00056641 rank 6
2023-02-11 17:56:50,298 DEBUG TRAIN Batch 9/2900 loss 13.363501 loss_att 14.960427 loss_ctc 20.352585 loss_rnnt 11.153708 hw_loss 0.179724 lr 0.00056637 rank 4
2023-02-11 17:58:06,090 DEBUG TRAIN Batch 9/3000 loss 26.060907 loss_att 31.669405 loss_ctc 39.613625 loss_rnnt 21.991482 hw_loss 0.213881 lr 0.00056618 rank 7
2023-02-11 17:58:06,091 DEBUG TRAIN Batch 9/3000 loss 6.543270 loss_att 6.682533 loss_ctc 5.577376 loss_rnnt 3.221967 hw_loss 0.641669 lr 0.00056611 rank 3
2023-02-11 17:58:06,092 DEBUG TRAIN Batch 9/3000 loss 15.419758 loss_att 16.790377 loss_ctc 21.276318 loss_rnnt 12.834787 hw_loss 0.286870 lr 0.00056605 rank 6
2023-02-11 17:58:06,097 DEBUG TRAIN Batch 9/3000 loss 17.151958 loss_att 18.607193 loss_ctc 27.652685 loss_rnnt 12.227466 hw_loss 0.606253 lr 0.00056576 rank 2
2023-02-11 17:58:06,098 DEBUG TRAIN Batch 9/3000 loss 16.652264 loss_att 18.180454 loss_ctc 21.971630 loss_rnnt 13.508232 hw_loss 0.399215 lr 0.00056600 rank 4
2023-02-11 17:58:06,100 DEBUG TRAIN Batch 9/3000 loss 29.026962 loss_att 32.405296 loss_ctc 45.517979 loss_rnnt 23.622997 hw_loss 0.474281 lr 0.00056583 rank 0
2023-02-11 17:58:06,100 DEBUG TRAIN Batch 9/3000 loss 10.498452 loss_att 11.244803 loss_ctc 13.138844 loss_rnnt 5.787429 hw_loss 0.789319 lr 0.00056581 rank 5
2023-02-11 17:58:06,103 DEBUG TRAIN Batch 9/3000 loss 14.595884 loss_att 17.540630 loss_ctc 21.673939 loss_rnnt 9.773956 hw_loss 0.616732 lr 0.00056579 rank 1
2023-02-11 17:59:22,378 DEBUG TRAIN Batch 9/3100 loss 13.301047 loss_att 14.119961 loss_ctc 21.841021 loss_rnnt 9.955624 hw_loss 0.383058 lr 0.00056574 rank 3
2023-02-11 17:59:22,380 DEBUG TRAIN Batch 9/3100 loss 13.454818 loss_att 10.266132 loss_ctc 12.045587 loss_rnnt 9.319022 hw_loss 0.930268 lr 0.00056545 rank 5
2023-02-11 17:59:22,382 DEBUG TRAIN Batch 9/3100 loss 16.579012 loss_att 19.390226 loss_ctc 29.096443 loss_rnnt 12.984270 hw_loss 0.255658 lr 0.00056543 rank 1
2023-02-11 17:59:22,386 DEBUG TRAIN Batch 9/3100 loss 15.476781 loss_att 16.132935 loss_ctc 23.345186 loss_rnnt 12.606122 hw_loss 0.316933 lr 0.00056547 rank 0
2023-02-11 17:59:22,388 DEBUG TRAIN Batch 9/3100 loss 15.457812 loss_att 18.443451 loss_ctc 26.608168 loss_rnnt 12.013354 hw_loss 0.255115 lr 0.00056582 rank 7
2023-02-11 17:59:22,389 DEBUG TRAIN Batch 9/3100 loss 12.083286 loss_att 14.847538 loss_ctc 21.436722 loss_rnnt 8.604200 hw_loss 0.314833 lr 0.00056540 rank 2
2023-02-11 17:59:22,395 DEBUG TRAIN Batch 9/3100 loss 10.415055 loss_att 12.982383 loss_ctc 14.694405 loss_rnnt 7.118916 hw_loss 0.414768 lr 0.00056564 rank 4
2023-02-11 17:59:22,433 DEBUG TRAIN Batch 9/3100 loss 23.796644 loss_att 25.655956 loss_ctc 38.346138 loss_rnnt 20.630451 hw_loss 0.160199 lr 0.00056569 rank 6
2023-02-11 18:00:41,583 DEBUG TRAIN Batch 9/3200 loss 15.826231 loss_att 15.899791 loss_ctc 19.287075 loss_rnnt 11.493610 hw_loss 0.723087 lr 0.00056546 rank 7
2023-02-11 18:00:41,585 DEBUG TRAIN Batch 9/3200 loss 14.913469 loss_att 16.541496 loss_ctc 21.598175 loss_rnnt 12.161700 hw_loss 0.287788 lr 0.00056538 rank 3
2023-02-11 18:00:41,586 DEBUG TRAIN Batch 9/3200 loss 14.915694 loss_att 16.983032 loss_ctc 24.726311 loss_rnnt 12.487444 hw_loss 0.132506 lr 0.00056509 rank 5
2023-02-11 18:00:41,591 DEBUG TRAIN Batch 9/3200 loss 15.924212 loss_att 14.502293 loss_ctc 20.040335 loss_rnnt 10.677500 hw_loss 0.934177 lr 0.00056511 rank 0
2023-02-11 18:00:41,590 DEBUG TRAIN Batch 9/3200 loss 21.816368 loss_att 22.567627 loss_ctc 24.291784 loss_rnnt 19.108536 hw_loss 0.417661 lr 0.00056532 rank 6
2023-02-11 18:00:41,591 DEBUG TRAIN Batch 9/3200 loss 14.712482 loss_att 17.524307 loss_ctc 21.493677 loss_rnnt 11.296964 hw_loss 0.365436 lr 0.00056507 rank 1
2023-02-11 18:00:41,593 DEBUG TRAIN Batch 9/3200 loss 12.421175 loss_att 14.077429 loss_ctc 20.170218 loss_rnnt 8.225154 hw_loss 0.530918 lr 0.00056528 rank 4
2023-02-11 18:00:41,617 DEBUG TRAIN Batch 9/3200 loss 16.790882 loss_att 12.360970 loss_ctc 15.910525 loss_rnnt 10.917209 hw_loss 1.289444 lr 0.00056504 rank 2
2023-02-11 18:01:57,567 DEBUG TRAIN Batch 9/3300 loss 13.588223 loss_att 17.928097 loss_ctc 27.856085 loss_rnnt 10.226564 hw_loss 0.110869 lr 0.00056510 rank 7
2023-02-11 18:01:57,567 DEBUG TRAIN Batch 9/3300 loss 12.750878 loss_att 14.875935 loss_ctc 19.675514 loss_rnnt 9.677895 hw_loss 0.323379 lr 0.00056502 rank 3
2023-02-11 18:01:57,572 DEBUG TRAIN Batch 9/3300 loss 17.148542 loss_att 22.797569 loss_ctc 21.052662 loss_rnnt 12.605537 hw_loss 0.542372 lr 0.00056471 rank 1
2023-02-11 18:01:57,573 DEBUG TRAIN Batch 9/3300 loss 19.194954 loss_att 26.467831 loss_ctc 29.127563 loss_rnnt 14.317104 hw_loss 0.393548 lr 0.00056472 rank 5
2023-02-11 18:01:57,574 DEBUG TRAIN Batch 9/3300 loss 19.031326 loss_att 22.235218 loss_ctc 28.235977 loss_rnnt 14.480381 hw_loss 0.503040 lr 0.00056475 rank 0
2023-02-11 18:01:57,575 DEBUG TRAIN Batch 9/3300 loss 19.284081 loss_att 21.727922 loss_ctc 25.354033 loss_rnnt 13.244772 hw_loss 0.888978 lr 0.00056468 rank 2
2023-02-11 18:01:57,577 DEBUG TRAIN Batch 9/3300 loss 10.128448 loss_att 15.083663 loss_ctc 18.849567 loss_rnnt 6.846401 hw_loss 0.211535 lr 0.00056492 rank 4
2023-02-11 18:01:57,615 DEBUG TRAIN Batch 9/3300 loss 15.044093 loss_att 19.981607 loss_ctc 25.763466 loss_rnnt 11.624434 hw_loss 0.188045 lr 0.00056496 rank 6
2023-02-11 18:03:15,473 DEBUG TRAIN Batch 9/3400 loss 8.261952 loss_att 9.987053 loss_ctc 18.035248 loss_rnnt 5.166220 hw_loss 0.271426 lr 0.00056466 rank 3
2023-02-11 18:03:15,475 DEBUG TRAIN Batch 9/3400 loss 23.745234 loss_att 27.461872 loss_ctc 40.283134 loss_rnnt 19.086382 hw_loss 0.320712 lr 0.00056456 rank 4
2023-02-11 18:03:15,475 DEBUG TRAIN Batch 9/3400 loss 18.869722 loss_att 18.544432 loss_ctc 24.546417 loss_rnnt 15.577013 hw_loss 0.487664 lr 0.00056437 rank 5
2023-02-11 18:03:15,477 DEBUG TRAIN Batch 9/3400 loss 17.573704 loss_att 19.989983 loss_ctc 29.923435 loss_rnnt 12.443381 hw_loss 0.562581 lr 0.00056460 rank 6
2023-02-11 18:03:15,477 DEBUG TRAIN Batch 9/3400 loss 16.106995 loss_att 17.865355 loss_ctc 26.243637 loss_rnnt 13.519567 hw_loss 0.165788 lr 0.00056439 rank 0
2023-02-11 18:03:15,479 DEBUG TRAIN Batch 9/3400 loss 16.514502 loss_att 18.155773 loss_ctc 23.220150 loss_rnnt 13.479433 hw_loss 0.339886 lr 0.00056474 rank 7
2023-02-11 18:03:15,481 DEBUG TRAIN Batch 9/3400 loss 14.547606 loss_att 15.573584 loss_ctc 20.411148 loss_rnnt 10.057371 hw_loss 0.656857 lr 0.00056432 rank 2
2023-02-11 18:03:15,491 DEBUG TRAIN Batch 9/3400 loss 16.288891 loss_att 16.604095 loss_ctc 27.850994 loss_rnnt 11.976809 hw_loss 0.507643 lr 0.00056435 rank 1
2023-02-11 18:04:32,892 DEBUG TRAIN Batch 9/3500 loss 19.134172 loss_att 20.135862 loss_ctc 32.853039 loss_rnnt 14.291399 hw_loss 0.527485 lr 0.00056438 rank 7
2023-02-11 18:04:32,893 DEBUG TRAIN Batch 9/3500 loss 21.293983 loss_att 19.253086 loss_ctc 27.686401 loss_rnnt 17.761883 hw_loss 0.578992 lr 0.00056399 rank 1
2023-02-11 18:04:32,893 DEBUG TRAIN Batch 9/3500 loss 8.470343 loss_att 9.666420 loss_ctc 14.074601 loss_rnnt 4.540604 hw_loss 0.551867 lr 0.00056396 rank 2
2023-02-11 18:04:32,894 DEBUG TRAIN Batch 9/3500 loss 11.333589 loss_att 14.709899 loss_ctc 20.298862 loss_rnnt 7.581253 hw_loss 0.352819 lr 0.00056403 rank 0
2023-02-11 18:04:32,898 DEBUG TRAIN Batch 9/3500 loss 12.344174 loss_att 17.728172 loss_ctc 24.089725 loss_rnnt 8.603129 hw_loss 0.205907 lr 0.00056430 rank 3
2023-02-11 18:04:32,899 DEBUG TRAIN Batch 9/3500 loss 12.070560 loss_att 12.888477 loss_ctc 13.048006 loss_rnnt 8.812283 hw_loss 0.555819 lr 0.00056401 rank 5
2023-02-11 18:04:32,904 DEBUG TRAIN Batch 9/3500 loss 20.097881 loss_att 24.216812 loss_ctc 39.203949 loss_rnnt 15.490255 hw_loss 0.231818 lr 0.00056420 rank 4
2023-02-11 18:04:32,906 DEBUG TRAIN Batch 9/3500 loss 14.366410 loss_att 17.166126 loss_ctc 24.511097 loss_rnnt 11.556047 hw_loss 0.168336 lr 0.00056424 rank 6
2023-02-11 18:05:50,489 DEBUG TRAIN Batch 9/3600 loss 20.305088 loss_att 22.928165 loss_ctc 24.143864 loss_rnnt 17.085464 hw_loss 0.409344 lr 0.00056367 rank 0
2023-02-11 18:05:50,491 DEBUG TRAIN Batch 9/3600 loss 28.928392 loss_att 30.535570 loss_ctc 46.442020 loss_rnnt 24.375553 hw_loss 0.355547 lr 0.00056394 rank 3
2023-02-11 18:05:50,496 DEBUG TRAIN Batch 9/3600 loss 13.056089 loss_att 14.409595 loss_ctc 19.700434 loss_rnnt 10.797584 hw_loss 0.206605 lr 0.00056363 rank 1
2023-02-11 18:05:50,498 DEBUG TRAIN Batch 9/3600 loss 10.158998 loss_att 14.270023 loss_ctc 15.196478 loss_rnnt 5.910304 hw_loss 0.516530 lr 0.00056388 rank 6
2023-02-11 18:05:50,499 DEBUG TRAIN Batch 9/3600 loss 22.495850 loss_att 24.106953 loss_ctc 32.154232 loss_rnnt 17.120996 hw_loss 0.705909 lr 0.00056384 rank 4
2023-02-11 18:05:50,499 DEBUG TRAIN Batch 9/3600 loss 15.235122 loss_att 18.385365 loss_ctc 22.756855 loss_rnnt 10.409899 hw_loss 0.598552 lr 0.00056402 rank 7
2023-02-11 18:05:50,500 DEBUG TRAIN Batch 9/3600 loss 24.826725 loss_att 26.436733 loss_ctc 34.145149 loss_rnnt 21.174894 hw_loss 0.391383 lr 0.00056365 rank 5
2023-02-11 18:05:50,501 DEBUG TRAIN Batch 9/3600 loss 21.540861 loss_att 29.411728 loss_ctc 41.256523 loss_rnnt 16.239136 hw_loss 0.206025 lr 0.00056360 rank 2
2023-02-11 18:07:05,906 DEBUG TRAIN Batch 9/3700 loss 17.200657 loss_att 17.558100 loss_ctc 20.630461 loss_rnnt 15.349048 hw_loss 0.248027 lr 0.00056353 rank 6
2023-02-11 18:07:05,907 DEBUG TRAIN Batch 9/3700 loss 12.973719 loss_att 16.624027 loss_ctc 26.008896 loss_rnnt 9.816383 hw_loss 0.129234 lr 0.00056327 rank 1
2023-02-11 18:07:05,907 DEBUG TRAIN Batch 9/3700 loss 11.967299 loss_att 12.046399 loss_ctc 17.167347 loss_rnnt 8.405600 hw_loss 0.534851 lr 0.00056358 rank 3
2023-02-11 18:07:05,907 DEBUG TRAIN Batch 9/3700 loss 12.633494 loss_att 10.383862 loss_ctc 15.511045 loss_rnnt 9.121346 hw_loss 0.670950 lr 0.00056366 rank 7
2023-02-11 18:07:05,910 DEBUG TRAIN Batch 9/3700 loss 18.581118 loss_att 16.421257 loss_ctc 29.804533 loss_rnnt 14.013262 hw_loss 0.656882 lr 0.00056331 rank 0
2023-02-11 18:07:05,914 DEBUG TRAIN Batch 9/3700 loss 16.110256 loss_att 14.837044 loss_ctc 17.291197 loss_rnnt 13.495722 hw_loss 0.508447 lr 0.00056329 rank 5
2023-02-11 18:07:05,914 DEBUG TRAIN Batch 9/3700 loss 12.751974 loss_att 13.629807 loss_ctc 18.813374 loss_rnnt 10.375077 hw_loss 0.261214 lr 0.00056324 rank 2
2023-02-11 18:07:05,916 DEBUG TRAIN Batch 9/3700 loss 14.263774 loss_att 14.445024 loss_ctc 14.509451 loss_rnnt 12.356126 hw_loss 0.344745 lr 0.00056348 rank 4
2023-02-11 18:08:22,191 DEBUG TRAIN Batch 9/3800 loss 13.238292 loss_att 9.644710 loss_ctc 13.484357 loss_rnnt 7.971110 hw_loss 1.116204 lr 0.00056295 rank 0
2023-02-11 18:08:22,192 DEBUG TRAIN Batch 9/3800 loss 12.433307 loss_att 8.741672 loss_ctc 10.861020 loss_rnnt 7.394857 hw_loss 1.122453 lr 0.00056323 rank 3
2023-02-11 18:08:22,197 DEBUG TRAIN Batch 9/3800 loss 34.759727 loss_att 35.729195 loss_ctc 49.944637 loss_rnnt 31.212330 hw_loss 0.249159 lr 0.00056330 rank 7
2023-02-11 18:08:22,199 DEBUG TRAIN Batch 9/3800 loss 19.263550 loss_att 17.172850 loss_ctc 23.126200 loss_rnnt 13.191440 hw_loss 1.120355 lr 0.00056289 rank 2
2023-02-11 18:08:22,200 DEBUG TRAIN Batch 9/3800 loss 10.080778 loss_att 9.556435 loss_ctc 11.668477 loss_rnnt 6.195581 hw_loss 0.708445 lr 0.00056313 rank 4
2023-02-11 18:08:22,200 DEBUG TRAIN Batch 9/3800 loss 18.939663 loss_att 15.629241 loss_ctc 20.546003 loss_rnnt 15.725392 hw_loss 0.686658 lr 0.00056317 rank 6
2023-02-11 18:08:22,202 DEBUG TRAIN Batch 9/3800 loss 12.211636 loss_att 15.450942 loss_ctc 17.709686 loss_rnnt 9.346910 hw_loss 0.278211 lr 0.00056293 rank 5
2023-02-11 18:08:22,247 DEBUG TRAIN Batch 9/3800 loss 10.004285 loss_att 11.924517 loss_ctc 17.866865 loss_rnnt 5.936948 hw_loss 0.494052 lr 0.00056291 rank 1
2023-02-11 18:09:40,925 DEBUG TRAIN Batch 9/3900 loss 21.799181 loss_att 25.684626 loss_ctc 40.922955 loss_rnnt 16.099957 hw_loss 0.444806 lr 0.00056294 rank 7
2023-02-11 18:09:40,925 DEBUG TRAIN Batch 9/3900 loss 22.580372 loss_att 30.352772 loss_ctc 39.498581 loss_rnnt 17.189430 hw_loss 0.296382 lr 0.00056281 rank 6
2023-02-11 18:09:40,928 DEBUG TRAIN Batch 9/3900 loss 14.130810 loss_att 11.395660 loss_ctc 15.524472 loss_rnnt 9.113764 hw_loss 1.008423 lr 0.00056256 rank 1
2023-02-11 18:09:40,928 DEBUG TRAIN Batch 9/3900 loss 15.616715 loss_att 20.399786 loss_ctc 22.202663 loss_rnnt 11.456732 hw_loss 0.435983 lr 0.00056287 rank 3
2023-02-11 18:09:40,930 DEBUG TRAIN Batch 9/3900 loss 13.363088 loss_att 16.431034 loss_ctc 20.747931 loss_rnnt 10.181998 hw_loss 0.296785 lr 0.00056253 rank 2
2023-02-11 18:09:40,932 DEBUG TRAIN Batch 9/3900 loss 13.954623 loss_att 11.346648 loss_ctc 14.536569 loss_rnnt 9.340628 hw_loss 0.948374 lr 0.00056277 rank 4
2023-02-11 18:09:40,932 DEBUG TRAIN Batch 9/3900 loss 19.471823 loss_att 20.590286 loss_ctc 24.485670 loss_rnnt 17.375948 hw_loss 0.225687 lr 0.00056258 rank 5
2023-02-11 18:09:40,954 DEBUG TRAIN Batch 9/3900 loss 11.062968 loss_att 13.432774 loss_ctc 21.010181 loss_rnnt 5.565555 hw_loss 0.693217 lr 0.00056260 rank 0
2023-02-11 18:10:56,893 DEBUG TRAIN Batch 9/4000 loss 19.663406 loss_att 22.049786 loss_ctc 26.348215 loss_rnnt 15.210535 hw_loss 0.578304 lr 0.00056259 rank 7
2023-02-11 18:10:56,903 DEBUG TRAIN Batch 9/4000 loss 15.781997 loss_att 17.368849 loss_ctc 26.835873 loss_rnnt 9.822441 hw_loss 0.781563 lr 0.00056217 rank 2
2023-02-11 18:10:56,904 DEBUG TRAIN Batch 9/4000 loss 20.352888 loss_att 22.012487 loss_ctc 26.763037 loss_rnnt 15.622962 hw_loss 0.664372 lr 0.00056241 rank 4
2023-02-11 18:10:56,904 DEBUG TRAIN Batch 9/4000 loss 10.857872 loss_att 13.298548 loss_ctc 15.733559 loss_rnnt 6.076892 hw_loss 0.683016 lr 0.00056222 rank 5
2023-02-11 18:10:56,906 DEBUG TRAIN Batch 9/4000 loss 26.905815 loss_att 30.679560 loss_ctc 37.826511 loss_rnnt 22.315865 hw_loss 0.446082 lr 0.00056224 rank 0
2023-02-11 18:10:56,907 DEBUG TRAIN Batch 9/4000 loss 19.884720 loss_att 20.251219 loss_ctc 26.898590 loss_rnnt 16.216980 hw_loss 0.498611 lr 0.00056220 rank 1
2023-02-11 18:10:56,907 DEBUG TRAIN Batch 9/4000 loss 15.006981 loss_att 16.571613 loss_ctc 17.433958 loss_rnnt 11.842910 hw_loss 0.473915 lr 0.00056245 rank 6
2023-02-11 18:10:56,909 DEBUG TRAIN Batch 9/4000 loss 20.537327 loss_att 30.318401 loss_ctc 40.020470 loss_rnnt 13.170906 hw_loss 0.527335 lr 0.00056251 rank 3
2023-02-11 18:12:13,195 DEBUG TRAIN Batch 9/4100 loss 19.590586 loss_att 20.612791 loss_ctc 31.544151 loss_rnnt 15.148060 hw_loss 0.495802 lr 0.00056189 rank 0
2023-02-11 18:12:13,195 DEBUG TRAIN Batch 9/4100 loss 14.525004 loss_att 16.673235 loss_ctc 21.446535 loss_rnnt 11.878158 hw_loss 0.242687 lr 0.00056216 rank 3
2023-02-11 18:12:13,196 DEBUG TRAIN Batch 9/4100 loss 18.152390 loss_att 21.503649 loss_ctc 28.426992 loss_rnnt 13.400589 hw_loss 0.508425 lr 0.00056223 rank 7
2023-02-11 18:12:13,198 DEBUG TRAIN Batch 9/4100 loss 16.892166 loss_att 18.988256 loss_ctc 27.369583 loss_rnnt 12.794609 hw_loss 0.427753 lr 0.00056182 rank 2
2023-02-11 18:12:13,199 DEBUG TRAIN Batch 9/4100 loss 31.403240 loss_att 35.074524 loss_ctc 46.684593 loss_rnnt 26.353910 hw_loss 0.427042 lr 0.00056187 rank 5
2023-02-11 18:12:13,199 DEBUG TRAIN Batch 9/4100 loss 13.334899 loss_att 14.285868 loss_ctc 22.753490 loss_rnnt 10.162718 hw_loss 0.323658 lr 0.00056206 rank 4
2023-02-11 18:12:13,202 DEBUG TRAIN Batch 9/4100 loss 10.502187 loss_att 14.044970 loss_ctc 18.085997 loss_rnnt 7.187147 hw_loss 0.299120 lr 0.00056185 rank 1
2023-02-11 18:12:13,204 DEBUG TRAIN Batch 9/4100 loss 14.162369 loss_att 20.313225 loss_ctc 22.744572 loss_rnnt 11.215965 hw_loss 0.107239 lr 0.00056210 rank 6
2023-02-11 18:13:29,021 DEBUG TRAIN Batch 9/4200 loss 25.678820 loss_att 28.170116 loss_ctc 34.594364 loss_rnnt 21.866955 hw_loss 0.398413 lr 0.00056153 rank 0
2023-02-11 18:13:29,024 DEBUG TRAIN Batch 9/4200 loss 17.014561 loss_att 17.787868 loss_ctc 29.724915 loss_rnnt 12.839526 hw_loss 0.436061 lr 0.00056180 rank 3
2023-02-11 18:13:29,025 DEBUG TRAIN Batch 9/4200 loss 15.036753 loss_att 20.714634 loss_ctc 27.747375 loss_rnnt 9.619694 hw_loss 0.485012 lr 0.00056170 rank 4
2023-02-11 18:13:29,026 DEBUG TRAIN Batch 9/4200 loss 21.162249 loss_att 22.523632 loss_ctc 31.210331 loss_rnnt 16.800549 hw_loss 0.515565 lr 0.00056149 rank 1
2023-02-11 18:13:29,026 DEBUG TRAIN Batch 9/4200 loss 13.304178 loss_att 14.279552 loss_ctc 16.801867 loss_rnnt 9.251934 hw_loss 0.635777 lr 0.00056188 rank 7
2023-02-11 18:13:29,030 DEBUG TRAIN Batch 9/4200 loss 22.329937 loss_att 25.671928 loss_ctc 35.474178 loss_rnnt 18.454382 hw_loss 0.272736 lr 0.00056146 rank 2
2023-02-11 18:13:29,030 DEBUG TRAIN Batch 9/4200 loss 25.624311 loss_att 27.333466 loss_ctc 39.249252 loss_rnnt 21.512257 hw_loss 0.366293 lr 0.00056151 rank 5
2023-02-11 18:13:29,072 DEBUG TRAIN Batch 9/4200 loss 20.894938 loss_att 22.326801 loss_ctc 30.277765 loss_rnnt 16.980408 hw_loss 0.445709 lr 0.00056174 rank 6
2023-02-11 18:14:47,341 DEBUG TRAIN Batch 9/4300 loss 8.441902 loss_att 11.225628 loss_ctc 12.251459 loss_rnnt 4.626273 hw_loss 0.515802 lr 0.00056139 rank 6
2023-02-11 18:14:47,341 DEBUG TRAIN Batch 9/4300 loss 19.032822 loss_att 18.260496 loss_ctc 27.520264 loss_rnnt 14.759600 hw_loss 0.618005 lr 0.00056116 rank 5
2023-02-11 18:14:47,341 DEBUG TRAIN Batch 9/4300 loss 16.632662 loss_att 16.763390 loss_ctc 17.661840 loss_rnnt 12.404157 hw_loss 0.762213 lr 0.00056118 rank 0
2023-02-11 18:14:47,342 DEBUG TRAIN Batch 9/4300 loss 17.513702 loss_att 16.787727 loss_ctc 22.113867 loss_rnnt 13.131072 hw_loss 0.733963 lr 0.00056152 rank 7
2023-02-11 18:14:47,343 DEBUG TRAIN Batch 9/4300 loss 11.608919 loss_att 14.336996 loss_ctc 17.723005 loss_rnnt 8.483108 hw_loss 0.330934 lr 0.00056145 rank 3
2023-02-11 18:14:47,346 DEBUG TRAIN Batch 9/4300 loss 20.309361 loss_att 22.521338 loss_ctc 30.840088 loss_rnnt 14.846891 hw_loss 0.677996 lr 0.00056135 rank 4
2023-02-11 18:14:47,346 DEBUG TRAIN Batch 9/4300 loss 17.444918 loss_att 18.072374 loss_ctc 24.100441 loss_rnnt 13.093523 hw_loss 0.625969 lr 0.00056114 rank 1
2023-02-11 18:14:47,390 DEBUG TRAIN Batch 9/4300 loss 23.645292 loss_att 23.993338 loss_ctc 38.873951 loss_rnnt 20.304508 hw_loss 0.232629 lr 0.00056111 rank 2
2023-02-11 18:16:04,252 DEBUG TRAIN Batch 9/4400 loss 16.779667 loss_att 14.387962 loss_ctc 19.297644 loss_rnnt 12.856918 hw_loss 0.762255 lr 0.00056109 rank 3
2023-02-11 18:16:04,254 DEBUG TRAIN Batch 9/4400 loss 18.705469 loss_att 17.919149 loss_ctc 29.078045 loss_rnnt 16.338150 hw_loss 0.214045 lr 0.00056104 rank 6
2023-02-11 18:16:04,256 DEBUG TRAIN Batch 9/4400 loss 9.367615 loss_att 6.603239 loss_ctc 8.269481 loss_rnnt 5.377387 hw_loss 0.879285 lr 0.00056080 rank 5
2023-02-11 18:16:04,259 DEBUG TRAIN Batch 9/4400 loss 30.114511 loss_att 30.802505 loss_ctc 47.018280 loss_rnnt 25.999702 hw_loss 0.323133 lr 0.00056099 rank 4
2023-02-11 18:16:04,259 DEBUG TRAIN Batch 9/4400 loss 20.938761 loss_att 26.101027 loss_ctc 36.230461 loss_rnnt 15.819259 hw_loss 0.384030 lr 0.00056117 rank 7
2023-02-11 18:16:04,259 DEBUG TRAIN Batch 9/4400 loss 14.291967 loss_att 10.513818 loss_ctc 14.619858 loss_rnnt 8.491489 hw_loss 1.221073 lr 0.00056076 rank 2
2023-02-11 18:16:04,260 DEBUG TRAIN Batch 9/4400 loss 20.306383 loss_att 20.869678 loss_ctc 28.228306 loss_rnnt 16.545908 hw_loss 0.485918 lr 0.00056083 rank 0
2023-02-11 18:16:04,267 DEBUG TRAIN Batch 9/4400 loss 15.860773 loss_att 16.563017 loss_ctc 19.220682 loss_rnnt 11.506945 hw_loss 0.706011 lr 0.00056079 rank 1
2023-02-11 18:17:20,311 DEBUG TRAIN Batch 9/4500 loss 17.808281 loss_att 23.980713 loss_ctc 31.650593 loss_rnnt 13.792788 hw_loss 0.175381 lr 0.00056081 rank 7
2023-02-11 18:17:20,311 DEBUG TRAIN Batch 9/4500 loss 13.259903 loss_att 14.218338 loss_ctc 22.678501 loss_rnnt 10.340113 hw_loss 0.276054 lr 0.00056047 rank 0
2023-02-11 18:17:20,312 DEBUG TRAIN Batch 9/4500 loss 14.102139 loss_att 16.083347 loss_ctc 24.131140 loss_rnnt 10.591460 hw_loss 0.333232 lr 0.00056074 rank 3
2023-02-11 18:17:20,315 DEBUG TRAIN Batch 9/4500 loss 16.887032 loss_att 18.684322 loss_ctc 23.110504 loss_rnnt 12.519501 hw_loss 0.595927 lr 0.00056043 rank 1
2023-02-11 18:17:20,317 DEBUG TRAIN Batch 9/4500 loss 14.977362 loss_att 14.594319 loss_ctc 18.207798 loss_rnnt 10.079992 hw_loss 0.851860 lr 0.00056068 rank 6
2023-02-11 18:17:20,319 DEBUG TRAIN Batch 9/4500 loss 11.632321 loss_att 13.076830 loss_ctc 14.441638 loss_rnnt 10.191407 hw_loss 0.145769 lr 0.00056045 rank 5
2023-02-11 18:17:20,320 DEBUG TRAIN Batch 9/4500 loss 9.909831 loss_att 10.319114 loss_ctc 11.147371 loss_rnnt 6.663976 hw_loss 0.562311 lr 0.00056064 rank 4
2023-02-11 18:17:20,366 DEBUG TRAIN Batch 9/4500 loss 9.255710 loss_att 12.001013 loss_ctc 15.409725 loss_rnnt 6.522975 hw_loss 0.255588 lr 0.00056041 rank 2
2023-02-11 18:18:39,447 DEBUG TRAIN Batch 9/4600 loss 19.109640 loss_att 20.606503 loss_ctc 31.484760 loss_rnnt 14.276855 hw_loss 0.540637 lr 0.00056039 rank 3
2023-02-11 18:18:39,451 DEBUG TRAIN Batch 9/4600 loss 17.665281 loss_att 22.107510 loss_ctc 23.504637 loss_rnnt 13.590794 hw_loss 0.451399 lr 0.00056046 rank 7
2023-02-11 18:18:39,450 DEBUG TRAIN Batch 9/4600 loss 13.104239 loss_att 15.678886 loss_ctc 22.238659 loss_rnnt 9.267857 hw_loss 0.394412 lr 0.00056012 rank 0
2023-02-11 18:18:39,451 DEBUG TRAIN Batch 9/4600 loss 23.722164 loss_att 27.954056 loss_ctc 41.987598 loss_rnnt 19.460224 hw_loss 0.183781 lr 0.00056010 rank 5
2023-02-11 18:18:39,453 DEBUG TRAIN Batch 9/4600 loss 12.631847 loss_att 15.554600 loss_ctc 17.756203 loss_rnnt 9.601851 hw_loss 0.330412 lr 0.00056005 rank 2
2023-02-11 18:18:39,460 DEBUG TRAIN Batch 9/4600 loss 20.783382 loss_att 22.069609 loss_ctc 32.929184 loss_rnnt 14.874496 hw_loss 0.756038 lr 0.00056033 rank 6
2023-02-11 18:18:39,503 DEBUG TRAIN Batch 9/4600 loss 18.854454 loss_att 20.406487 loss_ctc 32.923046 loss_rnnt 15.196803 hw_loss 0.275893 lr 0.00056029 rank 4
2023-02-11 18:18:39,511 DEBUG TRAIN Batch 9/4600 loss 13.206668 loss_att 20.294113 loss_ctc 19.295925 loss_rnnt 7.397590 hw_loss 0.671191 lr 0.00056008 rank 1
2023-02-11 18:19:56,034 DEBUG TRAIN Batch 9/4700 loss 13.462456 loss_att 13.310966 loss_ctc 18.949944 loss_rnnt 9.402453 hw_loss 0.629744 lr 0.00056004 rank 3
2023-02-11 18:19:56,034 DEBUG TRAIN Batch 9/4700 loss 9.164145 loss_att 15.277191 loss_ctc 17.790508 loss_rnnt 4.662958 hw_loss 0.399074 lr 0.00055977 rank 0
2023-02-11 18:19:56,036 DEBUG TRAIN Batch 9/4700 loss 21.471296 loss_att 21.968142 loss_ctc 27.881620 loss_rnnt 17.597500 hw_loss 0.547447 lr 0.00055994 rank 4
2023-02-11 18:19:56,037 DEBUG TRAIN Batch 9/4700 loss 10.683910 loss_att 10.913809 loss_ctc 13.993246 loss_rnnt 7.872040 hw_loss 0.435871 lr 0.00055998 rank 6
2023-02-11 18:19:56,040 DEBUG TRAIN Batch 9/4700 loss 9.356708 loss_att 13.557335 loss_ctc 16.232304 loss_rnnt 5.811340 hw_loss 0.335343 lr 0.00055975 rank 5
2023-02-11 18:19:56,040 DEBUG TRAIN Batch 9/4700 loss 29.390162 loss_att 36.032005 loss_ctc 49.949471 loss_rnnt 24.657213 hw_loss 0.124376 lr 0.00055970 rank 2
2023-02-11 18:19:56,041 DEBUG TRAIN Batch 9/4700 loss 19.151705 loss_att 23.430134 loss_ctc 30.279556 loss_rnnt 15.759587 hw_loss 0.197384 lr 0.00056011 rank 7
2023-02-11 18:19:56,042 DEBUG TRAIN Batch 9/4700 loss 14.927515 loss_att 15.409693 loss_ctc 17.695448 loss_rnnt 11.868532 hw_loss 0.486279 lr 0.00055973 rank 1
2023-02-11 18:21:12,069 DEBUG TRAIN Batch 9/4800 loss 19.384893 loss_att 23.195814 loss_ctc 31.660727 loss_rnnt 14.047960 hw_loss 0.550869 lr 0.00055938 rank 1
2023-02-11 18:21:12,069 DEBUG TRAIN Batch 9/4800 loss 6.906529 loss_att 8.975564 loss_ctc 12.264411 loss_rnnt 3.262861 hw_loss 0.471652 lr 0.00055976 rank 7
2023-02-11 18:21:12,069 DEBUG TRAIN Batch 9/4800 loss 11.896136 loss_att 11.313150 loss_ctc 13.294561 loss_rnnt 8.855211 hw_loss 0.557075 lr 0.00055969 rank 3
2023-02-11 18:21:12,073 DEBUG TRAIN Batch 9/4800 loss 11.203931 loss_att 11.856194 loss_ctc 18.524677 loss_rnnt 7.271692 hw_loss 0.529816 lr 0.00055935 rank 2
2023-02-11 18:21:12,073 DEBUG TRAIN Batch 9/4800 loss 16.159880 loss_att 18.609613 loss_ctc 22.133392 loss_rnnt 11.855544 hw_loss 0.565860 lr 0.00055940 rank 5
2023-02-11 18:21:12,074 DEBUG TRAIN Batch 9/4800 loss 16.618935 loss_att 18.135674 loss_ctc 23.597031 loss_rnnt 13.845250 hw_loss 0.288735 lr 0.00055942 rank 0
2023-02-11 18:21:12,074 DEBUG TRAIN Batch 9/4800 loss 10.279761 loss_att 10.038422 loss_ctc 12.893905 loss_rnnt 5.632307 hw_loss 0.815094 lr 0.00055959 rank 4
2023-02-11 18:21:12,121 DEBUG TRAIN Batch 9/4800 loss 8.175159 loss_att 11.705041 loss_ctc 14.658404 loss_rnnt 5.756906 hw_loss 0.158970 lr 0.00055963 rank 6
2023-02-11 18:22:28,826 DEBUG TRAIN Batch 9/4900 loss 12.012712 loss_att 14.110849 loss_ctc 15.731255 loss_rnnt 9.100526 hw_loss 0.374391 lr 0.00055903 rank 1
2023-02-11 18:22:28,827 DEBUG TRAIN Batch 9/4900 loss 20.324642 loss_att 23.045547 loss_ctc 39.714828 loss_rnnt 12.979202 hw_loss 0.790481 lr 0.00055934 rank 3
2023-02-11 18:22:28,833 DEBUG TRAIN Batch 9/4900 loss 21.681484 loss_att 19.522745 loss_ctc 31.046057 loss_rnnt 17.319456 hw_loss 0.664719 lr 0.00055941 rank 7
2023-02-11 18:22:28,834 DEBUG TRAIN Batch 9/4900 loss 15.464452 loss_att 16.041765 loss_ctc 23.405266 loss_rnnt 11.323783 hw_loss 0.556206 lr 0.00055928 rank 6
2023-02-11 18:22:28,838 DEBUG TRAIN Batch 9/4900 loss 9.938924 loss_att 10.108383 loss_ctc 15.402405 loss_rnnt 7.041458 hw_loss 0.400333 lr 0.00055905 rank 5
2023-02-11 18:22:28,839 DEBUG TRAIN Batch 9/4900 loss 18.565769 loss_att 19.729872 loss_ctc 28.651585 loss_rnnt 14.602657 hw_loss 0.447284 lr 0.00055924 rank 4
2023-02-11 18:22:28,844 DEBUG TRAIN Batch 9/4900 loss 14.770374 loss_att 16.921236 loss_ctc 25.997353 loss_rnnt 11.364645 hw_loss 0.277243 lr 0.00055907 rank 0
2023-02-11 18:22:28,886 DEBUG TRAIN Batch 9/4900 loss 15.444683 loss_att 14.881954 loss_ctc 16.563253 loss_rnnt 12.124495 hw_loss 0.615674 lr 0.00055900 rank 2
2023-02-11 18:23:48,394 DEBUG TRAIN Batch 9/5000 loss 17.839016 loss_att 15.430741 loss_ctc 16.969328 loss_rnnt 11.279167 hw_loss 1.342024 lr 0.00055899 rank 3
2023-02-11 18:23:48,397 DEBUG TRAIN Batch 9/5000 loss 16.070110 loss_att 11.607288 loss_ctc 16.766008 loss_rnnt 11.082999 hw_loss 1.085042 lr 0.00055870 rank 5
2023-02-11 18:23:48,400 DEBUG TRAIN Batch 9/5000 loss 20.361254 loss_att 23.382683 loss_ctc 33.141541 loss_rnnt 16.759113 hw_loss 0.242590 lr 0.00055868 rank 1
2023-02-11 18:23:48,401 DEBUG TRAIN Batch 9/5000 loss 11.064000 loss_att 10.254824 loss_ctc 14.265419 loss_rnnt 7.858068 hw_loss 0.551421 lr 0.00055906 rank 7
2023-02-11 18:23:48,403 DEBUG TRAIN Batch 9/5000 loss 16.583401 loss_att 13.340403 loss_ctc 17.286261 loss_rnnt 10.946611 hw_loss 1.160939 lr 0.00055893 rank 6
2023-02-11 18:23:48,405 DEBUG TRAIN Batch 9/5000 loss 12.725206 loss_att 12.077504 loss_ctc 17.045277 loss_rnnt 10.389641 hw_loss 0.354206 lr 0.00055889 rank 4
2023-02-11 18:23:48,406 DEBUG TRAIN Batch 9/5000 loss 21.555544 loss_att 22.900608 loss_ctc 28.620256 loss_rnnt 17.011749 hw_loss 0.624904 lr 0.00055872 rank 0
2023-02-11 18:23:48,454 DEBUG TRAIN Batch 9/5000 loss 15.788242 loss_att 14.166022 loss_ctc 19.915495 loss_rnnt 10.372893 hw_loss 0.973030 lr 0.00055865 rank 2
2023-02-11 18:25:02,511 DEBUG TRAIN Batch 9/5100 loss 20.961811 loss_att 21.520786 loss_ctc 31.832809 loss_rnnt 17.616169 hw_loss 0.334571 lr 0.00055833 rank 1
2023-02-11 18:25:02,512 DEBUG TRAIN Batch 9/5100 loss 14.717027 loss_att 16.367760 loss_ctc 27.663532 loss_rnnt 11.627589 hw_loss 0.193704 lr 0.00055864 rank 3
2023-02-11 18:25:02,513 DEBUG TRAIN Batch 9/5100 loss 11.955116 loss_att 13.404149 loss_ctc 18.381809 loss_rnnt 7.697164 hw_loss 0.583360 lr 0.00055854 rank 4
2023-02-11 18:25:02,518 DEBUG TRAIN Batch 9/5100 loss 14.584018 loss_att 19.565125 loss_ctc 20.452007 loss_rnnt 10.459021 hw_loss 0.439946 lr 0.00055871 rank 7
2023-02-11 18:25:02,519 DEBUG TRAIN Batch 9/5100 loss 17.388590 loss_att 19.901705 loss_ctc 24.673435 loss_rnnt 11.848808 hw_loss 0.762346 lr 0.00055837 rank 0
2023-02-11 18:25:02,521 DEBUG TRAIN Batch 9/5100 loss 7.030340 loss_att 9.990111 loss_ctc 13.024363 loss_rnnt 4.444510 hw_loss 0.224001 lr 0.00055831 rank 2
2023-02-11 18:25:02,520 DEBUG TRAIN Batch 9/5100 loss 18.981543 loss_att 22.589020 loss_ctc 25.887829 loss_rnnt 15.558876 hw_loss 0.333812 lr 0.00055858 rank 6
2023-02-11 18:25:02,521 DEBUG TRAIN Batch 9/5100 loss 23.055723 loss_att 25.497681 loss_ctc 33.306763 loss_rnnt 19.208477 hw_loss 0.373509 lr 0.00055835 rank 5
2023-02-11 18:26:18,398 DEBUG TRAIN Batch 9/5200 loss 9.906205 loss_att 9.846712 loss_ctc 15.141880 loss_rnnt 8.210289 hw_loss 0.189323 lr 0.00055802 rank 0
2023-02-11 18:26:18,399 DEBUG TRAIN Batch 9/5200 loss 13.830235 loss_att 14.055178 loss_ctc 20.515579 loss_rnnt 10.033412 hw_loss 0.536335 lr 0.00055829 rank 3
2023-02-11 18:26:18,400 DEBUG TRAIN Batch 9/5200 loss 15.592075 loss_att 11.506575 loss_ctc 15.507209 loss_rnnt 10.828534 hw_loss 1.048492 lr 0.00055819 rank 4
2023-02-11 18:26:18,405 DEBUG TRAIN Batch 9/5200 loss 8.139426 loss_att 8.413397 loss_ctc 8.122463 loss_rnnt 6.524711 hw_loss 0.292909 lr 0.00055836 rank 7
2023-02-11 18:26:18,405 DEBUG TRAIN Batch 9/5200 loss 25.766018 loss_att 28.690115 loss_ctc 43.586895 loss_rnnt 18.965069 hw_loss 0.720002 lr 0.00055800 rank 5
2023-02-11 18:26:18,423 DEBUG TRAIN Batch 9/5200 loss 10.222855 loss_att 14.045018 loss_ctc 14.088753 loss_rnnt 8.197445 hw_loss 0.139786 lr 0.00055796 rank 2
2023-02-11 18:26:18,430 DEBUG TRAIN Batch 9/5200 loss 10.727453 loss_att 8.909740 loss_ctc 10.871239 loss_rnnt 5.339890 hw_loss 1.074737 lr 0.00055799 rank 1
2023-02-11 18:26:18,447 DEBUG TRAIN Batch 9/5200 loss 8.942064 loss_att 11.659813 loss_ctc 9.250652 loss_rnnt 6.961806 hw_loss 0.261668 lr 0.00055823 rank 6
2023-02-11 18:27:36,056 DEBUG TRAIN Batch 9/5300 loss 21.230682 loss_att 21.141834 loss_ctc 28.666840 loss_rnnt 16.152140 hw_loss 0.769654 lr 0.00055794 rank 3
2023-02-11 18:27:36,057 DEBUG TRAIN Batch 9/5300 loss 12.906523 loss_att 15.254086 loss_ctc 19.840443 loss_rnnt 8.998366 hw_loss 0.471398 lr 0.00055801 rank 7
2023-02-11 18:27:36,057 DEBUG TRAIN Batch 9/5300 loss 7.953181 loss_att 12.524907 loss_ctc 17.381115 loss_rnnt 5.254157 hw_loss 0.098929 lr 0.00055764 rank 1
2023-02-11 18:27:36,059 DEBUG TRAIN Batch 9/5300 loss 17.596642 loss_att 19.596840 loss_ctc 24.836987 loss_rnnt 15.535444 hw_loss 0.130458 lr 0.00055761 rank 2
2023-02-11 18:27:36,061 DEBUG TRAIN Batch 9/5300 loss 12.087006 loss_att 14.408808 loss_ctc 20.369389 loss_rnnt 8.449617 hw_loss 0.387883 lr 0.00055766 rank 5
2023-02-11 18:27:36,061 DEBUG TRAIN Batch 9/5300 loss 15.318350 loss_att 17.076839 loss_ctc 26.559790 loss_rnnt 12.453417 hw_loss 0.190195 lr 0.00055768 rank 0
2023-02-11 18:27:36,066 DEBUG TRAIN Batch 9/5300 loss 9.827698 loss_att 7.973358 loss_ctc 9.452969 loss_rnnt 6.823308 hw_loss 0.642229 lr 0.00055784 rank 4
2023-02-11 18:27:36,101 DEBUG TRAIN Batch 9/5300 loss 14.355198 loss_att 15.098516 loss_ctc 22.707443 loss_rnnt 10.429811 hw_loss 0.499329 lr 0.00055788 rank 6
2023-02-11 18:28:54,003 DEBUG TRAIN Batch 9/5400 loss 22.005472 loss_att 23.241978 loss_ctc 28.647078 loss_rnnt 19.238058 hw_loss 0.306481 lr 0.00055754 rank 6
2023-02-11 18:28:54,005 DEBUG TRAIN Batch 9/5400 loss 13.708862 loss_att 13.975103 loss_ctc 17.847477 loss_rnnt 9.099669 hw_loss 0.750774 lr 0.00055759 rank 3
2023-02-11 18:28:54,005 DEBUG TRAIN Batch 9/5400 loss 9.230450 loss_att 13.458363 loss_ctc 20.340363 loss_rnnt 6.114519 hw_loss 0.147942 lr 0.00055729 rank 1
2023-02-11 18:28:54,006 DEBUG TRAIN Batch 9/5400 loss 26.129864 loss_att 33.026520 loss_ctc 36.343842 loss_rnnt 21.586021 hw_loss 0.337996 lr 0.00055733 rank 0
2023-02-11 18:28:54,008 DEBUG TRAIN Batch 9/5400 loss 12.972229 loss_att 11.703524 loss_ctc 12.679791 loss_rnnt 9.559706 hw_loss 0.694735 lr 0.00055767 rank 7
2023-02-11 18:28:54,010 DEBUG TRAIN Batch 9/5400 loss 16.076336 loss_att 15.845470 loss_ctc 25.323006 loss_rnnt 11.384113 hw_loss 0.657282 lr 0.00055726 rank 2
2023-02-11 18:28:54,011 DEBUG TRAIN Batch 9/5400 loss 8.579620 loss_att 12.649613 loss_ctc 10.955641 loss_rnnt 4.074093 hw_loss 0.632761 lr 0.00055731 rank 5
2023-02-11 18:28:54,011 DEBUG TRAIN Batch 9/5400 loss 17.791767 loss_att 19.290657 loss_ctc 33.413612 loss_rnnt 14.346969 hw_loss 0.199145 lr 0.00055750 rank 4
2023-02-11 18:30:10,431 DEBUG TRAIN Batch 9/5500 loss 10.539513 loss_att 11.945756 loss_ctc 17.452475 loss_rnnt 7.433639 hw_loss 0.356793 lr 0.00055732 rank 7
2023-02-11 18:30:10,434 DEBUG TRAIN Batch 9/5500 loss 11.102684 loss_att 13.999611 loss_ctc 18.449883 loss_rnnt 8.012361 hw_loss 0.287121 lr 0.00055719 rank 6
2023-02-11 18:30:10,439 DEBUG TRAIN Batch 9/5500 loss 12.580053 loss_att 16.675888 loss_ctc 15.823883 loss_rnnt 9.607023 hw_loss 0.322753 lr 0.00055725 rank 3
2023-02-11 18:30:10,442 DEBUG TRAIN Batch 9/5500 loss 10.534080 loss_att 14.596296 loss_ctc 18.064600 loss_rnnt 8.138361 hw_loss 0.108601 lr 0.00055692 rank 2
2023-02-11 18:30:10,444 DEBUG TRAIN Batch 9/5500 loss 23.086929 loss_att 30.776321 loss_ctc 34.602474 loss_rnnt 17.182583 hw_loss 0.530824 lr 0.00055715 rank 4
2023-02-11 18:30:10,471 DEBUG TRAIN Batch 9/5500 loss 17.315548 loss_att 21.882612 loss_ctc 26.296799 loss_rnnt 13.053812 hw_loss 0.403279 lr 0.00055698 rank 0
2023-02-11 18:30:10,480 DEBUG TRAIN Batch 9/5500 loss 14.851090 loss_att 16.379776 loss_ctc 21.390903 loss_rnnt 9.067212 hw_loss 0.863656 lr 0.00055696 rank 5
2023-02-11 18:30:10,483 DEBUG TRAIN Batch 9/5500 loss 22.780777 loss_att 25.980745 loss_ctc 33.246017 loss_rnnt 20.103666 hw_loss 0.120328 lr 0.00055695 rank 1
2023-02-11 18:31:25,551 DEBUG TRAIN Batch 9/5600 loss 17.347605 loss_att 21.176250 loss_ctc 27.074007 loss_rnnt 11.209217 hw_loss 0.764213 lr 0.00055660 rank 1
2023-02-11 18:31:25,556 DEBUG TRAIN Batch 9/5600 loss 17.666550 loss_att 19.737068 loss_ctc 21.062366 loss_rnnt 13.092112 hw_loss 0.695167 lr 0.00055664 rank 0
2023-02-11 18:31:25,557 DEBUG TRAIN Batch 9/5600 loss 9.554690 loss_att 9.246388 loss_ctc 11.331720 loss_rnnt 6.435894 hw_loss 0.551910 lr 0.00055697 rank 7
2023-02-11 18:31:25,559 DEBUG TRAIN Batch 9/5600 loss 14.187790 loss_att 18.654211 loss_ctc 24.079853 loss_rnnt 11.200830 hw_loss 0.145262 lr 0.00055680 rank 4
2023-02-11 18:31:25,559 DEBUG TRAIN Batch 9/5600 loss 7.924310 loss_att 10.397478 loss_ctc 11.018412 loss_rnnt 4.510162 hw_loss 0.470056 lr 0.00055690 rank 3
2023-02-11 18:31:25,561 DEBUG TRAIN Batch 9/5600 loss 21.810148 loss_att 20.537313 loss_ctc 26.351255 loss_rnnt 18.404291 hw_loss 0.572801 lr 0.00055685 rank 6
2023-02-11 18:31:25,565 DEBUG TRAIN Batch 9/5600 loss 14.831206 loss_att 16.530985 loss_ctc 22.015415 loss_rnnt 10.467265 hw_loss 0.574892 lr 0.00055657 rank 2
2023-02-11 18:31:25,566 DEBUG TRAIN Batch 9/5600 loss 14.203943 loss_att 10.100828 loss_ctc 15.335106 loss_rnnt 8.804916 hw_loss 1.137905 lr 0.00055662 rank 5
2023-02-11 18:32:44,865 DEBUG TRAIN Batch 9/5700 loss 13.442557 loss_att 10.019596 loss_ctc 14.352105 loss_rnnt 8.967414 hw_loss 0.944712 lr 0.00055623 rank 2
2023-02-11 18:32:44,867 DEBUG TRAIN Batch 9/5700 loss 20.356567 loss_att 19.598936 loss_ctc 28.710133 loss_rnnt 17.357903 hw_loss 0.381822 lr 0.00055629 rank 0
2023-02-11 18:32:44,867 DEBUG TRAIN Batch 9/5700 loss 15.552252 loss_att 18.443537 loss_ctc 24.067360 loss_rnnt 12.181540 hw_loss 0.310707 lr 0.00055627 rank 5
2023-02-11 18:32:44,868 DEBUG TRAIN Batch 9/5700 loss 16.321905 loss_att 20.558943 loss_ctc 23.992893 loss_rnnt 13.981030 hw_loss 0.088251 lr 0.00055626 rank 1
2023-02-11 18:32:44,869 DEBUG TRAIN Batch 9/5700 loss 12.876119 loss_att 16.152924 loss_ctc 17.619774 loss_rnnt 9.534122 hw_loss 0.385153 lr 0.00055646 rank 4
2023-02-11 18:32:44,870 DEBUG TRAIN Batch 9/5700 loss 10.606236 loss_att 11.995453 loss_ctc 19.282681 loss_rnnt 7.811646 hw_loss 0.254979 lr 0.00055656 rank 3
2023-02-11 18:32:44,871 DEBUG TRAIN Batch 9/5700 loss 18.959343 loss_att 23.051502 loss_ctc 30.697716 loss_rnnt 14.633236 hw_loss 0.364230 lr 0.00055663 rank 7
2023-02-11 18:32:44,919 DEBUG TRAIN Batch 9/5700 loss 17.841921 loss_att 15.576778 loss_ctc 25.606527 loss_rnnt 13.305264 hw_loss 0.741451 lr 0.00055650 rank 6
2023-02-11 18:34:01,318 DEBUG TRAIN Batch 9/5800 loss 10.296001 loss_att 10.638391 loss_ctc 13.700919 loss_rnnt 6.800000 hw_loss 0.557537 lr 0.00055595 rank 0
2023-02-11 18:34:01,323 DEBUG TRAIN Batch 9/5800 loss 7.413668 loss_att 10.917746 loss_ctc 11.442462 loss_rnnt 4.295114 hw_loss 0.352606 lr 0.00055593 rank 5
2023-02-11 18:34:01,323 DEBUG TRAIN Batch 9/5800 loss 15.877950 loss_att 16.172009 loss_ctc 26.141277 loss_rnnt 13.353905 hw_loss 0.205648 lr 0.00055621 rank 3
2023-02-11 18:34:01,324 DEBUG TRAIN Batch 9/5800 loss 17.420952 loss_att 19.498465 loss_ctc 19.292282 loss_rnnt 14.350447 hw_loss 0.451030 lr 0.00055628 rank 7
2023-02-11 18:34:01,324 DEBUG TRAIN Batch 9/5800 loss 15.787622 loss_att 22.435600 loss_ctc 29.791008 loss_rnnt 10.194400 hw_loss 0.449345 lr 0.00055616 rank 6
2023-02-11 18:34:01,325 DEBUG TRAIN Batch 9/5800 loss 22.056604 loss_att 25.535229 loss_ctc 31.524572 loss_rnnt 18.107311 hw_loss 0.373345 lr 0.00055589 rank 2
2023-02-11 18:34:01,326 DEBUG TRAIN Batch 9/5800 loss 10.229166 loss_att 8.393012 loss_ctc 10.983403 loss_rnnt 6.440153 hw_loss 0.760440 lr 0.00055612 rank 4
2023-02-11 18:34:01,329 DEBUG TRAIN Batch 9/5800 loss 20.764513 loss_att 20.890591 loss_ctc 23.674831 loss_rnnt 16.288687 hw_loss 0.761732 lr 0.00055591 rank 1
2023-02-11 18:35:16,611 DEBUG TRAIN Batch 9/5900 loss 11.789234 loss_att 12.955809 loss_ctc 15.906665 loss_rnnt 6.534069 hw_loss 0.838661 lr 0.00055587 rank 3
2023-02-11 18:35:16,616 DEBUG TRAIN Batch 9/5900 loss 13.694001 loss_att 14.475127 loss_ctc 15.354494 loss_rnnt 10.770990 hw_loss 0.477260 lr 0.00055559 rank 5
2023-02-11 18:35:16,617 DEBUG TRAIN Batch 9/5900 loss 22.241053 loss_att 23.987314 loss_ctc 33.327702 loss_rnnt 18.275253 hw_loss 0.400937 lr 0.00055594 rank 7
2023-02-11 18:35:16,617 DEBUG TRAIN Batch 9/5900 loss 14.549305 loss_att 14.929741 loss_ctc 17.568741 loss_rnnt 10.236929 hw_loss 0.718818 lr 0.00055561 rank 0
2023-02-11 18:35:16,618 DEBUG TRAIN Batch 9/5900 loss 10.297709 loss_att 16.868450 loss_ctc 16.016544 loss_rnnt 6.561525 hw_loss 0.311161 lr 0.00055581 rank 6
2023-02-11 18:35:16,618 DEBUG TRAIN Batch 9/5900 loss 16.932821 loss_att 18.700123 loss_ctc 20.960310 loss_rnnt 12.193251 hw_loss 0.721709 lr 0.00055554 rank 2
2023-02-11 18:35:16,619 DEBUG TRAIN Batch 9/5900 loss 10.734488 loss_att 13.764242 loss_ctc 18.341202 loss_rnnt 8.131260 hw_loss 0.184322 lr 0.00055577 rank 4
2023-02-11 18:35:16,622 DEBUG TRAIN Batch 9/5900 loss 15.587593 loss_att 17.095884 loss_ctc 28.798859 loss_rnnt 11.479686 hw_loss 0.383390 lr 0.00055557 rank 1
2023-02-11 18:36:33,599 DEBUG TRAIN Batch 9/6000 loss 7.474050 loss_att 7.470578 loss_ctc 10.104206 loss_rnnt 4.069725 hw_loss 0.572687 lr 0.00055526 rank 0
2023-02-11 18:36:33,600 DEBUG TRAIN Batch 9/6000 loss 16.044010 loss_att 16.757545 loss_ctc 20.588469 loss_rnnt 11.581846 hw_loss 0.696286 lr 0.00055547 rank 6
2023-02-11 18:36:33,602 DEBUG TRAIN Batch 9/6000 loss 14.662663 loss_att 15.065071 loss_ctc 23.503422 loss_rnnt 9.864750 hw_loss 0.663499 lr 0.00055543 rank 4
2023-02-11 18:36:33,602 DEBUG TRAIN Batch 9/6000 loss 13.535426 loss_att 13.819599 loss_ctc 22.851421 loss_rnnt 9.293999 hw_loss 0.551711 lr 0.00055524 rank 5
2023-02-11 18:36:33,603 DEBUG TRAIN Batch 9/6000 loss 6.006935 loss_att 7.650052 loss_ctc 6.147690 loss_rnnt 3.246007 hw_loss 0.452538 lr 0.00055523 rank 1
2023-02-11 18:36:33,613 DEBUG TRAIN Batch 9/6000 loss 11.619414 loss_att 13.388547 loss_ctc 14.098242 loss_rnnt 6.915080 hw_loss 0.753750 lr 0.00055552 rank 3
2023-02-11 18:36:33,614 DEBUG TRAIN Batch 9/6000 loss 21.382008 loss_att 24.054045 loss_ctc 29.815790 loss_rnnt 16.732929 hw_loss 0.560656 lr 0.00055520 rank 2
2023-02-11 18:36:33,924 DEBUG TRAIN Batch 9/6000 loss 19.696918 loss_att 26.349606 loss_ctc 26.524925 loss_rnnt 15.556156 hw_loss 0.356217 lr 0.00055560 rank 7
2023-02-11 18:37:52,048 DEBUG TRAIN Batch 9/6100 loss 17.904720 loss_att 20.883595 loss_ctc 33.906143 loss_rnnt 14.452295 hw_loss 0.135586 lr 0.00055525 rank 7
2023-02-11 18:37:52,050 DEBUG TRAIN Batch 9/6100 loss 14.183976 loss_att 16.063311 loss_ctc 17.588915 loss_rnnt 10.953526 hw_loss 0.450111 lr 0.00055513 rank 6
2023-02-11 18:37:52,051 DEBUG TRAIN Batch 9/6100 loss 18.403973 loss_att 18.209682 loss_ctc 26.831839 loss_rnnt 14.113170 hw_loss 0.601115 lr 0.00055509 rank 4
2023-02-11 18:37:52,053 DEBUG TRAIN Batch 9/6100 loss 19.274654 loss_att 20.264755 loss_ctc 28.608330 loss_rnnt 13.866440 hw_loss 0.743569 lr 0.00055490 rank 5
2023-02-11 18:37:52,055 DEBUG TRAIN Batch 9/6100 loss 11.647989 loss_att 12.106630 loss_ctc 16.541922 loss_rnnt 7.078685 hw_loss 0.717197 lr 0.00055488 rank 1
2023-02-11 18:37:52,056 DEBUG TRAIN Batch 9/6100 loss 7.541748 loss_att 9.821632 loss_ctc 15.922250 loss_rnnt 4.436942 hw_loss 0.287143 lr 0.00055486 rank 2
2023-02-11 18:37:52,055 DEBUG TRAIN Batch 9/6100 loss 13.421314 loss_att 16.158501 loss_ctc 20.766140 loss_rnnt 9.685259 hw_loss 0.414245 lr 0.00055518 rank 3
2023-02-11 18:37:52,056 DEBUG TRAIN Batch 9/6100 loss 19.121645 loss_att 25.686272 loss_ctc 30.990456 loss_rnnt 14.525926 hw_loss 0.318803 lr 0.00055492 rank 0
2023-02-11 18:39:07,547 DEBUG TRAIN Batch 9/6200 loss 8.615121 loss_att 9.839266 loss_ctc 15.568460 loss_rnnt 7.025125 hw_loss 0.078385 lr 0.00055484 rank 3
2023-02-11 18:39:07,552 DEBUG TRAIN Batch 9/6200 loss 17.722878 loss_att 21.639542 loss_ctc 26.401804 loss_rnnt 13.743574 hw_loss 0.382271 lr 0.00055454 rank 1
2023-02-11 18:39:07,556 DEBUG TRAIN Batch 9/6200 loss 20.558252 loss_att 20.229626 loss_ctc 27.986971 loss_rnnt 15.628298 hw_loss 0.750972 lr 0.00055491 rank 7
2023-02-11 18:39:07,557 DEBUG TRAIN Batch 9/6200 loss 11.889258 loss_att 15.267498 loss_ctc 18.882441 loss_rnnt 8.794538 hw_loss 0.278746 lr 0.00055479 rank 6
2023-02-11 18:39:07,557 DEBUG TRAIN Batch 9/6200 loss 12.334287 loss_att 12.578149 loss_ctc 13.323500 loss_rnnt 7.277559 hw_loss 0.914261 lr 0.00055458 rank 0
2023-02-11 18:39:07,559 DEBUG TRAIN Batch 9/6200 loss 11.624973 loss_att 14.903210 loss_ctc 22.250185 loss_rnnt 7.514049 hw_loss 0.382234 lr 0.00055452 rank 2
2023-02-11 18:39:07,559 DEBUG TRAIN Batch 9/6200 loss 14.478111 loss_att 13.146258 loss_ctc 18.054405 loss_rnnt 10.490074 hw_loss 0.708294 lr 0.00055456 rank 5
2023-02-11 18:39:07,559 DEBUG TRAIN Batch 9/6200 loss 9.930687 loss_att 13.427106 loss_ctc 12.356128 loss_rnnt 5.918206 hw_loss 0.560588 lr 0.00055474 rank 4
2023-02-11 18:40:24,931 DEBUG TRAIN Batch 9/6300 loss 13.895093 loss_att 15.237722 loss_ctc 24.716024 loss_rnnt 10.448898 hw_loss 0.325289 lr 0.00055450 rank 3
2023-02-11 18:40:24,931 DEBUG TRAIN Batch 9/6300 loss 12.812546 loss_att 15.074985 loss_ctc 21.335468 loss_rnnt 10.145584 hw_loss 0.202141 lr 0.00055457 rank 7
2023-02-11 18:40:24,932 DEBUG TRAIN Batch 9/6300 loss 28.865509 loss_att 25.578865 loss_ctc 39.161224 loss_rnnt 23.216309 hw_loss 0.925081 lr 0.00055424 rank 0
2023-02-11 18:40:24,933 DEBUG TRAIN Batch 9/6300 loss 12.943967 loss_att 20.310812 loss_ctc 17.591820 loss_rnnt 8.489406 hw_loss 0.442777 lr 0.00055422 rank 5
2023-02-11 18:40:24,935 DEBUG TRAIN Batch 9/6300 loss 23.271553 loss_att 27.130671 loss_ctc 30.197914 loss_rnnt 19.008726 hw_loss 0.481405 lr 0.00055420 rank 1
2023-02-11 18:40:24,938 DEBUG TRAIN Batch 9/6300 loss 7.021404 loss_att 9.201512 loss_ctc 8.811754 loss_rnnt 4.634593 hw_loss 0.321014 lr 0.00055440 rank 4
2023-02-11 18:40:24,939 DEBUG TRAIN Batch 9/6300 loss 11.482014 loss_att 9.264263 loss_ctc 10.138383 loss_rnnt 6.702645 hw_loss 1.012888 lr 0.00055418 rank 2
2023-02-11 18:40:24,950 DEBUG TRAIN Batch 9/6300 loss 8.386401 loss_att 10.595234 loss_ctc 13.153546 loss_rnnt 6.326430 hw_loss 0.184235 lr 0.00055444 rank 6
2023-02-11 18:41:44,059 DEBUG TRAIN Batch 9/6400 loss 18.163000 loss_att 23.314518 loss_ctc 25.851456 loss_rnnt 14.115947 hw_loss 0.373429 lr 0.00055384 rank 2
2023-02-11 18:41:44,061 DEBUG TRAIN Batch 9/6400 loss 12.885922 loss_att 14.709137 loss_ctc 14.793776 loss_rnnt 9.199514 hw_loss 0.575135 lr 0.00055388 rank 5
2023-02-11 18:41:44,061 DEBUG TRAIN Batch 9/6400 loss 12.124146 loss_att 18.287951 loss_ctc 21.018608 loss_rnnt 8.814654 hw_loss 0.167026 lr 0.00055423 rank 7
2023-02-11 18:41:44,063 DEBUG TRAIN Batch 9/6400 loss 14.464949 loss_att 24.410069 loss_ctc 24.611004 loss_rnnt 10.168940 hw_loss 0.178908 lr 0.00055410 rank 6
2023-02-11 18:41:44,065 DEBUG TRAIN Batch 9/6400 loss 18.846226 loss_att 20.565212 loss_ctc 24.265099 loss_rnnt 15.366017 hw_loss 0.452605 lr 0.00055386 rank 1
2023-02-11 18:41:44,068 DEBUG TRAIN Batch 9/6400 loss 12.698066 loss_att 10.459508 loss_ctc 14.349714 loss_rnnt 7.231464 hw_loss 1.067643 lr 0.00055390 rank 0
2023-02-11 18:41:44,082 DEBUG TRAIN Batch 9/6400 loss 10.041200 loss_att 14.084249 loss_ctc 15.879287 loss_rnnt 8.075369 hw_loss 0.071026 lr 0.00055416 rank 3
2023-02-11 18:41:44,115 DEBUG TRAIN Batch 9/6400 loss 12.489737 loss_att 10.417640 loss_ctc 12.512610 loss_rnnt 7.432085 hw_loss 1.025442 lr 0.00055406 rank 4
2023-02-11 18:43:01,050 DEBUG TRAIN Batch 9/6500 loss 15.244210 loss_att 12.653002 loss_ctc 20.770390 loss_rnnt 10.454598 hw_loss 0.857068 lr 0.00055382 rank 3
2023-02-11 18:43:01,050 DEBUG TRAIN Batch 9/6500 loss 35.312424 loss_att 41.559425 loss_ctc 49.132870 loss_rnnt 30.261738 hw_loss 0.367230 lr 0.00055389 rank 7
2023-02-11 18:43:01,050 DEBUG TRAIN Batch 9/6500 loss 9.366844 loss_att 11.734062 loss_ctc 14.041744 loss_rnnt 6.026369 hw_loss 0.420696 lr 0.00055372 rank 4
2023-02-11 18:43:01,051 DEBUG TRAIN Batch 9/6500 loss 21.550823 loss_att 23.442141 loss_ctc 31.116327 loss_rnnt 15.839025 hw_loss 0.760900 lr 0.00055354 rank 5
2023-02-11 18:43:01,056 DEBUG TRAIN Batch 9/6500 loss 12.110867 loss_att 16.965984 loss_ctc 19.254156 loss_rnnt 8.840670 hw_loss 0.252513 lr 0.00055356 rank 0
2023-02-11 18:43:01,056 DEBUG TRAIN Batch 9/6500 loss 15.120216 loss_att 12.271409 loss_ctc 16.383511 loss_rnnt 10.909476 hw_loss 0.864762 lr 0.00055352 rank 1
2023-02-11 18:43:01,057 DEBUG TRAIN Batch 9/6500 loss 21.402058 loss_att 24.228336 loss_ctc 30.276457 loss_rnnt 18.340391 hw_loss 0.246217 lr 0.00055350 rank 2
2023-02-11 18:43:01,104 DEBUG TRAIN Batch 9/6500 loss 12.688691 loss_att 15.718176 loss_ctc 18.821486 loss_rnnt 10.892535 hw_loss 0.069854 lr 0.00055376 rank 6
2023-02-11 18:44:17,200 DEBUG TRAIN Batch 9/6600 loss 8.074808 loss_att 9.522448 loss_ctc 11.317629 loss_rnnt 3.898622 hw_loss 0.647678 lr 0.00055322 rank 0
2023-02-11 18:44:17,201 DEBUG TRAIN Batch 9/6600 loss 16.911377 loss_att 20.095255 loss_ctc 26.445517 loss_rnnt 11.524642 hw_loss 0.652264 lr 0.00055338 rank 4
2023-02-11 18:44:17,205 DEBUG TRAIN Batch 9/6600 loss 20.625095 loss_att 22.588310 loss_ctc 26.560585 loss_rnnt 16.520481 hw_loss 0.547607 lr 0.00055320 rank 5
2023-02-11 18:44:17,205 DEBUG TRAIN Batch 9/6600 loss 25.921654 loss_att 28.180084 loss_ctc 38.818253 loss_rnnt 21.305117 hw_loss 0.458495 lr 0.00055355 rank 7
2023-02-11 18:44:17,206 DEBUG TRAIN Batch 9/6600 loss 11.879344 loss_att 13.641529 loss_ctc 22.314026 loss_rnnt 9.671502 hw_loss 0.087021 lr 0.00055348 rank 3
2023-02-11 18:44:17,206 DEBUG TRAIN Batch 9/6600 loss 20.041155 loss_att 24.224277 loss_ctc 40.940746 loss_rnnt 13.322169 hw_loss 0.580453 lr 0.00055318 rank 1
2023-02-11 18:44:17,207 DEBUG TRAIN Batch 9/6600 loss 9.702044 loss_att 11.385913 loss_ctc 13.610761 loss_rnnt 7.179884 hw_loss 0.312042 lr 0.00055316 rank 2
2023-02-11 18:44:17,207 DEBUG TRAIN Batch 9/6600 loss 16.395908 loss_att 15.552265 loss_ctc 23.677252 loss_rnnt 12.582892 hw_loss 0.564544 lr 0.00055342 rank 6
2023-02-11 18:45:34,861 DEBUG TRAIN Batch 9/6700 loss 8.874692 loss_att 14.192947 loss_ctc 14.629856 loss_rnnt 5.905183 hw_loss 0.213469 lr 0.00055285 rank 1
2023-02-11 18:45:34,866 DEBUG TRAIN Batch 9/6700 loss 13.661037 loss_att 16.688730 loss_ctc 19.794600 loss_rnnt 11.646907 hw_loss 0.110772 lr 0.00055288 rank 0
2023-02-11 18:45:34,865 DEBUG TRAIN Batch 9/6700 loss 15.809229 loss_att 15.374022 loss_ctc 28.172804 loss_rnnt 9.298790 hw_loss 0.927938 lr 0.00055321 rank 7
2023-02-11 18:45:34,868 DEBUG TRAIN Batch 9/6700 loss 19.127283 loss_att 19.174252 loss_ctc 25.419310 loss_rnnt 16.273830 hw_loss 0.375960 lr 0.00055314 rank 3
2023-02-11 18:45:34,869 DEBUG TRAIN Batch 9/6700 loss 15.007682 loss_att 15.225824 loss_ctc 28.782673 loss_rnnt 11.227070 hw_loss 0.356310 lr 0.00055282 rank 2
2023-02-11 18:45:34,872 DEBUG TRAIN Batch 9/6700 loss 12.161733 loss_att 12.120967 loss_ctc 14.501330 loss_rnnt 9.744707 hw_loss 0.396231 lr 0.00055309 rank 6
2023-02-11 18:45:34,875 DEBUG TRAIN Batch 9/6700 loss 14.014224 loss_att 14.502262 loss_ctc 15.885349 loss_rnnt 11.683242 hw_loss 0.371980 lr 0.00055286 rank 5
2023-02-11 18:45:34,879 DEBUG TRAIN Batch 9/6700 loss 12.875903 loss_att 15.302932 loss_ctc 23.228821 loss_rnnt 8.594908 hw_loss 0.452850 lr 0.00055305 rank 4
2023-02-11 18:46:52,374 DEBUG TRAIN Batch 9/6800 loss 12.102495 loss_att 12.494558 loss_ctc 18.423164 loss_rnnt 7.979655 hw_loss 0.600313 lr 0.00055280 rank 3
2023-02-11 18:46:52,378 DEBUG TRAIN Batch 9/6800 loss 12.793150 loss_att 15.106649 loss_ctc 19.815426 loss_rnnt 9.652196 hw_loss 0.326616 lr 0.00055287 rank 7
2023-02-11 18:46:52,382 DEBUG TRAIN Batch 9/6800 loss 17.992172 loss_att 19.368101 loss_ctc 23.863926 loss_rnnt 14.038778 hw_loss 0.542870 lr 0.00055271 rank 4
2023-02-11 18:46:52,384 DEBUG TRAIN Batch 9/6800 loss 9.191417 loss_att 13.374855 loss_ctc 19.639339 loss_rnnt 5.700634 hw_loss 0.236445 lr 0.00055275 rank 6
2023-02-11 18:46:52,385 DEBUG TRAIN Batch 9/6800 loss 9.021510 loss_att 7.542146 loss_ctc 9.515537 loss_rnnt 5.543731 hw_loss 0.695209 lr 0.00055251 rank 1
2023-02-11 18:46:52,385 DEBUG TRAIN Batch 9/6800 loss 13.444089 loss_att 18.062349 loss_ctc 23.877842 loss_rnnt 10.320073 hw_loss 0.151724 lr 0.00055255 rank 0
2023-02-11 18:46:52,392 DEBUG TRAIN Batch 9/6800 loss 10.224613 loss_att 9.095199 loss_ctc 10.671576 loss_rnnt 6.659649 hw_loss 0.699610 lr 0.00055252 rank 5
2023-02-11 18:46:52,393 DEBUG TRAIN Batch 9/6800 loss 17.302090 loss_att 17.150028 loss_ctc 20.071623 loss_rnnt 13.069636 hw_loss 0.730049 lr 0.00055248 rank 2
2023-02-11 18:48:07,194 DEBUG TRAIN Batch 9/6900 loss 40.658615 loss_att 41.496696 loss_ctc 45.661602 loss_rnnt 36.285301 hw_loss 0.663493 lr 0.00055237 rank 4
2023-02-11 18:48:07,195 DEBUG TRAIN Batch 9/6900 loss 11.067950 loss_att 12.694139 loss_ctc 17.070469 loss_rnnt 8.609484 hw_loss 0.249917 lr 0.00055246 rank 3
2023-02-11 18:48:07,200 DEBUG TRAIN Batch 9/6900 loss 11.794214 loss_att 13.720942 loss_ctc 16.080135 loss_rnnt 8.695736 hw_loss 0.401564 lr 0.00055254 rank 7
2023-02-11 18:48:07,202 DEBUG TRAIN Batch 9/6900 loss 20.797045 loss_att 20.512161 loss_ctc 28.975029 loss_rnnt 17.770641 hw_loss 0.373685 lr 0.00055221 rank 0
2023-02-11 18:48:07,202 DEBUG TRAIN Batch 9/6900 loss 8.150010 loss_att 7.776211 loss_ctc 8.938338 loss_rnnt 5.359542 hw_loss 0.517522 lr 0.00055241 rank 6
2023-02-11 18:48:07,205 DEBUG TRAIN Batch 9/6900 loss 19.215105 loss_att 20.996220 loss_ctc 31.854916 loss_rnnt 14.358879 hw_loss 0.527755 lr 0.00055217 rank 1
2023-02-11 18:48:07,206 DEBUG TRAIN Batch 9/6900 loss 11.136250 loss_att 11.527268 loss_ctc 15.866371 loss_rnnt 7.327479 hw_loss 0.581228 lr 0.00055214 rank 2
2023-02-11 18:48:07,208 DEBUG TRAIN Batch 9/6900 loss 16.557892 loss_att 19.772869 loss_ctc 29.381287 loss_rnnt 11.462558 hw_loss 0.514229 lr 0.00055219 rank 5
2023-02-11 18:49:22,105 DEBUG TRAIN Batch 9/7000 loss 19.690353 loss_att 23.788948 loss_ctc 35.621105 loss_rnnt 16.200457 hw_loss 0.102389 lr 0.00055220 rank 7
2023-02-11 18:49:22,114 DEBUG TRAIN Batch 9/7000 loss 13.682194 loss_att 13.866798 loss_ctc 16.947857 loss_rnnt 9.122377 hw_loss 0.766401 lr 0.00055187 rank 0
2023-02-11 18:49:22,114 DEBUG TRAIN Batch 9/7000 loss 15.458830 loss_att 18.260294 loss_ctc 27.856201 loss_rnnt 11.497120 hw_loss 0.327831 lr 0.00055185 rank 5
2023-02-11 18:49:22,115 DEBUG TRAIN Batch 9/7000 loss 13.308012 loss_att 13.468775 loss_ctc 17.242809 loss_rnnt 10.502395 hw_loss 0.421655 lr 0.00055213 rank 3
2023-02-11 18:49:22,115 DEBUG TRAIN Batch 9/7000 loss 16.393625 loss_att 17.185266 loss_ctc 26.883350 loss_rnnt 12.625360 hw_loss 0.414620 lr 0.00055207 rank 6
2023-02-11 18:49:22,119 DEBUG TRAIN Batch 9/7000 loss 20.125488 loss_att 19.719418 loss_ctc 21.842239 loss_rnnt 16.863770 hw_loss 0.583881 lr 0.00055183 rank 1
2023-02-11 18:49:22,123 DEBUG TRAIN Batch 9/7000 loss 12.089152 loss_att 11.907984 loss_ctc 16.485821 loss_rnnt 8.468877 hw_loss 0.575679 lr 0.00055203 rank 4
2023-02-11 18:49:22,123 DEBUG TRAIN Batch 9/7000 loss 20.635576 loss_att 23.129995 loss_ctc 35.993233 loss_rnnt 16.322496 hw_loss 0.331220 lr 0.00055181 rank 2
2023-02-11 18:50:40,972 DEBUG TRAIN Batch 9/7100 loss 12.188150 loss_att 15.394430 loss_ctc 19.809025 loss_rnnt 7.296615 hw_loss 0.606406 lr 0.00055179 rank 3
2023-02-11 18:50:40,973 DEBUG TRAIN Batch 9/7100 loss 12.548010 loss_att 16.257946 loss_ctc 19.220757 loss_rnnt 7.724544 hw_loss 0.598459 lr 0.00055174 rank 6
2023-02-11 18:50:40,973 DEBUG TRAIN Batch 9/7100 loss 13.912072 loss_att 17.897594 loss_ctc 22.726233 loss_rnnt 8.567051 hw_loss 0.632380 lr 0.00055186 rank 7
2023-02-11 18:50:40,974 DEBUG TRAIN Batch 9/7100 loss 11.650259 loss_att 12.585636 loss_ctc 18.199501 loss_rnnt 8.882223 hw_loss 0.320199 lr 0.00055152 rank 5
2023-02-11 18:50:40,977 DEBUG TRAIN Batch 9/7100 loss 20.305817 loss_att 24.122421 loss_ctc 38.335621 loss_rnnt 14.970469 hw_loss 0.406510 lr 0.00055170 rank 4
2023-02-11 18:50:40,977 DEBUG TRAIN Batch 9/7100 loss 10.675584 loss_att 13.965136 loss_ctc 18.904564 loss_rnnt 7.804426 hw_loss 0.209259 lr 0.00055154 rank 0
2023-02-11 18:50:40,980 DEBUG TRAIN Batch 9/7100 loss 23.235088 loss_att 22.174301 loss_ctc 34.931961 loss_rnnt 19.181221 hw_loss 0.507458 lr 0.00055150 rank 1
2023-02-11 18:50:40,983 DEBUG TRAIN Batch 9/7100 loss 20.617556 loss_att 22.588085 loss_ctc 30.211531 loss_rnnt 17.995054 hw_loss 0.177975 lr 0.00055147 rank 2
2023-02-11 18:51:57,395 DEBUG TRAIN Batch 9/7200 loss 10.687614 loss_att 13.911527 loss_ctc 17.945339 loss_rnnt 7.530317 hw_loss 0.289654 lr 0.00055146 rank 3
2023-02-11 18:51:57,399 DEBUG TRAIN Batch 9/7200 loss 13.843804 loss_att 14.803240 loss_ctc 17.743435 loss_rnnt 9.861095 hw_loss 0.613288 lr 0.00055118 rank 5
2023-02-11 18:51:57,400 DEBUG TRAIN Batch 9/7200 loss 22.375641 loss_att 24.355381 loss_ctc 34.320740 loss_rnnt 18.580729 hw_loss 0.338678 lr 0.00055116 rank 1
2023-02-11 18:51:57,400 DEBUG TRAIN Batch 9/7200 loss 20.762249 loss_att 21.244390 loss_ctc 30.307465 loss_rnnt 17.199926 hw_loss 0.411225 lr 0.00055114 rank 2
2023-02-11 18:51:57,400 DEBUG TRAIN Batch 9/7200 loss 12.151129 loss_att 20.691730 loss_ctc 22.130064 loss_rnnt 8.567060 hw_loss 0.102267 lr 0.00055120 rank 0
2023-02-11 18:51:57,401 DEBUG TRAIN Batch 9/7200 loss 13.935392 loss_att 21.274534 loss_ctc 27.348248 loss_rnnt 8.802487 hw_loss 0.351880 lr 0.00055153 rank 7
2023-02-11 18:51:57,402 DEBUG TRAIN Batch 9/7200 loss 26.588793 loss_att 37.002789 loss_ctc 50.685356 loss_rnnt 18.089905 hw_loss 0.600603 lr 0.00055136 rank 4
2023-02-11 18:51:57,403 DEBUG TRAIN Batch 9/7200 loss 12.837324 loss_att 16.764742 loss_ctc 17.222492 loss_rnnt 7.353156 hw_loss 0.771374 lr 0.00055140 rank 6
2023-02-11 18:53:13,383 DEBUG TRAIN Batch 9/7300 loss 17.386364 loss_att 17.041176 loss_ctc 22.921881 loss_rnnt 11.334427 hw_loss 1.009295 lr 0.00055107 rank 6
2023-02-11 18:53:13,385 DEBUG TRAIN Batch 9/7300 loss 21.303640 loss_att 19.314993 loss_ctc 25.989124 loss_rnnt 18.470278 hw_loss 0.488692 lr 0.00055103 rank 4
2023-02-11 18:53:13,387 DEBUG TRAIN Batch 9/7300 loss 22.478313 loss_att 21.928820 loss_ctc 31.597467 loss_rnnt 18.497324 hw_loss 0.539062 lr 0.00055119 rank 7
2023-02-11 18:53:13,387 DEBUG TRAIN Batch 9/7300 loss 15.232356 loss_att 18.236629 loss_ctc 25.102074 loss_rnnt 10.793009 hw_loss 0.472974 lr 0.00055080 rank 2
2023-02-11 18:53:13,388 DEBUG TRAIN Batch 9/7300 loss 23.044710 loss_att 24.659416 loss_ctc 29.008667 loss_rnnt 17.487217 hw_loss 0.832380 lr 0.00055083 rank 1
2023-02-11 18:53:13,389 DEBUG TRAIN Batch 9/7300 loss 7.050728 loss_att 9.272684 loss_ctc 6.151678 loss_rnnt 3.166558 hw_loss 0.667435 lr 0.00055087 rank 0
2023-02-11 18:53:13,389 DEBUG TRAIN Batch 9/7300 loss 8.742173 loss_att 9.426894 loss_ctc 12.077135 loss_rnnt 6.408540 hw_loss 0.328505 lr 0.00055112 rank 3
2023-02-11 18:53:13,393 DEBUG TRAIN Batch 9/7300 loss 12.803448 loss_att 13.236620 loss_ctc 16.585112 loss_rnnt 10.528737 hw_loss 0.315723 lr 0.00055085 rank 5
2023-02-11 18:54:30,235 DEBUG TRAIN Batch 9/7400 loss 13.869337 loss_att 15.827424 loss_ctc 17.623665 loss_rnnt 9.502341 hw_loss 0.651525 lr 0.00055053 rank 0
2023-02-11 18:54:30,235 DEBUG TRAIN Batch 9/7400 loss 13.202024 loss_att 14.327965 loss_ctc 21.032478 loss_rnnt 10.314926 hw_loss 0.303347 lr 0.00055079 rank 3
2023-02-11 18:54:30,239 DEBUG TRAIN Batch 9/7400 loss 11.441438 loss_att 12.110008 loss_ctc 16.413965 loss_rnnt 8.226690 hw_loss 0.453381 lr 0.00055086 rank 7
2023-02-11 18:54:30,239 DEBUG TRAIN Batch 9/7400 loss 5.874209 loss_att 8.505494 loss_ctc 9.780659 loss_rnnt 3.972195 hw_loss 0.160293 lr 0.00055050 rank 1
2023-02-11 18:54:30,243 DEBUG TRAIN Batch 9/7400 loss 8.613985 loss_att 8.242352 loss_ctc 10.056479 loss_rnnt 4.332409 hw_loss 0.780669 lr 0.00055051 rank 5
2023-02-11 18:54:30,243 DEBUG TRAIN Batch 9/7400 loss 13.541099 loss_att 16.436781 loss_ctc 23.412411 loss_rnnt 9.461558 hw_loss 0.409543 lr 0.00055069 rank 4
2023-02-11 18:54:30,245 DEBUG TRAIN Batch 9/7400 loss 8.035645 loss_att 10.476572 loss_ctc 14.135565 loss_rnnt 3.911686 hw_loss 0.529209 lr 0.00055073 rank 6
2023-02-11 18:54:30,287 DEBUG TRAIN Batch 9/7400 loss 11.586856 loss_att 14.192789 loss_ctc 21.394344 loss_rnnt 7.847566 hw_loss 0.358207 lr 0.00055047 rank 2
2023-02-11 18:55:49,184 DEBUG TRAIN Batch 9/7500 loss 29.848867 loss_att 29.532856 loss_ctc 44.298061 loss_rnnt 27.237368 hw_loss 0.140277 lr 0.00055020 rank 0
2023-02-11 18:55:49,190 DEBUG TRAIN Batch 9/7500 loss 17.531637 loss_att 17.375618 loss_ctc 21.692152 loss_rnnt 14.406159 hw_loss 0.487865 lr 0.00055045 rank 3
2023-02-11 18:55:49,194 DEBUG TRAIN Batch 9/7500 loss 15.305153 loss_att 13.108359 loss_ctc 17.212561 loss_rnnt 10.899462 hw_loss 0.860761 lr 0.00055018 rank 5
2023-02-11 18:55:49,194 DEBUG TRAIN Batch 9/7500 loss 13.926794 loss_att 13.120541 loss_ctc 18.390570 loss_rnnt 10.836606 hw_loss 0.498050 lr 0.00055014 rank 2
2023-02-11 18:55:49,195 DEBUG TRAIN Batch 9/7500 loss 22.035843 loss_att 25.067904 loss_ctc 37.937088 loss_rnnt 17.469437 hw_loss 0.344968 lr 0.00055016 rank 1
2023-02-11 18:55:49,195 DEBUG TRAIN Batch 9/7500 loss 13.107953 loss_att 16.431652 loss_ctc 17.708557 loss_rnnt 9.772971 hw_loss 0.385655 lr 0.00055036 rank 4
2023-02-11 18:55:49,197 DEBUG TRAIN Batch 9/7500 loss 14.322926 loss_att 15.272831 loss_ctc 27.697096 loss_rnnt 10.826609 hw_loss 0.285583 lr 0.00055040 rank 6
2023-02-11 18:55:49,198 DEBUG TRAIN Batch 9/7500 loss 14.019613 loss_att 7.488968 loss_ctc 10.498944 loss_rnnt 6.755334 hw_loss 1.694968 lr 0.00055052 rank 7
2023-02-11 18:57:05,932 DEBUG TRAIN Batch 9/7600 loss 10.363569 loss_att 15.457539 loss_ctc 17.030273 loss_rnnt 6.920990 hw_loss 0.287792 lr 0.00054980 rank 2
2023-02-11 18:57:05,936 DEBUG TRAIN Batch 9/7600 loss 11.171302 loss_att 13.886171 loss_ctc 17.103989 loss_rnnt 6.525672 hw_loss 0.620931 lr 0.00054987 rank 0
2023-02-11 18:57:05,940 DEBUG TRAIN Batch 9/7600 loss 8.752808 loss_att 12.543236 loss_ctc 14.619541 loss_rnnt 5.847816 hw_loss 0.255877 lr 0.00055019 rank 7
2023-02-11 18:57:05,941 DEBUG TRAIN Batch 9/7600 loss 13.937787 loss_att 13.718132 loss_ctc 14.992873 loss_rnnt 10.269992 hw_loss 0.669571 lr 0.00055007 rank 6
2023-02-11 18:57:05,942 DEBUG TRAIN Batch 9/7600 loss 10.057164 loss_att 13.992517 loss_ctc 17.281967 loss_rnnt 8.146712 hw_loss 0.030014 lr 0.00054985 rank 5
2023-02-11 18:57:05,943 DEBUG TRAIN Batch 9/7600 loss 15.569815 loss_att 14.325342 loss_ctc 22.597008 loss_rnnt 12.914272 hw_loss 0.368902 lr 0.00055012 rank 3
2023-02-11 18:57:05,947 DEBUG TRAIN Batch 9/7600 loss 20.682762 loss_att 25.651489 loss_ctc 25.219828 loss_rnnt 16.534945 hw_loss 0.477962 lr 0.00054983 rank 1
2023-02-11 18:57:05,986 DEBUG TRAIN Batch 9/7600 loss 14.793615 loss_att 15.329181 loss_ctc 18.448658 loss_rnnt 11.627863 hw_loss 0.482119 lr 0.00055003 rank 4
2023-02-11 18:58:23,404 DEBUG TRAIN Batch 9/7700 loss 12.808546 loss_att 11.826891 loss_ctc 14.462200 loss_rnnt 10.503112 hw_loss 0.427740 lr 0.00054979 rank 3
2023-02-11 18:58:23,407 DEBUG TRAIN Batch 9/7700 loss 7.040386 loss_att 8.173664 loss_ctc 10.832045 loss_rnnt 4.156748 hw_loss 0.403393 lr 0.00054951 rank 5
2023-02-11 18:58:23,411 DEBUG TRAIN Batch 9/7700 loss 18.897879 loss_att 24.296070 loss_ctc 34.281258 loss_rnnt 14.918985 hw_loss 0.159026 lr 0.00054950 rank 1
2023-02-11 18:58:23,412 DEBUG TRAIN Batch 9/7700 loss 10.237501 loss_att 10.545154 loss_ctc 11.947532 loss_rnnt 8.363523 hw_loss 0.297083 lr 0.00054969 rank 4
2023-02-11 18:58:23,412 DEBUG TRAIN Batch 9/7700 loss 12.587947 loss_att 13.937132 loss_ctc 23.980812 loss_rnnt 7.960776 hw_loss 0.532178 lr 0.00054953 rank 0
2023-02-11 18:58:23,413 DEBUG TRAIN Batch 9/7700 loss 21.952114 loss_att 25.114563 loss_ctc 34.808037 loss_rnnt 19.185888 hw_loss 0.078677 lr 0.00054986 rank 7
2023-02-11 18:58:23,417 DEBUG TRAIN Batch 9/7700 loss 21.250708 loss_att 20.861979 loss_ctc 29.585903 loss_rnnt 16.824696 hw_loss 0.636075 lr 0.00054947 rank 2
2023-02-11 18:58:23,463 DEBUG TRAIN Batch 9/7700 loss 13.823097 loss_att 12.883558 loss_ctc 20.916615 loss_rnnt 10.302035 hw_loss 0.518094 lr 0.00054973 rank 6
2023-02-11 18:59:42,235 DEBUG TRAIN Batch 9/7800 loss 10.785338 loss_att 12.736293 loss_ctc 13.873611 loss_rnnt 7.773185 hw_loss 0.414411 lr 0.00054945 rank 3
2023-02-11 18:59:42,237 DEBUG TRAIN Batch 9/7800 loss 14.171562 loss_att 12.881941 loss_ctc 19.842676 loss_rnnt 9.695794 hw_loss 0.745790 lr 0.00054917 rank 1
2023-02-11 18:59:42,238 DEBUG TRAIN Batch 9/7800 loss 12.670285 loss_att 12.148484 loss_ctc 15.340340 loss_rnnt 8.271526 hw_loss 0.777584 lr 0.00054952 rank 7
2023-02-11 18:59:42,239 DEBUG TRAIN Batch 9/7800 loss 14.910816 loss_att 18.140812 loss_ctc 18.082172 loss_rnnt 13.275591 hw_loss 0.106196 lr 0.00054920 rank 0
2023-02-11 18:59:42,240 DEBUG TRAIN Batch 9/7800 loss 12.478767 loss_att 15.145300 loss_ctc 20.729191 loss_rnnt 8.851063 hw_loss 0.373939 lr 0.00054936 rank 4
2023-02-11 18:59:42,241 DEBUG TRAIN Batch 9/7800 loss 14.142344 loss_att 14.438090 loss_ctc 22.305283 loss_rnnt 10.105163 hw_loss 0.541808 lr 0.00054940 rank 6
2023-02-11 18:59:42,244 DEBUG TRAIN Batch 9/7800 loss 10.925388 loss_att 10.190311 loss_ctc 14.448021 loss_rnnt 8.253306 hw_loss 0.440515 lr 0.00054914 rank 2
2023-02-11 18:59:42,247 DEBUG TRAIN Batch 9/7800 loss 11.611125 loss_att 14.897791 loss_ctc 16.311127 loss_rnnt 8.883307 hw_loss 0.270716 lr 0.00054918 rank 5
2023-02-11 19:00:59,368 DEBUG TRAIN Batch 9/7900 loss 21.568972 loss_att 24.479834 loss_ctc 34.687981 loss_rnnt 17.543833 hw_loss 0.317581 lr 0.00054887 rank 0
2023-02-11 19:00:59,370 DEBUG TRAIN Batch 9/7900 loss 19.652468 loss_att 24.624756 loss_ctc 26.321659 loss_rnnt 16.646629 hw_loss 0.210404 lr 0.00054907 rank 6
2023-02-11 19:00:59,371 DEBUG TRAIN Batch 9/7900 loss 7.141167 loss_att 8.810494 loss_ctc 11.089786 loss_rnnt 4.726427 hw_loss 0.291448 lr 0.00054912 rank 3
2023-02-11 19:00:59,372 DEBUG TRAIN Batch 9/7900 loss 7.550849 loss_att 10.041890 loss_ctc 14.585794 loss_rnnt 5.219746 hw_loss 0.167794 lr 0.00054919 rank 7
2023-02-11 19:00:59,377 DEBUG TRAIN Batch 9/7900 loss 16.740036 loss_att 21.336161 loss_ctc 28.028112 loss_rnnt 11.806606 hw_loss 0.470461 lr 0.00054881 rank 2
2023-02-11 19:00:59,377 DEBUG TRAIN Batch 9/7900 loss 13.556870 loss_att 16.203964 loss_ctc 19.368271 loss_rnnt 7.448341 hw_loss 0.900798 lr 0.00054883 rank 1
2023-02-11 19:00:59,378 DEBUG TRAIN Batch 9/7900 loss 18.314186 loss_att 21.942736 loss_ctc 30.440269 loss_rnnt 14.804300 hw_loss 0.218881 lr 0.00054885 rank 5
2023-02-11 19:00:59,422 DEBUG TRAIN Batch 9/7900 loss 8.841326 loss_att 11.189692 loss_ctc 12.534445 loss_rnnt 4.639843 hw_loss 0.607386 lr 0.00054903 rank 4
2023-02-11 19:02:15,638 DEBUG TRAIN Batch 9/8000 loss 11.557397 loss_att 15.902500 loss_ctc 19.083927 loss_rnnt 7.920407 hw_loss 0.330831 lr 0.00054850 rank 1
2023-02-11 19:02:15,638 DEBUG TRAIN Batch 9/8000 loss 11.646015 loss_att 12.874685 loss_ctc 18.529476 loss_rnnt 8.706219 hw_loss 0.333050 lr 0.00054852 rank 5
2023-02-11 19:02:15,638 DEBUG TRAIN Batch 9/8000 loss 25.338423 loss_att 21.669716 loss_ctc 33.154755 loss_rnnt 23.412128 hw_loss 0.303348 lr 0.00054886 rank 7
2023-02-11 19:02:15,640 DEBUG TRAIN Batch 9/8000 loss 16.474339 loss_att 17.816978 loss_ctc 27.112221 loss_rnnt 13.579330 hw_loss 0.226518 lr 0.00054879 rank 3
2023-02-11 19:02:15,644 DEBUG TRAIN Batch 9/8000 loss 15.620169 loss_att 17.475525 loss_ctc 25.436176 loss_rnnt 12.449598 hw_loss 0.279506 lr 0.00054848 rank 2
2023-02-11 19:02:15,644 DEBUG TRAIN Batch 9/8000 loss 9.144648 loss_att 14.253508 loss_ctc 19.530781 loss_rnnt 6.112319 hw_loss 0.117326 lr 0.00054854 rank 0
2023-02-11 19:02:15,655 DEBUG TRAIN Batch 9/8000 loss 20.681223 loss_att 26.388845 loss_ctc 35.777115 loss_rnnt 15.125831 hw_loss 0.450203 lr 0.00054870 rank 4
2023-02-11 19:02:15,686 DEBUG TRAIN Batch 9/8000 loss 16.469570 loss_att 20.734257 loss_ctc 23.459297 loss_rnnt 11.828192 hw_loss 0.535589 lr 0.00054874 rank 6
2023-02-11 19:03:32,436 DEBUG TRAIN Batch 9/8100 loss 9.986077 loss_att 11.513815 loss_ctc 17.145775 loss_rnnt 7.476295 hw_loss 0.234301 lr 0.00054841 rank 6
2023-02-11 19:03:32,440 DEBUG TRAIN Batch 9/8100 loss 13.972454 loss_att 10.796169 loss_ctc 18.529198 loss_rnnt 9.479268 hw_loss 0.847664 lr 0.00054853 rank 7
2023-02-11 19:03:32,440 DEBUG TRAIN Batch 9/8100 loss 13.214051 loss_att 19.995171 loss_ctc 23.808363 loss_rnnt 9.429988 hw_loss 0.190362 lr 0.00054846 rank 3
2023-02-11 19:03:32,440 DEBUG TRAIN Batch 9/8100 loss 11.268077 loss_att 14.690580 loss_ctc 18.872349 loss_rnnt 7.128939 hw_loss 0.457638 lr 0.00054821 rank 0
2023-02-11 19:03:32,441 DEBUG TRAIN Batch 9/8100 loss 22.046175 loss_att 21.136656 loss_ctc 30.737034 loss_rnnt 17.132559 hw_loss 0.738139 lr 0.00054815 rank 2
2023-02-11 19:03:32,442 DEBUG TRAIN Batch 9/8100 loss 11.651131 loss_att 12.847112 loss_ctc 20.036907 loss_rnnt 9.805464 hw_loss 0.091569 lr 0.00054837 rank 4
2023-02-11 19:03:32,442 DEBUG TRAIN Batch 9/8100 loss 18.145662 loss_att 20.923134 loss_ctc 29.098236 loss_rnnt 14.354944 hw_loss 0.332790 lr 0.00054819 rank 5
2023-02-11 19:03:32,496 DEBUG TRAIN Batch 9/8100 loss 17.727686 loss_att 19.118734 loss_ctc 27.859337 loss_rnnt 14.893362 hw_loss 0.225980 lr 0.00054817 rank 1
2023-02-11 19:04:48,949 DEBUG TRAIN Batch 9/8200 loss 33.755501 loss_att 31.349880 loss_ctc 45.782269 loss_rnnt 29.160263 hw_loss 0.651148 lr 0.00054788 rank 0
2023-02-11 19:04:48,951 DEBUG TRAIN Batch 9/8200 loss 9.866910 loss_att 11.317623 loss_ctc 14.740251 loss_rnnt 8.049768 hw_loss 0.164479 lr 0.00054785 rank 1
2023-02-11 19:04:48,955 DEBUG TRAIN Batch 9/8200 loss 23.517704 loss_att 20.576660 loss_ctc 31.785217 loss_rnnt 19.675135 hw_loss 0.624082 lr 0.00054813 rank 3
2023-02-11 19:04:48,956 DEBUG TRAIN Batch 9/8200 loss 9.397928 loss_att 13.873129 loss_ctc 15.552463 loss_rnnt 7.066925 hw_loss 0.115380 lr 0.00054820 rank 7
2023-02-11 19:04:48,956 DEBUG TRAIN Batch 9/8200 loss 20.439152 loss_att 22.742134 loss_ctc 29.549957 loss_rnnt 16.437145 hw_loss 0.436244 lr 0.00054808 rank 6
2023-02-11 19:04:48,958 DEBUG TRAIN Batch 9/8200 loss 17.633942 loss_att 11.645781 loss_ctc 16.264679 loss_rnnt 11.277113 hw_loss 1.450693 lr 0.00054786 rank 5
2023-02-11 19:04:48,959 DEBUG TRAIN Batch 9/8200 loss 17.860960 loss_att 25.199644 loss_ctc 34.698414 loss_rnnt 12.782389 hw_loss 0.256095 lr 0.00054782 rank 2
2023-02-11 19:04:48,960 DEBUG TRAIN Batch 9/8200 loss 9.904002 loss_att 11.966513 loss_ctc 15.893635 loss_rnnt 6.761059 hw_loss 0.362217 lr 0.00054804 rank 4
2023-02-11 19:06:03,840 DEBUG TRAIN Batch 9/8300 loss 21.239822 loss_att 20.928951 loss_ctc 22.835983 loss_rnnt 16.748358 hw_loss 0.813903 lr 0.00054753 rank 5
2023-02-11 19:06:03,842 DEBUG TRAIN Batch 9/8300 loss 10.808968 loss_att 7.096126 loss_ctc 8.163821 loss_rnnt 6.068505 hw_loss 1.094197 lr 0.00054755 rank 0
2023-02-11 19:06:03,843 DEBUG TRAIN Batch 9/8300 loss 16.474266 loss_att 19.269360 loss_ctc 19.122406 loss_rnnt 12.499496 hw_loss 0.574250 lr 0.00054787 rank 7
2023-02-11 19:06:03,844 DEBUG TRAIN Batch 9/8300 loss 8.102354 loss_att 12.736542 loss_ctc 18.179447 loss_rnnt 4.060064 hw_loss 0.332220 lr 0.00054752 rank 1
2023-02-11 19:06:03,844 DEBUG TRAIN Batch 9/8300 loss 12.407476 loss_att 9.981709 loss_ctc 14.034164 loss_rnnt 9.314829 hw_loss 0.630170 lr 0.00054780 rank 3
2023-02-11 19:06:03,845 DEBUG TRAIN Batch 9/8300 loss 17.084854 loss_att 18.770361 loss_ctc 29.742323 loss_rnnt 14.330981 hw_loss 0.136708 lr 0.00054771 rank 4
2023-02-11 19:06:03,848 DEBUG TRAIN Batch 9/8300 loss 22.113979 loss_att 24.508690 loss_ctc 30.799473 loss_rnnt 19.811012 hw_loss 0.124867 lr 0.00054775 rank 6
2023-02-11 19:06:03,851 DEBUG TRAIN Batch 9/8300 loss 20.138779 loss_att 22.015030 loss_ctc 33.829460 loss_rnnt 15.918667 hw_loss 0.378645 lr 0.00054749 rank 2
2023-02-11 19:07:07,016 DEBUG CV Batch 9/0 loss 7.393316 loss_att 2.445813 loss_ctc 3.617782 loss_rnnt 2.106653 hw_loss 1.271169 history loss 7.119489 rank 6
2023-02-11 19:07:07,017 DEBUG CV Batch 9/0 loss 7.393316 loss_att 2.445813 loss_ctc 3.617782 loss_rnnt 2.106653 hw_loss 1.271169 history loss 7.119489 rank 7
2023-02-11 19:07:07,018 DEBUG CV Batch 9/0 loss 7.393316 loss_att 2.445813 loss_ctc 3.617782 loss_rnnt 2.106653 hw_loss 1.271169 history loss 7.119490 rank 5
2023-02-11 19:07:07,020 DEBUG CV Batch 9/0 loss 7.393315 loss_att 2.445813 loss_ctc 3.617782 loss_rnnt 2.106653 hw_loss 1.271169 history loss 7.119489 rank 1
2023-02-11 19:07:07,023 DEBUG CV Batch 9/0 loss 7.393317 loss_att 2.445813 loss_ctc 3.617782 loss_rnnt 2.106653 hw_loss 1.271169 history loss 7.119490 rank 0
2023-02-11 19:07:07,023 DEBUG CV Batch 9/0 loss 7.393316 loss_att 2.445813 loss_ctc 3.617782 loss_rnnt 2.106653 hw_loss 1.271169 history loss 7.119490 rank 3
2023-02-11 19:07:07,032 DEBUG CV Batch 9/0 loss 7.393316 loss_att 2.445813 loss_ctc 3.617782 loss_rnnt 2.106653 hw_loss 1.271169 history loss 7.119490 rank 4
2023-02-11 19:07:07,039 DEBUG CV Batch 9/0 loss 7.393316 loss_att 2.445813 loss_ctc 3.617782 loss_rnnt 2.106653 hw_loss 1.271169 history loss 7.119490 rank 2
2023-02-11 19:07:18,135 DEBUG CV Batch 9/100 loss 10.923334 loss_att 8.587060 loss_ctc 13.983727 loss_rnnt 6.930139 hw_loss 0.759825 history loss 7.388958 rank 0
2023-02-11 19:07:18,162 DEBUG CV Batch 9/100 loss 10.923334 loss_att 8.587060 loss_ctc 13.983727 loss_rnnt 6.930139 hw_loss 0.759825 history loss 7.388958 rank 3
2023-02-11 19:07:18,193 DEBUG CV Batch 9/100 loss 10.923334 loss_att 8.587060 loss_ctc 13.983727 loss_rnnt 6.930139 hw_loss 0.759825 history loss 7.388958 rank 5
2023-02-11 19:07:18,264 DEBUG CV Batch 9/100 loss 10.923334 loss_att 8.587060 loss_ctc 13.983727 loss_rnnt 6.930139 hw_loss 0.759825 history loss 7.388958 rank 4
2023-02-11 19:07:18,269 DEBUG CV Batch 9/100 loss 10.923334 loss_att 8.587060 loss_ctc 13.983727 loss_rnnt 6.930139 hw_loss 0.759825 history loss 7.388958 rank 1
2023-02-11 19:07:18,317 DEBUG CV Batch 9/100 loss 10.923334 loss_att 8.587060 loss_ctc 13.983727 loss_rnnt 6.930139 hw_loss 0.759825 history loss 7.388958 rank 2
2023-02-11 19:07:18,326 DEBUG CV Batch 9/100 loss 10.923334 loss_att 8.587060 loss_ctc 13.983727 loss_rnnt 6.930139 hw_loss 0.759825 history loss 7.388958 rank 7
2023-02-11 19:07:18,599 DEBUG CV Batch 9/100 loss 10.923334 loss_att 8.587060 loss_ctc 13.983727 loss_rnnt 6.930139 hw_loss 0.759825 history loss 7.388958 rank 6
2023-02-11 19:07:31,841 DEBUG CV Batch 9/200 loss 12.964763 loss_att 18.970394 loss_ctc 14.377495 loss_rnnt 11.056540 hw_loss 0.097262 history loss 7.885447 rank 0
2023-02-11 19:07:31,978 DEBUG CV Batch 9/200 loss 12.964763 loss_att 18.970394 loss_ctc 14.377495 loss_rnnt 11.056540 hw_loss 0.097262 history loss 7.885447 rank 5
2023-02-11 19:07:31,984 DEBUG CV Batch 9/200 loss 12.964763 loss_att 18.970394 loss_ctc 14.377495 loss_rnnt 11.056540 hw_loss 0.097262 history loss 7.885447 rank 7
2023-02-11 19:07:32,023 DEBUG CV Batch 9/200 loss 12.964763 loss_att 18.970394 loss_ctc 14.377495 loss_rnnt 11.056540 hw_loss 0.097262 history loss 7.885447 rank 3
2023-02-11 19:07:32,056 DEBUG CV Batch 9/200 loss 12.964763 loss_att 18.970394 loss_ctc 14.377495 loss_rnnt 11.056540 hw_loss 0.097262 history loss 7.885447 rank 4
2023-02-11 19:07:32,294 DEBUG CV Batch 9/200 loss 12.964763 loss_att 18.970394 loss_ctc 14.377495 loss_rnnt 11.056540 hw_loss 0.097262 history loss 7.885447 rank 2
2023-02-11 19:07:32,661 DEBUG CV Batch 9/200 loss 12.964763 loss_att 18.970394 loss_ctc 14.377495 loss_rnnt 11.056540 hw_loss 0.097262 history loss 7.885447 rank 6
2023-02-11 19:07:32,912 DEBUG CV Batch 9/200 loss 12.964763 loss_att 18.970394 loss_ctc 14.377495 loss_rnnt 11.056540 hw_loss 0.097262 history loss 7.885447 rank 1
2023-02-11 19:07:43,879 DEBUG CV Batch 9/300 loss 6.919530 loss_att 5.579812 loss_ctc 7.516757 loss_rnnt 4.040272 hw_loss 0.575170 history loss 8.146446 rank 0
2023-02-11 19:07:44,029 DEBUG CV Batch 9/300 loss 6.919530 loss_att 5.579812 loss_ctc 7.516757 loss_rnnt 4.040272 hw_loss 0.575170 history loss 8.146446 rank 3
2023-02-11 19:07:44,035 DEBUG CV Batch 9/300 loss 6.919530 loss_att 5.579812 loss_ctc 7.516757 loss_rnnt 4.040272 hw_loss 0.575170 history loss 8.146446 rank 7
2023-02-11 19:07:44,111 DEBUG CV Batch 9/300 loss 6.919530 loss_att 5.579812 loss_ctc 7.516757 loss_rnnt 4.040272 hw_loss 0.575170 history loss 8.146446 rank 5
2023-02-11 19:07:44,181 DEBUG CV Batch 9/300 loss 6.919530 loss_att 5.579812 loss_ctc 7.516757 loss_rnnt 4.040272 hw_loss 0.575170 history loss 8.146446 rank 4
2023-02-11 19:07:44,424 DEBUG CV Batch 9/300 loss 6.919530 loss_att 5.579812 loss_ctc 7.516757 loss_rnnt 4.040272 hw_loss 0.575170 history loss 8.146446 rank 2
2023-02-11 19:07:44,745 DEBUG CV Batch 9/300 loss 6.919530 loss_att 5.579812 loss_ctc 7.516757 loss_rnnt 4.040272 hw_loss 0.575170 history loss 8.146446 rank 6
2023-02-11 19:07:45,023 DEBUG CV Batch 9/300 loss 6.919530 loss_att 5.579812 loss_ctc 7.516757 loss_rnnt 4.040272 hw_loss 0.575170 history loss 8.146446 rank 1
2023-02-11 19:07:55,821 DEBUG CV Batch 9/400 loss 22.800360 loss_att 80.432663 loss_ctc 16.423725 loss_rnnt 12.017315 hw_loss 0.020025 history loss 9.078867 rank 0
2023-02-11 19:07:55,987 DEBUG CV Batch 9/400 loss 22.800360 loss_att 80.432663 loss_ctc 16.423725 loss_rnnt 12.017315 hw_loss 0.020025 history loss 9.078867 rank 7
2023-02-11 19:07:56,021 DEBUG CV Batch 9/400 loss 22.800360 loss_att 80.432663 loss_ctc 16.423725 loss_rnnt 12.017315 hw_loss 0.020025 history loss 9.078867 rank 3
2023-02-11 19:07:56,136 DEBUG CV Batch 9/400 loss 22.800360 loss_att 80.432663 loss_ctc 16.423725 loss_rnnt 12.017315 hw_loss 0.020025 history loss 9.078867 rank 5
2023-02-11 19:07:56,207 DEBUG CV Batch 9/400 loss 22.800360 loss_att 80.432663 loss_ctc 16.423725 loss_rnnt 12.017315 hw_loss 0.020025 history loss 9.078868 rank 4
2023-02-11 19:07:56,435 DEBUG CV Batch 9/400 loss 22.800360 loss_att 80.432663 loss_ctc 16.423725 loss_rnnt 12.017315 hw_loss 0.020025 history loss 9.078867 rank 2
2023-02-11 19:07:56,670 DEBUG CV Batch 9/400 loss 22.800360 loss_att 80.432663 loss_ctc 16.423725 loss_rnnt 12.017315 hw_loss 0.020025 history loss 9.078867 rank 6
2023-02-11 19:07:57,026 DEBUG CV Batch 9/400 loss 22.800360 loss_att 80.432663 loss_ctc 16.423725 loss_rnnt 12.017315 hw_loss 0.020025 history loss 9.078867 rank 1
2023-02-11 19:08:06,210 DEBUG CV Batch 9/500 loss 5.599136 loss_att 5.908267 loss_ctc 6.147141 loss_rnnt 2.127438 hw_loss 0.625651 history loss 9.851873 rank 0
2023-02-11 19:08:06,386 DEBUG CV Batch 9/500 loss 5.599136 loss_att 5.908267 loss_ctc 6.147141 loss_rnnt 2.127438 hw_loss 0.625651 history loss 9.851873 rank 3
2023-02-11 19:08:06,455 DEBUG CV Batch 9/500 loss 5.599136 loss_att 5.908267 loss_ctc 6.147141 loss_rnnt 2.127438 hw_loss 0.625651 history loss 9.851873 rank 7
2023-02-11 19:08:06,572 DEBUG CV Batch 9/500 loss 5.599136 loss_att 5.908267 loss_ctc 6.147141 loss_rnnt 2.127438 hw_loss 0.625651 history loss 9.851873 rank 5
2023-02-11 19:08:06,695 DEBUG CV Batch 9/500 loss 5.599136 loss_att 5.908267 loss_ctc 6.147141 loss_rnnt 2.127438 hw_loss 0.625651 history loss 9.851873 rank 4
2023-02-11 19:08:06,960 DEBUG CV Batch 9/500 loss 5.599136 loss_att 5.908267 loss_ctc 6.147141 loss_rnnt 2.127438 hw_loss 0.625651 history loss 9.851873 rank 2
2023-02-11 19:08:07,204 DEBUG CV Batch 9/500 loss 5.599136 loss_att 5.908267 loss_ctc 6.147141 loss_rnnt 2.127438 hw_loss 0.625651 history loss 9.851873 rank 6
2023-02-11 19:08:07,493 DEBUG CV Batch 9/500 loss 5.599136 loss_att 5.908267 loss_ctc 6.147141 loss_rnnt 2.127438 hw_loss 0.625651 history loss 9.851873 rank 1
2023-02-11 19:08:18,246 DEBUG CV Batch 9/600 loss 10.225622 loss_att 7.507063 loss_ctc 11.506855 loss_rnnt 6.498943 hw_loss 0.768668 history loss 10.742310 rank 0
2023-02-11 19:08:18,402 DEBUG CV Batch 9/600 loss 10.225622 loss_att 7.507063 loss_ctc 11.506855 loss_rnnt 6.498943 hw_loss 0.768668 history loss 10.742310 rank 3
2023-02-11 19:08:18,462 DEBUG CV Batch 9/600 loss 10.225623 loss_att 7.507063 loss_ctc 11.506855 loss_rnnt 6.498943 hw_loss 0.768668 history loss 10.742310 rank 7
2023-02-11 19:08:18,634 DEBUG CV Batch 9/600 loss 10.225622 loss_att 7.507063 loss_ctc 11.506855 loss_rnnt 6.498943 hw_loss 0.768668 history loss 10.742310 rank 5
2023-02-11 19:08:19,063 DEBUG CV Batch 9/600 loss 10.225622 loss_att 7.507063 loss_ctc 11.506855 loss_rnnt 6.498943 hw_loss 0.768668 history loss 10.742310 rank 2
2023-02-11 19:08:19,065 DEBUG CV Batch 9/600 loss 10.225622 loss_att 7.507063 loss_ctc 11.506855 loss_rnnt 6.498943 hw_loss 0.768668 history loss 10.742310 rank 4
2023-02-11 19:08:19,583 DEBUG CV Batch 9/600 loss 10.225622 loss_att 7.507063 loss_ctc 11.506855 loss_rnnt 6.498943 hw_loss 0.768668 history loss 10.742310 rank 1
2023-02-11 19:08:19,948 DEBUG CV Batch 9/600 loss 10.225622 loss_att 7.507063 loss_ctc 11.506855 loss_rnnt 6.498943 hw_loss 0.768668 history loss 10.742310 rank 6
2023-02-11 19:08:29,520 DEBUG CV Batch 9/700 loss 17.947216 loss_att 50.677364 loss_ctc 28.307360 loss_rnnt 8.119612 hw_loss 0.356292 history loss 11.416151 rank 0
2023-02-11 19:08:29,669 DEBUG CV Batch 9/700 loss 17.947216 loss_att 50.677364 loss_ctc 28.307360 loss_rnnt 8.119612 hw_loss 0.356292 history loss 11.416151 rank 3
2023-02-11 19:08:29,718 DEBUG CV Batch 9/700 loss 17.947216 loss_att 50.677364 loss_ctc 28.307360 loss_rnnt 8.119612 hw_loss 0.356292 history loss 11.416151 rank 7
2023-02-11 19:08:30,029 DEBUG CV Batch 9/700 loss 17.947216 loss_att 50.677364 loss_ctc 28.307360 loss_rnnt 8.119612 hw_loss 0.356292 history loss 11.416151 rank 5
2023-02-11 19:08:30,646 DEBUG CV Batch 9/700 loss 17.947216 loss_att 50.677364 loss_ctc 28.307360 loss_rnnt 8.119612 hw_loss 0.356292 history loss 11.416151 rank 2
2023-02-11 19:08:30,950 DEBUG CV Batch 9/700 loss 17.947216 loss_att 50.677364 loss_ctc 28.307360 loss_rnnt 8.119612 hw_loss 0.356292 history loss 11.416151 rank 1
2023-02-11 19:08:31,466 DEBUG CV Batch 9/700 loss 17.947216 loss_att 50.677364 loss_ctc 28.307360 loss_rnnt 8.119612 hw_loss 0.356292 history loss 11.416151 rank 6
2023-02-11 19:08:31,808 DEBUG CV Batch 9/700 loss 17.947216 loss_att 50.677364 loss_ctc 28.307360 loss_rnnt 8.119612 hw_loss 0.356292 history loss 11.416151 rank 4
2023-02-11 19:08:40,930 DEBUG CV Batch 9/800 loss 13.360762 loss_att 10.941234 loss_ctc 19.124504 loss_rnnt 9.878849 hw_loss 0.599497 history loss 10.903502 rank 7
2023-02-11 19:08:41,222 DEBUG CV Batch 9/800 loss 13.360762 loss_att 10.941234 loss_ctc 19.124504 loss_rnnt 9.878849 hw_loss 0.599497 history loss 10.903502 rank 5
2023-02-11 19:08:41,304 DEBUG CV Batch 9/800 loss 13.360761 loss_att 10.941234 loss_ctc 19.124504 loss_rnnt 9.878849 hw_loss 0.599497 history loss 10.903502 rank 3
2023-02-11 19:08:41,384 DEBUG CV Batch 9/800 loss 13.360761 loss_att 10.941234 loss_ctc 19.124504 loss_rnnt 9.878849 hw_loss 0.599497 history loss 10.903502 rank 0
2023-02-11 19:08:42,548 DEBUG CV Batch 9/800 loss 13.360762 loss_att 10.941234 loss_ctc 19.124504 loss_rnnt 9.878849 hw_loss 0.599497 history loss 10.903502 rank 2
2023-02-11 19:08:42,549 DEBUG CV Batch 9/800 loss 13.360762 loss_att 10.941234 loss_ctc 19.124504 loss_rnnt 9.878849 hw_loss 0.599497 history loss 10.903502 rank 1
2023-02-11 19:08:43,506 DEBUG CV Batch 9/800 loss 13.360762 loss_att 10.941234 loss_ctc 19.124504 loss_rnnt 9.878849 hw_loss 0.599497 history loss 10.903502 rank 4
2023-02-11 19:08:44,045 DEBUG CV Batch 9/800 loss 13.360761 loss_att 10.941234 loss_ctc 19.124504 loss_rnnt 9.878849 hw_loss 0.599497 history loss 10.903502 rank 6
2023-02-11 19:08:54,404 DEBUG CV Batch 9/900 loss 12.367378 loss_att 18.323057 loss_ctc 24.533388 loss_rnnt 9.113281 hw_loss 0.082655 history loss 10.691393 rank 7
2023-02-11 19:08:54,738 DEBUG CV Batch 9/900 loss 12.367378 loss_att 18.323057 loss_ctc 24.533388 loss_rnnt 9.113281 hw_loss 0.082655 history loss 10.691393 rank 5
2023-02-11 19:08:55,010 DEBUG CV Batch 9/900 loss 12.367378 loss_att 18.323057 loss_ctc 24.533388 loss_rnnt 9.113281 hw_loss 0.082655 history loss 10.691393 rank 0
2023-02-11 19:08:55,129 DEBUG CV Batch 9/900 loss 12.367378 loss_att 18.323057 loss_ctc 24.533388 loss_rnnt 9.113281 hw_loss 0.082655 history loss 10.691393 rank 3
2023-02-11 19:08:56,278 DEBUG CV Batch 9/900 loss 12.367378 loss_att 18.323057 loss_ctc 24.533388 loss_rnnt 9.113281 hw_loss 0.082655 history loss 10.691393 rank 1
2023-02-11 19:08:56,369 DEBUG CV Batch 9/900 loss 12.367378 loss_att 18.323057 loss_ctc 24.533388 loss_rnnt 9.113281 hw_loss 0.082655 history loss 10.691393 rank 2
2023-02-11 19:08:57,242 DEBUG CV Batch 9/900 loss 12.367378 loss_att 18.323057 loss_ctc 24.533388 loss_rnnt 9.113281 hw_loss 0.082655 history loss 10.691393 rank 4
2023-02-11 19:08:58,157 DEBUG CV Batch 9/900 loss 12.367378 loss_att 18.323057 loss_ctc 24.533388 loss_rnnt 9.113281 hw_loss 0.082655 history loss 10.691393 rank 6
2023-02-11 19:09:06,642 DEBUG CV Batch 9/1000 loss 7.958959 loss_att 5.312234 loss_ctc 6.985880 loss_rnnt 4.283936 hw_loss 0.812646 history loss 10.470530 rank 7
2023-02-11 19:09:06,957 DEBUG CV Batch 9/1000 loss 7.958959 loss_att 5.312234 loss_ctc 6.985880 loss_rnnt 4.283936 hw_loss 0.812646 history loss 10.470530 rank 5
2023-02-11 19:09:07,153 DEBUG CV Batch 9/1000 loss 7.958959 loss_att 5.312234 loss_ctc 6.985880 loss_rnnt 4.283936 hw_loss 0.812646 history loss 10.470530 rank 0
2023-02-11 19:09:07,325 DEBUG CV Batch 9/1000 loss 7.958959 loss_att 5.312234 loss_ctc 6.985880 loss_rnnt 4.283936 hw_loss 0.812646 history loss 10.470530 rank 3
2023-02-11 19:09:08,465 DEBUG CV Batch 9/1000 loss 7.958959 loss_att 5.312234 loss_ctc 6.985880 loss_rnnt 4.283936 hw_loss 0.812646 history loss 10.470530 rank 1
2023-02-11 19:09:08,644 DEBUG CV Batch 9/1000 loss 7.958960 loss_att 5.312234 loss_ctc 6.985880 loss_rnnt 4.283936 hw_loss 0.812646 history loss 10.470530 rank 2
2023-02-11 19:09:09,442 DEBUG CV Batch 9/1000 loss 7.958959 loss_att 5.312234 loss_ctc 6.985880 loss_rnnt 4.283936 hw_loss 0.812646 history loss 10.470530 rank 4
2023-02-11 19:09:10,396 DEBUG CV Batch 9/1000 loss 7.958959 loss_att 5.312234 loss_ctc 6.985880 loss_rnnt 4.283936 hw_loss 0.812646 history loss 10.470530 rank 6
2023-02-11 19:09:18,578 DEBUG CV Batch 9/1100 loss 11.084004 loss_att 5.601286 loss_ctc 8.906778 loss_rnnt 5.090660 hw_loss 1.383785 history loss 10.442830 rank 7
2023-02-11 19:09:18,851 DEBUG CV Batch 9/1100 loss 11.084003 loss_att 5.601286 loss_ctc 8.906778 loss_rnnt 5.090660 hw_loss 1.383785 history loss 10.442830 rank 5
2023-02-11 19:09:19,007 DEBUG CV Batch 9/1100 loss 11.084003 loss_att 5.601286 loss_ctc 8.906778 loss_rnnt 5.090660 hw_loss 1.383785 history loss 10.442830 rank 0
2023-02-11 19:09:19,153 DEBUG CV Batch 9/1100 loss 11.084004 loss_att 5.601286 loss_ctc 8.906778 loss_rnnt 5.090660 hw_loss 1.383785 history loss 10.442830 rank 3
2023-02-11 19:09:20,731 DEBUG CV Batch 9/1100 loss 11.084004 loss_att 5.601286 loss_ctc 8.906778 loss_rnnt 5.090660 hw_loss 1.383785 history loss 10.442830 rank 2
2023-02-11 19:09:21,102 DEBUG CV Batch 9/1100 loss 11.084004 loss_att 5.601286 loss_ctc 8.906778 loss_rnnt 5.090660 hw_loss 1.383785 history loss 10.442830 rank 1
2023-02-11 19:09:21,381 DEBUG CV Batch 9/1100 loss 11.084003 loss_att 5.601286 loss_ctc 8.906778 loss_rnnt 5.090660 hw_loss 1.383785 history loss 10.442830 rank 4
2023-02-11 19:09:22,252 DEBUG CV Batch 9/1100 loss 11.084003 loss_att 5.601286 loss_ctc 8.906778 loss_rnnt 5.090660 hw_loss 1.383785 history loss 10.442830 rank 6
2023-02-11 19:09:29,015 DEBUG CV Batch 9/1200 loss 9.362381 loss_att 8.874768 loss_ctc 11.243258 loss_rnnt 6.696899 hw_loss 0.471041 history loss 10.788852 rank 7
2023-02-11 19:09:29,290 DEBUG CV Batch 9/1200 loss 9.362381 loss_att 8.874768 loss_ctc 11.243258 loss_rnnt 6.696899 hw_loss 0.471041 history loss 10.788852 rank 5
2023-02-11 19:09:29,352 DEBUG CV Batch 9/1200 loss 9.362381 loss_att 8.874768 loss_ctc 11.243258 loss_rnnt 6.696899 hw_loss 0.471041 history loss 10.788852 rank 0
2023-02-11 19:09:29,557 DEBUG CV Batch 9/1200 loss 9.362381 loss_att 8.874768 loss_ctc 11.243258 loss_rnnt 6.696899 hw_loss 0.471041 history loss 10.788852 rank 3
2023-02-11 19:09:31,499 DEBUG CV Batch 9/1200 loss 9.362381 loss_att 8.874768 loss_ctc 11.243258 loss_rnnt 6.696899 hw_loss 0.471041 history loss 10.788852 rank 1
2023-02-11 19:09:31,878 DEBUG CV Batch 9/1200 loss 9.362381 loss_att 8.874768 loss_ctc 11.243258 loss_rnnt 6.696899 hw_loss 0.471041 history loss 10.788852 rank 4
2023-02-11 19:09:32,596 DEBUG CV Batch 9/1200 loss 9.362381 loss_att 8.874768 loss_ctc 11.243258 loss_rnnt 6.696899 hw_loss 0.471041 history loss 10.788852 rank 2
2023-02-11 19:09:32,854 DEBUG CV Batch 9/1200 loss 9.362381 loss_att 8.874768 loss_ctc 11.243258 loss_rnnt 6.696899 hw_loss 0.471041 history loss 10.788852 rank 6
2023-02-11 19:09:40,900 DEBUG CV Batch 9/1300 loss 9.109022 loss_att 5.656677 loss_ctc 8.502104 loss_rnnt 4.808264 hw_loss 0.951028 history loss 11.037711 rank 7
2023-02-11 19:09:41,184 DEBUG CV Batch 9/1300 loss 9.109022 loss_att 5.656677 loss_ctc 8.502104 loss_rnnt 4.808264 hw_loss 0.951028 history loss 11.037711 rank 5
2023-02-11 19:09:41,185 DEBUG CV Batch 9/1300 loss 9.109022 loss_att 5.656677 loss_ctc 8.502104 loss_rnnt 4.808264 hw_loss 0.951028 history loss 11.037711 rank 0
2023-02-11 19:09:41,397 DEBUG CV Batch 9/1300 loss 9.109022 loss_att 5.656677 loss_ctc 8.502104 loss_rnnt 4.808264 hw_loss 0.951028 history loss 11.037711 rank 3
2023-02-11 19:09:43,389 DEBUG CV Batch 9/1300 loss 9.109022 loss_att 5.656677 loss_ctc 8.502104 loss_rnnt 4.808264 hw_loss 0.951028 history loss 11.037711 rank 1
2023-02-11 19:09:43,889 DEBUG CV Batch 9/1300 loss 9.109022 loss_att 5.656677 loss_ctc 8.502104 loss_rnnt 4.808264 hw_loss 0.951028 history loss 11.037711 rank 4
2023-02-11 19:09:44,615 DEBUG CV Batch 9/1300 loss 9.109022 loss_att 5.656677 loss_ctc 8.502104 loss_rnnt 4.808264 hw_loss 0.951028 history loss 11.037711 rank 2
2023-02-11 19:09:45,841 DEBUG CV Batch 9/1300 loss 9.109022 loss_att 5.656677 loss_ctc 8.502104 loss_rnnt 4.808264 hw_loss 0.951028 history loss 11.037711 rank 6
2023-02-11 19:09:52,074 DEBUG CV Batch 9/1400 loss 9.324695 loss_att 14.831518 loss_ctc 13.016104 loss_rnnt 7.275959 hw_loss 0.085347 history loss 11.374283 rank 7
2023-02-11 19:09:52,331 DEBUG CV Batch 9/1400 loss 9.324695 loss_att 14.831518 loss_ctc 13.016104 loss_rnnt 7.275959 hw_loss 0.085347 history loss 11.374283 rank 5
2023-02-11 19:09:52,350 DEBUG CV Batch 9/1400 loss 9.324695 loss_att 14.831518 loss_ctc 13.016104 loss_rnnt 7.275959 hw_loss 0.085347 history loss 11.374283 rank 0
2023-02-11 19:09:52,456 DEBUG CV Batch 9/1400 loss 9.324695 loss_att 14.831518 loss_ctc 13.016104 loss_rnnt 7.275959 hw_loss 0.085347 history loss 11.374283 rank 3
2023-02-11 19:09:54,467 DEBUG CV Batch 9/1400 loss 9.324695 loss_att 14.831518 loss_ctc 13.016104 loss_rnnt 7.275959 hw_loss 0.085347 history loss 11.374283 rank 1
2023-02-11 19:09:55,178 DEBUG CV Batch 9/1400 loss 9.324695 loss_att 14.831518 loss_ctc 13.016104 loss_rnnt 7.275959 hw_loss 0.085347 history loss 11.374283 rank 4
2023-02-11 19:09:55,784 DEBUG CV Batch 9/1400 loss 9.324695 loss_att 14.831518 loss_ctc 13.016104 loss_rnnt 7.275959 hw_loss 0.085347 history loss 11.374283 rank 2
2023-02-11 19:09:57,347 DEBUG CV Batch 9/1400 loss 9.324695 loss_att 14.831518 loss_ctc 13.016104 loss_rnnt 7.275959 hw_loss 0.085347 history loss 11.374283 rank 6
2023-02-11 19:10:03,514 DEBUG CV Batch 9/1500 loss 10.484481 loss_att 9.162708 loss_ctc 9.450977 loss_rnnt 8.590967 hw_loss 0.430438 history loss 11.219967 rank 7
2023-02-11 19:10:03,646 DEBUG CV Batch 9/1500 loss 10.484481 loss_att 9.162708 loss_ctc 9.450977 loss_rnnt 8.590967 hw_loss 0.430438 history loss 11.219967 rank 0
2023-02-11 19:10:03,823 DEBUG CV Batch 9/1500 loss 10.484482 loss_att 9.162708 loss_ctc 9.450977 loss_rnnt 8.590967 hw_loss 0.430438 history loss 11.219967 rank 3
2023-02-11 19:10:03,839 DEBUG CV Batch 9/1500 loss 10.484482 loss_att 9.162708 loss_ctc 9.450977 loss_rnnt 8.590967 hw_loss 0.430438 history loss 11.219967 rank 5
2023-02-11 19:10:06,276 DEBUG CV Batch 9/1500 loss 10.484482 loss_att 9.162708 loss_ctc 9.450977 loss_rnnt 8.590967 hw_loss 0.430438 history loss 11.219967 rank 1
2023-02-11 19:10:07,707 DEBUG CV Batch 9/1500 loss 10.484482 loss_att 9.162708 loss_ctc 9.450977 loss_rnnt 8.590967 hw_loss 0.430438 history loss 11.219967 rank 4
2023-02-11 19:10:07,926 DEBUG CV Batch 9/1500 loss 10.484482 loss_att 9.162708 loss_ctc 9.450977 loss_rnnt 8.590967 hw_loss 0.430438 history loss 11.219967 rank 2
2023-02-11 19:10:08,773 DEBUG CV Batch 9/1500 loss 10.484482 loss_att 9.162708 loss_ctc 9.450977 loss_rnnt 8.590967 hw_loss 0.430438 history loss 11.219967 rank 6
2023-02-11 19:10:16,636 DEBUG CV Batch 9/1600 loss 11.690001 loss_att 22.379288 loss_ctc 22.689692 loss_rnnt 7.986403 hw_loss 0.018584 history loss 11.126894 rank 7
2023-02-11 19:10:17,134 DEBUG CV Batch 9/1600 loss 11.690001 loss_att 22.379288 loss_ctc 22.689692 loss_rnnt 7.986403 hw_loss 0.018584 history loss 11.126894 rank 5
2023-02-11 19:10:17,217 DEBUG CV Batch 9/1600 loss 11.690001 loss_att 22.379288 loss_ctc 22.689692 loss_rnnt 7.986403 hw_loss 0.018584 history loss 11.126894 rank 0
2023-02-11 19:10:17,294 DEBUG CV Batch 9/1600 loss 11.690001 loss_att 22.379288 loss_ctc 22.689692 loss_rnnt 7.986403 hw_loss 0.018584 history loss 11.126894 rank 3
2023-02-11 19:10:20,054 DEBUG CV Batch 9/1600 loss 11.690001 loss_att 22.379288 loss_ctc 22.689692 loss_rnnt 7.986403 hw_loss 0.018584 history loss 11.126894 rank 1
2023-02-11 19:10:20,996 DEBUG CV Batch 9/1600 loss 11.690001 loss_att 22.379288 loss_ctc 22.689692 loss_rnnt 7.986403 hw_loss 0.018584 history loss 11.126894 rank 2
2023-02-11 19:10:21,242 DEBUG CV Batch 9/1600 loss 11.690001 loss_att 22.379288 loss_ctc 22.689692 loss_rnnt 7.986403 hw_loss 0.018584 history loss 11.126894 rank 4
2023-02-11 19:10:22,160 DEBUG CV Batch 9/1600 loss 11.690001 loss_att 22.379288 loss_ctc 22.689692 loss_rnnt 7.986403 hw_loss 0.018584 history loss 11.126894 rank 6
2023-02-11 19:10:29,114 DEBUG CV Batch 9/1700 loss 12.049055 loss_att 9.018169 loss_ctc 15.208874 loss_rnnt 7.840815 hw_loss 0.823708 history loss 11.064448 rank 7
2023-02-11 19:10:29,640 DEBUG CV Batch 9/1700 loss 12.049055 loss_att 9.018169 loss_ctc 15.208874 loss_rnnt 7.840815 hw_loss 0.823708 history loss 11.064448 rank 5
2023-02-11 19:10:29,678 DEBUG CV Batch 9/1700 loss 12.049055 loss_att 9.018169 loss_ctc 15.208874 loss_rnnt 7.840815 hw_loss 0.823708 history loss 11.064448 rank 0
2023-02-11 19:10:29,699 DEBUG CV Batch 9/1700 loss 12.049056 loss_att 9.018169 loss_ctc 15.208874 loss_rnnt 7.840815 hw_loss 0.823708 history loss 11.064448 rank 3
2023-02-11 19:10:32,463 DEBUG CV Batch 9/1700 loss 12.049056 loss_att 9.018169 loss_ctc 15.208874 loss_rnnt 7.840815 hw_loss 0.823708 history loss 11.064448 rank 1
2023-02-11 19:10:33,601 DEBUG CV Batch 9/1700 loss 12.049056 loss_att 9.018169 loss_ctc 15.208874 loss_rnnt 7.840815 hw_loss 0.823708 history loss 11.064448 rank 2
2023-02-11 19:10:34,287 DEBUG CV Batch 9/1700 loss 12.049056 loss_att 9.018169 loss_ctc 15.208874 loss_rnnt 7.840815 hw_loss 0.823708 history loss 11.064448 rank 4
2023-02-11 19:10:34,533 DEBUG CV Batch 9/1700 loss 12.049055 loss_att 9.018169 loss_ctc 15.208874 loss_rnnt 7.840815 hw_loss 0.823708 history loss 11.064448 rank 6
2023-02-11 19:10:38,307 INFO Epoch 9 CV info cv_loss 11.022035726854474
2023-02-11 19:10:38,309 INFO Epoch 10 TRAIN info lr 0.0005476218043616002
2023-02-11 19:10:38,312 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 19:10:38,755 INFO Epoch 9 CV info cv_loss 11.022035712709247
2023-02-11 19:10:38,756 INFO Epoch 10 TRAIN info lr 0.000547684220951432
2023-02-11 19:10:38,760 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 19:10:38,798 INFO Epoch 9 CV info cv_loss 11.022035700442009
2023-02-11 19:10:38,799 INFO Checkpoint: save to checkpoint exp2_10_rnnt_bias_loss/9.pt
2023-02-11 19:10:38,842 INFO Epoch 9 CV info cv_loss 11.022035727354123
2023-02-11 19:10:38,843 INFO Epoch 10 TRAIN info lr 0.0005473526720778872
2023-02-11 19:10:38,846 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 19:10:39,420 INFO Epoch 10 TRAIN info lr 0.0005474248393498837
2023-02-11 19:10:39,425 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 19:10:41,550 INFO Epoch 9 CV info cv_loss 11.02203572668218
2023-02-11 19:10:41,551 INFO Epoch 10 TRAIN info lr 0.000547497035174708
2023-02-11 19:10:41,555 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 19:10:42,621 INFO Epoch 9 CV info cv_loss 11.022035708953267
2023-02-11 19:10:42,622 INFO Epoch 10 TRAIN info lr 0.0005472739766870735
2023-02-11 19:10:42,625 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 19:10:43,357 INFO Epoch 9 CV info cv_loss 11.022035735262355
2023-02-11 19:10:43,358 INFO Epoch 10 TRAIN info lr 0.0005476053824896987
2023-02-11 19:10:43,360 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 19:10:43,618 INFO Epoch 9 CV info cv_loss 11.022035704559803
2023-02-11 19:10:43,619 INFO Epoch 10 TRAIN info lr 0.0005476579376808645
2023-02-11 19:10:43,622 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 19:11:55,878 DEBUG TRAIN Batch 10/0 loss 16.874285 loss_att 12.701937 loss_ctc 18.350124 loss_rnnt 12.680655 hw_loss 0.905873 lr 0.00054742 rank 0
2023-02-11 19:11:55,885 DEBUG TRAIN Batch 10/0 loss 15.039639 loss_att 12.228564 loss_ctc 15.860328 loss_rnnt 11.201596 hw_loss 0.804531 lr 0.00054735 rank 5
2023-02-11 19:11:55,887 DEBUG TRAIN Batch 10/0 loss 12.327967 loss_att 8.499446 loss_ctc 12.103945 loss_rnnt 7.631767 hw_loss 1.029708 lr 0.00054762 rank 7
2023-02-11 19:11:55,890 DEBUG TRAIN Batch 10/0 loss 12.222177 loss_att 9.561844 loss_ctc 15.072513 loss_rnnt 8.055711 hw_loss 0.809716 lr 0.00054749 rank 1
2023-02-11 19:11:55,907 DEBUG TRAIN Batch 10/0 loss 12.092361 loss_att 9.590719 loss_ctc 13.561135 loss_rnnt 8.819988 hw_loss 0.670662 lr 0.00054768 rank 3
2023-02-11 19:11:55,912 DEBUG TRAIN Batch 10/0 loss 12.137035 loss_att 8.603003 loss_ctc 12.207932 loss_rnnt 7.180883 hw_loss 1.060032 lr 0.00054765 rank 6
2023-02-11 19:11:55,918 DEBUG TRAIN Batch 10/0 loss 12.404852 loss_att 9.198416 loss_ctc 13.056372 loss_rnnt 8.903037 hw_loss 0.760543 lr 0.00054727 rank 2
2023-02-11 19:11:55,923 DEBUG TRAIN Batch 10/0 loss 12.963911 loss_att 10.647965 loss_ctc 13.994671 loss_rnnt 10.993081 hw_loss 0.430610 lr 0.00054760 rank 4
2023-02-11 19:13:12,582 DEBUG TRAIN Batch 10/100 loss 13.089528 loss_att 15.864298 loss_ctc 16.298161 loss_rnnt 10.468645 hw_loss 0.307146 lr 0.00054709 rank 0
2023-02-11 19:13:12,587 DEBUG TRAIN Batch 10/100 loss 6.560630 loss_att 9.143200 loss_ctc 10.651258 loss_rnnt 2.155411 hw_loss 0.626866 lr 0.00054733 rank 6
2023-02-11 19:13:12,591 DEBUG TRAIN Batch 10/100 loss 7.924396 loss_att 11.937979 loss_ctc 12.974236 loss_rnnt 5.986371 hw_loss 0.086624 lr 0.00054729 rank 7
2023-02-11 19:13:12,592 DEBUG TRAIN Batch 10/100 loss 15.847229 loss_att 16.720968 loss_ctc 19.790855 loss_rnnt 13.123668 hw_loss 0.379312 lr 0.00054727 rank 4
2023-02-11 19:13:12,594 DEBUG TRAIN Batch 10/100 loss 14.956246 loss_att 18.430126 loss_ctc 19.030890 loss_rnnt 11.090632 hw_loss 0.492666 lr 0.00054694 rank 2
2023-02-11 19:13:12,594 DEBUG TRAIN Batch 10/100 loss 8.787156 loss_att 13.656328 loss_ctc 17.597744 loss_rnnt 5.563768 hw_loss 0.201527 lr 0.00054702 rank 5
2023-02-11 19:13:12,596 DEBUG TRAIN Batch 10/100 loss 13.891310 loss_att 14.898365 loss_ctc 26.471457 loss_rnnt 8.673804 hw_loss 0.626014 lr 0.00054735 rank 3
2023-02-11 19:13:12,603 DEBUG TRAIN Batch 10/100 loss 11.461878 loss_att 13.422047 loss_ctc 18.215603 loss_rnnt 8.450571 hw_loss 0.322270 lr 0.00054717 rank 1
2023-02-11 19:14:27,952 DEBUG TRAIN Batch 10/200 loss 11.634001 loss_att 11.546436 loss_ctc 13.294018 loss_rnnt 8.739479 hw_loss 0.504506 lr 0.00054700 rank 6
2023-02-11 19:14:27,956 DEBUG TRAIN Batch 10/200 loss 8.713552 loss_att 11.589533 loss_ctc 14.242713 loss_rnnt 5.038092 hw_loss 0.443070 lr 0.00054677 rank 0
2023-02-11 19:14:27,957 DEBUG TRAIN Batch 10/200 loss 24.237108 loss_att 27.114674 loss_ctc 32.743176 loss_rnnt 18.450832 hw_loss 0.764366 lr 0.00054702 rank 3
2023-02-11 19:14:27,958 DEBUG TRAIN Batch 10/200 loss 20.710793 loss_att 25.975962 loss_ctc 39.477390 loss_rnnt 14.157130 hw_loss 0.562203 lr 0.00054669 rank 5
2023-02-11 19:14:27,958 DEBUG TRAIN Batch 10/200 loss 10.536955 loss_att 10.864610 loss_ctc 15.794744 loss_rnnt 7.423070 hw_loss 0.440122 lr 0.00054696 rank 7
2023-02-11 19:14:27,963 DEBUG TRAIN Batch 10/200 loss 17.573616 loss_att 18.286972 loss_ctc 22.020422 loss_rnnt 13.160262 hw_loss 0.689583 lr 0.00054695 rank 4
2023-02-11 19:14:27,962 DEBUG TRAIN Batch 10/200 loss 9.240122 loss_att 9.470336 loss_ctc 14.877827 loss_rnnt 6.534647 hw_loss 0.357701 lr 0.00054684 rank 1
2023-02-11 19:14:27,965 DEBUG TRAIN Batch 10/200 loss 16.928549 loss_att 21.265287 loss_ctc 24.024389 loss_rnnt 12.134703 hw_loss 0.558822 lr 0.00054662 rank 2
2023-02-11 19:15:44,203 DEBUG TRAIN Batch 10/300 loss 14.025037 loss_att 18.583456 loss_ctc 21.265665 loss_rnnt 9.635740 hw_loss 0.471037 lr 0.00054662 rank 4
2023-02-11 19:15:44,204 DEBUG TRAIN Batch 10/300 loss 12.851249 loss_att 16.039637 loss_ctc 22.788166 loss_rnnt 8.845161 hw_loss 0.383154 lr 0.00054644 rank 0
2023-02-11 19:15:44,207 DEBUG TRAIN Batch 10/300 loss 7.850597 loss_att 9.027468 loss_ctc 10.666021 loss_rnnt 4.388169 hw_loss 0.534687 lr 0.00054667 rank 6
2023-02-11 19:15:44,208 DEBUG TRAIN Batch 10/300 loss 12.152360 loss_att 13.363194 loss_ctc 19.400835 loss_rnnt 8.322744 hw_loss 0.491435 lr 0.00054670 rank 3
2023-02-11 19:15:44,208 DEBUG TRAIN Batch 10/300 loss 15.355473 loss_att 17.286478 loss_ctc 24.769871 loss_rnnt 10.982406 hw_loss 0.512177 lr 0.00054637 rank 5
2023-02-11 19:15:44,210 DEBUG TRAIN Batch 10/300 loss 33.662773 loss_att 35.467937 loss_ctc 42.591057 loss_rnnt 28.072834 hw_loss 0.757213 lr 0.00054664 rank 7
2023-02-11 19:15:44,211 DEBUG TRAIN Batch 10/300 loss 17.001469 loss_att 18.582579 loss_ctc 27.224979 loss_rnnt 11.794174 hw_loss 0.661488 lr 0.00054651 rank 1
2023-02-11 19:15:44,212 DEBUG TRAIN Batch 10/300 loss 25.874769 loss_att 28.964502 loss_ctc 37.522835 loss_rnnt 20.050724 hw_loss 0.684942 lr 0.00054629 rank 2
2023-02-11 19:17:01,854 DEBUG TRAIN Batch 10/400 loss 10.234756 loss_att 12.826500 loss_ctc 13.454840 loss_rnnt 7.902576 hw_loss 0.259591 lr 0.00054637 rank 3
2023-02-11 19:17:01,859 DEBUG TRAIN Batch 10/400 loss 13.000569 loss_att 13.588428 loss_ctc 18.645332 loss_rnnt 10.368884 hw_loss 0.330277 lr 0.00054596 rank 2
2023-02-11 19:17:01,860 DEBUG TRAIN Batch 10/400 loss 12.275183 loss_att 15.001751 loss_ctc 17.366394 loss_rnnt 7.039430 hw_loss 0.752177 lr 0.00054611 rank 0
2023-02-11 19:17:01,864 DEBUG TRAIN Batch 10/400 loss 12.906028 loss_att 14.145962 loss_ctc 17.259800 loss_rnnt 10.232396 hw_loss 0.345964 lr 0.00054629 rank 4
2023-02-11 19:17:01,863 DEBUG TRAIN Batch 10/400 loss 7.974848 loss_att 8.677994 loss_ctc 12.061834 loss_rnnt 5.361687 hw_loss 0.361425 lr 0.00054631 rank 7
2023-02-11 19:17:01,865 DEBUG TRAIN Batch 10/400 loss 13.965131 loss_att 16.462996 loss_ctc 24.475945 loss_rnnt 9.384504 hw_loss 0.502427 lr 0.00054619 rank 1
2023-02-11 19:17:01,866 DEBUG TRAIN Batch 10/400 loss 18.351707 loss_att 20.041384 loss_ctc 24.183907 loss_rnnt 14.965138 hw_loss 0.425814 lr 0.00054635 rank 6
2023-02-11 19:17:01,866 DEBUG TRAIN Batch 10/400 loss 13.130442 loss_att 15.671802 loss_ctc 18.458525 loss_rnnt 9.951983 hw_loss 0.367458 lr 0.00054604 rank 5
2023-02-11 19:18:16,189 DEBUG TRAIN Batch 10/500 loss 19.871885 loss_att 21.048065 loss_ctc 25.444204 loss_rnnt 16.173203 hw_loss 0.510089 lr 0.00054586 rank 1
2023-02-11 19:18:16,189 DEBUG TRAIN Batch 10/500 loss 20.417408 loss_att 20.475712 loss_ctc 27.073154 loss_rnnt 17.898020 hw_loss 0.303805 lr 0.00054572 rank 5
2023-02-11 19:18:16,190 DEBUG TRAIN Batch 10/500 loss 17.177711 loss_att 16.920746 loss_ctc 26.950638 loss_rnnt 13.143393 hw_loss 0.521748 lr 0.00054579 rank 0
2023-02-11 19:18:16,191 DEBUG TRAIN Batch 10/500 loss 8.669855 loss_att 12.785693 loss_ctc 12.912294 loss_rnnt 5.559585 hw_loss 0.322771 lr 0.00054605 rank 3
2023-02-11 19:18:16,193 DEBUG TRAIN Batch 10/500 loss 12.785291 loss_att 14.996246 loss_ctc 16.186338 loss_rnnt 9.550899 hw_loss 0.438511 lr 0.00054598 rank 7
2023-02-11 19:18:16,193 DEBUG TRAIN Batch 10/500 loss 11.914017 loss_att 12.770337 loss_ctc 16.499516 loss_rnnt 8.964506 hw_loss 0.406284 lr 0.00054602 rank 6
2023-02-11 19:18:16,197 DEBUG TRAIN Batch 10/500 loss 12.939488 loss_att 14.152490 loss_ctc 15.483461 loss_rnnt 10.755183 hw_loss 0.300470 lr 0.00054597 rank 4
2023-02-11 19:18:16,198 DEBUG TRAIN Batch 10/500 loss 23.337202 loss_att 25.458925 loss_ctc 39.710720 loss_rnnt 19.668266 hw_loss 0.199023 lr 0.00054564 rank 2
2023-02-11 19:19:33,004 DEBUG TRAIN Batch 10/600 loss 20.010323 loss_att 17.242188 loss_ctc 20.828535 loss_rnnt 13.755570 hw_loss 1.256116 lr 0.00054566 rank 7
2023-02-11 19:19:33,007 DEBUG TRAIN Batch 10/600 loss 15.642494 loss_att 18.112923 loss_ctc 22.283783 loss_rnnt 12.640635 hw_loss 0.304175 lr 0.00054572 rank 3
2023-02-11 19:19:33,009 DEBUG TRAIN Batch 10/600 loss 18.804424 loss_att 16.225609 loss_ctc 24.215811 loss_rnnt 12.566940 hw_loss 1.130949 lr 0.00054569 rank 6
2023-02-11 19:19:33,011 DEBUG TRAIN Batch 10/600 loss 13.286568 loss_att 11.071078 loss_ctc 16.821516 loss_rnnt 9.306116 hw_loss 0.741042 lr 0.00054531 rank 2
2023-02-11 19:19:33,013 DEBUG TRAIN Batch 10/600 loss 15.226889 loss_att 15.153843 loss_ctc 23.864187 loss_rnnt 12.052066 hw_loss 0.382086 lr 0.00054546 rank 0
2023-02-11 19:19:33,017 DEBUG TRAIN Batch 10/600 loss 11.456425 loss_att 13.037224 loss_ctc 20.392136 loss_rnnt 8.205793 hw_loss 0.326821 lr 0.00054539 rank 5
2023-02-11 19:19:33,041 DEBUG TRAIN Batch 10/600 loss 25.723518 loss_att 21.606379 loss_ctc 29.736685 loss_rnnt 18.809986 hw_loss 1.350351 lr 0.00054553 rank 1
2023-02-11 19:19:33,055 DEBUG TRAIN Batch 10/600 loss 13.510604 loss_att 13.844475 loss_ctc 18.176533 loss_rnnt 11.823367 hw_loss 0.187188 lr 0.00054564 rank 4
2023-02-11 19:20:51,641 DEBUG TRAIN Batch 10/700 loss 11.758385 loss_att 18.111795 loss_ctc 21.925339 loss_rnnt 8.237958 hw_loss 0.167653 lr 0.00054540 rank 3
2023-02-11 19:20:51,642 DEBUG TRAIN Batch 10/700 loss 7.430117 loss_att 11.483807 loss_ctc 15.463428 loss_rnnt 3.174324 hw_loss 0.445115 lr 0.00054533 rank 7
2023-02-11 19:20:51,645 DEBUG TRAIN Batch 10/700 loss 13.645105 loss_att 19.256443 loss_ctc 21.249668 loss_rnnt 9.415724 hw_loss 0.392470 lr 0.00054514 rank 0
2023-02-11 19:20:51,646 DEBUG TRAIN Batch 10/700 loss 9.795981 loss_att 10.842003 loss_ctc 12.739378 loss_rnnt 7.381229 hw_loss 0.339955 lr 0.00054521 rank 1
2023-02-11 19:20:51,649 DEBUG TRAIN Batch 10/700 loss 10.930002 loss_att 13.521824 loss_ctc 12.304707 loss_rnnt 6.641685 hw_loss 0.672499 lr 0.00054507 rank 5
2023-02-11 19:20:51,673 DEBUG TRAIN Batch 10/700 loss 15.911073 loss_att 18.899454 loss_ctc 30.623335 loss_rnnt 11.558707 hw_loss 0.336198 lr 0.00054537 rank 6
2023-02-11 19:20:51,679 DEBUG TRAIN Batch 10/700 loss 8.724095 loss_att 10.688061 loss_ctc 14.076403 loss_rnnt 7.142650 hw_loss 0.089065 lr 0.00054499 rank 2
2023-02-11 19:20:51,687 DEBUG TRAIN Batch 10/700 loss 18.281258 loss_att 20.821892 loss_ctc 33.991760 loss_rnnt 14.418292 hw_loss 0.236270 lr 0.00054532 rank 4
2023-02-11 19:22:08,050 DEBUG TRAIN Batch 10/800 loss 11.250162 loss_att 12.792996 loss_ctc 14.595912 loss_rnnt 8.836275 hw_loss 0.311104 lr 0.00054507 rank 3
2023-02-11 19:22:08,054 DEBUG TRAIN Batch 10/800 loss 24.787775 loss_att 24.634035 loss_ctc 30.697758 loss_rnnt 21.168989 hw_loss 0.536538 lr 0.00054482 rank 0
2023-02-11 19:22:08,061 DEBUG TRAIN Batch 10/800 loss 8.122286 loss_att 9.410682 loss_ctc 11.713606 loss_rnnt 6.603153 hw_loss 0.146740 lr 0.00054467 rank 2
2023-02-11 19:22:08,061 DEBUG TRAIN Batch 10/800 loss 17.338278 loss_att 19.366570 loss_ctc 27.278103 loss_rnnt 13.478396 hw_loss 0.399171 lr 0.00054501 rank 7
2023-02-11 19:22:08,061 DEBUG TRAIN Batch 10/800 loss 10.233118 loss_att 11.049309 loss_ctc 16.425625 loss_rnnt 4.866623 hw_loss 0.820798 lr 0.00054499 rank 4
2023-02-11 19:22:08,063 DEBUG TRAIN Batch 10/800 loss 15.116104 loss_att 20.488796 loss_ctc 25.227886 loss_rnnt 10.929314 hw_loss 0.330753 lr 0.00054489 rank 1
2023-02-11 19:22:08,063 DEBUG TRAIN Batch 10/800 loss 10.514121 loss_att 14.214037 loss_ctc 16.143538 loss_rnnt 8.950036 hw_loss 0.013783 lr 0.00054474 rank 5
2023-02-11 19:22:08,106 DEBUG TRAIN Batch 10/800 loss 11.373229 loss_att 16.494110 loss_ctc 25.549572 loss_rnnt 7.487501 hw_loss 0.182132 lr 0.00054505 rank 6
2023-02-11 19:23:23,328 DEBUG TRAIN Batch 10/900 loss 17.816729 loss_att 19.526064 loss_ctc 25.132610 loss_rnnt 14.381369 hw_loss 0.397133 lr 0.00054475 rank 3
2023-02-11 19:23:23,329 DEBUG TRAIN Batch 10/900 loss 12.465593 loss_att 17.504068 loss_ctc 23.527233 loss_rnnt 8.029525 hw_loss 0.366279 lr 0.00054434 rank 2
2023-02-11 19:23:23,329 DEBUG TRAIN Batch 10/900 loss 8.505680 loss_att 9.114380 loss_ctc 8.602689 loss_rnnt 5.061655 hw_loss 0.620503 lr 0.00054469 rank 7
2023-02-11 19:23:23,329 DEBUG TRAIN Batch 10/900 loss 15.184510 loss_att 16.232861 loss_ctc 20.208635 loss_rnnt 11.739055 hw_loss 0.481107 lr 0.00054456 rank 1
2023-02-11 19:23:23,332 DEBUG TRAIN Batch 10/900 loss 12.662659 loss_att 16.103239 loss_ctc 17.561520 loss_rnnt 9.621771 hw_loss 0.318673 lr 0.00054472 rank 6
2023-02-11 19:23:23,332 DEBUG TRAIN Batch 10/900 loss 11.331332 loss_att 14.125998 loss_ctc 11.948569 loss_rnnt 7.719860 hw_loss 0.556920 lr 0.00054449 rank 0
2023-02-11 19:23:23,333 DEBUG TRAIN Batch 10/900 loss 10.213228 loss_att 12.442609 loss_ctc 13.296093 loss_rnnt 5.139560 hw_loss 0.790639 lr 0.00054442 rank 5
2023-02-11 19:23:23,376 DEBUG TRAIN Batch 10/900 loss 9.590120 loss_att 10.597480 loss_ctc 11.126238 loss_rnnt 4.729437 hw_loss 0.835199 lr 0.00054467 rank 4
2023-02-11 19:24:40,669 DEBUG TRAIN Batch 10/1000 loss 10.537765 loss_att 14.151999 loss_ctc 17.372356 loss_rnnt 7.083058 hw_loss 0.341359 lr 0.00054440 rank 6
2023-02-11 19:24:40,672 DEBUG TRAIN Batch 10/1000 loss 12.001971 loss_att 13.487332 loss_ctc 23.113003 loss_rnnt 7.558959 hw_loss 0.499588 lr 0.00054410 rank 5
2023-02-11 19:24:40,674 DEBUG TRAIN Batch 10/1000 loss 14.909271 loss_att 16.610628 loss_ctc 21.681456 loss_rnnt 10.094860 hw_loss 0.669597 lr 0.00054424 rank 1
2023-02-11 19:24:40,676 DEBUG TRAIN Batch 10/1000 loss 14.521101 loss_att 17.353086 loss_ctc 22.668522 loss_rnnt 10.175942 hw_loss 0.504832 lr 0.00054402 rank 2
2023-02-11 19:24:40,677 DEBUG TRAIN Batch 10/1000 loss 16.915634 loss_att 17.328773 loss_ctc 20.739086 loss_rnnt 12.144547 hw_loss 0.783500 lr 0.00054417 rank 0
2023-02-11 19:24:40,685 DEBUG TRAIN Batch 10/1000 loss 20.237911 loss_att 24.578541 loss_ctc 42.085163 loss_rnnt 15.489092 hw_loss 0.181448 lr 0.00054442 rank 3
2023-02-11 19:24:40,690 DEBUG TRAIN Batch 10/1000 loss 7.726824 loss_att 10.212454 loss_ctc 12.552714 loss_rnnt 4.445876 hw_loss 0.401319 lr 0.00054436 rank 7
2023-02-11 19:24:40,726 DEBUG TRAIN Batch 10/1000 loss 8.779782 loss_att 11.616367 loss_ctc 12.139478 loss_rnnt 6.250199 hw_loss 0.283933 lr 0.00054435 rank 4
2023-02-11 19:25:58,570 DEBUG TRAIN Batch 10/1100 loss 22.041204 loss_att 22.381287 loss_ctc 29.371666 loss_rnnt 16.897148 hw_loss 0.768496 lr 0.00054404 rank 7
2023-02-11 19:25:58,576 DEBUG TRAIN Batch 10/1100 loss 13.504785 loss_att 18.100342 loss_ctc 28.069794 loss_rnnt 7.892725 hw_loss 0.515803 lr 0.00054370 rank 2
2023-02-11 19:25:58,576 DEBUG TRAIN Batch 10/1100 loss 16.182909 loss_att 15.933288 loss_ctc 19.400276 loss_rnnt 13.622573 hw_loss 0.408990 lr 0.00054385 rank 0
2023-02-11 19:25:58,577 DEBUG TRAIN Batch 10/1100 loss 24.517881 loss_att 26.820202 loss_ctc 29.344307 loss_rnnt 20.077721 hw_loss 0.625533 lr 0.00054410 rank 3
2023-02-11 19:25:58,578 DEBUG TRAIN Batch 10/1100 loss 17.032999 loss_att 18.323132 loss_ctc 26.562710 loss_rnnt 14.494717 hw_loss 0.189305 lr 0.00054402 rank 4
2023-02-11 19:25:58,581 DEBUG TRAIN Batch 10/1100 loss 17.181944 loss_att 19.067339 loss_ctc 24.037893 loss_rnnt 13.151275 hw_loss 0.513649 lr 0.00054408 rank 6
2023-02-11 19:25:58,582 DEBUG TRAIN Batch 10/1100 loss 14.987434 loss_att 17.663311 loss_ctc 17.672260 loss_rnnt 13.105213 hw_loss 0.185450 lr 0.00054378 rank 5
2023-02-11 19:25:58,583 DEBUG TRAIN Batch 10/1100 loss 17.510439 loss_att 19.170019 loss_ctc 22.158630 loss_rnnt 14.558633 hw_loss 0.375024 lr 0.00054392 rank 1
2023-02-11 19:27:14,515 DEBUG TRAIN Batch 10/1200 loss 8.219697 loss_att 9.045492 loss_ctc 9.968884 loss_rnnt 6.588275 hw_loss 0.231195 lr 0.00054378 rank 3
2023-02-11 19:27:14,519 DEBUG TRAIN Batch 10/1200 loss 12.942258 loss_att 14.773081 loss_ctc 16.679724 loss_rnnt 8.970535 hw_loss 0.582605 lr 0.00054346 rank 5
2023-02-11 19:27:14,520 DEBUG TRAIN Batch 10/1200 loss 13.375973 loss_att 13.255552 loss_ctc 18.413279 loss_rnnt 8.560435 hw_loss 0.781497 lr 0.00054353 rank 0
2023-02-11 19:27:14,521 DEBUG TRAIN Batch 10/1200 loss 13.116160 loss_att 13.619249 loss_ctc 20.814665 loss_rnnt 11.255382 hw_loss 0.137568 lr 0.00054375 rank 6
2023-02-11 19:27:14,524 DEBUG TRAIN Batch 10/1200 loss 26.141970 loss_att 28.353157 loss_ctc 32.537231 loss_rnnt 20.131664 hw_loss 0.884131 lr 0.00054372 rank 7
2023-02-11 19:27:14,524 DEBUG TRAIN Batch 10/1200 loss 21.128794 loss_att 22.130867 loss_ctc 30.470646 loss_rnnt 18.348402 hw_loss 0.250200 lr 0.00054360 rank 1
2023-02-11 19:27:14,526 DEBUG TRAIN Batch 10/1200 loss 16.549572 loss_att 18.795980 loss_ctc 24.834295 loss_rnnt 14.272314 hw_loss 0.135627 lr 0.00054338 rank 2
2023-02-11 19:27:14,567 DEBUG TRAIN Batch 10/1200 loss 16.554625 loss_att 15.424843 loss_ctc 19.841669 loss_rnnt 12.806605 hw_loss 0.662944 lr 0.00054370 rank 4
2023-02-11 19:28:29,467 DEBUG TRAIN Batch 10/1300 loss 23.305391 loss_att 26.893162 loss_ctc 37.969749 loss_rnnt 17.250618 hw_loss 0.634120 lr 0.00054346 rank 3
2023-02-11 19:28:29,468 DEBUG TRAIN Batch 10/1300 loss 17.105600 loss_att 20.943151 loss_ctc 26.004072 loss_rnnt 13.846949 hw_loss 0.244627 lr 0.00054340 rank 7
2023-02-11 19:28:29,470 DEBUG TRAIN Batch 10/1300 loss 12.522229 loss_att 16.460089 loss_ctc 17.446198 loss_rnnt 9.468344 hw_loss 0.301835 lr 0.00054321 rank 0
2023-02-11 19:28:29,472 DEBUG TRAIN Batch 10/1300 loss 13.841980 loss_att 15.757635 loss_ctc 25.545506 loss_rnnt 9.723656 hw_loss 0.407761 lr 0.00054338 rank 4
2023-02-11 19:28:29,474 DEBUG TRAIN Batch 10/1300 loss 10.104367 loss_att 12.545065 loss_ctc 14.824557 loss_rnnt 6.050648 hw_loss 0.550542 lr 0.00054343 rank 6
2023-02-11 19:28:29,475 DEBUG TRAIN Batch 10/1300 loss 11.543593 loss_att 10.549440 loss_ctc 14.798991 loss_rnnt 8.352148 hw_loss 0.554292 lr 0.00054314 rank 5
2023-02-11 19:28:29,478 DEBUG TRAIN Batch 10/1300 loss 5.247699 loss_att 10.164897 loss_ctc 9.671524 loss_rnnt 1.449982 hw_loss 0.417081 lr 0.00054328 rank 1
2023-02-11 19:28:29,515 DEBUG TRAIN Batch 10/1300 loss 15.774223 loss_att 16.445824 loss_ctc 23.181883 loss_rnnt 11.963728 hw_loss 0.504091 lr 0.00054306 rank 2
2023-02-11 19:29:47,500 DEBUG TRAIN Batch 10/1400 loss 18.633530 loss_att 22.136057 loss_ctc 25.384689 loss_rnnt 15.218738 hw_loss 0.340150 lr 0.00054311 rank 6
2023-02-11 19:29:47,502 DEBUG TRAIN Batch 10/1400 loss 17.834549 loss_att 18.859821 loss_ctc 27.626348 loss_rnnt 13.695198 hw_loss 0.492886 lr 0.00054308 rank 7
2023-02-11 19:29:47,504 DEBUG TRAIN Batch 10/1400 loss 12.407679 loss_att 16.243717 loss_ctc 23.689617 loss_rnnt 8.190501 hw_loss 0.364821 lr 0.00054314 rank 3
2023-02-11 19:29:47,504 DEBUG TRAIN Batch 10/1400 loss 17.036884 loss_att 21.047949 loss_ctc 24.637554 loss_rnnt 13.331355 hw_loss 0.354355 lr 0.00054289 rank 0
2023-02-11 19:29:47,505 DEBUG TRAIN Batch 10/1400 loss 22.540020 loss_att 23.279552 loss_ctc 31.831106 loss_rnnt 17.016045 hw_loss 0.775735 lr 0.00054296 rank 1
2023-02-11 19:29:47,506 DEBUG TRAIN Batch 10/1400 loss 12.377076 loss_att 15.885949 loss_ctc 18.977165 loss_rnnt 8.213453 hw_loss 0.484094 lr 0.00054281 rank 5
2023-02-11 19:29:47,510 DEBUG TRAIN Batch 10/1400 loss 13.980463 loss_att 17.169273 loss_ctc 23.500469 loss_rnnt 9.976255 hw_loss 0.393208 lr 0.00054306 rank 4
2023-02-11 19:29:47,555 DEBUG TRAIN Batch 10/1400 loss 11.682360 loss_att 16.485500 loss_ctc 18.896805 loss_rnnt 9.027779 hw_loss 0.137255 lr 0.00054274 rank 2
2023-02-11 19:31:04,073 DEBUG TRAIN Batch 10/1500 loss 14.546057 loss_att 16.967739 loss_ctc 22.445995 loss_rnnt 11.548012 hw_loss 0.273822 lr 0.00054276 rank 7
2023-02-11 19:31:04,076 DEBUG TRAIN Batch 10/1500 loss 11.843767 loss_att 13.853045 loss_ctc 19.676399 loss_rnnt 8.827301 hw_loss 0.294424 lr 0.00054242 rank 2
2023-02-11 19:31:04,077 DEBUG TRAIN Batch 10/1500 loss 14.432062 loss_att 17.882938 loss_ctc 22.217627 loss_rnnt 10.862495 hw_loss 0.345247 lr 0.00054274 rank 4
2023-02-11 19:31:04,079 DEBUG TRAIN Batch 10/1500 loss 13.872703 loss_att 15.975733 loss_ctc 20.713154 loss_rnnt 10.420966 hw_loss 0.397326 lr 0.00054264 rank 1
2023-02-11 19:31:04,079 DEBUG TRAIN Batch 10/1500 loss 12.577670 loss_att 13.913321 loss_ctc 19.886986 loss_rnnt 8.295691 hw_loss 0.570051 lr 0.00054257 rank 0
2023-02-11 19:31:04,082 DEBUG TRAIN Batch 10/1500 loss 21.419439 loss_att 26.312876 loss_ctc 41.742645 loss_rnnt 17.066467 hw_loss 0.124598 lr 0.00054279 rank 6
2023-02-11 19:31:04,082 DEBUG TRAIN Batch 10/1500 loss 19.347649 loss_att 21.400139 loss_ctc 30.537880 loss_rnnt 15.633560 hw_loss 0.339667 lr 0.00054282 rank 3
2023-02-11 19:31:04,087 DEBUG TRAIN Batch 10/1500 loss 9.431914 loss_att 13.689499 loss_ctc 16.686119 loss_rnnt 5.090447 hw_loss 0.473010 lr 0.00054250 rank 5
2023-02-11 19:32:18,463 DEBUG TRAIN Batch 10/1600 loss 11.052056 loss_att 12.207840 loss_ctc 14.735902 loss_rnnt 7.522433 hw_loss 0.526366 lr 0.00054250 rank 3
2023-02-11 19:32:18,465 DEBUG TRAIN Batch 10/1600 loss 8.534609 loss_att 11.068487 loss_ctc 13.834387 loss_rnnt 4.514860 hw_loss 0.526188 lr 0.00054247 rank 6
2023-02-11 19:32:18,467 DEBUG TRAIN Batch 10/1600 loss 7.710049 loss_att 10.733459 loss_ctc 13.328474 loss_rnnt 5.346675 hw_loss 0.189294 lr 0.00054244 rank 7
2023-02-11 19:32:18,468 DEBUG TRAIN Batch 10/1600 loss 17.532927 loss_att 18.407106 loss_ctc 29.151005 loss_rnnt 13.421148 hw_loss 0.447725 lr 0.00054210 rank 2
2023-02-11 19:32:18,468 DEBUG TRAIN Batch 10/1600 loss 11.581862 loss_att 12.455662 loss_ctc 17.163836 loss_rnnt 7.627552 hw_loss 0.569116 lr 0.00054225 rank 0
2023-02-11 19:32:18,471 DEBUG TRAIN Batch 10/1600 loss 18.814379 loss_att 20.539848 loss_ctc 27.062611 loss_rnnt 16.129021 hw_loss 0.232594 lr 0.00054242 rank 4
2023-02-11 19:32:18,474 DEBUG TRAIN Batch 10/1600 loss 11.501595 loss_att 12.162754 loss_ctc 16.115831 loss_rnnt 8.747147 hw_loss 0.376310 lr 0.00054218 rank 5
2023-02-11 19:32:18,519 DEBUG TRAIN Batch 10/1600 loss 14.408630 loss_att 18.315296 loss_ctc 20.757113 loss_rnnt 10.276943 hw_loss 0.469479 lr 0.00054232 rank 1
2023-02-11 19:33:34,900 DEBUG TRAIN Batch 10/1700 loss 19.504662 loss_att 20.074856 loss_ctc 25.604107 loss_rnnt 14.925415 hw_loss 0.684740 lr 0.00054193 rank 0
2023-02-11 19:33:34,901 DEBUG TRAIN Batch 10/1700 loss 15.222143 loss_att 17.628147 loss_ctc 18.640736 loss_rnnt 11.202480 hw_loss 0.577997 lr 0.00054178 rank 2
2023-02-11 19:33:34,905 DEBUG TRAIN Batch 10/1700 loss 17.472849 loss_att 20.159863 loss_ctc 21.528809 loss_rnnt 14.807707 hw_loss 0.297552 lr 0.00054210 rank 4
2023-02-11 19:33:34,907 DEBUG TRAIN Batch 10/1700 loss 15.051541 loss_att 17.396645 loss_ctc 24.380064 loss_rnnt 11.561620 hw_loss 0.333206 lr 0.00054200 rank 1
2023-02-11 19:33:34,910 DEBUG TRAIN Batch 10/1700 loss 17.250214 loss_att 21.801611 loss_ctc 26.881453 loss_rnnt 12.912686 hw_loss 0.401828 lr 0.00054218 rank 3
2023-02-11 19:33:34,912 DEBUG TRAIN Batch 10/1700 loss 18.989347 loss_att 23.330383 loss_ctc 29.420364 loss_rnnt 14.286528 hw_loss 0.458214 lr 0.00054212 rank 7
2023-02-11 19:33:34,921 DEBUG TRAIN Batch 10/1700 loss 18.714310 loss_att 21.276333 loss_ctc 26.770340 loss_rnnt 15.023749 hw_loss 0.394504 lr 0.00054186 rank 5
2023-02-11 19:33:34,946 DEBUG TRAIN Batch 10/1700 loss 11.548261 loss_att 15.490703 loss_ctc 19.305107 loss_rnnt 7.981116 hw_loss 0.327077 lr 0.00054215 rank 6
2023-02-11 19:34:54,106 DEBUG TRAIN Batch 10/1800 loss 10.708072 loss_att 12.482347 loss_ctc 16.015898 loss_rnnt 8.001922 hw_loss 0.308172 lr 0.00054186 rank 3
2023-02-11 19:34:54,108 DEBUG TRAIN Batch 10/1800 loss 8.480546 loss_att 9.664097 loss_ctc 12.265396 loss_rnnt 5.689497 hw_loss 0.384317 lr 0.00054146 rank 2
2023-02-11 19:34:54,110 DEBUG TRAIN Batch 10/1800 loss 8.320948 loss_att 8.000521 loss_ctc 10.230260 loss_rnnt 5.103599 hw_loss 0.567536 lr 0.00054154 rank 5
2023-02-11 19:34:54,113 DEBUG TRAIN Batch 10/1800 loss 17.760138 loss_att 20.184338 loss_ctc 24.471266 loss_rnnt 12.957481 hw_loss 0.641812 lr 0.00054178 rank 4
2023-02-11 19:34:54,114 DEBUG TRAIN Batch 10/1800 loss 11.414775 loss_att 13.745160 loss_ctc 18.052349 loss_rnnt 7.554943 hw_loss 0.470390 lr 0.00054161 rank 0
2023-02-11 19:34:54,114 DEBUG TRAIN Batch 10/1800 loss 17.742056 loss_att 16.411470 loss_ctc 25.772324 loss_rnnt 14.457703 hw_loss 0.464956 lr 0.00054180 rank 7
2023-02-11 19:34:54,116 DEBUG TRAIN Batch 10/1800 loss 14.607574 loss_att 16.075500 loss_ctc 21.409544 loss_rnnt 12.987615 hw_loss 0.078646 lr 0.00054168 rank 1
2023-02-11 19:34:54,158 DEBUG TRAIN Batch 10/1800 loss 20.806335 loss_att 22.145916 loss_ctc 34.487988 loss_rnnt 15.317795 hw_loss 0.636825 lr 0.00054184 rank 6
2023-02-11 19:36:11,319 DEBUG TRAIN Batch 10/1900 loss 13.000927 loss_att 17.452177 loss_ctc 15.347651 loss_rnnt 9.070581 hw_loss 0.511350 lr 0.00054154 rank 3
2023-02-11 19:36:11,321 DEBUG TRAIN Batch 10/1900 loss 22.470295 loss_att 19.446697 loss_ctc 24.431192 loss_rnnt 17.210615 hw_loss 1.050552 lr 0.00054136 rank 1
2023-02-11 19:36:11,324 DEBUG TRAIN Batch 10/1900 loss 11.685165 loss_att 9.946760 loss_ctc 12.469032 loss_rnnt 6.332985 hw_loss 1.049127 lr 0.00054129 rank 0
2023-02-11 19:36:11,324 DEBUG TRAIN Batch 10/1900 loss 9.818131 loss_att 12.889500 loss_ctc 18.230621 loss_rnnt 7.466717 hw_loss 0.115402 lr 0.00054115 rank 2
2023-02-11 19:36:11,325 DEBUG TRAIN Batch 10/1900 loss 11.075513 loss_att 15.404715 loss_ctc 20.924652 loss_rnnt 8.476271 hw_loss 0.078785 lr 0.00054148 rank 7
2023-02-11 19:36:11,327 DEBUG TRAIN Batch 10/1900 loss 11.152737 loss_att 15.930870 loss_ctc 15.202506 loss_rnnt 8.647081 hw_loss 0.189386 lr 0.00054152 rank 6
2023-02-11 19:36:11,328 DEBUG TRAIN Batch 10/1900 loss 21.236372 loss_att 24.920567 loss_ctc 38.501488 loss_rnnt 16.217499 hw_loss 0.371254 lr 0.00054147 rank 4
2023-02-11 19:36:11,330 DEBUG TRAIN Batch 10/1900 loss 9.963826 loss_att 11.789609 loss_ctc 12.329224 loss_rnnt 5.977239 hw_loss 0.619883 lr 0.00054122 rank 5
2023-02-11 19:37:25,199 DEBUG TRAIN Batch 10/2000 loss 11.029587 loss_att 13.830490 loss_ctc 19.451557 loss_rnnt 7.573174 hw_loss 0.332494 lr 0.00054098 rank 0
2023-02-11 19:37:25,201 DEBUG TRAIN Batch 10/2000 loss 12.082500 loss_att 15.741190 loss_ctc 26.447884 loss_rnnt 9.127293 hw_loss 0.057766 lr 0.00054120 rank 6
2023-02-11 19:37:25,203 DEBUG TRAIN Batch 10/2000 loss 9.351317 loss_att 14.389477 loss_ctc 15.367149 loss_rnnt 6.124358 hw_loss 0.265728 lr 0.00054117 rank 7
2023-02-11 19:37:25,205 DEBUG TRAIN Batch 10/2000 loss 17.098368 loss_att 18.677395 loss_ctc 25.235451 loss_rnnt 13.610560 hw_loss 0.391324 lr 0.00054105 rank 1
2023-02-11 19:37:25,205 DEBUG TRAIN Batch 10/2000 loss 15.488677 loss_att 16.548403 loss_ctc 21.935658 loss_rnnt 10.892876 hw_loss 0.660799 lr 0.00054123 rank 3
2023-02-11 19:37:25,207 DEBUG TRAIN Batch 10/2000 loss 10.910215 loss_att 14.182646 loss_ctc 16.832045 loss_rnnt 8.104298 hw_loss 0.255348 lr 0.00054091 rank 5
2023-02-11 19:37:25,207 DEBUG TRAIN Batch 10/2000 loss 16.587982 loss_att 21.692665 loss_ctc 25.548031 loss_rnnt 12.015482 hw_loss 0.441917 lr 0.00054115 rank 4
2023-02-11 19:37:25,211 DEBUG TRAIN Batch 10/2000 loss 29.342491 loss_att 31.752174 loss_ctc 42.054680 loss_rnnt 25.886005 hw_loss 0.239923 lr 0.00054083 rank 2
2023-02-11 19:38:42,685 DEBUG TRAIN Batch 10/2100 loss 14.756939 loss_att 17.488079 loss_ctc 20.048502 loss_rnnt 12.435489 hw_loss 0.200565 lr 0.00054066 rank 0
2023-02-11 19:38:42,685 DEBUG TRAIN Batch 10/2100 loss 16.301432 loss_att 21.107737 loss_ctc 26.121191 loss_rnnt 12.628363 hw_loss 0.262970 lr 0.00054059 rank 5
2023-02-11 19:38:42,686 DEBUG TRAIN Batch 10/2100 loss 24.795502 loss_att 24.043839 loss_ctc 37.528168 loss_rnnt 19.892996 hw_loss 0.629091 lr 0.00054091 rank 3
2023-02-11 19:38:42,688 DEBUG TRAIN Batch 10/2100 loss 17.975824 loss_att 18.857433 loss_ctc 29.064301 loss_rnnt 14.837379 hw_loss 0.278187 lr 0.00054085 rank 7
2023-02-11 19:38:42,690 DEBUG TRAIN Batch 10/2100 loss 6.040762 loss_att 11.198762 loss_ctc 9.463839 loss_rnnt 2.830972 hw_loss 0.322834 lr 0.00054051 rank 2
2023-02-11 19:38:42,692 DEBUG TRAIN Batch 10/2100 loss 8.953718 loss_att 11.982559 loss_ctc 13.532110 loss_rnnt 5.994044 hw_loss 0.326898 lr 0.00054083 rank 4
2023-02-11 19:38:42,692 DEBUG TRAIN Batch 10/2100 loss 15.630514 loss_att 19.925455 loss_ctc 24.435936 loss_rnnt 12.451324 hw_loss 0.214902 lr 0.00054088 rank 6
2023-02-11 19:38:42,693 DEBUG TRAIN Batch 10/2100 loss 16.317657 loss_att 19.135677 loss_ctc 25.919638 loss_rnnt 12.495018 hw_loss 0.371020 lr 0.00054073 rank 1
2023-02-11 19:40:00,500 DEBUG TRAIN Batch 10/2200 loss 9.043510 loss_att 11.407830 loss_ctc 18.160730 loss_rnnt 5.374372 hw_loss 0.371371 lr 0.00054034 rank 0
2023-02-11 19:40:00,500 DEBUG TRAIN Batch 10/2200 loss 13.586294 loss_att 14.031281 loss_ctc 21.623837 loss_rnnt 8.799912 hw_loss 0.679821 lr 0.00054041 rank 1
2023-02-11 19:40:00,503 DEBUG TRAIN Batch 10/2200 loss 14.293624 loss_att 15.370888 loss_ctc 19.430273 loss_rnnt 9.221638 hw_loss 0.782184 lr 0.00054053 rank 7
2023-02-11 19:40:00,504 DEBUG TRAIN Batch 10/2200 loss 20.857729 loss_att 20.225420 loss_ctc 28.199654 loss_rnnt 17.960003 hw_loss 0.383487 lr 0.00054059 rank 3
2023-02-11 19:40:00,507 DEBUG TRAIN Batch 10/2200 loss 8.307292 loss_att 11.548094 loss_ctc 16.092606 loss_rnnt 5.399816 hw_loss 0.228989 lr 0.00054027 rank 5
2023-02-11 19:40:00,508 DEBUG TRAIN Batch 10/2200 loss 9.117720 loss_att 12.002834 loss_ctc 15.059963 loss_rnnt 6.538815 hw_loss 0.226797 lr 0.00054052 rank 4
2023-02-11 19:40:00,510 DEBUG TRAIN Batch 10/2200 loss 10.996567 loss_att 14.964884 loss_ctc 15.093731 loss_rnnt 6.783968 hw_loss 0.538621 lr 0.00054020 rank 2
2023-02-11 19:40:00,556 DEBUG TRAIN Batch 10/2200 loss 21.813486 loss_att 23.705185 loss_ctc 29.093510 loss_rnnt 18.939335 hw_loss 0.285964 lr 0.00054057 rank 6
2023-02-11 19:41:16,104 DEBUG TRAIN Batch 10/2300 loss 8.683599 loss_att 12.708170 loss_ctc 13.205711 loss_rnnt 5.414650 hw_loss 0.348954 lr 0.00054003 rank 0
2023-02-11 19:41:16,104 DEBUG TRAIN Batch 10/2300 loss 11.213321 loss_att 13.553457 loss_ctc 15.037511 loss_rnnt 7.214777 hw_loss 0.566367 lr 0.00054025 rank 6
2023-02-11 19:41:16,107 DEBUG TRAIN Batch 10/2300 loss 17.127544 loss_att 19.032148 loss_ctc 25.942715 loss_rnnt 14.053621 hw_loss 0.284558 lr 0.00054028 rank 3
2023-02-11 19:41:16,108 DEBUG TRAIN Batch 10/2300 loss 9.541731 loss_att 10.447736 loss_ctc 12.624471 loss_rnnt 7.937912 hw_loss 0.189672 lr 0.00054022 rank 7
2023-02-11 19:41:16,110 DEBUG TRAIN Batch 10/2300 loss 11.102139 loss_att 12.060154 loss_ctc 12.012893 loss_rnnt 7.504956 hw_loss 0.615778 lr 0.00053996 rank 5
2023-02-11 19:41:16,110 DEBUG TRAIN Batch 10/2300 loss 17.570168 loss_att 20.057762 loss_ctc 25.510521 loss_rnnt 13.051063 hw_loss 0.555539 lr 0.00054010 rank 1
2023-02-11 19:41:16,116 DEBUG TRAIN Batch 10/2300 loss 12.645542 loss_att 13.398389 loss_ctc 20.069492 loss_rnnt 9.677582 hw_loss 0.342662 lr 0.00053988 rank 2
2023-02-11 19:41:16,157 DEBUG TRAIN Batch 10/2300 loss 12.916781 loss_att 14.670793 loss_ctc 21.326897 loss_rnnt 9.818994 hw_loss 0.304807 lr 0.00054020 rank 4
2023-02-11 19:42:31,800 DEBUG TRAIN Batch 10/2400 loss 12.985316 loss_att 13.203612 loss_ctc 16.017782 loss_rnnt 8.280235 hw_loss 0.798205 lr 0.00053996 rank 3
2023-02-11 19:42:31,802 DEBUG TRAIN Batch 10/2400 loss 9.154111 loss_att 11.042133 loss_ctc 11.794788 loss_rnnt 4.100009 hw_loss 0.810826 lr 0.00053964 rank 5
2023-02-11 19:42:31,802 DEBUG TRAIN Batch 10/2400 loss 19.681768 loss_att 17.014404 loss_ctc 21.665379 loss_rnnt 16.305176 hw_loss 0.683547 lr 0.00053990 rank 7
2023-02-11 19:42:31,805 DEBUG TRAIN Batch 10/2400 loss 12.716245 loss_att 14.961515 loss_ctc 17.423443 loss_rnnt 10.763639 hw_loss 0.164236 lr 0.00053971 rank 0
2023-02-11 19:42:31,810 DEBUG TRAIN Batch 10/2400 loss 14.833335 loss_att 18.809465 loss_ctc 22.078228 loss_rnnt 11.088417 hw_loss 0.371945 lr 0.00053994 rank 6
2023-02-11 19:42:31,812 DEBUG TRAIN Batch 10/2400 loss 21.714432 loss_att 23.258434 loss_ctc 31.835785 loss_rnnt 17.455984 hw_loss 0.487525 lr 0.00053989 rank 4
2023-02-11 19:42:31,815 DEBUG TRAIN Batch 10/2400 loss 14.162880 loss_att 16.093006 loss_ctc 26.532724 loss_rnnt 10.700934 hw_loss 0.267489 lr 0.00053957 rank 2
2023-02-11 19:42:31,852 DEBUG TRAIN Batch 10/2400 loss 10.370092 loss_att 12.699203 loss_ctc 13.433455 loss_rnnt 6.427751 hw_loss 0.575263 lr 0.00053978 rank 1
2023-02-11 19:43:51,684 DEBUG TRAIN Batch 10/2500 loss 11.427141 loss_att 10.530025 loss_ctc 13.127498 loss_rnnt 7.290082 hw_loss 0.766831 lr 0.00053959 rank 7
2023-02-11 19:43:51,689 DEBUG TRAIN Batch 10/2500 loss 13.265502 loss_att 12.104094 loss_ctc 15.681736 loss_rnnt 10.082823 hw_loss 0.579899 lr 0.00053940 rank 0
2023-02-11 19:43:51,691 DEBUG TRAIN Batch 10/2500 loss 11.700489 loss_att 9.529089 loss_ctc 13.597906 loss_rnnt 7.459562 hw_loss 0.829166 lr 0.00053925 rank 2
2023-02-11 19:43:51,693 DEBUG TRAIN Batch 10/2500 loss 12.510791 loss_att 13.321808 loss_ctc 15.533319 loss_rnnt 7.842581 hw_loss 0.769313 lr 0.00053933 rank 5
2023-02-11 19:43:51,694 DEBUG TRAIN Batch 10/2500 loss 17.544275 loss_att 16.405823 loss_ctc 22.875223 loss_rnnt 14.601692 hw_loss 0.461153 lr 0.00053947 rank 1
2023-02-11 19:43:51,695 DEBUG TRAIN Batch 10/2500 loss 17.265621 loss_att 19.303335 loss_ctc 28.970236 loss_rnnt 13.925900 hw_loss 0.257168 lr 0.00053962 rank 6
2023-02-11 19:43:51,699 DEBUG TRAIN Batch 10/2500 loss 18.113541 loss_att 15.592026 loss_ctc 20.181280 loss_rnnt 15.449517 hw_loss 0.542367 lr 0.00053965 rank 3
2023-02-11 19:43:51,737 DEBUG TRAIN Batch 10/2500 loss 17.287649 loss_att 14.465200 loss_ctc 22.121365 loss_rnnt 13.612356 hw_loss 0.674117 lr 0.00053957 rank 4
2023-02-11 19:45:06,903 DEBUG TRAIN Batch 10/2600 loss 20.141359 loss_att 24.031082 loss_ctc 38.090549 loss_rnnt 16.616455 hw_loss 0.066325 lr 0.00053909 rank 0
2023-02-11 19:45:06,902 DEBUG TRAIN Batch 10/2600 loss 18.878628 loss_att 17.394108 loss_ctc 26.132208 loss_rnnt 14.762020 hw_loss 0.646194 lr 0.00053927 rank 7
2023-02-11 19:45:06,904 DEBUG TRAIN Batch 10/2600 loss 20.532644 loss_att 22.147306 loss_ctc 28.991529 loss_rnnt 16.063988 hw_loss 0.565851 lr 0.00053894 rank 2
2023-02-11 19:45:06,905 DEBUG TRAIN Batch 10/2600 loss 14.651677 loss_att 11.407140 loss_ctc 18.652323 loss_rnnt 9.805730 hw_loss 0.930269 lr 0.00053902 rank 5
2023-02-11 19:45:06,905 DEBUG TRAIN Batch 10/2600 loss 16.919542 loss_att 25.424137 loss_ctc 33.040894 loss_rnnt 10.903461 hw_loss 0.406059 lr 0.00053915 rank 1
2023-02-11 19:45:06,906 DEBUG TRAIN Batch 10/2600 loss 13.156572 loss_att 14.183710 loss_ctc 21.059692 loss_rnnt 8.313318 hw_loss 0.672015 lr 0.00053933 rank 3
2023-02-11 19:45:06,913 DEBUG TRAIN Batch 10/2600 loss 14.854387 loss_att 17.642828 loss_ctc 21.750311 loss_rnnt 11.337368 hw_loss 0.382476 lr 0.00053931 rank 6
2023-02-11 19:45:06,949 DEBUG TRAIN Batch 10/2600 loss 19.746559 loss_att 24.110577 loss_ctc 24.699600 loss_rnnt 14.218855 hw_loss 0.748968 lr 0.00053926 rank 4
2023-02-11 19:46:22,024 DEBUG TRAIN Batch 10/2700 loss 13.646997 loss_att 16.332672 loss_ctc 23.889267 loss_rnnt 10.363109 hw_loss 0.258960 lr 0.00053902 rank 3
2023-02-11 19:46:22,024 DEBUG TRAIN Batch 10/2700 loss 11.065769 loss_att 12.798838 loss_ctc 17.132092 loss_rnnt 8.626413 hw_loss 0.240731 lr 0.00053899 rank 6
2023-02-11 19:46:22,026 DEBUG TRAIN Batch 10/2700 loss 18.940653 loss_att 26.450411 loss_ctc 23.828236 loss_rnnt 16.027142 hw_loss 0.142478 lr 0.00053896 rank 7
2023-02-11 19:46:22,028 DEBUG TRAIN Batch 10/2700 loss 11.179025 loss_att 14.401791 loss_ctc 22.325901 loss_rnnt 7.472986 hw_loss 0.295356 lr 0.00053863 rank 2
2023-02-11 19:46:22,027 DEBUG TRAIN Batch 10/2700 loss 8.299508 loss_att 11.222601 loss_ctc 11.787178 loss_rnnt 6.283881 hw_loss 0.181122 lr 0.00053870 rank 5
2023-02-11 19:46:22,028 DEBUG TRAIN Batch 10/2700 loss 5.142933 loss_att 9.645758 loss_ctc 10.314592 loss_rnnt 2.239680 hw_loss 0.246213 lr 0.00053877 rank 0
2023-02-11 19:46:22,032 DEBUG TRAIN Batch 10/2700 loss 13.501143 loss_att 15.874344 loss_ctc 19.010767 loss_rnnt 10.294827 hw_loss 0.374449 lr 0.00053884 rank 1
2023-02-11 19:46:22,033 DEBUG TRAIN Batch 10/2700 loss 8.378813 loss_att 11.137376 loss_ctc 11.117691 loss_rnnt 5.531475 hw_loss 0.361958 lr 0.00053894 rank 4
2023-02-11 19:47:39,240 DEBUG TRAIN Batch 10/2800 loss 12.114291 loss_att 19.274216 loss_ctc 17.987907 loss_rnnt 7.511509 hw_loss 0.447684 lr 0.00053846 rank 0
2023-02-11 19:47:39,244 DEBUG TRAIN Batch 10/2800 loss 19.387444 loss_att 18.820042 loss_ctc 34.449398 loss_rnnt 13.691596 hw_loss 0.712700 lr 0.00053865 rank 7
2023-02-11 19:47:39,244 DEBUG TRAIN Batch 10/2800 loss 12.974829 loss_att 18.606098 loss_ctc 28.351416 loss_rnnt 8.954872 hw_loss 0.158155 lr 0.00053832 rank 2
2023-02-11 19:47:39,246 DEBUG TRAIN Batch 10/2800 loss 12.436378 loss_att 18.124897 loss_ctc 24.486555 loss_rnnt 8.001739 hw_loss 0.316921 lr 0.00053868 rank 6
2023-02-11 19:47:39,246 DEBUG TRAIN Batch 10/2800 loss 17.603918 loss_att 12.288154 loss_ctc 20.547277 loss_rnnt 12.581026 hw_loss 1.067549 lr 0.00053871 rank 3
2023-02-11 19:47:39,248 DEBUG TRAIN Batch 10/2800 loss 19.104273 loss_att 22.938538 loss_ctc 27.939161 loss_rnnt 15.068675 hw_loss 0.392017 lr 0.00053839 rank 5
2023-02-11 19:47:39,247 DEBUG TRAIN Batch 10/2800 loss 8.931564 loss_att 11.870924 loss_ctc 16.323763 loss_rnnt 5.487632 hw_loss 0.350706 lr 0.00053863 rank 4
2023-02-11 19:47:39,248 DEBUG TRAIN Batch 10/2800 loss 11.445292 loss_att 14.423449 loss_ctc 14.609779 loss_rnnt 8.947330 hw_loss 0.277575 lr 0.00053853 rank 1
2023-02-11 19:48:55,303 DEBUG TRAIN Batch 10/2900 loss 12.427343 loss_att 14.370918 loss_ctc 18.615042 loss_rnnt 9.818430 hw_loss 0.261595 lr 0.00053839 rank 3
2023-02-11 19:48:55,303 DEBUG TRAIN Batch 10/2900 loss 15.424622 loss_att 14.721979 loss_ctc 21.504435 loss_rnnt 10.875772 hw_loss 0.727263 lr 0.00053834 rank 7
2023-02-11 19:48:55,308 DEBUG TRAIN Batch 10/2900 loss 40.954323 loss_att 41.568310 loss_ctc 66.758400 loss_rnnt 35.644974 hw_loss 0.327377 lr 0.00053837 rank 6
2023-02-11 19:48:55,309 DEBUG TRAIN Batch 10/2900 loss 16.142038 loss_att 16.171371 loss_ctc 20.955767 loss_rnnt 13.062671 hw_loss 0.455938 lr 0.00053822 rank 1
2023-02-11 19:48:55,310 DEBUG TRAIN Batch 10/2900 loss 13.895232 loss_att 19.423458 loss_ctc 21.947155 loss_rnnt 10.047036 hw_loss 0.312930 lr 0.00053815 rank 0
2023-02-11 19:48:55,309 DEBUG TRAIN Batch 10/2900 loss 17.463676 loss_att 16.886751 loss_ctc 24.511332 loss_rnnt 13.102017 hw_loss 0.663254 lr 0.00053832 rank 4
2023-02-11 19:48:55,309 DEBUG TRAIN Batch 10/2900 loss 14.094590 loss_att 16.303226 loss_ctc 16.048386 loss_rnnt 11.306505 hw_loss 0.391097 lr 0.00053808 rank 5
2023-02-11 19:48:55,310 DEBUG TRAIN Batch 10/2900 loss 14.664478 loss_att 18.102861 loss_ctc 24.070976 loss_rnnt 10.174679 hw_loss 0.477735 lr 0.00053800 rank 2
2023-02-11 19:50:11,451 DEBUG TRAIN Batch 10/3000 loss 17.305649 loss_att 19.066607 loss_ctc 17.554312 loss_rnnt 14.961710 hw_loss 0.367236 lr 0.00053802 rank 7
2023-02-11 19:50:11,454 DEBUG TRAIN Batch 10/3000 loss 15.154490 loss_att 17.907433 loss_ctc 25.329966 loss_rnnt 10.375369 hw_loss 0.538463 lr 0.00053791 rank 1
2023-02-11 19:50:11,454 DEBUG TRAIN Batch 10/3000 loss 12.030972 loss_att 13.681911 loss_ctc 18.072842 loss_rnnt 7.567282 hw_loss 0.623985 lr 0.00053801 rank 4
2023-02-11 19:50:11,457 DEBUG TRAIN Batch 10/3000 loss 13.829377 loss_att 15.635307 loss_ctc 18.171371 loss_rnnt 10.741330 hw_loss 0.402737 lr 0.00053784 rank 0
2023-02-11 19:50:11,456 DEBUG TRAIN Batch 10/3000 loss 13.989701 loss_att 15.478166 loss_ctc 19.390900 loss_rnnt 10.283429 hw_loss 0.504079 lr 0.00053808 rank 3
2023-02-11 19:50:11,457 DEBUG TRAIN Batch 10/3000 loss 16.072935 loss_att 19.195822 loss_ctc 22.700939 loss_rnnt 13.359784 hw_loss 0.225907 lr 0.00053806 rank 6
2023-02-11 19:50:11,463 DEBUG TRAIN Batch 10/3000 loss 11.073447 loss_att 13.910336 loss_ctc 16.659933 loss_rnnt 8.290521 hw_loss 0.275753 lr 0.00053769 rank 2
2023-02-11 19:50:11,462 DEBUG TRAIN Batch 10/3000 loss 8.161757 loss_att 11.242396 loss_ctc 9.429420 loss_rnnt 5.423387 hw_loss 0.366229 lr 0.00053777 rank 5
2023-02-11 19:51:27,075 DEBUG TRAIN Batch 10/3100 loss 12.077723 loss_att 13.535030 loss_ctc 16.361450 loss_rnnt 8.716169 hw_loss 0.468549 lr 0.00053777 rank 3
2023-02-11 19:51:27,079 DEBUG TRAIN Batch 10/3100 loss 19.616085 loss_att 18.024063 loss_ctc 24.638643 loss_rnnt 16.358164 hw_loss 0.544997 lr 0.00053771 rank 7
2023-02-11 19:51:27,081 DEBUG TRAIN Batch 10/3100 loss 26.579075 loss_att 28.072992 loss_ctc 42.227131 loss_rnnt 21.956413 hw_loss 0.419525 lr 0.00053746 rank 5
2023-02-11 19:51:27,081 DEBUG TRAIN Batch 10/3100 loss 23.285652 loss_att 23.097561 loss_ctc 27.184774 loss_rnnt 18.232285 hw_loss 0.857082 lr 0.00053759 rank 1
2023-02-11 19:51:27,081 DEBUG TRAIN Batch 10/3100 loss 13.580104 loss_att 10.867436 loss_ctc 15.551767 loss_rnnt 8.454632 hw_loss 1.013459 lr 0.00053770 rank 4
2023-02-11 19:51:27,081 DEBUG TRAIN Batch 10/3100 loss 23.048048 loss_att 25.454626 loss_ctc 33.955425 loss_rnnt 18.614384 hw_loss 0.468381 lr 0.00053775 rank 6
2023-02-11 19:51:27,081 DEBUG TRAIN Batch 10/3100 loss 10.910727 loss_att 9.558752 loss_ctc 11.936393 loss_rnnt 7.634300 hw_loss 0.639387 lr 0.00053753 rank 0
2023-02-11 19:51:27,082 DEBUG TRAIN Batch 10/3100 loss 14.112343 loss_att 16.313755 loss_ctc 19.483152 loss_rnnt 8.724506 hw_loss 0.793396 lr 0.00053738 rank 2
2023-02-11 19:52:46,834 DEBUG TRAIN Batch 10/3200 loss 20.045040 loss_att 20.257393 loss_ctc 33.345947 loss_rnnt 16.138779 hw_loss 0.391938 lr 0.00053722 rank 0
2023-02-11 19:52:46,836 DEBUG TRAIN Batch 10/3200 loss 25.138916 loss_att 30.205112 loss_ctc 43.824429 loss_rnnt 19.512342 hw_loss 0.397863 lr 0.00053728 rank 1
2023-02-11 19:52:46,836 DEBUG TRAIN Batch 10/3200 loss 16.466644 loss_att 16.321377 loss_ctc 22.403723 loss_rnnt 12.005339 hw_loss 0.693515 lr 0.00053715 rank 5
2023-02-11 19:52:46,837 DEBUG TRAIN Batch 10/3200 loss 22.068716 loss_att 23.818008 loss_ctc 33.560944 loss_rnnt 17.737398 hw_loss 0.459218 lr 0.00053740 rank 7
2023-02-11 19:52:46,839 DEBUG TRAIN Batch 10/3200 loss 17.078220 loss_att 19.332998 loss_ctc 24.220306 loss_rnnt 12.844933 hw_loss 0.530635 lr 0.00053746 rank 3
2023-02-11 19:52:46,844 DEBUG TRAIN Batch 10/3200 loss 23.867508 loss_att 24.593603 loss_ctc 39.653137 loss_rnnt 19.754702 hw_loss 0.349282 lr 0.00053739 rank 4
2023-02-11 19:52:46,853 DEBUG TRAIN Batch 10/3200 loss 19.586716 loss_att 15.837349 loss_ctc 23.273743 loss_rnnt 14.227816 hw_loss 1.053219 lr 0.00053707 rank 2
2023-02-11 19:52:46,857 DEBUG TRAIN Batch 10/3200 loss 14.437983 loss_att 12.850588 loss_ctc 16.611313 loss_rnnt 10.836791 hw_loss 0.680418 lr 0.00053744 rank 6
2023-02-11 19:54:01,827 DEBUG TRAIN Batch 10/3300 loss 14.303059 loss_att 16.902554 loss_ctc 20.343163 loss_rnnt 10.372915 hw_loss 0.488418 lr 0.00053691 rank 0
2023-02-11 19:54:01,826 DEBUG TRAIN Batch 10/3300 loss 15.035555 loss_att 12.030098 loss_ctc 19.792059 loss_rnnt 9.364626 hw_loss 1.057091 lr 0.00053713 rank 6
2023-02-11 19:54:01,827 DEBUG TRAIN Batch 10/3300 loss 11.743690 loss_att 16.447945 loss_ctc 18.627033 loss_rnnt 8.684137 hw_loss 0.225173 lr 0.00053715 rank 3
2023-02-11 19:54:01,828 DEBUG TRAIN Batch 10/3300 loss 17.877008 loss_att 19.320673 loss_ctc 23.969086 loss_rnnt 13.605806 hw_loss 0.594411 lr 0.00053709 rank 7
2023-02-11 19:54:01,829 DEBUG TRAIN Batch 10/3300 loss 13.315699 loss_att 17.090601 loss_ctc 23.589399 loss_rnnt 10.069681 hw_loss 0.210227 lr 0.00053676 rank 2
2023-02-11 19:54:01,829 DEBUG TRAIN Batch 10/3300 loss 13.762887 loss_att 18.095612 loss_ctc 21.855103 loss_rnnt 8.620769 hw_loss 0.599364 lr 0.00053708 rank 4
2023-02-11 19:54:01,829 DEBUG TRAIN Batch 10/3300 loss 32.550476 loss_att 31.974777 loss_ctc 42.676537 loss_rnnt 28.810522 hw_loss 0.469678 lr 0.00053697 rank 1
2023-02-11 19:54:01,832 DEBUG TRAIN Batch 10/3300 loss 7.722612 loss_att 10.028530 loss_ctc 11.284218 loss_rnnt 6.101050 hw_loss 0.128531 lr 0.00053684 rank 5
2023-02-11 19:55:18,106 DEBUG TRAIN Batch 10/3400 loss 9.994299 loss_att 12.058950 loss_ctc 15.821346 loss_rnnt 7.645101 hw_loss 0.217374 lr 0.00053645 rank 2
2023-02-11 19:55:18,108 DEBUG TRAIN Batch 10/3400 loss 22.242260 loss_att 20.337761 loss_ctc 33.616753 loss_rnnt 17.559242 hw_loss 0.665122 lr 0.00053684 rank 3
2023-02-11 19:55:18,108 DEBUG TRAIN Batch 10/3400 loss 29.899946 loss_att 32.016289 loss_ctc 38.373096 loss_rnnt 27.220205 hw_loss 0.211260 lr 0.00053660 rank 0
2023-02-11 19:55:18,111 DEBUG TRAIN Batch 10/3400 loss 14.757629 loss_att 17.339830 loss_ctc 28.353176 loss_rnnt 11.391734 hw_loss 0.194384 lr 0.00053666 rank 1
2023-02-11 19:55:18,111 DEBUG TRAIN Batch 10/3400 loss 35.895309 loss_att 37.051056 loss_ctc 57.893723 loss_rnnt 31.587814 hw_loss 0.214354 lr 0.00053653 rank 5
2023-02-11 19:55:18,116 DEBUG TRAIN Batch 10/3400 loss 6.668725 loss_att 10.727226 loss_ctc 10.834247 loss_rnnt 4.234824 hw_loss 0.200025 lr 0.00053678 rank 7
2023-02-11 19:55:18,122 DEBUG TRAIN Batch 10/3400 loss 27.503368 loss_att 30.764418 loss_ctc 44.855492 loss_rnnt 21.055321 hw_loss 0.652917 lr 0.00053677 rank 4
2023-02-11 19:55:18,158 DEBUG TRAIN Batch 10/3400 loss 16.617125 loss_att 22.938225 loss_ctc 20.742851 loss_rnnt 12.456381 hw_loss 0.439955 lr 0.00053682 rank 6
2023-02-11 19:56:35,839 DEBUG TRAIN Batch 10/3500 loss 21.201241 loss_att 25.879871 loss_ctc 29.280258 loss_rnnt 18.390524 hw_loss 0.149585 lr 0.00053615 rank 2
2023-02-11 19:56:35,840 DEBUG TRAIN Batch 10/3500 loss 11.135782 loss_att 11.957899 loss_ctc 12.097616 loss_rnnt 8.068567 hw_loss 0.520227 lr 0.00053653 rank 3
2023-02-11 19:56:35,840 DEBUG TRAIN Batch 10/3500 loss 10.449283 loss_att 13.780102 loss_ctc 20.588137 loss_rnnt 6.579619 hw_loss 0.347185 lr 0.00053636 rank 1
2023-02-11 19:56:35,842 DEBUG TRAIN Batch 10/3500 loss 15.771558 loss_att 17.578241 loss_ctc 25.422688 loss_rnnt 12.257584 hw_loss 0.349841 lr 0.00053629 rank 0
2023-02-11 19:56:35,841 DEBUG TRAIN Batch 10/3500 loss 10.672237 loss_att 18.835367 loss_ctc 16.652870 loss_rnnt 6.397170 hw_loss 0.345942 lr 0.00053647 rank 7
2023-02-11 19:56:35,845 DEBUG TRAIN Batch 10/3500 loss 26.327795 loss_att 30.719147 loss_ctc 58.233028 loss_rnnt 19.812881 hw_loss 0.259240 lr 0.00053622 rank 5
2023-02-11 19:56:35,845 DEBUG TRAIN Batch 10/3500 loss 13.686803 loss_att 15.871691 loss_ctc 17.706917 loss_rnnt 10.849585 hw_loss 0.349542 lr 0.00053651 rank 6
2023-02-11 19:56:35,847 DEBUG TRAIN Batch 10/3500 loss 17.633884 loss_att 20.162811 loss_ctc 28.931591 loss_rnnt 15.343209 hw_loss 0.052224 lr 0.00053646 rank 4
2023-02-11 19:57:52,236 DEBUG TRAIN Batch 10/3600 loss 11.700203 loss_att 14.051401 loss_ctc 16.555183 loss_rnnt 7.446977 hw_loss 0.587935 lr 0.00053598 rank 0
2023-02-11 19:57:52,238 DEBUG TRAIN Batch 10/3600 loss 10.702556 loss_att 13.231936 loss_ctc 16.367851 loss_rnnt 8.540659 hw_loss 0.168871 lr 0.00053622 rank 3
2023-02-11 19:57:52,238 DEBUG TRAIN Batch 10/3600 loss 27.636946 loss_att 29.344612 loss_ctc 43.152409 loss_rnnt 20.750378 hw_loss 0.839307 lr 0.00053615 rank 4
2023-02-11 19:57:52,241 DEBUG TRAIN Batch 10/3600 loss 19.829086 loss_att 17.600241 loss_ctc 25.220604 loss_rnnt 15.738322 hw_loss 0.715812 lr 0.00053616 rank 7
2023-02-11 19:57:52,241 DEBUG TRAIN Batch 10/3600 loss 10.098199 loss_att 12.911667 loss_ctc 12.649786 loss_rnnt 6.992512 hw_loss 0.413022 lr 0.00053605 rank 1
2023-02-11 19:57:52,241 DEBUG TRAIN Batch 10/3600 loss 13.636481 loss_att 16.686615 loss_ctc 19.085262 loss_rnnt 8.329563 hw_loss 0.744447 lr 0.00053584 rank 2
2023-02-11 19:57:52,242 DEBUG TRAIN Batch 10/3600 loss 15.433456 loss_att 18.189032 loss_ctc 21.615831 loss_rnnt 11.284178 hw_loss 0.520096 lr 0.00053591 rank 5
2023-02-11 19:57:52,243 DEBUG TRAIN Batch 10/3600 loss 11.188422 loss_att 14.794365 loss_ctc 20.544643 loss_rnnt 8.762475 hw_loss 0.085737 lr 0.00053620 rank 6
2023-02-11 19:59:07,833 DEBUG TRAIN Batch 10/3700 loss 12.669512 loss_att 13.131264 loss_ctc 19.089684 loss_rnnt 8.804831 hw_loss 0.546808 lr 0.00053586 rank 7
2023-02-11 19:59:07,837 DEBUG TRAIN Batch 10/3700 loss 13.061211 loss_att 12.403530 loss_ctc 15.215996 loss_rnnt 9.626136 hw_loss 0.614870 lr 0.00053591 rank 3
2023-02-11 19:59:07,837 DEBUG TRAIN Batch 10/3700 loss 7.101334 loss_att 10.747440 loss_ctc 11.185421 loss_rnnt 5.271154 hw_loss 0.104328 lr 0.00053574 rank 1
2023-02-11 19:59:07,840 DEBUG TRAIN Batch 10/3700 loss 7.192037 loss_att 9.451693 loss_ctc 11.403044 loss_rnnt 3.584354 hw_loss 0.486428 lr 0.00053567 rank 0
2023-02-11 19:59:07,842 DEBUG TRAIN Batch 10/3700 loss 13.660806 loss_att 15.720924 loss_ctc 17.386292 loss_rnnt 9.215283 hw_loss 0.663144 lr 0.00053589 rank 6
2023-02-11 19:59:07,845 DEBUG TRAIN Batch 10/3700 loss 19.703693 loss_att 18.274427 loss_ctc 28.900085 loss_rnnt 16.066093 hw_loss 0.505737 lr 0.00053584 rank 4
2023-02-11 19:59:07,848 DEBUG TRAIN Batch 10/3700 loss 11.057497 loss_att 11.120605 loss_ctc 14.930990 loss_rnnt 6.682590 hw_loss 0.721091 lr 0.00053560 rank 5
2023-02-11 19:59:07,884 DEBUG TRAIN Batch 10/3700 loss 11.994164 loss_att 15.492599 loss_ctc 17.276344 loss_rnnt 9.881981 hw_loss 0.132789 lr 0.00053553 rank 2
2023-02-11 20:00:24,880 DEBUG TRAIN Batch 10/3800 loss 11.438390 loss_att 11.727517 loss_ctc 16.553001 loss_rnnt 6.563369 hw_loss 0.775359 lr 0.00053543 rank 1
2023-02-11 20:00:24,884 DEBUG TRAIN Batch 10/3800 loss 13.250494 loss_att 16.385397 loss_ctc 21.168005 loss_rnnt 10.417251 hw_loss 0.215737 lr 0.00053558 rank 6
2023-02-11 20:00:24,886 DEBUG TRAIN Batch 10/3800 loss 18.785820 loss_att 20.425219 loss_ctc 24.410568 loss_rnnt 15.295588 hw_loss 0.452322 lr 0.00053522 rank 2
2023-02-11 20:00:24,886 DEBUG TRAIN Batch 10/3800 loss 14.992300 loss_att 15.255066 loss_ctc 22.337622 loss_rnnt 11.146820 hw_loss 0.527541 lr 0.00053536 rank 0
2023-02-11 20:00:24,887 DEBUG TRAIN Batch 10/3800 loss 16.092764 loss_att 20.968569 loss_ctc 30.828026 loss_rnnt 10.058353 hw_loss 0.580228 lr 0.00053555 rank 7
2023-02-11 20:00:24,887 DEBUG TRAIN Batch 10/3800 loss 18.014841 loss_att 18.733587 loss_ctc 27.473616 loss_rnnt 12.586029 hw_loss 0.754480 lr 0.00053561 rank 3
2023-02-11 20:00:24,889 DEBUG TRAIN Batch 10/3800 loss 11.877665 loss_att 8.802044 loss_ctc 12.620869 loss_rnnt 8.070829 hw_loss 0.810537 lr 0.00053553 rank 4
2023-02-11 20:00:24,892 DEBUG TRAIN Batch 10/3800 loss 13.243679 loss_att 13.600651 loss_ctc 14.632051 loss_rnnt 10.041258 hw_loss 0.552358 lr 0.00053530 rank 5
2023-02-11 20:01:43,170 DEBUG TRAIN Batch 10/3900 loss 14.945466 loss_att 17.877438 loss_ctc 20.794621 loss_rnnt 11.249339 hw_loss 0.436846 lr 0.00053530 rank 3
2023-02-11 20:01:43,173 DEBUG TRAIN Batch 10/3900 loss 12.884324 loss_att 18.080017 loss_ctc 28.069960 loss_rnnt 9.099472 hw_loss 0.135180 lr 0.00053524 rank 7
2023-02-11 20:01:43,174 DEBUG TRAIN Batch 10/3900 loss 11.488672 loss_att 14.207186 loss_ctc 16.554106 loss_rnnt 6.937215 hw_loss 0.624818 lr 0.00053513 rank 1
2023-02-11 20:01:43,178 DEBUG TRAIN Batch 10/3900 loss 13.343188 loss_att 15.522055 loss_ctc 21.086647 loss_rnnt 8.680673 hw_loss 0.598928 lr 0.00053528 rank 6
2023-02-11 20:01:43,182 DEBUG TRAIN Batch 10/3900 loss 15.196575 loss_att 14.425004 loss_ctc 23.000830 loss_rnnt 11.157323 hw_loss 0.591187 lr 0.00053499 rank 5
2023-02-11 20:01:43,187 DEBUG TRAIN Batch 10/3900 loss 9.031349 loss_att 11.344942 loss_ctc 9.913980 loss_rnnt 6.353138 hw_loss 0.393339 lr 0.00053506 rank 0
2023-02-11 20:01:43,200 DEBUG TRAIN Batch 10/3900 loss 15.277713 loss_att 21.361841 loss_ctc 23.944668 loss_rnnt 12.528056 hw_loss 0.070732 lr 0.00053523 rank 4
2023-02-11 20:01:43,202 DEBUG TRAIN Batch 10/3900 loss 12.848107 loss_att 18.658861 loss_ctc 21.290316 loss_rnnt 8.770979 hw_loss 0.335503 lr 0.00053492 rank 2
2023-02-11 20:02:59,061 DEBUG TRAIN Batch 10/4000 loss 9.097252 loss_att 10.300874 loss_ctc 12.543482 loss_rnnt 5.547370 hw_loss 0.534311 lr 0.00053475 rank 0
2023-02-11 20:02:59,067 DEBUG TRAIN Batch 10/4000 loss 8.354796 loss_att 8.238667 loss_ctc 12.032717 loss_rnnt 4.149061 hw_loss 0.700982 lr 0.00053468 rank 5
2023-02-11 20:02:59,067 DEBUG TRAIN Batch 10/4000 loss 17.358162 loss_att 18.122667 loss_ctc 24.558281 loss_rnnt 15.259480 hw_loss 0.184831 lr 0.00053494 rank 7
2023-02-11 20:02:59,067 DEBUG TRAIN Batch 10/4000 loss 12.060834 loss_att 13.461737 loss_ctc 13.692740 loss_rnnt 7.735085 hw_loss 0.717746 lr 0.00053482 rank 1
2023-02-11 20:02:59,068 DEBUG TRAIN Batch 10/4000 loss 8.922611 loss_att 12.911828 loss_ctc 16.583223 loss_rnnt 6.145719 hw_loss 0.179556 lr 0.00053492 rank 4
2023-02-11 20:02:59,070 DEBUG TRAIN Batch 10/4000 loss 19.626436 loss_att 23.856630 loss_ctc 30.888866 loss_rnnt 16.363251 hw_loss 0.171654 lr 0.00053499 rank 3
2023-02-11 20:02:59,075 DEBUG TRAIN Batch 10/4000 loss 7.611183 loss_att 9.258802 loss_ctc 16.625162 loss_rnnt 5.314927 hw_loss 0.143413 lr 0.00053497 rank 6
2023-02-11 20:02:59,119 DEBUG TRAIN Batch 10/4000 loss 18.279961 loss_att 19.022877 loss_ctc 28.132679 loss_rnnt 15.224035 hw_loss 0.298809 lr 0.00053461 rank 2
2023-02-11 20:04:14,171 DEBUG TRAIN Batch 10/4100 loss 17.515392 loss_att 21.685455 loss_ctc 32.446308 loss_rnnt 12.924001 hw_loss 0.331236 lr 0.00053445 rank 0
2023-02-11 20:04:14,173 DEBUG TRAIN Batch 10/4100 loss 19.737236 loss_att 24.367016 loss_ctc 33.685860 loss_rnnt 16.547678 hw_loss 0.075710 lr 0.00053431 rank 2
2023-02-11 20:04:14,173 DEBUG TRAIN Batch 10/4100 loss 12.654187 loss_att 15.486032 loss_ctc 18.575300 loss_rnnt 9.035604 hw_loss 0.424262 lr 0.00053466 rank 6
2023-02-11 20:04:14,173 DEBUG TRAIN Batch 10/4100 loss 17.051281 loss_att 24.465824 loss_ctc 36.834011 loss_rnnt 10.318096 hw_loss 0.489858 lr 0.00053463 rank 7
2023-02-11 20:04:14,179 DEBUG TRAIN Batch 10/4100 loss 5.724864 loss_att 8.054811 loss_ctc 10.150257 loss_rnnt 3.447767 hw_loss 0.228948 lr 0.00053438 rank 5
2023-02-11 20:04:14,178 DEBUG TRAIN Batch 10/4100 loss 16.000574 loss_att 15.558804 loss_ctc 19.837273 loss_rnnt 11.100437 hw_loss 0.839424 lr 0.00053469 rank 3
2023-02-11 20:04:14,180 DEBUG TRAIN Batch 10/4100 loss 15.274515 loss_att 16.910364 loss_ctc 19.998409 loss_rnnt 11.218065 hw_loss 0.581142 lr 0.00053461 rank 4
2023-02-11 20:04:14,181 DEBUG TRAIN Batch 10/4100 loss 25.416193 loss_att 25.053816 loss_ctc 34.220833 loss_rnnt 21.686607 hw_loss 0.492771 lr 0.00053451 rank 1
2023-02-11 20:05:30,444 DEBUG TRAIN Batch 10/4200 loss 16.798956 loss_att 15.709024 loss_ctc 20.076639 loss_rnnt 14.913234 hw_loss 0.312503 lr 0.00053438 rank 3
2023-02-11 20:05:30,447 DEBUG TRAIN Batch 10/4200 loss 10.240727 loss_att 11.803719 loss_ctc 13.902776 loss_rnnt 7.161422 hw_loss 0.427206 lr 0.00053432 rank 7
2023-02-11 20:05:30,449 DEBUG TRAIN Batch 10/4200 loss 13.349625 loss_att 14.642378 loss_ctc 19.102226 loss_rnnt 10.616342 hw_loss 0.320197 lr 0.00053400 rank 2
2023-02-11 20:05:30,450 DEBUG TRAIN Batch 10/4200 loss 13.619188 loss_att 18.039167 loss_ctc 22.829550 loss_rnnt 10.195802 hw_loss 0.245877 lr 0.00053436 rank 6
2023-02-11 20:05:30,450 DEBUG TRAIN Batch 10/4200 loss 8.679281 loss_att 9.491992 loss_ctc 9.159628 loss_rnnt 4.690778 hw_loss 0.705359 lr 0.00053431 rank 4
2023-02-11 20:05:30,450 DEBUG TRAIN Batch 10/4200 loss 11.539072 loss_att 16.516743 loss_ctc 17.600040 loss_rnnt 7.718843 hw_loss 0.378106 lr 0.00053414 rank 0
2023-02-11 20:05:30,451 DEBUG TRAIN Batch 10/4200 loss 18.551880 loss_att 22.559935 loss_ctc 29.682705 loss_rnnt 13.971220 hw_loss 0.430301 lr 0.00053421 rank 1
2023-02-11 20:05:30,454 DEBUG TRAIN Batch 10/4200 loss 9.097151 loss_att 14.312845 loss_ctc 12.185535 loss_rnnt 6.036724 hw_loss 0.301032 lr 0.00053407 rank 5
2023-02-11 20:06:49,552 DEBUG TRAIN Batch 10/4300 loss 27.452986 loss_att 32.526546 loss_ctc 44.575130 loss_rnnt 22.666004 hw_loss 0.279246 lr 0.00053408 rank 3
2023-02-11 20:06:49,553 DEBUG TRAIN Batch 10/4300 loss 12.901260 loss_att 13.395015 loss_ctc 18.768757 loss_rnnt 9.858851 hw_loss 0.405248 lr 0.00053402 rank 7
2023-02-11 20:06:49,553 DEBUG TRAIN Batch 10/4300 loss 11.370442 loss_att 13.794781 loss_ctc 16.882660 loss_rnnt 8.389174 hw_loss 0.330270 lr 0.00053370 rank 2
2023-02-11 20:06:49,553 DEBUG TRAIN Batch 10/4300 loss 6.708603 loss_att 9.803152 loss_ctc 11.661760 loss_rnnt 4.485981 hw_loss 0.176867 lr 0.00053384 rank 0
2023-02-11 20:06:49,554 DEBUG TRAIN Batch 10/4300 loss 10.746182 loss_att 14.347187 loss_ctc 15.805365 loss_rnnt 8.181410 hw_loss 0.219378 lr 0.00053377 rank 5
2023-02-11 20:06:49,555 DEBUG TRAIN Batch 10/4300 loss 11.224752 loss_att 12.908167 loss_ctc 17.348326 loss_rnnt 7.311597 hw_loss 0.517499 lr 0.00053405 rank 6
2023-02-11 20:06:49,560 DEBUG TRAIN Batch 10/4300 loss 12.334891 loss_att 14.229057 loss_ctc 18.317957 loss_rnnt 8.148685 hw_loss 0.564306 lr 0.00053390 rank 1
2023-02-11 20:06:49,615 DEBUG TRAIN Batch 10/4300 loss 15.184059 loss_att 14.416763 loss_ctc 18.688051 loss_rnnt 11.695810 hw_loss 0.595220 lr 0.00053400 rank 4
2023-02-11 20:08:05,444 DEBUG TRAIN Batch 10/4400 loss 10.491215 loss_att 7.596627 loss_ctc 9.655574 loss_rnnt 5.587278 hw_loss 1.048926 lr 0.00053371 rank 7
2023-02-11 20:08:05,447 DEBUG TRAIN Batch 10/4400 loss 15.351965 loss_att 25.742176 loss_ctc 27.256161 loss_rnnt 10.558584 hw_loss 0.211521 lr 0.00053347 rank 5
2023-02-11 20:08:05,448 DEBUG TRAIN Batch 10/4400 loss 14.043966 loss_att 10.512655 loss_ctc 16.634487 loss_rnnt 9.940681 hw_loss 0.837027 lr 0.00053377 rank 3
2023-02-11 20:08:05,451 DEBUG TRAIN Batch 10/4400 loss 18.931973 loss_att 22.734081 loss_ctc 27.739765 loss_rnnt 15.029917 hw_loss 0.368861 lr 0.00053375 rank 6
2023-02-11 20:08:05,452 DEBUG TRAIN Batch 10/4400 loss 17.924690 loss_att 19.819725 loss_ctc 24.597504 loss_rnnt 12.932587 hw_loss 0.698135 lr 0.00053370 rank 4
2023-02-11 20:08:05,452 DEBUG TRAIN Batch 10/4400 loss 12.681684 loss_att 11.344721 loss_ctc 20.297159 loss_rnnt 9.302485 hw_loss 0.493349 lr 0.00053360 rank 1
2023-02-11 20:08:05,454 DEBUG TRAIN Batch 10/4400 loss 14.250018 loss_att 13.807163 loss_ctc 17.976423 loss_rnnt 10.248397 hw_loss 0.673751 lr 0.00053353 rank 0
2023-02-11 20:08:05,495 DEBUG TRAIN Batch 10/4400 loss 14.912894 loss_att 17.542351 loss_ctc 23.095274 loss_rnnt 12.566779 hw_loss 0.136733 lr 0.00053339 rank 2
2023-02-11 20:09:21,014 DEBUG TRAIN Batch 10/4500 loss 19.398077 loss_att 21.273382 loss_ctc 27.292191 loss_rnnt 17.244654 hw_loss 0.136090 lr 0.00053347 rank 3
2023-02-11 20:09:21,014 DEBUG TRAIN Batch 10/4500 loss 10.357705 loss_att 12.928275 loss_ctc 13.159157 loss_rnnt 7.066421 hw_loss 0.450683 lr 0.00053344 rank 6
2023-02-11 20:09:21,017 DEBUG TRAIN Batch 10/4500 loss 10.394360 loss_att 16.504045 loss_ctc 17.853638 loss_rnnt 6.872988 hw_loss 0.244662 lr 0.00053341 rank 7
2023-02-11 20:09:21,021 DEBUG TRAIN Batch 10/4500 loss 11.035734 loss_att 7.737535 loss_ctc 11.551174 loss_rnnt 6.825200 hw_loss 0.900272 lr 0.00053309 rank 2
2023-02-11 20:09:21,021 DEBUG TRAIN Batch 10/4500 loss 9.500093 loss_att 12.288973 loss_ctc 16.201374 loss_rnnt 6.769314 hw_loss 0.239906 lr 0.00053323 rank 0
2023-02-11 20:09:21,023 DEBUG TRAIN Batch 10/4500 loss 13.632124 loss_att 15.557094 loss_ctc 22.322111 loss_rnnt 10.912141 hw_loss 0.220561 lr 0.00053316 rank 5
2023-02-11 20:09:21,024 DEBUG TRAIN Batch 10/4500 loss 14.198149 loss_att 15.707302 loss_ctc 24.595154 loss_rnnt 11.424229 hw_loss 0.203592 lr 0.00053330 rank 1
2023-02-11 20:09:21,025 DEBUG TRAIN Batch 10/4500 loss 6.986404 loss_att 10.846892 loss_ctc 11.802249 loss_rnnt 3.515101 hw_loss 0.385705 lr 0.00053340 rank 4
2023-02-11 20:10:39,695 DEBUG TRAIN Batch 10/4600 loss 16.631937 loss_att 20.656229 loss_ctc 35.541374 loss_rnnt 12.534733 hw_loss 0.144579 lr 0.00053317 rank 3
2023-02-11 20:10:39,701 DEBUG TRAIN Batch 10/4600 loss 12.637459 loss_att 7.615989 loss_ctc 11.066250 loss_rnnt 7.483293 hw_loss 1.193992 lr 0.00053286 rank 5
2023-02-11 20:10:39,703 DEBUG TRAIN Batch 10/4600 loss 5.388007 loss_att 10.135298 loss_ctc 12.006285 loss_rnnt 2.354806 hw_loss 0.225245 lr 0.00053293 rank 0
2023-02-11 20:10:39,703 DEBUG TRAIN Batch 10/4600 loss 9.099137 loss_att 12.457762 loss_ctc 13.768105 loss_rnnt 7.029294 hw_loss 0.145423 lr 0.00053311 rank 7
2023-02-11 20:10:39,705 DEBUG TRAIN Batch 10/4600 loss 11.379976 loss_att 14.564670 loss_ctc 17.233686 loss_rnnt 7.365086 hw_loss 0.487023 lr 0.00053299 rank 1
2023-02-11 20:10:39,706 DEBUG TRAIN Batch 10/4600 loss 10.583519 loss_att 11.921616 loss_ctc 17.789852 loss_rnnt 7.110029 hw_loss 0.420943 lr 0.00053309 rank 4
2023-02-11 20:10:39,707 DEBUG TRAIN Batch 10/4600 loss 24.609781 loss_att 26.544811 loss_ctc 36.488350 loss_rnnt 20.620758 hw_loss 0.378414 lr 0.00053279 rank 2
2023-02-11 20:10:39,710 DEBUG TRAIN Batch 10/4600 loss 17.728529 loss_att 16.639414 loss_ctc 26.007086 loss_rnnt 14.258715 hw_loss 0.484468 lr 0.00053314 rank 6
2023-02-11 20:11:56,074 DEBUG TRAIN Batch 10/4700 loss 14.913037 loss_att 18.147308 loss_ctc 23.336552 loss_rnnt 11.517776 hw_loss 0.304738 lr 0.00053281 rank 7
2023-02-11 20:11:56,078 DEBUG TRAIN Batch 10/4700 loss 22.723858 loss_att 25.268873 loss_ctc 37.822220 loss_rnnt 18.589193 hw_loss 0.302352 lr 0.00053262 rank 0
2023-02-11 20:11:56,081 DEBUG TRAIN Batch 10/4700 loss 8.098449 loss_att 11.660119 loss_ctc 13.334627 loss_rnnt 5.248336 hw_loss 0.269929 lr 0.00053256 rank 5
2023-02-11 20:11:56,082 DEBUG TRAIN Batch 10/4700 loss 11.335598 loss_att 15.426636 loss_ctc 19.232384 loss_rnnt 7.922939 hw_loss 0.289040 lr 0.00053269 rank 1
2023-02-11 20:11:56,083 DEBUG TRAIN Batch 10/4700 loss 13.461812 loss_att 13.226933 loss_ctc 19.957878 loss_rnnt 7.355653 hw_loss 0.991311 lr 0.00053248 rank 2
2023-02-11 20:11:56,083 DEBUG TRAIN Batch 10/4700 loss 6.728617 loss_att 9.100245 loss_ctc 10.294897 loss_rnnt 2.693081 hw_loss 0.578570 lr 0.00053286 rank 3
2023-02-11 20:11:56,083 DEBUG TRAIN Batch 10/4700 loss 16.229082 loss_att 21.738598 loss_ctc 29.644545 loss_rnnt 11.122524 hw_loss 0.415486 lr 0.00053284 rank 6
2023-02-11 20:11:56,125 DEBUG TRAIN Batch 10/4700 loss 17.713104 loss_att 19.563034 loss_ctc 27.837048 loss_rnnt 13.745243 hw_loss 0.421503 lr 0.00053279 rank 4
2023-02-11 20:13:10,864 DEBUG TRAIN Batch 10/4800 loss 11.416353 loss_att 13.434958 loss_ctc 20.384773 loss_rnnt 8.495075 hw_loss 0.247831 lr 0.00053256 rank 3
2023-02-11 20:13:10,868 DEBUG TRAIN Batch 10/4800 loss 19.978615 loss_att 21.336323 loss_ctc 34.262592 loss_rnnt 15.044796 hw_loss 0.517077 lr 0.00053239 rank 1
2023-02-11 20:13:10,871 DEBUG TRAIN Batch 10/4800 loss 32.593208 loss_att 35.981628 loss_ctc 43.458427 loss_rnnt 27.481819 hw_loss 0.559689 lr 0.00053250 rank 7
2023-02-11 20:13:10,876 DEBUG TRAIN Batch 10/4800 loss 16.108858 loss_att 17.003130 loss_ctc 21.011477 loss_rnnt 12.423684 hw_loss 0.534870 lr 0.00053232 rank 0
2023-02-11 20:13:10,876 DEBUG TRAIN Batch 10/4800 loss 23.774166 loss_att 23.469414 loss_ctc 33.229855 loss_rnnt 20.463280 hw_loss 0.395827 lr 0.00053254 rank 6
2023-02-11 20:13:10,877 DEBUG TRAIN Batch 10/4800 loss 9.904286 loss_att 15.141109 loss_ctc 16.875288 loss_rnnt 7.009055 hw_loss 0.172200 lr 0.00053226 rank 5
2023-02-11 20:13:10,878 DEBUG TRAIN Batch 10/4800 loss 11.093392 loss_att 14.144211 loss_ctc 18.689850 loss_rnnt 7.633251 hw_loss 0.344459 lr 0.00053218 rank 2
2023-02-11 20:13:10,881 DEBUG TRAIN Batch 10/4800 loss 14.994062 loss_att 15.939657 loss_ctc 19.505512 loss_rnnt 11.368359 hw_loss 0.531573 lr 0.00053249 rank 4
2023-02-11 20:14:26,259 DEBUG TRAIN Batch 10/4900 loss 16.445255 loss_att 17.868771 loss_ctc 23.665474 loss_rnnt 11.845095 hw_loss 0.628642 lr 0.00053188 rank 2
2023-02-11 20:14:26,258 DEBUG TRAIN Batch 10/4900 loss 9.192884 loss_att 11.094789 loss_ctc 16.346436 loss_rnnt 6.895591 hw_loss 0.180582 lr 0.00053223 rank 6
2023-02-11 20:14:26,259 DEBUG TRAIN Batch 10/4900 loss 15.025740 loss_att 16.514616 loss_ctc 21.994947 loss_rnnt 13.501024 hw_loss 0.055821 lr 0.00053219 rank 4
2023-02-11 20:14:26,262 DEBUG TRAIN Batch 10/4900 loss 8.383038 loss_att 9.792259 loss_ctc 12.238523 loss_rnnt 5.020597 hw_loss 0.481225 lr 0.00053220 rank 7
2023-02-11 20:14:26,262 DEBUG TRAIN Batch 10/4900 loss 13.778773 loss_att 19.756313 loss_ctc 27.423815 loss_rnnt 9.252812 hw_loss 0.283333 lr 0.00053195 rank 5
2023-02-11 20:14:26,263 DEBUG TRAIN Batch 10/4900 loss 13.182446 loss_att 15.358781 loss_ctc 17.382061 loss_rnnt 10.015249 hw_loss 0.407246 lr 0.00053209 rank 1
2023-02-11 20:14:26,264 DEBUG TRAIN Batch 10/4900 loss 8.588492 loss_att 10.859853 loss_ctc 14.665858 loss_rnnt 4.843531 hw_loss 0.465070 lr 0.00053226 rank 3
2023-02-11 20:14:26,264 DEBUG TRAIN Batch 10/4900 loss 17.737595 loss_att 19.517427 loss_ctc 25.136709 loss_rnnt 15.283096 hw_loss 0.208497 lr 0.00053202 rank 0
2023-02-11 20:15:45,591 DEBUG TRAIN Batch 10/5000 loss 11.782128 loss_att 11.768650 loss_ctc 13.619888 loss_rnnt 9.640259 hw_loss 0.356162 lr 0.00053196 rank 3
2023-02-11 20:15:45,591 DEBUG TRAIN Batch 10/5000 loss 17.661259 loss_att 18.630722 loss_ctc 26.990017 loss_rnnt 13.978516 hw_loss 0.420941 lr 0.00053158 rank 2
2023-02-11 20:15:45,594 DEBUG TRAIN Batch 10/5000 loss 11.194437 loss_att 12.842403 loss_ctc 15.596132 loss_rnnt 9.090819 hw_loss 0.222587 lr 0.00053179 rank 1
2023-02-11 20:15:45,593 DEBUG TRAIN Batch 10/5000 loss 12.439078 loss_att 14.750906 loss_ctc 21.295700 loss_rnnt 9.651876 hw_loss 0.214491 lr 0.00053165 rank 5
2023-02-11 20:15:45,594 DEBUG TRAIN Batch 10/5000 loss 13.477260 loss_att 13.702186 loss_ctc 19.100187 loss_rnnt 9.762765 hw_loss 0.547460 lr 0.00053193 rank 6
2023-02-11 20:15:45,594 DEBUG TRAIN Batch 10/5000 loss 11.510035 loss_att 11.355133 loss_ctc 16.801460 loss_rnnt 5.963758 hw_loss 0.913450 lr 0.00053190 rank 7
2023-02-11 20:15:45,594 DEBUG TRAIN Batch 10/5000 loss 19.612692 loss_att 23.082420 loss_ctc 20.710310 loss_rnnt 16.475143 hw_loss 0.430735 lr 0.00053188 rank 4
2023-02-11 20:15:45,596 DEBUG TRAIN Batch 10/5000 loss 20.393110 loss_att 23.435791 loss_ctc 29.716314 loss_rnnt 16.853889 hw_loss 0.316423 lr 0.00053172 rank 0
2023-02-11 20:17:02,460 DEBUG TRAIN Batch 10/5100 loss 19.286247 loss_att 16.252855 loss_ctc 23.410967 loss_rnnt 14.153413 hw_loss 0.973041 lr 0.00053142 rank 0
2023-02-11 20:17:02,461 DEBUG TRAIN Batch 10/5100 loss 12.229414 loss_att 12.857985 loss_ctc 14.986112 loss_rnnt 7.164751 hw_loss 0.857136 lr 0.00053148 rank 1
2023-02-11 20:17:02,462 DEBUG TRAIN Batch 10/5100 loss 15.837692 loss_att 15.638448 loss_ctc 20.228483 loss_rnnt 14.784909 hw_loss 0.095099 lr 0.00053135 rank 5
2023-02-11 20:17:02,463 DEBUG TRAIN Batch 10/5100 loss 9.922276 loss_att 6.751154 loss_ctc 8.164263 loss_rnnt 5.399617 hw_loss 1.010866 lr 0.00053158 rank 4
2023-02-11 20:17:02,463 DEBUG TRAIN Batch 10/5100 loss 9.123005 loss_att 14.586210 loss_ctc 16.912048 loss_rnnt 5.522646 hw_loss 0.275471 lr 0.00053160 rank 7
2023-02-11 20:17:02,467 DEBUG TRAIN Batch 10/5100 loss 11.355207 loss_att 13.715303 loss_ctc 14.695099 loss_rnnt 10.162246 hw_loss 0.051679 lr 0.00053163 rank 6
2023-02-11 20:17:02,469 DEBUG TRAIN Batch 10/5100 loss 17.948416 loss_att 19.246025 loss_ctc 27.161827 loss_rnnt 14.437124 hw_loss 0.379372 lr 0.00053128 rank 2
2023-02-11 20:17:02,470 DEBUG TRAIN Batch 10/5100 loss 20.478043 loss_att 19.444931 loss_ctc 26.921921 loss_rnnt 16.415251 hw_loss 0.639418 lr 0.00053166 rank 3
2023-02-11 20:18:19,002 DEBUG TRAIN Batch 10/5200 loss 16.954815 loss_att 19.655010 loss_ctc 21.750082 loss_rnnt 14.926250 hw_loss 0.159217 lr 0.00053136 rank 3
2023-02-11 20:18:19,007 DEBUG TRAIN Batch 10/5200 loss 21.731831 loss_att 28.508175 loss_ctc 24.561733 loss_rnnt 18.394909 hw_loss 0.300812 lr 0.00053112 rank 0
2023-02-11 20:18:19,010 DEBUG TRAIN Batch 10/5200 loss 24.316774 loss_att 24.342049 loss_ctc 38.204552 loss_rnnt 19.424107 hw_loss 0.569233 lr 0.00053130 rank 7
2023-02-11 20:18:19,010 DEBUG TRAIN Batch 10/5200 loss 14.158970 loss_att 18.097740 loss_ctc 25.849697 loss_rnnt 9.487457 hw_loss 0.435936 lr 0.00053133 rank 6
2023-02-11 20:18:19,010 DEBUG TRAIN Batch 10/5200 loss 21.783882 loss_att 23.672567 loss_ctc 30.683578 loss_rnnt 16.438618 hw_loss 0.708918 lr 0.00053098 rank 2
2023-02-11 20:18:19,015 DEBUG TRAIN Batch 10/5200 loss 10.937499 loss_att 11.676993 loss_ctc 11.333035 loss_rnnt 8.022774 hw_loss 0.508892 lr 0.00053118 rank 1
2023-02-11 20:18:19,016 DEBUG TRAIN Batch 10/5200 loss 12.009488 loss_att 10.838783 loss_ctc 17.582724 loss_rnnt 8.234553 hw_loss 0.612371 lr 0.00053105 rank 5
2023-02-11 20:18:19,017 DEBUG TRAIN Batch 10/5200 loss 11.243318 loss_att 16.104118 loss_ctc 22.052015 loss_rnnt 8.265146 hw_loss 0.105910 lr 0.00053128 rank 4
2023-02-11 20:19:36,610 DEBUG TRAIN Batch 10/5300 loss 15.689896 loss_att 19.132442 loss_ctc 27.706127 loss_rnnt 10.699948 hw_loss 0.506114 lr 0.00053100 rank 7
2023-02-11 20:19:36,611 DEBUG TRAIN Batch 10/5300 loss 9.855537 loss_att 11.012390 loss_ctc 13.662756 loss_rnnt 8.078461 hw_loss 0.194640 lr 0.00053106 rank 3
2023-02-11 20:19:36,614 DEBUG TRAIN Batch 10/5300 loss 14.502195 loss_att 18.488102 loss_ctc 25.528940 loss_rnnt 9.214865 hw_loss 0.566234 lr 0.00053103 rank 6
2023-02-11 20:19:36,614 DEBUG TRAIN Batch 10/5300 loss 10.099186 loss_att 14.346567 loss_ctc 20.192373 loss_rnnt 5.952515 hw_loss 0.365894 lr 0.00053082 rank 0
2023-02-11 20:19:36,617 DEBUG TRAIN Batch 10/5300 loss 12.724039 loss_att 13.944704 loss_ctc 18.978024 loss_rnnt 8.015273 hw_loss 0.680769 lr 0.00053089 rank 1
2023-02-11 20:19:36,618 DEBUG TRAIN Batch 10/5300 loss 16.889292 loss_att 20.012432 loss_ctc 26.698223 loss_rnnt 13.031237 hw_loss 0.361044 lr 0.00053075 rank 5
2023-02-11 20:19:36,619 DEBUG TRAIN Batch 10/5300 loss 19.007561 loss_att 22.836214 loss_ctc 27.325735 loss_rnnt 15.784546 hw_loss 0.252787 lr 0.00053098 rank 4
2023-02-11 20:19:36,657 DEBUG TRAIN Batch 10/5300 loss 9.999066 loss_att 17.371517 loss_ctc 17.091721 loss_rnnt 6.599237 hw_loss 0.183685 lr 0.00053068 rank 2
2023-02-11 20:20:53,699 DEBUG TRAIN Batch 10/5400 loss 11.540858 loss_att 15.916851 loss_ctc 20.597878 loss_rnnt 7.896907 hw_loss 0.292716 lr 0.00053076 rank 3
2023-02-11 20:20:53,701 DEBUG TRAIN Batch 10/5400 loss 12.428421 loss_att 13.438025 loss_ctc 18.175350 loss_rnnt 8.925869 hw_loss 0.475195 lr 0.00053038 rank 2
2023-02-11 20:20:53,704 DEBUG TRAIN Batch 10/5400 loss 8.499504 loss_att 12.758103 loss_ctc 13.382581 loss_rnnt 6.178115 hw_loss 0.153486 lr 0.00053070 rank 7
2023-02-11 20:20:53,705 DEBUG TRAIN Batch 10/5400 loss 15.072859 loss_att 14.146044 loss_ctc 20.646202 loss_rnnt 9.740747 hw_loss 0.895193 lr 0.00053046 rank 5
2023-02-11 20:20:53,708 DEBUG TRAIN Batch 10/5400 loss 8.085384 loss_att 10.312432 loss_ctc 13.388433 loss_rnnt 4.290593 hw_loss 0.495433 lr 0.00053059 rank 1
2023-02-11 20:20:53,708 DEBUG TRAIN Batch 10/5400 loss 11.106611 loss_att 11.702071 loss_ctc 13.767837 loss_rnnt 7.608476 hw_loss 0.567040 lr 0.00053052 rank 0
2023-02-11 20:20:53,708 DEBUG TRAIN Batch 10/5400 loss 9.757724 loss_att 12.172250 loss_ctc 14.708163 loss_rnnt 4.564277 hw_loss 0.759466 lr 0.00053069 rank 4
2023-02-11 20:20:53,709 DEBUG TRAIN Batch 10/5400 loss 13.573282 loss_att 16.382133 loss_ctc 27.446491 loss_rnnt 9.909324 hw_loss 0.234830 lr 0.00053073 rank 6
2023-02-11 20:22:10,009 DEBUG TRAIN Batch 10/5500 loss 14.665784 loss_att 14.357578 loss_ctc 24.050591 loss_rnnt 11.682283 hw_loss 0.336344 lr 0.00053046 rank 3
2023-02-11 20:22:10,011 DEBUG TRAIN Batch 10/5500 loss 15.272306 loss_att 15.960618 loss_ctc 25.787949 loss_rnnt 12.602863 hw_loss 0.211818 lr 0.00053040 rank 7
2023-02-11 20:22:10,017 DEBUG TRAIN Batch 10/5500 loss 12.914603 loss_att 14.329019 loss_ctc 20.698496 loss_rnnt 7.954865 hw_loss 0.682313 lr 0.00053022 rank 0
2023-02-11 20:22:10,024 DEBUG TRAIN Batch 10/5500 loss 19.886055 loss_att 21.438736 loss_ctc 31.584642 loss_rnnt 16.350611 hw_loss 0.312205 lr 0.00053043 rank 6
2023-02-11 20:22:10,025 DEBUG TRAIN Batch 10/5500 loss 7.621301 loss_att 8.857637 loss_ctc 9.527113 loss_rnnt 4.992994 hw_loss 0.398799 lr 0.00053039 rank 4
2023-02-11 20:22:10,025 DEBUG TRAIN Batch 10/5500 loss 23.073524 loss_att 24.033033 loss_ctc 34.830822 loss_rnnt 18.832226 hw_loss 0.465329 lr 0.00053016 rank 5
2023-02-11 20:22:10,028 DEBUG TRAIN Batch 10/5500 loss 19.640310 loss_att 19.615686 loss_ctc 24.450939 loss_rnnt 15.989847 hw_loss 0.565119 lr 0.00053029 rank 1
2023-02-11 20:22:10,063 DEBUG TRAIN Batch 10/5500 loss 21.146423 loss_att 24.245142 loss_ctc 28.244143 loss_rnnt 17.825912 hw_loss 0.328951 lr 0.00053009 rank 2
2023-02-11 20:23:25,947 DEBUG TRAIN Batch 10/5600 loss 15.604328 loss_att 18.350731 loss_ctc 21.237902 loss_rnnt 11.680747 hw_loss 0.491842 lr 0.00052992 rank 0
2023-02-11 20:23:25,948 DEBUG TRAIN Batch 10/5600 loss 17.103109 loss_att 15.941273 loss_ctc 24.865997 loss_rnnt 12.645713 hw_loss 0.685258 lr 0.00053016 rank 3
2023-02-11 20:23:25,949 DEBUG TRAIN Batch 10/5600 loss 13.783380 loss_att 17.679792 loss_ctc 26.897686 loss_rnnt 10.289285 hw_loss 0.181169 lr 0.00052979 rank 2
2023-02-11 20:23:25,951 DEBUG TRAIN Batch 10/5600 loss 13.118427 loss_att 16.459423 loss_ctc 21.385767 loss_rnnt 9.766829 hw_loss 0.296454 lr 0.00053009 rank 4
2023-02-11 20:23:25,952 DEBUG TRAIN Batch 10/5600 loss 12.608516 loss_att 9.768756 loss_ctc 18.194174 loss_rnnt 8.262079 hw_loss 0.781806 lr 0.00053014 rank 6
2023-02-11 20:23:25,952 DEBUG TRAIN Batch 10/5600 loss 7.488609 loss_att 12.777332 loss_ctc 14.417881 loss_rnnt 4.412859 hw_loss 0.205144 lr 0.00052986 rank 5
2023-02-11 20:23:25,956 DEBUG TRAIN Batch 10/5600 loss 20.624182 loss_att 19.332090 loss_ctc 20.835440 loss_rnnt 15.932526 hw_loss 0.922858 lr 0.00053010 rank 7
2023-02-11 20:23:25,998 DEBUG TRAIN Batch 10/5600 loss 19.645557 loss_att 23.382015 loss_ctc 31.857143 loss_rnnt 16.032310 hw_loss 0.232076 lr 0.00052999 rank 1
2023-02-11 20:24:45,124 DEBUG TRAIN Batch 10/5700 loss 19.265947 loss_att 17.251385 loss_ctc 22.917952 loss_rnnt 14.880750 hw_loss 0.806471 lr 0.00052949 rank 2
2023-02-11 20:24:45,128 DEBUG TRAIN Batch 10/5700 loss 13.985620 loss_att 12.705105 loss_ctc 19.290293 loss_rnnt 10.911907 hw_loss 0.491724 lr 0.00052969 rank 1
2023-02-11 20:24:45,129 DEBUG TRAIN Batch 10/5700 loss 10.134729 loss_att 15.333467 loss_ctc 20.022236 loss_rnnt 7.322696 hw_loss 0.085116 lr 0.00052984 rank 6
2023-02-11 20:24:45,129 DEBUG TRAIN Batch 10/5700 loss 13.319589 loss_att 16.215601 loss_ctc 16.394550 loss_rnnt 10.827785 hw_loss 0.281739 lr 0.00052986 rank 3
2023-02-11 20:24:45,129 DEBUG TRAIN Batch 10/5700 loss 16.116880 loss_att 13.451220 loss_ctc 17.801376 loss_rnnt 10.736613 hw_loss 1.066650 lr 0.00052963 rank 0
2023-02-11 20:24:45,130 DEBUG TRAIN Batch 10/5700 loss 14.755075 loss_att 16.781536 loss_ctc 23.212130 loss_rnnt 9.533701 hw_loss 0.691589 lr 0.00052956 rank 5
2023-02-11 20:24:45,130 DEBUG TRAIN Batch 10/5700 loss 14.182873 loss_att 16.635971 loss_ctc 21.913895 loss_rnnt 11.388523 hw_loss 0.238674 lr 0.00052981 rank 7
2023-02-11 20:24:45,134 DEBUG TRAIN Batch 10/5700 loss 14.158599 loss_att 12.101082 loss_ctc 15.304626 loss_rnnt 11.012972 hw_loss 0.638311 lr 0.00052979 rank 4
2023-02-11 20:26:02,330 DEBUG TRAIN Batch 10/5800 loss 17.361576 loss_att 21.215975 loss_ctc 31.111473 loss_rnnt 12.019069 hw_loss 0.513433 lr 0.00052951 rank 7
2023-02-11 20:26:02,330 DEBUG TRAIN Batch 10/5800 loss 15.253282 loss_att 19.768120 loss_ctc 24.886944 loss_rnnt 11.188334 hw_loss 0.352030 lr 0.00052956 rank 3
2023-02-11 20:26:02,336 DEBUG TRAIN Batch 10/5800 loss 21.036419 loss_att 24.547235 loss_ctc 31.340567 loss_rnnt 14.894056 hw_loss 0.762433 lr 0.00052949 rank 4
2023-02-11 20:26:02,336 DEBUG TRAIN Batch 10/5800 loss 10.289065 loss_att 13.152992 loss_ctc 13.742659 loss_rnnt 7.510839 hw_loss 0.327180 lr 0.00052933 rank 0
2023-02-11 20:26:02,337 DEBUG TRAIN Batch 10/5800 loss 14.027968 loss_att 19.198551 loss_ctc 28.744062 loss_rnnt 9.875204 hw_loss 0.216844 lr 0.00052954 rank 6
2023-02-11 20:26:02,337 DEBUG TRAIN Batch 10/5800 loss 10.761312 loss_att 11.646907 loss_ctc 12.200915 loss_rnnt 6.686488 hw_loss 0.694830 lr 0.00052927 rank 5
2023-02-11 20:26:02,340 DEBUG TRAIN Batch 10/5800 loss 13.363747 loss_att 15.722754 loss_ctc 17.220537 loss_rnnt 8.985496 hw_loss 0.636040 lr 0.00052919 rank 2
2023-02-11 20:26:02,376 DEBUG TRAIN Batch 10/5800 loss 27.628897 loss_att 27.136459 loss_ctc 40.115128 loss_rnnt 24.070618 hw_loss 0.373488 lr 0.00052940 rank 1
2023-02-11 20:27:18,258 DEBUG TRAIN Batch 10/5900 loss 12.459824 loss_att 15.165523 loss_ctc 19.073896 loss_rnnt 9.232589 hw_loss 0.338291 lr 0.00052927 rank 3
2023-02-11 20:27:18,261 DEBUG TRAIN Batch 10/5900 loss 24.468096 loss_att 25.269123 loss_ctc 32.461197 loss_rnnt 19.379604 hw_loss 0.724226 lr 0.00052920 rank 4
2023-02-11 20:27:18,262 DEBUG TRAIN Batch 10/5900 loss 12.906693 loss_att 16.451740 loss_ctc 19.152828 loss_rnnt 7.795043 hw_loss 0.669341 lr 0.00052924 rank 6
2023-02-11 20:27:18,263 DEBUG TRAIN Batch 10/5900 loss 17.591501 loss_att 19.592113 loss_ctc 27.295197 loss_rnnt 13.490039 hw_loss 0.451409 lr 0.00052903 rank 0
2023-02-11 20:27:18,264 DEBUG TRAIN Batch 10/5900 loss 10.347996 loss_att 13.029210 loss_ctc 13.613678 loss_rnnt 8.196036 hw_loss 0.221305 lr 0.00052897 rank 5
2023-02-11 20:27:18,265 DEBUG TRAIN Batch 10/5900 loss 18.784838 loss_att 21.161501 loss_ctc 26.751951 loss_rnnt 13.588031 hw_loss 0.686099 lr 0.00052910 rank 1
2023-02-11 20:27:18,266 DEBUG TRAIN Batch 10/5900 loss 7.260164 loss_att 12.515833 loss_ctc 11.649887 loss_rnnt 4.249983 hw_loss 0.257578 lr 0.00052921 rank 7
2023-02-11 20:27:18,322 DEBUG TRAIN Batch 10/5900 loss 14.730668 loss_att 18.418930 loss_ctc 24.724142 loss_rnnt 11.077246 hw_loss 0.296870 lr 0.00052890 rank 2
2023-02-11 20:28:36,172 DEBUG TRAIN Batch 10/6000 loss 12.130253 loss_att 14.285218 loss_ctc 20.746864 loss_rnnt 8.789051 hw_loss 0.330249 lr 0.00052897 rank 3
2023-02-11 20:28:36,174 DEBUG TRAIN Batch 10/6000 loss 15.927217 loss_att 21.290947 loss_ctc 26.800680 loss_rnnt 12.074862 hw_loss 0.249340 lr 0.00052867 rank 5
2023-02-11 20:28:36,175 DEBUG TRAIN Batch 10/6000 loss 16.763374 loss_att 18.249220 loss_ctc 20.321217 loss_rnnt 13.144622 hw_loss 0.533851 lr 0.00052895 rank 6
2023-02-11 20:28:36,175 DEBUG TRAIN Batch 10/6000 loss 8.722460 loss_att 11.869312 loss_ctc 11.819778 loss_rnnt 6.543655 hw_loss 0.213086 lr 0.00052874 rank 0
2023-02-11 20:28:36,176 DEBUG TRAIN Batch 10/6000 loss 16.480072 loss_att 15.802891 loss_ctc 21.187864 loss_rnnt 14.434120 hw_loss 0.291315 lr 0.00052892 rank 7
2023-02-11 20:28:36,177 DEBUG TRAIN Batch 10/6000 loss 12.834063 loss_att 17.456264 loss_ctc 23.127995 loss_rnnt 7.362501 hw_loss 0.595237 lr 0.00052890 rank 4
2023-02-11 20:28:36,193 DEBUG TRAIN Batch 10/6000 loss 13.508667 loss_att 15.960770 loss_ctc 17.151005 loss_rnnt 8.028658 hw_loss 0.844489 lr 0.00052860 rank 2
2023-02-11 20:28:36,201 DEBUG TRAIN Batch 10/6000 loss 15.193729 loss_att 18.987835 loss_ctc 32.766140 loss_rnnt 10.873441 hw_loss 0.228465 lr 0.00052880 rank 1
2023-02-11 20:29:54,294 DEBUG TRAIN Batch 10/6100 loss 15.594641 loss_att 19.071434 loss_ctc 20.483810 loss_rnnt 12.178926 hw_loss 0.387838 lr 0.00052868 rank 3
2023-02-11 20:29:54,297 DEBUG TRAIN Batch 10/6100 loss 22.682821 loss_att 26.066240 loss_ctc 37.918365 loss_rnnt 16.179337 hw_loss 0.711637 lr 0.00052844 rank 0
2023-02-11 20:29:54,297 DEBUG TRAIN Batch 10/6100 loss 17.356565 loss_att 18.617792 loss_ctc 25.003271 loss_rnnt 13.821930 hw_loss 0.424281 lr 0.00052851 rank 1
2023-02-11 20:29:54,299 DEBUG TRAIN Batch 10/6100 loss 14.421767 loss_att 16.092321 loss_ctc 20.661636 loss_rnnt 10.838108 hw_loss 0.453294 lr 0.00052862 rank 7
2023-02-11 20:29:54,302 DEBUG TRAIN Batch 10/6100 loss 25.378548 loss_att 24.700815 loss_ctc 33.749176 loss_rnnt 23.258163 hw_loss 0.213721 lr 0.00052831 rank 2
2023-02-11 20:29:54,302 DEBUG TRAIN Batch 10/6100 loss 19.084541 loss_att 22.061131 loss_ctc 27.654282 loss_rnnt 15.942646 hw_loss 0.263240 lr 0.00052838 rank 5
2023-02-11 20:29:54,304 DEBUG TRAIN Batch 10/6100 loss 18.601202 loss_att 22.170368 loss_ctc 25.142056 loss_rnnt 12.910044 hw_loss 0.769727 lr 0.00052861 rank 4
2023-02-11 20:29:54,306 DEBUG TRAIN Batch 10/6100 loss 17.925653 loss_att 17.566042 loss_ctc 21.479912 loss_rnnt 12.928724 hw_loss 0.861553 lr 0.00052865 rank 6
2023-02-11 20:31:10,846 DEBUG TRAIN Batch 10/6200 loss 8.122345 loss_att 10.794554 loss_ctc 14.278811 loss_rnnt 4.831501 hw_loss 0.362914 lr 0.00052832 rank 7
2023-02-11 20:31:10,849 DEBUG TRAIN Batch 10/6200 loss 20.133425 loss_att 21.671253 loss_ctc 31.272949 loss_rnnt 15.154389 hw_loss 0.597412 lr 0.00052815 rank 0
2023-02-11 20:31:10,855 DEBUG TRAIN Batch 10/6200 loss 11.964790 loss_att 12.920880 loss_ctc 14.961725 loss_rnnt 6.987273 hw_loss 0.822508 lr 0.00052838 rank 3
2023-02-11 20:31:10,855 DEBUG TRAIN Batch 10/6200 loss 7.874718 loss_att 10.652725 loss_ctc 10.721130 loss_rnnt 5.092266 hw_loss 0.346374 lr 0.00052836 rank 6
2023-02-11 20:31:10,859 DEBUG TRAIN Batch 10/6200 loss 10.715314 loss_att 12.407625 loss_ctc 18.394873 loss_rnnt 7.515962 hw_loss 0.344428 lr 0.00052821 rank 1
2023-02-11 20:31:10,859 DEBUG TRAIN Batch 10/6200 loss 13.419769 loss_att 15.725081 loss_ctc 17.054655 loss_rnnt 10.629240 hw_loss 0.345903 lr 0.00052808 rank 5
2023-02-11 20:31:10,861 DEBUG TRAIN Batch 10/6200 loss 11.012648 loss_att 13.258228 loss_ctc 13.493558 loss_rnnt 7.981136 hw_loss 0.422176 lr 0.00052831 rank 4
2023-02-11 20:31:10,862 DEBUG TRAIN Batch 10/6200 loss 21.537376 loss_att 23.556833 loss_ctc 33.878571 loss_rnnt 15.822562 hw_loss 0.687268 lr 0.00052801 rank 2
2023-02-11 20:32:26,926 DEBUG TRAIN Batch 10/6300 loss 12.958570 loss_att 14.772540 loss_ctc 20.404324 loss_rnnt 8.075236 hw_loss 0.661457 lr 0.00052772 rank 2
2023-02-11 20:32:26,928 DEBUG TRAIN Batch 10/6300 loss 13.888649 loss_att 10.910085 loss_ctc 18.086277 loss_rnnt 9.060160 hw_loss 0.912097 lr 0.00052806 rank 6
2023-02-11 20:32:26,930 DEBUG TRAIN Batch 10/6300 loss 15.365654 loss_att 11.780508 loss_ctc 15.472577 loss_rnnt 9.631245 hw_loss 1.206972 lr 0.00052803 rank 7
2023-02-11 20:32:26,931 DEBUG TRAIN Batch 10/6300 loss 8.646883 loss_att 6.744256 loss_ctc 8.630389 loss_rnnt 4.782859 hw_loss 0.796265 lr 0.00052809 rank 3
2023-02-11 20:32:26,931 DEBUG TRAIN Batch 10/6300 loss 14.273087 loss_att 14.306164 loss_ctc 18.120668 loss_rnnt 11.595171 hw_loss 0.404679 lr 0.00052792 rank 1
2023-02-11 20:32:26,933 DEBUG TRAIN Batch 10/6300 loss 24.731167 loss_att 24.853289 loss_ctc 37.662258 loss_rnnt 20.118307 hw_loss 0.537055 lr 0.00052785 rank 0
2023-02-11 20:32:26,936 DEBUG TRAIN Batch 10/6300 loss 24.310453 loss_att 24.835423 loss_ctc 31.472366 loss_rnnt 19.353683 hw_loss 0.730661 lr 0.00052779 rank 5
2023-02-11 20:32:26,936 DEBUG TRAIN Batch 10/6300 loss 14.230375 loss_att 13.657570 loss_ctc 16.498240 loss_rnnt 10.101262 hw_loss 0.738992 lr 0.00052802 rank 4
2023-02-11 20:33:45,305 DEBUG TRAIN Batch 10/6400 loss 33.624088 loss_att 34.838139 loss_ctc 51.300873 loss_rnnt 29.828278 hw_loss 0.224268 lr 0.00052774 rank 7
2023-02-11 20:33:45,307 DEBUG TRAIN Batch 10/6400 loss 23.884197 loss_att 27.233583 loss_ctc 40.919281 loss_rnnt 19.905144 hw_loss 0.194593 lr 0.00052779 rank 3
2023-02-11 20:33:45,308 DEBUG TRAIN Batch 10/6400 loss 20.428194 loss_att 24.407631 loss_ctc 29.609722 loss_rnnt 17.463171 hw_loss 0.177175 lr 0.00052777 rank 6
2023-02-11 20:33:45,308 DEBUG TRAIN Batch 10/6400 loss 9.790627 loss_att 14.132420 loss_ctc 13.249549 loss_rnnt 7.547338 hw_loss 0.171326 lr 0.00052762 rank 1
2023-02-11 20:33:45,310 DEBUG TRAIN Batch 10/6400 loss 15.451105 loss_att 12.146050 loss_ctc 17.020996 loss_rnnt 11.123091 hw_loss 0.896195 lr 0.00052742 rank 2
2023-02-11 20:33:45,313 DEBUG TRAIN Batch 10/6400 loss 22.487595 loss_att 24.380970 loss_ctc 34.589775 loss_rnnt 19.068588 hw_loss 0.267507 lr 0.00052756 rank 0
2023-02-11 20:33:45,314 DEBUG TRAIN Batch 10/6400 loss 23.984333 loss_att 23.482206 loss_ctc 31.167440 loss_rnnt 19.608355 hw_loss 0.659748 lr 0.00052749 rank 5
2023-02-11 20:33:45,317 DEBUG TRAIN Batch 10/6400 loss 15.554593 loss_att 22.065613 loss_ctc 20.319632 loss_rnnt 10.669162 hw_loss 0.552729 lr 0.00052772 rank 4
2023-02-11 20:35:01,006 DEBUG TRAIN Batch 10/6500 loss 18.055450 loss_att 20.171909 loss_ctc 23.459373 loss_rnnt 14.456589 hw_loss 0.460321 lr 0.00052727 rank 0
2023-02-11 20:35:01,012 DEBUG TRAIN Batch 10/6500 loss 11.130427 loss_att 17.749987 loss_ctc 15.115417 loss_rnnt 7.329448 hw_loss 0.364825 lr 0.00052743 rank 4
2023-02-11 20:35:01,011 DEBUG TRAIN Batch 10/6500 loss 12.954193 loss_att 11.820227 loss_ctc 20.207483 loss_rnnt 9.934363 hw_loss 0.427410 lr 0.00052747 rank 6
2023-02-11 20:35:01,015 DEBUG TRAIN Batch 10/6500 loss 11.523283 loss_att 13.090102 loss_ctc 19.589060 loss_rnnt 8.672626 hw_loss 0.274098 lr 0.00052713 rank 2
2023-02-11 20:35:01,015 DEBUG TRAIN Batch 10/6500 loss 22.131195 loss_att 21.857473 loss_ctc 29.521933 loss_rnnt 18.407516 hw_loss 0.523685 lr 0.00052720 rank 5
2023-02-11 20:35:01,015 DEBUG TRAIN Batch 10/6500 loss 6.314939 loss_att 9.932342 loss_ctc 6.933071 loss_rnnt 2.899768 hw_loss 0.489239 lr 0.00052750 rank 3
2023-02-11 20:35:01,016 DEBUG TRAIN Batch 10/6500 loss 20.978422 loss_att 25.762619 loss_ctc 33.969109 loss_rnnt 17.347324 hw_loss 0.176656 lr 0.00052744 rank 7
2023-02-11 20:35:01,016 DEBUG TRAIN Batch 10/6500 loss 6.289898 loss_att 8.565643 loss_ctc 10.892866 loss_rnnt 2.541510 hw_loss 0.502408 lr 0.00052733 rank 1
2023-02-11 20:36:16,114 DEBUG TRAIN Batch 10/6600 loss 13.100965 loss_att 17.190098 loss_ctc 15.165995 loss_rnnt 11.439054 hw_loss 0.106640 lr 0.00052715 rank 7
2023-02-11 20:36:16,118 DEBUG TRAIN Batch 10/6600 loss 15.096917 loss_att 18.551968 loss_ctc 23.013351 loss_rnnt 11.560765 hw_loss 0.335553 lr 0.00052720 rank 3
2023-02-11 20:36:16,118 DEBUG TRAIN Batch 10/6600 loss 13.962308 loss_att 16.692636 loss_ctc 20.690041 loss_rnnt 10.773978 hw_loss 0.327231 lr 0.00052697 rank 0
2023-02-11 20:36:16,119 DEBUG TRAIN Batch 10/6600 loss 15.077389 loss_att 15.857584 loss_ctc 21.389780 loss_rnnt 10.057856 hw_loss 0.754096 lr 0.00052718 rank 6
2023-02-11 20:36:16,124 DEBUG TRAIN Batch 10/6600 loss 13.902501 loss_att 13.797349 loss_ctc 21.215347 loss_rnnt 8.614740 hw_loss 0.812577 lr 0.00052713 rank 4
2023-02-11 20:36:16,125 DEBUG TRAIN Batch 10/6600 loss 34.496613 loss_att 37.031841 loss_ctc 41.239979 loss_rnnt 30.943447 hw_loss 0.402563 lr 0.00052691 rank 5
2023-02-11 20:36:16,126 DEBUG TRAIN Batch 10/6600 loss 10.004300 loss_att 14.071552 loss_ctc 15.635831 loss_rnnt 7.586554 hw_loss 0.160017 lr 0.00052704 rank 1
2023-02-11 20:36:16,127 DEBUG TRAIN Batch 10/6600 loss 24.432692 loss_att 25.232660 loss_ctc 35.701424 loss_rnnt 20.733002 hw_loss 0.381975 lr 0.00052684 rank 2
2023-02-11 20:37:34,456 DEBUG TRAIN Batch 10/6700 loss 15.426216 loss_att 18.888615 loss_ctc 24.860020 loss_rnnt 12.074310 hw_loss 0.262797 lr 0.00052655 rank 2
2023-02-11 20:37:34,457 DEBUG TRAIN Batch 10/6700 loss 12.172706 loss_att 12.422039 loss_ctc 14.485081 loss_rnnt 9.491470 hw_loss 0.435572 lr 0.00052691 rank 3
2023-02-11 20:37:34,458 DEBUG TRAIN Batch 10/6700 loss 11.549297 loss_att 12.576291 loss_ctc 16.357597 loss_rnnt 8.482013 hw_loss 0.416396 lr 0.00052689 rank 6
2023-02-11 20:37:34,459 DEBUG TRAIN Batch 10/6700 loss 20.544931 loss_att 23.161961 loss_ctc 31.480892 loss_rnnt 17.213219 hw_loss 0.253159 lr 0.00052674 rank 1
2023-02-11 20:37:34,460 DEBUG TRAIN Batch 10/6700 loss 11.787317 loss_att 16.789642 loss_ctc 15.369991 loss_rnnt 8.835729 hw_loss 0.276269 lr 0.00052668 rank 0
2023-02-11 20:37:34,462 DEBUG TRAIN Batch 10/6700 loss 17.147713 loss_att 20.396559 loss_ctc 36.110077 loss_rnnt 12.485216 hw_loss 0.278327 lr 0.00052684 rank 4
2023-02-11 20:37:34,465 DEBUG TRAIN Batch 10/6700 loss 9.489917 loss_att 14.262836 loss_ctc 22.159031 loss_rnnt 4.602508 hw_loss 0.420677 lr 0.00052662 rank 5
2023-02-11 20:37:34,465 DEBUG TRAIN Batch 10/6700 loss 12.969384 loss_att 15.027678 loss_ctc 19.562710 loss_rnnt 9.778541 hw_loss 0.356264 lr 0.00052686 rank 7
2023-02-11 20:38:52,445 DEBUG TRAIN Batch 10/6800 loss 15.245567 loss_att 14.944532 loss_ctc 28.802338 loss_rnnt 11.216386 hw_loss 0.427841 lr 0.00052639 rank 0
2023-02-11 20:38:52,445 DEBUG TRAIN Batch 10/6800 loss 18.915388 loss_att 19.138437 loss_ctc 27.962982 loss_rnnt 14.534966 hw_loss 0.586775 lr 0.00052656 rank 7
2023-02-11 20:38:52,447 DEBUG TRAIN Batch 10/6800 loss 11.234190 loss_att 12.601545 loss_ctc 16.489975 loss_rnnt 8.129301 hw_loss 0.399496 lr 0.00052660 rank 6
2023-02-11 20:38:52,449 DEBUG TRAIN Batch 10/6800 loss 15.272454 loss_att 15.381850 loss_ctc 20.317253 loss_rnnt 12.388519 hw_loss 0.410515 lr 0.00052645 rank 1
2023-02-11 20:38:52,449 DEBUG TRAIN Batch 10/6800 loss 13.044557 loss_att 13.738256 loss_ctc 19.456079 loss_rnnt 8.484630 hw_loss 0.668685 lr 0.00052662 rank 3
2023-02-11 20:38:52,451 DEBUG TRAIN Batch 10/6800 loss 11.040805 loss_att 12.110800 loss_ctc 16.301327 loss_rnnt 8.168579 hw_loss 0.366904 lr 0.00052632 rank 5
2023-02-11 20:38:52,453 DEBUG TRAIN Batch 10/6800 loss 9.379406 loss_att 13.378318 loss_ctc 13.338224 loss_rnnt 6.539401 hw_loss 0.283571 lr 0.00052655 rank 4
2023-02-11 20:38:52,497 DEBUG TRAIN Batch 10/6800 loss 5.703704 loss_att 7.274670 loss_ctc 9.183634 loss_rnnt 3.647187 hw_loss 0.239687 lr 0.00052625 rank 2
2023-02-11 20:40:10,387 DEBUG TRAIN Batch 10/6900 loss 15.307251 loss_att 13.454077 loss_ctc 16.253325 loss_rnnt 11.360183 hw_loss 0.785917 lr 0.00052627 rank 7
2023-02-11 20:40:10,391 DEBUG TRAIN Batch 10/6900 loss 20.628960 loss_att 17.439714 loss_ctc 26.382677 loss_rnnt 16.201033 hw_loss 0.805990 lr 0.00052633 rank 3
2023-02-11 20:40:10,391 DEBUG TRAIN Batch 10/6900 loss 16.325592 loss_att 15.351377 loss_ctc 25.013815 loss_rnnt 12.348882 hw_loss 0.564960 lr 0.00052630 rank 6
2023-02-11 20:40:10,392 DEBUG TRAIN Batch 10/6900 loss 11.250033 loss_att 15.588095 loss_ctc 20.315233 loss_rnnt 9.037944 hw_loss 0.025460 lr 0.00052610 rank 0
2023-02-11 20:40:10,394 DEBUG TRAIN Batch 10/6900 loss 13.021406 loss_att 12.110336 loss_ctc 20.584101 loss_rnnt 9.336286 hw_loss 0.536058 lr 0.00052596 rank 2
2023-02-11 20:40:10,397 DEBUG TRAIN Batch 10/6900 loss 8.969637 loss_att 10.035980 loss_ctc 12.442946 loss_rnnt 6.452658 hw_loss 0.345113 lr 0.00052626 rank 4
2023-02-11 20:40:10,397 DEBUG TRAIN Batch 10/6900 loss 22.841923 loss_att 27.189228 loss_ctc 38.630253 loss_rnnt 17.040283 hw_loss 0.530075 lr 0.00052603 rank 5
2023-02-11 20:40:10,448 DEBUG TRAIN Batch 10/6900 loss 16.504435 loss_att 18.606449 loss_ctc 26.630289 loss_rnnt 11.962224 hw_loss 0.519692 lr 0.00052616 rank 1
2023-02-11 20:41:25,895 DEBUG TRAIN Batch 10/7000 loss 18.832771 loss_att 15.372660 loss_ctc 20.772886 loss_rnnt 13.034503 hw_loss 1.168427 lr 0.00052581 rank 0
2023-02-11 20:41:25,897 DEBUG TRAIN Batch 10/7000 loss 11.085986 loss_att 12.934906 loss_ctc 17.374733 loss_rnnt 6.802457 hw_loss 0.576608 lr 0.00052598 rank 7
2023-02-11 20:41:25,897 DEBUG TRAIN Batch 10/7000 loss 13.728371 loss_att 15.383018 loss_ctc 22.940876 loss_rnnt 8.939319 hw_loss 0.605585 lr 0.00052567 rank 2
2023-02-11 20:41:25,898 DEBUG TRAIN Batch 10/7000 loss 16.521643 loss_att 25.020391 loss_ctc 29.750839 loss_rnnt 12.073908 hw_loss 0.184517 lr 0.00052604 rank 3
2023-02-11 20:41:25,900 DEBUG TRAIN Batch 10/7000 loss 14.113509 loss_att 18.024740 loss_ctc 21.930098 loss_rnnt 11.910981 hw_loss 0.070888 lr 0.00052574 rank 5
2023-02-11 20:41:25,900 DEBUG TRAIN Batch 10/7000 loss 10.782015 loss_att 8.417564 loss_ctc 12.252831 loss_rnnt 6.660823 hw_loss 0.824620 lr 0.00052597 rank 4
2023-02-11 20:41:25,902 DEBUG TRAIN Batch 10/7000 loss 10.547518 loss_att 7.445430 loss_ctc 8.116068 loss_rnnt 5.544719 hw_loss 1.115139 lr 0.00052601 rank 6
2023-02-11 20:41:25,904 DEBUG TRAIN Batch 10/7000 loss 10.926444 loss_att 14.462135 loss_ctc 15.363528 loss_rnnt 9.093769 hw_loss 0.100111 lr 0.00052587 rank 1
2023-02-11 20:42:44,241 DEBUG TRAIN Batch 10/7100 loss 14.535902 loss_att 18.537201 loss_ctc 24.784515 loss_rnnt 11.435352 hw_loss 0.175089 lr 0.00052575 rank 3
2023-02-11 20:42:44,243 DEBUG TRAIN Batch 10/7100 loss 10.503926 loss_att 13.227121 loss_ctc 14.775764 loss_rnnt 6.611809 hw_loss 0.520856 lr 0.00052552 rank 0
2023-02-11 20:42:44,249 DEBUG TRAIN Batch 10/7100 loss 16.923346 loss_att 19.583820 loss_ctc 25.143919 loss_rnnt 12.106606 hw_loss 0.597856 lr 0.00052545 rank 5
2023-02-11 20:42:44,249 DEBUG TRAIN Batch 10/7100 loss 13.859713 loss_att 17.597534 loss_ctc 24.838400 loss_rnnt 9.831096 hw_loss 0.340730 lr 0.00052538 rank 2
2023-02-11 20:42:44,249 DEBUG TRAIN Batch 10/7100 loss 10.411318 loss_att 14.145927 loss_ctc 11.915058 loss_rnnt 8.309057 hw_loss 0.216532 lr 0.00052568 rank 4
2023-02-11 20:42:44,250 DEBUG TRAIN Batch 10/7100 loss 9.445789 loss_att 8.988251 loss_ctc 8.994576 loss_rnnt 5.467438 hw_loss 0.774379 lr 0.00052558 rank 1
2023-02-11 20:42:44,251 DEBUG TRAIN Batch 10/7100 loss 13.172165 loss_att 14.749589 loss_ctc 18.085232 loss_rnnt 9.748693 hw_loss 0.459921 lr 0.00052569 rank 7
2023-02-11 20:42:44,253 DEBUG TRAIN Batch 10/7100 loss 10.294311 loss_att 13.193891 loss_ctc 12.544361 loss_rnnt 9.358829 hw_loss 0.010417 lr 0.00052572 rank 6
2023-02-11 20:44:01,277 DEBUG TRAIN Batch 10/7200 loss 11.860090 loss_att 14.603258 loss_ctc 18.786617 loss_rnnt 8.181285 hw_loss 0.413744 lr 0.00052545 rank 3
2023-02-11 20:44:01,283 DEBUG TRAIN Batch 10/7200 loss 11.994529 loss_att 13.620250 loss_ctc 15.913035 loss_rnnt 9.893242 hw_loss 0.235064 lr 0.00052509 rank 2
2023-02-11 20:44:01,286 DEBUG TRAIN Batch 10/7200 loss 21.776125 loss_att 26.208044 loss_ctc 33.237164 loss_rnnt 17.450790 hw_loss 0.358277 lr 0.00052540 rank 7
2023-02-11 20:44:01,287 DEBUG TRAIN Batch 10/7200 loss 24.789711 loss_att 28.428701 loss_ctc 33.584801 loss_rnnt 20.775829 hw_loss 0.396264 lr 0.00052523 rank 0
2023-02-11 20:44:01,287 DEBUG TRAIN Batch 10/7200 loss 2.689234 loss_att 5.343919 loss_ctc 4.814451 loss_rnnt 0.735454 hw_loss 0.213653 lr 0.00052516 rank 5
2023-02-11 20:44:01,289 DEBUG TRAIN Batch 10/7200 loss 26.007519 loss_att 31.039474 loss_ctc 39.078873 loss_rnnt 20.716780 hw_loss 0.476532 lr 0.00052529 rank 1
2023-02-11 20:44:01,290 DEBUG TRAIN Batch 10/7200 loss 12.936625 loss_att 15.355235 loss_ctc 22.174856 loss_rnnt 9.534316 hw_loss 0.316279 lr 0.00052539 rank 4
2023-02-11 20:44:01,336 DEBUG TRAIN Batch 10/7200 loss 17.240938 loss_att 22.303677 loss_ctc 26.795773 loss_rnnt 13.866837 hw_loss 0.203920 lr 0.00052543 rank 6
2023-02-11 20:45:15,811 DEBUG TRAIN Batch 10/7300 loss 8.573738 loss_att 9.157454 loss_ctc 12.940551 loss_rnnt 4.266566 hw_loss 0.676535 lr 0.00052511 rank 7
2023-02-11 20:45:15,814 DEBUG TRAIN Batch 10/7300 loss 8.702394 loss_att 12.639791 loss_ctc 11.293328 loss_rnnt 5.446846 hw_loss 0.397989 lr 0.00052500 rank 1
2023-02-11 20:45:15,815 DEBUG TRAIN Batch 10/7300 loss 15.168586 loss_att 15.605295 loss_ctc 20.963196 loss_rnnt 11.192054 hw_loss 0.584358 lr 0.00052514 rank 6
2023-02-11 20:45:15,815 DEBUG TRAIN Batch 10/7300 loss 19.968842 loss_att 22.411886 loss_ctc 28.015856 loss_rnnt 15.853617 hw_loss 0.478815 lr 0.00052516 rank 3
2023-02-11 20:45:15,818 DEBUG TRAIN Batch 10/7300 loss 20.513538 loss_att 22.995296 loss_ctc 31.543446 loss_rnnt 15.786311 hw_loss 0.517542 lr 0.00052510 rank 4
2023-02-11 20:45:15,819 DEBUG TRAIN Batch 10/7300 loss 9.243807 loss_att 12.051022 loss_ctc 14.146980 loss_rnnt 5.587908 hw_loss 0.457631 lr 0.00052494 rank 0
2023-02-11 20:45:15,820 DEBUG TRAIN Batch 10/7300 loss 5.199337 loss_att 9.377367 loss_ctc 11.398495 loss_rnnt 2.749882 hw_loss 0.147618 lr 0.00052487 rank 5
2023-02-11 20:45:15,822 DEBUG TRAIN Batch 10/7300 loss 10.358150 loss_att 10.483330 loss_ctc 14.327270 loss_rnnt 5.995009 hw_loss 0.714167 lr 0.00052480 rank 2
2023-02-11 20:46:32,882 DEBUG TRAIN Batch 10/7400 loss 19.970509 loss_att 22.173235 loss_ctc 27.625900 loss_rnnt 17.105110 hw_loss 0.263275 lr 0.00052451 rank 2
2023-02-11 20:46:32,885 DEBUG TRAIN Batch 10/7400 loss 7.493773 loss_att 9.529811 loss_ctc 9.170879 loss_rnnt 5.643416 hw_loss 0.228663 lr 0.00052458 rank 5
2023-02-11 20:46:32,886 DEBUG TRAIN Batch 10/7400 loss 16.909348 loss_att 23.112850 loss_ctc 24.754520 loss_rnnt 11.773085 hw_loss 0.534289 lr 0.00052485 rank 6
2023-02-11 20:46:32,886 DEBUG TRAIN Batch 10/7400 loss 13.628888 loss_att 15.705414 loss_ctc 24.906754 loss_rnnt 9.876426 hw_loss 0.343770 lr 0.00052488 rank 3
2023-02-11 20:46:32,888 DEBUG TRAIN Batch 10/7400 loss 24.429562 loss_att 26.101656 loss_ctc 35.271797 loss_rnnt 19.059473 hw_loss 0.673132 lr 0.00052482 rank 7
2023-02-11 20:46:32,890 DEBUG TRAIN Batch 10/7400 loss 12.172892 loss_att 13.563364 loss_ctc 17.832081 loss_rnnt 7.492120 hw_loss 0.684022 lr 0.00052471 rank 1
2023-02-11 20:46:32,890 DEBUG TRAIN Batch 10/7400 loss 10.164648 loss_att 13.416960 loss_ctc 20.494209 loss_rnnt 6.230380 hw_loss 0.357474 lr 0.00052465 rank 0
2023-02-11 20:46:32,937 DEBUG TRAIN Batch 10/7400 loss 14.708391 loss_att 15.530234 loss_ctc 23.727104 loss_rnnt 10.672712 hw_loss 0.500403 lr 0.00052481 rank 4
2023-02-11 20:47:51,505 DEBUG TRAIN Batch 10/7500 loss 11.908104 loss_att 9.970669 loss_ctc 14.311724 loss_rnnt 7.113914 hw_loss 0.911474 lr 0.00052459 rank 3
2023-02-11 20:47:51,508 DEBUG TRAIN Batch 10/7500 loss 14.523660 loss_att 15.986248 loss_ctc 16.307743 loss_rnnt 11.257580 hw_loss 0.512941 lr 0.00052423 rank 2
2023-02-11 20:47:51,508 DEBUG TRAIN Batch 10/7500 loss 4.007053 loss_att 7.275550 loss_ctc 5.444123 loss_rnnt 2.218259 hw_loss 0.176904 lr 0.00052430 rank 5
2023-02-11 20:47:51,511 DEBUG TRAIN Batch 10/7500 loss 11.799555 loss_att 12.005836 loss_ctc 11.752344 loss_rnnt 8.158668 hw_loss 0.676111 lr 0.00052452 rank 4
2023-02-11 20:47:51,510 DEBUG TRAIN Batch 10/7500 loss 12.431739 loss_att 11.380672 loss_ctc 16.234449 loss_rnnt 7.817632 hw_loss 0.809492 lr 0.00052442 rank 1
2023-02-11 20:47:51,513 DEBUG TRAIN Batch 10/7500 loss 16.725233 loss_att 19.399569 loss_ctc 28.480528 loss_rnnt 11.596438 hw_loss 0.567479 lr 0.00052453 rank 7
2023-02-11 20:47:51,513 DEBUG TRAIN Batch 10/7500 loss 25.537994 loss_att 25.701441 loss_ctc 37.591904 loss_rnnt 21.224539 hw_loss 0.501296 lr 0.00052436 rank 0
2023-02-11 20:47:51,562 DEBUG TRAIN Batch 10/7500 loss 17.705324 loss_att 18.938213 loss_ctc 20.841190 loss_rnnt 13.604101 hw_loss 0.644350 lr 0.00052456 rank 6
2023-02-11 20:49:08,755 DEBUG TRAIN Batch 10/7600 loss 15.852705 loss_att 18.675360 loss_ctc 24.857788 loss_rnnt 11.909178 hw_loss 0.408435 lr 0.00052424 rank 7
2023-02-11 20:49:08,756 DEBUG TRAIN Batch 10/7600 loss 20.788397 loss_att 22.866428 loss_ctc 38.350159 loss_rnnt 16.545395 hw_loss 0.278593 lr 0.00052430 rank 3
2023-02-11 20:49:08,764 DEBUG TRAIN Batch 10/7600 loss 14.900318 loss_att 15.460912 loss_ctc 24.967588 loss_rnnt 11.261050 hw_loss 0.409659 lr 0.00052394 rank 2
2023-02-11 20:49:08,764 DEBUG TRAIN Batch 10/7600 loss 17.089790 loss_att 20.055389 loss_ctc 26.456442 loss_rnnt 13.665834 hw_loss 0.296615 lr 0.00052423 rank 4
2023-02-11 20:49:08,764 DEBUG TRAIN Batch 10/7600 loss 12.241555 loss_att 14.638073 loss_ctc 19.288647 loss_rnnt 8.425581 hw_loss 0.449448 lr 0.00052407 rank 0
2023-02-11 20:49:08,766 DEBUG TRAIN Batch 10/7600 loss 8.811946 loss_att 13.372627 loss_ctc 14.090364 loss_rnnt 5.174610 hw_loss 0.379014 lr 0.00052413 rank 1
2023-02-11 20:49:08,770 DEBUG TRAIN Batch 10/7600 loss 19.980766 loss_att 22.139145 loss_ctc 23.821831 loss_rnnt 15.132213 hw_loss 0.732138 lr 0.00052401 rank 5
2023-02-11 20:49:08,812 DEBUG TRAIN Batch 10/7600 loss 16.421488 loss_att 20.709337 loss_ctc 28.865067 loss_rnnt 12.556345 hw_loss 0.252830 lr 0.00052427 rank 6
2023-02-11 20:50:24,002 DEBUG TRAIN Batch 10/7700 loss 10.901999 loss_att 12.734878 loss_ctc 13.632354 loss_rnnt 8.328636 hw_loss 0.345514 lr 0.00052365 rank 2
2023-02-11 20:50:24,008 DEBUG TRAIN Batch 10/7700 loss 16.738852 loss_att 23.658949 loss_ctc 29.775452 loss_rnnt 12.906961 hw_loss 0.133061 lr 0.00052401 rank 3
2023-02-11 20:50:24,010 DEBUG TRAIN Batch 10/7700 loss 15.506451 loss_att 16.789799 loss_ctc 18.316078 loss_rnnt 12.793425 hw_loss 0.390326 lr 0.00052378 rank 0
2023-02-11 20:50:24,011 DEBUG TRAIN Batch 10/7700 loss 9.500391 loss_att 9.031487 loss_ctc 9.695368 loss_rnnt 6.332714 hw_loss 0.606649 lr 0.00052396 rank 7
2023-02-11 20:50:24,011 DEBUG TRAIN Batch 10/7700 loss 10.218864 loss_att 11.653250 loss_ctc 14.248293 loss_rnnt 7.290355 hw_loss 0.394570 lr 0.00052394 rank 4
2023-02-11 20:50:24,011 DEBUG TRAIN Batch 10/7700 loss 26.606405 loss_att 28.513233 loss_ctc 34.838959 loss_rnnt 22.040455 hw_loss 0.578795 lr 0.00052385 rank 1
2023-02-11 20:50:24,013 DEBUG TRAIN Batch 10/7700 loss 21.116735 loss_att 19.933155 loss_ctc 27.815020 loss_rnnt 16.555464 hw_loss 0.732166 lr 0.00052372 rank 5
2023-02-11 20:50:24,015 DEBUG TRAIN Batch 10/7700 loss 11.270647 loss_att 11.416208 loss_ctc 14.561436 loss_rnnt 8.011580 hw_loss 0.523347 lr 0.00052399 rank 6
2023-02-11 20:51:42,130 DEBUG TRAIN Batch 10/7800 loss 27.372377 loss_att 31.750793 loss_ctc 42.364609 loss_rnnt 23.246250 hw_loss 0.234652 lr 0.00052367 rank 7
2023-02-11 20:51:42,131 DEBUG TRAIN Batch 10/7800 loss 13.153564 loss_att 13.394258 loss_ctc 15.587480 loss_rnnt 11.082211 hw_loss 0.318505 lr 0.00052372 rank 3
2023-02-11 20:51:42,131 DEBUG TRAIN Batch 10/7800 loss 11.141740 loss_att 14.870361 loss_ctc 21.410343 loss_rnnt 8.597315 hw_loss 0.080541 lr 0.00052336 rank 2
2023-02-11 20:51:42,132 DEBUG TRAIN Batch 10/7800 loss 14.522453 loss_att 15.577915 loss_ctc 21.117727 loss_rnnt 9.561636 hw_loss 0.725691 lr 0.00052370 rank 6
2023-02-11 20:51:42,134 DEBUG TRAIN Batch 10/7800 loss 9.684036 loss_att 10.107966 loss_ctc 11.586409 loss_rnnt 6.563642 hw_loss 0.521617 lr 0.00052343 rank 5
2023-02-11 20:51:42,139 DEBUG TRAIN Batch 10/7800 loss 10.809031 loss_att 8.999328 loss_ctc 14.415510 loss_rnnt 9.115578 hw_loss 0.295225 lr 0.00052356 rank 1
2023-02-11 20:51:42,141 DEBUG TRAIN Batch 10/7800 loss 19.978607 loss_att 20.158461 loss_ctc 30.923264 loss_rnnt 17.239828 hw_loss 0.233160 lr 0.00052350 rank 0
2023-02-11 20:51:42,142 DEBUG TRAIN Batch 10/7800 loss 10.920472 loss_att 11.792452 loss_ctc 13.585377 loss_rnnt 7.823666 hw_loss 0.481329 lr 0.00052365 rank 4
2023-02-11 20:52:57,962 DEBUG TRAIN Batch 10/7900 loss 13.773351 loss_att 15.955479 loss_ctc 24.032089 loss_rnnt 8.233397 hw_loss 0.700443 lr 0.00052321 rank 0
2023-02-11 20:52:57,963 DEBUG TRAIN Batch 10/7900 loss 27.133408 loss_att 31.548506 loss_ctc 38.564873 loss_rnnt 21.517483 hw_loss 0.601633 lr 0.00052338 rank 7
2023-02-11 20:52:57,966 DEBUG TRAIN Batch 10/7900 loss 11.810619 loss_att 13.646475 loss_ctc 13.375293 loss_rnnt 8.363818 hw_loss 0.538314 lr 0.00052308 rank 2
2023-02-11 20:52:57,966 DEBUG TRAIN Batch 10/7900 loss 12.003743 loss_att 14.425845 loss_ctc 16.747351 loss_rnnt 8.975296 hw_loss 0.358415 lr 0.00052344 rank 3
2023-02-11 20:52:57,967 DEBUG TRAIN Batch 10/7900 loss 26.774549 loss_att 29.737713 loss_ctc 42.569984 loss_rnnt 22.498501 hw_loss 0.295755 lr 0.00052327 rank 1
2023-02-11 20:52:57,969 DEBUG TRAIN Batch 10/7900 loss 12.700768 loss_att 13.604376 loss_ctc 23.960659 loss_rnnt 8.669174 hw_loss 0.440542 lr 0.00052341 rank 6
2023-02-11 20:52:57,972 DEBUG TRAIN Batch 10/7900 loss 25.041395 loss_att 29.909748 loss_ctc 44.522125 loss_rnnt 18.342400 hw_loss 0.586480 lr 0.00052337 rank 4
2023-02-11 20:52:57,976 DEBUG TRAIN Batch 10/7900 loss 15.118558 loss_att 17.881018 loss_ctc 30.388271 loss_rnnt 12.100590 hw_loss 0.080534 lr 0.00052315 rank 5
2023-02-11 20:54:12,902 DEBUG TRAIN Batch 10/8000 loss 16.970951 loss_att 17.687378 loss_ctc 21.889980 loss_rnnt 12.808544 hw_loss 0.630610 lr 0.00052309 rank 7
2023-02-11 20:54:12,905 DEBUG TRAIN Batch 10/8000 loss 14.668047 loss_att 17.897675 loss_ctc 19.685892 loss_rnnt 10.288723 hw_loss 0.574566 lr 0.00052308 rank 4
2023-02-11 20:54:12,908 DEBUG TRAIN Batch 10/8000 loss 7.903538 loss_att 8.442673 loss_ctc 8.093699 loss_rnnt 5.196416 hw_loss 0.482614 lr 0.00052292 rank 0
2023-02-11 20:54:12,909 DEBUG TRAIN Batch 10/8000 loss 13.634193 loss_att 16.570021 loss_ctc 26.864241 loss_rnnt 10.777065 hw_loss 0.094867 lr 0.00052286 rank 5
2023-02-11 20:54:12,909 DEBUG TRAIN Batch 10/8000 loss 7.881143 loss_att 12.131237 loss_ctc 13.144647 loss_rnnt 5.036219 hw_loss 0.242457 lr 0.00052313 rank 6
2023-02-11 20:54:12,910 DEBUG TRAIN Batch 10/8000 loss 17.756672 loss_att 18.676626 loss_ctc 25.253542 loss_rnnt 13.674040 hw_loss 0.543573 lr 0.00052299 rank 1
2023-02-11 20:54:12,910 DEBUG TRAIN Batch 10/8000 loss 15.604932 loss_att 18.439054 loss_ctc 21.156693 loss_rnnt 12.406437 hw_loss 0.354644 lr 0.00052315 rank 3
2023-02-11 20:54:12,913 DEBUG TRAIN Batch 10/8000 loss 5.820564 loss_att 7.910166 loss_ctc 10.827539 loss_rnnt 1.623645 hw_loss 0.583388 lr 0.00052279 rank 2
2023-02-11 20:55:28,759 DEBUG TRAIN Batch 10/8100 loss 15.489239 loss_att 17.382961 loss_ctc 29.669621 loss_rnnt 12.147648 hw_loss 0.201024 lr 0.00052257 rank 5
2023-02-11 20:55:28,762 DEBUG TRAIN Batch 10/8100 loss 8.713428 loss_att 5.569234 loss_ctc 8.864931 loss_rnnt 3.653126 hw_loss 1.062926 lr 0.00052286 rank 3
2023-02-11 20:55:28,761 DEBUG TRAIN Batch 10/8100 loss 21.442701 loss_att 20.966141 loss_ctc 29.443153 loss_rnnt 17.300442 hw_loss 0.594534 lr 0.00052281 rank 7
2023-02-11 20:55:28,763 DEBUG TRAIN Batch 10/8100 loss 10.468257 loss_att 11.807037 loss_ctc 12.692296 loss_rnnt 6.946691 hw_loss 0.554488 lr 0.00052264 rank 0
2023-02-11 20:55:28,764 DEBUG TRAIN Batch 10/8100 loss 18.811285 loss_att 20.562838 loss_ctc 26.525867 loss_rnnt 15.270259 hw_loss 0.405394 lr 0.00052284 rank 6
2023-02-11 20:55:28,765 DEBUG TRAIN Batch 10/8100 loss 10.903851 loss_att 14.031384 loss_ctc 22.857164 loss_rnnt 7.476225 hw_loss 0.226564 lr 0.00052251 rank 2
2023-02-11 20:55:28,765 DEBUG TRAIN Batch 10/8100 loss 12.912922 loss_att 14.108324 loss_ctc 20.746775 loss_rnnt 7.140313 hw_loss 0.841690 lr 0.00052270 rank 1
2023-02-11 20:55:28,767 DEBUG TRAIN Batch 10/8100 loss 18.267679 loss_att 22.541470 loss_ctc 24.336161 loss_rnnt 16.256420 hw_loss 0.065132 lr 0.00052279 rank 4
2023-02-11 20:56:45,360 DEBUG TRAIN Batch 10/8200 loss 8.782872 loss_att 8.894157 loss_ctc 10.330374 loss_rnnt 5.512707 hw_loss 0.570295 lr 0.00052252 rank 7
2023-02-11 20:56:45,362 DEBUG TRAIN Batch 10/8200 loss 11.264652 loss_att 12.381139 loss_ctc 17.470800 loss_rnnt 6.249866 hw_loss 0.743250 lr 0.00052222 rank 2
2023-02-11 20:56:45,363 DEBUG TRAIN Batch 10/8200 loss 19.563499 loss_att 21.747829 loss_ctc 27.347860 loss_rnnt 16.600616 hw_loss 0.279019 lr 0.00052255 rank 6
2023-02-11 20:56:45,363 DEBUG TRAIN Batch 10/8200 loss 23.574982 loss_att 22.965996 loss_ctc 28.808311 loss_rnnt 19.322830 hw_loss 0.689282 lr 0.00052258 rank 3
2023-02-11 20:56:45,364 DEBUG TRAIN Batch 10/8200 loss 20.330681 loss_att 20.841824 loss_ctc 27.937433 loss_rnnt 14.379860 hw_loss 0.906442 lr 0.00052235 rank 0
2023-02-11 20:56:45,369 DEBUG TRAIN Batch 10/8200 loss 18.793051 loss_att 20.183277 loss_ctc 25.504707 loss_rnnt 14.077322 hw_loss 0.664274 lr 0.00052229 rank 5
2023-02-11 20:56:45,371 DEBUG TRAIN Batch 10/8200 loss 12.644884 loss_att 14.288401 loss_ctc 19.480286 loss_rnnt 7.554099 hw_loss 0.722005 lr 0.00052241 rank 1
2023-02-11 20:56:45,371 DEBUG TRAIN Batch 10/8200 loss 20.238960 loss_att 22.408792 loss_ctc 25.108839 loss_rnnt 15.991051 hw_loss 0.593367 lr 0.00052251 rank 4
2023-02-11 20:58:00,104 DEBUG TRAIN Batch 10/8300 loss 10.731636 loss_att 14.131978 loss_ctc 15.673427 loss_rnnt 8.373697 hw_loss 0.191056 lr 0.00052229 rank 3
2023-02-11 20:58:00,105 DEBUG TRAIN Batch 10/8300 loss 15.819009 loss_att 15.837529 loss_ctc 26.308357 loss_rnnt 12.076323 hw_loss 0.438826 lr 0.00052224 rank 7
2023-02-11 20:58:00,106 DEBUG TRAIN Batch 10/8300 loss 14.059588 loss_att 14.073750 loss_ctc 17.843172 loss_rnnt 10.015411 hw_loss 0.663162 lr 0.00052207 rank 0
2023-02-11 20:58:00,107 DEBUG TRAIN Batch 10/8300 loss 10.621591 loss_att 17.259199 loss_ctc 21.669895 loss_rnnt 5.339543 hw_loss 0.465266 lr 0.00052213 rank 1
2023-02-11 20:58:00,107 DEBUG TRAIN Batch 10/8300 loss 9.186223 loss_att 7.350366 loss_ctc 8.682837 loss_rnnt 6.586829 hw_loss 0.568816 lr 0.00052227 rank 6
2023-02-11 20:58:00,109 DEBUG TRAIN Batch 10/8300 loss 12.162445 loss_att 13.491774 loss_ctc 17.460785 loss_rnnt 8.438940 hw_loss 0.515849 lr 0.00052200 rank 5
2023-02-11 20:58:00,111 DEBUG TRAIN Batch 10/8300 loss 7.526578 loss_att 7.214300 loss_ctc 10.891778 loss_rnnt 4.225270 hw_loss 0.546575 lr 0.00052194 rank 2
2023-02-11 20:58:00,112 DEBUG TRAIN Batch 10/8300 loss 14.588026 loss_att 13.249109 loss_ctc 19.204329 loss_rnnt 11.806866 hw_loss 0.456269 lr 0.00052222 rank 4
2023-02-11 20:58:55,097 DEBUG CV Batch 10/0 loss 8.039260 loss_att 2.297257 loss_ctc 3.662744 loss_rnnt 1.965040 hw_loss 1.463654 history loss 7.741510 rank 3
2023-02-11 20:58:55,102 DEBUG CV Batch 10/0 loss 8.039260 loss_att 2.297257 loss_ctc 3.662744 loss_rnnt 1.965040 hw_loss 1.463654 history loss 7.741510 rank 7
2023-02-11 20:58:55,102 DEBUG CV Batch 10/0 loss 8.039260 loss_att 2.297257 loss_ctc 3.662744 loss_rnnt 1.965040 hw_loss 1.463654 history loss 7.741510 rank 2
2023-02-11 20:58:55,103 DEBUG CV Batch 10/0 loss 8.039260 loss_att 2.297257 loss_ctc 3.662744 loss_rnnt 1.965040 hw_loss 1.463654 history loss 7.741510 rank 6
2023-02-11 20:58:55,104 DEBUG CV Batch 10/0 loss 8.039260 loss_att 2.297257 loss_ctc 3.662744 loss_rnnt 1.965040 hw_loss 1.463654 history loss 7.741510 rank 5
2023-02-11 20:58:55,116 DEBUG CV Batch 10/0 loss 8.039260 loss_att 2.297257 loss_ctc 3.662744 loss_rnnt 1.965040 hw_loss 1.463654 history loss 7.741510 rank 4
2023-02-11 20:58:55,118 DEBUG CV Batch 10/0 loss 8.039261 loss_att 2.297257 loss_ctc 3.662744 loss_rnnt 1.965040 hw_loss 1.463655 history loss 7.741510 rank 0
2023-02-11 20:58:55,125 DEBUG CV Batch 10/0 loss 8.039261 loss_att 2.297257 loss_ctc 3.662744 loss_rnnt 1.965040 hw_loss 1.463654 history loss 7.741510 rank 1
2023-02-11 20:59:06,185 DEBUG CV Batch 10/100 loss 9.371864 loss_att 7.645519 loss_ctc 14.744238 loss_rnnt 6.796004 hw_loss 0.413402 history loss 7.235310 rank 6
2023-02-11 20:59:06,256 DEBUG CV Batch 10/100 loss 9.371864 loss_att 7.645519 loss_ctc 14.744238 loss_rnnt 6.796004 hw_loss 0.413402 history loss 7.235310 rank 7
2023-02-11 20:59:06,264 DEBUG CV Batch 10/100 loss 9.371864 loss_att 7.645519 loss_ctc 14.744238 loss_rnnt 6.796004 hw_loss 0.413402 history loss 7.235310 rank 2
2023-02-11 20:59:06,273 DEBUG CV Batch 10/100 loss 9.371864 loss_att 7.645519 loss_ctc 14.744238 loss_rnnt 6.796004 hw_loss 0.413402 history loss 7.235310 rank 3
2023-02-11 20:59:06,285 DEBUG CV Batch 10/100 loss 9.371863 loss_att 7.645519 loss_ctc 14.744238 loss_rnnt 6.796004 hw_loss 0.413402 history loss 7.235310 rank 0
2023-02-11 20:59:06,335 DEBUG CV Batch 10/100 loss 9.371864 loss_att 7.645519 loss_ctc 14.744238 loss_rnnt 6.796004 hw_loss 0.413402 history loss 7.235310 rank 1
2023-02-11 20:59:06,356 DEBUG CV Batch 10/100 loss 9.371864 loss_att 7.645519 loss_ctc 14.744238 loss_rnnt 6.796004 hw_loss 0.413402 history loss 7.235310 rank 5
2023-02-11 20:59:06,448 DEBUG CV Batch 10/100 loss 9.371864 loss_att 7.645519 loss_ctc 14.744238 loss_rnnt 6.796004 hw_loss 0.413402 history loss 7.235310 rank 4
2023-02-11 20:59:19,791 DEBUG CV Batch 10/200 loss 11.628257 loss_att 13.771837 loss_ctc 17.787828 loss_rnnt 9.136204 hw_loss 0.232886 history loss 7.653236 rank 7
2023-02-11 20:59:20,006 DEBUG CV Batch 10/200 loss 11.628257 loss_att 13.771837 loss_ctc 17.787828 loss_rnnt 9.136204 hw_loss 0.232886 history loss 7.653236 rank 5
2023-02-11 20:59:20,073 DEBUG CV Batch 10/200 loss 11.628257 loss_att 13.771837 loss_ctc 17.787828 loss_rnnt 9.136204 hw_loss 0.232886 history loss 7.653236 rank 0
2023-02-11 20:59:20,199 DEBUG CV Batch 10/200 loss 11.628257 loss_att 13.771837 loss_ctc 17.787828 loss_rnnt 9.136204 hw_loss 0.232886 history loss 7.653236 rank 3
2023-02-11 20:59:20,340 DEBUG CV Batch 10/200 loss 11.628257 loss_att 13.771837 loss_ctc 17.787828 loss_rnnt 9.136204 hw_loss 0.232886 history loss 7.653236 rank 6
2023-02-11 20:59:20,447 DEBUG CV Batch 10/200 loss 11.628257 loss_att 13.771837 loss_ctc 17.787828 loss_rnnt 9.136204 hw_loss 0.232886 history loss 7.653236 rank 1
2023-02-11 20:59:20,489 DEBUG CV Batch 10/200 loss 11.628257 loss_att 13.771837 loss_ctc 17.787828 loss_rnnt 9.136204 hw_loss 0.232886 history loss 7.653236 rank 4
2023-02-11 20:59:20,838 DEBUG CV Batch 10/200 loss 11.628257 loss_att 13.771837 loss_ctc 17.787828 loss_rnnt 9.136204 hw_loss 0.232886 history loss 7.653236 rank 2
2023-02-11 20:59:31,845 DEBUG CV Batch 10/300 loss 7.383812 loss_att 5.338398 loss_ctc 9.386486 loss_rnnt 3.244392 hw_loss 0.802777 history loss 7.898475 rank 7
2023-02-11 20:59:32,067 DEBUG CV Batch 10/300 loss 7.383812 loss_att 5.338398 loss_ctc 9.386486 loss_rnnt 3.244392 hw_loss 0.802777 history loss 7.898475 rank 0
2023-02-11 20:59:32,107 DEBUG CV Batch 10/300 loss 7.383813 loss_att 5.338398 loss_ctc 9.386486 loss_rnnt 3.244392 hw_loss 0.802778 history loss 7.898475 rank 5
2023-02-11 20:59:32,264 DEBUG CV Batch 10/300 loss 7.383813 loss_att 5.338398 loss_ctc 9.386486 loss_rnnt 3.244392 hw_loss 0.802778 history loss 7.898475 rank 3
2023-02-11 20:59:32,376 DEBUG CV Batch 10/300 loss 7.383813 loss_att 5.338398 loss_ctc 9.386486 loss_rnnt 3.244392 hw_loss 0.802778 history loss 7.898475 rank 6
2023-02-11 20:59:32,538 DEBUG CV Batch 10/300 loss 7.383813 loss_att 5.338398 loss_ctc 9.386486 loss_rnnt 3.244392 hw_loss 0.802778 history loss 7.898475 rank 1
2023-02-11 20:59:32,611 DEBUG CV Batch 10/300 loss 7.383813 loss_att 5.338398 loss_ctc 9.386486 loss_rnnt 3.244392 hw_loss 0.802778 history loss 7.898475 rank 4
2023-02-11 20:59:34,381 DEBUG CV Batch 10/300 loss 7.383813 loss_att 5.338398 loss_ctc 9.386486 loss_rnnt 3.244392 hw_loss 0.802778 history loss 7.898475 rank 2
2023-02-11 20:59:43,858 DEBUG CV Batch 10/400 loss 21.014292 loss_att 73.626907 loss_ctc 10.552070 loss_rnnt 9.545914 hw_loss 0.438903 history loss 8.748027 rank 7
2023-02-11 20:59:44,034 DEBUG CV Batch 10/400 loss 21.014292 loss_att 73.626907 loss_ctc 10.552070 loss_rnnt 9.545914 hw_loss 0.438903 history loss 8.748027 rank 0
2023-02-11 20:59:44,124 DEBUG CV Batch 10/400 loss 21.014292 loss_att 73.626907 loss_ctc 10.552070 loss_rnnt 9.545914 hw_loss 0.438903 history loss 8.748027 rank 5
2023-02-11 20:59:44,312 DEBUG CV Batch 10/400 loss 21.014292 loss_att 73.626907 loss_ctc 10.552070 loss_rnnt 9.545914 hw_loss 0.438903 history loss 8.748027 rank 6
2023-02-11 20:59:44,335 DEBUG CV Batch 10/400 loss 21.014292 loss_att 73.626907 loss_ctc 10.552070 loss_rnnt 9.545914 hw_loss 0.438903 history loss 8.748027 rank 3
2023-02-11 20:59:44,567 DEBUG CV Batch 10/400 loss 21.014292 loss_att 73.626907 loss_ctc 10.552070 loss_rnnt 9.545914 hw_loss 0.438903 history loss 8.748027 rank 1
2023-02-11 20:59:44,702 DEBUG CV Batch 10/400 loss 21.014292 loss_att 73.626907 loss_ctc 10.552070 loss_rnnt 9.545914 hw_loss 0.438903 history loss 8.748027 rank 4
2023-02-11 20:59:46,749 DEBUG CV Batch 10/400 loss 21.014292 loss_att 73.626907 loss_ctc 10.552070 loss_rnnt 9.545914 hw_loss 0.438903 history loss 8.748027 rank 2
2023-02-11 20:59:54,264 DEBUG CV Batch 10/500 loss 9.563551 loss_att 8.173785 loss_ctc 9.461287 loss_rnnt 6.301872 hw_loss 0.666238 history loss 9.541676 rank 7
2023-02-11 20:59:54,442 DEBUG CV Batch 10/500 loss 9.563551 loss_att 8.173785 loss_ctc 9.461287 loss_rnnt 6.301872 hw_loss 0.666238 history loss 9.541675 rank 0
2023-02-11 20:59:54,617 DEBUG CV Batch 10/500 loss 9.563551 loss_att 8.173785 loss_ctc 9.461287 loss_rnnt 6.301872 hw_loss 0.666238 history loss 9.541675 rank 5
2023-02-11 20:59:54,761 DEBUG CV Batch 10/500 loss 9.563551 loss_att 8.173785 loss_ctc 9.461287 loss_rnnt 6.301872 hw_loss 0.666238 history loss 9.541675 rank 6
2023-02-11 20:59:54,809 DEBUG CV Batch 10/500 loss 9.563551 loss_att 8.173785 loss_ctc 9.461287 loss_rnnt 6.301872 hw_loss 0.666238 history loss 9.541675 rank 3
2023-02-11 20:59:55,064 DEBUG CV Batch 10/500 loss 9.563551 loss_att 8.173785 loss_ctc 9.461287 loss_rnnt 6.301872 hw_loss 0.666238 history loss 9.541675 rank 1
2023-02-11 20:59:55,269 DEBUG CV Batch 10/500 loss 9.563551 loss_att 8.173785 loss_ctc 9.461287 loss_rnnt 6.301872 hw_loss 0.666238 history loss 9.541675 rank 4
2023-02-11 20:59:57,270 DEBUG CV Batch 10/500 loss 9.563551 loss_att 8.173785 loss_ctc 9.461287 loss_rnnt 6.301872 hw_loss 0.666238 history loss 9.541675 rank 2
2023-02-11 21:00:06,246 DEBUG CV Batch 10/600 loss 10.687303 loss_att 7.806828 loss_ctc 11.039469 loss_rnnt 6.744837 hw_loss 0.838426 history loss 10.367324 rank 7
2023-02-11 21:00:06,458 DEBUG CV Batch 10/600 loss 10.687303 loss_att 7.806828 loss_ctc 11.039469 loss_rnnt 6.744837 hw_loss 0.838426 history loss 10.367324 rank 0
2023-02-11 21:00:06,729 DEBUG CV Batch 10/600 loss 10.687302 loss_att 7.806828 loss_ctc 11.039469 loss_rnnt 6.744837 hw_loss 0.838426 history loss 10.367324 rank 5
2023-02-11 21:00:06,877 DEBUG CV Batch 10/600 loss 10.687302 loss_att 7.806828 loss_ctc 11.039469 loss_rnnt 6.744837 hw_loss 0.838426 history loss 10.367324 rank 3
2023-02-11 21:00:06,894 DEBUG CV Batch 10/600 loss 10.687303 loss_att 7.806828 loss_ctc 11.039469 loss_rnnt 6.744837 hw_loss 0.838426 history loss 10.367324 rank 6
2023-02-11 21:00:07,129 DEBUG CV Batch 10/600 loss 10.687303 loss_att 7.806828 loss_ctc 11.039469 loss_rnnt 6.744837 hw_loss 0.838426 history loss 10.367324 rank 1
2023-02-11 21:00:07,347 DEBUG CV Batch 10/600 loss 10.687303 loss_att 7.806828 loss_ctc 11.039469 loss_rnnt 6.744837 hw_loss 0.838426 history loss 10.367324 rank 4
2023-02-11 21:00:10,562 DEBUG CV Batch 10/600 loss 10.687302 loss_att 7.806828 loss_ctc 11.039469 loss_rnnt 6.744837 hw_loss 0.838426 history loss 10.367324 rank 2
2023-02-11 21:00:17,554 DEBUG CV Batch 10/700 loss 11.330149 loss_att 37.454239 loss_ctc 20.372156 loss_rnnt 1.769530 hw_loss 0.586912 history loss 10.951545 rank 7
2023-02-11 21:00:17,747 DEBUG CV Batch 10/700 loss 11.330149 loss_att 37.454239 loss_ctc 20.372156 loss_rnnt 1.769530 hw_loss 0.586912 history loss 10.951545 rank 0
2023-02-11 21:00:18,079 DEBUG CV Batch 10/700 loss 11.330149 loss_att 37.454239 loss_ctc 20.372156 loss_rnnt 1.769530 hw_loss 0.586912 history loss 10.951545 rank 5
2023-02-11 21:00:18,274 DEBUG CV Batch 10/700 loss 11.330149 loss_att 37.454239 loss_ctc 20.372156 loss_rnnt 1.769530 hw_loss 0.586912 history loss 10.951545 rank 3
2023-02-11 21:00:18,441 DEBUG CV Batch 10/700 loss 11.330149 loss_att 37.454239 loss_ctc 20.372156 loss_rnnt 1.769530 hw_loss 0.586912 history loss 10.951545 rank 6
2023-02-11 21:00:18,715 DEBUG CV Batch 10/700 loss 11.330149 loss_att 37.454239 loss_ctc 20.372156 loss_rnnt 1.769530 hw_loss 0.586912 history loss 10.951545 rank 4
2023-02-11 21:00:19,428 DEBUG CV Batch 10/700 loss 11.330149 loss_att 37.454239 loss_ctc 20.372156 loss_rnnt 1.769530 hw_loss 0.586912 history loss 10.951545 rank 1
2023-02-11 21:00:22,082 DEBUG CV Batch 10/700 loss 11.330149 loss_att 37.454239 loss_ctc 20.372156 loss_rnnt 1.769530 hw_loss 0.586912 history loss 10.951545 rank 2
2023-02-11 21:00:28,773 DEBUG CV Batch 10/800 loss 11.404539 loss_att 9.586561 loss_ctc 18.545689 loss_rnnt 8.236437 hw_loss 0.483665 history loss 10.460760 rank 7
2023-02-11 21:00:29,419 DEBUG CV Batch 10/800 loss 11.404539 loss_att 9.586561 loss_ctc 18.545689 loss_rnnt 8.236437 hw_loss 0.483665 history loss 10.460760 rank 5
2023-02-11 21:00:29,544 DEBUG CV Batch 10/800 loss 11.404539 loss_att 9.586561 loss_ctc 18.545689 loss_rnnt 8.236437 hw_loss 0.483665 history loss 10.460760 rank 0
2023-02-11 21:00:29,847 DEBUG CV Batch 10/800 loss 11.404539 loss_att 9.586561 loss_ctc 18.545689 loss_rnnt 8.236437 hw_loss 0.483665 history loss 10.460760 rank 3
2023-02-11 21:00:30,161 DEBUG CV Batch 10/800 loss 11.404539 loss_att 9.586561 loss_ctc 18.545689 loss_rnnt 8.236437 hw_loss 0.483665 history loss 10.460760 rank 4
2023-02-11 21:00:30,514 DEBUG CV Batch 10/800 loss 11.404539 loss_att 9.586561 loss_ctc 18.545689 loss_rnnt 8.236437 hw_loss 0.483665 history loss 10.460760 rank 6
2023-02-11 21:00:32,278 DEBUG CV Batch 10/800 loss 11.404539 loss_att 9.586561 loss_ctc 18.545689 loss_rnnt 8.236437 hw_loss 0.483665 history loss 10.460760 rank 1
2023-02-11 21:00:33,300 DEBUG CV Batch 10/800 loss 11.404539 loss_att 9.586561 loss_ctc 18.545689 loss_rnnt 8.236437 hw_loss 0.483665 history loss 10.460760 rank 2
2023-02-11 21:00:42,544 DEBUG CV Batch 10/900 loss 13.809380 loss_att 16.281399 loss_ctc 23.337307 loss_rnnt 9.770635 hw_loss 0.426366 history loss 10.253606 rank 7
2023-02-11 21:00:42,800 DEBUG CV Batch 10/900 loss 13.809380 loss_att 16.281399 loss_ctc 23.337307 loss_rnnt 9.770635 hw_loss 0.426366 history loss 10.253606 rank 5
2023-02-11 21:00:42,988 DEBUG CV Batch 10/900 loss 13.809380 loss_att 16.281399 loss_ctc 23.337307 loss_rnnt 9.770635 hw_loss 0.426366 history loss 10.253606 rank 0
2023-02-11 21:00:43,628 DEBUG CV Batch 10/900 loss 13.809380 loss_att 16.281399 loss_ctc 23.337307 loss_rnnt 9.770635 hw_loss 0.426366 history loss 10.253606 rank 3
2023-02-11 21:00:43,838 DEBUG CV Batch 10/900 loss 13.809380 loss_att 16.281399 loss_ctc 23.337307 loss_rnnt 9.770635 hw_loss 0.426366 history loss 10.253606 rank 4
2023-02-11 21:00:44,097 DEBUG CV Batch 10/900 loss 13.809380 loss_att 16.281399 loss_ctc 23.337307 loss_rnnt 9.770635 hw_loss 0.426366 history loss 10.253606 rank 6
2023-02-11 21:00:46,107 DEBUG CV Batch 10/900 loss 13.809380 loss_att 16.281399 loss_ctc 23.337307 loss_rnnt 9.770635 hw_loss 0.426366 history loss 10.253606 rank 1
2023-02-11 21:00:46,689 DEBUG CV Batch 10/900 loss 13.809380 loss_att 16.281399 loss_ctc 23.337307 loss_rnnt 9.770635 hw_loss 0.426366 history loss 10.253606 rank 2
2023-02-11 21:00:54,751 DEBUG CV Batch 10/1000 loss 6.422311 loss_att 4.535719 loss_ctc 5.331557 loss_rnnt 3.623359 hw_loss 0.622819 history loss 10.077641 rank 7
2023-02-11 21:00:55,102 DEBUG CV Batch 10/1000 loss 6.422311 loss_att 4.535719 loss_ctc 5.331557 loss_rnnt 3.623359 hw_loss 0.622819 history loss 10.077641 rank 5
2023-02-11 21:00:55,129 DEBUG CV Batch 10/1000 loss 6.422311 loss_att 4.535719 loss_ctc 5.331557 loss_rnnt 3.623359 hw_loss 0.622819 history loss 10.077641 rank 0
2023-02-11 21:00:55,866 DEBUG CV Batch 10/1000 loss 6.422311 loss_att 4.535719 loss_ctc 5.331557 loss_rnnt 3.623359 hw_loss 0.622819 history loss 10.077641 rank 3
2023-02-11 21:00:56,101 DEBUG CV Batch 10/1000 loss 6.422311 loss_att 4.535719 loss_ctc 5.331557 loss_rnnt 3.623359 hw_loss 0.622819 history loss 10.077641 rank 4
2023-02-11 21:00:56,330 DEBUG CV Batch 10/1000 loss 6.422311 loss_att 4.535719 loss_ctc 5.331557 loss_rnnt 3.623359 hw_loss 0.622819 history loss 10.077641 rank 6
2023-02-11 21:00:58,348 DEBUG CV Batch 10/1000 loss 6.422311 loss_att 4.535719 loss_ctc 5.331557 loss_rnnt 3.623359 hw_loss 0.622819 history loss 10.077641 rank 1
2023-02-11 21:00:59,063 DEBUG CV Batch 10/1000 loss 6.422311 loss_att 4.535719 loss_ctc 5.331557 loss_rnnt 3.623359 hw_loss 0.622819 history loss 10.077641 rank 2
2023-02-11 21:01:06,683 DEBUG CV Batch 10/1100 loss 15.336906 loss_att 6.202610 loss_ctc 10.539886 loss_rnnt 5.871517 hw_loss 2.237222 history loss 10.078442 rank 7
2023-02-11 21:01:07,022 DEBUG CV Batch 10/1100 loss 15.336906 loss_att 6.202610 loss_ctc 10.539886 loss_rnnt 5.871517 hw_loss 2.237222 history loss 10.078442 rank 0
2023-02-11 21:01:07,024 DEBUG CV Batch 10/1100 loss 15.336906 loss_att 6.202610 loss_ctc 10.539886 loss_rnnt 5.871517 hw_loss 2.237222 history loss 10.078442 rank 5
2023-02-11 21:01:07,660 DEBUG CV Batch 10/1100 loss 15.336905 loss_att 6.202610 loss_ctc 10.539886 loss_rnnt 5.871517 hw_loss 2.237222 history loss 10.078442 rank 3
2023-02-11 21:01:08,048 DEBUG CV Batch 10/1100 loss 15.336906 loss_att 6.202610 loss_ctc 10.539886 loss_rnnt 5.871517 hw_loss 2.237222 history loss 10.078442 rank 4
2023-02-11 21:01:08,234 DEBUG CV Batch 10/1100 loss 15.336905 loss_att 6.202610 loss_ctc 10.539886 loss_rnnt 5.871517 hw_loss 2.237222 history loss 10.078442 rank 6
2023-02-11 21:01:10,363 DEBUG CV Batch 10/1100 loss 15.336908 loss_att 6.202610 loss_ctc 10.539886 loss_rnnt 5.871517 hw_loss 2.237222 history loss 10.078442 rank 1
2023-02-11 21:01:11,648 DEBUG CV Batch 10/1100 loss 15.336906 loss_att 6.202610 loss_ctc 10.539886 loss_rnnt 5.871517 hw_loss 2.237222 history loss 10.078442 rank 2
2023-02-11 21:01:17,192 DEBUG CV Batch 10/1200 loss 13.452444 loss_att 10.636412 loss_ctc 14.190312 loss_rnnt 9.638377 hw_loss 0.802292 history loss 10.390144 rank 7
2023-02-11 21:01:17,470 DEBUG CV Batch 10/1200 loss 13.452444 loss_att 10.636412 loss_ctc 14.190312 loss_rnnt 9.638377 hw_loss 0.802292 history loss 10.390144 rank 0
2023-02-11 21:01:17,548 DEBUG CV Batch 10/1200 loss 13.452444 loss_att 10.636412 loss_ctc 14.190312 loss_rnnt 9.638377 hw_loss 0.802292 history loss 10.390144 rank 5
2023-02-11 21:01:18,139 DEBUG CV Batch 10/1200 loss 13.452444 loss_att 10.636412 loss_ctc 14.190312 loss_rnnt 9.638377 hw_loss 0.802292 history loss 10.390144 rank 3
2023-02-11 21:01:18,618 DEBUG CV Batch 10/1200 loss 13.452444 loss_att 10.636412 loss_ctc 14.190312 loss_rnnt 9.638377 hw_loss 0.802292 history loss 10.390144 rank 4
2023-02-11 21:01:18,722 DEBUG CV Batch 10/1200 loss 13.452444 loss_att 10.636412 loss_ctc 14.190312 loss_rnnt 9.638377 hw_loss 0.802292 history loss 10.390144 rank 6
2023-02-11 21:01:20,882 DEBUG CV Batch 10/1200 loss 13.452444 loss_att 10.636412 loss_ctc 14.190312 loss_rnnt 9.638377 hw_loss 0.802292 history loss 10.390144 rank 1
2023-02-11 21:01:22,141 DEBUG CV Batch 10/1200 loss 13.452444 loss_att 10.636412 loss_ctc 14.190312 loss_rnnt 9.638377 hw_loss 0.802292 history loss 10.390144 rank 2
2023-02-11 21:01:29,175 DEBUG CV Batch 10/1300 loss 9.802206 loss_att 6.471539 loss_ctc 9.232355 loss_rnnt 5.096044 hw_loss 1.021552 history loss 10.665821 rank 7
2023-02-11 21:01:29,301 DEBUG CV Batch 10/1300 loss 9.802205 loss_att 6.471539 loss_ctc 9.232355 loss_rnnt 5.096044 hw_loss 1.021551 history loss 10.665821 rank 0
2023-02-11 21:01:29,559 DEBUG CV Batch 10/1300 loss 9.802206 loss_att 6.471539 loss_ctc 9.232355 loss_rnnt 5.096044 hw_loss 1.021552 history loss 10.665821 rank 5
2023-02-11 21:01:30,026 DEBUG CV Batch 10/1300 loss 9.802205 loss_att 6.471539 loss_ctc 9.232355 loss_rnnt 5.096044 hw_loss 1.021551 history loss 10.665821 rank 3
2023-02-11 21:01:30,619 DEBUG CV Batch 10/1300 loss 9.802206 loss_att 6.471539 loss_ctc 9.232355 loss_rnnt 5.096044 hw_loss 1.021552 history loss 10.665821 rank 4
2023-02-11 21:01:31,429 DEBUG CV Batch 10/1300 loss 9.802204 loss_att 6.471539 loss_ctc 9.232355 loss_rnnt 5.096044 hw_loss 1.021551 history loss 10.665821 rank 6
2023-02-11 21:01:32,838 DEBUG CV Batch 10/1300 loss 9.802206 loss_att 6.471539 loss_ctc 9.232355 loss_rnnt 5.096044 hw_loss 1.021552 history loss 10.665821 rank 1
2023-02-11 21:01:34,112 DEBUG CV Batch 10/1300 loss 9.802206 loss_att 6.471539 loss_ctc 9.232355 loss_rnnt 5.096044 hw_loss 1.021552 history loss 10.665821 rank 2
2023-02-11 21:01:40,281 DEBUG CV Batch 10/1400 loss 8.330615 loss_att 21.805733 loss_ctc 9.443188 loss_rnnt 3.908497 hw_loss 0.296016 history loss 10.968947 rank 7
2023-02-11 21:01:40,389 DEBUG CV Batch 10/1400 loss 8.330615 loss_att 21.805733 loss_ctc 9.443188 loss_rnnt 3.908497 hw_loss 0.296016 history loss 10.968947 rank 0
2023-02-11 21:01:40,723 DEBUG CV Batch 10/1400 loss 8.330615 loss_att 21.805733 loss_ctc 9.443188 loss_rnnt 3.908497 hw_loss 0.296016 history loss 10.968947 rank 5
2023-02-11 21:01:41,175 DEBUG CV Batch 10/1400 loss 8.330615 loss_att 21.805733 loss_ctc 9.443188 loss_rnnt 3.908497 hw_loss 0.296016 history loss 10.968947 rank 3
2023-02-11 21:01:41,937 DEBUG CV Batch 10/1400 loss 8.330615 loss_att 21.805733 loss_ctc 9.443188 loss_rnnt 3.908497 hw_loss 0.296016 history loss 10.968947 rank 4
2023-02-11 21:01:42,640 DEBUG CV Batch 10/1400 loss 8.330615 loss_att 21.805733 loss_ctc 9.443188 loss_rnnt 3.908497 hw_loss 0.296016 history loss 10.968947 rank 6
2023-02-11 21:01:43,975 DEBUG CV Batch 10/1400 loss 8.330615 loss_att 21.805733 loss_ctc 9.443188 loss_rnnt 3.908497 hw_loss 0.296016 history loss 10.968947 rank 1
2023-02-11 21:01:45,486 DEBUG CV Batch 10/1400 loss 8.330615 loss_att 21.805733 loss_ctc 9.443188 loss_rnnt 3.908497 hw_loss 0.296016 history loss 10.968947 rank 2
2023-02-11 21:01:51,669 DEBUG CV Batch 10/1500 loss 9.995768 loss_att 9.308723 loss_ctc 7.005909 loss_rnnt 8.664436 hw_loss 0.350135 history loss 10.824315 rank 7
2023-02-11 21:01:51,738 DEBUG CV Batch 10/1500 loss 9.995768 loss_att 9.308723 loss_ctc 7.005909 loss_rnnt 8.664436 hw_loss 0.350135 history loss 10.824315 rank 0
2023-02-11 21:01:52,163 DEBUG CV Batch 10/1500 loss 9.995768 loss_att 9.308723 loss_ctc 7.005909 loss_rnnt 8.664436 hw_loss 0.350135 history loss 10.824315 rank 5
2023-02-11 21:01:53,238 DEBUG CV Batch 10/1500 loss 9.995768 loss_att 9.308723 loss_ctc 7.005909 loss_rnnt 8.664436 hw_loss 0.350135 history loss 10.824315 rank 3
2023-02-11 21:01:55,167 DEBUG CV Batch 10/1500 loss 9.995768 loss_att 9.308723 loss_ctc 7.005909 loss_rnnt 8.664436 hw_loss 0.350135 history loss 10.824315 rank 4
2023-02-11 21:01:55,179 DEBUG CV Batch 10/1500 loss 9.995768 loss_att 9.308723 loss_ctc 7.005909 loss_rnnt 8.664436 hw_loss 0.350135 history loss 10.824315 rank 1
2023-02-11 21:01:55,408 DEBUG CV Batch 10/1500 loss 9.995768 loss_att 9.308723 loss_ctc 7.005909 loss_rnnt 8.664436 hw_loss 0.350135 history loss 10.824315 rank 6
2023-02-11 21:01:56,889 DEBUG CV Batch 10/1500 loss 9.995768 loss_att 9.308723 loss_ctc 7.005909 loss_rnnt 8.664436 hw_loss 0.350135 history loss 10.824315 rank 2
2023-02-11 21:02:04,836 DEBUG CV Batch 10/1600 loss 10.006231 loss_att 15.410677 loss_ctc 20.288082 loss_rnnt 7.084386 hw_loss 0.088133 history loss 10.735989 rank 7
2023-02-11 21:02:05,188 DEBUG CV Batch 10/1600 loss 10.006231 loss_att 15.410677 loss_ctc 20.288082 loss_rnnt 7.084386 hw_loss 0.088133 history loss 10.735989 rank 0
2023-02-11 21:02:05,286 DEBUG CV Batch 10/1600 loss 10.006231 loss_att 15.410677 loss_ctc 20.288082 loss_rnnt 7.084386 hw_loss 0.088133 history loss 10.735989 rank 5
2023-02-11 21:02:06,753 DEBUG CV Batch 10/1600 loss 10.006231 loss_att 15.410677 loss_ctc 20.288082 loss_rnnt 7.084386 hw_loss 0.088133 history loss 10.735989 rank 3
2023-02-11 21:02:08,249 DEBUG CV Batch 10/1600 loss 10.006231 loss_att 15.410677 loss_ctc 20.288082 loss_rnnt 7.084386 hw_loss 0.088133 history loss 10.735989 rank 1
2023-02-11 21:02:08,859 DEBUG CV Batch 10/1600 loss 10.006231 loss_att 15.410677 loss_ctc 20.288082 loss_rnnt 7.084386 hw_loss 0.088133 history loss 10.735989 rank 4
2023-02-11 21:02:09,261 DEBUG CV Batch 10/1600 loss 10.006231 loss_att 15.410677 loss_ctc 20.288082 loss_rnnt 7.084386 hw_loss 0.088133 history loss 10.735989 rank 6
2023-02-11 21:02:10,088 DEBUG CV Batch 10/1600 loss 10.006231 loss_att 15.410677 loss_ctc 20.288082 loss_rnnt 7.084386 hw_loss 0.088133 history loss 10.735989 rank 2
2023-02-11 21:02:17,394 DEBUG CV Batch 10/1700 loss 11.462598 loss_att 8.565792 loss_ctc 15.014502 loss_rnnt 7.646394 hw_loss 0.735371 history loss 10.679656 rank 7
2023-02-11 21:02:17,683 DEBUG CV Batch 10/1700 loss 11.462598 loss_att 8.565792 loss_ctc 15.014502 loss_rnnt 7.646394 hw_loss 0.735371 history loss 10.679656 rank 0
2023-02-11 21:02:17,844 DEBUG CV Batch 10/1700 loss 11.462598 loss_att 8.565792 loss_ctc 15.014502 loss_rnnt 7.646394 hw_loss 0.735371 history loss 10.679656 rank 5
2023-02-11 21:02:19,268 DEBUG CV Batch 10/1700 loss 11.462598 loss_att 8.565792 loss_ctc 15.014502 loss_rnnt 7.646394 hw_loss 0.735371 history loss 10.679656 rank 3
2023-02-11 21:02:20,749 DEBUG CV Batch 10/1700 loss 11.462598 loss_att 8.565792 loss_ctc 15.014502 loss_rnnt 7.646394 hw_loss 0.735371 history loss 10.679656 rank 1
2023-02-11 21:02:21,294 DEBUG CV Batch 10/1700 loss 11.462598 loss_att 8.565792 loss_ctc 15.014502 loss_rnnt 7.646394 hw_loss 0.735371 history loss 10.679656 rank 4
2023-02-11 21:02:21,759 DEBUG CV Batch 10/1700 loss 11.462598 loss_att 8.565792 loss_ctc 15.014502 loss_rnnt 7.646394 hw_loss 0.735371 history loss 10.679656 rank 6
2023-02-11 21:02:22,782 DEBUG CV Batch 10/1700 loss 11.462598 loss_att 8.565792 loss_ctc 15.014502 loss_rnnt 7.646394 hw_loss 0.735371 history loss 10.679656 rank 2
2023-02-11 21:02:26,602 INFO Epoch 10 CV info cv_loss 10.642681181267138
2023-02-11 21:02:26,603 INFO Epoch 11 TRAIN info lr 0.0005220981890038676
2023-02-11 21:02:26,606 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 21:02:26,825 INFO Epoch 10 CV info cv_loss 10.642681152804391
2023-02-11 21:02:26,826 INFO Checkpoint: save to checkpoint exp2_10_rnnt_bias_loss/10.pt
2023-02-11 21:02:27,055 INFO Epoch 10 CV info cv_loss 10.642681169327258
2023-02-11 21:02:27,056 INFO Epoch 11 TRAIN info lr 0.0005219985956586272
2023-02-11 21:02:27,059 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 21:02:27,824 INFO Epoch 11 TRAIN info lr 0.0005219729951520445
2023-02-11 21:02:27,830 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 21:02:28,329 INFO Epoch 10 CV info cv_loss 10.642681167276974
2023-02-11 21:02:28,330 INFO Epoch 11 TRAIN info lr 0.0005221038817740899
2023-02-11 21:02:28,333 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 21:02:29,887 INFO Epoch 10 CV info cv_loss 10.642681177390553
2023-02-11 21:02:29,888 INFO Epoch 11 TRAIN info lr 0.0005220014403918818
2023-02-11 21:02:29,892 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 21:02:30,379 INFO Epoch 10 CV info cv_loss 10.642681179699276
2023-02-11 21:02:30,380 INFO Epoch 11 TRAIN info lr 0.0005221238079364159
2023-02-11 21:02:30,384 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 21:02:30,827 INFO Epoch 10 CV info cv_loss 10.64268115943766
2023-02-11 21:02:30,828 INFO Epoch 11 TRAIN info lr 0.0005221579723803498
2023-02-11 21:02:30,832 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 21:02:31,789 INFO Epoch 10 CV info cv_loss 10.642681180905324
2023-02-11 21:02:31,790 INFO Epoch 11 TRAIN info lr 0.0005218422069168733
2023-02-11 21:02:31,794 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 21:03:45,004 DEBUG TRAIN Batch 11/0 loss 11.774632 loss_att 7.112764 loss_ctc 9.755744 loss_rnnt 6.952928 hw_loss 1.129362 lr 0.00052210 rank 7
2023-02-11 21:03:45,005 DEBUG TRAIN Batch 11/0 loss 11.276867 loss_att 6.577203 loss_ctc 8.931612 loss_rnnt 5.331613 hw_loss 1.349604 lr 0.00052210 rank 3
2023-02-11 21:03:45,011 DEBUG TRAIN Batch 11/0 loss 14.588945 loss_att 10.978840 loss_ctc 16.034651 loss_rnnt 10.193630 hw_loss 0.923358 lr 0.00052200 rank 1
2023-02-11 21:03:45,014 DEBUG TRAIN Batch 11/0 loss 12.917952 loss_att 10.260431 loss_ctc 12.699604 loss_rnnt 8.870033 hw_loss 0.864101 lr 0.00052216 rank 6
2023-02-11 21:03:45,016 DEBUG TRAIN Batch 11/0 loss 14.831091 loss_att 9.547624 loss_ctc 13.545987 loss_rnnt 9.868857 hw_loss 1.160676 lr 0.00052184 rank 2
2023-02-11 21:03:45,036 DEBUG TRAIN Batch 11/0 loss 14.908787 loss_att 10.100639 loss_ctc 14.514982 loss_rnnt 8.324129 hw_loss 1.424774 lr 0.00052197 rank 0
2023-02-11 21:03:45,047 DEBUG TRAIN Batch 11/0 loss 14.434765 loss_att 11.065147 loss_ctc 14.486643 loss_rnnt 8.086769 hw_loss 1.315313 lr 0.00052200 rank 5
2023-02-11 21:03:45,051 DEBUG TRAIN Batch 11/0 loss 10.684258 loss_att 6.055445 loss_ctc 8.052377 loss_rnnt 5.380547 hw_loss 1.233823 lr 0.00052212 rank 4
2023-02-11 21:05:00,337 DEBUG TRAIN Batch 11/100 loss 9.320015 loss_att 12.547230 loss_ctc 11.906836 loss_rnnt 6.724084 hw_loss 0.301046 lr 0.00052181 rank 7
2023-02-11 21:05:00,340 DEBUG TRAIN Batch 11/100 loss 17.756702 loss_att 16.369524 loss_ctc 33.275215 loss_rnnt 14.667227 hw_loss 0.243333 lr 0.00052171 rank 1
2023-02-11 21:05:00,341 DEBUG TRAIN Batch 11/100 loss 7.310458 loss_att 8.300055 loss_ctc 12.629284 loss_rnnt 4.772832 hw_loss 0.305724 lr 0.00052184 rank 4
2023-02-11 21:05:00,342 DEBUG TRAIN Batch 11/100 loss 19.444153 loss_att 18.592636 loss_ctc 23.279724 loss_rnnt 18.045826 hw_loss 0.198229 lr 0.00052156 rank 2
2023-02-11 21:05:00,341 DEBUG TRAIN Batch 11/100 loss 8.537589 loss_att 10.797226 loss_ctc 13.346119 loss_rnnt 5.243753 hw_loss 0.412645 lr 0.00052182 rank 3
2023-02-11 21:05:00,342 DEBUG TRAIN Batch 11/100 loss 22.404621 loss_att 25.521114 loss_ctc 34.342934 loss_rnnt 18.587027 hw_loss 0.300473 lr 0.00052171 rank 5
2023-02-11 21:05:00,344 DEBUG TRAIN Batch 11/100 loss 25.894062 loss_att 26.457893 loss_ctc 38.212952 loss_rnnt 21.152845 hw_loss 0.559862 lr 0.00052169 rank 0
2023-02-11 21:05:00,347 DEBUG TRAIN Batch 11/100 loss 15.556286 loss_att 16.694109 loss_ctc 22.507233 loss_rnnt 12.175516 hw_loss 0.417452 lr 0.00052187 rank 6
2023-02-11 21:06:15,543 DEBUG TRAIN Batch 11/200 loss 26.496288 loss_att 31.944363 loss_ctc 41.789162 loss_rnnt 21.868322 hw_loss 0.281119 lr 0.00052153 rank 7
2023-02-11 21:06:15,543 DEBUG TRAIN Batch 11/200 loss 12.915643 loss_att 14.251616 loss_ctc 17.686460 loss_rnnt 9.654266 hw_loss 0.442138 lr 0.00052159 rank 6
2023-02-11 21:06:15,544 DEBUG TRAIN Batch 11/200 loss 6.631820 loss_att 8.182165 loss_ctc 9.568010 loss_rnnt 4.374402 hw_loss 0.291723 lr 0.00052140 rank 0
2023-02-11 21:06:15,547 DEBUG TRAIN Batch 11/200 loss 13.879238 loss_att 17.739054 loss_ctc 18.550133 loss_rnnt 10.960508 hw_loss 0.285747 lr 0.00052143 rank 1
2023-02-11 21:06:15,548 DEBUG TRAIN Batch 11/200 loss 8.883237 loss_att 12.859590 loss_ctc 18.798870 loss_rnnt 6.388393 hw_loss 0.070779 lr 0.00052153 rank 3
2023-02-11 21:06:15,549 DEBUG TRAIN Batch 11/200 loss 13.235618 loss_att 13.200436 loss_ctc 19.514368 loss_rnnt 10.847995 hw_loss 0.292030 lr 0.00052127 rank 2
2023-02-11 21:06:15,551 DEBUG TRAIN Batch 11/200 loss 11.852345 loss_att 14.670192 loss_ctc 13.830974 loss_rnnt 8.462643 hw_loss 0.480434 lr 0.00052143 rank 5
2023-02-11 21:06:15,562 DEBUG TRAIN Batch 11/200 loss 11.653359 loss_att 14.331662 loss_ctc 15.100504 loss_rnnt 7.642358 hw_loss 0.565448 lr 0.00052155 rank 4
2023-02-11 21:07:33,051 DEBUG TRAIN Batch 11/300 loss 10.170048 loss_att 13.431370 loss_ctc 19.380182 loss_rnnt 7.301100 hw_loss 0.185375 lr 0.00052125 rank 3
2023-02-11 21:07:33,056 DEBUG TRAIN Batch 11/300 loss 16.294914 loss_att 16.756470 loss_ctc 23.808876 loss_rnnt 11.657354 hw_loss 0.664385 lr 0.00052124 rank 7
2023-02-11 21:07:33,059 DEBUG TRAIN Batch 11/300 loss 13.816557 loss_att 16.714943 loss_ctc 18.400997 loss_rnnt 9.977730 hw_loss 0.496480 lr 0.00052114 rank 5
2023-02-11 21:07:33,060 DEBUG TRAIN Batch 11/300 loss 22.313812 loss_att 23.829079 loss_ctc 39.027935 loss_rnnt 18.438591 hw_loss 0.251928 lr 0.00052127 rank 4
2023-02-11 21:07:33,061 DEBUG TRAIN Batch 11/300 loss 9.708590 loss_att 10.315849 loss_ctc 12.151028 loss_rnnt 7.218916 hw_loss 0.382980 lr 0.00052115 rank 1
2023-02-11 21:07:33,063 DEBUG TRAIN Batch 11/300 loss 7.145463 loss_att 8.375103 loss_ctc 8.880526 loss_rnnt 5.148545 hw_loss 0.284934 lr 0.00052099 rank 2
2023-02-11 21:07:33,064 DEBUG TRAIN Batch 11/300 loss 14.090048 loss_att 17.248047 loss_ctc 22.772583 loss_rnnt 10.125639 hw_loss 0.407838 lr 0.00052130 rank 6
2023-02-11 21:07:33,065 DEBUG TRAIN Batch 11/300 loss 23.125425 loss_att 27.150982 loss_ctc 36.893444 loss_rnnt 18.838894 hw_loss 0.308566 lr 0.00052112 rank 0
2023-02-11 21:08:50,959 DEBUG TRAIN Batch 11/400 loss 14.326003 loss_att 17.285414 loss_ctc 21.318237 loss_rnnt 11.579674 hw_loss 0.229153 lr 0.00052097 rank 3
2023-02-11 21:08:50,961 DEBUG TRAIN Batch 11/400 loss 14.334994 loss_att 17.557852 loss_ctc 20.273268 loss_rnnt 10.560968 hw_loss 0.438316 lr 0.00052096 rank 7
2023-02-11 21:08:50,961 DEBUG TRAIN Batch 11/400 loss 11.574651 loss_att 14.797951 loss_ctc 20.632412 loss_rnnt 7.065813 hw_loss 0.498089 lr 0.00052086 rank 5
2023-02-11 21:08:50,964 DEBUG TRAIN Batch 11/400 loss 10.627565 loss_att 14.266476 loss_ctc 18.626179 loss_rnnt 7.122911 hw_loss 0.320698 lr 0.00052084 rank 0
2023-02-11 21:08:50,966 DEBUG TRAIN Batch 11/400 loss 10.366711 loss_att 12.203356 loss_ctc 17.009884 loss_rnnt 6.820466 hw_loss 0.429967 lr 0.00052071 rank 2
2023-02-11 21:08:50,966 DEBUG TRAIN Batch 11/400 loss 21.582634 loss_att 30.830729 loss_ctc 43.010391 loss_rnnt 15.240496 hw_loss 0.306654 lr 0.00052102 rank 6
2023-02-11 21:08:50,967 DEBUG TRAIN Batch 11/400 loss 28.679243 loss_att 33.310150 loss_ctc 39.933231 loss_rnnt 22.663359 hw_loss 0.672970 lr 0.00052086 rank 1
2023-02-11 21:08:50,974 DEBUG TRAIN Batch 11/400 loss 16.293638 loss_att 19.136539 loss_ctc 17.728189 loss_rnnt 12.991401 hw_loss 0.476697 lr 0.00052099 rank 4
2023-02-11 21:10:05,385 DEBUG TRAIN Batch 11/500 loss 11.070227 loss_att 11.270363 loss_ctc 11.304369 loss_rnnt 7.804014 hw_loss 0.599056 lr 0.00052068 rank 7
2023-02-11 21:10:05,384 DEBUG TRAIN Batch 11/500 loss 17.230955 loss_att 19.128578 loss_ctc 26.703392 loss_rnnt 13.993276 hw_loss 0.299093 lr 0.00052055 rank 0
2023-02-11 21:10:05,386 DEBUG TRAIN Batch 11/500 loss 9.467510 loss_att 11.914333 loss_ctc 13.610918 loss_rnnt 5.613958 hw_loss 0.527200 lr 0.00052074 rank 6
2023-02-11 21:10:05,388 DEBUG TRAIN Batch 11/500 loss 30.922077 loss_att 33.269714 loss_ctc 47.138809 loss_rnnt 25.667652 hw_loss 0.491750 lr 0.00052068 rank 3
2023-02-11 21:10:05,389 DEBUG TRAIN Batch 11/500 loss 10.698372 loss_att 10.837206 loss_ctc 17.336084 loss_rnnt 6.663693 hw_loss 0.585353 lr 0.00052058 rank 1
2023-02-11 21:10:05,392 DEBUG TRAIN Batch 11/500 loss 9.212482 loss_att 11.929408 loss_ctc 15.993547 loss_rnnt 5.181720 hw_loss 0.484357 lr 0.00052058 rank 5
2023-02-11 21:10:05,394 DEBUG TRAIN Batch 11/500 loss 17.325663 loss_att 20.073719 loss_ctc 24.491463 loss_rnnt 12.368726 hw_loss 0.647228 lr 0.00052042 rank 2
2023-02-11 21:10:05,393 DEBUG TRAIN Batch 11/500 loss 12.318647 loss_att 13.681017 loss_ctc 17.719337 loss_rnnt 9.225800 hw_loss 0.393803 lr 0.00052070 rank 4
2023-02-11 21:11:20,987 DEBUG TRAIN Batch 11/600 loss 16.604292 loss_att 13.456261 loss_ctc 21.478521 loss_rnnt 14.095931 hw_loss 0.466513 lr 0.00052027 rank 0
2023-02-11 21:11:20,989 DEBUG TRAIN Batch 11/600 loss 12.519386 loss_att 10.965790 loss_ctc 16.265276 loss_rnnt 6.448674 hw_loss 1.102871 lr 0.00052040 rank 3
2023-02-11 21:11:20,992 DEBUG TRAIN Batch 11/600 loss 11.952330 loss_att 12.240690 loss_ctc 17.899757 loss_rnnt 8.179220 hw_loss 0.547959 lr 0.00052040 rank 7
2023-02-11 21:11:20,992 DEBUG TRAIN Batch 11/600 loss 11.500746 loss_att 9.109366 loss_ctc 11.983585 loss_rnnt 6.734146 hw_loss 0.971343 lr 0.00052014 rank 2
2023-02-11 21:11:20,993 DEBUG TRAIN Batch 11/600 loss 14.039851 loss_att 12.001792 loss_ctc 14.359722 loss_rnnt 8.431090 hw_loss 1.120073 lr 0.00052030 rank 5
2023-02-11 21:11:20,994 DEBUG TRAIN Batch 11/600 loss 12.186848 loss_att 10.398230 loss_ctc 13.935511 loss_rnnt 8.868723 hw_loss 0.645505 lr 0.00052042 rank 4
2023-02-11 21:11:20,995 DEBUG TRAIN Batch 11/600 loss 14.405566 loss_att 17.916098 loss_ctc 23.659147 loss_rnnt 11.120361 hw_loss 0.252991 lr 0.00052030 rank 1
2023-02-11 21:11:20,995 DEBUG TRAIN Batch 11/600 loss 16.115953 loss_att 13.580587 loss_ctc 17.952129 loss_rnnt 11.296114 hw_loss 0.952892 lr 0.00052046 rank 6
2023-02-11 21:12:39,166 DEBUG TRAIN Batch 11/700 loss 16.954348 loss_att 20.028526 loss_ctc 24.425156 loss_rnnt 13.247061 hw_loss 0.393064 lr 0.00052002 rank 5
2023-02-11 21:12:39,172 DEBUG TRAIN Batch 11/700 loss 10.227167 loss_att 10.831546 loss_ctc 11.121788 loss_rnnt 6.220779 hw_loss 0.706168 lr 0.00051999 rank 0
2023-02-11 21:12:39,172 DEBUG TRAIN Batch 11/700 loss 17.095793 loss_att 20.078533 loss_ctc 24.672527 loss_rnnt 13.124565 hw_loss 0.443334 lr 0.00051986 rank 2
2023-02-11 21:12:39,176 DEBUG TRAIN Batch 11/700 loss 17.467503 loss_att 19.586018 loss_ctc 23.247917 loss_rnnt 14.114264 hw_loss 0.404778 lr 0.00052002 rank 1
2023-02-11 21:12:39,178 DEBUG TRAIN Batch 11/700 loss 9.706498 loss_att 11.586082 loss_ctc 17.735432 loss_rnnt 6.820753 hw_loss 0.269870 lr 0.00052014 rank 4
2023-02-11 21:12:39,190 DEBUG TRAIN Batch 11/700 loss 19.047335 loss_att 26.611816 loss_ctc 40.385544 loss_rnnt 13.259662 hw_loss 0.268065 lr 0.00052012 rank 3
2023-02-11 21:12:39,200 DEBUG TRAIN Batch 11/700 loss 15.583708 loss_att 17.052078 loss_ctc 23.081768 loss_rnnt 13.699448 hw_loss 0.110783 lr 0.00052011 rank 7
2023-02-11 21:12:39,205 DEBUG TRAIN Batch 11/700 loss 12.038207 loss_att 15.479910 loss_ctc 12.368128 loss_rnnt 8.554629 hw_loss 0.515859 lr 0.00052017 rank 6
2023-02-11 21:13:55,812 DEBUG TRAIN Batch 11/800 loss 15.149082 loss_att 15.884300 loss_ctc 24.992117 loss_rnnt 10.991038 hw_loss 0.505987 lr 0.00051971 rank 0
2023-02-11 21:13:55,816 DEBUG TRAIN Batch 11/800 loss 25.025291 loss_att 27.359613 loss_ctc 45.251831 loss_rnnt 21.086079 hw_loss 0.145402 lr 0.00051986 rank 4
2023-02-11 21:13:55,816 DEBUG TRAIN Batch 11/800 loss 19.880146 loss_att 25.296926 loss_ctc 29.625256 loss_rnnt 16.328808 hw_loss 0.219119 lr 0.00051973 rank 5
2023-02-11 21:13:55,817 DEBUG TRAIN Batch 11/800 loss 11.675253 loss_att 16.025688 loss_ctc 14.212646 loss_rnnt 9.148589 hw_loss 0.247173 lr 0.00051984 rank 3
2023-02-11 21:13:55,819 DEBUG TRAIN Batch 11/800 loss 21.246311 loss_att 27.880276 loss_ctc 30.261703 loss_rnnt 16.228338 hw_loss 0.466712 lr 0.00051983 rank 7
2023-02-11 21:13:55,819 DEBUG TRAIN Batch 11/800 loss 8.267857 loss_att 8.967804 loss_ctc 10.932364 loss_rnnt 5.826198 hw_loss 0.364951 lr 0.00051974 rank 1
2023-02-11 21:13:55,821 DEBUG TRAIN Batch 11/800 loss 13.670107 loss_att 16.553102 loss_ctc 18.894629 loss_rnnt 11.582538 hw_loss 0.152694 lr 0.00051958 rank 2
2023-02-11 21:13:55,875 DEBUG TRAIN Batch 11/800 loss 12.102118 loss_att 14.770823 loss_ctc 11.621413 loss_rnnt 8.927223 hw_loss 0.507234 lr 0.00051989 rank 6
2023-02-11 21:15:13,151 DEBUG TRAIN Batch 11/900 loss 9.287594 loss_att 9.563006 loss_ctc 9.360329 loss_rnnt 7.650919 hw_loss 0.294730 lr 0.00051956 rank 3
2023-02-11 21:15:13,151 DEBUG TRAIN Batch 11/900 loss 6.992652 loss_att 7.989745 loss_ctc 7.239852 loss_rnnt 4.610889 hw_loss 0.403010 lr 0.00051946 rank 1
2023-02-11 21:15:13,153 DEBUG TRAIN Batch 11/900 loss 13.842638 loss_att 18.829409 loss_ctc 26.456129 loss_rnnt 9.735775 hw_loss 0.267696 lr 0.00051955 rank 7
2023-02-11 21:15:13,155 DEBUG TRAIN Batch 11/900 loss 12.212130 loss_att 13.640975 loss_ctc 17.250526 loss_rnnt 9.715603 hw_loss 0.288557 lr 0.00051958 rank 4
2023-02-11 21:15:13,156 DEBUG TRAIN Batch 11/900 loss 15.776955 loss_att 17.218733 loss_ctc 21.749899 loss_rnnt 13.556462 hw_loss 0.212952 lr 0.00051945 rank 5
2023-02-11 21:15:13,156 DEBUG TRAIN Batch 11/900 loss 13.130771 loss_att 16.550838 loss_ctc 20.399971 loss_rnnt 9.780159 hw_loss 0.318257 lr 0.00051943 rank 0
2023-02-11 21:15:13,162 DEBUG TRAIN Batch 11/900 loss 14.032851 loss_att 14.523863 loss_ctc 16.216555 loss_rnnt 12.378226 hw_loss 0.237237 lr 0.00051930 rank 2
2023-02-11 21:15:13,164 DEBUG TRAIN Batch 11/900 loss 7.290970 loss_att 9.527351 loss_ctc 12.548633 loss_rnnt 3.038383 hw_loss 0.582054 lr 0.00051961 rank 6
2023-02-11 21:16:29,467 DEBUG TRAIN Batch 11/1000 loss 17.211460 loss_att 18.148918 loss_ctc 21.543991 loss_rnnt 14.483298 hw_loss 0.368062 lr 0.00051928 rank 3
2023-02-11 21:16:29,472 DEBUG TRAIN Batch 11/1000 loss 10.026731 loss_att 13.611937 loss_ctc 17.333838 loss_rnnt 6.588206 hw_loss 0.327600 lr 0.00051902 rank 2
2023-02-11 21:16:29,475 DEBUG TRAIN Batch 11/1000 loss 14.554907 loss_att 16.207956 loss_ctc 26.288410 loss_rnnt 9.598822 hw_loss 0.573939 lr 0.00051918 rank 1
2023-02-11 21:16:29,476 DEBUG TRAIN Batch 11/1000 loss 10.922487 loss_att 11.959079 loss_ctc 11.270855 loss_rnnt 6.339900 hw_loss 0.811654 lr 0.00051927 rank 7
2023-02-11 21:16:29,481 DEBUG TRAIN Batch 11/1000 loss 19.202322 loss_att 20.458380 loss_ctc 24.368595 loss_rnnt 14.484166 hw_loss 0.708396 lr 0.00051915 rank 0
2023-02-11 21:16:29,480 DEBUG TRAIN Batch 11/1000 loss 11.149407 loss_att 12.973089 loss_ctc 15.211657 loss_rnnt 8.489836 hw_loss 0.328725 lr 0.00051930 rank 4
2023-02-11 21:16:29,481 DEBUG TRAIN Batch 11/1000 loss 13.301857 loss_att 14.911160 loss_ctc 23.843430 loss_rnnt 7.164388 hw_loss 0.826887 lr 0.00051917 rank 5
2023-02-11 21:16:29,491 DEBUG TRAIN Batch 11/1000 loss 16.716389 loss_att 17.100319 loss_ctc 28.214733 loss_rnnt 11.833536 hw_loss 0.613679 lr 0.00051933 rank 6
2023-02-11 21:17:46,624 DEBUG TRAIN Batch 11/1100 loss 9.562496 loss_att 9.136900 loss_ctc 12.005859 loss_rnnt 6.973467 hw_loss 0.440319 lr 0.00051900 rank 3
2023-02-11 21:17:46,628 DEBUG TRAIN Batch 11/1100 loss 6.732057 loss_att 8.730884 loss_ctc 9.256189 loss_rnnt 3.707743 hw_loss 0.428999 lr 0.00051905 rank 6
2023-02-11 21:17:46,631 DEBUG TRAIN Batch 11/1100 loss 13.580729 loss_att 15.217564 loss_ctc 24.574211 loss_rnnt 9.029663 hw_loss 0.517106 lr 0.00051899 rank 7
2023-02-11 21:17:46,632 DEBUG TRAIN Batch 11/1100 loss 15.168816 loss_att 15.364813 loss_ctc 22.165104 loss_rnnt 11.058634 hw_loss 0.588402 lr 0.00051887 rank 0
2023-02-11 21:17:46,634 DEBUG TRAIN Batch 11/1100 loss 11.397149 loss_att 15.664076 loss_ctc 17.428673 loss_rnnt 6.567597 hw_loss 0.594743 lr 0.00051890 rank 1
2023-02-11 21:17:46,636 DEBUG TRAIN Batch 11/1100 loss 14.150040 loss_att 17.217182 loss_ctc 21.981613 loss_rnnt 10.670116 hw_loss 0.341678 lr 0.00051889 rank 5
2023-02-11 21:17:46,637 DEBUG TRAIN Batch 11/1100 loss 9.863808 loss_att 12.090630 loss_ctc 16.896626 loss_rnnt 7.564392 hw_loss 0.171814 lr 0.00051902 rank 4
2023-02-11 21:17:46,642 DEBUG TRAIN Batch 11/1100 loss 11.329594 loss_att 11.036757 loss_ctc 14.692511 loss_rnnt 8.411410 hw_loss 0.474068 lr 0.00051874 rank 2
2023-02-11 21:19:03,226 DEBUG TRAIN Batch 11/1200 loss 22.996315 loss_att 18.964544 loss_ctc 26.688398 loss_rnnt 17.692913 hw_loss 1.053277 lr 0.00051859 rank 0
2023-02-11 21:19:03,227 DEBUG TRAIN Batch 11/1200 loss 16.950912 loss_att 14.693056 loss_ctc 19.709743 loss_rnnt 11.733055 hw_loss 0.994047 lr 0.00051872 rank 3
2023-02-11 21:19:03,231 DEBUG TRAIN Batch 11/1200 loss 9.235726 loss_att 8.876877 loss_ctc 10.622118 loss_rnnt 6.105466 hw_loss 0.565721 lr 0.00051874 rank 4
2023-02-11 21:19:03,232 DEBUG TRAIN Batch 11/1200 loss 15.922543 loss_att 16.184118 loss_ctc 23.488371 loss_rnnt 10.493056 hw_loss 0.819074 lr 0.00051871 rank 7
2023-02-11 21:19:03,233 DEBUG TRAIN Batch 11/1200 loss 16.122780 loss_att 14.802417 loss_ctc 19.683607 loss_rnnt 12.962191 hw_loss 0.553103 lr 0.00051862 rank 1
2023-02-11 21:19:03,233 DEBUG TRAIN Batch 11/1200 loss 11.108402 loss_att 16.125648 loss_ctc 17.057787 loss_rnnt 8.443789 hw_loss 0.162733 lr 0.00051877 rank 6
2023-02-11 21:19:03,235 DEBUG TRAIN Batch 11/1200 loss 15.219466 loss_att 14.004630 loss_ctc 20.419081 loss_rnnt 10.992103 hw_loss 0.708197 lr 0.00051862 rank 5
2023-02-11 21:19:03,276 DEBUG TRAIN Batch 11/1200 loss 18.461563 loss_att 17.250835 loss_ctc 23.807491 loss_rnnt 15.287193 hw_loss 0.506949 lr 0.00051846 rank 2
2023-02-11 21:20:20,765 DEBUG TRAIN Batch 11/1300 loss 25.645712 loss_att 24.998383 loss_ctc 34.019657 loss_rnnt 22.209709 hw_loss 0.459177 lr 0.00051843 rank 7
2023-02-11 21:20:20,766 DEBUG TRAIN Batch 11/1300 loss 13.827843 loss_att 14.210327 loss_ctc 22.694275 loss_rnnt 9.976023 hw_loss 0.486212 lr 0.00051844 rank 3
2023-02-11 21:20:20,768 DEBUG TRAIN Batch 11/1300 loss 21.810629 loss_att 24.963634 loss_ctc 34.717148 loss_rnnt 17.047165 hw_loss 0.452249 lr 0.00051834 rank 5
2023-02-11 21:20:20,772 DEBUG TRAIN Batch 11/1300 loss 15.994893 loss_att 11.290125 loss_ctc 15.516931 loss_rnnt 9.888974 hw_loss 1.333238 lr 0.00051849 rank 6
2023-02-11 21:20:20,774 DEBUG TRAIN Batch 11/1300 loss 5.440465 loss_att 8.791328 loss_ctc 7.096994 loss_rnnt 3.232488 hw_loss 0.246925 lr 0.00051818 rank 2
2023-02-11 21:20:20,775 DEBUG TRAIN Batch 11/1300 loss 6.818115 loss_att 7.138962 loss_ctc 8.747835 loss_rnnt 3.327576 hw_loss 0.594201 lr 0.00051831 rank 0
2023-02-11 21:20:20,776 DEBUG TRAIN Batch 11/1300 loss 8.924840 loss_att 12.040359 loss_ctc 17.852865 loss_rnnt 5.334303 hw_loss 0.333193 lr 0.00051846 rank 4
2023-02-11 21:20:20,815 DEBUG TRAIN Batch 11/1300 loss 14.715554 loss_att 9.799967 loss_ctc 14.456257 loss_rnnt 9.934667 hw_loss 1.087233 lr 0.00051834 rank 1
2023-02-11 21:21:39,419 DEBUG TRAIN Batch 11/1400 loss 17.966003 loss_att 23.131489 loss_ctc 25.852894 loss_rnnt 14.165966 hw_loss 0.321629 lr 0.00051806 rank 5
2023-02-11 21:21:39,421 DEBUG TRAIN Batch 11/1400 loss 16.421606 loss_att 17.606289 loss_ctc 24.216917 loss_rnnt 13.659694 hw_loss 0.278550 lr 0.00051806 rank 1
2023-02-11 21:21:39,421 DEBUG TRAIN Batch 11/1400 loss 11.795451 loss_att 14.798673 loss_ctc 18.429527 loss_rnnt 7.818027 hw_loss 0.467294 lr 0.00051803 rank 0
2023-02-11 21:21:39,423 DEBUG TRAIN Batch 11/1400 loss 10.455821 loss_att 10.788101 loss_ctc 14.845804 loss_rnnt 7.655212 hw_loss 0.402904 lr 0.00051816 rank 7
2023-02-11 21:21:39,425 DEBUG TRAIN Batch 11/1400 loss 13.330983 loss_att 16.432701 loss_ctc 24.915142 loss_rnnt 10.758408 hw_loss 0.076440 lr 0.00051818 rank 4
2023-02-11 21:21:39,436 DEBUG TRAIN Batch 11/1400 loss 11.555142 loss_att 13.278943 loss_ctc 18.146303 loss_rnnt 8.696402 hw_loss 0.306592 lr 0.00051816 rank 3
2023-02-11 21:21:39,438 DEBUG TRAIN Batch 11/1400 loss 19.386957 loss_att 23.338371 loss_ctc 32.436447 loss_rnnt 14.201095 hw_loss 0.497934 lr 0.00051821 rank 6
2023-02-11 21:21:39,458 DEBUG TRAIN Batch 11/1400 loss 11.000185 loss_att 14.272592 loss_ctc 21.507435 loss_rnnt 7.749979 hw_loss 0.224017 lr 0.00051791 rank 2
2023-02-11 21:22:56,081 DEBUG TRAIN Batch 11/1500 loss 15.945709 loss_att 18.141798 loss_ctc 23.586075 loss_rnnt 12.432800 hw_loss 0.385308 lr 0.00051788 rank 3
2023-02-11 21:22:56,084 DEBUG TRAIN Batch 11/1500 loss 9.389558 loss_att 11.777788 loss_ctc 18.847803 loss_rnnt 6.472633 hw_loss 0.220909 lr 0.00051776 rank 0
2023-02-11 21:22:56,089 DEBUG TRAIN Batch 11/1500 loss 5.943383 loss_att 9.884202 loss_ctc 12.442856 loss_rnnt 2.172671 hw_loss 0.396741 lr 0.00051778 rank 5
2023-02-11 21:22:56,090 DEBUG TRAIN Batch 11/1500 loss 17.395775 loss_att 18.075756 loss_ctc 21.852158 loss_rnnt 15.211588 hw_loss 0.272626 lr 0.00051763 rank 2
2023-02-11 21:22:56,089 DEBUG TRAIN Batch 11/1500 loss 9.549245 loss_att 11.905737 loss_ctc 14.066198 loss_rnnt 7.070453 hw_loss 0.263481 lr 0.00051788 rank 7
2023-02-11 21:22:56,090 DEBUG TRAIN Batch 11/1500 loss 26.450937 loss_att 24.542706 loss_ctc 41.351219 loss_rnnt 21.101521 hw_loss 0.702067 lr 0.00051790 rank 4
2023-02-11 21:22:56,093 DEBUG TRAIN Batch 11/1500 loss 28.163774 loss_att 29.568422 loss_ctc 42.743523 loss_rnnt 23.082939 hw_loss 0.535489 lr 0.00051794 rank 6
2023-02-11 21:22:56,137 DEBUG TRAIN Batch 11/1500 loss 7.807894 loss_att 10.722126 loss_ctc 8.818281 loss_rnnt 5.279221 hw_loss 0.339583 lr 0.00051778 rank 1
2023-02-11 21:24:10,892 DEBUG TRAIN Batch 11/1600 loss 14.483664 loss_att 17.574955 loss_ctc 25.040932 loss_rnnt 9.550529 hw_loss 0.545107 lr 0.00051751 rank 1
2023-02-11 21:24:10,892 DEBUG TRAIN Batch 11/1600 loss 27.606985 loss_att 25.940296 loss_ctc 36.855171 loss_rnnt 24.132313 hw_loss 0.482797 lr 0.00051762 rank 4
2023-02-11 21:24:10,894 DEBUG TRAIN Batch 11/1600 loss 13.027398 loss_att 15.866140 loss_ctc 21.903612 loss_rnnt 9.961811 hw_loss 0.246439 lr 0.00051761 rank 3
2023-02-11 21:24:10,897 DEBUG TRAIN Batch 11/1600 loss 22.744070 loss_att 19.748028 loss_ctc 31.119328 loss_rnnt 16.366156 hw_loss 1.098829 lr 0.00051760 rank 7
2023-02-11 21:24:10,898 DEBUG TRAIN Batch 11/1600 loss 18.888363 loss_att 18.436565 loss_ctc 25.707695 loss_rnnt 15.908328 hw_loss 0.405216 lr 0.00051748 rank 0
2023-02-11 21:24:10,899 DEBUG TRAIN Batch 11/1600 loss 17.437603 loss_att 22.294024 loss_ctc 25.883335 loss_rnnt 13.706867 hw_loss 0.306254 lr 0.00051750 rank 5
2023-02-11 21:24:10,902 DEBUG TRAIN Batch 11/1600 loss 28.091423 loss_att 35.678963 loss_ctc 47.615368 loss_rnnt 23.086336 hw_loss 0.165822 lr 0.00051766 rank 6
2023-02-11 21:24:10,944 DEBUG TRAIN Batch 11/1600 loss 8.839501 loss_att 9.599403 loss_ctc 11.430478 loss_rnnt 5.105236 hw_loss 0.606904 lr 0.00051735 rank 2
2023-02-11 21:25:27,273 DEBUG TRAIN Batch 11/1700 loss 22.144262 loss_att 28.695690 loss_ctc 40.661495 loss_rnnt 16.626406 hw_loss 0.325989 lr 0.00051733 rank 3
2023-02-11 21:25:27,276 DEBUG TRAIN Batch 11/1700 loss 13.686798 loss_att 12.700045 loss_ctc 16.979443 loss_rnnt 9.977677 hw_loss 0.650147 lr 0.00051723 rank 1
2023-02-11 21:25:27,277 DEBUG TRAIN Batch 11/1700 loss 29.752802 loss_att 32.691528 loss_ctc 43.512825 loss_rnnt 26.247017 hw_loss 0.203132 lr 0.00051720 rank 0
2023-02-11 21:25:27,279 DEBUG TRAIN Batch 11/1700 loss 14.989841 loss_att 16.863033 loss_ctc 21.463793 loss_rnnt 10.778307 hw_loss 0.557569 lr 0.00051732 rank 7
2023-02-11 21:25:27,279 DEBUG TRAIN Batch 11/1700 loss 24.625154 loss_att 23.284775 loss_ctc 35.856934 loss_rnnt 21.122553 hw_loss 0.426207 lr 0.00051735 rank 4
2023-02-11 21:25:27,283 DEBUG TRAIN Batch 11/1700 loss 14.049087 loss_att 16.210413 loss_ctc 22.389635 loss_rnnt 11.330658 hw_loss 0.220142 lr 0.00051723 rank 5
2023-02-11 21:25:27,283 DEBUG TRAIN Batch 11/1700 loss 8.876451 loss_att 11.652218 loss_ctc 12.301554 loss_rnnt 6.192759 hw_loss 0.313473 lr 0.00051738 rank 6
2023-02-11 21:25:27,289 DEBUG TRAIN Batch 11/1700 loss 10.136527 loss_att 12.585528 loss_ctc 15.193641 loss_rnnt 5.932298 hw_loss 0.570027 lr 0.00051707 rank 2
2023-02-11 21:26:45,688 DEBUG TRAIN Batch 11/1800 loss 21.235409 loss_att 24.892643 loss_ctc 39.198944 loss_rnnt 16.714518 hw_loss 0.261432 lr 0.00051705 rank 7
2023-02-11 21:26:45,690 DEBUG TRAIN Batch 11/1800 loss 14.824728 loss_att 18.330889 loss_ctc 16.690983 loss_rnnt 9.834587 hw_loss 0.757514 lr 0.00051705 rank 3
2023-02-11 21:26:45,692 DEBUG TRAIN Batch 11/1800 loss 13.283085 loss_att 12.362605 loss_ctc 16.711800 loss_rnnt 7.312975 hw_loss 1.068196 lr 0.00051680 rank 2
2023-02-11 21:26:45,693 DEBUG TRAIN Batch 11/1800 loss 13.605219 loss_att 13.267464 loss_ctc 19.306751 loss_rnnt 8.804260 hw_loss 0.770307 lr 0.00051707 rank 4
2023-02-11 21:26:45,696 DEBUG TRAIN Batch 11/1800 loss 25.591560 loss_att 27.199905 loss_ctc 35.687447 loss_rnnt 20.353289 hw_loss 0.669466 lr 0.00051695 rank 5
2023-02-11 21:26:45,696 DEBUG TRAIN Batch 11/1800 loss 18.785847 loss_att 17.575382 loss_ctc 19.982090 loss_rnnt 14.529943 hw_loss 0.813468 lr 0.00051692 rank 0
2023-02-11 21:26:45,698 DEBUG TRAIN Batch 11/1800 loss 28.298615 loss_att 31.159664 loss_ctc 53.237503 loss_rnnt 23.132473 hw_loss 0.237890 lr 0.00051710 rank 6
2023-02-11 21:26:45,742 DEBUG TRAIN Batch 11/1800 loss 24.831842 loss_att 24.757736 loss_ctc 38.938385 loss_rnnt 20.931948 hw_loss 0.381345 lr 0.00051695 rank 1
2023-02-11 21:28:02,678 DEBUG TRAIN Batch 11/1900 loss 11.633583 loss_att 11.094009 loss_ctc 13.336930 loss_rnnt 7.206424 hw_loss 0.807743 lr 0.00051678 rank 3
2023-02-11 21:28:02,680 DEBUG TRAIN Batch 11/1900 loss 15.963036 loss_att 12.870121 loss_ctc 14.577382 loss_rnnt 11.419765 hw_loss 1.002489 lr 0.00051667 rank 5
2023-02-11 21:28:02,680 DEBUG TRAIN Batch 11/1900 loss 15.382987 loss_att 10.816835 loss_ctc 16.152597 loss_rnnt 10.032890 hw_loss 1.155133 lr 0.00051677 rank 7
2023-02-11 21:28:02,680 DEBUG TRAIN Batch 11/1900 loss 14.150154 loss_att 10.825024 loss_ctc 13.839652 loss_rnnt 9.550333 hw_loss 0.994921 lr 0.00051679 rank 4
2023-02-11 21:28:02,680 DEBUG TRAIN Batch 11/1900 loss 11.030499 loss_att 10.023251 loss_ctc 14.405505 loss_rnnt 7.720160 hw_loss 0.574085 lr 0.00051683 rank 6
2023-02-11 21:28:02,684 DEBUG TRAIN Batch 11/1900 loss 20.056408 loss_att 21.912338 loss_ctc 34.792839 loss_rnnt 16.062031 hw_loss 0.310937 lr 0.00051665 rank 0
2023-02-11 21:28:02,686 DEBUG TRAIN Batch 11/1900 loss 10.650845 loss_att 13.329401 loss_ctc 14.025836 loss_rnnt 8.594790 hw_loss 0.200689 lr 0.00051668 rank 1
2023-02-11 21:28:02,687 DEBUG TRAIN Batch 11/1900 loss 13.221224 loss_att 10.878746 loss_ctc 16.201773 loss_rnnt 10.056739 hw_loss 0.606670 lr 0.00051652 rank 2
2023-02-11 21:29:17,972 DEBUG TRAIN Batch 11/2000 loss 9.915334 loss_att 14.723061 loss_ctc 13.189045 loss_rnnt 5.613721 hw_loss 0.544420 lr 0.00051650 rank 3
2023-02-11 21:29:17,973 DEBUG TRAIN Batch 11/2000 loss 12.551047 loss_att 12.307482 loss_ctc 15.211642 loss_rnnt 8.990433 hw_loss 0.610234 lr 0.00051637 rank 0
2023-02-11 21:29:17,974 DEBUG TRAIN Batch 11/2000 loss 15.095007 loss_att 11.658776 loss_ctc 16.133646 loss_rnnt 12.875376 hw_loss 0.519073 lr 0.00051640 rank 5
2023-02-11 21:29:17,974 DEBUG TRAIN Batch 11/2000 loss 14.895306 loss_att 17.406500 loss_ctc 26.660505 loss_rnnt 10.532604 hw_loss 0.429707 lr 0.00051649 rank 7
2023-02-11 21:29:17,976 DEBUG TRAIN Batch 11/2000 loss 25.503012 loss_att 27.808994 loss_ctc 38.834007 loss_rnnt 21.259331 hw_loss 0.375941 lr 0.00051655 rank 6
2023-02-11 21:29:17,976 DEBUG TRAIN Batch 11/2000 loss 13.403223 loss_att 14.334905 loss_ctc 17.387733 loss_rnnt 9.341788 hw_loss 0.626968 lr 0.00051652 rank 4
2023-02-11 21:29:17,978 DEBUG TRAIN Batch 11/2000 loss 20.653677 loss_att 22.835569 loss_ctc 27.142849 loss_rnnt 16.329557 hw_loss 0.566722 lr 0.00051640 rank 1
2023-02-11 21:29:18,016 DEBUG TRAIN Batch 11/2000 loss 5.155766 loss_att 7.921959 loss_ctc 4.045379 loss_rnnt 3.425999 hw_loss 0.248359 lr 0.00051625 rank 2
2023-02-11 21:30:35,723 DEBUG TRAIN Batch 11/2100 loss 9.849085 loss_att 13.097993 loss_ctc 14.532927 loss_rnnt 6.745234 hw_loss 0.343042 lr 0.00051622 rank 3
2023-02-11 21:30:35,725 DEBUG TRAIN Batch 11/2100 loss 13.647896 loss_att 18.364969 loss_ctc 32.552120 loss_rnnt 9.941507 hw_loss 0.045452 lr 0.00051622 rank 7
2023-02-11 21:30:35,726 DEBUG TRAIN Batch 11/2100 loss 13.564007 loss_att 18.097506 loss_ctc 25.407553 loss_rnnt 9.067389 hw_loss 0.377021 lr 0.00051610 rank 0
2023-02-11 21:30:35,730 DEBUG TRAIN Batch 11/2100 loss 6.514169 loss_att 10.200625 loss_ctc 8.420141 loss_rnnt 2.785471 hw_loss 0.513239 lr 0.00051624 rank 4
2023-02-11 21:30:35,730 DEBUG TRAIN Batch 11/2100 loss 14.981255 loss_att 15.891203 loss_ctc 21.955212 loss_rnnt 11.911357 hw_loss 0.367134 lr 0.00051628 rank 6
2023-02-11 21:30:35,736 DEBUG TRAIN Batch 11/2100 loss 24.983786 loss_att 29.120680 loss_ctc 45.312252 loss_rnnt 20.012861 hw_loss 0.268703 lr 0.00051597 rank 2
2023-02-11 21:30:35,737 DEBUG TRAIN Batch 11/2100 loss 7.773917 loss_att 10.329273 loss_ctc 9.729778 loss_rnnt 5.393338 hw_loss 0.301636 lr 0.00051612 rank 5
2023-02-11 21:30:35,781 DEBUG TRAIN Batch 11/2100 loss 9.116260 loss_att 8.985815 loss_ctc 13.673723 loss_rnnt 6.544591 hw_loss 0.373143 lr 0.00051613 rank 1
2023-02-11 21:31:52,849 DEBUG TRAIN Batch 11/2200 loss 12.318814 loss_att 14.208080 loss_ctc 17.334467 loss_rnnt 8.573685 hw_loss 0.505973 lr 0.00051595 rank 3
2023-02-11 21:31:52,850 DEBUG TRAIN Batch 11/2200 loss 18.428905 loss_att 22.448708 loss_ctc 23.282333 loss_rnnt 13.946699 hw_loss 0.568336 lr 0.00051594 rank 7
2023-02-11 21:31:52,854 DEBUG TRAIN Batch 11/2200 loss 11.039980 loss_att 13.814510 loss_ctc 17.660894 loss_rnnt 7.595369 hw_loss 0.376297 lr 0.00051585 rank 1
2023-02-11 21:31:52,854 DEBUG TRAIN Batch 11/2200 loss 20.073351 loss_att 24.686768 loss_ctc 31.224539 loss_rnnt 16.077934 hw_loss 0.297358 lr 0.00051597 rank 4
2023-02-11 21:31:52,854 DEBUG TRAIN Batch 11/2200 loss 19.422918 loss_att 20.765728 loss_ctc 35.723255 loss_rnnt 13.951017 hw_loss 0.568117 lr 0.00051585 rank 5
2023-02-11 21:31:52,854 DEBUG TRAIN Batch 11/2200 loss 19.094360 loss_att 22.003174 loss_ctc 31.115236 loss_rnnt 15.963266 hw_loss 0.177478 lr 0.00051570 rank 2
2023-02-11 21:31:52,858 DEBUG TRAIN Batch 11/2200 loss 16.799025 loss_att 20.290083 loss_ctc 32.792282 loss_rnnt 11.828684 hw_loss 0.401193 lr 0.00051582 rank 0
2023-02-11 21:31:52,900 DEBUG TRAIN Batch 11/2200 loss 18.668077 loss_att 24.940298 loss_ctc 32.590534 loss_rnnt 13.316414 hw_loss 0.420167 lr 0.00051600 rank 6
2023-02-11 21:33:09,244 DEBUG TRAIN Batch 11/2300 loss 16.168407 loss_att 19.820267 loss_ctc 22.693447 loss_rnnt 12.248893 hw_loss 0.434838 lr 0.00051567 rank 3
2023-02-11 21:33:09,245 DEBUG TRAIN Batch 11/2300 loss 35.067341 loss_att 41.030960 loss_ctc 52.108105 loss_rnnt 27.938631 hw_loss 0.686978 lr 0.00051567 rank 7
2023-02-11 21:33:09,246 DEBUG TRAIN Batch 11/2300 loss 8.857773 loss_att 12.812201 loss_ctc 15.192549 loss_rnnt 5.341666 hw_loss 0.352610 lr 0.00051542 rank 2
2023-02-11 21:33:09,249 DEBUG TRAIN Batch 11/2300 loss 11.122595 loss_att 13.746042 loss_ctc 18.306122 loss_rnnt 7.915633 hw_loss 0.323338 lr 0.00051555 rank 0
2023-02-11 21:33:09,253 DEBUG TRAIN Batch 11/2300 loss 16.321808 loss_att 16.975004 loss_ctc 29.074993 loss_rnnt 12.985722 hw_loss 0.282192 lr 0.00051557 rank 5
2023-02-11 21:33:09,254 DEBUG TRAIN Batch 11/2300 loss 17.161495 loss_att 16.833694 loss_ctc 23.270489 loss_rnnt 13.355988 hw_loss 0.573101 lr 0.00051573 rank 6
2023-02-11 21:33:09,256 DEBUG TRAIN Batch 11/2300 loss 8.234343 loss_att 11.605001 loss_ctc 14.213288 loss_rnnt 6.554745 hw_loss 0.039051 lr 0.00051569 rank 4
2023-02-11 21:33:09,299 DEBUG TRAIN Batch 11/2300 loss 20.685211 loss_att 25.389965 loss_ctc 35.289505 loss_rnnt 16.382881 hw_loss 0.265151 lr 0.00051558 rank 1
2023-02-11 21:34:25,231 DEBUG TRAIN Batch 11/2400 loss 14.552410 loss_att 14.915010 loss_ctc 22.706404 loss_rnnt 11.920836 hw_loss 0.275973 lr 0.00051545 rank 6
2023-02-11 21:34:25,231 DEBUG TRAIN Batch 11/2400 loss 10.015307 loss_att 11.043864 loss_ctc 14.717772 loss_rnnt 7.138583 hw_loss 0.383253 lr 0.00051540 rank 3
2023-02-11 21:34:25,233 DEBUG TRAIN Batch 11/2400 loss 25.289190 loss_att 24.654192 loss_ctc 40.272781 loss_rnnt 20.516058 hw_loss 0.544185 lr 0.00051530 rank 1
2023-02-11 21:34:25,234 DEBUG TRAIN Batch 11/2400 loss 15.538688 loss_att 16.569220 loss_ctc 24.756466 loss_rnnt 11.660816 hw_loss 0.458011 lr 0.00051515 rank 2
2023-02-11 21:34:25,235 DEBUG TRAIN Batch 11/2400 loss 8.934973 loss_att 11.520853 loss_ctc 16.220694 loss_rnnt 4.478879 hw_loss 0.556404 lr 0.00051542 rank 4
2023-02-11 21:34:25,237 DEBUG TRAIN Batch 11/2400 loss 20.766613 loss_att 20.115078 loss_ctc 22.081295 loss_rnnt 16.670254 hw_loss 0.759632 lr 0.00051540 rank 7
2023-02-11 21:34:25,238 DEBUG TRAIN Batch 11/2400 loss 17.569862 loss_att 19.225784 loss_ctc 26.321373 loss_rnnt 12.910857 hw_loss 0.592678 lr 0.00051530 rank 5
2023-02-11 21:34:25,238 DEBUG TRAIN Batch 11/2400 loss 13.589828 loss_att 15.257829 loss_ctc 19.536684 loss_rnnt 10.352996 hw_loss 0.395685 lr 0.00051528 rank 0
2023-02-11 21:35:44,278 DEBUG TRAIN Batch 11/2500 loss 11.217224 loss_att 12.648242 loss_ctc 20.023796 loss_rnnt 7.857150 hw_loss 0.356186 lr 0.00051518 rank 6
2023-02-11 21:35:44,281 DEBUG TRAIN Batch 11/2500 loss 14.468138 loss_att 13.128820 loss_ctc 16.528450 loss_rnnt 9.874918 hw_loss 0.859945 lr 0.00051500 rank 0
2023-02-11 21:35:44,282 DEBUG TRAIN Batch 11/2500 loss 19.558571 loss_att 18.444506 loss_ctc 22.246695 loss_rnnt 13.391936 hw_loss 1.130819 lr 0.00051503 rank 1
2023-02-11 21:35:44,282 DEBUG TRAIN Batch 11/2500 loss 17.442307 loss_att 16.207844 loss_ctc 21.586487 loss_rnnt 13.653856 hw_loss 0.653022 lr 0.00051512 rank 7
2023-02-11 21:35:44,282 DEBUG TRAIN Batch 11/2500 loss 14.450100 loss_att 13.813687 loss_ctc 17.958115 loss_rnnt 9.130020 hw_loss 0.933680 lr 0.00051503 rank 5
2023-02-11 21:35:44,283 DEBUG TRAIN Batch 11/2500 loss 17.708364 loss_att 17.964809 loss_ctc 25.035643 loss_rnnt 12.996761 hw_loss 0.690627 lr 0.00051513 rank 3
2023-02-11 21:35:44,286 DEBUG TRAIN Batch 11/2500 loss 16.940195 loss_att 17.844522 loss_ctc 26.021692 loss_rnnt 13.468887 hw_loss 0.389921 lr 0.00051515 rank 4
2023-02-11 21:35:44,287 DEBUG TRAIN Batch 11/2500 loss 14.311624 loss_att 12.870058 loss_ctc 22.834127 loss_rnnt 10.507141 hw_loss 0.554336 lr 0.00051488 rank 2
2023-02-11 21:36:59,388 DEBUG TRAIN Batch 11/2600 loss 15.624504 loss_att 21.040392 loss_ctc 26.505812 loss_rnnt 11.777522 hw_loss 0.246181 lr 0.00051485 rank 7
2023-02-11 21:36:59,389 DEBUG TRAIN Batch 11/2600 loss 15.926040 loss_att 15.135758 loss_ctc 21.537313 loss_rnnt 14.094120 hw_loss 0.232839 lr 0.00051473 rank 0
2023-02-11 21:36:59,392 DEBUG TRAIN Batch 11/2600 loss 17.190033 loss_att 19.158110 loss_ctc 26.394768 loss_rnnt 14.494122 hw_loss 0.201562 lr 0.00051476 rank 1
2023-02-11 21:36:59,393 DEBUG TRAIN Batch 11/2600 loss 24.710222 loss_att 26.435757 loss_ctc 40.901875 loss_rnnt 19.924238 hw_loss 0.427873 lr 0.00051485 rank 3
2023-02-11 21:36:59,394 DEBUG TRAIN Batch 11/2600 loss 10.823698 loss_att 13.219790 loss_ctc 15.974657 loss_rnnt 9.079472 hw_loss 0.108415 lr 0.00051475 rank 5
2023-02-11 21:36:59,394 DEBUG TRAIN Batch 11/2600 loss 11.779093 loss_att 12.346723 loss_ctc 15.258758 loss_rnnt 7.383792 hw_loss 0.715841 lr 0.00051487 rank 4
2023-02-11 21:36:59,395 DEBUG TRAIN Batch 11/2600 loss 50.206528 loss_att 50.711552 loss_ctc 75.637749 loss_rnnt 44.939236 hw_loss 0.332899 lr 0.00051460 rank 2
2023-02-11 21:36:59,444 DEBUG TRAIN Batch 11/2600 loss 7.803440 loss_att 9.839178 loss_ctc 11.724487 loss_rnnt 4.200105 hw_loss 0.501259 lr 0.00051491 rank 6
2023-02-11 21:38:15,545 DEBUG TRAIN Batch 11/2700 loss 14.269714 loss_att 11.860226 loss_ctc 17.076128 loss_rnnt 11.436264 hw_loss 0.551467 lr 0.00051458 rank 3
2023-02-11 21:38:15,546 DEBUG TRAIN Batch 11/2700 loss 10.167816 loss_att 13.611683 loss_ctc 13.298035 loss_rnnt 7.111470 hw_loss 0.365664 lr 0.00051446 rank 0
2023-02-11 21:38:15,549 DEBUG TRAIN Batch 11/2700 loss 12.259320 loss_att 15.323687 loss_ctc 21.591640 loss_rnnt 9.323440 hw_loss 0.202256 lr 0.00051433 rank 2
2023-02-11 21:38:15,549 DEBUG TRAIN Batch 11/2700 loss 13.442978 loss_att 16.238358 loss_ctc 22.790913 loss_rnnt 10.211078 hw_loss 0.267456 lr 0.00051460 rank 4
2023-02-11 21:38:15,549 DEBUG TRAIN Batch 11/2700 loss 13.634297 loss_att 13.766107 loss_ctc 17.031738 loss_rnnt 10.906650 hw_loss 0.421555 lr 0.00051458 rank 7
2023-02-11 21:38:15,551 DEBUG TRAIN Batch 11/2700 loss 14.619286 loss_att 15.783151 loss_ctc 16.053837 loss_rnnt 10.752378 hw_loss 0.645536 lr 0.00051448 rank 5
2023-02-11 21:38:15,551 DEBUG TRAIN Batch 11/2700 loss 9.764030 loss_att 11.796026 loss_ctc 17.583019 loss_rnnt 5.428940 hw_loss 0.541155 lr 0.00051448 rank 1
2023-02-11 21:38:15,596 DEBUG TRAIN Batch 11/2700 loss 11.226387 loss_att 10.560774 loss_ctc 18.091066 loss_rnnt 7.820348 hw_loss 0.491976 lr 0.00051463 rank 6
2023-02-11 21:39:32,946 DEBUG TRAIN Batch 11/2800 loss 13.687794 loss_att 15.827812 loss_ctc 17.718679 loss_rnnt 11.544302 hw_loss 0.220882 lr 0.00051406 rank 2
2023-02-11 21:39:32,946 DEBUG TRAIN Batch 11/2800 loss 12.570181 loss_att 18.252869 loss_ctc 25.872208 loss_rnnt 8.251553 hw_loss 0.264091 lr 0.00051433 rank 4
2023-02-11 21:39:32,948 DEBUG TRAIN Batch 11/2800 loss 11.196045 loss_att 10.944809 loss_ctc 14.443810 loss_rnnt 6.222695 hw_loss 0.860730 lr 0.00051430 rank 7
2023-02-11 21:39:32,950 DEBUG TRAIN Batch 11/2800 loss 7.794794 loss_att 10.158970 loss_ctc 11.529671 loss_rnnt 3.838746 hw_loss 0.559730 lr 0.00051418 rank 0
2023-02-11 21:39:32,953 DEBUG TRAIN Batch 11/2800 loss 7.019461 loss_att 10.402875 loss_ctc 11.866447 loss_rnnt 4.102776 hw_loss 0.298826 lr 0.00051431 rank 3
2023-02-11 21:39:32,953 DEBUG TRAIN Batch 11/2800 loss 6.966935 loss_att 9.146639 loss_ctc 11.320580 loss_rnnt 4.774919 hw_loss 0.220423 lr 0.00051421 rank 5
2023-02-11 21:39:32,958 DEBUG TRAIN Batch 11/2800 loss 15.493893 loss_att 17.017040 loss_ctc 25.019604 loss_rnnt 12.169086 hw_loss 0.328140 lr 0.00051436 rank 6
2023-02-11 21:39:32,995 DEBUG TRAIN Batch 11/2800 loss 21.699690 loss_att 22.075012 loss_ctc 31.073101 loss_rnnt 19.962326 hw_loss 0.077346 lr 0.00051421 rank 1
2023-02-11 21:40:49,836 DEBUG TRAIN Batch 11/2900 loss 15.524471 loss_att 19.847389 loss_ctc 26.973564 loss_rnnt 12.184578 hw_loss 0.177893 lr 0.00051404 rank 3
2023-02-11 21:40:49,837 DEBUG TRAIN Batch 11/2900 loss 14.082129 loss_att 16.199242 loss_ctc 20.277409 loss_rnnt 10.758766 hw_loss 0.388857 lr 0.00051391 rank 0
2023-02-11 21:40:49,839 DEBUG TRAIN Batch 11/2900 loss 14.276554 loss_att 17.125683 loss_ctc 25.761089 loss_rnnt 11.715866 hw_loss 0.086173 lr 0.00051379 rank 2
2023-02-11 21:40:49,838 DEBUG TRAIN Batch 11/2900 loss 24.247471 loss_att 25.199718 loss_ctc 38.012585 loss_rnnt 20.380768 hw_loss 0.345170 lr 0.00051403 rank 7
2023-02-11 21:40:49,839 DEBUG TRAIN Batch 11/2900 loss 11.240689 loss_att 12.213134 loss_ctc 15.345196 loss_rnnt 7.295003 hw_loss 0.600737 lr 0.00051409 rank 6
2023-02-11 21:40:49,842 DEBUG TRAIN Batch 11/2900 loss 12.453775 loss_att 13.606269 loss_ctc 17.712078 loss_rnnt 10.930163 hw_loss 0.111001 lr 0.00051394 rank 1
2023-02-11 21:40:49,843 DEBUG TRAIN Batch 11/2900 loss 21.248991 loss_att 22.784845 loss_ctc 31.940395 loss_rnnt 18.217417 hw_loss 0.243540 lr 0.00051394 rank 5
2023-02-11 21:40:49,845 DEBUG TRAIN Batch 11/2900 loss 10.771504 loss_att 12.644909 loss_ctc 14.650966 loss_rnnt 8.191940 hw_loss 0.316429 lr 0.00051406 rank 4
2023-02-11 21:42:06,439 DEBUG TRAIN Batch 11/3000 loss 10.711612 loss_att 13.435263 loss_ctc 19.484077 loss_rnnt 8.599198 hw_loss 0.074629 lr 0.00051377 rank 3
2023-02-11 21:42:06,444 DEBUG TRAIN Batch 11/3000 loss 10.840573 loss_att 11.598782 loss_ctc 11.603463 loss_rnnt 8.171560 hw_loss 0.452935 lr 0.00051367 rank 5
2023-02-11 21:42:06,447 DEBUG TRAIN Batch 11/3000 loss 15.069420 loss_att 16.885799 loss_ctc 24.902498 loss_rnnt 11.538310 hw_loss 0.348142 lr 0.00051352 rank 2
2023-02-11 21:42:06,446 DEBUG TRAIN Batch 11/3000 loss 11.552426 loss_att 9.568996 loss_ctc 14.116880 loss_rnnt 8.155366 hw_loss 0.647216 lr 0.00051376 rank 7
2023-02-11 21:42:06,448 DEBUG TRAIN Batch 11/3000 loss 18.271074 loss_att 21.437830 loss_ctc 29.483995 loss_rnnt 14.510880 hw_loss 0.305960 lr 0.00051364 rank 0
2023-02-11 21:42:06,449 DEBUG TRAIN Batch 11/3000 loss 18.046223 loss_att 23.107458 loss_ctc 28.867474 loss_rnnt 13.234173 hw_loss 0.441932 lr 0.00051367 rank 1
2023-02-11 21:42:06,451 DEBUG TRAIN Batch 11/3000 loss 25.331825 loss_att 23.640009 loss_ctc 38.771667 loss_rnnt 20.496284 hw_loss 0.634111 lr 0.00051378 rank 4
2023-02-11 21:42:06,452 DEBUG TRAIN Batch 11/3000 loss 23.629978 loss_att 24.222012 loss_ctc 44.009815 loss_rnnt 18.118826 hw_loss 0.501644 lr 0.00051382 rank 6
2023-02-11 21:43:22,626 DEBUG TRAIN Batch 11/3100 loss 20.862328 loss_att 22.232597 loss_ctc 31.049397 loss_rnnt 17.536636 hw_loss 0.317505 lr 0.00051337 rank 0
2023-02-11 21:43:22,628 DEBUG TRAIN Batch 11/3100 loss 12.174024 loss_att 11.033378 loss_ctc 13.281954 loss_rnnt 8.464920 hw_loss 0.710533 lr 0.00051349 rank 7
2023-02-11 21:43:22,629 DEBUG TRAIN Batch 11/3100 loss 14.898582 loss_att 14.315404 loss_ctc 18.490057 loss_rnnt 11.106295 hw_loss 0.643136 lr 0.00051339 rank 5
2023-02-11 21:43:22,633 DEBUG TRAIN Batch 11/3100 loss 10.975608 loss_att 13.966770 loss_ctc 19.530973 loss_rnnt 6.194942 hw_loss 0.570322 lr 0.00051349 rank 3
2023-02-11 21:43:22,635 DEBUG TRAIN Batch 11/3100 loss 10.136968 loss_att 12.425760 loss_ctc 12.564850 loss_rnnt 6.924905 hw_loss 0.455735 lr 0.00051325 rank 2
2023-02-11 21:43:22,638 DEBUG TRAIN Batch 11/3100 loss 13.615679 loss_att 14.336235 loss_ctc 19.266937 loss_rnnt 11.649135 hw_loss 0.200425 lr 0.00051340 rank 1
2023-02-11 21:43:22,640 DEBUG TRAIN Batch 11/3100 loss 17.807749 loss_att 17.482855 loss_ctc 24.940302 loss_rnnt 15.619735 hw_loss 0.244123 lr 0.00051351 rank 4
2023-02-11 21:43:22,679 DEBUG TRAIN Batch 11/3100 loss 20.047108 loss_att 18.298857 loss_ctc 25.212173 loss_rnnt 14.874731 hw_loss 0.906253 lr 0.00051355 rank 6
2023-02-11 21:44:41,160 DEBUG TRAIN Batch 11/3200 loss 8.063677 loss_att 6.237733 loss_ctc 6.821293 loss_rnnt 4.742067 hw_loss 0.722334 lr 0.00051322 rank 3
2023-02-11 21:44:41,161 DEBUG TRAIN Batch 11/3200 loss 12.373215 loss_att 9.072618 loss_ctc 12.107610 loss_rnnt 7.755065 hw_loss 0.996316 lr 0.00051324 rank 4
2023-02-11 21:44:41,161 DEBUG TRAIN Batch 11/3200 loss 8.605628 loss_att 10.962325 loss_ctc 13.237032 loss_rnnt 6.453540 hw_loss 0.199355 lr 0.00051322 rank 7
2023-02-11 21:44:41,164 DEBUG TRAIN Batch 11/3200 loss 16.641220 loss_att 19.503853 loss_ctc 21.229126 loss_rnnt 13.480186 hw_loss 0.370648 lr 0.00051312 rank 5
2023-02-11 21:44:41,165 DEBUG TRAIN Batch 11/3200 loss 9.390298 loss_att 14.400650 loss_ctc 15.355028 loss_rnnt 6.478027 hw_loss 0.209044 lr 0.00051310 rank 0
2023-02-11 21:44:41,169 DEBUG TRAIN Batch 11/3200 loss 15.748096 loss_att 12.481523 loss_ctc 18.459551 loss_rnnt 11.554211 hw_loss 0.841064 lr 0.00051298 rank 2
2023-02-11 21:44:41,176 DEBUG TRAIN Batch 11/3200 loss 15.391448 loss_att 15.757754 loss_ctc 24.663925 loss_rnnt 12.266699 hw_loss 0.340342 lr 0.00051328 rank 6
2023-02-11 21:44:41,205 DEBUG TRAIN Batch 11/3200 loss 11.130953 loss_att 11.653612 loss_ctc 13.673408 loss_rnnt 7.912421 hw_loss 0.520313 lr 0.00051313 rank 1
2023-02-11 21:45:56,519 DEBUG TRAIN Batch 11/3300 loss 11.296156 loss_att 13.403230 loss_ctc 18.291557 loss_rnnt 8.753743 hw_loss 0.222802 lr 0.00051285 rank 5
2023-02-11 21:45:56,522 DEBUG TRAIN Batch 11/3300 loss 12.040052 loss_att 12.733500 loss_ctc 18.550940 loss_rnnt 9.511992 hw_loss 0.285235 lr 0.00051283 rank 0
2023-02-11 21:45:56,522 DEBUG TRAIN Batch 11/3300 loss 16.183798 loss_att 17.874928 loss_ctc 28.651663 loss_rnnt 11.949314 hw_loss 0.418852 lr 0.00051295 rank 3
2023-02-11 21:45:56,524 DEBUG TRAIN Batch 11/3300 loss 10.513104 loss_att 11.206798 loss_ctc 17.738876 loss_rnnt 7.408936 hw_loss 0.375374 lr 0.00051271 rank 2
2023-02-11 21:45:56,525 DEBUG TRAIN Batch 11/3300 loss 12.203017 loss_att 13.746916 loss_ctc 20.034966 loss_rnnt 7.753454 hw_loss 0.580598 lr 0.00051286 rank 1
2023-02-11 21:45:56,525 DEBUG TRAIN Batch 11/3300 loss 12.561542 loss_att 15.193510 loss_ctc 15.916659 loss_rnnt 7.601313 hw_loss 0.747466 lr 0.00051295 rank 7
2023-02-11 21:45:56,528 DEBUG TRAIN Batch 11/3300 loss 14.605258 loss_att 15.054092 loss_ctc 23.004669 loss_rnnt 11.490852 hw_loss 0.357134 lr 0.00051301 rank 6
2023-02-11 21:45:56,527 DEBUG TRAIN Batch 11/3300 loss 13.762763 loss_att 15.089476 loss_ctc 17.371456 loss_rnnt 9.965584 hw_loss 0.572002 lr 0.00051297 rank 4
2023-02-11 21:47:11,449 DEBUG TRAIN Batch 11/3400 loss 14.228191 loss_att 19.229515 loss_ctc 26.224874 loss_rnnt 10.517263 hw_loss 0.208332 lr 0.00051268 rank 7
2023-02-11 21:47:11,455 DEBUG TRAIN Batch 11/3400 loss 33.690739 loss_att 30.037733 loss_ctc 41.279881 loss_rnnt 28.917400 hw_loss 0.842260 lr 0.00051256 rank 0
2023-02-11 21:47:11,455 DEBUG TRAIN Batch 11/3400 loss 21.095324 loss_att 23.819599 loss_ctc 39.820080 loss_rnnt 15.821066 hw_loss 0.418644 lr 0.00051268 rank 3
2023-02-11 21:47:11,457 DEBUG TRAIN Batch 11/3400 loss 6.781794 loss_att 8.468813 loss_ctc 7.249381 loss_rnnt 4.486944 hw_loss 0.355332 lr 0.00051274 rank 6
2023-02-11 21:47:11,457 DEBUG TRAIN Batch 11/3400 loss 17.156454 loss_att 17.897945 loss_ctc 21.515640 loss_rnnt 14.854826 hw_loss 0.294770 lr 0.00051259 rank 1
2023-02-11 21:47:11,458 DEBUG TRAIN Batch 11/3400 loss 11.324459 loss_att 12.950562 loss_ctc 15.364809 loss_rnnt 7.868320 hw_loss 0.486039 lr 0.00051244 rank 2
2023-02-11 21:47:11,458 DEBUG TRAIN Batch 11/3400 loss 16.614153 loss_att 20.367149 loss_ctc 26.385490 loss_rnnt 13.042742 hw_loss 0.284619 lr 0.00051258 rank 5
2023-02-11 21:47:11,465 DEBUG TRAIN Batch 11/3400 loss 12.666527 loss_att 14.245619 loss_ctc 16.273243 loss_rnnt 9.069234 hw_loss 0.525109 lr 0.00051270 rank 4
2023-02-11 21:48:28,132 DEBUG TRAIN Batch 11/3500 loss 16.249252 loss_att 21.061516 loss_ctc 30.944885 loss_rnnt 10.675676 hw_loss 0.497195 lr 0.00051242 rank 3
2023-02-11 21:48:28,133 DEBUG TRAIN Batch 11/3500 loss 10.673820 loss_att 16.099205 loss_ctc 23.220354 loss_rnnt 7.203168 hw_loss 0.133632 lr 0.00051243 rank 4
2023-02-11 21:48:28,134 DEBUG TRAIN Batch 11/3500 loss 9.476299 loss_att 12.717161 loss_ctc 13.571465 loss_rnnt 5.467058 hw_loss 0.527821 lr 0.00051217 rank 2
2023-02-11 21:48:28,135 DEBUG TRAIN Batch 11/3500 loss 16.142590 loss_att 18.773037 loss_ctc 20.198021 loss_rnnt 12.778078 hw_loss 0.430818 lr 0.00051241 rank 7
2023-02-11 21:48:28,139 DEBUG TRAIN Batch 11/3500 loss 8.090103 loss_att 10.386443 loss_ctc 10.959101 loss_rnnt 5.847387 hw_loss 0.262672 lr 0.00051232 rank 5
2023-02-11 21:48:28,141 DEBUG TRAIN Batch 11/3500 loss 10.716196 loss_att 11.479685 loss_ctc 15.628917 loss_rnnt 6.962304 hw_loss 0.552406 lr 0.00051247 rank 6
2023-02-11 21:48:28,141 DEBUG TRAIN Batch 11/3500 loss 17.936544 loss_att 17.829782 loss_ctc 22.724190 loss_rnnt 13.636090 hw_loss 0.690648 lr 0.00051229 rank 0
2023-02-11 21:48:28,143 DEBUG TRAIN Batch 11/3500 loss 9.402012 loss_att 11.100410 loss_ctc 17.068060 loss_rnnt 6.727917 hw_loss 0.246052 lr 0.00051232 rank 1
2023-02-11 21:49:45,427 DEBUG TRAIN Batch 11/3600 loss 9.594857 loss_att 11.363171 loss_ctc 15.147953 loss_rnnt 5.921599 hw_loss 0.483597 lr 0.00051215 rank 3
2023-02-11 21:49:45,427 DEBUG TRAIN Batch 11/3600 loss 20.296515 loss_att 24.962927 loss_ctc 39.386040 loss_rnnt 15.479703 hw_loss 0.250924 lr 0.00051202 rank 0
2023-02-11 21:49:45,430 DEBUG TRAIN Batch 11/3600 loss 10.953118 loss_att 13.130503 loss_ctc 18.309128 loss_rnnt 7.877139 hw_loss 0.311194 lr 0.00051214 rank 7
2023-02-11 21:49:45,431 DEBUG TRAIN Batch 11/3600 loss 15.846721 loss_att 14.555794 loss_ctc 14.691362 loss_rnnt 14.290036 hw_loss 0.369172 lr 0.00051220 rank 6
2023-02-11 21:49:45,435 DEBUG TRAIN Batch 11/3600 loss 11.111130 loss_att 14.225746 loss_ctc 17.609898 loss_rnnt 8.958326 hw_loss 0.124383 lr 0.00051205 rank 1
2023-02-11 21:49:45,435 DEBUG TRAIN Batch 11/3600 loss 25.610086 loss_att 27.013695 loss_ctc 48.340469 loss_rnnt 19.784014 hw_loss 0.471493 lr 0.00051216 rank 4
2023-02-11 21:49:45,436 DEBUG TRAIN Batch 11/3600 loss 11.385284 loss_att 11.142111 loss_ctc 17.555855 loss_rnnt 8.379075 hw_loss 0.418519 lr 0.00051205 rank 5
2023-02-11 21:49:45,481 DEBUG TRAIN Batch 11/3600 loss 20.549545 loss_att 23.244677 loss_ctc 33.553108 loss_rnnt 16.824554 hw_loss 0.272279 lr 0.00051190 rank 2
2023-02-11 21:51:01,804 DEBUG TRAIN Batch 11/3700 loss 22.017759 loss_att 20.661625 loss_ctc 33.534206 loss_rnnt 16.802580 hw_loss 0.740790 lr 0.00051193 rank 6
2023-02-11 21:51:01,805 DEBUG TRAIN Batch 11/3700 loss 12.799715 loss_att 15.442469 loss_ctc 19.272890 loss_rnnt 9.144287 hw_loss 0.424460 lr 0.00051190 rank 4
2023-02-11 21:51:01,808 DEBUG TRAIN Batch 11/3700 loss 13.369316 loss_att 13.947508 loss_ctc 20.210794 loss_rnnt 8.376557 hw_loss 0.743423 lr 0.00051178 rank 5
2023-02-11 21:51:01,809 DEBUG TRAIN Batch 11/3700 loss 16.123028 loss_att 13.920079 loss_ctc 20.004431 loss_rnnt 11.186564 hw_loss 0.911162 lr 0.00051187 rank 7
2023-02-11 21:51:01,810 DEBUG TRAIN Batch 11/3700 loss 29.873098 loss_att 32.242577 loss_ctc 49.820461 loss_rnnt 26.592180 hw_loss 0.027632 lr 0.00051175 rank 0
2023-02-11 21:51:01,811 DEBUG TRAIN Batch 11/3700 loss 7.499541 loss_att 11.825338 loss_ctc 15.256071 loss_rnnt 5.173383 hw_loss 0.080024 lr 0.00051163 rank 2
2023-02-11 21:51:01,812 DEBUG TRAIN Batch 11/3700 loss 16.982929 loss_att 17.636375 loss_ctc 23.645519 loss_rnnt 13.331596 hw_loss 0.493556 lr 0.00051188 rank 3
2023-02-11 21:51:01,860 DEBUG TRAIN Batch 11/3700 loss 18.556105 loss_att 23.168268 loss_ctc 25.433077 loss_rnnt 16.117840 hw_loss 0.112294 lr 0.00051178 rank 1
2023-02-11 21:52:18,254 DEBUG TRAIN Batch 11/3800 loss 13.354635 loss_att 10.152579 loss_ctc 16.771633 loss_rnnt 8.727053 hw_loss 0.902324 lr 0.00051149 rank 0
2023-02-11 21:52:18,255 DEBUG TRAIN Batch 11/3800 loss 13.434226 loss_att 12.812849 loss_ctc 18.063145 loss_rnnt 8.201989 hw_loss 0.888623 lr 0.00051136 rank 2
2023-02-11 21:52:18,256 DEBUG TRAIN Batch 11/3800 loss 15.364233 loss_att 15.785481 loss_ctc 19.865295 loss_rnnt 11.451428 hw_loss 0.605327 lr 0.00051151 rank 1
2023-02-11 21:52:18,256 DEBUG TRAIN Batch 11/3800 loss 21.623611 loss_att 18.478775 loss_ctc 26.396170 loss_rnnt 18.480171 hw_loss 0.588013 lr 0.00051161 rank 3
2023-02-11 21:52:18,263 DEBUG TRAIN Batch 11/3800 loss 13.558722 loss_att 10.116061 loss_ctc 12.552029 loss_rnnt 8.185259 hw_loss 1.161791 lr 0.00051160 rank 7
2023-02-11 21:52:18,264 DEBUG TRAIN Batch 11/3800 loss 6.456881 loss_att 9.310360 loss_ctc 8.874457 loss_rnnt 3.045516 hw_loss 0.472186 lr 0.00051151 rank 5
2023-02-11 21:52:18,264 DEBUG TRAIN Batch 11/3800 loss 19.094940 loss_att 16.178139 loss_ctc 23.304245 loss_rnnt 15.040802 hw_loss 0.764298 lr 0.00051163 rank 4
2023-02-11 21:52:18,270 DEBUG TRAIN Batch 11/3800 loss 16.122541 loss_att 12.488752 loss_ctc 16.486353 loss_rnnt 11.104818 hw_loss 1.067995 lr 0.00051166 rank 6
2023-02-11 21:53:37,245 DEBUG TRAIN Batch 11/3900 loss 8.811239 loss_att 8.145649 loss_ctc 10.494118 loss_rnnt 6.706909 hw_loss 0.377450 lr 0.00051125 rank 1
2023-02-11 21:53:37,248 DEBUG TRAIN Batch 11/3900 loss 10.671624 loss_att 13.314162 loss_ctc 13.139511 loss_rnnt 8.786849 hw_loss 0.192603 lr 0.00051136 rank 4
2023-02-11 21:53:37,250 DEBUG TRAIN Batch 11/3900 loss 12.858927 loss_att 9.911166 loss_ctc 15.227987 loss_rnnt 8.451166 hw_loss 0.877770 lr 0.00051134 rank 3
2023-02-11 21:53:37,252 DEBUG TRAIN Batch 11/3900 loss 14.311029 loss_att 18.554611 loss_ctc 19.633591 loss_rnnt 10.858035 hw_loss 0.355238 lr 0.00051134 rank 7
2023-02-11 21:53:37,252 DEBUG TRAIN Batch 11/3900 loss 16.240213 loss_att 22.103125 loss_ctc 30.149662 loss_rnnt 12.843801 hw_loss 0.069232 lr 0.00051122 rank 0
2023-02-11 21:53:37,253 DEBUG TRAIN Batch 11/3900 loss 17.889641 loss_att 22.721680 loss_ctc 28.267727 loss_rnnt 13.875519 hw_loss 0.311994 lr 0.00051124 rank 5
2023-02-11 21:53:37,253 DEBUG TRAIN Batch 11/3900 loss 27.546051 loss_att 27.948586 loss_ctc 43.394440 loss_rnnt 23.890484 hw_loss 0.274115 lr 0.00051139 rank 6
2023-02-11 21:53:37,301 DEBUG TRAIN Batch 11/3900 loss 10.239292 loss_att 10.228166 loss_ctc 11.160280 loss_rnnt 7.133941 hw_loss 0.559646 lr 0.00051110 rank 2
2023-02-11 21:54:53,109 DEBUG TRAIN Batch 11/4000 loss 12.209158 loss_att 11.971717 loss_ctc 22.725620 loss_rnnt 7.201274 hw_loss 0.684971 lr 0.00051098 rank 5
2023-02-11 21:54:53,109 DEBUG TRAIN Batch 11/4000 loss 32.801365 loss_att 31.116461 loss_ctc 43.534088 loss_rnnt 30.839844 hw_loss 0.162651 lr 0.00051095 rank 0
2023-02-11 21:54:53,109 DEBUG TRAIN Batch 11/4000 loss 6.654932 loss_att 8.026923 loss_ctc 10.191180 loss_rnnt 3.870319 hw_loss 0.382259 lr 0.00051098 rank 1
2023-02-11 21:54:53,109 DEBUG TRAIN Batch 11/4000 loss 10.996741 loss_att 13.808749 loss_ctc 18.816231 loss_rnnt 8.297957 hw_loss 0.205085 lr 0.00051113 rank 6
2023-02-11 21:54:53,110 DEBUG TRAIN Batch 11/4000 loss 19.754770 loss_att 21.492004 loss_ctc 28.304729 loss_rnnt 17.217106 hw_loss 0.196917 lr 0.00051083 rank 2
2023-02-11 21:54:53,112 DEBUG TRAIN Batch 11/4000 loss 26.405975 loss_att 30.724854 loss_ctc 39.241859 loss_rnnt 21.818838 hw_loss 0.377233 lr 0.00051107 rank 3
2023-02-11 21:54:53,113 DEBUG TRAIN Batch 11/4000 loss 9.167686 loss_att 13.500057 loss_ctc 17.685349 loss_rnnt 5.643117 hw_loss 0.285451 lr 0.00051109 rank 4
2023-02-11 21:54:53,114 DEBUG TRAIN Batch 11/4000 loss 16.854095 loss_att 15.573734 loss_ctc 30.605301 loss_rnnt 14.545132 hw_loss 0.137164 lr 0.00051107 rank 7
2023-02-11 21:56:09,037 DEBUG TRAIN Batch 11/4100 loss 27.439547 loss_att 29.751656 loss_ctc 43.014427 loss_rnnt 22.663692 hw_loss 0.419397 lr 0.00051069 rank 0
2023-02-11 21:56:09,037 DEBUG TRAIN Batch 11/4100 loss 14.546277 loss_att 17.199423 loss_ctc 24.069786 loss_rnnt 12.372572 hw_loss 0.069989 lr 0.00051081 rank 3
2023-02-11 21:56:09,040 DEBUG TRAIN Batch 11/4100 loss 8.740401 loss_att 10.538722 loss_ctc 14.802502 loss_rnnt 4.652910 hw_loss 0.547415 lr 0.00051080 rank 7
2023-02-11 21:56:09,041 DEBUG TRAIN Batch 11/4100 loss 14.396640 loss_att 17.273239 loss_ctc 19.802437 loss_rnnt 10.897558 hw_loss 0.413060 lr 0.00051056 rank 2
2023-02-11 21:56:09,042 DEBUG TRAIN Batch 11/4100 loss 26.426294 loss_att 33.004765 loss_ctc 45.580894 loss_rnnt 21.619978 hw_loss 0.175626 lr 0.00051071 rank 5
2023-02-11 21:56:09,045 DEBUG TRAIN Batch 11/4100 loss 17.432898 loss_att 21.285976 loss_ctc 29.477421 loss_rnnt 11.911815 hw_loss 0.589599 lr 0.00051086 rank 6
2023-02-11 21:56:09,046 DEBUG TRAIN Batch 11/4100 loss 8.188416 loss_att 13.945247 loss_ctc 14.172222 loss_rnnt 5.555790 hw_loss 0.128141 lr 0.00051071 rank 1
2023-02-11 21:56:09,087 DEBUG TRAIN Batch 11/4100 loss 19.770105 loss_att 23.072937 loss_ctc 32.399986 loss_rnnt 15.056902 hw_loss 0.444122 lr 0.00051083 rank 4
2023-02-11 21:57:25,268 DEBUG TRAIN Batch 11/4200 loss 11.575684 loss_att 13.769169 loss_ctc 17.455961 loss_rnnt 8.410391 hw_loss 0.364230 lr 0.00051054 rank 7
2023-02-11 21:57:25,269 DEBUG TRAIN Batch 11/4200 loss 12.619340 loss_att 16.191730 loss_ctc 18.718292 loss_rnnt 8.892465 hw_loss 0.412351 lr 0.00051042 rank 0
2023-02-11 21:57:25,273 DEBUG TRAIN Batch 11/4200 loss 23.327648 loss_att 25.545755 loss_ctc 36.248108 loss_rnnt 19.631723 hw_loss 0.286795 lr 0.00051030 rank 2
2023-02-11 21:57:25,273 DEBUG TRAIN Batch 11/4200 loss 14.062261 loss_att 16.553085 loss_ctc 22.652771 loss_rnnt 11.512260 hw_loss 0.169956 lr 0.00051054 rank 3
2023-02-11 21:57:25,275 DEBUG TRAIN Batch 11/4200 loss 24.435642 loss_att 26.613659 loss_ctc 38.533962 loss_rnnt 19.055819 hw_loss 0.574584 lr 0.00051059 rank 6
2023-02-11 21:57:25,275 DEBUG TRAIN Batch 11/4200 loss 8.690507 loss_att 9.979641 loss_ctc 10.570711 loss_rnnt 5.083316 hw_loss 0.581001 lr 0.00051044 rank 5
2023-02-11 21:57:25,276 DEBUG TRAIN Batch 11/4200 loss 10.941883 loss_att 11.708682 loss_ctc 13.572176 loss_rnnt 7.504555 hw_loss 0.549987 lr 0.00051056 rank 4
2023-02-11 21:57:25,278 DEBUG TRAIN Batch 11/4200 loss 10.895885 loss_att 12.790550 loss_ctc 18.251394 loss_rnnt 7.044189 hw_loss 0.467255 lr 0.00051045 rank 1
2023-02-11 21:58:43,973 DEBUG TRAIN Batch 11/4300 loss 16.629206 loss_att 18.183380 loss_ctc 24.905413 loss_rnnt 12.986799 hw_loss 0.417765 lr 0.00051027 rank 7
2023-02-11 21:58:43,974 DEBUG TRAIN Batch 11/4300 loss 20.625462 loss_att 26.022953 loss_ctc 35.429062 loss_rnnt 16.659401 hw_loss 0.171141 lr 0.00051015 rank 0
2023-02-11 21:58:43,976 DEBUG TRAIN Batch 11/4300 loss 23.473305 loss_att 27.912199 loss_ctc 31.947174 loss_rnnt 19.025600 hw_loss 0.455639 lr 0.00051028 rank 3
2023-02-11 21:58:43,976 DEBUG TRAIN Batch 11/4300 loss 11.948079 loss_att 14.749235 loss_ctc 19.259418 loss_rnnt 8.492065 hw_loss 0.360176 lr 0.00051033 rank 6
2023-02-11 21:58:43,981 DEBUG TRAIN Batch 11/4300 loss 29.203053 loss_att 29.204165 loss_ctc 37.715473 loss_rnnt 25.085329 hw_loss 0.559221 lr 0.00051018 rank 5
2023-02-11 21:58:43,983 DEBUG TRAIN Batch 11/4300 loss 19.140100 loss_att 19.810162 loss_ctc 26.586769 loss_rnnt 15.491890 hw_loss 0.472745 lr 0.00051029 rank 4
2023-02-11 21:58:43,983 DEBUG TRAIN Batch 11/4300 loss 12.089246 loss_att 12.633820 loss_ctc 12.513447 loss_rnnt 8.216732 hw_loss 0.695070 lr 0.00051018 rank 1
2023-02-11 21:58:43,988 DEBUG TRAIN Batch 11/4300 loss 13.393352 loss_att 16.133835 loss_ctc 23.214989 loss_rnnt 8.944766 hw_loss 0.485801 lr 0.00051003 rank 2
2023-02-11 21:59:59,819 DEBUG TRAIN Batch 11/4400 loss 16.075531 loss_att 13.694795 loss_ctc 19.534376 loss_rnnt 11.787955 hw_loss 0.806727 lr 0.00050989 rank 0
2023-02-11 21:59:59,821 DEBUG TRAIN Batch 11/4400 loss 9.091168 loss_att 8.547840 loss_ctc 10.421066 loss_rnnt 6.214086 hw_loss 0.526580 lr 0.00050977 rank 2
2023-02-11 21:59:59,822 DEBUG TRAIN Batch 11/4400 loss 12.838125 loss_att 14.917708 loss_ctc 18.434454 loss_rnnt 10.856607 hw_loss 0.153642 lr 0.00051001 rank 3
2023-02-11 21:59:59,823 DEBUG TRAIN Batch 11/4400 loss 12.472983 loss_att 10.564757 loss_ctc 13.857424 loss_rnnt 8.245159 hw_loss 0.829664 lr 0.00051006 rank 6
2023-02-11 21:59:59,825 DEBUG TRAIN Batch 11/4400 loss 15.820198 loss_att 12.926537 loss_ctc 15.897946 loss_rnnt 10.746428 hw_loss 1.057901 lr 0.00050991 rank 5
2023-02-11 21:59:59,826 DEBUG TRAIN Batch 11/4400 loss 16.512260 loss_att 15.855368 loss_ctc 20.453075 loss_rnnt 11.830692 hw_loss 0.803907 lr 0.00050991 rank 1
2023-02-11 21:59:59,826 DEBUG TRAIN Batch 11/4400 loss 10.350344 loss_att 8.386178 loss_ctc 11.496429 loss_rnnt 7.792697 hw_loss 0.524563 lr 0.00051000 rank 7
2023-02-11 21:59:59,871 DEBUG TRAIN Batch 11/4400 loss 15.286149 loss_att 15.105400 loss_ctc 21.549902 loss_rnnt 11.566494 hw_loss 0.547620 lr 0.00051003 rank 4
2023-02-11 22:01:14,689 DEBUG TRAIN Batch 11/4500 loss 16.153477 loss_att 17.497463 loss_ctc 26.624098 loss_rnnt 11.013351 hw_loss 0.651608 lr 0.00050962 rank 0
2023-02-11 22:01:14,690 DEBUG TRAIN Batch 11/4500 loss 10.971910 loss_att 11.717318 loss_ctc 14.538302 loss_rnnt 9.493078 hw_loss 0.160168 lr 0.00050975 rank 3
2023-02-11 22:01:14,691 DEBUG TRAIN Batch 11/4500 loss 6.538581 loss_att 9.569476 loss_ctc 9.651905 loss_rnnt 2.885753 hw_loss 0.493414 lr 0.00050965 rank 1
2023-02-11 22:01:14,693 DEBUG TRAIN Batch 11/4500 loss 24.458477 loss_att 26.898788 loss_ctc 44.211174 loss_rnnt 20.509617 hw_loss 0.155082 lr 0.00050980 rank 6
2023-02-11 22:01:14,699 DEBUG TRAIN Batch 11/4500 loss 22.311359 loss_att 24.402512 loss_ctc 34.242577 loss_rnnt 18.221069 hw_loss 0.390231 lr 0.00050950 rank 2
2023-02-11 22:01:14,701 DEBUG TRAIN Batch 11/4500 loss 22.366692 loss_att 29.046289 loss_ctc 32.253357 loss_rnnt 16.999014 hw_loss 0.508788 lr 0.00050974 rank 7
2023-02-11 22:01:14,703 DEBUG TRAIN Batch 11/4500 loss 4.967360 loss_att 7.338807 loss_ctc 7.480608 loss_rnnt 1.520697 hw_loss 0.494489 lr 0.00050965 rank 5
2023-02-11 22:01:14,705 DEBUG TRAIN Batch 11/4500 loss 6.188449 loss_att 10.848559 loss_ctc 10.701655 loss_rnnt 4.068688 hw_loss 0.109871 lr 0.00050976 rank 4
2023-02-11 22:02:32,249 DEBUG TRAIN Batch 11/4600 loss 14.420535 loss_att 19.222088 loss_ctc 28.405104 loss_rnnt 10.751255 hw_loss 0.158318 lr 0.00050939 rank 1
2023-02-11 22:02:32,249 DEBUG TRAIN Batch 11/4600 loss 10.047812 loss_att 12.028248 loss_ctc 17.531918 loss_rnnt 7.195487 hw_loss 0.273442 lr 0.00050953 rank 6
2023-02-11 22:02:32,252 DEBUG TRAIN Batch 11/4600 loss 16.746408 loss_att 20.491243 loss_ctc 28.177977 loss_rnnt 12.103048 hw_loss 0.444410 lr 0.00050948 rank 3
2023-02-11 22:02:32,257 DEBUG TRAIN Batch 11/4600 loss 28.735670 loss_att 33.522148 loss_ctc 41.168400 loss_rnnt 25.033438 hw_loss 0.203858 lr 0.00050936 rank 0
2023-02-11 22:02:32,258 DEBUG TRAIN Batch 11/4600 loss 25.994064 loss_att 28.197010 loss_ctc 30.759609 loss_rnnt 23.404995 hw_loss 0.283702 lr 0.00050924 rank 2
2023-02-11 22:02:32,261 DEBUG TRAIN Batch 11/4600 loss 15.234358 loss_att 21.633833 loss_ctc 17.719051 loss_rnnt 10.477269 hw_loss 0.589856 lr 0.00050938 rank 5
2023-02-11 22:02:32,261 DEBUG TRAIN Batch 11/4600 loss 18.774359 loss_att 16.986938 loss_ctc 38.997124 loss_rnnt 14.857605 hw_loss 0.295850 lr 0.00050948 rank 7
2023-02-11 22:02:32,310 DEBUG TRAIN Batch 11/4600 loss 8.947838 loss_att 10.686790 loss_ctc 15.308825 loss_rnnt 5.561059 hw_loss 0.410785 lr 0.00050950 rank 4
2023-02-11 22:03:50,038 DEBUG TRAIN Batch 11/4700 loss 18.936663 loss_att 22.746832 loss_ctc 33.300385 loss_rnnt 15.509439 hw_loss 0.140630 lr 0.00050921 rank 7
2023-02-11 22:03:50,038 DEBUG TRAIN Batch 11/4700 loss 17.005394 loss_att 17.698502 loss_ctc 25.532490 loss_rnnt 13.000793 hw_loss 0.511693 lr 0.00050897 rank 2
2023-02-11 22:03:50,040 DEBUG TRAIN Batch 11/4700 loss 8.507828 loss_att 11.748924 loss_ctc 12.387939 loss_rnnt 3.496757 hw_loss 0.721032 lr 0.00050927 rank 6
2023-02-11 22:03:50,040 DEBUG TRAIN Batch 11/4700 loss 11.683664 loss_att 12.479115 loss_ctc 19.026192 loss_rnnt 9.326557 hw_loss 0.228565 lr 0.00050909 rank 0
2023-02-11 22:03:50,042 DEBUG TRAIN Batch 11/4700 loss 14.721049 loss_att 20.927877 loss_ctc 21.653534 loss_rnnt 11.789415 hw_loss 0.143613 lr 0.00050912 rank 1
2023-02-11 22:03:50,043 DEBUG TRAIN Batch 11/4700 loss 20.355839 loss_att 19.289698 loss_ctc 19.687420 loss_rnnt 18.747389 hw_loss 0.358275 lr 0.00050912 rank 5
2023-02-11 22:03:50,044 DEBUG TRAIN Batch 11/4700 loss 13.817399 loss_att 18.141468 loss_ctc 18.473888 loss_rnnt 10.138704 hw_loss 0.411190 lr 0.00050922 rank 3
2023-02-11 22:03:50,088 DEBUG TRAIN Batch 11/4700 loss 13.206941 loss_att 17.075169 loss_ctc 19.855354 loss_rnnt 11.114122 hw_loss 0.081134 lr 0.00050923 rank 4
2023-02-11 22:05:06,028 DEBUG TRAIN Batch 11/4800 loss 17.611200 loss_att 17.274014 loss_ctc 24.944035 loss_rnnt 15.621712 hw_loss 0.202352 lr 0.00050895 rank 3
2023-02-11 22:05:06,033 DEBUG TRAIN Batch 11/4800 loss 18.691389 loss_att 20.647179 loss_ctc 29.714231 loss_rnnt 15.880645 hw_loss 0.178101 lr 0.00050895 rank 7
2023-02-11 22:05:06,033 DEBUG TRAIN Batch 11/4800 loss 13.019089 loss_att 13.606471 loss_ctc 19.801418 loss_rnnt 8.080427 hw_loss 0.734414 lr 0.00050883 rank 0
2023-02-11 22:05:06,034 DEBUG TRAIN Batch 11/4800 loss 18.991920 loss_att 20.740078 loss_ctc 27.437462 loss_rnnt 15.363579 hw_loss 0.403620 lr 0.00050885 rank 5
2023-02-11 22:05:06,039 DEBUG TRAIN Batch 11/4800 loss 18.729723 loss_att 19.572781 loss_ctc 22.432041 loss_rnnt 15.848927 hw_loss 0.415977 lr 0.00050871 rank 2
2023-02-11 22:05:06,042 DEBUG TRAIN Batch 11/4800 loss 15.502982 loss_att 17.551739 loss_ctc 21.308090 loss_rnnt 11.692518 hw_loss 0.492506 lr 0.00050886 rank 1
2023-02-11 22:05:06,043 DEBUG TRAIN Batch 11/4800 loss 7.160868 loss_att 8.668283 loss_ctc 10.153096 loss_rnnt 5.364677 hw_loss 0.205452 lr 0.00050897 rank 4
2023-02-11 22:05:06,046 DEBUG TRAIN Batch 11/4800 loss 10.850530 loss_att 10.364624 loss_ctc 17.658674 loss_rnnt 7.055848 hw_loss 0.559520 lr 0.00050900 rank 6
2023-02-11 22:06:23,132 DEBUG TRAIN Batch 11/4900 loss 11.764049 loss_att 14.833521 loss_ctc 14.123934 loss_rnnt 8.367865 hw_loss 0.462682 lr 0.00050869 rank 3
2023-02-11 22:06:23,134 DEBUG TRAIN Batch 11/4900 loss 23.326591 loss_att 23.023844 loss_ctc 32.393543 loss_rnnt 18.746576 hw_loss 0.643432 lr 0.00050874 rank 6
2023-02-11 22:06:23,138 DEBUG TRAIN Batch 11/4900 loss 20.213665 loss_att 22.165230 loss_ctc 28.011829 loss_rnnt 16.708805 hw_loss 0.389023 lr 0.00050859 rank 5
2023-02-11 22:06:23,139 DEBUG TRAIN Batch 11/4900 loss 12.055287 loss_att 13.869220 loss_ctc 21.321369 loss_rnnt 7.524627 hw_loss 0.549824 lr 0.00050859 rank 1
2023-02-11 22:06:23,139 DEBUG TRAIN Batch 11/4900 loss 17.398609 loss_att 17.768175 loss_ctc 33.072472 loss_rnnt 12.441477 hw_loss 0.523757 lr 0.00050857 rank 0
2023-02-11 22:06:23,141 DEBUG TRAIN Batch 11/4900 loss 7.351706 loss_att 8.595564 loss_ctc 11.234552 loss_rnnt 5.439698 hw_loss 0.214786 lr 0.00050868 rank 7
2023-02-11 22:06:23,147 DEBUG TRAIN Batch 11/4900 loss 18.648987 loss_att 19.496574 loss_ctc 33.935982 loss_rnnt 13.396558 hw_loss 0.570871 lr 0.00050871 rank 4
2023-02-11 22:06:23,184 DEBUG TRAIN Batch 11/4900 loss 14.264143 loss_att 16.070646 loss_ctc 19.674086 loss_rnnt 10.902007 hw_loss 0.427408 lr 0.00050845 rank 2
2023-02-11 22:07:43,219 DEBUG TRAIN Batch 11/5000 loss 20.752106 loss_att 23.928410 loss_ctc 30.630421 loss_rnnt 17.084885 hw_loss 0.321534 lr 0.00050843 rank 3
2023-02-11 22:07:43,223 DEBUG TRAIN Batch 11/5000 loss 19.119431 loss_att 18.073841 loss_ctc 23.149611 loss_rnnt 13.144483 hw_loss 1.058758 lr 0.00050818 rank 2
2023-02-11 22:07:43,224 DEBUG TRAIN Batch 11/5000 loss 10.457735 loss_att 11.477534 loss_ctc 13.619056 loss_rnnt 6.143993 hw_loss 0.691551 lr 0.00050842 rank 7
2023-02-11 22:07:43,225 DEBUG TRAIN Batch 11/5000 loss 18.759613 loss_att 17.611441 loss_ctc 25.105713 loss_rnnt 14.019879 hw_loss 0.773104 lr 0.00050833 rank 5
2023-02-11 22:07:43,229 DEBUG TRAIN Batch 11/5000 loss 11.534498 loss_att 9.739078 loss_ctc 12.604022 loss_rnnt 9.532086 hw_loss 0.416042 lr 0.00050848 rank 6
2023-02-11 22:07:43,229 DEBUG TRAIN Batch 11/5000 loss 20.401171 loss_att 22.389458 loss_ctc 27.731628 loss_rnnt 14.812415 hw_loss 0.790069 lr 0.00050830 rank 0
2023-02-11 22:07:43,230 DEBUG TRAIN Batch 11/5000 loss 17.967630 loss_att 17.939186 loss_ctc 28.165091 loss_rnnt 12.806424 hw_loss 0.713856 lr 0.00050844 rank 4
2023-02-11 22:07:43,232 DEBUG TRAIN Batch 11/5000 loss 11.451987 loss_att 12.250137 loss_ctc 16.565536 loss_rnnt 7.341970 hw_loss 0.612859 lr 0.00050833 rank 1
2023-02-11 22:09:00,529 DEBUG TRAIN Batch 11/5100 loss 10.799808 loss_att 9.246438 loss_ctc 12.852081 loss_rnnt 7.238331 hw_loss 0.674722 lr 0.00050816 rank 3
2023-02-11 22:09:00,530 DEBUG TRAIN Batch 11/5100 loss 13.439570 loss_att 16.601513 loss_ctc 22.085617 loss_rnnt 9.907291 hw_loss 0.327578 lr 0.00050816 rank 7
2023-02-11 22:09:00,531 DEBUG TRAIN Batch 11/5100 loss 6.090998 loss_att 7.828467 loss_ctc 9.673817 loss_rnnt 3.938834 hw_loss 0.248805 lr 0.00050807 rank 5
2023-02-11 22:09:00,532 DEBUG TRAIN Batch 11/5100 loss 12.209814 loss_att 9.421517 loss_ctc 12.011285 loss_rnnt 7.015708 hw_loss 1.083419 lr 0.00050792 rank 2
2023-02-11 22:09:00,533 DEBUG TRAIN Batch 11/5100 loss 13.205968 loss_att 15.658494 loss_ctc 21.008781 loss_rnnt 10.819244 hw_loss 0.160471 lr 0.00050818 rank 4
2023-02-11 22:09:00,535 DEBUG TRAIN Batch 11/5100 loss 13.597898 loss_att 13.747249 loss_ctc 19.054836 loss_rnnt 9.810457 hw_loss 0.568121 lr 0.00050804 rank 0
2023-02-11 22:09:00,535 DEBUG TRAIN Batch 11/5100 loss 12.908457 loss_att 9.918318 loss_ctc 17.838381 loss_rnnt 8.635160 hw_loss 0.790125 lr 0.00050807 rank 1
2023-02-11 22:09:00,538 DEBUG TRAIN Batch 11/5100 loss 11.478472 loss_att 16.402664 loss_ctc 20.014519 loss_rnnt 8.954269 hw_loss 0.075230 lr 0.00050821 rank 6
2023-02-11 22:10:16,503 DEBUG TRAIN Batch 11/5200 loss 9.460977 loss_att 11.343133 loss_ctc 14.874060 loss_rnnt 7.687697 hw_loss 0.126582 lr 0.00050790 rank 3
2023-02-11 22:10:16,506 DEBUG TRAIN Batch 11/5200 loss 6.454824 loss_att 9.456969 loss_ctc 10.498885 loss_rnnt 3.407842 hw_loss 0.357627 lr 0.00050781 rank 1
2023-02-11 22:10:16,506 DEBUG TRAIN Batch 11/5200 loss 9.195165 loss_att 12.126618 loss_ctc 13.624946 loss_rnnt 6.588314 hw_loss 0.268111 lr 0.00050790 rank 7
2023-02-11 22:10:16,509 DEBUG TRAIN Batch 11/5200 loss 8.640681 loss_att 10.347497 loss_ctc 15.015722 loss_rnnt 6.850909 hw_loss 0.112201 lr 0.00050766 rank 2
2023-02-11 22:10:16,510 DEBUG TRAIN Batch 11/5200 loss 11.114193 loss_att 14.631544 loss_ctc 18.517931 loss_rnnt 9.137680 hw_loss 0.053602 lr 0.00050792 rank 4
2023-02-11 22:10:16,510 DEBUG TRAIN Batch 11/5200 loss 13.412145 loss_att 16.241657 loss_ctc 19.773880 loss_rnnt 10.686745 hw_loss 0.245862 lr 0.00050778 rank 0
2023-02-11 22:10:16,510 DEBUG TRAIN Batch 11/5200 loss 14.170435 loss_att 15.690202 loss_ctc 20.143785 loss_rnnt 11.880699 hw_loss 0.223001 lr 0.00050795 rank 6
2023-02-11 22:10:16,511 DEBUG TRAIN Batch 11/5200 loss 12.519514 loss_att 17.022512 loss_ctc 21.484650 loss_rnnt 8.761298 hw_loss 0.311675 lr 0.00050780 rank 5
2023-02-11 22:11:34,501 DEBUG TRAIN Batch 11/5300 loss 16.197649 loss_att 19.250383 loss_ctc 26.254757 loss_rnnt 12.097053 hw_loss 0.402956 lr 0.00050754 rank 1
2023-02-11 22:11:34,502 DEBUG TRAIN Batch 11/5300 loss 13.991816 loss_att 14.738840 loss_ctc 19.585728 loss_rnnt 11.362362 hw_loss 0.325162 lr 0.00050752 rank 0
2023-02-11 22:11:34,502 DEBUG TRAIN Batch 11/5300 loss 11.438601 loss_att 13.798204 loss_ctc 12.827843 loss_rnnt 7.911148 hw_loss 0.538181 lr 0.00050764 rank 3
2023-02-11 22:11:34,505 DEBUG TRAIN Batch 11/5300 loss 29.326538 loss_att 28.467518 loss_ctc 39.729694 loss_rnnt 26.097776 hw_loss 0.377527 lr 0.00050763 rank 7
2023-02-11 22:11:34,505 DEBUG TRAIN Batch 11/5300 loss 8.748337 loss_att 11.643188 loss_ctc 18.508986 loss_rnnt 5.883144 hw_loss 0.184650 lr 0.00050754 rank 5
2023-02-11 22:11:34,506 DEBUG TRAIN Batch 11/5300 loss 10.337042 loss_att 10.790012 loss_ctc 12.052592 loss_rnnt 6.734384 hw_loss 0.615623 lr 0.00050740 rank 2
2023-02-11 22:11:34,528 DEBUG TRAIN Batch 11/5300 loss 7.596236 loss_att 8.314800 loss_ctc 11.661415 loss_rnnt 5.556812 hw_loss 0.253816 lr 0.00050766 rank 4
2023-02-11 22:11:34,533 DEBUG TRAIN Batch 11/5300 loss 12.746275 loss_att 16.434151 loss_ctc 14.686260 loss_rnnt 10.382277 hw_loss 0.256455 lr 0.00050769 rank 6
2023-02-11 22:12:51,187 DEBUG TRAIN Batch 11/5400 loss 16.243242 loss_att 16.895779 loss_ctc 23.237808 loss_rnnt 12.914190 hw_loss 0.424863 lr 0.00050726 rank 0
2023-02-11 22:12:51,189 DEBUG TRAIN Batch 11/5400 loss 7.421155 loss_att 11.492313 loss_ctc 11.221298 loss_rnnt 5.318487 hw_loss 0.146578 lr 0.00050738 rank 3
2023-02-11 22:12:51,195 DEBUG TRAIN Batch 11/5400 loss 10.666835 loss_att 12.895784 loss_ctc 12.931056 loss_rnnt 6.717966 hw_loss 0.600222 lr 0.00050737 rank 7
2023-02-11 22:12:51,195 DEBUG TRAIN Batch 11/5400 loss 9.183027 loss_att 10.447207 loss_ctc 9.386263 loss_rnnt 6.949526 hw_loss 0.366294 lr 0.00050714 rank 2
2023-02-11 22:12:51,195 DEBUG TRAIN Batch 11/5400 loss 15.263905 loss_att 14.846723 loss_ctc 23.759731 loss_rnnt 10.806349 hw_loss 0.639040 lr 0.00050740 rank 4
2023-02-11 22:12:51,196 DEBUG TRAIN Batch 11/5400 loss 21.730669 loss_att 26.789417 loss_ctc 31.721077 loss_rnnt 18.114136 hw_loss 0.238636 lr 0.00050728 rank 5
2023-02-11 22:12:51,197 DEBUG TRAIN Batch 11/5400 loss 16.935314 loss_att 19.894350 loss_ctc 19.059277 loss_rnnt 13.000590 hw_loss 0.573698 lr 0.00050743 rank 6
2023-02-11 22:12:51,198 DEBUG TRAIN Batch 11/5400 loss 9.497551 loss_att 10.829988 loss_ctc 11.741843 loss_rnnt 6.320151 hw_loss 0.489689 lr 0.00050728 rank 1
2023-02-11 22:14:07,114 DEBUG TRAIN Batch 11/5500 loss 23.253918 loss_att 25.878586 loss_ctc 35.471947 loss_rnnt 17.166504 hw_loss 0.737514 lr 0.00050712 rank 3
2023-02-11 22:14:07,114 DEBUG TRAIN Batch 11/5500 loss 17.214018 loss_att 23.845661 loss_ctc 23.991873 loss_rnnt 13.834003 hw_loss 0.215620 lr 0.00050702 rank 1
2023-02-11 22:14:07,114 DEBUG TRAIN Batch 11/5500 loss 12.384944 loss_att 16.402704 loss_ctc 21.448143 loss_rnnt 9.963631 hw_loss 0.076750 lr 0.00050717 rank 6
2023-02-11 22:14:07,115 DEBUG TRAIN Batch 11/5500 loss 12.661895 loss_att 13.837264 loss_ctc 17.362051 loss_rnnt 11.422707 hw_loss 0.070768 lr 0.00050702 rank 5
2023-02-11 22:14:07,115 DEBUG TRAIN Batch 11/5500 loss 21.209095 loss_att 19.157799 loss_ctc 28.172573 loss_rnnt 19.536470 hw_loss 0.216453 lr 0.00050688 rank 2
2023-02-11 22:14:07,116 DEBUG TRAIN Batch 11/5500 loss 24.982672 loss_att 26.593521 loss_ctc 34.000820 loss_rnnt 20.109814 hw_loss 0.627800 lr 0.00050700 rank 0
2023-02-11 22:14:07,117 DEBUG TRAIN Batch 11/5500 loss 18.522999 loss_att 18.529667 loss_ctc 27.558867 loss_rnnt 12.818323 hw_loss 0.843480 lr 0.00050711 rank 7
2023-02-11 22:14:07,122 DEBUG TRAIN Batch 11/5500 loss 10.493783 loss_att 11.610309 loss_ctc 14.342165 loss_rnnt 5.347514 hw_loss 0.826846 lr 0.00050713 rank 4
2023-02-11 22:15:22,816 DEBUG TRAIN Batch 11/5600 loss 8.692304 loss_att 8.891390 loss_ctc 10.050102 loss_rnnt 4.374765 hw_loss 0.768128 lr 0.00050685 rank 7
2023-02-11 22:15:22,816 DEBUG TRAIN Batch 11/5600 loss 17.655952 loss_att 18.147638 loss_ctc 25.769520 loss_rnnt 11.879471 hw_loss 0.861813 lr 0.00050674 rank 0
2023-02-11 22:15:22,817 DEBUG TRAIN Batch 11/5600 loss 12.374488 loss_att 15.474795 loss_ctc 20.067694 loss_rnnt 8.804838 hw_loss 0.360718 lr 0.00050676 rank 5
2023-02-11 22:15:22,817 DEBUG TRAIN Batch 11/5600 loss 9.536850 loss_att 10.175567 loss_ctc 14.754086 loss_rnnt 7.178965 hw_loss 0.287721 lr 0.00050686 rank 3
2023-02-11 22:15:22,817 DEBUG TRAIN Batch 11/5600 loss 13.171954 loss_att 11.929103 loss_ctc 17.108831 loss_rnnt 10.347438 hw_loss 0.477782 lr 0.00050691 rank 6
2023-02-11 22:15:22,818 DEBUG TRAIN Batch 11/5600 loss 18.040600 loss_att 23.737625 loss_ctc 24.500154 loss_rnnt 14.446486 hw_loss 0.298769 lr 0.00050676 rank 1
2023-02-11 22:15:22,821 DEBUG TRAIN Batch 11/5600 loss 11.161382 loss_att 12.125407 loss_ctc 15.315540 loss_rnnt 6.605947 hw_loss 0.714139 lr 0.00050687 rank 4
2023-02-11 22:15:22,821 DEBUG TRAIN Batch 11/5600 loss 15.499786 loss_att 14.019905 loss_ctc 16.481043 loss_rnnt 12.615766 hw_loss 0.571718 lr 0.00050662 rank 2
2023-02-11 22:16:42,090 DEBUG TRAIN Batch 11/5700 loss 11.325916 loss_att 8.116843 loss_ctc 10.875212 loss_rnnt 6.959687 hw_loss 0.950276 lr 0.00050648 rank 0
2023-02-11 22:16:42,096 DEBUG TRAIN Batch 11/5700 loss 10.656944 loss_att 12.962375 loss_ctc 15.487089 loss_rnnt 9.466209 hw_loss 0.016056 lr 0.00050659 rank 7
2023-02-11 22:16:42,097 DEBUG TRAIN Batch 11/5700 loss 13.184916 loss_att 12.879440 loss_ctc 14.304668 loss_rnnt 11.247766 hw_loss 0.346677 lr 0.00050660 rank 3
2023-02-11 22:16:42,098 DEBUG TRAIN Batch 11/5700 loss 18.825159 loss_att 18.909054 loss_ctc 27.398071 loss_rnnt 14.805020 hw_loss 0.536307 lr 0.00050650 rank 1
2023-02-11 22:16:42,100 DEBUG TRAIN Batch 11/5700 loss 9.645174 loss_att 6.534410 loss_ctc 8.080561 loss_rnnt 5.752020 hw_loss 0.885735 lr 0.00050650 rank 5
2023-02-11 22:16:42,101 DEBUG TRAIN Batch 11/5700 loss 13.011206 loss_att 13.046694 loss_ctc 18.272228 loss_rnnt 8.660876 hw_loss 0.682830 lr 0.00050661 rank 4
2023-02-11 22:16:42,105 DEBUG TRAIN Batch 11/5700 loss 14.565928 loss_att 13.831739 loss_ctc 17.046089 loss_rnnt 10.446228 hw_loss 0.737972 lr 0.00050636 rank 2
2023-02-11 22:16:42,106 DEBUG TRAIN Batch 11/5700 loss 8.393486 loss_att 11.920117 loss_ctc 14.939581 loss_rnnt 5.041620 hw_loss 0.332574 lr 0.00050665 rank 6
2023-02-11 22:17:57,247 DEBUG TRAIN Batch 11/5800 loss 10.708967 loss_att 12.838601 loss_ctc 10.981078 loss_rnnt 8.949450 hw_loss 0.243245 lr 0.00050622 rank 0
2023-02-11 22:17:57,249 DEBUG TRAIN Batch 11/5800 loss 5.781251 loss_att 9.330074 loss_ctc 7.826946 loss_rnnt 2.600327 hw_loss 0.412200 lr 0.00050610 rank 2
2023-02-11 22:17:57,249 DEBUG TRAIN Batch 11/5800 loss 14.238682 loss_att 18.318285 loss_ctc 28.488064 loss_rnnt 10.174827 hw_loss 0.252753 lr 0.00050633 rank 7
2023-02-11 22:17:57,251 DEBUG TRAIN Batch 11/5800 loss 14.418896 loss_att 11.691791 loss_ctc 16.198483 loss_rnnt 10.514698 hw_loss 0.789814 lr 0.00050634 rank 3
2023-02-11 22:17:57,251 DEBUG TRAIN Batch 11/5800 loss 10.330844 loss_att 15.695762 loss_ctc 15.940452 loss_rnnt 8.179113 hw_loss 0.062025 lr 0.00050624 rank 5
2023-02-11 22:17:57,254 DEBUG TRAIN Batch 11/5800 loss 5.972492 loss_att 6.471048 loss_ctc 4.330777 loss_rnnt 2.303874 hw_loss 0.710213 lr 0.00050639 rank 6
2023-02-11 22:17:57,255 DEBUG TRAIN Batch 11/5800 loss 6.690644 loss_att 9.687730 loss_ctc 14.589973 loss_rnnt 3.697718 hw_loss 0.251300 lr 0.00050635 rank 4
2023-02-11 22:17:57,304 DEBUG TRAIN Batch 11/5800 loss 15.921602 loss_att 18.300106 loss_ctc 20.781551 loss_rnnt 12.388046 hw_loss 0.451849 lr 0.00050624 rank 1
2023-02-11 22:19:12,139 DEBUG TRAIN Batch 11/5900 loss 15.413056 loss_att 19.135731 loss_ctc 19.522352 loss_rnnt 11.384807 hw_loss 0.512964 lr 0.00050598 rank 1
2023-02-11 22:19:12,140 DEBUG TRAIN Batch 11/5900 loss 22.858685 loss_att 22.995419 loss_ctc 26.947613 loss_rnnt 20.514585 hw_loss 0.332168 lr 0.00050608 rank 3
2023-02-11 22:19:12,142 DEBUG TRAIN Batch 11/5900 loss 15.938885 loss_att 14.500658 loss_ctc 20.343786 loss_rnnt 10.671152 hw_loss 0.931511 lr 0.00050598 rank 5
2023-02-11 22:19:12,143 DEBUG TRAIN Batch 11/5900 loss 16.471272 loss_att 18.659370 loss_ctc 21.415462 loss_rnnt 12.895338 hw_loss 0.464829 lr 0.00050609 rank 4
2023-02-11 22:19:12,144 DEBUG TRAIN Batch 11/5900 loss 9.113192 loss_att 11.219797 loss_ctc 13.802513 loss_rnnt 6.173308 hw_loss 0.354997 lr 0.00050596 rank 0
2023-02-11 22:19:12,144 DEBUG TRAIN Batch 11/5900 loss 14.904873 loss_att 15.987581 loss_ctc 23.615955 loss_rnnt 10.018896 hw_loss 0.657742 lr 0.00050613 rank 6
2023-02-11 22:19:12,145 DEBUG TRAIN Batch 11/5900 loss 19.944082 loss_att 19.359837 loss_ctc 26.555019 loss_rnnt 17.360413 hw_loss 0.341073 lr 0.00050607 rank 7
2023-02-11 22:19:12,147 DEBUG TRAIN Batch 11/5900 loss 8.844312 loss_att 11.367510 loss_ctc 12.096176 loss_rnnt 5.385279 hw_loss 0.472652 lr 0.00050584 rank 2
2023-02-11 22:20:29,225 DEBUG TRAIN Batch 11/6000 loss 7.882696 loss_att 7.236962 loss_ctc 8.300644 loss_rnnt 3.439855 hw_loss 0.846799 lr 0.00050581 rank 7
2023-02-11 22:20:29,228 DEBUG TRAIN Batch 11/6000 loss 13.808467 loss_att 15.768184 loss_ctc 19.398932 loss_rnnt 11.271267 hw_loss 0.262474 lr 0.00050582 rank 3
2023-02-11 22:20:29,231 DEBUG TRAIN Batch 11/6000 loss 14.334572 loss_att 14.647703 loss_ctc 13.594917 loss_rnnt 10.955503 hw_loss 0.640325 lr 0.00050572 rank 1
2023-02-11 22:20:29,230 DEBUG TRAIN Batch 11/6000 loss 14.792415 loss_att 16.525879 loss_ctc 14.212940 loss_rnnt 10.671867 hw_loss 0.722084 lr 0.00050570 rank 0
2023-02-11 22:20:29,231 DEBUG TRAIN Batch 11/6000 loss 10.884262 loss_att 14.680534 loss_ctc 21.404041 loss_rnnt 7.033081 hw_loss 0.316742 lr 0.00050572 rank 5
2023-02-11 22:20:29,232 DEBUG TRAIN Batch 11/6000 loss 10.463847 loss_att 12.112539 loss_ctc 13.806681 loss_rnnt 7.800903 hw_loss 0.353905 lr 0.00050558 rank 2
2023-02-11 22:20:29,234 DEBUG TRAIN Batch 11/6000 loss 15.123359 loss_att 15.855733 loss_ctc 21.345222 loss_rnnt 12.466667 hw_loss 0.315119 lr 0.00050587 rank 6
2023-02-11 22:20:29,241 DEBUG TRAIN Batch 11/6000 loss 9.322169 loss_att 12.220254 loss_ctc 11.475349 loss_rnnt 5.835830 hw_loss 0.491181 lr 0.00050584 rank 4
2023-02-11 22:21:46,577 DEBUG TRAIN Batch 11/6100 loss 11.531129 loss_att 10.334242 loss_ctc 13.681236 loss_rnnt 7.838587 hw_loss 0.683482 lr 0.00050555 rank 7
2023-02-11 22:21:46,584 DEBUG TRAIN Batch 11/6100 loss 16.894812 loss_att 17.261185 loss_ctc 22.351566 loss_rnnt 12.756305 hw_loss 0.625812 lr 0.00050561 rank 6
2023-02-11 22:21:46,585 DEBUG TRAIN Batch 11/6100 loss 24.626989 loss_att 23.818935 loss_ctc 40.035774 loss_rnnt 21.059769 hw_loss 0.313936 lr 0.00050556 rank 3
2023-02-11 22:21:46,587 DEBUG TRAIN Batch 11/6100 loss 18.260839 loss_att 18.913399 loss_ctc 24.860703 loss_rnnt 12.794428 hw_loss 0.835485 lr 0.00050547 rank 1
2023-02-11 22:21:46,587 DEBUG TRAIN Batch 11/6100 loss 11.990108 loss_att 13.337454 loss_ctc 14.699389 loss_rnnt 8.720686 hw_loss 0.494759 lr 0.00050544 rank 0
2023-02-11 22:21:46,587 DEBUG TRAIN Batch 11/6100 loss 8.349147 loss_att 10.676632 loss_ctc 15.362356 loss_rnnt 4.702053 hw_loss 0.421219 lr 0.00050532 rank 2
2023-02-11 22:21:46,588 DEBUG TRAIN Batch 11/6100 loss 11.727628 loss_att 14.952344 loss_ctc 20.734219 loss_rnnt 8.469549 hw_loss 0.264798 lr 0.00050558 rank 4
2023-02-11 22:21:46,590 DEBUG TRAIN Batch 11/6100 loss 14.023863 loss_att 14.993015 loss_ctc 20.495941 loss_rnnt 10.451344 hw_loss 0.471702 lr 0.00050546 rank 5
2023-02-11 22:23:03,123 DEBUG TRAIN Batch 11/6200 loss 15.345788 loss_att 16.986280 loss_ctc 22.422344 loss_rnnt 13.034263 hw_loss 0.194979 lr 0.00050530 rank 3
2023-02-11 22:23:03,123 DEBUG TRAIN Batch 11/6200 loss 13.033186 loss_att 13.578454 loss_ctc 24.467604 loss_rnnt 7.532043 hw_loss 0.725156 lr 0.00050506 rank 2
2023-02-11 22:23:03,123 DEBUG TRAIN Batch 11/6200 loss 15.266550 loss_att 16.142544 loss_ctc 19.772343 loss_rnnt 11.057434 hw_loss 0.643715 lr 0.00050530 rank 7
2023-02-11 22:23:03,126 DEBUG TRAIN Batch 11/6200 loss 13.529656 loss_att 14.092768 loss_ctc 17.419460 loss_rnnt 10.624495 hw_loss 0.426356 lr 0.00050532 rank 4
2023-02-11 22:23:03,127 DEBUG TRAIN Batch 11/6200 loss 7.081569 loss_att 11.758019 loss_ctc 15.789325 loss_rnnt 3.494048 hw_loss 0.279599 lr 0.00050521 rank 1
2023-02-11 22:23:03,130 DEBUG TRAIN Batch 11/6200 loss 9.233078 loss_att 10.576823 loss_ctc 13.386752 loss_rnnt 5.532271 hw_loss 0.539669 lr 0.00050518 rank 0
2023-02-11 22:23:03,132 DEBUG TRAIN Batch 11/6200 loss 15.051007 loss_att 14.907452 loss_ctc 21.136826 loss_rnnt 12.419076 hw_loss 0.346725 lr 0.00050521 rank 5
2023-02-11 22:23:03,176 DEBUG TRAIN Batch 11/6200 loss 23.734814 loss_att 22.868855 loss_ctc 31.528290 loss_rnnt 20.185461 hw_loss 0.503141 lr 0.00050535 rank 6
2023-02-11 22:24:19,463 DEBUG TRAIN Batch 11/6300 loss 13.730728 loss_att 16.037441 loss_ctc 21.748890 loss_rnnt 9.259818 hw_loss 0.551340 lr 0.00050509 rank 6
2023-02-11 22:24:19,464 DEBUG TRAIN Batch 11/6300 loss 15.947393 loss_att 14.750593 loss_ctc 22.751606 loss_rnnt 12.065712 hw_loss 0.602590 lr 0.00050481 rank 2
2023-02-11 22:24:19,467 DEBUG TRAIN Batch 11/6300 loss 8.051636 loss_att 13.115010 loss_ctc 12.774516 loss_rnnt 3.558113 hw_loss 0.534587 lr 0.00050504 rank 7
2023-02-11 22:24:19,472 DEBUG TRAIN Batch 11/6300 loss 9.925303 loss_att 11.603037 loss_ctc 12.122497 loss_rnnt 6.531629 hw_loss 0.518469 lr 0.00050495 rank 1
2023-02-11 22:24:19,474 DEBUG TRAIN Batch 11/6300 loss 14.763361 loss_att 15.421803 loss_ctc 24.060024 loss_rnnt 10.333265 hw_loss 0.573535 lr 0.00050506 rank 4
2023-02-11 22:24:19,474 DEBUG TRAIN Batch 11/6300 loss 14.260416 loss_att 12.719285 loss_ctc 18.743464 loss_rnnt 9.205037 hw_loss 0.893599 lr 0.00050492 rank 0
2023-02-11 22:24:19,474 DEBUG TRAIN Batch 11/6300 loss 10.829617 loss_att 12.977675 loss_ctc 16.097876 loss_rnnt 7.058808 hw_loss 0.494768 lr 0.00050504 rank 3
2023-02-11 22:24:19,474 DEBUG TRAIN Batch 11/6300 loss 16.184147 loss_att 14.778023 loss_ctc 21.219421 loss_rnnt 11.511998 hw_loss 0.802876 lr 0.00050495 rank 5
2023-02-11 22:25:37,768 DEBUG TRAIN Batch 11/6400 loss 17.368046 loss_att 21.767410 loss_ctc 34.848484 loss_rnnt 13.345016 hw_loss 0.152331 lr 0.00050467 rank 0
2023-02-11 22:25:37,771 DEBUG TRAIN Batch 11/6400 loss 16.591108 loss_att 17.838074 loss_ctc 21.967840 loss_rnnt 12.485415 hw_loss 0.588638 lr 0.00050479 rank 3
2023-02-11 22:25:37,772 DEBUG TRAIN Batch 11/6400 loss 10.590064 loss_att 15.859346 loss_ctc 17.524639 loss_rnnt 5.820832 hw_loss 0.523268 lr 0.00050478 rank 7
2023-02-11 22:25:37,775 DEBUG TRAIN Batch 11/6400 loss 10.887950 loss_att 16.436041 loss_ctc 17.324860 loss_rnnt 7.396530 hw_loss 0.285665 lr 0.00050455 rank 2
2023-02-11 22:25:37,776 DEBUG TRAIN Batch 11/6400 loss 16.769651 loss_att 26.332989 loss_ctc 33.546219 loss_rnnt 10.412991 hw_loss 0.413834 lr 0.00050469 rank 5
2023-02-11 22:25:37,794 DEBUG TRAIN Batch 11/6400 loss 16.736296 loss_att 21.572983 loss_ctc 28.695118 loss_rnnt 13.366729 hw_loss 0.151448 lr 0.00050483 rank 6
2023-02-11 22:25:37,798 DEBUG TRAIN Batch 11/6400 loss 17.874172 loss_att 24.707733 loss_ctc 26.618605 loss_rnnt 12.240493 hw_loss 0.581446 lr 0.00050480 rank 4
2023-02-11 22:25:37,843 DEBUG TRAIN Batch 11/6400 loss 12.680346 loss_att 9.070532 loss_ctc 13.008667 loss_rnnt 8.057917 hw_loss 0.993865 lr 0.00050469 rank 1
2023-02-11 22:26:53,084 DEBUG TRAIN Batch 11/6500 loss 12.895842 loss_att 14.074841 loss_ctc 17.980677 loss_rnnt 10.580444 hw_loss 0.262804 lr 0.00050441 rank 0
2023-02-11 22:26:53,086 DEBUG TRAIN Batch 11/6500 loss 15.848007 loss_att 17.115744 loss_ctc 23.832769 loss_rnnt 13.520160 hw_loss 0.189312 lr 0.00050452 rank 7
2023-02-11 22:26:53,089 DEBUG TRAIN Batch 11/6500 loss 11.751238 loss_att 16.392143 loss_ctc 25.838623 loss_rnnt 7.746880 hw_loss 0.224599 lr 0.00050429 rank 2
2023-02-11 22:26:53,094 DEBUG TRAIN Batch 11/6500 loss 15.475271 loss_att 16.741488 loss_ctc 22.937057 loss_rnnt 11.765709 hw_loss 0.461515 lr 0.00050453 rank 3
2023-02-11 22:26:53,094 DEBUG TRAIN Batch 11/6500 loss 16.759474 loss_att 17.340349 loss_ctc 23.562832 loss_rnnt 13.491903 hw_loss 0.420803 lr 0.00050443 rank 5
2023-02-11 22:26:53,095 DEBUG TRAIN Batch 11/6500 loss 6.898467 loss_att 7.779823 loss_ctc 9.493194 loss_rnnt 2.472416 hw_loss 0.731965 lr 0.00050444 rank 1
2023-02-11 22:26:53,097 DEBUG TRAIN Batch 11/6500 loss 18.570789 loss_att 25.458092 loss_ctc 34.264172 loss_rnnt 13.969066 hw_loss 0.212215 lr 0.00050458 rank 6
2023-02-11 22:26:53,097 DEBUG TRAIN Batch 11/6500 loss 15.362743 loss_att 14.015984 loss_ctc 17.692533 loss_rnnt 12.648237 hw_loss 0.501229 lr 0.00050455 rank 4
2023-02-11 22:28:08,359 DEBUG TRAIN Batch 11/6600 loss 15.223501 loss_att 15.977227 loss_ctc 22.907276 loss_rnnt 11.175690 hw_loss 0.538606 lr 0.00050415 rank 0
2023-02-11 22:28:08,360 DEBUG TRAIN Batch 11/6600 loss 14.188791 loss_att 16.852348 loss_ctc 19.486235 loss_rnnt 10.907444 hw_loss 0.382933 lr 0.00050418 rank 5
2023-02-11 22:28:08,360 DEBUG TRAIN Batch 11/6600 loss 23.891365 loss_att 25.736385 loss_ctc 29.993130 loss_rnnt 19.909683 hw_loss 0.524833 lr 0.00050427 rank 3
2023-02-11 22:28:08,364 DEBUG TRAIN Batch 11/6600 loss 15.744464 loss_att 16.764519 loss_ctc 25.874132 loss_rnnt 13.046844 hw_loss 0.214310 lr 0.00050427 rank 7
2023-02-11 22:28:08,365 DEBUG TRAIN Batch 11/6600 loss 10.197890 loss_att 14.495444 loss_ctc 12.697517 loss_rnnt 7.334728 hw_loss 0.313194 lr 0.00050418 rank 1
2023-02-11 22:28:08,366 DEBUG TRAIN Batch 11/6600 loss 19.857010 loss_att 30.015713 loss_ctc 32.471382 loss_rnnt 14.866589 hw_loss 0.239393 lr 0.00050429 rank 4
2023-02-11 22:28:08,366 DEBUG TRAIN Batch 11/6600 loss 31.555405 loss_att 31.352562 loss_ctc 42.299660 loss_rnnt 27.486122 hw_loss 0.501990 lr 0.00050432 rank 6
2023-02-11 22:28:08,367 DEBUG TRAIN Batch 11/6600 loss 10.179608 loss_att 12.837720 loss_ctc 15.702261 loss_rnnt 7.874767 hw_loss 0.194412 lr 0.00050404 rank 2
2023-02-11 22:29:25,500 DEBUG TRAIN Batch 11/6700 loss 13.692821 loss_att 11.896240 loss_ctc 15.601383 loss_rnnt 10.435268 hw_loss 0.630449 lr 0.00050401 rank 7
2023-02-11 22:29:25,501 DEBUG TRAIN Batch 11/6700 loss 10.850745 loss_att 14.487526 loss_ctc 16.264303 loss_rnnt 6.706366 hw_loss 0.505353 lr 0.00050402 rank 3
2023-02-11 22:29:25,503 DEBUG TRAIN Batch 11/6700 loss 15.498089 loss_att 17.647070 loss_ctc 20.463978 loss_rnnt 12.405714 hw_loss 0.375086 lr 0.00050378 rank 2
2023-02-11 22:29:25,506 DEBUG TRAIN Batch 11/6700 loss 6.470618 loss_att 9.355972 loss_ctc 8.196735 loss_rnnt 4.302374 hw_loss 0.255192 lr 0.00050390 rank 0
2023-02-11 22:29:25,506 DEBUG TRAIN Batch 11/6700 loss 11.904038 loss_att 15.893901 loss_ctc 19.542830 loss_rnnt 7.863647 hw_loss 0.416984 lr 0.00050392 rank 1
2023-02-11 22:29:25,511 DEBUG TRAIN Batch 11/6700 loss 16.131350 loss_att 17.645061 loss_ctc 22.021650 loss_rnnt 11.359816 hw_loss 0.690641 lr 0.00050406 rank 6
2023-02-11 22:29:25,511 DEBUG TRAIN Batch 11/6700 loss 18.359905 loss_att 20.332932 loss_ctc 29.996908 loss_rnnt 15.048082 hw_loss 0.256053 lr 0.00050392 rank 5
2023-02-11 22:29:25,514 DEBUG TRAIN Batch 11/6700 loss 11.214820 loss_att 15.497049 loss_ctc 19.664200 loss_rnnt 7.923616 hw_loss 0.245282 lr 0.00050403 rank 4
2023-02-11 22:30:43,258 DEBUG TRAIN Batch 11/6800 loss 19.056698 loss_att 19.085186 loss_ctc 29.675720 loss_rnnt 15.057008 hw_loss 0.483398 lr 0.00050375 rank 7
2023-02-11 22:30:43,263 DEBUG TRAIN Batch 11/6800 loss 12.580103 loss_att 12.629111 loss_ctc 14.268653 loss_rnnt 10.640017 hw_loss 0.319715 lr 0.00050376 rank 3
2023-02-11 22:30:43,264 DEBUG TRAIN Batch 11/6800 loss 7.550696 loss_att 7.770204 loss_ctc 8.204270 loss_rnnt 4.812328 hw_loss 0.488873 lr 0.00050367 rank 1
2023-02-11 22:30:43,269 DEBUG TRAIN Batch 11/6800 loss 14.120809 loss_att 15.651600 loss_ctc 20.621164 loss_rnnt 9.986237 hw_loss 0.555319 lr 0.00050352 rank 2
2023-02-11 22:30:43,269 DEBUG TRAIN Batch 11/6800 loss 17.618422 loss_att 18.747784 loss_ctc 25.906776 loss_rnnt 13.937103 hw_loss 0.440687 lr 0.00050378 rank 4
2023-02-11 22:30:43,269 DEBUG TRAIN Batch 11/6800 loss 18.020756 loss_att 20.306808 loss_ctc 28.425919 loss_rnnt 13.861753 hw_loss 0.433957 lr 0.00050364 rank 0
2023-02-11 22:30:43,270 DEBUG TRAIN Batch 11/6800 loss 9.026979 loss_att 11.861514 loss_ctc 11.803861 loss_rnnt 4.324502 hw_loss 0.705997 lr 0.00050366 rank 5
2023-02-11 22:30:43,273 DEBUG TRAIN Batch 11/6800 loss 15.209550 loss_att 15.758984 loss_ctc 21.325994 loss_rnnt 11.246469 hw_loss 0.569562 lr 0.00050381 rank 6
2023-02-11 22:32:00,396 DEBUG TRAIN Batch 11/6900 loss 11.744040 loss_att 11.198309 loss_ctc 18.065901 loss_rnnt 8.359064 hw_loss 0.497101 lr 0.00050352 rank 4
2023-02-11 22:32:00,398 DEBUG TRAIN Batch 11/6900 loss 17.158337 loss_att 17.315924 loss_ctc 25.377502 loss_rnnt 13.292964 hw_loss 0.513369 lr 0.00050327 rank 2
2023-02-11 22:32:00,397 DEBUG TRAIN Batch 11/6900 loss 26.383253 loss_att 24.075529 loss_ctc 34.396229 loss_rnnt 23.404352 hw_loss 0.444759 lr 0.00050339 rank 0
2023-02-11 22:32:00,398 DEBUG TRAIN Batch 11/6900 loss 9.795841 loss_att 12.661525 loss_ctc 17.215183 loss_rnnt 5.284482 hw_loss 0.552933 lr 0.00050341 rank 5
2023-02-11 22:32:00,399 DEBUG TRAIN Batch 11/6900 loss 16.322636 loss_att 14.083551 loss_ctc 18.272099 loss_rnnt 11.468410 hw_loss 0.945397 lr 0.00050355 rank 6
2023-02-11 22:32:00,399 DEBUG TRAIN Batch 11/6900 loss 10.327532 loss_att 6.867769 loss_ctc 6.621747 loss_rnnt 5.347071 hw_loss 1.156222 lr 0.00050350 rank 7
2023-02-11 22:32:00,399 DEBUG TRAIN Batch 11/6900 loss 13.902628 loss_att 17.124506 loss_ctc 22.964153 loss_rnnt 11.086908 hw_loss 0.180589 lr 0.00050350 rank 3
2023-02-11 22:32:00,411 DEBUG TRAIN Batch 11/6900 loss 15.083995 loss_att 17.240749 loss_ctc 20.805302 loss_rnnt 12.014436 hw_loss 0.351631 lr 0.00050341 rank 1
2023-02-11 22:33:17,196 DEBUG TRAIN Batch 11/7000 loss 25.163109 loss_att 28.351254 loss_ctc 45.068768 loss_rnnt 18.403013 hw_loss 0.650321 lr 0.00050324 rank 7
2023-02-11 22:33:17,197 DEBUG TRAIN Batch 11/7000 loss 17.320244 loss_att 15.644026 loss_ctc 22.762110 loss_rnnt 13.562812 hw_loss 0.631330 lr 0.00050316 rank 1
2023-02-11 22:33:17,199 DEBUG TRAIN Batch 11/7000 loss 14.118998 loss_att 11.791917 loss_ctc 16.882534 loss_rnnt 9.142613 hw_loss 0.951249 lr 0.00050315 rank 5
2023-02-11 22:33:17,200 DEBUG TRAIN Batch 11/7000 loss 11.128650 loss_att 11.809220 loss_ctc 16.052883 loss_rnnt 7.486408 hw_loss 0.534293 lr 0.00050325 rank 3
2023-02-11 22:33:17,201 DEBUG TRAIN Batch 11/7000 loss 17.696861 loss_att 16.157322 loss_ctc 26.553246 loss_rnnt 13.020680 hw_loss 0.713107 lr 0.00050301 rank 2
2023-02-11 22:33:17,201 DEBUG TRAIN Batch 11/7000 loss 15.478011 loss_att 18.546894 loss_ctc 24.927490 loss_rnnt 12.682929 hw_loss 0.172758 lr 0.00050330 rank 6
2023-02-11 22:33:17,204 DEBUG TRAIN Batch 11/7000 loss 9.063805 loss_att 6.465976 loss_ctc 9.735164 loss_rnnt 4.109275 hw_loss 1.009609 lr 0.00050327 rank 4
2023-02-11 22:33:17,204 DEBUG TRAIN Batch 11/7000 loss 11.978971 loss_att 16.316231 loss_ctc 20.199482 loss_rnnt 7.791053 hw_loss 0.417075 lr 0.00050313 rank 0
2023-02-11 22:34:36,390 DEBUG TRAIN Batch 11/7100 loss 20.507071 loss_att 21.278669 loss_ctc 29.359747 loss_rnnt 14.882969 hw_loss 0.804267 lr 0.00050288 rank 0
2023-02-11 22:34:36,392 DEBUG TRAIN Batch 11/7100 loss 10.432433 loss_att 9.166005 loss_ctc 10.771318 loss_rnnt 8.359454 hw_loss 0.427703 lr 0.00050299 rank 3
2023-02-11 22:34:36,393 DEBUG TRAIN Batch 11/7100 loss 5.590411 loss_att 8.538604 loss_ctc 10.074306 loss_rnnt 2.216915 hw_loss 0.409876 lr 0.00050299 rank 7
2023-02-11 22:34:36,395 DEBUG TRAIN Batch 11/7100 loss 7.324490 loss_att 8.245123 loss_ctc 12.990973 loss_rnnt 4.059353 hw_loss 0.436027 lr 0.00050290 rank 5
2023-02-11 22:34:36,396 DEBUG TRAIN Batch 11/7100 loss 18.741444 loss_att 23.896217 loss_ctc 29.997892 loss_rnnt 15.333652 hw_loss 0.164246 lr 0.00050276 rank 2
2023-02-11 22:34:36,402 DEBUG TRAIN Batch 11/7100 loss 6.265325 loss_att 11.177377 loss_ctc 8.272598 loss_rnnt 4.397258 hw_loss 0.115879 lr 0.00050290 rank 1
2023-02-11 22:34:36,401 DEBUG TRAIN Batch 11/7100 loss 11.249575 loss_att 11.791201 loss_ctc 20.679947 loss_rnnt 6.927442 hw_loss 0.554330 lr 0.00050304 rank 6
2023-02-11 22:34:36,447 DEBUG TRAIN Batch 11/7100 loss 9.511940 loss_att 9.984373 loss_ctc 7.265360 loss_rnnt 6.148152 hw_loss 0.669158 lr 0.00050301 rank 4
2023-02-11 22:35:52,435 DEBUG TRAIN Batch 11/7200 loss 16.239521 loss_att 17.060226 loss_ctc 19.611813 loss_rnnt 13.927164 hw_loss 0.318483 lr 0.00050273 rank 7
2023-02-11 22:35:52,435 DEBUG TRAIN Batch 11/7200 loss 12.638231 loss_att 15.383789 loss_ctc 25.499350 loss_rnnt 8.213964 hw_loss 0.405064 lr 0.00050274 rank 3
2023-02-11 22:35:52,436 DEBUG TRAIN Batch 11/7200 loss 9.498617 loss_att 12.582079 loss_ctc 15.523189 loss_rnnt 5.641832 hw_loss 0.456903 lr 0.00050251 rank 2
2023-02-11 22:35:52,436 DEBUG TRAIN Batch 11/7200 loss 19.640722 loss_att 23.642195 loss_ctc 26.383038 loss_rnnt 14.847613 hw_loss 0.580095 lr 0.00050262 rank 0
2023-02-11 22:35:52,436 DEBUG TRAIN Batch 11/7200 loss 6.432338 loss_att 8.259470 loss_ctc 9.206842 loss_rnnt 3.147581 hw_loss 0.478012 lr 0.00050265 rank 1
2023-02-11 22:35:52,437 DEBUG TRAIN Batch 11/7200 loss 16.701498 loss_att 17.874176 loss_ctc 21.527925 loss_rnnt 13.687165 hw_loss 0.400551 lr 0.00050279 rank 6
2023-02-11 22:35:52,437 DEBUG TRAIN Batch 11/7200 loss 17.858414 loss_att 24.752903 loss_ctc 21.838287 loss_rnnt 15.270508 hw_loss 0.127192 lr 0.00050265 rank 5
2023-02-11 22:35:52,439 DEBUG TRAIN Batch 11/7200 loss 13.068756 loss_att 16.802599 loss_ctc 21.036694 loss_rnnt 9.811028 hw_loss 0.271606 lr 0.00050276 rank 4
2023-02-11 22:37:09,387 DEBUG TRAIN Batch 11/7300 loss 9.774548 loss_att 11.576411 loss_ctc 17.235619 loss_rnnt 6.181187 hw_loss 0.419658 lr 0.00050237 rank 0
2023-02-11 22:37:09,389 DEBUG TRAIN Batch 11/7300 loss 13.382895 loss_att 17.117973 loss_ctc 22.275814 loss_rnnt 10.246716 hw_loss 0.225645 lr 0.00050239 rank 1
2023-02-11 22:37:09,392 DEBUG TRAIN Batch 11/7300 loss 19.650234 loss_att 20.379215 loss_ctc 31.520542 loss_rnnt 14.563739 hw_loss 0.629624 lr 0.00050249 rank 3
2023-02-11 22:37:09,393 DEBUG TRAIN Batch 11/7300 loss 15.371527 loss_att 15.259064 loss_ctc 21.452171 loss_rnnt 11.365782 hw_loss 0.603279 lr 0.00050225 rank 2
2023-02-11 22:37:09,394 DEBUG TRAIN Batch 11/7300 loss 13.517265 loss_att 15.332099 loss_ctc 19.599958 loss_rnnt 11.172871 hw_loss 0.219450 lr 0.00050248 rank 7
2023-02-11 22:37:09,399 DEBUG TRAIN Batch 11/7300 loss 22.614002 loss_att 23.591446 loss_ctc 40.492073 loss_rnnt 17.223766 hw_loss 0.527064 lr 0.00050253 rank 6
2023-02-11 22:37:09,399 DEBUG TRAIN Batch 11/7300 loss 19.485502 loss_att 21.019968 loss_ctc 26.137737 loss_rnnt 16.478840 hw_loss 0.339900 lr 0.00050250 rank 4
2023-02-11 22:37:09,401 DEBUG TRAIN Batch 11/7300 loss 12.209762 loss_att 13.146381 loss_ctc 16.744036 loss_rnnt 8.639881 hw_loss 0.520873 lr 0.00050239 rank 5
2023-02-11 22:38:25,542 DEBUG TRAIN Batch 11/7400 loss 15.001908 loss_att 17.791378 loss_ctc 25.654755 loss_rnnt 10.599931 hw_loss 0.454444 lr 0.00050212 rank 0
2023-02-11 22:38:25,543 DEBUG TRAIN Batch 11/7400 loss 23.185272 loss_att 24.237465 loss_ctc 34.222187 loss_rnnt 18.356812 hw_loss 0.589956 lr 0.00050200 rank 2
2023-02-11 22:38:25,548 DEBUG TRAIN Batch 11/7400 loss 13.450779 loss_att 13.044844 loss_ctc 21.885599 loss_rnnt 9.222541 hw_loss 0.597147 lr 0.00050223 rank 7
2023-02-11 22:38:25,548 DEBUG TRAIN Batch 11/7400 loss 11.930925 loss_att 12.927269 loss_ctc 19.891193 loss_rnnt 8.523705 hw_loss 0.402484 lr 0.00050225 rank 4
2023-02-11 22:38:25,550 DEBUG TRAIN Batch 11/7400 loss 16.110132 loss_att 18.872597 loss_ctc 32.618362 loss_rnnt 11.202557 hw_loss 0.403872 lr 0.00050228 rank 6
2023-02-11 22:38:25,552 DEBUG TRAIN Batch 11/7400 loss 13.466574 loss_att 12.608445 loss_ctc 20.335510 loss_rnnt 8.500935 hw_loss 0.791514 lr 0.00050223 rank 3
2023-02-11 22:38:25,553 DEBUG TRAIN Batch 11/7400 loss 7.623016 loss_att 11.883757 loss_ctc 16.735014 loss_rnnt 4.622138 hw_loss 0.175087 lr 0.00050214 rank 5
2023-02-11 22:38:25,598 DEBUG TRAIN Batch 11/7400 loss 21.610966 loss_att 21.128704 loss_ctc 25.564541 loss_rnnt 18.064190 hw_loss 0.584266 lr 0.00050214 rank 1
2023-02-11 22:39:44,341 DEBUG TRAIN Batch 11/7500 loss 11.723554 loss_att 11.291509 loss_ctc 13.265808 loss_rnnt 8.139532 hw_loss 0.649649 lr 0.00050197 rank 7
2023-02-11 22:39:44,342 DEBUG TRAIN Batch 11/7500 loss 18.015385 loss_att 19.303074 loss_ctc 26.755247 loss_rnnt 14.244349 hw_loss 0.440284 lr 0.00050186 rank 0
2023-02-11 22:39:44,346 DEBUG TRAIN Batch 11/7500 loss 12.237564 loss_att 14.801364 loss_ctc 16.801912 loss_rnnt 10.562862 hw_loss 0.103755 lr 0.00050198 rank 3
2023-02-11 22:39:44,349 DEBUG TRAIN Batch 11/7500 loss 12.685285 loss_att 14.947735 loss_ctc 16.686028 loss_rnnt 9.951410 hw_loss 0.327741 lr 0.00050189 rank 1
2023-02-11 22:39:44,350 DEBUG TRAIN Batch 11/7500 loss 16.009163 loss_att 18.985958 loss_ctc 31.027466 loss_rnnt 11.207726 hw_loss 0.413182 lr 0.00050175 rank 2
2023-02-11 22:39:44,350 DEBUG TRAIN Batch 11/7500 loss 11.171329 loss_att 10.939474 loss_ctc 14.504840 loss_rnnt 8.279921 hw_loss 0.467496 lr 0.00050203 rank 6
2023-02-11 22:39:44,350 DEBUG TRAIN Batch 11/7500 loss 22.904205 loss_att 23.732140 loss_ctc 36.340706 loss_rnnt 18.673189 hw_loss 0.426356 lr 0.00050189 rank 5
2023-02-11 22:39:44,352 DEBUG TRAIN Batch 11/7500 loss 13.429884 loss_att 11.636650 loss_ctc 14.357940 loss_rnnt 11.155354 hw_loss 0.470519 lr 0.00050200 rank 4
2023-02-11 22:41:01,223 DEBUG TRAIN Batch 11/7600 loss 9.137740 loss_att 7.611530 loss_ctc 10.462034 loss_rnnt 5.676847 hw_loss 0.673043 lr 0.00050161 rank 0
2023-02-11 22:41:01,225 DEBUG TRAIN Batch 11/7600 loss 15.697400 loss_att 19.928078 loss_ctc 27.905073 loss_rnnt 10.778258 hw_loss 0.458497 lr 0.00050164 rank 1
2023-02-11 22:41:01,225 DEBUG TRAIN Batch 11/7600 loss 22.975290 loss_att 25.178585 loss_ctc 37.624008 loss_rnnt 18.399607 hw_loss 0.409099 lr 0.00050177 rank 6
2023-02-11 22:41:01,229 DEBUG TRAIN Batch 11/7600 loss 10.842951 loss_att 13.285434 loss_ctc 20.544643 loss_rnnt 7.937257 hw_loss 0.210682 lr 0.00050172 rank 7
2023-02-11 22:41:01,230 DEBUG TRAIN Batch 11/7600 loss 14.126146 loss_att 13.240883 loss_ctc 17.056946 loss_rnnt 8.816294 hw_loss 0.955525 lr 0.00050149 rank 2
2023-02-11 22:41:01,233 DEBUG TRAIN Batch 11/7600 loss 12.235110 loss_att 14.863157 loss_ctc 16.897440 loss_rnnt 9.338118 hw_loss 0.328076 lr 0.00050173 rank 3
2023-02-11 22:41:01,234 DEBUG TRAIN Batch 11/7600 loss 11.489637 loss_att 13.347595 loss_ctc 19.231089 loss_rnnt 8.765288 hw_loss 0.247606 lr 0.00050163 rank 5
2023-02-11 22:41:01,235 DEBUG TRAIN Batch 11/7600 loss 17.608866 loss_att 15.955381 loss_ctc 24.337906 loss_rnnt 14.039680 hw_loss 0.563002 lr 0.00050174 rank 4
2023-02-11 22:42:16,776 DEBUG TRAIN Batch 11/7700 loss 13.899963 loss_att 14.881960 loss_ctc 19.701975 loss_rnnt 12.768431 hw_loss 0.030287 lr 0.00050136 rank 0
2023-02-11 22:42:16,780 DEBUG TRAIN Batch 11/7700 loss 18.276531 loss_att 13.806013 loss_ctc 20.780472 loss_rnnt 13.368725 hw_loss 1.025260 lr 0.00050147 rank 3
2023-02-11 22:42:16,780 DEBUG TRAIN Batch 11/7700 loss 10.412317 loss_att 13.318569 loss_ctc 15.018855 loss_rnnt 6.824454 hw_loss 0.448576 lr 0.00050138 rank 1
2023-02-11 22:42:16,782 DEBUG TRAIN Batch 11/7700 loss 12.844948 loss_att 14.159342 loss_ctc 19.828672 loss_rnnt 7.571564 hw_loss 0.764877 lr 0.00050152 rank 6
2023-02-11 22:42:16,783 DEBUG TRAIN Batch 11/7700 loss 12.171572 loss_att 14.321346 loss_ctc 16.953045 loss_rnnt 7.055433 hw_loss 0.759122 lr 0.00050147 rank 7
2023-02-11 22:42:16,786 DEBUG TRAIN Batch 11/7700 loss 17.452787 loss_att 22.489594 loss_ctc 38.454784 loss_rnnt 13.205896 hw_loss 0.082362 lr 0.00050149 rank 4
2023-02-11 22:42:16,786 DEBUG TRAIN Batch 11/7700 loss 21.002188 loss_att 28.694033 loss_ctc 37.072479 loss_rnnt 16.583286 hw_loss 0.138343 lr 0.00050138 rank 5
2023-02-11 22:42:16,787 DEBUG TRAIN Batch 11/7700 loss 8.344618 loss_att 9.592188 loss_ctc 14.417601 loss_rnnt 5.978928 hw_loss 0.244958 lr 0.00050124 rank 2
2023-02-11 22:43:34,314 DEBUG TRAIN Batch 11/7800 loss 21.774151 loss_att 23.869539 loss_ctc 36.364014 loss_rnnt 17.094364 hw_loss 0.434137 lr 0.00050122 rank 3
2023-02-11 22:43:34,317 DEBUG TRAIN Batch 11/7800 loss 9.663004 loss_att 13.668184 loss_ctc 15.270523 loss_rnnt 6.405468 hw_loss 0.320406 lr 0.00050111 rank 0
2023-02-11 22:43:34,317 DEBUG TRAIN Batch 11/7800 loss 11.442790 loss_att 13.424788 loss_ctc 21.225174 loss_rnnt 8.237408 hw_loss 0.282124 lr 0.00050113 rank 5
2023-02-11 22:43:34,317 DEBUG TRAIN Batch 11/7800 loss 9.137910 loss_att 9.537422 loss_ctc 13.622874 loss_rnnt 5.891907 hw_loss 0.481520 lr 0.00050124 rank 4
2023-02-11 22:43:34,319 DEBUG TRAIN Batch 11/7800 loss 10.391803 loss_att 14.294260 loss_ctc 14.746407 loss_rnnt 7.742926 hw_loss 0.241457 lr 0.00050122 rank 7
2023-02-11 22:43:34,323 DEBUG TRAIN Batch 11/7800 loss 11.579050 loss_att 11.677423 loss_ctc 13.961264 loss_rnnt 7.748692 hw_loss 0.654948 lr 0.00050099 rank 2
2023-02-11 22:43:34,357 DEBUG TRAIN Batch 11/7800 loss 18.316833 loss_att 19.997623 loss_ctc 30.545082 loss_rnnt 14.832671 hw_loss 0.284544 lr 0.00050113 rank 1
2023-02-11 22:43:34,372 DEBUG TRAIN Batch 11/7800 loss 11.792218 loss_att 14.407334 loss_ctc 18.508862 loss_rnnt 8.754084 hw_loss 0.303667 lr 0.00050127 rank 6
2023-02-11 22:44:50,931 DEBUG TRAIN Batch 11/7900 loss 15.838337 loss_att 17.364712 loss_ctc 32.997864 loss_rnnt 12.671606 hw_loss 0.107535 lr 0.00050097 rank 3
2023-02-11 22:44:50,933 DEBUG TRAIN Batch 11/7900 loss 17.230310 loss_att 24.822767 loss_ctc 43.156734 loss_rnnt 11.797487 hw_loss 0.085776 lr 0.00050097 rank 7
2023-02-11 22:44:50,936 DEBUG TRAIN Batch 11/7900 loss 19.741985 loss_att 20.704210 loss_ctc 25.085976 loss_rnnt 16.979792 hw_loss 0.348228 lr 0.00050088 rank 5
2023-02-11 22:44:50,936 DEBUG TRAIN Batch 11/7900 loss 10.584533 loss_att 12.277305 loss_ctc 17.270458 loss_rnnt 6.494389 hw_loss 0.536275 lr 0.00050102 rank 6
2023-02-11 22:44:50,938 DEBUG TRAIN Batch 11/7900 loss 24.638136 loss_att 26.144157 loss_ctc 40.761070 loss_rnnt 19.579683 hw_loss 0.488910 lr 0.00050088 rank 1
2023-02-11 22:44:50,939 DEBUG TRAIN Batch 11/7900 loss 9.091551 loss_att 10.916437 loss_ctc 17.115889 loss_rnnt 6.819372 hw_loss 0.156992 lr 0.00050085 rank 0
2023-02-11 22:44:50,940 DEBUG TRAIN Batch 11/7900 loss 8.388371 loss_att 9.053218 loss_ctc 10.102530 loss_rnnt 5.297140 hw_loss 0.511820 lr 0.00050074 rank 2
2023-02-11 22:44:50,942 DEBUG TRAIN Batch 11/7900 loss 20.743446 loss_att 25.673433 loss_ctc 34.601006 loss_rnnt 16.343914 hw_loss 0.293599 lr 0.00050099 rank 4
2023-02-11 22:46:08,169 DEBUG TRAIN Batch 11/8000 loss 20.033297 loss_att 23.009941 loss_ctc 33.280418 loss_rnnt 15.044896 hw_loss 0.492523 lr 0.00050077 rank 6
2023-02-11 22:46:08,171 DEBUG TRAIN Batch 11/8000 loss 13.099196 loss_att 16.619209 loss_ctc 19.987509 loss_rnnt 9.270262 hw_loss 0.413717 lr 0.00050072 rank 3
2023-02-11 22:46:08,172 DEBUG TRAIN Batch 11/8000 loss 15.650289 loss_att 12.592905 loss_ctc 19.685011 loss_rnnt 11.243311 hw_loss 0.840092 lr 0.00050060 rank 0
2023-02-11 22:46:08,173 DEBUG TRAIN Batch 11/8000 loss 16.890512 loss_att 17.551374 loss_ctc 26.677988 loss_rnnt 11.339863 hw_loss 0.771278 lr 0.00050071 rank 7
2023-02-11 22:46:08,174 DEBUG TRAIN Batch 11/8000 loss 16.336914 loss_att 19.047409 loss_ctc 25.048567 loss_rnnt 13.118381 hw_loss 0.284040 lr 0.00050063 rank 1
2023-02-11 22:46:08,176 DEBUG TRAIN Batch 11/8000 loss 13.170045 loss_att 15.535704 loss_ctc 18.249407 loss_rnnt 9.124936 hw_loss 0.542762 lr 0.00050074 rank 4
2023-02-11 22:46:08,177 DEBUG TRAIN Batch 11/8000 loss 8.208408 loss_att 8.276128 loss_ctc 13.995966 loss_rnnt 4.473382 hw_loss 0.553089 lr 0.00050063 rank 5
2023-02-11 22:46:08,219 DEBUG TRAIN Batch 11/8000 loss 14.169504 loss_att 15.773817 loss_ctc 21.160067 loss_rnnt 11.200819 hw_loss 0.321703 lr 0.00050049 rank 2
2023-02-11 22:47:24,372 DEBUG TRAIN Batch 11/8100 loss 11.130511 loss_att 13.775352 loss_ctc 21.191004 loss_rnnt 7.123197 hw_loss 0.400677 lr 0.00050035 rank 0
2023-02-11 22:47:24,373 DEBUG TRAIN Batch 11/8100 loss 10.849183 loss_att 15.068169 loss_ctc 16.616928 loss_rnnt 9.086664 hw_loss 0.028067 lr 0.00050046 rank 7
2023-02-11 22:47:24,375 DEBUG TRAIN Batch 11/8100 loss 11.171885 loss_att 13.181650 loss_ctc 18.828358 loss_rnnt 7.930236 hw_loss 0.341031 lr 0.00050024 rank 2
2023-02-11 22:47:24,375 DEBUG TRAIN Batch 11/8100 loss 14.725141 loss_att 17.228590 loss_ctc 23.342747 loss_rnnt 11.520732 hw_loss 0.291507 lr 0.00050047 rank 3
2023-02-11 22:47:24,378 DEBUG TRAIN Batch 11/8100 loss 11.030291 loss_att 13.699232 loss_ctc 14.213614 loss_rnnt 7.253846 hw_loss 0.528415 lr 0.00050049 rank 4
2023-02-11 22:47:24,378 DEBUG TRAIN Batch 11/8100 loss 14.055638 loss_att 13.541466 loss_ctc 25.785597 loss_rnnt 9.559417 hw_loss 0.569074 lr 0.00050052 rank 6
2023-02-11 22:47:24,382 DEBUG TRAIN Batch 11/8100 loss 12.294719 loss_att 14.041283 loss_ctc 16.620056 loss_rnnt 8.800741 hw_loss 0.481491 lr 0.00050038 rank 5
2023-02-11 22:47:24,384 DEBUG TRAIN Batch 11/8100 loss 10.888339 loss_att 12.796917 loss_ctc 14.829454 loss_rnnt 7.206305 hw_loss 0.520282 lr 0.00050038 rank 1
2023-02-11 22:48:41,168 DEBUG TRAIN Batch 11/8200 loss 20.863543 loss_att 24.365561 loss_ctc 31.751127 loss_rnnt 17.800394 hw_loss 0.170824 lr 0.00050021 rank 7
2023-02-11 22:48:41,169 DEBUG TRAIN Batch 11/8200 loss 23.566919 loss_att 23.429466 loss_ctc 30.150368 loss_rnnt 19.952864 hw_loss 0.518204 lr 0.00050022 rank 3
2023-02-11 22:48:41,169 DEBUG TRAIN Batch 11/8200 loss 22.620575 loss_att 21.695614 loss_ctc 27.225056 loss_rnnt 18.428698 hw_loss 0.705551 lr 0.00049999 rank 2
2023-02-11 22:48:41,170 DEBUG TRAIN Batch 11/8200 loss 14.119370 loss_att 13.181519 loss_ctc 19.812260 loss_rnnt 9.769957 hw_loss 0.708362 lr 0.00050027 rank 6
2023-02-11 22:48:41,171 DEBUG TRAIN Batch 11/8200 loss 24.055435 loss_att 22.084183 loss_ctc 27.116251 loss_rnnt 20.096203 hw_loss 0.739758 lr 0.00050013 rank 1
2023-02-11 22:48:41,172 DEBUG TRAIN Batch 11/8200 loss 10.601575 loss_att 9.304133 loss_ctc 12.324417 loss_rnnt 7.812503 hw_loss 0.528534 lr 0.00050013 rank 5
2023-02-11 22:48:41,173 DEBUG TRAIN Batch 11/8200 loss 10.099608 loss_att 11.862999 loss_ctc 18.974951 loss_rnnt 7.898065 hw_loss 0.124779 lr 0.00050010 rank 0
2023-02-11 22:48:41,173 DEBUG TRAIN Batch 11/8200 loss 11.094210 loss_att 11.750905 loss_ctc 19.432165 loss_rnnt 8.171793 hw_loss 0.314878 lr 0.00050024 rank 4
2023-02-11 22:49:57,116 DEBUG TRAIN Batch 11/8300 loss 14.322329 loss_att 14.965845 loss_ctc 20.752771 loss_rnnt 9.745156 hw_loss 0.673327 lr 0.00049997 rank 3
2023-02-11 22:49:57,120 DEBUG TRAIN Batch 11/8300 loss 11.990197 loss_att 16.103996 loss_ctc 24.703396 loss_rnnt 8.132345 hw_loss 0.251250 lr 0.00049974 rank 2
2023-02-11 22:49:57,122 DEBUG TRAIN Batch 11/8300 loss 22.832697 loss_att 24.747005 loss_ctc 31.167343 loss_rnnt 19.068001 hw_loss 0.425728 lr 0.00049996 rank 7
2023-02-11 22:49:57,122 DEBUG TRAIN Batch 11/8300 loss 7.580215 loss_att 7.363272 loss_ctc 8.271242 loss_rnnt 5.191246 hw_loss 0.438791 lr 0.00049988 rank 1
2023-02-11 22:49:57,123 DEBUG TRAIN Batch 11/8300 loss 11.949579 loss_att 10.950699 loss_ctc 16.054466 loss_rnnt 8.216099 hw_loss 0.634863 lr 0.00049985 rank 0
2023-02-11 22:49:57,125 DEBUG TRAIN Batch 11/8300 loss 16.920086 loss_att 20.137165 loss_ctc 22.427664 loss_rnnt 14.709487 hw_loss 0.156158 lr 0.00050002 rank 6
2023-02-11 22:49:57,125 DEBUG TRAIN Batch 11/8300 loss 10.352846 loss_att 8.078104 loss_ctc 10.862469 loss_rnnt 6.936886 hw_loss 0.713055 lr 0.00049999 rank 4
2023-02-11 22:49:57,127 DEBUG TRAIN Batch 11/8300 loss 12.782398 loss_att 12.133574 loss_ctc 15.558186 loss_rnnt 10.573566 hw_loss 0.369092 lr 0.00049988 rank 5
2023-02-11 22:50:47,181 DEBUG CV Batch 11/0 loss 6.591030 loss_att 1.816832 loss_ctc 2.626566 loss_rnnt 1.326579 hw_loss 1.265229 history loss 6.346918 rank 0
2023-02-11 22:50:47,181 DEBUG CV Batch 11/0 loss 6.591030 loss_att 1.816832 loss_ctc 2.626566 loss_rnnt 1.326579 hw_loss 1.265229 history loss 6.346918 rank 6
2023-02-11 22:50:47,200 DEBUG CV Batch 11/0 loss 6.591030 loss_att 1.816832 loss_ctc 2.626566 loss_rnnt 1.326579 hw_loss 1.265228 history loss 6.346917 rank 7
2023-02-11 22:50:47,205 DEBUG CV Batch 11/0 loss 6.591030 loss_att 1.816832 loss_ctc 2.626566 loss_rnnt 1.326579 hw_loss 1.265229 history loss 6.346918 rank 1
2023-02-11 22:50:47,206 DEBUG CV Batch 11/0 loss 6.591030 loss_att 1.816832 loss_ctc 2.626566 loss_rnnt 1.326579 hw_loss 1.265229 history loss 6.346918 rank 3
2023-02-11 22:50:47,213 DEBUG CV Batch 11/0 loss 6.591030 loss_att 1.816832 loss_ctc 2.626566 loss_rnnt 1.326579 hw_loss 1.265229 history loss 6.346918 rank 5
2023-02-11 22:50:47,217 DEBUG CV Batch 11/0 loss 6.591030 loss_att 1.816832 loss_ctc 2.626566 loss_rnnt 1.326579 hw_loss 1.265229 history loss 6.346918 rank 4
2023-02-11 22:50:47,219 DEBUG CV Batch 11/0 loss 6.591030 loss_att 1.816832 loss_ctc 2.626566 loss_rnnt 1.326579 hw_loss 1.265229 history loss 6.346918 rank 2
2023-02-11 22:50:58,237 DEBUG CV Batch 11/100 loss 10.776758 loss_att 8.704093 loss_ctc 14.799014 loss_rnnt 7.224945 hw_loss 0.643134 history loss 7.060057 rank 0
2023-02-11 22:50:58,282 DEBUG CV Batch 11/100 loss 10.776758 loss_att 8.704093 loss_ctc 14.799014 loss_rnnt 7.224945 hw_loss 0.643134 history loss 7.060057 rank 3
2023-02-11 22:50:58,308 DEBUG CV Batch 11/100 loss 10.776759 loss_att 8.704093 loss_ctc 14.799014 loss_rnnt 7.224945 hw_loss 0.643134 history loss 7.060057 rank 7
2023-02-11 22:50:58,360 DEBUG CV Batch 11/100 loss 10.776759 loss_att 8.704093 loss_ctc 14.799014 loss_rnnt 7.224945 hw_loss 0.643134 history loss 7.060057 rank 2
2023-02-11 22:50:58,419 DEBUG CV Batch 11/100 loss 10.776759 loss_att 8.704093 loss_ctc 14.799014 loss_rnnt 7.224945 hw_loss 0.643134 history loss 7.060057 rank 6
2023-02-11 22:50:58,446 DEBUG CV Batch 11/100 loss 10.776758 loss_att 8.704093 loss_ctc 14.799014 loss_rnnt 7.224945 hw_loss 0.643134 history loss 7.060057 rank 5
2023-02-11 22:50:58,583 DEBUG CV Batch 11/100 loss 10.776759 loss_att 8.704093 loss_ctc 14.799014 loss_rnnt 7.224945 hw_loss 0.643134 history loss 7.060057 rank 4
2023-02-11 22:50:58,941 DEBUG CV Batch 11/100 loss 10.776759 loss_att 8.704093 loss_ctc 14.799014 loss_rnnt 7.224945 hw_loss 0.643134 history loss 7.060057 rank 1
2023-02-11 22:51:11,997 DEBUG CV Batch 11/200 loss 11.642167 loss_att 15.265043 loss_ctc 15.704216 loss_rnnt 9.894484 hw_loss 0.090282 history loss 7.458920 rank 3
2023-02-11 22:51:12,155 DEBUG CV Batch 11/200 loss 11.642167 loss_att 15.265043 loss_ctc 15.704216 loss_rnnt 9.894484 hw_loss 0.090282 history loss 7.458920 rank 7
2023-02-11 22:51:12,174 DEBUG CV Batch 11/200 loss 11.642167 loss_att 15.265043 loss_ctc 15.704216 loss_rnnt 9.894484 hw_loss 0.090282 history loss 7.458920 rank 0
2023-02-11 22:51:12,178 DEBUG CV Batch 11/200 loss 11.642167 loss_att 15.265043 loss_ctc 15.704216 loss_rnnt 9.894484 hw_loss 0.090282 history loss 7.458920 rank 5
2023-02-11 22:51:12,384 DEBUG CV Batch 11/200 loss 11.642167 loss_att 15.265043 loss_ctc 15.704216 loss_rnnt 9.894484 hw_loss 0.090282 history loss 7.458920 rank 2
2023-02-11 22:51:12,470 DEBUG CV Batch 11/200 loss 11.642167 loss_att 15.265043 loss_ctc 15.704216 loss_rnnt 9.894484 hw_loss 0.090282 history loss 7.458920 rank 4
2023-02-11 22:51:12,510 DEBUG CV Batch 11/200 loss 11.642167 loss_att 15.265043 loss_ctc 15.704216 loss_rnnt 9.894484 hw_loss 0.090282 history loss 7.458920 rank 6
2023-02-11 22:51:13,121 DEBUG CV Batch 11/200 loss 11.642167 loss_att 15.265043 loss_ctc 15.704216 loss_rnnt 9.894484 hw_loss 0.090282 history loss 7.458920 rank 1
2023-02-11 22:51:24,020 DEBUG CV Batch 11/300 loss 8.853867 loss_att 6.258536 loss_ctc 9.753165 loss_rnnt 4.814522 hw_loss 0.832219 history loss 7.771170 rank 3
2023-02-11 22:51:24,201 DEBUG CV Batch 11/300 loss 8.853866 loss_att 6.258536 loss_ctc 9.753165 loss_rnnt 4.814522 hw_loss 0.832219 history loss 7.771170 rank 7
2023-02-11 22:51:24,219 DEBUG CV Batch 11/300 loss 8.853867 loss_att 6.258536 loss_ctc 9.753165 loss_rnnt 4.814522 hw_loss 0.832219 history loss 7.771170 rank 0
2023-02-11 22:51:24,238 DEBUG CV Batch 11/300 loss 8.853866 loss_att 6.258536 loss_ctc 9.753165 loss_rnnt 4.814522 hw_loss 0.832219 history loss 7.771170 rank 5
2023-02-11 22:51:24,413 DEBUG CV Batch 11/300 loss 8.853866 loss_att 6.258536 loss_ctc 9.753165 loss_rnnt 4.814522 hw_loss 0.832219 history loss 7.771170 rank 2
2023-02-11 22:51:24,571 DEBUG CV Batch 11/300 loss 8.853866 loss_att 6.258536 loss_ctc 9.753165 loss_rnnt 4.814522 hw_loss 0.832219 history loss 7.771170 rank 6
2023-02-11 22:51:24,604 DEBUG CV Batch 11/300 loss 8.853866 loss_att 6.258536 loss_ctc 9.753165 loss_rnnt 4.814522 hw_loss 0.832219 history loss 7.771170 rank 4
2023-02-11 22:51:25,846 DEBUG CV Batch 11/300 loss 8.853866 loss_att 6.258536 loss_ctc 9.753165 loss_rnnt 4.814522 hw_loss 0.832219 history loss 7.771170 rank 1
2023-02-11 22:51:36,004 DEBUG CV Batch 11/400 loss 21.534344 loss_att 101.217003 loss_ctc 9.201606 loss_rnnt 6.936441 hw_loss 0.057325 history loss 8.582986 rank 3
2023-02-11 22:51:36,129 DEBUG CV Batch 11/400 loss 21.534344 loss_att 101.217003 loss_ctc 9.201606 loss_rnnt 6.936441 hw_loss 0.057325 history loss 8.582986 rank 0
2023-02-11 22:51:36,221 DEBUG CV Batch 11/400 loss 21.534344 loss_att 101.217003 loss_ctc 9.201606 loss_rnnt 6.936441 hw_loss 0.057325 history loss 8.582986 rank 7
2023-02-11 22:51:36,252 DEBUG CV Batch 11/400 loss 21.534344 loss_att 101.217003 loss_ctc 9.201606 loss_rnnt 6.936441 hw_loss 0.057325 history loss 8.582986 rank 5
2023-02-11 22:51:36,539 DEBUG CV Batch 11/400 loss 21.534344 loss_att 101.217003 loss_ctc 9.201606 loss_rnnt 6.936441 hw_loss 0.057325 history loss 8.582986 rank 2
2023-02-11 22:51:36,588 DEBUG CV Batch 11/400 loss 21.534344 loss_att 101.217003 loss_ctc 9.201606 loss_rnnt 6.936441 hw_loss 0.057325 history loss 8.582986 rank 6
2023-02-11 22:51:36,650 DEBUG CV Batch 11/400 loss 21.534344 loss_att 101.217003 loss_ctc 9.201606 loss_rnnt 6.936441 hw_loss 0.057325 history loss 8.582986 rank 4
2023-02-11 22:51:37,911 DEBUG CV Batch 11/400 loss 21.534344 loss_att 101.217003 loss_ctc 9.201606 loss_rnnt 6.936441 hw_loss 0.057325 history loss 8.582986 rank 1
2023-02-11 22:51:46,460 DEBUG CV Batch 11/500 loss 7.820142 loss_att 7.490923 loss_ctc 8.234122 loss_rnnt 4.852556 hw_loss 0.558418 history loss 9.304838 rank 3
2023-02-11 22:51:46,546 DEBUG CV Batch 11/500 loss 7.820142 loss_att 7.490923 loss_ctc 8.234122 loss_rnnt 4.852556 hw_loss 0.558418 history loss 9.304838 rank 0
2023-02-11 22:51:46,703 DEBUG CV Batch 11/500 loss 7.820142 loss_att 7.490923 loss_ctc 8.234122 loss_rnnt 4.852556 hw_loss 0.558418 history loss 9.304838 rank 7
2023-02-11 22:51:46,722 DEBUG CV Batch 11/500 loss 7.820142 loss_att 7.490923 loss_ctc 8.234122 loss_rnnt 4.852556 hw_loss 0.558418 history loss 9.304838 rank 5
2023-02-11 22:51:47,113 DEBUG CV Batch 11/500 loss 7.820142 loss_att 7.490923 loss_ctc 8.234122 loss_rnnt 4.852556 hw_loss 0.558418 history loss 9.304838 rank 4
2023-02-11 22:51:47,184 DEBUG CV Batch 11/500 loss 7.820142 loss_att 7.490923 loss_ctc 8.234122 loss_rnnt 4.852556 hw_loss 0.558418 history loss 9.304838 rank 6
2023-02-11 22:51:48,398 DEBUG CV Batch 11/500 loss 7.820142 loss_att 7.490923 loss_ctc 8.234122 loss_rnnt 4.852556 hw_loss 0.558418 history loss 9.304838 rank 1
2023-02-11 22:51:48,517 DEBUG CV Batch 11/500 loss 7.820142 loss_att 7.490923 loss_ctc 8.234122 loss_rnnt 4.852556 hw_loss 0.558418 history loss 9.304838 rank 2
2023-02-11 22:51:58,522 DEBUG CV Batch 11/600 loss 10.232780 loss_att 7.065076 loss_ctc 9.735685 loss_rnnt 5.298616 hw_loss 1.056372 history loss 10.065642 rank 3
2023-02-11 22:51:58,615 DEBUG CV Batch 11/600 loss 10.232780 loss_att 7.065076 loss_ctc 9.735685 loss_rnnt 5.298616 hw_loss 1.056372 history loss 10.065642 rank 0
2023-02-11 22:51:58,718 DEBUG CV Batch 11/600 loss 10.232780 loss_att 7.065076 loss_ctc 9.735685 loss_rnnt 5.298616 hw_loss 1.056372 history loss 10.065642 rank 7
2023-02-11 22:51:58,795 DEBUG CV Batch 11/600 loss 10.232780 loss_att 7.065076 loss_ctc 9.735685 loss_rnnt 5.298616 hw_loss 1.056372 history loss 10.065642 rank 5
2023-02-11 22:51:59,209 DEBUG CV Batch 11/600 loss 10.232780 loss_att 7.065076 loss_ctc 9.735685 loss_rnnt 5.298616 hw_loss 1.056372 history loss 10.065642 rank 4
2023-02-11 22:51:59,992 DEBUG CV Batch 11/600 loss 10.232780 loss_att 7.065076 loss_ctc 9.735685 loss_rnnt 5.298616 hw_loss 1.056372 history loss 10.065642 rank 6
2023-02-11 22:52:00,500 DEBUG CV Batch 11/600 loss 10.232780 loss_att 7.065076 loss_ctc 9.735685 loss_rnnt 5.298616 hw_loss 1.056372 history loss 10.065642 rank 1
2023-02-11 22:52:00,777 DEBUG CV Batch 11/600 loss 10.232780 loss_att 7.065076 loss_ctc 9.735685 loss_rnnt 5.298616 hw_loss 1.056372 history loss 10.065642 rank 2
2023-02-11 22:52:09,784 DEBUG CV Batch 11/700 loss 16.186356 loss_att 52.442360 loss_ctc 26.309811 loss_rnnt 6.931443 hw_loss 0.122610 history loss 10.644296 rank 3
2023-02-11 22:52:09,878 DEBUG CV Batch 11/700 loss 16.186356 loss_att 52.442360 loss_ctc 26.309811 loss_rnnt 6.931443 hw_loss 0.122610 history loss 10.644296 rank 0
2023-02-11 22:52:10,026 DEBUG CV Batch 11/700 loss 16.186356 loss_att 52.442360 loss_ctc 26.309811 loss_rnnt 6.931443 hw_loss 0.122610 history loss 10.644296 rank 7
2023-02-11 22:52:10,110 DEBUG CV Batch 11/700 loss 16.186356 loss_att 52.442360 loss_ctc 26.309811 loss_rnnt 6.931443 hw_loss 0.122610 history loss 10.644296 rank 5
2023-02-11 22:52:10,586 DEBUG CV Batch 11/700 loss 16.186356 loss_att 52.442360 loss_ctc 26.309811 loss_rnnt 6.931443 hw_loss 0.122610 history loss 10.644296 rank 4
2023-02-11 22:52:11,549 DEBUG CV Batch 11/700 loss 16.186356 loss_att 52.442360 loss_ctc 26.309811 loss_rnnt 6.931443 hw_loss 0.122610 history loss 10.644296 rank 6
2023-02-11 22:52:11,804 DEBUG CV Batch 11/700 loss 16.186356 loss_att 52.442360 loss_ctc 26.309811 loss_rnnt 6.931443 hw_loss 0.122610 history loss 10.644296 rank 1
2023-02-11 22:52:12,117 DEBUG CV Batch 11/700 loss 16.186356 loss_att 52.442360 loss_ctc 26.309811 loss_rnnt 6.931443 hw_loss 0.122610 history loss 10.644296 rank 2
2023-02-11 22:52:21,223 DEBUG CV Batch 11/800 loss 12.046064 loss_att 10.622104 loss_ctc 18.207291 loss_rnnt 8.824349 hw_loss 0.503439 history loss 10.143940 rank 3
2023-02-11 22:52:21,331 DEBUG CV Batch 11/800 loss 12.046064 loss_att 10.622104 loss_ctc 18.207291 loss_rnnt 8.824349 hw_loss 0.503439 history loss 10.143940 rank 7
2023-02-11 22:52:21,515 DEBUG CV Batch 11/800 loss 12.046064 loss_att 10.622104 loss_ctc 18.207291 loss_rnnt 8.824349 hw_loss 0.503439 history loss 10.143940 rank 5
2023-02-11 22:52:21,571 DEBUG CV Batch 11/800 loss 12.046064 loss_att 10.622104 loss_ctc 18.207291 loss_rnnt 8.824349 hw_loss 0.503439 history loss 10.143940 rank 0
2023-02-11 22:52:22,168 DEBUG CV Batch 11/800 loss 12.046064 loss_att 10.622104 loss_ctc 18.207291 loss_rnnt 8.824349 hw_loss 0.503439 history loss 10.143940 rank 4
2023-02-11 22:52:23,328 DEBUG CV Batch 11/800 loss 12.046064 loss_att 10.622104 loss_ctc 18.207291 loss_rnnt 8.824349 hw_loss 0.503439 history loss 10.143940 rank 1
2023-02-11 22:52:23,341 DEBUG CV Batch 11/800 loss 12.046064 loss_att 10.622104 loss_ctc 18.207291 loss_rnnt 8.824349 hw_loss 0.503439 history loss 10.143940 rank 2
2023-02-11 22:52:24,130 DEBUG CV Batch 11/800 loss 12.046064 loss_att 10.622104 loss_ctc 18.207291 loss_rnnt 8.824349 hw_loss 0.503439 history loss 10.143940 rank 6
2023-02-11 22:52:34,955 DEBUG CV Batch 11/900 loss 15.444761 loss_att 20.088076 loss_ctc 26.059113 loss_rnnt 12.452230 hw_loss 0.121617 history loss 9.939936 rank 3
2023-02-11 22:52:35,016 DEBUG CV Batch 11/900 loss 15.444761 loss_att 20.088076 loss_ctc 26.059113 loss_rnnt 12.452230 hw_loss 0.121617 history loss 9.939936 rank 5
2023-02-11 22:52:35,020 DEBUG CV Batch 11/900 loss 15.444761 loss_att 20.088076 loss_ctc 26.059113 loss_rnnt 12.452230 hw_loss 0.121617 history loss 9.939936 rank 0
2023-02-11 22:52:35,153 DEBUG CV Batch 11/900 loss 15.444761 loss_att 20.088076 loss_ctc 26.059113 loss_rnnt 12.452230 hw_loss 0.121617 history loss 9.939936 rank 7
2023-02-11 22:52:36,430 DEBUG CV Batch 11/900 loss 15.444761 loss_att 20.088076 loss_ctc 26.059113 loss_rnnt 12.452230 hw_loss 0.121617 history loss 9.939936 rank 4
2023-02-11 22:52:36,700 DEBUG CV Batch 11/900 loss 15.444761 loss_att 20.088076 loss_ctc 26.059113 loss_rnnt 12.452230 hw_loss 0.121617 history loss 9.939936 rank 2
2023-02-11 22:52:37,028 DEBUG CV Batch 11/900 loss 15.444761 loss_att 20.088076 loss_ctc 26.059113 loss_rnnt 12.452230 hw_loss 0.121617 history loss 9.939936 rank 1
2023-02-11 22:52:37,498 DEBUG CV Batch 11/900 loss 15.444761 loss_att 20.088076 loss_ctc 26.059113 loss_rnnt 12.452230 hw_loss 0.121617 history loss 9.939936 rank 6
2023-02-11 22:52:47,105 DEBUG CV Batch 11/1000 loss 7.616889 loss_att 5.870269 loss_ctc 7.494069 loss_rnnt 4.682722 hw_loss 0.618725 history loss 9.756824 rank 3
2023-02-11 22:52:47,175 DEBUG CV Batch 11/1000 loss 7.616889 loss_att 5.870269 loss_ctc 7.494069 loss_rnnt 4.682722 hw_loss 0.618725 history loss 9.756824 rank 0
2023-02-11 22:52:47,257 DEBUG CV Batch 11/1000 loss 7.616889 loss_att 5.870269 loss_ctc 7.494069 loss_rnnt 4.682722 hw_loss 0.618725 history loss 9.756824 rank 5
2023-02-11 22:52:47,358 DEBUG CV Batch 11/1000 loss 7.616889 loss_att 5.870269 loss_ctc 7.494069 loss_rnnt 4.682722 hw_loss 0.618725 history loss 9.756824 rank 7
2023-02-11 22:52:48,674 DEBUG CV Batch 11/1000 loss 7.616889 loss_att 5.870269 loss_ctc 7.494069 loss_rnnt 4.682722 hw_loss 0.618725 history loss 9.756824 rank 4
2023-02-11 22:52:48,927 DEBUG CV Batch 11/1000 loss 7.616889 loss_att 5.870269 loss_ctc 7.494069 loss_rnnt 4.682722 hw_loss 0.618725 history loss 9.756824 rank 2
2023-02-11 22:52:49,259 DEBUG CV Batch 11/1000 loss 7.616889 loss_att 5.870269 loss_ctc 7.494069 loss_rnnt 4.682722 hw_loss 0.618725 history loss 9.756824 rank 1
2023-02-11 22:52:49,752 DEBUG CV Batch 11/1000 loss 7.616889 loss_att 5.870269 loss_ctc 7.494069 loss_rnnt 4.682722 hw_loss 0.618725 history loss 9.756825 rank 6
2023-02-11 22:52:58,922 DEBUG CV Batch 11/1100 loss 10.469763 loss_att 5.359906 loss_ctc 8.597000 loss_rnnt 4.356576 hw_loss 1.384661 history loss 9.736595 rank 3
2023-02-11 22:52:59,042 DEBUG CV Batch 11/1100 loss 10.469763 loss_att 5.359906 loss_ctc 8.597000 loss_rnnt 4.356576 hw_loss 1.384661 history loss 9.736595 rank 0
2023-02-11 22:52:59,159 DEBUG CV Batch 11/1100 loss 10.469763 loss_att 5.359906 loss_ctc 8.597000 loss_rnnt 4.356576 hw_loss 1.384661 history loss 9.736595 rank 5
2023-02-11 22:52:59,270 DEBUG CV Batch 11/1100 loss 10.469763 loss_att 5.359906 loss_ctc 8.597000 loss_rnnt 4.356576 hw_loss 1.384661 history loss 9.736595 rank 7
2023-02-11 22:53:00,604 DEBUG CV Batch 11/1100 loss 10.469763 loss_att 5.359906 loss_ctc 8.597000 loss_rnnt 4.356576 hw_loss 1.384661 history loss 9.736595 rank 4
2023-02-11 22:53:00,831 DEBUG CV Batch 11/1100 loss 10.469763 loss_att 5.359906 loss_ctc 8.597000 loss_rnnt 4.356576 hw_loss 1.384661 history loss 9.736595 rank 2
2023-02-11 22:53:01,228 DEBUG CV Batch 11/1100 loss 10.469763 loss_att 5.359906 loss_ctc 8.597000 loss_rnnt 4.356576 hw_loss 1.384661 history loss 9.736595 rank 1
2023-02-11 22:53:02,009 DEBUG CV Batch 11/1100 loss 10.469763 loss_att 5.359906 loss_ctc 8.597000 loss_rnnt 4.356576 hw_loss 1.384661 history loss 9.736595 rank 6
2023-02-11 22:53:09,285 DEBUG CV Batch 11/1200 loss 8.357674 loss_att 8.957607 loss_ctc 9.040304 loss_rnnt 6.357551 hw_loss 0.335460 history loss 10.070627 rank 3
2023-02-11 22:53:09,392 DEBUG CV Batch 11/1200 loss 8.357674 loss_att 8.957607 loss_ctc 9.040304 loss_rnnt 6.357551 hw_loss 0.335460 history loss 10.070627 rank 0
2023-02-11 22:53:09,590 DEBUG CV Batch 11/1200 loss 8.357674 loss_att 8.957607 loss_ctc 9.040304 loss_rnnt 6.357551 hw_loss 0.335460 history loss 10.070627 rank 5
2023-02-11 22:53:09,641 DEBUG CV Batch 11/1200 loss 8.357674 loss_att 8.957607 loss_ctc 9.040304 loss_rnnt 6.357551 hw_loss 0.335460 history loss 10.070627 rank 7
2023-02-11 22:53:11,136 DEBUG CV Batch 11/1200 loss 8.357674 loss_att 8.957607 loss_ctc 9.040304 loss_rnnt 6.357551 hw_loss 0.335460 history loss 10.070627 rank 4
2023-02-11 22:53:11,252 DEBUG CV Batch 11/1200 loss 8.357674 loss_att 8.957607 loss_ctc 9.040304 loss_rnnt 6.357551 hw_loss 0.335460 history loss 10.070627 rank 2
2023-02-11 22:53:11,663 DEBUG CV Batch 11/1200 loss 8.357674 loss_att 8.957607 loss_ctc 9.040304 loss_rnnt 6.357551 hw_loss 0.335460 history loss 10.070627 rank 1
2023-02-11 22:53:13,630 DEBUG CV Batch 11/1200 loss 8.357674 loss_att 8.957607 loss_ctc 9.040304 loss_rnnt 6.357551 hw_loss 0.335460 history loss 10.070627 rank 6
2023-02-11 22:53:21,157 DEBUG CV Batch 11/1300 loss 7.906201 loss_att 5.150263 loss_ctc 9.048441 loss_rnnt 3.815478 hw_loss 0.841802 history loss 10.303034 rank 3
2023-02-11 22:53:21,334 DEBUG CV Batch 11/1300 loss 7.906201 loss_att 5.150263 loss_ctc 9.048441 loss_rnnt 3.815478 hw_loss 0.841802 history loss 10.303034 rank 0
2023-02-11 22:53:21,469 DEBUG CV Batch 11/1300 loss 7.906201 loss_att 5.150263 loss_ctc 9.048441 loss_rnnt 3.815478 hw_loss 0.841802 history loss 10.303034 rank 5
2023-02-11 22:53:21,588 DEBUG CV Batch 11/1300 loss 7.906201 loss_att 5.150263 loss_ctc 9.048441 loss_rnnt 3.815478 hw_loss 0.841802 history loss 10.303034 rank 7
2023-02-11 22:53:23,084 DEBUG CV Batch 11/1300 loss 7.906201 loss_att 5.150263 loss_ctc 9.048441 loss_rnnt 3.815478 hw_loss 0.841802 history loss 10.303034 rank 4
2023-02-11 22:53:23,156 DEBUG CV Batch 11/1300 loss 7.906201 loss_att 5.150263 loss_ctc 9.048441 loss_rnnt 3.815478 hw_loss 0.841802 history loss 10.303034 rank 2
2023-02-11 22:53:24,355 DEBUG CV Batch 11/1300 loss 7.906201 loss_att 5.150263 loss_ctc 9.048441 loss_rnnt 3.815478 hw_loss 0.841802 history loss 10.303034 rank 1
2023-02-11 22:53:25,664 DEBUG CV Batch 11/1300 loss 7.906201 loss_att 5.150263 loss_ctc 9.048441 loss_rnnt 3.815478 hw_loss 0.841802 history loss 10.303034 rank 6
2023-02-11 22:53:32,218 DEBUG CV Batch 11/1400 loss 9.354407 loss_att 32.871120 loss_ctc 8.820038 loss_rnnt 3.575336 hw_loss 0.215058 history loss 10.619280 rank 3
2023-02-11 22:53:32,453 DEBUG CV Batch 11/1400 loss 9.354407 loss_att 32.871120 loss_ctc 8.820038 loss_rnnt 3.575336 hw_loss 0.215058 history loss 10.619280 rank 0
2023-02-11 22:53:32,666 DEBUG CV Batch 11/1400 loss 9.354407 loss_att 32.871120 loss_ctc 8.820038 loss_rnnt 3.575336 hw_loss 0.215058 history loss 10.619280 rank 5
2023-02-11 22:53:32,715 DEBUG CV Batch 11/1400 loss 9.354407 loss_att 32.871120 loss_ctc 8.820038 loss_rnnt 3.575336 hw_loss 0.215058 history loss 10.619280 rank 7
2023-02-11 22:53:34,221 DEBUG CV Batch 11/1400 loss 9.354407 loss_att 32.871120 loss_ctc 8.820038 loss_rnnt 3.575336 hw_loss 0.215058 history loss 10.619280 rank 4
2023-02-11 22:53:34,320 DEBUG CV Batch 11/1400 loss 9.354407 loss_att 32.871120 loss_ctc 8.820038 loss_rnnt 3.575336 hw_loss 0.215058 history loss 10.619280 rank 2
2023-02-11 22:53:35,475 DEBUG CV Batch 11/1400 loss 9.354407 loss_att 32.871120 loss_ctc 8.820038 loss_rnnt 3.575336 hw_loss 0.215058 history loss 10.619280 rank 1
2023-02-11 22:53:36,870 DEBUG CV Batch 11/1400 loss 9.354407 loss_att 32.871120 loss_ctc 8.820038 loss_rnnt 3.575336 hw_loss 0.215058 history loss 10.619280 rank 6
2023-02-11 22:53:43,503 DEBUG CV Batch 11/1500 loss 8.111239 loss_att 7.978828 loss_ctc 7.557149 loss_rnnt 6.298078 hw_loss 0.358785 history loss 10.470939 rank 3
2023-02-11 22:53:43,852 DEBUG CV Batch 11/1500 loss 8.111239 loss_att 7.978828 loss_ctc 7.557149 loss_rnnt 6.298078 hw_loss 0.358785 history loss 10.470939 rank 0
2023-02-11 22:53:44,035 DEBUG CV Batch 11/1500 loss 8.111239 loss_att 7.978828 loss_ctc 7.557149 loss_rnnt 6.298078 hw_loss 0.358785 history loss 10.470939 rank 7
2023-02-11 22:53:44,125 DEBUG CV Batch 11/1500 loss 8.111239 loss_att 7.978828 loss_ctc 7.557149 loss_rnnt 6.298078 hw_loss 0.358785 history loss 10.470939 rank 5
2023-02-11 22:53:45,932 DEBUG CV Batch 11/1500 loss 8.111239 loss_att 7.978828 loss_ctc 7.557149 loss_rnnt 6.298078 hw_loss 0.358785 history loss 10.470939 rank 2
2023-02-11 22:53:46,680 DEBUG CV Batch 11/1500 loss 8.111239 loss_att 7.978828 loss_ctc 7.557149 loss_rnnt 6.298078 hw_loss 0.358785 history loss 10.470939 rank 1
2023-02-11 22:53:47,055 DEBUG CV Batch 11/1500 loss 8.111239 loss_att 7.978828 loss_ctc 7.557149 loss_rnnt 6.298078 hw_loss 0.358785 history loss 10.470939 rank 4
2023-02-11 22:53:49,086 DEBUG CV Batch 11/1500 loss 8.111239 loss_att 7.978828 loss_ctc 7.557149 loss_rnnt 6.298078 hw_loss 0.358785 history loss 10.470939 rank 6
2023-02-11 22:53:56,593 DEBUG CV Batch 11/1600 loss 8.803949 loss_att 11.977398 loss_ctc 10.951502 loss_rnnt 4.804177 hw_loss 0.577264 history loss 10.387524 rank 3
2023-02-11 22:53:57,051 DEBUG CV Batch 11/1600 loss 8.803949 loss_att 11.977398 loss_ctc 10.951502 loss_rnnt 4.804177 hw_loss 0.577264 history loss 10.387524 rank 7
2023-02-11 22:53:57,185 DEBUG CV Batch 11/1600 loss 8.803949 loss_att 11.977398 loss_ctc 10.951502 loss_rnnt 4.804177 hw_loss 0.577264 history loss 10.387524 rank 5
2023-02-11 22:53:57,375 DEBUG CV Batch 11/1600 loss 8.803949 loss_att 11.977398 loss_ctc 10.951502 loss_rnnt 4.804177 hw_loss 0.577264 history loss 10.387524 rank 0
2023-02-11 22:53:59,591 DEBUG CV Batch 11/1600 loss 8.803949 loss_att 11.977398 loss_ctc 10.951502 loss_rnnt 4.804177 hw_loss 0.577264 history loss 10.387524 rank 2
2023-02-11 22:53:59,678 DEBUG CV Batch 11/1600 loss 8.803949 loss_att 11.977398 loss_ctc 10.951502 loss_rnnt 4.804177 hw_loss 0.577264 history loss 10.387524 rank 1
2023-02-11 22:54:00,538 DEBUG CV Batch 11/1600 loss 8.803949 loss_att 11.977398 loss_ctc 10.951502 loss_rnnt 4.804177 hw_loss 0.577264 history loss 10.387524 rank 4
2023-02-11 22:54:02,840 DEBUG CV Batch 11/1600 loss 8.803949 loss_att 11.977398 loss_ctc 10.951502 loss_rnnt 4.804177 hw_loss 0.577264 history loss 10.387524 rank 6
2023-02-11 22:54:09,091 DEBUG CV Batch 11/1700 loss 10.962245 loss_att 8.979589 loss_ctc 14.501657 loss_rnnt 7.101274 hw_loss 0.709796 history loss 10.342105 rank 3
2023-02-11 22:54:09,606 DEBUG CV Batch 11/1700 loss 10.962245 loss_att 8.979589 loss_ctc 14.501657 loss_rnnt 7.101274 hw_loss 0.709796 history loss 10.342105 rank 7
2023-02-11 22:54:09,709 DEBUG CV Batch 11/1700 loss 10.962245 loss_att 8.979589 loss_ctc 14.501657 loss_rnnt 7.101274 hw_loss 0.709796 history loss 10.342105 rank 5
2023-02-11 22:54:09,840 DEBUG CV Batch 11/1700 loss 10.962245 loss_att 8.979589 loss_ctc 14.501657 loss_rnnt 7.101274 hw_loss 0.709796 history loss 10.342105 rank 0
2023-02-11 22:54:12,073 DEBUG CV Batch 11/1700 loss 10.962245 loss_att 8.979589 loss_ctc 14.501657 loss_rnnt 7.101274 hw_loss 0.709796 history loss 10.342105 rank 2
2023-02-11 22:54:12,204 DEBUG CV Batch 11/1700 loss 10.962245 loss_att 8.979589 loss_ctc 14.501657 loss_rnnt 7.101274 hw_loss 0.709796 history loss 10.342105 rank 1
2023-02-11 22:54:12,923 DEBUG CV Batch 11/1700 loss 10.962245 loss_att 8.979589 loss_ctc 14.501657 loss_rnnt 7.101274 hw_loss 0.709796 history loss 10.342105 rank 4
2023-02-11 22:54:15,230 DEBUG CV Batch 11/1700 loss 10.962245 loss_att 8.979589 loss_ctc 14.501657 loss_rnnt 7.101274 hw_loss 0.709796 history loss 10.342105 rank 6
2023-02-11 22:54:18,327 INFO Epoch 11 CV info cv_loss 10.30650779957681
2023-02-11 22:54:18,328 INFO Epoch 12 TRAIN info lr 0.0004998825414025343
2023-02-11 22:54:18,333 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 22:54:18,753 INFO Epoch 11 CV info cv_loss 10.306507817030056
2023-02-11 22:54:18,754 INFO Epoch 12 TRAIN info lr 0.0004998126054028753
2023-02-11 22:54:18,757 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 22:54:18,923 INFO Epoch 11 CV info cv_loss 10.306507809139053
2023-02-11 22:54:18,924 INFO Epoch 12 TRAIN info lr 0.000499785138575691
2023-02-11 22:54:18,927 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 22:54:18,985 INFO Epoch 11 CV info cv_loss 10.306507805813805
2023-02-11 22:54:18,987 INFO Checkpoint: save to checkpoint exp2_10_rnnt_bias_loss/11.pt
2023-02-11 22:54:19,608 INFO Epoch 12 TRAIN info lr 0.0004997626690848965
2023-02-11 22:54:19,612 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 22:54:21,302 INFO Epoch 11 CV info cv_loss 10.30650779980079
2023-02-11 22:54:21,304 INFO Epoch 12 TRAIN info lr 0.0004996403883340271
2023-02-11 22:54:21,309 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 22:54:21,345 INFO Epoch 11 CV info cv_loss 10.306507787947055
2023-02-11 22:54:21,346 INFO Epoch 12 TRAIN info lr 0.0004998051140009018
2023-02-11 22:54:21,349 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 22:54:22,045 INFO Epoch 11 CV info cv_loss 10.306507822543422
2023-02-11 22:54:22,046 INFO Epoch 12 TRAIN info lr 0.0004999000299900035
2023-02-11 22:54:22,050 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 22:54:24,350 INFO Epoch 11 CV info cv_loss 10.306507820786036
2023-02-11 22:54:24,351 INFO Epoch 12 TRAIN info lr 0.0004998950330634281
2023-02-11 22:54:24,354 INFO using accumulate grad, new batch size is 1 times larger than before
2023-02-11 22:55:37,517 DEBUG TRAIN Batch 12/0 loss 13.647544 loss_att 10.284801 loss_ctc 16.118013 loss_rnnt 9.701914 hw_loss 0.804147 lr 0.00049980 rank 1
2023-02-11 22:55:37,517 DEBUG TRAIN Batch 12/0 loss 14.898331 loss_att 9.455993 loss_ctc 13.162984 loss_rnnt 8.560216 hw_loss 1.435868 lr 0.00049988 rank 3
2023-02-11 22:55:37,521 DEBUG TRAIN Batch 12/0 loss 11.748308 loss_att 7.818851 loss_ctc 11.957654 loss_rnnt 7.065998 hw_loss 1.020054 lr 0.00049990 rank 4
2023-02-11 22:55:37,522 DEBUG TRAIN Batch 12/0 loss 11.814135 loss_att 8.708476 loss_ctc 12.184357 loss_rnnt 8.210649 hw_loss 0.782860 lr 0.00049981 rank 7
2023-02-11 22:55:37,522 DEBUG TRAIN Batch 12/0 loss 15.469598 loss_att 12.105674 loss_ctc 15.747252 loss_rnnt 11.159875 hw_loss 0.927279 lr 0.00049964 rank 2
2023-02-11 22:55:37,524 DEBUG TRAIN Batch 12/0 loss 16.414293 loss_att 12.358871 loss_ctc 16.926409 loss_rnnt 11.367412 hw_loss 1.085566 lr 0.00049978 rank 5
2023-02-11 22:55:37,524 DEBUG TRAIN Batch 12/0 loss 13.551058 loss_att 10.241302 loss_ctc 15.129109 loss_rnnt 9.850629 hw_loss 0.778495 lr 0.00049976 rank 0
2023-02-11 22:55:37,534 DEBUG TRAIN Batch 12/0 loss 11.049265 loss_att 7.899328 loss_ctc 11.637368 loss_rnnt 7.155284 hw_loss 0.833541 lr 0.00049989 rank 6
2023-02-11 22:56:52,909 DEBUG TRAIN Batch 12/100 loss 9.668382 loss_att 13.887287 loss_ctc 16.590982 loss_rnnt 6.091779 hw_loss 0.339339 lr 0.00049956 rank 7
2023-02-11 22:56:52,912 DEBUG TRAIN Batch 12/100 loss 20.738159 loss_att 20.629057 loss_ctc 29.470730 loss_rnnt 14.771499 hw_loss 0.904526 lr 0.00049951 rank 0
2023-02-11 22:56:52,914 DEBUG TRAIN Batch 12/100 loss 11.423848 loss_att 12.444519 loss_ctc 15.401251 loss_rnnt 9.242439 hw_loss 0.271304 lr 0.00049953 rank 5
2023-02-11 22:56:52,915 DEBUG TRAIN Batch 12/100 loss 6.675360 loss_att 11.584581 loss_ctc 11.971117 loss_rnnt 3.528330 hw_loss 0.273578 lr 0.00049965 rank 4
2023-02-11 22:56:52,915 DEBUG TRAIN Batch 12/100 loss 16.818623 loss_att 18.172699 loss_ctc 27.869896 loss_rnnt 13.116138 hw_loss 0.367157 lr 0.00049955 rank 1
2023-02-11 22:56:52,915 DEBUG TRAIN Batch 12/100 loss 31.454496 loss_att 32.395443 loss_ctc 56.668701 loss_rnnt 26.081284 hw_loss 0.341837 lr 0.00049963 rank 3
2023-02-11 22:56:52,917 DEBUG TRAIN Batch 12/100 loss 16.199877 loss_att 15.271208 loss_ctc 16.640139 loss_rnnt 15.179008 hw_loss 0.215231 lr 0.00049964 rank 6
2023-02-11 22:56:52,964 DEBUG TRAIN Batch 12/100 loss 13.118127 loss_att 14.536428 loss_ctc 15.595264 loss_rnnt 10.123632 hw_loss 0.446353 lr 0.00049939 rank 2
2023-02-11 22:58:08,060 DEBUG TRAIN Batch 12/200 loss 19.541956 loss_att 24.008987 loss_ctc 36.199852 loss_rnnt 15.949351 hw_loss 0.089652 lr 0.00049938 rank 3
2023-02-11 22:58:08,064 DEBUG TRAIN Batch 12/200 loss 20.182978 loss_att 20.175886 loss_ctc 25.507612 loss_rnnt 18.454113 hw_loss 0.191312 lr 0.00049931 rank 7
2023-02-11 22:58:08,065 DEBUG TRAIN Batch 12/200 loss 8.026856 loss_att 10.234560 loss_ctc 11.001610 loss_rnnt 4.772169 hw_loss 0.453096 lr 0.00049928 rank 5
2023-02-11 22:58:08,072 DEBUG TRAIN Batch 12/200 loss 7.826000 loss_att 10.884768 loss_ctc 12.664909 loss_rnnt 6.146081 hw_loss 0.079308 lr 0.00049930 rank 1
2023-02-11 22:58:08,072 DEBUG TRAIN Batch 12/200 loss 7.467050 loss_att 10.331532 loss_ctc 11.696129 loss_rnnt 5.353137 hw_loss 0.183214 lr 0.00049939 rank 6
2023-02-11 22:58:08,073 DEBUG TRAIN Batch 12/200 loss 12.472797 loss_att 21.878246 loss_ctc 28.159529 loss_rnnt 7.597402 hw_loss 0.169264 lr 0.00049914 rank 2
2023-02-11 22:58:08,073 DEBUG TRAIN Batch 12/200 loss 6.066071 loss_att 9.098763 loss_ctc 10.521313 loss_rnnt 2.330410 hw_loss 0.475329 lr 0.00049926 rank 0
2023-02-11 22:58:08,075 DEBUG TRAIN Batch 12/200 loss 10.705649 loss_att 16.201982 loss_ctc 12.419138 loss_rnnt 6.498371 hw_loss 0.539915 lr 0.00049940 rank 4
2023-02-11 22:59:26,301 DEBUG TRAIN Batch 12/300 loss 7.108870 loss_att 9.710108 loss_ctc 11.937216 loss_rnnt 4.167485 hw_loss 0.333255 lr 0.00049913 rank 3
2023-02-11 22:59:26,301 DEBUG TRAIN Batch 12/300 loss 19.225056 loss_att 20.035337 loss_ctc 23.635193 loss_rnnt 14.875890 hw_loss 0.674830 lr 0.00049906 rank 7
2023-02-11 22:59:26,307 DEBUG TRAIN Batch 12/300 loss 14.371299 loss_att 18.925222 loss_ctc 25.214270 loss_rnnt 8.090475 hw_loss 0.735808 lr 0.00049904 rank 5
2023-02-11 22:59:26,308 DEBUG TRAIN Batch 12/300 loss 11.718516 loss_att 16.301926 loss_ctc 18.477678 loss_rnnt 8.889374 hw_loss 0.189607 lr 0.00049901 rank 0
2023-02-11 22:59:26,308 DEBUG TRAIN Batch 12/300 loss 13.187162 loss_att 12.941362 loss_ctc 16.840862 loss_rnnt 8.692271 hw_loss 0.760667 lr 0.00049889 rank 2
2023-02-11 22:59:26,311 DEBUG TRAIN Batch 12/300 loss 17.705479 loss_att 21.366230 loss_ctc 26.733490 loss_rnnt 14.159393 hw_loss 0.301912 lr 0.00049915 rank 4
2023-02-11 22:59:26,313 DEBUG TRAIN Batch 12/300 loss 10.762020 loss_att 12.671102 loss_ctc 20.221905 loss_rnnt 7.177650 hw_loss 0.363982 lr 0.00049914 rank 6
2023-02-11 22:59:26,350 DEBUG TRAIN Batch 12/300 loss 12.657238 loss_att 15.960808 loss_ctc 22.240183 loss_rnnt 10.015068 hw_loss 0.131949 lr 0.00049906 rank 1
2023-02-11 23:00:45,086 DEBUG TRAIN Batch 12/400 loss 10.017697 loss_att 11.748117 loss_ctc 12.862761 loss_rnnt 5.209342 hw_loss 0.765549 lr 0.00049876 rank 0
2023-02-11 23:00:45,090 DEBUG TRAIN Batch 12/400 loss 7.781096 loss_att 11.309399 loss_ctc 15.600653 loss_rnnt 4.199935 hw_loss 0.343667 lr 0.00049881 rank 7
2023-02-11 23:00:45,091 DEBUG TRAIN Batch 12/400 loss 14.031607 loss_att 16.771782 loss_ctc 21.963968 loss_rnnt 9.782223 hw_loss 0.495694 lr 0.00049888 rank 3
2023-02-11 23:00:45,092 DEBUG TRAIN Batch 12/400 loss 18.170183 loss_att 18.398754 loss_ctc 26.407015 loss_rnnt 15.001954 hw_loss 0.379551 lr 0.00049890 rank 4
2023-02-11 23:00:45,094 DEBUG TRAIN Batch 12/400 loss 11.569204 loss_att 14.073333 loss_ctc 17.249878 loss_rnnt 6.574598 hw_loss 0.700567 lr 0.00049879 rank 5
2023-02-11 23:00:45,096 DEBUG TRAIN Batch 12/400 loss 10.469946 loss_att 12.567574 loss_ctc 13.646934 loss_rnnt 7.307667 hw_loss 0.434842 lr 0.00049881 rank 1
2023-02-11 23:00:45,100 DEBUG TRAIN Batch 12/400 loss 16.117092 loss_att 17.494308 loss_ctc 25.310854 loss_rnnt 12.601095 hw_loss 0.377760 lr 0.00049890 rank 6
2023-02-11 23:00:45,134 DEBUG TRAIN Batch 12/400 loss 14.160748 loss_att 15.440321 loss_ctc 23.523769 loss_rnnt 9.232166 hw_loss 0.642049 lr 0.00049864 rank 2
2023-02-11 23:02:01,477 DEBUG TRAIN Batch 12/500 loss 24.517332 loss_att 27.652264 loss_ctc 35.644741 loss_rnnt 18.739717 hw_loss 0.687558 lr 0.00049856 rank 1
2023-02-11 23:02:01,478 DEBUG TRAIN Batch 12/500 loss 19.732700 loss_att 19.380020 loss_ctc 28.550848 loss_rnnt 16.241640 hw_loss 0.447345 lr 0.00049865 rank 4
2023-02-11 23:02:01,478 DEBUG TRAIN Batch 12/500 loss 13.627191 loss_att 13.985523 loss_ctc 18.568256 loss_rnnt 11.542609 hw_loss 0.253895 lr 0.00049857 rank 7
2023-02-11 23:02:01,479 DEBUG TRAIN Batch 12/500 loss 10.830718 loss_att 13.915504 loss_ctc 15.455471 loss_rnnt 7.818827 hw_loss 0.333431 lr 0.00049852 rank 0
2023-02-11 23:02:01,480 DEBUG TRAIN Batch 12/500 loss 10.974320 loss_att 12.934130 loss_ctc 15.850205 loss_rnnt 6.673894 hw_loss 0.610940 lr 0.00049865 rank 6
2023-02-11 23:02:01,480 DEBUG TRAIN Batch 12/500 loss 20.476025 loss_att 17.694998 loss_ctc 22.348450 loss_rnnt 16.365250 hw_loss 0.828248 lr 0.00049864 rank 3
2023-02-11 23:02:01,481 DEBUG TRAIN Batch 12/500 loss 11.261284 loss_att 11.520122 loss_ctc 16.642385 loss_rnnt 8.209194 hw_loss 0.428033 lr 0.00049840 rank 2
2023-02-11 23:02:01,483 DEBUG TRAIN Batch 12/500 loss 12.092742 loss_att 12.689680 loss_ctc 17.465582 loss_rnnt 8.909740 hw_loss 0.440107 lr 0.00049854 rank 5
2023-02-11 23:03:18,699 DEBUG TRAIN Batch 12/600 loss 10.805645 loss_att 10.030323 loss_ctc 13.435264 loss_rnnt 6.870541 hw_loss 0.701166 lr 0.00049839 rank 3
2023-02-11 23:03:18,705 DEBUG TRAIN Batch 12/600 loss 13.946520 loss_att 11.632833 loss_ctc 14.567902 loss_rnnt 10.052814 hw_loss 0.801298 lr 0.00049827 rank 0
2023-02-11 23:03:18,707 DEBUG TRAIN Batch 12/600 loss 20.790535 loss_att 22.324429 loss_ctc 33.114475 loss_rnnt 16.008606 hw_loss 0.530992 lr 0.00049832 rank 7
2023-02-11 23:03:18,707 DEBUG TRAIN Batch 12/600 loss 20.065935 loss_att 21.682037 loss_ctc 29.931616 loss_rnnt 17.174534 hw_loss 0.234892 lr 0.00049831 rank 1
2023-02-11 23:03:18,707 DEBUG TRAIN Batch 12/600 loss 13.448332 loss_att 10.208392 loss_ctc 14.235136 loss_rnnt 8.706861 hw_loss 0.990854 lr 0.00049829 rank 5
2023-02-11 23:03:18,708 DEBUG TRAIN Batch 12/600 loss 14.096674 loss_att 14.886511 loss_ctc 19.179197 loss_rnnt 10.759035 hw_loss 0.469125 lr 0.00049840 rank 6
2023-02-11 23:03:18,710 DEBUG TRAIN Batch 12/600 loss 14.611147 loss_att 11.315655 loss_ctc 16.040852 loss_rnnt 9.582603 hw_loss 1.030691 lr 0.00049841 rank 4
2023-02-11 23:03:18,764 DEBUG TRAIN Batch 12/600 loss 18.094339 loss_att 18.121368 loss_ctc 25.404053 loss_rnnt 15.577472 hw_loss 0.288156 lr 0.00049815 rank 2
2023-02-11 23:04:38,363 DEBUG TRAIN Batch 12/700 loss 18.822161 loss_att 26.379946 loss_ctc 33.677567 loss_rnnt 14.533077 hw_loss 0.149401 lr 0.00049804 rank 5
2023-02-11 23:04:38,364 DEBUG TRAIN Batch 12/700 loss 17.194914 loss_att 21.432524 loss_ctc 35.369629 loss_rnnt 11.139908 hw_loss 0.522035 lr 0.00049815 rank 6
2023-02-11 23:04:38,364 DEBUG TRAIN Batch 12/700 loss 16.953226 loss_att 18.774969 loss_ctc 29.813805 loss_rnnt 11.178157 hw_loss 0.692996 lr 0.00049806 rank 1
2023-02-11 23:04:38,368 DEBUG TRAIN Batch 12/700 loss 12.367551 loss_att 16.724884 loss_ctc 25.582203 loss_rnnt 8.594271 hw_loss 0.213724 lr 0.00049790 rank 2
2023-02-11 23:04:38,371 DEBUG TRAIN Batch 12/700 loss 13.280630 loss_att 17.144159 loss_ctc 22.603722 loss_rnnt 10.166897 hw_loss 0.205865 lr 0.00049814 rank 3
2023-02-11 23:04:38,374 DEBUG TRAIN Batch 12/700 loss 11.868899 loss_att 16.081503 loss_ctc 19.835051 loss_rnnt 9.016269 hw_loss 0.177742 lr 0.00049816 rank 4
2023-02-11 23:04:38,374 DEBUG TRAIN Batch 12/700 loss 15.863744 loss_att 17.754887 loss_ctc 18.096947 loss_rnnt 11.428711 hw_loss 0.704821 lr 0.00049807 rank 7
2023-02-11 23:04:38,373 DEBUG TRAIN Batch 12/700 loss 16.004564 loss_att 18.017147 loss_ctc 24.805130 loss_rnnt 12.046234 hw_loss 0.446701 lr 0.00049802 rank 0
2023-02-11 23:05:55,518 DEBUG TRAIN Batch 12/800 loss 9.408529 loss_att 12.765882 loss_ctc 13.123154 loss_rnnt 6.893204 hw_loss 0.252857 lr 0.00049782 rank 7
2023-02-11 23:05:55,523 DEBUG TRAIN Batch 12/800 loss 19.103094 loss_att 18.590639 loss_ctc 26.576864 loss_rnnt 16.080765 hw_loss 0.399060 lr 0.00049777 rank 0
2023-02-11 23:05:55,525 DEBUG TRAIN Batch 12/800 loss 4.409420 loss_att 6.238821 loss_ctc 4.966507 loss_rnnt 3.362384 hw_loss 0.113790 lr 0.00049791 rank 6
2023-02-11 23:05:55,524 DEBUG TRAIN Batch 12/800 loss 7.382900 loss_att 10.889668 loss_ctc 11.917541 loss_rnnt 4.488262 hw_loss 0.297875 lr 0.00049780 rank 5
2023-02-11 23:05:55,525 DEBUG TRAIN Batch 12/800 loss 24.787968 loss_att 27.410839 loss_ctc 37.790283 loss_rnnt 21.271660 hw_loss 0.235892 lr 0.00049765 rank 2
2023-02-11 23:05:55,526 DEBUG TRAIN Batch 12/800 loss 19.864796 loss_att 17.875999 loss_ctc 26.786266 loss_rnnt 16.030602 hw_loss 0.620454 lr 0.00049789 rank 3
2023-02-11 23:05:55,526 DEBUG TRAIN Batch 12/800 loss 12.295349 loss_att 14.341492 loss_ctc 15.538212 loss_rnnt 9.871167 hw_loss 0.296732 lr 0.00049791 rank 4
2023-02-11 23:05:55,575 DEBUG TRAIN Batch 12/800 loss 10.075688 loss_att 13.708893 loss_ctc 15.364490 loss_rnnt 7.142509 hw_loss 0.281506 lr 0.00049782 rank 1
2023-02-11 23:07:10,227 DEBUG TRAIN Batch 12/900 loss 21.888243 loss_att 24.057102 loss_ctc 31.798016 loss_rnnt 18.971592 hw_loss 0.217795 lr 0.00049753 rank 0
2023-02-11 23:07:10,230 DEBUG TRAIN Batch 12/900 loss 15.026045 loss_att 14.861104 loss_ctc 20.661812 loss_rnnt 12.558954 hw_loss 0.327870 lr 0.00049766 rank 4
2023-02-11 23:07:10,235 DEBUG TRAIN Batch 12/900 loss 16.503502 loss_att 21.307421 loss_ctc 32.110546 loss_rnnt 12.149824 hw_loss 0.245991 lr 0.00049758 rank 7
2023-02-11 23:07:10,235 DEBUG TRAIN Batch 12/900 loss 3.700607 loss_att 6.716899 loss_ctc 4.443110 loss_rnnt 1.507018 hw_loss 0.279624 lr 0.00049765 rank 3
2023-02-11 23:07:10,235 DEBUG TRAIN Batch 12/900 loss 10.535439 loss_att 13.093789 loss_ctc 16.815155 loss_rnnt 6.235435 hw_loss 0.553320 lr 0.00049741 rank 2
2023-02-11 23:07:10,235 DEBUG TRAIN Batch 12/900 loss 7.829486 loss_att 9.461352 loss_ctc 11.926414 loss_rnnt 4.001724 hw_loss 0.554087 lr 0.00049755 rank 5
2023-02-11 23:07:10,240 DEBUG TRAIN Batch 12/900 loss 13.678077 loss_att 16.695747 loss_ctc 18.731968 loss_rnnt 11.708350 hw_loss 0.129814 lr 0.00049766 rank 6
2023-02-11 23:07:10,285 DEBUG TRAIN Batch 12/900 loss 12.225707 loss_att 13.309166 loss_ctc 14.532284 loss_rnnt 9.228242 hw_loss 0.463731 lr 0.00049757 rank 1
2023-02-11 23:08:27,360 DEBUG TRAIN Batch 12/1000 loss 14.671192 loss_att 18.748089 loss_ctc 24.146469 loss_rnnt 9.695287 hw_loss 0.543217 lr 0.00049740 rank 3
2023-02-11 23:08:27,361 DEBUG TRAIN Batch 12/1000 loss 12.054703 loss_att 17.931353 loss_ctc 19.626961 loss_rnnt 7.431991 hw_loss 0.457078 lr 0.00049732 rank 1
2023-02-11 23:08:27,362 DEBUG TRAIN Batch 12/1000 loss 15.626184 loss_att 19.955292 loss_ctc 23.456497 loss_rnnt 11.533160 hw_loss 0.409342 lr 0.00049728 rank 0
2023-02-11 23:08:27,363 DEBUG TRAIN Batch 12/1000 loss 12.074877 loss_att 13.857479 loss_ctc 15.941806 loss_rnnt 8.638721 hw_loss 0.480759 lr 0.00049716 rank 2
2023-02-11 23:08:27,367 DEBUG TRAIN Batch 12/1000 loss 20.479595 loss_att 21.189264 loss_ctc 30.048033 loss_rnnt 16.161617 hw_loss 0.543797 lr 0.00049730 rank 5
2023-02-11 23:08:27,367 DEBUG TRAIN Batch 12/1000 loss 9.712754 loss_att 11.477128 loss_ctc 12.644570 loss_rnnt 6.639427 hw_loss 0.436789 lr 0.00049742 rank 4
2023-02-11 23:08:27,369 DEBUG TRAIN Batch 12/1000 loss 11.386036 loss_att 13.202596 loss_ctc 16.364273 loss_rnnt 6.289263 hw_loss 0.763068 lr 0.00049733 rank 7
2023-02-11 23:08:27,370 DEBUG TRAIN Batch 12/1000 loss 15.592102 loss_att 15.564248 loss_ctc 19.778149 loss_rnnt 14.048660 hw_loss 0.185789 lr 0.00049741 rank 6
2023-02-11 23:09:45,069 DEBUG TRAIN Batch 12/1100 loss 12.978244 loss_att 12.968903 loss_ctc 15.313640 loss_rnnt 10.029725 hw_loss 0.494813 lr 0.00049704 rank 0
2023-02-11 23:09:45,072 DEBUG TRAIN Batch 12/1100 loss 12.390809 loss_att 15.537716 loss_ctc 24.507763 loss_rnnt 9.732491 hw_loss 0.077502 lr 0.00049717 rank 6
2023-02-11 23:09:45,075 DEBUG TRAIN Batch 12/1100 loss 7.168430 loss_att 10.720324 loss_ctc 11.544928 loss_rnnt 4.300051 hw_loss 0.295212 lr 0.00049709 rank 7
2023-02-11 23:09:45,076 DEBUG TRAIN Batch 12/1100 loss 20.124029 loss_att 22.628365 loss_ctc 26.715170 loss_rnnt 15.753454 hw_loss 0.560791 lr 0.00049715 rank 3
2023-02-11 23:09:45,076 DEBUG TRAIN Batch 12/1100 loss 15.027163 loss_att 18.769531 loss_ctc 24.987915 loss_rnnt 10.923506 hw_loss 0.380078 lr 0.00049717 rank 4
2023-02-11 23:09:45,078 DEBUG TRAIN Batch 12/1100 loss 9.489102 loss_att 11.596962 loss_ctc 15.401295 loss_rnnt 7.025538 hw_loss 0.235069 lr 0.00049692 rank 2
2023-02-11 23:09:45,079 DEBUG TRAIN Batch 12/1100 loss 9.457231 loss_att 10.114268 loss_ctc 9.862471 loss_rnnt 4.710083 hw_loss 0.855320 lr 0.00049708 rank 1
2023-02-11 23:09:45,081 DEBUG TRAIN Batch 12/1100 loss 10.920645 loss_att 12.327250 loss_ctc 12.646671 loss_rnnt 6.328809 hw_loss 0.765071 lr 0.00049706 rank 5
2023-02-11 23:11:01,682 DEBUG TRAIN Batch 12/1200 loss 11.357843 loss_att 12.702147 loss_ctc 17.622890 loss_rnnt 7.659442 hw_loss 0.486412 lr 0.00049679 rank 0
2023-02-11 23:11:01,688 DEBUG TRAIN Batch 12/1200 loss 10.914745 loss_att 10.418501 loss_ctc 13.845140 loss_rnnt 6.512641 hw_loss 0.770744 lr 0.00049681 rank 5
2023-02-11 23:11:01,690 DEBUG TRAIN Batch 12/1200 loss 18.071617 loss_att 17.669744 loss_ctc 25.185163 loss_rnnt 13.165763 hw_loss 0.757079 lr 0.00049667 rank 2
2023-02-11 23:11:01,690 DEBUG TRAIN Batch 12/1200 loss 19.400278 loss_att 21.044580 loss_ctc 27.778992 loss_rnnt 15.344020 hw_loss 0.489420 lr 0.00049691 rank 3
2023-02-11 23:11:01,691 DEBUG TRAIN Batch 12/1200 loss 12.852474 loss_att 14.578231 loss_ctc 15.427347 loss_rnnt 9.791320 hw_loss 0.444879 lr 0.00049684 rank 7
2023-02-11 23:11:01,692 DEBUG TRAIN Batch 12/1200 loss 14.570738 loss_att 14.075651 loss_ctc 19.167606 loss_rnnt 11.449358 hw_loss 0.488903 lr 0.00049683 rank 1
2023-02-11 23:11:01,693 DEBUG TRAIN Batch 12/1200 loss 16.463758 loss_att 17.994213 loss_ctc 23.656698 loss_rnnt 14.388402 hw_loss 0.151914 lr 0.00049692 rank 6
2023-02-11 23:11:01,738 DEBUG TRAIN Batch 12/1200 loss 14.118332 loss_att 13.866525 loss_ctc 21.240004 loss_rnnt 9.375093 hw_loss 0.720758 lr 0.00049693 rank 4
2023-02-11 23:12:17,744 DEBUG TRAIN Batch 12/1300 loss 21.038105 loss_att 20.831284 loss_ctc 28.353176 loss_rnnt 18.927597 hw_loss 0.220599 lr 0.00049655 rank 0
2023-02-11 23:12:17,745 DEBUG TRAIN Batch 12/1300 loss 21.347616 loss_att 20.313625 loss_ctc 30.471313 loss_rnnt 16.536911 hw_loss 0.712689 lr 0.00049660 rank 7
2023-02-11 23:12:17,750 DEBUG TRAIN Batch 12/1300 loss 12.864878 loss_att 12.054113 loss_ctc 14.309399 loss_rnnt 7.514241 hw_loss 0.997535 lr 0.00049659 rank 1
2023-02-11 23:12:17,751 DEBUG TRAIN Batch 12/1300 loss 9.666335 loss_att 10.955325 loss_ctc 14.052718 loss_rnnt 6.522862 hw_loss 0.431404 lr 0.00049668 rank 4
2023-02-11 23:12:17,752 DEBUG TRAIN Batch 12/1300 loss 11.391243 loss_att 15.067688 loss_ctc 15.062171 loss_rnnt 7.708469 hw_loss 0.460880 lr 0.00049666 rank 3
2023-02-11 23:12:17,753 DEBUG TRAIN Batch 12/1300 loss 12.535896 loss_att 8.329718 loss_ctc 10.294513 loss_rnnt 7.960708 hw_loss 1.071614 lr 0.00049668 rank 6
2023-02-11 23:12:17,753 DEBUG TRAIN Batch 12/1300 loss 13.077190 loss_att 14.545795 loss_ctc 22.762035 loss_rnnt 8.230812 hw_loss 0.611502 lr 0.00049643 rank 2
2023-02-11 23:12:17,754 DEBUG TRAIN Batch 12/1300 loss 9.613729 loss_att 12.730600 loss_ctc 17.104124 loss_rnnt 4.326363 hw_loss 0.687239 lr 0.00049657 rank 5
2023-02-11 23:13:36,331 DEBUG TRAIN Batch 12/1400 loss 11.854649 loss_att 14.093748 loss_ctc 21.480345 loss_rnnt 8.898055 hw_loss 0.229753 lr 0.00049618 rank 2
2023-02-11 23:13:36,331 DEBUG TRAIN Batch 12/1400 loss 8.341563 loss_att 10.502717 loss_ctc 12.382488 loss_rnnt 6.388292 hw_loss 0.184172 lr 0.00049644 rank 4
2023-02-11 23:13:36,331 DEBUG TRAIN Batch 12/1400 loss 24.512556 loss_att 29.958782 loss_ctc 42.492241 loss_rnnt 19.058895 hw_loss 0.368836 lr 0.00049642 rank 3
2023-02-11 23:13:36,335 DEBUG TRAIN Batch 12/1400 loss 13.919048 loss_att 18.254190 loss_ctc 21.558020 loss_rnnt 10.058048 hw_loss 0.370395 lr 0.00049634 rank 1
2023-02-11 23:13:36,336 DEBUG TRAIN Batch 12/1400 loss 14.991880 loss_att 18.859255 loss_ctc 23.033794 loss_rnnt 11.723261 hw_loss 0.266792 lr 0.00049632 rank 5
2023-02-11 23:13:36,338 DEBUG TRAIN Batch 12/1400 loss 11.948722 loss_att 14.003933 loss_ctc 16.926088 loss_rnnt 9.142096 hw_loss 0.324738 lr 0.00049635 rank 7
2023-02-11 23:13:36,341 DEBUG TRAIN Batch 12/1400 loss 14.244238 loss_att 15.796434 loss_ctc 21.606550 loss_rnnt 11.465897 hw_loss 0.278674 lr 0.00049630 rank 0
2023-02-11 23:13:36,341 DEBUG TRAIN Batch 12/1400 loss 17.167837 loss_att 17.054646 loss_ctc 20.285824 loss_rnnt 12.122203 hw_loss 0.872352 lr 0.00049643 rank 6
2023-02-11 23:14:52,284 DEBUG TRAIN Batch 12/1500 loss 7.406501 loss_att 10.785000 loss_ctc 8.584438 loss_rnnt 3.053186 hw_loss 0.660105 lr 0.00049617 rank 3
2023-02-11 23:14:52,290 DEBUG TRAIN Batch 12/1500 loss 11.905112 loss_att 13.721689 loss_ctc 22.181135 loss_rnnt 7.947174 hw_loss 0.417091 lr 0.00049611 rank 7
2023-02-11 23:14:52,291 DEBUG TRAIN Batch 12/1500 loss 15.075596 loss_att 18.679955 loss_ctc 26.542988 loss_rnnt 10.757305 hw_loss 0.387831 lr 0.00049619 rank 6
2023-02-11 23:14:52,291 DEBUG TRAIN Batch 12/1500 loss 10.415439 loss_att 13.133524 loss_ctc 12.924167 loss_rnnt 7.197412 hw_loss 0.438734 lr 0.00049606 rank 0
2023-02-11 23:14:52,294 DEBUG TRAIN Batch 12/1500 loss 13.467842 loss_att 15.176698 loss_ctc 23.138083 loss_rnnt 9.124836 hw_loss 0.508476 lr 0.00049610 rank 1
2023-02-11 23:14:52,293 DEBUG TRAIN Batch 12/1500 loss 19.117353 loss_att 18.941404 loss_ctc 31.137989 loss_rnnt 17.426325 hw_loss 0.023150 lr 0.00049608 rank 5
2023-02-11 23:14:52,294 DEBUG TRAIN Batch 12/1500 loss 12.884635 loss_att 14.510658 loss_ctc 16.523424 loss_rnnt 11.478294 hw_loss 0.111743 lr 0.00049594 rank 2
2023-02-11 23:14:52,296 DEBUG TRAIN Batch 12/1500 loss 12.224044 loss_att 15.590227 loss_ctc 21.363972 loss_rnnt 9.560517 hw_loss 0.144681 lr 0.00049619 rank 4
2023-02-11 23:16:08,681 DEBUG TRAIN Batch 12/1600 loss 12.322184 loss_att 15.118826 loss_ctc 18.506977 loss_rnnt 8.961423 hw_loss 0.370649 lr 0.00049593 rank 3
2023-02-11 23:16:08,683 DEBUG TRAIN Batch 12/1600 loss 11.255817 loss_att 14.183659 loss_ctc 18.783073 loss_rnnt 6.059750 hw_loss 0.676287 lr 0.00049586 rank 7
2023-02-11 23:16:08,683 DEBUG TRAIN Batch 12/1600 loss 10.248643 loss_att 14.959249 loss_ctc 14.514022 loss_rnnt 6.791032 hw_loss 0.365020 lr 0.00049569 rank 2
2023-02-11 23:16:08,684 DEBUG TRAIN Batch 12/1600 loss 11.538070 loss_att 10.974371 loss_ctc 15.507378 loss_rnnt 8.037268 hw_loss 0.578306 lr 0.00049581 rank 0
2023-02-11 23:16:08,685 DEBUG TRAIN Batch 12/1600 loss 10.484242 loss_att 11.650551 loss_ctc 14.363751 loss_rnnt 6.241603 hw_loss 0.654771 lr 0.00049594 rank 6
2023-02-11 23:16:08,687 DEBUG TRAIN Batch 12/1600 loss 7.489402 loss_att 8.469291 loss_ctc 13.430361 loss_rnnt 4.628339 hw_loss 0.351180 lr 0.00049595 rank 4
2023-02-11 23:16:08,688 DEBUG TRAIN Batch 12/1600 loss 12.864979 loss_att 12.205256 loss_ctc 16.060894 loss_rnnt 8.941887 hw_loss 0.680421 lr 0.00049584 rank 5
2023-02-11 23:16:08,691 DEBUG TRAIN Batch 12/1600 loss 18.050743 loss_att 21.621519 loss_ctc 32.372387 loss_rnnt 13.402608 hw_loss 0.379580 lr 0.00049585 rank 1
2023-02-11 23:17:24,287 DEBUG TRAIN Batch 12/1700 loss 13.089118 loss_att 15.564057 loss_ctc 19.842834 loss_rnnt 8.795919 hw_loss 0.543322 lr 0.00049569 rank 3
2023-02-11 23:17:24,291 DEBUG TRAIN Batch 12/1700 loss 16.684132 loss_att 18.889757 loss_ctc 27.084564 loss_rnnt 12.419925 hw_loss 0.456817 lr 0.00049557 rank 0
2023-02-11 23:17:24,291 DEBUG TRAIN Batch 12/1700 loss 23.544947 loss_att 26.334755 loss_ctc 35.871464 loss_rnnt 19.961292 hw_loss 0.259155 lr 0.00049570 rank 6
2023-02-11 23:17:24,292 DEBUG TRAIN Batch 12/1700 loss 9.151182 loss_att 14.018734 loss_ctc 19.253067 loss_rnnt 6.096609 hw_loss 0.137652 lr 0.00049562 rank 7
2023-02-11 23:17:24,293 DEBUG TRAIN Batch 12/1700 loss 11.469110 loss_att 14.975824 loss_ctc 18.968994 loss_rnnt 9.081781 hw_loss 0.128625 lr 0.00049559 rank 5
2023-02-11 23:17:24,294 DEBUG TRAIN Batch 12/1700 loss 10.917904 loss_att 13.650741 loss_ctc 17.528149 loss_rnnt 8.183881 hw_loss 0.244892 lr 0.00049561 rank 1
2023-02-11 23:17:24,294 DEBUG TRAIN Batch 12/1700 loss 17.123560 loss_att 18.796772 loss_ctc 25.336670 loss_rnnt 13.438876 hw_loss 0.422805 lr 0.00049545 rank 2
2023-02-11 23:17:24,295 DEBUG TRAIN Batch 12/1700 loss 9.887869 loss_att 12.528112 loss_ctc 14.236167 loss_rnnt 6.439519 hw_loss 0.438849 lr 0.00049570 rank 4
2023-02-11 23:18:43,090 DEBUG TRAIN Batch 12/1800 loss 13.381277 loss_att 17.575085 loss_ctc 21.857914 loss_rnnt 9.306399 hw_loss 0.394856 lr 0.00049537 rank 7
2023-02-11 23:18:43,093 DEBUG TRAIN Batch 12/1800 loss 12.325054 loss_att 14.404801 loss_ctc 17.308348 loss_rnnt 9.795679 hw_loss 0.271685 lr 0.00049533 rank 0
2023-02-11 23:18:43,096 DEBUG TRAIN Batch 12/1800 loss 11.675291 loss_att 15.082178 loss_ctc 17.366224 loss_rnnt 8.272123 hw_loss 0.368062 lr 0.00049537 rank 1
2023-02-11 23:18:43,096 DEBUG TRAIN Batch 12/1800 loss 8.763060 loss_att 6.895214 loss_ctc 8.228742 loss_rnnt 4.301394 hw_loss 0.919964 lr 0.00049544 rank 3
2023-02-11 23:18:43,098 DEBUG TRAIN Batch 12/1800 loss 14.947609 loss_att 19.357939 loss_ctc 24.646948 loss_rnnt 11.163167 hw_loss 0.301712 lr 0.00049546 rank 6
2023-02-11 23:18:43,098 DEBUG TRAIN Batch 12/1800 loss 12.946695 loss_att 16.177319 loss_ctc 20.265997 loss_rnnt 10.690234 hw_loss 0.118956 lr 0.00049535 rank 5
2023-02-11 23:18:43,099 DEBUG TRAIN Batch 12/1800 loss 13.292205 loss_att 17.273279 loss_ctc 18.500254 loss_rnnt 8.991003 hw_loss 0.526984 lr 0.00049521 rank 2
2023-02-11 23:18:43,104 DEBUG TRAIN Batch 12/1800 loss 6.892127 loss_att 7.435744 loss_ctc 9.429963 loss_rnnt 4.183718 hw_loss 0.423995 lr 0.00049546 rank 4
2023-02-11 23:20:00,325 DEBUG TRAIN Batch 12/1900 loss 13.716417 loss_att 17.314568 loss_ctc 19.113386 loss_rnnt 11.291404 hw_loss 0.184835 lr 0.00049520 rank 3
2023-02-11 23:20:00,327 DEBUG TRAIN Batch 12/1900 loss 16.094486 loss_att 12.187143 loss_ctc 15.058600 loss_rnnt 10.516309 hw_loss 1.218331 lr 0.00049522 rank 4
2023-02-11 23:20:00,328 DEBUG TRAIN Batch 12/1900 loss 11.465137 loss_att 11.576191 loss_ctc 18.146627 loss_rnnt 8.535919 hw_loss 0.378026 lr 0.00049508 rank 0
2023-02-11 23:20:00,329 DEBUG TRAIN Batch 12/1900 loss 15.526712 loss_att 14.159736 loss_ctc 19.937117 loss_rnnt 10.851509 hw_loss 0.817602 lr 0.00049513 rank 7
2023-02-11 23:20:00,330 DEBUG TRAIN Batch 12/1900 loss 15.857880 loss_att 14.133348 loss_ctc 17.901752 loss_rnnt 10.717755 hw_loss 0.977347 lr 0.00049496 rank 2
2023-02-11 23:20:00,333 DEBUG TRAIN Batch 12/1900 loss 13.110170 loss_att 11.045684 loss_ctc 18.136662 loss_rnnt 9.677779 hw_loss 0.595329 lr 0.00049511 rank 5
2023-02-11 23:20:00,334 DEBUG TRAIN Batch 12/1900 loss 10.511568 loss_att 9.325660 loss_ctc 9.914623 loss_rnnt 8.183930 hw_loss 0.495827 lr 0.00049512 rank 1
2023-02-11 23:20:00,337 DEBUG TRAIN Batch 12/1900 loss 8.447238 loss_att 10.266699 loss_ctc 10.288760 loss_rnnt 5.172787 hw_loss 0.499692 lr 0.00049521 rank 6
2023-02-11 23:21:16,045 DEBUG TRAIN Batch 12/2000 loss 12.036150 loss_att 14.667622 loss_ctc 24.430237 loss_rnnt 8.157056 hw_loss 0.318798 lr 0.00049484 rank 0
2023-02-11 23:21:16,047 DEBUG TRAIN Batch 12/2000 loss 11.720989 loss_att 16.965305 loss_ctc 17.595200 loss_rnnt 7.801586 hw_loss 0.391371 lr 0.00049497 rank 4
2023-02-11 23:21:16,047 DEBUG TRAIN Batch 12/2000 loss 12.402799 loss_att 15.841135 loss_ctc 21.257061 loss_rnnt 7.715501 hw_loss 0.528574 lr 0.00049489 rank 7
2023-02-11 23:21:16,048 DEBUG TRAIN Batch 12/2000 loss 10.865208 loss_att 13.132022 loss_ctc 16.698059 loss_rnnt 7.235298 hw_loss 0.449781 lr 0.00049486 rank 5
2023-02-11 23:21:16,048 DEBUG TRAIN Batch 12/2000 loss 11.701025 loss_att 14.968947 loss_ctc 14.036001 loss_rnnt 8.987768 hw_loss 0.327814 lr 0.00049497 rank 6
2023-02-11 23:21:16,050 DEBUG TRAIN Batch 12/2000 loss 7.536793 loss_att 12.388049 loss_ctc 9.905841 loss_rnnt 4.998880 hw_loss 0.234710 lr 0.00049496 rank 3
2023-02-11 23:21:16,051 DEBUG TRAIN Batch 12/2000 loss 12.272006 loss_att 13.380091 loss_ctc 14.956404 loss_rnnt 10.394718 hw_loss 0.243328 lr 0.00049488 rank 1
2023-02-11 23:21:16,054 DEBUG TRAIN Batch 12/2000 loss 15.849609 loss_att 16.797310 loss_ctc 26.565826 loss_rnnt 13.383604 hw_loss 0.158932 lr 0.00049472 rank 2
2023-02-11 23:22:33,329 DEBUG TRAIN Batch 12/2100 loss 12.470504 loss_att 15.167920 loss_ctc 13.810946 loss_rnnt 8.036694 hw_loss 0.696675 lr 0.00049460 rank 0
2023-02-11 23:22:33,333 DEBUG TRAIN Batch 12/2100 loss 7.186460 loss_att 8.299406 loss_ctc 9.647837 loss_rnnt 4.973286 hw_loss 0.311700 lr 0.00049473 rank 6
2023-02-11 23:22:33,333 DEBUG TRAIN Batch 12/2100 loss 13.301870 loss_att 17.085064 loss_ctc 18.846115 loss_rnnt 9.632871 hw_loss 0.407462 lr 0.00049471 rank 3
2023-02-11 23:22:33,333 DEBUG TRAIN Batch 12/2100 loss 11.832147 loss_att 16.192650 loss_ctc 18.216146 loss_rnnt 7.248302 hw_loss 0.536352 lr 0.00049465 rank 7
2023-02-11 23:22:33,334 DEBUG TRAIN Batch 12/2100 loss 14.005368 loss_att 20.372593 loss_ctc 20.318050 loss_rnnt 11.354889 hw_loss 0.100377 lr 0.00049448 rank 2
2023-02-11 23:22:33,338 DEBUG TRAIN Batch 12/2100 loss 13.122551 loss_att 13.682333 loss_ctc 22.391609 loss_rnnt 7.677206 hw_loss 0.768284 lr 0.00049462 rank 5
2023-02-11 23:22:33,339 DEBUG TRAIN Batch 12/2100 loss 18.104406 loss_att 22.772358 loss_ctc 32.652584 loss_rnnt 13.540858 hw_loss 0.316913 lr 0.00049473 rank 4
2023-02-11 23:22:33,341 DEBUG TRAIN Batch 12/2100 loss 4.189700 loss_att 6.330799 loss_ctc 5.423155 loss_rnnt 3.038667 hw_loss 0.104691 lr 0.00049464 rank 1
2023-02-11 23:23:51,123 DEBUG TRAIN Batch 12/2200 loss 15.649031 loss_att 21.427250 loss_ctc 34.239845 loss_rnnt 9.258057 hw_loss 0.516854 lr 0.00049441 rank 7
2023-02-11 23:23:51,123 DEBUG TRAIN Batch 12/2200 loss 11.346663 loss_att 14.669315 loss_ctc 19.204990 loss_rnnt 9.043892 hw_loss 0.110712 lr 0.00049447 rank 3
2023-02-11 23:23:51,128 DEBUG TRAIN Batch 12/2200 loss 14.794557 loss_att 16.844715 loss_ctc 22.535025 loss_rnnt 12.983997 hw_loss 0.069087 lr 0.00049449 rank 6
2023-02-11 23:23:51,128 DEBUG TRAIN Batch 12/2200 loss 17.028248 loss_att 18.612598 loss_ctc 28.895702 loss_rnnt 13.681182 hw_loss 0.271475 lr 0.00049436 rank 0
2023-02-11 23:23:51,131 DEBUG TRAIN Batch 12/2200 loss 11.722238 loss_att 12.957525 loss_ctc 16.473574 loss_rnnt 8.768720 hw_loss 0.388678 lr 0.00049449 rank 4
2023-02-11 23:23:51,131 DEBUG TRAIN Batch 12/2200 loss 19.610645 loss_att 18.140530 loss_ctc 23.855303 loss_rnnt 16.783710 hw_loss 0.479063 lr 0.00049438 rank 5
2023-02-11 23:23:51,134 DEBUG TRAIN Batch 12/2200 loss 11.403633 loss_att 14.376842 loss_ctc 16.118752 loss_rnnt 8.811142 hw_loss 0.256719 lr 0.00049440 rank 1
2023-02-11 23:23:51,136 DEBUG TRAIN Batch 12/2200 loss 8.724894 loss_att 10.891165 loss_ctc 14.580167 loss_rnnt 7.476317 hw_loss 0.006491 lr 0.00049424 rank 2
2023-02-11 23:25:06,067 DEBUG TRAIN Batch 12/2300 loss 9.613067 loss_att 15.401512 loss_ctc 19.427147 loss_rnnt 6.831601 hw_loss 0.059106 lr 0.00049423 rank 3
2023-02-11 23:25:06,071 DEBUG TRAIN Batch 12/2300 loss 18.654436 loss_att 22.436531 loss_ctc 35.725864 loss_rnnt 14.414012 hw_loss 0.226465 lr 0.00049416 rank 7
2023-02-11 23:25:06,072 DEBUG TRAIN Batch 12/2300 loss 20.524256 loss_att 24.612337 loss_ctc 26.882965 loss_rnnt 17.360456 hw_loss 0.280942 lr 0.00049424 rank 6
2023-02-11 23:25:06,072 DEBUG TRAIN Batch 12/2300 loss 14.028835 loss_att 15.444913 loss_ctc 18.024570 loss_rnnt 9.448441 hw_loss 0.705828 lr 0.00049412 rank 0
2023-02-11 23:25:06,073 DEBUG TRAIN Batch 12/2300 loss 8.347227 loss_att 11.011528 loss_ctc 11.008477 loss_rnnt 5.445920 hw_loss 0.377552 lr 0.00049416 rank 1
2023-02-11 23:25:06,074 DEBUG TRAIN Batch 12/2300 loss 10.918642 loss_att 13.116669 loss_ctc 13.574035 loss_rnnt 8.461446 hw_loss 0.311913 lr 0.00049414 rank 5
2023-02-11 23:25:06,077 DEBUG TRAIN Batch 12/2300 loss 15.264689 loss_att 17.341267 loss_ctc 21.427290 loss_rnnt 12.659464 hw_loss 0.256543 lr 0.00049400 rank 2
2023-02-11 23:25:06,123 DEBUG TRAIN Batch 12/2300 loss 10.015489 loss_att 12.185347 loss_ctc 15.608189 loss_rnnt 7.204164 hw_loss 0.305936 lr 0.00049425 rank 4
2023-02-11 23:26:22,725 DEBUG TRAIN Batch 12/2400 loss 17.104425 loss_att 17.723660 loss_ctc 24.933357 loss_rnnt 13.499174 hw_loss 0.457040 lr 0.00049399 rank 3
2023-02-11 23:26:22,730 DEBUG TRAIN Batch 12/2400 loss 12.876411 loss_att 19.243536 loss_ctc 21.521318 loss_rnnt 7.031356 hw_loss 0.641058 lr 0.00049387 rank 0
2023-02-11 23:26:22,736 DEBUG TRAIN Batch 12/2400 loss 12.731694 loss_att 13.696137 loss_ctc 20.289257 loss_rnnt 9.820696 hw_loss 0.320707 lr 0.00049400 rank 6
2023-02-11 23:26:22,736 DEBUG TRAIN Batch 12/2400 loss 8.411759 loss_att 10.426468 loss_ctc 13.598119 loss_rnnt 5.680584 hw_loss 0.306885 lr 0.00049392 rank 1
2023-02-11 23:26:22,737 DEBUG TRAIN Batch 12/2400 loss 16.609303 loss_att 16.899399 loss_ctc 24.147999 loss_rnnt 12.551471 hw_loss 0.561498 lr 0.00049390 rank 5
2023-02-11 23:26:22,737 DEBUG TRAIN Batch 12/2400 loss 16.480688 loss_att 19.135773 loss_ctc 26.065769 loss_rnnt 10.765816 hw_loss 0.732346 lr 0.00049376 rank 2
2023-02-11 23:26:22,741 DEBUG TRAIN Batch 12/2400 loss 23.425817 loss_att 23.175621 loss_ctc 31.067896 loss_rnnt 18.958120 hw_loss 0.656024 lr 0.00049392 rank 7
2023-02-11 23:26:22,743 DEBUG TRAIN Batch 12/2400 loss 11.497646 loss_att 11.798421 loss_ctc 20.755857 loss_rnnt 9.384077 hw_loss 0.153560 lr 0.00049401 rank 4
2023-02-11 23:27:41,948 DEBUG TRAIN Batch 12/2500 loss 4.375089 loss_att 7.346871 loss_ctc 7.907575 loss_rnnt 2.938774 hw_loss 0.069555 lr 0.00049363 rank 0
2023-02-11 23:27:41,950 DEBUG TRAIN Batch 12/2500 loss 22.305824 loss_att 22.629045 loss_ctc 35.986660 loss_rnnt 17.424473 hw_loss 0.561112 lr 0.00049376 rank 6
2023-02-11 23:27:41,950 DEBUG TRAIN Batch 12/2500 loss 10.397141 loss_att 10.894559 loss_ctc 13.940725 loss_rnnt 7.437248 hw_loss 0.447737 lr 0.00049375 rank 3
2023-02-11 23:27:41,951 DEBUG TRAIN Batch 12/2500 loss 11.270014 loss_att 10.077801 loss_ctc 11.731535 loss_rnnt 7.838448 hw_loss 0.676589 lr 0.00049366 rank 5
2023-02-11 23:27:41,954 DEBUG TRAIN Batch 12/2500 loss 12.709142 loss_att 10.158733 loss_ctc 12.505647 loss_rnnt 9.269383 hw_loss 0.745682 lr 0.00049377 rank 4
2023-02-11 23:27:41,955 DEBUG TRAIN Batch 12/2500 loss 13.980165 loss_att 12.630190 loss_ctc 14.364412 loss_rnnt 8.578508 hw_loss 1.053828 lr 0.00049352 rank 2
2023-02-11 23:27:41,955 DEBUG TRAIN Batch 12/2500 loss 8.669183 loss_att 9.069750 loss_ctc 11.180217 loss_rnnt 4.371326 hw_loss 0.728051 lr 0.00049368 rank 7
2023-02-11 23:27:41,958 DEBUG TRAIN Batch 12/2500 loss 12.456898 loss_att 13.947866 loss_ctc 17.810173 loss_rnnt 8.257337 hw_loss 0.597674 lr 0.00049367 rank 1
2023-02-11 23:28:57,123 DEBUG TRAIN Batch 12/2600 loss 15.628459 loss_att 12.749784 loss_ctc 17.621876 loss_rnnt 12.527572 hw_loss 0.639531 lr 0.00049339 rank 0
2023-02-11 23:28:57,124 DEBUG TRAIN Batch 12/2600 loss 7.101040 loss_att 7.802731 loss_ctc 7.856541 loss_rnnt 2.720229 hw_loss 0.776201 lr 0.00049351 rank 3
2023-02-11 23:28:57,125 DEBUG TRAIN Batch 12/2600 loss 17.993549 loss_att 19.556538 loss_ctc 28.801291 loss_rnnt 15.430644 hw_loss 0.151739 lr 0.00049328 rank 2
2023-02-11 23:28:57,125 DEBUG TRAIN Batch 12/2600 loss 14.209442 loss_att 16.805027 loss_ctc 20.576622 loss_rnnt 10.567383 hw_loss 0.426372 lr 0.00049353 rank 4
2023-02-11 23:28:57,126 DEBUG TRAIN Batch 12/2600 loss 17.866360 loss_att 20.220146 loss_ctc 24.869946 loss_rnnt 13.837359 hw_loss 0.492081 lr 0.00049341 rank 5
2023-02-11 23:28:57,127 DEBUG TRAIN Batch 12/2600 loss 16.681486 loss_att 14.435086 loss_ctc 23.498095 loss_rnnt 13.289091 hw_loss 0.549899 lr 0.00049352 rank 6
2023-02-11 23:28:57,127 DEBUG TRAIN Batch 12/2600 loss 10.194834 loss_att 11.039886 loss_ctc 15.058124 loss_rnnt 5.598448 hw_loss 0.708551 lr 0.00049344 rank 7
2023-02-11 23:28:57,134 DEBUG TRAIN Batch 12/2600 loss 9.049328 loss_att 11.980129 loss_ctc 14.262973 loss_rnnt 5.599260 hw_loss 0.406642 lr 0.00049343 rank 1
2023-02-11 23:30:12,401 DEBUG TRAIN Batch 12/2700 loss 6.673182 loss_att 6.935454 loss_ctc 6.430780 loss_rnnt 4.269639 hw_loss 0.446889 lr 0.00049329 rank 4
2023-02-11 23:30:12,401 DEBUG TRAIN Batch 12/2700 loss 10.018217 loss_att 13.973739 loss_ctc 12.637675 loss_rnnt 7.620669 hw_loss 0.235722 lr 0.00049320 rank 7
2023-02-11 23:30:12,404 DEBUG TRAIN Batch 12/2700 loss 14.083490 loss_att 14.656738 loss_ctc 21.720716 loss_rnnt 10.021800 hw_loss 0.549139 lr 0.00049328 rank 6
2023-02-11 23:30:12,407 DEBUG TRAIN Batch 12/2700 loss 17.093910 loss_att 23.673746 loss_ctc 33.599823 loss_rnnt 12.538582 hw_loss 0.194732 lr 0.00049319 rank 1
2023-02-11 23:30:12,408 DEBUG TRAIN Batch 12/2700 loss 12.667651 loss_att 14.106981 loss_ctc 18.149172 loss_rnnt 9.597411 hw_loss 0.384657 lr 0.00049327 rank 3
2023-02-11 23:30:12,410 DEBUG TRAIN Batch 12/2700 loss 11.465414 loss_att 12.606363 loss_ctc 18.058006 loss_rnnt 8.227070 hw_loss 0.399589 lr 0.00049315 rank 0
2023-02-11 23:30:12,410 DEBUG TRAIN Batch 12/2700 loss 27.446810 loss_att 33.898773 loss_ctc 35.306896 loss_rnnt 23.374439 hw_loss 0.325119 lr 0.00049304 rank 2
2023-02-11 23:30:12,410 DEBUG TRAIN Batch 12/2700 loss 17.100573 loss_att 21.376413 loss_ctc 30.748808 loss_rnnt 12.519398 hw_loss 0.357420 lr 0.00049317 rank 5
2023-02-11 23:31:29,574 DEBUG TRAIN Batch 12/2800 loss 11.951345 loss_att 14.402424 loss_ctc 20.229000 loss_rnnt 8.979259 hw_loss 0.258409 lr 0.00049303 rank 3
2023-02-11 23:31:29,579 DEBUG TRAIN Batch 12/2800 loss 14.785297 loss_att 15.895094 loss_ctc 29.121315 loss_rnnt 8.777584 hw_loss 0.726429 lr 0.00049291 rank 0
2023-02-11 23:31:29,580 DEBUG TRAIN Batch 12/2800 loss 14.439490 loss_att 18.450329 loss_ctc 20.641567 loss_rnnt 9.759645 hw_loss 0.572012 lr 0.00049296 rank 7
2023-02-11 23:31:29,580 DEBUG TRAIN Batch 12/2800 loss 24.541916 loss_att 22.438375 loss_ctc 29.743589 loss_rnnt 20.692329 hw_loss 0.670638 lr 0.00049294 rank 5
2023-02-11 23:31:29,582 DEBUG TRAIN Batch 12/2800 loss 15.928591 loss_att 16.212482 loss_ctc 24.293175 loss_rnnt 13.014994 hw_loss 0.326539 lr 0.00049305 rank 4
2023-02-11 23:31:29,583 DEBUG TRAIN Batch 12/2800 loss 15.204116 loss_att 15.812832 loss_ctc 24.496008 loss_rnnt 12.659943 hw_loss 0.221908 lr 0.00049295 rank 1
2023-02-11 23:31:29,586 DEBUG TRAIN Batch 12/2800 loss 9.349607 loss_att 11.365876 loss_ctc 13.496033 loss_rnnt 5.642442 hw_loss 0.515823 lr 0.00049280 rank 2
2023-02-11 23:31:29,627 DEBUG TRAIN Batch 12/2800 loss 17.430206 loss_att 17.293970 loss_ctc 21.113184 loss_rnnt 14.969681 hw_loss 0.374383 lr 0.00049304 rank 6
2023-02-11 23:32:48,028 DEBUG TRAIN Batch 12/2900 loss 16.006067 loss_att 17.488852 loss_ctc 24.731054 loss_rnnt 12.242529 hw_loss 0.431934 lr 0.00049267 rank 0
2023-02-11 23:32:48,028 DEBUG TRAIN Batch 12/2900 loss 16.285709 loss_att 20.482918 loss_ctc 28.256889 loss_rnnt 13.267956 hw_loss 0.109154 lr 0.00049271 rank 1
2023-02-11 23:32:48,028 DEBUG TRAIN Batch 12/2900 loss 15.895620 loss_att 16.238739 loss_ctc 20.776562 loss_rnnt 12.621222 hw_loss 0.479059 lr 0.00049270 rank 5
2023-02-11 23:32:48,032 DEBUG TRAIN Batch 12/2900 loss 7.564443 loss_att 9.956261 loss_ctc 10.957422 loss_rnnt 5.172833 hw_loss 0.273909 lr 0.00049272 rank 7
2023-02-11 23:32:48,035 DEBUG TRAIN Batch 12/2900 loss 27.021034 loss_att 27.539368 loss_ctc 36.579674 loss_rnnt 22.507162 hw_loss 0.587948 lr 0.00049279 rank 3
2023-02-11 23:32:48,037 DEBUG TRAIN Batch 12/2900 loss 10.328465 loss_att 13.157382 loss_ctc 20.406435 loss_rnnt 6.889684 hw_loss 0.286738 lr 0.00049280 rank 6
2023-02-11 23:32:48,044 DEBUG TRAIN Batch 12/2900 loss 13.623040 loss_att 14.090538 loss_ctc 21.995747 loss_rnnt 10.281360 hw_loss 0.399716 lr 0.00049256 rank 2
2023-02-11 23:32:48,080 DEBUG TRAIN Batch 12/2900 loss 14.173674 loss_att 17.655109 loss_ctc 23.625034 loss_rnnt 10.851813 hw_loss 0.256011 lr 0.00049281 rank 4
2023-02-11 23:34:04,547 DEBUG TRAIN Batch 12/3000 loss 11.372519 loss_att 14.275968 loss_ctc 16.328962 loss_rnnt 5.513122 hw_loss 0.865846 lr 0.00049244 rank 0
2023-02-11 23:34:04,547 DEBUG TRAIN Batch 12/3000 loss 7.668065 loss_att 7.450955 loss_ctc 9.128350 loss_rnnt 4.803206 hw_loss 0.508795 lr 0.00049255 rank 3
2023-02-11 23:34:04,548 DEBUG TRAIN Batch 12/3000 loss 30.085995 loss_att 32.376919 loss_ctc 47.179188 loss_rnnt 22.969629 hw_loss 0.821079 lr 0.00049248 rank 7
2023-02-11 23:34:04,550 DEBUG TRAIN Batch 12/3000 loss 20.209457 loss_att 20.590496 loss_ctc 28.441704 loss_rnnt 14.790825 hw_loss 0.795898 lr 0.00049232 rank 2
2023-02-11 23:34:04,550 DEBUG TRAIN Batch 12/3000 loss 29.892986 loss_att 35.585121 loss_ctc 48.240723 loss_rnnt 23.218889 hw_loss 0.579245 lr 0.00049256 rank 6
2023-02-11 23:34:04,553 DEBUG TRAIN Batch 12/3000 loss 7.695026 loss_att 10.315499 loss_ctc 10.512602 loss_rnnt 4.029663 hw_loss 0.518548 lr 0.00049257 rank 4
2023-02-11 23:34:04,553 DEBUG TRAIN Batch 12/3000 loss 15.279153 loss_att 18.202744 loss_ctc 19.536453 loss_rnnt 11.831200 hw_loss 0.430424 lr 0.00049248 rank 1
2023-02-11 23:34:04,555 DEBUG TRAIN Batch 12/3000 loss 49.444023 loss_att 60.649918 loss_ctc 98.662460 loss_rnnt 37.576286 hw_loss 0.574518 lr 0.00049246 rank 5
2023-02-11 23:35:21,645 DEBUG TRAIN Batch 12/3100 loss 12.315194 loss_att 14.111603 loss_ctc 21.215923 loss_rnnt 9.897058 hw_loss 0.163517 lr 0.00049231 rank 3
2023-02-11 23:35:21,649 DEBUG TRAIN Batch 12/3100 loss 27.891754 loss_att 32.986870 loss_ctc 44.039543 loss_rnnt 23.470097 hw_loss 0.234299 lr 0.00049224 rank 1
2023-02-11 23:35:21,651 DEBUG TRAIN Batch 12/3100 loss 15.828776 loss_att 15.342474 loss_ctc 20.979818 loss_rnnt 13.849863 hw_loss 0.260506 lr 0.00049220 rank 0
2023-02-11 23:35:21,651 DEBUG TRAIN Batch 12/3100 loss 12.542192 loss_att 13.786541 loss_ctc 18.301397 loss_rnnt 8.179212 hw_loss 0.627416 lr 0.00049224 rank 7
2023-02-11 23:35:21,652 DEBUG TRAIN Batch 12/3100 loss 10.789007 loss_att 13.309629 loss_ctc 15.762027 loss_rnnt 6.792224 hw_loss 0.530548 lr 0.00049232 rank 6
2023-02-11 23:35:21,655 DEBUG TRAIN Batch 12/3100 loss 16.201685 loss_att 15.480038 loss_ctc 19.553755 loss_rnnt 10.162992 hw_loss 1.075515 lr 0.00049208 rank 2
2023-02-11 23:35:21,655 DEBUG TRAIN Batch 12/3100 loss 16.321348 loss_att 18.952980 loss_ctc 21.040464 loss_rnnt 12.880594 hw_loss 0.428477 lr 0.00049222 rank 5
2023-02-11 23:35:21,656 DEBUG TRAIN Batch 12/3100 loss 11.578914 loss_att 11.962090 loss_ctc 14.735674 loss_rnnt 8.067403 hw_loss 0.565120 lr 0.00049233 rank 4
2023-02-11 23:36:40,981 DEBUG TRAIN Batch 12/3200 loss 12.804287 loss_att 15.719483 loss_ctc 21.439583 loss_rnnt 8.233607 hw_loss 0.531800 lr 0.00049207 rank 3
2023-02-11 23:36:40,984 DEBUG TRAIN Batch 12/3200 loss 12.105069 loss_att 12.259922 loss_ctc 14.115353 loss_rnnt 9.701861 hw_loss 0.394537 lr 0.00049200 rank 1
2023-02-11 23:36:40,987 DEBUG TRAIN Batch 12/3200 loss 20.528433 loss_att 18.547321 loss_ctc 29.290325 loss_rnnt 19.116095 hw_loss 0.120058 lr 0.00049196 rank 0
2023-02-11 23:36:40,987 DEBUG TRAIN Batch 12/3200 loss 14.315967 loss_att 12.940222 loss_ctc 16.984276 loss_rnnt 11.685053 hw_loss 0.478179 lr 0.00049201 rank 7
2023-02-11 23:36:40,988 DEBUG TRAIN Batch 12/3200 loss 13.403898 loss_att 10.121857 loss_ctc 13.631226 loss_rnnt 9.196804 hw_loss 0.906223 lr 0.00049198 rank 5
2023-02-11 23:36:40,994 DEBUG TRAIN Batch 12/3200 loss 12.105297 loss_att 9.901011 loss_ctc 12.423354 loss_rnnt 8.358721 hw_loss 0.777192 lr 0.00049184 rank 2
2023-02-11 23:36:40,996 DEBUG TRAIN Batch 12/3200 loss 6.898329 loss_att 9.460778 loss_ctc 10.171477 loss_rnnt 5.245776 hw_loss 0.131933 lr 0.00049208 rank 6
2023-02-11 23:36:41,056 DEBUG TRAIN Batch 12/3200 loss 18.883791 loss_att 24.488708 loss_ctc 37.045815 loss_rnnt 12.858332 hw_loss 0.465538 lr 0.00049209 rank 4
2023-02-11 23:37:57,621 DEBUG TRAIN Batch 12/3300 loss 8.507916 loss_att 9.263461 loss_ctc 12.064586 loss_rnnt 4.199951 hw_loss 0.690494 lr 0.00049185 rank 6
2023-02-11 23:37:57,624 DEBUG TRAIN Batch 12/3300 loss 13.643044 loss_att 13.907022 loss_ctc 15.469448 loss_rnnt 11.582577 hw_loss 0.330778 lr 0.00049183 rank 3
2023-02-11 23:37:57,625 DEBUG TRAIN Batch 12/3300 loss 12.741043 loss_att 17.280581 loss_ctc 18.109722 loss_rnnt 8.593849 hw_loss 0.473149 lr 0.00049160 rank 2
2023-02-11 23:37:57,625 DEBUG TRAIN Batch 12/3300 loss 15.049413 loss_att 15.394190 loss_ctc 20.368179 loss_rnnt 12.124548 hw_loss 0.402514 lr 0.00049172 rank 0
2023-02-11 23:37:57,628 DEBUG TRAIN Batch 12/3300 loss 16.809082 loss_att 20.154583 loss_ctc 28.802946 loss_rnnt 11.055937 hw_loss 0.653412 lr 0.00049177 rank 7
2023-02-11 23:37:57,631 DEBUG TRAIN Batch 12/3300 loss 3.898895 loss_att 7.210460 loss_ctc 4.683352 loss_rnnt 2.288574 hw_loss 0.158140 lr 0.00049174 rank 5
2023-02-11 23:37:57,633 DEBUG TRAIN Batch 12/3300 loss 17.143806 loss_att 16.575161 loss_ctc 16.371330 loss_rnnt 15.414083 hw_loss 0.364959 lr 0.00049185 rank 4
2023-02-11 23:37:57,676 DEBUG TRAIN Batch 12/3300 loss 9.070723 loss_att 14.176181 loss_ctc 21.192402 loss_rnnt 5.809040 hw_loss 0.117069 lr 0.00049176 rank 1
2023-02-11 23:39:13,747 DEBUG TRAIN Batch 12/3400 loss 12.434471 loss_att 13.763026 loss_ctc 14.470396 loss_rnnt 9.423679 hw_loss 0.463805 lr 0.00049148 rank 0
2023-02-11 23:39:13,750 DEBUG TRAIN Batch 12/3400 loss 13.396208 loss_att 14.663260 loss_ctc 18.373259 loss_rnnt 7.806555 hw_loss 0.876119 lr 0.00049150 rank 5
2023-02-11 23:39:13,751 DEBUG TRAIN Batch 12/3400 loss 17.226952 loss_att 21.699289 loss_ctc 31.662344 loss_rnnt 13.543566 hw_loss 0.162037 lr 0.00049153 rank 7
2023-02-11 23:39:13,753 DEBUG TRAIN Batch 12/3400 loss 17.770876 loss_att 22.093542 loss_ctc 33.155937 loss_rnnt 13.547401 hw_loss 0.245175 lr 0.00049137 rank 2
2023-02-11 23:39:13,756 DEBUG TRAIN Batch 12/3400 loss 7.672650 loss_att 11.077188 loss_ctc 9.807280 loss_rnnt 4.629471 hw_loss 0.389560 lr 0.00049160 rank 3
2023-02-11 23:39:13,757 DEBUG TRAIN Batch 12/3400 loss 13.958619 loss_att 16.562187 loss_ctc 16.437347 loss_rnnt 12.455877 hw_loss 0.122162 lr 0.00049161 rank 6
2023-02-11 23:39:13,759 DEBUG TRAIN Batch 12/3400 loss 12.039431 loss_att 14.443313 loss_ctc 16.915579 loss_rnnt 7.833822 hw_loss 0.576502 lr 0.00049152 rank 1
2023-02-11 23:39:13,761 DEBUG TRAIN Batch 12/3400 loss 14.477003 loss_att 15.502723 loss_ctc 22.426689 loss_rnnt 9.752918 hw_loss 0.648559 lr 0.00049161 rank 4
2023-02-11 23:40:32,019 DEBUG TRAIN Batch 12/3500 loss 10.153553 loss_att 10.600177 loss_ctc 13.916632 loss_rnnt 6.583322 hw_loss 0.558593 lr 0.00049136 rank 3
2023-02-11 23:40:32,019 DEBUG TRAIN Batch 12/3500 loss 8.538284 loss_att 9.385234 loss_ctc 9.216657 loss_rnnt 6.431254 hw_loss 0.346348 lr 0.00049113 rank 2
2023-02-11 23:40:32,019 DEBUG TRAIN Batch 12/3500 loss 22.617434 loss_att 21.999622 loss_ctc 27.408478 loss_rnnt 20.806713 hw_loss 0.242902 lr 0.00049125 rank 0
2023-02-11 23:40:32,022 DEBUG TRAIN Batch 12/3500 loss 13.122087 loss_att 17.458946 loss_ctc 22.421293 loss_rnnt 9.123353 hw_loss 0.354650 lr 0.00049127 rank 5
2023-02-11 23:40:32,023 DEBUG TRAIN Batch 12/3500 loss 17.979115 loss_att 22.859861 loss_ctc 30.507719 loss_rnnt 14.536106 hw_loss 0.149321 lr 0.00049129 rank 1
2023-02-11 23:40:32,025 DEBUG TRAIN Batch 12/3500 loss 13.170797 loss_att 17.861561 loss_ctc 26.562798 loss_rnnt 9.419010 hw_loss 0.192756 lr 0.00049129 rank 7
2023-02-11 23:40:32,026 DEBUG TRAIN Batch 12/3500 loss 8.903818 loss_att 9.977654 loss_ctc 9.956432 loss_rnnt 6.332683 hw_loss 0.415504 lr 0.00049137 rank 6
2023-02-11 23:40:32,079 DEBUG TRAIN Batch 12/3500 loss 13.140779 loss_att 15.623219 loss_ctc 18.969639 loss_rnnt 8.754721 hw_loss 0.583573 lr 0.00049138 rank 4
2023-02-11 23:41:50,468 DEBUG TRAIN Batch 12/3600 loss 18.388535 loss_att 17.539598 loss_ctc 26.420635 loss_rnnt 12.982471 hw_loss 0.844669 lr 0.00049089 rank 2
2023-02-11 23:41:50,469 DEBUG TRAIN Batch 12/3600 loss 8.850577 loss_att 9.038033 loss_ctc 11.139415 loss_rnnt 4.963524 hw_loss 0.664572 lr 0.00049112 rank 3
2023-02-11 23:41:50,471 DEBUG TRAIN Batch 12/3600 loss 12.517325 loss_att 13.988903 loss_ctc 17.601679 loss_rnnt 9.476633 hw_loss 0.387837 lr 0.00049105 rank 1
2023-02-11 23:41:50,474 DEBUG TRAIN Batch 12/3600 loss 11.498700 loss_att 15.168653 loss_ctc 18.463413 loss_rnnt 7.235459 hw_loss 0.487616 lr 0.00049106 rank 7
2023-02-11 23:41:50,478 DEBUG TRAIN Batch 12/3600 loss 27.447697 loss_att 28.355927 loss_ctc 48.350010 loss_rnnt 22.259602 hw_loss 0.416151 lr 0.00049114 rank 4
2023-02-11 23:41:50,478 DEBUG TRAIN Batch 12/3600 loss 14.343810 loss_att 15.822302 loss_ctc 23.246450 loss_rnnt 11.309335 hw_loss 0.290955 lr 0.00049101 rank 0
2023-02-11 23:41:50,479 DEBUG TRAIN Batch 12/3600 loss 21.034288 loss_att 19.888912 loss_ctc 24.970169 loss_rnnt 18.367456 hw_loss 0.444585 lr 0.00049103 rank 5
2023-02-11 23:41:50,536 DEBUG TRAIN Batch 12/3600 loss 17.053122 loss_att 19.566450 loss_ctc 25.248978 loss_rnnt 13.577250 hw_loss 0.352580 lr 0.00049113 rank 6
2023-02-11 23:43:06,182 DEBUG TRAIN Batch 12/3700 loss 12.139977 loss_att 11.547361 loss_ctc 12.234953 loss_rnnt 8.065522 hw_loss 0.783809 lr 0.00049077 rank 0
2023-02-11 23:43:06,185 DEBUG TRAIN Batch 12/3700 loss 9.152371 loss_att 7.888381 loss_ctc 6.921362 loss_rnnt 6.205249 hw_loss 0.655760 lr 0.00049089 rank 3
2023-02-11 23:43:06,189 DEBUG TRAIN Batch 12/3700 loss 15.857487 loss_att 18.595428 loss_ctc 24.716175 loss_rnnt 12.350558 hw_loss 0.333409 lr 0.00049066 rank 2
2023-02-11 23:43:06,189 DEBUG TRAIN Batch 12/3700 loss 17.656645 loss_att 21.318451 loss_ctc 18.983322 loss_rnnt 14.945576 hw_loss 0.337841 lr 0.00049082 rank 7
2023-02-11 23:43:06,191 DEBUG TRAIN Batch 12/3700 loss 16.401108 loss_att 16.647465 loss_ctc 20.230392 loss_rnnt 12.849306 hw_loss 0.560992 lr 0.00049081 rank 1
2023-02-11 23:43:06,193 DEBUG TRAIN Batch 12/3700 loss 12.037286 loss_att 12.733007 loss_ctc 17.771120 loss_rnnt 8.134275 hw_loss 0.562379 lr 0.00049079 rank 5
2023-02-11 23:43:06,196 DEBUG TRAIN Batch 12/3700 loss 10.445574 loss_att 11.150578 loss_ctc 12.171229 loss_rnnt 8.445689 hw_loss 0.305400 lr 0.00049090 rank 4
2023-02-11 23:43:06,250 DEBUG TRAIN Batch 12/3700 loss 23.059402 loss_att 24.415058 loss_ctc 33.378696 loss_rnnt 18.168541 hw_loss 0.608217 lr 0.00049090 rank 6
2023-02-11 23:44:23,069 DEBUG TRAIN Batch 12/3800 loss 19.418980 loss_att 17.684933 loss_ctc 24.310812 loss_rnnt 16.670322 hw_loss 0.458104 lr 0.00049058 rank 7
2023-02-11 23:44:23,070 DEBUG TRAIN Batch 12/3800 loss 12.363422 loss_att 15.576135 loss_ctc 17.207012 loss_rnnt 9.455723 hw_loss 0.303627 lr 0.00049066 rank 6
2023-02-11 23:44:23,072 DEBUG TRAIN Batch 12/3800 loss 12.832699 loss_att 11.939083 loss_ctc 16.209631 loss_rnnt 9.917513 hw_loss 0.495685 lr 0.00049042 rank 2
2023-02-11 23:44:23,073 DEBUG TRAIN Batch 12/3800 loss 26.752945 loss_att 27.781069 loss_ctc 47.302853 loss_rnnt 20.769514 hw_loss 0.569591 lr 0.00049065 rank 3
2023-02-11 23:44:23,073 DEBUG TRAIN Batch 12/3800 loss 14.813924 loss_att 14.719044 loss_ctc 19.437098 loss_rnnt 11.939977 hw_loss 0.426844 lr 0.00049056 rank 5
2023-02-11 23:44:23,078 DEBUG TRAIN Batch 12/3800 loss 14.762471 loss_att 15.817486 loss_ctc 15.440067 loss_rnnt 11.898159 hw_loss 0.480556 lr 0.00049054 rank 0
2023-02-11 23:44:23,092 DEBUG TRAIN Batch 12/3800 loss 6.357463 loss_att 5.741947 loss_ctc 6.780586 loss_rnnt 4.367402 hw_loss 0.385640 lr 0.00049067 rank 4
2023-02-11 23:44:23,095 DEBUG TRAIN Batch 12/3800 loss 17.617031 loss_att 17.798199 loss_ctc 23.555681 loss_rnnt 13.186164 hw_loss 0.675528 lr 0.00049058 rank 1
2023-02-11 23:45:42,122 DEBUG TRAIN Batch 12/3900 loss 14.992106 loss_att 13.380417 loss_ctc 19.942602 loss_rnnt 10.960958 hw_loss 0.692516 lr 0.00049034 rank 1
2023-02-11 23:45:42,132 DEBUG TRAIN Batch 12/3900 loss 13.601933 loss_att 11.191205 loss_ctc 15.677645 loss_rnnt 10.457953 hw_loss 0.628006 lr 0.00049042 rank 6
2023-02-11 23:45:42,135 DEBUG TRAIN Batch 12/3900 loss 14.290196 loss_att 15.207163 loss_ctc 21.823584 loss_rnnt 11.611458 hw_loss 0.279543 lr 0.00049043 rank 4
2023-02-11 23:45:42,135 DEBUG TRAIN Batch 12/3900 loss 12.872436 loss_att 14.394921 loss_ctc 16.699614 loss_rnnt 10.234350 hw_loss 0.341868 lr 0.00049032 rank 5
2023-02-11 23:45:42,135 DEBUG TRAIN Batch 12/3900 loss 20.816547 loss_att 26.834919 loss_ctc 29.453705 loss_rnnt 17.141981 hw_loss 0.247363 lr 0.00049041 rank 3
2023-02-11 23:45:42,136 DEBUG TRAIN Batch 12/3900 loss 13.831567 loss_att 20.307661 loss_ctc 21.323353 loss_rnnt 6.240390 hw_loss 0.993197 lr 0.00049030 rank 0
2023-02-11 23:45:42,136 DEBUG TRAIN Batch 12/3900 loss 12.793965 loss_att 8.707054 loss_ctc 12.910828 loss_rnnt 8.224010 hw_loss 1.007204 lr 0.00049035 rank 7
2023-02-11 23:45:42,145 DEBUG TRAIN Batch 12/3900 loss 23.991764 loss_att 25.145275 loss_ctc 36.623764 loss_rnnt 20.441666 hw_loss 0.306587 lr 0.00049018 rank 2
2023-02-11 23:46:56,952 DEBUG TRAIN Batch 12/4000 loss 14.460150 loss_att 17.302244 loss_ctc 25.721619 loss_rnnt 9.060274 hw_loss 0.624361 lr 0.00049018 rank 3
2023-02-11 23:46:56,956 DEBUG TRAIN Batch 12/4000 loss 10.945059 loss_att 13.332998 loss_ctc 14.443674 loss_rnnt 7.709144 hw_loss 0.429721 lr 0.00048995 rank 2
2023-02-11 23:46:56,956 DEBUG TRAIN Batch 12/4000 loss 13.300391 loss_att 14.769604 loss_ctc 18.694811 loss_rnnt 11.808811 hw_loss 0.089715 lr 0.00049006 rank 0
2023-02-11 23:46:56,958 DEBUG TRAIN Batch 12/4000 loss 8.223909 loss_att 11.580135 loss_ctc 13.227125 loss_rnnt 4.437947 hw_loss 0.458929 lr 0.00049019 rank 4
2023-02-11 23:46:56,959 DEBUG TRAIN Batch 12/4000 loss 17.537104 loss_att 21.227793 loss_ctc 25.121014 loss_rnnt 14.657972 hw_loss 0.211839 lr 0.00049011 rank 7
2023-02-11 23:46:56,960 DEBUG TRAIN Batch 12/4000 loss 8.185939 loss_att 10.128533 loss_ctc 10.009006 loss_rnnt 4.921597 hw_loss 0.493640 lr 0.00049019 rank 6
2023-02-11 23:46:56,961 DEBUG TRAIN Batch 12/4000 loss 15.245847 loss_att 19.620306 loss_ctc 25.978926 loss_rnnt 11.619357 hw_loss 0.247597 lr 0.00049009 rank 5
2023-02-11 23:46:56,966 DEBUG TRAIN Batch 12/4000 loss 10.622200 loss_att 13.462217 loss_ctc 18.586094 loss_rnnt 8.539283 hw_loss 0.084949 lr 0.00049010 rank 1
2023-02-11 23:48:12,580 DEBUG TRAIN Batch 12/4100 loss 10.482654 loss_att 10.558411 loss_ctc 13.922087 loss_rnnt 8.370295 hw_loss 0.307241 lr 0.00048996 rank 4
2023-02-11 23:48:12,580 DEBUG TRAIN Batch 12/4100 loss 5.055958 loss_att 7.328947 loss_ctc 7.619384 loss_rnnt 2.071827 hw_loss 0.410202 lr 0.00048995 rank 6
2023-02-11 23:48:12,580 DEBUG TRAIN Batch 12/4100 loss 11.603210 loss_att 13.957262 loss_ctc 18.870380 loss_rnnt 7.805143 hw_loss 0.442181 lr 0.00048988 rank 7
2023-02-11 23:48:12,581 DEBUG TRAIN Batch 12/4100 loss 14.633327 loss_att 13.447777 loss_ctc 21.544073 loss_rnnt 11.041790 hw_loss 0.545102 lr 0.00048994 rank 3
2023-02-11 23:48:12,582 DEBUG TRAIN Batch 12/4100 loss 11.418943 loss_att 13.432394 loss_ctc 11.800631 loss_rnnt 8.002022 hw_loss 0.555626 lr 0.00048983 rank 0
2023-02-11 23:48:12,586 DEBUG TRAIN Batch 12/4100 loss 17.271301 loss_att 20.283216 loss_ctc 26.160864 loss_rnnt 13.414439 hw_loss 0.387976 lr 0.00048987 rank 1
2023-02-11 23:48:12,586 DEBUG TRAIN Batch 12/4100 loss 15.687449 loss_att 20.156893 loss_ctc 25.087414 loss_rnnt 12.544075 hw_loss 0.186779 lr 0.00048985 rank 5
2023-02-11 23:48:12,589 DEBUG TRAIN Batch 12/4100 loss 26.316059 loss_att 27.687023 loss_ctc 37.889153 loss_rnnt 21.897644 hw_loss 0.487715 lr 0.00048971 rank 2
2023-02-11 23:49:30,151 DEBUG TRAIN Batch 12/4200 loss 7.590613 loss_att 6.820880 loss_ctc 11.782828 loss_rnnt 4.347078 hw_loss 0.532222 lr 0.00048971 rank 3
2023-02-11 23:49:30,152 DEBUG TRAIN Batch 12/4200 loss 21.177364 loss_att 22.923990 loss_ctc 31.868694 loss_rnnt 16.873783 hw_loss 0.474140 lr 0.00048963 rank 1
2023-02-11 23:49:30,153 DEBUG TRAIN Batch 12/4200 loss 24.612730 loss_att 25.511702 loss_ctc 30.658367 loss_rnnt 21.302153 hw_loss 0.435881 lr 0.00048964 rank 7
2023-02-11 23:49:30,156 DEBUG TRAIN Batch 12/4200 loss 6.588654 loss_att 9.829493 loss_ctc 11.499180 loss_rnnt 4.397686 hw_loss 0.166512 lr 0.00048959 rank 0
2023-02-11 23:49:30,157 DEBUG TRAIN Batch 12/4200 loss 6.688248 loss_att 8.178000 loss_ctc 10.702756 loss_rnnt 3.194275 hw_loss 0.498892 lr 0.00048948 rank 2
2023-02-11 23:49:30,159 DEBUG TRAIN Batch 12/4200 loss 21.420488 loss_att 24.086432 loss_ctc 31.326332 loss_rnnt 19.029591 hw_loss 0.100674 lr 0.00048962 rank 5
2023-02-11 23:49:30,159 DEBUG TRAIN Batch 12/4200 loss 8.134647 loss_att 11.444361 loss_ctc 11.342064 loss_rnnt 5.792570 hw_loss 0.234840 lr 0.00048972 rank 4
2023-02-11 23:49:30,160 DEBUG TRAIN Batch 12/4200 loss 12.865097 loss_att 16.892124 loss_ctc 23.354141 loss_rnnt 9.750931 hw_loss 0.170667 lr 0.00048972 rank 6
2023-02-11 23:50:48,490 DEBUG TRAIN Batch 12/4300 loss 10.940125 loss_att 10.736691 loss_ctc 12.137024 loss_rnnt 9.320422 hw_loss 0.281401 lr 0.00048941 rank 7
2023-02-11 23:50:48,493 DEBUG TRAIN Batch 12/4300 loss 10.200214 loss_att 13.140345 loss_ctc 21.314978 loss_rnnt 7.595514 hw_loss 0.100257 lr 0.00048948 rank 6
2023-02-11 23:50:48,494 DEBUG TRAIN Batch 12/4300 loss 11.878295 loss_att 13.005013 loss_ctc 16.814310 loss_rnnt 7.467335 hw_loss 0.661403 lr 0.00048940 rank 1
2023-02-11 23:50:48,497 DEBUG TRAIN Batch 12/4300 loss 17.521124 loss_att 19.388935 loss_ctc 24.018654 loss_rnnt 15.000401 hw_loss 0.240154 lr 0.00048936 rank 0
2023-02-11 23:50:48,499 DEBUG TRAIN Batch 12/4300 loss 21.034651 loss_att 19.453785 loss_ctc 28.068542 loss_rnnt 15.991867 hw_loss 0.828957 lr 0.00048947 rank 3
2023-02-11 23:50:48,499 DEBUG TRAIN Batch 12/4300 loss 21.286087 loss_att 22.082047 loss_ctc 32.121964 loss_rnnt 17.593620 hw_loss 0.391592 lr 0.00048924 rank 2
2023-02-11 23:50:48,503 DEBUG TRAIN Batch 12/4300 loss 10.742226 loss_att 13.631564 loss_ctc 17.265606 loss_rnnt 7.127722 hw_loss 0.406285 lr 0.00048938 rank 5
2023-02-11 23:50:48,508 DEBUG TRAIN Batch 12/4300 loss 10.464572 loss_att 9.814929 loss_ctc 12.824544 loss_rnnt 6.415932 hw_loss 0.724482 lr 0.00048949 rank 4
2023-02-11 23:52:04,354 DEBUG TRAIN Batch 12/4400 loss 8.793289 loss_att 8.396874 loss_ctc 11.124095 loss_rnnt 5.337650 hw_loss 0.604528 lr 0.00048925 rank 4
2023-02-11 23:52:04,356 DEBUG TRAIN Batch 12/4400 loss 11.257975 loss_att 14.220778 loss_ctc 17.450792 loss_rnnt 8.108917 hw_loss 0.324523 lr 0.00048924 rank 3
2023-02-11 23:52:04,356 DEBUG TRAIN Batch 12/4400 loss 18.722818 loss_att 16.032883 loss_ctc 23.017218 loss_rnnt 13.673813 hw_loss 0.940201 lr 0.00048901 rank 2
2023-02-11 23:52:04,357 DEBUG TRAIN Batch 12/4400 loss 15.534527 loss_att 15.601822 loss_ctc 22.320833 loss_rnnt 13.471222 hw_loss 0.214688 lr 0.00048915 rank 5
2023-02-11 23:52:04,359 DEBUG TRAIN Batch 12/4400 loss 17.286985 loss_att 20.783012 loss_ctc 26.418707 loss_rnnt 13.203669 hw_loss 0.406228 lr 0.00048917 rank 1
2023-02-11 23:52:04,359 DEBUG TRAIN Batch 12/4400 loss 15.901516 loss_att 16.060419 loss_ctc 20.338373 loss_rnnt 10.358653 hw_loss 0.922407 lr 0.00048917 rank 7
2023-02-11 23:52:04,365 DEBUG TRAIN Batch 12/4400 loss 13.722681 loss_att 14.352654 loss_ctc 21.259193 loss_rnnt 9.685537 hw_loss 0.544928 lr 0.00048913 rank 0
2023-02-11 23:52:04,404 DEBUG TRAIN Batch 12/4400 loss 12.452182 loss_att 13.599885 loss_ctc 21.527756 loss_rnnt 7.573785 hw_loss 0.644771 lr 0.00048925 rank 6
2023-02-11 23:53:21,823 DEBUG TRAIN Batch 12/4500 loss 17.865385 loss_att 19.622200 loss_ctc 21.522383 loss_rnnt 13.171302 hw_loss 0.722835 lr 0.00048878 rank 2
2023-02-11 23:53:21,824 DEBUG TRAIN Batch 12/4500 loss 9.295228 loss_att 7.542588 loss_ctc 10.606353 loss_rnnt 5.885036 hw_loss 0.672357 lr 0.00048894 rank 7
2023-02-11 23:53:21,826 DEBUG TRAIN Batch 12/4500 loss 11.554659 loss_att 13.043804 loss_ctc 16.393486 loss_rnnt 7.424161 hw_loss 0.597655 lr 0.00048902 rank 4
2023-02-11 23:53:21,826 DEBUG TRAIN Batch 12/4500 loss 14.162589 loss_att 17.119547 loss_ctc 18.262503 loss_rnnt 11.926028 hw_loss 0.205972 lr 0.00048900 rank 3
2023-02-11 23:53:21,828 DEBUG TRAIN Batch 12/4500 loss 13.117239 loss_att 12.045246 loss_ctc 16.325605 loss_rnnt 8.740989 hw_loss 0.780537 lr 0.00048893 rank 1
2023-02-11 23:53:21,831 DEBUG TRAIN Batch 12/4500 loss 8.136042 loss_att 14.059084 loss_ctc 14.269107 loss_rnnt 5.389366 hw_loss 0.139561 lr 0.00048889 rank 0
2023-02-11 23:53:21,834 DEBUG TRAIN Batch 12/4500 loss 10.864944 loss_att 11.701188 loss_ctc 14.738356 loss_rnnt 7.602811 hw_loss 0.483456 lr 0.00048902 rank 6
2023-02-11 23:53:21,834 DEBUG TRAIN Batch 12/4500 loss 12.114804 loss_att 14.973558 loss_ctc 18.593451 loss_rnnt 10.064270 hw_loss 0.115306 lr 0.00048891 rank 5
2023-02-11 23:54:41,002 DEBUG TRAIN Batch 12/4600 loss 12.272603 loss_att 15.920229 loss_ctc 19.159752 loss_rnnt 8.091505 hw_loss 0.474991 lr 0.00048866 rank 0
2023-02-11 23:54:41,005 DEBUG TRAIN Batch 12/4600 loss 10.315747 loss_att 10.857708 loss_ctc 15.002103 loss_rnnt 8.687474 hw_loss 0.167819 lr 0.00048877 rank 3
2023-02-11 23:54:41,015 DEBUG TRAIN Batch 12/4600 loss 12.932037 loss_att 17.192568 loss_ctc 26.457184 loss_rnnt 9.379240 hw_loss 0.168251 lr 0.00048870 rank 7
2023-02-11 23:54:41,016 DEBUG TRAIN Batch 12/4600 loss 22.153563 loss_att 21.784149 loss_ctc 34.053452 loss_rnnt 16.793955 hw_loss 0.721282 lr 0.00048868 rank 5
2023-02-11 23:54:41,024 DEBUG TRAIN Batch 12/4600 loss 10.682387 loss_att 12.147789 loss_ctc 12.898666 loss_rnnt 6.739076 hw_loss 0.629011 lr 0.00048879 rank 4
2023-02-11 23:54:41,027 DEBUG TRAIN Batch 12/4600 loss 10.494488 loss_att 17.709703 loss_ctc 19.428921 loss_rnnt 5.909801 hw_loss 0.365697 lr 0.00048854 rank 2
2023-02-11 23:54:41,027 DEBUG TRAIN Batch 12/4600 loss 18.800674 loss_att 22.217083 loss_ctc 29.752930 loss_rnnt 13.600176 hw_loss 0.573172 lr 0.00048870 rank 1
2023-02-11 23:54:41,031 DEBUG TRAIN Batch 12/4600 loss 8.779911 loss_att 13.183559 loss_ctc 12.547744 loss_rnnt 5.634212 hw_loss 0.330486 lr 0.00048878 rank 6
2023-02-11 23:55:57,682 DEBUG TRAIN Batch 12/4700 loss 11.070891 loss_att 16.468094 loss_ctc 20.832439 loss_rnnt 6.759462 hw_loss 0.361959 lr 0.00048846 rank 1
2023-02-11 23:55:57,682 DEBUG TRAIN Batch 12/4700 loss 18.499485 loss_att 17.521338 loss_ctc 33.602795 loss_rnnt 13.654835 hw_loss 0.567469 lr 0.00048855 rank 4
2023-02-11 23:55:57,684 DEBUG TRAIN Batch 12/4700 loss 24.367781 loss_att 28.848289 loss_ctc 38.550488 loss_rnnt 19.598095 hw_loss 0.371729 lr 0.00048854 rank 3
2023-02-11 23:55:57,684 DEBUG TRAIN Batch 12/4700 loss 12.436142 loss_att 15.458481 loss_ctc 17.824802 loss_rnnt 8.918137 hw_loss 0.411572 lr 0.00048842 rank 0
2023-02-11 23:55:57,685 DEBUG TRAIN Batch 12/4700 loss 12.103749 loss_att 12.288887 loss_ctc 19.468060 loss_rnnt 8.310142 hw_loss 0.520251 lr 0.00048847 rank 7
2023-02-11 23:55:57,685 DEBUG TRAIN Batch 12/4700 loss 13.845079 loss_att 13.382405 loss_ctc 20.062569 loss_rnnt 10.517792 hw_loss 0.485779 lr 0.00048831 rank 2
2023-02-11 23:55:57,685 DEBUG TRAIN Batch 12/4700 loss 8.164349 loss_att 14.740015 loss_ctc 12.593332 loss_rnnt 4.538839 hw_loss 0.322471 lr 0.00048845 rank 5
2023-02-11 23:55:57,734 DEBUG TRAIN Batch 12/4700 loss 7.233233 loss_att 10.456543 loss_ctc 15.433409 loss_rnnt 4.103920 hw_loss 0.260868 lr 0.00048855 rank 6
2023-02-11 23:57:12,855 DEBUG TRAIN Batch 12/4800 loss 17.015617 loss_att 19.010052 loss_ctc 26.020008 loss_rnnt 13.440404 hw_loss 0.370451 lr 0.00048830 rank 3
2023-02-11 23:57:12,857 DEBUG TRAIN Batch 12/4800 loss 10.883777 loss_att 13.115829 loss_ctc 17.221598 loss_rnnt 7.622892 hw_loss 0.369268 lr 0.00048824 rank 7
2023-02-11 23:57:12,857 DEBUG TRAIN Batch 12/4800 loss 11.560150 loss_att 12.808365 loss_ctc 18.891788 loss_rnnt 8.080648 hw_loss 0.422307 lr 0.00048823 rank 1
2023-02-11 23:57:12,858 DEBUG TRAIN Batch 12/4800 loss 11.772136 loss_att 16.113092 loss_ctc 24.404684 loss_rnnt 7.528876 hw_loss 0.317012 lr 0.00048832 rank 6
2023-02-11 23:57:12,858 DEBUG TRAIN Batch 12/4800 loss 13.634179 loss_att 13.777317 loss_ctc 17.139877 loss_rnnt 12.766163 hw_loss 0.069743 lr 0.00048819 rank 0
2023-02-11 23:57:12,860 DEBUG TRAIN Batch 12/4800 loss 7.560099 loss_att 8.196743 loss_ctc 13.523611 loss_rnnt 4.349798 hw_loss 0.428970 lr 0.00048821 rank 5
2023-02-11 23:57:12,862 DEBUG TRAIN Batch 12/4800 loss 21.190956 loss_att 22.108936 loss_ctc 26.195465 loss_rnnt 18.998096 hw_loss 0.251624 lr 0.00048832 rank 4
2023-02-11 23:57:12,862 DEBUG TRAIN Batch 12/4800 loss 13.834937 loss_att 17.184944 loss_ctc 23.875702 loss_rnnt 10.444529 hw_loss 0.259057 lr 0.00048808 rank 2
2023-02-11 23:58:28,746 DEBUG TRAIN Batch 12/4900 loss 29.380171 loss_att 31.827198 loss_ctc 39.439537 loss_rnnt 25.600246 hw_loss 0.365488 lr 0.00048800 rank 1
2023-02-11 23:58:28,746 DEBUG TRAIN Batch 12/4900 loss 14.223187 loss_att 19.021105 loss_ctc 31.391155 loss_rnnt 10.179452 hw_loss 0.149079 lr 0.00048785 rank 2
2023-02-11 23:58:28,749 DEBUG TRAIN Batch 12/4900 loss 13.286150 loss_att 12.826823 loss_ctc 17.869276 loss_rnnt 9.130488 hw_loss 0.681833 lr 0.00048807 rank 3
2023-02-11 23:58:28,749 DEBUG TRAIN Batch 12/4900 loss 13.388020 loss_att 19.323706 loss_ctc 18.395927 loss_rnnt 9.529983 hw_loss 0.375596 lr 0.00048798 rank 5
2023-02-11 23:58:28,751 DEBUG TRAIN Batch 12/4900 loss 24.451115 loss_att 23.861658 loss_ctc 29.917122 loss_rnnt 19.896599 hw_loss 0.739426 lr 0.00048796 rank 0
2023-02-11 23:58:28,752 DEBUG TRAIN Batch 12/4900 loss 16.894449 loss_att 20.778727 loss_ctc 21.507399 loss_rnnt 14.236372 hw_loss 0.237406 lr 0.00048801 rank 7
2023-02-11 23:58:28,765 DEBUG TRAIN Batch 12/4900 loss 7.938058 loss_att 9.822949 loss_ctc 11.261451 loss_rnnt 4.743341 hw_loss 0.445241 lr 0.00048808 rank 6
2023-02-11 23:58:28,798 DEBUG TRAIN Batch 12/4900 loss 10.359268 loss_att 14.674238 loss_ctc 17.279526 loss_rnnt 7.370062 hw_loss 0.225659 lr 0.00048809 rank 4
2023-02-11 23:59:48,107 DEBUG TRAIN Batch 12/5000 loss 10.159378 loss_att 10.560496 loss_ctc 19.202940 loss_rnnt 6.929652 hw_loss 0.364443 lr 0.00048773 rank 0
2023-02-11 23:59:48,110 DEBUG TRAIN Batch 12/5000 loss 15.189644 loss_att 17.272053 loss_ctc 24.457724 loss_rnnt 11.149414 hw_loss 0.447751 lr 0.00048785 rank 4
2023-02-11 23:59:48,112 DEBUG TRAIN Batch 12/5000 loss 11.069033 loss_att 8.497785 loss_ctc 11.871471 loss_rnnt 7.374197 hw_loss 0.769143 lr 0.00048784 rank 3
2023-02-11 23:59:48,112 DEBUG TRAIN Batch 12/5000 loss 12.352524 loss_att 13.075237 loss_ctc 15.033144 loss_rnnt 8.911378 hw_loss 0.551098 lr 0.00048777 rank 7
2023-02-11 23:59:48,118 DEBUG TRAIN Batch 12/5000 loss 12.926710 loss_att 12.468100 loss_ctc 17.152533 loss_rnnt 9.244948 hw_loss 0.601883 lr 0.00048775 rank 5
2023-02-11 23:59:48,122 DEBUG TRAIN Batch 12/5000 loss 12.420288 loss_att 10.415672 loss_ctc 14.425592 loss_rnnt 9.300897 hw_loss 0.609926 lr 0.00048761 rank 2
2023-02-11 23:59:48,160 DEBUG TRAIN Batch 12/5000 loss 10.442351 loss_att 10.082754 loss_ctc 13.084650 loss_rnnt 6.823453 hw_loss 0.625971 lr 0.00048777 rank 1
2023-02-11 23:59:48,190 DEBUG TRAIN Batch 12/5000 loss 12.381145 loss_att 10.839928 loss_ctc 12.962219 loss_rnnt 10.528677 hw_loss 0.390606 lr 0.00048785 rank 6
2023-02-12 00:01:05,103 DEBUG TRAIN Batch 12/5100 loss 4.449362 loss_att 8.884030 loss_ctc 9.061038 loss_rnnt 2.857086 hw_loss 0.016960 lr 0.00048761 rank 3
2023-02-12 00:01:05,104 DEBUG TRAIN Batch 12/5100 loss 9.098558 loss_att 8.617989 loss_ctc 10.598281 loss_rnnt 5.526795 hw_loss 0.650234 lr 0.00048754 rank 7
2023-02-12 00:01:05,111 DEBUG TRAIN Batch 12/5100 loss 17.125402 loss_att 18.487694 loss_ctc 23.816715 loss_rnnt 13.294092 hw_loss 0.500002 lr 0.00048762 rank 6
2023-02-12 00:01:05,111 DEBUG TRAIN Batch 12/5100 loss 12.510265 loss_att 14.315399 loss_ctc 19.233917 loss_rnnt 9.227440 hw_loss 0.379746 lr 0.00048750 rank 0
2023-02-12 00:01:05,112 DEBUG TRAIN Batch 12/5100 loss 15.217728 loss_att 16.691124 loss_ctc 25.500372 loss_rnnt 11.863131 hw_loss 0.316668 lr 0.00048762 rank 4
2023-02-12 00:01:05,112 DEBUG TRAIN Batch 12/5100 loss 20.711084 loss_att 20.164593 loss_ctc 24.446674 loss_rnnt 15.629513 hw_loss 0.879898 lr 0.00048752 rank 5
2023-02-12 00:01:05,113 DEBUG TRAIN Batch 12/5100 loss 13.247180 loss_att 19.911968 loss_ctc 18.871897 loss_rnnt 10.070591 hw_loss 0.205063 lr 0.00048738 rank 2
2023-02-12 00:01:05,113 DEBUG TRAIN Batch 12/5100 loss 14.463266 loss_att 12.690160 loss_ctc 16.035620 loss_rnnt 11.399796 hw_loss 0.601583 lr 0.00048753 rank 1
2023-02-12 00:02:20,453 DEBUG TRAIN Batch 12/5200 loss 16.807194 loss_att 18.460257 loss_ctc 20.830389 loss_rnnt 14.734762 hw_loss 0.226011 lr 0.00048726 rank 0
2023-02-12 00:02:20,455 DEBUG TRAIN Batch 12/5200 loss 18.981483 loss_att 26.636532 loss_ctc 38.426773 loss_rnnt 13.213707 hw_loss 0.308261 lr 0.00048739 rank 6
2023-02-12 00:02:20,458 DEBUG TRAIN Batch 12/5200 loss 21.662100 loss_att 25.315254 loss_ctc 41.512981 loss_rnnt 17.062965 hw_loss 0.229072 lr 0.00048737 rank 3
2023-02-12 00:02:20,459 DEBUG TRAIN Batch 12/5200 loss 14.941454 loss_att 17.623098 loss_ctc 23.000210 loss_rnnt 10.851176 hw_loss 0.464897 lr 0.00048730 rank 1
2023-02-12 00:02:20,459 DEBUG TRAIN Batch 12/5200 loss 12.650039 loss_att 23.363049 loss_ctc 22.037121 loss_rnnt 7.185092 hw_loss 0.388263 lr 0.00048715 rank 2
2023-02-12 00:02:20,461 DEBUG TRAIN Batch 12/5200 loss 18.943865 loss_att 20.439993 loss_ctc 31.640347 loss_rnnt 14.158674 hw_loss 0.523706 lr 0.00048728 rank 5
2023-02-12 00:02:20,462 DEBUG TRAIN Batch 12/5200 loss 18.941475 loss_att 22.169907 loss_ctc 34.368889 loss_rnnt 13.432849 hw_loss 0.526116 lr 0.00048731 rank 7
2023-02-12 00:02:20,463 DEBUG TRAIN Batch 12/5200 loss 5.690418 loss_att 6.039283 loss_ctc 5.526317 loss_rnnt 3.330457 hw_loss 0.433513 lr 0.00048739 rank 4
2023-02-12 00:03:38,294 DEBUG TRAIN Batch 12/5300 loss 15.585417 loss_att 16.648954 loss_ctc 24.306015 loss_rnnt 12.615593 hw_loss 0.298944 lr 0.00048705 rank 5
2023-02-12 00:03:38,296 DEBUG TRAIN Batch 12/5300 loss 12.628539 loss_att 14.229521 loss_ctc 21.525146 loss_rnnt 9.024818 hw_loss 0.393246 lr 0.00048714 rank 3
2023-02-12 00:03:38,296 DEBUG TRAIN Batch 12/5300 loss 22.467943 loss_att 26.446991 loss_ctc 39.906242 loss_rnnt 16.654789 hw_loss 0.504794 lr 0.00048715 rank 6
2023-02-12 00:03:38,301 DEBUG TRAIN Batch 12/5300 loss 13.929207 loss_att 17.115955 loss_ctc 30.463591 loss_rnnt 10.755522 hw_loss 0.062203 lr 0.00048707 rank 1
2023-02-12 00:03:38,302 DEBUG TRAIN Batch 12/5300 loss 7.529286 loss_att 12.308331 loss_ctc 13.988636 loss_rnnt 4.692863 hw_loss 0.191132 lr 0.00048708 rank 7
2023-02-12 00:03:38,303 DEBUG TRAIN Batch 12/5300 loss 17.787357 loss_att 17.785381 loss_ctc 25.232578 loss_rnnt 16.056166 hw_loss 0.138542 lr 0.00048716 rank 4
2023-02-12 00:03:38,306 DEBUG TRAIN Batch 12/5300 loss 15.832725 loss_att 18.542032 loss_ctc 22.345730 loss_rnnt 10.339041 hw_loss 0.765641 lr 0.00048692 rank 2
2023-02-12 00:03:38,311 DEBUG TRAIN Batch 12/5300 loss 5.651901 loss_att 10.618851 loss_ctc 9.279058 loss_rnnt 2.558986 hw_loss 0.302982 lr 0.00048703 rank 0
2023-02-12 00:04:54,932 DEBUG TRAIN Batch 12/5400 loss 12.363379 loss_att 13.881386 loss_ctc 16.943199 loss_rnnt 9.053628 hw_loss 0.449158 lr 0.00048685 rank 7
2023-02-12 00:04:54,933 DEBUG TRAIN Batch 12/5400 loss 10.909728 loss_att 14.974011 loss_ctc 17.167278 loss_rnnt 8.421286 hw_loss 0.157734 lr 0.00048680 rank 0
2023-02-12 00:04:54,937 DEBUG TRAIN Batch 12/5400 loss 15.292337 loss_att 14.328459 loss_ctc 17.443405 loss_rnnt 11.320478 hw_loss 0.727092 lr 0.00048669 rank 2
2023-02-12 00:04:54,937 DEBUG TRAIN Batch 12/5400 loss 11.290968 loss_att 11.015611 loss_ctc 13.325641 loss_rnnt 7.644062 hw_loss 0.643254 lr 0.00048691 rank 3
2023-02-12 00:04:54,939 DEBUG TRAIN Batch 12/5400 loss 15.775710 loss_att 22.661482 loss_ctc 33.444942 loss_rnnt 11.323989 hw_loss 0.134750 lr 0.00048693 rank 4
2023-02-12 00:04:54,940 DEBUG TRAIN Batch 12/5400 loss 6.487450 loss_att 9.760442 loss_ctc 11.641634 loss_rnnt 3.652046 hw_loss 0.280046 lr 0.00048684 rank 1
2023-02-12 00:04:54,941 DEBUG TRAIN Batch 12/5400 loss 6.779127 loss_att 9.164097 loss_ctc 8.485600 loss_rnnt 3.885400 hw_loss 0.410476 lr 0.00048692 rank 6
2023-02-12 00:04:54,943 DEBUG TRAIN Batch 12/5400 loss 13.977121 loss_att 19.655544 loss_ctc 22.278889 loss_rnnt 10.558388 hw_loss 0.220527 lr 0.00048682 rank 5
2023-02-12 00:06:09,524 DEBUG TRAIN Batch 12/5500 loss 15.264355 loss_att 16.355564 loss_ctc 25.327097 loss_rnnt 11.003908 hw_loss 0.506344 lr 0.00048668 rank 3
2023-02-12 00:06:09,526 DEBUG TRAIN Batch 12/5500 loss 17.952257 loss_att 19.156651 loss_ctc 26.127625 loss_rnnt 13.331872 hw_loss 0.616773 lr 0.00048657 rank 0
2023-02-12 00:06:09,527 DEBUG TRAIN Batch 12/5500 loss 19.710823 loss_att 22.512375 loss_ctc 30.794878 loss_rnnt 14.889820 hw_loss 0.521779 lr 0.00048646 rank 2
2023-02-12 00:06:09,529 DEBUG TRAIN Batch 12/5500 loss 13.545691 loss_att 15.305470 loss_ctc 21.859890 loss_rnnt 8.728696 hw_loss 0.629340 lr 0.00048670 rank 4
2023-02-12 00:06:09,531 DEBUG TRAIN Batch 12/5500 loss 14.963490 loss_att 16.926548 loss_ctc 24.934776 loss_rnnt 11.862940 hw_loss 0.258456 lr 0.00048661 rank 1
2023-02-12 00:06:09,531 DEBUG TRAIN Batch 12/5500 loss 15.991485 loss_att 18.828503 loss_ctc 24.009333 loss_rnnt 11.968067 hw_loss 0.447556 lr 0.00048662 rank 7
2023-02-12 00:06:09,533 DEBUG TRAIN Batch 12/5500 loss 29.384541 loss_att 31.724413 loss_ctc 47.241268 loss_rnnt 24.732981 hw_loss 0.338004 lr 0.00048669 rank 6
2023-02-12 00:06:09,537 DEBUG TRAIN Batch 12/5500 loss 16.410051 loss_att 18.421345 loss_ctc 24.232113 loss_rnnt 13.855192 hw_loss 0.208061 lr 0.00048659 rank 5
2023-02-12 00:07:25,954 DEBUG TRAIN Batch 12/5600 loss 19.846159 loss_att 20.423431 loss_ctc 29.665792 loss_rnnt 16.486296 hw_loss 0.362836 lr 0.00048634 rank 0
2023-02-12 00:07:25,954 DEBUG TRAIN Batch 12/5600 loss 12.931332 loss_att 12.311698 loss_ctc 14.348849 loss_rnnt 9.446970 hw_loss 0.641116 lr 0.00048639 rank 7
2023-02-12 00:07:25,954 DEBUG TRAIN Batch 12/5600 loss 11.837629 loss_att 11.642912 loss_ctc 16.715172 loss_rnnt 8.020319 hw_loss 0.601109 lr 0.00048623 rank 2
2023-02-12 00:07:25,955 DEBUG TRAIN Batch 12/5600 loss 16.252548 loss_att 16.291752 loss_ctc 23.216322 loss_rnnt 13.091402 hw_loss 0.417150 lr 0.00048645 rank 3
2023-02-12 00:07:25,956 DEBUG TRAIN Batch 12/5600 loss 18.512163 loss_att 16.770275 loss_ctc 25.480999 loss_rnnt 15.396374 hw_loss 0.475310 lr 0.00048646 rank 6
2023-02-12 00:07:25,955 DEBUG TRAIN Batch 12/5600 loss 15.229956 loss_att 17.363689 loss_ctc 28.442526 loss_rnnt 10.911144 hw_loss 0.399448 lr 0.00048636 rank 5
2023-02-12 00:07:25,959 DEBUG TRAIN Batch 12/5600 loss 11.304934 loss_att 14.176825 loss_ctc 17.442026 loss_rnnt 7.957088 hw_loss 0.366598 lr 0.00048647 rank 4
2023-02-12 00:07:25,959 DEBUG TRAIN Batch 12/5600 loss 15.011428 loss_att 15.635937 loss_ctc 22.016438 loss_rnnt 13.005322 hw_loss 0.177601 lr 0.00048638 rank 1
2023-02-12 00:08:44,729 DEBUG TRAIN Batch 12/5700 loss 16.534174 loss_att 18.659397 loss_ctc 25.744669 loss_rnnt 12.646059 hw_loss 0.419063 lr 0.00048613 rank 5
2023-02-12 00:08:44,731 DEBUG TRAIN Batch 12/5700 loss 11.596496 loss_att 11.738694 loss_ctc 15.429517 loss_rnnt 8.154346 hw_loss 0.544245 lr 0.00048616 rank 7
2023-02-12 00:08:44,732 DEBUG TRAIN Batch 12/5700 loss 13.019847 loss_att 16.519230 loss_ctc 22.311569 loss_rnnt 10.652515 hw_loss 0.080355 lr 0.00048600 rank 2
2023-02-12 00:08:44,733 DEBUG TRAIN Batch 12/5700 loss 10.084417 loss_att 9.224620 loss_ctc 10.496809 loss_rnnt 7.285713 hw_loss 0.546690 lr 0.00048611 rank 0
2023-02-12 00:08:44,735 DEBUG TRAIN Batch 12/5700 loss 20.285000 loss_att 19.940674 loss_ctc 27.489344 loss_rnnt 16.040874 hw_loss 0.628577 lr 0.00048623 rank 6
2023-02-12 00:08:44,738 DEBUG TRAIN Batch 12/5700 loss 11.036924 loss_att 12.853320 loss_ctc 13.320560 loss_rnnt 6.387186 hw_loss 0.746620 lr 0.00048615 rank 1
2023-02-12 00:08:44,743 DEBUG TRAIN Batch 12/5700 loss 16.960323 loss_att 25.537766 loss_ctc 28.352066 loss_rnnt 12.926158 hw_loss 0.149958 lr 0.00048622 rank 3
2023-02-12 00:08:44,745 DEBUG TRAIN Batch 12/5700 loss 13.111892 loss_att 13.708634 loss_ctc 23.460758 loss_rnnt 9.351881 hw_loss 0.423903 lr 0.00048624 rank 4
2023-02-12 00:10:01,529 DEBUG TRAIN Batch 12/5800 loss 7.325317 loss_att 8.582365 loss_ctc 16.952366 loss_rnnt 2.890858 hw_loss 0.543646 lr 0.00048588 rank 0
2023-02-12 00:10:01,533 DEBUG TRAIN Batch 12/5800 loss 16.273220 loss_att 19.067806 loss_ctc 19.821159 loss_rnnt 11.547699 hw_loss 0.692540 lr 0.00048599 rank 3
2023-02-12 00:10:01,533 DEBUG TRAIN Batch 12/5800 loss 20.530273 loss_att 23.831303 loss_ctc 39.502823 loss_rnnt 14.944858 hw_loss 0.449163 lr 0.00048593 rank 7
2023-02-12 00:10:01,534 DEBUG TRAIN Batch 12/5800 loss 18.052252 loss_att 16.679741 loss_ctc 22.241951 loss_rnnt 15.429098 hw_loss 0.438568 lr 0.00048590 rank 5
2023-02-12 00:10:01,536 DEBUG TRAIN Batch 12/5800 loss 19.493561 loss_att 25.607046 loss_ctc 34.585064 loss_rnnt 16.033730 hw_loss 0.042175 lr 0.00048577 rank 2
2023-02-12 00:10:01,537 DEBUG TRAIN Batch 12/5800 loss 10.679125 loss_att 14.934439 loss_ctc 17.499180 loss_rnnt 6.963102 hw_loss 0.366679 lr 0.00048600 rank 6
2023-02-12 00:10:01,538 DEBUG TRAIN Batch 12/5800 loss 13.670016 loss_att 16.332905 loss_ctc 17.978157 loss_rnnt 9.862846 hw_loss 0.506283 lr 0.00048592 rank 1
2023-02-12 00:10:01,539 DEBUG TRAIN Batch 12/5800 loss 13.363524 loss_att 14.794062 loss_ctc 19.809078 loss_rnnt 9.454020 hw_loss 0.518248 lr 0.00048601 rank 4
2023-02-12 00:11:16,480 DEBUG TRAIN Batch 12/5900 loss 11.208539 loss_att 12.502372 loss_ctc 19.318998 loss_rnnt 9.440533 hw_loss 0.080221 lr 0.00048565 rank 0
2023-02-12 00:11:16,481 DEBUG TRAIN Batch 12/5900 loss 9.097749 loss_att 12.145777 loss_ctc 12.425963 loss_rnnt 5.956542 hw_loss 0.391470 lr 0.00048570 rank 7
2023-02-12 00:11:16,482 DEBUG TRAIN Batch 12/5900 loss 22.830915 loss_att 25.667440 loss_ctc 30.473827 loss_rnnt 17.617559 hw_loss 0.680062 lr 0.00048569 rank 1
2023-02-12 00:11:16,482 DEBUG TRAIN Batch 12/5900 loss 13.819284 loss_att 17.317146 loss_ctc 21.081049 loss_rnnt 9.643982 hw_loss 0.470155 lr 0.00048576 rank 3
2023-02-12 00:11:16,484 DEBUG TRAIN Batch 12/5900 loss 19.244764 loss_att 23.003349 loss_ctc 28.994507 loss_rnnt 15.930586 hw_loss 0.236718 lr 0.00048567 rank 5
2023-02-12 00:11:16,485 DEBUG TRAIN Batch 12/5900 loss 13.784996 loss_att 16.056257 loss_ctc 22.202299 loss_rnnt 10.013792 hw_loss 0.411496 lr 0.00048578 rank 4
2023-02-12 00:11:16,488 DEBUG TRAIN Batch 12/5900 loss 15.276568 loss_att 24.070866 loss_ctc 38.732292 loss_rnnt 8.011502 hw_loss 0.446021 lr 0.00048554 rank 2
2023-02-12 00:11:16,528 DEBUG TRAIN Batch 12/5900 loss 9.401777 loss_att 11.224005 loss_ctc 12.552679 loss_rnnt 3.969509 hw_loss 0.871444 lr 0.00048577 rank 6
2023-02-12 00:12:33,667 DEBUG TRAIN Batch 12/6000 loss 17.069141 loss_att 20.431564 loss_ctc 26.808722 loss_rnnt 14.369671 hw_loss 0.136570 lr 0.00048547 rank 7
2023-02-12 00:12:33,673 DEBUG TRAIN Batch 12/6000 loss 16.338243 loss_att 21.757320 loss_ctc 28.922342 loss_rnnt 11.463992 hw_loss 0.396104 lr 0.00048542 rank 0
2023-02-12 00:12:33,674 DEBUG TRAIN Batch 12/6000 loss 18.234095 loss_att 18.471708 loss_ctc 29.661840 loss_rnnt 13.776523 hw_loss 0.541191 lr 0.00048544 rank 5
2023-02-12 00:12:33,675 DEBUG TRAIN Batch 12/6000 loss 13.279718 loss_att 16.585281 loss_ctc 16.059607 loss_rnnt 10.479760 hw_loss 0.331536 lr 0.00048546 rank 1
2023-02-12 00:12:33,676 DEBUG TRAIN Batch 12/6000 loss 13.244657 loss_att 15.759254 loss_ctc 15.297474 loss_rnnt 9.592690 hw_loss 0.539126 lr 0.00048555 rank 4
2023-02-12 00:12:33,677 DEBUG TRAIN Batch 12/6000 loss 12.576471 loss_att 14.812778 loss_ctc 22.867016 loss_rnnt 10.307730 hw_loss 0.084264 lr 0.00048553 rank 3
2023-02-12 00:12:33,677 DEBUG TRAIN Batch 12/6000 loss 16.548691 loss_att 16.829502 loss_ctc 19.235435 loss_rnnt 13.456728 hw_loss 0.502044 lr 0.00048531 rank 2
2023-02-12 00:12:33,718 DEBUG TRAIN Batch 12/6000 loss 14.765129 loss_att 15.123923 loss_ctc 22.999456 loss_rnnt 11.205355 hw_loss 0.448144 lr 0.00048554 rank 6
2023-02-12 00:13:52,078 DEBUG TRAIN Batch 12/6100 loss 20.255287 loss_att 27.457623 loss_ctc 29.534248 loss_rnnt 16.244305 hw_loss 0.249997 lr 0.00048508 rank 2
2023-02-12 00:13:52,078 DEBUG TRAIN Batch 12/6100 loss 8.807351 loss_att 10.611921 loss_ctc 11.501505 loss_rnnt 5.859385 hw_loss 0.417718 lr 0.00048530 rank 3
2023-02-12 00:13:52,081 DEBUG TRAIN Batch 12/6100 loss 10.229485 loss_att 14.252811 loss_ctc 19.276419 loss_rnnt 6.732712 hw_loss 0.278597 lr 0.00048523 rank 1
2023-02-12 00:13:52,081 DEBUG TRAIN Batch 12/6100 loss 11.513313 loss_att 13.625685 loss_ctc 16.708900 loss_rnnt 8.392402 hw_loss 0.376067 lr 0.00048524 rank 7
2023-02-12 00:13:52,082 DEBUG TRAIN Batch 12/6100 loss 21.981316 loss_att 25.306763 loss_ctc 32.924355 loss_rnnt 18.095190 hw_loss 0.330368 lr 0.00048519 rank 0
2023-02-12 00:13:52,083 DEBUG TRAIN Batch 12/6100 loss 15.377508 loss_att 19.071804 loss_ctc 26.578501 loss_rnnt 11.842971 hw_loss 0.244165 lr 0.00048532 rank 6
2023-02-12 00:13:52,086 DEBUG TRAIN Batch 12/6100 loss 10.112912 loss_att 13.935019 loss_ctc 16.602333 loss_rnnt 6.826836 hw_loss 0.310575 lr 0.00048522 rank 5
2023-02-12 00:13:52,130 DEBUG TRAIN Batch 12/6100 loss 18.554777 loss_att 24.574852 loss_ctc 24.416348 loss_rnnt 15.140860 hw_loss 0.267817 lr 0.00048532 rank 4
2023-02-12 00:15:08,697 DEBUG TRAIN Batch 12/6200 loss 15.515217 loss_att 14.025764 loss_ctc 20.974676 loss_rnnt 9.392509 hw_loss 1.067376 lr 0.00048508 rank 3
2023-02-12 00:15:08,698 DEBUG TRAIN Batch 12/6200 loss 12.365639 loss_att 14.886223 loss_ctc 15.191355 loss_rnnt 8.331761 hw_loss 0.591187 lr 0.00048497 rank 0
2023-02-12 00:15:08,701 DEBUG TRAIN Batch 12/6200 loss 13.788826 loss_att 14.060608 loss_ctc 20.468815 loss_rnnt 11.798733 hw_loss 0.195951 lr 0.00048501 rank 7
2023-02-12 00:15:08,704 DEBUG TRAIN Batch 12/6200 loss 8.267988 loss_att 10.515321 loss_ctc 12.122696 loss_rnnt 4.586246 hw_loss 0.509684 lr 0.00048509 rank 6
2023-02-12 00:15:08,705 DEBUG TRAIN Batch 12/6200 loss 12.996222 loss_att 13.925707 loss_ctc 21.324482 loss_rnnt 9.284149 hw_loss 0.452952 lr 0.00048501 rank 1
2023-02-12 00:15:08,707 DEBUG TRAIN Batch 12/6200 loss 9.846389 loss_att 12.548868 loss_ctc 18.998777 loss_rnnt 4.764618 hw_loss 0.622679 lr 0.00048509 rank 4
2023-02-12 00:15:08,710 DEBUG TRAIN Batch 12/6200 loss 14.301200 loss_att 14.524349 loss_ctc 18.626965 loss_rnnt 10.653347 hw_loss 0.567460 lr 0.00048499 rank 5
2023-02-12 00:15:08,752 DEBUG TRAIN Batch 12/6200 loss 13.191843 loss_att 13.816557 loss_ctc 19.459518 loss_rnnt 9.743512 hw_loss 0.466443 lr 0.00048485 rank 2
2023-02-12 00:16:24,482 DEBUG TRAIN Batch 12/6300 loss 13.937831 loss_att 16.236210 loss_ctc 20.494286 loss_rnnt 11.079252 hw_loss 0.285883 lr 0.00048485 rank 3
2023-02-12 00:16:24,486 DEBUG TRAIN Batch 12/6300 loss 10.308635 loss_att 11.967732 loss_ctc 13.002886 loss_rnnt 6.985950 hw_loss 0.493431 lr 0.00048474 rank 0
2023-02-12 00:16:24,486 DEBUG TRAIN Batch 12/6300 loss 23.573801 loss_att 26.058983 loss_ctc 39.543209 loss_rnnt 20.177792 hw_loss 0.144322 lr 0.00048463 rank 2
2023-02-12 00:16:24,488 DEBUG TRAIN Batch 12/6300 loss 10.309952 loss_att 11.600956 loss_ctc 13.929736 loss_rnnt 7.162153 hw_loss 0.451305 lr 0.00048478 rank 7
2023-02-12 00:16:24,490 DEBUG TRAIN Batch 12/6300 loss 15.486528 loss_att 15.480133 loss_ctc 21.993315 loss_rnnt 10.747704 hw_loss 0.726100 lr 0.00048476 rank 5
2023-02-12 00:16:24,491 DEBUG TRAIN Batch 12/6300 loss 18.371918 loss_att 19.568157 loss_ctc 18.660463 loss_rnnt 13.123828 hw_loss 0.931944 lr 0.00048486 rank 6
2023-02-12 00:16:24,492 DEBUG TRAIN Batch 12/6300 loss 7.710576 loss_att 14.915464 loss_ctc 11.853998 loss_rnnt 5.538690 hw_loss 0.033460 lr 0.00048486 rank 4
2023-02-12 00:16:24,492 DEBUG TRAIN Batch 12/6300 loss 13.859541 loss_att 14.226070 loss_ctc 21.554754 loss_rnnt 9.621234 hw_loss 0.588557 lr 0.00048478 rank 1
2023-02-12 00:17:42,947 DEBUG TRAIN Batch 12/6400 loss 11.190811 loss_att 14.476803 loss_ctc 17.704121 loss_rnnt 8.678521 hw_loss 0.184997 lr 0.00048462 rank 3
2023-02-12 00:17:42,954 DEBUG TRAIN Batch 12/6400 loss 14.587053 loss_att 11.280441 loss_ctc 14.378443 loss_rnnt 10.412222 hw_loss 0.911994 lr 0.00048463 rank 6
2023-02-12 00:17:42,957 DEBUG TRAIN Batch 12/6400 loss 11.714928 loss_att 12.084008 loss_ctc 17.957172 loss_rnnt 8.636209 hw_loss 0.407363 lr 0.00048464 rank 4
2023-02-12 00:17:42,956 DEBUG TRAIN Batch 12/6400 loss 12.062338 loss_att 12.479643 loss_ctc 13.108580 loss_rnnt 7.828379 hw_loss 0.752062 lr 0.00048453 rank 5
2023-02-12 00:17:42,957 DEBUG TRAIN Batch 12/6400 loss 8.841180 loss_att 12.180910 loss_ctc 11.841090 loss_rnnt 6.925436 hw_loss 0.158964 lr 0.00048440 rank 2
2023-02-12 00:17:42,963 DEBUG TRAIN Batch 12/6400 loss 13.848500 loss_att 9.841314 loss_ctc 13.497809 loss_rnnt 9.924726 hw_loss 0.894744 lr 0.00048455 rank 1
2023-02-12 00:17:42,976 DEBUG TRAIN Batch 12/6400 loss 16.518299 loss_att 18.307995 loss_ctc 23.096096 loss_rnnt 13.147082 hw_loss 0.400545 lr 0.00048451 rank 0
2023-02-12 00:17:42,994 DEBUG TRAIN Batch 12/6400 loss 17.292051 loss_att 22.033108 loss_ctc 31.236135 loss_rnnt 12.879608 hw_loss 0.300941 lr 0.00048456 rank 7
2023-02-12 00:18:59,002 DEBUG TRAIN Batch 12/6500 loss 17.135351 loss_att 17.292339 loss_ctc 26.115736 loss_rnnt 11.658191 hw_loss 0.796571 lr 0.00048428 rank 0
2023-02-12 00:18:59,005 DEBUG TRAIN Batch 12/6500 loss 18.723286 loss_att 24.401402 loss_ctc 36.887421 loss_rnnt 14.166328 hw_loss 0.187397 lr 0.00048417 rank 2
2023-02-12 00:18:59,005 DEBUG TRAIN Batch 12/6500 loss 8.222205 loss_att 11.520466 loss_ctc 12.788859 loss_rnnt 5.755598 hw_loss 0.224638 lr 0.00048439 rank 3
2023-02-12 00:18:59,007 DEBUG TRAIN Batch 12/6500 loss 12.252776 loss_att 14.357156 loss_ctc 14.677681 loss_rnnt 9.107574 hw_loss 0.450188 lr 0.00048440 rank 6
2023-02-12 00:18:59,007 DEBUG TRAIN Batch 12/6500 loss 11.876487 loss_att 12.677826 loss_ctc 18.627625 loss_rnnt 8.209801 hw_loss 0.488675 lr 0.00048430 rank 5
2023-02-12 00:18:59,009 DEBUG TRAIN Batch 12/6500 loss 11.546729 loss_att 15.492734 loss_ctc 21.766403 loss_rnnt 7.286134 hw_loss 0.395395 lr 0.00048441 rank 4
2023-02-12 00:18:59,009 DEBUG TRAIN Batch 12/6500 loss 13.310471 loss_att 14.594707 loss_ctc 17.647980 loss_rnnt 9.696400 hw_loss 0.521042 lr 0.00048432 rank 1
2023-02-12 00:18:59,013 DEBUG TRAIN Batch 12/6500 loss 5.111204 loss_att 5.918755 loss_ctc 4.290471 loss_rnnt 1.574092 hw_loss 0.653444 lr 0.00048433 rank 7
2023-02-12 00:20:13,898 DEBUG TRAIN Batch 12/6600 loss 13.454632 loss_att 13.917310 loss_ctc 13.465716 loss_rnnt 10.505115 hw_loss 0.535407 lr 0.00048409 rank 1
2023-02-12 00:20:13,898 DEBUG TRAIN Batch 12/6600 loss 13.922377 loss_att 15.321466 loss_ctc 22.667763 loss_rnnt 11.041834 hw_loss 0.269001 lr 0.00048417 rank 3
2023-02-12 00:20:13,898 DEBUG TRAIN Batch 12/6600 loss 7.014777 loss_att 9.919663 loss_ctc 10.506435 loss_rnnt 4.555369 hw_loss 0.264914 lr 0.00048418 rank 4
2023-02-12 00:20:13,899 DEBUG TRAIN Batch 12/6600 loss 8.761045 loss_att 12.477171 loss_ctc 17.514204 loss_rnnt 5.059674 hw_loss 0.335823 lr 0.00048408 rank 5
2023-02-12 00:20:13,900 DEBUG TRAIN Batch 12/6600 loss 11.886125 loss_att 13.363287 loss_ctc 19.432766 loss_rnnt 9.183666 hw_loss 0.262651 lr 0.00048410 rank 7
2023-02-12 00:20:13,901 DEBUG TRAIN Batch 12/6600 loss 18.703627 loss_att 21.953991 loss_ctc 21.273548 loss_rnnt 15.552263 hw_loss 0.404744 lr 0.00048406 rank 0
2023-02-12 00:20:13,905 DEBUG TRAIN Batch 12/6600 loss 10.221360 loss_att 8.237898 loss_ctc 10.439451 loss_rnnt 5.353459 hw_loss 0.981659 lr 0.00048395 rank 2
2023-02-12 00:20:13,906 DEBUG TRAIN Batch 12/6600 loss 9.003635 loss_att 11.352560 loss_ctc 15.738517 loss_rnnt 5.972801 hw_loss 0.311825 lr 0.00048418 rank 6
2023-02-12 00:21:31,042 DEBUG TRAIN Batch 12/6700 loss 11.301687 loss_att 14.041846 loss_ctc 21.292660 loss_rnnt 8.808928 hw_loss 0.114862 lr 0.00048394 rank 3
2023-02-12 00:21:31,042 DEBUG TRAIN Batch 12/6700 loss 24.070126 loss_att 28.856024 loss_ctc 35.172115 loss_rnnt 21.025757 hw_loss 0.113798 lr 0.00048387 rank 7
2023-02-12 00:21:31,047 DEBUG TRAIN Batch 12/6700 loss 8.897853 loss_att 10.112379 loss_ctc 11.474119 loss_rnnt 5.293215 hw_loss 0.565918 lr 0.00048385 rank 5
2023-02-12 00:21:31,049 DEBUG TRAIN Batch 12/6700 loss 15.981888 loss_att 19.067234 loss_ctc 24.664003 loss_rnnt 11.767403 hw_loss 0.457462 lr 0.00048387 rank 1
2023-02-12 00:21:31,049 DEBUG TRAIN Batch 12/6700 loss 19.716915 loss_att 20.056870 loss_ctc 28.628975 loss_rnnt 15.855589 hw_loss 0.488449 lr 0.00048383 rank 0
2023-02-12 00:21:31,052 DEBUG TRAIN Batch 12/6700 loss 9.828944 loss_att 11.316498 loss_ctc 16.138868 loss_rnnt 5.070412 hw_loss 0.678694 lr 0.00048395 rank 6
2023-02-12 00:21:31,053 DEBUG TRAIN Batch 12/6700 loss 13.433521 loss_att 15.940920 loss_ctc 21.456209 loss_rnnt 9.193882 hw_loss 0.500338 lr 0.00048395 rank 4
2023-02-12 00:21:31,092 DEBUG TRAIN Batch 12/6700 loss 17.255499 loss_att 22.437841 loss_ctc 23.372730 loss_rnnt 12.517159 hw_loss 0.541170 lr 0.00048372 rank 2
2023-02-12 00:22:48,619 DEBUG TRAIN Batch 12/6800 loss 10.217391 loss_att 14.691793 loss_ctc 14.009399 loss_rnnt 7.655504 hw_loss 0.217763 lr 0.00048372 rank 6
2023-02-12 00:22:48,619 DEBUG TRAIN Batch 12/6800 loss 16.911669 loss_att 18.864639 loss_ctc 29.076103 loss_rnnt 13.491806 hw_loss 0.263877 lr 0.00048371 rank 3
2023-02-12 00:22:48,623 DEBUG TRAIN Batch 12/6800 loss 13.561608 loss_att 16.351326 loss_ctc 17.626320 loss_rnnt 8.979808 hw_loss 0.652855 lr 0.00048362 rank 5
2023-02-12 00:22:48,624 DEBUG TRAIN Batch 12/6800 loss 12.871237 loss_att 15.408865 loss_ctc 19.836388 loss_rnnt 9.799026 hw_loss 0.306750 lr 0.00048360 rank 0
2023-02-12 00:22:48,625 DEBUG TRAIN Batch 12/6800 loss 15.023563 loss_att 17.873322 loss_ctc 19.972012 loss_rnnt 8.915876 hw_loss 0.914614 lr 0.00048364 rank 1
2023-02-12 00:22:48,624 DEBUG TRAIN Batch 12/6800 loss 6.808870 loss_att 9.166656 loss_ctc 10.048204 loss_rnnt 2.802454 hw_loss 0.581803 lr 0.00048365 rank 7
2023-02-12 00:22:48,626 DEBUG TRAIN Batch 12/6800 loss 7.869470 loss_att 8.426641 loss_ctc 13.773246 loss_rnnt 3.167624 hw_loss 0.713108 lr 0.00048349 rank 2
2023-02-12 00:22:48,673 DEBUG TRAIN Batch 12/6800 loss 14.162534 loss_att 14.906975 loss_ctc 18.277273 loss_rnnt 11.697975 hw_loss 0.331320 lr 0.00048373 rank 4
2023-02-12 00:24:04,710 DEBUG TRAIN Batch 12/6900 loss 16.643311 loss_att 20.435322 loss_ctc 31.010843 loss_rnnt 13.168470 hw_loss 0.150144 lr 0.00048340 rank 5
2023-02-12 00:24:04,713 DEBUG TRAIN Batch 12/6900 loss 19.147526 loss_att 18.241320 loss_ctc 31.969131 loss_rnnt 14.574793 hw_loss 0.570830 lr 0.00048350 rank 4
2023-02-12 00:24:04,712 DEBUG TRAIN Batch 12/6900 loss 16.260313 loss_att 11.554863 loss_ctc 14.867352 loss_rnnt 10.770777 hw_loss 1.240566 lr 0.00048327 rank 2
2023-02-12 00:24:04,715 DEBUG TRAIN Batch 12/6900 loss 9.214878 loss_att 8.706514 loss_ctc 13.159039 loss_rnnt 5.171591 hw_loss 0.678576 lr 0.00048349 rank 3
2023-02-12 00:24:04,714 DEBUG TRAIN Batch 12/6900 loss 8.124224 loss_att 9.640967 loss_ctc 6.172729 loss_rnnt 4.744322 hw_loss 0.625641 lr 0.00048350 rank 6
2023-02-12 00:24:04,720 DEBUG TRAIN Batch 12/6900 loss 9.568607 loss_att 9.465473 loss_ctc 9.587858 loss_rnnt 7.189358 hw_loss 0.449495 lr 0.00048338 rank 0
2023-02-12 00:24:04,721 DEBUG TRAIN Batch 12/6900 loss 12.540371 loss_att 12.768753 loss_ctc 17.824289 loss_rnnt 10.197319 hw_loss 0.298660 lr 0.00048342 rank 7
2023-02-12 00:24:04,769 DEBUG TRAIN Batch 12/6900 loss 14.147626 loss_att 17.867552 loss_ctc 30.307766 loss_rnnt 9.195704 hw_loss 0.384985 lr 0.00048342 rank 1
2023-02-12 00:25:22,188 DEBUG TRAIN Batch 12/7000 loss 13.134539 loss_att 14.617155 loss_ctc 18.992361 loss_rnnt 9.709387 hw_loss 0.440172 lr 0.00048304 rank 2
2023-02-12 00:25:22,189 DEBUG TRAIN Batch 12/7000 loss 29.158171 loss_att 33.433224 loss_ctc 47.268566 loss_rnnt 23.918518 hw_loss 0.369360 lr 0.00048326 rank 3
2023-02-12 00:25:22,189 DEBUG TRAIN Batch 12/7000 loss 13.832261 loss_att 14.518304 loss_ctc 20.484123 loss_rnnt 11.836693 hw_loss 0.182146 lr 0.00048317 rank 5
2023-02-12 00:25:22,189 DEBUG TRAIN Batch 12/7000 loss 20.724350 loss_att 22.201885 loss_ctc 26.871685 loss_rnnt 17.470541 hw_loss 0.400999 lr 0.00048320 rank 7
2023-02-12 00:25:22,191 DEBUG TRAIN Batch 12/7000 loss 18.068186 loss_att 18.630997 loss_ctc 24.770508 loss_rnnt 13.854907 hw_loss 0.601326 lr 0.00048319 rank 1
2023-02-12 00:25:22,191 DEBUG TRAIN Batch 12/7000 loss 13.236429 loss_att 16.173069 loss_ctc 18.273407 loss_rnnt 9.809508 hw_loss 0.406499 lr 0.00048328 rank 4
2023-02-12 00:25:22,195 DEBUG TRAIN Batch 12/7000 loss 10.872041 loss_att 9.528123 loss_ctc 9.652293 loss_rnnt 7.785697 hw_loss 0.659580 lr 0.00048327 rank 6
2023-02-12 00:25:22,514 DEBUG TRAIN Batch 12/7000 loss 9.588072 loss_att 8.074522 loss_ctc 11.603332 loss_rnnt 6.026392 hw_loss 0.674192 lr 0.00048315 rank 0
2023-02-12 00:26:40,256 DEBUG TRAIN Batch 12/7100 loss 14.722791 loss_att 17.252274 loss_ctc 21.902645 loss_rnnt 11.557010 hw_loss 0.319232 lr 0.00048297 rank 7
2023-02-12 00:26:40,260 DEBUG TRAIN Batch 12/7100 loss 9.643062 loss_att 13.377722 loss_ctc 11.976383 loss_rnnt 8.158686 hw_loss 0.079938 lr 0.00048303 rank 3
2023-02-12 00:26:40,260 DEBUG TRAIN Batch 12/7100 loss 8.689467 loss_att 10.409235 loss_ctc 17.176830 loss_rnnt 6.268673 hw_loss 0.177224 lr 0.00048293 rank 0
2023-02-12 00:26:40,262 DEBUG TRAIN Batch 12/7100 loss 9.066042 loss_att 7.606835 loss_ctc 8.401359 loss_rnnt 4.424401 hw_loss 0.941645 lr 0.00048295 rank 5
2023-02-12 00:26:40,264 DEBUG TRAIN Batch 12/7100 loss 14.832693 loss_att 16.418793 loss_ctc 23.849989 loss_rnnt 10.550119 hw_loss 0.518071 lr 0.00048305 rank 4
2023-02-12 00:26:40,265 DEBUG TRAIN Batch 12/7100 loss 29.729773 loss_att 29.031118 loss_ctc 42.796921 loss_rnnt 24.881844 hw_loss 0.608507 lr 0.00048305 rank 6
2023-02-12 00:26:40,269 DEBUG TRAIN Batch 12/7100 loss 20.670963 loss_att 19.851677 loss_ctc 28.101149 loss_rnnt 17.875332 hw_loss 0.369149 lr 0.00048282 rank 2
2023-02-12 00:26:40,310 DEBUG TRAIN Batch 12/7100 loss 12.001964 loss_att 15.122662 loss_ctc 15.457804 loss_rnnt 9.468378 hw_loss 0.271625 lr 0.00048296 rank 1
2023-02-12 00:27:57,090 DEBUG TRAIN Batch 12/7200 loss 10.882130 loss_att 13.444885 loss_ctc 22.411551 loss_rnnt 8.289009 hw_loss 0.101871 lr 0.00048274 rank 1
2023-02-12 00:27:57,091 DEBUG TRAIN Batch 12/7200 loss 16.990505 loss_att 17.897497 loss_ctc 20.277451 loss_rnnt 13.049994 hw_loss 0.622660 lr 0.00048281 rank 3
2023-02-12 00:27:57,092 DEBUG TRAIN Batch 12/7200 loss 17.498034 loss_att 18.837852 loss_ctc 23.053976 loss_rnnt 13.808940 hw_loss 0.502563 lr 0.00048270 rank 0
2023-02-12 00:27:57,093 DEBUG TRAIN Batch 12/7200 loss 13.640425 loss_att 13.244073 loss_ctc 18.426201 loss_rnnt 8.644520 hw_loss 0.831951 lr 0.00048282 rank 6
2023-02-12 00:27:57,095 DEBUG TRAIN Batch 12/7200 loss 16.694950 loss_att 18.813845 loss_ctc 22.572510 loss_rnnt 14.540400 hw_loss 0.177581 lr 0.00048259 rank 2
2023-02-12 00:27:57,096 DEBUG TRAIN Batch 12/7200 loss 11.163849 loss_att 11.280499 loss_ctc 17.333933 loss_rnnt 7.643957 hw_loss 0.501353 lr 0.00048282 rank 4
2023-02-12 00:27:57,096 DEBUG TRAIN Batch 12/7200 loss 11.471668 loss_att 13.971124 loss_ctc 15.710372 loss_rnnt 8.252650 hw_loss 0.403869 lr 0.00048275 rank 7
2023-02-12 00:27:57,098 DEBUG TRAIN Batch 12/7200 loss 19.441006 loss_att 19.829035 loss_ctc 31.764288 loss_rnnt 16.250753 hw_loss 0.275539 lr 0.00048272 rank 5
2023-02-12 00:29:12,111 DEBUG TRAIN Batch 12/7300 loss 12.227591 loss_att 10.916310 loss_ctc 14.582801 loss_rnnt 7.887146 hw_loss 0.804126 lr 0.00048251 rank 1
2023-02-12 00:29:12,112 DEBUG TRAIN Batch 12/7300 loss 11.328024 loss_att 13.138006 loss_ctc 14.722733 loss_rnnt 8.920647 hw_loss 0.298641 lr 0.00048258 rank 3
2023-02-12 00:29:12,112 DEBUG TRAIN Batch 12/7300 loss 19.102011 loss_att 20.067745 loss_ctc 29.340166 loss_rnnt 14.686267 hw_loss 0.535783 lr 0.00048248 rank 0
2023-02-12 00:29:12,115 DEBUG TRAIN Batch 12/7300 loss 6.365320 loss_att 7.710438 loss_ctc 9.211529 loss_rnnt 4.023517 hw_loss 0.317491 lr 0.00048250 rank 5
2023-02-12 00:29:12,115 DEBUG TRAIN Batch 12/7300 loss 8.934142 loss_att 13.855646 loss_ctc 12.302361 loss_rnnt 4.643764 hw_loss 0.535684 lr 0.00048252 rank 7
2023-02-12 00:29:12,116 DEBUG TRAIN Batch 12/7300 loss 13.196037 loss_att 16.073713 loss_ctc 17.328884 loss_rnnt 10.467318 hw_loss 0.300401 lr 0.00048260 rank 4
2023-02-12 00:29:12,119 DEBUG TRAIN Batch 12/7300 loss 16.406370 loss_att 15.988758 loss_ctc 19.736336 loss_rnnt 12.569487 hw_loss 0.651827 lr 0.00048237 rank 2
2023-02-12 00:29:12,157 DEBUG TRAIN Batch 12/7300 loss 6.990415 loss_att 11.720767 loss_ctc 9.660498 loss_rnnt 2.465435 hw_loss 0.604293 lr 0.00048260 rank 6
2023-02-12 00:30:29,779 DEBUG TRAIN Batch 12/7400 loss 19.979404 loss_att 19.175856 loss_ctc 26.342873 loss_rnnt 12.753769 hw_loss 1.225853 lr 0.00048236 rank 3
2023-02-12 00:30:29,779 DEBUG TRAIN Batch 12/7400 loss 13.421780 loss_att 12.292183 loss_ctc 13.546465 loss_rnnt 9.822849 hw_loss 0.714042 lr 0.00048237 rank 6
2023-02-12 00:30:29,781 DEBUG TRAIN Batch 12/7400 loss 23.225979 loss_att 20.356821 loss_ctc 27.795994 loss_rnnt 19.517330 hw_loss 0.688715 lr 0.00048214 rank 2
2023-02-12 00:30:29,783 DEBUG TRAIN Batch 12/7400 loss 9.995207 loss_att 14.625842 loss_ctc 17.454258 loss_rnnt 6.774334 hw_loss 0.243788 lr 0.00048229 rank 1
2023-02-12 00:30:29,784 DEBUG TRAIN Batch 12/7400 loss 13.113094 loss_att 15.718106 loss_ctc 18.685280 loss_rnnt 11.314365 hw_loss 0.100269 lr 0.00048238 rank 4
2023-02-12 00:30:29,784 DEBUG TRAIN Batch 12/7400 loss 16.583632 loss_att 20.236637 loss_ctc 27.785530 loss_rnnt 13.254503 hw_loss 0.207176 lr 0.00048225 rank 0
2023-02-12 00:30:29,786 DEBUG TRAIN Batch 12/7400 loss 7.091938 loss_att 10.221395 loss_ctc 11.747132 loss_rnnt 3.588524 hw_loss 0.423156 lr 0.00048230 rank 7
2023-02-12 00:30:29,789 DEBUG TRAIN Batch 12/7400 loss 11.672403 loss_att 13.288525 loss_ctc 16.372894 loss_rnnt 9.374574 hw_loss 0.252726 lr 0.00048227 rank 5
